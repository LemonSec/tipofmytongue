1
00:00:04,509 --> 00:00:08,019
um hey so I'm Tim O'Shea I'm from

2
00:00:08,019 --> 00:00:12,240
Virginia Tech just researcher there and

3
00:00:12,240 --> 00:00:16,660
I wanted to talk a bit about kind of the

4
00:00:16,660 --> 00:00:18,550
possibilities for tensor signal

5
00:00:18,550 --> 00:00:20,710
processing and then kind of bleed into

6
00:00:20,710 --> 00:00:23,710
how that bleeds into machine learning as

7
00:00:23,710 --> 00:00:29,410
well so just to set the background I'm

8
00:00:29,410 --> 00:00:30,730
sure a lot of you've been watching this

9
00:00:30,730 --> 00:00:33,039
but you know what's been going on in

10
00:00:33,039 --> 00:00:34,359
machine learning and kind of the

11
00:00:34,359 --> 00:00:36,100
resurgence of neural networks has been

12
00:00:36,100 --> 00:00:38,679
pretty awesome to watch and this has

13
00:00:38,679 --> 00:00:40,510
primarily been in the computer vision

14
00:00:40,510 --> 00:00:43,030
area and so there's a lot of people in

15
00:00:43,030 --> 00:00:46,929
like the self-driving car area as well

16
00:00:46,929 --> 00:00:48,729
as like facial and object recognition

17
00:00:48,729 --> 00:00:50,399
areas and natural language processing

18
00:00:50,399 --> 00:00:52,629
where we've made like lots and lots of

19
00:00:52,629 --> 00:00:55,569
advances in in recent time in driving

20
00:00:55,569 --> 00:00:57,519
down error rates on translation and

21
00:00:57,519 --> 00:00:59,879
object recognition and all these things

22
00:00:59,879 --> 00:01:03,249
and if you look at it so no networks

23
00:01:03,249 --> 00:01:05,080
from a computational standpoint are

24
00:01:05,080 --> 00:01:06,940
really interesting because they have

25
00:01:06,940 --> 00:01:10,810
this fairly well-defined compute

26
00:01:10,810 --> 00:01:13,480
structure that constitutes a network

27
00:01:13,480 --> 00:01:14,290
right

28
00:01:14,290 --> 00:01:17,320
and so the if you look at kind of the

29
00:01:17,320 --> 00:01:20,020
calculations for a neural network you

30
00:01:20,020 --> 00:01:22,090
have this kind of it's really basically

31
00:01:22,090 --> 00:01:24,130
a big multiplied accumulate for each

32
00:01:24,130 --> 00:01:26,560
layer so you have this these inputs that

33
00:01:26,560 --> 00:01:27,970
are multiplied with a series of weights

34
00:01:27,970 --> 00:01:30,580
that are sung and then run through some

35
00:01:30,580 --> 00:01:33,960
non-linearity like a sigmoid function

36
00:01:33,960 --> 00:01:36,310
and that's basically one layer in a

37
00:01:36,310 --> 00:01:39,310
neural network now if you look at these

38
00:01:39,310 --> 00:01:42,340
so-called convolutional layers you no

39
00:01:42,340 --> 00:01:44,380
longer have a separate weight on each

40
00:01:44,380 --> 00:01:46,390
input but you have these weights that

41
00:01:46,390 --> 00:01:48,460
are tied in a way such that when you

42
00:01:48,460 --> 00:01:50,440
slide a patch across an input you

43
00:01:50,440 --> 00:01:52,720
replicate the same weights at different

44
00:01:52,720 --> 00:01:54,250
shifts all right so that's it's really

45
00:01:54,250 --> 00:01:57,220
the only difference and then if you look

46
00:01:57,220 --> 00:01:58,720
at some of the bigger models so this is

47
00:01:58,720 --> 00:02:01,300
from like a year and a half or ago one

48
00:02:01,300 --> 00:02:03,340
of Google's vision networks for doing

49
00:02:03,340 --> 00:02:05,350
object recognition you think of that

50
00:02:05,350 --> 00:02:07,360
transfer function for a layer you know

51
00:02:07,360 --> 00:02:10,149
that's one box in this network right so

52
00:02:10,149 --> 00:02:11,950
we now have this network which is you

53
00:02:11,950 --> 00:02:14,170
know 40 or 50 layers some of the ones

54
00:02:14,170 --> 00:02:16,730
this year were over 100 layers deep

55
00:02:16,730 --> 00:02:19,190
in the complexity that they're doing to

56
00:02:19,190 --> 00:02:21,800
do this object recognition

57
00:02:21,800 --> 00:02:23,569
so there's been a really really strong

58
00:02:23,569 --> 00:02:25,910
software ecosystem to support machine

59
00:02:25,910 --> 00:02:28,700
learning for computer vision and it's

60
00:02:28,700 --> 00:02:30,110
really kind of starting to centralize

61
00:02:30,110 --> 00:02:31,910
around this kind of tensor programming

62
00:02:31,910 --> 00:02:36,680
model I and and this is really you know

63
00:02:36,680 --> 00:02:37,790
interesting because you're building

64
00:02:37,790 --> 00:02:41,200
these these big tensor graph expressions

65
00:02:41,200 --> 00:02:44,360
and then you know as a big abstract

66
00:02:44,360 --> 00:02:47,330
dataflow representation and then you

67
00:02:47,330 --> 00:02:50,380
kind of map it down to hardware to run

68
00:02:50,380 --> 00:02:54,230
so two of these architectures are kind

69
00:02:54,230 --> 00:02:57,200
of theano and tensor flow piano was

70
00:02:57,200 --> 00:03:00,410
around kind of first and kind of

71
00:03:00,410 --> 00:03:02,120
pioneered this and then Google like

72
00:03:02,120 --> 00:03:04,700
secretly rewrote it internally and then

73
00:03:04,700 --> 00:03:06,290
eventually released it to the world and

74
00:03:06,290 --> 00:03:11,090
now they're both very popular but the

75
00:03:11,090 --> 00:03:14,890
whole idea here is these are basically

76
00:03:14,890 --> 00:03:19,000
libraries that allow you to write big

77
00:03:19,000 --> 00:03:21,920
numpy expressions essentially where you

78
00:03:21,920 --> 00:03:23,540
have many operations that are kind of

79
00:03:23,540 --> 00:03:27,769
forming a data flow graph and then take

80
00:03:27,769 --> 00:03:29,750
it and and the idea is you build this

81
00:03:29,750 --> 00:03:31,760
graph expression and then you go through

82
00:03:31,760 --> 00:03:34,700
the back end and you and you go out to

83
00:03:34,700 --> 00:03:36,950
any one of a number of targets and so

84
00:03:36,950 --> 00:03:39,739
right now we go to basically GCC and

85
00:03:39,739 --> 00:03:42,739
CUDA as the backend but there's a lot of

86
00:03:42,739 --> 00:03:44,450
plans underway at Google to do this

87
00:03:44,450 --> 00:03:46,639
thing called Excel a which is like their

88
00:03:46,639 --> 00:03:49,400
next generation tensor backend and

89
00:03:49,400 --> 00:03:51,470
they're there you're doing a lot of work

90
00:03:51,470 --> 00:03:54,139
to sync this up with LLVM so they can

91
00:03:54,139 --> 00:03:56,290
actually you just use kind of LLVM

92
00:03:56,290 --> 00:03:59,299
abstract representation to pass it in

93
00:03:59,299 --> 00:04:01,030
and then there's a lot of rumors about

94
00:04:01,030 --> 00:04:04,700
potential support on like the cue DSPs

95
00:04:04,700 --> 00:04:07,609
that Qualcomm builds for base bands as

96
00:04:07,609 --> 00:04:10,220
well as some of the Xilinx chips there's

97
00:04:10,220 --> 00:04:12,470
there's been a lot of talking about

98
00:04:12,470 --> 00:04:14,180
Xilinx potentially supporting this as a

99
00:04:14,180 --> 00:04:16,820
code generator so it's really cool we

100
00:04:16,820 --> 00:04:19,459
may have finally a language that we can

101
00:04:19,459 --> 00:04:21,139
target to a lot of different kind of

102
00:04:21,139 --> 00:04:24,470
platforms from this this kind of way to

103
00:04:24,470 --> 00:04:26,180
express things

104
00:04:26,180 --> 00:04:28,580
so this is used heavily for neural

105
00:04:28,580 --> 00:04:29,900
networks but it's not really a neural

106
00:04:29,900 --> 00:04:31,820
network specific so if you look at this

107
00:04:31,820 --> 00:04:34,190
is basically a simple expression we

108
00:04:34,190 --> 00:04:36,110
start by defining these variables like a

109
00:04:36,110 --> 00:04:38,450
and B and we can define operations on

110
00:04:38,450 --> 00:04:41,660
them like adding or multiplying and then

111
00:04:41,660 --> 00:04:43,810
eventually we go into our session and we

112
00:04:43,810 --> 00:04:46,460
evaluate these expressions and so this

113
00:04:46,460 --> 00:04:48,620
is basically building up your big in

114
00:04:48,620 --> 00:04:51,770
this case a very small kind of data flow

115
00:04:51,770 --> 00:04:53,480
graph and then this is going to be

116
00:04:53,480 --> 00:04:54,830
compiling and running your from your

117
00:04:54,830 --> 00:04:56,780
graph alright so you can build much

118
00:04:56,780 --> 00:04:59,930
bigger things in this so I talked a

119
00:04:59,930 --> 00:05:02,650
little bit before about gr tensor flow

120
00:05:02,650 --> 00:05:05,990
and the whole idea is you know really at

121
00:05:05,990 --> 00:05:07,970
the core of this this is just kind of

122
00:05:07,970 --> 00:05:11,930
like a a kernel work call right so we

123
00:05:11,930 --> 00:05:13,250
can wedge it right into a good radial

124
00:05:13,250 --> 00:05:17,390
block and use it to offload these tensor

125
00:05:17,390 --> 00:05:19,240
operations from within a work function

126
00:05:19,240 --> 00:05:23,660
and so this is something added a couple

127
00:05:23,660 --> 00:05:26,350
months ago and the whole idea here is

128
00:05:26,350 --> 00:05:29,240
you know can we take a sinc interpolator

129
00:05:29,240 --> 00:05:32,930
of a signal and offload that on to GPU

130
00:05:32,930 --> 00:05:35,180
or on to whatever using this kind of

131
00:05:35,180 --> 00:05:37,520
tensor language and so this is basically

132
00:05:37,520 --> 00:05:40,700
the definition of a sinc interpolation

133
00:05:40,700 --> 00:05:43,220
right and so you're going through here

134
00:05:43,220 --> 00:05:45,230
and and up at the top you're defining

135
00:05:45,230 --> 00:05:47,800
the the graph through this series of

136
00:05:47,800 --> 00:05:51,010
castings you know tiling of the input

137
00:05:51,010 --> 00:05:53,570
doing these gather operations which are

138
00:05:53,570 --> 00:05:58,580
basically index lookups into vectors and

139
00:05:58,580 --> 00:06:00,110
then doing a reduced sum which is

140
00:06:00,110 --> 00:06:01,310
basically just a big multiplied

141
00:06:01,310 --> 00:06:05,570
accumulate and so once we've kind of

142
00:06:05,570 --> 00:06:08,060
issued these commands we've built this

143
00:06:08,060 --> 00:06:10,640
this kind of dependence graph for the

144
00:06:10,640 --> 00:06:14,540
operation and now whenever we run it we

145
00:06:14,540 --> 00:06:16,100
could change the back end to either the

146
00:06:16,100 --> 00:06:20,360
CPU or the GPU or you know some of the

147
00:06:20,360 --> 00:06:22,270
targets that are probably coming soon

148
00:06:22,270 --> 00:06:26,720
and so that's kind of just an example I

149
00:06:26,720 --> 00:06:28,400
think there's not many people out there

150
00:06:28,400 --> 00:06:30,320
using this for pure signal processing

151
00:06:30,320 --> 00:06:34,629
like this yet but I think there's a huge

152
00:06:34,629 --> 00:06:37,330
the huge potential for it the tensor

153
00:06:37,330 --> 00:06:39,219
languages are pretty expressive for

154
00:06:39,219 --> 00:06:40,949
almost any of the comms problems we have

155
00:06:40,949 --> 00:06:44,709
and the kernel compilers and optimizers

156
00:06:44,709 --> 00:06:47,199
are really quite good so this is kind of

157
00:06:47,199 --> 00:06:50,559
a pretty exciting way to offload on to

158
00:06:50,559 --> 00:06:55,809
GPUs and things all right so let's

159
00:06:55,809 --> 00:06:57,659
switch over to the machine learning side

160
00:06:57,659 --> 00:07:00,610
so that was kind of basic signal

161
00:07:00,610 --> 00:07:02,770
processing but I guess my research now

162
00:07:02,770 --> 00:07:04,959
is really centered around okay how do we

163
00:07:04,959 --> 00:07:07,300
take these machine learning ideas and

164
00:07:07,300 --> 00:07:10,930
apply them to radio technology and radio

165
00:07:10,930 --> 00:07:12,639
communications and so these are just

166
00:07:12,639 --> 00:07:14,319
kind of a couple of the the questions

167
00:07:14,319 --> 00:07:16,809
you might ask you know can we apply it

168
00:07:16,809 --> 00:07:18,939
in these ways and so really I've been

169
00:07:18,939 --> 00:07:19,990
looking at you know can you learn

170
00:07:19,990 --> 00:07:23,529
entirely new communications schemes or

171
00:07:23,529 --> 00:07:25,990
can we just learn algorithms to put into

172
00:07:25,990 --> 00:07:27,669
our current waveforms as different

173
00:07:27,669 --> 00:07:31,479
subsystems and then in a sensing

174
00:07:31,479 --> 00:07:33,550
scenario you may want to know you know

175
00:07:33,550 --> 00:07:34,959
what's around you in your interference

176
00:07:34,959 --> 00:07:37,330
environment like tom was talking about

177
00:07:37,330 --> 00:07:40,360
this morning where you may have EMI

178
00:07:40,360 --> 00:07:44,259
emissions from your you know your power

179
00:07:44,259 --> 00:07:46,779
supply or whatever you may want your

180
00:07:46,779 --> 00:07:48,399
system to be aware of all these emitters

181
00:07:48,399 --> 00:07:50,019
around you when it makes decisions about

182
00:07:50,019 --> 00:07:52,839
setting up the communications link and

183
00:07:52,839 --> 00:07:54,969
then just how to optimize existing

184
00:07:54,969 --> 00:07:56,589
systems so these are kind of some of the

185
00:07:56,589 --> 00:08:01,779
high level goals right so this is some

186
00:08:01,779 --> 00:08:03,759
of the earlier work from this year and I

187
00:08:03,759 --> 00:08:05,860
think we saw a little bit in the gr

188
00:08:05,860 --> 00:08:11,079
inspector talk which was awesome so the

189
00:08:11,079 --> 00:08:13,449
whole idea here is you know for a long

190
00:08:13,449 --> 00:08:15,519
long time when we looked at doing

191
00:08:15,519 --> 00:08:17,949
modulation recognition which is kind of

192
00:08:17,949 --> 00:08:21,300
a classical communication sensing task

193
00:08:21,300 --> 00:08:25,449
the approach was generally to do this

194
00:08:25,449 --> 00:08:27,309
expert feature approach where you you

195
00:08:27,309 --> 00:08:30,759
extract a bunch of high order moments or

196
00:08:30,759 --> 00:08:33,309
high order cumulants along with maybe

197
00:08:33,309 --> 00:08:35,948
statistics on the signal and the phase

198
00:08:35,948 --> 00:08:40,779
and the envelope and here we're kind of

199
00:08:40,779 --> 00:08:42,969
we're trying to go to a whole different

200
00:08:42,969 --> 00:08:45,370
route of just let's instead let's go to

201
00:08:45,370 --> 00:08:48,040
feature learning on the raw input signal

202
00:08:48,040 --> 00:08:50,200
and just put the inq in and let it learn

203
00:08:50,200 --> 00:08:52,690
a whole new set of its own features and

204
00:08:52,690 --> 00:08:55,330
and it's funny I mean if you look at

205
00:08:55,330 --> 00:08:56,830
what's happened in the image and the

206
00:08:56,830 --> 00:08:58,840
computer vision domain this is exactly

207
00:08:58,840 --> 00:09:01,750
you know what is what has happened so

208
00:09:01,750 --> 00:09:03,940
until five or ten years ago there was a

209
00:09:03,940 --> 00:09:05,260
whole discipline of feature engineering

210
00:09:05,260 --> 00:09:08,230
envision which has been largely replaced

211
00:09:08,230 --> 00:09:10,060
now with with these kind of end-to-end

212
00:09:10,060 --> 00:09:12,640
learned features and so I think a lot of

213
00:09:12,640 --> 00:09:14,680
this is going to happen in the comms and

214
00:09:14,680 --> 00:09:17,200
the radio space as well and so this is

215
00:09:17,200 --> 00:09:18,280
really kind of showing that for

216
00:09:18,280 --> 00:09:20,350
modulation recognition we can do pretty

217
00:09:20,350 --> 00:09:23,560
much the same thing so so we start

218
00:09:23,560 --> 00:09:27,220
there's a data set that's up on the

219
00:09:27,220 --> 00:09:30,040
website and you know this is basically

220
00:09:30,040 --> 00:09:31,750
just using Guinea radio to generate a

221
00:09:31,750 --> 00:09:34,240
whole bunch of synthetic signals through

222
00:09:34,240 --> 00:09:36,850
a whole bunch of synthetic channels that

223
00:09:36,850 --> 00:09:39,130
use the dynamic fading model and then

224
00:09:39,130 --> 00:09:40,570
this is kind of what we use for that

225
00:09:40,570 --> 00:09:46,950
experiment so this is just essentially

226
00:09:46,950 --> 00:09:49,600
you know this is basically just a small

227
00:09:49,600 --> 00:09:51,040
convolutional neural network that we're

228
00:09:51,040 --> 00:09:54,400
using to do this classification and if

229
00:09:54,400 --> 00:09:56,320
you look at performance there's kind of

230
00:09:56,320 --> 00:09:58,000
a bunch of the solid ones here are

231
00:09:58,000 --> 00:10:00,310
different variations of a kind of

232
00:10:00,310 --> 00:10:02,440
feature learning approach which taken

233
00:10:02,440 --> 00:10:04,990
the raw samples and the dotted ones are

234
00:10:04,990 --> 00:10:07,930
basically different classifiers using

235
00:10:07,930 --> 00:10:10,240
these expert features like higher order

236
00:10:10,240 --> 00:10:13,630
moments to classify so here you can see

237
00:10:13,630 --> 00:10:15,760
you know in the best case for both we

238
00:10:15,760 --> 00:10:17,490
get you know three or four DB

239
00:10:17,490 --> 00:10:20,140
sensitivity improvement with these

240
00:10:20,140 --> 00:10:23,260
methods which is pretty exciting three

241
00:10:23,260 --> 00:10:27,720
or four DB is a lot in some worlds so

242
00:10:27,720 --> 00:10:33,580
and then yeah so alright so one of the

243
00:10:33,580 --> 00:10:36,040
other cool things you can do is if you

244
00:10:36,040 --> 00:10:37,990
take for instance if we look at this

245
00:10:37,990 --> 00:10:42,700
network our output is 11 values right so

246
00:10:42,700 --> 00:10:44,530
these is these correspond to one per

247
00:10:44,530 --> 00:10:46,630
modulation class you typically use like

248
00:10:46,630 --> 00:10:50,530
a one hot encoding for a classifier if

249
00:10:50,530 --> 00:10:52,930
you if you go back one layer you have

250
00:10:52,930 --> 00:10:55,060
this feature map of activations between

251
00:10:55,060 --> 00:10:57,550
each layer and and generally this is

252
00:10:57,550 --> 00:10:59,470
reducing in size as you go through the

253
00:10:59,470 --> 00:11:00,940
network to become a more and more

254
00:11:00,940 --> 00:11:01,830
concise

255
00:11:01,830 --> 00:11:04,840
representation of the information so if

256
00:11:04,840 --> 00:11:06,640
we go back one layer and we just take

257
00:11:06,640 --> 00:11:09,490
these activations here we actually now

258
00:11:09,490 --> 00:11:12,160
have a basically a compressed

259
00:11:12,160 --> 00:11:14,080
representation of the signals from the

260
00:11:14,080 --> 00:11:17,770
input in this feature map space and so

261
00:11:17,770 --> 00:11:19,750
what's really cool is we can start now

262
00:11:19,750 --> 00:11:23,020
using that compressed representation to

263
00:11:23,020 --> 00:11:26,040
just kind of visualize you know where

264
00:11:26,040 --> 00:11:28,450
where are these signals in this kind of

265
00:11:28,450 --> 00:11:31,150
abstract modulation space alright and so

266
00:11:31,150 --> 00:11:33,850
now we can start to cluster them and you

267
00:11:33,850 --> 00:11:35,620
know we have this basis now that is

268
00:11:35,620 --> 00:11:37,690
relatively good at separating a bunch of

269
00:11:37,690 --> 00:11:40,300
different signal types and so this is

270
00:11:40,300 --> 00:11:41,650
kind of interesting because you know if

271
00:11:41,650 --> 00:11:43,720
a new modulation pops up you know if

272
00:11:43,720 --> 00:11:45,730
these features generalize you know we

273
00:11:45,730 --> 00:11:47,380
hope we'll get a new cluster over here

274
00:11:47,380 --> 00:11:49,720
or something that's discernible so that

275
00:11:49,720 --> 00:11:51,730
we can start to recognize things online

276
00:11:51,730 --> 00:11:54,060
without having to train it for every

277
00:11:54,060 --> 00:12:02,140
explicit case kind of ahead of time all

278
00:12:02,140 --> 00:12:05,380
right so then this is this goes to some

279
00:12:05,380 --> 00:12:07,060
of the work that we did this week back

280
00:12:07,060 --> 00:12:13,330
fest and so how many times has I guess

281
00:12:13,330 --> 00:12:14,740
raise your hand if you've ever written a

282
00:12:14,740 --> 00:12:17,350
flow graph it's like a usurps source

283
00:12:17,350 --> 00:12:21,610
through a head to a vector sing alright

284
00:12:21,610 --> 00:12:25,830
I feel like okay we got a handful so

285
00:12:25,830 --> 00:12:28,060
sometimes it feels silly to use

286
00:12:28,060 --> 00:12:29,380
radio when you all you want to do is

287
00:12:29,380 --> 00:12:31,500
just grab a chunk of samples off a radio

288
00:12:31,500 --> 00:12:34,410
and so that's the whole point of this

289
00:12:34,410 --> 00:12:38,410
numpy uhd wrapper and so this is just

290
00:12:38,410 --> 00:12:41,350
like a super the thinnest interface you

291
00:12:41,350 --> 00:12:44,110
could have to say you know tune my radio

292
00:12:44,110 --> 00:12:46,830
somewhere and grab some samples from it

293
00:12:46,830 --> 00:12:50,560
and so super simple and so what we're

294
00:12:50,560 --> 00:12:53,740
doing here is this makes it really quick

295
00:12:53,740 --> 00:12:55,600
to just take little looks all over the

296
00:12:55,600 --> 00:12:58,270
spectrum and generate spectrograms for

297
00:12:58,270 --> 00:13:01,270
them so if we do that we can start to

298
00:13:01,270 --> 00:13:03,660
get all these samples of different bands

299
00:13:03,660 --> 00:13:06,320
that are all around us

300
00:13:06,320 --> 00:13:08,360
and so this is just kind of a sampling

301
00:13:08,360 --> 00:13:11,090
of a bunch of spectrums across you know

302
00:13:11,090 --> 00:13:15,170
common bands so if we use this in a

303
00:13:15,170 --> 00:13:17,390
confident we can also build a classifier

304
00:13:17,390 --> 00:13:20,000
for the different bands this is not a

305
00:13:20,000 --> 00:13:22,790
very good one at the moment there but

306
00:13:22,790 --> 00:13:26,230
that's just because the slides were a

307
00:13:26,230 --> 00:13:32,840
bit late but so it's not necessarily

308
00:13:32,840 --> 00:13:34,910
that exciting to classify which band

309
00:13:34,910 --> 00:13:36,650
you're on because you know we have

310
00:13:36,650 --> 00:13:38,840
allocation schemes this isn't really

311
00:13:38,840 --> 00:13:40,940
that useful but the thing that's really

312
00:13:40,940 --> 00:13:43,760
interesting about it is we learn these

313
00:13:43,760 --> 00:13:46,190
sets of features for each band that make

314
00:13:46,190 --> 00:13:47,510
that band what it is

315
00:13:47,510 --> 00:13:50,660
so like the LTE downlink band is filled

316
00:13:50,660 --> 00:13:52,610
with LTE signals that have all the

317
00:13:52,610 --> 00:13:54,530
properties and features of an LTE signal

318
00:13:54,530 --> 00:13:57,890
in the downlink and so our network as

319
00:13:57,890 --> 00:14:00,290
its learning this it starts to learn all

320
00:14:00,290 --> 00:14:03,080
these features within you know that

321
00:14:03,080 --> 00:14:05,690
comprise that band and so what we can do

322
00:14:05,690 --> 00:14:09,440
is we can now take any random

323
00:14:09,440 --> 00:14:11,900
spectrogram that comes in like these two

324
00:14:11,900 --> 00:14:15,620
and we can look at where in that input

325
00:14:15,620 --> 00:14:18,410
spectrogram where they're activations

326
00:14:18,410 --> 00:14:21,890
that led to thinking it was that class

327
00:14:21,890 --> 00:14:25,010
right so so we can say you know what it

328
00:14:25,010 --> 00:14:26,660
what in this image makes us think it's

329
00:14:26,660 --> 00:14:29,810
l2 eat up wink right and so if you do

330
00:14:29,810 --> 00:14:33,010
that you can look at and get this

331
00:14:33,010 --> 00:14:36,290
localization mask that's used in you

332
00:14:36,290 --> 00:14:38,660
know imagery for for object segmentation

333
00:14:38,660 --> 00:14:40,940
we can do the same thing in spectrum so

334
00:14:40,940 --> 00:14:43,430
we can now say well once we've trained

335
00:14:43,430 --> 00:14:45,530
these features we can take an arbitrary

336
00:14:45,530 --> 00:14:48,170
spectrograms and really identify what's

337
00:14:48,170 --> 00:14:52,750
going on where and start labeling things

338
00:14:53,020 --> 00:14:55,970
all right so then kind of the I think

339
00:14:55,970 --> 00:14:59,390
the last kind of little application

340
00:14:59,390 --> 00:15:01,400
thing here and I'm really this is the

341
00:15:01,400 --> 00:15:02,900
thing if you look at machine learning

342
00:15:02,900 --> 00:15:04,490
and coms this is what I'm I think most

343
00:15:04,490 --> 00:15:06,530
excited about right now and the whole

344
00:15:06,530 --> 00:15:11,450
idea here is if you think about a comm

345
00:15:11,450 --> 00:15:13,940
system at its most basic form it's

346
00:15:13,940 --> 00:15:17,600
really like you have some bits somewhere

347
00:15:17,600 --> 00:15:19,250
and at some of the location you just

348
00:15:19,250 --> 00:15:20,750
want a good estimate for those bits

349
00:15:20,750 --> 00:15:23,180
right that's kind of all it is you're

350
00:15:23,180 --> 00:15:25,070
just taking a bit bits in and trying to

351
00:15:25,070 --> 00:15:27,680
reconstruct them somewhere else and so

352
00:15:27,680 --> 00:15:28,940
that's pretty much what an auto encoder

353
00:15:28,940 --> 00:15:31,640
does in machine learning is it takes

354
00:15:31,640 --> 00:15:33,560
some input it goes through a couple

355
00:15:33,560 --> 00:15:35,060
different representations of it and it

356
00:15:35,060 --> 00:15:38,240
tries to reconstruct the input and so if

357
00:15:38,240 --> 00:15:40,970
we if we cast the basic communications

358
00:15:40,970 --> 00:15:44,270
problem as an auto encoder we have this

359
00:15:44,270 --> 00:15:47,330
case where we go through some input we

360
00:15:47,330 --> 00:15:49,580
form some new encoding of those input

361
00:15:49,580 --> 00:15:52,550
bits we go through some channel

362
00:15:52,550 --> 00:15:53,990
impairment which we don't control this

363
00:15:53,990 --> 00:15:55,220
is kind of defined by a wireless

364
00:15:55,220 --> 00:15:57,470
environment and then we go through this

365
00:15:57,470 --> 00:15:59,900
decoder representation that somehow it

366
00:15:59,900 --> 00:16:02,150
transforms the samples we receive back

367
00:16:02,150 --> 00:16:04,340
into bits and really that's the whole

368
00:16:04,340 --> 00:16:07,550
process we want to optimize so we can

369
00:16:07,550 --> 00:16:10,460
treat this as just a an optimization of

370
00:16:10,460 --> 00:16:13,520
a reconstruction process where we have

371
00:16:13,520 --> 00:16:15,200
this layer in the middle that introduces

372
00:16:15,200 --> 00:16:18,260
this randomness that that mirrors what a

373
00:16:18,260 --> 00:16:22,340
wireless Channel does and so what's

374
00:16:22,340 --> 00:16:23,750
really cool here is we can let this

375
00:16:23,750 --> 00:16:25,490
thing learn now some completely

376
00:16:25,490 --> 00:16:28,370
arbitrary physical layer we know we

377
00:16:28,370 --> 00:16:29,690
don't need PSK or any of these things

378
00:16:29,690 --> 00:16:31,070
anymore

379
00:16:31,070 --> 00:16:32,680
and we can actually start getting

380
00:16:32,680 --> 00:16:36,470
reasonably good capacities out of these

381
00:16:36,470 --> 00:16:39,860
and coatings so we can now you know just

382
00:16:39,860 --> 00:16:43,190
learn a radio for a specific radio

383
00:16:43,190 --> 00:16:46,280
environment you know without any expert

384
00:16:46,280 --> 00:16:48,950
knowledge of the past 70 years of signal

385
00:16:48,950 --> 00:16:54,680
processing which is pretty crazy so if

386
00:16:54,680 --> 00:16:56,980
we do that we can start plotting

387
00:16:56,980 --> 00:17:00,410
basically BER curves and these are these

388
00:17:00,410 --> 00:17:02,240
are kind of some old ones that aren't as

389
00:17:02,240 --> 00:17:05,660
clean but you can see that you know in

390
00:17:05,660 --> 00:17:09,530
some cases we can we can outperform the

391
00:17:09,530 --> 00:17:11,420
the performance you would get on a

392
00:17:11,420 --> 00:17:15,220
modulation without any error correction

393
00:17:15,220 --> 00:17:17,949
which is really cool because it means

394
00:17:17,949 --> 00:17:20,240
the encoders and decoders that we're

395
00:17:20,240 --> 00:17:22,849
learning can actually learn a little bit

396
00:17:22,849 --> 00:17:25,430
of error correction as well so you're

397
00:17:25,430 --> 00:17:27,109
now you're basically learning something

398
00:17:27,109 --> 00:17:28,670
that does better than just a normal

399
00:17:28,670 --> 00:17:30,080
model a ssin scheme

400
00:17:30,080 --> 00:17:36,559
so there's a leader so this is just an

401
00:17:36,559 --> 00:17:38,809
example of a couple different runs and

402
00:17:38,809 --> 00:17:41,559
what you know what the resulting learned

403
00:17:41,559 --> 00:17:46,879
bases look like in this case yeah and

404
00:17:46,879 --> 00:17:48,350
there's many many things that affect

405
00:17:48,350 --> 00:17:48,799
this

406
00:17:48,799 --> 00:17:50,869
so there's right now still a million

407
00:17:50,869 --> 00:17:54,740
kind of tuning dimensions that that you

408
00:17:54,740 --> 00:17:57,019
you can look at while training these

409
00:17:57,019 --> 00:17:59,149
things and and optimizing all over all

410
00:17:59,149 --> 00:18:01,039
of those it's still kind of a big

411
00:18:01,039 --> 00:18:03,139
challenge right now and right now the

412
00:18:03,139 --> 00:18:04,639
other big challenges are this you know

413
00:18:04,639 --> 00:18:07,429
this works for very small code words but

414
00:18:07,429 --> 00:18:09,259
if you try to scale this to like you

415
00:18:09,259 --> 00:18:11,119
know 1024 bits or something that else

416
00:18:11,119 --> 00:18:14,539
you might use in an LDPC code it's much

417
00:18:14,539 --> 00:18:16,039
harder to scale it so that's one of the

418
00:18:16,039 --> 00:18:17,240
things we're looking at now is how do

419
00:18:17,240 --> 00:18:21,409
you scale this up to like more real

420
00:18:21,409 --> 00:18:26,629
situations and over-the-air alright and

421
00:18:26,629 --> 00:18:30,230
then lastly so when we learned that

422
00:18:30,230 --> 00:18:33,799
encoder and decoder the decoder has to

423
00:18:33,799 --> 00:18:36,110
learn how to translate from some channel

424
00:18:36,110 --> 00:18:40,070
representation to the bits right now if

425
00:18:40,070 --> 00:18:45,440
you do that just naively we get some

426
00:18:45,440 --> 00:18:47,210
process that can it takes a long time to

427
00:18:47,210 --> 00:18:49,490
converge right because it's having to

428
00:18:49,490 --> 00:18:51,490
learn how to estimate the channel

429
00:18:51,490 --> 00:18:54,619
somehow apply those Corrections and then

430
00:18:54,619 --> 00:18:58,759
somehow go to a back to a bit

431
00:18:58,759 --> 00:19:01,639
information encoding so there's this

432
00:19:01,639 --> 00:19:05,330
notion in from vision of attention

433
00:19:05,330 --> 00:19:07,369
models and the whole idea of these

434
00:19:07,369 --> 00:19:09,679
attention models is that instead of

435
00:19:09,679 --> 00:19:13,190
learning some arbitrary transform like

436
00:19:13,190 --> 00:19:16,309
how to equalize you can simply break the

437
00:19:16,309 --> 00:19:18,649
network into learned parameter

438
00:19:18,649 --> 00:19:21,919
estimation kind of an expert transform

439
00:19:21,919 --> 00:19:25,249
like equalization and then our learned

440
00:19:25,249 --> 00:19:29,749
you know decoder and so in doing this

441
00:19:29,749 --> 00:19:32,360
you basically tell the system well okay

442
00:19:32,360 --> 00:19:34,009
this is this is how you would apply

443
00:19:34,009 --> 00:19:35,960
equalizer tap so this is how you'd apply

444
00:19:35,960 --> 00:19:38,240
frequency correction if you knew how far

445
00:19:38,240 --> 00:19:40,999
off it was it turns out if you do that

446
00:19:40,999 --> 00:19:44,030
this converges like much much faster

447
00:19:44,030 --> 00:19:47,600
orders of magnitude faster here and we

448
00:19:47,600 --> 00:19:48,830
get you know significantly better

449
00:19:48,830 --> 00:19:51,020
performance as well in the auto encoder

450
00:19:51,020 --> 00:19:54,679
case so it's like we're kind of helping

451
00:19:54,679 --> 00:19:56,900
the system along to to learn the basic

452
00:19:56,900 --> 00:19:59,630
physics of the problem to reduce the

453
00:19:59,630 --> 00:20:01,280
complexity that the machine learning has

454
00:20:01,280 --> 00:20:03,940
to fit and so this is this is kind of

455
00:20:03,940 --> 00:20:07,429
exciting that this works and so on top

456
00:20:07,429 --> 00:20:09,049
of that there's this whole problem of

457
00:20:09,049 --> 00:20:11,000
like you know we have a whole discipline

458
00:20:11,000 --> 00:20:13,760
of estimation and detection right

459
00:20:13,760 --> 00:20:17,960
and it's interesting to just look at you

460
00:20:17,960 --> 00:20:20,090
know can we treat these estimation

461
00:20:20,090 --> 00:20:21,890
problems as just machine learning

462
00:20:21,890 --> 00:20:24,559
regression problems and so we started

463
00:20:24,559 --> 00:20:26,539
looking at that and if you look at this

464
00:20:26,539 --> 00:20:29,600
is comparing the the map estimator for

465
00:20:29,600 --> 00:20:32,330
center frequency estimation with

466
00:20:32,330 --> 00:20:34,880
basically just a neural net trained to

467
00:20:34,880 --> 00:20:38,000
do regression to generate estimates for

468
00:20:38,000 --> 00:20:40,850
the same thing and if we do that and

469
00:20:40,850 --> 00:20:42,650
this is under a Rayleigh fading channel

470
00:20:42,650 --> 00:20:45,590
so if we do that we get a slightly

471
00:20:45,590 --> 00:20:47,799
tighter distribution from the regression

472
00:20:47,799 --> 00:20:51,380
process and so this speaks to like why

473
00:20:51,380 --> 00:20:52,970
do you want to do this you know

474
00:20:52,970 --> 00:20:55,130
we have we have a lot of great analytic

475
00:20:55,130 --> 00:20:57,380
models for these but one of the problems

476
00:20:57,380 --> 00:20:59,210
with them is there many of them are

477
00:20:59,210 --> 00:21:01,130
derived under much more simplistic

478
00:21:01,130 --> 00:21:04,549
channel assumptions and so if we can do

479
00:21:04,549 --> 00:21:07,429
this with real data and regression then

480
00:21:07,429 --> 00:21:09,559
we can start to model you know all kinds

481
00:21:09,559 --> 00:21:11,390
of nonlinear effects and all kinds of

482
00:21:11,390 --> 00:21:14,059
much more complex channel models than we

483
00:21:14,059 --> 00:21:17,090
can in our analytic forums and so it's

484
00:21:17,090 --> 00:21:18,530
really kind of exciting about we know

485
00:21:18,530 --> 00:21:21,200
where our estimation processes can go in

486
00:21:21,200 --> 00:21:26,470
the future with this approach right so

487
00:21:26,470 --> 00:21:29,539
ml is affecting a lot of fields in

488
00:21:29,539 --> 00:21:32,210
computer very quickly right now which is

489
00:21:32,210 --> 00:21:36,049
pretty exciting and the area of applying

490
00:21:36,049 --> 00:21:38,450
this to the RF radio domain is super

491
00:21:38,450 --> 00:21:40,400
young there's really not much work out

492
00:21:40,400 --> 00:21:43,309
there yet at all and so I think if

493
00:21:43,309 --> 00:21:44,720
you're a student right now looking for

494
00:21:44,720 --> 00:21:46,909
kind of topics to work on this is like

495
00:21:46,909 --> 00:21:50,419
you know super ripe and I wouldn't point

496
00:21:50,419 --> 00:21:52,760
you anywhere else but obviously I'm a

497
00:21:52,760 --> 00:21:54,230
little biased

498
00:21:54,230 --> 00:21:59,570
so there's also I have a journal article

499
00:21:59,570 --> 00:22:02,500
that'll be appearing on archive Monday

500
00:22:02,500 --> 00:22:05,870
and it goes into this auto-encoder

501
00:22:05,870 --> 00:22:10,040
and the mod req process much more

502
00:22:10,040 --> 00:22:12,620
rigorously so if you're interested in a

503
00:22:12,620 --> 00:22:14,570
more thorough explanation definitely go

504
00:22:14,570 --> 00:22:16,549
and check that out in one day and

505
00:22:16,549 --> 00:22:19,520
there'll be a link on Radio ml org so

506
00:22:19,520 --> 00:22:21,770
I'm trying to start kind of turning

507
00:22:21,770 --> 00:22:23,330
radio a male organ to somewhat of a

508
00:22:23,330 --> 00:22:25,040
community for people interested in this

509
00:22:25,040 --> 00:22:27,830
so you know if you would like to

510
00:22:27,830 --> 00:22:30,770
contribute pools or datasets or articles

511
00:22:30,770 --> 00:22:33,470
or examples or anything - right - radio

512
00:22:33,470 --> 00:22:35,299
ml and start contributing like please

513
00:22:35,299 --> 00:22:36,740
let me know because I would love to have

514
00:22:36,740 --> 00:22:42,309
your work there and yeah I think that's

515
00:22:42,309 --> 00:22:45,490
about it

516
00:22:45,730 --> 00:22:55,130
[Applause]

517
00:23:17,730 --> 00:23:20,649
yes so there's not much out there at all

518
00:23:20,649 --> 00:23:22,899
for like radio signal processing yet I

519
00:23:22,899 --> 00:23:25,539
think almost all the work has been done

520
00:23:25,539 --> 00:23:27,580
in computer vision and so there's

521
00:23:27,580 --> 00:23:29,620
there's a lot of tools to do kind of

522
00:23:29,620 --> 00:23:31,720
computer vision operations but very

523
00:23:31,720 --> 00:23:33,220
little that has been applied to radio

524
00:23:33,220 --> 00:23:35,889
yet and I think that's kind of one of

525
00:23:35,889 --> 00:23:37,840
the niceties is that the computer vision

526
00:23:37,840 --> 00:23:40,779
guys are you know paving a lot of the

527
00:23:40,779 --> 00:23:44,259
roads for you know figuring out the the

528
00:23:44,259 --> 00:23:45,970
compilers and all the back end and

529
00:23:45,970 --> 00:23:48,580
support issues so we can use a lot of

530
00:23:48,580 --> 00:23:51,429
the same infrastructure in radio without

531
00:23:51,429 --> 00:23:55,779
having to reinvent it I think Google

532
00:23:55,779 --> 00:23:58,570
said they moved like they're machine

533
00:23:58,570 --> 00:24:01,059
learning for all of their services over

534
00:24:01,059 --> 00:24:04,029
two tensorflow and they look at 30 or 40

535
00:24:04,029 --> 00:24:06,399
person team just supporting the

536
00:24:06,399 --> 00:24:09,639
tensorflow product line now so there's a

537
00:24:09,639 --> 00:24:12,850
lot of you know stuff we can just take

538
00:24:12,850 --> 00:24:16,620
for granted at this point

539
00:24:27,860 --> 00:24:33,840
right yeah so I haven't there's not been

540
00:24:33,840 --> 00:24:36,240
a whole lot done on latency yet but on

541
00:24:36,240 --> 00:24:38,790
computational performance for the

542
00:24:38,790 --> 00:24:43,140
moderate example I did a a opt counting

543
00:24:43,140 --> 00:24:46,740
comparison to the the kind of

544
00:24:46,740 --> 00:24:48,150
state-of-the-art kind of classic

545
00:24:48,150 --> 00:24:53,210
algorithms and we so the initial network

546
00:24:53,210 --> 00:24:56,370
was something like nine times more

547
00:24:56,370 --> 00:24:59,610
operations than the the classic method

548
00:24:59,610 --> 00:25:02,850
right so but it turns out then when we

549
00:25:02,850 --> 00:25:04,559
go in and we start doing certain things

550
00:25:04,559 --> 00:25:07,590
within the network like we use one by

551
00:25:07,590 --> 00:25:09,000
one

552
00:25:09,000 --> 00:25:11,820
comm filtering on the output of several

553
00:25:11,820 --> 00:25:14,250
complex which is a trick and and one by

554
00:25:14,250 --> 00:25:17,280
one filtering sounds very silly and I

555
00:25:17,280 --> 00:25:19,230
think to most electrical engineers

556
00:25:19,230 --> 00:25:20,809
because you know why would you do that

557
00:25:20,809 --> 00:25:23,640
but but the point of a one by one filter

558
00:25:23,640 --> 00:25:27,150
is actually that it's it's combining in

559
00:25:27,150 --> 00:25:30,510
the number of output channels so you

560
00:25:30,510 --> 00:25:33,240
have actually enchanting image coming in

561
00:25:33,240 --> 00:25:36,090
and M channels of 2d image going out so

562
00:25:36,090 --> 00:25:37,590
you can use one by one filtering to

563
00:25:37,590 --> 00:25:39,620
reduce like that number of channels down

564
00:25:39,620 --> 00:25:42,090
and so by playing tricks like that we

565
00:25:42,090 --> 00:25:44,030
were able to drive the complexity down

566
00:25:44,030 --> 00:25:49,110
like maybe 50x or so and so we're now a

567
00:25:49,110 --> 00:25:52,440
factor of about four lower in up counts

568
00:25:52,440 --> 00:25:56,850
than the the kind of classic approach in

569
00:25:56,850 --> 00:26:00,950
that application so I think like you

570
00:26:00,950 --> 00:26:03,929
know there's there's a lot of things

571
00:26:03,929 --> 00:26:05,970
that make it attractive right so all

572
00:26:05,970 --> 00:26:09,720
these multi-core architectures you know

573
00:26:09,720 --> 00:26:12,330
this is a very parallel thing right you

574
00:26:12,330 --> 00:26:14,910
can divide up the tensors in width and

575
00:26:14,910 --> 00:26:19,500
in depth on two different cores and one

576
00:26:19,500 --> 00:26:20,880
of the other cool things is there was a

577
00:26:20,880 --> 00:26:23,730
paper looking at how much representation

578
00:26:23,730 --> 00:26:25,140
precision do you need for these networks

579
00:26:25,140 --> 00:26:27,690
to work and because right now this is

580
00:26:27,690 --> 00:26:29,160
all done in single point single

581
00:26:29,160 --> 00:26:31,320
precision floating point but they showed

582
00:26:31,320 --> 00:26:32,970
that you really only need four to eight

583
00:26:32,970 --> 00:26:35,040
bits of precision throughout the whole

584
00:26:35,040 --> 00:26:36,240
network

585
00:26:36,240 --> 00:26:39,860
for this to work equally well and so

586
00:26:39,860 --> 00:26:43,289
there's another potential you know huge

587
00:26:43,289 --> 00:26:50,549
savings in in complexity so yeah I think

588
00:26:50,549 --> 00:26:53,549
ultimately for comms and for sensing

589
00:26:53,549 --> 00:26:56,880
this is potentially drastically lower

590
00:26:56,880 --> 00:26:59,929
complexity than our current approaches

591
00:26:59,929 --> 00:27:13,830
yep yeah so I can't do it justice here

592
00:27:13,830 --> 00:27:15,779
if you'll read the paper on Monday so

593
00:27:15,779 --> 00:27:17,940
the question was about coding and

594
00:27:17,940 --> 00:27:19,230
whether we compared to Shannon and so

595
00:27:19,230 --> 00:27:23,570
forth and yes so the base lines here are

596
00:27:23,570 --> 00:27:26,490
you know I didn't want to go and put

597
00:27:26,490 --> 00:27:27,600
everything that's gonna be released

598
00:27:27,600 --> 00:27:29,820
Monday yet but if you go through the

599
00:27:29,820 --> 00:27:32,370
paper it's going out Monday we have some

600
00:27:32,370 --> 00:27:34,110
very very good base lines where we're

601
00:27:34,110 --> 00:27:38,460
looking at comparisons to you know PS KS

602
00:27:38,460 --> 00:27:41,520
and DPS case with with handing code and

603
00:27:41,520 --> 00:27:44,190
you know basically right up against

604
00:27:44,190 --> 00:27:47,460
capacity and so we're much more robust

605
00:27:47,460 --> 00:27:48,630
there and showing you know the capacity

606
00:27:48,630 --> 00:27:52,049
that you can achieve with this and you

607
00:27:52,049 --> 00:27:54,990
can come very very close to you know the

608
00:27:54,990 --> 00:27:59,029
channel limit switch over okay

609
00:28:02,690 --> 00:28:08,539
[Applause]

