1
00:00:00,030 --> 00:00:02,960
good

2
00:00:04,500 --> 00:00:12,500
Hey on behalf of the overt KVM and son

3
00:00:12,500 --> 00:00:15,299
projects I am pleased to welcome many of

4
00:00:15,299 --> 00:00:17,760
you to the virtualization and

5
00:00:17,760 --> 00:00:20,359
infrastructure-as-a-service dead room

6
00:00:20,359 --> 00:00:23,060
thank you for coming this afternoon

7
00:00:23,060 --> 00:00:25,980
quick housekeeping reminder if you do

8
00:00:25,980 --> 00:00:28,109
have to leave before the end of the

9
00:00:28,109 --> 00:00:30,720
session we invite you to go to the back

10
00:00:30,720 --> 00:00:33,570
exit so you won't disturb the speaker

11
00:00:33,570 --> 00:00:38,220
area if at all possible I do I've been

12
00:00:38,220 --> 00:00:41,550
asked by the speaker to ask you to hold

13
00:00:41,550 --> 00:00:45,180
questions until the end he has a lot of

14
00:00:45,180 --> 00:00:48,240
material to get through and hopefully

15
00:00:48,240 --> 00:00:49,650
there'll be time for questions at the

16
00:00:49,650 --> 00:00:51,450
end if not we'll figure something else

17
00:00:51,450 --> 00:00:54,720
out so with that in mind and without

18
00:00:54,720 --> 00:00:56,840
further ado I'm pleased to welcome

19
00:00:56,840 --> 00:01:00,780
Andrea Arkin celli from red hat to our

20
00:01:00,780 --> 00:01:03,380
deaf room today

21
00:01:08,020 --> 00:01:12,280
it's a pleasure to be here so today we

22
00:01:12,280 --> 00:01:16,810
are going to talk about the evolution of

23
00:01:16,810 --> 00:01:20,230
the Linux virtual memory subsystem since

24
00:01:20,230 --> 00:01:22,800
the last about 20 years since I started

25
00:01:22,800 --> 00:01:31,470
about 1997 so then we see some of the

26
00:01:31,470 --> 00:01:35,740
decision behind the KBM can build

27
00:01:35,740 --> 00:01:38,710
machine design and how actually it

28
00:01:38,710 --> 00:01:40,869
integrates with the beautiful memory

29
00:01:40,869 --> 00:01:44,410
subsystem of Linux and so we will also

30
00:01:44,410 --> 00:01:46,479
see some of the beautiful memory latest

31
00:01:46,479 --> 00:01:50,560
innovations like automatically my

32
00:01:50,560 --> 00:01:53,619
balancing PHP developments and recently

33
00:01:53,619 --> 00:01:56,200
user portability which are kind of Linux

34
00:01:56,200 --> 00:01:57,790
kernel feature which can be used

35
00:01:57,790 --> 00:01:59,979
regardless of a localization but

36
00:01:59,979 --> 00:02:01,750
especially say help when you are

37
00:02:01,750 --> 00:02:03,550
actually using Linux as an eye provider

38
00:02:03,550 --> 00:02:08,038
with KDM so first of all what is

39
00:02:08,038 --> 00:02:10,389
beautiful memory virtual memory are

40
00:02:10,389 --> 00:02:13,480
pages which effectively costs nothing so

41
00:02:13,480 --> 00:02:16,450
that's where your problem is running and

42
00:02:16,450 --> 00:02:18,760
it's practically unlimited on 64-bit

43
00:02:18,760 --> 00:02:21,580
architectures and the RS you see the red

44
00:02:21,580 --> 00:02:24,430
arrows you see in the middle since I

45
00:02:24,430 --> 00:02:26,350
have the page tables so when you locate

46
00:02:26,350 --> 00:02:29,049
memory you locate memory which is

47
00:02:29,049 --> 00:02:33,280
virtual and then Linux will decide where

48
00:02:33,280 --> 00:02:34,989
to put this memory and you don't

49
00:02:34,989 --> 00:02:37,180
actually know so the memory of the

50
00:02:37,180 --> 00:02:40,000
bottom cell is physical page Cisco small

51
00:02:40,000 --> 00:02:42,250
these are actually the demes we put on

52
00:02:42,250 --> 00:02:46,209
your computer on the servers and these

53
00:02:46,209 --> 00:02:48,670
are also actually implemented as radix 3

54
00:02:48,670 --> 00:02:50,860
which are actually the page tables this

55
00:02:50,860 --> 00:02:53,739
is showing only two pointers in reality

56
00:02:53,739 --> 00:02:56,380
in the x86 architecture x86 64

57
00:02:56,380 --> 00:02:58,750
there are actually 512 pointers but they

58
00:02:58,750 --> 00:03:01,540
cannot show it or it will you know get

59
00:03:01,540 --> 00:03:04,930
big in the chart and know the page table

60
00:03:04,930 --> 00:03:08,590
are 4k in size 4 kilobytes and you can

61
00:03:08,590 --> 00:03:11,350
see the total amount of memory used in

62
00:03:11,350 --> 00:03:14,500
page tables in your system with with

63
00:03:14,500 --> 00:03:17,290
grab page tables in slash program info

64
00:03:17,290 --> 00:03:21,090
and this page table are you know

65
00:03:21,090 --> 00:03:23,640
a little costly because you need to

66
00:03:23,640 --> 00:03:25,379
allocate them so they are not entirely

67
00:03:25,379 --> 00:03:30,060
free and on vixx's this is architecture

68
00:03:30,060 --> 00:03:32,129
because of the page table layout which

69
00:03:32,129 --> 00:03:34,349
is actually imported by the hardware so

70
00:03:34,349 --> 00:03:37,650
this is a structure that the CPU will

71
00:03:37,650 --> 00:03:40,379
work in hardware so there's no software

72
00:03:40,379 --> 00:03:43,440
which actually read C's it's harder

73
00:03:43,440 --> 00:03:45,870
which actually reads this he looks

74
00:03:45,870 --> 00:03:48,209
really - but it's really for it's

75
00:03:48,209 --> 00:03:50,340
mandated by the hardware this format and

76
00:03:50,340 --> 00:03:52,410
this format is also forcing how much

77
00:03:52,410 --> 00:03:56,099
built on memory you can add in the x86

78
00:03:56,099 --> 00:03:59,370
64 architecture if you do the math at

79
00:03:59,370 --> 00:04:01,890
the bottom is the result is actually 48

80
00:04:01,890 --> 00:04:06,680
bits and it's based on C's format and

81
00:04:06,680 --> 00:04:11,819
through our 747 bits for the UN and 47

82
00:04:11,819 --> 00:04:14,340
bits of negative other space for the

83
00:04:14,340 --> 00:04:16,829
kernel the kernel takes all the negative

84
00:04:16,829 --> 00:04:20,459
other space and the to understand the

85
00:04:20,459 --> 00:04:22,108
earth or memory subsystem and how it

86
00:04:22,108 --> 00:04:23,639
evolved it's important understand

87
00:04:23,639 --> 00:04:25,770
effectively what we call the fabric of

88
00:04:25,770 --> 00:04:28,770
the virtual memory and fabric are all

89
00:04:28,770 --> 00:04:31,940
the collection of data structures which

90
00:04:31,940 --> 00:04:35,639
are used by all the cattle algorithms

91
00:04:35,639 --> 00:04:37,860
which work on the memory management and

92
00:04:37,860 --> 00:04:40,470
since abstractions are like task

93
00:04:40,470 --> 00:04:43,080
processes built memory areas called

94
00:04:43,080 --> 00:04:46,080
those VMA which stands for data memory

95
00:04:46,080 --> 00:04:49,530
are of course and a map gypsy and maluca

96
00:04:49,530 --> 00:04:52,440
and these things are all based on the

97
00:04:52,440 --> 00:04:56,250
fabric and the public is also the most

98
00:04:56,250 --> 00:04:58,289
black and white part of the other memory

99
00:04:58,289 --> 00:05:00,210
so it's easier to show because the

100
00:05:00,210 --> 00:05:02,160
algorithm which actually computes on the

101
00:05:02,160 --> 00:05:04,889
data structures often see our wrists 6

102
00:05:04,889 --> 00:05:08,150
and a listicle difficult to explain and

103
00:05:08,150 --> 00:05:10,830
they also need to solve problems which

104
00:05:10,830 --> 00:05:12,270
don't have the perfect guaranteed

105
00:05:12,270 --> 00:05:15,389
solution so for example what's the

106
00:05:15,389 --> 00:05:18,090
perfect time to swap whether were the

107
00:05:18,090 --> 00:05:21,060
best page the best candidate page to

108
00:05:21,060 --> 00:05:23,490
reclaim all these problems don't have a

109
00:05:23,490 --> 00:05:25,800
part of a solution while the data

110
00:05:25,800 --> 00:05:27,510
structure actually black and white so

111
00:05:27,510 --> 00:05:31,640
it's much easier to explain and

112
00:05:32,270 --> 00:05:36,270
also Linux we make heavy use of other

113
00:05:36,270 --> 00:05:38,159
committee and the overcommit is enabled

114
00:05:38,159 --> 00:05:41,580
by default it's not excessively over

115
00:05:41,580 --> 00:05:43,469
comments so if if you're booting a Linux

116
00:05:43,469 --> 00:05:45,360
server and you try to allocate one

117
00:05:45,360 --> 00:05:47,009
terabyte and you have one gigabyte it

118
00:05:47,009 --> 00:05:51,000
will turn no sort of memory but you can

119
00:05:51,000 --> 00:05:52,500
actually make it return even one

120
00:05:52,500 --> 00:05:55,530
terabyte but just setting echo 1 in over

121
00:05:55,530 --> 00:05:57,620
commit memory in this file at the bottom

122
00:05:57,620 --> 00:06:00,780
and if you do that you can actually

123
00:06:00,780 --> 00:06:02,759
locate as much real to memory 1 just

124
00:06:02,759 --> 00:06:04,770
like I said before is free and the r2

125
00:06:04,770 --> 00:06:08,069
Leroy does it so it's not so insane to

126
00:06:08,069 --> 00:06:08,580
do it

127
00:06:08,580 --> 00:06:11,759
it's resource echo 2 if you do echo 2

128
00:06:11,759 --> 00:06:14,939
you will actually enable strict comment

129
00:06:14,939 --> 00:06:17,159
checking which means you're not doing

130
00:06:17,159 --> 00:06:19,139
over commit anymore which means you need

131
00:06:19,139 --> 00:06:21,180
to add a lot of swap if you want to

132
00:06:21,180 --> 00:06:22,710
locate more built or my motif anywhere

133
00:06:22,710 --> 00:06:26,129
in a row so generally over commit saves

134
00:06:26,129 --> 00:06:28,259
huge amount of memory so it's very good

135
00:06:28,259 --> 00:06:31,560
technique so the best and the best way

136
00:06:31,560 --> 00:06:34,319
to start to explain the fabric is to

137
00:06:34,319 --> 00:06:36,360
understand the page structure so every

138
00:06:36,360 --> 00:06:38,520
page in the system so imagine your

139
00:06:38,520 --> 00:06:41,819
memory divided in small pieces of 4

140
00:06:41,819 --> 00:06:46,229
kilobytes each and every one of these

141
00:06:46,229 --> 00:06:49,409
pieces need a structure to describe it

142
00:06:49,409 --> 00:06:52,379
which is the page structure so this will

143
00:06:52,379 --> 00:06:54,659
be the size of the full 4 kilobyte

144
00:06:54,659 --> 00:06:59,099
memory and a few bites of C's memory I

145
00:06:59,099 --> 00:07:01,680
use it as a struct page itself which is

146
00:07:01,680 --> 00:07:05,849
64 bytes so every a 4k there are 64

147
00:07:05,849 --> 00:07:08,909
bytes use it just describe the memory

148
00:07:08,909 --> 00:07:11,219
itself so if you do the math they divide

149
00:07:11,219 --> 00:07:15,830
64 by 4000 it means x86 64 architecture

150
00:07:15,830 --> 00:07:21,150
1.56 of the memory is wasted it's not

151
00:07:21,150 --> 00:07:23,789
really waste is used for managing the

152
00:07:23,789 --> 00:07:27,210
memory cell and this is allocated as an

153
00:07:27,210 --> 00:07:29,810
array called memory map array mamuh

154
00:07:29,810 --> 00:07:32,909
recently is also you know zone point of

155
00:07:32,909 --> 00:07:35,849
a map it's a little more about now but

156
00:07:35,849 --> 00:07:38,610
the ceilin array where you have a page

157
00:07:38,610 --> 00:07:42,300
structure for each actor page

158
00:07:42,300 --> 00:07:48,260
and so we are always strict in terms of

159
00:07:48,260 --> 00:07:53,070
flags and basically sees page structure

160
00:07:53,070 --> 00:07:55,860
is encoded very efficiently so most

161
00:07:55,860 --> 00:07:58,800
compressed because if we were to add

162
00:07:58,800 --> 00:08:03,060
just eight bytes to this structure in

163
00:08:03,060 --> 00:08:04,620
the caramel it's a canvas track you can

164
00:08:04,620 --> 00:08:06,600
check the connoisseurs it's a structure

165
00:08:06,600 --> 00:08:08,610
like everyone else but this extremely

166
00:08:08,610 --> 00:08:10,620
important not to grow it because adding

167
00:08:10,620 --> 00:08:13,560
eight bytes globally in the world with

168
00:08:13,560 --> 00:08:15,900
billion of Linux devices would waste

169
00:08:15,900 --> 00:08:18,480
petabytes lozanov petabytes of memory

170
00:08:18,480 --> 00:08:20,850
globally so it's extremely important not

171
00:08:20,850 --> 00:08:22,500
to grow the structure and we do what

172
00:08:22,500 --> 00:08:25,800
kind of tricks not to do that we

173
00:08:25,800 --> 00:08:27,600
constantly running out of flags legacy

174
00:08:27,600 --> 00:08:29,790
so the other important structure are

175
00:08:29,790 --> 00:08:35,070
them and VMAs mm is the describing the

176
00:08:35,070 --> 00:08:38,490
process is effectively the memory of the

177
00:08:38,490 --> 00:08:42,210
process so each process are single mm

178
00:08:42,210 --> 00:08:44,790
and if you have threads they share the

179
00:08:44,790 --> 00:08:50,610
same mm EMR structure instead is created

180
00:08:50,610 --> 00:08:53,640
and tear down by Cisco's like an app mmm

181
00:08:53,640 --> 00:08:55,380
so effectively when your cake memory

182
00:08:55,380 --> 00:08:58,260
beat with Emma log beat with new beat

183
00:08:58,260 --> 00:09:02,820
with and you know Python a new object or

184
00:09:02,820 --> 00:09:06,210
whatever generally AVMA is created or

185
00:09:06,210 --> 00:09:09,540
enlarged so since describe effectively

186
00:09:09,540 --> 00:09:11,690
the layout of the memory in the process

187
00:09:11,690 --> 00:09:18,660
and the of course VMA is linked into the

188
00:09:18,660 --> 00:09:21,270
map so the mam is a process and vm a is

189
00:09:21,270 --> 00:09:26,300
a structure of memory in the process so

190
00:09:26,300 --> 00:09:30,630
let's try to describe our Linux was when

191
00:09:30,630 --> 00:09:33,720
I started so that was kind to the Dylan

192
00:09:33,720 --> 00:09:37,770
to the 2 so at the time we just said the

193
00:09:37,770 --> 00:09:39,390
main map array which is what I just

194
00:09:39,390 --> 00:09:42,330
described a start page for every page so

195
00:09:42,330 --> 00:09:44,610
it's not very very simple with those

196
00:09:44,610 --> 00:09:46,650
abstract pages which describe each page

197
00:09:46,650 --> 00:09:51,180
and when you want to free memory like

198
00:09:51,180 --> 00:09:53,310
when you are the cache we already add of

199
00:09:53,310 --> 00:09:54,370
course

200
00:09:54,370 --> 00:09:57,230
very deficient we already at the page

201
00:09:57,230 --> 00:09:59,900
cache in fact we had preached cashwell

202
00:09:59,900 --> 00:10:03,110
before or direct but if you wanted to

203
00:10:03,110 --> 00:10:05,300
free a page you will need to scan all

204
00:10:05,300 --> 00:10:07,790
the pages in the memory including

205
00:10:07,790 --> 00:10:12,740
careful memory anything and check every

206
00:10:12,740 --> 00:10:15,050
one of these pages until you would find

207
00:10:15,050 --> 00:10:17,660
one which looked like potential cash

208
00:10:17,660 --> 00:10:19,670
candidate which was not happened and you

209
00:10:19,670 --> 00:10:21,590
could actually see well nobody is using

210
00:10:21,590 --> 00:10:28,430
this page its cash let's free season was

211
00:10:28,430 --> 00:10:32,750
called the clock algorithm for pager

212
00:10:32,750 --> 00:10:38,240
King and that was also another issue the

213
00:10:38,240 --> 00:10:40,970
cache is not always a mapping so when

214
00:10:40,970 --> 00:10:44,030
you read a file you just generate cash

215
00:10:44,030 --> 00:10:46,190
you don't map the cash into the memory

216
00:10:46,190 --> 00:10:48,620
of the process but sometime you just do

217
00:10:48,620 --> 00:10:51,320
a map and for example rules executable

218
00:10:51,320 --> 00:10:54,740
in Linux some cache which gets mapping

219
00:10:54,740 --> 00:10:58,460
and this that's the way the binary you

220
00:10:58,460 --> 00:11:00,320
other actually lowered executable into

221
00:11:00,320 --> 00:11:02,630
memory but databases can actually map a

222
00:11:02,630 --> 00:11:05,600
file into the memory of the process and

223
00:11:05,600 --> 00:11:09,620
use this amedeo and when the memory is

224
00:11:09,620 --> 00:11:12,320
weapon you cannot just read because

225
00:11:12,320 --> 00:11:15,650
there are page tables which might be

226
00:11:15,650 --> 00:11:19,280
pointing to the cache and so before you

227
00:11:19,280 --> 00:11:21,500
can actually free the cash you need to

228
00:11:21,500 --> 00:11:24,380
get rid of the page table so in the 2.2

229
00:11:24,380 --> 00:11:27,980
kernel again the only way to free the

230
00:11:27,980 --> 00:11:31,040
page map at page would be to scan all

231
00:11:31,040 --> 00:11:34,490
the page table in the system and there

232
00:11:34,490 --> 00:11:36,320
can be again a lot of page tables

233
00:11:36,320 --> 00:11:37,850
because as I say that the beautiful

234
00:11:37,850 --> 00:11:40,040
memory is free so there can be many

235
00:11:40,040 --> 00:11:42,080
different built well addresses which

236
00:11:42,080 --> 00:11:43,940
point the same physical page like in

237
00:11:43,940 --> 00:11:47,990
this case here so it would be very

238
00:11:47,990 --> 00:11:50,330
competition computational inefficient

239
00:11:50,330 --> 00:11:53,360
it's another fan algorithm which

240
00:11:53,360 --> 00:11:55,400
requires can effectively all the page

241
00:11:55,400 --> 00:11:57,500
table in the system before you can hope

242
00:11:57,500 --> 00:12:00,290
to free single page of cache the same

243
00:12:00,290 --> 00:12:02,600
you had another scan here to actually

244
00:12:02,600 --> 00:12:05,270
find again so again

245
00:12:05,270 --> 00:12:11,600
was not scaling so in the 203 kernel we

246
00:12:11,600 --> 00:12:13,340
introduces the last lesson to use at

247
00:12:13,340 --> 00:12:15,920
least which you know right now sound so

248
00:12:15,920 --> 00:12:19,970
simple but back time didn't exist and we

249
00:12:19,970 --> 00:12:22,250
effectively link it together all the

250
00:12:22,250 --> 00:12:24,920
potential candidates and we created also

251
00:12:24,920 --> 00:12:28,580
a LRU order for time so instead of just

252
00:12:28,580 --> 00:12:31,190
scanning blindly in a loop over and away

253
00:12:31,190 --> 00:12:33,470
now we actually can keep an order so the

254
00:12:33,470 --> 00:12:37,910
last one cache which got hit and we

255
00:12:37,910 --> 00:12:39,770
loaded it it goes in the head of the

256
00:12:39,770 --> 00:12:43,580
list and we shrink from the tail so this

257
00:12:43,580 --> 00:12:45,920
is basic last lesson to use the least

258
00:12:45,920 --> 00:12:48,680
algorithm where you have the head and

259
00:12:48,680 --> 00:12:51,560
again all these caches are being linked

260
00:12:51,560 --> 00:12:59,150
together and but then we went ahead and

261
00:12:59,150 --> 00:13:00,950
we introduced in the in the two for

262
00:13:00,950 --> 00:13:05,360
kernel an active and inactive least not

263
00:13:05,360 --> 00:13:07,580
anymore just single Ilario and the

264
00:13:07,580 --> 00:13:11,000
reason is because a single error you can

265
00:13:11,000 --> 00:13:13,190
not detect when you have a certain

266
00:13:13,190 --> 00:13:17,300
working set and so the basic example is

267
00:13:17,300 --> 00:13:18,650
when you do a backup when you do a

268
00:13:18,650 --> 00:13:21,020
backup you are dreaming at you that gets

269
00:13:21,020 --> 00:13:24,200
read only once or written Holy Ones so

270
00:13:24,200 --> 00:13:26,740
this is no cash yet so if you are to ran

271
00:13:26,740 --> 00:13:30,110
back up with singular Larry with lists

272
00:13:30,110 --> 00:13:32,420
quickly the wall guru list will get

273
00:13:32,420 --> 00:13:34,160
destroyed the mnemonic and the cache

274
00:13:34,160 --> 00:13:36,020
would only contain the data of the

275
00:13:36,020 --> 00:13:37,850
backup which is useless because the only

276
00:13:37,850 --> 00:13:44,120
exit once maybe once a day so the active

277
00:13:44,120 --> 00:13:47,600
list effectively a way to keep a working

278
00:13:47,600 --> 00:13:52,760
set alive in the cache even thought the

279
00:13:52,760 --> 00:13:54,980
backup will draw through the inactive

280
00:13:54,980 --> 00:13:58,250
list so the idea here is to keep the

281
00:13:58,250 --> 00:14:01,030
data of the backup only in the

282
00:14:01,030 --> 00:14:04,360
this and such there will be inactivation

283
00:14:04,360 --> 00:14:08,590
so when you would get cash it on the

284
00:14:08,590 --> 00:14:11,560
inactive list the page will be moved to

285
00:14:11,560 --> 00:14:15,000
the active list and threes also

286
00:14:15,000 --> 00:14:16,960
something which all the time was called

287
00:14:16,960 --> 00:14:18,820
the refill inactive which is a way to

288
00:14:18,820 --> 00:14:20,890
keep the active and inactive list

289
00:14:20,890 --> 00:14:23,500
balances but very good algorithm to keep

290
00:14:23,500 --> 00:14:25,000
these things balanced it does only be

291
00:14:25,000 --> 00:14:27,400
implemented two years ago in the

292
00:14:27,400 --> 00:14:31,290
upstream colonel through a shadow and

293
00:14:31,290 --> 00:14:34,480
releases in a later slide so at the time

294
00:14:34,480 --> 00:14:37,150
we try to keep a similar size between

295
00:14:37,150 --> 00:14:38,980
the active and inactive list again it

296
00:14:38,980 --> 00:14:41,530
was an erisa can't work it but now we

297
00:14:41,530 --> 00:14:45,820
have even better one so this is the same

298
00:14:45,820 --> 00:14:47,890
chart as before but with two different

299
00:14:47,890 --> 00:14:50,950
lists so there is the active list the

300
00:14:50,950 --> 00:14:53,530
working set and inactive list would

301
00:14:53,530 --> 00:14:57,430
contain only the ones use the pages

302
00:14:57,430 --> 00:15:00,480
which effectively are trashing the cache

303
00:15:00,480 --> 00:15:02,650
ideally we wouldn't want to catch them

304
00:15:02,650 --> 00:15:04,810
but again we need a way to detect what's

305
00:15:04,810 --> 00:15:06,940
stuff which is useless to keep in the

306
00:15:06,940 --> 00:15:08,440
cache and what's actually part of the

307
00:15:08,440 --> 00:15:12,250
working set you can see the active and

308
00:15:12,250 --> 00:15:15,660
inactive list is less problem info and

309
00:15:15,660 --> 00:15:19,120
of course now for more than just two

310
00:15:19,120 --> 00:15:23,860
series also one for anonymous and filed

311
00:15:23,860 --> 00:15:26,620
back in mapping so these days or you

312
00:15:26,620 --> 00:15:29,530
know we added more a little ism but

313
00:15:29,530 --> 00:15:32,950
Vidya works still very similar and

314
00:15:32,950 --> 00:15:36,370
detecting the work and SATA and so

315
00:15:36,370 --> 00:15:38,290
what's the next problem well if you look

316
00:15:38,290 --> 00:15:40,630
at the previous chart here we got things

317
00:15:40,630 --> 00:15:42,640
more efficient they were we didn't need

318
00:15:42,640 --> 00:15:44,500
to scan the world memory anymore to find

319
00:15:44,500 --> 00:15:47,290
candidates to reclaim but whenever a

320
00:15:47,290 --> 00:15:49,090
page table was mapping one of these

321
00:15:49,090 --> 00:15:51,940
pages we still had this block algorithm

322
00:15:51,940 --> 00:15:53,800
all over the page tables we couldn't

323
00:15:53,800 --> 00:15:54,970
just get rid of Cesaro

324
00:15:54,970 --> 00:15:57,040
gets rid of Cesaro boonie we do need to

325
00:15:57,040 --> 00:15:59,860
scan the move outer space have a single

326
00:15:59,860 --> 00:16:01,780
program running in our computer and does

327
00:16:01,780 --> 00:16:05,110
not go into scale so you have to keep in

328
00:16:05,110 --> 00:16:07,300
mind at the time the machines had very

329
00:16:07,300 --> 00:16:09,340
little memory so we had hundreds of

330
00:16:09,340 --> 00:16:12,430
megabytes of RAM and he didn't take that

331
00:16:12,430 --> 00:16:14,530
long potentially to scan the world thing

332
00:16:14,530 --> 00:16:18,130
since this would be unthinkable so the

333
00:16:18,130 --> 00:16:22,140
next step is the 2.6 kernel those 2.5

334
00:16:22,140 --> 00:16:25,570
but the final version was to the 6 was

335
00:16:25,570 --> 00:16:29,920
to introduce air map which means a

336
00:16:29,920 --> 00:16:32,830
reverse mapping so if you remember I

337
00:16:32,830 --> 00:16:36,270
showed you before the page tables which

338
00:16:36,270 --> 00:16:39,310
effectively the side were the memory of

339
00:16:39,310 --> 00:16:41,410
your programmer side into the physical

340
00:16:41,410 --> 00:16:43,390
memory so you ran your program in the

341
00:16:43,390 --> 00:16:45,640
build so memory but the page table

342
00:16:45,640 --> 00:16:49,870
decide which page goes in the physical

343
00:16:49,870 --> 00:16:52,960
memory and let's assume you want to get

344
00:16:52,960 --> 00:16:55,060
rid of C's because you thinks is the

345
00:16:55,060 --> 00:16:57,160
best candidate pages of very end of the

346
00:16:57,160 --> 00:16:59,530
inactive Ilario and you need to three it

347
00:16:59,530 --> 00:17:01,450
so to free it you need to get rid of

348
00:17:01,450 --> 00:17:04,510
these two arrows and so to get rid of

349
00:17:04,510 --> 00:17:05,950
these two ro you need to update the page

350
00:17:05,950 --> 00:17:09,160
tables and their map exactly implements

351
00:17:09,160 --> 00:17:10,829
the structure is a software structure

352
00:17:10,829 --> 00:17:13,959
that provides you a way to reach all the

353
00:17:13,959 --> 00:17:16,270
page table which can possibly map this

354
00:17:16,270 --> 00:17:20,050
page so they are all going down is the

355
00:17:20,050 --> 00:17:22,180
page tables is basically worked by the

356
00:17:22,180 --> 00:17:24,640
hardware it's another a mandated

357
00:17:24,640 --> 00:17:27,190
structure but their map is completely

358
00:17:27,190 --> 00:17:29,560
software thing is just for us so we can

359
00:17:29,560 --> 00:17:32,260
read the page table and clear it once we

360
00:17:32,260 --> 00:17:35,790
cleared it we can get rid of the page

361
00:17:35,790 --> 00:17:38,980
because after we cleared it or actually

362
00:17:38,980 --> 00:17:42,310
better I should say make it not present

363
00:17:42,310 --> 00:17:44,140
as a swap entry because then we need to

364
00:17:44,140 --> 00:17:46,180
find where data is in the swap device

365
00:17:46,180 --> 00:17:50,350
and after we effectively make it maybe

366
00:17:50,350 --> 00:17:53,590
to not present the next time you access

367
00:17:53,590 --> 00:17:55,960
memory you will get the page fault and

368
00:17:55,960 --> 00:17:57,760
the page fault we will do this warping

369
00:17:57,760 --> 00:18:01,300
from disk so after we actually remove it

370
00:18:01,300 --> 00:18:04,480
the page the page tables we can free the

371
00:18:04,480 --> 00:18:10,620
page so the object reverse mapping is

372
00:18:10,620 --> 00:18:14,920
made in way that the single object can

373
00:18:14,920 --> 00:18:17,470
be shared by multiple pages and the

374
00:18:17,470 --> 00:18:19,870
single object can actually reverse map

375
00:18:19,870 --> 00:18:20,790
huge

376
00:18:20,790 --> 00:18:23,760
memory we want to be efficient we don't

377
00:18:23,760 --> 00:18:25,620
want to locate a single object for each

378
00:18:25,620 --> 00:18:28,800
one of the page tables that we need to

379
00:18:28,800 --> 00:18:31,170
reach the only case where we have to do

380
00:18:31,170 --> 00:18:35,010
it is with case I'm not going into the

381
00:18:35,010 --> 00:18:38,430
sale of this one but case I'm still ways

382
00:18:38,430 --> 00:18:41,730
to limit to long arm up chains so this

383
00:18:41,730 --> 00:18:43,680
was a batch queue 18 mm right now to do

384
00:18:43,680 --> 00:18:49,860
that so this is a very efficient way of

385
00:18:49,860 --> 00:18:53,790
doing arm up in linux and back to the

386
00:18:53,790 --> 00:18:57,390
previous chart if we introduce our map

387
00:18:57,390 --> 00:18:59,370
instead of the clock algorithm things

388
00:18:59,370 --> 00:19:01,800
start to look very efficient now because

389
00:19:01,800 --> 00:19:04,220
when you want to get rid of let's see

390
00:19:04,220 --> 00:19:08,490
the tail of the inactive LRU which would

391
00:19:08,490 --> 00:19:10,830
mean this one let's assume we want to

392
00:19:10,830 --> 00:19:12,960
get rid of this one you just use air map

393
00:19:12,960 --> 00:19:15,300
to read the page table you invalidate

394
00:19:15,300 --> 00:19:18,180
the page table and that's it then you

395
00:19:18,180 --> 00:19:22,020
already know which page to free and you

396
00:19:22,020 --> 00:19:25,290
also have a method to free and so this

397
00:19:25,290 --> 00:19:27,630
thing scale and TAS the service we have

398
00:19:27,630 --> 00:19:32,850
since the to the six car so since for

399
00:19:32,850 --> 00:19:37,460
our to know to the 6:30 something we got

400
00:19:37,460 --> 00:19:40,020
overtime introduces his new way of

401
00:19:40,020 --> 00:19:44,760
detecting the working set of the process

402
00:19:44,760 --> 00:19:48,710
and the way to detect the working set

403
00:19:48,710 --> 00:19:54,510
effectively consists in storing inactive

404
00:19:54,510 --> 00:19:57,720
age and keeping track of in something

405
00:19:57,720 --> 00:20:00,540
called inactive age and the idea is

406
00:20:00,540 --> 00:20:03,660
effectively to be able to say for

407
00:20:03,660 --> 00:20:05,580
example since the active list and

408
00:20:05,580 --> 00:20:08,670
citizen active list what if we would

409
00:20:08,670 --> 00:20:11,220
shrink two pages from the active list

410
00:20:11,220 --> 00:20:13,920
here there will be enough space to cache

411
00:20:13,920 --> 00:20:17,550
the world thing including a B which

412
00:20:17,550 --> 00:20:22,440
current adopted so if we are the way to

413
00:20:22,440 --> 00:20:26,640
tell that the report vistas in this set

414
00:20:26,640 --> 00:20:30,540
is smaller than the report distance and

415
00:20:30,540 --> 00:20:33,420
since said we can tell well we should

416
00:20:33,420 --> 00:20:34,429
actually shrink

417
00:20:34,429 --> 00:20:36,139
at least more aggressively because if we

418
00:20:36,139 --> 00:20:38,570
do it we will be able to activate a huge

419
00:20:38,570 --> 00:20:43,070
amount of the knack tablets so the whole

420
00:20:43,070 --> 00:20:44,629
point of this organism is to decide

421
00:20:44,629 --> 00:20:47,659
where to basically divide the inactive

422
00:20:47,659 --> 00:20:50,389
and the active list and move it more

423
00:20:50,389 --> 00:20:53,090
towards one side or the other side so

424
00:20:53,090 --> 00:20:55,970
effectively to grow or shrink the active

425
00:20:55,970 --> 00:20:58,039
list dynamically depending on the world

426
00:20:58,039 --> 00:21:00,860
consult the way to do it is very small

427
00:21:00,860 --> 00:21:04,669
and it consists in keeping track of his

428
00:21:04,669 --> 00:21:07,249
inactive age and a full distance in the

429
00:21:07,249 --> 00:21:09,409
radix tree the radix tree is a tree

430
00:21:09,409 --> 00:21:11,929
where you you basically describe the

431
00:21:11,929 --> 00:21:13,909
cache belonging to a file so you have a

432
00:21:13,909 --> 00:21:16,700
file and each offset of the file will

433
00:21:16,700 --> 00:21:17,980
have an entry in the radix tree

434
00:21:17,980 --> 00:21:22,039
generally this a radix tree is used for

435
00:21:22,039 --> 00:21:24,830
lookups to find the page so in fact it's

436
00:21:24,830 --> 00:21:27,080
the way you look up check if the

437
00:21:27,080 --> 00:21:29,360
information you are going to read from

438
00:21:29,360 --> 00:21:32,360
the file is already in the cache and if

439
00:21:32,360 --> 00:21:34,159
it's already in the cache you will find

440
00:21:34,159 --> 00:21:37,309
a page if it's not in the cache because

441
00:21:37,309 --> 00:21:41,110
it was reclaimed you will find an

442
00:21:41,110 --> 00:21:43,820
exceptional share of entry with the

443
00:21:43,820 --> 00:21:46,279
inactive age of the time plus you

444
00:21:46,279 --> 00:21:47,929
increase an activation so in fact with

445
00:21:47,929 --> 00:21:51,710
this prick allows to optimally size the

446
00:21:51,710 --> 00:21:53,929
active and inactive lists like I say

447
00:21:53,929 --> 00:21:56,149
it's happening about two years ago and

448
00:21:56,149 --> 00:21:58,190
it keeps going to be in development by

449
00:21:58,190 --> 00:22:04,580
the way and in addition multiply

450
00:22:04,580 --> 00:22:07,610
everything I just said many many times

451
00:22:07,610 --> 00:22:10,789
for many C groups so now probably cannot

452
00:22:10,789 --> 00:22:13,309
chart here anymore it kind of gets too

453
00:22:13,309 --> 00:22:17,869
big game but every memory C group has

454
00:22:17,869 --> 00:22:21,740
its own LRU and and all the algorithm I

455
00:22:21,740 --> 00:22:23,899
describe it will work within the C group

456
00:22:23,899 --> 00:22:25,369
so within the container the container

457
00:22:25,369 --> 00:22:28,100
will use memories Europe this is not

458
00:22:28,100 --> 00:22:30,950
enforced but it's optional and you can

459
00:22:30,950 --> 00:22:33,309
do that

460
00:22:33,639 --> 00:22:36,279
and for our additional optimization like

461
00:22:36,279 --> 00:22:39,369
for example these days the anonymous

462
00:22:39,369 --> 00:22:42,129
memory top for example if you don't have

463
00:22:42,129 --> 00:22:44,440
the anonymous memory cannot be a claim

464
00:22:44,440 --> 00:22:48,009
and so we don't add we don't add it to

465
00:22:48,009 --> 00:22:51,100
any other rule so we actually keep it in

466
00:22:51,100 --> 00:22:53,049
something called an a big double array

467
00:22:53,049 --> 00:22:56,649
so we have again many more optimization

468
00:22:56,649 --> 00:22:59,230
including the PHP optimization PHP is

469
00:22:59,230 --> 00:23:01,379
huge pages we'll see it in a later slide

470
00:23:01,379 --> 00:23:03,909
which increases the scalability of the

471
00:23:03,909 --> 00:23:06,399
lyric by 512 times because we are going

472
00:23:06,399 --> 00:23:08,619
to have a single entry which describe

473
00:23:08,619 --> 00:23:11,859
two megabytes not 4k so by having fewer

474
00:23:11,859 --> 00:23:13,749
entry things that are used things gets

475
00:23:13,749 --> 00:23:22,419
more fast when we reclaim it so many of

476
00:23:22,419 --> 00:23:24,639
the things which happen at the recently

477
00:23:24,639 --> 00:23:28,470
like Numa automatic Numa balancing

478
00:23:28,470 --> 00:23:31,889
transparent huge pages

479
00:23:31,950 --> 00:23:39,789
KSM and even something for GPU called

480
00:23:39,789 --> 00:23:42,220
hmm heterogeneous memory management

481
00:23:42,220 --> 00:23:45,519
which effectively allows to compute is

482
00:23:45,519 --> 00:23:49,570
GPU memory and without having to invoke

483
00:23:49,570 --> 00:23:52,960
anything in the driver of GPUs since the

484
00:23:52,960 --> 00:23:55,409
Linux kernel is able to move

485
00:23:55,409 --> 00:23:57,519
transparently it's a memory from the

486
00:23:57,519 --> 00:23:59,529
main memory of the computer to the GPU

487
00:23:59,529 --> 00:24:01,529
memory which is much faster of course

488
00:24:01,529 --> 00:24:03,340
transparently you just you know

489
00:24:03,340 --> 00:24:05,830
computer's memory whenever you start the

490
00:24:05,830 --> 00:24:09,999
competition with GPU with OpenGL or

491
00:24:09,999 --> 00:24:13,149
whatever it's going to fold and move the

492
00:24:13,149 --> 00:24:15,279
memory into the GPU memory then when the

493
00:24:15,279 --> 00:24:18,009
main CPU access it is going to bring it

494
00:24:18,009 --> 00:24:19,929
back to the main memory so all these

495
00:24:19,929 --> 00:24:23,080
things as you can see is the trends

496
00:24:23,080 --> 00:24:25,450
where the kernel time to optimize

497
00:24:25,450 --> 00:24:28,049
workload for you without manual tuning

498
00:24:28,049 --> 00:24:31,210
and you can see in all these features

499
00:24:31,210 --> 00:24:35,470
and all the optimization whoever can be

500
00:24:35,470 --> 00:24:37,480
optionally disabled because for example

501
00:24:37,480 --> 00:24:39,309
with automatic Numa balancing

502
00:24:39,309 --> 00:24:42,389
automatic Nova balancing is very good at

503
00:24:42,389 --> 00:24:44,559
automatically

504
00:24:44,559 --> 00:24:46,570
every workload in a different noumenon

505
00:24:46,570 --> 00:24:50,320
so you know you're running a database on

506
00:24:50,320 --> 00:24:53,350
one side a beautiful machine on the

507
00:24:53,350 --> 00:24:55,120
other side automatic animal balancing

508
00:24:55,120 --> 00:24:57,820
will detect the workload and move the

509
00:24:57,820 --> 00:25:02,740
staff in each note separately but if you

510
00:25:02,740 --> 00:25:06,190
were to be sure that the workloads are

511
00:25:06,190 --> 00:25:08,799
being ran in different notes you would

512
00:25:08,799 --> 00:25:12,340
still need to use hard bindings so the

513
00:25:12,340 --> 00:25:14,260
idea is if you want to go the extra mile

514
00:25:14,260 --> 00:25:17,159
you can optimize things yourself still

515
00:25:17,159 --> 00:25:20,769
but the idea of all these algorithm in

516
00:25:20,769 --> 00:25:21,340
the kernel

517
00:25:21,340 --> 00:25:23,529
is that you shouldn't need to do that to

518
00:25:23,529 --> 00:25:25,929
be very efficient so it's you shouldn't

519
00:25:25,929 --> 00:25:27,610
be so sure me much different between

520
00:25:27,610 --> 00:25:30,279
manual optimizations and what the camera

521
00:25:30,279 --> 00:25:31,570
can do automatically for you

522
00:25:31,570 --> 00:25:36,429
that is our objective so how can we use

523
00:25:36,429 --> 00:25:39,159
all these features in built machines

524
00:25:39,159 --> 00:25:44,590
like Tron built machine in hypervisor

525
00:25:44,590 --> 00:25:47,620
why should we invent anything I mean we

526
00:25:47,620 --> 00:25:49,870
already have this memory scheduler and

527
00:25:49,870 --> 00:25:54,389
in fact we don't because we use KVM and

528
00:25:54,389 --> 00:25:57,220
the whole point of the kvn philosophy's

529
00:25:57,220 --> 00:25:58,779
would use the Linux code as much as

530
00:25:58,779 --> 00:26:02,500
possible all the things I described work

531
00:26:02,500 --> 00:26:05,440
in the host but the already optimized

532
00:26:05,440 --> 00:26:08,830
guest so we don't have to write anything

533
00:26:08,830 --> 00:26:13,389
at all and in fact the Numa balancing

534
00:26:13,389 --> 00:26:15,730
was important for other applications as

535
00:26:15,730 --> 00:26:18,690
for virtual machines not much different

536
00:26:18,690 --> 00:26:20,860
transparent which pages give the bigger

537
00:26:20,860 --> 00:26:23,019
boost for built machine time for normal

538
00:26:23,019 --> 00:26:24,580
application but normal application gets

539
00:26:24,580 --> 00:26:27,399
benefit to all other things like driver

540
00:26:27,399 --> 00:26:29,230
and power management definitely would

541
00:26:29,230 --> 00:26:33,100
not want to write any driver at all so

542
00:26:33,100 --> 00:26:36,309
things integrate well into the existing

543
00:26:36,309 --> 00:26:38,559
infrastructure Acadia it's just a cable

544
00:26:38,559 --> 00:26:41,740
model plus some notifier in some case we

545
00:26:41,740 --> 00:26:44,080
need to hook into the existing color

546
00:26:44,080 --> 00:26:46,360
code to do a few more optimizations but

547
00:26:46,360 --> 00:26:49,210
it's not wrong for example transparent

548
00:26:49,210 --> 00:26:49,870
which pages

549
00:26:49,870 --> 00:26:52,299
automatic Numa balancing don't air and

550
00:26:52,299 --> 00:26:54,340
hook at all the strands

551
00:26:54,340 --> 00:26:57,220
like if KVM was a normal process it

552
00:26:57,220 --> 00:26:58,750
doesn't see the difference at submit

553
00:26:58,750 --> 00:27:00,820
machine the algorithm in the hosts work

554
00:27:00,820 --> 00:27:05,050
exactly the same way so this is just

555
00:27:05,050 --> 00:27:08,530
chart showing the machines running just

556
00:27:08,530 --> 00:27:10,990
like ordinary processes the difference

557
00:27:10,990 --> 00:27:13,810
is when you have a better machine with

558
00:27:13,810 --> 00:27:16,600
kvn it can also switch to gas mode which

559
00:27:16,600 --> 00:27:19,680
an ordinary process wouldn't do and

560
00:27:19,680 --> 00:27:22,990
normally all the legacy general

561
00:27:22,990 --> 00:27:25,390
applications use on user space and

562
00:27:25,390 --> 00:27:30,070
camera mode with KVM your switch to get

563
00:27:30,070 --> 00:27:32,260
small and through our lightweight

564
00:27:32,260 --> 00:27:33,880
switches sometime you can just keep

565
00:27:33,880 --> 00:27:36,250
computing here so you only go from guest

566
00:27:36,250 --> 00:27:38,080
mode to kernel mode sometimes you have

567
00:27:38,080 --> 00:27:40,240
to go down to PMO because you may need

568
00:27:40,240 --> 00:27:43,510
to do emulate Deo and driver of whatever

569
00:27:43,510 --> 00:27:46,360
is doing the guest actually is in crema

570
00:27:46,360 --> 00:27:52,890
and not in the car a few benchwork about

571
00:27:52,890 --> 00:27:56,980
Numa balancing so like I said my

572
00:27:56,980 --> 00:28:00,550
balancing is included in the rad7 that

573
00:28:00,550 --> 00:28:03,510
the first release which included it and

574
00:28:03,510 --> 00:28:09,730
before l7 you had to use other bindings

575
00:28:09,730 --> 00:28:11,380
so you could already optimized for Numa

576
00:28:11,380 --> 00:28:14,730
but it would be absolutely not automatic

577
00:28:14,730 --> 00:28:17,800
and of course the comparison the

578
00:28:17,800 --> 00:28:20,670
interesting comparison here is between

579
00:28:20,670 --> 00:28:24,250
hard bindings because like I said even

580
00:28:24,250 --> 00:28:27,850
with before an automatic Numa ballasts

581
00:28:27,850 --> 00:28:29,620
you could already optimize the workload

582
00:28:29,620 --> 00:28:33,630
for Roma but we have to use all kind of

583
00:28:33,630 --> 00:28:38,320
hard bindings with Numa control with men

584
00:28:38,320 --> 00:28:41,950
policy with am buying there are many

585
00:28:41,950 --> 00:28:45,190
schools which you can use to a radio

586
00:28:45,190 --> 00:28:47,560
optimized for lumen but the idea is this

587
00:28:47,560 --> 00:28:48,960
is difficult it's not flexible

588
00:28:48,960 --> 00:28:51,550
especially with built machines you want

589
00:28:51,550 --> 00:28:53,050
to start new Burton machines all the

590
00:28:53,050 --> 00:28:55,120
time shut them down they need to move

591
00:28:55,120 --> 00:28:56,830
from one node to another node you don't

592
00:28:56,830 --> 00:29:00,670
want to do horses management by hand in

593
00:29:00,670 --> 00:29:02,560
fact we also implemented something

594
00:29:02,560 --> 00:29:04,150
called new MIDI which uses their

595
00:29:04,150 --> 00:29:05,890
bindings but it does it for you

596
00:29:05,890 --> 00:29:07,059
so as an admission

597
00:29:07,059 --> 00:29:10,389
it's not that rules is binding and the

598
00:29:10,389 --> 00:29:13,090
management of where to ran the workload

599
00:29:13,090 --> 00:29:15,429
which noumenon to run the workload and

600
00:29:15,429 --> 00:29:17,620
keep in mind every server with two

601
00:29:17,620 --> 00:29:19,749
circuits today is a new machine so if

602
00:29:19,749 --> 00:29:21,820
you want to run optimal you have you

603
00:29:21,820 --> 00:29:23,080
will need to do this stuff without

604
00:29:23,080 --> 00:29:25,330
automatic animal balancing or without

605
00:29:25,330 --> 00:29:28,860
remedy so our idea is it should perform

606
00:29:28,860 --> 00:29:31,779
automatic Numa balancing almost as fast

607
00:29:31,779 --> 00:29:36,850
as an optimal a hard placement and as

608
00:29:36,850 --> 00:29:40,450
you can see the blue line is the hub

609
00:29:40,450 --> 00:29:44,080
binding it's the fastest and the red

610
00:29:44,080 --> 00:29:48,129
line is automatic Numa balancing so the

611
00:29:48,129 --> 00:29:51,399
camel the camel intelligence since BM

612
00:29:51,399 --> 00:29:54,009
effectively figuring out with the best

613
00:29:54,009 --> 00:29:56,409
way to run the workload were to put the

614
00:29:56,409 --> 00:29:58,119
memory where to put the processing the

615
00:29:58,119 --> 00:30:06,389
CPU and the yellow orange is just

616
00:30:06,389 --> 00:30:09,399
standard without automatically balancing

617
00:30:09,399 --> 00:30:12,940
like with basic iterated I mean it's

618
00:30:12,940 --> 00:30:18,249
always said some Numa bias but it was

619
00:30:18,249 --> 00:30:20,049
very short right so it kind of worked

620
00:30:20,049 --> 00:30:21,999
for DCC which allocates memory used it

621
00:30:21,999 --> 00:30:24,730
and freeze it then Linux was the really

622
00:30:24,730 --> 00:30:26,259
kind of okay before automatic aroma

623
00:30:26,259 --> 00:30:28,749
balancing but for all long line with a

624
00:30:28,749 --> 00:30:30,700
location like built machine the machine

625
00:30:30,700 --> 00:30:33,190
you started once and I keep run it keeps

626
00:30:33,190 --> 00:30:34,869
keeps running potentially for one year

627
00:30:34,869 --> 00:30:37,240
and for that Linux was not optimal

628
00:30:37,240 --> 00:30:40,090
before automatic Numa balancing and as

629
00:30:40,090 --> 00:30:42,309
you can see at the very top of the line

630
00:30:42,309 --> 00:30:45,190
are burning still give a little bit of a

631
00:30:45,190 --> 00:30:50,950
hatch so it's worth it for very complex

632
00:30:50,950 --> 00:30:53,049
workloads but especially in smaller

633
00:30:53,049 --> 00:30:56,590
systems so if you would use only a more

634
00:30:56,590 --> 00:30:59,760
limited number of nodes

635
00:30:59,760 --> 00:31:03,030
and the instances of Darby's the

636
00:31:03,030 --> 00:31:07,110
performance is almost identical so this

637
00:31:07,110 --> 00:31:10,140
is very good result and that's why of

638
00:31:10,140 --> 00:31:11,940
course automatic nomina balancing is

639
00:31:11,940 --> 00:31:15,200
enabled by default in our answer so

640
00:31:15,200 --> 00:31:19,020
something important here you need to

641
00:31:19,020 --> 00:31:21,090
know how to enable and disable sees and

642
00:31:21,090 --> 00:31:25,380
touch the slide showing it first of all

643
00:31:25,380 --> 00:31:28,050
Numa control - - Hardware shows you if

644
00:31:28,050 --> 00:31:30,390
your hardware while you're running your

645
00:31:30,390 --> 00:31:33,510
software is Numa or not normal so if

646
00:31:33,510 --> 00:31:35,610
it's not normal it will complain if it

647
00:31:35,610 --> 00:31:37,200
shows the layout it means you are

648
00:31:37,200 --> 00:31:39,330
running on a normal system so if you're

649
00:31:39,330 --> 00:31:40,860
running a normal system with the slash

650
00:31:40,860 --> 00:31:44,400
proxies kernel luma balancing you can

651
00:31:44,400 --> 00:31:48,600
enable or disable it by echoing a 1 or 0

652
00:31:48,600 --> 00:31:52,380
into it respectively you also have an

653
00:31:52,380 --> 00:31:53,850
option so if you want to go in the group

654
00:31:53,850 --> 00:31:56,070
command line you can do you know no more

655
00:31:56,070 --> 00:31:59,419
balancing equal enable/disable

656
00:31:59,630 --> 00:32:03,090
thumb which is some other thing which we

657
00:32:03,090 --> 00:32:05,930
think is interesting about youth pages

658
00:32:05,930 --> 00:32:09,630
huge pages is a relatively recent

659
00:32:09,630 --> 00:32:12,810
feature it's not so decent but you got a

660
00:32:12,810 --> 00:32:15,000
lot of development recently for example

661
00:32:15,000 --> 00:32:19,080
in the 4.8 caramel we just merged the HP

662
00:32:19,080 --> 00:32:22,560
and tmpfs so original HP transparent

663
00:32:22,560 --> 00:32:24,170
huge pages

664
00:32:24,170 --> 00:32:27,270
it was only in anonymous memory but

665
00:32:27,270 --> 00:32:30,300
since 4.8 you can also use it as shared

666
00:32:30,300 --> 00:32:33,060
memory and they say tmpfs but it works

667
00:32:33,060 --> 00:32:36,090
for everything like IPC shared memory

668
00:32:36,090 --> 00:32:40,980
system file or map shared slash dev

669
00:32:40,980 --> 00:32:43,170
slash 0 what kind of api which can

670
00:32:43,170 --> 00:32:45,360
generate a shared memory including

671
00:32:45,360 --> 00:32:48,570
mammoth needs Co the word point of

672
00:32:48,570 --> 00:32:50,730
transparent which pages is to draw a

673
00:32:50,730 --> 00:32:53,220
layer of the page table at least that's

674
00:32:53,220 --> 00:32:55,170
the way it does it you know the x86

675
00:32:55,170 --> 00:32:57,570
architecture not raccattack sure it's

676
00:32:57,570 --> 00:32:59,310
been different but still the wall point

677
00:32:59,310 --> 00:33:01,470
is to make the Kilby means faster so it

678
00:33:01,470 --> 00:33:02,910
means when you access the memory is

679
00:33:02,910 --> 00:33:04,830
going to run faster so it's like

680
00:33:04,830 --> 00:33:07,370
spinning up the computation of your CPU

681
00:33:07,370 --> 00:33:11,600
and the benefit of huge pages especially

682
00:33:11,600 --> 00:33:12,770
we

683
00:33:12,770 --> 00:33:14,780
in visualization environment we see in

684
00:33:14,780 --> 00:33:17,990
the next slide why Emily is some code

685
00:33:17,990 --> 00:33:21,080
and the concert generally about the cost

686
00:33:21,080 --> 00:33:24,050
of the page fault the page fault is

687
00:33:24,050 --> 00:33:25,250
going to cost more because you're not

688
00:33:25,250 --> 00:33:27,800
going to allocate more memory and before

689
00:33:27,800 --> 00:33:29,270
you can wrap the memory in userland you

690
00:33:29,270 --> 00:33:30,530
need to clear it we cannot show

691
00:33:30,530 --> 00:33:33,410
previously use the data to the guests to

692
00:33:33,410 --> 00:33:35,809
even a process to anything every time

693
00:33:35,809 --> 00:33:37,370
you look at memory it's always shows up

694
00:33:37,370 --> 00:33:40,370
at zero because you clear it is security

695
00:33:40,370 --> 00:33:44,420
show why we do it so because we have to

696
00:33:44,420 --> 00:33:47,720
clear two megabytes not 4k that might be

697
00:33:47,720 --> 00:33:49,730
a little slower to handful of course is

698
00:33:49,730 --> 00:33:52,730
lower so there is also an IR memory

699
00:33:52,730 --> 00:33:56,450
footprint some time and generating huge

700
00:33:56,450 --> 00:33:58,640
pages which takes time more times and

701
00:33:58,640 --> 00:34:01,100
locating a 4k page that's called direct

702
00:34:01,100 --> 00:34:05,420
conversion and since the chart showing

703
00:34:05,420 --> 00:34:07,190
why transparent news pages improve

704
00:34:07,190 --> 00:34:09,379
performance for the most part answer a

705
00:34:09,379 --> 00:34:11,869
lot of reasons but is also showing why

706
00:34:11,869 --> 00:34:14,540
in visualization environment this is

707
00:34:14,540 --> 00:34:16,489
going to make more difference to have

708
00:34:16,489 --> 00:34:17,960
transparency to pages enabled or not

709
00:34:17,960 --> 00:34:19,659
Donald bare-metal

710
00:34:19,659 --> 00:34:23,659
since the number of memory access the

711
00:34:23,659 --> 00:34:28,750
CPU has to do to reach the actual data

712
00:34:28,750 --> 00:34:31,010
starting from the built progress in your

713
00:34:31,010 --> 00:34:32,780
application which is beautiful not

714
00:34:32,780 --> 00:34:37,909
physical so when use EPT it needs to do

715
00:34:37,909 --> 00:34:40,879
about 25 accesses and don't remember

716
00:34:40,879 --> 00:34:43,219
exact number but duplex 25 in the chart

717
00:34:43,219 --> 00:34:46,040
the chart is accurate and if you enable

718
00:34:46,040 --> 00:34:47,989
HP both in the guest and in the host

719
00:34:47,989 --> 00:34:50,929
you're going to drop it like 17 or

720
00:34:50,929 --> 00:34:53,379
something

721
00:34:54,219 --> 00:34:56,899
the way to use transparent which pages

722
00:34:56,899 --> 00:34:58,520
basically does not require any change in

723
00:34:58,520 --> 00:35:00,560
your application just allocate the piece

724
00:35:00,560 --> 00:35:02,540
of memory bigger than 2 megabyte and

725
00:35:02,540 --> 00:35:04,010
you're going to get transparent which

726
00:35:04,010 --> 00:35:06,830
pages on it so it's going to do the same

727
00:35:06,830 --> 00:35:08,690
thing you would be doing area with you

728
00:35:08,690 --> 00:35:13,180
still BFS but without that usually BFS

729
00:35:13,180 --> 00:35:16,340
it's entirely transparent to user 1 so

730
00:35:16,340 --> 00:35:19,220
let's get to the interesting part so you

731
00:35:19,220 --> 00:35:22,940
will see some application and I don't

732
00:35:22,940 --> 00:35:24,380
think you have the time here to go into

733
00:35:24,380 --> 00:35:27,950
why data running slower with transparent

734
00:35:27,950 --> 00:35:30,110
which pages one example is ready and

735
00:35:30,110 --> 00:35:31,400
sort of very good reason why it's

736
00:35:31,400 --> 00:35:33,410
running slower and see I recommend to

737
00:35:33,410 --> 00:35:36,020
disable transparent which pages for

738
00:35:36,020 --> 00:35:38,210
radius well actually

739
00:35:38,210 --> 00:35:43,550
Paredes it should be using pl/sql to

740
00:35:43,550 --> 00:35:45,110
disable transparent which pages for a

741
00:35:45,110 --> 00:35:48,380
single application and generally in most

742
00:35:48,380 --> 00:35:50,600
cases so this is really a case where it

743
00:35:50,600 --> 00:35:52,100
makes sense to zero transparent a space

744
00:35:52,100 --> 00:35:54,020
but you know the other cases it

745
00:35:54,020 --> 00:35:56,330
generally does not make sense the other

746
00:35:56,330 --> 00:35:57,470
thing which makes sense which is

747
00:35:57,470 --> 00:36:00,260
actually the new default and I'm not

748
00:36:00,260 --> 00:36:01,940
sure if I fully agree with new default I

749
00:36:01,940 --> 00:36:04,640
prefer always but still if you have any

750
00:36:04,640 --> 00:36:06,650
slowdown there is should not disable

751
00:36:06,650 --> 00:36:08,180
spirit which pages which practically

752
00:36:08,180 --> 00:36:10,280
never slow down performance but you

753
00:36:10,280 --> 00:36:12,619
should disable direct compaction because

754
00:36:12,619 --> 00:36:14,980
the only thing which is costly is

755
00:36:14,980 --> 00:36:18,350
generation of the page actually the

756
00:36:18,350 --> 00:36:20,270
clear page is pretty fast to make about

757
00:36:20,270 --> 00:36:22,820
actually fit in the CPU cache it's not

758
00:36:22,820 --> 00:36:27,470
sled so that is if you have regressions

759
00:36:27,470 --> 00:36:32,090
before you try to do from always two am

760
00:36:32,090 --> 00:36:35,330
advice in the act on main knob so in the

761
00:36:35,330 --> 00:36:37,010
main transparent which pages enable it

762
00:36:37,010 --> 00:36:38,630
with sharing which is really turning of

763
00:36:38,630 --> 00:36:41,450
the feature first you should do from

764
00:36:41,450 --> 00:36:44,990
always to am advice into transparent use

765
00:36:44,990 --> 00:36:47,270
pages defrag the frame is effectively

766
00:36:47,270 --> 00:36:49,910
only controlling how aggressively and

767
00:36:49,910 --> 00:36:52,220
how much CPU time you are going to

768
00:36:52,220 --> 00:36:56,119
invest to create a huge page and it

769
00:36:56,119 --> 00:37:00,160
passes workload what is done if the

770
00:37:00,160 --> 00:37:03,020
allocation is long-lived it's always

771
00:37:03,020 --> 00:37:05,330
better to do always even if it takes

772
00:37:05,330 --> 00:37:06,160
time to Jenny

773
00:37:06,160 --> 00:37:08,470
the page then you're going to use it for

774
00:37:08,470 --> 00:37:09,910
a long time and it's going to run much

775
00:37:09,910 --> 00:37:13,269
faster if the location is very sharp

776
00:37:13,269 --> 00:37:17,319
like it might be faster to use 4 K pages

777
00:37:17,319 --> 00:37:19,089
and not spend the time to create a new

778
00:37:19,089 --> 00:37:20,950
page because they're going to free it

779
00:37:20,950 --> 00:37:23,109
immediately and unless you compute a lot

780
00:37:23,109 --> 00:37:24,880
on the page you are not going to get

781
00:37:24,880 --> 00:37:27,670
much benefit from having drop it this

782
00:37:27,670 --> 00:37:29,769
layer of page table and using the huge

783
00:37:29,769 --> 00:37:33,789
still be so the last thing and I have

784
00:37:33,789 --> 00:37:35,769
three minutes first one is Mavericks

785
00:37:35,769 --> 00:37:39,099
organization memory externalization is

786
00:37:39,099 --> 00:37:41,559
the concept where you effectively put

787
00:37:41,559 --> 00:37:43,690
memory where we are computing in a

788
00:37:43,690 --> 00:37:46,269
different computer so it's not swapping

789
00:37:46,269 --> 00:37:48,279
it's literally giving up the memory to

790
00:37:48,279 --> 00:37:50,380
somebody else while the program is

791
00:37:50,380 --> 00:37:52,809
running and when the program is running

792
00:37:52,809 --> 00:37:54,700
any Saxon the memory you drop it from

793
00:37:54,700 --> 00:37:57,519
your computer easier if you do what they

794
00:37:57,519 --> 00:38:00,250
call you support and the user fault will

795
00:38:00,250 --> 00:38:02,799
bring the memory back into your local

796
00:38:02,799 --> 00:38:04,839
memory so you can keep the computation

797
00:38:04,839 --> 00:38:08,769
and post copied emigration is a subset

798
00:38:08,769 --> 00:38:10,180
of this idea

799
00:38:10,180 --> 00:38:12,160
the scapulae migration effectively Arlo

800
00:38:12,160 --> 00:38:14,619
to ran able to machine in the

801
00:38:14,619 --> 00:38:16,569
destination node while the memory

802
00:38:16,569 --> 00:38:19,509
suicidal source so I implemented this

803
00:38:19,509 --> 00:38:21,789
user for Cisco which is used in the

804
00:38:21,789 --> 00:38:24,180
cream o current post copula emigration

805
00:38:24,180 --> 00:38:26,049
implementation which is reading vm

806
00:38:26,049 --> 00:38:28,509
upstream if you track get upstream of

807
00:38:28,509 --> 00:38:33,759
TMI straight available and the user for

808
00:38:33,759 --> 00:38:36,099
this goal is also available in the rel

809
00:38:36,099 --> 00:38:38,829
72 and it's possible to do the post

810
00:38:38,829 --> 00:38:41,369
copied emigration in the latest or l 7

811
00:38:41,369 --> 00:38:45,849
as an option so the user for latency he

812
00:38:45,849 --> 00:38:47,920
is similar to something you can imagine

813
00:38:47,920 --> 00:38:50,230
it like swap and his chart showing

814
00:38:50,230 --> 00:38:52,720
during post copula emigration what's the

815
00:38:52,720 --> 00:38:54,700
time it takes for the guest to access

816
00:38:54,700 --> 00:38:57,730
remote memory and again it's not very

817
00:38:57,730 --> 00:38:59,289
different from swapping we are talking

818
00:38:59,289 --> 00:39:02,259
about 17 milliseconds Nancy is on of

819
00:39:02,259 --> 00:39:03,970
course and a 10 Gigabit Ethernet so it's

820
00:39:03,970 --> 00:39:07,269
not even the fastest possible and you

821
00:39:07,269 --> 00:39:09,039
might be asking yourself why some time

822
00:39:09,039 --> 00:39:10,809
it takes so little about because

823
00:39:10,809 --> 00:39:13,450
resource background transfer I mean it's

824
00:39:13,450 --> 00:39:15,940
not like you're waiting to hit memory

825
00:39:15,940 --> 00:39:18,220
which is missing in the meantime while

826
00:39:18,220 --> 00:39:19,579
the guest computers this

827
00:39:19,579 --> 00:39:22,219
you know you keep sending all the memory

828
00:39:22,219 --> 00:39:24,469
in background and sometimes the memory

829
00:39:24,469 --> 00:39:27,650
is coming while the user fault happens

830
00:39:27,650 --> 00:39:29,390
and you don't have to refer to find it's

831
00:39:29,390 --> 00:39:30,440
already there so it's like a

832
00:39:30,440 --> 00:39:33,380
false-positive fault

833
00:39:33,380 --> 00:39:38,029
and it's getting computed immediately

834
00:39:38,029 --> 00:39:41,869
like in last one in second and it's so

835
00:39:41,869 --> 00:39:44,450
frequent because we do read around when

836
00:39:44,450 --> 00:39:46,640
we get an user fault we tell the

837
00:39:46,640 --> 00:39:49,219
background transfer to keep sending from

838
00:39:49,219 --> 00:39:51,589
that address from that piece of memory

839
00:39:51,589 --> 00:39:54,380
because it's very likely that the moment

840
00:39:54,380 --> 00:39:58,670
the destination guest is waking up again

841
00:39:58,670 --> 00:40:00,799
the disappearance destination returns

842
00:40:00,799 --> 00:40:01,369


843
00:40:01,369 --> 00:40:03,739
it will touch a piece of memory which is

844
00:40:03,739 --> 00:40:05,479
very close to the one which triggers the

845
00:40:05,479 --> 00:40:07,339
first fault so we have all cams

846
00:40:07,339 --> 00:40:09,709
organization to maximize this error of

847
00:40:09,709 --> 00:40:13,719
course we like the fact often is fast

848
00:40:13,719 --> 00:40:16,219
fill the chart showing a comparison

849
00:40:16,219 --> 00:40:17,410
between pre copy

850
00:40:17,410 --> 00:40:20,499
when sees the performance database so

851
00:40:20,499 --> 00:40:23,359
since before it's like three different

852
00:40:23,359 --> 00:40:27,079
trends before the test before the lab

853
00:40:27,079 --> 00:40:28,789
migration and after the line migration

854
00:40:28,789 --> 00:40:32,709
so you will you see pre copy as

855
00:40:32,709 --> 00:40:34,789
regression in performance for the

856
00:40:34,789 --> 00:40:37,729
duration of pre copy and this is

857
00:40:37,729 --> 00:40:40,130
actually post copula Malaysia and this

858
00:40:40,130 --> 00:40:41,420
is going to be the last slide because

859
00:40:41,420 --> 00:40:43,190
I'm running out of time but you can see

860
00:40:43,190 --> 00:40:45,410
post copula migration brings the

861
00:40:45,410 --> 00:40:47,930
performance back very fast and

862
00:40:47,930 --> 00:40:49,670
especially it can finish the emigration

863
00:40:49,670 --> 00:40:53,329
with the previous case dinner so that's

864
00:40:53,329 --> 00:40:55,969
all and if you have questions I think we

865
00:40:55,969 --> 00:40:57,799
ran out of time we are going to do it at

866
00:40:57,799 --> 00:40:59,359
the via book I think

867
00:40:59,359 --> 00:41:02,558
thank you very much

868
00:41:07,440 --> 00:41:09,500
you

