1
00:00:00,030 --> 00:00:03,380
hmm let me put this on

2
00:00:05,670 --> 00:00:07,630
thank you thank you for sticking around

3
00:00:07,630 --> 00:00:09,370
very good of you here we go it's boy

4
00:00:09,370 --> 00:00:10,690
ting concurrency it sounds bad doesn't

5
00:00:10,690 --> 00:00:12,969
it but it's good you know say so here we

6
00:00:12,969 --> 00:00:16,000
go so as we all know processors aren't

7
00:00:16,000 --> 00:00:18,640
getting any quicker clockwise you know

8
00:00:18,640 --> 00:00:21,670
the ticket about this quick um and there

9
00:00:21,670 --> 00:00:22,810
are lots of clever tricks to try and

10
00:00:22,810 --> 00:00:25,150
improve IPC you know obviously deep

11
00:00:25,150 --> 00:00:26,980
branch predictions and you know

12
00:00:26,980 --> 00:00:30,310
superscalar architecture and things but

13
00:00:30,310 --> 00:00:31,869
they only really go so far there's not

14
00:00:31,869 --> 00:00:35,920
huge wins in IPC coming the real win

15
00:00:35,920 --> 00:00:37,780
though I'd argue is coming from all of

16
00:00:37,780 --> 00:00:39,489
these other CPUs that are sitting on

17
00:00:39,489 --> 00:00:41,530
your die each of which can do multi

18
00:00:41,530 --> 00:00:43,120
threads I don't if you know one of our

19
00:00:43,120 --> 00:00:44,920
sponsors you get this gratuitous

20
00:00:44,920 --> 00:00:46,960
commercial plug Andy they're releasing

21
00:00:46,960 --> 00:00:49,389
the single rise and rather soon now and

22
00:00:49,389 --> 00:00:50,530
which i think is going to set the

23
00:00:50,530 --> 00:00:52,600
benchmark for the number of cores you

24
00:00:52,600 --> 00:00:55,629
expect 16 threads it's going to be the

25
00:00:55,629 --> 00:00:56,889
new normal in this year so it's

26
00:00:56,889 --> 00:00:58,299
fantastic to see almonds work they're

27
00:00:58,299 --> 00:01:00,129
authoring layers are going to you know

28
00:01:00,129 --> 00:01:02,199
do do all sorts of wonderful stuff much

29
00:01:02,199 --> 00:01:04,989
more quickly but the point is that

30
00:01:04,989 --> 00:01:06,760
unless you're using the other 15

31
00:01:06,760 --> 00:01:10,810
processors you're wasting you know 90

32
00:01:10,810 --> 00:01:12,729
plus percent of the silicon real estate

33
00:01:12,729 --> 00:01:14,590
that someone has very carefully etched

34
00:01:14,590 --> 00:01:16,570
and put on your device and that's super

35
00:01:16,570 --> 00:01:18,729
sad right so we need to we need to do

36
00:01:18,729 --> 00:01:21,369
something about that so we have started

37
00:01:21,369 --> 00:01:24,430
obviously we are we're trying um we use

38
00:01:24,430 --> 00:01:25,600
actually quite a lot of threads when you

39
00:01:25,600 --> 00:01:27,219
start LibreOffice will you to attach a

40
00:01:27,219 --> 00:01:29,560
debugger to it particularly Windows you

41
00:01:29,560 --> 00:01:31,810
think brilliant we're already using six

42
00:01:31,810 --> 00:01:33,460
threads and we're not doing anything you

43
00:01:33,460 --> 00:01:35,590
know unfortunately most of the threads

44
00:01:35,590 --> 00:01:37,719
are literally not doing anything so um

45
00:01:37,719 --> 00:01:39,909
the main thread is where everything

46
00:01:39,909 --> 00:01:41,619
happens pretty much and then we have a

47
00:01:41,619 --> 00:01:42,969
whole lit of random threads you know

48
00:01:42,969 --> 00:01:44,500
there's one our custom memory allocator

49
00:01:44,500 --> 00:01:46,929
of dubious benefit has its own thread

50
00:01:46,929 --> 00:01:50,020
does very little there's a factory said

51
00:01:50,020 --> 00:01:51,729
it's just listening for an accept on a

52
00:01:51,729 --> 00:01:53,499
pipe for some arguments so if you run

53
00:01:53,499 --> 00:01:54,850
another process it just listens there

54
00:01:54,850 --> 00:01:57,189
and handles the thread it does see

55
00:01:57,189 --> 00:01:59,109
nothing there's an update check thread

56
00:01:59,109 --> 00:02:01,179
which it's basically asleep

57
00:02:01,179 --> 00:02:02,799
I don't need quite why we need to run

58
00:02:02,799 --> 00:02:05,740
asleep in a thread but we do we have the

59
00:02:05,740 --> 00:02:08,169
G i/o thread which I give no idea what

60
00:02:08,169 --> 00:02:09,520
it does but it's probably uh this is

61
00:02:09,520 --> 00:02:11,380
under Linux and the ponds audio thread

62
00:02:11,380 --> 00:02:13,510
similarly we often don't play audio but

63
00:02:13,510 --> 00:02:15,070
they're there just in case which is

64
00:02:15,070 --> 00:02:17,560
useful because on Windows the situation

65
00:02:17,560 --> 00:02:18,230
is signal

66
00:02:18,230 --> 00:02:19,849
differently worse we use a thing called

67
00:02:19,849 --> 00:02:21,920
real-time timers on Windows and Windows

68
00:02:21,920 --> 00:02:23,659
as time api's are sufficiently bad that

69
00:02:23,659 --> 00:02:25,069
the way they do this is by creating a

70
00:02:25,069 --> 00:02:26,930
whole pool of threads the presumedly

71
00:02:26,930 --> 00:02:28,430
dumps that do something really dumb and

72
00:02:28,430 --> 00:02:30,620
and GDI of course does this as well it's

73
00:02:30,620 --> 00:02:33,290
normal to have 20 or so threads in a in

74
00:02:33,290 --> 00:02:36,470
a in a libreoffice on Windows and no

75
00:02:36,470 --> 00:02:37,519
concurrency at all

76
00:02:37,519 --> 00:02:38,840
practically that's the that's the

77
00:02:38,840 --> 00:02:39,950
punchline none of them are doing really

78
00:02:39,950 --> 00:02:42,049
anything still if you're not using the

79
00:02:42,049 --> 00:02:43,459
app that's fine right if you're not

80
00:02:43,459 --> 00:02:46,730
doing anything so it's not actually that

81
00:02:46,730 --> 00:02:48,500
bad though we do have some threads that

82
00:02:48,500 --> 00:02:50,360
make some sense I think Devin's config

83
00:02:50,360 --> 00:02:51,890
manager stuff has a nice thread that

84
00:02:51,890 --> 00:02:53,120
sort of spawns off and writes the

85
00:02:53,120 --> 00:02:54,440
configuration when it's when it's needed

86
00:02:54,440 --> 00:02:56,150
in the background which is kind of cool

87
00:02:56,150 --> 00:02:58,790
and increasingly something is quite

88
00:02:58,790 --> 00:03:00,319
short-lived so they actually start and

89
00:03:00,319 --> 00:03:01,879
they end cleanly which is nice so

90
00:03:01,879 --> 00:03:03,049
there's quite a lot of work being done

91
00:03:03,049 --> 00:03:05,780
to to get life cycles right there we now

92
00:03:05,780 --> 00:03:07,400
have a thread pool that even works

93
00:03:07,400 --> 00:03:09,379
amazing thread pools you know writing

94
00:03:09,379 --> 00:03:11,540
them is quite hard and we've done some

95
00:03:11,540 --> 00:03:12,920
work to improve our concurrency

96
00:03:12,920 --> 00:03:14,599
primitives so they're much harder to

97
00:03:14,599 --> 00:03:16,670
screw up with so there are some things

98
00:03:16,670 --> 00:03:18,049
that we do do not just the drawing layer

99
00:03:18,049 --> 00:03:19,849
which is fantastic I added to the bottom

100
00:03:19,849 --> 00:03:21,140
because I didn't know about it till I

101
00:03:21,140 --> 00:03:24,859
saw the talk before and but if you have

102
00:03:24,859 --> 00:03:26,840
huge high fidelity images you want to

103
00:03:26,840 --> 00:03:28,790
scale we do that across as many threads

104
00:03:28,790 --> 00:03:31,730
as we can steal things like zipping ODF

105
00:03:31,730 --> 00:03:33,470
we did a whole lot of profiling work to

106
00:03:33,470 --> 00:03:36,019
find why it's slow to save files and it

107
00:03:36,019 --> 00:03:37,340
turns out that a lot of the time of

108
00:03:37,340 --> 00:03:39,139
zipping stuff deflate is quite expensive

109
00:03:39,139 --> 00:03:41,299
so we spend a lot of time threading that

110
00:03:41,299 --> 00:03:43,310
and optimizing it and then it turned out

111
00:03:43,310 --> 00:03:45,500
we were trying to zip images like if you

112
00:03:45,500 --> 00:03:47,630
zip a JPEG it gets bigger and you just

113
00:03:47,630 --> 00:03:49,579
throw it away at the end so you might as

114
00:03:49,579 --> 00:03:51,980
well just not not bother zipping and

115
00:03:51,980 --> 00:03:54,230
actually the images are most of our

116
00:03:54,230 --> 00:03:56,840
files so although we still have

117
00:03:56,840 --> 00:03:58,310
threading they're actually the real big

118
00:03:58,310 --> 00:04:00,799
win it's not not doing dumb stuff which

119
00:04:00,799 --> 00:04:02,930
is often the way our XML parsing I'll

120
00:04:02,930 --> 00:04:04,790
talk a bit about later we do some

121
00:04:04,790 --> 00:04:07,579
threading there but this is as far as I

122
00:04:07,579 --> 00:04:10,730
recall where the threads are used so why

123
00:04:10,730 --> 00:04:13,160
thread well you know there's a lot of

124
00:04:13,160 --> 00:04:14,629
reasons to thread but but at least the

125
00:04:14,629 --> 00:04:17,839
ones that I like are these so the CPU

126
00:04:17,839 --> 00:04:19,430
has a holida resources we often didn't

127
00:04:19,430 --> 00:04:20,660
think about there are actually great

128
00:04:20,660 --> 00:04:22,910
reasonably limited and things like your

129
00:04:22,910 --> 00:04:25,070
branch predictor your branch predictor

130
00:04:25,070 --> 00:04:27,020
is great but if you do much too

131
00:04:27,020 --> 00:04:28,820
complicated a piece of code suddenly

132
00:04:28,820 --> 00:04:31,290
your performance falls off a cliff

133
00:04:31,290 --> 00:04:33,920
and there is a limited resource there

134
00:04:33,920 --> 00:04:37,050
and of course the less you use it you

135
00:04:37,050 --> 00:04:38,460
know all the the fewer branches you take

136
00:04:38,460 --> 00:04:40,290
the better the job it can do i'm similar

137
00:04:40,290 --> 00:04:42,210
your cash is a very limited size so if

138
00:04:42,210 --> 00:04:43,740
you can partition your work into do this

139
00:04:43,740 --> 00:04:44,940
bit and then do this bit and then do

140
00:04:44,940 --> 00:04:47,100
this bit each bit can work much more

141
00:04:47,100 --> 00:04:49,260
efficiently so you can win even on a

142
00:04:49,260 --> 00:04:50,760
fewer threaded or single threaded

143
00:04:50,760 --> 00:04:53,090
machine

144
00:05:00,269 --> 00:05:02,469
and the more code that the processor has

145
00:05:02,469 --> 00:05:04,899
to decode and turn into its own magic

146
00:05:04,899 --> 00:05:08,139
world of micro ops etc and try and catch

147
00:05:08,139 --> 00:05:09,939
those the more code you're using the

148
00:05:09,939 --> 00:05:11,919
less effective that cache is so the

149
00:05:11,919 --> 00:05:13,539
ideal is to have lots of very small

150
00:05:13,539 --> 00:05:15,610
tight loops doing one thing pending work

151
00:05:15,610 --> 00:05:19,330
on handing work on like this okay so

152
00:05:19,330 --> 00:05:21,039
that really requires a different way to

153
00:05:21,039 --> 00:05:24,909
think about programming really so so XML

154
00:05:24,909 --> 00:05:26,349
parsing I'll talk about in a minute but

155
00:05:26,349 --> 00:05:28,479
really this this whole message passing

156
00:05:28,479 --> 00:05:29,919
thing of doing a little bit of work and

157
00:05:29,919 --> 00:05:30,939
another little bit of work and a lot of

158
00:05:30,939 --> 00:05:32,619
work and parsing these messages along

159
00:05:32,619 --> 00:05:35,919
leads to a very nice safe world the only

160
00:05:35,919 --> 00:05:37,539
problem is that our code is not designed

161
00:05:37,539 --> 00:05:39,489
to do that really at all so you know

162
00:05:39,489 --> 00:05:42,489
this is the ideal yes however technology

163
00:05:42,489 --> 00:05:43,989
change provides opportunity and actually

164
00:05:43,989 --> 00:05:46,749
by using these threads and doing stuff

165
00:05:46,749 --> 00:05:48,279
here we can actually whip the

166
00:05:48,279 --> 00:05:50,800
competition in some interesting ways and

167
00:05:50,800 --> 00:05:52,419
we've done that already you know so

168
00:05:52,419 --> 00:05:55,029
we've made it possible to learn load you

169
00:05:55,029 --> 00:05:56,379
know certain excel sheets faster than

170
00:05:56,379 --> 00:05:58,899
Excel using their file format which is

171
00:05:58,899 --> 00:06:00,759
something I think we can build on and

172
00:06:00,759 --> 00:06:03,279
expand to to lots of other areas and of

173
00:06:03,279 --> 00:06:04,479
course there are plenty of well-known

174
00:06:04,479 --> 00:06:06,969
problems with threading so I'd like to

175
00:06:06,969 --> 00:06:08,860
talk about this just briefly just as

176
00:06:08,860 --> 00:06:11,110
give it flavor for why this is cool so

177
00:06:11,110 --> 00:06:14,289
we can parse an arbitrary sized XML file

178
00:06:14,289 --> 00:06:16,349
and omit sex events in constant time so

179
00:06:16,349 --> 00:06:18,639
there's a caveat the star at the end but

180
00:06:18,639 --> 00:06:19,899
consider this people always talk about

181
00:06:19,899 --> 00:06:21,699
their XML parser somehow mine's faster

182
00:06:21,699 --> 00:06:22,809
than yours and it does these clever

183
00:06:22,809 --> 00:06:23,949
memory map tricks and it doesn't

184
00:06:23,949 --> 00:06:25,719
allocate and doesn't that out of that we

185
00:06:25,719 --> 00:06:26,919
forgot all that we just use a standard

186
00:06:26,919 --> 00:06:29,439
XML parser but we do it in a thread and

187
00:06:29,439 --> 00:06:30,999
then we omit the sax events in the main

188
00:06:30,999 --> 00:06:33,009
thread so as you know the constant time

189
00:06:33,009 --> 00:06:34,959
is pausing the first bit of the file and

190
00:06:34,959 --> 00:06:36,759
after that you're emitting events and

191
00:06:36,759 --> 00:06:39,519
and you would hope that the dominant

192
00:06:39,519 --> 00:06:41,559
cost is the consuming Nick Samoan doing

193
00:06:41,559 --> 00:06:43,179
something with it so effectively you can

194
00:06:43,179 --> 00:06:45,399
get free parsing of any size file

195
00:06:45,399 --> 00:06:48,219
assuming that your consumption is flow

196
00:06:48,219 --> 00:06:51,039
and you have a three for free process of

197
00:06:51,039 --> 00:06:52,719
somewhere however having a free

198
00:06:52,719 --> 00:06:56,319
processor is the easy bit right okay

199
00:06:56,319 --> 00:06:57,339
perfect so we've been doing this for

200
00:06:57,339 --> 00:06:59,619
open XML import from a long time ago

201
00:06:59,619 --> 00:07:02,110
from sunlight 5-0 and actually calc has

202
00:07:02,110 --> 00:07:03,639
been threading concurrent loading of

203
00:07:03,639 --> 00:07:06,489
sheets as well so with occasional data

204
00:07:06,489 --> 00:07:08,680
loss as you see here a recently fixed by

205
00:07:08,680 --> 00:07:11,019
Kohei and we were convinced the bug was

206
00:07:11,019 --> 00:07:13,180
in calc initially or then you

207
00:07:13,180 --> 00:07:14,410
we convinced the bug was in the sacks

208
00:07:14,410 --> 00:07:16,449
passing a thing we spent a long time and

209
00:07:16,449 --> 00:07:17,650
then we found in the end it was in the

210
00:07:17,650 --> 00:07:18,220
package

211
00:07:18,220 --> 00:07:20,680
unzip thing right at the bottom which

212
00:07:20,680 --> 00:07:22,120
has had an you know API so we were

213
00:07:22,120 --> 00:07:24,190
convinced it was thread safe and if you

214
00:07:24,190 --> 00:07:26,199
mean safe by not crashing it's only

215
00:07:26,199 --> 00:07:28,120
didn't crash which was good on the other

216
00:07:28,120 --> 00:07:29,680
hand it has a stream pointer and the

217
00:07:29,680 --> 00:07:32,169
stream API is seek and then read and

218
00:07:32,169 --> 00:07:34,180
with multiple threads reading from the

219
00:07:34,180 --> 00:07:35,680
underlying zip file you could interleave

220
00:07:35,680 --> 00:07:38,110
the seek and read if you're under heavy

221
00:07:38,110 --> 00:07:40,570
load and yes you end up with rubbish

222
00:07:40,570 --> 00:07:42,220
coming out of your zip file as instead

223
00:07:42,220 --> 00:07:42,820
of XML

224
00:07:42,820 --> 00:07:45,699
um so luckily now fixed but you know

225
00:07:45,699 --> 00:07:48,699
there we go so the ODF formats we just

226
00:07:48,699 --> 00:07:50,500
pushed some stuff in five four five four

227
00:07:50,500 --> 00:07:53,130
that will start to thread the ODF format

228
00:07:53,130 --> 00:07:55,930
import so it's actually just one stream

229
00:07:55,930 --> 00:07:57,610
coming in there but again splitting the

230
00:07:57,610 --> 00:07:59,380
passing and the interconnecting and

231
00:07:59,380 --> 00:08:01,630
unzipping from the consuming of the

232
00:08:01,630 --> 00:08:04,120
events and thanks Muhammad Abdul Azim

233
00:08:04,120 --> 00:08:05,380
who did some of this with Google sort of

234
00:08:05,380 --> 00:08:07,240
Kade and switching to the X Fast Pass

235
00:08:07,240 --> 00:08:09,039
let's say there is a hope as we

236
00:08:09,039 --> 00:08:10,780
incrementally move there that ADF import

237
00:08:10,780 --> 00:08:13,389
will speed up significantly and if not

238
00:08:13,389 --> 00:08:15,099
maybe it'll stay the same speed but use

239
00:08:15,099 --> 00:08:18,940
more energy you know so where else can

240
00:08:18,940 --> 00:08:20,530
we win this is the speculative bit of

241
00:08:20,530 --> 00:08:22,300
the talk where you're all inspired to

242
00:08:22,300 --> 00:08:23,830
throw tomatoes and get involved with

243
00:08:23,830 --> 00:08:27,789
doing fun stuff so XML parsing can still

244
00:08:27,789 --> 00:08:29,889
be improved I think so there's a zipping

245
00:08:29,889 --> 00:08:32,708
unzipping actually takes some percentage

246
00:08:32,708 --> 00:08:35,440
of our import time something like 15% I

247
00:08:35,440 --> 00:08:37,450
think maybe it's only 10 I I forget

248
00:08:37,450 --> 00:08:38,950
something like that so we can put that

249
00:08:38,950 --> 00:08:40,630
in another thread so you have unzip and

250
00:08:40,630 --> 00:08:42,599
then you have taken eyes and and so on

251
00:08:42,599 --> 00:08:45,160
unfortunate XML parsing is really

252
00:08:45,160 --> 00:08:47,950
expensive unbelievably expensive its

253
00:08:47,950 --> 00:08:50,050
namespaces it's funny attributes its

254
00:08:50,050 --> 00:08:51,820
entities it's you know just the basic

255
00:08:51,820 --> 00:08:54,190
inner loop of that parser is it's just

256
00:08:54,190 --> 00:08:56,170
nasty and and it's checking that there

257
00:08:56,170 --> 00:08:58,360
are no duplicate namespaces and okay

258
00:08:58,360 --> 00:09:00,540
it's worse than you might think

259
00:09:00,540 --> 00:09:02,950
so quite possibly we want some kind of

260
00:09:02,950 --> 00:09:04,779
look ahead parser that's going to jump

261
00:09:04,779 --> 00:09:07,120
head in your file and start preeto

262
00:09:07,120 --> 00:09:10,630
conniving it maybe I don't know XML

263
00:09:10,630 --> 00:09:12,010
parsing is something a lot of people do

264
00:09:12,010 --> 00:09:13,270
if we could you know come up with a

265
00:09:13,270 --> 00:09:15,310
better approach unfortunately you can't

266
00:09:15,310 --> 00:09:17,110
take a nice early because namespaces can

267
00:09:17,110 --> 00:09:20,140
change fully but you know you can have a

268
00:09:20,140 --> 00:09:22,570
go and so we get some pretty big files I

269
00:09:22,570 --> 00:09:24,160
mean it's reasonably normal if you have

270
00:09:24,160 --> 00:09:25,779
a large spreadsheet to get you know 100

271
00:09:25,779 --> 00:09:26,950
megabytes of X

272
00:09:26,950 --> 00:09:29,350
in two parts so you know small XML files

273
00:09:29,350 --> 00:09:32,709
great but big ones highly repetitive are

274
00:09:32,709 --> 00:09:34,180
pretty bad so probably will need to do

275
00:09:34,180 --> 00:09:37,510
something there images handling' images

276
00:09:37,510 --> 00:09:39,160
is particularly slow I mentioned earlier

277
00:09:39,160 --> 00:09:41,649
they're the dominant memory object that

278
00:09:41,649 --> 00:09:43,810
we deal with and they're getting worse

279
00:09:43,810 --> 00:09:45,310
people's cameras are getting bigger and

280
00:09:45,310 --> 00:09:47,620
higher resolution so you know 100 pages

281
00:09:47,620 --> 00:09:48,730
of text or something is about 5

282
00:09:48,730 --> 00:09:52,209
megabytes of memory but one image is

283
00:09:52,209 --> 00:09:54,699
easily that right so how many hundreds

284
00:09:54,699 --> 00:09:56,350
of pages you write but you probably put

285
00:09:56,350 --> 00:09:57,970
images in because they're worth a

286
00:09:57,970 --> 00:10:00,519
thousand words right anyway

287
00:10:00,519 --> 00:10:04,060
good so very high resolution words that

288
00:10:04,060 --> 00:10:07,209
say so I'm sorry in the trending is a

289
00:10:07,209 --> 00:10:09,100
bit of a mess but we can fix that and we

290
00:10:09,100 --> 00:10:10,750
have opaque image handles luckily our

291
00:10:10,750 --> 00:10:13,180
history has gone in sort of revolutions

292
00:10:13,180 --> 00:10:15,730
from very old slavery and I'm actually

293
00:10:15,730 --> 00:10:16,990
the very ancient hardware that we had

294
00:10:16,990 --> 00:10:18,610
with a Paik image handles is not

295
00:10:18,610 --> 00:10:20,050
dissimilar from the very modern hardware

296
00:10:20,050 --> 00:10:21,940
we have just in between times they went

297
00:10:21,940 --> 00:10:24,790
via the CPU CPU just say actually we

298
00:10:24,790 --> 00:10:26,529
should be able to cue our image loading

299
00:10:26,529 --> 00:10:27,820
and immediately our image load be

300
00:10:27,820 --> 00:10:29,199
immediate but only when you actually

301
00:10:29,199 --> 00:10:31,060
access the data or render its we then

302
00:10:31,060 --> 00:10:32,920
take the hit so that we can cool these

303
00:10:32,920 --> 00:10:35,170
things load our whole toolbar in in

304
00:10:35,170 --> 00:10:36,699
parallel decompress all those pings

305
00:10:36,699 --> 00:10:38,079
allocate the memory do all the good

306
00:10:38,079 --> 00:10:41,199
stuff so so that would pretty nice

307
00:10:41,199 --> 00:10:44,050
isolated change and be quite helpful for

308
00:10:44,050 --> 00:10:45,850
rich presentations with lots of images

309
00:10:45,850 --> 00:10:48,880
my mine you notice lots of images anyway

310
00:10:48,880 --> 00:10:52,600
DCL windows so on windows we have this

311
00:10:52,600 --> 00:10:55,510
disaster area whereas on windows message

312
00:10:55,510 --> 00:10:56,740
queues that's thread of fine so if you

313
00:10:56,740 --> 00:10:59,440
create a window in a thread it knows

314
00:10:59,440 --> 00:11:01,540
which thread it was created in and you

315
00:11:01,540 --> 00:11:02,980
have to destroy it in that thread you

316
00:11:02,980 --> 00:11:04,660
have to ask for GDI resources in that

317
00:11:04,660 --> 00:11:06,880
thread and stuff which is bad because

318
00:11:06,880 --> 00:11:08,709
our we have a sort of thread safe widget

319
00:11:08,709 --> 00:11:10,300
scripting API that can spawn threads

320
00:11:10,300 --> 00:11:12,370
create windows and threads

321
00:11:12,370 --> 00:11:15,300
you know just it's really not nice and

322
00:11:15,300 --> 00:11:17,769
yes so we have all of these events that

323
00:11:17,769 --> 00:11:19,300
we try and push across into the main

324
00:11:19,300 --> 00:11:23,019
thread to do staff or the there's just

325
00:11:23,019 --> 00:11:24,579
absolute bunch of Horrors here and

326
00:11:24,579 --> 00:11:25,990
Michael star spends lots of time fixing

327
00:11:25,990 --> 00:11:28,540
deadlocks and hangs and things and tests

328
00:11:28,540 --> 00:11:30,699
and you have these horrible uncontrolled

329
00:11:30,699 --> 00:11:32,260
re-entrance e hazards so every time you

330
00:11:32,260 --> 00:11:33,490
wait on a condition you've got to be

331
00:11:33,490 --> 00:11:35,529
prepared not to fully block that thread

332
00:11:35,529 --> 00:11:37,089
because you might need to do one of

333
00:11:37,089 --> 00:11:38,560
these horrible windows operations that

334
00:11:38,560 --> 00:11:40,540
comes in and so just it's

335
00:11:40,540 --> 00:11:42,670
screws up your threading abstraction and

336
00:11:42,670 --> 00:11:44,290
it makes well it's a nightmare

337
00:11:44,290 --> 00:11:45,760
basically so wouldn't it be nice just

338
00:11:45,760 --> 00:11:47,080
have a have a thread that actually did

339
00:11:47,080 --> 00:11:48,280
something once in a while which would be

340
00:11:48,280 --> 00:11:50,470
creating Windows you know move all of

341
00:11:50,470 --> 00:11:52,540
this out into a place so you know that

342
00:11:52,540 --> 00:11:53,710
when you send a message you're not going

343
00:11:53,710 --> 00:11:55,420
to deadlock or block or do anything

344
00:11:55,420 --> 00:11:58,630
stupid now while you're there another

345
00:11:58,630 --> 00:12:00,070
thing we could be doing is actually

346
00:12:00,070 --> 00:12:01,660
doing our rendering in another threat

347
00:12:01,660 --> 00:12:03,100
now we have a mess file but of course

348
00:12:03,100 --> 00:12:04,510
the meta file is also a file format

349
00:12:04,510 --> 00:12:06,430
which is a bit of a disaster area and

350
00:12:06,430 --> 00:12:08,740
it's also a limited subset of what VCL

351
00:12:08,740 --> 00:12:12,190
does so kwikki has actually a patch to

352
00:12:12,190 --> 00:12:14,320
try and refactor this into to two pieces

353
00:12:14,320 --> 00:12:16,060
and it's potentially possible we've not

354
00:12:16,060 --> 00:12:18,070
we've done some research but you know

355
00:12:18,070 --> 00:12:19,480
the way we could split this out and do

356
00:12:19,480 --> 00:12:21,310
our rendering in a separate thread so

357
00:12:21,310 --> 00:12:22,690
you can start doing your document layout

358
00:12:22,690 --> 00:12:24,640
and text measuring in right here an

359
00:12:24,640 --> 00:12:26,550
actual rendering in the other thread

360
00:12:26,550 --> 00:12:28,540
that needs a lot of work around

361
00:12:28,540 --> 00:12:31,870
immutable structures safe safe things

362
00:12:31,870 --> 00:12:33,520
that you can share between between

363
00:12:33,520 --> 00:12:35,890
threads it might work if you have a

364
00:12:35,890 --> 00:12:37,180
thread there it would be nice it would

365
00:12:37,180 --> 00:12:38,980
really help with OpenGL which doesn't

366
00:12:38,980 --> 00:12:41,410
like threads despite the advertising to

367
00:12:41,410 --> 00:12:43,050
have all of the rendering in one place

368
00:12:43,050 --> 00:12:46,120
with one context if you've used OpenGL

369
00:12:46,120 --> 00:12:47,290
you'll know that it's just terrible has

370
00:12:47,290 --> 00:12:49,150
all this implicit thread local state I

371
00:12:49,150 --> 00:12:50,890
mean be really nice and all say there

372
00:12:50,890 --> 00:12:52,180
are some things we've always struggled

373
00:12:52,180 --> 00:12:54,550
with like progress bars so if you want

374
00:12:54,550 --> 00:12:55,690
to render a progress bar on your one

375
00:12:55,690 --> 00:12:57,610
thread application you need to spin the

376
00:12:57,610 --> 00:12:58,990
main loop and so you have this yield

377
00:12:58,990 --> 00:13:00,970
that goes on while you're while you're

378
00:13:00,970 --> 00:13:02,260
doing something you yield and the

379
00:13:02,260 --> 00:13:04,510
progress bar moves and hopefully nothing

380
00:13:04,510 --> 00:13:06,400
else comes in that's really bad at that

381
00:13:06,400 --> 00:13:09,340
point and we live on optimism but

382
00:13:09,340 --> 00:13:10,390
wouldn't it be nice if you'd have a

383
00:13:10,390 --> 00:13:11,620
progress bar that lived in another

384
00:13:11,620 --> 00:13:12,970
thread that carried on rendering and

385
00:13:12,970 --> 00:13:15,280
updating itself sensibly and while you

386
00:13:15,280 --> 00:13:16,870
carried on doing what you were doing I'm

387
00:13:16,870 --> 00:13:18,670
removing another horrible uncontrolled

388
00:13:18,670 --> 00:13:22,150
reentry point there are smaller pieces

389
00:13:22,150 --> 00:13:24,910
we can do so there are various tools one

390
00:13:24,910 --> 00:13:26,440
of the things I do so rust is the new

391
00:13:26,440 --> 00:13:28,300
trendy language right you know we want

392
00:13:28,300 --> 00:13:30,850
to add safe concurrency so why not throw

393
00:13:30,850 --> 00:13:32,320
away the whole language for most of it

394
00:13:32,320 --> 00:13:33,850
and start writing new compiler and and

395
00:13:33,850 --> 00:13:36,600
stuff and

