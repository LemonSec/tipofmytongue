1
00:00:04,590 --> 00:00:08,250
our next speaker is Theodore who will be

2
00:00:08,250 --> 00:00:10,920
guiding us through all the projects and

3
00:00:10,920 --> 00:00:12,959
things that you might need to know about

4
00:00:12,959 --> 00:00:17,430
if you're doing machinery thank you so

5
00:00:17,430 --> 00:00:19,320
my name is Theodore I'm a researcher at

6
00:00:19,320 --> 00:00:21,240
the Swedish astute of computer science I

7
00:00:21,240 --> 00:00:23,009
work on large K machine learning systems

8
00:00:23,009 --> 00:00:25,560
and the goal for today's presentations

9
00:00:25,560 --> 00:00:27,660
is to just put out some guidelines for

10
00:00:27,660 --> 00:00:29,939
people looking into putting their first

11
00:00:29,939 --> 00:00:31,890
machine learning project into production

12
00:00:31,890 --> 00:00:34,350
so the idea is that the you already have

13
00:00:34,350 --> 00:00:35,790
a product you have some data gathered

14
00:00:35,790 --> 00:00:37,530
and you would like to use a machine

15
00:00:37,530 --> 00:00:38,850
learning in order to improve some parts

16
00:00:38,850 --> 00:00:40,920
of it and one thing that I should

17
00:00:40,920 --> 00:00:42,660
clarify from the beginning that almost

18
00:00:42,660 --> 00:00:43,770
all of the things that I will present

19
00:00:43,770 --> 00:00:45,540
here was not written by me but by other

20
00:00:45,540 --> 00:00:47,340
much more experienced people and what

21
00:00:47,340 --> 00:00:48,570
I've done here is that just I've

22
00:00:48,570 --> 00:00:50,010
gathered all them all together and put

23
00:00:50,010 --> 00:00:51,210
them in context in order to make them

24
00:00:51,210 --> 00:00:53,550
more useful and all the sources that I

25
00:00:53,550 --> 00:00:54,720
have used are of course included that

26
00:00:54,720 --> 00:00:58,110
they at the end of the presentation so

27
00:00:58,110 --> 00:01:00,180
we'll just jump straight ahead into the

28
00:01:00,180 --> 00:01:02,690
content and we see how we move

29
00:01:02,690 --> 00:01:04,890
essentially from an idea into something

30
00:01:04,890 --> 00:01:06,509
that we can actually put in production

31
00:01:06,509 --> 00:01:08,909
machine learning and what I'll try to do

32
00:01:08,909 --> 00:01:11,939
is present a simple framework that we

33
00:01:11,939 --> 00:01:13,649
can use to think about most machine

34
00:01:13,649 --> 00:01:16,439
learning problems and one thing that I

35
00:01:16,439 --> 00:01:17,820
found very useful definitely as a

36
00:01:17,820 --> 00:01:20,219
programmer is to create interfaces for

37
00:01:20,219 --> 00:01:22,740
things so what we do is we find common

38
00:01:22,740 --> 00:01:25,590
things that all our problems have in

39
00:01:25,590 --> 00:01:28,829
common and then we use this that

40
00:01:28,829 --> 00:01:30,149
language in order to describe what we

41
00:01:30,149 --> 00:01:32,939
want to do so then we can do the same

42
00:01:32,939 --> 00:01:34,259
actually for machine learning problems

43
00:01:34,259 --> 00:01:35,759
and what we can try to figure out what

44
00:01:35,759 --> 00:01:36,659
are the things that machine learning

45
00:01:36,659 --> 00:01:39,630
problems also have in common so the

46
00:01:39,630 --> 00:01:41,429
first thing that we have in common is

47
00:01:41,429 --> 00:01:42,689
definitely the reason that we're using

48
00:01:42,689 --> 00:01:44,429
machine learning in the first place is

49
00:01:44,429 --> 00:01:46,499
that we want to describe the behavior of

50
00:01:46,499 --> 00:01:48,509
a very complex system and because the

51
00:01:48,509 --> 00:01:50,219
behavior is very complicated it's not

52
00:01:50,219 --> 00:01:51,630
possible for us to sit down and actually

53
00:01:51,630 --> 00:01:53,579
write a program for it we need some kind

54
00:01:53,579 --> 00:01:56,850
of algorithm that will learn it and in

55
00:01:56,850 --> 00:01:57,929
order to do that we need a way to

56
00:01:57,929 --> 00:01:59,850
describe the system in a way that is

57
00:01:59,850 --> 00:02:01,799
concise and understandable and this is

58
00:02:01,799 --> 00:02:03,479
what models do for us right they allow

59
00:02:03,479 --> 00:02:05,789
us to reason about this complex behavior

60
00:02:05,789 --> 00:02:08,310
in a mathematical language and the

61
00:02:08,310 --> 00:02:09,508
second thing that all machine learning

62
00:02:09,508 --> 00:02:11,970
problems have in common is data so in

63
00:02:11,970 --> 00:02:13,140
machine learning almost all of the

64
00:02:13,140 --> 00:02:14,280
models that we're going to use are

65
00:02:14,280 --> 00:02:15,989
statistical models and what that means

66
00:02:15,989 --> 00:02:17,640
is that we make assumptions about how

67
00:02:17,640 --> 00:02:18,360
the world behave

68
00:02:18,360 --> 00:02:19,950
and then we use the data the

69
00:02:19,950 --> 00:02:21,360
observations that we have in order to

70
00:02:21,360 --> 00:02:22,680
narrow down the assumptions in order

71
00:02:22,680 --> 00:02:25,470
that is much more specific so we always

72
00:02:25,470 --> 00:02:26,790
need data in order to train our

73
00:02:26,790 --> 00:02:29,250
algorithms and one thing that we

74
00:02:29,250 --> 00:02:30,870
definitely need is to be able to tell

75
00:02:30,870 --> 00:02:33,590
and how well our model is able to

76
00:02:33,590 --> 00:02:36,480
emulate the behavior that behavior so we

77
00:02:36,480 --> 00:02:37,890
need to some way to estimate the quality

78
00:02:37,890 --> 00:02:40,140
of the model and something that can

79
00:02:40,140 --> 00:02:41,610
guide us when we are trying to optimize

80
00:02:41,610 --> 00:02:45,960
the model and so that is our objective

81
00:02:45,960 --> 00:02:47,880
function basically so an objective

82
00:02:47,880 --> 00:02:48,990
function is the measure of the quality

83
00:02:48,990 --> 00:02:50,880
of our model so for example if we're

84
00:02:50,880 --> 00:02:51,990
trying to predict the temperature

85
00:02:51,990 --> 00:02:53,610
tomorrow an objective function could be

86
00:02:53,610 --> 00:02:55,470
the squared difference of the actual

87
00:02:55,470 --> 00:02:56,640
temperature versus the temperature that

88
00:02:56,640 --> 00:02:57,630
being predicted

89
00:02:57,630 --> 00:03:00,570
right and next we might have some

90
00:03:00,570 --> 00:03:02,790
knowledge and desires about the model so

91
00:03:02,790 --> 00:03:04,590
for examples maybe in our data set we

92
00:03:04,590 --> 00:03:06,600
have 10000 features but our assumption

93
00:03:06,600 --> 00:03:08,250
or our desire is that only a few of them

94
00:03:08,250 --> 00:03:10,230
are actually relevant so we might use

95
00:03:10,230 --> 00:03:12,270
something like regularization or our

96
00:03:12,270 --> 00:03:13,980
prior knowledge about the problem in

97
00:03:13,980 --> 00:03:15,120
order to bring down the end the number

98
00:03:15,120 --> 00:03:18,600
of features that we have and if we

99
00:03:18,600 --> 00:03:20,160
combine all of these then we get our

100
00:03:20,160 --> 00:03:22,230
machine learning program so my signaling

101
00:03:22,230 --> 00:03:24,360
program essentially is a function that

102
00:03:24,360 --> 00:03:26,040
takes the model that we have the data

103
00:03:26,040 --> 00:03:27,450
that we have and it provides an answer

104
00:03:27,450 --> 00:03:29,730
and in order to optimize this function

105
00:03:29,730 --> 00:03:31,080
we use the objective function that we

106
00:03:31,080 --> 00:03:34,050
have been created and this is usually

107
00:03:34,050 --> 00:03:36,120
done in an iterative manner where we

108
00:03:36,120 --> 00:03:37,739
take the model that we have and we

109
00:03:37,739 --> 00:03:39,330
update it by taking a look at the data

110
00:03:39,330 --> 00:03:40,860
and we do this again and again until we

111
00:03:40,860 --> 00:03:42,300
are satisfied with the quality of our

112
00:03:42,300 --> 00:03:44,790
model and all of these are the basic

113
00:03:44,790 --> 00:03:46,500
primitives that can we can use to

114
00:03:46,500 --> 00:03:47,850
describe almost any machine learning

115
00:03:47,850 --> 00:03:49,950
problem and we can see how this works in

116
00:03:49,950 --> 00:03:52,530
a specific example so let's say that we

117
00:03:52,530 --> 00:03:54,480
are Twitter and we observe that our

118
00:03:54,480 --> 00:03:56,190
users are leaving the platform and never

119
00:03:56,190 --> 00:03:58,739
returning and after some research we

120
00:03:58,739 --> 00:04:01,410
decide or we discover that users users

121
00:04:01,410 --> 00:04:03,420
that live usually do not engage with the

122
00:04:03,420 --> 00:04:05,640
platform and we what we decide to do as

123
00:04:05,640 --> 00:04:06,930
a solution is we try to increase the

124
00:04:06,930 --> 00:04:08,340
engagement of the users by trying to

125
00:04:08,340 --> 00:04:10,050
make them to read through it more and

126
00:04:10,050 --> 00:04:11,610
this is actually what the engineering

127
00:04:11,610 --> 00:04:12,870
decision started so this is something

128
00:04:12,870 --> 00:04:14,340
that the management could do for example

129
00:04:14,340 --> 00:04:17,548
up until now so the engineering decision

130
00:04:17,548 --> 00:04:19,890
is that we can that we can make is we

131
00:04:19,890 --> 00:04:21,600
can take this interface that we created

132
00:04:21,600 --> 00:04:23,250
before and then just fill in the blanks

133
00:04:23,250 --> 00:04:26,310
in order to solve our problem so first

134
00:04:26,310 --> 00:04:28,020
we have the common components and we

135
00:04:28,020 --> 00:04:29,580
start out of course as always with the

136
00:04:29,580 --> 00:04:31,080
data and the data that we have is

137
00:04:31,080 --> 00:04:32,130
features about

138
00:04:32,130 --> 00:04:33,960
the user themselves like the profile of

139
00:04:33,960 --> 00:04:36,030
the user and we have a features about

140
00:04:36,030 --> 00:04:37,440
the tweet the word that contains

141
00:04:37,440 --> 00:04:39,690
hashtags everything and then we have the

142
00:04:39,690 --> 00:04:42,750
labels which is the decision or what we

143
00:04:42,750 --> 00:04:44,730
have observed this tweet get retweeted

144
00:04:44,730 --> 00:04:46,500
by a specific user that would be the Y

145
00:04:46,500 --> 00:04:49,160
in our case what we're trying to predict

146
00:04:49,160 --> 00:04:51,990
next up is our model so what we said is

147
00:04:51,990 --> 00:04:53,370
what we want to find tweets that are

148
00:04:53,370 --> 00:04:55,650
more likely to be retweeted so ideally

149
00:04:55,650 --> 00:04:59,190
we want to have a probability as an

150
00:04:59,190 --> 00:05:01,170
output from our model and logistic

151
00:05:01,170 --> 00:05:02,730
regression here is a very good first

152
00:05:02,730 --> 00:05:04,260
model to try because it's a well studied

153
00:05:04,260 --> 00:05:06,060
classification algorithm and it gives us

154
00:05:06,060 --> 00:05:09,540
probabilistic out and in this particular

155
00:05:09,540 --> 00:05:11,730
model the model itself the logistic

156
00:05:11,730 --> 00:05:13,020
regression will actually give us the

157
00:05:13,020 --> 00:05:14,460
objective function as well so we take

158
00:05:14,460 --> 00:05:17,280
that as a given and you should know we

159
00:05:17,280 --> 00:05:18,930
should know that the more flexible

160
00:05:18,930 --> 00:05:20,940
algorithms we can actually sit down and

161
00:05:20,940 --> 00:05:22,380
design our own objective function in

162
00:05:22,380 --> 00:05:24,320
order to fit our problem much better

163
00:05:24,320 --> 00:05:26,670
and finally we choose which algorithm

164
00:05:26,670 --> 00:05:28,440
we're going to use to optimize the

165
00:05:28,440 --> 00:05:30,780
objective function and one thing that I

166
00:05:30,780 --> 00:05:32,310
should note is that pretty much you're

167
00:05:32,310 --> 00:05:34,290
done with the algorithm design at this

168
00:05:34,290 --> 00:05:36,000
point but there is a bunch of other

169
00:05:36,000 --> 00:05:37,620
problems that might come up and come up

170
00:05:37,620 --> 00:05:39,540
as you go from the data all the way down

171
00:05:39,540 --> 00:05:40,980
to the algorithm and what they presented

172
00:05:40,980 --> 00:05:43,140
here is very simplified a lot can go

173
00:05:43,140 --> 00:05:45,060
wrong if we're not carefully and we're

174
00:05:45,060 --> 00:05:46,890
going to talk a lot a bit more about

175
00:05:46,890 --> 00:05:51,330
these problems now so data is the common

176
00:05:51,330 --> 00:05:53,100
thing FM underpins all machine learning

177
00:05:53,100 --> 00:05:54,330
problems and it's perhaps the most

178
00:05:54,330 --> 00:05:57,570
important part of your pipeline in data

179
00:05:57,570 --> 00:05:59,520
came in can come in with millions of

180
00:05:59,520 --> 00:06:00,960
problems we can have measurement errors

181
00:06:00,960 --> 00:06:02,580
we can have privacy issues we can have

182
00:06:02,580 --> 00:06:05,850
even spread spread seed the errors in a

183
00:06:05,850 --> 00:06:08,100
function and in machine learning I think

184
00:06:08,100 --> 00:06:10,260
most pressingly as in most principles

185
00:06:10,260 --> 00:06:12,360
the output that we're going to get from

186
00:06:12,360 --> 00:06:13,980
a la algorithm is only going to be as

187
00:06:13,980 --> 00:06:16,230
good as the input that we give it and

188
00:06:16,230 --> 00:06:18,690
what we want to do here is to get to

189
00:06:18,690 --> 00:06:21,540
find a way to to quality to quantify the

190
00:06:21,540 --> 00:06:23,040
quality of our data in a principled

191
00:06:23,040 --> 00:06:26,280
manner and need Lauren's here is a

192
00:06:26,280 --> 00:06:28,050
researcher from a sample University she

193
00:06:28,050 --> 00:06:30,660
works a lot with in medicine which has

194
00:06:30,660 --> 00:06:33,030
not only bought datasets and he recently

195
00:06:33,030 --> 00:06:35,370
presented the idea of data rate and

196
00:06:35,370 --> 00:06:37,520
readiness which I'll try to explain here

197
00:06:37,520 --> 00:06:40,140
so what we want to do is we want to make

198
00:06:40,140 --> 00:06:41,730
it easier to reason about how

199
00:06:41,730 --> 00:06:43,050
appropriate the data set that we

200
00:06:43,050 --> 00:06:45,600
currently have is for learning so what

201
00:06:45,600 --> 00:06:47,160
this is that we create different levels

202
00:06:47,160 --> 00:06:49,410
of readiness for our data set and we

203
00:06:49,410 --> 00:06:51,510
move from one level to the next and when

204
00:06:51,510 --> 00:06:53,550
we are sure that they are data fulfills

205
00:06:53,550 --> 00:06:56,700
certain quality criteria so we can start

206
00:06:56,700 --> 00:06:57,930
by having three bands for these

207
00:06:57,930 --> 00:07:00,240
different levels let's say C B and a and

208
00:07:00,240 --> 00:07:01,950
maybe we can create sub levels for each

209
00:07:01,950 --> 00:07:05,070
one of those so the lowest band is bad C

210
00:07:05,070 --> 00:07:07,110
and it's about the accessibility of our

211
00:07:07,110 --> 00:07:09,300
data so when starting out at this level

212
00:07:09,300 --> 00:07:11,070
we might actually have what we call a

213
00:07:11,070 --> 00:07:13,800
hearsay data data that somebody has told

214
00:07:13,800 --> 00:07:15,450
you exists but it does you're not

215
00:07:15,450 --> 00:07:17,100
actually sure if it's there so this is

216
00:07:17,100 --> 00:07:18,630
very commonly when starting out a new

217
00:07:18,630 --> 00:07:20,490
machine learning project where you might

218
00:07:20,490 --> 00:07:22,620
hear from other teams like yeah we

219
00:07:22,620 --> 00:07:24,180
should have that or we have we are

220
00:07:24,180 --> 00:07:25,770
logging it out or we have been logging

221
00:07:25,770 --> 00:07:27,390
that for many years but until you

222
00:07:27,390 --> 00:07:29,040
actually sit down extract the data set

223
00:07:29,040 --> 00:07:30,690
and look at it there's no way that you

224
00:07:30,690 --> 00:07:32,700
can actually be sure about this so in

225
00:07:32,700 --> 00:07:34,140
order to graduate your data set from

226
00:07:34,140 --> 00:07:36,060
this level you need to ensure first that

227
00:07:36,060 --> 00:07:38,040
they data exist what kind of format it

228
00:07:38,040 --> 00:07:40,010
comes in if there is any privacy

229
00:07:40,010 --> 00:07:42,660
concerns or legal concerns in using it

230
00:07:42,660 --> 00:07:45,090
and anything that can can make it

231
00:07:45,090 --> 00:07:46,710
difficult to actually obtain the data so

232
00:07:46,710 --> 00:07:48,540
and at the end of this level which say

233
00:07:48,540 --> 00:07:50,850
we can call it C 1 and we have cleared

234
00:07:50,850 --> 00:07:52,530
all these obstacles and the data set is

235
00:07:52,530 --> 00:07:53,910
actually ready to be loaded into

236
00:07:53,910 --> 00:07:57,870
analysis software then at level B we are

237
00:07:57,870 --> 00:07:59,310
concerned with the faithfulness of the

238
00:07:59,310 --> 00:08:02,130
data so first of all the data that we

239
00:08:02,130 --> 00:08:04,260
have actually record the correct thing

240
00:08:04,260 --> 00:08:06,210
and what is the level of error in the

241
00:08:06,210 --> 00:08:08,040
measurements and did any sampling occur

242
00:08:08,040 --> 00:08:10,440
in the in the in the data and how did we

243
00:08:10,440 --> 00:08:13,110
treat the missing values so all of these

244
00:08:13,110 --> 00:08:14,460
things are very important in order to

245
00:08:14,460 --> 00:08:16,110
graduate this level we need to be fully

246
00:08:16,110 --> 00:08:17,910
aware of the faithfulness of our of our

247
00:08:17,910 --> 00:08:20,010
data about the representation and the

248
00:08:20,010 --> 00:08:22,080
truth that is actually from that comes

249
00:08:22,080 --> 00:08:24,530
from what we originally wanted to record

250
00:08:24,530 --> 00:08:28,290
and one day which is the last level is

251
00:08:28,290 --> 00:08:29,760
the first level where we can actually

252
00:08:29,760 --> 00:08:32,340
make questions about how appropriate the

253
00:08:32,340 --> 00:08:34,229
data is for what we're trying to answer

254
00:08:34,229 --> 00:08:36,059
so here is the first time that we

255
00:08:36,059 --> 00:08:38,309
actually answer can we use this data set

256
00:08:38,309 --> 00:08:41,159
want to predict add clicks from users or

257
00:08:41,159 --> 00:08:43,380
can we use this data set to predict how

258
00:08:43,380 --> 00:08:45,390
the time to failure for a specific

259
00:08:45,390 --> 00:08:48,030
component and here we might actually

260
00:08:48,030 --> 00:08:49,650
discover that we may need additional

261
00:08:49,650 --> 00:08:51,960
data sets we may need human annotation

262
00:08:51,960 --> 00:08:53,700
we may need to iterate through the whole

263
00:08:53,700 --> 00:08:55,500
pipeline again so again this is an

264
00:08:55,500 --> 00:08:57,330
iterative process and every time that

265
00:08:57,330 --> 00:08:58,470
you discover that you need some more

266
00:08:58,470 --> 00:08:59,510
data set you need to go through

267
00:08:59,510 --> 00:09:00,770
the whole thing again and make sure that

268
00:09:00,770 --> 00:09:02,420
the data said that you have at the end

269
00:09:02,420 --> 00:09:04,220
is actually fulfills all the quality

270
00:09:04,220 --> 00:09:08,450
criteria and the idea with these levels

271
00:09:08,450 --> 00:09:10,130
is to provide a common language so teams

272
00:09:10,130 --> 00:09:11,990
can communicate their data readiness

273
00:09:11,990 --> 00:09:13,610
levels and we can ask ask and answer

274
00:09:13,610 --> 00:09:15,470
concrete questions about the state of

275
00:09:15,470 --> 00:09:17,450
the data and trying to skip any of these

276
00:09:17,450 --> 00:09:19,580
parts will almost always leads a lead to

277
00:09:19,580 --> 00:09:22,100
problems and that's a final warning do

278
00:09:22,100 --> 00:09:23,750
not underestimate the time and effort

279
00:09:23,750 --> 00:09:25,250
required to bring this data from the

280
00:09:25,250 --> 00:09:27,530
level C and B and they perhaps am a

281
00:09:27,530 --> 00:09:28,910
least exciting we have a branch but they

282
00:09:28,910 --> 00:09:34,370
are all equally important so next after

283
00:09:34,370 --> 00:09:36,080
you selected your objective function and

284
00:09:36,080 --> 00:09:37,640
ensure that your data is in a good state

285
00:09:37,640 --> 00:09:39,860
to learn from what comes up is the

286
00:09:39,860 --> 00:09:41,390
selection of your software and your

287
00:09:41,390 --> 00:09:43,730
algorithm so I've labeled this here as

288
00:09:43,730 --> 00:09:45,800
easy choices because I actually believe

289
00:09:45,800 --> 00:09:46,970
that the other parts of your pipeline

290
00:09:46,970 --> 00:09:48,620
are much more important for the success

291
00:09:48,620 --> 00:09:53,000
of your of your product launch so when I

292
00:09:53,000 --> 00:09:53,960
was first thinking about this

293
00:09:53,960 --> 00:09:55,520
presentation I had to image this in mind

294
00:09:55,520 --> 00:09:57,290
the first one is this one from

295
00:09:57,290 --> 00:09:57,950
scikit-learn

296
00:09:57,950 --> 00:09:59,720
which is kind of like it's its it to

297
00:09:59,720 --> 00:10:01,190
guide people in order to select a

298
00:10:01,190 --> 00:10:03,740
specific algorithm and you can already

299
00:10:03,740 --> 00:10:04,910
see that there is a multitude of

300
00:10:04,910 --> 00:10:06,350
algorithmic choices but there's not too

301
00:10:06,350 --> 00:10:08,090
many so here I call this a farm it's not

302
00:10:08,090 --> 00:10:10,610
enough animals here and the second one

303
00:10:10,610 --> 00:10:11,840
this one is from the Assam of a

304
00:10:11,840 --> 00:10:13,100
Institute where they try to illustrate

305
00:10:13,100 --> 00:10:15,710
some of the most popular and neural

306
00:10:15,710 --> 00:10:18,290
network architectures and my point here

307
00:10:18,290 --> 00:10:20,300
with these two images is that already at

308
00:10:20,300 --> 00:10:21,860
algorithm so it is a staggering amount

309
00:10:21,860 --> 00:10:24,200
of choices that you have to make and the

310
00:10:24,200 --> 00:10:26,090
reality is that for your first load this

311
00:10:26,090 --> 00:10:28,250
is mostly unnecessary for your first

312
00:10:28,250 --> 00:10:29,870
launch but you should be focusing on its

313
00:10:29,870 --> 00:10:32,000
simplicity and there are a lot of good

314
00:10:32,000 --> 00:10:34,610
reasons to for that and we'll see those

315
00:10:34,610 --> 00:10:37,910
next so if you've read a couple of

316
00:10:37,910 --> 00:10:39,440
things about the machine learning you

317
00:10:39,440 --> 00:10:41,300
probably come across this suggestion

318
00:10:41,300 --> 00:10:43,400
we're picking the the simplest most

319
00:10:43,400 --> 00:10:45,680
model possible is often motivated by

320
00:10:45,680 --> 00:10:47,450
theoretically by things like Occam's

321
00:10:47,450 --> 00:10:50,210
razor or the the census so forward

322
00:10:50,210 --> 00:10:52,730
fitting if you use a complex model but

323
00:10:52,730 --> 00:10:54,410
what I would like to point out here is

324
00:10:54,410 --> 00:10:55,670
that there is also very tangible

325
00:10:55,670 --> 00:10:57,440
engineering benefits in using a simpler

326
00:10:57,440 --> 00:11:02,540
model and first the initial model that

327
00:11:02,540 --> 00:11:04,640
you that you will deploy it's more about

328
00:11:04,640 --> 00:11:06,830
getting all the infrastructure right so

329
00:11:06,830 --> 00:11:08,990
when you deploy your model you already

330
00:11:08,990 --> 00:11:10,370
have to deal with serving your

331
00:11:10,370 --> 00:11:11,810
predictions and making sure that the

332
00:11:11,810 --> 00:11:13,390
data is fed correctly into the albergue

333
00:11:13,390 --> 00:11:15,279
the predictions our output and provided

334
00:11:15,279 --> 00:11:16,660
to the user so there's a lot of

335
00:11:16,660 --> 00:11:18,940
complexity there even before dealing

336
00:11:18,940 --> 00:11:20,829
with the algorithms so if you add to

337
00:11:20,829 --> 00:11:22,839
that algorithmic complexity and try to

338
00:11:22,839 --> 00:11:25,390
figure out why the algorithm replied

339
00:11:25,390 --> 00:11:28,089
that that it did then you you're going

340
00:11:28,089 --> 00:11:29,589
to have a bad time basically and

341
00:11:29,589 --> 00:11:31,329
everything Google article actually

342
00:11:31,329 --> 00:11:33,279
suggests that you aim for your first

343
00:11:33,279 --> 00:11:34,899
learns to be neutral which means that

344
00:11:34,899 --> 00:11:36,250
you just aim for the to get the thing

345
00:11:36,250 --> 00:11:37,329
out there make sure that it doesn't

346
00:11:37,329 --> 00:11:39,279
break anything and then you can focus on

347
00:11:39,279 --> 00:11:43,540
games later second simpler models are

348
00:11:43,540 --> 00:11:46,360
usually interpreted if you run a linear

349
00:11:46,360 --> 00:11:47,829
regression every weight that you're

350
00:11:47,829 --> 00:11:49,240
gonna get in your model actually means

351
00:11:49,240 --> 00:11:50,980
something and that becomes very useful

352
00:11:50,980 --> 00:11:55,120
when you try to debug the the algorithms

353
00:11:55,120 --> 00:11:56,649
in made and try to explain why it made

354
00:11:56,649 --> 00:11:58,510
these predictions all of these things

355
00:11:58,510 --> 00:11:59,769
are very important when you're starting

356
00:11:59,769 --> 00:12:02,200
out so make sure that you're using the

357
00:12:02,200 --> 00:12:03,550
simple model because they're actually in

358
00:12:03,550 --> 00:12:05,260
interpretable which is much much harder

359
00:12:05,260 --> 00:12:06,700
to do if you have a neural network with

360
00:12:06,700 --> 00:12:08,529
1 million weights that's impossible to

361
00:12:08,529 --> 00:12:13,209
do basically and thirdly the the use of

362
00:12:13,209 --> 00:12:15,310
complex models are old binaries so what

363
00:12:15,310 --> 00:12:16,600
do we mean here like in software

364
00:12:16,600 --> 00:12:18,040
engineering we use concepts like

365
00:12:18,040 --> 00:12:20,019
abstraction and encapsulation in order

366
00:12:20,019 --> 00:12:21,430
to isolate different parts of the code

367
00:12:21,430 --> 00:12:22,779
so they don't affect each other if we

368
00:12:22,779 --> 00:12:24,880
make changes right but in machine

369
00:12:24,880 --> 00:12:26,260
learning we actually very often mix a

370
00:12:26,260 --> 00:12:28,300
signal so we have features that interact

371
00:12:28,300 --> 00:12:29,829
with each other and this is in the

372
00:12:29,829 --> 00:12:32,079
nature of the algorithms itself and this

373
00:12:32,079 --> 00:12:34,060
leads to a principle that's called the

374
00:12:34,060 --> 00:12:35,920
cake principle we're changing anything

375
00:12:35,920 --> 00:12:38,079
changes everything and this principle

376
00:12:38,079 --> 00:12:39,970
applies not only to the features but

377
00:12:39,970 --> 00:12:41,380
also to the hyper parameters and

378
00:12:41,380 --> 00:12:43,269
sampling process pretty much every knob

379
00:12:43,269 --> 00:12:45,010
that you can tweak in your machine

380
00:12:45,010 --> 00:12:46,329
learning pipeline will actually affect

381
00:12:46,329 --> 00:12:49,209
every other thing in your pipeline so by

382
00:12:49,209 --> 00:12:50,890
making every single part of the pipeline

383
00:12:50,890 --> 00:12:52,449
as simple as possible you're making much

384
00:12:52,449 --> 00:12:54,130
of your life much much easier as an

385
00:12:54,130 --> 00:12:56,949
engineer and of course there's a bunch

386
00:12:56,949 --> 00:12:58,630
of other things that can affect your or

387
00:12:58,630 --> 00:13:00,370
your choice of algorithm here but I

388
00:13:00,370 --> 00:13:01,690
think for people who are starting out

389
00:13:01,690 --> 00:13:03,250
just going for the simplest possible is

390
00:13:03,250 --> 00:13:05,709
actually a very good piece of advice so

391
00:13:05,709 --> 00:13:07,769
with that we can move on to software and

392
00:13:07,769 --> 00:13:10,360
actually I believe this is an even less

393
00:13:10,360 --> 00:13:12,250
important the decision to make a

394
00:13:12,250 --> 00:13:13,570
comeback to the rest of the pipeline so

395
00:13:13,570 --> 00:13:14,980
you only have like a single slide on

396
00:13:14,980 --> 00:13:16,839
this topic and I would just like to

397
00:13:16,839 --> 00:13:19,480
illustrate that the machine learning

398
00:13:19,480 --> 00:13:21,010
software so these are at some of the

399
00:13:21,010 --> 00:13:23,260
most popular open-source machine

400
00:13:23,260 --> 00:13:24,850
learning libraries on github all of them

401
00:13:24,850 --> 00:13:26,950
or almost all of them have more than one

402
00:13:26,950 --> 00:13:28,630
and stars which means that all of them

403
00:13:28,630 --> 00:13:30,670
are popular in the wrong way and my

404
00:13:30,670 --> 00:13:32,110
original plan was to pick a few of these

405
00:13:32,110 --> 00:13:34,630
and they try to talk about them more and

406
00:13:34,630 --> 00:13:36,519
explain them but I think that it's

407
00:13:36,519 --> 00:13:40,360
better to to point out that by now it

408
00:13:40,360 --> 00:13:41,889
machine learning software has become a

409
00:13:41,889 --> 00:13:43,180
commodity and there is very little

410
00:13:43,180 --> 00:13:45,790
differentiation between the top the top

411
00:13:45,790 --> 00:13:47,829
choices so what I would suggest for

412
00:13:47,829 --> 00:13:50,260
people starting out is that pick one but

413
00:13:50,260 --> 00:13:52,800
that's that you are comfortable with

414
00:13:52,800 --> 00:13:54,639
maybe something that your team has

415
00:13:54,639 --> 00:13:56,589
already worked on and focus on other

416
00:13:56,589 --> 00:13:58,120
parts of the album that will have a much

417
00:13:58,120 --> 00:13:59,980
bigger role in the success of your

418
00:13:59,980 --> 00:14:02,829
project so with that will I'd like to

419
00:14:02,829 --> 00:14:04,720
move on to another more neglected part

420
00:14:04,720 --> 00:14:07,329
of machine learning and that is what

421
00:14:07,329 --> 00:14:08,980
happens when your model comes in touch

422
00:14:08,980 --> 00:14:12,430
with with the world and this is

423
00:14:12,430 --> 00:14:13,990
something that you won't find a lot of

424
00:14:13,990 --> 00:14:16,240
research on and everyone seems to comes

425
00:14:16,240 --> 00:14:18,070
up with their own solution so what I

426
00:14:18,070 --> 00:14:19,300
would like to do in this section is

427
00:14:19,300 --> 00:14:20,680
point out problems that are common when

428
00:14:20,680 --> 00:14:23,170
deploying a machine learning model so

429
00:14:23,170 --> 00:14:24,310
first I would like to note the

430
00:14:24,310 --> 00:14:26,260
expectation versus reality of having a

431
00:14:26,260 --> 00:14:28,060
machine learning system in production so

432
00:14:28,060 --> 00:14:29,350
in an ideal world so this is the

433
00:14:29,350 --> 00:14:31,449
academic setting here right so we have

434
00:14:31,449 --> 00:14:33,730
data sisters are clean and standardized

435
00:14:33,730 --> 00:14:36,160
we develop the model and then we test it

436
00:14:36,160 --> 00:14:37,959
on some benchmark data set and that's it

437
00:14:37,959 --> 00:14:40,300
done right but the problem comes when

438
00:14:40,300 --> 00:14:41,620
you actually deploy the machine learning

439
00:14:41,620 --> 00:14:44,949
a model in production it needs to

440
00:14:44,949 --> 00:14:46,329
interact with the real world and that

441
00:14:46,329 --> 00:14:47,440
means that it's probably going to end up

442
00:14:47,440 --> 00:14:50,110
looking more much more like this so to

443
00:14:50,110 --> 00:14:51,399
have a running machine learning system

444
00:14:51,399 --> 00:14:53,680
you will need to have a large number of

445
00:14:53,680 --> 00:14:55,209
components around it it's with its own

446
00:14:55,209 --> 00:14:57,579
complexities and in recent Google's our

447
00:14:57,579 --> 00:14:59,620
survey the others mentioned that in a

448
00:14:59,620 --> 00:15:03,279
running matured program often only 5% of

449
00:15:03,279 --> 00:15:04,839
the code is actually machine learning

450
00:15:04,839 --> 00:15:07,600
code logic and 95% of the code is all

451
00:15:07,600 --> 00:15:09,519
that polemic that is required in order

452
00:15:09,519 --> 00:15:13,060
to make this whole thing work and then

453
00:15:13,060 --> 00:15:14,440
what are some common pitfalls when

454
00:15:14,440 --> 00:15:16,060
deploying machine learning programs in a

455
00:15:16,060 --> 00:15:18,760
complex setting like this one so first

456
00:15:18,760 --> 00:15:20,740
we almost always have data dependencies

457
00:15:20,740 --> 00:15:22,870
and similar to this similar to how you

458
00:15:22,870 --> 00:15:24,490
would have code dependencies in a

459
00:15:24,490 --> 00:15:25,990
project but they even harder to deal

460
00:15:25,990 --> 00:15:28,329
with so they are to some respect

461
00:15:28,329 --> 00:15:30,279
unavoidable in machine learning because

462
00:15:30,279 --> 00:15:32,579
at any point in a machine learning

463
00:15:32,579 --> 00:15:34,959
program we need to have our data set and

464
00:15:34,959 --> 00:15:36,819
we usually pass it through a complex

465
00:15:36,819 --> 00:15:38,470
data processing pipeline in order to

466
00:15:38,470 --> 00:15:40,450
make it and prepare it to be ready to

467
00:15:40,450 --> 00:15:42,459
for learning and this can create a bunch

468
00:15:42,459 --> 00:15:45,370
of problems so a common problem is that

469
00:15:45,370 --> 00:15:47,200
the the source data is unstable

470
00:15:47,200 --> 00:15:48,250
so that means that it can change

471
00:15:48,250 --> 00:15:50,260
distribution or it can have even more

472
00:15:50,260 --> 00:15:52,480
dramatic changes an example would be if

473
00:15:52,480 --> 00:15:54,100
a different data team owns the data

474
00:15:54,100 --> 00:15:56,079
pipeline in the different team does the

475
00:15:56,079 --> 00:15:58,570
learning so for example let's say that

476
00:15:58,570 --> 00:16:02,649
the data team starts monitoring the time

477
00:16:02,649 --> 00:16:04,389
that the users spend on a website using

478
00:16:04,389 --> 00:16:06,100
seconds because they want to have it for

479
00:16:06,100 --> 00:16:07,750
their own purposes and then you as a

480
00:16:07,750 --> 00:16:08,949
machine learning team you take that

481
00:16:08,949 --> 00:16:10,240
feature and they use it in order to do

482
00:16:10,240 --> 00:16:12,459
recommendations so maybe three months

483
00:16:12,459 --> 00:16:13,810
later the data team decides that they

484
00:16:13,810 --> 00:16:15,550
want to have more accurate accuracy in

485
00:16:15,550 --> 00:16:16,990
their measurements and they start

486
00:16:16,990 --> 00:16:18,670
measuring the time using milliseconds

487
00:16:18,670 --> 00:16:21,190
now if the data team does not have

488
00:16:21,190 --> 00:16:22,779
proper infrastructure to detect or the

489
00:16:22,779 --> 00:16:24,639
consumers of the data set or if the

490
00:16:24,639 --> 00:16:26,230
machine learning team does not have the

491
00:16:26,230 --> 00:16:28,329
infrastructure for monitoring to to to

492
00:16:28,329 --> 00:16:29,709
detect this change of distribution in

493
00:16:29,709 --> 00:16:31,329
the data the model will actually

494
00:16:31,329 --> 00:16:32,680
continue working and it will start

495
00:16:32,680 --> 00:16:35,949
producing a bogus predictions so so

496
00:16:35,949 --> 00:16:37,329
users to this would be to have very

497
00:16:37,329 --> 00:16:39,190
strict ACS for your data you can have a

498
00:16:39,190 --> 00:16:41,320
good monitoring or pipeline but what I

499
00:16:41,320 --> 00:16:42,940
prefer actually is to here for teams to

500
00:16:42,940 --> 00:16:44,500
actually have full ownership from of the

501
00:16:44,500 --> 00:16:46,420
pipeline from from serving the cryptic

502
00:16:46,420 --> 00:16:47,949
predictions all the way down to creating

503
00:16:47,949 --> 00:16:51,370
the data set a second related problems

504
00:16:51,370 --> 00:16:53,589
are feedback loops so feedback loops can

505
00:16:53,589 --> 00:16:55,120
be direct which are easier to deal with

506
00:16:55,120 --> 00:16:57,790
or indirect so in a direct feedback loop

507
00:16:57,790 --> 00:16:59,170
the model actually affects its own

508
00:16:59,170 --> 00:17:01,510
training set so this for example if your

509
00:17:01,510 --> 00:17:04,599
model ranks items in a list they list

510
00:17:04,599 --> 00:17:06,490
the items that it puts in towards the

511
00:17:06,490 --> 00:17:07,959
top of the list are always going to get

512
00:17:07,959 --> 00:17:09,669
clicked more often and then the

513
00:17:09,669 --> 00:17:10,869
algorithm will believe that it's also

514
00:17:10,869 --> 00:17:13,359
more probable that will get clicked and

515
00:17:13,359 --> 00:17:15,669
the solution to this type of things is

516
00:17:15,669 --> 00:17:16,750
that you can just remove all the

517
00:17:16,750 --> 00:17:18,339
predictions that have been passed by an

518
00:17:18,339 --> 00:17:18,730
algorithm

519
00:17:18,730 --> 00:17:20,380
but that of course would be very bad

520
00:17:20,380 --> 00:17:22,299
because you would be reducing your data

521
00:17:22,299 --> 00:17:24,280
so it can buy quite a lot so a better

522
00:17:24,280 --> 00:17:26,079
idea for this is to actually include the

523
00:17:26,079 --> 00:17:28,089
ranking of the item that your album

524
00:17:28,089 --> 00:17:29,770
produces in these features so if you

525
00:17:29,770 --> 00:17:31,150
include that as a feature then the

526
00:17:31,150 --> 00:17:32,799
algorithm says to figure out the

527
00:17:32,799 --> 00:17:34,870
importance of the rankings that the item

528
00:17:34,870 --> 00:17:36,309
has and that can help you quite a lot

529
00:17:36,309 --> 00:17:38,970
without you having to do anything and

530
00:17:38,970 --> 00:17:41,260
indirect feedback loops are much harder

531
00:17:41,260 --> 00:17:43,720
to deal with so for example Netflix uses

532
00:17:43,720 --> 00:17:46,179
curve uses a learning system in order to

533
00:17:46,179 --> 00:17:48,909
provide different covers for each item

534
00:17:48,909 --> 00:17:51,340
that the user see and then it will use a

535
00:17:51,340 --> 00:17:52,630
learning system in order to figure out

536
00:17:52,630 --> 00:17:54,310
which is the best cover for each of

537
00:17:54,310 --> 00:17:55,840
the items and of course it has a

538
00:17:55,840 --> 00:17:57,400
recommendation system that recommends

539
00:17:57,400 --> 00:18:00,190
its item in the first place right so

540
00:18:00,190 --> 00:18:01,450
then you have to think about what will

541
00:18:01,450 --> 00:18:03,010
happen if I get a good recommendation

542
00:18:03,010 --> 00:18:05,500
but with a bad cover so if Netflix is

543
00:18:05,500 --> 00:18:06,760
not careful in the way that they

544
00:18:06,760 --> 00:18:08,530
implement their elgu's it's very likely

545
00:18:08,530 --> 00:18:10,120
that one system will actually are

546
00:18:10,120 --> 00:18:11,860
starting flensing the output of the

547
00:18:11,860 --> 00:18:13,450
other system and the data set that it's

548
00:18:13,450 --> 00:18:15,790
strained with and that can be a hidden

549
00:18:15,790 --> 00:18:18,960
feedback loop that's very hard to detect

550
00:18:18,960 --> 00:18:21,730
so I think I would like to conclude here

551
00:18:21,730 --> 00:18:23,440
more or less and the idea is how do we

552
00:18:23,440 --> 00:18:26,260
bring this all together so I think that

553
00:18:26,260 --> 00:18:28,570
the key takeaways are that you can use a

554
00:18:28,570 --> 00:18:30,520
common interface to define most of the

555
00:18:30,520 --> 00:18:31,990
machine learning problems and this is

556
00:18:31,990 --> 00:18:34,750
very useful when starting out that you

557
00:18:34,750 --> 00:18:36,280
should determine the readiness of you of

558
00:18:36,280 --> 00:18:37,960
your data before starting learning and

559
00:18:37,960 --> 00:18:39,460
make sure that you monitor the readiness

560
00:18:39,460 --> 00:18:41,620
of your data at all times as well and

561
00:18:41,620 --> 00:18:43,120
that you shouldn't spend too much time

562
00:18:43,120 --> 00:18:44,980
worrying at first about the selection of

563
00:18:44,980 --> 00:18:46,510
algorithms or the selection of software

564
00:18:46,510 --> 00:18:48,220
because it's not as important as it may

565
00:18:48,220 --> 00:18:50,350
seem and finally I think that you should

566
00:18:50,350 --> 00:18:51,730
worry much more about what will happen

567
00:18:51,730 --> 00:18:53,770
when your model comes in touch with with

568
00:18:53,770 --> 00:18:55,030
the world and what will happen when you

569
00:18:55,030 --> 00:18:57,760
put it out in the world and without I

570
00:18:57,760 --> 00:18:59,020
think

571
00:18:59,020 --> 00:19:07,819
[Applause]

572
00:20:16,940 --> 00:20:19,710
features all the kind of like sitting on

573
00:20:19,710 --> 00:20:23,809
a very sort of fragile structure because

574
00:20:36,950 --> 00:20:43,230
yeah I think this is yeah okay so the

575
00:20:43,230 --> 00:20:46,860
question is like okay so I think that

576
00:20:46,860 --> 00:20:49,080
the main thing is that as you move on in

577
00:20:49,080 --> 00:20:50,430
a fast moving environment that a new

578
00:20:50,430 --> 00:20:52,500
company you always aggregate more and

579
00:20:52,500 --> 00:20:54,300
more technical debt right and the thing

580
00:20:54,300 --> 00:20:55,650
is that especially machine learning as

581
00:20:55,650 --> 00:20:57,000
another place do you have to pay it off

582
00:20:57,000 --> 00:20:58,350
at some point it doesn't work like you

583
00:20:58,350 --> 00:20:59,940
can just no you cannot just keep

584
00:20:59,940 --> 00:21:01,860
including more and more fragile fragile

585
00:21:01,860 --> 00:21:03,450
thing because at times at some point the

586
00:21:03,450 --> 00:21:05,010
whole thing is going to break so it's

587
00:21:05,010 --> 00:21:07,050
actually a very good idea that at some

588
00:21:07,050 --> 00:21:09,450
point to just stop and do this thing

589
00:21:09,450 --> 00:21:11,130
where we call this neutral loans right

590
00:21:11,130 --> 00:21:13,680
so it would be much better to just say

591
00:21:13,680 --> 00:21:15,390
okay we're stop worrying about the model

592
00:21:15,390 --> 00:21:16,890
but what we're gonna do now is we're

593
00:21:16,890 --> 00:21:18,600
gonna be deploying new thing where the

594
00:21:18,600 --> 00:21:19,590
new thing is going to be a new

595
00:21:19,590 --> 00:21:21,420
infrastructure and what is going what

596
00:21:21,420 --> 00:21:22,560
that is going to do is that we're going

597
00:21:22,560 --> 00:21:24,210
to build if it's just an easier system

598
00:21:24,210 --> 00:21:25,980
to make things that everything works we

599
00:21:25,980 --> 00:21:27,870
might have a prediction that this I

600
00:21:27,870 --> 00:21:29,580
don't know the mean of everything right

601
00:21:29,580 --> 00:21:31,500
that's always fine okay so that's our

602
00:21:31,500 --> 00:21:32,940
model now it's very simple we know what

603
00:21:32,940 --> 00:21:34,440
will happen what about the

604
00:21:34,440 --> 00:21:36,060
infrastructure all over around right

605
00:21:36,060 --> 00:21:37,980
it's much easier to just develop one

606
00:21:37,980 --> 00:21:39,570
thing at a time if you try to change the

607
00:21:39,570 --> 00:21:40,830
infrastructure at the same time as your

608
00:21:40,830 --> 00:21:42,600
algorithms that's not going to work so I

609
00:21:42,600 --> 00:21:44,010
think it's a very good idea to just go

610
00:21:44,010 --> 00:21:46,110
for one sprint or something that I don't

611
00:21:46,110 --> 00:21:47,130
know what system you're using

612
00:21:47,130 --> 00:21:48,840
that's hey okay we're gonna do a newer

613
00:21:48,840 --> 00:21:50,640
model deployment they were going to do

614
00:21:50,640 --> 00:21:52,830
an infrastructure around it as easy as

615
00:21:52,830 --> 00:21:54,390
possible it's actually very good to

616
00:21:54,390 --> 00:21:55,980
actually invest that time and effort

617
00:21:55,980 --> 00:21:57,540
into it because it's going to pay off in

618
00:21:57,540 --> 00:21:58,160
the future

619
00:21:58,160 --> 00:22:01,160
yep

620
00:22:04,440 --> 00:22:05,680
yeah

621
00:22:05,680 --> 00:22:08,110
so that is yeah so building your own

622
00:22:08,110 --> 00:22:10,600
model versus using the existing model

623
00:22:10,600 --> 00:22:11,920
here are you talking about the

624
00:22:11,920 --> 00:22:13,330
theoretical model itself or are you

625
00:22:13,330 --> 00:22:15,100
talking about using your own

626
00:22:15,100 --> 00:22:16,780
implementation of logistic regression

627
00:22:16,780 --> 00:22:18,460
instead of this part one so you're using

628
00:22:18,460 --> 00:22:20,020
a you're thinking about building your

629
00:22:20,020 --> 00:22:23,500
own what I found yeah so what I found

630
00:22:23,500 --> 00:22:25,750
from speaking to people in smaller and

631
00:22:25,750 --> 00:22:28,780
larger companies is that the bigger

632
00:22:28,780 --> 00:22:30,670
companies always almost always end up

633
00:22:30,670 --> 00:22:32,380
using their own because there is no

634
00:22:32,380 --> 00:22:34,210
infrastructure out there open-source

635
00:22:34,210 --> 00:22:35,530
that actually works in the scale that

636
00:22:35,530 --> 00:22:37,180
companies that with millions of clients

637
00:22:37,180 --> 00:22:40,780
say I want so I've talked with retail as

638
00:22:40,780 --> 00:22:43,030
well and in Spotify in other places and

639
00:22:43,030 --> 00:22:45,010
all of them end up building their own

640
00:22:45,010 --> 00:22:46,930
because it's impossible to do these

641
00:22:46,930 --> 00:22:49,150
things and there's so many moving parts

642
00:22:49,150 --> 00:22:50,830
that you end up breaking at some at some

643
00:22:50,830 --> 00:22:53,650
point always but for the smaller

644
00:22:53,650 --> 00:22:55,120
companies I think that they're good to

645
00:22:55,120 --> 00:22:57,220
try to just start with whatever they

646
00:22:57,220 --> 00:22:59,110
want but they should be aware that at

647
00:22:59,110 --> 00:23:00,340
some point they will probably have to

648
00:23:00,340 --> 00:23:03,959
roll their own everything basically

649
00:23:10,570 --> 00:23:15,200
no no so that is okay so if if it's a

650
00:23:15,200 --> 00:23:16,429
good idea to use different programming

651
00:23:16,429 --> 00:23:19,130
languages between training and producing

652
00:23:19,130 --> 00:23:21,110
the model the ideal thing is that you

653
00:23:21,110 --> 00:23:22,850
use as much code as possible in

654
00:23:22,850 --> 00:23:25,309
production or for serving the model as

655
00:23:25,309 --> 00:23:27,740
you do for training it so changing its

656
00:23:27,740 --> 00:23:29,120
changing language is changing the

657
00:23:29,120 --> 00:23:31,519
infrastructure same thing anything it

658
00:23:31,519 --> 00:23:33,559
does its add it just adds a lot more

659
00:23:33,559 --> 00:23:36,200
complexity and so one of the the

660
00:23:36,200 --> 00:23:37,789
articles that I've linked at at the end

661
00:23:37,789 --> 00:23:38,960
which is which is originating from

662
00:23:38,960 --> 00:23:41,179
google makes a specific point about all

663
00:23:41,179 --> 00:23:42,980
of this to increase the code reuse

664
00:23:42,980 --> 00:23:45,350
between these two parts of the pipeline

665
00:23:45,350 --> 00:23:47,659
as much as possible and also to make

666
00:23:47,659 --> 00:23:50,809
sure that the the difference in in the

667
00:23:50,809 --> 00:23:52,940
in the quality of your model when you

668
00:23:52,940 --> 00:23:55,340
train it and when you serve it is one of

669
00:23:55,340 --> 00:23:56,899
the most important indicators that you

670
00:23:56,899 --> 00:23:59,090
have for the quality so there are a lot

671
00:23:59,090 --> 00:24:01,490
of points to make about that as well so

672
00:24:01,490 --> 00:24:03,169
they need to be very active monitoring

673
00:24:03,169 --> 00:24:05,210
between the error that you get in the

674
00:24:05,210 --> 00:24:06,440
training and the error that you get in

675
00:24:06,440 --> 00:24:07,760
actual production because it can

676
00:24:07,760 --> 00:24:15,769
indicate a lot of problems can you speak

677
00:24:15,769 --> 00:24:18,370
up a little bit

678
00:24:34,669 --> 00:24:37,350
yeah it's definitely possible okay so

679
00:24:37,350 --> 00:24:39,960
the question is since a lot of models

680
00:24:39,960 --> 00:24:41,580
for example I'm guessing you're talking

681
00:24:41,580 --> 00:24:44,220
about in your networks here that can

682
00:24:44,220 --> 00:24:46,139
take days or weeks to train so if

683
00:24:46,139 --> 00:24:49,230
there's if it's any way to just make

684
00:24:49,230 --> 00:24:50,809
this whole pipeline go faster and

685
00:24:50,809 --> 00:24:53,009
usually I mean this is as in any

686
00:24:53,009 --> 00:24:54,389
computer science problem there's two

687
00:24:54,389 --> 00:24:55,860
ways to do that you can either add more

688
00:24:55,860 --> 00:24:57,990
hardware and hope that it works or you

689
00:24:57,990 --> 00:24:59,820
can do sampling and in machine learning

690
00:24:59,820 --> 00:25:02,580
the sampling part is it's so complicated

691
00:25:02,580 --> 00:25:04,470
that there's a whole subfield of science

692
00:25:04,470 --> 00:25:06,840
around around that so if you have

693
00:25:06,840 --> 00:25:08,580
samples from users you want to make sure

694
00:25:08,580 --> 00:25:10,320
that they are stratified and you're

695
00:25:10,320 --> 00:25:11,549
trying to predict I don't know a class

696
00:25:11,549 --> 00:25:12,629
you want to make sure that they're

697
00:25:12,629 --> 00:25:15,389
stratified by class as well so it's very

698
00:25:15,389 --> 00:25:17,370
very hard to actually get a true

699
00:25:17,370 --> 00:25:20,009
representative sample in order in order

700
00:25:20,009 --> 00:25:23,129
to train but there are cases where just

701
00:25:23,129 --> 00:25:24,840
taking a random sample from your data if

702
00:25:24,840 --> 00:25:28,620
you're looking into exploratory analysis

703
00:25:28,620 --> 00:25:30,269
it's not so important if you're not

704
00:25:30,269 --> 00:25:31,679
really worried about the quality of your

705
00:25:31,679 --> 00:25:33,629
modeling you just want to try out stuff

706
00:25:33,629 --> 00:25:35,399
it's better to just sample it down your

707
00:25:35,399 --> 00:25:37,320
data and use it in your own in your

708
00:25:37,320 --> 00:25:38,879
computer instead of running it on the

709
00:25:38,879 --> 00:25:42,330
cluster and iterate on that it's going

710
00:25:42,330 --> 00:25:44,009
to be much harder to try to do that with

711
00:25:44,009 --> 00:25:46,110
your complete data set so it's very

712
00:25:46,110 --> 00:25:48,330
important to just finish more as so to

713
00:25:48,330 --> 00:25:50,070
speak with your exploratory analysis as

714
00:25:50,070 --> 00:25:51,750
soon as possible and then you can go

715
00:25:51,750 --> 00:25:52,889
back and iterate through the whole

716
00:25:52,889 --> 00:25:56,660
pipeline again thank you

717
00:25:56,660 --> 00:26:00,829
[Applause]

