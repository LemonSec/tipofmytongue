1
00:00:00,030 --> 00:00:02,510
and everybody

2
00:00:04,550 --> 00:00:06,680
and next people co-speaker Robley

3
00:00:06,680 --> 00:00:09,710
filippova telling us about analyzing

4
00:00:09,710 --> 00:00:13,629
millions or what it's trillions of lines

5
00:00:13,629 --> 00:00:18,320
so a scout with one query so give them a

6
00:00:18,320 --> 00:00:20,650
big hand

7
00:00:21,460 --> 00:00:23,480
thank you very much thank you for being

8
00:00:23,480 --> 00:00:24,110
here

9
00:00:24,110 --> 00:00:27,920
yes I'm Felipe Hoffa I joined Google six

10
00:00:27,920 --> 00:00:28,850
years ago

11
00:00:28,850 --> 00:00:31,010
software engineer when I became a

12
00:00:31,010 --> 00:00:33,649
developer advocate that's basically a

13
00:00:33,649 --> 00:00:36,650
software engineer with our license to

14
00:00:36,650 --> 00:00:39,170
speak and today we're going to analyze a

15
00:00:39,170 --> 00:00:41,270
lot of data a lot of data from github

16
00:00:41,270 --> 00:00:44,329
then we have shared so you can do this

17
00:00:44,329 --> 00:00:47,210
analysis too as quickly as possible

18
00:00:47,210 --> 00:00:49,160
maybe in the next five minutes after the

19
00:00:49,160 --> 00:00:51,739
talk so what do you see here

20
00:00:51,739 --> 00:00:56,630
when you look at this source code great

21
00:00:56,630 --> 00:01:00,950
but there is way more here there is data

22
00:01:00,950 --> 00:01:04,099
let me zoom here we have a year we have

23
00:01:04,099 --> 00:01:06,829
a live sense we have oh this is Python

24
00:01:06,829 --> 00:01:09,219
code that is important from future

25
00:01:09,219 --> 00:01:13,459
certain fits certain future features we

26
00:01:13,459 --> 00:01:15,350
have certain imports that we are doing

27
00:01:15,350 --> 00:01:18,289
and then we look at the big picture we

28
00:01:18,289 --> 00:01:22,100
also see metadata like number of stars

29
00:01:22,100 --> 00:01:24,889
number of false pull requests how many

30
00:01:24,889 --> 00:01:27,740
people have contributed to this piece of

31
00:01:27,740 --> 00:01:31,189
source code so what I see here is a lot

32
00:01:31,189 --> 00:01:36,139
of data and I wrote it with a big phone

33
00:01:36,139 --> 00:01:39,740
because this is big data thank you for

34
00:01:39,740 --> 00:01:45,279
is for so who wants to analyze github

35
00:01:45,279 --> 00:01:48,740
project maintainer if you own a project

36
00:01:48,740 --> 00:01:50,929
you want to know how popular your

37
00:01:50,929 --> 00:01:54,289
project is who is following your project

38
00:01:54,289 --> 00:01:56,659
it's not only about the number of stars

39
00:01:56,659 --> 00:02:01,099
you want to do change management change

40
00:02:01,099 --> 00:02:03,770
management we should I add new features

41
00:02:03,770 --> 00:02:05,479
will they break people that are using my

42
00:02:05,479 --> 00:02:08,598
project is my project can see how the

43
00:02:08,598 --> 00:02:12,290
community behaving how am i behaving on

44
00:02:12,290 --> 00:02:14,490
issue closing closing

45
00:02:14,490 --> 00:02:17,090
and producers want this kind of data too

46
00:02:17,090 --> 00:02:19,320
they want to know what our similar

47
00:02:19,320 --> 00:02:20,940
products will follow they want to know

48
00:02:20,940 --> 00:02:23,310
how to request features how to better

49
00:02:23,310 --> 00:02:26,910
express themselves how to use data when

50
00:02:26,910 --> 00:02:31,800
asking for changes producers even before

51
00:02:31,800 --> 00:02:36,540
becoming a project user you you have to

52
00:02:36,540 --> 00:02:38,850
convince yourself or you can have to

53
00:02:38,850 --> 00:02:41,430
convince other people or should I use

54
00:02:41,430 --> 00:02:43,830
this project or not and having data to

55
00:02:43,830 --> 00:02:47,550
do so is great and data lovers if you

56
00:02:47,550 --> 00:02:49,740
love analyzing data just for the sake of

57
00:02:49,740 --> 00:02:54,780
it that may I hopefully you too

58
00:02:54,780 --> 00:02:56,640
and there's a lot of other people that

59
00:02:56,640 --> 00:02:59,970
are helping us use this data and get

60
00:02:59,970 --> 00:03:04,980
better metrics to drive open source we

61
00:03:04,980 --> 00:03:07,110
are using three main data sets there are

62
00:03:07,110 --> 00:03:08,640
three main data sets that I will talk

63
00:03:08,640 --> 00:03:11,580
about today github archive it was the

64
00:03:11,580 --> 00:03:16,890
first one I saw we already started this

65
00:03:16,890 --> 00:03:20,520
one in 2012 but has so far eight point

66
00:03:20,520 --> 00:03:23,580
seven billion events that are events

67
00:03:23,580 --> 00:03:25,620
published by github other world by our

68
00:03:25,620 --> 00:03:29,810
and we are getting updates every hour

69
00:03:29,810 --> 00:03:32,970
recently I added to my list of that set

70
00:03:32,970 --> 00:03:34,890
g8 story that has been a separate

71
00:03:34,890 --> 00:03:37,440
project for a long time but now I have

72
00:03:37,440 --> 00:03:40,650
it on bigquery to where we take the same

73
00:03:40,650 --> 00:03:44,190
events that have archived has but we go

74
00:03:44,190 --> 00:03:47,820
way deeper we are linking more metadata

75
00:03:47,820 --> 00:03:51,300
more we have a graph of the atop of what

76
00:03:51,300 --> 00:03:53,930
everything means who is each person etc

77
00:03:53,930 --> 00:03:57,060
and then the data said we are the last

78
00:03:57,060 --> 00:04:00,330
year is the source code taken from

79
00:04:00,330 --> 00:04:02,820
github we put it on bigquery so you

80
00:04:02,820 --> 00:04:05,520
could analyze even the source code and

81
00:04:05,520 --> 00:04:08,760
what's happening there and that's a lot

82
00:04:08,760 --> 00:04:11,190
of code I mentioned bigquery who knows

83
00:04:11,190 --> 00:04:14,220
bigquery excellent so many people know

84
00:04:14,220 --> 00:04:17,250
it when I started three years ago not so

85
00:04:17,250 --> 00:04:19,108
many people don't do it but they are

86
00:04:19,108 --> 00:04:20,880
quickly for anyone that doesn't know

87
00:04:20,880 --> 00:04:23,250
what it is it's a service from Google

88
00:04:23,250 --> 00:04:25,820
that lets you analyze a lot of the

89
00:04:25,820 --> 00:04:29,300
in very few seconds without setting up

90
00:04:29,300 --> 00:04:31,670
anything if the affair you can load its

91
00:04:31,670 --> 00:04:34,310
webpage you or you can use the REST API

92
00:04:34,310 --> 00:04:38,300
and even better I can share data with

93
00:04:38,300 --> 00:04:41,270
you any of these datasets any data set

94
00:04:41,270 --> 00:04:43,430
that you log here if you want to share

95
00:04:43,430 --> 00:04:45,790
it you can share it instantly and

96
00:04:45,790 --> 00:04:48,680
everyone has one free terabyte to

97
00:04:48,680 --> 00:04:52,130
analyze it every month you don't even

98
00:04:52,130 --> 00:04:57,830
need a credit card so for example let me

99
00:04:57,830 --> 00:05:00,050
show you quickly the query in case you

100
00:05:00,050 --> 00:05:03,230
have never seen it I have pretty big

101
00:05:03,230 --> 00:05:05,750
funds here but basically you can load a

102
00:05:05,750 --> 00:05:09,530
webpage you can load a query and you can

103
00:05:09,530 --> 00:05:12,080
run your query here and in very few

104
00:05:12,080 --> 00:05:15,680
seconds it will analyze terabytes of

105
00:05:15,680 --> 00:05:20,090
data in this case analysis more like 1.7

106
00:05:20,090 --> 00:05:24,110
gigabytes of data and this query takes 6

107
00:05:24,110 --> 00:05:27,170
seconds or 15 seconds and I got results

108
00:05:27,170 --> 00:05:30,380
that I will explain you now what I'm

109
00:05:30,380 --> 00:05:34,160
doing so for example top row is by stars

110
00:05:34,160 --> 00:05:38,840
on 2016 that's a simple query let's look

111
00:05:38,840 --> 00:05:41,600
at all the watch events during 2016

112
00:05:41,600 --> 00:05:45,050
we ran it and we get at the top project

113
00:05:45,050 --> 00:05:47,660
by stars was free code camp followed by

114
00:05:47,660 --> 00:05:51,080
Google interview University UJS but

115
00:05:51,080 --> 00:05:53,210
things are not so simple if you want to

116
00:05:53,210 --> 00:05:55,820
do things is this the real number of

117
00:05:55,820 --> 00:05:59,030
stars that it's project God turns out

118
00:05:59,030 --> 00:06:02,660
people can star and star star and star a

119
00:06:02,660 --> 00:06:04,730
project many times and we are counting

120
00:06:04,730 --> 00:06:08,240
those events so sometimes you want to

121
00:06:08,240 --> 00:06:09,740
think your queries a little boring and

122
00:06:09,740 --> 00:06:11,840
you want to add for example let's count

123
00:06:11,840 --> 00:06:14,600
let the duplicate the number of star

124
00:06:14,600 --> 00:06:16,160
let's count the distinct number of users

125
00:06:16,160 --> 00:06:18,950
yep then each product has lesser stars

126
00:06:18,950 --> 00:06:22,490
but more real count and what I want to

127
00:06:22,490 --> 00:06:24,230
highlight here is that you have the

128
00:06:24,230 --> 00:06:26,860
freedom to count things as you wish

129
00:06:26,860 --> 00:06:29,570
don't stop with the first number always

130
00:06:29,570 --> 00:06:34,040
try to go a little deeper what you'll

131
00:06:34,040 --> 00:06:36,230
have stars you may want also to know

132
00:06:36,230 --> 00:06:38,060
more people about the people starring

133
00:06:38,060 --> 00:06:38,360
you

134
00:06:38,360 --> 00:06:40,669
a thousand stars on this project is not

135
00:06:40,669 --> 00:06:43,069
are not the same of thousand stars for a

136
00:06:43,069 --> 00:06:45,349
different project because people have

137
00:06:45,349 --> 00:06:47,000
different interests and you can start

138
00:06:47,000 --> 00:06:49,370
doing queries like this where for here

139
00:06:49,370 --> 00:06:51,530
for example the query just ran outside

140
00:06:51,530 --> 00:06:53,780
I'm taking everyone that start

141
00:06:53,780 --> 00:06:55,330
tensorflow

142
00:06:55,330 --> 00:06:58,819
do it 2016 and I'm counting all of the

143
00:06:58,819 --> 00:07:02,539
other projects they very start and I'm

144
00:07:02,539 --> 00:07:05,030
taking out anyone that also star free

145
00:07:05,030 --> 00:07:06,710
code camp just because it's so popular

146
00:07:06,710 --> 00:07:11,120
that my my results get a little mallet

147
00:07:11,120 --> 00:07:14,300
so I'm free to add and strive and change

148
00:07:14,300 --> 00:07:16,939
the way I'm come to things yeah it's

149
00:07:16,939 --> 00:07:18,979
pretty cool because I kind of start from

150
00:07:18,979 --> 00:07:21,020
tensorflow and then I start building a

151
00:07:21,020 --> 00:07:23,930
graph where people also start transfer

152
00:07:23,930 --> 00:07:26,990
from others Cafe Kara's Google interview

153
00:07:26,990 --> 00:07:30,469
University six I get CNT K and the

154
00:07:30,469 --> 00:07:32,300
results make sense if you want to run it

155
00:07:32,300 --> 00:07:34,849
for your project I'm happy to show you

156
00:07:34,849 --> 00:07:37,250
how later or you can find it on the

157
00:07:37,250 --> 00:07:40,099
slides and then you are stuck wondering

158
00:07:40,099 --> 00:07:42,259
if you are thinking about stars how did

159
00:07:42,259 --> 00:07:43,779
people arrive here

160
00:07:43,779 --> 00:07:46,490
where did my three thousand stars come

161
00:07:46,490 --> 00:07:49,370
and it turns out if you look at the flow

162
00:07:49,370 --> 00:07:52,419
of stars they are mostly discrete event

163
00:07:52,419 --> 00:07:55,099
you get a lot of stars in two or three

164
00:07:55,099 --> 00:07:59,259
days and then everyone disappears and

165
00:07:59,259 --> 00:08:01,430
these events have a lot to do for

166
00:08:01,430 --> 00:08:05,240
example with being shown on the hacker

167
00:08:05,240 --> 00:08:06,339
news front page

168
00:08:06,339 --> 00:08:09,050
so here the smaller rotations that you

169
00:08:09,050 --> 00:08:11,719
might not be able to read show every

170
00:08:11,719 --> 00:08:14,089
time this project shall show that on

171
00:08:14,089 --> 00:08:16,879
Hacker News and the first thing here is

172
00:08:16,879 --> 00:08:18,819
that I didn't need to add these

173
00:08:18,819 --> 00:08:21,800
annotations manually because in bigquery

174
00:08:21,800 --> 00:08:24,439
I'm also storing hacker news post

175
00:08:24,439 --> 00:08:27,080
comments and I'm able to write a simple

176
00:08:27,080 --> 00:08:30,110
query or not so simple but it's one

177
00:08:30,110 --> 00:08:31,969
sequel query and I'm able to join social

178
00:08:31,969 --> 00:08:34,969
media with number of stars I can start I

179
00:08:34,969 --> 00:08:37,940
identify how social media affects my

180
00:08:37,940 --> 00:08:41,208
projects health let me go quickly

181
00:08:41,208 --> 00:08:42,708
through this

182
00:08:42,708 --> 00:08:45,410
let's find projects how many issues they

183
00:08:45,410 --> 00:08:50,270
have how what's the rate of closure of

184
00:08:50,270 --> 00:08:50,960
issues

185
00:08:50,960 --> 00:08:53,140
how's the engagement of the community

186
00:08:53,140 --> 00:08:56,660
what what are the best way of getting my

187
00:08:56,660 --> 00:09:02,980
issues action simple query these are the

188
00:09:02,980 --> 00:09:06,020
projects that have more issue comments

189
00:09:06,020 --> 00:09:09,620
during this month in 2016 and kubernetes

190
00:09:09,620 --> 00:09:11,420
cast a lot of comments spot you might

191
00:09:11,420 --> 00:09:14,089
know or open ship you may know but then

192
00:09:14,089 --> 00:09:15,920
also we have sat on them and no one

193
00:09:15,920 --> 00:09:18,020
knows this project but it got so many

194
00:09:18,020 --> 00:09:20,270
comments so maybe we are counting things

195
00:09:20,270 --> 00:09:22,490
wrong what if he started counting

196
00:09:22,490 --> 00:09:26,779
instead the number of people's how many

197
00:09:26,779 --> 00:09:29,690
people were really commenting and then

198
00:09:29,690 --> 00:09:32,660
we can start looking at metrics like how

199
00:09:32,660 --> 00:09:36,560
many comments each author wrote so in

200
00:09:36,560 --> 00:09:39,350
this chart I have the from big projects

201
00:09:39,350 --> 00:09:42,230
with more than 400 people commenting on

202
00:09:42,230 --> 00:09:44,990
issues who what are the projects that

203
00:09:44,990 --> 00:09:47,170
had more comments per author and

204
00:09:47,170 --> 00:09:51,700
kubernetes shows a high degree of

205
00:09:51,700 --> 00:09:54,649
community involvement people that come

206
00:09:54,649 --> 00:09:57,920
in here come right at least eight p

207
00:09:57,920 --> 00:09:59,900
comments per officer and I'm removing

208
00:09:59,900 --> 00:10:02,029
robots because that's another important

209
00:10:02,029 --> 00:10:03,920
thing to remove and you can see other

210
00:10:03,920 --> 00:10:05,690
projects that also have a lot of

211
00:10:05,690 --> 00:10:08,180
engagement but it differs a lot probably

212
00:10:08,180 --> 00:10:10,700
my project and you can go even deeper

213
00:10:10,700 --> 00:10:13,040
with more than numbers you can do text

214
00:10:13,040 --> 00:10:15,890
analysis here is a simple query to look

215
00:10:15,890 --> 00:10:20,870
at that the top four initial words to

216
00:10:20,870 --> 00:10:24,440
start an issue the top way to start an

217
00:10:24,440 --> 00:10:25,190
issue on github

218
00:10:25,190 --> 00:10:27,920
during this month was it would be nice

219
00:10:27,920 --> 00:10:28,760
bah-bah-bah

220
00:10:28,760 --> 00:10:33,080
follow but is it possible to pop up on

221
00:10:33,080 --> 00:10:36,110
you can see the rest yeah people are

222
00:10:36,110 --> 00:10:38,800
really nice when they ask questions but

223
00:10:38,800 --> 00:10:41,600
issues get different closure a closure

224
00:10:41,600 --> 00:10:44,150
rate depending on what kind of issue do

225
00:10:44,150 --> 00:10:48,110
I file it would be nice get 56% closure

226
00:10:48,110 --> 00:10:52,130
where so if it possible to gets a 74

227
00:10:52,130 --> 00:10:53,660
percent and if you start looking at

228
00:10:53,660 --> 00:10:55,640
patterns there are better ways of asking

229
00:10:55,640 --> 00:10:58,790
things and I come back to questions

230
00:10:58,790 --> 00:11:01,779
later if I have time

231
00:11:03,370 --> 00:11:06,560
huh so that the humans yes it's real

232
00:11:06,560 --> 00:11:08,660
there's some place where I have to be

233
00:11:08,660 --> 00:11:12,949
duplicate yeah have some minutes left

234
00:11:12,949 --> 00:11:15,319
let's talk about the code the data said

235
00:11:15,319 --> 00:11:18,889
that we released last year I had the

236
00:11:18,889 --> 00:11:20,990
pleasure of announcing this but there's

237
00:11:20,990 --> 00:11:23,089
a lot more people working here there are

238
00:11:23,089 --> 00:11:26,360
some Googlers people at github that

239
00:11:26,360 --> 00:11:28,720
allow us to make this data set wheel

240
00:11:28,720 --> 00:11:32,389
where we are taking the code from here

241
00:11:32,389 --> 00:11:36,379
have replicated on bigquery you can find

242
00:11:36,379 --> 00:11:38,810
the table online the last clincher I

243
00:11:38,810 --> 00:11:42,860
took this is 1.79 gigabytes of data

244
00:11:42,860 --> 00:11:46,759
terabytes of data 200 million rows and

245
00:11:46,759 --> 00:11:49,819
each one represents a lot of files if

246
00:11:49,819 --> 00:11:52,490
you look at the main table you can see

247
00:11:52,490 --> 00:11:56,540
that files kept being duplicated they D

248
00:11:56,540 --> 00:11:58,970
that is basically a hash of the content

249
00:11:58,970 --> 00:12:01,550
of the files we have the size of each

250
00:12:01,550 --> 00:12:05,029
file the content so you can see the

251
00:12:05,029 --> 00:12:07,220
source code if it's a binary or not

252
00:12:07,220 --> 00:12:09,980
binary file and the number of copies so

253
00:12:09,980 --> 00:12:12,560
when I say we have 46 terabytes of code

254
00:12:12,560 --> 00:12:17,269
and basically multiplying the number of

255
00:12:17,269 --> 00:12:20,300
copies that each five has byte size and

256
00:12:20,300 --> 00:12:24,519
that's how I arrived to 46 theorem X

257
00:12:24,610 --> 00:12:26,750
there are some rules when you want to

258
00:12:26,750 --> 00:12:29,060
work with this data set it only have

259
00:12:29,060 --> 00:12:31,009
text files that are less than one

260
00:12:31,009 --> 00:12:34,550
megabyte only one copy of each file if

261
00:12:34,550 --> 00:12:36,470
you want to know all of the paths that

262
00:12:36,470 --> 00:12:40,279
each file has you can join it with the

263
00:12:40,279 --> 00:12:43,370
table files but don't join it to get all

264
00:12:43,370 --> 00:12:45,410
of the contents deduplicated because you

265
00:12:45,410 --> 00:12:47,540
end up with 46 terabytes of code and

266
00:12:47,540 --> 00:12:49,550
that's not really what you want you want

267
00:12:49,550 --> 00:12:52,279
to be duplicate files and not really you

268
00:12:52,279 --> 00:12:55,459
want something you want as a result but

269
00:12:55,459 --> 00:12:58,040
whenever you want to analyze this take

270
00:12:58,040 --> 00:13:01,339
your a try to extract what you're

271
00:13:01,339 --> 00:13:03,680
interested in all of the Java files all

272
00:13:03,680 --> 00:13:06,290
of the Gaul files or Java files created

273
00:13:06,290 --> 00:13:07,399
in 2015

274
00:13:07,399 --> 00:13:11,830
etc and I left a table with a waste

275
00:13:11,830 --> 00:13:15,580
sample of 10% of the contents of the top

276
00:13:15,580 --> 00:13:18,870
projects and that's a faster way to

277
00:13:18,870 --> 00:13:23,550
start and not get all your freak what

278
00:13:23,550 --> 00:13:26,350
not use all your free quota and they say

279
00:13:26,350 --> 00:13:31,089
and the first day this data fed only has

280
00:13:31,089 --> 00:13:34,839
open source projects from it have how

281
00:13:34,839 --> 00:13:36,160
can we tell that something is

282
00:13:36,160 --> 00:13:38,230
open-source or not that it has a valid

283
00:13:38,230 --> 00:13:44,529
license we use github of license API so

284
00:13:44,529 --> 00:13:45,880
if you want to see your project

285
00:13:45,880 --> 00:13:48,070
replicated here if you want your project

286
00:13:48,070 --> 00:13:51,790
to count make sure that github can tell

287
00:13:51,790 --> 00:13:55,800
its API this uses the licensee project

288
00:13:55,800 --> 00:13:59,649
there are some license sometimes people

289
00:13:59,649 --> 00:14:02,709
modify licenses in whether the API can

290
00:14:02,709 --> 00:14:06,519
not detect it please look into that so

291
00:14:06,519 --> 00:14:08,890
to make sure that it's being detected

292
00:14:08,890 --> 00:14:11,440
your life that you practice open source

293
00:14:11,440 --> 00:14:13,600
and that a robot can tell that your

294
00:14:13,600 --> 00:14:16,540
project is open source some examples I

295
00:14:16,540 --> 00:14:20,410
did analyzing code take the top Java

296
00:14:20,410 --> 00:14:24,430
imports in 2013 take the ones from 2015

297
00:14:24,430 --> 00:14:27,490
and let's see what happens well the

298
00:14:27,490 --> 00:14:30,760
results I got here is that we got a lot

299
00:14:30,760 --> 00:14:32,829
more Android imports we got a lot more

300
00:14:32,829 --> 00:14:36,550
injection import and a lot of mojito

301
00:14:36,550 --> 00:14:39,880
tests we can go deeper my how this

302
00:14:39,880 --> 00:14:42,250
happened but thank you for testing your

303
00:14:42,250 --> 00:14:45,850
code or I love example or how to request

304
00:14:45,850 --> 00:14:49,029
a feature someone was asking hey I would

305
00:14:49,029 --> 00:14:53,440
love if the package time had a time

306
00:14:53,440 --> 00:14:56,380
until method and then the go team

307
00:14:56,380 --> 00:14:58,990
analyzed should we add this or not and

308
00:14:58,990 --> 00:15:01,120
France asked who is giving a talk right

309
00:15:01,120 --> 00:15:03,550
now in a different room if he's looking

310
00:15:03,550 --> 00:15:08,890
at the on the live stream from Celsius

311
00:15:08,890 --> 00:15:12,490
wrote a query and so that at least 2,000

312
00:15:12,490 --> 00:15:15,100
projects written in go would benefit

313
00:15:15,100 --> 00:15:17,920
from having this method and the the

314
00:15:17,920 --> 00:15:20,500
method was implemented and it's going

315
00:15:20,500 --> 00:15:23,420
live next month and these are we

316
00:15:23,420 --> 00:15:25,610
good way of asking for features used to

317
00:15:25,610 --> 00:15:27,820
date behind it

318
00:15:27,820 --> 00:15:30,740
am I out of time yeah sorry Philippe

319
00:15:30,740 --> 00:15:32,840
that's all the time we ask there thank

320
00:15:32,840 --> 00:15:37,010
you very much for you well the records

321
00:15:37,010 --> 00:15:40,400
of like our online video didn't sleep

322
00:15:40,400 --> 00:15:43,190
well Kenny people thank you yes please

323
00:15:43,190 --> 00:15:45,740
find me I find the talk fine I have

324
00:15:45,740 --> 00:15:47,780
links and everything else sorry for

325
00:15:47,780 --> 00:15:50,540
taking a little long thank you very much

326
00:15:50,540 --> 00:15:57,280
[Applause]

