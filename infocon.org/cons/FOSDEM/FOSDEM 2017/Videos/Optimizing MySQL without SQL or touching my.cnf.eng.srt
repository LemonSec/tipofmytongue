1
00:00:06,130 --> 00:00:10,010
my first talk today is optimizing my

2
00:00:10,010 --> 00:00:13,459
sequel felt sick or touching my dot CNF

3
00:00:13,459 --> 00:00:16,850
and there is a reason why I called this

4
00:00:16,850 --> 00:00:20,000
talk like that because it's a bit of

5
00:00:20,000 --> 00:00:24,290
information about me I'm sweet for last

6
00:00:24,290 --> 00:00:28,990
10 years and joined Dropbox as sre in

7
00:00:28,990 --> 00:00:36,680
2015 but despite him working as a member

8
00:00:36,680 --> 00:00:38,450
of storage team and I'm working on

9
00:00:38,450 --> 00:00:40,520
metadata storage and touching my sickle

10
00:00:40,520 --> 00:00:43,460
a lot I had known GBA experience

11
00:00:43,460 --> 00:00:47,180
previously so I have no idea about how

12
00:00:47,180 --> 00:00:50,180
to optimize or speed up Mexico a

13
00:00:50,180 --> 00:00:56,059
modifying Mexico configuration and let's

14
00:00:56,059 --> 00:00:58,969
look what is a Dropbox today

15
00:00:58,969 --> 00:01:02,899
so Dropbox days actually is 500 million

16
00:01:02,899 --> 00:01:06,850
users we have 200,000 business users and

17
00:01:06,850 --> 00:01:09,740
the users are uploading 1.2 billion

18
00:01:09,740 --> 00:01:13,749
files every day it's a quite big scale

19
00:01:13,749 --> 00:01:19,810
we have tens of thousands servers where

20
00:01:19,810 --> 00:01:22,520
we are located in multiple data centers

21
00:01:22,520 --> 00:01:24,560
across multiple continents in multiple

22
00:01:24,560 --> 00:01:28,249
countries and we're storing petabytes of

23
00:01:28,249 --> 00:01:32,200
data and exabytes of raw data and that

24
00:01:32,200 --> 00:01:40,279
leads to quite obvious problem that we

25
00:01:40,279 --> 00:01:42,349
need to optimize our performance because

26
00:01:42,349 --> 00:01:44,539
we want to say from the power we want to

27
00:01:44,539 --> 00:01:46,729
say from the number of hardware we are

28
00:01:46,729 --> 00:01:48,919
buying and we want to reduce latency

29
00:01:48,919 --> 00:01:55,119
sets theorem so this talk is covering

30
00:01:55,119 --> 00:01:59,090
optimizing my sequel and mostly we're

31
00:01:59,090 --> 00:02:01,609
cover I'm covering how we are building

32
00:02:01,609 --> 00:02:06,459
in Mexico and just rebuilding like is it

33
00:02:06,459 --> 00:02:10,669
is it make sense to build Mexico in your

34
00:02:10,669 --> 00:02:13,070
own infrastructure or is it just enough

35
00:02:13,070 --> 00:02:15,770
to use vendor packages

36
00:02:15,770 --> 00:02:21,350
and for every performance improvements

37
00:02:21,350 --> 00:02:23,900
alright for every performance change

38
00:02:23,900 --> 00:02:28,180
it's actually reasonable to use

39
00:02:28,180 --> 00:02:30,860
benchmarks information marks were using

40
00:02:30,860 --> 00:02:33,140
sis bench and this is example for

41
00:02:33,140 --> 00:02:35,390
configuration we're using for running

42
00:02:35,390 --> 00:02:39,380
sis bench so we're running several tests

43
00:02:39,380 --> 00:02:41,360
of different number of threats and

44
00:02:41,360 --> 00:02:45,380
number of races variable in this

45
00:02:45,380 --> 00:02:47,930
particular test we reason number of

46
00:02:47,930 --> 00:02:51,620
threats from 1 to 60 for each test was

47
00:02:51,620 --> 00:02:56,710
running for 5 minutes for testing

48
00:02:56,710 --> 00:03:01,270
compute it's enough to run on 5 minutes

49
00:03:01,270 --> 00:03:06,560
so we're just using standard law LTP

50
00:03:06,560 --> 00:03:09,950
read write test from C's bench and for

51
00:03:09,950 --> 00:03:11,870
this particular test reason master

52
00:03:11,870 --> 00:03:17,090
branch and this is quite fresh check out

53
00:03:17,090 --> 00:03:19,340
of C's bench

54
00:03:19,340 --> 00:03:21,410
sergeant stand there would be a this

55
00:03:21,410 --> 00:03:26,270
bench talk later this day so just we're

56
00:03:26,270 --> 00:03:29,600
creating 16 tables each table contains 1

57
00:03:29,600 --> 00:03:35,690
million rows so these are testing

58
00:03:35,690 --> 00:03:36,320
subjects

59
00:03:36,320 --> 00:03:40,610
this is examples of hardware not exactly

60
00:03:40,610 --> 00:03:43,959
hardware but systems worth testing on

61
00:03:43,959 --> 00:03:46,940
we're historically work for quite long

62
00:03:46,940 --> 00:03:51,080
time on Ubuntu 12 hour and we still in

63
00:03:51,080 --> 00:03:53,660
the process of migrating to Ubuntu 1604

64
00:03:53,660 --> 00:03:59,300
and both systems have different kernels

65
00:03:59,300 --> 00:04:02,330
we are currently running 3.16 on 1204

66
00:04:02,330 --> 00:04:09,140
and 4.8 on 1604 there's a different set

67
00:04:09,140 --> 00:04:12,700
of compilers available on each platform

68
00:04:12,700 --> 00:04:17,890
on 1204 these are just EC 4.6 4.9

69
00:04:17,890 --> 00:04:20,890
incline 3.0 which are pretty old by this

70
00:04:20,890 --> 00:04:25,420
time and 1604 these are GCC for point

71
00:04:25,420 --> 00:04:28,270
nine which is just back ported for

72
00:04:28,270 --> 00:04:32,410
Becker's compatibility to 1604 see five

73
00:04:32,410 --> 00:04:36,160
point four and rank three point eight so

74
00:04:36,160 --> 00:04:38,760
both machines are running this specific

75
00:04:38,760 --> 00:04:45,190
CPU and both machines are completely the

76
00:04:45,190 --> 00:04:50,230
same in terms of hardware so speaking

77
00:04:50,230 --> 00:04:52,600
little bit about built infrastructure

78
00:04:52,600 --> 00:04:56,650
Dropbox we use basil as an our build

79
00:04:56,650 --> 00:04:59,830
system and basil is tightly integrated

80
00:04:59,830 --> 00:05:03,490
and our build system but my Seco uses

81
00:05:03,490 --> 00:05:07,800
CMake as a build system and basil is not

82
00:05:07,800 --> 00:05:10,950
compatible to open source software and

83
00:05:10,950 --> 00:05:13,600
if you're trying to build something of

84
00:05:13,600 --> 00:05:16,180
based on integrate something to your

85
00:05:16,180 --> 00:05:20,919
basil build is it auto tools based or

86
00:05:20,919 --> 00:05:23,169
cement based or any other build system

87
00:05:23,169 --> 00:05:26,680
you're literally screwed and we need to

88
00:05:26,680 --> 00:05:30,280
do the same or maybe we were going to

89
00:05:30,280 --> 00:05:33,460
open source that we actually did we

90
00:05:33,460 --> 00:05:35,320
actually wrote C make two basil

91
00:05:35,320 --> 00:05:38,800
converter tool which actually helps us

92
00:05:38,800 --> 00:05:42,910
to integrate into basil build its

93
00:05:42,910 --> 00:05:45,120
section of that part to write that

94
00:05:45,120 --> 00:05:52,020
actually did that during one night so

95
00:05:52,169 --> 00:05:54,430
important stuff before running any

96
00:05:54,430 --> 00:05:56,320
benchmarks and actually made this

97
00:05:56,320 --> 00:05:58,750
mistake another one of these machines

98
00:05:58,750 --> 00:06:02,340
and thanks to boon to developers

99
00:06:02,340 --> 00:06:06,490
starting from 1 to 1604 cpu frac scaling

100
00:06:06,490 --> 00:06:10,630
governor set to Power Save and your CPU

101
00:06:10,630 --> 00:06:13,979
is justin power safe mode

102
00:06:14,539 --> 00:06:17,820
so don't forget to set CPU frac

103
00:06:17,820 --> 00:06:23,130
performance governor and let's start so

104
00:06:23,130 --> 00:06:25,680
what we are going to optimize is

105
00:06:25,680 --> 00:06:28,889
optimize my sequel just rebuilding it

106
00:06:28,889 --> 00:06:32,220
and one of advanced compiler techniques

107
00:06:32,220 --> 00:06:35,580
is profile guided optimizations and what

108
00:06:35,580 --> 00:06:39,020
is the profile guided optimizations

109
00:06:39,020 --> 00:06:42,090
you're literally very building building

110
00:06:42,090 --> 00:06:45,000
special build of your binary which

111
00:06:45,000 --> 00:06:48,680
starts collecting training data and then

112
00:06:48,680 --> 00:06:51,630
when you have enough collect enough

113
00:06:51,630 --> 00:06:55,080
training data you're rebuilding your

114
00:06:55,080 --> 00:06:59,190
binary again and it optimizes branches

115
00:06:59,190 --> 00:07:01,430
use better branch prediction it

116
00:07:01,430 --> 00:07:04,139
relocates code paths it has better

117
00:07:04,139 --> 00:07:06,000
inlining because it actually no

118
00:07:06,000 --> 00:07:10,949
statistics on how the code is used so it

119
00:07:10,949 --> 00:07:13,650
usually requires to rebuild but not in

120
00:07:13,650 --> 00:07:17,490
the same not not in every case in case

121
00:07:17,490 --> 00:07:20,970
of clank and as far as instant thanks to

122
00:07:20,970 --> 00:07:25,260
google clan can use perth data so you

123
00:07:25,260 --> 00:07:27,840
don't need to rebuild you can just

124
00:07:27,840 --> 00:07:29,520
collect birth data and build using pair

125
00:07:29,520 --> 00:07:33,690
data which is a bit easier so a common

126
00:07:33,690 --> 00:07:37,050
mistake collection profile data from

127
00:07:37,050 --> 00:07:39,150
unit tests don't do that because union

128
00:07:39,150 --> 00:07:41,250
tests usually are checking corner cases

129
00:07:41,250 --> 00:07:43,050
and you don't want to optimize for

130
00:07:43,050 --> 00:07:45,100
corner cases

131
00:07:45,100 --> 00:07:48,210
so literally your code would be fast on

132
00:07:48,210 --> 00:07:50,380
some corner cases like RIT are an

133
00:07:50,380 --> 00:07:53,820
exception but not in any other case and

134
00:07:53,820 --> 00:08:00,030
let's see how we're building with GCC so

135
00:08:00,030 --> 00:08:03,570
to build a profile guided optimization

136
00:08:03,570 --> 00:08:08,350
built with GCC we have two flags one of

137
00:08:08,350 --> 00:08:10,870
them is to enable profile data

138
00:08:10,870 --> 00:08:13,720
collection F profile generate there's

139
00:08:13,720 --> 00:08:16,210
another variety of this flag which

140
00:08:16,210 --> 00:08:18,520
allows you to set the output year where

141
00:08:18,520 --> 00:08:21,840
you want to write or file data and

142
00:08:21,840 --> 00:08:25,300
second flag is F profile use it actually

143
00:08:25,300 --> 00:08:27,820
when you're booting your binary it uses

144
00:08:27,820 --> 00:08:31,330
profile data and in case of mexico

145
00:08:31,330 --> 00:08:33,760
mexico it doesn't work and it doesn't

146
00:08:33,760 --> 00:08:35,490
work because Mexico is multi-threaded

147
00:08:35,490 --> 00:08:39,460
application and profile data would have

148
00:08:39,460 --> 00:08:41,890
incorrect counters and in order to fix

149
00:08:41,890 --> 00:08:43,240
that

150
00:08:43,240 --> 00:08:45,250
we need to use F profile correction

151
00:08:45,250 --> 00:08:49,780
which would tell GCC just try to fix

152
00:08:49,780 --> 00:08:57,280
counters for us and bad news for Ubuntu

153
00:08:57,280 --> 00:09:01,930
6:12 for users it doesn't work with GCC

154
00:09:01,930 --> 00:09:08,080
4.6 and 4.9 and flags are working but

155
00:09:08,080 --> 00:09:14,110
pgo doesn't work for my sequel and yeah

156
00:09:14,110 --> 00:09:18,190
that's that's about GCC so another

157
00:09:18,190 --> 00:09:21,190
compiler we have in distribution is

158
00:09:21,190 --> 00:09:26,890
clank-clank is they set up a bit

159
00:09:26,890 --> 00:09:28,270
different that has a little bit

160
00:09:28,270 --> 00:09:32,260
different set of flags and it's F

161
00:09:32,260 --> 00:09:35,410
profile generated but before they

162
00:09:35,410 --> 00:09:37,810
introduced

163
00:09:37,810 --> 00:09:41,740
comment line are back compatibility of

164
00:09:41,740 --> 00:09:43,990
GCC it was called to be different it was

165
00:09:43,990 --> 00:09:46,740
called profile instruct generate and

166
00:09:46,740 --> 00:09:49,600
there is a interesting languages F

167
00:09:49,600 --> 00:09:52,390
profile sample use which is exactly the

168
00:09:52,390 --> 00:09:57,329
flag I mentioned to use their data so

169
00:09:57,329 --> 00:10:02,410
bad news again for Ubuntu 1204 users no

170
00:10:02,410 --> 00:10:07,180
Pedro support and Clint 3-0 at all at

171
00:10:07,180 --> 00:10:07,690
all

172
00:10:07,690 --> 00:10:14,040
so we rebuilt my sickle with the jaw and

173
00:10:14,040 --> 00:10:19,029
we ran tests with this bench and we did

174
00:10:19,029 --> 00:10:23,220
several passes so we don't have any

175
00:10:23,220 --> 00:10:28,779
rotation Center or test and here results

176
00:10:28,779 --> 00:10:32,950
for 200 I didn't know how the colors are

177
00:10:32,950 --> 00:10:37,329
looking here but I can I can tell what's

178
00:10:37,329 --> 00:10:43,380
there so we have Glenn 3-0 is a winner

179
00:10:43,380 --> 00:10:47,380
it produces binary of highest throughput

180
00:10:47,380 --> 00:10:50,560
and throughput is something about 10%

181
00:10:50,560 --> 00:10:54,640
more on using building of Clank and then

182
00:10:54,640 --> 00:10:58,839
building a GCC but in the same time both

183
00:10:58,839 --> 00:11:02,980
GCC and clang Kira which old but if you

184
00:11:02,980 --> 00:11:06,730
stuck with TOEFL for and you should not

185
00:11:06,730 --> 00:11:10,839
do that because TOEFL for LTS ends this

186
00:11:10,839 --> 00:11:15,339
April it could be in good choice to just

187
00:11:15,339 --> 00:11:19,529
rebuilt going 3.0 and get like 10%

188
00:11:19,529 --> 00:11:22,160
performance improvement

189
00:11:22,160 --> 00:11:27,680
and here our response to n looks and it

190
00:11:27,680 --> 00:11:31,990
is the same so the lower is better and

191
00:11:31,990 --> 00:11:36,500
gland produces lower latency by nurse as

192
00:11:36,500 --> 00:11:40,579
well which is which is good so that

193
00:11:40,579 --> 00:11:44,319
slide is more interesting here we have

194
00:11:44,319 --> 00:11:49,100
these bench results for 1604 builds and

195
00:11:49,100 --> 00:11:52,029
on 16 are for we're actually able to use

196
00:11:52,029 --> 00:12:00,100
PTO and there is a bit interesting and

197
00:12:00,100 --> 00:12:04,670
we haven't found out why but GCC 55.4

198
00:12:04,670 --> 00:12:07,639
produces really bad results maybe

199
00:12:07,639 --> 00:12:10,509
something's broken of our compiler and

200
00:12:10,509 --> 00:12:15,139
not not the problem GCC but of our built

201
00:12:15,139 --> 00:12:18,230
infrastructure but we decided just to

202
00:12:18,230 --> 00:12:24,230
include that to be honest and GCC 5.4

203
00:12:24,230 --> 00:12:27,250
with PTO produces pretty good results

204
00:12:27,250 --> 00:12:32,060
it's generally 20% faster than just GCC

205
00:12:32,060 --> 00:12:36,740
5.4 and you can achieve that just just

206
00:12:36,740 --> 00:12:41,540
rebuilding your Mexico binary isn't good

207
00:12:41,540 --> 00:12:47,660
job and any every other compiler is a

208
00:12:47,660 --> 00:12:52,639
little bit slower but just using PTO you

209
00:12:52,639 --> 00:12:55,310
can achieve 20% performance improvement

210
00:12:55,310 --> 00:13:00,850
and gear latencies so looking at it

211
00:13:00,850 --> 00:13:05,899
lower the lower part is GCC if I went

212
00:13:05,899 --> 00:13:09,139
for the job built for that test we did

213
00:13:09,139 --> 00:13:10,850
not write Clank

214
00:13:10,850 --> 00:13:13,910
be job builds so we don't have Clank

215
00:13:13,910 --> 00:13:17,660
data here yet but it will be interesting

216
00:13:17,660 --> 00:13:20,660
to compare client B Joe built versus GCC

217
00:13:20,660 --> 00:13:23,540
with Joe built but licensor latencies

218
00:13:23,540 --> 00:13:27,410
also something like 20% lower for each

219
00:13:27,410 --> 00:13:29,280
or builds

220
00:13:29,280 --> 00:13:33,380
so this is one of interest in

221
00:13:33,380 --> 00:13:36,210
optimization techniques when you are not

222
00:13:36,210 --> 00:13:39,270
just you're not touching bicycle

223
00:13:39,270 --> 00:13:40,860
configuration at all and you're speeding

224
00:13:40,860 --> 00:13:43,260
up your Mexico

225
00:13:43,260 --> 00:13:47,130
another interesting advanced compiler

226
00:13:47,130 --> 00:13:50,550
optimization technique is link time

227
00:13:50,550 --> 00:13:54,570
optimizations also known as full program

228
00:13:54,570 --> 00:13:58,580
optimization and it is supported by both

229
00:13:58,580 --> 00:14:03,540
modern GCC and clang but my secure code

230
00:14:03,540 --> 00:14:07,110
base Mexico code base is not healthy all

231
00:14:07,110 --> 00:14:09,600
compatible top and a little bit what is

232
00:14:09,600 --> 00:14:14,940
the LG o until is when compiler instead

233
00:14:14,940 --> 00:14:16,920
of producing object code in compilation

234
00:14:16,920 --> 00:14:19,290
units it produces intermediate

235
00:14:19,290 --> 00:14:22,760
representation and linker does actual

236
00:14:22,760 --> 00:14:26,790
compilation and optimizations so you're

237
00:14:26,790 --> 00:14:31,500
postponing actual optimization to the

238
00:14:31,500 --> 00:14:34,460
link stage and linking the linker sees

239
00:14:34,460 --> 00:14:40,020
all object files and knows how how to in

240
00:14:40,020 --> 00:14:42,630
line like it can inline code from other

241
00:14:42,630 --> 00:14:45,660
object files which is not available with

242
00:14:45,660 --> 00:14:49,980
all tells you and but actually it's easy

243
00:14:49,980 --> 00:14:53,670
to fix in code base and we're going to

244
00:14:53,670 --> 00:14:56,990
start working on that pretty soon so

245
00:14:56,990 --> 00:15:00,080
we're going to send patches for that and

246
00:15:00,080 --> 00:15:02,820
it would be interesting to see out your

247
00:15:02,820 --> 00:15:05,700
results on other projects we're using we

248
00:15:05,700 --> 00:15:07,740
saw something or something about like

249
00:15:07,740 --> 00:15:09,840
five percent performance improvement so

250
00:15:09,840 --> 00:15:15,300
which is also interesting and so that's

251
00:15:15,300 --> 00:15:19,200
basically it what we accomplished by

252
00:15:19,200 --> 00:15:21,900
this time with optimizations we we have

253
00:15:21,900 --> 00:15:24,600
like 20 percent performance improvement

254
00:15:24,600 --> 00:15:27,900
just rebuilt in Mexico and we have

255
00:15:27,900 --> 00:15:30,060
actually more ideas what we want to do

256
00:15:30,060 --> 00:15:35,700
next we're working on because we were

257
00:15:35,700 --> 00:15:39,230
using this bench as a training data for

258
00:15:39,230 --> 00:15:41,890
B jaw

259
00:15:41,890 --> 00:15:44,230
we're testing with this bench again we

260
00:15:44,230 --> 00:15:48,160
actually point to start using aerial war

261
00:15:48,160 --> 00:15:51,670
Canyon data and for that we are going to

262
00:15:51,670 --> 00:15:53,320
start we actually started contributing

263
00:15:53,320 --> 00:15:56,320
token of playback and we're going to

264
00:15:56,320 --> 00:15:58,990
just play back the real reduction

265
00:15:58,990 --> 00:16:02,020
traffic we have in order to optimize our

266
00:16:02,020 --> 00:16:06,330
builds for production and another

267
00:16:06,330 --> 00:16:08,920
interesting thing that it's leads to

268
00:16:08,920 --> 00:16:11,440
interesting question that we don't have

269
00:16:11,440 --> 00:16:14,110
only one single database we have many

270
00:16:14,110 --> 00:16:16,300
databases and workload profiles are

271
00:16:16,300 --> 00:16:19,210
different and we we haven't decided what

272
00:16:19,210 --> 00:16:23,740
to do here because it would be

273
00:16:23,740 --> 00:16:26,140
interesting to build to have some some

274
00:16:26,140 --> 00:16:29,080
generic training data we can use some

275
00:16:29,080 --> 00:16:33,580
every production database so another

276
00:16:33,580 --> 00:16:35,790
interesting option is building with M

277
00:16:35,790 --> 00:16:41,580
our native I have missed out there so it

278
00:16:41,580 --> 00:16:44,920
it allows compiler to use latest

279
00:16:44,920 --> 00:16:49,090
extensions like a VX or a x2 and usually

280
00:16:49,090 --> 00:16:51,600
it just uses some generic compiler set a

281
00:16:51,600 --> 00:16:56,110
compiler spew instruction set but the

282
00:16:56,110 --> 00:16:58,840
that you can also achieve like free for

283
00:16:58,840 --> 00:17:02,890
sense of performance boost and another

284
00:17:02,890 --> 00:17:05,740
interesting thing that when we are

285
00:17:05,740 --> 00:17:08,410
running my second production we're

286
00:17:08,410 --> 00:17:10,900
usually usually running one single

287
00:17:10,900 --> 00:17:12,730
instance multi-threaded instance on

288
00:17:12,730 --> 00:17:15,010
single machine but we actually see in

289
00:17:15,010 --> 00:17:20,079
birth data cqp i interface and usually

290
00:17:20,079 --> 00:17:23,829
when you have multi-core machines you

291
00:17:23,829 --> 00:17:29,980
have usually you have two slots and CPUs

292
00:17:29,980 --> 00:17:33,010
if one CPU want to access the memory and

293
00:17:33,010 --> 00:17:36,070
from another cpu slot you use this keep

294
00:17:36,070 --> 00:17:39,040
a link and it actually slower than using

295
00:17:39,040 --> 00:17:42,370
local memory not significantly slower

296
00:17:42,370 --> 00:17:44,910
but still we see like three four percent

297
00:17:44,910 --> 00:17:48,580
here and another option we we probably

298
00:17:48,580 --> 00:17:52,120
would run to Mexico instances to

299
00:17:52,120 --> 00:17:55,590
are some single hardware machine and

300
00:17:55,590 --> 00:17:59,740
each amount of Numa CTL to each slot and

301
00:17:59,740 --> 00:18:08,530
to each memory slot so that's that's it

302
00:18:08,530 --> 00:18:11,190
questions

303
00:18:15,830 --> 00:18:19,070
[Music]

304
00:18:20,760 --> 00:18:23,780
so could you repeat the question yeah

305
00:18:23,780 --> 00:18:27,230
could you repeat the question

306
00:18:31,290 --> 00:18:34,380
do we have some public Debian package of

307
00:18:34,380 --> 00:18:40,980
oh so yeah like as I said we are not

308
00:18:40,980 --> 00:18:43,049
using that meant packages for our built

309
00:18:43,049 --> 00:18:45,270
infrastructure where isn't it with basil

310
00:18:45,270 --> 00:18:48,870
so we're unfortunately we're not we're

311
00:18:48,870 --> 00:18:52,040
not building that packages

312
00:19:03,270 --> 00:19:08,230
so yeah it so the question is how pgo

313
00:19:08,230 --> 00:19:15,570
works so Joe built collects data on

314
00:19:15,570 --> 00:19:20,620
branch uses and it writes that into the

315
00:19:20,620 --> 00:19:26,020
ccda files in case of GCC and using that

316
00:19:26,020 --> 00:19:28,240
statistics it just writes its statistics

317
00:19:28,240 --> 00:19:32,559
it can understand which branch branch

318
00:19:32,559 --> 00:19:36,700
branches are curved earlier which are

319
00:19:36,700 --> 00:19:41,590
not yes yes it's exactly what it's about

320
00:19:41,590 --> 00:19:44,520
right an object called

321
00:20:08,570 --> 00:20:11,570
without

322
00:20:19,309 --> 00:20:24,890
so we are collecting basic events I can

323
00:20:24,890 --> 00:20:28,590
yeah I don't recall correctly what is

324
00:20:28,590 --> 00:20:31,679
the size of data we have but we're also

325
00:20:31,679 --> 00:20:36,929
running an a table on the machines yeah

326
00:20:36,929 --> 00:20:41,179
okay yeah thank you

327
00:20:44,750 --> 00:20:48,210
so Maxima be around and so if you have

328
00:20:48,210 --> 00:20:50,970
questions just take him go outside and

329
00:20:50,970 --> 00:20:53,220
ask them so many question pave a beer

330
00:20:53,220 --> 00:20:57,890
and it will speak for a full day right

