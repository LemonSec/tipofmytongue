1
00:00:05,200 --> 00:00:08,800
and our next talk will be

2
00:00:07,279 --> 00:00:10,960
about one of the most important

3
00:00:08,800 --> 00:00:14,160
buzzwords nowadays machine learning

4
00:00:10,960 --> 00:00:16,240
and how his project helped the web

5
00:00:14,160 --> 00:00:17,039
compatibility team who has to parse

6
00:00:16,239 --> 00:00:19,759
around

7
00:00:17,039 --> 00:00:21,359
1 000 issues from volunteers about the

8
00:00:19,760 --> 00:00:24,880
open web and all

9
00:00:21,359 --> 00:00:26,480
the speaker janis janelos also known as

10
00:00:24,880 --> 00:00:29,679
john or famously

11
00:00:26,480 --> 00:00:31,679
nemo and yes we found him

12
00:00:29,679 --> 00:00:33,280
is part of open innovation and has this

13
00:00:31,679 --> 00:00:34,800
project again as i mentioned together

14
00:00:33,280 --> 00:00:35,520
with the web compatibility team and

15
00:00:34,800 --> 00:00:38,320
mozilla

16
00:00:35,520 --> 00:00:38,320
please welcome john

17
00:00:38,830 --> 00:00:45,199
[Applause]

18
00:00:42,480 --> 00:00:45,839
so hi thank you for having me here um my

19
00:00:45,200 --> 00:00:47,520
name is

20
00:00:45,840 --> 00:00:48,960
um janice janellos i'm working in the

21
00:00:47,520 --> 00:00:51,280
open innovation team um

22
00:00:48,960 --> 00:00:52,879
as a software engineer and i'm here to

23
00:00:51,280 --> 00:00:54,960
talk to you about web compatibility and

24
00:00:52,879 --> 00:00:59,839
machine learning

25
00:00:54,960 --> 00:00:59,840
um so here's a rough outline

26
00:01:00,559 --> 00:01:04,399
and yeah open innovation so um my team

27
00:01:03,920 --> 00:01:06,080
is

28
00:01:04,400 --> 00:01:10,080
like my team is trying to bring

29
00:01:06,080 --> 00:01:12,158
innovation in an open way across the org

30
00:01:10,080 --> 00:01:13,600
and experiment with other teams and

31
00:01:12,159 --> 00:01:16,159
ideas um

32
00:01:13,600 --> 00:01:16,960
and prototype stuff that might work

33
00:01:16,159 --> 00:01:21,200
might not work

34
00:01:16,960 --> 00:01:22,720
um iterate and try to improve things

35
00:01:21,200 --> 00:01:25,200
in an open way and also trying to keep

36
00:01:22,720 --> 00:01:26,640
track of the value that it brings back

37
00:01:25,200 --> 00:01:29,920
and one of the projects that we worked

38
00:01:26,640 --> 00:01:33,680
with is web compatibility team

39
00:01:29,920 --> 00:01:35,600
so the the team's initiative is to

40
00:01:33,680 --> 00:01:36,960
tackle the issue of web compatibility in

41
00:01:35,600 --> 00:01:40,000
the in the web

42
00:01:36,960 --> 00:01:42,798
which means that we are trying to reduce

43
00:01:40,000 --> 00:01:44,799
the issues where like different websites

44
00:01:42,799 --> 00:01:47,520
render differently or behave differently

45
00:01:44,799 --> 00:01:48,479
in different browsers or where apps or

46
00:01:47,520 --> 00:01:49,920
projects or

47
00:01:48,479 --> 00:01:52,079
websites don't work in different

48
00:01:49,920 --> 00:01:55,119
browsers uh and

49
00:01:52,079 --> 00:01:55,839
part of it is gathering feedback from

50
00:01:55,119 --> 00:01:59,600
users

51
00:01:55,840 --> 00:02:02,719
and getting input

52
00:01:59,600 --> 00:02:06,399
and try using the input and providing

53
00:02:02,719 --> 00:02:09,840
feedback back to the browser vendors

54
00:02:06,399 --> 00:02:13,200
so here how it looks like like a very

55
00:02:09,840 --> 00:02:15,599
basic reporting workflow so let's say we

56
00:02:13,200 --> 00:02:17,920
are an example.com and there is a

57
00:02:15,599 --> 00:02:20,959
compatibility issue then users click on

58
00:02:17,920 --> 00:02:24,640
report site issue then they fill a form

59
00:02:20,959 --> 00:02:26,319
and after that it goes through our um

60
00:02:24,640 --> 00:02:28,879
process and it generates an issue on

61
00:02:26,319 --> 00:02:30,640
github um

62
00:02:28,879 --> 00:02:33,280
and the issue is usually like some sort

63
00:02:30,640 --> 00:02:35,200
of uh basic title around what's the

64
00:02:33,280 --> 00:02:37,760
website and what's like the generic

65
00:02:35,200 --> 00:02:39,200
type of issue and then if you dive into

66
00:02:37,760 --> 00:02:40,560
there's like more details on how to

67
00:02:39,200 --> 00:02:43,119
reproduce stuff

68
00:02:40,560 --> 00:02:44,400
and uh where like with different

69
00:02:43,120 --> 00:02:47,120
browsers or devices

70
00:02:44,400 --> 00:02:48,319
uh the user has users have tried this

71
00:02:47,120 --> 00:02:50,480
and

72
00:02:48,319 --> 00:02:51,518
even some trace some tracebacks from the

73
00:02:50,480 --> 00:02:53,200
browser

74
00:02:51,519 --> 00:02:55,840
um and as you can see part of the

75
00:02:53,200 --> 00:02:58,799
process of triaging is

76
00:02:55,840 --> 00:02:59,760
putting labels and like people doing

77
00:02:58,800 --> 00:03:01,200
manual work

78
00:02:59,760 --> 00:03:02,959
in order to see what's wrong or

79
00:03:01,200 --> 00:03:04,238
something is false positive or is like

80
00:03:02,959 --> 00:03:05,680
something that is valuable

81
00:03:04,239 --> 00:03:07,120
or something that is very valuable so

82
00:03:05,680 --> 00:03:08,640
for example let's say wikipedia is

83
00:03:07,120 --> 00:03:10,080
broken on a browser then it's probably

84
00:03:08,640 --> 00:03:13,040
much more important than i don't know

85
00:03:10,080 --> 00:03:16,560
like a very very tiny local website

86
00:03:13,040 --> 00:03:19,440
um so this way this is

87
00:03:16,560 --> 00:03:21,120
um sorry this is where most of the

88
00:03:19,440 --> 00:03:23,280
triaging happens

89
00:03:21,120 --> 00:03:25,360
it's on github issues and using labels

90
00:03:23,280 --> 00:03:28,159
and milestones

91
00:03:25,360 --> 00:03:30,319
and disclaimer i'm not like any sort of

92
00:03:28,159 --> 00:03:32,640
data science machine learning expert

93
00:03:30,319 --> 00:03:34,238
but we try to see how innovation looks

94
00:03:32,640 --> 00:03:38,399
in that direction

95
00:03:34,239 --> 00:03:40,400
um and here's some context we

96
00:03:38,400 --> 00:03:42,000
we worked closely with welcome pat team

97
00:03:40,400 --> 00:03:43,840
um the idea is based on

98
00:03:42,000 --> 00:03:45,280
mozilla backpack which is firefox

99
00:03:43,840 --> 00:03:46,640
release engineering machine learning

100
00:03:45,280 --> 00:03:48,560
initiative

101
00:03:46,640 --> 00:03:50,079
where they were trying to introduce some

102
00:03:48,560 --> 00:03:51,519
sort of like machine learning machine

103
00:03:50,080 --> 00:03:54,239
principles and concepts in the whole

104
00:03:51,519 --> 00:03:55,840
triaging process

105
00:03:54,239 --> 00:03:58,080
and the problem statement that we came

106
00:03:55,840 --> 00:04:00,000
up is

107
00:03:58,080 --> 00:04:01,120
web compat projects reporting cadence is

108
00:04:00,000 --> 00:04:04,000
so fast so

109
00:04:01,120 --> 00:04:04,959
many people submit um when compatibility

110
00:04:04,000 --> 00:04:08,400
reports

111
00:04:04,959 --> 00:04:10,080
um firefox targets millions of users and

112
00:04:08,400 --> 00:04:13,920
this button is accessible to

113
00:04:10,080 --> 00:04:15,840
like all sorts of different websites and

114
00:04:13,920 --> 00:04:18,959
different users so

115
00:04:15,840 --> 00:04:20,639
people submit a lot of feedback but only

116
00:04:18,959 --> 00:04:21,519
a tiny fraction of the feedback is

117
00:04:20,639 --> 00:04:23,280
important

118
00:04:21,519 --> 00:04:24,960
and only tiny fraction of the user

119
00:04:23,280 --> 00:04:27,599
feedback ends up being valuable to any

120
00:04:24,960 --> 00:04:29,520
browser vendors

121
00:04:27,600 --> 00:04:31,040
so this this uh leads us to another

122
00:04:29,520 --> 00:04:32,799
problem statement that

123
00:04:31,040 --> 00:04:35,280
the web company the web compact

124
00:04:32,800 --> 00:04:36,880
reporting signal to noise ratio is too

125
00:04:35,280 --> 00:04:38,400
small um

126
00:04:36,880 --> 00:04:40,240
we have a lot of spam we have a lot of

127
00:04:38,400 --> 00:04:42,159
abusive content uh

128
00:04:40,240 --> 00:04:43,120
people probably won't necessarily

129
00:04:42,160 --> 00:04:45,040
understand the content of web

130
00:04:43,120 --> 00:04:46,960
compatibility so they might usually

131
00:04:45,040 --> 00:04:48,800
submit content like oh i

132
00:04:46,960 --> 00:04:50,159
have a virus or like i have spam where

133
00:04:48,800 --> 00:04:52,160
stuff like that so

134
00:04:50,160 --> 00:04:54,840
only a small fraction of the stuff that

135
00:04:52,160 --> 00:04:58,160
people submit actually end up being

136
00:04:54,840 --> 00:05:00,400
valuable and

137
00:04:58,160 --> 00:05:01,759
one thing that we came up with while

138
00:05:00,400 --> 00:05:02,960
trying to figure out how to improve the

139
00:05:01,759 --> 00:05:04,639
project is that we have a lot of

140
00:05:02,960 --> 00:05:09,359
historic data

141
00:05:04,639 --> 00:05:11,919
we have around 50k entries of reports

142
00:05:09,360 --> 00:05:13,520
and except of that we also have all the

143
00:05:11,919 --> 00:05:14,320
events and the historic data around the

144
00:05:13,520 --> 00:05:17,680
report so

145
00:05:14,320 --> 00:05:18,639
we have like five times more uh events

146
00:05:17,680 --> 00:05:20,080
around

147
00:05:18,639 --> 00:05:22,240
when something was labeled or whether

148
00:05:20,080 --> 00:05:25,840
something was a milestone

149
00:05:22,240 --> 00:05:29,360
who who got this issue assigned

150
00:05:25,840 --> 00:05:30,799
and stuff like that so we said that it

151
00:05:29,360 --> 00:05:34,000
might be a good idea to

152
00:05:30,800 --> 00:05:37,120
train a model using the web compat

153
00:05:34,000 --> 00:05:38,800
data as input to improve the triaging

154
00:05:37,120 --> 00:05:42,160
process

155
00:05:38,800 --> 00:05:45,199
but then we came to the reality

156
00:05:42,160 --> 00:05:47,039
and we figured out that we're not

157
00:05:45,199 --> 00:05:49,039
machine learning experts or we

158
00:05:47,039 --> 00:05:50,159
we barely know what these things look

159
00:05:49,039 --> 00:05:51,199
like but

160
00:05:50,160 --> 00:05:53,680
everything is going to be fine it's

161
00:05:51,199 --> 00:05:55,840
going to work out oh good um

162
00:05:53,680 --> 00:05:57,039
so here's how an example data point

163
00:05:55,840 --> 00:06:00,080
looks like

164
00:05:57,039 --> 00:06:01,680
we have title from the issue we have the

165
00:06:00,080 --> 00:06:03,240
content of the issue in

166
00:06:01,680 --> 00:06:04,800
free form and

167
00:06:03,240 --> 00:06:08,560
[Music]

168
00:06:04,800 --> 00:06:12,560
yeah everything lives on github

169
00:06:08,560 --> 00:06:14,479
so first steps we figured out that

170
00:06:12,560 --> 00:06:15,919
data living on github is not very future

171
00:06:14,479 --> 00:06:17,520
proof because we we

172
00:06:15,919 --> 00:06:19,919
tackled all sorts of different issues

173
00:06:17,520 --> 00:06:21,680
like throttling values of the api

174
00:06:19,919 --> 00:06:24,240
sometimes we couldn't get the data

175
00:06:21,680 --> 00:06:25,520
like they were not available or it was

176
00:06:24,240 --> 00:06:28,160
so much that

177
00:06:25,520 --> 00:06:29,198
even based on the like the github api

178
00:06:28,160 --> 00:06:33,120
policies it was

179
00:06:29,199 --> 00:06:36,240
barely doable to

180
00:06:33,120 --> 00:06:39,600
actually use this as a data storage so

181
00:06:36,240 --> 00:06:41,680
we we came up with the idea to use some

182
00:06:39,600 --> 00:06:43,680
other data storage and apparently

183
00:06:41,680 --> 00:06:45,520
elasticsearch and kibana was a good fit

184
00:06:43,680 --> 00:06:47,840
so what we did is we took all the web

185
00:06:45,520 --> 00:06:48,639
compat issues from the api in the json

186
00:06:47,840 --> 00:06:50,560
format

187
00:06:48,639 --> 00:06:53,360
we feed everything to elasticsearch and

188
00:06:50,560 --> 00:06:55,120
then we use kibana for the analytics

189
00:06:53,360 --> 00:06:56,560
and it was very useful because we never

190
00:06:55,120 --> 00:06:59,680
had the opportunity to actually

191
00:06:56,560 --> 00:07:00,960
have analytics around web compat reports

192
00:06:59,680 --> 00:07:02,960
and web compat data

193
00:07:00,960 --> 00:07:04,080
because usually what happens is

194
00:07:02,960 --> 00:07:07,359
everything used to live on

195
00:07:04,080 --> 00:07:10,479
github issues were in design law and

196
00:07:07,360 --> 00:07:11,919
we didn't have any like metadata or any

197
00:07:10,479 --> 00:07:14,000
analytics around it

198
00:07:11,919 --> 00:07:15,359
um so after that and after we figured

199
00:07:14,000 --> 00:07:17,120
out what

200
00:07:15,360 --> 00:07:18,400
like what we need to achieve and how

201
00:07:17,120 --> 00:07:21,199
data look like

202
00:07:18,400 --> 00:07:22,560
we we did some research and we we

203
00:07:21,199 --> 00:07:24,479
figured out there's like a

204
00:07:22,560 --> 00:07:27,120
big ecosystem around automatic learn

205
00:07:24,479 --> 00:07:30,240
like automatic machine learning tools

206
00:07:27,120 --> 00:07:33,199
um so two of the most

207
00:07:30,240 --> 00:07:34,800
popular ones is ludwig from uber which

208
00:07:33,199 --> 00:07:36,560
got a little bit hype because it's uber

209
00:07:34,800 --> 00:07:38,639
it's a big company that using tensorflow

210
00:07:36,560 --> 00:07:40,160
it builds up the networks the deep

211
00:07:38,639 --> 00:07:42,800
learning models

212
00:07:40,160 --> 00:07:44,319
uh based on just the csv and the other

213
00:07:42,800 --> 00:07:46,400
one is automgs

214
00:07:44,319 --> 00:07:48,400
uh which does pretty much the same in a

215
00:07:46,400 --> 00:07:50,000
more scrappy way

216
00:07:48,400 --> 00:07:52,159
and we figured out that even like with

217
00:07:50,000 --> 00:07:55,680
basic tooling and basic machine learning

218
00:07:52,160 --> 00:07:56,240
um models we we had some decent results

219
00:07:55,680 --> 00:07:58,319
and

220
00:07:56,240 --> 00:07:59,840
even like the decent results that we got

221
00:07:58,319 --> 00:08:01,680
like the basic

222
00:07:59,840 --> 00:08:03,758
accuracy that we got was probably good

223
00:08:01,680 --> 00:08:07,840
enough um

224
00:08:03,759 --> 00:08:10,560
so yeah we need to figure out

225
00:08:07,840 --> 00:08:13,840
like what's our data um so one of the

226
00:08:10,560 --> 00:08:16,879
most important

227
00:08:13,840 --> 00:08:18,719
things that we dealt with is actually

228
00:08:16,879 --> 00:08:20,720
came up with a proper data set

229
00:08:18,720 --> 00:08:22,560
that actually fit the purpose of our

230
00:08:20,720 --> 00:08:24,400
project and our problem statement

231
00:08:22,560 --> 00:08:26,639
and actually would help us and we

232
00:08:24,400 --> 00:08:27,840
figured out that by default even if we

233
00:08:26,639 --> 00:08:30,479
had like tons of data

234
00:08:27,840 --> 00:08:31,758
structured in a way that it's readable

235
00:08:30,479 --> 00:08:34,240
uh from

236
00:08:31,759 --> 00:08:35,279
the like tooling around uh the ecosystem

237
00:08:34,240 --> 00:08:37,760
and even though we

238
00:08:35,279 --> 00:08:39,679
it felt like we had something valuable

239
00:08:37,760 --> 00:08:40,000
we ended up having nothing in the first

240
00:08:39,679 --> 00:08:43,199
place

241
00:08:40,000 --> 00:08:44,959
because it didn't work like

242
00:08:43,200 --> 00:08:48,320
we felt that there's some correlation

243
00:08:44,959 --> 00:08:50,079
but things didn't work and the most

244
00:08:48,320 --> 00:08:52,000
weird example is that we came up with a

245
00:08:50,080 --> 00:08:53,920
model given the data set that we had

246
00:08:52,000 --> 00:08:55,920
and it always provided the right results

247
00:08:53,920 --> 00:08:58,479
which is suspicious by default

248
00:08:55,920 --> 00:09:00,160
um and we figured out that the data were

249
00:08:58,480 --> 00:09:02,480
kinda lying and they were biased

250
00:09:00,160 --> 00:09:03,199
so one of the most important things is

251
00:09:02,480 --> 00:09:06,160
uh

252
00:09:03,200 --> 00:09:07,839
that we worked closely with the teams

253
00:09:06,160 --> 00:09:09,439
that provide the data and the teams that

254
00:09:07,839 --> 00:09:10,320
do the actual triaging and do all the

255
00:09:09,440 --> 00:09:13,920
day-to-day

256
00:09:10,320 --> 00:09:17,040
um work just to figure out

257
00:09:13,920 --> 00:09:19,120
how to deal with the problem and after

258
00:09:17,040 --> 00:09:20,959
a couple of failures and after a couple

259
00:09:19,120 --> 00:09:23,920
of attempts that

260
00:09:20,959 --> 00:09:24,479
they were very like very biased very of

261
00:09:23,920 --> 00:09:26,479
and

262
00:09:24,480 --> 00:09:28,399
very suspicious on the results um we

263
00:09:26,480 --> 00:09:30,080
figured out that the

264
00:09:28,399 --> 00:09:32,160
value of the data was not on the actual

265
00:09:30,080 --> 00:09:33,839
data set but in the process of the

266
00:09:32,160 --> 00:09:37,360
events around the data

267
00:09:33,839 --> 00:09:38,640
um so apparently what did the trick in

268
00:09:37,360 --> 00:09:39,440
our case is going through all the

269
00:09:38,640 --> 00:09:42,560
historic data

270
00:09:39,440 --> 00:09:43,279
find all the events and see how triaging

271
00:09:42,560 --> 00:09:46,399
translates

272
00:09:43,279 --> 00:09:49,519
in actions from the users and

273
00:09:46,399 --> 00:09:53,120
based on that we we defined

274
00:09:49,519 --> 00:09:55,680
what a good or a bad

275
00:09:53,120 --> 00:09:57,120
report is how we defined it based on

276
00:09:55,680 --> 00:09:59,599
this

277
00:09:57,120 --> 00:10:01,760
this kind of statement and we built a

278
00:09:59,600 --> 00:10:04,880
data set

279
00:10:01,760 --> 00:10:06,720
and after that we

280
00:10:04,880 --> 00:10:07,920
came to the conclusion that we have a

281
00:10:06,720 --> 00:10:10,560
decent data set we have

282
00:10:07,920 --> 00:10:11,519
a model that works but we need something

283
00:10:10,560 --> 00:10:15,040
that works

284
00:10:11,519 --> 00:10:16,640
in production and we need something that

285
00:10:15,040 --> 00:10:18,640
it's not just the script based automatic

286
00:10:16,640 --> 00:10:20,160
tooling that we barely know how it works

287
00:10:18,640 --> 00:10:21,439
we have some indications that it works

288
00:10:20,160 --> 00:10:23,030
well but

289
00:10:21,440 --> 00:10:25,120
not really

290
00:10:23,030 --> 00:10:28,240
[Music]

291
00:10:25,120 --> 00:10:30,160
and yeah we we tried to see what

292
00:10:28,240 --> 00:10:33,200
ecosystem looked like

293
00:10:30,160 --> 00:10:35,040
and we came up to this type of basic

294
00:10:33,200 --> 00:10:37,440
tooling apparently python is

295
00:10:35,040 --> 00:10:38,880
leading in this world of machine

296
00:10:37,440 --> 00:10:42,720
learning

297
00:10:38,880 --> 00:10:46,000
and pandas is very good for data frames

298
00:10:42,720 --> 00:10:46,560
and handling data like that and psychic

299
00:10:46,000 --> 00:10:48,560
learn

300
00:10:46,560 --> 00:10:51,199
even though it's if it's researchy and

301
00:10:48,560 --> 00:10:53,680
more of educational it did the trick

302
00:10:51,200 --> 00:10:55,519
and by taking a look at the actual

303
00:10:53,680 --> 00:10:58,479
tooling around

304
00:10:55,519 --> 00:11:01,279
the machine ecosystem we came up with

305
00:10:58,480 --> 00:11:03,680
this basic set

306
00:11:01,279 --> 00:11:05,279
and we figured out that things are very

307
00:11:03,680 --> 00:11:09,359
simple

308
00:11:05,279 --> 00:11:13,040
and actually even though we're expecting

309
00:11:09,360 --> 00:11:15,279
complicated code base and some external

310
00:11:13,040 --> 00:11:16,480
resources for like telling us if things

311
00:11:15,279 --> 00:11:17,760
are fine

312
00:11:16,480 --> 00:11:21,360
we actually came up with something very

313
00:11:17,760 --> 00:11:24,480
basic all we did is had a proper basic

314
00:11:21,360 --> 00:11:27,920
data set we fit it to our model and

315
00:11:24,480 --> 00:11:29,200
it provided some good results and even

316
00:11:27,920 --> 00:11:31,439
under the hood

317
00:11:29,200 --> 00:11:33,120
um it's not that complicated so what

318
00:11:31,440 --> 00:11:34,959
we're pretty much doing

319
00:11:33,120 --> 00:11:36,480
is a very dummy approach we just

320
00:11:34,959 --> 00:11:37,599
concatenate all the data that we have

321
00:11:36,480 --> 00:11:40,800
from the free text

322
00:11:37,600 --> 00:11:41,040
we tokenize everything and we pass it to

323
00:11:40,800 --> 00:11:42,800
a

324
00:11:41,040 --> 00:11:44,319
well-known off-the-shelf classifier

325
00:11:42,800 --> 00:11:47,040
which is exit boost

326
00:11:44,320 --> 00:11:47,040
which is doing

327
00:11:48,079 --> 00:11:57,040
grad gradient boosting and

328
00:11:52,560 --> 00:11:59,760
actually provided like amazing results

329
00:11:57,040 --> 00:12:01,599
but even after that we we we're kind of

330
00:11:59,760 --> 00:12:04,880
challenging the whole idea of

331
00:12:01,600 --> 00:12:08,480
metrics and what success looks like

332
00:12:04,880 --> 00:12:10,959
and metrics came into the game

333
00:12:08,480 --> 00:12:12,399
and we we try to figure out what kind of

334
00:12:10,959 --> 00:12:14,399
metrics we need to have

335
00:12:12,399 --> 00:12:15,839
in order to make sure that we're doing

336
00:12:14,399 --> 00:12:19,040
good um

337
00:12:15,839 --> 00:12:21,200
so there are many things

338
00:12:19,040 --> 00:12:22,160
that you probably know as a machine

339
00:12:21,200 --> 00:12:25,200
learning developer

340
00:12:22,160 --> 00:12:28,399
and as a data scientist and it might be

341
00:12:25,200 --> 00:12:31,760
very confusing and very complicated but

342
00:12:28,399 --> 00:12:35,519
in the end what matters is

343
00:12:31,760 --> 00:12:38,560
having a basic understanding of

344
00:12:35,519 --> 00:12:40,480
the different metrics making sure that

345
00:12:38,560 --> 00:12:41,839
you know what the data set and what the

346
00:12:40,480 --> 00:12:44,079
results look like

347
00:12:41,839 --> 00:12:46,720
and be consistent with the things that

348
00:12:44,079 --> 00:12:46,719
you track

349
00:12:47,920 --> 00:12:50,880
so yeah understanding the problem you're

350
00:12:49,440 --> 00:12:51,200
solving and what the matrix means to

351
00:12:50,880 --> 00:12:56,320
that

352
00:12:51,200 --> 00:12:59,680
and we came up with this results

353
00:12:56,320 --> 00:13:03,600
and everyone was very happy so we got

354
00:12:59,680 --> 00:13:03,599
with basic tooling and with basic

355
00:13:04,800 --> 00:13:12,560
basic stuff we got 90 accuracy and

356
00:13:08,720 --> 00:13:13,279
it's not bad right um so our current

357
00:13:12,560 --> 00:13:16,560
stack

358
00:13:13,279 --> 00:13:18,320
uh look it's mostly python based um

359
00:13:16,560 --> 00:13:20,079
we have a project called webcompatml

360
00:13:18,320 --> 00:13:21,600
which is the python package of all the

361
00:13:20,079 --> 00:13:23,839
machine stuff that we're doing

362
00:13:21,600 --> 00:13:26,399
it's based on exit boost we release

363
00:13:23,839 --> 00:13:28,079
docker images for automation

364
00:13:26,399 --> 00:13:31,120
and we use github events in order to

365
00:13:28,079 --> 00:13:34,319
orchestrate all the flow

366
00:13:31,120 --> 00:13:37,680
and this is our

367
00:13:34,320 --> 00:13:39,839
pipeline so i think the things that

368
00:13:37,680 --> 00:13:41,359
how things look like is every time we

369
00:13:39,839 --> 00:13:42,240
have a new github issue if every time a

370
00:13:41,360 --> 00:13:44,800
user reports

371
00:13:42,240 --> 00:13:46,560
uh something we trigger the automation

372
00:13:44,800 --> 00:13:47,279
we send the payload to a simple http

373
00:13:46,560 --> 00:13:49,599
endpoint

374
00:13:47,279 --> 00:13:52,720
then from that we spin off a machine

375
00:13:49,600 --> 00:13:54,720
learning task based on docker

376
00:13:52,720 --> 00:13:56,079
this provides some results that we feed

377
00:13:54,720 --> 00:13:58,639
back to our

378
00:13:56,079 --> 00:13:59,599
data storage we have some analytics and

379
00:13:58,639 --> 00:14:01,760
then

380
00:13:59,600 --> 00:14:03,199
if we have like a basic threshold and

381
00:14:01,760 --> 00:14:04,560
basic confidence that the results that

382
00:14:03,199 --> 00:14:07,199
we have are good

383
00:14:04,560 --> 00:14:08,000
we just post back to github and either

384
00:14:07,199 --> 00:14:11,120
like close

385
00:14:08,000 --> 00:14:13,680
an issue or write a comment or just

386
00:14:11,120 --> 00:14:14,959
adding a label to see that this issue

387
00:14:13,680 --> 00:14:16,000
doesn't look really good or really

388
00:14:14,959 --> 00:14:17,680
valuable or like this

389
00:14:16,000 --> 00:14:20,639
issue is very good and we should go with

390
00:14:17,680 --> 00:14:23,680
go for it um

391
00:14:20,639 --> 00:14:26,880
and i think the most important thing

392
00:14:23,680 --> 00:14:26,880
that um

393
00:14:27,120 --> 00:14:30,800
at least my my takeaway message from all

394
00:14:29,440 --> 00:14:32,560
this at least what i'm trying to convey

395
00:14:30,800 --> 00:14:35,680
here is that

396
00:14:32,560 --> 00:14:40,319
the ecosystem is very

397
00:14:35,680 --> 00:14:41,920
very big in open source right now and

398
00:14:40,320 --> 00:14:43,440
machine learning is becoming commodity

399
00:14:41,920 --> 00:14:45,199
so

400
00:14:43,440 --> 00:14:46,959
it's not the case as in the past that

401
00:14:45,199 --> 00:14:49,040
you needed like extensive loads of like

402
00:14:46,959 --> 00:14:52,560
very very deep research stuff

403
00:14:49,040 --> 00:14:56,160
um very very highly skilled people

404
00:14:52,560 --> 00:14:57,680
uh that did this work that do this work

405
00:14:56,160 --> 00:14:58,880
pretty much like the tooling that we

406
00:14:57,680 --> 00:15:00,399
have right now and the open source

407
00:14:58,880 --> 00:15:02,800
ecosystem around machine learning

408
00:15:00,399 --> 00:15:04,639
and data science is very very

409
00:15:02,800 --> 00:15:07,920
approachable so

410
00:15:04,639 --> 00:15:09,440
what i'm trying to to say here is that

411
00:15:07,920 --> 00:15:11,439
if you have like a basic problem

412
00:15:09,440 --> 00:15:13,199
statement that you understand and

413
00:15:11,440 --> 00:15:14,720
you have data to back this problem

414
00:15:13,199 --> 00:15:16,560
statement then

415
00:15:14,720 --> 00:15:19,199
quick hacks can bring a lot of value and

416
00:15:16,560 --> 00:15:20,638
in our case a quick hack like that which

417
00:15:19,199 --> 00:15:24,240
is pretty much

418
00:15:20,639 --> 00:15:25,040
a very very basic nlp machine learning

419
00:15:24,240 --> 00:15:28,079
model

420
00:15:25,040 --> 00:15:30,880
provided 90 accuracy of all the input

421
00:15:28,079 --> 00:15:31,519
that we have which means that for i

422
00:15:30,880 --> 00:15:35,199
don't know like

423
00:15:31,519 --> 00:15:38,320
50k uh reports we can just like we can

424
00:15:35,199 --> 00:15:40,639
we can we can have signals that 10

425
00:15:38,320 --> 00:15:42,000
is okay and ninety percent we can skip

426
00:15:40,639 --> 00:15:45,199
it um

427
00:15:42,000 --> 00:15:46,800
which in the end brings up more

428
00:15:45,199 --> 00:15:49,680
opportunities about the project

429
00:15:46,800 --> 00:15:50,479
because if you can have like a like a

430
00:15:49,680 --> 00:15:54,719
way to

431
00:15:50,480 --> 00:15:58,160
get the input and um

432
00:15:54,720 --> 00:16:00,320
being able to throttle the input to your

433
00:15:58,160 --> 00:16:02,800
the pipeline that does the actual work

434
00:16:00,320 --> 00:16:04,160
it brings up a lot of opportunities like

435
00:16:02,800 --> 00:16:05,920
opening it up to more people right now

436
00:16:04,160 --> 00:16:08,639
we're only targeting um

437
00:16:05,920 --> 00:16:10,319
a specific firefox release what if we

438
00:16:08,639 --> 00:16:11,120
target all the firefox releases or what

439
00:16:10,320 --> 00:16:14,160
if we

440
00:16:11,120 --> 00:16:17,120
target like people outside firefox to

441
00:16:14,160 --> 00:16:19,199
contribute to the pipeline um so yeah

442
00:16:17,120 --> 00:16:21,600
quick hugs bring a lot of value

443
00:16:19,199 --> 00:16:22,639
we we saw this in real life in our

444
00:16:21,600 --> 00:16:25,920
project

445
00:16:22,639 --> 00:16:29,519
we have results that show that

446
00:16:25,920 --> 00:16:31,759
um what we did actually um saves time

447
00:16:29,519 --> 00:16:32,800
and effort from people doing the manual

448
00:16:31,759 --> 00:16:36,160
work

449
00:16:32,800 --> 00:16:39,439
without invading in their pipeline

450
00:16:36,160 --> 00:16:41,680
and yeah i mean it was quick

451
00:16:39,440 --> 00:16:42,959
contained easy experiment that turned

452
00:16:41,680 --> 00:16:45,439
out with good results

453
00:16:42,959 --> 00:16:46,800
so yeah my like my moment of wisdom here

454
00:16:45,440 --> 00:16:49,120
is that i'm

455
00:16:46,800 --> 00:16:51,279
highly encouraging people to try this

456
00:16:49,120 --> 00:16:53,199
type of experiments

457
00:16:51,279 --> 00:16:55,199
at least get comfort comfortable with

458
00:16:53,199 --> 00:16:56,479
the tooling and the idea of introducing

459
00:16:55,199 --> 00:16:57,920
machine learning to your project

460
00:16:56,480 --> 00:16:58,800
especially in open source world where we

461
00:16:57,920 --> 00:17:01,040
have

462
00:16:58,800 --> 00:17:03,359
open processes we have like issue

463
00:17:01,040 --> 00:17:05,599
management in the open we have

464
00:17:03,360 --> 00:17:06,880
user feedback especially in big projects

465
00:17:05,599 --> 00:17:10,719
that it cannot really

466
00:17:06,880 --> 00:17:12,720
easily be triaged by a few people

467
00:17:10,720 --> 00:17:14,559
and yeah by reducing that you can get

468
00:17:12,720 --> 00:17:17,600
like good results

469
00:17:14,559 --> 00:17:20,559
and also you like

470
00:17:17,599 --> 00:17:20,799
the the word is has a lot of buzz around

471
00:17:20,559 --> 00:17:23,760
it

472
00:17:20,799 --> 00:17:24,799
and there is like companies and projects

473
00:17:23,760 --> 00:17:27,599
that

474
00:17:24,799 --> 00:17:28,160
are very into machine learning and they

475
00:17:27,599 --> 00:17:29,840
try to

476
00:17:28,160 --> 00:17:31,280
promote like deep learning and more

477
00:17:29,840 --> 00:17:32,000
complicated stuff but in the end even

478
00:17:31,280 --> 00:17:34,480
basic tooling

479
00:17:32,000 --> 00:17:36,000
works we tried as like a state vector

480
00:17:34,480 --> 00:17:39,600
machine which is like the

481
00:17:36,000 --> 00:17:41,120
most basic notion of uh classifier for

482
00:17:39,600 --> 00:17:43,199
this type of problems and actually

483
00:17:41,120 --> 00:17:46,399
provided amazing results

484
00:17:43,200 --> 00:17:48,799
so try basic tooling um try it boost

485
00:17:46,400 --> 00:17:50,160
it's like the industry standard for this

486
00:17:48,799 --> 00:17:53,520
kind of problems

487
00:17:50,160 --> 00:17:55,039
and see the results and in the end

488
00:17:53,520 --> 00:17:56,559
this is all you need this is the most

489
00:17:55,039 --> 00:17:58,799
useful thing i've i've seen

490
00:17:56,559 --> 00:18:00,000
in this machine learning journey that we

491
00:17:58,799 --> 00:18:02,639
had

492
00:18:00,000 --> 00:18:04,240
it pretty much guides you through the

493
00:18:02,640 --> 00:18:05,280
problems that you need to solve and what

494
00:18:04,240 --> 00:18:08,720
kind of tooling you can

495
00:18:05,280 --> 00:18:11,280
use around so yeah

496
00:18:08,720 --> 00:18:12,799
i'm highly encouraging you to introduce

497
00:18:11,280 --> 00:18:15,760
machine learning to your project

498
00:18:12,799 --> 00:18:18,000
see how things work try to be a little

499
00:18:15,760 --> 00:18:21,440
bit more innovative without breaking

500
00:18:18,000 --> 00:18:24,400
your whole workflow and

501
00:18:21,440 --> 00:18:24,400
validate the results

502
00:18:24,640 --> 00:18:29,840
and that's it

503
00:18:30,790 --> 00:18:39,840
[Applause]

504
00:18:36,240 --> 00:18:39,840
thank you so much questions

505
00:18:40,799 --> 00:18:45,918
don't be shy yes

506
00:18:44,160 --> 00:18:48,960
i'm gonna run with my crystals i will

507
00:18:45,919 --> 00:18:48,960
need you to help me

508
00:18:51,280 --> 00:18:56,399
hi thanks for the talk so what's your

509
00:18:54,640 --> 00:18:59,200
expectation of issues that are

510
00:18:56,400 --> 00:19:01,360
incorrectly classified

511
00:18:59,200 --> 00:19:02,559
valid issues that are incorrectly

512
00:19:01,360 --> 00:19:04,799
classified as spam or

513
00:19:02,559 --> 00:19:06,720
like not of good quality do you expect

514
00:19:04,799 --> 00:19:09,360
them to be re-raised by people

515
00:19:06,720 --> 00:19:11,840
or how do you handle that can you repeat

516
00:19:09,360 --> 00:19:11,840
that

517
00:19:12,960 --> 00:19:17,520
yeah so if uh for issues that are

518
00:19:15,600 --> 00:19:19,199
incorrectly classified yeah

519
00:19:17,520 --> 00:19:20,559
what's your expectation around that how

520
00:19:19,200 --> 00:19:22,480
do you handle those

521
00:19:20,559 --> 00:19:24,480
uh do you expect the users to re-raise

522
00:19:22,480 --> 00:19:26,400
them or yeah so

523
00:19:24,480 --> 00:19:27,760
the people doing the manual triaging

524
00:19:26,400 --> 00:19:29,679
know about like

525
00:19:27,760 --> 00:19:31,200
the process and they are trying to flag

526
00:19:29,679 --> 00:19:33,760
things that are not correct

527
00:19:31,200 --> 00:19:35,919
so every time that we train the model it

528
00:19:33,760 --> 00:19:37,520
feeds back like it gets the

529
00:19:35,919 --> 00:19:40,240
notion of the false positive and false

530
00:19:37,520 --> 00:19:45,120
negatives back in the training model so

531
00:19:40,240 --> 00:19:45,120
we just keep this part of the workflow

532
00:19:48,480 --> 00:19:54,400
and someone was here i forgot okay yeah

533
00:19:52,799 --> 00:19:57,120
i was missing some steps today don't

534
00:19:54,400 --> 00:19:57,120
worry okay

535
00:19:58,320 --> 00:20:04,799
hello thing thank you for your talk um

536
00:20:01,520 --> 00:20:07,440
you said you used the the the feedback

537
00:20:04,799 --> 00:20:07,918
to improve your model and do you have

538
00:20:07,440 --> 00:20:10,400
any

539
00:20:07,919 --> 00:20:12,320
kind of statistics how that influenced

540
00:20:10,400 --> 00:20:15,039
the quality of the model over time

541
00:20:12,320 --> 00:20:15,840
um we don't have any statistics right

542
00:20:15,039 --> 00:20:18,080
now because

543
00:20:15,840 --> 00:20:20,799
everything is very new so we it started

544
00:20:18,080 --> 00:20:22,559
being in production in late november so

545
00:20:20,799 --> 00:20:24,400
we don't have a lot of

546
00:20:22,559 --> 00:20:27,039
statistics around or metrics around how

547
00:20:24,400 --> 00:20:29,200
it improved with time

548
00:20:27,039 --> 00:20:30,879
but yeah right now all we know is that

549
00:20:29,200 --> 00:20:33,440
people doing the manual work

550
00:20:30,880 --> 00:20:34,320
are also tasked to submit give back

551
00:20:33,440 --> 00:20:36,559
feedback about

552
00:20:34,320 --> 00:20:38,000
how this process work process works and

553
00:20:36,559 --> 00:20:41,280
how um

554
00:20:38,000 --> 00:20:43,360
if we have a false positive um just like

555
00:20:41,280 --> 00:20:44,399
let us know and we're gonna train

556
00:20:43,360 --> 00:20:48,799
everything again

557
00:20:44,400 --> 00:20:50,080
but yeah no matrix can i ask one more

558
00:20:48,799 --> 00:20:51,360
did you get feedback from the people

559
00:20:50,080 --> 00:20:52,240
that work with your system that work

560
00:20:51,360 --> 00:20:54,479
with the with this

561
00:20:52,240 --> 00:20:55,919
um with those predictions whether it has

562
00:20:54,480 --> 00:20:59,039
affected their productivity

563
00:20:55,919 --> 00:20:59,919
yeah so it was very interesting because

564
00:20:59,039 --> 00:21:02,320
like one of the things that we

565
00:20:59,919 --> 00:21:04,080
identified early on is that

566
00:21:02,320 --> 00:21:06,240
working on a silo and working on your

567
00:21:04,080 --> 00:21:06,720
own is very bad in this kind of work

568
00:21:06,240 --> 00:21:08,240
because

569
00:21:06,720 --> 00:21:10,080
we built a basic model that we're very

570
00:21:08,240 --> 00:21:11,919
happy that it provided results

571
00:21:10,080 --> 00:21:13,439
and then we we started writing it in a

572
00:21:11,919 --> 00:21:16,640
more experimental way

573
00:21:13,440 --> 00:21:17,840
in the actual workload and

574
00:21:16,640 --> 00:21:19,840
people didn't really like it because

575
00:21:17,840 --> 00:21:21,199
they didn't trust it so we asked for

576
00:21:19,840 --> 00:21:21,840
feedback from the people doing the

577
00:21:21,200 --> 00:21:23,840
manual

578
00:21:21,840 --> 00:21:26,000
uh triaging and one of the most

579
00:21:23,840 --> 00:21:28,959
important things that came up is that

580
00:21:26,000 --> 00:21:30,400
it looks okay um it gives results but we

581
00:21:28,960 --> 00:21:31,120
don't trust it like what is it what is

582
00:21:30,400 --> 00:21:33,039
it doing

583
00:21:31,120 --> 00:21:35,360
so part of it was writing documentation

584
00:21:33,039 --> 00:21:38,640
writing uh some examples of how

585
00:21:35,360 --> 00:21:39,760
it works um understanding the metrics

586
00:21:38,640 --> 00:21:41,520
like giving some sort of

587
00:21:39,760 --> 00:21:42,840
tldr about the metrics in machine

588
00:21:41,520 --> 00:21:46,000
learning and also

589
00:21:42,840 --> 00:21:47,678
um what kind of classifiers we use and

590
00:21:46,000 --> 00:21:49,840
what is confidence threshold

591
00:21:47,679 --> 00:21:50,880
and after that people were more familiar

592
00:21:49,840 --> 00:21:52,799
with it and they

593
00:21:50,880 --> 00:21:54,080
they were very happy like try hazards

594
00:21:52,799 --> 00:21:54,639
say that they are happy that there is

595
00:21:54,080 --> 00:21:56,639
something

596
00:21:54,640 --> 00:21:59,039
cleaning up the pipeline for more

597
00:21:56,640 --> 00:22:01,120
important stuff um

598
00:21:59,039 --> 00:22:03,600
so yeah also something that relates to

599
00:22:01,120 --> 00:22:05,760
the previous question is that

600
00:22:03,600 --> 00:22:07,520
we find very important the confidence

601
00:22:05,760 --> 00:22:10,640
thresholds uh in this project

602
00:22:07,520 --> 00:22:10,960
so given the given the accuracy that we

603
00:22:10,640 --> 00:22:14,480
have

604
00:22:10,960 --> 00:22:14,480
and given the metrics that are high

605
00:22:14,880 --> 00:22:18,400
related to the class that we care which

606
00:22:17,760 --> 00:22:20,559
is the

607
00:22:18,400 --> 00:22:23,280
bugs that don't need no don't need

608
00:22:20,559 --> 00:22:23,280
diagnosis

609
00:22:24,000 --> 00:22:28,480
we have so so big accuracy that the

610
00:22:26,240 --> 00:22:30,400
confidence threshold can be very high

611
00:22:28,480 --> 00:22:31,760
and if you tell people that you know

612
00:22:30,400 --> 00:22:33,760
what there's like 60

613
00:22:31,760 --> 00:22:34,879
chance that the results are bad they

614
00:22:33,760 --> 00:22:37,120
don't like it

615
00:22:34,880 --> 00:22:39,520
but if you say that the model says that

616
00:22:37,120 --> 00:22:42,158
it's like 19.99

617
00:22:39,520 --> 00:22:44,158
correct then people trust it so we

618
00:22:42,159 --> 00:22:47,360
identify like we introduced the idea of

619
00:22:44,159 --> 00:22:48,880
classifications and labels and high low

620
00:22:47,360 --> 00:22:54,158
and very high

621
00:22:48,880 --> 00:22:57,840
confidence yes

622
00:22:54,159 --> 00:22:57,840
i'm gonna need some help to pass the mic

623
00:22:58,880 --> 00:23:03,600
yes nice presentation uh regarding to

624
00:23:01,600 --> 00:23:05,520
the data points that you've showed

625
00:23:03,600 --> 00:23:07,520
i noticed the title of the usual was

626
00:23:05,520 --> 00:23:09,200
there as well the title of the

627
00:23:07,520 --> 00:23:11,679
issue so it was something written in

628
00:23:09,200 --> 00:23:12,240
natural language uh how did you handle

629
00:23:11,679 --> 00:23:15,039
that

630
00:23:12,240 --> 00:23:16,480
uh like using nlp methods or something

631
00:23:15,039 --> 00:23:18,720
and the next one for

632
00:23:16,480 --> 00:23:19,520
uh internet uh like uh different

633
00:23:18,720 --> 00:23:21,919
languages

634
00:23:19,520 --> 00:23:23,520
how did you handle it or you just uh

635
00:23:21,919 --> 00:23:26,480
limited it to english

636
00:23:23,520 --> 00:23:26,879
what's this so the title of reports that

637
00:23:26,480 --> 00:23:30,240
it is

638
00:23:26,880 --> 00:23:31,919
uh like any other languages did you

639
00:23:30,240 --> 00:23:34,320
filter that out or you just

640
00:23:31,919 --> 00:23:35,919
so first of all we don't have any like

641
00:23:34,320 --> 00:23:36,879
most of the content we have is in

642
00:23:35,919 --> 00:23:39,280
english so

643
00:23:36,880 --> 00:23:41,200
this wasn't an issue so far uh about

644
00:23:39,280 --> 00:23:44,320
cleaning up the content we we used

645
00:23:41,200 --> 00:23:46,720
um nlp methods to talk like

646
00:23:44,320 --> 00:23:48,320
we used idf and count vectorizers and

647
00:23:46,720 --> 00:23:48,960
they gave good results um one of the

648
00:23:48,320 --> 00:23:51,200
things that

649
00:23:48,960 --> 00:23:53,279
we might try in the future is

650
00:23:51,200 --> 00:23:56,159
introducing like some sort of

651
00:23:53,279 --> 00:23:58,000
more highly performant uh nlp libraries

652
00:23:56,159 --> 00:24:01,440
like spacey

653
00:23:58,000 --> 00:24:05,039
but even with the stuff from scikit and

654
00:24:01,440 --> 00:24:05,919
even with a basic um text extraction

655
00:24:05,039 --> 00:24:08,640
methods

656
00:24:05,919 --> 00:24:11,919
the results are very good so my approach

657
00:24:08,640 --> 00:24:11,919
is to not complicate things

658
00:24:12,000 --> 00:24:17,200
tfid i want to address the

659
00:24:15,600 --> 00:24:19,039
second power languages the tool he

660
00:24:17,200 --> 00:24:21,360
presented webcompat.org

661
00:24:19,039 --> 00:24:22,720
provides you suggestions when you enter

662
00:24:21,360 --> 00:24:24,639
a bug even if it's a

663
00:24:22,720 --> 00:24:25,760
different language website you will

664
00:24:24,640 --> 00:24:27,679
suggest you like

665
00:24:25,760 --> 00:24:29,200
site is broken mobile version doesn't

666
00:24:27,679 --> 00:24:31,840
work there are glitches

667
00:24:29,200 --> 00:24:33,200
so it's easy to just know that even if

668
00:24:31,840 --> 00:24:34,080
you add some description in other

669
00:24:33,200 --> 00:24:36,400
language

670
00:24:34,080 --> 00:24:38,000
you will identify with the suggested

671
00:24:36,400 --> 00:24:38,480
thing that you chose when reported the

672
00:24:38,000 --> 00:24:41,360
issue

673
00:24:38,480 --> 00:24:42,080
yeah also also part of the like general

674
00:24:41,360 --> 00:24:44,000
improvement

675
00:24:42,080 --> 00:24:45,840
in this project one of the things that

676
00:24:44,000 --> 00:24:47,679
my team also did which is not in that

677
00:24:45,840 --> 00:24:49,918
scope is we try to improve the reporting

678
00:24:47,679 --> 00:24:51,919
process so right now we have a free form

679
00:24:49,919 --> 00:24:53,200
that is written in markdown and it has

680
00:24:51,919 --> 00:24:54,640
some data

681
00:24:53,200 --> 00:24:57,200
and what we're trying to move forward is

682
00:24:54,640 --> 00:24:59,919
having structure on like

683
00:24:57,200 --> 00:25:01,760
the fields so for example what's the

684
00:24:59,919 --> 00:25:03,360
browser or

685
00:25:01,760 --> 00:25:04,960
what's the description and what are the

686
00:25:03,360 --> 00:25:07,760
steps because right now it's

687
00:25:04,960 --> 00:25:07,760
completely free text

688
00:25:08,559 --> 00:25:11,520
any other questions

689
00:25:11,760 --> 00:25:15,840
thank you so much

