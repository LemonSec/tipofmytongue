1
00:00:05,040 --> 00:00:08,960
uh looks pretty cool

2
00:00:06,480 --> 00:00:10,400
um we have a lot of talks today uh very

3
00:00:08,960 --> 00:00:12,160
short talks actually because we wanted

4
00:00:10,400 --> 00:00:14,080
to fit in as much as possible

5
00:00:12,160 --> 00:00:15,440
from all the applications hopefully next

6
00:00:14,080 --> 00:00:16,400
year we get the full day again which

7
00:00:15,440 --> 00:00:18,640
would be great

8
00:00:16,400 --> 00:00:20,479
um so we've got different topics like

9
00:00:18,640 --> 00:00:23,600
graph streaming craft analytics

10
00:00:20,480 --> 00:00:24,400
craft bearing so all things craft which

11
00:00:23,600 --> 00:00:26,960
is cool

12
00:00:24,400 --> 00:00:28,080
and yeah with that i want to introduce

13
00:00:26,960 --> 00:00:30,080
our first speaker

14
00:00:28,080 --> 00:00:33,920
vincent from intel who will talk about

15
00:00:30,080 --> 00:00:33,920
scalable cross-platform graphics

16
00:00:39,840 --> 00:00:46,239
so hi everybody so my name is

17
00:00:44,160 --> 00:00:49,199
which is not an acronym for scalable

18
00:00:46,239 --> 00:00:50,320
cross-platform graphics

19
00:00:49,200 --> 00:00:53,280
and this is work we are doing

20
00:00:50,320 --> 00:00:55,600
constructing with anaconda

21
00:00:53,280 --> 00:00:57,600
so quick outline what is hive what is

22
00:00:55,600 --> 00:01:00,879
the architecture the interfaces how do

23
00:00:57,600 --> 00:01:02,879
you extend it and a quick summary of it

24
00:01:00,879 --> 00:01:04,319
so at this core what we're trying to do

25
00:01:02,879 --> 00:01:06,158
with hive is

26
00:01:04,319 --> 00:01:08,479
to build the graph analytics api in

27
00:01:06,159 --> 00:01:10,159
python for graph users

28
00:01:08,479 --> 00:01:13,840
and because you're operating in python

29
00:01:10,159 --> 00:01:13,840
you probably want to do

30
00:01:13,920 --> 00:01:16,960
integrate into that whole data science

31
00:01:15,840 --> 00:01:19,920
ecosystem right

32
00:01:16,960 --> 00:01:20,640
and um the kind of interoperability you

33
00:01:19,920 --> 00:01:22,159
want to provide

34
00:01:20,640 --> 00:01:24,960
is that it's easy for instance if you

35
00:01:22,159 --> 00:01:27,759
have containers like an empire

36
00:01:24,960 --> 00:01:29,119
arrays of data frames you can use them

37
00:01:27,759 --> 00:01:32,000
convert them into graphs

38
00:01:29,119 --> 00:01:33,600
right so this sort of already exists if

39
00:01:32,000 --> 00:01:35,119
you think of network x

40
00:01:33,600 --> 00:01:37,280
the issue with it is that it's pretty

41
00:01:35,119 --> 00:01:38,560
slow so

42
00:01:37,280 --> 00:01:40,560
one of the things we want to do is

43
00:01:38,560 --> 00:01:41,680
really leverage all the the fantastic

44
00:01:40,560 --> 00:01:43,280
high performance

45
00:01:41,680 --> 00:01:44,880
graph libraries are out there right so

46
00:01:43,280 --> 00:01:46,159
the it's

47
00:01:44,880 --> 00:01:47,360
some people it's the bread and butter

48
00:01:46,159 --> 00:01:49,520
right they do that research they mean

49
00:01:47,360 --> 00:01:52,640
they need to make it proper

50
00:01:49,520 --> 00:01:54,560
uh once you have these uh apis and then

51
00:01:52,640 --> 00:01:56,479
a set of graph frameworks uh

52
00:01:54,560 --> 00:01:57,920
you need some kind of a glue right

53
00:01:56,479 --> 00:01:59,520
something that can orchestrate how do

54
00:01:57,920 --> 00:02:01,759
you go from this

55
00:01:59,520 --> 00:02:03,200
python api down to actually calling into

56
00:02:01,759 --> 00:02:05,040
some implementations right

57
00:02:03,200 --> 00:02:08,239
and for this we're going to use that

58
00:02:05,040 --> 00:02:09,920
which is developed by iphone uh

59
00:02:08,239 --> 00:02:11,920
we want this to be a community-driven

60
00:02:09,919 --> 00:02:13,280
effort right so there's a number of data

61
00:02:11,920 --> 00:02:14,799
science packages there's a number of

62
00:02:13,280 --> 00:02:17,120
high performance

63
00:02:14,800 --> 00:02:18,080
graph libraries and uh we can't just

64
00:02:17,120 --> 00:02:19,520
tackle uh

65
00:02:18,080 --> 00:02:22,720
everything by ourselves right so we

66
00:02:19,520 --> 00:02:24,080
wanna give out the uh the frameworks

67
00:02:22,720 --> 00:02:26,239
the interfaces and have people

68
00:02:24,080 --> 00:02:28,000
contribute to it

69
00:02:26,239 --> 00:02:29,920
and finally we want this to be hardware

70
00:02:28,000 --> 00:02:32,640
agnostic so we want to be able to plug

71
00:02:29,920 --> 00:02:33,679
as many hardware handles hardware in

72
00:02:32,640 --> 00:02:35,839
there

73
00:02:33,680 --> 00:02:37,599
but do nothing in that architecture that

74
00:02:35,840 --> 00:02:40,400
would make it at your location

75
00:02:37,599 --> 00:02:41,200
into some ecosystem uh finally this is

76
00:02:40,400 --> 00:02:43,200
uh

77
00:02:41,200 --> 00:02:44,480
in development right now um think of

78
00:02:43,200 --> 00:02:45,280
this as a kind of achievement of things

79
00:02:44,480 --> 00:02:48,840
to come

80
00:02:45,280 --> 00:02:51,840
and it's gonna be open source in 2020

81
00:02:48,840 --> 00:02:51,840
sometimes

82
00:02:54,560 --> 00:02:57,840
uh so let's start at the the basics

83
00:02:57,200 --> 00:03:00,560
right so

84
00:02:57,840 --> 00:03:01,920
if you if you want to express a graph

85
00:03:00,560 --> 00:03:05,120
algorithm right you're going to have

86
00:03:01,920 --> 00:03:06,399
to need data for graph representation

87
00:03:05,120 --> 00:03:08,159
and you're going to express your graph

88
00:03:06,400 --> 00:03:09,840
algorithm using a particle right so

89
00:03:08,159 --> 00:03:10,319
think of this for instance uh you can

90
00:03:09,840 --> 00:03:12,640
express

91
00:03:10,319 --> 00:03:14,560
a graph algorithm within an algebra you

92
00:03:12,640 --> 00:03:16,480
can use your tech centric

93
00:03:14,560 --> 00:03:19,519
focus synchronous kind of model when you

94
00:03:16,480 --> 00:03:20,720
update from your neighbors eccentric

95
00:03:19,519 --> 00:03:22,080
all right so someone is going to provide

96
00:03:20,720 --> 00:03:23,519
you with an api and you throw that

97
00:03:22,080 --> 00:03:25,360
paradigm and then you can implement your

98
00:03:23,519 --> 00:03:27,360
platform

99
00:03:25,360 --> 00:03:29,040
and finally you get your data in the

100
00:03:27,360 --> 00:03:32,000
compute right now you need a hardware

101
00:03:29,040 --> 00:03:33,200
architecture that you can render all

102
00:03:32,000 --> 00:03:36,480
these all of these things are

103
00:03:33,200 --> 00:03:38,480
interrelated so

104
00:03:36,480 --> 00:03:39,518
this is an example just a list of life

105
00:03:38,480 --> 00:03:41,119
frameworks right

106
00:03:39,519 --> 00:03:42,879
there i know associated with this effort

107
00:03:41,120 --> 00:03:44,159
i just picked them because

108
00:03:42,879 --> 00:03:46,399
people doing great work just to

109
00:03:44,159 --> 00:03:47,679
illustrate my point so if i take for

110
00:03:46,400 --> 00:03:50,879
instance choose fast right

111
00:03:47,680 --> 00:03:52,720
uh i'm gonna have uh basically using a

112
00:03:50,879 --> 00:03:54,959
subset of this graph representation

113
00:03:52,720 --> 00:03:56,799
and a certain way of expressing things

114
00:03:54,959 --> 00:03:58,480
to write my graph algorithm

115
00:03:56,799 --> 00:04:00,959
and then targeting a cell an

116
00:03:58,480 --> 00:04:02,560
architecture right and

117
00:04:00,959 --> 00:04:04,319
this is basically just because you know

118
00:04:02,560 --> 00:04:06,239
people are focusing on something

119
00:04:04,319 --> 00:04:08,399
and um it's not a critique i guess

120
00:04:06,239 --> 00:04:10,640
that's what i mean but uh if i switch to

121
00:04:08,400 --> 00:04:11,680
galwa then i have a different set of

122
00:04:10,640 --> 00:04:14,319
things i'm going to use

123
00:04:11,680 --> 00:04:15,040
and graph it and so on right so so the

124
00:04:14,319 --> 00:04:17,039
question is

125
00:04:15,040 --> 00:04:18,639
if i'm a data scientist and i'm sitting

126
00:04:17,040 --> 00:04:19,440
in the python ecosystem and i'm going to

127
00:04:18,639 --> 00:04:22,400
leverage this

128
00:04:19,440 --> 00:04:24,160
how do i do that right so if you have a

129
00:04:22,400 --> 00:04:24,799
python interface to one of them you can

130
00:04:24,160 --> 00:04:27,840
use it

131
00:04:24,800 --> 00:04:29,680
but then you kind of buying into a small

132
00:04:27,840 --> 00:04:31,440
ecosystem right you have to

133
00:04:29,680 --> 00:04:32,880
maybe format your data so that the graph

134
00:04:31,440 --> 00:04:34,639
algorithm can

135
00:04:32,880 --> 00:04:36,000
use them and if you're building a

136
00:04:34,639 --> 00:04:37,440
workflow maybe there's something in one

137
00:04:36,000 --> 00:04:38,639
of this framework that's not available

138
00:04:37,440 --> 00:04:39,120
in the order i know you have to deal

139
00:04:38,639 --> 00:04:42,479
with

140
00:04:39,120 --> 00:04:44,240
how do i go from one to the other so

141
00:04:42,479 --> 00:04:46,400
this is where we think the hive api

142
00:04:44,240 --> 00:04:49,280
would uh would contribute

143
00:04:46,400 --> 00:04:50,880
so the goal is to have a high level set

144
00:04:49,280 --> 00:04:52,638
of graph apis so think of this

145
00:04:50,880 --> 00:04:55,040
like you want to do communication

146
00:04:52,639 --> 00:04:57,040
clustering so you can use google

147
00:04:55,040 --> 00:04:58,240
you want to do some rough pattern

148
00:04:57,040 --> 00:05:01,600
matching so you have

149
00:04:58,240 --> 00:05:03,039
some isomorphism so very high level so

150
00:05:01,600 --> 00:05:05,600
that if your data centers you can just

151
00:05:03,039 --> 00:05:07,039
take it off the shelf

152
00:05:05,600 --> 00:05:08,880
one thing we want to explore is doing

153
00:05:07,039 --> 00:05:11,520
this kind of a graph

154
00:05:08,880 --> 00:05:12,320
apis so if you're not familiar with

155
00:05:11,520 --> 00:05:13,758
number

156
00:05:12,320 --> 00:05:15,759
it basically allows you to write a

157
00:05:13,759 --> 00:05:16,080
function in python and you can annotate

158
00:05:15,759 --> 00:05:18,400
it

159
00:05:16,080 --> 00:05:20,000
and then you can check it so one of the

160
00:05:18,400 --> 00:05:21,520
simple things we wanted to try to do for

161
00:05:20,000 --> 00:05:22,639
instance

162
00:05:21,520 --> 00:05:25,680
if you want to do some kind of a

163
00:05:22,639 --> 00:05:28,080
filtering operation uh you stay in the

164
00:05:25,680 --> 00:05:30,240
python side to write this kind of print

165
00:05:28,080 --> 00:05:33,919
tape and then you have the runtime

166
00:05:30,240 --> 00:05:35,199
go over the edges or the vertices

167
00:05:33,919 --> 00:05:37,198
you apply that function and you get a

168
00:05:35,199 --> 00:05:39,440
subset out

169
00:05:37,199 --> 00:05:40,479
and finally we want to make the

170
00:05:39,440 --> 00:05:42,479
interruptability

171
00:05:40,479 --> 00:05:43,520
uh easy with the data science in the

172
00:05:42,479 --> 00:05:46,000
system

173
00:05:43,520 --> 00:05:47,280
so uh think of this as how do i convert

174
00:05:46,000 --> 00:05:48,880
across containers what are the most

175
00:05:47,280 --> 00:05:50,559
popular things

176
00:05:48,880 --> 00:05:53,759
we can sort of support by default so

177
00:05:50,560 --> 00:05:56,720
that other people don't have to

178
00:05:53,759 --> 00:05:57,280
so once you have these apis you need a

179
00:05:56,720 --> 00:05:59,520
glue

180
00:05:57,280 --> 00:06:00,799
right in between the apis and the

181
00:05:59,520 --> 00:06:02,719
frameworks

182
00:06:00,800 --> 00:06:04,400
so we're going to use the dash runtime

183
00:06:02,720 --> 00:06:06,960
so think of this as

184
00:06:04,400 --> 00:06:08,560
you do lazy evaluation on the apis and

185
00:06:06,960 --> 00:06:10,080
you dynamically build this fast graph

186
00:06:08,560 --> 00:06:13,280
with the things you want to do

187
00:06:10,080 --> 00:06:14,719
right and and now you

188
00:06:13,280 --> 00:06:16,318
you have the user express what he wants

189
00:06:14,720 --> 00:06:18,840
to do and you also have

190
00:06:16,319 --> 00:06:20,000
a bunch of algorithm implementation that

191
00:06:18,840 --> 00:06:22,318
emphasizes

192
00:06:20,000 --> 00:06:24,319
so you need a broker uh totally off

193
00:06:22,319 --> 00:06:25,680
registration right so this is both

194
00:06:24,319 --> 00:06:28,160
i want to schedule the computer on

195
00:06:25,680 --> 00:06:29,680
resources and also i want

196
00:06:28,160 --> 00:06:32,800
this runtime to handle all data

197
00:06:29,680 --> 00:06:34,800
movements and finally we want this to be

198
00:06:32,800 --> 00:06:36,000
accessible yeah plugins so that you can

199
00:06:34,800 --> 00:06:39,600
just

200
00:06:36,000 --> 00:06:39,600
jump in and add your own things

201
00:06:40,080 --> 00:06:43,120
so let's have a look at the framework

202
00:06:41,759 --> 00:06:45,440
interfaces

203
00:06:43,120 --> 00:06:47,120
so the centerpiece is this high task

204
00:06:45,440 --> 00:06:50,000
runtime right so it's going to deal be

205
00:06:47,120 --> 00:06:50,639
observation then you have the user api

206
00:06:50,000 --> 00:06:53,520
so again

207
00:06:50,639 --> 00:06:55,360
a high-level thing like on the graph and

208
00:06:53,520 --> 00:06:58,639
the graph is kind of this opaque

209
00:06:55,360 --> 00:07:01,199
type uh the data type right

210
00:06:58,639 --> 00:07:03,039
it's just a graph then you can define

211
00:07:01,199 --> 00:07:05,280
your data models right so for this

212
00:07:03,039 --> 00:07:06,400
abstract type that's a graph i want a

213
00:07:05,280 --> 00:07:08,479
concrete type

214
00:07:06,400 --> 00:07:09,520
which is maybe i have a data frame that

215
00:07:08,479 --> 00:07:11,919
represents

216
00:07:09,520 --> 00:07:12,639
an adjacency matrix and it's storing the

217
00:07:11,919 --> 00:07:16,080
cpu

218
00:07:12,639 --> 00:07:17,039
memory subsystem and i also have a csr

219
00:07:16,080 --> 00:07:20,159
data dive right

220
00:07:17,039 --> 00:07:21,599
anything i can imagine so then you're

221
00:07:20,160 --> 00:07:23,199
going to define transformers right so

222
00:07:21,599 --> 00:07:25,039
how do i go from that data frame on the

223
00:07:23,199 --> 00:07:27,840
cpu to a csr on the cpu

224
00:07:25,039 --> 00:07:28,560
and so on so some of these they can be

225
00:07:27,840 --> 00:07:31,520
part of the

226
00:07:28,560 --> 00:07:34,160
common library and some of them the

227
00:07:31,520 --> 00:07:35,919
framework implementer can go in

228
00:07:34,160 --> 00:07:37,440
and finally you have the graphic the

229
00:07:35,919 --> 00:07:39,599
brass algorithm backend so

230
00:07:37,440 --> 00:07:40,800
think of here i'm saying i'm exposing

231
00:07:39,599 --> 00:07:43,199
luga it's

232
00:07:40,800 --> 00:07:44,479
running on this xbox it's last framework

233
00:07:43,199 --> 00:07:48,400
that just made it

234
00:07:44,479 --> 00:07:50,719
running on cpu and taking a csr

235
00:07:48,400 --> 00:07:52,000
all right so when you think of building

236
00:07:50,720 --> 00:07:55,599
all of these right

237
00:07:52,000 --> 00:07:58,560
you actually just built a graph of

238
00:07:55,599 --> 00:07:58,878
dependencies right so this user api they

239
00:07:58,560 --> 00:08:00,639
have

240
00:07:58,879 --> 00:08:02,080
implementations graph algorithms they

241
00:08:00,639 --> 00:08:03,680
use some data models

242
00:08:02,080 --> 00:08:06,400
these edges between the models they are

243
00:08:03,680 --> 00:08:06,400
the transformers

244
00:08:07,520 --> 00:08:11,039
so das can now take this graph and

245
00:08:09,599 --> 00:08:14,560
reason about

246
00:08:11,039 --> 00:08:17,520
what the user is first and what he can

247
00:08:14,560 --> 00:08:17,840
so it's really doing graph analytics

248
00:08:17,520 --> 00:08:21,120
with

249
00:08:17,840 --> 00:08:22,719
the help of graph so on the left hand

250
00:08:21,120 --> 00:08:26,240
side you can see a workflow

251
00:08:22,720 --> 00:08:28,879
of the task graph so here i start

252
00:08:26,240 --> 00:08:30,560
outside of the hive ecosystem including

253
00:08:28,879 --> 00:08:31,680
data pre-processing whatever is your

254
00:08:30,560 --> 00:08:33,760
workflow

255
00:08:31,680 --> 00:08:35,039
and then once you cross in right you can

256
00:08:33,760 --> 00:08:38,000
say i want to create a graph

257
00:08:35,039 --> 00:08:38,479
i want to type an operation and so on so

258
00:08:38,000 --> 00:08:40,399
if you

259
00:08:38,479 --> 00:08:41,599
think about that graph we have default

260
00:08:40,399 --> 00:08:44,000
dependencies right

261
00:08:41,599 --> 00:08:44,959
here i might have a data frame coming in

262
00:08:44,000 --> 00:08:47,279
here

263
00:08:44,959 --> 00:08:48,319
so the system knows okay i have a data

264
00:08:47,279 --> 00:08:50,959
frame

265
00:08:48,320 --> 00:08:51,839
a data model and what do i need to

266
00:08:50,959 --> 00:08:53,760
convert it into

267
00:08:51,839 --> 00:08:54,959
well it depends what what is the set of

268
00:08:53,760 --> 00:08:57,360
graph operation

269
00:08:54,959 --> 00:08:58,640
implementations i have right so solving

270
00:08:57,360 --> 00:09:01,760
this and you come up with

271
00:08:58,640 --> 00:09:02,160
basically a schedule and finally when

272
00:09:01,760 --> 00:09:03,839
you

273
00:09:02,160 --> 00:09:05,600
uh you know some point you just exit

274
00:09:03,839 --> 00:09:08,959
that and go back to your regular

275
00:09:05,600 --> 00:09:10,560
water another cool thing here is the

276
00:09:08,959 --> 00:09:13,599
data transformation so

277
00:09:10,560 --> 00:09:15,279
just by transitivity

278
00:09:13,600 --> 00:09:17,120
uh you might actually support some stuff

279
00:09:15,279 --> 00:09:19,200
that you haven't provisioned for so here

280
00:09:17,120 --> 00:09:21,440
for instance i start in a file format

281
00:09:19,200 --> 00:09:23,839
i know how to make it a table i know how

282
00:09:21,440 --> 00:09:27,120
to make it a second draft format

283
00:09:23,839 --> 00:09:29,440
into the last one so would

284
00:09:27,120 --> 00:09:30,720
probably run horribly but what i found

285
00:09:29,440 --> 00:09:31,600
pretty cool about this is that now you

286
00:09:30,720 --> 00:09:33,600
can think about

287
00:09:31,600 --> 00:09:35,440
building some government monitoring

288
00:09:33,600 --> 00:09:37,920
infrastructure right so

289
00:09:35,440 --> 00:09:40,000
in that you could have look at this

290
00:09:37,920 --> 00:09:41,599
graph and kind of figure out oh

291
00:09:40,000 --> 00:09:43,360
you know you keep doing this path that

292
00:09:41,600 --> 00:09:45,120
is very long and expensive

293
00:09:43,360 --> 00:09:46,560
so the system could tell you hey if you

294
00:09:45,120 --> 00:09:48,080
actually implement the conversion

295
00:09:46,560 --> 00:09:49,119
directly from that file format that

296
00:09:48,080 --> 00:09:51,600
graph format

297
00:09:49,120 --> 00:09:52,959
then you're saving time same thing on

298
00:09:51,600 --> 00:09:56,000
the on the task graph

299
00:09:52,959 --> 00:09:58,719
people think of um

300
00:09:56,000 --> 00:10:00,320
you know for different graph inputs you

301
00:09:58,720 --> 00:10:01,680
could try and characterize them

302
00:10:00,320 --> 00:10:03,279
and then you could see when you run on

303
00:10:01,680 --> 00:10:04,880
cpu when you run on gpu with these

304
00:10:03,279 --> 00:10:05,680
different inputs this is the results you

305
00:10:04,880 --> 00:10:07,519
have right so you

306
00:10:05,680 --> 00:10:09,199
you can plug all of this into some

307
00:10:07,519 --> 00:10:11,839
machine learning framework and basically

308
00:10:09,200 --> 00:10:11,839
learn from that

309
00:10:13,760 --> 00:10:18,160
so in terms of extensibility this is how

310
00:10:16,160 --> 00:10:20,319
you would support new offer

311
00:10:18,160 --> 00:10:21,920
so let you see there's no functional

312
00:10:20,320 --> 00:10:24,399
changes to the user api

313
00:10:21,920 --> 00:10:25,360
right so you basically the other thing

314
00:10:24,399 --> 00:10:27,920
you might do is just

315
00:10:25,360 --> 00:10:29,839
maybe add annotations to say i really

316
00:10:27,920 --> 00:10:31,040
want to use that new backend

317
00:10:29,839 --> 00:10:32,800
that you've provided but you don't

318
00:10:31,040 --> 00:10:35,120
change your products or transparent for

319
00:10:32,800 --> 00:10:35,120
the user

320
00:10:35,200 --> 00:10:38,800
and then you only need to implement

321
00:10:36,399 --> 00:10:40,800
these plugins right so i need to go and

322
00:10:38,800 --> 00:10:41,120
describe the data model for the cs on

323
00:10:40,800 --> 00:10:44,079
that

324
00:10:41,120 --> 00:10:45,200
xpu i made up one of the transformers

325
00:10:44,079 --> 00:10:48,880
again

326
00:10:45,200 --> 00:10:50,240
and finally my implementation so so here

327
00:10:48,880 --> 00:10:52,079
this is an example where i use a

328
00:10:50,240 --> 00:10:54,480
framework and i just extend it but

329
00:10:52,079 --> 00:10:56,160
um what i find what i find pretty

330
00:10:54,480 --> 00:10:57,839
interesting is that you could just take

331
00:10:56,160 --> 00:10:59,519
any code of the shelf from internet

332
00:10:57,839 --> 00:11:02,480
that's using keyframe or whatever

333
00:10:59,519 --> 00:11:03,920
you wrap it in the python interface and

334
00:11:02,480 --> 00:11:05,040
then you have it advertised in the

335
00:11:03,920 --> 00:11:07,360
framework

336
00:11:05,040 --> 00:11:08,079
and it's a great way to basically

337
00:11:07,360 --> 00:11:10,800
generate what's

338
00:11:08,079 --> 00:11:12,399
out there and once you've done that then

339
00:11:10,800 --> 00:11:15,519
it's part of the hard runtime toolbox

340
00:11:12,399 --> 00:11:16,160
it makes this a graphic scene larger and

341
00:11:15,519 --> 00:11:19,360
then

342
00:11:16,160 --> 00:11:20,560
you can use it so one thing that's

343
00:11:19,360 --> 00:11:22,640
pretty cool also that

344
00:11:20,560 --> 00:11:24,640
that allows you to mix power

345
00:11:22,640 --> 00:11:26,800
architecture right so you can

346
00:11:24,640 --> 00:11:28,399
start your if you're a different graph

347
00:11:26,800 --> 00:11:30,319
operation maybe you did one of the cpu

348
00:11:28,399 --> 00:11:31,760
the next one on the gpu

349
00:11:30,320 --> 00:11:33,839
uh it's also a great way to get

350
00:11:31,760 --> 00:11:35,760
portability right so if today i'm

351
00:11:33,839 --> 00:11:37,120
running on the box and it has a gpu and

352
00:11:35,760 --> 00:11:38,319
i'm using the deep algorithm but

353
00:11:37,120 --> 00:11:39,920
tomorrow i'm not

354
00:11:38,320 --> 00:11:42,480
as long as i have an implementation that

355
00:11:39,920 --> 00:11:45,519
covers the cpu

356
00:11:42,480 --> 00:11:45,519
my code would still run

357
00:11:47,600 --> 00:11:52,320
so in terms of the extensibility for the

358
00:11:50,480 --> 00:11:53,839
if you want a new user api

359
00:11:52,320 --> 00:11:56,720
then it's same thing you just have a

360
00:11:53,839 --> 00:12:00,240
subset of plugins you need to work with

361
00:11:56,720 --> 00:12:02,320
so the user api so here i'm expanding it

362
00:12:00,240 --> 00:12:03,920
as a letter i want triangle counting on

363
00:12:02,320 --> 00:12:05,040
the graph and then i just have to

364
00:12:03,920 --> 00:12:07,439
provide

365
00:12:05,040 --> 00:12:08,880
uh you know at least one implementation

366
00:12:07,440 --> 00:12:11,360
right so here i'm still using my

367
00:12:08,880 --> 00:12:13,360
last example and then again it's just

368
00:12:11,360 --> 00:12:16,480
going to be part of the

369
00:12:13,360 --> 00:12:18,800
of the api of the runtime toolbox

370
00:12:16,480 --> 00:12:19,680
right so we're on this page so that

371
00:12:18,800 --> 00:12:21,279
people can just

372
00:12:19,680 --> 00:12:23,120
you know plug in your algorithm and

373
00:12:21,279 --> 00:12:26,160
liberate all the work that's been done

374
00:12:23,120 --> 00:12:26,160
on the back end

375
00:12:26,560 --> 00:12:32,560
so as a follow the summary of the

376
00:12:30,959 --> 00:12:34,319
stakeholders view if you're a data

377
00:12:32,560 --> 00:12:37,359
scientist what you gain is that you have

378
00:12:34,320 --> 00:12:39,040
now unified apis for graph analytics

379
00:12:37,360 --> 00:12:40,560
you have the python interoperability

380
00:12:39,040 --> 00:12:41,040
that allows you basically to cut your

381
00:12:40,560 --> 00:12:44,319
work

382
00:12:41,040 --> 00:12:46,480
into a larger workflow and basically you

383
00:12:44,320 --> 00:12:47,680
just have this state-of-the-art backend

384
00:12:46,480 --> 00:12:49,760
always available right they are

385
00:12:47,680 --> 00:12:51,439
maintained or optimized

386
00:12:49,760 --> 00:12:52,959
you get a transparent orchestration so

387
00:12:51,440 --> 00:12:54,720
that you don't have to worry about

388
00:12:52,959 --> 00:12:56,880
what is the actual underlying hardware

389
00:12:54,720 --> 00:13:00,480
you have and you get the increased

390
00:12:56,880 --> 00:13:03,360
workflow portability if you're a graph

391
00:13:00,480 --> 00:13:03,360
framework developer

392
00:13:03,600 --> 00:13:07,680
you we hope this would help for the

393
00:13:05,760 --> 00:13:09,120
structural way of this is how i present

394
00:13:07,680 --> 00:13:11,920
a graph algorithm

395
00:13:09,120 --> 00:13:14,320
in the python form item form so

396
00:13:11,920 --> 00:13:16,959
hopefully this would sort of bring

397
00:13:14,320 --> 00:13:18,880
the community together uh it's an

398
00:13:16,959 --> 00:13:21,279
increased user base right so now

399
00:13:18,880 --> 00:13:22,079
because it's much easier to plug in your

400
00:13:21,279 --> 00:13:25,279
frame off

401
00:13:22,079 --> 00:13:26,959
into a larger hive ecosystem

402
00:13:25,279 --> 00:13:29,279
uh hopefully that will grow your user

403
00:13:26,959 --> 00:13:31,279
base and what i really hope we can do

404
00:13:29,279 --> 00:13:32,560
is some way to provide performance

405
00:13:31,279 --> 00:13:34,959
feedback for

406
00:13:32,560 --> 00:13:34,959
the people who

407
00:13:39,120 --> 00:13:44,079
and finally if you're a researcher i

408
00:13:41,360 --> 00:13:45,440
guess in the grand scheme of things

409
00:13:44,079 --> 00:13:48,880
we want it to be easy to integrate in

410
00:13:45,440 --> 00:13:48,880
your workflows right across the

411
00:13:50,320 --> 00:13:53,440
extensible so that people can do

412
00:13:51,680 --> 00:13:55,040
research either you know the

413
00:13:53,440 --> 00:13:58,480
orchestration level or the

414
00:13:55,040 --> 00:14:00,000
the data models other frameworks

415
00:13:58,480 --> 00:14:02,320
and basically you have this performance

416
00:14:00,000 --> 00:14:06,480
monitoring and optimization

417
00:14:02,320 --> 00:14:06,480
to improve the codes

418
00:14:06,800 --> 00:14:11,120
so that was my presentation not hyped

419
00:14:09,360 --> 00:14:17,839
upgrades between grass and data science

420
00:14:11,120 --> 00:14:17,839
and i would take any questions

421
00:14:51,680 --> 00:14:55,359
i think the question is basically if you

422
00:14:53,760 --> 00:14:59,040
could optimize

423
00:14:55,360 --> 00:14:59,040
the placement of the tasks that you

424
00:15:00,560 --> 00:15:04,160
yeah so i think it's um you can

425
00:15:02,800 --> 00:15:06,079
definitely do that

426
00:15:04,160 --> 00:15:08,079
i think part of the work would be also

427
00:15:06,079 --> 00:15:09,439
to

428
00:15:08,079 --> 00:15:10,479
you know instrument so that you kind of

429
00:15:09,440 --> 00:15:12,160
learn what is the performance

430
00:15:10,480 --> 00:15:14,079
characteristic of running something

431
00:15:12,160 --> 00:15:15,839
right so that because then when you have

432
00:15:14,079 --> 00:15:16,959
this data you can you can make decisions

433
00:15:15,839 --> 00:15:19,199
right so

434
00:15:16,959 --> 00:15:21,518
it could be very well in some cases even

435
00:15:19,199 --> 00:15:23,120
though you ship data back and forth

436
00:15:21,519 --> 00:15:24,959
your accelerator is so much faster that

437
00:15:23,120 --> 00:15:26,880
it makes sense in some cases it might

438
00:15:24,959 --> 00:15:28,719
not so

439
00:15:26,880 --> 00:15:30,880
if you have the data then you can do

440
00:15:28,720 --> 00:15:30,880
that

441
00:15:34,560 --> 00:15:38,479
yeah i think at the test level basically

442
00:15:36,480 --> 00:15:40,720
whatever is the uh

443
00:15:38,480 --> 00:15:43,759
the orchestration plugin that's why you

444
00:15:40,720 --> 00:15:43,759
plug in heuristics

445
00:15:44,079 --> 00:15:47,599
you know most likely this would be also

446
00:15:45,440 --> 00:15:49,759
policies that you can just inject

447
00:15:47,600 --> 00:15:50,800
so for some reason what you want to do

448
00:15:49,759 --> 00:15:55,839
is

449
00:15:50,800 --> 00:15:55,839
pay for this

450
00:15:56,480 --> 00:15:59,920
one of the sort of conditions that he

451
00:15:58,320 --> 00:16:02,240
had was

452
00:15:59,920 --> 00:16:03,279
you could be able to have any hardware

453
00:16:02,240 --> 00:16:05,279
and then

454
00:16:03,279 --> 00:16:08,720
run an algorithm on the cpu and then

455
00:16:05,279 --> 00:16:10,560
another one on the gpu do you expect in

456
00:16:08,720 --> 00:16:13,199
that scenario to handle that data

457
00:16:10,560 --> 00:16:16,959
movement going from cp's

458
00:16:13,199 --> 00:16:19,199
so the question is uh

459
00:16:16,959 --> 00:16:20,239
yes who do you expect to be doing

460
00:16:19,199 --> 00:16:23,279
basically the

461
00:16:20,240 --> 00:16:24,959
data movement between cpus and gpus

462
00:16:23,279 --> 00:16:26,399
so yeah i think it goes a little bit

463
00:16:24,959 --> 00:16:28,160
into how we

464
00:16:26,399 --> 00:16:30,320
this effort would fit in the ecosystem

465
00:16:28,160 --> 00:16:31,680
because uh some frameworks right here at

466
00:16:30,320 --> 00:16:33,279
one entry point and then it kind of

467
00:16:31,680 --> 00:16:35,199
decides

468
00:16:33,279 --> 00:16:37,439
their own heuristic to say do i do cpus

469
00:16:35,199 --> 00:16:39,279
or gpus so i think what we would need

470
00:16:37,440 --> 00:16:42,959
ideally what we want is

471
00:16:39,279 --> 00:16:45,040
as we build that task draft

472
00:16:42,959 --> 00:16:46,399
we would like that to have the control

473
00:16:45,040 --> 00:16:49,199
basically they have

474
00:16:46,399 --> 00:16:50,560
the most flexibility possible and for

475
00:16:49,199 --> 00:16:52,319
that you kind of have to open up a

476
00:16:50,560 --> 00:16:52,959
little bit these are these frameworks to

477
00:16:52,320 --> 00:16:54,639
say

478
00:16:52,959 --> 00:16:56,399
it's not just that i'm doing that on a

479
00:16:54,639 --> 00:16:57,920
graph i'm doing moving on the gpu or

480
00:16:56,399 --> 00:17:00,240
moving on

481
00:16:57,920 --> 00:17:01,199
and at that point then in that data

482
00:17:00,240 --> 00:17:03,120
transformers

483
00:17:01,199 --> 00:17:04,399
right because it goes back to that

484
00:17:03,120 --> 00:17:05,839
person right then you have the whole

485
00:17:04,400 --> 00:17:08,559
picture and you can say okay

486
00:17:05,839 --> 00:17:10,000
it would cost that much to do transfer

487
00:17:08,559 --> 00:17:10,959
and you can actually do something about

488
00:17:10,000 --> 00:17:14,640
it because it's not

489
00:17:10,959 --> 00:17:17,839
based in the framework um

490
00:17:14,640 --> 00:17:22,319
so yeah so then you have these data

491
00:17:17,839 --> 00:17:22,319
transformers that would basically do the

492
00:17:30,840 --> 00:17:36,299
copy

493
00:17:33,230 --> 00:17:36,299
[Applause]

494
00:17:39,120 --> 00:17:41,199
you

