1
00:00:06,799 --> 00:00:09,840
okay we'll get started with the next

2
00:00:08,240 --> 00:00:11,360
talk

3
00:00:09,840 --> 00:00:13,519
welcoming adrian who will be talking

4
00:00:11,360 --> 00:00:17,919
about open source data lake

5
00:00:13,519 --> 00:00:17,920
at scale in the cloud

6
00:00:20,640 --> 00:00:25,039
my name is adrian woodhead i work for

7
00:00:23,600 --> 00:00:27,279
expedia group as you can see

8
00:00:25,039 --> 00:00:28,320
i'm a principal engineer working on the

9
00:00:27,279 --> 00:00:31,119
big data platform

10
00:00:28,320 --> 00:00:32,159
and also all things open source so yes

11
00:00:31,119 --> 00:00:33,680
i'm going to be talking about building

12
00:00:32,159 --> 00:00:34,718
an open source data lake at scale in the

13
00:00:33,680 --> 00:00:36,960
cloud

14
00:00:34,719 --> 00:00:39,200
so a lot of the components we use in our

15
00:00:36,960 --> 00:00:41,520
data lake are open source

16
00:00:39,200 --> 00:00:43,040
and one of the things we feel very

17
00:00:41,520 --> 00:00:44,559
passionately about

18
00:00:43,040 --> 00:00:46,559
is that a lot of companies just take

19
00:00:44,559 --> 00:00:48,480
take take and build stuff on top of open

20
00:00:46,559 --> 00:00:50,399
source and don't give a lot back

21
00:00:48,480 --> 00:00:53,199
so we tried very very hard wherever we

22
00:00:50,399 --> 00:00:55,680
found gaps in the open source ecosystem

23
00:00:53,199 --> 00:00:57,120
to build tools that fill those gaps and

24
00:00:55,680 --> 00:00:58,320
then we've open sourced them so i'm

25
00:00:57,120 --> 00:00:59,120
going to be talking about a few of those

26
00:00:58,320 --> 00:01:00,480
today

27
00:00:59,120 --> 00:01:02,320
so hopefully those can you know other

28
00:01:00,480 --> 00:01:02,879
people can use them improve them and we

29
00:01:02,320 --> 00:01:06,720
also

30
00:01:02,879 --> 00:01:06,720
make sure the whole ecosystem is

31
00:01:10,840 --> 00:01:13,840
sustainable

32
00:01:16,880 --> 00:01:21,280
so i'm not sure why it's not moving

33
00:01:18,720 --> 00:01:21,280
forward

34
00:01:21,520 --> 00:01:25,280
there we go so the agenda for the talk

35
00:01:24,240 --> 00:01:26,640
today i'll just give a little bit of

36
00:01:25,280 --> 00:01:29,040
background about

37
00:01:26,640 --> 00:01:30,640
expedia group how we're structured

38
00:01:29,040 --> 00:01:32,640
because that has some sort of impact on

39
00:01:30,640 --> 00:01:34,000
how we built our data lake

40
00:01:32,640 --> 00:01:35,439
we'll talk about what we consider the

41
00:01:34,000 --> 00:01:37,200
foundation for that how we store our

42
00:01:35,439 --> 00:01:38,880
data and the metadata

43
00:01:37,200 --> 00:01:40,799
we'll talk about some options for high

44
00:01:38,880 --> 00:01:43,119
availability disaster recovery

45
00:01:40,799 --> 00:01:44,880
redundancy those kinds of things

46
00:01:43,119 --> 00:01:46,240
we'll look at some options if you

47
00:01:44,880 --> 00:01:49,119
operate at a certain scale it can be

48
00:01:46,240 --> 00:01:51,759
useful to federate access to your data

49
00:01:49,119 --> 00:01:52,560
and then we'll look at how we enable

50
00:01:51,759 --> 00:01:54,079
event based

51
00:01:52,560 --> 00:01:55,439
event-based data processing and we're

52
00:01:54,079 --> 00:01:57,679
going to look at a concrete use case

53
00:01:55,439 --> 00:01:59,520
that we have for this

54
00:01:57,680 --> 00:02:01,200
so before everyone runs out of the room

55
00:01:59,520 --> 00:02:01,600
screaming in terror i promise you this

56
00:02:01,200 --> 00:02:03,600
isn't

57
00:02:01,600 --> 00:02:05,039
marketing slide this is actually

58
00:02:03,600 --> 00:02:07,520
important for how we

59
00:02:05,040 --> 00:02:09,520
have had to structure our data lake so

60
00:02:07,520 --> 00:02:10,000
expedia group we consist of a number of

61
00:02:09,520 --> 00:02:12,160
different

62
00:02:10,000 --> 00:02:14,239
companies that we've either you know

63
00:02:12,160 --> 00:02:17,120
developed or bought acquired over the

64
00:02:14,239 --> 00:02:19,040
over the past 20 years or so so we have

65
00:02:17,120 --> 00:02:21,599
you know online travel agencies we have

66
00:02:19,040 --> 00:02:23,760
flights we have hotel bookings vacation

67
00:02:21,599 --> 00:02:27,599
rentals car rentals

68
00:02:23,760 --> 00:02:30,160
all kinds of different companies and

69
00:02:27,599 --> 00:02:31,920
these all operate at a different scale

70
00:02:30,160 --> 00:02:33,920
they have different requirements

71
00:02:31,920 --> 00:02:35,599
they all generate a lot of data and some

72
00:02:33,920 --> 00:02:36,079
of them have data sets that they're just

73
00:02:35,599 --> 00:02:38,399
interested

74
00:02:36,080 --> 00:02:39,760
in for their own usage but then we also

75
00:02:38,400 --> 00:02:41,360
as a business we like to be able to get

76
00:02:39,760 --> 00:02:44,000
a holistic view across

77
00:02:41,360 --> 00:02:45,360
all of this another challenge is as

78
00:02:44,000 --> 00:02:46,879
we've acquired them over the years some

79
00:02:45,360 --> 00:02:48,560
are more integrated into our platform

80
00:02:46,879 --> 00:02:49,679
than others some of their own technology

81
00:02:48,560 --> 00:02:51,599
platforms

82
00:02:49,680 --> 00:02:54,000
so getting one single view onto all of

83
00:02:51,599 --> 00:02:55,280
this is actually quite complicated

84
00:02:54,000 --> 00:02:57,120
and then sort of make it even more

85
00:02:55,280 --> 00:02:57,599
complicated the scale at which we

86
00:02:57,120 --> 00:02:59,360
operate

87
00:02:57,599 --> 00:03:01,839
across all of this is really really huge

88
00:02:59,360 --> 00:03:03,360
so we have literally billions of events

89
00:03:01,840 --> 00:03:04,879
coming in every single

90
00:03:03,360 --> 00:03:07,040
day from all of these different

91
00:03:04,879 --> 00:03:09,440
companies via streams

92
00:03:07,040 --> 00:03:10,480
batch processes massive file dumps you

93
00:03:09,440 --> 00:03:12,319
name it

94
00:03:10,480 --> 00:03:14,000
and then we have thousands probably even

95
00:03:12,319 --> 00:03:16,640
tens of thousands of data processing

96
00:03:14,000 --> 00:03:17,920
jobs ad hoc queries reports running

97
00:03:16,640 --> 00:03:22,000
joining all of this data together

98
00:03:17,920 --> 00:03:22,000
producing even more data sets and so on

99
00:03:22,640 --> 00:03:25,679
also our data platform today we didn't

100
00:03:24,400 --> 00:03:27,840
just build it from scratch

101
00:03:25,680 --> 00:03:28,959
in a vacuum in the last few years we've

102
00:03:27,840 --> 00:03:30,799
got like 20

103
00:03:28,959 --> 00:03:32,480
years of legacy in some cases that we

104
00:03:30,799 --> 00:03:35,599
need to deal with

105
00:03:32,480 --> 00:03:37,119
and initially our data warehouse started

106
00:03:35,599 --> 00:03:37,920
off as what you would now probably call

107
00:03:37,120 --> 00:03:40,239
a traditional

108
00:03:37,920 --> 00:03:41,040
data warehouse so this was a lot of data

109
00:03:40,239 --> 00:03:44,640
stored in

110
00:03:41,040 --> 00:03:47,599
relational databases most of the data

111
00:03:44,640 --> 00:03:49,119
processing data querying was done in sql

112
00:03:47,599 --> 00:03:50,879
and then about 10 years ago there was

113
00:03:49,120 --> 00:03:53,120
the rise of hadoop big data

114
00:03:50,879 --> 00:03:54,720
all of this stuff so we built an

115
00:03:53,120 --> 00:03:57,120
on-premise hadoop cluster

116
00:03:54,720 --> 00:03:58,400
you know 6 700 nodes distributed file

117
00:03:57,120 --> 00:04:01,599
system

118
00:03:58,400 --> 00:04:05,200
and then we put hive on top of that

119
00:04:01,599 --> 00:04:07,119
as a metadata platform and

120
00:04:05,200 --> 00:04:09,119
this was also very useful because hive

121
00:04:07,120 --> 00:04:12,959
provides metadata services

122
00:04:09,120 --> 00:04:14,959
but because of our legacy with sql

123
00:04:12,959 --> 00:04:16,880
hive also has a sql query engine on top

124
00:04:14,959 --> 00:04:18,478
of big data so a lot of our data

125
00:04:16,880 --> 00:04:20,000
processing that was written in sql could

126
00:04:18,478 --> 00:04:23,360
just be moved over more or less

127
00:04:20,000 --> 00:04:23,919
as is and be run via hive and what we

128
00:04:23,360 --> 00:04:25,840
found

129
00:04:23,919 --> 00:04:27,280
is that it was very hard for us running

130
00:04:25,840 --> 00:04:28,159
all of this on-premise on our own data

131
00:04:27,280 --> 00:04:29,840
center

132
00:04:28,160 --> 00:04:31,520
meeting peak demand became quite a

133
00:04:29,840 --> 00:04:33,198
challenge obviously we had to send

134
00:04:31,520 --> 00:04:35,280
people in to rack and stack machines and

135
00:04:33,199 --> 00:04:37,360
that becomes quite expensive

136
00:04:35,280 --> 00:04:39,119
and then the whole upgrade path for the

137
00:04:37,360 --> 00:04:39,680
software and the hardware was very very

138
00:04:39,120 --> 00:04:42,639
painful

139
00:04:39,680 --> 00:04:44,000
and quite expensive so around that time

140
00:04:42,639 --> 00:04:45,520
the cloud vendors

141
00:04:44,000 --> 00:04:47,840
all came along and they started offering

142
00:04:45,520 --> 00:04:49,758
big data capabilities

143
00:04:47,840 --> 00:04:51,679
so we then started migrating our primary

144
00:04:49,759 --> 00:04:54,800
data lake into the cloud

145
00:04:51,680 --> 00:04:57,199
so in our case we use amazon web

146
00:04:54,800 --> 00:04:57,600
services or amazon you know s3 emr all

147
00:04:57,199 --> 00:05:00,400
of these

148
00:04:57,600 --> 00:05:01,759
this functionality that's our primary uh

149
00:05:00,400 --> 00:05:03,440
cloud provider

150
00:05:01,759 --> 00:05:05,759
so that's what i'm going to be the

151
00:05:03,440 --> 00:05:07,759
terminology i'll be using my talk today

152
00:05:05,759 --> 00:05:09,600
but most of the concepts will apply the

153
00:05:07,759 --> 00:05:10,000
same if you're using google azure or

154
00:05:09,600 --> 00:05:14,080
something

155
00:05:10,000 --> 00:05:16,560
else so at

156
00:05:14,080 --> 00:05:17,120
very basic core foundation what does a

157
00:05:16,560 --> 00:05:20,080
cloud

158
00:05:17,120 --> 00:05:21,120
data lake mean to us so we obviously

159
00:05:20,080 --> 00:05:23,120
have a lot of data

160
00:05:21,120 --> 00:05:26,080
so we store that in a distributed file

161
00:05:23,120 --> 00:05:28,400
system so in amazon's case that's s3

162
00:05:26,080 --> 00:05:30,479
wherever possible we used efficient

163
00:05:28,400 --> 00:05:31,280
compressed binary formats like avro

164
00:05:30,479 --> 00:05:35,280
parque

165
00:05:31,280 --> 00:05:37,119
orc etc and then we need to store some

166
00:05:35,280 --> 00:05:39,440
kind of metadata about

167
00:05:37,120 --> 00:05:40,960
the data so that's where we use hives

168
00:05:39,440 --> 00:05:42,560
metastore service so we store the

169
00:05:40,960 --> 00:05:45,198
schemas in there so all the

170
00:05:42,560 --> 00:05:45,759
fields the types etc and then what's

171
00:05:45,199 --> 00:05:47,840
also

172
00:05:45,759 --> 00:05:49,759
quite important is we generally don't

173
00:05:47,840 --> 00:05:51,679
allow our users to go directly to the

174
00:05:49,759 --> 00:05:52,800
file system to access their data

175
00:05:51,680 --> 00:05:54,720
and there are a number of reasons for

176
00:05:52,800 --> 00:05:56,960
that which i'll touch on later

177
00:05:54,720 --> 00:05:58,639
but a lot of it is around the eventual

178
00:05:56,960 --> 00:06:00,000
consistency nature of

179
00:05:58,639 --> 00:06:02,000
cloud file systems because they're not

180
00:06:00,000 --> 00:06:03,520
really posix file systems they're

181
00:06:02,000 --> 00:06:06,639
actually object stores

182
00:06:03,520 --> 00:06:08,560
so often you can't tell if when data is

183
00:06:06,639 --> 00:06:10,560
complete there are no atomic move

184
00:06:08,560 --> 00:06:12,400
operations and things like that so

185
00:06:10,560 --> 00:06:14,479
we use the hive metastore as a way to

186
00:06:12,400 --> 00:06:16,159
register when data is available

187
00:06:14,479 --> 00:06:18,159
so all our users we direct them to the

188
00:06:16,160 --> 00:06:19,520
meta store they find the data set

189
00:06:18,160 --> 00:06:20,240
they're looking for they get the data

190
00:06:19,520 --> 00:06:23,520
locations

191
00:06:20,240 --> 00:06:25,840
and then they can access the data on s3

192
00:06:23,520 --> 00:06:27,520
the hive media store it has a backing

193
00:06:25,840 --> 00:06:28,880
relational database that's mainly an

194
00:06:27,520 --> 00:06:30,240
implementation detail you don't need to

195
00:06:28,880 --> 00:06:31,680
worry about too much

196
00:06:30,240 --> 00:06:33,840
and then the smiley face sort of

197
00:06:31,680 --> 00:06:35,120
represents all our users data processing

198
00:06:33,840 --> 00:06:37,039
jobs and so on

199
00:06:35,120 --> 00:06:39,600
they don't always smile but let's just

200
00:06:37,039 --> 00:06:42,000
pretend they do

201
00:06:39,600 --> 00:06:43,120
to make this setup highly available is

202
00:06:42,000 --> 00:06:46,000
actually fairly

203
00:06:43,120 --> 00:06:48,160
straightforward you put a load balancer

204
00:06:46,000 --> 00:06:49,919
in front of the hive meta store service

205
00:06:48,160 --> 00:06:51,919
you set up some kind of an auto scaling

206
00:06:49,919 --> 00:06:52,400
strategy so the nodes you know scale out

207
00:06:51,919 --> 00:06:55,680
and in

208
00:06:52,400 --> 00:06:57,840
as demand changes the backing database

209
00:06:55,680 --> 00:07:00,080
you can use something like amazon's rds

210
00:06:57,840 --> 00:07:01,280
so it handles that for you and then what

211
00:07:00,080 --> 00:07:02,960
we've found is the

212
00:07:01,280 --> 00:07:04,479
the cloud providers distributed file

213
00:07:02,960 --> 00:07:05,840
systems generally scale

214
00:07:04,479 --> 00:07:08,479
very very well so you don't need to do

215
00:07:05,840 --> 00:07:10,638
much yourself

216
00:07:08,479 --> 00:07:12,560
so one thing again why we've gone with

217
00:07:10,639 --> 00:07:14,240
such a simple setup here you know we

218
00:07:12,560 --> 00:07:16,000
could have chosen to use some very very

219
00:07:14,240 --> 00:07:18,400
fancy specific data warehousing

220
00:07:16,000 --> 00:07:19,840
technology or data lake technology we're

221
00:07:18,400 --> 00:07:21,520
coming back to that first slide where

222
00:07:19,840 --> 00:07:23,679
we've got so many different users with

223
00:07:21,520 --> 00:07:25,359
so many different technology platforms

224
00:07:23,680 --> 00:07:26,960
we've kind of gone for a lowest common

225
00:07:25,360 --> 00:07:29,360
denominator

226
00:07:26,960 --> 00:07:30,318
approach so generally what we found is

227
00:07:29,360 --> 00:07:33,520
if you have the data

228
00:07:30,319 --> 00:07:36,479
in the file system the metadata and hive

229
00:07:33,520 --> 00:07:36,479
most uh

230
00:07:37,039 --> 00:07:40,800
upstream data warehousing technologies

231
00:07:39,520 --> 00:07:43,520
things like spark

232
00:07:40,800 --> 00:07:44,479
flink legacy technologies like mapreduce

233
00:07:43,520 --> 00:07:46,240
cascading

234
00:07:44,479 --> 00:07:48,159
and then all kinds of other tooling like

235
00:07:46,240 --> 00:07:50,479
tableau etc they can all interact with

236
00:07:48,160 --> 00:07:52,240
this using jdbc and odbc

237
00:07:50,479 --> 00:07:54,479
so we enable a really really wide

238
00:07:52,240 --> 00:07:55,919
variety of use cases above all of this

239
00:07:54,479 --> 00:07:58,318
and now we've made it highly available

240
00:07:55,919 --> 00:08:00,318
so that's great

241
00:07:58,319 --> 00:08:02,319
but being highly available in one

242
00:08:00,319 --> 00:08:04,879
geographic region or data center

243
00:08:02,319 --> 00:08:05,840
is a bit risky so you obviously want to

244
00:08:04,879 --> 00:08:07,280
have that redundant

245
00:08:05,840 --> 00:08:10,000
and ideally you want to be able to run

246
00:08:07,280 --> 00:08:11,679
your entire setup in multiple regions

247
00:08:10,000 --> 00:08:13,840
so in order to do that again you can

248
00:08:11,680 --> 00:08:15,120
just spin up your entire setup in

249
00:08:13,840 --> 00:08:16,560
another region

250
00:08:15,120 --> 00:08:18,160
and then you can decide whether you want

251
00:08:16,560 --> 00:08:19,520
to run this in active active mode or

252
00:08:18,160 --> 00:08:21,199
just have a bare minimum in another

253
00:08:19,520 --> 00:08:24,878
region and just fail over to it

254
00:08:21,199 --> 00:08:24,879
if and when a disaster happens

255
00:08:25,680 --> 00:08:28,960
so the key thing from a data lake point

256
00:08:27,360 --> 00:08:30,000
of view is if you start operating in

257
00:08:28,960 --> 00:08:31,440
another region

258
00:08:30,000 --> 00:08:34,240
is you have to have your data and your

259
00:08:31,440 --> 00:08:35,679
metadata available in the other region

260
00:08:34,240 --> 00:08:37,279
so one thing you could do is you could

261
00:08:35,679 --> 00:08:39,120
have all your data producers set up to

262
00:08:37,279 --> 00:08:40,880
produce data to both regions

263
00:08:39,120 --> 00:08:42,240
but now all of them have this burden on

264
00:08:40,880 --> 00:08:43,439
themselves where they have to be able to

265
00:08:42,240 --> 00:08:44,800
synchronize and

266
00:08:43,440 --> 00:08:47,200
what if the one region right to one

267
00:08:44,800 --> 00:08:48,959
region fails and another one succeeds

268
00:08:47,200 --> 00:08:50,800
so we decided to not put that burden on

269
00:08:48,959 --> 00:08:53,119
all our data producers and instead make

270
00:08:50,800 --> 00:08:55,920
that a core feature of the platform

271
00:08:53,120 --> 00:08:58,880
so our platform is responsible for

272
00:08:55,920 --> 00:09:00,240
replicating data into another region

273
00:08:58,880 --> 00:09:02,399
and the key thing is that we need to do

274
00:09:00,240 --> 00:09:03,760
this in a very coordinated fashion

275
00:09:02,399 --> 00:09:05,519
because you want to make sure that if

276
00:09:03,760 --> 00:09:06,880
users are in different querying data in

277
00:09:05,519 --> 00:09:08,080
different regions that they have a very

278
00:09:06,880 --> 00:09:09,920
consistent view

279
00:09:08,080 --> 00:09:11,519
of the data and it's always as correct

280
00:09:09,920 --> 00:09:12,880
as possible

281
00:09:11,519 --> 00:09:14,880
and what that really means is when

282
00:09:12,880 --> 00:09:15,839
you're replicating data or metadata into

283
00:09:14,880 --> 00:09:17,839
another region

284
00:09:15,839 --> 00:09:19,440
you want to make sure that users in the

285
00:09:17,839 --> 00:09:22,240
other region can't get partial reads of

286
00:09:19,440 --> 00:09:24,399
the data whilst it's in transit so what

287
00:09:22,240 --> 00:09:26,160
we generally do is we only advertise

288
00:09:24,399 --> 00:09:28,320
data in the hive meta store when it's

289
00:09:26,160 --> 00:09:30,000
been completely replicated over

290
00:09:28,320 --> 00:09:31,680
and this means there's latency getting

291
00:09:30,000 --> 00:09:33,839
the data into the other region but we

292
00:09:31,680 --> 00:09:35,040
generally feel we'd rather have late

293
00:09:33,839 --> 00:09:38,560
complete data

294
00:09:35,040 --> 00:09:41,279
than incomplete or incorrect data

295
00:09:38,560 --> 00:09:43,599
so to do this we've built a tray a

296
00:09:41,279 --> 00:09:45,200
program that we call circus train

297
00:09:43,600 --> 00:09:46,880
and the name comes from the idea of

298
00:09:45,200 --> 00:09:48,880
taking the hadoop elephant and all of

299
00:09:46,880 --> 00:09:50,640
these other crazy circus

300
00:09:48,880 --> 00:09:52,160
animals in hadoop ecosystem putting them

301
00:09:50,640 --> 00:09:54,319
on a train and moving them from one

302
00:09:52,160 --> 00:09:55,760
place to another

303
00:09:54,320 --> 00:09:57,600
and one of the interesting things we

304
00:09:55,760 --> 00:09:58,160
found when we built it and why we built

305
00:09:57,600 --> 00:09:59,839
it

306
00:09:58,160 --> 00:10:01,760
is there were no replication tools out

307
00:09:59,839 --> 00:10:03,680
there that would only advertise the

308
00:10:01,760 --> 00:10:04,399
availability of the data in the meta

309
00:10:03,680 --> 00:10:06,319
store

310
00:10:04,399 --> 00:10:07,600
after it had been copied so there was

311
00:10:06,320 --> 00:10:08,720
this possibility of getting these

312
00:10:07,600 --> 00:10:11,440
partial

313
00:10:08,720 --> 00:10:13,600
reads so that was that's one of the main

314
00:10:11,440 --> 00:10:14,880
core features of circus train

315
00:10:13,600 --> 00:10:17,680
it supports various different

316
00:10:14,880 --> 00:10:19,200
distributed file systems hdfs s3

317
00:10:17,680 --> 00:10:22,880
google's cloud store

318
00:10:19,200 --> 00:10:25,600
etc and by default it uses hadoop's

319
00:10:22,880 --> 00:10:27,200
sort of famous standard dcp mechanism

320
00:10:25,600 --> 00:10:29,440
for copying massive data sets

321
00:10:27,200 --> 00:10:31,279
at scale we've also written some

322
00:10:29,440 --> 00:10:32,480
optimized copiers for s3 that take

323
00:10:31,279 --> 00:10:35,040
advantage of some of

324
00:10:32,480 --> 00:10:36,560
some of the aspects of that and we've

325
00:10:35,040 --> 00:10:38,240
architected in such a way it's got a

326
00:10:36,560 --> 00:10:41,359
plug-in architecture so you can

327
00:10:38,240 --> 00:10:44,560
write your own custom versions of

328
00:10:41,360 --> 00:10:45,920
various aspects of it

329
00:10:44,560 --> 00:10:47,760
and then we also there's some quite

330
00:10:45,920 --> 00:10:50,000
advanced features in it that can

331
00:10:47,760 --> 00:10:51,760
analyze the data on both sides and then

332
00:10:50,000 --> 00:10:53,200
make sure that it only replicates

333
00:10:51,760 --> 00:10:54,800
the bare minimum which is quite

334
00:10:53,200 --> 00:10:56,399
important when you possibly replicating

335
00:10:54,800 --> 00:10:58,399
terabytes of data every day you want to

336
00:10:56,399 --> 00:10:59,839
keep that to the minimum

337
00:10:58,399 --> 00:11:01,760
initially we built circus train with the

338
00:10:59,839 --> 00:11:02,959
idea to be run on like a time based

339
00:11:01,760 --> 00:11:05,439
schedule once a day

340
00:11:02,959 --> 00:11:06,880
once every four hours etc which works

341
00:11:05,440 --> 00:11:08,720
well for certain use cases

342
00:11:06,880 --> 00:11:10,000
but we found if you really want to scale

343
00:11:08,720 --> 00:11:12,480
this out and minimize

344
00:11:10,000 --> 00:11:14,000
latency between data being available and

345
00:11:12,480 --> 00:11:15,279
replicated you want to be able to have

346
00:11:14,000 --> 00:11:17,440
an event

347
00:11:15,279 --> 00:11:18,720
trigger for your applications so we

348
00:11:17,440 --> 00:11:19,680
built a layer on top of it called

349
00:11:18,720 --> 00:11:21,440
shunting odd

350
00:11:19,680 --> 00:11:23,199
which basically monitors the hive

351
00:11:21,440 --> 00:11:24,880
metastore for changes when data gets

352
00:11:23,200 --> 00:11:28,640
changed it then triggers replications

353
00:11:24,880 --> 00:11:30,160
automatically in the background

354
00:11:28,640 --> 00:11:32,800
so what we then found is sort of an

355
00:11:30,160 --> 00:11:34,480
unexpected side effect of this big cloud

356
00:11:32,800 --> 00:11:37,040
migration that we

357
00:11:34,480 --> 00:11:38,560
did across our entire company is that

358
00:11:37,040 --> 00:11:40,079
these different business units different

359
00:11:38,560 --> 00:11:41,599
parts of the company started moving to

360
00:11:40,079 --> 00:11:43,760
the cloud at different speeds

361
00:11:41,600 --> 00:11:44,959
which was kind of good for them but then

362
00:11:43,760 --> 00:11:48,000
what happened is they

363
00:11:44,959 --> 00:11:49,760
started building their own data lakes in

364
00:11:48,000 --> 00:11:51,279
their own amazon accounts sometimes even

365
00:11:49,760 --> 00:11:54,720
in different regions

366
00:11:51,279 --> 00:11:55,360
so we basically had the situation now

367
00:11:54,720 --> 00:11:57,839
where we've got

368
00:11:55,360 --> 00:12:00,000
data silos so when we're on premise and

369
00:11:57,839 --> 00:12:00,720
we had one hadoop cluster one hive meta

370
00:12:00,000 --> 00:12:02,800
store most of

371
00:12:00,720 --> 00:12:04,160
the data was in one place and people

372
00:12:02,800 --> 00:12:05,920
could very easily do

373
00:12:04,160 --> 00:12:07,760
joins and queries across all of this

374
00:12:05,920 --> 00:12:08,959
data but now

375
00:12:07,760 --> 00:12:10,560
in this case here i'm just showing three

376
00:12:08,959 --> 00:12:12,079
of the business units we've basically

377
00:12:10,560 --> 00:12:14,079
got three data lakes

378
00:12:12,079 --> 00:12:15,519
and hive was never built in a way that

379
00:12:14,079 --> 00:12:17,279
it was it was never designed to be able

380
00:12:15,519 --> 00:12:18,959
to federate queries in this fashion so

381
00:12:17,279 --> 00:12:20,320
we'd built these data silos

382
00:12:18,959 --> 00:12:23,439
and this wasn't going to be acceptable

383
00:12:20,320 --> 00:12:24,880
to our end users

384
00:12:23,440 --> 00:12:26,480
so we thought a little bit about how are

385
00:12:24,880 --> 00:12:28,639
we going to tackle this how are we going

386
00:12:26,480 --> 00:12:30,160
to you know break down these silos

387
00:12:28,639 --> 00:12:31,600
so one option would be that we would

388
00:12:30,160 --> 00:12:32,959
tell all of these business units you

389
00:12:31,600 --> 00:12:33,360
need to move everything back into one

390
00:12:32,959 --> 00:12:36,399
big

391
00:12:33,360 --> 00:12:38,160
central data lake in the cloud

392
00:12:36,399 --> 00:12:39,760
which is probably if you're operating on

393
00:12:38,160 --> 00:12:41,040
a smaller scale that's probably actually

394
00:12:39,760 --> 00:12:42,399
quite a good approach to take it's quite

395
00:12:41,040 --> 00:12:43,839
a bit simpler

396
00:12:42,399 --> 00:12:45,680
but we thought we were going to have

397
00:12:43,839 --> 00:12:47,760
some scalability issues there's certain

398
00:12:45,680 --> 00:12:50,079
limitations to how much you can do in

399
00:12:47,760 --> 00:12:51,439
you know one or two amazon accounts and

400
00:12:50,079 --> 00:12:53,279
we're also a little bit concerned about

401
00:12:51,440 --> 00:12:54,800
the blast radius of having the entire

402
00:12:53,279 --> 00:12:56,480
company all these different users

403
00:12:54,800 --> 00:12:58,399
operating in one

404
00:12:56,480 --> 00:13:00,160
amazon account if something went wrong

405
00:12:58,399 --> 00:13:01,760
the blast radius of that could take down

406
00:13:00,160 --> 00:13:03,439
the entire company which wouldn't be

407
00:13:01,760 --> 00:13:05,600
good

408
00:13:03,440 --> 00:13:07,360
so instead another option we we thought

409
00:13:05,600 --> 00:13:08,880
about we have a great replication tool

410
00:13:07,360 --> 00:13:10,160
we could possibly look at

411
00:13:08,880 --> 00:13:11,680
all the shared data sets and then

412
00:13:10,160 --> 00:13:12,319
replicate them into each of these data

413
00:13:11,680 --> 00:13:13,839
lakes

414
00:13:12,320 --> 00:13:16,639
so everyone has their own copy of the

415
00:13:13,839 --> 00:13:18,079
data and if you only have a few data

416
00:13:16,639 --> 00:13:18,800
sets that you share that is actually

417
00:13:18,079 --> 00:13:20,880
also probably

418
00:13:18,800 --> 00:13:23,199
quite a good approach but we had

419
00:13:20,880 --> 00:13:25,120
thousands possibly tens of thousands

420
00:13:23,200 --> 00:13:27,040
and this idea of setting up and

421
00:13:25,120 --> 00:13:29,120
maintaining thousands of replication

422
00:13:27,040 --> 00:13:30,800
jobs all the transfer costs increased

423
00:13:29,120 --> 00:13:34,160
storage costs we decided

424
00:13:30,800 --> 00:13:35,680
that was a no-go for us too

425
00:13:34,160 --> 00:13:37,839
so instead we looked at how could we

426
00:13:35,680 --> 00:13:40,399
federate the hive metastore

427
00:13:37,839 --> 00:13:40,880
so we built a open source tool that we

428
00:13:40,399 --> 00:13:44,000
call

429
00:13:40,880 --> 00:13:45,839
waggle dance and the name comes from the

430
00:13:44,000 --> 00:13:47,920
dance that bees make when they want to

431
00:13:45,839 --> 00:13:51,279
indicate to other bees where to find

432
00:13:47,920 --> 00:13:55,519
pollen or food sources and what this is

433
00:13:51,279 --> 00:13:57,040
is the hive metastore has a thrift api

434
00:13:55,519 --> 00:13:58,880
that it makes available for people who

435
00:13:57,040 --> 00:14:00,719
want to get hold of that metadata

436
00:13:58,880 --> 00:14:02,399
so we basically built a proxy that

437
00:14:00,720 --> 00:14:05,279
exposes the exact same

438
00:14:02,399 --> 00:14:06,959
api and what you do then is you

439
00:14:05,279 --> 00:14:07,680
configure that proxy with different

440
00:14:06,959 --> 00:14:09,839
downstream

441
00:14:07,680 --> 00:14:11,519
hive meta stores and then what people

442
00:14:09,839 --> 00:14:12,639
can do they query the proxy the proxy

443
00:14:11,519 --> 00:14:14,720
then goes out to

444
00:14:12,639 --> 00:14:16,240
all the federated hive meta stores

445
00:14:14,720 --> 00:14:17,920
gathers all the results

446
00:14:16,240 --> 00:14:19,839
aggregates them back and presents it

447
00:14:17,920 --> 00:14:21,920
back to the user as if it was a single

448
00:14:19,839 --> 00:14:23,680
metastore

449
00:14:21,920 --> 00:14:25,279
so that's good for the metadata access

450
00:14:23,680 --> 00:14:27,279
when it comes to the actual

451
00:14:25,279 --> 00:14:29,199
data on s3 you need to set up

452
00:14:27,279 --> 00:14:31,279
corresponding access permissions which

453
00:14:29,199 --> 00:14:33,199
is generally fairly straightforward

454
00:14:31,279 --> 00:14:35,519
and then as an end user what you do in

455
00:14:33,199 --> 00:14:37,680
your client application

456
00:14:35,519 --> 00:14:38,959
there's a url that's a configuration

457
00:14:37,680 --> 00:14:40,719
setting that you can

458
00:14:38,959 --> 00:14:42,399
change instead of pointing to your local

459
00:14:40,720 --> 00:14:43,600
meta store you point to igle dance and

460
00:14:42,399 --> 00:14:46,079
then you get this federated

461
00:14:43,600 --> 00:14:47,360
functionality

462
00:14:46,079 --> 00:14:49,199
so kind of what this looks like in

463
00:14:47,360 --> 00:14:49,839
practice if you set up a waggle dance

464
00:14:49,199 --> 00:14:51,519
service

465
00:14:49,839 --> 00:14:53,279
in this example we've got like what's

466
00:14:51,519 --> 00:14:55,120
considered a primary meta store which it

467
00:14:53,279 --> 00:14:56,959
has right access to that one

468
00:14:55,120 --> 00:14:58,639
we have two external meta stores that

469
00:14:56,959 --> 00:15:00,719
are set up in read-only mode

470
00:14:58,639 --> 00:15:01,839
and so if a user query comes in here it

471
00:15:00,720 --> 00:15:04,160
can basically see

472
00:15:01,839 --> 00:15:07,440
and do joins across all three meta

473
00:15:04,160 --> 00:15:07,439
stores as if they were just one

474
00:15:07,839 --> 00:15:11,279
so what this actually looks like in

475
00:15:09,199 --> 00:15:13,120
practice for us

476
00:15:11,279 --> 00:15:14,320
this is just an example here showing you

477
00:15:13,120 --> 00:15:16,399
know three of our

478
00:15:14,320 --> 00:15:17,519
business units hotels.com verba and

479
00:15:16,399 --> 00:15:18,800
expedia

480
00:15:17,519 --> 00:15:20,399
and they're operating here in three

481
00:15:18,800 --> 00:15:21,439
separate amazon accounts that's the

482
00:15:20,399 --> 00:15:23,839
vertical

483
00:15:21,440 --> 00:15:25,839
dotted lines and we're running in two

484
00:15:23,839 --> 00:15:28,240
different geographic regions us waste 2

485
00:15:25,839 --> 00:15:29,680
and usd1 in this example

486
00:15:28,240 --> 00:15:31,360
and so what we do then is within a

487
00:15:29,680 --> 00:15:34,079
region all the data

488
00:15:31,360 --> 00:15:36,320
is you know pretty much co-located

489
00:15:34,079 --> 00:15:38,160
latency and data transfer costs are low

490
00:15:36,320 --> 00:15:40,560
so we can federate data access across

491
00:15:38,160 --> 00:15:42,639
them we replicate data into another

492
00:15:40,560 --> 00:15:46,239
region and in that region we federate

493
00:15:42,639 --> 00:15:48,000
again so some of the best practices

494
00:15:46,240 --> 00:15:50,079
we've learned from operating all of this

495
00:15:48,000 --> 00:15:51,519
for the past few years is generally

496
00:15:50,079 --> 00:15:54,160
wherever possible we expose

497
00:15:51,519 --> 00:15:54,720
read-only endpoints to the end users you

498
00:15:54,160 --> 00:15:56,959
don't want

499
00:15:54,720 --> 00:15:58,480
you know ad hoc query writing into some

500
00:15:56,959 --> 00:16:00,079
unexpected place

501
00:15:58,480 --> 00:16:02,079
and similarly wherever there's critical

502
00:16:00,079 --> 00:16:03,680
path infrastructure so etl or streaming

503
00:16:02,079 --> 00:16:05,839
jobs which need to operate

504
00:16:03,680 --> 00:16:08,079
you need to you really really need to

505
00:16:05,839 --> 00:16:09,680
have them running or 100 reliability

506
00:16:08,079 --> 00:16:11,920
again separate all of that

507
00:16:09,680 --> 00:16:14,719
infrastructure from uh people doing

508
00:16:11,920 --> 00:16:16,079
queries and then yes whenever you're

509
00:16:14,720 --> 00:16:18,160
going to federate

510
00:16:16,079 --> 00:16:19,920
data access within a region you federate

511
00:16:18,160 --> 00:16:21,439
and then if you're going to

512
00:16:19,920 --> 00:16:24,000
have it have a need for the data another

513
00:16:21,440 --> 00:16:25,759
region you basically just set up one job

514
00:16:24,000 --> 00:16:27,600
to replicate the data into that other

515
00:16:25,759 --> 00:16:29,120
region and then you federate again

516
00:16:27,600 --> 00:16:30,800
what we always want to avoid is

517
00:16:29,120 --> 00:16:32,480
federating across a region boundary

518
00:16:30,800 --> 00:16:34,839
because then you're transferring data

519
00:16:32,480 --> 00:16:36,720
across the region which is slow and

520
00:16:34,839 --> 00:16:38,959
expensive

521
00:16:36,720 --> 00:16:40,079
there are other alternatives out there

522
00:16:38,959 --> 00:16:43,359
if you need this kind of

523
00:16:40,079 --> 00:16:44,239
federated query mechanism so there's the

524
00:16:43,360 --> 00:16:46,639
presto project

525
00:16:44,240 --> 00:16:48,480
that's also distributed sql query engine

526
00:16:46,639 --> 00:16:50,240
for big data

527
00:16:48,480 --> 00:16:52,720
it can federate hive it can also do my

528
00:16:50,240 --> 00:16:54,079
sequel postgres and many others

529
00:16:52,720 --> 00:16:56,000
the big problem with it is there's been

530
00:16:54,079 --> 00:16:57,758
a huge disagreement in the community a

531
00:16:56,000 --> 00:16:59,199
fork there are two versions of presto

532
00:16:57,759 --> 00:17:02,399
the same name

533
00:16:59,199 --> 00:17:05,918
um foundations behind them so good luck

534
00:17:02,399 --> 00:17:07,199
picking the winner and as you can

535
00:17:05,919 --> 00:17:08,880
imagine setting up and

536
00:17:07,199 --> 00:17:10,240
maintaining and configuring all of this

537
00:17:08,880 --> 00:17:12,240
it's it's there's quite a bit of

538
00:17:10,240 --> 00:17:14,000
configuration that's needed to do this

539
00:17:12,240 --> 00:17:15,599
so we built an umbrella project called a

540
00:17:14,000 --> 00:17:17,199
peri where we aim to put all of this

541
00:17:15,599 --> 00:17:18,559
stuff componentize as much of it as

542
00:17:17,199 --> 00:17:19,679
possible

543
00:17:18,559 --> 00:17:21,520
and then you can pick and choose the

544
00:17:19,679 --> 00:17:23,360
bits that you want so we have docker

545
00:17:21,520 --> 00:17:25,199
images for all the services

546
00:17:23,359 --> 00:17:26,319
we have terraform deployment scripts for

547
00:17:25,199 --> 00:17:28,160
being able to set up all of the

548
00:17:26,319 --> 00:17:29,280
networking load balancing infrastructure

549
00:17:28,160 --> 00:17:31,360
and so on

550
00:17:29,280 --> 00:17:34,799
we have a range of authorization and

551
00:17:31,360 --> 00:17:34,799
various optional extensions

552
00:17:35,440 --> 00:17:38,720
so i'm going to give an example of one

553
00:17:36,720 --> 00:17:40,720
of these optional extensions

554
00:17:38,720 --> 00:17:41,919
so it's a metadata event framework that

555
00:17:40,720 --> 00:17:44,000
we built

556
00:17:41,919 --> 00:17:45,440
and one of the reasons we did that is

557
00:17:44,000 --> 00:17:47,120
that we found when you're operating

558
00:17:45,440 --> 00:17:48,080
thousands of data processing jobs at

559
00:17:47,120 --> 00:17:50,000
scale

560
00:17:48,080 --> 00:17:52,320
doing this using some kind of time-based

561
00:17:50,000 --> 00:17:53,919
mechanism using cron and relying on when

562
00:17:52,320 --> 00:17:56,480
data should be there or not

563
00:17:53,919 --> 00:17:57,200
is very very painful so instead we

564
00:17:56,480 --> 00:17:59,039
prefer

565
00:17:57,200 --> 00:18:01,840
to be able to do everything based on

566
00:17:59,039 --> 00:18:01,840
metadata events

567
00:18:02,720 --> 00:18:05,919
so what we do what what this framework

568
00:18:04,799 --> 00:18:08,879
does is it it

569
00:18:05,919 --> 00:18:11,280
emits events whenever there is a change

570
00:18:08,880 --> 00:18:13,200
to the data they go into kafka sms

571
00:18:11,280 --> 00:18:15,678
and then downstream people can subscribe

572
00:18:13,200 --> 00:18:17,280
to those

573
00:18:15,679 --> 00:18:19,440
so one of the the big problems we have

574
00:18:17,280 --> 00:18:21,678
is rewriting data at scale

575
00:18:19,440 --> 00:18:23,200
so we generally partition our data by

576
00:18:21,679 --> 00:18:25,280
some kind of like when the data arrived

577
00:18:23,200 --> 00:18:27,360
like when hotel booking was made

578
00:18:25,280 --> 00:18:29,200
um ideally those partitions would be

579
00:18:27,360 --> 00:18:30,719
immutable but that's very rarely the

580
00:18:29,200 --> 00:18:32,320
case you've got late arriving data

581
00:18:30,720 --> 00:18:33,520
sometimes you have updates

582
00:18:32,320 --> 00:18:34,879
and one of the big problems when you

583
00:18:33,520 --> 00:18:36,480
have massive data sets massive

584
00:18:34,880 --> 00:18:38,080
partitions is even just doing an update

585
00:18:36,480 --> 00:18:40,960
takes a lot of time

586
00:18:38,080 --> 00:18:42,480
so what we do to ensure we have read

587
00:18:40,960 --> 00:18:43,760
isolation for queries that are running

588
00:18:42,480 --> 00:18:45,360
across those partitions

589
00:18:43,760 --> 00:18:46,799
so when updates come in we basically

590
00:18:45,360 --> 00:18:47,840
write an entire new version of the

591
00:18:46,799 --> 00:18:49,600
partition

592
00:18:47,840 --> 00:18:51,280
and then when that write is finished we

593
00:18:49,600 --> 00:18:53,120
re-point the meta the hive metastore

594
00:18:51,280 --> 00:18:54,480
over to the new location

595
00:18:53,120 --> 00:18:55,760
but then you have the problem what to do

596
00:18:54,480 --> 00:18:56,720
with the old versions of those

597
00:18:55,760 --> 00:18:58,240
partitions

598
00:18:56,720 --> 00:18:59,440
and because it's such a big distributed

599
00:18:58,240 --> 00:19:00,960
system we don't actually know when

600
00:18:59,440 --> 00:19:02,400
people are finished reading that data so

601
00:19:00,960 --> 00:19:04,080
we kind of have these orphan data sets

602
00:19:02,400 --> 00:19:07,120
that sit around

603
00:19:04,080 --> 00:19:09,039
so how do you expire them

604
00:19:07,120 --> 00:19:10,239
so what we did is we wrote a tool called

605
00:19:09,039 --> 00:19:11,679
beekeeper

606
00:19:10,240 --> 00:19:14,000
and what that does is that sits

607
00:19:11,679 --> 00:19:14,799
downstream of that metadata event

608
00:19:14,000 --> 00:19:16,480
framework

609
00:19:14,799 --> 00:19:18,879
and it watches all the time and it

610
00:19:16,480 --> 00:19:20,400
detects when one of these

611
00:19:18,880 --> 00:19:22,840
update operations has happened that is

612
00:19:20,400 --> 00:19:25,520
potentially orphaned data

613
00:19:22,840 --> 00:19:26,720
and all the the data owner needs to do

614
00:19:25,520 --> 00:19:29,039
is they put this

615
00:19:26,720 --> 00:19:30,400
hive table parameter on their table you

616
00:19:29,039 --> 00:19:30,960
plug in b keep it onto the event

617
00:19:30,400 --> 00:19:32,880
listener

618
00:19:30,960 --> 00:19:34,400
it finds the rewrites and then it

619
00:19:32,880 --> 00:19:34,960
basically schedules the data for

620
00:19:34,400 --> 00:19:37,280
deletion

621
00:19:34,960 --> 00:19:38,160
in the future so we have a time window

622
00:19:37,280 --> 00:19:39,840
of three days

623
00:19:38,160 --> 00:19:41,600
just to be completely sure that all

624
00:19:39,840 --> 00:19:45,439
people have stopped using that data

625
00:19:41,600 --> 00:19:46,879
and it will then do the data deletions

626
00:19:45,440 --> 00:19:49,039
so this is one of the places where

627
00:19:46,880 --> 00:19:50,640
having a central platform makes it a lot

628
00:19:49,039 --> 00:19:51,440
easier for all of our end users as they

629
00:19:50,640 --> 00:19:52,000
don't have to do all of these

630
00:19:51,440 --> 00:19:55,440
housekeeping

631
00:19:52,000 --> 00:19:56,160
operations themselves so there's some

632
00:19:55,440 --> 00:19:57,840
other

633
00:19:56,160 --> 00:19:59,039
alternatives that you can have if you

634
00:19:57,840 --> 00:19:59,678
want to be able to do these kinds of

635
00:19:59,039 --> 00:20:02,158
updates

636
00:19:59,679 --> 00:20:03,760
and have a consistency in your platform

637
00:20:02,159 --> 00:20:05,679
newer versions of hive have acid

638
00:20:03,760 --> 00:20:06,799
semantics like relational databases

639
00:20:05,679 --> 00:20:08,559
exhibits

640
00:20:06,799 --> 00:20:10,000
we have iceberg and delta lake which

641
00:20:08,559 --> 00:20:12,080
both use

642
00:20:10,000 --> 00:20:13,840
metadata files on a distributed file

643
00:20:12,080 --> 00:20:15,120
system instead of a database

644
00:20:13,840 --> 00:20:17,840
and then there's hoodie which is another

645
00:20:15,120 --> 00:20:20,000
apache incubating project

646
00:20:17,840 --> 00:20:22,000
it does something similar they're all

647
00:20:20,000 --> 00:20:26,080
under very active development so your

648
00:20:22,000 --> 00:20:26,080
mileage may vary if you use any of them

649
00:20:26,159 --> 00:20:30,080
we also find it's very very important to

650
00:20:27,919 --> 00:20:31,360
test your data processing jobs

651
00:20:30,080 --> 00:20:32,559
so there are a number of unit testing

652
00:20:31,360 --> 00:20:34,399
frameworks out there that we've

653
00:20:32,559 --> 00:20:36,158
contributed to or open sourced so

654
00:20:34,400 --> 00:20:39,120
there's hive runner which you can use to

655
00:20:36,159 --> 00:20:40,880
test hive sql we built a layer on top of

656
00:20:39,120 --> 00:20:42,719
that called mutant swarm which gives you

657
00:20:40,880 --> 00:20:43,200
code coverage of your sql so you can

658
00:20:42,720 --> 00:20:45,679
find

659
00:20:43,200 --> 00:20:47,120
the parts of your sql code that are

660
00:20:45,679 --> 00:20:48,480
missing tests

661
00:20:47,120 --> 00:20:50,399
and then we have another project called

662
00:20:48,480 --> 00:20:51,840
bijou which basically spins up a thrift

663
00:20:50,400 --> 00:20:53,520
hive metastore service or the hive

664
00:20:51,840 --> 00:20:56,158
server 2 service in memory so you can

665
00:20:53,520 --> 00:20:57,440
write unit tests against it

666
00:20:56,159 --> 00:20:59,440
so things we're looking at what are we

667
00:20:57,440 --> 00:21:00,880
going to do next what we really really

668
00:20:59,440 --> 00:21:03,280
want to do is have our entire data

669
00:21:00,880 --> 00:21:06,240
platform built on open source solutions

670
00:21:03,280 --> 00:21:07,520
that we can run where we want wherever

671
00:21:06,240 --> 00:21:10,320
based on performance

672
00:21:07,520 --> 00:21:11,600
cost scalability so hybrid cloud would

673
00:21:10,320 --> 00:21:12,158
be very nice we could run things on

674
00:21:11,600 --> 00:21:14,320
premise

675
00:21:12,159 --> 00:21:15,360
or in the cloud provider multi-cloud

676
00:21:14,320 --> 00:21:16,639
being able to use different cloud

677
00:21:15,360 --> 00:21:18,000
providers for their strengths

678
00:21:16,640 --> 00:21:20,400
but obviously both of those come with

679
00:21:18,000 --> 00:21:22,159
the cost of increased complexity

680
00:21:20,400 --> 00:21:24,000
so what we're really hoping for is the

681
00:21:22,159 --> 00:21:25,200
combination of docker terraform

682
00:21:24,000 --> 00:21:26,720
kubernetes

683
00:21:25,200 --> 00:21:29,039
that we can basically take this entire

684
00:21:26,720 --> 00:21:30,480
platform deploy it

685
00:21:29,039 --> 00:21:32,240
you know at scale without too much

686
00:21:30,480 --> 00:21:34,480
effort either on-premise or in one of

687
00:21:32,240 --> 00:21:37,600
the cloud providers

688
00:21:34,480 --> 00:21:39,280
kubernetes engines so

689
00:21:37,600 --> 00:21:40,719
these are some of the projects i've

690
00:21:39,280 --> 00:21:42,960
talked about some of the links

691
00:21:40,720 --> 00:21:44,400
if you're interested have a look they've

692
00:21:42,960 --> 00:21:45,760
all got mailing lists we'd love to hear

693
00:21:44,400 --> 00:21:48,320
from you

694
00:21:45,760 --> 00:21:49,200
and that is the end of my whirlwind tour

695
00:21:48,320 --> 00:21:51,280
of data lakes

696
00:21:49,200 --> 00:21:59,679
and i think i've got three four minutes

697
00:21:51,280 --> 00:22:01,360
for questions

698
00:21:59,679 --> 00:22:03,440
please stay seated while we do questions

699
00:22:01,360 --> 00:22:07,039
so we can actually hear the question

700
00:22:03,440 --> 00:22:07,039
any questions for adrian

701
00:22:08,159 --> 00:22:12,640
hi thank you for presentation so uh you

702
00:22:10,799 --> 00:22:15,440
said about uh

703
00:22:12,640 --> 00:22:17,440
distributed system within uh the amazon

704
00:22:15,440 --> 00:22:18,080
cloud so what particular components you

705
00:22:17,440 --> 00:22:21,840
use for

706
00:22:18,080 --> 00:22:23,678
foster s3 or any other bundled hadoop

707
00:22:21,840 --> 00:22:26,320
cluster within the amazon

708
00:22:23,679 --> 00:22:27,360
thank you sure so yeah so we use for the

709
00:22:26,320 --> 00:22:30,559
data lake

710
00:22:27,360 --> 00:22:32,158
we use s3 for long term storage uh

711
00:22:30,559 --> 00:22:32,960
whilst we're running data processing

712
00:22:32,159 --> 00:22:37,280
jobs

713
00:22:32,960 --> 00:22:38,880
we use emr we also use qball

714
00:22:37,280 --> 00:22:40,559
what a lot of those do is they spin up a

715
00:22:38,880 --> 00:22:42,720
temporary hdfs

716
00:22:40,559 --> 00:22:44,480
cluster for writes whilst the job is

717
00:22:42,720 --> 00:22:46,320
running but then when the job's complete

718
00:22:44,480 --> 00:22:48,080
they write everything back to s3 so that

719
00:22:46,320 --> 00:22:50,559
the foundational piece really is

720
00:22:48,080 --> 00:22:50,559
s3

721
00:22:51,760 --> 00:22:57,520
any more questions

722
00:22:54,799 --> 00:22:57,520
can i throw it

723
00:23:01,679 --> 00:23:04,720
hi i'm wondering if your users have low

724
00:23:03,760 --> 00:23:06,879
latency

725
00:23:04,720 --> 00:23:08,960
needs and that they don't want to wait

726
00:23:06,880 --> 00:23:12,080
for like the replication to finish

727
00:23:08,960 --> 00:23:14,240
before they can query the data

728
00:23:12,080 --> 00:23:16,080
so that's a good question about users

729
00:23:14,240 --> 00:23:19,200
who have lay low latency

730
00:23:16,080 --> 00:23:21,360
needs so generally what we

731
00:23:19,200 --> 00:23:22,880
recommend people do like the people who

732
00:23:21,360 --> 00:23:24,158
really want access to the data should be

733
00:23:22,880 --> 00:23:25,360
running their jobs in

734
00:23:24,159 --> 00:23:27,600
the region where the data is being

735
00:23:25,360 --> 00:23:29,199
produced so most of those replicas are

736
00:23:27,600 --> 00:23:32,080
just for disaster recovery

737
00:23:29,200 --> 00:23:32,720
and those use cases can generally handle

738
00:23:32,080 --> 00:23:34,879
um

739
00:23:32,720 --> 00:23:36,240
high latency the other thing i didn't

740
00:23:34,880 --> 00:23:38,320
really talk about in this talk because i

741
00:23:36,240 --> 00:23:39,760
was focusing on the data lake aspect

742
00:23:38,320 --> 00:23:42,158
is we're trying to move as much as

743
00:23:39,760 --> 00:23:43,840
possible to stream first approach

744
00:23:42,159 --> 00:23:46,000
so actually a lot of the data that comes

745
00:23:43,840 --> 00:23:47,840
into the data lake it arrives in real

746
00:23:46,000 --> 00:23:48,720
time and it goes on to we have a big

747
00:23:47,840 --> 00:23:50,879
streaming platform

748
00:23:48,720 --> 00:23:52,480
based on kafka so if you have really

749
00:23:50,880 --> 00:23:54,159
really really low latency needs you

750
00:23:52,480 --> 00:23:54,960
write a streaming application that pulls

751
00:23:54,159 --> 00:23:57,600
the data off

752
00:23:54,960 --> 00:23:59,200
kafka so then you get you get kind of

753
00:23:57,600 --> 00:24:00,480
that low latency use case

754
00:23:59,200 --> 00:24:02,080
and then all the data that arrives on

755
00:24:00,480 --> 00:24:03,760
kafka it then gets put onto the data

756
00:24:02,080 --> 00:24:04,320
lake but the latency there is usually

757
00:24:03,760 --> 00:24:07,200
minutes

758
00:24:04,320 --> 00:24:07,200
possibly an hour

759
00:24:07,760 --> 00:24:12,559
okay maybe one short question very short

760
00:24:17,279 --> 00:24:23,039
hello uh do you include the data

761
00:24:20,400 --> 00:24:25,360
catalogues in your process

762
00:24:23,039 --> 00:24:26,080
so the question is about how we catalog

763
00:24:25,360 --> 00:24:29,678
data

764
00:24:26,080 --> 00:24:32,799
yes yeah so that's a good question

765
00:24:29,679 --> 00:24:35,360
um so hive again is our

766
00:24:32,799 --> 00:24:36,960
basic data catalog because it has it has

767
00:24:35,360 --> 00:24:38,559
the schemas it has the

768
00:24:36,960 --> 00:24:40,159
everything's organized into databases

769
00:24:38,559 --> 00:24:43,200
and tables etc

770
00:24:40,159 --> 00:24:44,960
we also have views on top of this uh we

771
00:24:43,200 --> 00:24:46,000
use a product called elation which can

772
00:24:44,960 --> 00:24:47,600
basically spider

773
00:24:46,000 --> 00:24:49,679
the hive metastore and pull all that

774
00:24:47,600 --> 00:24:51,199
data in and we can then also register

775
00:24:49,679 --> 00:24:53,200
relational databases with that and get

776
00:24:51,200 --> 00:24:54,799
kind of one view over it

777
00:24:53,200 --> 00:24:56,240
there are a lot of other tools out there

778
00:24:54,799 --> 00:24:58,639
that do that they all have

779
00:24:56,240 --> 00:25:01,039
pros and cons and i haven't seen one

780
00:24:58,640 --> 00:25:03,120
that i massively happy with

781
00:25:01,039 --> 00:25:04,240
amazon have something called glue which

782
00:25:03,120 --> 00:25:05,678
does that for you but

783
00:25:04,240 --> 00:25:08,320
then there's the whole it's great but

784
00:25:05,679 --> 00:25:10,240
there's vendor lock-in so it's really

785
00:25:08,320 --> 00:25:11,678
it's not there's no one beautiful

786
00:25:10,240 --> 00:25:14,080
open-source solution for this at the

787
00:25:11,679 --> 00:25:15,679
moment that i'm aware of

788
00:25:14,080 --> 00:25:29,840
okay unfortunately we're out of time

789
00:25:15,679 --> 00:25:29,840
thank you very much adrian for this talk

