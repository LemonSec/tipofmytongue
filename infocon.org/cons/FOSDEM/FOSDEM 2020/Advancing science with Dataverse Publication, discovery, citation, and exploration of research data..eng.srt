1
00:00:06,160 --> 00:00:11,360
okay so we've got another lightning talk

2
00:00:08,240 --> 00:00:17,119
from philipp durbin

3
00:00:11,360 --> 00:00:18,480
on advancing science with dataverse

4
00:00:17,119 --> 00:00:20,320
uh thank you everyone for coming again

5
00:00:18,480 --> 00:00:20,960
my name is philip durbin i'm a software

6
00:00:20,320 --> 00:00:23,119
developer

7
00:00:20,960 --> 00:00:24,560
at harvard university this is a picture

8
00:00:23,119 --> 00:00:24,960
of our campus we're across the river

9
00:00:24,560 --> 00:00:27,038
from

10
00:00:24,960 --> 00:00:30,960
boston and the united states i'm here to

11
00:00:27,039 --> 00:00:34,399
tell you about dataverse

12
00:00:30,960 --> 00:00:36,719
so dataverse is a community of

13
00:00:34,399 --> 00:00:37,440
data enthusiasts and specifically

14
00:00:36,719 --> 00:00:40,719
research

15
00:00:37,440 --> 00:00:43,839
data so that means that we are

16
00:00:40,719 --> 00:00:44,640
scientists researchers and often we come

17
00:00:43,840 --> 00:00:47,280
from the

18
00:00:44,640 --> 00:00:48,559
academic library world so librarians and

19
00:00:47,280 --> 00:00:50,719
data curators

20
00:00:48,559 --> 00:00:51,599
data scientists software developers like

21
00:00:50,719 --> 00:00:53,600
myself

22
00:00:51,600 --> 00:00:55,920
these are some pictures from our annual

23
00:00:53,600 --> 00:00:58,719
gathering in cambridge massachusetts

24
00:00:55,920 --> 00:00:59,760
we have our sixth annual dataverse

25
00:00:58,719 --> 00:01:02,879
community meeting

26
00:00:59,760 --> 00:01:04,158
this june and everyone is welcome to

27
00:01:02,879 --> 00:01:07,199
come we always play

28
00:01:04,159 --> 00:01:07,199
what we call soccer

29
00:01:07,600 --> 00:01:11,759
and uh more importantly for fosdem

30
00:01:09,680 --> 00:01:13,119
dataverse is open source software we're

31
00:01:11,760 --> 00:01:15,439
apache licensed

32
00:01:13,119 --> 00:01:16,720
there are 52 installations of dataverse

33
00:01:15,439 --> 00:01:19,679
around the world

34
00:01:16,720 --> 00:01:21,200
across six continents it has been

35
00:01:19,680 --> 00:01:23,280
translated into

36
00:01:21,200 --> 00:01:25,200
ten languages and there's an opportunity

37
00:01:23,280 --> 00:01:27,119
to contribute there for sure

38
00:01:25,200 --> 00:01:28,720
here are some stats from github of our

39
00:01:27,119 --> 00:01:31,360
repository over

40
00:01:28,720 --> 00:01:31,920
100 contributors were written in java

41
00:01:31,360 --> 00:01:34,880
but

42
00:01:31,920 --> 00:01:35,680
i'd like to emphasize that we have apis

43
00:01:34,880 --> 00:01:37,199
and

44
00:01:35,680 --> 00:01:38,880
client libraries for a variety of

45
00:01:37,200 --> 00:01:42,079
languages such as

46
00:01:38,880 --> 00:01:43,280
javascript python r so if you would like

47
00:01:42,079 --> 00:01:44,320
to contribute to dataverse there are

48
00:01:43,280 --> 00:01:47,759
lots of ways

49
00:01:44,320 --> 00:01:50,158
to get involved and dataverse again is

50
00:01:47,759 --> 00:01:51,920
is for research data we would say that

51
00:01:50,159 --> 00:01:53,600
it's open source research data

52
00:01:51,920 --> 00:01:55,280
repository software

53
00:01:53,600 --> 00:01:57,039
but but what does that mean research

54
00:01:55,280 --> 00:01:59,200
data

55
00:01:57,040 --> 00:02:00,799
let me give you an example i saw this on

56
00:01:59,200 --> 00:02:03,040
twitter a few weeks ago and asked this

57
00:02:00,799 --> 00:02:03,920
scientist if i can put him in my slides

58
00:02:03,040 --> 00:02:06,399
his name is

59
00:02:03,920 --> 00:02:07,439
arvin p ravikumar he's working on

60
00:02:06,399 --> 00:02:09,199
climate change

61
00:02:07,439 --> 00:02:11,120
and you can see here that he is tweeting

62
00:02:09,199 --> 00:02:13,760
his heart out he is preparing

63
00:02:11,120 --> 00:02:14,959
a manuscript a paper for publication in

64
00:02:13,760 --> 00:02:18,160
a journal

65
00:02:14,959 --> 00:02:20,640
and he is explaining his argument

66
00:02:18,160 --> 00:02:21,200
he is making data visualizations of all

67
00:02:20,640 --> 00:02:24,879
of this

68
00:02:21,200 --> 00:02:27,839
and then he asks academic twitter

69
00:02:24,879 --> 00:02:28,640
if i have primary data what should i do

70
00:02:27,840 --> 00:02:30,720
with it

71
00:02:28,640 --> 00:02:32,559
so in the past he's saying he's always

72
00:02:30,720 --> 00:02:33,359
put it under what's called supplemental

73
00:02:32,560 --> 00:02:36,319
information

74
00:02:33,360 --> 00:02:38,879
in in the journal article but one of the

75
00:02:36,319 --> 00:02:42,640
reviewers of his paper is saying

76
00:02:38,879 --> 00:02:46,640
you should get a doi for your data

77
00:02:42,640 --> 00:02:48,399
now a doi is a digital object identifier

78
00:02:46,640 --> 00:02:49,920
it's a whole thing i was just in lisbon

79
00:02:48,400 --> 00:02:51,200
this week for a conference called

80
00:02:49,920 --> 00:02:54,000
pitapalooza

81
00:02:51,200 --> 00:02:56,079
pid being a persistent identifier but in

82
00:02:54,000 --> 00:02:58,159
the academic world this is how

83
00:02:56,080 --> 00:03:00,400
we cite each other's work this is how we

84
00:02:58,159 --> 00:03:03,440
acknowledge each other we build up

85
00:03:00,400 --> 00:03:04,800
a graph of this work is derived from

86
00:03:03,440 --> 00:03:06,000
this work we're all standing on the

87
00:03:04,800 --> 00:03:07,200
shoulders of giants

88
00:03:06,000 --> 00:03:09,360
and so with dataverse what we're trying

89
00:03:07,200 --> 00:03:12,640
to do is elevate the data set

90
00:03:09,360 --> 00:03:14,560
to be a first class research object

91
00:03:12,640 --> 00:03:16,319
so instead of just your papers think

92
00:03:14,560 --> 00:03:18,720
about a citation for your

93
00:03:16,319 --> 00:03:21,760
your data in the end i'm happy to say

94
00:03:18,720 --> 00:03:23,519
that that the scientist decided to

95
00:03:21,760 --> 00:03:26,480
put his data into harvard dataverse and

96
00:03:23,519 --> 00:03:29,200
then this is what that looks like

97
00:03:26,480 --> 00:03:30,399
so um harvard database and i have these

98
00:03:29,200 --> 00:03:32,640
pamphlets here

99
00:03:30,400 --> 00:03:34,799
is a little unique among the 50

100
00:03:32,640 --> 00:03:38,238
installation of dataverse in that

101
00:03:34,799 --> 00:03:40,400
we accept research data from around the

102
00:03:38,239 --> 00:03:43,120
world and will host it for free

103
00:03:40,400 --> 00:03:44,400
up to one terabyte so this is just an

104
00:03:43,120 --> 00:03:45,840
invitation to the crowd that if you

105
00:03:44,400 --> 00:03:46,720
yourself have research data and you

106
00:03:45,840 --> 00:03:48,640
don't know where to put it

107
00:03:46,720 --> 00:03:49,920
or you know someone who does please send

108
00:03:48,640 --> 00:03:50,958
them the harvard database and we'd be

109
00:03:49,920 --> 00:03:54,159
happy to

110
00:03:50,959 --> 00:03:55,760
host the data for them another thing i

111
00:03:54,159 --> 00:03:58,640
want to point out about this

112
00:03:55,760 --> 00:04:00,319
data set is that his raw data his

113
00:03:58,640 --> 00:04:03,279
primary data is

114
00:04:00,319 --> 00:04:05,200
only about half a megabyte in size and

115
00:04:03,280 --> 00:04:07,040
yet you can see how rich the data is

116
00:04:05,200 --> 00:04:08,159
he's exploring the data with data

117
00:04:07,040 --> 00:04:09,920
visualization he

118
00:04:08,159 --> 00:04:11,920
he obviously has a lot to say on twitter

119
00:04:09,920 --> 00:04:15,200
about his data we might call this the

120
00:04:11,920 --> 00:04:16,880
long tail of science if you work in say

121
00:04:15,200 --> 00:04:18,719
biochemistry you might have a natural

122
00:04:16,880 --> 00:04:21,120
place to put your data maybe you

123
00:04:18,720 --> 00:04:22,960
you put it in the protein databank for

124
00:04:21,120 --> 00:04:23,840
example but for a lot of science there

125
00:04:22,960 --> 00:04:25,440
is no place

126
00:04:23,840 --> 00:04:27,198
for their data so that's part of the

127
00:04:25,440 --> 00:04:29,360
need that harvard databurst

128
00:04:27,199 --> 00:04:30,479
and the databurst project as a whole is

129
00:04:29,360 --> 00:04:33,199
trying to meet

130
00:04:30,479 --> 00:04:34,320
that we want to welcome all scientists

131
00:04:33,199 --> 00:04:37,680
from all disciplines

132
00:04:34,320 --> 00:04:37,680
to publish their data

133
00:04:38,800 --> 00:04:42,400
i want to talk a little bit about

134
00:04:39,919 --> 00:04:44,880
cultural change and

135
00:04:42,400 --> 00:04:45,840
try to explain that people like the

136
00:04:44,880 --> 00:04:48,479
scientists we saw

137
00:04:45,840 --> 00:04:49,440
are very similar to open source

138
00:04:48,479 --> 00:04:52,479
developers

139
00:04:49,440 --> 00:04:56,160
you can see that we like to share code

140
00:04:52,479 --> 00:04:57,520
and and uh

141
00:04:56,160 --> 00:04:59,520
we're seeing that researchers are

142
00:04:57,520 --> 00:05:00,719
willing to share data but this is a

143
00:04:59,520 --> 00:05:04,000
relatively new

144
00:05:00,720 --> 00:05:06,560
thing and this uh pyramid is a

145
00:05:04,000 --> 00:05:07,759
diagram that's based on a tweet storm by

146
00:05:06,560 --> 00:05:10,320
brian nosek

147
00:05:07,759 --> 00:05:11,280
from the center for open science and

148
00:05:10,320 --> 00:05:13,280
what it means to me

149
00:05:11,280 --> 00:05:15,440
is that first we had to build the

150
00:05:13,280 --> 00:05:16,479
ability to even share data at all that's

151
00:05:15,440 --> 00:05:18,240
at the bottom

152
00:05:16,479 --> 00:05:19,919
and then projects like dataverse have

153
00:05:18,240 --> 00:05:22,479
come along to

154
00:05:19,919 --> 00:05:24,320
hopefully improve the user experience

155
00:05:22,479 --> 00:05:27,758
for sharing data i've

156
00:05:24,320 --> 00:05:29,840
stopped by the open source design table

157
00:05:27,759 --> 00:05:32,160
this morning and efforts like that are

158
00:05:29,840 --> 00:05:33,359
great right like let's not just have

159
00:05:32,160 --> 00:05:35,840
open source software let's make the

160
00:05:33,360 --> 00:05:38,960
software usable let's make it

161
00:05:35,840 --> 00:05:40,239
painless to share data and then

162
00:05:38,960 --> 00:05:42,560
as we go up the pyramid what we're

163
00:05:40,240 --> 00:05:45,120
seeing now is some cultural change

164
00:05:42,560 --> 00:05:46,560
so again the reviewer of the paper is

165
00:05:45,120 --> 00:05:49,199
the one who said hey

166
00:05:46,560 --> 00:05:49,680
you should make your data set a first

167
00:05:49,199 --> 00:05:52,320
class

168
00:05:49,680 --> 00:05:53,280
citable scholarly object so that's great

169
00:05:52,320 --> 00:05:55,120
that's exactly

170
00:05:53,280 --> 00:05:57,679
what we've been trying to do for years

171
00:05:55,120 --> 00:05:59,840
is is get there where it becomes

172
00:05:57,680 --> 00:06:02,000
a good scientific practice to share your

173
00:05:59,840 --> 00:06:04,400
data with the world

174
00:06:02,000 --> 00:06:06,160
and increasingly i will say that funding

175
00:06:04,400 --> 00:06:07,280
these days often requires you to share

176
00:06:06,160 --> 00:06:09,520
your data

177
00:06:07,280 --> 00:06:10,400
so university libraries and other places

178
00:06:09,520 --> 00:06:14,000
are

179
00:06:10,400 --> 00:06:15,758
have a reason to install research data

180
00:06:14,000 --> 00:06:16,479
repository software like dataverse so

181
00:06:15,759 --> 00:06:18,479
that they can

182
00:06:16,479 --> 00:06:21,039
have a place for their community to

183
00:06:18,479 --> 00:06:23,599
share their data

184
00:06:21,039 --> 00:06:24,240
also i'll mention that on the journal

185
00:06:23,600 --> 00:06:25,680
side

186
00:06:24,240 --> 00:06:27,840
the places that are publishing these

187
00:06:25,680 --> 00:06:29,759
academic papers they are now giving

188
00:06:27,840 --> 00:06:31,919
incentives to researchers to share their

189
00:06:29,759 --> 00:06:34,880
data they're trying to also

190
00:06:31,919 --> 00:06:37,440
move research towards more openness and

191
00:06:34,880 --> 00:06:39,759
more sharing of data

192
00:06:37,440 --> 00:06:40,719
all right now i'd like to step you

193
00:06:39,759 --> 00:06:43,600
through quickly

194
00:06:40,720 --> 00:06:45,919
this concept that we have in my world of

195
00:06:43,600 --> 00:06:47,440
what we call the fair data principles

196
00:06:45,919 --> 00:06:49,120
fair is an acronym this stands for

197
00:06:47,440 --> 00:06:51,680
findable accessible

198
00:06:49,120 --> 00:06:53,120
interoperable and reusable let's start

199
00:06:51,680 --> 00:06:56,560
with findable

200
00:06:53,120 --> 00:06:58,400
part of the idea with putting data in a

201
00:06:56,560 --> 00:07:00,160
repository like dataverse is that other

202
00:06:58,400 --> 00:07:02,799
scientists can find your work

203
00:07:00,160 --> 00:07:03,680
and reuse your work so when you publish

204
00:07:02,800 --> 00:07:05,919
a data set

205
00:07:03,680 --> 00:07:07,520
in dataverse we send metadata that's

206
00:07:05,919 --> 00:07:10,799
data about data

207
00:07:07,520 --> 00:07:13,440
across the wire to a site called

208
00:07:10,800 --> 00:07:14,639
a non-profit they're called datasite and

209
00:07:13,440 --> 00:07:18,400
this is an aggregator

210
00:07:14,639 --> 00:07:20,720
of all sorts of scientific data

211
00:07:18,400 --> 00:07:21,520
a new player on the scene is google they

212
00:07:20,720 --> 00:07:23,759
have

213
00:07:21,520 --> 00:07:24,880
just brought out of beta last week or

214
00:07:23,759 --> 00:07:27,520
the week before

215
00:07:24,880 --> 00:07:28,240
a tool called data google data set

216
00:07:27,520 --> 00:07:29,599
search

217
00:07:28,240 --> 00:07:31,440
and so we've been working closely with

218
00:07:29,599 --> 00:07:33,280
them and putting all of the right

219
00:07:31,440 --> 00:07:34,000
technology in place so they can easily

220
00:07:33,280 --> 00:07:36,719
crawl

221
00:07:34,000 --> 00:07:38,319
installations of dataverse and find the

222
00:07:36,720 --> 00:07:39,840
title the author the description and

223
00:07:38,319 --> 00:07:42,080
make them all available

224
00:07:39,840 --> 00:07:43,039
in their new tool and this third one is

225
00:07:42,080 --> 00:07:44,639
from a project called

226
00:07:43,039 --> 00:07:46,240
share it's another effort within

227
00:07:44,639 --> 00:07:49,520
academia to make

228
00:07:46,240 --> 00:07:50,560
data more findable in this case they use

229
00:07:49,520 --> 00:07:53,359
the dataverse

230
00:07:50,560 --> 00:07:55,759
search api to pull in the latest records

231
00:07:53,360 --> 00:07:58,240
all the time

232
00:07:55,759 --> 00:07:59,599
these are a couple screenshots of what

233
00:07:58,240 --> 00:08:00,639
these tools might look like when you're

234
00:07:59,599 --> 00:08:03,520
searching for data

235
00:08:00,639 --> 00:08:04,720
the thing i like about these tools is

236
00:08:03,520 --> 00:08:06,719
that they expose

237
00:08:04,720 --> 00:08:08,160
the number of citations to the data and

238
00:08:06,720 --> 00:08:10,240
again the citations are sort of the

239
00:08:08,160 --> 00:08:12,400
currency of the academic world so

240
00:08:10,240 --> 00:08:14,080
here's a data set with 13 citations that

241
00:08:12,400 --> 00:08:16,239
means that 13 papers

242
00:08:14,080 --> 00:08:17,758
are making use of that data reusing that

243
00:08:16,240 --> 00:08:19,919
data so we're really happy

244
00:08:17,759 --> 00:08:21,120
to see that the data is being reused

245
00:08:19,919 --> 00:08:24,159
we're hoping that this

246
00:08:21,120 --> 00:08:27,599
advances science

247
00:08:24,160 --> 00:08:29,840
the second part of fair is accessible

248
00:08:27,599 --> 00:08:31,199
uh it's one thing just to throw an excel

249
00:08:29,840 --> 00:08:32,880
file up on an ftp

250
00:08:31,199 --> 00:08:35,360
server but with dataverse what we're

251
00:08:32,880 --> 00:08:36,240
trying to do is give researchers tools

252
00:08:35,360 --> 00:08:38,839
to

253
00:08:36,240 --> 00:08:40,159
explain exactly what their data is about

254
00:08:38,839 --> 00:08:43,279
so

255
00:08:40,159 --> 00:08:45,120
we support what we would say is a rich

256
00:08:43,279 --> 00:08:46,800
set of metadata fields and

257
00:08:45,120 --> 00:08:48,160
data versus customizable to the

258
00:08:46,800 --> 00:08:49,519
scientific discipline

259
00:08:48,160 --> 00:08:50,880
so for example there's a group at

260
00:08:49,519 --> 00:08:52,480
harvard medical school that has

261
00:08:50,880 --> 00:08:55,439
structural biology data

262
00:08:52,480 --> 00:08:57,920
so they create their own metadata fields

263
00:08:55,440 --> 00:08:59,680
that matter to them

264
00:08:57,920 --> 00:09:01,439
this for the humans to read on the one

265
00:08:59,680 --> 00:09:03,519
side but then we also

266
00:09:01,440 --> 00:09:04,880
support lots and lots of standards for

267
00:09:03,519 --> 00:09:06,000
interoperating between other data

268
00:09:04,880 --> 00:09:09,760
repositories

269
00:09:06,000 --> 00:09:12,959
so xml json in a variety of formats

270
00:09:09,760 --> 00:09:16,240
google dataset search for example uses a

271
00:09:12,959 --> 00:09:19,518
standard called schema.org data

272
00:09:16,240 --> 00:09:22,480
jsonld schema.org the data set

273
00:09:19,519 --> 00:09:24,720
part of that and then uh older standards

274
00:09:22,480 --> 00:09:27,279
like dublin core are in xml

275
00:09:24,720 --> 00:09:29,279
there's a whole variety of that to make

276
00:09:27,279 --> 00:09:31,360
data accessible

277
00:09:29,279 --> 00:09:32,800
uh for for interoperable the third

278
00:09:31,360 --> 00:09:33,680
letter in fair i wanted to mention that

279
00:09:32,800 --> 00:09:36,000
we

280
00:09:33,680 --> 00:09:37,279
the dataverse is not trying to be all

281
00:09:36,000 --> 00:09:38,959
things to all people we're trying to

282
00:09:37,279 --> 00:09:40,800
focus really on the research data but

283
00:09:38,959 --> 00:09:41,518
we're very happy to interoperate and

284
00:09:40,800 --> 00:09:43,920
integrate

285
00:09:41,519 --> 00:09:46,240
with other platforms so if a researcher

286
00:09:43,920 --> 00:09:48,880
is happy to use dropbox for the early

287
00:09:46,240 --> 00:09:50,000
work in their their study that's totally

288
00:09:48,880 --> 00:09:52,320
fine they can just get it into

289
00:09:50,000 --> 00:09:54,320
data first later or other complementary

290
00:09:52,320 --> 00:09:57,760
tools like open science framework

291
00:09:54,320 --> 00:10:00,720
rspace it's like electronic lab notebook

292
00:09:57,760 --> 00:10:03,439
open journal systems and then once the

293
00:10:00,720 --> 00:10:06,000
data has been published

294
00:10:03,440 --> 00:10:07,600
we are happy to integrate with uh or

295
00:10:06,000 --> 00:10:09,279
even before publication i would say

296
00:10:07,600 --> 00:10:10,720
that we're happy to integrate with

297
00:10:09,279 --> 00:10:14,000
computational environments

298
00:10:10,720 --> 00:10:14,800
so uh jupiter notebooks for example can

299
00:10:14,000 --> 00:10:17,200
be

300
00:10:14,800 --> 00:10:19,439
uh opened up in binder you just punch in

301
00:10:17,200 --> 00:10:21,440
the doi of the data set from dataverse

302
00:10:19,440 --> 00:10:22,720
and there's a group called wholetail

303
00:10:21,440 --> 00:10:24,959
that

304
00:10:22,720 --> 00:10:26,399
is all about reproducibility you may

305
00:10:24,959 --> 00:10:27,119
have heard that in science there is what

306
00:10:26,399 --> 00:10:29,120
we call this

307
00:10:27,120 --> 00:10:30,399
reproducibility crisis and i'm not

308
00:10:29,120 --> 00:10:31,680
saying we're going to solve that problem

309
00:10:30,399 --> 00:10:33,839
but we're trying to make an effort

310
00:10:31,680 --> 00:10:36,839
toward that

311
00:10:33,839 --> 00:10:40,079
reusable um and back to that

312
00:10:36,839 --> 00:10:42,160
reproducibility problem

313
00:10:40,079 --> 00:10:43,359
one thing we're seeing is that journals

314
00:10:42,160 --> 00:10:45,279
are increasingly

315
00:10:43,360 --> 00:10:46,880
requiring the publication of data in

316
00:10:45,279 --> 00:10:49,120
order for the paper to be published

317
00:10:46,880 --> 00:10:51,279
we think this is a very uh positive

318
00:10:49,120 --> 00:10:52,480
thing it's a bit of a big stick to hit

319
00:10:51,279 --> 00:10:54,880
researchers with to say

320
00:10:52,480 --> 00:10:55,519
we're sorry you can't publish your paper

321
00:10:54,880 --> 00:10:57,680
until

322
00:10:55,519 --> 00:10:59,040
you publish the data set but for

323
00:10:57,680 --> 00:11:00,959
scientific reproducibility

324
00:10:59,040 --> 00:11:02,640
it's it's wonder it's a wonderful thing

325
00:11:00,959 --> 00:11:04,160
here's an example of this the american

326
00:11:02,640 --> 00:11:06,480
journal of political science

327
00:11:04,160 --> 00:11:07,760
has a replication policy that says you

328
00:11:06,480 --> 00:11:10,959
have to give us the data

329
00:11:07,760 --> 00:11:12,720
and also the code and then there are

330
00:11:10,959 --> 00:11:14,000
a group of analysts at the odom

331
00:11:12,720 --> 00:11:16,480
institute at the university

332
00:11:14,000 --> 00:11:18,480
of north carolina that will make sure

333
00:11:16,480 --> 00:11:21,680
the code executes make sure that

334
00:11:18,480 --> 00:11:23,519
the plots in the paper can be reproduced

335
00:11:21,680 --> 00:11:24,800
and then they give it the stamp of

336
00:11:23,519 --> 00:11:26,720
approval

337
00:11:24,800 --> 00:11:28,800
and then the data set can be published

338
00:11:26,720 --> 00:11:31,200
and then the paper can be published

339
00:11:28,800 --> 00:11:32,399
so that's part of the story of

340
00:11:31,200 --> 00:11:34,480
reproducibility

341
00:11:32,399 --> 00:11:35,920
the problem is that these poor analysts

342
00:11:34,480 --> 00:11:37,360
are downloading all kinds of software

343
00:11:35,920 --> 00:11:38,399
all the time through laptops trying to

344
00:11:37,360 --> 00:11:41,440
reproduce the work

345
00:11:38,399 --> 00:11:42,480
of random you know data sets all over

346
00:11:41,440 --> 00:11:45,279
the world

347
00:11:42,480 --> 00:11:45,920
uh what would what the next step for us

348
00:11:45,279 --> 00:11:48,720
is to

349
00:11:45,920 --> 00:11:49,680
partner with tools like code ocean again

350
00:11:48,720 --> 00:11:53,680
hotel

351
00:11:49,680 --> 00:11:57,120
renku and jupiter these are um

352
00:11:53,680 --> 00:11:59,120
reproducibility platforms so instead of

353
00:11:57,120 --> 00:12:01,600
that analyst trying to reproduce the

354
00:11:59,120 --> 00:12:02,639
results on their laptop along with a lot

355
00:12:01,600 --> 00:12:04,320
of other data sets

356
00:12:02,639 --> 00:12:06,000
what if they can click a button and have

357
00:12:04,320 --> 00:12:08,160
a docker container spun up

358
00:12:06,000 --> 00:12:09,680
that has all the the bits that they need

359
00:12:08,160 --> 00:12:13,040
to reproduce that work

360
00:12:09,680 --> 00:12:15,279
so again doi's for papers doi is for

361
00:12:13,040 --> 00:12:17,760
data sets and maybe in the future doi is

362
00:12:15,279 --> 00:12:20,240
for what we would call like an execution

363
00:12:17,760 --> 00:12:21,839
environment so a docker file that docker

364
00:12:20,240 --> 00:12:22,720
image that's sort of where our thinking

365
00:12:21,839 --> 00:12:26,639
is going

366
00:12:22,720 --> 00:12:28,079
in the future these fair data principles

367
00:12:26,639 --> 00:12:30,160
are in an academic paper that you're

368
00:12:28,079 --> 00:12:30,638
welcome to check out and i'd also point

369
00:12:30,160 --> 00:12:34,079
you to

370
00:12:30,639 --> 00:12:34,720
a recent uh talk by merce cross who's

371
00:12:34,079 --> 00:12:36,880
been leading

372
00:12:34,720 --> 00:12:38,320
the data verse project for over 10 years

373
00:12:36,880 --> 00:12:41,760
we had a event

374
00:12:38,320 --> 00:12:43,680
in tromso norway just a couple weeks ago

375
00:12:41,760 --> 00:12:45,600
where there were 19 countries

376
00:12:43,680 --> 00:12:46,479
represented and she gave a talk

377
00:12:45,600 --> 00:12:48,880
explaining

378
00:12:46,480 --> 00:12:49,839
this fair data concept from the

379
00:12:48,880 --> 00:12:52,320
dataverse

380
00:12:49,839 --> 00:12:54,959
perspective and i'd like to note that uh

381
00:12:52,320 --> 00:12:57,680
when i landed here on friday i was

382
00:12:54,959 --> 00:12:59,119
invited by yusuf and others from the

383
00:12:57,680 --> 00:13:01,599
state archives of belgium

384
00:12:59,120 --> 00:13:03,440
and we had a nice little meeting um

385
00:13:01,600 --> 00:13:05,040
representatives from six countries

386
00:13:03,440 --> 00:13:06,720
all running dataverse and so thanks

387
00:13:05,040 --> 00:13:07,839
again for that it was great to see

388
00:13:06,720 --> 00:13:10,320
friendly faces upon

389
00:13:07,839 --> 00:13:11,360
arriving in brussels i have a little bit

390
00:13:10,320 --> 00:13:14,800
of bonus content

391
00:13:11,360 --> 00:13:17,839
two minutes left um this is sort of

392
00:13:14,800 --> 00:13:21,279
a thing that i believe strongly in that

393
00:13:17,839 --> 00:13:23,839
that in the past open source has been

394
00:13:21,279 --> 00:13:25,040
very open in its communication that you

395
00:13:23,839 --> 00:13:26,079
know whether we're talking about the

396
00:13:25,040 --> 00:13:29,519
announcement of

397
00:13:26,079 --> 00:13:31,359
the of the gnu project or uh

398
00:13:29,519 --> 00:13:33,440
the announcement of linux and discussion

399
00:13:31,360 --> 00:13:34,320
about open source and free software

400
00:13:33,440 --> 00:13:36,560
throughout

401
00:13:34,320 --> 00:13:38,560
time we can still go back and look at

402
00:13:36,560 --> 00:13:39,839
that communication today

403
00:13:38,560 --> 00:13:41,599
and what i see more and more is that

404
00:13:39,839 --> 00:13:44,639
lots of projects are using slack

405
00:13:41,600 --> 00:13:46,639
which is fine we use slack to say things

406
00:13:44,639 --> 00:13:48,320
like hey i brought in donuts come on by

407
00:13:46,639 --> 00:13:50,639
you know it's great for that but when

408
00:13:48,320 --> 00:13:53,440
you're thinking about your communities

409
00:13:50,639 --> 00:13:54,320
and you're making decisions about your

410
00:13:53,440 --> 00:13:56,000
projects

411
00:13:54,320 --> 00:13:57,839
and the direction you're going i just

412
00:13:56,000 --> 00:14:00,800
like to encourage everyone to

413
00:13:57,839 --> 00:14:01,680
to continue to hold to our tradition of

414
00:14:00,800 --> 00:14:04,000
openness

415
00:14:01,680 --> 00:14:05,120
and so if there can be an acronym called

416
00:14:04,000 --> 00:14:06,560
fair

417
00:14:05,120 --> 00:14:08,399
about data i thought i could make an

418
00:14:06,560 --> 00:14:09,439
acronym called sloppy about

419
00:14:08,399 --> 00:14:11,920
communication

420
00:14:09,440 --> 00:14:13,680
so sloppy stands for searchable linkable

421
00:14:11,920 --> 00:14:15,680
open public indexed

422
00:14:13,680 --> 00:14:17,120
so i wrote a little blog post with more

423
00:14:15,680 --> 00:14:20,719
about what sloppy is

424
00:14:17,120 --> 00:14:22,079
that's that last thing is um

425
00:14:20,720 --> 00:14:24,000
there's a group called chaos that's

426
00:14:22,079 --> 00:14:27,040
around there was chaos con on

427
00:14:24,000 --> 00:14:29,600
friday and there's a there's a

428
00:14:27,040 --> 00:14:31,599
project at harvard that is called the

429
00:14:29,600 --> 00:14:34,800
open source software health

430
00:14:31,600 --> 00:14:36,480
index project the idea here is that

431
00:14:34,800 --> 00:14:38,399
something developers like us naturally

432
00:14:36,480 --> 00:14:39,120
do all the time is compare two projects

433
00:14:38,399 --> 00:14:40,560
and say well

434
00:14:39,120 --> 00:14:42,959
which one is healthy or which is the

435
00:14:40,560 --> 00:14:45,518
horse to bet on and uh

436
00:14:42,959 --> 00:14:47,359
what we're trying to do is get towards a

437
00:14:45,519 --> 00:14:49,360
way to quantify some of this

438
00:14:47,360 --> 00:14:50,639
so chaos has built this awesome tool

439
00:14:49,360 --> 00:14:53,760
called auger

440
00:14:50,639 --> 00:14:56,639
that will collect data about uh

441
00:14:53,760 --> 00:14:58,000
projects from github repos and and we're

442
00:14:56,639 --> 00:14:59,680
starting to mine that data

443
00:14:58,000 --> 00:15:02,240
a little bit and i just want to put this

444
00:14:59,680 --> 00:15:03,920
project on your on your radar

445
00:15:02,240 --> 00:15:05,199
and uh with that i just wanted to say

446
00:15:03,920 --> 00:15:06,479
thank you i don't think we have time for

447
00:15:05,199 --> 00:15:07,920
questions unfortunately but

448
00:15:06,480 --> 00:15:09,760
please find me online we have a chat

449
00:15:07,920 --> 00:15:12,319
room chat.dataverse.org

450
00:15:09,760 --> 00:15:25,920
here's my email my twitter and thank you

451
00:15:12,320 --> 00:15:25,920
very much for your attention

