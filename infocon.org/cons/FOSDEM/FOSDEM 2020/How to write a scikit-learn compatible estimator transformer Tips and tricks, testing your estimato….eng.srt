1
00:00:08,480 --> 00:00:13,840
okay thank you everyone

2
00:00:10,559 --> 00:00:14,959
next talk aderin is going to tell us

3
00:00:13,840 --> 00:00:17,920
about

4
00:00:14,960 --> 00:00:20,000
psychic custom transformers all right

5
00:00:17,920 --> 00:00:22,550
sorry it's not mike

6
00:00:20,000 --> 00:00:22,870
okay thank you

7
00:00:22,550 --> 00:00:28,800
[Music]

8
00:00:22,870 --> 00:00:31,519
[Applause]

9
00:00:28,800 --> 00:00:32,320
hello everybody um i'm adrian i work at

10
00:00:31,519 --> 00:00:34,640
anaconda

11
00:00:32,320 --> 00:00:36,239
and um i want to cycle land maintainers

12
00:00:34,640 --> 00:00:38,800
um

13
00:00:36,239 --> 00:00:40,559
today i'm gonna talk about how to write

14
00:00:38,800 --> 00:00:43,040
your own estimator um

15
00:00:40,559 --> 00:00:44,000
before i start i need to know how many

16
00:00:43,040 --> 00:00:47,280
people

17
00:00:44,000 --> 00:00:49,680
have used scikit-learn

18
00:00:47,280 --> 00:00:50,800
okay cool so i don't need to focus too

19
00:00:49,680 --> 00:00:54,000
much on the background

20
00:00:50,800 --> 00:00:55,680
it's good for the rest of us who are not

21
00:00:54,000 --> 00:00:57,440
familiar with it it's a statistical

22
00:00:55,680 --> 00:00:59,359
machine learning library it doesn't that

23
00:00:57,440 --> 00:01:02,718
means that it does cover all the

24
00:00:59,359 --> 00:01:04,400
old-school stuff the support vector

25
00:01:02,719 --> 00:01:05,280
machines random forest k-means and

26
00:01:04,400 --> 00:01:07,119
whatnot

27
00:01:05,280 --> 00:01:08,640
it does not include the deep learning

28
00:01:07,119 --> 00:01:12,479
ones it doesn't cover

29
00:01:08,640 --> 00:01:14,320
gpu acceleration um just not in this

30
00:01:12,479 --> 00:01:16,720
scope

31
00:01:14,320 --> 00:01:17,600
that said um what are the when we look

32
00:01:16,720 --> 00:01:19,920
at the library

33
00:01:17,600 --> 00:01:22,000
wanna what are the main or some of the

34
00:01:19,920 --> 00:01:23,680
main components of the library before we

35
00:01:22,000 --> 00:01:25,200
start writing our own estimator we need

36
00:01:23,680 --> 00:01:27,439
to understand that

37
00:01:25,200 --> 00:01:28,640
we have estimators the estimators are

38
00:01:27,439 --> 00:01:30,639
either transformers

39
00:01:28,640 --> 00:01:33,119
in which case they take some data they

40
00:01:30,640 --> 00:01:35,280
transform that they spit it out

41
00:01:33,119 --> 00:01:38,479
or their predictors they are classifiers

42
00:01:35,280 --> 00:01:38,479
or regressors

43
00:01:38,960 --> 00:01:42,798
then we have scorers these models we

44
00:01:41,360 --> 00:01:44,320
need to know how they perform

45
00:01:42,799 --> 00:01:45,759
uh so we have different scores to

46
00:01:44,320 --> 00:01:46,960
measure their performance in different

47
00:01:45,759 --> 00:01:49,360
ways

48
00:01:46,960 --> 00:01:51,039
then we have meta estimators the meta

49
00:01:49,360 --> 00:01:52,960
estimators take

50
00:01:51,040 --> 00:01:54,880
an estimator and they do something with

51
00:01:52,960 --> 00:01:56,640
it um

52
00:01:54,880 --> 00:01:58,320
two two of them two of the important

53
00:01:56,640 --> 00:02:01,360
ones and relevant ones to this talk

54
00:01:58,320 --> 00:02:04,479
are a pipeline which allows you

55
00:02:01,360 --> 00:02:04,960
to have a set of transformers and then

56
00:02:04,479 --> 00:02:06,880
if you

57
00:02:04,960 --> 00:02:08,079
will at the end a predictor you have

58
00:02:06,880 --> 00:02:09,280
your classifier at the end

59
00:02:08,080 --> 00:02:11,760
and then you have your transformers

60
00:02:09,280 --> 00:02:14,160
before that and then it lets you

61
00:02:11,760 --> 00:02:16,000
treat that whole pipeline as one single

62
00:02:14,160 --> 00:02:18,480
estimator

63
00:02:16,000 --> 00:02:19,599
and then you have grid stitch which is

64
00:02:18,480 --> 00:02:23,440
easier to explain

65
00:02:19,599 --> 00:02:25,519
with a little example the usual pipeline

66
00:02:23,440 --> 00:02:27,760
we have our data we need to we need to

67
00:02:25,520 --> 00:02:30,239
pre-process and prepare the data

68
00:02:27,760 --> 00:02:31,840
uh to give that to our classifier in the

69
00:02:30,239 --> 00:02:33,760
case of a classification

70
00:02:31,840 --> 00:02:34,879
so in this case i have two steps to

71
00:02:33,760 --> 00:02:38,000
prepare the data

72
00:02:34,879 --> 00:02:41,280
and then i feed that uh to an

73
00:02:38,000 --> 00:02:42,959
sgd classifier but each of these steps

74
00:02:41,280 --> 00:02:44,640
usually have some hyper parameters that

75
00:02:42,959 --> 00:02:47,519
you can tune if

76
00:02:44,640 --> 00:02:48,238
it if it's a transformer that um if it

77
00:02:47,519 --> 00:02:51,040
if it's doing

78
00:02:48,239 --> 00:02:52,959
um principal component analysis like how

79
00:02:51,040 --> 00:02:56,319
many components do you want to return

80
00:02:52,959 --> 00:02:59,040
that number are you doing k-means that k

81
00:02:56,319 --> 00:03:01,280
if you're uh if you're regularizing what

82
00:02:59,040 --> 00:03:03,840
is the regularization parameter um

83
00:03:01,280 --> 00:03:04,480
how do you do that that's your parameter

84
00:03:03,840 --> 00:03:06,879
set

85
00:03:04,480 --> 00:03:07,518
and then that set defines your your

86
00:03:06,879 --> 00:03:09,920
space

87
00:03:07,519 --> 00:03:10,560
and now you want to search in that space

88
00:03:09,920 --> 00:03:14,720
and find

89
00:03:10,560 --> 00:03:18,239
the best point for your data

90
00:03:14,720 --> 00:03:19,840
um glitters does that for you you pass

91
00:03:18,239 --> 00:03:21,680
it your estimator and your parameter

92
00:03:19,840 --> 00:03:23,920
space and it does this edge

93
00:03:21,680 --> 00:03:25,440
okay if you want to use a different

94
00:03:23,920 --> 00:03:26,798
score than the default one you can also

95
00:03:25,440 --> 00:03:28,640
pass that

96
00:03:26,799 --> 00:03:31,040
so with all that flexibility why why

97
00:03:28,640 --> 00:03:31,679
would we want to write our own estimator

98
00:03:31,040 --> 00:03:34,400
um

99
00:03:31,680 --> 00:03:35,840
there are a couple of cases one is that

100
00:03:34,400 --> 00:03:38,720
scikit-learn doesn't

101
00:03:35,840 --> 00:03:40,319
have all the algorithms out there it

102
00:03:38,720 --> 00:03:42,560
does have the classical ones

103
00:03:40,319 --> 00:03:43,679
but it's not really possible for us to

104
00:03:42,560 --> 00:03:45,680
include everything

105
00:03:43,680 --> 00:03:47,680
so if you if if you fancy a new

106
00:03:45,680 --> 00:03:50,000
algorithm it's probably not there

107
00:03:47,680 --> 00:03:51,519
or if you are a researcher who would

108
00:03:50,000 --> 00:03:53,120
like to implement their own

109
00:03:51,519 --> 00:03:54,720
and work on their own method you

110
00:03:53,120 --> 00:03:56,959
probably want to write your own

111
00:03:54,720 --> 00:03:58,400
and then see how it works um in

112
00:03:56,959 --> 00:04:00,080
combination with the other methods and

113
00:03:58,400 --> 00:04:02,159
transformers out there

114
00:04:00,080 --> 00:04:04,000
or my favorite example is if you're

115
00:04:02,159 --> 00:04:05,519
doing ethics um doing ethics and like

116
00:04:04,000 --> 00:04:07,120
virus mitigation and detection are not

117
00:04:05,519 --> 00:04:09,439
in the scope of psychic land

118
00:04:07,120 --> 00:04:10,959
um so if you if you want to work on that

119
00:04:09,439 --> 00:04:13,120
then you would have to write your own

120
00:04:10,959 --> 00:04:16,639
cycle and compatible ones and like

121
00:04:13,120 --> 00:04:17,918
mitigate your bias we also don't include

122
00:04:16,639 --> 00:04:20,400
things that are

123
00:04:17,918 --> 00:04:22,079
extremely specific to certain use cases

124
00:04:20,399 --> 00:04:23,198
if you need to do something that applies

125
00:04:22,079 --> 00:04:25,040
only to your data

126
00:04:23,199 --> 00:04:27,440
you probably need to write that and it's

127
00:04:25,040 --> 00:04:29,280
not going to be included in the library

128
00:04:27,440 --> 00:04:30,880
um another use case is writing meta

129
00:04:29,280 --> 00:04:33,198
estimators if you want to do

130
00:04:30,880 --> 00:04:34,719
something before or after every time you

131
00:04:33,199 --> 00:04:36,320
call an estimator you can easily write a

132
00:04:34,720 --> 00:04:37,199
method estimator wrap around your

133
00:04:36,320 --> 00:04:40,840
estimators

134
00:04:37,199 --> 00:04:42,160
and then do logging or auditing or

135
00:04:40,840 --> 00:04:43,840
whatnot

136
00:04:42,160 --> 00:04:45,280
so what's the basic api what does it

137
00:04:43,840 --> 00:04:47,919
look like um

138
00:04:45,280 --> 00:04:48,559
estimators um expose fit to train on the

139
00:04:47,919 --> 00:04:50,000
data

140
00:04:48,560 --> 00:04:51,840
predict if they're doing classification

141
00:04:50,000 --> 00:04:54,800
or regression transform

142
00:04:51,840 --> 00:04:56,159
if they're a transformer and score if

143
00:04:54,800 --> 00:05:00,080
they're a predictor you need to know

144
00:04:56,160 --> 00:05:03,039
how they perform when i look at

145
00:05:00,080 --> 00:05:04,479
people's people's codes trying to write

146
00:05:03,039 --> 00:05:07,039
their own estimators it

147
00:05:04,479 --> 00:05:08,719
it looks as if they watched this talk or

148
00:05:07,039 --> 00:05:09,199
equivalent of this talk and they stopped

149
00:05:08,720 --> 00:05:13,360
here

150
00:05:09,199 --> 00:05:17,039
so please don't um

151
00:05:13,360 --> 00:05:19,039
so if if i want to write uh this this is

152
00:05:17,039 --> 00:05:20,719
like this this estimator is not really

153
00:05:19,039 --> 00:05:24,080
doing anything fancy just

154
00:05:20,720 --> 00:05:26,160
it's just to show how you could write it

155
00:05:24,080 --> 00:05:27,280
what are the components that you need

156
00:05:26,160 --> 00:05:30,560
the main one

157
00:05:27,280 --> 00:05:33,280
or okay before that one thing it is it

158
00:05:30,560 --> 00:05:36,000
is a it is a very opinionated api

159
00:05:33,280 --> 00:05:38,000
and it has its own design i know

160
00:05:36,000 --> 00:05:39,600
probably half of us in this room

161
00:05:38,000 --> 00:05:41,280
may not agree with that design but

162
00:05:39,600 --> 00:05:44,560
that's what it is so that's not

163
00:05:41,280 --> 00:05:46,799
the discussion we can talk about later

164
00:05:44,560 --> 00:05:48,320
we do composition that means that if

165
00:05:46,800 --> 00:05:51,759
you're writing an estimator

166
00:05:48,320 --> 00:05:53,039
you are you have to have base estimator

167
00:05:51,759 --> 00:05:54,880
if you're writing a classifier is

168
00:05:53,039 --> 00:05:56,880
classified mixing

169
00:05:54,880 --> 00:05:58,400
and then depending on what you do you

170
00:05:56,880 --> 00:05:58,960
would need different mixings regressor

171
00:05:58,400 --> 00:06:00,960
mixing

172
00:05:58,960 --> 00:06:02,239
uh meta estimator mixing and a bunch of

173
00:06:00,960 --> 00:06:04,400
other ones

174
00:06:02,240 --> 00:06:06,080
we have a bunch of really nice methods

175
00:06:04,400 --> 00:06:07,520
to do input validation

176
00:06:06,080 --> 00:06:09,120
you really don't need to write your own

177
00:06:07,520 --> 00:06:09,919
input validation you need to you don't

178
00:06:09,120 --> 00:06:12,000
need to check if

179
00:06:09,919 --> 00:06:14,318
if the input is a non-parallel or not um

180
00:06:12,000 --> 00:06:16,479
all of that is there

181
00:06:14,319 --> 00:06:17,600
and then my classifier is going to wrap

182
00:06:16,479 --> 00:06:21,520
around on svc

183
00:06:17,600 --> 00:06:24,639
you know in a very poor way

184
00:06:21,520 --> 00:06:25,198
then so things to note here uh i have my

185
00:06:24,639 --> 00:06:27,680
init

186
00:06:25,199 --> 00:06:28,800
and in the in it i i accept my met my

187
00:06:27,680 --> 00:06:30,960
hyper parameters

188
00:06:28,800 --> 00:06:33,360
and the only thing i do is that i store

189
00:06:30,960 --> 00:06:34,080
them i store them in public attributes

190
00:06:33,360 --> 00:06:37,199
and i do

191
00:06:34,080 --> 00:06:38,080
no validation that is important all the

192
00:06:37,199 --> 00:06:40,400
validation

193
00:06:38,080 --> 00:06:42,000
goes into fit in fit i do input

194
00:06:40,400 --> 00:06:46,159
validation

195
00:06:42,000 --> 00:06:47,840
and if needed i do validation i'm up

196
00:06:46,160 --> 00:06:49,440
on my parameters if two if two

197
00:06:47,840 --> 00:06:50,000
parameters are not compatible and i need

198
00:06:49,440 --> 00:06:51,840
to check

199
00:06:50,000 --> 00:06:54,000
like only one of them is set this is

200
00:06:51,840 --> 00:06:57,039
where i do that

201
00:06:54,000 --> 00:06:57,680
and then here i'm just um storing my

202
00:06:57,039 --> 00:07:00,960
trained

203
00:06:57,680 --> 00:07:04,000
svc in an estimator with a trailing

204
00:07:00,960 --> 00:07:06,880
underscore and that's again important

205
00:07:04,000 --> 00:07:08,000
the convention is that attributes are

206
00:07:06,880 --> 00:07:09,840
attributes they're public

207
00:07:08,000 --> 00:07:11,039
if there's a trailing underscore it is

208
00:07:09,840 --> 00:07:13,119
set in fit

209
00:07:11,039 --> 00:07:14,240
if it's a leading underscore it's

210
00:07:13,120 --> 00:07:18,479
private and

211
00:07:14,240 --> 00:07:18,479
backward compatibility is not guaranteed

212
00:07:19,039 --> 00:07:22,800
then i have predict um i check if i'm

213
00:07:21,840 --> 00:07:26,400
fitted

214
00:07:22,800 --> 00:07:30,319
if yes then i check my input and then i

215
00:07:26,400 --> 00:07:33,359
delegate to my estimators pretty

216
00:07:30,319 --> 00:07:33,360
so what did i use there

217
00:07:38,319 --> 00:07:41,840
one of them was check is fitted it

218
00:07:39,759 --> 00:07:43,680
checks if there is any attribute with an

219
00:07:41,840 --> 00:07:45,280
uh with a with a with a trailing

220
00:07:43,680 --> 00:07:48,560
underscore you can you can

221
00:07:45,280 --> 00:07:50,638
tune the behavior chakra is a is a

222
00:07:48,560 --> 00:07:53,680
really long and important one

223
00:07:50,639 --> 00:07:54,160
it does return an empire uh unless you

224
00:07:53,680 --> 00:07:56,080
say you

225
00:07:54,160 --> 00:07:57,680
do explicitly want to support sparse

226
00:07:56,080 --> 00:08:00,080
arrays in which case it doesn't convert

227
00:07:57,680 --> 00:08:02,240
this particular to a dense array

228
00:08:00,080 --> 00:08:03,359
and if it's a pandas data frame it

229
00:08:02,240 --> 00:08:06,160
converts that

230
00:08:03,360 --> 00:08:06,879
to numpy so if you if you want to for

231
00:08:06,160 --> 00:08:08,879
example

232
00:08:06,879 --> 00:08:10,319
check your like get your feature names

233
00:08:08,879 --> 00:08:11,840
before from your

234
00:08:10,319 --> 00:08:14,080
pandas data frame you do that before

235
00:08:11,840 --> 00:08:16,318
passing it to check area

236
00:08:14,080 --> 00:08:20,479
and then check x y does the same thing

237
00:08:16,319 --> 00:08:20,479
plus doing some extra validation on y

238
00:08:21,599 --> 00:08:25,120
now that we have it how can we be sure

239
00:08:23,919 --> 00:08:28,400
that it is now

240
00:08:25,120 --> 00:08:31,280
compatible the compatibility is usually

241
00:08:28,400 --> 00:08:32,399
checked through our common tests we have

242
00:08:31,280 --> 00:08:35,439
check estimator

243
00:08:32,399 --> 00:08:37,440
it does a whole bunch of tests and we

244
00:08:35,440 --> 00:08:40,399
recently added this decorator

245
00:08:37,440 --> 00:08:41,200
parameters with checks you put that on

246
00:08:40,399 --> 00:08:43,839
top of your

247
00:08:41,200 --> 00:08:46,080
pi test test and then it does all the

248
00:08:43,839 --> 00:08:48,480
tests individually and you can easily

249
00:08:46,080 --> 00:08:50,480
check and debug what went wrong for

250
00:08:48,480 --> 00:08:52,640
example when i was writing this one

251
00:08:50,480 --> 00:08:54,640
i forgot to set the classes attribute

252
00:08:52,640 --> 00:08:56,319
which is needed if you're a classifier

253
00:08:54,640 --> 00:08:58,800
and then a complaint and then i go back

254
00:08:56,320 --> 00:08:58,800
and set it

255
00:09:00,160 --> 00:09:03,600
now that we have it then it's easy it

256
00:09:01,839 --> 00:09:06,399
you can use it the way that you

257
00:09:03,600 --> 00:09:07,200
you would use before um i have a bunch

258
00:09:06,399 --> 00:09:10,560
of data

259
00:09:07,200 --> 00:09:12,959
i can fit on my data i can get my score

260
00:09:10,560 --> 00:09:14,319
i can put that in a pipeline here i have

261
00:09:12,959 --> 00:09:17,599
a select kb

262
00:09:14,320 --> 00:09:22,320
best and then my classifier and then

263
00:09:17,600 --> 00:09:24,640
i can even pass that to a grid search

264
00:09:22,320 --> 00:09:25,920
i feed my grits edge and then if i check

265
00:09:24,640 --> 00:09:29,040
my best estimator

266
00:09:25,920 --> 00:09:30,640
i see that my classifier this is the

267
00:09:29,040 --> 00:09:32,959
hyper parameter selected by the grid

268
00:09:30,640 --> 00:09:32,959
stitch

269
00:09:33,519 --> 00:09:37,040
so what are the some what are some of

270
00:09:34,959 --> 00:09:37,518
the conventions um i pretty much

271
00:09:37,040 --> 00:09:40,640
mentioned

272
00:09:37,519 --> 00:09:42,720
all of them except um the one that the

273
00:09:40,640 --> 00:09:45,279
parameter is passed to fit

274
00:09:42,720 --> 00:09:46,880
the one that you see usually in in the

275
00:09:45,279 --> 00:09:50,240
existing encyclone api

276
00:09:46,880 --> 00:09:51,680
is sample weights uh but you

277
00:09:50,240 --> 00:09:53,360
you could pass other stuff you could

278
00:09:51,680 --> 00:09:56,399
pass groups you could do

279
00:09:53,360 --> 00:09:57,279
um in like when we have in the context

280
00:09:56,399 --> 00:09:59,760
of um

281
00:09:57,279 --> 00:10:01,439
um bias detection and fairness we

282
00:09:59,760 --> 00:10:02,079
usually have our protected attributes

283
00:10:01,440 --> 00:10:04,399
that are not

284
00:10:02,079 --> 00:10:05,439
a part of the data like gender zip code

285
00:10:04,399 --> 00:10:07,200
race all of that

286
00:10:05,440 --> 00:10:09,519
all of that you can pass to fit as a fit

287
00:10:07,200 --> 00:10:10,399
parameter the convention is that

288
00:10:09,519 --> 00:10:12,000
everything that you've

289
00:10:10,399 --> 00:10:14,079
passed as a fit parameter should be

290
00:10:12,000 --> 00:10:15,200
sample aligned if you have feature

291
00:10:14,079 --> 00:10:16,640
attributes

292
00:10:15,200 --> 00:10:18,720
probably don't pass it there if you have

293
00:10:16,640 --> 00:10:20,800
something that you could pass as an init

294
00:10:18,720 --> 00:10:22,480
from do that there

295
00:10:20,800 --> 00:10:24,240
and it's important because if you do

296
00:10:22,480 --> 00:10:25,600
pass things that are sample aligned the

297
00:10:24,240 --> 00:10:27,680
grid search when it does the

298
00:10:25,600 --> 00:10:28,800
uh the folding and um the cross

299
00:10:27,680 --> 00:10:31,279
validation

300
00:10:28,800 --> 00:10:33,279
it does slice these parameters these

301
00:10:31,279 --> 00:10:36,160
like extra parameters for you

302
00:10:33,279 --> 00:10:37,120
and then pass that with your data to the

303
00:10:36,160 --> 00:10:39,920
fit prompt

304
00:10:37,120 --> 00:10:39,920
to the feed function

305
00:10:43,600 --> 00:10:48,399
then um so this is these are the usual

306
00:10:46,480 --> 00:10:49,040
ones but not all estimators follow all

307
00:10:48,399 --> 00:10:52,160
of that

308
00:10:49,040 --> 00:10:53,120
and um either other meta estimators or

309
00:10:52,160 --> 00:10:55,279
some of the tests

310
00:10:53,120 --> 00:10:56,320
need to know that so that's why we

311
00:10:55,279 --> 00:10:58,560
recently introduced

312
00:10:56,320 --> 00:10:59,600
uh estimator tags um they're still

313
00:10:58,560 --> 00:11:02,800
experimental

314
00:10:59,600 --> 00:11:04,480
as in we may change them without

315
00:11:02,800 --> 00:11:07,040
prior notice like they don't go through

316
00:11:04,480 --> 00:11:09,519
the usual deprecation cycles

317
00:11:07,040 --> 00:11:11,439
but they're pretty useful um you can

318
00:11:09,519 --> 00:11:12,880
tell the other meta estimator or the

319
00:11:11,440 --> 00:11:15,279
test what kind of

320
00:11:12,880 --> 00:11:16,720
input types you allow do you support

321
00:11:15,279 --> 00:11:19,839
multi-output do you do

322
00:11:16,720 --> 00:11:21,200
accept nouns and then if you want to

323
00:11:19,839 --> 00:11:25,920
change any other defaults

324
00:11:21,200 --> 00:11:25,920
you can do that by having a more tags

325
00:11:26,839 --> 00:11:29,839
attribute

326
00:11:35,120 --> 00:11:40,240
so what are we doing now this is

327
00:11:38,160 --> 00:11:43,120
this is like how it works now but we are

328
00:11:40,240 --> 00:11:46,240
we're adding a bunch of stuff to the api

329
00:11:43,120 --> 00:11:48,000
and um uh they're useful but that means

330
00:11:46,240 --> 00:11:50,000
that um you would also need to

331
00:11:48,000 --> 00:11:51,279
to add or change your your api a little

332
00:11:50,000 --> 00:11:52,880
bit

333
00:11:51,279 --> 00:11:54,560
one of them the first one that is coming

334
00:11:52,880 --> 00:11:55,760
in uh which hopefully will be there in

335
00:11:54,560 --> 00:11:58,959
the next release

336
00:11:55,760 --> 00:12:01,360
our end features in and end features out

337
00:11:58,959 --> 00:12:03,040
we want to be able to inspect the models

338
00:12:01,360 --> 00:12:04,880
and know how many features went in

339
00:12:03,040 --> 00:12:06,160
and for a transformer how many features

340
00:12:04,880 --> 00:12:08,800
are coming out

341
00:12:06,160 --> 00:12:11,040
that's the first step and um it like it

342
00:12:08,800 --> 00:12:12,240
helps a lot uh for us also to clean up

343
00:12:11,040 --> 00:12:14,160
the code

344
00:12:12,240 --> 00:12:16,959
but it also helps to understand what's

345
00:12:14,160 --> 00:12:19,920
going on in a pipeline

346
00:12:16,959 --> 00:12:21,439
the the step after that is that we want

347
00:12:19,920 --> 00:12:24,719
to have feature names

348
00:12:21,440 --> 00:12:26,720
um if usually if i have data which is

349
00:12:24,720 --> 00:12:29,600
not just a numerical

350
00:12:26,720 --> 00:12:31,040
block if i have a pandas data frame with

351
00:12:29,600 --> 00:12:31,920
a bunch of feature names and i have a

352
00:12:31,040 --> 00:12:34,160
pipeline

353
00:12:31,920 --> 00:12:36,560
i would like to follow in my pipeline

354
00:12:34,160 --> 00:12:39,120
how my features are going through

355
00:12:36,560 --> 00:12:40,800
if i have a bunch of transformers at the

356
00:12:39,120 --> 00:12:42,959
end if i have a classifier i want to

357
00:12:40,800 --> 00:12:44,719
know what went into my classifier

358
00:12:42,959 --> 00:12:46,399
if i have a linear model and then i want

359
00:12:44,720 --> 00:12:47,680
to inspect my coefficients of the linear

360
00:12:46,399 --> 00:12:49,600
model i want to know

361
00:12:47,680 --> 00:12:52,000
which feature was it that now it has a

362
00:12:49,600 --> 00:12:54,320
high coefficient there

363
00:12:52,000 --> 00:12:56,800
so for that we would have right now the

364
00:12:54,320 --> 00:12:59,120
api allows you to have get feature names

365
00:12:56,800 --> 00:13:00,479
that you return the feature names uh but

366
00:12:59,120 --> 00:13:02,240
it becomes ambiguous

367
00:13:00,480 --> 00:13:03,920
or like is that the input feature names

368
00:13:02,240 --> 00:13:07,200
or is that the output feature name

369
00:13:03,920 --> 00:13:09,599
sometimes it's not um clear to define

370
00:13:07,200 --> 00:13:11,200
what it was so we're deprecating that

371
00:13:09,600 --> 00:13:14,480
and we're going to have feature names in

372
00:13:11,200 --> 00:13:14,480
feature names are pretty clear

373
00:13:15,200 --> 00:13:19,279
and that means that if you pass a pandas

374
00:13:17,600 --> 00:13:20,000
data frame you would extract the feature

375
00:13:19,279 --> 00:13:22,160
names for you

376
00:13:20,000 --> 00:13:25,519
and then at the end you will have all of

377
00:13:22,160 --> 00:13:25,519
that propagated in the pipeline

378
00:13:28,079 --> 00:13:32,079
the next one that i'm really excited

379
00:13:29,519 --> 00:13:34,639
about is

380
00:13:32,079 --> 00:13:36,880
data properties sample proper sample

381
00:13:34,639 --> 00:13:39,920
props feature props and data props

382
00:13:36,880 --> 00:13:41,360
um sample weights is an example um

383
00:13:39,920 --> 00:13:43,120
gender that i mentioned is another

384
00:13:41,360 --> 00:13:45,839
example the issue there

385
00:13:43,120 --> 00:13:47,760
is that right now in a pipeline if i

386
00:13:45,839 --> 00:13:48,000
have a pipeline and i want to pass that

387
00:13:47,760 --> 00:13:51,040
to

388
00:13:48,000 --> 00:13:53,600
a fit i have to say okay pass this one

389
00:13:51,040 --> 00:13:54,959
to the fit of that step of the pipeline

390
00:13:53,600 --> 00:13:56,399
and then if i want to pass the same

391
00:13:54,959 --> 00:13:57,760
sample ways to under the fit i need to

392
00:13:56,399 --> 00:13:59,760
copy that and say well

393
00:13:57,760 --> 00:14:01,199
also pass that to this one and if i have

394
00:13:59,760 --> 00:14:03,279
a meta estimator

395
00:14:01,199 --> 00:14:04,479
i don't know if the meta estimator

396
00:14:03,279 --> 00:14:09,120
should pass that through

397
00:14:04,480 --> 00:14:11,120
or not maybe i have to duplicate that

398
00:14:09,120 --> 00:14:12,880
and pass the one that is used by the

399
00:14:11,120 --> 00:14:14,160
meta estimator and pass another one that

400
00:14:12,880 --> 00:14:15,920
is used by the one

401
00:14:14,160 --> 00:14:17,920
handled by the meta estimator so it's

402
00:14:15,920 --> 00:14:19,920
really not clean the idea here

403
00:14:17,920 --> 00:14:21,279
is that i could have a really nice

404
00:14:19,920 --> 00:14:24,160
routing and

405
00:14:21,279 --> 00:14:25,519
um every set the pipeline every meta

406
00:14:24,160 --> 00:14:27,279
estimator would know

407
00:14:25,519 --> 00:14:29,920
what needs to be passed to what's to

408
00:14:27,279 --> 00:14:31,279
which step and not just fit also score

409
00:14:29,920 --> 00:14:33,360
and predict if you if you

410
00:14:31,279 --> 00:14:34,639
if you need to pass other features other

411
00:14:33,360 --> 00:14:36,639
other properties to them

412
00:14:34,639 --> 00:14:38,720
then you should be able to pass them

413
00:14:36,639 --> 00:14:39,279
that requires changing the the api a

414
00:14:38,720 --> 00:14:41,120
little bit

415
00:14:39,279 --> 00:14:42,639
um and then there are some prototypes

416
00:14:41,120 --> 00:14:43,760
and hopefully they will go forward and

417
00:14:42,639 --> 00:14:46,000
we'll have them uh

418
00:14:43,760 --> 00:14:46,000
soon

419
00:14:46,959 --> 00:14:50,959
but that's that's not all of it um they

420
00:14:49,360 --> 00:14:53,680
i i only showed you

421
00:14:50,959 --> 00:14:54,959
uh like a really really simple one and

422
00:14:53,680 --> 00:14:57,760
um

423
00:14:54,959 --> 00:14:58,000
for example here i could if i if i

424
00:14:57,760 --> 00:15:00,399
really

425
00:14:58,000 --> 00:15:02,240
wanted to write a clean estimator if i

426
00:15:00,399 --> 00:15:05,519
am wrapping around an estimator

427
00:15:02,240 --> 00:15:06,480
i may be a classifier but i'm also a

428
00:15:05,519 --> 00:15:08,880
meta estimator

429
00:15:06,480 --> 00:15:10,240
which means that i shouldn't have to

430
00:15:08,880 --> 00:15:12,320
care about

431
00:15:10,240 --> 00:15:14,000
which hyper parameters are there the

432
00:15:12,320 --> 00:15:15,600
user should be able to pass it

433
00:15:14,000 --> 00:15:17,199
an estimator and then i should be able

434
00:15:15,600 --> 00:15:18,959
to know what the parameters are

435
00:15:17,199 --> 00:15:21,199
you don't have to do that yourself you

436
00:15:18,959 --> 00:15:24,079
can use the meta estimator mixing

437
00:15:21,199 --> 00:15:25,599
and all of that you can see um in the

438
00:15:24,079 --> 00:15:26,239
like in the in the points that i give

439
00:15:25,600 --> 00:15:29,360
here

440
00:15:26,240 --> 00:15:32,720
um this one this documentation um covers

441
00:15:29,360 --> 00:15:35,839
most of the stuff i talked about

442
00:15:32,720 --> 00:15:37,600
uh this file the base that pile uh has

443
00:15:35,839 --> 00:15:39,279
everything other than the except the

444
00:15:37,600 --> 00:15:42,000
methyl similar ones there are other

445
00:15:39,279 --> 00:15:44,240
mixings that you probably could use

446
00:15:42,000 --> 00:15:46,639
um and then the meta estimator one and

447
00:15:44,240 --> 00:15:48,240
then the validation. has it has it has a

448
00:15:46,639 --> 00:15:50,639
lot more utility functions that you

449
00:15:48,240 --> 00:15:55,839
could use

450
00:15:50,639 --> 00:15:55,839
thanks i'll take questions now

451
00:15:57,420 --> 00:16:02,229
[Applause]

452
00:16:07,199 --> 00:16:11,040
we have time for lots of questions

453
00:16:18,480 --> 00:16:22,240
so this estimator can work with like

454
00:16:20,839 --> 00:16:24,800
tensorflow

455
00:16:22,240 --> 00:16:25,959
data structures and other from keras

456
00:16:24,800 --> 00:16:29,439
like hazard

457
00:16:25,959 --> 00:16:31,119
interoperability or just for basic data

458
00:16:29,440 --> 00:16:33,920
structures

459
00:16:31,120 --> 00:16:35,600
if i have a data and like tensor flows

460
00:16:33,920 --> 00:16:36,000
that that distributed structure can it

461
00:16:35,600 --> 00:16:38,160
like

462
00:16:36,000 --> 00:16:40,000
can i just insert it in this estimator

463
00:16:38,160 --> 00:16:42,639
from scikit-learn or it will work

464
00:16:40,000 --> 00:16:43,519
it will require some kind of other

465
00:16:42,639 --> 00:16:47,199
conversions

466
00:16:43,519 --> 00:16:48,720
in the in the way so if if i understand

467
00:16:47,199 --> 00:16:51,758
the question is a question

468
00:16:48,720 --> 00:16:54,240
that if you could put a for example a

469
00:16:51,759 --> 00:16:56,079
pi torch model as an estimator here or

470
00:16:54,240 --> 00:16:58,959
yes yeah or something like that yes

471
00:16:56,079 --> 00:16:59,599
yeah so so the um the idea is that um

472
00:16:58,959 --> 00:17:01,680
they don't

473
00:16:59,600 --> 00:17:02,880
so the default api of any of those

474
00:17:01,680 --> 00:17:05,198
libraries doesn't follow

475
00:17:02,880 --> 00:17:08,079
this api but usually what happens is

476
00:17:05,199 --> 00:17:10,400
that they have an sklearn wrapper

477
00:17:08,079 --> 00:17:11,359
so you could i don't remember which one

478
00:17:10,400 --> 00:17:13,600
has it where

479
00:17:11,359 --> 00:17:15,599
but for example if i see pytorch dot

480
00:17:13,599 --> 00:17:16,319
escalant then i know that that's where i

481
00:17:15,599 --> 00:17:18,799
can find

482
00:17:16,319 --> 00:17:20,399
my cycle and compatible estimators and

483
00:17:18,799 --> 00:17:23,199
then those estimators

484
00:17:20,400 --> 00:17:24,959
they wrap around their own estimators

485
00:17:23,199 --> 00:17:26,000
but they expose an api which is

486
00:17:24,959 --> 00:17:27,679
compatible here

487
00:17:26,000 --> 00:17:29,200
therefore you could take that and then

488
00:17:27,679 --> 00:17:31,679
plug it in a pipeline here

489
00:17:29,200 --> 00:17:32,960
okay so principally it can it can yeah

490
00:17:31,679 --> 00:17:46,640
no it does people do that

491
00:17:32,960 --> 00:17:50,480
okay thank you

492
00:17:46,640 --> 00:17:52,880
don't be shy raise your hand and if i

493
00:17:50,480 --> 00:17:52,880
don't see

494
00:17:53,120 --> 00:17:56,000
crazy tire

495
00:17:56,960 --> 00:18:01,840
nothing okay thank you

496
00:18:03,550 --> 00:18:08,129
[Applause]

