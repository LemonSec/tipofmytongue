1
00:00:04,590 --> 00:00:10,469
well so hello my name's Ben I'm over at

2
00:00:08,280 --> 00:00:11,910
Queen Mary University in London and I'm

3
00:00:10,469 --> 00:00:13,440
gonna be talking about Raftery a system

4
00:00:11,910 --> 00:00:15,180
that me and my two advisers been

5
00:00:13,440 --> 00:00:17,009
building which looked at distributed

6
00:00:15,180 --> 00:00:19,320
temporal graphs and how we're building

7
00:00:17,010 --> 00:00:21,869
and maintaining them from the set of

8
00:00:19,320 --> 00:00:23,250
event streams so I trying to give you a

9
00:00:21,869 --> 00:00:25,169
little bit of an idea of why we can't

10
00:00:23,250 --> 00:00:26,279
got to this point so kind of some of the

11
00:00:25,169 --> 00:00:28,410
original distributed graph processing

12
00:00:26,279 --> 00:00:30,150
systems have this idea that you've got a

13
00:00:28,410 --> 00:00:31,740
big chunk of data on disk you've got

14
00:00:30,150 --> 00:00:33,600
some chosen algorithm so you load it in

15
00:00:31,740 --> 00:00:35,070
turn into your graph you churn through

16
00:00:33,600 --> 00:00:37,860
in a couple of iterations and out pops

17
00:00:35,070 --> 00:00:39,000
your result and then if you say you want

18
00:00:37,860 --> 00:00:41,220
to see how things have changed for our

19
00:00:39,000 --> 00:00:42,720
time you might have snapshots you know

20
00:00:41,220 --> 00:00:44,730
once a day for the last sex number of

21
00:00:42,720 --> 00:00:46,620
months and again you load all these in

22
00:00:44,730 --> 00:00:48,089
build them into graphs you get a set of

23
00:00:46,620 --> 00:00:49,199
outputs and then these can you know you

24
00:00:48,090 --> 00:00:51,930
can do some dealt was between them to

25
00:00:49,200 --> 00:00:53,490
see how things have changed that's quite

26
00:00:51,930 --> 00:00:55,080
sort of coarse and you know you only

27
00:00:53,490 --> 00:00:56,430
have snapshots once every day then you

28
00:00:55,080 --> 00:00:58,350
kind of lose what happens in between and

29
00:00:56,430 --> 00:00:59,940
so on this is kind of improved with

30
00:00:58,350 --> 00:01:01,740
these stream based graph processing

31
00:00:59,940 --> 00:01:03,780
systems where you have some event source

32
00:01:01,740 --> 00:01:05,339
out in the wild so some examples we've

33
00:01:03,780 --> 00:01:07,229
been looking at like crypto currencies

34
00:01:05,339 --> 00:01:09,200
mapping data so people moving around

35
00:01:07,229 --> 00:01:12,630
cities and obviously social networks and

36
00:01:09,200 --> 00:01:14,579
then changes in these events sources can

37
00:01:12,630 --> 00:01:15,780
then affect your in memory graph so in

38
00:01:14,579 --> 00:01:17,490
the case of a social network you might

39
00:01:15,780 --> 00:01:19,380
have a user joins the network someone

40
00:01:17,490 --> 00:01:22,259
follows their friend and so on so these

41
00:01:19,380 --> 00:01:25,048
can all be inside in and then users of

42
00:01:22,259 --> 00:01:27,030
your system can then query this request

43
00:01:25,049 --> 00:01:28,259
processing and get their results back so

44
00:01:27,030 --> 00:01:29,609
this is great if you want to do some

45
00:01:28,259 --> 00:01:31,560
analysis on the most recent version the

46
00:01:29,609 --> 00:01:32,699
graph alternatively if you've got

47
00:01:31,560 --> 00:01:33,869
symmetric but you're interested in

48
00:01:32,700 --> 00:01:36,090
monitoring and then seeing how this

49
00:01:33,869 --> 00:01:37,439
changes over time so what were your

50
00:01:36,090 --> 00:01:39,119
thinking was is that well if you've got

51
00:01:37,439 --> 00:01:40,199
all these changes coming in and you have

52
00:01:39,119 --> 00:01:41,719
all these problems we're trying to keep

53
00:01:40,200 --> 00:01:43,740
all your graph in sync and up to date

54
00:01:41,719 --> 00:01:45,178
why don't we just try to keep all of the

55
00:01:43,740 --> 00:01:47,369
changes and build a full temple run

56
00:01:45,179 --> 00:01:48,569
graph so this could this in some way

57
00:01:47,369 --> 00:01:50,520
simplifies the way that we actually

58
00:01:48,569 --> 00:01:51,990
synchronized but it also allows us to do

59
00:01:50,520 --> 00:01:53,249
things like comparing the newest state

60
00:01:51,990 --> 00:01:54,600
to all of the previous versions of the

61
00:01:53,249 --> 00:01:56,369
state and then actually do proper

62
00:01:54,600 --> 00:01:57,568
temporal queries so something like if

63
00:01:56,369 --> 00:01:59,969
you're doing a shortest path it might be

64
00:01:57,569 --> 00:02:01,200
I only want to go out on edges that are

65
00:01:59,969 --> 00:02:03,270
younger than the one are coming on or

66
00:02:01,200 --> 00:02:05,130
alternatively you might have say for I

67
00:02:03,270 --> 00:02:06,719
know planes flying around edges only

68
00:02:05,130 --> 00:02:08,519
exist for a certain period of time and

69
00:02:06,719 --> 00:02:11,609
you need to get there and get on that

70
00:02:08,520 --> 00:02:14,849
edge before it disappears so those ideas

71
00:02:11,610 --> 00:02:16,439
in mind let me come up with Raftery our

72
00:02:14,849 --> 00:02:18,100
initial work was on kind of formalizing

73
00:02:16,439 --> 00:02:21,070
this temporal graph model and the

74
00:02:18,100 --> 00:02:22,960
semantics and how we add remove vertices

75
00:02:21,070 --> 00:02:24,940
and edges as well as updating a set of

76
00:02:22,960 --> 00:02:26,200
properties that they have so a key key

77
00:02:24,940 --> 00:02:28,630
value set of properties associated with

78
00:02:26,200 --> 00:02:29,950
them how we actually distribute and

79
00:02:28,630 --> 00:02:31,359
manage this graph in memory so we have a

80
00:02:29,950 --> 00:02:34,060
set of partitions which have a set of

81
00:02:31,360 --> 00:02:36,040
vertices and edges each and then how we

82
00:02:34,060 --> 00:02:37,120
sort of stream all of these updates into

83
00:02:36,040 --> 00:02:39,100
these partitions and keep them in sync

84
00:02:37,120 --> 00:02:40,600
and then we also provide this sort

85
00:02:39,100 --> 00:02:42,430
program like temporal graph analysis

86
00:02:40,600 --> 00:02:44,500
model in which the user can request to

87
00:02:42,430 --> 00:02:45,700
do some analysis on the live graph any

88
00:02:44,500 --> 00:02:47,020
point back in time down to the

89
00:02:45,700 --> 00:02:48,579
resolution of the actual time stamps on

90
00:02:47,020 --> 00:02:50,050
the data so you could say you know what

91
00:02:48,580 --> 00:02:52,000
does it look like the last Thursday at

92
00:02:50,050 --> 00:02:53,350
3:02 in the afternoon and then actually

93
00:02:52,000 --> 00:02:54,430
look through ranges so sort of hop

94
00:02:53,350 --> 00:02:56,019
throughout the whole history of the

95
00:02:54,430 --> 00:02:58,720
graph and compute these different

96
00:02:56,020 --> 00:03:00,130
metrics and see how they change so I'll

97
00:02:58,720 --> 00:03:02,350
just go over a quick run through the

98
00:03:00,130 --> 00:03:04,030
architecture so over here we have this

99
00:03:02,350 --> 00:03:05,680
date of spell so this is kind of how the

100
00:03:04,030 --> 00:03:07,600
user decides how to connect to the

101
00:03:05,680 --> 00:03:08,890
outside world so this is something like

102
00:03:07,600 --> 00:03:10,960
you know I want to read this file

103
00:03:08,890 --> 00:03:13,239
connect to this database listen to this

104
00:03:10,960 --> 00:03:15,250
katka stream or something on these lines

105
00:03:13,240 --> 00:03:17,200
this goes into a set of graph rooters

106
00:03:15,250 --> 00:03:18,820
effectively it does is it takes a

107
00:03:17,200 --> 00:03:20,920
user-defined function and what that raw

108
00:03:18,820 --> 00:03:23,680
input transfers into in terms of graph

109
00:03:20,920 --> 00:03:25,299
updates so what is a vertex what is an

110
00:03:23,680 --> 00:03:27,010
edge if someone comes in this is

111
00:03:25,300 --> 00:03:28,570
actually an update to a property and so

112
00:03:27,010 --> 00:03:29,980
on and then they forward it off to the

113
00:03:28,570 --> 00:03:31,209
correct partition manager or partition

114
00:03:29,980 --> 00:03:33,519
of the graph which deals with that

115
00:03:31,210 --> 00:03:35,140
vertex or edge they're affected and then

116
00:03:33,520 --> 00:03:37,330
this is constantly running and

117
00:03:35,140 --> 00:03:38,980
maintaining users can submit analysis

118
00:03:37,330 --> 00:03:41,980
requests which talk to the partitions

119
00:03:38,980 --> 00:03:43,329
that are going onto there in a second so

120
00:03:41,980 --> 00:03:45,220
if we dive into one of these partitions

121
00:03:43,330 --> 00:03:47,110
they'll have a set of vertices and edges

122
00:03:45,220 --> 00:03:48,700
as I said and all of these will then

123
00:03:47,110 --> 00:03:50,110
have some history appended to them so in

124
00:03:48,700 --> 00:03:51,970
this case this vertex was created at

125
00:03:50,110 --> 00:03:54,700
time eight then had some update appended

126
00:03:51,970 --> 00:03:56,230
to it at time fourteen and this edge was

127
00:03:54,700 --> 00:03:58,299
created at time 14 possibly why this

128
00:03:56,230 --> 00:04:00,850
vertex has an update and whether than

129
00:03:58,300 --> 00:04:02,560
delete at some point later on as we

130
00:04:00,850 --> 00:04:05,500
split across several partitions we use

131
00:04:02,560 --> 00:04:07,330
an edge cut partitioning algorithm so

132
00:04:05,500 --> 00:04:08,680
this edge down here because vertex one

133
00:04:07,330 --> 00:04:09,910
of vertex two different machines are

134
00:04:08,680 --> 00:04:13,690
actually split across the two machines I

135
00:04:09,910 --> 00:04:14,680
know see they're in sync right so one

136
00:04:13,690 --> 00:04:17,108
thing that's really interesting about

137
00:04:14,680 --> 00:04:18,820
this type of history is that now all of

138
00:04:17,108 --> 00:04:20,560
our updates kind of become additive so

139
00:04:18,820 --> 00:04:23,349
even if we have a delete happen first

140
00:04:20,560 --> 00:04:24,820
and an add happen after as long as we

141
00:04:23,350 --> 00:04:25,900
keep this chronological list we can just

142
00:04:24,820 --> 00:04:27,180
slot them into the correct position so

143
00:04:25,900 --> 00:04:29,620
you always end up with the right graph

144
00:04:27,180 --> 00:04:30,820
so this is kind of nice because if you

145
00:04:29,620 --> 00:04:31,569
have this problem of updates coming in

146
00:04:30,820 --> 00:04:33,159
the wrong order for a lot

147
00:04:31,569 --> 00:04:34,719
systems you either have to drop them

148
00:04:33,159 --> 00:04:36,759
ignore them or you get an incorrect

149
00:04:34,719 --> 00:04:38,589
state in one of your partitions so as an

150
00:04:36,759 --> 00:04:40,979
example of this we may have say this

151
00:04:38,589 --> 00:04:43,449
edge add that comes in at time fourteen

152
00:04:40,979 --> 00:04:44,679
because politician manager partition

153
00:04:43,449 --> 00:04:46,990
manager one deals with because vertex

154
00:04:44,679 --> 00:04:48,849
one is the source node so we insert that

155
00:04:46,990 --> 00:04:50,969
into the machine the edge gets created

156
00:04:48,849 --> 00:04:53,469
and the vertex one gets updated

157
00:04:50,969 --> 00:04:55,119
we then synchronize across to the other

158
00:04:53,469 --> 00:04:57,069
node say hey I've got an edge that I

159
00:04:55,119 --> 00:04:59,139
share with you so that gets updated into

160
00:04:57,069 --> 00:05:00,459
vertex two and the ID has created there

161
00:04:59,139 --> 00:05:01,689
as well so that's all fantastic

162
00:05:00,459 --> 00:05:02,020
everything's happened in the correct

163
00:05:01,689 --> 00:05:04,569
order

164
00:05:02,020 --> 00:05:06,938
everything's brilliant what happens if

165
00:05:04,569 --> 00:05:09,580
say an edge gets added before we get a

166
00:05:06,939 --> 00:05:11,259
vertex well in this case we can create

167
00:05:09,580 --> 00:05:13,990
both objects the vertex actually just

168
00:05:11,259 --> 00:05:15,249
becomes a placeholder and then so again

169
00:05:13,990 --> 00:05:17,770
we synchronize do everything exactly the

170
00:05:15,249 --> 00:05:19,509
same and in the vertex add add comes in

171
00:05:17,770 --> 00:05:21,068
later point we just slot light into the

172
00:05:19,509 --> 00:05:22,180
history behind so then if this comes in

173
00:05:21,069 --> 00:05:23,349
with all the properties all this sort of

174
00:05:22,180 --> 00:05:25,149
interesting there they are about that

175
00:05:23,349 --> 00:05:27,639
vertex it can be inserted at that point

176
00:05:25,149 --> 00:05:29,259
and then obviously things can go

177
00:05:27,639 --> 00:05:31,059
completely haywire so for some reason

178
00:05:29,259 --> 00:05:32,110
some packets have been lost or you know

179
00:05:31,059 --> 00:05:33,909
they know what's going on all over the

180
00:05:32,110 --> 00:05:35,139
place and in this case this vertex has

181
00:05:33,909 --> 00:05:37,360
actually been deleted before it's even

182
00:05:35,139 --> 00:05:38,680
been created so in a lot of systems you

183
00:05:37,360 --> 00:05:39,849
might find that this is just okay well

184
00:05:38,680 --> 00:05:41,169
this is nonsense this just drop it and

185
00:05:39,849 --> 00:05:42,969
ignore it and that's obviously not what

186
00:05:41,169 --> 00:05:44,438
we want to do here so we're again we

187
00:05:42,969 --> 00:05:47,169
have a placeholder object which holds

188
00:05:44,439 --> 00:05:49,240
its deletion when the edge ad in this

189
00:05:47,169 --> 00:05:50,498
instance comes into the other machine it

190
00:05:49,240 --> 00:05:51,999
does what it does in that machine and

191
00:05:50,499 --> 00:05:53,800
then the sink Rises across at which

192
00:05:51,999 --> 00:05:55,719
point the vertex now gets its creation

193
00:05:53,800 --> 00:05:57,699
of a great point and we can insert this

194
00:05:55,719 --> 00:05:59,169
edge and then because this vertex was

195
00:05:57,699 --> 00:06:01,300
deleted all of its incoming and outgoing

196
00:05:59,169 --> 00:06:02,558
edges should be deleted so we don't have

197
00:06:01,300 --> 00:06:03,879
anything hanging and that come in

198
00:06:02,559 --> 00:06:05,439
synchronize back so even though this

199
00:06:03,879 --> 00:06:07,479
went sort of completely wrong you still

200
00:06:05,439 --> 00:06:09,339
end up with the same state and the same

201
00:06:07,479 --> 00:06:10,779
temporal graphic moving forward so we've

202
00:06:09,339 --> 00:06:12,039
stuck in some water markings so you kind

203
00:06:10,779 --> 00:06:13,808
of know when when it gets to the point

204
00:06:12,039 --> 00:06:15,279
where this is safe to do or if you want

205
00:06:13,809 --> 00:06:16,479
to you know you can go there a proximate

206
00:06:15,279 --> 00:06:20,589
proach if you just give me what's going

207
00:06:16,479 --> 00:06:22,539
in memory now so on that point I know

208
00:06:20,589 --> 00:06:24,219
this is a bit so a whistle-stop will pop

209
00:06:22,539 --> 00:06:26,349
on to the analysis so the general idea

210
00:06:24,219 --> 00:06:27,729
is that the rooters are constantly

211
00:06:26,349 --> 00:06:28,719
ingesting new information from whatever

212
00:06:27,729 --> 00:06:30,818
source you've specified

213
00:06:28,719 --> 00:06:32,439
assuming it's unbounded and then the

214
00:06:30,819 --> 00:06:34,209
partition manager constantly keep in

215
00:06:32,439 --> 00:06:36,129
sync with each other and wait from

216
00:06:34,209 --> 00:06:37,240
request from an analysis manager so the

217
00:06:36,129 --> 00:06:40,360
user says hey I want to run this

218
00:06:37,240 --> 00:06:42,579
analysis can ice the minute so this goes

219
00:06:40,360 --> 00:06:44,199
off all the partition managers will then

220
00:06:42,579 --> 00:06:45,699
go from their set of vertices run this

221
00:06:44,199 --> 00:06:47,979
towards vertex centric

222
00:06:45,699 --> 00:06:49,990
and then returned to the analysis

223
00:06:47,979 --> 00:06:51,159
manager and then I smell chicken and say

224
00:06:49,990 --> 00:06:52,750
okay well all my vertices have either

225
00:06:51,160 --> 00:06:54,460
decided to vote to whole or another

226
00:06:52,750 --> 00:06:55,780
iteration is required and this will go

227
00:06:54,460 --> 00:06:56,948
back and forth until it's happy that

228
00:06:55,780 --> 00:06:59,770
it's finished and the result can be

229
00:06:56,949 --> 00:07:02,050
returned to the user so what can we use

230
00:06:59,770 --> 00:07:05,109
that actually requests well the first

231
00:07:02,050 --> 00:07:09,070
thing is that if we have this temporal

232
00:07:05,110 --> 00:07:10,270
graph in memory we can say okay well

233
00:07:09,070 --> 00:07:13,240
give me what the live graph looks like

234
00:07:10,270 --> 00:07:14,799
so this is the most recent version of

235
00:07:13,240 --> 00:07:16,330
the graph even watermarks as I said so

236
00:07:14,800 --> 00:07:18,010
this is kind of the safe live graph or

237
00:07:16,330 --> 00:07:20,139
alternatively you could ask for the

238
00:07:18,010 --> 00:07:21,340
bleeding edge absolute most recent

239
00:07:20,139 --> 00:07:22,900
version in which you have some error of

240
00:07:21,340 --> 00:07:24,880
a proximity so depending on what sort of

241
00:07:22,900 --> 00:07:26,380
use case you have there alternatively

242
00:07:24,880 --> 00:07:28,360
you might say okay well give me what it

243
00:07:26,380 --> 00:07:30,100
might look like last week last month a

244
00:07:28,360 --> 00:07:31,720
year ago something like this and these

245
00:07:30,100 --> 00:07:33,220
tends to be sort of stored in memory so

246
00:07:31,720 --> 00:07:35,110
we'll build that view and I'll go over

247
00:07:33,220 --> 00:07:36,160
that in a second or alternatively if

248
00:07:35,110 --> 00:07:37,570
rafter you've been running for a very

249
00:07:36,160 --> 00:07:39,280
long time and you started have to push

250
00:07:37,570 --> 00:07:40,330
the older stuff out of memory then we

251
00:07:39,280 --> 00:07:41,619
can start loading some of those things

252
00:07:40,330 --> 00:07:43,510
back if you want to go back to that file

253
00:07:41,620 --> 00:07:45,669
we're also looking for ways

254
00:07:43,510 --> 00:07:47,740
sort of offloading very old queries into

255
00:07:45,669 --> 00:07:49,150
a different set of partition managers so

256
00:07:47,740 --> 00:07:50,349
that query that sort doesn't interrupt

257
00:07:49,150 --> 00:07:53,460
what's going on in the most recent

258
00:07:50,349 --> 00:07:57,580
version the graph obvious is future work

259
00:07:53,460 --> 00:07:58,900
cool so if we then say we have this full

260
00:07:57,580 --> 00:08:02,530
history of everything that's been

261
00:07:58,900 --> 00:08:05,409
ingested from time zero up until time n

262
00:08:02,530 --> 00:08:07,119
so the newest update we might say okay

263
00:08:05,410 --> 00:08:10,419
well I want to see what the graph looked

264
00:08:07,120 --> 00:08:12,430
like t10 and a good way of viewing that

265
00:08:10,419 --> 00:08:14,440
what our view is it's kind of like a

266
00:08:12,430 --> 00:08:16,030
right-hand filter so it's okay well this

267
00:08:14,440 --> 00:08:17,169
is everything that's happened I'm not

268
00:08:16,030 --> 00:08:18,609
interested anything that's happened off

269
00:08:17,169 --> 00:08:20,049
at this point so let's just kind of get

270
00:08:18,610 --> 00:08:21,130
rid of that for the moment so that you

271
00:08:20,050 --> 00:08:22,270
can only get to see now what the graph

272
00:08:21,130 --> 00:08:25,300
looked like exactly at that point of

273
00:08:22,270 --> 00:08:27,609
time and then that can be used for your

274
00:08:25,300 --> 00:08:28,690
analysis one of the things we found was

275
00:08:27,610 --> 00:08:31,060
that you know if you're if you're

276
00:08:28,690 --> 00:08:32,469
looking at very large data sets that

277
00:08:31,060 --> 00:08:34,270
have been existed for you know years and

278
00:08:32,469 --> 00:08:35,380
years then there's an awful lot of

279
00:08:34,270 --> 00:08:37,088
patterns that happen in the short-term

280
00:08:35,380 --> 00:08:39,429
that kind of get hidden by this huge a

281
00:08:37,089 --> 00:08:41,560
great amount of data so we wanted in

282
00:08:39,429 --> 00:08:43,179
something we like to call some graph

283
00:08:41,559 --> 00:08:45,010
windowing which kind of gives like the

284
00:08:43,179 --> 00:08:45,910
light left-hand filter and in this case

285
00:08:45,010 --> 00:08:47,140
you're saying okay well I'm only

286
00:08:45,910 --> 00:08:48,370
interested in things that happened in

287
00:08:47,140 --> 00:08:50,319
this band of time so it could be from

288
00:08:48,370 --> 00:08:52,959
this timestamp for the last day the last

289
00:08:50,320 --> 00:08:54,430
week the last month and so on and so you

290
00:08:52,959 --> 00:08:55,810
then you can actually view the

291
00:08:54,430 --> 00:08:58,719
short-term pans as well as long-term

292
00:08:55,810 --> 00:09:00,310
ones and so for that we actually offer

293
00:08:58,720 --> 00:09:02,019
windowing batches so you can say okay

294
00:09:00,310 --> 00:09:03,388
well start at this point and then just

295
00:09:02,019 --> 00:09:05,769
decrease the size of the window down

296
00:09:03,389 --> 00:09:06,610
continuously until you've reached all

297
00:09:05,769 --> 00:09:12,610
you've done all the ones I'm interested

298
00:09:06,610 --> 00:09:13,660
in as well as these individual views you

299
00:09:12,610 --> 00:09:15,339
might actually say okay well I'm

300
00:09:13,660 --> 00:09:16,779
interested in this sort of range of

301
00:09:15,339 --> 00:09:18,459
times over the last year or something

302
00:09:16,779 --> 00:09:21,160
and I want to hop through some set

303
00:09:18,459 --> 00:09:23,079
interval maybe an hour or a day again

304
00:09:21,160 --> 00:09:24,879
you can do this so we can say build a

305
00:09:23,079 --> 00:09:26,769
viewer of the oldest points at time four

306
00:09:24,879 --> 00:09:29,019
and then we can hop forward to time six

307
00:09:26,769 --> 00:09:29,769
then the interviewers generated time

308
00:09:29,019 --> 00:09:31,420
eight in time ten

309
00:09:29,769 --> 00:09:32,560
so again if you're doing these ranges

310
00:09:31,420 --> 00:09:35,560
you can have all this windowing and

311
00:09:32,560 --> 00:09:38,430
window batching on top as well so that's

312
00:09:35,560 --> 00:09:40,388
obviously sort of very theoretical and

313
00:09:38,430 --> 00:09:42,790
it's not a concrete use case would

314
00:09:40,389 --> 00:09:44,379
obviously be very nice as I imagine what

315
00:09:42,790 --> 00:09:45,370
are you thinking so one of that one of

316
00:09:44,379 --> 00:09:46,750
the things here that we had looked at

317
00:09:45,370 --> 00:09:50,230
was a network called gab

318
00:09:46,750 --> 00:09:51,129
ai has anyone heard of gab good I'll do

319
00:09:50,230 --> 00:09:53,199
it no one think so

320
00:09:51,129 --> 00:09:56,259
so gab is a Twitter clone it's kind of

321
00:09:53,199 --> 00:09:58,449
this like right-wing forum but I had an

322
00:09:56,259 --> 00:10:02,110
open REST API so I downloaded all of

323
00:09:58,449 --> 00:10:03,219
their posts so they're like there's big

324
00:10:02,110 --> 00:10:04,839
free speech thing so I don't know I

325
00:10:03,220 --> 00:10:07,180
assume that's why it's open but so I

326
00:10:04,839 --> 00:10:10,629
scraped them all between the end of 2016

327
00:10:07,180 --> 00:10:12,339
up until mid 2018 and we then had a look

328
00:10:10,629 --> 00:10:14,050
at if we said we set a query running for

329
00:10:12,339 --> 00:10:15,850
that whole range of time and hopped

330
00:10:14,050 --> 00:10:17,109
forward an hour at a time what do we see

331
00:10:15,850 --> 00:10:18,100
any changes in something like just

332
00:10:17,110 --> 00:10:20,170
something simple like the largest

333
00:10:18,100 --> 00:10:21,759
connected component so for this we then

334
00:10:20,170 --> 00:10:23,949
set several different window sizes so we

335
00:10:21,759 --> 00:10:26,439
said okay have a look at all window like

336
00:10:23,949 --> 00:10:28,449
an hour a day week month year and then

337
00:10:26,439 --> 00:10:29,439
the flag will graph an interesting thing

338
00:10:28,449 --> 00:10:30,699
here is that even though you're running

339
00:10:29,439 --> 00:10:32,410
kind of the same algorithm you actually

340
00:10:30,699 --> 00:10:33,699
know it's very different patterns so the

341
00:10:32,410 --> 00:10:35,500
aggregate kind of shows older connect

342
00:10:33,699 --> 00:10:36,550
component continuously grows whereas

343
00:10:35,500 --> 00:10:38,439
actually if you look at something like

344
00:10:36,550 --> 00:10:39,639
the month you have these peaks of

345
00:10:38,439 --> 00:10:41,230
interest so this is actually Donald

346
00:10:39,639 --> 00:10:42,759
Trump's election as the Charlottesville

347
00:10:41,230 --> 00:10:44,230
riots so there's kind of like these like

348
00:10:42,759 --> 00:10:46,120
peeks of activity when people join the

349
00:10:44,230 --> 00:10:47,649
network and start using it and then that

350
00:10:46,120 --> 00:10:49,269
sort of drops down again and then if we

351
00:10:47,649 --> 00:10:51,790
zoom in a little bit further down to the

352
00:10:49,269 --> 00:10:54,459
hour scale you can see that everything

353
00:10:51,790 --> 00:10:56,170
above like a window size of a day the

354
00:10:54,459 --> 00:10:57,459
largest connected component is always

355
00:10:56,170 --> 00:10:59,620
like a hundred percent in the graph so

356
00:10:57,459 --> 00:11:01,508
everyone's always connected it doesn't

357
00:10:59,620 --> 00:11:02,920
really change very much however for an

358
00:11:01,509 --> 00:11:04,420
hour you get this lovely diurnal pattern

359
00:11:02,920 --> 00:11:07,149
as people kind of go to sleep and wake

360
00:11:04,420 --> 00:11:08,889
back up so the largest create component

361
00:11:07,149 --> 00:11:10,149
so it's like 80% of the graph so almost

362
00:11:08,889 --> 00:11:11,559
everyone is connected but then as people

363
00:11:10,149 --> 00:11:12,550
start to go to sleep this all breaks

364
00:11:11,559 --> 00:11:13,779
down into very small

365
00:11:12,550 --> 00:11:15,670
they're talking to travel in the wee

366
00:11:13,779 --> 00:11:18,149
hours and then that brings back up again

367
00:11:15,670 --> 00:11:21,370
as people start coming back online

368
00:11:18,149 --> 00:11:22,630
so yeah so even doing the same query I'm

369
00:11:21,370 --> 00:11:25,540
running on these sort of different

370
00:11:22,630 --> 00:11:26,920
lenses or views of the graph gives you

371
00:11:25,540 --> 00:11:28,380
very different results so we're kind of

372
00:11:26,920 --> 00:11:30,430
stein to explore this a little bit now

373
00:11:28,380 --> 00:11:32,740
and we're obviously interested anyone

374
00:11:30,430 --> 00:11:35,709
that's once talking about this sort of

375
00:11:32,740 --> 00:11:37,630
stuff so on that point if you are

376
00:11:35,709 --> 00:11:40,319
interested in using rs3 it is available

377
00:11:37,630 --> 00:11:42,820
on github it's all docker eyes and has

378
00:11:40,320 --> 00:11:44,050
some actually pretty dreadful scripts to

379
00:11:42,820 --> 00:11:47,110
run it but I'm working on improving

380
00:11:44,050 --> 00:11:48,729
those yes so you can you can run it in

381
00:11:47,110 --> 00:11:50,079
there there's the examples of that day

382
00:11:48,730 --> 00:11:52,060
actual gap graph that just went over

383
00:11:50,079 --> 00:11:54,189
we've got loads of spouts from jesting

384
00:11:52,060 --> 00:11:56,979
different data so gab Twitter a Bitcoin

385
00:11:54,190 --> 00:11:58,420
etherium and loads of a random ones we

386
00:11:56,980 --> 00:12:00,370
have actually ingested the whole Bitcoin

387
00:11:58,420 --> 00:12:01,719
in the theorem graphs over a big cluster

388
00:12:00,370 --> 00:12:03,640
of machines and are working with a

389
00:12:01,720 --> 00:12:05,260
couple of different companies to do some

390
00:12:03,640 --> 00:12:07,689
like know your customer entity

391
00:12:05,260 --> 00:12:09,189
resolution stuff early so um we also

392
00:12:07,690 --> 00:12:10,420
have multiple analysis functions so

393
00:12:09,190 --> 00:12:12,040
things like connect components and

394
00:12:10,420 --> 00:12:14,140
PageRank we're looking at information

395
00:12:12,040 --> 00:12:15,730
diffusion so this is like spreading

396
00:12:14,140 --> 00:12:17,800
paint across cryptocurrency

397
00:12:15,730 --> 00:12:22,120
and then simple things like degree

398
00:12:17,800 --> 00:12:23,859
ranking and so on so for the the future

399
00:12:22,120 --> 00:12:25,450
of Raftery we've just been funded by the

400
00:12:23,860 --> 00:12:27,970
Alan Turing Institute in London for any

401
00:12:25,450 --> 00:12:30,520
you guys that know it to turn this from

402
00:12:27,970 --> 00:12:31,839
kind of the initial research II project

403
00:12:30,520 --> 00:12:33,850
into an actual product that researchers

404
00:12:31,839 --> 00:12:37,149
can use so we're partnering with the

405
00:12:33,850 --> 00:12:40,180
Leeds University to look at some very

406
00:12:37,149 --> 00:12:41,829
large transport datasets mapping people

407
00:12:40,180 --> 00:12:44,170
moving around cities and then so let's

408
00:12:41,829 --> 00:12:45,010
see how that changes over time if you

409
00:12:44,170 --> 00:12:46,660
know the council did something where

410
00:12:45,010 --> 00:12:48,100
they put in a pelican crossing how long

411
00:12:46,660 --> 00:12:50,170
do they have to monitor to see sort of

412
00:12:48,100 --> 00:12:51,880
different changes and foot traffic and

413
00:12:50,170 --> 00:12:53,380
also we're now spinning this out of

414
00:12:51,880 --> 00:12:55,390
Queen Mary into a company called

415
00:12:53,380 --> 00:12:57,130
choreograph so if you do see this name

416
00:12:55,390 --> 00:12:59,620
pop up then it's probably me or an

417
00:12:57,130 --> 00:13:01,600
awesome and trying to steal my name okay

418
00:12:59,620 --> 00:13:04,949
if if you are interested please drop me

419
00:13:01,600 --> 00:13:07,779
a line or you know leave anything on the

420
00:13:04,949 --> 00:13:10,199
gate I'm always on there so thank you

421
00:13:07,779 --> 00:13:10,199
very much for listening

422
00:13:10,220 --> 00:13:17,559
[Applause]

423
00:13:23,160 --> 00:13:28,630
so the question is community performance

424
00:13:26,080 --> 00:13:31,300
improvements by taking snapshots so do

425
00:13:28,630 --> 00:13:35,800
you mean for the actual processing side

426
00:13:31,300 --> 00:13:39,189
or for the ingestion side things so the

427
00:13:35,800 --> 00:13:41,410
on the processing side we're looking at

428
00:13:39,190 --> 00:13:43,240
this side this a little bit so with all

429
00:13:41,410 --> 00:13:46,030
the memory stuff when you build a view

430
00:13:43,240 --> 00:13:48,400
all of the previous versions are already

431
00:13:46,030 --> 00:13:49,510
there so you just go to the vertex you

432
00:13:48,400 --> 00:13:51,010
pull what it would look like at that

433
00:13:49,510 --> 00:13:53,890
point of time if it was you know so

434
00:13:51,010 --> 00:13:55,569
you'd fill or initially and you then

435
00:13:53,890 --> 00:13:58,240
tour you can use that vertex as it

436
00:13:55,570 --> 00:14:00,670
exists in memory already for the stuff

437
00:13:58,240 --> 00:14:03,070
that's pulled back in from disk we're

438
00:14:00,670 --> 00:14:04,930
having a look at different snapshotting

439
00:14:03,070 --> 00:14:06,310
slash replay mechanics to make sure that

440
00:14:04,930 --> 00:14:08,050
they work properly so there'll be color

441
00:14:06,310 --> 00:14:09,819
side kind of idea of okay every X

442
00:14:08,050 --> 00:14:13,439
minutes you take a snapshot and then you

443
00:14:09,820 --> 00:14:15,700
have the replay of messages using occur

444
00:14:13,440 --> 00:14:16,750
sort of a message replay to Seraphin

445
00:14:15,700 --> 00:14:18,160
let's get back to exactly the point

446
00:14:16,750 --> 00:14:19,600
we're interested in and then what's the

447
00:14:18,160 --> 00:14:51,699
sort of heuristics around that so that's

448
00:14:19,600 --> 00:14:53,520
kind of the next step so we're having a

449
00:14:51,700 --> 00:14:55,420
look at perhaps some sort of like

450
00:14:53,520 --> 00:14:56,319
effects clock implementation or

451
00:14:55,420 --> 00:14:57,699
something where you get sort of

452
00:14:56,320 --> 00:14:59,500
different time stamps from all over the

453
00:14:57,700 --> 00:15:01,480
place coming in for the moment our

454
00:14:59,500 --> 00:15:04,060
assumption is that if you're attaching

455
00:15:01,480 --> 00:15:06,580
to an outside source that that's going

456
00:15:04,060 --> 00:15:08,170
to be a the time stamps coming in love

457
00:15:06,580 --> 00:15:09,880
time stamps were using so a lot of the

458
00:15:08,170 --> 00:15:11,110
ones or say for example on the social

459
00:15:09,880 --> 00:15:13,030
networks they tend to have you know

460
00:15:11,110 --> 00:15:14,170
that's done within their servers if for

461
00:15:13,030 --> 00:15:15,610
the cryptocurrency is that done when the

462
00:15:14,170 --> 00:15:16,750
block is published so for the most of

463
00:15:15,610 --> 00:15:18,130
our use cases we've kind of focused on

464
00:15:16,750 --> 00:15:19,960
that it'd be really interesting to see

465
00:15:18,130 --> 00:15:20,980
how we would do it but I think for the

466
00:15:19,960 --> 00:15:21,650
moment it's not going to be so much of

467
00:15:20,980 --> 00:15:23,960
it

468
00:15:21,650 --> 00:15:26,240
maybe you model some production in

469
00:15:23,960 --> 00:15:27,500
somebody sees okay what happens in a

470
00:15:26,240 --> 00:15:45,589
place of production order here and

471
00:15:27,500 --> 00:15:46,730
another person sitting in offices all

472
00:15:45,589 --> 00:15:47,870
right so yeah so yeah so that with

473
00:15:46,730 --> 00:15:51,410
perhaps in sort of roll back feature

474
00:15:47,870 --> 00:15:53,230
would be in like a ever sort of update

475
00:15:51,410 --> 00:15:55,699
that come in that shouldn't come in was

476
00:15:53,230 --> 00:15:57,080
so yeah so we could I don't know how we

477
00:15:55,700 --> 00:15:58,940
do it at the moment but it's definitely

478
00:15:57,080 --> 00:16:02,029
something to consider actually yeah or I

479
00:15:58,940 --> 00:16:03,890
will put in my notes to think things to

480
00:16:02,029 --> 00:16:28,490
tied in at some point you know thank you

481
00:16:03,890 --> 00:16:31,370
very much no so at the moment the the

482
00:16:28,490 --> 00:16:32,900
kind of view is that when you build if

483
00:16:31,370 --> 00:16:34,700
you're building of you which is kind of

484
00:16:32,900 --> 00:16:35,990
safe so either it's been watermark

485
00:16:34,700 --> 00:16:37,100
Tori's at previous point in time then

486
00:16:35,990 --> 00:16:39,560
it's kind of just a static graph and

487
00:16:37,100 --> 00:16:41,120
that's fine when it comes to the so if

488
00:16:39,560 --> 00:16:42,739
you have got like you're doing analysis

489
00:16:41,120 --> 00:16:44,029
so obviously it runs in parallel but if

490
00:16:42,740 --> 00:16:45,950
you're doing analysis on the most recent

491
00:16:44,029 --> 00:16:47,300
version you do have some degree of

492
00:16:45,950 --> 00:16:50,630
approximation we're having a look at

493
00:16:47,300 --> 00:16:51,979
like if we can kind of work out what

494
00:16:50,630 --> 00:16:52,970
that degrees or you know it's not

495
00:16:51,980 --> 00:16:54,650
something around but we've only really

496
00:16:52,970 --> 00:16:57,800
just I work on the analysis the last or

497
00:16:54,650 --> 00:16:59,270
six or nine months Soviet no it's it's

498
00:16:57,800 --> 00:17:02,319
definitely then the next sort of

499
00:16:59,270 --> 00:17:02,319
frontier a bit for sure

500
00:17:17,240 --> 00:17:24,810
so I guess the question is on can you

501
00:17:21,060 --> 00:17:26,490
use it for par finding in in dynamic

502
00:17:24,810 --> 00:17:29,550
environment so I think it depends on the

503
00:17:26,490 --> 00:17:32,010
sort of speed at which you're interested

504
00:17:29,550 --> 00:17:34,260
in so and of course the size of the

505
00:17:32,010 --> 00:17:35,850
graph so I think you probably could if

506
00:17:34,260 --> 00:17:37,650
you're going for like a you know if

507
00:17:35,850 --> 00:17:38,909
you're interested in maybe around you

508
00:17:37,650 --> 00:17:39,930
know a couple hundred milliseconds I

509
00:17:38,910 --> 00:17:41,250
don't know if you're if you're

510
00:17:39,930 --> 00:17:42,080
interested in sort of proper real time

511
00:17:41,250 --> 00:17:44,340
you know it needs to be sort of

512
00:17:42,080 --> 00:17:45,659
microsecond or sub millisecond it

513
00:17:44,340 --> 00:17:47,970
probably wouldn't return fast enough for

514
00:17:45,660 --> 00:17:49,020
something like that but then it's

515
00:17:47,970 --> 00:17:50,610
probably it's been more optimized for

516
00:17:49,020 --> 00:17:51,900
sort of general queries for out time

517
00:17:50,610 --> 00:17:53,610
like the ones we're showing so you kind

518
00:17:51,900 --> 00:17:55,220
of chunky and you leave it running and

519
00:17:53,610 --> 00:17:58,350
it kind of goes forever

520
00:17:55,220 --> 00:17:59,760
again if we can if we had the data to

521
00:17:58,350 --> 00:18:07,030
have it play around a bit I'd love to

522
00:17:59,760 --> 00:18:12,089
give you a go thank you very much

523
00:18:07,030 --> 00:18:12,089
[Applause]

