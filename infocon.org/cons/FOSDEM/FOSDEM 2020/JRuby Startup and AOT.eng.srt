1
00:00:05,920 --> 00:00:10,480
you're lucky people we have of course

2
00:00:07,520 --> 00:00:13,678
saved the best till last

3
00:00:10,480 --> 00:00:14,799
so if you could all sit down and open

4
00:00:13,679 --> 00:00:18,880
your ears for

5
00:00:14,799 --> 00:00:20,720
charles nettle and cole

6
00:00:18,880 --> 00:00:22,320
all right uh so we're going to get right

7
00:00:20,720 --> 00:00:24,160
into this or we plan for a little bit

8
00:00:22,320 --> 00:00:26,480
longer than 25 minutes so we'll

9
00:00:24,160 --> 00:00:27,519
we'll rail through it all right so i'm

10
00:00:26,480 --> 00:00:30,080
i'm tom anabol

11
00:00:27,519 --> 00:00:31,519
i'm charles nutter we've been working on

12
00:00:30,080 --> 00:00:33,680
jruby for

13
00:00:31,519 --> 00:00:34,879
15 years over 15 years a piece yeah

14
00:00:33,680 --> 00:00:36,960
crazy

15
00:00:34,880 --> 00:00:38,480
for people who don't know jruby is just

16
00:00:36,960 --> 00:00:40,399
another implementation of the ruby

17
00:00:38,480 --> 00:00:44,800
programming language and runtime

18
00:00:40,399 --> 00:00:46,719
we recommend it but why did we make it

19
00:00:44,800 --> 00:00:48,879
we made it to exploit some features that

20
00:00:46,719 --> 00:00:51,680
cruvi doesn't have like the ability to

21
00:00:48,879 --> 00:00:53,599
execute concurrently on native threads

22
00:00:51,680 --> 00:00:54,960
we can access java libraries from a ruby

23
00:00:53,600 --> 00:00:56,559
syntax

24
00:00:54,960 --> 00:00:58,000
and pretty much get all the good stuff

25
00:00:56,559 --> 00:01:00,959
that java has to provide

26
00:00:58,000 --> 00:01:00,960
we run fast

27
00:01:02,000 --> 00:01:05,519
but we have a problem startup time is

28
00:01:05,040 --> 00:01:07,439
not

29
00:01:05,519 --> 00:01:10,240
where we'd like it it's slower than c

30
00:01:07,439 --> 00:01:12,158
ruby ruby is constantly going type

31
00:01:10,240 --> 00:01:13,759
commands on the command line

32
00:01:12,159 --> 00:01:15,600
all the time that's the whole

33
00:01:13,760 --> 00:01:17,040
development process is all command line

34
00:01:15,600 --> 00:01:18,240
driven sound and for as long as we've

35
00:01:17,040 --> 00:01:20,640
been doing this we've been trying to

36
00:01:18,240 --> 00:01:20,640
solve it

37
00:01:21,360 --> 00:01:27,200
your keyboard sucks

38
00:01:24,640 --> 00:01:27,840
so here we're executing the simplest

39
00:01:27,200 --> 00:01:29,280
program

40
00:01:27,840 --> 00:01:30,880
we're going to evaluate the fixed num

41
00:01:29,280 --> 00:01:34,400
one um

42
00:01:30,880 --> 00:01:36,399
we by this period it load 415 ruby

43
00:01:34,400 --> 00:01:38,640
classes and modules

44
00:01:36,400 --> 00:01:42,320
over 300 of those come from ruby source

45
00:01:38,640 --> 00:01:44,960
that we have to parse and then interpret

46
00:01:42,320 --> 00:01:46,880
if we actually go under the covers now

47
00:01:44,960 --> 00:01:48,079
we're loading over six thousand java

48
00:01:46,880 --> 00:01:50,000
types

49
00:01:48,079 --> 00:01:52,880
and five thousand of those are from

50
00:01:50,000 --> 00:01:57,040
jruby uh our internals method handles

51
00:01:52,880 --> 00:01:57,039
interpreters instructions all of that

52
00:01:57,439 --> 00:02:01,119
ruby's also very dynamic so we can't

53
00:01:59,360 --> 00:02:03,600
look at a source file like this and go

54
00:02:01,119 --> 00:02:04,799
oh require normal oh we want to load a

55
00:02:03,600 --> 00:02:06,880
file called normal

56
00:02:04,799 --> 00:02:08,479
someone might have overridden that could

57
00:02:06,880 --> 00:02:08,959
be something else could be a different

58
00:02:08,479 --> 00:02:11,039
path

59
00:02:08,959 --> 00:02:13,120
we've tried speculatively trying to load

60
00:02:11,038 --> 00:02:16,238
these things in the background

61
00:02:13,120 --> 00:02:18,959
but you know we don't fully know it's

62
00:02:16,239 --> 00:02:21,360
also a path based language

63
00:02:18,959 --> 00:02:22,480
so when we do require normal we're going

64
00:02:21,360 --> 00:02:26,640
to just do a

65
00:02:22,480 --> 00:02:28,238
a lot of stats so basically it's like

66
00:02:26,640 --> 00:02:29,760
it's like if maven libraries were all

67
00:02:28,239 --> 00:02:32,000
distributed so they go all have their

68
00:02:29,760 --> 00:02:33,440
own loose file path on the file system

69
00:02:32,000 --> 00:02:35,519
and then you have to search through all

70
00:02:33,440 --> 00:02:37,359
3 000 of those file paths

71
00:02:35,519 --> 00:02:39,840
to find the one file that you're looking

72
00:02:37,360 --> 00:02:42,720
for so that's how it works in ruby

73
00:02:39,840 --> 00:02:44,080
it's a problem there are efforts to to

74
00:02:42,720 --> 00:02:45,680
try and cache some of this information

75
00:02:44,080 --> 00:02:47,200
but it's still early for that but of

76
00:02:45,680 --> 00:02:48,560
course when we're doing startup almost

77
00:02:47,200 --> 00:02:50,399
everything we're loading at this point

78
00:02:48,560 --> 00:02:51,200
is only going to get called or executed

79
00:02:50,400 --> 00:02:52,959
once

80
00:02:51,200 --> 00:02:54,238
and in java that's going to be stuck in

81
00:02:52,959 --> 00:02:56,560
the

82
00:02:54,239 --> 00:02:58,959
bytecode interpreter not many things are

83
00:02:56,560 --> 00:03:01,040
going to actually make it to c2

84
00:02:58,959 --> 00:03:02,720
and a good way of illustrating this is

85
00:03:01,040 --> 00:03:05,760
with the graph

86
00:03:02,720 --> 00:03:08,640
so this is e1 again with c ruby uh

87
00:03:05,760 --> 00:03:10,640
it takes almost no time when we run it

88
00:03:08,640 --> 00:03:12,159
this is an older slide

89
00:03:10,640 --> 00:03:13,760
but it was about 10 times slower when

90
00:03:12,159 --> 00:03:17,280
this was made

91
00:03:13,760 --> 00:03:20,319
now as an experiment we wrapped

92
00:03:17,280 --> 00:03:23,200
invoking a ruby run time into a loop

93
00:03:20,319 --> 00:03:24,798
and then timed it so at the 10 10th

94
00:03:23,200 --> 00:03:26,640
iteration we're starting to catch up to

95
00:03:24,799 --> 00:03:28,159
see ruby and by the 50th

96
00:03:26,640 --> 00:03:30,879
well we're pretty much done and we're

97
00:03:28,159 --> 00:03:32,560
beating it so if

98
00:03:30,879 --> 00:03:36,000
if we could get this performance right

99
00:03:32,560 --> 00:03:36,000
away we wouldn't have to have this talk

100
00:03:37,120 --> 00:03:41,760
um again this is kind of a duplicated

101
00:03:40,159 --> 00:03:43,760
slide doing the same thing

102
00:03:41,760 --> 00:03:46,399
gemlist is an important command for us

103
00:03:43,760 --> 00:03:47,840
because rubygems is the packaging system

104
00:03:46,400 --> 00:03:49,360
for ruby

105
00:03:47,840 --> 00:03:51,440
so it kind of shows that as we're doing

106
00:03:49,360 --> 00:03:52,159
a little bit more work we see ruby is

107
00:03:51,440 --> 00:03:54,000
going up

108
00:03:52,159 --> 00:03:57,920
but that ratio doesn't change a whole

109
00:03:54,000 --> 00:03:59,760
lot how slow we are compared to them

110
00:03:57,920 --> 00:04:01,040
so a little bit more background other

111
00:03:59,760 --> 00:04:03,359
implementations of course we're talking

112
00:04:01,040 --> 00:04:04,480
about c ruby or mri here the standard c

113
00:04:03,360 --> 00:04:06,560
implementation

114
00:04:04,480 --> 00:04:09,200
uh the peak performance is low it's the

115
00:04:06,560 --> 00:04:11,280
lowest of the available ruby runtimes

116
00:04:09,200 --> 00:04:12,879
but everything starts out hot so their

117
00:04:11,280 --> 00:04:13,680
parser starts out hot they have a very

118
00:04:12,879 --> 00:04:15,920
lightweight bar

119
00:04:13,680 --> 00:04:17,280
by code compiler and interpreter and so

120
00:04:15,920 --> 00:04:17,918
they get up and going fast they're

121
00:04:17,279 --> 00:04:19,679
loading

122
00:04:17,918 --> 00:04:21,120
all of those same ruby files and that's

123
00:04:19,680 --> 00:04:22,000
defining that same number of ruby

124
00:04:21,120 --> 00:04:25,759
classes

125
00:04:22,000 --> 00:04:25,759
but they're doing it about 0.1 seconds

126
00:04:26,080 --> 00:04:30,240
oh okay um the other one that is is

127
00:04:29,040 --> 00:04:32,960
interesting right now actually i don't

128
00:04:30,240 --> 00:04:34,320
need this i have this

129
00:04:32,960 --> 00:04:36,799
the other one that's interesting right

130
00:04:34,320 --> 00:04:38,479
now is uh truffle ruby which is a ruby

131
00:04:36,800 --> 00:04:40,240
implemented on top of truffle and grawl

132
00:04:38,479 --> 00:04:41,919
vm

133
00:04:40,240 --> 00:04:43,840
it's a very interesting project they

134
00:04:41,919 --> 00:04:46,159
show very good peak performance

135
00:04:43,840 --> 00:04:47,599
um but they also have this same sort of

136
00:04:46,160 --> 00:04:49,680
startup issue even more

137
00:04:47,600 --> 00:04:51,280
more so uh just because of the way

138
00:04:49,680 --> 00:04:52,720
they're designed they do a lot more

139
00:04:51,280 --> 00:04:55,440
interpretation at

140
00:04:52,720 --> 00:04:56,479
boot time um so they're they're solving

141
00:04:55,440 --> 00:04:57,680
it in some of the similar ways we'll

142
00:04:56,479 --> 00:05:00,880
talk a little bit more about them

143
00:04:57,680 --> 00:05:01,680
later all right oh and uh we have a few

144
00:05:00,880 --> 00:05:03,680
more minutes

145
00:05:01,680 --> 00:05:05,520
okay okay yeah so we're going to talk

146
00:05:03,680 --> 00:05:07,120
about some stuff we've done in the past

147
00:05:05,520 --> 00:05:08,560
some of this has stayed and some of his

148
00:05:07,120 --> 00:05:11,199
went

149
00:05:08,560 --> 00:05:12,240
um towards the beginning of the 2000s we

150
00:05:11,199 --> 00:05:15,199
had a simple

151
00:05:12,240 --> 00:05:16,639
ast interpreter so we just parse that

152
00:05:15,199 --> 00:05:18,800
into a stream of uh

153
00:05:16,639 --> 00:05:20,240
lexical tokens and build an outcheck

154
00:05:18,800 --> 00:05:24,639
syntax tree

155
00:05:20,240 --> 00:05:26,479
interpreter bounce around um

156
00:05:24,639 --> 00:05:28,960
what's that oh that should have been

157
00:05:26,479 --> 00:05:28,960
removed

158
00:05:29,199 --> 00:05:34,240
uh and startup was okay back then ruby

159
00:05:32,400 --> 00:05:35,520
was a much simpler environment it wasn't

160
00:05:34,240 --> 00:05:37,600
loading as much stuff

161
00:05:35,520 --> 00:05:39,840
and we might have still been two or

162
00:05:37,600 --> 00:05:41,360
three times slower but

163
00:05:39,840 --> 00:05:43,119
two or three times slower when it takes

164
00:05:41,360 --> 00:05:46,400
like 1.6 seconds

165
00:05:43,120 --> 00:05:46,400
it's not really a big deal

166
00:05:46,960 --> 00:05:50,000
the first optimization that's ever

167
00:05:48,960 --> 00:05:51,520
happened for startup

168
00:05:50,000 --> 00:05:54,320
happened before either one of us started

169
00:05:51,520 --> 00:05:54,320
on this project

170
00:05:54,479 --> 00:05:57,919
they would go and save the the luxor

171
00:05:57,360 --> 00:06:00,560
tokens

172
00:05:57,919 --> 00:06:02,880
to a file and then reload it back in

173
00:06:00,560 --> 00:06:04,639
java 1 4 days this was actually a pretty

174
00:06:02,880 --> 00:06:06,719
big optimization

175
00:06:04,639 --> 00:06:08,560
but by the time we supported java 5 and

176
00:06:06,720 --> 00:06:11,440
up we had optimized

177
00:06:08,560 --> 00:06:13,120
the lexer and parser and uh it just it

178
00:06:11,440 --> 00:06:14,719
got down to like three percent and we're

179
00:06:13,120 --> 00:06:17,199
like why are we supporting this

180
00:06:14,720 --> 00:06:20,960
weird sealization format it's just not

181
00:06:17,199 --> 00:06:23,600
worth it

182
00:06:20,960 --> 00:06:24,159
a bit more time passed and then uh the

183
00:06:23,600 --> 00:06:27,360
first

184
00:06:24,160 --> 00:06:29,199
jit compiler came and um

185
00:06:27,360 --> 00:06:30,960
this was about the same time that ruby

186
00:06:29,199 --> 00:06:32,479
was also improving its performance so we

187
00:06:30,960 --> 00:06:33,680
were kind of having that performance

188
00:06:32,479 --> 00:06:36,400
arms race

189
00:06:33,680 --> 00:06:37,680
or staying ahead of it anyways but this

190
00:06:36,400 --> 00:06:40,960
doesn't have any effect

191
00:06:37,680 --> 00:06:42,720
on short-lived processes because because

192
00:06:40,960 --> 00:06:44,719
by the time we actually jit something

193
00:06:42,720 --> 00:06:46,720
the process is already done right and

194
00:06:44,720 --> 00:06:48,479
this is to make it clear this is a jit

195
00:06:46,720 --> 00:06:50,639
from our internal instructions to

196
00:06:48,479 --> 00:06:51,520
jvm byte code which then the jvm would

197
00:06:50,639 --> 00:06:53,919
eventually jit

198
00:06:51,520 --> 00:06:55,520
so we're way way off of that tail of

199
00:06:53,919 --> 00:06:57,840
getting any sort of optimization

200
00:06:55,520 --> 00:07:00,159
startup wise but there was one benefit

201
00:06:57,840 --> 00:07:02,080
if you loaded a huge application

202
00:07:00,160 --> 00:07:03,599
things started to warm up and you

203
00:07:02,080 --> 00:07:05,919
started to get the payoff and then the

204
00:07:03,599 --> 00:07:09,440
startup time of a really long process

205
00:07:05,919 --> 00:07:09,440
uh got faster

206
00:07:09,520 --> 00:07:12,479
well if you can go and compile

207
00:07:10,800 --> 00:07:14,800
everything to java bytecode why not

208
00:07:12,479 --> 00:07:16,800
compile everything

209
00:07:14,800 --> 00:07:19,039
this experiment didn't really pan out

210
00:07:16,800 --> 00:07:21,440
too well uh

211
00:07:19,039 --> 00:07:23,440
with the uh verification on it was like

212
00:07:21,440 --> 00:07:24,080
10 times slower it was really really

213
00:07:23,440 --> 00:07:27,280
slow

214
00:07:24,080 --> 00:07:28,880
um if we disabled it it still was slower

215
00:07:27,280 --> 00:07:31,119
than just parsing ruby

216
00:07:28,880 --> 00:07:33,680
so well charlie's going to talk about

217
00:07:31,120 --> 00:07:36,560
that more later

218
00:07:33,680 --> 00:07:38,319
uh in our race for performance uh we

219
00:07:36,560 --> 00:07:38,960
created our own internal representation

220
00:07:38,319 --> 00:07:42,720
within a

221
00:07:38,960 --> 00:07:45,039
virtual instruction set

222
00:07:42,720 --> 00:07:46,080
we can do things like inline a method

223
00:07:45,039 --> 00:07:48,800
with a closure and

224
00:07:46,080 --> 00:07:49,199
and inline that back to this call site

225
00:07:48,800 --> 00:07:51,039
uh

226
00:07:49,199 --> 00:07:52,639
but uh because we're doing this extra

227
00:07:51,039 --> 00:07:53,840
building we actually made our startup

228
00:07:52,639 --> 00:07:57,280
time worse

229
00:07:53,840 --> 00:08:00,479
which sucks um but

230
00:07:57,280 --> 00:08:02,479
again if it was a really long process

231
00:08:00,479 --> 00:08:05,520
uh we continue to get a little bit

232
00:08:02,479 --> 00:08:05,520
faster in that case

233
00:08:06,639 --> 00:08:10,639
well we realized that the ast tree in

234
00:08:09,280 --> 00:08:13,679
memory was

235
00:08:10,639 --> 00:08:17,199
quite a bit smaller than our ir so uh

236
00:08:13,680 --> 00:08:18,960
we decided to get lazy and uh um

237
00:08:17,199 --> 00:08:21,599
until the first method was called we

238
00:08:18,960 --> 00:08:23,840
didn't actually build the ir itself

239
00:08:21,599 --> 00:08:25,520
it was mostly a memory optimization but

240
00:08:23,840 --> 00:08:27,840
it did actually improve startup a little

241
00:08:25,520 --> 00:08:27,840
bit

242
00:08:28,400 --> 00:08:34,240
ah we're back to serialization again uh

243
00:08:31,520 --> 00:08:34,799
google google summer of code uh project

244
00:08:34,240 --> 00:08:37,760
someone

245
00:08:34,799 --> 00:08:41,838
spiked this and we really were hoping it

246
00:08:37,760 --> 00:08:41,838
was gonna be magic

247
00:08:42,958 --> 00:08:48,319
turns out it's not we'll be talking

248
00:08:46,399 --> 00:08:49,920
about serialization more in this talk

249
00:08:48,320 --> 00:08:51,680
and parser and the compiler end up

250
00:08:49,920 --> 00:08:53,279
getting so hot that

251
00:08:51,680 --> 00:08:54,880
it really doesn't make any difference

252
00:08:53,279 --> 00:08:56,800
compared to serialization we still

253
00:08:54,880 --> 00:08:57,360
create all the same number of ir objects

254
00:08:56,800 --> 00:09:00,719
in the end

255
00:08:57,360 --> 00:09:02,640
so our most effective optimization we've

256
00:09:00,720 --> 00:09:03,440
ever made for startup time is to disable

257
00:09:02,640 --> 00:09:06,240
everything

258
00:09:03,440 --> 00:09:07,680
so just turn it all off we only use the

259
00:09:06,240 --> 00:09:10,800
our startup interpreter

260
00:09:07,680 --> 00:09:13,599
we disable c2 to this day this is still

261
00:09:10,800 --> 00:09:14,319
really difficult to beat c1 on just

262
00:09:13,600 --> 00:09:17,279
everything

263
00:09:14,320 --> 00:09:19,040
it's always the fastest but now we have

264
00:09:17,279 --> 00:09:20,720
to worry about people passing dash dash

265
00:09:19,040 --> 00:09:22,800
dev into their production environments

266
00:09:20,720 --> 00:09:24,240
yeah yeah it's not sending sending us

267
00:09:22,800 --> 00:09:26,240
benchmark results that aren't what they

268
00:09:24,240 --> 00:09:28,480
expected and like

269
00:09:26,240 --> 00:09:29,920
just this client server all over again

270
00:09:28,480 --> 00:09:31,440
but you can see

271
00:09:29,920 --> 00:09:33,199
doing this gem list again that it's

272
00:09:31,440 --> 00:09:36,399
about 33 faster

273
00:09:33,200 --> 00:09:38,560
so it was a pretty big win uh in the

274
00:09:36,399 --> 00:09:41,839
past we played with native compilers

275
00:09:38,560 --> 00:09:44,800
uh excelsior jets the one that i had

276
00:09:41,839 --> 00:09:45,839
some experience with and it it got

277
00:09:44,800 --> 00:09:48,160
better in dash dash

278
00:09:45,839 --> 00:09:49,519
dev but again it's one of these things

279
00:09:48,160 --> 00:09:51,839
where we didn't really want to go that

280
00:09:49,519 --> 00:09:53,519
extra step but something else to support

281
00:09:51,839 --> 00:09:55,760
and then it was also a company may they

282
00:09:53,519 --> 00:09:57,600
rest in peace um

283
00:09:55,760 --> 00:10:00,080
but uh we'll talk about native compilers

284
00:09:57,600 --> 00:10:00,080
later too

285
00:10:00,240 --> 00:10:04,240
okay so what startup experience i'm

286
00:10:03,120 --> 00:10:06,160
doing pre-booting right

287
00:10:04,240 --> 00:10:07,839
you've got a mic yeah oh right you want

288
00:10:06,160 --> 00:10:09,040
a soundtrack no i want to i want i want

289
00:10:07,839 --> 00:10:10,720
everyone to really hear me okay you want

290
00:10:09,040 --> 00:10:13,680
to sound twice as good

291
00:10:10,720 --> 00:10:15,120
okay okay i'll use this one it's fine um

292
00:10:13,680 --> 00:10:16,239
yeah so now we're going to go over some

293
00:10:15,120 --> 00:10:17,279
of the current experiments that we've

294
00:10:16,240 --> 00:10:19,200
been working on

295
00:10:17,279 --> 00:10:20,800
things that are still sort of active

296
00:10:19,200 --> 00:10:23,279
projects um

297
00:10:20,800 --> 00:10:24,880
we'll just jump right into those here so

298
00:10:23,279 --> 00:10:27,360
pre-booting uh this is

299
00:10:24,880 --> 00:10:29,600
similar to what like a scala compiler or

300
00:10:27,360 --> 00:10:30,240
gradle build will spin up a background

301
00:10:29,600 --> 00:10:32,000
process

302
00:10:30,240 --> 00:10:34,560
and then you throw more work at it but

303
00:10:32,000 --> 00:10:36,240
we we have some specific things for

304
00:10:34,560 --> 00:10:38,000
rails and people do use those

305
00:10:36,240 --> 00:10:40,079
but we've tried some general purpose

306
00:10:38,000 --> 00:10:41,760
options uh the first one was nail gun

307
00:10:40,079 --> 00:10:45,760
which you start up a background

308
00:10:41,760 --> 00:10:46,079
damon jvm and then you continually throw

309
00:10:45,760 --> 00:10:47,920
new

310
00:10:46,079 --> 00:10:50,000
operations at it they run in their own

311
00:10:47,920 --> 00:10:52,000
class loader they're isolated as well as

312
00:10:50,000 --> 00:10:54,240
class loaders can isolate things

313
00:10:52,000 --> 00:10:55,519
uh but it it really didn't work well

314
00:10:54,240 --> 00:10:57,600
with the way rubyists

315
00:10:55,519 --> 00:10:59,279
write these applications they would spin

316
00:10:57,600 --> 00:11:01,040
up threads and expect them to go away

317
00:10:59,279 --> 00:11:03,439
when they're done

318
00:11:01,040 --> 00:11:04,560
they would allocate resources and maybe

319
00:11:03,440 --> 00:11:05,839
walk away because it's going to be a

320
00:11:04,560 --> 00:11:07,680
short run process

321
00:11:05,839 --> 00:11:10,560
stuff like that so a lot of resource

322
00:11:07,680 --> 00:11:12,719
issues never really kind of panned out

323
00:11:10,560 --> 00:11:14,800
drip is a little bit better not a lot of

324
00:11:12,720 --> 00:11:15,440
folks know about drip drip basically

325
00:11:14,800 --> 00:11:18,240
will just

326
00:11:15,440 --> 00:11:19,519
start the next jvm so you run a command

327
00:11:18,240 --> 00:11:21,680
there's nothing available

328
00:11:19,519 --> 00:11:22,880
it'll start the one you're targeting and

329
00:11:21,680 --> 00:11:24,880
a second one

330
00:11:22,880 --> 00:11:26,399
to get ready for the next command and

331
00:11:24,880 --> 00:11:27,920
you can have it you can have a stack of

332
00:11:26,399 --> 00:11:29,360
these so you can have up to you know

333
00:11:27,920 --> 00:11:30,880
five or ten or whatever

334
00:11:29,360 --> 00:11:32,160
and then as you throw more commands at

335
00:11:30,880 --> 00:11:33,279
him you've already got a jvm up and

336
00:11:32,160 --> 00:11:35,279
going

337
00:11:33,279 --> 00:11:37,200
but it's also got to do a lot of tty

338
00:11:35,279 --> 00:11:38,480
juggling to hook you up to that process

339
00:11:37,200 --> 00:11:40,079
correctly

340
00:11:38,480 --> 00:11:42,480
and these instances in the background

341
00:11:40,079 --> 00:11:44,160
will eventually pick up stale code

342
00:11:42,480 --> 00:11:45,680
and you'll have to say oh wipe out all

343
00:11:44,160 --> 00:11:46,880
of them and then i'm back to slow start

344
00:11:45,680 --> 00:11:48,479
up again so

345
00:11:46,880 --> 00:11:50,959
kind of more problematic than it was

346
00:11:48,480 --> 00:11:51,279
actually worth we are interested now in

347
00:11:50,959 --> 00:11:53,359
the

348
00:11:51,279 --> 00:11:54,959
the using the checkpoint and restore

349
00:11:53,360 --> 00:11:56,959
stuff on linux

350
00:11:54,959 --> 00:11:58,319
some folks at red hat are experimenting

351
00:11:56,959 --> 00:11:59,680
with this but i think it's still kind of

352
00:11:58,320 --> 00:12:01,839
early days we haven't had a chance to

353
00:11:59,680 --> 00:12:05,199
play with it much yet so that's kind of

354
00:12:01,839 --> 00:12:09,120
where we stand on pre-booting stuff

355
00:12:05,200 --> 00:12:10,880
so we revisited uh serialization

356
00:12:09,120 --> 00:12:11,600
recently and one thing that we always

357
00:12:10,880 --> 00:12:14,720
wanted to do

358
00:12:11,600 --> 00:12:17,120
was lazily load the instructions just

359
00:12:14,720 --> 00:12:20,160
like we were being lazy with the methods

360
00:12:17,120 --> 00:12:22,399
with ir build versus ast

361
00:12:20,160 --> 00:12:24,319
but there was a weird artifact in our

362
00:12:22,399 --> 00:12:25,040
implementation that we solved a week or

363
00:12:24,320 --> 00:12:27,279
two ago

364
00:12:25,040 --> 00:12:29,839
so now that works so let's see how

365
00:12:27,279 --> 00:12:32,480
that's turning out

366
00:12:29,839 --> 00:12:33,680
um i don't know why these are built out

367
00:12:32,480 --> 00:12:37,040
ah

368
00:12:33,680 --> 00:12:39,199
so here uh

369
00:12:37,040 --> 00:12:41,040
if we look at old serialization to new

370
00:12:39,200 --> 00:12:44,399
serialization we got a good bump

371
00:12:41,040 --> 00:12:46,719
by being lazy um it's fine

372
00:12:44,399 --> 00:12:48,160
uh and it's actually now went from being

373
00:12:46,720 --> 00:12:49,120
a little bit slower to a little bit

374
00:12:48,160 --> 00:12:51,120
faster

375
00:12:49,120 --> 00:12:52,240
this is only 20 gems so this is doing

376
00:12:51,120 --> 00:12:54,240
virtually no work

377
00:12:52,240 --> 00:12:56,480
it's kind of a worst case of being

378
00:12:54,240 --> 00:12:59,120
something useful

379
00:12:56,480 --> 00:13:00,079
but now if we go to 2000 gems which

380
00:12:59,120 --> 00:13:04,720
happens to be my

381
00:13:00,079 --> 00:13:04,719
personal work dev uh oh one more

382
00:13:05,120 --> 00:13:09,040
we can see that it still improves and it

383
00:13:07,600 --> 00:13:09,760
still holds true but it's getting a

384
00:13:09,040 --> 00:13:12,880
little less

385
00:13:09,760 --> 00:13:14,399
interesting so is this worthwhile right

386
00:13:12,880 --> 00:13:16,240
at this point enough stuff starts to jit

387
00:13:14,399 --> 00:13:17,839
at the jvm that we don't get as much of

388
00:13:16,240 --> 00:13:20,399
a gain off of it we suspect

389
00:13:17,839 --> 00:13:22,000
and so on this last one it's it's going

390
00:13:20,399 --> 00:13:23,680
into rails console

391
00:13:22,000 --> 00:13:26,320
this is doing multiple indications of

392
00:13:23,680 --> 00:13:27,920
ruby and you can see that serialization

393
00:13:26,320 --> 00:13:29,040
really isn't playing any role at all

394
00:13:27,920 --> 00:13:31,519
here

395
00:13:29,040 --> 00:13:32,560
so there's a different issue with

396
00:13:31,519 --> 00:13:35,920
startup there

397
00:13:32,560 --> 00:13:38,239
but this really um makes

398
00:13:35,920 --> 00:13:39,279
us not know whether we want to continue

399
00:13:38,240 --> 00:13:42,480
this or not

400
00:13:39,279 --> 00:13:44,079
but when we came to europe i noticed

401
00:13:42,480 --> 00:13:46,000
that there was a constant pool index

402
00:13:44,079 --> 00:13:46,719
that we weren't using in our format so

403
00:13:46,000 --> 00:13:50,079
i'm like oh

404
00:13:46,720 --> 00:13:52,880
let's add some constant pooling so uh

405
00:13:50,079 --> 00:13:55,599
i'm saving symbols to a pool this

406
00:13:52,880 --> 00:13:59,120
prevents having to go and decode

407
00:13:55,600 --> 00:14:00,079
a bunch of bytes for the symbol name and

408
00:13:59,120 --> 00:14:01,519
it's encoding

409
00:14:00,079 --> 00:14:03,599
and it doesn't have to look up in our

410
00:14:01,519 --> 00:14:07,440
global symbol table

411
00:14:03,600 --> 00:14:09,600
uh so and basically we just have a new

412
00:14:07,440 --> 00:14:12,399
box here

413
00:14:09,600 --> 00:14:13,920
uh it just got a little bit faster so

414
00:14:12,399 --> 00:14:15,040
it's it's encouraging

415
00:14:13,920 --> 00:14:16,800
because there's a lot of other stuff

416
00:14:15,040 --> 00:14:19,040
that we could put in there i'm just

417
00:14:16,800 --> 00:14:23,199
going to pop through these

418
00:14:19,040 --> 00:14:27,599
quick and you see the same approximate

419
00:14:23,199 --> 00:14:30,479
ratio so oh i'm always one off on that

420
00:14:27,600 --> 00:14:31,839
so as you'll see later on there's other

421
00:14:30,480 --> 00:14:32,160
things that might be more exciting than

422
00:14:31,839 --> 00:14:33,839
this

423
00:14:32,160 --> 00:14:35,760
yeah there's there's more to do here too

424
00:14:33,839 --> 00:14:38,079
this is still doing a constant pool

425
00:14:35,760 --> 00:14:38,959
per scope uh a constant pool for an

426
00:14:38,079 --> 00:14:41,120
entire file

427
00:14:38,959 --> 00:14:42,880
would make some sense you try and share

428
00:14:41,120 --> 00:14:45,199
those symbols as much as possible

429
00:14:42,880 --> 00:14:46,720
yeah we can we're going to keep chipping

430
00:14:45,199 --> 00:14:48,639
away and it might become worth it

431
00:14:46,720 --> 00:14:51,279
right because it works really well for

432
00:14:48,639 --> 00:14:53,120
short really short commands

433
00:14:51,279 --> 00:14:54,720
okay so returning back to the jvm

434
00:14:53,120 --> 00:14:58,000
bytecode compiler

435
00:14:54,720 --> 00:14:59,920
because of the how much it didn't help

436
00:14:58,000 --> 00:15:01,760
us in the original the older version of

437
00:14:59,920 --> 00:15:04,719
jruby when we went to our nine dot

438
00:15:01,760 --> 00:15:05,519
x series uh we thought we won't even

439
00:15:04,720 --> 00:15:08,639
bother with it

440
00:15:05,519 --> 00:15:10,399
uh we wrote a new dot class compiler

441
00:15:08,639 --> 00:15:12,240
that well all it did it didn't actually

442
00:15:10,399 --> 00:15:13,839
compile bytecode it just took the

443
00:15:12,240 --> 00:15:16,000
serialized ir form

444
00:15:13,839 --> 00:15:17,839
format stuffed it into a bunch of

445
00:15:16,000 --> 00:15:19,680
constants in the constant pool

446
00:15:17,839 --> 00:15:21,680
and then when you boot the class up it

447
00:15:19,680 --> 00:15:22,239
just deserializes the ir and starts

448
00:15:21,680 --> 00:15:23,920
running it

449
00:15:22,240 --> 00:15:25,519
so it was a clever way to get a dot

450
00:15:23,920 --> 00:15:27,439
clasp without actually emitting any byte

451
00:15:25,519 --> 00:15:29,440
code

452
00:15:27,440 --> 00:15:31,279
but we wanted to revisit actually

453
00:15:29,440 --> 00:15:32,399
emitting jvm byte code doing the compile

454
00:15:31,279 --> 00:15:33,759
ahead of time

455
00:15:32,399 --> 00:15:36,160
so normally the bytecode compiler is

456
00:15:33,759 --> 00:15:38,480
used as a jit we've used this same

457
00:15:36,160 --> 00:15:40,000
call threshold for years and it's mostly

458
00:15:38,480 --> 00:15:42,079
served as well if method gets

459
00:15:40,000 --> 00:15:44,160
called 50 times or a block gets called

460
00:15:42,079 --> 00:15:44,959
50 times then we will turn it into jv

461
00:15:44,160 --> 00:15:48,079
and byte code

462
00:15:44,959 --> 00:15:51,279
and eventually the jvm will continue to

463
00:15:48,079 --> 00:15:51,279
optimize it from there

464
00:15:52,800 --> 00:15:56,639
but it also could certainly support

465
00:15:54,720 --> 00:15:58,079
compiling an entire script uh one of the

466
00:15:56,639 --> 00:15:59,680
things we learned was that a lot of

467
00:15:58,079 --> 00:16:02,000
people love to benchmark stuff

468
00:15:59,680 --> 00:16:02,800
at the root of the main file that

469
00:16:02,000 --> 00:16:05,199
they're running

470
00:16:02,800 --> 00:16:06,560
so if we don't compile the entire file

471
00:16:05,199 --> 00:16:08,160
you'll get a loop that won't run we

472
00:16:06,560 --> 00:16:09,758
don't have any on stack replacement and

473
00:16:08,160 --> 00:16:11,839
stuff it will never actually optimize

474
00:16:09,759 --> 00:16:13,279
so we always compile the target script

475
00:16:11,839 --> 00:16:14,880
completely

476
00:16:13,279 --> 00:16:17,360
expanding that to the rest of the files

477
00:16:14,880 --> 00:16:20,000
that are loaded was not a big leap

478
00:16:17,360 --> 00:16:21,839
so goals for this obviously we jruby and

479
00:16:20,000 --> 00:16:23,199
jvm initialization about the same we're

480
00:16:21,839 --> 00:16:25,600
not going to be able to do much to

481
00:16:23,199 --> 00:16:26,240
reduce that cost but hopefully we can

482
00:16:25,600 --> 00:16:28,079
get rid of

483
00:16:26,240 --> 00:16:29,279
the reading of the file parsing it

484
00:16:28,079 --> 00:16:31,839
compiling the ir

485
00:16:29,279 --> 00:16:33,199
optimizing the ir interpreting it we can

486
00:16:31,839 --> 00:16:35,120
launch ourselves straight into the

487
00:16:33,199 --> 00:16:38,079
bytecode execution

488
00:16:35,120 --> 00:16:40,320
maybe reduce the number of jvm classes

489
00:16:38,079 --> 00:16:41,758
probably reduce the amount of heat used

490
00:16:40,320 --> 00:16:43,839
because we don't have all of our ir

491
00:16:41,759 --> 00:16:45,680
stuff that we have to stand up

492
00:16:43,839 --> 00:16:47,839
and we mostly will get to the byte code

493
00:16:45,680 --> 00:16:51,839
eventually anyway so it's kind of wasted

494
00:16:47,839 --> 00:16:53,199
extra space but

495
00:16:51,839 --> 00:16:54,720
unfortunately it hasn't worked out as

496
00:16:53,199 --> 00:16:56,000
well we kind of expected that it would

497
00:16:54,720 --> 00:16:57,920
be the same thing as we had

498
00:16:56,000 --> 00:16:59,839
seen before so here's just some output

499
00:16:57,920 --> 00:17:01,120
from these in the normal jit mode with

500
00:16:59,839 --> 00:17:03,600
running jruby you'll see

501
00:17:01,120 --> 00:17:05,679
only the target script the main script

502
00:17:03,600 --> 00:17:07,599
actually compiles ahead of time

503
00:17:05,679 --> 00:17:09,439
everything else at run time it'll

504
00:17:07,599 --> 00:17:10,240
eventually compile once it's been hit

505
00:17:09,439 --> 00:17:12,079
enough

506
00:17:10,240 --> 00:17:13,520
uh down in the bottom just change the

507
00:17:12,079 --> 00:17:15,918
flag at a x

508
00:17:13,520 --> 00:17:17,280
plus c which forces every script to

509
00:17:15,919 --> 00:17:18,000
completely compile before it start

510
00:17:17,280 --> 00:17:20,480
executing

511
00:17:18,000 --> 00:17:21,359
then we can see lots of scripts come

512
00:17:20,480 --> 00:17:24,000
through

513
00:17:21,359 --> 00:17:25,119
if we combine this with the new aot mode

514
00:17:24,000 --> 00:17:27,599
which is compile

515
00:17:25,119 --> 00:17:28,479
cache classes up at the top turn on some

516
00:17:27,599 --> 00:17:30,000
logging

517
00:17:28,480 --> 00:17:31,679
then we get the whole list of the

518
00:17:30,000 --> 00:17:32,000
scripts that are being pre-compiled

519
00:17:31,679 --> 00:17:34,080
dumped

520
00:17:32,000 --> 00:17:36,000
into a cache directory and then the next

521
00:17:34,080 --> 00:17:39,678
time they can be loaded directly from

522
00:17:36,000 --> 00:17:41,039
the class files so does it work well it

523
00:17:39,679 --> 00:17:42,799
turns out that we're dealing with a

524
00:17:41,039 --> 00:17:44,080
tremendous amount of class files here as

525
00:17:42,799 --> 00:17:46,320
you would expect

526
00:17:44,080 --> 00:17:47,360
just generating a piece of a rails app

527
00:17:46,320 --> 00:17:49,918
like generating a

528
00:17:47,360 --> 00:17:51,120
a blog post the blog typical blog post

529
00:17:49,919 --> 00:17:53,520
thing that people do

530
00:17:51,120 --> 00:17:54,320
uh produces over 1200 class files it's

531
00:17:53,520 --> 00:17:57,440
loading

532
00:17:54,320 --> 00:17:58,240
at least 1200 1200 to 1400 uh ruby

533
00:17:57,440 --> 00:18:00,160
sources

534
00:17:58,240 --> 00:18:02,480
those all get dumped into giant class

535
00:18:00,160 --> 00:18:04,880
files 80 megabytes of

536
00:18:02,480 --> 00:18:06,000
classes as a result of this one rails

537
00:18:04,880 --> 00:18:08,240
command

538
00:18:06,000 --> 00:18:10,000
uh and then almost none of this jits so

539
00:18:08,240 --> 00:18:10,559
we're loading all of this byte code into

540
00:18:10,000 --> 00:18:13,760
the system

541
00:18:10,559 --> 00:18:14,080
running through it once and then that's

542
00:18:13,760 --> 00:18:15,520
it

543
00:18:14,080 --> 00:18:18,000
we don't we don't run it ever again for

544
00:18:15,520 --> 00:18:19,280
a short command uh so the first thing

545
00:18:18,000 --> 00:18:20,240
that i started doing to try and explore

546
00:18:19,280 --> 00:18:21,840
this was to trace

547
00:18:20,240 --> 00:18:23,760
the actual byte codes that are being

548
00:18:21,840 --> 00:18:24,559
executed i don't know if anybody's

549
00:18:23,760 --> 00:18:27,039
played with this

550
00:18:24,559 --> 00:18:28,879
this is a lot of fun to look at if you

551
00:18:27,039 --> 00:18:30,400
run on the debug build with the trace

552
00:18:28,880 --> 00:18:32,080
byte codes option

553
00:18:30,400 --> 00:18:34,000
you can see all of the byte codes as

554
00:18:32,080 --> 00:18:35,678
they're executed by the jvm's bytecode

555
00:18:34,000 --> 00:18:37,600
interpreter

556
00:18:35,679 --> 00:18:38,960
if you want to see them after they if

557
00:18:37,600 --> 00:18:41,600
you want to force it to not

558
00:18:38,960 --> 00:18:42,480
jit you'll see all of whatever would run

559
00:18:41,600 --> 00:18:44,080
but once they jit

560
00:18:42,480 --> 00:18:46,000
normally they will not show up in this

561
00:18:44,080 --> 00:18:48,000
trace anymore so it's a good way to see

562
00:18:46,000 --> 00:18:49,919
what cold byte code is executing how

563
00:18:48,000 --> 00:18:52,799
much a cold bytecode is executing

564
00:18:49,919 --> 00:18:53,280
i'm using uh clause's byte stacks tool

565
00:18:52,799 --> 00:18:55,280
here

566
00:18:53,280 --> 00:18:56,639
which you will take that trace bytecode

567
00:18:55,280 --> 00:18:58,240
outfit output

568
00:18:56,640 --> 00:18:59,679
and we'll turn it into a flame graph of

569
00:18:58,240 --> 00:19:01,520
your application so you can see

570
00:18:59,679 --> 00:19:03,120
where most of the cold byte code is

571
00:19:01,520 --> 00:19:04,639
executing

572
00:19:03,120 --> 00:19:06,559
um yes so we're looking for cold

573
00:19:04,640 --> 00:19:09,120
execution mostly here

574
00:19:06,559 --> 00:19:10,080
so here is cold byte codes for dash e1

575
00:19:09,120 --> 00:19:12,879
this is split up

576
00:19:10,080 --> 00:19:14,720
in uh jvm initialization which is the

577
00:19:12,880 --> 00:19:17,280
the java part of modules that

578
00:19:14,720 --> 00:19:19,600
that first runs to get things going uh

579
00:19:17,280 --> 00:19:21,280
the base jruby which is defining all of

580
00:19:19,600 --> 00:19:23,600
our core classes mostly

581
00:19:21,280 --> 00:19:25,840
uh loading up jruby libraries which is

582
00:19:23,600 --> 00:19:26,959
rubygems and any additional plugins and

583
00:19:25,840 --> 00:19:29,199
whatnot you've got

584
00:19:26,960 --> 00:19:30,640
and then other is just additional jruby

585
00:19:29,200 --> 00:19:33,520
stuff like setting up our native

586
00:19:30,640 --> 00:19:35,200
access layer and things um not really

587
00:19:33,520 --> 00:19:37,918
bytecode sensitive it's mostly

588
00:19:35,200 --> 00:19:38,960
callouts to native code and that's just

589
00:19:37,919 --> 00:19:41,919
e1

590
00:19:38,960 --> 00:19:42,960
just the hello world and you can see the

591
00:19:41,919 --> 00:19:45,120
with the cache byte

592
00:19:42,960 --> 00:19:46,640
codes we're actually running more cold

593
00:19:45,120 --> 00:19:48,159
at this point

594
00:19:46,640 --> 00:19:50,240
rather than getting the gain that we

595
00:19:48,160 --> 00:19:50,880
hoped where we would get into hot code

596
00:19:50,240 --> 00:19:54,160
faster

597
00:19:50,880 --> 00:19:56,160
hot for us is actually cold for the jvm

598
00:19:54,160 --> 00:19:58,320
so it doesn't give us much of a gain

599
00:19:56,160 --> 00:20:00,160
similarly on gem list we can see that

600
00:19:58,320 --> 00:20:02,320
the ruby libraries portion

601
00:20:00,160 --> 00:20:03,280
and the actual command being executed

602
00:20:02,320 --> 00:20:06,080
gem list

603
00:20:03,280 --> 00:20:07,360
now are they have more cold code they

604
00:20:06,080 --> 00:20:10,000
actually slow things down

605
00:20:07,360 --> 00:20:10,719
generally so we went back and looked at

606
00:20:10,000 --> 00:20:12,880
this

607
00:20:10,720 --> 00:20:14,480
uh and realized that we were still using

608
00:20:12,880 --> 00:20:16,240
a lot of invoke dynamic in

609
00:20:14,480 --> 00:20:18,080
a whole bunch of byte code that only ran

610
00:20:16,240 --> 00:20:20,159
once

611
00:20:18,080 --> 00:20:21,678
that really is ends up being a waste of

612
00:20:20,159 --> 00:20:23,520
time because all of the

613
00:20:21,679 --> 00:20:24,880
all the byte code to bootstrap these

614
00:20:23,520 --> 00:20:26,559
these uh call sites

615
00:20:24,880 --> 00:20:28,400
all the lambda forms that are inside

616
00:20:26,559 --> 00:20:29,840
method handles they would all execute

617
00:20:28,400 --> 00:20:31,520
through one time

618
00:20:29,840 --> 00:20:33,039
and then never be run again so they'd

619
00:20:31,520 --> 00:20:35,520
never jit

620
00:20:33,039 --> 00:20:37,760
we really saw this if i turn dash x into

621
00:20:35,520 --> 00:20:39,679
on it would use a tremendous amount more

622
00:20:37,760 --> 00:20:41,039
byte code because of all those lambda

623
00:20:39,679 --> 00:20:42,320
forms that just keep churning and

624
00:20:41,039 --> 00:20:44,240
churning and churning and never turn

625
00:20:42,320 --> 00:20:47,200
into native code

626
00:20:44,240 --> 00:20:49,120
so did a modification of this for aot

627
00:20:47,200 --> 00:20:51,039
mode

628
00:20:49,120 --> 00:20:53,039
that basically uses no invoke dynamic at

629
00:20:51,039 --> 00:20:54,799
all it's a great feature for us we love

630
00:20:53,039 --> 00:20:57,760
it for peak performance

631
00:20:54,799 --> 00:20:58,480
for cold execution it is really not not

632
00:20:57,760 --> 00:20:59,840
that great

633
00:20:58,480 --> 00:21:01,520
there's a lot of issues trying to get

634
00:20:59,840 --> 00:21:03,760
stuff to run at cold

635
00:21:01,520 --> 00:21:05,039
i know there's work to try and get uh

636
00:21:03,760 --> 00:21:06,799
lambda forms and

637
00:21:05,039 --> 00:21:08,799
and uh method handles and what not to

638
00:21:06,799 --> 00:21:10,400
compile in with j-link and stuff

639
00:21:08,799 --> 00:21:12,720
um we haven't started playing with any

640
00:21:10,400 --> 00:21:15,440
of the the work being done there

641
00:21:12,720 --> 00:21:16,000
um so this uh these the demos i've got

642
00:21:15,440 --> 00:21:18,400
here the

643
00:21:16,000 --> 00:21:20,320
the results i have here still are using

644
00:21:18,400 --> 00:21:22,880
invoke dynamic for constant lookup

645
00:21:20,320 --> 00:21:23,360
uh but almost everything else is just

646
00:21:22,880 --> 00:21:25,440
using

647
00:21:23,360 --> 00:21:27,039
the equivalent byte code with a little

648
00:21:25,440 --> 00:21:30,080
bit less dynamic a little bit less

649
00:21:27,039 --> 00:21:33,039
optimizable but less less

650
00:21:30,080 --> 00:21:34,158
cold by code to run so we did get a good

651
00:21:33,039 --> 00:21:36,240
reduction here

652
00:21:34,159 --> 00:21:38,080
uh this is just a very slight reduction

653
00:21:36,240 --> 00:21:40,480
from the original cache version

654
00:21:38,080 --> 00:21:42,080
more interestingly uh in the case of

655
00:21:40,480 --> 00:21:44,080
running a larger command

656
00:21:42,080 --> 00:21:46,000
now we actually start to see that we are

657
00:21:44,080 --> 00:21:48,240
running fewer cold byte codes

658
00:21:46,000 --> 00:21:49,120
and we do get a little bit of a boost

659
00:21:48,240 --> 00:21:50,799
from

660
00:21:49,120 --> 00:21:53,039
pre-caching that so we can shrink the

661
00:21:50,799 --> 00:21:53,600
size of that byte code maybe emit less

662
00:21:53,039 --> 00:21:57,039
efficient

663
00:21:53,600 --> 00:21:58,799
simpler byte code for uh for the class

664
00:21:57,039 --> 00:22:01,280
bodies for the script body

665
00:21:58,799 --> 00:22:03,360
uh but then use invoke dynamic for the

666
00:22:01,280 --> 00:22:04,799
methods and blocks that are called a lot

667
00:22:03,360 --> 00:22:07,918
i think we can get a kind of a happy

668
00:22:04,799 --> 00:22:07,918
medium between those two

669
00:22:08,960 --> 00:22:14,159
okay so all of these things combined we

670
00:22:12,240 --> 00:22:16,159
we've been playing with interpreter

671
00:22:14,159 --> 00:22:18,240
modes and jit and aot

672
00:22:16,159 --> 00:22:19,280
uh and then there's all these jvm flags

673
00:22:18,240 --> 00:22:21,440
that are coming up and

674
00:22:19,280 --> 00:22:22,320
and other options uh so we wanted to try

675
00:22:21,440 --> 00:22:24,880
and assemble

676
00:22:22,320 --> 00:22:26,960
a bunch of these together just to see

677
00:22:24,880 --> 00:22:29,840
what the best startup we could get with

678
00:22:26,960 --> 00:22:32,720
all of our current tricks

679
00:22:29,840 --> 00:22:34,639
so here this is gem list with just 20

680
00:22:32,720 --> 00:22:37,120
gems so a fairly small

681
00:22:34,640 --> 00:22:38,640
ruby command running here is our

682
00:22:37,120 --> 00:22:41,918
original

683
00:22:38,640 --> 00:22:43,120
dev result here is throwing app cds at

684
00:22:41,919 --> 00:22:45,200
it so this is

685
00:22:43,120 --> 00:22:46,158
helping us all of those jvm classes

686
00:22:45,200 --> 00:22:48,480
we're loading up

687
00:22:46,159 --> 00:22:50,400
uh it manages to trim some time off of

688
00:22:48,480 --> 00:22:53,520
there

689
00:22:50,400 --> 00:22:56,880
this is with a lazy serialization

690
00:22:53,520 --> 00:22:58,879
so that's the serialized ir now we're

691
00:22:56,880 --> 00:23:00,720
we're kind of getting a similar gain but

692
00:22:58,880 --> 00:23:03,760
lost a little bit of time

693
00:23:00,720 --> 00:23:06,159
uh 1.71 here is using the

694
00:23:03,760 --> 00:23:08,000
bytecode cache so again the aot to

695
00:23:06,159 --> 00:23:09,919
bytecode is just not really a win

696
00:23:08,000 --> 00:23:11,440
for startup in any way that we've found

697
00:23:09,919 --> 00:23:13,919
so far

698
00:23:11,440 --> 00:23:15,760
and then even appcs with our precached

699
00:23:13,919 --> 00:23:17,600
code it's still just too much cold

700
00:23:15,760 --> 00:23:19,039
bytecode executing so it's not going to

701
00:23:17,600 --> 00:23:19,439
get us the startup that we're looking

702
00:23:19,039 --> 00:23:22,000
for

703
00:23:19,440 --> 00:23:24,400
but we can do other things with it later

704
00:23:22,000 --> 00:23:26,880
here on a larger

705
00:23:24,400 --> 00:23:28,480
example gem list with 2 000 gems and it

706
00:23:26,880 --> 00:23:32,240
has to read through all of them

707
00:23:28,480 --> 00:23:35,120
here's our dev app cds gets us there

708
00:23:32,240 --> 00:23:36,720
with the lazy serialization is slightly

709
00:23:35,120 --> 00:23:38,559
better than that

710
00:23:36,720 --> 00:23:40,480
uh and then we start to see that the

711
00:23:38,559 --> 00:23:42,480
other the cached byte code does have a

712
00:23:40,480 --> 00:23:44,080
larger effect with a long running app

713
00:23:42,480 --> 00:23:46,240
again once we actually give it enough

714
00:23:44,080 --> 00:23:49,039
time to jit then things start to

715
00:23:46,240 --> 00:23:49,760
improve here uh and this one we also

716
00:23:49,039 --> 00:23:52,640
threw uh

717
00:23:49,760 --> 00:23:54,000
openj9 at it since it has a feature

718
00:23:52,640 --> 00:23:56,799
similar to app cds

719
00:23:54,000 --> 00:23:57,360
but that can also save some jit code uh

720
00:23:56,799 --> 00:24:00,320
we got

721
00:23:57,360 --> 00:24:02,000
some gains here but again it's it's

722
00:24:00,320 --> 00:24:04,158
saving code that's jitted

723
00:24:02,000 --> 00:24:05,360
and most of our byte code is cold so we

724
00:24:04,159 --> 00:24:07,279
need to basically like

725
00:24:05,360 --> 00:24:09,199
we're talking to some of the open j9

726
00:24:07,279 --> 00:24:11,679
folks we're going to tell it to try and

727
00:24:09,200 --> 00:24:13,760
pre-compile those script bodies as well

728
00:24:11,679 --> 00:24:14,880
then maybe we can launch into almost all

729
00:24:13,760 --> 00:24:16,240
native code

730
00:24:14,880 --> 00:24:19,440
for all of our scripts that'll be the

731
00:24:16,240 --> 00:24:21,840
next experiment to try

732
00:24:19,440 --> 00:24:23,440
uh unless the last one is rails console

733
00:24:21,840 --> 00:24:25,039
again the rails console most of the

734
00:24:23,440 --> 00:24:26,000
rails commands are kind of a worst case

735
00:24:25,039 --> 00:24:27,919
because

736
00:24:26,000 --> 00:24:29,919
not only do they run very short but

737
00:24:27,919 --> 00:24:32,080
usually it launches jruby twice

738
00:24:29,919 --> 00:24:33,440
it launches it once to determine a set

739
00:24:32,080 --> 00:24:35,120
of dependency paths

740
00:24:33,440 --> 00:24:37,120
and then relaunches with just those

741
00:24:35,120 --> 00:24:38,239
paths to isolate it from other libraries

742
00:24:37,120 --> 00:24:41,520
and whatnot

743
00:24:38,240 --> 00:24:42,880
um so here dash dash dev a little bit of

744
00:24:41,520 --> 00:24:45,760
a gain from app cds

745
00:24:42,880 --> 00:24:47,919
epcds here more more so with the

746
00:24:45,760 --> 00:24:51,520
serialization

747
00:24:47,919 --> 00:24:52,240
which is weird uh this is the class

748
00:24:51,520 --> 00:24:55,360
cache again

749
00:24:52,240 --> 00:24:57,760
slower than normal uh

750
00:24:55,360 --> 00:24:59,279
class cache with app cds now looking

751
00:24:57,760 --> 00:25:02,879
that's that's the best

752
00:24:59,279 --> 00:25:04,480
but oddly enough in this case if we only

753
00:25:02,880 --> 00:25:06,880
cached the classes that were used for

754
00:25:04,480 --> 00:25:08,080
that parent process the launch process

755
00:25:06,880 --> 00:25:09,279
that went and dug out all those

756
00:25:08,080 --> 00:25:10,960
dependencies

757
00:25:09,279 --> 00:25:12,880
that ends up being the fastest of all

758
00:25:10,960 --> 00:25:15,520
now so there is enough

759
00:25:12,880 --> 00:25:16,720
in that that top process that warms up

760
00:25:15,520 --> 00:25:18,799
and gets going

761
00:25:16,720 --> 00:25:20,480
that we we trim off quite a bit of time

762
00:25:18,799 --> 00:25:21,039
there kind of makes me want to profile

763
00:25:20,480 --> 00:25:23,279
which

764
00:25:21,039 --> 00:25:24,240
which things are actually yeah that'll

765
00:25:23,279 --> 00:25:26,559
be the next thing

766
00:25:24,240 --> 00:25:28,080
and then only class cast those it's very

767
00:25:26,559 --> 00:25:31,440
difficult for us to profile

768
00:25:28,080 --> 00:25:34,240
what's hot in the ruby code because

769
00:25:31,440 --> 00:25:34,799
we see either the methods we've jitted

770
00:25:34,240 --> 00:25:36,640
or

771
00:25:34,799 --> 00:25:38,080
jruby interpreter and it doesn't really

772
00:25:36,640 --> 00:25:41,520
tell us like what of

773
00:25:38,080 --> 00:25:43,918
ruby is executing in the interpreter

774
00:25:41,520 --> 00:25:45,679
okay so on to some futures um we'll be

775
00:25:43,919 --> 00:25:47,919
able to wrap up pretty quick here

776
00:25:45,679 --> 00:25:49,840
so now of course native compilation is

777
00:25:47,919 --> 00:25:52,880
cool again i feel like maybe we

778
00:25:49,840 --> 00:25:54,639
need to get gcj out of mothballs and

779
00:25:52,880 --> 00:25:57,279
and everyone will be thrilled about it

780
00:25:54,640 --> 00:26:00,320
um so we are experimenting with the the

781
00:25:57,279 --> 00:26:02,159
the interesting uh uses of the

782
00:26:00,320 --> 00:26:04,559
native compilation in graw vm at this

783
00:26:02,159 --> 00:26:06,240
point uh this is early days this is

784
00:26:04,559 --> 00:26:08,080
still a future work but we've got some

785
00:26:06,240 --> 00:26:10,400
proof of concepts here

786
00:26:08,080 --> 00:26:11,918
so uh first of all talking about i

787
00:26:10,400 --> 00:26:13,679
mentioned truffle ruby before truffle

788
00:26:11,919 --> 00:26:14,159
ruby does usually run out of a native

789
00:26:13,679 --> 00:26:16,240
image

790
00:26:14,159 --> 00:26:17,760
so they've compiled all of truffle all

791
00:26:16,240 --> 00:26:20,320
of truffle ruby's

792
00:26:17,760 --> 00:26:23,520
implementation logic down um in some of

793
00:26:20,320 --> 00:26:26,320
their some of their internal class logic

794
00:26:23,520 --> 00:26:27,440
so they they do actually pretty well on

795
00:26:26,320 --> 00:26:30,320
getting this

796
00:26:27,440 --> 00:26:32,159
base startup here's us with our best

797
00:26:30,320 --> 00:26:34,240
flag dash dash dev

798
00:26:32,159 --> 00:26:36,320
there is truffle ruby on the jvm not

799
00:26:34,240 --> 00:26:39,600
with the native compilation

800
00:26:36,320 --> 00:26:42,799
uh and here it is with native compile

801
00:26:39,600 --> 00:26:45,199
uh but there's there's more to this

802
00:26:42,799 --> 00:26:45,918
than meets the eye uh they're also

803
00:26:45,200 --> 00:26:49,279
actually

804
00:26:45,919 --> 00:26:51,200
pre-loading all of ruby gems and saving

805
00:26:49,279 --> 00:26:52,000
that in the native image so it's already

806
00:26:51,200 --> 00:26:54,000
booted

807
00:26:52,000 --> 00:26:55,679
they're not actually loading all of the

808
00:26:54,000 --> 00:26:57,760
code that we load so it's not

809
00:26:55,679 --> 00:26:59,840
quite apples to apples here they're

810
00:26:57,760 --> 00:27:00,799
essentially doing like a criu like a

811
00:26:59,840 --> 00:27:03,360
restore

812
00:27:00,799 --> 00:27:05,039
of where they were at zero so that they

813
00:27:03,360 --> 00:27:06,959
can launch right to zero

814
00:27:05,039 --> 00:27:08,720
if we make them do a little bit more

815
00:27:06,960 --> 00:27:10,159
work

816
00:27:08,720 --> 00:27:11,679
so here we have two different ones gem

817
00:27:10,159 --> 00:27:13,679
version which would be very lightweight

818
00:27:11,679 --> 00:27:15,520
but forces all of ruby gems to load

819
00:27:13,679 --> 00:27:16,880
and then of course a gem list of a large

820
00:27:15,520 --> 00:27:20,000
number of gems

821
00:27:16,880 --> 00:27:22,799
uh here's jruby versus truffle ruby jvm

822
00:27:20,000 --> 00:27:24,880
and native they're two to three times

823
00:27:22,799 --> 00:27:25,918
slower than us usually for just a basic

824
00:27:24,880 --> 00:27:27,440
gem command

825
00:27:25,919 --> 00:27:29,200
and then it continues to get worse the

826
00:27:27,440 --> 00:27:31,440
more work they have to do they're

827
00:27:29,200 --> 00:27:33,039
still essentially running cold because

828
00:27:31,440 --> 00:27:35,440
all that ruby code goes through the same

829
00:27:33,039 --> 00:27:38,559
sort of process it does with jruby

830
00:27:35,440 --> 00:27:39,919
so what we want to do uh we've

831
00:27:38,559 --> 00:27:42,480
already been able to compile all of

832
00:27:39,919 --> 00:27:44,000
jruby itself to native and get it to run

833
00:27:42,480 --> 00:27:45,840
and boot up

834
00:27:44,000 --> 00:27:47,200
but there are a lot of limitations have

835
00:27:45,840 --> 00:27:49,918
to turn off invoke dynamic

836
00:27:47,200 --> 00:27:51,279
we can't do any runtime jit we can't

837
00:27:49,919 --> 00:27:52,480
dynamically load any classes or

838
00:27:51,279 --> 00:27:54,320
libraries

839
00:27:52,480 --> 00:27:56,559
so the ultimate goal then is to compile

840
00:27:54,320 --> 00:27:58,879
jruby and all of those

841
00:27:56,559 --> 00:27:59,678
ahead of time compiled ruby scripts down

842
00:27:58,880 --> 00:28:02,080
to native

843
00:27:59,679 --> 00:28:03,600
and so this would be the first real

844
00:28:02,080 --> 00:28:06,158
fully functional

845
00:28:03,600 --> 00:28:07,520
native compile for a ruby application

846
00:28:06,159 --> 00:28:11,039
that leaves nothing but

847
00:28:07,520 --> 00:28:13,039
nothing but native code behind so that's

848
00:28:11,039 --> 00:28:15,279
that's coming up what we have right now

849
00:28:13,039 --> 00:28:16,559
is compiling jruby down to a native

850
00:28:15,279 --> 00:28:18,640
executable

851
00:28:16,559 --> 00:28:21,279
so here is our c ruby startup for the

852
00:28:18,640 --> 00:28:24,320
basic thing the basic dash e1

853
00:28:21,279 --> 00:28:27,200
uh jruby on jdk8

854
00:28:24,320 --> 00:28:28,879
here is after we've let it jit and

855
00:28:27,200 --> 00:28:31,840
there's where we get if we compile

856
00:28:28,880 --> 00:28:32,960
jruby down so this is at least getting

857
00:28:31,840 --> 00:28:35,600
us to zero

858
00:28:32,960 --> 00:28:37,120
as fast as truffle ruby uh without being

859
00:28:35,600 --> 00:28:38,080
truffle and without doing all of the

860
00:28:37,120 --> 00:28:40,719
other tricks

861
00:28:38,080 --> 00:28:42,399
uh but we want to be able to do this and

862
00:28:40,720 --> 00:28:42,799
have all the ruby code loaded up so

863
00:28:42,399 --> 00:28:45,439
that's

864
00:28:42,799 --> 00:28:45,840
that's the next thing so futures for

865
00:28:45,440 --> 00:28:47,600
this

866
00:28:45,840 --> 00:28:49,600
uh like i said we needed the bytecode

867
00:28:47,600 --> 00:28:52,000
aot to be working and now it is

868
00:28:49,600 --> 00:28:53,520
so we'll be expanding that native

869
00:28:52,000 --> 00:28:55,440
compile proof of concept

870
00:28:53,520 --> 00:28:57,039
to do the entire application probably

871
00:28:55,440 --> 00:28:59,200
starting with just smaller services and

872
00:28:57,039 --> 00:29:00,640
command line tools at first

873
00:28:59,200 --> 00:29:02,880
also have some ideas for static

874
00:29:00,640 --> 00:29:04,799
optimization that

875
00:29:02,880 --> 00:29:07,120
we can get some profile information from

876
00:29:04,799 --> 00:29:08,080
the ruby code and for monomorphic call

877
00:29:07,120 --> 00:29:10,399
sites

878
00:29:08,080 --> 00:29:11,120
just compile into our ahead of time

879
00:29:10,399 --> 00:29:12,639
bytecode

880
00:29:11,120 --> 00:29:14,559
a guess that it's probably the same

881
00:29:12,640 --> 00:29:17,440
method it was last time you ran it

882
00:29:14,559 --> 00:29:17,918
and then ideally the uh the native v

883
00:29:17,440 --> 00:29:19,520
native

884
00:29:17,919 --> 00:29:21,120
image compile could see through some of

885
00:29:19,520 --> 00:29:22,799
that and probably get a lot of the

886
00:29:21,120 --> 00:29:24,879
inlining that we want out of it

887
00:29:22,799 --> 00:29:26,960
most calls are monomorphic and ruby

888
00:29:24,880 --> 00:29:29,200
applications anyway

889
00:29:26,960 --> 00:29:31,120
all right and the last item so in in

890
00:29:29,200 --> 00:29:32,480
working with the ir serialization

891
00:29:31,120 --> 00:29:34,479
because we hadn't touched that in quite

892
00:29:32,480 --> 00:29:36,399
a long time we started thinking about

893
00:29:34,480 --> 00:29:37,679
ways that we could actually speed things

894
00:29:36,399 --> 00:29:40,959
up and like

895
00:29:37,679 --> 00:29:42,720
one one big problem we have is our ruby

896
00:29:40,960 --> 00:29:46,000
parser's like

897
00:29:42,720 --> 00:29:49,360
it's an la lr grammar with like 170

898
00:29:46,000 --> 00:29:52,159
000 like states so it's it's

899
00:29:49,360 --> 00:29:53,520
it takes a long time to warm up but what

900
00:29:52,159 --> 00:29:54,159
if we could do something that was a bit

901
00:29:53,520 --> 00:29:55,600
simpler

902
00:29:54,159 --> 00:29:57,679
something that could fit into a single

903
00:29:55,600 --> 00:30:01,360
method

904
00:29:57,679 --> 00:30:03,760
so in looking at in looking at

905
00:30:01,360 --> 00:30:06,158
ruby typical ruby files in libraries

906
00:30:03,760 --> 00:30:09,440
there's usually a couple requires

907
00:30:06,159 --> 00:30:11,360
which are just a function call and uh

908
00:30:09,440 --> 00:30:13,279
there's some modules and classes to find

909
00:30:11,360 --> 00:30:15,199
and they're reasonably simple so what if

910
00:30:13,279 --> 00:30:16,320
we limit a ruby interpreter to only

911
00:30:15,200 --> 00:30:18,880
those things

912
00:30:16,320 --> 00:30:18,879
and if

913
00:30:20,320 --> 00:30:24,080
if if the ruby has more complicated

914
00:30:22,240 --> 00:30:25,679
things like it has if conditionals

915
00:30:24,080 --> 00:30:26,399
inside of a module body then we'll just

916
00:30:25,679 --> 00:30:28,399
use the

917
00:30:26,399 --> 00:30:29,678
the current serialization but if it

918
00:30:28,399 --> 00:30:31,520
doesn't we'll

919
00:30:29,679 --> 00:30:32,880
use this new interpreter that is

920
00:30:31,520 --> 00:30:33,760
basically just going to be a single

921
00:30:32,880 --> 00:30:36,000
static method

922
00:30:33,760 --> 00:30:37,600
that's only going to have a limited

923
00:30:36,000 --> 00:30:43,360
number of instructions

924
00:30:37,600 --> 00:30:43,360
and we'll we'll we'll go with that

925
00:30:44,000 --> 00:30:47,840
i realize that all the stuff that i'm

926
00:30:45,840 --> 00:30:49,760
talking about here are things that will

927
00:30:47,840 --> 00:30:51,918
only execute once

928
00:30:49,760 --> 00:30:53,679
so we have no need to have ir at all so

929
00:30:51,919 --> 00:30:56,960
that that was something i realized

930
00:30:53,679 --> 00:30:58,880
after that slide yeah um so this is a

931
00:30:56,960 --> 00:31:01,440
typical structure of a

932
00:30:58,880 --> 00:31:02,000
ruby source and on the right it's just a

933
00:31:01,440 --> 00:31:04,720
little

934
00:31:02,000 --> 00:31:05,760
napkin thing a it'll probably just be

935
00:31:04,720 --> 00:31:08,880
five or seven

936
00:31:05,760 --> 00:31:09,200
uh case switches with uh inline bodies

937
00:31:08,880 --> 00:31:11,519
for

938
00:31:09,200 --> 00:31:12,240
just standing up a new module in a new

939
00:31:11,519 --> 00:31:15,120
class

940
00:31:12,240 --> 00:31:15,760
right right it also has another benefit

941
00:31:15,120 --> 00:31:18,639
which is

942
00:31:15,760 --> 00:31:20,640
that when we normally interpret stuff

943
00:31:18,640 --> 00:31:21,840
into ir we go through this prologue and

944
00:31:20,640 --> 00:31:23,200
epilogue of

945
00:31:21,840 --> 00:31:25,360
executing the script body and then

946
00:31:23,200 --> 00:31:28,320
executing the class and then

947
00:31:25,360 --> 00:31:30,080
so forth but in this case uh it's all

948
00:31:28,320 --> 00:31:31,840
going to happen in the same context

949
00:31:30,080 --> 00:31:33,918
right and we at least see that there are

950
00:31:31,840 --> 00:31:35,039
no other calls no unrecognized calls

951
00:31:33,919 --> 00:31:36,559
like require we

952
00:31:35,039 --> 00:31:38,640
require we've got some visibility

953
00:31:36,559 --> 00:31:40,080
changes but we can basically store the

954
00:31:38,640 --> 00:31:40,799
structure and just run through it

955
00:31:40,080 --> 00:31:43,360
quickly

956
00:31:40,799 --> 00:31:45,760
uh saving the entire ruby context that

957
00:31:43,360 --> 00:31:49,279
we would normally need to execute in

958
00:31:45,760 --> 00:31:50,559
so so wrapping up here uh pre-compiling

959
00:31:49,279 --> 00:31:52,080
to bytecode works but it

960
00:31:50,559 --> 00:31:54,320
you generally is hurting startup right

961
00:31:52,080 --> 00:31:55,840
now clearly a prerequisite for doing a

962
00:31:54,320 --> 00:31:58,000
native compile so that'll be the next

963
00:31:55,840 --> 00:31:59,519
step to try that out

964
00:31:58,000 --> 00:32:01,200
the class sharing features are looking

965
00:31:59,519 --> 00:32:04,640
very good these days uh

966
00:32:01,200 --> 00:32:07,039
running app cds on jdk 13

967
00:32:04,640 --> 00:32:08,559
is the probably the fastest startup for

968
00:32:07,039 --> 00:32:10,000
jruby at the moment

969
00:32:08,559 --> 00:32:11,678
we're going to continue playing with

970
00:32:10,000 --> 00:32:13,279
mixing these different options together

971
00:32:11,679 --> 00:32:15,200
but cds looks good

972
00:32:13,279 --> 00:32:18,000
the share classes quick start stuff on

973
00:32:15,200 --> 00:32:21,519
openj9 is also fairly competitive there

974
00:32:18,000 --> 00:32:23,360
we're looking to try out say ready now

975
00:32:21,519 --> 00:32:24,640
i think it was the alibaba folks are

976
00:32:23,360 --> 00:32:26,080
working on saving jit

977
00:32:24,640 --> 00:32:28,000
stuff in the background as well on

978
00:32:26,080 --> 00:32:31,039
openjdk so we're interested in that

979
00:32:28,000 --> 00:32:32,080
possibility as well um lazier and

980
00:32:31,039 --> 00:32:33,919
lighter ir like

981
00:32:32,080 --> 00:32:35,678
i mean really the best things we can do

982
00:32:33,919 --> 00:32:38,399
right now is just do less work

983
00:32:35,679 --> 00:32:39,360
at boot and try to get you to a running

984
00:32:38,399 --> 00:32:41,678
application quicker

985
00:32:39,360 --> 00:32:42,959
it's really just that first response if

986
00:32:41,679 --> 00:32:46,320
the whole application

987
00:32:42,960 --> 00:32:48,320
the whole run takes 20 seconds uh

988
00:32:46,320 --> 00:32:50,559
just getting you to the first output of

989
00:32:48,320 --> 00:32:52,000
it makes people feel so much better

990
00:32:50,559 --> 00:32:54,240
it's that sitting there staring at a

991
00:32:52,000 --> 00:32:55,760
blank command line with it just doing

992
00:32:54,240 --> 00:32:57,440
nothing while we boot up

993
00:32:55,760 --> 00:32:58,640
that's what really bothers people some

994
00:32:57,440 --> 00:32:59,360
people have suggested we should have a

995
00:32:58,640 --> 00:33:01,279
splash screen

996
00:32:59,360 --> 00:33:03,439
every time we run a run a command so

997
00:33:01,279 --> 00:33:05,120
that they know we're going we are going

998
00:33:03,440 --> 00:33:07,120
trust me we still occasionally get that

999
00:33:05,120 --> 00:33:09,600
with java 9 plus with module warnings

1000
00:33:07,120 --> 00:33:10,239
yeah exactly we got progress bar maybe

1001
00:33:09,600 --> 00:33:12,879
like

1002
00:33:10,240 --> 00:33:14,720
starting up yeah but i mean if we can do

1003
00:33:12,880 --> 00:33:16,320
less and get people at least some output

1004
00:33:14,720 --> 00:33:17,679
right away that would be better

1005
00:33:16,320 --> 00:33:19,918
um and the native compile stuff is

1006
00:33:17,679 --> 00:33:22,559
really cool it shows a lot of promise

1007
00:33:19,919 --> 00:33:23,200
but it's really super limited right now

1008
00:33:22,559 --> 00:33:26,240
it's not

1009
00:33:23,200 --> 00:33:28,240
java and in the way we know it um i

1010
00:33:26,240 --> 00:33:29,919
think we can get small ruby applications

1011
00:33:28,240 --> 00:33:30,799
to compile completely down to a native

1012
00:33:29,919 --> 00:33:32,559
binary

1013
00:33:30,799 --> 00:33:34,720
hopefully that binary is smaller than

1014
00:33:32,559 --> 00:33:36,240
one gigabyte once we get there

1015
00:33:34,720 --> 00:33:37,760
um but we're going to continue to play

1016
00:33:36,240 --> 00:33:39,279
with it and see how much we can actually

1017
00:33:37,760 --> 00:33:40,320
squeeze out of all of these different

1018
00:33:39,279 --> 00:33:43,600
options

1019
00:33:40,320 --> 00:33:43,600
and that's what we got thank you

1020
00:33:49,440 --> 00:33:53,840
who told you it would be good

1021
00:33:56,559 --> 00:34:00,320
how long does it take to compile jruby

1022
00:33:58,559 --> 00:34:03,279
native

1023
00:34:00,320 --> 00:34:04,879
to compile jruby native um it wasn't

1024
00:34:03,279 --> 00:34:07,120
terribly long i mean

1025
00:34:04,880 --> 00:34:09,839
in the order of a few minutes i guess it

1026
00:34:07,120 --> 00:34:12,480
was our code base isn't that large

1027
00:34:09,839 --> 00:34:14,320
and i also strip i i had to strip out

1028
00:34:12,480 --> 00:34:15,839
like our byte code compiler anything

1029
00:34:14,320 --> 00:34:18,159
that would reference stuff that

1030
00:34:15,839 --> 00:34:19,520
that the native image does not like i

1031
00:34:18,159 --> 00:34:22,240
basically just removed it

1032
00:34:19,520 --> 00:34:24,159
so it cut j ruby down to essentially

1033
00:34:22,239 --> 00:34:25,040
parser compiler interpreter and some of

1034
00:34:24,159 --> 00:34:27,760
our core classes

1035
00:34:25,040 --> 00:34:28,719
so it's you know five minutes maybe yeah

1036
00:34:27,760 --> 00:34:30,480
it wasn't too bad

1037
00:34:28,719 --> 00:34:32,158
it's not something that we would say oh

1038
00:34:30,480 --> 00:34:33,599
this is part of your dev cycle now

1039
00:34:32,159 --> 00:34:36,320
now that you've updated your libraries

1040
00:34:33,599 --> 00:34:39,280
do a native compile now be more like

1041
00:34:36,320 --> 00:34:40,639
we would pre-compile jruby plus some key

1042
00:34:39,280 --> 00:34:42,399
libraries

1043
00:34:40,639 --> 00:34:43,440
and then compile our interpreter in so

1044
00:34:42,399 --> 00:34:45,040
that you'd continue to use the

1045
00:34:43,440 --> 00:34:45,839
interpreter but you'd get the fast

1046
00:34:45,040 --> 00:34:48,399
startup of

1047
00:34:45,839 --> 00:34:50,000
basic things so a partial solution there

1048
00:34:48,399 --> 00:34:50,399
or if you're going to production compile

1049
00:34:50,000 --> 00:34:53,760
your home

1050
00:34:50,399 --> 00:34:53,759
micro service down or something

1051
00:34:54,000 --> 00:35:00,000
hello so my question is a few

1052
00:34:57,760 --> 00:35:02,000
a few years ago we talked about this on

1053
00:35:00,000 --> 00:35:03,680
twitter that you still

1054
00:35:02,000 --> 00:35:05,760
at the time jerubi still defaulted to

1055
00:35:03,680 --> 00:35:07,279
have compiled a timefork dynamic set to

1056
00:35:05,760 --> 00:35:10,640
false so by default

1057
00:35:07,280 --> 00:35:11,599
without dev jirubi would avoid invoke

1058
00:35:10,640 --> 00:35:14,720
dynamic

1059
00:35:11,599 --> 00:35:16,320
do you think some of this could be used

1060
00:35:14,720 --> 00:35:18,959
as an enabler to also

1061
00:35:16,320 --> 00:35:19,520
um have that on as default and not have

1062
00:35:18,960 --> 00:35:22,960
as big

1063
00:35:19,520 --> 00:35:25,040
as a penalty as in the past right so

1064
00:35:22,960 --> 00:35:26,560
so trying to get closer to having invoke

1065
00:35:25,040 --> 00:35:28,400
dynamic on all the time

1066
00:35:26,560 --> 00:35:29,680
we've kind of we've moved that bar a

1067
00:35:28,400 --> 00:35:32,480
little bit over time

1068
00:35:29,680 --> 00:35:33,440
so things that are uh literal values

1069
00:35:32,480 --> 00:35:35,119
will now

1070
00:35:33,440 --> 00:35:36,640
they're like uh they're sort of like a

1071
00:35:35,119 --> 00:35:38,400
constant dynamic sort of thing they

1072
00:35:36,640 --> 00:35:39,839
they boot up and then they they cache a

1073
00:35:38,400 --> 00:35:41,680
constant using a book dynamic

1074
00:35:39,839 --> 00:35:43,040
that's always on and that's what i had

1075
00:35:41,680 --> 00:35:46,078
to kind of re

1076
00:35:43,040 --> 00:35:48,000
remove from the compiler um the real

1077
00:35:46,079 --> 00:35:48,880
problem with us using invoke dynamic all

1078
00:35:48,000 --> 00:35:50,800
the time

1079
00:35:48,880 --> 00:35:52,960
is that we get those long chains of

1080
00:35:50,800 --> 00:35:55,200
totally dynamically constructed

1081
00:35:52,960 --> 00:35:56,720
lambda forms there's not it's not

1082
00:35:55,200 --> 00:35:58,240
something in a constant pool it's not

1083
00:35:56,720 --> 00:36:00,319
something we can represent as a as an

1084
00:35:58,240 --> 00:36:03,040
expression there easily

1085
00:36:00,320 --> 00:36:05,040
so those would always still be slow it's

1086
00:36:03,040 --> 00:36:06,320
possible that with const dynamic or

1087
00:36:05,040 --> 00:36:08,000
something like that

1088
00:36:06,320 --> 00:36:09,440
we might be able to say here is the

1089
00:36:08,000 --> 00:36:12,320
shape of a ruby

1090
00:36:09,440 --> 00:36:14,000
method call chain cache these and then

1091
00:36:12,320 --> 00:36:14,320
stick this direct method handle on the

1092
00:36:14,000 --> 00:36:17,359
end

1093
00:36:14,320 --> 00:36:19,440
and save some of that effort but we

1094
00:36:17,359 --> 00:36:21,598
we do so much of this programmatic

1095
00:36:19,440 --> 00:36:24,720
building of large method handle chains

1096
00:36:21,599 --> 00:36:27,359
that's where most of the problem is

1097
00:36:24,720 --> 00:36:29,839
there are two other things um one is

1098
00:36:27,359 --> 00:36:32,319
that charlie just recently changed our

1099
00:36:29,839 --> 00:36:33,920
our bytecode generator so that you can

1100
00:36:32,320 --> 00:36:37,280
decouple whether

1101
00:36:33,920 --> 00:36:39,599
indie's on for everything or or or not

1102
00:36:37,280 --> 00:36:41,119
so sliding scale more now so we can

1103
00:36:39,599 --> 00:36:41,920
adjust that so we might be able to

1104
00:36:41,119 --> 00:36:44,320
actually emit

1105
00:36:41,920 --> 00:36:45,760
less uh in india in places where it

1106
00:36:44,320 --> 00:36:47,760
probably doesn't matter

1107
00:36:45,760 --> 00:36:50,480
but then the second thing uh we've been

1108
00:36:47,760 --> 00:36:53,359
trying to add a timing metric

1109
00:36:50,480 --> 00:36:55,440
in to change our jit heuristics so that

1110
00:36:53,359 --> 00:36:58,560
we're actually getting less code

1111
00:36:55,440 --> 00:37:00,480
and that should enable us to if we

1112
00:36:58,560 --> 00:37:02,320
if we truly make it to a place where we

1113
00:37:00,480 --> 00:37:04,160
can know that something's hot

1114
00:37:02,320 --> 00:37:05,599
we can just use tons of invoke dynamic

1115
00:37:04,160 --> 00:37:06,560
in that but if it doesn't hit that

1116
00:37:05,599 --> 00:37:09,599
threshold then

1117
00:37:06,560 --> 00:37:12,400
maybe we do an indie free

1118
00:37:09,599 --> 00:37:12,800
compilation right well and we've we've

1119
00:37:12,400 --> 00:37:14,880
got

1120
00:37:12,800 --> 00:37:16,640
we're kind of building this tiered vm on

1121
00:37:14,880 --> 00:37:18,800
top of another tiered vm

1122
00:37:16,640 --> 00:37:20,560
um we've even talked about like oh we

1123
00:37:18,800 --> 00:37:22,000
could use indy but maybe use really

1124
00:37:20,560 --> 00:37:25,279
simple call sites that just

1125
00:37:22,000 --> 00:37:27,920
basically do uh uh you know a ver

1126
00:37:25,280 --> 00:37:29,040
virtual dispatch to some function object

1127
00:37:27,920 --> 00:37:31,680
that would be very quick

1128
00:37:29,040 --> 00:37:33,359
to bootstrap and then you know add a

1129
00:37:31,680 --> 00:37:35,118
counter into the method handle chain and

1130
00:37:33,359 --> 00:37:35,759
then once it gets really hot we go back

1131
00:37:35,119 --> 00:37:37,760
and we make it an

1132
00:37:35,760 --> 00:37:39,760
optimized invoke dynamic i mean there's

1133
00:37:37,760 --> 00:37:41,599
lots of lots of different things we can

1134
00:37:39,760 --> 00:37:44,800
try with this but

1135
00:37:41,599 --> 00:37:44,800
there's only so many hours in the day

1136
00:37:45,839 --> 00:37:49,200
when you tried all the abcds things and

1137
00:37:48,560 --> 00:37:52,560
so on

1138
00:37:49,200 --> 00:37:55,919
did you also try the open jdk aot thing

1139
00:37:52,560 --> 00:37:57,680
uh jaotc yeah uh we have played with it

1140
00:37:55,920 --> 00:37:59,440
and it it was it was similar

1141
00:37:57,680 --> 00:38:01,839
to what we get what we saw out of app

1142
00:37:59,440 --> 00:38:05,280
cds and other stuff it basically got

1143
00:38:01,839 --> 00:38:07,440
our zero flag startup pretty close to

1144
00:38:05,280 --> 00:38:09,359
the dev the c1 performance which is

1145
00:38:07,440 --> 00:38:11,359
about what we expect

1146
00:38:09,359 --> 00:38:13,440
we hope for a little bit more because we

1147
00:38:11,359 --> 00:38:14,880
wanted those bodies of code to actually

1148
00:38:13,440 --> 00:38:16,160
also compile

1149
00:38:14,880 --> 00:38:18,000
it just turns out to be such a

1150
00:38:16,160 --> 00:38:19,598
tremendous amount of code that we end up

1151
00:38:18,000 --> 00:38:21,280
loading into the system at that point i

1152
00:38:19,599 --> 00:38:23,359
think we lose it there

1153
00:38:21,280 --> 00:38:24,960
it creates a gigantic executable for all

1154
00:38:23,359 --> 00:38:27,680
the stuff that we we actually

1155
00:38:24,960 --> 00:38:29,119
would need to run at startup so we need

1156
00:38:27,680 --> 00:38:30,799
to figure out how to make that startup

1157
00:38:29,119 --> 00:38:32,960
stuff as lightweight as possible

1158
00:38:30,800 --> 00:38:35,200
and only do the real hard work for

1159
00:38:32,960 --> 00:38:37,680
methods and blocks

1160
00:38:35,200 --> 00:38:38,640
there's a question for me clearly you

1161
00:38:37,680 --> 00:38:42,480
know

1162
00:38:38,640 --> 00:38:43,839
in some detail which methods are going

1163
00:38:42,480 --> 00:38:46,880
to be hot

1164
00:38:43,839 --> 00:38:49,759
if you could drive

1165
00:38:46,880 --> 00:38:50,400
the hotspot jit compiler from the script

1166
00:38:49,760 --> 00:38:53,520
say

1167
00:38:50,400 --> 00:38:56,240
to say compile these methods now

1168
00:38:53,520 --> 00:38:57,759
inline these methods into them would you

1169
00:38:56,240 --> 00:38:59,598
be able to get a better performance that

1170
00:38:57,760 --> 00:39:01,200
way

1171
00:38:59,599 --> 00:39:02,640
well i would i would say almost none of

1172
00:39:01,200 --> 00:39:05,040
this affects our peak performance

1173
00:39:02,640 --> 00:39:06,799
uh in general we're already getting good

1174
00:39:05,040 --> 00:39:08,320
inlining through invoke dynamic call

1175
00:39:06,800 --> 00:39:10,240
sites it just takes a long time

1176
00:39:08,320 --> 00:39:11,920
what it would do and what the

1177
00:39:10,240 --> 00:39:12,640
pre-booting byte code and what that

1178
00:39:11,920 --> 00:39:14,880
would do

1179
00:39:12,640 --> 00:39:16,240
was we might be able to hint and get

1180
00:39:14,880 --> 00:39:18,480
warm up curve

1181
00:39:16,240 --> 00:39:20,240
a lot lower because we're we're

1182
00:39:18,480 --> 00:39:22,079
confusing the hell out of the jvm

1183
00:39:20,240 --> 00:39:23,680
we run this code for a long time in the

1184
00:39:22,079 --> 00:39:24,960
interpreter and then we're like oh no

1185
00:39:23,680 --> 00:39:25,839
it's not the interpreter anymore and now

1186
00:39:24,960 --> 00:39:27,280
it's going to be

1187
00:39:25,839 --> 00:39:28,480
this version of the byte code oh and now

1188
00:39:27,280 --> 00:39:29,839
we're going to re-optimize that byte

1189
00:39:28,480 --> 00:39:31,200
code and change it again

1190
00:39:29,839 --> 00:39:33,599
but if we could give some hints to the

1191
00:39:31,200 --> 00:39:35,118
vm it would it would certainly help us

1192
00:39:33,599 --> 00:39:37,200
shorten that because there's a sort of

1193
00:39:35,119 --> 00:39:39,599
mechanism that will do that in the shape

1194
00:39:37,200 --> 00:39:42,640
of the ci replay data that

1195
00:39:39,599 --> 00:39:44,640
engineers use to debug the jet yeah it's

1196
00:39:42,640 --> 00:39:46,319
a serialized form that tells you exactly

1197
00:39:44,640 --> 00:39:47,598
which methods to get and exactly where

1198
00:39:46,320 --> 00:39:48,960
to inline everything

1199
00:39:47,599 --> 00:39:50,640
and exactly what all the branch

1200
00:39:48,960 --> 00:39:52,079
probabilities are yeah

1201
00:39:50,640 --> 00:39:53,920
you can feed it with all that if you

1202
00:39:52,079 --> 00:39:56,400
want right and and we

1203
00:39:53,920 --> 00:39:57,599
actually we have a profiling inliner for

1204
00:39:56,400 --> 00:39:59,200
the ir already

1205
00:39:57,599 --> 00:40:00,800
so it's possible we'd be able to take

1206
00:39:59,200 --> 00:40:03,040
that our interpreter

1207
00:40:00,800 --> 00:40:04,960
profile data feed it into a tool like

1208
00:40:03,040 --> 00:40:05,920
that and then say hey we already know

1209
00:40:04,960 --> 00:40:08,480
this stuff

1210
00:40:05,920 --> 00:40:10,640
don't start from zero again yeah both

1211
00:40:08,480 --> 00:40:10,960
our parser and our ir interpreter are

1212
00:40:10,640 --> 00:40:14,078
just

1213
00:40:10,960 --> 00:40:14,800
java if we could just force that to c2

1214
00:40:14,079 --> 00:40:19,280
immediately

1215
00:40:14,800 --> 00:40:23,040
yeah right you can use the white box api

1216
00:40:19,280 --> 00:40:23,040
okay to put stuff

1217
00:40:25,839 --> 00:40:30,160
yeah it works yeah we'll give it a shot

1218
00:40:28,319 --> 00:40:32,240
then

1219
00:40:30,160 --> 00:40:33,440
anything else everybody wanna get dinner

1220
00:40:32,240 --> 00:40:36,640
on top of that uh

1221
00:40:33,440 --> 00:40:36,960
uh compile queue is not a fifo as it it

1222
00:40:36,640 --> 00:40:39,359
it's

1223
00:40:36,960 --> 00:40:40,720
it the there is an algorithm behind how

1224
00:40:39,359 --> 00:40:42,880
methods are explaining select

1225
00:40:40,720 --> 00:40:45,200
so in your case since you care so much

1226
00:40:42,880 --> 00:40:48,160
about you know the warm-up curve

1227
00:40:45,200 --> 00:40:49,598
it really worth it's worth using

1228
00:40:48,160 --> 00:40:51,118
visiting how

1229
00:40:49,599 --> 00:40:52,960
which in which order methods get

1230
00:40:51,119 --> 00:40:54,240
compiled and this might impact your your

1231
00:40:52,960 --> 00:40:56,000
warmer curve

1232
00:40:54,240 --> 00:40:57,439
the way to effectively is like whitebox

1233
00:40:56,000 --> 00:40:59,280
api um

1234
00:40:57,440 --> 00:41:00,640
you know the replay file can help you

1235
00:40:59,280 --> 00:41:03,119
there sure um by

1236
00:41:00,640 --> 00:41:03,759
tweaking some indexes indices um things

1237
00:41:03,119 --> 00:41:05,280
like that

1238
00:41:03,760 --> 00:41:07,280
sure all right thank you we'll

1239
00:41:05,280 --> 00:41:09,040
definitely do that thank you

1240
00:41:07,280 --> 00:41:10,880
thank you very much that was fascinating

1241
00:41:09,040 --> 00:41:21,839
i think we should wrap up at that point

1242
00:41:10,880 --> 00:41:21,839
all right thank you

1243
00:41:22,400 --> 00:41:24,480
you

