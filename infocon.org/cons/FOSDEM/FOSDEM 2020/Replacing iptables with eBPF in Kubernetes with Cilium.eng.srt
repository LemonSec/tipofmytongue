1
00:00:08,000 --> 00:00:12,320
okay

2
00:00:08,800 --> 00:00:15,599
so let's start hello everyone

3
00:00:12,320 --> 00:00:19,359
we will talk today about replacing

4
00:00:15,599 --> 00:00:22,000
traditional legacy ip tables with ebpf

5
00:00:19,359 --> 00:00:23,519
and kubernetes clusters with serious we

6
00:00:22,000 --> 00:00:26,960
are from souza

7
00:00:23,519 --> 00:00:30,080
i'm mikhail this is swami

8
00:00:26,960 --> 00:00:30,560
and yeah let's start from the question

9
00:00:30,080 --> 00:00:34,079
what's

10
00:00:30,560 --> 00:00:37,120
wrong with traditional iptables

11
00:00:34,079 --> 00:00:38,800
so there are several things wrong

12
00:00:37,120 --> 00:00:40,399
from the point of view of kubernetes

13
00:00:38,800 --> 00:00:42,879
clusters first of all

14
00:00:40,399 --> 00:00:44,399
iptables is a technology which has 20

15
00:00:42,879 --> 00:00:47,039
years and

16
00:00:44,399 --> 00:00:48,879
it was designed mostly for simple ip

17
00:00:47,039 --> 00:00:50,960
address and port matching

18
00:00:48,879 --> 00:00:53,199
which is a good approach for like

19
00:00:50,960 --> 00:00:55,760
traditional server applications

20
00:00:53,199 --> 00:00:57,199
uh for the time where we don't have like

21
00:00:55,760 --> 00:01:00,320
huge clusters and

22
00:00:57,199 --> 00:01:03,358
huge high availability

23
00:01:00,320 --> 00:01:07,360
but in the era of kubernetes clusters

24
00:01:03,359 --> 00:01:11,119
is not enough in european

25
00:01:07,360 --> 00:01:12,000
the other issue is that iptables is not

26
00:01:11,119 --> 00:01:15,119
really aware

27
00:01:12,000 --> 00:01:17,439
of the l7 protocols so you don't you

28
00:01:15,119 --> 00:01:20,400
can't filter

29
00:01:17,439 --> 00:01:22,240
the http codes for example you can

30
00:01:20,400 --> 00:01:24,799
filter

31
00:01:22,240 --> 00:01:27,439
particular database database queries

32
00:01:24,799 --> 00:01:28,320
it's all based on ip addresses and ports

33
00:01:27,439 --> 00:01:32,320
so layer 3

34
00:01:28,320 --> 00:01:34,559
layer 4. and the other thing is that

35
00:01:32,320 --> 00:01:36,158
iptables operates on the concept of

36
00:01:34,560 --> 00:01:39,119
chains and rules and

37
00:01:36,159 --> 00:01:41,360
to add a route to the chain you

38
00:01:39,119 --> 00:01:44,560
basically operate on the

39
00:01:41,360 --> 00:01:47,360
linked list so every operation

40
00:01:44,560 --> 00:01:48,159
except of insert is o n so like

41
00:01:47,360 --> 00:01:51,280
searching

42
00:01:48,159 --> 00:01:54,479
over the chain of rules or

43
00:01:51,280 --> 00:01:58,479
modifying the particular rule is always

44
00:01:54,479 --> 00:02:04,158
the like average or an operation

45
00:01:58,479 --> 00:02:06,399
and that's why kubernetes currently

46
00:02:04,159 --> 00:02:07,280
uses ip tables extensively so the

47
00:02:06,399 --> 00:02:09,840
tradition

48
00:02:07,280 --> 00:02:11,440
so when you use kubernetes with the most

49
00:02:09,840 --> 00:02:14,000
of cni plugins

50
00:02:11,440 --> 00:02:14,959
uh you use ip tables for mainly two

51
00:02:14,000 --> 00:02:16,959
things

52
00:02:14,959 --> 00:02:18,879
first thing is implementing surfaces

53
00:02:16,959 --> 00:02:20,959
with keep proxy

54
00:02:18,879 --> 00:02:22,480
and the second thing are network

55
00:02:20,959 --> 00:02:25,520
policies for

56
00:02:22,480 --> 00:02:29,119
filtering the traffic but the

57
00:02:25,520 --> 00:02:32,319
and uh it sometimes ends up with so much

58
00:02:29,120 --> 00:02:34,959
ip tables and so much sadness

59
00:02:32,319 --> 00:02:37,119
uh but there is one technology which

60
00:02:34,959 --> 00:02:40,000
tries to address that

61
00:02:37,120 --> 00:02:42,480
it's bpf which was already mentioned in

62
00:02:40,000 --> 00:02:45,599
previous presentations

63
00:02:42,480 --> 00:02:45,840
in the dev room but to briefly introduce

64
00:02:45,599 --> 00:02:48,079
it

65
00:02:45,840 --> 00:02:49,440
it's a virtual machine the kernel which

66
00:02:48,080 --> 00:02:52,720
allows you to write

67
00:02:49,440 --> 00:02:57,120
programs in the subset of c language

68
00:02:52,720 --> 00:03:00,480
which filters and traces the packets

69
00:02:57,120 --> 00:03:01,680
in the kernel or it can also be used to

70
00:03:00,480 --> 00:03:04,560
trace the

71
00:03:01,680 --> 00:03:06,560
kernel function calls but in case of

72
00:03:04,560 --> 00:03:08,560
psyllium and in case of our talk we

73
00:03:06,560 --> 00:03:12,480
focus more to uh on the

74
00:03:08,560 --> 00:03:13,760
networking side of bpf and swami will

75
00:03:12,480 --> 00:03:17,200
talk

76
00:03:13,760 --> 00:03:19,120
about details so network stack so thanks

77
00:03:17,200 --> 00:03:20,399
uh michael so mikhail actually explained

78
00:03:19,120 --> 00:03:21,760
about what are the issues that we are

79
00:03:20,400 --> 00:03:24,159
having with iptables

80
00:03:21,760 --> 00:03:26,239
so everyone here would be aware about

81
00:03:24,159 --> 00:03:27,519
the linux network stack and how complex

82
00:03:26,239 --> 00:03:29,519
it has been um

83
00:03:27,519 --> 00:03:32,159
so the design process of the linux has

84
00:03:29,519 --> 00:03:34,640
been for years and

85
00:03:32,159 --> 00:03:35,920
the layers are pretty compact and each

86
00:03:34,640 --> 00:03:39,200
layers uh

87
00:03:35,920 --> 00:03:40,720
talk to each other layers and uh if any

88
00:03:39,200 --> 00:03:42,480
packet has to process they have to

89
00:03:40,720 --> 00:03:43,920
process through all these packets all

90
00:03:42,480 --> 00:03:45,440
these layers and

91
00:03:43,920 --> 00:03:47,920
we do have the net filter layer in

92
00:03:45,440 --> 00:03:50,400
between uh so in order to get rid of the

93
00:03:47,920 --> 00:03:51,119
net filter uh layer we need to come up

94
00:03:50,400 --> 00:03:52,959
with

95
00:03:51,120 --> 00:03:54,159
a similar filtering capability with the

96
00:03:52,959 --> 00:03:57,760
bpf

97
00:03:54,159 --> 00:03:59,280
so what we are doing is as

98
00:03:57,760 --> 00:04:01,599
the previous sessions also discussed

99
00:03:59,280 --> 00:04:03,200
about the hook points so the bpf has

100
00:04:01,599 --> 00:04:03,840
different hook points in the networking

101
00:04:03,200 --> 00:04:05,280
stack

102
00:04:03,840 --> 00:04:07,760
so you can see the different hook points

103
00:04:05,280 --> 00:04:08,400
for the bpf has and using these hook

104
00:04:07,760 --> 00:04:10,319
points

105
00:04:08,400 --> 00:04:12,239
we can actually achieve the similar

106
00:04:10,319 --> 00:04:14,879
functionality that ipfilter

107
00:04:12,239 --> 00:04:18,000
has and has been providing for the

108
00:04:14,879 --> 00:04:20,798
customers for years

109
00:04:18,000 --> 00:04:22,400
so um so this is just a comparison about

110
00:04:20,798 --> 00:04:24,400
the legacy ip tables

111
00:04:22,400 --> 00:04:25,919
and the enhanced version of the ip

112
00:04:24,400 --> 00:04:28,638
tables with the nf tables

113
00:04:25,919 --> 00:04:30,880
um that have been used and then the bpf

114
00:04:28,639 --> 00:04:32,000
filters with the host driver and the bp

115
00:04:30,880 --> 00:04:34,000
filter with the

116
00:04:32,000 --> 00:04:35,680
hardware offload so you can see uh

117
00:04:34,000 --> 00:04:37,759
there's a substantial

118
00:04:35,680 --> 00:04:42,080
increase in performance by using the bpf

119
00:04:37,759 --> 00:04:44,639
filters against ib tables

120
00:04:42,080 --> 00:04:45,919
so this picture uh gives you an overview

121
00:04:44,639 --> 00:04:48,960
of uh how

122
00:04:45,919 --> 00:04:50,560
the bpf utilizes the filtering

123
00:04:48,960 --> 00:04:53,520
capabilities that ip

124
00:04:50,560 --> 00:04:54,560
filter used to do for the networking so

125
00:04:53,520 --> 00:04:57,280
uh in this picture

126
00:04:54,560 --> 00:04:58,960
we are seeing the five different chains

127
00:04:57,280 --> 00:05:01,039
that are currently available for any

128
00:04:58,960 --> 00:05:02,880
packet to traverse these chains

129
00:05:01,039 --> 00:05:04,400
so the decisions are made based upon

130
00:05:02,880 --> 00:05:06,080
where the packet needs to reach

131
00:05:04,400 --> 00:05:07,679
whether it's going to be inbound whether

132
00:05:06,080 --> 00:05:09,039
it's going to be outbound whether it's

133
00:05:07,680 --> 00:05:11,280
going to be

134
00:05:09,039 --> 00:05:12,400
egressed or interest so based on that

135
00:05:11,280 --> 00:05:14,799
you can see

136
00:05:12,400 --> 00:05:15,919
the yellow loops in here those are the

137
00:05:14,800 --> 00:05:17,759
net filter

138
00:05:15,919 --> 00:05:19,198
capabilities positions that we are

139
00:05:17,759 --> 00:05:20,880
having and then

140
00:05:19,199 --> 00:05:23,440
the routing decisions are happening in

141
00:05:20,880 --> 00:05:24,880
the input and forwarding and output

142
00:05:23,440 --> 00:05:26,639
as well as the netting is happening

143
00:05:24,880 --> 00:05:27,280
either in the pre-routing or in the post

144
00:05:26,639 --> 00:05:29,840
routing

145
00:05:27,280 --> 00:05:32,799
so in in case we wanted to achieve the

146
00:05:29,840 --> 00:05:34,880
same functionality with bpf filters

147
00:05:32,800 --> 00:05:36,080
we are planning to have the ppf code

148
00:05:34,880 --> 00:05:37,919
running

149
00:05:36,080 --> 00:05:39,919
in any one of the hook points that we

150
00:05:37,919 --> 00:05:41,919
already mentioned but in for the example

151
00:05:39,919 --> 00:05:46,159
case we are taking that we are actually

152
00:05:41,919 --> 00:05:49,919
uh applying the bpf code in the tc

153
00:05:46,160 --> 00:05:51,360
hook point so by applying this we are

154
00:05:49,919 --> 00:05:52,880
going to achieve similar

155
00:05:51,360 --> 00:05:54,720
functionality i'm going to show you the

156
00:05:52,880 --> 00:05:55,759
picture here so the pink region that

157
00:05:54,720 --> 00:05:57,840
you're seeing here

158
00:05:55,759 --> 00:05:59,199
the both the pink boxes are the bpf

159
00:05:57,840 --> 00:06:00,638
programs that are running on the hook

160
00:05:59,199 --> 00:06:03,440
points for the tc

161
00:06:00,639 --> 00:06:04,319
and those chains that are shown here are

162
00:06:03,440 --> 00:06:05,919
the

163
00:06:04,319 --> 00:06:07,600
english chain forwarding chain and

164
00:06:05,919 --> 00:06:09,359
output chain and we also have

165
00:06:07,600 --> 00:06:11,039
the netting capabilities as well for the

166
00:06:09,360 --> 00:06:13,520
pre-routing and post routing

167
00:06:11,039 --> 00:06:15,599
but for simplicity purposes i have taken

168
00:06:13,520 --> 00:06:18,318
these three chains in order to explain

169
00:06:15,600 --> 00:06:20,639
uh how we are achieving it through bpf

170
00:06:18,319 --> 00:06:23,520
and also connection tracking is involved

171
00:06:20,639 --> 00:06:25,280
so in all these cases uh we do have a

172
00:06:23,520 --> 00:06:27,520
hook point on the tc when the packet

173
00:06:25,280 --> 00:06:29,599
enters uh the hook point actually

174
00:06:27,520 --> 00:06:31,280
uh takes into consideration that there

175
00:06:29,600 --> 00:06:32,720
is a packet arriving and there if there

176
00:06:31,280 --> 00:06:34,239
is a vpf program that has been

177
00:06:32,720 --> 00:06:36,639
programmed to

178
00:06:34,240 --> 00:06:38,000
take care of it so it takes care either

179
00:06:36,639 --> 00:06:40,400
in the english chain or out

180
00:06:38,000 --> 00:06:41,680
of the interest chain and then it

181
00:06:40,400 --> 00:06:43,440
applies the

182
00:06:41,680 --> 00:06:45,840
filtering rules based upon what we have

183
00:06:43,440 --> 00:06:47,919
configured

184
00:06:45,840 --> 00:06:49,198
so the i think in the previous session

185
00:06:47,919 --> 00:06:51,359
also we saw that

186
00:06:49,199 --> 00:06:53,440
bpf filters has a capability that you

187
00:06:51,360 --> 00:06:54,960
can actually point one bpf filter to

188
00:06:53,440 --> 00:06:55,840
another vpn filter which is called as

189
00:06:54,960 --> 00:06:58,479
bpf

190
00:06:55,840 --> 00:07:00,000
uh tail calls uh so we can achieve a

191
00:06:58,479 --> 00:07:00,719
similar filtering capabilities with

192
00:07:00,000 --> 00:07:04,400
respect to

193
00:07:00,720 --> 00:07:07,360
bpf tail calls where each of the ebpf

194
00:07:04,400 --> 00:07:08,880
program can actually do a partial

195
00:07:07,360 --> 00:07:11,520
filtering on based on

196
00:07:08,880 --> 00:07:12,319
what the content has been uh derived for

197
00:07:11,520 --> 00:07:14,240
so basically

198
00:07:12,319 --> 00:07:16,240
one can do a header parsing the other

199
00:07:14,240 --> 00:07:18,479
can do an ip look up

200
00:07:16,240 --> 00:07:19,840
so all these things change together can

201
00:07:18,479 --> 00:07:21,919
actually provide a

202
00:07:19,840 --> 00:07:23,599
filtering capability that ip cables can

203
00:07:21,919 --> 00:07:24,240
provide and all these things are

204
00:07:23,599 --> 00:07:26,639
happening

205
00:07:24,240 --> 00:07:27,680
dynamically without any intrusion or

206
00:07:26,639 --> 00:07:29,520
without any kernel

207
00:07:27,680 --> 00:07:31,199
reprogramming so that's the advantage of

208
00:07:29,520 --> 00:07:34,000
ppf program

209
00:07:31,199 --> 00:07:34,800
i'll give back to michal to take it over

210
00:07:34,000 --> 00:07:37,759
from here

211
00:07:34,800 --> 00:07:38,880
yes so here there are examples of the

212
00:07:37,759 --> 00:07:41,360
other project

213
00:07:38,880 --> 00:07:42,719
psilium that are using bpf there is a

214
00:07:41,360 --> 00:07:45,759
load balancer written

215
00:07:42,720 --> 00:07:47,120
by facebook which is open songs which is

216
00:07:45,759 --> 00:07:49,840
called katran

217
00:07:47,120 --> 00:07:51,680
perth the utility linux utility is using

218
00:07:49,840 --> 00:07:54,080
bpf already for

219
00:07:51,680 --> 00:07:54,879
tracing the current function calls

220
00:07:54,080 --> 00:07:58,000
systemd

221
00:07:54,879 --> 00:08:02,080
has a basic firewall based

222
00:07:58,000 --> 00:08:04,960
on bpf so you can define basic roofs for

223
00:08:02,080 --> 00:08:06,719
services suricata is using bpf

224
00:08:04,960 --> 00:08:10,719
extensively

225
00:08:06,720 --> 00:08:13,840
openv switch has the af xdp driver

226
00:08:10,720 --> 00:08:16,240
fxdp is the

227
00:08:13,840 --> 00:08:18,960
let's say alternative to the pkk or the

228
00:08:16,240 --> 00:08:22,720
dpdk itself is also supporting it

229
00:08:18,960 --> 00:08:25,840
so dpdk in dpdk normally

230
00:08:22,720 --> 00:08:27,440
uh you expose the network device

231
00:08:25,840 --> 00:08:32,478
directly to the user space

232
00:08:27,440 --> 00:08:32,479
and the ptk has a network driver to

233
00:08:33,039 --> 00:08:38,000
to use that network card but in case of

234
00:08:35,839 --> 00:08:40,399
af xdp

235
00:08:38,000 --> 00:08:41,679
you use the network drivers in the

236
00:08:40,399 --> 00:08:45,360
kernel

237
00:08:41,679 --> 00:08:46,000
but you have the direct memory access to

238
00:08:45,360 --> 00:08:50,560
the network

239
00:08:46,000 --> 00:08:52,640
card and you can bypass the rest of

240
00:08:50,560 --> 00:08:54,640
linux kernel network abstraction you've

241
00:08:52,640 --> 00:08:56,800
seen in the previous slides and

242
00:08:54,640 --> 00:08:59,600
redirect the packet directly to the user

243
00:08:56,800 --> 00:09:00,000
space so it's like similar to dpdk in

244
00:08:59,600 --> 00:09:03,200
terms

245
00:09:00,000 --> 00:09:05,519
that's uh it's a

246
00:09:03,200 --> 00:09:06,320
datapath acceleration technology there

247
00:09:05,519 --> 00:09:09,279
is also

248
00:09:06,320 --> 00:09:10,880
you can use af xdp as a pm the driver in

249
00:09:09,279 --> 00:09:14,160
dpdk actually

250
00:09:10,880 --> 00:09:17,120
but yeah you are still using the

251
00:09:14,160 --> 00:09:17,680
network device drivers in kernel and

252
00:09:17,120 --> 00:09:22,080
yeah

253
00:09:17,680 --> 00:09:25,040
the list of projects using bpf will grow

254
00:09:22,080 --> 00:09:28,480
and grow in the time and these are

255
00:09:25,040 --> 00:09:31,519
companies which are using bpf

256
00:09:28,480 --> 00:09:34,800
so google red hat netflix souza

257
00:09:31,519 --> 00:09:38,000
we are using it because

258
00:09:34,800 --> 00:09:41,359
we are in our distribution of kubernetes

259
00:09:38,000 --> 00:09:46,080
suse container as a service platform

260
00:09:41,360 --> 00:09:49,120
we are using celium as the cni driver

261
00:09:46,080 --> 00:09:52,560
so we explained what bpf is

262
00:09:49,120 --> 00:09:54,399
briefly and now we will talk more about

263
00:09:52,560 --> 00:09:56,399
psyllium itself and what kind of

264
00:09:54,399 --> 00:09:59,920
features it has

265
00:09:56,399 --> 00:10:00,640
so psyllium uh consists of several

266
00:09:59,920 --> 00:10:03,120
components

267
00:10:00,640 --> 00:10:04,319
the main of it is the agent which runs

268
00:10:03,120 --> 00:10:06,399
on every note

269
00:10:04,320 --> 00:10:08,160
in the kubernetes cluster and it

270
00:10:06,399 --> 00:10:11,680
actually takes care of

271
00:10:08,160 --> 00:10:14,560
uh generating the ppf programs and

272
00:10:11,680 --> 00:10:16,719
loading them into into the kernel and

273
00:10:14,560 --> 00:10:20,079
you have several other components

274
00:10:16,720 --> 00:10:23,040
to interact with celium like the cli

275
00:10:20,079 --> 00:10:24,959
like plugins to different container

276
00:10:23,040 --> 00:10:28,800
runtimes

277
00:10:24,959 --> 00:10:28,800
or the policy repository

278
00:10:29,120 --> 00:10:36,560
and speaking about cni itself

279
00:10:33,279 --> 00:10:38,399
yeah maybe it's too much to

280
00:10:36,560 --> 00:10:41,518
to talk because we have five minutes

281
00:10:38,399 --> 00:10:44,399
left but yeah cnn is the specification

282
00:10:41,519 --> 00:10:46,079
used by kubernetes for creating or

283
00:10:44,399 --> 00:10:49,279
deleting the network

284
00:10:46,079 --> 00:10:52,800
interfaces uh and cni

285
00:10:49,279 --> 00:10:55,600
plugins are responsible for uh create

286
00:10:52,800 --> 00:10:58,000
for creating the network interface

287
00:10:55,600 --> 00:11:00,880
getting the ip address and s

288
00:10:58,000 --> 00:11:03,040
implementing of that so basically when

289
00:11:00,880 --> 00:11:05,360
you create the pot with kubectl

290
00:11:03,040 --> 00:11:07,439
you of course call firstly the

291
00:11:05,360 --> 00:11:11,600
kubernetes api server

292
00:11:07,440 --> 00:11:15,839
the cubelet takes that request and

293
00:11:11,600 --> 00:11:17,200
cubelets calls the cri and the cri can

294
00:11:15,839 --> 00:11:20,480
be

295
00:11:17,200 --> 00:11:24,240
docker shim container d or cryo

296
00:11:20,480 --> 00:11:26,399
and then usually the cri implementation

297
00:11:24,240 --> 00:11:28,959
caused the cni plugin

298
00:11:26,399 --> 00:11:30,800
to create the uh to create the network

299
00:11:28,959 --> 00:11:32,079
interface and provision the networking

300
00:11:30,800 --> 00:11:35,439
for the pod

301
00:11:32,079 --> 00:11:38,719
and in case of psyllium ethereum has its

302
00:11:35,440 --> 00:11:41,120
cni plug-in which uh caused the serium

303
00:11:38,720 --> 00:11:44,640
agent to request the ip address

304
00:11:41,120 --> 00:11:45,760
and then to it cause serium agents to

305
00:11:44,640 --> 00:11:48,720
actually create

306
00:11:45,760 --> 00:11:49,439
bpf programs which will handle the

307
00:11:48,720 --> 00:11:52,959
filtering

308
00:11:49,440 --> 00:11:55,600
and in case you are using serium for

309
00:11:52,959 --> 00:11:58,000
handling the packet encapsulation to the

310
00:11:55,600 --> 00:11:58,959
nodes it's also handled by bpf programs

311
00:11:58,000 --> 00:12:01,920
which

312
00:11:58,959 --> 00:12:04,638
serium agent creates and then the

313
00:12:01,920 --> 00:12:05,040
communication between those bpf programs

314
00:12:04,639 --> 00:12:07,920
which

315
00:12:05,040 --> 00:12:10,639
are loaded into the kernel goes through

316
00:12:07,920 --> 00:12:13,680
bpf maps which are exposed to

317
00:12:10,639 --> 00:12:16,480
the user space so serium agent after

318
00:12:13,680 --> 00:12:18,239
generating the pppf program compiling it

319
00:12:16,480 --> 00:12:21,200
loading into the kernel

320
00:12:18,240 --> 00:12:22,839
it keeps in contact with the ppf program

321
00:12:21,200 --> 00:12:26,160
by using

322
00:12:22,839 --> 00:12:29,360
maps and this is like the

323
00:12:26,160 --> 00:12:32,800
more general uh overview of

324
00:12:29,360 --> 00:12:34,880
how bpf looks like and how it works

325
00:12:32,800 --> 00:12:37,199
when we use it together with celium but

326
00:12:34,880 --> 00:12:40,399
also for example if you use

327
00:12:37,200 --> 00:12:44,639
a xdp which i mentioned to

328
00:12:40,399 --> 00:12:47,360
do a data plane acceleration to vms and

329
00:12:44,639 --> 00:12:47,360
containers

330
00:12:48,079 --> 00:12:54,160
and swarming it's your turn so

331
00:12:52,000 --> 00:12:55,760
so here's the details about the cni

332
00:12:54,160 --> 00:12:58,079
plug-in as um as he mentioned

333
00:12:55,760 --> 00:12:59,360
about uh how the cni plug-in gets

334
00:12:58,079 --> 00:13:02,319
involved in

335
00:12:59,360 --> 00:13:04,079
providing a networking access and

336
00:13:02,320 --> 00:13:05,519
providing ip address management and all

337
00:13:04,079 --> 00:13:07,519
those things so these are the internals

338
00:13:05,519 --> 00:13:09,600
that you can see when cni

339
00:13:07,519 --> 00:13:11,519
is configured where you have each of the

340
00:13:09,600 --> 00:13:14,639
containers has an internal

341
00:13:11,519 --> 00:13:15,279
interface and it has an um an lxc

342
00:13:14,639 --> 00:13:17,519
interface

343
00:13:15,279 --> 00:13:19,279
within the cni and also a physical

344
00:13:17,519 --> 00:13:20,000
interface to a node and and the nodes

345
00:13:19,279 --> 00:13:24,320
are interconnected

346
00:13:20,000 --> 00:13:26,480
in a cluster so the networking modes and

347
00:13:24,320 --> 00:13:29,519
then the policy will be taken care by

348
00:13:26,480 --> 00:13:31,600
michael yes so there are two networking

349
00:13:29,519 --> 00:13:34,399
modes basically in cilium

350
00:13:31,600 --> 00:13:37,040
you can use psyllium to actually

351
00:13:34,399 --> 00:13:40,399
encapsulate packet between nodes and the

352
00:13:37,040 --> 00:13:42,399
traditional mode like traditional

353
00:13:40,399 --> 00:13:43,440
the default method of doing that is

354
00:13:42,399 --> 00:13:46,800
vxlan

355
00:13:43,440 --> 00:13:49,279
but in case you want to use bgp

356
00:13:46,800 --> 00:13:51,519
or in case you are deploying your

357
00:13:49,279 --> 00:13:54,639
kubernetes cluster in the

358
00:13:51,519 --> 00:13:58,079
cloud environments like lws or

359
00:13:54,639 --> 00:13:58,720
gka you can use the direct routing where

360
00:13:58,079 --> 00:14:01,120
cdu

361
00:13:58,720 --> 00:14:03,360
doesn't fruit packets between nodes but

362
00:14:01,120 --> 00:14:06,240
you rather use something else to do that

363
00:14:03,360 --> 00:14:07,199
and yeah the most popular case of using

364
00:14:06,240 --> 00:14:11,360
the second mode

365
00:14:07,199 --> 00:14:15,760
is uh using it's in aws where you have

366
00:14:11,360 --> 00:14:18,399
eni and also the

367
00:14:15,760 --> 00:14:18,800
so you know basically the first method

368
00:14:18,399 --> 00:14:21,839
uh

369
00:14:18,800 --> 00:14:23,040
is more for bare metal installations at

370
00:14:21,839 --> 00:14:28,399
the second for

371
00:14:23,040 --> 00:14:28,399
cloud providers or bare metal with bgp

372
00:14:28,560 --> 00:14:34,880
and in case of uh the first

373
00:14:31,600 --> 00:14:37,040
option uh you have overlay the routing

374
00:14:34,880 --> 00:14:38,160
tunneling mode and you have the

375
00:14:37,040 --> 00:14:40,959
additional

376
00:14:38,160 --> 00:14:42,719
network header related to vxlan which is

377
00:14:40,959 --> 00:14:44,959
handled by celium

378
00:14:42,720 --> 00:14:46,880
and in the case of the other one you

379
00:14:44,959 --> 00:14:50,638
have source destination and payload

380
00:14:46,880 --> 00:14:53,439
and that's it

381
00:14:50,639 --> 00:14:54,160
and let's talk about uh packet filtering

382
00:14:53,440 --> 00:14:56,639
right now

383
00:14:54,160 --> 00:14:58,319
so kubernetes already provided by by

384
00:14:56,639 --> 00:15:00,959
itself the abstraction called

385
00:14:58,320 --> 00:15:03,440
network policies which applies on uh

386
00:15:00,959 --> 00:15:06,560
layer 3 and layer 4

387
00:15:03,440 --> 00:15:09,760
and one of the forms of

388
00:15:06,560 --> 00:15:12,239
pre-filtering is a label-based

389
00:15:09,760 --> 00:15:13,920
ingress filtering so let's imagine we

390
00:15:12,240 --> 00:15:18,320
have two labels

391
00:15:13,920 --> 00:15:21,680
uh two kind of rows in the clusters okay

392
00:15:18,320 --> 00:15:24,959
so you have front end and back end parts

393
00:15:21,680 --> 00:15:27,599
and uh so you can allow only front-end

394
00:15:24,959 --> 00:15:29,680
parts to contact the packet but

395
00:15:27,600 --> 00:15:31,920
deny everything else and there are

396
00:15:29,680 --> 00:15:34,160
examples also of

397
00:15:31,920 --> 00:15:36,800
egress filtering where you restrict the

398
00:15:34,160 --> 00:15:39,839
pot to connect to the outside world

399
00:15:36,800 --> 00:15:40,800
uh you have also for filtering for

400
00:15:39,839 --> 00:15:44,079
blocking

401
00:15:40,800 --> 00:15:44,880
the for allowing only particular pots to

402
00:15:44,079 --> 00:15:47,680
connect

403
00:15:44,880 --> 00:15:49,600
parts to connect in and as a filtering

404
00:15:47,680 --> 00:15:52,880
which also

405
00:15:49,600 --> 00:15:56,560
takes care about

406
00:15:52,880 --> 00:16:00,560
acknowledging http protocols or

407
00:15:56,560 --> 00:16:04,880
http endpoints you can connect to

408
00:16:00,560 --> 00:16:07,199
and i think yes

409
00:16:04,880 --> 00:16:09,279
so unfortunately we can't talk much

410
00:16:07,199 --> 00:16:23,040
about envoy because our time is

411
00:16:09,279 --> 00:16:26,290
up do you have any questions

412
00:16:23,040 --> 00:16:26,290
[Music]

413
00:16:30,740 --> 00:16:33,830
[Music]

414
00:16:40,720 --> 00:16:44,880
but in the case of i think edpf um the

415
00:16:43,600 --> 00:16:46,800
way the celium has been

416
00:16:44,880 --> 00:16:48,240
implemented it is is it is a little bit

417
00:16:46,800 --> 00:16:49,839
different than what i showed because

418
00:16:48,240 --> 00:16:51,600
i wanted to show a theoretical approach

419
00:16:49,839 --> 00:16:53,279
of how it has been handled

420
00:16:51,600 --> 00:16:55,040
in order for for us to get an

421
00:16:53,279 --> 00:16:56,560
understanding of how it is handled but

422
00:16:55,040 --> 00:16:59,279
in the case of ebpf

423
00:16:56,560 --> 00:17:00,319
that celium does is it has a map of like

424
00:16:59,279 --> 00:17:02,800
a source ip

425
00:17:00,320 --> 00:17:05,199
source port and then the ic cables and

426
00:17:02,800 --> 00:17:05,198
the tables

427
00:17:08,720 --> 00:17:11,760
no it's not just the um that's what i

428
00:17:11,439 --> 00:17:13,360
think

429
00:17:11,760 --> 00:17:15,119
michael mentioned it's not just because

430
00:17:13,359 --> 00:17:16,879
of uh ip and port

431
00:17:15,119 --> 00:17:18,319
the advantage that we have with celium

432
00:17:16,880 --> 00:17:20,559
is based on labels okay

433
00:17:18,319 --> 00:17:22,000
and you can actually provide uh level

434
00:17:20,559 --> 00:17:25,039
label based filtering where

435
00:17:22,000 --> 00:17:26,000
you cannot do with that in filtering and

436
00:17:25,039 --> 00:17:29,520
also in the case of

437
00:17:26,000 --> 00:17:31,600
um the q proxy

438
00:17:29,520 --> 00:17:33,760
q proxy basically uses ip tables and we

439
00:17:31,600 --> 00:17:35,760
have seen a degradation in performance

440
00:17:33,760 --> 00:17:40,720
when there are a lot of iptable rules

441
00:17:35,760 --> 00:17:40,720
that are handled at the point

442
00:17:40,880 --> 00:17:45,440
yeah so even by including ipsed or or

443
00:17:43,440 --> 00:17:47,600
even by going with a new version of

444
00:17:45,440 --> 00:17:50,559
ip tables the nf tables we have seen a

445
00:17:47,600 --> 00:17:55,120
degradation in performance and if we

446
00:17:50,559 --> 00:18:01,840
i'm very sorry all right

447
00:17:55,120 --> 00:18:01,840
thank you guys

448
00:18:05,600 --> 00:18:07,678
you

