1
00:00:11,759 --> 00:00:15,360
hello everybody

2
00:00:12,880 --> 00:00:16,880
welcome to foster lightning talks in

3
00:00:15,360 --> 00:00:19,198
building age

4
00:00:16,880 --> 00:00:20,720
i want to introduce you harness mule

5
00:00:19,199 --> 00:00:24,480
eisen where we talk about

6
00:00:20,720 --> 00:00:31,598
duck db an embedded analytic database

7
00:00:24,480 --> 00:00:33,840
and give him a warm welcome

8
00:00:31,599 --> 00:00:35,440
thank you welcome everybody um so a

9
00:00:33,840 --> 00:00:38,000
quick introduction

10
00:00:35,440 --> 00:00:39,680
so i work at cwi which is the dutch

11
00:00:38,000 --> 00:00:41,360
national research lab for computer

12
00:00:39,680 --> 00:00:44,160
science and mathematics

13
00:00:41,360 --> 00:00:46,960
i also teach computer science students

14
00:00:44,160 --> 00:00:49,360
about the wonderful world of databases

15
00:00:46,960 --> 00:00:50,879
but i have found out that a good way of

16
00:00:49,360 --> 00:00:51,680
learning about databases is building

17
00:00:50,879 --> 00:00:54,000
them

18
00:00:51,680 --> 00:00:55,680
and therefore i also do that and today

19
00:00:54,000 --> 00:00:56,800
i'd like to talk to you about one of

20
00:00:55,680 --> 00:00:59,600
these products

21
00:00:56,800 --> 00:01:00,559
and that is duckdb obviously duckdb is

22
00:00:59,600 --> 00:01:03,359
not my

23
00:01:00,559 --> 00:01:04,399
own sort of sole creation but there's of

24
00:01:03,359 --> 00:01:07,200
other people involved

25
00:01:04,400 --> 00:01:08,400
most notably mark rusfeld who is not

26
00:01:07,200 --> 00:01:10,159
here today

27
00:01:08,400 --> 00:01:11,920
um so we're going to talk about duckdb

28
00:01:10,159 --> 00:01:12,880
and duck to be the database management

29
00:01:11,920 --> 00:01:15,680
system

30
00:01:12,880 --> 00:01:16,158
and it's new it's completely new and

31
00:01:15,680 --> 00:01:19,200
it's

32
00:01:16,159 --> 00:01:20,799
focused specifically to be embeddable

33
00:01:19,200 --> 00:01:22,960
which means not embeddable as in

34
00:01:20,799 --> 00:01:25,840
hardware but embeddable as in embeddable

35
00:01:22,960 --> 00:01:27,520
into other software

36
00:01:25,840 --> 00:01:29,360
and it's analytical which means that

37
00:01:27,520 --> 00:01:31,280
it's focused on

38
00:01:29,360 --> 00:01:32,400
crunching through large amounts of data

39
00:01:31,280 --> 00:01:34,640
as opposed to

40
00:01:32,400 --> 00:01:36,479
you know dealing with uh transactions

41
00:01:34,640 --> 00:01:37,600
like you know orders in your online shop

42
00:01:36,479 --> 00:01:38,240
so if you want to do orders in your

43
00:01:37,600 --> 00:01:39,759
online shop

44
00:01:38,240 --> 00:01:41,679
go to up to the postgres people next

45
00:01:39,759 --> 00:01:44,079
door if you want to crunch large amount

46
00:01:41,680 --> 00:01:47,840
of data you can use duck tv

47
00:01:44,079 --> 00:01:51,679
um now i have to find out whether my

48
00:01:47,840 --> 00:01:53,200
clicker works it does um it is common to

49
00:01:51,680 --> 00:01:55,040
start these kind of talks with a

50
00:01:53,200 --> 00:01:56,240
description of how terrible the state of

51
00:01:55,040 --> 00:01:59,040
this world is

52
00:01:56,240 --> 00:02:00,079
um this is no exception the present is

53
00:01:59,040 --> 00:02:03,360
very bad

54
00:02:00,079 --> 00:02:04,880
um the data management in data analytics

55
00:02:03,360 --> 00:02:06,479
is a huge mess

56
00:02:04,880 --> 00:02:07,920
i don't know if anybody of you has ever

57
00:02:06,479 --> 00:02:10,560
tried to use things like

58
00:02:07,920 --> 00:02:12,000
pandas and that's great it works with

59
00:02:10,560 --> 00:02:13,200
the five examples that they have on the

60
00:02:12,000 --> 00:02:15,920
website but

61
00:02:13,200 --> 00:02:16,399
um one of the problems there that is

62
00:02:15,920 --> 00:02:19,760
really

63
00:02:16,400 --> 00:02:21,280
um overwhelming is the um

64
00:02:19,760 --> 00:02:22,879
in the data storage itself you know

65
00:02:21,280 --> 00:02:24,480
people tend to have

66
00:02:22,879 --> 00:02:26,560
these text files used where you know

67
00:02:24,480 --> 00:02:28,399
there's a well-known folder structure

68
00:02:26,560 --> 00:02:29,440
somewhere which has a bunch of csv files

69
00:02:28,400 --> 00:02:30,879
in it and there is

70
00:02:29,440 --> 00:02:32,560
maybe some code on top of that that

71
00:02:30,879 --> 00:02:36,160
decides which csv file to

72
00:02:32,560 --> 00:02:38,480
should be read once we have load

73
00:02:36,160 --> 00:02:40,560
loaded these files um we have these

74
00:02:38,480 --> 00:02:42,879
crude query processing engines

75
00:02:40,560 --> 00:02:43,840
for example the one that is in in pandas

76
00:02:42,879 --> 00:02:47,200
or

77
00:02:43,840 --> 00:02:50,319
the one that is in the r environment

78
00:02:47,200 --> 00:02:51,679
um once people decide that csv files are

79
00:02:50,319 --> 00:02:53,760
too slow they start

80
00:02:51,680 --> 00:02:55,440
inventing their own crude hand-rolled

81
00:02:53,760 --> 00:02:58,720
binary formats

82
00:02:55,440 --> 00:02:59,920
that are on disk maybe and and start

83
00:02:58,720 --> 00:03:03,519
processing those there's

84
00:02:59,920 --> 00:03:06,399
been a recent push in the direction um

85
00:03:03,519 --> 00:03:07,599
in generally this is sort of a zoo of

86
00:03:06,400 --> 00:03:09,840
one of solutions

87
00:03:07,599 --> 00:03:11,200
um and that makes like secondary

88
00:03:09,840 --> 00:03:12,480
problems like for example changing

89
00:03:11,200 --> 00:03:13,920
anything about the data that you have

90
00:03:12,480 --> 00:03:17,200
very difficult

91
00:03:13,920 --> 00:03:19,679
so this is bad um we don't want this

92
00:03:17,200 --> 00:03:21,200
um and these things are solve problems

93
00:03:19,680 --> 00:03:22,560
you know we have data management systems

94
00:03:21,200 --> 00:03:26,079
they've been around

95
00:03:22,560 --> 00:03:27,840
uh for 50 years or so um and

96
00:03:26,080 --> 00:03:29,680
what we're trying to do with db is make

97
00:03:27,840 --> 00:03:33,040
them usable also for these

98
00:03:29,680 --> 00:03:35,840
data analysis tasks that are so common

99
00:03:33,040 --> 00:03:37,519
so here so now this is the contra the

100
00:03:35,840 --> 00:03:41,920
future is bright obviously

101
00:03:37,519 --> 00:03:45,440
um with sqlite uh sorry with duct tape

102
00:03:41,920 --> 00:03:47,518
who has used sqlite okay this is

103
00:03:45,440 --> 00:03:49,440
very many people and in fact everybody

104
00:03:47,519 --> 00:03:50,959
has used sqlite because it is in every

105
00:03:49,440 --> 00:03:54,079
browser every phone

106
00:03:50,959 --> 00:03:55,840
um and every device that you can imagine

107
00:03:54,080 --> 00:03:58,080
um what we're trying to do is build

108
00:03:55,840 --> 00:04:00,640
something similar to sqlite

109
00:03:58,080 --> 00:04:02,239
but very different in sort of the um

110
00:04:00,640 --> 00:04:04,879
intended features

111
00:04:02,239 --> 00:04:06,239
um in the sense of what kind of data

112
00:04:04,879 --> 00:04:08,159
analysis questions

113
00:04:06,239 --> 00:04:09,840
you want to ask so you want to do anal

114
00:04:08,159 --> 00:04:12,560
data analytics in

115
00:04:09,840 --> 00:04:14,560
contrast to with sqlite where you do

116
00:04:12,560 --> 00:04:18,079
transactional data management

117
00:04:14,560 --> 00:04:21,199
and how do we do this um we have built a

118
00:04:18,079 --> 00:04:23,120
very fast so-called vectorized data

119
00:04:21,199 --> 00:04:25,759
processing engine i will explain to you

120
00:04:23,120 --> 00:04:28,160
in a bit uh what that is

121
00:04:25,759 --> 00:04:29,120
and we have stolen a lot of good ideas

122
00:04:28,160 --> 00:04:32,000
from sqlite

123
00:04:29,120 --> 00:04:33,199
for example and ductdb does not require

124
00:04:32,000 --> 00:04:36,479
you to

125
00:04:33,199 --> 00:04:38,960
run a separate server um you know this

126
00:04:36,479 --> 00:04:40,320
idea that you have to run a daemon that

127
00:04:38,960 --> 00:04:42,320
is your database that you have to kind

128
00:04:40,320 --> 00:04:43,199
of set up and configure and restart and

129
00:04:42,320 --> 00:04:45,759
whatever

130
00:04:43,199 --> 00:04:47,040
no it's kind of database as a library

131
00:04:45,759 --> 00:04:50,720
you run

132
00:04:47,040 --> 00:04:53,440
the duckdb system inside your process

133
00:04:50,720 --> 00:04:54,160
this has a nice side effect that data

134
00:04:53,440 --> 00:04:55,840
transfer

135
00:04:54,160 --> 00:04:58,800
from whatever you were using to talk to

136
00:04:55,840 --> 00:05:00,400
duckdb and that db becomes very fast

137
00:04:58,800 --> 00:05:02,240
and this is for data analysis this is

138
00:05:00,400 --> 00:05:04,479
really a critical question

139
00:05:02,240 --> 00:05:06,080
we've written a paper it was quite fun

140
00:05:04,479 --> 00:05:07,520
measuring for example the client

141
00:05:06,080 --> 00:05:10,479
protocol speed of various

142
00:05:07,520 --> 00:05:11,758
popular databases and the guys next door

143
00:05:10,479 --> 00:05:14,880
from postgres they

144
00:05:11,759 --> 00:05:16,639
came pretty badly what we also have

145
00:05:14,880 --> 00:05:17,440
stolen from sqlite is the idea that you

146
00:05:16,639 --> 00:05:19,919
have a single

147
00:05:17,440 --> 00:05:20,960
file storage format so basically where

148
00:05:19,919 --> 00:05:23,680
all your database

149
00:05:20,960 --> 00:05:24,000
no matter how complex it is no matter

150
00:05:23,680 --> 00:05:27,360
how many

151
00:05:24,000 --> 00:05:29,199
tables it has is in a single file

152
00:05:27,360 --> 00:05:30,960
and we've also stolen the idea of that

153
00:05:29,199 --> 00:05:33,600
it should be simple to install

154
00:05:30,960 --> 00:05:34,000
more on that in a bit so this is uh this

155
00:05:33,600 --> 00:05:37,039
is

156
00:05:34,000 --> 00:05:38,720
the bright future um how do we make that

157
00:05:37,039 --> 00:05:41,840
work

158
00:05:38,720 --> 00:05:44,000
um so dr b is a library so

159
00:05:41,840 --> 00:05:45,520
think of a just a package a library that

160
00:05:44,000 --> 00:05:48,560
you embed into your

161
00:05:45,520 --> 00:05:50,400
application um we have zero external

162
00:05:48,560 --> 00:05:51,199
dependencies this is really something

163
00:05:50,400 --> 00:05:54,638
that

164
00:05:51,199 --> 00:05:56,000
that took a lot of work but it is

165
00:05:54,639 --> 00:05:58,319
something that we believe

166
00:05:56,000 --> 00:06:00,000
is is actually quite necessary for a

167
00:05:58,319 --> 00:06:02,880
library to be successful

168
00:06:00,000 --> 00:06:05,680
is that you don't have to install 57

169
00:06:02,880 --> 00:06:08,639
other programs before you can use it

170
00:06:05,680 --> 00:06:10,479
in fact we have a special way to build

171
00:06:08,639 --> 00:06:12,720
activity that results in two files one

172
00:06:10,479 --> 00:06:16,159
header and one implementation

173
00:06:12,720 --> 00:06:18,319
um ductdb has a the on the base layer is

174
00:06:16,160 --> 00:06:20,880
a c plus plus api

175
00:06:18,319 --> 00:06:21,680
we have full sql support so i went

176
00:06:20,880 --> 00:06:24,639
through um

177
00:06:21,680 --> 00:06:26,800
the these wonderful job of implementing

178
00:06:24,639 --> 00:06:28,400
things like window functions in uh in a

179
00:06:26,800 --> 00:06:29,280
database system which i can tell you are

180
00:06:28,400 --> 00:06:30,880
not fun

181
00:06:29,280 --> 00:06:32,719
so you don't have to do it because you

182
00:06:30,880 --> 00:06:36,479
can use duckdb

183
00:06:32,720 --> 00:06:38,639
um we also have built a wrapper

184
00:06:36,479 --> 00:06:40,159
for the api that sqlite uses so in

185
00:06:38,639 --> 00:06:41,280
principle what you can do if you have an

186
00:06:40,160 --> 00:06:44,560
application

187
00:06:41,280 --> 00:06:46,159
that talks to sqlite you can do some

188
00:06:44,560 --> 00:06:48,080
library preload tricks and it will use

189
00:06:46,160 --> 00:06:50,240
duckdb instead so this is

190
00:06:48,080 --> 00:06:52,318
something that we have done to make it

191
00:06:50,240 --> 00:06:54,560
easy to to switch

192
00:06:52,319 --> 00:06:56,240
we've also learned from previous project

193
00:06:54,560 --> 00:06:58,479
how important it is to integrate with

194
00:06:56,240 --> 00:07:00,720
the tools that people are using

195
00:06:58,479 --> 00:07:01,599
in terms of data analysis people use r

196
00:07:00,720 --> 00:07:04,319
and python

197
00:07:01,599 --> 00:07:06,319
so there are packages for r and python

198
00:07:04,319 --> 00:07:08,400
i'll show an example in a bit

199
00:07:06,319 --> 00:07:09,759
that basically include everything that

200
00:07:08,400 --> 00:07:12,799
you need to run

201
00:07:09,759 --> 00:07:15,440
duckdb as well and just to wrap it up

202
00:07:12,800 --> 00:07:17,360
there is a command line interface

203
00:07:15,440 --> 00:07:21,039
and for the people that want to do the

204
00:07:17,360 --> 00:07:23,520
web stuff we have a rest server as well

205
00:07:21,039 --> 00:07:24,719
let's show some examples so here is an

206
00:07:23,520 --> 00:07:27,440
example for

207
00:07:24,720 --> 00:07:28,880
for python which by the way was also

208
00:07:27,440 --> 00:07:30,560
invented at cwi so

209
00:07:28,880 --> 00:07:33,039
we are kind of obliged to integrate with

210
00:07:30,560 --> 00:07:35,120
python

211
00:07:33,039 --> 00:07:36,960
you say pip install duckdb that's very

212
00:07:35,120 --> 00:07:38,720
complicated

213
00:07:36,960 --> 00:07:40,080
and then you have it installed there's

214
00:07:38,720 --> 00:07:42,639
no additional

215
00:07:40,080 --> 00:07:43,440
software required all the batteries

216
00:07:42,639 --> 00:07:45,759
included

217
00:07:43,440 --> 00:07:48,479
um and then you can just use this

218
00:07:45,759 --> 00:07:50,720
wonderful python database api where you

219
00:07:48,479 --> 00:07:52,560
um yeah you connect to a database in

220
00:07:50,720 --> 00:07:54,000
this case a database is a file so this

221
00:07:52,560 --> 00:07:56,800
would be a file

222
00:07:54,000 --> 00:07:58,319
um and then you can run sql queries

223
00:07:56,800 --> 00:08:00,080
which is

224
00:07:58,319 --> 00:08:01,840
a required you know skill that you have

225
00:08:00,080 --> 00:08:04,159
to have to work with db

226
00:08:01,840 --> 00:08:05,599
or maybe not because in the r world we

227
00:08:04,160 --> 00:08:07,759
have

228
00:08:05,599 --> 00:08:09,360
a similar integration where you you know

229
00:08:07,759 --> 00:08:10,960
you loaded up the database you connect

230
00:08:09,360 --> 00:08:12,479
to your database file

231
00:08:10,960 --> 00:08:14,799
and the our people have invented this

232
00:08:12,479 --> 00:08:16,719
wonderful deep flyer

233
00:08:14,800 --> 00:08:18,080
system of actually programmatically

234
00:08:16,720 --> 00:08:21,440
expressing queries which is

235
00:08:18,080 --> 00:08:23,198
quite nice um and finally

236
00:08:21,440 --> 00:08:24,879
the c plus plus api i wanted to show you

237
00:08:23,199 --> 00:08:28,080
for the people that are more

238
00:08:24,879 --> 00:08:29,919
in c land is really just that this is

239
00:08:28,080 --> 00:08:32,000
the actual fully functioning

240
00:08:29,919 --> 00:08:32,958
minimum integration of duckdb into c

241
00:08:32,000 --> 00:08:35,599
plus plus

242
00:08:32,958 --> 00:08:36,718
uh where again you know you you specify

243
00:08:35,599 --> 00:08:38,719
which file you want

244
00:08:36,719 --> 00:08:40,880
your database to be stored in and then

245
00:08:38,719 --> 00:08:44,240
you can merely run

246
00:08:40,880 --> 00:08:46,640
sql queries so that's the outside view

247
00:08:44,240 --> 00:08:48,320
right so it's not very exciting

248
00:08:46,640 --> 00:08:50,080
i realize this i mean not many people

249
00:08:48,320 --> 00:08:51,760
get excited about databases i'm one of

250
00:08:50,080 --> 00:08:53,440
the few

251
00:08:51,760 --> 00:08:55,120
but it is a tool that you can use to

252
00:08:53,440 --> 00:08:56,480
store your data and you can actually and

253
00:08:55,120 --> 00:08:59,040
this is the big difference

254
00:08:56,480 --> 00:08:59,760
you can get it out again quickly and you

255
00:08:59,040 --> 00:09:02,160
can run

256
00:08:59,760 --> 00:09:04,319
queries on large amounts of data on your

257
00:09:02,160 --> 00:09:07,279
local computer quite quickly

258
00:09:04,320 --> 00:09:09,440
now how do we do this um let me talk

259
00:09:07,279 --> 00:09:11,920
briefly about some internals

260
00:09:09,440 --> 00:09:13,680
um so we have something called

261
00:09:11,920 --> 00:09:15,279
vectorized processing i'm not gonna talk

262
00:09:13,680 --> 00:09:17,519
a lot about the other things

263
00:09:15,279 --> 00:09:19,120
but um this is the core of the engine

264
00:09:17,519 --> 00:09:21,120
that makes it fast

265
00:09:19,120 --> 00:09:22,800
um and you have to under to understand

266
00:09:21,120 --> 00:09:25,120
vectorized processing

267
00:09:22,800 --> 00:09:26,800
you have to understand that database

268
00:09:25,120 --> 00:09:27,040
engines comes in different flavors that

269
00:09:26,800 --> 00:09:28,640
is

270
00:09:27,040 --> 00:09:30,880
traditionally coupled at the time this

271
00:09:28,640 --> 00:09:31,680
is what postgresql sql sqlite everybody

272
00:09:30,880 --> 00:09:34,080
uses

273
00:09:31,680 --> 00:09:34,880
is basically we look at one row of data

274
00:09:34,080 --> 00:09:36,800
at a time

275
00:09:34,880 --> 00:09:38,080
in the process of running queries that's

276
00:09:36,800 --> 00:09:40,560
great

277
00:09:38,080 --> 00:09:41,600
however it's slow then we have the

278
00:09:40,560 --> 00:09:43,839
pandas numpy

279
00:09:41,600 --> 00:09:45,760
r way of doing things where we look at

280
00:09:43,839 --> 00:09:47,680
one column at a time

281
00:09:45,760 --> 00:09:49,760
which is faster but has issues when the

282
00:09:47,680 --> 00:09:51,680
data becomes bigger than memory

283
00:09:49,760 --> 00:09:53,519
and then finally we have vectorized

284
00:09:51,680 --> 00:09:55,279
processing which is kind of the

285
00:09:53,519 --> 00:09:57,440
the middle ground where you look at

286
00:09:55,279 --> 00:09:59,279
chunks of data at a time

287
00:09:57,440 --> 00:10:00,560
and this is a very nice thing because

288
00:09:59,279 --> 00:10:02,160
that means that

289
00:10:00,560 --> 00:10:04,640
the data that we look at in the query

290
00:10:02,160 --> 00:10:05,279
fits into the higher in the cpu cache

291
00:10:04,640 --> 00:10:08,480
hierarchy

292
00:10:05,279 --> 00:10:10,959
um so here on the right you see a short

293
00:10:08,480 --> 00:10:12,480
overview over the cpu caches and

294
00:10:10,959 --> 00:10:14,079
basically what we're trying to do with

295
00:10:12,480 --> 00:10:15,040
duckdb is keep the data that has been

296
00:10:14,079 --> 00:10:18,399
worked on

297
00:10:15,040 --> 00:10:18,959
up here in these very fast l1 and l2

298
00:10:18,399 --> 00:10:20,480
caches

299
00:10:18,959 --> 00:10:24,800
and actually avoid going into main

300
00:10:20,480 --> 00:10:24,800
memory for performance reasons

301
00:10:25,440 --> 00:10:29,360
and this is very nice because it allows

302
00:10:26,959 --> 00:10:31,279
us to process data that is bigger than

303
00:10:29,360 --> 00:10:33,200
main memory this is one of the

304
00:10:31,279 --> 00:10:34,720
limitations of things like pandas

305
00:10:33,200 --> 00:10:36,640
is that once your data becomes bigger

306
00:10:34,720 --> 00:10:38,880
than memory you're screwed

307
00:10:36,640 --> 00:10:40,560
with a vectorized execution engine you

308
00:10:38,880 --> 00:10:42,480
actually have a reasonable chance

309
00:10:40,560 --> 00:10:44,000
of still completing your analysis

310
00:10:42,480 --> 00:10:46,320
questions

311
00:10:44,000 --> 00:10:48,079
yeah and you don't get wonderful out of

312
00:10:46,320 --> 00:10:51,279
memory errors

313
00:10:48,079 --> 00:10:54,399
um so now i'm gonna

314
00:10:51,279 --> 00:10:56,880
actually uh skip something

315
00:10:54,399 --> 00:10:58,640
um so you would ask then you would ask

316
00:10:56,880 --> 00:11:00,240
okay so why should i do vectorization

317
00:10:58,640 --> 00:11:00,800
it's great that harness is excited about

318
00:11:00,240 --> 00:11:02,079
it

319
00:11:00,800 --> 00:11:04,000
but what's what does what kind of

320
00:11:02,079 --> 00:11:05,760
different does it makes and does it make

321
00:11:04,000 --> 00:11:08,399
and this is a

322
00:11:05,760 --> 00:11:11,120
uh like a very very crude benchmark we

323
00:11:08,399 --> 00:11:12,959
run like a standard benchmark tpch

324
00:11:11,120 --> 00:11:14,800
on different systems and this is based

325
00:11:12,959 --> 00:11:15,920
on an old version we have gotten faster

326
00:11:14,800 --> 00:11:17,760
in the meantime

327
00:11:15,920 --> 00:11:19,279
but basically if you look on the on the

328
00:11:17,760 --> 00:11:20,800
bottom there you can see the

329
00:11:19,279 --> 00:11:22,399
the time it takes to complete these

330
00:11:20,800 --> 00:11:23,439
benchmark queries between the different

331
00:11:22,399 --> 00:11:25,360
systems

332
00:11:23,440 --> 00:11:26,560
and then there is duckdb up here which

333
00:11:25,360 --> 00:11:30,160
clearly is

334
00:11:26,560 --> 00:11:32,959
much faster so generally you would say

335
00:11:30,160 --> 00:11:34,640
that this is 40 times faster than a

336
00:11:32,959 --> 00:11:36,719
traditional engine that is working in a

337
00:11:34,640 --> 00:11:38,160
top-level time fashion

338
00:11:36,720 --> 00:11:39,920
but then you would say but yeah honest

339
00:11:38,160 --> 00:11:41,839
you're an academic and

340
00:11:39,920 --> 00:11:43,439
you have a nice pet project but you know

341
00:11:41,839 --> 00:11:44,240
i i'm interested in something that i can

342
00:11:43,440 --> 00:11:47,279
use

343
00:11:44,240 --> 00:11:49,279
um maybe even a serious ideas

344
00:11:47,279 --> 00:11:51,600
um and this is why i briefly want to

345
00:11:49,279 --> 00:11:53,360
talk about our quality assurance

346
00:11:51,600 --> 00:11:55,680
and that we are um sort of doing with

347
00:11:53,360 --> 00:11:57,920
duckdb so basically we have

348
00:11:55,680 --> 00:11:59,760
continuous integration running where we

349
00:11:57,920 --> 00:12:01,040
have millions of sql queries run on

350
00:11:59,760 --> 00:12:02,720
every single release

351
00:12:01,040 --> 00:12:05,040
we know the correct result for every one

352
00:12:02,720 --> 00:12:07,279
of these queries so whenever we get

353
00:12:05,040 --> 00:12:09,360
something wrong with instantly flagged

354
00:12:07,279 --> 00:12:11,120
we have verified benchmark results for

355
00:12:09,360 --> 00:12:13,760
large standard benchmarks that

356
00:12:11,120 --> 00:12:16,320
we also check for and basically we went

357
00:12:13,760 --> 00:12:18,399
around and steal everyone's test cases

358
00:12:16,320 --> 00:12:19,760
so with sql engines you can do this

359
00:12:18,399 --> 00:12:21,360
because they all have the same sort of

360
00:12:19,760 --> 00:12:22,560
query language

361
00:12:21,360 --> 00:12:24,880
so the only thing you have to do is you

362
00:12:22,560 --> 00:12:26,959
have to write a parser for whatever the

363
00:12:24,880 --> 00:12:29,279
result format they have my favorite part

364
00:12:26,959 --> 00:12:31,119
was to write a scraper for the um

365
00:12:29,279 --> 00:12:33,200
sql server website because they have

366
00:12:31,120 --> 00:12:34,639
example queries with answers

367
00:12:33,200 --> 00:12:36,959
and from that we generated a bunch of

368
00:12:34,639 --> 00:12:38,639
test cases as well we also do query

369
00:12:36,959 --> 00:12:40,399
fuzzing where we ought to generate

370
00:12:38,639 --> 00:12:43,120
queries and to try to break um

371
00:12:40,399 --> 00:12:44,800
our system uh which always works if you

372
00:12:43,120 --> 00:12:47,120
run the fuzzer long enough but you find

373
00:12:44,800 --> 00:12:48,719
very important bugs in the meantime

374
00:12:47,120 --> 00:12:50,320
and we also have something that we call

375
00:12:48,720 --> 00:12:51,279
continuous benchmarking where every

376
00:12:50,320 --> 00:12:53,200
release

377
00:12:51,279 --> 00:12:55,279
is subjected to benchmarking and we can

378
00:12:53,200 --> 00:12:58,399
flag performance regressions

379
00:12:55,279 --> 00:13:00,800
quickly so

380
00:12:58,399 --> 00:13:02,720
db is free and open source under the mit

381
00:13:00,800 --> 00:13:04,800
license

382
00:13:02,720 --> 00:13:06,480
we are currently in pre-release so which

383
00:13:04,800 --> 00:13:08,479
means that you can't yell at us if we

384
00:13:06,480 --> 00:13:10,480
change apis internally

385
00:13:08,480 --> 00:13:11,920
but um it is fully functional you can

386
00:13:10,480 --> 00:13:14,320
use this to run

387
00:13:11,920 --> 00:13:15,360
uh queries to store data it's uh it is

388
00:13:14,320 --> 00:13:18,240
all there

389
00:13:15,360 --> 00:13:20,000
we have a website uh there's a github

390
00:13:18,240 --> 00:13:22,959
page where you know you can

391
00:13:20,000 --> 00:13:25,360
go file a full request if you want um we

392
00:13:22,959 --> 00:13:27,199
are very interested in hearing feedback

393
00:13:25,360 --> 00:13:28,880
and if duckdb doesn't do you know

394
00:13:27,200 --> 00:13:31,040
something that you wanted to do

395
00:13:28,880 --> 00:13:32,959
um then please tell us if you're even

396
00:13:31,040 --> 00:13:33,439
more database inclined then you can send

397
00:13:32,959 --> 00:13:36,000
us a

398
00:13:33,440 --> 00:13:37,519
pull request with new features bug fixes

399
00:13:36,000 --> 00:13:39,360
whatever we have a

400
00:13:37,519 --> 00:13:41,040
long list of issues in the issue tracker

401
00:13:39,360 --> 00:13:42,720
that have tagged with help wanted or

402
00:13:41,040 --> 00:13:44,719
good first issue so these are good

403
00:13:42,720 --> 00:13:46,320
places to start

404
00:13:44,720 --> 00:13:49,839
and with that i'm happy to take

405
00:13:46,320 --> 00:13:49,839
questions thank you

406
00:13:55,839 --> 00:13:59,839
can i ask two questions we have to ask

407
00:13:58,160 --> 00:14:01,760
him

408
00:13:59,839 --> 00:14:03,680
do you do something for internal data

409
00:14:01,760 --> 00:14:06,800
compression

410
00:14:03,680 --> 00:14:08,000
as you say you store it's used for a big

411
00:14:06,800 --> 00:14:09,839
amount of data

412
00:14:08,000 --> 00:14:11,440
yeah okay so the question is do we do

413
00:14:09,839 --> 00:14:14,000
something for internal compression

414
00:14:11,440 --> 00:14:15,519
um what we what we are working on is

415
00:14:14,000 --> 00:14:18,800
that the

416
00:14:15,519 --> 00:14:19,519
two things one is the um the storage on

417
00:14:18,800 --> 00:14:21,120
disk

418
00:14:19,519 --> 00:14:22,480
is going to be compressed so whatever we

419
00:14:21,120 --> 00:14:23,680
write to this to the single file format

420
00:14:22,480 --> 00:14:25,600
is going to be compressed

421
00:14:23,680 --> 00:14:27,199
but we also and we this is really

422
00:14:25,600 --> 00:14:28,880
something we're working on right now

423
00:14:27,199 --> 00:14:30,560
is working with compressed intermediates

424
00:14:28,880 --> 00:14:32,880
so that vectors for example if the

425
00:14:30,560 --> 00:14:34,399
if you have a vector 1000 values and

426
00:14:32,880 --> 00:14:36,480
they're all the same

427
00:14:34,399 --> 00:14:37,760
then we have compression that will

428
00:14:36,480 --> 00:14:40,800
actually not

429
00:14:37,760 --> 00:14:43,600
move these thousand values around but um

430
00:14:40,800 --> 00:14:45,439
you know the fact that it's the same and

431
00:14:43,600 --> 00:14:48,880
the second question is

432
00:14:45,440 --> 00:14:49,680
do you support any statistical functions

433
00:14:48,880 --> 00:14:52,000
like

434
00:14:49,680 --> 00:14:53,680
computing percentiles and getting

435
00:14:52,000 --> 00:14:55,279
histograms back from

436
00:14:53,680 --> 00:14:57,199
the database engine that's a good

437
00:14:55,279 --> 00:14:58,000
question um so our philosophy there is

438
00:14:57,199 --> 00:15:00,800
that because the data

439
00:14:58,000 --> 00:15:01,519
transfer between db and the host is so

440
00:15:00,800 --> 00:15:03,120
fast

441
00:15:01,519 --> 00:15:04,320
that if you want things that we don't

442
00:15:03,120 --> 00:15:05,120
support it's actually you're not going

443
00:15:04,320 --> 00:15:07,519
to die

444
00:15:05,120 --> 00:15:08,880
pulling a chunk of data into pandas for

445
00:15:07,519 --> 00:15:10,639
example and running it there

446
00:15:08,880 --> 00:15:12,639
um there is support for user defined

447
00:15:10,639 --> 00:15:14,880
functions if you want to add anything

448
00:15:12,639 --> 00:15:16,399
we have a fairly complete aggregation

449
00:15:14,880 --> 00:15:18,800
functions library so

450
00:15:16,399 --> 00:15:20,959
there is multiple options there but but

451
00:15:18,800 --> 00:15:23,120
the general idea is that we don't

452
00:15:20,959 --> 00:15:24,000
um we don't punish you for pulling a

453
00:15:23,120 --> 00:15:25,920
large chunk

454
00:15:24,000 --> 00:15:28,240
out of the system we don't hold the data

455
00:15:25,920 --> 00:15:30,160
hostage

456
00:15:28,240 --> 00:15:31,360
hi i have a question uh thanks for the

457
00:15:30,160 --> 00:15:33,759
talk um

458
00:15:31,360 --> 00:15:35,040
do we have a connector for the sql

459
00:15:33,759 --> 00:15:37,680
alchemy for example

460
00:15:35,040 --> 00:15:40,319
in pandas uh you have a connector for

461
00:15:37,680 --> 00:15:40,719
sqlite so you can write a sql query and

462
00:15:40,320 --> 00:15:43,040
then

463
00:15:40,720 --> 00:15:44,639
yeah um that has been i'm not sure what

464
00:15:43,040 --> 00:15:45,360
the status and that is but people have

465
00:15:44,639 --> 00:15:47,920
worked on this

466
00:15:45,360 --> 00:15:49,040
um i think eventually if it's not

467
00:15:47,920 --> 00:15:50,560
working already it should

468
00:15:49,040 --> 00:15:52,160
be working pretty straightforward

469
00:15:50,560 --> 00:15:54,880
because we support the exact same query

470
00:15:52,160 --> 00:15:57,279
language as posgress so i

471
00:15:54,880 --> 00:15:58,880
suspect it should already work and it's

472
00:15:57,279 --> 00:16:01,759
just a question of plumbing

473
00:15:58,880 --> 00:16:01,759
um the connection

474
00:16:03,600 --> 00:16:06,800
okay thank you very much i'm outside of

475
00:16:05,360 --> 00:16:07,279
if you want to talk to me i'm outside

476
00:16:06,800 --> 00:16:20,399
yeah

477
00:16:07,279 --> 00:16:20,399
okay perfect thank you for your talk

