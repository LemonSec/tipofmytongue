1
00:00:05,920 --> 00:00:10,240
so

2
00:00:07,200 --> 00:00:13,360
hello everyone i am bobo and

3
00:00:10,240 --> 00:00:16,000
this is ivan shah and today we're gonna

4
00:00:13,360 --> 00:00:18,240
talk about skydive which is an analyzer

5
00:00:16,000 --> 00:00:22,480
an analyzer for network topology

6
00:00:18,240 --> 00:00:25,359
and traffic and so we created skydive

7
00:00:22,480 --> 00:00:26,960
three years ago and at the time we were

8
00:00:25,359 --> 00:00:30,480
dealing with

9
00:00:26,960 --> 00:00:31,760
sdns many kinds of sdns and those are

10
00:00:30,480 --> 00:00:33,680
complicated beasts

11
00:00:31,760 --> 00:00:35,360
they implement the network in very

12
00:00:33,680 --> 00:00:38,559
different ways

13
00:00:35,360 --> 00:00:38,960
and when you have to develop or just use

14
00:00:38,559 --> 00:00:41,440
them

15
00:00:38,960 --> 00:00:43,040
it's a it's pretty hard to understand

16
00:00:41,440 --> 00:00:46,718
what what they really do

17
00:00:43,040 --> 00:00:48,879
so we had a need to

18
00:00:46,719 --> 00:00:51,039
the first need we had was to be able to

19
00:00:48,879 --> 00:00:54,239
just to be able to see

20
00:00:51,039 --> 00:00:54,879
uh what's uh what was the the sdn was

21
00:00:54,239 --> 00:00:56,959
doing so

22
00:00:54,879 --> 00:00:58,239
in terms of topology exploration and

23
00:00:56,960 --> 00:01:02,960
just to be able to

24
00:00:58,239 --> 00:01:02,959
visualize uh what it was doing

25
00:01:03,920 --> 00:01:10,320
and this we also

26
00:01:08,159 --> 00:01:12,320
one of the primary use cases was to be

27
00:01:10,320 --> 00:01:16,000
able to troubleshoot it uh

28
00:01:12,320 --> 00:01:20,399
even in on production machines

29
00:01:16,000 --> 00:01:23,119
so um we had to to to have a way to

30
00:01:20,400 --> 00:01:25,360
to capture network traffic and to

31
00:01:23,119 --> 00:01:28,640
analyze it to see what's going on why

32
00:01:25,360 --> 00:01:29,759
why packets were dropped are many

33
00:01:28,640 --> 00:01:32,960
different issues

34
00:01:29,759 --> 00:01:34,960
um as i said we were dealing with

35
00:01:32,960 --> 00:01:37,280
different sdn so we we didn't want to

36
00:01:34,960 --> 00:01:40,639
have a solution that that is tied to one

37
00:01:37,280 --> 00:01:41,920
particular sdn so we want it to be

38
00:01:40,640 --> 00:01:45,920
agnostic whether it's

39
00:01:41,920 --> 00:01:48,960
openstack or kubernetes or you name it

40
00:01:45,920 --> 00:01:50,880
um we have to be able to do this in real

41
00:01:48,960 --> 00:01:54,158
time so as i said maybe sometimes in

42
00:01:50,880 --> 00:01:57,199
production machines but um

43
00:01:54,159 --> 00:01:59,920
so but also um after

44
00:01:57,200 --> 00:02:02,079
the problem happened so we have we we

45
00:01:59,920 --> 00:02:05,840
wanted to have a solution that

46
00:02:02,079 --> 00:02:08,799
that would allow us to to analyze

47
00:02:05,840 --> 00:02:10,399
an issue in the past so sometimes you

48
00:02:08,800 --> 00:02:10,800
have an issue with the vm and then it's

49
00:02:10,399 --> 00:02:12,800
this

50
00:02:10,800 --> 00:02:13,920
you destroy it and then you have no way

51
00:02:12,800 --> 00:02:16,959
to to see what

52
00:02:13,920 --> 00:02:19,119
what was wrong at the time uh

53
00:02:16,959 --> 00:02:21,040
we wanted a lightweight solution but

54
00:02:19,120 --> 00:02:23,200
like everyone

55
00:02:21,040 --> 00:02:24,560
and we wanted to to have something easy

56
00:02:23,200 --> 00:02:26,958
to deploy

57
00:02:24,560 --> 00:02:28,400
uh because uh on production machines you

58
00:02:26,959 --> 00:02:30,800
don't have to you don't want to to

59
00:02:28,400 --> 00:02:34,080
install a lot of stuff

60
00:02:30,800 --> 00:02:36,879
um and yeah

61
00:02:34,080 --> 00:02:39,120
um that's something we wanted to even

62
00:02:36,879 --> 00:02:41,679
base i don't know what

63
00:02:39,120 --> 00:02:43,040
okay so so we came up with uh with uh

64
00:02:41,680 --> 00:02:46,480
this architecture

65
00:02:43,040 --> 00:02:48,879
so at the bottom you have the agents

66
00:02:46,480 --> 00:02:50,720
which are skydive agents so they are

67
00:02:48,879 --> 00:02:52,720
they need to run

68
00:02:50,720 --> 00:02:54,640
as close as possible to the physical

69
00:02:52,720 --> 00:02:57,680
machine so typically they would run

70
00:02:54,640 --> 00:02:58,159
on your uh compute nodes of your of your

71
00:02:57,680 --> 00:03:02,159
cloud

72
00:02:58,159 --> 00:03:05,679
or the cube of your kubernetes nodes

73
00:03:02,159 --> 00:03:08,959
and so so those agents

74
00:03:05,680 --> 00:03:11,599
collect the topology um locally and then

75
00:03:08,959 --> 00:03:14,080
they forward uh everything to another

76
00:03:11,599 --> 00:03:17,280
kind of component which is the analyzer

77
00:03:14,080 --> 00:03:18,720
which can be located every um out of the

78
00:03:17,280 --> 00:03:22,319
infrastructure

79
00:03:18,720 --> 00:03:24,560
and um and those analyzers

80
00:03:22,319 --> 00:03:25,839
are replica replicated together so we

81
00:03:24,560 --> 00:03:29,120
have uh

82
00:03:25,840 --> 00:03:31,200
high ability uh we also support

83
00:03:29,120 --> 00:03:32,720
load balancing because because the

84
00:03:31,200 --> 00:03:35,440
agents are connected to multiple

85
00:03:32,720 --> 00:03:35,440
analyzers

86
00:03:35,840 --> 00:03:41,120
um and so

87
00:03:38,879 --> 00:03:42,798
you can see here that the the the data

88
00:03:41,120 --> 00:03:46,799
model that we used uh

89
00:03:42,799 --> 00:03:50,319
to to store this topology is a graph

90
00:03:46,799 --> 00:03:52,640
and so um this this graph is

91
00:03:50,319 --> 00:03:53,839
event based so we try to to not use

92
00:03:52,640 --> 00:03:55,920
polling so we

93
00:03:53,840 --> 00:03:57,200
when we get information from the

94
00:03:55,920 --> 00:04:00,480
different subsystems

95
00:03:57,200 --> 00:04:03,280
we try to use uh just subscribe and to

96
00:04:00,480 --> 00:04:06,000
get evidence from them

97
00:04:03,280 --> 00:04:07,040
it's a it's it's a pop sub mechanism so

98
00:04:06,000 --> 00:04:09,280
you can

99
00:04:07,040 --> 00:04:11,200
you can have uh you can write your own

100
00:04:09,280 --> 00:04:13,599
clients and just publish to the

101
00:04:11,200 --> 00:04:14,720
to this graph or you can even subscribe

102
00:04:13,599 --> 00:04:17,839
to this so you get

103
00:04:14,720 --> 00:04:20,639
uh you get the events uh on on

104
00:04:17,839 --> 00:04:21,839
on this graph so what happened you can

105
00:04:20,639 --> 00:04:24,400
have those events through

106
00:04:21,839 --> 00:04:25,599
web sockets so the web ui that we have

107
00:04:24,400 --> 00:04:28,239
uh is using this

108
00:04:25,600 --> 00:04:29,680
this mechanism and then you get all the

109
00:04:28,240 --> 00:04:32,639
events so the the nod

110
00:04:29,680 --> 00:04:34,160
the note creation the updates the delete

111
00:04:32,639 --> 00:04:37,280
and everything

112
00:04:34,160 --> 00:04:38,320
and um and for every modification on

113
00:04:37,280 --> 00:04:41,520
this graph

114
00:04:38,320 --> 00:04:43,280
we we keep the we keep the revisions of

115
00:04:41,520 --> 00:04:46,320
every rough modification so

116
00:04:43,280 --> 00:04:50,479
we are able to rebuild the graph

117
00:04:46,320 --> 00:04:52,800
as it was at a certain point in time

118
00:04:50,479 --> 00:04:54,240
and so where do we get all these

119
00:04:52,800 --> 00:04:57,440
topology informations

120
00:04:54,240 --> 00:05:00,960
well from everywhere we can we

121
00:04:57,440 --> 00:05:02,000
use netlink for like to get information

122
00:05:00,960 --> 00:05:03,758
from the

123
00:05:02,000 --> 00:05:06,639
network interfaces to get the metrics

124
00:05:03,759 --> 00:05:09,840
the routing tables the fdb

125
00:05:06,639 --> 00:05:10,800
uh we also have i won't go through all

126
00:05:09,840 --> 00:05:12,960
of those but

127
00:05:10,800 --> 00:05:15,440
the main one the open v switch and many

128
00:05:12,960 --> 00:05:18,320
sdns are using your pv switch so

129
00:05:15,440 --> 00:05:19,360
you have out of the box if you have

130
00:05:18,320 --> 00:05:23,039
support for

131
00:05:19,360 --> 00:05:27,600
many sdns we get also information from

132
00:05:23,039 --> 00:05:27,599
from physical machines through lldp

133
00:05:27,919 --> 00:05:34,560
we have probes for libert to get the

134
00:05:31,440 --> 00:05:36,479
information from from the for our vms we

135
00:05:34,560 --> 00:05:38,800
have a kubernetes probe we get

136
00:05:36,479 --> 00:05:40,400
we also have docker integration so you

137
00:05:38,800 --> 00:05:44,000
can see all the

138
00:05:40,400 --> 00:05:46,000
all the other uh docker containers uh

139
00:05:44,000 --> 00:05:47,680
we also have electro completely

140
00:05:46,000 --> 00:05:50,800
unrelated uh network

141
00:05:47,680 --> 00:05:53,120
uh probes which one is the block device

142
00:05:50,800 --> 00:05:55,199
so you can you can

143
00:05:53,120 --> 00:05:58,639
you can get information about the the

144
00:05:55,199 --> 00:06:02,560
disk on your on your systems and stuff

145
00:05:58,639 --> 00:06:04,479
and um yeah and that's pretty much all

146
00:06:02,560 --> 00:06:06,479
all we have for the topology we had a

147
00:06:04,479 --> 00:06:08,560
demo but for some reason

148
00:06:06,479 --> 00:06:10,080
we are not able to demonstrate uh to

149
00:06:08,560 --> 00:06:13,440
demonstrate it

150
00:06:10,080 --> 00:06:16,240
so so that was the topology part and

151
00:06:13,440 --> 00:06:17,199
now we is going to talk about the

152
00:06:16,240 --> 00:06:20,479
network

153
00:06:17,199 --> 00:06:24,160
flow parts okay

154
00:06:20,479 --> 00:06:26,639
yeah perfect uh so now we have

155
00:06:24,160 --> 00:06:28,000
we have a way to build the the to have a

156
00:06:26,639 --> 00:06:28,720
view of the topology of the network

157
00:06:28,000 --> 00:06:31,759
topology

158
00:06:28,720 --> 00:06:34,560
so every interfaces and bridge

159
00:06:31,759 --> 00:06:37,120
and router and stuff like this are

160
00:06:34,560 --> 00:06:39,680
mapped to a topology view like a graph

161
00:06:37,120 --> 00:06:41,280
and what we wanted to bring is to to

162
00:06:39,680 --> 00:06:42,160
bring the ability to start packet

163
00:06:41,280 --> 00:06:44,479
capture for

164
00:06:42,160 --> 00:06:45,680
troubleshooting monitoring or stuff like

165
00:06:44,479 --> 00:06:47,840
that

166
00:06:45,680 --> 00:06:49,440
so we implemented on top of the topology

167
00:06:47,840 --> 00:06:53,039
view a way to

168
00:06:49,440 --> 00:06:55,680
to do distributed packet capture

169
00:06:53,039 --> 00:06:57,599
so you with a with a simple api call you

170
00:06:55,680 --> 00:06:59,199
can express that you want to capture

171
00:06:57,599 --> 00:07:01,280
to start packet capture on different

172
00:06:59,199 --> 00:07:04,400
interfaces

173
00:07:01,280 --> 00:07:07,758
in the topology we do support multiple

174
00:07:04,400 --> 00:07:09,520
methods for that and depending on the

175
00:07:07,759 --> 00:07:12,960
use cases you want to address

176
00:07:09,520 --> 00:07:16,159
some of them brings a lot of metrics and

177
00:07:12,960 --> 00:07:18,479
like and capabilities like tcp fragment

178
00:07:16,160 --> 00:07:22,639
defragmentation and stuff like this

179
00:07:18,479 --> 00:07:26,159
some of them are more efficient for uh

180
00:07:22,639 --> 00:07:26,160
yeah sorry more efficient for

181
00:07:27,280 --> 00:07:33,440
ev number of packets

182
00:07:31,360 --> 00:07:34,880
we can write when we start a capture you

183
00:07:33,440 --> 00:07:36,400
can expect that you want only few

184
00:07:34,880 --> 00:07:40,400
packets like

185
00:07:36,400 --> 00:07:43,679
playing with ebpa filtering mechanism

186
00:07:40,400 --> 00:07:45,198
and we do support l2 and l3 flow

187
00:07:43,680 --> 00:07:47,039
tracking

188
00:07:45,199 --> 00:07:48,879
tunnels are supported too meaning that

189
00:07:47,039 --> 00:07:53,120
then we do support gre

190
00:07:48,879 --> 00:07:54,960
vxlan and pls gv and maybe some others

191
00:07:53,120 --> 00:07:56,879
the goal of this is when you have an

192
00:07:54,960 --> 00:07:58,080
overlay and you want to track the

193
00:07:56,879 --> 00:08:01,599
traffic of the container

194
00:07:58,080 --> 00:08:04,400
or vm and even within a channel

195
00:08:01,599 --> 00:08:04,800
and you can do this with skydive what we

196
00:08:04,400 --> 00:08:07,520
do

197
00:08:04,800 --> 00:08:07,840
in fact we generate when we when we see

198
00:08:07,520 --> 00:08:11,440
that

199
00:08:07,840 --> 00:08:13,599
a packet is going to be embedded in a

200
00:08:11,440 --> 00:08:15,120
in a channel we split the packet in two

201
00:08:13,599 --> 00:08:17,840
parts and and we generate

202
00:08:15,120 --> 00:08:18,319
two flows within the within the system

203
00:08:17,840 --> 00:08:20,638
uh

204
00:08:18,319 --> 00:08:21,840
we don't keep the packet uh themselves

205
00:08:20,639 --> 00:08:23,199
in fact

206
00:08:21,840 --> 00:08:24,799
that's possible but that's not the main

207
00:08:23,199 --> 00:08:26,720
goal of skydive what we do we take the

208
00:08:24,800 --> 00:08:29,840
packet and we generate

209
00:08:26,720 --> 00:08:32,880
a flow table i can show you maybe

210
00:08:29,840 --> 00:08:35,039
the yeah here

211
00:08:32,880 --> 00:08:37,039
so here you have the probe at the bottom

212
00:08:35,039 --> 00:08:40,880
but that's that's topology bot

213
00:08:37,039 --> 00:08:42,799
probe or flow probe and what we do we

214
00:08:40,880 --> 00:08:44,959
we generate a flow table within the

215
00:08:42,799 --> 00:08:46,000
agent and then time to time the packet

216
00:08:44,959 --> 00:08:48,560
are forwarded to

217
00:08:46,000 --> 00:08:54,000
the the flows generated are forwarded to

218
00:08:48,560 --> 00:08:57,680
the analyzer and then to the data store

219
00:08:54,000 --> 00:09:00,240
that's basically uh how we do this

220
00:08:57,680 --> 00:09:01,760
so finally uh the the size of the of the

221
00:09:00,240 --> 00:09:04,480
data within the agent

222
00:09:01,760 --> 00:09:05,200
is pretty low regarding the uh the

223
00:09:04,480 --> 00:09:09,839
original

224
00:09:05,200 --> 00:09:09,839
um traffic size

225
00:09:11,600 --> 00:09:16,399
so so now you we have a way to to

226
00:09:14,000 --> 00:09:18,080
generate packets

227
00:09:16,399 --> 00:09:19,519
to generate full and and we want to

228
00:09:18,080 --> 00:09:20,959
export them so you

229
00:09:19,519 --> 00:09:22,959
with skylab you have multiple way to

230
00:09:20,959 --> 00:09:24,880
consume the packet the falls generated

231
00:09:22,959 --> 00:09:27,439
or the packet generated

232
00:09:24,880 --> 00:09:28,080
one of them is to to start a capture so

233
00:09:27,440 --> 00:09:30,000
you'll write

234
00:09:28,080 --> 00:09:31,760
your expression matching multiple

235
00:09:30,000 --> 00:09:34,160
interface for example and then you

236
00:09:31,760 --> 00:09:36,240
you said i i want to i want to add the

237
00:09:34,160 --> 00:09:38,480
packet

238
00:09:36,240 --> 00:09:40,160
going outside of skydive or the skydive

239
00:09:38,480 --> 00:09:43,279
scope so so we do support

240
00:09:40,160 --> 00:09:45,519
as flow net flow and airspan

241
00:09:43,279 --> 00:09:47,439
and you can do this for all the

242
00:09:45,519 --> 00:09:48,839
interfaces that you you see on the

243
00:09:47,440 --> 00:09:51,440
topology so meaning if you want to

244
00:09:48,839 --> 00:09:53,680
export the flow that you capture on

245
00:09:51,440 --> 00:09:55,920
an interface within a container that's

246
00:09:53,680 --> 00:09:57,359
possible

247
00:09:55,920 --> 00:10:00,000
all the flows and the metrics are stored

248
00:09:57,360 --> 00:10:03,440
in the time series database

249
00:10:00,000 --> 00:10:04,079
so if you want to to do calculation on

250
00:10:03,440 --> 00:10:07,519
that

251
00:10:04,079 --> 00:10:10,479
you can uh we we do have a

252
00:10:07,519 --> 00:10:11,279
uh either way to subscribe to to the to

253
00:10:10,480 --> 00:10:13,440
the flow bus

254
00:10:11,279 --> 00:10:15,279
so meaning when the agent forward the

255
00:10:13,440 --> 00:10:17,279
flows to the analyzer you can

256
00:10:15,279 --> 00:10:19,519
you can write a subscriber to the

257
00:10:17,279 --> 00:10:21,120
analyzer and then you will get the flows

258
00:10:19,519 --> 00:10:24,160
and that's useful if you want to to

259
00:10:21,120 --> 00:10:26,640
write your own flow

260
00:10:24,160 --> 00:10:28,719
process we do have an example where the

261
00:10:26,640 --> 00:10:30,880
flow are captured and then converted to

262
00:10:28,720 --> 00:10:34,399
a vpc logic format

263
00:10:30,880 --> 00:10:36,000
um and and when you when you want to

264
00:10:34,399 --> 00:10:39,040
recreate the the flows you

265
00:10:36,000 --> 00:10:40,800
you use the the exact same uh

266
00:10:39,040 --> 00:10:42,959
long way that you use for the topology

267
00:10:40,800 --> 00:10:46,800
or here that's just to retrieve

268
00:10:42,959 --> 00:10:51,518
uh the the traffic for the http

269
00:10:46,800 --> 00:10:51,519
https traffic for a docker container

270
00:10:54,000 --> 00:10:58,560
and now now we have a way to inject

271
00:10:56,240 --> 00:11:00,640
packet we may want to

272
00:10:58,560 --> 00:11:02,319
generate packet in order to do to

273
00:11:00,640 --> 00:11:04,079
generate specific trust or

274
00:11:02,320 --> 00:11:06,480
specific troubleshooting but also in

275
00:11:04,079 --> 00:11:09,439
order to get specific metrics

276
00:11:06,480 --> 00:11:11,680
so we do support icmp tcp udp there is

277
00:11:09,440 --> 00:11:14,880
also a way to inject

278
00:11:11,680 --> 00:11:17,839
already generated pcap truss

279
00:11:14,880 --> 00:11:19,200
for example that so you can write long

280
00:11:17,839 --> 00:11:23,040
running packet injection

281
00:11:19,200 --> 00:11:26,480
so you can say i want to have 10

282
00:11:23,040 --> 00:11:27,680
10 packets or 100 packets and you can

283
00:11:26,480 --> 00:11:29,680
define the rate

284
00:11:27,680 --> 00:11:31,359
for example that's useful if you want to

285
00:11:29,680 --> 00:11:34,319
generate a ping mesh for example so

286
00:11:31,360 --> 00:11:35,839
so here that's an expression an api call

287
00:11:34,320 --> 00:11:38,880
that you can do and it will

288
00:11:35,839 --> 00:11:41,760
generate a ping between all the v8

289
00:11:38,880 --> 00:11:42,959
and and and then you will get the the

290
00:11:41,760 --> 00:11:45,360
rtt reported

291
00:11:42,959 --> 00:11:47,839
and you can grab them uh you can grab

292
00:11:45,360 --> 00:11:51,360
the information if you want

293
00:11:47,839 --> 00:11:52,240
and there is also a way to to not give a

294
00:11:51,360 --> 00:11:53,839
file but uh

295
00:11:52,240 --> 00:11:55,440
to have a socket where you can you can

296
00:11:53,839 --> 00:11:58,480
inject uh

297
00:11:55,440 --> 00:12:00,560
pickup traffic and then it will be

298
00:11:58,480 --> 00:12:03,200
injected within the the skydive

299
00:12:00,560 --> 00:12:03,199
infrastructure

300
00:12:05,040 --> 00:12:08,430
so it was it was a an overview of the

301
00:12:07,680 --> 00:12:09,680
topology

302
00:12:08,430 --> 00:12:12,399
[Music]

303
00:12:09,680 --> 00:12:13,839
information retrieved and the flows and

304
00:12:12,399 --> 00:12:16,320
and on top of that we do have

305
00:12:13,839 --> 00:12:18,000
more so there is a way to do alerting so

306
00:12:16,320 --> 00:12:21,680
you write an expression matching

307
00:12:18,000 --> 00:12:23,519
a flows or a topology in information

308
00:12:21,680 --> 00:12:26,319
and then you can trigger something like

309
00:12:23,519 --> 00:12:29,440
a web or call or

310
00:12:26,320 --> 00:12:30,320
an execution of a script something like

311
00:12:29,440 --> 00:12:32,480
this

312
00:12:30,320 --> 00:12:34,079
you do have a way to to write your

313
00:12:32,480 --> 00:12:36,240
workflow like

314
00:12:34,079 --> 00:12:38,239
okay i want to start a capture then i

315
00:12:36,240 --> 00:12:39,680
want to check some metrics finally i

316
00:12:38,240 --> 00:12:42,959
want to stop the captures

317
00:12:39,680 --> 00:12:44,719
i want to trigger something uh with this

318
00:12:42,959 --> 00:12:47,599
if you want to play with it we do have a

319
00:12:44,720 --> 00:12:50,000
golang python client

320
00:12:47,600 --> 00:12:50,959
we do have a non-simple module so if you

321
00:12:50,000 --> 00:12:53,760
want to

322
00:12:50,959 --> 00:12:55,279
deploy your infrastructure and do

323
00:12:53,760 --> 00:12:56,959
something on top of that

324
00:12:55,279 --> 00:12:59,760
injecting some information within skype

325
00:12:56,959 --> 00:13:02,239
you can use the ansible module

326
00:12:59,760 --> 00:13:04,000
there is a way to to to add plugins so

327
00:13:02,240 --> 00:13:05,920
we have a collect d plugin so you can

328
00:13:04,000 --> 00:13:07,279
get all the matrix reported by goledy

329
00:13:05,920 --> 00:13:10,560
and inject them

330
00:13:07,279 --> 00:13:12,000
to skydive as a metadata and in order to

331
00:13:10,560 --> 00:13:14,959
consume the matrix

332
00:13:12,000 --> 00:13:16,800
we do have a graph and a data source so

333
00:13:14,959 --> 00:13:18,319
basically you use the exact same query

334
00:13:16,800 --> 00:13:23,040
language and you will have

335
00:13:18,320 --> 00:13:26,320
for example the rtt reported

336
00:13:23,040 --> 00:13:29,279
or more thank you you do have more

337
00:13:26,320 --> 00:13:31,120
i invite you to to to look at the the

338
00:13:29,279 --> 00:13:31,360
website especially the last line which

339
00:13:31,120 --> 00:13:33,570
is

340
00:13:31,360 --> 00:13:35,360
the new version of the web ui

341
00:13:33,570 --> 00:13:37,519
[Music]

342
00:13:35,360 --> 00:13:38,130
and i think that's it thanks if you have

343
00:13:37,519 --> 00:13:45,200
questions

344
00:13:38,130 --> 00:13:45,200
[Applause]

345
00:13:47,519 --> 00:13:51,440
everything is stored in the time series

346
00:13:48,880 --> 00:13:54,560
database uh which one

347
00:13:51,440 --> 00:13:56,720
so so so yeah i didn't say that but yeah

348
00:13:54,560 --> 00:13:56,719
yeah

349
00:13:57,040 --> 00:14:00,319
yeah i'm going to repeat the question so

350
00:13:58,800 --> 00:14:02,000
the question was

351
00:14:00,320 --> 00:14:04,240
we are storing the information within

352
00:14:02,000 --> 00:14:06,800
that time series database and which one

353
00:14:04,240 --> 00:14:08,399
so that's optional it's not mandatory to

354
00:14:06,800 --> 00:14:10,000
store anything by default you can start

355
00:14:08,399 --> 00:14:11,519
cadet without any database

356
00:14:10,000 --> 00:14:13,199
and you will have real time but not the

357
00:14:11,519 --> 00:14:15,600
possible time stuff

358
00:14:13,199 --> 00:14:17,519
and for the time series it's not a real

359
00:14:15,600 --> 00:14:19,120
time series database we are storing that

360
00:14:17,519 --> 00:14:21,199
in the form of a time series and we are

361
00:14:19,120 --> 00:14:23,760
using elasticsearch and there is another

362
00:14:21,199 --> 00:14:26,000
backend which is orion db but

363
00:14:23,760 --> 00:14:27,279
i would advise to use electric source

364
00:14:26,000 --> 00:14:31,839
yeah

365
00:14:27,279 --> 00:14:31,839
another question maybe

366
00:14:32,240 --> 00:14:46,639
no okay thank you

367
00:14:44,560 --> 00:14:46,638
you

