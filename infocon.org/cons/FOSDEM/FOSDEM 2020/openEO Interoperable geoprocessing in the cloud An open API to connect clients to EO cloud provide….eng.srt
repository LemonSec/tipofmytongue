1
00:00:05,040 --> 00:00:07,839
openly always the main thing i'm working

2
00:00:06,560 --> 00:00:10,399
on stack was just

3
00:00:07,839 --> 00:00:12,000
the side project basically that i

4
00:00:10,400 --> 00:00:13,679
started working on because i needed it

5
00:00:12,000 --> 00:00:16,720
for open yo

6
00:00:13,679 --> 00:00:18,720
so in openyao is an funded project by

7
00:00:16,720 --> 00:00:20,479
the european commission at the moment

8
00:00:18,720 --> 00:00:22,880
and the idea behind it is to get an

9
00:00:20,480 --> 00:00:27,599
interoperable geoprocessing

10
00:00:22,880 --> 00:00:29,359
api for the cloud for cloud services

11
00:00:27,599 --> 00:00:32,800
so why do we do that basically at the

12
00:00:29,359 --> 00:00:34,719
moment if you want to geoprocess data

13
00:00:32,800 --> 00:00:36,559
it's often the case that you have either

14
00:00:34,719 --> 00:00:37,600
r python javascript or whatever language

15
00:00:36,559 --> 00:00:39,360
you're using

16
00:00:37,600 --> 00:00:41,040
and then you need to connect to any of

17
00:00:39,360 --> 00:00:43,519
these cloud services they have

18
00:00:41,040 --> 00:00:44,079
all their own apis and specifications

19
00:00:43,520 --> 00:00:45,760
for

20
00:00:44,079 --> 00:00:48,239
how to process data whether it's for

21
00:00:45,760 --> 00:00:52,079
example a data cube or tile based

22
00:00:48,239 --> 00:00:53,839
um whether it's could be like downloaded

23
00:00:52,079 --> 00:00:55,520
as duotif or as

24
00:00:53,840 --> 00:00:56,879
whatever they have all the different

25
00:00:55,520 --> 00:00:59,280
things for billing

26
00:00:56,879 --> 00:01:00,000
and how to store data and stuff like

27
00:00:59,280 --> 00:01:01,920
that

28
00:01:00,000 --> 00:01:03,440
so basically for each of these things

29
00:01:01,920 --> 00:01:05,920
you need a different

30
00:01:03,440 --> 00:01:07,600
a different client you need to learn how

31
00:01:05,920 --> 00:01:09,840
to process the data you need

32
00:01:07,600 --> 00:01:12,158
like basically if you start working with

33
00:01:09,840 --> 00:01:14,640
one of these services you're logged in

34
00:01:12,159 --> 00:01:16,560
because you have learned that and of

35
00:01:14,640 --> 00:01:16,880
course you want to proceed to work with

36
00:01:16,560 --> 00:01:19,360
that

37
00:01:16,880 --> 00:01:21,119
because you learned it and it's always

38
00:01:19,360 --> 00:01:25,039
like a tough time to get

39
00:01:21,119 --> 00:01:26,880
used to something different so what is

40
00:01:25,040 --> 00:01:28,640
what do you think is better is to get

41
00:01:26,880 --> 00:01:31,520
something like this you have

42
00:01:28,640 --> 00:01:33,600
one client our python javascript in our

43
00:01:31,520 --> 00:01:35,600
case what we support at the moment

44
00:01:33,600 --> 00:01:36,798
and then you have a streamlined api in

45
00:01:35,600 --> 00:01:40,559
between

46
00:01:36,799 --> 00:01:43,759
um which then translates the things to

47
00:01:40,560 --> 00:01:47,600
a single um yeah

48
00:01:43,759 --> 00:01:50,640
to a single api basically where you have

49
00:01:47,600 --> 00:01:53,759
a single uh part how you process

50
00:01:50,640 --> 00:01:58,000
like whether for us it's a data cube how

51
00:01:53,759 --> 00:02:00,719
you build things how you download things

52
00:01:58,000 --> 00:02:01,520
and so on and so on so it's basically

53
00:02:00,719 --> 00:02:03,839
like

54
00:02:01,520 --> 00:02:05,600
most of you probably know gdal that's

55
00:02:03,840 --> 00:02:06,320
the thing that translates things between

56
00:02:05,600 --> 00:02:08,878
the

57
00:02:06,320 --> 00:02:09,840
gis programs and the data formats and

58
00:02:08,878 --> 00:02:12,319
that's basically

59
00:02:09,840 --> 00:02:13,440
some kind of gdal for the cloud um i

60
00:02:12,319 --> 00:02:16,399
guess so

61
00:02:13,440 --> 00:02:17,200
um that helps you to make reproducible

62
00:02:16,400 --> 00:02:20,239
uh

63
00:02:17,200 --> 00:02:22,480
research as you can basically

64
00:02:20,239 --> 00:02:24,080
take your application that you wrote or

65
00:02:22,480 --> 00:02:26,799
your algorithm

66
00:02:24,080 --> 00:02:27,200
from one provider to the other so if you

67
00:02:26,800 --> 00:02:30,000
run

68
00:02:27,200 --> 00:02:31,599
things on google earth engine first and

69
00:02:30,000 --> 00:02:32,239
want to know whether that's really true

70
00:02:31,599 --> 00:02:34,799
what they

71
00:02:32,239 --> 00:02:37,040
computed for you then you can take the

72
00:02:34,800 --> 00:02:40,000
code that you wrote in r and just

73
00:02:37,040 --> 00:02:41,599
change the url and some other minor

74
00:02:40,000 --> 00:02:45,040
things for pre-processing

75
00:02:41,599 --> 00:02:46,799
and transform it to code that is running

76
00:02:45,040 --> 00:02:51,040
on for example veto

77
00:02:46,800 --> 00:02:53,599
on the proper vmep or any of the other

78
00:02:51,040 --> 00:02:55,359
cloud processing providers that you are

79
00:02:53,599 --> 00:02:57,280
aware of

80
00:02:55,360 --> 00:02:58,800
in that case it's portable to some

81
00:02:57,280 --> 00:03:01,120
extent and that's

82
00:02:58,800 --> 00:03:03,360
how we think it should be in the future

83
00:03:01,120 --> 00:03:04,319
that you just have a very simple access

84
00:03:03,360 --> 00:03:07,519
to data

85
00:03:04,319 --> 00:03:08,560
in the end and don't need to write

86
00:03:07,519 --> 00:03:13,040
proprietary

87
00:03:08,560 --> 00:03:14,959
workflows in for other cloud providers

88
00:03:13,040 --> 00:03:16,879
so as i said it's a language for

89
00:03:14,959 --> 00:03:20,000
geospatial processing

90
00:03:16,879 --> 00:03:21,440
we have on the one side the api which is

91
00:03:20,000 --> 00:03:24,000
basically the translation

92
00:03:21,440 --> 00:03:24,480
layer between the clients and the server

93
00:03:24,000 --> 00:03:26,640
and

94
00:03:24,480 --> 00:03:28,319
a set of predefined processes which is

95
00:03:26,640 --> 00:03:30,720
basically

96
00:03:28,319 --> 00:03:32,238
trying to make interoperable processes

97
00:03:30,720 --> 00:03:34,799
so that

98
00:03:32,239 --> 00:03:36,959
for example if you compute things on

99
00:03:34,799 --> 00:03:40,000
python in x array and in

100
00:03:36,959 --> 00:03:42,159
r with stars on another package then

101
00:03:40,000 --> 00:03:43,920
processes may slightly differ in regard

102
00:03:42,159 --> 00:03:46,959
how they compute things

103
00:03:43,920 --> 00:03:48,879
and we try to do this like define it on

104
00:03:46,959 --> 00:03:50,480
on a higher level so that you can use

105
00:03:48,879 --> 00:03:52,480
all the same processes for

106
00:03:50,480 --> 00:03:54,159
processing for all the different kinds

107
00:03:52,480 --> 00:03:56,640
of computation software that is in the

108
00:03:54,159 --> 00:03:56,640
background

109
00:03:56,799 --> 00:04:00,959
this is in contrast to stack is focused

110
00:03:59,599 --> 00:04:04,560
on processing and

111
00:04:00,959 --> 00:04:06,400
that was focused on search and discovery

112
00:04:04,560 --> 00:04:08,720
it's open source so all software we

113
00:04:06,400 --> 00:04:11,599
develop here is open source and the

114
00:04:08,720 --> 00:04:14,159
specification as well

115
00:04:11,599 --> 00:04:16,238
we are focusing on data cube so that's a

116
00:04:14,159 --> 00:04:18,079
bit

117
00:04:16,238 --> 00:04:20,238
changed maybe from the traditional gis

118
00:04:18,079 --> 00:04:22,079
workflow where you downloaded

119
00:04:20,238 --> 00:04:24,239
individual tiles and process based on

120
00:04:22,079 --> 00:04:26,080
them and here it's all basically

121
00:04:24,240 --> 00:04:28,800
wrapped into a data cube which you can

122
00:04:26,080 --> 00:04:31,919
process on um

123
00:04:28,800 --> 00:04:34,720
and we support udfs which is a very

124
00:04:31,919 --> 00:04:36,159
um interesting thing because then it

125
00:04:34,720 --> 00:04:38,400
allows you to send your

126
00:04:36,160 --> 00:04:40,240
r or python code that is not like the

127
00:04:38,400 --> 00:04:42,159
processes we have at the moment are very

128
00:04:40,240 --> 00:04:44,479
like

129
00:04:42,160 --> 00:04:46,639
narrow in the sense that for example

130
00:04:44,479 --> 00:04:50,080
that you have don't can use

131
00:04:46,639 --> 00:04:53,440
custom pro libraries for example that

132
00:04:50,080 --> 00:04:55,359
compute some very advanced algorithm

133
00:04:53,440 --> 00:04:57,280
that we don't support at the moment

134
00:04:55,360 --> 00:04:59,040
and in that sense if you need any

135
00:04:57,280 --> 00:05:02,239
specific libraries for example be

136
00:04:59,040 --> 00:05:04,479
fast for some computations then you can

137
00:05:02,240 --> 00:05:05,440
actually run it as udf where you can

138
00:05:04,479 --> 00:05:07,680
basically just

139
00:05:05,440 --> 00:05:08,880
write a script code in python or r and

140
00:05:07,680 --> 00:05:12,320
send it to the server and then it's

141
00:05:08,880 --> 00:05:12,320
executed in the cloud for you

142
00:05:12,639 --> 00:05:16,720
so what is not well it's not another

143
00:05:14,560 --> 00:05:17,039
cloud provider we just specify the api

144
00:05:16,720 --> 00:05:19,280
and

145
00:05:17,039 --> 00:05:21,199
translation layer it's not another

146
00:05:19,280 --> 00:05:22,880
geoprocessing software so we're not

147
00:05:21,199 --> 00:05:25,440
writing the new arcgis or something like

148
00:05:22,880 --> 00:05:26,240
that it's really just the translation

149
00:05:25,440 --> 00:05:29,919
and it's

150
00:05:26,240 --> 00:05:31,919
not very much as the previous

151
00:05:29,919 --> 00:05:33,520
traditional gis workflow so that you

152
00:05:31,919 --> 00:05:33,919
download the data then you have tiles

153
00:05:33,520 --> 00:05:35,919
and

154
00:05:33,919 --> 00:05:38,000
you need to process them and so on it's

155
00:05:35,919 --> 00:05:39,359
all cloud-based so your algorithm is

156
00:05:38,000 --> 00:05:41,840
going to the

157
00:05:39,360 --> 00:05:42,560
data which is stored in large amounts in

158
00:05:41,840 --> 00:05:44,479
the cloud

159
00:05:42,560 --> 00:05:46,160
and then you get the result back and not

160
00:05:44,479 --> 00:05:49,280
the other way around

161
00:05:46,160 --> 00:05:50,960
of course in this part again i can show

162
00:05:49,280 --> 00:05:53,758
this again here

163
00:05:50,960 --> 00:05:54,880
which is basically of course defining a

164
00:05:53,759 --> 00:05:57,520
new standard

165
00:05:54,880 --> 00:05:58,560
and in that sense we could run into the

166
00:05:57,520 --> 00:06:01,680
issue that there are

167
00:05:58,560 --> 00:06:04,400
afterwards 15 competing standards but i

168
00:06:01,680 --> 00:06:07,120
hope it's not

169
00:06:04,400 --> 00:06:07,840
um so the api the translation layer in

170
00:06:07,120 --> 00:06:10,400
between

171
00:06:07,840 --> 00:06:11,599
offers the following functionalities um

172
00:06:10,400 --> 00:06:14,080
of course first it

173
00:06:11,600 --> 00:06:15,440
uh needs to give you the basic

174
00:06:14,080 --> 00:06:17,919
information so it's

175
00:06:15,440 --> 00:06:19,759
uh giving access to discovery things

176
00:06:17,919 --> 00:06:21,840
like for example how the api works what

177
00:06:19,759 --> 00:06:24,720
it supports

178
00:06:21,840 --> 00:06:26,560
the eo data that you can use in this

179
00:06:24,720 --> 00:06:28,880
workflows

180
00:06:26,560 --> 00:06:30,560
that is exposed via stack stack

181
00:06:28,880 --> 00:06:33,039
collections

182
00:06:30,560 --> 00:06:35,120
and stack api and then the processors

183
00:06:33,039 --> 00:06:37,680
which is basically a

184
00:06:35,120 --> 00:06:40,240
yeah just a list of processes that is

185
00:06:37,680 --> 00:06:41,520
supported by the back end

186
00:06:40,240 --> 00:06:44,639
then it supports of course

187
00:06:41,520 --> 00:06:46,719
authentication with open id connect

188
00:06:44,639 --> 00:06:48,319
then you have workflow management for

189
00:06:46,720 --> 00:06:51,840
where you can basically store

190
00:06:48,319 --> 00:06:54,319
your uh own user defined processes so if

191
00:06:51,840 --> 00:06:56,960
you for example

192
00:06:54,319 --> 00:06:57,840
want to make a new algorithm based on

193
00:06:56,960 --> 00:06:59,280
the

194
00:06:57,840 --> 00:07:00,960
predefined processes we have you can

195
00:06:59,280 --> 00:07:01,520
store them as user defined processes

196
00:07:00,960 --> 00:07:04,239
again

197
00:07:01,520 --> 00:07:05,359
and use them as were as as they were

198
00:07:04,240 --> 00:07:07,520
predefined before as

199
00:07:05,360 --> 00:07:09,120
from the back end so it's really

200
00:07:07,520 --> 00:07:10,000
integrated into things and you can pass

201
00:07:09,120 --> 00:07:13,360
around your

202
00:07:10,000 --> 00:07:14,960
algorithms and run them on other

203
00:07:13,360 --> 00:07:18,319
backends or you can pass them to other

204
00:07:14,960 --> 00:07:20,400
users to be reused

205
00:07:18,319 --> 00:07:22,240
then then there's file management where

206
00:07:20,400 --> 00:07:23,840
you can basically upload assets if

207
00:07:22,240 --> 00:07:25,599
there's a geojson file that you need to

208
00:07:23,840 --> 00:07:27,359
pass or something like that or whether

209
00:07:25,599 --> 00:07:28,719
there is uh things that you want to

210
00:07:27,360 --> 00:07:32,319
download all is

211
00:07:28,720 --> 00:07:33,520
handled by a central file management api

212
00:07:32,319 --> 00:07:35,039
of course then there is a processing

213
00:07:33,520 --> 00:07:36,719
service you can either process

214
00:07:35,039 --> 00:07:38,479
synchronous so then you basically send

215
00:07:36,720 --> 00:07:39,280
the things to the server and immediately

216
00:07:38,479 --> 00:07:40,880
or

217
00:07:39,280 --> 00:07:43,359
in a matter of seconds hopefully get a

218
00:07:40,880 --> 00:07:45,199
response back with the result that of

219
00:07:43,360 --> 00:07:48,720
course only works for limited like

220
00:07:45,199 --> 00:07:50,879
extends and data um and for

221
00:07:48,720 --> 00:07:52,160
bigger things you can use batch jobs

222
00:07:50,879 --> 00:07:54,639
where you can basically

223
00:07:52,160 --> 00:07:56,879
uh also send the data to the server and

224
00:07:54,639 --> 00:07:57,440
then wait for whatever time it needs to

225
00:07:56,879 --> 00:08:00,479
process

226
00:07:57,440 --> 00:08:01,199
things and then get back the results to

227
00:08:00,479 --> 00:08:04,240
download it

228
00:08:01,199 --> 00:08:07,440
again as stack catalog with the

229
00:08:04,240 --> 00:08:07,440
appropriate files in it

230
00:08:07,840 --> 00:08:11,520
and the third thing is the web services

231
00:08:09,919 --> 00:08:14,639
so you can basically um

232
00:08:11,520 --> 00:08:18,080
also there is an api to basically host

233
00:08:14,639 --> 00:08:20,560
wms through open eo or wcs or other

234
00:08:18,080 --> 00:08:22,800
services that you want to expose

235
00:08:20,560 --> 00:08:23,759
so we don't redefine things for viewing

236
00:08:22,800 --> 00:08:26,720
and stuff like that but

237
00:08:23,759 --> 00:08:28,720
rely on the standards that are already

238
00:08:26,720 --> 00:08:31,680
there and defined problem mostly from

239
00:08:28,720 --> 00:08:34,080
odc but you can also like expose

240
00:08:31,680 --> 00:08:36,159
non-standardized things like xyz tiles

241
00:08:34,080 --> 00:08:38,560
that are used by openstreetmap for

242
00:08:36,159 --> 00:08:38,559
example

243
00:08:39,039 --> 00:08:42,718
yeah processes are already mentioned

244
00:08:40,640 --> 00:08:44,399
there is a set of predefined processes

245
00:08:42,719 --> 00:08:45,680
like at the moment i think 130 or

246
00:08:44,399 --> 00:08:48,880
something like that

247
00:08:45,680 --> 00:08:50,079
for band mass for loading data into data

248
00:08:48,880 --> 00:08:52,320
cubes

249
00:08:50,080 --> 00:08:54,560
working on data cubes remaining renaming

250
00:08:52,320 --> 00:08:56,320
dimensions adding new values and stuff

251
00:08:54,560 --> 00:08:59,119
like that

252
00:08:56,320 --> 00:08:59,839
you can visit processes.opengo.org to

253
00:08:59,120 --> 00:09:01,760
see the list

254
00:08:59,839 --> 00:09:03,680
and then of course based on the

255
00:09:01,760 --> 00:09:05,920
predefined processes you can

256
00:09:03,680 --> 00:09:07,120
define your own user defined processes

257
00:09:05,920 --> 00:09:08,719
which is internally

258
00:09:07,120 --> 00:09:10,880
just a graph that is basically a

259
00:09:08,720 --> 00:09:12,160
dependency graph with instructions how

260
00:09:10,880 --> 00:09:15,040
to work

261
00:09:12,160 --> 00:09:17,120
on the data and then there is udfs again

262
00:09:15,040 --> 00:09:18,880
which is basically the thing i

263
00:09:17,120 --> 00:09:21,120
talked about before where you can write

264
00:09:18,880 --> 00:09:23,040
your r and python scripts and send it to

265
00:09:21,120 --> 00:09:24,959
the server as part of the other

266
00:09:23,040 --> 00:09:27,839
processes so basically you can

267
00:09:24,959 --> 00:09:29,518
say i use a predefined process and then

268
00:09:27,839 --> 00:09:32,959
load data with it and then

269
00:09:29,519 --> 00:09:33,760
this data gets passed to the udf process

270
00:09:32,959 --> 00:09:35,599
and then you can

271
00:09:33,760 --> 00:09:37,600
further compute it with other processes

272
00:09:35,600 --> 00:09:39,360
we have predefined to say for example

273
00:09:37,600 --> 00:09:41,360
the data

274
00:09:39,360 --> 00:09:43,519
and then you're ready to go and download

275
00:09:41,360 --> 00:09:45,120
the data

276
00:09:43,519 --> 00:09:47,279
we have several clients implemented at

277
00:09:45,120 --> 00:09:50,080
the moment we're tackling javascript

278
00:09:47,279 --> 00:09:52,880
python and r at the moment

279
00:09:50,080 --> 00:09:54,720
which should tackle most of the

280
00:09:52,880 --> 00:09:57,040
geospatial community i guess maybe

281
00:09:54,720 --> 00:09:58,240
there's yulia in the future again as

282
00:09:57,040 --> 00:10:01,040
well but

283
00:09:58,240 --> 00:10:03,120
we'll see we have a browser-based

284
00:10:01,040 --> 00:10:04,480
application as well for

285
00:10:03,120 --> 00:10:06,959
users that are not so much into

286
00:10:04,480 --> 00:10:07,680
programming so that pretty much works

287
00:10:06,959 --> 00:10:11,439
like a

288
00:10:07,680 --> 00:10:13,760
model builder in arcgis or qgis

289
00:10:11,440 --> 00:10:14,720
then we have a qgis implementation where

290
00:10:13,760 --> 00:10:17,519
you can

291
00:10:14,720 --> 00:10:18,640
use it as a plugin and basically start

292
00:10:17,519 --> 00:10:20,480
jobs from

293
00:10:18,640 --> 00:10:22,079
qe gis and download it and show it in

294
00:10:20,480 --> 00:10:23,760
qgis directly

295
00:10:22,079 --> 00:10:26,079
and there is a mobile app that can you

296
00:10:23,760 --> 00:10:27,680
can use as well

297
00:10:26,079 --> 00:10:29,120
this is a screenshot for example from

298
00:10:27,680 --> 00:10:32,079
the web editor

299
00:10:29,120 --> 00:10:33,760
you see these workflows over there at

300
00:10:32,079 --> 00:10:36,719
the top in the middle

301
00:10:33,760 --> 00:10:37,680
then the management stuff is here in the

302
00:10:36,720 --> 00:10:39,519
in the bottom

303
00:10:37,680 --> 00:10:41,040
you see a list of processes collections

304
00:10:39,519 --> 00:10:43,279
you can use you can drag and drop them

305
00:10:41,040 --> 00:10:44,719
into the model builder

306
00:10:43,279 --> 00:10:47,200
and then on the right there is a map

307
00:10:44,720 --> 00:10:51,120
that you can basically use to

308
00:10:47,200 --> 00:10:55,839
view the data i think there is some no2

309
00:10:51,120 --> 00:10:55,839
visualization at the moment on the map

310
00:10:57,120 --> 00:11:01,680
this is how for example an evi

311
00:10:59,200 --> 00:11:05,120
computation would look like

312
00:11:01,680 --> 00:11:08,079
on that is r yes that is r

313
00:11:05,120 --> 00:11:09,519
um it it's pretty easy you just connect

314
00:11:08,079 --> 00:11:10,959
to

315
00:11:09,519 --> 00:11:12,839
the web servers with the url and of

316
00:11:10,959 --> 00:11:14,000
course username password then will be

317
00:11:12,839 --> 00:11:16,079
prompted

318
00:11:14,000 --> 00:11:17,680
then you basically create a data cube

319
00:11:16,079 --> 00:11:20,239
you can load data

320
00:11:17,680 --> 00:11:21,599
in this example it's central to again

321
00:11:20,240 --> 00:11:23,760
you can specify the spatial extent

322
00:11:21,600 --> 00:11:25,279
template extends and bands to be loaded

323
00:11:23,760 --> 00:11:27,600
then that will be loaded into a data

324
00:11:25,279 --> 00:11:30,000
cube then for example in this case we

325
00:11:27,600 --> 00:11:32,480
will reduce the dimension bands

326
00:11:30,000 --> 00:11:36,079
and do some band mouth on the bands in

327
00:11:32,480 --> 00:11:36,079
this case the evi computation

328
00:11:36,399 --> 00:11:40,240
and then reduce the temporal dimension

329
00:11:38,160 --> 00:11:41,279
to b to just give you the minimum

330
00:11:40,240 --> 00:11:44,320
composite

331
00:11:41,279 --> 00:11:47,600
and save the result as geotiff and

332
00:11:44,320 --> 00:11:48,560
then the same you can do with python in

333
00:11:47,600 --> 00:11:51,920
this case

334
00:11:48,560 --> 00:11:52,319
it's looking very similar you can use

335
00:11:51,920 --> 00:11:56,079
the

336
00:11:52,320 --> 00:11:58,399
the functions as if in python like

337
00:11:56,079 --> 00:12:00,079
the the operators here are overloaded

338
00:11:58,399 --> 00:12:02,720
just to be used

339
00:12:00,079 --> 00:12:04,239
um and then they are translated into our

340
00:12:02,720 --> 00:12:06,639
internal representation and sent to the

341
00:12:04,240 --> 00:12:06,639
server

342
00:12:07,920 --> 00:12:11,040
yeah we have several server

343
00:12:09,279 --> 00:12:13,839
implementations already that are

344
00:12:11,040 --> 00:12:15,839
you can reuse um or extend if you want

345
00:12:13,839 --> 00:12:16,800
um there's geopyspark into your trellis

346
00:12:15,839 --> 00:12:18,880
implementation

347
00:12:16,800 --> 00:12:20,800
um there is a google earth

348
00:12:18,880 --> 00:12:22,160
implementation so you can basically run

349
00:12:20,800 --> 00:12:23,040
our scripts already on google earth

350
00:12:22,160 --> 00:12:25,839
engine as well

351
00:12:23,040 --> 00:12:27,360
for free there's a grass gis actinia

352
00:12:25,839 --> 00:12:30,880
implementation you can

353
00:12:27,360 --> 00:12:35,040
go to microstock and at 2pm

354
00:12:30,880 --> 00:12:36,560
to get more about that there's a jrc

355
00:12:35,040 --> 00:12:38,880
earth observation data and processing

356
00:12:36,560 --> 00:12:40,560
platform from the european commission

357
00:12:38,880 --> 00:12:42,959
there is an open stack implementation

358
00:12:40,560 --> 00:12:45,279
there is access to sentinel hub as well

359
00:12:42,959 --> 00:12:46,560
and there is a server implementation for

360
00:12:45,279 --> 00:12:50,079
wcps

361
00:12:46,560 --> 00:12:50,079
which is in the end rasterman

362
00:12:51,519 --> 00:12:55,040
there is a bit of ecosystem we also

363
00:12:53,200 --> 00:12:56,399
developed as for example open the oh hub

364
00:12:55,040 --> 00:12:57,920
which you can go to and

365
00:12:56,399 --> 00:13:00,480
then you get basically a list of

366
00:12:57,920 --> 00:13:01,839
overview which um servers are there

367
00:13:00,480 --> 00:13:03,600
where you can process on you can

368
00:13:01,839 --> 00:13:04,399
basically for example also just pass

369
00:13:03,600 --> 00:13:06,000
your

370
00:13:04,399 --> 00:13:07,519
algorithm that you implemented and then

371
00:13:06,000 --> 00:13:08,160
it tells you and which server you can

372
00:13:07,519 --> 00:13:09,680
run it

373
00:13:08,160 --> 00:13:11,760
gives you information about which data

374
00:13:09,680 --> 00:13:13,120
is available and what it costs and stuff

375
00:13:11,760 --> 00:13:15,279
like that

376
00:13:13,120 --> 00:13:17,360
you can also share there your own

377
00:13:15,279 --> 00:13:20,079
defined processes your udfs and

378
00:13:17,360 --> 00:13:22,320
stuff like that and then there is a

379
00:13:20,079 --> 00:13:25,199
validator of course to check whether the

380
00:13:22,320 --> 00:13:26,000
api implementations are valid it checks

381
00:13:25,200 --> 00:13:28,240
both the

382
00:13:26,000 --> 00:13:29,760
actual just the structure of the api

383
00:13:28,240 --> 00:13:32,000
whether the responses are valid

384
00:13:29,760 --> 00:13:34,880
and then also it checks whether the

385
00:13:32,000 --> 00:13:37,040
results that are processed are valid um

386
00:13:34,880 --> 00:13:38,720
so there is a also a way to check

387
00:13:37,040 --> 00:13:41,680
whether in between the

388
00:13:38,720 --> 00:13:43,600
back ends there is differences that are

389
00:13:41,680 --> 00:13:46,120
coming from processing

390
00:13:43,600 --> 00:13:48,160
um then we have of course when you visit

391
00:13:46,120 --> 00:13:49,040
processes.openmuo.org you see a rendered

392
00:13:48,160 --> 00:13:52,480
list of processes

393
00:13:49,040 --> 00:13:55,599
which is basically rendered through

394
00:13:52,480 --> 00:13:57,199
our dock generator for processors and of

395
00:13:55,600 --> 00:13:59,839
course you can also reuse for

396
00:13:57,199 --> 00:14:02,160
at least for the data discovery part you

397
00:13:59,839 --> 00:14:04,720
can use the stack and ogc api features

398
00:14:02,160 --> 00:14:05,760
ecosystem because the api is completely

399
00:14:04,720 --> 00:14:09,360
um

400
00:14:05,760 --> 00:14:09,920
yeah compliant to that standard and and

401
00:14:09,360 --> 00:14:11,839
that's such

402
00:14:09,920 --> 00:14:13,839
you can use that ecosystem and if you

403
00:14:11,839 --> 00:14:15,519
expose the wms of course you can just

404
00:14:13,839 --> 00:14:18,720
use the wms

405
00:14:15,519 --> 00:14:21,600
clients that you are aware of

406
00:14:18,720 --> 00:14:24,720
the state of openo at the moment is that

407
00:14:21,600 --> 00:14:28,399
all these partners are working on that

408
00:14:24,720 --> 00:14:31,600
and maybe also you in the future

409
00:14:28,399 --> 00:14:33,920
we are currently have released version

410
00:14:31,600 --> 00:14:35,760
1.0 release candidate once so we are

411
00:14:33,920 --> 00:14:37,599
pretty much going into stable mode now

412
00:14:35,760 --> 00:14:40,319
after experimenting a long while

413
00:14:37,600 --> 00:14:41,839
for two years um with what works best

414
00:14:40,320 --> 00:14:45,199
and what doesn't

415
00:14:41,839 --> 00:14:48,240
and um the project ends in the

416
00:14:45,199 --> 00:14:49,680
third quarter of the year so then we can

417
00:14:48,240 --> 00:14:52,399
expect a stable version where you can

418
00:14:49,680 --> 00:14:55,359
really rely on

419
00:14:52,399 --> 00:14:56,880
yeah and that's it for my two talks now

420
00:14:55,360 --> 00:14:59,120
i need some water and

421
00:14:56,880 --> 00:15:01,839
then thank you for listening and i take

422
00:14:59,120 --> 00:15:01,839
your questions

423
00:15:04,160 --> 00:15:13,839
here's some time for questions anyone

424
00:15:07,600 --> 00:15:13,839
can we stack and open yo yes

425
00:15:23,360 --> 00:15:27,440
yeah so regarding maintaining there are

426
00:15:25,680 --> 00:15:28,319
a couple of companies that are basing

427
00:15:27,440 --> 00:15:31,839
their work and

428
00:15:28,320 --> 00:15:33,680
future work of an open eo so eodc for

429
00:15:31,839 --> 00:15:35,839
example and veto

430
00:15:33,680 --> 00:15:37,120
are all already like pushing things

431
00:15:35,839 --> 00:15:39,199
internally so that

432
00:15:37,120 --> 00:15:40,240
their internal users and external users

433
00:15:39,199 --> 00:15:43,359
are using that so

434
00:15:40,240 --> 00:15:44,480
in that sense they need to continue with

435
00:15:43,360 --> 00:15:46,000
that of course

436
00:15:44,480 --> 00:15:48,079
because they have clients that rely on

437
00:15:46,000 --> 00:15:50,160
that

438
00:15:48,079 --> 00:15:53,279
and there's also further projects that

439
00:15:50,160 --> 00:15:57,360
we want to establish based on openyo so

440
00:15:53,279 --> 00:16:00,399
i hope that will make it future proof

441
00:15:57,360 --> 00:16:02,000
regarding user base we have some use

442
00:16:00,399 --> 00:16:02,480
cases that are running at the moment to

443
00:16:02,000 --> 00:16:04,160
really

444
00:16:02,480 --> 00:16:05,519
check whether all that what we did is

445
00:16:04,160 --> 00:16:08,480
working

446
00:16:05,519 --> 00:16:09,519
that is a broad range of things snow

447
00:16:08,480 --> 00:16:12,079
cover analysis

448
00:16:09,519 --> 00:16:14,480
agriculture and stuff like that but

449
00:16:12,079 --> 00:16:16,239
there could be more of course

450
00:16:14,480 --> 00:16:17,600
the thing is like if you start something

451
00:16:16,240 --> 00:16:20,480
new you start to find

452
00:16:17,600 --> 00:16:21,440
people that are really want to hop on a

453
00:16:20,480 --> 00:16:23,920
thing that is not

454
00:16:21,440 --> 00:16:26,000
stable yet so but we are working on that

455
00:16:23,920 --> 00:16:28,160
and it evolves over time

456
00:16:26,000 --> 00:16:29,360
we also have some metrological things in

457
00:16:28,160 --> 00:16:32,480
the future um

458
00:16:29,360 --> 00:16:37,839
with ecwmf plan so

459
00:16:32,480 --> 00:16:37,839
yeah that's the future hope

460
00:16:38,160 --> 00:16:42,399
questions what about licensing and

461
00:16:40,880 --> 00:16:46,000
actually about

462
00:16:42,399 --> 00:16:49,600
is this infrastructure for that

463
00:16:46,000 --> 00:16:51,759
license on my own

464
00:16:49,600 --> 00:16:53,440
so for open yo everything is licensed

465
00:16:51,759 --> 00:16:55,680
under apache 2 license so

466
00:16:53,440 --> 00:16:57,040
that's all open source and you can reuse

467
00:16:55,680 --> 00:17:00,399
it uh

468
00:16:57,040 --> 00:17:02,560
to whatever extent you want um

469
00:17:00,399 --> 00:17:04,240
so feel free to implement something or

470
00:17:02,560 --> 00:17:07,039
do pull request it's all on github

471
00:17:04,240 --> 00:17:08,079
um so that's good uh what was the other

472
00:17:07,039 --> 00:17:13,679
thing

473
00:17:08,079 --> 00:17:13,678
actually i see that

474
00:17:16,839 --> 00:17:19,839
um

475
00:17:34,960 --> 00:17:38,799
as far as i know for most of these

476
00:17:37,200 --> 00:17:42,000
implementations there are docker

477
00:17:38,799 --> 00:17:42,000
containers which you can run

478
00:17:42,960 --> 00:17:47,360
let's start we're working on making

479
00:17:45,120 --> 00:17:50,159
their that more

480
00:17:47,360 --> 00:17:51,439
easy to adopt at the moment most of the

481
00:17:50,160 --> 00:17:53,039
implementers are still

482
00:17:51,440 --> 00:17:55,440
like setting up their own infrastructure

483
00:17:53,039 --> 00:17:58,240
to get things running of course

484
00:17:55,440 --> 00:17:59,760
so in the future there should be more

485
00:17:58,240 --> 00:18:00,000
things like vagrant scripts and stuff

486
00:17:59,760 --> 00:18:02,160
like

487
00:18:00,000 --> 00:18:02,160
that

488
00:18:05,280 --> 00:18:15,840
anybody else if not

489
00:18:08,880 --> 00:18:15,840
well thank you very much thank you

