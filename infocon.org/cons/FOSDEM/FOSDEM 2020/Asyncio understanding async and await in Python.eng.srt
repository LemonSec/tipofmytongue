1
00:00:05,359 --> 00:00:08,560
okay thank you very much

2
00:00:08,639 --> 00:00:12,559
time to welcome our next speaker

3
00:00:10,719 --> 00:00:15,120
jonathan who's going to tell us more

4
00:00:12,559 --> 00:00:16,128
about i think io

5
00:00:15,120 --> 00:00:21,359
okay

6
00:00:16,129 --> 00:00:24,960
[Applause]

7
00:00:21,359 --> 00:00:27,439
thank you all right so good afternoon

8
00:00:24,960 --> 00:00:28,320
uh hope you have a good fall then so i'm

9
00:00:27,439 --> 00:00:31,840
going to talk

10
00:00:28,320 --> 00:00:31,840
you cannot hear me

11
00:00:32,960 --> 00:00:38,480
so speak louder okay can you hear me

12
00:00:36,800 --> 00:00:39,919
yeah good enough okay i tried to speak

13
00:00:38,480 --> 00:00:41,680
loud enough

14
00:00:39,920 --> 00:00:43,600
okay so we are going to talk a bit about

15
00:00:41,680 --> 00:00:45,920
async io and python

16
00:00:43,600 --> 00:00:47,280
so um it's about the async and await

17
00:00:45,920 --> 00:00:48,239
keywords that were added a couple of

18
00:00:47,280 --> 00:00:50,559
years ago

19
00:00:48,239 --> 00:00:51,440
and how we can use them within python

20
00:00:50,559 --> 00:00:53,599
and a bits

21
00:00:51,440 --> 00:00:55,199
about what is the difference between

22
00:00:53,600 --> 00:00:57,120
writing async io code

23
00:00:55,199 --> 00:00:59,199
and writing threaded code because that's

24
00:00:57,120 --> 00:01:02,239
another way of doing concurrency

25
00:00:59,199 --> 00:01:03,920
so all this is about how can we speed up

26
00:01:02,239 --> 00:01:04,798
our program how can we do things in

27
00:01:03,920 --> 00:01:08,720
parallel

28
00:01:04,799 --> 00:01:12,560
in order to improve the execution speed

29
00:01:08,720 --> 00:01:14,560
so we have quite a bit of different ways

30
00:01:12,560 --> 00:01:16,479
of doing concurrency in python

31
00:01:14,560 --> 00:01:17,920
first there was multi-threading which is

32
00:01:16,479 --> 00:01:20,000
the easiest way to do

33
00:01:17,920 --> 00:01:21,200
concurrency then there was

34
00:01:20,000 --> 00:01:23,360
multi-processing

35
00:01:21,200 --> 00:01:24,240
which solves an issue if you need more

36
00:01:23,360 --> 00:01:26,240
cpu

37
00:01:24,240 --> 00:01:28,000
because one python process can only

38
00:01:26,240 --> 00:01:30,880
consume one cpu

39
00:01:28,000 --> 00:01:32,640
if you need to have multiple cpus uh

40
00:01:30,880 --> 00:01:33,439
because your problem is very cpu

41
00:01:32,640 --> 00:01:35,840
intensive

42
00:01:33,439 --> 00:01:36,880
then you need multiprocessing then

43
00:01:35,840 --> 00:01:38,960
there's g events

44
00:01:36,880 --> 00:01:40,000
not going to talk a lot about that and

45
00:01:38,960 --> 00:01:42,960
then you have a whole

46
00:01:40,000 --> 00:01:44,720
lot of event loop based implementations

47
00:01:42,960 --> 00:01:45,600
like there's twisted which is probably

48
00:01:44,720 --> 00:01:48,720
the oldest

49
00:01:45,600 --> 00:01:51,360
then a few others and in 2012 we got

50
00:01:48,720 --> 00:01:53,759
async iu

51
00:01:51,360 --> 00:01:55,600
so let's first start with training so

52
00:01:53,759 --> 00:01:57,840
training is pretty easy you define two

53
00:01:55,600 --> 00:02:00,399
functions in this case lsm bob

54
00:01:57,840 --> 00:02:02,240
and then you create two threads where

55
00:02:00,399 --> 00:02:04,000
each time you say first the entry point

56
00:02:02,240 --> 00:02:04,960
the targets alice second time you see

57
00:02:04,000 --> 00:02:09,360
target is bob

58
00:02:04,960 --> 00:02:11,599
and you start in so if we execute it

59
00:02:09,360 --> 00:02:13,120
then you see these two things are

60
00:02:11,599 --> 00:02:14,799
running concurrently

61
00:02:13,120 --> 00:02:17,840
you see both print statements they're

62
00:02:14,800 --> 00:02:17,840
nicely interleaved

63
00:02:17,920 --> 00:02:22,160
now things become more complex if these

64
00:02:20,959 --> 00:02:25,840
threads if they has

65
00:02:22,160 --> 00:02:28,000
have to um coordinate with each other if

66
00:02:25,840 --> 00:02:29,680
they have to exchange data somehow

67
00:02:28,000 --> 00:02:31,200
like for instance in this example you

68
00:02:29,680 --> 00:02:34,080
see that there's a global variable

69
00:02:31,200 --> 00:02:35,760
counter and both threads are trying to

70
00:02:34,080 --> 00:02:38,319
manipulate that variable

71
00:02:35,760 --> 00:02:40,160
so um first we are doing an increment

72
00:02:38,319 --> 00:02:42,000
and then we are doing a decrement

73
00:02:40,160 --> 00:02:43,840
and both threads you see they're doing

74
00:02:42,000 --> 00:02:48,560
exactly the same thing

75
00:02:43,840 --> 00:02:51,360
and now we can try to execute this

76
00:02:48,560 --> 00:02:53,840
so what you would expect is that for

77
00:02:51,360 --> 00:02:55,440
every increment we do a decrement

78
00:02:53,840 --> 00:02:57,440
so if we would print the value of

79
00:02:55,440 --> 00:03:00,879
counter at regular points in time

80
00:02:57,440 --> 00:03:02,840
we would always print the value 0 1 or 2

81
00:03:00,879 --> 00:03:04,159
depending on when exactly we print the

82
00:03:02,840 --> 00:03:08,959
value

83
00:03:04,159 --> 00:03:10,799
so let's try that that's this script

84
00:03:08,959 --> 00:03:12,400
you see it's not exactly the case right

85
00:03:10,800 --> 00:03:14,080
now we're printing negative values then

86
00:03:12,400 --> 00:03:17,360
it becomes positive again

87
00:03:14,080 --> 00:03:20,800
and as we go on we

88
00:03:17,360 --> 00:03:26,159
diverge from actually the zero

89
00:03:20,800 --> 00:03:26,159
value so how is this possible

90
00:03:26,239 --> 00:03:30,159
let's take this function so very simple

91
00:03:28,640 --> 00:03:31,359
function with an assignment and an

92
00:03:30,159 --> 00:03:32,879
increment

93
00:03:31,360 --> 00:03:34,879
if we're going to disassemble this

94
00:03:32,879 --> 00:03:35,440
function you can do that in python by

95
00:03:34,879 --> 00:03:37,440
importing

96
00:03:35,440 --> 00:03:38,959
this library and then you do this dot

97
00:03:37,440 --> 00:03:41,840
this and you

98
00:03:38,959 --> 00:03:42,400
pass f so that you see the byte code of

99
00:03:41,840 --> 00:03:45,599
that phone

100
00:03:42,400 --> 00:03:48,640
this function then you see that actually

101
00:03:45,599 --> 00:03:51,839
for the increment that corresponds with

102
00:03:48,640 --> 00:03:53,518
these four instructions um that it's not

103
00:03:51,840 --> 00:03:55,920
really one instruction

104
00:03:53,519 --> 00:03:57,519
an increment like plus equal zero or

105
00:03:55,920 --> 00:04:01,760
plus equal one sorry

106
00:03:57,519 --> 00:04:05,840
um consists of these four instructions

107
00:04:01,760 --> 00:04:07,599
um it has to do with how the um

108
00:04:05,840 --> 00:04:09,439
the python interpreter operates on the

109
00:04:07,599 --> 00:04:11,760
stack um

110
00:04:09,439 --> 00:04:13,519
but it's very interesting it means that

111
00:04:11,760 --> 00:04:14,720
if we have two threads that operate on

112
00:04:13,519 --> 00:04:16,560
that same variable

113
00:04:14,720 --> 00:04:18,478
at any point in time between these

114
00:04:16,560 --> 00:04:19,759
instructions we can go from one thread

115
00:04:18,478 --> 00:04:21,680
to the other thread

116
00:04:19,759 --> 00:04:23,840
which means that these two threads can

117
00:04:21,680 --> 00:04:26,160
possibly interfere with each other

118
00:04:23,840 --> 00:04:27,758
and that's exactly what's happening in

119
00:04:26,160 --> 00:04:31,120
this example

120
00:04:27,759 --> 00:04:33,840
so the way to solve that is by using

121
00:04:31,120 --> 00:04:35,440
a lock so you can create a lock and you

122
00:04:33,840 --> 00:04:38,638
surround these blocks where you

123
00:04:35,440 --> 00:04:39,600
modify that shared variable uh with that

124
00:04:38,639 --> 00:04:41,840
with lock

125
00:04:39,600 --> 00:04:43,199
context manager and then you prevent

126
00:04:41,840 --> 00:04:45,599
these two threads from

127
00:04:43,199 --> 00:04:48,240
manipulating the same variable at the

128
00:04:45,600 --> 00:04:48,240
same time

129
00:04:48,800 --> 00:04:52,560
so what is wrong or what is the

130
00:04:51,440 --> 00:04:55,840
disadvantage of

131
00:04:52,560 --> 00:04:56,080
using threads is that when as soon as

132
00:04:55,840 --> 00:04:58,479
you

133
00:04:56,080 --> 00:04:59,280
have to uh manipulate shared data

134
00:04:58,479 --> 00:05:01,280
structures

135
00:04:59,280 --> 00:05:02,559
you have to think about locking and

136
00:05:01,280 --> 00:05:03,758
that's something which is very hard to

137
00:05:02,560 --> 00:05:06,880
get right

138
00:05:03,759 --> 00:05:07,919
so either you choose to use one global

139
00:05:06,880 --> 00:05:10,800
lock

140
00:05:07,919 --> 00:05:13,520
but then you have the rest that um you

141
00:05:10,800 --> 00:05:15,280
lock too often like things that could go

142
00:05:13,520 --> 00:05:17,599
in parallel that these things become

143
00:05:15,280 --> 00:05:20,559
sequential or you use

144
00:05:17,600 --> 00:05:22,240
very like many small fine grained locks

145
00:05:20,560 --> 00:05:23,840
like for each data structure you create

146
00:05:22,240 --> 00:05:26,080
one lock

147
00:05:23,840 --> 00:05:27,280
to protect that from being modified by

148
00:05:26,080 --> 00:05:28,400
other threats

149
00:05:27,280 --> 00:05:31,758
and then you have the risk of dead

150
00:05:28,400 --> 00:05:34,400
locking there are ways to prevent that

151
00:05:31,759 --> 00:05:35,680
uh like some some guidelines and so on

152
00:05:34,400 --> 00:05:37,919
but it's very hard to get

153
00:05:35,680 --> 00:05:38,800
right and then threads they have some

154
00:05:37,919 --> 00:05:42,799
overhead

155
00:05:38,800 --> 00:05:44,479
not a lot uh so it's it's not really

156
00:05:42,800 --> 00:05:47,440
a main reason not used threads but still

157
00:05:44,479 --> 00:05:49,919
they have a bit of overhead

158
00:05:47,440 --> 00:05:51,600
i should also mention that instead of

159
00:05:49,919 --> 00:05:54,719
using shared data structures

160
00:05:51,600 --> 00:05:55,280
you can also not share data between

161
00:05:54,720 --> 00:05:57,840
threads

162
00:05:55,280 --> 00:05:59,919
but use some kind of message passing so

163
00:05:57,840 --> 00:06:02,400
these threads they can communicate

164
00:05:59,919 --> 00:06:03,758
over a queue and so if one thread has to

165
00:06:02,400 --> 00:06:05,198
pass data to another thread

166
00:06:03,759 --> 00:06:08,000
you can send it over the queue and

167
00:06:05,199 --> 00:06:10,560
serialize it that's a way to prevent

168
00:06:08,000 --> 00:06:12,160
using locks and prevent these issues but

169
00:06:10,560 --> 00:06:14,240
it's also a whole different way of

170
00:06:12,160 --> 00:06:17,680
programming

171
00:06:14,240 --> 00:06:19,440
so let's come to async io

172
00:06:17,680 --> 00:06:21,199
we're going to have a look at how we can

173
00:06:19,440 --> 00:06:23,199
do these things in async io

174
00:06:21,199 --> 00:06:24,720
so here we have also two functions

175
00:06:23,199 --> 00:06:25,919
function1 and function2

176
00:06:24,720 --> 00:06:28,000
and we are going to run these in

177
00:06:25,919 --> 00:06:30,400
parallel and do the same thing the same

178
00:06:28,000 --> 00:06:33,360
increments and decrements

179
00:06:30,400 --> 00:06:35,120
now you see that these functions are not

180
00:06:33,360 --> 00:06:36,880
normal functions there's async

181
00:06:35,120 --> 00:06:38,639
in front of the dev keyword which means

182
00:06:36,880 --> 00:06:42,000
it's an asynchronous function

183
00:06:38,639 --> 00:06:44,880
and then there's an await as well

184
00:06:42,000 --> 00:06:45,919
now what the await keyword here actually

185
00:06:44,880 --> 00:06:48,400
means is

186
00:06:45,919 --> 00:06:50,639
that that is a place where it's fine to

187
00:06:48,400 --> 00:06:53,198
go from one function to the other

188
00:06:50,639 --> 00:06:54,880
so basically we are in control when we

189
00:06:53,199 --> 00:06:56,400
do the complex switching between these

190
00:06:54,880 --> 00:06:58,880
two functions

191
00:06:56,400 --> 00:07:00,960
so if we are now going to execute this

192
00:06:58,880 --> 00:07:03,199
these two will run concurrently

193
00:07:00,960 --> 00:07:04,000
but the complex switch between these two

194
00:07:03,199 --> 00:07:05,840
functions

195
00:07:04,000 --> 00:07:08,000
they will only happen at the place where

196
00:07:05,840 --> 00:07:10,159
we have an await keyword

197
00:07:08,000 --> 00:07:12,319
uh there is a sleep that's not important

198
00:07:10,160 --> 00:07:17,440
right now but it's just to make this

199
00:07:12,319 --> 00:07:20,080
example work so let's

200
00:07:17,440 --> 00:07:21,280
this example you see we always print

201
00:07:20,080 --> 00:07:23,120
zero

202
00:07:21,280 --> 00:07:25,039
that's what you get when you would

203
00:07:23,120 --> 00:07:28,080
execute the script

204
00:07:25,039 --> 00:07:30,960
um so

205
00:07:28,080 --> 00:07:32,719
the await keyword actually it means that

206
00:07:30,960 --> 00:07:34,880
it's a place where it's safe

207
00:07:32,720 --> 00:07:36,000
for one core team to move to another

208
00:07:34,880 --> 00:07:39,039
core team

209
00:07:36,000 --> 00:07:41,039
that's it basically now

210
00:07:39,039 --> 00:07:43,039
in practice it means a bit more than

211
00:07:41,039 --> 00:07:45,520
just that it also means that

212
00:07:43,039 --> 00:07:46,719
you're probably waiting for some io to

213
00:07:45,520 --> 00:07:49,120
complete

214
00:07:46,720 --> 00:07:51,360
because the problem that we typically

215
00:07:49,120 --> 00:07:54,800
try to solve with async io

216
00:07:51,360 --> 00:07:56,879
is a very i o intensive application

217
00:07:54,800 --> 00:07:58,000
and when you have many things going on

218
00:07:56,879 --> 00:08:00,000
in parallel a

219
00:07:58,000 --> 00:08:01,199
good point to go from one core team to

220
00:08:00,000 --> 00:08:02,639
another core team

221
00:08:01,199 --> 00:08:04,639
is when you're idle when you're not

222
00:08:02,639 --> 00:08:06,560
doing anything like for instance you do

223
00:08:04,639 --> 00:08:07,520
a network request you wait for response

224
00:08:06,560 --> 00:08:09,759
to arrive

225
00:08:07,520 --> 00:08:11,520
in between you're not doing anything so

226
00:08:09,759 --> 00:08:14,000
that is exactly the right place where it

227
00:08:11,520 --> 00:08:17,198
makes sense to go to another core team

228
00:08:14,000 --> 00:08:18,720
and resume the execution over there

229
00:08:17,199 --> 00:08:20,639
and so actually you will go back and

230
00:08:18,720 --> 00:08:22,479
forth between all these curtins

231
00:08:20,639 --> 00:08:24,000
at the point where you haven't await so

232
00:08:22,479 --> 00:08:27,120
you have total control

233
00:08:24,000 --> 00:08:28,639
over the context switching

234
00:08:27,120 --> 00:08:30,240
so basically the difference between

235
00:08:28,639 --> 00:08:31,759
threads and quarantines is that

236
00:08:30,240 --> 00:08:33,760
threads are pre-emptive and the

237
00:08:31,759 --> 00:08:34,479
operating system decides when to context

238
00:08:33,760 --> 00:08:36,559
switch

239
00:08:34,479 --> 00:08:37,919
with coroutines like what we have in

240
00:08:36,559 --> 00:08:39,919
async io

241
00:08:37,919 --> 00:08:41,039
we are in control over the context

242
00:08:39,919 --> 00:08:43,598
switching

243
00:08:41,039 --> 00:08:45,600
and that means that most of the time we

244
00:08:43,599 --> 00:08:48,000
don't have to use locks

245
00:08:45,600 --> 00:08:49,920
because we know what pieces of code are

246
00:08:48,000 --> 00:08:51,519
anatomically and won't be interrupted

247
00:08:49,920 --> 00:08:54,079
that's exactly where we don't have an

248
00:08:51,519 --> 00:08:56,959
await and so um

249
00:08:54,080 --> 00:08:57,279
it's much easier to get your quote right

250
00:08:56,959 --> 00:08:58,719
uh

251
00:08:57,279 --> 00:09:00,399
wave trending there's a lot of chance

252
00:08:58,720 --> 00:09:01,920
that you get things wrong that in

253
00:09:00,399 --> 00:09:04,560
production at some point

254
00:09:01,920 --> 00:09:05,120
things will start breaking uh with async

255
00:09:04,560 --> 00:09:08,479
io

256
00:09:05,120 --> 00:09:11,760
it's easier to get things right

257
00:09:08,480 --> 00:09:12,240
now important to know is that all of

258
00:09:11,760 --> 00:09:14,560
this

259
00:09:12,240 --> 00:09:16,160
runs actually on top of an event loop so

260
00:09:14,560 --> 00:09:17,359
the core things are an abstraction on

261
00:09:16,160 --> 00:09:20,399
top of an even

262
00:09:17,360 --> 00:09:22,880
of an event loop an event loop that's

263
00:09:20,399 --> 00:09:25,200
a very simple mapping where you map i o

264
00:09:22,880 --> 00:09:28,160
completion events to call backs

265
00:09:25,200 --> 00:09:28,720
so like for instance uh when a network

266
00:09:28,160 --> 00:09:31,199
socket

267
00:09:28,720 --> 00:09:33,600
becomes ready for reading or writing

268
00:09:31,200 --> 00:09:36,399
when you receive most keyboard events

269
00:09:33,600 --> 00:09:38,160
these are events and then you specify a

270
00:09:36,399 --> 00:09:41,279
callback that will execute

271
00:09:38,160 --> 00:09:42,000
um when that event happens and that's

272
00:09:41,279 --> 00:09:44,399
literally

273
00:09:42,000 --> 00:09:46,320
this while through so you wait for the

274
00:09:44,399 --> 00:09:48,399
file descriptor to become ready

275
00:09:46,320 --> 00:09:49,360
file the script maps to an event and

276
00:09:48,399 --> 00:09:51,680
then you

277
00:09:49,360 --> 00:09:54,160
call the corresponding callback and you

278
00:09:51,680 --> 00:09:56,640
keep doing this in a loop

279
00:09:54,160 --> 00:09:57,680
so if you keep this in mind then you see

280
00:09:56,640 --> 00:10:00,160
that we only run

281
00:09:57,680 --> 00:10:02,079
one callback at a time right and that's

282
00:10:00,160 --> 00:10:03,279
really the advantage of event loops

283
00:10:02,079 --> 00:10:06,560
these callbacks

284
00:10:03,279 --> 00:10:08,880
they won't interfere with each other so

285
00:10:06,560 --> 00:10:11,839
we run everything in one thread one

286
00:10:08,880 --> 00:10:11,839
callback at a time

287
00:10:12,560 --> 00:10:16,959
i've said there is no complicated

288
00:10:14,800 --> 00:10:19,760
synchronization like data locking

289
00:10:16,959 --> 00:10:21,359
and so on it's also pretty easy to debug

290
00:10:19,760 --> 00:10:22,160
because if you put a break statement in

291
00:10:21,360 --> 00:10:24,800
your code

292
00:10:22,160 --> 00:10:26,160
your whole event loop will freeze and

293
00:10:24,800 --> 00:10:28,719
you can inspect the state of all

294
00:10:26,160 --> 00:10:30,880
coroutines

295
00:10:28,720 --> 00:10:32,240
and this is great also for handling many

296
00:10:30,880 --> 00:10:33,600
connections in parallel

297
00:10:32,240 --> 00:10:36,240
like if you have thousands of

298
00:10:33,600 --> 00:10:38,720
connections like websockets connections

299
00:10:36,240 --> 00:10:39,680
and the idle most of the time then event

300
00:10:38,720 --> 00:10:41,440
loop is perfect

301
00:10:39,680 --> 00:10:43,279
because you can wait for so many file

302
00:10:41,440 --> 00:10:44,880
descriptors at the same time

303
00:10:43,279 --> 00:10:47,760
your operating system can do that for

304
00:10:44,880 --> 00:10:52,399
you and then you execute the callback

305
00:10:47,760 --> 00:10:54,000
that corresponds to the incoming

306
00:10:52,399 --> 00:10:56,640
network connection from where you

307
00:10:54,000 --> 00:10:58,800
receive a message

308
00:10:56,640 --> 00:11:00,000
and that is of course much cheaper than

309
00:10:58,800 --> 00:11:03,040
having one thread for

310
00:11:00,000 --> 00:11:03,040
every single connection

311
00:11:03,760 --> 00:11:07,839
one important thing to know though is

312
00:11:05,920 --> 00:11:11,120
that you should not mix

313
00:11:07,839 --> 00:11:12,800
async io code with traditional or

314
00:11:11,120 --> 00:11:15,040
like the typical blocking code that you

315
00:11:12,800 --> 00:11:17,279
find in other applications

316
00:11:15,040 --> 00:11:19,120
like for instance if you use the request

317
00:11:17,279 --> 00:11:20,800
library for doing network requests

318
00:11:19,120 --> 00:11:22,959
that's what many people do in python

319
00:11:20,800 --> 00:11:24,240
they will block you do a request and

320
00:11:22,959 --> 00:11:26,399
your statement will

321
00:11:24,240 --> 00:11:28,880
your request will get statement will

322
00:11:26,399 --> 00:11:31,040
wait for the response to arrive

323
00:11:28,880 --> 00:11:32,959
if you try to do that in an event loop

324
00:11:31,040 --> 00:11:34,319
your whole event loop will freeze so you

325
00:11:32,959 --> 00:11:37,119
cannot do that

326
00:11:34,320 --> 00:11:38,800
there are workarounds to still execute

327
00:11:37,120 --> 00:11:41,519
that kind of court but it's best to

328
00:11:38,800 --> 00:11:44,719
avoid it if you can

329
00:11:41,519 --> 00:11:45,600
um so we shouldn't we should not do

330
00:11:44,720 --> 00:11:49,519
blocking io

331
00:11:45,600 --> 00:11:52,320
instead we should do non-blocking io

332
00:11:49,519 --> 00:11:53,279
by registering a callback in that event

333
00:11:52,320 --> 00:11:57,040
loop which will then

334
00:11:53,279 --> 00:11:59,439
execute um when a response arrives for

335
00:11:57,040 --> 00:11:59,439
instance

336
00:12:00,240 --> 00:12:04,560
now these coroutines are an abstraction

337
00:12:02,800 --> 00:12:06,399
on top of event loops it's pretty nice

338
00:12:04,560 --> 00:12:07,599
so that you don't have to think about

339
00:12:06,399 --> 00:12:09,120
all these callbacks

340
00:12:07,600 --> 00:12:11,920
because otherwise you would end up with

341
00:12:09,120 --> 00:12:15,120
a very ugly code

342
00:12:11,920 --> 00:12:17,120
so this is an example of what um

343
00:12:15,120 --> 00:12:18,480
it's really hypothetical because this

344
00:12:17,120 --> 00:12:21,040
library doesn't exist

345
00:12:18,480 --> 00:12:21,680
but this is what a database query would

346
00:12:21,040 --> 00:12:24,880
look like

347
00:12:21,680 --> 00:12:26,800
in async io code so we do a query

348
00:12:24,880 --> 00:12:28,000
we wait for the response because it's

349
00:12:26,800 --> 00:12:31,040
like a networking

350
00:12:28,000 --> 00:12:33,200
in between and when the response arrives

351
00:12:31,040 --> 00:12:34,880
that thing will be assigned to users at

352
00:12:33,200 --> 00:12:38,000
this point

353
00:12:34,880 --> 00:12:40,560
so the await keyword here means

354
00:12:38,000 --> 00:12:42,399
that we wait for the response to arrive

355
00:12:40,560 --> 00:12:44,638
we return to the event loop the event

356
00:12:42,399 --> 00:12:47,600
loop can then do other things in between

357
00:12:44,639 --> 00:12:49,760
and when the response arrives the event

358
00:12:47,600 --> 00:12:50,880
loop will resume the execution of this

359
00:12:49,760 --> 00:12:52,880
function

360
00:12:50,880 --> 00:12:54,639
so it's like kind of a state machine the

361
00:12:52,880 --> 00:12:57,360
await will suspend it

362
00:12:54,639 --> 00:12:58,880
and later on we resume it so we do

363
00:12:57,360 --> 00:13:01,760
actually two things

364
00:12:58,880 --> 00:13:02,240
with or wait we say we can go to another

365
00:13:01,760 --> 00:13:06,800
function

366
00:13:02,240 --> 00:13:09,120
but we're also waiting for the response

367
00:13:06,800 --> 00:13:10,319
we can also use the await to call

368
00:13:09,120 --> 00:13:11,920
another core team

369
00:13:10,320 --> 00:13:13,360
like for instance here we have a main

370
00:13:11,920 --> 00:13:14,399
function and we have a get users

371
00:13:13,360 --> 00:13:16,240
function

372
00:13:14,399 --> 00:13:18,240
and the main function is call and get

373
00:13:16,240 --> 00:13:20,880
users but get users

374
00:13:18,240 --> 00:13:21,760
is an async function which means that if

375
00:13:20,880 --> 00:13:23,439
you call it

376
00:13:21,760 --> 00:13:25,439
you don't get a response but actually

377
00:13:23,440 --> 00:13:28,079
you get a quarantine object

378
00:13:25,440 --> 00:13:30,639
and you have to use a weight in front of

379
00:13:28,079 --> 00:13:33,359
it in order to get the actual

380
00:13:30,639 --> 00:13:34,320
result so the await keyword is very

381
00:13:33,360 --> 00:13:36,399
often used

382
00:13:34,320 --> 00:13:38,480
to await the outcome of another core

383
00:13:36,399 --> 00:13:40,160
team

384
00:13:38,480 --> 00:13:41,600
um you see at the very bottom there is

385
00:13:40,160 --> 00:13:43,519
async io.run

386
00:13:41,600 --> 00:13:45,839
that is how you start an async io

387
00:13:43,519 --> 00:13:47,600
program you need to have an event loop

388
00:13:45,839 --> 00:13:50,480
that gets started and that will

389
00:13:47,600 --> 00:13:51,120
like operate these uh quarantines that's

390
00:13:50,480 --> 00:13:54,320
what the

391
00:13:51,120 --> 00:13:54,320
very last line is doing

392
00:13:54,560 --> 00:13:57,920
uh yeah so async and await they very

393
00:13:57,199 --> 00:14:01,439
often

394
00:13:57,920 --> 00:14:03,599
go together like you see in this example

395
00:14:01,440 --> 00:14:04,800
something else which is important to

396
00:14:03,600 --> 00:14:06,959
know is how to run

397
00:14:04,800 --> 00:14:08,880
core teams in parallel because that's

398
00:14:06,959 --> 00:14:09,518
the whole point of using async io you

399
00:14:08,880 --> 00:14:12,560
want to

400
00:14:09,519 --> 00:14:16,800
parallelize stuff and one way of doing

401
00:14:12,560 --> 00:14:16,800
it is by using async io don't get it

402
00:14:16,880 --> 00:14:22,720
is a way to wait for the outcome of

403
00:14:20,079 --> 00:14:25,199
multiple coroutines at the same time

404
00:14:22,720 --> 00:14:27,120
in this case we spawn to get users

405
00:14:25,199 --> 00:14:31,519
cortine twice

406
00:14:27,120 --> 00:14:33,839
and when both are done these um

407
00:14:31,519 --> 00:14:35,440
the execution of the main function will

408
00:14:33,839 --> 00:14:37,040
uh go on

409
00:14:35,440 --> 00:14:39,839
so actually you can think of async

410
00:14:37,040 --> 00:14:40,319
io.get as a join in threads you're

411
00:14:39,839 --> 00:14:43,680
joining

412
00:14:40,320 --> 00:14:44,000
multiple things together and actually i

413
00:14:43,680 --> 00:14:47,199
like

414
00:14:44,000 --> 00:14:48,720
this way because of doing concurrency i

415
00:14:47,199 --> 00:14:49,439
like this because you have some kind of

416
00:14:48,720 --> 00:14:50,880
symmetry

417
00:14:49,440 --> 00:14:52,720
you have a place where you start things

418
00:14:50,880 --> 00:14:55,920
in parallel and things come back

419
00:14:52,720 --> 00:14:56,480
nicely together that's what you actually

420
00:14:55,920 --> 00:14:58,160
want

421
00:14:56,480 --> 00:15:00,240
you don't want to fire something and

422
00:14:58,160 --> 00:15:01,600
then forget about it it's very important

423
00:15:00,240 --> 00:15:05,279
actually to do the join

424
00:15:01,600 --> 00:15:08,800
in order to get some kind of symmetry

425
00:15:05,279 --> 00:15:11,920
um if you cannot do that then you

426
00:15:08,800 --> 00:15:14,000
could actually do async.createtask that

427
00:15:11,920 --> 00:15:15,920
will spawn the core routine

428
00:15:14,000 --> 00:15:18,000
and execution in the main function still

429
00:15:15,920 --> 00:15:18,959
goes on but if later on you decide you

430
00:15:18,000 --> 00:15:21,360
need the response

431
00:15:18,959 --> 00:15:22,638
then you can still wait for the task and

432
00:15:21,360 --> 00:15:25,440
you could actually do

433
00:15:22,639 --> 00:15:26,480
users equals await task to capture the

434
00:15:25,440 --> 00:15:29,440
outcome of that

435
00:15:26,480 --> 00:15:30,720
quarantine but i think it's pretty

436
00:15:29,440 --> 00:15:33,360
important to actually

437
00:15:30,720 --> 00:15:34,399
not just spawn tasks and not wait for

438
00:15:33,360 --> 00:15:37,440
the response

439
00:15:34,399 --> 00:15:39,839
but instead really wait for the response

440
00:15:37,440 --> 00:15:42,160
because that way you can do proper

441
00:15:39,839 --> 00:15:43,920
exception handling if there is an

442
00:15:42,160 --> 00:15:46,719
exception raised in get users

443
00:15:43,920 --> 00:15:50,079
using try accept you can capture them

444
00:15:46,720 --> 00:15:54,320
around the await statement

445
00:15:50,079 --> 00:15:56,880
then there is also async with an async 4

446
00:15:54,320 --> 00:15:58,880
which are pretty nice so the web block

447
00:15:56,880 --> 00:16:01,519
you probably know as a context manager

448
00:15:58,880 --> 00:16:02,079
that's something a code that you execute

449
00:16:01,519 --> 00:16:04,399
before

450
00:16:02,079 --> 00:16:05,519
and after the block very typically used

451
00:16:04,399 --> 00:16:07,440
for

452
00:16:05,519 --> 00:16:09,040
establishing a connection and closing

453
00:16:07,440 --> 00:16:10,880
the connection or

454
00:16:09,040 --> 00:16:12,160
allocating resources and releasing

455
00:16:10,880 --> 00:16:14,320
resources

456
00:16:12,160 --> 00:16:15,439
so that's what a web block is doing

457
00:16:14,320 --> 00:16:18,800
async with

458
00:16:15,440 --> 00:16:19,600
is what you do if any of these two

459
00:16:18,800 --> 00:16:22,800
blocks

460
00:16:19,600 --> 00:16:24,000
the enter or the release involve async

461
00:16:22,800 --> 00:16:26,000
code

462
00:16:24,000 --> 00:16:28,639
and in this case that's the case

463
00:16:26,000 --> 00:16:30,880
establishing a connection

464
00:16:28,639 --> 00:16:32,639
has to be asynchronous because it takes

465
00:16:30,880 --> 00:16:33,199
some time to establish the connection

466
00:16:32,639 --> 00:16:35,120
and

467
00:16:33,199 --> 00:16:36,800
you need an async with in order to do

468
00:16:35,120 --> 00:16:39,199
that

469
00:16:36,800 --> 00:16:41,120
then async 4 is something you typically

470
00:16:39,199 --> 00:16:42,240
see when you're consuming asynchronous

471
00:16:41,120 --> 00:16:44,800
data stream

472
00:16:42,240 --> 00:16:46,399
like for instance you select the users

473
00:16:44,800 --> 00:16:49,839
from a database table

474
00:16:46,399 --> 00:16:50,480
the entries are all transmitted over the

475
00:16:49,839 --> 00:16:53,040
wire

476
00:16:50,480 --> 00:16:53,600
over the network and you receive them in

477
00:16:53,040 --> 00:16:56,319
chunks

478
00:16:53,600 --> 00:16:58,079
not all at once so you don't want to

479
00:16:56,320 --> 00:16:58,959
wait until the whole response arrives

480
00:16:58,079 --> 00:17:00,880
before you start

481
00:16:58,959 --> 00:17:02,959
processing but you want to start

482
00:17:00,880 --> 00:17:04,559
processing things as soon as possible as

483
00:17:02,959 --> 00:17:06,559
they arrive

484
00:17:04,559 --> 00:17:07,678
so that means that every iteration of

485
00:17:06,559 --> 00:17:09,599
the for loop

486
00:17:07,679 --> 00:17:12,079
involves possibly waiting for the

487
00:17:09,599 --> 00:17:14,319
network network response to arrive

488
00:17:12,079 --> 00:17:15,918
and so that needs to be asynchronous

489
00:17:14,319 --> 00:17:18,639
that's when you have an async

490
00:17:15,919 --> 00:17:21,280
4 and these two are typically things

491
00:17:18,640 --> 00:17:23,520
that you see

492
00:17:21,280 --> 00:17:26,079
that you have to use for many async io

493
00:17:23,520 --> 00:17:26,079
libraries

494
00:17:27,039 --> 00:17:31,120
then there are executors which is also

495
00:17:29,440 --> 00:17:33,200
something good to know about

496
00:17:31,120 --> 00:17:35,199
so this is something you use whenever

497
00:17:33,200 --> 00:17:38,160
you have to run traditional

498
00:17:35,200 --> 00:17:40,400
blocking code it could be either a

499
00:17:38,160 --> 00:17:43,840
situation where you have

500
00:17:40,400 --> 00:17:45,360
a blocking i o library like requests

501
00:17:43,840 --> 00:17:47,600
or it could be a situation where you

502
00:17:45,360 --> 00:17:51,360
have very cpu intensive code

503
00:17:47,600 --> 00:17:52,159
um in that case also you would block the

504
00:17:51,360 --> 00:17:53,760
event loop

505
00:17:52,160 --> 00:17:55,600
if you have something which is very

506
00:17:53,760 --> 00:17:56,320
computational expensive you could run it

507
00:17:55,600 --> 00:17:59,280
in a

508
00:17:56,320 --> 00:18:01,360
other thread and have the main thread

509
00:17:59,280 --> 00:18:03,760
the main event loop go on and respond to

510
00:18:01,360 --> 00:18:06,320
incoming connections

511
00:18:03,760 --> 00:18:07,280
so in this case the executor will run on

512
00:18:06,320 --> 00:18:10,240
another thread

513
00:18:07,280 --> 00:18:11,039
on another process and the await can

514
00:18:10,240 --> 00:18:13,919
still be used

515
00:18:11,039 --> 00:18:16,240
to wait for the outcome of that piece of

516
00:18:13,919 --> 00:18:16,240
code

517
00:18:18,080 --> 00:18:24,480
then one warning don't turn

518
00:18:21,520 --> 00:18:25,600
every call into an async call it's what

519
00:18:24,480 --> 00:18:28,400
people often

520
00:18:25,600 --> 00:18:28,959
get wrong when they start with async io

521
00:18:28,400 --> 00:18:31,200
because

522
00:18:28,960 --> 00:18:33,679
some people think that at some point

523
00:18:31,200 --> 00:18:35,360
every function will become async

524
00:18:33,679 --> 00:18:37,200
because at some point every function

525
00:18:35,360 --> 00:18:40,559
will involve doing io

526
00:18:37,200 --> 00:18:42,720
right and often that is the case but

527
00:18:40,559 --> 00:18:44,240
doing io doesn't mean that you have to

528
00:18:42,720 --> 00:18:46,240
wait for the i o

529
00:18:44,240 --> 00:18:47,760
for instance in the case of a logging

530
00:18:46,240 --> 00:18:49,679
server imagine that you're logging to

531
00:18:47,760 --> 00:18:53,039
remote server

532
00:18:49,679 --> 00:18:54,400
then um you don't have to wait for these

533
00:18:53,039 --> 00:18:56,320
logging messages actually to be

534
00:18:54,400 --> 00:18:57,760
transmitted you want the logging to

535
00:18:56,320 --> 00:19:00,080
happen in your server

536
00:18:57,760 --> 00:19:02,559
but you want your execution to go go on

537
00:19:00,080 --> 00:19:05,439
as soon as possible

538
00:19:02,559 --> 00:19:07,678
and so instead of using an awaits in

539
00:19:05,440 --> 00:19:09,600
front of your login calls

540
00:19:07,679 --> 00:19:11,520
is best to implement your logging

541
00:19:09,600 --> 00:19:14,639
framework in a way that

542
00:19:11,520 --> 00:19:15,360
you push all your logging messages into

543
00:19:14,640 --> 00:19:17,600
an async

544
00:19:15,360 --> 00:19:19,439
queue and somewhere else you have then a

545
00:19:17,600 --> 00:19:21,120
core team that consumes the queue and

546
00:19:19,440 --> 00:19:23,679
flushes the messages

547
00:19:21,120 --> 00:19:24,479
over the network and so that way your

548
00:19:23,679 --> 00:19:29,039
functions

549
00:19:24,480 --> 00:19:29,039
don't have to be async not necessarily

550
00:19:29,760 --> 00:19:33,600
um something else here which i think is

551
00:19:32,480 --> 00:19:37,200
important

552
00:19:33,600 --> 00:19:40,240
um we should try to separate

553
00:19:37,200 --> 00:19:42,160
the code that is doing io

554
00:19:40,240 --> 00:19:43,360
from the code that is doing

555
00:19:42,160 --> 00:19:45,840
computational stuff

556
00:19:43,360 --> 00:19:46,719
if that's possible for instance if you

557
00:19:45,840 --> 00:19:49,039
are

558
00:19:46,720 --> 00:19:52,480
doing a parsing library where you are

559
00:19:49,039 --> 00:19:52,480
parsing data that's completely

560
00:19:52,559 --> 00:19:56,160
that can be written completely

561
00:19:54,080 --> 00:19:58,639
independent from the i o layer

562
00:19:56,160 --> 00:19:59,679
and so if you can separate these things

563
00:19:58,640 --> 00:20:02,000
then you can have

564
00:19:59,679 --> 00:20:03,840
code that is completely synchronous and

565
00:20:02,000 --> 00:20:05,760
an asynchronous code around it that

566
00:20:03,840 --> 00:20:08,799
calls the synchronous code

567
00:20:05,760 --> 00:20:10,799
and that's totally fine so try to avoid

568
00:20:08,799 --> 00:20:14,000
ending up in a situation where every

569
00:20:10,799 --> 00:20:16,158
function becomes async

570
00:20:14,000 --> 00:20:17,600
this is next actual example i'm not

571
00:20:16,159 --> 00:20:19,600
going to say a lot about this because

572
00:20:17,600 --> 00:20:21,039
later today tom christie will talk about

573
00:20:19,600 --> 00:20:24,000
httpx

574
00:20:21,039 --> 00:20:25,440
which is an async io library for doing

575
00:20:24,000 --> 00:20:27,200
http calls

576
00:20:25,440 --> 00:20:30,080
so if you're interested in that then

577
00:20:27,200 --> 00:20:32,480
stay for a few more talks then

578
00:20:30,080 --> 00:20:33,280
we will discuss this but you see that

579
00:20:32,480 --> 00:20:34,960
here as well

580
00:20:33,280 --> 00:20:36,639
we have the async web block for

581
00:20:34,960 --> 00:20:38,640
establishing the connection

582
00:20:36,640 --> 00:20:39,919
and then the await to wait for the

583
00:20:38,640 --> 00:20:42,240
response

584
00:20:39,919 --> 00:20:45,600
is something that you very often see

585
00:20:42,240 --> 00:20:45,600
with these async libraries

586
00:20:45,679 --> 00:20:49,679
then something else which is good to

587
00:20:47,280 --> 00:20:51,360
know is that if you're experimenting

588
00:20:49,679 --> 00:20:54,880
with async io

589
00:20:51,360 --> 00:20:57,600
um you cannot oh

590
00:20:54,880 --> 00:20:58,960
you cannot uh just use an await keyword

591
00:20:57,600 --> 00:21:00,639
in your interactive shell

592
00:20:58,960 --> 00:21:03,520
if you try that that would be a syntax

593
00:21:00,640 --> 00:21:06,080
error because you can only use an await

594
00:21:03,520 --> 00:21:08,559
in an asynchronous function and it's

595
00:21:06,080 --> 00:21:09,280
very cumbersome for trying out async io

596
00:21:08,559 --> 00:21:11,520
code

597
00:21:09,280 --> 00:21:13,918
but there is the solution ipython does

598
00:21:11,520 --> 00:21:13,918
support

599
00:21:14,000 --> 00:21:18,559
async io integration which means that in

600
00:21:16,159 --> 00:21:20,960
ipad and you can use the await keyword

601
00:21:18,559 --> 00:21:22,240
top level and then ipython will ensure

602
00:21:20,960 --> 00:21:24,080
that the event loops uh

603
00:21:22,240 --> 00:21:25,280
runs and so it's very great for

604
00:21:24,080 --> 00:21:27,918
experimenting

605
00:21:25,280 --> 00:21:29,200
or you can do python dash and async io

606
00:21:27,919 --> 00:21:30,640
it's also very

607
00:21:29,200 --> 00:21:33,840
it's basically the same thing but then

608
00:21:30,640 --> 00:21:36,720
with the normal python shell

609
00:21:33,840 --> 00:21:38,559
so to conclude async io it's a pretty

610
00:21:36,720 --> 00:21:41,600
great concurrency pattern

611
00:21:38,559 --> 00:21:42,158
for i o heavy applications not so much

612
00:21:41,600 --> 00:21:43,918
for

613
00:21:42,159 --> 00:21:45,360
cpu intensive applications but if you're

614
00:21:43,919 --> 00:21:46,799
dealing with a lot of i o and many

615
00:21:45,360 --> 00:21:49,918
connections then

616
00:21:46,799 --> 00:21:50,639
async io is great it's not the easiest

617
00:21:49,919 --> 00:21:53,600
to begin with

618
00:21:50,640 --> 00:21:54,960
honestly uh but very often when things

619
00:21:53,600 --> 00:21:57,199
become more complex

620
00:21:54,960 --> 00:21:59,840
it's it's it is much easier than

621
00:21:57,200 --> 00:22:02,400
training to get right

622
00:21:59,840 --> 00:22:03,840
um and then the important pitfalls i

623
00:22:02,400 --> 00:22:06,960
would like you to remember

624
00:22:03,840 --> 00:22:09,678
try not to mix um

625
00:22:06,960 --> 00:22:11,360
async io code with blocking io unless

626
00:22:09,679 --> 00:22:13,600
you use an acceptor

627
00:22:11,360 --> 00:22:15,918
and try not to turn every call into an

628
00:22:13,600 --> 00:22:17,918
async call

629
00:22:15,919 --> 00:22:19,120
so that's what i have i don't know

630
00:22:17,919 --> 00:22:21,679
whether any

631
00:22:19,120 --> 00:22:24,158
questions you can find me on twitter on

632
00:22:21,679 --> 00:22:24,159
github

633
00:22:25,280 --> 00:22:30,320
sorry yeah

634
00:22:31,919 --> 00:22:35,919
this one getter can take as many

635
00:22:34,080 --> 00:22:38,639
functions as you want

636
00:22:35,919 --> 00:22:39,520
it takes them as positional arguments

637
00:22:38,640 --> 00:22:43,039
you can

638
00:22:39,520 --> 00:22:43,039
pass as many core teams as you want

639
00:22:45,320 --> 00:22:55,840
[Applause]

640
00:22:52,840 --> 00:22:55,840
together

641
00:22:58,159 --> 00:23:00,240
you

