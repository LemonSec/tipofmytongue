1
00:00:06,640 --> 00:00:08,879
okay

2
00:00:09,440 --> 00:00:11,599
hi

3
00:00:14,240 --> 00:00:18,160
so uh high-speed traffic encryption on

4
00:00:16,840 --> 00:00:22,240
x864

5
00:00:18,160 --> 00:00:24,640
with snap so hi i'm max

6
00:00:22,240 --> 00:00:27,680
i'm an open source hacker and i've been

7
00:00:24,640 --> 00:00:29,279
working on the snap project since 2014.

8
00:00:27,680 --> 00:00:31,279
some of you may have heard of it i'm

9
00:00:29,279 --> 00:00:33,840
going to go a little bit into it

10
00:00:31,279 --> 00:00:35,200
later in this talk i'm also doing

11
00:00:33,840 --> 00:00:36,000
consulting on software networking and

12
00:00:35,200 --> 00:00:38,160
user space

13
00:00:36,000 --> 00:00:40,239
protocols software optimization et

14
00:00:38,160 --> 00:00:43,040
cetera

15
00:00:40,239 --> 00:00:45,839
so for the last couple of years i've

16
00:00:43,040 --> 00:00:47,440
been working on a project called vita

17
00:00:45,840 --> 00:00:49,440
vita is a high performance side to side

18
00:00:47,440 --> 00:00:52,480
vpn gateway

19
00:00:49,440 --> 00:00:54,480
it's fully open source and attackable

20
00:00:52,480 --> 00:00:56,160
by hackable here i mean that it has a

21
00:00:54,480 --> 00:00:58,398
very small and hopefully easy to

22
00:00:56,160 --> 00:01:01,358
understand code base

23
00:00:58,399 --> 00:01:02,079
and it runs on generic x86 64 server

24
00:01:01,359 --> 00:01:04,719
cpus

25
00:01:02,079 --> 00:01:04,718
and linux

26
00:01:06,560 --> 00:01:11,040
so vita is based on snap snap is a

27
00:01:09,680 --> 00:01:13,600
toolkit for writing

28
00:01:11,040 --> 00:01:15,119
fast networking applications in user

29
00:01:13,600 --> 00:01:16,798
space

30
00:01:15,119 --> 00:01:18,240
this mode of operation is also referred

31
00:01:16,799 --> 00:01:20,560
to as kernel bypass mode you've all

32
00:01:18,240 --> 00:01:22,399
heard of it i guess

33
00:01:20,560 --> 00:01:25,119
but basically it means the data path

34
00:01:22,400 --> 00:01:29,439
completely avoids the linux kernel

35
00:01:25,119 --> 00:01:31,680
and snap applications including beta

36
00:01:29,439 --> 00:01:33,600
and this is the important bit snap

37
00:01:31,680 --> 00:01:35,119
itself even

38
00:01:33,600 --> 00:01:38,079
uh written in a high-level programming

39
00:01:35,119 --> 00:01:39,920
language called lua

40
00:01:38,079 --> 00:01:43,600
and this is possible thanks to a super

41
00:01:39,920 --> 00:01:46,240
fast implementation of lua called luagit

42
00:01:43,600 --> 00:01:46,960
um which we have a fork off called

43
00:01:46,240 --> 00:01:48,240
repligid

44
00:01:46,960 --> 00:01:50,000
which i'm going to have a talk about

45
00:01:48,240 --> 00:01:52,079
tomorrow in the minimalistic language of

46
00:01:50,000 --> 00:01:54,240
staff room in case you're interested

47
00:01:52,079 --> 00:01:55,839
which basically thought of luigi that

48
00:01:54,240 --> 00:01:57,520
targets heavy duty serve applications

49
00:01:55,840 --> 00:01:59,840
specifically

50
00:01:57,520 --> 00:02:01,360
and by the way vito was funded through

51
00:01:59,840 --> 00:02:03,600
the internet foundation

52
00:02:01,360 --> 00:02:04,960
they are really really cool and i

53
00:02:03,600 --> 00:02:06,640
suggest you check them out if you

54
00:02:04,960 --> 00:02:09,758
are in need for funding for any open

55
00:02:06,640 --> 00:02:11,360
source project

56
00:02:09,758 --> 00:02:13,679
so i guess let me start by showing you

57
00:02:11,360 --> 00:02:15,520
some typical snap code

58
00:02:13,680 --> 00:02:17,440
so snap programs are divided into

59
00:02:15,520 --> 00:02:19,520
modules that we call apps

60
00:02:17,440 --> 00:02:20,959
which have a number of input and output

61
00:02:19,520 --> 00:02:23,680
links

62
00:02:20,959 --> 00:02:24,640
and they basically process packets in a

63
00:02:23,680 --> 00:02:26,720
loop

64
00:02:24,640 --> 00:02:28,319
so this example shows how to read

65
00:02:26,720 --> 00:02:29,359
packets while the input link is not

66
00:02:28,319 --> 00:02:30,879
empty

67
00:02:29,360 --> 00:02:32,800
uh check if their time to live has

68
00:02:30,879 --> 00:02:34,160
expired and

69
00:02:32,800 --> 00:02:36,080
unless they have if they have not

70
00:02:34,160 --> 00:02:37,120
expired if the time flip has not expired

71
00:02:36,080 --> 00:02:40,160
then we forward the package to the

72
00:02:37,120 --> 00:02:42,080
output link if the ttl has expired then

73
00:02:40,160 --> 00:02:43,280
we will transmit the packet onto the

74
00:02:42,080 --> 00:02:45,599
time exceeded link

75
00:02:43,280 --> 00:02:46,720
where it will be received by another app

76
00:02:45,599 --> 00:02:51,839
that would handle

77
00:02:46,720 --> 00:02:51,840
icmp for example

78
00:02:52,480 --> 00:02:56,000
so what does high performance mean in

79
00:02:53,920 --> 00:02:57,760
this context

80
00:02:56,000 --> 00:02:59,680
at the moment vita terminates 3 million

81
00:02:57,760 --> 00:03:03,440
packets per second

82
00:02:59,680 --> 00:03:04,879
on a single cpu core that translates to

83
00:03:03,440 --> 00:03:07,920
about five gigabits of

84
00:03:04,879 --> 00:03:09,440
imix traffic per core and these numbers

85
00:03:07,920 --> 00:03:11,359
are full duplex so this is actually

86
00:03:09,440 --> 00:03:12,480
six million packets being processed per

87
00:03:11,360 --> 00:03:14,159
second on a core

88
00:03:12,480 --> 00:03:16,720
three million being encapsulated and

89
00:03:14,159 --> 00:03:18,399
three million being decapsulated

90
00:03:16,720 --> 00:03:20,400
and the median term performance goal of

91
00:03:18,400 --> 00:03:24,239
vita is to be able to do

92
00:03:20,400 --> 00:03:25,760
100 g uh on a generic x86 server that

93
00:03:24,239 --> 00:03:27,440
you can buy off the shelf

94
00:03:25,760 --> 00:03:29,359
so here i'm betting on increasing core

95
00:03:27,440 --> 00:03:30,000
count sizes obviously and i'm thinking

96
00:03:29,360 --> 00:03:32,720
that

97
00:03:30,000 --> 00:03:35,360
maybe a zen 2 or 64 cores might just be

98
00:03:32,720 --> 00:03:35,359
able to do it

99
00:03:41,519 --> 00:03:47,200
so how does vita do it in snapland

100
00:03:45,440 --> 00:03:49,359
we like to write software that is both

101
00:03:47,200 --> 00:03:50,958
fast and simple

102
00:03:49,360 --> 00:03:53,200
so we think that simple designs

103
00:03:50,959 --> 00:03:55,360
translate to efficient designs

104
00:03:53,200 --> 00:03:57,920
and we don't think that fast programs

105
00:03:55,360 --> 00:03:59,439
need to be complex

106
00:03:57,920 --> 00:04:01,679
we also like to avoid vanderloken

107
00:03:59,439 --> 00:04:03,439
wherever possible so for vita this means

108
00:04:01,680 --> 00:04:05,439
we avoid any extensions

109
00:04:03,439 --> 00:04:07,120
such as intel quick assist or

110
00:04:05,439 --> 00:04:10,200
proprietary crypto cards

111
00:04:07,120 --> 00:04:12,959
to get the performance and rely on um

112
00:04:10,200 --> 00:04:14,399
x8664 and its commonly supported

113
00:04:12,959 --> 00:04:15,840
architecture extensions commonly

114
00:04:14,400 --> 00:04:17,680
supported here means that more than one

115
00:04:15,840 --> 00:04:20,478
vendor produces cpus that

116
00:04:17,680 --> 00:04:20,478
can do that stuff

117
00:04:21,839 --> 00:04:28,080
right so vita's most obvious cpu hawk is

118
00:04:25,919 --> 00:04:29,359
obviously encrypting packets and

119
00:04:28,080 --> 00:04:32,159
decrypting them

120
00:04:29,360 --> 00:04:34,960
basically crunching numbers and for that

121
00:04:32,160 --> 00:04:38,720
we rely on two x86 extensions

122
00:04:34,960 --> 00:04:41,359
aesni and avx2

123
00:04:38,720 --> 00:04:43,520
aes and i provide cpu instructions to do

124
00:04:41,360 --> 00:04:46,639
a round of aes basically

125
00:04:43,520 --> 00:04:48,400
and avx is a cmd extension

126
00:04:46,639 --> 00:04:50,000
you've probably heard of it simply here

127
00:04:48,400 --> 00:04:50,719
stands for single instruction multiple

128
00:04:50,000 --> 00:04:54,080
data

129
00:04:50,720 --> 00:04:56,160
two talks ago if you've heard about that

130
00:04:54,080 --> 00:04:58,000
and yeah this this code snippet shows

131
00:04:56,160 --> 00:04:59,759
that shows how we use a dynamic

132
00:04:58,000 --> 00:05:02,240
assembler called dnasem which

133
00:04:59,759 --> 00:05:03,199
ships with the widget uh to implement

134
00:05:02,240 --> 00:05:07,120
aes jcm

135
00:05:03,199 --> 00:05:07,120
using the mentioned instruction set

136
00:05:08,840 --> 00:05:12,400
extensions

137
00:05:10,560 --> 00:05:13,759
um for route lookups using longest

138
00:05:12,400 --> 00:05:17,919
prefix match

139
00:05:13,759 --> 00:05:20,400
we use optimized pop-tar implementation

140
00:05:17,919 --> 00:05:22,400
again here we used in asm to generate

141
00:05:20,400 --> 00:05:23,359
the lookup routine

142
00:05:22,400 --> 00:05:24,479
but everything else about this

143
00:05:23,360 --> 00:05:25,759
implementation is actually written in

144
00:05:24,479 --> 00:05:27,520
high-level lure

145
00:05:25,759 --> 00:05:28,639
so we have a high-level new

146
00:05:27,520 --> 00:05:30,320
implementation of all the like

147
00:05:28,639 --> 00:05:31,680
surrounding code and then the

148
00:05:30,320 --> 00:05:34,960
lookup routine that actually needs to be

149
00:05:31,680 --> 00:05:36,720
fast just generated at runtime

150
00:05:34,960 --> 00:05:38,000
and the reason the nsm is cool for this

151
00:05:36,720 --> 00:05:39,520
sort of stuff is that

152
00:05:38,000 --> 00:05:41,120
it lets you generate code based on

153
00:05:39,520 --> 00:05:43,280
algorithm parameters and

154
00:05:41,120 --> 00:05:46,240
even cpu features at runtime so we kind

155
00:05:43,280 --> 00:05:48,719
of like say oh you want to use

156
00:05:46,240 --> 00:05:49,680
this key size for you lpm lookup we just

157
00:05:48,720 --> 00:05:52,320
gonna generate

158
00:05:49,680 --> 00:05:53,680
an assembly routine to the lookup really

159
00:05:52,320 --> 00:05:55,440
fast

160
00:05:53,680 --> 00:05:56,960
and both the poptroy and asgcm

161
00:05:55,440 --> 00:05:57,600
implementations are upstream for you to

162
00:05:56,960 --> 00:05:59,919
reuse

163
00:05:57,600 --> 00:06:01,039
so with snap we maintain a library of

164
00:05:59,919 --> 00:06:04,799
all this stuff

165
00:06:01,039 --> 00:06:04,800
which you can basically plug and play

166
00:06:04,840 --> 00:06:08,638
with

167
00:06:06,160 --> 00:06:09,759
right so we also wrote a simple and fast

168
00:06:08,639 --> 00:06:12,880
ipsec esp

169
00:06:09,759 --> 00:06:14,319
implementation in lua um esp here stands

170
00:06:12,880 --> 00:06:15,840
for encapsulating security payload

171
00:06:14,319 --> 00:06:19,280
that's kind of like the standard

172
00:06:15,840 --> 00:06:21,359
ipsec encapsulation standard thingy

173
00:06:19,280 --> 00:06:23,119
um here i'm showing how to represent

174
00:06:21,360 --> 00:06:24,880
packet headers as c-structs

175
00:06:23,120 --> 00:06:26,240
in lua code using the foreign function

176
00:06:24,880 --> 00:06:28,880
interface

177
00:06:26,240 --> 00:06:31,039
and in lua you can access these if they

178
00:06:28,880 --> 00:06:35,840
were like native lua objects

179
00:06:31,039 --> 00:06:35,840
meaning object dot field member

180
00:06:39,520 --> 00:06:43,520
yes right and then another thing that i

181
00:06:42,400 --> 00:06:45,599
thought was cool is that

182
00:06:43,520 --> 00:06:46,719
we have this compiler or there is this

183
00:06:45,600 --> 00:06:49,120
compiler for

184
00:06:46,720 --> 00:06:50,080
pcap filter expressions that's the tcp

185
00:06:49,120 --> 00:06:53,039
dump

186
00:06:50,080 --> 00:06:54,318
language for matching stuff and there's

187
00:06:53,039 --> 00:06:55,759
an implementation of that language

188
00:06:54,319 --> 00:06:58,479
called pf lure

189
00:06:55,759 --> 00:06:59,680
developed by galia which is included in

190
00:06:58,479 --> 00:07:01,919
snap

191
00:06:59,680 --> 00:07:03,280
and it also extends the language the pf

192
00:07:01,919 --> 00:07:06,560
filter language

193
00:07:03,280 --> 00:07:09,840
um to be able to express um

194
00:07:06,560 --> 00:07:11,280
match action pipelines and this is

195
00:07:09,840 --> 00:07:12,719
basically another example of code

196
00:07:11,280 --> 00:07:14,479
generation

197
00:07:12,720 --> 00:07:16,000
at runtime that's really prevalent in

198
00:07:14,479 --> 00:07:19,039
snap where we

199
00:07:16,000 --> 00:07:22,000
have some dsl and we compile that to

200
00:07:19,039 --> 00:07:24,159
either native code or for example i've

201
00:07:22,000 --> 00:07:26,000
recently written a ebpf backend for that

202
00:07:24,160 --> 00:07:30,000
to be able to

203
00:07:26,000 --> 00:07:33,199
have bpf filters running as xcp programs

204
00:07:30,000 --> 00:07:34,880
yeah and either way

205
00:07:33,199 --> 00:07:36,880
i feel like this is a really robust way

206
00:07:34,880 --> 00:07:38,880
of writing the sort of program

207
00:07:36,880 --> 00:07:40,560
first of all you don't you don't do the

208
00:07:38,880 --> 00:07:43,680
mistakes when doing like little bit

209
00:07:40,560 --> 00:07:46,000
poking on packets and second of all

210
00:07:43,680 --> 00:07:47,680
there's really i mean this is already

211
00:07:46,000 --> 00:07:50,800
kind of like efficient

212
00:07:47,680 --> 00:07:52,479
being compiled to to specialized

213
00:07:50,800 --> 00:07:53,840
code just for this instruction and not

214
00:07:52,479 --> 00:07:55,039
like general being a general purpose

215
00:07:53,840 --> 00:07:57,440
language but there's still

216
00:07:55,039 --> 00:07:59,440
a lot of optimization potential

217
00:07:57,440 --> 00:08:01,680
completely unclaimed in this

218
00:07:59,440 --> 00:08:03,360
for example we could compile this

219
00:08:01,680 --> 00:08:06,240
expression using cmd

220
00:08:03,360 --> 00:08:07,759
or whatever really and that's stuff

221
00:08:06,240 --> 00:08:08,880
that's currently not done but

222
00:08:07,759 --> 00:08:11,680
very much feasible

223
00:08:08,880 --> 00:08:14,879
[Applause]

224
00:08:11,680 --> 00:08:14,879
what's my time thing

225
00:08:17,680 --> 00:08:20,160
all right

226
00:08:22,960 --> 00:08:28,560
right so the way security associations

227
00:08:26,639 --> 00:08:31,280
and that's flows basically

228
00:08:28,560 --> 00:08:33,599
work in esp presents some constraints

229
00:08:31,280 --> 00:08:35,519
with regard to parallelization

230
00:08:33,599 --> 00:08:37,360
for security reasons every packet

231
00:08:35,519 --> 00:08:38,399
transmitted over a security association

232
00:08:37,360 --> 00:08:41,279
has a unique

233
00:08:38,399 --> 00:08:41,919
monotonically increasing sequence number

234
00:08:41,279 --> 00:08:44,080
so

235
00:08:41,919 --> 00:08:45,680
if we want to distribute the work of

236
00:08:44,080 --> 00:08:47,200
processing one security association

237
00:08:45,680 --> 00:08:48,319
that's like one flow across more than

238
00:08:47,200 --> 00:08:50,959
one core

239
00:08:48,320 --> 00:08:52,640
we run into a problem where we end up

240
00:08:50,959 --> 00:08:53,199
having to synchronize them in one way or

241
00:08:52,640 --> 00:08:57,279
another

242
00:08:53,200 --> 00:08:57,279
in order to not reorder packets

243
00:08:57,680 --> 00:09:01,279
and this is a known issue in

244
00:08:58,720 --> 00:09:01,760
implementing ipsec and there are papers

245
00:09:01,279 --> 00:09:04,640
written

246
00:09:01,760 --> 00:09:04,640
on this topic really

247
00:09:05,279 --> 00:09:08,880
we actually really want to use multiple

248
00:09:07,440 --> 00:09:10,320
cores however

249
00:09:08,880 --> 00:09:12,320
because doing 3 million packets per

250
00:09:10,320 --> 00:09:13,680
second on one core is nice but really

251
00:09:12,320 --> 00:09:15,040
only makes sense if you can scale that

252
00:09:13,680 --> 00:09:18,319
in some way

253
00:09:15,040 --> 00:09:19,279
and for vita we decided to sidestep that

254
00:09:18,320 --> 00:09:21,360
issue

255
00:09:19,279 --> 00:09:23,279
rather completely by imitating a scaled

256
00:09:21,360 --> 00:09:25,519
architecture internally that is

257
00:09:23,279 --> 00:09:27,439
we prep we pretend that every core is

258
00:09:25,519 --> 00:09:29,440
its own node with its own address

259
00:09:27,440 --> 00:09:31,120
and kind of like do the network scaling

260
00:09:29,440 --> 00:09:33,680
as a network engineer might do it

261
00:09:31,120 --> 00:09:34,640
i imagine um in the program and don't

262
00:09:33,680 --> 00:09:38,560
try

263
00:09:34,640 --> 00:09:40,319
funky funky intel cpu core

264
00:09:38,560 --> 00:09:42,399
synchronization tricks which always end

265
00:09:40,320 --> 00:09:44,320
up being complex and slow

266
00:09:42,399 --> 00:09:45,600
so at this point we move the problem

267
00:09:44,320 --> 00:09:47,279
into the network layer

268
00:09:45,600 --> 00:09:48,800
and can let two common network device

269
00:09:47,279 --> 00:09:51,600
features take care of it

270
00:09:48,800 --> 00:09:53,040
in hardware the first of that is like

271
00:09:51,600 --> 00:09:54,560
receive site scaling which i guess is

272
00:09:53,040 --> 00:09:57,760
well known here

273
00:09:54,560 --> 00:09:59,599
which lets us distribute flows received

274
00:09:57,760 --> 00:10:01,439
on the private interface

275
00:09:59,600 --> 00:10:02,880
onto separate security associations for

276
00:10:01,440 --> 00:10:04,560
each core

277
00:10:02,880 --> 00:10:06,720
and the other one is vmdq which is

278
00:10:04,560 --> 00:10:08,800
originally a virtualization extension

279
00:10:06,720 --> 00:10:10,560
which lets us aggregate the separate

280
00:10:08,800 --> 00:10:12,079
security associations reefed on received

281
00:10:10,560 --> 00:10:14,079
on the public interface

282
00:10:12,079 --> 00:10:15,359
before forwarding them to the respective

283
00:10:14,079 --> 00:10:18,399
core

284
00:10:15,360 --> 00:10:19,519
and on the next slide yeah there's

285
00:10:18,399 --> 00:10:22,079
a high level overview of this

286
00:10:19,519 --> 00:10:22,079
architecture

287
00:10:22,320 --> 00:10:27,040
there are two queues here q1 and q2

288
00:10:24,720 --> 00:10:27,920
which run on separate cpu cores

289
00:10:27,040 --> 00:10:29,920
on the left you have the private

290
00:10:27,920 --> 00:10:31,120
interface running in rss mode it has one

291
00:10:29,920 --> 00:10:34,240
address

292
00:10:31,120 --> 00:10:36,560
it splits the flows onto the cpu course

293
00:10:34,240 --> 00:10:38,399
and onset with separate queues and on

294
00:10:36,560 --> 00:10:41,439
the right we have the public interface

295
00:10:38,399 --> 00:10:45,440
where each of the cores slash queues has

296
00:10:41,440 --> 00:10:48,240
a separate public address and

297
00:10:45,440 --> 00:10:49,360
this means that each queue can then

298
00:10:48,240 --> 00:10:51,760
negotiate

299
00:10:49,360 --> 00:10:53,279
security associations independently and

300
00:10:51,760 --> 00:10:53,680
process and even chunk of the traffic

301
00:10:53,279 --> 00:10:56,720
without

302
00:10:53,680 --> 00:10:58,839
any synchronization with other cues

303
00:10:56,720 --> 00:11:00,959
so we just don't have that problem

304
00:10:58,839 --> 00:11:03,440
anymore

305
00:11:00,959 --> 00:11:03,439
all right

306
00:11:10,480 --> 00:11:16,880
so on drivers the snap way is to write

307
00:11:14,000 --> 00:11:19,600
simple network card drivers in lua

308
00:11:16,880 --> 00:11:20,720
even if windows do not always make that

309
00:11:19,600 --> 00:11:23,120
easy

310
00:11:20,720 --> 00:11:23,839
uh luke gory had a talk on the subject i

311
00:11:23,120 --> 00:11:26,720
think

312
00:11:23,839 --> 00:11:28,160
one or two fosters ago and i hear that

313
00:11:26,720 --> 00:11:31,200
nowadays he's soldering a network

314
00:11:28,160 --> 00:11:31,199
interface card himself

315
00:11:31,360 --> 00:11:36,160
and for me i can say that recently i've

316
00:11:33,440 --> 00:11:37,040
worked on xdp and intel avf drivers for

317
00:11:36,160 --> 00:11:39,839
snap

318
00:11:37,040 --> 00:11:39,839
and hence vita

319
00:11:41,600 --> 00:11:49,360
the immediate goal of avf and

320
00:11:45,760 --> 00:11:52,880
more more more prominently xtp

321
00:11:49,360 --> 00:11:53,680
is to make beta easily deployable in the

322
00:11:52,880 --> 00:11:55,200
cloud

323
00:11:53,680 --> 00:11:58,399
so the idea is that if we could have

324
00:11:55,200 --> 00:12:00,079
some very common prevalent interface

325
00:11:58,399 --> 00:12:01,519
that we can rely on to be available in

326
00:12:00,079 --> 00:12:04,319
the cloud then we could easily deploy

327
00:12:01,519 --> 00:12:06,399
snap applications there

328
00:12:04,320 --> 00:12:08,320
on xdp i can report that the

329
00:12:06,399 --> 00:12:11,519
initialization sequence

330
00:12:08,320 --> 00:12:14,000
is a bit heavy for my taste personally

331
00:12:11,519 --> 00:12:16,160
like to me it's easier to initialize a

332
00:12:14,000 --> 00:12:18,959
reasonable hardware interface of a nick

333
00:12:16,160 --> 00:12:19,760
than xtp um but overall it was a fun

334
00:12:18,959 --> 00:12:21,518
hack

335
00:12:19,760 --> 00:12:24,480
and a good reason to read current source

336
00:12:21,519 --> 00:12:26,560
code as any if you ask me i hit some

337
00:12:24,480 --> 00:12:29,279
limitations with xtp

338
00:12:26,560 --> 00:12:31,359
which have mostly to do with conflicting

339
00:12:29,279 --> 00:12:32,000
memory allocation models between xdp and

340
00:12:31,360 --> 00:12:33,760
snap

341
00:12:32,000 --> 00:12:35,360
however it seems that working with

342
00:12:33,760 --> 00:12:37,040
kernel upstream

343
00:12:35,360 --> 00:12:38,399
on these issues looked promising and at

344
00:12:37,040 --> 00:12:39,360
that point i wanted to say kudos to

345
00:12:38,399 --> 00:12:40,800
beyond turple

346
00:12:39,360 --> 00:12:42,720
for helping out with that that was

347
00:12:40,800 --> 00:12:43,920
pretty great

348
00:12:42,720 --> 00:12:46,399
and if you're interested in a topic i

349
00:12:43,920 --> 00:12:50,319
have a blog post on the whole

350
00:12:46,399 --> 00:12:55,839
how to do xdp without

351
00:12:50,320 --> 00:12:59,440
lip bpf you can check that out

352
00:12:55,839 --> 00:12:59,440
all right it's five minutes let me see

353
00:13:00,079 --> 00:13:04,479
all right gonna right so there's the

354
00:13:02,800 --> 00:13:06,319
issue of authenticated key exchange as

355
00:13:04,480 --> 00:13:09,040
you might have guessed

356
00:13:06,320 --> 00:13:10,959
um we did something else there as well

357
00:13:09,040 --> 00:13:13,439
since we didn't want to do ike

358
00:13:10,959 --> 00:13:14,239
um authenticate key exchange is kind of

359
00:13:13,440 --> 00:13:16,639
like the tricky bit

360
00:13:14,240 --> 00:13:18,160
of the of the whole thing um you want to

361
00:13:16,639 --> 00:13:20,560
cycle security associations often

362
00:13:18,160 --> 00:13:22,560
without losing packets

363
00:13:20,560 --> 00:13:24,000
you want to cycle that often to be able

364
00:13:22,560 --> 00:13:26,959
to provide a

365
00:13:24,000 --> 00:13:28,240
strong forward secrecy and while this is

366
00:13:26,959 --> 00:13:30,560
kind of like a low throughput part of

367
00:13:28,240 --> 00:13:32,320
the system is quite complex and by far

368
00:13:30,560 --> 00:13:35,359
provides the biggest attack surface you

369
00:13:32,320 --> 00:13:37,279
can you can find

370
00:13:35,360 --> 00:13:39,920
yeah i mean if you if you want to get a

371
00:13:37,279 --> 00:13:43,360
feeling for that check out the ike

372
00:13:39,920 --> 00:13:43,360
lfc it's huge

373
00:13:45,120 --> 00:13:48,800
um so i ended up with a simple

374
00:13:46,720 --> 00:13:50,160
pre-shared key based protocol based on

375
00:13:48,800 --> 00:13:52,399
the noise protocol

376
00:13:50,160 --> 00:13:54,719
framework which i can really recommend

377
00:13:52,399 --> 00:13:56,639
that's something quite modern and

378
00:13:54,720 --> 00:13:58,560
quite clean if you have a need of some

379
00:13:56,639 --> 00:14:00,639
cryptographic key exchangey

380
00:13:58,560 --> 00:14:02,160
tls like thingies you should i think

381
00:14:00,639 --> 00:14:04,160
look at them they

382
00:14:02,160 --> 00:14:05,920
have a really good like community where

383
00:14:04,160 --> 00:14:07,439
you can figure out how to do this in a

384
00:14:05,920 --> 00:14:09,680
modern way

385
00:14:07,440 --> 00:14:11,760
um and yeah for that we use a minimal

386
00:14:09,680 --> 00:14:14,160
set of modern cryptographic primitives

387
00:14:11,760 --> 00:14:15,360
uh our dna is m-based aes jstm

388
00:14:14,160 --> 00:14:17,880
implementation

389
00:14:15,360 --> 00:14:20,240
the send e2x implementation of

390
00:14:17,880 --> 00:14:21,040
curve25519 which is written in assembler

391
00:14:20,240 --> 00:14:23,279
i think

392
00:14:21,040 --> 00:14:25,760
and the blake hash reference

393
00:14:23,279 --> 00:14:27,199
implementation on you

394
00:14:25,760 --> 00:14:29,040
the black hash reference information

395
00:14:27,199 --> 00:14:31,839
which is written in c

396
00:14:29,040 --> 00:14:32,880
um yeah and alternatively i plan to

397
00:14:31,839 --> 00:14:35,680
support

398
00:14:32,880 --> 00:14:36,800
full ik version 2. switch engineer

399
00:14:35,680 --> 00:14:39,760
alexander gal

400
00:14:36,800 --> 00:14:42,240
has developed a strong swan plug-in to

401
00:14:39,760 --> 00:14:44,160
provide interoperability with snaps so

402
00:14:42,240 --> 00:14:45,519
basically you could use strong swan if

403
00:14:44,160 --> 00:14:48,480
you really want to use ak

404
00:14:45,519 --> 00:14:51,040
ike and we would kind of like have a

405
00:14:48,480 --> 00:14:52,639
plug-in for strong swan to be able to

406
00:14:51,040 --> 00:14:55,040
consume the security associations

407
00:14:52,639 --> 00:14:57,839
negotiated by it

408
00:14:55,040 --> 00:15:00,480
right um and i guess lastly snap comes

409
00:14:57,839 --> 00:15:02,639
with a fairly complete yang library

410
00:15:00,480 --> 00:15:03,680
um vita manages configuration and

411
00:15:02,639 --> 00:15:06,399
runtime state

412
00:15:03,680 --> 00:15:07,279
using a custom yang model that means you

413
00:15:06,399 --> 00:15:12,240
can

414
00:15:07,279 --> 00:15:14,079
query and update configuration

415
00:15:12,240 --> 00:15:15,920
and also the runtime state using yang

416
00:15:14,079 --> 00:15:18,000
rpcs

417
00:15:15,920 --> 00:15:20,319
and um of course you also get the

418
00:15:18,000 --> 00:15:22,880
configuration validation

419
00:15:20,320 --> 00:15:24,079
that comes with the model and yeah below

420
00:15:22,880 --> 00:15:25,279
here is an example of querying in the

421
00:15:24,079 --> 00:15:27,120
runtime state of running beta

422
00:15:25,279 --> 00:15:30,399
application

423
00:15:27,120 --> 00:15:32,880
all right so that's

424
00:15:30,399 --> 00:15:34,000
it from me you are welcome to get

425
00:15:32,880 --> 00:15:36,079
involved with this

426
00:15:34,000 --> 00:15:38,560
project both vita and snap we're on

427
00:15:36,079 --> 00:15:38,560
github

428
00:15:39,120 --> 00:15:43,120
if you want to get more of the gritty

429
00:15:42,079 --> 00:15:45,680
details on that

430
00:15:43,120 --> 00:15:47,440
i try to journal as much as possible of

431
00:15:45,680 --> 00:15:48,000
this on my blog where i go like deeper

432
00:15:47,440 --> 00:15:51,040
into

433
00:15:48,000 --> 00:15:53,920
certain subtopics of this uh also i

434
00:15:51,040 --> 00:15:56,079
offer support and consulting on this

435
00:15:53,920 --> 00:15:57,519
both vita and snap again via my

436
00:15:56,079 --> 00:16:00,160
consulting company to seller

437
00:15:57,519 --> 00:16:00,720
and if you have any questions please ask

438
00:16:00,160 --> 00:16:04,959
them now

439
00:16:00,720 --> 00:16:04,959
in the hallway or shoot me a mail

440
00:16:05,600 --> 00:16:11,360
yes yes please go ahead so um

441
00:16:09,040 --> 00:16:13,040
i've kind of looked at the the let's say

442
00:16:11,360 --> 00:16:16,639
the lewis packard processing

443
00:16:13,040 --> 00:16:20,319
ecosystem there's snap there's vita

444
00:16:16,639 --> 00:16:21,199
there's moon gen and then built on the

445
00:16:20,320 --> 00:16:22,880
moon

446
00:16:21,199 --> 00:16:24,240
so there's a whole kind of little kind

447
00:16:22,880 --> 00:16:27,600
of uh let's say

448
00:16:24,240 --> 00:16:30,480
boutique ecosystem of lower-based uh

449
00:16:27,600 --> 00:16:31,759
data plane uh what what do you see the

450
00:16:30,480 --> 00:16:35,680
advantages of that are

451
00:16:31,759 --> 00:16:38,800
compared to uh compared to using dpdk

452
00:16:35,680 --> 00:16:39,519
mostly size size and complexity i'm

453
00:16:38,800 --> 00:16:40,880
sorry yeah

454
00:16:39,519 --> 00:16:43,120
so the question was what's the advantage

455
00:16:40,880 --> 00:16:45,120
of using uh doing packet processing in

456
00:16:43,120 --> 00:16:51,839
lua as opposed to do it in c with dptk

457
00:16:45,120 --> 00:16:51,839
for example

458
00:16:52,639 --> 00:16:56,399
well me personally i started with uber

459
00:16:54,639 --> 00:16:58,800
because i was hired to work on that

460
00:16:56,399 --> 00:17:00,160
um and i guess the answer for most

461
00:16:58,800 --> 00:17:02,519
people that work on dpdk is the same

462
00:17:00,160 --> 00:17:05,039
just the other way around

463
00:17:02,519 --> 00:17:06,319
however um for me personally it really

464
00:17:05,039 --> 00:17:08,240
boils down to size

465
00:17:06,319 --> 00:17:09,839
and one goal that we had with snap so so

466
00:17:08,240 --> 00:17:11,359
just to repeat that vita is based on

467
00:17:09,839 --> 00:17:13,198
snap it's written in snap it's not like

468
00:17:11,359 --> 00:17:14,559
its separate thing it just uses that as

469
00:17:13,199 --> 00:17:16,880
it's like toolkit

470
00:17:14,559 --> 00:17:18,480
to work and one goal that we had from

471
00:17:16,880 --> 00:17:20,400
the very beginning is that we want like

472
00:17:18,480 --> 00:17:22,319
non-hardcore programmers to be

473
00:17:20,400 --> 00:17:23,520
able to do network programming with

474
00:17:22,319 --> 00:17:26,240
performance

475
00:17:23,520 --> 00:17:27,359
um we have some use cases where network

476
00:17:26,240 --> 00:17:29,600
engineers

477
00:17:27,359 --> 00:17:32,000
use snap as sort of a kind of like a

478
00:17:29,600 --> 00:17:34,080
debugging introspection shell where

479
00:17:32,000 --> 00:17:37,520
network engineers write like little

480
00:17:34,080 --> 00:17:38,799
programs to to um debug their traffic

481
00:17:37,520 --> 00:17:41,200
their things

482
00:17:38,799 --> 00:17:42,480
and we really had this like idea that

483
00:17:41,200 --> 00:17:44,240
you shouldn't be

484
00:17:42,480 --> 00:17:46,320
it should be less expensive it should be

485
00:17:44,240 --> 00:17:48,080
more easy it should be less complex and

486
00:17:46,320 --> 00:17:49,600
i think if you compare the code based

487
00:17:48,080 --> 00:17:50,720
sizes you will see

488
00:17:49,600 --> 00:17:52,559
what i'm talking about it's like really

489
00:17:50,720 --> 00:17:54,640
really a difference in just size and

490
00:17:52,559 --> 00:17:57,360
scope

491
00:17:54,640 --> 00:17:57,840
so we want to keep it simple and a

492
00:17:57,360 --> 00:17:59,360
simple

493
00:17:57,840 --> 00:18:00,959
networking tool means that we also want

494
00:17:59,360 --> 00:18:03,199
to use a simple language and c is not

495
00:18:00,960 --> 00:18:03,200
that

496
00:18:03,360 --> 00:18:09,439
yes please so um you're using

497
00:18:07,039 --> 00:18:10,160
a direct curve bypass to get the network

498
00:18:09,440 --> 00:18:14,720
packet

499
00:18:10,160 --> 00:18:16,559
but cryptography is quite cpu intensive

500
00:18:14,720 --> 00:18:18,559
so does the direct bypass may actually

501
00:18:16,559 --> 00:18:21,600
make any difference in your use case

502
00:18:18,559 --> 00:18:24,320
or with just using normal sockets uh

503
00:18:21,600 --> 00:18:25,360
on big package on 1 500 byte packets

504
00:18:24,320 --> 00:18:29,120
probably not

505
00:18:25,360 --> 00:18:31,039
on 60 byte packets yes so

506
00:18:29,120 --> 00:18:32,000
it's like encryption on modern cpus

507
00:18:31,039 --> 00:18:34,240
especially if you're doing something

508
00:18:32,000 --> 00:18:35,919
that's um supported widely like ascm

509
00:18:34,240 --> 00:18:36,400
where you have like aes cpu instructions

510
00:18:35,919 --> 00:18:38,559
for that

511
00:18:36,400 --> 00:18:40,400
it's actually quite fast a single core

512
00:18:38,559 --> 00:18:43,678
can encrypt

513
00:18:40,400 --> 00:18:45,039
beyond 20 gigabits a second easily um

514
00:18:43,679 --> 00:18:46,799
but you're not hitting that rate ever

515
00:18:45,039 --> 00:18:48,799
when you're doing small packets because

516
00:18:46,799 --> 00:18:49,840
for that for it to hit that you kind of

517
00:18:48,799 --> 00:18:52,720
like have to give it a

518
00:18:49,840 --> 00:18:54,320
long chunk to work on so you really end

519
00:18:52,720 --> 00:18:57,280
up being

520
00:18:54,320 --> 00:18:58,320
bottlenecked by just the usual number of

521
00:18:57,280 --> 00:19:00,879
packets per second

522
00:18:58,320 --> 00:19:03,039
issue and the kernel is really bad at

523
00:19:00,880 --> 00:19:03,039
that

524
00:19:03,360 --> 00:19:06,000
anybody else

525
00:19:06,720 --> 00:19:10,559
yeah please i also have a second

526
00:19:08,160 --> 00:19:12,240
question so uh you

527
00:19:10,559 --> 00:19:14,080
i got from this slide that you actually

528
00:19:12,240 --> 00:19:16,160
implemented some parts of the

529
00:19:14,080 --> 00:19:18,559
cryptography and key exchange and all

530
00:19:16,160 --> 00:19:21,520
these algorithms and lua directly right

531
00:19:18,559 --> 00:19:23,039
so uh how can you be sure that there are

532
00:19:21,520 --> 00:19:24,559
no side channels in there

533
00:19:23,039 --> 00:19:26,080
especially those that might be

534
00:19:24,559 --> 00:19:28,240
introduced by the jit

535
00:19:26,080 --> 00:19:30,399
not by you yourself but the jit kind of

536
00:19:28,240 --> 00:19:33,120
optimizes something a way that

537
00:19:30,400 --> 00:19:33,520
then induces a sideshow not excellent

538
00:19:33,120 --> 00:19:34,959
but

539
00:19:33,520 --> 00:19:36,639
maybe oh it's a good question creating a

540
00:19:34,960 --> 00:19:38,160
comparison thinking

541
00:19:36,640 --> 00:19:39,760
it might be done early or something yeah

542
00:19:38,160 --> 00:19:41,840
yeah so there's no actual

543
00:19:39,760 --> 00:19:42,879
cryptographic like primitives written in

544
00:19:41,840 --> 00:19:45,120
lua

545
00:19:42,880 --> 00:19:46,320
um so the primitives are all either

546
00:19:45,120 --> 00:19:47,600
assembly or their respective c

547
00:19:46,320 --> 00:19:51,439
implementations

548
00:19:47,600 --> 00:19:53,039
and why we use lua to generate the

549
00:19:51,440 --> 00:19:54,559
so then asm is a dynamic assembler you

550
00:19:53,039 --> 00:19:55,039
write lure code that generates assembly

551
00:19:54,559 --> 00:19:56,559
code

552
00:19:55,039 --> 00:19:58,799
but what you actually run in the end is

553
00:19:56,559 --> 00:20:02,000
not any looper but just assembly code

554
00:19:58,799 --> 00:20:04,000
and like why is the aes constant time

555
00:20:02,000 --> 00:20:05,679
because the aes instruction on x86 it

556
00:20:04,000 --> 00:20:06,799
uses constant time and we're executing

557
00:20:05,679 --> 00:20:08,159
that

558
00:20:06,799 --> 00:20:10,639
so that's something definitely we have

559
00:20:08,159 --> 00:20:12,080
to make sure that we don't do that but

560
00:20:10,640 --> 00:20:21,840
yeah that's basically

561
00:20:12,080 --> 00:20:21,840
how we know

562
00:20:22,320 --> 00:20:28,639
so that concludes the sdn room day for

563
00:20:25,440 --> 00:20:28,880
fast m 2020 and we'd really appreciate

564
00:20:28,640 --> 00:20:30,799
it

565
00:20:28,880 --> 00:20:35,840
if you'd help us out in two ways if

566
00:20:30,799 --> 00:20:35,840
you'd leave feedback

567
00:20:36,880 --> 00:20:38,960
you

