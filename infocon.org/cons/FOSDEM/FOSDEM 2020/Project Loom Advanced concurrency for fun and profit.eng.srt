1
00:00:04,590 --> 00:00:12,389
thank you mark who gave an admirable

2
00:00:08,330 --> 00:00:15,840
introduction to some of the motivation

3
00:00:12,389 --> 00:00:20,009
behind project loom I'll go over that a

4
00:00:15,840 --> 00:00:22,439
little bit just for just to add a little

5
00:00:20,010 --> 00:00:28,380
bit more but I'll also talk a bit about

6
00:00:22,440 --> 00:00:30,480
how this stuff actually works so one of

7
00:00:28,380 --> 00:00:31,590
the marvelous things about Java well

8
00:00:30,480 --> 00:00:34,110
there are two marvelous things about

9
00:00:31,590 --> 00:00:37,109
Java in its early incarnation firstly

10
00:00:34,110 --> 00:00:39,480
that there was essentially no innovation

11
00:00:37,109 --> 00:00:42,210
in Java there was nothing new it was

12
00:00:39,480 --> 00:00:44,099
just a practical synthesis of a whole

13
00:00:42,210 --> 00:00:47,820
bunch of stuff that already existed in

14
00:00:44,100 --> 00:00:49,379
other programming languages a lot of

15
00:00:47,820 --> 00:00:52,649
them were just research languages though

16
00:00:49,379 --> 00:00:55,318
the genius of Java was to come up with a

17
00:00:52,649 --> 00:00:57,960
synthesis of some of the best ideas in

18
00:00:55,319 --> 00:00:59,699
computer science in a practical language

19
00:00:57,960 --> 00:01:02,429
that could be used by normal human

20
00:00:59,699 --> 00:01:06,050
beings that was a tremendous achievement

21
00:01:02,429 --> 00:01:11,070
and one of the things that Java did was

22
00:01:06,050 --> 00:01:13,860
concurrency multi-threading which was to

23
00:01:11,070 --> 00:01:16,439
actually get a portable definition of

24
00:01:13,860 --> 00:01:18,420
what a thread actually was which didn't

25
00:01:16,439 --> 00:01:19,860
depend really on any particular hardware

26
00:01:18,420 --> 00:01:23,039
implementations threads was a

27
00:01:19,860 --> 00:01:25,320
considerable considerable achievements

28
00:01:23,039 --> 00:01:26,969
at the time but as Mark said with 25

29
00:01:25,320 --> 00:01:30,658
years down the road and the cracks are

30
00:01:26,969 --> 00:01:32,429
beginning to show and servers in

31
00:01:30,659 --> 00:01:33,930
particular but all sorts of Java

32
00:01:32,430 --> 00:01:39,630
applications are running a lot of

33
00:01:33,930 --> 00:01:42,630
threads but manual use of threads II's

34
00:01:39,630 --> 00:01:45,960
using Java dot Languedoc thread by hand

35
00:01:42,630 --> 00:01:48,539
is clumsy error-prone you can end up

36
00:01:45,960 --> 00:01:50,788
with a whole load of threads hanging

37
00:01:48,539 --> 00:01:52,049
around not doing much and also that they

38
00:01:50,789 --> 00:01:54,390
were very heavyweight because they

39
00:01:52,049 --> 00:01:57,479
require on kernel lightweight processes

40
00:01:54,390 --> 00:02:02,490
now a kernel lightweight process in

41
00:01:57,479 --> 00:02:05,810
Linux is not really our idea at our end

42
00:02:02,490 --> 00:02:11,269
of what lightweight actually means even

43
00:02:05,810 --> 00:02:13,440
on a 32-bit system it can sometimes

44
00:02:11,270 --> 00:02:17,370
allocate a megabyte of address space

45
00:02:13,440 --> 00:02:20,800
just for the thread local heap

46
00:02:17,370 --> 00:02:23,670
so what we actually need again as Mark

47
00:02:20,800 --> 00:02:29,140
said is some more lightweight

48
00:02:23,670 --> 00:02:30,970
representation we don't want to we don't

49
00:02:29,140 --> 00:02:32,380
want the kernel to have to preempt

50
00:02:30,970 --> 00:02:35,260
threads we want to do it in user space

51
00:02:32,380 --> 00:02:38,260
because those of you have measured it

52
00:02:35,260 --> 00:02:40,359
we'll know that on any kind of Unix a

53
00:02:38,260 --> 00:02:42,730
Linux system it takes an ungodly long

54
00:02:40,360 --> 00:02:44,970
time to get into the kernel and back out

55
00:02:42,730 --> 00:02:48,310
again usually about a microsecond or so

56
00:02:44,970 --> 00:02:51,250
and pre-empting threads is quite

57
00:02:48,310 --> 00:02:52,870
expensive all right I should give Ron

58
00:02:51,250 --> 00:02:54,400
credit at this point there's a couple of

59
00:02:52,870 --> 00:02:56,620
the slides that I stole from you so

60
00:02:54,400 --> 00:03:00,280
thank you I'm sure you recognize them

61
00:02:56,620 --> 00:03:03,880
and Java threads don't need a lot of

62
00:03:00,280 --> 00:03:05,680
this stuff so again as Mark said

63
00:03:03,880 --> 00:03:09,310
programmers have responded to this by

64
00:03:05,680 --> 00:03:11,530
using reactive programming so you would

65
00:03:09,310 --> 00:03:13,840
like lots and lots of little tasks and

66
00:03:11,530 --> 00:03:16,510
the task would there's all run a

67
00:03:13,840 --> 00:03:18,040
synchronously and they don't block so

68
00:03:16,510 --> 00:03:19,450
whenever you need to block what you

69
00:03:18,040 --> 00:03:22,359
actually do is send the message out so

70
00:03:19,450 --> 00:03:24,310
you will have your code and it will send

71
00:03:22,360 --> 00:03:28,120
a message to the database service saying

72
00:03:24,310 --> 00:03:30,550
can I have a lookup for this please and

73
00:03:28,120 --> 00:03:32,680
the database server would then send a

74
00:03:30,550 --> 00:03:36,990
message to somebody else who would in

75
00:03:32,680 --> 00:03:39,280
turn respond to the result of the query

76
00:03:36,990 --> 00:03:43,990
there are people who like doing this

77
00:03:39,280 --> 00:03:45,580
stuff but it's quite difficult to write

78
00:03:43,990 --> 00:03:52,420
it's very difficult to understand

79
00:03:45,580 --> 00:03:54,220
debugging it is hilarious and so but

80
00:03:52,420 --> 00:03:56,380
this this this was done a while back

81
00:03:54,220 --> 00:03:59,050
this was done in this small talk eighty

82
00:03:56,380 --> 00:04:01,510
user interfaces back in what forty years

83
00:03:59,050 --> 00:04:03,880
ago where the system would be forever

84
00:04:01,510 --> 00:04:05,530
sending new messages which you would

85
00:04:03,880 --> 00:04:07,660
have to handle some way but it's

86
00:04:05,530 --> 00:04:10,480
difficult to do and I was despite it

87
00:04:07,660 --> 00:04:12,100
being pretty efficient we don't need to

88
00:04:10,480 --> 00:04:15,100
have so many threads we just schedule

89
00:04:12,100 --> 00:04:17,649
everything onto thread pools now if you

90
00:04:15,100 --> 00:04:20,409
if your thread pool is the same as size

91
00:04:17,649 --> 00:04:21,940
as the number of actual cores you have

92
00:04:20,410 --> 00:04:24,670
in your physical machine that works

93
00:04:21,940 --> 00:04:29,350
beautifully because the operating system

94
00:04:24,670 --> 00:04:33,650
never needs to preempt any threads

95
00:04:29,350 --> 00:04:35,420
so yes yes I've got a got a bit ahead of

96
00:04:33,650 --> 00:04:38,810
myself now oh yes the unit tests are

97
00:04:35,420 --> 00:04:40,970
difficult to maintain so why not reduce

98
00:04:38,810 --> 00:04:42,770
the weight of instances of thread Java

99
00:04:40,970 --> 00:04:44,300
threads don't need very much context

100
00:04:42,770 --> 00:04:46,700
really a certainly an awful lot less

101
00:04:44,300 --> 00:04:48,320
than kernel threads do and we should be

102
00:04:46,700 --> 00:04:50,330
able to get the total footprint of a

103
00:04:48,320 --> 00:04:52,580
thread down to a few hundred bytes this

104
00:04:50,330 --> 00:04:55,690
has been done in the past I mean the

105
00:04:52,580 --> 00:04:58,430
word systems going back even as far as

106
00:04:55,690 --> 00:05:00,830
the 1960s I believe with

107
00:04:58,430 --> 00:05:02,480
super-lightweight threads to do this

108
00:05:00,830 --> 00:05:07,280
sort of thing so there is a fair bit of

109
00:05:02,480 --> 00:05:11,780
prior art here but how can we bring this

110
00:05:07,280 --> 00:05:14,150
to Java so yes there are OS threads

111
00:05:11,780 --> 00:05:18,080
heavy right megabytes I've said all of

112
00:05:14,150 --> 00:05:20,690
that this is what we can do we can get

113
00:05:18,080 --> 00:05:24,020
userspace threads down to a few hundreds

114
00:05:20,690 --> 00:05:26,600
of bytes the stack that gets sock okay

115
00:05:24,020 --> 00:05:30,469
gets allocated sorry the important thing

116
00:05:26,600 --> 00:05:32,150
here is that the stack for a userspace

117
00:05:30,470 --> 00:05:35,030
thread is just going to be a few hundred

118
00:05:32,150 --> 00:05:38,239
bytes whereas the smallest stack that a

119
00:05:35,030 --> 00:05:41,599
kernel thread can possibly have is one

120
00:05:38,240 --> 00:05:45,020
kernel page and these are allocated

121
00:05:41,600 --> 00:05:48,140
lazily as you grow your spec clearly if

122
00:05:45,020 --> 00:05:50,060
you can fit several thread stacks into a

123
00:05:48,140 --> 00:05:52,099
single page which you certainly can I

124
00:05:50,060 --> 00:05:55,190
mean pages are typically 4k but they may

125
00:05:52,100 --> 00:06:01,870
be as big as 64 K you really are winning

126
00:05:55,190 --> 00:06:01,870
big-time yes yes yes yes right

127
00:06:01,960 --> 00:06:09,380
but thread locals and thread counts

128
00:06:05,210 --> 00:06:10,849
where they used all over the place so

129
00:06:09,380 --> 00:06:13,520
there's some parts of the API that are

130
00:06:10,850 --> 00:06:19,490
no longer a match for this lightweight

131
00:06:13,520 --> 00:06:21,680
way of working and thread could be

132
00:06:19,490 --> 00:06:23,840
cleaned up by moving removing long

133
00:06:21,680 --> 00:06:25,820
deprecated methods but as we all know

134
00:06:23,840 --> 00:06:29,330
it's extremely difficult to remove

135
00:06:25,820 --> 00:06:32,000
anything from Java so we really need a

136
00:06:29,330 --> 00:06:32,479
better abstraction for all of this so

137
00:06:32,000 --> 00:06:35,390
here we are

138
00:06:32,480 --> 00:06:36,290
virtual threads let's implement just

139
00:06:35,390 --> 00:06:37,969
what we need

140
00:06:36,290 --> 00:06:40,880
let's switch between threads and years

141
00:06:37,970 --> 00:06:41,599
of space let's only keep as much spec as

142
00:06:40,880 --> 00:06:44,419
we need

143
00:06:41,599 --> 00:06:45,919
now we won't be able to block in native

144
00:06:44,419 --> 00:06:48,258
code because that requires a full

145
00:06:45,919 --> 00:06:52,669
colonel task switch but there is a way

146
00:06:48,259 --> 00:06:55,939
around this there have been a few

147
00:06:52,669 --> 00:06:58,729
changes in the project recently but most

148
00:06:55,939 --> 00:07:02,179
particularly a virtual thread is now a

149
00:06:58,729 --> 00:07:03,830
subclass of java.lang thread now

150
00:07:02,179 --> 00:07:06,080
whenever virtual flesh is running it is

151
00:07:03,830 --> 00:07:07,520
mounted on a carrier third this is very

152
00:07:06,080 --> 00:07:09,770
important so your carrier thread will

153
00:07:07,520 --> 00:07:13,039
just be a thread out of your usual

154
00:07:09,770 --> 00:07:15,378
thread pool and when we switch virtual

155
00:07:13,039 --> 00:07:21,680
threads we have to dismount the virtual

156
00:07:15,379 --> 00:07:23,119
thread from its carrier thread yeah

157
00:07:21,680 --> 00:07:27,020
these slides are in a slightly funny

158
00:07:23,119 --> 00:07:32,029
order the problem is you've got your

159
00:07:27,020 --> 00:07:34,308
stack which is sitting on a carrier

160
00:07:32,029 --> 00:07:36,379
third this is this is the actual stack

161
00:07:34,309 --> 00:07:38,809
that's been provided to us by the kernel

162
00:07:36,379 --> 00:07:41,419
in the stack is the record of execution

163
00:07:38,809 --> 00:07:46,039
of your Java program what we actually

164
00:07:41,419 --> 00:07:48,649
need to do is to detach the stack frames

165
00:07:46,039 --> 00:07:51,610
from this back move them into the Java

166
00:07:48,649 --> 00:07:54,019
heap somewhere and then mount another

167
00:07:51,610 --> 00:07:55,909
virtual thread onto the same carrier

168
00:07:54,019 --> 00:08:01,599
thread and to do that we have to copy

169
00:07:55,909 --> 00:08:03,349
the stack now when I first saw this I

170
00:08:01,599 --> 00:08:06,680
was appalled

171
00:08:03,349 --> 00:08:08,869
you mean every time that we cop every

172
00:08:06,680 --> 00:08:11,029
time we dismount a thread for any

173
00:08:08,869 --> 00:08:15,289
blocking call at all we're having to

174
00:08:11,029 --> 00:08:17,719
copy the entire stack around how can

175
00:08:15,289 --> 00:08:20,329
this possibly make any sense shouldn't

176
00:08:17,719 --> 00:08:22,308
we just allocate stacks for virtual

177
00:08:20,329 --> 00:08:23,959
threads on the heap instead rather than

178
00:08:22,309 --> 00:08:28,699
I mean it's the obvious other way of

179
00:08:23,959 --> 00:08:31,899
doing it rather than allocating them in

180
00:08:28,699 --> 00:08:34,099
the stack space now it sounds like

181
00:08:31,899 --> 00:08:36,198
copying this stack is going to be a

182
00:08:34,099 --> 00:08:38,689
fabulously expensive operation but it

183
00:08:36,198 --> 00:08:42,409
it's actually isn't there's a couple of

184
00:08:38,688 --> 00:08:45,139
reasons for this one is that our

185
00:08:42,409 --> 00:08:48,500
computers are tremendously good at

186
00:08:45,139 --> 00:08:51,110
copying anybody who's spent a while

187
00:08:48,500 --> 00:08:53,149
observing the computer programs that

188
00:08:51,110 --> 00:08:54,089
actually run on our computers every day

189
00:08:53,149 --> 00:08:55,529
well

190
00:08:54,089 --> 00:08:58,860
observed that they spend most of their

191
00:08:55,529 --> 00:09:00,569
time just moving stuff around that's the

192
00:08:58,860 --> 00:09:03,899
nature of computers that's the nature of

193
00:09:00,569 --> 00:09:06,329
how they're used and therefore the

194
00:09:03,899 --> 00:09:08,040
people who design the computers that we

195
00:09:06,329 --> 00:09:11,128
use have gone to extraordinary lengths

196
00:09:08,040 --> 00:09:15,209
to make just moving stuff around very

197
00:09:11,129 --> 00:09:17,809
fast particularly with caches and

198
00:09:15,209 --> 00:09:21,779
particularly the accessing dynamic Ram

199
00:09:17,809 --> 00:09:24,839
sequentially is very very quick and it

200
00:09:21,779 --> 00:09:27,300
does prefetching and so on well we don't

201
00:09:24,839 --> 00:09:29,009
actually have to copy the entire stack

202
00:09:27,300 --> 00:09:30,959
when a virtual thread is a mounted now

203
00:09:29,009 --> 00:09:33,449
all we actually have to copy are the

204
00:09:30,959 --> 00:09:37,079
frames that have been altered since last

205
00:09:33,449 --> 00:09:39,180
time we unmounted the virtual thread the

206
00:09:37,079 --> 00:09:41,519
details of precisely how this works are

207
00:09:39,180 --> 00:09:44,519
kind of gnarly and this is return

208
00:09:41,519 --> 00:09:48,569
barriers thank you if you want to give

209
00:09:44,519 --> 00:09:51,209
it a name but at that point you're

210
00:09:48,569 --> 00:09:54,120
starting to see why this is a cheap

211
00:09:51,209 --> 00:09:57,050
operation the other thing to observe is

212
00:09:54,120 --> 00:10:00,449
that Java stack frames are small and

213
00:09:57,050 --> 00:10:02,189
they're small because you don't have

214
00:10:00,449 --> 00:10:04,050
local strings you don't have local

215
00:10:02,189 --> 00:10:09,748
arrays you don't have any of this stuff

216
00:10:04,050 --> 00:10:11,729
all that is in a java thread are your

217
00:10:09,749 --> 00:10:13,769
local variables and your local variables

218
00:10:11,730 --> 00:10:15,600
are always either scalars or references

219
00:10:13,769 --> 00:10:17,459
to an object somewhere else so the

220
00:10:15,600 --> 00:10:22,559
threads are small copying them on and

221
00:10:17,459 --> 00:10:24,300
off when we unmount is pretty cheap but

222
00:10:22,559 --> 00:10:26,670
we can't get away with that with native

223
00:10:24,300 --> 00:10:29,998
code we can't unmount stacks with native

224
00:10:26,670 --> 00:10:33,599
frames the reason reasons for this are

225
00:10:29,999 --> 00:10:37,170
quite complicated but the problem is

226
00:10:33,600 --> 00:10:38,999
that native stacks often contain

227
00:10:37,170 --> 00:10:41,790
pointers that a point isn't pointing

228
00:10:38,999 --> 00:10:44,040
into the stack frame and we'd have to do

229
00:10:41,790 --> 00:10:46,790
some really fancy footwork of relocating

230
00:10:44,040 --> 00:10:50,550
the stack frame in if we wanted to

231
00:10:46,790 --> 00:10:54,389
unmount a virtual thread from a stack

232
00:10:50,550 --> 00:10:57,740
over here and copy it to a stack over to

233
00:10:54,389 --> 00:10:57,740
a carrier thread over there

234
00:10:58,209 --> 00:11:05,518
all right so let's say we've got an

235
00:11:00,970 --> 00:11:08,139
unmounted thread over here somewhere

236
00:11:05,519 --> 00:11:11,499
what do we do about object pointers

237
00:11:08,139 --> 00:11:14,230
because we know that saved on the stack

238
00:11:11,499 --> 00:11:16,420
there will be a whole bunch of object

239
00:11:14,230 --> 00:11:19,059
pointers and the garbage collector this

240
00:11:16,420 --> 00:11:20,040
is Java is moving stuff around all the

241
00:11:19,059 --> 00:11:23,949
time

242
00:11:20,040 --> 00:11:26,230
how will the garbage collector be able

243
00:11:23,949 --> 00:11:28,599
to do that because if you look at the

244
00:11:26,230 --> 00:11:30,670
structure of this class here Java line

245
00:11:28,600 --> 00:11:34,290
continuation I should just explain a

246
00:11:30,670 --> 00:11:37,569
continuation is basically just the

247
00:11:34,290 --> 00:11:40,540
running context of a Java program a

248
00:11:37,569 --> 00:11:44,469
virtual thread is composed of its

249
00:11:40,540 --> 00:11:46,719
continuation plus a bit more stuff so

250
00:11:44,470 --> 00:11:51,639
when we save the stack we just copy it

251
00:11:46,720 --> 00:11:54,220
into this Java array here that's just an

252
00:11:51,639 --> 00:11:57,249
array events but the garbage collector

253
00:11:54,220 --> 00:12:00,749
is going to want to continue to run and

254
00:11:57,249 --> 00:12:04,119
it's going to move objects around which

255
00:12:00,749 --> 00:12:06,369
is going to invalidate some of the

256
00:12:04,119 --> 00:12:09,160
pointers in that enter a that's the copy

257
00:12:06,369 --> 00:12:11,649
of the stack and what we used to do was

258
00:12:09,160 --> 00:12:16,779
to scan the whole stack find out all of

259
00:12:11,649 --> 00:12:23,350
the words in the stack that were in fact

260
00:12:16,779 --> 00:12:25,209
object pointers or oops and copy those

261
00:12:23,350 --> 00:12:26,769
into a separate object array and we'd

262
00:12:25,209 --> 00:12:29,679
expose that to the garbage collector and

263
00:12:26,769 --> 00:12:32,740
then when we remounted the virtual

264
00:12:29,679 --> 00:12:35,230
thread it would copy them all back now

265
00:12:32,740 --> 00:12:40,540
the problem with this is that actually

266
00:12:35,230 --> 00:12:42,490
finding out which words in the stack our

267
00:12:40,540 --> 00:12:44,589
object pointers and which words are just

268
00:12:42,490 --> 00:12:47,529
integers is really quite an expensive

269
00:12:44,589 --> 00:12:49,899
operation you have to trawl through the

270
00:12:47,529 --> 00:12:55,119
metadata of all the methods that are on

271
00:12:49,899 --> 00:12:56,649
the stack granted the result is just a

272
00:12:55,119 --> 00:12:58,119
bitmap it's either this word is either

273
00:12:56,649 --> 00:13:00,459
an object or it's not

274
00:12:58,119 --> 00:13:02,350
we're actually scanning and on scanning

275
00:13:00,459 --> 00:13:04,689
and so on was really quite painful

276
00:13:02,350 --> 00:13:06,610
considerably more painful I have to say

277
00:13:04,689 --> 00:13:10,569
than the business of just copying the

278
00:13:06,610 --> 00:13:11,990
data into and out of the array but we

279
00:13:10,569 --> 00:13:13,969
have a new algorithm which

280
00:13:11,990 --> 00:13:16,910
we're on implemented a few weeks ago or

281
00:13:13,970 --> 00:13:21,200
something where the garbage collector

282
00:13:16,910 --> 00:13:23,209
can actually scan what's in there as

283
00:13:21,200 --> 00:13:26,840
long as it stays in the new generation

284
00:13:23,210 --> 00:13:30,650
if it stays in the old generation sorry

285
00:13:26,840 --> 00:13:32,540
if it gets if if the virtual thread gets

286
00:13:30,650 --> 00:13:34,310
promoted into the old generation I think

287
00:13:32,540 --> 00:13:35,719
then we have to do the whole thing of

288
00:13:34,310 --> 00:13:37,760
scanning the stack and setting at the

289
00:13:35,720 --> 00:13:43,300
pointers and so on I think that's one

290
00:13:37,760 --> 00:13:43,300
nodding or not good enough right

291
00:13:43,420 --> 00:13:51,319
okay synchronized blocks now those of

292
00:13:48,560 --> 00:13:54,680
you unfortunate enough to have actually

293
00:13:51,320 --> 00:13:56,810
written Java VM at the very very low

294
00:13:54,680 --> 00:13:59,000
level will know that the way that

295
00:13:56,810 --> 00:14:02,290
synchronized blocks work is some very

296
00:13:59,000 --> 00:14:06,620
very hairy handwritten assembly code

297
00:14:02,290 --> 00:14:08,630
which makes assumptions that this really

298
00:14:06,620 --> 00:14:09,980
is running on the native stack and you

299
00:14:08,630 --> 00:14:14,180
can block and you can call into the

300
00:14:09,980 --> 00:14:15,800
operating system and so on we can't do

301
00:14:14,180 --> 00:14:18,319
anything about this with virtual thread

302
00:14:15,800 --> 00:14:20,930
if you actually say synchronized and the

303
00:14:18,320 --> 00:14:24,620
synchronized has to block then you are

304
00:14:20,930 --> 00:14:26,150
going to block the carrier thread which

305
00:14:24,620 --> 00:14:27,680
you really really don't want to do

306
00:14:26,150 --> 00:14:29,390
because now you've got one for your

307
00:14:27,680 --> 00:14:32,449
thread that you can use to do some work

308
00:14:29,390 --> 00:14:34,400
but people are more and more these days

309
00:14:32,450 --> 00:14:36,200
using the locks from Java util

310
00:14:34,400 --> 00:14:38,050
concurrent rather than just synchronized

311
00:14:36,200 --> 00:14:42,470
blocks and these work perfectly well

312
00:14:38,050 --> 00:14:46,099
with Loom virtual thread state unmount

313
00:14:42,470 --> 00:14:48,020
the virtual thread if they block so that

314
00:14:46,100 --> 00:14:50,150
works fine so we've had to go through

315
00:14:48,020 --> 00:14:53,090
the Java IO library replacing these

316
00:14:50,150 --> 00:14:55,640
synchronized blocks you know it only has

317
00:14:53,090 --> 00:14:57,620
to do it once and thread yield hands off

318
00:14:55,640 --> 00:15:00,710
to continuation yield on mounting the

319
00:14:57,620 --> 00:15:04,040
virtual thread or good now the next bit

320
00:15:00,710 --> 00:15:07,630
is it's called possible futures here

321
00:15:04,040 --> 00:15:10,819
that's not really right the first one is

322
00:15:07,630 --> 00:15:12,830
structured concurrency which i think is

323
00:15:10,820 --> 00:15:16,670
definitely going to happen the second

324
00:15:12,830 --> 00:15:19,550
one is scope locals which may or may not

325
00:15:16,670 --> 00:15:21,890
happen but I want to talk about that

326
00:15:19,550 --> 00:15:24,520
because it's mine because I did it and I

327
00:15:21,890 --> 00:15:24,520
think it's interesting

328
00:15:25,399 --> 00:15:28,649
okay

329
00:15:26,610 --> 00:15:30,480
so let's think a bit about structured

330
00:15:28,649 --> 00:15:31,860
programming the traditional structured

331
00:15:30,480 --> 00:15:34,260
programming is all your control

332
00:15:31,860 --> 00:15:36,660
structures have it in at the top and and

333
00:15:34,260 --> 00:15:38,760
out at the bottom you can reason about

334
00:15:36,660 --> 00:15:40,790
programs much more easily if you use

335
00:15:38,760 --> 00:15:45,660
structured programming everything nests

336
00:15:40,790 --> 00:15:47,849
nicely when you think about what's

337
00:15:45,660 --> 00:15:52,040
actually going on with threaded

338
00:15:47,850 --> 00:15:54,329
programming it is the most gloriously

339
00:15:52,040 --> 00:15:56,189
unstructured way of programming you can

340
00:15:54,329 --> 00:15:57,989
possibly imagine not only is there not

341
00:15:56,190 --> 00:16:00,000
one in one out at the top well there's

342
00:15:57,990 --> 00:16:01,470
one in and as many out and they spawn

343
00:16:00,000 --> 00:16:03,209
over here and they start running over

344
00:16:01,470 --> 00:16:07,920
there and then they send messages to

345
00:16:03,209 --> 00:16:09,989
each other and if with Project loon

346
00:16:07,920 --> 00:16:11,849
you're going to have tens of thousands

347
00:16:09,990 --> 00:16:13,290
of thread or hundreds of thousands which

348
00:16:11,850 --> 00:16:16,050
we can do because they're only a few

349
00:16:13,290 --> 00:16:21,329
hundred bytes we somehow have to find a

350
00:16:16,050 --> 00:16:24,029
way to constrain that complexity in such

351
00:16:21,329 --> 00:16:26,250
a way that we can predict how a program

352
00:16:24,029 --> 00:16:26,790
is going to work we can analyze it and

353
00:16:26,250 --> 00:16:28,800
so on

354
00:16:26,790 --> 00:16:30,089
so simply firing off thousands and

355
00:16:28,800 --> 00:16:31,699
thousands of threads and passing

356
00:16:30,089 --> 00:16:33,779
messages back and forth and so on

357
00:16:31,699 --> 00:16:36,839
probably isn't going to work all that

358
00:16:33,779 --> 00:16:41,630
well yes old spaghetti Fortran programs

359
00:16:36,839 --> 00:16:44,220
have got nothing on this so here we are

360
00:16:41,630 --> 00:16:46,980
structured concurrency this is the idea

361
00:16:44,220 --> 00:16:51,149
and it's a very very simple idea that if

362
00:16:46,980 --> 00:16:53,940
you have a thread and it splits into a

363
00:16:51,149 --> 00:16:57,089
whole bunch of other threads then we

364
00:16:53,940 --> 00:16:58,769
want to have a join at the bottom when

365
00:16:57,089 --> 00:16:59,930
all of the other threads terminate and

366
00:16:58,769 --> 00:17:02,610
we carry on

367
00:16:59,930 --> 00:17:05,819
whoop-dee-doo this is structured and

368
00:17:02,610 --> 00:17:08,160
what's more if the threads have just

369
00:17:05,819 --> 00:17:10,199
done some purely functional computation

370
00:17:08,160 --> 00:17:11,669
for you and they all join together at

371
00:17:10,199 --> 00:17:14,730
the end what you've actually got there

372
00:17:11,669 --> 00:17:17,730
is a function you can analyze it you can

373
00:17:14,730 --> 00:17:21,449
reason about it it has no side effects

374
00:17:17,730 --> 00:17:25,370
but you've been able to use concurrency

375
00:17:21,449 --> 00:17:30,830
to make it more efficient so here we are

376
00:17:25,369 --> 00:17:34,020
here is an example of a structured

377
00:17:30,830 --> 00:17:38,279
concurrency construct this is your

378
00:17:34,020 --> 00:17:43,590
executor service here you submit to

379
00:17:38,279 --> 00:17:45,809
tasks for to execute and this is a try

380
00:17:43,590 --> 00:17:48,209
with resources so when you get to the

381
00:17:45,809 --> 00:17:52,200
end they both both joined together and

382
00:17:48,210 --> 00:17:54,450
it won't he won't terminate until

383
00:17:52,200 --> 00:17:57,419
they've both finished the executors

384
00:17:54,450 --> 00:17:59,179
submit returns the future that can be

385
00:17:57,419 --> 00:18:01,980
queried for a result of whatever

386
00:17:59,179 --> 00:18:03,809
computation you were doing there I don't

387
00:18:01,980 --> 00:18:06,740
I don't handle it there but you would

388
00:18:03,809 --> 00:18:10,470
you would need to assign it to something

389
00:18:06,740 --> 00:18:12,570
our handling and cancellation works much

390
00:18:10,470 --> 00:18:14,549
better because everybody joins therefore

391
00:18:12,570 --> 00:18:16,139
it's the responsibility of the joint

392
00:18:14,549 --> 00:18:18,570
point to handle anything that went wrong

393
00:18:16,139 --> 00:18:21,750
in any of these threads that you just

394
00:18:18,570 --> 00:18:23,428
learnt out and also thread cancellation

395
00:18:21,750 --> 00:18:26,250
is pretty cool as well because you can

396
00:18:23,429 --> 00:18:28,080
either cancel one of the child threads

397
00:18:26,250 --> 00:18:30,000
or you can cancel the parent thread in

398
00:18:28,080 --> 00:18:33,178
which case it'll all get propagated and

399
00:18:30,000 --> 00:18:35,009
so on and so on now this doesn't require

400
00:18:33,179 --> 00:18:36,539
virtual threads the structure

401
00:18:35,009 --> 00:18:39,149
concurrency works perfectly well with

402
00:18:36,539 --> 00:18:41,850
any kind of thread but it's very nice

403
00:18:39,149 --> 00:18:43,408
for this kind of work and so I've been

404
00:18:41,850 --> 00:18:45,269
looking at how far back this goes and

405
00:18:43,409 --> 00:18:50,240
I'm fairly sure that the Burroughs large

406
00:18:45,269 --> 00:18:55,940
systems of the 1960s worked this way so

407
00:18:50,240 --> 00:18:58,230
yeah it's it's good ok now thread locals

408
00:18:55,940 --> 00:19:00,990
Java stayed local it's kind of

409
00:18:58,230 --> 00:19:03,389
heavyweight it's slow and all the rest

410
00:19:00,990 --> 00:19:06,590
of it now I'm going to try now to open a

411
00:19:03,389 --> 00:19:06,590
link let's see

412
00:19:17,710 --> 00:19:20,710
Shh

413
00:19:21,460 --> 00:19:30,080
aha here's one I opened earlier this is

414
00:19:26,360 --> 00:19:33,439
an analysis that I did a couple of years

415
00:19:30,080 --> 00:19:36,110
ago of what actually happens when you

416
00:19:33,440 --> 00:19:38,210
say thread-local get and there's a

417
00:19:36,110 --> 00:19:39,560
tradition of my talks at frost em none

418
00:19:38,210 --> 00:19:44,210
of them are complete without some

419
00:19:39,560 --> 00:19:48,830
assembly language okay thank you this is

420
00:19:44,210 --> 00:19:51,410
what thread-local get actually does it

421
00:19:48,830 --> 00:19:53,480
does a whole bunch of reads from thread

422
00:19:51,410 --> 00:19:55,370
metadata we just read locals for a local

423
00:19:53,480 --> 00:19:59,120
table length field thread local hash

424
00:19:55,370 --> 00:20:00,949
code look it up in a table do the

425
00:19:59,120 --> 00:20:02,629
garbage collector magic because it's a

426
00:20:00,950 --> 00:20:05,450
WIC reference we now have our thread

427
00:20:02,630 --> 00:20:08,840
local and we done so read local get is

428
00:20:05,450 --> 00:20:12,440
twelve field loads five conditional

429
00:20:08,840 --> 00:20:16,100
branches this is not by any standard a

430
00:20:12,440 --> 00:20:17,810
lightweight operation so this was a

431
00:20:16,100 --> 00:20:21,050
couple of years ago and the question is

432
00:20:17,810 --> 00:20:27,320
can we actually do any better than this

433
00:20:21,050 --> 00:20:29,450
and I kind of hope we can so this is the

434
00:20:27,320 --> 00:20:33,200
this is the proposal for scope locals

435
00:20:29,450 --> 00:20:35,720
and the idea here is to do something

436
00:20:33,200 --> 00:20:39,260
rather similar to structured concurrency

437
00:20:35,720 --> 00:20:41,660
you will declare sorry you will bind the

438
00:20:39,260 --> 00:20:43,550
scope local at some points in your

439
00:20:41,660 --> 00:20:48,140
programs nesting it will then be visible

440
00:20:43,550 --> 00:20:51,110
to everything you call by doing your

441
00:20:48,140 --> 00:20:55,370
scope local get and it will disappear

442
00:20:51,110 --> 00:21:00,320
when you exit the same scope there will

443
00:20:55,370 --> 00:21:05,750
also be inherited by your child threads

444
00:21:00,320 --> 00:21:07,790
in your structure concurrency now it

445
00:21:05,750 --> 00:21:11,450
makes sense for them to inherited it

446
00:21:07,790 --> 00:21:13,610
doesn't make very much sense for local

447
00:21:11,450 --> 00:21:14,780
these Scott locals to be mutable ID only

448
00:21:13,610 --> 00:21:17,750
it makes very much sense for thread

449
00:21:14,780 --> 00:21:19,790
locals to be mutable either frankly but

450
00:21:17,750 --> 00:21:20,750
I don't think anybody understood that

451
00:21:19,790 --> 00:21:24,610
when there

452
00:21:20,750 --> 00:21:27,050
done 15 years ago or whatever it was

453
00:21:24,610 --> 00:21:32,840
okay and is and here's what it looks

454
00:21:27,050 --> 00:21:36,100
like you would launch your child tasks

455
00:21:32,840 --> 00:21:39,280
but you would bind a value to your

456
00:21:36,100 --> 00:21:41,570
integer there and then in this is

457
00:21:39,280 --> 00:21:44,570
execute swim bar and then in foo you

458
00:21:41,570 --> 00:21:47,960
would say I ain't get so it's like a

459
00:21:44,570 --> 00:21:50,450
thread-local but we've made it better by

460
00:21:47,960 --> 00:21:52,340
making it less powerful this is a

461
00:21:50,450 --> 00:21:56,330
crucial observation about a lot of this

462
00:21:52,340 --> 00:21:57,649
stuff is that we've got interfaces and

463
00:21:56,330 --> 00:21:59,720
constructs and so on that are

464
00:21:57,650 --> 00:22:01,640
tremendously powerful but in many ways

465
00:21:59,720 --> 00:22:04,220
they are too powerful and the sheer

466
00:22:01,640 --> 00:22:05,600
versatility of these constructs gets in

467
00:22:04,220 --> 00:22:08,570
the way of doing really efficient

468
00:22:05,600 --> 00:22:10,639
implementations and it also gets in the

469
00:22:08,570 --> 00:22:15,189
way of the programmer being able to

470
00:22:10,640 --> 00:22:19,250
reason about invariants and so on so

471
00:22:15,190 --> 00:22:21,470
scope locals and a fixed size local

472
00:22:19,250 --> 00:22:24,710
cache is the magic is what I've done is

473
00:22:21,470 --> 00:22:28,460
that every carrier thread has a fixed

474
00:22:24,710 --> 00:22:30,890
size cache of 16 entries where the most

475
00:22:28,460 --> 00:22:33,920
recent Scout locals that you've asked

476
00:22:30,890 --> 00:22:37,340
for are stored and from this will load a

477
00:22:33,920 --> 00:22:40,010
point at the locals cache c2 is plenty

478
00:22:37,340 --> 00:22:43,699
clever enough to hoist scoped locals

479
00:22:40,010 --> 00:22:45,710
into registers now that means the 12

480
00:22:43,700 --> 00:22:50,390
loads and 5 conditional branches that I

481
00:22:45,710 --> 00:22:53,480
showed you for thread local can be

482
00:22:50,390 --> 00:22:55,490
reduced to just if Skott locals are used

483
00:22:53,480 --> 00:22:57,230
in a loop they will be hoisted into

484
00:22:55,490 --> 00:23:02,120
registers at the start of the loop and

485
00:22:57,230 --> 00:23:03,920
they will stay there so this is what it

486
00:23:02,120 --> 00:23:07,129
looks like you've got a carrier thread

487
00:23:03,920 --> 00:23:10,780
here which has this 16 entry cash for

488
00:23:07,130 --> 00:23:13,700
scope locals you've got virtual threads

489
00:23:10,780 --> 00:23:16,070
every one of the virtual threads will

490
00:23:13,700 --> 00:23:19,160
have a scope local hash map for its

491
00:23:16,070 --> 00:23:20,990
local bindings when your program queries

492
00:23:19,160 --> 00:23:23,510
are scoped local it will search through

493
00:23:20,990 --> 00:23:27,440
the virtual threads through their

494
00:23:23,510 --> 00:23:29,600
parents through the structured

495
00:23:27,440 --> 00:23:31,400
concurrency if they essentially it looks

496
00:23:29,600 --> 00:23:33,980
like a cactus if you can imagine with

497
00:23:31,400 --> 00:23:34,610
multiple branches load the value into

498
00:23:33,980 --> 00:23:38,899
the care

499
00:23:34,610 --> 00:23:41,269
and the next time that that cache is

500
00:23:38,899 --> 00:23:45,080
queried it will find yours the value of

501
00:23:41,269 --> 00:23:47,450
your Scout local and lift it and that's

502
00:23:45,080 --> 00:23:49,100
very very fast worst-case is basically

503
00:23:47,450 --> 00:23:52,750
just a couple of instructions if you've

504
00:23:49,100 --> 00:23:57,110
got a cache hit for your scope local

505
00:23:52,750 --> 00:24:00,010
this works because scope locals are

506
00:23:57,110 --> 00:24:02,719
immutable this is absolutely crucial

507
00:24:00,010 --> 00:24:04,580
immutability is fantastic because once

508
00:24:02,720 --> 00:24:06,679
you've guaranteed that something is

509
00:24:04,580 --> 00:24:08,570
immutable you can copy it you can cache

510
00:24:06,679 --> 00:24:12,889
it you can do all of these wonderful

511
00:24:08,570 --> 00:24:16,510
things so by making thread locals less

512
00:24:12,889 --> 00:24:19,580
powerful giving them a fixed lifetime

513
00:24:16,510 --> 00:24:22,039
doing it in the simplest possible way

514
00:24:19,580 --> 00:24:25,460
what we've got is tremendously improved

515
00:24:22,039 --> 00:24:27,500
performance so we don't the effectively

516
00:24:25,460 --> 00:24:31,149
the cost of a scope locally is about the

517
00:24:27,500 --> 00:24:36,940
same as the cost of a load of a field

518
00:24:31,149 --> 00:24:36,939
from an object and I'm done

519
00:24:41,950 --> 00:24:44,010
you

