1
00:00:06,799 --> 00:00:10,800
okay

2
00:00:07,680 --> 00:00:14,920
everyone please welcome with me

3
00:00:10,800 --> 00:00:17,920
rohan and jose for some more cumulative

4
00:00:14,920 --> 00:00:17,920
fun

5
00:00:18,720 --> 00:00:23,439
all right welcome everyone uh we're here

6
00:00:21,520 --> 00:00:24,400
to discuss a relatively new feature that

7
00:00:23,439 --> 00:00:27,599
just made it

8
00:00:24,400 --> 00:00:30,080
that made it into rook um it's about

9
00:00:27,599 --> 00:00:31,599
how rook can now use persistent volumes

10
00:00:30,080 --> 00:00:34,320
to access its storage

11
00:00:31,599 --> 00:00:37,440
rather than going through a local host

12
00:00:34,320 --> 00:00:37,440
directly in kubernetes

13
00:00:37,600 --> 00:00:41,440
a fair warning this may contain opinion

14
00:00:39,600 --> 00:00:42,960
speculations and bad jokes that are

15
00:00:41,440 --> 00:00:45,039
entirely our fault

16
00:00:42,960 --> 00:00:46,559
uh please do not blame red hat ibm or

17
00:00:45,039 --> 00:00:49,120
the rogue project for anything we may or

18
00:00:46,559 --> 00:00:49,120
may not say

19
00:00:49,200 --> 00:00:54,000
all right who are we uh i'm jose i'm a

20
00:00:52,160 --> 00:00:55,599
senior software engineer at red hat

21
00:00:54,000 --> 00:00:57,520
i've been in and around storage for 10

22
00:00:55,600 --> 00:00:59,199
years i work with openshift container

23
00:00:57,520 --> 00:01:02,239
storage or ocs

24
00:00:59,199 --> 00:01:03,358
with a focus on rook and ceph i'm a

25
00:01:02,239 --> 00:01:05,280
project lead for

26
00:01:03,359 --> 00:01:08,720
the ocs operator which we will not be

27
00:01:05,280 --> 00:01:11,200
discussing in this talk that comes later

28
00:01:08,720 --> 00:01:12,158
and i tend to like hitting things mostly

29
00:01:11,200 --> 00:01:13,600
drums

30
00:01:12,159 --> 00:01:15,759
over here we have rohan gupta he

31
00:01:13,600 --> 00:01:20,080
graduated from college in 2018

32
00:01:15,759 --> 00:01:21,439
so young he also works in ocs with me

33
00:01:20,080 --> 00:01:22,770
he likes watching anime and riding

34
00:01:21,439 --> 00:01:24,720
motorbikes

35
00:01:22,770 --> 00:01:26,320
[Music]

36
00:01:24,720 --> 00:01:27,759
all right and here's where we're gonna

37
00:01:26,320 --> 00:01:29,919
go um

38
00:01:27,759 --> 00:01:31,280
we're gonna go through a bit of a setup

39
00:01:29,920 --> 00:01:32,560
i'm gonna skip a couple slides since

40
00:01:31,280 --> 00:01:33,600
most of you were already here for the

41
00:01:32,560 --> 00:01:36,640
rook talk

42
00:01:33,600 --> 00:01:37,919
um and then we're gonna go over how

43
00:01:36,640 --> 00:01:40,960
osd's work

44
00:01:37,920 --> 00:01:41,280
uh worked then and now um and hopefully

45
00:01:40,960 --> 00:01:45,839
give

46
00:01:41,280 --> 00:01:45,840
a proper demo uh network permitting

47
00:01:45,920 --> 00:01:51,840
all right to start storage in kubernetes

48
00:01:48,960 --> 00:01:53,679
um who here is familiar with general

49
00:01:51,840 --> 00:01:54,720
storage and kubernetes pvs pvcs and all

50
00:01:53,680 --> 00:01:55,920
that

51
00:01:54,720 --> 00:01:58,399
all right most of you this should be

52
00:01:55,920 --> 00:02:00,640
fairly easy all right so

53
00:01:58,399 --> 00:02:02,159
um you have pvs which are the

54
00:02:00,640 --> 00:02:03,520
representation of the actual storage

55
00:02:02,159 --> 00:02:06,719
volumes and kubernetes

56
00:02:03,520 --> 00:02:10,160
you have pvcs which which represent a

57
00:02:06,719 --> 00:02:12,319
user or developer request to use storage

58
00:02:10,160 --> 00:02:13,200
and you have storage classes which are a

59
00:02:12,319 --> 00:02:16,238
point of

60
00:02:13,200 --> 00:02:20,079
pvcs to create to buy to create

61
00:02:16,239 --> 00:02:22,400
to get access to and bind to pvs

62
00:02:20,080 --> 00:02:24,239
here's the general flow in a relatively

63
00:02:22,400 --> 00:02:26,480
small diagram

64
00:02:24,239 --> 00:02:27,920
slides will be available online if you

65
00:02:26,480 --> 00:02:31,840
want to look at it later

66
00:02:27,920 --> 00:02:33,280
but basically the user creates the

67
00:02:31,840 --> 00:02:35,519
persistent volume claim

68
00:02:33,280 --> 00:02:36,560
the admin or operator creates the

69
00:02:35,519 --> 00:02:38,480
storage class

70
00:02:36,560 --> 00:02:40,239
the pvc talks to the storage class which

71
00:02:38,480 --> 00:02:42,160
talks to the storage back end

72
00:02:40,239 --> 00:02:45,280
creates the persistent volume which then

73
00:02:42,160 --> 00:02:45,280
gets mounted by the pod

74
00:02:45,360 --> 00:02:49,040
all right now the new stuff raw block

75
00:02:47,680 --> 00:02:54,239
pvs

76
00:02:49,040 --> 00:02:57,840
uh this just went beta in 1.16

77
00:02:54,239 --> 00:03:00,000
i believe um and it allows kubernetes

78
00:02:57,840 --> 00:03:01,599
to present storage to containers

79
00:03:00,000 --> 00:03:02,319
basically without a formatted file

80
00:03:01,599 --> 00:03:04,879
system

81
00:03:02,319 --> 00:03:05,518
so uh if you've heard about block

82
00:03:04,879 --> 00:03:08,560
storage

83
00:03:05,519 --> 00:03:10,159
in kubernetes before this time um you

84
00:03:08,560 --> 00:03:12,800
weren't actually getting

85
00:03:10,159 --> 00:03:13,359
like actual block storage what you were

86
00:03:12,800 --> 00:03:15,760
getting

87
00:03:13,360 --> 00:03:16,800
was a file system formatted onto a block

88
00:03:15,760 --> 00:03:19,920
device

89
00:03:16,800 --> 00:03:23,120
uh but now with roblox pvs um

90
00:03:19,920 --> 00:03:25,920
kubernetes is able to present a

91
00:03:23,120 --> 00:03:26,959
actual uh to percent just a file because

92
00:03:25,920 --> 00:03:28,798
you know it's linux

93
00:03:26,959 --> 00:03:31,360
uh that represents the block storage

94
00:03:28,799 --> 00:03:33,840
device the the block storage device

95
00:03:31,360 --> 00:03:35,440
that can be used by the application

96
00:03:33,840 --> 00:03:39,599
running in the container

97
00:03:35,440 --> 00:03:42,720
um and many applications like databases

98
00:03:39,599 --> 00:03:46,000
mongodb cassandra already

99
00:03:42,720 --> 00:03:48,080
are capable of leveraging block devices

100
00:03:46,000 --> 00:03:49,760
for their storage with you know no

101
00:03:48,080 --> 00:03:51,040
additional configuration needed

102
00:03:49,760 --> 00:03:52,560
some of them require additional

103
00:03:51,040 --> 00:03:54,720
configuration if you want to use a

104
00:03:52,560 --> 00:03:57,920
pre-formatted file system

105
00:03:54,720 --> 00:03:59,519
um and you know generally avoiding the

106
00:03:57,920 --> 00:04:01,599
file system layer

107
00:03:59,519 --> 00:04:03,920
will tend to increase i o performance

108
00:04:01,599 --> 00:04:08,079
and give you lower latency

109
00:04:03,920 --> 00:04:11,359
so this was a much asked for feature

110
00:04:08,080 --> 00:04:11,360
for a while in kubernetes

111
00:04:11,680 --> 00:04:15,599
and the way they implemented this or the

112
00:04:14,239 --> 00:04:16,720
interface that they implemented for

113
00:04:15,599 --> 00:04:19,039
doing this is called the

114
00:04:16,720 --> 00:04:21,120
volume mode which is a new field in both

115
00:04:19,040 --> 00:04:23,600
pvcs and pvs

116
00:04:21,120 --> 00:04:25,600
that specify aha i was wrong it went

117
00:04:23,600 --> 00:04:28,639
beta and kubernetes 1.13

118
00:04:25,600 --> 00:04:31,040
there we go so um

119
00:04:28,639 --> 00:04:32,720
this basically takes one of two values

120
00:04:31,040 --> 00:04:33,520
and specifies how you want to access the

121
00:04:32,720 --> 00:04:36,639
volume

122
00:04:33,520 --> 00:04:38,639
either in file mode which is the default

123
00:04:36,639 --> 00:04:41,280
backwards compatible default

124
00:04:38,639 --> 00:04:42,320
uh yeah the backwards compatible default

125
00:04:41,280 --> 00:04:44,799
or uh

126
00:04:42,320 --> 00:04:45,599
block which is how you activate the new

127
00:04:44,800 --> 00:04:48,960
feature

128
00:04:45,600 --> 00:04:49,600
and this field must match in both the

129
00:04:48,960 --> 00:04:52,479
pvc

130
00:04:49,600 --> 00:04:54,240
and the pv uh this is similar to you

131
00:04:52,479 --> 00:04:57,599
know any other

132
00:04:54,240 --> 00:05:01,759
required field in a pvc that must match

133
00:04:57,600 --> 00:05:01,759
to a given pv to be bound to it

134
00:05:02,240 --> 00:05:07,039
uh here you have the yaml because you

135
00:05:04,639 --> 00:05:10,960
know lovely yaml don't we all love it

136
00:05:07,039 --> 00:05:14,719
um and you see down on the

137
00:05:10,960 --> 00:05:17,359
left uh in regular

138
00:05:14,720 --> 00:05:18,320
uh file volume mode you can just omit

139
00:05:17,360 --> 00:05:20,880
this field

140
00:05:18,320 --> 00:05:22,159
right because it defaults to file um and

141
00:05:20,880 --> 00:05:25,280
it would be the same in p

142
00:05:22,160 --> 00:05:28,639
in a pvc and over on the right

143
00:05:25,280 --> 00:05:31,119
you see the normal way of specifying uh

144
00:05:28,639 --> 00:05:32,160
where a pvc gets mounted inside the

145
00:05:31,120 --> 00:05:35,520
container

146
00:05:32,160 --> 00:05:38,240
using the volume mounts field specifying

147
00:05:35,520 --> 00:05:39,280
the name of the pvc and the mount path

148
00:05:38,240 --> 00:05:41,680
where it appears

149
00:05:39,280 --> 00:05:44,799
as and you know that's where the file

150
00:05:41,680 --> 00:05:44,800
system gets mounted

151
00:05:45,120 --> 00:05:49,120
volume mode block on the other hand you

152
00:05:47,039 --> 00:05:52,320
can't omit the volume mode obviously

153
00:05:49,120 --> 00:05:55,840
um even if you're using

154
00:05:52,320 --> 00:05:59,120
so the support of whether you can use

155
00:05:55,840 --> 00:06:01,599
file or block um is

156
00:05:59,120 --> 00:06:04,240
determined on a case-by-case basis for

157
00:06:01,600 --> 00:06:06,960
each storage provider in kubernetes

158
00:06:04,240 --> 00:06:08,880
so even if you choose a storage provider

159
00:06:06,960 --> 00:06:09,599
that somehow only supports volume mode

160
00:06:08,880 --> 00:06:11,840
block

161
00:06:09,600 --> 00:06:13,680
those may come um you still need to

162
00:06:11,840 --> 00:06:14,479
specify volume mode block because

163
00:06:13,680 --> 00:06:16,400
obviously

164
00:06:14,479 --> 00:06:17,758
it will default to file and if your

165
00:06:16,400 --> 00:06:22,159
search provider doesn't support

166
00:06:17,759 --> 00:06:22,160
file your pvc and pv won't bind

167
00:06:22,720 --> 00:06:26,880
the thing to note is that there is now

168
00:06:24,800 --> 00:06:30,400
also a new field in the pod spec

169
00:06:26,880 --> 00:06:31,440
called volume devices this is where you

170
00:06:30,400 --> 00:06:35,120
again specify

171
00:06:31,440 --> 00:06:35,680
the pvc name but instead you specify a

172
00:06:35,120 --> 00:06:38,160
device

173
00:06:35,680 --> 00:06:39,680
path which is the name of the file that

174
00:06:38,160 --> 00:06:42,880
will represent

175
00:06:39,680 --> 00:06:42,880
the storage device

176
00:06:44,000 --> 00:06:48,080
now a quick note here volume mode and

177
00:06:46,479 --> 00:06:51,520
axis mode are not the same

178
00:06:48,080 --> 00:06:52,080
thing no are they related um access

179
00:06:51,520 --> 00:06:55,919
modes

180
00:06:52,080 --> 00:06:59,120
uh as you may be aware um specify how a

181
00:06:55,919 --> 00:07:02,240
how pods may interact with a given pvc

182
00:06:59,120 --> 00:07:04,479
so rwx stands for read write many

183
00:07:02,240 --> 00:07:06,560
meaning that multiple pods can read and

184
00:07:04,479 --> 00:07:11,039
write to the same pvc

185
00:07:06,560 --> 00:07:15,199
um rwo stands for read read write once

186
00:07:11,039 --> 00:07:18,960
which means that only one pod can mount

187
00:07:15,199 --> 00:07:18,960
a pvc at a given time

188
00:07:20,080 --> 00:07:24,560
and the support of axis modes versus

189
00:07:23,599 --> 00:07:27,520
volume mode

190
00:07:24,560 --> 00:07:29,680
is again dependent on on the case by

191
00:07:27,520 --> 00:07:33,599
case basis for each storage provider

192
00:07:29,680 --> 00:07:37,440
so just because

193
00:07:33,599 --> 00:07:40,560
just because a storage provider supports

194
00:07:37,440 --> 00:07:42,719
rwx volumes in file mode does not

195
00:07:40,560 --> 00:07:45,039
necessarily mean they'll support rwx

196
00:07:42,720 --> 00:07:46,879
volumes in block mode

197
00:07:45,039 --> 00:07:48,960
so you have to know a little bit about

198
00:07:46,879 --> 00:07:52,560
which storage provider you're using

199
00:07:48,960 --> 00:07:52,560
uh to make sure that syncs up

200
00:07:53,680 --> 00:07:56,639
all right here's the slides i'm going to

201
00:07:54,879 --> 00:07:57,680
skip since we'll see you already here

202
00:07:56,639 --> 00:07:59,840
rook and stuff

203
00:07:57,680 --> 00:08:01,440
what is rook rook operators following

204
00:07:59,840 --> 00:08:05,119
the operator pattern

205
00:08:01,440 --> 00:08:06,960
um we're specifically interested

206
00:08:05,120 --> 00:08:08,240
in the rook seth operator since this is

207
00:08:06,960 --> 00:08:11,599
the first one

208
00:08:08,240 --> 00:08:13,120
to make use of this new uh pv pvc

209
00:08:11,599 --> 00:08:15,440
feature

210
00:08:13,120 --> 00:08:16,960
um and the main thing i want to go over

211
00:08:15,440 --> 00:08:20,800
here is that

212
00:08:16,960 --> 00:08:23,520
um all the stuff daemons are

213
00:08:20,800 --> 00:08:25,680
are encapsulated in their own pods that

214
00:08:23,520 --> 00:08:27,919
run across various notes in kubernetes

215
00:08:25,680 --> 00:08:31,039
uh the daemons we're interested in

216
00:08:27,919 --> 00:08:34,399
are the osd daemons um

217
00:08:31,039 --> 00:08:37,279
which are the ones that actually

218
00:08:34,399 --> 00:08:38,640
represent the underlying storage and in

219
00:08:37,279 --> 00:08:42,880
fact are the pods that

220
00:08:38,640 --> 00:08:42,880
bind to to the block devices

221
00:08:43,839 --> 00:08:48,160
all right osd's

222
00:08:48,560 --> 00:08:52,319
typically local storage osd's

223
00:08:52,880 --> 00:08:57,519
have access to our privileged pods that

224
00:08:56,080 --> 00:09:00,720
have access

225
00:08:57,519 --> 00:09:02,320
to the full slash dev directory of the

226
00:09:00,720 --> 00:09:05,120
host they run on

227
00:09:02,320 --> 00:09:06,959
um so the way you set this up is that

228
00:09:05,120 --> 00:09:09,920
you define your storage nodes

229
00:09:06,959 --> 00:09:11,040
um either by name by labels or you can

230
00:09:09,920 --> 00:09:14,160
use all nodes

231
00:09:11,040 --> 00:09:15,360
as specified here um

232
00:09:14,160 --> 00:09:17,439
and then you can then you have to

233
00:09:15,360 --> 00:09:18,399
specify your local devices and that can

234
00:09:17,440 --> 00:09:21,680
either be done

235
00:09:18,399 --> 00:09:24,399
by hand using uh

236
00:09:21,680 --> 00:09:25,199
you're using pv yamas or you can just

237
00:09:24,399 --> 00:09:27,200
use uh

238
00:09:25,200 --> 00:09:28,959
use all devices and make use of rooks

239
00:09:27,200 --> 00:09:32,320
auto discover daemon

240
00:09:28,959 --> 00:09:36,160
um and then takes care of the rest right

241
00:09:32,320 --> 00:09:38,080
so it has an osd prepared job that goes

242
00:09:36,160 --> 00:09:40,000
out and finds the devices

243
00:09:38,080 --> 00:09:41,839
and formats them appropriately to be

244
00:09:40,000 --> 00:09:44,880
used by the osds

245
00:09:41,839 --> 00:09:48,000
and then assigns given pvcs to

246
00:09:44,880 --> 00:09:48,000
particular osd's

247
00:09:49,279 --> 00:09:52,320
the advantage of this is that it's

248
00:09:50,720 --> 00:09:53,200
really the base case is really easy to

249
00:09:52,320 --> 00:09:55,760
configure

250
00:09:53,200 --> 00:09:57,519
um and for many people many storage

251
00:09:55,760 --> 00:09:59,200
admins coming into this in particular

252
00:09:57,519 --> 00:10:01,440
or in fact just anyone who's ever played

253
00:09:59,200 --> 00:10:02,480
with the linux system uh this is very

254
00:10:01,440 --> 00:10:04,240
familiar

255
00:10:02,480 --> 00:10:07,040
right because you're just directly

256
00:10:04,240 --> 00:10:08,959
accessing a given device at a given name

257
00:10:07,040 --> 00:10:12,800
on a given host

258
00:10:08,959 --> 00:10:14,959
right and it supports any type of device

259
00:10:12,800 --> 00:10:16,399
or appliance that linux supports

260
00:10:14,959 --> 00:10:18,479
right because all we care about is a

261
00:10:16,399 --> 00:10:19,600
file as long as there's a file

262
00:10:18,480 --> 00:10:21,519
representing

263
00:10:19,600 --> 00:10:24,640
uh that given block get that given

264
00:10:21,519 --> 00:10:27,120
storage volume we can make use of it

265
00:10:24,640 --> 00:10:29,040
the downside is at least in my opinion

266
00:10:27,120 --> 00:10:30,240
is that this relies on specialized

267
00:10:29,040 --> 00:10:32,800
storage nodes

268
00:10:30,240 --> 00:10:33,440
right so if you have a kubernetes

269
00:10:32,800 --> 00:10:35,279
cluster

270
00:10:33,440 --> 00:10:36,560
you need to have at least some of those

271
00:10:35,279 --> 00:10:38,720
nodes uh

272
00:10:36,560 --> 00:10:40,319
have local devices attached to them

273
00:10:38,720 --> 00:10:43,200
which may

274
00:10:40,320 --> 00:10:44,000
not be your standard compute node that

275
00:10:43,200 --> 00:10:46,720
you're using

276
00:10:44,000 --> 00:10:48,480
in the cluster um and in this case

277
00:10:46,720 --> 00:10:51,680
there's a rigid coupling

278
00:10:48,480 --> 00:10:54,560
between your compute and your storage

279
00:10:51,680 --> 00:10:55,920
um meaning that you know if a given if a

280
00:10:54,560 --> 00:10:57,518
given node goes down

281
00:10:55,920 --> 00:11:01,839
it brings down not only that node but

282
00:10:57,519 --> 00:11:01,839
the storage that goes along with it

283
00:11:02,399 --> 00:11:06,079
so we implemented something called

284
00:11:03,920 --> 00:11:09,199
storage class device sets

285
00:11:06,079 --> 00:11:12,160
it's a bit of a mouthful i know um

286
00:11:09,200 --> 00:11:14,240
so once again you define your storage

287
00:11:12,160 --> 00:11:17,439
nodes and your rook stuff cluster

288
00:11:14,240 --> 00:11:18,240
names labels are all but then you don't

289
00:11:17,440 --> 00:11:21,360
define your

290
00:11:18,240 --> 00:11:22,800
individual disks or you don't even yeah

291
00:11:21,360 --> 00:11:23,920
you don't define your individual disk

292
00:11:22,800 --> 00:11:27,519
you define

293
00:11:23,920 --> 00:11:31,120
a desired amount of storage right

294
00:11:27,519 --> 00:11:33,760
so um and then rook takes care

295
00:11:31,120 --> 00:11:35,839
of the same automation as before uh

296
00:11:33,760 --> 00:11:37,279
preparing the osds and starting the osd

297
00:11:35,839 --> 00:11:40,800
pods

298
00:11:37,279 --> 00:11:44,000
um what does this mean

299
00:11:40,800 --> 00:11:45,839
in that case so

300
00:11:44,000 --> 00:11:47,760
uh real quick here's what a storage

301
00:11:45,839 --> 00:11:50,000
class device set looks like

302
00:11:47,760 --> 00:11:51,920
um it was designed to be a generic rook

303
00:11:50,000 --> 00:11:54,079
struct but currently only rook ceph is

304
00:11:51,920 --> 00:11:56,639
using it

305
00:11:54,079 --> 00:11:58,399
you have to specify a name to give your

306
00:11:56,639 --> 00:12:01,920
set a unique identity

307
00:11:58,399 --> 00:12:05,519
that can map to the pvcs it generates so

308
00:12:01,920 --> 00:12:09,920
what this is going to do is it will

309
00:12:05,519 --> 00:12:13,279
dynamically provision a uh

310
00:12:09,920 --> 00:12:16,639
a pvc a single pvc for each osd

311
00:12:13,279 --> 00:12:18,959
pod right so now

312
00:12:16,639 --> 00:12:21,279
uh you're not going out and finding

313
00:12:18,959 --> 00:12:23,760
devices to attach your osd's

314
00:12:21,279 --> 00:12:26,800
you are defining your osd's and creating

315
00:12:23,760 --> 00:12:26,800
devices for them

316
00:12:27,200 --> 00:12:30,800
and then count is the number of devices

317
00:12:29,440 --> 00:12:34,320
you want in this set

318
00:12:30,800 --> 00:12:36,719
so you want you know a hundred gigabyte

319
00:12:34,320 --> 00:12:38,800
devices you want five of them

320
00:12:36,720 --> 00:12:41,040
in this particular set you specify five

321
00:12:38,800 --> 00:12:41,040
there

322
00:12:41,920 --> 00:12:46,479
we have a portable field that defines

323
00:12:44,320 --> 00:12:47,839
whether pvcs are allowed to move between

324
00:12:46,480 --> 00:12:50,000
nodes or not

325
00:12:47,839 --> 00:12:52,000
again this depends on your underlying

326
00:12:50,000 --> 00:12:54,079
storage provider

327
00:12:52,000 --> 00:12:56,639
some of them do allow pvcs to move

328
00:12:54,079 --> 00:13:00,319
between nodes some of them don't

329
00:12:56,639 --> 00:13:03,680
and then you have volume claim templates

330
00:13:00,320 --> 00:13:06,639
it is a list of pvc specs

331
00:13:03,680 --> 00:13:07,920
that's all it is currently only one is

332
00:13:06,639 --> 00:13:10,959
supported for rook

333
00:13:07,920 --> 00:13:11,920
we're looking to enable for a couple

334
00:13:10,959 --> 00:13:14,479
more

335
00:13:11,920 --> 00:13:18,319
um in the future to take to make use of

336
00:13:14,480 --> 00:13:18,320
more advanced features in rook stuff

337
00:13:19,040 --> 00:13:22,800
and yeah if you're at all familiar with

338
00:13:20,320 --> 00:13:24,639
the pvc spec uh

339
00:13:22,800 --> 00:13:27,920
basically it's just the it's just

340
00:13:24,639 --> 00:13:27,920
anything that can go into spec

341
00:13:29,519 --> 00:13:34,480
pros about this as far as i'm concerned

342
00:13:31,440 --> 00:13:38,079
um it offloads device distribution

343
00:13:34,480 --> 00:13:39,839
right so if you wanted to have

344
00:13:38,079 --> 00:13:42,800
robust storage you would generally have

345
00:13:39,839 --> 00:13:44,880
to make sure that your devices were

346
00:13:42,800 --> 00:13:46,719
properly distributed across nodes across

347
00:13:44,880 --> 00:13:50,560
zones across data centers

348
00:13:46,720 --> 00:13:52,480
um whereas in this case you can

349
00:13:50,560 --> 00:13:54,000
programmatically define what that

350
00:13:52,480 --> 00:13:56,639
distribution looks like

351
00:13:54,000 --> 00:14:00,000
and the devices will be provisioned at

352
00:13:56,639 --> 00:14:02,800
that distribution automatically

353
00:14:00,000 --> 00:14:03,600
and presuming your stor your underlying

354
00:14:02,800 --> 00:14:06,319
storage

355
00:14:03,600 --> 00:14:07,839
allows for it you can migrate devices

356
00:14:06,320 --> 00:14:11,279
between nodes

357
00:14:07,839 --> 00:14:13,519
um works with any raw block pv

358
00:14:11,279 --> 00:14:15,279
regardless of driver so if kubernetes

359
00:14:13,519 --> 00:14:17,600
supports it you can use it

360
00:14:15,279 --> 00:14:19,199
um and it's shiny and new some people

361
00:14:17,600 --> 00:14:20,399
like new features for the sake of them

362
00:14:19,199 --> 00:14:23,920
being different

363
00:14:20,399 --> 00:14:25,199
um on the on the downside this requires

364
00:14:23,920 --> 00:14:27,599
pre-defined storage

365
00:14:25,199 --> 00:14:29,359
classes so instead of having your

366
00:14:27,600 --> 00:14:33,199
previously defined devices you need to

367
00:14:29,360 --> 00:14:35,120
have a previously defined storage class

368
00:14:33,199 --> 00:14:36,639
which can only be done by a kubernetes

369
00:14:35,120 --> 00:14:39,279
cluster administrator

370
00:14:36,639 --> 00:14:40,320
so if for some reason uh if somehow

371
00:14:39,279 --> 00:14:42,480
you're running

372
00:14:40,320 --> 00:14:44,160
rook on someone else's cluster you'll

373
00:14:42,480 --> 00:14:45,760
need the admin to create the storage

374
00:14:44,160 --> 00:14:49,199
class for you

375
00:14:45,760 --> 00:14:50,880
um as while i said

376
00:14:49,199 --> 00:14:52,639
that you know anything that's supported

377
00:14:50,880 --> 00:14:54,480
in kubernetes is acceptable

378
00:14:52,639 --> 00:14:56,160
this is also limited only by what

379
00:14:54,480 --> 00:14:57,920
kubernetes accepts

380
00:14:56,160 --> 00:14:59,920
right so there must be a storage driver

381
00:14:57,920 --> 00:15:03,199
already existing in kubernetes

382
00:14:59,920 --> 00:15:04,719
for you to make use of this um

383
00:15:03,199 --> 00:15:06,719
it doesn't that is simple to configure

384
00:15:04,720 --> 00:15:09,440
the base case

385
00:15:06,720 --> 00:15:11,279
right is inherent is inherently more

386
00:15:09,440 --> 00:15:14,399
complicated to set up

387
00:15:11,279 --> 00:15:17,680
than the base case for how

388
00:15:14,399 --> 00:15:18,480
osd's used to be definable and it's new

389
00:15:17,680 --> 00:15:20,160
and different

390
00:15:18,480 --> 00:15:21,920
some people are suspicious of new

391
00:15:20,160 --> 00:15:26,560
features especially when they haven't

392
00:15:21,920 --> 00:15:29,360
been you know tested in the field yet

393
00:15:26,560 --> 00:15:31,599
all right and now we're going to go into

394
00:15:29,360 --> 00:15:33,360
some bumps and road that we

395
00:15:31,600 --> 00:15:35,600
ran along the way in trying to implement

396
00:15:33,360 --> 00:15:35,600
this

397
00:15:36,320 --> 00:15:40,399
so we asked developers when we write

398
00:15:37,920 --> 00:15:41,040
code and we think that when we will hit

399
00:15:40,399 --> 00:15:42,880
uh

400
00:15:41,040 --> 00:15:44,639
build it should just build and work out

401
00:15:42,880 --> 00:15:47,279
out of the box but that's

402
00:15:44,639 --> 00:15:48,720
never the case right so these are some

403
00:15:47,279 --> 00:15:50,560
of the issues which we face while

404
00:15:48,720 --> 00:15:54,160
writing this feature

405
00:15:50,560 --> 00:15:56,239
so og pods run as privileged pods so

406
00:15:54,160 --> 00:15:59,040
when kubernetes presents a blocked

407
00:15:56,240 --> 00:16:01,360
device to the privileged pod it's a

408
00:15:59,040 --> 00:16:02,560
bind mounted and it's uh presented in a

409
00:16:01,360 --> 00:16:04,639
different way

410
00:16:02,560 --> 00:16:06,160
so we don't get our block devices in the

411
00:16:04,639 --> 00:16:09,600
privileged containers

412
00:16:06,160 --> 00:16:11,199
and we uh really needed our blog devices

413
00:16:09,600 --> 00:16:13,040
on top of privilege containers because

414
00:16:11,199 --> 00:16:16,399
we were using lvm and

415
00:16:13,040 --> 00:16:17,759
we needed that so we uh uh figure out a

416
00:16:16,399 --> 00:16:21,040
work around so what we did

417
00:16:17,759 --> 00:16:24,720
we had a a common shared uh

418
00:16:21,040 --> 00:16:26,560
directory uh on an init container and we

419
00:16:24,720 --> 00:16:28,320
attached the block device to the init

420
00:16:26,560 --> 00:16:30,000
container which was not privileged

421
00:16:28,320 --> 00:16:31,920
and the osd container was running as a

422
00:16:30,000 --> 00:16:33,759
privileged container and as the shared

423
00:16:31,920 --> 00:16:35,199
directory was there

424
00:16:33,759 --> 00:16:37,440
in the in it container as well as the

425
00:16:35,199 --> 00:16:39,439
privileged container we found a way to

426
00:16:37,440 --> 00:16:42,880
copy the block device there

427
00:16:39,440 --> 00:16:45,120
to make it work i

428
00:16:42,880 --> 00:16:46,160
don't know if it is visible or not at

429
00:16:45,120 --> 00:16:48,720
the back but

430
00:16:46,160 --> 00:16:49,839
here on the right hand side if you see

431
00:16:48,720 --> 00:16:52,800
there is an empty

432
00:16:49,839 --> 00:16:53,839
directory that is a set one devon bridge

433
00:16:52,800 --> 00:16:57,199
and we have a

434
00:16:53,839 --> 00:16:59,759
block volume that is a set one dev zero

435
00:16:57,199 --> 00:17:00,959
that's uh that's mounted on the init

436
00:16:59,759 --> 00:17:02,880
container

437
00:17:00,959 --> 00:17:04,799
here on the left hand side we have the

438
00:17:02,880 --> 00:17:07,839
main osd port which has

439
00:17:04,799 --> 00:17:10,480
the only which has only the uh bridge

440
00:17:07,839 --> 00:17:11,760
directory and what init container is

441
00:17:10,480 --> 00:17:15,520
doing it's copying

442
00:17:11,760 --> 00:17:17,919
the set one dev0 device to the

443
00:17:15,520 --> 00:17:19,599
shared directory there and the shared

444
00:17:17,919 --> 00:17:22,000
directory is here so

445
00:17:19,599 --> 00:17:23,198
we get the block device here on the main

446
00:17:22,000 --> 00:17:25,119
osd container

447
00:17:23,199 --> 00:17:26,640
as we know uh in linux everything is

448
00:17:25,119 --> 00:17:27,438
presented as a file so we are just

449
00:17:26,640 --> 00:17:28,960
copying a file

450
00:17:27,439 --> 00:17:30,640
where the init container and we are

451
00:17:28,960 --> 00:17:33,840
getting it here on the

452
00:17:30,640 --> 00:17:33,840
main osd container

453
00:17:35,039 --> 00:17:39,280
so the next issue which we faced was

454
00:17:37,360 --> 00:17:40,479
when we were spinning up multiple osgs

455
00:17:39,280 --> 00:17:42,960
on the same node

456
00:17:40,480 --> 00:17:44,240
so we had the slash dev mounted on top

457
00:17:42,960 --> 00:17:46,320
of the container

458
00:17:44,240 --> 00:17:48,720
and the block device was presented to

459
00:17:46,320 --> 00:17:51,520
the pod as a loopback device

460
00:17:48,720 --> 00:17:52,640
so what was happening was that lvm was

461
00:17:51,520 --> 00:17:54,799
picking up the

462
00:17:52,640 --> 00:17:55,760
uh device from the slash dev as well as

463
00:17:54,799 --> 00:17:57,200
the loopback device

464
00:17:55,760 --> 00:17:59,360
and it was getting confused which device

465
00:17:57,200 --> 00:18:00,080
to pick for and the safe osd start

466
00:17:59,360 --> 00:18:03,360
command

467
00:18:00,080 --> 00:18:04,320
was the main thing that was confused for

468
00:18:03,360 --> 00:18:06,320
this

469
00:18:04,320 --> 00:18:07,678
so the solution we found out was we have

470
00:18:06,320 --> 00:18:10,080
to use the complete

471
00:18:07,679 --> 00:18:10,880
name of the lv that is slash df the name

472
00:18:10,080 --> 00:18:14,399
of the vg

473
00:18:10,880 --> 00:18:16,480
then the name of the lv

474
00:18:14,400 --> 00:18:17,760
and the other issue which we faced was

475
00:18:16,480 --> 00:18:20,320
proper distribution

476
00:18:17,760 --> 00:18:22,400
so when we suppose we are having uh six

477
00:18:20,320 --> 00:18:24,320
osds and on three nodes

478
00:18:22,400 --> 00:18:25,520
all the osgs were coming up on the same

479
00:18:24,320 --> 00:18:27,760
node which is

480
00:18:25,520 --> 00:18:29,360
where uh which is really not desired

481
00:18:27,760 --> 00:18:32,400
because we have the replicas

482
00:18:29,360 --> 00:18:34,159
of osgs suppose the replica is three

483
00:18:32,400 --> 00:18:36,480
and all the three replicas are on the

484
00:18:34,160 --> 00:18:38,880
same node and if the node goes down

485
00:18:36,480 --> 00:18:39,600
so we lose all the devices which is

486
00:18:38,880 --> 00:18:42,480
really

487
00:18:39,600 --> 00:18:44,590
bad for us so we to solve this we use

488
00:18:42,480 --> 00:18:46,080
placement affinities

489
00:18:44,590 --> 00:18:49,439
[Music]

490
00:18:46,080 --> 00:18:51,520
now the most interesting part the demo

491
00:18:49,440 --> 00:18:56,320
and we have a pic of cute cat that's

492
00:18:51,520 --> 00:18:59,520
praying hope this works

493
00:18:56,320 --> 00:19:01,678
okay so uh we have three osd's running

494
00:18:59,520 --> 00:19:04,320
here

495
00:19:01,679 --> 00:19:06,000
which uh one is on two four seven one is

496
00:19:04,320 --> 00:19:06,720
on two three three and one is on one

497
00:19:06,000 --> 00:19:10,160
five six

498
00:19:06,720 --> 00:19:14,000
nodes and if we see the status

499
00:19:10,160 --> 00:19:14,000
of ceph it's uh healthy

500
00:19:14,240 --> 00:19:18,160
and we are using an openshift cluster

501
00:19:16,320 --> 00:19:19,918
because our internal

502
00:19:18,160 --> 00:19:25,840
automation makes it easier for us to

503
00:19:19,919 --> 00:19:25,840
spin the clusters so

504
00:19:27,280 --> 00:19:31,360
we're using red hat because red hat

505
00:19:31,760 --> 00:19:35,679
uh we have four worker nodes here so

506
00:19:34,000 --> 00:19:37,039
which is our on three nodes

507
00:19:35,679 --> 00:19:38,559
and what we are going to do is we are

508
00:19:37,039 --> 00:19:39,840
going to delete one of the node which

509
00:19:38,559 --> 00:19:42,399
has the osg running on it

510
00:19:39,840 --> 00:19:53,840
and that osg is going to migrate on

511
00:19:42,400 --> 00:19:53,840
another node

512
00:20:01,600 --> 00:20:07,039
so uh i'm gonna delete this 156 machine

513
00:20:05,120 --> 00:20:09,039
and hope the osd is migrate to the

514
00:20:07,039 --> 00:20:12,400
different node and

515
00:20:09,039 --> 00:20:21,840
for 156 um

516
00:20:12,400 --> 00:20:21,840
yep here is the machine for that

517
00:20:31,679 --> 00:20:36,320
okay we deleted the machine and

518
00:20:34,799 --> 00:20:38,400
one of the osd went to the pending state

519
00:20:36,320 --> 00:20:40,960
because it's looking for the node

520
00:20:38,400 --> 00:20:42,559
and we see there is another osd that

521
00:20:40,960 --> 00:20:44,320
also in a pending state because it's

522
00:20:42,559 --> 00:20:49,840
looking for a new node to

523
00:20:44,320 --> 00:20:49,840
jump to and

524
00:20:51,360 --> 00:20:53,678
okay

525
00:20:55,679 --> 00:21:00,799
the toolbox there we go yep so

526
00:20:58,720 --> 00:21:03,039
uh one of the more is down because it

527
00:21:00,799 --> 00:21:05,760
was there on the node which i deleted

528
00:21:03,039 --> 00:21:07,120
and we have three usds two are up and

529
00:21:05,760 --> 00:21:09,760
three are in

530
00:21:07,120 --> 00:21:10,799
so uh one osu that is in pending state

531
00:21:09,760 --> 00:21:12,640
is the one which

532
00:21:10,799 --> 00:21:14,400
was lost because of the machine which

533
00:21:12,640 --> 00:21:16,000
was deleted

534
00:21:14,400 --> 00:21:17,520
and let's wait for it to come back on

535
00:21:16,000 --> 00:21:20,880
another note do you

536
00:21:17,520 --> 00:21:23,440
see get pods on the on the storage uh

537
00:21:20,880 --> 00:21:23,440
name space

538
00:21:23,919 --> 00:21:28,840
oh it's already running yep so uh the

539
00:21:26,799 --> 00:21:32,480
oasis back uh

540
00:21:28,840 --> 00:21:35,520
and in some time the health will be

541
00:21:32,480 --> 00:21:36,559
okay there it is so

542
00:21:35,520 --> 00:21:39,200
it's still in the morning because of the

543
00:21:36,559 --> 00:21:41,600
money's down yep but the osd pod came

544
00:21:39,200 --> 00:21:41,600
back up

545
00:21:42,320 --> 00:21:45,520
so yes and then at some point the ceph

546
00:21:44,080 --> 00:21:49,039
cluster will reconcile but

547
00:21:45,520 --> 00:21:49,039
our feature succeeded

548
00:21:53,440 --> 00:21:58,080
oh and it just went health okay all

549
00:21:55,760 --> 00:22:01,120
right thank you

550
00:21:58,080 --> 00:22:04,080
but wait there's more

551
00:22:01,120 --> 00:22:05,678
but wait there's more uh you may have

552
00:22:04,080 --> 00:22:07,520
noticed that we omitted one key thing

553
00:22:05,679 --> 00:22:11,440
that some of you may be interested in

554
00:22:07,520 --> 00:22:13,280
what about on premises

555
00:22:11,440 --> 00:22:15,120
i kept talking about you know osd

556
00:22:13,280 --> 00:22:16,799
portability and

557
00:22:15,120 --> 00:22:18,479
migrating between nodes and all that

558
00:22:16,799 --> 00:22:19,600
which is all great for cloud

559
00:22:18,480 --> 00:22:23,039
environments

560
00:22:19,600 --> 00:22:26,158
and the demo was on aws right

561
00:22:23,039 --> 00:22:27,600
but you know we don't necessarily we it

562
00:22:26,159 --> 00:22:28,320
sounds like we're leaving you know

563
00:22:27,600 --> 00:22:31,840
traditional

564
00:22:28,320 --> 00:22:34,720
on-prem um storage in the lurch

565
00:22:31,840 --> 00:22:37,439
not the case uh because also in

566
00:22:34,720 --> 00:22:41,600
kubernetes 1.14

567
00:22:37,440 --> 00:22:45,039
we have the notion of local block pvs so

568
00:22:41,600 --> 00:22:46,799
uh or rather also in 114 we have the

569
00:22:45,039 --> 00:22:50,158
notion of local pvs

570
00:22:46,799 --> 00:22:52,080
which when combined with the when

571
00:22:50,159 --> 00:22:55,919
which when combined with the block pv

572
00:22:52,080 --> 00:22:58,720
gives you obviously local block pvs

573
00:22:55,919 --> 00:23:00,400
and it allows you to access local

574
00:22:58,720 --> 00:23:03,360
volumes via the pvc

575
00:23:00,400 --> 00:23:04,640
pv interface rather than specifying a

576
00:23:03,360 --> 00:23:08,000
direct host path

577
00:23:04,640 --> 00:23:11,280
on a given node in the pod spec

578
00:23:08,000 --> 00:23:14,240
right so this is trying to decouple the

579
00:23:11,280 --> 00:23:15,039
uh specification of local storage from a

580
00:23:14,240 --> 00:23:18,080
pod

581
00:23:15,039 --> 00:23:20,000
to a separate entity um

582
00:23:18,080 --> 00:23:21,760
and the way this works is that you

583
00:23:20,000 --> 00:23:24,400
create a local pv

584
00:23:21,760 --> 00:23:25,520
with a storage class name and you have

585
00:23:24,400 --> 00:23:28,559
to specify

586
00:23:25,520 --> 00:23:30,080
a node affinity so

587
00:23:28,559 --> 00:23:32,399
you see there in bold there's the

588
00:23:30,080 --> 00:23:33,439
storage class name above it is volume

589
00:23:32,400 --> 00:23:35,520
mode block

590
00:23:33,440 --> 00:23:38,480
and then a node affinity that specifies

591
00:23:35,520 --> 00:23:40,879
what node this device is on

592
00:23:38,480 --> 00:23:40,880
all right

593
00:23:42,720 --> 00:23:46,960
so then what you have to do is create a

594
00:23:44,720 --> 00:23:49,360
storage class using no provisioner

595
00:23:46,960 --> 00:23:50,720
right because the device already exists

596
00:23:49,360 --> 00:23:53,678
so there's nothing to

597
00:23:50,720 --> 00:23:54,960
provision in that case and then you

598
00:23:53,679 --> 00:23:58,080
specify something called

599
00:23:54,960 --> 00:24:01,200
volume binding mode equal wake for

600
00:23:58,080 --> 00:24:02,960
first consumer which enables a new

601
00:24:01,200 --> 00:24:04,559
feature called topology aware

602
00:24:02,960 --> 00:24:07,039
provisioning

603
00:24:04,559 --> 00:24:09,039
what this does is that it allows the

604
00:24:07,039 --> 00:24:12,320
kubernetes pod scheduler

605
00:24:09,039 --> 00:24:12,960
to take into account the locality of the

606
00:24:12,320 --> 00:24:16,158
pv

607
00:24:12,960 --> 00:24:18,400
the pod is binding to

608
00:24:16,159 --> 00:24:19,279
all right so when the scheduler is

609
00:24:18,400 --> 00:24:22,480
calculating

610
00:24:19,279 --> 00:24:25,919
what nodes the pod can be scheduled on

611
00:24:22,480 --> 00:24:29,200
it will you know it will uh ping

612
00:24:25,919 --> 00:24:31,279
the pv spec to see if it has any

613
00:24:29,200 --> 00:24:32,799
uh locality information like a node

614
00:24:31,279 --> 00:24:35,440
affinity

615
00:24:32,799 --> 00:24:38,960
and input that into its algorithm to get

616
00:24:35,440 --> 00:24:41,919
a list of valid nodes

617
00:24:38,960 --> 00:24:42,640
and then after that you just create your

618
00:24:41,919 --> 00:24:46,720
pvc

619
00:24:42,640 --> 00:24:48,159
and pod spec as normal um so

620
00:24:46,720 --> 00:24:50,240
in this case you would just create

621
00:24:48,159 --> 00:24:52,240
another pvc that specifies

622
00:24:50,240 --> 00:24:54,000
oh yeah it's right there the specifies

623
00:24:52,240 --> 00:24:57,279
the local storage

624
00:24:54,000 --> 00:24:58,159
um storage class which i just made these

625
00:24:57,279 --> 00:24:59,840
slides like

626
00:24:58,159 --> 00:25:01,520
30 minutes ago so i guess i forgot to

627
00:24:59,840 --> 00:25:03,918
specify the storage class

628
00:25:01,520 --> 00:25:05,760
um and then you make sure the parameters

629
00:25:03,919 --> 00:25:07,840
match the pv you want

630
00:25:05,760 --> 00:25:09,600
read write want block mode same storage

631
00:25:07,840 --> 00:25:12,720
size

632
00:25:09,600 --> 00:25:13,678
and that's it so there's a lot of work

633
00:25:12,720 --> 00:25:15,520
on the back end

634
00:25:13,679 --> 00:25:17,360
for the administrator to take care of

635
00:25:15,520 --> 00:25:18,960
right because the administrator is the

636
00:25:17,360 --> 00:25:20,719
one that wants to be creating the local

637
00:25:18,960 --> 00:25:21,360
pvs and the storage class associated

638
00:25:20,720 --> 00:25:23,520
with it

639
00:25:21,360 --> 00:25:25,199
but from the developer point of view and

640
00:25:23,520 --> 00:25:27,679
right don't we all just love developers

641
00:25:25,200 --> 00:25:30,559
and making their lives easier

642
00:25:27,679 --> 00:25:32,880
it's no different than using any other

643
00:25:30,559 --> 00:25:36,320
storage

644
00:25:32,880 --> 00:25:36,320
all right thanks again

645
00:25:40,320 --> 00:25:47,520
questions question time anyone

646
00:25:43,679 --> 00:25:50,559
we got one you yeah

647
00:25:47,520 --> 00:25:53,918
and so you mentioned about rook

648
00:25:50,559 --> 00:25:56,000
and oh i need that i need that hold on

649
00:25:53,919 --> 00:25:57,279
just repeat it you mentioned rook and

650
00:25:56,000 --> 00:26:00,799
osd's using

651
00:25:57,279 --> 00:26:04,320
um block level pv but what about

652
00:26:00,799 --> 00:26:07,440
providing level pvs with rbd

653
00:26:04,320 --> 00:26:10,720
to other applications that is

654
00:26:07,440 --> 00:26:14,159
dependent entirely on the oh yeah uh

655
00:26:10,720 --> 00:26:17,679
what about rook providing block mode pvs

656
00:26:14,159 --> 00:26:20,880
from from from like say rbd in ceph

657
00:26:17,679 --> 00:26:22,720
um that is entirely dependent on the

658
00:26:20,880 --> 00:26:24,799
storage driver itself

659
00:26:22,720 --> 00:26:26,880
not the operator and i'm happy to say

660
00:26:24,799 --> 00:26:30,240
it's supported in sep csi

661
00:26:26,880 --> 00:26:32,720
so ceph csi rbd will support block mode

662
00:26:30,240 --> 00:26:32,720
pvs

663
00:26:36,080 --> 00:26:40,158
all right i'm going to say either i was

664
00:26:38,159 --> 00:26:42,320
not very interesting or i was very or i

665
00:26:40,159 --> 00:26:46,000
described myself very well

666
00:26:42,320 --> 00:26:48,480
oh here we go duplicate pv

667
00:26:46,000 --> 00:26:49,760
issue in lvm any reason you didn't solve

668
00:26:48,480 --> 00:26:53,279
that via lvm

669
00:26:49,760 --> 00:26:56,480
filters uh duplicate pvs

670
00:26:53,279 --> 00:26:58,559
and duplicate pvs in lvm

671
00:26:56,480 --> 00:26:59,679
uh any reason why we didn't solve that

672
00:26:58,559 --> 00:27:01,520
in this feature

673
00:26:59,679 --> 00:27:03,520
uh quite frankly because i'm not aware

674
00:27:01,520 --> 00:27:05,279
of it so

675
00:27:03,520 --> 00:27:06,639
uh i can look into that and see what we

676
00:27:05,279 --> 00:27:08,880
can do about it yeah you can just tell

677
00:27:06,640 --> 00:27:10,640
lvm to ignore certain devices

678
00:27:08,880 --> 00:27:12,559
with the records so if you have like

679
00:27:10,640 --> 00:27:14,320
that loop whatever

680
00:27:12,559 --> 00:27:16,158
you just tell lvm to ignore that and

681
00:27:14,320 --> 00:27:19,360
this error will go away

682
00:27:16,159 --> 00:27:21,360
we didn't know that there you go

683
00:27:19,360 --> 00:27:23,199
right so apparently there's a feat you

684
00:27:21,360 --> 00:27:26,479
can just use a regex to

685
00:27:23,200 --> 00:27:30,080
have uh lvm ignore certain devices

686
00:27:26,480 --> 00:27:32,399
but we didn't knew that then

687
00:27:30,080 --> 00:27:33,840
or did i'm wondering if that wasn't

688
00:27:32,399 --> 00:27:36,479
because we couldn't guarantee the name

689
00:27:33,840 --> 00:27:36,480
of the device

690
00:27:36,720 --> 00:27:41,760
um no we had the name okay

691
00:27:39,840 --> 00:27:43,120
so yeah might be something to look into

692
00:27:41,760 --> 00:27:45,360
again

693
00:27:43,120 --> 00:27:45,360
all right

694
00:27:46,240 --> 00:27:49,840
all right we good thank you

695
00:27:52,240 --> 00:28:02,480
thanks guys

