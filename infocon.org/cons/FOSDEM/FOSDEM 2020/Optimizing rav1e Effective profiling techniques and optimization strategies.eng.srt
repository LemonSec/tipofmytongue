1
00:00:05,359 --> 00:00:10,639
thank you

2
00:00:06,799 --> 00:00:14,400
so uh who i am

3
00:00:10,639 --> 00:00:15,360
i'm luca i contribute to many open

4
00:00:14,400 --> 00:00:17,680
source

5
00:00:15,360 --> 00:00:18,880
softwares lately i'm focusing on

6
00:00:17,680 --> 00:00:21,520
everyone

7
00:00:18,880 --> 00:00:22,320
and i'm a contributor for reddy and

8
00:00:21,520 --> 00:00:25,680
david

9
00:00:22,320 --> 00:00:29,679
and today i will talk to you about

10
00:00:25,680 --> 00:00:33,519
ravy and how we managed to optimize it

11
00:00:29,679 --> 00:00:36,719
so what is review is an

12
00:00:33,520 --> 00:00:39,760
ev1 encoder is written in rust

13
00:00:36,719 --> 00:00:40,960
currently does have a large amount of

14
00:00:39,760 --> 00:00:45,680
cmd

15
00:00:40,960 --> 00:00:48,480
either by importing what is written

16
00:00:45,680 --> 00:00:50,079
in david in plain assembly either

17
00:00:48,480 --> 00:00:53,279
written directly

18
00:00:50,079 --> 00:00:54,879
using the ras intrinsics provided by std

19
00:00:53,280 --> 00:00:57,520
arch

20
00:00:54,879 --> 00:00:58,399
it does have a good deal of multi-thread

21
00:00:57,520 --> 00:01:01,520
code

22
00:00:58,399 --> 00:01:04,480
and most of it is leveraging radiant

23
00:01:01,520 --> 00:01:04,480
because we are lazy

24
00:01:04,879 --> 00:01:08,640
today i will show you how we managed to

25
00:01:07,439 --> 00:01:11,279
get there

26
00:01:08,640 --> 00:01:12,000
which tool we managed to use what

27
00:01:11,280 --> 00:01:15,280
managed to work

28
00:01:12,000 --> 00:01:18,799
well and which crates

29
00:01:15,280 --> 00:01:22,240
make your life much easier

30
00:01:18,799 --> 00:01:23,840
so why optimizing if you have your

31
00:01:22,240 --> 00:01:27,119
software is working

32
00:01:23,840 --> 00:01:29,439
done right well no

33
00:01:27,119 --> 00:01:30,640
you might want to put your software in

34
00:01:29,439 --> 00:01:33,679
something that is tiny

35
00:01:30,640 --> 00:01:34,400
so you want to optimize for size you

36
00:01:33,680 --> 00:01:37,439
want to

37
00:01:34,400 --> 00:01:38,799
use your software for certain purpose in

38
00:01:37,439 --> 00:01:41,520
the case of

39
00:01:38,799 --> 00:01:44,240
a video encoder or even a database you

40
00:01:41,520 --> 00:01:46,079
want to optimize for latency

41
00:01:44,240 --> 00:01:48,000
you export something you want something

42
00:01:46,079 --> 00:01:50,240
back as soon as possible

43
00:01:48,000 --> 00:01:51,680
you send a frame to the encoder you want

44
00:01:50,240 --> 00:01:54,960
it back immediately

45
00:01:51,680 --> 00:01:57,200
so you can put down to the network

46
00:01:54,960 --> 00:01:59,039
on the other side a normal video

47
00:01:57,200 --> 00:02:02,320
conference scenario

48
00:01:59,040 --> 00:02:04,960
or security scenarios

49
00:02:02,320 --> 00:02:04,960
there are many

50
00:02:05,439 --> 00:02:11,200
you want to put your software on mobile

51
00:02:08,959 --> 00:02:13,280
then you have two different problems one

52
00:02:11,200 --> 00:02:15,359
you don't want to drain your battery

53
00:02:13,280 --> 00:02:16,640
and the other you don't want to burn the

54
00:02:15,360 --> 00:02:19,360
device

55
00:02:16,640 --> 00:02:20,559
because sadly the mobile cpu can be

56
00:02:19,360 --> 00:02:22,800
really fast

57
00:02:20,560 --> 00:02:24,560
but just for that amount of time then it

58
00:02:22,800 --> 00:02:28,879
gets dangerous

59
00:02:24,560 --> 00:02:32,640
so many reasons to optimize

60
00:02:28,879 --> 00:02:35,280
another use case you just want to be

61
00:02:32,640 --> 00:02:38,559
a resource conscious you don't want to

62
00:02:35,280 --> 00:02:40,720
pay that much money to run your business

63
00:02:38,560 --> 00:02:42,319
so you want to optimize for throughput

64
00:02:40,720 --> 00:02:45,280
that is a different target

65
00:02:42,319 --> 00:02:46,799
it's a mix between optimizing for speed

66
00:02:45,280 --> 00:02:49,120
cpu usage

67
00:02:46,800 --> 00:02:50,879
and other resources mainly you are

68
00:02:49,120 --> 00:02:53,200
optimizing for money

69
00:02:50,879 --> 00:02:55,280
and last but not least you want to prove

70
00:02:53,200 --> 00:02:57,280
that you are the smartest guy

71
00:02:55,280 --> 00:02:59,120
so you want to make the whole thing as

72
00:02:57,280 --> 00:03:01,760
fast as possible

73
00:02:59,120 --> 00:03:02,640
that works is not exactly a good reason

74
00:03:01,760 --> 00:03:05,440
but

75
00:03:02,640 --> 00:03:07,200
if you have multiple competing projects

76
00:03:05,440 --> 00:03:11,280
it is a good reason to have a

77
00:03:07,200 --> 00:03:14,720
some kind of healthy competition so

78
00:03:11,280 --> 00:03:16,319
why we are optimizing bravia what

79
00:03:14,720 --> 00:03:19,280
what we want to do well concord the

80
00:03:16,319 --> 00:03:22,159
world but

81
00:03:19,280 --> 00:03:23,599
we are talking about video encoding so

82
00:03:22,159 --> 00:03:25,920
for video encoding

83
00:03:23,599 --> 00:03:28,159
you have different targets maybe you

84
00:03:25,920 --> 00:03:31,119
want to have the best quality

85
00:03:28,159 --> 00:03:32,159
that's something sort of esoteric

86
00:03:31,120 --> 00:03:34,000
because

87
00:03:32,159 --> 00:03:35,599
quality in video is something that is

88
00:03:34,000 --> 00:03:39,040
not exactly objective

89
00:03:35,599 --> 00:03:41,839
it's mostly subjective so

90
00:03:39,040 --> 00:03:43,519
you put all the time possible all the

91
00:03:41,840 --> 00:03:46,159
memory possible

92
00:03:43,519 --> 00:03:47,680
everything possible to get the best

93
00:03:46,159 --> 00:03:50,959
looking video

94
00:03:47,680 --> 00:03:53,680
that's one target you care about the

95
00:03:50,959 --> 00:03:56,640
single encoding speed

96
00:03:53,680 --> 00:03:59,360
some kind of track racing okay i have a

97
00:03:56,640 --> 00:04:01,920
single video and i want it

98
00:03:59,360 --> 00:04:04,480
it immediately or as fast as possible i

99
00:04:01,920 --> 00:04:08,159
don't care about the rest

100
00:04:04,480 --> 00:04:11,439
as stress as track racing is as useful

101
00:04:08,159 --> 00:04:14,560
in my opinion but it's a good benchmark

102
00:04:11,439 --> 00:04:16,000
sort of so to speak lowest possible

103
00:04:14,560 --> 00:04:17,918
latency

104
00:04:16,000 --> 00:04:19,839
great for security great for video

105
00:04:17,918 --> 00:04:23,198
conference

106
00:04:19,839 --> 00:04:24,479
in the case the amount of cpu that you

107
00:04:23,199 --> 00:04:26,400
can throw at the problem

108
00:04:24,479 --> 00:04:29,840
is limited by the fact that latency

109
00:04:26,400 --> 00:04:32,799
requires you to get the frame out

110
00:04:29,840 --> 00:04:33,520
so you can try to use multiple threads

111
00:04:32,800 --> 00:04:37,520
if you cut

112
00:04:33,520 --> 00:04:40,400
cut the frame but you are restricting

113
00:04:37,520 --> 00:04:41,280
the trick that you can use maximum

114
00:04:40,400 --> 00:04:44,159
throughput

115
00:04:41,280 --> 00:04:46,559
that is i don't want to spend that much

116
00:04:44,160 --> 00:04:50,000
money to get results

117
00:04:46,560 --> 00:04:53,360
this is another thing that is a bit more

118
00:04:50,000 --> 00:04:56,160
harder than just being getting the best

119
00:04:53,360 --> 00:05:00,000
quality or getting the best speed

120
00:04:56,160 --> 00:05:02,960
you have to consider multiple trade-offs

121
00:05:00,000 --> 00:05:03,600
because you can have a batch of videos

122
00:05:02,960 --> 00:05:06,400
you have

123
00:05:03,600 --> 00:05:07,919
that much amount of money and you want

124
00:05:06,400 --> 00:05:10,799
to get them through

125
00:05:07,919 --> 00:05:11,919
and have the result that has the right

126
00:05:10,800 --> 00:05:15,120
quality

127
00:05:11,919 --> 00:05:18,320
and take the right amount of time but

128
00:05:15,120 --> 00:05:18,320
your target is money

129
00:05:18,560 --> 00:05:23,520
what driving is trying to do is to get

130
00:05:22,000 --> 00:05:25,280
in the right place in between all of

131
00:05:23,520 --> 00:05:28,479
those and

132
00:05:25,280 --> 00:05:31,280
as you may notice quality

133
00:05:28,479 --> 00:05:32,880
doesn't care about the results that you

134
00:05:31,280 --> 00:05:36,479
are throwing off

135
00:05:32,880 --> 00:05:39,520
money is pretty much the best proxy for

136
00:05:36,479 --> 00:05:41,199
all the possible resources so you want

137
00:05:39,520 --> 00:05:45,039
to get in between

138
00:05:41,199 --> 00:05:48,479
the right quality not spending too much

139
00:05:45,039 --> 00:05:49,120
and obviously not taking ages to get

140
00:05:48,479 --> 00:05:53,120
results

141
00:05:49,120 --> 00:05:56,240
because otherwise it's pointless

142
00:05:53,120 --> 00:06:00,800
so what i mean with

143
00:05:56,240 --> 00:06:00,800
optimization how we do optimize

144
00:06:01,120 --> 00:06:06,000
you need to pick your target what you

145
00:06:04,319 --> 00:06:07,759
want to optimize for

146
00:06:06,000 --> 00:06:10,479
if you have multiple targets it's better

147
00:06:07,759 --> 00:06:13,759
if you pick one or two at most

148
00:06:10,479 --> 00:06:15,440
at the same time you iterate you manage

149
00:06:13,759 --> 00:06:17,840
to measure

150
00:06:15,440 --> 00:06:19,120
how far you are so how much time am i

151
00:06:17,840 --> 00:06:21,198
spending

152
00:06:19,120 --> 00:06:23,199
how much time i spending in each

153
00:06:21,199 --> 00:06:27,840
function and so on and so forth

154
00:06:23,199 --> 00:06:31,840
or how many how much memory i'm using

155
00:06:27,840 --> 00:06:35,198
or which is my bill for this month

156
00:06:31,840 --> 00:06:38,318
and once you do that you can pick

157
00:06:35,199 --> 00:06:41,680
what you want to change you change it

158
00:06:38,319 --> 00:06:42,319
is the results good enough okay you move

159
00:06:41,680 --> 00:06:45,520
to the

160
00:06:42,319 --> 00:06:49,840
next target you are not happy yet

161
00:06:45,520 --> 00:06:49,840
with the result measure again

162
00:06:50,000 --> 00:06:55,759
so fairly simple right

163
00:06:53,360 --> 00:06:57,599
who did something like that please raise

164
00:06:55,759 --> 00:07:00,639
your hand

165
00:06:57,599 --> 00:07:03,120
okay nothing new

166
00:07:00,639 --> 00:07:04,720
so let me unpack a little for the people

167
00:07:03,120 --> 00:07:08,160
that didn't

168
00:07:04,720 --> 00:07:11,440
experience that so

169
00:07:08,160 --> 00:07:13,520
we start we pick a target we select the

170
00:07:11,440 --> 00:07:15,919
use case

171
00:07:13,520 --> 00:07:17,440
when we are measuring and splitting the

172
00:07:15,919 --> 00:07:20,479
task in two

173
00:07:17,440 --> 00:07:21,599
we profile and we benchmark the two

174
00:07:20,479 --> 00:07:24,719
things

175
00:07:21,599 --> 00:07:26,560
are a little different even if are sort

176
00:07:24,720 --> 00:07:29,360
of synonymous

177
00:07:26,560 --> 00:07:30,319
then we do our evaluation and then we

178
00:07:29,360 --> 00:07:35,120
change the code

179
00:07:30,319 --> 00:07:35,120
and the loop continue so

180
00:07:35,199 --> 00:07:42,800
let's say we are talking about metrics

181
00:07:39,440 --> 00:07:46,160
many of them are completely objective

182
00:07:42,800 --> 00:07:50,000
single execution time is easy you just

183
00:07:46,160 --> 00:07:53,360
use the wall clock basically latency

184
00:07:50,000 --> 00:07:54,879
is easy as well you just

185
00:07:53,360 --> 00:07:56,560
send a frame and measure when you're

186
00:07:54,879 --> 00:07:59,840
getting it back

187
00:07:56,560 --> 00:08:00,240
simple memory usage okay who doesn't

188
00:07:59,840 --> 00:08:03,280
know

189
00:08:00,240 --> 00:08:07,039
what is the maximum residence set

190
00:08:03,280 --> 00:08:10,840
we never hear about that okay

191
00:08:07,039 --> 00:08:12,318
so basically when we are running an

192
00:08:10,840 --> 00:08:14,719
application

193
00:08:12,319 --> 00:08:17,039
your operating system is giving the

194
00:08:14,720 --> 00:08:19,440
application the right amount of memory

195
00:08:17,039 --> 00:08:21,039
some of it has to be present all the

196
00:08:19,440 --> 00:08:23,759
time some of it can be

197
00:08:21,039 --> 00:08:25,120
swapped around because the operating

198
00:08:23,759 --> 00:08:28,400
system can be

199
00:08:25,120 --> 00:08:30,560
smart enough the maximum resistance set

200
00:08:28,400 --> 00:08:31,758
is that amount of memory that your

201
00:08:30,560 --> 00:08:34,399
application

202
00:08:31,759 --> 00:08:36,240
absolutely needs so cannot be swapped

203
00:08:34,399 --> 00:08:39,360
around

204
00:08:36,240 --> 00:08:40,959
if you don't have enough the system is

205
00:08:39,360 --> 00:08:42,240
going to kill your application once you

206
00:08:40,958 --> 00:08:43,838
try to assess the memory if we are

207
00:08:42,240 --> 00:08:45,279
talking about linux

208
00:08:43,839 --> 00:08:47,440
other operating system are more

209
00:08:45,279 --> 00:08:48,720
conservative your application is not

210
00:08:47,440 --> 00:08:50,959
going to run

211
00:08:48,720 --> 00:08:52,880
it's going to get killed as soon as you

212
00:08:50,959 --> 00:08:55,518
ask for the memory

213
00:08:52,880 --> 00:08:58,399
so you care about that if you're running

214
00:08:55,519 --> 00:09:03,920
multiple application or you're budgeting

215
00:08:58,399 --> 00:09:07,360
your system allocation counts

216
00:09:03,920 --> 00:09:11,360
another kind of memory usage we love

217
00:09:07,360 --> 00:09:13,839
dynamic memory we love malloc

218
00:09:11,360 --> 00:09:15,839
we like the all the pile of six gold

219
00:09:13,839 --> 00:09:18,800
that that implies

220
00:09:15,839 --> 00:09:21,839
the location count is something that can

221
00:09:18,800 --> 00:09:26,719
be problematic if you are locating

222
00:09:21,839 --> 00:09:30,959
thousand times during your run time

223
00:09:26,720 --> 00:09:34,080
we want to reduce that throughput

224
00:09:30,959 --> 00:09:37,199
number of results per unit of time

225
00:09:34,080 --> 00:09:38,800
numerous results for resource spend how

226
00:09:37,200 --> 00:09:41,920
many video i get out

227
00:09:38,800 --> 00:09:45,839
for that amount of money throughput is

228
00:09:41,920 --> 00:09:50,240
a mix it's harder to

229
00:09:45,839 --> 00:09:52,880
figure out when we are doing great but

230
00:09:50,240 --> 00:09:54,800
still sort of easy to measure quality

231
00:09:52,880 --> 00:09:58,320
completely application dependent

232
00:09:54,800 --> 00:10:01,359
for video is a bunch of magic we can

233
00:09:58,320 --> 00:10:03,200
talk about vmf we can talk about psnr

234
00:10:01,360 --> 00:10:06,720
we can talk about lots of stuff we are

235
00:10:03,200 --> 00:10:06,720
not going to talk about it here

236
00:10:07,440 --> 00:10:14,079
so in our case

237
00:10:10,959 --> 00:10:16,719
trade-off between quality and speed

238
00:10:14,079 --> 00:10:19,279
you get better quality you are going to

239
00:10:16,720 --> 00:10:22,480
sacrifice some speed

240
00:10:19,279 --> 00:10:23,839
for the memory you could do horrible

241
00:10:22,480 --> 00:10:27,120
horrible stuff and use

242
00:10:23,839 --> 00:10:28,480
a lot of memory to get fairly better

243
00:10:27,120 --> 00:10:32,000
speed

244
00:10:28,480 --> 00:10:35,519
but we tried to not do that or

245
00:10:32,000 --> 00:10:39,600
to not get way too extreme about it

246
00:10:35,519 --> 00:10:43,040
for revvy we try to shift the focus

247
00:10:39,600 --> 00:10:46,800
between speed and quality throughput

248
00:10:43,040 --> 00:10:50,000
so 0.2 that was

249
00:10:46,800 --> 00:10:50,800
about a month ago the focus was speed we

250
00:10:50,000 --> 00:10:54,240
wanted to get

251
00:10:50,800 --> 00:10:58,079
everything faster 0.3

252
00:10:54,240 --> 00:11:01,360
quality we want to get most of it

253
00:10:58,079 --> 00:11:05,680
better right in some ways

254
00:11:01,360 --> 00:11:07,839
0.4 we will probably try to balance

255
00:11:05,680 --> 00:11:10,399
everything and get a better throughput

256
00:11:07,839 --> 00:11:10,399
all in all

257
00:11:10,480 --> 00:11:15,120
so the idea is that we want to keep

258
00:11:13,279 --> 00:11:17,839
everything in balance

259
00:11:15,120 --> 00:11:18,160
so trade-offs we want to measure one

260
00:11:17,839 --> 00:11:20,800
thing

261
00:11:18,160 --> 00:11:22,640
and then the other so we want to have

262
00:11:20,800 --> 00:11:26,000
good tools to do that

263
00:11:22,640 --> 00:11:27,120
and also since it's something that is an

264
00:11:26,000 --> 00:11:30,000
iteration

265
00:11:27,120 --> 00:11:30,480
you don't want to spend lots of time

266
00:11:30,000 --> 00:11:33,920
during

267
00:11:30,480 --> 00:11:35,600
all the measurement that can be quite

268
00:11:33,920 --> 00:11:38,800
problematic if

269
00:11:35,600 --> 00:11:43,200
your encoding time is like 3 fps

270
00:11:38,800 --> 00:11:46,319
at best right

271
00:11:43,200 --> 00:11:48,800
so first we want good use case

272
00:11:46,320 --> 00:11:49,839
we want something that represents what

273
00:11:48,800 --> 00:11:54,479
our user

274
00:11:49,839 --> 00:11:57,519
is doing how we do that

275
00:11:54,480 --> 00:12:00,959
well either we can probe the user

276
00:11:57,519 --> 00:12:04,000
and force them to tell us or give us

277
00:12:00,959 --> 00:12:07,119
actual samples or

278
00:12:04,000 --> 00:12:08,240
we do that in a different way well code

279
00:12:07,120 --> 00:12:11,200
coverage

280
00:12:08,240 --> 00:12:13,279
is sort of not rocker science right who

281
00:12:11,200 --> 00:12:14,399
knows about code coverage who use code

282
00:12:13,279 --> 00:12:17,920
coverage

283
00:12:14,399 --> 00:12:19,680
everybody good code coverage is good

284
00:12:17,920 --> 00:12:20,479
when you are testing but it's also good

285
00:12:19,680 --> 00:12:23,680
when you are

286
00:12:20,480 --> 00:12:24,079
profiling and benchmarking because the

287
00:12:23,680 --> 00:12:27,120
two

288
00:12:24,079 --> 00:12:30,160
are sort of quite close but you are

289
00:12:27,120 --> 00:12:33,040
using different tools most of the time

290
00:12:30,160 --> 00:12:34,959
uh the code coverage is not as important

291
00:12:33,040 --> 00:12:38,240
as when you are testing to

292
00:12:34,959 --> 00:12:41,439
so 99 you don't care

293
00:12:38,240 --> 00:12:44,880
50 percent is good why that

294
00:12:41,440 --> 00:12:47,920
because you want to care about first

295
00:12:44,880 --> 00:12:49,920
the low-hanging fruits then

296
00:12:47,920 --> 00:12:51,279
once you manage to fix that you move

297
00:12:49,920 --> 00:12:54,399
further

298
00:12:51,279 --> 00:12:57,279
so your use case has to be

299
00:12:54,399 --> 00:12:57,680
well representative but you don't have

300
00:12:57,279 --> 00:13:00,720
to

301
00:12:57,680 --> 00:13:02,560
push it way further because it's going

302
00:13:00,720 --> 00:13:05,040
to take time to profile it

303
00:13:02,560 --> 00:13:07,760
all the time and extract the right

304
00:13:05,040 --> 00:13:10,800
amount of information

305
00:13:07,760 --> 00:13:14,160
so 8k videos are cool

306
00:13:10,800 --> 00:13:17,519
don't use them 4k videos

307
00:13:14,160 --> 00:13:19,680
depends on what you are doing 1080p

308
00:13:17,519 --> 00:13:20,720
well enough if you have a good coverage

309
00:13:19,680 --> 00:13:23,120
with that

310
00:13:20,720 --> 00:13:23,920
and the video is complex enough you are

311
00:13:23,120 --> 00:13:27,040
fine

312
00:13:23,920 --> 00:13:27,040
you can even go lower

313
00:13:28,480 --> 00:13:35,600
so how you are sure

314
00:13:31,680 --> 00:13:38,399
i say one way you profile

315
00:13:35,600 --> 00:13:39,360
how we providing rust we have a number

316
00:13:38,399 --> 00:13:43,040
of ways

317
00:13:39,360 --> 00:13:47,279
first one using the equivalent of

318
00:13:43,040 --> 00:13:49,519
minutes pg or minus instrument code or

319
00:13:47,279 --> 00:13:51,600
whatever is in the other compiler in

320
00:13:49,519 --> 00:13:53,920
brass minus z profile

321
00:13:51,600 --> 00:13:56,880
and this is already a problem because

322
00:13:53,920 --> 00:13:58,719
it's not stable yet

323
00:13:56,880 --> 00:14:01,600
on the other hand the output is

324
00:13:58,720 --> 00:14:03,680
completely stable is completely normal

325
00:14:01,600 --> 00:14:05,519
all the tools that you're normally using

326
00:14:03,680 --> 00:14:08,560
for collecting profile

327
00:14:05,519 --> 00:14:12,639
profile information and process it

328
00:14:08,560 --> 00:14:14,000
are good grcov is fairly good if you

329
00:14:12,639 --> 00:14:18,399
want to

330
00:14:14,000 --> 00:14:21,440
push the information further which cover

331
00:14:18,399 --> 00:14:23,600
is still good as well alcove

332
00:14:21,440 --> 00:14:25,279
all the tools that you want to use you

333
00:14:23,600 --> 00:14:27,279
have a way to do that

334
00:14:25,279 --> 00:14:29,439
mainly because gr cove is going to

335
00:14:27,279 --> 00:14:32,880
convert all the information

336
00:14:29,440 --> 00:14:34,800
in standard formats so we got

337
00:14:32,880 --> 00:14:37,120
we got covered what's the problem with

338
00:14:34,800 --> 00:14:40,000
that instrumenting code

339
00:14:37,120 --> 00:14:40,560
takes time because you have to unpile it

340
00:14:40,000 --> 00:14:42,839
and

341
00:14:40,560 --> 00:14:44,800
the runtime is going to be painfully

342
00:14:42,839 --> 00:14:48,079
slow but you get

343
00:14:44,800 --> 00:14:49,599
the exact information how to do better

344
00:14:48,079 --> 00:14:52,160
speed wise

345
00:14:49,600 --> 00:14:54,079
you can use some kind of sampling

346
00:14:52,160 --> 00:14:58,800
profiler

347
00:14:54,079 --> 00:15:01,120
kickoff is one of them is blazing fast

348
00:14:58,800 --> 00:15:02,079
it does work still on a number of

349
00:15:01,120 --> 00:15:06,000
platforms

350
00:15:02,079 --> 00:15:08,800
mainly mac and linux and we have a good

351
00:15:06,000 --> 00:15:09,760
integration with cargo so we don't have

352
00:15:08,800 --> 00:15:13,199
to

353
00:15:09,760 --> 00:15:15,839
think much we can just use it

354
00:15:13,199 --> 00:15:17,599
same thing for the other tools to

355
00:15:15,839 --> 00:15:20,880
extract the profiling information and

356
00:15:17,600 --> 00:15:21,440
push it forward you convert it you get

357
00:15:20,880 --> 00:15:24,079
it

358
00:15:21,440 --> 00:15:25,600
guess on the website that you like it

359
00:15:24,079 --> 00:15:27,040
and then you can do all your analysis

360
00:15:25,600 --> 00:15:28,560
that you want

361
00:15:27,040 --> 00:15:30,639
or you just get the number from the

362
00:15:28,560 --> 00:15:33,758
common line

363
00:15:30,639 --> 00:15:36,800
uh about two three times faster so

364
00:15:33,759 --> 00:15:39,279
to give you an idea if you're really

365
00:15:36,800 --> 00:15:40,319
hardcore about rust there is a project

366
00:15:39,279 --> 00:15:43,439
that is called

367
00:15:40,320 --> 00:15:46,639
torpol in that is pure rust

368
00:15:43,440 --> 00:15:50,160
is quite restricted works only on linux

369
00:15:46,639 --> 00:15:50,880
only x86 is pure rust so you don't have

370
00:15:50,160 --> 00:15:54,000
to carry

371
00:15:50,880 --> 00:15:56,399
lots of dependency and lots of stuff

372
00:15:54,000 --> 00:15:57,839
sadly it doesn't work for us because we

373
00:15:56,399 --> 00:16:01,680
are using assembly and

374
00:15:57,839 --> 00:16:01,680
it doesn't grok this kind of stuff

375
00:16:02,560 --> 00:16:06,000
so how we do that

376
00:16:06,480 --> 00:16:10,480
the story about using the normal

377
00:16:08,079 --> 00:16:12,479
profiling system

378
00:16:10,480 --> 00:16:14,480
is not exactly straightforward as you

379
00:16:12,480 --> 00:16:18,079
can see

380
00:16:14,480 --> 00:16:21,120
a bit of machinery then you run cargo

381
00:16:18,079 --> 00:16:24,239
and then you extract the information

382
00:16:21,120 --> 00:16:28,240
and it goes like this

383
00:16:24,240 --> 00:16:31,360
k cove is much much much much much nicer

384
00:16:28,240 --> 00:16:34,000
and this is calling directly kcov

385
00:16:31,360 --> 00:16:35,040
you can use the integration if you want

386
00:16:34,000 --> 00:16:38,079
to use it and

387
00:16:35,040 --> 00:16:41,759
it's a single comment but

388
00:16:38,079 --> 00:16:44,079
i mean mainly all it does

389
00:16:41,759 --> 00:16:45,360
is setting up k code with the right

390
00:16:44,079 --> 00:16:49,279
include path

391
00:16:45,360 --> 00:16:49,279
so is that kind of simple

392
00:16:49,680 --> 00:16:52,959
so let's assume that we are done with

393
00:16:51,519 --> 00:16:55,040
that

394
00:16:52,959 --> 00:16:58,880
we got our use case we want to profile

395
00:16:55,040 --> 00:17:03,599
it and then extract benchmarks

396
00:16:58,880 --> 00:17:06,959
so what i mean with profiling

397
00:17:03,600 --> 00:17:10,079
profiling which

398
00:17:06,959 --> 00:17:10,079
are common profilers

399
00:17:11,359 --> 00:17:15,438
perth to to mention one

400
00:17:16,559 --> 00:17:24,639
the trace sort of hard to use

401
00:17:21,839 --> 00:17:25,678
and slow i guess everybody has

402
00:17:24,640 --> 00:17:28,480
experience with

403
00:17:25,679 --> 00:17:31,200
running perf or rounding the trace in a

404
00:17:28,480 --> 00:17:35,360
way or another right

405
00:17:31,200 --> 00:17:38,320
nobody everybody good

406
00:17:35,360 --> 00:17:39,439
so the idea is we get their profile

407
00:17:38,320 --> 00:17:43,120
information

408
00:17:39,440 --> 00:17:46,240
and we reason about that

409
00:17:43,120 --> 00:17:49,439
so we can get something that

410
00:17:46,240 --> 00:17:50,240
is good enough for us to improve our

411
00:17:49,440 --> 00:17:52,320
code

412
00:17:50,240 --> 00:17:55,520
without spending that much time i call

413
00:17:52,320 --> 00:17:58,840
them benchmarks

414
00:17:55,520 --> 00:18:00,639
consider the profiling stage integration

415
00:17:58,840 --> 00:18:04,559
test benchmark

416
00:18:00,640 --> 00:18:05,840
unit test same problems the unit test is

417
00:18:04,559 --> 00:18:07,918
not going to be

418
00:18:05,840 --> 00:18:09,918
well representative of the behavior of

419
00:18:07,919 --> 00:18:12,720
the application

420
00:18:09,919 --> 00:18:14,960
a benchmark you can improve it you can

421
00:18:12,720 --> 00:18:16,559
improve that single function

422
00:18:14,960 --> 00:18:18,000
and then if you are not profiling the

423
00:18:16,559 --> 00:18:22,080
whole thing you can

424
00:18:18,000 --> 00:18:24,080
have what best surprises

425
00:18:22,080 --> 00:18:27,280
that tiny function you managed to make

426
00:18:24,080 --> 00:18:30,159
it fast and now it's like this

427
00:18:27,280 --> 00:18:31,360
okay what happens uh well the cache is

428
00:18:30,160 --> 00:18:32,960
something

429
00:18:31,360 --> 00:18:34,879
and if the function is not fitting the

430
00:18:32,960 --> 00:18:38,400
cache it's going to be

431
00:18:34,880 --> 00:18:40,559
extra slow or maybe is pulling out

432
00:18:38,400 --> 00:18:42,320
some other function that you would like

433
00:18:40,559 --> 00:18:44,960
to have fast so

434
00:18:42,320 --> 00:18:46,799
benchmarks are good but they are not the

435
00:18:44,960 --> 00:18:49,360
full solution

436
00:18:46,799 --> 00:18:50,559
all the time you manage to get a decent

437
00:18:49,360 --> 00:18:53,439
gain

438
00:18:50,559 --> 00:18:53,440
profile again

439
00:18:53,760 --> 00:19:00,000
or if you are in the case in which

440
00:18:57,200 --> 00:19:02,400
actually writing the benchmark is not

441
00:19:00,000 --> 00:19:05,120
cost-effective for your time

442
00:19:02,400 --> 00:19:05,840
because you cannot extract that path

443
00:19:05,120 --> 00:19:10,159
without doing

444
00:19:05,840 --> 00:19:12,399
lots of work around try to squeeze

445
00:19:10,160 --> 00:19:15,360
the test case so it's fast enough even

446
00:19:12,400 --> 00:19:15,360
profiling directly

447
00:19:16,320 --> 00:19:23,360
so what we can use before was theory

448
00:19:20,000 --> 00:19:26,480
now more practice first

449
00:19:23,360 --> 00:19:30,959
hyper fine is

450
00:19:26,480 --> 00:19:34,559
some kind of verified time no time

451
00:19:30,960 --> 00:19:37,440
so simple run time but it does

452
00:19:34,559 --> 00:19:40,559
all the statistical analysis for you it

453
00:19:37,440 --> 00:19:43,600
does all the repeat tests for you

454
00:19:40,559 --> 00:19:46,480
and it's quite good because if the

455
00:19:43,600 --> 00:19:49,520
amount of noise in your system is low

456
00:19:46,480 --> 00:19:52,880
you can just say okay i don't need to

457
00:19:49,520 --> 00:19:55,200
repeat my test lots of time to

458
00:19:52,880 --> 00:19:56,720
without that liars because we don't have

459
00:19:55,200 --> 00:19:59,200
outliers

460
00:19:56,720 --> 00:20:00,080
so this is the first thing if you manage

461
00:19:59,200 --> 00:20:03,440
to get

462
00:20:00,080 --> 00:20:08,240
your testing box completely

463
00:20:03,440 --> 00:20:11,600
unused fine is going to tell you hey

464
00:20:08,240 --> 00:20:14,000
run it just once it's fine

465
00:20:11,600 --> 00:20:14,719
and why is fine because if you have to

466
00:20:14,000 --> 00:20:18,480
do

467
00:20:14,720 --> 00:20:21,919
this proper statistical way 30 times

468
00:20:18,480 --> 00:20:25,200
around every round takes few minutes

469
00:20:21,919 --> 00:20:28,559
oh one hour is gone and you didn't do

470
00:20:25,200 --> 00:20:31,679
much so first

471
00:20:28,559 --> 00:20:33,200
try to get in that situation second you

472
00:20:31,679 --> 00:20:35,039
want to see stuff

473
00:20:33,200 --> 00:20:37,280
the analysis is important but it's

474
00:20:35,039 --> 00:20:38,720
important also to

475
00:20:37,280 --> 00:20:40,879
get the information in a way that you

476
00:20:38,720 --> 00:20:43,200
can rock it immediately

477
00:20:40,880 --> 00:20:44,480
so my first suggestion is to use cargo

478
00:20:43,200 --> 00:20:46,880
flame graph

479
00:20:44,480 --> 00:20:47,679
that under the hood is using perth and d

480
00:20:46,880 --> 00:20:49,760
trace

481
00:20:47,679 --> 00:20:50,960
so all the systems are covered more or

482
00:20:49,760 --> 00:20:53,840
less

483
00:20:50,960 --> 00:20:55,760
but instead of giving you data that has

484
00:20:53,840 --> 00:20:57,760
to be processed some way

485
00:20:55,760 --> 00:20:59,840
it does the work for you so if you like

486
00:20:57,760 --> 00:21:02,400
flame graphs

487
00:20:59,840 --> 00:21:03,439
or if you can tolerate flame graphs

488
00:21:02,400 --> 00:21:06,720
since some people

489
00:21:03,440 --> 00:21:11,200
love it some people hate it

490
00:21:06,720 --> 00:21:13,840
that's the tool for you you can explore

491
00:21:11,200 --> 00:21:14,960
the situation the graph is interactive

492
00:21:13,840 --> 00:21:18,720
so you can click on it

493
00:21:14,960 --> 00:21:18,720
you can expand it it's nice

494
00:21:18,960 --> 00:21:23,919
what's something that you can use also

495
00:21:21,919 --> 00:21:27,120
if you are doing something

496
00:21:23,919 --> 00:21:28,159
on a more embedded system we have not

497
00:21:27,120 --> 00:21:31,520
perf

498
00:21:28,159 --> 00:21:34,320
that is a pure rust replacement of perth

499
00:21:31,520 --> 00:21:35,840
that tries to solve some problems that

500
00:21:34,320 --> 00:21:37,760
performs

501
00:21:35,840 --> 00:21:39,600
mainly the fact that if you want to do

502
00:21:37,760 --> 00:21:42,840
the analysis you have to do the analysis

503
00:21:39,600 --> 00:21:44,158
inside the same machine that is running

504
00:21:42,840 --> 00:21:46,240
uh

505
00:21:44,159 --> 00:21:47,440
the data collection and if the machine

506
00:21:46,240 --> 00:21:49,280
is tiny

507
00:21:47,440 --> 00:21:51,039
it's going to be a problem they manage

508
00:21:49,280 --> 00:21:54,080
to solve it

509
00:21:51,039 --> 00:21:57,280
again it does produce flame graphs

510
00:21:54,080 --> 00:22:00,000
so the data analysis

511
00:21:57,280 --> 00:22:01,120
is already doing lots of work for you if

512
00:22:00,000 --> 00:22:04,400
you like flame graphs

513
00:22:01,120 --> 00:22:08,959
good you

514
00:22:04,400 --> 00:22:13,280
bought perth d trace not perth

515
00:22:08,960 --> 00:22:16,960
are sampling profilers so you are

516
00:22:13,280 --> 00:22:19,440
every end times per second

517
00:22:16,960 --> 00:22:20,559
checking the situation so it might miss

518
00:22:19,440 --> 00:22:23,600
stuff

519
00:22:20,559 --> 00:22:24,720
and also it's quite slow another

520
00:22:23,600 --> 00:22:28,879
suggestion you have

521
00:22:24,720 --> 00:22:32,240
trace that is probably less known

522
00:22:28,880 --> 00:22:36,720
requires you to do an instrumented build

523
00:22:32,240 --> 00:22:39,600
so another unstable unstable flag

524
00:22:36,720 --> 00:22:41,120
means the instrument count but is much

525
00:22:39,600 --> 00:22:44,639
faster

526
00:22:41,120 --> 00:22:47,360
and the tool itself gives you

527
00:22:44,640 --> 00:22:47,760
uh pretty much everything that you want

528
00:22:47,360 --> 00:22:50,799
and

529
00:22:47,760 --> 00:22:51,840
much more they did a lot of work on

530
00:22:50,799 --> 00:22:55,039
making it fast

531
00:22:51,840 --> 00:22:58,559
and also making it easy to use so

532
00:22:55,039 --> 00:23:01,280
again flame graphs you can have it

533
00:22:58,559 --> 00:23:02,879
chrome tracing you can have it any kind

534
00:23:01,280 --> 00:23:06,720
of data visualization

535
00:23:02,880 --> 00:23:09,840
they have planning so if you're on linux

536
00:23:06,720 --> 00:23:13,600
on the right cpus

537
00:23:09,840 --> 00:23:16,720
do use it gets you great results

538
00:23:13,600 --> 00:23:20,639
you're on mac well cargo instruments

539
00:23:16,720 --> 00:23:24,000
instruments is provided by xcode

540
00:23:20,640 --> 00:23:27,440
if you like open source is not great but

541
00:23:24,000 --> 00:23:31,200
it's effective and on mac does work

542
00:23:27,440 --> 00:23:34,400
i couldn't find any integration with uh

543
00:23:31,200 --> 00:23:38,320
vtune that would be my suggestion

544
00:23:34,400 --> 00:23:41,120
if you are really on windows

545
00:23:38,320 --> 00:23:41,918
so sorry for you learn how to install

546
00:23:41,120 --> 00:23:45,039
dtrace

547
00:23:41,919 --> 00:23:48,080
and use cargo flame graph

548
00:23:45,039 --> 00:23:48,080
i'm not using windows

549
00:23:48,840 --> 00:23:54,799
so once we have them

550
00:23:52,480 --> 00:23:54,799
sorry

551
00:23:56,559 --> 00:24:00,240
once we have the information we have to

552
00:23:58,159 --> 00:24:03,600
do something with that

553
00:24:00,240 --> 00:24:05,360
so we process it we figure out which is

554
00:24:03,600 --> 00:24:08,480
the best

555
00:24:05,360 --> 00:24:12,240
how many we have as

556
00:24:08,480 --> 00:24:15,600
function as timing memory usage

557
00:24:12,240 --> 00:24:18,559
everything we extract the benchmarks

558
00:24:15,600 --> 00:24:22,240
uh something that is important the only

559
00:24:18,559 --> 00:24:22,240
part that is important is this slide

560
00:24:22,400 --> 00:24:27,760
when you start using threads most of

561
00:24:25,760 --> 00:24:30,960
your analysis has to be

562
00:24:27,760 --> 00:24:34,000
reconsidered because every time

563
00:24:30,960 --> 00:24:35,760
you just want to get the information on

564
00:24:34,000 --> 00:24:37,200
how much time is being spent on the

565
00:24:35,760 --> 00:24:38,960
function

566
00:24:37,200 --> 00:24:41,279
once you have the threads if the

567
00:24:38,960 --> 00:24:44,240
function is happening in parallel

568
00:24:41,279 --> 00:24:46,000
or is called many times in parallel

569
00:24:44,240 --> 00:24:49,200
optimizing it

570
00:24:46,000 --> 00:24:51,039
is going to have a quite reduced impact

571
00:24:49,200 --> 00:24:52,480
compared to optimizing something that is

572
00:24:51,039 --> 00:24:53,840
a bottleneck because it's fully

573
00:24:52,480 --> 00:24:59,200
serialized

574
00:24:53,840 --> 00:25:01,678
and is blocking your code flow

575
00:24:59,200 --> 00:25:02,720
my suggestion to figure out what's going

576
00:25:01,679 --> 00:25:06,640
on and

577
00:25:02,720 --> 00:25:09,360
check it is to use lightweight probes

578
00:25:06,640 --> 00:25:09,840
because then again you are optimizing

579
00:25:09,360 --> 00:25:11,840
your

580
00:25:09,840 --> 00:25:12,879
the time you are spending lightweight

581
00:25:11,840 --> 00:25:14,639
probes

582
00:25:12,880 --> 00:25:16,720
on one hand requires you to put the

583
00:25:14,640 --> 00:25:18,880
probe in the code

584
00:25:16,720 --> 00:25:21,600
on the other you can you are just

585
00:25:18,880 --> 00:25:23,520
probing what you are caring about

586
00:25:21,600 --> 00:25:25,439
hulk tracer that have been also

587
00:25:23,520 --> 00:25:28,960
presented even this year

588
00:25:25,440 --> 00:25:31,919
again uh is one of the best is one of

589
00:25:28,960 --> 00:25:35,520
the easiest to use if you are using rust

590
00:25:31,919 --> 00:25:39,600
and it comes with

591
00:25:35,520 --> 00:25:42,879
really nice visualization and

592
00:25:39,600 --> 00:25:45,520
as you might see is really

593
00:25:42,880 --> 00:25:45,520
easy to use

594
00:25:46,799 --> 00:25:52,639
and you can use the chrome tracing

595
00:25:51,039 --> 00:25:55,039
feature to actually visualize what's

596
00:25:52,640 --> 00:25:57,919
going on in the case of revi

597
00:25:55,039 --> 00:25:59,520
you can notice that we have send frame

598
00:25:57,919 --> 00:26:03,200
and receive pocket that they are

599
00:25:59,520 --> 00:26:05,918
taking all the time and you can see that

600
00:26:03,200 --> 00:26:09,120
this part

601
00:26:05,919 --> 00:26:10,880
is neatly parallel so

602
00:26:09,120 --> 00:26:13,039
if you are improving and something in

603
00:26:10,880 --> 00:26:15,760
encode tile

604
00:26:13,039 --> 00:26:17,760
that in the serial case is that kind of

605
00:26:15,760 --> 00:26:20,799
log

606
00:26:17,760 --> 00:26:23,679
the impact is going to be tiny

607
00:26:20,799 --> 00:26:25,520
if i you are improving compute block

608
00:26:23,679 --> 00:26:27,919
importances

609
00:26:25,520 --> 00:26:29,600
well it's going to have quite an impact

610
00:26:27,919 --> 00:26:33,120
if you have that kind of

611
00:26:29,600 --> 00:26:35,360
that amount of course so

612
00:26:33,120 --> 00:26:36,239
once you start with threads you have to

613
00:26:35,360 --> 00:26:41,360
care about it

614
00:26:36,240 --> 00:26:41,360
and i suggest you use lightweight probes

615
00:26:41,520 --> 00:26:45,440
memory what are we going to do with

616
00:26:44,400 --> 00:26:48,480
memory that is

617
00:26:45,440 --> 00:26:51,919
so boring first

618
00:26:48,480 --> 00:26:53,600
uh hyperfine doesn't support measuring

619
00:26:51,919 --> 00:26:55,200
the memory usage

620
00:26:53,600 --> 00:26:58,399
i'm discussing with the author about it

621
00:26:55,200 --> 00:27:01,679
but it's not really convinced

622
00:26:58,400 --> 00:27:04,960
so you can use the old stupid

623
00:27:01,679 --> 00:27:06,480
new time getter usage is available in

624
00:27:04,960 --> 00:27:09,679
most system

625
00:27:06,480 --> 00:27:12,240
if you are on the other one windows

626
00:27:09,679 --> 00:27:13,360
there are some performance counter that

627
00:27:12,240 --> 00:27:16,960
you can use

628
00:27:13,360 --> 00:27:18,719
it's not a function is a couple but

629
00:27:16,960 --> 00:27:21,200
this is something that you can use and

630
00:27:18,720 --> 00:27:24,240
you can even use when you're

631
00:27:21,200 --> 00:27:27,360
using rust since the win api

632
00:27:24,240 --> 00:27:27,360
crate does support it

633
00:27:27,600 --> 00:27:33,678
once you get the ballpark you can

634
00:27:30,640 --> 00:27:36,399
dig down two tools to dig down

635
00:27:33,679 --> 00:27:37,600
one is mold and the other is memory

636
00:27:36,399 --> 00:27:41,279
profiler

637
00:27:37,600 --> 00:27:46,399
mold is written in c plus plus

638
00:27:41,279 --> 00:27:49,120
does support a plethora of different

639
00:27:46,399 --> 00:27:51,600
techniques to get the memory usage

640
00:27:49,120 --> 00:27:55,439
information

641
00:27:51,600 --> 00:27:57,918
uh it does have one of the nicest web ui

642
00:27:55,440 --> 00:27:58,559
to actual dig down the function that is

643
00:27:57,919 --> 00:28:02,159
taking

644
00:27:58,559 --> 00:28:03,840
the last amount the most amount of

645
00:28:02,159 --> 00:28:07,120
memory

646
00:28:03,840 --> 00:28:09,439
and gets you all the data what's the

647
00:28:07,120 --> 00:28:11,439
problem with that

648
00:28:09,440 --> 00:28:12,720
requires a bit of work to actually build

649
00:28:11,440 --> 00:28:16,880
it

650
00:28:12,720 --> 00:28:19,600
requires a bit of time

651
00:28:16,880 --> 00:28:21,039
because uh is not as fast as the memory

652
00:28:19,600 --> 00:28:24,959
profiler

653
00:28:21,039 --> 00:28:28,399
memory profiler pure rust yay

654
00:28:24,960 --> 00:28:32,399
so much easier to get it running

655
00:28:28,399 --> 00:28:34,000
going is linux only so

656
00:28:32,399 --> 00:28:36,080
that's could be a problem for you if

657
00:28:34,000 --> 00:28:41,440
you're not using linux

658
00:28:36,080 --> 00:28:44,639
uh the web ui is as rich or even richer

659
00:28:41,440 --> 00:28:47,760
in my opinion the two are pretty much

660
00:28:44,640 --> 00:28:48,880
in the same way but i prefer the memory

661
00:28:47,760 --> 00:28:53,120
profiler one

662
00:28:48,880 --> 00:28:53,120
when i'm just looking at the results

663
00:28:53,279 --> 00:28:59,760
and it does work quite well but

664
00:28:56,720 --> 00:29:02,960
it's a little harder to use for

665
00:28:59,760 --> 00:29:05,360
the reason that i will show you on mac

666
00:29:02,960 --> 00:29:06,320
cargo instruments what's wrong with

667
00:29:05,360 --> 00:29:09,360
instruments

668
00:29:06,320 --> 00:29:12,879
it gets you all the possible information

669
00:29:09,360 --> 00:29:15,439
a special mention if truck

670
00:29:12,880 --> 00:29:16,159
if you are on linux or you are using kde

671
00:29:15,440 --> 00:29:19,760
even on

672
00:29:16,159 --> 00:29:22,000
linux iprak comes with a ui that is

673
00:29:19,760 --> 00:29:25,279
really good for that

674
00:29:22,000 --> 00:29:26,720
uh malt a memory profiler provides the

675
00:29:25,279 --> 00:29:30,159
same kind

676
00:29:26,720 --> 00:29:33,600
of that data that uh hiptrac can

677
00:29:30,159 --> 00:29:37,679
process so you can mix both words

678
00:29:33,600 --> 00:29:39,760
if track is not as fast as

679
00:29:37,679 --> 00:29:41,279
memory profiler and malt at least in my

680
00:29:39,760 --> 00:29:44,320
experience

681
00:29:41,279 --> 00:29:45,679
so this is what you can use as a tool

682
00:29:44,320 --> 00:29:49,200
chain

683
00:29:45,679 --> 00:29:52,559
and what you can do for memory

684
00:29:49,200 --> 00:29:53,360
not much right i'm using that much from

685
00:29:52,559 --> 00:29:55,840
memory

686
00:29:53,360 --> 00:29:57,600
i am going to slay buffer that are

687
00:29:55,840 --> 00:30:02,158
pointless i'm going to

688
00:29:57,600 --> 00:30:05,840
size them properly i'm going to not use

689
00:30:02,159 --> 00:30:05,840
huge lookup tables

690
00:30:06,000 --> 00:30:13,039
they're kind of simple

691
00:30:09,520 --> 00:30:15,679
avoiding allocations well you try

692
00:30:13,039 --> 00:30:16,799
you can try to be smarter you can use

693
00:30:15,679 --> 00:30:20,880
slob

694
00:30:16,799 --> 00:30:20,879
or whichever technique you prefer name

695
00:30:21,520 --> 00:30:28,960
every location

696
00:30:25,279 --> 00:30:31,360
that is removed from a hot pot

697
00:30:28,960 --> 00:30:32,960
means that you are get getting better

698
00:30:31,360 --> 00:30:36,080
speed

699
00:30:32,960 --> 00:30:38,320
and overall better memory usage because

700
00:30:36,080 --> 00:30:40,879
every time you are locating you have

701
00:30:38,320 --> 00:30:43,120
chance that you are fragmenting memory

702
00:30:40,880 --> 00:30:45,039
and in the case of of revi in which we

703
00:30:43,120 --> 00:30:48,879
need to have a line

704
00:30:45,039 --> 00:30:49,360
a location there are chance in which we

705
00:30:48,880 --> 00:30:54,080
could

706
00:30:49,360 --> 00:30:57,519
manage to run out of pages if the job is

707
00:30:54,080 --> 00:31:00,799
long long enough so

708
00:30:57,519 --> 00:31:02,559
we had to focus on that fix that avoid

709
00:31:00,799 --> 00:31:06,480
really silly tiny location

710
00:31:02,559 --> 00:31:10,720
in hot pads because we did that kind of

711
00:31:06,480 --> 00:31:13,519
error last but not least memory leaks

712
00:31:10,720 --> 00:31:15,360
leaking memory is safe or soros is

713
00:31:13,519 --> 00:31:18,720
claiming

714
00:31:15,360 --> 00:31:21,840
so it is possible even in safe rust

715
00:31:18,720 --> 00:31:26,000
quite unlikely if you are not doing

716
00:31:21,840 --> 00:31:29,039
crazy stuff it never happened

717
00:31:26,000 --> 00:31:30,799
in review at least but

718
00:31:29,039 --> 00:31:32,158
you have to be careful about that the

719
00:31:30,799 --> 00:31:35,360
tools that i mentioned

720
00:31:32,159 --> 00:31:39,120
give you information about that as well

721
00:31:35,360 --> 00:31:41,279
so how to run it the memory profiler

722
00:31:39,120 --> 00:31:42,320
doesn't come with the run script so you

723
00:31:41,279 --> 00:31:45,600
have to write

724
00:31:42,320 --> 00:31:49,918
your own and after that

725
00:31:45,600 --> 00:31:53,199
still quite simple quite straightforward

726
00:31:49,919 --> 00:31:54,320
how does it look uh well not digging the

727
00:31:53,200 --> 00:31:57,840
data

728
00:31:54,320 --> 00:32:01,360
but seeing what's going on

729
00:31:57,840 --> 00:32:03,760
nice graphs you can

730
00:32:01,360 --> 00:32:05,360
check them see what's going on this is

731
00:32:03,760 --> 00:32:08,559
sort of

732
00:32:05,360 --> 00:32:10,879
what you would expect so

733
00:32:08,559 --> 00:32:15,279
you are using more or less the same

734
00:32:10,880 --> 00:32:18,000
amount of memory

735
00:32:15,279 --> 00:32:19,840
benchmarking and i guess we are running

736
00:32:18,000 --> 00:32:23,760
out of time so i'm going to

737
00:32:19,840 --> 00:32:26,959
run myself for benchmarking

738
00:32:23,760 --> 00:32:30,320
we don't have something that is great

739
00:32:26,960 --> 00:32:31,440
as a built-in in rust for testing we all

740
00:32:30,320 --> 00:32:34,960
know and we

741
00:32:31,440 --> 00:32:38,720
mostly love what we have benchmarking

742
00:32:34,960 --> 00:32:41,200
is in a worse situation ideally

743
00:32:38,720 --> 00:32:43,279
once we get the big testing testing

744
00:32:41,200 --> 00:32:43,600
framework overall so custom tests will

745
00:32:43,279 --> 00:32:46,640
be

746
00:32:43,600 --> 00:32:50,719
first class citizen everything will be

747
00:32:46,640 --> 00:32:53,519
easier right now not so nice not so good

748
00:32:50,720 --> 00:32:54,880
criterion is the best tool that you can

749
00:32:53,519 --> 00:32:58,720
use

750
00:32:54,880 --> 00:33:03,919
and it's quite good for getting speed

751
00:32:58,720 --> 00:33:03,919
and throughput analysis out of

752
00:33:04,080 --> 00:33:08,399
this out of box so

753
00:33:08,640 --> 00:33:12,559
it's good to use sadly we don't have

754
00:33:12,159 --> 00:33:16,480
much

755
00:33:12,559 --> 00:33:19,918
about memory so changing the code

756
00:33:16,480 --> 00:33:23,679
russ is going to help us here uh

757
00:33:19,919 --> 00:33:27,039
well yes

758
00:33:23,679 --> 00:33:30,240
the strategies i like to suggest

759
00:33:27,039 --> 00:33:31,039
are first maximize the impact get the

760
00:33:30,240 --> 00:33:34,080
top five

761
00:33:31,039 --> 00:33:38,480
pick the easiest fix it

762
00:33:34,080 --> 00:33:40,158
feel good keep going and everything is

763
00:33:38,480 --> 00:33:43,840
going to go

764
00:33:40,159 --> 00:33:46,559
to be right uh try to be conservative

765
00:33:43,840 --> 00:33:49,360
with trade-offs

766
00:33:46,559 --> 00:33:50,960
if you decide oh i can pre-compute

767
00:33:49,360 --> 00:33:52,639
everything in a look-up table and the

768
00:33:50,960 --> 00:33:55,840
lookout table is

769
00:33:52,640 --> 00:33:56,880
one gigabyte or two you have some

770
00:33:55,840 --> 00:33:59,918
problems

771
00:33:56,880 --> 00:34:00,399
speed wise you are great you cannot run

772
00:33:59,919 --> 00:34:04,159
that

773
00:34:00,399 --> 00:34:04,158
application many times at the same time

774
00:34:04,240 --> 00:34:09,918
last but not least if you are

775
00:34:07,360 --> 00:34:10,960
working in a team expect that your code

776
00:34:09,918 --> 00:34:14,560
your smart

777
00:34:10,960 --> 00:34:16,960
optimization is going to disappear

778
00:34:14,560 --> 00:34:19,199
it can happen you can do that yourself

779
00:34:16,960 --> 00:34:23,520
somebody else can do that

780
00:34:19,199 --> 00:34:26,719
do not feel bad it does happen

781
00:34:23,520 --> 00:34:28,480
it makes sense it's not disrespectful

782
00:34:26,719 --> 00:34:30,399
so if you find something that doesn't

783
00:34:28,480 --> 00:34:34,159
make sense remove it

784
00:34:30,399 --> 00:34:37,520
is fine

785
00:34:34,159 --> 00:34:40,800
so what we can do first

786
00:34:37,520 --> 00:34:42,239
think harder use less resources by using

787
00:34:40,800 --> 00:34:46,800
a better algorithm

788
00:34:42,239 --> 00:34:49,520
rust is not going to help you second

789
00:34:46,800 --> 00:34:50,879
do it better because you have better

790
00:34:49,520 --> 00:34:54,399
tools in your cpu

791
00:34:50,879 --> 00:34:55,279
cmd is your solution you have to think a

792
00:34:54,399 --> 00:34:57,920
bit

793
00:34:55,280 --> 00:34:59,680
but not as much as thinking about

794
00:34:57,920 --> 00:35:03,520
complexity and get the best

795
00:34:59,680 --> 00:35:07,279
algorithm for use your specific use case

796
00:35:03,520 --> 00:35:09,839
uh case locality and cmd are

797
00:35:07,280 --> 00:35:10,880
interesting uh having interesting

798
00:35:09,839 --> 00:35:13,119
interaction

799
00:35:10,880 --> 00:35:15,359
russ is not going to help you much about

800
00:35:13,119 --> 00:35:18,800
it but the compiler is still doing a

801
00:35:15,359 --> 00:35:18,799
well a good job

802
00:35:20,000 --> 00:35:26,640
last use more resources use

803
00:35:23,440 --> 00:35:26,640
more memory don't do that

804
00:35:26,720 --> 00:35:34,078
somebody did that not in writing

805
00:35:31,119 --> 00:35:34,880
use more threads within reason

806
00:35:34,079 --> 00:35:38,720
multi-threading

807
00:35:34,880 --> 00:35:38,720
and rust are great

808
00:35:39,119 --> 00:35:45,839
so what we did first cindy

809
00:35:43,359 --> 00:35:46,560
ravi and david are sort of twin projects

810
00:35:45,839 --> 00:35:49,599
so we share

811
00:35:46,560 --> 00:35:52,880
stuff which are also developers uh

812
00:35:49,599 --> 00:35:55,359
how to use assembly in rust

813
00:35:52,880 --> 00:35:56,720
we have good integration nas mrs and

814
00:35:55,359 --> 00:36:00,560
ccrs

815
00:35:56,720 --> 00:36:02,560
cover everything for you quite simple

816
00:36:00,560 --> 00:36:04,320
quite straightforward you don't have to

817
00:36:02,560 --> 00:36:08,400
think much about it

818
00:36:04,320 --> 00:36:12,320
but writing assembly is pain

819
00:36:08,400 --> 00:36:16,000
or if your ocd is quite rewarding but

820
00:36:12,320 --> 00:36:19,040
still pain what you do with trust

821
00:36:16,000 --> 00:36:22,240
we have good intrinsics we have even

822
00:36:19,040 --> 00:36:24,480
built in cpu detection so you don't have

823
00:36:22,240 --> 00:36:27,200
to reinvent the wheel for

824
00:36:24,480 --> 00:36:29,280
each project the standard library does

825
00:36:27,200 --> 00:36:32,560
that for you

826
00:36:29,280 --> 00:36:35,680
so you can use that also

827
00:36:32,560 --> 00:36:37,839
the compiler can do the work for you

828
00:36:35,680 --> 00:36:40,000
if the compiler knows that that

829
00:36:37,839 --> 00:36:42,960
extension is available

830
00:36:40,000 --> 00:36:45,200
for all the cpus is going to use it and

831
00:36:42,960 --> 00:36:48,320
the compiler is quite good at

832
00:36:45,200 --> 00:36:51,439
after vectorizing code iterators

833
00:36:48,320 --> 00:36:54,079
do unroll and do vectorize

834
00:36:51,440 --> 00:36:55,520
quite well by themselves so if you write

835
00:36:54,079 --> 00:36:58,800
the code the right way

836
00:36:55,520 --> 00:37:01,680
the compiler is going to work for you

837
00:36:58,800 --> 00:37:04,880
on top if you want to enable mx2 because

838
00:37:01,680 --> 00:37:08,319
all your cpus are going to have it

839
00:37:04,880 --> 00:37:10,240
you end up with a really faster binary

840
00:37:08,320 --> 00:37:13,520
mostly for free assuming that you don't

841
00:37:10,240 --> 00:37:13,520
have to support legacy

842
00:37:15,200 --> 00:37:23,759
multithreading multitrading in c pain

843
00:37:18,640 --> 00:37:25,839
multitaking c plus plus outer pain

844
00:37:23,760 --> 00:37:26,960
most of the language once you start

845
00:37:25,839 --> 00:37:28,480
using multitrading

846
00:37:26,960 --> 00:37:30,960
it means that you are going to spend the

847
00:37:28,480 --> 00:37:33,760
night on the debugger

848
00:37:30,960 --> 00:37:36,000
or trying to get background to figure

849
00:37:33,760 --> 00:37:38,560
out what's going on

850
00:37:36,000 --> 00:37:41,040
in rus most of the pitfalls are

851
00:37:38,560 --> 00:37:44,240
prevented by the compiler

852
00:37:41,040 --> 00:37:46,560
the standard library does provide you

853
00:37:44,240 --> 00:37:47,279
most of the stuff that you want you want

854
00:37:46,560 --> 00:37:50,560
more

855
00:37:47,280 --> 00:37:52,480
we have more external create support

856
00:37:50,560 --> 00:37:53,839
more primitives and better primitives

857
00:37:52,480 --> 00:37:56,079
faster primitives

858
00:37:53,839 --> 00:37:58,240
parking lot you are spending a single

859
00:37:56,079 --> 00:38:01,680
bite for a mutex

860
00:37:58,240 --> 00:38:04,240
fair enough not for one good

861
00:38:01,680 --> 00:38:05,118
crossbeam better channels we want to do

862
00:38:04,240 --> 00:38:06,959
more

863
00:38:05,119 --> 00:38:10,320
we want to have better data structure

864
00:38:06,960 --> 00:38:13,200
crossbeam is serving you

865
00:38:10,320 --> 00:38:14,800
we are lazy we are really lazy we

866
00:38:13,200 --> 00:38:18,319
managed to learn about

867
00:38:14,800 --> 00:38:21,680
iterators rayon is going to give you

868
00:38:18,320 --> 00:38:24,880
an automatic thread pull and

869
00:38:21,680 --> 00:38:27,359
a really easy way to move from

870
00:38:24,880 --> 00:38:29,920
your serial serial iterator to a

871
00:38:27,359 --> 00:38:31,680
parallel iterator

872
00:38:29,920 --> 00:38:34,320
and you do that usually with a single

873
00:38:31,680 --> 00:38:34,319
line of code

874
00:38:34,560 --> 00:38:39,040
i'm not kidding you this is our main

875
00:38:36,960 --> 00:38:42,079
encoding loop

876
00:38:39,040 --> 00:38:45,759
a little complex but i mean

877
00:38:42,079 --> 00:38:48,800
it's just iterators right okay

878
00:38:45,760 --> 00:38:48,800
this is multithreaded

879
00:38:49,119 --> 00:38:54,320
that's it simple right

880
00:38:54,400 --> 00:38:59,599
furless concurrency well lazy

881
00:38:56,800 --> 00:39:02,880
concurrency

882
00:38:59,599 --> 00:39:07,200
uh obviously if you are using rayon

883
00:39:02,880 --> 00:39:07,200
you might be sub-optimal in some ways

884
00:39:07,520 --> 00:39:13,440
ravi and rayon currently are exchanging

885
00:39:11,200 --> 00:39:14,960
notes on how to improve the the whole

886
00:39:13,440 --> 00:39:17,839
situation so

887
00:39:14,960 --> 00:39:20,320
the future rain will make revi even much

888
00:39:17,839 --> 00:39:20,320
faster

889
00:39:21,359 --> 00:39:27,598
so you remember this

890
00:39:24,560 --> 00:39:30,720
this is the encode tile that we saw

891
00:39:27,599 --> 00:39:34,480
here so

892
00:39:30,720 --> 00:39:37,279
before rayon that thing was that long

893
00:39:34,480 --> 00:39:37,280
now it's like this

894
00:39:37,520 --> 00:39:44,240
so kind of simple you have to

895
00:39:40,960 --> 00:39:47,599
care about it so we love reagan

896
00:39:44,240 --> 00:39:50,959
we also love curse beam

897
00:39:47,599 --> 00:39:52,720
the future api change will have a

898
00:39:50,960 --> 00:39:55,200
channel based api

899
00:39:52,720 --> 00:39:57,598
so if you like channels and you like

900
00:39:55,200 --> 00:40:01,200
encoding you will be quite happy

901
00:39:57,599 --> 00:40:04,960
because we'll be extra straightforward

902
00:40:01,200 --> 00:40:08,640
and if we are talking about memory

903
00:40:04,960 --> 00:40:09,440
what we have uh most of the problem that

904
00:40:08,640 --> 00:40:12,319
we had

905
00:40:09,440 --> 00:40:14,160
were because using vectors where is way

906
00:40:12,319 --> 00:40:16,640
too easy

907
00:40:14,160 --> 00:40:18,160
and every time you're using a vector you

908
00:40:16,640 --> 00:40:21,359
are using

909
00:40:18,160 --> 00:40:23,759
hip memory so you're allocating

910
00:40:21,359 --> 00:40:25,839
you are poking the kernel in the wrong

911
00:40:23,760 --> 00:40:25,839
way

912
00:40:26,160 --> 00:40:31,920
can be a problem how to avoid that

913
00:40:29,680 --> 00:40:33,919
and keep using vectors because the api

914
00:40:31,920 --> 00:40:36,800
is so nice

915
00:40:33,920 --> 00:40:37,680
we have solutions arrive small vac tiny

916
00:40:36,800 --> 00:40:40,880
vac

917
00:40:37,680 --> 00:40:42,240
pick one of them i mean

918
00:40:40,880 --> 00:40:44,480
they are more or less the same for the

919
00:40:42,240 --> 00:40:47,598
user arrive

920
00:40:44,480 --> 00:40:50,839
is the first small vac

921
00:40:47,599 --> 00:40:52,800
is one that is specifically geared for

922
00:40:50,839 --> 00:40:55,520
servo so

923
00:40:52,800 --> 00:40:57,680
it's some kind of a hybrid terivac is

924
00:40:55,520 --> 00:40:59,200
the smallest possible implementation of

925
00:40:57,680 --> 00:41:03,680
the concept

926
00:40:59,200 --> 00:41:06,879
it boils down to okay i know the size

927
00:41:03,680 --> 00:41:09,759
beforehand so i'm not going to

928
00:41:06,880 --> 00:41:11,520
have something that has to increase so

929
00:41:09,760 --> 00:41:13,119
i'm just going to use an array as a

930
00:41:11,520 --> 00:41:14,800
backing storage or something that is

931
00:41:13,119 --> 00:41:17,599
similar to an array

932
00:41:14,800 --> 00:41:18,800
so i can put everything in the stock so

933
00:41:17,599 --> 00:41:23,440
first

934
00:41:18,800 --> 00:41:27,440
cheapest to assess second no allocation

935
00:41:23,440 --> 00:41:29,680
third if your workload

936
00:41:27,440 --> 00:41:32,000
is such that you are going to allocate

937
00:41:29,680 --> 00:41:35,279
the full size all the time

938
00:41:32,000 --> 00:41:38,560
or nearly all the time

939
00:41:35,280 --> 00:41:42,079
you are not increasing the residence set

940
00:41:38,560 --> 00:41:44,400
statistically so this is a good way

941
00:41:42,079 --> 00:41:46,240
you want to have richer data structure

942
00:41:44,400 --> 00:41:49,440
that have the same thing

943
00:41:46,240 --> 00:41:51,359
uh i can mention a radicu

944
00:41:49,440 --> 00:41:54,079
that is using the same complexes as a

945
00:41:51,359 --> 00:41:56,480
little better than an array

946
00:41:54,079 --> 00:41:58,319
there are a number of other data

947
00:41:56,480 --> 00:42:00,839
structures that are doing that

948
00:41:58,319 --> 00:42:02,800
there is container arrest that has a

949
00:42:00,839 --> 00:42:05,680
collection uh

950
00:42:02,800 --> 00:42:06,880
tread with care because the whole effort

951
00:42:05,680 --> 00:42:09,680
is sort of

952
00:42:06,880 --> 00:42:11,280
suspended so if you like that structure

953
00:42:09,680 --> 00:42:13,440
do help them

954
00:42:11,280 --> 00:42:15,599
if you just want to use them just be

955
00:42:13,440 --> 00:42:18,560
careful because they are just maintained

956
00:42:15,599 --> 00:42:18,560
but not developed

957
00:42:19,359 --> 00:42:23,759
other solution for you why you need the

958
00:42:22,079 --> 00:42:26,000
intermediate buffer you can use

959
00:42:23,760 --> 00:42:27,599
iterators iterators are good and

960
00:42:26,000 --> 00:42:30,880
actuators are using

961
00:42:27,599 --> 00:42:34,000
less memory sometimes you have to

962
00:42:30,880 --> 00:42:36,720
turn around your code but the result is

963
00:42:34,000 --> 00:42:37,440
less memory and usually faster and

964
00:42:36,720 --> 00:42:40,560
usually

965
00:42:37,440 --> 00:42:43,119
even using simply so

966
00:42:40,560 --> 00:42:44,000
if you want to spare memory iterators

967
00:42:43,119 --> 00:42:47,040
can help you

968
00:42:44,000 --> 00:42:49,280
as well so

969
00:42:47,040 --> 00:42:51,520
to show with what happens when you are

970
00:42:49,280 --> 00:42:55,280
starting using the tools

971
00:42:51,520 --> 00:42:58,720
first reby we were doing that kind of

972
00:42:55,280 --> 00:43:03,520
amount of allocations

973
00:42:58,720 --> 00:43:08,240
about 6k okay driving two

974
00:43:03,520 --> 00:43:12,880
more or less pre-release we went there

975
00:43:08,240 --> 00:43:15,520
nowadays even less so

976
00:43:12,880 --> 00:43:16,319
you can use this kind of tool and you

977
00:43:15,520 --> 00:43:19,520
can say

978
00:43:16,319 --> 00:43:21,920
actually you can see the impact this way

979
00:43:19,520 --> 00:43:24,839
and i guess that's all and i don't know

980
00:43:21,920 --> 00:43:26,880
how much time do we have for the

981
00:43:24,839 --> 00:43:30,400
questions

982
00:43:26,880 --> 00:43:30,400
okay who's the lucky guy

983
00:43:30,480 --> 00:43:33,760
okay you where can you find the slides

984
00:43:32,960 --> 00:43:36,160
online or

985
00:43:33,760 --> 00:43:37,680
anywhere uh you can find that at the

986
00:43:36,160 --> 00:43:41,279
frozen website and

987
00:43:37,680 --> 00:43:43,839
you will have everything you ask about

988
00:43:41,280 --> 00:43:45,040
slides where to find them and the answer

989
00:43:43,839 --> 00:43:48,720
is

990
00:43:45,040 --> 00:43:52,640
for them website you can get another one

991
00:43:48,720 --> 00:43:54,959
yeah you you see you used to use a bite

992
00:43:52,640 --> 00:43:56,160
for a prematux but don't you have a

993
00:43:54,960 --> 00:43:57,839
problem that

994
00:43:56,160 --> 00:44:00,799
if something else is in the same cache

995
00:43:57,839 --> 00:44:04,880
line then you're gonna have to effect

996
00:44:00,800 --> 00:44:07,280
variables to the different l1

997
00:44:04,880 --> 00:44:08,160
okay if you have two threads on one

998
00:44:07,280 --> 00:44:09,920
chord and

999
00:44:08,160 --> 00:44:11,759
the others in the other car and yeah and

1000
00:44:09,920 --> 00:44:13,680
one takes the metrics

1001
00:44:11,760 --> 00:44:15,280
and mutex happens to be here and the

1002
00:44:13,680 --> 00:44:16,720
cash flow needs to move there

1003
00:44:15,280 --> 00:44:18,400
therefore our data which is in the same

1004
00:44:16,720 --> 00:44:23,839
cash line also moves there

1005
00:44:18,400 --> 00:44:23,839
so not if if

1006
00:44:25,920 --> 00:44:29,839
okay so the question is about uh how

1007
00:44:28,720 --> 00:44:33,200
parking lot is

1008
00:44:29,839 --> 00:44:34,078
able to make the music that tidy and my

1009
00:44:33,200 --> 00:44:36,078
answer is

1010
00:44:34,079 --> 00:44:37,119
uh it's written in the code and it's

1011
00:44:36,079 --> 00:44:39,760
also documented

1012
00:44:37,119 --> 00:44:40,880
um it would take way too much to answer

1013
00:44:39,760 --> 00:44:42,400
it properly

1014
00:44:40,880 --> 00:44:44,000
and probably i'm not the right person to

1015
00:44:42,400 --> 00:44:47,920
do that

1016
00:44:44,000 --> 00:44:51,839
somebody had an last question or we are

1017
00:44:47,920 --> 00:44:51,839
going to take it outside okay

1018
00:44:52,370 --> 00:45:02,040
[Applause]

1019
00:45:04,960 --> 00:45:07,040
you

