1
00:00:05,359 --> 00:00:07,919
hey folks

2
00:00:06,240 --> 00:00:09,679
so this is going to be a talk about two

3
00:00:07,919 --> 00:00:12,079
projects that i've been working on

4
00:00:09,679 --> 00:00:14,480
um one's a pretty new one that i've

5
00:00:12,080 --> 00:00:16,240
basically started a couple months ago

6
00:00:14,480 --> 00:00:18,240
and that's going to be around iou ring

7
00:00:16,239 --> 00:00:19,599
which is a new kernel interface that

8
00:00:18,240 --> 00:00:21,038
if you're working on linux it's

9
00:00:19,600 --> 00:00:22,800
basically going to completely replace

10
00:00:21,039 --> 00:00:25,600
all of your thread pool based i o

11
00:00:22,800 --> 00:00:25,600
as well as e-pol

12
00:00:27,680 --> 00:00:33,920
testing testing test test test

13
00:00:30,720 --> 00:00:36,079
test test test test uh

14
00:00:33,920 --> 00:00:38,079
yeah let me know if i should just go and

15
00:00:36,079 --> 00:00:42,239
scream or

16
00:00:38,079 --> 00:00:44,960
i can test test test

17
00:00:42,239 --> 00:00:44,959
test test

18
00:00:51,360 --> 00:00:54,399
is there any amplification can the folks

19
00:00:53,120 --> 00:00:57,280
in the back hear me okay

20
00:00:54,399 --> 00:00:59,760
okay cool um if if if you have trouble

21
00:00:57,280 --> 00:01:02,399
hearing me please go like this

22
00:00:59,760 --> 00:01:02,960
and i'll uh i'll adjust thank you um

23
00:01:02,399 --> 00:01:04,720
okay so

24
00:01:02,960 --> 00:01:07,360
the the recent project i've been working

25
00:01:04,720 --> 00:01:10,000
on is called rio and that's a iou ring

26
00:01:07,360 --> 00:01:10,640
library i o u ring is extremely exciting

27
00:01:10,000 --> 00:01:11,920
it's like

28
00:01:10,640 --> 00:01:13,200
in my opinion it's the most exciting

29
00:01:11,920 --> 00:01:15,040
thing that's been happening in the linux

30
00:01:13,200 --> 00:01:18,080
kernel for like the last 10 years

31
00:01:15,040 --> 00:01:18,799
um and i will be applying it to my

32
00:01:18,080 --> 00:01:20,080
database

33
00:01:18,799 --> 00:01:22,320
sled which i've been working on for the

34
00:01:20,080 --> 00:01:23,520
last four years and sled is an embedded

35
00:01:22,320 --> 00:01:26,639
database for the rust

36
00:01:23,520 --> 00:01:29,280
community and let's get started

37
00:01:26,640 --> 00:01:31,200
well so who am i i've been basically

38
00:01:29,280 --> 00:01:32,560
working on stateful systems in the rust

39
00:01:31,200 --> 00:01:35,280
ecosystem for the last

40
00:01:32,560 --> 00:01:37,600
six years or so my first rust project

41
00:01:35,280 --> 00:01:40,000
was the roxdb bindings

42
00:01:37,600 --> 00:01:41,439
uh that are now like like everybody's

43
00:01:40,000 --> 00:01:43,360
using it in like every blockchain

44
00:01:41,439 --> 00:01:45,520
project it's kind of scary

45
00:01:43,360 --> 00:01:46,880
but uh be careful what you build you

46
00:01:45,520 --> 00:01:47,839
never know how it's gonna be used um

47
00:01:46,880 --> 00:01:48,560
sometimes these things are good

48
00:01:47,840 --> 00:01:50,399
sometimes

49
00:01:48,560 --> 00:01:52,799
you know be careful about market

50
00:01:50,399 --> 00:01:55,119
externalities um

51
00:01:52,799 --> 00:01:56,079
i previously worked at a bunch of social

52
00:01:55,119 --> 00:01:58,159
media companies

53
00:01:56,079 --> 00:02:00,399
and infrastructure companies in the u.s

54
00:01:58,159 --> 00:02:01,840
um working on container orchestrators

55
00:02:00,399 --> 00:02:04,079
distributed systems distributed

56
00:02:01,840 --> 00:02:05,520
databases um some like serverless

57
00:02:04,079 --> 00:02:07,520
infrastructure

58
00:02:05,520 --> 00:02:08,959
data flow things i basically like

59
00:02:07,520 --> 00:02:10,318
low-level infrastructure

60
00:02:08,959 --> 00:02:13,599
and building things that other people

61
00:02:10,318 --> 00:02:16,480
use to build whatever they want with

62
00:02:13,599 --> 00:02:19,040
and uh yeah for fun i also like to build

63
00:02:16,480 --> 00:02:22,399
and destroy distributed databases

64
00:02:19,040 --> 00:02:24,640
for fun also i teach rust workshops

65
00:02:22,400 --> 00:02:26,000
i've taught workshops at mozilla

66
00:02:24,640 --> 00:02:28,720
microsoft

67
00:02:26,000 --> 00:02:29,440
bmw if you need a rest workshop i'm

68
00:02:28,720 --> 00:02:30,720
happy to

69
00:02:29,440 --> 00:02:33,120
give you a three-day workshop or

70
00:02:30,720 --> 00:02:36,720
specialized one beginner or

71
00:02:33,120 --> 00:02:41,519
advanced and uh i'm unemployable

72
00:02:36,720 --> 00:02:43,599
so um

73
00:02:41,519 --> 00:02:45,519
so i like databases because they

74
00:02:43,599 --> 00:02:48,000
basically involve working on all these

75
00:02:45,519 --> 00:02:49,920
kind of like low level problems where uh

76
00:02:48,000 --> 00:02:51,120
if you have managers who hired you to do

77
00:02:49,920 --> 00:02:52,480
them they're unlikely to tell you how to

78
00:02:51,120 --> 00:02:55,440
do your job

79
00:02:52,480 --> 00:02:56,480
so i i like front end work also but if

80
00:02:55,440 --> 00:02:57,760
you have it for

81
00:02:56,480 --> 00:02:59,679
your job there's a lot of people who

82
00:02:57,760 --> 00:03:01,200
kind of like tell you what to do

83
00:02:59,680 --> 00:03:03,200
i think i kind of got driven to

84
00:03:01,200 --> 00:03:04,799
distributed systems and databases

85
00:03:03,200 --> 00:03:06,000
because when you get into these weird

86
00:03:04,800 --> 00:03:07,280
areas there's just fewer people that

87
00:03:06,000 --> 00:03:10,080
tell you how to do your job

88
00:03:07,280 --> 00:03:11,280
and that appeals to me um and i got

89
00:03:10,080 --> 00:03:12,959
hooked

90
00:03:11,280 --> 00:03:14,800
so some interesting techniques and

91
00:03:12,959 --> 00:03:17,200
database engineering

92
00:03:14,800 --> 00:03:18,159
lock-free programming it's like juggling

93
00:03:17,200 --> 00:03:19,920
chainsaws

94
00:03:18,159 --> 00:03:21,440
uh basically having shared mutable state

95
00:03:19,920 --> 00:03:24,879
that you don't use mutexes

96
00:03:21,440 --> 00:03:26,079
to regulate um lots of like replication

97
00:03:24,879 --> 00:03:28,159
consensus

98
00:03:26,080 --> 00:03:29,440
uh distributed systems stuff lots of

99
00:03:28,159 --> 00:03:30,159
race conditions that you have to test

100
00:03:29,440 --> 00:03:31,359
for

101
00:03:30,159 --> 00:03:33,120
uh yeah you have to do a lot of

102
00:03:31,360 --> 00:03:35,280
correctness testing we can only build

103
00:03:33,120 --> 00:03:37,519
things that we can actually test

104
00:03:35,280 --> 00:03:39,200
the important characteristics about um

105
00:03:37,519 --> 00:03:41,200
so that also has a lot of restrictions

106
00:03:39,200 --> 00:03:43,518
on how we architect our systems

107
00:03:41,200 --> 00:03:44,798
um and also i'm pretty interested in

108
00:03:43,519 --> 00:03:46,400
self-tuning systems

109
00:03:44,799 --> 00:03:47,920
we basically the more that people have

110
00:03:46,400 --> 00:03:50,720
to configure a system

111
00:03:47,920 --> 00:03:52,319
uh the more likely they are to

112
00:03:50,720 --> 00:03:54,720
misconfigure the system

113
00:03:52,319 --> 00:03:56,560
and i love tuning things a lot so

114
00:03:54,720 --> 00:03:58,400
databases kind of are all of these

115
00:03:56,560 --> 00:04:00,480
things combined and that's what

116
00:03:58,400 --> 00:04:02,239
brought me here so i started this

117
00:04:00,480 --> 00:04:03,760
project sled about four years ago

118
00:04:02,239 --> 00:04:05,200
to basically have a personal project

119
00:04:03,760 --> 00:04:07,120
where i could just apply all these

120
00:04:05,200 --> 00:04:09,359
things that i like thinking about

121
00:04:07,120 --> 00:04:11,599
and to basically implement these papers

122
00:04:09,360 --> 00:04:13,519
that i was reading

123
00:04:11,599 --> 00:04:15,200
it's a pretty simple api it basically

124
00:04:13,519 --> 00:04:17,120
looks like a b3 map except you never

125
00:04:15,200 --> 00:04:19,599
need a mutable reference to it

126
00:04:17,120 --> 00:04:20,160
um yeah you can open it as if it were a

127
00:04:19,600 --> 00:04:21,759
file

128
00:04:20,160 --> 00:04:23,680
you can insert things you can get things

129
00:04:21,759 --> 00:04:26,479
you can iterate remove things

130
00:04:23,680 --> 00:04:28,080
when you drop it it fsyncs and it also

131
00:04:26,479 --> 00:04:31,440
fs periodically

132
00:04:28,080 --> 00:04:34,479
and uh yeah basically acts like a b3 map

133
00:04:31,440 --> 00:04:36,800
from bytes to bytes and it also handles

134
00:04:34,479 --> 00:04:39,599
all of the multi-threaded issues and

135
00:04:36,800 --> 00:04:41,120
uh reliability issues if you crash so

136
00:04:39,600 --> 00:04:44,639
basically it's just like a better

137
00:04:41,120 --> 00:04:46,479
map i think that rust is the best

138
00:04:44,639 --> 00:04:48,800
language for building databases in

139
00:04:46,479 --> 00:04:50,240
for a number number of reasons um one

140
00:04:48,800 --> 00:04:51,600
that gets often overlooked so i mean

141
00:04:50,240 --> 00:04:52,800
everyone always talks about like safety

142
00:04:51,600 --> 00:04:54,240
like unsafety

143
00:04:52,800 --> 00:04:56,080
but one of the ones that appeals to me

144
00:04:54,240 --> 00:04:57,440
is someone who like is more than willing

145
00:04:56,080 --> 00:04:59,280
to build unsafe things

146
00:04:57,440 --> 00:05:00,719
is the fact that rust has a lot more

147
00:04:59,280 --> 00:05:03,198
information at compile time

148
00:05:00,720 --> 00:05:04,720
than cnc plus plus around aliasing

149
00:05:03,199 --> 00:05:05,919
information now this is something that

150
00:05:04,720 --> 00:05:07,759
actually

151
00:05:05,919 --> 00:05:09,599
will allow russ to approach fortran

152
00:05:07,759 --> 00:05:12,320
performance over time

153
00:05:09,600 --> 00:05:12,720
as we unlock more and more llvm features

154
00:05:12,320 --> 00:05:15,680
uh

155
00:05:12,720 --> 00:05:17,280
around this but um i mean there's a

156
00:05:15,680 --> 00:05:19,759
reason why we're still using 50 year old

157
00:05:17,280 --> 00:05:21,599
fortran libraries in all of our

158
00:05:19,759 --> 00:05:23,120
linear algebra libraries so it's it's

159
00:05:21,600 --> 00:05:24,240
because fortran is able to optimize much

160
00:05:23,120 --> 00:05:26,960
more aggressively

161
00:05:24,240 --> 00:05:28,000
uh in cnc plus plus uh it's it's

162
00:05:26,960 --> 00:05:28,719
difficult to get that kind of

163
00:05:28,000 --> 00:05:30,080
performance

164
00:05:28,720 --> 00:05:32,400
rust is able to get the same kinds of

165
00:05:30,080 --> 00:05:33,919
optimizations as we can get in fortran

166
00:05:32,400 --> 00:05:37,039
so strictly from a performance

167
00:05:33,919 --> 00:05:38,639
standpoint rust is a superior tool

168
00:05:37,039 --> 00:05:40,320
correctness yeah blah blah blah everyone

169
00:05:38,639 --> 00:05:43,280
always talks about unsafety

170
00:05:40,320 --> 00:05:44,800
uh i write a lot of unsafe code i build

171
00:05:43,280 --> 00:05:46,559
lock free databases

172
00:05:44,800 --> 00:05:48,320
uh i try to do it in a responsible way

173
00:05:46,560 --> 00:05:49,759
with like miri where possible and lots

174
00:05:48,320 --> 00:05:51,520
of other tools but um

175
00:05:49,759 --> 00:05:53,600
anyway so i can still use the cnc plus

176
00:05:51,520 --> 00:05:55,758
performance and debugging tools

177
00:05:53,600 --> 00:05:57,680
and another big thing though is i can

178
00:05:55,759 --> 00:05:59,680
just accept other people's code

179
00:05:57,680 --> 00:06:01,600
really cheaply whereas if i'm working in

180
00:05:59,680 --> 00:06:03,360
a cnc plus plus code base it's like

181
00:06:01,600 --> 00:06:05,120
a lot more energy trying to review the

182
00:06:03,360 --> 00:06:06,400
code because you have to have a lot more

183
00:06:05,120 --> 00:06:07,840
things in your mind you have to

184
00:06:06,400 --> 00:06:09,440
familiarize yourself with more of the

185
00:06:07,840 --> 00:06:11,440
code that they're touching and it's just

186
00:06:09,440 --> 00:06:13,840
much more expensive to accept code

187
00:06:11,440 --> 00:06:15,680
from other people so as a one-person

188
00:06:13,840 --> 00:06:16,638
project essentially with a few awesome

189
00:06:15,680 --> 00:06:19,680
contributors

190
00:06:16,639 --> 00:06:20,319
like ivan over there it's uh it's a

191
00:06:19,680 --> 00:06:23,520
really nice

192
00:06:20,319 --> 00:06:26,240
language to uh to

193
00:06:23,520 --> 00:06:28,560
not spend too much energy doing the the

194
00:06:26,240 --> 00:06:31,280
normal maintainer ship stuff

195
00:06:28,560 --> 00:06:33,280
okay some other things about sled it's

196
00:06:31,280 --> 00:06:35,599
pretty fast to compile

197
00:06:33,280 --> 00:06:36,719
when you want to just have a database

198
00:06:35,600 --> 00:06:38,080
you don't want to like bring in a

199
00:06:36,720 --> 00:06:39,840
dependency and then have like

200
00:06:38,080 --> 00:06:41,680
hundreds of new dependencies that slow

201
00:06:39,840 --> 00:06:42,318
down your project so it's like it's

202
00:06:41,680 --> 00:06:44,319
pretty small

203
00:06:42,319 --> 00:06:45,520
it compiles pretty quickly and it should

204
00:06:44,319 --> 00:06:47,120
just let you

205
00:06:45,520 --> 00:06:49,120
solve the database problems without too

206
00:06:47,120 --> 00:06:51,840
much fuss

207
00:06:49,120 --> 00:06:53,120
one thing that has been really critical

208
00:06:51,840 --> 00:06:54,560
so it's good that there's a profiling

209
00:06:53,120 --> 00:06:56,000
talk right before this

210
00:06:54,560 --> 00:06:57,759
i lean really heavily into different

211
00:06:56,000 --> 00:06:59,520
kinds of profiling but when i build

212
00:06:57,759 --> 00:07:00,319
things i like to build profilers into

213
00:06:59,520 --> 00:07:02,318
the systems

214
00:07:00,319 --> 00:07:04,160
so i can tell i can basically trace like

215
00:07:02,319 --> 00:07:04,639
where like is this big number coming

216
00:07:04,160 --> 00:07:06,720
from

217
00:07:04,639 --> 00:07:08,560
i can kind of see through the system

218
00:07:06,720 --> 00:07:09,919
where things are starting to slow down

219
00:07:08,560 --> 00:07:11,599
where bottlenecks appear

220
00:07:09,919 --> 00:07:13,359
so when i do changes in my code i can

221
00:07:11,599 --> 00:07:14,400
see how it affects pretty much the whole

222
00:07:13,360 --> 00:07:15,919
stack

223
00:07:14,400 --> 00:07:17,840
and this will work on any system it

224
00:07:15,919 --> 00:07:19,680
doesn't rely on perf or anything

225
00:07:17,840 --> 00:07:21,440
uh and it can be compiled it can be

226
00:07:19,680 --> 00:07:22,880
turned off through a compile time flag

227
00:07:21,440 --> 00:07:24,319
so this is like a technique that if

228
00:07:22,880 --> 00:07:25,039
you're building performance critical

229
00:07:24,319 --> 00:07:27,360
systems

230
00:07:25,039 --> 00:07:28,880
just by having a profiler built into it

231
00:07:27,360 --> 00:07:32,479
it uh it really

232
00:07:28,880 --> 00:07:34,400
it's a wonderful thing to give yourself

233
00:07:32,479 --> 00:07:36,159
i also work a lot with flame graphs i

234
00:07:34,400 --> 00:07:40,000
wrote a tool

235
00:07:36,160 --> 00:07:42,240
that's available here basically to make

236
00:07:40,000 --> 00:07:43,599
flame graphs easier to use and you don't

237
00:07:42,240 --> 00:07:46,400
have to mess with

238
00:07:43,599 --> 00:07:48,080
pearl scripts or anything and it works

239
00:07:46,400 --> 00:07:49,039
pretty well so if you do a lot of flame

240
00:07:48,080 --> 00:07:51,359
graph stuff

241
00:07:49,039 --> 00:07:53,440
this is a very nice tool for using you

242
00:07:51,360 --> 00:07:55,440
can basically just type flame graph

243
00:07:53,440 --> 00:07:57,680
my workload and i'll just spit something

244
00:07:55,440 --> 00:08:00,479
out like this

245
00:07:57,680 --> 00:08:02,400
um how fast is it uh very fast it can do

246
00:08:00,479 --> 00:08:03,840
over 17 million operations per second

247
00:08:02,400 --> 00:08:06,239
when you're doing a 95

248
00:08:03,840 --> 00:08:07,679
read 5 right workload which is like

249
00:08:06,240 --> 00:08:11,520
somewhat representative of most

250
00:08:07,680 --> 00:08:13,919
like transactional workloads um so

251
00:08:11,520 --> 00:08:14,719
it's very fast but um it's definitely

252
00:08:13,919 --> 00:08:17,599
still beta

253
00:08:14,720 --> 00:08:18,319
um so you don't store your primary data

254
00:08:17,599 --> 00:08:21,360
in it yet

255
00:08:18,319 --> 00:08:22,639
uh there's like a sre proverb uh never

256
00:08:21,360 --> 00:08:23,199
use a database that's less than five

257
00:08:22,639 --> 00:08:24,960
years old

258
00:08:23,199 --> 00:08:26,720
uh you always regret this decision no

259
00:08:24,960 --> 00:08:29,039
matter what um so

260
00:08:26,720 --> 00:08:31,199
lucky for you sled turns five this year

261
00:08:29,039 --> 00:08:31,199
so

262
00:08:31,360 --> 00:08:34,880
this is a uh an exciting year for the

263
00:08:33,200 --> 00:08:36,080
project so so now is like when things

264
00:08:34,880 --> 00:08:37,838
are like really starting to be

265
00:08:36,080 --> 00:08:39,680
more and more product uh productionized

266
00:08:37,839 --> 00:08:40,880
and uh now is when i'm like starting to

267
00:08:39,679 --> 00:08:41,598
get on stages and telling people about

268
00:08:40,880 --> 00:08:44,720
it because

269
00:08:41,599 --> 00:08:45,600
the next year is really exciting cool

270
00:08:44,720 --> 00:08:47,920
how's it work

271
00:08:45,600 --> 00:08:49,760
um basically has a lock free index that

272
00:08:47,920 --> 00:08:51,279
maps from keys to the locations on disk

273
00:08:49,760 --> 00:08:52,480
or memory so this is how we like look

274
00:08:51,279 --> 00:08:54,320
things up

275
00:08:52,480 --> 00:08:55,920
it's based on the microsoft bw tree

276
00:08:54,320 --> 00:08:57,839
loosely

277
00:08:55,920 --> 00:08:59,040
it has a page cache that translates

278
00:08:57,839 --> 00:09:01,440
things in memory into

279
00:08:59,040 --> 00:09:02,880
on-desk representation also lock free

280
00:09:01,440 --> 00:09:04,560
and based on another microsoft project

281
00:09:02,880 --> 00:09:06,480
called lama

282
00:09:04,560 --> 00:09:08,800
it uses log structured storage that

283
00:09:06,480 --> 00:09:10,720
plays very nicely with modern flash

284
00:09:08,800 --> 00:09:11,920
based on sprite lfs which is like a

285
00:09:10,720 --> 00:09:13,839
pretty ancient

286
00:09:11,920 --> 00:09:15,120
log structured file system but it works

287
00:09:13,839 --> 00:09:16,399
pretty well because it basically just

288
00:09:15,120 --> 00:09:18,240
gives us a nice clean framework for

289
00:09:16,399 --> 00:09:20,160
doing garbage collection over segments

290
00:09:18,240 --> 00:09:22,080
and we tend to just write large segments

291
00:09:20,160 --> 00:09:24,160
at a time

292
00:09:22,080 --> 00:09:25,920
and of course we use iou ring for

293
00:09:24,160 --> 00:09:27,360
writing these huge buffers and this is

294
00:09:25,920 --> 00:09:28,800
uh this is going to be like the second

295
00:09:27,360 --> 00:09:30,720
half of this i'll talk about this in

296
00:09:28,800 --> 00:09:32,240
much more detail

297
00:09:30,720 --> 00:09:34,560
and this is also exported as its own

298
00:09:32,240 --> 00:09:35,279
crate rao i squatted that for like six

299
00:09:34,560 --> 00:09:37,359
years

300
00:09:35,279 --> 00:09:38,880
like and only now can i actually have

301
00:09:37,360 --> 00:09:40,399
like a really good use case for it i'm

302
00:09:38,880 --> 00:09:42,640
very excited to uh

303
00:09:40,399 --> 00:09:44,640
to be publishing this and we also have

304
00:09:42,640 --> 00:09:45,839
the cache based on windowed tiny lfu

305
00:09:44,640 --> 00:09:48,160
which is basically what

306
00:09:45,839 --> 00:09:49,360
all of the java ecosystem is relying on

307
00:09:48,160 --> 00:09:50,480
for all their high performance caching

308
00:09:49,360 --> 00:09:52,080
needs any

309
00:09:50,480 --> 00:09:54,000
database that's written in java is going

310
00:09:52,080 --> 00:09:54,720
to be using the caffeine library for the

311
00:09:54,000 --> 00:09:56,640
most part

312
00:09:54,720 --> 00:09:58,880
and this is a technique that they rely

313
00:09:56,640 --> 00:10:01,519
on this will be soon exported as the

314
00:09:58,880 --> 00:10:01,519
bear concrete

315
00:10:01,920 --> 00:10:06,079
so we need to avoid blocking wherever

316
00:10:04,880 --> 00:10:07,920
possible because

317
00:10:06,079 --> 00:10:09,279
we want to support lots of threads

318
00:10:07,920 --> 00:10:10,479
threads cannot

319
00:10:09,279 --> 00:10:12,160
if you just want to read some things

320
00:10:10,480 --> 00:10:13,680
ideally you shouldn't have to acquire a

321
00:10:12,160 --> 00:10:15,439
reader lock before

322
00:10:13,680 --> 00:10:16,640
you access that because you know maybe

323
00:10:15,440 --> 00:10:18,560
there's a bunch of writers coming at the

324
00:10:16,640 --> 00:10:20,880
same time and readers

325
00:10:18,560 --> 00:10:22,079
i won't focus too much on this because

326
00:10:20,880 --> 00:10:23,200
this is like basically like a 20 minute

327
00:10:22,079 --> 00:10:26,000
lightning talk

328
00:10:23,200 --> 00:10:27,519
but the important thing is that anything

329
00:10:26,000 --> 00:10:29,120
should just be able to do what it wants

330
00:10:27,519 --> 00:10:31,279
to do without blocking

331
00:10:29,120 --> 00:10:32,640
otherwise yeah you're going to start

332
00:10:31,279 --> 00:10:34,079
seeing huge latency spikes

333
00:10:32,640 --> 00:10:35,920
and these will backlash through your

334
00:10:34,079 --> 00:10:38,239
system um

335
00:10:35,920 --> 00:10:39,120
so in order to set a value to any key we

336
00:10:38,240 --> 00:10:41,440
first find

337
00:10:39,120 --> 00:10:42,720
so it's organized as a tree structure we

338
00:10:41,440 --> 00:10:44,959
go from the root node

339
00:10:42,720 --> 00:10:46,399
to the responsible leaf and then we

340
00:10:44,959 --> 00:10:48,079
mutate that leaf

341
00:10:46,399 --> 00:10:51,120
but it's important how we do this

342
00:10:48,079 --> 00:10:54,319
because it cannot be blocking

343
00:10:51,120 --> 00:10:55,040
so um yeah we don't want latency that's

344
00:10:54,320 --> 00:10:58,399
bad

345
00:10:55,040 --> 00:11:00,160
um so we use a technique called rcu

346
00:10:58,399 --> 00:11:01,519
read copy update this is a technique

347
00:11:00,160 --> 00:11:02,319
that gets used all over the place in our

348
00:11:01,519 --> 00:11:04,560
kernels

349
00:11:02,320 --> 00:11:06,240
um the high level idea of what what

350
00:11:04,560 --> 00:11:07,920
happens here is we read an atomic

351
00:11:06,240 --> 00:11:09,760
pointer

352
00:11:07,920 --> 00:11:11,199
we make a local copy of the data that it

353
00:11:09,760 --> 00:11:12,880
points to

354
00:11:11,200 --> 00:11:14,320
we change it in the way that represents

355
00:11:12,880 --> 00:11:17,120
our mutation

356
00:11:14,320 --> 00:11:17,920
and then we attempt to install our

357
00:11:17,120 --> 00:11:19,680
mutation

358
00:11:17,920 --> 00:11:22,560
by using an atomic compare and swap

359
00:11:19,680 --> 00:11:25,839
operation on that atomic pointer

360
00:11:22,560 --> 00:11:28,160
if we fail we basically

361
00:11:25,839 --> 00:11:28,880
retry and go back to one but if we

362
00:11:28,160 --> 00:11:30,480
succeed

363
00:11:28,880 --> 00:11:32,720
at some point we want to then destroy

364
00:11:30,480 --> 00:11:33,519
that data and the way that we do that in

365
00:11:32,720 --> 00:11:35,279
a way

366
00:11:33,519 --> 00:11:37,120
that's safe is by using the cross beam

367
00:11:35,279 --> 00:11:39,439
epoc crate so the

368
00:11:37,120 --> 00:11:40,480
the real problem here is if we

369
00:11:39,440 --> 00:11:42,640
immediately did

370
00:11:40,480 --> 00:11:44,480
a free of the data that we just

371
00:11:42,640 --> 00:11:46,079
basically made inaccessible

372
00:11:44,480 --> 00:11:48,079
it's possible that other threads still

373
00:11:46,079 --> 00:11:50,160
had a reference to it so we have to

374
00:11:48,079 --> 00:11:51,120
delay the destruction of that data until

375
00:11:50,160 --> 00:11:53,519
all threads

376
00:11:51,120 --> 00:11:54,639
that might have witnessed the data have

377
00:11:53,519 --> 00:11:56,160
have finished their work

378
00:11:54,639 --> 00:11:58,399
and that's what we use cross-beam epoch

379
00:11:56,160 --> 00:11:58,399
for

380
00:11:58,800 --> 00:12:02,240
so readers don't wait for writers they

381
00:12:00,880 --> 00:12:03,200
just read that atomic pointer and get

382
00:12:02,240 --> 00:12:05,200
their data

383
00:12:03,200 --> 00:12:06,720
and writers proceed optimistically they

384
00:12:05,200 --> 00:12:10,079
just read

385
00:12:06,720 --> 00:12:11,839
copy update and if they fail they retry

386
00:12:10,079 --> 00:12:13,599
but um the trade-off here is that

387
00:12:11,839 --> 00:12:16,800
instead of taking out a mutex

388
00:12:13,600 --> 00:12:18,880
uh we just do it anyway and

389
00:12:16,800 --> 00:12:20,719
the bet that we're making here is that

390
00:12:18,880 --> 00:12:24,639
we have to retry

391
00:12:20,720 --> 00:12:26,399
less often than

392
00:12:24,639 --> 00:12:28,399
the price that we would pay for

393
00:12:26,399 --> 00:12:30,320
acquiring a mutex on every update

394
00:12:28,399 --> 00:12:31,519
so if we have to start retrying a lot

395
00:12:30,320 --> 00:12:33,519
then it makes sense to actually

396
00:12:31,519 --> 00:12:34,639
dynamically start taking out a mutex

397
00:12:33,519 --> 00:12:36,480
and we can actually detect this at

398
00:12:34,639 --> 00:12:37,440
runtime dynamically like we can measure

399
00:12:36,480 --> 00:12:39,519
how often we

400
00:12:37,440 --> 00:12:41,680
experience contention and only start

401
00:12:39,519 --> 00:12:43,680
acquiring mutex's four rights

402
00:12:41,680 --> 00:12:44,959
when we're in a high contention area so

403
00:12:43,680 --> 00:12:46,319
this is an example of auto-tuning

404
00:12:44,959 --> 00:12:48,000
systems you can basically measure

405
00:12:46,320 --> 00:12:49,839
contention as you experience it

406
00:12:48,000 --> 00:12:51,360
switch over to using locks when they

407
00:12:49,839 --> 00:12:53,519
prevent contention

408
00:12:51,360 --> 00:12:55,040
or when they prevent wasted work but

409
00:12:53,519 --> 00:12:57,839
usually just proceed optimistically and

410
00:12:55,040 --> 00:12:57,839
it goes really fast

411
00:12:58,240 --> 00:13:01,040
however this is just the in-memory part

412
00:12:59,760 --> 00:13:01,760
of this we're building a database and

413
00:13:01,040 --> 00:13:03,680
ideally

414
00:13:01,760 --> 00:13:05,760
the things that we do in memory are

415
00:13:03,680 --> 00:13:08,479
mapped to things on disk

416
00:13:05,760 --> 00:13:10,160
the key constraint here being the

417
00:13:08,480 --> 00:13:11,839
ordering in memory has to map the

418
00:13:10,160 --> 00:13:13,360
ordering on disk

419
00:13:11,839 --> 00:13:15,120
so if we have a bunch of threads doing

420
00:13:13,360 --> 00:13:17,120
read copy update

421
00:13:15,120 --> 00:13:18,800
and then after they do the read copy

422
00:13:17,120 --> 00:13:21,600
update

423
00:13:18,800 --> 00:13:22,880
they log to disk it's possible to have a

424
00:13:21,600 --> 00:13:25,760
race condition here

425
00:13:22,880 --> 00:13:27,680
imagine one thread tries to delete a key

426
00:13:25,760 --> 00:13:28,880
and another thread tries to change its

427
00:13:27,680 --> 00:13:32,319
value

428
00:13:28,880 --> 00:13:34,639
let's say that the delete should happen

429
00:13:32,320 --> 00:13:37,920
before the mutation

430
00:13:34,639 --> 00:13:40,880
and the deletion gets through here

431
00:13:37,920 --> 00:13:41,839
it deletes the old value and then the

432
00:13:40,880 --> 00:13:43,360
mutation

433
00:13:41,839 --> 00:13:45,760
does the same thing and installs a new

434
00:13:43,360 --> 00:13:47,839
value

435
00:13:45,760 --> 00:13:49,360
but then there's a race condition here

436
00:13:47,839 --> 00:13:52,160
where they log their up

437
00:13:49,360 --> 00:13:52,639
their updates out of order if we then

438
00:13:52,160 --> 00:13:54,880
crash

439
00:13:52,639 --> 00:13:57,440
and then recover the database even

440
00:13:54,880 --> 00:13:59,839
though we mutated things in one order

441
00:13:57,440 --> 00:14:01,279
in memory we recover something that no

442
00:13:59,839 --> 00:14:03,760
longer has the data

443
00:14:01,279 --> 00:14:04,880
that's data loss so we basically can't

444
00:14:03,760 --> 00:14:07,519
have this

445
00:14:04,880 --> 00:14:08,320
so how do we make the things on disk map

446
00:14:07,519 --> 00:14:10,240
in memory

447
00:14:08,320 --> 00:14:11,600
even though we're not using any locks

448
00:14:10,240 --> 00:14:13,360
and we're basically

449
00:14:11,600 --> 00:14:15,120
uh yeah all this has to be locked free

450
00:14:13,360 --> 00:14:17,839
but we still have to have our order

451
00:14:15,120 --> 00:14:18,959
on disk map the order in memory so what

452
00:14:17,839 --> 00:14:21,839
we do is we use

453
00:14:18,959 --> 00:14:22,638
a special type of log reservation so we

454
00:14:21,839 --> 00:14:25,279
try to

455
00:14:22,639 --> 00:14:26,240
reserve a slot at the end of the log

456
00:14:25,279 --> 00:14:28,079
that can later on

457
00:14:26,240 --> 00:14:29,279
either be cancelled or filled in with

458
00:14:28,079 --> 00:14:32,638
data

459
00:14:29,279 --> 00:14:34,880
and the important part here is that that

460
00:14:32,639 --> 00:14:36,079
reservation at the tip of the log

461
00:14:34,880 --> 00:14:38,720
happens

462
00:14:36,079 --> 00:14:40,880
after we did our read but before we did

463
00:14:38,720 --> 00:14:43,040
our compare and swap operation

464
00:14:40,880 --> 00:14:45,439
later on when we know if our compare and

465
00:14:43,040 --> 00:14:47,439
swap failed or succeeded

466
00:14:45,440 --> 00:14:49,360
if it failed we basically can fill that

467
00:14:47,440 --> 00:14:50,240
conditional log reservation in with like

468
00:14:49,360 --> 00:14:52,880
zeros

469
00:14:50,240 --> 00:14:53,920
but if our compare and swap succeeded it

470
00:14:52,880 --> 00:14:56,240
means that

471
00:14:53,920 --> 00:14:58,240
the log reservation also happened at a

472
00:14:56,240 --> 00:15:01,279
point that is linearizable

473
00:14:58,240 --> 00:15:02,240
and at that point we can actually fill

474
00:15:01,279 --> 00:15:04,959
in the mutation

475
00:15:02,240 --> 00:15:05,760
on disk such that it matches the order

476
00:15:04,959 --> 00:15:07,199
in memory

477
00:15:05,760 --> 00:15:08,959
so even though we don't have any locks

478
00:15:07,199 --> 00:15:10,399
we're still able to basically have

479
00:15:08,959 --> 00:15:11,359
things lined up

480
00:15:10,399 --> 00:15:13,120
and this is a really interesting

481
00:15:11,360 --> 00:15:14,720
technique that you can use for basically

482
00:15:13,120 --> 00:15:15,519
linearizing all kinds of things without

483
00:15:14,720 --> 00:15:17,440
locks

484
00:15:15,519 --> 00:15:18,880
you basically have like some conditional

485
00:15:17,440 --> 00:15:20,959
slot here that gets taken out

486
00:15:18,880 --> 00:15:22,959
between the read and the operation

487
00:15:20,959 --> 00:15:23,839
that's that's actually installing a new

488
00:15:22,959 --> 00:15:25,680
version

489
00:15:23,839 --> 00:15:27,040
if that operation succeeds you do the

490
00:15:25,680 --> 00:15:28,800
conditional thing

491
00:15:27,040 --> 00:15:30,560
so sled also supports reactive

492
00:15:28,800 --> 00:15:32,160
subscription and

493
00:15:30,560 --> 00:15:34,880
basically the way that that works is it

494
00:15:32,160 --> 00:15:38,079
also takes out like a subscriber

495
00:15:34,880 --> 00:15:40,399
a possible subscription slot here

496
00:15:38,079 --> 00:15:41,920
and it only actually fills it in after

497
00:15:40,399 --> 00:15:43,680
the compare and swap so this is how we

498
00:15:41,920 --> 00:15:46,000
keep things on disk matched up with in

499
00:15:43,680 --> 00:15:49,120
memory

500
00:15:46,000 --> 00:15:50,399
cool how do we get fast io uh one of the

501
00:15:49,120 --> 00:15:51,680
main things is we just write things

502
00:15:50,399 --> 00:15:53,920
eight megabytes at a time

503
00:15:51,680 --> 00:15:55,359
all rights are non-blocking even though

504
00:15:53,920 --> 00:15:56,240
our write functions are not marked as

505
00:15:55,360 --> 00:15:58,320
async functions

506
00:15:56,240 --> 00:16:00,320
they're async they basically just cue

507
00:15:58,320 --> 00:16:01,600
things up into an eight megabyte buffer

508
00:16:00,320 --> 00:16:03,680
and later on we write the whole thing at

509
00:16:01,600 --> 00:16:04,880
once um we also support out of order

510
00:16:03,680 --> 00:16:06,000
rights there's so there's no head of

511
00:16:04,880 --> 00:16:07,439
line blocking

512
00:16:06,000 --> 00:16:09,279
at recovery time we figure out the right

513
00:16:07,440 --> 00:16:11,360
order um and

514
00:16:09,279 --> 00:16:13,199
of course we use i o u ring which i'll

515
00:16:11,360 --> 00:16:15,759
start talking about now

516
00:16:13,199 --> 00:16:17,680
so i o u ring is basically an interface

517
00:16:15,759 --> 00:16:18,720
for fully asynchronous communication

518
00:16:17,680 --> 00:16:20,079
with the kernel

519
00:16:18,720 --> 00:16:21,759
what we're used to before this is we

520
00:16:20,079 --> 00:16:23,199
have to do a syscall

521
00:16:21,759 --> 00:16:24,959
anytime we want to do like a read or

522
00:16:23,199 --> 00:16:28,079
write or an e-poll

523
00:16:24,959 --> 00:16:29,518
the kernel will basically uh yeah we're

524
00:16:28,079 --> 00:16:32,479
basically going to need to do

525
00:16:29,519 --> 00:16:34,240
a lot more context switches and people

526
00:16:32,480 --> 00:16:35,600
have already talked at length about

527
00:16:34,240 --> 00:16:37,519
some of the reasons why we might want to

528
00:16:35,600 --> 00:16:39,759
avoid these

529
00:16:37,519 --> 00:16:42,160
so i won't go too much into it but how

530
00:16:39,759 --> 00:16:43,759
did iou ring actually come about

531
00:16:42,160 --> 00:16:46,319
it actually started with a much more

532
00:16:43,759 --> 00:16:46,880
modest goal which was to basically

533
00:16:46,320 --> 00:16:49,360
improve

534
00:16:46,880 --> 00:16:50,079
the old aio interface linux actually

535
00:16:49,360 --> 00:16:53,120
already had

536
00:16:50,079 --> 00:16:55,120
async disk operations but it was

537
00:16:53,120 --> 00:16:57,440
it was very restricted it only worked

538
00:16:55,120 --> 00:16:58,000
for files that were opened in odirect

539
00:16:57,440 --> 00:17:01,279
mode

540
00:16:58,000 --> 00:17:01,680
which many databases did do but other

541
00:17:01,279 --> 00:17:04,160
people

542
00:17:01,680 --> 00:17:06,000
tend not to want to use odirect odirec

543
00:17:04,160 --> 00:17:07,199
basically skips the operating system's

544
00:17:06,000 --> 00:17:09,599
page cache

545
00:17:07,199 --> 00:17:11,039
and so you don't have to pay the costs

546
00:17:09,599 --> 00:17:12,879
of the page cache but you don't also

547
00:17:11,039 --> 00:17:14,879
you but then you don't get your reads

548
00:17:12,880 --> 00:17:16,799
cached in memory and you also

549
00:17:14,880 --> 00:17:18,240
importantly you have to do all of your

550
00:17:16,799 --> 00:17:21,839
your i o operations

551
00:17:18,240 --> 00:17:23,280
based on uh the the discs block size so

552
00:17:21,839 --> 00:17:25,918
most people don't want to do all their

553
00:17:23,280 --> 00:17:28,399
reads and writes aligned to 512 byte

554
00:17:25,919 --> 00:17:29,520
blocks it's a lot of effort to add to

555
00:17:28,400 --> 00:17:30,880
everybody's program

556
00:17:29,520 --> 00:17:32,799
the kernel does this for you under the

557
00:17:30,880 --> 00:17:34,320
hood but you had to do this if you

558
00:17:32,799 --> 00:17:36,559
wanted to use aio

559
00:17:34,320 --> 00:17:38,399
the effect was nobody actually used aio

560
00:17:36,559 --> 00:17:40,320
everyone just used thread pools that

561
00:17:38,400 --> 00:17:42,400
would do blocking i o under the hood

562
00:17:40,320 --> 00:17:43,760
exposing an async interface but that's

563
00:17:42,400 --> 00:17:46,559
that's much much more work

564
00:17:43,760 --> 00:17:47,120
and much slower so iou ring started to

565
00:17:46,559 --> 00:17:50,240
just

566
00:17:47,120 --> 00:17:52,959
or began initially as an effort

567
00:17:50,240 --> 00:17:54,320
just to replace that but in effect it's

568
00:17:52,960 --> 00:17:56,720
much more ambitious

569
00:17:54,320 --> 00:17:58,799
so in the first version of i o u ring um

570
00:17:56,720 --> 00:18:00,320
we've got basically read like vectored

571
00:17:58,799 --> 00:18:03,039
reads vectored rights

572
00:18:00,320 --> 00:18:04,320
um f syncs the ability to work with like

573
00:18:03,039 --> 00:18:07,520
pole fd or

574
00:18:04,320 --> 00:18:10,320
yeah like event fd devices um

575
00:18:07,520 --> 00:18:10,960
however so that the very top row is the

576
00:18:10,320 --> 00:18:14,000
linux

577
00:18:10,960 --> 00:18:15,919
version um so 5.1 came

578
00:18:14,000 --> 00:18:18,400
out with support for like the basic file

579
00:18:15,919 --> 00:18:20,160
operations but as you can see over time

580
00:18:18,400 --> 00:18:21,440
we're starting to get many more file

581
00:18:20,160 --> 00:18:24,559
operations as well

582
00:18:21,440 --> 00:18:27,440
um and and also network so connect

583
00:18:24,559 --> 00:18:28,480
accept um we can like send message

584
00:18:27,440 --> 00:18:29,679
receive message

585
00:18:28,480 --> 00:18:31,840
and this is the reason why it's also

586
00:18:29,679 --> 00:18:34,000
going to start replacing epo um because

587
00:18:31,840 --> 00:18:36,240
we're using i e pull for our network

588
00:18:34,000 --> 00:18:37,679
i o um but this is going to let us just

589
00:18:36,240 --> 00:18:38,160
start submitting operations to the

590
00:18:37,679 --> 00:18:40,240
kernel

591
00:18:38,160 --> 00:18:41,440
and it's going to like execute them

592
00:18:40,240 --> 00:18:44,960
asynchronously

593
00:18:41,440 --> 00:18:46,559
and uh it has a number of

594
00:18:44,960 --> 00:18:49,679
of advantages that i'm going to cover

595
00:18:46,559 --> 00:18:52,399
now um what's the time by the way

596
00:18:49,679 --> 00:18:52,880
cool um cool so the way it works is with

597
00:18:52,400 --> 00:18:55,840
two

598
00:18:52,880 --> 00:18:57,760
ring buffers there's a submission ring

599
00:18:55,840 --> 00:19:00,399
buffer where we basically just load up

600
00:18:57,760 --> 00:19:01,760
uh this ring buffer with those events

601
00:19:00,400 --> 00:19:03,520
that that we saw before

602
00:19:01,760 --> 00:19:05,360
so we load up the the submission ring

603
00:19:03,520 --> 00:19:06,879
buffer with one of these events

604
00:19:05,360 --> 00:19:08,320
um they have different arguments that

605
00:19:06,880 --> 00:19:09,280
you can pass as well depending on the

606
00:19:08,320 --> 00:19:11,439
operation

607
00:19:09,280 --> 00:19:12,639
uh fsync just requires a file descriptor

608
00:19:11,440 --> 00:19:14,880
that you pass to it

609
00:19:12,640 --> 00:19:15,679
uh but read like a vectored read would

610
00:19:14,880 --> 00:19:18,880
require

611
00:19:15,679 --> 00:19:20,880
a buffer to put the read into

612
00:19:18,880 --> 00:19:23,440
as well as like where in the file you

613
00:19:20,880 --> 00:19:25,280
want to read from etc

614
00:19:23,440 --> 00:19:27,440
so the submission queue is just those

615
00:19:25,280 --> 00:19:29,440
operations that you want to submit

616
00:19:27,440 --> 00:19:31,360
they get executed out of order and this

617
00:19:29,440 --> 00:19:33,360
is a way to dramatically increase the

618
00:19:31,360 --> 00:19:35,760
throughput

619
00:19:33,360 --> 00:19:37,439
and then the result of those operations

620
00:19:35,760 --> 00:19:39,840
gets put into a completion

621
00:19:37,440 --> 00:19:39,840
ring buffer

622
00:19:41,200 --> 00:19:45,600
interestingly after you set this thing

623
00:19:42,960 --> 00:19:46,559
up you can run it with zero syscalls

624
00:19:45,600 --> 00:19:48,959
and there's a mode that you can

625
00:19:46,559 --> 00:19:50,879
configure it with called sq poll

626
00:19:48,960 --> 00:19:52,640
and this basically creates a kernel

627
00:19:50,880 --> 00:19:53,200
thread that will pull the submission

628
00:19:52,640 --> 00:19:54,480
queue

629
00:19:53,200 --> 00:19:56,080
looking at those events that you just

630
00:19:54,480 --> 00:19:56,960
submitted or operations that you just

631
00:19:56,080 --> 00:19:59,760
submitted

632
00:19:56,960 --> 00:20:01,120
execute them asynchronously and then

633
00:19:59,760 --> 00:20:02,559
fill them into the completion queue

634
00:20:01,120 --> 00:20:04,320
which you can also read without doing

635
00:20:02,559 --> 00:20:06,720
any sys calls this is mapped

636
00:20:04,320 --> 00:20:08,080
and shared between user space and kernel

637
00:20:06,720 --> 00:20:11,280
space

638
00:20:08,080 --> 00:20:14,080
so we can do all of those operations now

639
00:20:11,280 --> 00:20:15,280
with zero assist calls this is

640
00:20:14,080 --> 00:20:17,520
increasingly important

641
00:20:15,280 --> 00:20:18,960
in like the post kpti like spectre

642
00:20:17,520 --> 00:20:20,000
meltdown mitigation world where our

643
00:20:18,960 --> 00:20:21,919
syscalls became a lot

644
00:20:20,000 --> 00:20:24,000
slower especially if you're doing a ton

645
00:20:21,919 --> 00:20:26,240
of them now we don't need to do any of

646
00:20:24,000 --> 00:20:26,240
them

647
00:20:26,640 --> 00:20:32,640
cool the rio crate is pretty simple

648
00:20:29,840 --> 00:20:32,959
you just create a u-ring instance you

649
00:20:32,640 --> 00:20:34,960
like

650
00:20:32,960 --> 00:20:36,000
write at you pass a buffer file

651
00:20:34,960 --> 00:20:39,760
descriptor

652
00:20:36,000 --> 00:20:41,840
um an important api design issue here um

653
00:20:39,760 --> 00:20:43,280
is it async or does it work with threads

654
00:20:41,840 --> 00:20:43,918
uh you know this is like the question

655
00:20:43,280 --> 00:20:45,440
like this is

656
00:20:43,919 --> 00:20:47,200
the first question pretty much anyone

657
00:20:45,440 --> 00:20:49,120
asks when they see a rust library

658
00:20:47,200 --> 00:20:50,159
can i use this thing at all or would i

659
00:20:49,120 --> 00:20:51,280
have to completely change my

660
00:20:50,159 --> 00:20:52,159
architecture if i wanted to take

661
00:20:51,280 --> 00:20:54,320
advantage of it

662
00:20:52,159 --> 00:20:56,320
rio doesn't force you to make a decision

663
00:20:54,320 --> 00:20:57,840
it returns a concrete object that just

664
00:20:56,320 --> 00:21:00,158
happens to implement future

665
00:20:57,840 --> 00:21:01,120
so you can either just call weight on

666
00:21:00,159 --> 00:21:02,799
the completion

667
00:21:01,120 --> 00:21:04,239
so you can basically send off a bunch of

668
00:21:02,799 --> 00:21:06,960
events

669
00:21:04,240 --> 00:21:07,520
from a thread and then like basically

670
00:21:06,960 --> 00:21:09,840
batch up

671
00:21:07,520 --> 00:21:11,120
these completions and then later on wait

672
00:21:09,840 --> 00:21:12,720
on them just like you would do if you

673
00:21:11,120 --> 00:21:15,360
were spinning up a bunch of threads

674
00:21:12,720 --> 00:21:16,000
that you then join on later so you can

675
00:21:15,360 --> 00:21:18,240
do a similar

676
00:21:16,000 --> 00:21:19,039
kind of pattern with this blocking

677
00:21:18,240 --> 00:21:21,919
weight

678
00:21:19,039 --> 00:21:23,679
method or you can just dot await it

679
00:21:21,919 --> 00:21:25,520
because it's also a future

680
00:21:23,679 --> 00:21:26,880
by returning concrete features that just

681
00:21:25,520 --> 00:21:29,280
work with both we

682
00:21:26,880 --> 00:21:30,320
don't force as many api constraints on

683
00:21:29,280 --> 00:21:32,399
our users if

684
00:21:30,320 --> 00:21:34,480
if like i think everyone's kind of tired

685
00:21:32,400 --> 00:21:36,400
of choosing like uh

686
00:21:34,480 --> 00:21:37,679
or of seeing libraries that they wish

687
00:21:36,400 --> 00:21:38,640
they could use but it just targets the

688
00:21:37,679 --> 00:21:41,440
other side of the world

689
00:21:38,640 --> 00:21:41,440
we can target both

690
00:21:42,880 --> 00:21:48,640
we can also uh do like accepts here

691
00:21:46,400 --> 00:21:50,320
uh so this is just a simple proxy that

692
00:21:48,640 --> 00:21:52,480
well in this case it's just an

693
00:21:50,320 --> 00:21:54,000
echo service really because uh we're

694
00:21:52,480 --> 00:21:56,240
doing this proxy method

695
00:21:54,000 --> 00:21:58,159
for the same stream we read a bunch of

696
00:21:56,240 --> 00:22:00,080
bytes

697
00:21:58,159 --> 00:22:01,919
and then we we write the same thing

698
00:22:00,080 --> 00:22:03,918
right back so

699
00:22:01,919 --> 00:22:05,200
this is just a simple example of how you

700
00:22:03,919 --> 00:22:07,679
might describe

701
00:22:05,200 --> 00:22:08,880
an echo service you can also do this in

702
00:22:07,679 --> 00:22:12,720
other ways

703
00:22:08,880 --> 00:22:14,320
but it works with network stuff

704
00:22:12,720 --> 00:22:16,320
operations are executed out of order by

705
00:22:14,320 --> 00:22:16,879
default however you can chain them

706
00:22:16,320 --> 00:22:19,039
together

707
00:22:16,880 --> 00:22:20,640
by setting a flag that links them and

708
00:22:19,039 --> 00:22:22,240
what this does is it basically allows

709
00:22:20,640 --> 00:22:23,919
you to specify

710
00:22:22,240 --> 00:22:25,520
that the kernel should not begin the

711
00:22:23,919 --> 00:22:26,159
next operation until the previous one

712
00:22:25,520 --> 00:22:28,000
finished

713
00:22:26,159 --> 00:22:29,600
so this lets you do things like submit a

714
00:22:28,000 --> 00:22:32,320
bunch of writes to a file

715
00:22:29,600 --> 00:22:34,000
and then link that to an fsync so you do

716
00:22:32,320 --> 00:22:36,080
all these things you submit them

717
00:22:34,000 --> 00:22:38,240
all to the kernel and the kernel will

718
00:22:36,080 --> 00:22:40,000
just do all of these writes and after

719
00:22:38,240 --> 00:22:41,440
the writes finish it will do an fsync

720
00:22:40,000 --> 00:22:43,760
and then you really only have to look at

721
00:22:41,440 --> 00:22:45,840
the completion for that fsync and you

722
00:22:43,760 --> 00:22:48,240
just basically submitted a topology of

723
00:22:45,840 --> 00:22:49,280
i o operations at the kernel and uh and

724
00:22:48,240 --> 00:22:50,880
it just tells you

725
00:22:49,280 --> 00:22:52,480
after they're all done it's it's a

726
00:22:50,880 --> 00:22:54,080
really beautiful low interaction way to

727
00:22:52,480 --> 00:22:56,320
communicate with the kernel

728
00:22:54,080 --> 00:22:57,918
um you can also do things like a chain

729
00:22:56,320 --> 00:23:00,559
like a connect call

730
00:22:57,919 --> 00:23:01,039
to some service uh send a bunch of bytes

731
00:23:00,559 --> 00:23:03,520
to it

732
00:23:01,039 --> 00:23:04,400
and then chain that to a receive and and

733
00:23:03,520 --> 00:23:06,559
whenever the res

734
00:23:04,400 --> 00:23:07,600
and just by using these links you just

735
00:23:06,559 --> 00:23:09,600
like submit

736
00:23:07,600 --> 00:23:10,959
uh like a whole whole client operation

737
00:23:09,600 --> 00:23:12,799
to the kernel and then you just get the

738
00:23:10,960 --> 00:23:13,679
completion back when it has sent you a

739
00:23:12,799 --> 00:23:14,960
response

740
00:23:13,679 --> 00:23:17,520
it's uh it's really beautiful you can

741
00:23:14,960 --> 00:23:19,200
also attach timeouts to all these

742
00:23:17,520 --> 00:23:20,720
um so if you're working on top of a

743
00:23:19,200 --> 00:23:22,400
kernel programming languages are

744
00:23:20,720 --> 00:23:24,880
effectively just dsls for orchestrating

745
00:23:22,400 --> 00:23:24,880
syscalls

746
00:23:25,919 --> 00:23:30,720
so uh you know and and this is you know

747
00:23:28,960 --> 00:23:33,200
our programs take input

748
00:23:30,720 --> 00:23:34,400
and and you know and they're useful

749
00:23:33,200 --> 00:23:36,720
based on their output

750
00:23:34,400 --> 00:23:38,559
uh if you're only looking at the program

751
00:23:36,720 --> 00:23:42,480
rather than its effect on your life but

752
00:23:38,559 --> 00:23:44,000
uh it's uh but really the the way that

753
00:23:42,480 --> 00:23:45,600
like as long as we're not like working

754
00:23:44,000 --> 00:23:46,799
in the embedded world or even in the

755
00:23:45,600 --> 00:23:47,918
embedded world to some extent

756
00:23:46,799 --> 00:23:50,000
if you're using like a real-time

757
00:23:47,919 --> 00:23:52,559
operating system um the

758
00:23:50,000 --> 00:23:53,200
we are using programming languages to

759
00:23:52,559 --> 00:23:55,120
interact

760
00:23:53,200 --> 00:23:57,039
with the world around us and part of the

761
00:23:55,120 --> 00:23:58,959
reason why i'm so excited about iou ring

762
00:23:57,039 --> 00:24:00,158
is because it's like totally changing

763
00:23:58,960 --> 00:24:02,000
this conversation

764
00:24:00,159 --> 00:24:04,480
we're able to just kind of like submit

765
00:24:02,000 --> 00:24:05,200
topologies of interesting dependencies

766
00:24:04,480 --> 00:24:06,960
to the kernel

767
00:24:05,200 --> 00:24:08,799
the kernel just does them and then we

768
00:24:06,960 --> 00:24:10,720
find out later on how they worked

769
00:24:08,799 --> 00:24:12,480
and this is sort of like uh kind of like

770
00:24:10,720 --> 00:24:13,200
separating user space into like control

771
00:24:12,480 --> 00:24:16,480
plane

772
00:24:13,200 --> 00:24:18,240
kernels data plane um and and it's

773
00:24:16,480 --> 00:24:19,840
i'm just really really really excited

774
00:24:18,240 --> 00:24:21,200
about this whole change it's uh it's

775
00:24:19,840 --> 00:24:23,600
really cool

776
00:24:21,200 --> 00:24:25,039
um interestingly uh one possible

777
00:24:23,600 --> 00:24:28,080
direction this could evolve in

778
00:24:25,039 --> 00:24:30,158
is by integrating bpf uh as a way to

779
00:24:28,080 --> 00:24:32,320
basically execute a little bit of logic

780
00:24:30,159 --> 00:24:33,600
in between chain calls for example we

781
00:24:32,320 --> 00:24:34,639
can accept a socket

782
00:24:33,600 --> 00:24:36,719
which you know we don't know what the

783
00:24:34,640 --> 00:24:38,960
file descriptor of that new

784
00:24:36,720 --> 00:24:40,000
client is going to be yet um but we can

785
00:24:38,960 --> 00:24:42,559
use bpf

786
00:24:40,000 --> 00:24:43,919
to basically um uh then do a read on the

787
00:24:42,559 --> 00:24:44,799
same file descriptor and then write some

788
00:24:43,919 --> 00:24:46,880
stuff back to it

789
00:24:44,799 --> 00:24:48,639
so with bpf we're going to be doing even

790
00:24:46,880 --> 00:24:49,360
more interesting stuff without having to

791
00:24:48,640 --> 00:24:51,039
do

792
00:24:49,360 --> 00:24:53,760
an interaction between user space and

793
00:24:51,039 --> 00:24:55,440
kernel space it's it's an amazing system

794
00:24:53,760 --> 00:24:57,200
okay lots of people have been getting

795
00:24:55,440 --> 00:24:58,559
extremely good results with it

796
00:24:57,200 --> 00:25:00,080
everybody loves it anyone who's doing

797
00:24:58,559 --> 00:25:01,200
extremely high performance systems right

798
00:25:00,080 --> 00:25:04,559
now they are getting

799
00:25:01,200 --> 00:25:06,480
uh ridiculously cool results um and uh

800
00:25:04,559 --> 00:25:08,480
yeah if you're interested try out uh rio

801
00:25:06,480 --> 00:25:09,440
for i o u ring um if you have a linux

802
00:25:08,480 --> 00:25:10,960
kernel 5 1 and

803
00:25:09,440 --> 00:25:12,640
up you can start to use some of the

804
00:25:10,960 --> 00:25:15,200
operations and sled

805
00:25:12,640 --> 00:25:16,080
for everybody if you have to store some

806
00:25:15,200 --> 00:25:17,760
things so

807
00:25:16,080 --> 00:25:19,439
it's uh these are the projects that i'm

808
00:25:17,760 --> 00:25:21,360
excited to be talking about today

809
00:25:19,440 --> 00:25:22,480
um yeah we have some cool results i

810
00:25:21,360 --> 00:25:24,639
already talked about

811
00:25:22,480 --> 00:25:27,039
we want to do a lot more things if you

812
00:25:24,640 --> 00:25:29,600
want to help out i'm on github sponsors

813
00:25:27,039 --> 00:25:31,919
as i said i'm unemployable so i'm really

814
00:25:29,600 --> 00:25:34,719
uh trying to just work on open source

815
00:25:31,919 --> 00:25:36,000
right now through uh like donations and

816
00:25:34,720 --> 00:25:36,960
i'm trying to still make useful things

817
00:25:36,000 --> 00:25:39,600
for other people

818
00:25:36,960 --> 00:25:41,200
um also if you want to talk about

819
00:25:39,600 --> 00:25:42,399
distributed systems come in our discord

820
00:25:41,200 --> 00:25:45,039
channel um

821
00:25:42,400 --> 00:25:45,600
it's actually pretty pretty active uh

822
00:25:45,039 --> 00:25:47,600
and

823
00:25:45,600 --> 00:25:48,799
yeah if you're interested in helping out

824
00:25:47,600 --> 00:25:49,760
i love talking about this with other

825
00:25:48,799 --> 00:25:51,840
people so

826
00:25:49,760 --> 00:25:57,840
come and join us i also do russ

827
00:25:51,840 --> 00:25:57,840
trainings uh thanks

828
00:26:07,279 --> 00:26:09,360
you

