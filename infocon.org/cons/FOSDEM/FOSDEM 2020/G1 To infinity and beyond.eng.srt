1
00:00:08,800 --> 00:00:13,759
good to go

2
00:00:11,360 --> 00:00:14,480
hi my name is stephan johansson i work

3
00:00:13,759 --> 00:00:16,560
at oracle

4
00:00:14,480 --> 00:00:18,960
in the hotspot gc team i've been working

5
00:00:16,560 --> 00:00:21,038
with gc for the last seven years

6
00:00:18,960 --> 00:00:23,760
and but i've been at oracle for almost

7
00:00:21,039 --> 00:00:26,320
14 years now working closely to the jvm

8
00:00:23,760 --> 00:00:26,320
the whole time

9
00:00:27,279 --> 00:00:34,399
okay so my focus in gc has

10
00:00:31,119 --> 00:00:36,239
mostly been g1 uh and that's what i'm

11
00:00:34,399 --> 00:00:39,040
going to talk to you about today

12
00:00:36,239 --> 00:00:40,399
uh if we go back some years to when jdk8

13
00:00:39,040 --> 00:00:44,079
was released

14
00:00:40,399 --> 00:00:45,840
gm was kind of the new cool gc getting a

15
00:00:44,079 --> 00:00:47,440
lot of buzz and by some maybe being

16
00:00:45,840 --> 00:00:48,640
perceived a bit like buzz lightyear and

17
00:00:47,440 --> 00:00:51,760
toy story

18
00:00:48,640 --> 00:00:53,520
hence the title this is not true anymore

19
00:00:51,760 --> 00:00:55,199
instead we have new other cool uses

20
00:00:53,520 --> 00:00:58,239
we've heard about one today

21
00:00:55,199 --> 00:01:00,000
that gets most of the bus and g1 has

22
00:00:58,239 --> 00:01:03,199
matured into well-performing

23
00:01:00,000 --> 00:01:05,920
very stable default garbage collector

24
00:01:03,199 --> 00:01:07,360
the goal of this talk is to show this

25
00:01:05,920 --> 00:01:09,360
progress in g1

26
00:01:07,360 --> 00:01:10,799
and by doing so hopefully convince some

27
00:01:09,360 --> 00:01:14,240
of you still on jdk8

28
00:01:10,799 --> 00:01:17,520
to move to new yet rate jdk releases 11

29
00:01:14,240 --> 00:01:21,199
or maybe 14. before we get started

30
00:01:17,520 --> 00:01:22,000
you've seen this before the agenda for

31
00:01:21,200 --> 00:01:24,240
today

32
00:01:22,000 --> 00:01:26,720
i'm going to start off with a very short

33
00:01:24,240 --> 00:01:30,720
introduction to gcs concept

34
00:01:26,720 --> 00:01:32,960
then g1 in a very quick

35
00:01:30,720 --> 00:01:34,720
fashion and then focus mostly on the

36
00:01:32,960 --> 00:01:37,119
progress we've done in g1

37
00:01:34,720 --> 00:01:38,240
since jdk8 and hopefully in then i'll

38
00:01:37,119 --> 00:01:39,920
have some

39
00:01:38,240 --> 00:01:41,759
some time to do a short glimpse at the

40
00:01:39,920 --> 00:01:44,880
future

41
00:01:41,759 --> 00:01:46,880
so gc in open udk uh

42
00:01:44,880 --> 00:01:48,798
garbage collection is not only about

43
00:01:46,880 --> 00:01:50,798
collecting garbage before we can do that

44
00:01:48,799 --> 00:01:53,680
we need to hand out the memory and

45
00:01:50,799 --> 00:01:55,920
having a fast and efficient allocation

46
00:01:53,680 --> 00:01:57,119
algorithm is very important and this is

47
00:01:55,920 --> 00:01:58,799
something that's done

48
00:01:57,119 --> 00:02:01,040
fairly equally to all the garbage

49
00:01:58,799 --> 00:02:02,560
collectors in opengdk

50
00:02:01,040 --> 00:02:04,640
so what we have is something called t

51
00:02:02,560 --> 00:02:06,240
labs thread local allocation buffers

52
00:02:04,640 --> 00:02:08,720
so that when a yaw thread needs to

53
00:02:06,240 --> 00:02:10,160
allocate in memory or an object

54
00:02:08,720 --> 00:02:12,319
you basically just have to add to a

55
00:02:10,160 --> 00:02:14,879
pointer and fill out the object it's

56
00:02:12,319 --> 00:02:15,519
a little more but that's the gist of it

57
00:02:14,879 --> 00:02:17,120
and

58
00:02:15,520 --> 00:02:19,040
then when we have memory that's not used

59
00:02:17,120 --> 00:02:20,720
anymore then the garbage collection kick

60
00:02:19,040 --> 00:02:23,120
in and this is of course the most

61
00:02:20,720 --> 00:02:25,440
efficient or and most important thing

62
00:02:23,120 --> 00:02:27,040
for the garbage collection algorithms we

63
00:02:25,440 --> 00:02:28,160
have quite quite a few of them in open

64
00:02:27,040 --> 00:02:29,359
jdk

65
00:02:28,160 --> 00:02:31,440
as i mentioned you heard about

66
00:02:29,360 --> 00:02:33,360
shenandoah already

67
00:02:31,440 --> 00:02:35,040
when you design a garbage collection

68
00:02:33,360 --> 00:02:37,200
algorithm you have to take

69
00:02:35,040 --> 00:02:38,160
a few different content concepts into

70
00:02:37,200 --> 00:02:41,760
consideration

71
00:02:38,160 --> 00:02:44,720
and do some trade-offs between those

72
00:02:41,760 --> 00:02:46,399
we have many concepts but the the three

73
00:02:44,720 --> 00:02:49,519
i'm focusing on today are

74
00:02:46,400 --> 00:02:50,879
throughput latency and footprint by

75
00:02:49,519 --> 00:02:52,480
throughput will basically mean

76
00:02:50,879 --> 00:02:54,399
the number of operations you can

77
00:02:52,480 --> 00:02:56,879
complete in a set amount of time

78
00:02:54,400 --> 00:02:57,760
while latency is the time one operation

79
00:02:56,879 --> 00:03:00,799
takes to complete

80
00:02:57,760 --> 00:03:02,399
so if you have a long gc pause that will

81
00:03:00,800 --> 00:03:04,959
affect your latency

82
00:03:02,400 --> 00:03:06,640
footprint that is basically the resource

83
00:03:04,959 --> 00:03:07,599
overhead caused by a garbage collection

84
00:03:06,640 --> 00:03:11,119
algorithm

85
00:03:07,599 --> 00:03:11,839
so uh for example many of these

86
00:03:11,120 --> 00:03:13,920
algorithms

87
00:03:11,840 --> 00:03:15,840
need extra to be able to do the memory

88
00:03:13,920 --> 00:03:17,760
uh do the garbage collection

89
00:03:15,840 --> 00:03:20,000
uh and yeah i'm to focus on memory

90
00:03:17,760 --> 00:03:22,879
overhead today

91
00:03:20,000 --> 00:03:24,560
so the current collectors in openidk or

92
00:03:22,879 --> 00:03:26,959
actually i actually included

93
00:03:24,560 --> 00:03:29,200
cms as well even though it's been

94
00:03:26,959 --> 00:03:31,280
removed in jk14

95
00:03:29,200 --> 00:03:32,480
i'm sorry for those of you who had cms

96
00:03:31,280 --> 00:03:34,400
as their favorite

97
00:03:32,480 --> 00:03:35,518
but there are new good alternatives that

98
00:03:34,400 --> 00:03:38,239
we can use

99
00:03:35,519 --> 00:03:40,720
going forward so a few words about the

100
00:03:38,239 --> 00:03:43,040
collectors still around

101
00:03:40,720 --> 00:03:45,280
we have the serial collector very basic

102
00:03:43,040 --> 00:03:47,679
and easy to understand collector

103
00:03:45,280 --> 00:03:49,280
which has its main feature it has very

104
00:03:47,680 --> 00:03:50,720
low memory overhead so if you for

105
00:03:49,280 --> 00:03:53,599
example run something

106
00:03:50,720 --> 00:03:55,040
like a function in a cloud serial can be

107
00:03:53,599 --> 00:03:57,439
a really good choice

108
00:03:55,040 --> 00:03:58,959
because you might do not do very much

109
00:03:57,439 --> 00:04:01,200
garbage collection

110
00:03:58,959 --> 00:04:02,720
and the parallel dc was the default up

111
00:04:01,200 --> 00:04:05,439
until jdk8

112
00:04:02,720 --> 00:04:07,120
it's very throughput oriented focusing

113
00:04:05,439 --> 00:04:07,840
on gaming the best possible throughput

114
00:04:07,120 --> 00:04:10,159
for java

115
00:04:07,840 --> 00:04:11,120
and it also has very good average pulse

116
00:04:10,159 --> 00:04:14,239
times

117
00:04:11,120 --> 00:04:16,478
but the worst case latencies can be bad

118
00:04:14,239 --> 00:04:17,280
because if you run with parallel for a

119
00:04:16,478 --> 00:04:19,758
long time

120
00:04:17,279 --> 00:04:20,559
in many cases you eventually run into a

121
00:04:19,759 --> 00:04:23,360
full collection

122
00:04:20,560 --> 00:04:25,040
which has yeah that they take a lot of

123
00:04:23,360 --> 00:04:26,960
time

124
00:04:25,040 --> 00:04:29,199
so there's where g1 come in the new

125
00:04:26,960 --> 00:04:30,880
default collector since jdk9

126
00:04:29,199 --> 00:04:32,479
we try to have a balanced performance

127
00:04:30,880 --> 00:04:34,800
still providing good throughput

128
00:04:32,479 --> 00:04:35,520
but also caring about the latencies how

129
00:04:34,800 --> 00:04:38,479
we do this

130
00:04:35,520 --> 00:04:39,280
i will show you a bit later the new and

131
00:04:38,479 --> 00:04:41,919
cool uses

132
00:04:39,280 --> 00:04:43,280
focusing on low latency said you see in

133
00:04:41,919 --> 00:04:46,000
shenandoah

134
00:04:43,280 --> 00:04:47,359
they are experimental but yeah i guess

135
00:04:46,000 --> 00:04:50,240
both of the teams are working

136
00:04:47,360 --> 00:04:50,880
hard to to make them fully supported and

137
00:04:50,240 --> 00:04:53,280
you've

138
00:04:50,880 --> 00:04:55,600
heard a lot about shenandoah already but

139
00:04:53,280 --> 00:04:57,679
yeah from cgc

140
00:04:55,600 --> 00:04:59,199
the main goal here is to try to provide

141
00:04:57,680 --> 00:05:01,600
some millisecond pulse times

142
00:04:59,199 --> 00:05:04,560
so yeah we're looking forward to that

143
00:05:01,600 --> 00:05:04,560
being fully supported

144
00:05:04,800 --> 00:05:09,360
that was that about this so let's move

145
00:05:07,039 --> 00:05:12,080
over on to g1

146
00:05:09,360 --> 00:05:14,400
as i mentioned the basic idea here is to

147
00:05:12,080 --> 00:05:17,440
write a balance between latency and

148
00:05:14,400 --> 00:05:20,638
throughput to be able to do this we have

149
00:05:17,440 --> 00:05:22,400
two big concepts in g1

150
00:05:20,639 --> 00:05:24,240
of course there are more things needed

151
00:05:22,400 --> 00:05:26,320
but the two big things are

152
00:05:24,240 --> 00:05:28,080
that it's really regional based and we

153
00:05:26,320 --> 00:05:28,880
have concurrent marking what we mean by

154
00:05:28,080 --> 00:05:31,758
region based

155
00:05:28,880 --> 00:05:33,280
is that we divide the hip into several

156
00:05:31,759 --> 00:05:35,680
hip regions

157
00:05:33,280 --> 00:05:38,479
and so for example if you have a 10

158
00:05:35,680 --> 00:05:40,560
gigabyte of heat we try to have 2 000

159
00:05:38,479 --> 00:05:41,919
regions

160
00:05:40,560 --> 00:05:44,080
but that's hard because you want a

161
00:05:41,919 --> 00:05:45,758
multiple by two region size

162
00:05:44,080 --> 00:05:47,359
so you'll have a few more but we'll

163
00:05:45,759 --> 00:05:50,320
we'll use a four meg

164
00:05:47,360 --> 00:05:50,880
region size those regions can be used

165
00:05:50,320 --> 00:05:54,080
both for

166
00:05:50,880 --> 00:05:56,400
young and old generation so g1 is still

167
00:05:54,080 --> 00:05:57,199
generally regenerational with two

168
00:05:56,400 --> 00:05:59,280
generations

169
00:05:57,199 --> 00:06:01,680
but these generations are not big chunks

170
00:05:59,280 --> 00:06:02,880
of memory but they are a set of regions

171
00:06:01,680 --> 00:06:05,280
instead

172
00:06:02,880 --> 00:06:06,080
what this gives us is that we can

173
00:06:05,280 --> 00:06:08,159
collect a few

174
00:06:06,080 --> 00:06:10,159
old regions at a time we don't have to

175
00:06:08,160 --> 00:06:13,680
collect all old regions at once which is

176
00:06:10,160 --> 00:06:15,120
the case for serial and parallel

177
00:06:13,680 --> 00:06:17,440
but to be able to do this we also need

178
00:06:15,120 --> 00:06:19,120
to know what's live in those old regions

179
00:06:17,440 --> 00:06:20,479
and here's where the concurrent morgan

180
00:06:19,120 --> 00:06:23,440
comes in

181
00:06:20,479 --> 00:06:24,639
and as roman mentioned previously i

182
00:06:23,440 --> 00:06:26,800
won't have time to explain how the

183
00:06:24,639 --> 00:06:31,039
concurrent marking works

184
00:06:26,800 --> 00:06:32,560
but yeah look it up

185
00:06:31,039 --> 00:06:34,240
so basically when you have the marking

186
00:06:32,560 --> 00:06:36,720
information in place and you have

187
00:06:34,240 --> 00:06:37,520
a region based collector you're able to

188
00:06:36,720 --> 00:06:40,080
collect a few

189
00:06:37,520 --> 00:06:41,198
old regions at the time we call this

190
00:06:40,080 --> 00:06:43,840
mixed collections

191
00:06:41,199 --> 00:06:44,960
and by doing so we are in many cases

192
00:06:43,840 --> 00:06:48,159
able to avoid

193
00:06:44,960 --> 00:06:50,638
the long and costly fall collections uh

194
00:06:48,160 --> 00:06:51,919
another thing with g1 that might have

195
00:06:50,639 --> 00:06:53,360
been a problem in the past but we're

196
00:06:51,919 --> 00:06:54,080
working hard on it trying to make it

197
00:06:53,360 --> 00:06:56,080
through

198
00:06:54,080 --> 00:06:58,000
is that we want it to be easy to tune

199
00:06:56,080 --> 00:06:59,680
you you shouldn't be able to have to set

200
00:06:58,000 --> 00:07:03,199
a lot of different flags

201
00:06:59,680 --> 00:07:05,360
to to change the behavior

202
00:07:03,199 --> 00:07:08,160
so we have a main tuning knob it's the

203
00:07:05,360 --> 00:07:08,160
pulse time goal

204
00:07:08,400 --> 00:07:12,080
and if you want to increase the

205
00:07:10,000 --> 00:07:14,000
throughput you can increase this value

206
00:07:12,080 --> 00:07:15,599
if you want better latencies you turn

207
00:07:14,000 --> 00:07:17,440
this value down so

208
00:07:15,599 --> 00:07:19,199
the the default value here is 200

209
00:07:17,440 --> 00:07:21,120
milliseconds that has shown us

210
00:07:19,199 --> 00:07:24,080
that it's a pretty good default it gives

211
00:07:21,120 --> 00:07:25,759
a balance between latency and throughput

212
00:07:24,080 --> 00:07:27,758
but your application might have

213
00:07:25,759 --> 00:07:28,560
different needs so try tune this the

214
00:07:27,759 --> 00:07:32,240
first thing you do

215
00:07:28,560 --> 00:07:32,240
if you want to change the behavior of d1

216
00:07:32,560 --> 00:07:36,400
so the current status of g1 it was added

217
00:07:35,360 --> 00:07:40,080
in jdk 6

218
00:07:36,400 --> 00:07:42,318
but the support came in jdk 7u4

219
00:07:40,080 --> 00:07:44,159
and after that we worked really hard on

220
00:07:42,319 --> 00:07:46,080
making g1 sort of complete uh

221
00:07:44,160 --> 00:07:47,199
adding some really necessary features to

222
00:07:46,080 --> 00:07:49,120
it in the jdk8

223
00:07:47,199 --> 00:07:50,319
time frame and also improving the

224
00:07:49,120 --> 00:07:53,680
performance a lot

225
00:07:50,319 --> 00:07:55,599
and one such feature is

226
00:07:53,680 --> 00:07:57,039
class unloading of the concurrent mark

227
00:07:55,599 --> 00:07:58,878
so you don't have to rely on a full

228
00:07:57,039 --> 00:08:01,599
collection to be able to do

229
00:07:58,879 --> 00:08:02,800
class unloading because g1 tries to

230
00:08:01,599 --> 00:08:05,280
avoid full collections

231
00:08:02,800 --> 00:08:06,879
so in practice you would never do class

232
00:08:05,280 --> 00:08:08,479
unloading

233
00:08:06,879 --> 00:08:10,240
indicate where the class unloading of

234
00:08:08,479 --> 00:08:12,400
the concurrent mark

235
00:08:10,240 --> 00:08:14,400
and a lot of other features making it

236
00:08:12,400 --> 00:08:16,878
more stable and more mature

237
00:08:14,400 --> 00:08:17,758
and in jdk 9 we decided that it was time

238
00:08:16,879 --> 00:08:19,840
to make

239
00:08:17,759 --> 00:08:21,120
t1 the default collector a somewhat

240
00:08:19,840 --> 00:08:23,119
controversial decision

241
00:08:21,120 --> 00:08:24,879
uh because people thought that parallel

242
00:08:23,120 --> 00:08:26,879
has better throughput

243
00:08:24,879 --> 00:08:29,120
but we saw that having a balance between

244
00:08:26,879 --> 00:08:31,039
latency and throughput is very important

245
00:08:29,120 --> 00:08:33,200
and the fact that we're also working

246
00:08:31,039 --> 00:08:36,559
really hard on improving d1

247
00:08:33,200 --> 00:08:37,120
we want the users to benefit from all

248
00:08:36,559 --> 00:08:39,199
those

249
00:08:37,120 --> 00:08:40,159
improvements without having to switch

250
00:08:39,200 --> 00:08:42,640
easy

251
00:08:40,159 --> 00:08:45,039
so making it to 49 i think it was a good

252
00:08:42,640 --> 00:08:45,039
decision

253
00:08:46,240 --> 00:08:49,920
yeah that's the background let's look at

254
00:08:47,760 --> 00:08:52,560
the progress or what we've done since

255
00:08:49,920 --> 00:08:52,560
jdk8

256
00:08:53,040 --> 00:08:56,399
we've done a lot uh around 700

257
00:08:55,680 --> 00:08:59,680
enhancements

258
00:08:56,399 --> 00:09:00,560
to g1 since jdk8 some of those are big

259
00:08:59,680 --> 00:09:02,160
features

260
00:09:00,560 --> 00:09:04,239
but a lot of them are just small

261
00:09:02,160 --> 00:09:06,079
enhancements improving small parts of

262
00:09:04,240 --> 00:09:08,480
the garbage collection algorithm

263
00:09:06,080 --> 00:09:09,680
and those together show some really

264
00:09:08,480 --> 00:09:12,480
significant improvements

265
00:09:09,680 --> 00:09:13,839
uh and we see those across all areas

266
00:09:12,480 --> 00:09:15,680
it's not done like we're

267
00:09:13,839 --> 00:09:16,880
we're only improved latency or only

268
00:09:15,680 --> 00:09:19,760
improved footprint

269
00:09:16,880 --> 00:09:21,439
we managed to improve all areas and the

270
00:09:19,760 --> 00:09:22,160
way we've been able to do this is that

271
00:09:21,440 --> 00:09:25,279
we've improved

272
00:09:22,160 --> 00:09:28,000
on old efficiencies and in some cases

273
00:09:25,279 --> 00:09:28,880
been able to to cut away trade-offs that

274
00:09:28,000 --> 00:09:32,160
were done

275
00:09:28,880 --> 00:09:35,040
in the early days of g1 so yeah we see

276
00:09:32,160 --> 00:09:37,839
some really significant improvements in

277
00:09:35,040 --> 00:09:37,839
g1

278
00:09:43,680 --> 00:09:47,839
so throughput one of the big things

279
00:09:46,240 --> 00:09:48,640
we've done to improve the throughput in

280
00:09:47,839 --> 00:09:50,399
g1

281
00:09:48,640 --> 00:09:52,959
is that we've improved the pneuma

282
00:09:50,399 --> 00:09:55,839
awareness so

283
00:09:52,959 --> 00:09:56,640
g1 has always have a very basic number

284
00:09:55,839 --> 00:09:58,880
support since the

285
00:09:56,640 --> 00:10:00,640
java heap itself has a basic neuma

286
00:09:58,880 --> 00:10:04,320
support but what we've done

287
00:10:00,640 --> 00:10:06,880
in in the late latest release is that

288
00:10:04,320 --> 00:10:07,680
we now actively try to allocate java

289
00:10:06,880 --> 00:10:09,600
memory

290
00:10:07,680 --> 00:10:11,920
on a local node giving better

291
00:10:09,600 --> 00:10:13,440
performance the same goes for the gc the

292
00:10:11,920 --> 00:10:15,920
user tries to keep

293
00:10:13,440 --> 00:10:17,440
the the memory on the same numerator as

294
00:10:15,920 --> 00:10:19,680
it was allocated

295
00:10:17,440 --> 00:10:22,160
we still have more ideas and more work

296
00:10:19,680 --> 00:10:23,599
to be done in this area but

297
00:10:22,160 --> 00:10:26,079
those things really showed some good

298
00:10:23,600 --> 00:10:26,079
improvements

299
00:10:27,200 --> 00:10:30,800
we also spent quite significant amount

300
00:10:29,040 --> 00:10:32,800
of time on making the concurrent work

301
00:10:30,800 --> 00:10:35,120
more efficient

302
00:10:32,800 --> 00:10:37,040
so the important thing here is to try to

303
00:10:35,120 --> 00:10:38,800
keep the gc out of the way making sure

304
00:10:37,040 --> 00:10:39,920
the java application can use as many

305
00:10:38,800 --> 00:10:43,040
resources

306
00:10:39,920 --> 00:10:45,360
or all the resources in the best case

307
00:10:43,040 --> 00:10:46,959
so this can this can be that making the

308
00:10:45,360 --> 00:10:47,920
market more efficient in itself but it

309
00:10:46,959 --> 00:10:49,760
can also be

310
00:10:47,920 --> 00:10:51,360
delaying the marking or making sure that

311
00:10:49,760 --> 00:10:53,360
instead of running five marking cycles

312
00:10:51,360 --> 00:10:55,920
we only run two because we

313
00:10:53,360 --> 00:10:57,120
we can still avoid the full collections

314
00:10:55,920 --> 00:10:59,360
and so

315
00:10:57,120 --> 00:11:00,399
the work we've done there is also

316
00:10:59,360 --> 00:11:03,040
proving to be really

317
00:11:00,399 --> 00:11:04,720
important for throughput we also added a

318
00:11:03,040 --> 00:11:06,480
parallel full collection to g1

319
00:11:04,720 --> 00:11:08,320
and this can be seen both as a

320
00:11:06,480 --> 00:11:10,320
throughput and latency thing but

321
00:11:08,320 --> 00:11:12,399
if you want to tune g1 to be more

322
00:11:10,320 --> 00:11:14,640
throughput oriented

323
00:11:12,399 --> 00:11:16,240
you might be able to suffer or take the

324
00:11:14,640 --> 00:11:19,120
hit of a few full diseases

325
00:11:16,240 --> 00:11:20,000
if they take not extremely long amount

326
00:11:19,120 --> 00:11:22,320
of time

327
00:11:20,000 --> 00:11:24,160
uh so having a parallel full gc that

328
00:11:22,320 --> 00:11:25,120
works kind of similar to the other full

329
00:11:24,160 --> 00:11:27,680
uses

330
00:11:25,120 --> 00:11:28,720
out there is really important for g1 if

331
00:11:27,680 --> 00:11:31,760
you want to tune it

332
00:11:28,720 --> 00:11:35,680
to like work well in batch work

333
00:11:31,760 --> 00:11:36,399
scenarios so let's take a look at some

334
00:11:35,680 --> 00:11:39,040
numbers

335
00:11:36,399 --> 00:11:42,320
uh from the throughput improvements uh

336
00:11:39,040 --> 00:11:45,360
i'm using spec abv 2015 here uh

337
00:11:42,320 --> 00:11:47,279
the the results we're looking at are the

338
00:11:45,360 --> 00:11:49,040
the throughput metrics and the raw

339
00:11:47,279 --> 00:11:51,600
throughput metrics from speculb

340
00:11:49,040 --> 00:11:54,160
if you're familiar with this benchmark

341
00:11:51,600 --> 00:11:57,120
uh it's run with a 16 gigabyte of heap

342
00:11:54,160 --> 00:11:58,319
and i've i normalized the score towards

343
00:11:57,120 --> 00:11:59,600
jdk8

344
00:11:58,320 --> 00:12:01,519
and parallel because that was the

345
00:11:59,600 --> 00:12:04,480
default back in jdk8

346
00:12:01,519 --> 00:12:05,920
so as we can see in in jdk8 g1 was

347
00:12:04,480 --> 00:12:08,160
behind

348
00:12:05,920 --> 00:12:09,199
but we've been able to close this gap in

349
00:12:08,160 --> 00:12:12,719
jdk 11

350
00:12:09,200 --> 00:12:14,160
and 14 we're around 10 better

351
00:12:12,720 --> 00:12:15,920
when it comes to performance or

352
00:12:14,160 --> 00:12:18,079
throughput performance

353
00:12:15,920 --> 00:12:19,839
this is of course not only these

354
00:12:18,079 --> 00:12:21,279
improvements the whole java platform

355
00:12:19,839 --> 00:12:22,959
has been made more efficient and

356
00:12:21,279 --> 00:12:26,000
performs better

357
00:12:22,959 --> 00:12:27,439
but having the gc g1 especially keep

358
00:12:26,000 --> 00:12:28,800
keep more out of the way

359
00:12:27,440 --> 00:12:31,279
has really helped improving this

360
00:12:28,800 --> 00:12:34,319
performance and

361
00:12:31,279 --> 00:12:35,600
yeah like letting java run on the cpus

362
00:12:34,320 --> 00:12:39,839
instead of the gc running on

363
00:12:35,600 --> 00:12:39,839
cpu really helps here

364
00:12:41,360 --> 00:12:47,440
yeah let's move over to latency

365
00:12:44,800 --> 00:12:48,319
this is an area where we yeah most or

366
00:12:47,440 --> 00:12:49,920
most but

367
00:12:48,320 --> 00:12:52,639
at least a lot of the enhancements gone

368
00:12:49,920 --> 00:12:54,639
in here we improve the parallelism

369
00:12:52,639 --> 00:12:55,920
in a lot of the different gc phases and

370
00:12:54,639 --> 00:12:57,760
making sure that

371
00:12:55,920 --> 00:13:00,160
even though a face seems to be pretty

372
00:12:57,760 --> 00:13:02,079
small we make sure that it's done

373
00:13:00,160 --> 00:13:03,839
run in parallel and and take a short

374
00:13:02,079 --> 00:13:05,519
amount of time to keep the pulses as

375
00:13:03,839 --> 00:13:08,720
short as possible

376
00:13:05,519 --> 00:13:10,720
we also work very hard on making those

377
00:13:08,720 --> 00:13:12,079
phases more efficient for example

378
00:13:10,720 --> 00:13:14,399
reference processing

379
00:13:12,079 --> 00:13:15,920
that's the overlying references that

380
00:13:14,399 --> 00:13:17,519
phase has been both improved when it

381
00:13:15,920 --> 00:13:20,240
comes to parallelism and the way

382
00:13:17,519 --> 00:13:21,360
the efficiency of the processing so if

383
00:13:20,240 --> 00:13:22,800
you have an application

384
00:13:21,360 --> 00:13:24,720
where you're in the past in problems

385
00:13:22,800 --> 00:13:26,479
with with reference processing

386
00:13:24,720 --> 00:13:28,399
it might be a good idea to check out the

387
00:13:26,480 --> 00:13:30,399
later releases

388
00:13:28,399 --> 00:13:31,839
we also improved a lot of pulse on on

389
00:13:30,399 --> 00:13:34,720
paul's time predictions

390
00:13:31,839 --> 00:13:36,000
and what i mean by that is basically d1

391
00:13:34,720 --> 00:13:39,279
tries to predict

392
00:13:36,000 --> 00:13:42,000
the number of regions it can collect uh

393
00:13:39,279 --> 00:13:43,360
keeping the pulse target set by the user

394
00:13:42,000 --> 00:13:45,120
if those predictions are bad

395
00:13:43,360 --> 00:13:48,160
we might take too many regions and then

396
00:13:45,120 --> 00:13:50,399
not be able to keep the post-time target

397
00:13:48,160 --> 00:13:51,600
so working on this is really really

398
00:13:50,399 --> 00:13:54,880
important if you want

399
00:13:51,600 --> 00:13:57,120
like a predictable latency story

400
00:13:54,880 --> 00:13:58,880
another part of this predictable latency

401
00:13:57,120 --> 00:14:00,000
story is the border millimeters

402
00:13:58,880 --> 00:14:01,279
collections

403
00:14:00,000 --> 00:14:03,279
and as i mentioned before mixed

404
00:14:01,279 --> 00:14:03,839
collections are the collections where we

405
00:14:03,279 --> 00:14:07,040
collect

406
00:14:03,839 --> 00:14:08,480
a set of old regions and those are a bit

407
00:14:07,040 --> 00:14:10,560
harder to predict because we're not

408
00:14:08,480 --> 00:14:12,160
doing this as often and they have

409
00:14:10,560 --> 00:14:15,199
different characteristics

410
00:14:12,160 --> 00:14:17,519
from the young regions so

411
00:14:15,199 --> 00:14:18,319
what we do here is that instead of like

412
00:14:17,519 --> 00:14:20,560
before these

413
00:14:18,320 --> 00:14:22,000
start select a set of old regions that

414
00:14:20,560 --> 00:14:24,000
we have to complete

415
00:14:22,000 --> 00:14:25,120
we select the set of old regions that we

416
00:14:24,000 --> 00:14:27,279
tried to complete

417
00:14:25,120 --> 00:14:30,000
and then we complete as many as we can

418
00:14:27,279 --> 00:14:31,760
until the post-time target is mets or we

419
00:14:30,000 --> 00:14:33,120
don't go over the post-time target if

420
00:14:31,760 --> 00:14:36,800
possible in some cases

421
00:14:33,120 --> 00:14:38,800
we still do but this is a good

422
00:14:36,800 --> 00:14:41,040
a good improvement to try to to achieve

423
00:14:38,800 --> 00:14:44,079
that always keeping the post-time target

424
00:14:41,040 --> 00:14:46,880
goal that we have

425
00:14:44,079 --> 00:14:47,760
yeah let's look at some results here uh

426
00:14:46,880 --> 00:14:50,959
once again

427
00:14:47,760 --> 00:14:52,399
speculably 2015 results but this time

428
00:14:50,959 --> 00:14:55,599
we're looking at the throughput

429
00:14:52,399 --> 00:14:58,079
requirement the the throughput risk

430
00:14:55,600 --> 00:15:00,639
the throughput metric but with latency

431
00:14:58,079 --> 00:15:00,638
requirements

432
00:15:00,800 --> 00:15:04,319
so these are basically still throughput

433
00:15:03,680 --> 00:15:06,239
scores

434
00:15:04,320 --> 00:15:07,360
but they are affected a lot by the

435
00:15:06,240 --> 00:15:10,480
latency

436
00:15:07,360 --> 00:15:12,639
provided by the java platform

437
00:15:10,480 --> 00:15:15,120
again it's from the same rounds so it's

438
00:15:12,639 --> 00:15:18,880
a 16 gig hit

439
00:15:15,120 --> 00:15:22,399
we see here that g1 in jdk8

440
00:15:18,880 --> 00:15:23,600
not very impressive but we've done a lot

441
00:15:22,399 --> 00:15:27,279
of work

442
00:15:23,600 --> 00:15:28,160
so in jdk 11 around 10 15 percent up i

443
00:15:27,279 --> 00:15:30,320
think

444
00:15:28,160 --> 00:15:31,759
but the big thing comes in jdk 14 where

445
00:15:30,320 --> 00:15:35,440
we're more than 40

446
00:15:31,759 --> 00:15:37,040
better than parallel in jdk8

447
00:15:35,440 --> 00:15:38,839
and even more if you compared to g1

448
00:15:37,040 --> 00:15:42,079
itself

449
00:15:38,839 --> 00:15:45,440
uh the cool thing here is also

450
00:15:42,079 --> 00:15:48,160
to me cool thing uh is the last bar here

451
00:15:45,440 --> 00:15:50,000
so there i set the pause time target to

452
00:15:48,160 --> 00:15:51,519
50 milliseconds instead of the default

453
00:15:50,000 --> 00:15:53,839
200 milliseconds

454
00:15:51,519 --> 00:15:55,680
uh by doing so you can see that i

455
00:15:53,839 --> 00:15:59,120
improved the

456
00:15:55,680 --> 00:16:00,880
the latency score uh towards the default

457
00:15:59,120 --> 00:16:02,399
this of course comes with the throughput

458
00:16:00,880 --> 00:16:04,880
cost but

459
00:16:02,399 --> 00:16:06,160
if your main goal is to have good

460
00:16:04,880 --> 00:16:08,959
latencies

461
00:16:06,160 --> 00:16:11,439
it's very easy to improve that by just

462
00:16:08,959 --> 00:16:13,439
tuning the post angle

463
00:16:11,440 --> 00:16:14,560
uh another thing to mention is like the

464
00:16:13,440 --> 00:16:17,440
average pulse time

465
00:16:14,560 --> 00:16:19,758
uh from the adk8 for g1 the average

466
00:16:17,440 --> 00:16:22,320
pause is around 160 milliseconds

467
00:16:19,759 --> 00:16:23,839
uh so we're still we're still below the

468
00:16:22,320 --> 00:16:26,160
post time target

469
00:16:23,839 --> 00:16:26,959
uh in jdk 14 it's down to 100

470
00:16:26,160 --> 00:16:29,759
milliseconds

471
00:16:26,959 --> 00:16:31,119
uh so we've done some quite significant

472
00:16:29,759 --> 00:16:34,399
improvements here

473
00:16:31,120 --> 00:16:36,240
and that's really nice to see and the

474
00:16:34,399 --> 00:16:39,519
last thing i want to talk about

475
00:16:36,240 --> 00:16:42,320
is uh the footprint

476
00:16:39,519 --> 00:16:43,440
and as i mentioned this is memory

477
00:16:42,320 --> 00:16:45,040
footprint

478
00:16:43,440 --> 00:16:46,720
something we heard a lot when it comes

479
00:16:45,040 --> 00:16:49,279
to g1 is that

480
00:16:46,720 --> 00:16:50,240
the remember sets take up way too much

481
00:16:49,279 --> 00:16:52,959
space

482
00:16:50,240 --> 00:16:54,560
and that was true back in the day uh the

483
00:16:52,959 --> 00:16:56,719
remember sets are the data structure

484
00:16:54,560 --> 00:16:59,199
that g1 needs to be able to collect

485
00:16:56,720 --> 00:17:00,560
a region so all young regions always

486
00:16:59,199 --> 00:17:02,639
have remember sets

487
00:17:00,560 --> 00:17:04,079
in the past old regions also always had

488
00:17:02,639 --> 00:17:06,160
remember sets

489
00:17:04,079 --> 00:17:07,359
but we only collect old regions of the

490
00:17:06,160 --> 00:17:10,880
concurrent mark cycles

491
00:17:07,359 --> 00:17:12,799
so for much of the application run

492
00:17:10,880 --> 00:17:17,199
we kept those rumor sets around without

493
00:17:12,799 --> 00:17:17,199
having to without needing them basically

494
00:17:17,599 --> 00:17:21,438
so what we realized was if we can

495
00:17:19,760 --> 00:17:22,480
rebuild those remember sets during the

496
00:17:21,439 --> 00:17:24,079
concurrent cycle

497
00:17:22,480 --> 00:17:25,679
and just having them around when we

498
00:17:24,079 --> 00:17:27,438
actually need them that should provide a

499
00:17:25,679 --> 00:17:29,919
much better user experience

500
00:17:27,439 --> 00:17:31,120
and i'll show you that in the next slide

501
00:17:29,919 --> 00:17:33,679
how how much

502
00:17:31,120 --> 00:17:35,280
this gave us and we also improved the

503
00:17:33,679 --> 00:17:38,880
sizing ergonomics a lot

504
00:17:35,280 --> 00:17:40,720
uh since the adk8 time frame uh

505
00:17:38,880 --> 00:17:42,640
and this is basically making sure that

506
00:17:40,720 --> 00:17:43,600
besides the remember set data structures

507
00:17:42,640 --> 00:17:45,919
correctly with the

508
00:17:43,600 --> 00:17:48,000
regards to to the region size and stuff

509
00:17:45,919 --> 00:17:52,000
like that making sure that

510
00:17:48,000 --> 00:17:54,080
yeah they they follow a good pattern

511
00:17:52,000 --> 00:17:56,000
another thing that i want to mention is

512
00:17:54,080 --> 00:17:56,480
the way g1 return memory to operating

513
00:17:56,000 --> 00:17:58,799
system

514
00:17:56,480 --> 00:18:00,559
when it comes to java hit memory in the

515
00:17:58,799 --> 00:18:01,440
past this was only done after full

516
00:18:00,559 --> 00:18:04,240
collection

517
00:18:01,440 --> 00:18:06,000
and as you remember g1 tries to avoid

518
00:18:04,240 --> 00:18:07,840
full collections so basically

519
00:18:06,000 --> 00:18:09,440
we never turn java hit memory even

520
00:18:07,840 --> 00:18:12,879
though it wasn't used

521
00:18:09,440 --> 00:18:15,360
uh nowadays g1 can return

522
00:18:12,880 --> 00:18:16,400
hit memory after concurrent work cycle

523
00:18:15,360 --> 00:18:18,159
and

524
00:18:16,400 --> 00:18:19,840
that together with the fact that we also

525
00:18:18,160 --> 00:18:20,640
can schedule periodic concurrent work

526
00:18:19,840 --> 00:18:22,159
cycles

527
00:18:20,640 --> 00:18:24,320
can really help out if you have an

528
00:18:22,160 --> 00:18:26,400
application which have kind of an idle

529
00:18:24,320 --> 00:18:27,840
state or something like that

530
00:18:26,400 --> 00:18:29,679
where you want it to behave better when

531
00:18:27,840 --> 00:18:31,918
it comes to memory footprint

532
00:18:29,679 --> 00:18:33,600
um i don't have any slides to show those

533
00:18:31,919 --> 00:18:34,720
kind of improvements but i think you get

534
00:18:33,600 --> 00:18:37,439
the idea

535
00:18:34,720 --> 00:18:40,080
uh instead i have a slide that shows the

536
00:18:37,440 --> 00:18:42,720
improvements down to the remember sets

537
00:18:40,080 --> 00:18:43,840
i tried to use spec v for this but they

538
00:18:42,720 --> 00:18:47,039
don't have very many

539
00:18:43,840 --> 00:18:49,199
old regions and objects so i had to use

540
00:18:47,039 --> 00:18:50,400
something we call the big rom tester to

541
00:18:49,200 --> 00:18:52,400
be able to show this

542
00:18:50,400 --> 00:18:53,679
this is instead of benchmark that's

543
00:18:52,400 --> 00:18:56,400
tried to mimic

544
00:18:53,679 --> 00:18:58,160
kind of an in-memory database keeping a

545
00:18:56,400 --> 00:19:00,080
fairly large live set with a lot of

546
00:18:58,160 --> 00:19:01,679
references between the objects

547
00:19:00,080 --> 00:19:03,360
which is kind of the worst case for the

548
00:19:01,679 --> 00:19:05,039
g1 remember sets

549
00:19:03,360 --> 00:19:07,520
and this is wrong with the 16 gigabyte

550
00:19:05,039 --> 00:19:10,640
of heap and as you can see

551
00:19:07,520 --> 00:19:13,120
in jdk8 uh we

552
00:19:10,640 --> 00:19:14,080
used around four gigabyte of extra

553
00:19:13,120 --> 00:19:16,639
native memory

554
00:19:14,080 --> 00:19:17,840
to be able to support a 16gb hip so this

555
00:19:16,640 --> 00:19:20,400
is a 25

556
00:19:17,840 --> 00:19:21,600
overhead so i really understand the

557
00:19:20,400 --> 00:19:23,919
people complaining about

558
00:19:21,600 --> 00:19:26,559
complaining about this what we managed

559
00:19:23,919 --> 00:19:27,919
to do in jdk 11 when where we added the

560
00:19:26,559 --> 00:19:30,080
rebuild remember that's that concurrent

561
00:19:27,919 --> 00:19:33,840
mark was to push it down to around

562
00:19:30,080 --> 00:19:34,480
2.7 2.8 gigabytes still quite a lot but

563
00:19:33,840 --> 00:19:36,879
the improved

564
00:19:34,480 --> 00:19:37,679
ergonomics around the sizing also really

565
00:19:36,880 --> 00:19:40,799
helped out

566
00:19:37,679 --> 00:19:44,960
so in jdk 14 we're down to

567
00:19:40,799 --> 00:19:46,799
around 1.6 1.7 gigabytes

568
00:19:44,960 --> 00:19:48,799
uh a fun thing is also to note is the

569
00:19:46,799 --> 00:19:51,120
kind of saw pattern you see here

570
00:19:48,799 --> 00:19:53,280
so basically the memory usage go up at

571
00:19:51,120 --> 00:19:54,639
the concurrent mortgage cycle end

572
00:19:53,280 --> 00:19:56,559
and then while doing the mixed

573
00:19:54,640 --> 00:19:58,799
collections it slowly decreases

574
00:19:56,559 --> 00:19:59,760
until no more mixed collections is done

575
00:19:58,799 --> 00:20:01,440
then go

576
00:19:59,760 --> 00:20:03,280
go down to the kind of stable state

577
00:20:01,440 --> 00:20:05,840
again

578
00:20:03,280 --> 00:20:07,440
but yeah the big tester is stressing

579
00:20:05,840 --> 00:20:10,158
this quite a lot so we're having

580
00:20:07,440 --> 00:20:12,880
back-to-back concurrent cycles

581
00:20:10,159 --> 00:20:14,400
uh is it's not only that we improved

582
00:20:12,880 --> 00:20:17,120
footprint for this benchmark

583
00:20:14,400 --> 00:20:18,720
uh as i mentioned earlier sometimes you

584
00:20:17,120 --> 00:20:22,158
have to do trade-off

585
00:20:18,720 --> 00:20:23,120
between latency and and footprint and

586
00:20:22,159 --> 00:20:24,799
stuff like that

587
00:20:23,120 --> 00:20:26,879
in this case we managed to improve both

588
00:20:24,799 --> 00:20:29,760
areas so the average pulse time in eight

589
00:20:26,880 --> 00:20:32,960
for this benchmark was 1.7 seconds

590
00:20:29,760 --> 00:20:33,520
with the default full scope and in jdk

591
00:20:32,960 --> 00:20:36,320
14

592
00:20:33,520 --> 00:20:37,840
this is down to 360 milliseconds so

593
00:20:36,320 --> 00:20:39,439
that's also quite a significant

594
00:20:37,840 --> 00:20:41,520
improvement in pulse times

595
00:20:39,440 --> 00:20:42,559
we're still over the target but that's

596
00:20:41,520 --> 00:20:44,720
also kind of

597
00:20:42,559 --> 00:20:46,080
it's yeah it's a really nice nasty

598
00:20:44,720 --> 00:20:48,400
benchmark uh

599
00:20:46,080 --> 00:20:50,080
in some sense but good for fighting

600
00:20:48,400 --> 00:20:53,360
problems

601
00:20:50,080 --> 00:20:56,799
uh yeah that's basically it i think i

602
00:20:53,360 --> 00:20:58,719
i will have time for the future uh

603
00:20:56,799 --> 00:21:00,400
so these are the main three

604
00:20:58,720 --> 00:21:02,559
investigation areas going forward

605
00:21:00,400 --> 00:21:04,559
humongous object handling and humongous

606
00:21:02,559 --> 00:21:06,879
objects are basically

607
00:21:04,559 --> 00:21:08,399
a bit simplified objects larger than a

608
00:21:06,880 --> 00:21:10,799
region in g1

609
00:21:08,400 --> 00:21:12,159
those can add up to fragmentation both

610
00:21:10,799 --> 00:21:13,918
within regions

611
00:21:12,159 --> 00:21:15,600
and between regions and we want to

612
00:21:13,919 --> 00:21:17,600
improve on this there are ongoing

613
00:21:15,600 --> 00:21:18,719
discussions on on how to do this most

614
00:21:17,600 --> 00:21:21,039
efficiently

615
00:21:18,720 --> 00:21:22,640
in the openmate opengdk mailing list so

616
00:21:21,039 --> 00:21:23,520
if you're interested please subscribe

617
00:21:22,640 --> 00:21:26,640
and

618
00:21:23,520 --> 00:21:28,400
follow discussions there or joining

619
00:21:26,640 --> 00:21:30,880
same goes for improving right barriers

620
00:21:28,400 --> 00:21:32,559
discussions ongoing there as well

621
00:21:30,880 --> 00:21:34,000
we have some different ideas on how to

622
00:21:32,559 --> 00:21:35,678
improve this

623
00:21:34,000 --> 00:21:37,120
the main reason behind this is to try to

624
00:21:35,679 --> 00:21:39,520
improve the g1 throughput

625
00:21:37,120 --> 00:21:41,199
because right now the g1 write barriers

626
00:21:39,520 --> 00:21:42,320
is a bit more expensive than the other

627
00:21:41,200 --> 00:21:44,000
ones

628
00:21:42,320 --> 00:21:45,918
but we're having we have plans on

629
00:21:44,000 --> 00:21:47,760
improving this as well and again

630
00:21:45,919 --> 00:21:49,120
footprint reductions as you see we still

631
00:21:47,760 --> 00:21:50,879
are have like 10

632
00:21:49,120 --> 00:21:52,639
overhead to be able to support that

633
00:21:50,880 --> 00:21:56,000
benchmark we want to

634
00:21:52,640 --> 00:21:56,000
to cut that down even more

635
00:21:56,559 --> 00:22:00,000
yeah the key takeaways from this

636
00:21:58,559 --> 00:22:02,158
presentation then so

637
00:22:00,000 --> 00:22:03,840
we've done massive improvements to g1

638
00:22:02,159 --> 00:22:06,640
since jdk8

639
00:22:03,840 --> 00:22:08,639
and if you if you have an application

640
00:22:06,640 --> 00:22:09,840
running g1 on an older version i really

641
00:22:08,640 --> 00:22:12,880
encourage you

642
00:22:09,840 --> 00:22:13,520
to try out jdk11 or yeti k14 and i'm

643
00:22:12,880 --> 00:22:15,280
sure that

644
00:22:13,520 --> 00:22:16,559
gonna give you a performance boost if

645
00:22:15,280 --> 00:22:18,000
you're not running j1

646
00:22:16,559 --> 00:22:20,399
you should move to a later release and

647
00:22:18,000 --> 00:22:22,080
try it out because it might help you out

648
00:22:20,400 --> 00:22:24,640
and we also have some really exciting

649
00:22:22,080 --> 00:22:26,879
features features and ideas in the past

650
00:22:24,640 --> 00:22:28,240
and i'm sure that they are going to help

651
00:22:26,880 --> 00:22:31,039
us bring g1

652
00:22:28,240 --> 00:22:33,280
to infinity and beyond that's all for me

653
00:22:31,039 --> 00:22:33,280
thanks

654
00:22:37,600 --> 00:22:42,320
we have a few minutes any takers

655
00:22:44,480 --> 00:22:47,679
hi um what's the lowest pause time

656
00:22:46,799 --> 00:22:49,610
target that

657
00:22:47,679 --> 00:22:51,039
is practical that you've seen

658
00:22:49,610 --> 00:22:53,678
[Applause]

659
00:22:51,039 --> 00:22:54,720
well very hard to say it depends on the

660
00:22:53,679 --> 00:22:57,840
application

661
00:22:54,720 --> 00:23:01,120
uh we we never

662
00:22:57,840 --> 00:23:02,080
force it much lower than or that's not

663
00:23:01,120 --> 00:23:04,399
true either but said

664
00:23:02,080 --> 00:23:06,240
as you see setting a pulse angle at 50

665
00:23:04,400 --> 00:23:09,360
is okay

666
00:23:06,240 --> 00:23:10,480
setting it at 10 you you will i mean you

667
00:23:09,360 --> 00:23:12,080
should try out cjc

668
00:23:10,480 --> 00:23:14,559
or or chando or something like that

669
00:23:12,080 --> 00:23:15,918
because g1 is focusing on a balance

670
00:23:14,559 --> 00:23:18,720
between latency and throughput

671
00:23:15,919 --> 00:23:20,000
so going all the way to the really ultra

672
00:23:18,720 --> 00:23:23,360
low latency

673
00:23:20,000 --> 00:23:24,880
is not really a goal um but yeah i think

674
00:23:23,360 --> 00:23:27,280
10 milliseconds should be okay

675
00:23:24,880 --> 00:23:28,640
uh in some in some cases depending on

676
00:23:27,280 --> 00:23:31,840
how the application looks

677
00:23:28,640 --> 00:23:33,760
uh you will do a lot of uses i

678
00:23:31,840 --> 00:23:36,158
i think the total is the time in the in

679
00:23:33,760 --> 00:23:39,360
the when i tuned the pause time goal

680
00:23:36,159 --> 00:23:42,960
it went from 200 seconds or yeah

681
00:23:39,360 --> 00:23:44,639
total time 200 seconds to 600 seconds so

682
00:23:42,960 --> 00:23:46,240
you trade away throughput when you do

683
00:23:44,640 --> 00:23:51,840
that kind of thing so you have to keep

684
00:23:46,240 --> 00:23:51,840
that in mind

685
00:24:01,200 --> 00:24:04,559
you mentioned making the right barrier

686
00:24:02,720 --> 00:24:06,080
faster yep but

687
00:24:04,559 --> 00:24:07,840
the right barrier should only be

688
00:24:06,080 --> 00:24:11,199
happening if there are inter-region

689
00:24:07,840 --> 00:24:14,320
pointers yeah is there any plan to make

690
00:24:11,200 --> 00:24:16,960
there to be fewer into region pointers

691
00:24:14,320 --> 00:24:18,080
so you mean increasing the region size

692
00:24:16,960 --> 00:24:19,600
or

693
00:24:18,080 --> 00:24:21,760
it's something that we've observed that

694
00:24:19,600 --> 00:24:23,520
we go into the right barrier a lot

695
00:24:21,760 --> 00:24:25,919
and we wouldn't expect that if

696
00:24:23,520 --> 00:24:29,360
everything was in the new gen

697
00:24:25,919 --> 00:24:30,320
oh okay yes well eventually you have to

698
00:24:29,360 --> 00:24:33,678
promote objects

699
00:24:30,320 --> 00:24:36,080
too old if they're really or you could

700
00:24:33,679 --> 00:24:38,799
have just one generation but

701
00:24:36,080 --> 00:24:39,600
might not yeah they're always trade-offs

702
00:24:38,799 --> 00:24:42,480
uh

703
00:24:39,600 --> 00:24:44,240
4g one we're not looking into liking it

704
00:24:42,480 --> 00:24:47,679
makes make single generation at

705
00:24:44,240 --> 00:24:50,799
right now or ever i would say

706
00:24:47,679 --> 00:24:52,720
uh but something that we have thought

707
00:24:50,799 --> 00:24:53,600
about is making the regions larger and

708
00:24:52,720 --> 00:24:56,640
that way

709
00:24:53,600 --> 00:24:57,840
having fewer in like points between

710
00:24:56,640 --> 00:25:00,240
regions

711
00:24:57,840 --> 00:25:01,360
uh not sure that really helped you out

712
00:25:00,240 --> 00:25:05,039
but

713
00:25:01,360 --> 00:25:05,039
thanks for the kissing thank you

714
00:25:07,279 --> 00:25:14,610
any more everything is crystal clear

715
00:25:10,960 --> 00:25:23,400
everybody will move to jdk 14.

716
00:25:14,610 --> 00:25:23,399
[Applause]

