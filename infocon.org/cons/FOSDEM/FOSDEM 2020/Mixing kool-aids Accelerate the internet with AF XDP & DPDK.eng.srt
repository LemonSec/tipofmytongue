1
00:00:05,279 --> 00:00:08,960
so we'll kick off hi everyone

2
00:00:07,120 --> 00:00:11,360
my name is kevin latz this is kira

3
00:00:08,960 --> 00:00:13,599
loftus we're network software engineers

4
00:00:11,360 --> 00:00:16,400
out of intel in janun which is hidden

5
00:00:13,599 --> 00:00:19,920
away in the west of ireland

6
00:00:16,400 --> 00:00:21,278
today we're gonna mix some kool-aids

7
00:00:19,920 --> 00:00:24,080
and hope things go quicker in the

8
00:00:21,279 --> 00:00:25,840
internet then um

9
00:00:24,080 --> 00:00:27,680
so most of you probably know what dbk

10
00:00:25,840 --> 00:00:30,000
and fxtp are

11
00:00:27,680 --> 00:00:31,679
for those of you who don't we'll do a

12
00:00:30,000 --> 00:00:34,079
quick introduction

13
00:00:31,679 --> 00:00:35,280
so dbdk is a set of user space libraries

14
00:00:34,079 --> 00:00:37,120
and drivers

15
00:00:35,280 --> 00:00:39,280
and they aim to accelerate pack

16
00:00:37,120 --> 00:00:42,480
processing workloads and they run

17
00:00:39,280 --> 00:00:43,680
on a variety of cpu architectures and

18
00:00:42,480 --> 00:00:44,320
some important things to remember for

19
00:00:43,680 --> 00:00:47,519
this talk

20
00:00:44,320 --> 00:00:48,239
is that um dbdk supports many different

21
00:00:47,520 --> 00:00:51,280
pmds

22
00:00:48,239 --> 00:00:53,280
and they're usually device specific and

23
00:00:51,280 --> 00:00:55,280
dbtk has its own memory management

24
00:00:53,280 --> 00:00:58,239
system

25
00:00:55,280 --> 00:00:59,199
af xdp is a kernel-based address family

26
00:00:58,239 --> 00:01:01,519
optimized for ipad

27
00:00:59,199 --> 00:01:02,640
prof high pack performance pack of

28
00:01:01,520 --> 00:01:05,840
processing

29
00:01:02,640 --> 00:01:06,320
um if xdp has its own sockets in order

30
00:01:05,840 --> 00:01:08,720
to move

31
00:01:06,320 --> 00:01:11,119
packets from kernel space to user space

32
00:01:08,720 --> 00:01:14,080
and it uses the internal fast path

33
00:01:11,119 --> 00:01:17,200
so it bypasses the network stack in

34
00:01:14,080 --> 00:01:18,560
order to move those packets quickly

35
00:01:17,200 --> 00:01:20,159
so if we take a closer look at a

36
00:01:18,560 --> 00:01:21,119
simplified diagram of the traditional

37
00:01:20,159 --> 00:01:23,280
dpdk model

38
00:01:21,119 --> 00:01:24,240
and down the bottom in kernel space we

39
00:01:23,280 --> 00:01:27,439
have

40
00:01:24,240 --> 00:01:30,479
dpdk specific kernel modules

41
00:01:27,439 --> 00:01:33,520
um they interact with the nics and

42
00:01:30,479 --> 00:01:36,000
expose them to user space and

43
00:01:33,520 --> 00:01:38,399
in user space then we have all of our

44
00:01:36,000 --> 00:01:40,720
dbdk pmds and our applications

45
00:01:38,400 --> 00:01:42,159
and they work together in order to do

46
00:01:40,720 --> 00:01:44,798
whatever wonderful things you want to do

47
00:01:42,159 --> 00:01:44,799
with your packets

48
00:01:45,600 --> 00:01:53,199
the aim of this work was to introduce

49
00:01:48,880 --> 00:01:56,158
and use the new dpdk of xdb pmd

50
00:01:53,200 --> 00:01:57,920
um and then that will directly talk to

51
00:01:56,159 --> 00:01:59,119
your nic driver so you can still use all

52
00:01:57,920 --> 00:02:01,280
of your

53
00:01:59,119 --> 00:02:04,159
usual kernel tools that you like using

54
00:02:01,280 --> 00:02:07,439
like ifconfig and so on

55
00:02:04,159 --> 00:02:08,080
um so the goal of this work was to have

56
00:02:07,439 --> 00:02:10,318
all gpt

57
00:02:08,080 --> 00:02:12,720
applications working out of the box um

58
00:02:10,318 --> 00:02:15,679
with the new way of xp pmd

59
00:02:12,720 --> 00:02:16,959
um and of course it should do so with go

60
00:02:15,680 --> 00:02:18,800
performance

61
00:02:16,959 --> 00:02:20,480
and the performance we were aiming for

62
00:02:18,800 --> 00:02:23,760
was close to

63
00:02:20,480 --> 00:02:28,079
or on par with the kernel

64
00:02:23,760 --> 00:02:28,079
sample app xdp sock

65
00:02:28,400 --> 00:02:31,680
the challenge with this was that

66
00:02:29,760 --> 00:02:34,160
frameworks like dbdk have their own

67
00:02:31,680 --> 00:02:35,200
memory management as said and these come

68
00:02:34,160 --> 00:02:37,840
with constraints

69
00:02:35,200 --> 00:02:38,720
and assumptions of their own dpdk

70
00:02:37,840 --> 00:02:42,319
specifically

71
00:02:38,720 --> 00:02:45,359
we have a discrepancy between the

72
00:02:42,319 --> 00:02:48,640
gptk and the fxtp buffer alignment

73
00:02:45,360 --> 00:02:53,840
so this prevents us from mapping gptk

74
00:02:48,640 --> 00:02:56,160
memory buffers directly to afx tpu-mems

75
00:02:53,840 --> 00:02:57,760
and in order to do this mapping um we

76
00:02:56,160 --> 00:02:59,680
needed to do some extra

77
00:02:57,760 --> 00:03:02,560
work and complexity which negatively

78
00:02:59,680 --> 00:03:02,560
impacts performance

79
00:03:02,959 --> 00:03:06,239
okay um so i'm going to talk about how

80
00:03:05,599 --> 00:03:09,920
both

81
00:03:06,239 --> 00:03:11,200
af xtp and tbdk lay out their memory for

82
00:03:09,920 --> 00:03:13,200
packet handling

83
00:03:11,200 --> 00:03:14,480
i'll talk about the differences between

84
00:03:13,200 --> 00:03:16,319
the two and

85
00:03:14,480 --> 00:03:18,399
why those differences pose the

86
00:03:16,319 --> 00:03:22,399
integration challenges which kevin just

87
00:03:18,400 --> 00:03:24,720
touched on there so af xtp

88
00:03:22,400 --> 00:03:25,599
it's got this concept of a umem or user

89
00:03:24,720 --> 00:03:27,840
memory

90
00:03:25,599 --> 00:03:29,200
and it's essentially an area of memory

91
00:03:27,840 --> 00:03:32,720
allocated by the user

92
00:03:29,200 --> 00:03:34,879
for packet data

93
00:03:32,720 --> 00:03:36,640
the um it's split up into equal sized

94
00:03:34,879 --> 00:03:37,518
chunks with each chunk being used to

95
00:03:36,640 --> 00:03:40,879
hold

96
00:03:37,519 --> 00:03:43,040
data from a particular packet and

97
00:03:40,879 --> 00:03:43,920
how it's used is for instance on the

98
00:03:43,040 --> 00:03:45,920
receive path

99
00:03:43,920 --> 00:03:47,599
the kernel will place packet data into a

100
00:03:45,920 --> 00:03:48,480
chunk for the user space process to

101
00:03:47,599 --> 00:03:50,159
retrieve

102
00:03:48,480 --> 00:03:52,720
and in our case our user's base

103
00:03:50,159 --> 00:03:55,519
processes to bdk

104
00:03:52,720 --> 00:03:56,080
and on the transmit path the user space

105
00:03:55,519 --> 00:03:57,920
process

106
00:03:56,080 --> 00:04:01,840
places packet data into a chunk for the

107
00:03:57,920 --> 00:04:01,839
kernel nic driver to transmit

108
00:04:02,560 --> 00:04:08,879
and prior to kernel 5.4 this

109
00:04:05,840 --> 00:04:11,439
umem this area of memory that afxdp uses

110
00:04:08,879 --> 00:04:13,920
to hold packet data it had a number of

111
00:04:11,439 --> 00:04:16,639
restrictions on it in terms of its size

112
00:04:13,920 --> 00:04:18,320
and its alignment

113
00:04:16,639 --> 00:04:20,320
the first being that the start address

114
00:04:18,320 --> 00:04:21,358
of the um had to be page size aligned so

115
00:04:20,320 --> 00:04:24,079
that's going to be 4k

116
00:04:21,358 --> 00:04:24,079
in most cases

117
00:04:24,400 --> 00:04:29,039
the chunks within the um they had to be

118
00:04:26,720 --> 00:04:32,160
power of two sized

119
00:04:29,040 --> 00:04:33,759
and kind of as a side effect of that the

120
00:04:32,160 --> 00:04:36,479
chunks could not cross

121
00:04:33,759 --> 00:04:37,360
page boundaries and in a kind of

122
00:04:36,479 --> 00:04:39,120
networking

123
00:04:37,360 --> 00:04:40,960
use case that leaves you really with

124
00:04:39,120 --> 00:04:41,680
only two potential chunk size options

125
00:04:40,960 --> 00:04:44,880
either 2k

126
00:04:41,680 --> 00:04:46,400
or 4k anything bigger than 4k

127
00:04:44,880 --> 00:04:49,759
and you're going to cross the page

128
00:04:46,400 --> 00:04:52,080
boundary and anything smaller than 2k

129
00:04:49,759 --> 00:04:54,240
isn't big enough for a networking packet

130
00:04:52,080 --> 00:04:56,159
or networking use case

131
00:04:54,240 --> 00:04:57,440
so in this example here we've got a

132
00:04:56,160 --> 00:05:01,120
chunk size of

133
00:04:57,440 --> 00:05:03,600
2k we've two 2k chunks per 4k page

134
00:05:01,120 --> 00:05:04,800
and as you can see none of the chunks

135
00:05:03,600 --> 00:05:08,400
are crossing the page boundaries

136
00:05:04,800 --> 00:05:10,400
everything is nice and neat and tidy

137
00:05:08,400 --> 00:05:12,159
the reason for these restrictions is

138
00:05:10,400 --> 00:05:12,960
essentially it just makes calculations

139
00:05:12,160 --> 00:05:14,800
in the kernel

140
00:05:12,960 --> 00:05:16,479
a little bit easier when everything is

141
00:05:14,800 --> 00:05:19,120
nicely aligned you can use things like

142
00:05:16,479 --> 00:05:22,880
masks etc

143
00:05:19,120 --> 00:05:25,199
okay so let's see how dbdk

144
00:05:22,880 --> 00:05:27,360
lays out its memory for packet handling

145
00:05:25,199 --> 00:05:27,840
and see if it satisfies the requirements

146
00:05:27,360 --> 00:05:31,039
of the

147
00:05:27,840 --> 00:05:33,758
af xtp umem

148
00:05:31,039 --> 00:05:34,719
so dvdk as many of you know or in the

149
00:05:33,759 --> 00:05:37,600
stn room

150
00:05:34,720 --> 00:05:39,440
it holds packet data inside structures

151
00:05:37,600 --> 00:05:40,400
known as memory buffers or mbuffs for

152
00:05:39,440 --> 00:05:43,199
short

153
00:05:40,400 --> 00:05:45,679
and a group of those together is known

154
00:05:43,199 --> 00:05:48,000
as an mbof pool

155
00:05:45,680 --> 00:05:49,759
and dpdk mf pools they don't have as

156
00:05:48,000 --> 00:05:51,520
strict restrictions on them as the af

157
00:05:49,759 --> 00:05:54,720
xtpum

158
00:05:51,520 --> 00:05:56,719
so for instance m buffs can be of any

159
00:05:54,720 --> 00:05:59,280
size within reason

160
00:05:56,720 --> 00:06:00,880
and they can have arbitrary alignment

161
00:05:59,280 --> 00:06:03,119
relevant to the page size so they can

162
00:06:00,880 --> 00:06:05,360
cross page boundaries

163
00:06:03,120 --> 00:06:06,560
so in this example here we've got a mbof

164
00:06:05,360 --> 00:06:09,600
size of maybe

165
00:06:06,560 --> 00:06:11,039
three and a half k and or m of their

166
00:06:09,600 --> 00:06:12,960
crossing page boundaries all over the

167
00:06:11,039 --> 00:06:14,960
place

168
00:06:12,960 --> 00:06:16,799
and i suppose why do we care whether or

169
00:06:14,960 --> 00:06:19,440
not the hdbk

170
00:06:16,800 --> 00:06:21,759
mbof pool um satisfies the requirements

171
00:06:19,440 --> 00:06:25,199
of the afx gpu mem

172
00:06:21,759 --> 00:06:27,360
and the reason is that in order to get

173
00:06:25,199 --> 00:06:29,680
the highest performing integration of

174
00:06:27,360 --> 00:06:32,960
afx dp into bdk

175
00:06:29,680 --> 00:06:35,680
we need to map the mbuff pool directly

176
00:06:32,960 --> 00:06:36,960
into the um to get a zero copy data path

177
00:06:35,680 --> 00:06:38,560
which is obviously going to be the best

178
00:06:36,960 --> 00:06:40,960
the most performant

179
00:06:38,560 --> 00:06:42,479
um but as you can see here that's not

180
00:06:40,960 --> 00:06:45,520
possible at the moment

181
00:06:42,479 --> 00:06:46,800
this is just one example of a tbk mfp

182
00:06:45,520 --> 00:06:48,080
there's plenty more examples of

183
00:06:46,800 --> 00:06:49,199
different sized m buffs different

184
00:06:48,080 --> 00:06:51,919
alignments

185
00:06:49,199 --> 00:06:53,280
and most of them won't comply with the

186
00:06:51,919 --> 00:06:57,039
kind of restrictions of the

187
00:06:53,280 --> 00:06:59,520
um but to get around this

188
00:06:57,039 --> 00:07:01,199
the clever folks in the dbdk community

189
00:06:59,520 --> 00:07:01,758
have come up with a number of solutions

190
00:07:01,199 --> 00:07:03,440
to

191
00:07:01,759 --> 00:07:04,880
to get them to integrate and work

192
00:07:03,440 --> 00:07:06,960
together

193
00:07:04,880 --> 00:07:10,800
each of them have a varying degree of

194
00:07:06,960 --> 00:07:10,799
success in terms of performance

195
00:07:11,280 --> 00:07:15,280
so the first solution that was

196
00:07:13,440 --> 00:07:18,240
considered was copy mode

197
00:07:15,280 --> 00:07:18,559
and in this mode we allocate memory for

198
00:07:18,240 --> 00:07:21,520
or

199
00:07:18,560 --> 00:07:22,720
um and we also allocate our tpdk and

200
00:07:21,520 --> 00:07:25,198
pool as normal

201
00:07:22,720 --> 00:07:27,680
and we simply mem copy between the two

202
00:07:25,199 --> 00:07:30,000
locations in memory

203
00:07:27,680 --> 00:07:31,599
this works really well but in terms of

204
00:07:30,000 --> 00:07:33,599
performance it's not

205
00:07:31,599 --> 00:07:35,440
the most performant just due to the

206
00:07:33,599 --> 00:07:36,719
cycle cost of the mem copy being pretty

207
00:07:35,440 --> 00:07:38,880
high

208
00:07:36,720 --> 00:07:40,800
but nevertheless it made it into a dbdk

209
00:07:38,880 --> 00:07:43,280
release 1905

210
00:07:40,800 --> 00:07:46,960
as part of the series that initially

211
00:07:43,280 --> 00:07:46,960
introduced af xtp support

212
00:07:47,919 --> 00:07:52,560
the second approach then that was looked

213
00:07:49,440 --> 00:07:55,759
into was this alignment api

214
00:07:52,560 --> 00:07:57,280
so it was proposed to introduce a new

215
00:07:55,759 --> 00:08:00,400
api into bdk

216
00:07:57,280 --> 00:08:02,318
which allowed you to kind of specify the

217
00:08:00,400 --> 00:08:04,960
type of alignment you wanted for your

218
00:08:02,319 --> 00:08:06,720
mbof pool and then any application you

219
00:08:04,960 --> 00:08:09,758
wanted to work with af xtp

220
00:08:06,720 --> 00:08:10,400
could use this new api and kind of mold

221
00:08:09,759 --> 00:08:14,319
its

222
00:08:10,400 --> 00:08:16,400
mbof pool to fit the um requirements

223
00:08:14,319 --> 00:08:17,919
um then you could do the one-to-one

224
00:08:16,400 --> 00:08:19,599
mapping and you could get your zero copy

225
00:08:17,919 --> 00:08:21,840
performance

226
00:08:19,599 --> 00:08:23,520
but even though this did give really

227
00:08:21,840 --> 00:08:26,560
really good performance

228
00:08:23,520 --> 00:08:28,799
it was deemed a bit too invasive um

229
00:08:26,560 --> 00:08:30,240
so it didn't make it into a dbk release

230
00:08:28,800 --> 00:08:31,599
it was invasive because you had to

231
00:08:30,240 --> 00:08:32,320
change your application to get it to

232
00:08:31,599 --> 00:08:33,838
work which

233
00:08:32,320 --> 00:08:36,000
kind of went against what kevin said at

234
00:08:33,839 --> 00:08:37,680
the start about apps needing to work out

235
00:08:36,000 --> 00:08:40,000
of the box

236
00:08:37,679 --> 00:08:41,120
so that didn't get into a dbk release

237
00:08:40,000 --> 00:08:43,120
but it

238
00:08:41,120 --> 00:08:44,800
generated a good discussion on the

239
00:08:43,120 --> 00:08:45,839
mailing list which led to this third

240
00:08:44,800 --> 00:08:48,560
approach

241
00:08:45,839 --> 00:08:51,440
um i think it was suggested by oliver

242
00:08:48,560 --> 00:08:54,800
matz and implemented by xiaolong yay

243
00:08:51,440 --> 00:08:56,080
and this approach uses dbdk's external

244
00:08:54,800 --> 00:08:59,040
mbuff feature

245
00:08:56,080 --> 00:08:59,519
which allows dpdkmf2 instead of holding

246
00:08:59,040 --> 00:09:02,000
the

247
00:08:59,519 --> 00:09:05,120
packet data in the structure itself to

248
00:09:02,000 --> 00:09:06,560
point to a different location in memory

249
00:09:05,120 --> 00:09:08,399
in this case we'll be pointing to our

250
00:09:06,560 --> 00:09:10,399
umem chunk

251
00:09:08,399 --> 00:09:12,240
and then you can achieve your your zero

252
00:09:10,399 --> 00:09:14,640
copy

253
00:09:12,240 --> 00:09:15,920
however there are still kind of

254
00:09:14,640 --> 00:09:18,560
additional cycles

255
00:09:15,920 --> 00:09:20,240
with this solution so there's additional

256
00:09:18,560 --> 00:09:23,119
complexity involved in

257
00:09:20,240 --> 00:09:25,120
attaching and detaching that external

258
00:09:23,120 --> 00:09:27,760
piece of memory from your mbof

259
00:09:25,120 --> 00:09:28,800
um but then again it does give a really

260
00:09:27,760 --> 00:09:31,279
really good

261
00:09:28,800 --> 00:09:32,959
improvement over copy mode i think 29

262
00:09:31,279 --> 00:09:35,839
for a certain use case

263
00:09:32,959 --> 00:09:36,399
so it made it into dpdk 1908 as kind of

264
00:09:35,839 --> 00:09:41,680
a

265
00:09:36,399 --> 00:09:41,680
first gen af xtp zero copy solution

266
00:09:42,399 --> 00:09:45,839
at this point we kind of felt that we'd

267
00:09:45,200 --> 00:09:48,480
well

268
00:09:45,839 --> 00:09:49,839
the community had taken to bdk as far as

269
00:09:48,480 --> 00:09:51,680
they could in terms of performance with

270
00:09:49,839 --> 00:09:53,120
af x-tp

271
00:09:51,680 --> 00:09:54,800
but we still felt that there was still

272
00:09:53,120 --> 00:09:56,399
some performance left on the table some

273
00:09:54,800 --> 00:09:58,240
cycles to save

274
00:09:56,399 --> 00:09:59,600
so at that point we decided it would be

275
00:09:58,240 --> 00:10:00,959
a good idea to

276
00:09:59,600 --> 00:10:03,680
start looking at the kernel side of

277
00:10:00,959 --> 00:10:05,599
things and maybe looking at

278
00:10:03,680 --> 00:10:06,800
adapting the um to make it a bit more

279
00:10:05,600 --> 00:10:09,519
flexible to work with

280
00:10:06,800 --> 00:10:10,640
the flexibility of dbdk as opposed to

281
00:10:09,519 --> 00:10:13,519
trying to

282
00:10:10,640 --> 00:10:15,680
make tpdk fit the narrow restrictions of

283
00:10:13,519 --> 00:10:15,680
the

284
00:10:16,839 --> 00:10:20,000
um

285
00:10:18,160 --> 00:10:22,800
so what do we do in the kernel when we

286
00:10:20,000 --> 00:10:26,000
finally took off our dpdk hats

287
00:10:22,800 --> 00:10:28,719
um we took a look at the original um

288
00:10:26,000 --> 00:10:29,279
and its constraints being trunk size

289
00:10:28,720 --> 00:10:32,640
aligned

290
00:10:29,279 --> 00:10:34,240
our page size line sorry um was one

291
00:10:32,640 --> 00:10:36,720
major restriction that we had to lift

292
00:10:34,240 --> 00:10:38,240
so we enabled arbitrary trunk alignment

293
00:10:36,720 --> 00:10:40,959
so you can now

294
00:10:38,240 --> 00:10:43,519
align your trunks anywhere you want

295
00:10:40,959 --> 00:10:46,319
within the um

296
00:10:43,519 --> 00:10:47,839
as a part of this we allowed arbitrary

297
00:10:46,320 --> 00:10:51,120
trunk sizing as well

298
00:10:47,839 --> 00:10:52,880
um so now you can size and align

299
00:10:51,120 --> 00:10:55,680
wherever you want within the um much

300
00:10:52,880 --> 00:10:58,240
more flexible than the original

301
00:10:55,680 --> 00:10:59,760
with this we also had to allow um the

302
00:10:58,240 --> 00:11:00,959
crossing of page boundaries so we now

303
00:10:59,760 --> 00:11:02,800
need to keep track of

304
00:11:00,959 --> 00:11:04,640
whether pages are physically contiguous

305
00:11:02,800 --> 00:11:07,199
in memory or not

306
00:11:04,640 --> 00:11:08,480
if they aren't contiguous like chunk

307
00:11:07,200 --> 00:11:11,120
three in this case let's assume

308
00:11:08,480 --> 00:11:11,519
page three is non-contiguous to page two

309
00:11:11,120 --> 00:11:14,800
then

310
00:11:11,519 --> 00:11:15,600
it will cross into a non contiguous

311
00:11:14,800 --> 00:11:17,920
memory region

312
00:11:15,600 --> 00:11:19,279
so we can't use that address we discard

313
00:11:17,920 --> 00:11:22,319
it get a new one

314
00:11:19,279 --> 00:11:24,560
and we use the start of the next page um

315
00:11:22,320 --> 00:11:25,440
so we do have a gap in memory and this

316
00:11:24,560 --> 00:11:28,640
is just one the

317
00:11:25,440 --> 00:11:30,800
the side effects to this kind of added

318
00:11:28,640 --> 00:11:33,680
flexibility

319
00:11:30,800 --> 00:11:34,240
but a lot of the time you're going to be

320
00:11:33,680 --> 00:11:38,319
a lot more

321
00:11:34,240 --> 00:11:40,560
better off with this um

322
00:11:38,320 --> 00:11:42,720
with this we also need to change the af

323
00:11:40,560 --> 00:11:44,079
xdp rx and tx descriptor

324
00:11:42,720 --> 00:11:46,160
and one of the fields within this

325
00:11:44,079 --> 00:11:48,239
descriptor is the address field

326
00:11:46,160 --> 00:11:50,719
and this is simply an offset into the um

327
00:11:48,240 --> 00:11:53,680
of where your trunk is placed

328
00:11:50,720 --> 00:11:54,160
as the packet travels through the data

329
00:11:53,680 --> 00:11:57,040
path

330
00:11:54,160 --> 00:11:57,439
and various offsets are added on to this

331
00:11:57,040 --> 00:12:01,680
uh

332
00:11:57,440 --> 00:12:03,760
in the original design of this

333
00:12:01,680 --> 00:12:05,439
the offsets were added directly to the

334
00:12:03,760 --> 00:12:07,600
address field

335
00:12:05,440 --> 00:12:08,480
so the value would change as you it made

336
00:12:07,600 --> 00:12:10,560
its way through the

337
00:12:08,480 --> 00:12:11,760
data path at the end of it when we

338
00:12:10,560 --> 00:12:14,638
recycle the buffer

339
00:12:11,760 --> 00:12:16,240
we could simply mask back to 2k 4k

340
00:12:14,639 --> 00:12:18,639
whatever your alignment was

341
00:12:16,240 --> 00:12:20,079
and because it was a power of two this

342
00:12:18,639 --> 00:12:22,240
isn't possible anymore without doing

343
00:12:20,079 --> 00:12:24,719
complex calculations seeing as we have

344
00:12:22,240 --> 00:12:28,079
arbitrary sizing and alignment

345
00:12:24,720 --> 00:12:30,959
so we moved to a model where we took the

346
00:12:28,079 --> 00:12:32,560
upper 16 bits of the address field and

347
00:12:30,959 --> 00:12:34,239
stored the offset there rather than

348
00:12:32,560 --> 00:12:36,880
adding it to the address field

349
00:12:34,240 --> 00:12:38,079
and we kept the lower 48 bits purely for

350
00:12:36,880 --> 00:12:42,160
the original base

351
00:12:38,079 --> 00:12:45,839
address or the original offset as it was

352
00:12:42,160 --> 00:12:47,760
um this still gives us 256 terabytes

353
00:12:45,839 --> 00:12:50,399
of address space so we've more than

354
00:12:47,760 --> 00:12:50,399
enough for now

355
00:12:51,040 --> 00:12:54,240
and what this enables us to do is

356
00:12:52,880 --> 00:12:56,079
basically just when we're doing the

357
00:12:54,240 --> 00:12:57,839
buffer recycling just mask off the upper

358
00:12:56,079 --> 00:13:00,959
16 bits we have our original address

359
00:12:57,839 --> 00:13:04,240
and we're back to where we were

360
00:13:00,959 --> 00:13:06,479
um all of this added flexibility um

361
00:13:04,240 --> 00:13:08,079
makes the um a lot more flexible so we

362
00:13:06,480 --> 00:13:11,200
can map directly into it

363
00:13:08,079 --> 00:13:13,760
um and it really gives us a lot

364
00:13:11,200 --> 00:13:18,160
more a much more seamless integration

365
00:13:13,760 --> 00:13:18,160
with existing frameworks such as dpdk

366
00:13:18,480 --> 00:13:25,279
okay um so as kevin said now that we've

367
00:13:21,920 --> 00:13:28,079
relaxed our um alignment constraints

368
00:13:25,279 --> 00:13:29,519
we can now map or to bdk and off pools

369
00:13:28,079 --> 00:13:32,319
no matter what size they are

370
00:13:29,519 --> 00:13:34,079
directly into the um so using our

371
00:13:32,320 --> 00:13:35,200
example from earlier with our three and

372
00:13:34,079 --> 00:13:38,319
a half km buff

373
00:13:35,200 --> 00:13:38,639
we can size or um chunk to to match that

374
00:13:38,320 --> 00:13:41,040
or

375
00:13:38,639 --> 00:13:42,560
whatever the end of size is and we can

376
00:13:41,040 --> 00:13:45,519
get our seamless

377
00:13:42,560 --> 00:13:46,319
zero copy and we don't need to modify

378
00:13:45,519 --> 00:13:48,000
our

379
00:13:46,320 --> 00:13:49,440
existing dbk applications they're going

380
00:13:48,000 --> 00:13:51,839
to work out of the box

381
00:13:49,440 --> 00:13:53,199
so those were our kind of two key goals

382
00:13:51,839 --> 00:13:53,519
that we outlined at the start of this

383
00:13:53,199 --> 00:13:55,279
and

384
00:13:53,519 --> 00:13:57,199
they were key goals at the start of this

385
00:13:55,279 --> 00:14:00,079
work so we've achieved those

386
00:13:57,199 --> 00:14:03,359
and in achieving those we've got both a

387
00:14:00,079 --> 00:14:06,638
performant and portable solution

388
00:14:03,360 --> 00:14:07,760
in terms of performance this solution it

389
00:14:06,639 --> 00:14:09,920
gives a 60

390
00:14:07,760 --> 00:14:11,360
improvement on the copy mode the first

391
00:14:09,920 --> 00:14:14,240
one that i showed earlier

392
00:14:11,360 --> 00:14:15,279
and a further 24 upon the first

393
00:14:14,240 --> 00:14:17,600
generation

394
00:14:15,279 --> 00:14:18,560
zero copy which was in 1908 which used

395
00:14:17,600 --> 00:14:21,120
the

396
00:14:18,560 --> 00:14:22,239
external m-buff feature so it's a pretty

397
00:14:21,120 --> 00:14:25,360
significant

398
00:14:22,240 --> 00:14:27,760
performance improvement and the feature

399
00:14:25,360 --> 00:14:30,240
itself it's available in dbdk 1911 which

400
00:14:27,760 --> 00:14:32,560
is the most recent tpdk release

401
00:14:30,240 --> 00:14:33,920
so provided you have kernel 5.4 this

402
00:14:32,560 --> 00:14:36,079
feature will be available

403
00:14:33,920 --> 00:14:38,079
if you don't dpdk will simply fall back

404
00:14:36,079 --> 00:14:41,120
to copy mode

405
00:14:38,079 --> 00:14:44,719
um i think we're out of time so

406
00:14:41,120 --> 00:14:48,480
yeah okay yeah so just a a quick note

407
00:14:44,720 --> 00:14:50,720
um before we end a lot of people kind of

408
00:14:48,480 --> 00:14:52,880
ask what is the value of integrating af

409
00:14:50,720 --> 00:14:56,079
xtp into dpdk

410
00:14:52,880 --> 00:14:57,680
so dbdk as many of you know

411
00:14:56,079 --> 00:15:00,160
it provides an application developer

412
00:14:57,680 --> 00:15:03,040
with a wide variety of functionality for

413
00:15:00,160 --> 00:15:04,000
an application so things like memory and

414
00:15:03,040 --> 00:15:06,959
power management

415
00:15:04,000 --> 00:15:08,720
crypto virtual networking qos the list

416
00:15:06,959 --> 00:15:11,760
goes on

417
00:15:08,720 --> 00:15:14,560
af xtp then provides

418
00:15:11,760 --> 00:15:15,760
unrivaled flexibility and magnus touched

419
00:15:14,560 --> 00:15:18,479
on this in his

420
00:15:15,760 --> 00:15:19,120
uh presentation first thing this morning

421
00:15:18,480 --> 00:15:21,120
um

422
00:15:19,120 --> 00:15:22,720
so in contrast with the typical wdk

423
00:15:21,120 --> 00:15:24,720
usage model or

424
00:15:22,720 --> 00:15:26,160
nick remains bound to the kernel driver

425
00:15:24,720 --> 00:15:28,880
so we can avail of the

426
00:15:26,160 --> 00:15:31,920
kernel control paths and have use of our

427
00:15:28,880 --> 00:15:35,040
familiar tools like ifconfig eth2 etc

428
00:15:31,920 --> 00:15:36,959
so that has a huge impact on the

429
00:15:35,040 --> 00:15:38,560
usability of an application and a

430
00:15:36,959 --> 00:15:40,880
solution as a whole

431
00:15:38,560 --> 00:15:42,319
so together essentially the best of both

432
00:15:40,880 --> 00:15:44,800
worlds can be enjoyed

433
00:15:42,320 --> 00:15:45,680
and we can get applications that are

434
00:15:44,800 --> 00:15:48,479
high performing

435
00:15:45,680 --> 00:15:50,399
portable fully featured accelerated

436
00:15:48,480 --> 00:15:53,040
insert buzzword here

437
00:15:50,399 --> 00:15:54,800
um yeah so i think they're just a good

438
00:15:53,040 --> 00:15:57,599
combination together

439
00:15:54,800 --> 00:15:59,279
um and then just to close a couple words

440
00:15:57,600 --> 00:16:00,800
of thanks to some people that helped

441
00:15:59,279 --> 00:16:03,360
myself and kevin along the way with this

442
00:16:00,800 --> 00:16:06,639
work um magnus and bjorn

443
00:16:03,360 --> 00:16:07,519
on the kernel side um bruce chi and xiao

444
00:16:06,639 --> 00:16:10,240
long on the

445
00:16:07,519 --> 00:16:11,120
dbdk side and the dbk and kernel

446
00:16:10,240 --> 00:16:14,639
communities

447
00:16:11,120 --> 00:16:17,519
as a whole yeah that's it for myself and

448
00:16:14,639 --> 00:16:17,519
kevin um

449
00:16:18,460 --> 00:16:23,179
[Applause]

450
00:16:29,199 --> 00:16:34,000
so it really depends on the workload

451
00:16:35,279 --> 00:16:39,199
um off the top of my head i don't have a

452
00:16:37,279 --> 00:16:40,560
number i it really does depend on the

453
00:16:39,199 --> 00:16:41,839
workload like if it's a heavy workload

454
00:16:40,560 --> 00:16:44,160
they could be pretty close

455
00:16:41,839 --> 00:16:45,040
if it's something like test pmd some or

456
00:16:44,160 --> 00:16:48,160
l2 forward

457
00:16:45,040 --> 00:16:49,279
there's going to be a bigger data um i'm

458
00:16:48,160 --> 00:16:50,880
trying to think

459
00:16:49,279 --> 00:16:52,320
they're i think we might have some data

460
00:16:50,880 --> 00:16:54,160
published soon which

461
00:16:52,320 --> 00:16:55,360
we might have some data published soon

462
00:16:54,160 --> 00:16:56,319
we're running some benchmarks at the

463
00:16:55,360 --> 00:17:00,079
moment so

464
00:16:56,320 --> 00:17:00,079
that should be public uh soon enough

465
00:17:02,839 --> 00:17:05,839
yeah

466
00:17:06,959 --> 00:17:09,039
you

