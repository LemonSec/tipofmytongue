1
00:00:05,440 --> 00:00:08,240
we're going to be talking about

2
00:00:06,399 --> 00:00:11,599
distributed hpc applications

3
00:00:08,240 --> 00:00:14,480
with unprivileged containers

4
00:00:11,599 --> 00:00:16,800
thank you stefan so i'm felix this is

5
00:00:14,480 --> 00:00:18,800
jonathan we work at nvidia

6
00:00:16,800 --> 00:00:21,199
and in california and we're going to

7
00:00:18,800 --> 00:00:22,320
talk about our infrastructure or we use

8
00:00:21,199 --> 00:00:25,519
containers

9
00:00:22,320 --> 00:00:27,198
for multiple different applications so

10
00:00:25,519 --> 00:00:28,639
let me get something out of the way i

11
00:00:27,199 --> 00:00:31,199
know we just got steamed

12
00:00:28,640 --> 00:00:32,800
but and we are from nvidia but we don't

13
00:00:31,199 --> 00:00:35,280
do video games

14
00:00:32,800 --> 00:00:37,040
and some people sometime when i go to a

15
00:00:35,280 --> 00:00:38,399
conference about linux and containers

16
00:00:37,040 --> 00:00:40,719
they say why are you here

17
00:00:38,399 --> 00:00:42,879
you're nvidia you're you do windows and

18
00:00:40,719 --> 00:00:45,440
games but but that's not only what we do

19
00:00:42,879 --> 00:00:47,920
actually so our latest gpus do

20
00:00:45,440 --> 00:00:49,920
ray tracing with rtx so that's useful

21
00:00:47,920 --> 00:00:51,440
for games but also for visualization

22
00:00:49,920 --> 00:00:55,280
professional visualization

23
00:00:51,440 --> 00:00:57,599
for movies and in the middle we have

24
00:00:55,280 --> 00:00:59,280
we have the type of gpus that's only

25
00:00:57,600 --> 00:01:01,359
used for crunching numbers so like

26
00:00:59,280 --> 00:01:02,559
astrophysics biology simulation

27
00:01:01,359 --> 00:01:05,519
mathematics

28
00:01:02,559 --> 00:01:06,720
machine learning um so we have gpu that

29
00:01:05,519 --> 00:01:08,560
don't have a display they don't have a

30
00:01:06,720 --> 00:01:10,560
display you put them in data center and

31
00:01:08,560 --> 00:01:12,080
they just crunch numbers like deep

32
00:01:10,560 --> 00:01:13,920
learning or or

33
00:01:12,080 --> 00:01:15,600
saying what we call hpc like performance

34
00:01:13,920 --> 00:01:18,320
computing and on the other end of the

35
00:01:15,600 --> 00:01:20,960
spectrum we even have autonomous

36
00:01:18,320 --> 00:01:22,479
machines like robots self-driving cars

37
00:01:20,960 --> 00:01:23,600
so it's like more like smaller system

38
00:01:22,479 --> 00:01:25,520
embedded systems

39
00:01:23,600 --> 00:01:26,960
that people can use for computer visions

40
00:01:25,520 --> 00:01:29,679
and and kind of

41
00:01:26,960 --> 00:01:31,199
real-time real-time tasks uh that are

42
00:01:29,680 --> 00:01:33,119
involved so we call it gpu computing and

43
00:01:31,200 --> 00:01:35,040
you might have out of cuda

44
00:01:33,119 --> 00:01:36,880
that's our platform for doing that

45
00:01:35,040 --> 00:01:40,400
beyond video games

46
00:01:36,880 --> 00:01:42,798
okay um so we

47
00:01:40,400 --> 00:01:44,240
at nvidia we have an infrastructure of

48
00:01:42,799 --> 00:01:47,040
we have multiple clusters

49
00:01:44,240 --> 00:01:48,640
multiple data centers uh in santa clara

50
00:01:47,040 --> 00:01:51,360
and we have one that's

51
00:01:48,640 --> 00:01:52,320
per there's some benchmark the top 500

52
00:01:51,360 --> 00:01:54,159
that's a

53
00:01:52,320 --> 00:01:55,600
measure of supercomputers we are number

54
00:01:54,159 --> 00:01:58,320
20 in the world

55
00:01:55,600 --> 00:01:59,199
and those are very very large machines

56
00:01:58,320 --> 00:02:03,679
right here

57
00:01:59,200 --> 00:02:06,799
we have 16 gpu each more than 400 watts

58
00:02:03,680 --> 00:02:07,600
so with a total of 12 kilowatts per

59
00:02:06,799 --> 00:02:10,560
machine

60
00:02:07,600 --> 00:02:11,359
and we have 96 of those 1.5 terabyte of

61
00:02:10,560 --> 00:02:13,040
ram

62
00:02:11,360 --> 00:02:14,959
so that those are machined that are

63
00:02:13,040 --> 00:02:17,840
gigantic infiniband for the networking

64
00:02:14,959 --> 00:02:21,599
because we need very fast networking

65
00:02:17,840 --> 00:02:24,319
and pretty uncommon we win ubuntu

66
00:02:21,599 --> 00:02:25,119
a little bit uncommon in hpc but but but

67
00:02:24,319 --> 00:02:26,720
um

68
00:02:25,120 --> 00:02:28,720
that happens so the next talk is about i

69
00:02:26,720 --> 00:02:30,319
know the next talk is about raspberry pi

70
00:02:28,720 --> 00:02:32,160
and that's that would be a lot of

71
00:02:30,319 --> 00:02:35,599
raspberry pies to

72
00:02:32,160 --> 00:02:38,319
reach one note here 12 kilowatt

73
00:02:35,599 --> 00:02:39,920
four years ago we uh jonathan and myself

74
00:02:38,319 --> 00:02:42,319
we started a project

75
00:02:39,920 --> 00:02:44,000
called nvidia docker and then evolved

76
00:02:42,319 --> 00:02:46,879
into live nvidia container

77
00:02:44,000 --> 00:02:48,239
and the goal was to make it easy to

78
00:02:46,879 --> 00:02:49,280
deploy your code applications in

79
00:02:48,239 --> 00:02:52,239
containers

80
00:02:49,280 --> 00:02:54,239
and so it worked pretty well it's and it

81
00:02:52,239 --> 00:02:55,760
supports all run time so that's good

82
00:02:54,239 --> 00:02:57,680
because it doesn't force us to use a

83
00:02:55,760 --> 00:03:01,519
specific runtime we can use

84
00:02:57,680 --> 00:03:04,319
lxc we can use run c docker continuity

85
00:03:01,519 --> 00:03:05,040
kubernetes you can run your code apps in

86
00:03:04,319 --> 00:03:07,119
there

87
00:03:05,040 --> 00:03:09,760
and especially we use containers at

88
00:03:07,120 --> 00:03:11,599
nvidia for deep learning and hpc

89
00:03:09,760 --> 00:03:14,239
because we know some of these apps are

90
00:03:11,599 --> 00:03:16,319
difficult to package to install

91
00:03:14,239 --> 00:03:18,720
and and they sometimes conflict between

92
00:03:16,319 --> 00:03:21,280
each other so we put that in a container

93
00:03:18,720 --> 00:03:23,280
and we put that on docker hub or or some

94
00:03:21,280 --> 00:03:25,599
of them in our own container registry

95
00:03:23,280 --> 00:03:27,440
people can download those and have a

96
00:03:25,599 --> 00:03:30,079
stack already installed for tensorflow

97
00:03:27,440 --> 00:03:30,079
by torch

98
00:03:30,319 --> 00:03:34,480
biology and stuff like that and so we

99
00:03:33,040 --> 00:03:35,679
use continuous for a lot of things even

100
00:03:34,480 --> 00:03:37,440
benchmarking

101
00:03:35,680 --> 00:03:38,720
and especially for machine learning deep

102
00:03:37,440 --> 00:03:42,319
learning

103
00:03:38,720 --> 00:03:43,440
so uh i've mentioned our hardware so

104
00:03:42,319 --> 00:03:45,518
but let's take a look at what the

105
00:03:43,440 --> 00:03:48,799
typical cloud deployment looks like

106
00:03:45,519 --> 00:03:50,319
so so you don't have nodes usually like

107
00:03:48,799 --> 00:03:52,319
we have 12 kilowatts

108
00:03:50,319 --> 00:03:54,720
you have maybe smaller nodes instances

109
00:03:52,319 --> 00:03:57,839
like wise hundreds of thousands of them

110
00:03:54,720 --> 00:03:59,840
and you contain rise for security we uh

111
00:03:57,840 --> 00:04:02,000
not for some time for packaging but also

112
00:03:59,840 --> 00:04:02,640
for security and you have micro services

113
00:04:02,000 --> 00:04:05,680
so maybe

114
00:04:02,640 --> 00:04:07,760
100 containers per node you have traffic

115
00:04:05,680 --> 00:04:09,439
from the outside world you have user

116
00:04:07,760 --> 00:04:11,840
uploads and stuff like that

117
00:04:09,439 --> 00:04:13,040
uh internal traffic and you don't use

118
00:04:11,840 --> 00:04:15,120
that users don't

119
00:04:13,040 --> 00:04:16,478
don't access the cluster directly they

120
00:04:15,120 --> 00:04:18,720
they basically

121
00:04:16,478 --> 00:04:20,159
ask someone if they can deploy the new

122
00:04:18,720 --> 00:04:22,800
app on the cluster

123
00:04:20,160 --> 00:04:24,479
and you have advanced features that i've

124
00:04:22,800 --> 00:04:28,080
listed here but

125
00:04:24,479 --> 00:04:31,120
um so that was kind of the kubernetes

126
00:04:28,080 --> 00:04:33,599
what kubernetes has to offer so going to

127
00:04:31,120 --> 00:04:35,120
what we do at nvidia as you've seen very

128
00:04:33,600 --> 00:04:35,840
large nodes and we can have trusted

129
00:04:35,120 --> 00:04:37,199
users

130
00:04:35,840 --> 00:04:38,799
because our clusters are sometimes

131
00:04:37,199 --> 00:04:39,680
air-gapped or very little access to the

132
00:04:38,800 --> 00:04:41,919
outside

133
00:04:39,680 --> 00:04:43,440
so if someone asks the cluster if

134
00:04:41,919 --> 00:04:44,960
someone uses zero day

135
00:04:43,440 --> 00:04:46,320
on our cluster i mean we're just going

136
00:04:44,960 --> 00:04:46,960
to fire him and that's that's pretty

137
00:04:46,320 --> 00:04:49,120
much it

138
00:04:46,960 --> 00:04:51,120
we say they ran trusted we were

139
00:04:49,120 --> 00:04:53,759
interested trusted code

140
00:04:51,120 --> 00:04:54,400
on our on our on our clusters so and

141
00:04:53,759 --> 00:04:56,400
also not

142
00:04:54,400 --> 00:04:57,758
all applications are containerized if an

143
00:04:56,400 --> 00:04:59,520
application has not containerized

144
00:04:57,759 --> 00:05:00,800
because it's packaged well well

145
00:04:59,520 --> 00:05:03,520
don't use a container we don't want

146
00:05:00,800 --> 00:05:06,400
people to force users to use a container

147
00:05:03,520 --> 00:05:07,520
because they did that job correctly so

148
00:05:06,400 --> 00:05:10,080
um

149
00:05:07,520 --> 00:05:12,240
this actual step is actually eliminate

150
00:05:10,080 --> 00:05:14,240
kubernetes already because kubernetes is

151
00:05:12,240 --> 00:05:15,600
is fully containerized everything and we

152
00:05:14,240 --> 00:05:17,280
have fewer applications per node we

153
00:05:15,600 --> 00:05:19,199
don't we are not very dense

154
00:05:17,280 --> 00:05:22,840
and we have multiple jobs also which

155
00:05:19,199 --> 00:05:26,320
means that you are you need to start 30

156
00:05:22,840 --> 00:05:27,039
um you need to start the job on 30 nodes

157
00:05:26,320 --> 00:05:29,599
in parallel

158
00:05:27,039 --> 00:05:30,639
so it takes a bit of time and as i say

159
00:05:29,600 --> 00:05:34,160
mostly

160
00:05:30,639 --> 00:05:36,720
little traffic to the outside world so

161
00:05:34,160 --> 00:05:37,680
uh so we are not choosing kubernetes

162
00:05:36,720 --> 00:05:40,320
like unlike

163
00:05:37,680 --> 00:05:41,440
maybe many people before us we have

164
00:05:40,320 --> 00:05:44,240
chosen something that's

165
00:05:41,440 --> 00:05:45,520
pretty classic in hpc called slurm so

166
00:05:44,240 --> 00:05:47,919
it's more

167
00:05:45,520 --> 00:05:49,680
it was way more adapted to our use case

168
00:05:47,919 --> 00:05:50,400
so it has advanced scheduling algorithms

169
00:05:49,680 --> 00:05:53,600
so for

170
00:05:50,400 --> 00:05:55,840
coders teams and stuff like that and

171
00:05:53,600 --> 00:05:56,960
especially it supports gang scheduling

172
00:05:55,840 --> 00:05:59,758
which means that if you

173
00:05:56,960 --> 00:06:00,960
need to run on 30 nodes there is no need

174
00:05:59,759 --> 00:06:02,880
to start running

175
00:06:00,960 --> 00:06:04,400
unless everyone is ready because if you

176
00:06:02,880 --> 00:06:07,120
start running on 50 nodes

177
00:06:04,400 --> 00:06:09,280
you're just going to spend cpu cycles

178
00:06:07,120 --> 00:06:11,120
waiting for the other 15 nodes to join

179
00:06:09,280 --> 00:06:12,799
so you really have to make sure that

180
00:06:11,120 --> 00:06:14,400
they are all ready at the same time

181
00:06:12,800 --> 00:06:16,160
and start at pretty much the same time

182
00:06:14,400 --> 00:06:17,758
otherwise it's just waste

183
00:06:16,160 --> 00:06:19,280
loading time overhead the control plane

184
00:06:17,759 --> 00:06:21,440
is pretty small

185
00:06:19,280 --> 00:06:22,479
topology aware so that if you have newer

186
00:06:21,440 --> 00:06:23,919
machines you are

187
00:06:22,479 --> 00:06:25,520
you optimize for performance in the

188
00:06:23,919 --> 00:06:27,440
allocation and

189
00:06:25,520 --> 00:06:30,240
it's user-centric is that you submit the

190
00:06:27,440 --> 00:06:32,400
bash script it will run your bash script

191
00:06:30,240 --> 00:06:34,160
you can ssh into a login node and then

192
00:06:32,400 --> 00:06:36,479
have an interactive session on

193
00:06:34,160 --> 00:06:37,520
on a big machine like we showed and it's

194
00:06:36,479 --> 00:06:40,000
about gpus

195
00:06:37,520 --> 00:06:41,520
and while the only drawback was it did

196
00:06:40,000 --> 00:06:43,600
not support containers

197
00:06:41,520 --> 00:06:45,120
and we use containers for especially for

198
00:06:43,600 --> 00:06:48,160
deep learning machine learning

199
00:06:45,120 --> 00:06:51,360
so but it talks about plugins

200
00:06:48,160 --> 00:06:52,160
so what we did is uh we looked at our

201
00:06:51,360 --> 00:06:54,160
requirements

202
00:06:52,160 --> 00:06:55,360
and we need performance we need no

203
00:06:54,160 --> 00:06:57,759
overhead

204
00:06:55,360 --> 00:06:59,280
in uh the container runtime we need to

205
00:06:57,759 --> 00:07:01,039
support docker images because our

206
00:06:59,280 --> 00:07:03,599
researchers still install darker

207
00:07:01,039 --> 00:07:05,520
on their machines because that's that's

208
00:07:03,599 --> 00:07:06,159
convenience that's very nice ui local

209
00:07:05,520 --> 00:07:09,440
build

210
00:07:06,160 --> 00:07:11,840
everything is is nice we

211
00:07:09,440 --> 00:07:13,520
need soft custom multi-tenancy so that

212
00:07:11,840 --> 00:07:15,198
means that you can have multiple users

213
00:07:13,520 --> 00:07:16,639
on the same machine but you just want to

214
00:07:15,199 --> 00:07:17,680
make sure they don't steal resources

215
00:07:16,639 --> 00:07:19,440
from someone else

216
00:07:17,680 --> 00:07:21,360
we are not trying to really strongly

217
00:07:19,440 --> 00:07:23,440
isolate uh between

218
00:07:21,360 --> 00:07:25,759
uh so it's not a security boundary just

219
00:07:23,440 --> 00:07:27,039
you you have two cpus you have four cpus

220
00:07:25,759 --> 00:07:30,240
and you cannot take more

221
00:07:27,039 --> 00:07:33,759
and when the gpu supports melanox for

222
00:07:30,240 --> 00:07:36,240
rdma for networking and material jobs

223
00:07:33,759 --> 00:07:38,000
so the runtime should not get in the way

224
00:07:36,240 --> 00:07:38,639
of all of that and also interactive

225
00:07:38,000 --> 00:07:41,199
containers

226
00:07:38,639 --> 00:07:41,680
you can install package uh b trace s

227
00:07:41,199 --> 00:07:45,680
trace

228
00:07:41,680 --> 00:07:47,520
gdb your process everything like that so

229
00:07:45,680 --> 00:07:49,360
there was no consider run time that

230
00:07:47,520 --> 00:07:50,318
really filled this need so it was

231
00:07:49,360 --> 00:07:52,960
actually simpler

232
00:07:50,319 --> 00:07:54,479
but simpler still to use slum but use a

233
00:07:52,960 --> 00:07:55,359
plugin system to create a new one and

234
00:07:54,479 --> 00:07:57,280
integrate it

235
00:07:55,360 --> 00:07:58,560
then modifying kubernetes for need so

236
00:07:57,280 --> 00:08:01,599
that's what we did

237
00:07:58,560 --> 00:08:03,520
uh before i end over to jonathan just

238
00:08:01,599 --> 00:08:05,039
want to mention that

239
00:08:03,520 --> 00:08:08,080
get something out of the way first is

240
00:08:05,039 --> 00:08:09,280
that to writing a secure privileged

241
00:08:08,080 --> 00:08:10,639
container on time

242
00:08:09,280 --> 00:08:12,400
is very very hard so there's this

243
00:08:10,639 --> 00:08:15,599
presentation by alexa

244
00:08:12,400 --> 00:08:19,120
from from if um one month ago or so so

245
00:08:15,599 --> 00:08:20,240
um we you really want to have something

246
00:08:19,120 --> 00:08:21,440
that

247
00:08:20,240 --> 00:08:23,759
you really have to use what we call

248
00:08:21,440 --> 00:08:25,919
username spaces and uh that's

249
00:08:23,759 --> 00:08:27,280
basically the point of his of his talk

250
00:08:25,919 --> 00:08:30,639
so

251
00:08:27,280 --> 00:08:31,919
you avoid a lot of issues and so if you

252
00:08:30,639 --> 00:08:33,680
get that out of the way

253
00:08:31,919 --> 00:08:35,679
writing in a container on time is not

254
00:08:33,679 --> 00:08:37,039
actually that difficult

255
00:08:35,679 --> 00:08:38,799
uh we're not going to explain at the

256
00:08:37,039 --> 00:08:40,479
radio continuum time because there's a

257
00:08:38,799 --> 00:08:41,679
lot of talks about this already

258
00:08:40,479 --> 00:08:43,839
but we're going to explain what the

259
00:08:41,679 --> 00:08:46,319
reasons why we did what we did

260
00:08:43,839 --> 00:08:47,360
and and the last point being here that

261
00:08:46,320 --> 00:08:48,959
even if you don't

262
00:08:47,360 --> 00:08:50,959
if you trust your users pretty much like

263
00:08:48,959 --> 00:08:51,279
you do there's still a lot of accidents

264
00:08:50,959 --> 00:08:53,439
or

265
00:08:51,279 --> 00:08:55,519
damage that can happen if you still give

266
00:08:53,440 --> 00:08:56,399
roots in real root inside containers for

267
00:08:55,519 --> 00:08:59,040
users

268
00:08:56,399 --> 00:09:00,160
like file access to files or breaking

269
00:08:59,040 --> 00:09:02,160
the system

270
00:09:00,160 --> 00:09:03,839
or or being able to debug from outside

271
00:09:02,160 --> 00:09:06,240
the container to debug your container

272
00:09:03,839 --> 00:09:08,720
because if it's running as uid0 you

273
00:09:06,240 --> 00:09:11,040
might not be able to debug it

274
00:09:08,720 --> 00:09:11,920
so our runtime is called android and i

275
00:09:11,040 --> 00:09:15,680
will end off to

276
00:09:11,920 --> 00:09:17,199
jonathan to explain each topic here on

277
00:09:15,680 --> 00:09:18,880
this list

278
00:09:17,200 --> 00:09:20,480
right so we're going to go through some

279
00:09:18,880 --> 00:09:23,839
of the design principles

280
00:09:20,480 --> 00:09:25,760
that are listed here uh and

281
00:09:23,839 --> 00:09:28,160
to be fair it's uh heavily influenced

282
00:09:25,760 --> 00:09:31,439
for lxc uh

283
00:09:28,160 --> 00:09:33,120
so the first thing we did was like we

284
00:09:31,440 --> 00:09:34,800
actually used username spaces

285
00:09:33,120 --> 00:09:37,760
the reason for that is we wanted a fully

286
00:09:34,800 --> 00:09:39,279
unprivileged container

287
00:09:37,760 --> 00:09:41,120
the difference with other runtimes

288
00:09:39,279 --> 00:09:44,000
though is we only have one user

289
00:09:41,120 --> 00:09:44,800
namespace mapping which basically maps

290
00:09:44,000 --> 00:09:46,959
the user

291
00:09:44,800 --> 00:09:47,920
uh that's outside of the container it's

292
00:09:46,959 --> 00:09:50,560
the same user

293
00:09:47,920 --> 00:09:52,399
inside so they have the same uid and

294
00:09:50,560 --> 00:09:54,560
optionally we let them also remap

295
00:09:52,399 --> 00:09:57,680
themselves as roots inside the container

296
00:09:54,560 --> 00:09:59,359
and uh why we have both of like

297
00:09:57,680 --> 00:10:01,599
both choices is because like some

298
00:09:59,360 --> 00:10:04,480
applications refuse to run as root

299
00:10:01,600 --> 00:10:06,240
and some need actually root access or

300
00:10:04,480 --> 00:10:08,640
fake root access

301
00:10:06,240 --> 00:10:09,920
we also like keep the same username

302
00:10:08,640 --> 00:10:12,880
inside the container for

303
00:10:09,920 --> 00:10:13,439
just convenience as not to confuse

304
00:10:12,880 --> 00:10:16,399
people

305
00:10:13,440 --> 00:10:17,120
and um and we can automatically mount

306
00:10:16,399 --> 00:10:20,399
home and

307
00:10:17,120 --> 00:10:22,560
other things inside the container um

308
00:10:20,399 --> 00:10:24,640
also like note that like run c or like

309
00:10:22,560 --> 00:10:26,479
docker based containers they they always

310
00:10:24,640 --> 00:10:28,959
remap route inside the container and we

311
00:10:26,480 --> 00:10:28,959
we don't

312
00:10:29,839 --> 00:10:34,000
so we talked about other run times and

313
00:10:32,480 --> 00:10:36,800
like traditional run times they

314
00:10:34,000 --> 00:10:37,120
usually use sub-gradient subject maps

315
00:10:36,800 --> 00:10:40,240
for

316
00:10:37,120 --> 00:10:41,680
username spaces and they

317
00:10:40,240 --> 00:10:44,880
they do that because they want to

318
00:10:41,680 --> 00:10:47,680
allocate a huge chunk of uids and gids

319
00:10:44,880 --> 00:10:49,439
and we don't really do that because we

320
00:10:47,680 --> 00:10:49,920
run application containers we don't need

321
00:10:49,440 --> 00:10:53,040
like this

322
00:10:49,920 --> 00:10:53,519
ready separation but we you kind of have

323
00:10:53,040 --> 00:10:55,519
to

324
00:10:53,519 --> 00:10:58,000
um when you start installing packages

325
00:10:55,519 --> 00:10:58,640
because you usually need to be root and

326
00:10:58,000 --> 00:11:00,320
you have

327
00:10:58,640 --> 00:11:02,720
you need to have additional uids and

328
00:11:00,320 --> 00:11:04,959
jd's because the packages will try to

329
00:11:02,720 --> 00:11:08,640
install new users on your groups

330
00:11:04,959 --> 00:11:10,880
um plus like there is also a problem

331
00:11:08,640 --> 00:11:12,640
with sub-ui and sub-gi e-maps is that

332
00:11:10,880 --> 00:11:14,560
you have it's difficult to maintain

333
00:11:12,640 --> 00:11:17,120
across a cluster they have some

334
00:11:14,560 --> 00:11:18,800
uh efforts in shadow utils and stuff to

335
00:11:17,120 --> 00:11:21,519
solve this problem but

336
00:11:18,800 --> 00:11:23,599
uh right now it's kind of difficult and

337
00:11:21,519 --> 00:11:25,200
uh you you can also run into permission

338
00:11:23,600 --> 00:11:27,600
issue once you

339
00:11:25,200 --> 00:11:28,399
like exit the container then you have

340
00:11:27,600 --> 00:11:30,800
like

341
00:11:28,399 --> 00:11:31,839
you have to deal with like permissions

342
00:11:30,800 --> 00:11:34,560
that were inside

343
00:11:31,839 --> 00:11:36,480
there are different outside so to solve

344
00:11:34,560 --> 00:11:38,800
that we basically use a satcom filter

345
00:11:36,480 --> 00:11:40,800
and we trap all the set uid ciscos

346
00:11:38,800 --> 00:11:42,399
to make them succeed even though they

347
00:11:40,800 --> 00:11:44,800
don't have a mapping inside the

348
00:11:42,399 --> 00:11:44,800
container

349
00:11:46,160 --> 00:11:49,439
we also wanted like a standalone runtime

350
00:11:48,720 --> 00:11:52,079
with

351
00:11:49,440 --> 00:11:53,120
low overhead so basically there's no

352
00:11:52,079 --> 00:11:55,599
daemon involved

353
00:11:53,120 --> 00:11:57,600
there's no versatile spawning demon and

354
00:11:55,600 --> 00:12:00,079
we inherit all the c groups from

355
00:11:57,600 --> 00:12:01,920
whatever was above us so it could be

356
00:12:00,079 --> 00:12:02,399
systemd it could be a docker if we're

357
00:12:01,920 --> 00:12:04,240
running

358
00:12:02,399 --> 00:12:05,600
and route inside docker or it could be

359
00:12:04,240 --> 00:12:09,120
slurm itself

360
00:12:05,600 --> 00:12:10,800
in our case and

361
00:12:09,120 --> 00:12:12,880
for dockers people are really confused

362
00:12:10,800 --> 00:12:13,199
by that because uh you actually use the

363
00:12:12,880 --> 00:12:14,720
c

364
00:12:13,200 --> 00:12:16,639
groups from the docker demon and not

365
00:12:14,720 --> 00:12:18,480
from the docker run command

366
00:12:16,639 --> 00:12:20,320
uh and that's that's kind of the

367
00:12:18,480 --> 00:12:23,120
behavior we wanted

368
00:12:20,320 --> 00:12:24,959
uh also like basically after the runtime

369
00:12:23,120 --> 00:12:26,000
has executed the application it's out of

370
00:12:24,959 --> 00:12:27,599
the picture so

371
00:12:26,000 --> 00:12:29,279
it execs the application and just

372
00:12:27,600 --> 00:12:31,839
disappear so

373
00:12:29,279 --> 00:12:32,959
you don't have any other process hanging

374
00:12:31,839 --> 00:12:35,839
around like

375
00:12:32,959 --> 00:12:36,800
like run c or docker have like to handle

376
00:12:35,839 --> 00:12:38,959
pty or

377
00:12:36,800 --> 00:12:41,519
or exit or tracking containers so we

378
00:12:38,959 --> 00:12:41,518
don't have that

379
00:12:41,760 --> 00:12:46,160
we also wanted minimal isolation so we

380
00:12:44,160 --> 00:12:47,040
don't need like this fancy network

381
00:12:46,160 --> 00:12:50,560
namespace

382
00:12:47,040 --> 00:12:53,279
with like overlays or or we don't need

383
00:12:50,560 --> 00:12:55,359
an ip for each container we don't need

384
00:12:53,279 --> 00:12:56,959
to bind privilege board

385
00:12:55,360 --> 00:12:58,720
we also don't want to pie in any space

386
00:12:56,959 --> 00:13:01,760
because we tend to confuse

387
00:12:58,720 --> 00:13:04,880
some programs as we saw before and

388
00:13:01,760 --> 00:13:06,639
um and also like end link pid one is

389
00:13:04,880 --> 00:13:09,200
pretty tricky and we've seen a lot of

390
00:13:06,639 --> 00:13:13,120
people like running sleep at speed one

391
00:13:09,200 --> 00:13:15,440
um as i said like we we just

392
00:13:13,120 --> 00:13:16,720
uh want to keep the secrets that were

393
00:13:15,440 --> 00:13:20,399
handled

394
00:13:16,720 --> 00:13:22,079
to us and um especially that like this

395
00:13:20,399 --> 00:13:24,959
killer is

396
00:13:22,079 --> 00:13:26,638
like has better insights on like what

397
00:13:24,959 --> 00:13:28,560
needs to happen like if you can over

398
00:13:26,639 --> 00:13:31,440
commit resources or not

399
00:13:28,560 --> 00:13:32,160
um and and obviously it simplifies the

400
00:13:31,440 --> 00:13:34,639
runtime and

401
00:13:32,160 --> 00:13:36,639
and improves the performance and

402
00:13:34,639 --> 00:13:38,240
speaking of performance some of like the

403
00:13:36,639 --> 00:13:39,440
problems you can get with traditional

404
00:13:38,240 --> 00:13:41,360
runtimes is you

405
00:13:39,440 --> 00:13:43,040
have a network namespace which like

406
00:13:41,360 --> 00:13:46,399
usually involves a bridge or

407
00:13:43,040 --> 00:13:48,639
nat or overlay uh networking so

408
00:13:46,399 --> 00:13:51,040
you had overhead there you have sac comp

409
00:13:48,639 --> 00:13:54,720
and lsm which can have overhead for

410
00:13:51,040 --> 00:13:57,360
cisco heavy uh applications we also uh

411
00:13:54,720 --> 00:14:00,720
rely on shared memory a lot so

412
00:13:57,360 --> 00:14:02,639
we need shared ipc namespace and uh

413
00:14:00,720 --> 00:14:03,920
docker and other runtimes also try to

414
00:14:02,639 --> 00:14:06,880
tune your r limits

415
00:14:03,920 --> 00:14:08,079
which sometimes are not really uh

416
00:14:06,880 --> 00:14:10,160
adapted

417
00:14:08,079 --> 00:14:12,399
uh so for example maplock is pretty low

418
00:14:10,160 --> 00:14:14,800
on docker by default

419
00:14:12,399 --> 00:14:16,399
and uh something that's less known is

420
00:14:14,800 --> 00:14:17,920
like when you actually turn on

421
00:14:16,399 --> 00:14:20,079
satcom by default on a lot of

422
00:14:17,920 --> 00:14:21,439
distribution you turn on also spectre

423
00:14:20,079 --> 00:14:24,160
mitigation so

424
00:14:21,440 --> 00:14:25,680
if you're uh concerned about performance

425
00:14:24,160 --> 00:14:29,120
then like

426
00:14:25,680 --> 00:14:32,319
we we actually don't want that

427
00:14:29,120 --> 00:14:33,040
a little note about mpi which is like a

428
00:14:32,320 --> 00:14:35,279
standard

429
00:14:33,040 --> 00:14:37,360
for framework for message passing that

430
00:14:35,279 --> 00:14:40,480
we use uh to communicate

431
00:14:37,360 --> 00:14:43,920
uh inside a node or even outside

432
00:14:40,480 --> 00:14:45,120
uh so mpi doesn't really like also pid

433
00:14:43,920 --> 00:14:47,920
and ipc namespaces

434
00:14:45,120 --> 00:14:49,279
as we discussed and the cool thing of

435
00:14:47,920 --> 00:14:50,959
having like a fully and privileged

436
00:14:49,279 --> 00:14:52,399
runtime is that we can use a cross

437
00:14:50,959 --> 00:14:54,399
memory attach

438
00:14:52,399 --> 00:14:55,440
so it it's like the cisco s process

439
00:14:54,399 --> 00:14:59,279
vmware v

440
00:14:55,440 --> 00:15:01,760
which is extensively used by mpi

441
00:14:59,279 --> 00:15:02,720
and that actually requires ptrace access

442
00:15:01,760 --> 00:15:05,120
so

443
00:15:02,720 --> 00:15:05,839
with traditional privilege runtimes it's

444
00:15:05,120 --> 00:15:09,120
kind of hard to

445
00:15:05,839 --> 00:15:11,839
have that working as for

446
00:15:09,120 --> 00:15:12,639
coordination with pmi and pmx i'm really

447
00:15:11,839 --> 00:15:16,399
dwell on that

448
00:15:12,639 --> 00:15:17,360
but uh we just let like we actually need

449
00:15:16,399 --> 00:15:19,360
to pass uh

450
00:15:17,360 --> 00:15:20,480
file descriptor to the actual container

451
00:15:19,360 --> 00:15:22,480
so we link

452
00:15:20,480 --> 00:15:25,279
uh file descriptor inside uh the

453
00:15:22,480 --> 00:15:28,000
containers by default

454
00:15:25,279 --> 00:15:29,600
uh the most difficult part is actually

455
00:15:28,000 --> 00:15:31,759
the importing docker images

456
00:15:29,600 --> 00:15:32,800
in the runtime because you have to deal

457
00:15:31,759 --> 00:15:35,839
with a lot of

458
00:15:32,800 --> 00:15:38,079
the oci stuff uh ufs formats and

459
00:15:35,839 --> 00:15:39,839
and other things and we really wanted to

460
00:15:38,079 --> 00:15:42,800
speed that up

461
00:15:39,839 --> 00:15:43,440
because we pull like really big images

462
00:15:42,800 --> 00:15:44,959
uh so

463
00:15:43,440 --> 00:15:47,120
what we do is we actually relay on

464
00:15:44,959 --> 00:15:50,160
overlay fs uh to

465
00:15:47,120 --> 00:15:51,839
basically do a a power

466
00:15:50,160 --> 00:15:54,240
basically we just want the kernel to do

467
00:15:51,839 --> 00:15:56,000
all the uh squashing of layers

468
00:15:54,240 --> 00:15:58,320
rather than like a sequential extraction

469
00:15:56,000 --> 00:16:00,800
like docker or imochi do

470
00:15:58,320 --> 00:16:03,600
um also we found out that like just

471
00:16:00,800 --> 00:16:06,000
using play bash like the parallel curl

472
00:16:03,600 --> 00:16:07,040
uh pipeline it tends to be much faster

473
00:16:06,000 --> 00:16:10,240
than the going

474
00:16:07,040 --> 00:16:13,759
because some of the packages are

475
00:16:10,240 --> 00:16:13,759
not really optimized

476
00:16:14,160 --> 00:16:19,680
and we weren't really fond of the

477
00:16:17,600 --> 00:16:21,680
format like the vfs format for example

478
00:16:19,680 --> 00:16:24,719
that podman or docker

479
00:16:21,680 --> 00:16:28,399
have because it's huge on disk space

480
00:16:24,720 --> 00:16:30,639
and if you were to use the overlay

481
00:16:28,399 --> 00:16:32,560
driver in docker or other things what

482
00:16:30,639 --> 00:16:34,399
they do is they actually keep the layers

483
00:16:32,560 --> 00:16:36,239
uncompressed

484
00:16:34,399 --> 00:16:37,759
but you can't share the layers between

485
00:16:36,240 --> 00:16:38,800
users because you would need something

486
00:16:37,759 --> 00:16:42,079
like shift fs

487
00:16:38,800 --> 00:16:44,639
or something uh to convert the reddis uh

488
00:16:42,079 --> 00:16:46,880
so what we do is we actually uh store

489
00:16:44,639 --> 00:16:48,560
share layers across the same

490
00:16:46,880 --> 00:16:52,480
across users in the same group and we

491
00:16:48,560 --> 00:16:52,479
compress them with z standard

492
00:16:52,639 --> 00:16:56,000
and we have a helper binaries for

493
00:16:54,399 --> 00:16:58,720
overlay because uh

494
00:16:56,000 --> 00:17:00,320
unfortunately overlay is privileged it's

495
00:16:58,720 --> 00:17:01,199
unprivileged on ubuntu but it's kind of

496
00:17:00,320 --> 00:17:04,319
broken

497
00:17:01,199 --> 00:17:07,359
right now so we have that

498
00:17:04,319 --> 00:17:08,240
uh which is not owned by default so only

499
00:17:07,359 --> 00:17:11,760
the admin can

500
00:17:08,240 --> 00:17:14,799
import images by default with android

501
00:17:11,760 --> 00:17:16,160
uh for the image format we chose uh

502
00:17:14,799 --> 00:17:18,240
squash fs

503
00:17:16,160 --> 00:17:20,160
and we wanted to be super simple so

504
00:17:18,240 --> 00:17:22,000
basically uh when we convert the docker

505
00:17:20,160 --> 00:17:25,199
image all the the entry point becomes

506
00:17:22,000 --> 00:17:27,520
just slash atc rc all the environment

507
00:17:25,199 --> 00:17:28,400
goes to htc environment and the volumes

508
00:17:27,520 --> 00:17:31,520
goes to

509
00:17:28,400 --> 00:17:32,000
hcfs tab and basically when you land in

510
00:17:31,520 --> 00:17:33,679
the container

511
00:17:32,000 --> 00:17:35,440
you can edit this configuration

512
00:17:33,679 --> 00:17:37,600
configuration files like you're

513
00:17:35,440 --> 00:17:39,520
used to and and restart the container

514
00:17:37,600 --> 00:17:41,600
and it will just be picked up

515
00:17:39,520 --> 00:17:42,799
uh we like squash fs images because you

516
00:17:41,600 --> 00:17:44,799
can store that

517
00:17:42,799 --> 00:17:46,400
as a single file on the parallel file

518
00:17:44,799 --> 00:17:49,200
system and and use it

519
00:17:46,400 --> 00:17:51,360
to pull that really fast internally and

520
00:17:49,200 --> 00:17:53,440
also avoid like all the thundering hurts

521
00:17:51,360 --> 00:17:54,719
problems that you have when mult well

522
00:17:53,440 --> 00:17:56,799
you kick in uh

523
00:17:54,720 --> 00:17:58,960
multiple jobs and it starts pulling the

524
00:17:56,799 --> 00:18:01,440
image like 100 times

525
00:17:58,960 --> 00:18:03,120
uh also useful for hair gaps where the

526
00:18:01,440 --> 00:18:05,120
admin can control actually what you can

527
00:18:03,120 --> 00:18:06,959
run so it imports the squash fs and just

528
00:18:05,120 --> 00:18:09,039
stores it on the cluster

529
00:18:06,960 --> 00:18:10,000
and uh you can also mount it as a black

530
00:18:09,039 --> 00:18:13,039
device

531
00:18:10,000 --> 00:18:16,559
and uh have it lazily fetch

532
00:18:13,039 --> 00:18:20,160
for example through nfs or something

533
00:18:16,559 --> 00:18:20,960
uh also we and finally like we wanted to

534
00:18:20,160 --> 00:18:23,840
be

535
00:18:20,960 --> 00:18:25,360
super simple so the runtime is actually

536
00:18:23,840 --> 00:18:26,879
just a simple shell script that's like

537
00:18:25,360 --> 00:18:29,520
500 lines of code

538
00:18:26,880 --> 00:18:31,600
and it uses just basic linux utilities

539
00:18:29,520 --> 00:18:34,400
to set up everything

540
00:18:31,600 --> 00:18:36,080
so um it's actually easy for users and

541
00:18:34,400 --> 00:18:36,799
admin to customize everything if they

542
00:18:36,080 --> 00:18:37,840
want to

543
00:18:36,799 --> 00:18:39,120
if there's something that they don't

544
00:18:37,840 --> 00:18:40,399
like in the runtime they can change

545
00:18:39,120 --> 00:18:43,439
something

546
00:18:40,400 --> 00:18:45,120
and we have users and and system-wide

547
00:18:43,440 --> 00:18:46,559
configuration that you can drop in if

548
00:18:45,120 --> 00:18:48,639
you want the mouse or

549
00:18:46,559 --> 00:18:50,160
environment in all your containers on

550
00:18:48,640 --> 00:18:52,720
the system or on this

551
00:18:50,160 --> 00:18:53,760
or all the containers of specific users

552
00:18:52,720 --> 00:18:57,520
you can just write these

553
00:18:53,760 --> 00:18:59,360
uh configuration files

554
00:18:57,520 --> 00:19:01,520
so now for the basic usage you can just

555
00:18:59,360 --> 00:19:03,039
uh so basically you can do android

556
00:19:01,520 --> 00:19:05,520
import you will just uh

557
00:19:03,039 --> 00:19:06,080
give it give it the docker uh uri and

558
00:19:05,520 --> 00:19:08,720
you

559
00:19:06,080 --> 00:19:10,320
end up with like squash fs representing

560
00:19:08,720 --> 00:19:11,679
the the entire image

561
00:19:10,320 --> 00:19:13,520
then you can store that and share it

562
00:19:11,679 --> 00:19:15,440
with someone

563
00:19:13,520 --> 00:19:16,879
you can create then the container from

564
00:19:15,440 --> 00:19:19,360
this clashfast image

565
00:19:16,880 --> 00:19:22,000
which just unpacks the squashfs and

566
00:19:19,360 --> 00:19:23,918
under your xdg datapath

567
00:19:22,000 --> 00:19:25,360
and then you can start obviously stuff

568
00:19:23,919 --> 00:19:27,679
in there so

569
00:19:25,360 --> 00:19:29,039
you can run nvidia semi in tensorflow or

570
00:19:27,679 --> 00:19:31,760
you can also remap

571
00:19:29,039 --> 00:19:33,200
yourself as root and have the read write

572
00:19:31,760 --> 00:19:36,879
root file system so you can install

573
00:19:33,200 --> 00:19:36,880
packages as a non-privileged user

574
00:19:37,200 --> 00:19:41,280
uh some of the advanced stuff you can do

575
00:19:39,039 --> 00:19:41,840
also is you can start the actual image

576
00:19:41,280 --> 00:19:43,840
directly

577
00:19:41,840 --> 00:19:45,280
in this case we actually rely on fuse to

578
00:19:43,840 --> 00:19:49,600
mount squash fs

579
00:19:45,280 --> 00:19:52,000
and uh and all you change are in memory

580
00:19:49,600 --> 00:19:53,840
and they're really uh i think like neat

581
00:19:52,000 --> 00:19:54,960
thing that like people like is actually

582
00:19:53,840 --> 00:19:57,678
being able to create

583
00:19:54,960 --> 00:19:58,559
uh self-extracting bundles so you can do

584
00:19:57,679 --> 00:20:02,000
android bundle

585
00:19:58,559 --> 00:20:02,000
and then you will actually have a

586
00:20:02,400 --> 00:20:06,880
a run file that we call in run file that

587
00:20:04,880 --> 00:20:10,000
includes the image and the runtime

588
00:20:06,880 --> 00:20:12,080
so you can send that to anyone running

589
00:20:10,000 --> 00:20:14,880
linux and they can just run your

590
00:20:12,080 --> 00:20:17,039
container without any dependency

591
00:20:14,880 --> 00:20:18,799
so if you have an experience you want to

592
00:20:17,039 --> 00:20:19,440
share with a coworker you can send it by

593
00:20:18,799 --> 00:20:23,039
email or

594
00:20:19,440 --> 00:20:26,159
send ubuntu by email or something

595
00:20:23,039 --> 00:20:27,919
which is really really practical

596
00:20:26,159 --> 00:20:29,200
especially when you do cloud deployments

597
00:20:27,919 --> 00:20:30,400
as well

598
00:20:29,200 --> 00:20:32,159
you don't have to install anything on

599
00:20:30,400 --> 00:20:34,240
the instance you just drop this file and

600
00:20:32,159 --> 00:20:36,720
run it

601
00:20:34,240 --> 00:20:37,760
now when you look at how it's

602
00:20:36,720 --> 00:20:40,159
implemented inside

603
00:20:37,760 --> 00:20:41,039
uh we have few utilities that replace

604
00:20:40,159 --> 00:20:44,000
basically the

605
00:20:41,039 --> 00:20:45,440
linux ones they're really simple uh it's

606
00:20:44,000 --> 00:20:48,000
basically three of them and written

607
00:20:45,440 --> 00:20:49,840
share and mountain and research

608
00:20:48,000 --> 00:20:52,880
and we have two other ones which are

609
00:20:49,840 --> 00:20:56,158
mostly used for docker imports

610
00:20:52,880 --> 00:20:57,120
if you were to use the actual utilities

611
00:20:56,159 --> 00:20:58,799
directly

612
00:20:57,120 --> 00:21:00,719
you could write your own custom runtimes

613
00:20:58,799 --> 00:21:01,280
really easily so here you just download

614
00:21:00,720 --> 00:21:03,679
the

615
00:21:01,280 --> 00:21:05,280
ubuntu official root file system you

616
00:21:03,679 --> 00:21:06,880
create new name spaces

617
00:21:05,280 --> 00:21:08,399
and then you mount a bunch of things and

618
00:21:06,880 --> 00:21:10,480
at the end you just exact

619
00:21:08,400 --> 00:21:12,159
switch route and run bash inside your

620
00:21:10,480 --> 00:21:12,640
container and now you have a really

621
00:21:12,159 --> 00:21:17,360
simple

622
00:21:12,640 --> 00:21:20,799
uh like container runtime

623
00:21:17,360 --> 00:21:20,799
and now i'll do the

624
00:21:21,360 --> 00:21:24,799
likes which will explain the strong

625
00:21:22,799 --> 00:21:28,080
plugin that we did right so

626
00:21:24,799 --> 00:21:30,000
we saw androids the runtime so we

627
00:21:28,080 --> 00:21:32,000
actually give access to this runtime

628
00:21:30,000 --> 00:21:33,440
for users so they can use android start

629
00:21:32,000 --> 00:21:35,760
and route create

630
00:21:33,440 --> 00:21:36,880
but we didn't want to have users learn

631
00:21:35,760 --> 00:21:39,120
something new

632
00:21:36,880 --> 00:21:40,880
because they are used to darker and and

633
00:21:39,120 --> 00:21:41,520
but for some for reasons that we have

634
00:21:40,880 --> 00:21:44,960
explained

635
00:21:41,520 --> 00:21:48,480
we didn't give them access to darker

636
00:21:44,960 --> 00:21:48,880
on on our cluster so um they are used to

637
00:21:48,480 --> 00:21:51,679
the

638
00:21:48,880 --> 00:21:53,440
syntax above with slum the commands

639
00:21:51,679 --> 00:21:54,559
called strand you just specify a command

640
00:21:53,440 --> 00:21:56,799
and it will run that

641
00:21:54,559 --> 00:21:58,559
on one node on multiple nodes and you

642
00:21:56,799 --> 00:22:02,400
say i want to run python

643
00:21:58,559 --> 00:22:04,240
on onenote and slam has a lot of plugins

644
00:22:02,400 --> 00:22:06,039
and it was very nice because we could

645
00:22:04,240 --> 00:22:08,720
add we added the container

646
00:22:06,039 --> 00:22:10,640
image.container image

647
00:22:08,720 --> 00:22:12,000
flag and you say i want to run

648
00:22:10,640 --> 00:22:14,000
tensorflow and that's the

649
00:22:12,000 --> 00:22:15,520
only change in blue and yellow here

650
00:22:14,000 --> 00:22:17,039
that's the only change that our users

651
00:22:15,520 --> 00:22:19,200
had to learn they can still use any

652
00:22:17,039 --> 00:22:20,080
route if they want but we wanted to make

653
00:22:19,200 --> 00:22:21,200
it easy

654
00:22:20,080 --> 00:22:22,799
they don't know about the container

655
00:22:21,200 --> 00:22:23,840
runtimes they don't know it's enroutes

656
00:22:22,799 --> 00:22:25,360
they don't know

657
00:22:23,840 --> 00:22:29,120
it actually started as a prototype with

658
00:22:25,360 --> 00:22:31,120
lxc2 and it was the same syntax because

659
00:22:29,120 --> 00:22:32,959
here we don't need to be very

660
00:22:31,120 --> 00:22:34,559
complicated because our runtime is very

661
00:22:32,960 --> 00:22:38,320
simple too we just want

662
00:22:34,559 --> 00:22:39,760
to say run this image with mounts

663
00:22:38,320 --> 00:22:41,520
and that's pretty much it that's the

664
00:22:39,760 --> 00:22:43,919
basic um

665
00:22:41,520 --> 00:22:45,200
so a little bit of the details oh we do

666
00:22:43,919 --> 00:22:47,679
that since

667
00:22:45,200 --> 00:22:49,200
that we start the container so so right

668
00:22:47,679 --> 00:22:51,440
now it's within roots

669
00:22:49,200 --> 00:22:52,799
and we basically get the handles on the

670
00:22:51,440 --> 00:22:54,640
the namespaces

671
00:22:52,799 --> 00:22:56,158
we get environment viables about about

672
00:22:54,640 --> 00:22:59,120
the process and we get

673
00:22:56,159 --> 00:23:01,200
the directory where the container is but

674
00:22:59,120 --> 00:23:03,678
we cannot hijack the exact we cannot

675
00:23:01,200 --> 00:23:07,200
hijack the exact python train the py

676
00:23:03,679 --> 00:23:10,240
so it's more like a darker exact what we

677
00:23:07,200 --> 00:23:12,480
do here in slum is we docker exactly

678
00:23:10,240 --> 00:23:13,280
that be just before we go to the python

679
00:23:12,480 --> 00:23:16,240
trade on

680
00:23:13,280 --> 00:23:17,918
train.py we do a bunch of saturn s calls

681
00:23:16,240 --> 00:23:19,200
to join the name spaces of the container

682
00:23:17,919 --> 00:23:21,600
we have created

683
00:23:19,200 --> 00:23:23,320
and then we hand it back to slurm and

684
00:23:21,600 --> 00:23:25,678
slurm will execute

685
00:23:23,320 --> 00:23:27,280
python00.py it doesn't know it that has

686
00:23:25,679 --> 00:23:29,440
been containerized in between

687
00:23:27,280 --> 00:23:30,480
but it actually just worked um that

688
00:23:29,440 --> 00:23:33,600
works just fine

689
00:23:30,480 --> 00:23:37,200
with just those few steps

690
00:23:33,600 --> 00:23:40,959
um so quickly uh as i said we have

691
00:23:37,200 --> 00:23:42,559
a few just a few um new flags

692
00:23:40,960 --> 00:23:44,240
so you can name the container if you do

693
00:23:42,559 --> 00:23:47,039
container image by torch

694
00:23:44,240 --> 00:23:48,559
it pulls that from daca up transparently

695
00:23:47,039 --> 00:23:50,000
and you can name it so you can

696
00:23:48,559 --> 00:23:51,760
you can reuse it if i call that

697
00:23:50,000 --> 00:23:54,159
container by torch

698
00:23:51,760 --> 00:23:55,440
and i can install a package for instance

699
00:23:54,159 --> 00:23:58,480
vm vm touch

700
00:23:55,440 --> 00:24:00,320
to load data sets in memory and then if

701
00:23:58,480 --> 00:24:02,159
i reuse this container name and i add a

702
00:24:00,320 --> 00:24:04,480
mount it's still the same container

703
00:24:02,159 --> 00:24:05,200
and i will load my dataset in memory and

704
00:24:04,480 --> 00:24:09,600
then

705
00:24:05,200 --> 00:24:11,200
um for interactive job if i want um

706
00:24:09,600 --> 00:24:12,559
a shell inside my container it's

707
00:24:11,200 --> 00:24:13,520
actually we don't do actually anything

708
00:24:12,559 --> 00:24:17,279
on this side

709
00:24:13,520 --> 00:24:20,480
slurm as a command as a flag called pty

710
00:24:17,279 --> 00:24:21,840
and i'm a fake i mean i'm remapped roots

711
00:24:20,480 --> 00:24:23,919
inside the container

712
00:24:21,840 --> 00:24:26,399
and i can do whatever i want with the

713
00:24:23,919 --> 00:24:29,679
combination of slum and our plugin

714
00:24:26,400 --> 00:24:31,679
and we have a slum as batch

715
00:24:29,679 --> 00:24:32,960
job so you can have a shelf script you

716
00:24:31,679 --> 00:24:35,520
just send this

717
00:24:32,960 --> 00:24:36,320
uh send this shell script to slim with

718
00:24:35,520 --> 00:24:38,400
sbatch

719
00:24:36,320 --> 00:24:39,840
and you can run that on 64 nodes for

720
00:24:38,400 --> 00:24:42,080
instance and here

721
00:24:39,840 --> 00:24:43,360
is something a bit more complicated but

722
00:24:42,080 --> 00:24:46,399
uh you can have a

723
00:24:43,360 --> 00:24:49,678
multi-node tensorflow job

724
00:24:46,400 --> 00:24:53,840
uh with 16

725
00:24:49,679 --> 00:24:53,840
process per node and

726
00:24:54,400 --> 00:24:58,080
and five minutes left and we reach the

727
00:24:56,480 --> 00:24:59,039
conclusion so we have five minutes for

728
00:24:58,080 --> 00:25:01,120
question

729
00:24:59,039 --> 00:25:02,559
um so we'll have to thank all our

730
00:25:01,120 --> 00:25:04,000
colleagues because we've been

731
00:25:02,559 --> 00:25:05,760
working on that for a few months at

732
00:25:04,000 --> 00:25:09,279
nvidia and

733
00:25:05,760 --> 00:25:10,400
uh that's it so our end time in roots is

734
00:25:09,279 --> 00:25:13,279
open source on github

735
00:25:10,400 --> 00:25:16,720
and our plugin is also open source and

736
00:25:13,279 --> 00:25:16,720
we are open for questions now

737
00:25:16,900 --> 00:25:25,840
[Applause]

738
00:25:23,200 --> 00:25:27,039
so could you explain a little bit better

739
00:25:25,840 --> 00:25:30,720
what didn't you

740
00:25:27,039 --> 00:25:32,240
find that you wanted in current hpc

741
00:25:30,720 --> 00:25:35,600
container solutions

742
00:25:32,240 --> 00:25:38,159
that prompted you to create and root so

743
00:25:35,600 --> 00:25:39,199
like like singularity sorry cloud these

744
00:25:38,159 --> 00:25:42,559
kind of things

745
00:25:39,200 --> 00:25:44,320
uh well we reviewed lots of them

746
00:25:42,559 --> 00:25:46,000
and i mean each one of them are their

747
00:25:44,320 --> 00:25:48,559
downsides uh

748
00:25:46,000 --> 00:25:50,080
i mean i i could list like all the

749
00:25:48,559 --> 00:25:51,600
reasons for each one of them but we

750
00:25:50,080 --> 00:25:53,918
evaluated all of them

751
00:25:51,600 --> 00:25:56,000
uh the closest one was like charlie

752
00:25:53,919 --> 00:25:58,320
cloud i think which was the closest in

753
00:25:56,000 --> 00:25:59,520
philosophy it's like android problem is

754
00:25:58,320 --> 00:26:02,320
that we scan a little

755
00:25:59,520 --> 00:26:04,080
too static in our case so we had we

756
00:26:02,320 --> 00:26:06,080
wanted something that was way more

757
00:26:04,080 --> 00:26:07,439
dynamic and then like basically we could

758
00:26:06,080 --> 00:26:10,559
modify depending on

759
00:26:07,440 --> 00:26:12,240
cluster environments so admins are wants

760
00:26:10,559 --> 00:26:12,960
to do some stuffs in the container

761
00:26:12,240 --> 00:26:15,679
runtimes

762
00:26:12,960 --> 00:26:16,960
and charity cargo is kind of static so

763
00:26:15,679 --> 00:26:18,640
uh

764
00:26:16,960 --> 00:26:20,240
yeah and they don't use all the tricks

765
00:26:18,640 --> 00:26:22,640
that we we have

766
00:26:20,240 --> 00:26:23,840
listed so i mean eventually maybe they

767
00:26:22,640 --> 00:26:25,360
will but

768
00:26:23,840 --> 00:26:27,199
right now isn't the case it was easier

769
00:26:25,360 --> 00:26:28,559
for us to write it and again there was

770
00:26:27,200 --> 00:26:38,640
500 lines of batch

771
00:26:28,559 --> 00:26:41,520
so it wasn't too complicated

772
00:26:38,640 --> 00:26:42,080
um perhaps i missed it uh are there any

773
00:26:41,520 --> 00:26:43,918
bits

774
00:26:42,080 --> 00:26:45,279
that need wood privileges in handling

775
00:26:43,919 --> 00:26:48,400
the containers

776
00:26:45,279 --> 00:26:49,919
uh no so the runtime itself is fully

777
00:26:48,400 --> 00:26:52,960
unprivileged

778
00:26:49,919 --> 00:26:54,720
now the import you only have one

779
00:26:52,960 --> 00:26:56,480
you need one cap to actually mount

780
00:26:54,720 --> 00:26:58,720
overlay but then the

781
00:26:56,480 --> 00:27:00,720
actual squash is on privilege so by

782
00:26:58,720 --> 00:27:01,919
default we don't allow users to pull

783
00:27:00,720 --> 00:27:03,760
images

784
00:27:01,919 --> 00:27:05,200
to convert docker images i mean even

785
00:27:03,760 --> 00:27:07,279
though they could do it with like

786
00:27:05,200 --> 00:27:09,520
scorpio and umochi or something we don't

787
00:27:07,279 --> 00:27:11,919
allow that

788
00:27:09,520 --> 00:27:13,440
because basically it's also discouraging

789
00:27:11,919 --> 00:27:14,559
like people from pulling random stuff

790
00:27:13,440 --> 00:27:16,720
from the internet

791
00:27:14,559 --> 00:27:18,480
and if the admin wants to allow that

792
00:27:16,720 --> 00:27:20,240
then you can just add one cap on

793
00:27:18,480 --> 00:27:22,320
on the binary which is fairly safe

794
00:27:20,240 --> 00:27:26,080
because mounting really only

795
00:27:22,320 --> 00:27:29,039
overlays fairly safe ubuntu allows it

796
00:27:26,080 --> 00:27:35,840
other distribution not but no the rest

797
00:27:29,039 --> 00:27:35,840
is fully in privilege

798
00:27:36,000 --> 00:27:49,840
oh that's gonna be fun

799
00:27:51,360 --> 00:27:53,760
was it

800
00:27:56,799 --> 00:28:02,720
so now since all the focus here is on

801
00:27:58,880 --> 00:28:02,720
htc's on performance i would like to

802
00:28:04,000 --> 00:28:08,080
here is on performance on hpc side side

803
00:28:06,640 --> 00:28:09,039
and as a user i would like to understand

804
00:28:08,080 --> 00:28:11,120
if your plan is

805
00:28:09,039 --> 00:28:12,799
more to go towards substitute to the

806
00:28:11,120 --> 00:28:14,399
modules schema where the

807
00:28:12,799 --> 00:28:16,158
where a single cluster provides to the

808
00:28:14,399 --> 00:28:17,199
modules for the software and you load

809
00:28:16,159 --> 00:28:19,840
the module and run

810
00:28:17,200 --> 00:28:20,320
your software with the library already

811
00:28:19,840 --> 00:28:23,600
pre

812
00:28:20,320 --> 00:28:24,639
configured or you rather see the cluster

813
00:28:23,600 --> 00:28:27,199
the cluster

814
00:28:24,640 --> 00:28:27,679
it guys to provide you the container

815
00:28:27,200 --> 00:28:29,440
that is

816
00:28:27,679 --> 00:28:30,960
compa with the software specifically

817
00:28:29,440 --> 00:28:34,080
compiled for that cluster

818
00:28:30,960 --> 00:28:36,080
or you provide the container to run the

819
00:28:34,080 --> 00:28:38,399
software like tensorflow for example

820
00:28:36,080 --> 00:28:39,120
can i download the application from your

821
00:28:38,399 --> 00:28:42,000
site should pro

822
00:28:39,120 --> 00:28:42,399
should it be provided by my cluster it

823
00:28:42,000 --> 00:28:44,640
guy

824
00:28:42,399 --> 00:28:46,479
or should i compile it myself in your

825
00:28:44,640 --> 00:28:49,919
environment how do you foresee it or

826
00:28:46,480 --> 00:28:53,120
the module schema is not it's not yet

827
00:28:49,919 --> 00:28:53,679
it's not okay right now for example i

828
00:28:53,120 --> 00:28:57,678
mean

829
00:28:53,679 --> 00:28:59,600
i see the module schema as the standard

830
00:28:57,679 --> 00:29:01,840
right so the problem we problem with

831
00:28:59,600 --> 00:29:03,600
modules and stuff it's like

832
00:29:01,840 --> 00:29:04,959
i mean you only get all the benefits

833
00:29:03,600 --> 00:29:08,320
from containers

834
00:29:04,960 --> 00:29:09,919
so it's mostly admin driven where our

835
00:29:08,320 --> 00:29:11,360
our needs were more like user-centric

836
00:29:09,919 --> 00:29:12,320
where we want a user to bring their own

837
00:29:11,360 --> 00:29:15,520
applications

838
00:29:12,320 --> 00:29:17,200
so modules didn't really fit uh these

839
00:29:15,520 --> 00:29:18,639
uh we didn't want admins to be really

840
00:29:17,200 --> 00:29:21,760
involved in in the

841
00:29:18,640 --> 00:29:23,520
the process of running apps as for uh

842
00:29:21,760 --> 00:29:25,520
actually compiling stuff specifically

843
00:29:23,520 --> 00:29:28,639
for your clusters

844
00:29:25,520 --> 00:29:33,279
we tend to do that with our containers

845
00:29:28,640 --> 00:29:36,320
so okay if i am

846
00:29:33,279 --> 00:29:39,360
how do you call it if i am a developer

847
00:29:36,320 --> 00:29:40,799
and i develop my software for

848
00:29:39,360 --> 00:29:42,639
for example my specific case for

849
00:29:40,799 --> 00:29:45,360
tensorflow okay

850
00:29:42,640 --> 00:29:46,559
i do that and at the end if i provide to

851
00:29:45,360 --> 00:29:49,199
the end user

852
00:29:46,559 --> 00:29:50,000
the container with tensorflow embedded

853
00:29:49,200 --> 00:29:52,000
in it

854
00:29:50,000 --> 00:29:54,559
the flag that i will that i would have

855
00:29:52,000 --> 00:29:56,080
used to compile that particular machine

856
00:29:54,559 --> 00:29:57,120
would have been the one that fit my own

857
00:29:56,080 --> 00:29:58,720
clusters

858
00:29:57,120 --> 00:30:00,799
environment okay not the one of the

859
00:29:58,720 --> 00:30:03,360
final user in his own machine

860
00:30:00,799 --> 00:30:04,799
right okay so it would be useless for

861
00:30:03,360 --> 00:30:06,479
him at the end or it won't be the

862
00:30:04,799 --> 00:30:07,200
maximum performance that he will get by

863
00:30:06,480 --> 00:30:09,440
compiling it

864
00:30:07,200 --> 00:30:11,360
on its own machine right and again we so

865
00:30:09,440 --> 00:30:12,799
we have a registry where we host all the

866
00:30:11,360 --> 00:30:15,678
optimized stuff from

867
00:30:12,799 --> 00:30:17,600
for our platforms and but again like you

868
00:30:15,679 --> 00:30:18,240
can have an admin that just drops squash

869
00:30:17,600 --> 00:30:20,000
files

870
00:30:18,240 --> 00:30:21,440
that are specifically compiled for your

871
00:30:20,000 --> 00:30:23,120
clusters and then

872
00:30:21,440 --> 00:30:25,039
your users can just use the squash file

873
00:30:23,120 --> 00:30:26,320
that the admin imported similarly to

874
00:30:25,039 --> 00:30:28,399
modules

875
00:30:26,320 --> 00:30:29,760
or you can have the user if you really

876
00:30:28,399 --> 00:30:32,158
know what it's doing

877
00:30:29,760 --> 00:30:32,960
can also push something to a registry

878
00:30:32,159 --> 00:30:35,440
and pull that

879
00:30:32,960 --> 00:30:37,840
so we have both use cases covered pretty

880
00:30:35,440 --> 00:30:37,840
much

881
00:30:38,880 --> 00:30:47,520
and we're off time thank you

