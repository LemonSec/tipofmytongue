1
00:00:10,880 --> 00:00:13,679
good morning everyone

2
00:00:14,000 --> 00:00:17,840
thanks for being here this early i'm

3
00:00:17,199 --> 00:00:19,920
arna

4
00:00:17,840 --> 00:00:21,840
i'm a lecturer in future engineering at

5
00:00:19,920 --> 00:00:23,600
the hamsa university of applied sciences

6
00:00:21,840 --> 00:00:26,720
in the netherlands

7
00:00:23,600 --> 00:00:28,960
and what i'll be talking about is how

8
00:00:26,720 --> 00:00:31,198
we might be able to use threat modeling

9
00:00:28,960 --> 00:00:32,800
for improving or to help improve the

10
00:00:31,199 --> 00:00:36,559
security of

11
00:00:32,800 --> 00:00:38,879
software because currently

12
00:00:36,559 --> 00:00:42,160
if we compare the security of software

13
00:00:38,879 --> 00:00:46,239
with the security or at least the safety

14
00:00:42,160 --> 00:00:49,679
of for example um air travel

15
00:00:46,239 --> 00:00:53,120
or elevators then there's quite

16
00:00:49,680 --> 00:00:56,239
a well difference

17
00:00:53,120 --> 00:00:59,358
to put it mildly now

18
00:00:56,239 --> 00:01:02,320
of course safety and

19
00:00:59,359 --> 00:01:03,120
security are not exactly the same thing

20
00:01:02,320 --> 00:01:06,000
uh

21
00:01:03,120 --> 00:01:06,960
with safety we're interested in

22
00:01:06,000 --> 00:01:10,400
protecting

23
00:01:06,960 --> 00:01:13,439
our infrastructure against the elements

24
00:01:10,400 --> 00:01:16,000
right now with security

25
00:01:13,439 --> 00:01:16,559
we want to protect our infrastructure

26
00:01:16,000 --> 00:01:19,840
against

27
00:01:16,560 --> 00:01:22,400
godzilla or attackers

28
00:01:19,840 --> 00:01:23,439
intelligence usually at least we can

29
00:01:22,400 --> 00:01:25,520
assume

30
00:01:23,439 --> 00:01:28,158
at least part of the time intelligence

31
00:01:25,520 --> 00:01:28,158
trying to

32
00:01:28,240 --> 00:01:34,798
get around our defenses so

33
00:01:31,520 --> 00:01:37,840
of course as developers we can then ask

34
00:01:34,799 --> 00:01:38,400
are we do right can we can we actually

35
00:01:37,840 --> 00:01:41,920
protect

36
00:01:38,400 --> 00:01:45,119
ourselves and if we take the approach

37
00:01:41,920 --> 00:01:48,000
of penetrate and patch so

38
00:01:45,119 --> 00:01:49,280
after we've shipped the products looking

39
00:01:48,000 --> 00:01:52,079
for vulnerabilities

40
00:01:49,280 --> 00:01:53,520
and patching them i think we are doomed

41
00:01:52,079 --> 00:01:56,559
well

42
00:01:53,520 --> 00:01:58,880
another approach has been proposed scott

43
00:01:56,560 --> 00:01:59,680
uh goes under different names security

44
00:01:58,880 --> 00:02:01,759
by design

45
00:01:59,680 --> 00:02:03,520
building security in or shifting

46
00:02:01,759 --> 00:02:06,079
security left

47
00:02:03,520 --> 00:02:07,039
the idea is to integrate security into

48
00:02:06,079 --> 00:02:10,318
the development

49
00:02:07,040 --> 00:02:14,000
life cycle early on and

50
00:02:10,318 --> 00:02:14,000
that can be in the form of

51
00:02:20,080 --> 00:02:25,599
approach now

52
00:02:23,599 --> 00:02:26,720
if you want to start applying this where

53
00:02:25,599 --> 00:02:28,399
do you start right which

54
00:02:26,720 --> 00:02:31,519
which activity is then the most

55
00:02:28,400 --> 00:02:34,640
important now if we follow howard

56
00:02:31,519 --> 00:02:38,160
and lipner they say that

57
00:02:34,640 --> 00:02:40,720
if they had to choose they'd choose for

58
00:02:38,160 --> 00:02:42,480
threat modeling any day every day of the

59
00:02:40,720 --> 00:02:45,120
week

60
00:02:42,480 --> 00:02:45,679
now what is threat modeling threat

61
00:02:45,120 --> 00:02:48,720
modeling

62
00:02:45,680 --> 00:02:51,280
it's got um

63
00:02:48,720 --> 00:02:52,480
well the term is used in for for two

64
00:02:51,280 --> 00:02:54,000
different things

65
00:02:52,480 --> 00:02:55,359
uh one thing more relates to

66
00:02:54,000 --> 00:02:56,879
requirements engineering and the other

67
00:02:55,360 --> 00:02:59,120
thing more related to

68
00:02:56,879 --> 00:03:01,359
uh analyzing the architecture against

69
00:02:59,120 --> 00:03:03,040
security threats

70
00:03:01,360 --> 00:03:05,519
so the one related to requirements

71
00:03:03,040 --> 00:03:07,280
engineering is the thing related to

72
00:03:05,519 --> 00:03:09,440
when people ask what's your threat model

73
00:03:07,280 --> 00:03:13,040
right what are your security assumptions

74
00:03:09,440 --> 00:03:16,239
and to give you one example

75
00:03:13,040 --> 00:03:16,640
this is a paper a classic paper by dolov

76
00:03:16,239 --> 00:03:20,319
and

77
00:03:16,640 --> 00:03:23,200
yao and the model that they they propose

78
00:03:20,319 --> 00:03:24,879
is the following they assume about a

79
00:03:23,200 --> 00:03:27,679
saboteur or an attacker

80
00:03:24,879 --> 00:03:29,280
that the attacker can obtain any message

81
00:03:27,680 --> 00:03:30,239
initiate any conversation and be a

82
00:03:29,280 --> 00:03:34,480
receiver

83
00:03:30,239 --> 00:03:36,720
to any user for any message now

84
00:03:34,480 --> 00:03:38,319
this is a threat model which assumes an

85
00:03:36,720 --> 00:03:41,519
omnipotent attacker

86
00:03:38,319 --> 00:03:46,000
right who can listen on listen uh on the

87
00:03:41,519 --> 00:03:49,280
ether to any uh message now

88
00:03:46,000 --> 00:03:52,319
this mess this image should be familiar

89
00:03:49,280 --> 00:03:56,799
to you right this is the model of

90
00:03:52,319 --> 00:03:59,679
the nsa intercepting any communication

91
00:03:56,799 --> 00:04:00,000
and also injecting any communication the

92
00:03:59,680 --> 00:04:02,799
other

93
00:04:00,000 --> 00:04:03,439
approach of architectural analysis can

94
00:04:02,799 --> 00:04:06,879
take place

95
00:04:03,439 --> 00:04:08,319
later in the um so so during design or

96
00:04:06,879 --> 00:04:11,040
actually

97
00:04:08,319 --> 00:04:12,000
once a design has been built analyzing

98
00:04:11,040 --> 00:04:15,280
whether

99
00:04:12,000 --> 00:04:16,639
there are any possible problems

100
00:04:15,280 --> 00:04:18,320
and the question that we then ask

101
00:04:16,639 --> 00:04:21,680
ourselves is

102
00:04:18,320 --> 00:04:23,919
what could possibly go wrong

103
00:04:21,680 --> 00:04:24,960
and this is by by asking ourselves this

104
00:04:23,919 --> 00:04:27,120
question we can

105
00:04:24,960 --> 00:04:28,638
before we write a single line of code we

106
00:04:27,120 --> 00:04:31,600
can really start thinking through

107
00:04:28,639 --> 00:04:32,960
possible security problems and we can

108
00:04:31,600 --> 00:04:36,560
also think of like how

109
00:04:32,960 --> 00:04:38,638
might it then go wrong there's different

110
00:04:36,560 --> 00:04:41,280
types of threat models at least

111
00:04:38,639 --> 00:04:44,479
different three different classes

112
00:04:41,280 --> 00:04:45,840
the ones that focus more on

113
00:04:44,479 --> 00:04:48,479
looking at the different types of

114
00:04:45,840 --> 00:04:50,880
attackers and their capabilities

115
00:04:48,479 --> 00:04:52,320
once looking more at which assets are

116
00:04:50,880 --> 00:04:54,560
important to protect

117
00:04:52,320 --> 00:04:56,320
and methods looking at what is the

118
00:04:54,560 --> 00:04:59,600
structure of our system

119
00:04:56,320 --> 00:05:00,639
and sketching that out so for the

120
00:04:59,600 --> 00:05:04,000
attacker-centric

121
00:05:00,639 --> 00:05:06,160
approach uh we want to look at

122
00:05:04,000 --> 00:05:09,039
who are our attackers when we look at

123
00:05:06,160 --> 00:05:12,479
their methodologies their motivations

124
00:05:09,039 --> 00:05:15,919
and one approach to map out

125
00:05:12,479 --> 00:05:18,880
um like to take an attacker

126
00:05:15,919 --> 00:05:20,320
perspective when threat modeling is kill

127
00:05:18,880 --> 00:05:23,680
chains

128
00:05:20,320 --> 00:05:28,240
and this is an example of

129
00:05:23,680 --> 00:05:28,240
one like a general kill chain

130
00:05:28,400 --> 00:05:33,520
model right it it models how can an

131
00:05:31,440 --> 00:05:37,360
attacker get initial access

132
00:05:33,520 --> 00:05:41,280
uh how can they go through the network

133
00:05:37,360 --> 00:05:43,840
and what can they like what are their

134
00:05:41,280 --> 00:05:44,719
objectives another approach is looking

135
00:05:43,840 --> 00:05:46,799
at our assets

136
00:05:44,720 --> 00:05:48,880
specifically the key assets what do we

137
00:05:46,800 --> 00:05:52,000
really want to protect

138
00:05:48,880 --> 00:05:54,240
and one approach there is to for example

139
00:05:52,000 --> 00:05:55,280
sketch an access control matrix and

140
00:05:54,240 --> 00:05:57,120
looking at what are

141
00:05:55,280 --> 00:05:59,359
assets what are the different actors

142
00:05:57,120 --> 00:06:02,560
within

143
00:05:59,360 --> 00:06:06,000
our system and what are the possible

144
00:06:02,560 --> 00:06:09,199
missions now the approach that i'll look

145
00:06:06,000 --> 00:06:10,319
at in more detail are uh is the

146
00:06:09,199 --> 00:06:13,120
system-centric

147
00:06:10,319 --> 00:06:13,520
approach yeah what we do what we do

148
00:06:13,120 --> 00:06:16,720
there

149
00:06:13,520 --> 00:06:17,840
is we sketch an approach to threat

150
00:06:16,720 --> 00:06:21,280
modeling

151
00:06:17,840 --> 00:06:24,799
sorry which like a

152
00:06:21,280 --> 00:06:28,080
so so we sketch a view of the system

153
00:06:24,800 --> 00:06:31,280
and this view it can take can

154
00:06:28,080 --> 00:06:31,919
take different forms but so this is what

155
00:06:31,280 --> 00:06:35,919
we'll look at

156
00:06:31,919 --> 00:06:38,639
in more detail some approaches that

157
00:06:35,919 --> 00:06:40,000
some specific system-centric threat

158
00:06:38,639 --> 00:06:43,680
modeling approaches

159
00:06:40,000 --> 00:06:47,199
are stride trike and

160
00:06:43,680 --> 00:06:48,080
pasta now the one we'll look at in more

161
00:06:47,199 --> 00:06:52,400
detail

162
00:06:48,080 --> 00:06:55,280
is the stride approach

163
00:06:52,400 --> 00:06:56,239
and four questions can guide us when

164
00:06:55,280 --> 00:06:59,520
we're doing

165
00:06:56,240 --> 00:06:59,919
system-centric threat modeling and these

166
00:06:59,520 --> 00:07:03,758
are

167
00:06:59,919 --> 00:07:06,159
the the phases that we can go through

168
00:07:03,759 --> 00:07:08,000
when we're carrying out a threat model

169
00:07:06,160 --> 00:07:10,960
or an architectural

170
00:07:08,000 --> 00:07:11,520
risk assessments firstly what's our

171
00:07:10,960 --> 00:07:14,000
system

172
00:07:11,520 --> 00:07:16,080
right we want we want to get an idea of

173
00:07:14,000 --> 00:07:18,479
what we're actually analyzing

174
00:07:16,080 --> 00:07:19,758
then what can go wrong right what are

175
00:07:18,479 --> 00:07:23,199
what are possible

176
00:07:19,759 --> 00:07:24,479
um problems within that system that

177
00:07:23,199 --> 00:07:27,039
we've sketched

178
00:07:24,479 --> 00:07:28,800
then once we have a good view of that

179
00:07:27,039 --> 00:07:30,159
what are we what are possible security

180
00:07:28,800 --> 00:07:32,560
controls right what can

181
00:07:30,160 --> 00:07:33,520
what can we actually do about it and

182
00:07:32,560 --> 00:07:36,400
finally

183
00:07:33,520 --> 00:07:38,719
looking back have we done the right

184
00:07:36,400 --> 00:07:38,719
things

185
00:07:39,360 --> 00:07:42,800
so a lightweight methodology that you

186
00:07:41,759 --> 00:07:46,639
can apply

187
00:07:42,800 --> 00:07:49,599
going through these four steps i'll

188
00:07:46,639 --> 00:07:50,560
um i'll walk you through the the one at

189
00:07:49,599 --> 00:07:53,680
a time

190
00:07:50,560 --> 00:07:56,840
firstly data flow diagrams i

191
00:07:53,680 --> 00:07:58,000
die so sketching data flows within a

192
00:07:56,840 --> 00:07:59,280
system

193
00:07:58,000 --> 00:08:01,280
uh there are of course many different

194
00:07:59,280 --> 00:08:03,198
ways to sketch a system but data flow

195
00:08:01,280 --> 00:08:06,719
diagrams tend to be the one

196
00:08:03,199 --> 00:08:07,680
used when threat modeling suppose this

197
00:08:06,720 --> 00:08:10,720
is our

198
00:08:07,680 --> 00:08:11,280
our system right a a general sketch of

199
00:08:10,720 --> 00:08:14,960
the

200
00:08:11,280 --> 00:08:18,479
headquarters of a an anonymous

201
00:08:14,960 --> 00:08:20,318
organization now

202
00:08:18,479 --> 00:08:22,560
there's many different types of threats

203
00:08:20,319 --> 00:08:25,120
here someone can can break in

204
00:08:22,560 --> 00:08:26,000
steal a server but what we're interested

205
00:08:25,120 --> 00:08:29,520
in

206
00:08:26,000 --> 00:08:33,279
from a software perspective are is the

207
00:08:29,520 --> 00:08:34,718
the bottom part of so so all the things

208
00:08:33,279 --> 00:08:39,200
related to

209
00:08:34,719 --> 00:08:39,200
like web server firewall etc

210
00:08:39,599 --> 00:08:44,640
now what we can what we can do is we can

211
00:08:43,599 --> 00:08:46,880
abstract away

212
00:08:44,640 --> 00:08:48,640
from like this radiant abstraction but

213
00:08:46,880 --> 00:08:52,000
we can further abstract that

214
00:08:48,640 --> 00:08:55,680
um to focus on uh so the

215
00:08:52,000 --> 00:08:56,720
data flow diagrams and these have a

216
00:08:55,680 --> 00:08:59,920
standard

217
00:08:56,720 --> 00:09:03,440
so these allow us to sketch

218
00:08:59,920 --> 00:09:04,319
data at rest data in motion or data

219
00:09:03,440 --> 00:09:06,880
being

220
00:09:04,320 --> 00:09:06,880
processed

221
00:09:07,600 --> 00:09:12,000
so besides so this is one uh one data

222
00:09:10,959 --> 00:09:15,599
flow diagram

223
00:09:12,000 --> 00:09:19,839
we can also diagram different

224
00:09:15,600 --> 00:09:22,720
levels of the system starting from

225
00:09:19,839 --> 00:09:23,680
our context diagram who are our external

226
00:09:22,720 --> 00:09:25,519
entities

227
00:09:23,680 --> 00:09:27,680
going through and then going in more

228
00:09:25,519 --> 00:09:28,640
more detail and especially we can also

229
00:09:27,680 --> 00:09:33,199
look at

230
00:09:28,640 --> 00:09:37,839
um for in this case this is a

231
00:09:33,200 --> 00:09:37,839
web application and we

232
00:09:38,480 --> 00:09:43,920
we've deconstructed that into the login

233
00:09:41,360 --> 00:09:46,160
process and the authenticated operations

234
00:09:43,920 --> 00:09:48,399
and then we can if we want to analyze

235
00:09:46,160 --> 00:09:50,959
the login process in more detail

236
00:09:48,399 --> 00:09:52,240
then we can we can do so and draw more

237
00:09:50,959 --> 00:09:56,319
data flow diagrams

238
00:09:52,240 --> 00:09:59,360
of that now these data flow diagrams

239
00:09:56,320 --> 00:10:02,160
uh we can also label the data flows with

240
00:09:59,360 --> 00:10:03,040
how data gets transferred from point a

241
00:10:02,160 --> 00:10:06,079
to point b

242
00:10:03,040 --> 00:10:08,079
right over what protocol and what type

243
00:10:06,079 --> 00:10:11,359
of data is being transferred

244
00:10:08,079 --> 00:10:14,959
now once we have this picture

245
00:10:11,360 --> 00:10:18,160
of our system this this abstraction we

246
00:10:14,959 --> 00:10:19,119
can think through we can we can work on

247
00:10:18,160 --> 00:10:21,279
our next step

248
00:10:19,120 --> 00:10:22,320
which is to think through the possible

249
00:10:21,279 --> 00:10:24,959
problems

250
00:10:22,320 --> 00:10:25,440
that can happen and this is also called

251
00:10:24,959 --> 00:10:28,800
threat

252
00:10:25,440 --> 00:10:32,560
elicitation so

253
00:10:28,800 --> 00:10:35,839
to take one step back if we look at

254
00:10:32,560 --> 00:10:37,760
security then there there tends to be uh

255
00:10:35,839 --> 00:10:39,519
three goals that we want to achieve

256
00:10:37,760 --> 00:10:41,200
confidentiality confidentiality

257
00:10:39,519 --> 00:10:44,880
integrity and availability

258
00:10:41,200 --> 00:10:46,800
of information and we usually do that

259
00:10:44,880 --> 00:10:48,800
through applying authentication

260
00:10:46,800 --> 00:10:52,160
authorization and accountability

261
00:10:48,800 --> 00:10:54,160
controls so

262
00:10:52,160 --> 00:10:55,839
if we were if we then want to think of

263
00:10:54,160 --> 00:10:59,439
what can possibly go wrong

264
00:10:55,839 --> 00:11:02,560
we can invert these we can

265
00:10:59,440 --> 00:11:06,880
so to harm or to

266
00:11:02,560 --> 00:11:10,239
to affect the confidentiality of

267
00:11:06,880 --> 00:11:12,839
uh information within our system we can

268
00:11:10,240 --> 00:11:14,959
perform attacks related to information

269
00:11:12,839 --> 00:11:20,000
disclosure

270
00:11:14,959 --> 00:11:23,279
to harm integrity of data we can tamper

271
00:11:20,000 --> 00:11:27,040
information so for each of these

272
00:11:23,279 --> 00:11:30,560
six uh classes of of these of these

273
00:11:27,040 --> 00:11:34,800
six goals that we have we have a

274
00:11:30,560 --> 00:11:34,800
class of threats now

275
00:11:35,040 --> 00:11:40,880
if we take the first letter of each of

276
00:11:37,680 --> 00:11:43,599
these six then we get the acronym stride

277
00:11:40,880 --> 00:11:45,279
spoofing tampering repudiation

278
00:11:43,600 --> 00:11:46,800
information disclosure denial of service

279
00:11:45,279 --> 00:11:50,320
an elevation of privilege

280
00:11:46,800 --> 00:11:53,760
threats so what we do

281
00:11:50,320 --> 00:11:57,200
is for each element of our diagram

282
00:11:53,760 --> 00:11:58,560
we can identify whether there's threats

283
00:11:57,200 --> 00:12:03,680
related to

284
00:11:58,560 --> 00:12:06,800
one of the stride classes

285
00:12:03,680 --> 00:12:10,719
so here's an example here we see

286
00:12:06,800 --> 00:12:14,800
that the browser client might be spoofed

287
00:12:10,720 --> 00:12:17,279
so someone can impersonate

288
00:12:14,800 --> 00:12:20,240
someone else and also the same goes for

289
00:12:17,279 --> 00:12:20,240
the web application

290
00:12:20,720 --> 00:12:25,760
now here we have a sketch of

291
00:12:23,760 --> 00:12:27,439
the architecture of the swiss the the

292
00:12:25,760 --> 00:12:30,560
swift payment network

293
00:12:27,440 --> 00:12:34,240
and we can already see

294
00:12:30,560 --> 00:12:36,399
what for example in the

295
00:12:34,240 --> 00:12:37,920
bank of bangladesh i think it was what

296
00:12:36,399 --> 00:12:40,720
went wrong there

297
00:12:37,920 --> 00:12:41,680
we can we see that the end user the end

298
00:12:40,720 --> 00:12:43,760
user computer

299
00:12:41,680 --> 00:12:45,279
is connected to the internet and also

300
00:12:43,760 --> 00:12:48,399
connected to internal

301
00:12:45,279 --> 00:12:50,240
swift the internal swift network so we

302
00:12:48,399 --> 00:12:52,160
can by brainstorming by eliciting

303
00:12:50,240 --> 00:12:55,680
threats we can already identify

304
00:12:52,160 --> 00:12:59,040
possible problems we can

305
00:12:55,680 --> 00:13:02,399
the end user computer might be exploited

306
00:12:59,040 --> 00:13:04,880
through an elevation of privilege attack

307
00:13:02,399 --> 00:13:07,680
here's another example this is a

308
00:13:04,880 --> 00:13:10,720
one-time token authentication

309
00:13:07,680 --> 00:13:14,000
solution and by going through

310
00:13:10,720 --> 00:13:14,800
so by sketching this representation of

311
00:13:14,000 --> 00:13:17,440
the system

312
00:13:14,800 --> 00:13:18,079
and by going through every so by going

313
00:13:17,440 --> 00:13:20,480
through the

314
00:13:18,079 --> 00:13:21,439
s for spoofing or is there a possible is

315
00:13:20,480 --> 00:13:25,279
there spoofing

316
00:13:21,440 --> 00:13:28,320
uh possible anywhere well um

317
00:13:25,279 --> 00:13:32,000
we could we could think of can

318
00:13:28,320 --> 00:13:33,680
can someone uh so spoofing

319
00:13:32,000 --> 00:13:35,680
we go we go through all the elements and

320
00:13:33,680 --> 00:13:38,800
think of all is is this threat

321
00:13:35,680 --> 00:13:40,959
possible for example uh

322
00:13:38,800 --> 00:13:42,319
information disclosure is information

323
00:13:40,959 --> 00:13:45,359
disclosure possible well

324
00:13:42,320 --> 00:13:46,880
we could we could think of

325
00:13:45,360 --> 00:13:49,199
the one-time token that's being

326
00:13:46,880 --> 00:13:50,560
transmitted but what are all the places

327
00:13:49,199 --> 00:13:53,839
where we can intercept

328
00:13:50,560 --> 00:13:57,119
that token now once we've done

329
00:13:53,839 --> 00:13:57,120
we've got a whole bunch of

330
00:13:57,279 --> 00:14:02,880
of threats we can think of

331
00:14:00,320 --> 00:14:04,399
ranking them we can think of what are

332
00:14:02,880 --> 00:14:07,360
what are the relevant

333
00:14:04,399 --> 00:14:07,760
and the less relevant threats to address

334
00:14:07,360 --> 00:14:09,519
so

335
00:14:07,760 --> 00:14:10,800
how how do we actually rank these

336
00:14:09,519 --> 00:14:12,959
threats right we've got a whole

337
00:14:10,800 --> 00:14:14,479
a whole bunch of threats and which which

338
00:14:12,959 --> 00:14:15,040
are the most important which are less

339
00:14:14,480 --> 00:14:16,720
important

340
00:14:15,040 --> 00:14:18,639
what's our what's for example our top

341
00:14:16,720 --> 00:14:21,600
three

342
00:14:18,639 --> 00:14:23,040
now the answer to that is looking at

343
00:14:21,600 --> 00:14:27,760
risk

344
00:14:23,040 --> 00:14:30,000
not not this risk but the risk

345
00:14:27,760 --> 00:14:32,639
concepts being the combination of

346
00:14:30,000 --> 00:14:37,600
likelihood and impact

347
00:14:32,639 --> 00:14:37,600
and one approach can be

348
00:14:37,839 --> 00:14:44,399
mapping risk from so having

349
00:14:41,600 --> 00:14:45,519
the possible to the likelihood or the

350
00:14:44,399 --> 00:14:48,880
estimated time

351
00:14:45,519 --> 00:14:52,079
until a threat

352
00:14:48,880 --> 00:14:55,199
actually impacts the system and then the

353
00:14:52,079 --> 00:14:57,359
amount of impacts you can imagine that

354
00:14:55,199 --> 00:14:58,959
we want to focus our attention on the

355
00:14:57,360 --> 00:15:02,720
threats that are

356
00:14:58,959 --> 00:15:05,839
likely to happen to occur often so

357
00:15:02,720 --> 00:15:13,120
soon and also on those that

358
00:15:05,839 --> 00:15:15,920
have a big impact on our system

359
00:15:13,120 --> 00:15:16,399
another approach besides that can help

360
00:15:15,920 --> 00:15:19,439
us

361
00:15:16,399 --> 00:15:22,399
with prioritizing threats is

362
00:15:19,440 --> 00:15:24,639
so decision trees this is an example for

363
00:15:22,399 --> 00:15:27,440
an elevation of privilege

364
00:15:24,639 --> 00:15:28,160
related threats we can identify does it

365
00:15:27,440 --> 00:15:31,519
impact

366
00:15:28,160 --> 00:15:32,880
the server or the client um is it local

367
00:15:31,519 --> 00:15:34,480
or remote

368
00:15:32,880 --> 00:15:36,320
to what extent do users need to

369
00:15:34,480 --> 00:15:36,880
authenticate or not right this can help

370
00:15:36,320 --> 00:15:42,240
us

371
00:15:36,880 --> 00:15:45,920
in in in in our prioritization

372
00:15:42,240 --> 00:15:46,800
lastly so once we've once we've sketched

373
00:15:45,920 --> 00:15:48,880
our system

374
00:15:46,800 --> 00:15:49,920
once we've elicited threats through

375
00:15:48,880 --> 00:15:52,639
applying stride

376
00:15:49,920 --> 00:15:54,880
it once we've ranked these threats to

377
00:15:52,639 --> 00:15:56,800
identify the most important ones

378
00:15:54,880 --> 00:15:58,320
we need to know have we done the right

379
00:15:56,800 --> 00:16:01,439
thing

380
00:15:58,320 --> 00:16:03,120
of course as george box

381
00:16:01,440 --> 00:16:05,279
states all models are wrong and some

382
00:16:03,120 --> 00:16:05,600
models are useful so we could say like

383
00:16:05,279 --> 00:16:07,680
well

384
00:16:05,600 --> 00:16:10,160
at least if the model is useful to us

385
00:16:07,680 --> 00:16:13,279
then why why check whether it's correct

386
00:16:10,160 --> 00:16:13,920
and if they're all wrong then yeah why

387
00:16:13,279 --> 00:16:16,959
do this

388
00:16:13,920 --> 00:16:18,479
well some models are more useful than

389
00:16:16,959 --> 00:16:19,920
others so if we can improve that

390
00:16:18,480 --> 00:16:23,440
usefulness that's

391
00:16:19,920 --> 00:16:25,120
handy one way to check whether our model

392
00:16:23,440 --> 00:16:28,320
is correct

393
00:16:25,120 --> 00:16:30,800
is to check whether the higher level

394
00:16:28,320 --> 00:16:32,639
data flow diagrams

395
00:16:30,800 --> 00:16:34,719
whether they are matched to the lower

396
00:16:32,639 --> 00:16:36,720
level ones i do

397
00:16:34,720 --> 00:16:38,399
do data flows that occur in our context

398
00:16:36,720 --> 00:16:42,240
diagram do they also occur

399
00:16:38,399 --> 00:16:46,480
in the the level 0 and the level 1

400
00:16:42,240 --> 00:16:50,240
data flow diagrams another approach

401
00:16:46,480 --> 00:16:51,839
is to check have we do we have all

402
00:16:50,240 --> 00:16:54,160
have we covered our complete attack

403
00:16:51,839 --> 00:16:57,600
surface right have we looked at all the

404
00:16:54,160 --> 00:16:59,680
different ways of accessing our system

405
00:16:57,600 --> 00:17:00,959
because they those data flows should be

406
00:16:59,680 --> 00:17:04,720
present in our

407
00:17:00,959 --> 00:17:05,119
threat model of course we can also make

408
00:17:04,720 --> 00:17:08,319
use

409
00:17:05,119 --> 00:17:12,639
of cans lists of

410
00:17:08,319 --> 00:17:13,359
top 10 possible vulnerabilities see if

411
00:17:12,640 --> 00:17:17,839
we have

412
00:17:13,359 --> 00:17:20,879
we have those included in our analysis

413
00:17:17,839 --> 00:17:23,599
what can also help is uh threat trees

414
00:17:20,880 --> 00:17:24,799
or actually stretchy templates this is

415
00:17:23,599 --> 00:17:26,639
an example for

416
00:17:24,799 --> 00:17:27,839
the denial of service attack against a

417
00:17:26,640 --> 00:17:30,000
data flow

418
00:17:27,839 --> 00:17:32,080
we can check if we thought about for

419
00:17:30,000 --> 00:17:33,919
example

420
00:17:32,080 --> 00:17:36,080
corrupting the message we can think

421
00:17:33,919 --> 00:17:40,480
about whether

422
00:17:36,080 --> 00:17:40,480
we thought about for example

423
00:17:40,880 --> 00:17:45,840
making the channel so

424
00:17:44,320 --> 00:17:47,840
incapacitating the channel right so we

425
00:17:45,840 --> 00:17:51,439
can we can check if we've

426
00:17:47,840 --> 00:17:54,399
we've covered all these threats and

427
00:17:51,440 --> 00:17:55,919
of course this checking whether we've

428
00:17:54,400 --> 00:17:57,919
done a good job that doesn't

429
00:17:55,919 --> 00:18:00,000
that doesn't end once you've done threat

430
00:17:57,919 --> 00:18:02,799
modeling once

431
00:18:00,000 --> 00:18:03,600
systems they change so we also need to

432
00:18:02,799 --> 00:18:05,679
keep

433
00:18:03,600 --> 00:18:07,039
thinking if we need to keep checking if

434
00:18:05,679 --> 00:18:11,039
our

435
00:18:07,039 --> 00:18:13,360
threat models are still up to date

436
00:18:11,039 --> 00:18:15,360
so that's a lightweight methodology for

437
00:18:13,360 --> 00:18:17,760
threat modeling a lightweight approach

438
00:18:15,360 --> 00:18:19,360
for looking at for going through the

439
00:18:17,760 --> 00:18:23,360
architecture of a system

440
00:18:19,360 --> 00:18:23,360
and thinking through possible problems

441
00:18:24,640 --> 00:18:27,760
one thing that's very important when

442
00:18:26,320 --> 00:18:28,480
when threat modeling is to do that with

443
00:18:27,760 --> 00:18:31,840
a team

444
00:18:28,480 --> 00:18:35,039
to involve not just developers

445
00:18:31,840 --> 00:18:38,720
but also uh also users or or

446
00:18:35,039 --> 00:18:42,960
proxies for for users and to to

447
00:18:38,720 --> 00:18:45,280
to take different perspectives and

448
00:18:42,960 --> 00:18:46,799
to to do that what what helps what

449
00:18:45,280 --> 00:18:48,720
really helps is to

450
00:18:46,799 --> 00:18:50,799
do this on paper do this collaboratively

451
00:18:48,720 --> 00:18:54,160
do it on a whiteboard

452
00:18:50,799 --> 00:18:57,520
for example this is the

453
00:18:54,160 --> 00:19:01,280
the vulnerable application g-shock

454
00:18:57,520 --> 00:19:02,000
and this is the a quite high-level data

455
00:19:01,280 --> 00:19:04,799
flow

456
00:19:02,000 --> 00:19:06,640
diagram for g-shock so we can we can

457
00:19:04,799 --> 00:19:07,520
sketch this on a white board relatively

458
00:19:06,640 --> 00:19:11,440
easily just

459
00:19:07,520 --> 00:19:14,559
with with markers and we can then

460
00:19:11,440 --> 00:19:16,880
with post-its identify where are our key

461
00:19:14,559 --> 00:19:19,840
assets

462
00:19:16,880 --> 00:19:21,440
right so personally identifiable

463
00:19:19,840 --> 00:19:23,199
information might be stored in the sql

464
00:19:21,440 --> 00:19:26,720
database

465
00:19:23,200 --> 00:19:28,720
there's money um involved with

466
00:19:26,720 --> 00:19:29,760
the whole payment service and then we

467
00:19:28,720 --> 00:19:31,520
can think through

468
00:19:29,760 --> 00:19:33,120
on different post-its what might be

469
00:19:31,520 --> 00:19:35,200
possible

470
00:19:33,120 --> 00:19:36,719
uh protections right what might be

471
00:19:35,200 --> 00:19:41,039
possible controls

472
00:19:36,720 --> 00:19:41,039
so you could think of um

473
00:19:42,160 --> 00:19:45,440
oh sorry like what what what are

474
00:19:43,440 --> 00:19:47,039
possible threats and then we can think

475
00:19:45,440 --> 00:19:50,000
of possible controls

476
00:19:47,039 --> 00:19:50,799
um against those threats and this is

477
00:19:50,000 --> 00:19:53,840
what it

478
00:19:50,799 --> 00:19:53,840
tends to look like

479
00:19:54,480 --> 00:19:57,600
and the idea is that especially by by

480
00:19:56,320 --> 00:20:01,840
doing this early

481
00:19:57,600 --> 00:20:01,840
by doing this collaboratively you can

482
00:20:02,240 --> 00:20:06,400
address security early on in the

483
00:20:03,840 --> 00:20:08,000
development life cycle

484
00:20:06,400 --> 00:20:11,360
of course threat modelling is not

485
00:20:08,000 --> 00:20:14,320
everything there is there's many other

486
00:20:11,360 --> 00:20:16,479
aspects to address right there's many

487
00:20:14,320 --> 00:20:19,760
different activities within

488
00:20:16,480 --> 00:20:22,159
the security development life cycle and

489
00:20:19,760 --> 00:20:23,039
whatever you might think of microsoft

490
00:20:22,159 --> 00:20:25,200
they do have

491
00:20:23,039 --> 00:20:26,480
a quite nice book that they've made

492
00:20:25,200 --> 00:20:29,520
freely available

493
00:20:26,480 --> 00:20:31,600
it's it is from 2006 but the sections on

494
00:20:29,520 --> 00:20:34,879
threat modeling are still

495
00:20:31,600 --> 00:20:36,559
relevant and an interesting exercise

496
00:20:34,880 --> 00:20:40,000
that i'd recommend

497
00:20:36,559 --> 00:20:43,520
those interested to do is to take

498
00:20:40,000 --> 00:20:45,520
any iot application and to think through

499
00:20:43,520 --> 00:20:46,639
the possible threats to that iot

500
00:20:45,520 --> 00:20:49,520
application

501
00:20:46,640 --> 00:20:50,240
one example being a smart washing

502
00:20:49,520 --> 00:20:53,200
machine

503
00:20:50,240 --> 00:20:54,080
connected to the cloud connected to a

504
00:20:53,200 --> 00:20:57,760
smartphone

505
00:20:54,080 --> 00:20:59,360
like ask yourself the question what

506
00:20:57,760 --> 00:21:02,480
could possibly go wrong

507
00:20:59,360 --> 00:21:03,840
right and and try to apply this also to

508
00:21:02,480 --> 00:21:07,200
your own

509
00:21:03,840 --> 00:21:07,199
development process

510
00:21:07,360 --> 00:21:17,840
thank you

511
00:21:26,080 --> 00:21:32,000
the question was where do you start

512
00:21:29,280 --> 00:21:34,320
so that's a broad question but generally

513
00:21:32,000 --> 00:21:37,360
you start you start at the beginning and

514
00:21:34,320 --> 00:21:39,840
uh the idea is you you start sketching

515
00:21:37,360 --> 00:21:40,719
sketching the the application from the

516
00:21:39,840 --> 00:21:43,120
perspective of

517
00:21:40,720 --> 00:21:44,320
who interfaces with the application

518
00:21:43,120 --> 00:21:45,918
right so you start sketching your

519
00:21:44,320 --> 00:21:48,720
context diagram

520
00:21:45,919 --> 00:21:50,320
um and from there you think what are the

521
00:21:48,720 --> 00:21:52,559
possible

522
00:21:50,320 --> 00:21:54,480
uh yeah possible things that can go

523
00:21:52,559 --> 00:21:56,240
wrong sorry

524
00:21:54,480 --> 00:21:58,799
top down yeah generally so so yeah

525
00:21:56,240 --> 00:22:02,480
generally top down but you can also

526
00:21:58,799 --> 00:22:02,799
um you can start from you can also start

527
00:22:02,480 --> 00:22:05,760
with

528
00:22:02,799 --> 00:22:07,039
with like subsystems and then you can

529
00:22:05,760 --> 00:22:13,840
combine the threat models of the

530
00:22:07,039 --> 00:22:15,919
different subsystems

531
00:22:13,840 --> 00:22:15,918
you

