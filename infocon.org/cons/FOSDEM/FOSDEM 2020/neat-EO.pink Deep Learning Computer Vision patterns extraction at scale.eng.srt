1
00:00:05,279 --> 00:00:08,879
so

2
00:00:05,839 --> 00:00:10,160
olivier cortan i'm working in js field

3
00:00:08,880 --> 00:00:15,120
since years

4
00:00:10,160 --> 00:00:18,560
and i founded the tapping company

5
00:00:15,120 --> 00:00:21,119
and one of our main focus

6
00:00:18,560 --> 00:00:21,119
is to

7
00:00:21,760 --> 00:00:28,160
build bridge between gis

8
00:00:24,880 --> 00:00:30,880
fields and deep learning stuff so how

9
00:00:28,160 --> 00:00:32,238
are we able to extract insight from just

10
00:00:30,880 --> 00:00:35,120
pastel data

11
00:00:32,238 --> 00:00:37,280
through the latest available tool that

12
00:00:35,120 --> 00:00:40,000
we have we already knew

13
00:00:37,280 --> 00:00:40,879
how to do it with special analysis in a

14
00:00:40,000 --> 00:00:44,000
classical way

15
00:00:40,879 --> 00:00:46,800
but what can we extend with new tools

16
00:00:44,000 --> 00:00:49,039
to go further that's it and so this

17
00:00:46,800 --> 00:00:52,160
presentation is about a computer vision

18
00:00:49,039 --> 00:00:55,760
tool able to extract information from

19
00:00:52,160 --> 00:00:55,760
imagery that's it

20
00:00:56,640 --> 00:01:04,319
that was my one minute presentation so

21
00:01:00,480 --> 00:01:07,600
the um the framework is called

22
00:01:04,319 --> 00:01:09,919
net eo the pink and uh if we

23
00:01:07,600 --> 00:01:11,360
go back to the story everything begins

24
00:01:09,920 --> 00:01:15,200
with a loop

25
00:01:11,360 --> 00:01:18,880
so it's a vinyl loop a one century ago

26
00:01:15,200 --> 00:01:20,960
and the point is to say that

27
00:01:18,880 --> 00:01:24,399
you have to understand what is wrong

28
00:01:20,960 --> 00:01:24,399
before to be able to fix it

29
00:01:24,479 --> 00:01:30,158
and you loop again and again

30
00:01:28,159 --> 00:01:31,600
but since you are not able to understand

31
00:01:30,159 --> 00:01:34,320
what is wrong

32
00:01:31,600 --> 00:01:35,119
there's nothing to do about so if we

33
00:01:34,320 --> 00:01:39,119
look about the

34
00:01:35,119 --> 00:01:41,680
association nowadays it's widely used

35
00:01:39,119 --> 00:01:42,640
there is a vast amount of information

36
00:01:41,680 --> 00:01:46,479
available

37
00:01:42,640 --> 00:01:48,960
but we are unable to use it really

38
00:01:46,479 --> 00:01:50,479
and most of the pixel acquired we don't

39
00:01:48,960 --> 00:01:54,240
do anything with them

40
00:01:50,479 --> 00:01:56,799
it's a waste so the id

41
00:01:54,240 --> 00:01:57,280
the need is to say okay we are able to

42
00:01:56,799 --> 00:02:00,159
gather

43
00:01:57,280 --> 00:02:01,280
pixels but what can we do with this

44
00:02:00,159 --> 00:02:04,000
pixel

45
00:02:01,280 --> 00:02:05,119
to um to be able to switch from pixel to

46
00:02:04,000 --> 00:02:07,759
insights

47
00:02:05,119 --> 00:02:09,440
that's the key point if we look about

48
00:02:07,759 --> 00:02:11,760
the deep learning stuff

49
00:02:09,440 --> 00:02:13,120
supervised learning is quite simple you

50
00:02:11,760 --> 00:02:16,239
have one input

51
00:02:13,120 --> 00:02:17,599
one expected output and you train a

52
00:02:16,239 --> 00:02:21,040
neural network till

53
00:02:17,599 --> 00:02:22,000
is able to compute the output from the

54
00:02:21,040 --> 00:02:25,040
input

55
00:02:22,000 --> 00:02:26,800
and the key point is a loss function

56
00:02:25,040 --> 00:02:28,400
the loss function is the ability to

57
00:02:26,800 --> 00:02:31,680
compute the distance

58
00:02:28,400 --> 00:02:34,800
between what he performed

59
00:02:31,680 --> 00:02:38,480
and what it expected since

60
00:02:34,800 --> 00:02:41,920
you are able to compute a meaningful

61
00:02:38,480 --> 00:02:44,399
distance function you are then able to

62
00:02:41,920 --> 00:02:45,839
find a way to convert to a solution okay

63
00:02:44,400 --> 00:02:48,000
so i think you train

64
00:02:45,840 --> 00:02:49,680
a model rightly you're able only with

65
00:02:48,000 --> 00:02:52,400
the input

66
00:02:49,680 --> 00:02:53,120
to use your train model to compute an

67
00:02:52,400 --> 00:02:56,879
output

68
00:02:53,120 --> 00:03:00,000
that's it okay so it's

69
00:02:56,879 --> 00:03:01,599
only a way to train a model so what is

70
00:03:00,000 --> 00:03:03,760
really a trained model there are several

71
00:03:01,599 --> 00:03:05,518
ways to understand it

72
00:03:03,760 --> 00:03:07,120
we will focus only on one because it's a

73
00:03:05,519 --> 00:03:10,159
simple one to understand

74
00:03:07,120 --> 00:03:12,239
it's a compression you only compress

75
00:03:10,159 --> 00:03:15,120
your information

76
00:03:12,239 --> 00:03:15,680
the wool imagery information and you

77
00:03:15,120 --> 00:03:18,720
accept

78
00:03:15,680 --> 00:03:21,760
to lose a lot of information but

79
00:03:18,720 --> 00:03:22,800
you keep all the information you need to

80
00:03:21,760 --> 00:03:26,399
achieve your task

81
00:03:22,800 --> 00:03:29,200
so it just directed

82
00:03:26,400 --> 00:03:29,519
comprehension stuff to lose information

83
00:03:29,200 --> 00:03:31,200
but

84
00:03:29,519 --> 00:03:34,560
the one you have to to keep for the

85
00:03:31,200 --> 00:03:36,959
classification so also you understand it

86
00:03:34,560 --> 00:03:39,440
net you that pink is just a way to build

87
00:03:36,959 --> 00:03:44,640
a bridge between your special data

88
00:03:39,440 --> 00:03:44,640
and deep learning stuff there is a three

89
00:03:45,040 --> 00:03:48,560
task we are focused on first is called

90
00:03:47,200 --> 00:03:51,599
detail analysis

91
00:03:48,560 --> 00:03:54,480
so once you train your data and you

92
00:03:51,599 --> 00:03:55,359
are able to compute an output you will

93
00:03:54,480 --> 00:03:57,840
be able

94
00:03:55,360 --> 00:03:59,120
also to compare this output to an

95
00:03:57,840 --> 00:04:01,439
internet data set

96
00:03:59,120 --> 00:04:03,200
and so to put in evidence if there is a

97
00:04:01,439 --> 00:04:06,239
significant difference yes or no

98
00:04:03,200 --> 00:04:11,359
and for instance here in pink it's

99
00:04:06,239 --> 00:04:11,360
what is predicted by the model oh

100
00:04:11,760 --> 00:04:15,599
yep in pink it's what's pre is predicted

101
00:04:14,480 --> 00:04:18,478
by the model in

102
00:04:15,599 --> 00:04:19,918
green it's the labels and in the gray is

103
00:04:18,478 --> 00:04:24,159
when both are agree

104
00:04:19,918 --> 00:04:27,840
so it's a quick way to be able to um

105
00:04:24,160 --> 00:04:30,560
to check if the model and the label are

106
00:04:27,840 --> 00:04:31,679
matching yes or no and to see that this

107
00:04:30,560 --> 00:04:33,919
one for instance

108
00:04:31,680 --> 00:04:35,040
it's because it's beyond the trees so

109
00:04:33,919 --> 00:04:38,159
it's harder for

110
00:04:35,040 --> 00:04:38,160
the model to

111
00:04:38,240 --> 00:04:45,520
to to find a building

112
00:04:41,360 --> 00:04:47,840
because it's iron and it's also

113
00:04:45,520 --> 00:04:50,080
interesting to see that if you zoom out

114
00:04:47,840 --> 00:04:52,960
there is a

115
00:04:50,080 --> 00:04:53,840
spotify differences will help you to

116
00:04:52,960 --> 00:04:55,840
save time

117
00:04:53,840 --> 00:04:57,440
because we will focus only on the path

118
00:04:55,840 --> 00:05:00,638
where there is enough differences

119
00:04:57,440 --> 00:05:00,639
between your two datasets

120
00:05:02,639 --> 00:05:06,400
one other thing you can perform with

121
00:05:04,960 --> 00:05:09,198
exactly the same

122
00:05:06,400 --> 00:05:11,440
framework is change detection because in

123
00:05:09,199 --> 00:05:15,520
this um

124
00:05:11,440 --> 00:05:18,560
in this scenario you will train a model

125
00:05:15,520 --> 00:05:20,560
and use an alternate input for example

126
00:05:18,560 --> 00:05:23,120
for example something like one years

127
00:05:20,560 --> 00:05:26,320
later or two years later or one week

128
00:05:23,120 --> 00:05:28,000
anytime and you will so compute

129
00:05:26,320 --> 00:05:30,960
an alternate output and compare the

130
00:05:28,000 --> 00:05:33,919
difference okay

131
00:05:30,960 --> 00:05:36,840
and the last one is feature extraction

132
00:05:33,919 --> 00:05:39,919
you will train your model

133
00:05:36,840 --> 00:05:44,080
with a small data set

134
00:05:39,919 --> 00:05:48,400
a train area and you will use a wider

135
00:05:44,080 --> 00:05:50,880
image input to compute output

136
00:05:48,400 --> 00:05:52,719
for instance you will only label a

137
00:05:50,880 --> 00:05:55,440
smaller layer

138
00:05:52,720 --> 00:05:56,319
and once your model is trained you will

139
00:05:55,440 --> 00:05:59,600
be able

140
00:05:56,319 --> 00:06:02,479
to launch a prediction on a wide

141
00:05:59,600 --> 00:06:02,960
area and thereafter to vectorize it so

142
00:06:02,479 --> 00:06:06,080
to

143
00:06:02,960 --> 00:06:09,758
be able to use the tree scenario

144
00:06:06,080 --> 00:06:13,039
um we have several um little tools

145
00:06:09,759 --> 00:06:16,240
you can um assemble

146
00:06:13,039 --> 00:06:17,280
with um kind of lego stuff so there is

147
00:06:16,240 --> 00:06:20,639
small tools

148
00:06:17,280 --> 00:06:21,679
and you can change them to create your

149
00:06:20,639 --> 00:06:24,160
own

150
00:06:21,680 --> 00:06:25,520
workflow so it's the command line

151
00:06:24,160 --> 00:06:28,560
interfaces

152
00:06:25,520 --> 00:06:30,799
um and the wool id is ability to deal

153
00:06:28,560 --> 00:06:32,880
with a different kind of imagery

154
00:06:30,800 --> 00:06:35,280
different kind of well-known labels

155
00:06:32,880 --> 00:06:36,719
format to compute the prediction

156
00:06:35,280 --> 00:06:38,559
and thereafter to do something

157
00:06:36,720 --> 00:06:41,759
meaningful with

158
00:06:38,560 --> 00:06:45,039
other insights from the prediction mask

159
00:06:41,759 --> 00:06:46,880
you generated okay so that's the key

160
00:06:45,039 --> 00:06:50,318
concept

161
00:06:46,880 --> 00:06:54,639
about the stacks um we reuse and sell

162
00:06:50,319 --> 00:06:58,000
some well-known um computer

163
00:06:54,639 --> 00:07:01,039
software from a gis field some

164
00:06:58,000 --> 00:07:04,479
we came from python imagery as

165
00:07:01,039 --> 00:07:04,960
and some came from um deep learning a

166
00:07:04,479 --> 00:07:08,080
world

167
00:07:04,960 --> 00:07:11,758
so it's a bridge between

168
00:07:08,080 --> 00:07:11,758
these and these worlds

169
00:07:11,840 --> 00:07:15,359
it's full of open source except the

170
00:07:14,560 --> 00:07:18,319
nvidia

171
00:07:15,360 --> 00:07:20,160
parts because it's not open source by

172
00:07:18,319 --> 00:07:22,160
nvidia itself

173
00:07:20,160 --> 00:07:23,840
it's easy to deploy it's not because we

174
00:07:22,160 --> 00:07:26,240
use a lot of software that we

175
00:07:23,840 --> 00:07:30,318
didn't package so it's just a single

176
00:07:26,240 --> 00:07:32,800
line to install the wool stuff

177
00:07:30,319 --> 00:07:33,440
um there is a one-on-one tutorial will

178
00:07:32,800 --> 00:07:36,160
help you

179
00:07:33,440 --> 00:07:38,000
to do it by yourself and so to learn by

180
00:07:36,160 --> 00:07:41,199
yourself by doing it

181
00:07:38,000 --> 00:07:44,319
with a real world data and something

182
00:07:41,199 --> 00:07:46,319
uh from the install to the train data

183
00:07:44,319 --> 00:07:49,520
preparation training and so on

184
00:07:46,319 --> 00:07:50,639
um take something like two three three

185
00:07:49,520 --> 00:07:54,080
hours

186
00:07:50,639 --> 00:07:56,840
to um to launch the wool um

187
00:07:54,080 --> 00:07:58,800
the wool training session and they will

188
00:07:56,840 --> 00:08:01,440
um

189
00:07:58,800 --> 00:08:03,199
results so it's also available online so

190
00:08:01,440 --> 00:08:06,080
if you want to look at it right now

191
00:08:03,199 --> 00:08:06,560
you just have to to click on it and you

192
00:08:06,080 --> 00:08:09,440
click

193
00:08:06,560 --> 00:08:11,120
on the different picture to zoom in the

194
00:08:09,440 --> 00:08:14,479
leaflet

195
00:08:11,120 --> 00:08:16,879
interfaces so all you need in fact

196
00:08:14,479 --> 00:08:17,840
is imagery and we seem that it's not a

197
00:08:16,879 --> 00:08:21,039
problem anymore

198
00:08:17,840 --> 00:08:24,560
gpu and you need at least

199
00:08:21,039 --> 00:08:27,599
a recent gpu with enough

200
00:08:24,560 --> 00:08:30,879
memory and labels and so

201
00:08:27,599 --> 00:08:33,838
the key point is the label

202
00:08:30,879 --> 00:08:34,719
because most of the time we are we have

203
00:08:33,839 --> 00:08:37,120
labels

204
00:08:34,719 --> 00:08:37,839
but not accurate enough so if you look

205
00:08:37,120 --> 00:08:40,880
here on

206
00:08:37,839 --> 00:08:43,599
osm buildings

207
00:08:40,880 --> 00:08:44,800
data we have building from this imagery

208
00:08:43,599 --> 00:08:49,040
it's true

209
00:08:44,800 --> 00:08:51,359
but they are not accurate enough

210
00:08:49,040 --> 00:08:53,040
to be sure that your train model if you

211
00:08:51,360 --> 00:08:56,480
use this kind of data

212
00:08:53,040 --> 00:09:00,079
will be really accurate so it's

213
00:08:56,480 --> 00:09:02,720
something important to keep in mind that

214
00:09:00,080 --> 00:09:04,000
if you are a garbage in label you will

215
00:09:02,720 --> 00:09:07,279
have garbage out

216
00:09:04,000 --> 00:09:11,279
prediction yeah

217
00:09:07,279 --> 00:09:12,560
so um the point here is also to reuse

218
00:09:11,279 --> 00:09:15,920
this technique

219
00:09:12,560 --> 00:09:18,959
to check that your dataset training

220
00:09:15,920 --> 00:09:23,199
is quality enough and so

221
00:09:18,959 --> 00:09:26,640
to compare your labels you use here

222
00:09:23,200 --> 00:09:30,560
with these very tools and so

223
00:09:26,640 --> 00:09:33,760
also be able to keep or not some labels

224
00:09:30,560 --> 00:09:34,560
because for instance here these

225
00:09:33,760 --> 00:09:38,399
buildings

226
00:09:34,560 --> 00:09:41,599
appear in the label but

227
00:09:38,399 --> 00:09:42,560
is not it's not right related to this

228
00:09:41,600 --> 00:09:45,920
imagery

229
00:09:42,560 --> 00:09:48,479
because it's a right now on this imagery

230
00:09:45,920 --> 00:09:49,439
it's there is no buildings at this time

231
00:09:48,480 --> 00:09:52,000
so

232
00:09:49,440 --> 00:09:53,040
the most common way is to remove this

233
00:09:52,000 --> 00:09:56,240
ones

234
00:09:53,040 --> 00:09:59,439
and there is an integrated tool

235
00:09:56,240 --> 00:10:02,959
to help you to keep

236
00:09:59,440 --> 00:10:06,160
yes or no in a second so what's new

237
00:10:02,959 --> 00:10:09,439
inside an eto that pink first

238
00:10:06,160 --> 00:10:12,480
is the ability to

239
00:10:09,440 --> 00:10:14,959
enhance the quality of the prediction

240
00:10:12,480 --> 00:10:15,839
despite the fact that we use tiles so

241
00:10:14,959 --> 00:10:20,399
it's well known

242
00:10:15,839 --> 00:10:22,560
we use meta tiles to enlarge the focus

243
00:10:20,399 --> 00:10:23,680
obviously it will take longer if we

244
00:10:22,560 --> 00:10:27,119
choose this option

245
00:10:23,680 --> 00:10:29,839
but the result here is cleaner okay

246
00:10:27,120 --> 00:10:31,040
so if we slow the whole process we have

247
00:10:29,839 --> 00:10:34,480
to

248
00:10:31,040 --> 00:10:37,599
improve it some other way so we

249
00:10:34,480 --> 00:10:41,200
we add the multi gpu

250
00:10:37,600 --> 00:10:44,240
scaling to help to to use

251
00:10:41,200 --> 00:10:46,399
as many gpu you can get

252
00:10:44,240 --> 00:10:47,360
on a single host and for the trade and

253
00:10:46,399 --> 00:10:51,360
the prediction

254
00:10:47,360 --> 00:10:52,560
so you can scale it up and also we add

255
00:10:51,360 --> 00:10:56,320
the multi-classes

256
00:10:52,560 --> 00:10:57,199
so you are not only obliged to use it on

257
00:10:56,320 --> 00:11:00,320
a single class

258
00:10:57,200 --> 00:11:04,000
you can use on several class at once

259
00:11:00,320 --> 00:11:07,440
and we also provide an automated

260
00:11:04,000 --> 00:11:10,959
unbalanced option

261
00:11:07,440 --> 00:11:14,079
to help you to um to give

262
00:11:10,959 --> 00:11:18,719
up weights

263
00:11:14,079 --> 00:11:21,680
related to the classes if they are not

264
00:11:18,720 --> 00:11:23,200
distributed in the same way in your data

265
00:11:21,680 --> 00:11:26,160
set

266
00:11:23,200 --> 00:11:28,240
so what's the limit right now first the

267
00:11:26,160 --> 00:11:31,279
kind of imagery you want to predict on

268
00:11:28,240 --> 00:11:34,959
must be quite

269
00:11:31,279 --> 00:11:37,600
related to the ones you already train on

270
00:11:34,959 --> 00:11:38,800
remember it's a kind of compression so

271
00:11:37,600 --> 00:11:42,480
you can't expect

272
00:11:38,800 --> 00:11:45,920
a good result if the kind of imagery

273
00:11:42,480 --> 00:11:48,640
has nothing related to the ones you use

274
00:11:45,920 --> 00:11:48,640
for the training

275
00:11:49,040 --> 00:11:53,199
about the labels we think that you need

276
00:11:51,440 --> 00:11:55,200
something accurate

277
00:11:53,200 --> 00:11:56,639
and the amount of libel you need is

278
00:11:55,200 --> 00:11:59,680
something like

279
00:11:56,639 --> 00:12:00,240
thousands so observe at least one

280
00:11:59,680 --> 00:12:03,760
thousand

281
00:12:00,240 --> 00:12:06,880
or few thousands it depends but not

282
00:12:03,760 --> 00:12:09,519
a dozen okay and also

283
00:12:06,880 --> 00:12:11,120
right now it don't deal with topology so

284
00:12:09,519 --> 00:12:11,839
if you have something you want to

285
00:12:11,120 --> 00:12:14,880
extract

286
00:12:11,839 --> 00:12:17,760
and it's topology related something like

287
00:12:14,880 --> 00:12:18,800
a networks or roads for instance uh it

288
00:12:17,760 --> 00:12:21,760
doesn't work well

289
00:12:18,800 --> 00:12:23,199
it's far better behave with surfaces any

290
00:12:21,760 --> 00:12:25,839
kind of surfaces

291
00:12:23,200 --> 00:12:25,839
okay

292
00:12:26,399 --> 00:12:29,600
right now we are still working hard on

293
00:12:29,200 --> 00:12:31,839
it

294
00:12:29,600 --> 00:12:34,639
and we are looking for funding for

295
00:12:31,839 --> 00:12:37,040
sponsor in any way it could be

296
00:12:34,639 --> 00:12:38,079
related to a code so pull requests are

297
00:12:37,040 --> 00:12:41,040
really welcome

298
00:12:38,079 --> 00:12:43,120
it could be related to money funding it

299
00:12:41,040 --> 00:12:43,760
could be related to adwords funding and

300
00:12:43,120 --> 00:12:46,720
so on

301
00:12:43,760 --> 00:12:48,319
so help us to increase the gain accuracy

302
00:12:46,720 --> 00:12:50,560
especially on low resolution

303
00:12:48,320 --> 00:12:52,000
we talked just before about the

304
00:12:50,560 --> 00:12:54,638
copernicus and sentinel

305
00:12:52,000 --> 00:12:55,600
the next step obviously will be to

306
00:12:54,639 --> 00:12:58,000
behave

307
00:12:55,600 --> 00:12:58,880
and to increase the resolution even

308
00:12:58,000 --> 00:13:02,399
before

309
00:12:58,880 --> 00:13:03,680
we um we perform training and prediction

310
00:13:02,399 --> 00:13:06,720
on it

311
00:13:03,680 --> 00:13:09,839
the topology obviously and to reduce

312
00:13:06,720 --> 00:13:11,200
the amount of labels we need before be

313
00:13:09,839 --> 00:13:14,560
able to have an

314
00:13:11,200 --> 00:13:17,440
accurate training and also go on

315
00:13:14,560 --> 00:13:18,479
on the performance improvement because

316
00:13:17,440 --> 00:13:21,920
it's not

317
00:13:18,480 --> 00:13:25,120
necessary anymore to have a huge

318
00:13:21,920 --> 00:13:25,760
infrastructure to be able to use it you

319
00:13:25,120 --> 00:13:29,200
can

320
00:13:25,760 --> 00:13:29,200
but it's not mandatory

321
00:13:29,360 --> 00:13:34,560
there is also alternative open source

322
00:13:32,800 --> 00:13:37,279
to this project there is raster vision

323
00:13:34,560 --> 00:13:40,880
you'll learn roboset solaris

324
00:13:37,279 --> 00:13:43,920
so why choosing this one

325
00:13:40,880 --> 00:13:46,000
few arguments we

326
00:13:43,920 --> 00:13:47,680
really focus on just on their compliancy

327
00:13:46,000 --> 00:13:50,800
so it's really easy

328
00:13:47,680 --> 00:13:52,079
and standard compliant to reuse all the

329
00:13:50,800 --> 00:13:55,760
geospatial formats

330
00:13:52,079 --> 00:13:58,000
that you you work on daily with

331
00:13:55,760 --> 00:13:59,360
your data progression will be easy and

332
00:13:58,000 --> 00:14:01,680
fast

333
00:13:59,360 --> 00:14:02,720
there is a built-in web ui interface

334
00:14:01,680 --> 00:14:04,638
with help you

335
00:14:02,720 --> 00:14:06,160
to check at every step that everything

336
00:14:04,639 --> 00:14:08,560
is online yes or no

337
00:14:06,160 --> 00:14:11,040
it's modular and extensible so it's not

338
00:14:08,560 --> 00:14:15,040
something

339
00:14:11,040 --> 00:14:17,680
you can't extend easily on the contrary

340
00:14:15,040 --> 00:14:19,839
you can really easily add new tools add

341
00:14:17,680 --> 00:14:20,800
new interfaces add new templates and so

342
00:14:19,839 --> 00:14:25,040
on

343
00:14:20,800 --> 00:14:28,800
um it's um also handled multibands

344
00:14:25,040 --> 00:14:32,240
imagery uh and also on the data fusion

345
00:14:28,800 --> 00:14:35,279
so you can for instance use vector

346
00:14:32,240 --> 00:14:38,480
rasterize your vector and add it

347
00:14:35,279 --> 00:14:42,079
add an input from your imagery

348
00:14:38,480 --> 00:14:45,120
so it's really the same kind that a gis

349
00:14:42,079 --> 00:14:48,719
map you compose your map

350
00:14:45,120 --> 00:14:51,360
by adding several layers and

351
00:14:48,720 --> 00:14:52,160
with this stack you can train and then

352
00:14:51,360 --> 00:14:54,720
compute

353
00:14:52,160 --> 00:14:56,000
it's high performances and it's accurate

354
00:14:54,720 --> 00:14:59,199
because

355
00:14:56,000 --> 00:15:01,680
we use and reuse the latest computer

356
00:14:59,199 --> 00:15:05,040
vision papers available

357
00:15:01,680 --> 00:15:05,839
if this field interests you there is in

358
00:15:05,040 --> 00:15:08,880
one slide

359
00:15:05,839 --> 00:15:10,839
all the best resources to to learn from

360
00:15:08,880 --> 00:15:15,279
it

361
00:15:10,839 --> 00:15:18,240
and yeah one slide about the company

362
00:15:15,279 --> 00:15:18,959
to take away um there is right now

363
00:15:18,240 --> 00:15:22,560
undercl

364
00:15:18,959 --> 00:15:25,439
open source ie40 framework available

365
00:15:22,560 --> 00:15:26,638
um the performance are already okay to

366
00:15:25,440 --> 00:15:29,920
use it

367
00:15:26,639 --> 00:15:29,920
at a country level

368
00:15:30,399 --> 00:15:34,079
you not need anymore to be a computer

369
00:15:32,720 --> 00:15:36,720
vision scientist

370
00:15:34,079 --> 00:15:38,719
to use it as a special guy who

371
00:15:36,720 --> 00:15:42,880
understands the idea of the compression

372
00:15:38,720 --> 00:15:45,279
can do it right now plain open data

373
00:15:42,880 --> 00:15:46,320
could be used to train a model because

374
00:15:45,279 --> 00:15:49,519
you can

375
00:15:46,320 --> 00:15:52,480
use it step by step and so to

376
00:15:49,519 --> 00:15:54,399
refine your labels till as they are

377
00:15:52,480 --> 00:15:56,000
accurate enough and

378
00:15:54,399 --> 00:15:59,440
funding and pull requests are really

379
00:15:56,000 --> 00:15:59,440
welcome that's it

380
00:16:05,040 --> 00:16:08,240
for once we have more than one minute

381
00:16:06,959 --> 00:16:11,199
time for questions

382
00:16:08,240 --> 00:16:11,199
so bring it on

383
00:16:13,120 --> 00:16:20,000
it was just a renamer

384
00:16:17,440 --> 00:16:22,160
okay yeah repeat the question yeah a bit

385
00:16:20,000 --> 00:16:25,759
louder please

386
00:16:22,160 --> 00:16:28,319
there's another framework yeah

387
00:16:25,759 --> 00:16:29,519
robust pink was the name of the previous

388
00:16:28,320 --> 00:16:34,639
version

389
00:16:29,519 --> 00:16:38,399
and nitio.pink is a rename it's a 0.0.7

390
00:16:34,639 --> 00:16:41,040
version of the 0.6 robust big mansion

391
00:16:38,399 --> 00:16:42,639
the the point is there is a robust

392
00:16:41,040 --> 00:16:44,319
project and robo setting

393
00:16:42,639 --> 00:16:46,320
and people a lot of people made the

394
00:16:44,320 --> 00:16:48,320
mistake and oneness

395
00:16:46,320 --> 00:16:50,000
told robert pink lots of people

396
00:16:48,320 --> 00:16:52,240
understand the robosat

397
00:16:50,000 --> 00:16:53,199
and so at the end it was a mess so i

398
00:16:52,240 --> 00:16:57,040
said okay we

399
00:16:53,199 --> 00:16:59,920
stop it we rename it so if nitio

400
00:16:57,040 --> 00:17:00,319
there is no eto anywhere so it's a new

401
00:16:59,920 --> 00:17:05,039
name

402
00:17:00,320 --> 00:17:08,160
and go on so it's a zero set version yep

403
00:17:05,039 --> 00:17:10,480
um do you have a statistical output

404
00:17:08,160 --> 00:17:12,559
about how well the model performs

405
00:17:10,480 --> 00:17:14,160
it doesn't give you any statistics on

406
00:17:12,559 --> 00:17:17,760
your training

407
00:17:14,160 --> 00:17:18,240
related to these ones no right now no

408
00:17:17,760 --> 00:17:21,039
one

409
00:17:18,240 --> 00:17:21,919
uh at my uh i don't i don't have any

410
00:17:21,039 --> 00:17:25,119
information that

411
00:17:21,919 --> 00:17:27,679
anyone uh compare this will framework

412
00:17:25,119 --> 00:17:28,719
it will be a really good idea uh on

413
00:17:27,679 --> 00:17:31,039
several aspects

414
00:17:28,720 --> 00:17:32,320
related to accuracy related performances

415
00:17:31,039 --> 00:17:35,679
and related to

416
00:17:32,320 --> 00:17:39,039
how easy it is to use them yep

417
00:17:35,679 --> 00:17:40,240
it's a need in fact but at my um i don't

418
00:17:39,039 --> 00:17:43,360
know anyone who

419
00:17:40,240 --> 00:17:43,360
would we did it before

420
00:17:44,880 --> 00:17:47,919
the example of the computer vision in

421
00:17:47,039 --> 00:17:52,320
the

422
00:17:47,919 --> 00:17:52,320
right is basically a use fighter

423
00:17:56,559 --> 00:18:02,720
yeah it's a unit like with an encoder

424
00:17:59,600 --> 00:18:03,199
and you reuse an encoder as a resonant

425
00:18:02,720 --> 00:18:05,919
like

426
00:18:03,200 --> 00:18:06,720
so you can choose any kind of resnet as

427
00:18:05,919 --> 00:18:09,679
an encoder

428
00:18:06,720 --> 00:18:10,480
it's a unit like and there is also copy

429
00:18:09,679 --> 00:18:13,039
from

430
00:18:10,480 --> 00:18:14,000
the encoder to the decoder as a unit but

431
00:18:13,039 --> 00:18:16,160
also on the decoder

432
00:18:14,000 --> 00:18:16,160
part

433
00:18:19,600 --> 00:18:21,760
yep

434
00:18:23,039 --> 00:18:28,400
because yeah you also you already have

435
00:18:25,760 --> 00:18:31,440
all the python and the pigmentation

436
00:18:28,400 --> 00:18:34,000
implementation is the augmentation

437
00:18:31,440 --> 00:18:35,039
yeah that's augmentation and the

438
00:18:34,000 --> 00:18:37,600
documentation

439
00:18:35,039 --> 00:18:39,600
able to deal with multi-channel and

440
00:18:37,600 --> 00:18:42,799
that's the augmentation able to deal

441
00:18:39,600 --> 00:18:45,439
with several kind of imagery

442
00:18:42,799 --> 00:18:46,240
color shifting so you can add a lot of

443
00:18:45,440 --> 00:18:48,240
noise

444
00:18:46,240 --> 00:18:49,440
in your model and because you had a lot

445
00:18:48,240 --> 00:18:52,400
of noise

446
00:18:49,440 --> 00:18:54,160
the model is forced to generalize enough

447
00:18:52,400 --> 00:18:57,039
to be able to still work

448
00:18:54,160 --> 00:18:59,760
even if the imagery of the input will

449
00:18:57,039 --> 00:19:03,760
slightly change

450
00:18:59,760 --> 00:19:06,879
yep okay

451
00:19:03,760 --> 00:19:11,840
anybody no then once again thank you

452
00:19:06,880 --> 00:19:11,840
very much

453
00:19:16,799 --> 00:19:18,879
you

