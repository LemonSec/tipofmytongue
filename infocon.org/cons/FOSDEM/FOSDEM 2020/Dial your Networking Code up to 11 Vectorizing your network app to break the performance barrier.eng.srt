1
00:00:04,600 --> 00:00:10,190
so hi everybody my name is Bruce

2
00:00:08,029 --> 00:00:12,500
Richardson this is Hardy Van Haaren and

3
00:00:10,190 --> 00:00:14,480
like the last speakers actually we're

4
00:00:12,500 --> 00:00:18,070
both from Intel and Shannon in the West

5
00:00:14,480 --> 00:00:25,520
of Ireland and so we're talk today is

6
00:00:18,070 --> 00:00:32,360
liner networking code up to 11 spinal

7
00:00:25,520 --> 00:00:34,850
tap reference there just go with dashes

8
00:00:32,360 --> 00:00:37,129
the explanation first so this talk is

9
00:00:34,850 --> 00:00:38,420
all about vectorization so the first

10
00:00:37,129 --> 00:00:40,160
thing is what are we talking about

11
00:00:38,420 --> 00:00:42,050
whenever we talk about factorization so

12
00:00:40,160 --> 00:00:44,059
every we're talking here vectorization

13
00:00:42,050 --> 00:00:47,449
and vectors is a little different to

14
00:00:44,059 --> 00:00:49,489
let's say vectors in bpp terms okay what

15
00:00:47,449 --> 00:00:51,500
we're referring to is if you remember

16
00:00:49,489 --> 00:00:54,050
your computer science classes those when

17
00:00:51,500 --> 00:00:56,629
did if your science at college Cindy

18
00:00:54,050 --> 00:00:58,280
your single instruction multiple data so

19
00:00:56,629 --> 00:01:00,890
our vectors here literally just arrays

20
00:00:58,280 --> 00:01:03,920
of numbers designed for use in Cindy

21
00:01:00,890 --> 00:01:06,320
registers okay so with single

22
00:01:03,920 --> 00:01:08,000
instruction multiple data the idea is

23
00:01:06,320 --> 00:01:09,919
that instead of having an add

24
00:01:08,000 --> 00:01:11,660
instruction take two individual numbers

25
00:01:09,920 --> 00:01:13,790
and add them together it would take two

26
00:01:11,660 --> 00:01:15,890
vectors two arrays of numbers and add

27
00:01:13,790 --> 00:01:18,380
them together in parallel so with one

28
00:01:15,890 --> 00:01:21,680
instruction you can actually do for a or

29
00:01:18,380 --> 00:01:24,410
sixteen and effective operations from

30
00:01:21,680 --> 00:01:26,030
that one instruction so Cindy now is is

31
00:01:24,410 --> 00:01:27,350
very weapon wide spreads you know

32
00:01:26,030 --> 00:01:29,750
unarmed you've got neon you go that

33
00:01:27,350 --> 00:01:32,240
alphabet PowerPC but for obvious reasons

34
00:01:29,750 --> 00:01:33,890
this talk is mostly focused on Intel's

35
00:01:32,240 --> 00:01:36,170
treatments in the extensions better

36
00:01:33,890 --> 00:01:38,750
known as SSE eat you and me and Intel

37
00:01:36,170 --> 00:01:40,370
advanced vector extensions or AVX all

38
00:01:38,750 --> 00:01:42,020
the way up to avx-512

39
00:01:40,370 --> 00:01:46,520
so that's mostly what we're focusing

40
00:01:42,020 --> 00:01:48,259
these examples on so if you look on the

41
00:01:46,520 --> 00:01:52,759
internet and do your google searches and

42
00:01:48,260 --> 00:01:54,740
try reading off vectorization and you'll

43
00:01:52,760 --> 00:01:57,380
find a lot of examples doing you know

44
00:01:54,740 --> 00:01:59,660
vector additions and matrix multiplies

45
00:01:57,380 --> 00:02:01,729
and things like that there's not a lot

46
00:01:59,660 --> 00:02:03,259
of matrix multiplies done in packet

47
00:02:01,730 --> 00:02:04,790
processing normally there's a lot of

48
00:02:03,260 --> 00:02:07,190
packet header processing though which is

49
00:02:04,790 --> 00:02:09,170
because it'll be different so why would

50
00:02:07,190 --> 00:02:10,060
we want to vectorize why would we want

51
00:02:09,169 --> 00:02:11,950
to use these

52
00:02:10,060 --> 00:02:13,270
the instructions well there's a number

53
00:02:11,950 --> 00:02:14,530
of reasons okay

54
00:02:13,270 --> 00:02:16,090
one it gives us the opportunity

55
00:02:14,530 --> 00:02:18,640
potentially to work with multiple

56
00:02:16,090 --> 00:02:21,069
packets in parallel for example we see

57
00:02:18,640 --> 00:02:23,079
in one of the cases here where we try

58
00:02:21,069 --> 00:02:24,390
and process the flags from four packets

59
00:02:23,080 --> 00:02:26,020
at a time

60
00:02:24,390 --> 00:02:27,640
alternatively if we're doing maybe

61
00:02:26,020 --> 00:02:30,780
lookups we might have the opportunity to

62
00:02:27,640 --> 00:02:33,130
do a lookup or for hashes at a time

63
00:02:30,780 --> 00:02:35,739
alternatively instead of doing that

64
00:02:33,130 --> 00:02:37,510
whole scindia's with multiple data we

65
00:02:35,739 --> 00:02:39,850
can perhaps work with these as larger

66
00:02:37,510 --> 00:02:42,910
blocks larger block registers okay so

67
00:02:39,850 --> 00:02:44,950
instead of I'm just working with 8 bytes

68
00:02:42,910 --> 00:02:47,440
of data from a packet at a time maybe we

69
00:02:44,950 --> 00:02:50,140
could load and work on all 64 bytes of

70
00:02:47,440 --> 00:02:51,280
packet headers within one register and

71
00:02:50,140 --> 00:02:53,140
working out at a time so it's not

72
00:02:51,280 --> 00:02:56,950
multiple packets it's just more data

73
00:02:53,140 --> 00:02:59,049
from one packet Hey so in that case we

74
00:02:56,950 --> 00:03:00,280
could potentially you know save 8 load

75
00:02:59,050 --> 00:03:13,180
instructions and just do one load

76
00:03:00,280 --> 00:03:15,250
instruction time lastly and perhaps most

77
00:03:13,180 --> 00:03:17,230
interestingly it also opens up new

78
00:03:15,250 --> 00:03:19,299
possibilities of new ways of doing

79
00:03:17,230 --> 00:03:20,950
things taking advantage of their

80
00:03:19,299 --> 00:03:22,420
capabilities and their novel

81
00:03:20,950 --> 00:03:24,850
instructions that these vector

82
00:03:22,420 --> 00:03:27,100
instruction sets provides so we'll see

83
00:03:24,850 --> 00:03:28,840
used here a bit well actually in the

84
00:03:27,100 --> 00:03:30,190
case of when shopping is secure that use

85
00:03:28,840 --> 00:03:32,110
from Losh as we work through these

86
00:03:30,190 --> 00:03:34,870
examples so that's where we change the

87
00:03:32,110 --> 00:03:37,209
order of bikes within a register ok and

88
00:03:34,870 --> 00:03:39,190
you can't really do that except manually

89
00:03:37,209 --> 00:03:41,290
to a sequence of instructions if you're

90
00:03:39,190 --> 00:03:42,850
using scalar code with vector code you

91
00:03:41,290 --> 00:03:45,100
can do a lot of shuffling really quickly

92
00:03:42,850 --> 00:03:47,140
then also especially in some like

93
00:03:45,100 --> 00:03:48,160
avx-512 they've got these new thing

94
00:03:47,140 --> 00:03:50,649
called hey master

95
00:03:48,160 --> 00:03:52,510
delay you do masking operations to work

96
00:03:50,650 --> 00:03:53,769
with partial registers simultaneously

97
00:03:52,510 --> 00:03:55,390
and how he's a big fan of these

98
00:03:53,769 --> 00:03:57,070
instructions I'm going to touch on those

99
00:03:55,390 --> 00:03:59,170
as well afterwards but these are again

100
00:03:57,070 --> 00:04:01,870
new capabilities offered by these

101
00:03:59,170 --> 00:04:04,119
instruction sets okay however the

102
00:04:01,870 --> 00:04:07,420
overall upshot really is that these

103
00:04:04,120 --> 00:04:09,100
vectorization instructions whose AVX SSE

104
00:04:07,420 --> 00:04:11,649
instructions all allow you to do more

105
00:04:09,100 --> 00:04:13,120
work with your instructions you get more

106
00:04:11,650 --> 00:04:16,880
bang from your book

107
00:04:13,120 --> 00:04:17,930
okay so here's a brief outline of the

108
00:04:16,880 --> 00:04:19,608
lesson talk

109
00:04:17,930 --> 00:04:21,858
initially I'll hand over to Harry to

110
00:04:19,608 --> 00:04:24,169
talk a bit about how they do packet

111
00:04:21,858 --> 00:04:26,690
parsing in OBS and how we can accelerate

112
00:04:24,169 --> 00:04:28,580
that mini flow extract function using

113
00:04:26,690 --> 00:04:29,990
factorization then because you're not

114
00:04:28,580 --> 00:04:31,849
getting rid of me that easily I'll be

115
00:04:29,990 --> 00:04:34,460
back on stage again to talk about some

116
00:04:31,850 --> 00:04:37,010
of our DBK for more drivers and how we

117
00:04:34,460 --> 00:04:39,859
use vectorization there to speed up

118
00:04:37,010 --> 00:04:41,330
those and then finally how he will come

119
00:04:39,860 --> 00:04:51,560
up and talk a bit more about another

120
00:04:41,330 --> 00:04:52,698
part of folks so as Bruce mentioned I'm

121
00:04:51,560 --> 00:04:54,830
talking about packet parsing

122
00:04:52,699 --> 00:04:56,150
particularly in the context of Simbi so

123
00:04:54,830 --> 00:04:57,440
there's multiple ways that we can use

124
00:04:56,150 --> 00:04:59,120
these instructions Bruce mentioned we

125
00:04:57,440 --> 00:05:01,310
can do multiple data or we can look at

126
00:04:59,120 --> 00:05:02,870
one big block of data and in this case

127
00:05:01,310 --> 00:05:05,449
we're gonna focus more on the one big

128
00:05:02,870 --> 00:05:07,190
block of data use case so what we're

129
00:05:05,449 --> 00:05:09,470
really trying to do here is when OVS

130
00:05:07,190 --> 00:05:11,960
receives the packet from any back-end D

131
00:05:09,470 --> 00:05:13,850
PDK or any of the others it basically

132
00:05:11,960 --> 00:05:15,320
gets the packet data that we've received

133
00:05:13,850 --> 00:05:17,150
over the wire and now we need to

134
00:05:15,320 --> 00:05:18,440
interpret that we need to do something

135
00:05:17,150 --> 00:05:19,880
with it we need to match it to some

136
00:05:18,440 --> 00:05:22,310
rules right that's what OVS ultimately

137
00:05:19,880 --> 00:05:24,139
does perform some actions and then TX

138
00:05:22,310 --> 00:05:27,260
the packet again either to a guest or to

139
00:05:24,139 --> 00:05:28,940
the network so a very big part of that

140
00:05:27,260 --> 00:05:30,789
cycle cost is actually parsing the

141
00:05:28,940 --> 00:05:33,590
packet understanding what that packet is

142
00:05:30,789 --> 00:05:37,039
so when obvious is actually parsing a

143
00:05:33,590 --> 00:05:39,320
packet into its own internal shower or

144
00:05:37,039 --> 00:05:40,820
data structure it parses it into

145
00:05:39,320 --> 00:05:41,960
something called a mini flow for those

146
00:05:40,820 --> 00:05:44,000
not familiar with the mini flow data

147
00:05:41,960 --> 00:05:45,320
structure I wasn't a couple of years ago

148
00:05:44,000 --> 00:05:47,240
so I'll presume not everyone here is

149
00:05:45,320 --> 00:05:48,380
it's it's worth talking about this data

150
00:05:47,240 --> 00:05:50,360
structure for a little while because

151
00:05:48,380 --> 00:05:52,400
it's a really nice concept of how to

152
00:05:50,360 --> 00:05:54,400
compress data in a very cash friendly

153
00:05:52,400 --> 00:05:56,570
way and it's also something that's

154
00:05:54,400 --> 00:05:58,760
relatively a trades off compute and

155
00:05:56,570 --> 00:06:00,320
memory kind accesses so it's an

156
00:05:58,760 --> 00:06:01,550
interesting data structure and I'll talk

157
00:06:00,320 --> 00:06:03,469
about it in the next slides and then

158
00:06:01,550 --> 00:06:04,699
later again so I'll spend a couple of

159
00:06:03,470 --> 00:06:07,550
minutes just explaining what how this

160
00:06:04,699 --> 00:06:09,979
works or what it does I'm it's composed

161
00:06:07,550 --> 00:06:11,270
out of two parts and I draw most of my

162
00:06:09,979 --> 00:06:12,440
things graphically so over on the right

163
00:06:11,270 --> 00:06:14,719
hand side we have kind of the graphical

164
00:06:12,440 --> 00:06:17,780
representation of the mini flow the mini

165
00:06:14,720 --> 00:06:21,620
flow has bits and blocks the bits to

166
00:06:17,780 --> 00:06:24,650
your left is essentially a bit mask of

167
00:06:21,620 --> 00:06:26,670
what what is parsed into this mini flow

168
00:06:24,650 --> 00:06:29,520
so if you receive a packet that

169
00:06:26,670 --> 00:06:31,500
as an Ethernet header than an IP there

170
00:06:29,520 --> 00:06:33,930
will be in Ethernet bit and there'll be

171
00:06:31,500 --> 00:06:36,420
an IP bit or an ipv4 bit and a separate

172
00:06:33,930 --> 00:06:38,880
ipv6 bit somewhere else so those bits

173
00:06:36,420 --> 00:06:41,070
are kind of like individual identifiers

174
00:06:38,880 --> 00:06:45,930
for is a particular thing that the mini

175
00:06:41,070 --> 00:06:47,760
flow is aware of so IP VLANs the X line

176
00:06:45,930 --> 00:06:49,590
all those kind of things are they

177
00:06:47,760 --> 00:06:52,020
present in this mini flow data structure

178
00:06:49,590 --> 00:06:53,940
if it is present a bit set if it's not

179
00:06:52,020 --> 00:06:55,830
then it's not set so it's just an

180
00:06:53,940 --> 00:06:59,580
individual bit to identify is this for

181
00:06:55,830 --> 00:07:01,620
example an ipv4 packet if it is then we

182
00:06:59,580 --> 00:07:04,440
move to the blocks and the blocks the

183
00:07:01,620 --> 00:07:06,720
the data contained there changes based

184
00:07:04,440 --> 00:07:08,310
on what bits are set so in that way it's

185
00:07:06,720 --> 00:07:11,910
kind of a dynamic data structure in a

186
00:07:08,310 --> 00:07:14,700
way if you like so the bits identify

187
00:07:11,910 --> 00:07:17,850
what each block represents and the

188
00:07:14,700 --> 00:07:19,469
blocks contain the actual value so ipv4

189
00:07:17,850 --> 00:07:23,370
we have a source and a destination

190
00:07:19,470 --> 00:07:25,890
address those actual values so one 27001

191
00:07:23,370 --> 00:07:28,350
as an example will that value itself

192
00:07:25,890 --> 00:07:30,840
will be stored in a block but the fact

193
00:07:28,350 --> 00:07:32,700
that it's an ipv4 packet will be stored

194
00:07:30,840 --> 00:07:34,830
in an individual bit in this mini flow

195
00:07:32,700 --> 00:07:37,349
bits so that's how the bits and blocks

196
00:07:34,830 --> 00:07:39,659
kind of work together the number of bits

197
00:07:37,350 --> 00:07:42,420
set is also the number of blocks that

198
00:07:39,660 --> 00:07:44,040
are filled with valid data afterwards so

199
00:07:42,420 --> 00:07:47,580
so there's always a relationship between

200
00:07:44,040 --> 00:07:50,520
these blocks and the bits so in total

201
00:07:47,580 --> 00:07:53,370
the data structure has 128 bits so to un

202
00:07:50,520 --> 00:07:56,250
64's in terms of scalar code as u and 64

203
00:07:53,370 --> 00:07:59,970
being though the widest integer that

204
00:07:56,250 --> 00:08:02,130
most modern cpus support and the blocks

205
00:07:59,970 --> 00:08:04,410
essentially they scale out depending on

206
00:08:02,130 --> 00:08:07,050
how many things this obvious instance is

207
00:08:04,410 --> 00:08:08,550
aware of so it largely over provisions

208
00:08:07,050 --> 00:08:11,250
for most use cases I think it's about

209
00:08:08,550 --> 00:08:13,530
580 bytes or so so the mini flow is a

210
00:08:11,250 --> 00:08:14,340
very large data structure but because of

211
00:08:13,530 --> 00:08:16,140
the way it works

212
00:08:14,340 --> 00:08:19,020
we always compress the data that we use

213
00:08:16,140 --> 00:08:21,390
in towards the bits so left pack all the

214
00:08:19,020 --> 00:08:22,770
data if you like that gives us very good

215
00:08:21,390 --> 00:08:24,510
cache affinity with this data structure

216
00:08:22,770 --> 00:08:26,190
and that's the reason it's actually

217
00:08:24,510 --> 00:08:27,990
really nice because together with the

218
00:08:26,190 --> 00:08:30,300
bits and the blocks you cannot interpret

219
00:08:27,990 --> 00:08:32,820
any type of packet and you can represent

220
00:08:30,300 --> 00:08:37,650
a very wide range of packets in a very

221
00:08:32,820 --> 00:08:39,240
cache dense way so the last thing I kind

222
00:08:37,650 --> 00:08:40,350
of refer to it earlier but the count of

223
00:08:39,240 --> 00:08:43,049
the block so the number of block

224
00:08:40,350 --> 00:08:45,000
is equal to a pop count or the number of

225
00:08:43,049 --> 00:08:46,880
bits set so that kind of becomes more

226
00:08:45,000 --> 00:08:49,830
important later on in the presentation

227
00:08:46,880 --> 00:08:52,140
so if we look at the packet parsing

228
00:08:49,830 --> 00:08:54,390
itself bringing us back to a more Simbi

229
00:08:52,140 --> 00:08:56,699
context here at the top right I've

230
00:08:54,390 --> 00:09:00,300
graphically represented a packet and

231
00:08:56,700 --> 00:09:02,100
Ethernet ipv4 UDP packet and we want to

232
00:09:00,300 --> 00:09:03,449
parse that into the mini flow so again

233
00:09:02,100 --> 00:09:05,190
the mini flow here on the bottom right I

234
00:09:03,450 --> 00:09:06,630
described it earlier so we want to build

235
00:09:05,190 --> 00:09:08,910
up the mini flow that's specific for

236
00:09:06,630 --> 00:09:10,860
this type of packet we receive this

237
00:09:08,910 --> 00:09:12,540
packet from an Ethernet device so we

238
00:09:10,860 --> 00:09:14,670
know that the outer frame is going to be

239
00:09:12,540 --> 00:09:16,589
in either a header but what we don't

240
00:09:14,670 --> 00:09:17,939
know is what the either type is so what

241
00:09:16,590 --> 00:09:20,340
does it contain what are the contents of

242
00:09:17,940 --> 00:09:22,290
this Ethernet frame to build up the mini

243
00:09:20,340 --> 00:09:24,630
flow we're gonna load the Mac so the

244
00:09:22,290 --> 00:09:26,730
actual Ethernet MAC address source test

245
00:09:24,630 --> 00:09:28,260
we're gonna copy those into the mini

246
00:09:26,730 --> 00:09:29,940
flow data structure down below so you

247
00:09:28,260 --> 00:09:32,040
can see one block gets consumed in this

248
00:09:29,940 --> 00:09:33,720
case in theory it's actually two the

249
00:09:32,040 --> 00:09:35,579
slides are slightly simplified just for

250
00:09:33,720 --> 00:09:38,670
manageability and kind of being able to

251
00:09:35,580 --> 00:09:40,770
see it and represent it easier so we

252
00:09:38,670 --> 00:09:42,599
pulled these MAC addresses we store them

253
00:09:40,770 --> 00:09:44,760
in the mini flow in a block and we'll

254
00:09:42,600 --> 00:09:46,290
set a bit in the bits array saying hey

255
00:09:44,760 --> 00:09:48,660
there's an Ethernet header present in

256
00:09:46,290 --> 00:09:50,550
this mini film the next thing we're

257
00:09:48,660 --> 00:09:53,310
gonna do in a scalar mini flow extract

258
00:09:50,550 --> 00:09:54,870
is look essentially load this Ethernet

259
00:09:53,310 --> 00:09:56,310
type and then we're going to perform a

260
00:09:54,870 --> 00:09:57,390
branch on it for those familiar with

261
00:09:56,310 --> 00:09:58,979
those assembly statements we're gonna

262
00:09:57,390 --> 00:10:01,920
jump somewhere else in the instruction

263
00:09:58,980 --> 00:10:04,050
stream and we're gonna perform some type

264
00:10:01,920 --> 00:10:06,150
of operation based on that so if it's

265
00:10:04,050 --> 00:10:09,510
equal to oh X 800 that happens to be an

266
00:10:06,150 --> 00:10:10,800
ipv4 as a protocol contained inside then

267
00:10:09,510 --> 00:10:13,560
we're gonna parse that next block of

268
00:10:10,800 --> 00:10:15,930
data as an ipv4 header and we're gonna

269
00:10:13,560 --> 00:10:17,640
load that ipv4 info we're gonna store it

270
00:10:15,930 --> 00:10:19,020
at to a mini flow block we're gonna set

271
00:10:17,640 --> 00:10:21,270
a bit in the mini flow saying hey this

272
00:10:19,020 --> 00:10:23,340
is actually an ipv4 header as well or an

273
00:10:21,270 --> 00:10:27,300
ipv4 packet it contained in this mini

274
00:10:23,340 --> 00:10:28,770
flow with the IP we're gonna now load

275
00:10:27,300 --> 00:10:30,150
the protocol field again we're gonna

276
00:10:28,770 --> 00:10:31,680
load it we're gonna branch on it because

277
00:10:30,150 --> 00:10:33,689
we don't know what's inside this it

278
00:10:31,680 --> 00:10:36,959
could be a whole range of things in this

279
00:10:33,690 --> 00:10:38,940
particular example it's a UDP so now we

280
00:10:36,960 --> 00:10:40,200
go and we interpret the next piece of

281
00:10:38,940 --> 00:10:42,510
data you can see it's kind of very

282
00:10:40,200 --> 00:10:44,010
scalar we load something a small piece

283
00:10:42,510 --> 00:10:46,590
of data we store it into the mini flow

284
00:10:44,010 --> 00:10:48,410
we set a bit we now branch based on

285
00:10:46,590 --> 00:10:51,450
whatever properties that that particular

286
00:10:48,410 --> 00:10:54,120
protocol field had so either net type or

287
00:10:51,450 --> 00:10:57,000
IP protocol and it's a very slow

288
00:10:54,120 --> 00:10:58,800
stepwise process from a CPU performance

289
00:10:57,000 --> 00:11:00,480
point of view that we need to understand

290
00:10:58,800 --> 00:11:02,160
what the next or the either type is

291
00:11:00,480 --> 00:11:03,540
before we can interpret the next piece

292
00:11:02,160 --> 00:11:05,250
of data we need to understand what the

293
00:11:03,540 --> 00:11:07,020
IP protocol is before we can actually

294
00:11:05,250 --> 00:11:09,540
store that piece of data so it's a very

295
00:11:07,020 --> 00:11:12,270
scaler and step-by-step way of building

296
00:11:09,540 --> 00:11:14,430
up a mini phone so if we try and

297
00:11:12,270 --> 00:11:16,710
vectorize this what what could we do how

298
00:11:14,430 --> 00:11:19,229
could we use Simbi instructions to do

299
00:11:16,710 --> 00:11:21,150
better and this as Bruce referred

300
00:11:19,230 --> 00:11:24,390
earlier we can slurp up a huge amount of

301
00:11:21,150 --> 00:11:26,550
data into a register so SSE being 128

302
00:11:24,390 --> 00:11:28,770
bits or 16 bytes avx2

303
00:11:26,550 --> 00:11:30,810
extending those registers to 32 bytes

304
00:11:28,770 --> 00:11:33,990
and avx-512 actually giving us a full

305
00:11:30,810 --> 00:11:36,779
512 bits or 64 bytes or a cache line on

306
00:11:33,990 --> 00:11:39,330
most architectures a full cache line of

307
00:11:36,779 --> 00:11:40,650
information in a single register so in

308
00:11:39,330 --> 00:11:42,870
this case we could actually load the

309
00:11:40,650 --> 00:11:45,240
ethernet ipv4 the UDP and a little chunk

310
00:11:42,870 --> 00:11:47,100
of payload into a single register and

311
00:11:45,240 --> 00:11:48,990
now we can operate on all that data in

312
00:11:47,100 --> 00:11:51,089
parallel so one instruction could

313
00:11:48,990 --> 00:11:53,100
influence all of the bits of that packet

314
00:11:51,089 --> 00:11:54,600
header basically and that gives us a lot

315
00:11:53,100 --> 00:11:56,760
of flexibility to start thinking about

316
00:11:54,600 --> 00:12:00,180
compute and how we build this mini flow

317
00:11:56,760 --> 00:12:02,010
data structure so if we're aware of the

318
00:12:00,180 --> 00:12:03,390
types of traffic that run through our

319
00:12:02,010 --> 00:12:07,189
data center there's some great

320
00:12:03,390 --> 00:12:09,839
presentations earlier about the SN

321
00:12:07,190 --> 00:12:11,520
protocols and and that you can run

322
00:12:09,839 --> 00:12:12,870
specific types of traffic and your

323
00:12:11,520 --> 00:12:16,410
encapsulation is something you'll be

324
00:12:12,870 --> 00:12:17,760
aware of I'm basically we can specialize

325
00:12:16,410 --> 00:12:19,500
those so I have here on the right-hand

326
00:12:17,760 --> 00:12:21,959
side that we could load the whole packet

327
00:12:19,500 --> 00:12:24,510
data we could do a bitwise and with that

328
00:12:21,959 --> 00:12:26,790
and compare it to a known protocol so we

329
00:12:24,510 --> 00:12:30,720
could write code or we can write generic

330
00:12:26,790 --> 00:12:33,209
code in a way that the packet headers

331
00:12:30,720 --> 00:12:35,310
that we receive most common so 80% or

332
00:12:33,209 --> 00:12:37,739
90% of our traffic will probably have a

333
00:12:35,310 --> 00:12:40,260
specific layout for a cific specific

334
00:12:37,740 --> 00:12:42,779
like set of protocols and we can create

335
00:12:40,260 --> 00:12:47,040
a essentially a register or a bit mask

336
00:12:42,779 --> 00:12:48,600
and with values to compare so in this

337
00:12:47,040 --> 00:12:50,099
case we're loading the data we're going

338
00:12:48,600 --> 00:12:52,230
to do a bit mask we're going to compare

339
00:12:50,100 --> 00:12:53,640
and that will tell us if all three

340
00:12:52,230 --> 00:12:56,370
headers were present in a specific

341
00:12:53,640 --> 00:12:59,220
layout or in a specific order so in this

342
00:12:56,370 --> 00:13:00,839
case Ethernet ipv4 and UDP all those

343
00:12:59,220 --> 00:13:02,820
checks that we don't earlier can be done

344
00:13:00,839 --> 00:13:04,350
in parallel because we have a very wide

345
00:13:02,820 --> 00:13:06,870
register and all these operations can

346
00:13:04,350 --> 00:13:08,149
occur in a single instruction with

347
00:13:06,870 --> 00:13:11,610
multiple days

348
00:13:08,149 --> 00:13:13,079
so if we do hit on this protocol then we

349
00:13:11,610 --> 00:13:14,550
can create something called a shuffle so

350
00:13:13,079 --> 00:13:16,888
let's kind of represent it on the bottom

351
00:13:14,550 --> 00:13:19,079
left here I'm a shuffle is ultimately a

352
00:13:16,889 --> 00:13:20,879
way to transform data inside a register

353
00:13:19,079 --> 00:13:22,138
Bruce is gonna go into detail in the

354
00:13:20,879 --> 00:13:24,389
next couple of slides how they work so

355
00:13:22,139 --> 00:13:26,069
I'm gonna kind of gloss over it here but

356
00:13:24,389 --> 00:13:28,170
let's hypothetically say that magic

357
00:13:26,069 --> 00:13:30,449
happens that packet layout whatever it

358
00:13:28,170 --> 00:13:32,459
was gets transformed into the mini flow

359
00:13:30,449 --> 00:13:34,559
layout there below and now we can use

360
00:13:32,459 --> 00:13:37,618
one store instruction to take that whole

361
00:13:34,559 --> 00:13:39,480
packet and create a mini flow using a

362
00:13:37,619 --> 00:13:42,509
single store we store 64 bytes of data

363
00:13:39,480 --> 00:13:45,209
into our memory subsystem or into our

364
00:13:42,509 --> 00:13:48,119
il-1 cache and in the space of about

365
00:13:45,209 --> 00:13:50,099
five or ten instructions or cycles we've

366
00:13:48,119 --> 00:13:52,410
now done that whole mini flow packet

367
00:13:50,100 --> 00:13:53,879
parsing whereas previously we had two

368
00:13:52,410 --> 00:13:56,069
branches and a whole bunch of smaller

369
00:13:53,879 --> 00:13:57,839
loads and stores we've reduced that to a

370
00:13:56,069 --> 00:14:00,689
handful of instructions and equally so

371
00:13:57,839 --> 00:14:02,970
most likely a handful of cycles so

372
00:14:00,689 --> 00:14:05,279
that's a vectorized mini flow extract

373
00:14:02,970 --> 00:14:07,740
we'll build on this mini flow and more

374
00:14:05,279 --> 00:14:11,209
vectorization in a subsequent part but

375
00:14:07,740 --> 00:14:11,209
first I'll hang on to Bruce to do some

376
00:14:39,980 --> 00:14:44,730
every pull more driver needs to take the

377
00:14:42,809 --> 00:14:47,279
metadata supplied by the network card

378
00:14:44,730 --> 00:14:48,929
and transform us into the metadata

379
00:14:47,279 --> 00:14:53,309
structure expected by the application

380
00:14:48,929 --> 00:14:55,230
which is the mo but you heard so what

381
00:14:53,309 --> 00:14:56,879
I've done this right here on the right

382
00:14:55,230 --> 00:14:58,410
hand side I've got a list of the

383
00:14:56,879 --> 00:15:00,569
descriptive fields from one of our pull

384
00:14:58,410 --> 00:15:03,029
more drivers and I've taken the IH gve

385
00:15:00,569 --> 00:15:06,149
for my driver because it's one of the

386
00:15:03,029 --> 00:15:09,350
simple ones here and then I've also got

387
00:15:06,149 --> 00:15:09,350
on the left the

388
00:15:13,750 --> 00:15:19,760
hey I'm roughly speaking we have a

389
00:15:17,570 --> 00:15:20,930
one-to-one correspondence for a lot of

390
00:15:19,760 --> 00:15:24,290
these fields and it's something like

391
00:15:20,930 --> 00:15:25,849
this okay so we've got pike and lengths

392
00:15:24,290 --> 00:15:27,560
and a legs come for a packet length

393
00:15:25,850 --> 00:15:29,120
fields VLAN information comes across

394
00:15:27,560 --> 00:15:30,709
we've got a packet type field that needs

395
00:15:29,120 --> 00:15:33,740
to be matched to a packet type field and

396
00:15:30,709 --> 00:15:36,770
then we've got someone used fields and

397
00:15:33,740 --> 00:15:38,450
some that we actually don't direct

398
00:15:36,770 --> 00:15:40,819
directly the one to the end off so the

399
00:15:38,450 --> 00:15:43,610
status field which we'll process later

400
00:15:40,820 --> 00:15:45,290
it's it gives us information about my

401
00:15:43,610 --> 00:15:48,080
descriptor invalid or not

402
00:15:45,290 --> 00:15:49,579
hey though in this particular case what

403
00:15:48,080 --> 00:15:51,080
additional wrinkle is that the packet

404
00:15:49,580 --> 00:15:52,610
type field even though it has the same

405
00:15:51,080 --> 00:15:54,350
name it does need some additional

406
00:15:52,610 --> 00:15:59,050
processing so it's not a straight man

407
00:15:54,350 --> 00:16:01,790
okay well in short we essentially have

408
00:15:59,050 --> 00:16:04,880
four different field arrows here of

409
00:16:01,790 --> 00:16:06,740
fields in our NIC descriptor that need

410
00:16:04,880 --> 00:16:09,380
to be moved about and then written into

411
00:16:06,740 --> 00:16:11,330
the end off in a different order okay so

412
00:16:09,380 --> 00:16:13,189
that's a very very common operation we

413
00:16:11,330 --> 00:16:16,940
have to do inside our form of drivers

414
00:16:13,190 --> 00:16:18,649
and to do that we use the shuffle

415
00:16:16,940 --> 00:16:20,690
operation a hairy refer to earlier so

416
00:16:18,649 --> 00:16:22,250
it's the exact same kind of operation

417
00:16:20,690 --> 00:16:24,320
that needs to be done for that mini flow

418
00:16:22,250 --> 00:16:25,910
where you go set of fields inside a

419
00:16:24,320 --> 00:16:27,440
register and you need to store them

420
00:16:25,910 --> 00:16:30,560
somewhere else in a different order and

421
00:16:27,440 --> 00:16:32,779
this can be slow to do in scalar code

422
00:16:30,560 --> 00:16:34,849
using a lot of loads of stores to load

423
00:16:32,779 --> 00:16:37,279
one field storage but we can work a lot

424
00:16:34,850 --> 00:16:39,860
faster using vector operations and using

425
00:16:37,279 --> 00:16:41,930
shuffles and again for simplicity sake

426
00:16:39,860 --> 00:16:45,709
I'm just using an SSD version here if

427
00:16:41,930 --> 00:16:48,529
you look in DB eki or de pollo driver we

428
00:16:45,709 --> 00:16:50,599
have an avx2 instance there which will

429
00:16:48,529 --> 00:16:52,700
use shuffles in pretty much exactly the

430
00:16:50,600 --> 00:16:55,550
same way so this is applicable for a B X

431
00:16:52,700 --> 00:16:57,290
2 and X 512 it's just due to the larger

432
00:16:55,550 --> 00:16:57,920
size the registers just as well overflow

433
00:16:57,290 --> 00:17:00,349
slice

434
00:16:57,920 --> 00:17:03,469
so I'm limit goes to 16 bytes here for

435
00:17:00,350 --> 00:17:05,929
simplicity sake okay so if we start off

436
00:17:03,470 --> 00:17:08,150
looking at this the first we have from

437
00:17:05,929 --> 00:17:10,610
the top we have the actual source so

438
00:17:08,150 --> 00:17:12,949
visit the descriptor with the original

439
00:17:10,609 --> 00:17:14,569
data and on the bottom we have the M

440
00:17:12,949 --> 00:17:16,760
both fields that we need to fill in okay

441
00:17:14,569 --> 00:17:18,149
so how do we map from here to here using

442
00:17:16,760 --> 00:17:20,280
you shuffle operation

443
00:17:18,150 --> 00:17:23,400
I'll actually fill in the actual

444
00:17:20,280 --> 00:17:25,290
instruction set used the set was called

445
00:17:23,400 --> 00:17:26,939
the shuffle mask that tells us where to

446
00:17:25,290 --> 00:17:28,620
pull the bikes and this way I'll show

447
00:17:26,939 --> 00:17:31,380
you how to shuffle operation how you

448
00:17:28,620 --> 00:17:33,479
actually use that instruction okay again

449
00:17:31,380 --> 00:17:35,850
everything is unfortunately right to

450
00:17:33,480 --> 00:17:38,580
left because whatever we fill in the

451
00:17:35,850 --> 00:17:40,709
fields in the register it actually

452
00:17:38,580 --> 00:17:42,570
primaries go from right to left so the

453
00:17:40,710 --> 00:17:45,809
mole of Piyush goes on the very end so

454
00:17:42,570 --> 00:17:48,270
everything is consistently right it is

455
00:17:45,809 --> 00:17:51,809
deliberate okay even though it may

456
00:17:48,270 --> 00:17:53,730
initially look backwards so the first

457
00:17:51,809 --> 00:17:55,678
field is a packet type but unfortunately

458
00:17:53,730 --> 00:17:57,150
as I said earlier it does need some

459
00:17:55,679 --> 00:17:57,750
additional plastic so we're not ready to

460
00:17:57,150 --> 00:17:59,520
fill it in

461
00:17:57,750 --> 00:18:02,010
so what we want to do for now is we want

462
00:17:59,520 --> 00:18:03,870
to zero out that field so the shuffle

463
00:18:02,010 --> 00:18:06,510
operation setting the high bish means

464
00:18:03,870 --> 00:18:09,178
set us zero send the hybin I would find

465
00:18:06,510 --> 00:18:10,830
a bit confusing so I actually I named

466
00:18:09,179 --> 00:18:13,170
our driving of scene we set it to F F

467
00:18:10,830 --> 00:18:15,419
which is just a big big you know

468
00:18:13,170 --> 00:18:16,710
flashing sign saying this is not just a

469
00:18:15,420 --> 00:18:19,050
regular field this is going to be zero

470
00:18:16,710 --> 00:18:21,450
day okay so okay we have to skip over

471
00:18:19,050 --> 00:18:22,980
that that's zero okay but now we start

472
00:18:21,450 --> 00:18:25,620
getting to actually move in the database

473
00:18:22,980 --> 00:18:28,590
so in the shuffle mask the value that

474
00:18:25,620 --> 00:18:30,090
gets filled in is the original field

475
00:18:28,590 --> 00:18:32,100
position that you want to put into the

476
00:18:30,090 --> 00:18:35,399
new place okay so we're now for bite

477
00:18:32,100 --> 00:18:37,110
scene okay so invite four we want the

478
00:18:35,400 --> 00:18:40,020
bike that was in position 12 because

479
00:18:37,110 --> 00:18:42,990
what packet length is a like 12 13 in

480
00:18:40,020 --> 00:18:45,929
our source so we fill in 12 and 13 into

481
00:18:42,990 --> 00:18:48,360
our packet length field however if you

482
00:18:45,929 --> 00:18:49,500
look so I don't think anybody will

483
00:18:48,360 --> 00:18:52,740
notice but back in the embossed

484
00:18:49,500 --> 00:18:54,809
description packet length it's actually

485
00:18:52,740 --> 00:18:56,670
four black white field so we actually

486
00:18:54,809 --> 00:18:59,129
need to pad in some zeros as well and

487
00:18:56,670 --> 00:19:00,929
that's done by sticking more FS so now

488
00:18:59,130 --> 00:19:03,330
we've got our first 2 field spell game

489
00:19:00,929 --> 00:19:06,230
so instead of 4 zeros then we take bites

490
00:19:03,330 --> 00:19:08,460
12 and 13 and then two more zeros right

491
00:19:06,230 --> 00:19:09,840
another cool thing with shuffles is as

492
00:19:08,460 --> 00:19:11,340
well as moving the data arrange it be

493
00:19:09,840 --> 00:19:12,240
duplicated just by putting the same

494
00:19:11,340 --> 00:19:14,399
numbers in twice

495
00:19:12,240 --> 00:19:16,880
so our next field is data length well

496
00:19:14,400 --> 00:19:21,110
that also needs to call by 12 and 15

497
00:19:16,880 --> 00:19:23,570
again 16 byte field 16 bit fields

498
00:19:21,110 --> 00:19:26,240
Zero's and then the rest of the data

499
00:19:23,570 --> 00:19:28,490
falls into the same pattern hey a v-line

500
00:19:26,240 --> 00:19:31,610
is a by supporting the 15 so they stick

501
00:19:28,490 --> 00:19:34,730
their next rrss field and Koshu bytes 4

502
00:19:31,610 --> 00:19:36,830
through 7 so well initially this can

503
00:19:34,730 --> 00:19:38,660
look quite complex is daunting it's

504
00:19:36,830 --> 00:19:40,100
actually relatively mechanical process

505
00:19:38,660 --> 00:19:41,750
whenever you're building at all you just

506
00:19:40,100 --> 00:19:44,949
fill in the position you want to take

507
00:19:41,750 --> 00:19:47,390
the bite strong picture shuffle Mouse

508
00:19:44,950 --> 00:19:49,040
this is what she looks like in our final

509
00:19:47,390 --> 00:19:50,960
code including line numbers prove it

510
00:19:49,040 --> 00:19:53,540
actually came to the DK source code same

511
00:19:50,960 --> 00:19:54,049
data just five days and here is how it's

512
00:19:53,540 --> 00:19:57,290
used

513
00:19:54,049 --> 00:19:58,790
hey we had four different fields in

514
00:19:57,290 --> 00:20:01,280
scattered coder would have to do four

515
00:19:58,790 --> 00:20:03,290
loads and four stores we can get it down

516
00:20:01,280 --> 00:20:06,710
there per descriptor to one load one

517
00:20:03,290 --> 00:20:08,720
shuffle and store Hey in the main loop

518
00:20:06,710 --> 00:20:10,669
we actually work up for descriptors at a

519
00:20:08,720 --> 00:20:13,100
time I'm showing two here again for

520
00:20:10,669 --> 00:20:14,450
simplicity so we load two descriptors

521
00:20:13,100 --> 00:20:16,280
this is just so we're going compiler

522
00:20:14,450 --> 00:20:18,919
reordering so we load descriptive one

523
00:20:16,280 --> 00:20:20,299
number 6 to 0 then we do two shuffles

524
00:20:18,919 --> 00:20:21,830
one of these descriptor to get the

525
00:20:20,299 --> 00:20:24,020
actual date and they're like and we'll

526
00:20:21,830 --> 00:20:26,510
order from two stores so one load

527
00:20:24,020 --> 00:20:28,639
shuffle store our package gets us all

528
00:20:26,510 --> 00:20:30,350
those fields in the right position okay

529
00:20:28,640 --> 00:20:33,650
so we're saving huge amounts of

530
00:20:30,350 --> 00:20:35,389
instruction ok so that's one way we can

531
00:20:33,650 --> 00:20:37,460
move data back and one thing we do in

532
00:20:35,390 --> 00:20:38,960
our polar driver and just briefly before

533
00:20:37,460 --> 00:20:42,070
I hand it back over to Harry I'll talk

534
00:20:38,960 --> 00:20:42,070
about the other kind of

535
00:20:42,470 --> 00:20:46,050
which is where we set things up for

536
00:20:44,520 --> 00:20:48,870
parallelism okay

537
00:20:46,050 --> 00:20:50,220
I talked a little about the status

538
00:20:48,870 --> 00:20:51,899
Vincent about how they don't get

539
00:20:50,220 --> 00:20:54,240
transferred directly into the M ball

540
00:20:51,900 --> 00:20:55,740
instead they're used to determine of the

541
00:20:54,240 --> 00:20:57,930
four package for processing and elutes

542
00:20:55,740 --> 00:20:59,520
whether they're valid or not but we

543
00:20:57,930 --> 00:21:00,930
don't want to do that individually or

544
00:20:59,520 --> 00:21:03,330
packaged because I could be wasteful

545
00:21:00,930 --> 00:21:06,540
instead we want to take all those status

546
00:21:03,330 --> 00:21:12,629
and error information I'm fine the four

547
00:21:06,540 --> 00:21:13,770
packets into a single register and we

548
00:21:12,630 --> 00:21:15,630
can do that using these other

549
00:21:13,770 --> 00:21:18,870
instructions these unpack instructions

550
00:21:15,630 --> 00:21:21,210
and here's a very brief diagram using

551
00:21:18,870 --> 00:21:23,879
super boxes and looking fancy of how you

552
00:21:21,210 --> 00:21:27,120
do that hey we don't have to use unpack

553
00:21:23,880 --> 00:21:29,190
I take the high half of each register of

554
00:21:27,120 --> 00:21:30,510
each pair of registers and merge them

555
00:21:29,190 --> 00:21:32,730
together as shown here in the middle row

556
00:21:30,510 --> 00:21:34,680
and then we use a non packed low to

557
00:21:32,730 --> 00:21:36,840
stick the low halves each one together

558
00:21:34,680 --> 00:21:39,450
so with three instructions we've gone

559
00:21:36,840 --> 00:21:41,550
from having the data spread across four

560
00:21:39,450 --> 00:21:43,740
registers to all the fields we care

561
00:21:41,550 --> 00:21:45,930
about before 32-bit values inside a

562
00:21:43,740 --> 00:21:48,750
single register and we can now operate

563
00:21:45,930 --> 00:21:51,570
I prayed upon a in parallel using our

564
00:21:48,750 --> 00:21:57,120
Cindy instructions okay and again the

565
00:21:51,570 --> 00:21:58,860
actual code in all its glory and we mask

566
00:21:57,120 --> 00:22:00,389
off the bits we care about and that then

567
00:21:58,860 --> 00:22:04,169
allows us to actually shrink it down

568
00:22:00,390 --> 00:22:06,090
even further from 128 bits to 64 I wish

569
00:22:04,170 --> 00:22:07,410
point we've been can go scale and do the

570
00:22:06,090 --> 00:22:09,600
rest the operations and scalar code

571
00:22:07,410 --> 00:22:11,220
because we've got a 64-bit value what

572
00:22:09,600 --> 00:22:13,679
we're actually doing here is a pop count

573
00:22:11,220 --> 00:22:15,720
which paints number one bit session so

574
00:22:13,680 --> 00:22:17,670
all we've done is we've masked off that

575
00:22:15,720 --> 00:22:19,830
everything but the valid bit so now we

576
00:22:17,670 --> 00:22:21,360
by doing a big camp we can work out how

577
00:22:19,830 --> 00:22:23,909
many the four packets we rarely are

578
00:22:21,360 --> 00:22:25,320
valid update our stats and determine if

579
00:22:23,910 --> 00:22:27,630
we need to blink after a loop or if

580
00:22:25,320 --> 00:22:29,700
you've got more packets to process okay

581
00:22:27,630 --> 00:22:32,040
so this is showing the advantages of

582
00:22:29,700 --> 00:22:34,410
using shuffles to very quickly move data

583
00:22:32,040 --> 00:22:36,090
about and then how we can use on packs

584
00:22:34,410 --> 00:22:37,830
to take this rhodesia

585
00:22:36,090 --> 00:22:39,570
read from different scriptures or

586
00:22:37,830 --> 00:22:43,790
different packets and combine it down

587
00:22:39,570 --> 00:22:43,790
into a single register that we can use

588
00:22:48,600 --> 00:22:52,840
so as promised I'd talk a little more

589
00:22:51,040 --> 00:22:54,760
about OVS and matching rules in

590
00:22:52,840 --> 00:22:56,169
particular so keeping that mini flow

591
00:22:54,760 --> 00:22:58,330
data structure in mind the one that we

592
00:22:56,170 --> 00:23:02,680
were talking about earlier if we look at

593
00:22:58,330 --> 00:23:05,470
what OBS does most of today in actual

594
00:23:02,680 --> 00:23:07,060
like matching code of a packet comes in

595
00:23:05,470 --> 00:23:08,920
we've parsed that packet we've made a

596
00:23:07,060 --> 00:23:10,929
mini flow the rest of the obvious

597
00:23:08,920 --> 00:23:12,910
pipeline or data path actually operates

598
00:23:10,930 --> 00:23:14,980
on the mini flow so the packet data

599
00:23:12,910 --> 00:23:17,740
isn't actually referred to anymore it's

600
00:23:14,980 --> 00:23:19,810
all the metadata that OVS can match on

601
00:23:17,740 --> 00:23:21,910
or code care about is going to be cached

602
00:23:19,810 --> 00:23:24,850
in this mini flow data structure so when

603
00:23:21,910 --> 00:23:27,460
we try and match a mini or a packet mini

604
00:23:24,850 --> 00:23:29,560
flow against the the rule set that our

605
00:23:27,460 --> 00:23:31,750
OVS received from an SDN controller

606
00:23:29,560 --> 00:23:34,270
somewhere what it's really doing is

607
00:23:31,750 --> 00:23:35,980
comparing mini flows so it doesn't refer

608
00:23:34,270 --> 00:23:37,360
to the packet anymore and refer to open

609
00:23:35,980 --> 00:23:39,310
flow rules everything becomes a mini

610
00:23:37,360 --> 00:23:40,870
fill it's a bit of an overloaded term

611
00:23:39,310 --> 00:23:43,870
for that reason so there are mini flows

612
00:23:40,870 --> 00:23:45,070
for rules for masks for packets etc if

613
00:23:43,870 --> 00:23:46,419
you've read the code base you may have

614
00:23:45,070 --> 00:23:48,100
like scratched your head like there's a

615
00:23:46,420 --> 00:23:50,200
lot of this data structure how does it

616
00:23:48,100 --> 00:23:52,780
work in theory or in concept it's

617
00:23:50,200 --> 00:23:54,250
actually quite simple what you have is a

618
00:23:52,780 --> 00:23:56,139
mini fill for a packet that's

619
00:23:54,250 --> 00:23:59,350
represented on the top here there's a

620
00:23:56,140 --> 00:24:01,630
table or a sub table that's essentially

621
00:23:59,350 --> 00:24:04,330
one to poll that OVS can match on so

622
00:24:01,630 --> 00:24:06,550
when you program an open flow rule to

623
00:24:04,330 --> 00:24:08,560
OVS and you match on let's say an IP

624
00:24:06,550 --> 00:24:12,070
field and a UDP field as this example

625
00:24:08,560 --> 00:24:13,990
shows then what OVS is going to do is

626
00:24:12,070 --> 00:24:16,360
it's going to create a sub table with

627
00:24:13,990 --> 00:24:17,410
those two properties so IP and UDP it's

628
00:24:16,360 --> 00:24:18,790
going to wild-card the rest of

629
00:24:17,410 --> 00:24:20,500
everything because obvious has this

630
00:24:18,790 --> 00:24:24,250
capability of doing wild card rule

631
00:24:20,500 --> 00:24:26,410
matching and then when our packet comes

632
00:24:24,250 --> 00:24:31,000
in it will try and compare it with this

633
00:24:26,410 --> 00:24:32,290
table or sub table so this is all

634
00:24:31,000 --> 00:24:33,760
happening inside the data path

635
00:24:32,290 --> 00:24:35,290
classifier of obvious I should specify

636
00:24:33,760 --> 00:24:36,580
obvious has multiple ways of matching

637
00:24:35,290 --> 00:24:38,560
packets this is all the data path

638
00:24:36,580 --> 00:24:41,110
classifier or the wild card matching

639
00:24:38,560 --> 00:24:42,760
engine so really from a scalar point of

640
00:24:41,110 --> 00:24:44,740
view what is it trying to do it's trying

641
00:24:42,760 --> 00:24:46,750
to find everything that's defined in the

642
00:24:44,740 --> 00:24:48,850
table so in this case IP and UDP

643
00:24:46,750 --> 00:24:51,280
it's trying to find the relevant block

644
00:24:48,850 --> 00:24:52,540
in the packet mini flow I mentioned

645
00:24:51,280 --> 00:24:55,030
earlier this was a dynamic data

646
00:24:52,540 --> 00:24:57,310
structure so it's not always in the same

647
00:24:55,030 --> 00:24:57,940
place depending on what properties that

648
00:24:57,310 --> 00:24:59,620
packet had

649
00:24:57,940 --> 00:25:02,169
if there were VLAN tags or if there was

650
00:24:59,620 --> 00:25:05,949
other properties maybe it was an ipv6

651
00:25:02,169 --> 00:25:08,860
and then ipv4 encapsulated packet those

652
00:25:05,950 --> 00:25:10,240
offsets are going to be different so OVS

653
00:25:08,860 --> 00:25:11,830
can't just do a straight look up into

654
00:25:10,240 --> 00:25:13,179
this mini flow and say load offset

655
00:25:11,830 --> 00:25:15,220
whatever like we usually would with a

656
00:25:13,179 --> 00:25:16,779
data structure in this case it has to

657
00:25:15,220 --> 00:25:18,789
actually iterate through the bits and

658
00:25:16,779 --> 00:25:20,710
try and find the block it's looking for

659
00:25:18,789 --> 00:25:22,899
so that's really the the compute

660
00:25:20,710 --> 00:25:25,960
workload that's going on here is loop

661
00:25:22,899 --> 00:25:28,120
across the packet mini flow and find the

662
00:25:25,960 --> 00:25:31,059
block that we care about so IP goes up

663
00:25:28,120 --> 00:25:33,879
to IP next we go again we have a loop to

664
00:25:31,059 --> 00:25:36,610
find that UDP block now OVS doesn't know

665
00:25:33,879 --> 00:25:38,769
at compile time usually what the table

666
00:25:36,610 --> 00:25:40,000
properties are so in this case there's

667
00:25:38,769 --> 00:25:41,980
two blocks but there could be three

668
00:25:40,000 --> 00:25:44,019
blocks so we could have nested loops one

669
00:25:41,980 --> 00:25:46,629
for the quantity of blocks want to find

670
00:25:44,019 --> 00:25:50,110
the actual block index in the scalar

671
00:25:46,629 --> 00:25:51,610
packet mini flow and then a branch to

672
00:25:50,110 --> 00:25:53,590
see if this one actually compared equal

673
00:25:51,610 --> 00:25:55,750
so it's it's kind of your your worst

674
00:25:53,590 --> 00:25:57,100
case scenario for branch prediction that

675
00:25:55,750 --> 00:25:58,779
you have nested for loops and then

676
00:25:57,100 --> 00:26:00,850
branches on the inside you don't want

677
00:25:58,779 --> 00:26:02,289
that from a performance point of view so

678
00:26:00,850 --> 00:26:04,209
let's look at the vectorized version or

679
00:26:02,289 --> 00:26:06,970
rather getting towards a vectorized

680
00:26:04,210 --> 00:26:08,860
version because first there was a lot of

681
00:26:06,970 --> 00:26:11,350
branches and for loops in this scalar

682
00:26:08,860 --> 00:26:12,969
implementation and branches and for

683
00:26:11,350 --> 00:26:16,389
loops are kind of or can be difficult to

684
00:26:12,970 --> 00:26:18,549
do sim D or vectorize processing with so

685
00:26:16,389 --> 00:26:20,740
if we look at from a more compute point

686
00:26:18,549 --> 00:26:23,230
of view is there a way that we can not

687
00:26:20,740 --> 00:26:25,600
like loop and find but actually

688
00:26:23,230 --> 00:26:27,940
calculate an offset for this packet mini

689
00:26:25,600 --> 00:26:30,009
flow so if we generate a bit mask when

690
00:26:27,940 --> 00:26:31,779
we create the table and then use the pop

691
00:26:30,009 --> 00:26:34,120
count instruction which will tell us how

692
00:26:31,779 --> 00:26:36,429
many 1 bits are set in any integer then

693
00:26:34,120 --> 00:26:38,709
we can actually like calculate the block

694
00:26:36,429 --> 00:26:40,659
index as opposed to looping through in a

695
00:26:38,710 --> 00:26:43,090
data structure and trying to find it and

696
00:26:40,659 --> 00:26:45,940
that happens to be a lot easier to do a

697
00:26:43,090 --> 00:26:47,649
vector version of so with this like

698
00:26:45,940 --> 00:26:49,299
approach the compute approach to this

699
00:26:47,649 --> 00:26:52,600
problem we can just get a lot more

700
00:26:49,299 --> 00:26:55,029
performance and even nicer is that I

701
00:26:52,600 --> 00:26:57,250
should touch on one more thing we still

702
00:26:55,029 --> 00:26:58,899
loop the number of blocks we have so in

703
00:26:57,250 --> 00:27:00,730
the previous example we had IP and UDP

704
00:26:58,899 --> 00:27:02,439
those are two blocks so this loop would

705
00:27:00,730 --> 00:27:05,470
execute twice for this particular sub

706
00:27:02,440 --> 00:27:08,080
table but what's even nicer is if we

707
00:27:05,470 --> 00:27:10,210
implement an avx-512 version of this

708
00:27:08,080 --> 00:27:12,039
same scalar code so the same compute

709
00:27:10,210 --> 00:27:14,350
that was happening on the previous slide

710
00:27:12,039 --> 00:27:16,090
we can now essentially loop unroll into

711
00:27:14,350 --> 00:27:18,549
the simle register so each iteration

712
00:27:16,090 --> 00:27:20,379
that was previously occurring like in

713
00:27:18,549 --> 00:27:22,509
scalar code each time each loop

714
00:27:20,379 --> 00:27:24,789
iteration so each time we'd go through

715
00:27:22,509 --> 00:27:27,789
this loop we can put like lay those out

716
00:27:24,789 --> 00:27:29,859
side by side into our our sim D register

717
00:27:27,789 --> 00:27:31,570
and we can compute all of those in

718
00:27:29,859 --> 00:27:33,070
parallel there's no loop carry

719
00:27:31,570 --> 00:27:35,559
dependence ease here we can just roll

720
00:27:33,070 --> 00:27:38,109
eight different blocks out into a single

721
00:27:35,559 --> 00:27:40,299
register and do all that compute using

722
00:27:38,109 --> 00:27:42,639
one instruction with multiple data each

723
00:27:40,299 --> 00:27:44,019
time so this gives you much more compute

724
00:27:42,639 --> 00:27:46,269
per cycle and just increases your

725
00:27:44,019 --> 00:27:48,820
performance by whatever 8x if you have

726
00:27:46,269 --> 00:27:52,119
eight lanes active so earlier we

727
00:27:48,820 --> 00:27:54,070
mentioned this K masks feature I'm also

728
00:27:52,119 --> 00:27:57,189
in the the previous example we only had

729
00:27:54,070 --> 00:27:59,289
two particular blocks we cared for so we

730
00:27:57,190 --> 00:28:00,970
need to be able to disabled lanes that

731
00:27:59,289 --> 00:28:03,249
we don't care for or be able to disable

732
00:28:00,970 --> 00:28:06,159
some compute somewhere and that's where

733
00:28:03,249 --> 00:28:08,200
this avx-512 K masks comes in as Bruce

734
00:28:06,159 --> 00:28:11,559
mentions my favorite and feature in

735
00:28:08,200 --> 00:28:13,389
avx-512 so it allows you to switch off

736
00:28:11,559 --> 00:28:15,940
flames and what that really means is you

737
00:28:13,389 --> 00:28:17,439
can do compute on a full register but in

738
00:28:15,940 --> 00:28:19,029
the locations where you don't want the

739
00:28:17,440 --> 00:28:20,979
compute to happen you can set a bit mask

740
00:28:19,029 --> 00:28:22,960
and also pass that to the instruction

741
00:28:20,979 --> 00:28:25,149
and it won't perform the compute on that

742
00:28:22,960 --> 00:28:27,099
particular Lane now that's really nice

743
00:28:25,149 --> 00:28:28,658
because that flexibility usually you

744
00:28:27,099 --> 00:28:29,830
would have to use extra instructions for

745
00:28:28,659 --> 00:28:33,220
in SSE in avx2

746
00:28:29,830 --> 00:28:34,989
but with the avx-512 k masks we get this

747
00:28:33,220 --> 00:28:36,970
feature and and became ask is

748
00:28:34,989 --> 00:28:38,979
represented here on the top right it

749
00:28:36,970 --> 00:28:45,009
gives you a huge amount of flexibility

750
00:28:38,979 --> 00:28:47,109
or orthogonal orthogonal T orthogonal

751
00:28:45,009 --> 00:28:48,970
kind of way of writing your code what

752
00:28:47,109 --> 00:28:50,918
that really means is the the width of

753
00:28:48,970 --> 00:28:52,869
the register you use you can now

754
00:28:50,919 --> 00:28:55,720
manually define and that's really really

755
00:28:52,869 --> 00:28:57,399
useful I'm so you don't have explicit

756
00:28:55,720 --> 00:28:58,809
plans in your instruction stream anymore

757
00:28:57,399 --> 00:29:00,699
that would have been the previous way to

758
00:28:58,809 --> 00:29:03,099
solve this type of problem in sse code

759
00:29:00,700 --> 00:29:05,470
and it's much easier to manage Perlane

760
00:29:03,099 --> 00:29:06,908
ops so based on Bruce's packet

761
00:29:05,470 --> 00:29:09,599
descriptor things sometimes we want to

762
00:29:06,909 --> 00:29:12,190
reduce the CRC offset in a packet to

763
00:29:09,599 --> 00:29:13,720
away from our statistics bytes that's

764
00:29:12,190 --> 00:29:16,029
one way that we could do this we could

765
00:29:13,720 --> 00:29:18,099
add for or remove for from an entire

766
00:29:16,029 --> 00:29:19,479
register but only enable the one-lane

767
00:29:18,099 --> 00:29:22,090
that we wanted that action to take place

768
00:29:19,479 --> 00:29:24,659
on so that's a nice usage of the kay

769
00:29:22,090 --> 00:29:24,658
masks as well

770
00:29:28,050 --> 00:29:35,080
so in summary there are a number of

771
00:29:32,559 --> 00:29:37,600
benefits of vectorization I hope this

772
00:29:35,080 --> 00:29:40,720
talk has been useful in showing how we

773
00:29:37,600 --> 00:29:43,000
can take packets some type of processing

774
00:29:40,720 --> 00:29:45,630
workloads hopefully a lot our common

775
00:29:43,000 --> 00:29:48,100
tactic rustling operations and actually

776
00:29:45,630 --> 00:29:50,260
adjust some our work with them to take

777
00:29:48,100 --> 00:29:52,300
advantage of the vectorization you know

778
00:29:50,260 --> 00:29:54,190
for the things given here like be now to

779
00:29:52,300 --> 00:29:56,409
do larger loads and stores so you got

780
00:29:54,190 --> 00:29:58,840
fewer instructions to get data in and

781
00:29:56,410 --> 00:30:00,790
out of the core or to increase the

782
00:29:58,840 --> 00:30:03,010
amount of computer doing per instruction

783
00:30:00,790 --> 00:30:05,230
while there whether it be working on

784
00:30:03,010 --> 00:30:06,970
bigger blocks of data or whether working

785
00:30:05,230 --> 00:30:09,520
on multiple blocks of data from several

786
00:30:06,970 --> 00:30:10,809
packets in parallel and then we've also

787
00:30:09,520 --> 00:30:14,710
touched on some of the novel

788
00:30:10,809 --> 00:30:16,120
instructions you have in the AVX and

789
00:30:14,710 --> 00:30:18,160
this is the instruction sets for doing

790
00:30:16,120 --> 00:30:21,159
shopping and masking that you can then

791
00:30:18,160 --> 00:30:23,770
use again to get more work done per

792
00:30:21,160 --> 00:30:26,710
cycle because it really all doors boils

793
00:30:23,770 --> 00:30:28,330
down to the being able to have fewer

794
00:30:26,710 --> 00:30:30,250
instructions for the same amount of work

795
00:30:28,330 --> 00:30:32,199
and whenever we take a piece of cord and

796
00:30:30,250 --> 00:30:35,320
vectorizer this then inevitably what we

797
00:30:32,200 --> 00:30:37,150
find and what we love to see as long as

798
00:30:35,320 --> 00:30:39,730
it can be spectacular reductions and the

799
00:30:37,150 --> 00:30:41,530
number of instructions and this is what

800
00:30:39,730 --> 00:30:45,880
then can give us our performance benefit

801
00:30:41,530 --> 00:30:47,559
from factorization okay so see the signs

802
00:30:45,880 --> 00:30:48,870
we have just five minutes left

803
00:30:47,559 --> 00:30:53,280
so we have a couple minutes for

804
00:30:48,870 --> 00:30:53,280
questions on this

805
00:31:05,610 --> 00:31:10,269
okay so the question was how much was

806
00:31:08,049 --> 00:31:11,950
actually gained from using simply

807
00:31:10,269 --> 00:31:13,899
instructions that we had multiple lanes

808
00:31:11,950 --> 00:31:16,659
of data being operated on in parallel as

809
00:31:13,899 --> 00:31:19,149
opposed to branch or reductions in

810
00:31:16,659 --> 00:31:20,590
branch count or you know could we do

811
00:31:19,149 --> 00:31:23,110
this with the C move instruction for

812
00:31:20,590 --> 00:31:24,668
example I'm it depends on the type of

813
00:31:23,110 --> 00:31:26,350
computer ultimately right a lot of these

814
00:31:24,669 --> 00:31:29,049
questions engineering questions are it

815
00:31:26,350 --> 00:31:31,509
depends in practice add the sim D gives

816
00:31:29,049 --> 00:31:33,309
us a huge huge speed-up so I'll let you

817
00:31:31,509 --> 00:31:35,320
come Bruce on the descriptor processing

818
00:31:33,309 --> 00:31:37,090
side of things I know in the OBS case

819
00:31:35,320 --> 00:31:39,730
just the fact that we can unroll loops

820
00:31:37,090 --> 00:31:41,830
literally just gives us that X number of

821
00:31:39,730 --> 00:31:44,350
reduction in instructions right you saw

822
00:31:41,830 --> 00:31:46,059
the compute if you unroll that you're

823
00:31:44,350 --> 00:31:47,830
not losing anything anywhere it's just

824
00:31:46,059 --> 00:31:48,970
doing more in parallel so there's

825
00:31:47,830 --> 00:31:50,710
certain things like that that just make

826
00:31:48,970 --> 00:31:52,119
a lot of sense from the mini flow

827
00:31:50,710 --> 00:31:54,879
extract so the the first part of the

828
00:31:52,119 --> 00:31:56,918
presentation that one because we take

829
00:31:54,879 --> 00:31:58,658
kind of a novel approach as well because

830
00:31:56,919 --> 00:32:01,629
we can use so much data in one register

831
00:31:58,659 --> 00:32:02,919
that gives us huge speed ups so we're

832
00:32:01,629 --> 00:32:05,859
talking I've seen that run in five

833
00:32:02,919 --> 00:32:08,169
cycles to like basically probe a

834
00:32:05,859 --> 00:32:10,449
specific pattern and move to a specific

835
00:32:08,169 --> 00:32:12,460
mini flow for that packet whereas I've

836
00:32:10,450 --> 00:32:15,759
measured it somewhere around 60 to 70

837
00:32:12,460 --> 00:32:17,889
cycles in scalar code so there's orders

838
00:32:15,759 --> 00:32:34,450
of magnitude there in certain situations

839
00:32:17,889 --> 00:32:35,709
right and the answer is it depends I try

840
00:32:34,450 --> 00:32:37,200
to remember don't remember the exact

841
00:32:35,710 --> 00:32:39,879
numbers but as far as I remember was

842
00:32:37,200 --> 00:32:41,950
15-20 percent faster going from s is e

843
00:32:39,879 --> 00:32:43,330
to the x/2 there was no branch remover

844
00:32:41,950 --> 00:32:46,509
or anything like that it was just going

845
00:32:43,330 --> 00:32:49,090
to bigger vectors being able to do more

846
00:32:46,509 --> 00:32:52,029
work per instruction and we got

847
00:32:49,090 --> 00:32:54,789
additional benefit from that okay so yes

848
00:32:52,029 --> 00:32:56,409
going branch free try and give benefits

849
00:32:54,789 --> 00:32:58,960
going branch free and then vectorizing a

850
00:32:56,409 --> 00:33:01,060
table gives you additional benefits so

851
00:32:58,960 --> 00:33:04,290
please do

852
00:33:01,060 --> 00:33:04,290
yep question over here

853
00:33:23,679 --> 00:33:30,620
okay so we'll summarize the question

854
00:33:26,840 --> 00:33:56,620
deals using a VX give us a performance

855
00:33:30,620 --> 00:34:00,139
benefit is that too simple or yes we see

856
00:33:56,620 --> 00:34:09,618
improvements in the overall proof like

857
00:34:00,140 --> 00:34:13,000
performance of obvious no no other

858
00:34:09,619 --> 00:34:13,000
questions and oh yeah yourself

859
00:34:29,679 --> 00:34:34,969
yes so it in most low-level packet

860
00:34:33,650 --> 00:34:36,410
processing libraries that are well

861
00:34:34,969 --> 00:34:37,939
optimized we try and cache line line

862
00:34:36,409 --> 00:34:39,980
things we are very aware of where cache

863
00:34:37,940 --> 00:34:41,690
line boundaries are and in the case of

864
00:34:39,980 --> 00:34:43,520
obvious we try and do as much as we can

865
00:34:41,690 --> 00:34:45,020
however it's not always possible to

866
00:34:43,520 --> 00:34:46,900
actually do cache aligning for

867
00:34:45,020 --> 00:34:49,400
everything purely because it might be

868
00:34:46,900 --> 00:34:50,630
comprised as part of a larger data

869
00:34:49,400 --> 00:34:52,700
structure where the mini flow is

870
00:34:50,630 --> 00:34:54,260
embedded in the inside and over time

871
00:34:52,699 --> 00:34:56,540
that could change or even it could just

872
00:34:54,260 --> 00:34:59,780
be online right from the start and in

873
00:34:56,540 --> 00:35:02,840
practice the loads of cash local data

874
00:34:59,780 --> 00:35:04,640
even in an avx-512 register that

875
00:35:02,840 --> 00:35:06,770
referred to as a split load that it's

876
00:35:04,640 --> 00:35:08,569
not cache line aligned and have very

877
00:35:06,770 --> 00:35:10,670
little performance impact in my

878
00:35:08,570 --> 00:35:12,080
experience as opposed to the amount of

879
00:35:10,670 --> 00:35:15,410
benefit in compute that you're actually

880
00:35:12,080 --> 00:35:16,549
getting so I mean if your loads are your

881
00:35:15,410 --> 00:35:19,040
bottleneck then there's something very

882
00:35:16,550 --> 00:35:20,900
strange in your code going on so so from

883
00:35:19,040 --> 00:35:23,750
that point of view and a good question I

884
00:35:20,900 --> 00:35:25,900
don't think it's concerned that or it's

885
00:35:23,750 --> 00:35:28,100
not something I've experienced myself

886
00:35:25,900 --> 00:35:29,300
great work in form time's up thank you

887
00:35:28,100 --> 00:35:35,799
very much

888
00:35:29,300 --> 00:35:35,800
[Applause]

