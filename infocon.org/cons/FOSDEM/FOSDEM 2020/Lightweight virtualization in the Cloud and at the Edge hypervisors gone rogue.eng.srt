1
00:00:13,670 --> 00:00:23,580
Thanks hi old I'm Anastasia Stannis my

2
00:00:20,970 --> 00:00:27,029
talk is about light with hypervisors in

3
00:00:23,580 --> 00:00:33,199
the cloud above the aides I'm going to

4
00:00:27,029 --> 00:00:36,140
talk about our work in our team we are a

5
00:00:33,200 --> 00:00:39,750
youngest and me we're doing research in

6
00:00:36,140 --> 00:00:43,260
hypervisors and and the low level parts

7
00:00:39,750 --> 00:00:45,420
of the stack we are almost seven people

8
00:00:43,260 --> 00:00:47,610
most of the things here you can ping us

9
00:00:45,420 --> 00:00:50,030
right there in front you can think of

10
00:00:47,610 --> 00:00:53,040
any time to grab a coffee or a beer

11
00:00:50,030 --> 00:00:54,180
we're working on on the lower level

12
00:00:53,040 --> 00:00:57,410
parts of the stock

13
00:00:54,180 --> 00:01:01,830
meaning with hypervisors with containers

14
00:00:57,410 --> 00:01:06,170
with antenna runtimes with storage with

15
00:01:01,830 --> 00:01:08,640
uni kernels and we're also working on

16
00:01:06,170 --> 00:01:11,969
accessing hardware accelerators from

17
00:01:08,640 --> 00:01:15,869
within VMs or containers or unique

18
00:01:11,969 --> 00:01:24,419
animals we're based in the UK in Greece

19
00:01:15,869 --> 00:01:27,469
and in Spain so this talk is about how

20
00:01:24,420 --> 00:01:29,909
we should handle the hypervisor layers

21
00:01:27,469 --> 00:01:35,780
and that and the virtualization layers

22
00:01:29,909 --> 00:01:38,729
in general at the edge so people are

23
00:01:35,780 --> 00:01:40,619
using micro services based approaches

24
00:01:38,729 --> 00:01:42,210
they're using platform as a service

25
00:01:40,619 --> 00:01:45,119
software as a service function of the

26
00:01:42,210 --> 00:01:50,329
service that several staff and they have

27
00:01:45,119 --> 00:01:55,229
been using hypervisors or sandbox

28
00:01:50,329 --> 00:02:00,329
environments or hybrid approaches on on

29
00:01:55,229 --> 00:02:02,009
this level so we have been working on on

30
00:02:00,329 --> 00:02:04,999
this kind of stuff and trying to

31
00:02:02,009 --> 00:02:08,429
understand which is best for its

32
00:02:04,999 --> 00:02:13,290
solution for its for the workloads that

33
00:02:08,429 --> 00:02:17,670
people are running we will present a

34
00:02:13,290 --> 00:02:18,410
minimal light with vm m which interfaces

35
00:02:17,670 --> 00:02:21,679
directly

36
00:02:18,410 --> 00:02:25,280
with a VM and some of the work that we

37
00:02:21,680 --> 00:02:30,680
did to port the Firecracker on on a

38
00:02:25,280 --> 00:02:33,860
Raspberry Pi so as as I mentioned people

39
00:02:30,680 --> 00:02:36,620
are using containers sandboxes micro

40
00:02:33,860 --> 00:02:41,570
vm's micro via MEMS all unique kernels

41
00:02:36,620 --> 00:02:44,050
were not sure about that and we we have

42
00:02:41,570 --> 00:02:47,930
seen that the community has introduced

43
00:02:44,050 --> 00:02:52,100
some lower overhead via MEMS that can

44
00:02:47,930 --> 00:02:54,940
host these approaches people are using

45
00:02:52,100 --> 00:02:58,989
containers and unique Amazon containers

46
00:02:54,940 --> 00:03:02,270
they're using sandbox environments like

47
00:02:58,990 --> 00:03:04,700
that they're using second to actually

48
00:03:02,270 --> 00:03:06,670
contain a specific workload within a

49
00:03:04,700 --> 00:03:11,619
specific enclaved

50
00:03:06,670 --> 00:03:15,500
they're using KVM to isolate workloads

51
00:03:11,620 --> 00:03:18,620
there's work on solar 5 that the former

52
00:03:15,500 --> 00:03:22,070
UK event you given stuff there's

53
00:03:18,620 --> 00:03:28,310
firecracker this rusty and mam or cross

54
00:03:22,070 --> 00:03:31,459
VM all that stuff but if we if we try to

55
00:03:28,310 --> 00:03:34,370
run this kind of stuff on on a low power

56
00:03:31,459 --> 00:03:38,630
device on a Raspberry Pi on a on an

57
00:03:34,370 --> 00:03:43,160
Nvidia objection board we're getting

58
00:03:38,630 --> 00:03:46,630
issues there seems to be a lot of of

59
00:03:43,160 --> 00:03:50,270
contention in these kind of boards

60
00:03:46,630 --> 00:03:54,280
additionally these boards are built to

61
00:03:50,270 --> 00:03:59,900
have extra hardware to be able to

62
00:03:54,280 --> 00:04:06,050
accelerate specific applications like NP

63
00:03:59,900 --> 00:04:12,560
use or GPUs specifically to handle ML

64
00:04:06,050 --> 00:04:16,850
workloads and and stuff like that so if

65
00:04:12,560 --> 00:04:19,430
we try to run a VM on on this kind of

66
00:04:16,850 --> 00:04:24,980
devices where we will probably end up

67
00:04:19,430 --> 00:04:27,790
with either Zen or or TV M so the I'm an

68
00:04:24,980 --> 00:04:30,610
Amazon guy so foolish

69
00:04:27,790 --> 00:04:34,360
I've been working with them for quite

70
00:04:30,610 --> 00:04:38,920
some time so I'm a more biased on their

71
00:04:34,360 --> 00:04:41,950
approach so Zen is is a bare-metal

72
00:04:38,920 --> 00:04:46,390
hypervisor and we are men there is no

73
00:04:41,950 --> 00:04:50,229
mode treaties between the the monitor

74
00:04:46,390 --> 00:04:52,719
and the hypervisor actually JVM is a is

75
00:04:50,230 --> 00:04:57,460
Apache it's it's actually support for

76
00:04:52,720 --> 00:05:00,340
the hardware extensions using a an

77
00:04:57,460 --> 00:05:03,909
emulator in in user space there have

78
00:05:00,340 --> 00:05:08,560
been approaches where people have been

79
00:05:03,910 --> 00:05:11,500
not have been optimizing the the DMM

80
00:05:08,560 --> 00:05:13,390
worth came alight with cross VM with

81
00:05:11,500 --> 00:05:21,580
rusty I'm with firecracker with solo 5

82
00:05:13,390 --> 00:05:28,930
stuff with the HVT tender at least so we

83
00:05:21,580 --> 00:05:31,690
think that on one part KVM is really

84
00:05:28,930 --> 00:05:33,640
useful in in terms of the hardware of

85
00:05:31,690 --> 00:05:39,040
the of the interface for the hardware

86
00:05:33,640 --> 00:05:41,590
extensions for VMs so it's it's easy to

87
00:05:39,040 --> 00:05:44,980
debug it's easier to debug on Zen

88
00:05:41,590 --> 00:05:49,929
because it's the the most of most of the

89
00:05:44,980 --> 00:05:52,660
vmm is in the user space linux has all

90
00:05:49,930 --> 00:05:55,120
the available device drivers to be

91
00:05:52,660 --> 00:05:58,930
handled by by the system so there's no

92
00:05:55,120 --> 00:06:02,230
custom porting there on the other hand

93
00:05:58,930 --> 00:06:05,290
then has the VM and the hypervisor on

94
00:06:02,230 --> 00:06:08,260
the same context so it's it's a bit

95
00:06:05,290 --> 00:06:10,930
faster in terms of spawning a guest of

96
00:06:08,260 --> 00:06:14,560
handling the memory of the guest and the

97
00:06:10,930 --> 00:06:18,340
hardware extensions for for the memory

98
00:06:14,560 --> 00:06:20,610
management but we need a driver domain

99
00:06:18,340 --> 00:06:23,440
to handle device drivers to act to

100
00:06:20,610 --> 00:06:33,130
interface with the external world of the

101
00:06:23,440 --> 00:06:34,960
nodes that's a figure of how how kayvyun

102
00:06:33,130 --> 00:06:38,230
handles the VM running

103
00:06:34,960 --> 00:06:39,820
so there are device drivers in the Linux

104
00:06:38,230 --> 00:06:42,130
kernel there's the network and

105
00:06:39,820 --> 00:06:47,650
look stuck there are the functions that

106
00:06:42,130 --> 00:06:48,969
KVM offers to to provide this kind of

107
00:06:47,650 --> 00:06:51,310
isolation through the hardware

108
00:06:48,970 --> 00:06:55,650
extensions there's a VM M running in

109
00:06:51,310 --> 00:06:59,010
user space on the on the left side that

110
00:06:55,650 --> 00:07:03,310
handles all the binary loading for the

111
00:06:59,010 --> 00:07:06,969
VM OS to run some of the memory

112
00:07:03,310 --> 00:07:09,370
management all the PV drivers and the

113
00:07:06,970 --> 00:07:11,710
the exit handler for the VM when when a

114
00:07:09,370 --> 00:07:14,470
privileged instruction needs to be

115
00:07:11,710 --> 00:07:18,609
executed and on the right side is the

116
00:07:14,470 --> 00:07:22,180
non route mode where the VM is running

117
00:07:18,610 --> 00:07:24,010
so on on a VM enter there's the this the

118
00:07:22,180 --> 00:07:26,950
streets from route mode to normal mode

119
00:07:24,010 --> 00:07:30,130
at least on the x86 architecture the

120
00:07:26,950 --> 00:07:32,979
application is running or in in user

121
00:07:30,130 --> 00:07:37,000
space there's a runtime there are the

122
00:07:32,980 --> 00:07:41,110
drivers to interface with the monitor so

123
00:07:37,000 --> 00:07:43,270
it switches to kennel space on non earth

124
00:07:41,110 --> 00:07:46,540
mode then the PV drivers communicate

125
00:07:43,270 --> 00:07:50,740
with the PV drivers of of the monitor

126
00:07:46,540 --> 00:07:54,120
there's another world switch there with

127
00:07:50,740 --> 00:07:57,400
an exit with a with a VM exit and then

128
00:07:54,120 --> 00:08:01,600
there's another there is another mode

129
00:07:57,400 --> 00:08:03,609
treats to KVM to handle all the all the

130
00:08:01,600 --> 00:08:05,740
hardware specific stuff I mean like in

131
00:08:03,610 --> 00:08:10,300
the in them in the network occasionally

132
00:08:05,740 --> 00:08:16,120
or in in the block case so all these

133
00:08:10,300 --> 00:08:18,310
paths seem a bit they they seem to

134
00:08:16,120 --> 00:08:25,510
produce a lot of overhead when handling

135
00:08:18,310 --> 00:08:30,010
IO in in the same case the good thing is

136
00:08:25,510 --> 00:08:34,150
that there's no there's no redundant

137
00:08:30,010 --> 00:08:37,240
mode switch but still we need a helper

138
00:08:34,150 --> 00:08:41,289
driver domain to be able to handle

139
00:08:37,240 --> 00:08:43,120
device access so actually there is an

140
00:08:41,289 --> 00:08:45,419
extra mode street and the next are world

141
00:08:43,120 --> 00:08:45,419
treats

142
00:08:47,280 --> 00:08:54,010
so we have been trying to understand

143
00:08:51,210 --> 00:08:58,870
which are the overheads when running

144
00:08:54,010 --> 00:09:03,760
stuff at low power devices and to do

145
00:08:58,870 --> 00:09:07,390
that we we explored several lightweight

146
00:09:03,760 --> 00:09:10,480
hypervisors and we we executed them on a

147
00:09:07,390 --> 00:09:17,980
number of low-power devices are based

148
00:09:10,480 --> 00:09:22,210
and on x86 so we we used a lot of tools

149
00:09:17,980 --> 00:09:25,630
from from the community we used the the

150
00:09:22,210 --> 00:09:29,320
RAM Ranjini kernel we used the Mira's OS

151
00:09:25,630 --> 00:09:34,750
unique Ehrmann we run Redis and nginx

152
00:09:29,320 --> 00:09:37,420
and the DNS example on on solar 5 on the

153
00:09:34,750 --> 00:09:41,470
on the KVM tender of Scylla 5 which is

154
00:09:37,420 --> 00:09:46,599
solar 5 hv t on firecracker on on chemo

155
00:09:41,470 --> 00:09:51,580
and while sulfide worked out of the box

156
00:09:46,600 --> 00:09:54,400
on on a Raspberry Pi the it's it's the

157
00:09:51,580 --> 00:09:56,440
first thing that that we tried we tried

158
00:09:54,400 --> 00:10:00,459
to run firecracker but it didn't work

159
00:09:56,440 --> 00:10:03,760
because there's no geek support for for

160
00:10:00,460 --> 00:10:07,000
the geek v2 version of of the interrupt

161
00:10:03,760 --> 00:10:11,410
controller solar 5 actually works

162
00:10:07,000 --> 00:10:15,590
because there's no interrupt handling so

163
00:10:11,410 --> 00:10:16,920
we we run this simple unit kernel

164
00:10:15,590 --> 00:10:21,100
[Music]

165
00:10:16,920 --> 00:10:25,150
example so we with the blue bars we see

166
00:10:21,100 --> 00:10:28,360
Khemu we have the client running on in

167
00:10:25,150 --> 00:10:32,680
on the same host and the VM running on

168
00:10:28,360 --> 00:10:35,140
kaymu on a on a CD core so the blue

169
00:10:32,680 --> 00:10:37,870
lines show the the chemo results these

170
00:10:35,140 --> 00:10:43,030
are requests per second so higher is

171
00:10:37,870 --> 00:10:45,970
better and the red lines show salah

172
00:10:43,030 --> 00:10:51,520
fiber hv t there is some kind of

173
00:10:45,970 --> 00:10:56,680
improvement but still we think that it's

174
00:10:51,520 --> 00:11:00,460
not enough so we we wanted to try how

175
00:10:56,680 --> 00:11:06,800
firecracker would respond to this

176
00:11:00,460 --> 00:11:12,190
to the set up firecracker is a huge

177
00:11:06,800 --> 00:11:18,140
space monitor written in rust AWS Amazon

178
00:11:12,190 --> 00:11:21,260
introduced it there was already support

179
00:11:18,140 --> 00:11:28,310
for armed devices so what we had to do

180
00:11:21,260 --> 00:11:30,710
was to just port gig v2 support we

181
00:11:28,310 --> 00:11:32,420
managed to drop stirring this effort

182
00:11:30,710 --> 00:11:37,550
which is good so far cracker now

183
00:11:32,420 --> 00:11:43,490
supports I Raspberry Pi 4 and we run the

184
00:11:37,550 --> 00:11:47,240
same experiment we see that that

185
00:11:43,490 --> 00:11:54,080
firecracker behaves a bit like chemo and

186
00:11:47,240 --> 00:12:00,920
solar 5 is still a better than than

187
00:11:54,080 --> 00:12:03,640
those two approaches but still we we

188
00:12:00,920 --> 00:12:12,439
think that there is a space for

189
00:12:03,640 --> 00:12:15,890
improvement in this space so so actually

190
00:12:12,440 --> 00:12:18,050
we we say that that very the

191
00:12:15,890 --> 00:12:20,980
requirements for a for a work load to be

192
00:12:18,050 --> 00:12:24,859
running on on such a low power device

193
00:12:20,980 --> 00:12:27,350
should be that we need a driver for the

194
00:12:24,860 --> 00:12:31,790
hardware extensions we need access to

195
00:12:27,350 --> 00:12:34,940
the hardware so an interface a device

196
00:12:31,790 --> 00:12:37,880
driver for the hardware we need to

197
00:12:34,940 --> 00:12:41,470
define the ABI for the workload to be

198
00:12:37,880 --> 00:12:46,910
running will it be a unique kernel Linux

199
00:12:41,470 --> 00:12:50,210
something else and we need that a VM and

200
00:12:46,910 --> 00:12:53,480
we and we need some kind of software to

201
00:12:50,210 --> 00:12:55,670
be able to access and interface with the

202
00:12:53,480 --> 00:13:01,250
hardware extensions and to handle via

203
00:12:55,670 --> 00:13:04,910
mentor and VM exits so on

204
00:13:01,250 --> 00:13:06,950
we think that KVM is fine it's it's a

205
00:13:04,910 --> 00:13:11,360
great example for for the driver for

206
00:13:06,950 --> 00:13:13,460
most platforms we think that the Linux

207
00:13:11,360 --> 00:13:16,070
kernel is the most used thing

208
00:13:13,460 --> 00:13:19,399
so we have drivers for almost every

209
00:13:16,070 --> 00:13:21,710
device available regarding the the

210
00:13:19,399 --> 00:13:26,240
binary interface were experimenting with

211
00:13:21,710 --> 00:13:29,600
solo 5 we want to try micro VM the the

212
00:13:26,240 --> 00:13:34,450
the firecracker approach or even the

213
00:13:29,600 --> 00:13:42,440
Linux API and for the vmm we introduce

214
00:13:34,450 --> 00:13:45,170
our own monitor so kV mm is actually a v

215
00:13:42,440 --> 00:13:47,660
mm ramming in the linux kernel it

216
00:13:45,170 --> 00:13:52,010
handles a VM enters and the VM exits

217
00:13:47,660 --> 00:13:56,319
just the same way as km o or solo 5/8 VT

218
00:13:52,010 --> 00:14:01,279
and it it interfaces with network and

219
00:13:56,320 --> 00:14:07,880
block stock directly in the kernel so

220
00:14:01,279 --> 00:14:11,020
this is an equivalent figure how off of

221
00:14:07,880 --> 00:14:14,120
how a VM is running this is all in in

222
00:14:11,020 --> 00:14:17,600
internal space so there is no mode

223
00:14:14,120 --> 00:14:18,260
switch on on the VM exit and on via

224
00:14:17,600 --> 00:14:23,089
Mentors

225
00:14:18,260 --> 00:14:27,490
there is nothing that would interrupt

226
00:14:23,089 --> 00:14:30,589
the execution the VM is running on the

227
00:14:27,490 --> 00:14:34,459
under eye on on the right part of the of

228
00:14:30,589 --> 00:14:38,660
the graph and the PV drivers are

229
00:14:34,459 --> 00:14:42,290
interfacing with the vm m in the linux

230
00:14:38,660 --> 00:14:45,370
kernel so there's only a root mode to do

231
00:14:42,290 --> 00:14:48,770
non-root world suites

232
00:14:45,370 --> 00:14:52,220
it's it's working progress so we're

233
00:14:48,770 --> 00:14:58,069
working on that we have support for x86

234
00:14:52,220 --> 00:15:01,010
and arm we are able to run sulla 5

235
00:14:58,070 --> 00:15:03,860
applications and everything that support

236
00:15:01,010 --> 00:15:06,680
that runs on top of solo 5 so we can run

237
00:15:03,860 --> 00:15:10,190
rampant greenie kernels meritorious unit

238
00:15:06,680 --> 00:15:16,099
craft recently we have tried to

239
00:15:10,190 --> 00:15:18,680
integrate noci compatible runtime we

240
00:15:16,100 --> 00:15:24,230
forked the work that the nabla

241
00:15:18,680 --> 00:15:26,540
containers thing have done so it's as

242
00:15:24,230 --> 00:15:27,290
easy as running dhakkir on with our

243
00:15:26,540 --> 00:15:34,040
runtime

244
00:15:27,290 --> 00:15:37,759
and specific image so we run the same

245
00:15:34,040 --> 00:15:41,769
experiment with Redis that's up I should

246
00:15:37,759 --> 00:15:44,630
mention that these results are on on x86

247
00:15:41,769 --> 00:15:47,540
so we we can see that there is

248
00:15:44,630 --> 00:15:50,870
improvement compared to eme on

249
00:15:47,540 --> 00:15:55,509
firecracker and also improvement

250
00:15:50,870 --> 00:15:55,509
compared to the generic solo 5 approach

251
00:15:55,899 --> 00:16:04,339
regarding latency we have run a micro

252
00:16:01,790 --> 00:16:06,500
benchmark ring for further for the

253
00:16:04,339 --> 00:16:10,940
round-trip latency handling on x86 and

254
00:16:06,500 --> 00:16:14,389
own arm we see that that k vm m is so

255
00:16:10,940 --> 00:16:16,639
this is time so lower is better we can

256
00:16:14,389 --> 00:16:20,569
see that k vm m outperforms all other

257
00:16:16,639 --> 00:16:24,829
approaches and and the same stands for

258
00:16:20,569 --> 00:16:32,449
forearm for for the arm case we run dot

259
00:16:24,829 --> 00:16:39,849
America thus vim 3 board we could do a

260
00:16:32,449 --> 00:16:43,839
small demo for showcasing our approach I

261
00:16:39,850 --> 00:16:43,839
have a screencast

262
00:16:48,770 --> 00:17:04,770
I have a Korean custom luxury of kind of

263
00:16:52,080 --> 00:17:09,059
zoom can you see I'm not sure how to

264
00:17:04,770 --> 00:17:12,540
zoom on that so the whole point let me

265
00:17:09,059 --> 00:17:16,079
let me just skip that I'll just say what

266
00:17:12,540 --> 00:17:21,209
what the demo is about so we login into

267
00:17:16,079 --> 00:17:26,419
a into an Nvidia jets on nano board and

268
00:17:21,209 --> 00:17:28,980
we actually run we execute doctor run

269
00:17:26,420 --> 00:17:32,880
and and the container image with our

270
00:17:28,980 --> 00:17:37,770
runtime and we we see that we if we

271
00:17:32,880 --> 00:17:40,679
point a DNS client to this IP address

272
00:17:37,770 --> 00:17:46,889
that that the runtime has given us we

273
00:17:40,679 --> 00:17:51,929
see that zones are being resolved as

274
00:17:46,890 --> 00:17:58,500
they should so it's actually showcasing

275
00:17:51,929 --> 00:18:12,679
our vmm on an unarmed device let me go

276
00:17:58,500 --> 00:18:18,480
back I think okay let me conclude so

277
00:18:12,679 --> 00:18:21,030
we've shown with some TV mm which is a

278
00:18:18,480 --> 00:18:23,840
minimal virtual machine monitor residing

279
00:18:21,030 --> 00:18:30,240
in the Linux kernel we currently support

280
00:18:23,840 --> 00:18:32,639
the sole of five ABI and we're planning

281
00:18:30,240 --> 00:18:38,010
to have a pre-alpha release sometime

282
00:18:32,640 --> 00:18:41,040
next month our next steps are to support

283
00:18:38,010 --> 00:18:47,250
more ABI so we would like to try running

284
00:18:41,040 --> 00:18:51,450
something more let's say extending our

285
00:18:47,250 --> 00:18:53,940
our ability to run more applications we

286
00:18:51,450 --> 00:18:56,370
would like to study the the container

287
00:18:53,940 --> 00:18:59,220
integration there's some work we have

288
00:18:56,370 --> 00:19:02,158
been doing some work on in

289
00:18:59,220 --> 00:19:07,049
eating container storage and uni Kendall

290
00:19:02,159 --> 00:19:11,370
storage and bridging the gap actually

291
00:19:07,049 --> 00:19:13,860
when we run clinical containers as when

292
00:19:11,370 --> 00:19:17,939
we run eunuch analyst as pass containers

293
00:19:13,860 --> 00:19:21,539
and also we would like to try some of

294
00:19:17,940 --> 00:19:25,919
the of recent approach by the community

295
00:19:21,539 --> 00:19:28,919
like VM forking or pre allocation of of

296
00:19:25,919 --> 00:19:33,990
V CPUs to be able to handle to to have

297
00:19:28,919 --> 00:19:36,210
instant respond times I would like to

298
00:19:33,990 --> 00:19:42,240
mention that this project is partially

299
00:19:36,210 --> 00:19:44,280
funded by horizon 2020 projects and also

300
00:19:42,240 --> 00:19:49,440
I would like to take the opportunity to

301
00:19:44,280 --> 00:19:54,178
invite you to submit a paper in our

302
00:19:49,440 --> 00:20:01,159
workshop on I see this year it's in June

303
00:19:54,179 --> 00:20:04,549
21 25th and the deadline is April 5th

304
00:20:01,159 --> 00:20:04,549
thanks very much

305
00:20:10,420 --> 00:20:20,410
you can also feel free to check out our

306
00:20:12,710 --> 00:20:20,410
blog blog cloud canvas.net or our github

307
00:20:22,630 --> 00:20:25,769
[Music]

308
00:20:40,960 --> 00:20:52,880
so so the question is if we were using

309
00:20:47,900 --> 00:20:57,670
the host why are we better than than the

310
00:20:52,880 --> 00:20:57,670
game or the Firecracker alternative so

311
00:20:57,880 --> 00:21:04,250
we are using the host that's one thing

312
00:21:01,100 --> 00:21:07,870
that the second thing is that for these

313
00:21:04,250 --> 00:21:11,270
kind of benchmarks we are in on on a

314
00:21:07,870 --> 00:21:18,500
Layton sees analytics side so because

315
00:21:11,270 --> 00:21:45,530
it's not helping with latency at all it

316
00:21:18,500 --> 00:21:48,860
should I'm not sure okay we can shut

317
00:21:45,530 --> 00:21:57,080
about the flying but I I think that in

318
00:21:48,860 --> 00:22:01,129
the in the V host case if the message

319
00:21:57,080 --> 00:22:03,830
size is large then you do get the same

320
00:22:01,130 --> 00:22:07,720
result if if the message size is small I

321
00:22:03,830 --> 00:22:07,720
think you get an exit

322
00:22:08,160 --> 00:22:15,690
back then because you waited for too

323
00:22:09,960 --> 00:22:22,290
long for the Packer to come in sure sure

324
00:22:15,690 --> 00:22:24,360
sure but sure yes and just to be clear

325
00:22:22,290 --> 00:22:26,670
we're doing the exact same thing as

326
00:22:24,360 --> 00:22:28,260
solar fiber came before the exit and the

327
00:22:26,670 --> 00:22:32,250
our how they are handling there's a

328
00:22:28,260 --> 00:22:35,580
hyper coal we you wake up in the monitor

329
00:22:32,250 --> 00:22:40,340
and you do the the send message we

330
00:22:35,580 --> 00:22:44,449
receive my certificates for the network

331
00:22:40,340 --> 00:22:50,540
and actually we have been thinking that

332
00:22:44,450 --> 00:22:54,120
we don't have to use having avatar your

333
00:22:50,540 --> 00:22:56,970
approach or the solo 5 approach which

334
00:22:54,120 --> 00:23:00,000
which just poles we could use something

335
00:22:56,970 --> 00:23:02,910
which is more elegant and tailored to

336
00:23:00,000 --> 00:23:05,520
our approach I mean if you if you are

337
00:23:02,910 --> 00:23:07,800
already in the kernel then we don't have

338
00:23:05,520 --> 00:23:12,540
to do anything complicated like iron

339
00:23:07,800 --> 00:23:14,970
rings or you could just forward requests

340
00:23:12,540 --> 00:23:39,990
from the guests to the network or to

341
00:23:14,970 --> 00:23:41,970
storage so it's what you always want

342
00:23:39,990 --> 00:23:43,860
optimized for in nvm worlds to not have

343
00:23:41,970 --> 00:23:45,060
exits because any exit is always slow

344
00:23:43,860 --> 00:23:47,729
it's always going to be through the slow

345
00:23:45,060 --> 00:23:49,620
path whatever you do if you can somehow

346
00:23:47,730 --> 00:23:51,630
avoid to do accept is exactly what all

347
00:23:49,620 --> 00:23:55,620
of the modern interfaces are about like

348
00:23:51,630 --> 00:23:59,070
the V host or i/o Ewing or everybody

349
00:23:55,620 --> 00:24:01,050
who's like if even the smart NICs do the

350
00:23:59,070 --> 00:24:03,389
same thing right the whole point is to

351
00:24:01,050 --> 00:24:05,820
not ever exit the VM at all if you're

352
00:24:03,390 --> 00:24:08,580
doing UI oh yes you might end up

353
00:24:05,820 --> 00:24:11,460
sacrificing a core but again especially

354
00:24:08,580 --> 00:24:13,500
on edge devices you have in order cores

355
00:24:11,460 --> 00:24:15,630
just lying around basically you could

356
00:24:13,500 --> 00:24:18,180
dedicate one of those just to to keep

357
00:24:15,630 --> 00:24:19,530
handling you IO in the background if we

358
00:24:18,180 --> 00:24:21,860
could integrate with what I'd suggest

359
00:24:19,530 --> 00:24:24,290
earlier with IO Ewing or maybe just

360
00:24:21,860 --> 00:24:26,780
prove Rijos - to do the polling for you

361
00:24:24,290 --> 00:24:28,460
on behalf of you you might literally get

362
00:24:26,780 --> 00:24:32,120
to the same performance numbers as

363
00:24:28,460 --> 00:24:35,510
bi-metal most likely yeah could be

364
00:24:32,120 --> 00:24:42,500
issue is that we need to exit to ensure

365
00:24:35,510 --> 00:24:44,299
isolation in this kind of case so no I

366
00:24:42,500 --> 00:24:46,340
disagree and we don't we don't need to

367
00:24:44,299 --> 00:24:50,179
exit - into if you need to exit you need

368
00:24:46,340 --> 00:24:51,860
to make sure you have only access to the

369
00:24:50,179 --> 00:24:53,450
data you actually need to from from the

370
00:24:51,860 --> 00:24:57,260
the polling side but that doesn't have

371
00:24:53,450 --> 00:24:59,030
to be the same entity as like the vmm it

372
00:24:57,260 --> 00:25:01,580
can be defined either way um I don't

373
00:24:59,030 --> 00:25:03,710
think this is the like we don't have the

374
00:25:01,580 --> 00:25:07,600
time to to go through this in detail so

375
00:25:03,710 --> 00:25:07,600
let's take this offline and then okay

376
00:25:07,770 --> 00:25:16,500
[Applause]

