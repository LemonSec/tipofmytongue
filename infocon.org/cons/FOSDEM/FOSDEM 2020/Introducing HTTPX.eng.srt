1
00:00:07,839 --> 00:00:11,920
okay let's

2
00:00:08,639 --> 00:00:15,759
welcome the next speaker tom who's gonna

3
00:00:11,920 --> 00:00:17,590
present us his project hcpx

4
00:00:15,759 --> 00:00:23,279
thank you

5
00:00:17,590 --> 00:00:25,359
[Applause]

6
00:00:23,279 --> 00:00:27,759
okay so i'll just start by checking the

7
00:00:25,359 --> 00:00:31,279
mic volume am i okay at the back

8
00:00:27,760 --> 00:00:32,079
yes cool okay good okay so my name's tom

9
00:00:31,279 --> 00:00:34,239
christie

10
00:00:32,079 --> 00:00:36,719
uh i'm the author of a whole bunch of

11
00:00:34,239 --> 00:00:39,839
different open source projects

12
00:00:36,719 --> 00:00:41,760
uh including an api framework called

13
00:00:39,840 --> 00:00:45,920
django rest framework

14
00:00:41,760 --> 00:00:49,199
um a tool for building documentation

15
00:00:45,920 --> 00:00:51,920
from markdown called mk docs

16
00:00:49,200 --> 00:00:53,280
um more recently i've been spending a

17
00:00:51,920 --> 00:00:56,719
whole lot of time

18
00:00:53,280 --> 00:00:59,920
in the async io landscape

19
00:00:56,719 --> 00:01:00,879
building an async i o web server called

20
00:00:59,920 --> 00:01:04,640
univercorn

21
00:01:00,879 --> 00:01:08,798
a nice an async io microweb framework

22
00:01:04,640 --> 00:01:11,760
called starlet and most recently of all

23
00:01:08,799 --> 00:01:12,320
spending a whole bunch of time working

24
00:01:11,760 --> 00:01:15,360
on

25
00:01:12,320 --> 00:01:18,080
this httpx

26
00:01:15,360 --> 00:01:19,439
which has just about now gotten to the

27
00:01:18,080 --> 00:01:21,039
stage where

28
00:01:19,439 --> 00:01:24,240
it's kind of ready for everybody to

29
00:01:21,040 --> 00:01:24,240
start using it so

30
00:01:25,439 --> 00:01:33,279
what is httpx httpx is

31
00:01:28,799 --> 00:01:35,840
an http client just like requests

32
00:01:33,280 --> 00:01:37,040
so you can use it for downloading web

33
00:01:35,840 --> 00:01:40,720
pages or

34
00:01:37,040 --> 00:01:43,520
interacting with apis or anywhere

35
00:01:40,720 --> 00:01:45,439
where you're issuing http requests over

36
00:01:43,520 --> 00:01:48,720
the network

37
00:01:45,439 --> 00:01:50,240
and it should look pretty familiar to

38
00:01:48,720 --> 00:01:51,759
anybody here who's used

39
00:01:50,240 --> 00:01:55,119
the request library which i guess would

40
00:01:51,759 --> 00:01:57,759
be most of you

41
00:01:55,119 --> 00:01:57,759
we've um

42
00:02:00,240 --> 00:02:03,600
we've got to the point now in the

43
00:02:02,799 --> 00:02:06,320
development

44
00:02:03,600 --> 00:02:08,000
where we pretty much got feature parity

45
00:02:06,320 --> 00:02:11,200
with requests

46
00:02:08,000 --> 00:02:14,080
and that's a lot of ground to cover so

47
00:02:11,200 --> 00:02:14,079
for instance

48
00:02:14,800 --> 00:02:20,560
if you want to be able to seamlessly

49
00:02:18,319 --> 00:02:22,079
just present the user with the unicode

50
00:02:20,560 --> 00:02:24,080
text of the response

51
00:02:22,080 --> 00:02:25,440
that's been returned all of the things

52
00:02:24,080 --> 00:02:28,640
that you've got to do under the hood

53
00:02:25,440 --> 00:02:30,560
include things like okay well the bytes

54
00:02:28,640 --> 00:02:33,839
that we got over the wire

55
00:02:30,560 --> 00:02:35,519
might be compressed because http has

56
00:02:33,840 --> 00:02:36,480
content a mechanism for content

57
00:02:35,519 --> 00:02:38,080
compression

58
00:02:36,480 --> 00:02:39,840
so first of all you've got to figure out

59
00:02:38,080 --> 00:02:42,000
whether they're compressed or not

60
00:02:39,840 --> 00:02:43,440
and if they are decompress it and at

61
00:02:42,000 --> 00:02:46,959
that point you've still got

62
00:02:43,440 --> 00:02:46,959
a whole load of bytes on the wire

63
00:02:47,200 --> 00:02:50,160
so you've got to figure out well what's

64
00:02:48,480 --> 00:02:52,399
the character set that we're going to

65
00:02:50,160 --> 00:02:55,120
decode that text into

66
00:02:52,400 --> 00:02:56,319
that might be present in one of the http

67
00:02:55,120 --> 00:02:58,159
headers

68
00:02:56,319 --> 00:03:00,159
if it's not then you're going to have to

69
00:02:58,159 --> 00:03:02,480
find some way of figuring out

70
00:03:00,159 --> 00:03:03,760
what the character set probably is so

71
00:03:02,480 --> 00:03:05,119
doing all of that sort of stuff

72
00:03:03,760 --> 00:03:08,159
gracefully

73
00:03:05,120 --> 00:03:11,840
um handling redirects gracefully

74
00:03:08,159 --> 00:03:13,840
different http redirect status codes

75
00:03:11,840 --> 00:03:14,959
have different behaviors they might

76
00:03:13,840 --> 00:03:16,640
change the method

77
00:03:14,959 --> 00:03:18,319
some of them preserve the body when

78
00:03:16,640 --> 00:03:19,599
you're issuing the redirect some of them

79
00:03:18,319 --> 00:03:22,399
don't

80
00:03:19,599 --> 00:03:23,839
being able to handle basic and digest

81
00:03:22,400 --> 00:03:26,720
authentication

82
00:03:23,840 --> 00:03:29,360
there might be authentication in the url

83
00:03:26,720 --> 00:03:31,599
itself because that can contain

84
00:03:29,360 --> 00:03:32,799
basic uh basic authentication

85
00:03:31,599 --> 00:03:35,518
credentials

86
00:03:32,799 --> 00:03:37,280
if you get redirected away from the

87
00:03:35,519 --> 00:03:37,760
origin that you first made the request

88
00:03:37,280 --> 00:03:39,200
to

89
00:03:37,760 --> 00:03:41,040
then you need to be stripping the

90
00:03:39,200 --> 00:03:46,879
authentication there's a lot of ground

91
00:03:41,040 --> 00:03:49,120
to cover

92
00:03:46,879 --> 00:03:51,120
but there wouldn't really be much point

93
00:03:49,120 --> 00:03:53,200
to this if what we were doing was just

94
00:03:51,120 --> 00:03:55,040
building a new package and trying to

95
00:03:53,200 --> 00:03:58,959
match requests

96
00:03:55,040 --> 00:04:00,239
like for like so the big motivation for

97
00:03:58,959 --> 00:04:02,799
httpx

98
00:04:00,239 --> 00:04:07,120
has been to do all of that but also

99
00:04:02,799 --> 00:04:07,120
introduce a bunch of new functionality

100
00:04:07,519 --> 00:04:13,760
the first big piece of that is

101
00:04:10,720 --> 00:04:17,600
to provide both an

102
00:04:13,760 --> 00:04:21,680
async capable http client

103
00:04:17,600 --> 00:04:25,520
and a standard synchronous api

104
00:04:21,680 --> 00:04:29,840
all in one same package with a coherent

105
00:04:25,520 --> 00:04:29,840
api between those two different cases

106
00:04:30,440 --> 00:04:36,639
httpx includes support

107
00:04:33,440 --> 00:04:40,080
both for http 1.1

108
00:04:36,639 --> 00:04:42,960
and also http 2

109
00:04:40,080 --> 00:04:44,080
i'm pretty sure it's the first well yeah

110
00:04:42,960 --> 00:04:47,120
i think it's the first

111
00:04:44,080 --> 00:04:51,440
python client library to really do that

112
00:04:47,120 --> 00:04:54,160
um it's got the ability to make requests

113
00:04:51,440 --> 00:04:56,400
directly to a web framework rather than

114
00:04:54,160 --> 00:04:59,199
actually sending requests out over the

115
00:04:56,400 --> 00:05:03,520
wire so you can plug it directly into a

116
00:04:59,199 --> 00:05:03,520
flask application or something like this

117
00:05:03,680 --> 00:05:07,520
we've got some nice sensible behavior

118
00:05:05,680 --> 00:05:08,479
about strict timeouts which we'll come

119
00:05:07,520 --> 00:05:10,479
to

120
00:05:08,479 --> 00:05:12,719
and the whole thing is fully type

121
00:05:10,479 --> 00:05:15,479
annotated all the way through

122
00:05:12,720 --> 00:05:16,960
all of that together with reams of

123
00:05:15,479 --> 00:05:20,880
documentation

124
00:05:16,960 --> 00:05:25,840
and almost 100 test coverage

125
00:05:20,880 --> 00:05:25,840
and there's more to come as well

126
00:05:27,120 --> 00:05:32,560
so um httpx as i've said

127
00:05:30,800 --> 00:05:34,160
should look pretty familiar if you've

128
00:05:32,560 --> 00:05:37,520
used requests

129
00:05:34,160 --> 00:05:40,479
we've gone to great lengths to

130
00:05:37,520 --> 00:05:42,320
retain api compatibility with requests

131
00:05:40,479 --> 00:05:44,240
wherever possible

132
00:05:42,320 --> 00:05:45,440
there's a documentation page

133
00:05:44,240 --> 00:05:48,560
specifically

134
00:05:45,440 --> 00:05:49,120
for what differences are there between

135
00:05:48,560 --> 00:05:51,440
the two

136
00:05:49,120 --> 00:05:52,639
in places where we've chosen to make a

137
00:05:51,440 --> 00:05:55,199
change

138
00:05:52,639 --> 00:05:56,960
uh you ought to be able to migrate over

139
00:05:55,199 --> 00:05:59,520
from one to the other just by going and

140
00:05:56,960 --> 00:06:01,520
having a quick scan through that guide

141
00:05:59,520 --> 00:06:03,680
and switching anything over that's

142
00:06:01,520 --> 00:06:06,080
apparent there but mostly

143
00:06:03,680 --> 00:06:07,600
not a couple of examples of places where

144
00:06:06,080 --> 00:06:09,680
we differ

145
00:06:07,600 --> 00:06:11,360
and we got a slightly more constrained

146
00:06:09,680 --> 00:06:13,440
streaming api

147
00:06:11,360 --> 00:06:15,440
so with requests it's actually quite

148
00:06:13,440 --> 00:06:18,319
easy to inadvertently

149
00:06:15,440 --> 00:06:18,719
use a streaming response and not realize

150
00:06:18,319 --> 00:06:21,039
that

151
00:06:18,720 --> 00:06:22,160
the way that you've done that has left

152
00:06:21,039 --> 00:06:24,960
the connection

153
00:06:22,160 --> 00:06:26,400
hanging open at the end of it so a

154
00:06:24,960 --> 00:06:28,840
little bit more constrained there

155
00:06:26,400 --> 00:06:30,080
we use different naming instead of

156
00:06:28,840 --> 00:06:35,640
request.session

157
00:06:30,080 --> 00:06:37,198
we've proper we preferred httpx.com

158
00:06:35,640 --> 00:06:38,800
[Music]

159
00:06:37,199 --> 00:06:40,479
and there's some differences at some of

160
00:06:38,800 --> 00:06:43,280
the lower levels of the api

161
00:06:40,479 --> 00:06:44,159
as well once you start getting into

162
00:06:43,280 --> 00:06:46,799
stuff that's

163
00:06:44,160 --> 00:06:49,360
more really implementation details

164
00:06:46,800 --> 00:06:51,919
methods on the client class

165
00:06:49,360 --> 00:06:51,919
and so on

166
00:06:54,960 --> 00:06:58,960
so fully type annotated

167
00:06:59,039 --> 00:07:02,080
that's both at the layer of the public

168
00:07:01,280 --> 00:07:03,758
api

169
00:07:02,080 --> 00:07:05,840
but also all the way through the code

170
00:07:03,759 --> 00:07:09,120
base the

171
00:07:05,840 --> 00:07:10,799
big advantages of that if you're

172
00:07:09,120 --> 00:07:13,120
building up your service and you're

173
00:07:10,800 --> 00:07:15,599
using a type checker like my pi

174
00:07:13,120 --> 00:07:16,160
it will be able to automatically ensure

175
00:07:15,599 --> 00:07:19,440
for you

176
00:07:16,160 --> 00:07:21,919
that you're calling into httpx

177
00:07:19,440 --> 00:07:23,520
correctly with the right types

178
00:07:21,919 --> 00:07:27,280
everywhere

179
00:07:23,520 --> 00:07:31,280
you get type hinting in some ides

180
00:07:27,280 --> 00:07:33,119
and all of the apis are nice and clear

181
00:07:31,280 --> 00:07:34,799
and explicit there's no

182
00:07:33,120 --> 00:07:37,120
going and having a look at something

183
00:07:34,800 --> 00:07:39,280
going well does that thing take a string

184
00:07:37,120 --> 00:07:40,160
or does it take something that's string

185
00:07:39,280 --> 00:07:43,039
like

186
00:07:40,160 --> 00:07:44,080
or so it's also given us a really high

187
00:07:43,039 --> 00:07:47,759
degree of confidence

188
00:07:44,080 --> 00:07:50,080
in our own code base i think httpx would

189
00:07:47,759 --> 00:07:50,639
have taken a lot longer to build if we

190
00:07:50,080 --> 00:07:53,120
hadn't

191
00:07:50,639 --> 00:07:55,120
had strict type checking all the way

192
00:07:53,120 --> 00:07:58,479
through i think and some of the

193
00:07:55,120 --> 00:08:02,000
bits where we've made large refactorings

194
00:07:58,479 --> 00:08:02,479
earlier on in the in the age of the

195
00:08:02,000 --> 00:08:03,759
project

196
00:08:02,479 --> 00:08:05,599
i think would have been really really

197
00:08:03,759 --> 00:08:08,319
difficult to do

198
00:08:05,599 --> 00:08:08,319
without that

199
00:08:09,919 --> 00:08:16,799
what else um

200
00:08:13,199 --> 00:08:20,879
timeouts by default so

201
00:08:16,800 --> 00:08:23,440
the timeout policy in httpx

202
00:08:20,879 --> 00:08:24,080
is to always have timeouts enabled by

203
00:08:23,440 --> 00:08:27,840
default

204
00:08:24,080 --> 00:08:29,840
so that rather than being able to

205
00:08:27,840 --> 00:08:31,919
if you inadvertently make a request and

206
00:08:29,840 --> 00:08:34,399
you haven't set any timeouts

207
00:08:31,919 --> 00:08:37,199
and the network hangs then your script

208
00:08:34,399 --> 00:08:39,760
is just left hanging indefinitely

209
00:08:37,200 --> 00:08:40,479
you've got a five second timeout by

210
00:08:39,760 --> 00:08:43,760
default

211
00:08:40,479 --> 00:08:46,480
and if you want to raise that or remove

212
00:08:43,760 --> 00:08:48,640
that then you can

213
00:08:46,480 --> 00:08:50,560
there's lots of fine-grained controls on

214
00:08:48,640 --> 00:08:52,720
that you can control different aspects

215
00:08:50,560 --> 00:08:57,279
of the timeout so for example

216
00:08:52,720 --> 00:09:00,240
you can allow long connection times

217
00:08:57,279 --> 00:09:01,360
but reasonable timeout periods if it

218
00:09:00,240 --> 00:09:05,200
hangs

219
00:09:01,360 --> 00:09:05,200
whilst you're downloading a response

220
00:09:06,080 --> 00:09:11,200
and you can control the the timeouts

221
00:09:09,440 --> 00:09:13,360
on the connection pooling and things

222
00:09:11,200 --> 00:09:15,519
like this but we try to provide a really

223
00:09:13,360 --> 00:09:19,360
simple api

224
00:09:15,519 --> 00:09:20,959
at the basic level and then allow you to

225
00:09:19,360 --> 00:09:24,560
expand into some of the more

226
00:09:20,959 --> 00:09:24,560
complex options if you need to

227
00:09:26,800 --> 00:09:32,319
um one of the

228
00:09:30,000 --> 00:09:35,120
absolutely one of the bigger things the

229
00:09:32,320 --> 00:09:37,839
the async support

230
00:09:35,120 --> 00:09:37,839
so

231
00:09:38,480 --> 00:09:45,839
threaded concurrency is

232
00:09:42,160 --> 00:09:48,079
um not very good at performing

233
00:09:45,839 --> 00:09:50,560
lots and lots of network operations at

234
00:09:48,080 --> 00:09:53,120
the same time you're kind of bounded by

235
00:09:50,560 --> 00:09:54,479
maybe having 10 or 20 threads running on

236
00:09:53,120 --> 00:09:56,080
the machine and that's as many

237
00:09:54,480 --> 00:09:56,800
concurrent requests as you'll be able to

238
00:09:56,080 --> 00:10:01,680
make

239
00:09:56,800 --> 00:10:05,680
with async io the concurrency model

240
00:10:01,680 --> 00:10:08,479
is much less resource intensive so you

241
00:10:05,680 --> 00:10:11,839
can have thousands of concurrent tasks

242
00:10:08,480 --> 00:10:15,120
running easily and that

243
00:10:11,839 --> 00:10:15,120
allows you to

244
00:10:16,240 --> 00:10:19,760
do stuff that python hasn't

245
00:10:17,760 --> 00:10:23,279
traditionally been very good at

246
00:10:19,760 --> 00:10:25,760
making large numbers of concurrent http

247
00:10:23,279 --> 00:10:29,040
requests

248
00:10:25,760 --> 00:10:32,959
um we've kind of

249
00:10:29,040 --> 00:10:35,199
been having to catch up with other

250
00:10:32,959 --> 00:10:36,640
other environments such as go and node

251
00:10:35,200 --> 00:10:37,440
which have performed much better in this

252
00:10:36,640 --> 00:10:38,880
regard

253
00:10:37,440 --> 00:10:42,480
but we're actually really kind of coming

254
00:10:38,880 --> 00:10:42,480
quite a long way along now so

255
00:10:43,440 --> 00:10:48,560
async io is one of the async frameworks

256
00:10:47,440 --> 00:10:50,480
for python

257
00:10:48,560 --> 00:10:51,599
it's the one that's there in this in the

258
00:10:50,480 --> 00:10:53,519
stud lib

259
00:10:51,600 --> 00:10:55,440
but it's not the only one now so there's

260
00:10:53,519 --> 00:10:57,040
at least a couple of others there's one

261
00:10:55,440 --> 00:10:59,839
called curio

262
00:10:57,040 --> 00:11:01,120
and there's one which is getting a lot

263
00:10:59,839 --> 00:11:04,720
of development

264
00:11:01,120 --> 00:11:06,320
um called trio trio is exceptionally

265
00:11:04,720 --> 00:11:09,680
well designed

266
00:11:06,320 --> 00:11:14,000
it's motivated by this particular design

267
00:11:09,680 --> 00:11:17,199
constraint that its author has been

268
00:11:14,000 --> 00:11:20,079
kind of one of the architects of

269
00:11:17,200 --> 00:11:20,079
i guess you would say

270
00:11:20,959 --> 00:11:26,880
called structured structured concurrency

271
00:11:24,240 --> 00:11:26,880
and

272
00:11:27,519 --> 00:11:31,680
one of the things that's a bit difficult

273
00:11:29,279 --> 00:11:33,360
is async io and trio

274
00:11:31,680 --> 00:11:35,279
and curio they're all completely

275
00:11:33,360 --> 00:11:36,640
incompatible so you either have to pick

276
00:11:35,279 --> 00:11:39,200
one or the other

277
00:11:36,640 --> 00:11:40,640
at the moment of course async io because

278
00:11:39,200 --> 00:11:43,839
it's in the stud lib

279
00:11:40,640 --> 00:11:44,959
has the widest ecosystem support out of

280
00:11:43,839 --> 00:11:47,839
any of the options

281
00:11:44,959 --> 00:11:49,439
but trio is really worth looking at and

282
00:11:47,839 --> 00:11:51,040
a lot of the design work that's been

283
00:11:49,440 --> 00:11:53,360
going on to trio

284
00:11:51,040 --> 00:11:54,639
people are trying to pull down into the

285
00:11:53,360 --> 00:11:57,839
into async io

286
00:11:54,639 --> 00:11:57,839
as well

287
00:12:01,600 --> 00:12:07,200
the second of the really big features is

288
00:12:04,240 --> 00:12:11,279
adding http 2 supports

289
00:12:07,200 --> 00:12:14,639
so http 2 is

290
00:12:11,279 --> 00:12:17,760
a big update to the http protocol

291
00:12:14,639 --> 00:12:21,279
that switches from using whereas

292
00:12:17,760 --> 00:12:23,120
http 1.1 has always been

293
00:12:21,279 --> 00:12:25,200
text over the wire so if you go and

294
00:12:23,120 --> 00:12:27,760
inspect the raw bytes you'd be able to

295
00:12:25,200 --> 00:12:30,639
just go and inspect the headers

296
00:12:27,760 --> 00:12:32,720
and see what's happening http 2 is a

297
00:12:30,639 --> 00:12:35,920
binary protocol

298
00:12:32,720 --> 00:12:37,839
and that's allowed them to do

299
00:12:35,920 --> 00:12:40,639
some things that can improve the

300
00:12:37,839 --> 00:12:43,279
performance such as

301
00:12:40,639 --> 00:12:47,279
header compression and minimizing the

302
00:12:43,279 --> 00:12:50,720
size of the requests and the responses

303
00:12:47,279 --> 00:12:53,120
but probably bigger than that is

304
00:12:50,720 --> 00:12:55,360
what's called stream multiplexing so

305
00:12:53,120 --> 00:12:58,160
with http 1.1

306
00:12:55,360 --> 00:13:00,480
when you're making concurrent requests

307
00:12:58,160 --> 00:13:03,519
from one particular server to another

308
00:13:00,480 --> 00:13:07,200
you have to use one tcp stream

309
00:13:03,519 --> 00:13:10,399
for each individual request with http

310
00:13:07,200 --> 00:13:13,360
2 it has a mechanism whereby

311
00:13:10,399 --> 00:13:14,800
you just open up a single tcp stream and

312
00:13:13,360 --> 00:13:16,639
you can send

313
00:13:14,800 --> 00:13:18,800
almost as many different requests and

314
00:13:16,639 --> 00:13:22,160
responses along that single

315
00:13:18,800 --> 00:13:22,160
connection as you want

316
00:13:22,399 --> 00:13:24,639
and

317
00:13:26,959 --> 00:13:34,959
those two things mean that http 2

318
00:13:31,600 --> 00:13:38,240
has both lower latency

319
00:13:34,959 --> 00:13:40,079
sometimes uh latency being the time it

320
00:13:38,240 --> 00:13:41,920
takes from when you've made the request

321
00:13:40,079 --> 00:13:43,920
until you get the response back

322
00:13:41,920 --> 00:13:46,000
the lower latency being because you're

323
00:13:43,920 --> 00:13:48,079
less frequently having to establish

324
00:13:46,000 --> 00:13:49,760
a whole new connection in order to get

325
00:13:48,079 --> 00:13:51,599
your response back

326
00:13:49,760 --> 00:13:53,680
and it also means you can get much

327
00:13:51,600 --> 00:13:54,399
higher throughput be able to make more

328
00:13:53,680 --> 00:13:58,479
requests

329
00:13:54,399 --> 00:14:02,160
at the same time so this is

330
00:13:58,480 --> 00:14:04,800
a bit of an example of the

331
00:14:02,160 --> 00:14:07,199
stream multiplexing in this example it's

332
00:14:04,800 --> 00:14:09,279
a web browser that's making the request

333
00:14:07,199 --> 00:14:11,439
it's going off and it's fetching a web

334
00:14:09,279 --> 00:14:14,480
page the web page has got a bunch of

335
00:14:11,440 --> 00:14:18,800
javascript and css associated with it

336
00:14:14,480 --> 00:14:22,480
in the 1.0k in the 1.1 case

337
00:14:18,800 --> 00:14:23,839
each of the two other resources that

338
00:14:22,480 --> 00:14:27,040
we're downloading

339
00:14:23,839 --> 00:14:28,720
is then downloaded sequentially and in

340
00:14:27,040 --> 00:14:31,839
the http 2

341
00:14:28,720 --> 00:14:32,560
we can go and uh download them in

342
00:14:31,839 --> 00:14:34,639
parallel

343
00:14:32,560 --> 00:14:36,560
over the same connection now it's a

344
00:14:34,639 --> 00:14:38,399
slight simplification because actually

345
00:14:36,560 --> 00:14:41,279
in http 1.1

346
00:14:38,399 --> 00:14:42,639
you'll tend to open up more than a

347
00:14:41,279 --> 00:14:44,560
single connection

348
00:14:42,639 --> 00:14:47,440
but even so if you're downloading lots

349
00:14:44,560 --> 00:14:49,439
of resources at the same time

350
00:14:47,440 --> 00:14:51,600
this is kind of what it ends up looking

351
00:14:49,440 --> 00:14:51,600
like

352
00:14:55,279 --> 00:15:03,040
http 2 is significantly more complex

353
00:14:58,639 --> 00:15:06,480
than http1 so for the moment

354
00:15:03,040 --> 00:15:09,760
we've decided that the

355
00:15:06,480 --> 00:15:12,560
best user experience is to not enable it

356
00:15:09,760 --> 00:15:16,560
by default

357
00:15:12,560 --> 00:15:17,040
we don't have any big outstanding bugs

358
00:15:16,560 --> 00:15:19,760
for it

359
00:15:17,040 --> 00:15:22,000
that i can see at the moment but i think

360
00:15:19,760 --> 00:15:25,360
there may still be some cases

361
00:15:22,000 --> 00:15:27,440
where servers might be less robust or

362
00:15:25,360 --> 00:15:28,639
you know that it gives us a little bit

363
00:15:27,440 --> 00:15:30,480
of a chance

364
00:15:28,639 --> 00:15:31,759
just to start battle testing it before

365
00:15:30,480 --> 00:15:33,920
we decide to

366
00:15:31,759 --> 00:15:35,040
flip the switch and say yes we're happy

367
00:15:33,920 --> 00:15:36,800
enough that

368
00:15:35,040 --> 00:15:37,839
the user experience on this is always

369
00:15:36,800 --> 00:15:39,680
going to be good enough that we'll just

370
00:15:37,839 --> 00:15:40,079
keep it on by default unless you want to

371
00:15:39,680 --> 00:15:42,399
switch

372
00:15:40,079 --> 00:15:46,000
off and presumably at some point in the

373
00:15:42,399 --> 00:15:46,000
future we'll end up doing that

374
00:15:52,839 --> 00:15:59,759
so some use cases for httpx

375
00:15:57,199 --> 00:16:01,439
and the first one's really simple

376
00:15:59,759 --> 00:16:02,320
everywhere that you're using requests at

377
00:16:01,440 --> 00:16:04,399
the moment

378
00:16:02,320 --> 00:16:05,360
right it's a it's a fully featured

379
00:16:04,399 --> 00:16:08,480
alternative

380
00:16:05,360 --> 00:16:09,839
um if there's something that you can do

381
00:16:08,480 --> 00:16:13,040
in requests that you're

382
00:16:09,839 --> 00:16:15,600
not currently able to do in httpx

383
00:16:13,040 --> 00:16:16,399
raise that as an issue uh those things

384
00:16:15,600 --> 00:16:18,720
are going to be

385
00:16:16,399 --> 00:16:19,519
pretty limited around the edges at the

386
00:16:18,720 --> 00:16:22,800
moment you know

387
00:16:19,519 --> 00:16:25,360
there's i think event hooks

388
00:16:22,800 --> 00:16:28,498
we don't yet support um

389
00:16:25,360 --> 00:16:28,499
[Music]

390
00:16:28,720 --> 00:16:31,839
i can't remember

391
00:16:32,720 --> 00:16:36,000
and and the course request has got a

392
00:16:34,160 --> 00:16:37,120
little bit about ecosystem support you

393
00:16:36,000 --> 00:16:40,000
know so for example

394
00:16:37,120 --> 00:16:41,839
customer authentication classes more

395
00:16:40,000 --> 00:16:46,000
people have written those for requests

396
00:16:41,839 --> 00:16:46,000
so far than they have for http x

397
00:16:47,199 --> 00:16:51,599
yeah socks for proxy support is

398
00:16:49,920 --> 00:16:54,800
available in requests

399
00:16:51,600 --> 00:16:54,800
we haven't yet got that

400
00:16:56,639 --> 00:17:00,720
and yes

401
00:17:01,360 --> 00:17:05,839
next use case

402
00:17:06,160 --> 00:17:09,679
making parallel requests right make it

403
00:17:08,880 --> 00:17:14,079
using

404
00:17:09,679 --> 00:17:17,600
the async client variants

405
00:17:14,079 --> 00:17:20,079
to make multiple http requests at the

406
00:17:17,599 --> 00:17:24,719
same time so in this example

407
00:17:20,079 --> 00:17:29,080
i'm using trio as the async framework

408
00:17:24,720 --> 00:17:32,240
and i'm starting up

409
00:17:29,080 --> 00:17:35,520
120 requests to wikipedia

410
00:17:32,240 --> 00:17:38,799
to download all of the wikipedia pages

411
00:17:35,520 --> 00:17:44,039
on the years from also 100 requests

412
00:17:38,799 --> 00:17:46,639
from the years 1920 through to

413
00:17:44,039 --> 00:17:50,000
today um

414
00:17:46,640 --> 00:17:52,799
don't expect this to be completely magic

415
00:17:50,000 --> 00:17:53,679
although i say they run in parallel

416
00:17:52,799 --> 00:17:54,960
you're not go

417
00:17:53,679 --> 00:17:57,039
you know if you were running these

418
00:17:54,960 --> 00:17:59,200
sequentially it won't actually take

419
00:17:57,039 --> 00:18:00,559
a hundred times longer than this one

420
00:17:59,200 --> 00:18:02,960
will run

421
00:18:00,559 --> 00:18:04,559
it will be faster or it'll be slower

422
00:18:02,960 --> 00:18:07,679
whichever way rounds i've said it

423
00:18:04,559 --> 00:18:09,200
can't remember but you've got a there

424
00:18:07,679 --> 00:18:10,960
are other factors at play you know you

425
00:18:09,200 --> 00:18:12,720
may be constrained by the network

426
00:18:10,960 --> 00:18:13,520
bandwidth that's available full stop

427
00:18:12,720 --> 00:18:16,080
anyway

428
00:18:13,520 --> 00:18:18,639
you might be constrained by the server

429
00:18:16,080 --> 00:18:21,760
resources on the other side

430
00:18:18,640 --> 00:18:23,679
so it's not going to just be magically

431
00:18:21,760 --> 00:18:24,879
the number of times that you're issuing

432
00:18:23,679 --> 00:18:28,320
parallel requests

433
00:18:24,880 --> 00:18:30,559
faster than but it will

434
00:18:28,320 --> 00:18:31,360
you know it makes a big improvement you

435
00:18:30,559 --> 00:18:33,840
know uh

436
00:18:31,360 --> 00:18:33,840
like uh

437
00:18:34,880 --> 00:18:38,960
they're there um also that really that's

438
00:18:37,840 --> 00:18:41,199
something that i ought to

439
00:18:38,960 --> 00:18:42,960
go and write some do some really good

440
00:18:41,200 --> 00:18:44,320
investigation on and write some blog

441
00:18:42,960 --> 00:18:46,559
posts and case studies

442
00:18:44,320 --> 00:18:48,240
so i'm hoping to do that in the future

443
00:18:46,559 --> 00:18:51,120
what we got next

444
00:18:48,240 --> 00:18:53,280
oh yeah same thing same thing but add

445
00:18:51,120 --> 00:18:55,520
http 2 into the mix and

446
00:18:53,280 --> 00:18:56,960
why you might do that is because because

447
00:18:55,520 --> 00:18:59,280
as we've talked about

448
00:18:56,960 --> 00:19:00,640
performance benefits sensible thing to

449
00:18:59,280 --> 00:19:04,000
do say you're

450
00:19:00,640 --> 00:19:07,200
writing a web spidering tool um

451
00:19:04,000 --> 00:19:09,039
and you're using the async requests

452
00:19:07,200 --> 00:19:10,720
to get really good performance out of

453
00:19:09,039 --> 00:19:13,520
that try it

454
00:19:10,720 --> 00:19:14,000
with just http1 to start with and then

455
00:19:13,520 --> 00:19:17,360
add

456
00:19:14,000 --> 00:19:20,720
http2 into the mix you'll also want to

457
00:19:17,360 --> 00:19:22,559
check whether the http version

458
00:19:20,720 --> 00:19:24,400
that the server has responded with

459
00:19:22,559 --> 00:19:27,559
really is http 2

460
00:19:24,400 --> 00:19:29,200
it might not support it you can look on

461
00:19:27,559 --> 00:19:30,720
response.http version

462
00:19:29,200 --> 00:19:39,840
and that will give you the actual

463
00:19:30,720 --> 00:19:39,840
version that was used in the response

464
00:19:40,480 --> 00:19:49,360
um next use case okay so we talked about

465
00:19:45,039 --> 00:19:52,480
making requests in parallel

466
00:19:49,360 --> 00:19:56,080
well one of the use cases here

467
00:19:52,480 --> 00:19:56,559
doesn't look within the particular code

468
00:19:56,080 --> 00:19:58,639
block

469
00:19:56,559 --> 00:20:00,559
like you're making requests in parallel

470
00:19:58,640 --> 00:20:04,240
when you're using http

471
00:20:00,559 --> 00:20:06,000
x with one of the newer async web

472
00:20:04,240 --> 00:20:09,840
frameworks that's out there

473
00:20:06,000 --> 00:20:14,080
maybe sanic fast api

474
00:20:09,840 --> 00:20:17,439
starlets court and

475
00:20:14,080 --> 00:20:20,480
uh air http although they've got their

476
00:20:17,440 --> 00:20:20,480
own built-in clients

477
00:20:23,840 --> 00:20:29,360
the end point code that you're looking

478
00:20:26,799 --> 00:20:31,200
at will just be a

479
00:20:29,360 --> 00:20:33,520
generally will just be a single

480
00:20:31,200 --> 00:20:36,799
sequential flow of codes

481
00:20:33,520 --> 00:20:39,440
however your web server is handling

482
00:20:36,799 --> 00:20:43,039
multiple requests at the same time

483
00:20:39,440 --> 00:20:46,799
um because you're using an async

484
00:20:43,039 --> 00:20:48,000
framework with an async http client

485
00:20:46,799 --> 00:20:50,080
inside that

486
00:20:48,000 --> 00:20:52,000
you're not blocking an entire thread

487
00:20:50,080 --> 00:20:55,199
every time you're making

488
00:20:52,000 --> 00:20:56,480
an outgoing request so your framework

489
00:20:55,200 --> 00:20:59,440
will be able to support

490
00:20:56,480 --> 00:21:00,840
a far higher throughput than if you were

491
00:20:59,440 --> 00:21:04,320
using

492
00:21:00,840 --> 00:21:06,240
um a whiskey framework such as flask and

493
00:21:04,320 --> 00:21:09,439
using requests

494
00:21:06,240 --> 00:21:09,440
to issue those requests

495
00:21:10,799 --> 00:21:15,039
um another use case that i think is

496
00:21:13,280 --> 00:21:17,039
going to start to be really interesting

497
00:21:15,039 --> 00:21:19,919
don't expect to read that on the side

498
00:21:17,039 --> 00:21:21,120
it's just to kind of give you a feel for

499
00:21:19,919 --> 00:21:24,240
oh okay

500
00:21:21,120 --> 00:21:26,799
for the on on the right hand side that's

501
00:21:24,240 --> 00:21:31,039
an example of a proxy server

502
00:21:26,799 --> 00:21:35,679
written using httpx

503
00:21:31,039 --> 00:21:35,679
and an ascii proxy server and

504
00:21:36,480 --> 00:21:39,840
what i think is really exciting about

505
00:21:38,159 --> 00:21:44,159
being able to start to build up

506
00:21:39,840 --> 00:21:47,120
things like um

507
00:21:44,159 --> 00:21:47,840
gateway services is i think python

508
00:21:47,120 --> 00:21:49,918
really hits

509
00:21:47,840 --> 00:21:51,360
starts to hit a sweet spot between

510
00:21:49,919 --> 00:21:54,000
productivity

511
00:21:51,360 --> 00:21:55,520
and performance typically for this sort

512
00:21:54,000 --> 00:21:55,840
of thing in the past you've wanted to

513
00:21:55,520 --> 00:21:57,520
use

514
00:21:55,840 --> 00:21:59,199
node if you want to do this sort of

515
00:21:57,520 --> 00:22:02,559
thing or maybe go

516
00:21:59,200 --> 00:22:05,919
um what else have we got

517
00:22:02,559 --> 00:22:10,240
plugging directly into web apps

518
00:22:05,919 --> 00:22:12,080
so yes you can direct your htc's pre

519
00:22:10,240 --> 00:22:13,919
requests to a whiskey or an

520
00:22:12,080 --> 00:22:15,760
ascii app rather than actually sending

521
00:22:13,919 --> 00:22:18,080
them out over the network

522
00:22:15,760 --> 00:22:19,280
that's useful for using as a test client

523
00:22:18,080 --> 00:22:22,720
it's also useful

524
00:22:19,280 --> 00:22:25,039
for writing in you know sometimes

525
00:22:22,720 --> 00:22:26,240
you don't actually want to be sending

526
00:22:25,039 --> 00:22:27,200
out requests you just want to be

527
00:22:26,240 --> 00:22:29,760
simulating it

528
00:22:27,200 --> 00:22:31,280
say if you're in your staging

529
00:22:29,760 --> 00:22:32,080
environment or when you're testing

530
00:22:31,280 --> 00:22:34,480
locally

531
00:22:32,080 --> 00:22:35,360
it's really useful to be able to stub

532
00:22:34,480 --> 00:22:38,840
out

533
00:22:35,360 --> 00:22:41,840
mocks there and switch depending on the

534
00:22:38,840 --> 00:22:41,840
environment

535
00:22:44,480 --> 00:22:48,080
now one of the technical challenges in

536
00:22:46,720 --> 00:22:51,039
this has been

537
00:22:48,080 --> 00:22:52,158
how do you build an api that supports

538
00:22:51,039 --> 00:22:54,080
both

539
00:22:52,159 --> 00:22:55,760
the synchronous variant and the async

540
00:22:54,080 --> 00:22:59,120
variant without just

541
00:22:55,760 --> 00:23:00,559
copying everything in two separate sets

542
00:22:59,120 --> 00:23:03,199
of code bases

543
00:23:00,559 --> 00:23:04,399
we initially started out with this kind

544
00:23:03,200 --> 00:23:06,480
of bridging approach

545
00:23:04,400 --> 00:23:08,240
whereby everything under the hood was

546
00:23:06,480 --> 00:23:10,400
actually running async

547
00:23:08,240 --> 00:23:12,240
and for the synchronous variant you just

548
00:23:10,400 --> 00:23:15,520
run this little kind of shim

549
00:23:12,240 --> 00:23:16,720
layer over the top and you run your

550
00:23:15,520 --> 00:23:20,000
event loop

551
00:23:16,720 --> 00:23:21,840
behind the scenes underneath that turns

552
00:23:20,000 --> 00:23:23,600
out there were some issues with that

553
00:23:21,840 --> 00:23:25,039
which were pretty intractable so we've

554
00:23:23,600 --> 00:23:26,879
ended up switching well

555
00:23:25,039 --> 00:23:29,919
we're in the process of switching over

556
00:23:26,880 --> 00:23:33,520
to a slightly different approach

557
00:23:29,919 --> 00:23:35,039
we've got something um

558
00:23:33,520 --> 00:23:37,760
in the interim that's working really

559
00:23:35,039 --> 00:23:40,960
well

560
00:23:37,760 --> 00:23:44,320
so i'm in a bit of a rush now but

561
00:23:40,960 --> 00:23:47,279
some of the components that we've used

562
00:23:44,320 --> 00:23:49,120
to build this up uh there's two packages

563
00:23:47,279 --> 00:23:50,480
in particular that are absolutely

564
00:23:49,120 --> 00:23:54,158
outstanding

565
00:23:50,480 --> 00:23:58,000
uh pieces of work h11 and h2

566
00:23:54,159 --> 00:24:01,360
which are deal with our

567
00:23:58,000 --> 00:24:04,640
the core http parsing

568
00:24:01,360 --> 00:24:08,639
for us

569
00:24:04,640 --> 00:24:11,440
at the moment so requests

570
00:24:08,640 --> 00:24:13,200
under the hood uses the url lib three

571
00:24:11,440 --> 00:24:16,480
package to actually do the

572
00:24:13,200 --> 00:24:20,559
now send a network request at the moment

573
00:24:16,480 --> 00:24:24,320
our synchronous client also uses url

574
00:24:20,559 --> 00:24:27,360
url lib3 when it's sending requests

575
00:24:24,320 --> 00:24:32,879
and the async client uses our own

576
00:24:27,360 --> 00:24:34,959
engine that we've developed from scratch

577
00:24:32,880 --> 00:24:36,240
um the thing that we're changing the

578
00:24:34,960 --> 00:24:36,799
biggest thing that we're changing at the

579
00:24:36,240 --> 00:24:38,640
moment

580
00:24:36,799 --> 00:24:40,559
is getting rid of that and making sure

581
00:24:38,640 --> 00:24:43,919
that we're using the same

582
00:24:40,559 --> 00:24:46,799
engine in both places uh

583
00:24:43,919 --> 00:24:48,480
sorry i've ended up rushing a little bit

584
00:24:46,799 --> 00:24:51,600
towards the end

585
00:24:48,480 --> 00:24:53,840
so quick look at some of the other stuff

586
00:24:51,600 --> 00:24:57,120
that's on the horizon

587
00:24:53,840 --> 00:24:59,439
um streaming multi-part uploads

588
00:24:57,120 --> 00:25:00,719
so with one of the things that's

589
00:24:59,440 --> 00:25:03,200
difficult to do with multiple

590
00:25:00,720 --> 00:25:04,159
uploads is typically say with requests

591
00:25:03,200 --> 00:25:06,559
it will

592
00:25:04,159 --> 00:25:07,760
pull the whole if you're doing a file

593
00:25:06,559 --> 00:25:09,520
upload

594
00:25:07,760 --> 00:25:11,279
and you're using multi-part it will pull

595
00:25:09,520 --> 00:25:12,320
that whole file into memory and then

596
00:25:11,279 --> 00:25:14,240
send the request

597
00:25:12,320 --> 00:25:16,240
and it needs to do that because it might

598
00:25:14,240 --> 00:25:18,640
get a redirect response and it might

599
00:25:16,240 --> 00:25:21,679
need to resend it

600
00:25:18,640 --> 00:25:22,880
we've taken care of how we're going to

601
00:25:21,679 --> 00:25:25,919
be able to

602
00:25:22,880 --> 00:25:29,760
provide streaming but rewindable

603
00:25:25,919 --> 00:25:33,360
multi-part uploads um http

604
00:25:29,760 --> 00:25:35,679
3 support uh jeremy lane is doing

605
00:25:33,360 --> 00:25:36,719
stacks of work in this in python and i

606
00:25:35,679 --> 00:25:39,200
think

607
00:25:36,720 --> 00:25:40,960
yeah that's something that we're going

608
00:25:39,200 --> 00:25:45,039
to be looking at in the future

609
00:25:40,960 --> 00:25:45,039
almost certainly um

610
00:25:49,279 --> 00:25:52,320
one of the other big things that we're

611
00:25:50,720 --> 00:25:55,760
looking at as well is taking

612
00:25:52,320 --> 00:25:58,720
our core networking components and

613
00:25:55,760 --> 00:26:00,000
isolating that into a really really

614
00:25:58,720 --> 00:26:02,880
tightly scoped

615
00:26:00,000 --> 00:26:04,080
independent package that just makes

616
00:26:02,880 --> 00:26:06,400
network requests

617
00:26:04,080 --> 00:26:08,240
doesn't do any of the client smarts

618
00:26:06,400 --> 00:26:10,000
doesn't have any request or response

619
00:26:08,240 --> 00:26:11,520
models over it but it's just the data

620
00:26:10,000 --> 00:26:13,679
primitives here's how you make a request

621
00:26:11,520 --> 00:26:15,840
is how you get a response and being able

622
00:26:13,679 --> 00:26:17,039
to do that both in the sync case and in

623
00:26:15,840 --> 00:26:20,080
the async case

624
00:26:17,039 --> 00:26:20,480
and in the async case supporting i think

625
00:26:20,080 --> 00:26:22,320
i o

626
00:26:20,480 --> 00:26:24,159
supporting trio hopefully in the future

627
00:26:22,320 --> 00:26:25,360
supporting curio maybe supporting

628
00:26:24,159 --> 00:26:26,880
twisted as well

629
00:26:25,360 --> 00:26:28,879
so that we've got this one really

630
00:26:26,880 --> 00:26:32,720
tightly scoped based package

631
00:26:28,880 --> 00:26:35,840
that then the client can sit on top of

632
00:26:32,720 --> 00:26:52,799
and i think we're probably

633
00:26:35,840 --> 00:26:52,799
all right thank you yes

