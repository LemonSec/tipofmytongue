1
00:00:10,539 --> 00:00:30,250
your talk starts at 30 he's gonna be

2
00:00:21,010 --> 00:00:31,029
talking<font color="#CCCCCC"> about Thanks so</font><font color="#E5E5E5"> hi my name is</font>

3
00:00:30,250 --> 00:00:33,730
Romain

4
00:00:31,029 --> 00:00:48,010
I'm a former<font color="#CCCCCC"> Internet source</font><font color="#E5E5E5"> and I'm</font>

5
00:00:33,730 --> 00:00:52,870
going to talk what<font color="#E5E5E5"> what have they done</font>

6
00:00:48,010 --> 00:00:56,110
oh my god<font color="#CCCCCC"> okay in your pocket I</font><font color="#E5E5E5"> also</font>

7
00:00:52,870 --> 00:00:59,349
talk as<font color="#E5E5E5"> long</font><font color="#CCCCCC"> as possible because</font><font color="#E5E5E5"> there's</font>

8
00:00:56,110 --> 00:01:05,289
no the mic is<font color="#E5E5E5"> only for the recorder let</font>

9
00:00:59,350 --> 00:01:07,270
me pick<font color="#CCCCCC"> okay so I was saying</font><font color="#E5E5E5"> I'm a</font>

10
00:01:05,289 --> 00:01:09,670
<font color="#E5E5E5">formal</font><font color="#CCCCCC"> sauced intern and I'm going to</font>

11
00:01:07,270 --> 00:01:12,130
talk<font color="#CCCCCC"> about a project I worked on</font><font color="#E5E5E5"> during</font>

12
00:01:09,670 --> 00:01:15,820
my<font color="#E5E5E5"> time</font><font color="#CCCCCC"> now it's an open source</font><font color="#E5E5E5"> project</font>

13
00:01:12,130 --> 00:01:18,369
called<font color="#E5E5E5"> gemiini and it basically tries to</font>

14
00:01:15,820 --> 00:01:20,320
deduplicate large amounts<font color="#E5E5E5"> of code so</font>

15
00:01:18,369 --> 00:01:22,990
before talking<font color="#E5E5E5"> about how gemiini works</font>

16
00:01:20,320 --> 00:01:25,990
and the<font color="#CCCCCC"> results I got while applying</font><font color="#E5E5E5"> it</font>

17
00:01:22,990 --> 00:01:30,039
<font color="#E5E5E5">I'm just going</font><font color="#CCCCCC"> to go over some elements</font>

18
00:01:25,990 --> 00:01:32,830
of deduplication<font color="#E5E5E5"> so first off what are</font>

19
00:01:30,040 --> 00:01:36,400
called clones so<font color="#E5E5E5"> called clones at a high</font>

20
00:01:32,830 --> 00:01:39,369
level<font color="#CCCCCC"> or snippets that show little to no</font>

21
00:01:36,400 --> 00:01:42,850
differences so a<font color="#E5E5E5"> natural language</font>

22
00:01:39,369 --> 00:01:44,979
usually<font color="#CCCCCC"> we can basically say where</font><font color="#E5E5E5"> the</font>

23
00:01:42,850 --> 00:01:47,080
two<font color="#E5E5E5"> sentences or more</font><font color="#CCCCCC"> or similar just</font><font color="#E5E5E5"> by</font>

24
00:01:44,979 --> 00:01:49,810
looking at<font color="#E5E5E5"> some tactical features so</font>

25
00:01:47,080 --> 00:01:52,119
here I highlighted for example<font color="#E5E5E5"> exactly</font>

26
00:01:49,810 --> 00:01:54,159
similar words and even<font color="#CCCCCC"> if we try</font><font color="#E5E5E5"> to make</font>

27
00:01:52,119 --> 00:01:56,189
this form of a bit harder<font color="#E5E5E5"> so for</font>

28
00:01:54,159 --> 00:01:58,930
<font color="#E5E5E5">instance by</font><font color="#CCCCCC"> using synonyms like</font><font color="#E5E5E5"> this</font>

29
00:01:56,189 --> 00:02:01,329
<font color="#E5E5E5">today in the NLP so natural language</font>

30
00:01:58,930 --> 00:02:03,780
processing<font color="#CCCCCC"> we're able to vectorize</font>

31
00:02:01,329 --> 00:02:06,520
tokens<font color="#CCCCCC"> in spaces</font><font color="#E5E5E5"> which will yield</font>

32
00:02:03,780 --> 00:02:12,099
similar vectors for words<font color="#E5E5E5"> that have</font>

33
00:02:06,520 --> 00:02:14,168
<font color="#CCCCCC">similar meaning so however</font><font color="#E5E5E5"> in for trying</font>

34
00:02:12,099 --> 00:02:15,700
<font color="#E5E5E5">to find similarities between code this</font>

35
00:02:14,169 --> 00:02:17,680
<font color="#E5E5E5">is a much</font><font color="#CCCCCC"> harder problem because you</font>

36
00:02:15,700 --> 00:02:18,310
usually have<font color="#CCCCCC"> some</font><font color="#E5E5E5"> tactical as well as</font>

37
00:02:17,680 --> 00:02:21,099
structure

38
00:02:18,310 --> 00:02:23,819
language<font color="#E5E5E5"> that</font><font color="#CCCCCC"> effectively semantics so</font>

39
00:02:21,099 --> 00:02:26,470
what happens when you<font color="#CCCCCC"> compile a code</font>

40
00:02:23,819 --> 00:02:28,810
<font color="#E5E5E5">every different snippets so lots been a</font>

41
00:02:26,470 --> 00:02:30,849
extensive research done in<font color="#E5E5E5"> this field</font>

42
00:02:28,810 --> 00:02:34,209
which have led to<font color="#E5E5E5"> a taxonomy of</font>

43
00:02:30,849 --> 00:02:36,579
<font color="#E5E5E5">different kinds of clones</font><font color="#CCCCCC"> so we usually</font>

44
00:02:34,209 --> 00:02:39,090
use four types so the<font color="#E5E5E5"> first is basically</font>

45
00:02:36,580 --> 00:02:42,069
<font color="#E5E5E5">copy-paste clones</font><font color="#CCCCCC"> if you remove</font><font color="#E5E5E5"> all</font>

46
00:02:39,090 --> 00:02:44,800
things<font color="#E5E5E5"> that are not code any</font><font color="#CCCCCC"> snippets of</font>

47
00:02:42,069 --> 00:02:45,369
<font color="#CCCCCC">Winston's comments white</font><font color="#E5E5E5"> spaces stuff</font>

48
00:02:44,800 --> 00:02:47,739
like<font color="#E5E5E5"> that</font>

49
00:02:45,370 --> 00:02:50,200
the second type is structurally similar

50
00:02:47,739 --> 00:02:52,690
code so imagine two snippets with

51
00:02:50,200 --> 00:02:55,390
different identifiers<font color="#CCCCCC"> you</font><font color="#E5E5E5"> type free as a</font>

52
00:02:52,690 --> 00:02:57,670
<font color="#CCCCCC">combination of both with minor changes</font>

53
00:02:55,390 --> 00:03:01,059
like additions insertions deletions

54
00:02:57,670 --> 00:03:03,849
<font color="#CCCCCC">stuff like</font><font color="#E5E5E5"> that and finally you type</font>

55
00:03:01,060 --> 00:03:07,959
<font color="#CCCCCC">four which is</font><font color="#E5E5E5"> the most hard to detect is</font>

56
00:03:03,849 --> 00:03:10,349
semantically semantical clones<font color="#E5E5E5"> so just</font>

57
00:03:07,959 --> 00:03:13,239
snippets that compute these same

58
00:03:10,349 --> 00:03:15,760
calculations and output the same result

59
00:03:13,239 --> 00:03:17,709
but can do it in<font color="#E5E5E5"> different ways so as an</font>

60
00:03:15,760 --> 00:03:20,530
example here<font color="#CCCCCC"> are two</font><font color="#E5E5E5"> function that do</font>

61
00:03:17,709 --> 00:03:22,120
exactly<font color="#E5E5E5"> the</font><font color="#CCCCCC"> same thing</font><font color="#E5E5E5"> but do it in</font>

62
00:03:20,530 --> 00:03:24,760
completely different ways with different

63
00:03:22,120 --> 00:03:28,900
identifiers and well<font color="#E5E5E5"> just looking at the</font>

64
00:03:24,760 --> 00:03:31,209
syntax one will not<font color="#E5E5E5"> be able</font><font color="#CCCCCC"> to judge</font>

65
00:03:28,900 --> 00:03:34,390
whether<font color="#CCCCCC"> these is lipids are the same or</font>

66
00:03:31,209 --> 00:03:36,310
<font color="#CCCCCC">not at least</font><font color="#E5E5E5"> not</font><font color="#CCCCCC"> easily</font><font color="#E5E5E5"> so I'm going to</font>

67
00:03:34,390 --> 00:03:38,619
<font color="#E5E5E5">talk</font><font color="#CCCCCC"> about the baseline approach before</font>

68
00:03:36,310 --> 00:03:42,180
<font color="#E5E5E5">talking</font><font color="#CCCCCC"> about</font><font color="#E5E5E5"> Germany so this is a</font>

69
00:03:38,620 --> 00:03:46,480
<font color="#E5E5E5">review</font><font color="#CCCCCC"> paper which</font><font color="#E5E5E5"> was released in 2017</font>

70
00:03:42,180 --> 00:03:49,510
which tried to<font color="#E5E5E5"> duplicate about 480</font>

71
00:03:46,480 --> 00:03:52,238
million files<font color="#E5E5E5"> using a free level</font>

72
00:03:49,510 --> 00:03:54,760
granularity<font color="#E5E5E5"> skim so the first thing they</font>

73
00:03:52,239 --> 00:03:58,410
did<font color="#E5E5E5"> was like I said before we move all</font>

74
00:03:54,760 --> 00:04:01,660
comments<font color="#CCCCCC"> all white spaces</font><font color="#E5E5E5"> and just hash</font>

75
00:03:58,410 --> 00:04:04,269
each file<font color="#E5E5E5"> computing a file hash and then</font>

76
00:04:01,660 --> 00:04:06,069
trying to<font color="#E5E5E5"> zero which hash is all the</font>

77
00:04:04,269 --> 00:04:08,859
same and which are not<font color="#E5E5E5"> the second level</font>

78
00:04:06,069 --> 00:04:11,380
was after extracting<font color="#E5E5E5"> tokens and creating</font>

79
00:04:08,859 --> 00:04:14,620
bag of<font color="#E5E5E5"> features as</font><font color="#CCCCCC"> you can see here they</font>

80
00:04:11,380 --> 00:04:17,409
hashed the strings of tokens which

81
00:04:14,620 --> 00:04:20,228
produces second hash and the third level

82
00:04:17,410 --> 00:04:22,300
was using all these<font color="#E5E5E5"> extracted tokens</font>

83
00:04:20,228 --> 00:04:28,510
they<font color="#CCCCCC"> used the troll coughs also were CC</font>

84
00:04:22,300 --> 00:04:31,180
which<font color="#CCCCCC"> is able</font><font color="#E5E5E5"> to basically tell so you</font>

85
00:04:28,510 --> 00:04:35,320
<font color="#CCCCCC">latter</font><font color="#E5E5E5"> two snippets are similar</font>

86
00:04:31,180 --> 00:04:37,510
if Felicia<font color="#E5E5E5"> about 80% similar clones so</font>

87
00:04:35,320 --> 00:04:41,080
<font color="#CCCCCC">the results they found on applying</font><font color="#E5E5E5"> this</font>

88
00:04:37,510 --> 00:04:43,090
on about<font color="#E5E5E5"> 400 million snippets of files</font>

89
00:04:41,080 --> 00:04:44,830
of<font color="#CCCCCC"> code</font><font color="#E5E5E5"> was lat</font>

90
00:04:43,090 --> 00:04:47,229
basically<font color="#E5E5E5"> if you</font><font color="#CCCCCC"> look at a file on</font>

91
00:04:44,830 --> 00:04:50,020
github<font color="#CCCCCC"> you have about an 80% chance</font>

92
00:04:47,230 --> 00:04:52,780
<font color="#CCCCCC">that's a similar file exists somewhere</font>

93
00:04:50,020 --> 00:04:55,270
on github which<font color="#CCCCCC"> were brilliant passive</font>

94
00:04:52,780 --> 00:04:58,719
results so however from what I just

95
00:04:55,270 --> 00:05:01,359
<font color="#E5E5E5">explained</font><font color="#CCCCCC"> to you before I think you can</font>

96
00:04:58,720 --> 00:05:03,610
deduce<font color="#E5E5E5"> from this</font><font color="#CCCCCC"> Bethenny's methods</font><font color="#E5E5E5"> that</font>

97
00:05:01,360 --> 00:05:05,860
they can't actually do much small and

98
00:05:03,610 --> 00:05:08,530
detect type<font color="#E5E5E5"> 1 and type 2 clones</font>

99
00:05:05,860 --> 00:05:10,930
possibly type 2 it might<font color="#E5E5E5"> be a problem if</font>

100
00:05:08,530 --> 00:05:15,039
too many tokens<font color="#E5E5E5"> are altered and type 3</font>

101
00:05:10,930 --> 00:05:16,510
and<font color="#E5E5E5"> for all</font><font color="#CCCCCC"> probably out of</font><font color="#E5E5E5"> which this</font>

102
00:05:15,040 --> 00:05:19,030
<font color="#E5E5E5">is</font><font color="#CCCCCC"> where I add sourced we developed a</font>

103
00:05:16,510 --> 00:05:22,599
<font color="#E5E5E5">project called</font><font color="#CCCCCC"> gemiini so I'm</font><font color="#E5E5E5"> first</font>

104
00:05:19,030 --> 00:05:25,150
<font color="#E5E5E5">going to outline the</font><font color="#CCCCCC"> main steps</font><font color="#E5E5E5"> we do</font>

105
00:05:22,600 --> 00:05:28,000
and applying this this algorithm and

106
00:05:25,150 --> 00:05:30,849
then I'll get more<font color="#CCCCCC"> into exactly what we</font>

107
00:05:28,000 --> 00:05:33,790
do<font color="#E5E5E5"> and how we do it and why it works</font><font color="#CCCCCC"> so</font>

108
00:05:30,850 --> 00:05:36,370
<font color="#CCCCCC">Germany has four steps the first steps</font>

109
00:05:33,790 --> 00:05:39,100
is<font color="#CCCCCC"> that out</font><font color="#E5E5E5"> of the</font><font color="#CCCCCC"> dataset</font><font color="#E5E5E5"> we</font><font color="#CCCCCC"> are going</font>

110
00:05:36,370 --> 00:05:41,020
to extract<font color="#E5E5E5"> a certain amount of</font><font color="#CCCCCC"> features</font>

111
00:05:39,100 --> 00:05:43,030
which are<font color="#CCCCCC"> going to be syntactical</font><font color="#E5E5E5"> as</font>

112
00:05:41,020 --> 00:05:45,460
well as structural I'll get more<font color="#E5E5E5"> into</font>

113
00:05:43,030 --> 00:05:47,830
<font color="#E5E5E5">depth into what kind of features we use</font>

114
00:05:45,460 --> 00:05:50,500
and why we use<font color="#CCCCCC"> them the next step is</font>

115
00:05:47,830 --> 00:05:54,039
creating<font color="#CCCCCC"> a pairwise humidity graph</font>

116
00:05:50,500 --> 00:05:56,140
between<font color="#E5E5E5"> our snippets so basically in</font>

117
00:05:54,040 --> 00:05:58,600
this graph each node is<font color="#CCCCCC"> going to</font>

118
00:05:56,140 --> 00:06:01,000
represent<font color="#E5E5E5"> a file and two nodes will</font><font color="#CCCCCC"> be</font>

119
00:05:58,600 --> 00:06:03,970
connected if they are similar<font color="#CCCCCC"> enough</font>

120
00:06:01,000 --> 00:06:05,170
again<font color="#CCCCCC"> I'll get more into depth into what</font>

121
00:06:03,970 --> 00:06:07,390
<font color="#CCCCCC">this means</font>

122
00:06:05,170 --> 00:06:11,080
so if third step is out of<font color="#E5E5E5"> this huge</font>

123
00:06:07,390 --> 00:06:15,039
graph the most interesting parts of<font color="#E5E5E5"> this</font>

124
00:06:11,080 --> 00:06:17,349
graph are actually parts<font color="#CCCCCC"> of the graph</font><font color="#E5E5E5"> or</font>

125
00:06:15,040 --> 00:06:18,910
groups of<font color="#CCCCCC"> uf</font><font color="#E5E5E5"> which consists of files</font>

126
00:06:17,350 --> 00:06:21,040
<font color="#E5E5E5">which are all</font><font color="#CCCCCC"> connected one to each</font>

127
00:06:18,910 --> 00:06:24,190
other<font color="#E5E5E5"> either directly or indirectly</font>

128
00:06:21,040 --> 00:06:25,420
<font color="#E5E5E5">through hops so well this is in graph</font>

129
00:06:24,190 --> 00:06:27,940
theory this is called connected

130
00:06:25,420 --> 00:06:30,090
components and we extract this from the

131
00:06:27,940 --> 00:06:33,460
graph of similarity<font color="#E5E5E5"> that we've created</font>

132
00:06:30,090 --> 00:06:35,500
<font color="#CCCCCC">the final step in Germany is on each</font><font color="#E5E5E5"> of</font>

133
00:06:33,460 --> 00:06:38,349
these connected components we apply

134
00:06:35,500 --> 00:06:41,410
community detection<font color="#E5E5E5"> in order to find the</font>

135
00:06:38,350 --> 00:06:44,090
<font color="#E5E5E5">final</font><font color="#CCCCCC"> clone communities</font><font color="#E5E5E5"> so I'll go a bit</font>

136
00:06:41,410 --> 00:06:47,389
<font color="#CCCCCC">more in depth</font><font color="#E5E5E5"> on why we do that later</font>

137
00:06:44,090 --> 00:06:49,520
so let's first go<font color="#CCCCCC"> on the first step so</font>

138
00:06:47,389 --> 00:06:52,669
extracting<font color="#CCCCCC"> SiC tax</font><font color="#E5E5E5"> and tactical and</font>

139
00:06:49,520 --> 00:06:55,070
structural features so as you<font color="#E5E5E5"> can</font>

140
00:06:52,669 --> 00:06:57,680
<font color="#CCCCCC">imagine we can't actually extract such</font>

141
00:06:55,070 --> 00:07:00,560
structural<font color="#E5E5E5"> features just from</font><font color="#CCCCCC"> plaintext</font>

142
00:06:57,680 --> 00:07:03,169
code to do<font color="#E5E5E5"> that we have to go to a lower</font>

143
00:07:00,560 --> 00:07:05,480
representation of code<font color="#E5E5E5"> so namely</font>

144
00:07:03,169 --> 00:07:07,609
abstract syntax<font color="#E5E5E5"> twist so for those of</font>

145
00:07:05,480 --> 00:07:10,490
<font color="#E5E5E5">you who don't</font><font color="#CCCCCC"> know this</font><font color="#E5E5E5"> data structure</font>

146
00:07:07,610 --> 00:07:12,740
it's used in compilers<font color="#CCCCCC"> for syntactic</font>

147
00:07:10,490 --> 00:07:15,830
analysis and it looks roughly like

148
00:07:12,740 --> 00:07:18,020
something like<font color="#E5E5E5"> this so this is clearly a</font>

149
00:07:15,830 --> 00:07:21,800
<font color="#CCCCCC">very simplified version of an AST is</font>

150
00:07:18,020 --> 00:07:23,719
probably not<font color="#E5E5E5"> even correct but one of the</font>

151
00:07:21,800 --> 00:07:27,169
properties<font color="#CCCCCC"> let each of these nodes</font><font color="#E5E5E5"> have</font>

152
00:07:23,720 --> 00:07:30,010
is an internal type so for instance here

153
00:07:27,169 --> 00:07:33,620
<font color="#E5E5E5">you can see identifiers statements</font>

154
00:07:30,010 --> 00:07:36,050
declarations operations and so we're

155
00:07:33,620 --> 00:07:38,330
mostly going<font color="#E5E5E5"> to be</font><font color="#CCCCCC"> able to</font><font color="#E5E5E5"> extract</font>

156
00:07:36,050 --> 00:07:43,280
structural features from list data

157
00:07:38,330 --> 00:07:44,900
structure so before describing<font color="#E5E5E5"> each of</font>

158
00:07:43,280 --> 00:07:46,880
the features<font color="#CCCCCC"> you can imagine that</font>

159
00:07:44,900 --> 00:07:49,909
<font color="#E5E5E5">differing languages are going to have</font>

160
00:07:46,880 --> 00:07:52,580
different<font color="#CCCCCC"> kinds of ast s so for</font><font color="#E5E5E5"> those of</font>

161
00:07:49,910 --> 00:07:55,880
you which were here before<font color="#CCCCCC"> Vadim talked</font>

162
00:07:52,580 --> 00:07:57,469
a bit about<font color="#E5E5E5"> lists we developed at</font><font color="#CCCCCC"> source</font>

163
00:07:55,880 --> 00:08:01,280
<font color="#CCCCCC">top project which is named Babel Fish</font>

164
00:07:57,470 --> 00:08:04,520
<font color="#CCCCCC">which aims</font><font color="#E5E5E5"> at creating a unified the</font>

165
00:08:01,280 --> 00:08:07,039
abstract syntax tree so giving any fire

166
00:08:04,520 --> 00:08:08,599
of any language<font color="#CCCCCC"> you would obtain</font><font color="#E5E5E5"> the</font>

167
00:08:07,039 --> 00:08:11,300
same data<font color="#E5E5E5"> structure which can then be</font>

168
00:08:08,600 --> 00:08:12,919
<font color="#CCCCCC">used in</font><font color="#E5E5E5"> a unified way</font><font color="#CCCCCC"> so this</font><font color="#E5E5E5"> is pretty</font>

169
00:08:11,300 --> 00:08:17,270
useful<font color="#CCCCCC"> because that's why we don't</font><font color="#E5E5E5"> have</font>

170
00:08:12,919 --> 00:08:18,620
to create code for each kind of language

171
00:08:17,270 --> 00:08:21,460
and<font color="#E5E5E5"> you</font><font color="#CCCCCC"> can just transform everything</font>

172
00:08:18,620 --> 00:08:23,900
<font color="#E5E5E5">into Universal way STS and work on that</font>

173
00:08:21,460 --> 00:08:26,539
<font color="#E5E5E5">so first</font><font color="#CCCCCC"> I'm going to go over the two</font>

174
00:08:23,900 --> 00:08:28,849
<font color="#CCCCCC">syntactical features that we used so</font>

175
00:08:26,539 --> 00:08:30,950
identify<font color="#E5E5E5"> Lysander</font><font color="#CCCCCC"> two also identifiers</font>

176
00:08:28,850 --> 00:08:33,830
so basically variable or function names

177
00:08:30,950 --> 00:08:36,289
and literals<font color="#CCCCCC"> are values so for</font><font color="#E5E5E5"> instance</font>

178
00:08:33,830 --> 00:08:38,990
here<font color="#E5E5E5"> I hided</font><font color="#CCCCCC"> no</font><font color="#E5E5E5"> I</font><font color="#CCCCCC"> highlighted in lemon</font>

179
00:08:36,289 --> 00:08:42,080
green and the<font color="#E5E5E5"> identifier</font><font color="#CCCCCC"> czar in blue I</font>

180
00:08:38,990 --> 00:08:45,260
<font color="#E5E5E5">think it's pretty straightforward</font><font color="#CCCCCC"> so</font>

181
00:08:42,080 --> 00:08:47,390
<font color="#CCCCCC">fully structual</font><font color="#E5E5E5"> we used for kind</font><font color="#CCCCCC"> of</font>

182
00:08:45,260 --> 00:08:49,819
structural features<font color="#CCCCCC"> each I'm going</font><font color="#E5E5E5"> to</font>

183
00:08:47,390 --> 00:08:53,480
talk about<font color="#E5E5E5"> our graph let's and children</font>

184
00:08:49,820 --> 00:08:55,430
so a graph let in a graph is basically a

185
00:08:53,480 --> 00:08:57,980
given node as well<font color="#CCCCCC"> as</font><font color="#E5E5E5"> all its children</font>

186
00:08:55,430 --> 00:09:00,229
<font color="#E5E5E5">so as</font><font color="#CCCCCC"> you can see here we don't</font><font color="#E5E5E5"> actually</font>

187
00:08:57,980 --> 00:09:01,730
for<font color="#CCCCCC"> releasing tactical data so we don't</font>

188
00:09:00,230 --> 00:09:04,220
care with<font color="#CCCCCC"> that</font><font color="#E5E5E5"> you know this called</font>

189
00:09:01,730 --> 00:09:07,030
<font color="#E5E5E5">death who</font><font color="#CCCCCC"> acts on</font><font color="#E5E5E5"> return we actually</font>

190
00:09:04,220 --> 00:09:10,610
<font color="#CCCCCC">relies purely</font><font color="#E5E5E5"> on the nodes internal type</font>

191
00:09:07,030 --> 00:09:13,490
so<font color="#E5E5E5"> we create so here I showed you how we</font>

192
00:09:10,610 --> 00:09:15,950
extract<font color="#CCCCCC"> our</font><font color="#E5E5E5"> graph let's sorry children</font>

193
00:09:13,490 --> 00:09:18,080
feature is actually<font color="#CCCCCC"> just each node and</font>

194
00:09:15,950 --> 00:09:20,540
the number of children nodes that it has

195
00:09:18,080 --> 00:09:22,700
<font color="#E5E5E5">and once you convert this to a weighted</font>

196
00:09:20,540 --> 00:09:25,819
bag of<font color="#E5E5E5"> features it looks something like</font>

197
00:09:22,700 --> 00:09:28,970
this so for<font color="#E5E5E5"> instance we</font><font color="#CCCCCC"> have the</font>

198
00:09:25,820 --> 00:09:31,340
identifier and no nodes and no children

199
00:09:28,970 --> 00:09:35,000
nodes which appears free time in this

200
00:09:31,340 --> 00:09:37,190
example<font color="#E5E5E5"> so we as I said we used four</font>

201
00:09:35,000 --> 00:09:41,270
kinds of structural features the two

202
00:09:37,190 --> 00:09:44,420
others are<font color="#CCCCCC"> basically just how</font><font color="#E5E5E5"> would I</font>

203
00:09:41,270 --> 00:09:47,510
say<font color="#E5E5E5"> I</font><font color="#CCCCCC"> can't concatenations</font><font color="#E5E5E5"> of of</font>

204
00:09:44,420 --> 00:09:50,360
different<font color="#CCCCCC"> internal types that we obtain</font>

205
00:09:47,510 --> 00:09:52,700
by<font color="#E5E5E5"> traversing the</font><font color="#CCCCCC"> ast s in two different</font>

206
00:09:50,360 --> 00:09:55,370
<font color="#E5E5E5">ways</font><font color="#CCCCCC"> one using a depth-first</font><font color="#E5E5E5"> search and</font>

207
00:09:52,700 --> 00:09:57,890
the second one using<font color="#E5E5E5"> a random walk</font><font color="#CCCCCC"> I</font>

208
00:09:55,370 --> 00:10:00,560
won't get too<font color="#CCCCCC"> much into why we use these</font>

209
00:09:57,890 --> 00:10:03,410
features<font color="#E5E5E5"> but we</font><font color="#CCCCCC"> thought</font><font color="#E5E5E5"> that they would</font>

210
00:10:00,560 --> 00:10:07,910
be<font color="#CCCCCC"> able to capture</font><font color="#E5E5E5"> long longer-term</font>

211
00:10:03,410 --> 00:10:11,569
structural structural information<font color="#CCCCCC"> of</font>

212
00:10:07,910 --> 00:10:13,130
<font color="#CCCCCC">these</font><font color="#E5E5E5"> lipids</font><font color="#CCCCCC"> so we thought</font><font color="#E5E5E5"> that</font><font color="#CCCCCC"> these</font>

213
00:10:11,570 --> 00:10:15,920
features<font color="#CCCCCC"> were good however</font><font color="#E5E5E5"> we don't</font>

214
00:10:13,130 --> 00:10:18,320
<font color="#E5E5E5">actually have any metric or any pure</font>

215
00:10:15,920 --> 00:10:20,270
<font color="#CCCCCC">region pure reason</font><font color="#E5E5E5"> other than intuition</font>

216
00:10:18,320 --> 00:10:23,180
<font color="#CCCCCC">that leaves with good</font><font color="#E5E5E5"> features however</font>

217
00:10:20,270 --> 00:10:24,740
as you'll see a bit later<font color="#E5E5E5"> we</font><font color="#CCCCCC"> actually is</font>

218
00:10:23,180 --> 00:10:31,069
<font color="#E5E5E5">actually yielded some pretty good</font>

219
00:10:24,740 --> 00:10:33,830
results<font color="#CCCCCC"> so to go back now yeah</font><font color="#E5E5E5"> so as you</font>

220
00:10:31,070 --> 00:10:36,440
can<font color="#CCCCCC"> imagine</font><font color="#E5E5E5"> extracting these features</font>

221
00:10:33,830 --> 00:10:39,410
from snippets of code is<font color="#CCCCCC"> actually yields</font>

222
00:10:36,440 --> 00:10:41,480
a<font color="#E5E5E5"> lot of features</font><font color="#CCCCCC"> so in order to reduce</font>

223
00:10:39,410 --> 00:10:43,130
<font color="#CCCCCC">that we used an NLP technique which is</font>

224
00:10:41,480 --> 00:10:45,680
called<font color="#E5E5E5"> term frequency inverse document</font>

225
00:10:43,130 --> 00:10:48,230
frequency<font color="#E5E5E5"> which basically amounts to</font>

226
00:10:45,680 --> 00:10:50,780
<font color="#CCCCCC">calculate</font><font color="#E5E5E5"> calculating a weight for each</font>

227
00:10:48,230 --> 00:10:54,130
<font color="#E5E5E5">feature and then fresh holding in order</font>

228
00:10:50,780 --> 00:10:58,209
to reduce the<font color="#E5E5E5"> amounts of features so</font>

229
00:10:54,130 --> 00:11:01,640
that's it<font color="#E5E5E5"> and it basically is able to</font>

230
00:10:58,210 --> 00:11:03,470
reject all<font color="#CCCCCC"> where features so features</font>

231
00:11:01,640 --> 00:11:06,170
that<font color="#CCCCCC"> only a part</font><font color="#E5E5E5"> appeal and maybe once</font>

232
00:11:03,470 --> 00:11:08,720
or twice<font color="#CCCCCC"> for only one</font><font color="#E5E5E5"> file or one</font>

233
00:11:06,170 --> 00:11:11,089
snippet<font color="#CCCCCC"> and it also is able</font><font color="#E5E5E5"> to reject</font>

234
00:11:08,720 --> 00:11:13,430
very common features of<font color="#E5E5E5"> each other</font>

235
00:11:11,089 --> 00:11:14,990
<font color="#E5E5E5">pío</font><font color="#CCCCCC"> I don't know 10 million times or</font>

236
00:11:13,430 --> 00:11:18,109
something<font color="#CCCCCC"> I glad so things that are not</font>

237
00:11:14,990 --> 00:11:19,970
very discriminative<font color="#E5E5E5"> so at the end of the</font>

238
00:11:18,110 --> 00:11:22,189
day if we feature extraction revolves

239
00:11:19,970 --> 00:11:25,490
about list so first converting<font color="#CCCCCC"> all files</font>

240
00:11:22,189 --> 00:11:27,439
<font color="#E5E5E5">to UA STS then extracting the Vedic bag</font>

241
00:11:25,490 --> 00:11:30,110
of features<font color="#CCCCCC"> of each</font><font color="#E5E5E5"> you</font><font color="#CCCCCC"> AST</font><font color="#E5E5E5"> applying</font>

242
00:11:27,439 --> 00:11:32,149
<font color="#CCCCCC">tf-idf in order to reduce the</font><font color="#E5E5E5"> amount of</font>

243
00:11:30,110 --> 00:11:36,259
<font color="#CCCCCC">features as you</font><font color="#E5E5E5"> can see it as a</font><font color="#CCCCCC"> fourth</font>

244
00:11:32,149 --> 00:11:40,160
step<font color="#E5E5E5"> so this is actually a step that</font>

245
00:11:36,259 --> 00:11:42,740
allows<font color="#CCCCCC"> us</font><font color="#E5E5E5"> to look</font><font color="#CCCCCC"> more</font><font color="#E5E5E5"> into biased</font>

246
00:11:40,160 --> 00:11:45,139
versions of our algorithm<font color="#E5E5E5"> we could use</font>

247
00:11:42,740 --> 00:11:47,180
<font color="#E5E5E5">purely</font><font color="#CCCCCC"> Li weighted back</font><font color="#E5E5E5"> the features as</font>

248
00:11:45,139 --> 00:11:50,149
is but if we wanted for instance to look

249
00:11:47,180 --> 00:11:51,859
at more<font color="#CCCCCC"> of</font><font color="#E5E5E5"> the structural</font><font color="#CCCCCC"> differences</font>

250
00:11:50,149 --> 00:11:54,410
between code<font color="#E5E5E5"> then</font><font color="#CCCCCC"> we would be able to</font>

251
00:11:51,860 --> 00:11:56,059
give more weight<font color="#E5E5E5"> to</font><font color="#CCCCCC"> these structural</font>

252
00:11:54,410 --> 00:11:58,490
<font color="#E5E5E5">features and invert here we could do the</font>

253
00:11:56,059 --> 00:12:01,490
<font color="#E5E5E5">same thing for some tactical features so</font>

254
00:11:58,490 --> 00:12:04,999
that was the first<font color="#E5E5E5"> step</font><font color="#CCCCCC"> that was the</font>

255
00:12:01,490 --> 00:12:07,220
first step of<font color="#E5E5E5"> Germany</font><font color="#CCCCCC"> so the second step</font>

256
00:12:04,999 --> 00:12:09,259
<font color="#E5E5E5">is the</font><font color="#CCCCCC"> hashing step</font><font color="#E5E5E5"> so we're going to</font>

257
00:12:07,220 --> 00:12:11,449
<font color="#E5E5E5">hash the features using an algorithm I'm</font>

258
00:12:09,259 --> 00:12:13,790
going to explain<font color="#E5E5E5"> in order to create the</font>

259
00:12:11,449 --> 00:12:15,740
pairwise similarity graph so at this

260
00:12:13,790 --> 00:12:17,509
<font color="#CCCCCC">point you might be wondering well we</font>

261
00:12:15,740 --> 00:12:21,079
could simply choose a given distance

262
00:12:17,509 --> 00:12:23,059
metric then apply it to<font color="#CCCCCC"> each file in</font>

263
00:12:21,079 --> 00:12:27,170
<font color="#E5E5E5">order to compute similarities between</font>

264
00:12:23,059 --> 00:12:30,439
files<font color="#CCCCCC"> however that</font><font color="#E5E5E5"> doesn't really work</font>

265
00:12:27,170 --> 00:12:32,149
<font color="#E5E5E5">the reason is that well it scales</font>

266
00:12:30,439 --> 00:12:35,389
quadratically<font color="#CCCCCC"> with the amount of</font><font color="#E5E5E5"> files</font>

267
00:12:32,149 --> 00:12:38,720
you<font color="#E5E5E5"> use so if we're trying to do this at</font>

268
00:12:35,389 --> 00:12:41,329
scale<font color="#CCCCCC"> it would</font><font color="#E5E5E5"> basically explode so in</font>

269
00:12:38,720 --> 00:12:43,449
order<font color="#E5E5E5"> to introduce the</font><font color="#CCCCCC"> early algorithm</font>

270
00:12:41,329 --> 00:12:47,329
we're going to use I'm<font color="#CCCCCC"> going</font><font color="#E5E5E5"> to have to</font>

271
00:12:43,449 --> 00:12:49,189
explain<font color="#E5E5E5"> a couple concepts so the first</font>

272
00:12:47,329 --> 00:12:51,888
thing is weighted Jaccard similarity so

273
00:12:49,189 --> 00:12:53,599
giving two sets<font color="#CCCCCC"> of features a and B now</font>

274
00:12:51,889 --> 00:12:56,600
weighted Jaccard similarity is basically

275
00:12:53,600 --> 00:13:00,290
<font color="#CCCCCC">just</font><font color="#E5E5E5"> Li intersection of both features /</font>

276
00:12:56,600 --> 00:13:01,939
<font color="#E5E5E5">Li Union so if both a and B were equal</font>

277
00:13:00,290 --> 00:13:06,998
<font color="#E5E5E5">and you can see it would be equal to</font><font color="#CCCCCC"> 1</font>

278
00:13:01,939 --> 00:13:10,248
<font color="#CCCCCC">to</font><font color="#E5E5E5"> 0 so here</font><font color="#CCCCCC"> I displayed it for integer</font>

279
00:13:06,999 --> 00:13:12,949
<font color="#E5E5E5">weighted features but it will also work</font>

280
00:13:10,249 --> 00:13:16,279
<font color="#CCCCCC">for we all value the features so</font><font color="#E5E5E5"> imagine</font>

281
00:13:12,949 --> 00:13:17,809
half<font color="#E5E5E5"> the Sun would</font><font color="#CCCCCC"> be the same so we</font><font color="#E5E5E5"> use</font>

282
00:13:16,279 --> 00:13:20,240
<font color="#CCCCCC">lists because</font><font color="#E5E5E5"> it actually has</font><font color="#CCCCCC"> a pretty</font>

283
00:13:17,809 --> 00:13:22,819
interesting property<font color="#E5E5E5"> and that is that if</font>

284
00:13:20,240 --> 00:13:24,499
we<font color="#CCCCCC"> pick a random permutation</font><font color="#E5E5E5"> over all</font>

285
00:13:22,819 --> 00:13:28,519
set of<font color="#CCCCCC"> features</font>

286
00:13:24,499 --> 00:13:31,699
and apply it to a and<font color="#CCCCCC"> B Len hash all the</font>

287
00:13:28,519 --> 00:13:34,159
<font color="#E5E5E5">elements</font><font color="#CCCCCC"> that were mutated</font><font color="#E5E5E5"> and select</font>

288
00:13:31,699 --> 00:13:37,069
<font color="#E5E5E5">the smallish the smallest hash so the</font>

289
00:13:34,159 --> 00:13:39,468
<font color="#CCCCCC">min hash</font><font color="#E5E5E5"> let</font><font color="#CCCCCC"> any probability</font><font color="#E5E5E5"> that Lisa's</font>

290
00:13:37,069 --> 00:13:41,559
values will be the same<font color="#E5E5E5"> is equal</font><font color="#CCCCCC"> to the</font>

291
00:13:39,469 --> 00:13:43,759
jack out similarity of both lipids

292
00:13:41,559 --> 00:13:46,249
<font color="#CCCCCC">what's</font><font color="#E5E5E5"> interesting with this is that</font>

293
00:13:43,759 --> 00:13:48,349
since it's a<font color="#CCCCCC"> random permutation if we</font>

294
00:13:46,249 --> 00:13:52,249
<font color="#CCCCCC">actually pick the second only</font><font color="#E5E5E5"> third only</font>

295
00:13:48,349 --> 00:13:55,249
<font color="#E5E5E5">for</font><font color="#CCCCCC"> fo the nth element</font><font color="#E5E5E5"> then this</font><font color="#CCCCCC"> Stowe</font>

296
00:13:52,249 --> 00:13:57,249
is true so if we take K values creating

297
00:13:55,249 --> 00:14:00,709
what we call a<font color="#E5E5E5"> min hash signature and</font>

298
00:13:57,249 --> 00:14:03,259
concatenate<font color="#E5E5E5"> them into what</font><font color="#CCCCCC"> we call mean</font>

299
00:14:00,709 --> 00:14:04,758
hash signature<font color="#E5E5E5"> matrix then we have the</font>

300
00:14:03,259 --> 00:14:08,869
interesting property<font color="#CCCCCC"> that for each</font>

301
00:14:04,759 --> 00:14:11,449
column<font color="#E5E5E5"> and each row the value will</font><font color="#CCCCCC"> be</font>

302
00:14:08,869 --> 00:14:13,249
<font color="#CCCCCC">equal will be the same with probability</font>

303
00:14:11,449 --> 00:14:16,429
equal to the Jaccard similarity every

304
00:14:13,249 --> 00:14:18,319
files associated to each column so

305
00:14:16,429 --> 00:14:22,309
formulas what we're going to do is we're

306
00:14:18,319 --> 00:14:24,498
going<font color="#CCCCCC"> to cut</font><font color="#E5E5E5"> our</font><font color="#CCCCCC"> matrix into bands of so</font>

307
00:14:22,309 --> 00:14:27,679
<font color="#CCCCCC">B</font><font color="#E5E5E5"> bands of our walls and we're going to</font>

308
00:14:24,499 --> 00:14:30,619
<font color="#E5E5E5">call candidate pair any two files which</font>

309
00:14:27,679 --> 00:14:33,559
<font color="#E5E5E5">only which hold the same value in at</font>

310
00:14:30,619 --> 00:14:36,289
<font color="#E5E5E5">least one band so we're now going</font><font color="#CCCCCC"> to</font>

311
00:14:33,559 --> 00:14:38,419
calculate<font color="#E5E5E5"> quickly don't vary the</font>

312
00:14:36,289 --> 00:14:41,899
probability of two<font color="#E5E5E5"> snippets</font><font color="#CCCCCC"> to be a</font>

313
00:14:38,419 --> 00:14:43,848
queen<font color="#E5E5E5"> I can do that pair so if we call</font>

314
00:14:41,899 --> 00:14:45,949
as the similarity between<font color="#E5E5E5"> two snippets</font>

315
00:14:43,849 --> 00:14:48,709
<font color="#CCCCCC">learn the probability that</font><font color="#E5E5E5"> is signature</font>

316
00:14:45,949 --> 00:14:51,978
<font color="#CCCCCC">are the same in one band is just</font><font color="#E5E5E5"> as to</font>

317
00:14:48,709 --> 00:14:53,839
the<font color="#E5E5E5"> power all so if we take the opposite</font>

318
00:14:51,979 --> 00:14:57,379
event<font color="#CCCCCC"> lattice</font><font color="#E5E5E5"> they are different in one</font>

319
00:14:53,839 --> 00:14:59,299
band<font color="#E5E5E5"> and we can calculate</font><font color="#CCCCCC"> less</font><font color="#E5E5E5"> if you do</font>

320
00:14:57,379 --> 00:15:01,220
this for<font color="#CCCCCC"> all</font><font color="#E5E5E5"> bands ladies since we have</font>

321
00:14:59,299 --> 00:15:03,589
<font color="#CCCCCC">B bands</font><font color="#E5E5E5"> we just put</font><font color="#CCCCCC"> that to the</font><font color="#E5E5E5"> power</font><font color="#CCCCCC"> of</font>

322
00:15:01,220 --> 00:15:06,109
<font color="#E5E5E5">B</font><font color="#CCCCCC"> and if we</font><font color="#E5E5E5"> take the opposite event that</font>

323
00:15:03,589 --> 00:15:09,589
is the event<font color="#CCCCCC"> that use two snippets</font><font color="#E5E5E5"> or a</font>

324
00:15:06,109 --> 00:15:11,389
candidate pair you get<font color="#E5E5E5"> this so for those</font>

325
00:15:09,589 --> 00:15:12,859
of<font color="#E5E5E5"> you that don't often do math</font><font color="#CCCCCC"> or</font>

326
00:15:11,389 --> 00:15:14,779
<font color="#CCCCCC">haven't</font><font color="#E5E5E5"> done some for a while</font>

327
00:15:12,859 --> 00:15:17,269
this might<font color="#E5E5E5"> seem a bit abstract</font><font color="#CCCCCC"> but</font>

328
00:15:14,779 --> 00:15:20,989
basically this function regardless<font color="#CCCCCC"> of</font>

329
00:15:17,269 --> 00:15:24,529
<font color="#CCCCCC">our NB has lists shape so what we call</font>

330
00:15:20,989 --> 00:15:27,229
<font color="#E5E5E5">an S curve now if we choose</font><font color="#CCCCCC"> our 1b</font>

331
00:15:24,529 --> 00:15:29,089
appropriately<font color="#E5E5E5"> we get actually this kind</font>

332
00:15:27,229 --> 00:15:31,639
of curve which is<font color="#E5E5E5"> exactly what we did</font>

333
00:15:29,089 --> 00:15:33,979
want because<font color="#CCCCCC"> that this</font><font color="#E5E5E5"> curve means that</font>

334
00:15:31,639 --> 00:15:35,359
if we<font color="#E5E5E5"> have a candidate peril and with</font>

335
00:15:33,979 --> 00:15:37,339
high probability they will have a

336
00:15:35,359 --> 00:15:38,120
Jaccard similarity<font color="#E5E5E5"> over a certain</font>

337
00:15:37,339 --> 00:15:40,490
<font color="#CCCCCC">threshold</font>

338
00:15:38,120 --> 00:15:43,280
that you can choose beforehand<font color="#E5E5E5"> so here</font>

339
00:15:40,490 --> 00:15:46,430
this<font color="#CCCCCC"> is an</font><font color="#E5E5E5"> example with if I figure</font>

340
00:15:43,280 --> 00:15:50,569
threshold which might be about of 0.9<font color="#E5E5E5"> t5</font>

341
00:15:46,430 --> 00:15:52,729
<font color="#E5E5E5">for the similarity okay</font><font color="#CCCCCC"> so at the</font><font color="#E5E5E5"> end</font>

342
00:15:50,570 --> 00:15:54,260
<font color="#CCCCCC">everyday list basically allows us to</font>

343
00:15:52,730 --> 00:15:57,080
completely<font color="#E5E5E5"> simulate this similarity</font>

344
00:15:54,260 --> 00:15:59,450
graph<font color="#E5E5E5"> by simply creating signatures for</font>

345
00:15:57,080 --> 00:16:01,490
each of these snippets<font color="#CCCCCC"> lend selecting a</font>

346
00:15:59,450 --> 00:16:05,990
threshold and deducing<font color="#CCCCCC"> lis constants</font><font color="#E5E5E5"> R</font>

347
00:16:01,490 --> 00:16:09,440
and B and then on each sub<font color="#E5E5E5"> signal sub</font>

348
00:16:05,990 --> 00:16:11,660
signature of each file<font color="#E5E5E5"> hashing Li sub</font>

349
00:16:09,440 --> 00:16:14,630
sub signatures and put them<font color="#CCCCCC"> into buckets</font>

350
00:16:11,660 --> 00:16:16,579
<font color="#E5E5E5">and then we'll simply any</font><font color="#CCCCCC"> lipids</font><font color="#E5E5E5"> that</font>

351
00:16:14,630 --> 00:16:18,650
land and<font color="#E5E5E5"> at least one bucket in common</font>

352
00:16:16,580 --> 00:16:21,440
<font color="#CCCCCC">are going</font><font color="#E5E5E5"> to be our candidate pairs</font>

353
00:16:18,650 --> 00:16:25,160
which theoretically<font color="#CCCCCC"> are going to be over</font>

354
00:16:21,440 --> 00:16:27,920
<font color="#CCCCCC">a certain threshold</font><font color="#E5E5E5"> of similarity so the</font>

355
00:16:25,160 --> 00:16:29,180
next step is pretty straightforward<font color="#E5E5E5"> it's</font>

356
00:16:27,920 --> 00:16:31,969
the extraction of<font color="#E5E5E5"> the connected</font>

357
00:16:29,180 --> 00:16:34,400
components so basically looks something

358
00:16:31,970 --> 00:16:37,850
like this hopefully you<font color="#CCCCCC"> can see the</font>

359
00:16:34,400 --> 00:16:39,740
<font color="#CCCCCC">edges but yeah it doesn't yeah that's</font>

360
00:16:37,850 --> 00:16:41,030
not very<font color="#E5E5E5"> health really see the edges but</font>

361
00:16:39,740 --> 00:16:44,120
<font color="#E5E5E5">yeah I imagine</font><font color="#CCCCCC"> that these are</font><font color="#E5E5E5"> all</font>

362
00:16:41,030 --> 00:16:46,100
connected components<font color="#CCCCCC"> so I haven't</font><font color="#E5E5E5"> talked</font>

363
00:16:44,120 --> 00:16:48,680
too much about<font color="#CCCCCC"> let's step the community</font>

364
00:16:46,100 --> 00:16:52,010
detection<font color="#E5E5E5"> step so why do we do this um</font>

365
00:16:48,680 --> 00:16:54,109
<font color="#E5E5E5">so you could imagine that all snippets</font>

366
00:16:52,010 --> 00:16:56,240
<font color="#E5E5E5">in one connected components would be</font>

367
00:16:54,110 --> 00:16:58,490
clones<font color="#E5E5E5"> however in practice last this</font>

368
00:16:56,240 --> 00:17:00,760
isn't true because if you take<font color="#E5E5E5"> three</font>

369
00:16:58,490 --> 00:17:03,380
snippets for example a<font color="#E5E5E5"> B and C and</font>

370
00:17:00,760 --> 00:17:05,589
imagine that a and B hashed<font color="#E5E5E5"> to a same</font>

371
00:17:03,380 --> 00:17:09,020
<font color="#CCCCCC">bucket and B and C hash to a same bucket</font>

372
00:17:05,589 --> 00:17:11,569
<font color="#E5E5E5">let's take a fresh hold of</font><font color="#CCCCCC"> 0.8 then in</font>

373
00:17:09,020 --> 00:17:15,740
the<font color="#E5E5E5"> worst case even no loss a similarity</font>

374
00:17:11,569 --> 00:17:19,939
<font color="#CCCCCC">of 0.8 between a and b and b and c you'd</font>

375
00:17:15,740 --> 00:17:21,920
only<font color="#CCCCCC"> have maybe</font><font color="#E5E5E5"> 0.62 for similarity</font>

376
00:17:19,940 --> 00:17:23,990
between a<font color="#E5E5E5"> and C and if you increase the</font>

377
00:17:21,920 --> 00:17:26,150
amount<font color="#E5E5E5"> of hops you have to do</font><font color="#CCCCCC"> the</font>

378
00:17:23,990 --> 00:17:28,940
<font color="#E5E5E5">similarity is going to drop so this is</font>

379
00:17:26,150 --> 00:17:30,860
why we do the<font color="#CCCCCC"> community</font><font color="#E5E5E5"> detection and it</font>

380
00:17:28,940 --> 00:17:33,350
looks a bit something it looks something

381
00:17:30,860 --> 00:17:37,010
like something reckless<font color="#CCCCCC"> so you can see</font>

382
00:17:33,350 --> 00:17:40,899
it<font color="#E5E5E5"> you kind of put into</font><font color="#CCCCCC"> the same groups</font>

383
00:17:37,010 --> 00:17:43,250
and files<font color="#E5E5E5"> that are relatively</font><font color="#CCCCCC"> close</font>

384
00:17:40,900 --> 00:17:46,460
<font color="#E5E5E5">depending</font><font color="#CCCCCC"> on the</font><font color="#E5E5E5"> structure of the edges</font>

385
00:17:43,250 --> 00:17:47,960
so that<font color="#CCCCCC"> was it fully Germany algorithm</font>

386
00:17:46,460 --> 00:17:51,730
now I'm going to talk a<font color="#CCCCCC"> bit about the</font>

387
00:17:47,960 --> 00:17:53,860
<font color="#E5E5E5">results I got while applying it so I</font>

388
00:17:51,730 --> 00:17:56,350
<font color="#CCCCCC">the public get archived so public get</font>

389
00:17:53,860 --> 00:18:00,250
<font color="#CCCCCC">archived is largest data set of consoles</font>

390
00:17:56,350 --> 00:18:03,428
<font color="#E5E5E5">new world</font><font color="#CCCCCC"> it's maintained by a source</font>

391
00:18:00,250 --> 00:18:05,890
<font color="#E5E5E5">and is basically created from only</font>

392
00:18:03,429 --> 00:18:09,070
<font color="#E5E5E5">weapons and</font><font color="#CCCCCC"> github which have over 50</font>

393
00:18:05,890 --> 00:18:12,160
stars<font color="#CCCCCC"> it has</font><font color="#E5E5E5"> the neat property that we</font>

394
00:18:09,070 --> 00:18:14,918
didn't use<font color="#E5E5E5"> and my in</font><font color="#CCCCCC"> my case</font><font color="#E5E5E5"> that it</font>

395
00:18:12,160 --> 00:18:16,750
includes all<font color="#E5E5E5"> of</font><font color="#CCCCCC"> Lee commit history</font><font color="#E5E5E5"> but</font>

396
00:18:14,919 --> 00:18:18,640
as I said<font color="#CCCCCC"> I didn't use that and I only</font>

397
00:18:16,750 --> 00:18:22,150
took the head which<font color="#CCCCCC"> stole amounts</font><font color="#E5E5E5"> for</font>

398
00:18:18,640 --> 00:18:25,360
fifty four point<font color="#E5E5E5"> five million files</font><font color="#CCCCCC"> so I</font>

399
00:18:22,150 --> 00:18:27,750
was also<font color="#E5E5E5"> restricted with files from</font>

400
00:18:25,360 --> 00:18:29,949
<font color="#E5E5E5">which I could extract</font><font color="#CCCCCC"> a unified ast S</font>

401
00:18:27,750 --> 00:18:32,559
<font color="#E5E5E5">which meant that I could actually only</font>

402
00:18:29,950 --> 00:18:34,210
<font color="#E5E5E5">use at the time when I did list files</font>

403
00:18:32,559 --> 00:18:37,720
stemming from five different languages

404
00:18:34,210 --> 00:18:40,630
<font color="#E5E5E5">so Python Java JavaScript Ruby and go I</font>

405
00:18:37,720 --> 00:18:43,240
decided<font color="#CCCCCC"> to apply the pipeline on all</font>

406
00:18:40,630 --> 00:18:45,760
five<font color="#CCCCCC"> languages at once because I wanted</font>

407
00:18:43,240 --> 00:18:47,530
to see what early<font color="#E5E5E5"> algorithm would</font><font color="#CCCCCC"> be</font>

408
00:18:45,760 --> 00:18:50,160
able<font color="#E5E5E5"> to</font><font color="#CCCCCC"> detect the structural</font>

409
00:18:47,530 --> 00:18:54,100
differences<font color="#CCCCCC"> between</font><font color="#E5E5E5"> different languages</font>

410
00:18:50,160 --> 00:18:55,990
so when I applied this pipeline<font color="#E5E5E5"> this is</font>

411
00:18:54,100 --> 00:18:59,168
what I got<font color="#E5E5E5"> so for those of you that know</font>

412
00:18:55,990 --> 00:19:01,809
spoke you know<font color="#E5E5E5"> what I'm talking about</font>

413
00:18:59,169 --> 00:19:04,299
<font color="#CCCCCC">and</font><font color="#E5E5E5"> unfortunately with</font><font color="#CCCCCC"> lists kinds of</font>

414
00:19:01,809 --> 00:19:06,639
logs<font color="#E5E5E5"> usually they</font><font color="#CCCCCC"> hurriedly</font><font color="#E5E5E5"> hide a</font>

415
00:19:04,299 --> 00:19:11,918
certain amount<font color="#E5E5E5"> of problems so without</font>

416
00:19:06,640 --> 00:19:13,840
going too much<font color="#E5E5E5"> into detail I had faced a</font>

417
00:19:11,919 --> 00:19:16,900
certain<font color="#E5E5E5"> amount of challenges</font><font color="#CCCCCC"> or for</font>

418
00:19:13,840 --> 00:19:21,250
example corrupt files<font color="#E5E5E5"> pulsing errors</font>

419
00:19:16,900 --> 00:19:25,929
from Babel Fish GPUs not<font color="#E5E5E5"> responding for</font>

420
00:19:21,250 --> 00:19:28,120
no<font color="#E5E5E5"> reason at all during the</font><font color="#CCCCCC"> tf-idf step</font>

421
00:19:25,929 --> 00:19:31,240
<font color="#E5E5E5">at some point that was basically</font>

422
00:19:28,120 --> 00:19:33,549
<font color="#E5E5E5">infinite garbage collection so my tasks</font>

423
00:19:31,240 --> 00:19:36,730
never finished<font color="#E5E5E5"> and yeah I also</font>

424
00:19:33,549 --> 00:19:39,549
encountered<font color="#E5E5E5"> some github repositories</font>

425
00:19:36,730 --> 00:19:42,429
made by very clever engineers which were

426
00:19:39,549 --> 00:19:45,100
<font color="#CCCCCC">designed to not be cloneable</font><font color="#E5E5E5"> so we were</font>

427
00:19:42,429 --> 00:19:48,070
able<font color="#CCCCCC"> to clone them however</font><font color="#E5E5E5"> giving enough</font>

428
00:19:45,100 --> 00:19:51,370
structure<font color="#E5E5E5"> which basically imagine a</font>

429
00:19:48,070 --> 00:19:54,220
folder with<font color="#E5E5E5"> ten folders inside of lemon</font>

430
00:19:51,370 --> 00:19:56,070
and each subfolder or have ten more<font color="#E5E5E5"> etc</font>

431
00:19:54,220 --> 00:19:58,299
and said<font color="#CCCCCC"> evolved</font><font color="#E5E5E5"> so yeah an</font>

432
00:19:56,070 --> 00:20:01,540
exponentially<font color="#E5E5E5"> an exponentially</font>

433
00:19:58,299 --> 00:20:03,158
increasing<font color="#CCCCCC"> size yeah</font><font color="#E5E5E5"> so these were</font>

434
00:20:01,540 --> 00:20:04,820
<font color="#CCCCCC">actually pretty hard to process</font><font color="#E5E5E5"> and at</font>

435
00:20:03,159 --> 00:20:08,929
the end of the day I was only<font color="#E5E5E5"> able</font>

436
00:20:04,820 --> 00:20:10,610
to process 7.8 million files<font color="#E5E5E5"> so as you</font>

437
00:20:08,929 --> 00:20:12,799
can<font color="#CCCCCC"> see most</font><font color="#E5E5E5"> of them with JavaScript and</font>

438
00:20:10,610 --> 00:20:15,740
<font color="#E5E5E5">Java files and then I oh I still had</font>

439
00:20:12,799 --> 00:20:18,559
good amount of<font color="#E5E5E5"> other Python</font><font color="#CCCCCC"> Ruby and go</font>

440
00:20:15,740 --> 00:20:21,049
files<font color="#E5E5E5"> and out of all of these I was</font><font color="#CCCCCC"> able</font>

441
00:20:18,559 --> 00:20:25,158
to<font color="#E5E5E5"> extract about 6.2 million distinct</font>

442
00:20:21,049 --> 00:20:28,970
<font color="#E5E5E5">features so looking more and truly</font>

443
00:20:25,159 --> 00:20:30,620
features we extracted<font color="#E5E5E5"> so much of most of</font>

444
00:20:28,970 --> 00:20:32,840
them were<font color="#E5E5E5"> the syntactical features as</font>

445
00:20:30,620 --> 00:20:37,370
you<font color="#E5E5E5"> can see so identifies and literals</font>

446
00:20:32,840 --> 00:20:39,320
which<font color="#CCCCCC"> amounted for about 75% of lis of</font>

447
00:20:37,370 --> 00:20:42,258
<font color="#CCCCCC">already features</font><font color="#E5E5E5"> I extracted however</font>

448
00:20:39,320 --> 00:20:45,259
when looking at each file individually<font color="#CCCCCC"> I</font>

449
00:20:42,259 --> 00:20:47,360
saw that they each had about a thousand

450
00:20:45,259 --> 00:20:50,179
features and most of them were actually

451
00:20:47,360 --> 00:20:53,449
<font color="#E5E5E5">this time structural features so this</font>

452
00:20:50,179 --> 00:20:55,940
was an average<font color="#E5E5E5"> made on all of the only</font>

453
00:20:53,450 --> 00:20:58,610
features from files of<font color="#E5E5E5"> any given</font>

454
00:20:55,940 --> 00:21:02,179
languages but this was about<font color="#CCCCCC"> the same</font>

455
00:20:58,610 --> 00:21:07,100
when looking<font color="#CCCCCC"> at files of the specific</font>

456
00:21:02,179 --> 00:21:10,220
languages so next what I did was<font color="#CCCCCC"> that I</font>

457
00:21:07,100 --> 00:21:12,709
applied early rehashing with two

458
00:21:10,220 --> 00:21:15,289
different<font color="#E5E5E5"> thresholds early 80% which was</font>

459
00:21:12,710 --> 00:21:18,200
also used<font color="#CCCCCC"> in</font><font color="#E5E5E5"> the</font><font color="#CCCCCC"> Java as well as the</font><font color="#E5E5E5"> 95</font>

460
00:21:15,289 --> 00:21:21,080
<font color="#E5E5E5">percent threshold so as you as could be</font>

461
00:21:18,200 --> 00:21:23,120
expected<font color="#CCCCCC"> along</font><font color="#E5E5E5"> a much bigger amount of</font>

462
00:21:21,080 --> 00:21:25,039
<font color="#E5E5E5">connected components</font><font color="#CCCCCC"> for a</font><font color="#E5E5E5"> 95</font><font color="#CCCCCC"> percent</font>

463
00:21:23,120 --> 00:21:27,439
threshold<font color="#E5E5E5"> but let's actually just</font>

464
00:21:25,039 --> 00:21:29,450
connected components of only one file

465
00:21:27,440 --> 00:21:32,179
<font color="#E5E5E5">and if you look at the ones with have</font>

466
00:21:29,450 --> 00:21:34,759
which have more than<font color="#E5E5E5"> one file well</font>

467
00:21:32,179 --> 00:21:36,710
actually more 40 80<font color="#CCCCCC"> percent</font><font color="#E5E5E5"> thresholds</font>

468
00:21:34,759 --> 00:21:39,169
for about<font color="#E5E5E5"> 10 percent more and the</font>

469
00:21:36,710 --> 00:21:42,409
connected components are also a bit

470
00:21:39,169 --> 00:21:44,470
larger so<font color="#E5E5E5"> on</font><font color="#CCCCCC"> average they had about 1</font>

471
00:21:42,409 --> 00:21:48,320
more files per connected components

472
00:21:44,470 --> 00:21:50,059
<font color="#CCCCCC">looking more into</font><font color="#E5E5E5"> detail into the size</font>

473
00:21:48,320 --> 00:21:54,230
of<font color="#CCCCCC"> the connected component</font><font color="#E5E5E5"> size we can</font>

474
00:21:50,059 --> 00:21:56,418
see<font color="#E5E5E5"> from this log log graph the size</font>

475
00:21:54,230 --> 00:21:58,759
<font color="#CCCCCC">while most of the connected components</font>

476
00:21:56,419 --> 00:22:02,679
<font color="#CCCCCC">actually had a relatively small amount</font>

477
00:21:58,759 --> 00:22:06,529
<font color="#CCCCCC">of files</font><font color="#E5E5E5"> with that most for the 80%</font>

478
00:22:02,679 --> 00:22:08,210
<font color="#E5E5E5">threshold</font><font color="#CCCCCC"> a thousand</font><font color="#E5E5E5"> maybe a couple</font>

479
00:22:06,529 --> 00:22:11,840
thousand files<font color="#CCCCCC"> and</font><font color="#E5E5E5"> one connected</font>

480
00:22:08,210 --> 00:22:13,460
component<font color="#E5E5E5"> so one forget</font><font color="#CCCCCC"> I said earlier</font>

481
00:22:11,840 --> 00:22:16,070
was<font color="#CCCCCC"> that</font><font color="#E5E5E5"> I applied my pipeline on</font>

482
00:22:13,460 --> 00:22:18,410
languages of<font color="#E5E5E5"> on files of all languages</font>

483
00:22:16,070 --> 00:22:21,530
<font color="#CCCCCC">in order</font><font color="#E5E5E5"> to see if they were able</font>

484
00:22:18,410 --> 00:22:24,140
to find<font color="#E5E5E5"> if</font><font color="#CCCCCC"> we if they were able to be</font>

485
00:22:21,530 --> 00:22:26,899
<font color="#E5E5E5">separated using our algorithm that was</font>

486
00:22:24,140 --> 00:22:30,140
mostly<font color="#E5E5E5"> case apart from one community</font>

487
00:22:26,900 --> 00:22:33,530
<font color="#CCCCCC">which was actually pretty huge</font><font color="#E5E5E5"> which had</font>

488
00:22:30,140 --> 00:22:36,080
I<font color="#CCCCCC"> recall about 800,000 files</font><font color="#E5E5E5"> and which</font>

489
00:22:33,530 --> 00:22:37,670
had the files from all five languages<font color="#CCCCCC"> so</font>

490
00:22:36,080 --> 00:22:39,770
when I looked a bit<font color="#E5E5E5"> more into this I</font>

491
00:22:37,670 --> 00:22:42,350
<font color="#E5E5E5">found that it was because</font><font color="#CCCCCC"> all of</font><font color="#E5E5E5"> these</font>

492
00:22:39,770 --> 00:22:44,960
files were very short<font color="#E5E5E5"> and had</font><font color="#CCCCCC"> very</font>

493
00:22:42,350 --> 00:22:47,780
similar syntax<font color="#E5E5E5"> so what I did</font><font color="#CCCCCC"> was I</font>

494
00:22:44,960 --> 00:22:49,850
reapplied my pipeline<font color="#CCCCCC"> adding some bias</font>

495
00:22:47,780 --> 00:22:52,520
towards<font color="#CCCCCC"> these structural</font><font color="#E5E5E5"> features and</font>

496
00:22:49,850 --> 00:22:55,580
this large community<font color="#CCCCCC"> actually exploded</font>

497
00:22:52,520 --> 00:22:59,050
into monolingual<font color="#E5E5E5"> communities at the end</font>

498
00:22:55,580 --> 00:23:01,460
I mean connected components for them so

499
00:22:59,050 --> 00:23:03,850
looking at each<font color="#E5E5E5"> kind of connected</font>

500
00:23:01,460 --> 00:23:06,530
components<font color="#CCCCCC"> per language you can see that</font>

501
00:23:03,850 --> 00:23:09,080
<font color="#CCCCCC">pho connected components have over</font><font color="#E5E5E5"> one</font>

502
00:23:06,530 --> 00:23:11,510
fire we have a big<font color="#E5E5E5"> difference between</font>

503
00:23:09,080 --> 00:23:13,610
<font color="#E5E5E5">JavaScript and</font><font color="#CCCCCC"> NGO which have much more</font>

504
00:23:11,510 --> 00:23:15,440
files in these kinds of connected

505
00:23:13,610 --> 00:23:18,320
components<font color="#CCCCCC"> than for Java</font><font color="#E5E5E5"> will be in</font>

506
00:23:15,440 --> 00:23:21,020
Python<font color="#E5E5E5"> so</font><font color="#CCCCCC"> that can be</font><font color="#E5E5E5"> explained</font><font color="#CCCCCC"> with</font>

507
00:23:18,320 --> 00:23:23,000
kind of intuitive explanation for

508
00:23:21,020 --> 00:23:26,420
example Java<font color="#E5E5E5"> which is</font><font color="#CCCCCC"> a much more</font>

509
00:23:23,000 --> 00:23:29,450
<font color="#E5E5E5">object-oriented language would probably</font>

510
00:23:26,420 --> 00:23:32,240
have files which are<font color="#E5E5E5"> much more distinct</font>

511
00:23:29,450 --> 00:23:33,950
and invert<font color="#CCCCCC"> Li and go for example we use</font>

512
00:23:32,240 --> 00:23:36,590
a<font color="#E5E5E5"> practice which is</font><font color="#CCCCCC"> called</font><font color="#E5E5E5"> ven doing</font>

513
00:23:33,950 --> 00:23:39,230
<font color="#E5E5E5">it's kind of logical that would</font><font color="#CCCCCC"> be a lot</font>

514
00:23:36,590 --> 00:23:43,939
<font color="#CCCCCC">of</font><font color="#E5E5E5"> the same files that</font><font color="#CCCCCC"> would appear loss</font>

515
00:23:39,230 --> 00:23:45,890
<font color="#E5E5E5">these</font><font color="#CCCCCC"> results yeah so Len</font><font color="#E5E5E5"> I applied the</font>

516
00:23:43,940 --> 00:23:49,190
community detection with free walk<font color="#E5E5E5"> track</font>

517
00:23:45,890 --> 00:23:50,930
algorithm so as you<font color="#E5E5E5"> can</font><font color="#CCCCCC"> see if looking</font>

518
00:23:49,190 --> 00:23:54,200
purely at<font color="#CCCCCC"> Li connected components with</font>

519
00:23:50,930 --> 00:23:56,360
over one file the amount of connected

520
00:23:54,200 --> 00:23:58,070
components<font color="#CCCCCC"> was about the same however</font>

521
00:23:56,360 --> 00:23:59,899
when doing the<font color="#E5E5E5"> community detection we</font>

522
00:23:58,070 --> 00:24:02,270
can see that<font color="#CCCCCC"> la</font><font color="#E5E5E5"> was a huge increase</font>

523
00:23:59,900 --> 00:24:04,370
about<font color="#CCCCCC"> 50</font><font color="#E5E5E5"> percent our</font><font color="#CCCCCC"> V</font><font color="#E5E5E5"> number</font><font color="#CCCCCC"> of</font>

524
00:24:02,270 --> 00:24:06,800
communities detected when going for<font color="#CCCCCC"> me</font>

525
00:24:04,370 --> 00:24:10,489
<font color="#CCCCCC">ninety-five percent threshold</font><font color="#E5E5E5"> to</font><font color="#CCCCCC"> 8020</font>

526
00:24:06,800 --> 00:24:13,010
<font color="#CCCCCC">eighty percent okay</font><font color="#E5E5E5"> so</font><font color="#CCCCCC"> now I'm</font><font color="#E5E5E5"> going to</font>

527
00:24:10,490 --> 00:24:15,350
show you<font color="#E5E5E5"> a couple</font><font color="#CCCCCC"> examples but before</font>

528
00:24:13,010 --> 00:24:17,450
<font color="#E5E5E5">that you might notice that up until now</font>

529
00:24:15,350 --> 00:24:19,330
I haven't used any metrics which is kind

530
00:24:17,450 --> 00:24:21,380
of odd in a machine learning problem

531
00:24:19,330 --> 00:24:25,010
<font color="#CCCCCC">that's because this</font><font color="#E5E5E5"> is actually an</font>

532
00:24:21,380 --> 00:24:26,870
unsupervised problem and well as<font color="#E5E5E5"> you can</font>

533
00:24:25,010 --> 00:24:29,180
imagine<font color="#E5E5E5"> I wasn't going to</font><font color="#CCCCCC"> look at each</font>

534
00:24:26,870 --> 00:24:32,110
of these 7.8 million files to kind of

535
00:24:29,180 --> 00:24:34,539
see okay<font color="#CCCCCC"> this one is 80%</font><font color="#E5E5E5"> similar</font>

536
00:24:32,110 --> 00:24:37,209
is not like<font color="#E5E5E5"> pairwise that would have</font>

537
00:24:34,539 --> 00:24:38,769
been a bit hot so<font color="#CCCCCC"> I in order</font><font color="#E5E5E5"> to judge</font>

538
00:24:37,210 --> 00:24:41,049
whether this work was relevant<font color="#CCCCCC"> or not I</font>

539
00:24:38,769 --> 00:24:43,419
had to look at communities and connected

540
00:24:41,049 --> 00:24:46,480
components individually<font color="#E5E5E5"> which was how I</font>

541
00:24:43,419 --> 00:24:51,070
judged my work so as I was<font color="#CCCCCC"> saying before</font>

542
00:24:46,480 --> 00:24:55,360
<font color="#E5E5E5">were a lot of F connected components</font>

543
00:24:51,070 --> 00:24:57,039
which had a lot<font color="#CCCCCC"> of go files and one</font>

544
00:24:55,360 --> 00:24:58,658
thing that<font color="#E5E5E5"> was</font><font color="#CCCCCC"> interesting was</font><font color="#E5E5E5"> that a</font>

545
00:24:57,039 --> 00:25:00,760
certain<font color="#E5E5E5"> amount of disconnected</font>

546
00:24:58,659 --> 00:25:03,159
components<font color="#E5E5E5"> actually files which only had</font>

547
00:25:00,760 --> 00:25:05,679
one file name so<font color="#E5E5E5"> for instance this is a</font>

548
00:25:03,159 --> 00:25:08,289
<font color="#E5E5E5">connected component with only files</font>

549
00:25:05,679 --> 00:25:10,870
which are called<font color="#E5E5E5"> text parser</font><font color="#CCCCCC"> that go so</font>

550
00:25:08,289 --> 00:25:13,330
the white nodes are actually<font color="#CCCCCC"> not files</font>

551
00:25:10,870 --> 00:25:17,500
here they are representations of<font color="#CCCCCC"> lis</font>

552
00:25:13,330 --> 00:25:19,689
buckets<font color="#E5E5E5"> but however</font><font color="#CCCCCC"> so yeah as you can</font>

553
00:25:17,500 --> 00:25:21,820
see<font color="#CCCCCC"> Lau or maybe you can't see from afar</font>

554
00:25:19,690 --> 00:25:24,010
<font color="#E5E5E5">but I was actually</font><font color="#CCCCCC"> four communities</font>

555
00:25:21,820 --> 00:25:25,330
except that two of<font color="#E5E5E5"> them or miniscule</font>

556
00:25:24,010 --> 00:25:28,059
<font color="#E5E5E5">here and here</font>

557
00:25:25,330 --> 00:25:30,720
but as you can see<font color="#E5E5E5"> especially</font><font color="#CCCCCC"> for the</font>

558
00:25:28,059 --> 00:25:33,460
blue<font color="#E5E5E5"> community well that was detected</font>

559
00:25:30,720 --> 00:25:36,159
<font color="#E5E5E5">very strongly strongly links between</font>

560
00:25:33,460 --> 00:25:38,440
each file however<font color="#E5E5E5"> this doesn't mean that</font>

561
00:25:36,159 --> 00:25:40,659
<font color="#E5E5E5">each of our connected component were</font>

562
00:25:38,440 --> 00:25:43,299
only<font color="#E5E5E5"> formed the files with one file name</font>

563
00:25:40,659 --> 00:25:45,880
so looking at this larger connected

564
00:25:43,299 --> 00:25:47,559
<font color="#CCCCCC">component</font><font color="#E5E5E5"> which only has a ruby file you</font>

565
00:25:45,880 --> 00:25:50,139
<font color="#E5E5E5">can see that we detected three</font>

566
00:25:47,559 --> 00:25:52,480
communities and<font color="#E5E5E5"> looking more at lis file</font>

567
00:25:50,139 --> 00:25:55,240
names inside<font color="#CCCCCC"> less connected</font><font color="#E5E5E5"> components</font>

568
00:25:52,480 --> 00:25:57,970
you can<font color="#E5E5E5"> see that</font><font color="#CCCCCC"> all loli</font><font color="#E5E5E5"> do seem</font><font color="#CCCCCC"> to</font>

569
00:25:55,240 --> 00:26:00,070
cluster together<font color="#CCCCCC"> it doesn't actually</font>

570
00:25:57,970 --> 00:26:03,010
mean that<font color="#E5E5E5"> the community has formed of</font>

571
00:26:00,070 --> 00:26:07,570
only one kind well<font color="#E5E5E5"> I've only files</font>

572
00:26:03,010 --> 00:26:09,908
<font color="#E5E5E5">sharing the same file</font><font color="#CCCCCC"> name so this</font><font color="#E5E5E5"> is</font><font color="#CCCCCC"> a</font>

573
00:26:07,570 --> 00:26:12,309
<font color="#CCCCCC">final</font><font color="#E5E5E5"> example I'm going to talk about so</font>

574
00:26:09,909 --> 00:26:15,250
this was actually a pretty<font color="#E5E5E5"> interesting</font>

575
00:26:12,309 --> 00:26:16,750
<font color="#E5E5E5">thing</font><font color="#CCCCCC"> because it was one of</font><font color="#E5E5E5"> the larger</font>

576
00:26:15,250 --> 00:26:20,320
connected components I found

577
00:26:16,750 --> 00:26:22,750
and although the files unless<font color="#E5E5E5"> actually</font>

578
00:26:20,320 --> 00:26:25,178
stem from<font color="#E5E5E5"> free project only 25 files</font>

579
00:26:22,750 --> 00:26:31,120
came from<font color="#E5E5E5"> two projects and all of</font><font color="#CCCCCC"> the</font>

580
00:26:25,179 --> 00:26:34,620
<font color="#CCCCCC">arrows</font><font color="#E5E5E5"> came from 4700 7500 files so as</font>

581
00:26:31,120 --> 00:26:37,629
you can<font color="#CCCCCC"> see that's a</font><font color="#E5E5E5"> lot of duplication</font>

582
00:26:34,620 --> 00:26:40,299
<font color="#CCCCCC">for only</font><font color="#E5E5E5"> one project and when</font><font color="#CCCCCC"> looking at</font>

583
00:26:37,630 --> 00:26:42,639
the github repository of<font color="#CCCCCC"> the</font><font color="#E5E5E5"> Microsoft</font>

584
00:26:40,299 --> 00:26:45,190
Azure as decay<font color="#E5E5E5"> you can actually see that</font>

585
00:26:42,639 --> 00:26:45,760
lossless very repetitive<font color="#CCCCCC"> kind of</font>

586
00:26:45,190 --> 00:26:48,880
structure

587
00:26:45,760 --> 00:26:50,560
with a lot<font color="#E5E5E5"> of files incoming and well as</font>

588
00:26:48,880 --> 00:26:54,340
you<font color="#E5E5E5"> can see we were able</font><font color="#CCCCCC"> to detect</font>

589
00:26:50,560 --> 00:26:56,379
lacked<font color="#E5E5E5"> and so I could I got this</font>

590
00:26:54,340 --> 00:27:01,570
<font color="#CCCCCC">representation when I created my graph</font>

591
00:26:56,380 --> 00:27:03,850
on<font color="#CCCCCC"> goofy so that was it for me I hope</font>

592
00:27:01,570 --> 00:27:05,260
you<font color="#E5E5E5"> liked this talk I liked</font><font color="#CCCCCC"> working on</font>

593
00:27:03,850 --> 00:27:08,080
this<font color="#E5E5E5"> and I found that</font><font color="#CCCCCC"> it was</font><font color="#E5E5E5"> also very</font>

594
00:27:05,260 --> 00:27:10,629
interesting<font color="#CCCCCC"> if you want to</font><font color="#E5E5E5"> look more</font>

595
00:27:08,080 --> 00:27:14,710
<font color="#CCCCCC">into the results you</font><font color="#E5E5E5"> can go on the blog</font>

596
00:27:10,630 --> 00:27:18,550
on<font color="#E5E5E5"> the sauce blog</font><font color="#CCCCCC"> I created a blog post</font>

597
00:27:14,710 --> 00:27:20,410
which goes much more<font color="#E5E5E5"> in-depth into into</font>

598
00:27:18,550 --> 00:27:22,570
<font color="#CCCCCC">different aspects of</font><font color="#E5E5E5"> lis results I found</font>

599
00:27:20,410 --> 00:27:24,310
on applying<font color="#CCCCCC"> less</font><font color="#E5E5E5"> if you want to check</font>

600
00:27:22,570 --> 00:27:27,250
out the code and<font color="#E5E5E5"> possibly use it you can</font>

601
00:27:24,310 --> 00:27:29,470
look<font color="#E5E5E5"> at</font><font color="#CCCCCC"> lease or the gemiini project</font><font color="#E5E5E5"> and</font>

602
00:27:27,250 --> 00:27:31,240
if you are interested<font color="#CCCCCC"> in</font><font color="#E5E5E5"> the PG a</font>

603
00:27:29,470 --> 00:27:34,240
dataset well you can also download it

604
00:27:31,240 --> 00:27:36,640
for free<font color="#E5E5E5"> although yeah it's a bit big so</font>

605
00:27:34,240 --> 00:28:06,790
we might<font color="#CCCCCC"> want to save about three</font>

606
00:27:36,640 --> 00:28:09,670
terabytes of<font color="#E5E5E5"> a storage</font><font color="#CCCCCC"> thanks yeah so</font>

607
00:28:06,790 --> 00:28:12,220
the question<font color="#CCCCCC"> was whether this technique</font>

608
00:28:09,670 --> 00:28:13,780
could be<font color="#E5E5E5"> used for</font><font color="#CCCCCC"> we factor in cloud or</font>

609
00:28:12,220 --> 00:28:19,600
if it was much more aimed towards

610
00:28:13,780 --> 00:28:21,460
duplication so I think<font color="#E5E5E5"> I'm not</font><font color="#CCCCCC"> sure what</font>

611
00:28:19,600 --> 00:28:24,580
you mean<font color="#CCCCCC"> by</font><font color="#E5E5E5"> that question I think</font><font color="#CCCCCC"> it</font>

612
00:28:21,460 --> 00:28:27,180
would be able<font color="#CCCCCC"> to</font><font color="#E5E5E5"> find codes which are</font>

613
00:28:24,580 --> 00:28:30,129
<font color="#CCCCCC">similar if you only</font><font color="#E5E5E5"> focus on structure</font>

614
00:28:27,180 --> 00:28:33,520
<font color="#E5E5E5">features so in that sense if you applied</font>

615
00:28:30,130 --> 00:28:35,020
it<font color="#E5E5E5"> to let's say one</font><font color="#CCCCCC"> project in order</font><font color="#E5E5E5"> to</font>

616
00:28:33,520 --> 00:28:37,480
find all of these<font color="#CCCCCC"> structurally similar</font>

617
00:28:35,020 --> 00:28:40,000
files<font color="#E5E5E5"> it might be applied</font><font color="#CCCCCC"> to a factoring</font>

618
00:28:37,480 --> 00:28:43,570
I don't really think that<font color="#E5E5E5"> it will</font>

619
00:28:40,000 --> 00:28:47,950
necessarily be impacted by<font color="#E5E5E5"> my</font><font color="#CCCCCC"> D</font>

620
00:28:43,570 --> 00:28:49,960
roughness of<font color="#E5E5E5"> the estimate because if you</font>

621
00:28:47,950 --> 00:28:52,750
give enough weight<font color="#CCCCCC"> to the 2d features</font>

622
00:28:49,960 --> 00:28:55,450
<font color="#CCCCCC">and if you apply tf-idf with a</font>

623
00:28:52,750 --> 00:28:57,580
relatively low threshold<font color="#CCCCCC"> and</font><font color="#E5E5E5"> you can</font>

624
00:28:55,450 --> 00:28:58,880
keep enough features<font color="#E5E5E5"> for I think the</font>

625
00:28:57,580 --> 00:29:02,419
similarity to be one of

626
00:28:58,880 --> 00:29:04,660
in your case<font color="#E5E5E5"> so probably be interesting</font>

627
00:29:02,420 --> 00:29:04,660
to see

628
00:29:12,630 --> 00:29:20,619
[Applause]

