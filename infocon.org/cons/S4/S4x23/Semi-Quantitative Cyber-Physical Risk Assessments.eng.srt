1
00:00:00,179 --> 00:00:03,179
foreign

2
00:00:05,100 --> 00:00:07,680
I'd like to talk the next 25 minutes

3
00:00:07,680 --> 00:00:10,860
about cyber physical risk I actually

4
00:00:10,860 --> 00:00:13,259
going to raise the bar a little bit by

5
00:00:13,259 --> 00:00:15,360
talking about semi-quantitative

6
00:00:15,360 --> 00:00:17,580
physical risk

7
00:00:17,580 --> 00:00:20,300
that is the area between on the one and

8
00:00:20,300 --> 00:00:25,680
the quantitative risk Heaven and the

9
00:00:25,680 --> 00:00:27,019
qualitative

10
00:00:27,019 --> 00:00:29,880
uh risks stuff

11
00:00:29,880 --> 00:00:32,058
it's a conflict so on just in between

12
00:00:32,058 --> 00:00:35,579
some people think the glass is half full

13
00:00:35,579 --> 00:00:38,480
honestly the glass is half empty but

14
00:00:38,480 --> 00:00:42,120
that will be my my topic let's go to the

15
00:00:42,120 --> 00:00:43,500
first slide

16
00:00:43,500 --> 00:00:46,440
first slide shows in the middle uh a

17
00:00:46,440 --> 00:00:49,620
reactive vessel and for reactors

18
00:00:49,620 --> 00:00:52,920
one of the most critical assets is

19
00:00:52,920 --> 00:00:55,020
thermal runaway reaction

20
00:00:55,020 --> 00:00:57,960
if that happens it can explode the

21
00:00:57,960 --> 00:01:01,100
reactor can rupture the reaction

22
00:01:01,100 --> 00:01:04,500
toxic papers can escape

23
00:01:04,500 --> 00:01:06,540
well what is the first message

24
00:01:06,540 --> 00:01:08,520
in this slide

25
00:01:08,520 --> 00:01:11,400
first of all you see this reactor vessel

26
00:01:11,400 --> 00:01:14,400
you have a potential explosion which

27
00:01:14,400 --> 00:01:17,360
might result into gas fertilities

28
00:01:17,360 --> 00:01:20,520
single people multiple people if you

29
00:01:20,520 --> 00:01:23,700
look at accidents like Bhopal also

30
00:01:23,700 --> 00:01:26,280
terminal radiation thermal runaway

31
00:01:26,280 --> 00:01:29,700
reaction 25 000 people died in that

32
00:01:29,700 --> 00:01:32,700
action and after years even a quarter of

33
00:01:32,700 --> 00:01:34,979
a million people died so it's a very

34
00:01:34,979 --> 00:01:37,380
serious accidents

35
00:01:37,380 --> 00:01:40,439
that we have to properly Safeguard but

36
00:01:40,439 --> 00:01:42,960
also with security prevent them from

37
00:01:42,960 --> 00:01:45,900
happening so I show on the slide

38
00:01:45,900 --> 00:01:50,040
two similar causes the top one shows a

39
00:01:50,040 --> 00:01:52,680
pump failure a random pump failure due

40
00:01:52,680 --> 00:01:56,100
due to wear and tear or pumps and the

41
00:01:56,100 --> 00:01:57,119
other one

42
00:01:57,119 --> 00:02:00,540
is a Cyber attack that shuts down a bump

43
00:02:00,540 --> 00:02:03,479
will lose the cooling system both will

44
00:02:03,479 --> 00:02:06,000
result in overheating of the Reactor

45
00:02:06,000 --> 00:02:09,360
with a potential explosion the message

46
00:02:09,360 --> 00:02:12,120
here is two different courses

47
00:02:12,120 --> 00:02:15,300
still the same explosion still the same

48
00:02:15,300 --> 00:02:18,599
impact and risk criteria are connected

49
00:02:18,599 --> 00:02:21,720
to the impact they're not relevant on

50
00:02:21,720 --> 00:02:23,700
the course so what I'm actually say in

51
00:02:23,700 --> 00:02:26,459
this slide is that process safety risk

52
00:02:26,459 --> 00:02:30,180
criteria also account for cyber physical

53
00:02:30,180 --> 00:02:33,300
risk criteria because the cost is the

54
00:02:33,300 --> 00:02:36,620
same the result is the same

55
00:02:37,680 --> 00:02:41,580
let me move forward this slide shows who

56
00:02:41,580 --> 00:02:44,400
sets these risk tolerance limits for

57
00:02:44,400 --> 00:02:47,220
this type of accidents when you try to

58
00:02:47,220 --> 00:02:50,220
build a new chemical plant somewhere you

59
00:02:50,220 --> 00:02:51,959
will get

60
00:02:51,959 --> 00:02:54,420
you say that into contact with the land

61
00:02:54,420 --> 00:02:57,480
use Act of a particular country and that

62
00:02:57,480 --> 00:03:00,019
country specifies

63
00:03:00,019 --> 00:03:02,700
risk tolerance criteria for individual

64
00:03:02,700 --> 00:03:05,819
risk which is the risk typically within

65
00:03:05,819 --> 00:03:08,040
defense of the plant

66
00:03:08,040 --> 00:03:12,060
the the actual if maximum event rate

67
00:03:12,060 --> 00:03:15,060
allowed there for the fatality in my

68
00:03:15,060 --> 00:03:17,760
picture here shows one e minus five so

69
00:03:17,760 --> 00:03:21,060
once every 100 000 year an incident like

70
00:03:21,060 --> 00:03:23,580
that may happen but this is depending on

71
00:03:23,580 --> 00:03:26,340
the country it can be once every 10 000

72
00:03:26,340 --> 00:03:28,140
years can even be once every Thousand

73
00:03:28,140 --> 00:03:30,680
Years depending on which country you

74
00:03:30,680 --> 00:03:34,019
this plant a situation you have also

75
00:03:34,019 --> 00:03:36,659
something called aggregated risk that is

76
00:03:36,659 --> 00:03:38,519
the risk

77
00:03:38,519 --> 00:03:40,920
for the office directly outside the

78
00:03:40,920 --> 00:03:43,920
fence of the plant and the ideas that

79
00:03:43,920 --> 00:03:46,860
when you go in the plant you could do a

80
00:03:46,860 --> 00:03:49,080
safety induction so you learn how to

81
00:03:49,080 --> 00:03:50,280
react

82
00:03:50,280 --> 00:03:53,640
on on incidents that go wrong so you can

83
00:03:53,640 --> 00:03:56,459
have a little bit uh

84
00:03:56,459 --> 00:03:59,280
I would say that higher risk tolerance

85
00:03:59,280 --> 00:04:02,459
level while if you go into the office

86
00:04:02,459 --> 00:04:05,040
you just walk in you do not do a safety

87
00:04:05,040 --> 00:04:07,440
induction uh so you need to be better

88
00:04:07,440 --> 00:04:10,159
protected and you have a more restricted

89
00:04:10,159 --> 00:04:12,299
restorative and the other one is

90
00:04:12,299 --> 00:04:15,540
societal risk societal risk is covering

91
00:04:15,540 --> 00:04:19,019
the public area so it might be a toxic

92
00:04:19,019 --> 00:04:22,260
Faber going into a village going in over

93
00:04:22,260 --> 00:04:24,960
churches over schools over hospitals

94
00:04:24,960 --> 00:04:28,440
where people are together so those are

95
00:04:28,440 --> 00:04:30,840
much more restrictive as shown a slide a

96
00:04:30,840 --> 00:04:32,540
single value that's not correct

97
00:04:32,540 --> 00:04:35,880
basically these risks are in this area

98
00:04:35,880 --> 00:04:38,040
defined by what we call frequency number

99
00:04:38,040 --> 00:04:40,639
diagrams so they give a

100
00:04:40,639 --> 00:04:43,699
a decreasing

101
00:04:43,699 --> 00:04:46,440
risk tolerance

102
00:04:46,440 --> 00:04:48,479
depending on the number of potential

103
00:04:48,479 --> 00:04:51,479
fatalities that is why if you have a

104
00:04:51,479 --> 00:04:53,600
nuclear plant you have a very

105
00:04:53,600 --> 00:04:56,360
restrictive

106
00:04:56,360 --> 00:04:58,560
restorance regime

107
00:04:58,560 --> 00:05:00,360
so that's governments are setting those

108
00:05:00,360 --> 00:05:02,340
those limits in these are in the mirrors

109
00:05:02,340 --> 00:05:04,560
numerical limits and not only setting

110
00:05:04,560 --> 00:05:08,280
these limits for safety incidents but

111
00:05:08,280 --> 00:05:10,860
also for environmental incidents

112
00:05:10,860 --> 00:05:11,759
foreign

113
00:05:11,759 --> 00:05:13,979
this is the few and the same risk

114
00:05:13,979 --> 00:05:16,020
criteria but then from the corporate

115
00:05:16,020 --> 00:05:19,320
perspective in corporate perspective you

116
00:05:19,320 --> 00:05:22,440
also use frequency number diagrams you

117
00:05:22,440 --> 00:05:25,320
determine the maximum restorance limit

118
00:05:25,320 --> 00:05:28,020
that's the the top bar here the purple

119
00:05:28,020 --> 00:05:30,780
bar anything above that is an acceptable

120
00:05:30,780 --> 00:05:33,780
risk anything below that is tolerable

121
00:05:33,780 --> 00:05:36,539
risk but when you

122
00:05:36,539 --> 00:05:38,820
are part of a corporate you also

123
00:05:38,820 --> 00:05:41,940
typically specify a Minimus failure a

124
00:05:41,940 --> 00:05:44,639
low value below which you don't have to

125
00:05:44,639 --> 00:05:47,639
act anymore if you press the risk down

126
00:05:47,639 --> 00:05:49,320
to that level

127
00:05:49,320 --> 00:05:52,080
and that's the acceptable risk level and

128
00:05:52,080 --> 00:05:54,539
the the regime in between

129
00:05:54,539 --> 00:05:56,880
you try to reduce the risk as much as

130
00:05:56,880 --> 00:06:00,240
possible that we what we call a LARP as

131
00:06:00,240 --> 00:06:02,699
low as reasonable practical

132
00:06:02,699 --> 00:06:05,100
or in some countries we have not alarmed

133
00:06:05,100 --> 00:06:07,080
we have a Lara as well as reasonable

134
00:06:07,080 --> 00:06:09,419
achievable in those countries you don't

135
00:06:09,419 --> 00:06:12,000
have that slower level there's lower the

136
00:06:12,000 --> 00:06:14,100
Minimus level the US isn't a large

137
00:06:14,100 --> 00:06:16,560
country so you have this

138
00:06:16,560 --> 00:06:19,940
typically this lower level

139
00:06:20,520 --> 00:06:22,500
this is probably the more familiar

140
00:06:22,500 --> 00:06:24,960
picture for most of you this is the

141
00:06:24,960 --> 00:06:27,560
picture you get if you ask a risk Matrix

142
00:06:27,560 --> 00:06:31,319
from a chemical plant or a Refinery or

143
00:06:31,319 --> 00:06:32,880
an offshore platform you get something

144
00:06:32,880 --> 00:06:34,919
like this

145
00:06:34,919 --> 00:06:38,580
it shows on one end shows you some risk

146
00:06:38,580 --> 00:06:39,780
categories

147
00:06:39,780 --> 00:06:42,060
like a show here individual risk

148
00:06:42,060 --> 00:06:45,720
societal risk environmental risk

149
00:06:45,720 --> 00:06:48,479
a financial risk of force not to forget

150
00:06:48,479 --> 00:06:52,560
no countries do not specify anything on

151
00:06:52,560 --> 00:06:55,800
Financial Risk restaurants levels for

152
00:06:55,800 --> 00:06:59,100
Financial Risk are company decisions

153
00:06:59,100 --> 00:07:01,020
and on the right side

154
00:07:01,020 --> 00:07:03,020
you see if it's yes or no acceptable

155
00:07:03,020 --> 00:07:05,280
that is the

156
00:07:05,280 --> 00:07:09,539
the big picture of these slides

157
00:07:09,539 --> 00:07:11,880
one thing is still missing for me is

158
00:07:11,880 --> 00:07:14,940
semiconductive rational analyst and that

159
00:07:14,940 --> 00:07:18,840
is I need some numbers to to

160
00:07:18,840 --> 00:07:24,000
work with some numbers that determine my

161
00:07:24,000 --> 00:07:26,699
the limit of my risk reduction this is

162
00:07:26,699 --> 00:07:28,440
why we call the target mitigated event

163
00:07:28,440 --> 00:07:30,360
likelihood that's coming from the

164
00:07:30,360 --> 00:07:32,099
process safety people the process safety

165
00:07:32,099 --> 00:07:34,560
people use these values in what they

166
00:07:34,560 --> 00:07:36,479
call low lopa layers of protection

167
00:07:36,479 --> 00:07:38,580
analysis I'll explain that a little

168
00:07:38,580 --> 00:07:39,360
later

169
00:07:39,360 --> 00:07:43,319
uh these numbers are basically the risk

170
00:07:43,319 --> 00:07:45,599
tolerance for a particular impact level

171
00:07:45,599 --> 00:07:48,120
so when you have a particular loss

172
00:07:48,120 --> 00:07:49,919
scenario resulting in a specific

173
00:07:49,919 --> 00:07:52,860
consequence causing something a fatality

174
00:07:52,860 --> 00:07:55,440
or a particular damage of a specific

175
00:07:55,440 --> 00:07:59,520
size or environmental damage then

176
00:07:59,520 --> 00:08:01,800
they set a particular event frequency

177
00:08:01,800 --> 00:08:05,940
for that type of loss in in the top left

178
00:08:05,940 --> 00:08:10,020
side fatality they say once every 100

179
00:08:10,020 --> 00:08:11,039
000 years

180
00:08:11,039 --> 00:08:14,340
but here in America I've seen it's more

181
00:08:14,340 --> 00:08:16,680
or less once every 10 000 years I've

182
00:08:16,680 --> 00:08:18,539
seen in the Middle East places where

183
00:08:18,539 --> 00:08:21,599
it's every once in a thousand years so

184
00:08:21,599 --> 00:08:25,759
it differs very much country by country

185
00:08:26,220 --> 00:08:29,940
let's go over a practical case and then

186
00:08:29,940 --> 00:08:31,620
I explain

187
00:08:31,620 --> 00:08:34,799
first a little bit how this reactor

188
00:08:34,799 --> 00:08:37,320
works then how process safety looks at

189
00:08:37,320 --> 00:08:39,179
it then how

190
00:08:39,179 --> 00:08:42,299
cyber physical risk looks at it and then

191
00:08:42,299 --> 00:08:43,520
I can't explain

192
00:08:43,520 --> 00:08:46,560
a technique called ropa rings of

193
00:08:46,560 --> 00:08:49,140
protection analysis how to estimate some

194
00:08:49,140 --> 00:08:51,120
of this risk

195
00:08:51,120 --> 00:08:55,560
so this is my little uh reactor

196
00:08:55,560 --> 00:08:59,580
I enter in the top some chemicals

197
00:08:59,580 --> 00:09:02,940
feed a and a feed B whatever it is I

198
00:09:02,940 --> 00:09:04,920
start stealing it a little bit so these

199
00:09:04,920 --> 00:09:07,560
atoms already start mingling a little

200
00:09:07,560 --> 00:09:10,440
bit and I start heating the reactor

201
00:09:10,440 --> 00:09:12,839
vessel to the reaction temperature so

202
00:09:12,839 --> 00:09:15,779
that the bonding between these atoms is

203
00:09:15,779 --> 00:09:17,880
the most ideal situation for that

204
00:09:17,880 --> 00:09:20,279
particular reaction

205
00:09:20,279 --> 00:09:23,519
that heating is shown here so I insert

206
00:09:23,519 --> 00:09:27,060
some steam in the jacket to eat that

207
00:09:27,060 --> 00:09:29,640
when I've done that I can also stimulate

208
00:09:29,640 --> 00:09:32,880
a reaction a bit more by entering

209
00:09:32,880 --> 00:09:36,060
Catalyst into the

210
00:09:36,060 --> 00:09:37,560
The Vessel

211
00:09:37,560 --> 00:09:40,100
and then it really starts

212
00:09:40,100 --> 00:09:43,860
boiling and then boiling and creating

213
00:09:43,860 --> 00:09:46,320
all kind of reactions

214
00:09:46,320 --> 00:09:48,740
the problem here is that when

215
00:09:48,740 --> 00:09:52,200
atoms bond when atoms create new

216
00:09:52,200 --> 00:09:55,140
configurations they release they create

217
00:09:55,140 --> 00:09:56,040
Heat

218
00:09:56,040 --> 00:09:59,040
and when that creates heat the reaction

219
00:09:59,040 --> 00:10:02,100
rate increases and when the reaction

220
00:10:02,100 --> 00:10:04,200
rate increases you create more heat so

221
00:10:04,200 --> 00:10:06,740
it becomes kind of a circling

222
00:10:06,740 --> 00:10:11,580
process that you have to to manage and

223
00:10:11,580 --> 00:10:14,040
to manage it we need to cool it so we

224
00:10:14,040 --> 00:10:16,680
need to try to keep it stable on one

225
00:10:16,680 --> 00:10:19,140
temperature on one temperature I showed

226
00:10:19,140 --> 00:10:21,000
that a little bit in the right top of

227
00:10:21,000 --> 00:10:22,740
this slide

228
00:10:22,740 --> 00:10:25,260
where you have a ball on this they speak

229
00:10:25,260 --> 00:10:27,240
and through Heating and Cooling we're

230
00:10:27,240 --> 00:10:29,760
trying to keep the the ball on the top

231
00:10:29,760 --> 00:10:31,200
if we

232
00:10:31,200 --> 00:10:34,080
cool too much then our reaction will

233
00:10:34,080 --> 00:10:37,500
fail if we heat too much we create a

234
00:10:37,500 --> 00:10:40,800
stomach runaway situation where things

235
00:10:40,800 --> 00:10:43,740
get out of hand and when you have a high

236
00:10:43,740 --> 00:10:45,839
temperature you automatically have a

237
00:10:45,839 --> 00:10:47,640
high pressure and we have a high

238
00:10:47,640 --> 00:10:50,519
pressure yeah a reactive vessel might

239
00:10:50,519 --> 00:10:54,180
rupture and it's even so I showed up a

240
00:10:54,180 --> 00:10:56,100
little bit in the right

241
00:10:56,100 --> 00:10:57,720
bottom

242
00:10:57,720 --> 00:11:00,120
screen

243
00:11:00,120 --> 00:11:03,180
is that chemicals with a high reaction

244
00:11:03,180 --> 00:11:05,420
temperature also have a very high speed

245
00:11:05,420 --> 00:11:09,060
of increasing this reaction rate and

246
00:11:09,060 --> 00:11:11,100
there are chemicals that actually triple

247
00:11:11,100 --> 00:11:13,399
their temperature in matter of minutes

248
00:11:13,399 --> 00:11:17,279
so from fewer and degrees to four or 500

249
00:11:17,279 --> 00:11:19,800
degrees is very much possible for some

250
00:11:19,800 --> 00:11:22,320
chemicals

251
00:11:22,320 --> 00:11:25,019
so it is a dangerous situation we need

252
00:11:25,019 --> 00:11:27,360
to create safeguards for we need to

253
00:11:27,360 --> 00:11:30,000
create cyber security for

254
00:11:30,000 --> 00:11:31,980
let's look at first at the process

255
00:11:31,980 --> 00:11:34,680
safety site so what can I do

256
00:11:34,680 --> 00:11:36,600
I have an operator so operator

257
00:11:36,600 --> 00:11:38,279
intervention is always a good thing

258
00:11:38,279 --> 00:11:42,120
operators get an alarm they try to

259
00:11:42,120 --> 00:11:44,700
increase the cooling they also have

260
00:11:44,700 --> 00:11:45,720
something

261
00:11:45,720 --> 00:11:48,019
some possibilities to manually shut down

262
00:11:48,019 --> 00:11:51,660
the the reaction that's what we call the

263
00:11:51,660 --> 00:11:53,880
inhibitor it's kind of injecting a

264
00:11:53,880 --> 00:11:55,920
specific fluid in the chemical that

265
00:11:55,920 --> 00:11:59,579
kills this reaction process

266
00:11:59,579 --> 00:12:01,860
that is shown here in an automatic

267
00:12:01,860 --> 00:12:03,420
version where we have an emergency

268
00:12:03,420 --> 00:12:06,600
shutdown system trickling that so if a

269
00:12:06,600 --> 00:12:08,700
particular pressure gets too high

270
00:12:08,700 --> 00:12:11,220
particular temperature gets too high at

271
00:12:11,220 --> 00:12:14,279
that point in time the emergency down

272
00:12:14,279 --> 00:12:17,899
system will open this

273
00:12:17,899 --> 00:12:20,060
inhibitor

274
00:12:20,060 --> 00:12:22,200
vessel there will be some pressure

275
00:12:22,200 --> 00:12:25,440
behind it of course to kill the reaction

276
00:12:25,440 --> 00:12:27,959
there's a third one I have as a

277
00:12:27,959 --> 00:12:29,880
possibility in this case is a rupture

278
00:12:29,880 --> 00:12:32,040
disc or it could have a pressure relief

279
00:12:32,040 --> 00:12:32,880
off

280
00:12:32,880 --> 00:12:35,339
doing that there's a mechanical device

281
00:12:35,339 --> 00:12:38,100
so it breaks open at a specific pressure

282
00:12:38,100 --> 00:12:40,440
and when it breaks open it doesn't close

283
00:12:40,440 --> 00:12:42,420
anymore pressure relief valve will

284
00:12:42,420 --> 00:12:46,019
probably close again but uh rupture this

285
00:12:46,019 --> 00:12:48,480
doesn't close it's a mechanical device I

286
00:12:48,480 --> 00:12:50,820
cannot Cyber attack it so let's see if

287
00:12:50,820 --> 00:12:52,019
we are

288
00:12:52,019 --> 00:12:55,079
secure because we have this I don't

289
00:12:55,079 --> 00:12:58,079
think so but I will try to show you

290
00:12:58,079 --> 00:13:00,779
this is showing the picture of low pile

291
00:13:00,779 --> 00:13:02,820
as a protection analysis

292
00:13:02,820 --> 00:13:06,600
in Lopez more or less developed about 20

293
00:13:06,600 --> 00:13:08,880
years ago a little bit 25 years ago

294
00:13:08,880 --> 00:13:11,459
maybe to determine how many safeguards

295
00:13:11,459 --> 00:13:15,300
we need to protect the system

296
00:13:15,300 --> 00:13:18,420
I have here and in the first protection

297
00:13:18,420 --> 00:13:21,480
layer by this operator intervention that

298
00:13:21,480 --> 00:13:22,860
would actually

299
00:13:22,860 --> 00:13:26,579
if that would be activated it would

300
00:13:26,579 --> 00:13:27,959
solve the problem

301
00:13:27,959 --> 00:13:29,880
the second one

302
00:13:29,880 --> 00:13:34,079
in the protection layer is the

303
00:13:34,079 --> 00:13:37,079
image shutdown system

304
00:13:37,079 --> 00:13:39,360
if that would react it would also solve

305
00:13:39,360 --> 00:13:40,740
the problem and the third one is the

306
00:13:40,740 --> 00:13:43,200
rupture disk would also solve the

307
00:13:43,200 --> 00:13:45,480
problem so all of three of them solve

308
00:13:45,480 --> 00:13:48,240
the problem though we need multiple why

309
00:13:48,240 --> 00:13:50,579
do we need multiple well because we have

310
00:13:50,579 --> 00:13:52,800
something called the probability of

311
00:13:52,800 --> 00:13:55,139
failure on demand so the probability

312
00:13:55,139 --> 00:13:57,120
that it actually doesn't work when you

313
00:13:57,120 --> 00:13:58,079
need it

314
00:13:58,079 --> 00:14:00,180
so the probability that the operator

315
00:14:00,180 --> 00:14:03,180
doesn't intervene when he needs to be

316
00:14:03,180 --> 00:14:05,459
done well this sat here once every 10

317
00:14:05,459 --> 00:14:10,100
years so 0.1 number for the cell 2

318
00:14:10,100 --> 00:14:14,040
emerge down system that risk reduction

319
00:14:14,040 --> 00:14:17,339
factor is a factor around it so one one

320
00:14:17,339 --> 00:14:19,440
hundredths so once every 100 Year

321
00:14:19,440 --> 00:14:22,380
actually that measure down function will

322
00:14:22,380 --> 00:14:24,899
not work for the rupture disk it's

323
00:14:24,899 --> 00:14:29,060
another once and every 10 years

324
00:14:30,120 --> 00:14:31,980
what you see here

325
00:14:31,980 --> 00:14:36,360
is a particular event rate initiating

326
00:14:36,360 --> 00:14:39,060
event rate of the school water pump a

327
00:14:39,060 --> 00:14:40,440
random failure because I'm talking

328
00:14:40,440 --> 00:14:42,120
process safety now

329
00:14:42,120 --> 00:14:45,000
so I settled once every 10 years I have

330
00:14:45,000 --> 00:14:47,760
on the ultimate left side I'm a wrist

331
00:14:47,760 --> 00:14:49,860
tolerance limit once every hundred

332
00:14:49,860 --> 00:14:52,500
thousand years so I need to reduce my

333
00:14:52,500 --> 00:14:54,839
risk with a factor ten thousand

334
00:14:54,839 --> 00:14:59,820
and I do that with these three ipls 10

335
00:14:59,820 --> 00:15:03,120
times 100 times 10 is 10 000 is just

336
00:15:03,120 --> 00:15:05,399
enough to reduce

337
00:15:05,399 --> 00:15:07,800
my risk sufficiently so that's how

338
00:15:07,800 --> 00:15:10,380
process safety looks at it cyber

339
00:15:10,380 --> 00:15:12,839
security cannot look at it this way we

340
00:15:12,839 --> 00:15:15,360
do show that differently later on so

341
00:15:15,360 --> 00:15:20,040
let's go on to the Cyber physical aspect

342
00:15:20,040 --> 00:15:21,720
I can of course

343
00:15:21,720 --> 00:15:24,060
make alarms disappear

344
00:15:24,060 --> 00:15:26,519
that's not so difficult in most systems

345
00:15:26,519 --> 00:15:28,260
to do that

346
00:15:28,260 --> 00:15:30,720
then the operator will not get a high

347
00:15:30,720 --> 00:15:33,660
temperature will not get a high pressure

348
00:15:33,660 --> 00:15:37,500
he might not respond in time

349
00:15:37,500 --> 00:15:39,720
I can also of course

350
00:15:39,720 --> 00:15:43,320
try to manipulate the heat of the

351
00:15:43,320 --> 00:15:45,720
process by instead of cooling the

352
00:15:45,720 --> 00:15:46,800
process

353
00:15:46,800 --> 00:15:50,100
remove the cooling or increase the heat

354
00:15:50,100 --> 00:15:52,260
somehow with the steam injection so

355
00:15:52,260 --> 00:15:56,279
attack these transmitter functions

356
00:15:56,279 --> 00:16:00,300
I can also immediately try to stop the

357
00:16:00,300 --> 00:16:02,760
pump I can

358
00:16:02,760 --> 00:16:06,660
this is more complex in fact the safety

359
00:16:06,660 --> 00:16:09,720
system by preventing the

360
00:16:09,720 --> 00:16:13,079
activation of my immersion down system

361
00:16:13,079 --> 00:16:16,740
and I can as a most probably the most

362
00:16:16,740 --> 00:16:18,899
promising attack is to add some

363
00:16:18,899 --> 00:16:21,839
additional Catalyst while I already do

364
00:16:21,839 --> 00:16:24,060
hot I just throw in some more catalysts

365
00:16:24,060 --> 00:16:26,519
to stir up the stuff a bit

366
00:16:26,519 --> 00:16:28,500
one thing I can't do

367
00:16:28,500 --> 00:16:30,480
that has attacked this

368
00:16:30,480 --> 00:16:35,220
physical device disrupture disk so can

369
00:16:35,220 --> 00:16:38,339
we say because I have to rip your disc I

370
00:16:38,339 --> 00:16:39,779
am secure

371
00:16:39,779 --> 00:16:42,899
I don't think so because we need to meet

372
00:16:42,899 --> 00:16:45,620
this risk tolerance limit and

373
00:16:45,620 --> 00:16:49,019
probability of failure on demand of this

374
00:16:49,019 --> 00:16:51,180
rupture disk is once every 10 years that

375
00:16:51,180 --> 00:16:55,620
will never cover the full line of risk

376
00:16:55,620 --> 00:16:58,440
reduction I need for that I still need

377
00:16:58,440 --> 00:17:01,040
to make sure that my programmable

378
00:17:01,040 --> 00:17:05,160
hackable functions in this are protected

379
00:17:05,160 --> 00:17:07,559
sufficiently that they can do the

380
00:17:07,559 --> 00:17:10,079
then to the fort

381
00:17:10,079 --> 00:17:13,740
so let's see now a little bit more into

382
00:17:13,740 --> 00:17:18,179
the detail of the

383
00:17:18,179 --> 00:17:19,799
of the formulas

384
00:17:19,799 --> 00:17:22,559
most people say

385
00:17:22,559 --> 00:17:25,199
quantitative approach of cyber physical

386
00:17:25,199 --> 00:17:27,959
risk is very difficult because we do not

387
00:17:27,959 --> 00:17:30,540
have enough statistical data which is

388
00:17:30,540 --> 00:17:33,179
true it depends a little bit on which

389
00:17:33,179 --> 00:17:35,700
statistical data you're looking for

390
00:17:35,700 --> 00:17:39,120
you see here the formula it says risk is

391
00:17:39,120 --> 00:17:40,860
probability of attack

392
00:17:40,860 --> 00:17:43,799
times the probability of Defense failure

393
00:17:43,799 --> 00:17:46,799
if attacked times consequence

394
00:17:46,799 --> 00:17:49,320
and in my formula I'm not interested in

395
00:17:49,320 --> 00:17:51,840
the probability of attack because first

396
00:17:51,840 --> 00:17:52,860
of all

397
00:17:52,860 --> 00:17:55,020
there's not enough statistical

398
00:17:55,020 --> 00:17:57,660
information to estimate this

399
00:17:57,660 --> 00:18:01,620
so I not necessarily ignore it I can do

400
00:18:01,620 --> 00:18:04,559
it qualitatively but I have no

401
00:18:04,559 --> 00:18:08,160
statistical way to to show that but for

402
00:18:08,160 --> 00:18:10,140
the probability of Defense failure or

403
00:18:10,140 --> 00:18:11,880
intact I have a lot of statistical

404
00:18:11,880 --> 00:18:13,740
information because I have a lot of

405
00:18:13,740 --> 00:18:16,020
information of vulnerabilities I have a

406
00:18:16,020 --> 00:18:18,000
lot of information on typical threat

407
00:18:18,000 --> 00:18:20,640
actions and how they combine

408
00:18:20,640 --> 00:18:22,559
so I can create some statistical

409
00:18:22,559 --> 00:18:24,900
information from that for my risk

410
00:18:24,900 --> 00:18:26,400
analysis

411
00:18:26,400 --> 00:18:29,580
so I'm basically saying this formula

412
00:18:29,580 --> 00:18:33,600
I am focusing on to be ready that my

413
00:18:33,600 --> 00:18:36,000
defense is ready if attacked

414
00:18:36,000 --> 00:18:38,880
and how often that is attacked I do not

415
00:18:38,880 --> 00:18:40,860
care though as much I want when I attack

416
00:18:40,860 --> 00:18:43,679
I want to prevent this fatality when I

417
00:18:43,679 --> 00:18:45,480
attack I want to prevent this

418
00:18:45,480 --> 00:18:47,400
environmental damage

419
00:18:47,400 --> 00:18:50,100
so that is the focus and how can you

420
00:18:50,100 --> 00:18:53,400
look at it then for a fairly similar to

421
00:18:53,400 --> 00:18:56,940
lopa is the methodology called Europa

422
00:18:56,940 --> 00:18:58,580
rings of protection

423
00:18:58,580 --> 00:19:01,380
analysis rings of protection analysis

424
00:19:01,380 --> 00:19:04,020
and I'll show you that in later slides

425
00:19:04,020 --> 00:19:07,620
builds kind of protection rings around

426
00:19:07,620 --> 00:19:10,919
where the actual loss starts so if I'm

427
00:19:10,919 --> 00:19:13,980
attacking a transmitter then that's the

428
00:19:13,980 --> 00:19:16,020
point where the law starts and I build

429
00:19:16,020 --> 00:19:18,660
protection rings around that by grouping

430
00:19:18,660 --> 00:19:21,360
particular system elements I'll show you

431
00:19:21,360 --> 00:19:22,740
that in

432
00:19:22,740 --> 00:19:25,380
in slice what is important in this slide

433
00:19:25,380 --> 00:19:27,660
you can have multiple rings of

434
00:19:27,660 --> 00:19:31,140
protection so increasing the strength of

435
00:19:31,140 --> 00:19:34,500
your defense by each each step

436
00:19:34,500 --> 00:19:38,100
and another thing is you do not

437
00:19:38,100 --> 00:19:40,160
necessarily need to meet a full

438
00:19:40,160 --> 00:19:42,960
restorance limit because I still have

439
00:19:42,960 --> 00:19:44,059
this little

440
00:19:44,059 --> 00:19:47,520
refugees there that provides me the

441
00:19:47,520 --> 00:19:50,580
advantage of a factor 10 and it had a

442
00:19:50,580 --> 00:19:52,559
probability failure on the amount of

443
00:19:52,559 --> 00:19:54,840
once every 10 years so instead of having

444
00:19:54,840 --> 00:19:58,500
the original one every 100 000 years I

445
00:19:58,500 --> 00:20:01,140
can go over the ones every 10 000 years

446
00:20:01,140 --> 00:20:02,760
as my

447
00:20:02,760 --> 00:20:05,360
limit

448
00:20:07,740 --> 00:20:10,500
this is the ropa process so the Rope

449
00:20:10,500 --> 00:20:13,380
process starts with the topology diagram

450
00:20:13,380 --> 00:20:16,740
from a topology diagram which is a

451
00:20:16,740 --> 00:20:19,140
physical representation of the system we

452
00:20:19,140 --> 00:20:21,120
make a functional representation of the

453
00:20:21,120 --> 00:20:23,700
system what's the difference well in the

454
00:20:23,700 --> 00:20:24,440
physical

455
00:20:24,440 --> 00:20:26,760
representation you might have one

456
00:20:26,760 --> 00:20:28,440
engineer station

457
00:20:28,440 --> 00:20:31,919
in a functional representation that one

458
00:20:31,919 --> 00:20:34,080
engineer station might become three

459
00:20:34,080 --> 00:20:37,020
engineer stations because I have a tool

460
00:20:37,020 --> 00:20:39,960
in there from which I configure my

461
00:20:39,960 --> 00:20:42,059
control system or configure my safety

462
00:20:42,059 --> 00:20:44,940
system or manage my switches so instead

463
00:20:44,940 --> 00:20:46,919
of having one I suddenly have three

464
00:20:46,919 --> 00:20:48,840
engineer stations it works the other way

465
00:20:48,840 --> 00:20:50,760
around two if I have 10 operator

466
00:20:50,760 --> 00:20:53,160
stations well why should I am interested

467
00:20:53,160 --> 00:20:55,620
in all 10 operator station I can just

468
00:20:55,620 --> 00:20:58,260
reduce it maybe to one or two but the

469
00:20:58,260 --> 00:21:00,900
moment I use that operator station to

470
00:21:00,900 --> 00:21:02,700
create some overrides in the safety

471
00:21:02,700 --> 00:21:04,740
system well and it also has a CIS

472
00:21:04,740 --> 00:21:07,200
function so then I need to add some

473
00:21:07,200 --> 00:21:08,820
functions

474
00:21:08,820 --> 00:21:10,799
the other thing I need is channels

475
00:21:10,799 --> 00:21:14,460
protocols because my targets are always

476
00:21:14,460 --> 00:21:17,340
my assets and my protocols so that's why

477
00:21:17,340 --> 00:21:20,780
we have the son and konyi diagram

478
00:21:21,000 --> 00:21:22,980
a totem boat

479
00:21:22,980 --> 00:21:25,919
from boat I create a risk model

480
00:21:25,919 --> 00:21:29,400
I have a risk engine that I can load

481
00:21:29,400 --> 00:21:31,919
with that risk model and for each system

482
00:21:31,919 --> 00:21:34,860
element in that rich model

483
00:21:34,860 --> 00:21:37,919
I have a set of attack scenarios so

484
00:21:37,919 --> 00:21:40,080
we've trap modeled each element so we

485
00:21:40,080 --> 00:21:42,360
thread models how to attack a switch how

486
00:21:42,360 --> 00:21:44,340
to Echo operate the station how to to

487
00:21:44,340 --> 00:21:46,860
attack a controller how to attack a

488
00:21:46,860 --> 00:21:48,480
transmitter

489
00:21:48,480 --> 00:21:51,360
all of this is in there really hundreds

490
00:21:51,360 --> 00:21:54,360
of cyber attacks put into that risk

491
00:21:54,360 --> 00:21:56,520
engine and that risk against unit is

492
00:21:56,520 --> 00:22:00,000
estimating for many different threat

493
00:22:00,000 --> 00:22:03,120
actions and countermeasures it estimates

494
00:22:03,120 --> 00:22:06,179
the probability of failure on attack and

495
00:22:06,179 --> 00:22:07,799
then they need to communicate combine

496
00:22:07,799 --> 00:22:09,600
this because this is all per system

497
00:22:09,600 --> 00:22:12,480
element now I need to combine it and I

498
00:22:12,480 --> 00:22:14,280
use for that dependency diagram I

499
00:22:14,280 --> 00:22:16,980
combine over dependencies I need to

500
00:22:16,980 --> 00:22:19,260
speed up a little bit because of time

501
00:22:19,260 --> 00:22:22,740
this is a zooming in a little bit shows

502
00:22:22,740 --> 00:22:25,140
a number of system elements

503
00:22:25,140 --> 00:22:27,059
you see on the right side I start with

504
00:22:27,059 --> 00:22:28,799
the fuel transmitters that I have the

505
00:22:28,799 --> 00:22:31,140
controller then I have some operator

506
00:22:31,140 --> 00:22:34,080
station engineer station and I have some

507
00:22:34,080 --> 00:22:35,700
other function instrument Asset

508
00:22:35,700 --> 00:22:38,820
Management function where I'm managers

509
00:22:38,820 --> 00:22:41,760
manage my field devices with

510
00:22:41,760 --> 00:22:44,820
so how do I do well I've already said

511
00:22:44,820 --> 00:22:47,400
first thing is estimate the probability

512
00:22:47,400 --> 00:22:50,039
of failure on defense failure on attack

513
00:22:50,039 --> 00:22:54,179
BFA for each system element so I have a

514
00:22:54,179 --> 00:22:56,400
number for each system element is it one

515
00:22:56,400 --> 00:22:59,100
number no it's not one number because I

516
00:22:59,100 --> 00:23:01,799
have number of threat actors maybe eight

517
00:23:01,799 --> 00:23:04,020
threat actors so it's actually a factor

518
00:23:04,020 --> 00:23:06,179
it's for each threat actor it can be a

519
00:23:06,179 --> 00:23:08,179
different PFA

520
00:23:08,179 --> 00:23:12,659
so when I have that estimated then I

521
00:23:12,659 --> 00:23:15,240
want to combine them again so how I'm

522
00:23:15,240 --> 00:23:17,640
going to do that well these are metric

523
00:23:17,640 --> 00:23:20,280
diagrams that give training people can

524
00:23:20,280 --> 00:23:22,380
really struggle with it certainly when

525
00:23:22,380 --> 00:23:25,260
it becomes bigger in systems but here I

526
00:23:25,260 --> 00:23:28,460
combine S1 which was our field equipment

527
00:23:28,460 --> 00:23:32,760
with S2 which was our controller and I

528
00:23:32,760 --> 00:23:36,120
kind of create a protection ring which

529
00:23:36,120 --> 00:23:38,419
means that I'm going to look at the

530
00:23:38,419 --> 00:23:41,159
defensive strength of the boat

531
00:23:41,159 --> 00:23:43,260
and the controller adds some defensive

532
00:23:43,260 --> 00:23:45,000
strength because it can be a parameter

533
00:23:45,000 --> 00:23:47,480
in there that yes or no enables right

534
00:23:47,480 --> 00:23:50,400
activity to the transmitter or yes and

535
00:23:50,400 --> 00:23:51,780
no you need to set a particular

536
00:23:51,780 --> 00:23:53,940
maintenance mode to allow that so we

537
00:23:53,940 --> 00:23:56,159
have a first ring

538
00:23:56,159 --> 00:23:59,039
then I can extend that ring

539
00:23:59,039 --> 00:24:03,179
and include maybe X S6 that was I think

540
00:24:03,179 --> 00:24:04,980
the engineer station

541
00:24:04,980 --> 00:24:08,159
and create again a new

542
00:24:08,159 --> 00:24:12,059
uh ring with a new probability of

543
00:24:12,059 --> 00:24:14,600
Defense failure on Attack by combining

544
00:24:14,600 --> 00:24:17,400
these I can do the same thing

545
00:24:17,400 --> 00:24:20,159
with the DCS server I can do the same

546
00:24:20,159 --> 00:24:21,059
thing

547
00:24:21,059 --> 00:24:23,880
with the operator station

548
00:24:23,880 --> 00:24:26,640
so I have already three different rings

549
00:24:26,640 --> 00:24:30,120
at that point in time I can have just a

550
00:24:30,120 --> 00:24:32,520
little bit more complex ring where we

551
00:24:32,520 --> 00:24:34,020
have an indirect relationship an

552
00:24:34,020 --> 00:24:37,320
operator station A7 that needs to first

553
00:24:37,320 --> 00:24:40,440
talk with the DCS server before it can

554
00:24:40,440 --> 00:24:42,900
talk to the controller before it can

555
00:24:42,900 --> 00:24:45,059
reach the

556
00:24:45,059 --> 00:24:47,520
the sensor so you have the longer line

557
00:24:47,520 --> 00:24:50,400
there so you first have a inner ring

558
00:24:50,400 --> 00:24:52,740
there you combine the two inner rings

559
00:24:52,740 --> 00:24:56,880
and I can also do the same thing which

560
00:24:56,880 --> 00:24:58,760
is engineering

561
00:24:58,760 --> 00:25:03,299
IMS and then I can look at which of the

562
00:25:03,299 --> 00:25:05,820
tree which of the four or five different

563
00:25:05,820 --> 00:25:08,340
rings has the highest probability and

564
00:25:08,340 --> 00:25:10,380
the highest probability gives me the

565
00:25:10,380 --> 00:25:13,260
highest risk of course I can extend that

566
00:25:13,260 --> 00:25:15,059
because I also need to include the

567
00:25:15,059 --> 00:25:17,220
domain function I need to include the

568
00:25:17,220 --> 00:25:20,220
APC phosphorus control the storing

569
00:25:20,220 --> 00:25:22,080
function that becomes a very big picture

570
00:25:22,080 --> 00:25:24,539
on that here is a kind of a summary

571
00:25:24,539 --> 00:25:27,480
again I built my risk model I'm a Cyber

572
00:25:27,480 --> 00:25:30,659
attack scenarios I'm a loss scenarios I

573
00:25:30,659 --> 00:25:33,240
have connected those law scenarios to

574
00:25:33,240 --> 00:25:36,120
the targets I want to attack so okay to

575
00:25:36,120 --> 00:25:37,679
create this whole scenario I need to

576
00:25:37,679 --> 00:25:39,779
attack up registration I need the tech

577
00:25:39,779 --> 00:25:41,640
maybe the controller and we need to

578
00:25:41,640 --> 00:25:43,740
attack the transmitter

579
00:25:43,740 --> 00:25:48,120
all of those are in-depth model and and

580
00:25:48,120 --> 00:25:49,679
I get my

581
00:25:49,679 --> 00:25:53,039
previous from the risk engine then I

582
00:25:53,039 --> 00:25:55,679
combine it again with ropa and then I

583
00:25:55,679 --> 00:25:57,900
can actually look at risk from two

584
00:25:57,900 --> 00:26:02,340
angles I can look at risk from the angle

585
00:26:02,340 --> 00:26:05,820
of the installation so I kind of ask

586
00:26:05,820 --> 00:26:08,880
myself okay I have terminal run away

587
00:26:08,880 --> 00:26:11,940
possibilities what can cause that which

588
00:26:11,940 --> 00:26:13,919
cyber attacks can cause it which threats

589
00:26:13,919 --> 00:26:16,320
can cause it which equipment play a role

590
00:26:16,320 --> 00:26:17,820
in this which functions I should say

591
00:26:17,820 --> 00:26:20,820
basically I can even ask for for which

592
00:26:20,820 --> 00:26:23,840
threat actors might cause that

593
00:26:23,840 --> 00:26:26,700
and I can look at the other way if I

594
00:26:26,700 --> 00:26:29,460
attack this device what can I do in the

595
00:26:29,460 --> 00:26:30,539
control

596
00:26:30,539 --> 00:26:33,720
in the installation environment so I can

597
00:26:33,720 --> 00:26:36,120
have a look at different

598
00:26:36,120 --> 00:26:39,419
different ways looking at risk with this

599
00:26:39,419 --> 00:26:42,919
methodology and we use this methodology

600
00:26:42,919 --> 00:26:45,059
since eight years

601
00:26:45,059 --> 00:26:47,700
we've developed tooling for it that

602
00:26:47,700 --> 00:26:50,820
makes life a little bit more easy

603
00:26:50,820 --> 00:26:54,179
and this is kind of the overall scenario

604
00:26:54,179 --> 00:26:56,460
so I'm ready with my

605
00:26:56,460 --> 00:26:57,840
slides

606
00:26:57,840 --> 00:27:00,240
so if there are any questions

607
00:27:00,240 --> 00:27:02,580
I believe there are some microphones on

608
00:27:02,580 --> 00:27:03,539
the site

609
00:27:03,539 --> 00:27:06,120
where you can ask your question please

610
00:27:06,120 --> 00:27:08,400
speak loud for me because I'm kind of a

611
00:27:08,400 --> 00:27:11,279
little bit old deaf guy

612
00:27:11,279 --> 00:27:13,200
so so

613
00:27:13,200 --> 00:27:15,480
um your use of what I assume is Markov

614
00:27:15,480 --> 00:27:18,240
models Markov chains and I know with the

615
00:27:18,240 --> 00:27:19,159
fair

616
00:27:19,159 --> 00:27:23,100
ontology there are uh Monte Carlo

617
00:27:23,100 --> 00:27:24,539
simulations and those sorts of things

618
00:27:24,539 --> 00:27:27,059
are there tools that you have built or

619
00:27:27,059 --> 00:27:29,340
you use that are combining those those

620
00:27:29,340 --> 00:27:31,980
probability and and

621
00:27:31,980 --> 00:27:34,860
mathematics of which

622
00:27:34,860 --> 00:27:36,960
I'm sorry what you were saying before

623
00:27:36,960 --> 00:27:40,020
the combining so you were showing the

624
00:27:40,020 --> 00:27:42,840
the probability chains the Markov chains

625
00:27:42,840 --> 00:27:44,279
I think they probably are and then

626
00:27:44,279 --> 00:27:46,559
there's also statistical models that fit

627
00:27:46,559 --> 00:27:48,659
behind the fair ontology like Monte

628
00:27:48,659 --> 00:27:51,120
Carlo simulations are there tools that

629
00:27:51,120 --> 00:27:53,880
you have identified that actually do all

630
00:27:53,880 --> 00:27:54,960
that for you

631
00:27:54,960 --> 00:27:57,360
because there's a lot of math there no

632
00:27:57,360 --> 00:27:59,220
we we have developed a tool like that

633
00:27:59,220 --> 00:28:01,679
ourselves okay but Honeywell we use for

634
00:28:01,679 --> 00:28:04,020
the risk estimation for determining the

635
00:28:04,020 --> 00:28:06,179
probability of failure or attack we use

636
00:28:06,179 --> 00:28:09,120
the methodology of fare factor analysis

637
00:28:09,120 --> 00:28:12,659
uh information risk and for the

638
00:28:12,659 --> 00:28:15,539
combining everything we use ropa a

639
00:28:15,539 --> 00:28:17,120
technique developed

640
00:28:17,120 --> 00:28:21,120
about 15 years ago initially for the I.T

641
00:28:21,120 --> 00:28:24,360
World there it actually failed and then

642
00:28:24,360 --> 00:28:28,980
in 2008 it was picked up for the

643
00:28:28,980 --> 00:28:31,080
OT world we didn't call it the OT in

644
00:28:31,080 --> 00:28:34,320
those days but okay and there it works

645
00:28:34,320 --> 00:28:36,659
much better because we have much clearer

646
00:28:36,659 --> 00:28:39,559
dependencies between hey if you have a

647
00:28:39,559 --> 00:28:42,960
transmitter it depends on the controller

648
00:28:42,960 --> 00:28:44,760
a controller depends on the operator

649
00:28:44,760 --> 00:28:47,159
station and so you have clear lines of

650
00:28:47,159 --> 00:28:49,080
dependency clear lines to which you can

651
00:28:49,080 --> 00:28:50,940
combine these

652
00:28:50,940 --> 00:28:53,460
these system elements and create new

653
00:28:53,460 --> 00:28:56,940
rings and new probability of failure on

654
00:28:56,940 --> 00:28:58,620
attack thank you

655
00:28:58,620 --> 00:29:01,980
one question on the left yeah so first

656
00:29:01,980 --> 00:29:03,179
of all thank you for the presentation

657
00:29:03,179 --> 00:29:05,580
this was really good

658
00:29:05,580 --> 00:29:08,340
um so the model so the statistical model

659
00:29:08,340 --> 00:29:10,440
that you have presented

660
00:29:10,440 --> 00:29:12,720
relies in my opinion

661
00:29:12,720 --> 00:29:16,200
a lot on the probability of failure of

662
00:29:16,200 --> 00:29:17,760
the defense failure

663
00:29:17,760 --> 00:29:20,340
so how do you determine that probability

664
00:29:20,340 --> 00:29:23,460
in the context of a specific system not

665
00:29:23,460 --> 00:29:25,559
in general when you do a threat modeling

666
00:29:25,559 --> 00:29:27,419
but when you have let's say a system

667
00:29:27,419 --> 00:29:31,520
which is the US so geographical context

668
00:29:31,520 --> 00:29:33,840
industrial context

669
00:29:33,840 --> 00:29:36,720
so how do you how do you get that

670
00:29:36,720 --> 00:29:40,740
probability calculated precisely yeah

671
00:29:40,740 --> 00:29:43,500
well that's always a

672
00:29:43,500 --> 00:29:45,659
a good question when you talk in the

673
00:29:45,659 --> 00:29:47,820
semi quantitative environment because

674
00:29:47,820 --> 00:29:50,520
part of the data comes from statistical

675
00:29:50,520 --> 00:29:52,080
information parties subject matter

676
00:29:52,080 --> 00:29:56,340
expertise and you might say over the

677
00:29:56,340 --> 00:29:58,919
years you'll learn to tune that and come

678
00:29:58,919 --> 00:30:03,360
to uh results that are acceptable we are

679
00:30:03,360 --> 00:30:05,279
very often challenged when we have

680
00:30:05,279 --> 00:30:07,200
Greenfield projects build new chemical

681
00:30:07,200 --> 00:30:09,960
plants then nowadays governments

682
00:30:09,960 --> 00:30:12,840
certainly in Europe are challenging us

683
00:30:12,840 --> 00:30:16,520
to show that the Cyber physical risk

684
00:30:16,520 --> 00:30:19,740
meets their risk criteria so they're

685
00:30:19,740 --> 00:30:22,080
it's checked by

686
00:30:22,080 --> 00:30:24,600
by those organization kind of audited if

687
00:30:24,600 --> 00:30:27,539
if it's correctly done in the sense that

688
00:30:27,539 --> 00:30:30,120
it provides more or less reliable

689
00:30:30,120 --> 00:30:34,740
information but we do not uh

690
00:30:34,740 --> 00:30:38,760
is not accurate in that sense it remains

691
00:30:38,760 --> 00:30:42,120
a semi-quantitative but full qualitative

692
00:30:42,120 --> 00:30:44,880
is not accurate either the only real

693
00:30:44,880 --> 00:30:48,299
accurate thing would be quantitative but

694
00:30:48,299 --> 00:30:50,100
that's very difficult to do in our world

695
00:30:50,100 --> 00:30:53,640
so that's typically not that so if you

696
00:30:53,640 --> 00:30:55,980
have to ask all the partners of the

697
00:30:55,980 --> 00:30:58,620
defense defense sorry can you speak a

698
00:30:58,620 --> 00:31:00,840
little yeah if you have to if we have to

699
00:31:00,840 --> 00:31:03,360
ask the cyber security controls

700
00:31:03,360 --> 00:31:07,140
providers today to make this better

701
00:31:07,140 --> 00:31:10,760
what would you ask them to do

702
00:31:10,919 --> 00:31:13,020
I'm not sure I understand the question

703
00:31:13,020 --> 00:31:14,760
in order for you to determine the

704
00:31:14,760 --> 00:31:18,020
probability of failure of a of a defense

705
00:31:18,020 --> 00:31:20,880
right so we need to have some

706
00:31:20,880 --> 00:31:22,799
information about how the defense and

707
00:31:22,799 --> 00:31:25,980
and what are the possible failure modes

708
00:31:25,980 --> 00:31:28,380
for that defense mechanism okay okay

709
00:31:28,380 --> 00:31:31,860
okay well first of all

710
00:31:31,860 --> 00:31:34,500
the the trick is of course in the risk

711
00:31:34,500 --> 00:31:36,720
reduction how much a security measure

712
00:31:36,720 --> 00:31:40,679
actually reduces the risk there is some

713
00:31:40,679 --> 00:31:42,679
some

714
00:31:42,679 --> 00:31:47,039
subjective element in that but the

715
00:31:47,039 --> 00:31:51,299
statistical uh strength is talking about

716
00:31:51,299 --> 00:31:55,260
the popularity of specific threat

717
00:31:55,260 --> 00:31:58,399
actions that we can do very accurately

718
00:31:58,399 --> 00:32:01,980
in a statistical way to show okay this

719
00:32:01,980 --> 00:32:03,419
this type of attack is much more

720
00:32:03,419 --> 00:32:05,700
effective much more common than an other

721
00:32:05,700 --> 00:32:07,440
type of fact and of course you try to

722
00:32:07,440 --> 00:32:09,960
focus to uh

723
00:32:09,960 --> 00:32:13,740
secure your system on the most

724
00:32:13,740 --> 00:32:16,919
yeah the most the most common type of

725
00:32:16,919 --> 00:32:20,340
attack that that is a clever threat

726
00:32:20,340 --> 00:32:23,159
actor Will of course focus on the least

727
00:32:23,159 --> 00:32:26,220
common type of attack in the hope that

728
00:32:26,220 --> 00:32:28,919
you can bypass your defense that's

729
00:32:28,919 --> 00:32:30,059
always

730
00:32:30,059 --> 00:32:32,940
the the fight you have there is not

731
00:32:32,940 --> 00:32:34,559
really a good solution

732
00:32:34,559 --> 00:32:37,679
on an anticipating threat actor in that

733
00:32:37,679 --> 00:32:39,860
sense

734
00:32:40,559 --> 00:32:42,539
okay thank you

735
00:32:42,539 --> 00:32:46,799
okay I think I bypassed my time no still

736
00:32:46,799 --> 00:32:49,080
another question

737
00:32:49,080 --> 00:32:50,880
um just one more thing it's not a

738
00:32:50,880 --> 00:32:53,220
question it's a comment I just wanted to

739
00:32:53,220 --> 00:32:55,020
thank Sinclair for those of you who

740
00:32:55,020 --> 00:32:58,320
don't know him he is one of the ogs of

741
00:32:58,320 --> 00:33:01,919
OT cyber security and he is retiring

742
00:33:01,919 --> 00:33:04,679
unfortunately I've had the privilege to

743
00:33:04,679 --> 00:33:06,179
work with him for a long time and that

744
00:33:06,179 --> 00:33:08,100
time is is ending so I want to ask

745
00:33:08,100 --> 00:33:09,539
everybody to give them a huge round of

746
00:33:09,539 --> 00:33:11,399
applause and I wish I'd gotten up here

747
00:33:11,399 --> 00:33:14,360
before a lot of people

748
00:33:14,940 --> 00:33:17,720
Sinclair

749
00:33:20,480 --> 00:33:23,039
retiring is not an achievement you know

750
00:33:23,039 --> 00:33:24,419
that's just

751
00:33:24,419 --> 00:33:26,880
keep bringing

752
00:33:26,880 --> 00:33:29,580
and then you manage okay thank you very

753
00:33:29,580 --> 00:33:30,779
much

754
00:33:30,779 --> 00:33:33,779
foreign

