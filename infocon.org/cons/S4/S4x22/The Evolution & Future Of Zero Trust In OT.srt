1
00:00:05,279 --> 00:00:06,640
thank you john and richard for joining

2
00:00:06,640 --> 00:00:08,080
us today to talk a little bit about zero

3
00:00:08,080 --> 00:00:10,719
trust um to kind of get this started uh

4
00:00:10,719 --> 00:00:12,320
john would you mind just kind of walking

5
00:00:12,320 --> 00:00:15,280
us through what zero trust means to you

6
00:00:15,280 --> 00:00:17,279
and how you talk about it with with your

7
00:00:17,279 --> 00:00:19,039
customers sure

8
00:00:19,039 --> 00:00:22,720
so um let me talk about zero trust

9
00:00:22,720 --> 00:00:25,359
uh the quickest i possibly can so what

10
00:00:25,359 --> 00:00:27,840
is zero trust oh the slide was already

11
00:00:27,840 --> 00:00:30,400
up so i'm gonna move back please

12
00:00:30,400 --> 00:00:32,640
one

13
00:00:33,200 --> 00:00:34,880
because it's not on my mind there we go

14
00:00:34,880 --> 00:00:37,200
so trust what is it well trust is a

15
00:00:37,200 --> 00:00:38,879
human emotion that we've injected into

16
00:00:38,879 --> 00:00:41,200
digital systems for absolutely no reason

17
00:00:41,200 --> 00:00:43,440
so it turns out the trust

18
00:00:43,440 --> 00:00:46,000
in digital systems is a vulnerability

19
00:00:46,000 --> 00:00:47,760
and it's a very dangerous vulnerability

20
00:00:47,760 --> 00:00:49,280
in fact it's the most dangerous

21
00:00:49,280 --> 00:00:51,120
vulnerability in the world because it's

22
00:00:51,120 --> 00:00:54,079
the only vault that's also an exploit at

23
00:00:54,079 --> 00:00:56,079
the same time you don't need to create

24
00:00:56,079 --> 00:00:58,879
new malware for trust all you need to do

25
00:00:58,879 --> 00:01:01,440
is be on the network and the bad actors

26
00:01:01,440 --> 00:01:03,039
can always get on the network so the

27
00:01:03,039 --> 00:01:06,000
only value you get from trust in your

28
00:01:06,000 --> 00:01:07,520
organization

29
00:01:07,520 --> 00:01:09,680
uh is that the malicious actors have a

30
00:01:09,680 --> 00:01:11,920
cool place to hang out that's all that's

31
00:01:11,920 --> 00:01:14,400
the only thing it provides for you so

32
00:01:14,400 --> 00:01:16,880
there's a lot of myths about xero trust

33
00:01:16,880 --> 00:01:19,439
the first one is zero trust means making

34
00:01:19,439 --> 00:01:22,000
a system trusted how much trust should

35
00:01:22,000 --> 00:01:24,400
there be in a zero trust system i tried

36
00:01:24,400 --> 00:01:27,280
to make it as explicit as as i could

37
00:01:27,280 --> 00:01:29,280
zero we're trying to get rid of trust

38
00:01:29,280 --> 00:01:32,400
not make system trusted trust is a joke

39
00:01:32,400 --> 00:01:34,720
you can read the trusted computing fact

40
00:01:34,720 --> 00:01:37,119
from ross anderson he will tell you that

41
00:01:37,119 --> 00:01:40,000
zero trust is also not about identity it

42
00:01:40,000 --> 00:01:42,960
consumes identity but it isn't equal to

43
00:01:42,960 --> 00:01:45,840
identity i can prove that with two words

44
00:01:45,840 --> 00:01:48,399
snowden manning they were trusted users

45
00:01:48,399 --> 00:01:50,799
they had all the right identity in mfa

46
00:01:50,799 --> 00:01:52,880
but nobody looked at their packets post

47
00:01:52,880 --> 00:01:55,119
authentication and then there are zero

48
00:01:55,119 --> 00:01:58,159
trusts products that is not true

49
00:01:58,159 --> 00:02:00,640
there are products that work well in

50
00:02:00,640 --> 00:02:02,640
zero trust environments

51
00:02:02,640 --> 00:02:05,360
but zero trust is a strategy designed to

52
00:02:05,360 --> 00:02:07,920
stop data breaches and make other cyber

53
00:02:07,920 --> 00:02:10,800
security attacks unsuccessful it's a

54
00:02:10,800 --> 00:02:13,760
strategy that uses products and then

55
00:02:13,760 --> 00:02:16,560
zero trust is complicated not true there

56
00:02:16,560 --> 00:02:18,560
are nine things you need to know to

57
00:02:18,560 --> 00:02:21,280
understand and do zero trust they look

58
00:02:21,280 --> 00:02:24,640
like this the four design concepts first

59
00:02:24,640 --> 00:02:26,560
focus on the business drivers what is

60
00:02:26,560 --> 00:02:29,040
your business trying to achieve second

61
00:02:29,040 --> 00:02:31,519
design the system from the inside out

62
00:02:31,519 --> 00:02:33,760
start with the data or assets you're

63
00:02:33,760 --> 00:02:36,080
trying to protect if you don't know what

64
00:02:36,080 --> 00:02:37,760
you're protecting it will never work

65
00:02:37,760 --> 00:02:40,400
will it third determine who

66
00:02:40,400 --> 00:02:42,160
or what should have access to any

67
00:02:42,160 --> 00:02:44,879
particular resource need to know least

68
00:02:44,879 --> 00:02:47,280
privilege but enforce it we've talked

69
00:02:47,280 --> 00:02:49,040
about least privilege forever but we

70
00:02:49,040 --> 00:02:51,519
never enforced it and then finally you

71
00:02:51,519 --> 00:02:54,319
inspect and log all traffic because

72
00:02:54,319 --> 00:02:56,160
that's where all the bad stuff happens

73
00:02:56,160 --> 00:02:58,319
in the traffic and if we do that we can

74
00:02:58,319 --> 00:03:01,440
create a layer 7 policy ultimately zero

75
00:03:01,440 --> 00:03:05,440
trust is a layer 7 policy statement now

76
00:03:05,440 --> 00:03:07,920
there is a five-step methodology that

77
00:03:07,920 --> 00:03:10,080
will guide your journey the first thing

78
00:03:10,080 --> 00:03:12,959
you need to do is define your protect

79
00:03:12,959 --> 00:03:15,440
surface i can take the attack surface

80
00:03:15,440 --> 00:03:18,239
and shrink it down orders of magnitude

81
00:03:18,239 --> 00:03:21,360
to something very small and easily known

82
00:03:21,360 --> 00:03:23,840
called a protect surface what do you put

83
00:03:23,840 --> 00:03:26,400
in a protect surface you put in a daz

84
00:03:26,400 --> 00:03:28,640
element stands for data

85
00:03:28,640 --> 00:03:33,760
applications assets or resources

86
00:03:33,760 --> 00:03:36,400
so you want to protect the stuff that

87
00:03:36,400 --> 00:03:38,480
matters and then you're going to see how

88
00:03:38,480 --> 00:03:40,640
it works as a system map the transaction

89
00:03:40,640 --> 00:03:42,560
flows and that will determine the

90
00:03:42,560 --> 00:03:44,879
technology that you need to protect it

91
00:03:44,879 --> 00:03:47,040
so you cannot understand how to protect

92
00:03:47,040 --> 00:03:49,120
something until you need to know what to

93
00:03:49,120 --> 00:03:51,440
protect the fourth step is to create

94
00:03:51,440 --> 00:03:54,080
policy the fifth step is to monitor and

95
00:03:54,080 --> 00:03:56,080
maintain so you can take all the

96
00:03:56,080 --> 00:03:58,959
telemetry and send it into a feedback

97
00:03:58,959 --> 00:04:01,280
loop and make the system in stronger and

98
00:04:01,280 --> 00:04:05,000
stronger over time zero trust is an

99
00:04:05,000 --> 00:04:07,439
anti-fragile system if you're familiar

100
00:04:07,439 --> 00:04:10,560
with anti-fragility read the book by to

101
00:04:10,560 --> 00:04:11,439
lab

102
00:04:11,439 --> 00:04:12,959
we can make

103
00:04:12,959 --> 00:04:15,040
this particular system stronger and

104
00:04:15,040 --> 00:04:16,798
stronger over time so you're going to

105
00:04:16,798 --> 00:04:19,440
break the big problem of cyber security

106
00:04:19,440 --> 00:04:21,440
down into multiple small problems called

107
00:04:21,440 --> 00:04:24,240
protect surfaces and we can do that for

108
00:04:24,240 --> 00:04:27,040
ot environments all the time and i've

109
00:04:27,040 --> 00:04:28,880
done it a lot so

110
00:04:28,880 --> 00:04:30,880
this is the quick introduction to xero

111
00:04:30,880 --> 00:04:32,639
trust and

112
00:04:32,639 --> 00:04:34,639
tony and

113
00:04:34,639 --> 00:04:36,000
richard and i are going to have a little

114
00:04:36,000 --> 00:04:37,840
discussion because we all all have been

115
00:04:37,840 --> 00:04:40,320
hanging out for a while now talking zero

116
00:04:40,320 --> 00:04:44,320
trust in cleveland in phoenix for ot and

117
00:04:44,320 --> 00:04:45,840
all that stuff so

118
00:04:45,840 --> 00:04:47,680
thank you for uh letting me come and

119
00:04:47,680 --> 00:04:48,880
chat

120
00:04:48,880 --> 00:04:50,080
thank you john

121
00:04:50,080 --> 00:04:51,680
and we talked about zero trust we talk a

122
00:04:51,680 --> 00:04:54,880
lot about the hype the marketing buzz

123
00:04:54,880 --> 00:04:56,320
you know what's the latest product and

124
00:04:56,320 --> 00:04:58,400
you just talked about those myths and i

125
00:04:58,400 --> 00:04:59,759
think one of the things that that people

126
00:04:59,759 --> 00:05:01,680
struggle with is you know are people

127
00:05:01,680 --> 00:05:04,080
actually doing zero trust today and can

128
00:05:04,080 --> 00:05:06,000
you talk about you know are you seeing

129
00:05:06,000 --> 00:05:08,400
zero trust applied today and and what

130
00:05:08,400 --> 00:05:10,560
does it look like well there are

131
00:05:10,560 --> 00:05:12,320
certainly are thousands of zero trust

132
00:05:12,320 --> 00:05:14,240
environments the president united states

133
00:05:14,240 --> 00:05:16,160
issued an executive order mandating all

134
00:05:16,160 --> 00:05:18,400
federal agencies adopt zero trust he

135
00:05:18,400 --> 00:05:20,080
didn't just pick a buzzword out of the

136
00:05:20,080 --> 00:05:22,000
air right there's been a lot of stuff

137
00:05:22,000 --> 00:05:23,600
going on behind the scenes that i can't

138
00:05:23,600 --> 00:05:25,919
really talk about but in this context

139
00:05:25,919 --> 00:05:29,520
for ics ot iot whatever buzzword we're

140
00:05:29,520 --> 00:05:31,600
going to use i've been building a lot of

141
00:05:31,600 --> 00:05:33,039
those zero trust networks starting

142
00:05:33,039 --> 00:05:36,080
probably 2012. was the first one i did

143
00:05:36,080 --> 00:05:38,240
for a big manufacturing

144
00:05:38,240 --> 00:05:40,080
company because they couldn't solve a

145
00:05:40,080 --> 00:05:42,320
lot of their problems traditionally and

146
00:05:42,320 --> 00:05:43,919
it was the executive vice president of

147
00:05:43,919 --> 00:05:46,160
manufacturing who understood

148
00:05:46,160 --> 00:05:48,320
strategically what i was trying to do

149
00:05:48,320 --> 00:05:50,800
but i've done it for smart meters i've

150
00:05:50,800 --> 00:05:52,880
done it for wind farms

151
00:05:52,880 --> 00:05:55,440
i've done it for oil and gas rigs

152
00:05:55,440 --> 00:05:58,720
it doesn't matter

153
00:05:58,720 --> 00:06:00,880
what the protect surface is i can put

154
00:06:00,880 --> 00:06:03,440
anything in a protect surface so a plc

155
00:06:03,440 --> 00:06:05,680
from rockwell automation done that

156
00:06:05,680 --> 00:06:07,600
dozens of times

157
00:06:07,600 --> 00:06:08,880
very cool and

158
00:06:08,880 --> 00:06:10,400
and i guess when you

159
00:06:10,400 --> 00:06:12,240
when you look at uh

160
00:06:12,240 --> 00:06:14,160
zero trust there's a lot of

161
00:06:14,160 --> 00:06:16,479
interpretations of what zero trust means

162
00:06:16,479 --> 00:06:18,560
you talked about it as a strategy and

163
00:06:18,560 --> 00:06:20,400
we've seen publications from nist and i

164
00:06:20,400 --> 00:06:21,759
know you've done some recent work with

165
00:06:21,759 --> 00:06:23,520
nstack you know what

166
00:06:23,520 --> 00:06:25,199
how do we find the the authoritative

167
00:06:25,199 --> 00:06:27,520
answer as to what is zero trust and

168
00:06:27,520 --> 00:06:29,039
where can we be looking

169
00:06:29,039 --> 00:06:31,680
so we just can't we just finished in

170
00:06:31,680 --> 00:06:32,960
february

171
00:06:32,960 --> 00:06:36,160
uh the and published the report uh from

172
00:06:36,160 --> 00:06:38,319
nsac which is a governmental

173
00:06:38,319 --> 00:06:39,840
organization that brings public and

174
00:06:39,840 --> 00:06:42,319
private uh organizations together and

175
00:06:42,319 --> 00:06:44,319
they have representatives from

176
00:06:44,319 --> 00:06:46,240
disa nsa

177
00:06:46,240 --> 00:06:47,199
uh

178
00:06:47,199 --> 00:06:50,240
dod and then private sector and so that

179
00:06:50,240 --> 00:06:52,720
report which is on cis's website

180
00:06:52,720 --> 00:06:54,319
is what i would consider to be

181
00:06:54,319 --> 00:06:56,400
authoritative it contains the four

182
00:06:56,400 --> 00:06:58,639
design principles the five steps it has

183
00:06:58,639 --> 00:07:01,280
the kipling method policy uh framework

184
00:07:01,280 --> 00:07:03,520
it has the maturity model and it has

185
00:07:03,520 --> 00:07:05,680
some examples in there so if you really

186
00:07:05,680 --> 00:07:07,440
want to know what xero trust is without

187
00:07:07,440 --> 00:07:09,360
the vendor hype go

188
00:07:09,360 --> 00:07:11,440
look at the end stack zero trust

189
00:07:11,440 --> 00:07:13,759
subcommittee report i i really enjoyed

190
00:07:13,759 --> 00:07:16,080
that mater maturity model element of it

191
00:07:16,080 --> 00:07:17,919
because it really did show how do we

192
00:07:17,919 --> 00:07:20,400
move into this right not every device

193
00:07:20,400 --> 00:07:22,160
not every everything has to have an

194
00:07:22,160 --> 00:07:24,080
identity and you mentioned that zero

195
00:07:24,080 --> 00:07:25,840
trust is not identity and i guess

196
00:07:25,840 --> 00:07:27,199
richard you know what what is your view

197
00:07:27,199 --> 00:07:29,039
and how identity and xero trust work

198
00:07:29,039 --> 00:07:31,039
together well

199
00:07:31,039 --> 00:07:32,319
it's been really interesting the last

200
00:07:32,319 --> 00:07:34,000
year and a half that um i've had an

201
00:07:34,000 --> 00:07:36,400
opportunity to work with john because

202
00:07:36,400 --> 00:07:38,800
the the id the identity solutions

203
00:07:38,800 --> 00:07:42,720
identity uh practice space of security

204
00:07:42,720 --> 00:07:45,280
um has had tremendous amounts of

205
00:07:45,280 --> 00:07:46,720
challenges

206
00:07:46,720 --> 00:07:48,319
in workforce and customer access

207
00:07:48,319 --> 00:07:49,599
management

208
00:07:49,599 --> 00:07:51,360
and and the reason that we've had

209
00:07:51,360 --> 00:07:53,120
tremendous amounts of challenges is

210
00:07:53,120 --> 00:07:56,160
because we really have had a difficult

211
00:07:56,160 --> 00:07:58,720
time defining identities within our

212
00:07:58,720 --> 00:08:00,319
systems our networks our processes our

213
00:08:00,319 --> 00:08:03,440
transactions you know organizations

214
00:08:03,440 --> 00:08:04,639
literally have

215
00:08:04,639 --> 00:08:06,879
you know maybe 10 percent of their

216
00:08:06,879 --> 00:08:09,440
identities known within their uh

217
00:08:09,440 --> 00:08:12,479
organizations and 90 percent are unknown

218
00:08:12,479 --> 00:08:14,319
you've got developers that are creating

219
00:08:14,319 --> 00:08:16,800
you know accounts and passwords you know

220
00:08:16,800 --> 00:08:18,319
you have other developers that are

221
00:08:18,319 --> 00:08:19,919
creating accounts and passwords and

222
00:08:19,919 --> 00:08:22,160
entitlements and attributes um and so

223
00:08:22,160 --> 00:08:24,000
it's a little bit uh you know of the

224
00:08:24,000 --> 00:08:26,960
wild west and when i met john um and we

225
00:08:26,960 --> 00:08:28,720
started talking about you know identity

226
00:08:28,720 --> 00:08:30,800
and zero trust in this rightful role

227
00:08:30,800 --> 00:08:33,200
this idea that identity is information

228
00:08:33,200 --> 00:08:35,120
that is consumed within the zero trust

229
00:08:35,120 --> 00:08:37,360
network and it was a really it was a

230
00:08:37,360 --> 00:08:41,200
eureka moment for me um because i'm i do

231
00:08:41,200 --> 00:08:43,279
a lot in identity i'm fairly well known

232
00:08:43,279 --> 00:08:45,360
in that space and i looked at john and

233
00:08:45,360 --> 00:08:47,040
said i struggle with where identity fits

234
00:08:47,040 --> 00:08:48,560
within xero trust

235
00:08:48,560 --> 00:08:50,160
and he looked at me and he said zero

236
00:08:50,160 --> 00:08:52,000
trust consumes identity and at that

237
00:08:52,000 --> 00:08:54,480
point it began to spawn a number of

238
00:08:54,480 --> 00:08:56,160
conversations with the and within the

239
00:08:56,160 --> 00:08:58,720
identity uh solutions and identity uh

240
00:08:58,720 --> 00:09:00,880
practitioners community around

241
00:09:00,880 --> 00:09:03,519
well if you really do understand the

242
00:09:03,519 --> 00:09:05,760
identity of a thing

243
00:09:05,760 --> 00:09:07,920
um you know whether it is a human being

244
00:09:07,920 --> 00:09:10,399
or it is a device whatever the case

245
00:09:10,399 --> 00:09:13,440
might be um you can begin to manage it

246
00:09:13,440 --> 00:09:15,360
and it really falls in line with the uh

247
00:09:15,360 --> 00:09:16,720
the principles that are on the slide

248
00:09:16,720 --> 00:09:18,640
that in front of everybody right think

249
00:09:18,640 --> 00:09:21,040
about that 90 of identities that are

250
00:09:21,040 --> 00:09:22,800
undefined in almost everybody's

251
00:09:22,800 --> 00:09:24,399
organization here

252
00:09:24,399 --> 00:09:27,600
that is a infinite attack surface right

253
00:09:27,600 --> 00:09:28,560
it is

254
00:09:28,560 --> 00:09:30,720
you don't have any guardrails around it

255
00:09:30,720 --> 00:09:32,959
by understanding those identities and

256
00:09:32,959 --> 00:09:36,320
and beginning to whittle them down you

257
00:09:36,320 --> 00:09:38,800
begin to put controls around that attack

258
00:09:38,800 --> 00:09:41,200
surface and it becomes a protect surface

259
00:09:41,200 --> 00:09:43,279
and i think when we start to think about

260
00:09:43,279 --> 00:09:46,000
identity in security terms which has

261
00:09:46,000 --> 00:09:47,360
been the biggest struggle for the last

262
00:09:47,360 --> 00:09:49,839
30 years within within the corporate

263
00:09:49,839 --> 00:09:50,640
world

264
00:09:50,640 --> 00:09:52,560
because we love to talk about identity

265
00:09:52,560 --> 00:09:54,640
in an access administration function but

266
00:09:54,640 --> 00:09:56,320
when we start to talk about it in true

267
00:09:56,320 --> 00:09:58,240
security terms thinking about attack

268
00:09:58,240 --> 00:09:59,360
vectors

269
00:09:59,360 --> 00:10:01,200
thinking about um you know the

270
00:10:01,200 --> 00:10:03,279
weaknesses that are inherent within

271
00:10:03,279 --> 00:10:05,279
unknown identities and entities how

272
00:10:05,279 --> 00:10:07,600
we've ascribed you know these identities

273
00:10:07,600 --> 00:10:10,800
to machines devices processes

274
00:10:10,800 --> 00:10:13,600
flows when we start to rethink that from

275
00:10:13,600 --> 00:10:16,079
perspective of a zero trust framework

276
00:10:16,079 --> 00:10:17,680
identity starts to make a whole lot of

277
00:10:17,680 --> 00:10:18,480
sense

278
00:10:18,480 --> 00:10:20,320
uh in terms of where you need to focus

279
00:10:20,320 --> 00:10:21,920
attention to reduce risk within your

280
00:10:21,920 --> 00:10:23,519
organization

281
00:10:23,519 --> 00:10:25,200
yeah any element

282
00:10:25,200 --> 00:10:27,360
in a digital environment can have an

283
00:10:27,360 --> 00:10:30,000
identity and that's what

284
00:10:30,000 --> 00:10:31,920
some people call the identity don't want

285
00:10:31,920 --> 00:10:34,240
to believe right they only people can

286
00:10:34,240 --> 00:10:35,839
have identities well there's no people

287
00:10:35,839 --> 00:10:37,600
on networks right

288
00:10:37,600 --> 00:10:40,720
it's an asserted identity right so

289
00:10:40,720 --> 00:10:42,800
people aren't packets only packets are

290
00:10:42,800 --> 00:10:44,880
on networks and so you can give any

291
00:10:44,880 --> 00:10:47,279
packet an identity and

292
00:10:47,279 --> 00:10:48,800
that's going to be

293
00:10:48,800 --> 00:10:50,800
the exciting thing of working in

294
00:10:50,800 --> 00:10:53,440
something like ics because

295
00:10:53,440 --> 00:10:54,880
things that you didn't think could have

296
00:10:54,880 --> 00:10:56,079
identities

297
00:10:56,079 --> 00:10:56,959
only

298
00:10:56,959 --> 00:10:59,120
couldn't because you limited yourself to

299
00:10:59,120 --> 00:11:02,160
this human analog model and not the

300
00:11:02,160 --> 00:11:03,920
digital world that we're actually living

301
00:11:03,920 --> 00:11:05,839
in when i tony if i could jump on that

302
00:11:05,839 --> 00:11:07,680
real quick because i think that it's

303
00:11:07,680 --> 00:11:09,600
really important when i when i start to

304
00:11:09,600 --> 00:11:11,200
have conversations about identity and

305
00:11:11,200 --> 00:11:12,800
its relationship within zero trust

306
00:11:12,800 --> 00:11:14,399
especially with audiences like

307
00:11:14,399 --> 00:11:16,560
like we have today um this whole notion

308
00:11:16,560 --> 00:11:18,640
of identity description is

309
00:11:18,640 --> 00:11:21,200
is new it's it's uh it's a challenge

310
00:11:21,200 --> 00:11:22,399
sometimes for people to get a hold of

311
00:11:22,399 --> 00:11:23,680
and it's because

312
00:11:23,680 --> 00:11:26,560
we we talk about identities

313
00:11:26,560 --> 00:11:29,200
in the digital world as if they were

314
00:11:29,200 --> 00:11:32,320
the people right and in reality you know

315
00:11:32,320 --> 00:11:34,160
account assignments identifiers unique

316
00:11:34,160 --> 00:11:36,640
identifiers anything that we ascribe

317
00:11:36,640 --> 00:11:38,959
uh or we use to ascribe an identity is

318
00:11:38,959 --> 00:11:40,880
simply a proxy

319
00:11:40,880 --> 00:11:42,959
for an actor

320
00:11:42,959 --> 00:11:45,120
of some type within your systems that

321
00:11:45,120 --> 00:11:47,120
actor might be human right that actor

322
00:11:47,120 --> 00:11:49,279
might be you know robotics that actor

323
00:11:49,279 --> 00:11:51,600
might be you know a device but identity

324
00:11:51,600 --> 00:11:53,600
description is a real thing and i want

325
00:11:53,600 --> 00:11:55,920
people to understand how easy it is to

326
00:11:55,920 --> 00:11:57,760
make this logical leap and understand

327
00:11:57,760 --> 00:11:59,680
how identity description works

328
00:11:59,680 --> 00:12:00,959
we've been doing it for thousands of

329
00:12:00,959 --> 00:12:02,959
years right show of hands in the

330
00:12:02,959 --> 00:12:06,079
audience how many of you have a dog

331
00:12:06,079 --> 00:12:07,279
okay cool

332
00:12:07,279 --> 00:12:09,920
how many of you have a dog with a dog

333
00:12:09,920 --> 00:12:11,200
name now that's a rhetorical question

334
00:12:11,200 --> 00:12:12,240
because no one's going to raise their

335
00:12:12,240 --> 00:12:14,320
hand because the the question i really

336
00:12:14,320 --> 00:12:15,600
want to ask is how many of you have a

337
00:12:15,600 --> 00:12:18,959
dog with a human name

338
00:12:18,959 --> 00:12:20,800
see a lot of hands

339
00:12:20,800 --> 00:12:22,800
why do we ascribe a human identity to

340
00:12:22,800 --> 00:12:25,519
dogs right this is actually a very

341
00:12:25,519 --> 00:12:28,320
important part of human civilization we

342
00:12:28,320 --> 00:12:31,440
we have to make complex constructs

343
00:12:31,440 --> 00:12:34,240
simple through abstraction and identity

344
00:12:34,240 --> 00:12:36,720
description is exactly that type of

345
00:12:36,720 --> 00:12:38,399
abstraction that humans understand

346
00:12:38,399 --> 00:12:40,560
intuitively and applying that intuitive

347
00:12:40,560 --> 00:12:42,079
understanding of identity description

348
00:12:42,079 --> 00:12:45,200
within your systems makes the idea of

349
00:12:45,200 --> 00:12:46,720
using identity within a zero trust

350
00:12:46,720 --> 00:12:48,720
framework a lot more palatable and

351
00:12:48,720 --> 00:12:51,279
actually a lot easier to execute

352
00:12:51,279 --> 00:12:53,120
so you talked about this coming in the

353
00:12:53,120 --> 00:12:54,720
future how far away are we from being

354
00:12:54,720 --> 00:12:57,519
able to do those types of things

355
00:12:57,519 --> 00:12:59,200
well from an identity description

356
00:12:59,200 --> 00:13:01,040
standpoint we are there right it

357
00:13:01,040 --> 00:13:03,040
actually is very much like xero trust in

358
00:13:03,040 --> 00:13:06,240
that it requires a different type of

359
00:13:06,240 --> 00:13:09,279
thinking and pulling yourself out of you

360
00:13:09,279 --> 00:13:10,160
know

361
00:13:10,160 --> 00:13:12,320
layered models pulling yourself out of

362
00:13:12,320 --> 00:13:14,480
defense in depth pulling yourself out of

363
00:13:14,480 --> 00:13:16,079
you know any number of frameworks that

364
00:13:16,079 --> 00:13:18,079
we want to talk about um that have come

365
00:13:18,079 --> 00:13:20,560
and gone or persisted right and when you

366
00:13:20,560 --> 00:13:22,399
look at the technology and tools that

367
00:13:22,399 --> 00:13:24,160
are available today

368
00:13:24,160 --> 00:13:28,000
being able to define a set of you know

369
00:13:28,000 --> 00:13:30,399
actors as a population and ascribe

370
00:13:30,399 --> 00:13:31,920
identity to identity to them is

371
00:13:31,920 --> 00:13:33,120
achievable

372
00:13:33,120 --> 00:13:34,720
i actually left the more traditional

373
00:13:34,720 --> 00:13:37,120
workforce and customer access management

374
00:13:37,120 --> 00:13:38,399
identity space

375
00:13:38,399 --> 00:13:40,720
just within the past year specifically

376
00:13:40,720 --> 00:13:43,600
to go focus on this problem and so the

377
00:13:43,600 --> 00:13:45,760
tech is here the capabilities are here

378
00:13:45,760 --> 00:13:47,519
the only impediment to actually

379
00:13:47,519 --> 00:13:50,320
deploying those technologies and in my

380
00:13:50,320 --> 00:13:52,240
case i'm working with you know upwards

381
00:13:52,240 --> 00:13:54,240
of about four dozen different customers

382
00:13:54,240 --> 00:13:55,199
on this

383
00:13:55,199 --> 00:13:57,040
across all different industry segments

384
00:13:57,040 --> 00:13:59,199
the only impediment is thinking

385
00:13:59,199 --> 00:14:01,519
differently about your architecture from

386
00:14:01,519 --> 00:14:03,920
a security standpoint and incorporating

387
00:14:03,920 --> 00:14:06,880
identity into uh that equation within a

388
00:14:06,880 --> 00:14:09,760
zero trust framework

389
00:14:10,320 --> 00:14:11,839
just to pivot a little bit i mean just

390
00:14:11,839 --> 00:14:13,120
knowing the community we have here we

391
00:14:13,120 --> 00:14:15,680
talk about ics we talk about ot and john

392
00:14:15,680 --> 00:14:17,040
a while back you know you wrote an

393
00:14:17,040 --> 00:14:18,399
article about

394
00:14:18,399 --> 00:14:20,320
you know zero trust and six two four

395
00:14:20,320 --> 00:14:22,959
four three you know those principles um

396
00:14:22,959 --> 00:14:24,560
i would you mind just elaborating a

397
00:14:24,560 --> 00:14:26,079
little bit on what you saw when you

398
00:14:26,079 --> 00:14:28,480
started to look at both of those and

399
00:14:28,480 --> 00:14:31,199
started to compare and contrast them

400
00:14:31,199 --> 00:14:32,320
well

401
00:14:32,320 --> 00:14:34,240
when i was working at palo alto networks

402
00:14:34,240 --> 00:14:36,480
we were all we were mapping

403
00:14:36,480 --> 00:14:38,800
purdue model to zero trust to help

404
00:14:38,800 --> 00:14:40,639
people understand that but of course

405
00:14:40,639 --> 00:14:43,440
purdue model was created in the 80s

406
00:14:43,440 --> 00:14:45,760
before we had any of this technology and

407
00:14:45,760 --> 00:14:47,360
now we've got six two four four three

408
00:14:47,360 --> 00:14:50,000
and i was working with uh actually

409
00:14:50,000 --> 00:14:52,959
accenture the uh i don't know not not

410
00:14:52,959 --> 00:14:55,199
the guy who was on stage but accenture

411
00:14:55,199 --> 00:14:58,000
on this report because we could map six

412
00:14:58,000 --> 00:14:59,680
two four four three two zero trust so

413
00:14:59,680 --> 00:15:02,079
for example a kipling method policy

414
00:15:02,079 --> 00:15:04,079
which is a concept in zero trust who

415
00:15:04,079 --> 00:15:06,320
what when where why and how right retro

416
00:15:06,320 --> 00:15:07,920
kipling gave us that idea in a poem in

417
00:15:07,920 --> 00:15:11,120
1902 who should have access via what

418
00:15:11,120 --> 00:15:13,680
application to wear a particular

419
00:15:13,680 --> 00:15:16,160
resource via what criteria how

420
00:15:16,160 --> 00:15:18,240
that defines a conduit in six two four

421
00:15:18,240 --> 00:15:20,959
four three for example right and so

422
00:15:20,959 --> 00:15:22,880
while there's a lot of process stuff

423
00:15:22,880 --> 00:15:25,199
around uh six two four four three and

424
00:15:25,199 --> 00:15:27,600
this in the security stuff it fits

425
00:15:27,600 --> 00:15:30,160
actually very perfectly and that's what

426
00:15:30,160 --> 00:15:32,160
we all kind of went wow that that that

427
00:15:32,160 --> 00:15:33,519
worked out

428
00:15:33,519 --> 00:15:36,399
well serendipitously because we're

429
00:15:36,399 --> 00:15:38,160
calling we're kind of all understanding

430
00:15:38,160 --> 00:15:40,079
the same problem this is all about very

431
00:15:40,079 --> 00:15:44,320
granular policy allowing only specific

432
00:15:44,320 --> 00:15:46,959
users to access a specific resource at a

433
00:15:46,959 --> 00:15:49,199
specific time over a specific

434
00:15:49,199 --> 00:15:51,759
application for a specific reason right

435
00:15:51,759 --> 00:15:53,440
instead of allowing everybody and

436
00:15:53,440 --> 00:15:55,519
playing whack-a-mole and trying to drop

437
00:15:55,519 --> 00:15:57,600
you know stop the bad stuff just let the

438
00:15:57,600 --> 00:15:59,040
good stuff in

439
00:15:59,040 --> 00:16:02,399
and so i tell people all the time if

440
00:16:02,399 --> 00:16:04,240
something bad happens in your

441
00:16:04,240 --> 00:16:06,079
environment you have a rule that allowed

442
00:16:06,079 --> 00:16:06,959
it

443
00:16:06,959 --> 00:16:09,040
right all bad things happen in the allow

444
00:16:09,040 --> 00:16:11,440
rule and i see socks spending a lot of

445
00:16:11,440 --> 00:16:13,120
time trying to figure out oh we we

446
00:16:13,120 --> 00:16:15,360
denied something let's investigate that

447
00:16:15,360 --> 00:16:17,279
no just give yourself a high five you

448
00:16:17,279 --> 00:16:19,680
stop some bad stuff and start looking at

449
00:16:19,680 --> 00:16:21,440
what what's happening inside the allow

450
00:16:21,440 --> 00:16:23,199
rule because when we look at this

451
00:16:23,199 --> 00:16:25,279
like this uh data breach that where they

452
00:16:25,279 --> 00:16:26,959
were in there for nine months that came

453
00:16:26,959 --> 00:16:28,959
out a couple of weeks ago there was a

454
00:16:28,959 --> 00:16:30,880
bunch of policies in place that allowed

455
00:16:30,880 --> 00:16:33,199
those attackers to go in and out all the

456
00:16:33,199 --> 00:16:35,600
time and nobody looking right and you

457
00:16:35,600 --> 00:16:37,519
don't do that in real life right when

458
00:16:37,519 --> 00:16:38,720
when

459
00:16:38,720 --> 00:16:41,600
this man makes really cool tiki drinks

460
00:16:41,600 --> 00:16:44,800
and if he has a tiki party uh at his

461
00:16:44,800 --> 00:16:47,120
home bar and there's some guy sitting

462
00:16:47,120 --> 00:16:49,440
there that he doesn't know he doesn't go

463
00:16:49,440 --> 00:16:50,399
oh

464
00:16:50,399 --> 00:16:52,160
well i guess since he's able to come in

465
00:16:52,160 --> 00:16:54,240
here and sit at my bar he belongs here

466
00:16:54,240 --> 00:16:56,560
hey honey can you make up the guest room

467
00:16:56,560 --> 00:16:57,839
he's like what the heck are you doing

468
00:16:57,839 --> 00:16:59,600
here only a few people get to come in

469
00:16:59,600 --> 00:17:02,079
and have tiki drinks with richard byrd

470
00:17:02,079 --> 00:17:03,839
i'm not one of them yet right i need to

471
00:17:03,839 --> 00:17:06,720
we need to adopt a new policy but still

472
00:17:06,720 --> 00:17:08,959
that's how we do it in real life but in

473
00:17:08,959 --> 00:17:09,839
in

474
00:17:09,839 --> 00:17:13,039
in in in our technological world we're

475
00:17:13,039 --> 00:17:14,880
willing to let a lot of bad traffic come

476
00:17:14,880 --> 00:17:16,959
in because we're so fearful of stopping

477
00:17:16,959 --> 00:17:19,359
that one good thing and we need to

478
00:17:19,359 --> 00:17:22,559
change that particular paradigm

479
00:17:22,559 --> 00:17:23,599
and i think there's really awkward

480
00:17:23,599 --> 00:17:24,880
there's really a big opportunity there

481
00:17:24,880 --> 00:17:26,480
for us um

482
00:17:26,480 --> 00:17:27,919
when you look at those similarities look

483
00:17:27,919 --> 00:17:29,440
at the common concepts and core

484
00:17:29,440 --> 00:17:31,360
principles that really

485
00:17:31,360 --> 00:17:33,120
again complement one another

486
00:17:33,120 --> 00:17:34,720
it's an opportunity for us to i guess in

487
00:17:34,720 --> 00:17:36,720
this community to help embrace that hype

488
00:17:36,720 --> 00:17:38,799
if you will right i mean zero trust is a

489
00:17:38,799 --> 00:17:40,320
strategy is a term

490
00:17:40,320 --> 00:17:42,799
um is a is a hot topic right now with

491
00:17:42,799 --> 00:17:44,480
executives we're seeing a lot of csos a

492
00:17:44,480 --> 00:17:46,320
lot of companies they're they're being

493
00:17:46,320 --> 00:17:48,000
asked by their board of directors and

494
00:17:48,000 --> 00:17:49,520
whatnot you know what is our zero trust

495
00:17:49,520 --> 00:17:50,559
strategy

496
00:17:50,559 --> 00:17:52,320
how are we going to get there

497
00:17:52,320 --> 00:17:54,000
and i think from from our community

498
00:17:54,000 --> 00:17:55,200
perspective this is an opportunity to

499
00:17:55,200 --> 00:17:57,760
not maybe resist you know that that's

500
00:17:57,760 --> 00:17:59,360
not necessarily invented here type thing

501
00:17:59,360 --> 00:18:01,120
but that

502
00:18:01,120 --> 00:18:03,760
uh personifies or represents a lot of

503
00:18:03,760 --> 00:18:04,880
the things that we've been trying to

504
00:18:04,880 --> 00:18:07,280
accomplish and it's it's a way for us to

505
00:18:07,280 --> 00:18:09,760
to gain momentum align and bring those

506
00:18:09,760 --> 00:18:11,120
concepts to bear as part of that

507
00:18:11,120 --> 00:18:13,200
holistic strategy and we can make your

508
00:18:13,200 --> 00:18:16,080
job easier and you're not going to get

509
00:18:16,080 --> 00:18:19,360
a choice anymore right so

510
00:18:19,360 --> 00:18:20,880
uh people will say to me you can't do

511
00:18:20,880 --> 00:18:22,799
zero trust for ot well why can't i why

512
00:18:22,799 --> 00:18:25,919
can't i apply this strategy to this this

513
00:18:25,919 --> 00:18:27,919
technological problem

514
00:18:27,919 --> 00:18:29,760
well because that's not the way we've

515
00:18:29,760 --> 00:18:31,679
always done it but things are changing

516
00:18:31,679 --> 00:18:34,640
you have you have executives

517
00:18:34,640 --> 00:18:36,640
changing the incentive structure and now

518
00:18:36,640 --> 00:18:38,960
you have legal

519
00:18:38,960 --> 00:18:40,400
environments changing the incentive

520
00:18:40,400 --> 00:18:42,080
structure so there was a hospital in new

521
00:18:42,080 --> 00:18:44,160
jersey that did a whole bunch of bad

522
00:18:44,160 --> 00:18:45,919
things and

523
00:18:45,919 --> 00:18:48,400
health ins or no the state of new jersey

524
00:18:48,400 --> 00:18:50,960
issued a consent decree and part of the

525
00:18:50,960 --> 00:18:53,280
consent decree says that you must build

526
00:18:53,280 --> 00:18:55,280
a zero trust environment and listed some

527
00:18:55,280 --> 00:18:57,600
of the specifics that they must do now

528
00:18:57,600 --> 00:18:59,520
that has never happened

529
00:18:59,520 --> 00:19:00,400
uh

530
00:19:00,400 --> 00:19:01,919
you know

531
00:19:01,919 --> 00:19:04,400
in my knowledge yet i mean you know but

532
00:19:04,400 --> 00:19:06,880
a lawyer sent it to me look at this

533
00:19:06,880 --> 00:19:08,400
there is a legal

534
00:19:08,400 --> 00:19:10,799
uh consent decree a legal document that

535
00:19:10,799 --> 00:19:13,600
says they have to do this and so this is

536
00:19:13,600 --> 00:19:16,559
a this is a movement that is way bigger

537
00:19:16,559 --> 00:19:18,960
than i ever thought it would be for sure

538
00:19:18,960 --> 00:19:20,080
but

539
00:19:20,080 --> 00:19:21,760
jump on board and we'll make your life

540
00:19:21,760 --> 00:19:23,679
easier man

541
00:19:23,679 --> 00:19:24,880
ride the waves

542
00:19:24,880 --> 00:19:27,600
well and i think that for this audience

543
00:19:27,600 --> 00:19:30,080
so i i spent a large part of my working

544
00:19:30,080 --> 00:19:32,720
career in the corporate world nearly 24

545
00:19:32,720 --> 00:19:35,200
years and about 16 or 17 those years i

546
00:19:35,200 --> 00:19:37,440
spent in banking and financial services

547
00:19:37,440 --> 00:19:38,799
however when i became a chief

548
00:19:38,799 --> 00:19:40,960
information security officer i became a

549
00:19:40,960 --> 00:19:42,400
chief information security officer in

550
00:19:42,400 --> 00:19:44,240
high-tech manufacturing

551
00:19:44,240 --> 00:19:45,280
and

552
00:19:45,280 --> 00:19:47,520
um i i want to share a brief story i

553
00:19:47,520 --> 00:19:49,280
you know you guys have great stories i

554
00:19:49,280 --> 00:19:51,520
know it and i only have a few

555
00:19:51,520 --> 00:19:53,200
for my days working

556
00:19:53,200 --> 00:19:56,160
in in high-tech analytical devices

557
00:19:56,160 --> 00:19:58,000
but one that stands out in particular as

558
00:19:58,000 --> 00:20:00,400
an example of how xero trusts could

559
00:20:00,400 --> 00:20:02,000
really benefit

560
00:20:02,000 --> 00:20:04,320
this room full of people

561
00:20:04,320 --> 00:20:06,880
specifically because

562
00:20:06,880 --> 00:20:08,400
i had a situation here in florida

563
00:20:08,400 --> 00:20:10,240
actually where i had a cnc water jet

564
00:20:10,240 --> 00:20:12,480
machine um that every couple of months

565
00:20:12,480 --> 00:20:14,240
would all the sudden with windows

566
00:20:14,240 --> 00:20:16,640
embedded xp unfortunately um all of a

567
00:20:16,640 --> 00:20:18,559
sudden start throwing bad email traffic

568
00:20:18,559 --> 00:20:19,919
right and that was getting us

569
00:20:19,919 --> 00:20:22,159
blacklisted on our domain

570
00:20:22,159 --> 00:20:23,919
um and it was a swiss company and the

571
00:20:23,919 --> 00:20:26,000
swiss were not really happy about that

572
00:20:26,000 --> 00:20:27,200
situation

573
00:20:27,200 --> 00:20:29,120
so we came down and actually did an

574
00:20:29,120 --> 00:20:30,880
on-site forensic and we just couldn't

575
00:20:30,880 --> 00:20:32,080
figure it out

576
00:20:32,080 --> 00:20:35,200
why is this device somehow becoming you

577
00:20:35,200 --> 00:20:38,960
know a deliverer of of bad emails where

578
00:20:38,960 --> 00:20:40,480
is this happening

579
00:20:40,480 --> 00:20:42,559
so we checked every possibility in the

580
00:20:42,559 --> 00:20:44,400
network we checked every possibility

581
00:20:44,400 --> 00:20:46,320
within our own systems still couldn't

582
00:20:46,320 --> 00:20:47,760
find it until one day we were standing

583
00:20:47,760 --> 00:20:49,840
on the floor in this on-site forensic

584
00:20:49,840 --> 00:20:53,280
and uh the gentleman that operated that

585
00:20:53,280 --> 00:20:54,720
cnc machine

586
00:20:54,720 --> 00:20:57,280
lifted a thumb drive up off of the desk

587
00:20:57,280 --> 00:20:58,640
where he had been

588
00:20:58,640 --> 00:21:00,080
taken care of loading the next set of

589
00:21:00,080 --> 00:21:02,240
plans and walked over plucked it in the

590
00:21:02,240 --> 00:21:03,760
cnc machine and all of a sudden it

591
00:21:03,760 --> 00:21:05,919
dawned on us to ask him where that thumb

592
00:21:05,919 --> 00:21:07,679
drive came from

593
00:21:07,679 --> 00:21:10,400
and it came from his third grader

594
00:21:10,400 --> 00:21:13,039
and it was infested

595
00:21:13,039 --> 00:21:15,919
and every time he would go to change

596
00:21:15,919 --> 00:21:18,799
those plans every few weeks then all of

597
00:21:18,799 --> 00:21:20,159
a sudden we would have the situation now

598
00:21:20,159 --> 00:21:21,440
think about this for just a second in

599
00:21:21,440 --> 00:21:24,320
the concept of zero trust if i ascribed

600
00:21:24,320 --> 00:21:26,640
an identity to that device one of the

601
00:21:26,640 --> 00:21:28,000
problems that we have an identity is we

602
00:21:28,000 --> 00:21:29,440
don't answer that important question

603
00:21:29,440 --> 00:21:31,679
within the kipling method which is why

604
00:21:31,679 --> 00:21:33,360
why should this device have access why

605
00:21:33,360 --> 00:21:36,640
should the cnc machine have the ability

606
00:21:36,640 --> 00:21:38,159
to have an attribute or an entitlement

607
00:21:38,159 --> 00:21:40,000
that allows it to send email the answer

608
00:21:40,000 --> 00:21:42,000
is it should not

609
00:21:42,000 --> 00:21:44,000
but we're not managing it in a way that

610
00:21:44,000 --> 00:21:47,200
allows us to both control and monitor

611
00:21:47,200 --> 00:21:48,720
activities

612
00:21:48,720 --> 00:21:50,640
that that device is doing that it should

613
00:21:50,640 --> 00:21:52,159
not be doing and this is the point that

614
00:21:52,159 --> 00:21:54,480
i'll leave you with on on how valuable

615
00:21:54,480 --> 00:21:56,480
as well as you know how quickly you can

616
00:21:56,480 --> 00:21:57,760
adopt zero stress within your

617
00:21:57,760 --> 00:22:00,000
organizations when we look at the ot the

618
00:22:00,000 --> 00:22:02,799
iot the rpa space

619
00:22:02,799 --> 00:22:04,480
everything that's built in that space is

620
00:22:04,480 --> 00:22:06,240
built for a purpose

621
00:22:06,240 --> 00:22:07,760
it has a reason

622
00:22:07,760 --> 00:22:10,720
humans are infinitely variable

623
00:22:10,720 --> 00:22:13,679
devices and the things that we build are

624
00:22:13,679 --> 00:22:16,480
meant to be used for a specific purpose

625
00:22:16,480 --> 00:22:18,880
so when that goes out of band and starts

626
00:22:18,880 --> 00:22:20,880
throwing bad email

627
00:22:20,880 --> 00:22:23,280
we know that something has gone wrong

628
00:22:23,280 --> 00:22:26,000
within rules and policies because that's

629
00:22:26,000 --> 00:22:28,640
not what it's intended to do

630
00:22:28,640 --> 00:22:31,679
so we can isolate in your communities

631
00:22:31,679 --> 00:22:34,480
and your companies and in your endeavors

632
00:22:34,480 --> 00:22:36,240
down to the why should this thing have

633
00:22:36,240 --> 00:22:38,159
access give it the entitlements and

634
00:22:38,159 --> 00:22:39,679
grants that are associated to the

635
00:22:39,679 --> 00:22:42,159
identity and drive improvements in your

636
00:22:42,159 --> 00:22:43,919
organization while reducing risk by an

637
00:22:43,919 --> 00:22:46,240
exponential factor and let's take this

638
00:22:46,240 --> 00:22:48,720
example of how we could build a zero

639
00:22:48,720 --> 00:22:50,880
trust environment around it because this

640
00:22:50,880 --> 00:22:52,840
waterjet cnc

641
00:22:52,840 --> 00:22:55,200
machine and its system becomes the

642
00:22:55,200 --> 00:22:57,360
protect surface right so even if

643
00:22:57,360 --> 00:23:00,000
somebody does plug in the the malware

644
00:23:00,000 --> 00:23:02,559
drive and it starts sending email there

645
00:23:02,559 --> 00:23:05,039
is there is some technology in front of

646
00:23:05,039 --> 00:23:06,080
that

647
00:23:06,080 --> 00:23:08,080
that says oh you're not supposed to be

648
00:23:08,080 --> 00:23:09,919
allowed to send email i'm going to stop

649
00:23:09,919 --> 00:23:12,400
that and alert that is happening and

650
00:23:12,400 --> 00:23:14,320
i'll give you some insight into what's

651
00:23:14,320 --> 00:23:16,159
happening but

652
00:23:16,159 --> 00:23:18,400
it would never get the email out because

653
00:23:18,400 --> 00:23:21,200
we've reduced the blast radius you see

654
00:23:21,200 --> 00:23:22,159
so

655
00:23:22,159 --> 00:23:24,400
things might be able to get in but they

656
00:23:24,400 --> 00:23:27,039
can't get out so if you take ransomware

657
00:23:27,039 --> 00:23:30,480
for example ransomware means that for at

658
00:23:30,480 --> 00:23:32,400
least three times you've allowed

659
00:23:32,400 --> 00:23:34,159
malicious actor to come in and out of

660
00:23:34,159 --> 00:23:36,240
your environment to first drop the

661
00:23:36,240 --> 00:23:39,039
malware then second set up the cnc

662
00:23:39,039 --> 00:23:42,000
control and third do the symmetric key

663
00:23:42,000 --> 00:23:44,159
exchange and probably a fourth step

664
00:23:44,159 --> 00:23:46,000
where they exfiltrated the data before

665
00:23:46,000 --> 00:23:48,240
they encrypted it uh and you just

666
00:23:48,240 --> 00:23:50,159
allowed that to happen and then you go

667
00:23:50,159 --> 00:23:52,799
whoa look at our machines encrypted well

668
00:23:52,799 --> 00:23:55,600
if you would we're monitoring that like

669
00:23:55,600 --> 00:23:56,400
the

670
00:23:56,400 --> 00:23:59,440
the the step of monitor and maintain and

671
00:23:59,440 --> 00:24:02,240
you had a policy that said uh

672
00:24:02,240 --> 00:24:04,159
you know only these things can come in

673
00:24:04,159 --> 00:24:07,760
and out and so suddenly a a a piece of

674
00:24:07,760 --> 00:24:10,640
software that is unknown tries to make a

675
00:24:10,640 --> 00:24:14,240
call to a server in the ukraine that is

676
00:24:14,240 --> 00:24:16,720
unknown well an unknown thing can't talk

677
00:24:16,720 --> 00:24:19,200
to an unknown thing by default and you

678
00:24:19,200 --> 00:24:21,120
would stop it and be alerted and you

679
00:24:21,120 --> 00:24:23,360
wouldn't have any damage to your system

680
00:24:23,360 --> 00:24:24,159
but

681
00:24:24,159 --> 00:24:25,840
we have a lot i talk to people all the

682
00:24:25,840 --> 00:24:27,919
time do you have any unknown traffic on

683
00:24:27,919 --> 00:24:30,400
your network oh yeah we have a lot of it

684
00:24:30,400 --> 00:24:32,640
well in xero trust you should have zero

685
00:24:32,640 --> 00:24:35,200
unknown traffic right traffic should

686
00:24:35,200 --> 00:24:38,080
have identities to it as well right so

687
00:24:38,080 --> 00:24:41,360
cnc machine is easy cn machine cnc

688
00:24:41,360 --> 00:24:44,559
machine one cnc machine two they're each

689
00:24:44,559 --> 00:24:46,480
a protect surface or maybe you aggregate

690
00:24:46,480 --> 00:24:49,520
them right and then you have the cmc

691
00:24:49,520 --> 00:24:52,799
machine is controlled by a plc right and

692
00:24:52,799 --> 00:24:56,720
the plc has attributes and so it has an

693
00:24:56,720 --> 00:25:00,159
application that it uses and so we can

694
00:25:00,159 --> 00:25:02,000
know only that application should talk

695
00:25:02,000 --> 00:25:04,880
to that plc and so now we've reduced

696
00:25:04,880 --> 00:25:07,679
this problem down to a very small

697
00:25:07,679 --> 00:25:12,159
set so the policy gets reduced 10 to

698
00:25:12,159 --> 00:25:14,720
7 to 10 times so now it's a very small

699
00:25:14,720 --> 00:25:17,600
policy set that we can actually uh audit

700
00:25:17,600 --> 00:25:19,600
and make sure that we know exactly

701
00:25:19,600 --> 00:25:21,600
what's going on and so when auditors

702
00:25:21,600 --> 00:25:24,320
come in to audit that which happens in

703
00:25:24,320 --> 00:25:26,000
these kinds of environments all the time

704
00:25:26,000 --> 00:25:27,600
they go oh yeah i see what you're doing

705
00:25:27,600 --> 00:25:28,640
great

706
00:25:28,640 --> 00:25:29,679
excellent

707
00:25:29,679 --> 00:25:32,320
uh go forth and prosper

708
00:25:32,320 --> 00:25:34,559
i think a big part of it is you talked

709
00:25:34,559 --> 00:25:36,000
about the blast radius but we also

710
00:25:36,000 --> 00:25:37,760
earlier mentioned an end stack the

711
00:25:37,760 --> 00:25:40,000
maturity model and and you don't you

712
00:25:40,000 --> 00:25:41,600
don't have to get to that point and

713
00:25:41,600 --> 00:25:43,279
oftentimes we hear about well zero trust

714
00:25:43,279 --> 00:25:44,240
you know the first question that comes

715
00:25:44,240 --> 00:25:45,760
to mind is you know where do i put the

716
00:25:45,760 --> 00:25:48,799
pki and i so going back to the maturity

717
00:25:48,799 --> 00:25:50,720
model and what you talked about it's

718
00:25:50,720 --> 00:25:52,320
your blast radius

719
00:25:52,320 --> 00:25:54,640
improves over time right like you don't

720
00:25:54,640 --> 00:25:56,320
have to have it all perfect you don't

721
00:25:56,320 --> 00:25:57,840
have to rip and replace all your devices

722
00:25:57,840 --> 00:25:59,520
with and replace them with ones that

723
00:25:59,520 --> 00:26:02,240
support identity right it's it's how do

724
00:26:02,240 --> 00:26:04,480
you start to work through the process

725
00:26:04,480 --> 00:26:06,559
and start to break it down and start to

726
00:26:06,559 --> 00:26:08,960
reduce that blast surface

727
00:26:08,960 --> 00:26:11,760
or blast radius sorry over time and i

728
00:26:11,760 --> 00:26:13,440
think that's a really big part like get

729
00:26:13,440 --> 00:26:15,200
started now you know leverage the

730
00:26:15,200 --> 00:26:17,840
concepts and and improve

731
00:26:17,840 --> 00:26:19,440
the continuous improvement cycle and

732
00:26:19,440 --> 00:26:22,159
let's talk about the pki thing because

733
00:26:22,159 --> 00:26:23,279
pki

734
00:26:23,279 --> 00:26:27,279
you know i covered it at forrester um

735
00:26:27,279 --> 00:26:29,200
you know it has some value it has some

736
00:26:29,200 --> 00:26:31,200
problems but

737
00:26:31,200 --> 00:26:33,279
do you have to have pki to do identity

738
00:26:33,279 --> 00:26:35,760
anymore no no and i think this is a

739
00:26:35,760 --> 00:26:38,720
really interesting question because the

740
00:26:38,720 --> 00:26:41,520
the truth of it is is pki and you know

741
00:26:41,520 --> 00:26:42,320
other

742
00:26:42,320 --> 00:26:44,720
you know other forms of um you know

743
00:26:44,720 --> 00:26:46,799
containing identity

744
00:26:46,799 --> 00:26:49,440
security issues exist because of what i

745
00:26:49,440 --> 00:26:51,360
said earlier

746
00:26:51,360 --> 00:26:53,360
90 of the identities inside of your

747
00:26:53,360 --> 00:26:55,279
organization are unknown

748
00:26:55,279 --> 00:26:57,600
right if you if you actually have

749
00:26:57,600 --> 00:27:01,360
a very solid asset inventory like i love

750
00:27:01,360 --> 00:27:03,039
companies that say you know our

751
00:27:03,039 --> 00:27:04,960
employees are our greatest asset and

752
00:27:04,960 --> 00:27:06,400
then when you ask them you know

753
00:27:06,400 --> 00:27:08,320
what's your inventory of human beings

754
00:27:08,320 --> 00:27:09,760
you know how what's your surety level

755
00:27:09,760 --> 00:27:10,640
and they go

756
00:27:10,640 --> 00:27:12,880
well what do you mean like well what's

757
00:27:12,880 --> 00:27:15,279
your error rate i mean do you know 60 of

758
00:27:15,279 --> 00:27:16,400
the people in your company from a

759
00:27:16,400 --> 00:27:19,120
digital perspective or do you know zero

760
00:27:19,120 --> 00:27:20,720
right and when you

761
00:27:20,720 --> 00:27:22,799
when you get to a point where you have a

762
00:27:22,799 --> 00:27:24,159
strong

763
00:27:24,159 --> 00:27:25,440
body of knowledge within your

764
00:27:25,440 --> 00:27:27,840
organization about these identities to

765
00:27:27,840 --> 00:27:29,440
be honest with your pki becomes

766
00:27:29,440 --> 00:27:31,679
irrelevant right because

767
00:27:31,679 --> 00:27:34,399
a a identity can only do what it is

768
00:27:34,399 --> 00:27:36,320
supposed to do based upon authentication

769
00:27:36,320 --> 00:27:39,120
authorization entitlement and attributes

770
00:27:39,120 --> 00:27:41,520
and and therefore if it's doing anything

771
00:27:41,520 --> 00:27:43,600
different that's anomalous behavior and

772
00:27:43,600 --> 00:27:46,000
you know that something's gone wrong so

773
00:27:46,000 --> 00:27:47,600
you know i think that we're rapidly

774
00:27:47,600 --> 00:27:49,279
moving towards a world where things like

775
00:27:49,279 --> 00:27:51,440
pki which as we've talked about as a

776
00:27:51,440 --> 00:27:53,840
20th century solution to a 21st century

777
00:27:53,840 --> 00:27:56,080
problem um are are quickly going to get

778
00:27:56,080 --> 00:27:58,320
put aside by focusing on the

779
00:27:58,320 --> 00:28:00,480
architecture and making the architecture

780
00:28:00,480 --> 00:28:02,960
different to account for these unknowns

781
00:28:02,960 --> 00:28:05,919
yeah i mean x509 certificates work well

782
00:28:05,919 --> 00:28:08,480
for authenticating say a vpn system

783
00:28:08,480 --> 00:28:10,159
right and you can push them to a device

784
00:28:10,159 --> 00:28:11,840
and all that kind of stuff but how are

785
00:28:11,840 --> 00:28:14,080
you managing that certificate right

786
00:28:14,080 --> 00:28:16,480
certificate management is poorly done

787
00:28:16,480 --> 00:28:19,200
so whether it's a x 509 certificate or

788
00:28:19,200 --> 00:28:21,200
an ssh

789
00:28:21,200 --> 00:28:24,080
key right if we look at snowden no one

790
00:28:24,080 --> 00:28:26,799
did centralized ssh key management he

791
00:28:26,799 --> 00:28:30,240
just set up putty sys putty sessions and

792
00:28:30,240 --> 00:28:32,399
created his own ssh keys and then

793
00:28:32,399 --> 00:28:34,480
downloaded stuff and no one knew what he

794
00:28:34,480 --> 00:28:36,799
was downloaded via ssh because it was

795
00:28:36,799 --> 00:28:39,279
all encrypted right so are you doing

796
00:28:39,279 --> 00:28:42,240
centralized key management for your pki

797
00:28:42,240 --> 00:28:44,000
subsystem because it there's no such

798
00:28:44,000 --> 00:28:47,520
thing as apki it is a system right and

799
00:28:47,520 --> 00:28:50,320
so uh do you know how many certificates

800
00:28:50,320 --> 00:28:52,559
you have because the answer is no you

801
00:28:52,559 --> 00:28:54,799
don't i mean i'm sorry the answer is you

802
00:28:54,799 --> 00:28:56,640
don't you think you have two thousand

803
00:28:56,640 --> 00:28:58,720
and when we do when we used to do audits

804
00:28:58,720 --> 00:29:00,480
you'd have sixteen twenty thousand a

805
00:29:00,480 --> 00:29:01,919
hundred thousand do you know when the

806
00:29:01,919 --> 00:29:05,440
expiry is done on them right uh

807
00:29:05,440 --> 00:29:07,200
what what were we talking about today at

808
00:29:07,200 --> 00:29:09,760
lunch uh the expiry of uh zero zero zero

809
00:29:09,760 --> 00:29:12,080
zero zero zero zero zero right yeah

810
00:29:12,080 --> 00:29:14,559
never expires because if it expired it

811
00:29:14,559 --> 00:29:16,320
might be on my watch and i could get in

812
00:29:16,320 --> 00:29:18,080
trouble so i'll just make a certificate

813
00:29:18,080 --> 00:29:20,080
that doesn't expire so therefore it's

814
00:29:20,080 --> 00:29:23,600
not very useful because uh you know

815
00:29:23,600 --> 00:29:25,039
anybody could

816
00:29:25,039 --> 00:29:27,039
hack it and now we see people hacking

817
00:29:27,039 --> 00:29:30,399
certificates like in solar winds

818
00:29:30,399 --> 00:29:32,480
that was i mean sometimes what these

819
00:29:32,480 --> 00:29:34,080
hackers do i just want to give them a

820
00:29:34,080 --> 00:29:36,480
round of applause that is awesome what

821
00:29:36,480 --> 00:29:38,399
you did that's not even supposed to be

822
00:29:38,399 --> 00:29:40,960
possible and they did it yeah right well

823
00:29:40,960 --> 00:29:42,720
that's and i know that we're coming up

824
00:29:42,720 --> 00:29:44,399
on time we're certainly going to be

825
00:29:44,399 --> 00:29:46,799
available uh this evening as we uh go to

826
00:29:46,799 --> 00:29:49,840
the event um after uh the session um and

827
00:29:49,840 --> 00:29:51,440
happy to talk about actually the golden

828
00:29:51,440 --> 00:29:52,720
saml

829
00:29:52,720 --> 00:29:54,559
exploit is uh definitely worth talking

830
00:29:54,559 --> 00:29:55,840
about if anybody's interested in the

831
00:29:55,840 --> 00:29:57,840
mechanics behind that uh that john just

832
00:29:57,840 --> 00:30:00,000
referenced um but tony thank you very

833
00:30:00,000 --> 00:30:02,000
much for having us we appreciate it yeah

834
00:30:02,000 --> 00:30:03,200
thank you both and i think it's an

835
00:30:03,200 --> 00:30:04,799
opportunity for all of us to flip the

836
00:30:04,799 --> 00:30:07,279
script on this leverage zero trust right

837
00:30:07,279 --> 00:30:08,880
let's let's embrace the zero trust

838
00:30:08,880 --> 00:30:10,799
strategy the messaging and help us move

839
00:30:10,799 --> 00:30:12,880
the needle on security in the ics space

840
00:30:12,880 --> 00:30:15,039
so thank you both very much thank you

841
00:30:15,039 --> 00:30:18,039
cheers

842
00:30:22,080 --> 00:30:24,158
you

