1
00:00:00,760 --> 00:00:03,909
[Music]

2
00:00:06,750 --> 00:00:09,820
[Music]

3
00:02:01,680 --> 00:02:04,680
so

4
00:02:48,400 --> 00:02:51,400
so

5
00:03:10,319 --> 00:03:11,760
okay it looks like people are still

6
00:03:11,760 --> 00:03:14,239
coming in

7
00:03:14,400 --> 00:03:19,720
um i see some tuna

8
00:03:19,760 --> 00:03:23,000
in the room

9
00:04:17,040 --> 00:04:20,040
so

10
00:05:51,840 --> 00:05:53,919
you

11
00:06:08,240 --> 00:06:11,240
okay

12
00:06:27,840 --> 00:06:30,840
actually

13
00:06:49,280 --> 00:06:52,280
um

14
00:07:33,919 --> 00:07:37,120
okay i could have a few minutes now so

15
00:07:37,120 --> 00:07:39,680
you should probably get started it's uh

16
00:07:39,680 --> 00:07:41,199
i don't know

17
00:07:41,199 --> 00:07:42,000
there

18
00:07:42,000 --> 00:07:44,879
so you want to come up and get ready for

19
00:07:44,879 --> 00:07:47,520
the microphone

20
00:07:47,520 --> 00:07:51,719
while i do the introductory slides

21
00:08:20,730 --> 00:08:24,230
[Music]

22
00:08:36,000 --> 00:08:39,279
okay so sure can you do an audio check i

23
00:08:39,279 --> 00:08:40,559
see you're there now

24
00:08:40,559 --> 00:08:45,239
it's taking a little camera to work

25
00:08:56,399 --> 00:08:57,920
okay um

26
00:08:57,920 --> 00:08:59,760
i will assume that you can hear me in

27
00:08:59,760 --> 00:09:03,360
the room uh if that's not true please

28
00:09:03,360 --> 00:09:06,000
enter the chat

29
00:09:06,000 --> 00:09:09,839
um so um

30
00:09:14,880 --> 00:09:18,000
so uh welcome everybody this is the iota

31
00:09:18,000 --> 00:09:23,279
open meeting uh at uh ipf4104 uh i'm

32
00:09:23,279 --> 00:09:27,360
colin perkins i'm the irtf chair

33
00:09:27,360 --> 00:09:30,880
hopefully you can all see and hear me

34
00:09:30,880 --> 00:09:34,680
in the room and i'm remote

35
00:09:41,680 --> 00:09:45,120
so uh i would like to

36
00:09:45,120 --> 00:09:47,440
begin with the um

37
00:09:47,440 --> 00:09:51,200
the usual note well slides

38
00:09:55,519 --> 00:09:57,760
echo but hopefully it's not too bad

39
00:09:57,760 --> 00:10:00,640
so uh this is the irtf open meeting the

40
00:10:00,640 --> 00:10:03,120
irtf follows the

41
00:10:03,120 --> 00:10:04,959
itf's intellectual property rights

42
00:10:04,959 --> 00:10:07,839
disclosure rules uh and a reminder that

43
00:10:07,839 --> 00:10:10,320
by participating in this meeting and by

44
00:10:10,320 --> 00:10:12,480
commenting on the presentations that you

45
00:10:12,480 --> 00:10:15,360
you agree to follow the irtf

46
00:10:15,360 --> 00:10:17,680
processes and procedures including

47
00:10:17,680 --> 00:10:20,079
disclosing any intellectual property uh

48
00:10:20,079 --> 00:10:22,320
relating to the contributions that you

49
00:10:22,320 --> 00:10:23,519
make

50
00:10:23,519 --> 00:10:25,279
uh i'm sure most of you have seen these

51
00:10:25,279 --> 00:10:27,680
slides before the the details are in the

52
00:10:27,680 --> 00:10:30,000
documents linked but

53
00:10:30,000 --> 00:10:32,320
essentially if if you have ipr on the

54
00:10:32,320 --> 00:10:33,839
documents you're talking about you you

55
00:10:33,839 --> 00:10:35,120
need to disclose that if you're

56
00:10:35,120 --> 00:10:39,120
commenting a microphone

57
00:10:40,320 --> 00:10:42,720
in addition a reminder that

58
00:10:42,720 --> 00:10:45,519
the irtf routinely makes recordings of

59
00:10:45,519 --> 00:10:48,240
these meetings uh available both the the

60
00:10:48,240 --> 00:10:50,720
online and the in-person person meetings

61
00:10:50,720 --> 00:10:52,959
uh including this one uh and this

62
00:10:52,959 --> 00:10:55,519
meeting is being streamed uh

63
00:10:55,519 --> 00:10:59,519
live on uh youtube as well as via the

64
00:10:59,519 --> 00:11:02,160
usual meat ecosystem

65
00:11:02,160 --> 00:11:04,640
um if you're participating in person and

66
00:11:04,640 --> 00:11:07,040
you are not wearing one of the red uh do

67
00:11:07,040 --> 00:11:09,040
not photograph lanyards then you consent

68
00:11:09,040 --> 00:11:11,360
to appear in these recordings and if you

69
00:11:11,360 --> 00:11:14,480
speak at the microphones um

70
00:11:14,480 --> 00:11:16,880
then again your consenting to being

71
00:11:16,880 --> 00:11:19,279
recorded and as i say the recording is

72
00:11:19,279 --> 00:11:22,399
being made available on youtube

73
00:11:22,399 --> 00:11:24,240
equally uh if you're participating

74
00:11:24,240 --> 00:11:26,480
online and you turn on your camera or

75
00:11:26,480 --> 00:11:28,640
your microphone and make a contribution

76
00:11:28,640 --> 00:11:29,519
then

77
00:11:29,519 --> 00:11:31,360
that that is being recorded and you can

78
00:11:31,360 --> 00:11:33,360
consent being recorded

79
00:11:33,360 --> 00:11:36,399
um and also the chat is also being

80
00:11:36,399 --> 00:11:38,560
recorded and will be made available in

81
00:11:38,560 --> 00:11:42,920
the the usual jabber archives

82
00:11:44,320 --> 00:11:48,399
as a participant in the irtf um

83
00:11:48,399 --> 00:11:51,519
as i say you uh acknowledge that

84
00:11:51,519 --> 00:11:53,360
recordings of the meeting may be made

85
00:11:53,360 --> 00:11:55,760
available and that the previous that any

86
00:11:55,760 --> 00:11:57,360
personal information you provide will be

87
00:11:57,360 --> 00:11:58,959
handled in accordance with the privacy

88
00:11:58,959 --> 00:12:00,160
policy

89
00:12:00,160 --> 00:12:02,000
um and you also agree to work

90
00:12:02,000 --> 00:12:04,079
respectfully with the other participants

91
00:12:04,079 --> 00:12:06,880
in the ietf and the irtf and if you have

92
00:12:06,880 --> 00:12:08,079
any uh

93
00:12:08,079 --> 00:12:09,519
issues or

94
00:12:09,519 --> 00:12:11,760
concerns about that speak to me or speak

95
00:12:11,760 --> 00:12:14,000
with the ombuds team

96
00:12:14,000 --> 00:12:16,160
and the the itf's code of conduct and

97
00:12:16,160 --> 00:12:18,800
anti-harassment procedures uh

98
00:12:18,800 --> 00:12:20,639
linked on the slide also apply to the

99
00:12:20,639 --> 00:12:23,639
irtf

100
00:12:25,360 --> 00:12:27,519
um for those of you participating in

101
00:12:27,519 --> 00:12:30,639
person um please sign in using the the

102
00:12:30,639 --> 00:12:33,279
mobile meet echo the meet echo light

103
00:12:33,279 --> 00:12:35,680
tool uh we're running the queue

104
00:12:35,680 --> 00:12:37,680
electronically so if you have questions

105
00:12:37,680 --> 00:12:39,360
then we're using the electronic queue

106
00:12:39,360 --> 00:12:41,360
that's accessed by via the meet echo

107
00:12:41,360 --> 00:12:43,200
tool

108
00:12:43,200 --> 00:12:44,800
and keep the audio and video off if

109
00:12:44,800 --> 00:12:46,639
you're using the on-site version that

110
00:12:46,639 --> 00:12:49,279
the meet echo light tool

111
00:12:49,279 --> 00:12:51,360
remote participants please leave your

112
00:12:51,360 --> 00:12:53,519
audio and video off and unless you're

113
00:12:53,519 --> 00:12:56,240
you're presenting

114
00:12:56,240 --> 00:12:58,880
or asking a question uh just to avoid

115
00:12:58,880 --> 00:13:02,560
feedback in the comment section

116
00:13:03,440 --> 00:13:06,480
also a reminder for those of you who are

117
00:13:06,480 --> 00:13:09,680
attending the meeting in person uh as a

118
00:13:09,680 --> 00:13:12,480
covet safety measure um the itf is

119
00:13:12,480 --> 00:13:14,720
requiring those those of you in

120
00:13:14,720 --> 00:13:16,800
attending the meeting in person to wear

121
00:13:16,800 --> 00:13:17,600
an

122
00:13:17,600 --> 00:13:20,800
ffp2 and 95 mask

123
00:13:20,800 --> 00:13:22,560
or its equivalent

124
00:13:22,560 --> 00:13:24,560
and the only exception for that is the

125
00:13:24,560 --> 00:13:26,560
the chairs and the presenters who are

126
00:13:26,560 --> 00:13:28,399
actively speaking

127
00:13:28,399 --> 00:13:30,160
uh in particular participants who are

128
00:13:30,160 --> 00:13:31,920
making comments or asking questions from

129
00:13:31,920 --> 00:13:34,320
the floor microphones are expected to

130
00:13:34,320 --> 00:13:36,480
wear a mask at all times including while

131
00:13:36,480 --> 00:13:37,839
they're asking the

132
00:13:37,839 --> 00:13:40,000
those questions as i said the only

133
00:13:40,000 --> 00:13:41,760
exception for that is

134
00:13:41,760 --> 00:13:43,680
the active presenter at the front of the

135
00:13:43,680 --> 00:13:46,680
room

136
00:13:49,199 --> 00:13:52,320
okay so uh as i say this is the the irtf

137
00:13:52,320 --> 00:13:55,839
open meeting uh the goals of the irtf uh

138
00:13:55,839 --> 00:13:58,240
are to complement the standards work

139
00:13:58,240 --> 00:14:00,320
being done in the ietf by focusing on

140
00:14:00,320 --> 00:14:04,000
some of the longer term research issues

141
00:14:04,000 --> 00:14:05,600
the iitf is very much a research

142
00:14:05,600 --> 00:14:07,600
organization it's not a standards

143
00:14:07,600 --> 00:14:09,680
development organization

144
00:14:09,680 --> 00:14:13,120
and while it can publish rfcs and and we

145
00:14:13,120 --> 00:14:15,040
do publish both experimental and

146
00:14:15,040 --> 00:14:16,880
informational documents on the rfc

147
00:14:16,880 --> 00:14:19,040
series that the primary output of the

148
00:14:19,040 --> 00:14:21,920
irtf is his research is understanding

149
00:14:21,920 --> 00:14:24,959
his research papers

150
00:14:28,639 --> 00:14:31,920
the irtf is organized as a series of

151
00:14:31,920 --> 00:14:34,240
research groups um

152
00:14:34,240 --> 00:14:36,160
hopefully you can see them on the slide

153
00:14:36,160 --> 00:14:38,959
here the the crypto forum group and the

154
00:14:38,959 --> 00:14:40,959
uh privacy enhanced enhancements and

155
00:14:40,959 --> 00:14:43,600
assessments groups met earlier today

156
00:14:43,600 --> 00:14:46,240
um the the other groups meant uh sort of

157
00:14:46,240 --> 00:14:48,160
highlighted in dark blue on the slider

158
00:14:48,160 --> 00:14:50,800
meeting later in this week uh so please

159
00:14:50,800 --> 00:14:54,320
do um look out for those groups uh this

160
00:14:54,320 --> 00:14:56,079
week and try and attend the sessions if

161
00:14:56,079 --> 00:14:59,839
you're interested in those topics

162
00:15:01,279 --> 00:15:04,000
a little bit of research group news uh

163
00:15:04,000 --> 00:15:07,360
i'd like to welcome curtis heimerl

164
00:15:07,360 --> 00:15:09,760
who's uh recently joined as co-chair of

165
00:15:09,760 --> 00:15:12,720
the gaia group the global access to the

166
00:15:12,720 --> 00:15:15,199
internet for all research group

167
00:15:15,199 --> 00:15:18,079
um curtis will be joining uh leandro

168
00:15:18,079 --> 00:15:21,360
navarro who is um planning on stepping

169
00:15:21,360 --> 00:15:22,639
down from

170
00:15:22,639 --> 00:15:24,320
from chairing that group after this

171
00:15:24,320 --> 00:15:26,639
meeting and jane coffin who is uh

172
00:15:26,639 --> 00:15:27,839
continuing

173
00:15:27,839 --> 00:15:32,880
so i'd like to welcome uh curtis

174
00:15:33,519 --> 00:15:36,399
and um thank uh him for his service and

175
00:15:36,399 --> 00:15:38,880
thankfully andrew for his his many years

176
00:15:38,880 --> 00:15:40,959
of service to the group

177
00:15:40,959 --> 00:15:44,079
and i very much appreciate the efforts

178
00:15:44,079 --> 00:15:45,600
the android has put into chairing the

179
00:15:45,600 --> 00:15:48,240
group and i look forward to working with

180
00:15:48,240 --> 00:15:50,720
curtis going forward

181
00:15:50,720 --> 00:15:51,440
so

182
00:15:51,440 --> 00:15:54,839
thank you both

183
00:15:58,160 --> 00:16:01,600
as i say the irtf is primarily a

184
00:16:01,600 --> 00:16:03,279
research organization we tend not to

185
00:16:03,279 --> 00:16:06,480
publish many rfcs we've had one rfc

186
00:16:06,480 --> 00:16:08,959
published since the last meeting um from

187
00:16:08,959 --> 00:16:10,880
the information-centric networking group

188
00:16:10,880 --> 00:16:12,639
uh looking at uh architectural

189
00:16:12,639 --> 00:16:15,759
considerations for um using an ic and

190
00:16:15,759 --> 00:16:18,000
main resolution service

191
00:16:18,000 --> 00:16:21,360
um but primarily the the iitf tends not

192
00:16:21,360 --> 00:16:23,279
to publish much in the rfc series and

193
00:16:23,279 --> 00:16:25,440
the output is more in form of

194
00:16:25,440 --> 00:16:26,880
interesting presentations and

195
00:16:26,880 --> 00:16:30,720
understanding and research papers

196
00:16:32,800 --> 00:16:35,040
to support that

197
00:16:35,040 --> 00:16:36,639
we run

198
00:16:36,639 --> 00:16:39,920
the applied networking research prize

199
00:16:39,920 --> 00:16:42,720
and the the goal of this prize is to

200
00:16:42,720 --> 00:16:45,279
recognize that some of the best recent

201
00:16:45,279 --> 00:16:48,000
results in applied networking research

202
00:16:48,000 --> 00:16:50,560
uh is to to um recognize some

203
00:16:50,560 --> 00:16:52,639
interesting new ideas uh which are

204
00:16:52,639 --> 00:16:54,480
potentially relevant to the internet

205
00:16:54,480 --> 00:16:56,800
standards community going forward is to

206
00:16:56,800 --> 00:16:58,560
recognize up and coming people who are

207
00:16:58,560 --> 00:17:01,120
likely to have an impact on the internet

208
00:17:01,120 --> 00:17:02,800
standards process and internet

209
00:17:02,800 --> 00:17:04,720
technologies

210
00:17:04,720 --> 00:17:06,799
uh we're very grateful to the internet

211
00:17:06,799 --> 00:17:09,839
society to comcast and mbc universal for

212
00:17:09,839 --> 00:17:11,119
their sponsorship

213
00:17:11,119 --> 00:17:13,520
of the a rp that

214
00:17:13,520 --> 00:17:17,359
allows us to make these awards

215
00:17:17,439 --> 00:17:19,280
bring different people to give these

216
00:17:19,280 --> 00:17:21,599
thoughts

217
00:17:23,599 --> 00:17:25,039
and uh

218
00:17:25,039 --> 00:17:28,240
what uh what we're doing today is uh

219
00:17:28,240 --> 00:17:30,559
the goal of this session is to to to

220
00:17:30,559 --> 00:17:32,640
make some of these awards so i'd like to

221
00:17:32,640 --> 00:17:35,360
congratulate uh tasha swami

222
00:17:35,360 --> 00:17:38,640
and sam kumar who will be giving

223
00:17:38,640 --> 00:17:41,600
their award talks

224
00:17:42,480 --> 00:17:44,720
on this session today

225
00:17:44,720 --> 00:17:45,520
um

226
00:17:45,520 --> 00:17:47,520
tasha will be talking first in a couple

227
00:17:47,520 --> 00:17:49,520
of minutes uh talking about uh his work

228
00:17:49,520 --> 00:17:51,600
on data plane architectures what's the

229
00:17:51,600 --> 00:17:54,720
line right in for insurance um and sam

230
00:17:54,720 --> 00:17:56,640
will be following uh later in the

231
00:17:56,640 --> 00:17:58,480
session talking about tcp

232
00:17:58,480 --> 00:18:01,039
low power

233
00:18:01,039 --> 00:18:03,039
uh we have two really really good talks

234
00:18:03,039 --> 00:18:04,400
coming so

235
00:18:04,400 --> 00:18:06,000
please do

236
00:18:06,000 --> 00:18:07,520
please do stick around pay attention to

237
00:18:07,520 --> 00:18:10,480
those again congratulations to

238
00:18:10,480 --> 00:18:14,760
tasha and to sex

239
00:18:15,280 --> 00:18:17,039
going forward um

240
00:18:17,039 --> 00:18:19,120
look out for a little bit more of more

241
00:18:19,120 --> 00:18:22,640
wood talks uh goten akiwati uh korean

242
00:18:22,640 --> 00:18:24,720
cat and daniel wagner will be giving the

243
00:18:24,720 --> 00:18:27,360
talks of atf-115

244
00:18:27,360 --> 00:18:30,880
and the nominations for the um

245
00:18:30,880 --> 00:18:33,440
nominations for the 2023 awards will be

246
00:18:33,440 --> 00:18:36,640
opening in september 2022 so to look out

247
00:18:36,640 --> 00:18:38,720
for those uh

248
00:18:38,720 --> 00:18:41,200
um look out for the nominations opening

249
00:18:41,200 --> 00:18:43,760
in online

250
00:18:49,200 --> 00:18:51,360
okay did the audio improve

251
00:18:51,360 --> 00:18:53,120
trade muting and restarting hopefully

252
00:18:53,120 --> 00:18:56,678
you can hear me

253
00:18:58,000 --> 00:19:00,400
okay

254
00:19:00,400 --> 00:19:02,240
okay hopefully that's better as i was

255
00:19:02,240 --> 00:19:04,240
saying look out for the uh nominations

256
00:19:04,240 --> 00:19:08,080
for the 2023 a rp um in september this

257
00:19:08,080 --> 00:19:08,880
year

258
00:19:08,880 --> 00:19:11,840
uh and um congratulations to tasha and

259
00:19:11,840 --> 00:19:14,720
to sam who will be giving their very nrp

260
00:19:14,720 --> 00:19:17,440
talks today

261
00:19:18,640 --> 00:19:21,679
in uh addition to the applied networking

262
00:19:21,679 --> 00:19:25,280
research prize we also host the uh

263
00:19:25,280 --> 00:19:27,039
applied networking research workshop

264
00:19:27,039 --> 00:19:28,799
which we organize in conjunction with

265
00:19:28,799 --> 00:19:30,720
acm sitcom

266
00:19:30,720 --> 00:19:32,799
um this workshop is taking place

267
00:19:32,799 --> 00:19:35,120
tomorrow it's co-locating with the itf

268
00:19:35,120 --> 00:19:36,640
in philadelphia

269
00:19:36,640 --> 00:19:39,919
so thank you to tj chung and marwan fire

270
00:19:39,919 --> 00:19:41,919
to the chairs this year and who've been

271
00:19:41,919 --> 00:19:44,000
organizing that workshop

272
00:19:44,000 --> 00:19:47,200
um we've got um a program of uh i think

273
00:19:47,200 --> 00:19:49,200
that there are four four really nice

274
00:19:49,200 --> 00:19:51,520
research papers uh a keynote and some

275
00:19:51,520 --> 00:19:53,919
invited talks on novel approaches to

276
00:19:53,919 --> 00:19:56,160
protocol specification

277
00:19:56,160 --> 00:19:57,760
as i say that the workshop's happening

278
00:19:57,760 --> 00:20:01,440
tomorrow um if you're there in in person

279
00:20:01,440 --> 00:20:02,559
then

280
00:20:02,559 --> 00:20:04,480
please do consider attending if you're

281
00:20:04,480 --> 00:20:06,480
attending remotely then you can register

282
00:20:06,480 --> 00:20:08,640
and attend um

283
00:20:08,640 --> 00:20:10,799
registration is free for anyone who's uh

284
00:20:10,799 --> 00:20:13,039
also registered with the itf although we

285
00:20:13,039 --> 00:20:15,440
do ask you to to register separately so

286
00:20:15,440 --> 00:20:18,320
we know who's attending the workshop

287
00:20:18,320 --> 00:20:21,440
um and the a rw next year will be uh

288
00:20:21,440 --> 00:20:24,320
again co-locating with the the itf in

289
00:20:24,320 --> 00:20:27,600
july 2023 which is planned to be in san

290
00:20:27,600 --> 00:20:30,320
francisco

291
00:20:32,480 --> 00:20:34,559
and to finish up before we get to the

292
00:20:34,559 --> 00:20:36,960
talks uh i'd just like to

293
00:20:36,960 --> 00:20:39,440
um note that we we are very pleased to

294
00:20:39,440 --> 00:20:40,960
offer a number of travel grants for

295
00:20:40,960 --> 00:20:43,280
these meetings um

296
00:20:43,280 --> 00:20:46,080
both to support early career academics

297
00:20:46,080 --> 00:20:49,440
and phd students from underrepresented

298
00:20:49,440 --> 00:20:51,919
groups to to attend the irtf research

299
00:20:51,919 --> 00:20:53,120
groups

300
00:20:53,120 --> 00:20:55,600
and a number of travel grants for the uh

301
00:20:55,600 --> 00:20:58,480
applied networking research workshop

302
00:20:58,480 --> 00:21:00,799
um thank you very much to

303
00:21:00,799 --> 00:21:03,120
the travel ground sponsors to akamai

304
00:21:03,120 --> 00:21:06,240
comcast cloudflare and netflix uh for

305
00:21:06,240 --> 00:21:08,240
supporting that um

306
00:21:08,240 --> 00:21:10,320
if you'll you know please see the the

307
00:21:10,320 --> 00:21:12,159
travel grants page uh linked from the

308
00:21:12,159 --> 00:21:13,919
website um

309
00:21:13,919 --> 00:21:17,200
for details of that um and if if you're

310
00:21:17,200 --> 00:21:20,000
interested in sponsoring uh

311
00:21:20,000 --> 00:21:22,000
the travel grants in future or if you're

312
00:21:22,000 --> 00:21:23,440
interested in applying for a travel

313
00:21:23,440 --> 00:21:26,080
grant uh see that webpage or contact me

314
00:21:26,080 --> 00:21:28,840
for for details of those sponsorship

315
00:21:28,840 --> 00:21:30,960
opportunities and again thank you very

316
00:21:30,960 --> 00:21:34,000
much for the sponsors

317
00:21:35,760 --> 00:21:37,919
so that's uh essentially all i have to

318
00:21:37,919 --> 00:21:40,080
say today um

319
00:21:40,080 --> 00:21:42,640
the agenda for the remainder of the day

320
00:21:42,640 --> 00:21:46,000
um we have the the two a rp award talks

321
00:21:46,000 --> 00:21:47,200
uh

322
00:21:47,200 --> 00:21:49,440
tasha swami will be first uh talking

323
00:21:49,440 --> 00:21:51,919
about taurus a data plane architecture

324
00:21:51,919 --> 00:21:54,720
for per packet machine learning and that

325
00:21:54,720 --> 00:21:56,640
will be followed by some sam kumar's

326
00:21:56,640 --> 00:21:59,280
talk on performance tcp for for low

327
00:21:59,280 --> 00:22:02,480
power wireless networks

328
00:22:03,679 --> 00:22:06,720
okay um i will at this point switch over

329
00:22:06,720 --> 00:22:07,840
to

330
00:22:07,840 --> 00:22:09,840
uh tasha can you

331
00:22:09,840 --> 00:22:11,200
check the microphone when i get the

332
00:22:11,200 --> 00:22:13,600
slides up

333
00:22:13,600 --> 00:22:16,320
yes it's okay

334
00:22:18,480 --> 00:22:22,720
uh yeah i can hear you remotely

335
00:22:22,720 --> 00:22:26,520
is it working in the room

336
00:22:30,400 --> 00:22:32,799
awesome should i get started

337
00:22:32,799 --> 00:22:35,760
yes just one one second if you have a

338
00:22:35,760 --> 00:22:37,919
phone i can pass you control so you can

339
00:22:37,919 --> 00:22:39,679
control the slides yourself if you have

340
00:22:39,679 --> 00:22:42,880
the meat echo light if not then

341
00:22:42,880 --> 00:22:44,720
shout when you want to go to the next

342
00:22:44,720 --> 00:22:47,120
slide

343
00:22:52,480 --> 00:22:56,159
okay so i should have control over that

344
00:22:56,159 --> 00:22:57,200
um

345
00:22:57,200 --> 00:22:59,679
while uh tasha is checking to see if

346
00:22:59,679 --> 00:23:02,000
that works uh i'd just like to say that

347
00:23:02,000 --> 00:23:02,880
uh

348
00:23:02,880 --> 00:23:05,039
the that as i say the first talk today

349
00:23:05,039 --> 00:23:06,240
is uh

350
00:23:06,240 --> 00:23:08,240
he'll be talking about taurus at data

351
00:23:08,240 --> 00:23:11,360
plane architecture for per packet ml

352
00:23:11,360 --> 00:23:13,280
tasha is a phd candidate in the

353
00:23:13,280 --> 00:23:14,799
electrical engineering department at

354
00:23:14,799 --> 00:23:16,320
stanford

355
00:23:16,320 --> 00:23:18,880
his research is focusing on the

356
00:23:18,880 --> 00:23:20,320
intersection of machine learning

357
00:23:20,320 --> 00:23:22,799
networking and architecture and he works

358
00:23:22,799 --> 00:23:24,799
on the hardware software stack for data

359
00:23:24,799 --> 00:23:26,080
plane based machine learning

360
00:23:26,080 --> 00:23:28,559
infrastructure and applications

361
00:23:28,559 --> 00:23:31,120
uh tasha is due to graduate this year i

362
00:23:31,120 --> 00:23:33,360
understand he's on the job market so uh

363
00:23:33,360 --> 00:23:35,679
if if you like this work then please do

364
00:23:35,679 --> 00:23:38,159
uh talk to him he'll be

365
00:23:38,159 --> 00:23:40,240
around at the itf all week and if you

366
00:23:40,240 --> 00:23:42,320
find this talk interesting i believe

367
00:23:42,320 --> 00:23:44,000
he's also going to be presenting in the

368
00:23:44,000 --> 00:23:47,760
coin rg session later this week

369
00:23:47,760 --> 00:23:51,360
um tasha over to you

370
00:23:51,360 --> 00:23:53,440
awesome thanks colin

371
00:23:53,440 --> 00:23:55,200
uh cool so

372
00:23:55,200 --> 00:23:57,360
um i'm gonna be talking about taurus

373
00:23:57,360 --> 00:23:59,600
which is a project that uh me and my

374
00:23:59,600 --> 00:24:01,600
colleagues have been working on and so

375
00:24:01,600 --> 00:24:03,279
taurus is essentially a data plane

376
00:24:03,279 --> 00:24:05,919
architecture for per packet machine

377
00:24:05,919 --> 00:24:09,039
learning and

378
00:24:09,440 --> 00:24:11,279
go into a little bit of what

379
00:24:11,279 --> 00:24:13,760
that means all right so

380
00:24:13,760 --> 00:24:16,320
this here is a quote from a 2015 google

381
00:24:16,320 --> 00:24:17,279
blog

382
00:24:17,279 --> 00:24:19,679
and at that time uh

383
00:24:19,679 --> 00:24:22,240
google was already dealing with uh over

384
00:24:22,240 --> 00:24:24,159
one petabit per second of total

385
00:24:24,159 --> 00:24:27,200
bisection bandwidth um and it's only

386
00:24:27,200 --> 00:24:29,840
grown larger and harder to scale since

387
00:24:29,840 --> 00:24:31,600
so what we're essentially dealing with

388
00:24:31,600 --> 00:24:33,919
here is a situation where networks

389
00:24:33,919 --> 00:24:36,640
require more and more complex management

390
00:24:36,640 --> 00:24:38,799
with higher and higher performance

391
00:24:38,799 --> 00:24:41,440
um and so it's

392
00:24:41,440 --> 00:24:43,679
uh the time is ripe for finding new

393
00:24:43,679 --> 00:24:47,200
solutions here

394
00:24:47,200 --> 00:24:48,400
and

395
00:24:48,400 --> 00:24:51,039
one of the promising solutions in this

396
00:24:51,039 --> 00:24:54,240
area is machine learning so machine

397
00:24:54,240 --> 00:24:57,600
learning can allow us to

398
00:24:57,600 --> 00:24:59,360
essentially take in data from the

399
00:24:59,360 --> 00:25:01,200
network and make progressively better

400
00:25:01,200 --> 00:25:02,960
and better decisions as we train our

401
00:25:02,960 --> 00:25:04,000
models

402
00:25:04,000 --> 00:25:04,960
and

403
00:25:04,960 --> 00:25:06,880
these machine learning algorithms can

404
00:25:06,880 --> 00:25:08,960
approximate network functions based on

405
00:25:08,960 --> 00:25:10,720
the data they see

406
00:25:10,720 --> 00:25:11,760
and

407
00:25:11,760 --> 00:25:13,520
they're also going to customize their

408
00:25:13,520 --> 00:25:15,600
operation to the data that they're

409
00:25:15,600 --> 00:25:18,720
training on which in turn means that

410
00:25:18,720 --> 00:25:20,400
these machine learning algorithms are

411
00:25:20,400 --> 00:25:22,960
actually customizing their models to the

412
00:25:22,960 --> 00:25:24,720
network itself

413
00:25:24,720 --> 00:25:28,640
and so we're sort of uh doing elements

414
00:25:28,640 --> 00:25:30,320
of this already with handwritten

415
00:25:30,320 --> 00:25:32,559
heuristics in the network so something

416
00:25:32,559 --> 00:25:34,000
like an active queue management

417
00:25:34,000 --> 00:25:35,760
algorithm or

418
00:25:35,760 --> 00:25:38,240
hashing and load balancing and playing

419
00:25:38,240 --> 00:25:41,120
with operator tuned parameters so

420
00:25:41,120 --> 00:25:42,559
all machine learning

421
00:25:42,559 --> 00:25:44,960
uh is doing here is taking the next step

422
00:25:44,960 --> 00:25:48,159
by automating the um

423
00:25:48,159 --> 00:25:48,880
the

424
00:25:48,880 --> 00:25:51,120
search for these kind of parameters that

425
00:25:51,120 --> 00:25:55,479
allow to work well within your network

426
00:25:57,200 --> 00:25:58,080
so

427
00:25:58,080 --> 00:26:00,000
uh if we're okay with using machine

428
00:26:00,000 --> 00:26:02,240
learning we now need to examine where

429
00:26:02,240 --> 00:26:04,799
exactly in the network it has to happen

430
00:26:04,799 --> 00:26:06,720
so i'm sure many of you already familiar

431
00:26:06,720 --> 00:26:08,880
with software-defined networks

432
00:26:08,880 --> 00:26:10,480
essentially the control plane and the

433
00:26:10,480 --> 00:26:13,440
data plane are split and the control

434
00:26:13,440 --> 00:26:16,480
plane is responsible for policy creation

435
00:26:16,480 --> 00:26:18,799
um essentially in the form of flow rules

436
00:26:18,799 --> 00:26:20,880
which are installed into a data plane

437
00:26:20,880 --> 00:26:22,159
where that's where you're going to find

438
00:26:22,159 --> 00:26:24,559
your switches and they're doing packet

439
00:26:24,559 --> 00:26:27,279
forwarding via match action

440
00:26:27,279 --> 00:26:28,799
so

441
00:26:28,799 --> 00:26:30,640
right off the bat there are two good

442
00:26:30,640 --> 00:26:32,880
candidates for where we should operate

443
00:26:32,880 --> 00:26:35,840
with machine learning

444
00:26:36,640 --> 00:26:37,440
and

445
00:26:37,440 --> 00:26:40,799
uh on the left here i have a diagram of

446
00:26:40,799 --> 00:26:43,279
the same typical define software defined

447
00:26:43,279 --> 00:26:44,240
network

448
00:26:44,240 --> 00:26:46,960
but on the right uh i have a software

449
00:26:46,960 --> 00:26:48,400
defined network with the taurus

450
00:26:48,400 --> 00:26:49,600
worldview

451
00:26:49,600 --> 00:26:51,440
and so

452
00:26:51,440 --> 00:26:53,200
what we've actually done here is we've

453
00:26:53,200 --> 00:26:55,679
split the machine learning operation

454
00:26:55,679 --> 00:26:57,600
into training which is going to happen

455
00:26:57,600 --> 00:26:59,919
in the control plane and then inference

456
00:26:59,919 --> 00:27:01,120
which is going to happen in the data

457
00:27:01,120 --> 00:27:04,320
plane so in the control plane policy

458
00:27:04,320 --> 00:27:06,080
creation is going to take the form of

459
00:27:06,080 --> 00:27:09,440
flow rules plus ml training and when

460
00:27:09,440 --> 00:27:11,279
installing this information into the

461
00:27:11,279 --> 00:27:13,520
data plane it's going to be sending flow

462
00:27:13,520 --> 00:27:16,960
rules as usual but also the ml model

463
00:27:16,960 --> 00:27:17,919
weights

464
00:27:17,919 --> 00:27:20,080
and in the data plane we're going to be

465
00:27:20,080 --> 00:27:22,320
doing our typical match action packet

466
00:27:22,320 --> 00:27:24,000
forwarding but we're also going to be

467
00:27:24,000 --> 00:27:28,720
doing decision making with ml inference

468
00:27:31,120 --> 00:27:33,440
and so that brings me to one of the core

469
00:27:33,440 --> 00:27:36,080
tenets of taurus and that's essentially

470
00:27:36,080 --> 00:27:38,240
the ml inference should happen per

471
00:27:38,240 --> 00:27:40,480
packet in the data plane

472
00:27:40,480 --> 00:27:43,840
um and so the the intuition here is

473
00:27:43,840 --> 00:27:45,919
relatively straightforward you want to

474
00:27:45,919 --> 00:27:48,159
be able to do per packet operation

475
00:27:48,159 --> 00:27:50,880
because that is the finest granularity

476
00:27:50,880 --> 00:27:52,720
of traffic essentially operating on a

477
00:27:52,720 --> 00:27:55,440
packet scale now not every application

478
00:27:55,440 --> 00:27:58,799
may need per packet

479
00:27:58,799 --> 00:28:01,120
level operation but

480
00:28:01,120 --> 00:28:03,120
the there are applications that need it

481
00:28:03,120 --> 00:28:05,279
and so the platform should be able to

482
00:28:05,279 --> 00:28:07,840
support per packet operation and then

483
00:28:07,840 --> 00:28:09,840
the data plane that's where the packets

484
00:28:09,840 --> 00:28:11,039
are so if we're going to be doing

485
00:28:11,039 --> 00:28:13,200
decisions on packets it should happen in

486
00:28:13,200 --> 00:28:16,520
the data plane

487
00:28:17,440 --> 00:28:18,480
oh

488
00:28:18,480 --> 00:28:20,799
i think uh powerpoint animations don't

489
00:28:20,799 --> 00:28:23,520
play well with the pdf um

490
00:28:23,520 --> 00:28:24,399
so

491
00:28:24,399 --> 00:28:26,399
that's okay uh

492
00:28:26,399 --> 00:28:28,480
what what's basically happening in here

493
00:28:28,480 --> 00:28:31,840
is that um if we were to do just a rough

494
00:28:31,840 --> 00:28:35,039
off the uh off the cuff math here so you

495
00:28:35,039 --> 00:28:37,039
have traffic at one giga packet per

496
00:28:37,039 --> 00:28:39,279
second moving through your data plane

497
00:28:39,279 --> 00:28:42,080
now in the time it takes you to send a

498
00:28:42,080 --> 00:28:43,919
packet digest from the data plane up to

499
00:28:43,919 --> 00:28:45,360
the control plane

500
00:28:45,360 --> 00:28:48,000
calculate flow rules and then install it

501
00:28:48,000 --> 00:28:49,919
back in the data plane in this case

502
00:28:49,919 --> 00:28:52,159
we've assumed

503
00:28:52,159 --> 00:28:54,320
half a millisecond for each step so

504
00:28:54,320 --> 00:28:56,159
we've now missed

505
00:28:56,159 --> 00:28:58,399
1.5 million packets

506
00:28:58,399 --> 00:29:01,600
in our traffic stream by the time

507
00:29:01,600 --> 00:29:03,679
uh we had flow rules installed into the

508
00:29:03,679 --> 00:29:05,679
data plane so

509
00:29:05,679 --> 00:29:07,760
in the example here we're doing anomaly

510
00:29:07,760 --> 00:29:09,520
detection so we're trying to find out if

511
00:29:09,520 --> 00:29:12,240
incoming packets are malicious or benign

512
00:29:12,240 --> 00:29:14,720
and maybe if we find that it's malicious

513
00:29:14,720 --> 00:29:16,720
we're going to install some rule to say

514
00:29:16,720 --> 00:29:18,240
block that ip

515
00:29:18,240 --> 00:29:19,120
um

516
00:29:19,120 --> 00:29:19,919
and

517
00:29:19,919 --> 00:29:22,080
by the so we've missed 1.5 million

518
00:29:22,080 --> 00:29:23,360
packets during this flow rule

519
00:29:23,360 --> 00:29:25,039
installation time by the time we block

520
00:29:25,039 --> 00:29:28,000
that ip we've already let a ton of uh

521
00:29:28,000 --> 00:29:30,320
potentially malicious traffic into the

522
00:29:30,320 --> 00:29:32,399
network so

523
00:29:32,399 --> 00:29:34,240
the whole takeaway here is really just

524
00:29:34,240 --> 00:29:34,960
to

525
00:29:34,960 --> 00:29:37,440
um show you why

526
00:29:37,440 --> 00:29:39,600
we can't let

527
00:29:39,600 --> 00:29:42,240
our operation for these kind of this

528
00:29:42,240 --> 00:29:44,720
level of application happen in the

529
00:29:44,720 --> 00:29:46,720
control plane and if we're committing to

530
00:29:46,720 --> 00:29:48,960
using machine learning we can't have

531
00:29:48,960 --> 00:29:53,640
inference happen in the control plane

532
00:29:54,880 --> 00:29:56,240
so

533
00:29:56,240 --> 00:29:58,000
fundamentally the conclusion here is

534
00:29:58,000 --> 00:29:59,520
that the robustness and performance of

535
00:29:59,520 --> 00:30:01,520
your network are going to be determined

536
00:30:01,520 --> 00:30:03,360
by the quality of your reaction and the

537
00:30:03,360 --> 00:30:05,120
speed of your reaction

538
00:30:05,120 --> 00:30:06,000
so

539
00:30:06,000 --> 00:30:08,399
in the machine learning world view the

540
00:30:08,399 --> 00:30:10,000
quality of the reaction is going to be

541
00:30:10,000 --> 00:30:12,960
determined by your training data so how

542
00:30:12,960 --> 00:30:15,120
much do you have what kind of cases does

543
00:30:15,120 --> 00:30:17,039
it cover how well is it cleaned

544
00:30:17,039 --> 00:30:18,880
but also your speed of reaction so in

545
00:30:18,880 --> 00:30:21,760
the case of the anomaly detection

546
00:30:21,760 --> 00:30:23,760
you want to act on a malicious packet

547
00:30:23,760 --> 00:30:25,039
the moment you see it you don't want to

548
00:30:25,039 --> 00:30:26,480
have to go to the control plane and come

549
00:30:26,480 --> 00:30:29,279
back and install any sort of flow rules

550
00:30:29,279 --> 00:30:30,480
and

551
00:30:30,480 --> 00:30:32,080
this is essentially the per-packet

552
00:30:32,080 --> 00:30:36,120
operation in the data plane

553
00:30:38,240 --> 00:30:38,960
so

554
00:30:38,960 --> 00:30:40,559
zooming in on

555
00:30:40,559 --> 00:30:41,360
uh

556
00:30:41,360 --> 00:30:43,039
the control plane let's talk a little

557
00:30:43,039 --> 00:30:45,360
bit about the actual implementation of

558
00:30:45,360 --> 00:30:46,720
how you do this

559
00:30:46,720 --> 00:30:48,320
so i mentioned before that we're going

560
00:30:48,320 --> 00:30:51,520
to split our machine learning uh into

561
00:30:51,520 --> 00:30:52,640
training in the control plane and

562
00:30:52,640 --> 00:30:54,960
inference in the data plane and so the

563
00:30:54,960 --> 00:30:56,960
key here is that training is off the

564
00:30:56,960 --> 00:30:58,799
critical path if packet forward is

565
00:30:58,799 --> 00:31:00,240
packet forwarding is happening in the

566
00:31:00,240 --> 00:31:01,440
data plane

567
00:31:01,440 --> 00:31:02,720
then

568
00:31:02,720 --> 00:31:04,640
the control plane is not

569
00:31:04,640 --> 00:31:07,519
uh responsible for making uh per packet

570
00:31:07,519 --> 00:31:09,519
level decisions which means that we can

571
00:31:09,519 --> 00:31:12,480
do our machine learning training there

572
00:31:12,480 --> 00:31:15,120
at leisure and um

573
00:31:15,120 --> 00:31:16,880
essentially we can we can put in

574
00:31:16,880 --> 00:31:18,799
whatever the latest and greatest ml

575
00:31:18,799 --> 00:31:20,960
accelerators are whatever your favorite

576
00:31:20,960 --> 00:31:23,279
ml framework is um install it in a

577
00:31:23,279 --> 00:31:25,760
control plane server and have it

578
00:31:25,760 --> 00:31:28,320
training models offline

579
00:31:28,320 --> 00:31:30,480
the trickier part

580
00:31:30,480 --> 00:31:33,039
comes in the next step where

581
00:31:33,039 --> 00:31:35,360
now uh we need to deal with the actual

582
00:31:35,360 --> 00:31:37,440
critical path basically

583
00:31:37,440 --> 00:31:40,640
um tackling packets as they come so

584
00:31:40,640 --> 00:31:42,960
machine learning inference here

585
00:31:42,960 --> 00:31:44,399
is going to happen in the data plane

586
00:31:44,399 --> 00:31:47,440
like i mentioned and the the final

587
00:31:47,440 --> 00:31:50,000
outstanding question here then is if

588
00:31:50,000 --> 00:31:51,679
we're okay with doing

589
00:31:51,679 --> 00:31:54,480
uh training in the control plane we can

590
00:31:54,480 --> 00:31:57,600
use whatever existing hardware we want

591
00:31:57,600 --> 00:31:59,760
and then what do we do about the data

592
00:31:59,760 --> 00:32:01,679
plane do we have

593
00:32:01,679 --> 00:32:05,039
say a switch that can do inference um at

594
00:32:05,039 --> 00:32:07,919
line rate per packet operation

595
00:32:07,919 --> 00:32:09,600
and

596
00:32:09,600 --> 00:32:12,320
so this is really the the crux of taurus

597
00:32:12,320 --> 00:32:14,159
and that's what it needs to do so taurus

598
00:32:14,159 --> 00:32:16,080
is an architecture for per packet

599
00:32:16,080 --> 00:32:18,159
machine learning inference in the data

600
00:32:18,159 --> 00:32:20,399
plane

601
00:32:22,720 --> 00:32:23,760
so

602
00:32:23,760 --> 00:32:26,640
let's jump into the actual hardware

603
00:32:26,640 --> 00:32:28,720
and how we enable this kind of machine

604
00:32:28,720 --> 00:32:31,760
learning inference at line rate so i

605
00:32:31,760 --> 00:32:33,919
have a picture here of a piece of

606
00:32:33,919 --> 00:32:36,000
pipeline a protocol independent switch

607
00:32:36,000 --> 00:32:38,159
architecture so this is

608
00:32:38,159 --> 00:32:40,399
the typical uh

609
00:32:40,399 --> 00:32:43,200
programmable structures you'll find in

610
00:32:43,200 --> 00:32:46,000
these kind of uh switches so

611
00:32:46,000 --> 00:32:48,399
some sort of programmable packet parser

612
00:32:48,399 --> 00:32:50,159
match action tables that allow you to

613
00:32:50,159 --> 00:32:52,399
encode your network functions and then

614
00:32:52,399 --> 00:32:55,279
maybe a programmable traffic manager

615
00:32:55,279 --> 00:32:57,200
so

616
00:32:57,200 --> 00:32:59,200
we're going to actually keep most of

617
00:32:59,200 --> 00:33:01,039
these elements

618
00:33:01,039 --> 00:33:03,519
and just make a modification of

619
00:33:03,519 --> 00:33:05,679
additional hardware that'll allow us to

620
00:33:05,679 --> 00:33:09,200
do our machine learning inference

621
00:33:09,519 --> 00:33:11,279
but the natural question is

622
00:33:11,279 --> 00:33:12,799
if we're if we're committing to adding

623
00:33:12,799 --> 00:33:16,480
hardware into the switch pipeline um

624
00:33:16,480 --> 00:33:18,159
what does that look like and more

625
00:33:18,159 --> 00:33:20,080
specifically what is the abstraction

626
00:33:20,080 --> 00:33:20,880
here

627
00:33:20,880 --> 00:33:22,840
with which we're going to create our

628
00:33:22,840 --> 00:33:25,760
programmable machine learning

629
00:33:25,760 --> 00:33:26,960
fabric

630
00:33:26,960 --> 00:33:30,320
and so in taurus we use the mapreduce

631
00:33:30,320 --> 00:33:32,720
abstraction so mapreduce is really

632
00:33:32,720 --> 00:33:34,880
useful for machine learning because it

633
00:33:34,880 --> 00:33:36,720
supports a lot of the common linear

634
00:33:36,720 --> 00:33:38,480
algebra operations that you need for

635
00:33:38,480 --> 00:33:40,640
your ml algorithm so this covers

636
00:33:40,640 --> 00:33:42,159
everything from

637
00:33:42,159 --> 00:33:44,080
neural networks support vector machines

638
00:33:44,080 --> 00:33:45,360
k-means

639
00:33:45,360 --> 00:33:46,320
all these different kinds of

640
00:33:46,320 --> 00:33:49,120
applications and just as an example i

641
00:33:49,120 --> 00:33:50,840
have here in the picture

642
00:33:50,840 --> 00:33:54,480
um an example of a single neuron from a

643
00:33:54,480 --> 00:33:57,279
deep neural network so you can see

644
00:33:57,279 --> 00:33:59,919
exactly how map and reducer applied here

645
00:33:59,919 --> 00:34:03,200
in this case in the blue box

646
00:34:03,200 --> 00:34:04,880
we are doing an element-wise

647
00:34:04,880 --> 00:34:06,559
multiplication that's our map with

648
00:34:06,559 --> 00:34:10,079
multiplication with inputs and weights

649
00:34:10,079 --> 00:34:12,719
and then we're applying a reduction and

650
00:34:12,719 --> 00:34:14,719
so this is going to

651
00:34:14,719 --> 00:34:17,520
essentially add all the values together

652
00:34:17,520 --> 00:34:19,119
and

653
00:34:19,119 --> 00:34:20,399
you're going to produce

654
00:34:20,399 --> 00:34:22,639
a scalar value from your vector of

655
00:34:22,639 --> 00:34:23,918
inputs

656
00:34:23,918 --> 00:34:25,280
and then finally we're going to apply an

657
00:34:25,280 --> 00:34:27,839
activation function and so that suffices

658
00:34:27,839 --> 00:34:30,159
for a single neuron but you can

659
00:34:30,159 --> 00:34:33,199
mix and match this pattern ad nauseam uh

660
00:34:33,199 --> 00:34:36,639
to create a full neural network so by

661
00:34:36,639 --> 00:34:38,639
stacking extra

662
00:34:38,639 --> 00:34:40,000
of these blocks

663
00:34:40,000 --> 00:34:43,440
um in parallel you'll be creating a

664
00:34:43,440 --> 00:34:45,359
layer of neurons and then stacking them

665
00:34:45,359 --> 00:34:47,760
sequentially you'll be creating multiple

666
00:34:47,760 --> 00:34:49,440
layers and so that's how you can create

667
00:34:49,440 --> 00:34:52,720
say a deep neural network

668
00:34:54,960 --> 00:34:56,879
so the other advantage of the mapreduce

669
00:34:56,879 --> 00:34:59,760
pattern is uh comes from the kind of

670
00:34:59,760 --> 00:35:02,720
performance that it enables primarily

671
00:35:02,720 --> 00:35:05,680
it's a from the the cmd parallelism that

672
00:35:05,680 --> 00:35:08,160
same instruction multiple data so we can

673
00:35:08,160 --> 00:35:10,079
get a lot of performance out of the

674
00:35:10,079 --> 00:35:13,119
parallelism with minimal logic

675
00:35:13,119 --> 00:35:15,359
and this is as opposed to what you might

676
00:35:15,359 --> 00:35:17,839
find in a say like a

677
00:35:17,839 --> 00:35:20,160
a typical like tofino pipeline where

678
00:35:20,160 --> 00:35:22,320
they have vliw pipelines

679
00:35:22,320 --> 00:35:25,200
which give you much more flexibility but

680
00:35:25,200 --> 00:35:27,520
the cost here is that there's a lot of

681
00:35:27,520 --> 00:35:29,119
logic that's needed for the

682
00:35:29,119 --> 00:35:32,480
communication hardware and um

683
00:35:32,480 --> 00:35:34,880
that ends up taking up a lot of the the

684
00:35:34,880 --> 00:35:36,960
overall on-chip area

685
00:35:36,960 --> 00:35:39,119
and uh in addition

686
00:35:39,119 --> 00:35:40,960
simply parallelism gives us the ability

687
00:35:40,960 --> 00:35:41,680
to

688
00:35:41,680 --> 00:35:43,359
um unroll

689
00:35:43,359 --> 00:35:46,320
the loops in our um

690
00:35:46,320 --> 00:35:49,680
uh in our algorithms so the the idea of

691
00:35:49,680 --> 00:35:52,240
unrolling here if we take the example of

692
00:35:52,240 --> 00:35:54,400
um say a single layer of a neural

693
00:35:54,400 --> 00:35:57,040
network and say you have four neurons in

694
00:35:57,040 --> 00:36:00,400
your network you can either

695
00:36:00,400 --> 00:36:03,040
execute them sequentially you're doing

696
00:36:03,040 --> 00:36:05,680
one neuron after the other or if you

697
00:36:05,680 --> 00:36:07,920
have the resources you can instantiate

698
00:36:07,920 --> 00:36:09,920
all four of them in parallel

699
00:36:09,920 --> 00:36:12,400
and so the trade-off here is that

700
00:36:12,400 --> 00:36:14,000
more on rolling is going to give you

701
00:36:14,000 --> 00:36:15,599
better performance essentially doing all

702
00:36:15,599 --> 00:36:17,680
four of those neurons at once

703
00:36:17,680 --> 00:36:20,240
while less enrolling means you only need

704
00:36:20,240 --> 00:36:21,599
the hardware

705
00:36:21,599 --> 00:36:23,760
for one single neurons worth of

706
00:36:23,760 --> 00:36:25,760
operations but it's going to take you

707
00:36:25,760 --> 00:36:28,240
four times as long so it's less resource

708
00:36:28,240 --> 00:36:32,479
intensive but it's also uh

709
00:36:32,640 --> 00:36:34,079
much less

710
00:36:34,079 --> 00:36:37,280
a much higher latency and

711
00:36:37,280 --> 00:36:39,280
but we get this kind of control with the

712
00:36:39,280 --> 00:36:42,240
cmd pattern by um essentially on

713
00:36:42,240 --> 00:36:45,759
adjusting unrolling factors

714
00:36:47,520 --> 00:36:48,800
so

715
00:36:48,800 --> 00:36:51,119
we went ahead and we

716
00:36:51,119 --> 00:36:54,160
essentially adjusted the switch pipeline

717
00:36:54,160 --> 00:36:57,599
with a mapreduce unit that

718
00:36:57,599 --> 00:36:58,960
implements the patterns that i just

719
00:36:58,960 --> 00:37:00,800
described so

720
00:37:00,800 --> 00:37:01,839
the

721
00:37:01,839 --> 00:37:04,079
the we still have our typical

722
00:37:04,079 --> 00:37:06,000
programmable elements we have a

723
00:37:06,000 --> 00:37:08,240
programmable packet parser match action

724
00:37:08,240 --> 00:37:10,320
tables and traffic manager but you can

725
00:37:10,320 --> 00:37:12,880
see in the center we have this mapreduce

726
00:37:12,880 --> 00:37:14,880
unit and that's essentially what's going

727
00:37:14,880 --> 00:37:18,000
to do our machine learning inference and

728
00:37:18,000 --> 00:37:19,920
so there are a couple uh little

729
00:37:19,920 --> 00:37:22,400
idiosyncrasies about the um the

730
00:37:22,400 --> 00:37:23,680
arrangement of the pipeline that i want

731
00:37:23,680 --> 00:37:26,400
to point out and uh and that's how we

732
00:37:26,400 --> 00:37:28,160
use these different elements

733
00:37:28,160 --> 00:37:29,839
for machine learning context even if

734
00:37:29,839 --> 00:37:32,480
they're typically uh network elements so

735
00:37:32,480 --> 00:37:34,320
a packet parser is normally for pulling

736
00:37:34,320 --> 00:37:37,680
out your headers from your packets

737
00:37:37,680 --> 00:37:39,280
and doing whatever you want with your

738
00:37:39,280 --> 00:37:41,359
match action rules in this case packet

739
00:37:41,359 --> 00:37:43,520
parsing is also pulling out the features

740
00:37:43,520 --> 00:37:45,520
for our machine learning

741
00:37:45,520 --> 00:37:47,520
inference and then we have match action

742
00:37:47,520 --> 00:37:50,079
tables before and after the mapreduce

743
00:37:50,079 --> 00:37:52,320
unit and so these are doing

744
00:37:52,320 --> 00:37:54,720
different types of rule-based pre and

745
00:37:54,720 --> 00:37:57,119
post-processing on our machine learning

746
00:37:57,119 --> 00:38:00,400
inputs and outputs so uh the

747
00:38:00,400 --> 00:38:02,880
match action tables before mapreduce can

748
00:38:02,880 --> 00:38:04,480
be doing some sort of cleaning on the

749
00:38:04,480 --> 00:38:06,640
features and then the match action

750
00:38:06,640 --> 00:38:09,520
tables on the output

751
00:38:09,520 --> 00:38:11,520
on the right side of the mapreduce unit

752
00:38:11,520 --> 00:38:14,160
can be doing some sort of interpretation

753
00:38:14,160 --> 00:38:15,839
of the results

754
00:38:15,839 --> 00:38:16,800
and

755
00:38:16,800 --> 00:38:17,599
so

756
00:38:17,599 --> 00:38:19,280
when we actually went to design this

757
00:38:19,280 --> 00:38:21,359
mapreduce unit um

758
00:38:21,359 --> 00:38:23,760
there's a couple of things that came up

759
00:38:23,760 --> 00:38:25,920
it turns out you can't really just stick

760
00:38:25,920 --> 00:38:29,200
an accelerator into the switch pipeline

761
00:38:29,200 --> 00:38:30,560
so

762
00:38:30,560 --> 00:38:33,359
uh what we did was we kind of

763
00:38:33,359 --> 00:38:35,119
established what were the the points

764
00:38:35,119 --> 00:38:37,359
that we wanted our mapreduce block to

765
00:38:37,359 --> 00:38:38,320
fit

766
00:38:38,320 --> 00:38:40,480
and so most of all we wanted it to be

767
00:38:40,480 --> 00:38:42,720
reconfigurable so essentially you should

768
00:38:42,720 --> 00:38:45,040
be able to program it it can't be a an

769
00:38:45,040 --> 00:38:47,119
asic for a single type of machine

770
00:38:47,119 --> 00:38:48,640
learning application you should be able

771
00:38:48,640 --> 00:38:51,280
to put in whatever or program whatever

772
00:38:51,280 --> 00:38:54,960
application you want oops

773
00:38:55,760 --> 00:38:57,119
and

774
00:38:57,119 --> 00:38:58,480
it has some meat line rate with the

775
00:38:58,480 --> 00:39:00,480
fixed clock so

776
00:39:00,480 --> 00:39:03,680
this essentially uh rules out an fpga

777
00:39:03,680 --> 00:39:05,200
makes an fpga will give you a variable

778
00:39:05,200 --> 00:39:06,240
clock

779
00:39:06,240 --> 00:39:09,280
we want it to be deterministic um

780
00:39:09,280 --> 00:39:11,440
and of course line rate is our

781
00:39:11,440 --> 00:39:13,119
performance requirement

782
00:39:13,119 --> 00:39:16,160
and then minimal area and power overhead

783
00:39:16,160 --> 00:39:18,160
we don't want to blow up the entire chip

784
00:39:18,160 --> 00:39:20,160
area adding in

785
00:39:20,160 --> 00:39:23,359
like a a map reduced block it should be

786
00:39:23,359 --> 00:39:24,960
something that is

787
00:39:24,960 --> 00:39:27,680
small but gives you access to a whole

788
00:39:27,680 --> 00:39:30,320
class of applications

789
00:39:30,320 --> 00:39:32,240
and so finally the

790
00:39:32,240 --> 00:39:34,160
one little thing to note here that's

791
00:39:34,160 --> 00:39:36,000
kind of interesting is that

792
00:39:36,000 --> 00:39:38,079
most of these ml accelerators are built

793
00:39:38,079 --> 00:39:39,280
to do

794
00:39:39,280 --> 00:39:41,520
batch processing in an effort to get

795
00:39:41,520 --> 00:39:44,400
high throughput but in the network

796
00:39:44,400 --> 00:39:46,160
pipeline you're actually

797
00:39:46,160 --> 00:39:48,400
processing packets as they're coming

798
00:39:48,400 --> 00:39:50,640
which means that you're operating on a

799
00:39:50,640 --> 00:39:52,800
batch size of one

800
00:39:52,800 --> 00:39:55,359
which is uh turns out

801
00:39:55,359 --> 00:39:56,720
puts a lot of different performance

802
00:39:56,720 --> 00:39:59,280
demands on the hardware than a typical

803
00:39:59,280 --> 00:40:02,480
accelerator would see

804
00:40:03,359 --> 00:40:04,160
uh

805
00:40:04,160 --> 00:40:06,160
yeah so um

806
00:40:06,160 --> 00:40:07,599
i have a quick example here just to make

807
00:40:07,599 --> 00:40:09,119
this a little more concrete going back

808
00:40:09,119 --> 00:40:11,839
to anomaly detection

809
00:40:11,839 --> 00:40:13,119
um

810
00:40:13,119 --> 00:40:15,920
so you can you can uh imagine say a

811
00:40:15,920 --> 00:40:17,920
packet coming into the switch pipeline

812
00:40:17,920 --> 00:40:19,599
and we want to see essentially whether

813
00:40:19,599 --> 00:40:21,920
it's malicious or benign

814
00:40:21,920 --> 00:40:25,599
so the packet hits the first stage and

815
00:40:25,599 --> 00:40:28,319
that's where we're going to um do our

816
00:40:28,319 --> 00:40:30,079
packet parsing so we're going to read

817
00:40:30,079 --> 00:40:31,520
local features

818
00:40:31,520 --> 00:40:33,200
say our ip

819
00:40:33,200 --> 00:40:35,040
whatever information we can extract from

820
00:40:35,040 --> 00:40:36,560
the packet itself

821
00:40:36,560 --> 00:40:38,240
the packet is going to move to the

822
00:40:38,240 --> 00:40:40,000
second stage which are the match action

823
00:40:40,000 --> 00:40:41,040
tables

824
00:40:41,040 --> 00:40:43,440
and from there maybe we're going to do

825
00:40:43,440 --> 00:40:45,440
some sort of uh retrieval of

826
00:40:45,440 --> 00:40:47,040
out-of-network events so these would be

827
00:40:47,040 --> 00:40:49,440
different kinds of uh elements of

828
00:40:49,440 --> 00:40:51,200
metadata that the control plane may have

829
00:40:51,200 --> 00:40:53,760
installed into the match action tables

830
00:40:53,760 --> 00:40:55,680
so something like the failed logins per

831
00:40:55,680 --> 00:40:56,960
ip

832
00:40:56,960 --> 00:40:59,040
the packet then moves to the the center

833
00:40:59,040 --> 00:41:01,119
block the mapreduce unit that's where

834
00:41:01,119 --> 00:41:02,720
we're going to apply our learned anomaly

835
00:41:02,720 --> 00:41:04,560
detection so you can imagine this is

836
00:41:04,560 --> 00:41:06,240
maybe a binary neural network and it

837
00:41:06,240 --> 00:41:09,040
gives it a a score from zero to one on

838
00:41:09,040 --> 00:41:11,920
how anomalous it is so one is definitely

839
00:41:11,920 --> 00:41:14,400
anomalous zero is benign

840
00:41:14,400 --> 00:41:15,359
and

841
00:41:15,359 --> 00:41:17,359
finally the match action or the the

842
00:41:17,359 --> 00:41:19,440
packet will move to the post-processing

843
00:41:19,440 --> 00:41:21,839
match action tables and that's where we

844
00:41:21,839 --> 00:41:23,839
do our interpretation so say we got a

845
00:41:23,839 --> 00:41:26,640
score of 0.8 so it's pretty anomalous

846
00:41:26,640 --> 00:41:27,920
and

847
00:41:27,920 --> 00:41:30,160
now we want to drop it or quarantine it

848
00:41:30,160 --> 00:41:32,000
this is where the match action table

849
00:41:32,000 --> 00:41:34,319
will set a rule for that such that when

850
00:41:34,319 --> 00:41:35,920
the packet now moves to the traffic

851
00:41:35,920 --> 00:41:37,599
manager it's going to go to the

852
00:41:37,599 --> 00:41:40,800
appropriate destination

853
00:41:43,839 --> 00:41:46,000
so uh

854
00:41:46,000 --> 00:41:46,880
in the

855
00:41:46,880 --> 00:41:50,000
paper we actually did a full um asic

856
00:41:50,000 --> 00:41:51,119
analysis

857
00:41:51,119 --> 00:41:55,040
of uh this taurus hardware and how we

858
00:41:55,040 --> 00:41:56,160
can uh

859
00:41:56,160 --> 00:41:57,599
we wanted to show essentially that it

860
00:41:57,599 --> 00:41:59,520
has minimal overhead and it's feasible

861
00:41:59,520 --> 00:42:01,520
to to build something like this

862
00:42:01,520 --> 00:42:03,760
and so we based our evaluation platform

863
00:42:03,760 --> 00:42:06,079
on a coarse grain reconfigurable

864
00:42:06,079 --> 00:42:08,160
architecture called plasticine

865
00:42:08,160 --> 00:42:10,880
and we programmed our applications in

866
00:42:10,880 --> 00:42:12,480
the spatial hardware description

867
00:42:12,480 --> 00:42:15,119
language and so spatial is just an hdl

868
00:42:15,119 --> 00:42:18,079
that lets you um use these kind of uh

869
00:42:18,079 --> 00:42:21,280
parallel patterns like map and reduce to

870
00:42:21,280 --> 00:42:23,119
uh program your

871
00:42:23,119 --> 00:42:24,319
um

872
00:42:24,319 --> 00:42:27,119
your your reconfigurable architectures

873
00:42:27,119 --> 00:42:30,319
uh at the loop level and so the the

874
00:42:30,319 --> 00:42:32,319
basic architecture of the mapreduce unit

875
00:42:32,319 --> 00:42:34,880
here is really just a grid of compute

876
00:42:34,880 --> 00:42:39,040
and memory tiles so easily scalable and

877
00:42:39,040 --> 00:42:40,960
very very straightforward

878
00:42:40,960 --> 00:42:44,319
in the compute units we have cindy lanes

879
00:42:44,319 --> 00:42:46,720
that are operating in parallel and a

880
00:42:46,720 --> 00:42:48,720
reduction network that allows us to

881
00:42:48,720 --> 00:42:51,119
implement the reduce operation and the

882
00:42:51,119 --> 00:42:53,760
memory units are just um blocks of

883
00:42:53,760 --> 00:42:55,280
banked sram

884
00:42:55,280 --> 00:42:56,000
so

885
00:42:56,000 --> 00:42:57,280
uh we're doing

886
00:42:57,280 --> 00:42:59,520
severe pipelining within the compute

887
00:42:59,520 --> 00:43:01,040
unit but then we're also doing

888
00:43:01,040 --> 00:43:03,119
pipelining one level higher between the

889
00:43:03,119 --> 00:43:05,280
compute and memory units so the idea

890
00:43:05,280 --> 00:43:08,560
here is cindy parallelism everywhere

891
00:43:08,560 --> 00:43:10,240
uh and then pipeline parallelism

892
00:43:10,240 --> 00:43:11,680
everywhere and that's how you get your

893
00:43:11,680 --> 00:43:14,640
performance really

894
00:43:16,960 --> 00:43:17,680
so

895
00:43:17,680 --> 00:43:18,560
uh

896
00:43:18,560 --> 00:43:21,359
we went through a set of real world

897
00:43:21,359 --> 00:43:22,640
applications

898
00:43:22,640 --> 00:43:27,119
and um programmed them onto our asic and

899
00:43:27,119 --> 00:43:29,200
we ended up using a 12x10 grid to

900
00:43:29,200 --> 00:43:30,720
support all of them

901
00:43:30,720 --> 00:43:32,079
and

902
00:43:32,079 --> 00:43:33,920
we compared it to state-of-the-art

903
00:43:33,920 --> 00:43:37,520
switches with four uh pipelines

904
00:43:37,520 --> 00:43:39,280
and um

905
00:43:39,280 --> 00:43:41,680
our reference which was 500 square

906
00:43:41,680 --> 00:43:43,359
millimeters and

907
00:43:43,359 --> 00:43:45,280
we found that our grid which could

908
00:43:45,280 --> 00:43:47,040
support these different applications was

909
00:43:47,040 --> 00:43:49,920
only adding a 3.8 percent overhead or

910
00:43:49,920 --> 00:43:52,240
4.8 millimeters per pipeline

911
00:43:52,240 --> 00:43:55,599
so um again before uh earlier i said we

912
00:43:55,599 --> 00:43:59,119
want minimal area overhead so 3.8 is

913
00:43:59,119 --> 00:44:01,680
pretty low given that you're now getting

914
00:44:01,680 --> 00:44:03,760
an entire class of machine learning

915
00:44:03,760 --> 00:44:06,760
applications

916
00:44:08,480 --> 00:44:10,880
and jumping into one of these uh

917
00:44:10,880 --> 00:44:12,880
applications i've been using anomaly

918
00:44:12,880 --> 00:44:16,480
detection as a recurring example here um

919
00:44:16,480 --> 00:44:18,000
we tried out two different types of

920
00:44:18,000 --> 00:44:20,160
anomaly detection with support vector

921
00:44:20,160 --> 00:44:22,640
machines and a deep neural network

922
00:44:22,640 --> 00:44:25,040
and so uh

923
00:44:25,040 --> 00:44:26,560
for both models you can see in the

924
00:44:26,560 --> 00:44:28,880
throughput it's one gigabyte per second

925
00:44:28,880 --> 00:44:32,160
which is the line rate for um

926
00:44:32,160 --> 00:44:34,800
high end uh switch pipelines like your

927
00:44:34,800 --> 00:44:37,839
tofinos and broadcoms uh the latency

928
00:44:37,839 --> 00:44:40,720
that we added was in the um hundreds of

929
00:44:40,720 --> 00:44:42,800
nanoseconds or less

930
00:44:42,800 --> 00:44:44,800
so in this case you would choose your

931
00:44:44,800 --> 00:44:46,560
application you can see here that the

932
00:44:46,560 --> 00:44:49,040
bsvm requires 83 nanoseconds while the

933
00:44:49,040 --> 00:44:52,160
dnn requires 221 nanoseconds so

934
00:44:52,160 --> 00:44:54,000
depending on your slos and what kind of

935
00:44:54,000 --> 00:44:55,920
requirements you have to meet you can

936
00:44:55,920 --> 00:44:59,280
choose your algorithm to reduce latency

937
00:44:59,280 --> 00:45:00,160
um

938
00:45:00,160 --> 00:45:02,640
and then in both cases the area and

939
00:45:02,640 --> 00:45:05,200
power overhead required for the hardware

940
00:45:05,200 --> 00:45:07,839
to implement just these applications

941
00:45:07,839 --> 00:45:09,440
is um

942
00:45:09,440 --> 00:45:14,319
single digits or uh or less of 0.6

943
00:45:14,319 --> 00:45:16,960
power overhead 0.5 area overhead or

944
00:45:16,960 --> 00:45:19,119
point eight and point uh and 1.0

945
00:45:19,119 --> 00:45:20,960
respectively

946
00:45:20,960 --> 00:45:22,079
again

947
00:45:22,079 --> 00:45:24,560
if you don't need um

948
00:45:24,560 --> 00:45:26,800
say the full suite of benchmarks you

949
00:45:26,800 --> 00:45:29,680
only want a reconfigurable fabric that

950
00:45:29,680 --> 00:45:31,599
will let you do anomaly detection you

951
00:45:31,599 --> 00:45:34,160
can do it with um

952
00:45:34,160 --> 00:45:36,480
minimal overhead here and so

953
00:45:36,480 --> 00:45:38,480
in the paper there's a

954
00:45:38,480 --> 00:45:40,480
several more applications if people are

955
00:45:40,480 --> 00:45:42,640
are interested such as

956
00:45:42,640 --> 00:45:44,640
a congestion control network and a

957
00:45:44,640 --> 00:45:48,240
traffic classification network

958
00:45:52,240 --> 00:45:52,960
so

959
00:45:52,960 --> 00:45:54,319
uh

960
00:45:54,319 --> 00:45:55,839
we went through this whole process of

961
00:45:55,839 --> 00:45:59,119
doing an asic analysis to prove that it

962
00:45:59,119 --> 00:46:02,480
could be done um but as far as research

963
00:46:02,480 --> 00:46:05,040
goes we don't really want anyone waiting

964
00:46:05,040 --> 00:46:07,119
for some sort of mass-produced taurus

965
00:46:07,119 --> 00:46:09,839
asic so we've put out an open source

966
00:46:09,839 --> 00:46:12,960
fpga based test bed um and so this is

967
00:46:12,960 --> 00:46:14,720
just a rough diagram of what it looks

968
00:46:14,720 --> 00:46:17,839
like um at the control plane we're using

969
00:46:17,839 --> 00:46:22,160
um your typical network os like onos um

970
00:46:22,160 --> 00:46:25,040
we're using a tofino switch to to mimic

971
00:46:25,040 --> 00:46:25,760
the

972
00:46:25,760 --> 00:46:27,280
piece of pipeline elements like your

973
00:46:27,280 --> 00:46:29,839
programmable packet parsers match action

974
00:46:29,839 --> 00:46:31,760
tables and traffic managers and then

975
00:46:31,760 --> 00:46:35,839
we're using an fpga to um

976
00:46:35,839 --> 00:46:38,079
to mimic the mapreduce unit so we set it

977
00:46:38,079 --> 00:46:39,440
up in this bump in the wire

978
00:46:39,440 --> 00:46:40,880
configuration

979
00:46:40,880 --> 00:46:42,720
um and so

980
00:46:42,720 --> 00:46:43,599
uh

981
00:46:43,599 --> 00:46:45,200
because of the limits of an fpga you're

982
00:46:45,200 --> 00:46:46,720
not going to be able to hit the same

983
00:46:46,720 --> 00:46:48,880
performance as you're going to get with

984
00:46:48,880 --> 00:46:50,079
the asic

985
00:46:50,079 --> 00:46:52,079
uh core screen reconfigurable

986
00:46:52,079 --> 00:46:53,440
architecture

987
00:46:53,440 --> 00:46:55,839
but it's there to serve

988
00:46:55,839 --> 00:46:57,920
as a proof of concept for the

989
00:46:57,920 --> 00:47:00,720
functionality

990
00:47:03,680 --> 00:47:06,400
so just a quick demonstration of this

991
00:47:06,400 --> 00:47:08,319
testbed

992
00:47:08,319 --> 00:47:10,400
we did an example

993
00:47:10,400 --> 00:47:11,760
essentially the example i mentioned

994
00:47:11,760 --> 00:47:13,920
earlier about anomaly detection where

995
00:47:13,920 --> 00:47:15,599
we're trying to do

996
00:47:15,599 --> 00:47:17,599
uh detection of anomalous packets in the

997
00:47:17,599 --> 00:47:19,040
control plane

998
00:47:19,040 --> 00:47:22,240
or we're trying to use taurus and do an

999
00:47:22,240 --> 00:47:24,720
uh anomaly detection in the data plane

1000
00:47:24,720 --> 00:47:26,319
and so with the testbed that i just

1001
00:47:26,319 --> 00:47:29,839
showed you you can do um

1002
00:47:29,839 --> 00:47:31,920
you can do either so you so in the case

1003
00:47:31,920 --> 00:47:34,720
of taurus we'd be uh placing our anomaly

1004
00:47:34,720 --> 00:47:37,760
detection application on the fpga

1005
00:47:37,760 --> 00:47:39,839
while if we're trying to do control

1006
00:47:39,839 --> 00:47:42,079
plane based anomaly detection we would

1007
00:47:42,079 --> 00:47:44,880
run it at the uh the controller on the

1008
00:47:44,880 --> 00:47:47,359
cpu

1009
00:47:47,680 --> 00:47:48,720
so

1010
00:47:48,720 --> 00:47:51,119
uh the takeaway here is is the same sort

1011
00:47:51,119 --> 00:47:52,400
of message on

1012
00:47:52,400 --> 00:47:54,960
um why you really can't

1013
00:47:54,960 --> 00:47:58,720
use the control plane for efficient um

1014
00:47:58,720 --> 00:48:01,359
machine learning just based uh decision

1015
00:48:01,359 --> 00:48:02,400
making

1016
00:48:02,400 --> 00:48:06,720
and um if you take a look at the very

1017
00:48:06,720 --> 00:48:09,760
last two columns the f1 score

1018
00:48:09,760 --> 00:48:12,480
um now this is the f1 score

1019
00:48:12,480 --> 00:48:13,280
for

1020
00:48:13,280 --> 00:48:15,760
the model when it was implemented on the

1021
00:48:15,760 --> 00:48:17,359
baseline which is a control plane or

1022
00:48:17,359 --> 00:48:20,000
taurus which was in the data plane and

1023
00:48:20,000 --> 00:48:21,680
in software

1024
00:48:21,680 --> 00:48:26,240
in tensorflow uh the f1 score is 71.1 so

1025
00:48:26,240 --> 00:48:28,720
you can see that taurus on the far right

1026
00:48:28,720 --> 00:48:30,720
side of the uh

1027
00:48:30,720 --> 00:48:32,640
the uh the table

1028
00:48:32,640 --> 00:48:35,280
is achieving an f1 score of 71.1 so it's

1029
00:48:35,280 --> 00:48:38,400
faithfully recreating the model as it

1030
00:48:38,400 --> 00:48:42,640
was in software and um we're processing

1031
00:48:42,640 --> 00:48:44,480
packets as they're coming in

1032
00:48:44,480 --> 00:48:46,480
whereas in the control plane we actually

1033
00:48:46,480 --> 00:48:47,520
had to

1034
00:48:47,520 --> 00:48:51,280
sample packets from the network and um

1035
00:48:51,280 --> 00:48:53,280
run it through the control plane and run

1036
00:48:53,280 --> 00:48:56,160
it through an ml framework and try to

1037
00:48:56,160 --> 00:48:58,720
install flow rules and what ends up

1038
00:48:58,720 --> 00:49:01,200
happening is that you miss so many

1039
00:49:01,200 --> 00:49:04,000
packets while doing this operation that

1040
00:49:04,000 --> 00:49:06,880
your effective f1 score uh drops pretty

1041
00:49:06,880 --> 00:49:09,680
heavily so you can see on the far right

1042
00:49:09,680 --> 00:49:12,640
column the f1 score for the baseline

1043
00:49:12,640 --> 00:49:16,559
ranges from 1.5 to almost almost zero

1044
00:49:16,559 --> 00:49:17,440
so

1045
00:49:17,440 --> 00:49:19,280
you're effectively throwing away your

1046
00:49:19,280 --> 00:49:23,200
model because of the added latency

1047
00:49:23,200 --> 00:49:25,599
so that's just uh one example of what

1048
00:49:25,599 --> 00:49:27,280
you know what we did with our fpga

1049
00:49:27,280 --> 00:49:29,040
testbed um

1050
00:49:29,040 --> 00:49:30,400
there's of course lots of other things

1051
00:49:30,400 --> 00:49:32,720
you can do but the just to reinforce the

1052
00:49:32,720 --> 00:49:34,559
point why you have to operate in the

1053
00:49:34,559 --> 00:49:37,119
data plane

1054
00:49:39,440 --> 00:49:40,880
cool so

1055
00:49:40,880 --> 00:49:43,520
yeah so that's mostly it uh for me um i

1056
00:49:43,520 --> 00:49:46,720
have my contact information here and i

1057
00:49:46,720 --> 00:49:50,000
have at the bottom the git lab link for

1058
00:49:50,000 --> 00:49:53,119
the fpga testbed we hope people wanna

1059
00:49:53,119 --> 00:49:55,440
can uh try it out and there's the link

1060
00:49:55,440 --> 00:49:58,559
to the full paper in this easy to

1061
00:49:58,559 --> 00:50:00,720
memorize url

1062
00:50:00,720 --> 00:50:01,440
so

1063
00:50:01,440 --> 00:50:02,559
uh

1064
00:50:02,559 --> 00:50:06,480
yeah i'm happy to take any questions

1065
00:50:07,200 --> 00:50:10,559
okay uh thank you very much

1066
00:50:10,559 --> 00:50:13,520
the excellent talk um

1067
00:50:13,520 --> 00:50:16,400
since we we have a some people remote

1068
00:50:16,400 --> 00:50:18,400
some in the room i think if if we can

1069
00:50:18,400 --> 00:50:21,599
manage the queue using meet echo uh me

1070
00:50:21,599 --> 00:50:23,119
take a queueing tool i think that would

1071
00:50:23,119 --> 00:50:24,319
be helpful

1072
00:50:24,319 --> 00:50:27,040
uh i do see i guess it's barry at the

1073
00:50:27,040 --> 00:50:29,839
microphone there

1074
00:50:30,240 --> 00:50:32,559
okay actually i'm being uh dave or am

1075
00:50:32,559 --> 00:50:35,839
right now um dave iran asks i assume the

1076
00:50:35,839 --> 00:50:38,160
class of anomalies you can detect are

1077
00:50:38,160 --> 00:50:40,000
those that can be detected by header

1078
00:50:40,000 --> 00:50:42,480
fields within the width of the alu of

1079
00:50:42,480 --> 00:50:43,839
the switch

1080
00:50:43,839 --> 00:50:45,440
things in the packet data beyond the

1081
00:50:45,440 --> 00:50:48,240
headers won't be seen is that correct um

1082
00:50:48,240 --> 00:50:51,040
so the in the case of anomaly detection

1083
00:50:51,040 --> 00:50:52,559
we used

1084
00:50:52,559 --> 00:50:55,680
the kde nsl data set which had a a

1085
00:50:55,680 --> 00:50:57,920
record of different um

1086
00:50:57,920 --> 00:51:00,559
attacks that were calculated from like

1087
00:51:00,559 --> 00:51:02,640
you said either header fields or

1088
00:51:02,640 --> 00:51:03,599
um

1089
00:51:03,599 --> 00:51:05,599
you can also actually calculate

1090
00:51:05,599 --> 00:51:07,760
aggregate fields from across headers so

1091
00:51:07,760 --> 00:51:10,160
you can um

1092
00:51:10,160 --> 00:51:12,400
say create like a histogram using the

1093
00:51:12,400 --> 00:51:14,160
matte checking tables across different

1094
00:51:14,160 --> 00:51:15,839
packets um

1095
00:51:15,839 --> 00:51:16,559
and

1096
00:51:16,559 --> 00:51:18,559
the the packets the

1097
00:51:18,559 --> 00:51:19,760
the packet

1098
00:51:19,760 --> 00:51:22,319
headers um are going to be limited by

1099
00:51:22,319 --> 00:51:24,400
the packet header vector size that's

1100
00:51:24,400 --> 00:51:26,480
moving between stages in the switch

1101
00:51:26,480 --> 00:51:28,880
pipeline but you don't necessarily need

1102
00:51:28,880 --> 00:51:31,839
to be limited to features in the header

1103
00:51:31,839 --> 00:51:34,240
because the control plane can install

1104
00:51:34,240 --> 00:51:35,839
different types of metadata into the

1105
00:51:35,839 --> 00:51:37,920
imagination tables and you can do your

1106
00:51:37,920 --> 00:51:41,200
own um processing in the match action

1107
00:51:41,200 --> 00:51:45,119
tables um over time or whatever other

1108
00:51:45,119 --> 00:51:46,559
kind of calculations you want to do on

1109
00:51:46,559 --> 00:51:48,319
your headers so the headers are just the

1110
00:51:48,319 --> 00:51:53,279
starting point for the the features here

1111
00:51:56,000 --> 00:51:56,960
hi

1112
00:51:56,960 --> 00:51:59,680
is this working yeah

1113
00:51:59,680 --> 00:52:02,559
george michaelson can i say

1114
00:52:02,559 --> 00:52:05,119
can i sneak two questions in is that

1115
00:52:05,119 --> 00:52:06,559
okay yeah

1116
00:52:06,559 --> 00:52:10,000
so the first one and this is the naive

1117
00:52:10,000 --> 00:52:12,880
attendee question i suspect the paper is

1118
00:52:12,880 --> 00:52:14,960
very important for interpreting that

1119
00:52:14,960 --> 00:52:16,480
last table

1120
00:52:16,480 --> 00:52:18,800
it was really quite opaque how to

1121
00:52:18,800 --> 00:52:21,599
understand the meaning of the columns

1122
00:52:21,599 --> 00:52:24,319
and their impact on a comparison to the

1123
00:52:24,319 --> 00:52:25,839
baseline i think there's a lot of

1124
00:52:25,839 --> 00:52:28,400
implicit knowledge in your table

1125
00:52:28,400 --> 00:52:30,800
structure i'm sure the paper explains it

1126
00:52:30,800 --> 00:52:32,559
the slideway it was just a bit of

1127
00:52:32,559 --> 00:52:35,119
produce to a naive reader

1128
00:52:35,119 --> 00:52:37,119
so at the start of your talk that was

1129
00:52:37,119 --> 00:52:39,440
the first point you made a

1130
00:52:39,440 --> 00:52:42,240
case to say that the delay between doing

1131
00:52:42,240 --> 00:52:44,720
a packet sample constructing

1132
00:52:44,720 --> 00:52:46,640
table match rules in the controller

1133
00:52:46,640 --> 00:52:49,200
injecting those rules down into the

1134
00:52:49,200 --> 00:52:51,680
functional plane and applying them had a

1135
00:52:51,680 --> 00:52:53,119
huge packet

1136
00:52:53,119 --> 00:52:56,160
loss and mismatch interval but it seems

1137
00:52:56,160 --> 00:52:57,200
to me

1138
00:52:57,200 --> 00:52:59,920
the delay to perform the ml operation

1139
00:52:59,920 --> 00:53:02,640
tune your ml have a model that is

1140
00:53:02,640 --> 00:53:04,640
representative of the condition you want

1141
00:53:04,640 --> 00:53:07,520
to model and then install that has a

1142
00:53:07,520 --> 00:53:09,440
similar cost

1143
00:53:09,440 --> 00:53:11,760
it's not to say there's no benefit of ml

1144
00:53:11,760 --> 00:53:13,920
i think it's huge but the component

1145
00:53:13,920 --> 00:53:16,160
that's about the delay cost of doing an

1146
00:53:16,160 --> 00:53:19,040
instantiation of rules i don't think is

1147
00:53:19,040 --> 00:53:21,200
the basis of doing it i think you're on

1148
00:53:21,200 --> 00:53:23,040
stronger ground arguing it's about the

1149
00:53:23,040 --> 00:53:26,559
ability to do complex match at line rate

1150
00:53:26,559 --> 00:53:28,720
than the static cost of doing the rule

1151
00:53:28,720 --> 00:53:30,160
installation

1152
00:53:30,160 --> 00:53:31,440
right so

1153
00:53:31,440 --> 00:53:33,520
um the installation you're right about

1154
00:53:33,520 --> 00:53:35,599
the installing the model itself so the

1155
00:53:35,599 --> 00:53:37,599
idea is that you could be taking

1156
00:53:37,599 --> 00:53:40,160
sampling uh packets from the your

1157
00:53:40,160 --> 00:53:42,079
network and be sending different kinds

1158
00:53:42,079 --> 00:53:43,839
of metadata to the control plane and

1159
00:53:43,839 --> 00:53:45,200
essentially be doing your training

1160
00:53:45,200 --> 00:53:47,760
offline and you can install model

1161
00:53:47,760 --> 00:53:50,319
weights or replace model weights

1162
00:53:50,319 --> 00:53:53,040
as uh as needed the idea is that

1163
00:53:53,040 --> 00:53:55,200
whatever is operating in the data plane

1164
00:53:55,200 --> 00:53:57,359
itself has nothing to do with the

1165
00:53:57,359 --> 00:53:58,960
installation of model weights yeah

1166
00:53:58,960 --> 00:54:01,280
completely agnostic and i thought i

1167
00:54:01,280 --> 00:54:02,880
thought that idea that you could do the

1168
00:54:02,880 --> 00:54:05,200
model training asynchronously the sample

1169
00:54:05,200 --> 00:54:07,599
exactly is very beneficial but if you

1170
00:54:07,599 --> 00:54:10,319
consider a new class of attack that you

1171
00:54:10,319 --> 00:54:12,960
have to understand it and do some form

1172
00:54:12,960 --> 00:54:15,359
of bayesian analysis and classification

1173
00:54:15,359 --> 00:54:17,520
which is completely unmodeled here

1174
00:54:17,520 --> 00:54:20,800
exactly how you do that training unknown

1175
00:54:20,800 --> 00:54:22,960
how long that takes it's not about the

1176
00:54:22,960 --> 00:54:24,800
speed of the chipset it's about your

1177
00:54:24,800 --> 00:54:26,720
ability to do the good bad

1178
00:54:26,720 --> 00:54:29,599
classification a priory to inform the

1179
00:54:29,599 --> 00:54:32,319
model and then download it that's quite

1180
00:54:32,319 --> 00:54:35,040
a high cost in time

1181
00:54:35,040 --> 00:54:37,040
yeah so so this is always like kind of

1182
00:54:37,040 --> 00:54:39,359
the uh the trouble with security rate

1183
00:54:39,359 --> 00:54:41,760
like if you want to do an on-the-fly

1184
00:54:41,760 --> 00:54:44,240
analysis of a brand new attack that's

1185
00:54:44,240 --> 00:54:46,640
not really uh what we're what we're

1186
00:54:46,640 --> 00:54:48,319
targeting at the moment here

1187
00:54:48,319 --> 00:54:50,559
but uh but in engineering terms your

1188
00:54:50,559 --> 00:54:53,040
case this is extremely fast at line

1189
00:54:53,040 --> 00:54:55,520
right well made i enjoyed listening to

1190
00:54:55,520 --> 00:54:56,720
it a lot

1191
00:54:56,720 --> 00:54:59,598
thank you thank you

1192
00:55:01,040 --> 00:55:02,319
so

1193
00:55:02,319 --> 00:55:05,280
excellent work to share

1194
00:55:05,280 --> 00:55:06,880
i have a question

1195
00:55:06,880 --> 00:55:09,119
doing machine learning and data blend

1196
00:55:09,119 --> 00:55:12,240
will consume more energy

1197
00:55:12,240 --> 00:55:15,118
oh sorry i can't

1198
00:55:15,440 --> 00:55:17,920
using machine learning in the data plane

1199
00:55:17,920 --> 00:55:20,720
will consume more energy

1200
00:55:20,720 --> 00:55:22,720
so and we would like to reduce the

1201
00:55:22,720 --> 00:55:24,559
energy consumption of filters and

1202
00:55:24,559 --> 00:55:25,680
switches

1203
00:55:25,680 --> 00:55:28,160
so have you looked at this issue yeah so

1204
00:55:28,160 --> 00:55:29,200
i think the

1205
00:55:29,200 --> 00:55:30,000
the

1206
00:55:30,000 --> 00:55:30,799
for

1207
00:55:30,799 --> 00:55:33,040
energy consumption needs to be looked at

1208
00:55:33,040 --> 00:55:35,760
maybe more holistically so while you are

1209
00:55:35,760 --> 00:55:39,359
increasing by some small percentage the

1210
00:55:39,359 --> 00:55:41,760
energy that you'd be consuming in the

1211
00:55:41,760 --> 00:55:44,240
the switch itself you can consider that

1212
00:55:44,240 --> 00:55:46,079
say if you're doing anomaly detection

1213
00:55:46,079 --> 00:55:47,440
you're removing

1214
00:55:47,440 --> 00:55:49,920
the cost of running an anomaly detection

1215
00:55:49,920 --> 00:55:51,680
application and software on a server

1216
00:55:51,680 --> 00:55:53,040
somewhere else

1217
00:55:53,040 --> 00:55:55,599
so with this like specialized hardware

1218
00:55:55,599 --> 00:55:57,839
here you're consuming less power

1219
00:55:57,839 --> 00:56:00,240
in the switch than you would running it

1220
00:56:00,240 --> 00:56:02,799
in software elsewhere so

1221
00:56:02,799 --> 00:56:04,160
on the whole

1222
00:56:04,160 --> 00:56:06,640
you're reducing power cost but for the

1223
00:56:06,640 --> 00:56:08,480
switch itself yeah you'd be increasing

1224
00:56:08,480 --> 00:56:13,079
it minimally okay thank you

1225
00:56:16,319 --> 00:56:20,400
okay thank you uh when i have questions

1226
00:56:20,400 --> 00:56:23,440
but for sure

1227
00:56:25,000 --> 00:56:26,079
[Music]

1228
00:56:26,079 --> 00:56:27,200
and i guess

1229
00:56:27,200 --> 00:56:30,480
while we're waiting at the

1230
00:56:31,839 --> 00:56:33,920
this is a an irtf

1231
00:56:33,920 --> 00:56:36,000
uh meeting which is which is co-locating

1232
00:56:36,000 --> 00:56:38,880
with the ietf um

1233
00:56:38,880 --> 00:56:41,280
and obviously you know since that this

1234
00:56:41,280 --> 00:56:42,799
communicates with the itf the question

1235
00:56:42,799 --> 00:56:45,119
is then you know to what extent have you

1236
00:56:45,119 --> 00:56:47,599
given any thought towards how that how

1237
00:56:47,599 --> 00:56:50,880
this might change or affect the type of

1238
00:56:50,880 --> 00:56:53,280
work the ietf does

1239
00:56:53,280 --> 00:56:54,880
are there any implications of these

1240
00:56:54,880 --> 00:56:57,680
types of systems so for the way

1241
00:56:57,680 --> 00:56:59,920
way we design standards or other types

1242
00:56:59,920 --> 00:57:01,200
of protocols

1243
00:57:01,200 --> 00:57:04,480
the itf designs or is this just a an

1244
00:57:04,480 --> 00:57:06,079
optimization that fits within the

1245
00:57:06,079 --> 00:57:08,480
existing architecture

1246
00:57:08,480 --> 00:57:10,000
yeah i think

1247
00:57:10,000 --> 00:57:10,880
so

1248
00:57:10,880 --> 00:57:13,200
one of the the things that uh actually

1249
00:57:13,200 --> 00:57:15,200
uh shamu who uh

1250
00:57:15,200 --> 00:57:16,799
asked a question earlier

1251
00:57:16,799 --> 00:57:17,680
um

1252
00:57:17,680 --> 00:57:19,839
brought to my attention was

1253
00:57:19,839 --> 00:57:23,520
that was what kind of um standardization

1254
00:57:23,520 --> 00:57:24,960
is needed for

1255
00:57:24,960 --> 00:57:27,119
packet headers if we're going to be

1256
00:57:27,119 --> 00:57:28,960
using them as

1257
00:57:28,960 --> 00:57:31,839
features or carrying model weights or

1258
00:57:31,839 --> 00:57:34,000
basically doing kind of this

1259
00:57:34,000 --> 00:57:38,480
like ml ml assist type operations um

1260
00:57:38,480 --> 00:57:40,000
so i think there's probably something

1261
00:57:40,000 --> 00:57:42,319
there as far as um

1262
00:57:42,319 --> 00:57:45,040
making a cleaner definition of what what

1263
00:57:45,040 --> 00:57:47,119
has to happen at the uh

1264
00:57:47,119 --> 00:57:50,640
the the packet standardization level um

1265
00:57:50,640 --> 00:57:52,559
to support this kind of machine learning

1266
00:57:52,559 --> 00:57:54,400
and make it

1267
00:57:54,400 --> 00:57:56,240
easier for different different types of

1268
00:57:56,240 --> 00:57:57,760
ml systems to

1269
00:57:57,760 --> 00:58:00,010
interoperate

1270
00:58:00,010 --> 00:58:02,880
[Music]

1271
00:58:02,880 --> 00:58:06,559
yeah that makes a lot of sense

1272
00:58:07,119 --> 00:58:08,720
presumably there's also something in

1273
00:58:08,720 --> 00:58:10,400
terms of the control plane and the

1274
00:58:10,400 --> 00:58:12,880
standardized um sort of programming

1275
00:58:12,880 --> 00:58:15,520
model for that in order to to

1276
00:58:15,520 --> 00:58:19,119
to specify the the model is that right

1277
00:58:19,119 --> 00:58:22,319
uh sorry very exciting

1278
00:58:22,319 --> 00:58:24,480
um i i i mean i'm thinking that your

1279
00:58:24,480 --> 00:58:27,280
traditional programmable switch uses p4

1280
00:58:27,280 --> 00:58:28,720
or something like that as a programming

1281
00:58:28,720 --> 00:58:30,960
model do do we need a similar

1282
00:58:30,960 --> 00:58:33,040
standardized programming model for these

1283
00:58:33,040 --> 00:58:36,319
types of ml switches

1284
00:58:36,319 --> 00:58:38,400
yeah so um

1285
00:58:38,400 --> 00:58:40,160
yeah so so it's like kind of a

1286
00:58:40,160 --> 00:58:43,680
compliment to to p4 um we went with

1287
00:58:43,680 --> 00:58:45,760
mapreduce so we're not necessarily

1288
00:58:45,760 --> 00:58:47,599
married to the idea of using

1289
00:58:47,599 --> 00:58:50,319
um a map produced blocker anything the

1290
00:58:50,319 --> 00:58:52,079
the bigger idea here is just doing

1291
00:58:52,079 --> 00:58:55,200
inference in the data plane um so but

1292
00:58:55,200 --> 00:58:56,720
yeah it could definitely help to have

1293
00:58:56,720 --> 00:58:59,040
some sort of standardization in the way

1294
00:58:59,040 --> 00:59:01,599
that p4 works but for

1295
00:59:01,599 --> 00:59:03,520
um the

1296
00:59:03,520 --> 00:59:05,599
the mapreduce element so

1297
00:59:05,599 --> 00:59:08,079
uh you could even consider like an extra

1298
00:59:08,079 --> 00:59:10,640
control block in p4 as mapreduce and we

1299
00:59:10,640 --> 00:59:12,160
actually we have another paper and

1300
00:59:12,160 --> 00:59:15,280
submission on um what the the language

1301
00:59:15,280 --> 00:59:17,520
level constructs here look like so yeah

1302
00:59:17,520 --> 00:59:19,520
there's that's definitely an area for

1303
00:59:19,520 --> 00:59:22,640
standardization as well

1304
00:59:24,559 --> 00:59:27,280
all right great thank you very much

1305
00:59:27,280 --> 00:59:31,559
are there any any final

1306
00:59:36,720 --> 00:59:39,119
okay i don't see anything screw thank

1307
00:59:39,119 --> 00:59:42,119
you

1308
00:59:46,079 --> 00:59:49,119
all right sam if you can come up while i

1309
00:59:49,119 --> 00:59:50,960
try and

1310
00:59:50,960 --> 00:59:54,440
share the slides

1311
01:00:07,140 --> 01:00:08,799
[Music]

1312
01:00:08,799 --> 01:00:12,240
all right so can you see the slides

1313
01:00:12,240 --> 01:00:14,720
yes we can see the slides here

1314
01:00:14,720 --> 01:00:17,118
okay

1315
01:00:19,359 --> 01:00:21,760
all right so with any luck you should

1316
01:00:21,760 --> 01:00:24,240
now have control of the

1317
01:00:24,240 --> 01:00:25,680
slide

1318
01:00:25,680 --> 01:00:29,078
they gone away

1319
01:00:34,160 --> 01:00:36,558
i see

1320
01:00:39,359 --> 01:00:40,839
so

1321
01:00:40,839 --> 01:00:44,400
that's is it working

1322
01:00:44,400 --> 01:00:46,640
i can see it on my oh yeah i see i had

1323
01:00:46,640 --> 01:00:48,640
to click share okay here we are just

1324
01:00:48,640 --> 01:00:50,880
took a little while yeah

1325
01:00:50,880 --> 01:00:53,119
okay scope

1326
01:00:53,119 --> 01:00:55,359
okay great all right so the second talk

1327
01:00:55,359 --> 01:00:57,200
today is um

1328
01:00:57,200 --> 01:00:58,880
focusing i think on a very different

1329
01:00:58,880 --> 01:01:01,760
problem domain um so in this talk sam

1330
01:01:01,760 --> 01:01:04,160
kumar will talk about his uh paper on

1331
01:01:04,160 --> 01:01:06,640
performance tcp for low power wireless

1332
01:01:06,640 --> 01:01:07,920
networks

1333
01:01:07,920 --> 01:01:10,160
uh this was originally presented at the

1334
01:01:10,160 --> 01:01:13,280
nsdi conference in 2020 if i don't if i

1335
01:01:13,280 --> 01:01:14,880
remember correctly

1336
01:01:14,880 --> 01:01:18,079
uh sam is a phd student at uc berkeley

1337
01:01:18,079 --> 01:01:22,319
uh advised by david culler and rolac

1338
01:01:22,319 --> 01:01:24,079
he's broadly interested in systems

1339
01:01:24,079 --> 01:01:26,640
security and networking and his research

1340
01:01:26,640 --> 01:01:29,040
focuses on rethinking systems designed

1341
01:01:29,040 --> 01:01:31,200
to manage the overhead uh using

1342
01:01:31,200 --> 01:01:33,920
cryptography uh and presumably also uh

1343
01:01:33,920 --> 01:01:36,079
improving the performance of tcp for

1344
01:01:36,079 --> 01:01:40,319
power wireless networks so um sam over

1345
01:01:40,319 --> 01:01:40,820
to you

1346
01:01:40,820 --> 01:01:42,799
[Music]

1347
01:01:42,799 --> 01:01:44,640
okay um thanks colin for the

1348
01:01:44,640 --> 01:01:46,960
introduction um as you said i'm sam and

1349
01:01:46,960 --> 01:01:48,960
i'm going to present my research on

1350
01:01:48,960 --> 01:01:50,799
performant tcp for low power wireless

1351
01:01:50,799 --> 01:01:52,880
networks and to join work with my

1352
01:01:52,880 --> 01:01:55,200
collaborators at uc berkeley and as you

1353
01:01:55,200 --> 01:01:57,680
mentioned it was published in 2020 at

1354
01:01:57,680 --> 01:01:58,799
nsdi

1355
01:01:58,799 --> 01:01:59,839
so

1356
01:01:59,839 --> 01:02:01,839
i'm going to begin by giving a brief

1357
01:02:01,839 --> 01:02:04,720
overview of of history of research in

1358
01:02:04,720 --> 01:02:06,240
low power wireless personal area

1359
01:02:06,240 --> 01:02:08,079
networks or lopens

1360
01:02:08,079 --> 01:02:10,160
to put our research in context

1361
01:02:10,160 --> 01:02:12,160
so low plan research began in the late

1362
01:02:12,160 --> 01:02:14,480
1990s and at this point in time

1363
01:02:14,480 --> 01:02:16,640
researchers deliberately cast away the

1364
01:02:16,640 --> 01:02:18,960
internet architecture based on the idea

1365
01:02:18,960 --> 01:02:20,640
that low panels may have to operate in

1366
01:02:20,640 --> 01:02:22,480
two extreme environments and two

1367
01:02:22,480 --> 01:02:24,799
different uh from regular networks in

1368
01:02:24,799 --> 01:02:26,480
order for the internet architecture to

1369
01:02:26,480 --> 01:02:28,160
directly apply so

1370
01:02:28,160 --> 01:02:30,319
many of the early protocols like s mac

1371
01:02:30,319 --> 01:02:32,799
dmacc and so on and the early systems

1372
01:02:32,799 --> 01:02:35,680
like taneos and contiki did not conform

1373
01:02:35,680 --> 01:02:37,039
to any particular standard or

1374
01:02:37,039 --> 01:02:38,799
architecture and this allowed the

1375
01:02:38,799 --> 01:02:40,799
researchers to nicely explore how to

1376
01:02:40,799 --> 01:02:42,319
tackle the challenges of low panels

1377
01:02:42,319 --> 01:02:44,160
without being hindered by having to

1378
01:02:44,160 --> 01:02:46,480
conform to an architecture

1379
01:02:46,480 --> 01:02:49,680
about a decade later in 2008 ip the

1380
01:02:49,680 --> 01:02:51,599
internet protocol was first introduced

1381
01:02:51,599 --> 01:02:53,520
in the space largely enabled by the six

1382
01:02:53,520 --> 01:02:55,440
lowpan adaptation layer standardized by

1383
01:02:55,440 --> 01:02:56,960
the ietf

1384
01:02:56,960 --> 01:02:58,640
and what happened here is that people

1385
01:02:58,640 --> 01:03:00,559
found ways to take the lessons that were

1386
01:03:00,559 --> 01:03:02,640
learned in the earlier systems and

1387
01:03:02,640 --> 01:03:04,799
applied them within an ip-based

1388
01:03:04,799 --> 01:03:07,280
architecture and this essentially caught

1389
01:03:07,280 --> 01:03:08,160
on

1390
01:03:08,160 --> 01:03:10,640
in a few years by about 2012 ib had

1391
01:03:10,640 --> 01:03:12,559
essentially become the standard in the

1392
01:03:12,559 --> 01:03:13,760
space

1393
01:03:13,760 --> 01:03:16,319
but surprisingly the adoption of iep did

1394
01:03:16,319 --> 01:03:18,240
not come with tcp

1395
01:03:18,240 --> 01:03:20,960
for example openthread a lowpan network

1396
01:03:20,960 --> 01:03:23,680
stack developed by nest and used in

1397
01:03:23,680 --> 01:03:25,599
in the smart home space didn't even

1398
01:03:25,599 --> 01:03:27,039
support tcp

1399
01:03:27,039 --> 01:03:29,119
and instead the community has come to

1400
01:03:29,119 --> 01:03:31,599
rely on protocols like coap

1401
01:03:31,599 --> 01:03:33,680
which are specialized low-pass protocols

1402
01:03:33,680 --> 01:03:35,599
based on udp

1403
01:03:35,599 --> 01:03:37,200
it's also worth pointing out that during

1404
01:03:37,200 --> 01:03:39,680
this time lopens have not yet achieved

1405
01:03:39,680 --> 01:03:41,680
the same kind of pervasive adoption that

1406
01:03:41,680 --> 01:03:43,200
we've seen

1407
01:03:43,200 --> 01:03:45,359
in other protocols like wi-fi at least

1408
01:03:45,359 --> 01:03:46,880
in the context of branding internet

1409
01:03:46,880 --> 01:03:48,640
access to devices

1410
01:03:48,640 --> 01:03:50,640
so a natural question is whether to get

1411
01:03:50,640 --> 01:03:52,400
that kind of pervasive adoption of

1412
01:03:52,400 --> 01:03:55,760
lopens we should adopt not only ip but

1413
01:03:55,760 --> 01:03:57,760
also the broader set of iep-based

1414
01:03:57,760 --> 01:04:00,880
protocols including tcp

1415
01:04:00,880 --> 01:04:03,039
in this context our work completes the

1416
01:04:03,039 --> 01:04:05,520
transition of low pans to an ip-based

1417
01:04:05,520 --> 01:04:08,640
architecture by showing how to make tcp

1418
01:04:08,640 --> 01:04:10,559
work well in low pans and a research

1419
01:04:10,559 --> 01:04:13,839
artifact is tcplp a performant tcp stack

1420
01:04:13,839 --> 01:04:15,280
for low bands

1421
01:04:15,280 --> 01:04:17,119
so what exactly do i mean when say

1422
01:04:17,119 --> 01:04:18,799
performant

1423
01:04:18,799 --> 01:04:21,119
well one metric is good put and that's

1424
01:04:21,119 --> 01:04:22,400
the amount of bandwidth that an

1425
01:04:22,400 --> 01:04:24,240
application is able to get when

1426
01:04:24,240 --> 01:04:26,640
operating over a tcp connection

1427
01:04:26,640 --> 01:04:28,400
now there have been a few prior attempts

1428
01:04:28,400 --> 01:04:31,039
to use tcp in the space uh typically

1429
01:04:31,039 --> 01:04:33,200
based on a simplified embedded tcp stack

1430
01:04:33,200 --> 01:04:35,200
like micro ip or blip

1431
01:04:35,200 --> 01:04:36,640
and what we can see in this graph is

1432
01:04:36,640 --> 01:04:38,640
that our work tcplp achieves

1433
01:04:38,640 --> 01:04:40,559
significantly higher good put than prior

1434
01:04:40,559 --> 01:04:43,200
attempts to use tcp in this space

1435
01:04:43,200 --> 01:04:45,039
in fact we can calculate an upper bound

1436
01:04:45,039 --> 01:04:47,440
on good put shown by these dashed lines

1437
01:04:47,440 --> 01:04:49,680
based on measurements of how fast the

1438
01:04:49,680 --> 01:04:51,359
radio can send out packets and how much

1439
01:04:51,359 --> 01:04:53,440
overhead is lost to headers and acts and

1440
01:04:53,440 --> 01:04:55,760
so on and our work comes quite close to

1441
01:04:55,760 --> 01:04:58,400
these upper bounds

1442
01:04:58,400 --> 01:05:00,160
i'd also like to share an update that's

1443
01:05:00,160 --> 01:05:01,359
happened since we published this

1444
01:05:01,359 --> 01:05:03,200
research which is that open thread the

1445
01:05:03,200 --> 01:05:05,280
low power network stack that i mentioned

1446
01:05:05,280 --> 01:05:07,280
that's used in the smart home space we

1447
01:05:07,280 --> 01:05:09,520
simply adopted tcp directly based on our

1448
01:05:09,520 --> 01:05:12,400
research it uses tcplp as its tcp

1449
01:05:12,400 --> 01:05:14,480
implementation and the research also

1450
01:05:14,480 --> 01:05:16,400
influenced thread the network standard

1451
01:05:16,400 --> 01:05:18,160
that open thread implements

1452
01:05:18,160 --> 01:05:20,400
so i'm delighted to have been invited to

1453
01:05:20,400 --> 01:05:22,400
spear help spearhead this process and i

1454
01:05:22,400 --> 01:05:25,200
am hopeful that that the adoption of tcp

1455
01:05:25,200 --> 01:05:26,960
in the space will help improve the

1456
01:05:26,960 --> 01:05:29,119
adoption of lopens more broadly in the

1457
01:05:29,119 --> 01:05:31,920
smart home space

1458
01:05:31,920 --> 01:05:33,520
so now i'm going to take a step back and

1459
01:05:33,520 --> 01:05:34,960
provide some more context as to what

1460
01:05:34,960 --> 01:05:36,799
exactly low pans are and what some of

1461
01:05:36,799 --> 01:05:39,440
the challenges are with using low pens

1462
01:05:39,440 --> 01:05:41,359
and i can do that by comparing low pans

1463
01:05:41,359 --> 01:05:43,119
to other wireless technologies that you

1464
01:05:43,119 --> 01:05:45,359
might be more familiar with so on the

1465
01:05:45,359 --> 01:05:47,760
left wi-fi provides a host with internet

1466
01:05:47,760 --> 01:05:50,559
access via an access point in the middle

1467
01:05:50,559 --> 01:05:52,880
bluetooth uh it doesn't really provide

1468
01:05:52,880 --> 01:05:54,480
full internet access it's more like a

1469
01:05:54,480 --> 01:05:56,880
cable replacement channel a wireless usb

1470
01:05:56,880 --> 01:05:58,240
of sorts

1471
01:05:58,240 --> 01:05:59,839
and then on the right we have low pans

1472
01:05:59,839 --> 01:06:01,200
which aim to provide internet

1473
01:06:01,200 --> 01:06:03,359
connectivity at the same level as wi-fi

1474
01:06:03,359 --> 01:06:05,839
would but to embedded devices and while

1475
01:06:05,839 --> 01:06:07,839
operating within the constraints of low

1476
01:06:07,839 --> 01:06:09,920
power for example having a transmit data

1477
01:06:09,920 --> 01:06:12,160
over multiple wireless hops to set up an

1478
01:06:12,160 --> 01:06:14,799
embedded mesh network

1479
01:06:14,799 --> 01:06:17,039
so lopez has been used in a variety of

1480
01:06:17,039 --> 01:06:19,039
applications for example scientific

1481
01:06:19,039 --> 01:06:20,559
applications like environmental

1482
01:06:20,559 --> 01:06:22,720
monitoring structural monitoring of a

1483
01:06:22,720 --> 01:06:24,640
bridge

1484
01:06:24,640 --> 01:06:25,680
and it's also been deployed in the

1485
01:06:25,680 --> 01:06:27,200
indoor environment in a smart grid

1486
01:06:27,200 --> 01:06:28,240
context

1487
01:06:28,240 --> 01:06:30,240
and recently there's been a push to

1488
01:06:30,240 --> 01:06:32,559
deploy it in a smart home and iot space

1489
01:06:32,559 --> 01:06:34,319
and the thread and open thread efforts i

1490
01:06:34,319 --> 01:06:36,880
mentioned earlier are one such attempt

1491
01:06:36,880 --> 01:06:38,720
but despite being useful for all these

1492
01:06:38,720 --> 01:06:40,480
applications it's difficult to use low

1493
01:06:40,480 --> 01:06:42,079
pans because they also come with a set

1494
01:06:42,079 --> 01:06:44,079
of challenges

1495
01:06:44,079 --> 01:06:45,520
the first set of challenges come from

1496
01:06:45,520 --> 01:06:47,039
the resource constraints the fact that

1497
01:06:47,039 --> 01:06:49,039
the embedded hosts have limited cpu and

1498
01:06:49,039 --> 01:06:50,640
memory resources

1499
01:06:50,640 --> 01:06:52,160
uh the second set of constraints come

1500
01:06:52,160 --> 01:06:54,079
from the link layer uh low pass link

1501
01:06:54,079 --> 01:06:57,599
clear like for example ieee 802.15.4

1502
01:06:57,599 --> 01:07:00,559
has a small mtu of only about 100 bytes

1503
01:07:00,559 --> 01:07:02,400
and has low wireless range which means

1504
01:07:02,400 --> 01:07:04,079
that in order to in order to get

1505
01:07:04,079 --> 01:07:05,839
connectivity over a large area you need

1506
01:07:05,839 --> 01:07:07,839
to transmit data over multiple wireless

1507
01:07:07,839 --> 01:07:08,880
hops

1508
01:07:08,880 --> 01:07:10,799
and finally energy constraints are also

1509
01:07:10,799 --> 01:07:12,079
an issue

1510
01:07:12,079 --> 01:07:13,520
you typically don't have enough energy

1511
01:07:13,520 --> 01:07:15,200
to keep your radio on and listening all

1512
01:07:15,200 --> 01:07:17,680
the time so you duty cycle your radio

1513
01:07:17,680 --> 01:07:19,200
what that means is that your radio is

1514
01:07:19,200 --> 01:07:21,839
actually in a low power sleep state for

1515
01:07:21,839 --> 01:07:24,880
say 99 of the time and then one percent

1516
01:07:24,880 --> 01:07:26,319
of the time you can turn on your radio

1517
01:07:26,319 --> 01:07:29,119
to send or receive packets

1518
01:07:29,119 --> 01:07:30,799
and in order to provide an always-on

1519
01:07:30,799 --> 01:07:32,799
allusion to applications despite doing

1520
01:07:32,799 --> 01:07:34,960
this to save power we need some careful

1521
01:07:34,960 --> 01:07:36,400
scheduling at the link player in order

1522
01:07:36,400 --> 01:07:38,640
to make sure the data is only sent to a

1523
01:07:38,640 --> 01:07:40,799
node when this radio is on and ready to

1524
01:07:40,799 --> 01:07:43,680
receive that data

1525
01:07:43,680 --> 01:07:46,240
so to make this more concrete uh i'm

1526
01:07:46,240 --> 01:07:47,599
going to tell you about the platform we

1527
01:07:47,599 --> 01:07:49,200
used in our research it's called

1528
01:07:49,200 --> 01:07:50,799
hamilton and some of the stats of this

1529
01:07:50,799 --> 01:07:52,000
platform

1530
01:07:52,000 --> 01:07:54,400
are on the slide the key point here is

1531
01:07:54,400 --> 01:07:56,000
that this kind of device is more

1532
01:07:56,000 --> 01:07:58,000
powerful than the devices we had when

1533
01:07:58,000 --> 01:07:59,680
low band research first got started in

1534
01:07:59,680 --> 01:08:01,839
the early 2000s but it's still

1535
01:08:01,839 --> 01:08:03,839
substantially less powerful than even a

1536
01:08:03,839 --> 01:08:05,200
raspberry pi

1537
01:08:05,200 --> 01:08:06,880
you cannot run linux in a device like

1538
01:08:06,880 --> 01:08:08,480
this instead you have to run a

1539
01:08:08,480 --> 01:08:10,960
specialized embedded operating system

1540
01:08:10,960 --> 01:08:12,559
and you can understand our research as

1541
01:08:12,559 --> 01:08:14,720
tackling the central question of how

1542
01:08:14,720 --> 01:08:16,399
should a device like this connect to the

1543
01:08:16,399 --> 01:08:17,679
internet

1544
01:08:17,679 --> 01:08:19,600
and the result of our research is that

1545
01:08:19,600 --> 01:08:22,640
we show that tcp ip works well

1546
01:08:22,640 --> 01:08:24,560
now as i mentioned earlier the adoption

1547
01:08:24,560 --> 01:08:27,759
of iep in this space did not include tcp

1548
01:08:27,759 --> 01:08:29,600
and that was no accident

1549
01:08:29,600 --> 01:08:31,759
the reason is that researchers had

1550
01:08:31,759 --> 01:08:33,600
doubts as to whether tcp would work well

1551
01:08:33,600 --> 01:08:35,439
and we expected it to not work well

1552
01:08:35,439 --> 01:08:38,640
given the challenges of lopens so here

1553
01:08:38,640 --> 01:08:40,000
are some quotes i've taken from some

1554
01:08:40,000 --> 01:08:41,439
research papers to show some of the

1555
01:08:41,439 --> 01:08:42,960
concerns that the community has had

1556
01:08:42,960 --> 01:08:45,439
about using tcp the first one is that

1557
01:08:45,439 --> 01:08:47,520
tcp is not lightweight and may not be

1558
01:08:47,520 --> 01:08:49,279
suitable for implementation and low-cost

1559
01:08:49,279 --> 01:08:50,719
sensor nodes with limiting processing

1560
01:08:50,719 --> 01:08:52,880
memory and energy resources

1561
01:08:52,880 --> 01:08:54,479
the second one is that certain features

1562
01:08:54,479 --> 01:08:57,040
of tcp may cause harm like for example

1563
01:08:57,040 --> 01:08:58,880
that the connection oriented protocol

1564
01:08:58,880 --> 01:09:01,279
aspect of tcp is a poor match for

1565
01:09:01,279 --> 01:09:03,279
wireless sensor networks where actual

1566
01:09:03,279 --> 01:09:05,120
data may only be in the order of a few

1567
01:09:05,120 --> 01:09:07,520
bytes and finally there's the wireless

1568
01:09:07,520 --> 01:09:10,238
tcp problem the idea that tcp may use a

1569
01:09:10,238 --> 01:09:11,839
single packet drop to infer that the

1570
01:09:11,839 --> 01:09:14,080
network is congested which can result in

1571
01:09:14,080 --> 01:09:15,679
extremely poor performance because

1572
01:09:15,679 --> 01:09:16,960
wireless links tend to exhibit

1573
01:09:16,960 --> 01:09:19,120
relatively high packet loss rates

1574
01:09:19,120 --> 01:09:21,759
so again to summarize more simply

1575
01:09:21,759 --> 01:09:24,000
there's concern that tcp is too heavy

1576
01:09:24,000 --> 01:09:26,399
that its features are necessary and that

1577
01:09:26,399 --> 01:09:27,920
it will perform poorly in the presence

1578
01:09:27,920 --> 01:09:29,279
of wireless loss

1579
01:09:29,279 --> 01:09:30,399
so

1580
01:09:30,399 --> 01:09:31,679
central to our research was

1581
01:09:31,679 --> 01:09:34,238
understanding tcp's performance and what

1582
01:09:34,238 --> 01:09:35,920
we did is we did a study where we

1583
01:09:35,920 --> 01:09:38,560
actually ran tcp in a low pan measured

1584
01:09:38,560 --> 01:09:40,000
its performance

1585
01:09:40,000 --> 01:09:42,080
and try to draw conclusions about how

1586
01:09:42,080 --> 01:09:45,359
well tcp really does or does not perform

1587
01:09:45,359 --> 01:09:47,839
and what we found is that out of the box

1588
01:09:47,839 --> 01:09:51,120
tcp indeed performs poorly but it turns

1589
01:09:51,120 --> 01:09:53,600
out it's not due to the expected reasons

1590
01:09:53,600 --> 01:09:55,120
that people had

1591
01:09:55,120 --> 01:09:56,640
the actual reasons were somewhat

1592
01:09:56,640 --> 01:09:58,159
different

1593
01:09:58,159 --> 01:10:00,719
okay so the actual reasons are that low

1594
01:10:00,719 --> 01:10:03,120
pans have a small l2 frame size

1595
01:10:03,120 --> 01:10:05,440
basically a small mtu and this results

1596
01:10:05,440 --> 01:10:07,440
in very high header overhead

1597
01:10:07,440 --> 01:10:08,800
the second problem is that hidden

1598
01:10:08,800 --> 01:10:10,800
terminals are a serious issue for tcp

1599
01:10:10,800 --> 01:10:12,480
when operating over multiple wireless

1600
01:10:12,480 --> 01:10:13,600
hops

1601
01:10:13,600 --> 01:10:15,199
and finally that the kind of scheduling

1602
01:10:15,199 --> 01:10:16,719
at the link layer needed to support a

1603
01:10:16,719 --> 01:10:18,560
low duty cycle and low energy

1604
01:10:18,560 --> 01:10:21,600
consumption interact poorly with tcp

1605
01:10:21,600 --> 01:10:23,280
now there's a key difference between the

1606
01:10:23,280 --> 01:10:24,800
issues on the left

1607
01:10:24,800 --> 01:10:26,560
and the issues on the right

1608
01:10:26,560 --> 01:10:28,159
the issues on the left if they were to

1609
01:10:28,159 --> 01:10:29,679
exist would be fundamental issues

1610
01:10:29,679 --> 01:10:32,400
there's no clear way to adapt tcp or the

1611
01:10:32,400 --> 01:10:35,040
link clear to eliminate those issues

1612
01:10:35,040 --> 01:10:37,520
but the issues on the right it turns out

1613
01:10:37,520 --> 01:10:39,920
are fixable within the paradigm of tcp

1614
01:10:39,920 --> 01:10:42,400
or a fairly straightforward techniques

1615
01:10:42,400 --> 01:10:45,040
so in our research we show why the

1616
01:10:45,040 --> 01:10:47,679
expected reasons don't actually apply

1617
01:10:47,679 --> 01:10:49,679
we demonstrate techniques to address the

1618
01:10:49,679 --> 01:10:51,520
actual issues causing poor tcp

1619
01:10:51,520 --> 01:10:53,840
performance and our overall conclusion

1620
01:10:53,840 --> 01:10:56,239
is that tcp can perform well in low pans

1621
01:10:56,239 --> 01:10:58,640
after all

1622
01:10:58,640 --> 01:10:59,600
so

1623
01:10:59,600 --> 01:11:01,199
that's an overview

1624
01:11:01,199 --> 01:11:02,320
of what i'm going to be telling you

1625
01:11:02,320 --> 01:11:03,280
about

1626
01:11:03,280 --> 01:11:04,880
and they're also by the way a set of

1627
01:11:04,880 --> 01:11:06,320
techniques that we propose in order to

1628
01:11:06,320 --> 01:11:08,400
make low pans work well which i'll go

1629
01:11:08,400 --> 01:11:11,120
over in the course of the talk

1630
01:11:11,120 --> 01:11:12,800
okay in the next part of the talk i'm

1631
01:11:12,800 --> 01:11:14,719
going to focus on the expected reasons

1632
01:11:14,719 --> 01:11:15,520
for

1633
01:11:15,520 --> 01:11:18,320
uh why uh or why the expected reasons

1634
01:11:18,320 --> 01:11:20,480
for performance don't apply

1635
01:11:20,480 --> 01:11:22,480
um and to go back here i'll be talking

1636
01:11:22,480 --> 01:11:24,080
about this technique in this part of the

1637
01:11:24,080 --> 01:11:25,600
talk and the reason is that this part of

1638
01:11:25,600 --> 01:11:27,520
the talk is more about our experiments

1639
01:11:27,520 --> 01:11:29,280
and our observations about the expected

1640
01:11:29,280 --> 01:11:31,120
reasons this technique has to do with

1641
01:11:31,120 --> 01:11:32,400
our implementation which is why it's

1642
01:11:32,400 --> 01:11:34,239
included i'll talk about the remaining

1643
01:11:34,239 --> 01:11:36,159
techniques in the next part of the talk

1644
01:11:36,159 --> 01:11:37,760
where i dive into how to affix the

1645
01:11:37,760 --> 01:11:40,960
actual reasons for poor performance

1646
01:11:40,960 --> 01:11:43,120
so our methodology is based on a

1647
01:11:43,120 --> 01:11:45,040
hamilton platform as i mentioned earlier

1648
01:11:45,040 --> 01:11:46,640
you can see the picture there this is a

1649
01:11:46,640 --> 01:11:47,920
hamilton platform connected to a

1650
01:11:47,920 --> 01:11:49,840
raspberry pi and the raspberry pi is

1651
01:11:49,840 --> 01:11:51,920
just there as a back channel to collect

1652
01:11:51,920 --> 01:11:54,400
logs and so on and measurements

1653
01:11:54,400 --> 01:11:56,560
uh the tcp stack was of course running

1654
01:11:56,560 --> 01:11:58,880
on the hamilton platform directly

1655
01:11:58,880 --> 01:12:00,880
our software stack is using open thread

1656
01:12:00,880 --> 01:12:02,400
with riot os

1657
01:12:02,400 --> 01:12:04,000
and we used a wireless test button

1658
01:12:04,000 --> 01:12:05,440
collector data where each of those

1659
01:12:05,440 --> 01:12:08,159
numbers is one of our hamilton nodes uh

1660
01:12:08,159 --> 01:12:09,679
the lines connecting them show an

1661
01:12:09,679 --> 01:12:12,400
example of a topology uh in reality open

1662
01:12:12,400 --> 01:12:13,360
third is going to generate this

1663
01:12:13,360 --> 01:12:15,040
dynamically this is just a snapshot of

1664
01:12:15,040 --> 01:12:17,280
what it might look like

1665
01:12:17,280 --> 01:12:20,800
and we ran tcp where one tcp endpoint is

1666
01:12:20,800 --> 01:12:22,080
in the wireless mesh on one of the

1667
01:12:22,080 --> 01:12:24,560
hamilton nodes and the other tcp

1668
01:12:24,560 --> 01:12:26,239
endpoint is hosted on the cloud and

1669
01:12:26,239 --> 01:12:29,120
amazon ec2

1670
01:12:29,600 --> 01:12:31,920
so um one of the first things we had to

1671
01:12:31,920 --> 01:12:34,159
do was to implement tcp

1672
01:12:34,159 --> 01:12:35,440
now as i mentioned earlier there have

1673
01:12:35,440 --> 01:12:37,440
been several prior attempts to use tcp

1674
01:12:37,440 --> 01:12:38,880
in this space based on simplified

1675
01:12:38,880 --> 01:12:41,520
embedded tcp stacks but we wanted to use

1676
01:12:41,520 --> 01:12:44,800
a full scale tcp stack in our study now

1677
01:12:44,800 --> 01:12:46,000
the challenge is that implementing a

1678
01:12:46,000 --> 01:12:48,480
full scale tcp stack is hard and in fact

1679
01:12:48,480 --> 01:12:50,719
there's an entire rfc devoted to all

1680
01:12:50,719 --> 01:12:52,400
describing all the problems that people

1681
01:12:52,400 --> 01:12:54,560
were seeing in full scale tcp stacks

1682
01:12:54,560 --> 01:12:57,840
back in 1999 even though these tcps had

1683
01:12:57,840 --> 01:12:59,840
matured for at least a decade by this

1684
01:12:59,840 --> 01:13:01,280
point

1685
01:13:01,280 --> 01:13:02,000
so

1686
01:13:02,000 --> 01:13:04,480
um our approach was not to implement a

1687
01:13:04,480 --> 01:13:06,320
tcp stack from scratch since we felt it

1688
01:13:06,320 --> 01:13:09,199
would be too error prone uh to do

1689
01:13:09,199 --> 01:13:10,640
instead we started with the mature

1690
01:13:10,640 --> 01:13:13,520
full-scale tcp implementation in freebsd

1691
01:13:13,520 --> 01:13:15,679
and re-engineered key parts of it so it

1692
01:13:15,679 --> 01:13:17,679
would work well on an embedded platform

1693
01:13:17,679 --> 01:13:19,440
and we call a resulting implementation

1694
01:13:19,440 --> 01:13:24,400
tcp lp where the lp stands for low power

1695
01:13:24,560 --> 01:13:26,239
so now that we have our implementation

1696
01:13:26,239 --> 01:13:28,159
of tcp we can concretely answer the

1697
01:13:28,159 --> 01:13:30,880
question of what are the resource

1698
01:13:30,880 --> 01:13:33,040
requirements of running tcp

1699
01:13:33,040 --> 01:13:35,440
so what we found is that tcp lp requires

1700
01:13:35,440 --> 01:13:37,440
32 kilobytes of code memory and about

1701
01:13:37,440 --> 01:13:39,040
half a kilobyte of data memory per

1702
01:13:39,040 --> 01:13:40,800
connection to store all of the tcp

1703
01:13:40,800 --> 01:13:42,560
connection state in a full scale tcp

1704
01:13:42,560 --> 01:13:44,000
implementation

1705
01:13:44,000 --> 01:13:45,600
while our platform has substantially

1706
01:13:45,600 --> 01:13:47,760
more code and data memory than that now

1707
01:13:47,760 --> 01:13:49,280
as an optimization we use separate

1708
01:13:49,280 --> 01:13:50,960
structures for active sockets that are

1709
01:13:50,960 --> 01:13:52,800
actually endpoints of a tcp connection

1710
01:13:52,800 --> 01:13:54,000
and passive sockets that are just

1711
01:13:54,000 --> 01:13:55,679
listening for new connections which also

1712
01:13:55,679 --> 01:13:57,600
save a bunch of memory as well

1713
01:13:57,600 --> 01:13:59,760
um but the point here is that you know

1714
01:13:59,760 --> 01:14:01,520
at least in terms of connection state

1715
01:14:01,520 --> 01:14:02,880
we're well within the bounds of the

1716
01:14:02,880 --> 01:14:05,199
available memory so natural question is

1717
01:14:05,199 --> 01:14:07,120
what about the actual buffers used to

1718
01:14:07,120 --> 01:14:09,520
send and receive data

1719
01:14:09,520 --> 01:14:12,480
so um the tcp buffers need to be the

1720
01:14:12,480 --> 01:14:14,239
bandwidth delay product and size in

1721
01:14:14,239 --> 01:14:15,920
order to be able to send at full speed

1722
01:14:15,920 --> 01:14:17,120
of the network

1723
01:14:17,120 --> 01:14:18,480
uh and we empirically determine the

1724
01:14:18,480 --> 01:14:20,080
bandwidth delay product has two to three

1725
01:14:20,080 --> 01:14:21,760
kilobytes and we can see in the graph

1726
01:14:21,760 --> 01:14:23,840
here how we experimentally did that you

1727
01:14:23,840 --> 01:14:25,600
can see two to three kilobytes of buffer

1728
01:14:25,600 --> 01:14:27,920
size the available could put over tcp

1729
01:14:27,920 --> 01:14:29,280
levels off

1730
01:14:29,280 --> 01:14:30,080
so

1731
01:14:30,080 --> 01:14:31,920
our conclusion here is that tcp

1732
01:14:31,920 --> 01:14:33,920
including the size of the buffers fits

1733
01:14:33,920 --> 01:14:35,840
comfortably in memory and in fact

1734
01:14:35,840 --> 01:14:37,199
there's another conclusion to be drawn

1735
01:14:37,199 --> 01:14:39,679
here which is that if you notice the the

1736
01:14:39,679 --> 01:14:41,280
size of the buffers is actually much

1737
01:14:41,280 --> 01:14:42,560
bigger than the connection state which

1738
01:14:42,560 --> 01:14:44,400
suggests that most of the overhead of

1739
01:14:44,400 --> 01:14:46,159
tcp doesn't come from the complexity of

1740
01:14:46,159 --> 01:14:48,960
the protocol is from the buffers and any

1741
01:14:48,960 --> 01:14:50,800
performant bulk transfer protocol would

1742
01:14:50,800 --> 01:14:52,880
need these buffers in order to transmit

1743
01:14:52,880 --> 01:14:55,360
at the bdp so in some sense the overhead

1744
01:14:55,360 --> 01:14:56,960
really isn't bottlenecked by tcp's

1745
01:14:56,960 --> 01:14:59,840
complexity at all

1746
01:15:00,080 --> 01:15:02,560
um there's also some we also introduced

1747
01:15:02,560 --> 01:15:04,560
a technique here in order to reduce the

1748
01:15:04,560 --> 01:15:07,280
memory used for the buffers uh and part

1749
01:15:07,280 --> 01:15:10,000
of this has to rely on tcp having both a

1750
01:15:10,000 --> 01:15:12,239
receive buffer and a reassembly buffer

1751
01:15:12,239 --> 01:15:14,320
to store in sequence data and auto

1752
01:15:14,320 --> 01:15:16,239
sequence data for reassembly

1753
01:15:16,239 --> 01:15:16,960
now

1754
01:15:16,960 --> 01:15:19,360
full scale tcp stacks like freebsd use

1755
01:15:19,360 --> 01:15:20,800
packet queues there's a separate queue

1756
01:15:20,800 --> 01:15:22,800
of packets for each of these but in the

1757
01:15:22,800 --> 01:15:24,880
embedded setting we don't want to use

1758
01:15:24,880 --> 01:15:26,719
dynamically allocated packets because if

1759
01:15:26,719 --> 01:15:28,480
we hold on to dynamically allocated

1760
01:15:28,480 --> 01:15:30,719
packets in a memory constraint setting

1761
01:15:30,719 --> 01:15:32,480
we may cause other memory allocations to

1762
01:15:32,480 --> 01:15:34,480
fail so we instead we want to use flat

1763
01:15:34,480 --> 01:15:36,320
arrays and the naive strategy would be

1764
01:15:36,320 --> 01:15:38,239
to have a separate flat array for your

1765
01:15:38,239 --> 01:15:40,000
receive queue and for your reassembly

1766
01:15:40,000 --> 01:15:40,880
queue

1767
01:15:40,880 --> 01:15:42,719
now to optimize this what we observe is

1768
01:15:42,719 --> 01:15:44,400
that there's an interesting relationship

1769
01:15:44,400 --> 01:15:47,040
between the advertised windows size the

1770
01:15:47,040 --> 01:15:49,360
number of bias we currently have and the

1771
01:15:49,360 --> 01:15:50,960
total size of the buffer which is that

1772
01:15:50,960 --> 01:15:52,320
the number of received bytes plus the

1773
01:15:52,320 --> 01:15:54,239
advertised windows size is equal to the

1774
01:15:54,239 --> 01:15:56,400
total size of a receive buffer

1775
01:15:56,400 --> 01:15:58,640
now the observation we make on top of

1776
01:15:58,640 --> 01:16:00,719
this is that all of the data we may

1777
01:16:00,719 --> 01:16:03,199
possibly get for reassembly has to fit

1778
01:16:03,199 --> 01:16:04,880
within the advertised window size that's

1779
01:16:04,880 --> 01:16:06,400
the contract of tcp that if you're

1780
01:16:06,400 --> 01:16:08,320
sending to a recipient you do not go

1781
01:16:08,320 --> 01:16:10,880
past their advertised window

1782
01:16:10,880 --> 01:16:12,960
so this allows us to actually store the

1783
01:16:12,960 --> 01:16:15,600
receive buffer and the reassembly queue

1784
01:16:15,600 --> 01:16:18,719
in a single flat array okay so the way

1785
01:16:18,719 --> 01:16:20,400
this works is that we have our flat

1786
01:16:20,400 --> 01:16:22,080
array and the yellow region with the

1787
01:16:22,080 --> 01:16:23,440
start and end pointers is just a

1788
01:16:23,440 --> 01:16:25,440
circular buffer to store our in sequence

1789
01:16:25,440 --> 01:16:28,159
data then as we receive auto sequence

1790
01:16:28,159 --> 01:16:30,159
data that needs to be reassembled we

1791
01:16:30,159 --> 01:16:32,159
store it in the same array past the end

1792
01:16:32,159 --> 01:16:34,400
of the circular buffer using a bitmap to

1793
01:16:34,400 --> 01:16:36,000
keep track of which of these bytes are

1794
01:16:36,000 --> 01:16:37,920
active corresponding to received out of

1795
01:16:37,920 --> 01:16:39,920
sequence data and which of them are just

1796
01:16:39,920 --> 01:16:41,679
empty slots on the array where new data

1797
01:16:41,679 --> 01:16:43,120
can be stored

1798
01:16:43,120 --> 01:16:45,040
okay so in this way we can significantly

1799
01:16:45,040 --> 01:16:47,360
reduce the memory for buffers by in some

1800
01:16:47,360 --> 01:16:49,199
sense not having to allocate a separate

1801
01:16:49,199 --> 01:16:50,960
buffer for a reassembly queue and just

1802
01:16:50,960 --> 01:16:52,239
sharing that with the buffer we've

1803
01:16:52,239 --> 01:16:55,679
allocated for the received view

1804
01:16:55,679 --> 01:16:57,199
okay next i'm going to talk about the

1805
01:16:57,199 --> 01:16:59,520
wireless tcp problem and before we talk

1806
01:16:59,520 --> 01:17:00,960
about that i need to tell you about the

1807
01:17:00,960 --> 01:17:02,480
number of implied segments is that

1808
01:17:02,480 --> 01:17:04,880
affects tcp's congestion control

1809
01:17:04,880 --> 01:17:06,560
so as i mentioned the bama's lip product

1810
01:17:06,560 --> 01:17:08,239
is two to three kilobytes

1811
01:17:08,239 --> 01:17:10,800
each segment is sized to about 250 to

1812
01:17:10,800 --> 01:17:12,880
500 bytes and this was chosen carefully

1813
01:17:12,880 --> 01:17:14,239
it's actually based on the technique

1814
01:17:14,239 --> 01:17:16,000
i'll tell you about later on in the talk

1815
01:17:16,000 --> 01:17:17,760
or coping with a small mtu of these

1816
01:17:17,760 --> 01:17:19,679
networks uh so we'll come back and

1817
01:17:19,679 --> 01:17:21,040
explain this but for now take it as a

1818
01:17:21,040 --> 01:17:22,800
given that our segments are 250 bytes to

1819
01:17:22,800 --> 01:17:24,159
500 bytes

1820
01:17:24,159 --> 01:17:25,840
and what this works out to is we have

1821
01:17:25,840 --> 01:17:28,239
four to 12 in flight tcp segments at any

1822
01:17:28,239 --> 01:17:29,679
one point in time

1823
01:17:29,679 --> 01:17:32,080
now this is different from other higher

1824
01:17:32,080 --> 01:17:33,520
bandwidth networks you might imagine if

1825
01:17:33,520 --> 01:17:34,719
you're transmitting over a higher

1826
01:17:34,719 --> 01:17:36,159
bandwidth network or over a longer

1827
01:17:36,159 --> 01:17:37,840
distance you may have hundreds or

1828
01:17:37,840 --> 01:17:39,520
thousands or tens of thousands of

1829
01:17:39,520 --> 01:17:41,920
packets in flight and in comparison 4 to

1830
01:17:41,920 --> 01:17:44,640
12 is is very small and that profoundly

1831
01:17:44,640 --> 01:17:46,560
affects how tcp's congestion control

1832
01:17:46,560 --> 01:17:48,560
operates

1833
01:17:48,560 --> 01:17:51,760
so here are some examples of how of tcp

1834
01:17:51,760 --> 01:17:53,199
and urena's behavior in a low pain and

1835
01:17:53,199 --> 01:17:56,000
for now focus on the left graph

1836
01:17:56,000 --> 01:17:56,960
here

1837
01:17:56,960 --> 01:18:00,400
our maximum segment size is 462 bytes

1838
01:18:00,400 --> 01:18:03,199
um and what's going on and when i say in

1839
01:18:03,199 --> 01:18:04,400
action segment size i'm actually

1840
01:18:04,400 --> 01:18:06,239
subtracting the space for tcp options so

1841
01:18:06,239 --> 01:18:08,080
this is how much data is sent in each

1842
01:18:08,080 --> 01:18:09,600
tcp packet

1843
01:18:09,600 --> 01:18:11,440
and our bandwidth delay product is

1844
01:18:11,440 --> 01:18:14,640
filled by just four tcp segments

1845
01:18:14,640 --> 01:18:16,320
so what ends up happening is that yeah

1846
01:18:16,320 --> 01:18:18,719
we're our losses are very frequent but

1847
01:18:18,719 --> 01:18:20,640
because we only need a connection window

1848
01:18:20,640 --> 01:18:23,920
of four segments in order to fill up uh

1849
01:18:23,920 --> 01:18:26,560
the bdp and send senate line rate tcp's

1850
01:18:26,560 --> 01:18:28,560
congestion control actually

1851
01:18:28,560 --> 01:18:30,159
is actually able to recover from losses

1852
01:18:30,159 --> 01:18:32,159
extremely quickly and we spend most of

1853
01:18:32,159 --> 01:18:33,840
our time actually sending at a full

1854
01:18:33,840 --> 01:18:34,800
window

1855
01:18:34,800 --> 01:18:36,239
despite the losses in the wireless

1856
01:18:36,239 --> 01:18:37,840
medium being frequent

1857
01:18:37,840 --> 01:18:39,280
on the right we have a more challenging

1858
01:18:39,280 --> 01:18:41,360
scenario where we size our mss to be

1859
01:18:41,360 --> 01:18:43,280
smaller and we use some active queue

1860
01:18:43,280 --> 01:18:44,880
management which induces some more loss

1861
01:18:44,880 --> 01:18:47,840
events but we still find that tcp is

1862
01:18:47,840 --> 01:18:49,920
able to reach a full window and operate

1863
01:18:49,920 --> 01:18:52,000
there most of the time despite seeing

1864
01:18:52,000 --> 01:18:54,080
treatment losses

1865
01:18:54,080 --> 01:18:56,480
so somewhat counter-intuitively we find

1866
01:18:56,480 --> 01:18:58,640
that because our bandwidth in these

1867
01:18:58,640 --> 01:19:01,199
networks is so small our bandwidth delay

1868
01:19:01,199 --> 01:19:03,280
product is small and as a result we can

1869
01:19:03,280 --> 01:19:05,520
recover to a full bdp quickly after a

1870
01:19:05,520 --> 01:19:06,400
loss

1871
01:19:06,400 --> 01:19:08,080
and this means that the wireless tcp

1872
01:19:08,080 --> 01:19:10,159
problem actually does not affect tcp's

1873
01:19:10,159 --> 01:19:11,600
performance significantly in these

1874
01:19:11,600 --> 01:19:12,640
networks

1875
01:19:12,640 --> 01:19:14,000
uh and it's much more resilient to

1876
01:19:14,000 --> 01:19:15,520
wireless losses in a lower pan than it

1877
01:19:15,520 --> 01:19:16,960
is in a higher bandwidth wireless

1878
01:19:16,960 --> 01:19:18,960
network so that was a surprising result

1879
01:19:18,960 --> 01:19:20,640
but one that works well for us because

1880
01:19:20,640 --> 01:19:22,159
it removes one of the obstacles we

1881
01:19:22,159 --> 01:19:24,000
ordinarily would have faced in getting

1882
01:19:24,000 --> 01:19:26,800
tcp to work

1883
01:19:26,800 --> 01:19:28,400
so now i've talked about the expect why

1884
01:19:28,400 --> 01:19:30,320
the expected reasons don't apply in the

1885
01:19:30,320 --> 01:19:31,440
next part of the talk i'm going to tell

1886
01:19:31,440 --> 01:19:33,120
you about the actual reasons for poor

1887
01:19:33,120 --> 01:19:34,320
performance

1888
01:19:34,320 --> 01:19:35,760
and going back to our slide with our

1889
01:19:35,760 --> 01:19:37,120
techniques on it i'll be telling you

1890
01:19:37,120 --> 01:19:39,040
about these three techniques now there

1891
01:19:39,040 --> 01:19:40,560
are a couple i didn't get to the zero

1892
01:19:40,560 --> 01:19:42,159
copy send buffer the link clear queue

1893
01:19:42,159 --> 01:19:43,280
management and that's because i don't

1894
01:19:43,280 --> 01:19:44,960
have the time in this talk to talk about

1895
01:19:44,960 --> 01:19:46,800
it but if you want to chat about it

1896
01:19:46,800 --> 01:19:48,560
afterwards i'll be around

1897
01:19:48,560 --> 01:19:49,760
or you can look in the paper to find

1898
01:19:49,760 --> 01:19:52,800
some details about those

1899
01:19:52,800 --> 01:19:55,760
so first dealing with the mtu problem

1900
01:19:55,760 --> 01:19:58,080
here's a graphic showing the size of the

1901
01:19:58,080 --> 01:20:00,960
mtu in ethernet wi-fi and i triple eeee

1902
01:20:00,960 --> 01:20:02,960
into the 15.4 which is an example of a

1903
01:20:02,960 --> 01:20:04,480
low pan link layer

1904
01:20:04,480 --> 01:20:08,080
and what we can see is that um tcp ip

1905
01:20:08,080 --> 01:20:10,480
headers are very small compared to the

1906
01:20:10,480 --> 01:20:12,719
ethernet and wi-fi mtus but they're

1907
01:20:12,719 --> 01:20:15,360
significant compared to the ieee inner

1908
01:20:15,360 --> 01:20:18,080
tutor 15.4 mtu

1909
01:20:18,080 --> 01:20:19,280
and this is going to result in large

1910
01:20:19,280 --> 01:20:21,440
header overhead okay normally we size

1911
01:20:21,440 --> 01:20:23,920
tcp segments to be as large the link

1912
01:20:23,920 --> 01:20:25,920
supports but no larger this is standard

1913
01:20:25,920 --> 01:20:27,120
this is what's used in ethernet and

1914
01:20:27,120 --> 01:20:28,320
wi-fi

1915
01:20:28,320 --> 01:20:31,440
but in the case of ieee air duty 15.4

1916
01:20:31,440 --> 01:20:32,400
it's only

1917
01:20:32,400 --> 01:20:35,520
104 bytes right our mtu is small and our

1918
01:20:35,520 --> 01:20:38,080
tcp ip headers can actually take up more

1919
01:20:38,080 --> 01:20:39,600
than half of that if you include the

1920
01:20:39,600 --> 01:20:42,159
cost of tcp options even if you use a

1921
01:20:42,159 --> 01:20:44,159
standard ip header compression that's

1922
01:20:44,159 --> 01:20:46,480
part of 6lowpan and what that means is

1923
01:20:46,480 --> 01:20:47,840
that if you're transmitting data in a

1924
01:20:47,840 --> 01:20:49,760
tcp connection more than half of the

1925
01:20:49,760 --> 01:20:51,199
data you're setting out are just these

1926
01:20:51,199 --> 01:20:53,280
headers and your good put is severely

1927
01:20:53,280 --> 01:20:55,600
affected by that

1928
01:20:55,600 --> 01:20:58,000
so in order to overcome this we break

1929
01:20:58,000 --> 01:20:59,600
this conventional wisdom and instead

1930
01:20:59,600 --> 01:21:02,960
allow tcp lp to have tcp segments that

1931
01:21:02,960 --> 01:21:05,520
span multiple link layer frames okay

1932
01:21:05,520 --> 01:21:07,840
what that means is that we're relying on

1933
01:21:07,840 --> 01:21:09,600
the six lowpan adaptation layer to

1934
01:21:09,600 --> 01:21:11,520
handle fragmentation and reassembly for

1935
01:21:11,520 --> 01:21:12,239
us

1936
01:21:12,239 --> 01:21:14,159
which adds some overhead but it means

1937
01:21:14,159 --> 01:21:16,239
that the overhead of our headers is now

1938
01:21:16,239 --> 01:21:18,639
amortized over multiple frames allowing

1939
01:21:18,639 --> 01:21:20,560
us to get some good good put

1940
01:21:20,560 --> 01:21:24,000
now there is a trade-off here um if we

1941
01:21:24,000 --> 01:21:26,400
use too much fragmentation if we set our

1942
01:21:26,400 --> 01:21:28,960
our mtu i mean if we set our tcp

1943
01:21:28,960 --> 01:21:30,880
segments to be way too large what's

1944
01:21:30,880 --> 01:21:32,560
going to end up happening is that we

1945
01:21:32,560 --> 01:21:34,080
rely on too much fragmentation and

1946
01:21:34,080 --> 01:21:35,920
that's bad because now if one fragment

1947
01:21:35,920 --> 01:21:38,159
gets lost we lose the entire packet so

1948
01:21:38,159 --> 01:21:39,600
what we want to do is we want to choose

1949
01:21:39,600 --> 01:21:41,840
our tcp segments to be as large as

1950
01:21:41,840 --> 01:21:43,520
possible to effectively amortize the

1951
01:21:43,520 --> 01:21:45,679
overhead without incurring more

1952
01:21:45,679 --> 01:21:48,080
fragmentation beyond that okay and this

1953
01:21:48,080 --> 01:21:50,239
graph was an experiment where we where

1954
01:21:50,239 --> 01:21:52,800
we measured the maximum segment size and

1955
01:21:52,800 --> 01:21:54,719
the good put that results and we found

1956
01:21:54,719 --> 01:21:56,400
that the gains essentially level off

1957
01:21:56,400 --> 01:21:59,199
around three to five frames uh so that's

1958
01:21:59,199 --> 01:22:00,719
what we use for our future experiments

1959
01:22:00,719 --> 01:22:02,159
and it shows that you know there's a

1960
01:22:02,159 --> 01:22:03,920
good trade-off to be made here where we

1961
01:22:03,920 --> 01:22:06,159
can get good good put despite the

1962
01:22:06,159 --> 01:22:08,239
despite the header sizes

1963
01:22:08,239 --> 01:22:09,840
now one thing that we didn't do but

1964
01:22:09,840 --> 01:22:11,440
could potentially help in a way that's

1965
01:22:11,440 --> 01:22:14,480
orthogonal to this is to get good tcp

1966
01:22:14,480 --> 01:22:15,920
header compression right because six

1967
01:22:15,920 --> 01:22:18,480
lupine currently standardizes udp header

1968
01:22:18,480 --> 01:22:20,239
compression with six low pen but not tcp

1969
01:22:20,239 --> 01:22:22,159
header compression and that's another

1970
01:22:22,159 --> 01:22:23,760
opportunity to reduce these overheads

1971
01:22:23,760 --> 01:22:26,080
further

1972
01:22:26,080 --> 01:22:28,239
okay now i'll talk about how the link

1973
01:22:28,239 --> 01:22:30,159
clear scheduling to support a low duty

1974
01:22:30,159 --> 01:22:32,560
cycle interacts poorly with tcp

1975
01:22:32,560 --> 01:22:34,960
so recall that these devices often don't

1976
01:22:34,960 --> 01:22:36,639
have enough energy to keep their radios

1977
01:22:36,639 --> 01:22:39,199
on listening all the time so we define

1978
01:22:39,199 --> 01:22:41,120
the duty cycle as the proportion of time

1979
01:22:41,120 --> 01:22:42,880
that the radio is listening or

1980
01:22:42,880 --> 01:22:44,560
transmitting basically the percent of

1981
01:22:44,560 --> 01:22:47,040
time where the radio is not in a low

1982
01:22:47,040 --> 01:22:49,280
power sleep state okay and in order to

1983
01:22:49,280 --> 01:22:50,639
get good energy construction we want the

1984
01:22:50,639 --> 01:22:52,960
duty cycle to be as close to zero as

1985
01:22:52,960 --> 01:22:54,639
possible

1986
01:22:54,639 --> 01:22:56,400
now there are several ways in order to

1987
01:22:56,400 --> 01:22:57,920
support this uh in the session

1988
01:22:57,920 --> 01:23:00,239
literature open3d uses a particular duty

1989
01:23:00,239 --> 01:23:01,679
cycling mechanism that's called a

1990
01:23:01,679 --> 01:23:03,920
receiver initiated duty cycle protocol

1991
01:23:03,920 --> 01:23:07,440
which i'll now explain so in open thread

1992
01:23:07,440 --> 01:23:09,120
you have two kinds of nodes we have

1993
01:23:09,120 --> 01:23:10,880
battery powered nodes where we want to

1994
01:23:10,880 --> 01:23:13,199
minimize the duty cycle and wall power

1995
01:23:13,199 --> 01:23:14,560
nodes that are plugged into a wall

1996
01:23:14,560 --> 01:23:16,159
outlet and have enough power to keep

1997
01:23:16,159 --> 01:23:18,560
their videos always on

1998
01:23:18,560 --> 01:23:19,360
okay

1999
01:23:19,360 --> 01:23:22,960
now sending a frame from b to w is easy

2000
01:23:22,960 --> 01:23:25,360
because w video is always on so we can

2001
01:23:25,360 --> 01:23:28,400
just send the frame whenever we like

2002
01:23:28,400 --> 01:23:30,639
more challenging is the reverse getting

2003
01:23:30,639 --> 01:23:32,960
a frame from w to b

2004
01:23:32,960 --> 01:23:35,760
okay so what has to happen is that w has

2005
01:23:35,760 --> 01:23:36,960
to wait

2006
01:23:36,960 --> 01:23:38,719
until b's radio is listening and how

2007
01:23:38,719 --> 01:23:40,960
does it know when b's radio is listening

2008
01:23:40,960 --> 01:23:42,719
well this is where the protocol comes in

2009
01:23:42,719 --> 01:23:44,719
what b does is that whenever it turns on

2010
01:23:44,719 --> 01:23:47,280
as radio to listen for a for a frame

2011
01:23:47,280 --> 01:23:50,239
it'll send a data request packet to w

2012
01:23:50,239 --> 01:23:52,639
informing it that it's now listening so

2013
01:23:52,639 --> 01:23:54,480
w has to wait until it guesses it a

2014
01:23:54,480 --> 01:23:56,560
request packet and once it does

2015
01:23:56,560 --> 01:23:58,320
then it can go ahead and send the frame

2016
01:23:58,320 --> 01:24:00,320
to b and b will listen and receive the

2017
01:24:00,320 --> 01:24:02,880
frame okay so what's the key point here

2018
01:24:02,880 --> 01:24:04,480
the key point i want to emphasize is

2019
01:24:04,480 --> 01:24:06,880
that these idle duty cycle is directly

2020
01:24:06,880 --> 01:24:08,800
related to how frequently it sends data

2021
01:24:08,800 --> 01:24:11,120
request frames b can choose to send data

2022
01:24:11,120 --> 01:24:13,520
request frames very rarely which allow

2023
01:24:13,520 --> 01:24:15,440
it to get very good energy consumption

2024
01:24:15,440 --> 01:24:17,840
but doing so would uh but by doing so

2025
01:24:17,840 --> 01:24:19,600
will cause more of a delay in getting

2026
01:24:19,600 --> 01:24:21,679
frames to it since w has to wait for the

2027
01:24:21,679 --> 01:24:24,000
request frame in order to send it one of

2028
01:24:24,000 --> 01:24:26,719
the uh one of the data frames

2029
01:24:26,719 --> 01:24:29,040
okay so now let me talk about what this

2030
01:24:29,040 --> 01:24:31,600
means for tcp operation and i'll do this

2031
01:24:31,600 --> 01:24:35,360
by comparing http over tcp to coap okay

2032
01:24:35,360 --> 01:24:37,199
and coap is a rest-based protocol

2033
01:24:37,199 --> 01:24:39,040
running on top of udp

2034
01:24:39,040 --> 01:24:41,520
and in our setup we had bsnw data

2035
01:24:41,520 --> 01:24:43,600
request frame every one second basically

2036
01:24:43,600 --> 01:24:45,280
it makes it listen for packets every one

2037
01:24:45,280 --> 01:24:46,960
second and that allows it to get a

2038
01:24:46,960 --> 01:24:49,040
really low duty cycle

2039
01:24:49,040 --> 01:24:50,880
now the key difference between http and

2040
01:24:50,880 --> 01:24:53,040
co-app here is that http requires two

2041
01:24:53,040 --> 01:24:55,600
round trips whereas co-app only requires

2042
01:24:55,600 --> 01:24:56,880
one round trip

2043
01:24:56,880 --> 01:24:59,040
okay so for the first round trip right

2044
01:24:59,040 --> 01:25:01,040
you start at a random uh phase within

2045
01:25:01,040 --> 01:25:03,120
the 100 million within the thousand

2046
01:25:03,120 --> 01:25:04,960
millisecond sleep interval so you'd

2047
01:25:04,960 --> 01:25:06,880
expect on average a 500 millisecond

2048
01:25:06,880 --> 01:25:09,600
delay and co-op is consistent with that

2049
01:25:09,600 --> 01:25:11,600
for http what happens is that for the

2050
01:25:11,600 --> 01:25:14,080
first round trip we see 500 milliseconds

2051
01:25:14,080 --> 01:25:16,560
but the second round trip starts right

2052
01:25:16,560 --> 01:25:17,920
at the beginning of the next leap

2053
01:25:17,920 --> 01:25:19,600
interval so the second round trip

2054
01:25:19,600 --> 01:25:22,880
consistently sees the worst case latency

2055
01:25:22,880 --> 01:25:25,199
when transmitting the packet from

2056
01:25:25,199 --> 01:25:26,080
b

2057
01:25:26,080 --> 01:25:28,480
okay and as a result http performs more

2058
01:25:28,480 --> 01:25:30,880
than twice as poorly as coap

2059
01:25:30,880 --> 01:25:32,800
on this workload now i want to point out

2060
01:25:32,800 --> 01:25:33,760
that there have been some recent

2061
01:25:33,760 --> 01:25:36,400
extensions to tcp for example tcp fast

2062
01:25:36,400 --> 01:25:38,239
open which you can use to eliminate the

2063
01:25:38,239 --> 01:25:39,920
second round trip and get performance

2064
01:25:39,920 --> 01:25:42,560
parity between co-app and http

2065
01:25:42,560 --> 01:25:45,199
but this problem also happens for bulk

2066
01:25:45,199 --> 01:25:47,040
transfers where the acclock nature of

2067
01:25:47,040 --> 01:25:49,840
tcp causes it to consistently experience

2068
01:25:49,840 --> 01:25:51,840
the worst case latency even for bulk

2069
01:25:51,840 --> 01:25:53,440
transfers so this is an important

2070
01:25:53,440 --> 01:25:56,239
problem to solve regardless of that

2071
01:25:56,239 --> 01:25:58,000
and our approach to solving it is to use

2072
01:25:58,000 --> 01:26:00,560
an adaptive duty cycle the idea is that

2073
01:26:00,560 --> 01:26:03,280
we can use the tcp and http protocol

2074
01:26:03,280 --> 01:26:06,080
state in order to vary how often we send

2075
01:26:06,080 --> 01:26:08,159
data request frames the idea being when

2076
01:26:08,159 --> 01:26:10,480
we expect a packet we want to send data

2077
01:26:10,480 --> 01:26:12,480
request frames more frequently so for

2078
01:26:12,480 --> 01:26:14,639
example if i'm an http server of one of

2079
01:26:14,639 --> 01:26:16,800
these battery-powered devices and i just

2080
01:26:16,800 --> 01:26:19,120
accepted a tcp connection i can be

2081
01:26:19,120 --> 01:26:20,960
pretty sure that that i'm going to soon

2082
01:26:20,960 --> 01:26:22,560
receive an http request on that

2083
01:26:22,560 --> 01:26:24,800
connection so i may choose to send data

2084
01:26:24,800 --> 01:26:26,639
request frames more frequently at that

2085
01:26:26,639 --> 01:26:28,960
point in time and doing this

2086
01:26:28,960 --> 01:26:31,280
nearly entirely eliminates the gap

2087
01:26:31,280 --> 01:26:33,280
between co-app and http in terms of

2088
01:26:33,280 --> 01:26:35,440
performance

2089
01:26:35,440 --> 01:26:36,880
so if we zoom out and look at the

2090
01:26:36,880 --> 01:26:39,520
overall network this adaptive duty cycle

2091
01:26:39,520 --> 01:26:41,600
technique works well for the last hop

2092
01:26:41,600 --> 01:26:43,120
going from a wall powered node to a

2093
01:26:43,120 --> 01:26:45,120
battery powered node but the overall

2094
01:26:45,120 --> 01:26:46,560
network still has to operate over

2095
01:26:46,560 --> 01:26:48,639
multiple wireless hops to even get to

2096
01:26:48,639 --> 01:26:50,000
that hop

2097
01:26:50,000 --> 01:26:51,600
and what we observed with the tcp

2098
01:26:51,600 --> 01:26:54,080
performs poorly over this chain of wall

2099
01:26:54,080 --> 01:26:57,600
powered nodes due to hidden terminals

2100
01:26:57,600 --> 01:26:59,040
so

2101
01:26:59,040 --> 01:27:00,800
let me step back and go over hidden

2102
01:27:00,800 --> 01:27:02,400
terminals to provide some background on

2103
01:27:02,400 --> 01:27:03,840
that for those who aren't familiar with

2104
01:27:03,840 --> 01:27:04,880
it

2105
01:27:04,880 --> 01:27:06,480
we can understand the wireless range of

2106
01:27:06,480 --> 01:27:08,719
a node is looking something like this

2107
01:27:08,719 --> 01:27:10,639
the unit just models the simplification

2108
01:27:10,639 --> 01:27:12,480
where we consider this to be in some

2109
01:27:12,480 --> 01:27:14,239
sort of perfect circle

2110
01:27:14,239 --> 01:27:16,159
in practice of course it can be more

2111
01:27:16,159 --> 01:27:17,920
complex depending on the exact

2112
01:27:17,920 --> 01:27:20,400
environment your deployment is in

2113
01:27:20,400 --> 01:27:22,960
uh but unit this model is is going to be

2114
01:27:22,960 --> 01:27:24,400
enough for us to capture the phenomena

2115
01:27:24,400 --> 01:27:27,040
of interest here so you'll go with that

2116
01:27:27,040 --> 01:27:28,960
um so imagine you have four segments in

2117
01:27:28,960 --> 01:27:31,440
a line i mean four four nodes in a line

2118
01:27:31,440 --> 01:27:33,440
with their uh with their transmission

2119
01:27:33,440 --> 01:27:34,880
ranges shown here and we want to

2120
01:27:34,880 --> 01:27:37,040
transmit data from a to d

2121
01:27:37,040 --> 01:27:39,760
now the nature of tcp is that uh we have

2122
01:27:39,760 --> 01:27:41,520
multiple segments in flight at the same

2123
01:27:41,520 --> 01:27:43,440
time for a single connection and that's

2124
01:27:43,440 --> 01:27:45,120
why we have segment one being sent from

2125
01:27:45,120 --> 01:27:46,960
c to d and segment two being sent from a

2126
01:27:46,960 --> 01:27:48,480
to b

2127
01:27:48,480 --> 01:27:50,880
but unfortunately this is bad because

2128
01:27:50,880 --> 01:27:52,560
the wireless ranges are going to overlap

2129
01:27:52,560 --> 01:27:54,159
at b so the two packets are going to

2130
01:27:54,159 --> 01:27:56,320
interfere there okay now in the context

2131
01:27:56,320 --> 01:27:58,800
of wi-fi we typically overcome this

2132
01:27:58,800 --> 01:28:01,280
using a protocol based on rts and cts

2133
01:28:01,280 --> 01:28:03,360
frames that allow us to mitigate the

2134
01:28:03,360 --> 01:28:05,920
hidden terminal problem in most cases

2135
01:28:05,920 --> 01:28:08,480
but in the context of lopens the small

2136
01:28:08,480 --> 01:28:12,000
mtu means that rtsdts typically has too

2137
01:28:12,000 --> 01:28:14,320
high of an overhead as a result most

2138
01:28:14,320 --> 01:28:17,679
uses of it don't use rts and cts packets

2139
01:28:17,679 --> 01:28:19,440
uh so as a result we're only relying on

2140
01:28:19,440 --> 01:28:23,440
csma right so at a csma can't detect uh

2141
01:28:23,440 --> 01:28:24,880
c's transmission

2142
01:28:24,880 --> 01:28:27,520
because uh it's all the way

2143
01:28:27,520 --> 01:28:30,159
because a is out of range of c and csma

2144
01:28:30,159 --> 01:28:32,080
at c can't detect a's transmission

2145
01:28:32,080 --> 01:28:34,800
because c is out of range of a

2146
01:28:34,800 --> 01:28:36,400
but both of the packets end up

2147
01:28:36,400 --> 01:28:38,239
interfering at b and the packet gets

2148
01:28:38,239 --> 01:28:40,480
lost

2149
01:28:40,480 --> 01:28:42,239
this also happens because of data

2150
01:28:42,239 --> 01:28:43,840
packets and acts going in opposite

2151
01:28:43,840 --> 01:28:46,639
directions so for example here

2152
01:28:46,639 --> 01:28:49,360
what we'll ultimately see is that

2153
01:28:49,360 --> 01:28:50,880
um

2154
01:28:50,880 --> 01:28:52,960
you get the same problem with b and d

2155
01:28:52,960 --> 01:28:55,120
both sending at the same time to c

2156
01:28:55,120 --> 01:28:57,440
because each of their csmas can't hear

2157
01:28:57,440 --> 01:28:59,840
the other

2158
01:28:59,840 --> 01:29:02,080
so to mitigate this our approach is to

2159
01:29:02,080 --> 01:29:04,880
add a new random back off delay between

2160
01:29:04,880 --> 01:29:06,960
link player rate price okay so the idea

2161
01:29:06,960 --> 01:29:09,360
is if you transmit a frame and it fails

2162
01:29:09,360 --> 01:29:10,400
which you know because you don't get a

2163
01:29:10,400 --> 01:29:12,400
link layer acknowledgement for it

2164
01:29:12,400 --> 01:29:15,040
then you wait a random amount and retry

2165
01:29:15,040 --> 01:29:16,639
the transmission and this is different

2166
01:29:16,639 --> 01:29:18,960
from csma in two respects the first

2167
01:29:18,960 --> 01:29:21,360
respect is that in csma

2168
01:29:21,360 --> 01:29:23,280
you do this randomized

2169
01:29:23,280 --> 01:29:25,760
delay with exponential back off if the

2170
01:29:25,760 --> 01:29:27,520
channel appears busy

2171
01:29:27,520 --> 01:29:29,280
in this case even the channel appears

2172
01:29:29,280 --> 01:29:32,320
clear if our transmission fails we still

2173
01:29:32,320 --> 01:29:33,840
do the back off so it's different in

2174
01:29:33,840 --> 01:29:35,440
regards of what triggers the

2175
01:29:35,440 --> 01:29:36,880
transmission

2176
01:29:36,880 --> 01:29:38,800
and second it's a much longer delay

2177
01:29:38,800 --> 01:29:40,800
right because in csma you can rely on

2178
01:29:40,800 --> 01:29:42,320
hearing a concurrent transmission you

2179
01:29:42,320 --> 01:29:44,320
can transmit immediately if the channel

2180
01:29:44,320 --> 01:29:46,639
appears clear in this new delay that

2181
01:29:46,639 --> 01:29:49,280
we're adding this link retry delay what

2182
01:29:49,280 --> 01:29:51,840
we're seeing is that we want to have a

2183
01:29:51,840 --> 01:29:54,480
delay that's chosen between 0 and 10

2184
01:29:54,480 --> 01:29:56,400
times the time to transmit a frame the

2185
01:29:56,400 --> 01:29:57,760
idea being even if there are two

2186
01:29:57,760 --> 01:29:59,199
concurrent permissions that can't hear

2187
01:29:59,199 --> 01:30:00,880
each other with high probability they

2188
01:30:00,880 --> 01:30:03,120
won't overlap in time

2189
01:30:03,120 --> 01:30:04,400
okay so

2190
01:30:04,400 --> 01:30:06,480
um the way this would work is that

2191
01:30:06,480 --> 01:30:08,560
uh each of these two nodes would send

2192
01:30:08,560 --> 01:30:11,120
its data once in order to go and they

2193
01:30:11,120 --> 01:30:12,960
would never collide but then when they

2194
01:30:12,960 --> 01:30:14,960
retry they'll transmit a second time at

2195
01:30:14,960 --> 01:30:16,639
hopefully different intervals and they

2196
01:30:16,639 --> 01:30:18,560
won't overlap in time and the

2197
01:30:18,560 --> 01:30:21,840
transmission will succeed okay so

2198
01:30:21,840 --> 01:30:22,639
um

2199
01:30:22,639 --> 01:30:24,320
we did a measurement study to understand

2200
01:30:24,320 --> 01:30:25,520
what kind of link delays would be

2201
01:30:25,520 --> 01:30:27,600
appropriate and what would work what we

2202
01:30:27,600 --> 01:30:29,360
observe is that there's a huge reduction

2203
01:30:29,360 --> 01:30:30,639
in packet loss

2204
01:30:30,639 --> 01:30:32,800
even from a small delay and as we

2205
01:30:32,800 --> 01:30:34,400
increase the delay too much it starts to

2206
01:30:34,400 --> 01:30:35,840
eat away at your good foot because now

2207
01:30:35,840 --> 01:30:37,679
you're beating a lot when transmitting

2208
01:30:37,679 --> 01:30:38,960
your packets

2209
01:30:38,960 --> 01:30:40,480
so we found that there's a sweet spot

2210
01:30:40,480 --> 01:30:42,239
here at around 40 milliseconds which is

2211
01:30:42,239 --> 01:30:44,000
about 10 times the time you transmit a

2212
01:30:44,000 --> 01:30:47,520
single frame and actually to the 15.4

2213
01:30:47,520 --> 01:30:50,000
so that's what we used in our study

2214
01:30:50,000 --> 01:30:50,880
um

2215
01:30:50,880 --> 01:30:52,639
and this reduced the packet loss from

2216
01:30:52,639 --> 01:30:55,040
six percent to one percent which was

2217
01:30:55,040 --> 01:30:56,159
which you consider a significant

2218
01:30:56,159 --> 01:30:58,159
improvement

2219
01:30:58,159 --> 01:30:59,760
so finally i'm going to summarize our

2220
01:30:59,760 --> 01:31:02,960
evaluation and and conclusions so

2221
01:31:02,960 --> 01:31:04,480
first i previewed this result at the

2222
01:31:04,480 --> 01:31:05,840
beginning we're able to achieve

2223
01:31:05,840 --> 01:31:07,520
significantly higher good put than prior

2224
01:31:07,520 --> 01:31:09,920
attempts at using tcp and we're very

2225
01:31:09,920 --> 01:31:11,440
close to a reasonable upper bound that

2226
01:31:11,440 --> 01:31:13,120
we computed based on measurements of how

2227
01:31:13,120 --> 01:31:15,040
fast the radio can send out packets and

2228
01:31:15,040 --> 01:31:18,800
the overhead loss to headers and x

2229
01:31:19,440 --> 01:31:21,520
we also did a measurement study to study

2230
01:31:21,520 --> 01:31:23,840
the energy efficiency so we used tcp and

2231
01:31:23,840 --> 01:31:26,080
co-app for a sentence and task and

2232
01:31:26,080 --> 01:31:27,840
measured the radio duty cycle over a

2233
01:31:27,840 --> 01:31:30,400
24-hour period and you can see the radio

2234
01:31:30,400 --> 01:31:31,840
duty cycle here

2235
01:31:31,840 --> 01:31:33,760
the key point is that tcp is not

2236
01:31:33,760 --> 01:31:35,600
significantly worse than co-app in fact

2237
01:31:35,600 --> 01:31:37,280
they perform comparably for the duration

2238
01:31:37,280 --> 01:31:39,280
of the experiment at about a two percent

2239
01:31:39,280 --> 01:31:41,199
duty cycle and we consider this a

2240
01:31:41,199 --> 01:31:43,280
success because tcp is able to perform

2241
01:31:43,280 --> 01:31:45,679
essentially on par as a protocol over

2242
01:31:45,679 --> 01:31:49,679
udp developed specifically for low bands

2243
01:31:49,679 --> 01:31:51,679
so now the tcp is a viable option what

2244
01:31:51,679 --> 01:31:53,600
does this mean well first we should

2245
01:31:53,600 --> 01:31:54,960
reconsider the use of lightweight

2246
01:31:54,960 --> 01:31:56,800
protocols that emulate part of tcp's

2247
01:31:56,800 --> 01:31:58,639
functionality

2248
01:31:58,639 --> 01:32:00,239
in the sense that you know if you have a

2249
01:32:00,239 --> 01:32:01,440
protocol that's specialized that

2250
01:32:01,440 --> 01:32:03,280
performs just as well as a general

2251
01:32:03,280 --> 01:32:05,120
protocol that's more interoperable and

2252
01:32:05,120 --> 01:32:06,960
used more broadly you should perhaps

2253
01:32:06,960 --> 01:32:08,639
prefer the one that's used more broadly

2254
01:32:08,639 --> 01:32:10,560
and is more interoperable

2255
01:32:10,560 --> 01:32:12,719
second we think that tcp may influence

2256
01:32:12,719 --> 01:32:14,880
the design of low-pan network systems in

2257
01:32:14,880 --> 01:32:16,400
the sense that you know for a long time

2258
01:32:16,400 --> 01:32:17,920
it's been the case that many sport home

2259
01:32:17,920 --> 01:32:19,679
devices that you buy on the market

2260
01:32:19,679 --> 01:32:21,520
require a specialized gateway to get

2261
01:32:21,520 --> 01:32:23,120
internet connectivity

2262
01:32:23,120 --> 01:32:25,920
um and tcp gives us the opportunity to

2263
01:32:25,920 --> 01:32:27,120
allow these devices to connect

2264
01:32:27,120 --> 01:32:29,920
end-to-end to any uh services externally

2265
01:32:29,920 --> 01:32:32,480
that they may depend on

2266
01:32:32,480 --> 01:32:34,000
and finally i just want to mention that

2267
01:32:34,000 --> 01:32:35,920
udp-based protocols i think will still

2268
01:32:35,920 --> 01:32:38,080
be used in lopens but just in the same

2269
01:32:38,080 --> 01:32:39,360
sense that they're used broadly in the

2270
01:32:39,360 --> 01:32:40,880
internet for applications where

2271
01:32:40,880 --> 01:32:42,400
specialized protocols substantially

2272
01:32:42,400 --> 01:32:44,080
outperform tcp

2273
01:32:44,080 --> 01:32:46,400
in cases where tcp performs on par with

2274
01:32:46,400 --> 01:32:48,960
specialized protocols using tcp is now a

2275
01:32:48,960 --> 01:32:51,360
viable option

2276
01:32:51,360 --> 01:32:53,679
so just to talk a little more about the

2277
01:32:53,679 --> 01:32:55,440
about the middle point about how tcp may

2278
01:32:55,440 --> 01:32:56,880
influence the design of low-pan network

2279
01:32:56,880 --> 01:32:59,360
systems when i say gateway architecture

2280
01:32:59,360 --> 01:33:00,960
i mean a setup like this where you have

2281
01:33:00,960 --> 01:33:02,560
your devices these smartphone devices

2282
01:33:02,560 --> 01:33:04,719
you bought on the market and in order to

2283
01:33:04,719 --> 01:33:06,000
allow them to communicate with an

2284
01:33:06,000 --> 01:33:07,520
application server and a data center

2285
01:33:07,520 --> 01:33:09,199
somewhere you have to install some

2286
01:33:09,199 --> 01:33:11,199
specific gateway in your home there is

2287
01:33:11,199 --> 01:33:12,560
some protocol translation and

2288
01:33:12,560 --> 01:33:14,560
application logic in order to bring

2289
01:33:14,560 --> 01:33:16,639
connectivity to those devices

2290
01:33:16,639 --> 01:33:18,239
uh what this means is is often the case

2291
01:33:18,239 --> 01:33:19,440
that some of you may have experienced

2292
01:33:19,440 --> 01:33:21,440
this is that if you go buy smart devices

2293
01:33:21,440 --> 01:33:22,880
from a new vendor

2294
01:33:22,880 --> 01:33:23,760
uh

2295
01:33:23,760 --> 01:33:25,920
now all of a sudden you need another

2296
01:33:25,920 --> 01:33:28,320
gateway for those new devices or even

2297
01:33:28,320 --> 01:33:30,000
maybe the newer versions of devices on

2298
01:33:30,000 --> 01:33:32,239
the same fender like for example uh for

2299
01:33:32,239 --> 01:33:34,480
a long time it was the case that for

2300
01:33:34,480 --> 01:33:36,960
life that if you have bulbs from say

2301
01:33:36,960 --> 01:33:38,560
lifx and bulbs from philips you would

2302
01:33:38,560 --> 01:33:40,639
need separate gateways for both of those

2303
01:33:40,639 --> 01:33:42,320
devices

2304
01:33:42,320 --> 01:33:43,600
um

2305
01:33:43,600 --> 01:33:46,480
so uh the the introduction of ip in this

2306
01:33:46,480 --> 01:33:47,360
space

2307
01:33:47,360 --> 01:33:48,960
didn't really change this in the sense

2308
01:33:48,960 --> 01:33:50,719
that now your application protocol on

2309
01:33:50,719 --> 01:33:52,480
the left is now implemented over ip but

2310
01:33:52,480 --> 01:33:54,000
you still need the application layer

2311
01:33:54,000 --> 01:33:56,239
gateway and the missing piece i think

2312
01:33:56,239 --> 01:33:58,960
that would allow an end-to-end

2313
01:33:58,960 --> 01:34:00,239
connection here would be to have a

2314
01:34:00,239 --> 01:34:01,840
transfer protocol that's supported on

2315
01:34:01,840 --> 01:34:04,800
both sides namely tcp and once you do

2316
01:34:04,800 --> 01:34:06,560
this your application layer gps become

2317
01:34:06,560 --> 01:34:08,000
regular border routers and you could

2318
01:34:08,000 --> 01:34:10,000
potentially consolidate these together

2319
01:34:10,000 --> 01:34:12,400
into a single border router

2320
01:34:12,400 --> 01:34:13,679
so

2321
01:34:13,679 --> 01:34:15,280
in conclusion

2322
01:34:15,280 --> 01:34:18,080
we implemented tcplp a full-scale tcp

2323
01:34:18,080 --> 01:34:19,920
stack for low-pan devices

2324
01:34:19,920 --> 01:34:21,679
uh we explained why the expected reasons

2325
01:34:21,679 --> 01:34:24,000
for poor tcp performance don't apply

2326
01:34:24,000 --> 01:34:25,679
uh we show how to address the actual

2327
01:34:25,679 --> 01:34:28,000
reasons for poor tcp performance and we

2328
01:34:28,000 --> 01:34:29,760
show that once the issues are resolved

2329
01:34:29,760 --> 01:34:31,760
tcp can perform comparably to low-pan

2330
01:34:31,760 --> 01:34:33,440
specialized protocols

2331
01:34:33,440 --> 01:34:34,880
that's all i have prepared i'm happy to

2332
01:34:34,880 --> 01:34:37,920
take any questions now

2333
01:34:41,119 --> 01:34:42,639
okay

2334
01:34:42,639 --> 01:34:44,960
thank you

2335
01:34:44,960 --> 01:34:48,080
sam now that's for that excellent talk

2336
01:34:48,080 --> 01:34:50,800
um i see we have a couple of people in

2337
01:34:50,800 --> 01:34:51,679
the

2338
01:34:51,679 --> 01:34:53,280
online queue and a couple of people at

2339
01:34:53,280 --> 01:34:54,719
the microphone

2340
01:34:54,719 --> 01:34:56,960
um should we do the uh

2341
01:34:56,960 --> 01:34:58,719
i guess they will do the microphone

2342
01:34:58,719 --> 01:35:00,400
first so

2343
01:35:00,400 --> 01:35:02,719
who that is but if you can go ahead and

2344
01:35:02,719 --> 01:35:06,159
say see your name in your question

2345
01:35:08,000 --> 01:35:10,320
so hi i'm matthias i'm one of the

2346
01:35:10,320 --> 01:35:12,000
co-founders of white great work thanks a

2347
01:35:12,000 --> 01:35:13,040
lot

2348
01:35:13,040 --> 01:35:15,760
um one remark and two questions uh

2349
01:35:15,760 --> 01:35:17,679
question first

2350
01:35:17,679 --> 01:35:19,920
so you argued that supporting tcp is

2351
01:35:19,920 --> 01:35:22,080
important because it's popular now quick

2352
01:35:22,080 --> 01:35:24,320
becomes popular did you work on any

2353
01:35:24,320 --> 01:35:26,960
comparison from the system point of view

2354
01:35:26,960 --> 01:35:30,239
um sorry i didn't quite hear what i said

2355
01:35:30,239 --> 01:35:33,119
becomes popular uh you said that tcp is

2356
01:35:33,119 --> 01:35:35,119
quite popular but quick also becomes

2357
01:35:35,119 --> 01:35:39,520
popular in the internet quick you know

2358
01:35:39,520 --> 01:35:42,639
quick so trying to quick quick yes yes

2359
01:35:42,639 --> 01:35:44,719
yeah yeah so did you do any comparison

2360
01:35:44,719 --> 01:35:46,560
uh so we didn't do a comparison against

2361
01:35:46,560 --> 01:35:47,840
quick but i'd like to comment on that

2362
01:35:47,840 --> 01:35:49,360
because that's a good point that other

2363
01:35:49,360 --> 01:35:51,520
transports are becoming popular many of

2364
01:35:51,520 --> 01:35:53,280
the issues that we addressed

2365
01:35:53,280 --> 01:35:55,199
aren't specific to tcp they apply

2366
01:35:55,199 --> 01:35:57,520
broadly to tcp and other protocols

2367
01:35:57,520 --> 01:35:58,960
needed for bulk transfer like for

2368
01:35:58,960 --> 01:36:00,000
example

2369
01:36:00,000 --> 01:36:02,239
um the main issues getting it to work

2370
01:36:02,239 --> 01:36:04,080
with hidden terminals getting it to play

2371
01:36:04,080 --> 01:36:06,159
well with link clear scheduling and so

2372
01:36:06,159 --> 01:36:08,639
on apply broadly to any protocol that's

2373
01:36:08,639 --> 01:36:10,800
transmitting a lot of data and wants a

2374
01:36:10,800 --> 01:36:12,480
significant amount of bandwidth

2375
01:36:12,480 --> 01:36:13,679
therefore i think that many of our

2376
01:36:13,679 --> 01:36:15,360
conclusions would actually apply equally

2377
01:36:15,360 --> 01:36:17,840
well to quickest due to tcp

2378
01:36:17,840 --> 01:36:18,880
okay

2379
01:36:18,880 --> 01:36:19,679
um

2380
01:36:19,679 --> 01:36:21,520
and another question i mean in your

2381
01:36:21,520 --> 01:36:23,360
paper you'll note that you also have an

2382
01:36:23,360 --> 01:36:25,280
implementation for gneic the default

2383
01:36:25,280 --> 01:36:27,520
networks they can write do you also plan

2384
01:36:27,520 --> 01:36:29,360
to submit the pierre to upstream's

2385
01:36:29,360 --> 01:36:31,840
implementation um

2386
01:36:31,840 --> 01:36:33,520
at some point we did have plans for that

2387
01:36:33,520 --> 01:36:35,040
but what happened is that riot os

2388
01:36:35,040 --> 01:36:36,800
already adopted a different tcp stack

2389
01:36:36,800 --> 01:36:38,080
and it seemed a bit redundant to

2390
01:36:38,080 --> 01:36:40,239
contribute a second one uh recently what

2391
01:36:40,239 --> 01:36:41,760
we have done is we have we must have

2392
01:36:41,760 --> 01:36:43,520
contributed our code to open thread

2393
01:36:43,520 --> 01:36:45,360
which now uses it as its default ecb

2394
01:36:45,360 --> 01:36:47,600
stack okay firstly i highly encourage

2395
01:36:47,600 --> 01:36:49,520
you to submit the pm

2396
01:36:49,520 --> 01:36:53,119
and finally remark um you said that

2397
01:36:53,119 --> 01:36:54,560
fragment needs to be

2398
01:36:54,560 --> 01:36:56,159
a packet needs to be is lost when the

2399
01:36:56,159 --> 01:36:58,239
fragment is lost i mean this depends a

2400
01:36:58,239 --> 01:36:59,760
little bit on the fragmentation screen

2401
01:36:59,760 --> 01:37:01,600
right if you consider for example

2402
01:37:01,600 --> 01:37:04,159
selective fragment recovery

2403
01:37:04,159 --> 01:37:05,040
um

2404
01:37:05,040 --> 01:37:07,440
it doesn't matter too much whether the

2405
01:37:07,440 --> 01:37:09,040
fragment is lost or not for the whole

2406
01:37:09,040 --> 01:37:10,000
packet

2407
01:37:10,000 --> 01:37:12,800
yeah so um my understanding about the

2408
01:37:12,800 --> 01:37:14,400
basic slope and work or at least the way

2409
01:37:14,400 --> 01:37:15,679
it was implemented in the operating

2410
01:37:15,679 --> 01:37:17,440
systems we looked at was indeed that if

2411
01:37:17,440 --> 01:37:18,960
a fragment is lost you lose the whole

2412
01:37:18,960 --> 01:37:21,040
packet but i do agree that there are

2413
01:37:21,040 --> 01:37:23,360
protocols you can use to recover a loss

2414
01:37:23,360 --> 01:37:24,639
for happening without losing the entire

2415
01:37:24,639 --> 01:37:26,480
packet and those could also help with

2416
01:37:26,480 --> 01:37:28,000
the problem allowing you to make the

2417
01:37:28,000 --> 01:37:30,320
packet bigger and amortize tcp ib

2418
01:37:30,320 --> 01:37:33,880
headers even better

2419
01:37:35,040 --> 01:37:37,119
all right hello um tommy paulie from

2420
01:37:37,119 --> 01:37:38,000
apple

2421
01:37:38,000 --> 01:37:40,719
thank you for doing this talk um very

2422
01:37:40,719 --> 01:37:42,000
interesting i'm

2423
01:37:42,000 --> 01:37:43,440
super happy to see

2424
01:37:43,440 --> 01:37:46,080
the use of tcp here um i just had a

2425
01:37:46,080 --> 01:37:48,480
couple questions from the presentation

2426
01:37:48,480 --> 01:37:50,400
um

2427
01:37:50,400 --> 01:37:52,159
way earlier and you don't have to go

2428
01:37:52,159 --> 01:37:54,320
back when you're talking about

2429
01:37:54,320 --> 01:37:55,760
the memory saving aspects and the

2430
01:37:55,760 --> 01:37:58,239
ability to have the flat

2431
01:37:58,239 --> 01:38:00,080
buffer you had the diagram there of you

2432
01:38:00,080 --> 01:38:02,960
know essentially here's kind of what's

2433
01:38:02,960 --> 01:38:04,560
in flight and then there's the out of

2434
01:38:04,560 --> 01:38:06,719
order bits

2435
01:38:06,719 --> 01:38:09,440
and there are gaps in there as well um

2436
01:38:09,440 --> 01:38:10,880
when you're doing this are you able to

2437
01:38:10,880 --> 01:38:13,040
essentially guarantee 100 of the time

2438
01:38:13,040 --> 01:38:14,320
that you'll never need to allocate

2439
01:38:14,320 --> 01:38:16,719
memory or is it like just most of the

2440
01:38:16,719 --> 01:38:18,080
time and then there would be a failover

2441
01:38:18,080 --> 01:38:19,679
case where you do need to have dynamic

2442
01:38:19,679 --> 01:38:22,159
allocation uh that's a great question uh

2443
01:38:22,159 --> 01:38:23,760
we ensure that you never have to

2444
01:38:23,760 --> 01:38:25,600
dynamically allocate memory cool and the

2445
01:38:25,600 --> 01:38:27,199
way we do it is that you store the data

2446
01:38:27,199 --> 01:38:29,360
there you have a bitmap to keep track of

2447
01:38:29,360 --> 01:38:31,760
which bits contain the out-of-order data

2448
01:38:31,760 --> 01:38:33,440
but the bitmap can also be sized

2449
01:38:33,440 --> 01:38:35,119
statically because it depends only on

2450
01:38:35,119 --> 01:38:37,679
the array size which is also static

2451
01:38:37,679 --> 01:38:40,480
got it okay cool

2452
01:38:40,480 --> 01:38:41,600
and then

2453
01:38:41,600 --> 01:38:43,040
the other question is more about kind of

2454
01:38:43,040 --> 01:38:44,880
what you're ending with talking about

2455
01:38:44,880 --> 01:38:48,000
how you can use this to get to internet

2456
01:38:48,000 --> 01:38:49,840
hosts and end

2457
01:38:49,840 --> 01:38:52,320
and i believe in your tests

2458
01:38:52,320 --> 01:38:54,560
you were testing against end-to-end

2459
01:38:54,560 --> 01:38:57,119
internet connections

2460
01:38:57,119 --> 01:39:00,320
for that do you need to modify anything

2461
01:39:00,320 --> 01:39:02,960
on the tcp implementation on the

2462
01:39:02,960 --> 01:39:04,400
internet servers because we were

2463
01:39:04,400 --> 01:39:05,679
mentioning things like timing the

2464
01:39:05,679 --> 01:39:07,280
re-transmit timing schedules that you

2465
01:39:07,280 --> 01:39:09,040
want to add randomness so you're not

2466
01:39:09,040 --> 01:39:10,800
colliding

2467
01:39:10,800 --> 01:39:13,040
um is this something that

2468
01:39:13,040 --> 01:39:14,800
needs tuning

2469
01:39:14,800 --> 01:39:17,600
on the internet hosts to make sure that

2470
01:39:17,600 --> 01:39:20,880
they are friendly to the low pan devices

2471
01:39:20,880 --> 01:39:23,600
or can you use completely unmodified

2472
01:39:23,600 --> 01:39:26,159
um internet hosts to talk to yeah that's

2473
01:39:26,159 --> 01:39:27,360
an excellent question and the short

2474
01:39:27,360 --> 01:39:29,119
answer is that the hosts on the linux

2475
01:39:29,119 --> 01:39:32,239
side were completely unmodified great um

2476
01:39:32,239 --> 01:39:34,480
i mean that's uh to say a little bit

2477
01:39:34,480 --> 01:39:36,320
more about that uh the timing that we

2478
01:39:36,320 --> 01:39:38,159
adjusted for like the randomized delay

2479
01:39:38,159 --> 01:39:40,000
was none of the tcp levels at the link

2480
01:39:40,000 --> 01:39:40,800
layer

2481
01:39:40,800 --> 01:39:42,639
so as a result the the other side

2482
01:39:42,639 --> 01:39:44,400
actually doesn't see any of that got it

2483
01:39:44,400 --> 01:39:46,400
um this is also one of the advantages to

2484
01:39:46,400 --> 01:39:48,400
us using a full scale tcp stack like the

2485
01:39:48,400 --> 01:39:49,920
one from freebsd because it's been

2486
01:39:49,920 --> 01:39:51,440
battle tested in the real world and it's

2487
01:39:51,440 --> 01:39:53,520
interoperable with all the major tcp

2488
01:39:53,520 --> 01:39:55,360
stacks that are out there and i just

2489
01:39:55,360 --> 01:39:57,360
want to say that uh interoperability is

2490
01:39:57,360 --> 01:39:59,440
actually a problem in the embedded space

2491
01:39:59,440 --> 01:40:01,360
many of the other tcp stacks you find

2492
01:40:01,360 --> 01:40:02,880
are have

2493
01:40:02,880 --> 01:40:04,480
have interoperability problems in pretty

2494
01:40:04,480 --> 01:40:06,400
subtle ways with the real tcp stacks

2495
01:40:06,400 --> 01:40:08,800
that are used and that's something we

2496
01:40:08,800 --> 01:40:10,719
manage a side step by using a battle

2497
01:40:10,719 --> 01:40:12,719
tested tcp implementation as the basis

2498
01:40:12,719 --> 01:40:13,840
of our study

2499
01:40:13,840 --> 01:40:16,540
cool thank you

2500
01:40:16,540 --> 01:40:18,080
[Music]

2501
01:40:18,080 --> 01:40:20,080
so hello this is thomas also from the

2502
01:40:20,080 --> 01:40:22,000
riot community thanks again for this

2503
01:40:22,000 --> 01:40:24,320
work thanks for using riot

2504
01:40:24,320 --> 01:40:25,600
there's

2505
01:40:25,600 --> 01:40:27,760
another encouragement using generosity

2506
01:40:27,760 --> 01:40:30,080
because you have a generic packet buffer

2507
01:40:30,080 --> 01:40:32,800
here which you could reuse that even

2508
01:40:32,800 --> 01:40:34,800
reduces your memory overhead even

2509
01:40:34,800 --> 01:40:37,280
further

2510
01:40:37,280 --> 01:40:39,199
just just a remark

2511
01:40:39,199 --> 01:40:40,639
one question about

2512
01:40:40,639 --> 01:40:41,840
about your

2513
01:40:41,840 --> 01:40:43,840
multi-hop experiments

2514
01:40:43,840 --> 01:40:46,560
you showed us nicely how by

2515
01:40:46,560 --> 01:40:50,320
jittering the the tcp forwarding how you

2516
01:40:50,320 --> 01:40:52,639
could avoid the hidden terminal problem

2517
01:40:52,639 --> 01:40:55,040
was that in a clean environment without

2518
01:40:55,040 --> 01:40:57,760
cross traffic with only a single tcp

2519
01:40:57,760 --> 01:40:59,440
connection

2520
01:40:59,440 --> 01:41:00,639
yeah so

2521
01:41:00,639 --> 01:41:02,960
uh the hidden terminal problem affects

2522
01:41:02,960 --> 01:41:04,639
even a single tcp connection in

2523
01:41:04,639 --> 01:41:06,080
isolation

2524
01:41:06,080 --> 01:41:08,960
um and we verify that our

2525
01:41:08,960 --> 01:41:10,960
randomized back off

2526
01:41:10,960 --> 01:41:13,040
fixes the problem in that case yeah but

2527
01:41:13,040 --> 01:41:15,040
only in this case i mean the normal case

2528
01:41:15,040 --> 01:41:16,400
is that you have background traffic

2529
01:41:16,400 --> 01:41:17,199
right

2530
01:41:17,199 --> 01:41:18,880
yeah yeah so i mean if you have

2531
01:41:18,880 --> 01:41:20,480
background traffic this is also why we

2532
01:41:20,480 --> 01:41:22,080
use randomized delays instead of fixed

2533
01:41:22,080 --> 01:41:24,639
delays because if you have a randomized

2534
01:41:24,639 --> 01:41:25,760
backup it doesn't matter the

2535
01:41:25,760 --> 01:41:27,600
interference is coming from the same

2536
01:41:27,600 --> 01:41:29,280
stream or a different stream

2537
01:41:29,280 --> 01:41:31,040
right in both cases you'll back up a

2538
01:41:31,040 --> 01:41:32,639
random amount and hopefully transmit

2539
01:41:32,639 --> 01:41:34,639
again without colliding

2540
01:41:34,639 --> 01:41:35,679
um

2541
01:41:35,679 --> 01:41:37,199
this is also why we did it without

2542
01:41:37,199 --> 01:41:38,480
because i mean there are several

2543
01:41:38,480 --> 01:41:40,800
particles you could use that look at tcp

2544
01:41:40,800 --> 01:41:42,320
state in some way

2545
01:41:42,320 --> 01:41:44,800
um and having it just be a randomized

2546
01:41:44,800 --> 01:41:46,080
delightfully the link clear gives us

2547
01:41:46,080 --> 01:41:47,679
some confidence that it would work

2548
01:41:47,679 --> 01:41:49,679
across tcp streams and regardless of the

2549
01:41:49,679 --> 01:41:51,679
source of traffic whether it's tcp

2550
01:41:51,679 --> 01:41:53,520
different tcp streams or even something

2551
01:41:53,520 --> 01:41:54,960
else

2552
01:41:54,960 --> 01:41:57,840
in this context did you also consider

2553
01:41:57,840 --> 01:42:00,960
experimenting with more flexible

2554
01:42:00,960 --> 01:42:03,520
link layer mac layers than

2555
01:42:03,520 --> 01:42:06,639
just a csm aca for instance the dsme

2556
01:42:06,639 --> 01:42:08,320
mech layer which is also supported by

2557
01:42:08,320 --> 01:42:09,360
riot

2558
01:42:09,360 --> 01:42:11,600
no we didn't experiment with that we

2559
01:42:11,600 --> 01:42:13,119
looked at the sme because that was the

2560
01:42:13,119 --> 01:42:15,040
most common one supported across all the

2561
01:42:15,040 --> 01:42:16,880
operating systems and networking

2562
01:42:16,880 --> 01:42:18,880
particles that we tried across tiny os

2563
01:42:18,880 --> 01:42:20,639
riot and open thread

2564
01:42:20,639 --> 01:42:22,239
so it's the most natural to focus on

2565
01:42:22,239 --> 01:42:23,280
that

2566
01:42:23,280 --> 01:42:24,960
okay thank you

2567
01:42:24,960 --> 01:42:26,840
thank

2568
01:42:26,840 --> 01:42:29,760
you all right thank you i think we have

2569
01:42:29,760 --> 01:42:30,480
a

2570
01:42:30,480 --> 01:42:33,440
remote question

2571
01:42:35,520 --> 01:42:39,199
am i unmuted finally

2572
01:42:39,199 --> 01:42:40,880
so uh this is following up on the

2573
01:42:40,880 --> 01:42:42,880
multi-hop case

2574
01:42:42,880 --> 01:42:45,440
uh so in these environments the uh

2575
01:42:45,440 --> 01:42:47,679
forwarding devices are in fact also very

2576
01:42:47,679 --> 01:42:49,119
low power low

2577
01:42:49,119 --> 01:42:51,360
uh resource devices

2578
01:42:51,360 --> 01:42:54,239
um did you see or could you speculate on

2579
01:42:54,239 --> 01:42:56,880
what you might see as to whether tcp

2580
01:42:56,880 --> 01:42:59,760
traffic would have more stress on the

2581
01:42:59,760 --> 01:43:00,880
buffers

2582
01:43:00,880 --> 01:43:03,199
of the forwarding multi-hop wireless

2583
01:43:03,199 --> 01:43:05,040
nodes

2584
01:43:05,040 --> 01:43:07,600
uh so that's a great question um first i

2585
01:43:07,600 --> 01:43:08,880
want to i mean

2586
01:43:08,880 --> 01:43:11,280
so first i just want to clarify that the

2587
01:43:11,280 --> 01:43:12,639
buffer is used at the intermediate

2588
01:43:12,639 --> 01:43:14,800
routers these aren't tcp layer buffers

2589
01:43:14,800 --> 01:43:16,320
it's just like the general packet

2590
01:43:16,320 --> 01:43:17,760
buffers used for forwarding because you

2591
01:43:17,760 --> 01:43:19,199
know an end-to-end tcp connection

2592
01:43:19,199 --> 01:43:21,040
there's no tcp state

2593
01:43:21,040 --> 01:43:22,800
sure sure sure but it may put a

2594
01:43:22,800 --> 01:43:24,639
different may put a different low

2595
01:43:24,639 --> 01:43:26,400
aggregate load

2596
01:43:26,400 --> 01:43:27,440
um

2597
01:43:27,440 --> 01:43:29,760
on those buffers than say co-app traffic

2598
01:43:29,760 --> 01:43:31,440
or something that's more

2599
01:43:31,440 --> 01:43:35,040
you know simple request response related

2600
01:43:35,040 --> 01:43:37,199
yeah so i mean of course it's the case

2601
01:43:37,199 --> 01:43:38,480
that when you're transmitting at higher

2602
01:43:38,480 --> 01:43:39,600
bandwidth you're going to place some

2603
01:43:39,600 --> 01:43:41,440
more stress on the on the buffers of the

2604
01:43:41,440 --> 01:43:43,760
intermediate uh of the intermediate

2605
01:43:43,760 --> 01:43:45,040
routers and there are a couple things

2606
01:43:45,040 --> 01:43:47,280
that that we do in that we actually did

2607
01:43:47,280 --> 01:43:48,880
in our study in order to help mitigate

2608
01:43:48,880 --> 01:43:50,880
that the first one is that we added some

2609
01:43:50,880 --> 01:43:52,560
active queue management functionality to

2610
01:43:52,560 --> 01:43:54,320
those intermediate routers where you

2611
01:43:54,320 --> 01:43:56,080
mark packets that's congested using

2612
01:43:56,080 --> 01:43:57,520
explicit connect using explicit

2613
01:43:57,520 --> 01:43:59,679
condition notification and so on in

2614
01:43:59,679 --> 01:44:01,440
order to prevent tcp from filling up the

2615
01:44:01,440 --> 01:44:03,040
entire buffer and keeping your cues

2616
01:44:03,040 --> 01:44:04,400
short

2617
01:44:04,400 --> 01:44:06,159
the primary reason we did this was to

2618
01:44:06,159 --> 01:44:08,159
improve fairness of different tcp flows

2619
01:44:08,159 --> 01:44:09,600
that are competing for buffer space of

2620
01:44:09,600 --> 01:44:11,600
these intermediate routers and also to

2621
01:44:11,600 --> 01:44:14,320
reduce the and also reduce the latency

2622
01:44:14,320 --> 01:44:16,480
of traffic uh but it also has a side

2623
01:44:16,480 --> 01:44:18,320
effect of limiting the amount of buffer

2624
01:44:18,320 --> 01:44:20,320
space that's being used by a single tcp

2625
01:44:20,320 --> 01:44:22,080
flow to address some of the concerns

2626
01:44:22,080 --> 01:44:24,639
that you brought up

2627
01:44:24,719 --> 01:44:27,679
thanks i was looking for the ac aqm

2628
01:44:27,679 --> 01:44:30,400
angle on that

2629
01:44:33,360 --> 01:44:35,199
all right uh

2630
01:44:35,199 --> 01:44:36,400
you have so

2631
01:44:36,400 --> 01:44:38,719
i have a question um

2632
01:44:38,719 --> 01:44:42,159
does the uh i i i very much like the

2633
01:44:42,159 --> 01:44:44,239
idea of the

2634
01:44:44,239 --> 01:44:46,719
headers multiple linked airframes

2635
01:44:46,719 --> 01:44:49,040
um does this put any constraints on the

2636
01:44:49,040 --> 01:44:51,119
link there or or does the six loop

2637
01:44:51,119 --> 01:44:53,360
handler

2638
01:44:53,360 --> 01:44:55,199
handle all of that

2639
01:44:55,199 --> 01:44:55,920
um

2640
01:44:55,920 --> 01:44:57,840
that's a great question so some of these

2641
01:44:57,840 --> 01:44:59,600
uh can potentially be handled at the

2642
01:44:59,600 --> 01:45:02,400
sixth low fan layer but others do indeed

2643
01:45:02,400 --> 01:45:04,880
have to do with with the uh with the

2644
01:45:04,880 --> 01:45:07,119
link layer directly like for example the

2645
01:45:07,119 --> 01:45:09,520
randomized delete that we added to avoid

2646
01:45:09,520 --> 01:45:11,360
hidden terminals is something that would

2647
01:45:11,360 --> 01:45:13,199
operate at the link layer right because

2648
01:45:13,199 --> 01:45:14,880
at the six little band layer

2649
01:45:14,880 --> 01:45:16,719
you don't have or at least you don't

2650
01:45:16,719 --> 01:45:18,000
naturally have the same kind of

2651
01:45:18,000 --> 01:45:20,239
visibility into you know when your link

2652
01:45:20,239 --> 01:45:22,080
clear acts are coming in and so on

2653
01:45:22,080 --> 01:45:23,920
whereas you would need that to determine

2654
01:45:23,920 --> 01:45:25,760
uh that resolution failed and how much

2655
01:45:25,760 --> 01:45:27,679
to back off on the retransmission and so

2656
01:45:27,679 --> 01:45:29,600
on so some of them do indeed affect the

2657
01:45:29,600 --> 01:45:31,360
link layer

2658
01:45:31,360 --> 01:45:33,199
yeah are the requirements that the link

2659
01:45:33,199 --> 01:45:36,000
layer delivers packets in order um to

2660
01:45:36,000 --> 01:45:38,800
avoid um damaging the headers or

2661
01:45:38,800 --> 01:45:42,000
or is six we're pen handling that

2662
01:45:42,000 --> 01:45:43,920
uh sorry i didn't understand your

2663
01:45:43,920 --> 01:45:45,840
question

2664
01:45:45,840 --> 01:45:47,760
is there a requirement that the link

2665
01:45:47,760 --> 01:45:50,639
layer delivers packets in order in order

2666
01:45:50,639 --> 01:45:52,400
because of the way you've uh sent the

2667
01:45:52,400 --> 01:45:54,080
headers split across multiple link their

2668
01:45:54,080 --> 01:45:56,320
frames um or is that all that the

2669
01:45:56,320 --> 01:45:58,719
reordering handled by six looper

2670
01:45:58,719 --> 01:46:00,800
oh yeah so the reordering and reassembly

2671
01:46:00,800 --> 01:46:02,639
is handled by six low pan and there's no

2672
01:46:02,639 --> 01:46:04,400
strict requirement that you have to

2673
01:46:04,400 --> 01:46:06,560
transmit the frames of a packet directly

2674
01:46:06,560 --> 01:46:08,639
one after the other consecutively in

2675
01:46:08,639 --> 01:46:10,000
fact one of the things that i skipped

2676
01:46:10,000 --> 01:46:11,440
because of the time limit was another

2677
01:46:11,440 --> 01:46:13,360
set of techniques we have

2678
01:46:13,360 --> 01:46:15,520
at the level of managing

2679
01:46:15,520 --> 01:46:17,360
how to deal with concurrent frames

2680
01:46:17,360 --> 01:46:19,119
basically how to schedule frames when

2681
01:46:19,119 --> 01:46:20,400
you're some of them are going to other

2682
01:46:20,400 --> 01:46:21,920
wall power devices some to battery

2683
01:46:21,920 --> 01:46:24,239
powered devices and in effect what we do

2684
01:46:24,239 --> 01:46:26,560
is if you if you receive a data request

2685
01:46:26,560 --> 01:46:28,639
from a battery-powered device then you

2686
01:46:28,639 --> 01:46:30,400
prioritize sending frames to that in

2687
01:46:30,400 --> 01:46:32,320
order to reduce its duty cycle and let

2688
01:46:32,320 --> 01:46:34,800
it go to sleep as fast as possible and

2689
01:46:34,800 --> 01:46:36,719
that's one case where we specifically

2690
01:46:36,719 --> 01:46:39,199
might interrupt another transmission and

2691
01:46:39,199 --> 01:46:41,360
not send its frames concurrently i mean

2692
01:46:41,360 --> 01:46:44,719
nuts in the streams consecutively

2693
01:46:46,800 --> 01:46:50,320
okay yeah that makes sense okay

2694
01:46:50,320 --> 01:46:53,320
gabrielle

2695
01:46:54,880 --> 01:46:57,119
me

2696
01:46:57,440 --> 01:46:59,520
hear me when

2697
01:46:59,520 --> 01:47:00,480
okay

2698
01:47:00,480 --> 01:47:02,960
um yeah thank you very much

2699
01:47:02,960 --> 01:47:05,679
for this work this is great stuff

2700
01:47:05,679 --> 01:47:06,560
um

2701
01:47:06,560 --> 01:47:08,400
i did have a

2702
01:47:08,400 --> 01:47:10,560
comment on

2703
01:47:10,560 --> 01:47:13,600
the comparison with co-app i think the

2704
01:47:13,600 --> 01:47:16,480
specification for co-app was not

2705
01:47:16,480 --> 01:47:18,080
entirely

2706
01:47:18,080 --> 01:47:19,760
based on

2707
01:47:19,760 --> 01:47:22,080
we can't use tcp type that thing it was

2708
01:47:22,080 --> 01:47:24,480
more based on we can't use http because

2709
01:47:24,480 --> 01:47:27,760
the justification for it was for

2710
01:47:27,760 --> 01:47:29,679
folks who wanted to use a restful

2711
01:47:29,679 --> 01:47:31,600
interface for the application layer not

2712
01:47:31,600 --> 01:47:34,159
every application of the year in iot

2713
01:47:34,159 --> 01:47:36,880
wishes to do that but there's certainly

2714
01:47:36,880 --> 01:47:40,400
a lot uh of a lot of incentive

2715
01:47:40,400 --> 01:47:42,320
to use restful so

2716
01:47:42,320 --> 01:47:43,920
uh when

2717
01:47:43,920 --> 01:47:47,440
when um the restful folks

2718
01:47:47,440 --> 01:47:49,760
started

2719
01:47:49,760 --> 01:47:51,840
to become interested in iot the only

2720
01:47:51,840 --> 01:47:55,119
alternative was http one one which uh

2721
01:47:55,119 --> 01:47:57,920
i completely agree is terrible uh it's

2722
01:47:57,920 --> 01:48:00,480
massager it's textual based vertical you

2723
01:48:00,480 --> 01:48:02,800
cannot compress it it's it's very

2724
01:48:02,800 --> 01:48:05,760
verbose et cetera it's it's terrible

2725
01:48:05,760 --> 01:48:08,480
um we subsequently had http 2 which

2726
01:48:08,480 --> 01:48:10,320
became a binary protocol and we actually

2727
01:48:10,320 --> 01:48:11,920
had a paper

2728
01:48:11,920 --> 01:48:14,560
uh three years ago in a in our w about

2729
01:48:14,560 --> 01:48:16,000
you know how to use that over something

2730
01:48:16,000 --> 01:48:18,800
like 6lowpan for example some just

2731
01:48:18,800 --> 01:48:20,800
initial scratching the surface but now

2732
01:48:20,800 --> 01:48:23,199
we have http 3 and quick and it's all

2733
01:48:23,199 --> 01:48:26,239
binary so um

2734
01:48:26,239 --> 01:48:27,199
i

2735
01:48:27,199 --> 01:48:29,119
i understand you you guys haven't had a

2736
01:48:29,119 --> 01:48:31,280
chance to go after the excellent work

2737
01:48:31,280 --> 01:48:32,639
you've done to look at those layers but

2738
01:48:32,639 --> 01:48:34,080
i would highly encourage you to do that

2739
01:48:34,080 --> 01:48:37,119
because that would that would address um

2740
01:48:37,119 --> 01:48:39,440
a significant portion of the

2741
01:48:39,440 --> 01:48:42,239
of the application layer incentives

2742
01:48:42,239 --> 01:48:43,040
um

2743
01:48:43,040 --> 01:48:44,719
to um

2744
01:48:44,719 --> 01:48:47,119
for iot as well

2745
01:48:47,119 --> 01:48:48,960
yeah so uh so thanks for

2746
01:48:48,960 --> 01:48:51,600
clarifying that um i do acknowledge that

2747
01:48:51,600 --> 01:48:53,440
co-op has has evolved quite a bit in a

2748
01:48:53,440 --> 01:48:54,719
few years some of those evolutions

2749
01:48:54,719 --> 01:48:56,960
happen after after we published this

2750
01:48:56,960 --> 01:49:01,119
work uh but i do want to uh to clarify

2751
01:49:01,119 --> 01:49:03,760
my position on co-op a little bit uh

2752
01:49:03,760 --> 01:49:05,679
based on what you said it's that uh

2753
01:49:05,679 --> 01:49:07,600
indeed i think that co-op is useful and

2754
01:49:07,600 --> 01:49:09,520
it has its uses and it's very flexible

2755
01:49:09,520 --> 01:49:10,960
it's been evolving a lot over the years

2756
01:49:10,960 --> 01:49:13,920
and that's great um i do i mean i have

2757
01:49:13,920 --> 01:49:16,080
noticed that coap has been evolving in

2758
01:49:16,080 --> 01:49:17,760
some sense more and more towards the

2759
01:49:17,760 --> 01:49:19,520
same kind of abstraction that tcp

2760
01:49:19,520 --> 01:49:21,599
provides right in some sense uh the

2761
01:49:21,599 --> 01:49:22,960
ability like for example with some of

2762
01:49:22,960 --> 01:49:25,440
the recent work on on streaming on

2763
01:49:25,440 --> 01:49:28,159
streaming block transfers and so on

2764
01:49:28,159 --> 01:49:29,760
all i'm seeing here is that i think that

2765
01:49:29,760 --> 01:49:32,159
an application that's built on coap in

2766
01:49:32,159 --> 01:49:33,840
these kinds of networks with all the

2767
01:49:33,840 --> 01:49:35,360
latest features like for example the

2768
01:49:35,360 --> 01:49:36,800
ability to have multiple blocks in

2769
01:49:36,800 --> 01:49:39,679
flight concurrently and so on would also

2770
01:49:39,679 --> 01:49:41,840
be wise to potentially consider using

2771
01:49:41,840 --> 01:49:44,320
tcp directly itself given that tcp is

2772
01:49:44,320 --> 01:49:48,080
also a viable option in these networks

2773
01:49:48,480 --> 01:49:51,440
but thanks for that comment

2774
01:49:52,480 --> 01:49:54,159
all right thank you

2775
01:49:54,159 --> 01:49:57,679
one more question uh benjamin uh salt

2776
01:49:57,679 --> 01:50:00,320
summit closet

2777
01:50:00,320 --> 01:50:02,239
i thank you so much for the presentation

2778
01:50:02,239 --> 01:50:04,400
i really appreciate it um i was just

2779
01:50:04,400 --> 01:50:06,400
wondering you talked mainly about the

2780
01:50:06,400 --> 01:50:09,760
applications of this in um in lans do

2781
01:50:09,760 --> 01:50:11,760
you see any application for longer range

2782
01:50:11,760 --> 01:50:14,400
networks like uh like mobile ad hoc

2783
01:50:14,400 --> 01:50:17,599
networks or anything of that sort

2784
01:50:17,599 --> 01:50:20,480
uh that's a great question so all of our

2785
01:50:20,480 --> 01:50:23,360
experimentation was uh was done using

2786
01:50:23,360 --> 01:50:26,080
ieee introduce 15.4 which is a personal

2787
01:50:26,080 --> 01:50:28,159
area network protocol and that was

2788
01:50:28,159 --> 01:50:30,239
motivated by the recent interest in

2789
01:50:30,239 --> 01:50:32,560
adopting some of that technology uh to

2790
01:50:32,560 --> 01:50:35,679
work in the smart home and iot space um

2791
01:50:35,679 --> 01:50:37,920
some of the i mean some of these lessons

2792
01:50:37,920 --> 01:50:40,000
might carry you over to the mobile and

2793
01:50:40,000 --> 01:50:42,000
an ad hoc network space like lp vans and

2794
01:50:42,000 --> 01:50:44,480
so on um i'm not sure i'll be able to

2795
01:50:44,480 --> 01:50:45,840
tell you any specifics given that i

2796
01:50:45,840 --> 01:50:47,119
don't have much experience with those

2797
01:50:47,119 --> 01:50:49,920
networks um but i mean

2798
01:50:49,920 --> 01:50:52,080
my first gut would be there's probably a

2799
01:50:52,080 --> 01:50:53,760
way to make tcp work well given that

2800
01:50:53,760 --> 01:50:55,280
it's been adapted to work on so many

2801
01:50:55,280 --> 01:50:57,760
different kinds of networks uh in all

2802
01:50:57,760 --> 01:50:59,440
kinds of different environments but

2803
01:50:59,440 --> 01:51:01,280
other than that i'm not sure if any of

2804
01:51:01,280 --> 01:51:02,639
this which of the specific techniques

2805
01:51:02,639 --> 01:51:04,840
would directly carry over

2806
01:51:04,840 --> 01:51:08,639
there thank you so much

2807
01:51:13,679 --> 01:51:18,080
all right uh thank you very much

2808
01:51:18,639 --> 01:51:20,180
excellent talk

2809
01:51:20,180 --> 01:51:24,560
[Applause]

2810
01:51:24,560 --> 01:51:25,520
uh

2811
01:51:25,520 --> 01:51:27,840
and thank you again to to both of the

2812
01:51:27,840 --> 01:51:29,679
speakers i think there were two two

2813
01:51:29,679 --> 01:51:32,480
really great talks there um

2814
01:51:32,480 --> 01:51:35,920
both uh sam and tasha will be uh around

2815
01:51:35,920 --> 01:51:37,520
all week uh i'm sure they'll be very

2816
01:51:37,520 --> 01:51:39,840
happy to talk with people more about

2817
01:51:39,840 --> 01:51:41,920
their work uh so

2818
01:51:41,920 --> 01:51:44,320
please do to find them have a chat chat

2819
01:51:44,320 --> 01:51:46,400
about their work make them welcome to

2820
01:51:46,400 --> 01:51:49,199
the the ietf and to the irtf

2821
01:51:49,199 --> 01:51:51,599
uh congratulations both to

2822
01:51:51,599 --> 01:51:54,480
uh sam and tasha for the award of the

2823
01:51:54,480 --> 01:51:56,400
anrp this time

2824
01:51:56,400 --> 01:51:57,280
um

2825
01:51:57,280 --> 01:51:59,760
as i said earlier look out for

2826
01:51:59,760 --> 01:52:03,679
more a rp award talks um at the the uh

2827
01:52:03,679 --> 01:52:06,560
itf one five in london in november

2828
01:52:06,560 --> 01:52:10,639
uh the nominations for the uh 2023 uh a

2829
01:52:10,639 --> 01:52:12,560
rp awards will be opening in september

2830
01:52:12,560 --> 01:52:15,199
so um if you know any good work please

2831
01:52:15,199 --> 01:52:17,599
think about nominating that work

2832
01:52:17,599 --> 01:52:19,840
and look out for the applied networking

2833
01:52:19,840 --> 01:52:22,000
research workshop which is taking place

2834
01:52:22,000 --> 01:52:24,000
uh co-locating with the itf in

2835
01:52:24,000 --> 01:52:26,000
philadelphia tomorrow

2836
01:52:26,000 --> 01:52:28,800
um thank you again everybody

2837
01:52:28,800 --> 01:52:31,679
hopefully i will see some or all of you

2838
01:52:31,679 --> 01:52:34,960
in london or at the end nrw tomorrow or

2839
01:52:34,960 --> 01:52:36,480
later this week

2840
01:52:36,480 --> 01:52:39,799
thanks everyone

2841
01:53:21,760 --> 01:53:23,840
you

