1
00:00:15,839 --> 00:00:17,920
hello everyone

2
00:00:17,920 --> 00:00:20,960
can you hear me richard

3
00:00:21,600 --> 00:00:24,320
ah very good

4
00:00:26,720 --> 00:00:30,240
all right we'll just give it

5
00:00:30,240 --> 00:00:32,960
a minute more

6
00:00:33,280 --> 00:00:37,200
but in the meantime if anyone

7
00:00:37,200 --> 00:00:40,800
would like to volunteer

8
00:00:40,800 --> 00:00:44,960
to do um to take down the minutes

9
00:00:44,960 --> 00:00:46,480
that save us some time going through the

10
00:00:46,480 --> 00:00:48,879
presentations that give us more time to

11
00:00:48,879 --> 00:00:51,920
do more interesting discussions

12
00:00:51,920 --> 00:00:59,840
let me put it that way

13
00:01:04,690 --> 00:01:06,080
[Music]

14
00:01:06,080 --> 00:01:09,439
are you volunteering richard

15
00:01:09,760 --> 00:01:11,040
i will take that as richard is

16
00:01:11,040 --> 00:01:13,040
volunteering

17
00:01:13,040 --> 00:01:16,159
aha there you go well done

18
00:01:16,159 --> 00:01:20,400
thank you sir so um

19
00:01:20,400 --> 00:01:26,720
i'll call you out in a moment

20
00:01:26,720 --> 00:01:29,520
and if we

21
00:01:31,600 --> 00:01:34,159
do we need a job ascribe for this i'm

22
00:01:34,159 --> 00:01:36,079
tempted to say no unless somebody says

23
00:01:36,079 --> 00:01:37,040
we should

24
00:01:37,040 --> 00:01:41,840
i'm not gonna ask for a job ascribe

25
00:02:14,400 --> 00:02:16,720
well

26
00:02:19,280 --> 00:02:23,840
if i can get this going right

27
00:02:25,040 --> 00:02:26,959
i'm going to try to share my screen from

28
00:02:26,959 --> 00:02:29,200
here

29
00:02:32,319 --> 00:02:34,959
do you want to share your screen yes i

30
00:02:34,959 --> 00:02:37,840
did not change my mind

31
00:02:43,280 --> 00:02:45,760
all right i think people can see my

32
00:02:45,760 --> 00:02:46,480
screen

33
00:02:46,480 --> 00:02:51,840
yes i can see it clearly

34
00:02:53,040 --> 00:02:56,560
all right very good

35
00:02:57,599 --> 00:03:04,800
there you go even better

36
00:03:04,800 --> 00:03:07,840
um all right

37
00:03:07,840 --> 00:03:09,599
let's get started it's a few minutes

38
00:03:09,599 --> 00:03:11,040
past the hour

39
00:03:11,040 --> 00:03:15,599
and uh welcome to iccrg everyone

40
00:03:15,599 --> 00:03:19,680
um it's ridiculously early for me it's

41
00:03:19,680 --> 00:03:21,120
four in the morning for me

42
00:03:21,120 --> 00:03:23,440
hopefully it's a more sane time for many

43
00:03:23,440 --> 00:03:24,640
of you

44
00:03:24,640 --> 00:03:27,680
um but uh i'm

45
00:03:27,680 --> 00:03:28,799
looking forward to this session

46
00:03:28,799 --> 00:03:30,720
hopefully this will wake you up

47
00:03:30,720 --> 00:03:32,799
and hopefully you'll be engaged as we go

48
00:03:32,799 --> 00:03:34,720
through this

49
00:03:34,720 --> 00:03:37,840
um so let's just start off

50
00:03:37,840 --> 00:03:41,040
with a couple of notes

51
00:03:41,040 --> 00:03:46,000
at a high level just uh note well oh

52
00:03:46,000 --> 00:03:46,879
hang on

53
00:03:46,879 --> 00:03:48,560
let me fix this so you can actually see

54
00:03:48,560 --> 00:03:51,280
it there you go

55
00:03:58,720 --> 00:04:03,439
i'm reading chris's note here

56
00:04:04,080 --> 00:04:06,159
all right chris if you're willing and

57
00:04:06,159 --> 00:04:07,599
able to do this i would very much

58
00:04:07,599 --> 00:04:15,839
appreciate that then

59
00:04:20,238 --> 00:04:21,358
all right we'll go through that in a

60
00:04:21,358 --> 00:04:23,600
second so that's the note well um

61
00:04:23,600 --> 00:04:25,440
if you haven't taken a look at it please

62
00:04:25,440 --> 00:04:26,800
do uh

63
00:04:26,800 --> 00:04:29,120
please read it before you you uh

64
00:04:29,120 --> 00:04:31,120
participate at the mic

65
00:04:31,120 --> 00:04:33,120
i'm not gonna walk through all of it in

66
00:04:33,120 --> 00:04:34,639
in in detail

67
00:04:34,639 --> 00:04:36,720
but uh that and then you note on the

68
00:04:36,720 --> 00:04:37,840
code of conduct

69
00:04:37,840 --> 00:04:40,880
that we are bound by the iit of code of

70
00:04:40,880 --> 00:04:42,639
conduct if this is important

71
00:04:42,639 --> 00:04:44,880
uh please make sure you've seen this as

72
00:04:44,880 --> 00:04:46,160
well

73
00:04:46,160 --> 00:04:48,160
and read this as well before you

74
00:04:48,160 --> 00:04:49,440
participate

75
00:04:49,440 --> 00:04:52,160
um and here's the high level goals for

76
00:04:52,160 --> 00:04:54,240
the irtf and reminded the folks here

77
00:04:54,240 --> 00:04:55,199
that the irtf

78
00:04:55,199 --> 00:04:57,600
is not a standards development

79
00:04:57,600 --> 00:04:58,560
organization

80
00:04:58,560 --> 00:05:02,160
it is a research organization and

81
00:05:02,160 --> 00:05:05,600
uh with that i will jump into the agenda

82
00:05:05,600 --> 00:05:06,720
for today

83
00:05:06,720 --> 00:05:11,120
so we have a several presentations today

84
00:05:11,120 --> 00:05:12,880
and we have a

85
00:05:12,880 --> 00:05:16,560
an excellent uh agenda here uh with

86
00:05:16,560 --> 00:05:20,000
with uh events which are we i'll talk

87
00:05:20,000 --> 00:05:21,600
about the first one in a moment

88
00:05:21,600 --> 00:05:23,600
but um we have a number of presentations

89
00:05:23,600 --> 00:05:25,039
and i hope uh that

90
00:05:25,039 --> 00:05:27,199
everybody stays engaged to the entire

91
00:05:27,199 --> 00:05:28,639
meeting

92
00:05:28,639 --> 00:05:31,759
i uh um i'll thank richard

93
00:05:31,759 --> 00:05:35,120
for for uh taking down the minutes

94
00:05:35,120 --> 00:05:38,479
and as chris pointed out on the chat

95
00:05:38,479 --> 00:05:41,360
if somebody wants any comments my any

96
00:05:41,360 --> 00:05:42,479
comments to be

97
00:05:42,479 --> 00:05:45,199
voiced at the mic please prefix it with

98
00:05:45,199 --> 00:05:46,800
mike in this chat

99
00:05:46,800 --> 00:05:50,000
and chris has offered to kindly

100
00:05:50,000 --> 00:05:52,000
deliver them at the mic and i'll take

101
00:05:52,000 --> 00:05:54,320
him up on that

102
00:05:54,320 --> 00:05:57,680
that is about all from from me

103
00:05:57,680 --> 00:06:01,440
i am going to now kick off the first

104
00:06:01,440 --> 00:06:02,639
presentation

105
00:06:02,639 --> 00:06:05,919
from rui now this is a slightly unusual

106
00:06:05,919 --> 00:06:07,520
presentation in that we are actually

107
00:06:07,520 --> 00:06:09,120
going to be talking about

108
00:06:09,120 --> 00:06:12,479
a congestion control that is more

109
00:06:12,479 --> 00:06:17,039
um it's more geared towards

110
00:06:17,039 --> 00:06:20,000
data centers uh we will kick it off with

111
00:06:20,000 --> 00:06:21,520
that presentation

112
00:06:21,520 --> 00:06:24,960
rui do you want to

113
00:06:24,960 --> 00:06:26,639
i'm looking here to see do you have to

114
00:06:26,639 --> 00:06:28,720
come up and ask for

115
00:06:28,720 --> 00:06:31,759
camera and mike uh

116
00:06:31,759 --> 00:06:36,000
can you hear me now yes we can hear you

117
00:06:36,000 --> 00:06:41,360
okay let me get you going

118
00:06:42,639 --> 00:06:47,039
okay perfect go for it

119
00:06:47,199 --> 00:06:50,639
um hi everyone this is raymil

120
00:06:50,639 --> 00:06:54,080
from alibaba group so today we were

121
00:06:54,080 --> 00:06:58,000
trying to introduce the hpcc plus plus

122
00:06:58,000 --> 00:07:02,400
so we use use http plus plus to

123
00:07:02,400 --> 00:07:04,960
control the conjunction precisely which

124
00:07:04,960 --> 00:07:06,000
you can

125
00:07:06,000 --> 00:07:08,639
achieve near zero q in our data center

126
00:07:08,639 --> 00:07:10,319
and also

127
00:07:10,319 --> 00:07:13,039
maintain very high throughput so this is

128
00:07:13,039 --> 00:07:13,759
our work

129
00:07:13,759 --> 00:07:17,120
we publish in sitcom 2019

130
00:07:17,120 --> 00:07:19,680
and then after that we actively deployed

131
00:07:19,680 --> 00:07:20,240
this

132
00:07:20,240 --> 00:07:23,280
technique into alibaba cloud and with

133
00:07:23,280 --> 00:07:23,840
many

134
00:07:23,840 --> 00:07:26,639
other vendors so by that time we think

135
00:07:26,639 --> 00:07:27,199
like

136
00:07:27,199 --> 00:07:30,800
we are working with many vendors to

137
00:07:30,800 --> 00:07:33,280
want to standardize this algorithm and

138
00:07:33,280 --> 00:07:34,960
this design so

139
00:07:34,960 --> 00:07:38,000
we can be aligned in the in the same

140
00:07:38,000 --> 00:07:41,840
setting so

141
00:07:41,840 --> 00:07:45,840
next page

142
00:07:50,960 --> 00:07:55,440
okay so so the motivation for our design

143
00:07:55,440 --> 00:07:56,560
is like

144
00:07:56,560 --> 00:07:58,960
today in the clouds we design very high

145
00:07:58,960 --> 00:08:00,400
performance networking

146
00:08:00,400 --> 00:08:03,120
so there are a couple of motivation uh

147
00:08:03,120 --> 00:08:04,400
for our design

148
00:08:04,400 --> 00:08:07,680
first is the first um

149
00:08:07,680 --> 00:08:09,360
application in the cloud right now is

150
00:08:09,360 --> 00:08:11,599
very sensitive to

151
00:08:11,599 --> 00:08:15,199
latency inflation for example in the ebs

152
00:08:15,199 --> 00:08:18,879
elastic block storage the sra guarantee

153
00:08:18,879 --> 00:08:21,680
on the latency is 200 microseconds

154
00:08:21,680 --> 00:08:23,759
and some other like key value

155
00:08:23,759 --> 00:08:26,560
application memory id application

156
00:08:26,560 --> 00:08:29,599
also requires some millisecond latency

157
00:08:29,599 --> 00:08:33,360
so we we think that makes the network

158
00:08:33,360 --> 00:08:35,440
become one more important

159
00:08:35,440 --> 00:08:37,599
the second is that this many

160
00:08:37,599 --> 00:08:38,559
applications

161
00:08:38,559 --> 00:08:40,640
such as high performance storage and the

162
00:08:40,640 --> 00:08:41,760
distributed

163
00:08:41,760 --> 00:08:44,959
deep learning application that use

164
00:08:44,959 --> 00:08:48,080
a device hardware that can generate

165
00:08:48,080 --> 00:08:50,800
the data orders magnitude faster and

166
00:08:50,800 --> 00:08:51,600
also require

167
00:08:51,600 --> 00:08:54,240
outer low latency for those applications

168
00:08:54,240 --> 00:08:56,480
so that network become a new bottleneck

169
00:08:56,480 --> 00:08:58,880
in our system

170
00:08:58,880 --> 00:09:00,880
and the last part is the new

171
00:09:00,880 --> 00:09:02,640
architecture is happening

172
00:09:02,640 --> 00:09:05,120
in the cloud for example the resource

173
00:09:05,120 --> 00:09:06,320
disaggregation

174
00:09:06,320 --> 00:09:09,440
which separates the compute

175
00:09:09,440 --> 00:09:11,440
memory and the disk into separate

176
00:09:11,440 --> 00:09:12,880
resources pools

177
00:09:12,880 --> 00:09:14,959
so even memory access will go through a

178
00:09:14,959 --> 00:09:16,399
network in the future

179
00:09:16,399 --> 00:09:19,440
so in this case the network becomes

180
00:09:19,440 --> 00:09:22,560
very important require very

181
00:09:22,560 --> 00:09:25,760
low latency for those settings

182
00:09:25,760 --> 00:09:30,000
so please next page

183
00:09:32,320 --> 00:09:35,760
so to support those applications

184
00:09:35,760 --> 00:09:39,120
the silicon manufacturer

185
00:09:39,120 --> 00:09:42,560
generate fast asics because the

186
00:09:42,560 --> 00:09:44,399
traditional softwares that cannot keep

187
00:09:44,399 --> 00:09:45,680
up with the speed

188
00:09:45,680 --> 00:09:49,360
so the hardware offloading is inevitable

189
00:09:49,360 --> 00:09:53,440
so however using faster hardware

190
00:09:53,440 --> 00:09:56,000
can generate traffic more aggressively

191
00:09:56,000 --> 00:09:58,160
the network congestion becomes a severe

192
00:09:58,160 --> 00:09:59,680
problem for our clouds

193
00:09:59,680 --> 00:10:01,680
for example we running rdma in our

194
00:10:01,680 --> 00:10:02,880
network we

195
00:10:02,880 --> 00:10:06,480
we find that there are lots of pfc store

196
00:10:06,480 --> 00:10:09,760
and also data lock events so we find

197
00:10:09,760 --> 00:10:11,279
it's necessary to solve the conjugation

198
00:10:11,279 --> 00:10:14,640
control problem in this case

199
00:10:14,640 --> 00:10:19,839
next please

200
00:10:21,120 --> 00:10:24,800
so um we identify a couple of key issues

201
00:10:24,800 --> 00:10:25,680
in our

202
00:10:25,680 --> 00:10:27,360
conjunction control er high speed

203
00:10:27,360 --> 00:10:29,839
network the first issue that we

204
00:10:29,839 --> 00:10:32,160
observe lots of pfc store and the

205
00:10:32,160 --> 00:10:33,839
deadlock event

206
00:10:33,839 --> 00:10:37,440
in our rdma network and we

207
00:10:37,440 --> 00:10:41,120
we find that's a cause of stability

208
00:10:41,120 --> 00:10:41,600
issue

209
00:10:41,600 --> 00:10:44,480
in our network however we cannot disable

210
00:10:44,480 --> 00:10:45,440
pfc

211
00:10:45,440 --> 00:10:47,600
because that will affect the application

212
00:10:47,600 --> 00:10:49,120
performance as well

213
00:10:49,120 --> 00:10:52,160
so the key the key uh

214
00:10:52,160 --> 00:10:55,440
insight for this limitation is that the

215
00:10:55,440 --> 00:10:58,480
current congestion control algorithm is

216
00:10:58,480 --> 00:10:58,800
has

217
00:10:58,800 --> 00:11:01,839
has a very slow convergence speed so

218
00:11:01,839 --> 00:11:03,920
so that's the essential part we want to

219
00:11:03,920 --> 00:11:05,440
address

220
00:11:05,440 --> 00:11:08,320
the second issue that we want to run

221
00:11:08,320 --> 00:11:09,200
application

222
00:11:09,200 --> 00:11:12,000
mix of application in the same cluster

223
00:11:12,000 --> 00:11:12,880
however

224
00:11:12,880 --> 00:11:15,600
we cannot achieve both high throughput

225
00:11:15,600 --> 00:11:17,200
and the low latency for different

226
00:11:17,200 --> 00:11:18,399
applications

227
00:11:18,399 --> 00:11:21,680
so the essential reason for that is

228
00:11:21,680 --> 00:11:23,760
the traditional condition control

229
00:11:23,760 --> 00:11:26,240
algorithm rely on the standing queue

230
00:11:26,240 --> 00:11:29,600
so when the queue build up the condition

231
00:11:29,600 --> 00:11:30,880
control works

232
00:11:30,880 --> 00:11:32,800
uh start to work to react to the

233
00:11:32,800 --> 00:11:35,360
congestion however

234
00:11:35,360 --> 00:11:37,760
when the standing cube build up the

235
00:11:37,760 --> 00:11:39,040
application latency

236
00:11:39,040 --> 00:11:43,760
has already been affected

237
00:11:43,760 --> 00:11:47,839
the last part is we we run dcqc which is

238
00:11:47,839 --> 00:11:49,279
a state of art

239
00:11:49,279 --> 00:11:50,800
conjunction control algorithm for the

240
00:11:50,800 --> 00:11:52,320
rdma network

241
00:11:52,320 --> 00:11:54,560
and that we find that those those

242
00:11:54,560 --> 00:11:55,519
algorithms

243
00:11:55,519 --> 00:11:59,279
rely on the heuristic to configure their

244
00:11:59,279 --> 00:12:02,399
algorithms so for example in dcqcn they

245
00:12:02,399 --> 00:12:05,760
use at least 15 parameter

246
00:12:05,760 --> 00:12:08,720
so to to to work with the congestion

247
00:12:08,720 --> 00:12:09,519
control

248
00:12:09,519 --> 00:12:12,320
so in our case it's really time

249
00:12:12,320 --> 00:12:13,440
consuming

250
00:12:13,440 --> 00:12:16,160
to tune those parameters to work for

251
00:12:16,160 --> 00:12:16,560
different

252
00:12:16,560 --> 00:12:19,119
workloads

253
00:12:19,920 --> 00:12:26,079
next please so this is why

254
00:12:26,079 --> 00:12:28,959
we we want to come up with a new

255
00:12:28,959 --> 00:12:31,200
condition control algorithm

256
00:12:31,200 --> 00:12:34,639
which you can address our

257
00:12:34,639 --> 00:12:38,160
currently issue in our production so

258
00:12:38,160 --> 00:12:40,800
the new opportunity we found is that new

259
00:12:40,800 --> 00:12:42,240
commodity asics

260
00:12:42,240 --> 00:12:44,560
switching ethics have invented

261
00:12:44,560 --> 00:12:46,160
elementary ability

262
00:12:46,160 --> 00:12:49,519
which tells what the status

263
00:12:49,519 --> 00:12:52,560
in real time that switch has

264
00:12:52,560 --> 00:12:56,240
so the idea is to use inband telemetry

265
00:12:56,240 --> 00:12:58,560
as a precise feedback for conjunction

266
00:12:58,560 --> 00:13:00,079
control

267
00:13:00,079 --> 00:13:03,200
so for example in this in this figure

268
00:13:03,200 --> 00:13:05,920
so the sender generate packets package

269
00:13:05,920 --> 00:13:07,519
of the user data

270
00:13:07,519 --> 00:13:09,040
and when the packet goes through the

271
00:13:09,040 --> 00:13:10,560
network

272
00:13:10,560 --> 00:13:12,480
each hop of the switch will add a

273
00:13:12,480 --> 00:13:14,079
telemetry information

274
00:13:14,079 --> 00:13:16,480
into the packet so those telemetry

275
00:13:16,480 --> 00:13:17,279
information

276
00:13:17,279 --> 00:13:21,120
includes the q lens and the tx bytes

277
00:13:21,120 --> 00:13:24,000
and time stem

278
00:13:26,160 --> 00:13:30,079
so to allow us to calculate precisely

279
00:13:30,079 --> 00:13:33,360
the the extent of the congestion so

280
00:13:33,360 --> 00:13:36,160
um the packet continues forward around

281
00:13:36,160 --> 00:13:36,959
the pass

282
00:13:36,959 --> 00:13:40,000
and each switch will attach the

283
00:13:40,000 --> 00:13:41,920
terminal tree of its own into the

284
00:13:41,920 --> 00:13:44,240
package when the package

285
00:13:44,240 --> 00:13:47,440
arrives at the destination the reservoir

286
00:13:47,440 --> 00:13:48,639
will generate

287
00:13:48,639 --> 00:13:50,880
acknowledgement packets back to the

288
00:13:50,880 --> 00:13:51,839
sender

289
00:13:51,839 --> 00:13:54,480
while putting those telemetry pack

290
00:13:54,480 --> 00:13:55,199
information

291
00:13:55,199 --> 00:13:59,279
into the act packet to allow the sender

292
00:13:59,279 --> 00:14:02,560
to adjust the scenery based on telemetry

293
00:14:02,560 --> 00:14:06,000
information so as i said the the

294
00:14:06,000 --> 00:14:07,920
most important telemetry information we

295
00:14:07,920 --> 00:14:09,839
need is the key lens and the tx

296
00:14:09,839 --> 00:14:13,920
rates so which it tells precisely

297
00:14:13,920 --> 00:14:18,000
if the buffer build up for this

298
00:14:18,000 --> 00:14:20,959
particular egress port and more

299
00:14:20,959 --> 00:14:21,600
important

300
00:14:21,600 --> 00:14:24,800
that if there's no queue buildup in in a

301
00:14:24,800 --> 00:14:27,199
in the eagles port we still can use the

302
00:14:27,199 --> 00:14:28,480
txt rate

303
00:14:28,480 --> 00:14:31,920
to quantify the the occupancy of the

304
00:14:31,920 --> 00:14:32,560
link

305
00:14:32,560 --> 00:14:34,800
for example we can control the link to

306
00:14:34,800 --> 00:14:36,000
you use as a

307
00:14:36,000 --> 00:14:40,160
95 percent utilization so in this case

308
00:14:40,160 --> 00:14:43,040
we can maintain near zero q because we

309
00:14:43,040 --> 00:14:44,160
have a five percent

310
00:14:44,160 --> 00:14:47,120
bandwidth buffer to absorb the the

311
00:14:47,120 --> 00:14:48,320
traffic burst

312
00:14:48,320 --> 00:14:50,480
while still we can ensure very high

313
00:14:50,480 --> 00:14:51,600
throughput

314
00:14:51,600 --> 00:14:55,760
to saturated saturated link

315
00:14:56,399 --> 00:14:59,839
uh next

316
00:15:01,040 --> 00:15:04,800
so we we want to compare our

317
00:15:04,800 --> 00:15:07,760
inbantanometry mechanism with the

318
00:15:07,760 --> 00:15:10,839
traditional isin

319
00:15:10,839 --> 00:15:14,160
marking easy as we know that a single

320
00:15:14,160 --> 00:15:14,480
bit

321
00:15:14,480 --> 00:15:17,760
notification of condition uh is a simple

322
00:15:17,760 --> 00:15:18,639
and efficient

323
00:15:18,639 --> 00:15:22,079
uh being supported by many vendors

324
00:15:22,079 --> 00:15:25,600
we viewed that inventory is an advanced

325
00:15:25,600 --> 00:15:26,079
version

326
00:15:26,079 --> 00:15:28,639
of ecn which provides a fun green

327
00:15:28,639 --> 00:15:29,199
network

328
00:15:29,199 --> 00:15:32,720
load information um for example q lens

329
00:15:32,720 --> 00:15:33,440
precisely

330
00:15:33,440 --> 00:15:36,240
q lens uh in terms of bias or in terms

331
00:15:36,240 --> 00:15:37,120
of sales

332
00:15:37,120 --> 00:15:40,800
and also transmit bias which allows to

333
00:15:40,800 --> 00:15:43,600
generate on the calculate the tx rates

334
00:15:43,600 --> 00:15:46,000
on the egress port

335
00:15:46,000 --> 00:15:48,000
based on the tx byte and the timestamp

336
00:15:48,000 --> 00:15:49,360
information

337
00:15:49,360 --> 00:15:51,680
the link capacity actually we use to con

338
00:15:51,680 --> 00:15:53,040
to differentiate

339
00:15:53,040 --> 00:15:56,399
a different link either is 100g link is

340
00:15:56,399 --> 00:15:57,199
25g

341
00:15:57,199 --> 00:16:00,560
link the benefit

342
00:16:00,560 --> 00:16:04,160
or the key insight we get is first

343
00:16:04,160 --> 00:16:08,000
we can convert to uh appropriate

344
00:16:08,000 --> 00:16:11,040
uh just just a one round trip ton we can

345
00:16:11,040 --> 00:16:12,079
adapt to the

346
00:16:12,079 --> 00:16:15,920
uh corrector rates to avoid congestion

347
00:16:15,920 --> 00:16:18,399
while traditional condition control if

348
00:16:18,399 --> 00:16:20,959
you rely on the heuristics

349
00:16:20,959 --> 00:16:22,959
every time you cut to half and after

350
00:16:22,959 --> 00:16:25,360
multiple round trip time you can

351
00:16:25,360 --> 00:16:28,880
adapt to the red sending rate

352
00:16:28,880 --> 00:16:32,000
the second benefit is we can constantly

353
00:16:32,000 --> 00:16:34,320
maintain a near zero queue

354
00:16:34,320 --> 00:16:37,120
for loading latency while still we

355
00:16:37,120 --> 00:16:38,720
maintain a very high throughput

356
00:16:38,720 --> 00:16:41,759
because we can set a

357
00:16:41,759 --> 00:16:44,880
bandwidth buffer to observe the

358
00:16:44,880 --> 00:16:48,320
small burst without actually building up

359
00:16:48,320 --> 00:16:49,759
a queue

360
00:16:49,759 --> 00:16:52,320
so there are a couple of numeral

361
00:16:52,320 --> 00:16:53,360
comparison

362
00:16:53,360 --> 00:16:56,880
or overhead of using inventorment tree

363
00:16:56,880 --> 00:17:00,800
the first one is we we use in the paper

364
00:17:00,800 --> 00:17:03,279
we allow each packet to carry the

365
00:17:03,279 --> 00:17:04,959
telemetry information

366
00:17:04,959 --> 00:17:07,359
which uses up up to less than five

367
00:17:07,359 --> 00:17:09,359
percent of the bandwidth

368
00:17:09,359 --> 00:17:14,000
that's a uh ideal case but in reality we

369
00:17:14,000 --> 00:17:17,039
we prefer uh to query

370
00:17:17,039 --> 00:17:19,039
inbound animation information per round

371
00:17:19,039 --> 00:17:20,240
trip time

372
00:17:20,240 --> 00:17:25,199
in this case we use a standard rfi 1.0

373
00:17:25,199 --> 00:17:28,880
which is iotf standard int

374
00:17:28,880 --> 00:17:32,720
format and for those standard

375
00:17:32,720 --> 00:17:35,919
we have 200 bytes metadata

376
00:17:35,919 --> 00:17:39,360
for the for the int which is account for

377
00:17:39,360 --> 00:17:42,799
only 2.5 percent of the

378
00:17:42,799 --> 00:17:47,200
binaries so in this case we um

379
00:17:47,200 --> 00:17:50,080
we see that because bandwidth is the

380
00:17:50,080 --> 00:17:51,200
generally abundant

381
00:17:51,200 --> 00:17:53,919
in the data center and we we treat we

382
00:17:53,919 --> 00:17:55,039
use the

383
00:17:55,039 --> 00:17:58,240
um those small bandwidths

384
00:17:58,240 --> 00:18:01,600
for for low latency i think we think

385
00:18:01,600 --> 00:18:04,639
it's a good trade-off

386
00:18:05,039 --> 00:18:07,600
next page

387
00:18:10,240 --> 00:18:11,919
uh should i address the question right

388
00:18:11,919 --> 00:18:14,400
now just later for the after the

389
00:18:14,400 --> 00:18:17,039
presentation

390
00:18:18,400 --> 00:18:21,679
um that's up to you rui oh okay i can

391
00:18:21,679 --> 00:18:26,799
i can talk about that um

392
00:18:26,840 --> 00:18:29,840
l4s

393
00:18:30,320 --> 00:18:34,240
oh ifrs i i'm not quite sure the detail

394
00:18:34,240 --> 00:18:36,240
but

395
00:18:36,240 --> 00:18:39,200
it seems like a another standard in the

396
00:18:39,200 --> 00:18:40,640
tsv

397
00:18:40,640 --> 00:18:43,760
vwg right so um

398
00:18:43,760 --> 00:18:46,880
yeah they proposed to use the

399
00:18:46,880 --> 00:18:51,120
fundraising um

400
00:18:51,440 --> 00:18:55,360
um i'm not sure

401
00:18:55,360 --> 00:18:58,720
how to compare it because uh i remember

402
00:18:58,720 --> 00:18:59,760
ps

403
00:18:59,760 --> 00:19:02,960
l4s targeting on the wide area network

404
00:19:02,960 --> 00:19:06,000
and uh it focused on

405
00:19:06,000 --> 00:19:09,120
the the switch support to to improve the

406
00:19:09,120 --> 00:19:10,720
traditional ecn

407
00:19:10,720 --> 00:19:12,480
while we're focusing more on the data

408
00:19:12,480 --> 00:19:13,919
center environment

409
00:19:13,919 --> 00:19:17,520
uh where the the ion team features

410
00:19:17,520 --> 00:19:20,080
can be supported in those switches that

411
00:19:20,080 --> 00:19:20,559
can give

412
00:19:20,559 --> 00:19:24,000
us more information and especially

413
00:19:24,000 --> 00:19:26,080
for the for the for the data center the

414
00:19:26,080 --> 00:19:27,600
bandwidth is

415
00:19:27,600 --> 00:19:30,640
uh abundant so we can

416
00:19:30,640 --> 00:19:33,760
use the those boundaries to

417
00:19:33,760 --> 00:19:39,840
send the telemetry information

418
00:19:42,080 --> 00:19:45,200
if the protocol intend to be used

419
00:19:45,200 --> 00:19:48,720
on the internet so right now we are

420
00:19:48,720 --> 00:19:50,840
focused more on the on the data center

421
00:19:50,840 --> 00:19:54,240
environment because

422
00:19:54,240 --> 00:19:56,880
you know the because the telemetry

423
00:19:56,880 --> 00:19:57,760
information

424
00:19:57,760 --> 00:20:01,600
is more directed to the

425
00:20:01,600 --> 00:20:05,120
data center or cloud provider so those

426
00:20:05,120 --> 00:20:08,400
low level uh congestion information or

427
00:20:08,400 --> 00:20:10,400
traffic load information is very

428
00:20:10,400 --> 00:20:11,840
sensitive to

429
00:20:11,840 --> 00:20:15,200
uh to the to the network operator so if

430
00:20:15,200 --> 00:20:15,679
you

431
00:20:15,679 --> 00:20:18,080
if we want to use the internet wide

432
00:20:18,080 --> 00:20:19,280
environment

433
00:20:19,280 --> 00:20:22,400
then the one issue is maybe

434
00:20:22,400 --> 00:20:24,960
explode those detailed information to

435
00:20:24,960 --> 00:20:25,440
the

436
00:20:25,440 --> 00:20:28,480
to the other user maybe there are some

437
00:20:28,480 --> 00:20:34,320
privacy issues um through

438
00:20:34,320 --> 00:20:36,799
just a high level point the chat will

439
00:20:36,799 --> 00:20:37,919
keep going on

440
00:20:37,919 --> 00:20:41,039
uh you may you may want to you want to

441
00:20:41,039 --> 00:20:42,799
finish your presentation and then see

442
00:20:42,799 --> 00:20:45,039
if people want to answer questions at

443
00:20:45,039 --> 00:20:46,880
the mic or you can continue

444
00:20:46,880 --> 00:20:48,640
the conversation on the chat after your

445
00:20:48,640 --> 00:20:49,919
presentation as well

446
00:20:49,919 --> 00:20:53,280
okay okay okay thank you so we

447
00:20:53,280 --> 00:20:56,720
will highlight our design so the the

448
00:20:56,720 --> 00:21:00,240
key design is using implantation as a

449
00:21:00,240 --> 00:21:01,600
precise feedback

450
00:21:01,600 --> 00:21:03,600
we can quantify the condition and

451
00:21:03,600 --> 00:21:05,679
precisely and react to it

452
00:21:05,679 --> 00:21:08,559
precisely so that this gave us three

453
00:21:08,559 --> 00:21:09,679
benefits

454
00:21:09,679 --> 00:21:12,000
first the first convergence so the

455
00:21:12,000 --> 00:21:12,799
sender know

456
00:21:12,799 --> 00:21:16,880
exactly uh how to react to the condition

457
00:21:16,880 --> 00:21:20,480
and and it can adapt to the precise rate

458
00:21:20,480 --> 00:21:23,520
in just one round trip time the second

459
00:21:23,520 --> 00:21:25,760
is we can maintain near zero q

460
00:21:25,760 --> 00:21:27,919
because our feedback here doesn't rely

461
00:21:27,919 --> 00:21:30,400
on the q lens

462
00:21:30,400 --> 00:21:32,640
not only rely on the q lens but also we

463
00:21:32,640 --> 00:21:33,520
learn the tx

464
00:21:33,520 --> 00:21:36,799
rate and also in our case we have

465
00:21:36,799 --> 00:21:39,760
few parameters we only have three

466
00:21:39,760 --> 00:21:40,720
parameters

467
00:21:40,720 --> 00:21:43,919
and those parameters is not related to

468
00:21:43,919 --> 00:21:44,960
the

469
00:21:44,960 --> 00:21:47,760
uh the performance just the trade-off so

470
00:21:47,760 --> 00:21:50,799
in this case we don't need any heuristic

471
00:21:50,799 --> 00:21:52,640
to infer the status because we can

472
00:21:52,640 --> 00:21:54,799
directly get what what's going on in the

473
00:21:54,799 --> 00:21:57,280
network

474
00:21:57,840 --> 00:22:00,158
next

475
00:22:02,400 --> 00:22:05,919
so this is the preliminary result from

476
00:22:05,919 --> 00:22:08,240
our smarnic implementation

477
00:22:08,240 --> 00:22:11,280
we deployed and

478
00:22:11,280 --> 00:22:14,720
as we see that in the in the left figure

479
00:22:14,720 --> 00:22:17,919
showed that the axis is the different

480
00:22:17,919 --> 00:22:19,440
flow size

481
00:22:19,440 --> 00:22:23,520
um the y-axis is a 99 percentile

482
00:22:23,520 --> 00:22:26,559
normalized flow composition time

483
00:22:26,559 --> 00:22:28,960
actually in this figure the lower the

484
00:22:28,960 --> 00:22:29,600
better

485
00:22:29,600 --> 00:22:32,480
the lower means the lower latency and we

486
00:22:32,480 --> 00:22:33,360
compare

487
00:22:33,360 --> 00:22:36,720
our design with dcqcn the

488
00:22:36,720 --> 00:22:38,880
the purple curve which is the default

489
00:22:38,880 --> 00:22:40,240
condition control

490
00:22:40,240 --> 00:22:43,360
in rdma and we as we see that

491
00:22:43,360 --> 00:22:46,080
for those small messages we can reduce

492
00:22:46,080 --> 00:22:47,280
the latency by

493
00:22:47,280 --> 00:22:50,480
25 and

494
00:22:50,480 --> 00:22:54,159
even in a medium like 200k um

495
00:22:54,159 --> 00:22:56,320
flow so we can still reduce the latency

496
00:22:56,320 --> 00:22:57,280
by

497
00:22:57,280 --> 00:23:01,440
50 55 percent in the right figure we

498
00:23:01,440 --> 00:23:03,600
showed that overall in the

499
00:23:03,600 --> 00:23:06,880
experiment uh the distribution of the q

500
00:23:06,880 --> 00:23:10,880
length in the switch and as we see that

501
00:23:10,880 --> 00:23:14,480
in the hpcc plus plus we say that

502
00:23:14,480 --> 00:23:17,520
in even in the 99 percentile the q lens

503
00:23:17,520 --> 00:23:18,880
is only

504
00:23:18,880 --> 00:23:22,000
23 kilobytes which translate to

505
00:23:22,000 --> 00:23:25,440
seven micro second and q delay in 25 g

506
00:23:25,440 --> 00:23:29,600
link which demonstrates that we can

507
00:23:29,600 --> 00:23:32,000
achieve ultra low latency while

508
00:23:32,000 --> 00:23:36,559
maintaining near zero q

509
00:23:36,559 --> 00:23:40,000
um that's all for for

510
00:23:40,000 --> 00:23:42,480
my presentation i'm happy to take any

511
00:23:42,480 --> 00:23:43,120
questions

512
00:23:43,120 --> 00:23:51,840
right now

513
00:23:52,159 --> 00:23:55,360
thank you roy um i see vidi

514
00:23:55,360 --> 00:23:58,959
at the mic let me

515
00:24:00,880 --> 00:24:04,640
okay i thought this was

516
00:24:04,640 --> 00:24:08,480
sorry there you go with this

517
00:24:08,480 --> 00:24:10,480
uh thank you rui for the great

518
00:24:10,480 --> 00:24:11,520
presentation

519
00:24:11,520 --> 00:24:13,520
i just have a question in the graph that

520
00:24:13,520 --> 00:24:15,120
you were showing

521
00:24:15,120 --> 00:24:20,320
um just the previous slide

522
00:24:20,640 --> 00:24:23,840
okay okay oh can we switch to the

523
00:24:23,840 --> 00:24:24,640
previous slide

524
00:24:24,640 --> 00:24:27,520
if that's okay

525
00:24:29,760 --> 00:24:32,799
so the first graph why does the why does

526
00:24:32,799 --> 00:24:33,120
the

527
00:24:33,120 --> 00:24:36,000
latency becomes normalized like for the

528
00:24:36,000 --> 00:24:37,120
purple and the green i

529
00:24:37,120 --> 00:24:40,080
was i was imagining in my head that it

530
00:24:40,080 --> 00:24:42,320
would always stay low why does it become

531
00:24:42,320 --> 00:24:47,840
the same at higher

532
00:24:49,039 --> 00:24:52,159
oh yeah so for the higher which means

533
00:24:52,159 --> 00:24:53,840
the flow size is larger than

534
00:24:53,840 --> 00:24:57,120
one megabyte for example is

535
00:24:57,120 --> 00:25:01,520
is a throughput oriented for those flows

536
00:25:01,520 --> 00:25:05,279
and those flow maybe need uh tons of

537
00:25:05,279 --> 00:25:08,400
rounds to finishing

538
00:25:09,520 --> 00:25:12,640
all right but don't we have

539
00:25:12,640 --> 00:25:15,760
much better feedback is is this assuming

540
00:25:15,760 --> 00:25:16,559
some kind of

541
00:25:16,559 --> 00:25:18,799
loss or is it like a real-time test i

542
00:25:18,799 --> 00:25:20,320
didn't get the environment

543
00:25:20,320 --> 00:25:22,320
yeah yeah it's a yeah it's a it's a

544
00:25:22,320 --> 00:25:25,520
really just very very quickly videos

545
00:25:25,520 --> 00:25:28,559
there's echo coming out of your mind

546
00:25:28,559 --> 00:25:31,279
okay yeah please mute if you're not

547
00:25:31,279 --> 00:25:32,799
speaking it might be the best way to do

548
00:25:32,799 --> 00:25:34,960
this

549
00:25:35,360 --> 00:25:39,360
yes yeah so we we keep the utilization

550
00:25:39,360 --> 00:25:39,760
to

551
00:25:39,760 --> 00:25:43,919
95 percent in this case we have a five

552
00:25:43,919 --> 00:25:44,640
percent

553
00:25:44,640 --> 00:25:46,559
bandwidth header room to absorb some

554
00:25:46,559 --> 00:25:47,679
more bursts so

555
00:25:47,679 --> 00:25:51,039
in the case the shuffles like a the the

556
00:25:51,039 --> 00:25:51,600
number

557
00:25:51,600 --> 00:25:54,840
in the in the in the left have very low

558
00:25:54,840 --> 00:25:56,480
latency

559
00:25:56,480 --> 00:25:58,320
because we don't build up the queue

560
00:25:58,320 --> 00:26:00,880
however if you look at very tale

561
00:26:00,880 --> 00:26:04,559
of this uh figure we actually perform

562
00:26:04,559 --> 00:26:06,720
worse than the

563
00:26:06,720 --> 00:26:09,279
dcq scene for those long flow because

564
00:26:09,279 --> 00:26:10,960
they can use hundred percent

565
00:26:10,960 --> 00:26:14,240
uh throughput we only use a 9 percent

566
00:26:14,240 --> 00:26:17,039
that's a difference

567
00:26:20,240 --> 00:26:24,240
thank you

568
00:26:24,240 --> 00:26:27,440
ignacio you're up next

569
00:26:29,760 --> 00:26:33,039
um hi um we we

570
00:26:33,039 --> 00:26:36,000
just comment on the chat that this idea

571
00:26:36,000 --> 00:26:38,320
is similar to a protocol discussed

572
00:26:38,320 --> 00:26:42,159
in ippm group the er

573
00:26:42,159 --> 00:26:45,760
aom protocol it's different because here

574
00:26:45,760 --> 00:26:47,039
you are measuring the

575
00:26:47,039 --> 00:26:49,919
the cues which is directly related to

576
00:26:49,919 --> 00:26:52,400
traffic and congestion and

577
00:26:52,400 --> 00:26:55,520
but there is several issues that you can

578
00:26:55,520 --> 00:26:58,559
find when you try to do this in every

579
00:26:58,559 --> 00:27:02,480
in every step or or you you flow

580
00:27:02,480 --> 00:27:05,520
and the the question is

581
00:27:05,520 --> 00:27:08,799
is if you already knew this

582
00:27:08,799 --> 00:27:12,799
protocol that we are discussing um ippm

583
00:27:12,799 --> 00:27:15,919
and how do you think that this

584
00:27:15,919 --> 00:27:18,080
the second second question is how do you

585
00:27:18,080 --> 00:27:20,159
think that is possible

586
00:27:20,159 --> 00:27:23,679
to use your protocol when not all

587
00:27:23,679 --> 00:27:26,799
all the steps inside in the path in the

588
00:27:26,799 --> 00:27:27,679
flow paths

589
00:27:27,679 --> 00:27:31,520
are collaborating with your protocol

590
00:27:31,520 --> 00:27:34,240
because if you are thinking that this is

591
00:27:34,240 --> 00:27:35,279
developed

592
00:27:35,279 --> 00:27:38,399
very slowly uh okay you

593
00:27:38,399 --> 00:27:40,720
you will get this this intention thank

594
00:27:40,720 --> 00:27:42,640
you

595
00:27:42,640 --> 00:27:45,760
oh you mean i don't get the related work

596
00:27:45,760 --> 00:27:47,679
is mean

597
00:27:47,679 --> 00:27:51,360
or ippm

598
00:27:52,159 --> 00:27:55,600
so to answer a question i think for

599
00:27:55,600 --> 00:27:59,120
uh for hpcc plus plus the up we need a

600
00:27:59,120 --> 00:28:00,399
separate queue

601
00:28:00,399 --> 00:28:03,760
for our protocol just like ecn you need

602
00:28:03,760 --> 00:28:05,760
a separate queue for easy and for tcp

603
00:28:05,760 --> 00:28:07,200
traffic as well right

604
00:28:07,200 --> 00:28:10,559
so we need to have a separate queue

605
00:28:10,559 --> 00:28:13,840
for hpc plus plus if you don't use the

606
00:28:13,840 --> 00:28:15,679
hpc plus plus for

607
00:28:15,679 --> 00:28:18,720
for some of the in-house

608
00:28:18,720 --> 00:28:20,880
you might you might have to use

609
00:28:20,880 --> 00:28:22,159
different queue

610
00:28:22,159 --> 00:28:24,399
so you will use the queues in the switch

611
00:28:24,399 --> 00:28:31,360
to separate different protocols

612
00:28:31,360 --> 00:28:33,440
let's continue this one on that if you

613
00:28:33,440 --> 00:28:35,360
would like ignacio

614
00:28:35,360 --> 00:28:38,639
um stuart you're up next

615
00:28:42,840 --> 00:28:45,919
hi hey um just a quick comment

616
00:28:45,919 --> 00:28:49,440
uh i think i understand the confusion

617
00:28:49,440 --> 00:28:54,080
uh that led to vidi's question uh

618
00:28:54,080 --> 00:28:56,480
and this happens a lot when people use

619
00:28:56,480 --> 00:28:58,720
the terms latency and delay

620
00:28:58,720 --> 00:29:01,919
interchangeably this graph is not

621
00:29:01,919 --> 00:29:03,600
showing the latency

622
00:29:03,600 --> 00:29:05,520
uh in the sense of the per pack round

623
00:29:05,520 --> 00:29:06,720
trip time it's showing

624
00:29:06,720 --> 00:29:09,039
the total completion time for the

625
00:29:09,039 --> 00:29:09,919
transfer

626
00:29:09,919 --> 00:29:11,840
so when you have really large transfer

627
00:29:11,840 --> 00:29:13,600
many many round trips

628
00:29:13,600 --> 00:29:15,679
the actual per packet latency becomes

629
00:29:15,679 --> 00:29:17,679
less important

630
00:29:17,679 --> 00:29:22,880
yeah yeah that's why yeah so the left

631
00:29:22,880 --> 00:29:26,399
more than per pack

632
00:29:26,399 --> 00:29:29,520
yeah the left figure shows the trans

633
00:29:29,520 --> 00:29:31,120
the flow combination time which means

634
00:29:31,120 --> 00:29:32,720
the translation

635
00:29:32,720 --> 00:29:36,480
uh delay for this flow the hot

636
00:29:36,480 --> 00:29:38,720
how much time for the network transmit

637
00:29:38,720 --> 00:29:40,399
this particular flow

638
00:29:40,399 --> 00:29:42,320
yeah certainly need a couple of round

639
00:29:42,320 --> 00:29:44,080
triple times for the for the figure in

640
00:29:44,080 --> 00:29:44,960
the right

641
00:29:44,960 --> 00:29:48,000
it actually shows the the the delay of

642
00:29:48,000 --> 00:29:49,200
the network

643
00:29:49,200 --> 00:29:51,840
because the left side shows the cdf of q

644
00:29:51,840 --> 00:29:52,880
lens

645
00:29:52,880 --> 00:29:56,960
and so if you if you add about the

646
00:29:56,960 --> 00:29:58,720
transmission delay this is the queuing

647
00:29:58,720 --> 00:30:01,039
delay right so this is a queuing delay

648
00:30:01,039 --> 00:30:03,039
um distribution you can you can

649
00:30:03,039 --> 00:30:04,799
translate into that

650
00:30:04,799 --> 00:30:06,559
yeah my comment was just because video

651
00:30:06,559 --> 00:30:08,320
was asking on the left graph

652
00:30:08,320 --> 00:30:10,799
why the lines converge above two

653
00:30:10,799 --> 00:30:11,520
megabytes

654
00:30:11,520 --> 00:30:13,600
and i just anyway that was my comments

655
00:30:13,600 --> 00:30:14,559
just oh i see

656
00:30:14,559 --> 00:30:19,200
yeah help clear that up yeah thank you

657
00:30:19,760 --> 00:30:23,840
thanks stuart chris europe

658
00:30:24,159 --> 00:30:27,120
uh relaying for ayush what's the

659
00:30:27,120 --> 00:30:29,039
difference between the hpcc

660
00:30:29,039 --> 00:30:32,080
presented at sitcom and the hpcc

661
00:30:32,080 --> 00:30:36,480
plus plus which is being presented here

662
00:30:36,480 --> 00:30:40,320
um hpcc is more academia

663
00:30:40,320 --> 00:30:43,360
like a style there are a couple of

664
00:30:43,360 --> 00:30:43,919
different

665
00:30:43,919 --> 00:30:47,200
first one is we use per package

666
00:30:47,200 --> 00:30:51,200
int but uh in the production

667
00:30:51,200 --> 00:30:53,440
once we because once we after the

668
00:30:53,440 --> 00:30:54,240
published

669
00:30:54,240 --> 00:30:57,600
uh on sitcom we we work on the vendor to

670
00:30:57,600 --> 00:31:00,480
deploy this in in our production and

671
00:31:00,480 --> 00:31:01,760
during this procedure

672
00:31:01,760 --> 00:31:04,799
we'll accumulate a couple insights

673
00:31:04,799 --> 00:31:07,760
or experience from deploying this

674
00:31:07,760 --> 00:31:08,480
protocol

675
00:31:08,480 --> 00:31:11,120
that's come with hpcc plus plus so it's

676
00:31:11,120 --> 00:31:11,679
more

677
00:31:11,679 --> 00:31:15,519
production ready and

678
00:31:15,519 --> 00:31:19,200
it's a standardizable protocol

679
00:31:19,200 --> 00:31:22,559
now some of the design is too

680
00:31:22,559 --> 00:31:25,679
artificial in the second paper so

681
00:31:25,679 --> 00:31:28,880
in the htc plus plus it's more

682
00:31:28,880 --> 00:31:32,000
practical and design and

683
00:31:32,000 --> 00:31:35,039
it's it's good to uh align with

684
00:31:35,039 --> 00:31:36,799
different vendors because we

685
00:31:36,799 --> 00:31:38,799
uh when we deploy this protocol and then

686
00:31:38,799 --> 00:31:41,440
we actually talk to different vendors

687
00:31:41,440 --> 00:31:43,760
uh to implement these protocols we talk

688
00:31:43,760 --> 00:31:45,519
to the unique vendors and also talk to

689
00:31:45,519 --> 00:31:46,000
the switch

690
00:31:46,000 --> 00:31:48,080
vendors individually so that's the

691
00:31:48,080 --> 00:31:49,440
common ways that

692
00:31:49,440 --> 00:31:52,559
we want to standardize so that we can

693
00:31:52,559 --> 00:31:54,080
we don't have to talk to each one

694
00:31:54,080 --> 00:31:56,159
individually but we're talking a common

695
00:31:56,159 --> 00:31:56,799
language

696
00:31:56,799 --> 00:31:58,399
so that's the way we come up with this

697
00:31:58,399 --> 00:32:01,360
htc plus plus

698
00:32:01,360 --> 00:32:03,200
there are a couple of uh a detailed

699
00:32:03,200 --> 00:32:05,440
design in in the draft

700
00:32:05,440 --> 00:32:08,720
um that's quite different with the paper

701
00:32:08,720 --> 00:32:11,039
version

702
00:32:11,519 --> 00:32:12,880
yeah i would encourage people to read

703
00:32:12,880 --> 00:32:16,000
the draft as well

704
00:32:16,000 --> 00:32:19,679
roland you're up next all right just a

705
00:32:19,679 --> 00:32:21,440
quick question

706
00:32:21,440 --> 00:32:23,679
about multiple bottlenecks so did you

707
00:32:23,679 --> 00:32:26,240
consider multiple bottlenecks or

708
00:32:26,240 --> 00:32:29,039
are they occurring in your setup at all

709
00:32:29,039 --> 00:32:29,760
and the

710
00:32:29,760 --> 00:32:32,640
the network telemetry data does it allow

711
00:32:32,640 --> 00:32:33,600
you to

712
00:32:33,600 --> 00:32:35,919
identify the particular blocked neck for

713
00:32:35,919 --> 00:32:36,880
a

714
00:32:36,880 --> 00:32:40,480
specific flow um

715
00:32:40,480 --> 00:32:42,480
in the paper version we consider the

716
00:32:42,480 --> 00:32:44,240
multiple bottleneck design

717
00:32:44,240 --> 00:32:47,360
and we actually we carry int information

718
00:32:47,360 --> 00:32:48,640
for each hop

719
00:32:48,640 --> 00:32:51,039
so that we can actually know where is

720
00:32:51,039 --> 00:32:52,399
the conjunction

721
00:32:52,399 --> 00:32:55,279
and we have of a complete design to

722
00:32:55,279 --> 00:32:56,960
consider all the bottleneck

723
00:32:56,960 --> 00:32:59,200
and we actually can change the scenic

724
00:32:59,200 --> 00:33:00,880
ray

725
00:33:00,880 --> 00:33:03,840
so both based on different policy so we

726
00:33:03,840 --> 00:33:04,960
can see like

727
00:33:04,960 --> 00:33:06,320
under the multiple bottleneck we can

728
00:33:06,320 --> 00:33:08,080
achieve maximum fairness

729
00:33:08,080 --> 00:33:10,559
or proportional fairness or something

730
00:33:10,559 --> 00:33:11,519
between

731
00:33:11,519 --> 00:33:14,080
that it's our fairness we can achieve

732
00:33:14,080 --> 00:33:15,840
but the later in the in the production

733
00:33:15,840 --> 00:33:17,360
deployment we found that

734
00:33:17,360 --> 00:33:20,640
the simplest way is just to uh

735
00:33:20,640 --> 00:33:24,000
uh do the the the

736
00:33:24,000 --> 00:33:27,360
maximum fairness we don't store because

737
00:33:27,360 --> 00:33:28,960
in multiple bottleneck cases we need to

738
00:33:28,960 --> 00:33:31,600
stop all the information for each hub

739
00:33:31,600 --> 00:33:35,039
that actually causes more resources

740
00:33:35,039 --> 00:33:38,240
but the the the benefit is very limited

741
00:33:38,240 --> 00:33:41,679
the benefit just uh how how fairness we

742
00:33:41,679 --> 00:33:43,440
can achieve what what fairness we can

743
00:33:43,440 --> 00:33:45,440
achieve and how quickly we can adapt to

744
00:33:45,440 --> 00:33:46,240
the

745
00:33:46,240 --> 00:33:49,360
uh the fairness point but actually we

746
00:33:49,360 --> 00:33:52,000
we we care more about ut utilization

747
00:33:52,000 --> 00:33:52,799
convergence

748
00:33:52,799 --> 00:33:56,320
which which can avoid congestion

749
00:33:56,320 --> 00:33:58,480
but we don't care much about fairness

750
00:33:58,480 --> 00:33:59,840
convergence

751
00:33:59,840 --> 00:34:02,080
so because the flows are actually very

752
00:34:02,080 --> 00:34:03,600
short in our case

753
00:34:03,600 --> 00:34:06,240
we don't consider so that that's why we

754
00:34:06,240 --> 00:34:06,640
we

755
00:34:06,640 --> 00:34:09,679
make a very simple design uh

756
00:34:09,679 --> 00:34:11,199
that that works with the multiple

757
00:34:11,199 --> 00:34:14,879
personality case yeah thanks

758
00:34:17,520 --> 00:34:20,079
all right um thank you so much rui for

759
00:34:20,079 --> 00:34:21,359
that um

760
00:34:21,359 --> 00:34:24,960
i'll encourage this is this is uh a

761
00:34:24,960 --> 00:34:28,399
presentation which was uh in part

762
00:34:28,399 --> 00:34:30,079
there's some discussion on the iccrg

763
00:34:30,079 --> 00:34:31,280
mailing list people seem to be

764
00:34:31,280 --> 00:34:32,239
interested in

765
00:34:32,239 --> 00:34:34,000
discussing and engaging in data center

766
00:34:34,000 --> 00:34:35,520
construction controllers

767
00:34:35,520 --> 00:34:37,679
so if people are interested in that i

768
00:34:37,679 --> 00:34:38,879
would encourage you to

769
00:34:38,879 --> 00:34:41,280
engage on this more on the mailing list

770
00:34:41,280 --> 00:34:43,280
and i'll also encourage roy to

771
00:34:43,280 --> 00:34:45,839
to bring these up on the mailing list we

772
00:34:45,839 --> 00:34:47,599
are trying to gauge how much interest

773
00:34:47,599 --> 00:34:48,079
there is

774
00:34:48,079 --> 00:34:52,399
in topics around dc construction control

775
00:34:52,399 --> 00:34:54,079
if there is interest please bring it up

776
00:34:54,079 --> 00:34:55,520
on the mailing list it would be good to

777
00:34:55,520 --> 00:34:56,719
know

778
00:34:56,719 --> 00:34:59,599
yeah thanks i have already uh copied

779
00:34:59,599 --> 00:35:01,200
these comments i will reply

780
00:35:01,200 --> 00:35:04,240
in the email thank you everyone

781
00:35:04,240 --> 00:35:07,440
thank you so much roy uh with that

782
00:35:07,440 --> 00:35:11,280
we will move on to the next presentation

783
00:35:11,280 --> 00:35:17,839
of the day let me see if i can

784
00:35:22,490 --> 00:35:28,759
[Music]

785
00:35:28,880 --> 00:35:33,680
robin get up yeah mike is on

786
00:35:33,680 --> 00:35:36,880
yep all right um so

787
00:35:36,880 --> 00:35:38,400
for those people who've seen this uh

788
00:35:38,400 --> 00:35:40,400
yesterday don't worry it contains a lot

789
00:35:40,400 --> 00:35:42,079
of new information

790
00:35:42,079 --> 00:35:44,160
so you don't get too bored uh next slide

791
00:35:44,160 --> 00:35:46,480
please

792
00:35:47,760 --> 00:35:50,800
so qlog stands for uh quick logging and

793
00:35:50,800 --> 00:35:51,760
its project uh

794
00:35:51,760 --> 00:35:53,839
started about two years ago when we

795
00:35:53,839 --> 00:35:55,680
identified that the new protocols would

796
00:35:55,680 --> 00:35:59,119
probably get quite complex to actually

797
00:35:59,119 --> 00:36:00,000
analyze

798
00:36:00,000 --> 00:36:01,760
and debug in practice and we're going to

799
00:36:01,760 --> 00:36:04,240
need some advanced tooling to do that

800
00:36:04,240 --> 00:36:05,599
which would typically do for something

801
00:36:05,599 --> 00:36:07,359
like tcp for example

802
00:36:07,359 --> 00:36:11,599
next slide is we take a packet capture

803
00:36:11,599 --> 00:36:12,000
somewhere

804
00:36:12,000 --> 00:36:13,839
in the network right and then analyze

805
00:36:13,839 --> 00:36:15,200
that using something like

806
00:36:15,200 --> 00:36:17,599
wireshark for example this is still

807
00:36:17,599 --> 00:36:18,800
possible for quick but

808
00:36:18,800 --> 00:36:20,960
quite a bit more difficult because next

809
00:36:20,960 --> 00:36:23,280
slide

810
00:36:23,920 --> 00:36:26,640
quick of course encrypts most of its

811
00:36:26,640 --> 00:36:28,560
transport level metadata as well

812
00:36:28,560 --> 00:36:29,920
so to do this you would have to store

813
00:36:29,920 --> 00:36:32,000
the entire packet capture including the

814
00:36:32,000 --> 00:36:33,599
very large payloads

815
00:36:33,599 --> 00:36:36,880
and also the tls decryption secrets um

816
00:36:36,880 --> 00:36:38,480
leading to obvious privacy and

817
00:36:38,480 --> 00:36:40,000
scalability issues

818
00:36:40,000 --> 00:36:41,359
there's however a second more

819
00:36:41,359 --> 00:36:43,599
long-standing problem with the typical

820
00:36:43,599 --> 00:36:46,720
way that we do this next slide

821
00:36:46,720 --> 00:36:49,280
which is of course that a lot of

822
00:36:49,280 --> 00:36:50,720
protocol information isn't always

823
00:36:50,720 --> 00:36:51,839
reflected on the wire

824
00:36:51,839 --> 00:36:53,520
that's of course always the case for

825
00:36:53,520 --> 00:36:55,680
congestion control information like

826
00:36:55,680 --> 00:36:57,440
the congestion window which i don't have

827
00:36:57,440 --> 00:36:59,359
to tell all of you

828
00:36:59,359 --> 00:37:02,720
and so um to solve these problems

829
00:37:02,720 --> 00:37:04,560
or to try and solve them for quick we

830
00:37:04,560 --> 00:37:05,839
proposed a different approach

831
00:37:05,839 --> 00:37:10,000
next slide where the idea is instead of

832
00:37:10,000 --> 00:37:12,320
doing a network based capture let's

833
00:37:12,320 --> 00:37:14,079
log this information at the endpoints

834
00:37:14,079 --> 00:37:16,960
directly from the implementations

835
00:37:16,960 --> 00:37:19,200
obviously or have all the salient data

836
00:37:19,200 --> 00:37:20,400
right there available and they can

837
00:37:20,400 --> 00:37:22,640
easily leave out the privacy sensitive

838
00:37:22,640 --> 00:37:23,839
parts

839
00:37:23,839 --> 00:37:25,599
this is of course not a brand new idea

840
00:37:25,599 --> 00:37:27,040
many implementations have

841
00:37:27,040 --> 00:37:28,720
some kind of debugging output for

842
00:37:28,720 --> 00:37:31,119
example but the idea of qlog is to have

843
00:37:31,119 --> 00:37:32,480
like a single format

844
00:37:32,480 --> 00:37:35,200
a single schema that all the different

845
00:37:35,200 --> 00:37:37,359
implementations can use

846
00:37:37,359 --> 00:37:39,359
uh making it easier for us to create

847
00:37:39,359 --> 00:37:41,359
reusable tooling

848
00:37:41,359 --> 00:37:45,280
uh on top of that and so the next slide

849
00:37:45,280 --> 00:37:48,160
um qlog really is not rocket science

850
00:37:48,160 --> 00:37:48,640
it's

851
00:37:48,640 --> 00:37:50,720
relatively simple currently we just map

852
00:37:50,720 --> 00:37:52,160
this into json

853
00:37:52,160 --> 00:37:54,880
and we define how for example i receive

854
00:37:54,880 --> 00:37:55,839
packets

855
00:37:55,839 --> 00:37:57,200
containing an acknowledgement frame

856
00:37:57,200 --> 00:37:59,040
should look like or indeed on the right

857
00:37:59,040 --> 00:38:00,240
side what

858
00:38:00,240 --> 00:38:02,640
uh you should call the variables related

859
00:38:02,640 --> 00:38:04,000
to for example

860
00:38:04,000 --> 00:38:08,079
just control updates using this type of

861
00:38:08,079 --> 00:38:10,160
log as input we were then able to create

862
00:38:10,160 --> 00:38:11,440
quite a few indeed

863
00:38:11,440 --> 00:38:14,560
reusable tools next slide which are

864
00:38:14,560 --> 00:38:16,800
available in the queue this tool suite

865
00:38:16,800 --> 00:38:18,400
one of those is for example here the

866
00:38:18,400 --> 00:38:19,839
sequence diagram

867
00:38:19,839 --> 00:38:21,680
where in the middle you see the packets

868
00:38:21,680 --> 00:38:23,040
going over the wire

869
00:38:23,040 --> 00:38:25,440
from client server and vice versa and

870
00:38:25,440 --> 00:38:26,800
their contents

871
00:38:26,800 --> 00:38:29,280
but on the right side you see

872
00:38:29,280 --> 00:38:30,960
implementation side updates

873
00:38:30,960 --> 00:38:33,680
including for example when when a probe

874
00:38:33,680 --> 00:38:34,320
timeout

875
00:38:34,320 --> 00:38:37,119
timer was set or indeed when the the

876
00:38:37,119 --> 00:38:38,720
bytes in flight was updated

877
00:38:38,720 --> 00:38:41,760
allowing for very fine grains debugging

878
00:38:41,760 --> 00:38:42,400
of these

879
00:38:42,400 --> 00:38:47,119
these systems next slide

880
00:38:47,119 --> 00:38:50,160
the second major tool that we have in

881
00:38:50,160 --> 00:38:52,000
cubist is is a kind of

882
00:38:52,000 --> 00:38:54,240
you can call it the tcp trace for them

883
00:38:54,240 --> 00:38:55,520
for quick

884
00:38:55,520 --> 00:38:57,440
where because of this approach we we

885
00:38:57,440 --> 00:38:59,119
don't just show the data and the

886
00:38:59,119 --> 00:39:01,119
acknowledgements and the flow control

887
00:39:01,119 --> 00:39:03,520
we can also show just the window bytes

888
00:39:03,520 --> 00:39:04,320
in flight

889
00:39:04,320 --> 00:39:06,079
and also the various round-trip time

890
00:39:06,079 --> 00:39:07,920
measurements that are used

891
00:39:07,920 --> 00:39:11,200
internally immediately and so for me

892
00:39:11,200 --> 00:39:14,000
as definitely a non-expert in congestion

893
00:39:14,000 --> 00:39:14,720
control

894
00:39:14,720 --> 00:39:16,400
i really liked this type of thing where

895
00:39:16,400 --> 00:39:18,880
you see the the very clear correlation

896
00:39:18,880 --> 00:39:19,680
between the

897
00:39:19,680 --> 00:39:22,320
congestion window rising and the rtt

898
00:39:22,320 --> 00:39:23,599
going up

899
00:39:23,599 --> 00:39:26,160
with that as well it's very interesting

900
00:39:26,160 --> 00:39:26,880
to see this so

901
00:39:26,880 --> 00:39:31,500
so graphically next slide

902
00:39:31,500 --> 00:39:32,800
[Music]

903
00:39:32,800 --> 00:39:34,320
this this tool has then been used by

904
00:39:34,320 --> 00:39:36,079
quite a few implementers for example

905
00:39:36,079 --> 00:39:39,280
this is from a blog post from cloudflare

906
00:39:39,280 --> 00:39:41,359
who explain in detail how they've used

907
00:39:41,359 --> 00:39:43,040
this to debug their initial

908
00:39:43,040 --> 00:39:46,160
cubic and high stark implementation

909
00:39:46,160 --> 00:39:50,480
for their quick stack next slide

910
00:39:51,040 --> 00:39:53,040
but it's also going beyond initial

911
00:39:53,040 --> 00:39:54,400
deployment initial

912
00:39:54,400 --> 00:39:56,560
implementation debugging for example

913
00:39:56,560 --> 00:39:57,920
what facebook has done is they have

914
00:39:57,920 --> 00:39:58,640
deploys

915
00:39:58,640 --> 00:40:01,359
q log at scale in their data centers as

916
00:40:01,359 --> 00:40:02,400
well and so

917
00:40:02,400 --> 00:40:05,040
they've been able to find quite a few um

918
00:40:05,040 --> 00:40:07,040
relatively quick specific bugs in their

919
00:40:07,040 --> 00:40:09,040
setup that were previously missed in

920
00:40:09,040 --> 00:40:11,359
lab testing they only really surfaced

921
00:40:11,359 --> 00:40:13,280
during their deployment

922
00:40:13,280 --> 00:40:16,400
for example one of the things they had

923
00:40:16,400 --> 00:40:17,920
was that they were underestimating

924
00:40:17,920 --> 00:40:18,720
bandwidth

925
00:40:18,720 --> 00:40:20,640
during the zero rtt phase because they

926
00:40:20,640 --> 00:40:23,440
were relying on previously acknowledged

927
00:40:23,440 --> 00:40:24,880
packets

928
00:40:24,880 --> 00:40:27,359
which during zero rtt you do not have

929
00:40:27,359 --> 00:40:29,680
previously knowledge packets

930
00:40:29,680 --> 00:40:32,720
at least not once containing application

931
00:40:32,720 --> 00:40:33,920
layer data

932
00:40:33,920 --> 00:40:35,200
another one that is in a very

933
00:40:35,200 --> 00:40:37,520
interesting paper that i'll link to the

934
00:40:37,520 --> 00:40:39,119
bottom there

935
00:40:39,119 --> 00:40:41,520
was that in quick you change encryption

936
00:40:41,520 --> 00:40:42,400
levels

937
00:40:42,400 --> 00:40:45,520
and that is accompanied by

938
00:40:45,520 --> 00:40:47,200
you can do that with implicitly

939
00:40:47,200 --> 00:40:48,880
acknowledging all the packets from the

940
00:40:48,880 --> 00:40:50,079
previous

941
00:40:50,079 --> 00:40:51,920
encryption level and the way they did

942
00:40:51,920 --> 00:40:54,079
that was they they uh

943
00:40:54,079 --> 00:40:56,720
mismeasured the rtt there so rtt was

944
00:40:56,720 --> 00:40:58,400
only much much lower than it actually

945
00:40:58,400 --> 00:40:58,880
was

946
00:40:58,880 --> 00:41:01,040
because of the implicit acknowledgements

947
00:41:01,040 --> 00:41:02,640
again causing a wrong bandwidth

948
00:41:02,640 --> 00:41:04,319
estimation

949
00:41:04,319 --> 00:41:07,440
but there you go

950
00:41:07,440 --> 00:41:09,760
okay

951
00:41:10,560 --> 00:41:14,720
okay so um the thing is that no no

952
00:41:14,720 --> 00:41:17,520
previous slide please

953
00:41:18,560 --> 00:41:20,800
so the thing is that this has been used

954
00:41:20,800 --> 00:41:22,160
not just by

955
00:41:22,160 --> 00:41:24,560
um the experts or the people that knew

956
00:41:24,560 --> 00:41:25,680
that they were doing

957
00:41:25,680 --> 00:41:27,680
uh to great effect but i think it quick

958
00:41:27,680 --> 00:41:28,800
we have this um

959
00:41:28,800 --> 00:41:31,599
very um special situation where you have

960
00:41:31,599 --> 00:41:33,119
a lot of quick implementers

961
00:41:33,119 --> 00:41:35,200
that are really not congestion control

962
00:41:35,200 --> 00:41:36,480
experts

963
00:41:36,480 --> 00:41:38,319
by themselves and they have to try to

964
00:41:38,319 --> 00:41:39,839
make something working

965
00:41:39,839 --> 00:41:41,760
based on the drafts and looking at other

966
00:41:41,760 --> 00:41:43,040
people's code

967
00:41:43,040 --> 00:41:44,160
and i think this kind of tool and

968
00:41:44,160 --> 00:41:46,160
approach has really helped them to get

969
00:41:46,160 --> 00:41:47,280
their things at least

970
00:41:47,280 --> 00:41:51,040
somewhat working um next slide

971
00:41:51,040 --> 00:41:52,960
and i think that's that's one of the

972
00:41:52,960 --> 00:41:55,280
main reasons that qlog has found quite a

973
00:41:55,280 --> 00:41:56,480
bit of support

974
00:41:56,480 --> 00:41:58,240
within the quick community most of the

975
00:41:58,240 --> 00:42:00,319
implementations actually

976
00:42:00,319 --> 00:42:03,280
output this directly as well and as i

977
00:42:03,280 --> 00:42:04,960
said facebook is using this

978
00:42:04,960 --> 00:42:07,280
extensively in production it's because

979
00:42:07,280 --> 00:42:08,160
of this that

980
00:42:08,160 --> 00:42:10,720
the format has shown promise and the

981
00:42:10,720 --> 00:42:12,160
tools seem useful

982
00:42:12,160 --> 00:42:14,000
that we are now moving for adoption of

983
00:42:14,000 --> 00:42:16,079
this work by the quick working group

984
00:42:16,079 --> 00:42:20,319
next slide which is intended to happen

985
00:42:20,319 --> 00:42:22,800
somewhere over the next months as part

986
00:42:22,800 --> 00:42:24,720
of the quick recharger

987
00:42:24,720 --> 00:42:26,800
one of the goals there is to flash out

988
00:42:26,800 --> 00:42:27,920
all of this for for

989
00:42:27,920 --> 00:42:30,560
quick we have some basic adjust control

990
00:42:30,560 --> 00:42:32,400
stuff in there but for example facebook

991
00:42:32,400 --> 00:42:34,160
they have added a lot of custom events

992
00:42:34,160 --> 00:42:35,280
as well

993
00:42:35,280 --> 00:42:39,040
to help them better debug their their

994
00:42:39,040 --> 00:42:41,200
custom setups so it's going to be

995
00:42:41,200 --> 00:42:42,480
interesting to see if we

996
00:42:42,480 --> 00:42:44,319
how we need to update the default q log

997
00:42:44,319 --> 00:42:45,680
stuff to to

998
00:42:45,680 --> 00:42:48,400
match that the second main thing and one

999
00:42:48,400 --> 00:42:50,160
of the main reasons i'm here today

1000
00:42:50,160 --> 00:42:51,920
is that we're also trying to figure out

1001
00:42:51,920 --> 00:42:53,359
if this can be extended

1002
00:42:53,359 --> 00:42:56,240
to more than just quick logically of

1003
00:42:56,240 --> 00:42:58,400
course things like tcp or

1004
00:42:58,400 --> 00:43:00,240
the multipath versions of these or

1005
00:43:00,240 --> 00:43:03,119
things like mask or general tunneling

1006
00:43:03,119 --> 00:43:05,599
also of course have to deal with aspects

1007
00:43:05,599 --> 00:43:07,280
of congestion control

1008
00:43:07,280 --> 00:43:09,520
and can get quite complex and we hope

1009
00:43:09,520 --> 00:43:11,200
this approach could be useful for those

1010
00:43:11,200 --> 00:43:12,240
things as well

1011
00:43:12,240 --> 00:43:14,880
with the ideal goal of creating tools

1012
00:43:14,880 --> 00:43:18,800
that can be reused across protocols

1013
00:43:18,880 --> 00:43:21,440
like slide

1014
00:43:23,359 --> 00:43:26,000
we also have a few proof of concepts

1015
00:43:26,000 --> 00:43:27,119
projects around that

1016
00:43:27,119 --> 00:43:29,119
for example for tcp we've been playing

1017
00:43:29,119 --> 00:43:30,880
around with ebpf

1018
00:43:30,880 --> 00:43:33,440
and using k probes to get this kind of

1019
00:43:33,440 --> 00:43:35,680
information bubbled up from the kernel

1020
00:43:35,680 --> 00:43:37,680
we then combine these with the raw

1021
00:43:37,680 --> 00:43:39,760
packet captures

1022
00:43:39,760 --> 00:43:42,160
from wireshark to get like a full view

1023
00:43:42,160 --> 00:43:43,839
of what the tcp stack

1024
00:43:43,839 --> 00:43:46,640
for example in linux is doing which has

1025
00:43:46,640 --> 00:43:48,240
led to some some

1026
00:43:48,240 --> 00:43:51,920
interesting observations next slide

1027
00:43:51,920 --> 00:43:53,680
we've also been playing around with this

1028
00:43:53,680 --> 00:43:55,440
for multi-parts quick

1029
00:43:55,440 --> 00:43:57,040
and we have an ongoing project looking

1030
00:43:57,040 --> 00:43:59,200
at it from multiple tcp as well

1031
00:43:59,200 --> 00:44:02,079
where we tag each event with a specific

1032
00:44:02,079 --> 00:44:03,119
path id

1033
00:44:03,119 --> 00:44:04,960
so we can split them out later and have

1034
00:44:04,960 --> 00:44:07,119
a comparison between the different paths

1035
00:44:07,119 --> 00:44:09,760
of course

1036
00:44:09,760 --> 00:44:12,240
so it shows definite promise it looks

1037
00:44:12,240 --> 00:44:13,680
like we will be able to do this however

1038
00:44:13,680 --> 00:44:16,400
we are also running against a few

1039
00:44:16,400 --> 00:44:20,160
challenges or bottlenecks next slide

1040
00:44:21,200 --> 00:44:22,960
for example we've recently started a

1041
00:44:22,960 --> 00:44:24,960
major push towards actual performance

1042
00:44:24,960 --> 00:44:26,960
testing of quick stacks

1043
00:44:26,960 --> 00:44:29,920
um and qlo currently as i said is json

1044
00:44:29,920 --> 00:44:30,480
based

1045
00:44:30,480 --> 00:44:32,400
which is flexible but it's also not

1046
00:44:32,400 --> 00:44:33,760
super optimized

1047
00:44:33,760 --> 00:44:36,240
uh for example in terms of file size and

1048
00:44:36,240 --> 00:44:37,359
so testing

1049
00:44:37,359 --> 00:44:40,480
um performance on gigabit networks

1050
00:44:40,480 --> 00:44:42,079
has turned out to be quite difficult to

1051
00:44:42,079 --> 00:44:43,839
scale um

1052
00:44:43,839 --> 00:44:47,119
there are however other people like for

1053
00:44:47,119 --> 00:44:47,680
example

1054
00:44:47,680 --> 00:44:50,480
big banks from microsoft they're using a

1055
00:44:50,480 --> 00:44:51,119
custom

1056
00:44:51,119 --> 00:44:52,720
similar approach but they are using a

1057
00:44:52,720 --> 00:44:54,400
more optimized format

1058
00:44:54,400 --> 00:44:56,800
and custom tools where they are able to

1059
00:44:56,800 --> 00:44:57,760
ingest

1060
00:44:57,760 --> 00:44:59,760
much much larger log files and much much

1061
00:44:59,760 --> 00:45:01,040
more information

1062
00:45:01,040 --> 00:45:02,800
to help debug this kind of high

1063
00:45:02,800 --> 00:45:04,240
performance scenario

1064
00:45:04,240 --> 00:45:06,560
so i think the general approach is is

1065
00:45:06,560 --> 00:45:08,319
good we just need to look at how we

1066
00:45:08,319 --> 00:45:11,680
implement it specifically that's one of

1067
00:45:11,680 --> 00:45:13,280
the discussions that we will definitely

1068
00:45:13,280 --> 00:45:14,640
have

1069
00:45:14,640 --> 00:45:18,960
for q log one of the problems that i

1070
00:45:18,960 --> 00:45:20,000
have there is

1071
00:45:20,000 --> 00:45:21,599
kind of the main puller of this thing

1072
00:45:21,599 --> 00:45:24,240
next slide is that again i am not

1073
00:45:24,240 --> 00:45:26,960
a uh i'm not an expert i don't i don't

1074
00:45:26,960 --> 00:45:28,480
implement these things myself i don't

1075
00:45:28,480 --> 00:45:29,200
test them

1076
00:45:29,200 --> 00:45:31,280
i don't do research um so i don't know

1077
00:45:31,280 --> 00:45:32,640
what what like what the

1078
00:45:32,640 --> 00:45:34,880
the typical way of working for this is

1079
00:45:34,880 --> 00:45:36,560
either research or

1080
00:45:36,560 --> 00:45:38,720
actual deployment i've seen things like

1081
00:45:38,720 --> 00:45:40,319
this come along here in

1082
00:45:40,319 --> 00:45:42,960
this research group this was from a

1083
00:45:42,960 --> 00:45:44,319
couple of meetings ago

1084
00:45:44,319 --> 00:45:46,800
which seems fantastically interesting as

1085
00:45:46,800 --> 00:45:47,839
a tool

1086
00:45:47,839 --> 00:45:50,000
it's unclear for example here i don't

1087
00:45:50,000 --> 00:45:51,280
know if you can actually log the

1088
00:45:51,280 --> 00:45:53,040
individual congestion control windows or

1089
00:45:53,040 --> 00:45:55,040
if that's even useful

1090
00:45:55,040 --> 00:46:00,319
right um and so next slide

1091
00:46:00,319 --> 00:46:02,000
the fact that i need more feedback

1092
00:46:02,000 --> 00:46:03,440
became obvious

1093
00:46:03,440 --> 00:46:05,040
earlier in the early days when i talked

1094
00:46:05,040 --> 00:46:06,960
to jonah um

1095
00:46:06,960 --> 00:46:08,480
asking you know how how can we improve

1096
00:46:08,480 --> 00:46:10,480
this tcp trace for quick

1097
00:46:10,480 --> 00:46:11,760
and he said the simplest thing you could

1098
00:46:11,760 --> 00:46:13,599
do is add a

1099
00:46:13,599 --> 00:46:15,119
type of thing a ruler where i can just

1100
00:46:15,119 --> 00:46:16,880
drag and drop

1101
00:46:16,880 --> 00:46:20,720
across the data line here

1102
00:46:20,720 --> 00:46:22,560
and it shows me about what the data rate

1103
00:46:22,560 --> 00:46:24,720
was and how how long it took

1104
00:46:24,720 --> 00:46:26,319
which is really really simple to

1105
00:46:26,319 --> 00:46:28,800
implement it did in about one hour

1106
00:46:28,800 --> 00:46:30,160
and i would have never thought of that

1107
00:46:30,160 --> 00:46:31,920
myself that would actually be useful in

1108
00:46:31,920 --> 00:46:33,040
practice

1109
00:46:33,040 --> 00:46:34,480
so that kind of input that was really

1110
00:46:34,480 --> 00:46:36,480
really useful for me to uh

1111
00:46:36,480 --> 00:46:39,040
to optimize this tool now where am i

1112
00:46:39,040 --> 00:46:40,160
going with this

1113
00:46:40,160 --> 00:46:44,160
final slide because of course the

1114
00:46:44,160 --> 00:46:47,359
itf does not standardize tools

1115
00:46:47,359 --> 00:46:48,480
and i don't want to make this whole

1116
00:46:48,480 --> 00:46:50,560
about the tools but i do think that if

1117
00:46:50,560 --> 00:46:52,640
the goal is to have a format

1118
00:46:52,640 --> 00:46:54,000
that can be reused across

1119
00:46:54,000 --> 00:46:56,560
implementations and protocols

1120
00:46:56,560 --> 00:46:58,160
and that we can then build reusable

1121
00:46:58,160 --> 00:47:00,240
tools on top of

1122
00:47:00,240 --> 00:47:02,079
that it might be a good idea to start

1123
00:47:02,079 --> 00:47:04,160
from the tools and then work our way

1124
00:47:04,160 --> 00:47:05,040
backwards

1125
00:47:05,040 --> 00:47:06,880
to make sure that we are not missing

1126
00:47:06,880 --> 00:47:09,440
things that are very useful in practice

1127
00:47:09,440 --> 00:47:12,319
or are actually being used

1128
00:47:12,319 --> 00:47:14,960
right now so we're looking for feedback

1129
00:47:14,960 --> 00:47:16,400
now

1130
00:47:16,400 --> 00:47:18,960
on formats and ideas you might have had

1131
00:47:18,960 --> 00:47:19,440
there

1132
00:47:19,440 --> 00:47:20,720
and also some things that you might have

1133
00:47:20,720 --> 00:47:23,040
had as input from tools

1134
00:47:23,040 --> 00:47:24,800
most of this work for for practical

1135
00:47:24,800 --> 00:47:26,079
reasons will happen in the

1136
00:47:26,079 --> 00:47:27,599
quick working group even though we're

1137
00:47:27,599 --> 00:47:29,839
also looking for other protocols

1138
00:47:29,839 --> 00:47:31,839
um as well and we will of course have

1139
00:47:31,839 --> 00:47:33,359
some very good input already because

1140
00:47:33,359 --> 00:47:34,480
there are

1141
00:47:34,480 --> 00:47:36,079
a lot of knowledgeable people involved

1142
00:47:36,079 --> 00:47:38,000
in quick with this as well but extra

1143
00:47:38,000 --> 00:47:39,680
feedback and opinions are always

1144
00:47:39,680 --> 00:47:43,280
welcome there are using the giz help of

1145
00:47:43,280 --> 00:47:44,559
course right now

1146
00:47:44,559 --> 00:47:46,240
as i'm interested hearing feedback and

1147
00:47:46,240 --> 00:47:49,598
questions thank you

1148
00:47:51,680 --> 00:47:53,040
thank you so much for the presentation

1149
00:47:53,040 --> 00:47:54,960
robin uh we have time for just a couple

1150
00:47:54,960 --> 00:47:56,160
of quick questions

1151
00:47:56,160 --> 00:47:59,200
but i want to uh uh quickly say that i'm

1152
00:47:59,200 --> 00:48:01,040
i'm grateful for robin for presenting

1153
00:48:01,040 --> 00:48:02,640
this here and of course for

1154
00:48:02,640 --> 00:48:04,720
the work that he's doing this is super

1155
00:48:04,720 --> 00:48:06,079
super useful

1156
00:48:06,079 --> 00:48:07,920
for quick but as he points out it's

1157
00:48:07,920 --> 00:48:09,359
super helpful for

1158
00:48:09,359 --> 00:48:11,040
for for transports as well people who

1159
00:48:11,040 --> 00:48:12,559
wanted to do

1160
00:48:12,559 --> 00:48:15,839
and use tooling that's um that's more

1161
00:48:15,839 --> 00:48:17,839
modern so to speak will find this to be

1162
00:48:17,839 --> 00:48:19,280
extremely useful okay

1163
00:48:19,280 --> 00:48:23,280
john john you're you're you're up

1164
00:48:23,280 --> 00:48:27,440
uh thanks um i just wanted to ask

1165
00:48:27,440 --> 00:48:30,079
what sort of compression algorithm

1166
00:48:30,079 --> 00:48:34,319
you're using to get the 18 megabytes

1167
00:48:34,319 --> 00:48:37,359
oh that's just normal zip

1168
00:48:37,359 --> 00:48:40,559
yesterday okay

1169
00:48:40,559 --> 00:48:42,960
so presumably a more advanced conversion

1170
00:48:42,960 --> 00:48:45,760
would get it down smaller

1171
00:48:45,760 --> 00:48:48,559
sure and for storage and transfer that's

1172
00:48:48,559 --> 00:48:49,440
fine

1173
00:48:49,440 --> 00:48:51,280
for now but it's mainly if you want to

1174
00:48:51,280 --> 00:48:52,960
load this for example rqvis tools are

1175
00:48:52,960 --> 00:48:54,480
all web-based

1176
00:48:54,480 --> 00:48:56,319
and your browser really doesn't like you

1177
00:48:56,319 --> 00:48:57,839
uploading a gigabytes

1178
00:48:57,839 --> 00:49:01,040
json file or or

1179
00:49:01,040 --> 00:49:02,400
or downloading the compressed version

1180
00:49:02,400 --> 00:49:03,599
and then having to unzip it in the

1181
00:49:03,599 --> 00:49:05,040
browser is also not something it likes

1182
00:49:05,040 --> 00:49:07,200
to do so

1183
00:49:07,200 --> 00:49:09,839
yeah okay

1184
00:49:15,040 --> 00:49:16,640
all right it looks like we don't have

1185
00:49:16,640 --> 00:49:18,720
anybody else in the queue but

1186
00:49:18,720 --> 00:49:20,720
oh jake you're a stretcher okay i'm

1187
00:49:20,720 --> 00:49:22,319
gonna close the queue after richard but

1188
00:49:22,319 --> 00:49:25,040
jake you're up next

1189
00:49:25,040 --> 00:49:27,520
yeah hi i i do think this looks very

1190
00:49:27,520 --> 00:49:28,960
interesting has anybody started doing

1191
00:49:28,960 --> 00:49:30,079
anything with this for

1192
00:49:30,079 --> 00:49:33,920
uh for tcp like

1193
00:49:33,920 --> 00:49:38,240
this seems like it does have obvious

1194
00:49:38,240 --> 00:49:41,280
um not not concretely like we have the

1195
00:49:41,280 --> 00:49:43,599
proof of concepts those are more like

1196
00:49:43,599 --> 00:49:47,040
research projects i do know that people

1197
00:49:47,040 --> 00:49:48,640
at facebook and google have shown

1198
00:49:48,640 --> 00:49:49,359
interest

1199
00:49:49,359 --> 00:49:52,800
in applying this to tcp as well and i

1200
00:49:52,800 --> 00:49:53,520
think even

1201
00:49:53,520 --> 00:49:57,119
apple as well to doing that but i don't

1202
00:49:57,119 --> 00:49:58,000
know of any concrete

1203
00:49:58,000 --> 00:49:59,599
efforts yet but i'm very interested in

1204
00:49:59,599 --> 00:50:02,400
hearing from people

1205
00:50:02,640 --> 00:50:12,000
okay thanks

1206
00:50:12,000 --> 00:50:14,000
so i would just wanted to uh basically

1207
00:50:14,000 --> 00:50:15,680
chime into the same horn here

1208
00:50:15,680 --> 00:50:18,800
and i think it's very interesting to

1209
00:50:18,800 --> 00:50:22,400
have a standardized way to lock these

1210
00:50:22,400 --> 00:50:25,200
um congestion control internal events

1211
00:50:25,200 --> 00:50:27,920
especially useful for tcp obviously

1212
00:50:27,920 --> 00:50:30,880
because right now at least i am faced

1213
00:50:30,880 --> 00:50:32,559
with at least three different

1214
00:50:32,559 --> 00:50:35,599
approaches how to diagnose and

1215
00:50:35,599 --> 00:50:37,760
troubleshoot

1216
00:50:37,760 --> 00:50:40,480
tcp and none of them are standardized so

1217
00:50:40,480 --> 00:50:42,160
they all need their specialized tool

1218
00:50:42,160 --> 00:50:42,800
sets they

1219
00:50:42,800 --> 00:50:45,119
may need the recompilations of the stack

1220
00:50:45,119 --> 00:50:47,599
and so forth

1221
00:50:48,100 --> 00:50:51,159
[Music]

1222
00:50:52,480 --> 00:50:54,160
thanks for that comment richard i'll say

1223
00:50:54,160 --> 00:50:56,160
that uh at high level

1224
00:50:56,160 --> 00:50:59,040
um just two quick points before i let

1225
00:50:59,040 --> 00:50:59,839
robin go

1226
00:50:59,839 --> 00:51:03,200
one is that the q log tool the q log

1227
00:51:03,200 --> 00:51:04,480
schema is different from the

1228
00:51:04,480 --> 00:51:06,640
visualization tool and that's actually

1229
00:51:06,640 --> 00:51:06,960
quite

1230
00:51:06,960 --> 00:51:09,119
quite an important distinction here to

1231
00:51:09,119 --> 00:51:10,240
your point uh

1232
00:51:10,240 --> 00:51:12,079
there richard which is that if you want

1233
00:51:12,079 --> 00:51:13,920
to extend the with the schema

1234
00:51:13,920 --> 00:51:16,160
to include more events in tcp and so on

1235
00:51:16,160 --> 00:51:17,440
and so forth that is an

1236
00:51:17,440 --> 00:51:19,839
excellent uh uh that that would be very

1237
00:51:19,839 --> 00:51:21,280
useful work i think

1238
00:51:21,280 --> 00:51:23,599
i'm speaking for robin here but at the

1239
00:51:23,599 --> 00:51:25,119
moment in the quick working group at

1240
00:51:25,119 --> 00:51:25,680
least

1241
00:51:25,680 --> 00:51:27,359
this is going to be taken up and the

1242
00:51:27,359 --> 00:51:29,280
focus is going to be what

1243
00:51:29,280 --> 00:51:31,680
needs to be logged for quick not for

1244
00:51:31,680 --> 00:51:33,119
other protocols but if there are

1245
00:51:33,119 --> 00:51:34,960
extensions that you need to make or if

1246
00:51:34,960 --> 00:51:36,400
you want to extend the schema for the

1247
00:51:36,400 --> 00:51:37,200
future

1248
00:51:37,200 --> 00:51:39,119
that work would be very useful to do now

1249
00:51:39,119 --> 00:51:40,480
because i imagine that if you want to

1250
00:51:40,480 --> 00:51:42,079
adopt this sort of work in other working

1251
00:51:42,079 --> 00:51:42,640
groups

1252
00:51:42,640 --> 00:51:44,160
then having that work done before it

1253
00:51:44,160 --> 00:51:47,598
gets there would be very useful

1254
00:51:49,359 --> 00:51:52,880
all right i will uh thank uh robin for

1255
00:51:52,880 --> 00:51:53,680
his presentation

1256
00:51:53,680 --> 00:51:56,720
and martin you get to jump into the

1257
00:51:56,720 --> 00:51:58,559
queue and say something

1258
00:51:58,559 --> 00:52:00,400
yeah hi thanks john i just want to say

1259
00:52:00,400 --> 00:52:02,240
yeah as as responsibly

1260
00:52:02,240 --> 00:52:05,520
for tcpm and psvwg

1261
00:52:05,520 --> 00:52:09,920
i think i would be very interested in

1262
00:52:09,920 --> 00:52:12,960
drafts for events in those protocols and

1263
00:52:12,960 --> 00:52:15,359
other transport protocols

1264
00:52:15,359 --> 00:52:16,839
appearing in those working groups to

1265
00:52:16,839 --> 00:52:20,880
standardize in the q log framework

1266
00:52:26,960 --> 00:52:30,800
thank you martin and thank you robin

1267
00:52:30,800 --> 00:52:33,839
to the next one

1268
00:52:34,559 --> 00:52:40,000
uh anna i think

1269
00:52:40,480 --> 00:52:46,720
europe i should

1270
00:52:46,720 --> 00:52:49,920
okay thank you jana so i

1271
00:52:49,920 --> 00:52:51,920
am going to talk about the congestion

1272
00:52:51,920 --> 00:52:53,839
control in congestion control in the

1273
00:52:53,839 --> 00:52:54,880
multipath

1274
00:52:54,880 --> 00:52:58,559
context and this is work that has

1275
00:52:58,559 --> 00:53:00,640
been done as part of our work on

1276
00:53:00,640 --> 00:53:01,680
multipath

1277
00:53:01,680 --> 00:53:04,480
dccp but what i'm going to talk about

1278
00:53:04,480 --> 00:53:05,520
today

1279
00:53:05,520 --> 00:53:08,400
is also applicable for for other

1280
00:53:08,400 --> 00:53:10,240
protocols so the general problem of

1281
00:53:10,240 --> 00:53:11,760
congestion controlling congestion

1282
00:53:11,760 --> 00:53:13,359
control for multipath

1283
00:53:13,359 --> 00:53:16,079
and this is joint work with colleagues

1284
00:53:16,079 --> 00:53:17,680
at deutsche telekom

1285
00:53:17,680 --> 00:53:19,520
city university of london and my

1286
00:53:19,520 --> 00:53:21,920
colleagues at college university

1287
00:53:21,920 --> 00:53:24,000
and in particular the results that i

1288
00:53:24,000 --> 00:53:25,520
will talk about today

1289
00:53:25,520 --> 00:53:27,920
is from our phd student at college

1290
00:53:27,920 --> 00:53:28,640
university

1291
00:53:28,640 --> 00:53:33,520
marcus piezka so next slide please

1292
00:53:35,520 --> 00:53:37,119
so first a little bit about the

1293
00:53:37,119 --> 00:53:38,720
background and context

1294
00:53:38,720 --> 00:53:42,480
so we are working on multipath

1295
00:53:42,480 --> 00:53:46,319
dccp as a multipath solution for

1296
00:53:46,319 --> 00:53:49,839
transporting general ip traffic or udp

1297
00:53:49,839 --> 00:53:54,160
traffic and this framework is using dccp

1298
00:53:54,160 --> 00:53:57,920
as the protocol so you have one dccp

1299
00:53:57,920 --> 00:54:01,200
tunnel per path and the two main use

1300
00:54:01,200 --> 00:54:02,079
cases

1301
00:54:02,079 --> 00:54:05,200
that we have in mind for this is

1302
00:54:05,200 --> 00:54:08,480
in the context of 3gpp and

1303
00:54:08,480 --> 00:54:11,040
access traffic steering switching and

1304
00:54:11,040 --> 00:54:12,960
splitting architecture

1305
00:54:12,960 --> 00:54:14,640
that is being defined there for

1306
00:54:14,640 --> 00:54:16,000
combining

1307
00:54:16,000 --> 00:54:19,200
cellular and wi-fi networks and

1308
00:54:19,200 --> 00:54:22,800
also for the hybrid access use case in

1309
00:54:22,800 --> 00:54:24,800
in home networks where you combine the

1310
00:54:24,800 --> 00:54:28,079
fixed and a cellular link for

1311
00:54:28,079 --> 00:54:33,200
better performance next slide please

1312
00:54:36,160 --> 00:54:38,960
so then let's look at the the problem uh

1313
00:54:38,960 --> 00:54:41,119
that we then encounter if we have

1314
00:54:41,119 --> 00:54:44,799
this type of multipath uh framework and

1315
00:54:44,799 --> 00:54:47,680
and this is generic for the protocol as

1316
00:54:47,680 --> 00:54:48,799
i said

1317
00:54:48,799 --> 00:54:51,520
so this tunneling solution of course

1318
00:54:51,520 --> 00:54:52,559
results in

1319
00:54:52,559 --> 00:54:55,520
nested congestion controls and this can

1320
00:54:55,520 --> 00:54:56,160
also be

1321
00:54:56,160 --> 00:54:59,040
a problem for for single bath a single

1322
00:54:59,040 --> 00:55:00,079
path

1323
00:55:00,079 --> 00:55:02,640
tunneling but when you move into the

1324
00:55:02,640 --> 00:55:03,760
multipath

1325
00:55:03,760 --> 00:55:08,000
context this encounters of course

1326
00:55:08,000 --> 00:55:11,280
an added complexity and

1327
00:55:11,280 --> 00:55:14,319
in our work we are using uncoupled

1328
00:55:14,319 --> 00:55:16,400
congestion control over the the two

1329
00:55:16,400 --> 00:55:17,520
parts

1330
00:55:17,520 --> 00:55:21,040
in all the cases as the use cases here

1331
00:55:21,040 --> 00:55:22,880
we don't see the need for coupling the

1332
00:55:22,880 --> 00:55:25,280
congestion control as the idea is to to

1333
00:55:25,280 --> 00:55:27,920
use the two parts and to be able to

1334
00:55:27,920 --> 00:55:30,480
to aggregate them and use them for the

1335
00:55:30,480 --> 00:55:32,720
better performance and we don't expect

1336
00:55:32,720 --> 00:55:35,520
the fairness issues to come into play

1337
00:55:35,520 --> 00:55:36,480
here so

1338
00:55:36,480 --> 00:55:39,359
you see the general setup on the picture

1339
00:55:39,359 --> 00:55:40,960
here you have a ue

1340
00:55:40,960 --> 00:55:45,119
and then you have a proxy or a

1341
00:55:45,119 --> 00:55:47,760
tunneling endpoint where you in this

1342
00:55:47,760 --> 00:55:50,079
figure have a downlink transfer so you

1343
00:55:50,079 --> 00:55:51,839
have the scheduling

1344
00:55:51,839 --> 00:55:54,559
component in this amp and then you have

1345
00:55:54,559 --> 00:55:56,000
two paths

1346
00:55:56,000 --> 00:55:57,680
two multi-paths with a congestion

1347
00:55:57,680 --> 00:55:59,200
control

1348
00:55:59,200 --> 00:56:01,839
a reordering component for the packets

1349
00:56:01,839 --> 00:56:02,480
and then

1350
00:56:02,480 --> 00:56:04,960
you have the also the congestion control

1351
00:56:04,960 --> 00:56:05,920
from the ue

1352
00:56:05,920 --> 00:56:09,839
and the to the server

1353
00:56:09,839 --> 00:56:16,400
next slide

1354
00:56:16,400 --> 00:56:19,920
so this scheduling and reordering

1355
00:56:19,920 --> 00:56:21,520
components will have a very

1356
00:56:21,520 --> 00:56:24,640
large impact on the performance in this

1357
00:56:24,640 --> 00:56:27,680
scenario so in this

1358
00:56:27,680 --> 00:56:30,640
results that i will talk about today and

1359
00:56:30,640 --> 00:56:32,079
also for a lot of the

1360
00:56:32,079 --> 00:56:34,480
the work we have done here we have

1361
00:56:34,480 --> 00:56:36,480
looked particularly as

1362
00:56:36,480 --> 00:56:39,599
at the cheapest path the first

1363
00:56:39,599 --> 00:56:42,240
scheduler or the the strict priority

1364
00:56:42,240 --> 00:56:43,440
scheduler

1365
00:56:43,440 --> 00:56:46,640
so you have a prepare preferred path and

1366
00:56:46,640 --> 00:56:47,359
you send

1367
00:56:47,359 --> 00:56:51,119
data on this path whenever you have a

1368
00:56:51,119 --> 00:56:53,200
space available in your congestion

1369
00:56:53,200 --> 00:56:54,240
window

1370
00:56:54,240 --> 00:56:57,359
and it's only if this

1371
00:56:57,359 --> 00:56:59,920
preferred path is not available that you

1372
00:56:59,920 --> 00:57:02,480
start to use your your other paths and

1373
00:57:02,480 --> 00:57:05,520
this is also of course uh

1374
00:57:05,520 --> 00:57:08,799
we think a quite reasonable scheduler

1375
00:57:08,799 --> 00:57:10,839
for the scenario that we are targeting

1376
00:57:10,839 --> 00:57:13,280
because you may for instance want to use

1377
00:57:13,280 --> 00:57:13,920
your

1378
00:57:13,920 --> 00:57:16,400
your wi-fi network and then only use

1379
00:57:16,400 --> 00:57:17,200
your

1380
00:57:17,200 --> 00:57:20,240
cellular quota if you if the wi-fi

1381
00:57:20,240 --> 00:57:21,839
network does not provide the

1382
00:57:21,839 --> 00:57:24,799
sufficient performance or you use your

1383
00:57:24,799 --> 00:57:25,359
your fixed

1384
00:57:25,359 --> 00:57:27,200
network in the hybrid access scenario

1385
00:57:27,200 --> 00:57:29,040
and then use your cellular

1386
00:57:29,040 --> 00:57:32,319
network for improved performance when

1387
00:57:32,319 --> 00:57:34,160
needed so this is a

1388
00:57:34,160 --> 00:57:37,680
scheduler that can have benefits both

1389
00:57:37,680 --> 00:57:39,359
from the user perspective and also from

1390
00:57:39,359 --> 00:57:40,000
the

1391
00:57:40,000 --> 00:57:43,280
operator perspective

1392
00:57:43,280 --> 00:57:46,000
the reordering component can also have

1393
00:57:46,000 --> 00:57:46,640
different

1394
00:57:46,640 --> 00:57:49,359
uh functions and i think marcus will

1395
00:57:49,359 --> 00:57:49,920
talk

1396
00:57:49,920 --> 00:57:52,720
particularly about reordering in the the

1397
00:57:52,720 --> 00:57:54,000
next talk

1398
00:57:54,000 --> 00:57:56,000
but in the work i'm presenting here

1399
00:57:56,000 --> 00:57:57,119
we're using an

1400
00:57:57,119 --> 00:58:00,480
adaptive time limit for

1401
00:58:00,480 --> 00:58:03,680
for the reordering to determine if to

1402
00:58:03,680 --> 00:58:05,599
pass the packets on

1403
00:58:05,599 --> 00:58:08,640
or not as we

1404
00:58:08,640 --> 00:58:11,200
may not have a reliable transfer also

1405
00:58:11,200 --> 00:58:14,799
over the the tunnel paths

1406
00:58:15,280 --> 00:58:18,160
next slide please

1407
00:58:20,559 --> 00:58:23,040
so i mentioned that if we move to the

1408
00:58:23,040 --> 00:58:25,200
multipath domain we have some

1409
00:58:25,200 --> 00:58:27,920
additional uh challenges uh for the

1410
00:58:27,920 --> 00:58:30,640
congestion control in congestion control

1411
00:58:30,640 --> 00:58:33,839
and particularly uh the challenge in

1412
00:58:33,839 --> 00:58:36,559
in this scenario is to be able to

1413
00:58:36,559 --> 00:58:38,160
aggregate the capacity

1414
00:58:38,160 --> 00:58:41,200
over the two parts so you're using one

1415
00:58:41,200 --> 00:58:42,880
path as your

1416
00:58:42,880 --> 00:58:46,079
preferred path and the challenge then is

1417
00:58:46,079 --> 00:58:48,079
to actually be able to also

1418
00:58:48,079 --> 00:58:51,119
use the second path when needed and in

1419
00:58:51,119 --> 00:58:52,720
particular

1420
00:58:52,720 --> 00:58:56,000
the end-to-end congestion control may

1421
00:58:56,000 --> 00:58:57,680
react

1422
00:58:57,680 --> 00:59:00,559
before and slow down before you are able

1423
00:59:00,559 --> 00:59:04,640
to actually start to utilize that path

1424
00:59:04,640 --> 00:59:08,240
if we take the the next slide

1425
00:59:11,760 --> 00:59:14,799
and here we have a example of this so

1426
00:59:14,799 --> 00:59:16,559
what you see in this graph

1427
00:59:16,559 --> 00:59:19,920
is a time sequence of four

1428
00:59:19,920 --> 00:59:22,720
different transmissions stacked on top

1429
00:59:22,720 --> 00:59:24,000
of each other

1430
00:59:24,000 --> 00:59:27,520
and for each one you see the the green

1431
00:59:27,520 --> 00:59:30,640
throughput is for the preferred path and

1432
00:59:30,640 --> 00:59:33,520
the red throughput is for the second

1433
00:59:33,520 --> 00:59:33,920
path

1434
00:59:33,920 --> 00:59:37,119
so up at the top of the

1435
00:59:37,119 --> 00:59:40,559
the topmost scenario you see that

1436
00:59:40,559 --> 00:59:42,400
things work as you would like it you

1437
00:59:42,400 --> 00:59:43,839
have

1438
00:59:43,839 --> 00:59:46,799
capacity using both the first path and

1439
00:59:46,799 --> 00:59:48,559
the second path

1440
00:59:48,559 --> 00:59:51,200
the second scenario from the top on the

1441
00:59:51,200 --> 00:59:52,480
other hand does not

1442
00:59:52,480 --> 00:59:55,920
work well at all you're not able to

1443
00:59:55,920 --> 00:59:58,480
use any of the second path so only the

1444
00:59:58,480 --> 01:00:00,240
capacity on the first part

1445
01:00:00,240 --> 01:00:03,119
is actually utilized and then we have

1446
01:00:03,119 --> 01:00:04,720
two examples where you

1447
01:00:04,720 --> 01:00:08,000
kind of manage to use some of the

1448
01:00:08,000 --> 01:00:11,119
the capacity of the second path and

1449
01:00:11,119 --> 01:00:13,359
in general the the use here is going up

1450
01:00:13,359 --> 01:00:14,880
and down a bit and this is

1451
01:00:14,880 --> 01:00:17,359
uh experiments with four different

1452
01:00:17,359 --> 01:00:19,599
configurations that shows how

1453
01:00:19,599 --> 01:00:21,680
different the outcome can actually be

1454
01:00:21,680 --> 01:00:24,160
here depending on

1455
01:00:24,160 --> 01:00:27,040
a number of parameters that impact this

1456
01:00:27,040 --> 01:00:28,640
performance

1457
01:00:28,640 --> 01:00:31,520
next slide please

1458
01:00:33,520 --> 01:00:36,160
so the results that i'm showing here is

1459
01:00:36,160 --> 01:00:36,799
using

1460
01:00:36,799 --> 01:00:40,480
a user's base implementation

1461
01:00:40,480 --> 01:00:43,599
of this multipath framework so there is

1462
01:00:43,599 --> 01:00:44,640
also a

1463
01:00:44,640 --> 01:00:47,520
kernel level uh implementation developed

1464
01:00:47,520 --> 01:00:47,839
by

1465
01:00:47,839 --> 01:00:49,599
uh the colleagues at deutsche telekom

1466
01:00:49,599 --> 01:00:51,680
available that

1467
01:00:51,680 --> 01:00:54,839
mike has presented the last ietf in the

1468
01:00:54,839 --> 01:00:56,960
tsvwd session some measurements from

1469
01:00:56,960 --> 01:00:57,760
there

1470
01:00:57,760 --> 01:01:00,160
but here we use a user space

1471
01:01:00,160 --> 01:01:02,160
implementation which of course offered

1472
01:01:02,160 --> 01:01:02,720
and

1473
01:01:02,720 --> 01:01:05,839
quite a lot of flexibility in trying out

1474
01:01:05,839 --> 01:01:06,559
different

1475
01:01:06,559 --> 01:01:11,760
protocols and different configurations

1476
01:01:11,760 --> 01:01:16,319
and this usage base program

1477
01:01:20,400 --> 01:01:22,960
do you hear me

1478
01:01:23,440 --> 01:01:25,440
okay something seemed to have happened

1479
01:01:25,440 --> 01:01:27,280
there with uh

1480
01:01:27,280 --> 01:01:30,400
good luck i'm back okay when did you

1481
01:01:30,400 --> 01:01:32,000
lose me

1482
01:01:32,000 --> 01:01:35,119
so i was uh explaining that we are using

1483
01:01:35,119 --> 01:01:35,839
a multi

1484
01:01:35,839 --> 01:01:39,520
the user space framework for this

1485
01:01:39,520 --> 01:01:42,480
experiments and this offers them a lot

1486
01:01:42,480 --> 01:01:44,400
of flexibility in how to

1487
01:01:44,400 --> 01:01:47,119
try out different scheduling methods and

1488
01:01:47,119 --> 01:01:48,079
and different

1489
01:01:48,079 --> 01:01:49,920
protocols so in this framework the

1490
01:01:49,920 --> 01:01:52,079
packets are captured through the

1491
01:01:52,079 --> 01:01:54,799
linux tune device and then the framework

1492
01:01:54,799 --> 01:01:57,280
encapsulates the packets with

1493
01:01:57,280 --> 01:01:59,200
information like the path sequence

1494
01:01:59,200 --> 01:02:00,960
numbers and the timestamps of the

1495
01:02:00,960 --> 01:02:02,160
packets

1496
01:02:02,160 --> 01:02:05,599
and then packets are scheduled over two

1497
01:02:05,599 --> 01:02:08,240
single path sockets so this means that

1498
01:02:08,240 --> 01:02:09,440
the framework as such

1499
01:02:09,440 --> 01:02:13,760
is not tied to dccp it also allows us to

1500
01:02:13,760 --> 01:02:16,880
use other protocols uh as tunnels so in

1501
01:02:16,880 --> 01:02:17,520
the

1502
01:02:17,520 --> 01:02:21,839
experimental results we have both

1503
01:02:22,160 --> 01:02:26,400
dccp and the tcp in the experiment

1504
01:02:26,400 --> 01:02:34,319
that you will see in the next line

1505
01:02:34,319 --> 01:02:36,480
and so this is the setup of the

1506
01:02:36,480 --> 01:02:37,680
experiments

1507
01:02:37,680 --> 01:02:40,640
on the end-to-end path it's the ip

1508
01:02:40,640 --> 01:02:42,799
tunneling where we have tcp

1509
01:02:42,799 --> 01:02:46,799
on top so we have used tcp cubic and tcp

1510
01:02:46,799 --> 01:02:50,880
bbr and in the tunnel

1511
01:03:00,319 --> 01:03:02,720
okay so i think maybe i will turn off my

1512
01:03:02,720 --> 01:03:05,039
video because this maybe is messing up

1513
01:03:05,039 --> 01:03:07,440
with the

1514
01:03:13,200 --> 01:03:16,799
okay so uh

1515
01:03:16,799 --> 01:03:19,359
as i said for the tunnel we are using

1516
01:03:19,359 --> 01:03:20,319
using both

1517
01:03:20,319 --> 01:03:24,160
tcp tcp neurino and tcp bbr

1518
01:03:24,160 --> 01:03:27,880
and then we are using a dccp with the

1519
01:03:27,880 --> 01:03:31,039
ccid2 which corresponds to

1520
01:03:31,039 --> 01:03:35,079
neurino and also a new ccid

1521
01:03:35,079 --> 01:03:38,720
ccid5 which is a implementation

1522
01:03:38,720 --> 01:03:43,920
of bbr style congestion control for dccp

1523
01:03:43,920 --> 01:03:45,760
and

1524
01:03:45,760 --> 01:03:49,200
we have uh some base

1525
01:03:49,200 --> 01:03:51,839
delays for the the two different paths

1526
01:03:51,839 --> 01:03:54,480
on the multipath and for the added delay

1527
01:03:54,480 --> 01:03:58,079
to the server 20 milliseconds on on

1528
01:03:58,079 --> 01:04:01,520
the preferred path and initial 20

1529
01:04:01,520 --> 01:04:03,920
milliseconds to the server as a baseline

1530
01:04:03,920 --> 01:04:06,079
and a similar trick path as a baseline

1531
01:04:06,079 --> 01:04:09,039
with 40 milliseconds to the second

1532
01:04:09,039 --> 01:04:11,599
over the second path and the same

1533
01:04:11,599 --> 01:04:12,640
bandwidth

1534
01:04:12,640 --> 01:04:16,319
and same q configurations on both paths

1535
01:04:16,319 --> 01:04:19,520
so next slide please

1536
01:04:22,400 --> 01:04:25,599
so now some example

1537
01:04:25,599 --> 01:04:28,160
results so short here stands for the

1538
01:04:28,160 --> 01:04:28,880
basic

1539
01:04:28,880 --> 01:04:32,000
configuration and what we see here

1540
01:04:32,000 --> 01:04:34,480
is the combination of different

1541
01:04:34,480 --> 01:04:37,599
congestion controls

1542
01:04:37,599 --> 01:04:41,280
on the end to end path and then in the

1543
01:04:41,280 --> 01:04:45,520
the tunnel and the results are relative

1544
01:04:45,520 --> 01:04:46,960
to the performance

1545
01:04:46,960 --> 01:04:50,880
over a single path so you see a

1546
01:04:50,880 --> 01:04:53,119
percentage of the the flow completion

1547
01:04:53,119 --> 01:04:54,400
time for downloading

1548
01:04:54,400 --> 01:04:57,839
a large file here so if you're below 100

1549
01:04:57,839 --> 01:05:01,119
you have gained performance as compared

1550
01:05:01,119 --> 01:05:02,319
to the

1551
01:05:02,319 --> 01:05:05,599
single path case and you can see here

1552
01:05:05,599 --> 01:05:06,319
that the

1553
01:05:06,319 --> 01:05:09,280
the performance varies a lot depending

1554
01:05:09,280 --> 01:05:10,559
on what

1555
01:05:10,559 --> 01:05:14,240
congestion control combinations you use

1556
01:05:14,240 --> 01:05:17,760
uh in general bbr is performing better

1557
01:05:17,760 --> 01:05:19,520
as a tunnel protocol

1558
01:05:19,520 --> 01:05:23,359
and this is as bbr reacts faster

1559
01:05:23,359 --> 01:05:26,319
when you start to experience congestion

1560
01:05:26,319 --> 01:05:27,760
and there is also less

1561
01:05:27,760 --> 01:05:31,119
loss over the tunnel

1562
01:05:31,119 --> 01:05:35,280
with bbr and you can also see that the

1563
01:05:35,280 --> 01:05:38,480
bbr at endpoints with reno in the tunnel

1564
01:05:38,480 --> 01:05:42,799
performs very poorly here because bbr

1565
01:05:42,799 --> 01:05:45,760
reacts before the the second path is

1566
01:05:45,760 --> 01:05:48,319
used

1567
01:05:49,039 --> 01:05:51,839
next slide please

1568
01:05:56,000 --> 01:05:58,559
so here we have another scenario where

1569
01:05:58,559 --> 01:05:59,119
we

1570
01:05:59,119 --> 01:06:02,160
look at the impact of where you

1571
01:06:02,160 --> 01:06:06,000
put the tunnel end point in relation

1572
01:06:06,000 --> 01:06:09,760
to the the server so the short

1573
01:06:09,760 --> 01:06:14,000
near scenario here the the proxy

1574
01:06:14,000 --> 01:06:16,799
is closer to the ue and you have more of

1575
01:06:16,799 --> 01:06:18,000
a difference between

1576
01:06:18,000 --> 01:06:21,680
the round-trip times end-to-end and

1577
01:06:21,680 --> 01:06:24,960
over the tunnel whereas the the short

1578
01:06:24,960 --> 01:06:26,240
distance then the

1579
01:06:26,240 --> 01:06:28,640
proxy is further away and closer to the

1580
01:06:28,640 --> 01:06:30,240
server

1581
01:06:30,240 --> 01:06:32,559
and you can see that this placement of

1582
01:06:32,559 --> 01:06:33,520
the

1583
01:06:33,520 --> 01:06:37,119
tunnel endpoint also has a large impact

1584
01:06:37,119 --> 01:06:38,720
on performance

1585
01:06:38,720 --> 01:06:42,160
and having the proxy closer to the user

1586
01:06:42,160 --> 01:06:45,359
to the ue as expected is typically

1587
01:06:45,359 --> 01:06:46,799
beneficial

1588
01:06:46,799 --> 01:06:49,440
because in this case you have more of a

1589
01:06:49,440 --> 01:06:50,880
difference between

1590
01:06:50,880 --> 01:06:53,599
the two control loops when you have more

1591
01:06:53,599 --> 01:06:56,400
difference in the rtts

1592
01:06:56,400 --> 01:06:59,920
and in particular you can see that

1593
01:06:59,920 --> 01:07:04,400
if the two rtt's are similar then bbr

1594
01:07:04,400 --> 01:07:08,160
over bbr performs quite poorly

1595
01:07:08,160 --> 01:07:14,160
next slide please

1596
01:07:14,160 --> 01:07:17,119
this is taking a little closer look at

1597
01:07:17,119 --> 01:07:18,880
this particular scenario

1598
01:07:18,880 --> 01:07:22,000
of the bbr uh over bbr

1599
01:07:22,000 --> 01:07:24,720
so what you see on the x-axis here is

1600
01:07:24,720 --> 01:07:25,119
the

1601
01:07:25,119 --> 01:07:28,880
end-to-end rtt and on the y-axis

1602
01:07:28,880 --> 01:07:31,920
you have the portion of that rtt

1603
01:07:31,920 --> 01:07:35,359
that is within the tunnel and you can

1604
01:07:35,359 --> 01:07:36,880
see very clearly here

1605
01:07:36,880 --> 01:07:42,480
how this has an impact on performance

1606
01:07:42,480 --> 01:07:46,160
and if you have

1607
01:07:46,720 --> 01:07:49,680
have a similar or similar rtt between

1608
01:07:49,680 --> 01:07:50,319
the

1609
01:07:50,319 --> 01:07:54,000
the two paths then bbr here is

1610
01:07:54,000 --> 01:07:58,079
reacting with the similar

1611
01:07:58,079 --> 01:08:00,400
attempt to fill the bottleneck and is

1612
01:08:00,400 --> 01:08:03,039
not able to move the the traffic over to

1613
01:08:03,039 --> 01:08:03,359
the

1614
01:08:03,359 --> 01:08:11,119
to the second path next slide please

1615
01:08:11,119 --> 01:08:14,400
um okay so to summarize um

1616
01:08:14,400 --> 01:08:16,000
the congestion control and congestion

1617
01:08:16,000 --> 01:08:18,719
control aspect has a lot of

1618
01:08:18,719 --> 01:08:21,279
impact on the performance on the the

1619
01:08:21,279 --> 01:08:22,238
multipath

1620
01:08:22,238 --> 01:08:25,120
tunneling problem and there's a lot of

1621
01:08:25,120 --> 01:08:26,158
factors that

1622
01:08:26,158 --> 01:08:29,198
interact here so the results that we saw

1623
01:08:29,198 --> 01:08:29,679
here

1624
01:08:29,679 --> 01:08:31,920
were particular to the the scheduling

1625
01:08:31,920 --> 01:08:34,000
mechanism of cheapest

1626
01:08:34,000 --> 01:08:37,040
pipe first and it also has a large

1627
01:08:37,040 --> 01:08:38,799
impact what the ordering mechanism you

1628
01:08:38,799 --> 01:08:41,679
use the different congestion controls

1629
01:08:41,679 --> 01:08:43,198
have quite the different

1630
01:08:43,198 --> 01:08:45,679
interactions uh the placement of the

1631
01:08:45,679 --> 01:08:48,319
proxy of course is also quite

1632
01:08:48,319 --> 01:08:50,839
important as well as the the path

1633
01:08:50,839 --> 01:08:52,319
characteristics

1634
01:08:52,319 --> 01:08:54,479
and if we should have some some first

1635
01:08:54,479 --> 01:08:56,799
general conclusions

1636
01:08:56,799 --> 01:09:00,080
uh from uh the the work we are going uh

1637
01:09:00,080 --> 01:09:01,839
we are working on we can see that

1638
01:09:01,839 --> 01:09:04,799
overall bbr performs better than

1639
01:09:04,799 --> 01:09:06,799
reno as the congestion control for the

1640
01:09:06,799 --> 01:09:08,238
tunnel

1641
01:09:08,238 --> 01:09:11,120
and having the proxy close to the user

1642
01:09:11,120 --> 01:09:12,158
as expected

1643
01:09:12,158 --> 01:09:15,359
is typically beneficial and

1644
01:09:15,359 --> 01:09:17,600
we are actively working on this playing

1645
01:09:17,600 --> 01:09:18,719
with the different

1646
01:09:18,719 --> 01:09:22,080
parameters and analyzing the the various

1647
01:09:22,080 --> 01:09:25,198
interactions so i hope that more results

1648
01:09:25,198 --> 01:09:26,399
will also

1649
01:09:26,399 --> 01:09:29,520
be coming and with the

1650
01:09:29,520 --> 01:09:34,560
next slide

1651
01:09:34,560 --> 01:09:36,960
and there are also a number of drafts

1652
01:09:36,960 --> 01:09:39,198
that are related to this presentation so

1653
01:09:39,198 --> 01:09:42,238
there's a draft for the multi-path tccp

1654
01:09:42,238 --> 01:09:45,198
protocol there's a draft related to the

1655
01:09:45,198 --> 01:09:45,679
the

1656
01:09:45,679 --> 01:09:48,719
framework multi-path framework some

1657
01:09:48,719 --> 01:09:51,600
draft related to how to

1658
01:09:51,600 --> 01:09:55,600
send dccp efficiently over udp

1659
01:09:55,600 --> 01:09:57,920
there is a draft on reordering that i

1660
01:09:57,920 --> 01:09:59,520
think marcus will talk about next and

1661
01:09:59,520 --> 01:10:00,239
there is also

1662
01:10:00,239 --> 01:10:04,559
a draft on multipath schedulers

1663
01:10:04,800 --> 01:10:07,760
and with that i am happy to have

1664
01:10:07,760 --> 01:10:09,840
questions

1665
01:10:09,840 --> 01:10:11,600
thank you anna let's keep this quick

1666
01:10:11,600 --> 01:10:13,040
because we have questions

1667
01:10:13,040 --> 01:10:15,760
after marcus's presentation next as well

1668
01:10:15,760 --> 01:10:17,360
uh i'll close the mic line here after

1669
01:10:17,360 --> 01:10:20,639
gauri but martin you're up

1670
01:10:21,280 --> 01:10:22,960
thank you anna this is very interesting

1671
01:10:22,960 --> 01:10:25,120
um how applicable do you think

1672
01:10:25,120 --> 01:10:27,760
these results are to non-multi-path

1673
01:10:27,760 --> 01:10:29,520
scenarios that have congestion control

1674
01:10:29,520 --> 01:10:33,199
in congestion fall like mask

1675
01:10:34,000 --> 01:10:37,520
so i mean the the particular problem of

1676
01:10:37,520 --> 01:10:37,920
of

1677
01:10:37,920 --> 01:10:40,719
using the second path which is the main

1678
01:10:40,719 --> 01:10:42,480
challenge here

1679
01:10:42,480 --> 01:10:44,800
will not happen unless you have have

1680
01:10:44,800 --> 01:10:47,199
multiple paths of course

1681
01:10:47,199 --> 01:10:50,400
uh some of the some of the

1682
01:10:50,400 --> 01:10:53,040
aspects that we see here for instance

1683
01:10:53,040 --> 01:10:55,280
the relation between

1684
01:10:55,280 --> 01:10:58,159
uh the different control loops in terms

1685
01:10:58,159 --> 01:10:59,520
of of rtt

1686
01:10:59,520 --> 01:11:02,480
and the impact of what what the

1687
01:11:02,480 --> 01:11:04,560
congestion controls you use in the

1688
01:11:04,560 --> 01:11:07,920
tunnel versus what you use and

1689
01:11:07,920 --> 01:11:10,320
will also come in to play in the single

1690
01:11:10,320 --> 01:11:12,400
path context but

1691
01:11:12,400 --> 01:11:14,719
the results are not directly

1692
01:11:14,719 --> 01:11:18,000
transferable of course

1693
01:11:21,679 --> 01:11:27,120
gauri you're up next

1694
01:11:27,120 --> 01:11:31,199
we don't hear yogori uh on side 11

1695
01:11:31,199 --> 01:11:34,000
i was curious with your heat map and how

1696
01:11:34,000 --> 01:11:36,080
this would play out if there was a much

1697
01:11:36,080 --> 01:11:39,440
larger rtt at place you know

1698
01:11:39,440 --> 01:11:41,679
is it so so can you just talk me through

1699
01:11:41,679 --> 01:11:44,320
a little bit more about what's going on

1700
01:11:44,320 --> 01:11:47,520
yeah so what you see here is

1701
01:11:47,520 --> 01:11:50,880
that the end to end rtt is going from

1702
01:11:50,880 --> 01:11:54,960
a very small rtt from you know

1703
01:11:54,960 --> 01:11:57,280
i think the smallest value used is 5

1704
01:11:57,280 --> 01:11:58,000
here

1705
01:11:58,000 --> 01:12:03,120
and up to about 100 milliseconds

1706
01:12:03,120 --> 01:12:06,640
and then on the y-axis you see

1707
01:12:06,640 --> 01:12:10,159
what portion of that rtt is

1708
01:12:10,159 --> 01:12:13,040
in the tunnel

1709
01:12:13,280 --> 01:12:16,719
so as you go up on the y-axis you have

1710
01:12:16,719 --> 01:12:20,320
more and more of the

1711
01:12:20,320 --> 01:12:23,920
rtt is inside the tunnel

1712
01:12:23,920 --> 01:12:26,080
which means that the the proxy is

1713
01:12:26,080 --> 01:12:29,199
further away from the ue

1714
01:12:29,199 --> 01:12:31,760
is the blue hole around 20 just an

1715
01:12:31,760 --> 01:12:34,640
artifact of the

1716
01:12:34,840 --> 01:12:36,880
analysis

1717
01:12:36,880 --> 01:12:40,239
uh the blue hole around 20 i'm not sure

1718
01:12:40,239 --> 01:12:42,400
what you you mean up in the top there

1719
01:12:42,400 --> 01:12:44,719
yeah yeah the top yeah i think that i

1720
01:12:44,719 --> 01:12:45,600
think that's just

1721
01:12:45,600 --> 01:12:47,760
a random effect so i mean what we have

1722
01:12:47,760 --> 01:12:49,520
done here is that we have sampled this

1723
01:12:49,520 --> 01:12:50,000
space

1724
01:12:50,000 --> 01:12:53,600
with the number of measurements and

1725
01:12:53,600 --> 01:12:55,520
so each measure of each measurement

1726
01:12:55,520 --> 01:12:57,920
point here is is

1727
01:12:57,920 --> 01:13:00,960
uh you know not repeated

1728
01:13:00,960 --> 01:13:03,679
many times it's like 400 samples over

1729
01:13:03,679 --> 01:13:04,880
the space

1730
01:13:04,880 --> 01:13:07,360
to create this heat map so there is

1731
01:13:07,360 --> 01:13:09,679
there is some noise in in this

1732
01:13:09,679 --> 01:13:13,679
graph of course but you can see

1733
01:13:13,679 --> 01:13:16,800
uh quite

1734
01:13:16,800 --> 01:13:19,840
clearly that the uh yeah

1735
01:13:19,840 --> 01:13:22,800
that the blue space is quite separated

1736
01:13:22,800 --> 01:13:23,920
from the red

1737
01:13:23,920 --> 01:13:26,080
so you can see quite clearly the impact

1738
01:13:26,080 --> 01:13:28,159
of the two control loops and and the

1739
01:13:28,159 --> 01:13:30,159
difference between the rtt's in the two

1740
01:13:30,159 --> 01:13:31,360
cases

1741
01:13:31,360 --> 01:13:35,120
thanks that's really nice thank you

1742
01:13:39,040 --> 01:13:42,560
thank you so much anna um we'll move on

1743
01:13:42,560 --> 01:13:44,239
to the next presentation

1744
01:13:44,239 --> 01:13:47,520
this would be the same space but i'm

1745
01:13:47,520 --> 01:13:48,960
gonna

1746
01:13:48,960 --> 01:13:52,800
bring this up marcus

1747
01:13:58,840 --> 01:14:00,719
europe

1748
01:14:00,719 --> 01:14:03,600
all right can you hear me

1749
01:14:03,840 --> 01:14:07,840
yes very good yeah

1750
01:14:07,840 --> 01:14:09,679
so i want to talk today about the

1751
01:14:09,679 --> 01:14:11,520
multi-pass sequence

1752
01:14:11,520 --> 01:14:14,080
maintenance what this means i will

1753
01:14:14,080 --> 01:14:16,000
elaborate in the next slide so next

1754
01:14:16,000 --> 01:14:18,480
slide please

1755
01:14:21,840 --> 01:14:25,040
yes starting with

1756
01:14:25,040 --> 01:14:27,280
how multi-path typically works which

1757
01:14:27,280 --> 01:14:28,239
components are

1758
01:14:28,239 --> 01:14:30,640
usually employed so let's have first to

1759
01:14:30,640 --> 01:14:33,360
look into the the picture

1760
01:14:33,360 --> 01:14:35,280
so on the left there's a sender on the

1761
01:14:35,280 --> 01:14:36,560
on the right you have a

1762
01:14:36,560 --> 01:14:40,640
receiver and in between that is now

1763
01:14:40,640 --> 01:14:42,960
very much related to multiples you have

1764
01:14:42,960 --> 01:14:43,920
at least two

1765
01:14:43,920 --> 01:14:47,360
communication paths

1766
01:14:47,440 --> 01:14:51,120
and on center side you have a scheduler

1767
01:14:51,120 --> 01:14:51,760
which

1768
01:14:51,760 --> 01:14:54,320
is responsible to distribute traffic

1769
01:14:54,320 --> 01:14:55,360
across

1770
01:14:55,360 --> 01:14:56,960
the multiple paths so you can have

1771
01:14:56,960 --> 01:14:58,880
different logics for this and you will

1772
01:14:58,880 --> 01:15:00,320
find the number of logics already

1773
01:15:00,320 --> 01:15:01,120
described

1774
01:15:01,120 --> 01:15:06,320
in the iccrg scheduler draft

1775
01:15:06,320 --> 01:15:08,960
while on the receiver side you probably

1776
01:15:08,960 --> 01:15:10,480
have a reorder

1777
01:15:10,480 --> 01:15:12,960
reordering mechanism so here is called

1778
01:15:12,960 --> 01:15:14,640
reordering queue and that's exactly

1779
01:15:14,640 --> 01:15:15,840
where we want to focus

1780
01:15:15,840 --> 01:15:20,719
on today on how can we ensure

1781
01:15:20,719 --> 01:15:22,880
the sequence maintenance when it comes

1782
01:15:22,880 --> 01:15:25,520
to to multiples

1783
01:15:25,520 --> 01:15:28,880
between sender and receiver a multi-pass

1784
01:15:28,880 --> 01:15:29,920
network protocol

1785
01:15:29,920 --> 01:15:33,840
takes responsibility to

1786
01:15:33,840 --> 01:15:36,000
allow the communication between sender

1787
01:15:36,000 --> 01:15:37,280
and receiver

1788
01:15:37,280 --> 01:15:40,800
and typically in such

1789
01:15:40,800 --> 01:15:43,840
scenarios when it comes to heterogeneous

1790
01:15:43,840 --> 01:15:45,920
environments you have a latency

1791
01:15:45,920 --> 01:15:50,000
delta between the multiple paths

1792
01:15:50,000 --> 01:15:52,640
employed in the communication and that

1793
01:15:52,640 --> 01:15:54,400
is exactly the issue

1794
01:15:54,400 --> 01:15:57,520
um where i want to talk about so

1795
01:15:57,520 --> 01:15:59,760
with this latency delta you can imagine

1796
01:15:59,760 --> 01:16:01,360
when we simultaneously

1797
01:16:01,360 --> 01:16:04,719
use the two parts so maybe we send

1798
01:16:04,719 --> 01:16:08,000
the packets in a round robin fashion

1799
01:16:08,000 --> 01:16:10,880
that will cause out of order delivery on

1800
01:16:10,880 --> 01:16:13,440
receiver side

1801
01:16:13,440 --> 01:16:16,960
and with that it completely differs from

1802
01:16:16,960 --> 01:16:17,280
the

1803
01:16:17,280 --> 01:16:19,520
characteristic of a single path

1804
01:16:19,520 --> 01:16:21,199
communication because in a single past

1805
01:16:21,199 --> 01:16:23,360
communications you're only dependent

1806
01:16:23,360 --> 01:16:26,960
um from from from the latency of this

1807
01:16:26,960 --> 01:16:29,440
single path

1808
01:16:29,440 --> 01:16:31,520
so keeping it short here having a

1809
01:16:31,520 --> 01:16:33,440
latency delta between multiple paths

1810
01:16:33,440 --> 01:16:36,080
causes some trouble and services with a

1811
01:16:36,080 --> 01:16:38,159
certain expectation on data sequence and

1812
01:16:38,159 --> 01:16:39,520
consistency

1813
01:16:39,520 --> 01:16:44,080
will experience issues

1814
01:16:44,719 --> 01:16:46,480
if you look at itf we see there are

1815
01:16:46,480 --> 01:16:49,760
multiple multi-pass protocols

1816
01:16:49,760 --> 01:16:52,080
defined or available as a draft that is

1817
01:16:52,080 --> 01:16:53,199
multiple tcp

1818
01:16:53,199 --> 01:16:56,560
multi-pass dccpa multi-pass quick cmt

1819
01:16:56,560 --> 01:16:59,679
sctp and so on

1820
01:16:59,679 --> 01:17:01,280
and would be interesting to see in the

1821
01:17:01,280 --> 01:17:03,199
next slide how they

1822
01:17:03,199 --> 01:17:06,080
behave uh when it comes to out-of-order

1823
01:17:06,080 --> 01:17:09,360
delivery and which mechanisms they have

1824
01:17:09,360 --> 01:17:14,239
um implemented to to overcome this

1825
01:17:14,239 --> 01:17:16,159
nevertheless typically scheduling and

1826
01:17:16,159 --> 01:17:18,000
reordering are not part of the protocol

1827
01:17:18,000 --> 01:17:19,040
specification

1828
01:17:19,040 --> 01:17:22,719
and it's left with the implementers um

1829
01:17:22,719 --> 01:17:25,840
to to take care and

1830
01:17:25,840 --> 01:17:27,440
that might cause trouble if an

1831
01:17:27,440 --> 01:17:29,520
implementation is dependent on

1832
01:17:29,520 --> 01:17:33,040
protocol mechanisms we will come to this

1833
01:17:33,040 --> 01:17:36,400
in the next slides so for mptcp

1834
01:17:36,400 --> 01:17:38,640
reordering is simple to do the strict

1835
01:17:38,640 --> 01:17:39,679
reliability

1836
01:17:39,679 --> 01:17:42,080
of tcp so it's a trust trust to weight

1837
01:17:42,080 --> 01:17:42,880
approach

1838
01:17:42,880 --> 01:17:45,840
on the receiver side

1839
01:17:46,239 --> 01:17:50,239
but if you look into the next slide

1840
01:17:53,199 --> 01:17:56,719
then we see that there are a number of

1841
01:17:56,719 --> 01:17:59,760
multi-pass protocols which claim

1842
01:17:59,760 --> 01:18:03,360
to provide no strict reliable in-order

1843
01:18:03,360 --> 01:18:05,040
delivery and that is for example the

1844
01:18:05,040 --> 01:18:06,800
multi-pass dccp

1845
01:18:06,800 --> 01:18:08,800
it's also the combination of a

1846
01:18:08,800 --> 01:18:10,840
concurrent multipass

1847
01:18:10,840 --> 01:18:13,120
http combined with the partial

1848
01:18:13,120 --> 01:18:14,239
reliability

1849
01:18:14,239 --> 01:18:18,480
functionality from sctp it's also

1850
01:18:18,480 --> 01:18:20,800
the multipass quick when it becomes

1851
01:18:20,800 --> 01:18:21,679
combined

1852
01:18:21,679 --> 01:18:26,960
with a quick data cram

1853
01:18:26,960 --> 01:18:30,480
so from from today's perspective

1854
01:18:30,480 --> 01:18:33,360
i think they should consider sequence

1855
01:18:33,360 --> 01:18:35,360
maintenance in their design

1856
01:18:35,360 --> 01:18:38,400
but i from my feeling uh that is not

1857
01:18:38,400 --> 01:18:41,360
complete completely given right now

1858
01:18:41,360 --> 01:18:44,400
um so

1859
01:18:44,400 --> 01:18:47,199
for the three protocols i mentioned on

1860
01:18:47,199 --> 01:18:47,679
this

1861
01:18:47,679 --> 01:18:52,000
slide the dccp http and quick

1862
01:18:52,000 --> 01:18:54,000
when it becomes combined with the unreal

1863
01:18:54,000 --> 01:18:56,400
of unreliable transmission

1864
01:18:56,400 --> 01:18:59,280
um then strict reliability is is not an

1865
01:18:59,280 --> 01:19:01,120
option obviously

1866
01:19:01,120 --> 01:19:04,080
um and the solution if we talk about

1867
01:19:04,080 --> 01:19:06,080
sequence maintenance will be a trade-off

1868
01:19:06,080 --> 01:19:07,120
between

1869
01:19:07,120 --> 01:19:09,600
maintaining the data sequence without

1870
01:19:09,600 --> 01:19:10,560
interrupting

1871
01:19:10,560 --> 01:19:13,360
the data flow

1872
01:19:13,679 --> 01:19:16,719
a special challenge in this scenario

1873
01:19:16,719 --> 01:19:20,159
is when it comes to to packet loss and

1874
01:19:20,159 --> 01:19:21,920
i think it's likely when when we talk

1875
01:19:21,920 --> 01:19:24,000
about multi-path transmission that

1876
01:19:24,000 --> 01:19:26,719
uh we will see packet loss to some

1877
01:19:26,719 --> 01:19:27,920
extent

1878
01:19:27,920 --> 01:19:29,840
and then this is all always combined

1879
01:19:29,840 --> 01:19:31,120
with the question

1880
01:19:31,120 --> 01:19:34,000
so how long do we have to wait in a

1881
01:19:34,000 --> 01:19:35,679
potential reordering mechanism on

1882
01:19:35,679 --> 01:19:37,040
receiver side

1883
01:19:37,040 --> 01:19:40,960
and at one point at which point in time

1884
01:19:40,960 --> 01:19:43,600
we can assume that the packet is really

1885
01:19:43,600 --> 01:19:45,679
lost and we have not to wait

1886
01:19:45,679 --> 01:19:48,800
for it any longer so during the

1887
01:19:48,800 --> 01:19:50,719
multi-pass protocol design

1888
01:19:50,719 --> 01:19:52,800
this has to be considered and possible

1889
01:19:52,800 --> 01:19:54,719
measures like different sequencing

1890
01:19:54,719 --> 01:19:57,199
schemes so for example sequencing scheme

1891
01:19:57,199 --> 01:19:58,480
for path

1892
01:19:58,480 --> 01:20:00,640
and separately for the multi-pass

1893
01:20:00,640 --> 01:20:01,520
connection

1894
01:20:01,520 --> 01:20:03,840
or a sender receiver signaling have to

1895
01:20:03,840 --> 01:20:05,600
be taken into account i will come to

1896
01:20:05,600 --> 01:20:07,600
this in the next slides

1897
01:20:07,600 --> 01:20:09,920
um yeah with this draft we have

1898
01:20:09,920 --> 01:20:12,159
available as icci the multi-pass

1899
01:20:12,159 --> 01:20:14,000
reordering craft now in version two we

1900
01:20:14,000 --> 01:20:14,800
claim

1901
01:20:14,800 --> 01:20:17,199
to cover all these aspects and provide

1902
01:20:17,199 --> 01:20:19,199
guidelines for design and implementers

1903
01:20:19,199 --> 01:20:20,960
of multi-parts protocols

1904
01:20:20,960 --> 01:20:23,760
next slide please

1905
01:20:27,760 --> 01:20:31,280
yeah okay let's have a

1906
01:20:31,280 --> 01:20:33,920
deeper look into what we have specified

1907
01:20:33,920 --> 01:20:35,679
so far in the draft

1908
01:20:35,679 --> 01:20:40,639
so we discuss uh several mechanisms

1909
01:20:40,639 --> 01:20:43,600
to support smooth and adjustable in

1910
01:20:43,600 --> 01:20:44,960
order delivery for multi-path

1911
01:20:44,960 --> 01:20:46,000
communication

1912
01:20:46,000 --> 01:20:48,239
and this draft scheduling is out of

1913
01:20:48,239 --> 01:20:50,000
scope so scheduling

1914
01:20:50,000 --> 01:20:52,000
uh maybe also provide some some

1915
01:20:52,000 --> 01:20:53,040
measurements to

1916
01:20:53,040 --> 01:20:55,760
to out to overcome out of order delivery

1917
01:20:55,760 --> 01:20:56,960
on receiver side

1918
01:20:56,960 --> 01:21:01,120
but we see is this rather as part of the

1919
01:21:01,120 --> 01:21:05,360
scheduler draft available at iccrg

1920
01:21:05,360 --> 01:21:09,199
so we discuss for example resequencing

1921
01:21:09,199 --> 01:21:11,920
mechanism with which we want to keep the

1922
01:21:11,920 --> 01:21:13,280
generated sequence

1923
01:21:13,280 --> 01:21:16,800
of data at receiver side and

1924
01:21:16,800 --> 01:21:19,199
there we discussed multiple

1925
01:21:19,199 --> 01:21:21,920
functionalities or multiple logics

1926
01:21:21,920 --> 01:21:24,080
so the first is the passive one so we

1927
01:21:24,080 --> 01:21:26,800
trust forward packets as arrived

1928
01:21:26,800 --> 01:21:30,960
for sure that will not reorder at all

1929
01:21:30,960 --> 01:21:33,920
then we have the exact mechanism that is

1930
01:21:33,920 --> 01:21:36,239
similar to tcp

1931
01:21:36,239 --> 01:21:39,440
and provides strict reliability another

1932
01:21:39,440 --> 01:21:42,080
mechanism is the static expiration that

1933
01:21:42,080 --> 01:21:44,080
means we wait a certain time

1934
01:21:44,080 --> 01:21:47,440
for missing packets until we assume

1935
01:21:47,440 --> 01:21:50,000
a packet loss and any packet which

1936
01:21:50,000 --> 01:21:50,560
arrive

1937
01:21:50,560 --> 01:21:53,679
in time will be reordered adaptive

1938
01:21:53,679 --> 01:21:55,600
expiration is similar to the static

1939
01:21:55,600 --> 01:21:57,040
expiration but

1940
01:21:57,040 --> 01:22:00,080
we do not have a fixed time threshold so

1941
01:22:00,080 --> 01:22:00,480
we

1942
01:22:00,480 --> 01:22:04,000
dynamically adjust the time uh on how we

1943
01:22:04,000 --> 01:22:06,159
how long we wait for a missing packet

1944
01:22:06,159 --> 01:22:09,440
depending on the rtt for example

1945
01:22:09,440 --> 01:22:13,600
or the latency on the part

1946
01:22:13,600 --> 01:22:16,159
then we have delay equalization strictly

1947
01:22:16,159 --> 01:22:17,120
spoken

1948
01:22:17,120 --> 01:22:19,280
that is is not a reordering mechanism

1949
01:22:19,280 --> 01:22:21,360
that just delay

1950
01:22:21,360 --> 01:22:24,000
the faster packets to match the latency

1951
01:22:24,000 --> 01:22:24,639
of the

1952
01:22:24,639 --> 01:22:28,400
slower part and last but not least we

1953
01:22:28,400 --> 01:22:31,040
discuss fast packet loss detection that

1954
01:22:31,040 --> 01:22:33,040
is probably something which can be

1955
01:22:33,040 --> 01:22:37,199
combined with the other logics

1956
01:22:37,199 --> 01:22:39,120
and that level the part and connection

1957
01:22:39,120 --> 01:22:40,320
sequencing

1958
01:22:40,320 --> 01:22:43,520
to to have a very early idea um

1959
01:22:43,520 --> 01:22:47,520
about if a packet is lost or delayed

1960
01:22:47,520 --> 01:22:52,719
next slide please

1961
01:22:52,719 --> 01:22:56,239
then we have two other areas identified

1962
01:22:56,239 --> 01:22:57,440
which can help to

1963
01:22:57,440 --> 01:23:00,480
overcome out-of-order delivery

1964
01:23:00,480 --> 01:23:03,679
that is recovery and re-transmission

1965
01:23:03,679 --> 01:23:06,800
in the recovery area we see that we can

1966
01:23:06,800 --> 01:23:07,600
overcome

1967
01:23:07,600 --> 01:23:11,440
packet loss when we spend redundancy and

1968
01:23:11,440 --> 01:23:12,239
in that

1969
01:23:12,239 --> 01:23:15,120
area we see forward error correction but

1970
01:23:15,120 --> 01:23:17,440
also network coding

1971
01:23:17,440 --> 01:23:19,760
and when it comes to re-transmission so

1972
01:23:19,760 --> 01:23:21,280
overcome packet loss by

1973
01:23:21,280 --> 01:23:23,840
by re-transmission we also see you see

1974
01:23:23,840 --> 01:23:25,199
three different

1975
01:23:25,199 --> 01:23:26,880
mechanisms which can help here on the

1976
01:23:26,880 --> 01:23:29,040
one hand we have the signaling

1977
01:23:29,040 --> 01:23:31,440
which is for example used in in tcp or

1978
01:23:31,440 --> 01:23:32,800
dccp

1979
01:23:32,800 --> 01:23:35,760
to signal outstanding packets to to the

1980
01:23:35,760 --> 01:23:37,440
sender

1981
01:23:37,440 --> 01:23:39,600
uh anticipated means we predict a

1982
01:23:39,600 --> 01:23:40,960
beneficial

1983
01:23:40,960 --> 01:23:43,040
uh early retransmission for for the

1984
01:23:43,040 --> 01:23:44,000
reordering

1985
01:23:44,000 --> 01:23:46,639
reordering purpose and last but not

1986
01:23:46,639 --> 01:23:48,560
least we have the flow selection

1987
01:23:48,560 --> 01:23:51,760
so the abil ability to retransmit

1988
01:23:51,760 --> 01:23:53,679
packages on a path different to the

1989
01:23:53,679 --> 01:23:54,800
original

1990
01:23:54,800 --> 01:23:57,920
one if this is if this supports the

1991
01:23:57,920 --> 01:23:59,440
reorder

1992
01:23:59,440 --> 01:24:01,360
as i said combinations of mechanisms are

1993
01:24:01,360 --> 01:24:03,679
in principle possible and most

1994
01:24:03,679 --> 01:24:06,800
probably useful

1995
01:24:06,800 --> 01:24:16,560
next slide please yeah

1996
01:24:16,560 --> 01:24:18,639
first of all i want to invite you to to

1997
01:24:18,639 --> 01:24:20,719
contribute to this draft

1998
01:24:20,719 --> 01:24:24,080
uh where i think that this is a

1999
01:24:24,080 --> 01:24:26,400
applicable to many of the multi-pass

2000
01:24:26,400 --> 01:24:27,280
protocols

2001
01:24:27,280 --> 01:24:31,040
um discussed or standardized at iitf

2002
01:24:31,040 --> 01:24:33,360
so that the draft itself is still under

2003
01:24:33,360 --> 01:24:34,400
development

2004
01:24:34,400 --> 01:24:36,880
and some content is not finalized

2005
01:24:36,880 --> 01:24:37,840
however

2006
01:24:37,840 --> 01:24:41,040
you have got an idea today on

2007
01:24:41,040 --> 01:24:44,320
which mechanisms yeah

2008
01:24:44,320 --> 01:24:47,440
about which mechanisms we think and my

2009
01:24:47,440 --> 01:24:49,440
question today is is there any mechanism

2010
01:24:49,440 --> 01:24:50,639
which is missing

2011
01:24:50,639 --> 01:24:54,000
so far and my second question is how to

2012
01:24:54,000 --> 01:24:56,320
proceed with this trough do you see

2013
01:24:56,320 --> 01:25:00,159
any value in that

2014
01:25:00,320 --> 01:25:03,520
yeah and with that i'm

2015
01:25:03,520 --> 01:25:05,679
ready for today and now i'm would like

2016
01:25:05,679 --> 01:25:09,120
to see some feedback

2017
01:25:10,080 --> 01:25:13,679
thank you marcus

2018
01:25:13,679 --> 01:25:16,639
i don't see anybody at the queue and i

2019
01:25:16,639 --> 01:25:18,000
don't want to spend a lot of time

2020
01:25:18,000 --> 01:25:19,360
waiting but i'll give it just

2021
01:25:19,360 --> 01:25:21,199
30 seconds if somebody wants to come up

2022
01:25:21,199 --> 01:25:24,159
to the mic and offer feedback

2023
01:25:24,159 --> 01:25:26,320
in the meantime i'll i'll offer marcus

2024
01:25:26,320 --> 01:25:27,440
that your question about

2025
01:25:27,440 --> 01:25:28,880
uh how do you want to proceed with this

2026
01:25:28,880 --> 01:25:30,320
draft i think the one thing i would

2027
01:25:30,320 --> 01:25:31,040
recommend is

2028
01:25:31,040 --> 01:25:33,360
is is engaging the group on the mailing

2029
01:25:33,360 --> 01:25:34,560
list

2030
01:25:34,560 --> 01:25:36,960
and and seeing if we can generate

2031
01:25:36,960 --> 01:25:39,360
discussion that's always a good way to

2032
01:25:39,360 --> 01:25:43,199
to to to get people interested um

2033
01:25:43,199 --> 01:25:54,239
andre is in the queue europe andre

2034
01:25:54,239 --> 01:25:57,678
andre we cannot hear you

2035
01:26:03,760 --> 01:26:06,800
i'm not sure what's going on there

2036
01:26:06,800 --> 01:26:09,840
but uh

2037
01:26:10,800 --> 01:26:14,159
i myself can you hear me now

2038
01:26:14,159 --> 01:26:17,760
yes yes go on okay sorry um

2039
01:26:17,760 --> 01:26:19,679
andre bondi software performance and

2040
01:26:19,679 --> 01:26:22,719
scalability consulting in new jersey

2041
01:26:22,719 --> 01:26:25,760
my question for marcus is how do you go

2042
01:26:25,760 --> 01:26:27,920
about setting the adaptive expiration

2043
01:26:27,920 --> 01:26:29,920
time what are the variables that go into

2044
01:26:29,920 --> 01:26:30,960
that

2045
01:26:30,960 --> 01:26:32,159
is this something that you're going to

2046
01:26:32,159 --> 01:26:34,000
do at connection setups that you can

2047
01:26:34,000 --> 01:26:36,080
establish what a floor on the latency

2048
01:26:36,080 --> 01:26:39,840
would be and how do you go about

2049
01:26:39,840 --> 01:26:41,520
increasing the expiration time because

2050
01:26:41,520 --> 01:26:43,280
if you make it too large

2051
01:26:43,280 --> 01:26:46,560
uh there's going to be an issue and

2052
01:26:46,560 --> 01:26:49,120
then there's a problem of degraded

2053
01:26:49,120 --> 01:26:50,719
throughput if you assume that you have a

2054
01:26:50,719 --> 01:26:54,480
longer latency on the slower pipe

2055
01:26:54,480 --> 01:26:56,480
yeah very good question thank you for

2056
01:26:56,480 --> 01:26:59,360
that um short answer here

2057
01:26:59,360 --> 01:27:01,120
we have some implementation in the

2058
01:27:01,120 --> 01:27:02,639
multi-pass gccp

2059
01:27:02,639 --> 01:27:05,080
available for that and there we

2060
01:27:05,080 --> 01:27:06,800
continuously

2061
01:27:06,800 --> 01:27:10,239
update the timer

2062
01:27:10,239 --> 01:27:13,280
with rtt information we get from the

2063
01:27:13,280 --> 01:27:13,840
sender

2064
01:27:13,840 --> 01:27:15,760
during transmission so we have some

2065
01:27:15,760 --> 01:27:17,679
signaling mechanism implemented for that

2066
01:27:17,679 --> 01:27:18,639
and

2067
01:27:18,639 --> 01:27:21,280
second point you are totally right we

2068
01:27:21,280 --> 01:27:22,400
have to set some

2069
01:27:22,400 --> 01:27:25,920
boundaries so it doesn't make sense to

2070
01:27:25,920 --> 01:27:29,920
let the reordering queue

2071
01:27:29,920 --> 01:27:33,360
grow to an infinite value that would

2072
01:27:33,360 --> 01:27:36,639
slow down the total throughput so

2073
01:27:36,639 --> 01:27:38,800
one measure could be here to set a

2074
01:27:38,800 --> 01:27:40,000
manual

2075
01:27:40,000 --> 01:27:42,800
limit yeah on the signaling is that

2076
01:27:42,800 --> 01:27:44,719
going to be in band or out of band that

2077
01:27:44,719 --> 01:27:45,679
is to say

2078
01:27:45,679 --> 01:27:47,280
along the connection the payload

2079
01:27:47,280 --> 01:27:49,440
connection on a separate connection

2080
01:27:49,440 --> 01:27:52,719
yeah yeah that is exactly uh

2081
01:27:52,719 --> 01:27:55,600
why i think we need this draft and that

2082
01:27:55,600 --> 01:27:57,199
is a question which should

2083
01:27:57,199 --> 01:27:59,280
should be mentioned there and then it's

2084
01:27:59,280 --> 01:28:02,080
on on the particular protocol to think

2085
01:28:02,080 --> 01:28:02,719
about

2086
01:28:02,719 --> 01:28:05,600
should this be something which is in or

2087
01:28:05,600 --> 01:28:07,199
out of bed

2088
01:28:07,199 --> 01:28:09,840
so we we would not give a final or i

2089
01:28:09,840 --> 01:28:11,440
don't see that we have to give a final

2090
01:28:11,440 --> 01:28:13,679
recommendation to a particular protocol

2091
01:28:13,679 --> 01:28:16,480
that is we just give some guidelines and

2092
01:28:16,480 --> 01:28:18,639
and such questions you have put now

2093
01:28:18,639 --> 01:28:21,760
um should this be something protocol

2094
01:28:21,760 --> 01:28:23,360
specific or out of band or

2095
01:28:23,360 --> 01:28:26,639
whatever that then has to be decided um

2096
01:28:26,639 --> 01:28:31,520
within the particular uh working groups

2097
01:28:31,520 --> 01:28:33,600
okay it may be service specific just the

2098
01:28:33,600 --> 01:28:35,520
way one uses out of band signaling for

2099
01:28:35,520 --> 01:28:40,000
circuit switch telecom ss7 for instance

2100
01:28:40,000 --> 01:28:43,760
oh that is that is now very specific

2101
01:28:43,760 --> 01:28:50,320
um ss7 from my knowledge uses stdp right

2102
01:28:50,320 --> 01:28:52,159
yeah it just goes along on a separate

2103
01:28:52,159 --> 01:28:53,600
trunk actually

2104
01:28:53,600 --> 01:28:57,199
this is old stuff yeah yeah okay

2105
01:28:57,199 --> 01:28:59,920
and then really old stuff like 30 20 30

2106
01:28:59,920 --> 01:29:00,880
years ago

2107
01:29:00,880 --> 01:29:03,360
yeah i'm gonna jump in here marcus let's

2108
01:29:03,360 --> 01:29:04,719
let's take that question

2109
01:29:04,719 --> 01:29:07,280
on to the chat yeah uh okay we do need

2110
01:29:07,280 --> 01:29:08,880
to warn but thank you for your questions

2111
01:29:08,880 --> 01:29:10,560
andre very much appreciate it

2112
01:29:10,560 --> 01:29:12,719
sure i'm going to the next presentation

2113
01:29:12,719 --> 01:29:14,320
and thank you again marcus and anna for

2114
01:29:14,320 --> 01:29:15,760
your presentations i think

2115
01:29:15,760 --> 01:29:18,480
we should continue the discussion on uh

2116
01:29:18,480 --> 01:29:18,960
on

2117
01:29:18,960 --> 01:29:22,639
on the list uh coming up next bbr

2118
01:29:22,639 --> 01:29:26,159
neil take it away

2119
01:29:26,400 --> 01:29:30,239
uh let's see can you guys hear my audio

2120
01:29:31,440 --> 01:29:33,678
um

2121
01:29:34,880 --> 01:29:37,840
okay great um all right uh so thanks

2122
01:29:37,840 --> 01:29:38,560
jana

2123
01:29:38,560 --> 01:29:40,639
yeah we just wanted to give a uh quick

2124
01:29:40,639 --> 01:29:41,760
update on

2125
01:29:41,760 --> 01:29:44,480
uh the bbr related work that's going on

2126
01:29:44,480 --> 01:29:46,239
uh in our team at google

2127
01:29:46,239 --> 01:29:48,960
uh and this is joint work uh with my

2128
01:29:48,960 --> 01:29:50,960
colleagues uh listed here

2129
01:29:50,960 --> 01:29:54,639
um next slide please

2130
01:29:57,440 --> 01:30:00,560
so i think this will be a a shorter talk

2131
01:30:00,560 --> 01:30:02,159
than many of our recent talks

2132
01:30:02,159 --> 01:30:04,320
at the itf just wanted to give a quick

2133
01:30:04,320 --> 01:30:05,520
update on

2134
01:30:05,520 --> 01:30:08,719
the deployment status at google where

2135
01:30:08,719 --> 01:30:09,360
we're

2136
01:30:09,360 --> 01:30:12,239
nearing completion for internal tcp

2137
01:30:12,239 --> 01:30:13,040
traffic

2138
01:30:13,040 --> 01:30:16,080
uh give a quick update on the alpha

2139
01:30:16,080 --> 01:30:18,960
open source release on github talk about

2140
01:30:18,960 --> 01:30:19,600
some plans

2141
01:30:19,600 --> 01:30:22,000
with respect to internet drafts and then

2142
01:30:22,000 --> 01:30:22,960
also talk about

2143
01:30:22,960 --> 01:30:24,880
our continued work on uh what we're

2144
01:30:24,880 --> 01:30:26,719
calling pbr netswift

2145
01:30:26,719 --> 01:30:29,199
uh and as always you know we're just

2146
01:30:29,199 --> 01:30:30,159
offering this in

2147
01:30:30,159 --> 01:30:32,960
in spirit of offering our experience uh

2148
01:30:32,960 --> 01:30:33,520
with

2149
01:30:33,520 --> 01:30:35,679
these kinds of experiments in deployment

2150
01:30:35,679 --> 01:30:37,520
and of course we are always um

2151
01:30:37,520 --> 01:30:40,639
looking for feedback or test results

2152
01:30:40,639 --> 01:30:43,520
issues people run into any ideas or

2153
01:30:43,520 --> 01:30:45,120
patches folks want to contribute would

2154
01:30:45,120 --> 01:30:46,800
be would be great

2155
01:30:46,800 --> 01:30:49,520
next libraries

2156
01:30:50,560 --> 01:30:53,520
so uh in terms of the um ongoing

2157
01:30:53,520 --> 01:30:54,560
deployment of

2158
01:30:54,560 --> 01:30:57,679
the bbr v2 algorithm within uh

2159
01:30:57,679 --> 01:31:01,440
google for google internal traffic

2160
01:31:01,440 --> 01:31:03,760
this is coming pretty far along right

2161
01:31:03,760 --> 01:31:05,040
now we're in the process

2162
01:31:05,040 --> 01:31:08,239
of deploying vbr v2

2163
01:31:08,239 --> 01:31:11,199
as the default tcp congestion control

2164
01:31:11,199 --> 01:31:11,679
for

2165
01:31:11,679 --> 01:31:14,960
internal google traffic and

2166
01:31:14,960 --> 01:31:16,960
uh we've gotten to a point recently

2167
01:31:16,960 --> 01:31:19,520
where uh it's used as the congestion

2168
01:31:19,520 --> 01:31:21,120
control algorithm for over

2169
01:31:21,120 --> 01:31:24,560
98 of the internal tcp traffic

2170
01:31:24,560 --> 01:31:26,880
uh as measured by traffic raid or

2171
01:31:26,880 --> 01:31:28,400
traffic volume

2172
01:31:28,400 --> 01:31:31,120
um just to be clear here so for this

2173
01:31:31,120 --> 01:31:32,400
internal traffic

2174
01:31:32,400 --> 01:31:34,800
uh we're using a number of different

2175
01:31:34,800 --> 01:31:36,000
congestion signals

2176
01:31:36,000 --> 01:31:39,600
uh you know we're using the core uh bbr

2177
01:31:39,600 --> 01:31:41,840
uh approach of modeling the bandwidth

2178
01:31:41,840 --> 01:31:44,159
and running around trip time but we're

2179
01:31:44,159 --> 01:31:45,280
also using

2180
01:31:45,280 --> 01:31:49,120
ecn and loss as signals as well

2181
01:31:49,120 --> 01:31:52,400
and as we deploy this we're seeing some

2182
01:31:52,400 --> 01:31:55,679
latency reductions at the tail for rpc

2183
01:31:55,679 --> 01:31:58,239
traffic and this is as compared to the

2184
01:31:58,239 --> 01:31:58,880
previous

2185
01:31:58,880 --> 01:32:01,760
uh congestion control which for internal

2186
01:32:01,760 --> 01:32:02,320
traffic

2187
01:32:02,320 --> 01:32:05,199
was um based on a shallow threshold uh

2188
01:32:05,199 --> 01:32:06,159
ecn

2189
01:32:06,159 --> 01:32:09,199
algorithm um and then we

2190
01:32:09,199 --> 01:32:12,960
also have ongoing work for

2191
01:32:12,960 --> 01:32:15,520
looking at bbr v2 for google external

2192
01:32:15,520 --> 01:32:16,400
traffic so

2193
01:32:16,400 --> 01:32:19,120
basically uh youtube and google.com

2194
01:32:19,120 --> 01:32:20,960
traffic over the public internet to end

2195
01:32:20,960 --> 01:32:22,320
users

2196
01:32:22,320 --> 01:32:25,360
and that work continues we're seeing

2197
01:32:25,360 --> 01:32:27,520
some reduced uh camera delays

2198
01:32:27,520 --> 01:32:30,880
um and reduced packet loss versus

2199
01:32:30,880 --> 01:32:34,320
vbr v1 um but we're still not

2200
01:32:34,320 --> 01:32:36,320
quite where we'd like to be and so we're

2201
01:32:36,320 --> 01:32:38,320
continuing to work on that

2202
01:32:38,320 --> 01:32:40,159
uh and of course we're continuing to

2203
01:32:40,159 --> 01:32:41,679
iterate in

2204
01:32:41,679 --> 01:32:44,159
internal lab tests and experiments as

2205
01:32:44,159 --> 01:32:44,719
well

2206
01:32:44,719 --> 01:32:47,679
uh next slide please

2207
01:32:51,840 --> 01:32:53,440
so in terms of the status of the

2208
01:32:53,440 --> 01:32:55,120
algorithm and code

2209
01:32:55,120 --> 01:32:57,760
as we've mentioned uh at the ietf a few

2210
01:32:57,760 --> 01:32:58,639
times

2211
01:32:58,639 --> 01:33:02,639
before we've got a release of the

2212
01:33:02,639 --> 01:33:06,159
both the quick and the linux tcp code

2213
01:33:06,159 --> 01:33:09,280
that's available the linux tcp code is

2214
01:33:09,280 --> 01:33:10,080
on github

2215
01:33:10,080 --> 01:33:13,440
and we've made a couple of recent um

2216
01:33:13,440 --> 01:33:16,159
minor updates to that code rebased it

2217
01:33:16,159 --> 01:33:18,719
onto a more recent version of linux

2218
01:33:18,719 --> 01:33:20,880
for those who are interested and posted

2219
01:33:20,880 --> 01:33:23,360
a few uh minor bug fixes

2220
01:33:23,360 --> 01:33:26,560
um and we think the the pbrv2

2221
01:33:26,560 --> 01:33:28,400
uh alpha releases is ready for

2222
01:33:28,400 --> 01:33:30,880
experiments and i think there have been

2223
01:33:30,880 --> 01:33:33,520
uh reports you know over the past uh

2224
01:33:33,520 --> 01:33:34,800
year or two from

2225
01:33:34,800 --> 01:33:36,960
other folks in industry and academia who

2226
01:33:36,960 --> 01:33:38,960
have taken a look at it both in

2227
01:33:38,960 --> 01:33:43,040
production settings and in lab settings

2228
01:33:43,040 --> 01:33:44,480
and there are just some links in the

2229
01:33:44,480 --> 01:33:46,480
slides to previous talks where we've

2230
01:33:46,480 --> 01:33:48,560
given more details about the algorithm

2231
01:33:48,560 --> 01:33:51,520
and the code and how it behaves

2232
01:33:51,520 --> 01:33:54,239
next slide please

2233
01:33:55,840 --> 01:33:58,000
so we um there have been a number of

2234
01:33:58,000 --> 01:33:59,840
requests for

2235
01:33:59,840 --> 01:34:03,199
updating the apr internet drafts

2236
01:34:03,199 --> 01:34:05,199
they the ones that are out there

2237
01:34:05,199 --> 01:34:06,400
currently uh

2238
01:34:06,400 --> 01:34:08,239
document the version one of the

2239
01:34:08,239 --> 01:34:09,679
algorithm um

2240
01:34:09,679 --> 01:34:12,800
and we are now uh planning to go ahead

2241
01:34:12,800 --> 01:34:13,440
and

2242
01:34:13,440 --> 01:34:16,840
uh update those to reflect uh bbr

2243
01:34:16,840 --> 01:34:20,159
v2 um and our goal is to get those out

2244
01:34:20,159 --> 01:34:20,560
there

2245
01:34:20,560 --> 01:34:23,679
by the july ietf so we can uh present

2246
01:34:23,679 --> 01:34:25,199
those and discuss those

2247
01:34:25,199 --> 01:34:28,320
um and you know the idea i think is to

2248
01:34:28,320 --> 01:34:30,800
uh just replace the drafts that are up

2249
01:34:30,800 --> 01:34:32,080
there with uh

2250
01:34:32,080 --> 01:34:34,560
drafts that are targeting bbrv2 hoping

2251
01:34:34,560 --> 01:34:36,560
that that will make it more clear that

2252
01:34:36,560 --> 01:34:39,360
um these are sort of replacing the the

2253
01:34:39,360 --> 01:34:40,719
earlier drafts

2254
01:34:40,719 --> 01:34:47,840
um uh next slide please

2255
01:34:49,360 --> 01:34:52,800
so we did want to mention uh briefly

2256
01:34:52,800 --> 01:34:54,000
that we are also

2257
01:34:54,000 --> 01:34:56,239
continuing uh another thread of research

2258
01:34:56,239 --> 01:34:58,400
work that we discussed briefly

2259
01:34:58,400 --> 01:35:01,600
at the november ietf on a

2260
01:35:01,600 --> 01:35:03,880
an approach we're calling for now

2261
01:35:03,880 --> 01:35:05,600
bbr.swift

2262
01:35:05,600 --> 01:35:07,520
which basically leverages approaches

2263
01:35:07,520 --> 01:35:09,280
from the swift congestion control

2264
01:35:09,280 --> 01:35:10,159
algorithm

2265
01:35:10,159 --> 01:35:13,760
uh which was presented at sitcom 2020

2266
01:35:13,760 --> 01:35:16,480
where the approach basically uses uh the

2267
01:35:16,480 --> 01:35:17,840
network round trip time

2268
01:35:17,840 --> 01:35:20,639
as the primary congestion signal and

2269
01:35:20,639 --> 01:35:22,639
there the the main motivation is that

2270
01:35:22,639 --> 01:35:24,800
it gives you uh for environments where

2271
01:35:24,800 --> 01:35:27,119
it's available it can give you a richer

2272
01:35:27,119 --> 01:35:29,040
signal with more information about the

2273
01:35:29,040 --> 01:35:31,840
current degree of cueing along the path

2274
01:35:31,840 --> 01:35:35,040
which has sort of two advantages

2275
01:35:35,040 --> 01:35:37,199
one is that it allows faster reaction if

2276
01:35:37,199 --> 01:35:39,679
there really are long queues right now

2277
01:35:39,679 --> 01:35:41,679
and then the other is that it allows you

2278
01:35:41,679 --> 01:35:42,960
to help

2279
01:35:42,960 --> 01:35:45,760
avoid overreaction when the cues may be

2280
01:35:45,760 --> 01:35:47,040
persistent but might be

2281
01:35:47,040 --> 01:35:50,239
short for example and you know there's

2282
01:35:50,239 --> 01:35:51,760
ongoing work for that

2283
01:35:51,760 --> 01:35:54,880
preparing for production testing doing

2284
01:35:54,880 --> 01:35:55,280
some

2285
01:35:55,280 --> 01:35:57,600
lab testing right now is the main focus

2286
01:35:57,600 --> 01:35:59,840
um as we mentioned uh tcpm

2287
01:35:59,840 --> 01:36:02,960
part of this uh research and development

2288
01:36:02,960 --> 01:36:03,679
effort

2289
01:36:03,679 --> 01:36:06,960
includes work to provide

2290
01:36:06,960 --> 01:36:09,520
time stamp information in the tcp

2291
01:36:09,520 --> 01:36:10,320
options

2292
01:36:10,320 --> 01:36:13,440
to provide the sort of detailed fine

2293
01:36:13,440 --> 01:36:14,000
grain

2294
01:36:14,000 --> 01:36:16,560
and more accurate round trip time

2295
01:36:16,560 --> 01:36:17,920
measurements that you need for

2296
01:36:17,920 --> 01:36:20,159
a scheme like this so there's a link to

2297
01:36:20,159 --> 01:36:21,040
the

2298
01:36:21,040 --> 01:36:23,840
extensible time stamp draft that we put

2299
01:36:23,840 --> 01:36:25,360
out last fall

2300
01:36:25,360 --> 01:36:28,239
and ultimately the goal is to allow this

2301
01:36:28,239 --> 01:36:30,000
as an optional

2302
01:36:30,000 --> 01:36:34,000
approach for contexts where

2303
01:36:34,000 --> 01:36:36,480
the target network round-trip time is

2304
01:36:36,480 --> 01:36:37,440
known which

2305
01:36:37,440 --> 01:36:39,440
might be the case for example in data

2306
01:36:39,440 --> 01:36:40,960
centers

2307
01:36:40,960 --> 01:36:44,239
and also where cases for cases where you

2308
01:36:44,239 --> 01:36:45,920
know that the other traffic sharing your

2309
01:36:45,920 --> 01:36:46,719
bottlenecks

2310
01:36:46,719 --> 01:36:50,719
is using an algorithm of this same type

2311
01:36:50,719 --> 01:36:52,320
and this might be the case for example

2312
01:36:52,320 --> 01:36:54,080
if you have separate uh

2313
01:36:54,080 --> 01:36:55,920
quality of service cues and you can

2314
01:36:55,920 --> 01:36:57,360
isolate this traffic

2315
01:36:57,360 --> 01:37:00,080
to its own queue to avoid interaction

2316
01:37:00,080 --> 01:37:02,239
with other

2317
01:37:02,239 --> 01:37:04,239
classes of algorithm and we do

2318
01:37:04,239 --> 01:37:05,840
ultimately want this to be usable for

2319
01:37:05,840 --> 01:37:08,000
physical machines and virtual machines

2320
01:37:08,000 --> 01:37:10,719
which will take some work to plumb the

2321
01:37:10,719 --> 01:37:12,400
time stamp information

2322
01:37:12,400 --> 01:37:14,800
up and down the stack to make these

2323
01:37:14,800 --> 01:37:15,840
timestamps available

2324
01:37:15,840 --> 01:37:18,000
but that is kind of the long-term goal

2325
01:37:18,000 --> 01:37:18,960
uh next

2326
01:37:18,960 --> 01:37:21,840
slide please

2327
01:37:22,719 --> 01:37:25,760
so um just in conclusion wrapping up uh

2328
01:37:25,760 --> 01:37:28,880
you know we're uh continuing to work on

2329
01:37:28,880 --> 01:37:33,360
both bbr v2 and this newer

2330
01:37:33,360 --> 01:37:36,159
approach uh bbr swift uh and we're

2331
01:37:36,159 --> 01:37:38,080
finishing the rollout for internal tcp

2332
01:37:38,080 --> 01:37:39,840
traffic for bbr v2

2333
01:37:39,840 --> 01:37:43,040
uh continuing to iterate on external

2334
01:37:43,040 --> 01:37:44,639
traffic or public internet

2335
01:37:44,639 --> 01:37:48,080
performance and are hoping to

2336
01:37:48,080 --> 01:37:50,480
release an internet draft in july and as

2337
01:37:50,480 --> 01:37:51,440
always we uh

2338
01:37:51,440 --> 01:37:54,800
invite um feedback or test results uh

2339
01:37:54,800 --> 01:37:58,080
issues uh patches anything like that um

2340
01:37:58,080 --> 01:38:00,880
and uh next slide please and i think uh

2341
01:38:00,880 --> 01:38:02,000
that's

2342
01:38:02,000 --> 01:38:05,119
that wraps it up also if there are any

2343
01:38:05,119 --> 01:38:07,599
questions

2344
01:38:08,800 --> 01:38:13,600
thank you neil we have a few minutes or

2345
01:38:14,840 --> 01:38:16,800
questions

2346
01:38:16,800 --> 01:38:18,480
i am going to try a new experiment this

2347
01:38:18,480 --> 01:38:20,639
time which is that i will cut off

2348
01:38:20,639 --> 01:38:23,760
the q and a at uh at uh in

2349
01:38:23,760 --> 01:38:27,280
about in just under five minutes uh

2350
01:38:27,280 --> 01:38:29,679
doesn't matter who's in the line so i'm

2351
01:38:29,679 --> 01:38:31,119
not going to cut the mic line but i'm

2352
01:38:31,119 --> 01:38:32,400
going to cut off the q a

2353
01:38:32,400 --> 01:38:35,839
all right omer you are up

2354
01:38:39,280 --> 01:38:43,199
can you hear me yes

2355
01:38:43,199 --> 01:38:46,320
thanks dan uh can you share uh

2356
01:38:46,320 --> 01:38:49,679
do you have any data on what

2357
01:38:49,679 --> 01:38:53,119
kind of end devices bbr v2

2358
01:38:53,119 --> 01:38:56,320
is deployed on for the external users

2359
01:38:56,320 --> 01:39:00,159
are chromebooks uh androids uh

2360
01:39:00,159 --> 01:39:04,719
or something else and uh

2361
01:39:04,719 --> 01:39:08,960
but interests me the masters how bb2

2362
01:39:08,960 --> 01:39:13,520
interacts with the modern

2363
01:39:13,520 --> 01:39:17,199
modern cellular networks if you have

2364
01:39:17,199 --> 01:39:19,520
that if you if you have information to

2365
01:39:19,520 --> 01:39:21,920
share thank you

2366
01:39:21,920 --> 01:39:25,440
sure yeah so um to add some details

2367
01:39:25,440 --> 01:39:26,480
there so

2368
01:39:26,480 --> 01:39:30,159
where we're deploying bbr v2 um

2369
01:39:30,159 --> 01:39:33,679
in for the types of traffic you're

2370
01:39:33,679 --> 01:39:34,639
talking about

2371
01:39:34,639 --> 01:39:38,880
is for the google.com and youtube

2372
01:39:38,880 --> 01:39:40,960
servers that are sending traffic out

2373
01:39:40,960 --> 01:39:42,239
over the public internet

2374
01:39:42,239 --> 01:39:45,520
to end users and

2375
01:39:45,520 --> 01:39:48,639
um so since this is uh basically

2376
01:39:48,639 --> 01:39:52,480
um talking about all of the

2377
01:39:52,880 --> 01:39:55,280
users using youtube and google.com or

2378
01:39:55,280 --> 01:39:56,080
currently just

2379
01:39:56,080 --> 01:39:58,239
some a small percentage of them for

2380
01:39:58,239 --> 01:39:59,119
testing

2381
01:39:59,119 --> 01:40:00,400
uh this basically should be a

2382
01:40:00,400 --> 01:40:02,639
cross-section of of every kind of device

2383
01:40:02,639 --> 01:40:04,239
that connects to google

2384
01:40:04,239 --> 01:40:06,800
and youtube um and in our experience of

2385
01:40:06,800 --> 01:40:08,239
course that's a pretty diverse

2386
01:40:08,239 --> 01:40:11,040
set that largely these days i think

2387
01:40:11,040 --> 01:40:12,639
largely

2388
01:40:12,639 --> 01:40:16,000
the the dominant um bottleneck

2389
01:40:16,000 --> 01:40:16,960
technology is

2390
01:40:16,960 --> 01:40:21,040
wi-fi but obviously we do have a lot of

2391
01:40:21,040 --> 01:40:24,159
cellular users as well on the cellular

2392
01:40:24,159 --> 01:40:25,600
side i think it's still

2393
01:40:25,600 --> 01:40:28,880
mostly um 3g and 4g although we're

2394
01:40:28,880 --> 01:40:29,679
starting to see

2395
01:40:29,679 --> 01:40:32,080
you know obviously some 5g trickling in

2396
01:40:32,080 --> 01:40:33,920
now

2397
01:40:33,920 --> 01:40:37,760
and so the i don't have any numbers to

2398
01:40:37,760 --> 01:40:38,400
share

2399
01:40:38,400 --> 01:40:41,840
uh with you today um mainly because

2400
01:40:41,840 --> 01:40:44,159
this uh the public internet aspect is

2401
01:40:44,159 --> 01:40:46,239
still a work in progress

2402
01:40:46,239 --> 01:40:49,040
um but i can share that definitely we do

2403
01:40:49,040 --> 01:40:50,800
spend a lot of time

2404
01:40:50,800 --> 01:40:53,840
looking at the performance of both bbr

2405
01:40:53,840 --> 01:40:54,320
v1

2406
01:40:54,320 --> 01:40:58,000
and v2 for users that have cellular or

2407
01:40:58,000 --> 01:41:00,239
wi-fi connectivity since that is such a

2408
01:41:00,239 --> 01:41:03,199
dominant uh slice of traffic for for

2409
01:41:03,199 --> 01:41:04,880
google and youtube

2410
01:41:04,880 --> 01:41:08,800
excuse me does that answer the question

2411
01:41:08,800 --> 01:41:11,600
yes thanks

2412
01:41:17,600 --> 01:41:20,480
anna europe

2413
01:41:29,520 --> 01:41:32,480
anna europe i don't know if you're

2414
01:41:32,480 --> 01:41:36,080
unable to get yourself unmuted

2415
01:41:39,040 --> 01:41:42,159
and you're out of the queue

2416
01:41:42,960 --> 01:41:46,080
all right well i will uh thank neil then

2417
01:41:46,080 --> 01:41:48,000
for his presentation and i

2418
01:41:48,000 --> 01:41:50,320
will uh i won't speak for everybody here

2419
01:41:50,320 --> 01:41:52,000
but i speak for many people that

2420
01:41:52,000 --> 01:41:55,440
um very excited about the

2421
01:41:55,440 --> 01:41:57,280
the update to the draft looking forward

2422
01:41:57,280 --> 01:41:58,480
to reading

2423
01:41:58,480 --> 01:42:01,600
updates to the draft to the pbr

2424
01:42:01,600 --> 01:42:04,560
draft view

2425
01:42:05,280 --> 01:42:09,199
and that is now

2426
01:42:09,199 --> 01:42:15,839
oh give me a second

2427
01:42:26,840 --> 01:42:29,840
okay

2428
01:42:32,239 --> 01:42:36,000
all right gori get up

2429
01:42:37,760 --> 01:42:42,080
hi can you hear me

2430
01:42:42,080 --> 01:42:45,440
yes excellent okay

2431
01:42:45,440 --> 01:42:48,639
so um this short talk is going to look

2432
01:42:48,639 --> 01:42:52,159
at zero rtt parameters

2433
01:42:52,159 --> 01:42:55,679
for quick basically to exchange

2434
01:42:55,679 --> 01:42:57,840
transport parameters to let you do

2435
01:42:57,840 --> 01:42:59,360
something different in congestion

2436
01:42:59,360 --> 01:43:00,400
control

2437
01:43:00,400 --> 01:43:02,880
and there's a draft it's a revision

2438
01:43:02,880 --> 01:43:04,800
seven and it's with these people

2439
01:43:04,800 --> 01:43:07,840
on the side nicholas emile tom and me

2440
01:43:07,840 --> 01:43:11,840
next slide please

2441
01:43:12,880 --> 01:43:17,119
so this is a draft that tries to deal

2442
01:43:17,119 --> 01:43:20,080
with paths which are not typical

2443
01:43:20,080 --> 01:43:22,159
so we're talking about paths that have

2444
01:43:22,159 --> 01:43:23,440
something that's different

2445
01:43:23,440 --> 01:43:26,159
in them and maybe they're slightly

2446
01:43:26,159 --> 01:43:27,520
higher in delay

2447
01:43:27,520 --> 01:43:29,920
that could be many tens of milliseconds

2448
01:43:29,920 --> 01:43:31,920
it could be many seconds

2449
01:43:31,920 --> 01:43:34,080
they maybe have a very large bandwidth

2450
01:43:34,080 --> 01:43:36,239
delay product

2451
01:43:36,239 --> 01:43:40,080
they maybe have a sub ip layer

2452
01:43:40,080 --> 01:43:43,280
that is on demand and therefore

2453
01:43:43,280 --> 01:43:45,840
when you resume a connection you get a

2454
01:43:45,840 --> 01:43:47,840
different capacity or maybe

2455
01:43:47,840 --> 01:43:49,840
you usually get the same capacity but

2456
01:43:49,840 --> 01:43:52,800
sometimes you might get a different one

2457
01:43:52,800 --> 01:43:54,560
these paths are typically also have

2458
01:43:54,560 --> 01:43:56,800
other optimizations such as

2459
01:43:56,800 --> 01:43:59,280
asymmetry improvements and to get their

2460
01:43:59,280 --> 01:44:00,560
overall efficiency

2461
01:44:00,560 --> 01:44:03,760
at an acceptable level

2462
01:44:03,760 --> 01:44:06,159
if you have paths which are non-typical

2463
01:44:06,159 --> 01:44:08,560
then there's two options either you

2464
01:44:08,560 --> 01:44:10,400
dynamically learn that the paths are

2465
01:44:10,400 --> 01:44:12,560
non-typical or you have information

2466
01:44:12,560 --> 01:44:15,600
that lets you customize the

2467
01:44:15,600 --> 01:44:18,000
protocol stack to make it work and you

2468
01:44:18,000 --> 01:44:19,119
can do this

2469
01:44:19,119 --> 01:44:22,080
to mitigate the effects of delay the bdp

2470
01:44:22,080 --> 01:44:24,800
capacity asymmetry

2471
01:44:24,800 --> 01:44:27,920
our focus was primarily on satellite

2472
01:44:27,920 --> 01:44:28,800
paths

2473
01:44:28,800 --> 01:44:31,199
and that now covers a very wide range of

2474
01:44:31,199 --> 01:44:32,560
paths and we focus

2475
01:44:32,560 --> 01:44:35,920
just on geo in in the initial work here

2476
01:44:35,920 --> 01:44:38,080
and but you might see other paths that

2477
01:44:38,080 --> 01:44:40,320
have similar needs and i think

2478
01:44:40,320 --> 01:44:42,480
that's one of the important things i'd

2479
01:44:42,480 --> 01:44:43,520
like to kind of

2480
01:44:43,520 --> 01:44:45,920
bring up here is if other people are

2481
01:44:45,920 --> 01:44:47,600
seeing paths

2482
01:44:47,600 --> 01:44:50,159
that have other needs maybe slightly

2483
01:44:50,159 --> 01:44:51,280
different characteristics

2484
01:44:51,280 --> 01:44:53,119
we'd love to talk to you because we'd

2485
01:44:53,119 --> 01:44:55,040
love to make sure whatever we propose

2486
01:44:55,040 --> 01:44:55,600
here

2487
01:44:55,600 --> 01:44:57,679
actually works on across a variety of

2488
01:44:57,679 --> 01:44:59,920
different paths

2489
01:44:59,920 --> 01:45:03,840
next slide please

2490
01:45:05,600 --> 01:45:07,920
the context is to define some transport

2491
01:45:07,920 --> 01:45:10,800
parameters as extensions to quick

2492
01:45:10,800 --> 01:45:13,520
and these are shared during the zero rtt

2493
01:45:13,520 --> 01:45:14,880
phase

2494
01:45:14,880 --> 01:45:17,360
basically allowing resumption using

2495
01:45:17,360 --> 01:45:19,040
additional transport and connection

2496
01:45:19,040 --> 01:45:19,760
properties

2497
01:45:19,760 --> 01:45:22,480
discovered from a previous successful

2498
01:45:22,480 --> 01:45:25,040
connection

2499
01:45:25,199 --> 01:45:28,239
and what this is a lot like tcp control

2500
01:45:28,239 --> 01:45:29,360
block sharing

2501
01:45:29,360 --> 01:45:31,119
but it's also different because it's

2502
01:45:31,119 --> 01:45:33,440
designed for quick

2503
01:45:33,440 --> 01:45:35,119
we hope that the information that's

2504
01:45:35,119 --> 01:45:37,440
provided is useful for optimizing client

2505
01:45:37,440 --> 01:45:39,440
requests

2506
01:45:39,440 --> 01:45:41,920
there are cases where your web browser

2507
01:45:41,920 --> 01:45:43,920
automatically prioritizes different

2508
01:45:43,920 --> 01:45:45,920
pieces of information

2509
01:45:45,920 --> 01:45:48,159
maybe for the web client that's a

2510
01:45:48,159 --> 01:45:50,000
well-known bit of technology that many

2511
01:45:50,000 --> 01:45:51,600
vendors have already have in their

2512
01:45:51,600 --> 01:45:52,400
products

2513
01:45:52,400 --> 01:45:55,280
but for other applications such as dash

2514
01:45:55,280 --> 01:45:55,760
and

2515
01:45:55,760 --> 01:45:59,440
probably for a vpn applications etc

2516
01:45:59,440 --> 01:46:01,679
there will be ways to optimize the way

2517
01:46:01,679 --> 01:46:03,199
in which the network's used by the

2518
01:46:03,199 --> 01:46:05,280
clients

2519
01:46:05,280 --> 01:46:08,400
since this is iccrg the core

2520
01:46:08,400 --> 01:46:10,239
thing we're going to talk about is using

2521
01:46:10,239 --> 01:46:12,000
the information to make a jump in the

2522
01:46:12,000 --> 01:46:12,960
sea wind

2523
01:46:12,960 --> 01:46:15,119
the congestion window so that you

2524
01:46:15,119 --> 01:46:16,480
instead of starting a

2525
01:46:16,480 --> 01:46:19,280
session with a configured large initial

2526
01:46:19,280 --> 01:46:20,320
window

2527
01:46:20,320 --> 01:46:23,280
or with a normal small initial window

2528
01:46:23,280 --> 01:46:25,119
you choose something which is based on

2529
01:46:25,119 --> 01:46:26,239
previous history

2530
01:46:26,239 --> 01:46:28,880
and use that to initialize a safe sea

2531
01:46:28,880 --> 01:46:30,719
wind

2532
01:46:30,719 --> 01:46:33,119
and like any other method that's used

2533
01:46:33,119 --> 01:46:35,280
with tcp for instance

2534
01:46:35,280 --> 01:46:36,800
we'd like this information to be shared

2535
01:46:36,800 --> 01:46:40,239
across multiple connections

2536
01:46:40,239 --> 01:46:42,800
this is not a new proposal but it's a

2537
01:46:42,800 --> 01:46:44,239
proposal which we'd like to make

2538
01:46:44,239 --> 01:46:45,280
concrete for

2539
01:46:45,280 --> 01:46:49,599
quick next slide please

2540
01:46:51,360 --> 01:46:55,040
and why is this important if you have

2541
01:46:55,040 --> 01:46:56,159
the sort of

2542
01:46:56,159 --> 01:46:59,360
bdp and uh

2543
01:46:59,360 --> 01:47:01,360
delay that you might see in a satellite

2544
01:47:01,360 --> 01:47:02,800
geo environment

2545
01:47:02,800 --> 01:47:05,040
then it might take you many seconds to

2546
01:47:05,040 --> 01:47:06,239
download something

2547
01:47:06,239 --> 01:47:10,480
which you could actually send using tcp

2548
01:47:10,480 --> 01:47:14,320
and in maybe a small number of seconds

2549
01:47:14,320 --> 01:47:17,199
so quick is adding maybe two seconds of

2550
01:47:17,199 --> 01:47:17,679
extra

2551
01:47:17,679 --> 01:47:20,719
time in a typical configuration here

2552
01:47:20,719 --> 01:47:24,159
simply because there is no pep

2553
01:47:24,159 --> 01:47:27,199
involved optimizing the protocol so

2554
01:47:27,199 --> 01:47:29,440
maybe we can do much better

2555
01:47:29,440 --> 01:47:32,080
and this this slide shows two methods

2556
01:47:32,080 --> 01:47:34,400
which could be used to improve

2557
01:47:34,400 --> 01:47:36,239
performance that we've tried in a

2558
01:47:36,239 --> 01:47:38,320
spreadsheet analysis using a

2559
01:47:38,320 --> 01:47:40,480
a little tool we have to look at

2560
01:47:40,480 --> 01:47:42,719
different combinations of parameters

2561
01:47:42,719 --> 01:47:44,960
and we see the orange one is a jump to

2562
01:47:44,960 --> 01:47:46,080
25

2563
01:47:46,080 --> 01:47:48,800
of the last window and then two rounds

2564
01:47:48,800 --> 01:47:49,600
of rtt

2565
01:47:49,600 --> 01:47:52,800
to get to the full size window and green

2566
01:47:52,800 --> 01:47:54,960
a high jump method where we delay it by

2567
01:47:54,960 --> 01:47:56,400
one rtt

2568
01:47:56,400 --> 01:47:59,520
so we make the jump more conservatively

2569
01:47:59,520 --> 01:48:01,920
this range of options in the orange

2570
01:48:01,920 --> 01:48:03,119
green

2571
01:48:03,119 --> 01:48:05,280
area all the way across the glue area

2572
01:48:05,280 --> 01:48:07,600
where you can trade performance

2573
01:48:07,600 --> 01:48:09,840
against conservative congestion control

2574
01:48:09,840 --> 01:48:10,880
behavior

2575
01:48:10,880 --> 01:48:12,639
and that's the good reason for

2576
01:48:12,639 --> 01:48:14,800
presenting this in iccrg because

2577
01:48:14,800 --> 01:48:18,000
a lot of the issues are concerned with

2578
01:48:18,000 --> 01:48:20,639
how best to adapt but before you adapt

2579
01:48:20,639 --> 01:48:21,679
you need a method

2580
01:48:21,679 --> 01:48:23,440
of having the data about the previous

2581
01:48:23,440 --> 01:48:27,199
connection next slide

2582
01:48:31,520 --> 01:48:33,520
and the way in which to have this

2583
01:48:33,520 --> 01:48:34,560
information

2584
01:48:34,560 --> 01:48:37,440
we believe is to get the server to store

2585
01:48:37,440 --> 01:48:38,960
parameters

2586
01:48:38,960 --> 01:48:42,560
in a bdp extension which we then

2587
01:48:42,560 --> 01:48:43,679
communicate

2588
01:48:43,679 --> 01:48:47,119
from the server to the client the client

2589
01:48:47,119 --> 01:48:49,360
gets visibility of the information

2590
01:48:49,360 --> 01:48:53,520
it may also get a encrypted token

2591
01:48:53,520 --> 01:48:55,199
the encrypted talk can be returned back

2592
01:48:55,199 --> 01:48:57,040
to the server so the server could be

2593
01:48:57,040 --> 01:48:59,199
stateless if that's the design you want

2594
01:48:59,199 --> 01:49:02,239
and simply receive previous information

2595
01:49:02,239 --> 01:49:05,360
and about a floor that it had previously

2596
01:49:05,360 --> 01:49:09,119
struck with the same client

2597
01:49:09,280 --> 01:49:10,960
when you come to the second connection

2598
01:49:10,960 --> 01:49:12,719
to the same server

2599
01:49:12,719 --> 01:49:15,760
you can reinitialize the information and

2600
01:49:15,760 --> 01:49:17,920
of course there's a possibility that the

2601
01:49:17,920 --> 01:49:19,119
path to the end point

2602
01:49:19,119 --> 01:49:22,320
could have changed as a point there's a

2603
01:49:22,320 --> 01:49:23,520
path

2604
01:49:23,520 --> 01:49:24,800
change possibility in the amount of

2605
01:49:24,800 --> 01:49:27,440
capacity that you might have

2606
01:49:27,440 --> 01:49:29,760
of these two the most dangerous is the

2607
01:49:29,760 --> 01:49:32,000
change of the path

2608
01:49:32,000 --> 01:49:34,400
but um the method we propose will

2609
01:49:34,400 --> 01:49:36,000
validate the rtt

2610
01:49:36,000 --> 01:49:38,880
against the previous rtt and we're

2611
01:49:38,880 --> 01:49:39,840
suggesting that

2612
01:49:39,840 --> 01:49:42,960
we include some form of pacing when we

2613
01:49:42,960 --> 01:49:46,320
initially start a new um

2614
01:49:46,320 --> 01:49:49,280
higher congestion window and in this way

2615
01:49:49,280 --> 01:49:50,639
if there is a big rtt

2616
01:49:50,639 --> 01:49:53,599
change on the path then the damage

2617
01:49:53,599 --> 01:49:54,400
that's created

2618
01:49:54,400 --> 01:49:57,520
is very much limited and we believe

2619
01:49:57,520 --> 01:49:58,800
could be made safe

2620
01:49:58,800 --> 01:50:02,320
for wide-scale deployment and therefore

2621
01:50:02,320 --> 01:50:03,679
something that might be interesting to

2622
01:50:03,679 --> 01:50:10,159
standardize next slide please

2623
01:50:10,159 --> 01:50:13,280
this is the set of metadata we

2624
01:50:13,280 --> 01:50:17,199
expect to put in the bdp metadata

2625
01:50:17,199 --> 01:50:20,080
um three parameters bytes in flight

2626
01:50:20,080 --> 01:50:21,119
minimum rtt

2627
01:50:21,119 --> 01:50:24,080
encountered which is partly to configure

2628
01:50:24,080 --> 01:50:26,320
as a safeguard but also to configure a

2629
01:50:26,320 --> 01:50:28,239
pacing interval

2630
01:50:28,239 --> 01:50:30,480
and one of the issue one of the problems

2631
01:50:30,480 --> 01:50:31,360
is

2632
01:50:31,360 --> 01:50:34,239
is initializing the rtt of the pacer so

2633
01:50:34,239 --> 01:50:35,760
this information is quite helpful in

2634
01:50:35,760 --> 01:50:36,639
getting a

2635
01:50:36,639 --> 01:50:39,199
good response and the maximum packet

2636
01:50:39,199 --> 01:50:41,520
number encountered

2637
01:50:41,520 --> 01:50:43,040
so we say with these three pieces of

2638
01:50:43,040 --> 01:50:44,880
information can we now jump

2639
01:50:44,880 --> 01:50:53,119
safely next slide please

2640
01:50:53,119 --> 01:50:54,880
and next slide we don't need to talk

2641
01:50:54,880 --> 01:50:57,280
about this

2642
01:50:59,280 --> 01:51:02,800
um well we've approached this in

2643
01:51:02,800 --> 01:51:06,560
various ways one way uh was to perform

2644
01:51:06,560 --> 01:51:09,280
some implementation work in pico quick

2645
01:51:09,280 --> 01:51:12,480
and um there's a github that you can use

2646
01:51:12,480 --> 01:51:13,040
to

2647
01:51:13,040 --> 01:51:16,239
access this this is primarily focused on

2648
01:51:16,239 --> 01:51:19,119
the exchange of the cryptographic

2649
01:51:19,119 --> 01:51:21,360
information at the start of quick

2650
01:51:21,360 --> 01:51:23,040
of a quick connection so that you can

2651
01:51:23,040 --> 01:51:24,480
actually get the bandwidth

2652
01:51:24,480 --> 01:51:27,520
uh parameters exchanged and it focused

2653
01:51:27,520 --> 01:51:28,159
on a very

2654
01:51:28,159 --> 01:51:30,960
simple easy to implement change to the

2655
01:51:30,960 --> 01:51:32,159
congestion controller

2656
01:51:32,159 --> 01:51:34,400
we have a more advanced version of how

2657
01:51:34,400 --> 01:51:36,880
we expect that congestion control

2658
01:51:36,880 --> 01:51:39,760
um update to occur in the draft so

2659
01:51:39,760 --> 01:51:40,320
please leave

2660
01:51:40,320 --> 01:51:42,159
there to find more details about what we

2661
01:51:42,159 --> 01:51:43,520
actually suggest

2662
01:51:43,520 --> 01:51:46,480
but it's clear even from these three

2663
01:51:46,480 --> 01:51:47,760
simple results that

2664
01:51:47,760 --> 01:51:51,360
with out the option it took four point

2665
01:51:51,360 --> 01:51:52,320
three seconds

2666
01:51:52,320 --> 01:51:55,119
to exchange the two megabyte chunk of

2667
01:51:55,119 --> 01:51:58,560
data on average as the median value

2668
01:51:58,560 --> 01:52:03,840
with the zero rtt enhancement 3.4

2669
01:52:03,920 --> 01:52:07,040
and with the zero rtt vdp and 2.9

2670
01:52:07,040 --> 01:52:08,800
seconds so at least

2671
01:52:08,800 --> 01:52:11,920
saving what we would see um as people

2672
01:52:11,920 --> 01:52:14,400
evaluating satellite links a significant

2673
01:52:14,400 --> 01:52:17,119
proportion of the download time

2674
01:52:17,119 --> 01:52:20,480
and these are uh for

2675
01:52:20,480 --> 01:52:22,560
modern satellite length running at 50

2676
01:52:22,560 --> 01:52:25,599
megabits per second

2677
01:52:25,760 --> 01:52:31,280
next slide please

2678
01:52:31,280 --> 01:52:34,400
uh with also looking at uh how the

2679
01:52:34,400 --> 01:52:36,000
client might use this information

2680
01:52:36,000 --> 01:52:36,880
because

2681
01:52:36,880 --> 01:52:40,080
um the server can always optimize and

2682
01:52:40,080 --> 01:52:42,400
it be nicely optimized in a predictable

2683
01:52:42,400 --> 01:52:43,119
way so

2684
01:52:43,119 --> 01:52:45,280
the user didn't have to be concerned

2685
01:52:45,280 --> 01:52:47,520
about it but also there's a possibility

2686
01:52:47,520 --> 01:52:49,920
to optimize the client

2687
01:52:49,920 --> 01:52:53,599
if it knew about the

2688
01:52:53,599 --> 01:52:56,639
likely bdp aspects

2689
01:52:56,639 --> 01:52:59,360
of the path it's using and we did some

2690
01:52:59,360 --> 01:53:02,239
work in 2018 which is

2691
01:53:02,239 --> 01:53:05,119
published in the netsat days um

2692
01:53:05,119 --> 01:53:06,639
conference

2693
01:53:06,639 --> 01:53:08,639
it looked at dash and we showed that

2694
01:53:08,639 --> 01:53:09,679
using a

2695
01:53:09,679 --> 01:53:12,320
dash client we could take this

2696
01:53:12,320 --> 01:53:13,119
information

2697
01:53:13,119 --> 01:53:16,400
as one of the inputs to adapt the

2698
01:53:16,400 --> 01:53:18,400
results to produce a much more

2699
01:53:18,400 --> 01:53:20,239
predictable performance

2700
01:53:20,239 --> 01:53:24,159
in this case trying to avoid um

2701
01:53:24,159 --> 01:53:26,639
the strange behaviors that happen uh

2702
01:53:26,639 --> 01:53:28,400
when your predictor gets the

2703
01:53:28,400 --> 01:53:30,639
uh capacity wrong and therefore vastly

2704
01:53:30,639 --> 01:53:32,239
under underestimates the amount of

2705
01:53:32,239 --> 01:53:33,360
capacity you've got

2706
01:53:33,360 --> 01:53:37,199
because you've got a larger rtt and

2707
01:53:37,199 --> 01:53:41,119
there was talks in the irtf open about

2708
01:53:41,119 --> 01:53:42,480
the various ways in which

2709
01:53:42,480 --> 01:53:45,040
um dynamic adaptive streaming players

2710
01:53:45,040 --> 01:53:46,560
can play out and this is kind of like

2711
01:53:46,560 --> 01:53:48,880
one of the input parameters and a good

2712
01:53:48,880 --> 01:53:50,320
example of how

2713
01:53:50,320 --> 01:53:52,560
um knowing something at the client can

2714
01:53:52,560 --> 01:53:54,480
help you actually make better requests

2715
01:53:54,480 --> 01:53:56,480
at the application layer

2716
01:53:56,480 --> 01:53:59,040
next slide

2717
01:54:01,440 --> 01:54:05,840
and this shows a number of

2718
01:54:05,840 --> 01:54:08,719
different plots on the same graph i'm

2719
01:54:08,719 --> 01:54:10,480
first of all going to talk about the

2720
01:54:10,480 --> 01:54:11,599
blue plot this is

2721
01:54:11,599 --> 01:54:15,040
redo and the reno behavior is

2722
01:54:15,040 --> 01:54:17,440
that the congestion window opens in more

2723
01:54:17,440 --> 01:54:19,280
or less steps

2724
01:54:19,280 --> 01:54:21,440
stepping up each time it gets a round of

2725
01:54:21,440 --> 01:54:22,639
apps

2726
01:54:22,639 --> 01:54:25,840
and for a longer rtt

2727
01:54:25,840 --> 01:54:28,719
path this basically controls the amount

2728
01:54:28,719 --> 01:54:30,480
of capacity you can get

2729
01:54:30,480 --> 01:54:33,920
for small to medium sizes of exchange

2730
01:54:33,920 --> 01:54:35,920
this is totally the dominant factor

2731
01:54:35,920 --> 01:54:37,360
rather than the amount of bandwidth

2732
01:54:37,360 --> 01:54:38,639
available

2733
01:54:38,639 --> 01:54:41,040
when you use something like quake

2734
01:54:41,040 --> 01:54:41,840
because

2735
01:54:41,840 --> 01:54:44,800
if quit uses reno there is no protocol

2736
01:54:44,800 --> 01:54:47,440
enhancement along the path

2737
01:54:47,440 --> 01:54:51,040
so if we look at the jump

2738
01:54:51,040 --> 01:54:53,679
scenario we see here a different case

2739
01:54:53,679 --> 01:54:55,440
this is where the congestion controller

2740
01:54:55,440 --> 01:54:57,199
is initialized

2741
01:54:57,199 --> 01:55:01,040
with a previous rtt measurement

2742
01:55:01,040 --> 01:55:03,040
and we chose in this case to initialize

2743
01:55:03,040 --> 01:55:04,159
with 25

2744
01:55:04,159 --> 01:55:07,360
of the bandwidth that's 25 of the

2745
01:55:07,360 --> 01:55:10,000
previously used capacity

2746
01:55:10,000 --> 01:55:12,000
that means the following rtt there is a

2747
01:55:12,000 --> 01:55:13,760
step up

2748
01:55:13,760 --> 01:55:15,599
to use half the capacity and then

2749
01:55:15,599 --> 01:55:17,440
another step up etc

2750
01:55:17,440 --> 01:55:20,320
until after several rtts we've used the

2751
01:55:20,320 --> 01:55:22,080
whole capacity

2752
01:55:22,080 --> 01:55:23,760
now it would be possible to jump

2753
01:55:23,760 --> 01:55:26,639
immediately to use the full capacity

2754
01:55:26,639 --> 01:55:28,159
but if you're a congestion control

2755
01:55:28,159 --> 01:55:30,400
person that might frighten you

2756
01:55:30,400 --> 01:55:33,199
and because it would cause severe

2757
01:55:33,199 --> 01:55:35,119
congestion against any other flaws that

2758
01:55:35,119 --> 01:55:37,119
happened to be present

2759
01:55:37,119 --> 01:55:39,119
at the time when your new flow started

2760
01:55:39,119 --> 01:55:41,199
rather than when you previously measured

2761
01:55:41,199 --> 01:55:42,639
your available capacity

2762
01:55:42,639 --> 01:55:46,239
so we decided to initialize to around 25

2763
01:55:46,239 --> 01:55:48,880
and again and something we're happy to

2764
01:55:48,880 --> 01:55:50,080
experiment with

2765
01:55:50,080 --> 01:55:53,040
and there are ways of making this more

2766
01:55:53,040 --> 01:55:54,719
conservative we know this

2767
01:55:54,719 --> 01:56:00,960
next slide slight variation here i'm

2768
01:56:00,960 --> 01:56:01,920
going to talk about the

2769
01:56:01,920 --> 01:56:05,119
pink and gray curves the pink curve

2770
01:56:05,119 --> 01:56:07,840
is a method we call high jump which

2771
01:56:07,840 --> 01:56:08,800
delays

2772
01:56:08,800 --> 01:56:12,880
the arc the the increase and

2773
01:56:12,880 --> 01:56:14,480
we can talk about more of this in the

2774
01:56:14,480 --> 01:56:16,639
draft we also have high jump paste the

2775
01:56:16,639 --> 01:56:18,159
gray curve

2776
01:56:18,159 --> 01:56:19,840
what i'm trying to say here is that

2777
01:56:19,840 --> 01:56:21,280
there are a range of

2778
01:56:21,280 --> 01:56:23,360
congestion control decisions all of

2779
01:56:23,360 --> 01:56:25,760
which are

2780
01:56:25,760 --> 01:56:29,199
um safe to some extent

2781
01:56:29,199 --> 01:56:32,080
we would claim safe enough and a much

2782
01:56:32,080 --> 01:56:34,880
better performance than than reno

2783
01:56:34,880 --> 01:56:38,480
the hijab paste and paces the packets

2784
01:56:38,480 --> 01:56:42,480
out at the rate determined by

2785
01:56:42,480 --> 01:56:44,560
the previous capacity and we get this

2786
01:56:44,560 --> 01:56:46,400
more linear growth

2787
01:56:46,400 --> 01:56:49,280
in the use of the capacity and we could

2788
01:56:49,280 --> 01:56:50,880
talk more about that but i can't because

2789
01:56:50,880 --> 01:56:57,840
i need to move on so next slide

2790
01:56:58,400 --> 01:57:00,239
we talked about the client being able to

2791
01:57:00,239 --> 01:57:01,440
use the

2792
01:57:01,440 --> 01:57:03,280
information so this is not just a

2793
01:57:03,280 --> 01:57:05,119
server-side decision which is why

2794
01:57:05,119 --> 01:57:07,199
we're trying to standardize the format

2795
01:57:07,199 --> 01:57:08,320
of the transport

2796
01:57:08,320 --> 01:57:11,840
extension next slide

2797
01:57:15,280 --> 01:57:17,520
and we've also looked at the security of

2798
01:57:17,520 --> 01:57:20,320
it they the way in which to exchange the

2799
01:57:20,320 --> 01:57:23,280
the parameters the way in which the path

2800
01:57:23,280 --> 01:57:24,080
cannot

2801
01:57:24,080 --> 01:57:27,119
modify these parameters are important to

2802
01:57:27,119 --> 01:57:27,920
us

2803
01:57:27,920 --> 01:57:30,320
and we believe that we have a safe

2804
01:57:30,320 --> 01:57:31,520
mechanism here

2805
01:57:31,520 --> 01:57:35,679
that works with tls 1.3

2806
01:57:36,840 --> 01:57:39,840
next

2807
01:57:40,719 --> 01:57:42,960
there's some interaction um emil is our

2808
01:57:42,960 --> 01:57:44,239
tls person

2809
01:57:44,239 --> 01:57:48,080
um and there are probably things that we

2810
01:57:48,080 --> 01:57:49,199
should discuss

2811
01:57:49,199 --> 01:57:52,320
between quick and tls to see how

2812
01:57:52,320 --> 01:57:54,639
this initial exchange of data should

2813
01:57:54,639 --> 01:57:56,400
best be handled

2814
01:57:56,400 --> 01:57:58,560
and i think some form of synchronization

2815
01:57:58,560 --> 01:58:00,320
between the two working groups is

2816
01:58:00,320 --> 01:58:01,520
important

2817
01:58:01,520 --> 01:58:03,360
this isn't a congestion control issue

2818
01:58:03,360 --> 01:58:05,840
it's more a security

2819
01:58:05,840 --> 01:58:07,520
discussion but but it's still an

2820
01:58:07,520 --> 01:58:09,199
important part of the design of the

2821
01:58:09,199 --> 01:58:10,080
mechanism

2822
01:58:10,080 --> 01:58:12,559
next slide

2823
01:58:15,679 --> 01:58:19,040
congestion control safety is the

2824
01:58:19,040 --> 01:58:21,280
thing which probably is most important

2825
01:58:21,280 --> 01:58:22,159
for this group

2826
01:58:22,159 --> 01:58:26,159
and if we can standardize

2827
01:58:26,159 --> 01:58:29,199
or adopt a way of exchanging this

2828
01:58:29,199 --> 01:58:31,360
information we also need to adopt a way

2829
01:58:31,360 --> 01:58:31,840
of

2830
01:58:31,840 --> 01:58:35,679
safely using it and

2831
01:58:35,679 --> 01:58:37,360
we're assuming that any method we use

2832
01:58:37,360 --> 01:58:39,440
here will have a way of backing out

2833
01:58:39,440 --> 01:58:41,520
quickly and efficiently as soon as there

2834
01:58:41,520 --> 01:58:42,639
is loss detected

2835
01:58:42,639 --> 01:58:45,840
and the cw d has been artificially

2836
01:58:45,840 --> 01:58:49,360
increased so um we will we will

2837
01:58:49,360 --> 01:58:51,360
expect to quickly back out of any

2838
01:58:51,360 --> 01:58:52,639
problem but

2839
01:58:52,639 --> 01:58:55,679
um do we need a draft on congestion

2840
01:58:55,679 --> 01:58:58,480
control safety that updates 6928

2841
01:58:58,480 --> 01:59:01,119
maybe this might be something useful to

2842
01:59:01,119 --> 01:59:02,000
set the boundaries

2843
01:59:02,000 --> 01:59:05,520
here next slide please

2844
01:59:10,480 --> 01:59:13,920
we could use a new bdp extension

2845
01:59:13,920 --> 01:59:15,199
specified in quick

2846
01:59:15,199 --> 01:59:18,560
and we are wanting to do that part of

2847
01:59:18,560 --> 01:59:19,920
the work in quick

2848
01:59:19,920 --> 01:59:22,000
but there's obviously also a congestion

2849
01:59:22,000 --> 01:59:23,840
control piece which is why we're trying

2850
01:59:23,840 --> 01:59:26,560
to bubble this up here in this group

2851
01:59:26,560 --> 01:59:30,480
and attract some comments so

2852
01:59:30,480 --> 01:59:32,320
trying to stick roughly to time i'd like

2853
01:59:32,320 --> 01:59:35,759
to take comments now if possible

2854
01:59:37,119 --> 01:59:40,159
um very quickly

2855
01:59:40,159 --> 01:59:43,040
can you meet your mic there so i i don't

2856
01:59:43,040 --> 01:59:44,000
know that we have time

2857
01:59:44,000 --> 01:59:47,440
for q a we are already at time um

2858
01:59:47,440 --> 01:59:49,599
but i'll encourage people to thank you

2859
01:59:49,599 --> 01:59:50,960
for presenting this here

2860
01:59:50,960 --> 01:59:53,199
i want people to engage on this question

2861
01:59:53,199 --> 01:59:54,400
and i'll take my

2862
01:59:54,400 --> 01:59:58,000
my my moment to basically say that

2863
01:59:58,000 --> 02:00:00,719
this is something that we expect the the

2864
02:00:00,719 --> 02:00:01,520
the

2865
02:00:01,520 --> 02:00:03,360
us at a specific mechanism but the idea

2866
02:00:03,360 --> 02:00:04,719
of recording and

2867
02:00:04,719 --> 02:00:06,000
reusing constitutional control

2868
02:00:06,000 --> 02:00:07,520
information is something that we expect

2869
02:00:07,520 --> 02:00:08,480
will happen

2870
02:00:08,480 --> 02:00:10,719
in quick because there are places to

2871
02:00:10,719 --> 02:00:12,480
store this information at the client

2872
02:00:12,480 --> 02:00:13,840
this is something that is different from

2873
02:00:13,840 --> 02:00:17,040
pcb where a server can actually encode

2874
02:00:17,040 --> 02:00:18,480
this information and ship it off to a

2875
02:00:18,480 --> 02:00:19,360
client and then

2876
02:00:19,360 --> 02:00:21,280
use it on the next connection when

2877
02:00:21,280 --> 02:00:22,639
connection is established

2878
02:00:22,639 --> 02:00:24,080
which makes it much more likely that

2879
02:00:24,080 --> 02:00:26,159
something like this will get deployed by

2880
02:00:26,159 --> 02:00:27,360
quick implementations

2881
02:00:27,360 --> 02:00:29,760
so it is uh much more important now that

2882
02:00:29,760 --> 02:00:31,440
we actually engage on this topic

2883
02:00:31,440 --> 02:00:33,840
iccrg is the right forum perhaps we can

2884
02:00:33,840 --> 02:00:35,679
continue this discussion on the list

2885
02:00:35,679 --> 02:00:39,040
and at subsequent uh at the next meeting

2886
02:00:39,040 --> 02:00:41,360
as well but i'll thank gauri also for

2887
02:00:41,360 --> 02:00:43,119
putting this together very quickly

2888
02:00:43,119 --> 02:00:45,199
at short notice do you want to say

2889
02:00:45,199 --> 02:00:46,159
something cody

2890
02:00:46,159 --> 02:00:48,800
yeah i'd just like to say that we are we

2891
02:00:48,800 --> 02:00:50,080
are super interested

2892
02:00:50,080 --> 02:00:52,560
in not doing this as a group of

2893
02:00:52,560 --> 02:00:54,239
satellite engineers who've worked on

2894
02:00:54,239 --> 02:00:55,199
peps

2895
02:00:55,199 --> 02:00:57,360
and enhancement and modelling of really

2896
02:00:57,360 --> 02:00:59,280
long delay paths but to do it within the

2897
02:00:59,280 --> 02:01:00,320
ietf

2898
02:01:00,320 --> 02:01:02,480
where we can get other people involved

2899
02:01:02,480 --> 02:01:04,320
in this this is a super

2900
02:01:04,320 --> 02:01:05,840
interesting place where we can actually

2901
02:01:05,840 --> 02:01:07,599
collaborate between different people

2902
02:01:07,599 --> 02:01:10,239
and we'd really love to get feedback on

2903
02:01:10,239 --> 02:01:12,400
this

2904
02:01:12,639 --> 02:01:14,159
thank you so much gauri again for the

2905
02:01:14,159 --> 02:01:16,159
presentation one quick announcement bob

2906
02:01:16,159 --> 02:01:17,440
just announced that uh

2907
02:01:17,440 --> 02:01:20,320
a new draft uh describing product

2908
02:01:20,320 --> 02:01:22,320
construction control has been posted

2909
02:01:22,320 --> 02:01:25,199
please take a look uh we might end up

2910
02:01:25,199 --> 02:01:26,080
discussing that

2911
02:01:26,080 --> 02:01:28,159
at the next idea at the next iccrg

2912
02:01:28,159 --> 02:01:30,480
meeting um

2913
02:01:30,480 --> 02:01:32,639
thank you again everybody and enjoy the

2914
02:01:32,639 --> 02:01:33,679
rest of the itf

2915
02:01:33,679 --> 02:01:37,840
we'll see you next time

