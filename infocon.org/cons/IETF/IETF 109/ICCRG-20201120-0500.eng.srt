1
00:00:08,160 --> 00:00:12,219
[Music]

2
00:00:14,920 --> 00:00:17,920
foreign

3
00:00:22,950 --> 00:00:26,160
[Music]

4
00:00:37,120 --> 00:00:41,280
anybody come on people are 55 people in

5
00:00:39,920 --> 00:00:45,840
this meeting

6
00:00:41,280 --> 00:00:45,840
not one person

7
00:01:01,380 --> 00:01:04,659
[Music]

8
00:01:24,970 --> 00:01:28,019
[Music]

9
00:01:38,840 --> 00:01:42,560
hello

10
00:01:41,110 --> 00:01:45,360
[Music]

11
00:01:42,560 --> 00:01:55,840
we need someone to do minutes i'd like

12
00:01:45,360 --> 00:01:55,840
to get started

13
00:01:58,000 --> 00:02:02,880
you're going to hear my lovely voice

14
00:01:59,360 --> 00:02:02,880
until we get somebody to two minutes

15
00:02:07,360 --> 00:02:15,120
yes thank you

16
00:02:11,520 --> 00:02:16,879
and brian thank you i think uh if brian

17
00:02:15,120 --> 00:02:19,200
you guys can sort it out but presumably

18
00:02:16,879 --> 00:02:22,399
west can do it but but you need to

19
00:02:19,200 --> 00:02:26,879
i i'm very grateful thank you so much

20
00:02:22,400 --> 00:02:30,080
for doing that um

21
00:02:26,879 --> 00:02:32,399
well welcome to iccrg um this is

22
00:02:30,080 --> 00:02:33,599
the meeting after six months and it's

23
00:02:32,400 --> 00:02:37,519
been a while so

24
00:02:33,599 --> 00:02:40,399
um we've had i had a large number of

25
00:02:37,519 --> 00:02:41,760
uh people having things that uh we

26
00:02:40,400 --> 00:02:43,760
unfortunately could not

27
00:02:41,760 --> 00:02:44,799
we did not have enough time to present

28
00:02:43,760 --> 00:02:48,319
here but

29
00:02:44,800 --> 00:02:52,080
um i want to start off this meeting

30
00:02:48,319 --> 00:02:54,160
by before i do the

31
00:02:52,080 --> 00:02:55,360
agenda bash just very quickly note a

32
00:02:54,160 --> 00:02:59,040
couple of things first

33
00:02:55,360 --> 00:03:02,959
the note well as you all know applies

34
00:02:59,040 --> 00:03:04,319
um the important thing i wanted to

35
00:03:02,959 --> 00:03:06,480
point out here is that i would like to

36
00:03:04,319 --> 00:03:09,280
really try and shift

37
00:03:06,480 --> 00:03:10,079
uh the focus away from presentations at

38
00:03:09,280 --> 00:03:12,720
meetings

39
00:03:10,080 --> 00:03:14,640
to discussions i am probably going to

40
00:03:12,720 --> 00:03:18,159
slowly start insisting

41
00:03:14,640 --> 00:03:21,440
that those who want a presentation slot

42
00:03:18,159 --> 00:03:24,879
actually have um initiate

43
00:03:21,440 --> 00:03:27,760
a discussion on the list first so that

44
00:03:24,879 --> 00:03:29,440
it doesn't seem like a one-shot thing we

45
00:03:27,760 --> 00:03:30,480
always have this problem with iccrg i

46
00:03:29,440 --> 00:03:32,480
think where

47
00:03:30,480 --> 00:03:34,238
people come to a presentation walk away

48
00:03:32,480 --> 00:03:34,879
and it's 10 minutes of engagement for

49
00:03:34,239 --> 00:03:36,560
three months

50
00:03:34,879 --> 00:03:39,359
which is not particularly exciting or

51
00:03:36,560 --> 00:03:40,959
interesting and there's no continuity

52
00:03:39,360 --> 00:03:43,450
so i would i want to encourage everybody

53
00:03:40,959 --> 00:03:44,720
to to to participate on the list

54
00:03:43,450 --> 00:03:47,839
[Music]

55
00:03:44,720 --> 00:03:48,720
i want people to uh bring topics up on

56
00:03:47,840 --> 00:03:50,959
the list and if

57
00:03:48,720 --> 00:03:52,159
if the topics are interesting i would

58
00:03:50,959 --> 00:03:54,640
like to give that time

59
00:03:52,159 --> 00:03:56,399
on the agenda and i will say that topics

60
00:03:54,640 --> 00:04:00,480
that are getting discussion on the list

61
00:03:56,400 --> 00:04:02,239
will uh will have priority

62
00:04:00,480 --> 00:04:03,840
when it comes to agenda time at a

63
00:04:02,239 --> 00:04:06,959
meeting so

64
00:04:03,840 --> 00:04:10,080
uh keep that in mind and uh uh

65
00:04:06,959 --> 00:04:12,400
i'll move along um one one more thing

66
00:04:10,080 --> 00:04:14,720
before i get on to the agenda is that

67
00:04:12,400 --> 00:04:18,239
later today uh during the irtf open

68
00:04:14,720 --> 00:04:21,839
there's a talk by rainesha ware of cnu

69
00:04:18,238 --> 00:04:24,000
uh she will be presenting uh on

70
00:04:21,839 --> 00:04:25,359
uh oh i don't remember the name of the

71
00:04:24,000 --> 00:04:28,400
talk but it's about

72
00:04:25,360 --> 00:04:30,720
the chain fairness index and and uh and

73
00:04:28,400 --> 00:04:31,919
moving past the chain fairness index to

74
00:04:30,720 --> 00:04:34,400
measure

75
00:04:31,919 --> 00:04:35,280
uh fairness amongst flows and it's a

76
00:04:34,400 --> 00:04:38,799
very interesting

77
00:04:35,280 --> 00:04:42,719
piece of work um i encourage you to

78
00:04:38,800 --> 00:04:45,120
show up uh and and and and give feedback

79
00:04:42,720 --> 00:04:46,320
i'm sure you will be interested in this

80
00:04:45,120 --> 00:04:48,800
talk

81
00:04:46,320 --> 00:04:50,080
um with that let's get started we have a

82
00:04:48,800 --> 00:04:52,000
packed agenda today so we're going to

83
00:04:50,080 --> 00:04:56,000
try and keep this on time

84
00:04:52,000 --> 00:04:59,520
um i uh we have praveen doing an update

85
00:04:56,000 --> 00:05:02,800
on our like that and then we have

86
00:04:59,520 --> 00:05:06,240
a special guest ayush mishra who will be

87
00:05:02,800 --> 00:05:08,800
talking about a really interesting paper

88
00:05:06,240 --> 00:05:10,080
where they've done some fascinating work

89
00:05:08,800 --> 00:05:12,400
on measuring

90
00:05:10,080 --> 00:05:14,800
tcp condition control deployment on the

91
00:05:12,400 --> 00:05:14,799
internet

92
00:05:15,280 --> 00:05:20,559
the we have neil from google giving us

93
00:05:17,919 --> 00:05:24,080
an update on bbr v2

94
00:05:20,560 --> 00:05:27,199
followed by sylvester who who

95
00:05:24,080 --> 00:05:30,400
will be talking i think about bbr uh

96
00:05:27,199 --> 00:05:32,080
unfairness um and and then

97
00:05:30,400 --> 00:05:34,159
uh bob talking about pcb product

98
00:05:32,080 --> 00:05:35,440
congestion control and if we have time

99
00:05:34,160 --> 00:05:37,680
we will have a chance to talk about

100
00:05:35,440 --> 00:05:40,800
mpdccp as well so

101
00:05:37,680 --> 00:05:42,800
it's a packed agenda um let's keep this

102
00:05:40,800 --> 00:05:44,800
uh to the speakers let's keep this

103
00:05:42,800 --> 00:05:48,240
within time i'm gonna try and

104
00:05:44,800 --> 00:05:50,080
uh move you along if uh if i need to

105
00:05:48,240 --> 00:05:52,479
uh and i would like to get started so

106
00:05:50,080 --> 00:05:53,440
i'm gonna take uh i think charge of the

107
00:05:52,479 --> 00:05:55,520
slides here

108
00:05:53,440 --> 00:05:56,880
and i'll run them i know sylvester you

109
00:05:55,520 --> 00:05:58,400
were going to try and do your own slides

110
00:05:56,880 --> 00:06:02,000
and that's fine

111
00:05:58,400 --> 00:06:05,359
but i will i'm going to cue praveen now

112
00:06:02,000 --> 00:06:08,639
i'm going to switch this to

113
00:06:05,360 --> 00:06:12,400
my um to

114
00:06:08,639 --> 00:06:12,400
to your slides praveen

115
00:06:17,759 --> 00:06:21,360
all right can you see and hear me i can

116
00:06:20,880 --> 00:06:24,000
see you

117
00:06:21,360 --> 00:06:25,440
hearing is you you might want to move

118
00:06:24,000 --> 00:06:29,600
your mic down

119
00:06:25,440 --> 00:06:32,000
uh better now uh slightly better

120
00:06:29,600 --> 00:06:35,840
you can go a little bit oh i'm sorry

121
00:06:32,000 --> 00:06:35,840
it's me not you

122
00:06:38,320 --> 00:06:43,440
[Music]

123
00:06:40,560 --> 00:06:43,910
hang on waiting for the slides to show

124
00:06:43,440 --> 00:06:45,840
up

125
00:06:43,910 --> 00:06:47,919
[Music]

126
00:06:45,840 --> 00:06:49,198
okay hello everyone everybody is

127
00:06:47,919 --> 00:06:53,520
probably in different time zone

128
00:06:49,199 --> 00:06:55,120
uh uh after a long time we have iccrg so

129
00:06:53,520 --> 00:06:57,758
happy to see everybody here

130
00:06:55,120 --> 00:06:59,199
uh today i'm going to talk about our led

131
00:06:57,759 --> 00:07:01,360
bat

132
00:06:59,199 --> 00:07:02,400
we have an update on our luck bat this

133
00:07:01,360 --> 00:07:04,800
is joint work

134
00:07:02,400 --> 00:07:05,919
with others at microsoft and also uh

135
00:07:04,800 --> 00:07:09,599
much less

136
00:07:05,919 --> 00:07:11,359
bertrow from uc3m uh i missed gabriel's

137
00:07:09,599 --> 00:07:14,639
name uh sorry about that

138
00:07:11,360 --> 00:07:14,639
jenna can you move to the next slide

139
00:07:14,840 --> 00:07:20,080
please

140
00:07:17,680 --> 00:07:21,680
uh so what is our led by a quick recap

141
00:07:20,080 --> 00:07:23,120
so what we want to do is we want to

142
00:07:21,680 --> 00:07:24,720
bring the benefit of

143
00:07:23,120 --> 00:07:26,160
light back plus plus to the receive side

144
00:07:24,720 --> 00:07:28,400
of the transport connection for those

145
00:07:26,160 --> 00:07:30,319
who don't know what ledbet plus plus is

146
00:07:28,400 --> 00:07:32,479
it's an improvement over the original

147
00:07:30,319 --> 00:07:35,120
lightbet rfc to solve

148
00:07:32,479 --> 00:07:35,919
a bunch of uh shortcomings of that rfc

149
00:07:35,120 --> 00:07:38,479
uh

150
00:07:35,919 --> 00:07:40,240
so uh network plus plus is a sender side

151
00:07:38,479 --> 00:07:43,440
congestion control algorithm

152
00:07:40,240 --> 00:07:45,120
what we want to do is uh bring the same

153
00:07:43,440 --> 00:07:46,719
benefits of that algorithm to the

154
00:07:45,120 --> 00:07:48,479
received side of the transport

155
00:07:46,720 --> 00:07:50,240
connection

156
00:07:48,479 --> 00:07:51,919
uh how we do this we use the flow

157
00:07:50,240 --> 00:07:54,879
control mechanism so as you know

158
00:07:51,919 --> 00:07:55,680
each tcp packet contains the window

159
00:07:54,879 --> 00:07:57,280
field

160
00:07:55,680 --> 00:08:00,240
which advertises to the peer how much

161
00:07:57,280 --> 00:08:03,198
data it can buffer

162
00:08:00,240 --> 00:08:04,800
and that is typically a typical tcp

163
00:08:03,199 --> 00:08:07,280
implementation would tune that

164
00:08:04,800 --> 00:08:09,120
buffer over time to make the performance

165
00:08:07,280 --> 00:08:10,878
good so we would increase the window as

166
00:08:09,120 --> 00:08:12,000
long as the sender is able to keep up

167
00:08:10,879 --> 00:08:14,080
and the application is draining

168
00:08:12,000 --> 00:08:16,000
data but in this case what we want to do

169
00:08:14,080 --> 00:08:19,758
is use that as a throttle

170
00:08:16,000 --> 00:08:22,720
so uh based on the uh

171
00:08:19,759 --> 00:08:24,639
ledbet algorithm we want to actually

172
00:08:22,720 --> 00:08:25,199
control how much data the sender is able

173
00:08:24,639 --> 00:08:27,680
to send

174
00:08:25,199 --> 00:08:28,560
effectively implementing a less than

175
00:08:27,680 --> 00:08:31,280
best effort

176
00:08:28,560 --> 00:08:32,080
congestion control uh for the end-to-end

177
00:08:31,280 --> 00:08:34,399
connection

178
00:08:32,080 --> 00:08:35,599
on the receive side uh one of the key

179
00:08:34,399 --> 00:08:37,120
points there is yeah we don't want to

180
00:08:35,599 --> 00:08:38,959
shrink the advertised window

181
00:08:37,120 --> 00:08:41,679
but based on the computer window we can

182
00:08:38,958 --> 00:08:44,959
over time reduce it

183
00:08:41,679 --> 00:08:45,680
over the period of rtt uh why do we want

184
00:08:44,959 --> 00:08:47,119
to do this why

185
00:08:45,680 --> 00:08:49,199
why is it important to do this on the

186
00:08:47,120 --> 00:08:51,279
receive side uh

187
00:08:49,200 --> 00:08:52,959
three major reasons one of the

188
00:08:51,279 --> 00:08:54,320
challenges is that a lot of like

189
00:08:52,959 --> 00:08:56,560
software updates

190
00:08:54,320 --> 00:08:58,240
which is uh one of the primary use cases

191
00:08:56,560 --> 00:09:01,518
for background transfers

192
00:08:58,240 --> 00:09:03,120
uh uses uh cdns uh and and

193
00:09:01,519 --> 00:09:05,120
having control over the servers is

194
00:09:03,120 --> 00:09:07,279
difficult to most of them don't have lab

195
00:09:05,120 --> 00:09:09,200
plus plus support

196
00:09:07,279 --> 00:09:10,480
the second reason we want to do this on

197
00:09:09,200 --> 00:09:11,519
the receiver is that there can be

198
00:09:10,480 --> 00:09:14,160
proxies on the path

199
00:09:11,519 --> 00:09:14,720
corporate networks have a lot of proxies

200
00:09:14,160 --> 00:09:18,319
um

201
00:09:14,720 --> 00:09:20,320
and that can prevent uh the

202
00:09:18,320 --> 00:09:21,680
the sort of less than best effort

203
00:09:20,320 --> 00:09:24,320
happening end to end

204
00:09:21,680 --> 00:09:25,279
the the network on the client side might

205
00:09:24,320 --> 00:09:27,519
be overloaded

206
00:09:25,279 --> 00:09:29,519
and just doing it in one path of the

207
00:09:27,519 --> 00:09:31,600
network is not sufficient

208
00:09:29,519 --> 00:09:33,200
um and of course there's like cases

209
00:09:31,600 --> 00:09:34,480
where the receiver application has more

210
00:09:33,200 --> 00:09:35,120
information about exactly which

211
00:09:34,480 --> 00:09:36,880
connections

212
00:09:35,120 --> 00:09:39,120
need to be lower priority and might not

213
00:09:36,880 --> 00:09:42,240
be able to communicate that to the

214
00:09:39,120 --> 00:09:44,480
server side and doing this just using

215
00:09:42,240 --> 00:09:45,839
the client side application has a lot of

216
00:09:44,480 --> 00:09:48,640
advantages

217
00:09:45,839 --> 00:09:50,080
uh including having enforcing any sort

218
00:09:48,640 --> 00:09:53,360
of preference that the

219
00:09:50,080 --> 00:09:56,000
local application or operating system

220
00:09:53,360 --> 00:09:57,040
that wants to apply a less than best

221
00:09:56,000 --> 00:09:59,680
effort

222
00:09:57,040 --> 00:10:00,800
this is based on the draft that is

223
00:09:59,680 --> 00:10:02,719
co-authored by

224
00:10:00,800 --> 00:10:04,000
everybody that was on the first slide

225
00:10:02,720 --> 00:10:06,320
please next slide please

226
00:10:04,000 --> 00:10:06,320
you know

227
00:10:12,959 --> 00:10:16,079
so the update i have is that we have an

228
00:10:14,560 --> 00:10:18,160
implementation now in the windows

229
00:10:16,079 --> 00:10:19,920
operating system is based on the draft

230
00:10:18,160 --> 00:10:22,959
it's implemented for tcp

231
00:10:19,920 --> 00:10:24,719
uh we already had an api and sort of uh

232
00:10:22,959 --> 00:10:26,560
configuration in the os to turn on

233
00:10:24,720 --> 00:10:27,920
ledbet plus plus the same one also

234
00:10:26,560 --> 00:10:30,000
enables our led bat

235
00:10:27,920 --> 00:10:31,360
so when you enable this you get less

236
00:10:30,000 --> 00:10:33,200
than best effort in both send and

237
00:10:31,360 --> 00:10:34,800
receive directions

238
00:10:33,200 --> 00:10:36,959
uh it includes all the additional

239
00:10:34,800 --> 00:10:37,839
mechanisms of led by plus plus the r led

240
00:10:36,959 --> 00:10:39,518
by draft

241
00:10:37,839 --> 00:10:40,880
leaves it open to the implementation at

242
00:10:39,519 --> 00:10:42,560
least the current version of the draft

243
00:10:40,880 --> 00:10:43,360
leaves it open to the implementation to

244
00:10:42,560 --> 00:10:45,279
either

245
00:10:43,360 --> 00:10:46,720
use lead battery led by plus plus we

246
00:10:45,279 --> 00:10:48,320
have chosen to implement

247
00:10:46,720 --> 00:10:50,399
all of the goodness of lightbulb plus

248
00:10:48,320 --> 00:10:53,440
plus which includes uh

249
00:10:50,399 --> 00:10:56,800
rtt measurement slower than

250
00:10:53,440 --> 00:10:59,760
reno increase for the window

251
00:10:56,800 --> 00:11:01,599
with the adaptive gain factor we also do

252
00:10:59,760 --> 00:11:04,800
the multiplicative decrease

253
00:11:01,600 --> 00:11:06,720
to solve uh interlaced but fairness and

254
00:11:04,800 --> 00:11:08,000
late command advantage problems we also

255
00:11:06,720 --> 00:11:09,839
have

256
00:11:08,000 --> 00:11:12,320
a modified version of slow start which

257
00:11:09,839 --> 00:11:14,079
exits early based on deal increase

258
00:11:12,320 --> 00:11:16,240
and we have the initial and periodic

259
00:11:14,079 --> 00:11:17,760
slowdown which helps us measure the

260
00:11:16,240 --> 00:11:19,839
base delay accurately throughout the

261
00:11:17,760 --> 00:11:23,200
lifetime of the connection and

262
00:11:19,839 --> 00:11:24,800
solve the latency drift problem uh one

263
00:11:23,200 --> 00:11:26,800
of the key things here is that

264
00:11:24,800 --> 00:11:28,719
when you turn this on we automatically

265
00:11:26,800 --> 00:11:31,519
negotiate tsb time stamps

266
00:11:28,720 --> 00:11:33,680
if tcp times time negotiation fails

267
00:11:31,519 --> 00:11:35,360
effective the algorithm is disabled at

268
00:11:33,680 --> 00:11:37,199
that point it becomes

269
00:11:35,360 --> 00:11:40,079
it generally just falls back to a

270
00:11:37,200 --> 00:11:41,680
traditional tcp connection

271
00:11:40,079 --> 00:11:43,279
we do expose that information after the

272
00:11:41,680 --> 00:11:46,319
application so the application could

273
00:11:43,279 --> 00:11:48,079
uh apply like a static uh throttle uh

274
00:11:46,320 --> 00:11:50,560
for these kind of workloads uh next

275
00:11:48,079 --> 00:11:50,560
slide please

276
00:11:52,160 --> 00:11:56,000
uh so what are the dv there are some

277
00:11:53,680 --> 00:11:59,199
deviations from the draft

278
00:11:56,000 --> 00:12:00,959
that i wanted to call out uh the

279
00:11:59,200 --> 00:12:03,120
periodic slowdown algorithm in that

280
00:12:00,959 --> 00:12:04,959
ledbet plus plus is is complicated for

281
00:12:03,120 --> 00:12:06,000
this uh our ledbetter implementation we

282
00:12:04,959 --> 00:12:09,279
have chosen to

283
00:12:06,000 --> 00:12:12,480
make it uh more simplified so

284
00:12:09,279 --> 00:12:15,680
instead of targeting only a

285
00:12:12,480 --> 00:12:18,240
90 reduction uh we are

286
00:12:15,680 --> 00:12:19,599
uh basically doing one slowdown per uh

287
00:12:18,240 --> 00:12:21,440
each measurement interval and that

288
00:12:19,600 --> 00:12:21,760
measurement interval is also different

289
00:12:21,440 --> 00:12:23,440
than

290
00:12:21,760 --> 00:12:26,800
uh the one for ledward plus plus which

291
00:12:23,440 --> 00:12:30,000
was 30 seconds this is like 60 seconds

292
00:12:26,800 --> 00:12:30,639
uh period uh for measuring uh the base

293
00:12:30,000 --> 00:12:33,120
delay

294
00:12:30,639 --> 00:12:34,639
it was basically a periodic slowdown we

295
00:12:33,120 --> 00:12:35,839
also have a different target delay this

296
00:12:34,639 --> 00:12:38,480
was arrived at

297
00:12:35,839 --> 00:12:39,760
based on some measurements the target

298
00:12:38,480 --> 00:12:41,839
delay of

299
00:12:39,760 --> 00:12:43,439
60 milliseconds was used in lightweight

300
00:12:41,839 --> 00:12:44,880
plus but we found that on the receiver

301
00:12:43,440 --> 00:12:47,519
side we have to use

302
00:12:44,880 --> 00:12:50,399
a lower value we are still sort of

303
00:12:47,519 --> 00:12:52,720
experimenting and tuning these constants

304
00:12:50,399 --> 00:12:54,720
and once we have more results with a

305
00:12:52,720 --> 00:12:55,519
real world workload we will update the

306
00:12:54,720 --> 00:12:58,560
draft with

307
00:12:55,519 --> 00:13:01,040
the correct recommendations uh next

308
00:12:58,560 --> 00:13:01,040
slide please

309
00:13:02,480 --> 00:13:05,920
so i have some initial lab results i

310
00:13:04,000 --> 00:13:06,959
don't have data from like a white

311
00:13:05,920 --> 00:13:08,079
deployment yet

312
00:13:06,959 --> 00:13:10,800
but this is just to show the

313
00:13:08,079 --> 00:13:12,479
effectiveness of the algorithm

314
00:13:10,800 --> 00:13:15,040
as implemented on the receive site so

315
00:13:12,480 --> 00:13:18,399
this is just a cubic short flow

316
00:13:15,040 --> 00:13:21,040
that kicks in during the middle of a

317
00:13:18,399 --> 00:13:22,399
are light but connection as you can see

318
00:13:21,040 --> 00:13:25,279
the connection lamps up

319
00:13:22,399 --> 00:13:26,800
the center doing slow start uh then we

320
00:13:25,279 --> 00:13:28,320
basically enter the

321
00:13:26,800 --> 00:13:30,000
slowdown period that's the initial

322
00:13:28,320 --> 00:13:31,040
slowdown and we throttle the sender

323
00:13:30,000 --> 00:13:32,480
completely

324
00:13:31,040 --> 00:13:34,240
this is what would have happened if the

325
00:13:32,480 --> 00:13:35,760
sender was using ledbet plus plus but in

326
00:13:34,240 --> 00:13:38,959
this case it's the receiver

327
00:13:35,760 --> 00:13:41,360
throttle in the center and then we exit

328
00:13:38,959 --> 00:13:44,560
the slowdown we continue

329
00:13:41,360 --> 00:13:44,800
our growth but then the cubic flow kicks

330
00:13:44,560 --> 00:13:46,399
in

331
00:13:44,800 --> 00:13:48,000
and the reaction is pretty immediate we

332
00:13:46,399 --> 00:13:51,199
can sense the delay build up

333
00:13:48,000 --> 00:13:53,440
in the bottleneck and we back off to

334
00:13:51,199 --> 00:13:54,399
the minimum rate which is the uh two

335
00:13:53,440 --> 00:13:55,920
packet window

336
00:13:54,399 --> 00:13:58,079
that is recommended by lightweight plus

337
00:13:55,920 --> 00:13:59,519
plus and then once the cubic flow

338
00:13:58,079 --> 00:14:00,959
leaves as you can see the ramp up is

339
00:13:59,519 --> 00:14:02,320
pretty slow here there's a 50

340
00:14:00,959 --> 00:14:05,359
millisecond

341
00:14:02,320 --> 00:14:06,639
rtt and because we are still slower than

342
00:14:05,360 --> 00:14:16,320
reno the growth is

343
00:14:06,639 --> 00:14:19,440
pretty slow uh next slide please

344
00:14:16,320 --> 00:14:20,720
this demonstrates the uh latecomer uh

345
00:14:19,440 --> 00:14:22,639
this this basically shows that the

346
00:14:20,720 --> 00:14:25,040
latecomer advantage problem does not

347
00:14:22,639 --> 00:14:26,959
exist uh with our leadback uh so what

348
00:14:25,040 --> 00:14:29,920
happens here is that uh

349
00:14:26,959 --> 00:14:32,160
when the late camera flow starts the

350
00:14:29,920 --> 00:14:34,479
slowdown the periodic slowdown basically

351
00:14:32,160 --> 00:14:37,600
allows the flows to remeasure the

352
00:14:34,480 --> 00:14:38,800
base delay and that causes the both the

353
00:14:37,600 --> 00:14:40,560
flows to sort of

354
00:14:38,800 --> 00:14:43,519
fair share and we don't see that the

355
00:14:40,560 --> 00:14:46,160
late gamer gets undue advantage and

356
00:14:43,519 --> 00:14:47,680
completely throttles the first floor

357
00:14:46,160 --> 00:14:50,319
this is the same

358
00:14:47,680 --> 00:14:52,638
configuration with a 50 millisecond 100

359
00:14:50,320 --> 00:14:55,360
mbps link

360
00:14:52,639 --> 00:14:55,360
next slide please

361
00:14:57,360 --> 00:15:02,880
uh this sort of shows the interled bat

362
00:15:00,800 --> 00:15:04,399
fairness for outlet blood flows these

363
00:15:02,880 --> 00:15:06,320
are four different outlet bright flows

364
00:15:04,399 --> 00:15:08,320
staggered started

365
00:15:06,320 --> 00:15:09,760
as you can see uh there's periodic

366
00:15:08,320 --> 00:15:11,120
slowdowns happening for all of these

367
00:15:09,760 --> 00:15:13,120
flows as a result

368
00:15:11,120 --> 00:15:14,240
they all measure the base delay

369
00:15:13,120 --> 00:15:17,360
accurately and they're

370
00:15:14,240 --> 00:15:20,320
able to like uh fair share the link

371
00:15:17,360 --> 00:15:20,800
amongst themselves uh this does not show

372
00:15:20,320 --> 00:15:22,399
uh

373
00:15:20,800 --> 00:15:23,839
what would happen if you put in a cubic

374
00:15:22,399 --> 00:15:24,240
flow but as soon as you have a cubic

375
00:15:23,839 --> 00:15:27,519
flow

376
00:15:24,240 --> 00:15:29,360
all of these would back off and then

377
00:15:27,519 --> 00:15:31,360
ram back up when there's no competing

378
00:15:29,360 --> 00:15:34,079
traffic

379
00:15:31,360 --> 00:15:34,079
next slide please

380
00:15:35,360 --> 00:15:40,480
uh this is the low latency competition

381
00:15:37,839 --> 00:15:42,880
effectively this is the problem where

382
00:15:40,480 --> 00:15:44,480
the queue is small enough actually

383
00:15:42,880 --> 00:15:46,720
there's a mistake on the slide the the

384
00:15:44,480 --> 00:15:48,639
queue size was actually 250

385
00:15:46,720 --> 00:15:51,040
packets so this is actually a shallow

386
00:15:48,639 --> 00:15:51,680
queue and because we can't build the

387
00:15:51,040 --> 00:15:55,279
queue

388
00:15:51,680 --> 00:15:57,199
we can't exceed the target delay so that

389
00:15:55,279 --> 00:15:59,360
bite would not back off

390
00:15:57,199 --> 00:16:01,199
we had the same experiment with ledbet

391
00:15:59,360 --> 00:16:02,800
plus plus and when it was a sender

392
00:16:01,199 --> 00:16:05,040
and we would see that it was actually

393
00:16:02,800 --> 00:16:07,519
taking much smaller share compared to

394
00:16:05,040 --> 00:16:09,680
cubic but with our ledbit we are seeing

395
00:16:07,519 --> 00:16:11,600
that uh there is actually a little bit

396
00:16:09,680 --> 00:16:12,800
more competition it's almost as if

397
00:16:11,600 --> 00:16:14,639
they're fair sharing

398
00:16:12,800 --> 00:16:16,079
but this is a problem we will continue

399
00:16:14,639 --> 00:16:18,560
to investigate we haven't

400
00:16:16,079 --> 00:16:20,000
root caused this yet uh but this this is

401
00:16:18,560 --> 00:16:22,079
something that needs to be uh

402
00:16:20,000 --> 00:16:24,480
investigated so certainly different

403
00:16:22,079 --> 00:16:27,599
behavior than what we saw with

404
00:16:24,480 --> 00:16:30,480
the library plus on this intersect

405
00:16:27,600 --> 00:16:30,480
uh next slide please

406
00:16:32,560 --> 00:16:36,079
uh that's sort of the summary of where

407
00:16:35,199 --> 00:16:38,319
we are at

408
00:16:36,079 --> 00:16:40,399
the next step for us is to take this

409
00:16:38,320 --> 00:16:43,519
implementation out for a spin with a

410
00:16:40,399 --> 00:16:44,399
real-world software update workload and

411
00:16:43,519 --> 00:16:47,680
measure its

412
00:16:44,399 --> 00:16:50,160
effectiveness measuring this is hard

413
00:16:47,680 --> 00:16:51,839
less than best effort in general uh

414
00:16:50,160 --> 00:16:53,680
metrics for this are really really

415
00:16:51,839 --> 00:16:55,360
really really hard problem particularly

416
00:16:53,680 --> 00:16:58,479
because the goal is to actually

417
00:16:55,360 --> 00:17:01,040
improve other traffic uh we've had cases

418
00:16:58,480 --> 00:17:03,279
where people had to drop off the call

419
00:17:01,040 --> 00:17:05,599
and go tell their family members to like

420
00:17:03,279 --> 00:17:08,720
stop doing things on the network so

421
00:17:05,599 --> 00:17:11,918
um you know it's it's basically a

422
00:17:08,720 --> 00:17:13,600
user experience uh uh measurement

423
00:17:11,919 --> 00:17:15,039
we have ways of doing this so we're

424
00:17:13,599 --> 00:17:16,559
still working on

425
00:17:15,039 --> 00:17:18,559
creative ways to measure the

426
00:17:16,559 --> 00:17:19,918
effectiveness of this algorithm in the

427
00:17:18,559 --> 00:17:22,000
real world

428
00:17:19,919 --> 00:17:23,600
uh we want to do constant tuning there's

429
00:17:22,000 --> 00:17:24,720
a bunch of magic constraints i think

430
00:17:23,599 --> 00:17:28,399
this applies to both

431
00:17:24,720 --> 00:17:30,000
uh let that plus plus an outlet pat

432
00:17:28,400 --> 00:17:32,720
the other thing we want to explore is

433
00:17:30,000 --> 00:17:35,679
the uh making the target value

434
00:17:32,720 --> 00:17:36,080
dynamic currently it's 60 milliseconds

435
00:17:35,679 --> 00:17:38,080
for

436
00:17:36,080 --> 00:17:39,678
uh ledbet plus plus and 40 milliseconds

437
00:17:38,080 --> 00:17:42,879
for our left back

438
00:17:39,679 --> 00:17:45,200
we would like to figure out a way to

439
00:17:42,880 --> 00:17:46,640
tune this based on the bottleneck link

440
00:17:45,200 --> 00:17:48,000
one of the challenges here is that

441
00:17:46,640 --> 00:17:49,919
because it's a less than best effort

442
00:17:48,000 --> 00:17:53,120
algorithm we can't really

443
00:17:49,919 --> 00:17:56,480
uh send at a very high rate to to figure

444
00:17:53,120 --> 00:17:57,918
out the the capacity of the link so

445
00:17:56,480 --> 00:18:01,760
this is a challenging problem we're

446
00:17:57,919 --> 00:18:04,799
still figuring out how best to do this

447
00:18:01,760 --> 00:18:05,440
there is a problem with bbr v2 so we

448
00:18:04,799 --> 00:18:08,160
took the

449
00:18:05,440 --> 00:18:10,080
latest alpha release of the linux

450
00:18:08,160 --> 00:18:13,280
implementation of bbrv2 and

451
00:18:10,080 --> 00:18:15,760
took it for a spin with ledbet plus plus

452
00:18:13,280 --> 00:18:16,320
uh in the lab so the same thing should

453
00:18:15,760 --> 00:18:18,640
apply to

454
00:18:16,320 --> 00:18:20,240
our ledbet as well uh effectively

455
00:18:18,640 --> 00:18:21,520
they're the same algorithm implemented

456
00:18:20,240 --> 00:18:23,200
on either side so

457
00:18:21,520 --> 00:18:24,799
the problem here is that uh we don't

458
00:18:23,200 --> 00:18:27,039
really see uh

459
00:18:24,799 --> 00:18:28,080
qubit up with bbr which is kind of by

460
00:18:27,039 --> 00:18:31,280
design and

461
00:18:28,080 --> 00:18:33,280
as a result uh we sort of enter the low

462
00:18:31,280 --> 00:18:34,799
low latency competition mode and and our

463
00:18:33,280 --> 00:18:36,799
led back and light red plus plus are not

464
00:18:34,799 --> 00:18:39,918
backing off

465
00:18:36,799 --> 00:18:44,639
so we have to do more work here

466
00:18:39,919 --> 00:18:46,559
uh to figure out how best to uh

467
00:18:44,640 --> 00:18:47,679
do less than best effort in the presence

468
00:18:46,559 --> 00:18:50,559
of an algorithm like

469
00:18:47,679 --> 00:18:52,240
uh bb or v2 so this is interesting

470
00:18:50,559 --> 00:18:53,840
avenue for research if

471
00:18:52,240 --> 00:18:56,240
there are folks on this group who want

472
00:18:53,840 --> 00:18:56,959
to contribute here we would be really

473
00:18:56,240 --> 00:19:00,640
happy to

474
00:18:56,960 --> 00:19:03,760
hear about any ideas

475
00:19:00,640 --> 00:19:07,360
on the draft side we have both drafts

476
00:19:03,760 --> 00:19:08,879
currently adopted in iccrg on the our

477
00:19:07,360 --> 00:19:10,959
ledbet side

478
00:19:08,880 --> 00:19:12,720
we may want to think about just

479
00:19:10,960 --> 00:19:14,320
referencing light but plus plus i i

480
00:19:12,720 --> 00:19:16,000
don't really see the point of

481
00:19:14,320 --> 00:19:18,799
going back to lead back with the known

482
00:19:16,000 --> 00:19:20,320
problems uh we also want to update uh

483
00:19:18,799 --> 00:19:22,559
the draft based on

484
00:19:20,320 --> 00:19:25,280
the data and the tuning on the ledward

485
00:19:22,559 --> 00:19:26,960
plus plus side um

486
00:19:25,280 --> 00:19:28,639
we want to add pseudocode that's been an

487
00:19:26,960 --> 00:19:32,240
ask from a lot of people

488
00:19:28,640 --> 00:19:33,679
uh so that the rfc is draft is easier to

489
00:19:32,240 --> 00:19:35,039
read and implement

490
00:19:33,679 --> 00:19:37,440
uh and there is there has been a

491
00:19:35,039 --> 00:19:40,879
suggestion to also make it uh

492
00:19:37,440 --> 00:19:42,960
alone instead of having to refer the

493
00:19:40,880 --> 00:19:45,360
original ledbet rfc and sort of

494
00:19:42,960 --> 00:19:47,120
replace the original one and that

495
00:19:45,360 --> 00:19:47,600
there's a third point i miss here which

496
00:19:47,120 --> 00:19:49,840
is

497
00:19:47,600 --> 00:19:51,678
to also make it agnostic to transport

498
00:19:49,840 --> 00:19:55,120
right now both of these drafts are

499
00:19:51,679 --> 00:19:56,640
very much specific to tcp uh whereas

500
00:19:55,120 --> 00:19:58,799
they could also be applied to quick

501
00:19:56,640 --> 00:20:00,400
so that's the third sort of work that

502
00:19:58,799 --> 00:20:03,120
needs to happen

503
00:20:00,400 --> 00:20:04,640
for these drafts uh with that i think

504
00:20:03,120 --> 00:20:05,360
i'm done with my talk and i'll be happy

505
00:20:04,640 --> 00:20:07,840
to take

506
00:20:05,360 --> 00:20:07,840
questions

507
00:20:14,960 --> 00:20:24,320
um thanks for watching

508
00:20:20,960 --> 00:20:26,240
thank you uh thank you for this um

509
00:20:24,320 --> 00:20:28,320
certainly an interesting idea i have to

510
00:20:26,240 --> 00:20:30,720
ask a question though like

511
00:20:28,320 --> 00:20:32,158
if you had your way would you prefer a

512
00:20:30,720 --> 00:20:35,520
server-side-only

513
00:20:32,159 --> 00:20:37,440
approach uh because assuming all servers

514
00:20:35,520 --> 00:20:39,520
implemented something

515
00:20:37,440 --> 00:20:42,320
that was of the shape of led back plus

516
00:20:39,520 --> 00:20:45,600
plus and we didn't agree on the hdb

517
00:20:42,320 --> 00:20:46,399
priority strap that like the like lowest

518
00:20:45,600 --> 00:20:49,360
priority

519
00:20:46,400 --> 00:20:49,760
actually like indicated a congestion

520
00:20:49,360 --> 00:20:52,879
drill

521
00:20:49,760 --> 00:20:57,200
change and maybe we can get like

522
00:20:52,880 --> 00:20:57,200
similar results just an idea

523
00:20:57,360 --> 00:21:00,799
it's kind of cross layer but um given

524
00:21:00,159 --> 00:21:02,799
them like

525
00:21:00,799 --> 00:21:05,280
very aware but their opposites worth

526
00:21:02,799 --> 00:21:07,120
thinking about

527
00:21:05,280 --> 00:21:10,960
but everything else sounds interesting

528
00:21:07,120 --> 00:21:10,959
and thanks for continuing this work

529
00:21:14,799 --> 00:21:18,400
if you if you look at the original

530
00:21:16,559 --> 00:21:19,840
problem right so yeah you could do this

531
00:21:18,400 --> 00:21:20,880
on the server side which is how we

532
00:21:19,840 --> 00:21:22,799
started out with

533
00:21:20,880 --> 00:21:25,760
as a conversion controller the challenge

534
00:21:22,799 --> 00:21:27,918
is the proxies the challenges uh

535
00:21:25,760 --> 00:21:30,158
not in not all applications we can

536
00:21:27,919 --> 00:21:31,840
modify to inform the sender about which

537
00:21:30,159 --> 00:21:33,919
connection is lower priority so

538
00:21:31,840 --> 00:21:34,959
there's some challenges doing just just

539
00:21:33,919 --> 00:21:36,640
on the server side

540
00:21:34,960 --> 00:21:39,039
one of the good parts of our ledbet is

541
00:21:36,640 --> 00:21:40,880
that it can easily coexist

542
00:21:39,039 --> 00:21:43,440
with the ledbet plus plus on the sender

543
00:21:40,880 --> 00:21:45,280
so there's no like interrupt problem

544
00:21:43,440 --> 00:21:46,880
here so let's say the server decided to

545
00:21:45,280 --> 00:21:49,120
do lightweight plus plus and the same

546
00:21:46,880 --> 00:21:51,280
time client is doing outlet bet

547
00:21:49,120 --> 00:21:52,399
uh those would just uh co-exist very

548
00:21:51,280 --> 00:21:54,080
peacefully

549
00:21:52,400 --> 00:21:55,840
and one of the advantages of violet bite

550
00:21:54,080 --> 00:21:57,678
is that you don't need any changes on

551
00:21:55,840 --> 00:21:59,760
the sender side

552
00:21:57,679 --> 00:22:02,080
but yeah i think like uh both both have

553
00:21:59,760 --> 00:22:05,039
their advantages

554
00:22:02,080 --> 00:22:06,960
yeah messing with conju flow control

555
00:22:05,039 --> 00:22:13,840
always makes me a little bit scared but

556
00:22:06,960 --> 00:22:13,840
i agree that it does work

557
00:22:18,400 --> 00:22:21,840
yeah i'm going to inject myself at the

558
00:22:20,159 --> 00:22:22,640
end of the line and also close the queue

559
00:22:21,840 --> 00:22:27,199
here

560
00:22:22,640 --> 00:22:29,600
um your next

561
00:22:27,200 --> 00:22:32,640
thank you uh for this talk uh why does

562
00:22:29,600 --> 00:22:35,678
it critically depend on tcp timestamps

563
00:22:32,640 --> 00:22:38,840
i saw that we you disable

564
00:22:35,679 --> 00:22:41,840
on like that if timestamp is not

565
00:22:38,840 --> 00:22:41,840
negotiated

566
00:22:42,159 --> 00:22:45,280
uh yeah good question i think this is

567
00:22:43,679 --> 00:22:48,559
covered in the draft so

568
00:22:45,280 --> 00:22:51,918
um basically we want to be able to take

569
00:22:48,559 --> 00:22:53,600
rdt measurements uh and that's the basis

570
00:22:51,919 --> 00:22:55,760
of the algorithm rate we use latency

571
00:22:53,600 --> 00:22:57,360
measurements uh the challenge is that

572
00:22:55,760 --> 00:22:59,120
if you're a pure receiver and not

573
00:22:57,360 --> 00:23:01,678
sending data throughout the life of the

574
00:22:59,120 --> 00:23:04,239
connection you cannot accurately measure

575
00:23:01,679 --> 00:23:06,000
rtt so that's the reason we have a

576
00:23:04,240 --> 00:23:10,720
strong dependency on the

577
00:23:06,000 --> 00:23:10,720
timestamp option i see thank you

578
00:23:13,600 --> 00:23:16,480
vedi you're next

579
00:23:20,000 --> 00:23:27,039
can you hear me uh yes we can yes we can

580
00:23:24,080 --> 00:23:28,639
thank you um so i have a lot of

581
00:23:27,039 --> 00:23:29,600
questions because i've been actively

582
00:23:28,640 --> 00:23:32,000
looking into this

583
00:23:29,600 --> 00:23:33,199
i did send some emails to the mailing

584
00:23:32,000 --> 00:23:36,880
list

585
00:23:33,200 --> 00:23:39,840
for the things that i have found

586
00:23:36,880 --> 00:23:40,320
um a couple things that i have yet not

587
00:23:39,840 --> 00:23:43,120
know

588
00:23:40,320 --> 00:23:44,879
updated on the mailing list one thing is

589
00:23:43,120 --> 00:23:47,760
uh when you do internal like that

590
00:23:44,880 --> 00:23:49,840
experiment don't you don't you sometimes

591
00:23:47,760 --> 00:23:51,520
see a delayed act problem in the rtt

592
00:23:49,840 --> 00:23:52,559
estimate because that's what i was

593
00:23:51,520 --> 00:23:54,400
seeing and

594
00:23:52,559 --> 00:23:58,799
some of the flows were really like

595
00:23:54,400 --> 00:23:58,799
struggling to get any bandwidth at all

596
00:24:02,720 --> 00:24:04,960
it's

597
00:24:28,080 --> 00:24:32,240
so we have a filter that we window

598
00:24:30,080 --> 00:24:34,320
filter that we apply to all these rtt

599
00:24:32,240 --> 00:24:37,360
samples which allows us to

600
00:24:34,320 --> 00:24:38,799
sort of weed out the delay tax samples

601
00:24:37,360 --> 00:24:40,479
one of the things i would point out is

602
00:24:38,799 --> 00:24:42,400
that the workloads we are looking at

603
00:24:40,480 --> 00:24:43,600
are mostly continuously transferring

604
00:24:42,400 --> 00:24:45,200
data

605
00:24:43,600 --> 00:24:47,039
because these are like update workloads

606
00:24:45,200 --> 00:24:49,120
which always have data to send even if

607
00:24:47,039 --> 00:24:51,279
it is in chunks uh so

608
00:24:49,120 --> 00:24:53,039
applying the window filter for the most

609
00:24:51,279 --> 00:24:54,640
recent and received rtd samples is

610
00:24:53,039 --> 00:24:56,240
really important that will allow you to

611
00:24:54,640 --> 00:25:01,840
sort of overcome the

612
00:24:56,240 --> 00:25:01,840
delay rack inflating the rtd problem

613
00:25:02,080 --> 00:25:15,840
set or receive that

614
00:25:17,279 --> 00:25:20,960
did you uh do you do that for both the

615
00:25:19,120 --> 00:25:23,199
receive light pattern uh lightpad plus

616
00:25:20,960 --> 00:25:23,200
plus

617
00:25:24,799 --> 00:25:28,639
yes we do it for both and it's more

618
00:25:27,279 --> 00:25:30,960
important on the

619
00:25:28,640 --> 00:25:32,720
ledbet side because uh if you're not

620
00:25:30,960 --> 00:25:34,159
sending data then then you're completely

621
00:25:32,720 --> 00:25:36,080
dependent on

622
00:25:34,159 --> 00:25:37,600
using the timestamp technique to measure

623
00:25:36,080 --> 00:25:40,320
rtt

624
00:25:37,600 --> 00:25:43,120
um but yeah if you're sending data then

625
00:25:40,320 --> 00:25:43,120
the deal attack

626
00:25:45,120 --> 00:25:49,760
um second question was uh the dynamic

627
00:25:47,919 --> 00:25:52,480
target

628
00:25:49,760 --> 00:25:54,559
i'm gonna have to interrupt you on

629
00:25:52,480 --> 00:25:56,880
thecube

630
00:25:54,559 --> 00:25:59,520
um uh would you would you be able to be

631
00:25:56,880 --> 00:25:59,520
able to list

632
00:26:02,080 --> 00:26:05,520
that that's okay but i just want to ask

633
00:26:03,760 --> 00:26:07,840
one one last question which is

634
00:26:05,520 --> 00:26:08,559
a little bit more important was the base

635
00:26:07,840 --> 00:26:10,559
delay

636
00:26:08,559 --> 00:26:11,918
is i think the basic lane travel is 10

637
00:26:10,559 --> 00:26:15,120
minutes in the

638
00:26:11,919 --> 00:26:17,919
light pad plus plus draft not 60 seconds

639
00:26:15,120 --> 00:26:20,239
which i noticed in the slides

640
00:26:17,919 --> 00:26:20,240
right

641
00:26:22,960 --> 00:26:28,799
uh i i'm pretty sure it's 60 seconds

642
00:26:26,080 --> 00:26:31,360
maybe there's a problem but let's take

643
00:26:28,799 --> 00:26:31,360
this offline

644
00:26:31,679 --> 00:26:35,600
okay cool uh and i have your other

645
00:26:33,679 --> 00:26:37,279
emails as well asking questions so i'll

646
00:26:35,600 --> 00:26:39,840
respond to all of them later yeah thank

647
00:26:37,279 --> 00:26:39,840
you

648
00:26:41,600 --> 00:26:45,199
all right uh let's keep this quick folks

649
00:26:44,480 --> 00:26:49,360
uh we

650
00:26:45,200 --> 00:26:49,360
are going past time now jeff europe

651
00:26:50,400 --> 00:26:55,440
i gathered from slide eight that it

652
00:26:53,440 --> 00:26:57,039
seems like you're assuming some kind of

653
00:26:55,440 --> 00:26:58,720
delay bandwidth product

654
00:26:57,039 --> 00:27:01,120
queue size in the network it doesn't

655
00:26:58,720 --> 00:27:03,919
work well on small queues

656
00:27:01,120 --> 00:27:06,000
let me ask you explicitly what

657
00:27:03,919 --> 00:27:09,360
assumptions is led back making

658
00:27:06,000 --> 00:27:12,320
about the network queue sizes and

659
00:27:09,360 --> 00:27:13,918
in relation to this sort of recent work

660
00:27:12,320 --> 00:27:15,678
about trying to reduce the amount of

661
00:27:13,919 --> 00:27:19,440
buffering in the network

662
00:27:15,679 --> 00:27:22,559
how does lead back react to consistently

663
00:27:19,440 --> 00:27:24,480
under provision but network buffers when

664
00:27:22,559 --> 00:27:27,678
the initial provisioning might have been

665
00:27:24,480 --> 00:27:27,679
delayed bandwidth product

666
00:27:32,480 --> 00:27:37,600
shallow buffers was attempted to be sold

667
00:27:36,080 --> 00:27:38,399
in that by plus plus which was more

668
00:27:37,600 --> 00:27:41,600
effective

669
00:27:38,399 --> 00:27:43,520
uh so basically uh what we do is we

670
00:27:41,600 --> 00:27:46,000
we are effectively slower than reno so

671
00:27:43,520 --> 00:27:49,120
there's no assumptions here about

672
00:27:46,000 --> 00:27:51,200
what the buffer size is there are cases

673
00:27:49,120 --> 00:27:52,879
where it's bdp or higher in which case

674
00:27:51,200 --> 00:27:54,240
you know there is enough buffer for us

675
00:27:52,880 --> 00:27:57,039
to build a queue and

676
00:27:54,240 --> 00:27:59,039
be able to detect that the target delay

677
00:27:57,039 --> 00:28:01,360
has been exceeded

678
00:27:59,039 --> 00:28:03,360
but there is no other assumptions here

679
00:28:01,360 --> 00:28:04,959
but if it's a shallow buffer the way we

680
00:28:03,360 --> 00:28:05,840
solve that problem in red red plus plus

681
00:28:04,960 --> 00:28:07,919
was that

682
00:28:05,840 --> 00:28:09,439
uh our effectively our window growth was

683
00:28:07,919 --> 00:28:11,760
lower than reno

684
00:28:09,440 --> 00:28:13,840
uh so that that would basically make it

685
00:28:11,760 --> 00:28:15,120
uh go much slower than competing traffic

686
00:28:13,840 --> 00:28:16,080
that's the best solution we could come

687
00:28:15,120 --> 00:28:18,080
up with

688
00:28:16,080 --> 00:28:19,840
as i explained earlier detecting exactly

689
00:28:18,080 --> 00:28:22,320
what the bottleneck capacity is is a

690
00:28:19,840 --> 00:28:24,240
hard problem for a less than best effort

691
00:28:22,320 --> 00:28:25,840
congestion control so all of these are

692
00:28:24,240 --> 00:28:26,480
good areas for research i also think

693
00:28:25,840 --> 00:28:28,158
that the

694
00:28:26,480 --> 00:28:29,679
as i mentioned the target value that we

695
00:28:28,159 --> 00:28:32,080
have is fixed right now

696
00:28:29,679 --> 00:28:34,640
and making it dynamic is also an

697
00:28:32,080 --> 00:28:36,158
important problem that should be solved

698
00:28:34,640 --> 00:28:38,240
thanks that answers my question thank

699
00:28:36,159 --> 00:28:38,240
you

700
00:28:39,600 --> 00:28:47,439
eric you're up

701
00:28:45,039 --> 00:28:49,120
very quickly say thank you and and i'm

702
00:28:47,440 --> 00:28:50,880
really interested to see

703
00:28:49,120 --> 00:28:52,479
some of the the further results and

704
00:28:50,880 --> 00:28:55,919
things we've noticed

705
00:28:52,480 --> 00:28:57,440
similar issues in terms of uh many of

706
00:28:55,919 --> 00:28:59,600
the flows that you would really like to

707
00:28:57,440 --> 00:29:01,760
be background flows are not flows where

708
00:28:59,600 --> 00:29:03,360
where uh you're doing a lot of the

709
00:29:01,760 --> 00:29:05,679
sending um

710
00:29:03,360 --> 00:29:07,279
and especially around intermediaries you

711
00:29:05,679 --> 00:29:09,520
may not be able to go find all the

712
00:29:07,279 --> 00:29:11,520
corners of the internet so that that

713
00:29:09,520 --> 00:29:13,039
i think has a real practical use in a

714
00:29:11,520 --> 00:29:14,960
way that that a lot of the other things

715
00:29:13,039 --> 00:29:16,720
we do are

716
00:29:14,960 --> 00:29:18,240
helpful in some cases but not quite as

717
00:29:16,720 --> 00:29:20,960
critical the one

718
00:29:18,240 --> 00:29:22,480
the one thing that would be interesting

719
00:29:20,960 --> 00:29:25,679
to know if you've seen

720
00:29:22,480 --> 00:29:27,440
is we've discovered a couple of senders

721
00:29:25,679 --> 00:29:28,960
and i can go look up what what

722
00:29:27,440 --> 00:29:31,200
congestion control they're using

723
00:29:28,960 --> 00:29:32,640
where after you've closed the window

724
00:29:31,200 --> 00:29:35,840
down they take

725
00:29:32,640 --> 00:29:38,799
many tens of seconds if not minutes

726
00:29:35,840 --> 00:29:40,799
to respond to the window opening back up

727
00:29:38,799 --> 00:29:42,158
and i'd be curious to know if if either

728
00:29:40,799 --> 00:29:43,440
you've seen anything like that and

729
00:29:42,159 --> 00:29:44,559
is that one of those cases where we say

730
00:29:43,440 --> 00:29:46,399
well it's fine because you're trying to

731
00:29:44,559 --> 00:29:47,678
be background flow anyway and so

732
00:29:46,399 --> 00:29:49,039
if it's going to take you you know two

733
00:29:47,679 --> 00:29:50,960
and a half minutes before you get back

734
00:29:49,039 --> 00:29:52,080
up to actually transferring real data

735
00:29:50,960 --> 00:29:54,159
that's fine because it's in the

736
00:29:52,080 --> 00:29:56,399
background or is there

737
00:29:54,159 --> 00:29:59,279
uh is that going to be a problem with

738
00:29:56,399 --> 00:29:59,279
this kind of a strategy

739
00:30:01,279 --> 00:30:05,279
so that's an interesting problem so we

740
00:30:03,440 --> 00:30:06,159
haven't done at scale measurements so i

741
00:30:05,279 --> 00:30:07,679
can't tell you

742
00:30:06,159 --> 00:30:09,600
if you have seen that problem that's a

743
00:30:07,679 --> 00:30:11,440
short of work that's upcoming i'm very

744
00:30:09,600 --> 00:30:12,959
uh happy to keep an eye out for that so

745
00:30:11,440 --> 00:30:15,360
thanks for the heads up

746
00:30:12,960 --> 00:30:16,960
um if the if that becomes a problem yeah

747
00:30:15,360 --> 00:30:19,279
i mean we don't want to go

748
00:30:16,960 --> 00:30:20,399
artificially slow either i mean yes we

749
00:30:19,279 --> 00:30:21,120
are trying to do these things in the

750
00:30:20,399 --> 00:30:22,719
background but

751
00:30:21,120 --> 00:30:24,320
if there is enough capacity we want to

752
00:30:22,720 --> 00:30:25,840
be able to saturate it

753
00:30:24,320 --> 00:30:27,760
one of the also the other problems with

754
00:30:25,840 --> 00:30:29,520
going slower than reno has been that you

755
00:30:27,760 --> 00:30:30,320
know if you're really on a big van link

756
00:30:29,520 --> 00:30:31,760
and

757
00:30:30,320 --> 00:30:33,840
you artificially slow down it takes a

758
00:30:31,760 --> 00:30:35,679
long time to to come back up so yes

759
00:30:33,840 --> 00:30:37,199
that is also an avenue for more

760
00:30:35,679 --> 00:30:38,880
improvements possibly

761
00:30:37,200 --> 00:30:40,799
but i'll keep an eye out and keep you

762
00:30:38,880 --> 00:30:43,039
posted hopefully another update in

763
00:30:40,799 --> 00:30:44,399
one of the other upcoming iccrgs so

764
00:30:43,039 --> 00:30:47,760
thank you

765
00:30:44,399 --> 00:30:50,000
thank you um

766
00:30:47,760 --> 00:30:51,360
i want to take a quick moment to thank

767
00:30:50,000 --> 00:30:52,799
praveen for this

768
00:30:51,360 --> 00:30:54,399
there's clearly a lot of interest in

769
00:30:52,799 --> 00:30:56,559
this work and i think it's

770
00:30:54,399 --> 00:30:57,840
the results are super interesting i have

771
00:30:56,559 --> 00:30:59,039
questions about them as well

772
00:30:57,840 --> 00:31:00,720
but i'm going to hold them off for the

773
00:30:59,039 --> 00:31:01,679
list which is the plug i want to make

774
00:31:00,720 --> 00:31:03,760
here

775
00:31:01,679 --> 00:31:04,799
please take these questions to the list

776
00:31:03,760 --> 00:31:06,240
i think that

777
00:31:04,799 --> 00:31:08,080
we want to see continued engagement on

778
00:31:06,240 --> 00:31:08,799
the list praveen's already said that

779
00:31:08,080 --> 00:31:10,559
he's

780
00:31:08,799 --> 00:31:12,158
interested in they are interested in in

781
00:31:10,559 --> 00:31:13,200
getting feedback on how to make things

782
00:31:12,159 --> 00:31:15,279
better here

783
00:31:13,200 --> 00:31:16,960
uh please please please take those to

784
00:31:15,279 --> 00:31:18,960
the list make suggestions

785
00:31:16,960 --> 00:31:20,240
engage in conversation there i'd love to

786
00:31:18,960 --> 00:31:22,159
see more of this happen

787
00:31:20,240 --> 00:31:23,600
on the list instead of just during the q

788
00:31:22,159 --> 00:31:26,799
a session here

789
00:31:23,600 --> 00:31:30,399
at the iccrg meeting um

790
00:31:26,799 --> 00:31:30,960
i i wanna yeah uh i'll say that just one

791
00:31:30,399 --> 00:31:32,559
comment i

792
00:31:30,960 --> 00:31:34,559
to make which is that people are talking

793
00:31:32,559 --> 00:31:37,918
about doing this per stream in quick or

794
00:31:34,559 --> 00:31:39,600
in http and that is very tricky

795
00:31:37,919 --> 00:31:41,360
you don't want to do multiple

796
00:31:39,600 --> 00:31:42,320
construction controllers within a single

797
00:31:41,360 --> 00:31:44,240
connection

798
00:31:42,320 --> 00:31:46,080
that walks into very very strange

799
00:31:44,240 --> 00:31:47,840
territory

800
00:31:46,080 --> 00:31:49,279
i'll just make that comment and move on

801
00:31:47,840 --> 00:31:54,158
we can have more discussion on the list

802
00:31:49,279 --> 00:32:00,640
or on the chat here thank you praveen

803
00:31:54,159 --> 00:32:04,080
um are you sure you're up next

804
00:32:00,640 --> 00:32:07,760
let me bring up your slides

805
00:32:04,080 --> 00:32:11,678
okay uh can you guys hear me

806
00:32:07,760 --> 00:32:14,480
yes we can okay okay

807
00:32:11,679 --> 00:32:16,080
i will just go on you want to introduce

808
00:32:14,480 --> 00:32:17,279
yourself and take it away irish by the

809
00:32:16,080 --> 00:32:20,639
way for everybody here

810
00:32:17,279 --> 00:32:21,600
is an iccrg newcomer so please treat him

811
00:32:20,640 --> 00:32:24,880
kindly

812
00:32:21,600 --> 00:32:28,158
and make him feel welcomed and uh

813
00:32:24,880 --> 00:32:30,399
happy to be here take it away okay

814
00:32:28,159 --> 00:32:31,279
okay thanks for the introduction janna

815
00:32:30,399 --> 00:32:33,439
uh so

816
00:32:31,279 --> 00:32:34,880
hello everyone i'm ayush i'm a second

817
00:32:33,440 --> 00:32:37,360
year phd student at

818
00:32:34,880 --> 00:32:39,600
nus and today i'll be talking about the

819
00:32:37,360 --> 00:32:40,799
great internet tcp congestion control

820
00:32:39,600 --> 00:32:42,320
census

821
00:32:40,799 --> 00:32:45,440
so this was basically a measurement

822
00:32:42,320 --> 00:32:47,200
study that we connected in mid 2019

823
00:32:45,440 --> 00:32:48,559
to figure out who's running what

824
00:32:47,200 --> 00:32:51,840
congestion control

825
00:32:48,559 --> 00:32:57,840
uh algorithms on the internet uh

826
00:32:51,840 --> 00:32:57,840
next slide please

827
00:32:58,480 --> 00:33:03,279
uh okay so 30 years of congestion

828
00:33:01,279 --> 00:33:05,679
control research have produced

829
00:33:03,279 --> 00:33:07,200
numerous congestion control algorithms

830
00:33:05,679 --> 00:33:09,200
and as a result

831
00:33:07,200 --> 00:33:10,799
for most of the internet's lifetime we

832
00:33:09,200 --> 00:33:13,120
have seen a heterogeneous mix of

833
00:33:10,799 --> 00:33:15,760
congestion control algorithms

834
00:33:13,120 --> 00:33:17,439
and um i mean i'm just not seeing this

835
00:33:15,760 --> 00:33:19,039
but this has also been verified by

836
00:33:17,440 --> 00:33:20,960
previous similar studies

837
00:33:19,039 --> 00:33:22,320
as marked in brown on the timeline on

838
00:33:20,960 --> 00:33:24,480
the slide

839
00:33:22,320 --> 00:33:25,840
but what's happened since the last such

840
00:33:24,480 --> 00:33:29,039
study in 2011

841
00:33:25,840 --> 00:33:32,480
is that we've had a new kid on the block

842
00:33:29,039 --> 00:33:34,399
so bbr which was proposed in 2016

843
00:33:32,480 --> 00:33:36,240
may arguably be the most momentous

844
00:33:34,399 --> 00:33:37,678
development in the congestion control

845
00:33:36,240 --> 00:33:40,960
landscape yet

846
00:33:37,679 --> 00:33:42,320
and the main reason we feel uh this way

847
00:33:40,960 --> 00:33:44,399
is because for the first time in the

848
00:33:42,320 --> 00:33:46,559
internet's history you're going to have

849
00:33:44,399 --> 00:33:48,000
a significant part of internet traffic

850
00:33:46,559 --> 00:33:50,240
that's not going to back off when it

851
00:33:48,000 --> 00:33:52,480
sees a random packet loss

852
00:33:50,240 --> 00:33:53,519
so what this essentially does is that it

853
00:33:52,480 --> 00:33:55,200
introduces an

854
00:33:53,519 --> 00:33:57,440
entirely different congestion control

855
00:33:55,200 --> 00:33:59,120
mechanic into the existing mix of

856
00:33:57,440 --> 00:33:59,679
window-based and loss-based congestion

857
00:33:59,120 --> 00:34:06,959
control

858
00:33:59,679 --> 00:34:09,520
on the internet next slide please

859
00:34:06,960 --> 00:34:11,760
so with this uh in mind what we wanted

860
00:34:09,520 --> 00:34:14,719
to do was we wanted to uncover

861
00:34:11,760 --> 00:34:15,679
the exact extent of bpr's deployment on

862
00:34:14,719 --> 00:34:18,560
the internet

863
00:34:15,679 --> 00:34:19,280
and maybe refresh our view of what the

864
00:34:18,560 --> 00:34:20,960
current

865
00:34:19,280 --> 00:34:23,119
internet congestion control landscape

866
00:34:20,960 --> 00:34:25,280
looks like so to do this

867
00:34:23,119 --> 00:34:26,639
uh we set out to do a congestion control

868
00:34:25,280 --> 00:34:29,040
census of sorts

869
00:34:26,639 --> 00:34:30,480
to measure the 20 000 most popular

870
00:34:29,040 --> 00:34:32,560
websites on the internet

871
00:34:30,480 --> 00:34:34,800
and figure out what congestion control

872
00:34:32,560 --> 00:34:37,520
algorithm theorem

873
00:34:34,800 --> 00:34:37,520
next slide please

874
00:34:38,480 --> 00:34:42,320
so unsurprisingly it turns out this is a

875
00:34:40,560 --> 00:34:43,599
non-trivial task for a variety of

876
00:34:42,320 --> 00:34:45,839
reasons

877
00:34:43,599 --> 00:34:47,679
firstly uh while making such a

878
00:34:45,839 --> 00:34:49,359
measurement we will need to isolate the

879
00:34:47,679 --> 00:34:51,599
internet's network dynamics

880
00:34:49,359 --> 00:34:53,440
so that whatever we see on the receiver

881
00:34:51,599 --> 00:34:54,480
end uh we can make sure that that's a

882
00:34:53,440 --> 00:34:55,679
function of what the congestion

883
00:34:54,480 --> 00:34:58,160
controller is doing

884
00:34:55,679 --> 00:35:00,720
and not just what uh the network looks

885
00:34:58,160 --> 00:35:02,640
like at that point of time

886
00:35:00,720 --> 00:35:04,240
second we would also want to extract a

887
00:35:02,640 --> 00:35:06,319
common feature from variety of

888
00:35:04,240 --> 00:35:09,279
congestion control algorithms

889
00:35:06,320 --> 00:35:12,079
uh since we don't know up front what the

890
00:35:09,280 --> 00:35:14,640
remote condition control algorithm is

891
00:35:12,079 --> 00:35:16,640
and finally uh we will need to identify

892
00:35:14,640 --> 00:35:19,759
these congestion control algorithms

893
00:35:16,640 --> 00:35:21,839
uh within short http page downloads so

894
00:35:19,760 --> 00:35:23,839
this was a design decision that we took

895
00:35:21,839 --> 00:35:25,599
uh very early into this measurement

896
00:35:23,839 --> 00:35:28,400
study and the reason was

897
00:35:25,599 --> 00:35:31,119
that most of the websites that we were

898
00:35:28,400 --> 00:35:33,839
aiming to measure serve http pages

899
00:35:31,119 --> 00:35:36,640
so it would be the best candidate for

900
00:35:33,839 --> 00:35:38,480
conducting such measurements

901
00:35:36,640 --> 00:35:40,400
so our solution to do this measurement

902
00:35:38,480 --> 00:35:44,000
study uh was a tool called

903
00:35:40,400 --> 00:35:44,960
gordon and gordo got in deals with each

904
00:35:44,000 --> 00:35:47,440
of these concerns

905
00:35:44,960 --> 00:35:50,079
through a variety of strategies and

906
00:35:47,440 --> 00:35:52,800
design decisions

907
00:35:50,079 --> 00:35:52,800
next slide please

908
00:35:53,760 --> 00:35:57,040
so the first issue which is isolating

909
00:35:55,920 --> 00:35:59,200
the network's

910
00:35:57,040 --> 00:36:01,440
dynamics is start by gordon by

911
00:35:59,200 --> 00:36:03,359
localizing the connection bottleneck

912
00:36:01,440 --> 00:36:05,680
so gordon does this by date limiting the

913
00:36:03,359 --> 00:36:07,520
connection right before the client

914
00:36:05,680 --> 00:36:09,118
and the reason we do this is because

915
00:36:07,520 --> 00:36:10,720
this provides us an opportunity to

916
00:36:09,119 --> 00:36:11,760
directly control the bandwidth that the

917
00:36:10,720 --> 00:36:15,680
sender sees

918
00:36:11,760 --> 00:36:17,599
and it also minimizes uh the risk of

919
00:36:15,680 --> 00:36:19,520
random packet losses on the internet

920
00:36:17,599 --> 00:36:20,960
that can potentially be hard to account

921
00:36:19,520 --> 00:36:27,839
for when we are doing

922
00:36:20,960 --> 00:36:27,839
our measurement next slide please

923
00:36:30,000 --> 00:36:34,400
the second issue which was uh selecting

924
00:36:32,480 --> 00:36:37,680
a common feature to extract from

925
00:36:34,400 --> 00:36:40,240
all our congestion control algorithms um

926
00:36:37,680 --> 00:36:40,799
we dealt dealt with this by actually

927
00:36:40,240 --> 00:36:43,118
choosing

928
00:36:40,800 --> 00:36:44,079
the seventh of the remote congestion

929
00:36:43,119 --> 00:36:46,640
controller

930
00:36:44,079 --> 00:36:48,000
as the common feature in our measurement

931
00:36:46,640 --> 00:36:51,279
and the reason we did this

932
00:36:48,000 --> 00:36:52,880
was because since um whether your

933
00:36:51,280 --> 00:36:55,680
congestion control algorithm

934
00:36:52,880 --> 00:36:56,560
is window-based or raid-based it's

935
00:36:55,680 --> 00:36:59,118
always going to

936
00:36:56,560 --> 00:37:00,400
have a cap on how many packages that you

937
00:36:59,119 --> 00:37:02,800
have in flight

938
00:37:00,400 --> 00:37:03,760
and this can essentially become it's

939
00:37:02,800 --> 00:37:05,280
essential

940
00:37:03,760 --> 00:37:07,760
it's effective event and this is

941
00:37:05,280 --> 00:37:10,720
something that we can measure

942
00:37:07,760 --> 00:37:12,240
so how we measure the seabend uh is

943
00:37:10,720 --> 00:37:15,040
actually through a very simple

944
00:37:12,240 --> 00:37:15,759
iterative procedure so we note that this

945
00:37:15,040 --> 00:37:18,240
event

946
00:37:15,760 --> 00:37:19,119
is the maximum number of unacknowledged

947
00:37:18,240 --> 00:37:21,040
packets

948
00:37:19,119 --> 00:37:22,160
a sender allows you to have during the

949
00:37:21,040 --> 00:37:24,320
connection

950
00:37:22,160 --> 00:37:26,000
so to basically get this number what we

951
00:37:24,320 --> 00:37:28,720
do is we start the connection

952
00:37:26,000 --> 00:37:29,359
uh with the remote server and then we

953
00:37:28,720 --> 00:37:32,879
drop

954
00:37:29,359 --> 00:37:35,119
all the packets till we see a retransmit

955
00:37:32,880 --> 00:37:36,960
so in this case all the packets that we

956
00:37:35,119 --> 00:37:38,240
received before we see a retransmit

957
00:37:36,960 --> 00:37:41,200
is going to be the value of the first

958
00:37:38,240 --> 00:37:43,839
congestion window or c1

959
00:37:41,200 --> 00:37:44,720
next uh we start a new connection after

960
00:37:43,839 --> 00:37:46,880
some time

961
00:37:44,720 --> 00:37:48,879
and this time we accept c1 number of

962
00:37:46,880 --> 00:37:49,440
packets before we start dropping packets

963
00:37:48,880 --> 00:37:51,680
again

964
00:37:49,440 --> 00:37:53,200
till we see a retransmit and in this

965
00:37:51,680 --> 00:37:53,919
case the new number of packets that

966
00:37:53,200 --> 00:37:56,960
we've dropped

967
00:37:53,920 --> 00:38:00,160
will become c2 or the second condition

968
00:37:56,960 --> 00:38:02,720
so we perform this uh

969
00:38:00,160 --> 00:38:04,879
procedure iteratively till we exhaust

970
00:38:02,720 --> 00:38:07,839
all the data in our target

971
00:38:04,880 --> 00:38:09,920
web page and thereby we produce a sieve

972
00:38:07,839 --> 00:38:12,160
and evolution graph

973
00:38:09,920 --> 00:38:13,040
we have found that this even evolution

974
00:38:12,160 --> 00:38:15,118
graph

975
00:38:13,040 --> 00:38:16,720
is uh not only effective enough to

976
00:38:15,119 --> 00:38:19,040
differ between the known

977
00:38:16,720 --> 00:38:20,640
congestion control variants but it's

978
00:38:19,040 --> 00:38:24,079
also quite handy in making

979
00:38:20,640 --> 00:38:26,000
uh useful observations about any unknown

980
00:38:24,079 --> 00:38:28,560
congestion control variants that gordon

981
00:38:26,000 --> 00:38:33,839
might encounter

982
00:38:28,560 --> 00:38:33,839
next slide please

983
00:38:34,400 --> 00:38:39,119
the last issue that we had to deal with

984
00:38:36,880 --> 00:38:40,480
was dealing with short http page

985
00:38:39,119 --> 00:38:43,040
downloads

986
00:38:40,480 --> 00:38:44,400
so how we can deal with this is really

987
00:38:43,040 --> 00:38:46,560
simple

988
00:38:44,400 --> 00:38:48,320
we can either look for larger pages

989
00:38:46,560 --> 00:38:50,160
which is exactly what we did we crawled

990
00:38:48,320 --> 00:38:51,440
the target domains for the largest pages

991
00:38:50,160 --> 00:38:54,560
we could find

992
00:38:51,440 --> 00:38:56,640
and since our measurements are

993
00:38:54,560 --> 00:38:58,400
made on a packet basis we use the

994
00:38:56,640 --> 00:38:59,200
smallest mtu that was allowed by the

995
00:38:58,400 --> 00:39:00,960
network path

996
00:38:59,200 --> 00:39:02,720
or during the connection so this

997
00:39:00,960 --> 00:39:05,520
basically allowed us to extract

998
00:39:02,720 --> 00:39:07,919
as many packets as we could from a given

999
00:39:05,520 --> 00:39:07,920
excise

1000
00:39:09,040 --> 00:39:11,759
next slide please

1001
00:39:13,599 --> 00:39:17,359
so while making these measurements uh

1002
00:39:15,680 --> 00:39:20,160
gordon actually simulates

1003
00:39:17,359 --> 00:39:20,880
our two key network stimuli in a way to

1004
00:39:20,160 --> 00:39:22,960
l-set

1005
00:39:20,880 --> 00:39:25,200
uh characteristic responses from a

1006
00:39:22,960 --> 00:39:28,320
remote congestion controller

1007
00:39:25,200 --> 00:39:30,399
and um we can encompass

1008
00:39:28,320 --> 00:39:31,839
the stimuli in something what we call a

1009
00:39:30,400 --> 00:39:34,000
network profile

1010
00:39:31,839 --> 00:39:36,640
and this network profile will be applied

1011
00:39:34,000 --> 00:39:38,400
to each measurement that coordinates

1012
00:39:36,640 --> 00:39:41,200
so in this network profile what garden

1013
00:39:38,400 --> 00:39:43,280
does is it emulates a packet drop

1014
00:39:41,200 --> 00:39:44,399
the first time this event exceeds 80

1015
00:39:43,280 --> 00:39:46,000
packets

1016
00:39:44,400 --> 00:39:49,839
and it immediately gets a bandwidth

1017
00:39:46,000 --> 00:39:51,359
change after receiving 1500 packets

1018
00:39:49,839 --> 00:39:53,200
and it does these changes while

1019
00:39:51,359 --> 00:39:57,040
emulating an rtt

1020
00:39:53,200 --> 00:39:59,439
of 100 ms the exact details for

1021
00:39:57,040 --> 00:40:00,320
why we use these numbers and why we

1022
00:39:59,440 --> 00:40:02,400
choose

1023
00:40:00,320 --> 00:40:04,960
these two network stimuli can be found

1024
00:40:02,400 --> 00:40:04,960
in the paper

1025
00:40:05,520 --> 00:40:08,240
next slide please

1026
00:40:09,359 --> 00:40:13,520
so this is a really interesting slide

1027
00:40:11,359 --> 00:40:16,640
and what it essentially illustrates

1028
00:40:13,520 --> 00:40:17,680
are the distinct congestion window

1029
00:40:16,640 --> 00:40:19,040
responses

1030
00:40:17,680 --> 00:40:21,520
for different congestion control

1031
00:40:19,040 --> 00:40:22,560
algorithms when we apply our network

1032
00:40:21,520 --> 00:40:25,359
profile

1033
00:40:22,560 --> 00:40:25,779
so as we can see uh all these graphs

1034
00:40:25,359 --> 00:40:26,880
have

1035
00:40:25,780 --> 00:40:29,520
[Music]

1036
00:40:26,880 --> 00:40:30,960
reasonably distinct shapes and in fact

1037
00:40:29,520 --> 00:40:33,839
our classifier

1038
00:40:30,960 --> 00:40:35,760
uses a decision uh tree based classifier

1039
00:40:33,839 --> 00:40:37,440
that uses these distinct shapes to

1040
00:40:35,760 --> 00:40:39,040
identify different congestion control

1041
00:40:37,440 --> 00:40:42,800
algorithms

1042
00:40:39,040 --> 00:40:44,480
again how this classifier exactly works

1043
00:40:42,800 --> 00:40:46,720
you can find more details about that in

1044
00:40:44,480 --> 00:40:52,560
the paper

1045
00:40:46,720 --> 00:40:54,560
next slide please so now

1046
00:40:52,560 --> 00:40:56,078
uh i'll cover the measurement results

1047
00:40:54,560 --> 00:40:59,440
for our measurement study

1048
00:40:56,079 --> 00:41:01,680
and let's start with accuracy next slide

1049
00:40:59,440 --> 00:41:01,680
please

1050
00:41:01,920 --> 00:41:05,920
so to measure the accuracy of gordon uh

1051
00:41:04,240 --> 00:41:06,640
what we did was we set up control

1052
00:41:05,920 --> 00:41:09,200
servers

1053
00:41:06,640 --> 00:41:10,240
in various locations on the internet and

1054
00:41:09,200 --> 00:41:12,799
we measured them

1055
00:41:10,240 --> 00:41:15,040
via a local server in the lab and later

1056
00:41:12,800 --> 00:41:17,520
on we reversed this configuration

1057
00:41:15,040 --> 00:41:18,480
by with our local server acting as a

1058
00:41:17,520 --> 00:41:20,400
control server

1059
00:41:18,480 --> 00:41:22,400
and we made gordon run in various

1060
00:41:20,400 --> 00:41:24,560
machines around the globe

1061
00:41:22,400 --> 00:41:25,839
and what we've seen is that our

1062
00:41:24,560 --> 00:41:27,920
shape-based

1063
00:41:25,839 --> 00:41:29,040
decision tree based classifier works

1064
00:41:27,920 --> 00:41:32,550
reasonably well

1065
00:41:29,040 --> 00:41:33,759
to identify a bulk of the algorithms and

1066
00:41:32,550 --> 00:41:37,280
[Music]

1067
00:41:33,760 --> 00:41:39,440
any misidentifications uh that we see

1068
00:41:37,280 --> 00:41:41,599
are basically between algorithms that

1069
00:41:39,440 --> 00:41:45,839
have a very similar congestion

1070
00:41:41,599 --> 00:41:48,960
of congestion window evolution shapes

1071
00:41:45,839 --> 00:41:50,960
which is something that we expected but

1072
00:41:48,960 --> 00:41:52,400
even given that we can see that for most

1073
00:41:50,960 --> 00:41:55,839
of our identifications

1074
00:41:52,400 --> 00:41:55,839
the accuracy is more than 90

1075
00:41:56,640 --> 00:41:59,440
next slide please

1076
00:42:00,720 --> 00:42:04,720
so the measurements of the websites

1077
00:42:02,400 --> 00:42:06,000
themselves uh were made from servers in

1078
00:42:04,720 --> 00:42:09,680
singapore mumbai

1079
00:42:06,000 --> 00:42:11,920
paris sao paulo and ohio and uh for the

1080
00:42:09,680 --> 00:42:12,640
websites uh given our network profile we

1081
00:42:11,920 --> 00:42:15,200
found that

1082
00:42:12,640 --> 00:42:16,160
16 of the pages were less than the

1083
00:42:15,200 --> 00:42:19,359
optimal

1084
00:42:16,160 --> 00:42:20,960
uh page size of 165 kb so basically

1085
00:42:19,359 --> 00:42:24,400
based on our network profile

1086
00:42:20,960 --> 00:42:25,359
we calculated um you know in the worst

1087
00:42:24,400 --> 00:42:26,960
case scenario

1088
00:42:25,359 --> 00:42:29,040
what is the minimum page size that we

1089
00:42:26,960 --> 00:42:31,359
need uh to get a

1090
00:42:29,040 --> 00:42:32,400
reasonably long event graph that we can

1091
00:42:31,359 --> 00:42:35,680
identify

1092
00:42:32,400 --> 00:42:37,839
so it turned out this number was 165 kb

1093
00:42:35,680 --> 00:42:39,200
but 68 of the pages we measured were

1094
00:42:37,839 --> 00:42:40,640
lower than this number

1095
00:42:39,200 --> 00:42:42,160
so in case they were lower than this

1096
00:42:40,640 --> 00:42:44,160
number what we did was we did a

1097
00:42:42,160 --> 00:42:45,200
classification and our best effort basis

1098
00:42:44,160 --> 00:42:48,078
which is that

1099
00:42:45,200 --> 00:42:49,040
if we could make identification we went

1100
00:42:48,079 --> 00:42:51,040
ahead with it

1101
00:42:49,040 --> 00:42:54,319
but if you couldn't then it was just

1102
00:42:51,040 --> 00:42:54,319
classified as a short flow

1103
00:42:54,400 --> 00:42:57,760
we also found out that about 1400

1104
00:42:56,560 --> 00:43:00,880
websites

1105
00:42:57,760 --> 00:43:03,680
among the top 20k alexa websites were

1106
00:43:00,880 --> 00:43:05,200
unresponsive to our rather aggressive

1107
00:43:03,680 --> 00:43:06,879
measurement methodology

1108
00:43:05,200 --> 00:43:09,040
so i'm going to be referring to these

1109
00:43:06,880 --> 00:43:11,520
websites as unresponsive websites for

1110
00:43:09,040 --> 00:43:14,720
rest of the presentation

1111
00:43:11,520 --> 00:43:14,720
uh next slide please

1112
00:43:15,839 --> 00:43:19,839
so in terms of the distribution of the

1113
00:43:18,000 --> 00:43:22,960
congestion control algorithms

1114
00:43:19,839 --> 00:43:23,520
in terms of website count uh what we

1115
00:43:22,960 --> 00:43:26,880
found

1116
00:43:23,520 --> 00:43:28,400
is that cubic is still the most dominant

1117
00:43:26,880 --> 00:43:31,440
congestion control algorithm

1118
00:43:28,400 --> 00:43:33,599
on the internet and we measured it being

1119
00:43:31,440 --> 00:43:37,040
deployed by 30.7

1120
00:43:33,599 --> 00:43:39,280
of the measured websites however

1121
00:43:37,040 --> 00:43:40,160
uh it looks like bbr has been adopted at

1122
00:43:39,280 --> 00:43:43,280
an unprecedented

1123
00:43:40,160 --> 00:43:43,920
rate since its introduction in 2016 and

1124
00:43:43,280 --> 00:43:46,960
it's now

1125
00:43:43,920 --> 00:43:50,000
accounting for almost 18 of the

1126
00:43:46,960 --> 00:43:52,079
top 20 000 alexa websites we also

1127
00:43:50,000 --> 00:43:53,040
identified a slightly modified version

1128
00:43:52,079 --> 00:43:55,280
of pvr

1129
00:43:53,040 --> 00:43:56,079
being deployed by 167 google owned

1130
00:43:55,280 --> 00:43:57,839
domains

1131
00:43:56,079 --> 00:43:59,440
and you will be referring to this

1132
00:43:57,839 --> 00:44:03,440
slightly different variant

1133
00:43:59,440 --> 00:44:05,599
as pbr the other significant shares

1134
00:44:03,440 --> 00:44:07,680
in the congestion control landscape

1135
00:44:05,599 --> 00:44:08,560
belong to congestion control algorithms

1136
00:44:07,680 --> 00:44:11,839
like

1137
00:44:08,560 --> 00:44:15,759
ctcp illinois vegas htcp

1138
00:44:11,839 --> 00:44:17,839
and uh yet another high-speed tcp

1139
00:44:15,760 --> 00:44:19,440
there was also a significantly large

1140
00:44:17,839 --> 00:44:21,520
chunk of websites that

1141
00:44:19,440 --> 00:44:22,960
gordon was not able to classify or

1142
00:44:21,520 --> 00:44:25,040
classified as unknown

1143
00:44:22,960 --> 00:44:29,040
so we'll have a closer look at these

1144
00:44:25,040 --> 00:44:29,040
websites later on in the presentation

1145
00:44:29,520 --> 00:44:32,319
next slide please

1146
00:44:33,920 --> 00:44:38,400
so given our numbers uh from

1147
00:44:36,960 --> 00:44:40,160
the distribution based on just the

1148
00:44:38,400 --> 00:44:42,640
website accounts themselves

1149
00:44:40,160 --> 00:44:44,000
um i don't think that really gives us a

1150
00:44:42,640 --> 00:44:46,400
complete picture because

1151
00:44:44,000 --> 00:44:48,160
not all websites are made equal and it's

1152
00:44:46,400 --> 00:44:49,599
likely that more popular websites are

1153
00:44:48,160 --> 00:44:50,720
contributing more traffic to the

1154
00:44:49,599 --> 00:44:52,480
internet

1155
00:44:50,720 --> 00:44:54,879
so for this what we did was we just

1156
00:44:52,480 --> 00:44:56,880
looked at the top 250 alexa websites

1157
00:44:54,880 --> 00:44:58,640
and when we do that it looks like ppr

1158
00:44:56,880 --> 00:44:59,520
overtakes cubic as the most dominant

1159
00:44:58,640 --> 00:45:02,640
algorithm

1160
00:44:59,520 --> 00:45:04,800
in the websites uh that matter

1161
00:45:02,640 --> 00:45:07,279
we also noticed that a significant

1162
00:45:04,800 --> 00:45:10,560
number of the website that deployed pbr

1163
00:45:07,280 --> 00:45:12,800
um served video content however

1164
00:45:10,560 --> 00:45:14,560
uh i should note here that it's not

1165
00:45:12,800 --> 00:45:16,160
necessary for these websites to be

1166
00:45:14,560 --> 00:45:18,319
deploying dpr for

1167
00:45:16,160 --> 00:45:20,560
delivering video as well since our

1168
00:45:18,319 --> 00:45:23,119
measurements were made on static http

1169
00:45:20,560 --> 00:45:25,200
web pages

1170
00:45:23,119 --> 00:45:26,480
uh but that said even if you just

1171
00:45:25,200 --> 00:45:30,000
consider the static

1172
00:45:26,480 --> 00:45:32,240
http web pages vbr is still contributing

1173
00:45:30,000 --> 00:45:34,880
uh significantly to the downstream

1174
00:45:32,240 --> 00:45:34,879
private chair

1175
00:45:35,200 --> 00:45:38,960
um another thing i would like to note uh

1176
00:45:38,079 --> 00:45:41,520
circling back

1177
00:45:38,960 --> 00:45:43,200
to there being a difference between the

1178
00:45:41,520 --> 00:45:45,280
video congestion control algorithm and

1179
00:45:43,200 --> 00:45:46,399
the http webpage congestion control

1180
00:45:45,280 --> 00:45:48,640
algorithm

1181
00:45:46,400 --> 00:45:49,760
uh gordon actually identified

1182
00:45:48,640 --> 00:45:51,920
netflix.com

1183
00:45:49,760 --> 00:45:54,160
to be using cubic to serve its web pages

1184
00:45:51,920 --> 00:45:57,200
but when we actually reached out to

1185
00:45:54,160 --> 00:46:01,040
netflix um it turns out they actually

1186
00:45:57,200 --> 00:46:04,078
use new reno to deliver video

1187
00:46:01,040 --> 00:46:04,079
uh next slide please

1188
00:46:05,200 --> 00:46:09,279
so coming back to the unclassified

1189
00:46:07,280 --> 00:46:10,240
variants we found a significant number

1190
00:46:09,280 --> 00:46:12,880
of websites that

1191
00:46:10,240 --> 00:46:13,279
gordon was not able to identify so to

1192
00:46:12,880 --> 00:46:15,359
just

1193
00:46:13,280 --> 00:46:17,200
uh to investigate further what we did

1194
00:46:15,359 --> 00:46:17,839
was we re-ran experiments on these

1195
00:46:17,200 --> 00:46:20,960
websites

1196
00:46:17,839 --> 00:46:23,359
and it used a variety of different uh

1197
00:46:20,960 --> 00:46:24,720
network profiles to see how differently

1198
00:46:23,359 --> 00:46:27,598
they react

1199
00:46:24,720 --> 00:46:29,359
so in the measured websites about 14 of

1200
00:46:27,599 --> 00:46:30,400
them were either short flows that we

1201
00:46:29,359 --> 00:46:33,680
discussed earlier

1202
00:46:30,400 --> 00:46:35,200
or did not respond to our measurement

1203
00:46:33,680 --> 00:46:36,879
methodology

1204
00:46:35,200 --> 00:46:38,879
but of the remaining websites that did

1205
00:46:36,880 --> 00:46:40,079
actually respond and give us long enough

1206
00:46:38,880 --> 00:46:42,560
even graphs

1207
00:46:40,079 --> 00:46:44,400
we found that most of them are reactive

1208
00:46:42,560 --> 00:46:48,319
packet losses but a significant number

1209
00:46:44,400 --> 00:46:48,319
of them do not reactivate losses

1210
00:46:48,720 --> 00:46:52,959
we were also able to identify a variant

1211
00:46:51,440 --> 00:46:55,520
run by websites that were

1212
00:46:52,960 --> 00:46:57,280
hosted by akamai and i'll be calling

1213
00:46:55,520 --> 00:47:00,000
this period akamai cc

1214
00:46:57,280 --> 00:47:02,640
for the rest of the presentation uh next

1215
00:47:00,000 --> 00:47:02,640
slide please

1216
00:47:03,839 --> 00:47:07,119
so arkham cc on its own uh turned out to

1217
00:47:06,800 --> 00:47:08,640
be

1218
00:47:07,119 --> 00:47:11,119
quite an interesting digestion control

1219
00:47:08,640 --> 00:47:14,319
variant from its reaction to

1220
00:47:11,119 --> 00:47:16,880
various network profiles what we found

1221
00:47:14,319 --> 00:47:19,599
was that it did not react to packet loss

1222
00:47:16,880 --> 00:47:23,440
but it closely followed whatever

1223
00:47:19,599 --> 00:47:25,520
pdp was emulated by gordon we feel that

1224
00:47:23,440 --> 00:47:26,960
it's likely that this radiant uh this is

1225
00:47:25,520 --> 00:47:29,599
a variant of uh

1226
00:47:26,960 --> 00:47:31,680
fast tcp there were some other

1227
00:47:29,599 --> 00:47:32,000
interesting uh cbn evolution crafts that

1228
00:47:31,680 --> 00:47:34,720
we

1229
00:47:32,000 --> 00:47:36,400
found as well so for example uh on your

1230
00:47:34,720 --> 00:47:38,240
right you can see amazon.com

1231
00:47:36,400 --> 00:47:40,000
which ran a in that did not really

1232
00:47:38,240 --> 00:47:43,359
respond to our

1233
00:47:40,000 --> 00:47:46,800
uh emulated packet loss and showed

1234
00:47:43,359 --> 00:47:49,839
uh htc uh htcp like uh behavior in the

1235
00:47:46,800 --> 00:47:53,040
congestion avoidance phase

1236
00:47:49,839 --> 00:47:55,040
uh yahoo.coda jp was quite conservative

1237
00:47:53,040 --> 00:47:56,720
uh and seemed to exit slow start even

1238
00:47:55,040 --> 00:47:58,558
before it saw package laws were

1239
00:47:56,720 --> 00:48:00,799
saturated the pdp

1240
00:47:58,559 --> 00:48:03,200
uh and on the other hand zero.com was on

1241
00:48:00,800 --> 00:48:05,200
the exact end of the spectrum

1242
00:48:03,200 --> 00:48:07,359
other end of the spectrum which is to

1243
00:48:05,200 --> 00:48:07,919
say that it did not respond to packet

1244
00:48:07,359 --> 00:48:10,160
losses

1245
00:48:07,920 --> 00:48:12,880
or changes in bandwidth it just seemed

1246
00:48:10,160 --> 00:48:20,160
to keep 200 packets in flight

1247
00:48:12,880 --> 00:48:22,960
all the time next slide please

1248
00:48:20,160 --> 00:48:24,960
in summary uh what i think uh we are

1249
00:48:22,960 --> 00:48:26,079
seeing is essentially a paradigm shift

1250
00:48:24,960 --> 00:48:27,440
in internet

1251
00:48:26,079 --> 00:48:29,920
in the internet congestion control

1252
00:48:27,440 --> 00:48:30,960
landscape so similar to the transition

1253
00:48:29,920 --> 00:48:35,839
that we have seen

1254
00:48:30,960 --> 00:48:37,680
um earlier on between a and d and mind

1255
00:48:35,839 --> 00:48:39,599
a sizeable chunk of the internet traffic

1256
00:48:37,680 --> 00:48:42,720
today is being controlled by these

1257
00:48:39,599 --> 00:48:43,520
rate-based algorithms like dpi and we

1258
00:48:42,720 --> 00:48:45,200
feel this

1259
00:48:43,520 --> 00:48:46,720
really further underlines the importance

1260
00:48:45,200 --> 00:48:49,359
of understanding the interactions

1261
00:48:46,720 --> 00:48:51,839
between these two different uh schools

1262
00:48:49,359 --> 00:48:54,160
of doing conduction control

1263
00:48:51,839 --> 00:48:57,200
and mitigating any unfairness and

1264
00:48:54,160 --> 00:48:57,200
coexisting issues

1265
00:48:57,760 --> 00:49:00,559
next slide please

1266
00:49:01,760 --> 00:49:04,800
so given that we are seeing such a

1267
00:49:03,280 --> 00:49:06,559
fast-paced uh

1268
00:49:04,800 --> 00:49:07,920
we're seeing such fast previous changes

1269
00:49:06,559 --> 00:49:08,880
in the internet congestion control

1270
00:49:07,920 --> 00:49:11,520
landscape

1271
00:49:08,880 --> 00:49:12,079
uh we would want to make some changes to

1272
00:49:11,520 --> 00:49:15,359
gordon

1273
00:49:12,079 --> 00:49:18,480
to keep up with these changes uh so

1274
00:49:15,359 --> 00:49:20,400
primary among these is identifying newer

1275
00:49:18,480 --> 00:49:24,079
congestion control algorithms

1276
00:49:20,400 --> 00:49:26,400
so for example since ppi we have seen uh

1277
00:49:24,079 --> 00:49:28,480
we have seen proposals for variants like

1278
00:49:26,400 --> 00:49:31,200
copper and pcc we're watching

1279
00:49:28,480 --> 00:49:33,280
which are also rate-based and ideally we

1280
00:49:31,200 --> 00:49:35,279
would like to identify them as well

1281
00:49:33,280 --> 00:49:36,559
so since the measurement study we have

1282
00:49:35,280 --> 00:49:41,280
extended gordon to

1283
00:49:36,559 --> 00:49:43,359
measure the received rate along with the

1284
00:49:41,280 --> 00:49:45,599
sea wind and turns out receive rate is

1285
00:49:43,359 --> 00:49:47,839
quite handy to differentiate between

1286
00:49:45,599 --> 00:49:50,160
i mean not just differentiate that

1287
00:49:47,839 --> 00:49:53,359
identify copa and pcc privacy

1288
00:49:50,160 --> 00:49:55,759
uh in controlled experiments um

1289
00:49:53,359 --> 00:49:57,920
lastly we would also want god to emulate

1290
00:49:55,760 --> 00:49:59,760
a larger variety of networks stimuli so

1291
00:49:57,920 --> 00:50:01,040
for example there might be slightly

1292
00:49:59,760 --> 00:50:04,000
modified

1293
00:50:01,040 --> 00:50:06,240
versions of qubit or renault that don't

1294
00:50:04,000 --> 00:50:08,319
respond to one packet loss but

1295
00:50:06,240 --> 00:50:09,919
two or three packet losses that we are

1296
00:50:08,319 --> 00:50:13,119
not able to emulate and therefore

1297
00:50:09,920 --> 00:50:15,520
we're not able to identify them and

1298
00:50:13,119 --> 00:50:17,839
we would also want gordon to identify

1299
00:50:15,520 --> 00:50:19,520
sub-rtt behaviors since right now we are

1300
00:50:17,839 --> 00:50:22,799
constrained to measuring just a

1301
00:50:19,520 --> 00:50:27,839
per rtt seventh

1302
00:50:22,800 --> 00:50:27,839
next slide please

1303
00:50:29,200 --> 00:50:32,319
so i would like to end this talk uh with

1304
00:50:31,599 --> 00:50:34,400
some

1305
00:50:32,319 --> 00:50:36,319
with two high-level research questions

1306
00:50:34,400 --> 00:50:36,960
that our research group has been dealing

1307
00:50:36,319 --> 00:50:39,440
with since

1308
00:50:36,960 --> 00:50:41,200
our measurement study so the first is

1309
00:50:39,440 --> 00:50:43,440
really understanding how ppr

1310
00:50:41,200 --> 00:50:45,520
and cubic will cope with this evolving

1311
00:50:43,440 --> 00:50:47,359
congestion control landscape

1312
00:50:45,520 --> 00:50:49,359
while there has been plenty of work that

1313
00:50:47,359 --> 00:50:50,720
indicates pbr can be unfair to cubic in

1314
00:50:49,359 --> 00:50:54,000
some scenarios

1315
00:50:50,720 --> 00:50:55,919
uh this congestion control evolution

1316
00:50:54,000 --> 00:50:58,160
is unlikely to be a walk in the park for

1317
00:50:55,920 --> 00:51:00,800
ppr either

1318
00:50:58,160 --> 00:51:02,558
so uh we have done a lot of interesting

1319
00:51:00,800 --> 00:51:04,319
work in this front and i will not go

1320
00:51:02,559 --> 00:51:05,200
into the details of it in the interest

1321
00:51:04,319 --> 00:51:07,200
of time

1322
00:51:05,200 --> 00:51:08,799
but allow me to illustrate one of our

1323
00:51:07,200 --> 00:51:10,319
key results through a very simple

1324
00:51:08,800 --> 00:51:12,480
experiment

1325
00:51:10,319 --> 00:51:13,759
so we ran multiple instances of tent

1326
00:51:12,480 --> 00:51:17,520
flow experiments

1327
00:51:13,760 --> 00:51:18,079
uh with different shares of them running

1328
00:51:17,520 --> 00:51:20,880
dbr

1329
00:51:18,079 --> 00:51:22,319
and cubic so first we had only one bpr

1330
00:51:20,880 --> 00:51:24,640
and nine cubic first

1331
00:51:22,319 --> 00:51:25,920
or the second trial we introduced bbr2

1332
00:51:24,640 --> 00:51:29,520
and we kept on doing this

1333
00:51:25,920 --> 00:51:32,319
uh till all our flows for pbi

1334
00:51:29,520 --> 00:51:33,520
and the graph on the right plots all the

1335
00:51:32,319 --> 00:51:36,240
bbr flows

1336
00:51:33,520 --> 00:51:38,000
overflow average throughput as compared

1337
00:51:36,240 --> 00:51:40,240
to the fair share

1338
00:51:38,000 --> 00:51:42,319
in that scenario which is indicated by

1339
00:51:40,240 --> 00:51:45,040
the dotted line

1340
00:51:42,319 --> 00:51:46,319
so what we see is that as you slowly

1341
00:51:45,040 --> 00:51:49,359
increase the number of

1342
00:51:46,319 --> 00:51:51,200
pbr flows at the bottleneck the buffalo

1343
00:51:49,359 --> 00:51:53,680
average throughput of ppr

1344
00:51:51,200 --> 00:51:54,879
drops very sharply in fact at one point

1345
00:51:53,680 --> 00:51:57,839
it even goes

1346
00:51:54,880 --> 00:51:59,119
um below the pressure for that

1347
00:51:57,839 --> 00:52:01,440
bottleneck

1348
00:51:59,119 --> 00:52:02,319
so the main coin that i'm going that i'm

1349
00:52:01,440 --> 00:52:05,760
trying to drive

1350
00:52:02,319 --> 00:52:06,960
from this graph is that um if bpr is

1351
00:52:05,760 --> 00:52:10,000
working really well today

1352
00:52:06,960 --> 00:52:12,240
does not mean dpr will be the obvious

1353
00:52:10,000 --> 00:52:15,359
choice against cubic tomorrow

1354
00:52:12,240 --> 00:52:17,279
uh both for bbr and cubic uh the

1355
00:52:15,359 --> 00:52:19,119
performance is likely to be a function

1356
00:52:17,280 --> 00:52:21,599
of what the congestion control landscape

1357
00:52:19,119 --> 00:52:21,599
looks like

1358
00:52:21,839 --> 00:52:33,920
next slide please

1359
00:52:32,400 --> 00:52:35,520
the second research question we're

1360
00:52:33,920 --> 00:52:37,520
trying to look at

1361
00:52:35,520 --> 00:52:39,040
is understanding the database congestion

1362
00:52:37,520 --> 00:52:41,680
control mechanic

1363
00:52:39,040 --> 00:52:42,960
so bpr and other new internet congestion

1364
00:52:41,680 --> 00:52:44,640
control algorithms

1365
00:52:42,960 --> 00:52:46,319
that have been proposed since have been

1366
00:52:44,640 --> 00:52:48,640
predominantly replaced

1367
00:52:46,319 --> 00:52:49,839
examples of this would be coppa and pcc

1368
00:52:48,640 --> 00:52:52,480
we're watching

1369
00:52:49,839 --> 00:52:54,078
and it's quite common for these

1370
00:52:52,480 --> 00:52:56,480
algorithms to work on

1371
00:52:54,079 --> 00:52:57,839
type send rate and receive rate feedback

1372
00:52:56,480 --> 00:53:00,480
loops to

1373
00:52:57,839 --> 00:53:01,680
basically inform what's going on at the

1374
00:53:00,480 --> 00:53:04,000
bottleneck

1375
00:53:01,680 --> 00:53:05,839
we feel that this is a new congestion

1376
00:53:04,000 --> 00:53:08,400
control mechanic that's still not

1377
00:53:05,839 --> 00:53:10,319
uh completely understood and what we

1378
00:53:08,400 --> 00:53:12,559
essentially need to do is we need to

1379
00:53:10,319 --> 00:53:14,000
be answer some of the key congestion

1380
00:53:12,559 --> 00:53:16,720
patrol questions

1381
00:53:14,000 --> 00:53:18,400
like on convergence and fairness will be

1382
00:53:16,720 --> 00:53:20,558
in the rate-based setting

1383
00:53:18,400 --> 00:53:21,680
so in this direction we are working on

1384
00:53:20,559 --> 00:53:24,960
modeling such

1385
00:53:21,680 --> 00:53:26,799
um send rate and receive

1386
00:53:24,960 --> 00:53:29,520
these feedback loops and trying to

1387
00:53:26,800 --> 00:53:32,319
understand how they work

1388
00:53:29,520 --> 00:53:32,319
next slide please

1389
00:53:36,400 --> 00:53:40,559
yes and that's all i have for you today

1390
00:53:39,040 --> 00:53:43,839
uh thank you for your time and i'll be

1391
00:53:40,559 --> 00:53:43,839
happy to take any questions

1392
00:53:46,960 --> 00:53:50,559
all right we have time for very quick

1393
00:53:49,599 --> 00:53:53,040
few questions

1394
00:53:50,559 --> 00:53:54,800
um if you could try to keep this brief

1395
00:53:53,040 --> 00:53:56,480
that would be very much appreciated

1396
00:53:54,800 --> 00:53:57,920
but thank you so much ayush this is

1397
00:53:56,480 --> 00:53:58,960
excellent work and i'm really glad to

1398
00:53:57,920 --> 00:54:00,800
finally see it

1399
00:53:58,960 --> 00:54:04,240
in iccrg despite the fact that we were

1400
00:54:00,800 --> 00:54:04,240
trying to have it here six months ago

1401
00:54:07,920 --> 00:54:13,800
um i just thank for the work um

1402
00:54:10,960 --> 00:54:15,040
it's really interesting i think uh

1403
00:54:13,800 --> 00:54:18,800
categorizing

1404
00:54:15,040 --> 00:54:22,720
uh cubic um as a mimd

1405
00:54:18,800 --> 00:54:25,200
uh may be um not very precise

1406
00:54:22,720 --> 00:54:27,439
because uh cubic actually runs this sort

1407
00:54:25,200 --> 00:54:30,240
of tcp friendly mode

1408
00:54:27,440 --> 00:54:32,160
you'll be good to know that how often

1409
00:54:30,240 --> 00:54:33,439
the cubic internet connections are

1410
00:54:32,160 --> 00:54:36,160
actually in this

1411
00:54:33,440 --> 00:54:37,040
region because in that mode it's really

1412
00:54:36,160 --> 00:54:40,960
just running

1413
00:54:37,040 --> 00:54:43,200
know so yeah

1414
00:54:40,960 --> 00:54:44,160
yeah so yeah i think that's a really

1415
00:54:43,200 --> 00:54:46,000
interesting point

1416
00:54:44,160 --> 00:54:47,359
and i think that's a little

1417
00:54:46,000 --> 00:54:50,720
short-sighted on my

1418
00:54:47,359 --> 00:54:51,680
um my half so cuba i agree that cubic

1419
00:54:50,720 --> 00:54:55,439
can actually

1420
00:54:51,680 --> 00:54:57,598
be both mi and d and aimd but as far as

1421
00:54:55,440 --> 00:54:58,720
uh actually measuring how often it does

1422
00:54:57,599 --> 00:55:00,640
this on the internet

1423
00:54:58,720 --> 00:55:02,319
i don't think it would be possible to do

1424
00:55:00,640 --> 00:55:05,040
this without current tool

1425
00:55:02,319 --> 00:55:06,160
since we essentially isolate the flow we

1426
00:55:05,040 --> 00:55:06,880
are measuring in the localized

1427
00:55:06,160 --> 00:55:08,720
bottleneck

1428
00:55:06,880 --> 00:55:11,040
so it's really not competing with other

1429
00:55:08,720 --> 00:55:11,040
flows

1430
00:55:16,400 --> 00:55:21,839
thank you praveen you're next

1431
00:55:23,440 --> 00:55:27,839
uh great work uh thanks for presenting

1432
00:55:25,440 --> 00:55:29,839
this uh one question i had was any early

1433
00:55:27,839 --> 00:55:33,440
thoughts on being able to distinguish

1434
00:55:29,839 --> 00:55:36,400
bbr uh and bbrv too

1435
00:55:33,440 --> 00:55:37,760
okay so uh we did actually plot out

1436
00:55:36,400 --> 00:55:40,720
graphs for ppr and

1437
00:55:37,760 --> 00:55:42,720
uh dpi v2 as well they have very

1438
00:55:40,720 --> 00:55:44,240
distinct congestion window responses

1439
00:55:42,720 --> 00:55:48,078
but the problem they are having right

1440
00:55:44,240 --> 00:55:51,359
now is that dpr v2 is congestion

1441
00:55:48,079 --> 00:55:54,880
window response is not consistent so

1442
00:55:51,359 --> 00:55:56,000
given pbr and dvr v2 we can distinguish

1443
00:55:54,880 --> 00:55:58,640
between them but

1444
00:55:56,000 --> 00:56:01,200
given ddr v2 and some noisy measurement

1445
00:55:58,640 --> 00:56:03,920
on the internet we are not able to pick

1446
00:56:01,200 --> 00:56:04,399
whether it's dpip2 or not so we need to

1447
00:56:03,920 --> 00:56:06,799
do

1448
00:56:04,400 --> 00:56:08,000
a significant amount amount of work in

1449
00:56:06,799 --> 00:56:17,839
that direction to

1450
00:56:08,000 --> 00:56:17,839
be able to make this distinction

1451
00:56:19,450 --> 00:56:23,839
[Music]

1452
00:56:20,640 --> 00:56:23,839
jonathan you're next

1453
00:56:24,079 --> 00:56:30,799
uh thank you um are you planning to

1454
00:56:27,680 --> 00:56:33,759
incorporate ecn response characteristics

1455
00:56:30,799 --> 00:56:33,759
into your research

1456
00:56:33,839 --> 00:56:37,599
uh that's actually an interesting idea

1457
00:56:36,000 --> 00:56:40,960
but we have

1458
00:56:37,599 --> 00:56:42,720
not done this so far but

1459
00:56:40,960 --> 00:56:44,079
that's definitely a direction we would

1460
00:56:42,720 --> 00:56:47,040
like to look into

1461
00:56:44,079 --> 00:56:47,920
so i mean not only just excellent but

1462
00:56:47,040 --> 00:56:50,880
possibly

1463
00:56:47,920 --> 00:56:52,000
later on being able to classify uh quick

1464
00:56:50,880 --> 00:56:54,319
connections as well

1465
00:56:52,000 --> 00:56:55,839
so those are the two key uh directions

1466
00:56:54,319 --> 00:56:59,119
that we have not

1467
00:56:55,839 --> 00:57:00,960
um specifically looked into so far but

1468
00:56:59,119 --> 00:57:03,359
he definitely would like to look into in

1469
00:57:00,960 --> 00:57:03,359
the future

1470
00:57:03,760 --> 00:57:06,400
all right thank you

1471
00:57:07,440 --> 00:57:10,319
well thank you everyone for your

1472
00:57:08,640 --> 00:57:12,078
questions and thank you ayush again for

1473
00:57:10,319 --> 00:57:14,079
presenting this

1474
00:57:12,079 --> 00:57:16,559
i'm assuming that you're going to be uh

1475
00:57:14,079 --> 00:57:19,599
subscribed to the iccrg mailing list

1476
00:57:16,559 --> 00:57:20,559
yes yes okay excellent so if people if

1477
00:57:19,599 --> 00:57:22,960
you have questions

1478
00:57:20,559 --> 00:57:23,920
take it to the list please uh i wish

1479
00:57:22,960 --> 00:57:25,280
we'll be there on the list

1480
00:57:23,920 --> 00:57:27,359
and you can also give him more

1481
00:57:25,280 --> 00:57:28,960
suggestions for what he could do

1482
00:57:27,359 --> 00:57:30,400
to continue this work because i think

1483
00:57:28,960 --> 00:57:32,960
this is very useful work and

1484
00:57:30,400 --> 00:57:34,640
its use is also in being able to uh find

1485
00:57:32,960 --> 00:57:35,680
out how the internet is changing as time

1486
00:57:34,640 --> 00:57:40,558
goes

1487
00:57:35,680 --> 00:57:44,319
so thank you again thank you

1488
00:57:40,559 --> 00:57:47,440
moving on uh we have neil

1489
00:57:44,319 --> 00:57:49,839
uh neil uh to

1490
00:57:47,440 --> 00:57:51,280
to defend why bbr v2 might not actually

1491
00:57:49,839 --> 00:57:55,200
be noise

1492
00:57:51,280 --> 00:57:57,920
as is but i'll leave that for you

1493
00:57:55,200 --> 00:58:01,040
to do neil take it away oh actually let

1494
00:57:57,920 --> 00:58:01,040
me get you your slides first

1495
00:58:02,160 --> 00:58:08,078
there we go all right take it away sir

1496
00:58:05,280 --> 00:58:09,359
all right great uh thanks jana so uh i'd

1497
00:58:08,079 --> 00:58:12,480
like to give a quick

1498
00:58:09,359 --> 00:58:14,480
update on some bbr work at google

1499
00:58:12,480 --> 00:58:16,240
uh this is joint work with my colleagues

1500
00:58:14,480 --> 00:58:18,799
at google listed there

1501
00:58:16,240 --> 00:58:19,279
including folks on the tcp team uh quick

1502
00:58:18,799 --> 00:58:24,640
team

1503
00:58:19,280 --> 00:58:24,640
and the swift team next slide please

1504
00:58:26,240 --> 00:58:30,640
so um in brief uh some aspects that i'd

1505
00:58:29,839 --> 00:58:34,558
like to cover

1506
00:58:30,640 --> 00:58:37,440
uh include a main focus on

1507
00:58:34,559 --> 00:58:38,720
some work that we're calling bbr swift

1508
00:58:37,440 --> 00:58:40,880
where we're looking at

1509
00:58:38,720 --> 00:58:43,200
using delay as a congestion signal

1510
00:58:40,880 --> 00:58:45,200
inside data centers

1511
00:58:43,200 --> 00:58:47,279
and then briefly i'd like to touch on a

1512
00:58:45,200 --> 00:58:51,200
second topic about

1513
00:58:47,280 --> 00:58:53,119
scalable loss recovery handling and

1514
00:58:51,200 --> 00:58:54,558
some of the considerations that we think

1515
00:58:53,119 --> 00:58:57,359
are kind of interesting

1516
00:58:54,559 --> 00:58:58,079
as we've looked at our experiences with

1517
00:58:57,359 --> 00:59:01,839
bbr

1518
00:58:58,079 --> 00:59:04,400
and prr and the question of how scalable

1519
00:59:01,839 --> 00:59:05,920
are these various um styles of

1520
00:59:04,400 --> 00:59:08,160
multiplicative decrease

1521
00:59:05,920 --> 00:59:09,440
uh when there are large decreases in the

1522
00:59:08,160 --> 00:59:11,040
available bandwidth

1523
00:59:09,440 --> 00:59:13,599
uh and then i'll do a quick summary of

1524
00:59:11,040 --> 00:59:17,279
the status of bbr at google and

1525
00:59:13,599 --> 00:59:19,359
a quick wrap up and just uh

1526
00:59:17,280 --> 00:59:20,319
just to sort of set the context here

1527
00:59:19,359 --> 00:59:23,359
about what we're

1528
00:59:20,319 --> 00:59:25,119
trying to aim for um for this talk we we

1529
00:59:23,359 --> 00:59:25,520
mainly wanted to share our experience

1530
00:59:25,119 --> 00:59:27,280
with

1531
00:59:25,520 --> 00:59:28,190
uh some of these experiments and

1532
00:59:27,280 --> 00:59:29,359
algorithms were

1533
00:59:28,190 --> 00:59:31,599
[Music]

1534
00:59:29,359 --> 00:59:32,960
trying out and we wanted wanted to

1535
00:59:31,599 --> 00:59:34,240
invite the community to share any

1536
00:59:32,960 --> 00:59:36,240
feedback you have

1537
00:59:34,240 --> 00:59:37,359
uh and of course always encourage you to

1538
00:59:36,240 --> 00:59:39,839
share any uh

1539
00:59:37,359 --> 00:59:40,400
test results or issues you see or

1540
00:59:39,839 --> 00:59:43,839
patches

1541
00:59:40,400 --> 00:59:47,680
traces or ideas generally uh

1542
00:59:43,839 --> 00:59:49,520
next slide please

1543
00:59:47,680 --> 00:59:51,919
so the first part of this talk will be

1544
00:59:49,520 --> 00:59:54,960
about what we're calling bbr swift

1545
00:59:51,920 --> 00:59:56,640
where we're using delay as a congestion

1546
00:59:54,960 --> 01:00:00,319
signal in the data center

1547
00:59:56,640 --> 01:00:03,359
next slide please

1548
01:00:00,319 --> 01:00:06,160
so um a little background here

1549
01:00:03,359 --> 01:00:08,319
for folks who haven't run into it um the

1550
01:00:06,160 --> 01:00:11,440
swift congestion control algorithm

1551
01:00:08,319 --> 01:00:12,240
uh is one that some of our colleagues at

1552
01:00:11,440 --> 01:00:16,000
google

1553
01:00:12,240 --> 01:00:18,319
uh recently published at sig com in 2020

1554
01:00:16,000 --> 01:00:20,240
and at a high level one of the

1555
01:00:18,319 --> 01:00:23,680
interesting aspects of the algorithm

1556
01:00:20,240 --> 01:00:24,558
is that it uses the network rtt and host

1557
01:00:23,680 --> 01:00:26,879
delays

1558
01:00:24,559 --> 01:00:28,000
as the primary congestion signals

1559
01:00:26,880 --> 01:00:31,440
although it also uses

1560
01:00:28,000 --> 01:00:32,799
loss it generally tends to try to keep

1561
01:00:31,440 --> 01:00:36,240
the queues low enough that

1562
01:00:32,799 --> 01:00:36,559
loss is quite rare and so the delays are

1563
01:00:36,240 --> 01:00:39,040
the

1564
01:00:36,559 --> 01:00:40,480
very much the primary signals and of

1565
01:00:39,040 --> 01:00:41,839
course um

1566
01:00:40,480 --> 01:00:45,119
you know this crowd will notice right

1567
01:00:41,839 --> 01:00:46,880
away that this use of network rtt means

1568
01:00:45,119 --> 01:00:49,119
that there are particular

1569
01:00:46,880 --> 01:00:50,400
scopes where this is an appropriate and

1570
01:00:49,119 --> 01:00:52,880
feasible algorithm

1571
01:00:50,400 --> 01:00:54,160
uh and in particular um this is

1572
01:00:52,880 --> 01:00:56,319
appropriate where

1573
01:00:54,160 --> 01:00:57,440
you're you have traffic that's inside a

1574
01:00:56,319 --> 01:01:00,079
network with a

1575
01:00:57,440 --> 01:01:01,119
unknown topology or a known rtt

1576
01:01:00,079 --> 01:01:03,680
properties

1577
01:01:01,119 --> 01:01:05,119
um which applies to a lot of today's

1578
01:01:03,680 --> 01:01:08,160
data centers which have

1579
01:01:05,119 --> 01:01:11,599
very regular topologies where the

1580
01:01:08,160 --> 01:01:14,640
operators know the expected rtts

1581
01:01:11,599 --> 01:01:15,680
another requirement here for scopes

1582
01:01:14,640 --> 01:01:20,078
where this makes sense

1583
01:01:15,680 --> 01:01:23,200
is that the network interface cards

1584
01:01:20,079 --> 01:01:26,480
support hardware timestamps

1585
01:01:23,200 --> 01:01:29,118
at least receive timestamps transmit

1586
01:01:26,480 --> 01:01:30,880
timestamps can also be useful uh and the

1587
01:01:29,119 --> 01:01:32,240
third requirement is that

1588
01:01:30,880 --> 01:01:34,799
uh all the traffic's sharing the

1589
01:01:32,240 --> 01:01:38,078
bottlenecks be swift compatible

1590
01:01:34,799 --> 01:01:41,200
um because the the algorithm uh

1591
01:01:38,079 --> 01:01:44,079
sort of requires that uh to behave well

1592
01:01:41,200 --> 01:01:45,439
and in terms of that algorithm i think

1593
01:01:44,079 --> 01:01:48,000
the two main points

1594
01:01:45,440 --> 01:01:48,880
uh that are interesting about swift are

1595
01:01:48,000 --> 01:01:52,240
that it's

1596
01:01:48,880 --> 01:01:54,880
uh it's using um a

1597
01:01:52,240 --> 01:01:56,640
fairly typical aim d that is additive

1598
01:01:54,880 --> 01:01:58,720
increase in multiplicative decrease

1599
01:01:56,640 --> 01:02:00,400
approach uh where the one of the

1600
01:01:58,720 --> 01:02:02,399
interesting aspects here is that the

1601
01:02:00,400 --> 01:02:05,599
multiplicative decrease

1602
01:02:02,400 --> 01:02:07,599
is proportional to the excess delay

1603
01:02:05,599 --> 01:02:09,200
and we'll talk about the details there

1604
01:02:07,599 --> 01:02:10,799
in a little bit

1605
01:02:09,200 --> 01:02:12,799
and then a second really interesting

1606
01:02:10,799 --> 01:02:16,400
aspect of the algorithm is that

1607
01:02:12,799 --> 01:02:18,079
when the congestion window is below 1

1608
01:02:16,400 --> 01:02:20,559
and it does support fractional

1609
01:02:18,079 --> 01:02:23,680
congestion window values

1610
01:02:20,559 --> 01:02:27,520
it accomplishes that by using pacing

1611
01:02:23,680 --> 01:02:30,720
so that the average number of packets

1612
01:02:27,520 --> 01:02:31,759
in the network is is fractional and that

1613
01:02:30,720 --> 01:02:35,359
allows it to handle

1614
01:02:31,760 --> 01:02:37,359
large scale multiplexing that is lots of

1615
01:02:35,359 --> 01:02:39,440
flows sharing a single bottleneck

1616
01:02:37,359 --> 01:02:41,680
which some people call in cast where you

1617
01:02:39,440 --> 01:02:43,119
may have hundreds thousands or even tens

1618
01:02:41,680 --> 01:02:47,038
of thousands of flows

1619
01:02:43,119 --> 01:02:48,319
sharing a a path that may have a bdp

1620
01:02:47,039 --> 01:02:50,640
that can only hold

1621
01:02:48,319 --> 01:02:52,000
a hundred packets or 200 packets

1622
01:02:50,640 --> 01:02:55,118
something like that

1623
01:02:52,000 --> 01:02:58,160
um so in terms of where

1624
01:02:55,119 --> 01:03:01,200
swift has been used so far um

1625
01:02:58,160 --> 01:03:02,960
it has been used in production inside

1626
01:03:01,200 --> 01:03:06,240
google data centers

1627
01:03:02,960 --> 01:03:07,039
by a a user space and networking stack

1628
01:03:06,240 --> 01:03:09,919
called

1629
01:03:07,039 --> 01:03:10,799
snap in the sosp publication about that

1630
01:03:09,920 --> 01:03:14,720
system

1631
01:03:10,799 --> 01:03:17,038
in uh sosp 2019

1632
01:03:14,720 --> 01:03:18,640
and this is used in uh for a significant

1633
01:03:17,039 --> 01:03:20,720
amount of traffic within google

1634
01:03:18,640 --> 01:03:21,920
data centers where this is an

1635
01:03:20,720 --> 01:03:24,720
appropriate uh

1636
01:03:21,920 --> 01:03:26,240
environment since a we we know the

1637
01:03:24,720 --> 01:03:28,959
target network rtt we're

1638
01:03:26,240 --> 01:03:30,000
aiming for and b we know that all the

1639
01:03:28,960 --> 01:03:33,039
other traffic

1640
01:03:30,000 --> 01:03:35,520
sharing the queue and then is

1641
01:03:33,039 --> 01:03:36,480
swift compatible and in this case we use

1642
01:03:35,520 --> 01:03:39,839
uh per

1643
01:03:36,480 --> 01:03:40,559
quality of service cues to accomplish

1644
01:03:39,839 --> 01:03:43,038
that

1645
01:03:40,559 --> 01:03:43,680
segregation of different algorithms into

1646
01:03:43,039 --> 01:03:47,520
different

1647
01:03:43,680 --> 01:03:47,520
cues next slide please

1648
01:03:47,839 --> 01:03:53,200
so um how so

1649
01:03:51,119 --> 01:03:54,640
why would we want to use delay as a

1650
01:03:53,200 --> 01:03:56,839
congestion signal

1651
01:03:54,640 --> 01:03:58,640
there are a couple different advantages

1652
01:03:56,839 --> 01:04:01,279
so um

1653
01:03:58,640 --> 01:04:02,799
the first sort of class of advantages is

1654
01:04:01,280 --> 01:04:04,960
that it provides a richer

1655
01:04:02,799 --> 01:04:07,359
source of information about how much

1656
01:04:04,960 --> 01:04:12,400
cueing is at the bottleneck

1657
01:04:07,359 --> 01:04:13,839
and this is um quite

1658
01:04:12,400 --> 01:04:16,240
interesting because it actually allows

1659
01:04:13,839 --> 01:04:18,640
you to to get a quantitative notion

1660
01:04:16,240 --> 01:04:19,279
of the current degree or magnitude of

1661
01:04:18,640 --> 01:04:20,720
queuing

1662
01:04:19,280 --> 01:04:23,440
which is something that you can't really

1663
01:04:20,720 --> 01:04:25,680
get from ecn or lost signals

1664
01:04:23,440 --> 01:04:28,079
and this is useful because this allows

1665
01:04:25,680 --> 01:04:30,960
you to react more quickly

1666
01:04:28,079 --> 01:04:32,319
in cases where there is a long queue to

1667
01:04:30,960 --> 01:04:35,280
get rid of that

1668
01:04:32,319 --> 01:04:36,640
cue more quickly and dissipate that

1669
01:04:35,280 --> 01:04:38,880
congestion more quickly

1670
01:04:36,640 --> 01:04:41,279
but also correspondingly it allows you

1671
01:04:38,880 --> 01:04:43,520
to avoid overreaction

1672
01:04:41,280 --> 01:04:44,319
and potential underutilization if the

1673
01:04:43,520 --> 01:04:48,240
queue is actually

1674
01:04:44,319 --> 01:04:50,799
short and you can think about that

1675
01:04:48,240 --> 01:04:52,640
ambiguity if you consider for example a

1676
01:04:50,799 --> 01:04:55,680
dc-tcp style

1677
01:04:52,640 --> 01:05:00,558
shallow threshold ecn signal where

1678
01:04:55,680 --> 01:05:01,440
you might have a a sustained ecn signal

1679
01:05:00,559 --> 01:05:04,480
that lasts

1680
01:05:01,440 --> 01:05:07,200
for quite a while um and

1681
01:05:04,480 --> 01:05:08,799
the you know an ewma filter of that

1682
01:05:07,200 --> 01:05:10,720
might

1683
01:05:08,799 --> 01:05:12,720
turn that into a very high alpha for

1684
01:05:10,720 --> 01:05:13,439
example but it's still quite possible

1685
01:05:12,720 --> 01:05:16,078
that that

1686
01:05:13,440 --> 01:05:17,280
q even though it has lasted a long time

1687
01:05:16,079 --> 01:05:19,280
is quite shallow

1688
01:05:17,280 --> 01:05:21,280
and so it's quite easy for an algorithm

1689
01:05:19,280 --> 01:05:23,039
to sort of overreact to that

1690
01:05:21,280 --> 01:05:24,319
whereas a delay signal allows you to

1691
01:05:23,039 --> 01:05:28,079
avoid that issue

1692
01:05:24,319 --> 01:05:31,279
so the second class of advantage

1693
01:05:28,079 --> 01:05:33,200
for a delay as a signal is that

1694
01:05:31,280 --> 01:05:34,559
it gives you sort of a known target

1695
01:05:33,200 --> 01:05:37,038
latency for

1696
01:05:34,559 --> 01:05:38,720
engineering your systems um and this

1697
01:05:37,039 --> 01:05:41,359
applies to several different pieces

1698
01:05:38,720 --> 01:05:43,279
of the puzzle here one it helps

1699
01:05:41,359 --> 01:05:46,400
applications to sort of predict

1700
01:05:43,280 --> 01:05:49,039
the latency that they should expect

1701
01:05:46,400 --> 01:05:50,880
and second it allows people who are

1702
01:05:49,039 --> 01:05:55,440
engineering the network itself

1703
01:05:50,880 --> 01:05:57,359
to set slos or service level objectives

1704
01:05:55,440 --> 01:05:59,280
and that can in turn help inform

1705
01:05:57,359 --> 01:06:01,038
monitoring and alerting because you sort

1706
01:05:59,280 --> 01:06:03,599
of know what to expect or what you're

1707
01:06:01,039 --> 01:06:06,720
aiming to achieve at least

1708
01:06:03,599 --> 01:06:10,160
by contrast using loss rates or

1709
01:06:06,720 --> 01:06:13,200
ecn and monitoring those um and

1710
01:06:10,160 --> 01:06:14,640
and conveying those to applications

1711
01:06:13,200 --> 01:06:15,839
it makes things actually quite difficult

1712
01:06:14,640 --> 01:06:17,920
to translate into application

1713
01:06:15,839 --> 01:06:19,279
performance so if you tell someone to

1714
01:06:17,920 --> 01:06:21,520
expect a 0.1

1715
01:06:19,280 --> 01:06:22,799
loss rate what are applications supposed

1716
01:06:21,520 --> 01:06:24,480
to do with that they don't really know

1717
01:06:22,799 --> 01:06:27,038
how to translate that into

1718
01:06:24,480 --> 01:06:27,520
into latency expectations and it's a

1719
01:06:27,039 --> 01:06:30,640
tricky

1720
01:06:27,520 --> 01:06:32,160
thing to do and finally at a high level

1721
01:06:30,640 --> 01:06:34,240
a key piece of the puzzle here

1722
01:06:32,160 --> 01:06:36,240
is that to make this work we need

1723
01:06:34,240 --> 01:06:38,720
accurate delay measurements

1724
01:06:36,240 --> 01:06:40,078
for network and host delays so next

1725
01:06:38,720 --> 01:06:42,799
we'll talk about that

1726
01:06:40,079 --> 01:06:42,799
next slide please

1727
01:06:44,960 --> 01:06:50,559
um so bbr swift um the primary signal

1728
01:06:48,880 --> 01:06:52,880
that it's using is uh we call

1729
01:06:50,559 --> 01:06:54,640
network rtt and that's something that

1730
01:06:52,880 --> 01:06:57,680
the data center computes

1731
01:06:54,640 --> 01:07:00,000
by uh basically computing the

1732
01:06:57,680 --> 01:07:00,879
uh total round trip time for a data

1733
01:07:00,000 --> 01:07:03,520
segment

1734
01:07:00,880 --> 01:07:04,400
minus the receiver act delay and so

1735
01:07:03,520 --> 01:07:05,839
we've

1736
01:07:04,400 --> 01:07:08,160
drawn a diagram here to sort of

1737
01:07:05,839 --> 01:07:11,038
illustrate that and we've shown the

1738
01:07:08,160 --> 01:07:12,879
total rtt in this sort of teal color

1739
01:07:11,039 --> 01:07:14,400
and the receiver act delay in this sort

1740
01:07:12,880 --> 01:07:17,039
of orange color

1741
01:07:14,400 --> 01:07:19,440
and then the network rtt component you

1742
01:07:17,039 --> 01:07:22,000
can sort of visualize as the purple

1743
01:07:19,440 --> 01:07:23,440
um path of the packet there and the sort

1744
01:07:22,000 --> 01:07:27,599
of vertical distance

1745
01:07:23,440 --> 01:07:30,000
of the represents the the network rtt

1746
01:07:27,599 --> 01:07:31,839
so the we can consider a specific

1747
01:07:30,000 --> 01:07:33,760
example depicted here if we

1748
01:07:31,839 --> 01:07:35,359
if we look at the sender here the data

1749
01:07:33,760 --> 01:07:38,240
center tcpa

1750
01:07:35,359 --> 01:07:39,839
it um schedules some packets uh or

1751
01:07:38,240 --> 01:07:41,200
schedules a packet to be released at a

1752
01:07:39,839 --> 01:07:43,680
particular

1753
01:07:41,200 --> 01:07:46,160
time from the pacing layer that packet

1754
01:07:43,680 --> 01:07:48,558
travels across the network as data p1

1755
01:07:46,160 --> 01:07:49,920
it's received at the receiver here at

1756
01:07:48,559 --> 01:07:51,359
the receiving nic

1757
01:07:49,920 --> 01:07:53,599
but then there are all sorts of

1758
01:07:51,359 --> 01:07:54,960
interesting delays that can happen on

1759
01:07:53,599 --> 01:07:58,240
the receiver side

1760
01:07:54,960 --> 01:08:01,200
for various reasons so one big

1761
01:07:58,240 --> 01:08:02,799
delay source that we've noticed is uh

1762
01:08:01,200 --> 01:08:05,919
power saving c states

1763
01:08:02,799 --> 01:08:09,759
so often um servers that are not

1764
01:08:05,920 --> 01:08:11,119
running at you know 100 cpu utilization

1765
01:08:09,760 --> 01:08:13,280
on all the cpus

1766
01:08:11,119 --> 01:08:14,880
will take the opportunity to go into a

1767
01:08:13,280 --> 01:08:18,319
power saving state

1768
01:08:14,880 --> 01:08:20,560
and if the packet arrives um and

1769
01:08:18,319 --> 01:08:22,640
the nic that's handling the receive

1770
01:08:20,560 --> 01:08:23,279
interrupt is actually in a power saving

1771
01:08:22,640 --> 01:08:25,759
state

1772
01:08:23,279 --> 01:08:26,560
it can take a quite a bit of time to

1773
01:08:25,759 --> 01:08:28,799
wake up

1774
01:08:26,560 --> 01:08:30,880
sometimes often that's longer than the

1775
01:08:28,799 --> 01:08:32,719
actual rtt of the data packet

1776
01:08:30,880 --> 01:08:34,960
so that delay is significant and needs

1777
01:08:32,719 --> 01:08:37,600
to be quantified

1778
01:08:34,960 --> 01:08:38,080
other delays happen because the tcp

1779
01:08:37,600 --> 01:08:39,839
stack

1780
01:08:38,080 --> 01:08:41,759
might be processing a whole queue of

1781
01:08:39,839 --> 01:08:43,839
packets not just one packet

1782
01:08:41,759 --> 01:08:45,759
and then of course in tcp and other

1783
01:08:43,839 --> 01:08:49,278
protocols there's often

1784
01:08:45,759 --> 01:08:51,120
an intentional delayed ack mechanism

1785
01:08:49,279 --> 01:08:53,520
that comes into play as the receiver is

1786
01:08:51,120 --> 01:08:55,679
trying to piggyback that ack on

1787
01:08:53,520 --> 01:08:56,960
hopefully some outgoing data segment

1788
01:08:55,679 --> 01:08:58,640
later on

1789
01:08:56,960 --> 01:09:00,960
um and so if you think about all of

1790
01:08:58,640 --> 01:09:03,600
these delays

1791
01:09:00,960 --> 01:09:04,640
you could have various combinations and

1792
01:09:03,600 --> 01:09:06,799
in this protocol

1793
01:09:04,640 --> 01:09:08,960
what happens is the receiver is able to

1794
01:09:06,799 --> 01:09:12,960
convey that receiver actually

1795
01:09:08,960 --> 01:09:16,799
back to the sender and to do that

1796
01:09:12,960 --> 01:09:19,679
we use basically a new timestamp option

1797
01:09:16,799 --> 01:09:20,640
that we've described earlier in the week

1798
01:09:19,679 --> 01:09:23,759
in the

1799
01:09:20,640 --> 01:09:26,159
linked internet draft here that

1800
01:09:23,759 --> 01:09:27,279
we are calling extensible timestamps or

1801
01:09:26,158 --> 01:09:29,759
ets

1802
01:09:27,279 --> 01:09:31,279
so you can check out the tcpm slides and

1803
01:09:29,759 --> 01:09:33,439
presentation and also the

1804
01:09:31,279 --> 01:09:36,000
the linked internet draft that describes

1805
01:09:33,439 --> 01:09:38,559
the details

1806
01:09:36,000 --> 01:09:38,560
but basically

1807
01:09:39,040 --> 01:09:43,198
we'll we'll talk about some of it and an

1808
01:09:41,839 --> 01:09:43,839
interesting thing to note here in the

1809
01:09:43,198 --> 01:09:46,399
diagram

1810
01:09:43,839 --> 01:09:47,120
is that the data and act transmission

1811
01:09:46,399 --> 01:09:49,839
times

1812
01:09:47,120 --> 01:09:52,559
are measured by tcp and here in this

1813
01:09:49,839 --> 01:09:55,840
picture the data and act reception times

1814
01:09:52,560 --> 01:09:58,080
are measured by the nic and conveyed

1815
01:09:55,840 --> 01:10:00,800
via the net hardware receive timestamp

1816
01:09:58,080 --> 01:10:03,840
mechanism to the tcp stack

1817
01:10:00,800 --> 01:10:03,840
next slide please

1818
01:10:04,080 --> 01:10:07,280
so how is the signal used in the

1819
01:10:06,239 --> 01:10:10,480
algorithm

1820
01:10:07,280 --> 01:10:13,679
so in bbr swift uh this is uh

1821
01:10:10,480 --> 01:10:17,839
an extension of bbr v2 where

1822
01:10:13,679 --> 01:10:20,159
the core aspects of bbr v2 are unchanged

1823
01:10:17,840 --> 01:10:21,360
and in particular if a connection does

1824
01:10:20,159 --> 01:10:24,320
not have

1825
01:10:21,360 --> 01:10:26,559
the delay as available as a signal it is

1826
01:10:24,320 --> 01:10:28,880
going to behave exactly as the algorithm

1827
01:10:26,560 --> 01:10:31,360
that we've documented at the itf and

1828
01:10:28,880 --> 01:10:32,000
open source with respect to its response

1829
01:10:31,360 --> 01:10:36,400
to

1830
01:10:32,000 --> 01:10:38,320
ecn loss bandwidth min rdt and so forth

1831
01:10:36,400 --> 01:10:39,440
but what we have here is an extension to

1832
01:10:38,320 --> 01:10:42,960
br v2

1833
01:10:39,440 --> 01:10:45,599
that's based on the swift algorithm and

1834
01:10:42,960 --> 01:10:47,600
key piece of this is basically that a

1835
01:10:45,600 --> 01:10:51,360
new configuration parameter

1836
01:10:47,600 --> 01:10:53,280
which is the target rtt the rtt value

1837
01:10:51,360 --> 01:10:56,799
that the algorithm is trying to seek

1838
01:10:53,280 --> 01:11:00,239
in some sense and trying to maintain

1839
01:10:56,800 --> 01:11:01,600
rtt values near that target and inside

1840
01:11:00,239 --> 01:11:02,000
of a data center you can think of this

1841
01:11:01,600 --> 01:11:04,560
as

1842
01:11:02,000 --> 01:11:06,480
being in the ballpark of or in the order

1843
01:11:04,560 --> 01:11:08,480
of a 100 microseconds

1844
01:11:06,480 --> 01:11:10,400
although you know a particular

1845
01:11:08,480 --> 01:11:13,599
installation we get to choose the target

1846
01:11:10,400 --> 01:11:16,400
that makes sense for that installation

1847
01:11:13,600 --> 01:11:18,239
and then how is that target used

1848
01:11:16,400 --> 01:11:21,519
basically the algorithm

1849
01:11:18,239 --> 01:11:22,718
at its core says that if the network rtt

1850
01:11:21,520 --> 01:11:25,280
that's been measured

1851
01:11:22,719 --> 01:11:26,400
is greater than the target then we do a

1852
01:11:25,280 --> 01:11:28,239
multiplicative

1853
01:11:26,400 --> 01:11:30,000
decrease where the multiplicative

1854
01:11:28,239 --> 01:11:32,159
decrease factor

1855
01:11:30,000 --> 01:11:33,280
is essentially proportional to that

1856
01:11:32,159 --> 01:11:35,199
excess delay

1857
01:11:33,280 --> 01:11:37,440
and here the excess delay is quantified

1858
01:11:35,199 --> 01:11:40,879
as network rtt

1859
01:11:37,440 --> 01:11:43,599
minus the target rtt and that's turned

1860
01:11:40,880 --> 01:11:44,960
into a fraction by dividing that by the

1861
01:11:43,600 --> 01:11:47,199
network rtt

1862
01:11:44,960 --> 01:11:49,360
so you can think of this intuitively as

1863
01:11:47,199 --> 01:11:52,799
saying

1864
01:11:49,360 --> 01:11:54,239
what is the fraction of the delay that

1865
01:11:52,800 --> 01:11:57,040
we're seeing that is

1866
01:11:54,239 --> 01:11:59,120
excess delay because we want to reduce

1867
01:11:57,040 --> 01:12:00,960
the congestion window

1868
01:11:59,120 --> 01:12:02,239
by a corresponding amount so that we've

1869
01:12:00,960 --> 01:12:04,960
cut out the excess

1870
01:12:02,239 --> 01:12:05,360
fraction of the congestion window which

1871
01:12:04,960 --> 01:12:07,360
is

1872
01:12:05,360 --> 01:12:08,400
proportional to the excess fraction of

1873
01:12:07,360 --> 01:12:11,360
the delay

1874
01:12:08,400 --> 01:12:13,519
in those cases and then you can see here

1875
01:12:11,360 --> 01:12:15,040
there's also a bound so that we don't

1876
01:12:13,520 --> 01:12:16,800
reduce the congestion window by more

1877
01:12:15,040 --> 01:12:20,080
than 50 per

1878
01:12:16,800 --> 01:12:22,960
round trip and again this response

1879
01:12:20,080 --> 01:12:24,719
happens at most once per round trip as

1880
01:12:22,960 --> 01:12:25,360
you would expect since the center needs

1881
01:12:24,719 --> 01:12:27,600
to

1882
01:12:25,360 --> 01:12:28,559
react and then wait a round trip time to

1883
01:12:27,600 --> 01:12:30,800
see the

1884
01:12:28,560 --> 01:12:33,120
impact of its reaction and see if it

1885
01:12:30,800 --> 01:12:36,080
needs to cut further

1886
01:12:33,120 --> 01:12:37,840
so that's the the basic approach that

1887
01:12:36,080 --> 01:12:40,080
the algorithm takes

1888
01:12:37,840 --> 01:12:41,120
and one thing that is important to note

1889
01:12:40,080 --> 01:12:44,480
here is that

1890
01:12:41,120 --> 01:12:47,120
when this target rtt response is used

1891
01:12:44,480 --> 01:12:48,080
we disable the ecn response so that

1892
01:12:47,120 --> 01:12:49,920
essentially this

1893
01:12:48,080 --> 01:12:52,080
target rtt response is used as a

1894
01:12:49,920 --> 01:12:54,480
replacement for ecn

1895
01:12:52,080 --> 01:12:56,400
if the administrator wants to use that

1896
01:12:54,480 --> 01:12:59,759
in their site

1897
01:12:56,400 --> 01:12:59,759
and one interesting

1898
01:12:59,920 --> 01:13:04,480
issue that we are still working on

1899
01:13:02,560 --> 01:13:07,199
nailing down the details of

1900
01:13:04,480 --> 01:13:09,759
is the question of how exactly land

1901
01:13:07,199 --> 01:13:12,559
flows using ecn as a signal

1902
01:13:09,760 --> 01:13:14,480
should interact with bbr swift flows

1903
01:13:12,560 --> 01:13:16,719
using delay as a signal

1904
01:13:14,480 --> 01:13:18,559
there's an interesting set of issues

1905
01:13:16,719 --> 01:13:19,280
there and we have some ideas that we're

1906
01:13:18,560 --> 01:13:22,480
exploring

1907
01:13:19,280 --> 01:13:24,480
uh one kind of approach would be to

1908
01:13:22,480 --> 01:13:26,000
say that landflows can dynamically set

1909
01:13:24,480 --> 01:13:29,919
the target rtt

1910
01:13:26,000 --> 01:13:32,719
based on where they see the network rtt

1911
01:13:29,920 --> 01:13:34,800
around the boundary between ecn marked

1912
01:13:32,719 --> 01:13:36,960
packets and non-ecm marked packets which

1913
01:13:34,800 --> 01:13:40,159
gives you a sort of sense of

1914
01:13:36,960 --> 01:13:43,920
the target rtt that you'd like where

1915
01:13:40,159 --> 01:13:47,920
the ecn mechanism thinks the delay

1916
01:13:43,920 --> 01:13:50,960
is at a good level uh next slide please

1917
01:13:47,920 --> 01:13:53,199
um how am i doing on time yeah yeah

1918
01:13:50,960 --> 01:13:54,000
uh not well so that's what i wanted we

1919
01:13:53,199 --> 01:13:57,040
have

1920
01:13:54,000 --> 01:13:58,560
seven minutes left and uh slides so okay

1921
01:13:57,040 --> 01:14:00,480
we wanna

1922
01:13:58,560 --> 01:14:02,560
uh yeah i mean decide yeah you want to

1923
01:14:00,480 --> 01:14:06,000
do it sounds great yeah i'll just

1924
01:14:02,560 --> 01:14:09,199
thanks so just a quick sketch of

1925
01:14:06,000 --> 01:14:11,840
the kinds of um results we see with this

1926
01:14:09,199 --> 01:14:12,719
this class of algorithm so here uh we

1927
01:14:11,840 --> 01:14:14,880
have a

1928
01:14:12,719 --> 01:14:16,560
sort of very simple or basic in-cast

1929
01:14:14,880 --> 01:14:18,640
scenario with two machines

1930
01:14:16,560 --> 01:14:21,360
each machine is sending a thousand uh

1931
01:14:18,640 --> 01:14:22,000
bulk uh tcp flows so with 2000 flows in

1932
01:14:21,360 --> 01:14:25,360
total

1933
01:14:22,000 --> 01:14:26,000
and we're comparing dc tcp bbr v2 with

1934
01:14:25,360 --> 01:14:28,960
ecn

1935
01:14:26,000 --> 01:14:30,159
and bbr swift uh the thing to notice

1936
01:14:28,960 --> 01:14:32,480
here is that

1937
01:14:30,159 --> 01:14:34,080
because of the large number of flows and

1938
01:14:32,480 --> 01:14:36,320
and dc tcp

1939
01:14:34,080 --> 01:14:37,679
is sort of operating uh sea wind bound

1940
01:14:36,320 --> 01:14:40,080
and act clocked

1941
01:14:37,679 --> 01:14:41,280
it is basically trying to maintain at

1942
01:14:40,080 --> 01:14:43,519
least one packet

1943
01:14:41,280 --> 01:14:45,280
in flight for each flow which leads to a

1944
01:14:43,520 --> 01:14:47,520
very large standing queue of

1945
01:14:45,280 --> 01:14:49,120
all of those excess packets which leads

1946
01:14:47,520 --> 01:14:49,840
to a large loss rate that you can see

1947
01:14:49,120 --> 01:14:52,960
here

1948
01:14:49,840 --> 01:14:54,640
six percent for one machine 66 for the

1949
01:14:52,960 --> 01:14:56,640
other machine

1950
01:14:54,640 --> 01:14:57,920
and it also has some some sort of

1951
01:14:56,640 --> 01:15:00,880
fairness issues

1952
01:14:57,920 --> 01:15:01,760
um whereas um bbr v2 with ecn does a

1953
01:15:00,880 --> 01:15:03,440
little better

1954
01:15:01,760 --> 01:15:05,600
uh it's a little bit more fair the

1955
01:15:03,440 --> 01:15:08,239
retransmit rate is considerably lower

1956
01:15:05,600 --> 01:15:10,080
around 1.6 1.7 percent

1957
01:15:08,239 --> 01:15:11,599
uh and the fairness is a little better

1958
01:15:10,080 --> 01:15:14,719
uh or

1959
01:15:11,600 --> 01:15:18,159
actually comparable i guess to dc tcp um

1960
01:15:14,719 --> 01:15:20,719
and then if we look at bbr swift um the

1961
01:15:18,159 --> 01:15:21,519
you can see that the uh the algorithm

1962
01:15:20,719 --> 01:15:24,000
because it's

1963
01:15:21,520 --> 01:15:26,239
able to use the pacing rate to match its

1964
01:15:24,000 --> 01:15:27,840
sending to the aggregate delivery rate

1965
01:15:26,239 --> 01:15:30,718
it's able to keep that queue nice and

1966
01:15:27,840 --> 01:15:33,480
small correspondingly achieve a very low

1967
01:15:30,719 --> 01:15:35,760
loss rate here the loss rate is is about

1968
01:15:33,480 --> 01:15:37,199
.05 percent

1969
01:15:35,760 --> 01:15:40,640
and you can see there that the network

1970
01:15:37,199 --> 01:15:43,440
rtt on average is around 93 microseconds

1971
01:15:40,640 --> 01:15:44,560
corresponding to the 50 microsecond

1972
01:15:43,440 --> 01:15:47,040
target that was

1973
01:15:44,560 --> 01:15:48,880
used in this particular experiment and

1974
01:15:47,040 --> 01:15:51,600
you can see the jane's fairness index is

1975
01:15:48,880 --> 01:15:53,840
is fairly good um so that's just a quick

1976
01:15:51,600 --> 01:15:54,800
uh comparison to give you a sense of the

1977
01:15:53,840 --> 01:15:58,000
properties

1978
01:15:54,800 --> 01:15:58,000
uh next slide please

1979
01:15:59,280 --> 01:16:02,639
so where are we uh we're preparing for

1980
01:16:01,199 --> 01:16:05,199
production testing

1981
01:16:02,640 --> 01:16:06,960
uh we're basically rolling this out in

1982
01:16:05,199 --> 01:16:10,960
preparation for doing

1983
01:16:06,960 --> 01:16:12,719
large-scale production workload testing

1984
01:16:10,960 --> 01:16:14,560
and we're also planning to release this

1985
01:16:12,719 --> 01:16:15,840
code as open source and document the

1986
01:16:14,560 --> 01:16:17,840
algorithm

1987
01:16:15,840 --> 01:16:19,120
and this includes the the timestamp

1988
01:16:17,840 --> 01:16:20,640
implementation as well

1989
01:16:19,120 --> 01:16:22,400
and basically the goal here is we want

1990
01:16:20,640 --> 01:16:24,800
transports to be able to use this

1991
01:16:22,400 --> 01:16:27,199
algorithm as their cc

1992
01:16:24,800 --> 01:16:27,840
on connections where a target network

1993
01:16:27,199 --> 01:16:30,159
rtt

1994
01:16:27,840 --> 01:16:31,920
can be known and we know that the

1995
01:16:30,159 --> 01:16:33,280
coexisting traffic is also running a

1996
01:16:31,920 --> 01:16:35,199
compatible algorithm

1997
01:16:33,280 --> 01:16:36,320
and we also in the long run like this to

1998
01:16:35,199 --> 01:16:38,879
be usable on both

1999
01:16:36,320 --> 01:16:39,599
physical machines and inside virtual

2000
01:16:38,880 --> 01:16:43,600
machine

2001
01:16:39,600 --> 01:16:43,600
guests next slide please

2002
01:16:44,640 --> 01:16:48,320
so the second part i just wanted to

2003
01:16:46,159 --> 01:16:50,080
briefly mention was some interesting

2004
01:16:48,320 --> 01:16:51,599
observations and issues we've seen

2005
01:16:50,080 --> 01:16:55,440
around congestion control and

2006
01:16:51,600 --> 01:16:55,440
loss recovery next slide please

2007
01:16:56,400 --> 01:17:01,519
so perhaps the slide

2008
01:16:59,760 --> 01:17:03,120
title here is a little provocative but i

2009
01:17:01,520 --> 01:17:04,800
thought it was interesting to

2010
01:17:03,120 --> 01:17:07,599
to sort of raise this issue that we've

2011
01:17:04,800 --> 01:17:10,239
seen because

2012
01:17:07,600 --> 01:17:10,719
our experience is showing that both uh

2013
01:17:10,239 --> 01:17:12,718
on

2014
01:17:10,719 --> 01:17:14,719
data center traffic and on the public

2015
01:17:12,719 --> 01:17:17,120
internet this is an interesting issue

2016
01:17:14,719 --> 01:17:17,920
so as this audience well knows

2017
01:17:17,120 --> 01:17:19,679
traditional

2018
01:17:17,920 --> 01:17:21,520
tcp congestion control uses a

2019
01:17:19,679 --> 01:17:23,920
multiplicative decrease

2020
01:17:21,520 --> 01:17:25,920
upon round trips that have packet loss

2021
01:17:23,920 --> 01:17:28,400
reno will cut to 0.5

2022
01:17:25,920 --> 01:17:29,520
of the old congestion window cubic will

2023
01:17:28,400 --> 01:17:31,679
cut to 0.7

2024
01:17:29,520 --> 01:17:33,280
per round trip but an interesting

2025
01:17:31,679 --> 01:17:35,760
question arises

2026
01:17:33,280 --> 01:17:37,759
what if the bandwidth available to a

2027
01:17:35,760 --> 01:17:38,159
flow suddenly drops by a very large

2028
01:17:37,760 --> 01:17:41,760
amount

2029
01:17:38,159 --> 01:17:43,759
say 100x 1000x it sounds like a lot but

2030
01:17:41,760 --> 01:17:46,080
this can actually happen

2031
01:17:43,760 --> 01:17:47,440
in the data center when you are

2032
01:17:46,080 --> 01:17:49,840
partitioning work among

2033
01:17:47,440 --> 01:17:52,400
thousands of servers or even in the

2034
01:17:49,840 --> 01:17:54,719
public internet when you drop from

2035
01:17:52,400 --> 01:17:55,759
a well-provisioned flow going at

2036
01:17:54,719 --> 01:17:59,040
hundreds of megabits

2037
01:17:55,760 --> 01:17:59,679
down to a police flow at a much lower

2038
01:17:59,040 --> 01:18:04,000
rate

2039
01:17:59,679 --> 01:18:06,800
due to an isp police or policy

2040
01:18:04,000 --> 01:18:08,239
and where policers are quite well

2041
01:18:06,800 --> 01:18:10,560
deployed quite

2042
01:18:08,239 --> 01:18:12,159
quite frequently so in theory what

2043
01:18:10,560 --> 01:18:14,880
happens in these kind of scenarios

2044
01:18:12,159 --> 01:18:15,839
is that with something like reno you

2045
01:18:14,880 --> 01:18:18,239
expect

2046
01:18:15,840 --> 01:18:19,040
a number of round trips of very high

2047
01:18:18,239 --> 01:18:22,718
packet loss

2048
01:18:19,040 --> 01:18:24,719
until the flow reacts fully and adapts

2049
01:18:22,719 --> 01:18:26,480
to the new congestion window and

2050
01:18:24,719 --> 01:18:28,000
in particular you expect a number of

2051
01:18:26,480 --> 01:18:29,839
round trips that is basically

2052
01:18:28,000 --> 01:18:31,360
the old bandwidth divided by the new

2053
01:18:29,840 --> 01:18:34,239
bandwidth and then

2054
01:18:31,360 --> 01:18:36,080
you take the log base two of that ratio

2055
01:18:34,239 --> 01:18:37,839
that tells you how long you expect

2056
01:18:36,080 --> 01:18:39,519
to to see these high losses so if

2057
01:18:37,840 --> 01:18:40,480
there's a thousand x cut in the fair

2058
01:18:39,520 --> 01:18:43,600
share bandwidth

2059
01:18:40,480 --> 01:18:46,000
you can see 10 rounds of high loss

2060
01:18:43,600 --> 01:18:48,000
that's the theory in reality it's it's

2061
01:18:46,000 --> 01:18:50,080
actually a little bit different

2062
01:18:48,000 --> 01:18:51,840
with traditional tcp loss recovery

2063
01:18:50,080 --> 01:18:53,519
before rack

2064
01:18:51,840 --> 01:18:54,880
it actually couldn't handle consecutive

2065
01:18:53,520 --> 01:18:56,640
rounds of loss

2066
01:18:54,880 --> 01:18:58,480
what tends to happen instead is you get

2067
01:18:56,640 --> 01:19:00,159
a re-transmission timeout

2068
01:18:58,480 --> 01:19:02,559
you cut your congestion window to one

2069
01:19:00,159 --> 01:19:05,920
and you slow start back up

2070
01:19:02,560 --> 01:19:07,440
with tcp rack but but no proportional

2071
01:19:05,920 --> 01:19:10,239
rate reduction

2072
01:19:07,440 --> 01:19:11,759
you actually see a reality that matches

2073
01:19:10,239 --> 01:19:14,000
the theory

2074
01:19:11,760 --> 01:19:15,280
multiple rounds of high loss and this

2075
01:19:14,000 --> 01:19:17,520
can be quite painful

2076
01:19:15,280 --> 01:19:19,519
and we've definitely seen this in

2077
01:19:17,520 --> 01:19:20,480
experiments where you use rack but no

2078
01:19:19,520 --> 01:19:22,080
prr

2079
01:19:20,480 --> 01:19:24,718
in the public internet when you run into

2080
01:19:22,080 --> 01:19:27,920
a policer it can get quite ugly

2081
01:19:24,719 --> 01:19:31,520
um but finally if you're using rack and

2082
01:19:27,920 --> 01:19:33,840
prr uh you get a nice kind of behavior

2083
01:19:31,520 --> 01:19:36,320
where the sending rate is bounded to be

2084
01:19:33,840 --> 01:19:38,480
quite near the delivery rate and thus

2085
01:19:36,320 --> 01:19:40,960
this keeps the loss rate at sort of a

2086
01:19:38,480 --> 01:19:42,799
reasonable level while still robustly

2087
01:19:40,960 --> 01:19:46,320
probing for bandwidth and this

2088
01:19:42,800 --> 01:19:48,800
this is uh what you get if you say run

2089
01:19:46,320 --> 01:19:50,799
a default linux stack you're going to

2090
01:19:48,800 --> 01:19:52,560
get cubic plus prr and you'll get that

2091
01:19:50,800 --> 01:19:55,360
kind of behavior today

2092
01:19:52,560 --> 01:19:55,360
next slide please

2093
01:19:56,400 --> 01:20:01,519
you have two minutes at most

2094
01:19:59,840 --> 01:20:03,760
okay i don't think we go through the ten

2095
01:20:01,520 --> 01:20:07,040
slides yeah

2096
01:20:03,760 --> 01:20:09,920
uh um yeah i just want to zoom through

2097
01:20:07,040 --> 01:20:10,719
the a couple of these um yeah so can we

2098
01:20:09,920 --> 01:20:13,840
just yeah

2099
01:20:10,719 --> 01:20:16,600
so so what we've done with bbr is we've

2100
01:20:13,840 --> 01:20:18,320
um i mean for bbr v1 there was a sort of

2101
01:20:16,600 --> 01:20:20,719
prr-inspired approach

2102
01:20:18,320 --> 01:20:22,239
for v2 we tried to simplify things by

2103
01:20:20,719 --> 01:20:23,600
removing that and just doing a pure

2104
01:20:22,239 --> 01:20:25,759
multiplicative decrease

2105
01:20:23,600 --> 01:20:26,800
but what we're seeing in our experience

2106
01:20:25,760 --> 01:20:29,120
as we roll this out

2107
01:20:26,800 --> 01:20:31,120
is that actually there are important

2108
01:20:29,120 --> 01:20:32,559
scenarios where that does

2109
01:20:31,120 --> 01:20:34,320
give you that sort of theoretical

2110
01:20:32,560 --> 01:20:36,960
behavior that's quite poor

2111
01:20:34,320 --> 01:20:38,799
and so what we're doing is we're now

2112
01:20:36,960 --> 01:20:40,320
trying in production various prr

2113
01:20:38,800 --> 01:20:42,000
inspired responses

2114
01:20:40,320 --> 01:20:43,599
and we hope to update you in the future

2115
01:20:42,000 --> 01:20:46,320
either on the list or in

2116
01:20:43,600 --> 01:20:49,120
in presentations with the results uh

2117
01:20:46,320 --> 01:20:49,120
next slide please

2118
01:20:49,679 --> 01:20:56,159
uh so wrapping up next slide

2119
01:20:53,360 --> 01:20:57,040
so as folks know we've open sourced bbr

2120
01:20:56,159 --> 01:20:59,280
v2

2121
01:20:57,040 --> 01:21:00,960
and talked about our previous ietfs you

2122
01:20:59,280 --> 01:21:04,559
can find the links in

2123
01:21:00,960 --> 01:21:04,560
the slides here next slide

2124
01:21:06,159 --> 01:21:11,599
and just a quick status update so

2125
01:21:09,199 --> 01:21:13,040
for youtube and google.com public

2126
01:21:11,600 --> 01:21:15,520
internet traffic

2127
01:21:13,040 --> 01:21:17,280
we've deployed bbr v2 for a small

2128
01:21:15,520 --> 01:21:18,320
percentage of users as an ongoing

2129
01:21:17,280 --> 01:21:21,440
experiment as we

2130
01:21:18,320 --> 01:21:22,880
refine the algorithm and code we see

2131
01:21:21,440 --> 01:21:24,080
reduced queuing delays and reduced

2132
01:21:22,880 --> 01:21:27,600
losses

2133
01:21:24,080 --> 01:21:28,559
versus pvr v1 getting closer to cubic

2134
01:21:27,600 --> 01:21:30,560
levels

2135
01:21:28,560 --> 01:21:32,960
for google internal traffic we're

2136
01:21:30,560 --> 01:21:36,000
deploying bbr v2 as the default

2137
01:21:32,960 --> 01:21:38,000
and we're in transition there currently

2138
01:21:36,000 --> 01:21:39,600
it is used as a congestion control for

2139
01:21:38,000 --> 01:21:40,639
most of the internal traffic within

2140
01:21:39,600 --> 01:21:42,880
google

2141
01:21:40,639 --> 01:21:44,880
this is using the algorithm as

2142
01:21:42,880 --> 01:21:46,080
previously described with bandwidth then

2143
01:21:44,880 --> 01:21:48,480
rtt

2144
01:21:46,080 --> 01:21:49,519
ecn and loss as signals as i mentioned

2145
01:21:48,480 --> 01:21:50,959
before we're

2146
01:21:49,520 --> 01:21:52,880
still in the process of rolling out the

2147
01:21:50,960 --> 01:21:58,080
code for this network rtt

2148
01:21:52,880 --> 01:21:58,080
signal inspired by swift uh next slide

2149
01:21:59,440 --> 01:22:04,480
and in conclusion we are you know

2150
01:22:01,679 --> 01:22:07,040
actively working on bbr v2 and this

2151
01:22:04,480 --> 01:22:08,239
variant we're calling bbr swift um

2152
01:22:07,040 --> 01:22:10,800
continuing to iterate

2153
01:22:08,239 --> 01:22:11,519
and we are you know open we love to hear

2154
01:22:10,800 --> 01:22:14,960
feedback

2155
01:22:11,520 --> 01:22:18,159
uh on these approaches uh test results

2156
01:22:14,960 --> 01:22:19,360
uh and so forth and we definitely

2157
01:22:18,159 --> 01:22:21,360
appreciate the

2158
01:22:19,360 --> 01:22:23,519
survey results from the previous uh

2159
01:22:21,360 --> 01:22:26,239
presentation uh for example

2160
01:22:23,520 --> 01:22:26,719
uh so thank you very much and uh

2161
01:22:26,239 --> 01:22:29,678
hopefully

2162
01:22:26,719 --> 01:22:30,400
we have a few uh moments for a q a um if

2163
01:22:29,679 --> 01:22:31,760
not we'll

2164
01:22:30,400 --> 01:22:34,000
we can take questions on the mailing

2165
01:22:31,760 --> 01:22:36,639
list

2166
01:22:34,000 --> 01:22:38,719
um whitney's in queue so i'll let her

2167
01:22:36,639 --> 01:22:41,360
get in but i i

2168
01:22:38,719 --> 01:22:42,320
will have to take more questions uh

2169
01:22:41,360 --> 01:22:46,000
offline

2170
01:22:42,320 --> 01:22:49,199
go ahead i'll try and use headset is it

2171
01:22:46,000 --> 01:22:52,480
is it better yes

2172
01:22:49,199 --> 01:22:54,960
much better thank you um this is very

2173
01:22:52,480 --> 01:22:58,239
good question so the network rtt

2174
01:22:54,960 --> 01:23:00,719
uh is obviously used for bvr swift is it

2175
01:22:58,239 --> 01:23:02,159
is it used like how is the delay thing

2176
01:23:00,719 --> 01:23:04,840
working in bbr v2

2177
01:23:02,159 --> 01:23:06,080
if network rtt is used or if it's not

2178
01:23:04,840 --> 01:23:08,480
used

2179
01:23:06,080 --> 01:23:10,159
uh sorry can you repeat that last part

2180
01:23:08,480 --> 01:23:12,638
how is the what used

2181
01:23:10,159 --> 01:23:15,040
so are you doing the multiplicative

2182
01:23:12,639 --> 01:23:17,600
decrease for bb or v2 as well

2183
01:23:15,040 --> 01:23:20,320
in the van using network rtt or

2184
01:23:17,600 --> 01:23:24,159
something else

2185
01:23:20,320 --> 01:23:27,199
so in the wan case we are not using the

2186
01:23:24,159 --> 01:23:30,000
the network rtt signal um the basic

2187
01:23:27,199 --> 01:23:30,559
uh practical issue there is that usually

2188
01:23:30,000 --> 01:23:33,760
for

2189
01:23:30,560 --> 01:23:37,040
land paths um you don't know

2190
01:23:33,760 --> 01:23:37,760
the uh target round trip time ahead of

2191
01:23:37,040 --> 01:23:40,239
time

2192
01:23:37,760 --> 01:23:41,920
um and so in our deployment so far we

2193
01:23:40,239 --> 01:23:42,959
are we're definitely just using the

2194
01:23:41,920 --> 01:23:45,520
target rtt

2195
01:23:42,960 --> 01:23:47,120
uh within a data center for the wan

2196
01:23:45,520 --> 01:23:50,960
flows they're just using

2197
01:23:47,120 --> 01:23:52,239
ecn and lost signals we do have ideas

2198
01:23:50,960 --> 01:23:55,520
about how we might

2199
01:23:52,239 --> 01:23:58,400
unify those and use a

2200
01:23:55,520 --> 01:24:00,239
delay-based signal you know i guess i

2201
01:23:58,400 --> 01:24:03,280
briefly alluded to that in terms of

2202
01:24:00,239 --> 01:24:06,799
perhaps using ecn signals to

2203
01:24:03,280 --> 01:24:08,639
find the delay the target delay at which

2204
01:24:06,800 --> 01:24:10,320
we'd like to match based on the

2205
01:24:08,639 --> 01:24:12,480
transition between

2206
01:24:10,320 --> 01:24:14,320
rtt's above that point where we see ecn

2207
01:24:12,480 --> 01:24:16,239
marks our gt is below that point where

2208
01:24:14,320 --> 01:24:19,599
we see no ecm marks

2209
01:24:16,239 --> 01:24:20,799
use that as a sort of way to uh find a

2210
01:24:19,600 --> 01:24:22,880
target rt

2211
01:24:20,800 --> 01:24:25,199
dynamically for for when phase but

2212
01:24:22,880 --> 01:24:26,880
that's a future work

2213
01:24:25,199 --> 01:24:28,480
right a quick queuing delay can be

2214
01:24:26,880 --> 01:24:30,880
measured right by just having a base

2215
01:24:28,480 --> 01:24:34,320
delay and a target target

2216
01:24:30,880 --> 01:24:37,679
whatever just like what led back does

2217
01:24:34,320 --> 01:24:40,320
sure but to have that base delay you

2218
01:24:37,679 --> 01:24:40,320
sort of need to

2219
01:24:40,560 --> 01:24:44,719
you know in general to be able to to

2220
01:24:43,440 --> 01:24:48,559
distinguish

2221
01:24:44,719 --> 01:24:52,400
um a standing queue for

2222
01:24:48,560 --> 01:24:54,000
a longer wire it's it's uh can be quite

2223
01:24:52,400 --> 01:24:55,360
tricky unless you either have

2224
01:24:54,000 --> 01:24:57,040
knowledge ahead of time or you have an

2225
01:24:55,360 --> 01:25:00,080
ecn signal or something that allows you

2226
01:24:57,040 --> 01:25:00,080
to disambiguate those

2227
01:25:00,480 --> 01:25:04,879
all right well thank you so much neil

2228
01:25:02,560 --> 01:25:07,440
and thank you video for that question

2229
01:25:04,880 --> 01:25:08,080
um please continue this conversation on

2230
01:25:07,440 --> 01:25:10,159
uh

2231
01:25:08,080 --> 01:25:11,360
the mailing list again i'm sure a lot of

2232
01:25:10,159 --> 01:25:13,199
people are interested in

2233
01:25:11,360 --> 01:25:14,400
the relationship between dbr swift and

2234
01:25:13,199 --> 01:25:17,360
that that plus plus

2235
01:25:14,400 --> 01:25:18,559
and and uh questions on dbrv2 please

2236
01:25:17,360 --> 01:25:21,679
continue that

2237
01:25:18,560 --> 01:25:24,880
on the mailing list uh thanks neil

2238
01:25:21,679 --> 01:25:28,400
silvester you're up with your uh

2239
01:25:24,880 --> 01:25:28,400
i'm going to bring your presentation up

2240
01:25:28,800 --> 01:25:33,520
and there we are take it away

2241
01:25:34,639 --> 01:25:38,960
can i share my screen you know is that

2242
01:25:39,360 --> 01:25:43,280
yes let me let me give you the screen

2243
01:25:46,960 --> 01:25:51,520
i'm in the screen sharing cue so it

2244
01:25:49,120 --> 01:25:55,840
should be working

2245
01:25:51,520 --> 01:25:55,840
i see yep

2246
01:26:03,760 --> 01:26:12,159
can you see it can you hear me well

2247
01:26:09,120 --> 01:26:15,199
can you hear me yes

2248
01:26:12,159 --> 01:26:18,320
okay and can you also see my screen

2249
01:26:15,199 --> 01:26:20,879
yes okay thank you so hello everyone

2250
01:26:18,320 --> 01:26:22,320
i'm sylvester and with my co-authors we

2251
01:26:20,880 --> 01:26:23,440
are interested in internet resource

2252
01:26:22,320 --> 01:26:25,280
sharing so

2253
01:26:23,440 --> 01:26:27,199
we run some tests but studies on

2254
01:26:25,280 --> 01:26:29,360
fairness and we chose

2255
01:26:27,199 --> 01:26:31,440
bbrv to condition control as a new wave

2256
01:26:29,360 --> 01:26:33,280
of congestion control to control

2257
01:26:31,440 --> 01:26:34,960
compared to existing ones because it's

2258
01:26:33,280 --> 01:26:36,320
designed to be friendly to cubic flows

2259
01:26:34,960 --> 01:26:38,159
as opposed to e1

2260
01:26:36,320 --> 01:26:41,360
it has scalable ecm response and it

2261
01:26:38,159 --> 01:26:41,360
already has some deployments

2262
01:26:41,600 --> 01:26:44,639
so we use three machines connected and

2263
01:26:43,679 --> 01:26:47,040
train

2264
01:26:44,639 --> 01:26:48,400
chain topology in our test bed traffic

2265
01:26:47,040 --> 01:26:51,760
generator receiver

2266
01:26:48,400 --> 01:26:53,280
and the button in the middle and

2267
01:26:51,760 --> 01:26:55,679
on the sender and receiver we installed

2268
01:26:53,280 --> 01:26:58,480
the bbr v2 alpha kernel and we used

2269
01:26:55,679 --> 01:27:00,239
default linux settings we implemented

2270
01:26:58,480 --> 01:27:03,519
several aqms

2271
01:27:00,239 --> 01:27:06,638
in dpdk tail drop pi

2272
01:27:03,520 --> 01:27:08,800
gsp step pi square dual pi square and

2273
01:27:06,639 --> 01:27:10,960
and virtual drawer queue core stateless

2274
01:27:08,800 --> 01:27:13,679
aqm

2275
01:27:10,960 --> 01:27:16,320
we use data delay for rtt emulation of

2276
01:27:13,679 --> 01:27:18,239
acknowledgements to emulate rtt

2277
01:27:16,320 --> 01:27:19,840
the button accrete was changed between

2278
01:27:18,239 --> 01:27:21,280
100 meg and 10 gigs and

2279
01:27:19,840 --> 01:27:23,199
the results i present are with one

2280
01:27:21,280 --> 01:27:24,880
gigabit per second

2281
01:27:23,199 --> 01:27:26,879
and we use several condition controls

2282
01:27:24,880 --> 01:27:28,719
cubic bbrv to in both scalable and

2283
01:27:26,880 --> 01:27:30,960
classic mode and dc-tcp

2284
01:27:28,719 --> 01:27:31,840
we change the number of flows from 2 to

2285
01:27:30,960 --> 01:27:34,560
100

2286
01:27:31,840 --> 01:27:34,560
in this measurement

2287
01:27:35,360 --> 01:27:38,880
so this is an example measurement

2288
01:27:36,960 --> 01:27:40,560
results

2289
01:27:38,880 --> 01:27:43,679
we have two connection classes

2290
01:27:40,560 --> 01:27:46,080
connection classes are

2291
01:27:43,679 --> 01:27:48,080
identified by congestion control and rtt

2292
01:27:46,080 --> 01:27:50,400
so this was cubic ten millisecond and

2293
01:27:48,080 --> 01:27:52,400
bbr 10 millisecond rtt is over one gear

2294
01:27:50,400 --> 01:27:54,159
per second button like

2295
01:27:52,400 --> 01:27:55,759
we change the number of connections half

2296
01:27:54,159 --> 01:27:57,679
is from one connection class the other

2297
01:27:55,760 --> 01:27:59,360
half is from the other

2298
01:27:57,679 --> 01:28:02,320
the buffer size is set as a factor of

2299
01:27:59,360 --> 01:28:05,519
the rtt so 0.5 means

2300
01:28:02,320 --> 01:28:08,000
five millisecond in this case buffer

2301
01:28:05,520 --> 01:28:09,920
and we present plot the relative good

2302
01:28:08,000 --> 01:28:11,520
where one is the ideal and the relative

2303
01:28:09,920 --> 01:28:12,960
good put of a connection class is the

2304
01:28:11,520 --> 01:28:13,360
average good put within the connection

2305
01:28:12,960 --> 01:28:15,600
clause

2306
01:28:13,360 --> 01:28:18,159
divided by the ideal perfect pair

2307
01:28:15,600 --> 01:28:22,400
connection fair share

2308
01:28:18,159 --> 01:28:22,400
and we also studied several like aqms

2309
01:28:24,239 --> 01:28:28,159
so we have seen reasonable fairness with

2310
01:28:26,320 --> 01:28:31,360
tail drop when it comes to sharing

2311
01:28:28,159 --> 01:28:32,960
between cubic and bbr v2

2312
01:28:31,360 --> 01:28:35,360
it was it was much worse for small

2313
01:28:32,960 --> 01:28:37,360
buffers

2314
01:28:35,360 --> 01:28:40,960
and we also have seen good fairness with

2315
01:28:37,360 --> 01:28:43,759
csaqm for basically all cases

2316
01:28:40,960 --> 01:28:44,320
so what happens with the different aqms

2317
01:28:43,760 --> 01:28:46,320
we

2318
01:28:44,320 --> 01:28:48,080
plotted the tail drop results the grey

2319
01:28:46,320 --> 01:28:50,799
shadow for reference

2320
01:28:48,080 --> 01:28:52,800
so with pi the the fairness is very

2321
01:28:50,800 --> 01:28:55,120
similar to tail drop

2322
01:28:52,800 --> 01:28:56,719
while with gsp we have seen huge

2323
01:28:55,120 --> 01:28:59,440
degradation compared to

2324
01:28:56,719 --> 01:29:01,199
drop for a smaller number of users and

2325
01:28:59,440 --> 01:29:04,000
it was similar to teradrop for a larger

2326
01:29:01,199 --> 01:29:04,000
number of users

2327
01:29:05,280 --> 01:29:09,360
so what is what is csaqm mentioned as a

2328
01:29:08,080 --> 01:29:11,360
result so

2329
01:29:09,360 --> 01:29:12,480
in addition to existing aqms we also

2330
01:29:11,360 --> 01:29:14,960
have it of course

2331
01:29:12,480 --> 01:29:16,159
uh csaqm which is a core status resource

2332
01:29:14,960 --> 01:29:18,320
sharing framework

2333
01:29:16,159 --> 01:29:20,239
it can apply a wide variety of policies

2334
01:29:18,320 --> 01:29:21,759
not only fair sharing and it can enforce

2335
01:29:20,239 --> 01:29:24,000
these policies for

2336
01:29:21,760 --> 01:29:25,280
heterogeneous traffic mixes and it also

2337
01:29:24,000 --> 01:29:27,600
scales well with a

2338
01:29:25,280 --> 01:29:29,360
very large number of flows because the

2339
01:29:27,600 --> 01:29:31,199
algorithm itself is stateless

2340
01:29:29,360 --> 01:29:33,120
and it's also conduction control

2341
01:29:31,199 --> 01:29:36,000
independent it puts no assumption on how

2342
01:29:33,120 --> 01:29:37,840
the condition control behaves

2343
01:29:36,000 --> 01:29:39,920
it relies on packet marks with different

2344
01:29:37,840 --> 01:29:40,880
values larger values mean more important

2345
01:29:39,920 --> 01:29:42,639
packets

2346
01:29:40,880 --> 01:29:44,639
in conditional situations packets with

2347
01:29:42,639 --> 01:29:45,120
smaller values can be dropped or marked

2348
01:29:44,639 --> 01:29:48,320
with a

2349
01:29:45,120 --> 01:29:50,400
condition experience dcm flag and

2350
01:29:48,320 --> 01:29:52,080
the button like behavior is purely based

2351
01:29:50,400 --> 01:29:54,159
on the packet values so we don't have to

2352
01:29:52,080 --> 01:29:56,320
do any flow identification we don't have

2353
01:29:54,159 --> 01:29:58,719
to use separate queues

2354
01:29:56,320 --> 01:30:00,400
or decode the policy information anyway

2355
01:29:58,719 --> 01:30:03,600
therefore the implementation can be

2356
01:30:00,400 --> 01:30:06,000
very simple and fast

2357
01:30:03,600 --> 01:30:07,760
at the same time it's it's needs some

2358
01:30:06,000 --> 01:30:09,600
standardization or it has to be done

2359
01:30:07,760 --> 01:30:12,880
within an administrative domain because

2360
01:30:09,600 --> 01:30:12,880
it needs a header field

2361
01:30:13,280 --> 01:30:18,080
even though the the aqm is almost like

2362
01:30:16,159 --> 01:30:21,199
this installs that we were implementing

2363
01:30:18,080 --> 01:30:22,639
able to implement it in p4 you can you

2364
01:30:21,199 --> 01:30:25,759
can find much more about it

2365
01:30:22,639 --> 01:30:27,040
at our home page so getting back to

2366
01:30:25,760 --> 01:30:30,719
results

2367
01:30:27,040 --> 01:30:33,360
we also also use the dc-tcp

2368
01:30:30,719 --> 01:30:34,000
like condition controls so we we compare

2369
01:30:33,360 --> 01:30:37,920
the fairness

2370
01:30:34,000 --> 01:30:39,760
of dc-tcp and vbrv2 in scalable mode

2371
01:30:37,920 --> 01:30:42,080
in in this case instead of changing

2372
01:30:39,760 --> 01:30:46,320
buffer size we change the target delay

2373
01:30:42,080 --> 01:30:47,440
as a factor of rtt and our key findings

2374
01:30:46,320 --> 01:30:51,280
here is that

2375
01:30:47,440 --> 01:30:54,400
why the step aqm prefers

2376
01:30:51,280 --> 01:30:57,599
dc tcp uh

2377
01:30:54,400 --> 01:30:57,599
pi square aqm

2378
01:30:58,000 --> 01:31:02,639
for pi squared the bbrp v2

2379
01:31:01,040 --> 01:31:04,400
and this is actually hard to choose

2380
01:31:02,639 --> 01:31:06,639
which one is better

2381
01:31:04,400 --> 01:31:10,000
and for pi square the fan is improving

2382
01:31:06,639 --> 01:31:12,320
as the number of flows grows

2383
01:31:10,000 --> 01:31:14,560
by by which step it it gets worse for

2384
01:31:12,320 --> 01:31:17,120
larger number of flows

2385
01:31:14,560 --> 01:31:18,880
and the csa qms mentioned before it it

2386
01:31:17,120 --> 01:31:21,440
provided a reasonable fairness in all

2387
01:31:18,880 --> 01:31:23,360
these cases

2388
01:31:21,440 --> 01:31:25,440
again this was the relative throughput i

2389
01:31:23,360 --> 01:31:29,199
have also shown for the

2390
01:31:25,440 --> 01:31:29,199
bbrv two versus cubic cases

2391
01:31:29,679 --> 01:31:33,440
so let's see how these aqms are marking

2392
01:31:32,000 --> 01:31:35,360
the connection process the ec and

2393
01:31:33,440 --> 01:31:37,519
marking ratio here shows what

2394
01:31:35,360 --> 01:31:39,120
what is the fraction of the congestion

2395
01:31:37,520 --> 01:31:40,880
experienced

2396
01:31:39,120 --> 01:31:42,320
mark packets compared to the total

2397
01:31:40,880 --> 01:31:44,480
number of packets it's a logarithmic

2398
01:31:42,320 --> 01:31:47,519
scale and the y-axis

2399
01:31:44,480 --> 01:31:48,159
it is clear that step and pi square both

2400
01:31:47,520 --> 01:31:51,600
connection

2401
01:31:48,159 --> 01:31:51,599
classes are marked the same

2402
01:31:52,000 --> 01:31:56,000
and because the two condition controls

2403
01:31:53,840 --> 01:31:57,120
use the ecn feedback differently this

2404
01:31:56,000 --> 01:32:00,960
results in that fairness as

2405
01:31:57,120 --> 01:32:00,960
shown in the previous figure

2406
01:32:01,440 --> 01:32:06,159
and with csaqm there are seemingly no

2407
01:32:05,360 --> 01:32:07,920
connection

2408
01:32:06,159 --> 01:32:09,280
connection with the marking ratios of

2409
01:32:07,920 --> 01:32:11,199
the connection classes so there is no

2410
01:32:09,280 --> 01:32:14,000
clear formula how to mark the

2411
01:32:11,199 --> 01:32:14,719
the packets but this is exactly the the

2412
01:32:14,000 --> 01:32:16,719
right

2413
01:32:14,719 --> 01:32:19,199
marking ratio to to achieve good

2414
01:32:16,719 --> 01:32:19,199
fairness

2415
01:32:22,560 --> 01:32:27,440
um we also compare the fairness between

2416
01:32:24,800 --> 01:32:29,600
vbrv to scalable end and cubic flows

2417
01:32:27,440 --> 01:32:31,839
over dua pi square bottom like

2418
01:32:29,600 --> 01:32:33,440
we in this time i present time series

2419
01:32:31,840 --> 01:32:35,280
plot

2420
01:32:33,440 --> 01:32:37,360
and the number of flows in from the

2421
01:32:35,280 --> 01:32:39,360
different classes changes between

2422
01:32:37,360 --> 01:32:41,839
0 and 50 you can see the number of flows

2423
01:32:39,360 --> 01:32:41,839
at the top

2424
01:32:46,239 --> 01:32:50,480
and you can see that dual pi square can

2425
01:32:48,239 --> 01:32:52,080
control bbr v2 alphas traffic class

2426
01:32:50,480 --> 01:32:52,799
leading to significant unfairness

2427
01:32:52,080 --> 01:32:55,280
between the two

2428
01:32:52,800 --> 01:32:56,880
traffic classes in in general when the

2429
01:32:55,280 --> 01:33:00,800
number of bbr

2430
01:32:56,880 --> 01:33:02,560
two flows is large uh the classic flows

2431
01:33:00,800 --> 01:33:03,760
experience very small circuits so

2432
01:33:02,560 --> 01:33:05,600
please be available this is a

2433
01:33:03,760 --> 01:33:09,840
logarithmic scale you can see the

2434
01:33:05,600 --> 01:33:09,840
the total gas throughput at the top

2435
01:33:10,880 --> 01:33:13,920
and we believe that this is because

2436
01:33:12,880 --> 01:33:15,199
vbrv2

2437
01:33:13,920 --> 01:33:17,360
applies the model-based condition

2438
01:33:15,199 --> 01:33:19,280
control but what happens if the

2439
01:33:17,360 --> 01:33:21,839
network works with different models so

2440
01:33:19,280 --> 01:33:23,440
this this kind of unfairness can happen

2441
01:33:21,840 --> 01:33:26,560
then

2442
01:33:23,440 --> 01:33:29,120
and comparing that to to do our cue

2443
01:33:26,560 --> 01:33:31,440
called stateless aqm that can that can

2444
01:33:29,120 --> 01:33:33,920
provide a pretty good fairness

2445
01:33:31,440 --> 01:33:37,839
by not applying not assuming anything

2446
01:33:33,920 --> 01:33:37,840
about the condition control used

2447
01:33:38,800 --> 01:33:43,120
so in summary we have we have uh

2448
01:33:41,679 --> 01:33:45,440
performed much more

2449
01:33:43,120 --> 01:33:48,080
testbed discernments i will have a link

2450
01:33:45,440 --> 01:33:50,320
to to all the results

2451
01:33:48,080 --> 01:33:52,000
but most condition controls have rtt

2452
01:33:50,320 --> 01:33:53,440
fairness issues even in mono congestion

2453
01:33:52,000 --> 01:33:55,120
control scenarios

2454
01:33:53,440 --> 01:33:58,000
and evolve congestion controls have

2455
01:33:55,120 --> 01:33:59,920
fairness issues with legacy

2456
01:33:58,000 --> 01:34:02,080
bbr v2 vs cubic fairness is very

2457
01:33:59,920 --> 01:34:04,159
dependent on settings i actually

2458
01:34:02,080 --> 01:34:05,840
shown some some good results sometimes

2459
01:34:04,159 --> 01:34:09,040
it can become quite bad

2460
01:34:05,840 --> 01:34:09,280
and dc-tcp versus bbr v2 scalable mode

2461
01:34:09,040 --> 01:34:12,400
in

2462
01:34:09,280 --> 01:34:14,239
in general provides that fairness

2463
01:34:12,400 --> 01:34:16,239
and then an interesting finding we have

2464
01:34:14,239 --> 01:34:17,839
we have seen is that aqm tunes for a

2465
01:34:16,239 --> 01:34:18,718
specific congestion control have

2466
01:34:17,840 --> 01:34:20,880
actually

2467
01:34:18,719 --> 01:34:21,760
the potential to hurt the resistance

2468
01:34:20,880 --> 01:34:23,760
even more

2469
01:34:21,760 --> 01:34:25,520
and and they very rarely have it even

2470
01:34:23,760 --> 01:34:26,639
though they they hop in for example

2471
01:34:25,520 --> 01:34:28,320
multi-rtt

2472
01:34:26,639 --> 01:34:29,920
scenarios when the specific condition

2473
01:34:28,320 --> 01:34:31,519
control is used

2474
01:34:29,920 --> 01:34:33,040
so there are examples for the graded

2475
01:34:31,520 --> 01:34:34,159
performance compared to teardrop or

2476
01:34:33,040 --> 01:34:37,199
spend and it's pi

2477
01:34:34,159 --> 01:34:39,920
and gsp for bbr v2 vs cubic pi square

2478
01:34:37,199 --> 01:34:42,879
for dc tcp versus bbr v2

2479
01:34:39,920 --> 01:34:46,480
and dual pi square for bbrv to scalable

2480
01:34:42,880 --> 01:34:48,480
mode versus cubic

2481
01:34:46,480 --> 01:34:50,480
so in summary the condition control

2482
01:34:48,480 --> 01:34:52,400
evolution has accelerated

2483
01:34:50,480 --> 01:34:53,839
it's also possible to use a space

2484
01:34:52,400 --> 01:34:56,159
congestion control or condition

2485
01:34:53,840 --> 01:34:58,000
controlling in bpf

2486
01:34:56,159 --> 01:35:00,000
but it's very hard for a new congestion

2487
01:34:58,000 --> 01:35:01,840
controller to be both innovative and to

2488
01:35:00,000 --> 01:35:03,119
be fair to existing condition control so

2489
01:35:01,840 --> 01:35:04,960
we don't want to say

2490
01:35:03,119 --> 01:35:06,639
in any way that bbr v2 is a bad

2491
01:35:04,960 --> 01:35:09,760
congestion control we believe it's

2492
01:35:06,639 --> 01:35:11,600
actually a quite good one but but as

2493
01:35:09,760 --> 01:35:13,440
also stated in reference number one tcp

2494
01:35:11,600 --> 01:35:15,520
friendliness greatly constrains how we

2495
01:35:13,440 --> 01:35:17,519
can handle congestion in the internet

2496
01:35:15,520 --> 01:35:18,800
and and why fairness to existence

2497
01:35:17,520 --> 01:35:21,679
congestion controls is often

2498
01:35:18,800 --> 01:35:24,239
demonstrated in in special cases

2499
01:35:21,679 --> 01:35:26,080
that is that is not universal and now

2500
01:35:24,239 --> 01:35:27,199
and as the number of deployed congestion

2501
01:35:26,080 --> 01:35:29,440
controls increases

2502
01:35:27,199 --> 01:35:30,719
this becomes even harder and even the

2503
01:35:29,440 --> 01:35:32,400
harm-based buyer for a

2504
01:35:30,719 --> 01:35:34,400
new new congestion control is closely

2505
01:35:32,400 --> 01:35:36,080
impossible to meet so this is

2506
01:35:34,400 --> 01:35:38,320
i refer to the presentation which jonah

2507
01:35:36,080 --> 01:35:40,000
mentioned at the beginning

2508
01:35:38,320 --> 01:35:41,360
and i believe that two congestion

2509
01:35:40,000 --> 01:35:44,000
controls can be

2510
01:35:41,360 --> 01:35:45,920
still tuned to be compatible for some

2511
01:35:44,000 --> 01:35:47,760
scenarios but we are skeptical that this

2512
01:35:45,920 --> 01:35:48,800
can be generic enough for it this can be

2513
01:35:47,760 --> 01:35:51,920
done among several

2514
01:35:48,800 --> 01:35:51,920
new congestion controls

2515
01:35:52,800 --> 01:35:57,600
so what can be done how can we provide

2516
01:35:55,040 --> 01:36:00,080
fairness what are the ways forward

2517
01:35:57,600 --> 01:36:01,440
so today fairness is dominated by

2518
01:36:00,080 --> 01:36:03,679
end-to-end condition control and

2519
01:36:01,440 --> 01:36:05,119
and over provisioning and we question

2520
01:36:03,679 --> 01:36:08,159
whether this is still the way

2521
01:36:05,119 --> 01:36:09,679
or or whether actually tcp friendliness

2522
01:36:08,159 --> 01:36:11,920
to reno and or

2523
01:36:09,679 --> 01:36:13,360
data center tcp a point of facification

2524
01:36:11,920 --> 01:36:15,679
and the similar point of a

2525
01:36:13,360 --> 01:36:19,360
classification is aqm's tuned for a

2526
01:36:15,679 --> 01:36:21,840
specific condition control behavior

2527
01:36:19,360 --> 01:36:24,159
there is another other method used quite

2528
01:36:21,840 --> 01:36:25,760
often is that is fairness scheduling by

2529
01:36:24,159 --> 01:36:28,879
scheduling the network for example

2530
01:36:25,760 --> 01:36:31,119
fqa qms and here articular qs

2531
01:36:28,880 --> 01:36:33,040
and this is used this is working quite

2532
01:36:31,119 --> 01:36:35,519
well it has its issues

2533
01:36:33,040 --> 01:36:36,159
it's it's not practical for high-speed

2534
01:36:35,520 --> 01:36:39,679
users

2535
01:36:36,159 --> 01:36:41,440
it results on equal or or static sharing

2536
01:36:39,679 --> 01:36:44,000
which is not always optimal

2537
01:36:41,440 --> 01:36:45,119
and communicating policies to every

2538
01:36:44,000 --> 01:36:48,560
potential button

2539
01:36:45,119 --> 01:36:50,719
is hard so we believe that cooperative

2540
01:36:48,560 --> 01:36:51,440
approaches like csaqm has a good

2541
01:36:50,719 --> 01:36:55,199
potential

2542
01:36:51,440 --> 01:36:57,919
for controlling resource sharing

2543
01:36:55,199 --> 01:36:58,879
uh flow identification and policy

2544
01:36:57,920 --> 01:37:00,800
decisions are

2545
01:36:58,880 --> 01:37:01,920
done at that point endpoint or at the

2546
01:37:00,800 --> 01:37:04,639
network edge

2547
01:37:01,920 --> 01:37:06,480
in this case the implementation in the

2548
01:37:04,639 --> 01:37:08,080
routers is then very simple and

2549
01:37:06,480 --> 01:37:10,080
invariant to the number of flows or

2550
01:37:08,080 --> 01:37:11,840
invariant to the policies used

2551
01:37:10,080 --> 01:37:14,480
though it requires a header field but to

2552
01:37:11,840 --> 01:37:16,480
be on the fair side uh

2553
01:37:14,480 --> 01:37:17,519
headers or some kind of solutions are

2554
01:37:16,480 --> 01:37:19,199
needed for for

2555
01:37:17,520 --> 01:37:22,000
for many other solutions like we have

2556
01:37:19,199 --> 01:37:24,080
ecn we have an l4 s bit or we are we are

2557
01:37:22,000 --> 01:37:25,679
proposing enough for usb and also there

2558
01:37:24,080 --> 01:37:28,000
is the scp

2559
01:37:25,679 --> 01:37:29,360
but this this one requires a new header

2560
01:37:28,000 --> 01:37:32,960
field

2561
01:37:29,360 --> 01:37:36,080
so to to compare these solutions

2562
01:37:32,960 --> 01:37:36,320
created a table with the free methods

2563
01:37:36,080 --> 01:37:38,400
and

2564
01:37:36,320 --> 01:37:40,080
condition control in network and

2565
01:37:38,400 --> 01:37:41,839
cooperative sharing

2566
01:37:40,080 --> 01:37:43,760
so engine condition control provides

2567
01:37:41,840 --> 01:37:46,239
fairness by congestion control issue

2568
01:37:43,760 --> 01:37:47,600
condition control but it has fairness

2569
01:37:46,239 --> 01:37:51,440
issues and there

2570
01:37:47,600 --> 01:37:54,880
ftt unfairness is hard to solve

2571
01:37:51,440 --> 01:37:56,400
in network scheduling provides very good

2572
01:37:54,880 --> 01:37:59,520
fairness and actually solves

2573
01:37:56,400 --> 01:38:00,638
rtt and fairness by cooperative resource

2574
01:37:59,520 --> 01:38:02,880
sharing

2575
01:38:00,639 --> 01:38:03,679
provides fairness by marking packet

2576
01:38:02,880 --> 01:38:06,239
marking plus

2577
01:38:03,679 --> 01:38:07,199
aqm it provides good fairness and it

2578
01:38:06,239 --> 01:38:10,239
also solves the

2579
01:38:07,199 --> 01:38:12,239
rtt and fairness issues so

2580
01:38:10,239 --> 01:38:13,678
resource sharing is dynamic front and

2581
01:38:12,239 --> 01:38:16,559
condition control and cooperative and

2582
01:38:13,679 --> 01:38:19,920
pretty static for the network solutions

2583
01:38:16,560 --> 01:38:22,239
and the end host control the antenna

2584
01:38:19,920 --> 01:38:23,760
condition controls has a full

2585
01:38:22,239 --> 01:38:25,678
illusion of the entrance control and i'm

2586
01:38:23,760 --> 01:38:27,760
saying illusion here because

2587
01:38:25,679 --> 01:38:28,800
there is still a fake sharing of packets

2588
01:38:27,760 --> 01:38:31,600
and also

2589
01:38:28,800 --> 01:38:34,000
condition control aggressiveness and rtt

2590
01:38:31,600 --> 01:38:37,679
is very chaotic and and actually hard

2591
01:38:34,000 --> 01:38:39,840
to control there is limited control of

2592
01:38:37,679 --> 01:38:41,280
anthrax in the in-network scheduling

2593
01:38:39,840 --> 01:38:43,199
scenarios and

2594
01:38:41,280 --> 01:38:44,880
with the cooperative if actually the

2595
01:38:43,199 --> 01:38:47,119
marking is done at the end point there

2596
01:38:44,880 --> 01:38:49,520
can be high control

2597
01:38:47,119 --> 01:38:51,599
high amount of control while it can be

2598
01:38:49,520 --> 01:38:51,920
limited if there is edge marking so it's

2599
01:38:51,600 --> 01:38:54,560
if

2600
01:38:51,920 --> 01:38:56,880
if the entrance is not communicating

2601
01:38:54,560 --> 01:38:56,880
with the

2602
01:38:56,960 --> 01:39:03,520
edge and congestion control evolution

2603
01:39:01,600 --> 01:39:05,840
is is constrained by end-to-end

2604
01:39:03,520 --> 01:39:09,600
condition control based fairning

2605
01:39:05,840 --> 01:39:11,199
fairness because uh because of the harm

2606
01:39:09,600 --> 01:39:12,159
to existing congestion control and it's

2607
01:39:11,199 --> 01:39:14,879
less constrained

2608
01:39:12,159 --> 01:39:16,638
constrained in the two other cases and

2609
01:39:14,880 --> 01:39:18,560
the bottleneck complexities

2610
01:39:16,639 --> 01:39:19,920
is low for end-to-end condition control

2611
01:39:18,560 --> 01:39:21,920
this is basically the buttons we have

2612
01:39:19,920 --> 01:39:24,239
today we don't have to change anything

2613
01:39:21,920 --> 01:39:25,520
for the in-network we believe that in

2614
01:39:24,239 --> 01:39:27,280
most cases

2615
01:39:25,520 --> 01:39:29,520
some kind of cpu-based solution is

2616
01:39:27,280 --> 01:39:31,519
needed especially for high number flows

2617
01:39:29,520 --> 01:39:33,280
or especially if you want to control

2618
01:39:31,520 --> 01:39:35,199
higher ories of resource sharing

2619
01:39:33,280 --> 01:39:38,639
while it's medium for cooperative we

2620
01:39:35,199 --> 01:39:41,919
were able to successfully implement

2621
01:39:38,639 --> 01:39:43,440
the aqm in in p4

2622
01:39:41,920 --> 01:39:45,360
there is no need for signaling for

2623
01:39:43,440 --> 01:39:49,119
end-to-end condition control

2624
01:39:45,360 --> 01:39:51,920
uh there is a high need of

2625
01:39:49,119 --> 01:39:53,759
signaling for every potential button

2626
01:39:51,920 --> 01:39:56,159
like in the in-network case

2627
01:39:53,760 --> 01:39:58,159
and depending on how how we do marking

2628
01:39:56,159 --> 01:40:00,000
some kind of signaling might be needed

2629
01:39:58,159 --> 01:40:02,879
and actually the packet marking is a

2630
01:40:00,000 --> 01:40:04,239
kind of inbound signaling also

2631
01:40:02,880 --> 01:40:05,600
also the antenna condition country is a

2632
01:40:04,239 --> 01:40:07,119
cooldown state of effort so it doesn't

2633
01:40:05,600 --> 01:40:09,199
require standardization

2634
01:40:07,119 --> 01:40:10,559
the in-network likely requires some

2635
01:40:09,199 --> 01:40:13,199
signaling unless we

2636
01:40:10,560 --> 01:40:14,000
are okay with the flow fairness

2637
01:40:13,199 --> 01:40:15,759
basically

2638
01:40:14,000 --> 01:40:19,600
and the cooperatives require some kind

2639
01:40:15,760 --> 01:40:19,600
of standardization for packet marking

2640
01:40:21,440 --> 01:40:26,719
so questions to community future work

2641
01:40:24,960 --> 01:40:28,400
first question is what more to include

2642
01:40:26,719 --> 01:40:30,560
in these type of evaluation congestion

2643
01:40:28,400 --> 01:40:33,040
controls aqms rtts

2644
01:40:30,560 --> 01:40:35,119
also what is uh what are the typical

2645
01:40:33,040 --> 01:40:36,880
implementations when it comes to

2646
01:40:35,119 --> 01:40:38,960
operating systems and meaningful

2647
01:40:36,880 --> 01:40:41,760
defaults of the of the

2648
01:40:38,960 --> 01:40:42,560
congestion controls also very important

2649
01:40:41,760 --> 01:40:46,000
question to

2650
01:40:42,560 --> 01:40:47,920
to discuss and and uh is that what are

2651
01:40:46,000 --> 01:40:50,000
the typical battery lacks what is the

2652
01:40:47,920 --> 01:40:51,920
speed of them how many flows do we have

2653
01:40:50,000 --> 01:40:53,760
over them and how many button actually

2654
01:40:51,920 --> 01:40:55,520
consider in the path

2655
01:40:53,760 --> 01:40:57,360
and the third interesting question is is

2656
01:40:55,520 --> 01:40:59,119
the effect of the sub millisecond

2657
01:40:57,360 --> 01:41:01,920
internet on fairness so

2658
01:40:59,119 --> 01:41:02,480
some caches are very close to the edge

2659
01:41:01,920 --> 01:41:05,119
and

2660
01:41:02,480 --> 01:41:07,199
do and flow still have a chance when

2661
01:41:05,119 --> 01:41:10,559
when sharing a button like form

2662
01:41:07,199 --> 01:41:12,239
with these submission flows so you can

2663
01:41:10,560 --> 01:41:16,080
find our results at

2664
01:41:12,239 --> 01:41:17,919
this web pages

2665
01:41:16,080 --> 01:41:19,199
and i'm looking forward to your

2666
01:41:17,920 --> 01:41:21,520
questions and comments

2667
01:41:19,199 --> 01:41:21,519
thank you

2668
01:41:25,600 --> 01:41:28,400
what's yesterday

2669
01:41:28,880 --> 01:41:37,760
um cohn is in line

2670
01:41:33,360 --> 01:41:40,799
go for it hi here

2671
01:41:37,760 --> 01:41:43,119
can you hear me yes yes

2672
01:41:40,800 --> 01:41:44,320
thank you for this work it's very

2673
01:41:43,119 --> 01:41:46,400
interesting and

2674
01:41:44,320 --> 01:41:47,599
i think it opens also a very interesting

2675
01:41:46,400 --> 01:41:51,040
discussion

2676
01:41:47,600 --> 01:41:52,159
um because indeed from from alpharest

2677
01:41:51,040 --> 01:41:55,840
point of view

2678
01:41:52,159 --> 01:41:58,559
the strategy here is to try to line up

2679
01:41:55,840 --> 01:41:59,280
long-term congestion controls to to be

2680
01:41:58,560 --> 01:42:01,760
fair

2681
01:41:59,280 --> 01:42:03,679
so that the aqm like you showed doesn't

2682
01:42:01,760 --> 01:42:05,760
need to make differentiation between the

2683
01:42:03,679 --> 01:42:07,840
different types of congestion controls

2684
01:42:05,760 --> 01:42:09,840
well for alpharest we did a big up

2685
01:42:07,840 --> 01:42:13,360
between the classic and

2686
01:42:09,840 --> 01:42:14,639
and alpha s traffic so i think it's very

2687
01:42:13,360 --> 01:42:17,759
valuable to do these

2688
01:42:14,639 --> 01:42:18,800
these comparisons definitely um it's

2689
01:42:17,760 --> 01:42:22,080
also a good

2690
01:42:18,800 --> 01:42:22,400
discussion whether um we we should do

2691
01:42:22,080 --> 01:42:26,480
this

2692
01:42:22,400 --> 01:42:27,920
differentiation or not um

2693
01:42:26,480 --> 01:42:29,759
from within the network and whether the

2694
01:42:27,920 --> 01:42:30,239
network is really responsible for doing

2695
01:42:29,760 --> 01:42:33,840
this

2696
01:42:30,239 --> 01:42:35,519
or that we also should focus also on

2697
01:42:33,840 --> 01:42:37,199
the cases where it's not possible to do

2698
01:42:35,520 --> 01:42:38,800
something in the network to also make

2699
01:42:37,199 --> 01:42:40,719
sure that congestion controls

2700
01:42:38,800 --> 01:42:42,719
really have a common protocol and a

2701
01:42:40,719 --> 01:42:45,760
common behavior

2702
01:42:42,719 --> 01:42:48,000
related to ecn marking definitely drops

2703
01:42:45,760 --> 01:42:50,239
but also i think it's more important to

2704
01:42:48,000 --> 01:42:53,840
to have this behavior on the longer term

2705
01:42:50,239 --> 01:42:56,879
um so yeah

2706
01:42:53,840 --> 01:42:58,000
i think it's a a good point for

2707
01:42:56,880 --> 01:43:00,639
discussion

2708
01:42:58,000 --> 01:43:01,040
and as as you know alphares is relying

2709
01:43:00,639 --> 01:43:04,480
on

2710
01:43:01,040 --> 01:43:07,760
on the the end system to to uh

2711
01:43:04,480 --> 01:43:10,879
to do at least their best they can do

2712
01:43:07,760 --> 01:43:13,360
to to line up

2713
01:43:10,880 --> 01:43:14,960
i don't know yeah i guess it's up to

2714
01:43:13,360 --> 01:43:16,960
other people also to have this

2715
01:43:14,960 --> 01:43:18,719
discussion

2716
01:43:16,960 --> 01:43:20,560
[Music]

2717
01:43:18,719 --> 01:43:25,840
but thank you for the work it's very

2718
01:43:20,560 --> 01:43:25,840
useful thank you for your comment coin

2719
01:43:30,080 --> 01:43:33,840
thank you and thank you so much

2720
01:43:32,480 --> 01:43:37,040
sylvester

2721
01:43:33,840 --> 01:43:38,880
thank you i would again encourage

2722
01:43:37,040 --> 01:43:40,639
the conversation to continue on the

2723
01:43:38,880 --> 01:43:41,679
mailing list this is for the presenters

2724
01:43:40,639 --> 01:43:44,080
as well as for the

2725
01:43:41,679 --> 01:43:44,880
for the other folks in the group uh

2726
01:43:44,080 --> 01:43:46,880
please go ahead

2727
01:43:44,880 --> 01:43:49,199
and and kickstart conversations on the

2728
01:43:46,880 --> 01:43:52,880
mailing list i think that's a much much

2729
01:43:49,199 --> 01:43:55,119
higher uh you can have much deeper and

2730
01:43:52,880 --> 01:43:58,560
higher bandwidth engagement there

2731
01:43:55,119 --> 01:44:00,639
um all right moving along is uh bob

2732
01:43:58,560 --> 01:44:02,480
or which one of you is going to do

2733
01:44:00,639 --> 01:44:04,560
this

2734
01:44:02,480 --> 01:44:06,718
i'm probably going to start um and then

2735
01:44:04,560 --> 01:44:09,679
 will do um

2736
01:44:06,719 --> 01:44:10,400
we'll switch to in the middle okay

2737
01:44:09,679 --> 01:44:12,880
uh just

2738
01:44:10,400 --> 01:44:14,960
a quick note uh bob that we have 16

2739
01:44:12,880 --> 01:44:17,520
minutes before the end of the session

2740
01:44:14,960 --> 01:44:18,080
um so i want to give you a heads up on

2741
01:44:17,520 --> 01:44:21,119
that okay

2742
01:44:18,080 --> 01:44:25,040
take it away all right so um

2743
01:44:21,119 --> 01:44:29,599
this is let's talk about tcp prague um

2744
01:44:25,040 --> 01:44:34,480
which the authors are there

2745
01:44:29,600 --> 01:44:37,119
let's move straight on next slide

2746
01:44:34,480 --> 01:44:37,119
uh jenna

2747
01:44:40,320 --> 01:44:46,960
yep um so as i mentioned in

2748
01:44:43,840 --> 01:44:48,400
tsvwg if you were there

2749
01:44:46,960 --> 01:44:50,639
this is going to be a bit of an

2750
01:44:48,400 --> 01:44:55,119
invitation to collaborate because

2751
01:44:50,639 --> 01:44:58,320
um when we first started on l4s

2752
01:44:55,119 --> 01:45:02,159
back five years ago i think um

2753
01:44:58,320 --> 01:45:05,440
dc tcp that we were using version 319

2754
01:45:02,159 --> 01:45:08,638
the linux linux kernel um

2755
01:45:05,440 --> 01:45:12,000
just happened to work really well

2756
01:45:08,639 --> 01:45:15,360
but um and we carried on using it for

2757
01:45:12,000 --> 01:45:16,639
um maybe three years because we were

2758
01:45:15,360 --> 01:45:20,239
really focusing on

2759
01:45:16,639 --> 01:45:21,360
aqm products um we were mainly network

2760
01:45:20,239 --> 01:45:23,360
companies

2761
01:45:21,360 --> 01:45:24,480
we were dealing with the um some safety

2762
01:45:23,360 --> 01:45:27,199
aspects

2763
01:45:24,480 --> 01:45:27,759
but um we were largely just sticking

2764
01:45:27,199 --> 01:45:31,199
with

2765
01:45:27,760 --> 01:45:32,560
uh what worked and when we tried to

2766
01:45:31,199 --> 01:45:34,400
use later versions of the kernel it

2767
01:45:32,560 --> 01:45:35,760
didn't work that well but um

2768
01:45:34,400 --> 01:45:37,119
we were mostly just sticking with what

2769
01:45:35,760 --> 01:45:38,800
we've got and then we started getting

2770
01:45:37,119 --> 01:45:42,080
criticisms that

2771
01:45:38,800 --> 01:45:44,880
didn't work with later kernels

2772
01:45:42,080 --> 01:45:46,080
and finally started looking at it and

2773
01:45:44,880 --> 01:45:49,600
found there was a

2774
01:45:46,080 --> 01:45:53,280
real rat's nest of tangled bugs

2775
01:45:49,600 --> 01:45:56,480
um and they seemed to have

2776
01:45:53,280 --> 01:45:59,759
come into the um linux kernel

2777
01:45:56,480 --> 01:46:02,559
um since 319 and

2778
01:45:59,760 --> 01:46:04,000
uh it's taken us it took us months to

2779
01:46:02,560 --> 01:46:05,440
work it all out anyway so

2780
01:46:04,000 --> 01:46:07,600
coon's going to talk a bit about that in

2781
01:46:05,440 --> 01:46:09,839
the middle of this talk

2782
01:46:07,600 --> 01:46:11,760
i mean we we fixed it probably about a

2783
01:46:09,840 --> 01:46:14,880
year ago now but we haven't really

2784
01:46:11,760 --> 01:46:18,080
talked about it since um

2785
01:46:14,880 --> 01:46:21,040
so what what we really think is

2786
01:46:18,080 --> 01:46:22,159
that it got a bit of a bad reputation

2787
01:46:21,040 --> 01:46:26,639
for

2788
01:46:22,159 --> 01:46:29,920
um not being um

2789
01:46:26,639 --> 01:46:33,040
it's possible to uh reproduce any of our

2790
01:46:29,920 --> 01:46:35,520
results because no one could

2791
01:46:33,040 --> 01:46:38,800
um use it on the latest kernel and so we

2792
01:46:35,520 --> 01:46:41,920
we want to do a bit of a relaunch

2793
01:46:38,800 --> 01:46:44,239
now that the code base is usable

2794
01:46:41,920 --> 01:46:45,679
for others you know it's been up um

2795
01:46:44,239 --> 01:46:48,799
against the latest version of

2796
01:46:45,679 --> 01:46:52,080
um the kernel now for a good um

2797
01:46:48,800 --> 01:46:54,400
year or so and so um

2798
01:46:52,080 --> 01:46:55,679
and also it seems likely that we're

2799
01:46:54,400 --> 01:46:58,559
going to start seeing

2800
01:46:55,679 --> 01:46:59,440
deployments in the network probably not

2801
01:46:58,560 --> 01:47:00,639
like in the next

2802
01:46:59,440 --> 01:47:02,638
few months because they're going to

2803
01:47:00,639 --> 01:47:06,400
depend on the code point assignment

2804
01:47:02,639 --> 01:47:09,119
but once that does come um i think the

2805
01:47:06,400 --> 01:47:10,080
um you'll start to see it in production

2806
01:47:09,119 --> 01:47:12,559
networks

2807
01:47:10,080 --> 01:47:13,920
so um i'll come back to the invitation

2808
01:47:12,560 --> 01:47:14,320
to collaborate at the end if we can move

2809
01:47:13,920 --> 01:47:16,400
on

2810
01:47:14,320 --> 01:47:17,679
to the next slide that was just a bit of

2811
01:47:16,400 --> 01:47:21,199
background as to

2812
01:47:17,679 --> 01:47:23,440
why we're giving this talk jenna next

2813
01:47:21,199 --> 01:47:26,559
so first i wanted to give a very very

2814
01:47:23,440 --> 01:47:28,080
quick tutorial on dc tcp so for those

2815
01:47:26,560 --> 01:47:29,760
who aren't familiar with some of the

2816
01:47:28,080 --> 01:47:32,960
things coon's going to talk about it it

2817
01:47:29,760 --> 01:47:32,960
will give some context next

2818
01:47:34,560 --> 01:47:41,280
right so i guess the the main thing

2819
01:47:38,320 --> 01:47:42,880
um i believe is important about data

2820
01:47:41,280 --> 01:47:43,759
center tcp and it's not often seen this

2821
01:47:42,880 --> 01:47:45,920
way

2822
01:47:43,760 --> 01:47:47,679
is um that the smoothing of the

2823
01:47:45,920 --> 01:47:52,000
congestion signals

2824
01:47:47,679 --> 01:47:55,280
shifts out of the network where um

2825
01:47:52,000 --> 01:47:58,000
aqms traditionally have filtered out

2826
01:47:55,280 --> 01:48:00,159
variations in the queue obviously the

2827
01:47:58,000 --> 01:48:02,000
queue still varies they've filtered out

2828
01:48:00,159 --> 01:48:03,519
measurements of variations in the queue

2829
01:48:02,000 --> 01:48:04,639
before signaling drop because they

2830
01:48:03,520 --> 01:48:08,239
didn't want to

2831
01:48:04,639 --> 01:48:11,280
signal drop too early and um

2832
01:48:08,239 --> 01:48:13,599
because dc tcp uses ecn it can shift

2833
01:48:11,280 --> 01:48:17,199
that responsibility to the end system

2834
01:48:13,600 --> 01:48:18,320
and then the important difference is

2835
01:48:17,199 --> 01:48:21,360
that

2836
01:48:18,320 --> 01:48:24,559
the when it's in the network the

2837
01:48:21,360 --> 01:48:28,159
um delay

2838
01:48:24,560 --> 01:48:31,199
that the smoothing has to add um

2839
01:48:28,159 --> 01:48:32,879
just in case it's not really um

2840
01:48:31,199 --> 01:48:35,839
just in case the q variation is going to

2841
01:48:32,880 --> 01:48:39,280
go away has to be about a worst case rtt

2842
01:48:35,840 --> 01:48:42,000
typically 100 milliseconds um

2843
01:48:39,280 --> 01:48:42,719
whereas once you move to the end system

2844
01:48:42,000 --> 01:48:44,560
it can

2845
01:48:42,719 --> 01:48:46,400
smooth based on its own round trip time

2846
01:48:44,560 --> 01:48:48,080
and it always the

2847
01:48:46,400 --> 01:48:50,239
end systems that are using a particular

2848
01:48:48,080 --> 01:48:51,840
bottleneck can all be smoothing on their

2849
01:48:50,239 --> 01:48:54,480
own round trip times

2850
01:48:51,840 --> 01:48:55,360
um and also very importantly the zero

2851
01:48:54,480 --> 01:48:58,400
there

2852
01:48:55,360 --> 01:49:00,880
um that they actually get the signal

2853
01:48:58,400 --> 01:49:02,879
with no smoothing delay if they want to

2854
01:49:00,880 --> 01:49:06,320
react to it straight away so

2855
01:49:02,880 --> 01:49:09,840
if you can do next slide it builds

2856
01:49:06,320 --> 01:49:11,199
um jenna then they can choose not to

2857
01:49:09,840 --> 01:49:14,800
smooth at all for instance

2858
01:49:11,199 --> 01:49:17,280
during flow when the flow is starting up

2859
01:49:14,800 --> 01:49:19,360
and of course um you've got zero delay

2860
01:49:17,280 --> 01:49:24,480
on the network side as well

2861
01:49:19,360 --> 01:49:24,480
um you've got an instantaneous q um

2862
01:49:24,800 --> 01:49:29,840
aqm sorry so um next

2863
01:49:31,280 --> 01:49:35,040
i said i'd go quick and i'm not am i um

2864
01:49:34,080 --> 01:49:38,080
through this

2865
01:49:35,040 --> 01:49:41,599
um so the

2866
01:49:38,080 --> 01:49:44,639
the way that the end system smooths

2867
01:49:41,599 --> 01:49:45,599
in um in dc tcp this is really the only

2868
01:49:44,639 --> 01:49:47,920
difference from reno

2869
01:49:45,599 --> 01:49:49,440
other than a load of implementation

2870
01:49:47,920 --> 01:49:50,639
details different but it's the only real

2871
01:49:49,440 --> 01:49:52,239
design difference

2872
01:49:50,639 --> 01:49:54,880
it just takes a fraction of the marks

2873
01:49:52,239 --> 01:49:58,718
every round trip time doesn't ewma of it

2874
01:49:54,880 --> 01:50:01,440
and then uses that ewma to scale down

2875
01:49:58,719 --> 01:50:02,560
the reductions which is why it does a

2876
01:50:01,440 --> 01:50:04,879
reduction by extent

2877
01:50:02,560 --> 01:50:04,880
next

2878
01:50:07,599 --> 01:50:14,719
yep so um the

2879
01:50:10,719 --> 01:50:15,760
effect of that is the memory in the end

2880
01:50:14,719 --> 01:50:18,960
systems

2881
01:50:15,760 --> 01:50:20,400
um it deals with the fact that short

2882
01:50:18,960 --> 01:50:22,480
flows and bursts

2883
01:50:20,400 --> 01:50:23,519
are effectively unresponsive and what it

2884
01:50:22,480 --> 01:50:27,360
does

2885
01:50:23,520 --> 01:50:30,239
it um in the classic approach sorry

2886
01:50:27,360 --> 01:50:31,119
um not what it does yet in the classic

2887
01:50:30,239 --> 01:50:34,638
approach

2888
01:50:31,119 --> 01:50:36,320
and including bbr um short flows burst

2889
01:50:34,639 --> 01:50:39,119
into the buffer

2890
01:50:36,320 --> 01:50:39,920
so the the buffer is held um slightly

2891
01:50:39,119 --> 01:50:43,759
full

2892
01:50:39,920 --> 01:50:46,880
even with bbr um and and fuller with

2893
01:50:43,760 --> 01:50:47,760
um obviously um tower drop and the rest

2894
01:50:46,880 --> 01:50:50,320
of it

2895
01:50:47,760 --> 01:50:51,040
um and then short flows burst into the

2896
01:50:50,320 --> 01:50:53,599
buffer

2897
01:50:51,040 --> 01:50:55,440
where whereas with um data center tcp

2898
01:50:53,599 --> 01:50:58,719
and l4s and so on

2899
01:50:55,440 --> 01:50:59,199
uh the long running flows leave headroom

2900
01:50:58,719 --> 01:51:03,119
for the

2901
01:50:59,199 --> 01:51:05,678
recent level of short short flows um

2902
01:51:03,119 --> 01:51:06,880
and they they've learned that headroom

2903
01:51:05,679 --> 01:51:09,599
from

2904
01:51:06,880 --> 01:51:11,840
maintaining that ewma of the feedback

2905
01:51:09,599 --> 01:51:14,719
and so the short flows

2906
01:51:11,840 --> 01:51:16,639
um burst into that headroom and stay

2907
01:51:14,719 --> 01:51:20,239
below the threshold

2908
01:51:16,639 --> 01:51:22,719
unless they're just occasional surprise

2909
01:51:20,239 --> 01:51:23,678
short flows that the memory um isn't

2910
01:51:22,719 --> 01:51:27,360
used to

2911
01:51:23,679 --> 01:51:31,280
next so that's really

2912
01:51:27,360 --> 01:51:33,920
um next jenna um so this is now

2913
01:51:31,280 --> 01:51:35,119
the core of the presentation um next

2914
01:51:33,920 --> 01:51:38,080
please jana

2915
01:51:35,119 --> 01:51:38,880
and just wanted to start with a um

2916
01:51:38,080 --> 01:51:41,920
traffic light

2917
01:51:38,880 --> 01:51:43,760
slide that i've used before

2918
01:51:41,920 --> 01:51:45,840
um many times but you'll see it's got

2919
01:51:43,760 --> 01:51:49,920
some extra bits added on the end

2920
01:51:45,840 --> 01:51:53,040
um these are all the bits of um

2921
01:51:49,920 --> 01:51:54,719
a prior congestion control that have to

2922
01:51:53,040 --> 01:51:56,880
um

2923
01:51:54,719 --> 01:51:59,119
be there to be safe on the internet for

2924
01:51:56,880 --> 01:52:00,840
the in the first block the requirements

2925
01:51:59,119 --> 01:52:03,040
and to perform well which is the second

2926
01:52:00,840 --> 01:52:04,960
block and that used to just have

2927
01:52:03,040 --> 01:52:06,639
two items in it the top two in the

2928
01:52:04,960 --> 01:52:09,679
performance

2929
01:52:06,639 --> 01:52:12,239
area um but we've

2930
01:52:09,679 --> 01:52:14,239
added a number of others as we've found

2931
01:52:12,239 --> 01:52:16,480
all these problems

2932
01:52:14,239 --> 01:52:17,440
that um kuhn's going to talk more about

2933
01:52:16,480 --> 01:52:21,280
some of those

2934
01:52:17,440 --> 01:52:24,080
areas um and i'm not going to even

2935
01:52:21,280 --> 01:52:24,559
read out all the titles and you know you

2936
01:52:24,080 --> 01:52:25,840
can

2937
01:52:24,560 --> 01:52:28,000
have a look at this slide in your own

2938
01:52:25,840 --> 01:52:30,000
time um because

2939
01:52:28,000 --> 01:52:32,639
the point of it is merely to show that

2940
01:52:30,000 --> 01:52:35,599
there's more stuff added on the bottom

2941
01:52:32,639 --> 01:52:36,239
uh including bug fixes which you know

2942
01:52:35,599 --> 01:52:38,000
obviously

2943
01:52:36,239 --> 01:52:39,280
performance improvements and when i say

2944
01:52:38,000 --> 01:52:41,040
bug fixes these aren't

2945
01:52:39,280 --> 01:52:42,400
sort of code bugs they're performance

2946
01:52:41,040 --> 01:52:44,560
bugs where

2947
01:52:42,400 --> 01:52:45,759
the effect of the bug is to reduce the

2948
01:52:44,560 --> 01:52:47,840
performance

2949
01:52:45,760 --> 01:52:49,040
so um kuhn i don't know whether you want

2950
01:52:47,840 --> 01:52:50,480
to pick up on this side i'll move

2951
01:52:49,040 --> 01:52:54,000
straight to the next one

2952
01:52:50,480 --> 01:52:54,000
yeah next slide i guess

2953
01:52:54,400 --> 01:52:59,119
for the time so first slide i want to

2954
01:52:57,520 --> 01:53:02,159
show is um

2955
01:52:59,119 --> 01:53:04,719
uh the the the improvements we did

2956
01:53:02,159 --> 01:53:05,679
in in prague we had to do in prague to

2957
01:53:04,719 --> 01:53:08,080
to solve the

2958
01:53:05,679 --> 01:53:10,480
the quite bad degraded behavior of data

2959
01:53:08,080 --> 01:53:14,159
centers being the recent kernels

2960
01:53:10,480 --> 01:53:15,280
so um if you if you look uh the queuing

2961
01:53:14,159 --> 01:53:18,799
latency

2962
01:53:15,280 --> 01:53:19,920
spikes are very high um and and we found

2963
01:53:18,800 --> 01:53:23,520
out it's mainly

2964
01:53:19,920 --> 01:53:28,880
due to less responsiveness

2965
01:53:23,520 --> 01:53:28,880
on on one hand because of rounding downs

2966
01:53:29,280 --> 01:53:34,159
also not enough number of bits which

2967
01:53:33,119 --> 01:53:37,679
were used

2968
01:53:34,159 --> 01:53:41,360
in integers we

2969
01:53:37,679 --> 01:53:44,159
we definitely had issues with tso sizing

2970
01:53:41,360 --> 01:53:44,880
and the pacing with it so the default

2971
01:53:44,159 --> 01:53:48,480
settings

2972
01:53:44,880 --> 01:53:52,239
which we had to adapt there are bugs in

2973
01:53:48,480 --> 01:53:55,839
br which have a small impact on

2974
01:53:52,239 --> 01:53:55,839
cubic and other

2975
01:53:57,840 --> 01:54:02,960
let's say classic congestion control but

2976
01:53:59,520 --> 01:54:05,199
had a huge impact on on data center tcp

2977
01:54:02,960 --> 01:54:06,800
and also to to even further improve

2978
01:54:05,199 --> 01:54:09,119
smoothing we also found

2979
01:54:06,800 --> 01:54:11,520
that the there was a need for partial

2980
01:54:09,119 --> 01:54:15,280
additive increase

2981
01:54:11,520 --> 01:54:15,760
so instead of when there is a slide for

2982
01:54:15,280 --> 01:54:18,639
it

2983
01:54:15,760 --> 01:54:19,520
uh non-response at a certain time which

2984
01:54:18,639 --> 01:54:22,320
makes it also

2985
01:54:19,520 --> 01:54:24,080
vary a lot so if you really look at it

2986
01:54:22,320 --> 01:54:26,799
under the same conditions with the one

2987
01:54:24,080 --> 01:54:29,840
millisecond thresholds if people tried

2988
01:54:26,800 --> 01:54:32,719
in a long year to reproduce and and i

2989
01:54:29,840 --> 01:54:33,840
also saw that uh the the presentations

2990
01:54:32,719 --> 01:54:36,960
from

2991
01:54:33,840 --> 01:54:39,440
sylvester um

2992
01:54:36,960 --> 01:54:40,480
also use data center tcp the latest

2993
01:54:39,440 --> 01:54:42,799
kernel version

2994
01:54:40,480 --> 01:54:44,080
you will see it really underutilizes the

2995
01:54:42,800 --> 01:54:46,159
link

2996
01:54:44,080 --> 01:54:48,239
so in our prague version we fixed all

2997
01:54:46,159 --> 01:54:50,000
those and it was really difficult

2998
01:54:48,239 --> 01:54:51,598
because we had to remove

2999
01:54:50,000 --> 01:54:53,679
all of them before we got the good

3000
01:54:51,599 --> 01:54:55,920
result again um

3001
01:54:53,679 --> 01:54:58,159
so we spent quite some time a few years

3002
01:54:55,920 --> 01:54:59,520
or a year ago or more than a year ago in

3003
01:54:58,159 --> 01:55:02,638
the meantime

3004
01:54:59,520 --> 01:55:05,760
so to get back our initial 3.19

3005
01:55:02,639 --> 01:55:08,159
results so i think

3006
01:55:05,760 --> 01:55:10,480
that's very important to know if you

3007
01:55:08,159 --> 01:55:12,480
want to do experiments please use prague

3008
01:55:10,480 --> 01:55:14,320
instead of data center tcp in the latest

3009
01:55:12,480 --> 01:55:19,360
kernel

3010
01:55:14,320 --> 01:55:22,480
next slide

3011
01:55:19,360 --> 01:55:26,480
so the the the smoother steady state

3012
01:55:22,480 --> 01:55:29,119
additive increase if you are aware

3013
01:55:26,480 --> 01:55:29,598
if data center tcp is driven by an aqm

3014
01:55:29,119 --> 01:55:32,639
which is

3015
01:55:29,599 --> 01:55:36,560
smoothing like in a coupling or or

3016
01:55:32,639 --> 01:55:39,199
in in pi square or whatever other aqm

3017
01:55:36,560 --> 01:55:40,719
you you need you expect that every round

3018
01:55:39,199 --> 01:55:44,239
trip time there are marks

3019
01:55:40,719 --> 01:55:45,040
but classic uh congestion controls and

3020
01:55:44,239 --> 01:55:47,119
also

3021
01:55:45,040 --> 01:55:48,960
data center tcp took it over it

3022
01:55:47,119 --> 01:55:51,119
suppresses the additive increase

3023
01:55:48,960 --> 01:55:52,080
in the round trip time after a multiple

3024
01:55:51,119 --> 01:55:53,920
decrease so when

3025
01:55:52,080 --> 01:55:55,920
it's in the congestion window reduce

3026
01:55:53,920 --> 01:55:58,320
state

3027
01:55:55,920 --> 01:55:59,440
so that means that if you get marks

3028
01:55:58,320 --> 01:56:01,840
every round trip time

3029
01:55:59,440 --> 01:56:04,559
for you inspect expect that that you

3030
01:56:01,840 --> 01:56:07,840
don't have any opportunity to increase

3031
01:56:04,560 --> 01:56:09,360
so um because of that your aqm will

3032
01:56:07,840 --> 01:56:10,000
start to oscillate the interaction

3033
01:56:09,360 --> 01:56:12,639
because

3034
01:56:10,000 --> 01:56:14,239
it's putting the right marking

3035
01:56:12,639 --> 01:56:17,119
probability and then

3036
01:56:14,239 --> 01:56:18,400
it becomes non-responsive so it goes

3037
01:56:17,119 --> 01:56:20,400
down

3038
01:56:18,400 --> 01:56:22,159
because it allows it to increase again

3039
01:56:20,400 --> 01:56:24,879
and then certainly it's

3040
01:56:22,159 --> 01:56:25,440
uh the probability is too low so so all

3041
01:56:24,880 --> 01:56:29,199
of these

3042
01:56:25,440 --> 01:56:32,480
interactions were creating extra

3043
01:56:29,199 --> 01:56:33,678
periods of going up going down which are

3044
01:56:32,480 --> 01:56:35,759
not good of course

3045
01:56:33,679 --> 01:56:36,800
and then also for round trip time

3046
01:56:35,760 --> 01:56:39,040
dependence

3047
01:56:36,800 --> 01:56:41,119
if you have a very big round trip time

3048
01:56:39,040 --> 01:56:43,040
of course if you compete with a small

3049
01:56:41,119 --> 01:56:45,280
round trip time you will definitely get

3050
01:56:43,040 --> 01:56:47,440
every round trip time marks so that

3051
01:56:45,280 --> 01:56:49,280
means that a bigger round trip time will

3052
01:56:47,440 --> 01:56:51,598
get pushed down completely

3053
01:56:49,280 --> 01:56:52,400
so this is an important difference

3054
01:56:51,599 --> 01:56:55,440
between

3055
01:56:52,400 --> 01:56:58,960
prague and data center tcp

3056
01:56:55,440 --> 01:57:01,759
that we have in in prague

3057
01:56:58,960 --> 01:57:02,560
so in prague what we do we increase on

3058
01:57:01,760 --> 01:57:06,080
every ack

3059
01:57:02,560 --> 01:57:08,719
except on the ones that echo an ecn mark

3060
01:57:06,080 --> 01:57:10,320
so it's a kind of proportional additive

3061
01:57:08,719 --> 01:57:13,280
increase as well so we

3062
01:57:10,320 --> 01:57:14,080
we do only one a half a packet increase

3063
01:57:13,280 --> 01:57:16,000
if 50

3064
01:57:14,080 --> 01:57:17,199
of the the packets are marked in that

3065
01:57:16,000 --> 01:57:20,320
case

3066
01:57:17,199 --> 01:57:20,320
okay next slide

3067
01:57:23,360 --> 01:57:30,239
um so so to to compare a little bit

3068
01:57:27,440 --> 01:57:30,799
uh what are the the the real benefits of

3069
01:57:30,239 --> 01:57:34,400
of

3070
01:57:30,800 --> 01:57:35,920
using prague or alfres or the data

3071
01:57:34,400 --> 01:57:39,920
center tcp kind of

3072
01:57:35,920 --> 01:57:41,679
uh flows is that um obviously we have a

3073
01:57:39,920 --> 01:57:44,719
very smooth throughput

3074
01:57:41,679 --> 01:57:47,520
um and a very low latency you see

3075
01:57:44,719 --> 01:57:49,199
here uh in in blue at the right we are

3076
01:57:47,520 --> 01:57:51,840
below one millisecond

3077
01:57:49,199 --> 01:57:53,759
still having full link utilization in a

3078
01:57:51,840 --> 01:57:57,520
wide range of

3079
01:57:53,760 --> 01:58:00,880
cases okay there is a a worse

3080
01:57:57,520 --> 01:58:03,599
startup and it becomes worse

3081
01:58:00,880 --> 01:58:06,880
when the bdp becomes bigger so for

3082
01:58:03,599 --> 01:58:09,599
longer round trip times but

3083
01:58:06,880 --> 01:58:10,800
these these are things which we haven't

3084
01:58:09,599 --> 01:58:13,840
fully focused on

3085
01:58:10,800 --> 01:58:17,040
or or well there are

3086
01:58:13,840 --> 01:58:17,679
research in progress uh work is being

3087
01:58:17,040 --> 01:58:20,320
done but

3088
01:58:17,679 --> 01:58:22,320
okay it's uh it was a little bit shifted

3089
01:58:20,320 --> 01:58:24,880
behind because of all the

3090
01:58:22,320 --> 01:58:26,400
the safety issues and and the the

3091
01:58:24,880 --> 01:58:27,040
discussions on the mailing list but

3092
01:58:26,400 --> 01:58:29,839
anyway

3093
01:58:27,040 --> 01:58:33,280
that there are potentials to to clearly

3094
01:58:29,840 --> 01:58:36,400
potentials to to optimize that

3095
01:58:33,280 --> 01:58:39,119
so comparing it to okay the best case

3096
01:58:36,400 --> 01:58:39,920
uh codal five milliseconds on on a

3097
01:58:39,119 --> 01:58:43,199
bottleneck

3098
01:58:39,920 --> 01:58:45,280
there is still a significant improvement

3099
01:58:43,199 --> 01:58:49,839
let's say

3100
01:58:45,280 --> 01:58:49,840
next slide

3101
01:58:50,719 --> 01:58:55,760
so um one of the things we have also

3102
01:58:54,320 --> 01:58:59,040
worked on is a better

3103
01:58:55,760 --> 01:59:00,960
round-trip time independence and uh

3104
01:58:59,040 --> 01:59:02,239
we can play with it and and do whatever

3105
01:59:00,960 --> 01:59:04,960
we want with it so

3106
01:59:02,239 --> 01:59:06,879
um that's that's the main message the

3107
01:59:04,960 --> 01:59:08,639
the the discussion and there is a lot of

3108
01:59:06,880 --> 01:59:11,679
discussion on the mailing list

3109
01:59:08,639 --> 01:59:13,840
about what it should do but i mean um

3110
01:59:11,679 --> 01:59:15,360
tcp practicing itself can be made

3111
01:59:13,840 --> 01:59:17,679
completely round with time

3112
01:59:15,360 --> 01:59:19,759
independent like is shown at the right

3113
01:59:17,679 --> 01:59:21,840
side so here we have

3114
01:59:19,760 --> 01:59:23,599
different flows from half a millisecond

3115
01:59:21,840 --> 01:59:24,480
around three times one millisecond round

3116
01:59:23,599 --> 01:59:27,119
trip time 10

3117
01:59:24,480 --> 01:59:28,080
and 30 milliseconds if you look at how

3118
01:59:27,119 --> 01:59:30,719
it

3119
01:59:28,080 --> 01:59:32,719
works on a codal aqm which has a buffer

3120
01:59:30,719 --> 01:59:35,119
of five milliseconds so

3121
01:59:32,719 --> 01:59:36,480
luckily it adds five milliseconds to

3122
01:59:35,119 --> 01:59:38,559
each round trip time

3123
01:59:36,480 --> 01:59:40,638
and if it's then proportional to the one

3124
01:59:38,560 --> 01:59:42,800
over the the effective round of time

3125
01:59:40,639 --> 01:59:44,800
including the buffer you will see

3126
01:59:42,800 --> 01:59:46,000
the different rates so the one with the

3127
01:59:44,800 --> 01:59:48,880
30 milliseconds

3128
01:59:46,000 --> 01:59:49,280
really has a very low latency compared

3129
01:59:48,880 --> 01:59:52,080
to the

3130
01:59:49,280 --> 01:59:53,119
0.5 and 1 millisecond which effectively

3131
01:59:52,080 --> 01:59:56,159
get around

3132
01:59:53,119 --> 01:59:59,199
5 6 millisecond latency

3133
01:59:56,159 --> 02:00:01,119
if you look at at prague which only has

3134
01:59:59,199 --> 02:00:02,719
one millisecond buffer

3135
02:00:01,119 --> 02:00:04,559
uh initially in the beginning of the

3136
02:00:02,719 --> 02:00:05,679
flow you see you get an impression of

3137
02:00:04,560 --> 02:00:09,360
what would be

3138
02:00:05,679 --> 02:00:12,080
the the the rates and and what we did in

3139
02:00:09,360 --> 02:00:12,799
in prague is after 500 milliseconds we

3140
02:00:12,080 --> 02:00:16,480
enable

3141
02:00:12,800 --> 02:00:19,920
this uh conversions towards

3142
02:00:16,480 --> 02:00:20,799
uh fair share so you see after a while

3143
02:00:19,920 --> 02:00:23,920
all the rates

3144
02:00:20,800 --> 02:00:24,320
go and share the link evenly and why do

3145
02:00:23,920 --> 02:00:27,199
we

3146
02:00:24,320 --> 02:00:29,599
not immediately do that because we think

3147
02:00:27,199 --> 02:00:31,839
it would be a good strategy to start

3148
02:00:29,599 --> 02:00:34,480
from a dynamics point of view to still

3149
02:00:31,840 --> 02:00:38,239
get the benefits of your lower latency

3150
02:00:34,480 --> 02:00:40,400
but fairness

3151
02:00:38,239 --> 02:00:42,320
and convergence is is a process of

3152
02:00:40,400 --> 02:00:44,719
longer time so we only need to

3153
02:00:42,320 --> 02:00:45,440
that's over longer time so we don't want

3154
02:00:44,719 --> 02:00:47,920
to

3155
02:00:45,440 --> 02:00:49,759
disadvantage smaller round trip times

3156
02:00:47,920 --> 02:00:52,639
when it's about dynamics

3157
02:00:49,760 --> 02:00:53,119
but we want we don't want to this this

3158
02:00:52,639 --> 02:00:56,960
uh

3159
02:00:53,119 --> 02:00:58,799
or give these advantages to to the

3160
02:00:56,960 --> 02:00:59,360
longer round trip times if it's a matter

3161
02:00:58,800 --> 02:01:01,840
of

3162
02:00:59,360 --> 02:01:02,719
of downloads and if the round trip time

3163
02:01:01,840 --> 02:01:05,440
is very long

3164
02:01:02,719 --> 02:01:07,280
well there is not much the base round

3165
02:01:05,440 --> 02:01:08,000
retime is already very long there is not

3166
02:01:07,280 --> 02:01:10,080
much

3167
02:01:08,000 --> 02:01:13,280
uh possibility to do interactive

3168
02:01:10,080 --> 02:01:16,320
applications and the the shorter term

3169
02:01:13,280 --> 02:01:18,239
interactive uh mechanisms will

3170
02:01:16,320 --> 02:01:19,840
will not make a big difference so that's

3171
02:01:18,239 --> 02:01:24,239
a little bit the strategy that we

3172
02:01:19,840 --> 02:01:26,159
that we follow but that's of course also

3173
02:01:24,239 --> 02:01:28,638
for discussion or it can be adapted

3174
02:01:26,159 --> 02:01:29,440
based on applications that that use this

3175
02:01:28,639 --> 02:01:31,920
mechanism

3176
02:01:29,440 --> 02:01:34,000
but the the good point is that and i

3177
02:01:31,920 --> 02:01:35,679
think it can be done in every congestion

3178
02:01:34,000 --> 02:01:37,760
control that after a while

3179
02:01:35,679 --> 02:01:40,000
if you have if you are in a very steady

3180
02:01:37,760 --> 02:01:43,119
state that you can all convert

3181
02:01:40,000 --> 02:01:45,199
to the same fair throughput

3182
02:01:43,119 --> 02:01:47,280
uh for the rest it's it's still a matter

3183
02:01:45,199 --> 02:01:50,400
of being non-responsive

3184
02:01:47,280 --> 02:01:52,000
and and use whatever there is because

3185
02:01:50,400 --> 02:01:55,759
congestion control cannot

3186
02:01:52,000 --> 02:01:58,639
cannot happen in a very short time frame

3187
02:01:55,760 --> 02:02:00,000
especially not for short transactions

3188
02:01:58,639 --> 02:02:02,880
anyway so

3189
02:02:00,000 --> 02:02:04,320
okay next slide kuhn yeah can we have

3190
02:02:02,880 --> 02:02:07,520
past time do you want to

3191
02:02:04,320 --> 02:02:10,880
wrap up in a minute yes uh next slide

3192
02:02:07,520 --> 02:02:14,320
quickly okay bob

3193
02:02:10,880 --> 02:02:16,639
yeah yeah just i think look there's

3194
02:02:14,320 --> 02:02:18,239
just one more two more slides actually

3195
02:02:16,639 --> 02:02:20,320
and i'll go very quickly

3196
02:02:18,239 --> 02:02:22,320
because i've said a lot of this before

3197
02:02:20,320 --> 02:02:24,719
um so we think there's

3198
02:02:22,320 --> 02:02:25,679
a lot of potential in exploiting high

3199
02:02:24,719 --> 02:02:29,440
fidelity

3200
02:02:25,679 --> 02:02:32,159
ecn markings particularly as um

3201
02:02:29,440 --> 02:02:32,799
there are there are signs that there are

3202
02:02:32,159 --> 02:02:36,159
going to be

3203
02:02:32,800 --> 02:02:39,520
operators deploying that so um

3204
02:02:36,159 --> 02:02:41,440
you know network operators so um

3205
02:02:39,520 --> 02:02:43,920
there's a list here of possible topics

3206
02:02:41,440 --> 02:02:46,080
to work on i i was hoping

3207
02:02:43,920 --> 02:02:47,360
um we could go through this but i guess

3208
02:02:46,080 --> 02:02:50,559
it's a bit late just

3209
02:02:47,360 --> 02:02:51,440
um so you'll just have to quickly look

3210
02:02:50,560 --> 02:02:53,280
at them but they're

3211
02:02:51,440 --> 02:02:54,719
you know if there's any people in the

3212
02:02:53,280 --> 02:02:55,519
room that are looking for a research

3213
02:02:54,719 --> 02:02:58,000
project you know

3214
02:02:55,520 --> 02:03:00,960
um uh coming to the end of a masters

3215
02:02:58,000 --> 02:03:04,639
wanting to do a phd or whatever um

3216
02:03:00,960 --> 02:03:06,800
or phd students looking a bit lost um

3217
02:03:04,639 --> 02:03:08,480
or anyone who's you know a postdoc or

3218
02:03:06,800 --> 02:03:09,119
whatever there's there's all sorts of

3219
02:03:08,480 --> 02:03:12,559
things there

3220
02:03:09,119 --> 02:03:16,159
to look at um and

3221
02:03:12,560 --> 02:03:17,760
um you know we're sort of wanting to try

3222
02:03:16,159 --> 02:03:20,799
and be a bit more open and be

3223
02:03:17,760 --> 02:03:22,080
um a bit more helpful and the next slide

3224
02:03:20,800 --> 02:03:26,480
was really

3225
02:03:22,080 --> 02:03:29,920
um uh just just

3226
02:03:26,480 --> 02:03:33,119
we want to start thinking about um

3227
02:03:29,920 --> 02:03:36,880
a more um a better way to be able to

3228
02:03:33,119 --> 02:03:40,559
visualize comparisons to be able to um

3229
02:03:36,880 --> 02:03:41,679
um come up with common metrics because

3230
02:03:40,560 --> 02:03:43,840
because at the moment a lot of the

3231
02:03:41,679 --> 02:03:46,880
metrics aren't aren't common

3232
02:03:43,840 --> 02:03:48,880
um there are drafts on reference test

3233
02:03:46,880 --> 02:03:52,239
cases and rfcs

3234
02:03:48,880 --> 02:03:56,639
but not many that really focus on

3235
02:03:52,239 --> 02:04:00,159
low latency um 7928 is probably the

3236
02:03:56,639 --> 02:04:01,760
closest and um possibly

3237
02:04:00,159 --> 02:04:03,759
uh well certainly everyone's got to use

3238
02:04:01,760 --> 02:04:07,920
re reusable tools

3239
02:04:03,760 --> 02:04:11,679
i don't think common tools is a um

3240
02:04:07,920 --> 02:04:13,280
an aspiration that is realistic but um

3241
02:04:11,679 --> 02:04:14,800
certainly make sure that other people

3242
02:04:13,280 --> 02:04:17,440
can use your tools and

3243
02:04:14,800 --> 02:04:18,719
so um i think we're gonna end there just

3244
02:04:17,440 --> 02:04:20,239
if you can switch to the last slide and

3245
02:04:18,719 --> 02:04:22,880
leave it up that's just

3246
02:04:20,239 --> 02:04:25,040
some point as to how you get involved

3247
02:04:22,880 --> 02:04:29,599
thanks

3248
02:04:25,040 --> 02:04:32,960
any questions i know we're over time but

3249
02:04:29,599 --> 02:04:35,599
yep uh thank you so much bob and cone um

3250
02:04:32,960 --> 02:04:37,440
we have two people in line and i'm gonna

3251
02:04:35,599 --> 02:04:41,040
cut off the line after that

3252
02:04:37,440 --> 02:04:44,400
uh well god is in line too so

3253
02:04:41,040 --> 02:04:47,599
you just go um so uh

3254
02:04:44,400 --> 02:04:48,320
how do you solve or improve the rtt uh

3255
02:04:47,599 --> 02:04:51,760
fairness

3256
02:04:48,320 --> 02:04:52,079
by the proportional increase on the axe

3257
02:04:51,760 --> 02:04:56,800
i

3258
02:04:52,079 --> 02:04:56,799
can't quite get the the inside there

3259
02:04:59,040 --> 02:05:03,040
cool that sounds like it's yeah so so

3260
02:05:01,520 --> 02:05:06,239
your question is how

3261
02:05:03,040 --> 02:05:10,079
how did we improve it yeah how do you

3262
02:05:06,239 --> 02:05:13,598
get better rtt fairness so so what we do

3263
02:05:10,079 --> 02:05:16,799
is um that we

3264
02:05:13,599 --> 02:05:19,840
adapt the additive increase so we

3265
02:05:16,800 --> 02:05:21,520
we slow down the additive increase and

3266
02:05:19,840 --> 02:05:23,920
um

3267
02:05:21,520 --> 02:05:25,440
we can i jump in because i think i think

3268
02:05:23,920 --> 02:05:28,239
i know why you chung

3269
02:05:25,440 --> 02:05:30,559
the description of what explained

3270
02:05:28,239 --> 02:05:33,040
for the additive increase in this talk

3271
02:05:30,560 --> 02:05:34,239
wasn't the there's another change the

3272
02:05:33,040 --> 02:05:35,360
added to be increased that he hasn't

3273
02:05:34,239 --> 02:05:40,000
talked about in this talk

3274
02:05:35,360 --> 02:05:40,000
during the rtt unfairness does that help

3275
02:05:41,119 --> 02:05:47,360
okay i guess yeah well

3276
02:05:45,119 --> 02:05:49,360
i did a presentation for it i think in

3277
02:05:47,360 --> 02:05:51,839
in the previous or one of the previous

3278
02:05:49,360 --> 02:05:55,040
iccrgs and if you have questions maybe

3279
02:05:51,840 --> 02:05:58,320
ask on the mailing list we can go in

3280
02:05:55,040 --> 02:05:58,320
more details i guess right

3281
02:05:59,840 --> 02:06:04,639
all right jonathan you're up next and

3282
02:06:01,760 --> 02:06:04,639
let's keep this quick

3283
02:06:04,880 --> 02:06:08,400
okay i'd just like to highlight the

3284
02:06:06,960 --> 02:06:11,599
fundamental feature

3285
02:06:08,400 --> 02:06:12,879
of gcp park which is it relies on a

3286
02:06:11,599 --> 02:06:16,560
redefinition

3287
02:06:12,880 --> 02:06:19,679
of the congestion experience mark in ecm

3288
02:06:16,560 --> 02:06:21,440
um the uh the standard definition

3289
02:06:19,679 --> 02:06:23,119
is that it requests a multiplicative

3290
02:06:21,440 --> 02:06:26,159
decrease

3291
02:06:23,119 --> 02:06:30,320
in but prague expects it to mean

3292
02:06:26,159 --> 02:06:33,280
an additive decrease so

3293
02:06:30,320 --> 02:06:34,159
um i think no it's multiplicative don't

3294
02:06:33,280 --> 02:06:35,759
have to

3295
02:06:34,159 --> 02:06:37,280
so i think a lot of the discussion is

3296
02:06:35,760 --> 02:06:41,920
going to have to talk about

3297
02:06:37,280 --> 02:06:45,840
the uh resolving that discrepancy

3298
02:06:41,920 --> 02:06:45,840
i think i think

3299
02:06:46,880 --> 02:06:52,159
i think it even doesn't matter it's it's

3300
02:06:49,920 --> 02:06:53,679
just in the long term when we are in a

3301
02:06:52,159 --> 02:06:56,960
kind of steady situation

3302
02:06:53,679 --> 02:06:58,079
where we want fairness in download

3303
02:06:56,960 --> 02:07:00,239
situations or

3304
02:06:58,079 --> 02:07:01,199
or whatever if you if you really can

3305
02:07:00,239 --> 02:07:04,400
measure what is

3306
02:07:01,199 --> 02:07:05,199
the the share of each flow there we want

3307
02:07:04,400 --> 02:07:09,360
to converge

3308
02:07:05,199 --> 02:07:13,040
to uh or an obeyance let's say to

3309
02:07:09,360 --> 02:07:16,480
a kind of marking probability to rate

3310
02:07:13,040 --> 02:07:17,840
equation and that's all of it it doesn't

3311
02:07:16,480 --> 02:07:20,559
mean that you have to be a

3312
02:07:17,840 --> 02:07:22,560
imd you can do whatever you want very

3313
02:07:20,560 --> 02:07:24,800
clever and even if you see that

3314
02:07:22,560 --> 02:07:26,239
you're in a dynamic situation you can

3315
02:07:24,800 --> 02:07:27,679
make optimal use of the dynamic

3316
02:07:26,239 --> 02:07:29,598
situation it's only

3317
02:07:27,679 --> 02:07:31,360
and it's the only way to measure if you

3318
02:07:29,599 --> 02:07:34,560
are on a long standing

3319
02:07:31,360 --> 02:07:36,480
uh link very greedy situation

3320
02:07:34,560 --> 02:07:38,159
it is important to converge because

3321
02:07:36,480 --> 02:07:38,879
that's where it's measured but on a

3322
02:07:38,159 --> 02:07:42,079
short term

3323
02:07:38,880 --> 02:07:43,520
you can do whatever you want well that's

3324
02:07:42,079 --> 02:07:45,599
maybe another

3325
02:07:43,520 --> 02:07:48,159
point of discussion what are we going to

3326
02:07:45,599 --> 02:07:52,560
allow um

3327
02:07:48,159 --> 02:07:54,320
but in alpharest you still need to

3328
02:07:52,560 --> 02:07:55,920
keep the the the latency low for

3329
02:07:54,320 --> 02:07:58,799
instance but uh

3330
02:07:55,920 --> 02:08:00,639
well that's the main difference and

3331
02:07:58,800 --> 02:08:01,920
there is

3332
02:08:00,639 --> 02:08:04,239
you're being far too clever here

3333
02:08:01,920 --> 02:08:07,679
jonathan's just got a misconception

3334
02:08:04,239 --> 02:08:08,879
that because uh the the reduction is

3335
02:08:07,679 --> 02:08:11,520
equivalent to

3336
02:08:08,880 --> 02:08:12,719
reducing by half a pack at every mark he

3337
02:08:11,520 --> 02:08:15,280
thinks that's additive

3338
02:08:12,719 --> 02:08:16,960
but it's it's it's repetitive additive

3339
02:08:15,280 --> 02:08:20,000
therefore it's multiplicative

3340
02:08:16,960 --> 02:08:22,000
that's the whole point no each each mark

3341
02:08:20,000 --> 02:08:25,360
is additive

3342
02:08:22,000 --> 02:08:27,679
in park no it's actually not in prague

3343
02:08:25,360 --> 02:08:28,799
it is in relentless but in prague it

3344
02:08:27,679 --> 02:08:31,040
does a multiplicative

3345
02:08:28,800 --> 02:08:33,119
decrease based on the number of marks

3346
02:08:31,040 --> 02:08:35,920
over a round trip

3347
02:08:33,119 --> 02:08:36,639
all right with that yeah i will call i

3348
02:08:35,920 --> 02:08:39,920
will call

3349
02:08:36,639 --> 02:08:41,199
uh um this this is thank you so much bob

3350
02:08:39,920 --> 02:08:43,199
and cone and

3351
02:08:41,199 --> 02:08:44,400
jonathan for asking the questions but uh

3352
02:08:43,199 --> 02:08:45,440
i'm sorry that we had to rush a little

3353
02:08:44,400 --> 02:08:48,159
bit at the end

3354
02:08:45,440 --> 02:08:49,919
um but thank you so much and thank you

3355
02:08:48,159 --> 02:08:50,799
everybody for staying eight minutes past

3356
02:08:49,920 --> 02:08:53,520
time

3357
02:08:50,800 --> 02:08:54,239
um this has been an excellent session

3358
02:08:53,520 --> 02:08:55,599
please

3359
02:08:54,239 --> 02:08:57,440
continue the conversations on the

3360
02:08:55,599 --> 02:08:59,440
mailing list um

3361
02:08:57,440 --> 02:09:01,119
let's use that medium i think there are

3362
02:08:59,440 --> 02:09:04,879
a lot of conversations that

3363
02:09:01,119 --> 02:09:08,159
we want to have so let's have them there

3364
02:09:04,880 --> 02:09:10,960
um enjoy the rest of the

3365
02:09:08,159 --> 02:09:11,519
idf and uh hopefully we'll see you again

3366
02:09:10,960 --> 02:09:13,920
soon

3367
02:09:11,520 --> 02:09:16,000
thank you jana for cheering us so well

3368
02:09:13,920 --> 02:09:19,840
yep

3369
02:09:16,000 --> 02:09:19,840
thank you

3370
02:11:55,920 --> 02:11:58,000
you

