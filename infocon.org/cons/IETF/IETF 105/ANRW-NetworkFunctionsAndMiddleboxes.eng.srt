1
00:00:05,200 --> 00:00:12,900
so take your seats buckle up for middle

2
00:00:11,510 --> 00:00:18,750
boxes and no

3
00:00:12,900 --> 00:00:23,550
functions the bird the bane of the

4
00:00:18,750 --> 00:00:30,019
existence of the ITF so this session has

5
00:00:23,550 --> 00:00:32,668
three tax interesting mix of things so

6
00:00:30,019 --> 00:00:34,470
the common theme of course is what

7
00:00:32,668 --> 00:00:36,750
happens in between the people who are

8
00:00:34,470 --> 00:00:38,220
trying to get useful work done by things

9
00:00:36,750 --> 00:00:41,970
in the middle that are trying to help

10
00:00:38,220 --> 00:00:46,739
them happen quotes first talk is

11
00:00:41,970 --> 00:00:49,350
limitless HTTP in an HTTP world where we

12
00:00:46,739 --> 00:00:51,629
are trying the author's try to infer

13
00:00:49,350 --> 00:00:55,080
semantics of HTTP operations by

14
00:00:51,629 --> 00:00:57,809
observing traffic without having to

15
00:00:55,080 --> 00:01:00,239
decrypt it the authors are Blake

16
00:00:57,809 --> 00:01:02,760
Anderson and Richie Scott Dunlop and

17
00:01:00,239 --> 00:01:04,319
they've McGrew and the talk is going to

18
00:01:02,760 --> 00:01:06,539
be given by blake anderson who is a

19
00:01:04,319 --> 00:01:08,939
software engineer at cisco who

20
00:01:06,540 --> 00:01:14,100
unintentionally shared with me that he's

21
00:01:08,939 --> 00:01:28,460
a reformed physicist like me they

22
00:01:14,100 --> 00:01:30,899
reformed physicists so the the goal of

23
00:01:28,460 --> 00:01:34,020
the goal of this worker there's like two

24
00:01:30,900 --> 00:01:35,430
goals really but the specific goal of

25
00:01:34,020 --> 00:01:39,090
the work that i'm going to be going over

26
00:01:35,430 --> 00:01:43,920
in this talk is that given a stream of

27
00:01:39,090 --> 00:01:47,159
TLS application data records we want to

28
00:01:43,920 --> 00:01:50,010
be able to infer which records have

29
00:01:47,159 --> 00:01:52,400
which specific HTTP frames the frame

30
00:01:50,010 --> 00:01:55,080
types and then for the subset of those

31
00:01:52,400 --> 00:01:58,590
application records that contain headers

32
00:01:55,080 --> 00:02:01,470
frames we want to be able to make even

33
00:01:58,590 --> 00:02:04,229
more detailed inferences about the HTTP

34
00:02:01,470 --> 00:02:08,000
headers that are inside that frame and

35
00:02:04,229 --> 00:02:10,619
in some cases we want to be able to say

36
00:02:08,000 --> 00:02:15,269
what were the actual values of those

37
00:02:10,619 --> 00:02:17,400
HTTP headers and a higher-level goal

38
00:02:15,269 --> 00:02:20,340
which i'm not going to really spend too

39
00:02:17,400 --> 00:02:22,889
much time on but given those inferences

40
00:02:20,340 --> 00:02:26,910
so given the fact that we can annotate a

41
00:02:22,889 --> 00:02:28,710
TLS session with this information of

42
00:02:26,910 --> 00:02:31,859
where the headers are and what those

43
00:02:28,710 --> 00:02:34,200
specific HTTP fields and values for

44
00:02:31,860 --> 00:02:36,840
those headers you know the what they

45
00:02:34,200 --> 00:02:40,769
actually are you know how can we use

46
00:02:36,840 --> 00:02:44,160
this and in the original CODIS by paper

47
00:02:40,770 --> 00:02:45,750
that this talk is based on we presented

48
00:02:44,160 --> 00:02:48,410
it in two ways where what kind of

49
00:02:45,750 --> 00:02:50,760
defender do and what can an attacker do

50
00:02:48,410 --> 00:02:53,040
you know from the the point of view of

51
00:02:50,760 --> 00:02:55,829
the attacker it's mostly centered around

52
00:02:53,040 --> 00:02:57,120
website fingerprinting from the point of

53
00:02:55,830 --> 00:02:58,740
view of the defender it's mostly

54
00:02:57,120 --> 00:03:03,110
centered around identifying malicious

55
00:02:58,740 --> 00:03:05,670
communication malicious websites and

56
00:03:03,110 --> 00:03:08,100
doing things like identifying data

57
00:03:05,670 --> 00:03:11,609
exfiltration by you know matching the

58
00:03:08,100 --> 00:03:13,230
sizes of the data objects you know

59
00:03:11,610 --> 00:03:17,340
downloaded or uploaded versus something

60
00:03:13,230 --> 00:03:21,299
that's in a contextual database and so

61
00:03:17,340 --> 00:03:23,070
the the the motivating factor for all of

62
00:03:21,300 --> 00:03:24,710
this is this is what many enterprises

63
00:03:23,070 --> 00:03:28,230
look like today it's very generic

64
00:03:24,710 --> 00:03:30,900
cartoonish picture but we have some set

65
00:03:28,230 --> 00:03:32,399
of clients they're internal they want to

66
00:03:30,900 --> 00:03:34,440
talk to the internet so there's a

67
00:03:32,400 --> 00:03:36,090
man-in-the-middle proxy in between those

68
00:03:34,440 --> 00:03:37,290
two that will decrypt the traffic and

69
00:03:36,090 --> 00:03:41,540
make sure that it's good and then send

70
00:03:37,290 --> 00:03:44,579
it on its way and basically this work is

71
00:03:41,540 --> 00:03:48,150
saying if we if we eliminate the men in

72
00:03:44,580 --> 00:03:50,010
the middle box and we want to do you

73
00:03:48,150 --> 00:03:51,840
know how many of those features can we

74
00:03:50,010 --> 00:03:54,929
get away with I do it by passively

75
00:03:51,840 --> 00:03:56,790
observing the TLS traffic you know can

76
00:03:54,930 --> 00:03:58,410
we ensure that there's not malicious

77
00:03:56,790 --> 00:04:00,269
communication that sensitive data is not

78
00:03:58,410 --> 00:04:02,609
leaving the network with the hope that

79
00:04:00,270 --> 00:04:04,950
if we can get close enough then we want

80
00:04:02,610 --> 00:04:07,200
to have to rely on men in the middle

81
00:04:04,950 --> 00:04:11,880
boxes at least for all all the functions

82
00:04:07,200 --> 00:04:14,488
and so to level set after the TLS

83
00:04:11,880 --> 00:04:16,070
handshake we you know this is more or

84
00:04:14,489 --> 00:04:18,840
less what when you see a series of

85
00:04:16,070 --> 00:04:23,490
application data records between the

86
00:04:18,839 --> 00:04:25,560
client and the server and interestingly

87
00:04:23,490 --> 00:04:28,919
what you know when we actually decrypt

88
00:04:25,560 --> 00:04:31,320
that and look at what's underneath you

89
00:04:28,919 --> 00:04:34,979
know we could have HTTP you want HTTP to

90
00:04:31,320 --> 00:04:37,979
if it's HTTP to we have a series of all

91
00:04:34,979 --> 00:04:40,889
these different frame types where some

92
00:04:37,979 --> 00:04:42,599
of its setting up the connection

93
00:04:40,889 --> 00:04:44,429
and then it's the client is actually

94
00:04:42,599 --> 00:04:47,248
requesting some data from the server and

95
00:04:44,429 --> 00:04:49,229
a headers frame and then the you know

96
00:04:47,249 --> 00:04:51,659
there's a little bit more setup and

97
00:04:49,229 --> 00:04:57,989
finally the server sends its headers

98
00:04:51,659 --> 00:05:02,879
responds and in the data so a big part

99
00:04:57,989 --> 00:05:04,948
of this work was building out the

100
00:05:02,879 --> 00:05:07,979
infrastructure to build the data sets

101
00:05:04,949 --> 00:05:10,289
that correlate you know this view that

102
00:05:07,979 --> 00:05:14,639
we that we can passively observe on the

103
00:05:10,289 --> 00:05:17,308
wire with a view that has you know this

104
00:05:14,639 --> 00:05:20,099
detailed data the the TLS application

105
00:05:17,309 --> 00:05:21,599
data records that are annotated with the

106
00:05:20,099 --> 00:05:24,419
information that we want to be able to

107
00:05:21,599 --> 00:05:27,359
infer so you know it's like 99% of what

108
00:05:24,419 --> 00:05:29,639
we did was you know building out those

109
00:05:27,359 --> 00:05:36,859
training data sets and then the last 1%

110
00:05:29,639 --> 00:05:41,269
was some light machine learning and so

111
00:05:36,859 --> 00:05:45,899
we started by obviously we needed the

112
00:05:41,269 --> 00:05:48,299
TLS key material and you know

113
00:05:45,899 --> 00:05:50,789
interesting and rude Android she did

114
00:05:48,299 --> 00:05:53,128
most of most of this work and I you know

115
00:05:50,789 --> 00:05:54,929
I asked him you know given a memory

116
00:05:53,129 --> 00:05:56,339
don't go find all of the the TLS master

117
00:05:54,929 --> 00:05:59,039
secrets and do all these like entropy

118
00:05:56,339 --> 00:06:01,199
type things and I thought was gonna be

119
00:05:59,039 --> 00:06:02,489
like a summer long project he came back

120
00:06:01,199 --> 00:06:03,929
that afternoon was like oh there here's

121
00:06:02,489 --> 00:06:05,279
like three or four regular expressions

122
00:06:03,929 --> 00:06:09,958
that will get you all of this data and

123
00:06:05,279 --> 00:06:12,209
worked out really well so yeah he

124
00:06:09,959 --> 00:06:16,709
defined a couple of regular expressions

125
00:06:12,209 --> 00:06:19,939
for s channel open SSL and an NSS which

126
00:06:16,709 --> 00:06:24,029
gave us the majority of what we needed

127
00:06:19,939 --> 00:06:29,279
so you know we took that and and we

128
00:06:24,029 --> 00:06:30,959
started transition in it so to extract

129
00:06:29,279 --> 00:06:33,719
the key material we we do one of two

130
00:06:30,959 --> 00:06:36,079
things so for Firefox in Chrome

131
00:06:33,719 --> 00:06:38,759
we just use this cell key log file

132
00:06:36,079 --> 00:06:42,559
environment variable obviously it's a

133
00:06:38,759 --> 00:06:47,249
lot easier and then as a more general

134
00:06:42,559 --> 00:06:50,729
approach given given a memory dump of

135
00:06:47,249 --> 00:06:53,129
either a process or a virtual machine we

136
00:06:50,729 --> 00:06:54,359
will use all of the the regular

137
00:06:53,129 --> 00:06:58,250
expressions to

138
00:06:54,360 --> 00:07:00,900
extract those those master secrets and

139
00:06:58,250 --> 00:07:03,150
scott dunlop took you know some of

140
00:07:00,900 --> 00:07:05,549
andrew's work and tuned it and it was

141
00:07:03,150 --> 00:07:08,400
able to get it to run and about 400

142
00:07:05,550 --> 00:07:12,719
milliseconds for a 1 1 gigabyte memory

143
00:07:08,400 --> 00:07:14,310
down which is what we did for the the

144
00:07:12,719 --> 00:07:16,680
standard setup for the malware analysis

145
00:07:14,310 --> 00:07:19,080
sandbox which i'll get to in a minute

146
00:07:16,680 --> 00:07:20,400
and from there you know we had a Python

147
00:07:19,080 --> 00:07:24,419
program that we wrote that would take

148
00:07:20,400 --> 00:07:25,979
the master secrets and touré s keys that

149
00:07:24,419 --> 00:07:28,198
goes through and decrypts all of the

150
00:07:25,979 --> 00:07:29,609
traffic so that we get a nice JSON file

151
00:07:28,199 --> 00:07:35,370
that says application data record

152
00:07:29,610 --> 00:07:42,300
contains you know these HTTP headers and

153
00:07:35,370 --> 00:07:45,449
then for tour it was an interesting the

154
00:07:42,300 --> 00:07:47,460
code is actually really ugly so you know

155
00:07:45,449 --> 00:07:49,650
the tour the outside layer is normal TLS

156
00:07:47,460 --> 00:07:51,779
application data records when you

157
00:07:49,650 --> 00:07:54,359
decrypt that you start to see all of the

158
00:07:51,779 --> 00:07:56,580
the tour cells in this case it's the

159
00:07:54,360 --> 00:07:58,229
relay data cell and so here you need to

160
00:07:56,580 --> 00:07:59,550
maintain a list of all of the AES keys

161
00:07:58,229 --> 00:08:03,900
and you need to know the proper order

162
00:07:59,550 --> 00:08:06,479
which we just force and then finally

163
00:08:03,900 --> 00:08:09,330
we'll get the TLS protocol which again

164
00:08:06,479 --> 00:08:12,919
we need to decrypt decrypt that with the

165
00:08:09,330 --> 00:08:17,729
TLS master secret to get you know that

166
00:08:12,919 --> 00:08:19,650
association between the HTTP headers and

167
00:08:17,729 --> 00:08:22,949
frame types that we care about and the

168
00:08:19,650 --> 00:08:29,400
you know outside TLS application data

169
00:08:22,949 --> 00:08:31,199
record and we had two main avenues to

170
00:08:29,400 --> 00:08:33,539
get this data so one of them was a

171
00:08:31,199 --> 00:08:36,570
decryption lab that we set up with

172
00:08:33,539 --> 00:08:39,689
Chrome Firefox in the tor browser where

173
00:08:36,570 --> 00:08:42,120
we would just you know we got the Alexa

174
00:08:39,690 --> 00:08:45,240
top 1,000 websites and just pinged each

175
00:08:42,120 --> 00:08:48,360
one of them and collected you know all

176
00:08:45,240 --> 00:08:49,769
of the all of the initial sessions and

177
00:08:48,360 --> 00:08:51,050
all of the ancillary sessions that

178
00:08:49,769 --> 00:08:53,519
happen

179
00:08:51,050 --> 00:08:56,430
along with all of the key materials so

180
00:08:53,519 --> 00:09:00,029
either sss ssl key log for for Firefox

181
00:08:56,430 --> 00:09:02,399
or Chrome for tor browser we took

182
00:09:00,029 --> 00:09:03,870
memories snapshots every two seconds

183
00:09:02,399 --> 00:09:05,959
which seemed like a pretty good

184
00:09:03,870 --> 00:09:08,190
trade-off we got the majority of the

185
00:09:05,959 --> 00:09:11,280
both the AES keys for

186
00:09:08,190 --> 00:09:17,070
and the tls master secrets for the

187
00:09:11,280 --> 00:09:19,980
Firefox processes so the the malware

188
00:09:17,070 --> 00:09:23,220
sandbox is the other set of experiments

189
00:09:19,980 --> 00:09:24,960
are the other large data set that we

190
00:09:23,220 --> 00:09:27,810
used and this is a production malware

191
00:09:24,960 --> 00:09:30,570
analysis sandbox running in Windows 7

192
00:09:27,810 --> 00:09:33,270
and Windows 10 samples were allowed to

193
00:09:30,570 --> 00:09:36,630
run for five minutes and then at the end

194
00:09:33,270 --> 00:09:38,730
of the five minute run the the memory

195
00:09:36,630 --> 00:09:40,939
dump from that virtual machine was post

196
00:09:38,730 --> 00:09:44,130
processed to try to extract all of the

197
00:09:40,940 --> 00:09:47,340
TLS master secrets from major TLS

198
00:09:44,130 --> 00:09:50,610
libraries and you would think that

199
00:09:47,340 --> 00:09:52,200
approach would work poorly because at

200
00:09:50,610 --> 00:09:54,650
least initially we thought that the TLS

201
00:09:52,200 --> 00:09:56,730
master secrets would be mostly zero eyes

202
00:09:54,650 --> 00:09:58,709
it turned out that wasn't the case and

203
00:09:56,730 --> 00:10:02,010
it's right around 80 percent of the TLS

204
00:09:58,710 --> 00:10:03,810
sessions and that's you know 80 percent

205
00:10:02,010 --> 00:10:05,960
of the samples and 80% of the TLS

206
00:10:03,810 --> 00:10:08,670
sessions those samples and sessions are

207
00:10:05,960 --> 00:10:10,410
relatively close to each other but we

208
00:10:08,670 --> 00:10:13,709
could decrypt the majority of the data

209
00:10:10,410 --> 00:10:17,209
so we were able to actually get the key

210
00:10:13,710 --> 00:10:20,760
material for most of the sessions and

211
00:10:17,210 --> 00:10:24,440
then we we ended up with you know four

212
00:10:20,760 --> 00:10:29,160
main data sets so Firefox and Chrome

213
00:10:24,440 --> 00:10:32,040
tour and and malware so the the Firefox

214
00:10:29,160 --> 00:10:34,110
Chrome and tour data sets are slightly

215
00:10:32,040 --> 00:10:35,969
different from the malware data set in

216
00:10:34,110 --> 00:10:39,120
in the biggest sense is that they're all

217
00:10:35,970 --> 00:10:40,470
relatively homogeneous so all Firefox

218
00:10:39,120 --> 00:10:43,320
connections are obviously going from the

219
00:10:40,470 --> 00:10:48,480
same version of Firefox the the malware

220
00:10:43,320 --> 00:10:52,170
data set on the other hand has a wide

221
00:10:48,480 --> 00:10:55,440
variety of different of different TLS

222
00:10:52,170 --> 00:10:58,890
libraries and applications you know the

223
00:10:55,440 --> 00:11:00,900
standard windows s channel you know some

224
00:10:58,890 --> 00:11:03,960
types of TLS connections were by far the

225
00:11:00,900 --> 00:11:06,600
most prevalent they were about 60% of

226
00:11:03,960 --> 00:11:09,420
the data set and then there was kind of

227
00:11:06,600 --> 00:11:16,970
a longtail between you know a long tail

228
00:11:09,420 --> 00:11:16,969
so to finish it off and right so

229
00:11:17,089 --> 00:11:23,880
to recap we have we have our datasets we

230
00:11:21,839 --> 00:11:27,330
you know they're they're well labeled

231
00:11:23,880 --> 00:11:28,709
we're able to associate the encrypted

232
00:11:27,330 --> 00:11:30,839
data features that we would see on the

233
00:11:28,709 --> 00:11:35,609
wire with the unencrypted data features

234
00:11:30,839 --> 00:11:37,410
that we want to infer but but we still

235
00:11:35,610 --> 00:11:39,930
need that that extra step of like what

236
00:11:37,410 --> 00:11:41,670
actual data features are we gonna feed

237
00:11:39,930 --> 00:11:44,279
into our machine learning algorithm and

238
00:11:41,670 --> 00:11:46,410
you know after some trial and error and

239
00:11:44,279 --> 00:11:49,339
not too much trial there we kind of

240
00:11:46,410 --> 00:11:51,990
settled on this set of data features and

241
00:11:49,339 --> 00:11:54,870
the the important thing here is that

242
00:11:51,990 --> 00:11:56,580
there is a sense of locality for each

243
00:11:54,870 --> 00:12:01,500
data feature so if we're trying to

244
00:11:56,580 --> 00:12:04,620
identify HTTP headers for a specific

245
00:12:01,500 --> 00:12:06,570
application data record we would you

246
00:12:04,620 --> 00:12:09,300
know take the number of packets in that

247
00:12:06,570 --> 00:12:12,029
application data record and other things

248
00:12:09,300 --> 00:12:16,229
like TCP push flags and and packet sizes

249
00:12:12,029 --> 00:12:17,700
and bytes but we would also take the set

250
00:12:16,230 --> 00:12:20,880
of data features from the previous five

251
00:12:17,700 --> 00:12:22,470
application data records and so this

252
00:12:20,880 --> 00:12:27,029
could be things that are in the actual

253
00:12:22,470 --> 00:12:29,339
handshake and then the TLS records from

254
00:12:27,029 --> 00:12:30,959
the the following five and and they

255
00:12:29,339 --> 00:12:34,160
could be 0 if it's at the end of the

256
00:12:30,959 --> 00:12:37,709
session and that locality really does

257
00:12:34,160 --> 00:12:39,529
really does help and the other thing

258
00:12:37,709 --> 00:12:45,149
that that really helped was the

259
00:12:39,529 --> 00:12:47,850
iterative classification so the the the

260
00:12:45,149 --> 00:12:50,190
assumption here is that all of these

261
00:12:47,850 --> 00:12:52,020
headers are kind of interdependent so if

262
00:12:50,190 --> 00:12:54,089
we know if we know something about the

263
00:12:52,020 --> 00:12:57,240
HTTP request that gives us a lot of

264
00:12:54,089 --> 00:12:59,670
information about the HTTP response so

265
00:12:57,240 --> 00:13:02,520
what we do is we make a single pass

266
00:12:59,670 --> 00:13:06,089
where we identify the HTTP frame types

267
00:13:02,520 --> 00:13:08,640
and make an initial guess at all of the

268
00:13:06,089 --> 00:13:12,270
header fields and values and then we

269
00:13:08,640 --> 00:13:13,980
refine all of those guesses by you know

270
00:13:12,270 --> 00:13:17,449
including in the feature set the the

271
00:13:13,980 --> 00:13:17,450
guesses from the previous round

272
00:13:20,630 --> 00:13:26,839
right so to talk about the the actual

273
00:13:23,000 --> 00:13:32,899
inferences that we we wanted to make so

274
00:13:26,839 --> 00:13:35,269
the the datasets that we collected at

275
00:13:32,899 --> 00:13:37,339
least for the the Chrome Firefox and tor

276
00:13:35,269 --> 00:13:40,699
browsers there they had limited

277
00:13:37,339 --> 00:13:43,209
variability in the request so a lot of

278
00:13:40,699 --> 00:13:46,189
the results in the paper or more server

279
00:13:43,209 --> 00:13:51,349
oriented so that was one of the

280
00:13:46,190 --> 00:13:53,389
limitations and the the other thing is

281
00:13:51,350 --> 00:13:54,589
that you know we're not we're not

282
00:13:53,389 --> 00:13:56,420
claiming to do something like

283
00:13:54,589 --> 00:14:00,050
identifying the exact value of a cookie

284
00:13:56,420 --> 00:14:01,550
field because that's not it's probably

285
00:14:00,050 --> 00:14:04,839
not exactly exactly possible at least

286
00:14:01,550 --> 00:14:07,160
with these methods so we set up our

287
00:14:04,839 --> 00:14:09,500
classification into two broad sets so we

288
00:14:07,160 --> 00:14:14,089
have a set of multi-class classification

289
00:14:09,500 --> 00:14:15,769
problems and these are the I've never

290
00:14:14,089 --> 00:14:18,889
listened it here so things like the

291
00:14:15,769 --> 00:14:22,459
method the response the the content type

292
00:14:18,889 --> 00:14:24,620
and the actual server field were

293
00:14:22,459 --> 00:14:25,910
multi-class classification problems

294
00:14:24,620 --> 00:14:28,970
where we're trying to identify a

295
00:14:25,910 --> 00:14:33,139
specific value so a specific you know

296
00:14:28,970 --> 00:14:34,370
JavaScript versus image in addition to

297
00:14:33,139 --> 00:14:37,550
these we had a set of binary

298
00:14:34,370 --> 00:14:39,920
classification problems and here the the

299
00:14:37,550 --> 00:14:42,589
intuition is that you know the fact that

300
00:14:39,920 --> 00:14:45,589
there's a referrer field present in an

301
00:14:42,589 --> 00:14:47,540
HTTP request gives us gives us some

302
00:14:45,589 --> 00:14:54,740
amount of information the fact that

303
00:14:47,540 --> 00:14:56,599
there was a you know like a cookie field

304
00:14:54,740 --> 00:14:58,639
yeah so a cookie field also gives you

305
00:14:56,600 --> 00:15:01,370
some amount of information and you can

306
00:14:58,639 --> 00:15:03,730
actually get the or you it's difficult

307
00:15:01,370 --> 00:15:06,579
to get the actual values for these but

308
00:15:03,730 --> 00:15:08,720
determining their presence was

309
00:15:06,579 --> 00:15:14,989
significantly easier for these

310
00:15:08,720 --> 00:15:18,189
techniques alright so I apologize this

311
00:15:14,990 --> 00:15:20,630
is a little bit of an overloaded slide

312
00:15:18,189 --> 00:15:22,399
this is kind of summarizing all of the

313
00:15:20,630 --> 00:15:25,610
results that we did we broke it out from

314
00:15:22,399 --> 00:15:28,430
HTTP 1.1 and HTTP 2 and there were two

315
00:15:25,610 --> 00:15:31,250
main sets of experiments so there was

316
00:15:28,430 --> 00:15:34,319
one experiment where we divided the

317
00:15:31,250 --> 00:15:36,450
training and the testing set by weeks so

318
00:15:34,320 --> 00:15:39,200
one week of data to Train and then we

319
00:15:36,450 --> 00:15:43,170
took the second week of data to test and

320
00:15:39,200 --> 00:15:47,940
the other set of experiments used an sni

321
00:15:43,170 --> 00:15:49,500
based split where no - you know no 2s

322
00:15:47,940 --> 00:15:51,480
and eyes were in both the training and

323
00:15:49,500 --> 00:15:55,650
the test set and they were relatively

324
00:15:51,480 --> 00:15:58,560
even there are many interesting

325
00:15:55,650 --> 00:15:58,980
observations like in this in this data

326
00:15:58,560 --> 00:16:00,719
set

327
00:15:58,980 --> 00:16:02,400
one of them being that we can do a

328
00:16:00,720 --> 00:16:06,390
really good job of identifying message

329
00:16:02,400 --> 00:16:09,600
types so we can with relatively high

330
00:16:06,390 --> 00:16:12,780
confidence we can say you know this

331
00:16:09,600 --> 00:16:17,160
packet has a HTTP request versus data

332
00:16:12,780 --> 00:16:18,689
versus ping frame etc the other

333
00:16:17,160 --> 00:16:20,760
interesting thing is that even for some

334
00:16:18,690 --> 00:16:22,500
of the more difficult multi-class

335
00:16:20,760 --> 00:16:25,380
classification problems like server

336
00:16:22,500 --> 00:16:28,590
identification on this it's in the paper

337
00:16:25,380 --> 00:16:32,430
we're able to do surprisingly well

338
00:16:28,590 --> 00:16:34,620
especially in the non sni based data set

339
00:16:32,430 --> 00:16:37,770
so if we were doing time-based splits

340
00:16:34,620 --> 00:16:40,200
which you know it is reasonable

341
00:16:37,770 --> 00:16:41,819
especially for you know some of the the

342
00:16:40,200 --> 00:16:45,300
servers that don't really change that

343
00:16:41,820 --> 00:16:47,700
much we can do a pretty good job of

344
00:16:45,300 --> 00:16:49,829
identifying the different types of web

345
00:16:47,700 --> 00:16:53,940
servers and a really good example that

346
00:16:49,830 --> 00:16:56,400
we had was where we we opened a session

347
00:16:53,940 --> 00:16:57,990
to like gmail.com and there were several

348
00:16:56,400 --> 00:16:59,730
different servers and a single

349
00:16:57,990 --> 00:17:04,829
connection to gmail.com and we were able

350
00:16:59,730 --> 00:17:08,240
to identify each of them and content

351
00:17:04,829 --> 00:17:10,319
types actually had specific results on

352
00:17:08,240 --> 00:17:16,439
content types so these are all confusion

353
00:17:10,319 --> 00:17:18,060
matrices you know so a perfect algorithm

354
00:17:16,439 --> 00:17:21,000
will get everything in the diagonal so

355
00:17:18,060 --> 00:17:24,089
that's that's what we want for the cases

356
00:17:21,000 --> 00:17:26,550
of Chrome and Firefox were able to do a

357
00:17:24,089 --> 00:17:28,169
pretty good job of identifying the the

358
00:17:26,550 --> 00:17:33,629
content types and this is a heavily

359
00:17:28,170 --> 00:17:34,890
imbalanced data set so you know I did if

360
00:17:33,630 --> 00:17:37,190
you've ever looked at a lot of this

361
00:17:34,890 --> 00:17:42,270
traffic which I'm sure all of you have

362
00:17:37,190 --> 00:17:44,310
images are you know definitely you know

363
00:17:42,270 --> 00:17:47,850
or magnitude more than then something

364
00:17:44,310 --> 00:17:49,110
like JSON so

365
00:17:47,850 --> 00:17:50,939
you know from a machine-learning

366
00:17:49,110 --> 00:17:53,610
perspective and balanced datasets make

367
00:17:50,940 --> 00:17:55,830
things pretty difficult but we were able

368
00:17:53,610 --> 00:17:57,740
to do a pretty good job relatively

369
00:17:55,830 --> 00:18:02,129
evenly across the datasets except for

370
00:17:57,740 --> 00:18:04,860
the tour data which more or less over

371
00:18:02,130 --> 00:18:10,770
fit everything to image and again that

372
00:18:04,860 --> 00:18:12,629
was mostly because tor does I guess

373
00:18:10,770 --> 00:18:14,370
there's two things so toward that's

374
00:18:12,630 --> 00:18:16,410
fixed-length messages and it does a lot

375
00:18:14,370 --> 00:18:18,389
of multiplexing the fix linked messages

376
00:18:16,410 --> 00:18:21,300
and some of the the site experiments

377
00:18:18,390 --> 00:18:24,510
that we did had relatively little impact

378
00:18:21,300 --> 00:18:26,970
on on these techniques the multiplexing

379
00:18:24,510 --> 00:18:29,310
on the other hand had a huge impact

380
00:18:26,970 --> 00:18:34,020
so multiplexing mini sessions over a

381
00:18:29,310 --> 00:18:37,320
single section this is probably the most

382
00:18:34,020 --> 00:18:46,220
valuable defense to these type of

383
00:18:37,320 --> 00:18:48,750
techniques yeah so quick conclusions the

384
00:18:46,220 --> 00:18:51,990
you know by far the most important part

385
00:18:48,750 --> 00:18:54,330
of all of these experiments was building

386
00:18:51,990 --> 00:18:56,400
the the ground truth data sets so if

387
00:18:54,330 --> 00:18:58,550
you're willing to invest a lot of time

388
00:18:56,400 --> 00:19:00,870
into coming up with very varied

389
00:18:58,550 --> 00:19:04,470
representative data set that can

390
00:19:00,870 --> 00:19:06,120
actually make that can actually link the

391
00:19:04,470 --> 00:19:07,410
things that you care about so that the

392
00:19:06,120 --> 00:19:12,090
application data records and the

393
00:19:07,410 --> 00:19:13,560
unencrypted HTTP headers actually

394
00:19:12,090 --> 00:19:15,270
defining the machine learning algorithms

395
00:19:13,560 --> 00:19:19,500
take advantage of that is relatively

396
00:19:15,270 --> 00:19:22,350
easy like I just said you know fixed

397
00:19:19,500 --> 00:19:24,030
length records yeah definitely they

398
00:19:22,350 --> 00:19:26,699
don't make these techniques like work

399
00:19:24,030 --> 00:19:28,740
better obviously but really the the

400
00:19:26,700 --> 00:19:32,460
biggest thing was the multiplexing in

401
00:19:28,740 --> 00:19:35,280
terms of a deterrent and then finally so

402
00:19:32,460 --> 00:19:38,820
the results are almost certainly client

403
00:19:35,280 --> 00:19:41,399
dependent in the in the paper we looked

404
00:19:38,820 --> 00:19:43,409
at training the the classifier on

405
00:19:41,400 --> 00:19:47,070
Firefox data and testing on Chrome data

406
00:19:43,410 --> 00:19:49,530
and vice versa and it does relatively

407
00:19:47,070 --> 00:19:52,409
poorly on so it's definitely leveraging

408
00:19:49,530 --> 00:19:55,649
some of the the artifacts of the

409
00:19:52,410 --> 00:19:57,780
specific browser so to actually actually

410
00:19:55,650 --> 00:20:00,180
make these techniques efficient and in

411
00:19:57,780 --> 00:20:01,230
like production you would need to have

412
00:20:00,180 --> 00:20:03,630
like a pre-processing

413
00:20:01,230 --> 00:20:07,020
stuff where you do something like TLS

414
00:20:03,630 --> 00:20:10,530
fingerprinting to identify the actual

415
00:20:07,020 --> 00:20:13,790
TLS library and use and then you know

416
00:20:10,530 --> 00:20:20,250
bring in the right model to to identify

417
00:20:13,790 --> 00:20:24,350
to identify these features great

418
00:20:20,250 --> 00:20:24,350
questions folks please come to the mics

419
00:20:29,150 --> 00:20:33,450
all right Chris would thank you for

420
00:20:31,620 --> 00:20:35,129
bringing this research today in our view

421
00:20:33,450 --> 00:20:36,900
I think it's really great that a

422
00:20:35,130 --> 00:20:38,250
question about the mitigations that you

423
00:20:36,900 --> 00:20:42,150
talked about at the end in particular

424
00:20:38,250 --> 00:20:44,250
the fixed-length record possibility did

425
00:20:42,150 --> 00:20:47,250
you do any experiments with perhaps what

426
00:20:44,250 --> 00:20:49,049
is a you know this is it all depends on

427
00:20:47,250 --> 00:20:51,030
a lot of conditions a lot of variables

428
00:20:49,049 --> 00:20:53,160
what is a good size for that fixed

429
00:20:51,030 --> 00:20:55,470
length and whether or not it needs to be

430
00:20:53,160 --> 00:20:57,150
applied in both directions the same way

431
00:20:55,470 --> 00:21:00,000
like from client to server and server to

432
00:20:57,150 --> 00:21:01,049
client or did you just take like Taurus

433
00:21:00,000 --> 00:21:05,190
implementation or tors

434
00:21:01,049 --> 00:21:09,750
fix length and infer from that so I just

435
00:21:05,190 --> 00:21:13,770
took tourists fixed length and me to

436
00:21:09,750 --> 00:21:16,290
give a little more intuition the I did

437
00:21:13,770 --> 00:21:24,450
some relatively artificial experiments

438
00:21:16,290 --> 00:21:29,090
where I I created new data sets where

439
00:21:24,450 --> 00:21:32,910
each TLS tor session only included one

440
00:21:29,090 --> 00:21:35,280
TLS connection so more or less like you

441
00:21:32,910 --> 00:21:38,309
would see from TLS on the wire and in

442
00:21:35,280 --> 00:21:40,500
those cases tor did not give you are

443
00:21:38,309 --> 00:21:44,190
anywhere near the same protections as

444
00:21:40,500 --> 00:21:45,900
the multiplexing case so that's where

445
00:21:44,190 --> 00:21:48,860
that intuition comes from I haven't

446
00:21:45,900 --> 00:21:56,790
looked very much at very in that size of

447
00:21:48,860 --> 00:21:58,080
fixed length records thank you hi Pat

448
00:21:56,790 --> 00:22:00,290
McManus thanks for doing this this is

449
00:21:58,080 --> 00:22:02,699
really interesting

450
00:22:00,290 --> 00:22:04,559
I'm curious sort of just from the last

451
00:22:02,700 --> 00:22:07,470
slide where you talked about the level

452
00:22:04,559 --> 00:22:09,149
of fingerprinting yeah being used to

453
00:22:07,470 --> 00:22:10,380
classify the data is that the trainer

454
00:22:09,150 --> 00:22:13,559
and then where you can kind of you know

455
00:22:10,380 --> 00:22:14,790
apply the results and the emphasis on

456
00:22:13,559 --> 00:22:16,470
the client side

457
00:22:14,790 --> 00:22:18,149
cendars doing like the bulk of the

458
00:22:16,470 --> 00:22:20,190
sending why don't you think that that

459
00:22:18,150 --> 00:22:22,700
has a bigger sort of influence on on how

460
00:22:20,190 --> 00:22:22,700
that happens

461
00:22:30,360 --> 00:22:33,840
to determine our you know basically

462
00:22:31,650 --> 00:22:35,520
client feels the method and whatever but

463
00:22:33,840 --> 00:22:40,070
like the content like for instance comes

464
00:22:35,520 --> 00:22:40,070
from the other side yeah so sorry

465
00:22:40,370 --> 00:22:48,330
the the the interesting thing is if we

466
00:22:43,620 --> 00:22:54,179
were I don't know exactly how to say

467
00:22:48,330 --> 00:22:55,889
this but we could throw enough I hate

468
00:22:54,180 --> 00:22:57,720
the explanation like throwing data at it

469
00:22:55,890 --> 00:22:59,430
so like the malware case is a really

470
00:22:57,720 --> 00:23:02,010
good example where it encompasses a

471
00:22:59,430 --> 00:23:03,990
large number of clients and if they're

472
00:23:02,010 --> 00:23:06,060
relatively well represented then it can

473
00:23:03,990 --> 00:23:07,650
do a pretty good job of identifying it

474
00:23:06,060 --> 00:23:10,879
that's what's happening on the server

475
00:23:07,650 --> 00:23:15,750
end so the fact that we have a

476
00:23:10,880 --> 00:23:18,390
relatively you know distributed set of

477
00:23:15,750 --> 00:23:19,950
servers in the training database the the

478
00:23:18,390 --> 00:23:22,290
server specification actually doesn't

479
00:23:19,950 --> 00:23:23,430
influence the model as much on the other

480
00:23:22,290 --> 00:23:25,800
hand if we have like Chrome and Firefox

481
00:23:23,430 --> 00:23:29,400
we trained just on Chrome it'll do a bad

482
00:23:25,800 --> 00:23:30,960
job at classifying on Firefox if we do

483
00:23:29,400 --> 00:23:33,600
something like the malware data set

484
00:23:30,960 --> 00:23:35,460
where we get really you know a large

485
00:23:33,600 --> 00:23:36,659
number of examples from every possible

486
00:23:35,460 --> 00:23:38,400
client and then train the machine

487
00:23:36,660 --> 00:23:40,260
learning algorithm it would probably

488
00:23:38,400 --> 00:23:42,450
have a form it's similar to that of the

489
00:23:40,260 --> 00:23:45,510
malware data set which in our data sets

490
00:23:42,450 --> 00:23:49,230
a little worse than the the Chrome and

491
00:23:45,510 --> 00:23:53,840
Firefox specific data sets but it does

492
00:23:49,230 --> 00:23:56,880
all right and you know I think too you

493
00:23:53,840 --> 00:23:58,699
know we wouldn't want it would be

494
00:23:56,880 --> 00:24:01,140
difficult to create a system that had a

495
00:23:58,700 --> 00:24:04,350
reasonable number of false positives if

496
00:24:01,140 --> 00:24:05,670
we both ignore any kind of domain

497
00:24:04,350 --> 00:24:08,490
knowledge on the client side and the

498
00:24:05,670 --> 00:24:10,880
server side so you know definitely in

499
00:24:08,490 --> 00:24:13,170
these experiments we've picked to ignore

500
00:24:10,880 --> 00:24:15,120
things about the server and just let the

501
00:24:13,170 --> 00:24:19,400
data take care of that I think doing

502
00:24:15,120 --> 00:24:22,020
both of them would it leads to slightly

503
00:24:19,400 --> 00:24:27,590
reduced results basically as you can see

504
00:24:22,020 --> 00:24:29,940
in the malware data and it would be I

505
00:24:27,590 --> 00:24:31,889
guess the end of the day it would be

506
00:24:29,940 --> 00:24:33,150
better if you had specific models for

507
00:24:31,890 --> 00:24:37,190
each client because that would improve

508
00:24:33,150 --> 00:24:37,190
performance but it's not necessary

509
00:24:38,000 --> 00:24:44,420
Louis yeah thanks

510
00:24:41,000 --> 00:24:45,860
West fair to Careyes a so somebody on

511
00:24:44,420 --> 00:24:47,750
the internet and in the ATF said

512
00:24:45,860 --> 00:24:48,830
something wrong so I naturally wanted to

513
00:24:47,750 --> 00:24:50,900
correct them and I've been thinking

514
00:24:48,830 --> 00:24:53,270
about collecting a bunch of data like

515
00:24:50,900 --> 00:24:54,920
this actually and it started doing this

516
00:24:53,270 --> 00:24:56,210
last week and then to find out that

517
00:24:54,920 --> 00:24:59,090
you've pretty much done all the work for

518
00:24:56,210 --> 00:24:59,450
me so I really appreciate that fantastic

519
00:24:59,090 --> 00:25:02,060
work

520
00:24:59,450 --> 00:25:04,130
are you did you mention I don't think

521
00:25:02,060 --> 00:25:06,649
you mentioned if you're releasing any

522
00:25:04,130 --> 00:25:12,830
elements of it either data or models or

523
00:25:06,650 --> 00:25:16,780
tools or code or anything so it was our

524
00:25:12,830 --> 00:25:16,780
original intention to release everything

525
00:25:21,340 --> 00:25:29,090
that's about the answer I expected and

526
00:25:26,840 --> 00:25:30,439
actually I'm probably at fault more more

527
00:25:29,090 --> 00:25:36,169
than anyone

528
00:25:30,440 --> 00:25:38,210
I think there's it would be great to

529
00:25:36,170 --> 00:25:39,890
send me an email and remind me there

530
00:25:38,210 --> 00:25:41,720
there's very little that's actually

531
00:25:39,890 --> 00:25:43,390
sensitive in this data set since I

532
00:25:41,720 --> 00:25:48,110
collected it all on a virtual machine

533
00:25:43,390 --> 00:25:52,340
and most of the tools that we we rode I

534
00:25:48,110 --> 00:25:53,929
think could definitely be open source I

535
00:25:52,340 --> 00:25:56,230
don't think there's that much that's

536
00:25:53,930 --> 00:25:58,160
sensitive with them I would need to talk

537
00:25:56,230 --> 00:26:00,980
definitely about the tools the data

538
00:25:58,160 --> 00:26:04,280
itself would probably be easier to open

539
00:26:00,980 --> 00:26:08,690
source I definitely want would want to

540
00:26:04,280 --> 00:26:10,770
do that email me remind me right Thank

541
00:26:08,690 --> 00:26:17,299
You Blake everybody

542
00:26:10,770 --> 00:26:17,299
[Applause]

543
00:26:17,540 --> 00:26:25,800
so our next talk is on our flexible

544
00:26:22,740 --> 00:26:29,850
little box implementation in luton user

545
00:26:25,800 --> 00:26:34,530
space on the authors are accordion it

546
00:26:29,850 --> 00:26:38,159
aligned just a month serosa lonnie and

547
00:26:34,530 --> 00:26:40,350
benoit journey from the University of

548
00:26:38,160 --> 00:26:53,280
liège and Chuck will be given by Cory on

549
00:26:40,350 --> 00:27:00,300
ed aligned we all set it's missing the

550
00:26:53,280 --> 00:27:02,550
image oh that's not good okay sure let's

551
00:27:00,300 --> 00:27:04,409
hope the battery don't know talk fast

552
00:27:02,550 --> 00:27:06,870
we're worried that is battery might die

553
00:27:04,410 --> 00:27:10,410
because this AC adapter is a little

554
00:27:06,870 --> 00:27:14,629
flaky so they'll be a yeah there'll be

555
00:27:10,410 --> 00:27:36,000
some motivation to talk fast

556
00:27:14,630 --> 00:27:40,250
take it away yeah it's it's interesting

557
00:27:36,000 --> 00:27:40,250
it's on this monitor

558
00:27:43,580 --> 00:27:46,730
[Music]

559
00:27:49,250 --> 00:27:55,260
so carranza a PhD stood the University

560
00:27:52,620 --> 00:27:57,149
of liège and works on Miller box

561
00:27:55,260 --> 00:27:59,580
classification impact on transport

562
00:27:57,150 --> 00:28:01,679
protocols published a bunch of stuff and

563
00:27:59,580 --> 00:28:04,620
be defending his thesis later this year

564
00:28:01,679 --> 00:28:06,679
so I'll come back and circle around with

565
00:28:04,620 --> 00:28:09,928
him when he's done go ahead

566
00:28:06,679 --> 00:28:12,900
okay thanks for the introduction so our

567
00:28:09,929 --> 00:28:16,260
paper is untitled and then be flexible

568
00:28:12,900 --> 00:28:18,630
high-speed user space Minard boxes so

569
00:28:16,260 --> 00:28:20,280
I'll start with a bit of context at

570
00:28:18,630 --> 00:28:22,050
first there was the end to an Internet

571
00:28:20,280 --> 00:28:23,850
where Allison book collections packets

572
00:28:22,050 --> 00:28:26,668
while being unsure that they wouldn't

573
00:28:23,850 --> 00:28:27,600
remain untouched in transit then the

574
00:28:26,669 --> 00:28:30,270
middle boxes half

575
00:28:27,600 --> 00:28:32,490
and now packet exchange by Isis and Bob

576
00:28:30,270 --> 00:28:34,410
are crossing various types of middle

577
00:28:32,490 --> 00:28:37,980
boxes from network address translators

578
00:28:34,410 --> 00:28:41,480
to various kind of tunnels firewalls TCP

579
00:28:37,980 --> 00:28:43,950
accelerators and so on and so forth so

580
00:28:41,480 --> 00:28:45,809
originally most of those middle box

581
00:28:43,950 --> 00:28:48,980
appliances were implemented into

582
00:28:45,809 --> 00:28:51,330
dedicated hardware but with the rise of

583
00:28:48,980 --> 00:28:53,580
virtualization and containerization

584
00:28:51,330 --> 00:28:57,510
there is more incentives in being able

585
00:28:53,580 --> 00:28:59,100
to do it on commodity hardware so

586
00:28:57,510 --> 00:29:00,570
straightforward way to do it would be to

587
00:28:59,100 --> 00:29:03,750
rely on the kernel packet processing

588
00:29:00,570 --> 00:29:06,059
functions but unfortunately it was shown

589
00:29:03,750 --> 00:29:09,150
to be a bit too slow to sustain high

590
00:29:06,059 --> 00:29:11,129
speed packet processing plus it is

591
00:29:09,150 --> 00:29:14,429
missing a lot of potential optimizations

592
00:29:11,130 --> 00:29:16,549
such as packet batching or more

593
00:29:14,429 --> 00:29:19,590
efficient use of caching and many more

594
00:29:16,549 --> 00:29:22,799
and one might ask why not do it in user

595
00:29:19,590 --> 00:29:24,360
space directly but first and foremost

596
00:29:22,799 --> 00:29:26,280
because there's no like access to the

597
00:29:24,360 --> 00:29:28,740
network controller you have to go

598
00:29:26,280 --> 00:29:31,408
through a system call which involves a

599
00:29:28,740 --> 00:29:34,799
context switch which involves an extra

600
00:29:31,409 --> 00:29:37,890
overhead that we just can't afford plus

601
00:29:34,799 --> 00:29:40,470
it relies on the escape of structure to

602
00:29:37,890 --> 00:29:43,890
store packets which is very complex and

603
00:29:40,470 --> 00:29:46,140
it's not really in line with packet

604
00:29:43,890 --> 00:29:48,840
batching or butter processing but

605
00:29:46,140 --> 00:29:50,669
fortunately there is DP DK she can be

606
00:29:48,840 --> 00:29:54,149
understood as a user per user space

607
00:29:50,669 --> 00:29:57,630
friendly driver for the network

608
00:29:54,150 --> 00:29:59,700
controller which will write packets on

609
00:29:57,630 --> 00:30:01,950
the memory regions shared between the

610
00:29:59,700 --> 00:30:05,250
kernel and the user space and allow user

611
00:30:01,950 --> 00:30:08,700
space to access to packet directly plus

612
00:30:05,250 --> 00:30:12,270
it relies on spatial data structures -

613
00:30:08,700 --> 00:30:15,929
that are specially crafted 200 packet

614
00:30:12,270 --> 00:30:18,960
batching so this opens the way for user

615
00:30:15,929 --> 00:30:23,340
space middle boxes and for adding more

616
00:30:18,960 --> 00:30:25,559
optimization and flexibility to it this

617
00:30:23,340 --> 00:30:28,350
is a short state-of-the-art of existing

618
00:30:25,559 --> 00:30:30,480
kernel bypass framework first there is

619
00:30:28,350 --> 00:30:32,699
clique which is one of the first to

620
00:30:30,480 --> 00:30:35,850
introduce modularity in the form of

621
00:30:32,700 --> 00:30:36,510
clique elements which are sets of

622
00:30:35,850 --> 00:30:39,120
related

623
00:30:36,510 --> 00:30:41,280
packet processing functions that the

624
00:30:39,120 --> 00:30:43,020
user should combine together

625
00:30:41,280 --> 00:30:46,680
to create its own packet processing

626
00:30:43,020 --> 00:30:50,190
pipeline but it is kind of all and it's

627
00:30:46,680 --> 00:30:51,630
not much optimized then there is PF ring

628
00:30:50,190 --> 00:30:54,270
which I'm not improving the performance

629
00:30:51,630 --> 00:30:57,660
of packet capture but she's too narrowed

630
00:30:54,270 --> 00:31:00,420
for us then there is rod breaks which is

631
00:30:57,660 --> 00:31:03,720
a first step in extending click to

632
00:31:00,420 --> 00:31:06,660
optimize it to introduce parallelism

633
00:31:03,720 --> 00:31:10,020
support to it here's a pocket cheddar

634
00:31:06,660 --> 00:31:12,540
but it relies on a GPU which is out of

635
00:31:10,020 --> 00:31:15,450
scope for us then there is double click

636
00:31:12,540 --> 00:31:18,060
fast click and middle click adjust which

637
00:31:15,450 --> 00:31:20,400
are successive exchange extensions of

638
00:31:18,060 --> 00:31:24,929
click which each introduces new

639
00:31:20,400 --> 00:31:27,750
optimization techniques there is notably

640
00:31:24,930 --> 00:31:30,720
click and P which is the fastest here

641
00:31:27,750 --> 00:31:33,330
but it relies on FPGAs which are out of

642
00:31:30,720 --> 00:31:36,110
part of scope once again and then

643
00:31:33,330 --> 00:31:38,790
finally there is VPP which is modular

644
00:31:36,110 --> 00:31:41,969
inspired by clique but not an extension

645
00:31:38,790 --> 00:31:43,980
of it which has support for a lot of

646
00:31:41,970 --> 00:31:47,460
optimization techniques and runs on

647
00:31:43,980 --> 00:31:50,130
commodity hardware so it stands for

648
00:31:47,460 --> 00:31:51,930
vector packet processing it relies on GP

649
00:31:50,130 --> 00:31:55,650
DK but it's not a requirement are

650
00:31:51,930 --> 00:31:58,710
alternatives it has support for access 0

651
00:31:55,650 --> 00:32:01,920
copy forwarding and many more it relies

652
00:31:58,710 --> 00:32:04,970
on a ket vectors paradigms so it has it

653
00:32:01,920 --> 00:32:08,160
has native support for packet batching

654
00:32:04,970 --> 00:32:11,040
and it has a node based approach similar

655
00:32:08,160 --> 00:32:13,230
to click and additionally it has it

656
00:32:11,040 --> 00:32:16,110
gives special attention to low level

657
00:32:13,230 --> 00:32:20,490
optimizations such as catching and

658
00:32:16,110 --> 00:32:24,090
pipelining so this is an example of out

659
00:32:20,490 --> 00:32:27,150
of the book example of a VPP guru so it

660
00:32:24,090 --> 00:32:29,790
processes packet 0 & 1 in one iteration

661
00:32:27,150 --> 00:32:33,600
of the loop but it start by prefetching

662
00:32:29,790 --> 00:32:36,300
packet 2 entry so not only we subtract

663
00:32:33,600 --> 00:32:38,959
the processing time of packet 0 n 1 the

664
00:32:36,300 --> 00:32:42,450
memory access time of packet to entry

665
00:32:38,960 --> 00:32:44,700
but given the packet vector paradigm the

666
00:32:42,450 --> 00:32:46,500
node based architecture and the nature

667
00:32:44,700 --> 00:32:49,410
of the CPU cache it will in fact

668
00:32:46,500 --> 00:32:53,350
amortize the cost of memory access to

669
00:32:49,410 --> 00:32:55,539
the entire packet vector and now in that

670
00:32:53,350 --> 00:32:58,199
memory access is a major bottleneck in

671
00:32:55,539 --> 00:33:00,970
software which is a major improvement

672
00:32:58,200 --> 00:33:01,450
let's process it packet to packets at a

673
00:33:00,970 --> 00:33:06,639
time

674
00:33:01,450 --> 00:33:08,980
and this is done to increase to leverage

675
00:33:06,639 --> 00:33:10,809
more hardware pipelining which is

676
00:33:08,980 --> 00:33:13,330
basically anticipating the nest in the

677
00:33:10,809 --> 00:33:17,559
next instructions and unpredictable

678
00:33:13,330 --> 00:33:20,590
Jones makes pipelining lose a few clock

679
00:33:17,559 --> 00:33:24,340
cycles so by explicitly unrolling the

680
00:33:20,590 --> 00:33:27,879
loop you can avoid losing truck cycles

681
00:33:24,340 --> 00:33:31,299
needlessly and the last loop is simply

682
00:33:27,879 --> 00:33:34,389
processing the remain packets so we

683
00:33:31,299 --> 00:33:38,799
choose to rely on VPP to implement MB

684
00:33:34,389 --> 00:33:41,110
which is middle box plugin for VPP which

685
00:33:38,799 --> 00:33:43,769
has the following goals it should be

686
00:33:41,110 --> 00:33:46,269
able to handle various mailbox policies

687
00:33:43,769 --> 00:33:48,419
firewalls network address translators or

688
00:33:46,269 --> 00:33:52,179
more complex traffic engineering

689
00:33:48,419 --> 00:33:54,279
policies it should be fast even with

690
00:33:52,179 --> 00:33:56,519
thousands tens of thousands hundred

691
00:33:54,279 --> 00:34:00,250
thousand rules and it should have

692
00:33:56,519 --> 00:34:02,559
possible intuitive July so this is an

693
00:34:00,250 --> 00:34:05,529
overview of the brahmer for rules

694
00:34:02,559 --> 00:34:08,020
addition you can add stateless on

695
00:34:05,529 --> 00:34:10,540
stateful rules you can match any

696
00:34:08,020 --> 00:34:12,879
combination of fields and you can apply

697
00:34:10,540 --> 00:34:16,149
any combination of actions from

698
00:34:12,879 --> 00:34:21,639
modification addition stripping mapping

699
00:34:16,149 --> 00:34:24,190
shuffling and dropping those are the two

700
00:34:21,639 --> 00:34:26,200
MMD nodes in the VPP for warding Raph

701
00:34:24,190 --> 00:34:28,960
so we fetches packet into the

702
00:34:26,199 --> 00:34:31,960
classification node and then depending

703
00:34:28,960 --> 00:34:33,760
on the outcome the classification before

704
00:34:31,960 --> 00:34:36,490
what packets either to the road root

705
00:34:33,760 --> 00:34:38,079
node to the rewind node if needed or to

706
00:34:36,489 --> 00:34:42,219
the next node in the hippie graph which

707
00:34:38,079 --> 00:34:44,619
is before cap and we rely on binary

708
00:34:42,219 --> 00:34:48,730
operations to perform classification and

709
00:34:44,619 --> 00:34:52,540
rewriting plus we rely on a mask based

710
00:34:48,730 --> 00:34:54,719
approach which means that we do not

711
00:34:52,540 --> 00:34:56,949
consider single fields but rather

712
00:34:54,719 --> 00:35:00,578
combination of years to reduce the

713
00:34:56,949 --> 00:35:02,890
complexity so this is an overview of the

714
00:35:00,579 --> 00:35:04,480
processing path of the plugin so we

715
00:35:02,890 --> 00:35:07,270
fetches a packet vector

716
00:35:04,480 --> 00:35:09,790
test each packets against each table

717
00:35:07,270 --> 00:35:12,930
this one table mask which contains all

718
00:35:09,790 --> 00:35:15,310
keys for the rules of using this mask

719
00:35:12,930 --> 00:35:18,339
then we test them against the more

720
00:35:15,310 --> 00:35:20,740
complex matching rules for example ECP

721
00:35:18,340 --> 00:35:23,920
options which cannot be done using masks

722
00:35:20,740 --> 00:35:26,680
and finally we test the packets against

723
00:35:23,920 --> 00:35:31,119
the connection table and if needed we

724
00:35:26,680 --> 00:35:33,730
have the states of the flow and when

725
00:35:31,119 --> 00:35:36,520
needed like the packet vector is

726
00:35:33,730 --> 00:35:38,230
forwarded to write to the right node the

727
00:35:36,520 --> 00:35:40,780
simple rewrite are done in constant time

728
00:35:38,230 --> 00:35:42,610
and then the more complex one which is

729
00:35:40,780 --> 00:35:47,619
if your Shone's again are done

730
00:35:42,610 --> 00:35:50,350
afterwards so we compare the performance

731
00:35:47,619 --> 00:35:52,690
of nmv to three state-of-the-art

732
00:35:50,350 --> 00:35:56,470
solutions fastclick already introduced

733
00:35:52,690 --> 00:36:00,010
sending extension of click designed to

734
00:35:56,470 --> 00:36:04,089
be fast then there is Express data pass

735
00:36:00,010 --> 00:36:09,190
XDP which is an internal solution that

736
00:36:04,090 --> 00:36:12,040
relies on extended BPF which allows to

737
00:36:09,190 --> 00:36:15,609
do packet classification in the kernel

738
00:36:12,040 --> 00:36:18,279
and it also adds support for flow

739
00:36:15,609 --> 00:36:20,980
tracking tables hashmaps and it's

740
00:36:18,280 --> 00:36:26,859
supposed to be fast and IP table for

741
00:36:20,980 --> 00:36:30,820
completeness so we configured our test

742
00:36:26,859 --> 00:36:33,609
bed into four setups direct/indirect PCI

743
00:36:30,820 --> 00:36:35,650
pass-through and breach the top the

744
00:36:33,609 --> 00:36:38,130
direct setup is simply the two traffic

745
00:36:35,650 --> 00:36:40,480
generators directly connected to

746
00:36:38,130 --> 00:36:41,050
evaluate the bottlenecks and the

747
00:36:40,480 --> 00:36:44,950
baselines

748
00:36:41,050 --> 00:36:46,960
the indirect setup with the frameworks

749
00:36:44,950 --> 00:36:49,629
running in bare metal on a device under

750
00:36:46,960 --> 00:36:51,609
test then the PCI pass-through setup

751
00:36:49,630 --> 00:36:55,150
with the frameworks running on a virtual

752
00:36:51,609 --> 00:36:57,460
machine with the physical network

753
00:36:55,150 --> 00:36:59,830
controller directly plugged into the VM

754
00:36:57,460 --> 00:37:02,530
with as few virtualization steps as

755
00:36:59,830 --> 00:37:05,460
possible using so called PCI

756
00:37:02,530 --> 00:37:09,280
pass-through technologies and finally a

757
00:37:05,460 --> 00:37:11,710
bridge set up with realtor network

758
00:37:09,280 --> 00:37:13,359
controller plugged into the VM connected

759
00:37:11,710 --> 00:37:15,280
to the physical ones using bridge

760
00:37:13,359 --> 00:37:18,040
networks for the sake of this

761
00:37:15,280 --> 00:37:20,980
presentation I will skip the two last

762
00:37:18,040 --> 00:37:24,990
but you can find more information

763
00:37:20,980 --> 00:37:29,050
paper extended fish version of the paper

764
00:37:24,990 --> 00:37:31,779
so first we evaluated the baselines of

765
00:37:29,050 --> 00:37:35,110
packet forwarding and found that VPP

766
00:37:31,780 --> 00:37:39,300
fastclick and kernel for 115 is able to

767
00:37:35,110 --> 00:37:39,300
sustain most of the Derrick baseline

768
00:37:39,690 --> 00:37:45,100
then we evaluated the performances of

769
00:37:42,490 --> 00:37:47,589
five triple firewall filtering by

770
00:37:45,100 --> 00:37:52,319
injecting stateless rules matching on

771
00:37:47,590 --> 00:37:54,700
randomly generated five topples and

772
00:37:52,320 --> 00:37:58,410
measuring the throughput you find that

773
00:37:54,700 --> 00:38:01,839
MMB and XDP sustains the direct baseline

774
00:37:58,410 --> 00:38:03,520
surprisingly fast click doesn't because

775
00:38:01,840 --> 00:38:06,820
our performance issue in one of the

776
00:38:03,520 --> 00:38:11,050
component and surprisingly IP tables on

777
00:38:06,820 --> 00:38:16,390
kernel 15 sustains but to sustain the

778
00:38:11,050 --> 00:38:19,210
direct baseline for up to 1k rules then

779
00:38:16,390 --> 00:38:23,859
we evaluated a scenario of stateful flow

780
00:38:19,210 --> 00:38:25,480
matching well inject similarly stateful

781
00:38:23,860 --> 00:38:27,550
rules matching on randomly generated

782
00:38:25,480 --> 00:38:30,730
factor per but here we make sure that

783
00:38:27,550 --> 00:38:34,500
each flow matches at least one rule so

784
00:38:30,730 --> 00:38:37,060
that the states of each ropes maintain

785
00:38:34,500 --> 00:38:39,370
the results are pretty similar we find

786
00:38:37,060 --> 00:38:42,810
that mm v and x DP sustains that our

787
00:38:39,370 --> 00:38:46,529
baseline fast leak this time sustains

788
00:38:42,810 --> 00:38:48,970
85% of the dark baseline and IP tables

789
00:38:46,530 --> 00:38:56,560
behave similarly to the stateless

790
00:38:48,970 --> 00:38:58,740
scenario and finally we tested the TCP

791
00:38:56,560 --> 00:39:02,049
option passing scenario where we match

792
00:38:58,740 --> 00:39:06,729
where we matches on rondalee generated

793
00:39:02,050 --> 00:39:09,700
tcp orphan kind it is not applicable to

794
00:39:06,730 --> 00:39:12,550
IP tables nor fast click because fastly

795
00:39:09,700 --> 00:39:16,390
doesn't support it and we couldn't

796
00:39:12,550 --> 00:39:18,490
manage to push it into x DP in a modular

797
00:39:16,390 --> 00:39:21,970
enough where this is probably possible

798
00:39:18,490 --> 00:39:22,689
but not comparable to MMB so we only

799
00:39:21,970 --> 00:39:26,100
evaluated

800
00:39:22,690 --> 00:39:29,950
MMB here and we found that it is stable

801
00:39:26,100 --> 00:39:33,450
up to with up to seventy eight seventy

802
00:39:29,950 --> 00:39:39,509
eight different TCP options

803
00:39:33,450 --> 00:39:42,569
which drastically is very enough so the

804
00:39:39,510 --> 00:39:44,309
confusion we evaluated MMB found that it

805
00:39:42,569 --> 00:39:46,500
was able to sustain line rate for

806
00:39:44,309 --> 00:39:49,589
different use cases of middle box

807
00:39:46,500 --> 00:39:53,040
policies in the future who would like to

808
00:39:49,589 --> 00:39:57,960
add payload work instruction to it to be

809
00:39:53,040 --> 00:40:01,290
able to implement policies for our PSS

810
00:39:57,960 --> 00:40:04,440
idss or other things if you are

811
00:40:01,290 --> 00:40:09,480
interested or just curious just check

812
00:40:04,440 --> 00:40:13,940
out the repository thank you great thank

813
00:40:09,480 --> 00:40:13,940
you Korean questions

814
00:40:24,540 --> 00:40:34,080
can't tell whether you're headed out or

815
00:40:26,860 --> 00:40:34,080
to the mic here come somebody

816
00:40:34,590 --> 00:40:40,480
come Robert so some of this actually

817
00:40:38,170 --> 00:40:43,350
ties in with that presentation we're

818
00:40:40,480 --> 00:40:45,490
doing tomorrow on deep dive into Nicks

819
00:40:43,350 --> 00:40:47,680
we're definitely going to have smart

820
00:40:45,490 --> 00:40:51,220
Nick's coming that can do a lot of this

821
00:40:47,680 --> 00:40:53,620
processing inside the neck so I think a

822
00:40:51,220 --> 00:40:55,569
direction for something like this might

823
00:40:53,620 --> 00:40:57,400
be how how to leverage some of those

824
00:40:55,570 --> 00:40:58,900
advanced features because we know once

825
00:40:57,400 --> 00:41:01,300
you start pushing stuff down to the neck

826
00:40:58,900 --> 00:41:03,130
like the fire Rover rules they'll

827
00:41:01,300 --> 00:41:08,740
perform better so something to consider

828
00:41:03,130 --> 00:41:14,590
mm-hmm thank you yes great let's spend

829
00:41:08,740 --> 00:41:20,100
coding in games thank you Pledger

830
00:41:14,590 --> 00:41:20,100
machine lasted there you go

831
00:41:32,890 --> 00:41:43,970
so how you doing good

832
00:41:40,540 --> 00:41:46,370
so last talk of this session is checking

833
00:41:43,970 --> 00:41:46,970
in on network functions by addition

834
00:41:46,370 --> 00:41:52,940
Lakhani

835
00:41:46,970 --> 00:41:57,109
and has a Miller at Carnegie Mellon so

836
00:41:52,940 --> 00:41:59,000
zhushan the first-year student a PhD in

837
00:41:57,110 --> 00:42:01,580
CMU's institute of software engineering

838
00:41:59,000 --> 00:42:03,590
research and working on programming

839
00:42:01,580 --> 00:42:05,660
languages assistance research and also

840
00:42:03,590 --> 00:42:07,400
does some work for Comcast around edge

841
00:42:05,660 --> 00:42:09,649
computing and programmable networks and

842
00:42:07,400 --> 00:42:15,490
claims he's not on the job market so

843
00:42:09,650 --> 00:42:18,800
approaching please hear me all right

844
00:42:15,490 --> 00:42:20,990
cool so this is some interesting work

845
00:42:18,800 --> 00:42:22,490
that we've been looking at I've been

846
00:42:20,990 --> 00:42:25,759
looking at actually from two kind of

847
00:42:22,490 --> 00:42:27,709
ways kind of inspired by work we're

848
00:42:25,760 --> 00:42:29,210
doing at Comcast around edge computing

849
00:42:27,710 --> 00:42:30,860
and and it's good the last talk was

850
00:42:29,210 --> 00:42:33,400
before me so remember all those things

851
00:42:30,860 --> 00:42:36,080
about middleboxes and network functions

852
00:42:33,400 --> 00:42:37,580
and about things like VPP we use

853
00:42:36,080 --> 00:42:40,069
something different I'll talk about that

854
00:42:37,580 --> 00:42:43,880
but we were doing all this work with

855
00:42:40,070 --> 00:42:45,500
ipv6 segment routing variable data and

856
00:42:43,880 --> 00:42:48,640
that kind of changed the way we thought

857
00:42:45,500 --> 00:42:51,410
about things so in my research mind I

858
00:42:48,640 --> 00:42:52,850
thought well how can I apply programming

859
00:42:51,410 --> 00:42:56,540
languages and software engineering

860
00:42:52,850 --> 00:42:59,690
research and tooling to to doing these

861
00:42:56,540 --> 00:43:02,990
network functions so kind of cover the

862
00:42:59,690 --> 00:43:05,210
last talk network functions had you know

863
00:43:02,990 --> 00:43:08,049
this kind of vendor base hardware items

864
00:43:05,210 --> 00:43:11,360
that ran these very single specific

865
00:43:08,050 --> 00:43:15,410
pieces of that random Network firewalls

866
00:43:11,360 --> 00:43:17,180
IDs load balancers and then things kind

867
00:43:15,410 --> 00:43:21,020
of got recycled as we moved into the

868
00:43:17,180 --> 00:43:22,520
cloud and software and so the way we

869
00:43:21,020 --> 00:43:24,170
thought about running these things we

870
00:43:22,520 --> 00:43:26,240
random on nodes there's really good work

871
00:43:24,170 --> 00:43:27,980
from people like Justine sherry while

872
00:43:26,240 --> 00:43:28,759
she was at Berkeley talking about how

873
00:43:27,980 --> 00:43:31,580
middleboxes

874
00:43:28,760 --> 00:43:33,680
have moved into the cloud I mean you see

875
00:43:31,580 --> 00:43:36,710
these things running in AWS now and all

876
00:43:33,680 --> 00:43:39,200
these kind of cloud providers but we're

877
00:43:36,710 --> 00:43:40,700
really interested in though is the rise

878
00:43:39,200 --> 00:43:43,040
of how we're writing and modeling

879
00:43:40,700 --> 00:43:44,689
network functions which is something

880
00:43:43,040 --> 00:43:45,860
probably maybe not everyone is

881
00:43:44,690 --> 00:43:48,320
interested in I

882
00:43:45,860 --> 00:43:50,420
of higher-level languages I love

883
00:43:48,320 --> 00:43:52,070
functional programming these were not

884
00:43:50,420 --> 00:43:54,350
the typical things I saw when I started

885
00:43:52,070 --> 00:43:56,120
writing Network functions but then there

886
00:43:54,350 --> 00:43:58,400
there actually is a lot out there so

887
00:43:56,120 --> 00:44:01,000
there are things like PI retic which

888
00:43:58,400 --> 00:44:05,870
comes out of the frenetic kind of

889
00:44:01,000 --> 00:44:07,760
lineage which is a python-based library

890
00:44:05,870 --> 00:44:10,160
for writing modular network functions

891
00:44:07,760 --> 00:44:12,470
there's stuff like slick that came out

892
00:44:10,160 --> 00:44:14,600
that lets you do interesting kind of

893
00:44:12,470 --> 00:44:16,370
pipelining for subsets of traffic and

894
00:44:14,600 --> 00:44:19,009
then there's things like netcat which is

895
00:44:16,370 --> 00:44:20,839
this really cool semantic model for

896
00:44:19,010 --> 00:44:22,400
thinking about networks it has a proofs

897
00:44:20,840 --> 00:44:24,080
for soundness and completion

898
00:44:22,400 --> 00:44:25,790
it seems really really great it lets you

899
00:44:24,080 --> 00:44:28,490
do things like reachability analysis

900
00:44:25,790 --> 00:44:32,000
writing your code for all these things

901
00:44:28,490 --> 00:44:33,740
that are really great things are getting

902
00:44:32,000 --> 00:44:35,570
more and more complex and even though

903
00:44:33,740 --> 00:44:37,009
you have these great this great set of

904
00:44:35,570 --> 00:44:38,420
research that's coming out showing us

905
00:44:37,010 --> 00:44:41,510
how we can do certain things it doesn't

906
00:44:38,420 --> 00:44:43,610
really cover a lot of ad hoc and you

907
00:44:41,510 --> 00:44:45,650
know kind of large scale ideas because

908
00:44:43,610 --> 00:44:48,050
now writing network functions is is

909
00:44:45,650 --> 00:44:50,060
dealing with complex routing and load

910
00:44:48,050 --> 00:44:51,710
balancing policies so my work at Comcast

911
00:44:50,060 --> 00:44:53,090
is the kind of inspiration and inputs

912
00:44:51,710 --> 00:44:55,070
it's for us like what we looked at from

913
00:44:53,090 --> 00:44:57,590
their traffic monitoring is a major

914
00:44:55,070 --> 00:44:59,600
thing you have a lot around experimental

915
00:44:57,590 --> 00:45:01,700
new specifications protocols and headers

916
00:44:59,600 --> 00:45:03,920
and then you have a lot of work there's

917
00:45:01,700 --> 00:45:05,810
recent I think 2018 or 17 this paper

918
00:45:03,920 --> 00:45:07,490
called in network computation is a dumb

919
00:45:05,810 --> 00:45:10,009
idea whose time has come it's a great

920
00:45:07,490 --> 00:45:11,540
title talks about how we're doing

921
00:45:10,010 --> 00:45:13,490
aggregation and doing all this different

922
00:45:11,540 --> 00:45:14,990
kinds of views on computation in the

923
00:45:13,490 --> 00:45:17,270
network so things are getting really

924
00:45:14,990 --> 00:45:20,450
complex can these frameworks that we

925
00:45:17,270 --> 00:45:22,100
have to write high high level code and

926
00:45:20,450 --> 00:45:23,600
network functions and packet processing

927
00:45:22,100 --> 00:45:26,029
is that we get going in the right

928
00:45:23,600 --> 00:45:28,700
direction so the motivation for us was

929
00:45:26,030 --> 00:45:30,560
it sounds a little cheeky because I come

930
00:45:28,700 --> 00:45:32,810
from web programming and application

931
00:45:30,560 --> 00:45:34,549
programming was if I program and react

932
00:45:32,810 --> 00:45:36,110
who here knows react the JavaScript

933
00:45:34,550 --> 00:45:40,190
framework yeah I'm definitely at a

934
00:45:36,110 --> 00:45:42,710
networking conference but yeah reactive

935
00:45:40,190 --> 00:45:44,120
this major kind of JavaScript UI

936
00:45:42,710 --> 00:45:46,190
framework that's gotten a lot of

937
00:45:44,120 --> 00:45:47,870
popularity because it's a really great

938
00:45:46,190 --> 00:45:49,820
set of engineering work does really

939
00:45:47,870 --> 00:45:52,730
smart work about doing differentiation

940
00:45:49,820 --> 00:45:54,680
and moving toward immutability and how

941
00:45:52,730 --> 00:45:56,210
we write programs but if I'm writing if

942
00:45:54,680 --> 00:45:57,529
I'm a react programmer how do I write a

943
00:45:56,210 --> 00:45:58,720
network function if I don't know much

944
00:45:57,530 --> 00:46:00,369
about the lower layers

945
00:45:58,720 --> 00:46:04,089
in packet level computation that's

946
00:46:00,369 --> 00:46:05,260
available and so say I start and I have

947
00:46:04,090 --> 00:46:07,119
a way to do that in these high-level

948
00:46:05,260 --> 00:46:09,099
frameworks maybe in like a language like

949
00:46:07,119 --> 00:46:10,660
Python you saw how do we know what we're

950
00:46:09,099 --> 00:46:13,150
doing is right I don't know much about

951
00:46:10,660 --> 00:46:15,368
this is not my background I don't read

952
00:46:13,150 --> 00:46:17,560
IETF specs all the time how do I do this

953
00:46:15,369 --> 00:46:19,540
and then how can we iterate upon this

954
00:46:17,560 --> 00:46:22,660
and debug and kind of learn as we're

955
00:46:19,540 --> 00:46:24,430
writing and so this might be scary for

956
00:46:22,660 --> 00:46:26,200
some but maybe it's okay if all those

957
00:46:24,430 --> 00:46:29,609
react and JavaScript programmers start

958
00:46:26,200 --> 00:46:31,810
coming over to write Network code maybe

959
00:46:29,609 --> 00:46:33,400
the problem that is out there with

960
00:46:31,810 --> 00:46:35,049
what's available in these higher level

961
00:46:33,400 --> 00:46:37,330
abstractions that is a limit there's

962
00:46:35,050 --> 00:46:39,010
limits of correctness so netcat which is

963
00:46:37,330 --> 00:46:40,299
again this really great cinematic model

964
00:46:39,010 --> 00:46:41,980
for doing network program and it's

965
00:46:40,300 --> 00:46:44,200
gotten better and you know i'm baseness

966
00:46:41,980 --> 00:46:47,500
a little bit off the original work they

967
00:46:44,200 --> 00:46:50,049
they compile down to two code that had

968
00:46:47,500 --> 00:46:51,550
to work on the OpenFlow protocol again

969
00:46:50,050 --> 00:46:53,050
that's great but there's a lot of other

970
00:46:51,550 --> 00:46:55,599
protocols of course and even the

971
00:46:53,050 --> 00:46:57,940
original impetus of open flow was like

972
00:46:55,599 --> 00:46:59,950
on campus research and experimentation

973
00:46:57,940 --> 00:47:01,570
and yet if you do if a new protocol

974
00:46:59,950 --> 00:47:04,410
comes in our experimental protocol is

975
00:47:01,570 --> 00:47:07,270
available open flow might not support it

976
00:47:04,410 --> 00:47:08,740
and a lot of the case that I dealt with

977
00:47:07,270 --> 00:47:10,720
and coming up with this research was

978
00:47:08,740 --> 00:47:13,569
dealing with arbitrary I add hot logic

979
00:47:10,720 --> 00:47:15,189
in variable link data extension headers

980
00:47:13,570 --> 00:47:16,690
extension headers extension headers so

981
00:47:15,190 --> 00:47:20,260
we do a lot of work at Comcast around

982
00:47:16,690 --> 00:47:21,990
segment routing and other than there was

983
00:47:20,260 --> 00:47:24,520
some library that had implemented

984
00:47:21,990 --> 00:47:26,770
versions of the v6 segment routing

985
00:47:24,520 --> 00:47:28,509
header there was not much we had to

986
00:47:26,770 --> 00:47:29,680
write a lot of this ourselves and then

987
00:47:28,510 --> 00:47:31,990
just imagine when you have multiple

988
00:47:29,680 --> 00:47:33,790
extension headers on top of each other

989
00:47:31,990 --> 00:47:36,368
we're not just hot you know it can get

990
00:47:33,790 --> 00:47:38,589
pretty complex and so dealing with how

991
00:47:36,369 --> 00:47:39,910
if I update segments on the fly in the

992
00:47:38,589 --> 00:47:41,650
middle of the network over and over

993
00:47:39,910 --> 00:47:43,868
again how do I change the packet lengths

994
00:47:41,650 --> 00:47:45,310
all the time how do I deal with dynamic

995
00:47:43,869 --> 00:47:47,859
information around failure and we've

996
00:47:45,310 --> 00:47:49,420
configuration so the you know separately

997
00:47:47,859 --> 00:47:51,910
from the research kind of part of this

998
00:47:49,420 --> 00:47:53,589
my work at Comcast is dealing with how

999
00:47:51,910 --> 00:47:55,359
do we make things like failure and load

1000
00:47:53,589 --> 00:47:57,640
shedding a primitive for how we write

1001
00:47:55,359 --> 00:47:59,440
programs anybody can write programs

1002
00:47:57,640 --> 00:48:03,490
thinking about these things and policies

1003
00:47:59,440 --> 00:48:05,109
at application level so the last talk

1004
00:48:03,490 --> 00:48:06,939
mentioned a little bit about click-click

1005
00:48:05,109 --> 00:48:09,640
is kind of the fact they're like really

1006
00:48:06,940 --> 00:48:14,200
awesome in 99

1007
00:48:09,640 --> 00:48:16,990
yeah way to write code for doing packet

1008
00:48:14,200 --> 00:48:19,720
processing pipelines and you know it's

1009
00:48:16,990 --> 00:48:21,578
still used and and and I you know

1010
00:48:19,720 --> 00:48:22,899
Eddie's awesome for a lot of things but

1011
00:48:21,579 --> 00:48:25,650
this is this is a piece of code that's

1012
00:48:22,900 --> 00:48:30,220
still in there to do ipv6 validation

1013
00:48:25,650 --> 00:48:34,510
with this kind of go too bad sink that a

1014
00:48:30,220 --> 00:48:36,640
lot of other little pieces of code if

1015
00:48:34,510 --> 00:48:38,319
things are not right and you see that we

1016
00:48:36,640 --> 00:48:40,480
have this kind of hard-coded value in

1017
00:48:38,319 --> 00:48:42,880
our paper if you download it there's

1018
00:48:40,480 --> 00:48:44,950
even code a more complex set of code

1019
00:48:42,880 --> 00:48:47,289
maybe from Facebook on there and network

1020
00:48:44,950 --> 00:48:49,000
load balancer called cat ran which just

1021
00:48:47,289 --> 00:48:51,609
came out you know open source I guess

1022
00:48:49,000 --> 00:48:53,980
officially not too long ago and they had

1023
00:48:51,609 --> 00:48:56,049
a lot of code it's seemingly really good

1024
00:48:53,980 --> 00:48:58,089
results but they you know everything is

1025
00:48:56,049 --> 00:48:59,440
based on constants hard-coded numbers I

1026
00:48:58,089 --> 00:49:01,390
mean maybe this is pretty common in

1027
00:48:59,440 --> 00:49:02,500
networking man it is not common when you

1028
00:49:01,390 --> 00:49:05,410
think of higher level programming

1029
00:49:02,500 --> 00:49:08,140
abstractions the two examples we look at

1030
00:49:05,410 --> 00:49:11,200
in the in the paper which are kind of

1031
00:49:08,140 --> 00:49:13,480
these variable ad hoc ones the MTU sent

1032
00:49:11,200 --> 00:49:15,819
to big response so you have a client

1033
00:49:13,480 --> 00:49:18,069
that has like a TCP packet it's way too

1034
00:49:15,819 --> 00:49:20,740
big we have to do these sets of actions

1035
00:49:18,069 --> 00:49:22,960
to then return it back including

1036
00:49:20,740 --> 00:49:25,689
changing the protocol to an IC icmpv6

1037
00:49:22,960 --> 00:49:27,279
and the v6 variation calculating

1038
00:49:25,690 --> 00:49:29,799
checksum swapping source and destination

1039
00:49:27,279 --> 00:49:31,779
how do we make sure that happens

1040
00:49:29,799 --> 00:49:33,190
especially if I'm writing this network

1041
00:49:31,779 --> 00:49:35,259
function from the beginning the other

1042
00:49:33,190 --> 00:49:37,630
one as I mentioned is ipv6 extension

1043
00:49:35,259 --> 00:49:38,559
headers which if you look at the spec

1044
00:49:37,630 --> 00:49:40,779
right there you have things like

1045
00:49:38,559 --> 00:49:43,599
obviously the segment lists can get can

1046
00:49:40,779 --> 00:49:46,089
change over time and you have this TLV

1047
00:49:43,599 --> 00:49:47,619
type value objects which can change you

1048
00:49:46,089 --> 00:49:50,200
know which can change and again it's

1049
00:49:47,619 --> 00:49:52,690
variable information a earlier talk is

1050
00:49:50,200 --> 00:49:54,640
about NTP we do a lot of ntp which has

1051
00:49:52,690 --> 00:49:56,529
these prefix options you can sometimes

1052
00:49:54,640 --> 00:49:58,000
do get options on this packet sometimes

1053
00:49:56,529 --> 00:50:00,880
you won't we've seen this in practice

1054
00:49:58,000 --> 00:50:02,680
and and that makes things very difficult

1055
00:50:00,880 --> 00:50:03,880
so I want to wait we want to wait to

1056
00:50:02,680 --> 00:50:08,529
think about this from an abstraction

1057
00:50:03,880 --> 00:50:10,839
level and so as you see there v6 and so

1058
00:50:08,529 --> 00:50:14,920
we thought about what is an interesting

1059
00:50:10,839 --> 00:50:17,619
way to combine a hybrid set of checks or

1060
00:50:14,920 --> 00:50:18,789
we call contracts and in in software

1061
00:50:17,619 --> 00:50:21,730
engineering and programming language

1062
00:50:18,789 --> 00:50:22,940
land and that the impetus kind of came

1063
00:50:21,730 --> 00:50:24,829
from

1064
00:50:22,940 --> 00:50:27,980
early things the Eifel programming

1065
00:50:24,829 --> 00:50:29,510
language which was in the 86 talked

1066
00:50:27,980 --> 00:50:31,310
about this idea of designed by contract

1067
00:50:29,510 --> 00:50:32,480
where your focus on how run some

1068
00:50:31,310 --> 00:50:34,250
countries have you turned on for

1069
00:50:32,480 --> 00:50:36,079
monitoring and testing situations and

1070
00:50:34,250 --> 00:50:38,210
quoted from I think the original paper a

1071
00:50:36,079 --> 00:50:40,520
book you can just sit back and watch

1072
00:50:38,210 --> 00:50:42,680
your contract to be violated again this

1073
00:50:40,520 --> 00:50:44,900
is during the design and testing phase

1074
00:50:42,680 --> 00:50:47,089
of writing programs and this is built

1075
00:50:44,900 --> 00:50:48,710
into the language contractor primitive

1076
00:50:47,089 --> 00:50:50,660
and iPhone and now you're seeing this a

1077
00:50:48,710 --> 00:50:52,700
lot of other languages if you like some

1078
00:50:50,660 --> 00:50:57,020
kind of modern list to see this a lot

1079
00:50:52,700 --> 00:50:59,779
too and so in design by contract you can

1080
00:50:57,020 --> 00:51:01,069
run this stuff in development but like

1081
00:50:59,780 --> 00:51:02,869
in our case in our tool and our

1082
00:51:01,069 --> 00:51:05,240
prototype we erase this information

1083
00:51:02,869 --> 00:51:08,690
these assertions and work in release

1084
00:51:05,240 --> 00:51:10,700
binaries we also wanted to add some sort

1085
00:51:08,690 --> 00:51:12,680
of static checking that is based on

1086
00:51:10,700 --> 00:51:15,529
compile time assertion so in languages

1087
00:51:12,680 --> 00:51:17,509
like C C++ and D you'll see this used

1088
00:51:15,530 --> 00:51:19,280
and you can do checks on constant

1089
00:51:17,510 --> 00:51:21,050
statics which again happy' get happen

1090
00:51:19,280 --> 00:51:23,270
and Static having at compile time and

1091
00:51:21,050 --> 00:51:24,920
these can actually remain and release

1092
00:51:23,270 --> 00:51:26,740
binaries because they have their only

1093
00:51:24,920 --> 00:51:30,140
affect is its that is the static

1094
00:51:26,740 --> 00:51:32,810
programming and then we have this idea

1095
00:51:30,140 --> 00:51:34,490
of static order preserving headers so in

1096
00:51:32,810 --> 00:51:35,930
the framework we use I'm an exercise on

1097
00:51:34,490 --> 00:51:39,979
the implementation it's that one called

1098
00:51:35,930 --> 00:51:43,190
net bricks it has this concept of the

1099
00:51:39,980 --> 00:51:44,630
previous header as a type so we use this

1100
00:51:43,190 --> 00:51:47,089
kind of previous set of headers to

1101
00:51:44,630 --> 00:51:49,400
determine order so if you're traversing

1102
00:51:47,089 --> 00:51:51,109
a packet in your network function code

1103
00:51:49,400 --> 00:51:54,319
and you use something that's you know

1104
00:51:51,109 --> 00:51:57,828
TCP coming after some I not coming after

1105
00:51:54,319 --> 00:51:59,599
v6 or v4 IP part of your packet that

1106
00:51:57,829 --> 00:52:01,280
will be a compile time error so we use

1107
00:51:59,599 --> 00:52:04,069
that to our advantage in doing our code

1108
00:52:01,280 --> 00:52:07,339
so again the design by contract as I

1109
00:52:04,069 --> 00:52:09,170
mentioned influenced by Tony Hoare and

1110
00:52:07,339 --> 00:52:12,560
this workaround whore logic around pre

1111
00:52:09,170 --> 00:52:14,720
and post conditions we kind of relate

1112
00:52:12,560 --> 00:52:17,450
that in our code to input an egress for

1113
00:52:14,720 --> 00:52:19,540
pre and output an output an egress for

1114
00:52:17,450 --> 00:52:22,069
post

1115
00:52:19,540 --> 00:52:24,020
static assertions as I mentioned kind of

1116
00:52:22,069 --> 00:52:25,250
comes from this world of c and c++ can

1117
00:52:24,020 --> 00:52:28,550
do a lot of interesting work with

1118
00:52:25,250 --> 00:52:30,230
checking on conversions as well and you

1119
00:52:28,550 --> 00:52:32,240
know an example we use it for is some of

1120
00:52:30,230 --> 00:52:33,950
these MTU values for determining where

1121
00:52:32,240 --> 00:52:35,810
something is too big depending on where

1122
00:52:33,950 --> 00:52:36,950
you are in the packet that's depends on

1123
00:52:35,810 --> 00:52:40,040
how many bytes are actually look

1124
00:52:36,950 --> 00:52:42,230
and again static for the static order

1125
00:52:40,040 --> 00:52:43,460
preserving headers the idea of Sachi to

1126
00:52:42,230 --> 00:52:44,690
find an order mechanism I'll show an

1127
00:52:43,460 --> 00:52:46,790
example of what that means

1128
00:52:44,690 --> 00:52:48,260
so our implementation is done as a

1129
00:52:46,790 --> 00:52:51,020
gradual extension to this through

1130
00:52:48,260 --> 00:52:53,780
Netflix which is a DP DK based you know

1131
00:52:51,020 --> 00:52:56,120
user space that we just heard about take

1132
00:52:53,780 --> 00:52:58,760
on this this work and it's written in

1133
00:52:56,120 --> 00:53:01,009
rust which is a really cool language

1134
00:52:58,760 --> 00:53:02,840
that is now starting to get you know

1135
00:53:01,010 --> 00:53:06,670
even Congress knows about rust Knight

1136
00:53:02,840 --> 00:53:09,320
leaves if you saw a recent video and and

1137
00:53:06,670 --> 00:53:11,660
in particular Netflix is focusing idea

1138
00:53:09,320 --> 00:53:13,580
of zero copy soft isolation it's able to

1139
00:53:11,660 --> 00:53:16,910
do it be able to like eliminate the need

1140
00:53:13,580 --> 00:53:18,710
for copying packets recapping Eureka you

1141
00:53:16,910 --> 00:53:21,259
have copying packets because of this

1142
00:53:18,710 --> 00:53:23,390
idea of using static types to do these

1143
00:53:21,260 --> 00:53:24,590
checks and using this idea of order we

1144
00:53:23,390 --> 00:53:27,560
just leverage it and go a little bit

1145
00:53:24,590 --> 00:53:30,380
further and we implement our work our

1146
00:53:27,560 --> 00:53:32,330
prototype as a small rust library which

1147
00:53:30,380 --> 00:53:34,190
generates code for validations and

1148
00:53:32,330 --> 00:53:36,080
assertion so the key here this comes

1149
00:53:34,190 --> 00:53:37,760
more from some previous software

1150
00:53:36,080 --> 00:53:39,740
engineering research and and and

1151
00:53:37,760 --> 00:53:42,230
programming language work is that we

1152
00:53:39,740 --> 00:53:44,509
didn't want the programmer to have to

1153
00:53:42,230 --> 00:53:45,860
write all these all these validations

1154
00:53:44,510 --> 00:53:47,840
and worry about how all these

1155
00:53:45,860 --> 00:53:50,420
validations work together we let them

1156
00:53:47,840 --> 00:53:53,120
write very simple checks and we generate

1157
00:53:50,420 --> 00:53:54,830
the code to do the work using macros

1158
00:53:53,120 --> 00:53:56,330
another talk for another time about how

1159
00:53:54,830 --> 00:54:00,049
great macros are it's my favorite thing

1160
00:53:56,330 --> 00:54:01,819
in the world so and and rust has

1161
00:54:00,050 --> 00:54:04,070
hygienic procedural macros which are

1162
00:54:01,820 --> 00:54:07,370
really cool for a low-level know TC

1163
00:54:04,070 --> 00:54:08,840
language so here's a net Brix a typical

1164
00:54:07,370 --> 00:54:10,640
example I she's from Newark Cove we've

1165
00:54:08,840 --> 00:54:12,830
been writing and 1/4 of metrics which is

1166
00:54:10,640 --> 00:54:14,500
open source under and github and I'll

1167
00:54:12,830 --> 00:54:18,520
talk yeah you can find that in the paper

1168
00:54:14,500 --> 00:54:21,470
this is a simple Mac swap where we're

1169
00:54:18,520 --> 00:54:22,550
checking just doing a simple parse here

1170
00:54:21,470 --> 00:54:24,890
and you see that we have these types

1171
00:54:22,550 --> 00:54:26,330
like Ethernet that we can determine and

1172
00:54:24,890 --> 00:54:28,310
the code looks like a declarative

1173
00:54:26,330 --> 00:54:29,870
MapReduce if you're familiar with spark

1174
00:54:28,310 --> 00:54:32,270
or any of these frameworks that's the

1175
00:54:29,870 --> 00:54:34,130
thing that Netflix has but it's very ad

1176
00:54:32,270 --> 00:54:36,980
hoc I can do terrible things I can try

1177
00:54:34,130 --> 00:54:38,630
to log a blot do a log that's a blocking

1178
00:54:36,980 --> 00:54:40,280
process as my packets are being

1179
00:54:38,630 --> 00:54:42,080
processed I have to know what I'm doing

1180
00:54:40,280 --> 00:54:46,370
and think about it so there's a price

1181
00:54:42,080 --> 00:54:48,650
you pay so our work in particular see if

1182
00:54:46,370 --> 00:54:50,299
this works there we go yeah a little bit

1183
00:54:48,650 --> 00:54:54,990
delayed but alright

1184
00:54:50,299 --> 00:54:56,730
okay alright so we we missed the word

1185
00:54:54,990 --> 00:54:58,109
gradual so we have these network

1186
00:54:56,730 --> 00:55:00,089
functions they look like this

1187
00:54:58,109 --> 00:55:01,619
I've alighted some some work of filters

1188
00:55:00,089 --> 00:55:04,740
maps and group bys that you can do in

1189
00:55:01,619 --> 00:55:07,530
this but what's cool about our work is

1190
00:55:04,740 --> 00:55:09,149
that you can add this check attribute we

1191
00:55:07,530 --> 00:55:10,170
will check this we will be able to check

1192
00:55:09,150 --> 00:55:13,380
that network function if you're

1193
00:55:10,170 --> 00:55:14,760
composing these functions for example if

1194
00:55:13,380 --> 00:55:16,890
you don't put the check we won't check

1195
00:55:14,760 --> 00:55:18,599
it again it's gradual it's buy-in and we

1196
00:55:16,890 --> 00:55:20,368
can take old metric functions for

1197
00:55:18,599 --> 00:55:22,109
example and just add our code on to it

1198
00:55:20,369 --> 00:55:24,540
and if you don't want it you don't get

1199
00:55:22,109 --> 00:55:26,369
it and so in our in our piece we have

1200
00:55:24,540 --> 00:55:28,740
our preconditions here which are using a

1201
00:55:26,369 --> 00:55:30,180
macro called ingress check where we can

1202
00:55:28,740 --> 00:55:31,618
determine we actually saying here's the

1203
00:55:30,180 --> 00:55:34,169
order we expect which again it's going

1204
00:55:31,619 --> 00:55:36,510
to be static time runtime checks and

1205
00:55:34,170 --> 00:55:39,089
then a post condition which checks what

1206
00:55:36,510 --> 00:55:41,579
the packet was before to what it is at

1207
00:55:39,089 --> 00:55:43,799
the end and so again orders checked

1208
00:55:41,579 --> 00:55:45,480
statically via tracer package contents

1209
00:55:43,799 --> 00:55:47,040
we have pre checks that validate

1210
00:55:45,480 --> 00:55:49,079
incoming content and store content at

1211
00:55:47,040 --> 00:55:50,759
runtime and we have post checks that

1212
00:55:49,079 --> 00:55:53,040
validate the transform packets correct

1213
00:55:50,760 --> 00:55:55,500
in this case when I have an MTU send too

1214
00:55:53,040 --> 00:55:57,390
big I have a TCP packet for example

1215
00:55:55,500 --> 00:56:00,089
that's too large my return packet now

1216
00:55:57,390 --> 00:56:02,069
should be an ICMP packet that is that is

1217
00:56:00,089 --> 00:56:03,750
the right amount of bytes 1280 and in

1218
00:56:02,069 --> 00:56:07,109
most cases that is the right amount of

1219
00:56:03,750 --> 00:56:08,880
bytes and I have swapped destination and

1220
00:56:07,109 --> 00:56:11,490
source addresses I have swapped Ethernet

1221
00:56:08,880 --> 00:56:13,619
addresses and basically if this works

1222
00:56:11,490 --> 00:56:16,020
again at design time in a run time so

1223
00:56:13,619 --> 00:56:18,420
our evaluation was pretty much looking

1224
00:56:16,020 --> 00:56:22,230
at additional syntax compilation time

1225
00:56:18,420 --> 00:56:23,790
and runtime overhead again the focus has

1226
00:56:22,230 --> 00:56:25,589
been on the design phase so we look at

1227
00:56:23,790 --> 00:56:27,210
syntax added this is a very common

1228
00:56:25,589 --> 00:56:29,400
software engineering thing you see in

1229
00:56:27,210 --> 00:56:32,339
papers emitting Li I will say I kind of

1230
00:56:29,400 --> 00:56:34,619
hate it but I did it and so we see that

1231
00:56:32,339 --> 00:56:36,359
we don't we don't really add many lines

1232
00:56:34,619 --> 00:56:38,790
of code most of it really around

1233
00:56:36,359 --> 00:56:40,440
configuration for adding some new

1234
00:56:38,790 --> 00:56:42,690
libraries but we you know adding these

1235
00:56:40,440 --> 00:56:43,559
tracks is basically end to the amount of

1236
00:56:42,690 --> 00:56:46,710
checks that you want to add for

1237
00:56:43,559 --> 00:56:48,059
assertions this one we feel is pretty

1238
00:56:46,710 --> 00:56:50,940
important which is that we have this

1239
00:56:48,059 --> 00:56:54,359
tool we the goal is designed by contract

1240
00:56:50,940 --> 00:56:56,339
combining static and dynamic checks but

1241
00:56:54,359 --> 00:56:58,259
compilation time should not be affected

1242
00:56:56,339 --> 00:56:59,880
the same Russ program the same metrics

1243
00:56:58,260 --> 00:57:03,000
function you should be writing without

1244
00:56:59,880 --> 00:57:04,740
any of these generated code should

1245
00:57:03,000 --> 00:57:07,110
the same as you know with or without so

1246
00:57:04,740 --> 00:57:08,819
we show that actually in some cases no

1247
00:57:07,110 --> 00:57:11,580
significance we're actually faster it

1248
00:57:08,820 --> 00:57:13,680
means it just doesn't matter and there

1249
00:57:11,580 --> 00:57:15,930
is a runtime cost so we're doing we're

1250
00:57:13,680 --> 00:57:17,370
doing some work to do like order

1251
00:57:15,930 --> 00:57:19,560
preserving headers we're actually

1252
00:57:17,370 --> 00:57:21,299
tracing the entire path we're tracing

1253
00:57:19,560 --> 00:57:24,810
the entire transformation of the packet

1254
00:57:21,300 --> 00:57:26,310
header by header to make sure that we in

1255
00:57:24,810 --> 00:57:27,810
the code that we generated to make sure

1256
00:57:26,310 --> 00:57:29,370
that the order is correct for example

1257
00:57:27,810 --> 00:57:31,620
and we do a lot of runtime storing for

1258
00:57:29,370 --> 00:57:33,779
the dynamic check so as a packet comes

1259
00:57:31,620 --> 00:57:35,609
in we store all this information so we

1260
00:57:33,780 --> 00:57:39,330
can use it for validation at the post

1261
00:57:35,610 --> 00:57:40,740
condition that does take time so we have

1262
00:57:39,330 --> 00:57:43,100
these runtime checks also we're not

1263
00:57:40,740 --> 00:57:45,720
using the most optimized data structure

1264
00:57:43,100 --> 00:57:47,610
but again this is for design phase and

1265
00:57:45,720 --> 00:57:48,689
ideally you wouldn't be running this in

1266
00:57:47,610 --> 00:57:51,750
production you would only have the

1267
00:57:48,690 --> 00:57:53,100
static assertions in production so our

1268
00:57:51,750 --> 00:57:55,620
future work we've already started on

1269
00:57:53,100 --> 00:57:57,089
some of this is that is not just to run

1270
00:57:55,620 --> 00:57:58,710
this kind of on your computer while

1271
00:57:57,090 --> 00:58:00,570
you're while you're designing programs

1272
00:57:58,710 --> 00:58:02,430
and network functions you can do this as

1273
00:58:00,570 --> 00:58:04,560
part of a deployment model and CI or

1274
00:58:02,430 --> 00:58:06,509
already we have this working running up

1275
00:58:04,560 --> 00:58:10,170
in mini net and container net which we

1276
00:58:06,510 --> 00:58:13,290
use heavily to run this up you can run

1277
00:58:10,170 --> 00:58:14,880
these as part of your simulation we hope

1278
00:58:13,290 --> 00:58:16,920
to further leverage static analysis have

1279
00:58:14,880 --> 00:58:18,240
been put programs and we really want to

1280
00:58:16,920 --> 00:58:19,920
bring in a lot of the work that we see

1281
00:58:18,240 --> 00:58:22,109
in compilation now and even from UI

1282
00:58:19,920 --> 00:58:25,530
tooling around interactive feedback

1283
00:58:22,110 --> 00:58:27,090
program slicing and refinement using

1284
00:58:25,530 --> 00:58:29,760
program affine and constraint solving so

1285
00:58:27,090 --> 00:58:31,050
there's a lot of work in p4 which is

1286
00:58:29,760 --> 00:58:33,570
used to write a lot of network functions

1287
00:58:31,050 --> 00:58:35,640
to look at constraint solvers for work

1288
00:58:33,570 --> 00:58:38,070
but they tend not to go for these very

1289
00:58:35,640 --> 00:58:40,259
ad hoc variable linked data examples and

1290
00:58:38,070 --> 00:58:42,720
we hope to actually show this in

1291
00:58:40,260 --> 00:58:44,460
practice at Comcast we use this net Brix

1292
00:58:42,720 --> 00:58:45,569
library and we've forked it and created

1293
00:58:44,460 --> 00:58:48,270
a kind of our own version we've

1294
00:58:45,570 --> 00:58:49,710
rewritten a lot of the runtime we do use

1295
00:58:48,270 --> 00:58:51,630
some of the checking work that actually

1296
00:58:49,710 --> 00:58:53,880
I've done in my research but we also had

1297
00:58:51,630 --> 00:58:55,560
to come up with some new ideas that that

1298
00:58:53,880 --> 00:58:57,270
kind of emphasized what does it mean to

1299
00:58:55,560 --> 00:58:58,770
program these network shion's for

1300
00:58:57,270 --> 00:59:00,750
anybody and we have to create

1301
00:58:58,770 --> 00:59:02,640
limitations so one of the limitations we

1302
00:59:00,750 --> 00:59:04,500
have to do this idea of scope side

1303
00:59:02,640 --> 00:59:06,450
effects so I mentioned earlier in the

1304
00:59:04,500 --> 00:59:08,460
MTU example we have to update all these

1305
00:59:06,450 --> 00:59:10,740
things when you when you change from

1306
00:59:08,460 --> 00:59:13,680
your change to go back to the sender

1307
00:59:10,740 --> 00:59:15,520
with the specific response we have to

1308
00:59:13,680 --> 00:59:18,190
basically have this cascade function

1309
00:59:15,520 --> 00:59:19,930
which says any time that I update parts

1310
00:59:18,190 --> 00:59:21,520
of the packet automatically cascade and

1311
00:59:19,930 --> 00:59:23,440
change the packet length and recalculate

1312
00:59:21,520 --> 00:59:25,060
the checksum the same thing for segments

1313
00:59:23,440 --> 00:59:26,619
so the work we do in Comcast we're

1314
00:59:25,060 --> 00:59:28,779
constantly changing semantics on the

1315
00:59:26,619 --> 00:59:31,240
segment's we actually use the bits in

1316
00:59:28,780 --> 00:59:33,040
the address 100 the 128-bit addresses to

1317
00:59:31,240 --> 00:59:35,290
actually encode actions takes an idea

1318
00:59:33,040 --> 00:59:38,770
from old light an OL idea called active

1319
00:59:35,290 --> 00:59:40,300
networks and so what we need to do there

1320
00:59:38,770 --> 00:59:42,040
and say well when I set the segment's

1321
00:59:40,300 --> 00:59:45,130
make sure I change the packet lengths

1322
00:59:42,040 --> 00:59:47,410
update the checksum etc etc let's not

1323
00:59:45,130 --> 00:59:49,030
let the programmer have to actually do

1324
00:59:47,410 --> 00:59:51,520
that let's force them to do that it's a

1325
00:59:49,030 --> 00:59:53,619
limitation upfront giving away some like

1326
00:59:51,520 --> 00:59:54,759
some interesting flexibility but an

1327
00:59:53,619 --> 00:59:56,619
interesting thing we also have this

1328
00:59:54,760 --> 00:59:59,080
concept of tight packets and not only do

1329
00:59:56,619 --> 01:00:00,640
we have the previous header and the the

1330
00:59:59,080 --> 01:00:02,740
header that comes after us where you

1331
01:00:00,640 --> 01:00:05,710
guys say what's the envelope so we can

1332
01:00:02,740 --> 01:00:09,700
bound things using our type system to

1333
01:00:05,710 --> 01:00:12,250
say well a tcp or UDP UDP part of a

1334
01:00:09,700 --> 01:00:14,859
packet you know can't come after some

1335
01:00:12,250 --> 01:00:16,750
ICMP one and we can now do that using

1336
01:00:14,860 --> 01:00:20,230
bounding and types and again that's

1337
01:00:16,750 --> 01:00:21,730
statically checked so takeaways are we

1338
01:00:20,230 --> 01:00:23,109
need better approaches to verify

1339
01:00:21,730 --> 01:00:25,750
interact with network functions and

1340
01:00:23,109 --> 01:00:28,690
processing packet processing program

1341
01:00:25,750 --> 01:00:30,850
properties in this work we have a hybrid

1342
01:00:28,690 --> 01:00:33,520
approach that we use to gradually check

1343
01:00:30,850 --> 01:00:35,770
and validate arbitrary large logic and

1344
01:00:33,520 --> 01:00:38,320
side-effects and by combining these

1345
01:00:35,770 --> 01:00:40,180
different kinds of contracts we show

1346
01:00:38,320 --> 01:00:42,910
that a mixed model can really work and

1347
01:00:40,180 --> 01:00:45,520
we did this all about penalizing the

1348
01:00:42,910 --> 01:00:48,600
developer and programmers at the design

1349
01:00:45,520 --> 01:00:54,750
time of writing these network functions

1350
01:00:48,600 --> 01:00:54,750
thanks buddy thank you questions

1351
01:00:55,710 --> 01:01:02,109
hi I'm coach I'm Riku working a nice

1352
01:00:59,859 --> 01:01:04,299
presentation it's probably in the paper

1353
01:01:02,109 --> 01:01:07,119
which I haven't read yet but I assume

1354
01:01:04,300 --> 01:01:09,670
this supports stateful functions as well

1355
01:01:07,119 --> 01:01:11,650
that yeah yeah I mean so the work that

1356
01:01:09,670 --> 01:01:14,070
we actually use that bricks for is doing

1357
01:01:11,650 --> 01:01:17,770
a lot of stateful probably so does um

1358
01:01:14,070 --> 01:01:20,619
are you aware of the computing in the

1359
01:01:17,770 --> 01:01:23,170
network research group in the IRT F I'm

1360
01:01:20,619 --> 01:01:25,210
aware of it yeah yeah for sure yeah so

1361
01:01:23,170 --> 01:01:28,240
yeah I mean I I hope to see more of this

1362
01:01:25,210 --> 01:01:29,890
you know most of my background came from

1363
01:01:28,240 --> 01:01:31,540
looking at stuff like netcat which you

1364
01:01:29,890 --> 01:01:33,009
won't necessarily see here you'll see it

1365
01:01:31,540 --> 01:01:34,599
pop I was so surprised when we saw I

1366
01:01:33,010 --> 01:01:36,250
started working in networks and going

1367
01:01:34,599 --> 01:01:38,950
not everybody's using netcat

1368
01:01:36,250 --> 01:01:40,570
and everyone laughed at me and the work

1369
01:01:38,950 --> 01:01:42,310
is so amazing but the idea is I think

1370
01:01:40,570 --> 01:01:43,570
obviously for actually use you have to

1371
01:01:42,310 --> 01:01:45,660
find some sort of balance and that's

1372
01:01:43,570 --> 01:01:47,880
what we're trying to convey thank you

1373
01:01:45,660 --> 01:01:51,310
anyone else

1374
01:01:47,880 --> 01:01:56,020
great so let's thank them one more time

1375
01:01:51,310 --> 01:01:59,730
and next session starts at 4:00 3:50

1376
01:01:56,020 --> 01:01:59,730
p.m. so enjoy your break

