1
00:00:03,419 --> 00:00:06,359
hi everyone my name is Jason I am a

2
00:00:06,359 --> 00:00:08,700
research scientist at Mozilla my work

3
00:00:08,700 --> 00:00:11,429
focuses on bring more transparency to

4
00:00:11,429 --> 00:00:13,860
artificial intelligence algorithms or

5
00:00:13,860 --> 00:00:17,490
more specifically I build tools I built

6
00:00:17,490 --> 00:00:21,180
was to help users verify and interrogate

7
00:00:21,180 --> 00:00:24,300
AI algorithms and so for the next few

8
00:00:24,300 --> 00:00:25,980
minutes I'll walk through or I walk

9
00:00:25,980 --> 00:00:28,290
through this by topics with you I will

10
00:00:28,290 --> 00:00:30,330
explain what I mean by verify and

11
00:00:30,330 --> 00:00:33,450
interrogate AI algorithms our use

12
00:00:33,450 --> 00:00:34,710
machine friends our language

13
00:00:34,710 --> 00:00:37,530
translations at example and I'll go into

14
00:00:37,530 --> 00:00:39,329
what happens when AI makes a billion

15
00:00:39,329 --> 00:00:41,010
translation mistakes

16
00:00:41,010 --> 00:00:45,300
I'll then look at what happens when a AI

17
00:00:45,300 --> 00:00:47,160
impacts us both physically on the road

18
00:00:47,160 --> 00:00:49,980
and also virtually on the web and I'll

19
00:00:49,980 --> 00:00:51,270
conclude with some of the work that

20
00:00:51,270 --> 00:00:52,649
we're doing here at Mozilla around

21
00:00:52,649 --> 00:00:56,309
transparency so we all have very

22
00:00:56,309 --> 00:00:58,380
different ideas of what a I could mean

23
00:00:58,380 --> 00:01:01,200
to us it could be for example my

24
00:01:01,200 --> 00:01:03,660
refrigerator started talking to me or it

25
00:01:03,660 --> 00:01:05,069
could be the killer robots that you see

26
00:01:05,069 --> 00:01:07,710
in the movies and so to kill grunt the

27
00:01:07,710 --> 00:01:09,540
conversation I am going to look at

28
00:01:09,540 --> 00:01:13,350
language translation so these days if

29
00:01:13,350 --> 00:01:14,960
you point your phone at a menu like this

30
00:01:14,960 --> 00:01:17,850
you can if you translate the menu from a

31
00:01:17,850 --> 00:01:20,250
foreign language into English so I hope

32
00:01:20,250 --> 00:01:21,869
all of us agree here in the room this is

33
00:01:21,869 --> 00:01:23,909
one type of AI or artificial

34
00:01:23,909 --> 00:01:27,150
intelligence and I was also just

35
00:01:27,150 --> 00:01:28,260
traveling in Asia

36
00:01:28,260 --> 00:01:30,210
last week and saw one of these signs I

37
00:01:30,210 --> 00:01:32,310
was standing next to a cliff and the

38
00:01:32,310 --> 00:01:33,659
sign told me to fall in the water

39
00:01:33,659 --> 00:01:36,780
carefully so in the back of our mind

40
00:01:36,780 --> 00:01:38,850
aside this is I really mean for me to

41
00:01:38,850 --> 00:01:40,200
jump off the curb a point of water

42
00:01:40,200 --> 00:01:41,549
carefully or is it trying to say

43
00:01:41,549 --> 00:01:43,890
something else so as well using these

44
00:01:43,890 --> 00:01:46,740
tours AI to help us translate in all

45
00:01:46,740 --> 00:01:48,780
languages for us the question is how do

46
00:01:48,780 --> 00:01:52,220
we trust the result of the translation

47
00:01:52,220 --> 00:01:54,390
how many of you here have used Google

48
00:01:54,390 --> 00:01:57,479
Translate okay so I think most of you

49
00:01:57,479 --> 00:01:58,680
are you here familiar with the

50
00:01:58,680 --> 00:02:01,229
technology and so if I were to translate

51
00:02:01,229 --> 00:02:03,479
the phrase for beans from English to say

52
00:02:03,479 --> 00:02:05,400
German which one of these two

53
00:02:05,400 --> 00:02:07,860
translations would you trust am i saying

54
00:02:07,860 --> 00:02:10,500
you know a can full of beans or am i

55
00:02:10,500 --> 00:02:12,300
talking about a child who just woke up

56
00:02:12,300 --> 00:02:14,040
on the map who's full of beans and run

57
00:02:14,040 --> 00:02:14,690
around the heart

58
00:02:14,690 --> 00:02:17,030
how do you trust the result of who go

59
00:02:17,030 --> 00:02:20,270
translate so 10 years ago I should

60
00:02:20,270 --> 00:02:22,760
interned at Google as part of my project

61
00:02:22,760 --> 00:02:25,190
I build this tour on the bottom right

62
00:02:25,190 --> 00:02:27,080
hand side and so rather than just

63
00:02:27,080 --> 00:02:29,240
showing users to block through box at

64
00:02:29,240 --> 00:02:31,400
the top users now have some additional

65
00:02:31,400 --> 00:02:33,590
tools to help them understand what

66
00:02:33,590 --> 00:02:36,170
Google Translate is doing and what do I

67
00:02:36,170 --> 00:02:38,990
mean by verify an AI algorithm so as

68
00:02:38,990 --> 00:02:43,310
part of this tour we provide information

69
00:02:43,310 --> 00:02:47,000
such as part of speech a can full of

70
00:02:47,000 --> 00:02:49,250
beans is the Hmong a Chow for beans as

71
00:02:49,250 --> 00:02:51,170
an adjective so users can use these

72
00:02:51,170 --> 00:02:52,850
information to assess what a lot of

73
00:02:52,850 --> 00:02:54,020
translations correct

74
00:02:54,020 --> 00:02:57,890
we also translate the word English back

75
00:02:57,890 --> 00:02:59,570
into English from German back into

76
00:02:59,570 --> 00:03:01,640
English into a language that the users

77
00:03:01,640 --> 00:03:03,680
understand so the users can you know

78
00:03:03,680 --> 00:03:05,990
look at it look at the transverse

79
00:03:05,990 --> 00:03:07,820
translation and see whether or not

80
00:03:07,820 --> 00:03:09,110
Google Translate is doing the right

81
00:03:09,110 --> 00:03:12,980
thing what do I mean by interrogate so

82
00:03:12,980 --> 00:03:14,360
even though Google Translate only gives

83
00:03:14,360 --> 00:03:16,370
you one translation the tool is also

84
00:03:16,370 --> 00:03:18,530
interactive and will provide different

85
00:03:18,530 --> 00:03:20,480
synonyms so the users and click on

86
00:03:20,480 --> 00:03:22,430
different potential translations and

87
00:03:22,430 --> 00:03:24,890
explore from themselves which one they

88
00:03:24,890 --> 00:03:28,040
might you want to use and instead of

89
00:03:28,040 --> 00:03:29,870
just accept accept in the first result

90
00:03:29,870 --> 00:03:31,100
that Google Trends they give back to the

91
00:03:31,100 --> 00:03:34,160
users so my first takeaway of my talk

92
00:03:34,160 --> 00:03:36,950
today or first two are for with us AI

93
00:03:36,950 --> 00:03:39,020
algorithms one we should verify the

94
00:03:39,020 --> 00:03:41,570
results with human expertise and

95
00:03:41,570 --> 00:03:43,459
hopefully use the language that we

96
00:03:43,459 --> 00:03:46,310
humans can understand and two is that we

97
00:03:46,310 --> 00:03:48,590
should interrogate analyze all possible

98
00:03:48,590 --> 00:03:50,930
outcomes that a and I could generate and

99
00:03:50,930 --> 00:03:52,850
not just accept but firstly another AI

100
00:03:52,850 --> 00:03:58,100
fist is to us and so my next topic is so

101
00:03:58,100 --> 00:04:01,550
what happens when AI makes mistakes so

102
00:04:01,550 --> 00:04:04,100
Google Translate I think is about four

103
00:04:04,100 --> 00:04:05,870
years ago is used by about 500 million

104
00:04:05,870 --> 00:04:08,180
users and translates about 200 billion

105
00:04:08,180 --> 00:04:11,030
words per day but even though we know is

106
00:04:11,030 --> 00:04:12,350
super convenient if you have an

107
00:04:12,350 --> 00:04:14,570
important document I legal document if

108
00:04:14,570 --> 00:04:16,190
you are doing marketing material you

109
00:04:16,190 --> 00:04:17,450
probably don't want to just feed the

110
00:04:17,450 --> 00:04:19,040
document through go translate and put it

111
00:04:19,040 --> 00:04:19,640
out there

112
00:04:19,640 --> 00:04:21,769
we still higher human professional

113
00:04:21,769 --> 00:04:24,560
translators and as I was doing all the

114
00:04:24,560 --> 00:04:26,120
research on machine translation we

115
00:04:26,120 --> 00:04:27,980
noticed there's a new business model

116
00:04:27,980 --> 00:04:32,000
post-edit so historically professional

117
00:04:32,000 --> 00:04:34,160
human translators are paid for the

118
00:04:34,160 --> 00:04:36,410
number of words translated and a new

119
00:04:36,410 --> 00:04:37,910
business model that we noticed is that

120
00:04:37,910 --> 00:04:39,320
the translation companies will start

121
00:04:39,320 --> 00:04:41,840
giving translators documented documents

122
00:04:41,840 --> 00:04:44,750
translated by Google first and then exit

123
00:04:44,750 --> 00:04:46,760
translator to correct the document to

124
00:04:46,760 --> 00:04:49,070
transact read the document and the

125
00:04:49,070 --> 00:04:50,540
translator and then paid by the number

126
00:04:50,540 --> 00:04:53,690
of wars corrected this is one anybody

127
00:04:53,690 --> 00:04:59,540
want to take a guess what happened was

128
00:04:59,540 --> 00:05:02,570
that yeah name acknowledged changes and

129
00:05:02,570 --> 00:05:04,430
order to more concretely where she put a

130
00:05:04,430 --> 00:05:06,620
poll on Twitter and this is what the

131
00:05:06,620 --> 00:05:09,170
translators told us translators we want

132
00:05:09,170 --> 00:05:10,250
to know what do you think of post

133
00:05:10,250 --> 00:05:12,620
editing and more than one would rather

134
00:05:12,620 --> 00:05:14,720
go to a dentist then try to correct your

135
00:05:14,720 --> 00:05:18,350
translation or this in terms of numbers

136
00:05:18,350 --> 00:05:20,000
for researchers from the study the

137
00:05:20,000 --> 00:05:22,550
practice they found that to pay the

138
00:05:22,550 --> 00:05:24,170
researchers fair rate you actually have

139
00:05:24,170 --> 00:05:26,240
to pay them more than the original rate

140
00:05:26,240 --> 00:05:28,610
about up to 110 percent before the

141
00:05:28,610 --> 00:05:31,220
translators were bid for job to post

142
00:05:31,220 --> 00:05:33,320
edit because of all the manual efforts

143
00:05:33,320 --> 00:05:35,330
involved they actually in a controlled

144
00:05:35,330 --> 00:05:36,830
environment when they use professional

145
00:05:36,830 --> 00:05:39,080
translating tools they spent up to 90%

146
00:05:39,080 --> 00:05:40,730
of the time correcting Google

147
00:05:40,730 --> 00:05:42,890
translation then start in a translation

148
00:05:42,890 --> 00:05:45,770
from scratch because you know the effort

149
00:05:45,770 --> 00:05:47,480
required to comprehend the document stay

150
00:05:47,480 --> 00:05:49,730
on the same but they are not only paid

151
00:05:49,730 --> 00:05:51,170
about 40 percent of what they were

152
00:05:51,170 --> 00:05:52,790
before

153
00:05:52,790 --> 00:05:55,310
so my next I'll take away from how we

154
00:05:55,310 --> 00:05:55,790
truss

155
00:05:55,790 --> 00:05:59,120
algorithms is that AI is really only at

156
00:05:59,120 --> 00:06:01,940
or Spoonamore evaluatee in AI we need to

157
00:06:01,940 --> 00:06:04,040
take your account what a is being used

158
00:06:04,040 --> 00:06:06,230
for and who's benefiting from the

159
00:06:06,230 --> 00:06:10,220
algorithm so I'm sort of lighting in

160
00:06:10,220 --> 00:06:11,480
part I'm going through a lot of habits

161
00:06:11,480 --> 00:06:14,870
very quickly so the third topic um what

162
00:06:14,870 --> 00:06:16,940
happens for we know AI hopes try to

163
00:06:16,940 --> 00:06:18,500
arrange four billion miles of travels

164
00:06:18,500 --> 00:06:21,080
how many of you here use --lift

165
00:06:21,080 --> 00:06:24,410
uper or not a car sharing app app so I

166
00:06:24,410 --> 00:06:26,330
see police over half of a hen's go up so

167
00:06:26,330 --> 00:06:27,860
hopefully this is another example most

168
00:06:27,860 --> 00:06:29,420
of you can relate or many of you can

169
00:06:29,420 --> 00:06:33,500
relate in this room so back in 2008 when

170
00:06:33,500 --> 00:06:35,840
uber try to seek funding and start a

171
00:06:35,840 --> 00:06:37,670
company this is actually from their own

172
00:06:37,670 --> 00:06:40,550
their own presentation they described

173
00:06:40,550 --> 00:06:41,810
that they were used algorithm

174
00:06:41,810 --> 00:06:45,110
to help have better utilized vehicle

175
00:06:45,110 --> 00:06:47,960
resources or is in other words as part

176
00:06:47,960 --> 00:06:49,850
of you know their business model they're

177
00:06:49,850 --> 00:06:51,800
gonna remove reduce traffic jams in

178
00:06:51,800 --> 00:06:54,440
cities and what happens 11 years later

179
00:06:54,440 --> 00:06:58,070
is when lived and Google commissioned a

180
00:06:58,070 --> 00:07:00,410
study in 68 of cities in the United

181
00:07:00,410 --> 00:07:02,150
States they should found the opposite of

182
00:07:02,150 --> 00:07:04,130
fact that they were actually increase in

183
00:07:04,130 --> 00:07:07,730
traffic congestion in fact the head of

184
00:07:07,730 --> 00:07:09,860
global policy uber came out to actually

185
00:07:09,860 --> 00:07:11,540
admit that publicly to the button

186
00:07:11,540 --> 00:07:13,520
imposed they are likely contribute into

187
00:07:13,520 --> 00:07:15,080
traffic congestions

188
00:07:15,080 --> 00:07:17,540
so while this may not be good news for

189
00:07:17,540 --> 00:07:20,450
uber or lyft these were able to have the

190
00:07:20,450 --> 00:07:22,700
data to verify what's happening to AI

191
00:07:22,700 --> 00:07:25,130
and a large scale so they made a claim

192
00:07:25,130 --> 00:07:27,080
this is why I could do and we have the

193
00:07:27,080 --> 00:07:29,150
data how to back it up and so my next

194
00:07:29,150 --> 00:07:31,340
pick ways if you want to available what

195
00:07:31,340 --> 00:07:33,680
happens systemically we need a data and

196
00:07:33,680 --> 00:07:35,360
in this case at least uber and lyft

197
00:07:35,360 --> 00:07:37,760
I'm sure the data with the independent

198
00:07:37,760 --> 00:07:41,510
group and so my next topic is what

199
00:07:41,510 --> 00:07:44,020
happens when we have AI on the internet

200
00:07:44,020 --> 00:07:46,250
how many of you have opened up either

201
00:07:46,250 --> 00:07:49,940
Facebook or Instagram sometime today and

202
00:07:49,940 --> 00:07:51,680
also see about half of a hen's go up in

203
00:07:51,680 --> 00:07:53,240
a room so hopefully it's not exempt or

204
00:07:53,240 --> 00:07:56,390
you can relate to so this is the job ad

205
00:07:56,390 --> 00:07:58,550
that I saw on Facebook yesterday I was

206
00:07:58,550 --> 00:08:01,460
preparing for the slides and what do we

207
00:08:01,460 --> 00:08:03,140
see an ad on Facebook you can actually

208
00:08:03,140 --> 00:08:05,330
click on the bottom on the road the

209
00:08:05,330 --> 00:08:06,590
three dots on the top right hand corner

210
00:08:06,590 --> 00:08:09,289
and ask Facebook give you an explanation

211
00:08:09,289 --> 00:08:11,120
why you know I'm seeing this particular

212
00:08:11,120 --> 00:08:13,100
ad and we'll give you an explicit

213
00:08:13,100 --> 00:08:14,840
explanation like this to say though

214
00:08:14,840 --> 00:08:16,310
these are the reasons why I'm seeing

215
00:08:16,310 --> 00:08:18,410
this ad um

216
00:08:18,410 --> 00:08:20,210
but research researchers have found that

217
00:08:20,210 --> 00:08:22,039
there's a lot of reasons that Facebook

218
00:08:22,039 --> 00:08:24,440
is not providing us and some of these

219
00:08:24,440 --> 00:08:27,229
reasons include the budget of the ad on

220
00:08:27,229 --> 00:08:29,630
your gender your raised and automatic

221
00:08:29,630 --> 00:08:32,539
ethanol's is well does anybody want to

222
00:08:32,539 --> 00:08:34,460
venture a guess why the budget of the ad

223
00:08:34,460 --> 00:08:36,770
my effect whether I'm seeing this ad and

224
00:08:36,770 --> 00:08:39,919
not you know Connie sitting in the back

225
00:08:39,919 --> 00:08:46,250
of the room two minutes so I'm just

226
00:08:46,250 --> 00:08:49,640
gonna insert this myself so as it turns

227
00:08:49,640 --> 00:08:51,560
out there are more products and the

228
00:08:51,560 --> 00:08:53,630
women on Facebook than men

229
00:08:53,630 --> 00:08:54,560
and therefore it's actually more

230
00:08:54,560 --> 00:08:56,569
expensive to advertise to women than men

231
00:08:56,569 --> 00:08:58,940
and if you're a company trying to note

232
00:08:58,940 --> 00:09:01,040
advertise for a job opening and your

233
00:09:01,040 --> 00:09:02,930
budget is below the kind of products

234
00:09:02,930 --> 00:09:04,850
that we and the women Facebook will

235
00:09:04,850 --> 00:09:06,889
naturally service low value as to men

236
00:09:06,889 --> 00:09:08,839
and show the higher value as to women

237
00:09:08,839 --> 00:09:10,730
and this the swipe is one of the

238
00:09:10,730 --> 00:09:12,470
possible reasons why I'm seeing a job ad

239
00:09:12,470 --> 00:09:14,089
and not the other women here in this

240
00:09:14,089 --> 00:09:17,329
room or more specifically some of the

241
00:09:17,329 --> 00:09:19,519
more recent research found some of these

242
00:09:19,519 --> 00:09:21,920
findings they found that for example

243
00:09:21,920 --> 00:09:24,829
when they post jobs about the lumber

244
00:09:24,829 --> 00:09:27,050
industry facebook / horny serve that

245
00:09:27,050 --> 00:09:29,149
they as two white men when they

246
00:09:29,149 --> 00:09:31,250
advertised for jobs positions for

247
00:09:31,250 --> 00:09:33,889
example cashiers in the supermarket 85

248
00:09:33,889 --> 00:09:36,319
of them went to women and when they

249
00:09:36,319 --> 00:09:38,750
advertised for jobs for taxi drivers

250
00:09:38,750 --> 00:09:41,029
they went to black Americans and all

251
00:09:41,029 --> 00:09:43,399
this researchers posting a job ad with

252
00:09:43,399 --> 00:09:45,560
exactly the same targeting criteria and

253
00:09:45,560 --> 00:09:47,990
the delivery is determined by the

254
00:09:47,990 --> 00:09:51,290
algorithm and the problem is this is

255
00:09:51,290 --> 00:09:53,060
that because we don't have the data even

256
00:09:53,060 --> 00:09:54,139
though we can demonstrate some of these

257
00:09:54,139 --> 00:09:55,490
effects we don't know how widespread

258
00:09:55,490 --> 00:09:58,100
these effects are how many people day of

259
00:09:58,100 --> 00:10:00,410
their effect are impacted by such

260
00:10:00,410 --> 00:10:02,990
practices and which means race me to the

261
00:10:02,990 --> 00:10:05,149
last point some of the recent work that

262
00:10:05,149 --> 00:10:07,069
we're doing with the US and new

263
00:10:07,069 --> 00:10:09,860
elections in Mozilla so for the past

264
00:10:09,860 --> 00:10:11,240
year or so I've been trying to build

265
00:10:11,240 --> 00:10:13,610
tools to help our users and just web

266
00:10:13,610 --> 00:10:15,980
users in general better understand how

267
00:10:15,980 --> 00:10:17,990
they're being targeted during the US

268
00:10:17,990 --> 00:10:19,880
midterm selections and the new elections

269
00:10:19,880 --> 00:10:22,040
earlier this year some these tools

270
00:10:22,040 --> 00:10:24,199
include the an analysis analysis for

271
00:10:24,199 --> 00:10:26,959
Facebook and a transparency report for

272
00:10:26,959 --> 00:10:29,120
the European Union but for both of these

273
00:10:29,120 --> 00:10:30,980
projects we could not deliver the entire

274
00:10:30,980 --> 00:10:33,019
product because we do not have the data

275
00:10:33,019 --> 00:10:36,500
and which is why I'm here and this in

276
00:10:36,500 --> 00:10:37,910
pecan and hopefully we'll engage with

277
00:10:37,910 --> 00:10:39,949
some of the representative or platforms

278
00:10:39,949 --> 00:10:41,389
to break the top seal to have a

279
00:10:41,389 --> 00:10:43,730
contractive conversation how we can get

280
00:10:43,730 --> 00:10:45,319
some the data we definitely have the

281
00:10:45,319 --> 00:10:47,180
expertise to build these tools to bring

282
00:10:47,180 --> 00:10:49,189
more transparency to AI but we don't

283
00:10:49,189 --> 00:10:51,889
have the data and so thank you very much

284
00:10:51,889 --> 00:10:54,690
and thanks

285
00:10:54,690 --> 00:10:56,750
you

