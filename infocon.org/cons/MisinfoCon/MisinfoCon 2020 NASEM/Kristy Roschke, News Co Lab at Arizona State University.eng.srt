1
00:00:02,629 --> 00:00:10,559
Thank You Ahmed I set my timer so as

2
00:00:10,559 --> 00:00:12,269
Ahmed said I'm my name is Christy Rashi

3
00:00:12,269 --> 00:00:14,280
and I'm at the Arizona State University

4
00:00:14,280 --> 00:00:16,289
journalism school where I teach and I

5
00:00:16,289 --> 00:00:18,300
research media literacy and I'm gonna

6
00:00:18,300 --> 00:00:21,060
talk to you today about why we should be

7
00:00:21,060 --> 00:00:22,740
embedding digital media literacy into

8
00:00:22,740 --> 00:00:24,510
science education and I'm really

9
00:00:24,510 --> 00:00:27,510
grateful for the previous presentation

10
00:00:27,510 --> 00:00:29,220
because it cued up a lot of the things

11
00:00:29,220 --> 00:00:30,990
that I'm going to say so just remember

12
00:00:30,990 --> 00:00:35,130
all of that and then we'll carry on so

13
00:00:35,130 --> 00:00:37,559
starting with some good news

14
00:00:37,559 --> 00:00:39,450
recent research would indicate that

15
00:00:39,450 --> 00:00:42,329
trust and scientists is up so relative

16
00:00:42,329 --> 00:00:44,190
to other types of professionals and

17
00:00:44,190 --> 00:00:46,289
other institutions Americans generally

18
00:00:46,289 --> 00:00:48,120
think that scientists act in the public

19
00:00:48,120 --> 00:00:50,879
interest but that's kind of that story

20
00:00:50,879 --> 00:00:53,340
of like I trust my local scientist but

21
00:00:53,340 --> 00:00:54,989
maybe my trust in science as an

22
00:00:54,989 --> 00:00:57,449
institution isn't quite as strong so

23
00:00:57,449 --> 00:01:00,390
we've seen a lot of instances where

24
00:01:00,390 --> 00:01:02,550
there's a growing distrust in certain

25
00:01:02,550 --> 00:01:04,260
areas of science and some of them have

26
00:01:04,260 --> 00:01:05,459
already been mentioned and will be

27
00:01:05,459 --> 00:01:07,500
mentioned later today so there's sort of

28
00:01:07,500 --> 00:01:09,510
this dichotomy between I trust

29
00:01:09,510 --> 00:01:11,400
scientists but I'm not so sure about

30
00:01:11,400 --> 00:01:14,760
some scientific topics and I think part

31
00:01:14,760 --> 00:01:16,439
of that reason is because there is just

32
00:01:16,439 --> 00:01:19,350
so much information out there people are

33
00:01:19,350 --> 00:01:20,909
very confused it's a stressful

34
00:01:20,909 --> 00:01:24,119
environment to be in so if you're like

35
00:01:24,119 --> 00:01:25,380
me and you've avoid your news

36
00:01:25,380 --> 00:01:28,320
notifications for days on end you open

37
00:01:28,320 --> 00:01:29,790
your phone in your lock screen looks a

38
00:01:29,790 --> 00:01:31,619
little bit like this and those green

39
00:01:31,619 --> 00:01:33,810
arrows for me indicate last weekend

40
00:01:33,810 --> 00:01:35,310
those are just those are our stories

41
00:01:35,310 --> 00:01:37,409
from just to news outlets about the

42
00:01:37,409 --> 00:01:40,350
corona virus over a span of a day so

43
00:01:40,350 --> 00:01:41,970
these are trusted news outlets with

44
00:01:41,970 --> 00:01:44,340
trusted stories but just the the amount

45
00:01:44,340 --> 00:01:46,140
of information is incredibly

46
00:01:46,140 --> 00:01:48,570
overwhelming before we even start

47
00:01:48,570 --> 00:01:50,100
talking about the proliferation of

48
00:01:50,100 --> 00:01:51,930
misinformation and disinformation and

49
00:01:51,930 --> 00:01:53,880
the really bad stuff that's out there so

50
00:01:53,880 --> 00:01:56,040
we really shouldn't be surprised that

51
00:01:56,040 --> 00:01:57,540
we're all very confused about where to

52
00:01:57,540 --> 00:01:59,340
go for information there's just so much

53
00:01:59,340 --> 00:02:02,579
out there and I've been very happy to

54
00:02:02,579 --> 00:02:05,340
see the platform's taking efforts with

55
00:02:05,340 --> 00:02:07,799
the coronavirus information and you know

56
00:02:07,799 --> 00:02:09,508
partnering with people like who and the

57
00:02:09,508 --> 00:02:11,610
CDC to say if you were going to search

58
00:02:11,610 --> 00:02:13,380
for coronavirus you're going to get this

59
00:02:13,380 --> 00:02:15,410
that says four trustworthy information

60
00:02:15,410 --> 00:02:18,030
go here to the CDC and you can see the

61
00:02:18,030 --> 00:02:19,740
latest but when I searched the

62
00:02:19,740 --> 00:02:21,930
coronavirus hashtag a couple of days ago

63
00:02:21,930 --> 00:02:23,910
I got that box which is very encouraging

64
00:02:23,910 --> 00:02:25,740
and then right underneath it is a

65
00:02:25,740 --> 00:02:28,080
conspiracy theory about how corona virus

66
00:02:28,080 --> 00:02:30,660
was originated in a lab so this

67
00:02:30,660 --> 00:02:32,610
juxtaposition of credible information

68
00:02:32,610 --> 00:02:35,610
and not credible information happens to

69
00:02:35,610 --> 00:02:38,310
us all the time and we I think we all

70
00:02:38,310 --> 00:02:40,350
generally understand that our emotions

71
00:02:40,350 --> 00:02:42,540
often get the better of us and yeah I

72
00:02:42,540 --> 00:02:44,580
could go check out the CDC but I could

73
00:02:44,580 --> 00:02:46,530
also check out this conspiracy theory so

74
00:02:46,530 --> 00:02:48,840
maybe I'm gonna go and do that so

75
00:02:48,840 --> 00:02:50,850
despite best efforts we're we're gonna

76
00:02:50,850 --> 00:02:52,980
live in a digital world where hoaxes and

77
00:02:52,980 --> 00:02:55,110
conspiracy theories propaganda are going

78
00:02:55,110 --> 00:02:59,520
to proliferate even though people are

79
00:02:59,520 --> 00:03:00,510
saying that they're searching for

80
00:03:00,510 --> 00:03:02,430
reliable sources so again there's a

81
00:03:02,430 --> 00:03:04,320
there's a dichotomy here between what

82
00:03:04,320 --> 00:03:06,240
people say that they want which is

83
00:03:06,240 --> 00:03:08,370
credible trustworthy information and a

84
00:03:08,370 --> 00:03:09,930
lot of the information that they click

85
00:03:09,930 --> 00:03:12,720
on so people are seeking out reliable

86
00:03:12,720 --> 00:03:15,420
sources and this is a global survey that

87
00:03:15,420 --> 00:03:18,210
Edelman does each year on trust and 73

88
00:03:18,210 --> 00:03:19,500
percent of people are worried about

89
00:03:19,500 --> 00:03:22,350
false information but behaviors are

90
00:03:22,350 --> 00:03:24,030
different from worried about

91
00:03:24,030 --> 00:03:26,070
misinformation and so people are still

92
00:03:26,070 --> 00:03:28,230
gravitating to and tend to gravitate to

93
00:03:28,230 --> 00:03:31,020
miss and disinformation or overhyped

94
00:03:31,020 --> 00:03:34,470
information and when we're talking about

95
00:03:34,470 --> 00:03:36,660
health and science in particular this is

96
00:03:36,660 --> 00:03:38,820
not only you know unfortunate and

97
00:03:38,820 --> 00:03:40,380
dangerous it can have real ramifications

98
00:03:40,380 --> 00:03:43,230
on people's health so when we talk about

99
00:03:43,230 --> 00:03:45,390
reliable sources and you see surveys

100
00:03:45,390 --> 00:03:47,160
like that what is a reliable source to

101
00:03:47,160 --> 00:03:49,290
people we assign credibility in

102
00:03:49,290 --> 00:03:50,910
different ways

103
00:03:50,910 --> 00:03:52,890
and we attach it to different types of

104
00:03:52,890 --> 00:03:54,600
people and a lot of people gravitate

105
00:03:54,600 --> 00:03:56,370
towards people with similar interests or

106
00:03:56,370 --> 00:03:58,110
shared views we talked in the last

107
00:03:58,110 --> 00:04:00,270
presentation about pre-existing beliefs

108
00:04:00,270 --> 00:04:02,670
so when you come into a say a Facebook

109
00:04:02,670 --> 00:04:04,770
group with people that you believe that

110
00:04:04,770 --> 00:04:07,500
you can trust and you get bad not

111
00:04:07,500 --> 00:04:09,120
professional information it can have

112
00:04:09,120 --> 00:04:11,370
severe consequences very unfortunate

113
00:04:11,370 --> 00:04:15,120
consequences and a thing that concerns

114
00:04:15,120 --> 00:04:17,700
me is as we move away from or we move

115
00:04:17,700 --> 00:04:19,230
closer to getting more information from

116
00:04:19,230 --> 00:04:20,970
things like smart speakers and we're

117
00:04:20,970 --> 00:04:22,830
moving away from provenance and

118
00:04:22,830 --> 00:04:24,720
attribution as part of our you know

119
00:04:24,720 --> 00:04:26,830
information

120
00:04:26,830 --> 00:04:29,560
and in random people can provide Alexa

121
00:04:29,560 --> 00:04:32,800
answers to information it just creates

122
00:04:32,800 --> 00:04:34,449
the situation where we're less attached

123
00:04:34,449 --> 00:04:36,520
to where the source of information comes

124
00:04:36,520 --> 00:04:38,500
from and it creates more confusion and

125
00:04:38,500 --> 00:04:40,930
more problems so you know it's

126
00:04:40,930 --> 00:04:42,240
complicated

127
00:04:42,240 --> 00:04:45,129
so media literacy is generally

128
00:04:45,129 --> 00:04:46,629
understood to be the ways in which

129
00:04:46,629 --> 00:04:49,509
people access analyze and interact with

130
00:04:49,509 --> 00:04:52,030
media and this is a definition that I

131
00:04:52,030 --> 00:04:53,800
use and I really like for digital media

132
00:04:53,800 --> 00:04:55,990
literacy which defines it as a set of

133
00:04:55,990 --> 00:04:58,719
social practices so it's not a skill set

134
00:04:58,719 --> 00:05:00,280
that you learn when you're 5 or you're

135
00:05:00,280 --> 00:05:02,919
12 or you're 25 it's an ongoing process

136
00:05:02,919 --> 00:05:04,659
throughout lifetime and it's based on

137
00:05:04,659 --> 00:05:06,340
social circumstance it's based on

138
00:05:06,340 --> 00:05:08,590
personal context it's based on education

139
00:05:08,590 --> 00:05:10,930
and experience and media literacy is

140
00:05:10,930 --> 00:05:13,020
about so much more than just verifying

141
00:05:13,020 --> 00:05:15,250
information certainly that's a big part

142
00:05:15,250 --> 00:05:16,960
of it and certainly today that's the

143
00:05:16,960 --> 00:05:18,699
part that gets talked about most often

144
00:05:18,699 --> 00:05:20,349
but when we talk about media literacy

145
00:05:20,349 --> 00:05:21,940
we're really talking about how we engage

146
00:05:21,940 --> 00:05:24,099
with the information in our environment

147
00:05:24,099 --> 00:05:26,219
and we can characterize that by

148
00:05:26,219 --> 00:05:28,060
collaboration and openness and

149
00:05:28,060 --> 00:05:30,129
interactivity around these conversations

150
00:05:30,129 --> 00:05:32,440
in a way that it can feel when we're

151
00:05:32,440 --> 00:05:33,940
just looking at social media like that's

152
00:05:33,940 --> 00:05:36,699
not happening and what I like to present

153
00:05:36,699 --> 00:05:38,529
today is there's an opportunity in

154
00:05:38,529 --> 00:05:40,629
subject mayor subject areas that aren't

155
00:05:40,629 --> 00:05:42,940
related to media like science and health

156
00:05:42,940 --> 00:05:45,789
to bridge subject matter and the related

157
00:05:45,789 --> 00:05:48,039
media environment around it so I think

158
00:05:48,039 --> 00:05:50,979
we all typically understand say science

159
00:05:50,979 --> 00:05:52,599
classes to be where we go and learn

160
00:05:52,599 --> 00:05:55,029
scientific information from scientific

161
00:05:55,029 --> 00:05:56,979
sources from science subject matter

162
00:05:56,979 --> 00:05:59,500
experts and traditional popular media is

163
00:05:59,500 --> 00:06:02,199
typically not it doesn't enter into that

164
00:06:02,199 --> 00:06:03,969
equation and whether it's not seen as

165
00:06:03,969 --> 00:06:05,860
trustworthy or credible or it's just not

166
00:06:05,860 --> 00:06:07,810
part of the conversation I think that

167
00:06:07,810 --> 00:06:09,460
that's very unfortunate because it

168
00:06:09,460 --> 00:06:11,740
discounts the ways in which we're all

169
00:06:11,740 --> 00:06:13,930
interacting with information even those

170
00:06:13,930 --> 00:06:15,699
of us who are subject matter experts are

171
00:06:15,699 --> 00:06:17,469
still googling things all the time I

172
00:06:17,469 --> 00:06:19,000
mean that we're not talking about that

173
00:06:19,000 --> 00:06:21,190
in classrooms I think is is a big missed

174
00:06:21,190 --> 00:06:25,000
opportunity recent research would

175
00:06:25,000 --> 00:06:26,830
indicate that young people do use news

176
00:06:26,830 --> 00:06:28,389
and I think that this is relevant

177
00:06:28,389 --> 00:06:30,279
information for people that interact

178
00:06:30,279 --> 00:06:32,020
with young people of all ages but in

179
00:06:32,020 --> 00:06:33,099
this presentation I'm kind of

180
00:06:33,099 --> 00:06:34,949
specifically thinking of undergraduates

181
00:06:34,949 --> 00:06:38,589
but more than 75% of us teens follow

182
00:06:38,589 --> 00:06:40,719
events and a project information

183
00:06:40,719 --> 00:06:42,549
literacy study that I found especially

184
00:06:42,549 --> 00:06:44,409
interesting shows that most college

185
00:06:44,409 --> 00:06:45,819
students are interacting and talking

186
00:06:45,819 --> 00:06:48,579
about news on a weekly basis and most of

187
00:06:48,579 --> 00:06:50,319
that happens on digital and social

188
00:06:50,319 --> 00:06:52,449
platforms but it also happens among

189
00:06:52,449 --> 00:06:54,149
peers and it does happen in classrooms

190
00:06:54,149 --> 00:06:58,119
this survey found that social sciences

191
00:06:58,119 --> 00:07:00,159
English classrooms history clubs neurs

192
00:07:00,159 --> 00:07:01,569
are more inclined to bring current

193
00:07:01,569 --> 00:07:03,309
events into the classroom then then

194
00:07:03,309 --> 00:07:05,409
stems STEM subjects though which again I

195
00:07:05,409 --> 00:07:07,989
think is a missed opportunity because

196
00:07:07,989 --> 00:07:09,299
professors can model and demonstrate

197
00:07:09,299 --> 00:07:12,309
engagement with traditional media in a

198
00:07:12,309 --> 00:07:14,499
way that can be useful for students and

199
00:07:14,499 --> 00:07:16,719
just a little bit more from that project

200
00:07:16,719 --> 00:07:20,469
information literacy study it's again

201
00:07:20,469 --> 00:07:22,709
there's there's these dueling ideas that

202
00:07:22,709 --> 00:07:24,759
information and the amount of it can be

203
00:07:24,759 --> 00:07:27,309
very overwhelming but our ability to use

204
00:07:27,309 --> 00:07:29,649
it via digital and social and to make it

205
00:07:29,649 --> 00:07:31,299
a social practice can also be very

206
00:07:31,299 --> 00:07:34,359
empowering and I like to work with my

207
00:07:34,359 --> 00:07:35,739
students on sort of this empowerment

208
00:07:35,739 --> 00:07:37,569
side of this how do we harness in this

209
00:07:37,569 --> 00:07:40,029
information for conversation and to

210
00:07:40,029 --> 00:07:43,360
learn more and to sort of not back from

211
00:07:43,360 --> 00:07:45,099
a deficit model and not talk about the

212
00:07:45,099 --> 00:07:47,349
fear and the confusion but rather to

213
00:07:47,349 --> 00:07:50,879
talk about how we can make it better I

214
00:07:50,879 --> 00:07:53,379
teach a class on digital media literacy

215
00:07:53,379 --> 00:07:55,089
in every semester I asked my students to

216
00:07:55,089 --> 00:07:57,639
track their media use for 24 hours and I

217
00:07:57,639 --> 00:08:00,129
am astounded every time by their answers

218
00:08:00,129 --> 00:08:02,199
and I've been doing this for about 6 or

219
00:08:02,199 --> 00:08:03,969
7 years and the answers have changed

220
00:08:03,969 --> 00:08:06,549
dramatically over 6 or 7 years and so

221
00:08:06,549 --> 00:08:08,349
here's just a few of the icons of the

222
00:08:08,349 --> 00:08:10,929
most common responses YouTube these days

223
00:08:10,929 --> 00:08:12,819
is far and away that place that they're

224
00:08:12,819 --> 00:08:15,039
at most not only for entertainment

225
00:08:15,039 --> 00:08:17,649
purposes but for news purposes um you'll

226
00:08:17,649 --> 00:08:19,959
see news aggregators social platforms

227
00:08:19,959 --> 00:08:21,609
and then some traditional media outlets

228
00:08:21,609 --> 00:08:23,679
there there's also anecdotally an

229
00:08:23,679 --> 00:08:24,879
increase in students who are listening

230
00:08:24,879 --> 00:08:28,149
to podcasts so this is super interesting

231
00:08:28,149 --> 00:08:29,829
to me because I don't use a lot of these

232
00:08:29,829 --> 00:08:31,779
platforms myself and I'm a media

233
00:08:31,779 --> 00:08:33,399
instructor so I use this as an

234
00:08:33,399 --> 00:08:35,019
opportunity to ask my students more

235
00:08:35,019 --> 00:08:37,299
questions so you go to YouTube for news

236
00:08:37,299 --> 00:08:38,860
what does that mean and who's giving you

237
00:08:38,860 --> 00:08:40,958
this news on YouTube who are these

238
00:08:40,958 --> 00:08:42,129
people that are providing this

239
00:08:42,129 --> 00:08:43,990
information and chances are in a lot of

240
00:08:43,990 --> 00:08:46,029
cases they're providing other people's

241
00:08:46,029 --> 00:08:47,949
information so it's an opportunity to

242
00:08:47,949 --> 00:08:51,360
you know do an exercise in enforcing

243
00:08:51,360 --> 00:08:53,610
when the YouTube personality is talking

244
00:08:53,610 --> 00:08:55,260
about a big story that hit where did

245
00:08:55,260 --> 00:08:57,510
that person get their information so all

246
00:08:57,510 --> 00:08:59,459
kinds of conversations can abound on

247
00:08:59,459 --> 00:09:01,740
subjects related to science and health

248
00:09:01,740 --> 00:09:03,450
when you start to ask students about

249
00:09:03,450 --> 00:09:04,920
where they're finding their information

250
00:09:04,920 --> 00:09:07,290
and I'd also like to point out that if

251
00:09:07,290 --> 00:09:08,910
we're operating in this world where I'm

252
00:09:08,910 --> 00:09:10,470
assuming you're getting information from

253
00:09:10,470 --> 00:09:12,089
someplace and you're actually getting it

254
00:09:12,089 --> 00:09:13,620
from someplace else we're not having the

255
00:09:13,620 --> 00:09:15,810
same conversation I mean until we can

256
00:09:15,810 --> 00:09:19,709
kind of address these gaps excuse me you

257
00:09:19,709 --> 00:09:20,940
know we can't really get to the root of

258
00:09:20,940 --> 00:09:24,750
the problem so again a lot of attention

259
00:09:24,750 --> 00:09:26,220
these days around media literacy is

260
00:09:26,220 --> 00:09:28,140
around verification and whether or not

261
00:09:28,140 --> 00:09:29,910
we can determine a source is credible or

262
00:09:29,910 --> 00:09:31,800
if it's it's fake news all of those

263
00:09:31,800 --> 00:09:33,720
words that we see in the media lie and

264
00:09:33,720 --> 00:09:35,519
I'm certainly not here to say that

265
00:09:35,519 --> 00:09:36,990
that's not important because absolutely

266
00:09:36,990 --> 00:09:38,730
it is it's part and parcel of media

267
00:09:38,730 --> 00:09:40,950
literacy but I'd also like to point out

268
00:09:40,950 --> 00:09:42,810
that it's a practice again I said that

269
00:09:42,810 --> 00:09:45,720
that that begets participation and

270
00:09:45,720 --> 00:09:47,910
collaboration and evaluation in a way

271
00:09:47,910 --> 00:09:50,010
that doesn't just have to be is this

272
00:09:50,010 --> 00:09:52,769
picture true or false and firt and for

273
00:09:52,769 --> 00:09:55,110
teachers professors parents who have

274
00:09:55,110 --> 00:09:56,579
different subject matter expertise

275
00:09:56,579 --> 00:09:58,649
sometimes there's a reluctance to teach

276
00:09:58,649 --> 00:10:00,690
about media if you're not an expert in

277
00:10:00,690 --> 00:10:02,310
media but you're an expert in your

278
00:10:02,310 --> 00:10:04,620
subject matter and there's media about

279
00:10:04,620 --> 00:10:06,690
pretty much every scientific topic so

280
00:10:06,690 --> 00:10:08,430
when you broach it from your subject

281
00:10:08,430 --> 00:10:10,470
area and you bring popular media into

282
00:10:10,470 --> 00:10:12,240
the classroom you're not only making it

283
00:10:12,240 --> 00:10:13,740
more accessible to the students but

284
00:10:13,740 --> 00:10:15,269
you're acknowledging and you're

285
00:10:15,269 --> 00:10:17,370
respecting that traditional and new

286
00:10:17,370 --> 00:10:19,079
sources and information sources are

287
00:10:19,079 --> 00:10:20,339
really where we're getting a lot of our

288
00:10:20,339 --> 00:10:22,410
information and though we would love our

289
00:10:22,410 --> 00:10:24,360
students to only access our library

290
00:10:24,360 --> 00:10:26,339
databases and read peer-reviewed

291
00:10:26,339 --> 00:10:28,290
scholarly journals and and surely we

292
00:10:28,290 --> 00:10:30,449
will assign those and continue to expect

293
00:10:30,449 --> 00:10:32,040
our students to read those and talk

294
00:10:32,040 --> 00:10:34,110
about them in class that doesn't

295
00:10:34,110 --> 00:10:35,850
discount the popular media and the

296
00:10:35,850 --> 00:10:37,410
experience that they're experiencing

297
00:10:37,410 --> 00:10:39,570
you're outside your classroom and it

298
00:10:39,570 --> 00:10:41,130
also doesn't change the fact that when

299
00:10:41,130 --> 00:10:42,420
you give them an assignment they're

300
00:10:42,420 --> 00:10:44,940
going to Google at first 100% that's

301
00:10:44,940 --> 00:10:46,589
what they're going to do so how do you

302
00:10:46,589 --> 00:10:49,260
help them find information in a Google

303
00:10:49,260 --> 00:10:51,300
search or a Wikipedia search that can

304
00:10:51,300 --> 00:10:52,829
lead you to the things that maybe you're

305
00:10:52,829 --> 00:10:54,660
as an as an instructor more comfortable

306
00:10:54,660 --> 00:10:57,269
with and this should be happening in all

307
00:10:57,269 --> 00:10:58,769
classrooms it's not just science and

308
00:10:58,769 --> 00:11:01,470
health or or media or you know history

309
00:11:01,470 --> 00:11:02,220
this

310
00:11:02,220 --> 00:11:04,230
can be a conversation that any professor

311
00:11:04,230 --> 00:11:06,480
any teacher has with people at anytime

312
00:11:06,480 --> 00:11:09,600
and I think it really values the young

313
00:11:09,600 --> 00:11:12,420
people's media experience values their

314
00:11:12,420 --> 00:11:13,860
experience when you ask them about their

315
00:11:13,860 --> 00:11:16,560
media use so I think it's an important

316
00:11:16,560 --> 00:11:18,510
thing to be doing across the board it's

317
00:11:18,510 --> 00:11:21,000
not just a singular subject area that

318
00:11:21,000 --> 00:11:24,360
should be relegated to its own class and

319
00:11:24,360 --> 00:11:25,950
then the last kind of point I want to

320
00:11:25,950 --> 00:11:27,540
make is that and this was said in the

321
00:11:27,540 --> 00:11:29,150
previous presentation a little bit too

322
00:11:29,150 --> 00:11:31,110
subject matter knowledge doesn't

323
00:11:31,110 --> 00:11:33,150
necessarily increase trust in science

324
00:11:33,150 --> 00:11:35,580
and it definitely doesn't equate the

325
00:11:35,580 --> 00:11:37,680
ability to find and use credible sources

326
00:11:37,680 --> 00:11:40,410
about a topic if you've taken a bio 101

327
00:11:40,410 --> 00:11:43,260
class like I did in college I may have

328
00:11:43,260 --> 00:11:44,880
learned about biology but I definitely

329
00:11:44,880 --> 00:11:47,070
didn't learn about what trusted sources

330
00:11:47,070 --> 00:11:50,640
for biology subjects are that was not

331
00:11:50,640 --> 00:11:52,980
what this class was about and I think a

332
00:11:52,980 --> 00:11:54,570
conversation about what are those

333
00:11:54,570 --> 00:11:56,580
trusted institutions for information

334
00:11:56,580 --> 00:11:58,830
should come from science instructors

335
00:11:58,830 --> 00:12:00,690
there was a lot of talk already today

336
00:12:00,690 --> 00:12:02,610
about consensus reports which i think is

337
00:12:02,610 --> 00:12:06,030
fantastic but who in you know who what

338
00:12:06,030 --> 00:12:07,770
lay audience understands what consensus

339
00:12:07,770 --> 00:12:10,350
reports really do in which consensus

340
00:12:10,350 --> 00:12:11,850
report is trustworthy and which one is

341
00:12:11,850 --> 00:12:13,860
sponsored by a think tank that has

342
00:12:13,860 --> 00:12:15,510
alternative dejenne des these

343
00:12:15,510 --> 00:12:17,190
conversations I don't think come up

344
00:12:17,190 --> 00:12:18,810
enough in science classes when we're

345
00:12:18,810 --> 00:12:20,850
talking about bias and funding and all

346
00:12:20,850 --> 00:12:22,950
those things that you know can be good

347
00:12:22,950 --> 00:12:25,110
and bad about scientific discovery as

348
00:12:25,110 --> 00:12:27,030
we're talking about the way that we

349
00:12:27,030 --> 00:12:29,460
create knowledge we should also talk

350
00:12:29,460 --> 00:12:31,380
about the way that we create information

351
00:12:31,380 --> 00:12:32,810
those things are like in extract

352
00:12:32,810 --> 00:12:35,400
inextricable from one another and so I

353
00:12:35,400 --> 00:12:37,290
would implore everyone in the position

354
00:12:37,290 --> 00:12:39,120
to sort of interrogate some of these

355
00:12:39,120 --> 00:12:41,520
questions in the classroom do typical

356
00:12:41,520 --> 00:12:43,800
people know how to find good consensus

357
00:12:43,800 --> 00:12:45,570
documents on things and understand what

358
00:12:45,570 --> 00:12:47,340
that means do they have access to

359
00:12:47,340 --> 00:12:49,590
quality information and if not how can

360
00:12:49,590 --> 00:12:52,560
you help them gain access and then how

361
00:12:52,560 --> 00:12:55,290
do we evaluate scholarly research on a

362
00:12:55,290 --> 00:12:57,300
single study level on a consensus level

363
00:12:57,300 --> 00:12:59,790
on a trend level and importantly how do

364
00:12:59,790 --> 00:13:02,310
we then also examine the press coverage

365
00:13:02,310 --> 00:13:04,620
related to those scholarly journal

366
00:13:04,620 --> 00:13:06,360
articles and research because sometimes

367
00:13:06,360 --> 00:13:08,670
there's problems there these are things

368
00:13:08,670 --> 00:13:10,320
that can happen across a course and you

369
00:13:10,320 --> 00:13:11,940
don't really have to put too much effort

370
00:13:11,940 --> 00:13:13,670
into him I think and I think they would

371
00:13:13,670 --> 00:13:15,600
engender a lot of really inch

372
00:13:15,600 --> 00:13:19,079
in conversation and help people have you

373
00:13:19,079 --> 00:13:21,029
know just fine-tune theirs their their

374
00:13:21,029 --> 00:13:22,589
knowledge about the information that

375
00:13:22,589 --> 00:13:25,050
consume and something I do I wouldn't

376
00:13:25,050 --> 00:13:26,639
expect you to be able to read these but

377
00:13:26,639 --> 00:13:27,720
in my classroom we do a lot of

378
00:13:27,720 --> 00:13:30,089
discussion around this and I have found

379
00:13:30,089 --> 00:13:31,709
both in my classroom and little

380
00:13:31,709 --> 00:13:33,149
experience and in my research that the

381
00:13:33,149 --> 00:13:34,529
more people are talking about these

382
00:13:34,529 --> 00:13:37,079
issues obviously the better their

383
00:13:37,079 --> 00:13:38,519
understanding I think it kind of feels

384
00:13:38,519 --> 00:13:40,589
like common sense but it is a practice

385
00:13:40,589 --> 00:13:42,120
and we must practice it to have a better

386
00:13:42,120 --> 00:13:44,009
understanding and these are just

387
00:13:44,009 --> 00:13:45,690
examples of students talking to each

388
00:13:45,690 --> 00:13:47,459
other that you they don't have to talk

389
00:13:47,459 --> 00:13:48,899
to you they can make sense of these

390
00:13:48,899 --> 00:13:50,370
things through conversation with each

391
00:13:50,370 --> 00:13:50,819
other

392
00:13:50,819 --> 00:13:53,100
scaffolded by you know a conversation in

393
00:13:53,100 --> 00:13:56,519
the classroom so we have lots of tools

394
00:13:56,519 --> 00:13:58,920
and tips that on how to help students

395
00:13:58,920 --> 00:14:00,300
with credibility and find good sources

396
00:14:00,300 --> 00:14:02,130
on our website if that's of interest to

397
00:14:02,130 --> 00:14:04,110
you and you can follow us and me on

398
00:14:04,110 --> 00:14:06,029
Twitter and happy to have you reach out

399
00:14:06,029 --> 00:14:09,710
if you'd like more information thank you

400
00:14:09,710 --> 00:14:15,539
[Applause]

