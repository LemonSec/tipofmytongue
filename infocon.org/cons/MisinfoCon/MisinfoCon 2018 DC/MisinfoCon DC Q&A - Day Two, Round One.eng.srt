1
00:00:00,000 --> 00:00:03,210
all right questions for the first round

2
00:00:03,210 --> 00:00:05,970
of lightning presenters questions any

3
00:00:05,970 --> 00:00:08,700
questions from the audience back there

4
00:00:08,700 --> 00:00:16,410
yep John samples McKay doe Institute I'm

5
00:00:16,410 --> 00:00:18,090
reluctant to ask this question because

6
00:00:18,090 --> 00:00:19,859
it's going to sound pessimistic and I

7
00:00:19,859 --> 00:00:21,930
don't want to so I'll just put the facts

8
00:00:21,930 --> 00:00:23,550
out there it's it's a question that

9
00:00:23,550 --> 00:00:25,439
applies to a lot of that I've heard at

10
00:00:25,439 --> 00:00:28,439
this conference I'm by background a

11
00:00:28,439 --> 00:00:30,449
political scientist and the oldest and

12
00:00:30,449 --> 00:00:32,189
in some ways the firm is finding of

13
00:00:32,189 --> 00:00:34,920
political science is that voters in

14
00:00:34,920 --> 00:00:37,440
general don't know much and that's like

15
00:00:37,440 --> 00:00:40,260
a 60-year finding the problem always is

16
00:00:40,260 --> 00:00:42,960
in rooms like this people know a lot

17
00:00:42,960 --> 00:00:45,719
about politics but voters don't know I

18
00:00:45,719 --> 00:00:47,520
mean voters don't know much voters don't

19
00:00:47,520 --> 00:00:49,320
know much about politics they may well

20
00:00:49,320 --> 00:00:51,930
know a lot about cars and things like

21
00:00:51,930 --> 00:00:55,079
that or consumer goods and the reason

22
00:00:55,079 --> 00:00:58,010
advanced for that over time is that

23
00:00:58,010 --> 00:01:00,930
rational ignorance is actually the

24
00:01:00,930 --> 00:01:03,840
unnatural equilibrium right if people

25
00:01:03,840 --> 00:01:06,060
vote they don't have a great deal at

26
00:01:06,060 --> 00:01:08,490
stake so there's not it's very unlikely

27
00:01:08,490 --> 00:01:10,890
that a single vote will change an

28
00:01:10,890 --> 00:01:12,270
election which would have an enormous

29
00:01:12,270 --> 00:01:15,840
effect so the incentives for finding

30
00:01:15,840 --> 00:01:17,640
information for thinking critically

31
00:01:17,640 --> 00:01:21,240
about information and for knowing a lot

32
00:01:21,240 --> 00:01:23,369
about politics or what actually quite

33
00:01:23,369 --> 00:01:26,400
poor and that theory is actually an

34
00:01:26,400 --> 00:01:28,680
explanation of what we observe and have

35
00:01:28,680 --> 00:01:30,990
observed I should add for 60 years in

36
00:01:30,990 --> 00:01:35,009
surveys so given all of that and not

37
00:01:35,009 --> 00:01:36,630
wanting to be pessimistic I guess I

38
00:01:36,630 --> 00:01:40,320
would just say given that fact how do

39
00:01:40,320 --> 00:01:44,579
you how can we expect to deal with these

40
00:01:44,579 --> 00:01:46,409
this problem of incentives because I

41
00:01:46,409 --> 00:01:48,180
think maybe it doesn't apply to what

42
00:01:48,180 --> 00:01:49,259
you're talking about

43
00:01:49,259 --> 00:01:53,509
but it does to me seem to apply

44
00:02:01,100 --> 00:02:03,590
hello oh there it is sorry so I actually

45
00:02:03,590 --> 00:02:05,840
think this is a great question because I

46
00:02:05,840 --> 00:02:09,679
think that what the purveyors of

47
00:02:09,679 --> 00:02:11,510
misinformation have done really well is

48
00:02:11,510 --> 00:02:13,459
they go into exactly that place that

49
00:02:13,459 --> 00:02:15,620
you're talking about which is people are

50
00:02:15,620 --> 00:02:18,110
disinterested which is why the these

51
00:02:18,110 --> 00:02:23,239
memes and these online digital content

52
00:02:23,239 --> 00:02:24,920
spreads the way it does I was talking to

53
00:02:24,920 --> 00:02:26,930
a gentleman before this conversation or

54
00:02:26,930 --> 00:02:28,099
before I came up here and I was saying

55
00:02:28,099 --> 00:02:30,260
they're just better at this stuff then

56
00:02:30,260 --> 00:02:33,170
then the fact people are they really

57
00:02:33,170 --> 00:02:34,819
know how to go into sort of personal

58
00:02:34,819 --> 00:02:38,690
biases and split people off who are like

59
00:02:38,690 --> 00:02:40,310
I kind of believe part of this and I

60
00:02:40,310 --> 00:02:44,269
think the solution to me is less

61
00:02:44,269 --> 00:02:46,610
regulation and less finger-wagging and

62
00:02:46,610 --> 00:02:49,489
more we need to get better at reaching

63
00:02:49,489 --> 00:02:51,620
people where they live with this type of

64
00:02:51,620 --> 00:02:53,390
information in the ways that they

65
00:02:53,390 --> 00:02:57,230
consume it because it's not it's

66
00:02:57,230 --> 00:02:59,569
interesting a lot of people view this

67
00:02:59,569 --> 00:03:03,260
these narratives from fake news

68
00:03:03,260 --> 00:03:06,470
purveyors as negative it's actually

69
00:03:06,470 --> 00:03:08,120
positive there they're there their

70
00:03:08,120 --> 00:03:09,980
storytelling ability their narratives

71
00:03:09,980 --> 00:03:12,500
are our affirmation 'el to their

72
00:03:12,500 --> 00:03:15,109
audience and we if we're going to like

73
00:03:15,109 --> 00:03:18,500
combat this need an affirmation 'el you

74
00:03:18,500 --> 00:03:22,910
know value at for people to consume the

75
00:03:22,910 --> 00:03:25,310
truth so to speak so it's less finger

76
00:03:25,310 --> 00:03:28,010
wagging and more reaching people where

77
00:03:28,010 --> 00:03:30,260
they live in a way that they actually

78
00:03:30,260 --> 00:03:35,000
care about which I would argue we're

79
00:03:35,000 --> 00:03:39,739
awful at I'll just say a few things

80
00:03:39,739 --> 00:03:41,900
outside of politics so I'll sort of put

81
00:03:41,900 --> 00:03:44,180
that aside and just say that in our

82
00:03:44,180 --> 00:03:46,700
class in my class we sort of treat

83
00:03:46,700 --> 00:03:49,340
misinformation disinformation much more

84
00:03:49,340 --> 00:03:51,200
broadly than politics in fact we you

85
00:03:51,200 --> 00:03:53,150
know we try to avoid those kind of

86
00:03:53,150 --> 00:03:54,829
conversations that we can't fully avoid

87
00:03:54,829 --> 00:03:56,389
them but they're just such low-hanging

88
00:03:56,389 --> 00:03:58,459
fruit and students are pretty good at

89
00:03:58,459 --> 00:04:01,190
least the test that we have we people do

90
00:04:01,190 --> 00:04:03,139
care about their health though and they

91
00:04:03,139 --> 00:04:06,139
do care about making decisions that

92
00:04:06,139 --> 00:04:08,420
might improve their quality of living or

93
00:04:08,420 --> 00:04:09,799
their family and there's a lot of

94
00:04:09,799 --> 00:04:11,599
disinformation out there and my sort of

95
00:04:11,599 --> 00:04:13,050
concern like I mentioned in my talk

96
00:04:13,050 --> 00:04:15,690
around the the misinformation a rap

97
00:04:15,690 --> 00:04:19,230
about and in science and and that I do

98
00:04:19,230 --> 00:04:21,810
think we need people to be able to to

99
00:04:21,810 --> 00:04:23,720
reason a little bit more and at least

100
00:04:23,720 --> 00:04:26,730
sort of have a set of skills to make

101
00:04:26,730 --> 00:04:28,290
sort of decisions so when I when I think

102
00:04:28,290 --> 00:04:30,480
about you know this missing folk on or

103
00:04:30,480 --> 00:04:33,390
just misinformation field emerging you

104
00:04:33,390 --> 00:04:34,980
know III think of it much broader than

105
00:04:34,980 --> 00:04:36,630
politics but your point is an

106
00:04:36,630 --> 00:04:39,420
interesting point maybe I'd love to talk

107
00:04:39,420 --> 00:04:48,330
more offline about that okay I guess III

108
00:04:48,330 --> 00:04:50,310
also feel that

109
00:04:50,310 --> 00:04:52,710
mmm sometimes ambivalence I suppose

110
00:04:52,710 --> 00:04:54,510
about where we are situationally right

111
00:04:54,510 --> 00:04:58,530
now in the sense that mmm an additional

112
00:04:58,530 --> 00:04:59,760
problem is really the abundance of

113
00:04:59,760 --> 00:05:01,530
information right so not only do you

114
00:05:01,530 --> 00:05:04,170
have the issue that people may be maybe

115
00:05:04,170 --> 00:05:05,970
in certain realms they don't seem like

116
00:05:05,970 --> 00:05:08,550
that they care but added to that is this

117
00:05:08,550 --> 00:05:10,470
challenge of the weight of it there's so

118
00:05:10,470 --> 00:05:12,510
much information so in terms of trying

119
00:05:12,510 --> 00:05:14,400
to sift it and trying to prioritize

120
00:05:14,400 --> 00:05:16,170
what's important versus other that's an

121
00:05:16,170 --> 00:05:17,520
additional challenge that people didn't

122
00:05:17,520 --> 00:05:21,330
have as much earlier but I I guess I

123
00:05:21,330 --> 00:05:23,040
have two additional thoughts one was

124
00:05:23,040 --> 00:05:26,400
that honestly as Jevon said to this the

125
00:05:26,400 --> 00:05:28,740
smaller the smaller realms these are

126
00:05:28,740 --> 00:05:30,660
also political realms these these issues

127
00:05:30,660 --> 00:05:33,300
about health and I have asked in than

128
00:05:33,300 --> 00:05:35,460
this recent time period to about my own

129
00:05:35,460 --> 00:05:38,250
personal relationships family and

130
00:05:38,250 --> 00:05:40,950
friends that that are actually on many

131
00:05:40,950 --> 00:05:42,600
sides of the spectrum and voted in

132
00:05:42,600 --> 00:05:44,010
different ways during this past election

133
00:05:44,010 --> 00:05:46,140
and thinking about like what does it

134
00:05:46,140 --> 00:05:47,760
mean to authentically engage with them

135
00:05:47,760 --> 00:05:50,310
people I care about about issues maybe

136
00:05:50,310 --> 00:05:52,560
not sort of P with a capital P but small

137
00:05:52,560 --> 00:05:55,080
P so maybe there are the that there is

138
00:05:55,080 --> 00:05:56,640
that opportunity there that we need to

139
00:05:56,640 --> 00:05:58,820
think about what is authentic in

140
00:05:58,820 --> 00:06:01,919
exchange mean with so much information

141
00:06:01,919 --> 00:06:05,040
and maybe one final thing I have a

142
00:06:05,040 --> 00:06:07,140
nine-year-old son and we were recently

143
00:06:07,140 --> 00:06:08,760
in England this past year and they

144
00:06:08,760 --> 00:06:11,130
actually have news education for very

145
00:06:11,130 --> 00:06:14,100
young people one once a week they have

146
00:06:14,100 --> 00:06:16,200
something called news round and so they

147
00:06:16,200 --> 00:06:18,630
look at with their whole class and these

148
00:06:18,630 --> 00:06:20,730
little excerpts from the news and they

149
00:06:20,730 --> 00:06:23,220
love it they love it and so that was

150
00:06:23,220 --> 00:06:25,020
actually also inspiring and hopeful that

151
00:06:25,020 --> 00:06:26,849
maybe maybe we've

152
00:06:26,849 --> 00:06:28,619
we don't have the conditions now but

153
00:06:28,619 --> 00:06:30,089
there could be these conditions to

154
00:06:30,089 --> 00:06:32,909
create curiosity and promote productive

155
00:06:32,909 --> 00:06:38,520
discussion one quick thought I think it

156
00:06:38,520 --> 00:06:41,389
was EB White who said something like

157
00:06:41,389 --> 00:06:44,009
democracy is the recurring suspicion

158
00:06:44,009 --> 00:06:46,379
that more than people are right more

159
00:06:46,379 --> 00:06:50,339
than half the time that that feels

160
00:06:50,339 --> 00:06:52,860
appropriate for what you are saying and

161
00:06:52,860 --> 00:06:55,259
the thing is that people do vote with

162
00:06:55,259 --> 00:06:57,869
more knowledge when they think they have

163
00:06:57,869 --> 00:07:01,979
a stake in the outcome it seems to me

164
00:07:01,979 --> 00:07:05,759
that people have recognized in somewhat

165
00:07:05,759 --> 00:07:08,629
larger numbers than I anticipated that

166
00:07:08,629 --> 00:07:13,259
voting does matter that 2016 was a shock

167
00:07:13,259 --> 00:07:17,969
to a whole lot of people who I'm forget

168
00:07:17,969 --> 00:07:19,800
the Jill Stein voters for but a whole

169
00:07:19,800 --> 00:07:21,769
lot of people just said ah screw it

170
00:07:21,769 --> 00:07:24,929
she's going to win doesn't matter that

171
00:07:24,929 --> 00:07:27,119
was a shock to the system and the result

172
00:07:27,119 --> 00:07:29,879
of that that profound changes that have

173
00:07:29,879 --> 00:07:32,939
been occurring in this country really

174
00:07:32,939 --> 00:07:35,839
major changes I'm going to go accelerate

175
00:07:35,839 --> 00:07:41,759
at the current status quo is something

176
00:07:41,759 --> 00:07:43,379
people have taken seriously so I think

177
00:07:43,379 --> 00:07:45,569
there's more interest now than there was

178
00:07:45,569 --> 00:07:47,999
and it may be that low information will

179
00:07:47,999 --> 00:07:50,309
always be a problem but the closer it

180
00:07:50,309 --> 00:07:55,019
gets to home the more information from

181
00:07:55,019 --> 00:07:58,110
my ancient studies in political science

182
00:07:58,110 --> 00:08:01,860
which was my major seems possible that

183
00:08:01,860 --> 00:08:05,429
there will be some you know willingness

184
00:08:05,429 --> 00:08:09,029
and needing of more information thank

185
00:08:09,029 --> 00:08:10,289
you that was a great question

186
00:08:10,289 --> 00:08:15,179
next next question thank you please

187
00:08:15,179 --> 00:08:17,399
state your name affiliation make it

188
00:08:17,399 --> 00:08:19,199
brief and make sure it's a question

189
00:08:19,199 --> 00:08:22,139
please thank you we'll do it right this

190
00:08:22,139 --> 00:08:24,119
is I'm Nick Adams from the goodly labs

191
00:08:24,119 --> 00:08:27,509
this question is especially for Jevon

192
00:08:27,509 --> 00:08:29,999
and Dan but anyone else in the panel

193
00:08:29,999 --> 00:08:33,179
sure and I'm really channeling Dana Boyd

194
00:08:33,179 --> 00:08:35,729
from the data in society and

195
00:08:35,729 --> 00:08:37,740
she has a concern that if we just teach

196
00:08:37,740 --> 00:08:39,269
people media literacy or news literacy

197
00:08:39,269 --> 00:08:42,419
that you're actually giving people the

198
00:08:42,419 --> 00:08:43,948
ammunition they needs it's a kind of

199
00:08:43,948 --> 00:08:46,260
weaponized doubt that they that everyone

200
00:08:46,260 --> 00:08:47,880
can learn to call on anything

201
00:08:47,880 --> 00:08:52,800
and that maybe we need some way to not

202
00:08:52,800 --> 00:08:55,079
just armed individuals with this doubt

203
00:08:55,079 --> 00:08:58,500
but to have a broader maybe consensual

204
00:08:58,500 --> 00:09:00,810
framework for people to understand media

205
00:09:00,810 --> 00:09:02,490
literacy maybe it's something like the

206
00:09:02,490 --> 00:09:04,199
public editor project but I'm just

207
00:09:04,199 --> 00:09:07,019
curious how would you respond to that

208
00:09:07,019 --> 00:09:08,579
since you're actually arming people with

209
00:09:08,579 --> 00:09:11,010
doubt in her framework yeah and actually

210
00:09:11,010 --> 00:09:13,110
I'm a huge fan of Dana

211
00:09:13,110 --> 00:09:14,699
Dana's work and she's always very

212
00:09:14,699 --> 00:09:16,410
provocative in her questioning and

213
00:09:16,410 --> 00:09:18,269
really at so and I'm familiar with that

214
00:09:18,269 --> 00:09:20,370
that writing I I still don't think it's

215
00:09:20,370 --> 00:09:22,649
a good reason not to arm people with

216
00:09:22,649 --> 00:09:24,750
critical reasoning and and and and

217
00:09:24,750 --> 00:09:27,060
skills for understanding their digital

218
00:09:27,060 --> 00:09:29,040
environments but but I get the point I

219
00:09:29,040 --> 00:09:32,180
mean I've recognized when I talk to

220
00:09:32,180 --> 00:09:34,589
middle schoolers there that's the level

221
00:09:34,589 --> 00:09:36,360
in which I start getting concerned about

222
00:09:36,360 --> 00:09:38,310
giving them too much doubt about the

223
00:09:38,310 --> 00:09:40,110
world they at that point they're just

224
00:09:40,110 --> 00:09:41,910
starting to learn it if you crumble

225
00:09:41,910 --> 00:09:44,279
everything about all the foundation

226
00:09:44,279 --> 00:09:46,079
under them about what might be true

227
00:09:46,079 --> 00:09:48,000
about the world that could be that could

228
00:09:48,000 --> 00:09:49,560
be you know we want to create a new

229
00:09:49,560 --> 00:09:50,970
generation of nihilist or something that

230
00:09:50,970 --> 00:09:54,060
just doesn't trust anything and so that

231
00:09:54,060 --> 00:09:56,160
that is a concise where I'm more

232
00:09:56,160 --> 00:09:57,990
concerned necessarily than arming people

233
00:09:57,990 --> 00:09:59,610
with the ability to then know how to

234
00:09:59,610 --> 00:10:01,019
manipulate the system that's going to

235
00:10:01,019 --> 00:10:01,980
happen no matter what

236
00:10:01,980 --> 00:10:04,290
so I still think we should be teaching

237
00:10:04,290 --> 00:10:05,910
critical reasoning but where I have

238
00:10:05,910 --> 00:10:08,970
pause is in having them question

239
00:10:08,970 --> 00:10:10,230
everything so I'll give you one last

240
00:10:10,230 --> 00:10:13,620
example my love affair with science may

241
00:10:13,620 --> 00:10:15,930
not come out when I'm always I tend to

242
00:10:15,930 --> 00:10:17,310
be critical of some of the problems

243
00:10:17,310 --> 00:10:19,019
whether it's reproducibility crisis P

244
00:10:19,019 --> 00:10:21,269
hacking you know all the outcomes

245
00:10:21,269 --> 00:10:22,319
switching all the kinds of things that

246
00:10:22,319 --> 00:10:23,579
we need to clean up inside because that

247
00:10:23,579 --> 00:10:26,209
is a true bastion we hope of somewhat

248
00:10:26,209 --> 00:10:29,550
truthiness and and when I criticize it I

249
00:10:29,550 --> 00:10:31,680
always start lectures with my love

250
00:10:31,680 --> 00:10:33,120
affair with science and that it still

251
00:10:33,120 --> 00:10:35,250
works for crying out loud

252
00:10:35,250 --> 00:10:37,889
and you still fly in you know 747s you

253
00:10:37,889 --> 00:10:39,209
still you know we say love these

254
00:10:39,209 --> 00:10:40,680
beautiful things called vaccines that

255
00:10:40,680 --> 00:10:42,000
are saving millions people's of lives

256
00:10:42,000 --> 00:10:45,029
but but but I still think it's okay to

257
00:10:45,029 --> 00:10:48,280
have even that middle schooler question

258
00:10:48,280 --> 00:10:49,150
the things that they're hearing

259
00:10:49,150 --> 00:10:52,090
especially when it deals with their

260
00:10:52,090 --> 00:10:55,090
health and stuff first of all the

261
00:10:55,090 --> 00:11:02,700
airlines are retiring the 747 I share

262
00:11:02,700 --> 00:11:07,690
the affection for Dana she's been one of

263
00:11:07,690 --> 00:11:10,030
my favorite people for a long time and I

264
00:11:10,030 --> 00:11:13,620
I think that what you're referring to

265
00:11:13,620 --> 00:11:17,530
was a hypothesis more than a conclusion

266
00:11:17,530 --> 00:11:20,800
it needs a whole lot of testing which

267
00:11:20,800 --> 00:11:22,360
we've done very little of we need all we

268
00:11:22,360 --> 00:11:25,300
need so much more data research in this

269
00:11:25,300 --> 00:11:30,190
field but the part of bringing news and

270
00:11:30,190 --> 00:11:32,770
media literacy and I think embedding it

271
00:11:32,770 --> 00:11:34,660
in other things as opposed to making it

272
00:11:34,660 --> 00:11:36,880
a topic really is going to be the best

273
00:11:36,880 --> 00:11:41,170
way if it's not skepticism based on

274
00:11:41,170 --> 00:11:44,560
everything should be checked period its

275
00:11:44,560 --> 00:11:47,980
skepticism based on wanting evidence so

276
00:11:47,980 --> 00:11:51,340
when her worries that people become

277
00:11:51,340 --> 00:11:55,140
skeptical of everything for example

278
00:11:55,140 --> 00:11:59,650
science or vaccines or whatever well

279
00:11:59,650 --> 00:12:02,200
that's often based on actually no

280
00:12:02,200 --> 00:12:06,040
evidence or lies so I want I want to

281
00:12:06,040 --> 00:12:07,900
build critical thinking with a

282
00:12:07,900 --> 00:12:11,860
foundation of fact as opposed to a

283
00:12:11,860 --> 00:12:15,670
foundation of belief which is the part

284
00:12:15,670 --> 00:12:17,320
that worries her a lot don't worries all

285
00:12:17,320 --> 00:12:20,260
of us but the core we need much more and

286
00:12:20,260 --> 00:12:22,510
better research and I think much more

287
00:12:22,510 --> 00:12:25,540
and better work in this whole area but

288
00:12:25,540 --> 00:12:27,820
it's pretty it has there hasn't been

289
00:12:27,820 --> 00:12:30,400
much until quite recently so I think

290
00:12:30,400 --> 00:12:33,640
we're at the beginning well I do want to

291
00:12:33,640 --> 00:12:35,620
join your your comment with the

292
00:12:35,620 --> 00:12:38,710
gentleman comment over here which is I

293
00:12:38,710 --> 00:12:42,089
think part of this is it's emotional

294
00:12:42,089 --> 00:12:44,680
there's a lot of emotion behind this

295
00:12:44,680 --> 00:12:48,280
stuff and so the the narratives that are

296
00:12:48,280 --> 00:12:52,270
built online that's already built into

297
00:12:52,270 --> 00:12:54,940
it this mist this this mistrust of facts

298
00:12:54,940 --> 00:12:57,700
that's a big part of their narratives

299
00:12:57,700 --> 00:13:00,459
and so building out a curriculum to

300
00:13:00,459 --> 00:13:02,050
critically

301
00:13:02,050 --> 00:13:05,019
analyzed this stuff oh yeah great

302
00:13:05,019 --> 00:13:06,459
there's somebody on the other side he

303
00:13:06,459 --> 00:13:08,949
was already been doing that online for a

304
00:13:08,949 --> 00:13:10,839
long like don't trust anything on the

305
00:13:10,839 --> 00:13:12,309
about the government or don't trust you

306
00:13:12,309 --> 00:13:14,470
know the mainstream media that's a big

307
00:13:14,470 --> 00:13:16,689
part of their narrative and where allows

308
00:13:16,689 --> 00:13:18,489
them to reach their people emotionally

309
00:13:18,489 --> 00:13:20,499
and how this connects back to the

310
00:13:20,499 --> 00:13:23,199
political part of it is what what these

311
00:13:23,199 --> 00:13:24,519
guys have done really well as they've

312
00:13:24,519 --> 00:13:26,230
localized a lot of these conversations

313
00:13:26,230 --> 00:13:29,799
in a way that is related to science

314
00:13:29,799 --> 00:13:31,600
related to any number of things that

315
00:13:31,600 --> 00:13:33,970
affects people on the daily basis and

316
00:13:33,970 --> 00:13:36,699
and part of it is you know the

317
00:13:36,699 --> 00:13:38,499
curriculum and all that but the other

318
00:13:38,499 --> 00:13:40,839
part of it is how do we also reach

319
00:13:40,839 --> 00:13:43,559
people where they live in a way that is

320
00:13:43,559 --> 00:13:46,749
emotional that they will actually share

321
00:13:46,749 --> 00:13:48,549
because I would argue that the biggest

322
00:13:48,549 --> 00:13:50,980
problem to solve for here is they have

323
00:13:50,980 --> 00:13:53,410
an organic audience that just reshares

324
00:13:53,410 --> 00:13:56,949
because they feel like what is being

325
00:13:56,949 --> 00:14:01,600
said in these fake news validates their

326
00:14:01,600 --> 00:14:03,819
everyday life and I think that's a

327
00:14:03,819 --> 00:14:07,269
that's a trickier question underlying

328
00:14:07,269 --> 00:14:11,139
all of this I have one thought which is

329
00:14:11,139 --> 00:14:13,299
that I think an edition alongside two

330
00:14:13,299 --> 00:14:17,379
critical thinking skills is that you

331
00:14:17,379 --> 00:14:18,730
know we need to also be talking about

332
00:14:18,730 --> 00:14:21,069
people talking about truth more with

333
00:14:21,069 --> 00:14:23,699
more complexity right so in other words

334
00:14:23,699 --> 00:14:26,860
you know the numbers the numbers thing I

335
00:14:26,860 --> 00:14:28,839
really like trying to demystify numbers

336
00:14:28,839 --> 00:14:30,939
- right because they're so opaque where

337
00:14:30,939 --> 00:14:32,679
you see a number and you're like what do

338
00:14:32,679 --> 00:14:34,779
I do with that number or in some of

339
00:14:34,779 --> 00:14:36,220
these situations - like talking about

340
00:14:36,220 --> 00:14:38,799
facts I think sometimes we're in danger

341
00:14:38,799 --> 00:14:40,689
of replicating the same binaries and

342
00:14:40,689 --> 00:14:42,610
certain and some very complicated issues

343
00:14:42,610 --> 00:14:43,839
and so if we're teaching the critical

344
00:14:43,839 --> 00:14:45,339
thinking skills we do need to start

345
00:14:45,339 --> 00:14:47,259
taking a talking about the same time

346
00:14:47,259 --> 00:14:49,209
talking about truth with complexity and

347
00:14:49,209 --> 00:14:50,980
having people being comfortable with

348
00:14:50,980 --> 00:14:52,869
that complexity I think you know perhaps

349
00:14:52,869 --> 00:14:54,220
that's one thing that we haven't been

350
00:14:54,220 --> 00:14:56,410
doing as much as how to be you know

351
00:14:56,410 --> 00:14:57,730
comfortable with the fact that there is

352
00:14:57,730 --> 00:14:59,529
difference and a little bit of diversity

353
00:14:59,529 --> 00:15:02,949
and a little bit of like a little yeah a

354
00:15:02,949 --> 00:15:05,139
little spectrum there and the reason why

355
00:15:05,139 --> 00:15:06,819
I think about this has to do with for

356
00:15:06,819 --> 00:15:08,259
example when you start talking about

357
00:15:08,259 --> 00:15:11,110
genocide or the reporting of genocide my

358
00:15:11,110 --> 00:15:13,660
background is as a German history person

359
00:15:13,660 --> 00:15:15,429
and I think about so these numbers were

360
00:15:15,429 --> 00:15:15,640
they

361
00:15:15,640 --> 00:15:18,340
to the Holocaust for example or in more

362
00:15:18,340 --> 00:15:20,680
recent work numbers related to human

363
00:15:20,680 --> 00:15:23,440
rights violations say in Burundi it's

364
00:15:23,440 --> 00:15:24,940
not to say that this these events aren't

365
00:15:24,940 --> 00:15:26,980
happening how concrete can you be about

366
00:15:26,980 --> 00:15:28,840
these numbers the the reports are very

367
00:15:28,840 --> 00:15:30,940
difficult and you you try to gather as

368
00:15:30,940 --> 00:15:32,980
best as you can not to undermine the

369
00:15:32,980 --> 00:15:34,870
scientific process not to undermining a

370
00:15:34,870 --> 00:15:36,460
very good reporting process so how do

371
00:15:36,460 --> 00:15:38,770
you teach trust in that critically as

372
00:15:38,770 --> 00:15:40,420
well as I think trying to give people

373
00:15:40,420 --> 00:15:42,760
vocabulary for a complex thinking and

374
00:15:42,760 --> 00:15:44,440
that would be I think those are the two

375
00:15:44,440 --> 00:15:46,690
things I would say hand in hand I think

376
00:15:46,690 --> 00:15:48,250
there's a good question we've time for

377
00:15:48,250 --> 00:15:50,380
one more one more question in the back

378
00:15:50,380 --> 00:15:51,970
gleb supporters key with approach of

379
00:15:51,970 --> 00:15:54,190
pledge so something that I was noticing

380
00:15:54,190 --> 00:15:57,330
and there's a lot of focus on fighting

381
00:15:57,330 --> 00:16:00,010
 you know and so on and I'm

382
00:16:00,010 --> 00:16:03,190
wondering how much focus is there on the

383
00:16:03,190 --> 00:16:04,840
opposite aspect of fighting

384
00:16:04,840 --> 00:16:07,050
misinformation which is loving truth

385
00:16:07,050 --> 00:16:09,250
caring about truth which is a really

386
00:16:09,250 --> 00:16:11,140
different emotion taps had really

387
00:16:11,140 --> 00:16:13,360
different things and that's something I

388
00:16:13,360 --> 00:16:15,310
haven't yet heard about spoken of and

389
00:16:15,310 --> 00:16:17,740
then tying it to politics as well there

390
00:16:17,740 --> 00:16:20,110
is a lot of movements right now to unite

391
00:16:20,110 --> 00:16:22,360
the country as opposed to divide it

392
00:16:22,360 --> 00:16:25,480
which i think is tied to call a call to

393
00:16:25,480 --> 00:16:27,610
love truth unite our country be

394
00:16:27,610 --> 00:16:30,400
patriotic as opposed to split apart and

395
00:16:30,400 --> 00:16:33,190
fight misinformation fight so

396
00:16:33,190 --> 00:16:34,870
I'm curious about your commentary and

397
00:16:34,870 --> 00:16:38,170
your thoughts and those things I can

398
00:16:38,170 --> 00:16:39,640
just say a couple of things it's an

399
00:16:39,640 --> 00:16:42,610
interesting question

400
00:16:42,610 --> 00:16:45,130
one thing that researchers have found

401
00:16:45,130 --> 00:16:47,110
that sort of that live in these

402
00:16:47,110 --> 00:16:49,360
conspiracy worlds that read this and can

403
00:16:49,360 --> 00:16:50,710
be completely disoriented to the

404
00:16:50,710 --> 00:16:53,020
researchers themselves they have found a

405
00:16:53,020 --> 00:16:54,760
few things that I found super interest

406
00:16:54,760 --> 00:16:56,590
in Kate starboard what is one researcher

407
00:16:56,590 --> 00:16:58,180
a university that's found some of this

408
00:16:58,180 --> 00:17:01,840
stuff one is that these conspiracies

409
00:17:01,840 --> 00:17:03,400
online conspiracy communities are

410
00:17:03,400 --> 00:17:05,319
gateways to other conspiracy communities

411
00:17:05,319 --> 00:17:08,290
so if you you know if you sort of

412
00:17:08,290 --> 00:17:12,310
stumbled upon a website around the

413
00:17:12,310 --> 00:17:14,380
anti-vaccination or whatever you're

414
00:17:14,380 --> 00:17:16,569
invited to be a critical reason you

415
00:17:16,569 --> 00:17:18,270
you're you're questioning the

416
00:17:18,270 --> 00:17:20,290
institutions that are telling you how to

417
00:17:20,290 --> 00:17:22,900
think and so these individuals are in

418
00:17:22,900 --> 00:17:24,760
love I think with the true and do want

419
00:17:24,760 --> 00:17:26,560
to seek truth in some ways I think you

420
00:17:26,560 --> 00:17:28,150
know I give most people to benefit it

421
00:17:28,150 --> 00:17:29,020
out across the

422
00:17:29,020 --> 00:17:30,900
political spectrum that want to get at

423
00:17:30,900 --> 00:17:33,700
truth and once they can they're inviting

424
00:17:33,700 --> 00:17:34,900
in the same ways that we do at

425
00:17:34,900 --> 00:17:36,700
universities we want to make you better

426
00:17:36,700 --> 00:17:38,290
critical thinkers well do you want to be

427
00:17:38,290 --> 00:17:39,760
a critical thinker and just accept that

428
00:17:39,760 --> 00:17:41,320
vaccine will come on in

429
00:17:41,320 --> 00:17:42,850
so they come on into these communities

430
00:17:42,850 --> 00:17:45,880
and they start to you know you get this

431
00:17:45,880 --> 00:17:48,160
illusionary truth effect where you sort

432
00:17:48,160 --> 00:17:49,270
of keep hearing the same thing and you

433
00:17:49,270 --> 00:17:50,650
start to believe it and then before you

434
00:17:50,650 --> 00:17:51,310
know it

435
00:17:51,310 --> 00:17:53,500
they find these same individuals these

436
00:17:53,500 --> 00:17:56,350
same you know these same people that are

437
00:17:56,350 --> 00:17:59,290
in this anti-vaccination community now

438
00:17:59,290 --> 00:18:01,120
in the flat earth communities and and

439
00:18:01,120 --> 00:18:02,260
they tracking a lot of these people that

440
00:18:02,260 --> 00:18:03,700
move from one to the next and become

441
00:18:03,700 --> 00:18:05,320
sort of gateways and but the Gateway the

442
00:18:05,320 --> 00:18:08,290
original gateway is sort of being a part

443
00:18:08,290 --> 00:18:09,640
of this group being sort of that

444
00:18:09,640 --> 00:18:11,320
independent thing or a critical reason

445
00:18:11,320 --> 00:18:13,690
which is sort of hard to that's the same

446
00:18:13,690 --> 00:18:16,240
sort of thing that we're recruiting at

447
00:18:16,240 --> 00:18:18,250
university campuses and and both groups

448
00:18:18,250 --> 00:18:20,710
seem to be after becoming smarter or

449
00:18:20,710 --> 00:18:27,160
closer to the truth you know truth

450
00:18:27,160 --> 00:18:34,920
capital T is different than reality and

451
00:18:35,100 --> 00:18:37,420
one of the issues and I think it's

452
00:18:37,420 --> 00:18:39,850
directly related to the science question

453
00:18:39,850 --> 00:18:41,650
which is that you know the whole

454
00:18:41,650 --> 00:18:44,800
scientific method at some level is about

455
00:18:44,800 --> 00:18:46,690
attacking what has been the perceived

456
00:18:46,690 --> 00:18:51,400
truth to find out if it's wrong to to

457
00:18:51,400 --> 00:18:55,240
iterate to test to hypothesize to see if

458
00:18:55,240 --> 00:18:59,340
we can figure out a little bit better

459
00:18:59,340 --> 00:19:05,710
and to the point just made everything is

460
00:19:05,710 --> 00:19:09,370
complicated and we treat things as if

461
00:19:09,370 --> 00:19:12,430
they're not that so that that's one of

462
00:19:12,430 --> 00:19:14,470
the worries and saying yeah believe the

463
00:19:14,470 --> 00:19:18,400
truth I want I really want people to

464
00:19:18,400 --> 00:19:22,450
believe in nuance and to understand what

465
00:19:22,450 --> 00:19:24,670
anyone who has who is in a family and

466
00:19:24,670 --> 00:19:27,100
which would include everyone here knows

467
00:19:27,100 --> 00:19:30,940
that life is complicated yet oddly we

468
00:19:30,940 --> 00:19:33,580
turn everything into binary yes I know

469
00:19:33,580 --> 00:19:37,300
true or not so we have a lot of work to

470
00:19:37,300 --> 00:19:38,160
do on

471
00:19:38,160 --> 00:19:42,780
I want truth with various meanings as

472
00:19:42,780 --> 00:19:46,920
but I want fact-based evidence-based

473
00:19:46,920 --> 00:19:51,570
truth I think in addition to all of that

474
00:19:51,570 --> 00:19:56,190
we have to facilitate conversation in a

475
00:19:56,190 --> 00:19:59,310
meaningful way in a serious way that

476
00:19:59,310 --> 00:20:03,720
allows people to feel safe to say how

477
00:20:03,720 --> 00:20:06,810
they feel and that may say sound

478
00:20:06,810 --> 00:20:09,720
Pollyannish but the Internet does a

479
00:20:09,720 --> 00:20:14,760
great job of siloing people by belief

480
00:20:14,760 --> 00:20:18,150
and that truth is relative to those

481
00:20:18,150 --> 00:20:21,300
beliefs online which is why those

482
00:20:21,300 --> 00:20:24,630
various reddit channels and everything

483
00:20:24,630 --> 00:20:26,610
else are so popular people just want to

484
00:20:26,610 --> 00:20:29,880
feel like they belong and part of that

485
00:20:29,880 --> 00:20:32,460
appeal is here's a group of people that

486
00:20:32,460 --> 00:20:35,040
believes in this truth and that truth is

487
00:20:35,040 --> 00:20:36,600
that these other people are idiots and

488
00:20:36,600 --> 00:20:38,310
don't know what they're talking about

489
00:20:38,310 --> 00:20:42,410
and so the solution to that really is

490
00:20:42,410 --> 00:20:46,860
how do we facilitate conversation and

491
00:20:46,860 --> 00:20:50,820
community in real life which again

492
00:20:50,820 --> 00:20:53,190
sounds pollyannish and it's probably not

493
00:20:53,190 --> 00:20:56,730
very useful but you know similar to what

494
00:20:56,730 --> 00:20:58,800
he said in a family you can say things

495
00:20:58,800 --> 00:21:01,680
online that you would never say to a

496
00:21:01,680 --> 00:21:04,650
person at a bar you can say things

497
00:21:04,650 --> 00:21:07,290
online and you can participate in

498
00:21:07,290 --> 00:21:09,150
actions online that you never would do

499
00:21:09,150 --> 00:21:11,370
in real life and I think part of it is

500
00:21:11,370 --> 00:21:14,760
is figuring out that solving for that

501
00:21:14,760 --> 00:21:17,910
binary which is life is complex truth is

502
00:21:17,910 --> 00:21:20,700
relative how do we allow people to to

503
00:21:20,700 --> 00:21:22,680
live in that in a way that they feel

504
00:21:22,680 --> 00:21:26,040
comfortable with each other as opposed

505
00:21:26,040 --> 00:21:28,350
to going off to their sides of the room

506
00:21:28,350 --> 00:21:31,410
like little children and demonizing the

507
00:21:31,410 --> 00:21:35,670
the other group all right so please join

508
00:21:35,670 --> 00:21:38,400
me in in thanking our lightning round

509
00:21:38,400 --> 00:21:39,920
presenters

510
00:21:39,920 --> 00:21:42,140
thank you that was fantastic gonna break

511
00:21:42,140 --> 00:21:43,610
for coffee we're gonna be back here in

512
00:21:43,610 --> 00:21:46,400
10 minutes so 11:05 11:05 everyone thank

513
00:21:46,400 --> 00:21:48,550
you

