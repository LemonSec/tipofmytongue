1
00:00:00,030 --> 00:00:01,709
so first ones Center for new American

2
00:00:01,709 --> 00:00:05,659
security and now Lauren take it away

3
00:00:05,660 --> 00:00:08,250
hey guys I'm Lauren DeYoung Shulman I

4
00:00:08,250 --> 00:00:11,700
had a group that was all about winning

5
00:00:11,700 --> 00:00:18,890
the future WTF he the I selected this

6
00:00:18,890 --> 00:00:21,869
let me explain we've basically generated

7
00:00:21,869 --> 00:00:24,600
three actually many more but ultimately

8
00:00:24,600 --> 00:00:27,029
three scenarios about what the future

9
00:00:27,029 --> 00:00:28,800
information space is going to look like

10
00:00:28,800 --> 00:00:30,869
in about ten years and I did this for a

11
00:00:30,869 --> 00:00:33,239
couple of reasons one we as a community

12
00:00:33,239 --> 00:00:35,190
whether we are in government in

13
00:00:35,190 --> 00:00:38,399
technology in education and news tend to

14
00:00:38,399 --> 00:00:40,379
focus on the problem directly in front

15
00:00:40,379 --> 00:00:41,910
of our face and maybe just ever so

16
00:00:41,910 --> 00:00:43,290
slightly further but we're kind of

17
00:00:43,290 --> 00:00:45,090
terrible at projecting out what is this

18
00:00:45,090 --> 00:00:46,710
threat to what does this challenge gonna

19
00:00:46,710 --> 00:00:48,780
look like any time beyond that people

20
00:00:48,780 --> 00:00:50,550
talk about deep fakes people talk about

21
00:00:50,550 --> 00:00:52,260
you know artificial intelligence enabled

22
00:00:52,260 --> 00:00:54,059
micro targeting and these are things

23
00:00:54,059 --> 00:00:55,620
that work alike I kinda have thought

24
00:00:55,620 --> 00:00:57,180
through what that means for me but not

25
00:00:57,180 --> 00:00:59,850
really beyond next six months or so so I

26
00:00:59,850 --> 00:01:02,100
wanted to take a lot of the trends that

27
00:01:02,100 --> 00:01:04,080
we see forming in the information space

28
00:01:04,080 --> 00:01:06,210
right now and think those through to

29
00:01:06,210 --> 00:01:08,760
their extreme ends and what would that

30
00:01:08,760 --> 00:01:10,860
how would those trends interact create

31
00:01:10,860 --> 00:01:13,140
different kinds of world that we should

32
00:01:13,140 --> 00:01:15,299
be either worried about or maybe

33
00:01:15,299 --> 00:01:17,549
actually we should prepare for so what

34
00:01:17,549 --> 00:01:19,860
we did today as I completely wore my

35
00:01:19,860 --> 00:01:21,509
groups out and they were amazing gave me

36
00:01:21,509 --> 00:01:25,290
tons of creative ideas is you a scenario

37
00:01:25,290 --> 00:01:27,119
planning an extremely accelerated

38
00:01:27,119 --> 00:01:30,299
version of that model to create worlds

39
00:01:30,299 --> 00:01:31,790
and I'll brief you about in just second

40
00:01:31,790 --> 00:01:33,990
su-- own hopefully in the fall I'll

41
00:01:33,990 --> 00:01:35,400
create a podcast series that will go

42
00:01:35,400 --> 00:01:37,290
over these worlds in detail and explain

43
00:01:37,290 --> 00:01:38,670
like how you might prepare for them or

44
00:01:38,670 --> 00:01:40,770
the implications and over the long term

45
00:01:40,770 --> 00:01:42,509
since I got to do my practice session

46
00:01:42,509 --> 00:01:45,360
today we will use this game in order to

47
00:01:45,360 --> 00:01:47,100
have bigger groups different groups

48
00:01:47,100 --> 00:01:48,450
think through the same questions in

49
00:01:48,450 --> 00:01:52,380
process so we the vision the future that

50
00:01:52,380 --> 00:01:54,360
we want no matter what kind of trends

51
00:01:54,360 --> 00:01:56,759
were going on are I'm reading our access

52
00:01:56,759 --> 00:01:58,290
to the truth in the short term and

53
00:01:58,290 --> 00:02:00,360
limited courage and public discourse in

54
00:02:00,360 --> 00:02:02,159
the long term we just said I just told

55
00:02:02,159 --> 00:02:03,899
everyone you don't get to argue with me

56
00:02:03,899 --> 00:02:05,460
here's the here's the vision of the

57
00:02:05,460 --> 00:02:07,049
world that I once you just have to agree

58
00:02:07,049 --> 00:02:09,389
with me and the biggest question that we

59
00:02:09,389 --> 00:02:10,590
wanted to be able to answer no matter

60
00:02:10,590 --> 00:02:13,230
what the world was was in 10 years what

61
00:02:13,230 --> 00:02:13,950
will the

62
00:02:13,950 --> 00:02:15,690
and space to look like and then what

63
00:02:15,690 --> 00:02:17,580
kind of capabilities do governments in

64
00:02:17,580 --> 00:02:19,080
particular but not just government's

65
00:02:19,080 --> 00:02:22,379
other institutions need to identify and

66
00:02:22,379 --> 00:02:24,480
communicate the truth so that's a very

67
00:02:24,480 --> 00:02:26,519
broad question because all the worlds we

68
00:02:26,519 --> 00:02:29,250
created we're super different you're not

69
00:02:29,250 --> 00:02:30,810
gonna be able to read this but the the

70
00:02:30,810 --> 00:02:33,030
the more detailed questions that I asked

71
00:02:33,030 --> 00:02:34,920
folks once we created our worlds were

72
00:02:34,920 --> 00:02:36,540
things like if you could invest in

73
00:02:36,540 --> 00:02:38,730
anything today to prepare for your world

74
00:02:38,730 --> 00:02:40,709
what would it be what kind of skills do

75
00:02:40,709 --> 00:02:42,720
we need as a community to develop over

76
00:02:42,720 --> 00:02:44,790
the next 10 years in order to survive in

77
00:02:44,790 --> 00:02:46,769
this world or maybe do a better than the

78
00:02:46,769 --> 00:02:49,170
world that we're looking at what kind of

79
00:02:49,170 --> 00:02:50,760
partnership should we start building now

80
00:02:50,760 --> 00:02:52,440
what kind of information sharing

81
00:02:52,440 --> 00:02:54,599
infrastructure do you need or what kind

82
00:02:54,599 --> 00:02:56,459
of information protection do you need in

83
00:02:56,459 --> 00:02:57,989
order to actually survive in this world

84
00:02:57,989 --> 00:03:00,329
what laws would you get rid of how would

85
00:03:00,329 --> 00:03:02,099
you redesign government what kind of

86
00:03:02,099 --> 00:03:03,690
foreign policy would you want to have

87
00:03:03,690 --> 00:03:05,519
things to think through how do you

88
00:03:05,519 --> 00:03:07,170
actually thrive in the worlds we're

89
00:03:07,170 --> 00:03:08,880
creating instead of just like having it

90
00:03:08,880 --> 00:03:10,799
be a horrible dystopia which we created

91
00:03:10,799 --> 00:03:13,680
don't don't worry the three worlds that

92
00:03:13,680 --> 00:03:17,099
we worked out in detail were the rise of

93
00:03:17,099 --> 00:03:20,190
the demagogues the dystopia and there's

94
00:03:20,190 --> 00:03:22,260
a dystopia of uninformed in distrustful

95
00:03:22,260 --> 00:03:24,810
people and a fractured and manipulated

96
00:03:24,810 --> 00:03:26,730
society basically they all kind of

97
00:03:26,730 --> 00:03:29,880
sucked so we took extremes of being not

98
00:03:29,880 --> 00:03:31,889
trusting media of having a via

99
00:03:31,889 --> 00:03:34,410
manipulation of little trust and

100
00:03:34,410 --> 00:03:39,060
democratic institutions and a rise of

101
00:03:39,060 --> 00:03:40,829
populism and tribalism and brought those

102
00:03:40,829 --> 00:03:43,139
out to the logical extremes and to see

103
00:03:43,139 --> 00:03:45,510
how they interacted but what was

104
00:03:45,510 --> 00:03:47,340
interesting is when we asked people how

105
00:03:47,340 --> 00:03:49,680
you would prepare for them no matter how

106
00:03:49,680 --> 00:03:51,269
different those worlds were there were

107
00:03:51,269 --> 00:03:52,950
several commonalities and what people

108
00:03:52,950 --> 00:03:54,510
said here's what I would want to do to

109
00:03:54,510 --> 00:03:56,250
either prevent that world from happening

110
00:03:56,250 --> 00:03:57,930
or prepare ourselves to be able to

111
00:03:57,930 --> 00:04:00,000
survive in it so obvious ones like

112
00:04:00,000 --> 00:04:03,090
education to include divil digital and

113
00:04:03,090 --> 00:04:05,970
civic literacy to really focus on

114
00:04:05,970 --> 00:04:08,069
strengthening the role of local and

115
00:04:08,069 --> 00:04:09,780
community governments and empowering

116
00:04:09,780 --> 00:04:11,669
individuals as well in particular

117
00:04:11,669 --> 00:04:14,609
empowering local news sources what an

118
00:04:14,609 --> 00:04:15,720
interesting element of that that I

119
00:04:15,720 --> 00:04:18,329
thought was really unique was talking

120
00:04:18,329 --> 00:04:20,220
about better multi-generational

121
00:04:20,220 --> 00:04:21,478
engagement within local communities

122
00:04:21,478 --> 00:04:23,430
because a lot of the political divisions

123
00:04:23,430 --> 00:04:25,729
we see are less between economic

124
00:04:25,729 --> 00:04:27,400
different economic

125
00:04:27,400 --> 00:04:29,290
and more between generations so the

126
00:04:29,290 --> 00:04:30,220
interesting point that I thought worth

127
00:04:30,220 --> 00:04:32,260
of highlighting getting rid of

128
00:04:32,260 --> 00:04:34,510
institutional incentives for

129
00:04:34,510 --> 00:04:36,430
bipartisanship and Polar's a I'm sorry

130
00:04:36,430 --> 00:04:37,810
not for bipartisanship getting rid of

131
00:04:37,810 --> 00:04:39,550
institutional and said centers for a

132
00:04:39,550 --> 00:04:42,240
polarization like gerrymandering or

133
00:04:42,240 --> 00:04:44,380
first-past-the-post democratic voting

134
00:04:44,380 --> 00:04:46,210
institutions those were things that

135
00:04:46,210 --> 00:04:47,169
people were worried about and we should

136
00:04:47,169 --> 00:04:51,130
try to get rid of generating we there

137
00:04:51,130 --> 00:04:52,300
was an interesting theme across all

138
00:04:52,300 --> 00:04:54,400
groups of generating solutions that were

139
00:04:54,400 --> 00:04:56,830
very human oriented and not technology

140
00:04:56,830 --> 00:04:58,720
oriented which i think is worth

141
00:04:58,720 --> 00:05:00,280
highlighting in a group of people that

142
00:05:00,280 --> 00:05:01,990
quite often kind of turns to the how do

143
00:05:01,990 --> 00:05:05,139
we use algorithms to solve the world the

144
00:05:05,139 --> 00:05:08,169
that alas you a highlight are groups

145
00:05:08,169 --> 00:05:10,990
focused on historical preservation so

146
00:05:10,990 --> 00:05:12,910
making sure we are saving our history

147
00:05:12,910 --> 00:05:14,889
but also increasing historical education

148
00:05:14,889 --> 00:05:18,490
so we understand it better the skills of

149
00:05:18,490 --> 00:05:20,440
self-sufficiency of resilience

150
00:05:20,440 --> 00:05:22,930
leadership and the ability to disconnect

151
00:05:22,930 --> 00:05:25,150
from technology in all kinds of ways

152
00:05:25,150 --> 00:05:26,860
both in terms of our communication as

153
00:05:26,860 --> 00:05:28,479
well as our government we're all things

154
00:05:28,479 --> 00:05:29,590
that people said that we needed to

155
00:05:29,590 --> 00:05:32,740
invest in and lastly I can barely read

156
00:05:32,740 --> 00:05:35,320
this that an obvious one but I'll say it

157
00:05:35,320 --> 00:05:36,340
anyway is to strengthen democratic

158
00:05:36,340 --> 00:05:38,680
institutions so each of these two has

159
00:05:38,680 --> 00:05:39,970
interesting commonalities across the

160
00:05:39,970 --> 00:05:42,190
worlds that we created so clearly we

161
00:05:42,190 --> 00:05:43,360
should be investing in all of them now

162
00:05:43,360 --> 00:05:45,050
and that is my presentation thank you

163
00:05:45,050 --> 00:05:46,350
[Music]

164
00:05:46,350 --> 00:05:47,760
[Applause]

165
00:05:47,760 --> 00:05:50,849
[Music]

166
00:05:53,250 --> 00:05:55,389
thanks Lauren that was great all right

167
00:05:55,389 --> 00:05:58,270
next presentation can we load that on

168
00:05:58,270 --> 00:05:59,289
the screen please

169
00:05:59,289 --> 00:06:09,520
AV team so how's everyone doing all

170
00:06:09,520 --> 00:06:09,849
right

171
00:06:09,849 --> 00:06:12,580
mapping the solution space harmony labs

172
00:06:12,580 --> 00:06:14,440
in Mozilla can someone from army labs

173
00:06:14,440 --> 00:06:24,389
and or Mozilla hello great all right

174
00:06:24,389 --> 00:06:28,180
hello I'm Susan Paulton I'm not with

175
00:06:28,180 --> 00:06:30,250
Harmony labs or Mozilla but our amazing

176
00:06:30,250 --> 00:06:34,840
team had them and got nominated to come

177
00:06:34,840 --> 00:06:37,210
and represent them and we did a thought

178
00:06:37,210 --> 00:06:40,080
exercise on mapping the solution space

179
00:06:40,080 --> 00:06:43,349
so everyone put every concept every

180
00:06:43,349 --> 00:06:45,389
piece of research every solution every

181
00:06:45,389 --> 00:06:47,699
idea that they had heard in this space

182
00:06:47,699 --> 00:06:51,569
down and we tried to find a matrix in

183
00:06:51,569 --> 00:06:53,759
which we could map and group these

184
00:06:53,759 --> 00:06:59,759
solutions and and this is what we came

185
00:06:59,759 --> 00:07:01,530
up with so first there's um you know a

186
00:07:01,530 --> 00:07:03,180
lot of people already you know thinking

187
00:07:03,180 --> 00:07:05,219
about and working in the space obviously

188
00:07:05,219 --> 00:07:07,319
everyone in this room is working on

189
00:07:07,319 --> 00:07:11,039
solutions and so we were drawing on most

190
00:07:11,039 --> 00:07:13,590
of the work that that's well known here

191
00:07:13,590 --> 00:07:16,099
as well as discovering a few new things

192
00:07:16,099 --> 00:07:20,840
that some hadn't hadn't heard about

193
00:07:20,840 --> 00:07:25,110
needless to say it's complex and some of

194
00:07:25,110 --> 00:07:26,969
the common categories that emerged were

195
00:07:26,969 --> 00:07:29,909
researched fact-checking media literacy

196
00:07:29,909 --> 00:07:32,310
government regulation industry standards

197
00:07:32,310 --> 00:07:35,699
collaboration and different tools this

198
00:07:35,699 --> 00:07:38,819
is kind of what it looked like and I

199
00:07:38,819 --> 00:07:43,080
think the big takeaway here we tried to

200
00:07:43,080 --> 00:07:44,759
come up with several matrices in which

201
00:07:44,759 --> 00:07:46,830
you could map all these solutions on the

202
00:07:46,830 --> 00:07:49,770
far left you had research and theory and

203
00:07:49,770 --> 00:07:52,259
on the far right you had practice which

204
00:07:52,259 --> 00:07:53,580
I know is something that the credibility

205
00:07:53,580 --> 00:07:56,310
Coalition has also kind of framework

206
00:07:56,310 --> 00:07:57,960
that they've experimented with and then

207
00:07:57,960 --> 00:08:00,389
we tried to go from high complexity to

208
00:08:00,389 --> 00:08:02,729
low complexity we also experimented with

209
00:08:02,729 --> 00:08:05,279
an x-axis that would have time frame for

210
00:08:05,279 --> 00:08:06,719
solution whether it's a short term

211
00:08:06,719 --> 00:08:09,449
solution or a long term solution so

212
00:08:09,449 --> 00:08:10,740
there's a lot of different ways to slice

213
00:08:10,740 --> 00:08:12,479
and dice all of these different

214
00:08:12,479 --> 00:08:14,339
solutions but what we were looking for

215
00:08:14,339 --> 00:08:15,419
is the gaps

216
00:08:15,419 --> 00:08:17,490
now just to frame it this is the biases

217
00:08:17,490 --> 00:08:19,229
of the folks that were in this room so

218
00:08:19,229 --> 00:08:21,419
we there was not a lot of expertise in

219
00:08:21,419 --> 00:08:23,639
the research area there was a lot of us

220
00:08:23,639 --> 00:08:25,169
in the room who were definitely in the

221
00:08:25,169 --> 00:08:26,879
solutions in the practice area which you

222
00:08:26,879 --> 00:08:29,580
can see over on the right but

223
00:08:29,580 --> 00:08:31,379
essentially what I think the gaps that

224
00:08:31,379 --> 00:08:33,120
we discovered is that we're missing a

225
00:08:33,120 --> 00:08:34,979
lot of the research in at least our

226
00:08:34,979 --> 00:08:36,539
knowledgebase of this the research is

227
00:08:36,539 --> 00:08:37,890
probably out there but we don't know

228
00:08:37,890 --> 00:08:40,229
about it down at the bottom nothing is

229
00:08:40,229 --> 00:08:42,029
simple everything is kind of in the

230
00:08:42,029 --> 00:08:44,130
complex space and that we're working on

231
00:08:44,130 --> 00:08:45,660
a lot of solutions but I think the big

232
00:08:45,660 --> 00:08:48,209
takeaway that this could become is a

233
00:08:48,209 --> 00:08:49,860
matrices so instead of having

234
00:08:49,860 --> 00:08:52,620
spreadsheets of lists of opportunities

235
00:08:52,620 --> 00:08:53,180
that every

236
00:08:53,180 --> 00:08:54,890
here is working on how can we come up

237
00:08:54,890 --> 00:08:57,260
with a better visualization to identify

238
00:08:57,260 --> 00:08:59,420
collaboration on these different things

239
00:08:59,420 --> 00:09:01,490
either core areas because now is the

240
00:09:01,490 --> 00:09:04,790
time for us to start collaborating and

241
00:09:04,790 --> 00:09:06,860
we need consolidation we have tons of

242
00:09:06,860 --> 00:09:08,690
people working in certain spaces and we

243
00:09:08,690 --> 00:09:10,339
all kind of need to come together and

244
00:09:10,339 --> 00:09:12,380
apply for these fundings on certain

245
00:09:12,380 --> 00:09:14,240
platforms and consolidate and

246
00:09:14,240 --> 00:09:16,700
collaborate that there's a bit of a silo

247
00:09:16,700 --> 00:09:18,350
between practice and research you've got

248
00:09:18,350 --> 00:09:19,880
research happening over here in academia

249
00:09:19,880 --> 00:09:21,680
you've got practices over here but

250
00:09:21,680 --> 00:09:23,180
they're not necessarily informing each

251
00:09:23,180 --> 00:09:26,149
other and that we don't have an efficacy

252
00:09:26,149 --> 00:09:28,880
framework for real-time research so how

253
00:09:28,880 --> 00:09:30,560
are we testing the things we are doing

254
00:09:30,560 --> 00:09:32,660
and feeding that data back to people who

255
00:09:32,660 --> 00:09:34,339
are experimenting and doing the research

256
00:09:34,339 --> 00:09:35,899
so that they know what's effective and

257
00:09:35,899 --> 00:09:38,029
what isn't effective so the hope is that

258
00:09:38,029 --> 00:09:41,570
this big hot mess can become more of a

259
00:09:41,570 --> 00:09:43,760
open source crowd-sourced framework that

260
00:09:43,760 --> 00:09:45,260
we can build on that can help us

261
00:09:45,260 --> 00:09:48,770
visualize those collaborations Thanks

262
00:09:48,770 --> 00:09:56,630
[Applause]

263
00:09:58,240 --> 00:10:01,160
can the cred Co folks please come on

264
00:10:01,160 --> 00:10:08,199
credibility coalition Connie

265
00:10:11,420 --> 00:10:13,330
this is gonna be a tremendous

266
00:10:13,330 --> 00:10:16,190
presentation because I am working for

267
00:10:16,190 --> 00:10:18,470
the credibility coalition this is gonna

268
00:10:18,470 --> 00:10:28,490
be great yeah I'm gonna have to zoom in

269
00:10:28,490 --> 00:10:29,420
a little because I think there's

270
00:10:29,420 --> 00:10:30,710
literally screen-sharing

271
00:10:30,710 --> 00:10:37,010
there we go okay okay no you're

272
00:10:37,010 --> 00:10:38,960
literally gonna say next slide next

273
00:10:38,960 --> 00:10:41,570
slide I just want to go to the one keep

274
00:10:41,570 --> 00:10:44,120
on going next it's in backward order

275
00:10:44,120 --> 00:10:44,990
next

276
00:10:44,990 --> 00:10:54,590
that's one okay technology hi so and it

277
00:10:54,590 --> 00:10:56,720
was really great actually to to fall on

278
00:10:56,720 --> 00:10:58,130
the heels of that one because we did

279
00:10:58,130 --> 00:11:00,290
also work on our miss info Matt my name

280
00:11:00,290 --> 00:11:01,970
is Connie means aha and I'm part of the

281
00:11:01,970 --> 00:11:03,950
credibility coalition I'll be speaking a

282
00:11:03,950 --> 00:11:05,390
little bit more of our approach to

283
00:11:05,390 --> 00:11:07,820
trying to find frameworks that allow for

284
00:11:07,820 --> 00:11:10,970
collaboration tomorrow but today what we

285
00:11:10,970 --> 00:11:12,530
decided to do was to focus in two

286
00:11:12,530 --> 00:11:14,660
specific areas one is that we wanted to

287
00:11:14,660 --> 00:11:16,370
kind of think about a couple of

288
00:11:16,370 --> 00:11:17,900
different frameworks specifically in the

289
00:11:17,900 --> 00:11:20,450
areas of Elections and the second was

290
00:11:20,450 --> 00:11:21,770
also to think about some of these

291
00:11:21,770 --> 00:11:23,570
frameworks that were working on in the

292
00:11:23,570 --> 00:11:25,700
credibility coalition specifically

293
00:11:25,700 --> 00:11:27,050
around the area of private messaging

294
00:11:27,050 --> 00:11:29,870
spaces so maybe just to kind of condense

295
00:11:29,870 --> 00:11:33,500
it in a few three broad areas um first

296
00:11:33,500 --> 00:11:34,790
we worked on something that we called

297
00:11:34,790 --> 00:11:36,230
the missing phone app thank you so much

298
00:11:36,230 --> 00:11:37,850
for the reference earlier to the

299
00:11:37,850 --> 00:11:39,740
credibility coalition and this is

300
00:11:39,740 --> 00:11:40,700
something that we've been developing

301
00:11:40,700 --> 00:11:42,830
over the last month in which again we

302
00:11:42,830 --> 00:11:44,630
don't want to duplicate efforts we

303
00:11:44,630 --> 00:11:46,070
thought that we could try to come up

304
00:11:46,070 --> 00:11:47,630
with a framework that allows people to

305
00:11:47,630 --> 00:11:49,940
situate their own work within a specific

306
00:11:49,940 --> 00:11:52,130
context and to see what who have who

307
00:11:52,130 --> 00:11:54,590
else is collaborating in the space but

308
00:11:54,590 --> 00:11:56,630
also to ask questions that prompt people

309
00:11:56,630 --> 00:11:59,450
to deeper inquiry as well as to think

310
00:11:59,450 --> 00:12:01,250
about if there is sufficient responses

311
00:12:01,250 --> 00:12:02,630
and specific areas related to

312
00:12:02,630 --> 00:12:05,630
disinformation and misinformation so one

313
00:12:05,630 --> 00:12:07,310
way that we think about it is to what

314
00:12:07,310 --> 00:12:09,650
extent does your project on an access

315
00:12:09,650 --> 00:12:11,210
between theory and practice in other

316
00:12:11,210 --> 00:12:12,830
words is it trying to understand the

317
00:12:12,830 --> 00:12:14,150
problem of misinformation or just

318
00:12:14,150 --> 00:12:16,750
information is it prop is it trying to

319
00:12:16,750 --> 00:12:19,520
shape the quality of information they're

320
00:12:19,520 --> 00:12:20,960
actually engaging

321
00:12:20,960 --> 00:12:23,330
the second access that we have is

322
00:12:23,330 --> 00:12:26,120
between infrastructure and content so to

323
00:12:26,120 --> 00:12:27,410
what extent are you actually dealing

324
00:12:27,410 --> 00:12:31,550
with the the means of communication you

325
00:12:31,550 --> 00:12:32,810
might be more interested in the term

326
00:12:32,810 --> 00:12:34,839
medium in this case versus the message

327
00:12:34,839 --> 00:12:37,610
and then really wanting to think about

328
00:12:37,610 --> 00:12:39,470
the dimensions of diversity of language

329
00:12:39,470 --> 00:12:44,600
of of country of theme and so our first

330
00:12:44,600 --> 00:12:46,790
study actually had to do with excuse me

331
00:12:46,790 --> 00:12:48,680
our first study had to do with that we

332
00:12:48,680 --> 00:12:49,760
published earlier this year with had to

333
00:12:49,760 --> 00:12:52,339
do with scientific content but we were

334
00:12:52,339 --> 00:12:53,959
like well what happens when you enter

335
00:12:53,959 --> 00:12:55,850
the world of elections so that's what we

336
00:12:55,850 --> 00:12:57,380
did and we want to share that really

337
00:12:57,380 --> 00:13:01,670
pretty map with you we have actually a

338
00:13:01,670 --> 00:13:03,500
developing era table and we are working

339
00:13:03,500 --> 00:13:05,209
on data visualizations so we're really

340
00:13:05,209 --> 00:13:06,920
eager to share that the second thing

341
00:13:06,920 --> 00:13:08,630
that we did was we worked on indicators

342
00:13:08,630 --> 00:13:12,080
related to elections trying to think

343
00:13:12,080 --> 00:13:14,240
about what are the specific signals what

344
00:13:14,240 --> 00:13:16,580
if what about content related signals

345
00:13:16,580 --> 00:13:18,140
does it matter if content is hyper

346
00:13:18,140 --> 00:13:20,540
partisan do you want hyper partisan

347
00:13:20,540 --> 00:13:22,190
content maybe though in terms of an

348
00:13:22,190 --> 00:13:23,779
election maybe that's part of what

349
00:13:23,779 --> 00:13:25,339
should be allowed we asked questions

350
00:13:25,339 --> 00:13:27,260
about what kind of indicators related to

351
00:13:27,260 --> 00:13:30,459
context does aggressive ad placement

352
00:13:30,459 --> 00:13:32,420
indicate something about credible

353
00:13:32,420 --> 00:13:35,589
credible information we also asked about

354
00:13:35,589 --> 00:13:37,910
posed the question of indicators related

355
00:13:37,910 --> 00:13:39,950
to user behaviors there's a there's a

356
00:13:39,950 --> 00:13:42,170
sort of if you see a certain number of

357
00:13:42,170 --> 00:13:44,510
posts per second and which indicates a

358
00:13:44,510 --> 00:13:46,580
bot does that signify something but

359
00:13:46,580 --> 00:13:48,470
again even if it signals something about

360
00:13:48,470 --> 00:13:50,720
credibility to what extent do some of

361
00:13:50,720 --> 00:13:53,420
these behaviors need to a flourish in a

362
00:13:53,420 --> 00:13:55,880
functioning democracy so we brainstormed

363
00:13:55,880 --> 00:13:57,770
about more indicators in which will be

364
00:13:57,770 --> 00:14:00,200
sharing again also in terms of our

365
00:14:00,200 --> 00:14:02,839
infrastructures for in partnership with

366
00:14:02,839 --> 00:14:05,839
the w3c credible web community and I

367
00:14:05,839 --> 00:14:07,790
think Sandro is also here somewhere oh

368
00:14:07,790 --> 00:14:09,650
there he is there so hopefully you can

369
00:14:09,650 --> 00:14:11,360
learn more about that and then finally

370
00:14:11,360 --> 00:14:12,680
when we talked about private messaging

371
00:14:12,680 --> 00:14:14,680
spaces we talked about specific methods

372
00:14:14,680 --> 00:14:17,870
in terms of how we might do research in

373
00:14:17,870 --> 00:14:19,880
this space but also the ethics involved

374
00:14:19,880 --> 00:14:21,950
and maybe the final thing that will end

375
00:14:21,950 --> 00:14:23,870
is that we came up with some approaches

376
00:14:23,870 --> 00:14:25,310
to try and figure out what it would mean

377
00:14:25,310 --> 00:14:28,250
to study this space but given that it is

378
00:14:28,250 --> 00:14:30,320
private messaging space we ended with a

379
00:14:30,320 --> 00:14:32,600
sort of challenge to ourself are the

380
00:14:32,600 --> 00:14:34,040
requirements higher for people

381
00:14:34,040 --> 00:14:34,790
interested in doing

382
00:14:34,790 --> 00:14:37,700
rigorous research in these spaces in

383
00:14:37,700 --> 00:14:39,200
terms of what happens if there's a

384
00:14:39,200 --> 00:14:41,330
breach in privacy in other words these

385
00:14:41,330 --> 00:14:43,430
spaces are meant to be private spaces if

386
00:14:43,430 --> 00:14:45,770
we're doing research and information

387
00:14:45,770 --> 00:14:47,810
that we've anonymized becomes identified

388
00:14:47,810 --> 00:14:49,490
even though we've tried to de-identify

389
00:14:49,490 --> 00:14:51,680
it to what extent is that problematic

390
00:14:51,680 --> 00:14:54,140
when we engage in these spaces so that's

391
00:14:54,140 --> 00:14:56,060
what we did and this is why we worry

392
00:14:56,060 --> 00:14:58,610
about our lack of pretty slides thank

393
00:14:58,610 --> 00:15:08,390
you thank you I just wanted to put a

394
00:15:08,390 --> 00:15:11,240
quick plug in for cred Co I am looking

395
00:15:11,240 --> 00:15:12,920
to partner with journalism schools and

396
00:15:12,920 --> 00:15:14,570
journalism students so if anyone here is

397
00:15:14,570 --> 00:15:16,520
affiliated with a journalism school

398
00:15:16,520 --> 00:15:18,740
please come talk to me because we're

399
00:15:18,740 --> 00:15:21,320
looking to hire students to annotate

400
00:15:21,320 --> 00:15:23,150
articles based on specific indicators

401
00:15:23,150 --> 00:15:25,070
that we've identified so please come

402
00:15:25,070 --> 00:15:27,950
talk to me today or tomorrow if you are

403
00:15:27,950 --> 00:15:29,810
affiliated with an institution academic

404
00:15:29,810 --> 00:15:31,730
institution thank you alright next

405
00:15:31,730 --> 00:15:49,790
presentation is going to be here we go

406
00:15:49,790 --> 00:16:02,210
all right witness witness yes great tag

407
00:16:02,210 --> 00:16:04,550
team on this one we had pre-prepared

408
00:16:04,550 --> 00:16:06,230
pretty slides so he cheated

409
00:16:06,230 --> 00:16:11,240
she totally cheated so we started off

410
00:16:11,240 --> 00:16:12,830
just kind of surveying what was

411
00:16:12,830 --> 00:16:15,140
happening and we've put the link at the

412
00:16:15,140 --> 00:16:17,120
top to a bunch of our notes and sort of

413
00:16:17,120 --> 00:16:19,070
information and resource links we were

414
00:16:19,070 --> 00:16:20,330
building off a convening that happened

415
00:16:20,330 --> 00:16:21,920
about a month ago that first draft and

416
00:16:21,920 --> 00:16:23,810
witness led that was a day-long

417
00:16:23,810 --> 00:16:25,520
convening looking at solutions in this

418
00:16:25,520 --> 00:16:27,980
space so we shared some of the backdrop

419
00:16:27,980 --> 00:16:31,340
of that to start with and then we wanted

420
00:16:31,340 --> 00:16:32,690
just to kind of get a baseline on the

421
00:16:32,690 --> 00:16:33,950
tools here we think that's one of the

422
00:16:33,950 --> 00:16:35,870
problems is the challenge of people

423
00:16:35,870 --> 00:16:37,070
understanding what we mean when we talk

424
00:16:37,070 --> 00:16:38,750
about deep fakes so we looked at kind of

425
00:16:38,750 --> 00:16:40,010
the range of ways we might think about

426
00:16:40,010 --> 00:16:41,900
this so we can actually make realistic

427
00:16:41,900 --> 00:16:44,390
threat assessments the other thing we're

428
00:16:44,390 --> 00:16:46,010
really trying to do is sort of demystify

429
00:16:46,010 --> 00:16:48,380
the kind of information apocalypse type

430
00:16:48,380 --> 00:16:50,570
approach to this where it's separating

431
00:16:50,570 --> 00:16:52,130
it from so many other trends and also

432
00:16:52,130 --> 00:16:53,720
creating the damage around the sort of

433
00:16:53,720 --> 00:16:55,040
public trust issues when we talk about

434
00:16:55,040 --> 00:16:57,920
in those terms and we included the

435
00:16:57,920 --> 00:17:00,620
longer slide deck is in them in there in

436
00:17:00,620 --> 00:17:01,910
the notes that you could see from the

437
00:17:01,910 --> 00:17:05,630
link before and we were looking at you

438
00:17:05,630 --> 00:17:06,980
know a range of ways of trying to

439
00:17:06,980 --> 00:17:09,020
understand how this might play out how

440
00:17:09,020 --> 00:17:10,640
people might make subtle edits to

441
00:17:10,640 --> 00:17:13,310
content how they might create what we

442
00:17:13,310 --> 00:17:15,560
described as doppelgangers of

443
00:17:15,560 --> 00:17:16,760
individuals kind of credible

444
00:17:16,760 --> 00:17:19,040
doppelgangers and then this bigger

445
00:17:19,040 --> 00:17:20,599
threat that I think we've been talking

446
00:17:20,599 --> 00:17:22,339
about a lot recently and certainly in

447
00:17:22,339 --> 00:17:23,780
the u.s. political context a kind of

448
00:17:23,780 --> 00:17:26,329
plausible deniability the way in which

449
00:17:26,329 --> 00:17:28,640
volume of deep fake content can also

450
00:17:28,640 --> 00:17:31,220
create disruption in the information

451
00:17:31,220 --> 00:17:32,780
ecosystem which is obviously in

452
00:17:32,780 --> 00:17:34,610
alignment with so much of what we're

453
00:17:34,610 --> 00:17:38,390
seeing already and then we moved on to

454
00:17:38,390 --> 00:17:39,920
thinking about threat models and

455
00:17:39,920 --> 00:17:43,040
solution areas and we decided to focus

456
00:17:43,040 --> 00:17:45,110
on three solution three threat areas

457
00:17:45,110 --> 00:17:47,240
based on the group's interest so we

458
00:17:47,240 --> 00:17:48,800
looked at kind of the big problem of

459
00:17:48,800 --> 00:17:50,030
kind of collapse of truth and

460
00:17:50,030 --> 00:17:52,040
generalized effect on society when we

461
00:17:52,040 --> 00:17:54,040
look at a volume of fake information

462
00:17:54,040 --> 00:17:55,820
particularly playing to some of the

463
00:17:55,820 --> 00:17:58,550
things that we described as possibly

464
00:17:58,550 --> 00:18:00,320
novel with kind of deep fakes and other

465
00:18:00,320 --> 00:18:02,810
synthetic media so the visual nature the

466
00:18:02,810 --> 00:18:05,150
possibility that's individualized the

467
00:18:05,150 --> 00:18:06,680
way that many more people can create

468
00:18:06,680 --> 00:18:08,000
this type of information that we've had

469
00:18:08,000 --> 00:18:10,400
less experience dealing with as faked

470
00:18:10,400 --> 00:18:12,950
information I individualized audio and

471
00:18:12,950 --> 00:18:15,260
visual information that is manipulated

472
00:18:15,260 --> 00:18:17,360
and then the second one was a crisis

473
00:18:17,360 --> 00:18:19,580
event we ended up focusing on national

474
00:18:19,580 --> 00:18:21,290
or localized and then targeting of

475
00:18:21,290 --> 00:18:27,140
activists so here is the mic so if

476
00:18:27,140 --> 00:18:29,900
you're looking at sort of the collapse

477
00:18:29,900 --> 00:18:34,930
of truth there's to try to figure out it

478
00:18:34,930 --> 00:18:37,550
did you want to frame this in relation

479
00:18:37,550 --> 00:18:38,960
to the previous things because I'm yeah

480
00:18:38,960 --> 00:18:40,760
so collapse of truth we were trying to

481
00:18:40,760 --> 00:18:42,050
really think about how do you think

482
00:18:42,050 --> 00:18:45,440
about you know which of the what are the

483
00:18:45,440 --> 00:18:46,730
ways to deal with the generalized

484
00:18:46,730 --> 00:18:48,560
problem not a specific incident and this

485
00:18:48,560 --> 00:18:49,490
ties into sort of that plausible

486
00:18:49,490 --> 00:18:51,500
deniability also and so the solution

487
00:18:51,500 --> 00:18:54,770
approaches here media literacy how do we

488
00:18:54,770 --> 00:18:56,900
label content what is what are the

489
00:18:56,900 --> 00:18:58,160
regulatory frameworks we can build

490
00:18:58,160 --> 00:18:59,750
around this and I think really

491
00:18:59,750 --> 00:19:01,070
importantly how do we build confidence

492
00:19:01,070 --> 00:19:02,030
in people

493
00:19:02,030 --> 00:19:03,980
that they can actually navigate this

494
00:19:03,980 --> 00:19:05,990
train because if they can't then we lose

495
00:19:05,990 --> 00:19:08,180
that we're in that role that plausible

496
00:19:08,180 --> 00:19:11,120
deniability then we looked at crisis

497
00:19:11,120 --> 00:19:12,890
events and so there's three things that

498
00:19:12,890 --> 00:19:14,420
are very interesting about crisis events

499
00:19:14,420 --> 00:19:16,670
which is that scams are more believable

500
00:19:16,670 --> 00:19:18,740
so it's not just the political dissing

501
00:19:18,740 --> 00:19:20,150
formation that's a problem but the ways

502
00:19:20,150 --> 00:19:21,620
in which this actually affects the

503
00:19:21,620 --> 00:19:23,540
likelihood that you know as someone in

504
00:19:23,540 --> 00:19:25,910
the group said their their grandparents

505
00:19:25,910 --> 00:19:27,380
were almost convinced to give people

506
00:19:27,380 --> 00:19:29,090
money under the assumption that that

507
00:19:29,090 --> 00:19:31,270
they had been in a car crash just

508
00:19:31,270 --> 00:19:34,010
through like robocalls without even a

509
00:19:34,010 --> 00:19:36,860
realistic voice saying I'm making them

510
00:19:36,860 --> 00:19:38,420
appear to be that person and so what

511
00:19:38,420 --> 00:19:39,980
happens when we actually have really

512
00:19:39,980 --> 00:19:42,380
believable voices even the mainstream

513
00:19:42,380 --> 00:19:44,360
media is more fool Abul when there's a

514
00:19:44,360 --> 00:19:47,120
crisis happening right now and any

515
00:19:47,120 --> 00:19:48,530
individual is looking for what is the

516
00:19:48,530 --> 00:19:51,500
information that can guide them and so

517
00:19:51,500 --> 00:19:53,450
examples of this are you know thinking

518
00:19:53,450 --> 00:19:55,880
about how could terrorists so even more

519
00:19:55,880 --> 00:19:58,600
confusion and conflict after an attack

520
00:19:58,600 --> 00:20:00,890
how can provocateurs actually take

521
00:20:00,890 --> 00:20:02,930
advantage of the disasters either in

522
00:20:02,930 --> 00:20:05,200
financial ways or in political ways and

523
00:20:05,200 --> 00:20:07,760
there's also these localized issues like

524
00:20:07,760 --> 00:20:10,760
that example with you know can you fish

525
00:20:10,760 --> 00:20:12,740
someone more effectively as a result of

526
00:20:12,740 --> 00:20:14,870
this and you know if you're if you're

527
00:20:14,870 --> 00:20:17,090
dead someone no one can you can't deny

528
00:20:17,090 --> 00:20:18,230
that you said something very effectively

529
00:20:18,230 --> 00:20:19,970
is a deep fake there's a lot of

530
00:20:19,970 --> 00:20:22,010
mitigations here around you know best

531
00:20:22,010 --> 00:20:24,170
practices around crisis scenarios for

532
00:20:24,170 --> 00:20:25,910
publishers for platforms for emergency

533
00:20:25,910 --> 00:20:28,730
responders what are the what are the

534
00:20:28,730 --> 00:20:31,130
ways in which individuals can sort of be

535
00:20:31,130 --> 00:20:32,600
taught almost to first aid to send that

536
00:20:32,600 --> 00:20:35,900
bleeding of misinformation and what are

537
00:20:35,900 --> 00:20:39,800
the what are these sort of the best

538
00:20:39,800 --> 00:20:42,080
practices around transparency that I can

539
00:20:42,080 --> 00:20:43,220
actually facilitate this within the

540
00:20:43,220 --> 00:20:47,570
journalism world and finally this danger

541
00:20:47,570 --> 00:20:49,250
of targeting vulnerable journalists and

542
00:20:49,250 --> 00:20:52,730
activists so you can no longer you know

543
00:20:52,730 --> 00:20:53,930
they need to take a real video like

544
00:20:53,930 --> 00:20:55,130
Project Verret does that have to do in

545
00:20:55,130 --> 00:20:56,870
some sense to create that they can just

546
00:20:56,870 --> 00:20:58,460
use it to fake and so that's a whole new

547
00:20:58,460 --> 00:21:01,070
threat scenario and this can also happen

548
00:21:01,070 --> 00:21:02,480
in niche domains where there isn't that

549
00:21:02,480 --> 00:21:04,610
broad visibility so we might not even

550
00:21:04,610 --> 00:21:06,260
know about it if you're not in that very

551
00:21:06,260 --> 00:21:08,210
particular let's say help domain for

552
00:21:08,210 --> 00:21:10,490
example and you can do this with no cost

553
00:21:10,490 --> 00:21:12,920
and so in order to address this you need

554
00:21:12,920 --> 00:21:14,210
to make this information a beat in

555
00:21:14,210 --> 00:21:15,650
newsrooms both

556
00:21:15,650 --> 00:21:18,530
national and local and we really need to

557
00:21:18,530 --> 00:21:19,850
inoculate media there's actually a great

558
00:21:19,850 --> 00:21:22,160
report on the the broad scope of

559
00:21:22,160 --> 00:21:23,600
disinformation by date in society which

560
00:21:23,600 --> 00:21:25,520
is worth looking at but inoculate media

561
00:21:25,520 --> 00:21:26,630
so they have the resources and support

562
00:21:26,630 --> 00:22:15,400
to take this stuff can goodly labs and

563
00:22:15,400 --> 00:22:20,860
Nick Adams come up here he comes

564
00:22:20,860 --> 00:22:33,540
no thanks

565
00:22:33,540 --> 00:22:36,230
I'll stand here awkwardly for a moment

566
00:22:36,230 --> 00:22:41,190
you may sit there awkwardly here we go

567
00:22:41,190 --> 00:22:43,080
so we had a breakout session where we

568
00:22:43,080 --> 00:22:45,240
were looking at the research tools that

569
00:22:45,240 --> 00:22:46,919
people can use to study disinformation

570
00:22:46,919 --> 00:22:50,190
and in particular to respond to some of

571
00:22:50,190 --> 00:22:52,980
the recent calls for research so I press

572
00:22:52,980 --> 00:22:59,669
a button or do a green button the big

573
00:22:59,669 --> 00:23:03,480
the biggest greenest button okay so we

574
00:23:03,480 --> 00:23:05,370
what we did our in the group is first we

575
00:23:05,370 --> 00:23:07,260
kind of mapped the research funding

576
00:23:07,260 --> 00:23:08,669
landscape so there are a number of

577
00:23:08,669 --> 00:23:10,530
number of requests for proposals out

578
00:23:10,530 --> 00:23:12,540
there right now some very large

579
00:23:12,540 --> 00:23:14,340
prominent ones from the Hewlett

580
00:23:14,340 --> 00:23:17,040
Foundation from social science one which

581
00:23:17,040 --> 00:23:18,929
is a collaboration among multiple

582
00:23:18,929 --> 00:23:21,690
funders and Facebook who's providing

583
00:23:21,690 --> 00:23:23,850
data and then it's all led by the Social

584
00:23:23,850 --> 00:23:25,650
Science Research Council who's kind of

585
00:23:25,650 --> 00:23:28,290
managing that collaboration the whatsapp

586
00:23:28,290 --> 00:23:31,140
call and there was a brand new and from

587
00:23:31,140 --> 00:23:33,210
the night foundation today so we at

588
00:23:33,210 --> 00:23:35,520
least mentioned that one slightly but we

589
00:23:35,520 --> 00:23:36,809
spend a little time just kind of digging

590
00:23:36,809 --> 00:23:38,190
into what are these different funders

591
00:23:38,190 --> 00:23:41,520
looking for and what kinds of strands of

592
00:23:41,520 --> 00:23:42,690
research what particular research

593
00:23:42,690 --> 00:23:45,240
questions are they asking so that

594
00:23:45,240 --> 00:23:47,190
researchers in the room can effectively

595
00:23:47,190 --> 00:23:50,340
respond that next we spent some time

596
00:23:50,340 --> 00:23:51,840
just kind of talking through the various

597
00:23:51,840 --> 00:23:53,100
social science and methods that are

598
00:23:53,100 --> 00:23:54,090
going to be able to answer those

599
00:23:54,090 --> 00:23:55,410
questions making sure we had a

600
00:23:55,410 --> 00:23:57,150
comprehensive understanding of what

601
00:23:57,150 --> 00:24:00,059
those are so as people might do surveys

602
00:24:00,059 --> 00:24:03,780
of folks to see what did they receive a

603
00:24:03,780 --> 00:24:05,549
particular bit of fake news how did they

604
00:24:05,549 --> 00:24:07,169
respond to it what what were their

605
00:24:07,169 --> 00:24:10,020
thoughts about it field experiments

606
00:24:10,020 --> 00:24:11,610
where you could actually launch your own

607
00:24:11,610 --> 00:24:14,429
content and and maybe it's

608
00:24:14,429 --> 00:24:15,179
misinformation

609
00:24:15,179 --> 00:24:17,070
maybe not you could launch it into a

610
00:24:17,070 --> 00:24:19,740
network and into an actual platform like

611
00:24:19,740 --> 00:24:21,390
Facebook and see how people respond

612
00:24:21,390 --> 00:24:24,240
online social experiments where you're

613
00:24:24,240 --> 00:24:25,799
not really working in one of the

614
00:24:25,799 --> 00:24:28,190
platforms but you're still testing some

615
00:24:28,190 --> 00:24:30,480
hypothesis about how people respond to

616
00:24:30,480 --> 00:24:32,690
different types of misinformation

617
00:24:32,690 --> 00:24:35,880
Network analyses to understand how this

618
00:24:35,880 --> 00:24:37,679
information spreads differently through

619
00:24:37,679 --> 00:24:39,299
networks that are constructed in

620
00:24:39,299 --> 00:24:41,659
different ways or take different shapes

621
00:24:41,659 --> 00:24:45,299
and then deep analysis into the content

622
00:24:45,299 --> 00:24:47,500
of misinformation like into

623
00:24:47,500 --> 00:24:50,409
the content of a news story or what we

624
00:24:50,409 --> 00:24:53,110
might differentiate as context analysis

625
00:24:53,110 --> 00:24:55,330
where you're not so much interested in

626
00:24:55,330 --> 00:24:58,120
the content of the article or the claim

627
00:24:58,120 --> 00:25:00,429
that's missing for misinforming you're

628
00:25:00,429 --> 00:25:02,500
interested in how it's couched is it

629
00:25:02,500 --> 00:25:04,690
couched in some other rhetoric is it put

630
00:25:04,690 --> 00:25:07,389
in a particular URL served on a

631
00:25:07,389 --> 00:25:09,309
particular website so we kind of

632
00:25:09,309 --> 00:25:12,039
discussed all of that with the goal

633
00:25:12,039 --> 00:25:15,820
finally of giving an opportunity to to

634
00:25:15,820 --> 00:25:17,740
various different tool providers to show

635
00:25:17,740 --> 00:25:20,830
off how their tools could be effective

636
00:25:20,830 --> 00:25:23,110
for answering research questions using

637
00:25:23,110 --> 00:25:26,830
those methods so some of these we were

638
00:25:26,830 --> 00:25:29,200
able to have demos for others we just

639
00:25:29,200 --> 00:25:31,179
placed the links and if you track

640
00:25:31,179 --> 00:25:33,549
through the documents for you here from

641
00:25:33,549 --> 00:25:34,960
Miss invokana you'll be able to find

642
00:25:34,960 --> 00:25:37,149
these links to various tools that we

643
00:25:37,149 --> 00:25:39,210
think will be effective for those calls

644
00:25:39,210 --> 00:25:41,980
so you can do surveys through these

645
00:25:41,980 --> 00:25:43,389
different tools like Qualtrics and

646
00:25:43,389 --> 00:25:46,059
Survey Monkey online social experiments

647
00:25:46,059 --> 00:25:47,559
breadboard and Challenger we didn't get

648
00:25:47,559 --> 00:25:49,659
to look at those today but we did have

649
00:25:49,659 --> 00:25:51,720
represents from hypothesis and check

650
00:25:51,720 --> 00:25:54,429
show off how their tools can be used for

651
00:25:54,429 --> 00:25:57,690
what we might call this context analysis

652
00:25:57,690 --> 00:26:01,419
check especially allowing these these

653
00:26:01,419 --> 00:26:04,419
kind of tasks runs of tasks that people

654
00:26:04,419 --> 00:26:06,549
can do and that you could actually in

655
00:26:06,549 --> 00:26:07,750
your own researcher you can set up your

656
00:26:07,750 --> 00:26:10,870
own version of this and using their

657
00:26:10,870 --> 00:26:13,210
tools hypothesis allowing people to

658
00:26:13,210 --> 00:26:16,000
anchor their annotations in different

659
00:26:16,000 --> 00:26:17,919
places on the web so that you can trace

660
00:26:17,919 --> 00:26:21,940
through and see how a claim a particular

661
00:26:21,940 --> 00:26:23,950
section of an article might need

662
00:26:23,950 --> 00:26:26,320
debunking for instance instead of just

663
00:26:26,320 --> 00:26:27,549
having to look through the entire

664
00:26:27,549 --> 00:26:31,360
article we showed off the tag works tool

665
00:26:31,360 --> 00:26:34,509
for content analysis which allows a

666
00:26:34,509 --> 00:26:37,389
researcher to direct potentially

667
00:26:37,389 --> 00:26:39,279
hundreds or thousands of people through

668
00:26:39,279 --> 00:26:41,649
their through the Internet to do small

669
00:26:41,649 --> 00:26:43,990
little bits of content analysis that can

670
00:26:43,990 --> 00:26:45,940
then all be statistically stitched back

671
00:26:45,940 --> 00:26:49,330
together so that a very rich deep high

672
00:26:49,330 --> 00:26:52,000
scale content analysis job that would

673
00:26:52,000 --> 00:26:54,460
take years or months to do using old

674
00:26:54,460 --> 00:26:56,169
methods can actually be done in a matter

675
00:26:56,169 --> 00:26:58,960
of weeks or months that's a new tool

676
00:26:58,960 --> 00:27:00,909
that's available we got a great

677
00:27:00,909 --> 00:27:02,110
presentation

678
00:27:02,110 --> 00:27:04,330
from Phil mentor at Indiana University

679
00:27:04,330 --> 00:27:06,910
showing off oxy which is really

680
00:27:06,910 --> 00:27:09,700
fantastic tool for visualizing the

681
00:27:09,700 --> 00:27:11,380
network analyses so you can see the

682
00:27:11,380 --> 00:27:13,450
spread of misinformation through

683
00:27:13,450 --> 00:27:16,360
networks and you can also with Hoke see

684
00:27:16,360 --> 00:27:19,780
you can see which nodes and a network

685
00:27:19,780 --> 00:27:24,460
our box or likely to be bots because his

686
00:27:24,460 --> 00:27:26,080
team has also created this tool called

687
00:27:26,080 --> 00:27:28,870
bought ometer which does bot detection

688
00:27:28,870 --> 00:27:31,180
so it's really those two tools I think

689
00:27:31,180 --> 00:27:32,590
are gonna be incredibly valuable for

690
00:27:32,590 --> 00:27:35,440
anyone who's looking at the spread of

691
00:27:35,440 --> 00:27:37,660
misinformation just information through

692
00:27:37,660 --> 00:27:40,780
a network and finally Rebecca from faker

693
00:27:40,780 --> 00:27:45,040
fact gave us a look into that tool which

694
00:27:45,040 --> 00:27:47,320
can be really useful for just getting a

695
00:27:47,320 --> 00:27:49,270
high level understanding of is the

696
00:27:49,270 --> 00:27:51,520
content from this URL likely to be

697
00:27:51,520 --> 00:27:53,500
misinformation or just information so

698
00:27:53,500 --> 00:27:55,270
maybe a really great first layer of

699
00:27:55,270 --> 00:27:57,640
analysis for any kind of research into

700
00:27:57,640 --> 00:28:00,850
the space everyone was really fantastic

701
00:28:00,850 --> 00:28:03,520
and we learned a lot in the process and

702
00:28:03,520 --> 00:28:05,770
we hope this is valuable for the whole

703
00:28:05,770 --> 00:28:14,650
community thanks Chris an nd I can you

704
00:28:14,650 --> 00:28:17,140
guys come up bridging people and

705
00:28:17,140 --> 00:28:18,610
platforms it's the name of the

706
00:28:18,610 --> 00:28:20,500
presentation by the way DHS do you guys

707
00:28:20,500 --> 00:28:24,820
have a presentation or no you do ok I'll

708
00:28:24,820 --> 00:28:27,450
come talk to you cuz I don't see you

709
00:28:27,450 --> 00:28:30,100
alright can we get we get NDIS

710
00:28:30,100 --> 00:28:33,510
presentation up please

711
00:28:40,840 --> 00:28:43,309
it looks like a trigger for something

712
00:28:43,309 --> 00:28:45,049
okay hi folks

713
00:28:45,049 --> 00:28:47,389
Chris Doulton from NDI I'm really here

714
00:28:47,389 --> 00:28:49,820
not so much with my NDI hat on but

715
00:28:49,820 --> 00:28:52,730
rather with the the design for democracy

716
00:28:52,730 --> 00:28:54,279
coalition which is a new initiative

717
00:28:54,279 --> 00:28:56,240
being started up by a number of

718
00:28:56,240 --> 00:28:58,429
international NGOs designed to kind of

719
00:28:58,429 --> 00:29:00,919
connect the major technology platforms

720
00:29:00,919 --> 00:29:02,509
and folks around the world so talking

721
00:29:02,509 --> 00:29:03,649
about some of these problems with our

722
00:29:03,649 --> 00:29:05,450
group here at Miss info con today so

723
00:29:05,450 --> 00:29:06,940
thanks very much for the opportunity

724
00:29:06,940 --> 00:29:12,769
one of the core issues or whether

725
00:29:12,769 --> 00:29:16,129
clickers work or not the green button

726
00:29:16,129 --> 00:29:19,309
I'm colorblind okay there we go

727
00:29:19,309 --> 00:29:21,409
great Thanks so there's one of the tape

728
00:29:21,409 --> 00:29:22,460
on it which seemed like you might be the

729
00:29:22,460 --> 00:29:24,529
one okay great so basically the kind of

730
00:29:24,529 --> 00:29:26,179
the the core conversation boiled down to

731
00:29:26,179 --> 00:29:28,100
the fact that a lot of the problems that

732
00:29:28,100 --> 00:29:30,230
we face on our technology platforms

733
00:29:30,230 --> 00:29:31,970
today with spread of information or

734
00:29:31,970 --> 00:29:33,769
disinformation or because of a lack of

735
00:29:33,769 --> 00:29:36,409
local context when you take this out

736
00:29:36,409 --> 00:29:37,789
globally like how do you understand

737
00:29:37,789 --> 00:29:40,490
what's going on around the world it has

738
00:29:40,490 --> 00:29:41,840
to be actually specific to every

739
00:29:41,840 --> 00:29:44,570
individuals context so how do we

740
00:29:44,570 --> 00:29:46,039
actually do something about that

741
00:29:46,039 --> 00:29:47,720
so talking through some of the problems

742
00:29:47,720 --> 00:29:51,590
that that manifest because of this lack

743
00:29:51,590 --> 00:29:52,970
of local knowledge

744
00:29:52,970 --> 00:29:55,159
you know the algorithms are not usually

745
00:29:55,159 --> 00:29:57,559
fueled with local languages so hate

746
00:29:57,559 --> 00:30:00,470
speech threatening speech markers for

747
00:30:00,470 --> 00:30:02,710
disinformation are not necessarily

748
00:30:02,710 --> 00:30:05,210
recognized and if they're shared in

749
00:30:05,210 --> 00:30:07,909
local languages the the challenge is

750
00:30:07,909 --> 00:30:10,460
what content sources are bogus or

751
00:30:10,460 --> 00:30:12,559
legitimate requires a lot of local

752
00:30:12,559 --> 00:30:15,049
context the knowing the democratic

753
00:30:15,049 --> 00:30:18,110
schisms excuse me demographic targeting

754
00:30:18,110 --> 00:30:20,690
schisms in one particular society that

755
00:30:20,690 --> 00:30:23,539
might be used for incitement or more

756
00:30:23,539 --> 00:30:25,970
dangerous trends could be it is also

757
00:30:25,970 --> 00:30:29,200
something locally dependent and how

758
00:30:29,200 --> 00:30:31,100
people react disinformation

759
00:30:31,100 --> 00:30:33,799
misinformation what what works for

760
00:30:33,799 --> 00:30:36,679
debunking or not in it also depends very

761
00:30:36,679 --> 00:30:39,110
much on the local context there's some

762
00:30:39,110 --> 00:30:40,970
other problems we see that we've

763
00:30:40,970 --> 00:30:42,710
discussed a little bit around our table

764
00:30:42,710 --> 00:30:45,230
today how do we how do grassroots groups

765
00:30:45,230 --> 00:30:47,539
get their problems solved should I be

766
00:30:47,539 --> 00:30:49,190
microphone in is it better if I stand

767
00:30:49,190 --> 00:30:51,289
here okay sorry about that I didn't

768
00:30:51,289 --> 00:30:52,340
think about that

769
00:30:52,340 --> 00:30:54,830
okay so I'm a wanderer on platform but

770
00:30:54,830 --> 00:30:56,029
I'll try and keep myself anchored here

771
00:30:56,029 --> 00:30:58,789
so problems that they are encountered at

772
00:30:58,789 --> 00:31:00,890
the grassroots level go into often

773
00:31:00,890 --> 00:31:03,350
opaque resolution processes and are not

774
00:31:03,350 --> 00:31:05,029
what happens to them are a little bit

775
00:31:05,029 --> 00:31:09,049
limited the research and access to data

776
00:31:09,049 --> 00:31:11,330
is a big big conversation topic here

777
00:31:11,330 --> 00:31:12,950
today but it's also particularly true

778
00:31:12,950 --> 00:31:14,210
for local groups who may have the

779
00:31:14,210 --> 00:31:16,429
knowledge to kind of put things in a

780
00:31:16,429 --> 00:31:19,090
context and then local fact-checking

781
00:31:19,090 --> 00:31:22,640
so one of our core core conversations

782
00:31:22,640 --> 00:31:25,130
insights the idea that connections with

783
00:31:25,130 --> 00:31:26,750
grass local grassroots groups can make

784
00:31:26,750 --> 00:31:27,620
things better

785
00:31:27,620 --> 00:31:30,380
every platforms have an obligation to

786
00:31:30,380 --> 00:31:32,149
really understand their global their

787
00:31:32,149 --> 00:31:34,640
global footprint and be able to kind of

788
00:31:34,640 --> 00:31:37,190
think about things in a in a local

789
00:31:37,190 --> 00:31:39,289
context but we recognize that you know

790
00:31:39,289 --> 00:31:40,309
with the exception of some of the real

791
00:31:40,309 --> 00:31:42,350
Titans not everybody can and probably

792
00:31:42,350 --> 00:31:44,450
nobody should have an office in each

793
00:31:44,450 --> 00:31:46,220
individual country but how do you

794
00:31:46,220 --> 00:31:49,190
actually tap into the local knowledge to

795
00:31:49,190 --> 00:31:51,490
inform all these different challenges so

796
00:31:51,490 --> 00:31:53,899
connecting with local grassroots groups

797
00:31:53,899 --> 00:31:55,370
can help bridge some of these gaps if

798
00:31:55,370 --> 00:31:56,630
they have the right sort of transmission

799
00:31:56,630 --> 00:31:58,549
mechanisms to grab that information push

800
00:31:58,549 --> 00:32:01,340
it up so some of the things that we're

801
00:32:01,340 --> 00:32:03,110
hoping could be solutions to some of

802
00:32:03,110 --> 00:32:05,960
these challenges so better access to

803
00:32:05,960 --> 00:32:09,110
research creation of a a hot line to

804
00:32:09,110 --> 00:32:11,360
solve to elevate problems being seen

805
00:32:11,360 --> 00:32:13,100
particularly by some of the most

806
00:32:13,100 --> 00:32:16,010
vulnerable grassroots democratic or

807
00:32:16,010 --> 00:32:19,580
human rights organizations who often are

808
00:32:19,580 --> 00:32:21,470
faced problems that need a really

809
00:32:21,470 --> 00:32:24,500
time-sensitive resolution being able to

810
00:32:24,500 --> 00:32:26,270
try and work with local groups to build

811
00:32:26,270 --> 00:32:28,760
out lexicons of what like threatening

812
00:32:28,760 --> 00:32:30,679
speech looks like and I like an

813
00:32:30,679 --> 00:32:32,240
indigenous language context or other

814
00:32:32,240 --> 00:32:33,080
things like that

815
00:32:33,080 --> 00:32:34,820
which requires knowledge from the

816
00:32:34,820 --> 00:32:36,740
platforms like what is it that you need

817
00:32:36,740 --> 00:32:38,240
for your algorithms how do we build that

818
00:32:38,240 --> 00:32:40,039
information out and then working with

819
00:32:40,039 --> 00:32:41,809
local fact checkers to try and help

820
00:32:41,809 --> 00:32:43,520
build their capacity and think more

821
00:32:43,520 --> 00:32:45,260
broadly about fact checking is

822
00:32:45,260 --> 00:32:48,260
disinformation analysis and what what we

823
00:32:48,260 --> 00:32:51,039
can do with that few other thoughts

824
00:32:51,039 --> 00:32:53,779
trying to understand what the the local

825
00:32:53,779 --> 00:32:56,120
bogus sites are in a given country

826
00:32:56,120 --> 00:32:57,620
context to try and make sure that

827
00:32:57,620 --> 00:32:59,720
advertising dollars do not flow into

828
00:32:59,720 --> 00:33:02,690
into those sources to kind of remove

829
00:33:02,690 --> 00:33:04,190
some of the monetary incentives to

830
00:33:04,190 --> 00:33:05,990
things

831
00:33:05,990 --> 00:33:07,670
people know a little bit letting the

832
00:33:07,670 --> 00:33:09,140
platform's know especially with an

833
00:33:09,140 --> 00:33:11,390
upcoming say election or other kind of

834
00:33:11,390 --> 00:33:13,100
divisive political event or a crisis

835
00:33:13,100 --> 00:33:15,890
what are some of the demographic schisms

836
00:33:15,890 --> 00:33:19,040
that might be targeted for with with

837
00:33:19,040 --> 00:33:22,429
malevolent intent trying to do research

838
00:33:22,429 --> 00:33:25,010
that's really on a locality basis for

839
00:33:25,010 --> 00:33:27,890
like what are the kind of the methods of

840
00:33:27,890 --> 00:33:29,750
disinformation flow what are the kind of

841
00:33:29,750 --> 00:33:31,120
vulnerabilities and then trying to

842
00:33:31,120 --> 00:33:36,290
target I Media literacy micro campaigns

843
00:33:36,290 --> 00:33:39,140
in that particular local context so a

844
00:33:39,140 --> 00:33:40,640
lot of different challenges we've seen

845
00:33:40,640 --> 00:33:43,190
so trying to think about what we can do

846
00:33:43,190 --> 00:33:46,490
with that so again a little sign for

847
00:33:46,490 --> 00:33:49,040
democracy coalition would love to chat

848
00:33:49,040 --> 00:33:50,690
with any of you folks about how to take

849
00:33:50,690 --> 00:33:52,100
these ideas and elevate them the core

850
00:33:52,100 --> 00:33:53,840
right the core concept is that we've got

851
00:33:53,840 --> 00:33:55,910
a pre-existing connection to the right

852
00:33:55,910 --> 00:33:57,950
people at the right platforms and so I'm

853
00:33:57,950 --> 00:33:59,270
going to be starting by taking these

854
00:33:59,270 --> 00:34:00,860
ideas and these suggestions we've

855
00:34:00,860 --> 00:34:02,600
discussed here today and bringing them

856
00:34:02,600 --> 00:34:04,160
up with them would love to get other

857
00:34:04,160 --> 00:34:06,890
people involved in that process and

858
00:34:06,890 --> 00:34:08,449
trying to share some of these issues and

859
00:34:08,449 --> 00:34:09,739
other ones that will come up in the

860
00:34:09,739 --> 00:34:12,139
future so thanks all very much

861
00:34:12,139 --> 00:34:13,399
appreciate it and thanks for the

862
00:34:13,399 --> 00:34:20,899
opportunity to be here today that's

863
00:34:20,899 --> 00:34:21,859
great thank you Chris

864
00:34:21,859 --> 00:34:23,929
I've DHS could come up there's our final

865
00:34:23,929 --> 00:34:26,750
presentation of the day Clara this is

866
00:34:26,750 --> 00:34:31,369
fantastic our last presentation so if

867
00:34:31,369 --> 00:34:33,409
you load up that one AV team by the way

868
00:34:33,409 --> 00:34:35,179
I just want to make a another quick plug

869
00:34:35,179 --> 00:34:36,469
I've had a lot of quick plugs but

870
00:34:36,469 --> 00:34:39,350
another one missus infocomm every one

871
00:34:39,350 --> 00:34:41,418
should go there it's a it's the Malcolm

872
00:34:41,418 --> 00:34:43,699
of a bunch of different articles that

873
00:34:43,699 --> 00:34:45,379
people right around this information and

874
00:34:45,379 --> 00:34:47,389
we want all of you to contribute to that

875
00:34:47,389 --> 00:34:50,719
so it's medium based and you should

876
00:34:50,719 --> 00:34:54,139
write on medium and then email me and we

877
00:34:54,139 --> 00:34:57,260
will we will put it up there on missing

878
00:34:57,260 --> 00:34:58,970
folk on comm so if you want something

879
00:34:58,970 --> 00:35:01,570
published on our main medium site please

880
00:35:01,570 --> 00:35:04,280
write it on medium and then email me and

881
00:35:04,280 --> 00:35:06,859
and we can make it happen so with that

882
00:35:06,859 --> 00:35:14,750
being said DHS thank you so much so my

883
00:35:14,750 --> 00:35:16,369
name is Clara it's how I'm here with my

884
00:35:16,369 --> 00:35:18,260
colleague Rob and we are from the

885
00:35:18,260 --> 00:35:21,670
HS countering for an influence taskforce

886
00:35:21,670 --> 00:35:24,950
during our workshop we asked the

887
00:35:24,950 --> 00:35:28,400
workshop participants to response some

888
00:35:28,400 --> 00:35:29,990
case studies that we had developed as a

889
00:35:29,990 --> 00:35:33,410
team so Phil he is going to actually go

890
00:35:33,410 --> 00:35:36,380
over some of the responses so I'm Phil

891
00:35:36,380 --> 00:35:38,750
Anderson from the State Department and

892
00:35:38,750 --> 00:35:40,220
I'm gonna be going over some of the case

893
00:35:40,220 --> 00:35:41,930
studies that we had and some of the sort

894
00:35:41,930 --> 00:35:43,250
of brainstorming sessions we pulled

895
00:35:43,250 --> 00:35:46,460
together and sort of the approach we

896
00:35:46,460 --> 00:35:48,830
took to this was a framework that DHS

897
00:35:48,830 --> 00:36:13,880
has been display the image that we okay

898
00:36:13,880 --> 00:36:16,520
so well this is looking at is

899
00:36:16,520 --> 00:36:18,230
essentially a framework of how to

900
00:36:18,230 --> 00:36:20,140
approach misinformation disinformation

901
00:36:20,140 --> 00:36:23,240
with a particular eye towards risk

902
00:36:23,240 --> 00:36:25,750
management especially from DHS's

903
00:36:25,750 --> 00:36:28,190
perspective and the three stages where

904
00:36:28,190 --> 00:36:30,530
research in logistics production and

905
00:36:30,530 --> 00:36:33,740
then publication and amplification and

906
00:36:33,740 --> 00:36:35,180
you don't really have to read all of the

907
00:36:35,180 --> 00:36:36,830
little pieces that are in there but that

908
00:36:36,830 --> 00:36:38,960
is the order of the Chevron's as they go

909
00:36:38,960 --> 00:36:41,330
across and the idea was can we look at

910
00:36:41,330 --> 00:36:43,400
each one of these three pieces and come

911
00:36:43,400 --> 00:36:44,930
up with ways to respond to it or

912
00:36:44,930 --> 00:36:47,360
research it or sort of create some

913
00:36:47,360 --> 00:36:49,010
open-ended questions for things we'd

914
00:36:49,010 --> 00:36:50,960
like you know all the great partners

915
00:36:50,960 --> 00:36:52,370
that are here and other open source

916
00:36:52,370 --> 00:36:54,170
groups and corporations to take a look

917
00:36:54,170 --> 00:36:56,300
at and the first case study we were

918
00:36:56,300 --> 00:36:58,070
talking about was the scree Paul

919
00:36:58,070 --> 00:37:00,170
poisoning in Salisbury and the

920
00:37:00,170 --> 00:37:02,870
disinformation surrounding that so under

921
00:37:02,870 --> 00:37:05,150
the research and logistics section some

922
00:37:05,150 --> 00:37:06,950
of the ideas that the group came up with

923
00:37:06,950 --> 00:37:09,620
were formalized network analysis

924
00:37:09,620 --> 00:37:11,600
techniques for seeing what the

925
00:37:11,600 --> 00:37:14,420
communities are which ones may be primed

926
00:37:14,420 --> 00:37:16,660
for accepting or sharing disinformation

927
00:37:16,660 --> 00:37:19,550
sort of the idea of how does a topic or

928
00:37:19,550 --> 00:37:21,200
a narrative propagate throughout these

929
00:37:21,200 --> 00:37:23,330
communities especially in a crisis

930
00:37:23,330 --> 00:37:24,740
situation which Aviv was speaking to a

931
00:37:24,740 --> 00:37:27,560
little bit earlier the another one was

932
00:37:27,560 --> 00:37:29,180
inoculating the audience ahead of time

933
00:37:29,180 --> 00:37:31,220
so this could be either a longer-term

934
00:37:31,220 --> 00:37:31,880
camp

935
00:37:31,880 --> 00:37:34,490
along the media literacy side of things

936
00:37:34,490 --> 00:37:37,220
or more of a direct and acute response

937
00:37:37,220 --> 00:37:41,359
to disinformation that's coming up some

938
00:37:41,359 --> 00:37:43,039
other topics were a little broader was

939
00:37:43,039 --> 00:37:46,339
these new threat awareness channels that

940
00:37:46,339 --> 00:37:48,529
may be ways for groups to share

941
00:37:48,529 --> 00:37:50,779
information on the research and

942
00:37:50,779 --> 00:37:52,700
logistics side similar to how you know

943
00:37:52,700 --> 00:37:54,230
cybersecurity information is shared

944
00:37:54,230 --> 00:37:56,359
between corporations between governments

945
00:37:56,359 --> 00:37:58,250
kind of creating this environment where

946
00:37:58,250 --> 00:37:59,990
people feel more comfortable sharing

947
00:37:59,990 --> 00:38:02,240
vulnerabilities in ways that you might

948
00:38:02,240 --> 00:38:04,940
be able to respond to them and then sort

949
00:38:04,940 --> 00:38:06,259
of that overall idea is just increased

950
00:38:06,259 --> 00:38:08,990
skepticism about these sort of topics

951
00:38:08,990 --> 00:38:10,730
and how people respond to them when they

952
00:38:10,730 --> 00:38:12,470
see this popping up in their channels

953
00:38:12,470 --> 00:38:16,099
the second side was on production and so

954
00:38:16,099 --> 00:38:17,480
this is how do you respond or

955
00:38:17,480 --> 00:38:19,400
investigate the content itself and how

956
00:38:19,400 --> 00:38:22,309
it's being shared in the initial phase

957
00:38:22,309 --> 00:38:24,500
so a great idea we had was this

958
00:38:24,500 --> 00:38:26,779
misinformation core or I guess a counter

959
00:38:26,779 --> 00:38:28,789
misinformation core the other side is

960
00:38:28,789 --> 00:38:30,710
the misinformation core and so this

961
00:38:30,710 --> 00:38:32,839
would help sort of be a crowd-sourced

962
00:38:32,839 --> 00:38:35,240
and open group of people that are able

963
00:38:35,240 --> 00:38:37,849
to be deployed into these sort of acute

964
00:38:37,849 --> 00:38:39,319
situations or these crisis scenarios

965
00:38:39,319 --> 00:38:40,700
that might be happening it could be

966
00:38:40,700 --> 00:38:42,319
journalists it could be something

967
00:38:42,319 --> 00:38:44,240
similar to a Wikipedia editing system

968
00:38:44,240 --> 00:38:45,769
and so these people can sort of be

969
00:38:45,769 --> 00:38:47,150
called up when something starts to pop

970
00:38:47,150 --> 00:38:49,309
off to help provide additional support

971
00:38:49,309 --> 00:38:51,980
for governments or corporations or or

972
00:38:51,980 --> 00:38:53,960
journalistic outfits as they respond

973
00:38:53,960 --> 00:38:55,849
some of the broader ones as well we're

974
00:38:55,849 --> 00:38:57,529
investing journalism that's a great one

975
00:38:57,529 --> 00:39:00,259
a big part of this is get that gets

976
00:39:00,259 --> 00:39:02,029
skipped over is just you know a lot of

977
00:39:02,029 --> 00:39:03,680
small papers are shutting down smaller

978
00:39:03,680 --> 00:39:05,900
outlets are being consolidated and

979
00:39:05,900 --> 00:39:07,609
actually providing a lot of resources to

980
00:39:07,609 --> 00:39:09,950
on-the-ground local journalists is one

981
00:39:09,950 --> 00:39:11,450
of the best ways to produce these credit

982
00:39:11,450 --> 00:39:13,700
credible voices in local communities

983
00:39:13,700 --> 00:39:15,859
which then spread to the online sphere

984
00:39:15,859 --> 00:39:18,890
as well we also moved a little bit into

985
00:39:18,890 --> 00:39:20,480
the offline and talking more about

986
00:39:20,480 --> 00:39:23,210
bilateral bilateral understanding and

987
00:39:23,210 --> 00:39:24,829
collaborations between governments and

988
00:39:24,829 --> 00:39:26,480
possibly between international

989
00:39:26,480 --> 00:39:29,059
corporations so we had an example of the

990
00:39:29,059 --> 00:39:31,700
German and Polish sort of

991
00:39:31,700 --> 00:39:36,079
non-interference agreements that that

992
00:39:36,079 --> 00:39:37,430
came about during World War Two and

993
00:39:37,430 --> 00:39:39,319
similar ones that exists now and is

994
00:39:39,319 --> 00:39:41,000
there a way to sort of formalize this in

995
00:39:41,000 --> 00:39:44,210
treaties or at least you know statement

996
00:39:44,210 --> 00:39:45,470
saying we're not going to actively in

997
00:39:45,470 --> 00:39:47,210
fear if that happens we'll have these

998
00:39:47,210 --> 00:39:48,920
sort of hotlines for communication to

999
00:39:48,920 --> 00:39:49,940
try and deconflict

1000
00:39:49,940 --> 00:39:52,130
and then some of the usual you know

1001
00:39:52,130 --> 00:39:54,170
looking at verified accounts ways to

1002
00:39:54,170 --> 00:39:55,940
verify websites and some of the other

1003
00:39:55,940 --> 00:39:57,230
tools that we've seen in previous

1004
00:39:57,230 --> 00:39:59,270
presentations then we get to the

1005
00:39:59,270 --> 00:40:01,280
publication and amplification side and

1006
00:40:01,280 --> 00:40:03,980
two ideas we had there was a data vacuum

1007
00:40:03,980 --> 00:40:07,730
so when a crisis event starts sort of

1008
00:40:07,730 --> 00:40:09,260
the first mover often has an advantage

1009
00:40:09,260 --> 00:40:12,140
so a shooters name or a location of an

1010
00:40:12,140 --> 00:40:14,210
attack whoever can sort of flood that

1011
00:40:14,210 --> 00:40:17,300
keyword the fastest often gets sort of

1012
00:40:17,300 --> 00:40:18,980
the advantage in the first few hours and

1013
00:40:18,980 --> 00:40:20,630
are there ways to work with companies to

1014
00:40:20,630 --> 00:40:22,790
change algorithms or put the brakes a

1015
00:40:22,790 --> 00:40:24,920
little bit on how those topics move to

1016
00:40:24,920 --> 00:40:26,690
the top of people's feeds or people's

1017
00:40:26,690 --> 00:40:29,990
search results the second case study we

1018
00:40:29,990 --> 00:40:31,849
were looking at was the Louisiana Ken

1019
00:40:31,849 --> 00:40:36,349
chemical attack which was in 2014 2014

1020
00:40:36,349 --> 00:40:38,359
and basically it's a little different

1021
00:40:38,359 --> 00:40:40,520
the idea behind this was there was a

1022
00:40:40,520 --> 00:40:43,160
video that was real it was a real video

1023
00:40:43,160 --> 00:40:46,070
but from a different event and people

1024
00:40:46,070 --> 00:40:53,330
receive self how did we do that one more

1025
00:40:53,330 --> 00:40:56,720
son yep and so this was a very short of

1026
00:40:56,720 --> 00:40:59,780
short turnaround disinformation campaign

1027
00:40:59,780 --> 00:41:01,940
happen you know from beginning to end

1028
00:41:01,940 --> 00:41:03,710
within a few hours there obviously you

1029
00:41:03,710 --> 00:41:06,080
know latent results after the fact but

1030
00:41:06,080 --> 00:41:08,270
people started getting text messages

1031
00:41:08,270 --> 00:41:10,339
saying there was an attack on a local

1032
00:41:10,339 --> 00:41:13,490
chemical plant videos out of context

1033
00:41:13,490 --> 00:41:17,330
were shared online journalists and sort

1034
00:41:17,330 --> 00:41:19,940
of influencers on various platforms were

1035
00:41:19,940 --> 00:41:21,830
reached out to directly for response to

1036
00:41:21,830 --> 00:41:23,660
this attack some of them did respond

1037
00:41:23,660 --> 00:41:25,430
some of them didn't but it had a very

1038
00:41:25,430 --> 00:41:27,650
sort of direct impact on the ground of

1039
00:41:27,650 --> 00:41:29,720
people sharing this you know some panic

1040
00:41:29,720 --> 00:41:31,160
people are reaching out to the police

1041
00:41:31,160 --> 00:41:33,349
and DHS and government officials asking

1042
00:41:33,349 --> 00:41:35,210
about should they evacuate should they

1043
00:41:35,210 --> 00:41:36,500
shelter in place how do you deal with

1044
00:41:36,500 --> 00:41:38,750
this poison gas cloud that's got to be

1045
00:41:38,750 --> 00:41:43,130
drifting over their community and so at

1046
00:41:43,130 --> 00:41:44,690
first people thought it was sort of a

1047
00:41:44,690 --> 00:41:46,640
hoax more on the fore chanting kind of

1048
00:41:46,640 --> 00:41:49,310
side got one minute left but it turned

1049
00:41:49,310 --> 00:41:52,880
out it was a Russian campaign so it sort

1050
00:41:52,880 --> 00:41:55,040
of expanded the research into it and say

1051
00:41:55,040 --> 00:41:56,510
you know looking into why might someone

1052
00:41:56,510 --> 00:41:58,020
want to do this

1053
00:41:58,020 --> 00:41:59,790
a lot of these responses we came up with

1054
00:41:59,790 --> 00:42:01,350
were similar a few of the new ones we're

1055
00:42:01,350 --> 00:42:04,920
looking at these known or band known

1056
00:42:04,920 --> 00:42:06,540
accounts that were banned can we help

1057
00:42:06,540 --> 00:42:08,700
trance Mei models or some L group some

1058
00:42:08,700 --> 00:42:10,290
newer algorithms to detect that ahead of

1059
00:42:10,290 --> 00:42:12,960
time also looking at sort of the non

1060
00:42:12,960 --> 00:42:15,330
social media space so how does this get

1061
00:42:15,330 --> 00:42:17,460
shared by word of mouth what are ways of

1062
00:42:17,460 --> 00:42:19,530
responding to SMS based disinformation

1063
00:42:19,530 --> 00:42:22,440
or even phone call based disinformation

1064
00:42:22,440 --> 00:42:24,300
so you can see you know if something

1065
00:42:24,300 --> 00:42:26,760
like an Amber Alert or reverse 9-1-1

1066
00:42:26,760 --> 00:42:28,860
call to immediately respond to people

1067
00:42:28,860 --> 00:42:31,310
who received these fake text messages

1068
00:42:31,310 --> 00:42:33,540
one idea under production we thought was

1069
00:42:33,540 --> 00:42:35,070
cool was this hoax wire service so

1070
00:42:35,070 --> 00:42:37,230
similar to an AP wire can you have some

1071
00:42:37,230 --> 00:42:39,330
kind of RSS feed or a real-time updated

1072
00:42:39,330 --> 00:42:42,810
feed that a collaboration of journalists

1073
00:42:42,810 --> 00:42:45,030
get together to produce saying here all

1074
00:42:45,030 --> 00:42:47,310
the hoaxes as we see in real-time these

1075
00:42:47,310 --> 00:42:48,750
are the ones that are popping up so all

1076
00:42:48,750 --> 00:42:51,030
the other journalists know what not to

1077
00:42:51,030 --> 00:42:52,680
respond to or what isn't actually

1078
00:42:52,680 --> 00:42:54,600
accurate in the information space and

1079
00:42:54,600 --> 00:42:58,470
then in publication and amplification we

1080
00:42:58,470 --> 00:43:00,390
looked into getting the ground truth out

1081
00:43:00,390 --> 00:43:03,060
faster and how you sort of create an

1082
00:43:03,060 --> 00:43:04,080
environment where it's more successful

1083
00:43:04,080 --> 00:43:06,660
and then also the idea of being able to

1084
00:43:06,660 --> 00:43:08,460
detect these sort of fake sockpuppet

1085
00:43:08,460 --> 00:43:10,800
when websites ahead of time so can you

1086
00:43:10,800 --> 00:43:12,240
see how people are laying the groundwork

1087
00:43:12,240 --> 00:43:13,950
for future disinformation campaigns

1088
00:43:13,950 --> 00:43:15,420
that's probably about the end of the

1089
00:43:15,420 --> 00:43:16,560
time but I wanted to say from my

1090
00:43:16,560 --> 00:43:18,750
perspective if Lee says convening body

1091
00:43:18,750 --> 00:43:20,400
at state and the convening body at DHS

1092
00:43:20,400 --> 00:43:21,900
that sort of bringing all these people

1093
00:43:21,900 --> 00:43:23,550
together to talk about these ideas is

1094
00:43:23,550 --> 00:43:25,560
exactly what we're looking for sort of

1095
00:43:25,560 --> 00:43:26,910
pulling all the tools and people and

1096
00:43:26,910 --> 00:43:28,950
resources together so feel free to reach

1097
00:43:28,950 --> 00:43:31,470
out and we would love feedback on

1098
00:43:31,470 --> 00:43:32,850
whether this is the right framework

1099
00:43:32,850 --> 00:43:34,950
around you know this research and

1100
00:43:34,950 --> 00:43:38,149
positioning and then to

