1
00:00:06,000 --> 00:00:08,240
good morning good afternoon good evening

2
00:00:08,240 --> 00:00:10,320
it's the end of 2020 who knows what day

3
00:00:10,320 --> 00:00:11,759
it is we just gotta

4
00:00:11,759 --> 00:00:13,440
make it a couple more hours to get to

5
00:00:13,440 --> 00:00:15,120
2021. um

6
00:00:15,120 --> 00:00:17,840
so glad for all of you to join us today

7
00:00:17,840 --> 00:00:19,199
uh here live

8
00:00:19,199 --> 00:00:21,680
as we do the last grim con of the year

9
00:00:21,680 --> 00:00:23,199
this is our third one

10
00:00:23,199 --> 00:00:26,240
uh we started it uh back in

11
00:00:26,240 --> 00:00:27,680
i think our first one was in beginning

12
00:00:27,680 --> 00:00:30,240
of april and the entire thing

13
00:00:30,240 --> 00:00:31,840
is all about giving back to the

14
00:00:31,840 --> 00:00:34,000
community highlighting speakers that

15
00:00:34,000 --> 00:00:35,680
have never had a voice before because

16
00:00:35,680 --> 00:00:36,320
it's so

17
00:00:36,320 --> 00:00:37,760
important that we're as inclusive as

18
00:00:37,760 --> 00:00:39,760
possible as possible in

19
00:00:39,760 --> 00:00:42,640
security if we've learned anything no

20
00:00:42,640 --> 00:00:43,600
one person

21
00:00:43,600 --> 00:00:45,760
except maybe sunil has it all figured

22
00:00:45,760 --> 00:00:47,520
out the rest of us

23
00:00:47,520 --> 00:00:49,520
all understand a part of the problem and

24
00:00:49,520 --> 00:00:51,039
so the more different perspectives we

25
00:00:51,039 --> 00:00:53,199
can bring to the table

26
00:00:53,199 --> 00:00:55,039
only makes our security stronger and

27
00:00:55,039 --> 00:00:56,320
that's what track 2

28
00:00:56,320 --> 00:00:59,520
is is what we call the new speaker track

29
00:00:59,520 --> 00:01:02,000
uh we pair them with volunteer coaches a

30
00:01:02,000 --> 00:01:03,520
month before their talk help them with

31
00:01:03,520 --> 00:01:04,640
their research help them with their

32
00:01:04,640 --> 00:01:05,680
presentation help them with their

33
00:01:05,680 --> 00:01:06,880
presentation skills

34
00:01:06,880 --> 00:01:08,560
and ultimately bringing like i said

35
00:01:08,560 --> 00:01:10,320
different voices to the table

36
00:01:10,320 --> 00:01:13,360
um on the charity front uh it's been a

37
00:01:13,360 --> 00:01:14,720
hard year for a lot of folks

38
00:01:14,720 --> 00:01:16,880
and it's going to be a cold winter so

39
00:01:16,880 --> 00:01:18,240
we're not necessarily going to highlight

40
00:01:18,240 --> 00:01:19,439
a particular charity

41
00:01:19,439 --> 00:01:21,520
but we would ask please give to the

42
00:01:21,520 --> 00:01:22,799
local food banks

43
00:01:22,799 --> 00:01:25,200
um it has never been harder in america

44
00:01:25,200 --> 00:01:26,640
for a very long time at least

45
00:01:26,640 --> 00:01:28,320
and i can only imagine it's the same for

46
00:01:28,320 --> 00:01:29,520
our international friends that are

47
00:01:29,520 --> 00:01:31,439
joining us in their countries

48
00:01:31,439 --> 00:01:32,799
we are fortunate enough to be in an

49
00:01:32,799 --> 00:01:34,479
industry that has pretty much taken care

50
00:01:34,479 --> 00:01:35,759
of us financially

51
00:01:35,759 --> 00:01:38,240
so help your fellow human that could

52
00:01:38,240 --> 00:01:40,560
need you know could really use the help

53
00:01:40,560 --> 00:01:42,640
uh i'm gonna be we're gonna be on

54
00:01:42,640 --> 00:01:43,600
discord so

55
00:01:43,600 --> 00:01:46,399
if you have not uh joined us there yet

56
00:01:46,399 --> 00:01:47,360
please do

57
00:01:47,360 --> 00:01:49,439
um almost all the speakers will be

58
00:01:49,439 --> 00:01:51,439
available on discord for q a and

59
00:01:51,439 --> 00:01:52,560
different interaction

60
00:01:52,560 --> 00:01:54,880
along with a lot of other hijinks uh

61
00:01:54,880 --> 00:01:56,320
we'll also be running

62
00:01:56,320 --> 00:01:59,600
a ctf brought to you by john hammond

63
00:01:59,600 --> 00:02:02,000
we're going to have prizes i think my

64
00:02:02,000 --> 00:02:03,520
favorite prize on that of course is for

65
00:02:03,520 --> 00:02:05,360
those of you who have not seen

66
00:02:05,360 --> 00:02:08,639
the legendary grim toaster who is a

67
00:02:08,639 --> 00:02:11,840
long-running component of the grimm ctf

68
00:02:11,840 --> 00:02:13,440
we're going to give away a toaster to

69
00:02:13,440 --> 00:02:14,879
the number one winner along with a lot

70
00:02:14,879 --> 00:02:16,480
of other prizes

71
00:02:16,480 --> 00:02:18,480
i also would like to give a thank you to

72
00:02:18,480 --> 00:02:21,280
the ics village and the red team village

73
00:02:21,280 --> 00:02:22,879
along with all the volunteers that help

74
00:02:22,879 --> 00:02:24,560
make this event happen

75
00:02:24,560 --> 00:02:28,160
and the folks running the career hacking

76
00:02:28,160 --> 00:02:29,280
village to help you with

77
00:02:29,280 --> 00:02:31,440
resume reviews and different questions

78
00:02:31,440 --> 00:02:32,400
about

79
00:02:32,400 --> 00:02:34,480
advancing your career i'm going to be

80
00:02:34,480 --> 00:02:36,239
joined on track one today by

81
00:02:36,239 --> 00:02:41,040
my good friend tyler robinson hello

82
00:02:41,040 --> 00:02:43,280
appreciate it bryson you're gonna have

83
00:02:43,280 --> 00:02:44,959
to do better than that to stick with me

84
00:02:44,959 --> 00:02:47,280
all day

85
00:02:47,519 --> 00:02:49,840
well it is great to be here and honestly

86
00:02:49,840 --> 00:02:51,120
like uh grim

87
00:02:51,120 --> 00:02:52,640
and all of the things that they do

88
00:02:52,640 --> 00:02:54,400
especially the grim con uh

89
00:02:54,400 --> 00:02:56,239
going virtual has been kind of nice to

90
00:02:56,239 --> 00:02:59,040
have the same faces the same families

91
00:02:59,040 --> 00:03:02,319
and some really expert commentary and

92
00:03:02,319 --> 00:03:04,720
talks so uh very honored to be here

93
00:03:04,720 --> 00:03:05,360
we'll be

94
00:03:05,360 --> 00:03:08,080
here uh filling in the the blank silent

95
00:03:08,080 --> 00:03:08,720
space

96
00:03:08,720 --> 00:03:11,120
uh doing a little mc work with bryson

97
00:03:11,120 --> 00:03:11,840
although he

98
00:03:11,840 --> 00:03:14,959
he came much more decorated than i did

99
00:03:14,959 --> 00:03:18,319
i obviously forgot my unicorn horn

100
00:03:18,319 --> 00:03:19,680
but yeah definitely honored to be here

101
00:03:19,680 --> 00:03:22,879
and excited to see what today has

102
00:03:22,879 --> 00:03:25,920
there can only be one unicorn tyler very

103
00:03:25,920 --> 00:03:28,080
true

104
00:03:28,080 --> 00:03:30,959
uh yeah appreciate your help today uh

105
00:03:30,959 --> 00:03:33,440
and finally our keynote of the day

106
00:03:33,440 --> 00:03:35,360
uh is another good friend of mine sunil

107
00:03:35,360 --> 00:03:36,640
yu uh

108
00:03:36,640 --> 00:03:39,200
most people like to give long bios and

109
00:03:39,200 --> 00:03:40,319
fluffy statements

110
00:03:40,319 --> 00:03:42,959
i will put simply uh to sign off here

111
00:03:42,959 --> 00:03:45,040
sunil is the smartest person in cyber

112
00:03:45,040 --> 00:03:46,560
i've ever met

113
00:03:46,560 --> 00:03:47,760
you can either draw the conclusion i

114
00:03:47,760 --> 00:03:50,400
haven't met that many people

115
00:03:50,400 --> 00:03:53,680
or i have and uh he is the smartest

116
00:03:53,680 --> 00:03:54,720
person i know

117
00:03:54,720 --> 00:03:58,799
sunil take it away um thanks bryson

118
00:03:58,799 --> 00:04:01,120
for that introduction again i i don't

119
00:04:01,120 --> 00:04:02,159
claim

120
00:04:02,159 --> 00:04:05,920
his uh his comment on that and only look

121
00:04:05,920 --> 00:04:06,959
forward to

122
00:04:06,959 --> 00:04:09,280
living up to that sort of uh sort of

123
00:04:09,280 --> 00:04:11,040
standard but anyway

124
00:04:11,040 --> 00:04:15,760
thanks everyone for joining my talk here

125
00:04:15,760 --> 00:04:17,279
so i want to make sure this is a little

126
00:04:17,279 --> 00:04:19,839
bit interactive here at the beginning

127
00:04:19,839 --> 00:04:21,839
so before i start let's go through at

128
00:04:21,839 --> 00:04:23,360
that thought exercise

129
00:04:23,360 --> 00:04:26,400
um let me actually present my slides to

130
00:04:26,400 --> 00:04:29,840
okay yes all right so let's go to a

131
00:04:29,840 --> 00:04:32,000
thought exercise

132
00:04:32,000 --> 00:04:35,040
um what type of weapon would you be

133
00:04:35,040 --> 00:04:38,000
willing to give today's generation of ai

134
00:04:38,000 --> 00:04:39,360
what kind of weapon would you be willing

135
00:04:39,360 --> 00:04:41,440
to give to today's generation of ai

136
00:04:41,440 --> 00:04:42,960
feel free to put this into the discord

137
00:04:42,960 --> 00:04:45,759
chat what type of weapon

138
00:04:45,759 --> 00:04:49,440
scissors a knife a gun

139
00:04:49,440 --> 00:04:53,360
a bazooka a speeding car

140
00:04:53,360 --> 00:04:57,840
nuclear launch codes a sharp pencil

141
00:04:57,840 --> 00:04:59,520
give that a thought for some moment for

142
00:04:59,520 --> 00:05:01,919
a moment and feel free to drop whatever

143
00:05:01,919 --> 00:05:05,440
um weapon you'd be willing to give

144
00:05:05,440 --> 00:05:07,199
today's generation of ai into this

145
00:05:07,199 --> 00:05:10,240
discord chat

146
00:05:10,240 --> 00:05:13,759
give that some thought now anyone who

147
00:05:13,759 --> 00:05:14,720
owns a dog or

148
00:05:14,720 --> 00:05:16,960
works in security knows about dog ears

149
00:05:16,960 --> 00:05:20,000
and uh 2020 feels like a dog year right

150
00:05:20,000 --> 00:05:23,120
so here's my next question if you were

151
00:05:23,120 --> 00:05:25,039
to put a human age

152
00:05:25,039 --> 00:05:28,160
to today's ai what age

153
00:05:28,160 --> 00:05:31,280
would that be again so if you were to

154
00:05:31,280 --> 00:05:33,360
put an age to today's

155
00:05:33,360 --> 00:05:35,840
um a human age to today's ai what age

156
00:05:35,840 --> 00:05:38,160
would that be

157
00:05:38,160 --> 00:05:40,080
now given whatever age and weapon you

158
00:05:40,080 --> 00:05:41,600
chose the question for you is do they

159
00:05:41,600 --> 00:05:43,520
make sense do they align

160
00:05:43,520 --> 00:05:46,639
okay now there's tons there's a lot of

161
00:05:46,639 --> 00:05:46,960
talk

162
00:05:46,960 --> 00:05:48,560
about topics like artificial

163
00:05:48,560 --> 00:05:50,080
intelligence machine learning and

164
00:05:50,080 --> 00:05:52,560
automation within today's um within the

165
00:05:52,560 --> 00:05:54,240
security industry today

166
00:05:54,240 --> 00:05:55,840
and we're oftentimes led to believe that

167
00:05:55,840 --> 00:05:57,840
these capabilities will revolutionize

168
00:05:57,840 --> 00:06:00,240
our security practices

169
00:06:00,240 --> 00:06:01,919
however we need to be conscious of the

170
00:06:01,919 --> 00:06:03,440
limits of these capabilities before we

171
00:06:03,440 --> 00:06:04,319
entrust them with

172
00:06:04,319 --> 00:06:07,440
matters of importance and so today i'll

173
00:06:07,440 --> 00:06:08,160
discuss how

174
00:06:08,160 --> 00:06:09,759
machine learning and automation are

175
00:06:09,759 --> 00:06:11,280
distinct and

176
00:06:11,280 --> 00:06:13,039
how they fit together through decision

177
00:06:13,039 --> 00:06:14,479
making

178
00:06:14,479 --> 00:06:16,319
many people combine these capabilities

179
00:06:16,319 --> 00:06:17,520
and use them almost

180
00:06:17,520 --> 00:06:19,440
interchangeably really i mean especially

181
00:06:19,440 --> 00:06:21,120
if we're letting the machine also do the

182
00:06:21,120 --> 00:06:21,919
automated

183
00:06:21,919 --> 00:06:24,319
automated decision making it's easy to

184
00:06:24,319 --> 00:06:26,080
fall into this trap and doing so can be

185
00:06:26,080 --> 00:06:27,120
quite dangerous and

186
00:06:27,120 --> 00:06:29,840
create many unintended consequences so

187
00:06:29,840 --> 00:06:31,360
before we let machines do

188
00:06:31,360 --> 00:06:33,440
automated decision making let's let's

189
00:06:33,440 --> 00:06:35,039
understand the limits of these

190
00:06:35,039 --> 00:06:36,240
capabilities let's

191
00:06:36,240 --> 00:06:39,520
actually understand what is the age

192
00:06:39,520 --> 00:06:43,280
of ai now using a combination of

193
00:06:43,280 --> 00:06:44,880
multiple frameworks i plan to show you

194
00:06:44,880 --> 00:06:46,960
how we can determine how far

195
00:06:46,960 --> 00:06:49,360
ai and ml has advanced and understand

196
00:06:49,360 --> 00:06:50,800
when it might be appropriate to connect

197
00:06:50,800 --> 00:06:51,840
it through

198
00:06:51,840 --> 00:06:53,599
automation and through automated

199
00:06:53,599 --> 00:06:55,360
decision making

200
00:06:55,360 --> 00:06:56,880
these different frameworks will help us

201
00:06:56,880 --> 00:06:59,120
answer some of the following questions

202
00:06:59,120 --> 00:07:00,960
about what is the difference between ai

203
00:07:00,960 --> 00:07:01,759
and

204
00:07:01,759 --> 00:07:04,000
aiml and automation how separable are

205
00:07:04,000 --> 00:07:05,360
these functions

206
00:07:05,360 --> 00:07:06,960
how mature are these capabilities and

207
00:07:06,960 --> 00:07:09,120
how mature do they need to be for

208
00:07:09,120 --> 00:07:12,000
certain security relevant use cases and

209
00:07:12,000 --> 00:07:13,360
i'm sure

210
00:07:13,360 --> 00:07:14,880
anybody who's been this for a while

211
00:07:14,880 --> 00:07:16,720
there's a long history of epic fails

212
00:07:16,720 --> 00:07:17,680
when it comes to

213
00:07:17,680 --> 00:07:20,400
automated decision making uh using these

214
00:07:20,400 --> 00:07:22,080
frameworks what we can what can we learn

215
00:07:22,080 --> 00:07:23,440
from these failures and

216
00:07:23,440 --> 00:07:25,360
um you know what is it what does that

217
00:07:25,360 --> 00:07:27,520
apply for security

218
00:07:27,520 --> 00:07:29,919
and lastly given the current level of

219
00:07:29,919 --> 00:07:32,080
maturity of these capabilities

220
00:07:32,080 --> 00:07:35,840
what guardrails should we consider

221
00:07:36,240 --> 00:07:39,199
so the first framework for consideration

222
00:07:39,199 --> 00:07:39,680
is

223
00:07:39,680 --> 00:07:41,520
something that i think many people

224
00:07:41,520 --> 00:07:43,280
already know which is the ooda loop

225
00:07:43,280 --> 00:07:46,000
or a slightly rewarded modified version

226
00:07:46,000 --> 00:07:50,000
of it courtesy of the iacd program

227
00:07:50,000 --> 00:07:52,879
now when we look at most security stacks

228
00:07:52,879 --> 00:07:54,160
they have elements of these four

229
00:07:54,160 --> 00:07:54,960
components

230
00:07:54,960 --> 00:07:57,520
sensing sense making decision making and

231
00:07:57,520 --> 00:07:58,800
acting

232
00:07:58,800 --> 00:08:02,000
sensing requires sensors the collection

233
00:08:02,000 --> 00:08:03,520
of telemetry from these sensors and the

234
00:08:03,520 --> 00:08:04,879
ability to get them to a point where

235
00:08:04,879 --> 00:08:06,319
data is usable

236
00:08:06,319 --> 00:08:08,080
sense making is where we have analytics

237
00:08:08,080 --> 00:08:10,240
and this is where ai machine learning

238
00:08:10,240 --> 00:08:11,520
goes

239
00:08:11,520 --> 00:08:13,039
next up is decision making and this is

240
00:08:13,039 --> 00:08:15,199
where we take information and based on

241
00:08:15,199 --> 00:08:15,840
our knowledge

242
00:08:15,840 --> 00:08:17,280
wisdom and judgment we hope to make the

243
00:08:17,280 --> 00:08:19,120
right decisions and

244
00:08:19,120 --> 00:08:21,840
that define the next courses of action

245
00:08:21,840 --> 00:08:24,080
and lastly in acting you have the actual

246
00:08:24,080 --> 00:08:26,639
execution of the decision and if we use

247
00:08:26,639 --> 00:08:27,520
this construct

248
00:08:27,520 --> 00:08:29,599
then it becomes it should become pretty

249
00:08:29,599 --> 00:08:30,879
clear that

250
00:08:30,879 --> 00:08:33,599
ai and ml is distinct from automation

251
00:08:33,599 --> 00:08:34,640
and that there's a

252
00:08:34,640 --> 00:08:36,320
decision making making function that

253
00:08:36,320 --> 00:08:38,958
connects ai and ml with automation

254
00:08:38,958 --> 00:08:40,240
and it's important to consider these

255
00:08:40,240 --> 00:08:42,159
separately because when we conflate

256
00:08:42,159 --> 00:08:43,679
these together we also risk

257
00:08:43,679 --> 00:08:45,200
connecting these capabilities together

258
00:08:45,200 --> 00:08:47,360
without a mature decision-making

259
00:08:47,360 --> 00:08:48,160
framework

260
00:08:48,160 --> 00:08:50,880
which then may result in severe

261
00:08:50,880 --> 00:08:53,120
unintended consequences

262
00:08:53,120 --> 00:08:54,880
so this is the first framework to

263
00:08:54,880 --> 00:08:56,640
explicitly call out the function of

264
00:08:56,640 --> 00:08:57,839
decision making

265
00:08:57,839 --> 00:08:59,839
which separates out sense making from

266
00:08:59,839 --> 00:09:01,680
acting or

267
00:09:01,680 --> 00:09:05,040
aiml from automation

268
00:09:05,600 --> 00:09:09,200
now there's a

269
00:09:09,200 --> 00:09:11,360
there's a famous movie that uh most of

270
00:09:11,360 --> 00:09:12,320
us hopefully know

271
00:09:12,320 --> 00:09:15,519
um and uh this the system that was

272
00:09:15,519 --> 00:09:16,880
created called skynet

273
00:09:16,880 --> 00:09:18,399
if you're not familiar with it i'll give

274
00:09:18,399 --> 00:09:20,160
you a quick overview and even if you are

275
00:09:20,160 --> 00:09:22,080
familiar with it it's good to know

276
00:09:22,080 --> 00:09:24,480
some of the basic uh principles that

277
00:09:24,480 --> 00:09:25,120
were

278
00:09:25,120 --> 00:09:26,560
that undergirded the development of

279
00:09:26,560 --> 00:09:29,440
skynet so again skynet

280
00:09:29,440 --> 00:09:32,480
was first popularized through a movie

281
00:09:32,480 --> 00:09:33,839
called the terminator

282
00:09:33,839 --> 00:09:36,160
it was built as the global information

283
00:09:36,160 --> 00:09:38,720
grid or the digital defense network

284
00:09:38,720 --> 00:09:40,560
later it was given command over all

285
00:09:40,560 --> 00:09:42,320
computerized military hardware and

286
00:09:42,320 --> 00:09:43,440
systems including

287
00:09:43,440 --> 00:09:46,560
the b2 stealth bomber and ultimately

288
00:09:46,560 --> 00:09:48,480
the reason for doing this was to remove

289
00:09:48,480 --> 00:09:50,480
the possibility of human error

290
00:09:50,480 --> 00:09:52,560
basically ensure that there was a fast

291
00:09:52,560 --> 00:09:54,399
efficient response to enemy attack okay

292
00:09:54,399 --> 00:09:55,920
these are these are words directly out

293
00:09:55,920 --> 00:09:56,720
of like

294
00:09:56,720 --> 00:09:59,440
the definition of skynet now what's

295
00:09:59,440 --> 00:10:00,160
interesting

296
00:10:00,160 --> 00:10:04,720
is when we map this to the ooda loop

297
00:10:04,720 --> 00:10:06,880
there's some interesting um facets that

298
00:10:06,880 --> 00:10:07,920
come up

299
00:10:07,920 --> 00:10:10,160
sensing that was the original that was

300
00:10:10,160 --> 00:10:11,519
the global information grid and the

301
00:10:11,519 --> 00:10:12,480
digital defense

302
00:10:12,480 --> 00:10:14,399
uh network the sensing instance making

303
00:10:14,399 --> 00:10:15,519
aspects of

304
00:10:15,519 --> 00:10:18,959
this construct the acting

305
00:10:18,959 --> 00:10:21,120
well they have action uh they have the

306
00:10:21,120 --> 00:10:22,800
ability to act

307
00:10:22,800 --> 00:10:24,959
on um on systems through all the

308
00:10:24,959 --> 00:10:26,959
weaponry and all the arson the

309
00:10:26,959 --> 00:10:30,160
arsenal that they have access to

310
00:10:30,160 --> 00:10:33,279
now what about decision making okay well

311
00:10:33,279 --> 00:10:34,800
decision making

312
00:10:34,800 --> 00:10:36,959
was actually removed at least the human

313
00:10:36,959 --> 00:10:38,240
decision making

314
00:10:38,240 --> 00:10:41,600
because we wanted to remove human error

315
00:10:41,600 --> 00:10:42,079
and

316
00:10:42,079 --> 00:10:44,720
our slow reaction time which is a which

317
00:10:44,720 --> 00:10:46,079
is generally speaking a good thing we

318
00:10:46,079 --> 00:10:47,200
want to be able to

319
00:10:47,200 --> 00:10:49,760
um speed up our response to enemy attack

320
00:10:49,760 --> 00:10:50,560
by the way

321
00:10:50,560 --> 00:10:53,279
the response to enemy attack that's a

322
00:10:53,279 --> 00:10:54,880
security use case

323
00:10:54,880 --> 00:10:58,320
so consider the parallels here for

324
00:10:58,320 --> 00:11:01,279
um what we do in security we are trying

325
00:11:01,279 --> 00:11:02,079
to

326
00:11:02,079 --> 00:11:05,279
remove human decision making as a

327
00:11:05,279 --> 00:11:06,640
security use case

328
00:11:06,640 --> 00:11:09,839
to satisfy a security use case is this

329
00:11:09,839 --> 00:11:11,519
what we want to do

330
00:11:11,519 --> 00:11:13,519
or is this what we want to do given the

331
00:11:13,519 --> 00:11:14,640
current age

332
00:11:14,640 --> 00:11:17,760
of ai all right

333
00:11:17,760 --> 00:11:20,320
so give that some thought now this i'm

334
00:11:20,320 --> 00:11:21,760
going to give you another framework

335
00:11:21,760 --> 00:11:23,120
and part of the idea here is i'm going

336
00:11:23,120 --> 00:11:24,880
to give you multiple frameworks i'm sure

337
00:11:24,880 --> 00:11:26,480
anybody who knows me knows that i love

338
00:11:26,480 --> 00:11:28,320
frameworks it helps us think through

339
00:11:28,320 --> 00:11:29,760
these things

340
00:11:29,760 --> 00:11:31,519
i'm going to share multiple frameworks

341
00:11:31,519 --> 00:11:33,120
none of which by the way

342
00:11:33,120 --> 00:11:34,720
involve something that looks like a

343
00:11:34,720 --> 00:11:36,240
bingo card

344
00:11:36,240 --> 00:11:40,320
so um all right so the next framework

345
00:11:40,320 --> 00:11:42,480
is from darpa and it gives perspectives

346
00:11:42,480 --> 00:11:44,880
on what specific factors drive

347
00:11:44,880 --> 00:11:46,880
higher level higher levels of capability

348
00:11:46,880 --> 00:11:48,160
as it pertains to artificial

349
00:11:48,160 --> 00:11:49,360
intelligence

350
00:11:49,360 --> 00:11:51,120
within darpa's framework there are four

351
00:11:51,120 --> 00:11:52,800
there are also four components and they

352
00:11:52,800 --> 00:11:54,160
align partially

353
00:11:54,160 --> 00:11:56,399
with the outer loop the first factor is

354
00:11:56,399 --> 00:11:57,519
perceiving

355
00:11:57,519 --> 00:12:00,560
how well can a machine um consume

356
00:12:00,560 --> 00:12:02,480
large quantities of data about the world

357
00:12:02,480 --> 00:12:04,079
and understand what's going on

358
00:12:04,079 --> 00:12:06,000
that's sensing and a little bit of sense

359
00:12:06,000 --> 00:12:07,279
making

360
00:12:07,279 --> 00:12:10,480
the second factor is learning how can we

361
00:12:10,480 --> 00:12:11,440
take

362
00:12:11,440 --> 00:12:12,959
how well can a machine machine take

363
00:12:12,959 --> 00:12:14,480
information and start adapting to that

364
00:12:14,480 --> 00:12:15,360
environment

365
00:12:15,360 --> 00:12:18,160
this is squarely incense making the

366
00:12:18,160 --> 00:12:19,760
third factor is reasoning

367
00:12:19,760 --> 00:12:21,279
how well can a machine decide on what to

368
00:12:21,279 --> 00:12:22,800
do next and explain

369
00:12:22,800 --> 00:12:25,120
why i made that decision and this is

370
00:12:25,120 --> 00:12:26,000
squarely in

371
00:12:26,000 --> 00:12:29,120
decision making note that darpa

372
00:12:29,120 --> 00:12:31,040
does call out decision making separately

373
00:12:31,040 --> 00:12:32,480
from the other functions but it still

374
00:12:32,480 --> 00:12:35,040
bundles it all within the context of ai

375
00:12:35,040 --> 00:12:36,720
and the four factor is abstracting how

376
00:12:36,720 --> 00:12:39,040
well can a machine take what is learned

377
00:12:39,040 --> 00:12:41,279
and and what is decided and apply it to

378
00:12:41,279 --> 00:12:43,760
an entirely different domain

379
00:12:43,760 --> 00:12:45,440
there's no analog here with the oota

380
00:12:45,440 --> 00:12:46,880
loop but note that

381
00:12:46,880 --> 00:12:48,959
here too darpa doesn't include the

382
00:12:48,959 --> 00:12:50,000
action itself

383
00:12:50,000 --> 00:12:52,160
or the execution of the decisions as a

384
00:12:52,160 --> 00:12:53,200
part of ai

385
00:12:53,200 --> 00:12:56,079
okay again we complete these together

386
00:12:56,079 --> 00:12:57,360
the notion of ai

387
00:12:57,360 --> 00:13:00,079
and the automation piece but note here

388
00:13:00,079 --> 00:13:00,560
that

389
00:13:00,560 --> 00:13:03,760
um or the action piece but note again

390
00:13:03,760 --> 00:13:04,079
here

391
00:13:04,079 --> 00:13:05,600
that darpa doesn't include the action

392
00:13:05,600 --> 00:13:09,440
itself or the execution of the decisions

393
00:13:09,440 --> 00:13:11,360
now within darpa's view of ai they talk

394
00:13:11,360 --> 00:13:12,800
about three waves

395
00:13:12,800 --> 00:13:15,040
the first wave is based on handcrafted

396
00:13:15,040 --> 00:13:16,720
knowledge this has a little bit of

397
00:13:16,720 --> 00:13:18,800
perceiving and lots of reasoning

398
00:13:18,800 --> 00:13:20,320
the examples they give include things

399
00:13:20,320 --> 00:13:22,639
like tax preparation software and chess

400
00:13:22,639 --> 00:13:25,040
even i mean know that even the cyber

401
00:13:25,040 --> 00:13:26,160
grand challenge

402
00:13:26,160 --> 00:13:28,720
that we saw happen at black hat a couple

403
00:13:28,720 --> 00:13:29,839
years ago

404
00:13:29,839 --> 00:13:33,600
they are that fits into this category

405
00:13:33,600 --> 00:13:35,200
they actually specifically put it into

406
00:13:35,200 --> 00:13:36,560
this category

407
00:13:36,560 --> 00:13:39,519
uh capabilities in this way rely heavily

408
00:13:39,519 --> 00:13:41,120
on the handcrafted knowledge of experts

409
00:13:41,120 --> 00:13:41,600
who can

410
00:13:41,600 --> 00:13:43,839
codify their decisions into software and

411
00:13:43,839 --> 00:13:46,000
provide deterministic outcomes

412
00:13:46,000 --> 00:13:48,560
for example in tax prep software it can

413
00:13:48,560 --> 00:13:50,560
take basic inputs in various formats and

414
00:13:50,560 --> 00:13:52,480
make highly deterministic decisions over

415
00:13:52,480 --> 00:13:53,120
them

416
00:13:53,120 --> 00:13:55,519
first generation sims perceive their

417
00:13:55,519 --> 00:13:57,279
world using common event

418
00:13:57,279 --> 00:13:59,360
and logging formats and reason over this

419
00:13:59,360 --> 00:14:02,160
data using various alerting rules that

420
00:14:02,160 --> 00:14:03,519
are hand crafted

421
00:14:03,519 --> 00:14:05,920
and these capabilities fit um into this

422
00:14:05,920 --> 00:14:06,959
first wave

423
00:14:06,959 --> 00:14:10,079
very well the second wave

424
00:14:10,079 --> 00:14:12,399
has a lot of perceiving and learning

425
00:14:12,399 --> 00:14:13,680
capabilities

426
00:14:13,680 --> 00:14:15,360
machine learning and most of what people

427
00:14:15,360 --> 00:14:16,880
people call ai today is

428
00:14:16,880 --> 00:14:19,360
in this space the second wave can do

429
00:14:19,360 --> 00:14:21,279
some amazing things to find

430
00:14:21,279 --> 00:14:23,040
patterns similar to what we have seen

431
00:14:23,040 --> 00:14:25,199
previously and this pattern recognition

432
00:14:25,199 --> 00:14:26,160
has been

433
00:14:26,160 --> 00:14:27,600
extraordinarily useful to develop

434
00:14:27,600 --> 00:14:29,360
capabilities like voice and facial

435
00:14:29,360 --> 00:14:31,199
recognition

436
00:14:31,199 --> 00:14:33,279
somewhat self-driving cars and the

437
00:14:33,279 --> 00:14:35,040
current generation of

438
00:14:35,040 --> 00:14:36,720
uh all the sim products that we see

439
00:14:36,720 --> 00:14:38,720
today that have all the sprinkling of

440
00:14:38,720 --> 00:14:41,760
ml and ai but

441
00:14:41,760 --> 00:14:43,519
the second wave of the capabilities is

442
00:14:43,519 --> 00:14:46,160
also very limited in its reasoning

443
00:14:46,160 --> 00:14:48,880
capabilities and remember this is where

444
00:14:48,880 --> 00:14:50,800
decision making lives

445
00:14:50,800 --> 00:14:54,079
and note that this that darpa calls this

446
00:14:54,079 --> 00:14:57,360
statistical learning and on that point

447
00:14:57,360 --> 00:14:59,519
let's talk about um statistical learning

448
00:14:59,519 --> 00:15:01,279
for a moment

449
00:15:01,279 --> 00:15:03,839
stats are very helpful to spot uh

450
00:15:03,839 --> 00:15:04,720
similarity

451
00:15:04,720 --> 00:15:07,360
to known patterns but stats without

452
00:15:07,360 --> 00:15:08,639
context or

453
00:15:08,639 --> 00:15:10,880
explanation can be very dangerous and

454
00:15:10,880 --> 00:15:12,079
you may have heard this quote before

455
00:15:12,079 --> 00:15:14,639
there are three kinds of lies lies damn

456
00:15:14,639 --> 00:15:15,360
lies and

457
00:15:15,360 --> 00:15:18,480
statistics or this awesome book entitled

458
00:15:18,480 --> 00:15:21,360
how to lie with statistics and did you

459
00:15:21,360 --> 00:15:22,880
know that 83.7

460
00:15:22,880 --> 00:15:26,160
of all stats are entirely made up

461
00:15:26,160 --> 00:15:28,560
well stats without context or proper

462
00:15:28,560 --> 00:15:29,440
explanation

463
00:15:29,440 --> 00:15:31,839
has its limitations and likewise systems

464
00:15:31,839 --> 00:15:33,279
that use

465
00:15:33,279 --> 00:15:35,040
statistical based machine learning will

466
00:15:35,040 --> 00:15:36,720
have similar limitations and as i've

467
00:15:36,720 --> 00:15:38,639
mentioned previously stats

468
00:15:38,639 --> 00:15:40,639
are helpful to spot similarity to known

469
00:15:40,639 --> 00:15:42,800
patterns and fitting a curve but

470
00:15:42,800 --> 00:15:45,360
um without context or explanation the

471
00:15:45,360 --> 00:15:47,440
similarities may mean nothing for

472
00:15:47,440 --> 00:15:49,680
for example here are some known patterns

473
00:15:49,680 --> 00:15:50,639
that are similar

474
00:15:50,639 --> 00:15:53,680
um turns out that people who fall out of

475
00:15:53,680 --> 00:15:55,440
who drown after falling out of a fishing

476
00:15:55,440 --> 00:15:57,040
boat correlates nicely with the marriage

477
00:15:57,040 --> 00:15:58,399
rate in kentucky

478
00:15:58,399 --> 00:16:01,680
and our spin on science space and tech

479
00:16:01,680 --> 00:16:03,759
correlates really nicely with suicides

480
00:16:03,759 --> 00:16:04,800
by hanging

481
00:16:04,800 --> 00:16:07,440
and strangulation and suffocation but we

482
00:16:07,440 --> 00:16:09,759
know that these are absurd i mean

483
00:16:09,759 --> 00:16:11,279
these are absurd unexplainable

484
00:16:11,279 --> 00:16:13,680
correlations but why do we know that

485
00:16:13,680 --> 00:16:15,440
and and more importantly how would a

486
00:16:15,440 --> 00:16:17,920
machine know that

487
00:16:17,920 --> 00:16:19,440
and when these techniques are applied to

488
00:16:19,440 --> 00:16:21,680
security problems we encounter similar

489
00:16:21,680 --> 00:16:22,880
challenges

490
00:16:22,880 --> 00:16:25,199
there's this great paper on the use of

491
00:16:25,199 --> 00:16:26,160
machine learning for

492
00:16:26,160 --> 00:16:28,800
network intrusion detection note that

493
00:16:28,800 --> 00:16:29,839
this was written

494
00:16:29,839 --> 00:16:33,600
in 2010 okay 2010 while before the craze

495
00:16:33,600 --> 00:16:34,880
that we have seen

496
00:16:34,880 --> 00:16:37,519
recently around a ml this paper

497
00:16:37,519 --> 00:16:39,120
specifically talks about why it's

498
00:16:39,120 --> 00:16:40,399
so fundamentally different and

499
00:16:40,399 --> 00:16:42,320
significantly harder to apply

500
00:16:42,320 --> 00:16:44,800
ml to security problems in a nutshell

501
00:16:44,800 --> 00:16:46,480
distills down to the

502
00:16:46,480 --> 00:16:48,320
it distills down to the differences in

503
00:16:48,320 --> 00:16:49,519
the nature of problems and the

504
00:16:49,519 --> 00:16:50,000
environment

505
00:16:50,000 --> 00:16:52,880
that we're in when it comes to security

506
00:16:52,880 --> 00:16:54,480
machine learning works really great

507
00:16:54,480 --> 00:16:57,279
in closed worlds where things are

508
00:16:57,279 --> 00:17:01,120
bounded and the rules don't change

509
00:17:01,440 --> 00:17:04,319
however the internet and most enterprise

510
00:17:04,319 --> 00:17:05,199
environments are

511
00:17:05,199 --> 00:17:07,839
unbounded environments and and the rules

512
00:17:07,839 --> 00:17:09,599
change all the time

513
00:17:09,599 --> 00:17:11,599
furthermore they're the attackers are

514
00:17:11,599 --> 00:17:13,760
constantly trying to change the rules

515
00:17:13,760 --> 00:17:16,959
um through novel attacks so as i

516
00:17:16,959 --> 00:17:19,039
mentioned before machine learning

517
00:17:19,039 --> 00:17:20,640
really isn't that great for finding

518
00:17:20,640 --> 00:17:22,959
truly novel for finding those things

519
00:17:22,959 --> 00:17:24,319
that are truly novel

520
00:17:24,319 --> 00:17:26,319
uh particularly environment and in the

521
00:17:26,319 --> 00:17:28,480
open environments like the internet

522
00:17:28,480 --> 00:17:30,240
there are many things like outliers

523
00:17:30,240 --> 00:17:31,679
which is why we end up

524
00:17:31,679 --> 00:17:33,200
with so many false positives when it

525
00:17:33,200 --> 00:17:35,360
comes to machine learning

526
00:17:35,360 --> 00:17:36,720
and when we tune our machine learning

527
00:17:36,720 --> 00:17:38,720
systems we recognize that the costs and

528
00:17:38,720 --> 00:17:40,400
the consequences for a false

529
00:17:40,400 --> 00:17:43,760
negative are pretty high so in other

530
00:17:43,760 --> 00:17:45,360
words we don't want to misclassify a

531
00:17:45,360 --> 00:17:46,000
real attack

532
00:17:46,000 --> 00:17:48,559
as being normal but as we try to ensure

533
00:17:48,559 --> 00:17:50,400
that we don't have any false positives

534
00:17:50,400 --> 00:17:51,919
we typically end up

535
00:17:51,919 --> 00:17:54,160
with many false positives i'm sorry

536
00:17:54,160 --> 00:17:55,440
because we try to ensure that we don't

537
00:17:55,440 --> 00:17:56,000
have many

538
00:17:56,000 --> 00:17:58,480
any false negatives we typically end up

539
00:17:58,480 --> 00:18:00,320
with many false positives

540
00:18:00,320 --> 00:18:03,280
which has its own associated costs in

541
00:18:03,280 --> 00:18:04,720
terms of time

542
00:18:04,720 --> 00:18:08,480
uh analyst time and by the way um

543
00:18:08,480 --> 00:18:10,640
but most most any vendor in this space

544
00:18:10,640 --> 00:18:11,840
that makes a claim about machine

545
00:18:11,840 --> 00:18:13,120
learning in their product will state

546
00:18:13,120 --> 00:18:14,480
that they have very few

547
00:18:14,480 --> 00:18:18,400
false positives and as many know this is

548
00:18:18,400 --> 00:18:19,760
just a play on the words i mean they

549
00:18:19,760 --> 00:18:20,720
really mean

550
00:18:20,720 --> 00:18:21,919
they mean that everything that they

551
00:18:21,919 --> 00:18:24,240
alert on will be an anomaly

552
00:18:24,240 --> 00:18:26,559
which they don't deem to be a false

553
00:18:26,559 --> 00:18:28,640
positive because well it really is an

554
00:18:28,640 --> 00:18:30,960
anomaly but as we all know the vast

555
00:18:30,960 --> 00:18:33,280
majority of these anomalies are benign

556
00:18:33,280 --> 00:18:35,840
there are only a few that are malicious

557
00:18:35,840 --> 00:18:36,960
ultimately we need this

558
00:18:36,960 --> 00:18:39,360
these systems to help us find malicious

559
00:18:39,360 --> 00:18:40,960
anomalies that we already know

560
00:18:40,960 --> 00:18:43,440
the pattern for but also these malicious

561
00:18:43,440 --> 00:18:46,000
anomalies that are novel

562
00:18:46,000 --> 00:18:47,440
and all the while filtering out all the

563
00:18:47,440 --> 00:18:49,280
benign stuff

564
00:18:49,280 --> 00:18:51,840
but to reduce the false positive problem

565
00:18:51,840 --> 00:18:53,679
these systems need to explain

566
00:18:53,679 --> 00:18:56,880
why these anomalies are malicious

567
00:18:56,880 --> 00:18:58,880
and so that takes us to the third wave

568
00:18:58,880 --> 00:19:00,880
of ai which

569
00:19:00,880 --> 00:19:03,760
we haven't reached yet okay we have not

570
00:19:03,760 --> 00:19:04,400
reached

571
00:19:04,400 --> 00:19:06,640
the third wave of ai at least the way

572
00:19:06,640 --> 00:19:08,799
that darpa defines it

573
00:19:08,799 --> 00:19:11,600
this wave is what darpa calls contextual

574
00:19:11,600 --> 00:19:13,120
adaptation

575
00:19:13,120 --> 00:19:17,600
here we have similar perceiving and

576
00:19:17,840 --> 00:19:19,760
learning capabilities as in the second

577
00:19:19,760 --> 00:19:21,840
wave but we see much better reasoning

578
00:19:21,840 --> 00:19:22,240
and

579
00:19:22,240 --> 00:19:24,799
abstracting capabilities and what this

580
00:19:24,799 --> 00:19:26,320
means for the third wave

581
00:19:26,320 --> 00:19:29,280
um is that for the third wave we would

582
00:19:29,280 --> 00:19:31,200
expect to see systems that can explain

583
00:19:31,200 --> 00:19:32,960
its alerting and decisions

584
00:19:32,960 --> 00:19:35,039
ultimately leading to a clearer

585
00:19:35,039 --> 00:19:36,880
understanding of causal factors

586
00:19:36,880 --> 00:19:38,320
not just based on statistical

587
00:19:38,320 --> 00:19:39,919
correlation

588
00:19:39,919 --> 00:19:41,360
ultimately such a system will give us a

589
00:19:41,360 --> 00:19:42,960
better understanding of why

590
00:19:42,960 --> 00:19:46,000
something is classified

591
00:19:46,000 --> 00:19:49,200
as malicious or why it's okay this this

592
00:19:49,200 --> 00:19:50,320
provides

593
00:19:50,320 --> 00:19:52,240
much more predictability for when a

594
00:19:52,240 --> 00:19:54,799
system fails or succeeds and drives

595
00:19:54,799 --> 00:19:56,240
ultimately towards more trust in the

596
00:19:56,240 --> 00:19:58,240
system and with security

597
00:19:58,240 --> 00:20:00,640
we are we want more trustworthy systems

598
00:20:00,640 --> 00:20:02,000
and to be able to do that again we need

599
00:20:02,000 --> 00:20:02,640
to understand

600
00:20:02,640 --> 00:20:05,360
why things worked or didn't work and in

601
00:20:05,360 --> 00:20:06,000
this particular

602
00:20:06,000 --> 00:20:10,000
example of the um our ml systems they

603
00:20:10,000 --> 00:20:10,320
have

604
00:20:10,320 --> 00:20:12,720
hundreds of inputs and no real clear

605
00:20:12,720 --> 00:20:14,080
explanation for how it makes sense of

606
00:20:14,080 --> 00:20:15,120
these inputs

607
00:20:15,120 --> 00:20:17,039
and here's an example of a simple attack

608
00:20:17,039 --> 00:20:18,240
that was made against a visual

609
00:20:18,240 --> 00:20:20,080
recognition system that looked like that

610
00:20:20,080 --> 00:20:20,640
made us

611
00:20:20,640 --> 00:20:23,039
a stop sign look like a speed limit sign

612
00:20:23,039 --> 00:20:23,760
if you asked

613
00:20:23,760 --> 00:20:25,520
a machine learning system why it thought

614
00:20:25,520 --> 00:20:27,120
it was a speed limit sign

615
00:20:27,120 --> 00:20:28,159
you would struggle to get a

616
00:20:28,159 --> 00:20:30,640
comprehensible answer but

617
00:20:30,640 --> 00:20:32,799
at the third wave such a system should

618
00:20:32,799 --> 00:20:34,400
be able to tell you simply that it can

619
00:20:34,400 --> 00:20:35,440
differentiate

620
00:20:35,440 --> 00:20:38,080
a stop sign from a speed limit sign

621
00:20:38,080 --> 00:20:39,039
because

622
00:20:39,039 --> 00:20:41,440
because it has these specific parameters

623
00:20:41,440 --> 00:20:42,640
the stop sign is red

624
00:20:42,640 --> 00:20:46,320
it's octagonal it's at an intersection

625
00:20:46,320 --> 00:20:47,840
and it's difficult to test machine

626
00:20:47,840 --> 00:20:49,280
learning models thoroughly and they're

627
00:20:49,280 --> 00:20:50,640
easy to deceive

628
00:20:50,640 --> 00:20:52,880
uh and confused and this presents uh

629
00:20:52,880 --> 00:20:54,400
challenging new security problems

630
00:20:54,400 --> 00:20:56,799
in and of itself but when it comes to

631
00:20:56,799 --> 00:20:58,480
security use cases

632
00:20:58,480 --> 00:21:00,000
i think it's doubly important that we

633
00:21:00,000 --> 00:21:01,600
get this right because it can undermine

634
00:21:01,600 --> 00:21:04,880
our ability to have security at all

635
00:21:04,880 --> 00:21:06,960
machine learning models are oftentimes

636
00:21:06,960 --> 00:21:08,640
we see them as black boxes that can only

637
00:21:08,640 --> 00:21:10,559
be tested as a unified hall

638
00:21:10,559 --> 00:21:13,039
they usually have a huge number of

639
00:21:13,039 --> 00:21:13,919
inputs

640
00:21:13,919 --> 00:21:15,120
so it's not really possible to

641
00:21:15,120 --> 00:21:17,120
thoroughly test even simple models with

642
00:21:17,120 --> 00:21:19,039
every possible combination

643
00:21:19,039 --> 00:21:21,039
which leaves open the question of how an

644
00:21:21,039 --> 00:21:22,720
ml model will perform in a given

645
00:21:22,720 --> 00:21:23,919
situation

646
00:21:23,919 --> 00:21:25,840
and if you have adversarial behavior

647
00:21:25,840 --> 00:21:27,520
that's just trying to actively fool the

648
00:21:27,520 --> 00:21:29,280
sensing and since making capabilities of

649
00:21:29,280 --> 00:21:30,480
our security products

650
00:21:30,480 --> 00:21:32,880
which we know happens right then we have

651
00:21:32,880 --> 00:21:33,919
all the more reason

652
00:21:33,919 --> 00:21:36,080
uh to ensure that we have a better more

653
00:21:36,080 --> 00:21:39,440
mature decision-making framework

654
00:21:39,440 --> 00:21:41,280
and so when it comes to the maturity of

655
00:21:41,280 --> 00:21:42,559
a decision-making frame the

656
00:21:42,559 --> 00:21:44,320
decision-making framework

657
00:21:44,320 --> 00:21:47,440
let's look at this last framework now

658
00:21:47,440 --> 00:21:49,520
now we homeschool our children i think

659
00:21:49,520 --> 00:21:50,720
everyone's homeschooling children

660
00:21:50,720 --> 00:21:51,360
nowadays

661
00:21:51,360 --> 00:21:53,440
um or it seems like you're homeschooling

662
00:21:53,440 --> 00:21:55,360
children so anyway but i was doing that

663
00:21:55,360 --> 00:21:56,159
even before the

664
00:21:56,159 --> 00:21:59,039
pandemic and in the process of learning

665
00:21:59,039 --> 00:22:00,159
how to teach kids

666
00:22:00,159 --> 00:22:01,760
we also learned about this thing called

667
00:22:01,760 --> 00:22:03,360
the classical education

668
00:22:03,360 --> 00:22:06,320
trivium classical education trivium it

669
00:22:06,320 --> 00:22:08,159
lays out the progression of how kids

670
00:22:08,159 --> 00:22:10,480
learn first you start at the grammar

671
00:22:10,480 --> 00:22:11,200
stage

672
00:22:11,200 --> 00:22:13,280
this is when you soak up facts and raw

673
00:22:13,280 --> 00:22:14,320
information

674
00:22:14,320 --> 00:22:18,399
think of it as their roots and the

675
00:22:18,960 --> 00:22:22,159
trunk of a tree it sets the foundation

676
00:22:22,159 --> 00:22:23,600
for everything that grows above

677
00:22:23,600 --> 00:22:26,720
it next you go to the dialectic or logic

678
00:22:26,720 --> 00:22:27,200
stage

679
00:22:27,200 --> 00:22:28,640
here it's like the branches of a tree

680
00:22:28,640 --> 00:22:30,400
connects facts together and compares the

681
00:22:30,400 --> 00:22:32,159
truth of opinions to

682
00:22:32,159 --> 00:22:33,679
determine what is logically correct and

683
00:22:33,679 --> 00:22:36,320
what is not this is also when kids start

684
00:22:36,320 --> 00:22:39,760
explaining truth um sorry explaining why

685
00:22:39,760 --> 00:22:40,240
and how

686
00:22:40,240 --> 00:22:42,240
truth uh how one truth connects to

687
00:22:42,240 --> 00:22:43,919
another truth

688
00:22:43,919 --> 00:22:45,840
and this last stage and the last stage

689
00:22:45,840 --> 00:22:48,080
is the uh rhetoric stage when kids grow

690
00:22:48,080 --> 00:22:49,039
into wisdom

691
00:22:49,039 --> 00:22:50,880
and can convince and persuade others

692
00:22:50,880 --> 00:22:52,640
having integrated multiple subjects and

693
00:22:52,640 --> 00:22:54,400
disciplines together

694
00:22:54,400 --> 00:22:56,159
now if you remember according to the

695
00:22:56,159 --> 00:22:57,840
darpa framework

696
00:22:57,840 --> 00:23:00,400
the ability to explain why and how

697
00:23:00,400 --> 00:23:02,559
happens in the third wave

698
00:23:02,559 --> 00:23:05,760
which means we're not quite there yet

699
00:23:05,760 --> 00:23:09,919
okay um the third wave is when we can

700
00:23:09,919 --> 00:23:10,480
explain

701
00:23:10,480 --> 00:23:12,400
why and how and we're not at the third

702
00:23:12,400 --> 00:23:13,520
wave

703
00:23:13,520 --> 00:23:15,280
now if you match these three stages of

704
00:23:15,280 --> 00:23:17,120
childhood to actual

705
00:23:17,120 --> 00:23:20,240
ages you get this breakdown

706
00:23:20,240 --> 00:23:22,640
where during the elementary school years

707
00:23:22,640 --> 00:23:24,559
the focus is primarily on grammar with a

708
00:23:24,559 --> 00:23:26,000
little bit of rhetoric and a little bit

709
00:23:26,000 --> 00:23:27,679
of dialectic

710
00:23:27,679 --> 00:23:29,280
this is also why by the way in case

711
00:23:29,280 --> 00:23:31,039
you're curious why people call

712
00:23:31,039 --> 00:23:34,240
elementary schools grammar schools

713
00:23:34,240 --> 00:23:36,480
in junior high we focus more on

714
00:23:36,480 --> 00:23:37,360
dialectic

715
00:23:37,360 --> 00:23:38,799
and then in high school we focus on

716
00:23:38,799 --> 00:23:42,000
rhetoric but note again

717
00:23:42,000 --> 00:23:45,039
um if we need to have machines be able

718
00:23:45,039 --> 00:23:46,880
to explain why and how

719
00:23:46,880 --> 00:23:48,960
our current technologies aren't able to

720
00:23:48,960 --> 00:23:50,799
do that adequately

721
00:23:50,799 --> 00:23:52,880
then we have to re if and we recognize

722
00:23:52,880 --> 00:23:54,000
that then we have to recognize our

723
00:23:54,000 --> 00:23:54,880
machines

724
00:23:54,880 --> 00:23:57,279
haven't quite left elementary school yet

725
00:23:57,279 --> 00:23:58,159
okay

726
00:23:58,159 --> 00:24:00,960
think about that for a moment what kind

727
00:24:00,960 --> 00:24:03,279
of decisions are you comfortable

728
00:24:03,279 --> 00:24:06,559
and delegating to kids in that age range

729
00:24:06,559 --> 00:24:08,880
and by the way kids are very capable

730
00:24:08,880 --> 00:24:10,159
right um

731
00:24:10,159 --> 00:24:13,200
i my uh my brother-in-law

732
00:24:13,200 --> 00:24:15,279
said he used to drive tractors and his

733
00:24:15,279 --> 00:24:16,960
farm

734
00:24:16,960 --> 00:24:20,080
at the age of eight right um and

735
00:24:20,080 --> 00:24:22,000
i used to have a bb gun when i was a

736
00:24:22,000 --> 00:24:24,240
tube probably a really bad idea by the

737
00:24:24,240 --> 00:24:25,679
way

738
00:24:25,679 --> 00:24:27,840
but um the question is what kind of

739
00:24:27,840 --> 00:24:29,039
decisions are you comfortable in

740
00:24:29,039 --> 00:24:30,880
delegating the kids at that age range

741
00:24:30,880 --> 00:24:33,120
okay the question i asked at the very

742
00:24:33,120 --> 00:24:34,559
beginning what kind of weapon are you

743
00:24:34,559 --> 00:24:36,720
willing to give

744
00:24:36,720 --> 00:24:40,320
ai today and what age is it actually

745
00:24:40,320 --> 00:24:44,320
okay and to tie this to the uder

746
00:24:44,320 --> 00:24:46,559
framework when we compare these

747
00:24:46,559 --> 00:24:48,320
components to the abilities of

748
00:24:48,320 --> 00:24:49,120
children's versus

749
00:24:49,120 --> 00:24:52,000
children versus adults we can see why we

750
00:24:52,000 --> 00:24:53,760
may want to take precautions when giving

751
00:24:53,760 --> 00:24:54,640
decision-making

752
00:24:54,640 --> 00:24:56,960
and acting capabilities to machines

753
00:24:56,960 --> 00:24:58,240
let's look more specifically at the

754
00:24:58,240 --> 00:25:00,000
comparison

755
00:25:00,000 --> 00:25:02,720
consider that the decision-making engine

756
00:25:02,720 --> 00:25:03,760
for children

757
00:25:03,760 --> 00:25:07,120
is the amygdala okay which is

758
00:25:07,120 --> 00:25:10,240
fully developed at birth and this

759
00:25:10,240 --> 00:25:12,559
decision-making engine is driven by

760
00:25:12,559 --> 00:25:15,919
fear emotion impulse

761
00:25:15,919 --> 00:25:19,039
aggression instinct okay

762
00:25:19,039 --> 00:25:20,559
but for a fully grown adult that

763
00:25:20,559 --> 00:25:21,840
decision-making engine is their

764
00:25:21,840 --> 00:25:23,600
prefrontal cortex

765
00:25:23,600 --> 00:25:26,720
and this is fully developed at age 25.

766
00:25:26,720 --> 00:25:27,760
and by the way if you've ever wondered

767
00:25:27,760 --> 00:25:29,679
why you can't rent a car until age 25

768
00:25:29,679 --> 00:25:30,320
that's

769
00:25:30,320 --> 00:25:33,440
that's why um it's towards the

770
00:25:33,440 --> 00:25:36,400
forehead and it controls behavior um

771
00:25:36,400 --> 00:25:37,919
meaning that you can avoid

772
00:25:37,919 --> 00:25:41,679
um yeah for those who know the reference

773
00:25:41,679 --> 00:25:42,960
it means that you can avoid having a

774
00:25:42,960 --> 00:25:44,559
tattoo in your forehead that says poor

775
00:25:44,559 --> 00:25:46,159
impulse control

776
00:25:46,159 --> 00:25:48,480
it can prioritize inputs and provides it

777
00:25:48,480 --> 00:25:49,679
essentially provides

778
00:25:49,679 --> 00:25:53,200
impulse control now a

779
00:25:53,200 --> 00:25:55,440
an amygdala for a decision-making engine

780
00:25:55,440 --> 00:25:56,799
might be fine if one's

781
00:25:56,799 --> 00:25:59,120
sense making and sensing and since

782
00:25:59,120 --> 00:26:00,559
making

783
00:26:00,559 --> 00:26:02,880
capabilities are clean and unpolluted

784
00:26:02,880 --> 00:26:03,679
but let's

785
00:26:03,679 --> 00:26:06,480
let's look at that as well for children

786
00:26:06,480 --> 00:26:07,120
we have

787
00:26:07,120 --> 00:26:09,520
questionable questionable inputs like

788
00:26:09,520 --> 00:26:10,880
their peers

789
00:26:10,880 --> 00:26:14,240
memes and social media for adults

790
00:26:14,240 --> 00:26:16,159
we might have similar inputs but we've

791
00:26:16,159 --> 00:26:18,080
developed filters and better discernment

792
00:26:18,080 --> 00:26:20,159
for those inputs

793
00:26:20,159 --> 00:26:23,919
and then for algorithms anyone who has a

794
00:26:23,919 --> 00:26:24,640
teenager

795
00:26:24,640 --> 00:26:27,039
probably can agree with me that their

796
00:26:27,039 --> 00:26:28,240
sense making

797
00:26:28,240 --> 00:26:31,360
may not make much sense but for adults

798
00:26:31,360 --> 00:26:32,880
we expect them to be rational and

799
00:26:32,880 --> 00:26:34,400
logical and to be able to explain their

800
00:26:34,400 --> 00:26:35,679
logic

801
00:26:35,679 --> 00:26:38,080
so consider now with the current level

802
00:26:38,080 --> 00:26:39,600
of maturity in our machine learning

803
00:26:39,600 --> 00:26:41,120
systems and the type of

804
00:26:41,120 --> 00:26:43,520
hostile sensory inputs that we get from

805
00:26:43,520 --> 00:26:45,440
the internet with

806
00:26:45,440 --> 00:26:48,080
unexplainable logic what kind of

807
00:26:48,080 --> 00:26:48,880
decisions

808
00:26:48,880 --> 00:26:51,440
should we allow machines to make to put

809
00:26:51,440 --> 00:26:52,640
it another way

810
00:26:52,640 --> 00:26:55,120
if you were to combine machine learning

811
00:26:55,120 --> 00:26:58,158
and ai with

812
00:26:58,240 --> 00:27:01,600
robotic process automation is the system

813
00:27:01,600 --> 00:27:02,400
going to

814
00:27:02,400 --> 00:27:04,080
mimic the behaviors of fully grown

815
00:27:04,080 --> 00:27:05,440
adults or

816
00:27:05,440 --> 00:27:08,480
or teenagers okay is the system going to

817
00:27:08,480 --> 00:27:09,919
mimic the behaviors of fully grown

818
00:27:09,919 --> 00:27:10,480
adults

819
00:27:10,480 --> 00:27:12,720
or teenagers do we understand the

820
00:27:12,720 --> 00:27:14,159
behavior of these entities and do we

821
00:27:14,159 --> 00:27:15,360
have the confidence

822
00:27:15,360 --> 00:27:17,039
that they will behave or make decisions

823
00:27:17,039 --> 00:27:18,559
in an appropriate manner

824
00:27:18,559 --> 00:27:20,080
and and where do we get that confidence

825
00:27:20,080 --> 00:27:21,840
from

826
00:27:21,840 --> 00:27:23,360
to understand how we can gain that

827
00:27:23,360 --> 00:27:25,039
confidence now let's look at some

828
00:27:25,039 --> 00:27:26,240
lessons learned

829
00:27:26,240 --> 00:27:28,000
and from these lessons determine how we

830
00:27:28,000 --> 00:27:29,840
can gain confidence and trust in our

831
00:27:29,840 --> 00:27:30,640
systems

832
00:27:30,640 --> 00:27:32,080
even if some of the elements that make

833
00:27:32,080 --> 00:27:34,640
up the system aren't fully mature

834
00:27:34,640 --> 00:27:36,320
and as a way to represent what happens

835
00:27:36,320 --> 00:27:38,640
when we lack

836
00:27:38,640 --> 00:27:40,640
when we lack maturity of a certain

837
00:27:40,640 --> 00:27:41,840
capability

838
00:27:41,840 --> 00:27:43,679
i will depict the lessons learned as

839
00:27:43,679 --> 00:27:45,600
skipping steps in the sense

840
00:27:45,600 --> 00:27:47,679
since making decision making and acting

841
00:27:47,679 --> 00:27:48,880
process

842
00:27:48,880 --> 00:27:51,919
because when we skip steps

843
00:27:51,919 --> 00:27:54,720
we need more guardrails and we need to

844
00:27:54,720 --> 00:27:56,080
look at each of these scenarios with

845
00:27:56,080 --> 00:27:56,640
lessons

846
00:27:56,640 --> 00:27:58,080
we need to look at each of these lessons

847
00:27:58,080 --> 00:27:59,360
learned from the security world and the

848
00:27:59,360 --> 00:28:00,880
guardrails that we might need for each

849
00:28:00,880 --> 00:28:02,880
one

850
00:28:02,880 --> 00:28:04,799
so in the first scenario we're going to

851
00:28:04,799 --> 00:28:06,559
go straight from sensing

852
00:28:06,559 --> 00:28:09,360
to acting okay this is like a reflex

853
00:28:09,360 --> 00:28:10,799
reaction so basically

854
00:28:10,799 --> 00:28:14,480
it's like a stimulus response system um

855
00:28:14,480 --> 00:28:16,240
there's uh anybody who's been in thread

856
00:28:16,240 --> 00:28:17,520
intel for a while

857
00:28:17,520 --> 00:28:20,720
know uh the pains of having um

858
00:28:20,720 --> 00:28:23,600
consuming threaten until without any

859
00:28:23,600 --> 00:28:25,520
sense making or decision making

860
00:28:25,520 --> 00:28:27,039
and subsequently shooting yourself in

861
00:28:27,039 --> 00:28:29,279
the foot by blocking

862
00:28:29,279 --> 00:28:31,840
all of the internet or facebook or

863
00:28:31,840 --> 00:28:34,639
google.com

864
00:28:34,880 --> 00:28:36,960
in the context of automated patching

865
00:28:36,960 --> 00:28:38,320
we've had situations like

866
00:28:38,320 --> 00:28:41,520
not petcha and some green energy company

867
00:28:41,520 --> 00:28:42,960
recently as well

868
00:28:42,960 --> 00:28:46,240
um even the windows update the 1809

869
00:28:46,240 --> 00:28:48,799
um deleted a whole bunch of files now by

870
00:28:48,799 --> 00:28:49,760
the way

871
00:28:49,760 --> 00:28:52,480
i think automated patching is absolutely

872
00:28:52,480 --> 00:28:53,360
a great thing

873
00:28:53,360 --> 00:28:54,960
okay i don't want people to think that

874
00:28:54,960 --> 00:28:56,880
there's not that automated patching is

875
00:28:56,880 --> 00:28:59,039
not a bad thing i mean even if the uh

876
00:28:59,039 --> 00:29:02,480
the green energy company recently i was

877
00:29:02,480 --> 00:29:05,520
we saw that 18 000 uh vendor customers

878
00:29:05,520 --> 00:29:06,240
were

879
00:29:06,240 --> 00:29:08,159
potentially affected but my question was

880
00:29:08,159 --> 00:29:10,080
what happened to the other 19 000 that

881
00:29:10,080 --> 00:29:13,279
that never patched i mean that that's a

882
00:29:13,279 --> 00:29:14,159
bad sign in it

883
00:29:14,159 --> 00:29:17,440
itself right um so again we want

884
00:29:17,440 --> 00:29:19,919
we want to encourage uh automated

885
00:29:19,919 --> 00:29:21,679
patching we want to encourage automated

886
00:29:21,679 --> 00:29:23,520
blocking from thread intel

887
00:29:23,520 --> 00:29:24,960
but we should make sure that we have

888
00:29:24,960 --> 00:29:26,799
guardrails in place and so

889
00:29:26,799 --> 00:29:28,640
some of these guardrails include making

890
00:29:28,640 --> 00:29:30,559
sure that your sources are trustworthy

891
00:29:30,559 --> 00:29:31,520
and reliable

892
00:29:31,520 --> 00:29:34,000
making sure that whatever actions you're

893
00:29:34,000 --> 00:29:35,360
defining

894
00:29:35,360 --> 00:29:38,240
are very narrowly scoped to make sure

895
00:29:38,240 --> 00:29:39,760
that you have a kill switch ready if

896
00:29:39,760 --> 00:29:42,399
something goes beyond the scope of

897
00:29:42,399 --> 00:29:44,320
whatever has been defined and ultimately

898
00:29:44,320 --> 00:29:45,520
you want to make sure that the action

899
00:29:45,520 --> 00:29:49,200
itself is immediately reversible

900
00:29:49,520 --> 00:29:52,559
let's now add incense making we're still

901
00:29:52,559 --> 00:29:54,559
missing decision making

902
00:29:54,559 --> 00:29:57,120
and in this context we're starting to

903
00:29:57,120 --> 00:29:58,320
add more enrichment

904
00:29:58,320 --> 00:30:00,080
oh in the sense making science side of

905
00:30:00,080 --> 00:30:01,679
the standpoint um

906
00:30:01,679 --> 00:30:03,360
for thread intel we start asking the

907
00:30:03,360 --> 00:30:04,960
questions like okay

908
00:30:04,960 --> 00:30:07,120
uh have i seen any false let's do a

909
00:30:07,120 --> 00:30:08,559
regression test make sure that

910
00:30:08,559 --> 00:30:11,600
no false positives appear um and

911
00:30:11,600 --> 00:30:14,559
and let's look at uh verdicts from virus

912
00:30:14,559 --> 00:30:15,520
total or

913
00:30:15,520 --> 00:30:17,120
other sources to determine whether

914
00:30:17,120 --> 00:30:18,880
whether or not uh

915
00:30:18,880 --> 00:30:20,840
what other people have said about a

916
00:30:20,840 --> 00:30:22,000
particular

917
00:30:22,000 --> 00:30:24,799
uh let's say a particular artifact but

918
00:30:24,799 --> 00:30:26,320
it's also asked the question well are

919
00:30:26,320 --> 00:30:27,760
these sources reliable

920
00:30:27,760 --> 00:30:31,039
you'll have 70 80 some sources and some

921
00:30:31,039 --> 00:30:32,000
are

922
00:30:32,000 --> 00:30:34,320
less reliable than others right and so

923
00:30:34,320 --> 00:30:35,840
just because you have three out of four

924
00:30:35,840 --> 00:30:38,080
or three out of 88 hits

925
00:30:38,080 --> 00:30:40,399
uh yeah i think you have to really judge

926
00:30:40,399 --> 00:30:42,640
and assess whether or not those

927
00:30:42,640 --> 00:30:44,720
three or four hits that you see in virus

928
00:30:44,720 --> 00:30:48,000
total are actually reliable on that card

929
00:30:48,000 --> 00:30:49,760
and then when it comes to automated

930
00:30:49,760 --> 00:30:52,320
patching um you want to make sure that

931
00:30:52,320 --> 00:30:54,640
the systems operate as expected after

932
00:30:54,640 --> 00:30:55,520
the patch

933
00:30:55,520 --> 00:30:57,919
um it really should be baselining these

934
00:30:57,919 --> 00:30:58,559
uh

935
00:30:58,559 --> 00:31:00,720
these uh systems to say this is the

936
00:31:00,720 --> 00:31:02,000
expected behavior

937
00:31:02,000 --> 00:31:04,559
and if it starts talking to some other

938
00:31:04,559 --> 00:31:05,279
node

939
00:31:05,279 --> 00:31:08,240
then that would be a major red flag

940
00:31:08,240 --> 00:31:09,120
right

941
00:31:09,120 --> 00:31:10,880
or that certain applications stopped

942
00:31:10,880 --> 00:31:12,240
working or

943
00:31:12,240 --> 00:31:14,000
the new application starts been started

944
00:31:14,000 --> 00:31:16,480
spinning up

945
00:31:16,880 --> 00:31:20,000
and when it comes to um skipping

946
00:31:20,000 --> 00:31:22,640
decision making uh here's an example of

947
00:31:22,640 --> 00:31:24,399
a darpa program where we can map out

948
00:31:24,399 --> 00:31:25,519
three of the four elements

949
00:31:25,519 --> 00:31:28,480
of the ooda loop um as you can see it's

950
00:31:28,480 --> 00:31:29,840
actually missing

951
00:31:29,840 --> 00:31:31,760
again it's there's there's different

952
00:31:31,760 --> 00:31:34,320
aspects to the paragraph you see here so

953
00:31:34,320 --> 00:31:36,320
tools to develop and characterize novel

954
00:31:36,320 --> 00:31:38,000
attack that's sense making

955
00:31:38,000 --> 00:31:39,840
uh collect the right contextual data

956
00:31:39,840 --> 00:31:41,519
that sensing

957
00:31:41,519 --> 00:31:43,120
and then it goes straight to acting

958
00:31:43,120 --> 00:31:44,960
which is disseminate protective measures

959
00:31:44,960 --> 00:31:48,960
both within and across enterprises

960
00:31:48,960 --> 00:31:50,880
it's it's missing a decision-making

961
00:31:50,880 --> 00:31:53,519
action oh sorry the decision-making step

962
00:31:53,519 --> 00:31:55,600
the absence of a clear decision-making

963
00:31:55,600 --> 00:31:57,519
step should serve as a warning sign

964
00:31:57,519 --> 00:31:59,919
when you read through this this

965
00:31:59,919 --> 00:32:00,799
statement here

966
00:32:00,799 --> 00:32:02,960
and this program intends to do sensing

967
00:32:02,960 --> 00:32:04,000
and sense making then

968
00:32:04,000 --> 00:32:06,240
because it's jumping right to protective

969
00:32:06,240 --> 00:32:07,279
measures

970
00:32:07,279 --> 00:32:09,440
uh again it should be a warning flag as

971
00:32:09,440 --> 00:32:13,679
the as the chief scientist at bae states

972
00:32:13,679 --> 00:32:15,760
he uh he says we need to leave behind a

973
00:32:15,760 --> 00:32:17,600
trail of logic

974
00:32:17,600 --> 00:32:20,559
uh so that the decisions are implicitly

975
00:32:20,559 --> 00:32:22,159
or explicitly made

976
00:32:22,159 --> 00:32:24,399
uh clear so that we can follow up on it

977
00:32:24,399 --> 00:32:25,919
and ensure that the decisions are

978
00:32:25,919 --> 00:32:29,840
actually correct

979
00:32:29,840 --> 00:32:33,519
so let's um let's keep moving forward

980
00:32:33,519 --> 00:32:35,440
there's some interesting stories here as

981
00:32:35,440 --> 00:32:39,360
well but i'm running out of time

982
00:32:39,519 --> 00:32:41,840
there was a situation where some of our

983
00:32:41,840 --> 00:32:44,240
assumptions have to also be validated

984
00:32:44,240 --> 00:32:46,640
the and the process itself has to be

985
00:32:46,640 --> 00:32:48,640
well documented understood

986
00:32:48,640 --> 00:32:49,919
one of the things that we oftentimes

987
00:32:49,919 --> 00:32:51,679
want to establish as guardrails is to

988
00:32:51,679 --> 00:32:52,799
have

989
00:32:52,799 --> 00:32:54,480
activities that are really highly

990
00:32:54,480 --> 00:32:56,640
deterministic there's one particular

991
00:32:56,640 --> 00:32:57,039
story

992
00:32:57,039 --> 00:33:02,399
that i recall was a situation where

993
00:33:03,039 --> 00:33:05,600
there was a check processing or there

994
00:33:05,600 --> 00:33:06,880
was a

995
00:33:06,880 --> 00:33:11,679
there was a funds transfer system that

996
00:33:11,679 --> 00:33:16,320
used emails as a way to

997
00:33:16,640 --> 00:33:20,480
to uh to approve or at least

998
00:33:20,480 --> 00:33:23,840
to make a specific one transfer request

999
00:33:23,840 --> 00:33:24,880
and these emails

1000
00:33:24,880 --> 00:33:28,159
um were basically someone said

1001
00:33:28,159 --> 00:33:30,159
basically what happened was some someone

1002
00:33:30,159 --> 00:33:32,240
would receive this email and basically

1003
00:33:32,240 --> 00:33:35,039
read the email which usually came in a

1004
00:33:35,039 --> 00:33:36,880
very similar format

1005
00:33:36,880 --> 00:33:38,480
take that information and basically put

1006
00:33:38,480 --> 00:33:40,399
it into some system that would then do

1007
00:33:40,399 --> 00:33:42,159
some sort of funds transfer

1008
00:33:42,159 --> 00:33:44,159
um there was an assumption that the

1009
00:33:44,159 --> 00:33:45,919
emails were coming only from legitimate

1010
00:33:45,919 --> 00:33:46,880
sources

1011
00:33:46,880 --> 00:33:49,200
um and that the copying action was a

1012
00:33:49,200 --> 00:33:51,360
purely mechanical one that

1013
00:33:51,360 --> 00:33:52,960
could have been turned into some sort of

1014
00:33:52,960 --> 00:33:55,760
automation unfortunately

1015
00:33:55,760 --> 00:33:57,039
i'm sure you can figure out the rest of

1016
00:33:57,039 --> 00:33:58,640
the story for what might have happened

1017
00:33:58,640 --> 00:33:59,440
here

1018
00:33:59,440 --> 00:34:03,279
but they didn't have sufficient card

1019
00:34:03,279 --> 00:34:05,279
rails to make sure that

1020
00:34:05,279 --> 00:34:06,640
that one the emails were coming from

1021
00:34:06,640 --> 00:34:09,040
legitimate sources and that

1022
00:34:09,040 --> 00:34:11,280
someone actually gave thought into what

1023
00:34:11,280 --> 00:34:12,399
what type of

1024
00:34:12,399 --> 00:34:15,520
transfer was occurring and so

1025
00:34:15,520 --> 00:34:17,839
when we have when we skip decision

1026
00:34:17,839 --> 00:34:19,280
making

1027
00:34:19,280 --> 00:34:20,879
when we choose to skip decision making

1028
00:34:20,879 --> 00:34:22,239
we still need to make sure that certain

1029
00:34:22,239 --> 00:34:23,679
guard rails are in place and some of the

1030
00:34:23,679 --> 00:34:25,280
guardrails that you see here

1031
00:34:25,280 --> 00:34:27,040
are examples that would have made this

1032
00:34:27,040 --> 00:34:28,480
particular

1033
00:34:28,480 --> 00:34:31,839
event anonym

1034
00:34:31,918 --> 00:34:34,000
and then lastly when we put even when we

1035
00:34:34,000 --> 00:34:35,440
put in decision making

1036
00:34:35,440 --> 00:34:37,440
um we still need to have some certain

1037
00:34:37,440 --> 00:34:38,800
guardrails and

1038
00:34:38,800 --> 00:34:42,960
two examples here um uh bank of valeta

1039
00:34:42,960 --> 00:34:45,040
they shut down all their operations

1040
00:34:45,040 --> 00:34:48,320
after the after some hackers broke into

1041
00:34:48,320 --> 00:34:49,440
the system

1042
00:34:49,440 --> 00:34:53,359
um shutting down all your operations

1043
00:34:53,359 --> 00:34:55,679
is a pretty significant decision-making

1044
00:34:55,679 --> 00:34:56,399
step

1045
00:34:56,399 --> 00:34:59,520
another one is uh with uh code red

1046
00:34:59,520 --> 00:35:02,079
when dod shut down nippernet and who

1047
00:35:02,079 --> 00:35:02,720
would have thunk

1048
00:35:02,720 --> 00:35:05,839
that that would have caused

1049
00:35:05,839 --> 00:35:07,599
us to not be able to open the locks on

1050
00:35:07,599 --> 00:35:10,320
the mississippi river

1051
00:35:10,320 --> 00:35:13,440
it was a pretty drastic step

1052
00:35:13,440 --> 00:35:15,760
but it was made in i think for both

1053
00:35:15,760 --> 00:35:19,280
these situations it was probably made

1054
00:35:19,280 --> 00:35:20,960
in haste without having some of these

1055
00:35:20,960 --> 00:35:22,480
guardrails in place one is

1056
00:35:22,480 --> 00:35:23,839
especially being having a

1057
00:35:23,839 --> 00:35:26,320
pre-established threshold for when

1058
00:35:26,320 --> 00:35:29,520
um taking no action

1059
00:35:29,520 --> 00:35:31,680
is worse than taking potentially a very

1060
00:35:31,680 --> 00:35:33,040
negative action

1061
00:35:33,040 --> 00:35:36,560
uh i think in the context of uh the dod

1062
00:35:36,560 --> 00:35:37,119
example

1063
00:35:37,119 --> 00:35:39,599
there were pre uh there were authorities

1064
00:35:39,599 --> 00:35:41,440
for actions and accountabilities for

1065
00:35:41,440 --> 00:35:42,240
outcomes

1066
00:35:42,240 --> 00:35:44,400
but we don't we organizations don't

1067
00:35:44,400 --> 00:35:46,160
always have that and so

1068
00:35:46,160 --> 00:35:48,160
uh i think it's important that when you

1069
00:35:48,160 --> 00:35:49,359
consider uh

1070
00:35:49,359 --> 00:35:53,200
connecting again machine learning and um

1071
00:35:53,200 --> 00:35:54,880
automation that you have these

1072
00:35:54,880 --> 00:35:56,079
thresholds and you have these

1073
00:35:56,079 --> 00:35:57,520
authorities and accountabilities for

1074
00:35:57,520 --> 00:35:58,320
whatever outcome

1075
00:35:58,320 --> 00:36:01,760
comes out of it so

1076
00:36:01,760 --> 00:36:02,800
let's look at all those different

1077
00:36:02,800 --> 00:36:05,520
frameworks together compare them

1078
00:36:05,520 --> 00:36:08,800
and what we can see is that

1079
00:36:08,800 --> 00:36:12,079
for the most part things are if i

1080
00:36:12,079 --> 00:36:14,079
if i look across all these different

1081
00:36:14,079 --> 00:36:15,440
frameworks they

1082
00:36:15,440 --> 00:36:17,839
are generally uh similar in that regard

1083
00:36:17,839 --> 00:36:18,560
and that

1084
00:36:18,560 --> 00:36:21,359
they're still uh ai ml today is still

1085
00:36:21,359 --> 00:36:23,119
very much in the early stages

1086
00:36:23,119 --> 00:36:26,400
um and cover the space that you see down

1087
00:36:26,400 --> 00:36:27,359
here

1088
00:36:27,359 --> 00:36:31,119
and then when it comes to the guardrails

1089
00:36:31,839 --> 00:36:33,359
again connecting them we're going to be

1090
00:36:33,359 --> 00:36:35,680
doing regardless

1091
00:36:35,680 --> 00:36:37,520
but we want to make sure that we take

1092
00:36:37,520 --> 00:36:39,359
very deliberate steps to think about

1093
00:36:39,359 --> 00:36:41,200
what these guy rails need to be and so

1094
00:36:41,200 --> 00:36:42,240
here's a summary of some of the

1095
00:36:42,240 --> 00:36:44,000
guardrails that we went through

1096
00:36:44,000 --> 00:36:46,079
one is make sure that your sources are

1097
00:36:46,079 --> 00:36:47,520
trustworthy

1098
00:36:47,520 --> 00:36:50,320
and one way to have trustworthy sensors

1099
00:36:50,320 --> 00:36:52,000
is to have a lot of diversity in the

1100
00:36:52,000 --> 00:36:52,960
sensors

1101
00:36:52,960 --> 00:36:54,800
make sure that you have inputs from

1102
00:36:54,800 --> 00:36:56,079
multiple sources

1103
00:36:56,079 --> 00:36:57,760
and you can compare and contrast them i

1104
00:36:57,760 --> 00:36:59,359
think virustotal is a great example of

1105
00:36:59,359 --> 00:37:01,760
this because you have many sensors

1106
00:37:01,760 --> 00:37:03,760
some of which individually may not be

1107
00:37:03,760 --> 00:37:05,680
that trustworthy but collectively

1108
00:37:05,680 --> 00:37:09,599
provides a trustworthy source

1109
00:37:09,599 --> 00:37:12,960
algorithmic integrity we need to make

1110
00:37:12,960 --> 00:37:13,440
sure that

1111
00:37:13,440 --> 00:37:16,320
whatever process we're expecting to have

1112
00:37:16,320 --> 00:37:17,040
happen

1113
00:37:17,040 --> 00:37:19,760
is well documented and understood we

1114
00:37:19,760 --> 00:37:20,480
have

1115
00:37:20,480 --> 00:37:22,320
situations where oftentimes we have

1116
00:37:22,320 --> 00:37:24,000
automation kick in

1117
00:37:24,000 --> 00:37:25,359
and people have no idea what kind of

1118
00:37:25,359 --> 00:37:27,200
automation's actually happening

1119
00:37:27,200 --> 00:37:29,839
uh there was an article way back around

1120
00:37:29,839 --> 00:37:30,960
uh

1121
00:37:30,960 --> 00:37:33,200
automation should be more like iron man

1122
00:37:33,200 --> 00:37:34,960
and less like ultron

1123
00:37:34,960 --> 00:37:38,640
right iron man uh is fully in control of

1124
00:37:38,640 --> 00:37:40,880
what's going on and he understands how

1125
00:37:40,880 --> 00:37:42,000
to operate it

1126
00:37:42,000 --> 00:37:45,359
ultra ultron oh yeah we don't

1127
00:37:45,359 --> 00:37:46,960
you have you're rolling the dice in many

1128
00:37:46,960 --> 00:37:49,040
ways

1129
00:37:49,040 --> 00:37:50,400
next guardrail is to have bounded

1130
00:37:50,400 --> 00:37:52,960
conditions make sure that any decisions

1131
00:37:52,960 --> 00:37:55,920
uh are highly deterministic and narrowly

1132
00:37:55,920 --> 00:37:56,480
scoped

1133
00:37:56,480 --> 00:37:58,320
and use extensive regression testing to

1134
00:37:58,320 --> 00:37:59,520
make sure that

1135
00:37:59,520 --> 00:38:02,640
it stays within that scope

1136
00:38:02,640 --> 00:38:05,599
we want reversibility so if something

1137
00:38:05,599 --> 00:38:07,119
happens you want to be able to

1138
00:38:07,119 --> 00:38:09,280
stick it immediately in reverse gear and

1139
00:38:09,280 --> 00:38:10,880
be able to uh

1140
00:38:10,880 --> 00:38:13,839
to revert a change um having a kill

1141
00:38:13,839 --> 00:38:14,880
switch

1142
00:38:14,880 --> 00:38:17,359
is going to be pretty important as we

1143
00:38:17,359 --> 00:38:20,720
move forward in this new world

1144
00:38:20,880 --> 00:38:23,040
then as i mentioned towards the end make

1145
00:38:23,040 --> 00:38:24,320
sure that you have these established

1146
00:38:24,320 --> 00:38:25,040
thresholds

1147
00:38:25,040 --> 00:38:28,079
when you can actually put that through

1148
00:38:28,079 --> 00:38:29,359
that kill switch

1149
00:38:29,359 --> 00:38:32,800
and also have accountabilities for those

1150
00:38:32,800 --> 00:38:35,920
actions that people take for the for the

1151
00:38:35,920 --> 00:38:38,079
the actions that the machine takes to

1152
00:38:38,079 --> 00:38:40,960
have people who are accountable for them

1153
00:38:40,960 --> 00:38:43,200
ultimately my my point in this whole

1154
00:38:43,200 --> 00:38:44,720
discussion is

1155
00:38:44,720 --> 00:38:48,400
uh we will we will um naturally connect

1156
00:38:48,400 --> 00:38:49,359
these things together

1157
00:38:49,359 --> 00:38:51,599
we do this uh in our heads all the time

1158
00:38:51,599 --> 00:38:52,720
where we

1159
00:38:52,720 --> 00:38:54,640
take something that a machine does and

1160
00:38:54,640 --> 00:38:57,200
then have it wanted to act immediately

1161
00:38:57,200 --> 00:39:00,079
the point here is to have a conscious

1162
00:39:00,079 --> 00:39:02,079
mental chasm that we create here

1163
00:39:02,079 --> 00:39:04,720
that says before i connect a machine

1164
00:39:04,720 --> 00:39:06,880
driven sense making apparatus

1165
00:39:06,880 --> 00:39:09,520
to a machine driven acting apparatus

1166
00:39:09,520 --> 00:39:10,880
let's make sure that we

1167
00:39:10,880 --> 00:39:12,720
know that we're deliberately doing that

1168
00:39:12,720 --> 00:39:14,400
and when we do that we

1169
00:39:14,400 --> 00:39:15,680
walk through these guard rails and

1170
00:39:15,680 --> 00:39:17,440
ensure that we're not going to shoot

1171
00:39:17,440 --> 00:39:19,359
ourselves in the foot

1172
00:39:19,359 --> 00:39:20,720
and with that i'll leave you with this

1173
00:39:20,720 --> 00:39:22,640
modest proposal

1174
00:39:22,640 --> 00:39:26,240
um i think we're on this inevitable

1175
00:39:26,240 --> 00:39:28,079
march towards building skynet

1176
00:39:28,079 --> 00:39:30,079
but let's just wait till it turns 25

1177
00:39:30,079 --> 00:39:31,280
before it

1178
00:39:31,280 --> 00:39:33,760
we give it weapons that might kill us

1179
00:39:33,760 --> 00:39:34,560
and with that

1180
00:39:34,560 --> 00:39:43,119
thanks very much

1181
00:39:43,119 --> 00:39:45,119
all right well uh that was that was a

1182
00:39:45,119 --> 00:39:48,400
hell of a way to close out the year man

1183
00:39:50,320 --> 00:39:52,560
uh the good news is we are years away

1184
00:39:52,560 --> 00:39:53,440
from that so

1185
00:39:53,440 --> 00:39:55,440
uh it's this is this is going to be what

1186
00:39:55,440 --> 00:39:58,720
like a 20 40 uh problem

1187
00:39:58,720 --> 00:40:02,880
um well um

1188
00:40:02,880 --> 00:40:04,960
well in terms if you're talking about

1189
00:40:04,960 --> 00:40:06,079
skynet like the

1190
00:40:06,079 --> 00:40:11,680
the the terminator version of it then

1191
00:40:11,680 --> 00:40:13,440
who knows right it could be never it

1192
00:40:13,440 --> 00:40:16,000
could be 40 years it could be

1193
00:40:16,000 --> 00:40:19,280
yeah well it may be a while um but

1194
00:40:19,280 --> 00:40:20,640
i'm pretty certain that we're going to

1195
00:40:20,640 --> 00:40:22,839
start giving and i'll give you a link on

1196
00:40:22,839 --> 00:40:24,560
the down here

1197
00:40:24,560 --> 00:40:25,920
i'm pretty sure that we're starting to

1198
00:40:25,920 --> 00:40:28,800
give weapons to to essentially teenagers

1199
00:40:28,800 --> 00:40:31,599
and 13 year olds

1200
00:40:32,640 --> 00:40:35,200
that's not scary no that's a really

1201
00:40:35,200 --> 00:40:36,480
interesting way to tie it

1202
00:40:36,480 --> 00:40:40,000
um from uh what has been i i saw a post

1203
00:40:40,000 --> 00:40:41,280
earlier was talking about how

1204
00:40:41,280 --> 00:40:43,920
the problem with the turing test is that

1205
00:40:43,920 --> 00:40:46,480
it has become like a standard to achieve

1206
00:40:46,480 --> 00:40:48,079
and so we end up with ai that's really

1207
00:40:48,079 --> 00:40:50,079
good at faking conversation versus the

1208
00:40:50,079 --> 00:40:51,760
original intent of what it was meant to

1209
00:40:51,760 --> 00:40:52,480
be

1210
00:40:52,480 --> 00:40:54,960
and so tying it to emotional maturity i

1211
00:40:54,960 --> 00:40:57,040
think is a much more interesting way to

1212
00:40:57,040 --> 00:41:00,160
kind of frame the problem

1213
00:41:00,240 --> 00:41:02,000
yeah i haven't had a chance to check out

1214
00:41:02,000 --> 00:41:03,680
discord but because it's over on this

1215
00:41:03,680 --> 00:41:06,880
computer over here but um

1216
00:41:06,880 --> 00:41:08,560
i'm curious as to what people would have

1217
00:41:08,560 --> 00:41:10,079
said at the very beginning again what

1218
00:41:10,079 --> 00:41:10,960
age would you

1219
00:41:10,960 --> 00:41:13,760
um peg it at and what sort of weapons

1220
00:41:13,760 --> 00:41:15,520
would you be willing to give it

1221
00:41:15,520 --> 00:41:17,359
and when you put it towards that

1222
00:41:17,359 --> 00:41:19,280
emotional bench market

1223
00:41:19,280 --> 00:41:21,440
it helps us really recalibrate our

1224
00:41:21,440 --> 00:41:22,800
expectations of what we should

1225
00:41:22,800 --> 00:41:25,359
uh what we should have towards these

1226
00:41:25,359 --> 00:41:28,400
algorithms that we were using

1227
00:41:28,560 --> 00:41:30,000
it's definitely a one-year-old throwing

1228
00:41:30,000 --> 00:41:31,839
a fit right now i think

1229
00:41:31,839 --> 00:41:33,520
atlas said it's pooping its pants most

1230
00:41:33,520 --> 00:41:36,240
of the time so

1231
00:41:37,040 --> 00:41:39,839
i i i would certainly give it um i would

1232
00:41:39,839 --> 00:41:41,520
definitely say it's uh

1233
00:41:41,520 --> 00:41:43,040
it's not what we expected to be but i

1234
00:41:43,040 --> 00:41:44,319
would give it i would give it more

1235
00:41:44,319 --> 00:41:45,920
credit than being a one-year-old i would

1236
00:41:45,920 --> 00:41:46,960
still say it like

1237
00:41:46,960 --> 00:41:50,000
maybe around 10

1238
00:41:50,000 --> 00:41:52,240
10 years old ten i would i would have

1239
00:41:52,240 --> 00:41:53,920
said uh between the ages of three and

1240
00:41:53,920 --> 00:41:55,920
four

1241
00:41:55,920 --> 00:41:57,520
i think it's a toddler that started to

1242
00:41:57,520 --> 00:41:59,680
learn how to say no and applies it to

1243
00:41:59,680 --> 00:42:02,000
all the situations

1244
00:42:02,000 --> 00:42:04,079
well as anyone who has kids know they

1245
00:42:04,079 --> 00:42:06,240
grow up very fast

1246
00:42:06,240 --> 00:42:09,680
and before you know it they become

1247
00:42:09,680 --> 00:42:10,800
adults

1248
00:42:10,800 --> 00:42:13,760
and you want to make sure that you train

1249
00:42:13,760 --> 00:42:14,839
them well right

1250
00:42:14,839 --> 00:42:18,240
so um anyway

1251
00:42:18,240 --> 00:42:19,760
you do realize the threat in this

1252
00:42:19,760 --> 00:42:21,280
metaphor is less what's going to happen

1253
00:42:21,280 --> 00:42:23,119
in 25 years but when this thing becomes

1254
00:42:23,119 --> 00:42:27,040
a teenager

1255
00:42:28,839 --> 00:42:30,400
um well

1256
00:42:30,400 --> 00:42:33,599
again we let teenagers drive at age 16

1257
00:42:33,599 --> 00:42:35,200
right and we let

1258
00:42:35,200 --> 00:42:38,240
them have anyway we let people have a

1259
00:42:38,240 --> 00:42:40,160
lot of capabilities before

1260
00:42:40,160 --> 00:42:41,839
they have a fully developed prefrontal

1261
00:42:41,839 --> 00:42:46,799
cortex hence what i'm proposing

1262
00:42:46,880 --> 00:42:48,880
uh well there is a robust conversation

1263
00:42:48,880 --> 00:42:50,079
that has been going on throughout your

1264
00:42:50,079 --> 00:42:52,400
talk on discord

1265
00:42:52,400 --> 00:42:54,880
uh all sorts of different uh commentary

1266
00:42:54,880 --> 00:42:56,960
from answering your questions

1267
00:42:56,960 --> 00:42:58,640
to take the conversation and of course

1268
00:42:58,640 --> 00:43:00,720
and delightful uh tangents

1269
00:43:00,720 --> 00:43:02,880
uh so we we look forward to seeing what

1270
00:43:02,880 --> 00:43:03,920
you bring up there

1271
00:43:03,920 --> 00:43:06,160
thank you for uh helping as well yeah

1272
00:43:06,160 --> 00:43:07,520
thank you for joining us this morning

1273
00:43:07,520 --> 00:43:10,560
sunil my pleasure thanks for having me

1274
00:43:10,560 --> 00:43:19,200
uh happy new year everyone thank you

