1
00:00:13,264 --> 00:00:18,563
Herzlich willkommen zu meinem Talk. Vielen Dank für die nette Einführung und die nette Begrüßung von euch allen!

2
00:00:18,563 --> 00:00:25,472
Ihr seht der Talk hat den anspielungsreichen Namen "Überwachen und Sprache"

3
00:00:25,472 --> 00:00:28,343
spielt natürlich auf Foucault an "Überwachen und Strafen"

4
00:00:28,343 --> 00:00:36,115
Allerdings, lange bevor Foucault die Genese der Disziplinargesellschaft dargestellt hat

5
00:00:36,115 --> 00:00:41,592
findet man in einem Kinderbuch eine sehr schöne moralische Erzählung

6
00:00:41,592 --> 00:00:48,776
die heißt "Das Kind im Glashaus" von Heinrich Oswalt entstanden 1877 und sehr weitsichtig

7
00:00:48,776 --> 00:00:53,111
*In Frankfurt lebt ein Glasermeister,
Herr Lebrecht Scheibenmann, so heißt er;*

8
00:00:53,111 --> 00:00:56,960
*Der hat ein kleines Töchterlein,
Das wollte nie gewaschen sein.*

9
00:00:56,960 --> 00:00:59,576
*Und kam mit Schwamm und Seif sein Gretchen,
Da lief davon das böse Mädchen;*

10
00:00:59,576 --> 00:01:04,408
*Es warf sogar den Waschtisch um -
Das Wasser floß im Haus herum.*

11
00:01:04,408 --> 00:01:09,695
*Da fing Herr Lebrecht Scheibenmann
Ein seltsam Haus zu bauen an,*

12
00:01:09,695 --> 00:01:13,519
*Aus lauter Glas ein Haus, das, ach!
Durchsichtig war bis unters Dach.*

13
00:01:13,519 --> 00:01:16,479
*Und in dies Glashaus setzte man
Das böse Töchterlein sodann.*

14
00:01:16,479 --> 00:01:19,739
*Da blieben, um es anzusehn,
Die Leute auf der Straße stehn.*

15
00:01:19,739 --> 00:01:23,575
*[…]
Da schämte sich das Kind und lief
Im ganzen Haus herum und rief:*

16
00:01:23,575 --> 00:01:26,359
*“Wo soll ich mich denn nur verstecken?
Man sieht mich ja in allen Ecken!*

17
00:01:26,359 --> 00:01:31,839
*Das Dach, der Keller, jedes Zimmer
Ist ja von Glas! man sieht mich immer!”*

18
00:01:31,839 --> 00:01:35,967
*Die Mutter sprach: “Mein liebes Kind!
Ein Mittel gibt’s, das hilft geschwind:*

19
00:01:35,967 --> 00:01:40,360
*Wenn dich die Leute artig sehn
Dann werden sie vorübergehn;*

20
00:01:40,360 --> 00:01:43,472
*[…]
Das merkte sich das Töchterlein;
Es nahm sich vor, geschickt zu sein.*

21
00:01:43,472 --> 00:01:46,831
*Und weil’s beim Waschen nicht mehr schrie,
Da lachten auch die Leute nie;*

22
00:01:46,831 --> 00:01:50,791
*Denn jeder, der ins Haus jetzt blickt,
Der sieht ein Kind, das ganz geschickt.*

23
00:01:50,791 --> 00:01:54,888
*Und habt Ihr selbst ein Kind, Ihr Leut’,
Das bei dem Waschen immer schreit,*

24
00:01:54,888 --> 00:02:01,431
*Sagts nur Herrn Lebrecht Scheibenmann,
Der schafft Euch gleich ein Glashaus an.*

25
00:02:01,431 --> 00:02:09,935
Ja, da … erste Applausansätze *lacht*
*Applaus*

26
00:02:09,935 --> 00:02:13,487
Ja, interessante Geschichte, die natürlich sehr gut auf unsere Zeit passt

27
00:02:13,487 --> 00:02:21,264
denn Lebrecht Scheibenmann heißt Keith Alexander und arbeitet für die NSA

28
00:02:21,941 --> 00:02:26,311
Die NSA hat aus unser aller Zuhause Glashäuser gemacht

29
00:02:26,311 --> 00:02:29,127
wir können alle gesehen werden in diesen Glashäusern

30
00:02:29,127 --> 00:02:39,559
und man weiß nicht, bzw. ich bin mir ziemlich sicher, dass man damit pädagogische Ziele verfolgt

31
00:02:39,559 --> 00:02:43,351
dass bestimmte Handlungen nicht mehr als akzeptabel gelten

32
00:02:43,351 --> 00:02:47,320
und dass wir diese Beobachtung verinnerlichen

33
00:02:47,320 --> 00:02:51,552
Bei dieser Beobachtung spielt Sprache natürlich eine ganz wichtige Rolle

34
00:02:51,552 --> 00:02:56,535
Viele unserer Äußerungen finden im Medium der Sprache statt

35
00:02:56,535 --> 00:03:05,655
Das hat auch viele Hacker auf die Idee gebracht, dass wir die NSA austricksen mit einer Seite wie "Hallo NSA"

36
00:03:05,655 --> 00:03:16,767
Eine Website, die wie ein „Bullshitter“ verdächtige Wörter zu Botschaften zusammensetzt

37
00:03:16,767 --> 00:03:23,895
und diese dann getweetet, gemailt oder verchattet werden sollen

38
00:03:23,895 --> 00:03:30,399
um soetwas zu erreichen wie hier "Operation Troll the NSA“

39
00:03:30,399 --> 00:03:35,879
dass man die NSA-Scanners jammen kann, dass man eine DDOS Attacke machen kann.

40
00:03:35,879 --> 00:03:44,370
indem man einfach zu viel Content schickt, der quasi verdächtig ist auf der Basis von Keywords

41
00:03:44,370 --> 00:03:50,911
In meinem Vortrag soll es darum gehen, dass dieses Bild von der NSA falsch ist.

42
00:03:50,911 --> 00:03:55,394
Wir können nicht davon ausgehen, dass in der NSA die Leute tatsächlich bei Anzeige eines Keywords

43
00:03:55,394 --> 00:04:05,358
sofort etwas ausdrucken und zu einer *Gelächter*
Analyse schreiten

44
00:04:05,404 --> 00:04:10,968
und sich das genauer anschauen und qualitativ quasi auswerten

45
00:04:11,060 --> 00:04:13,519
und das natürlich eine sehr intensive Tätigkeit

46
00:04:13,519 --> 00:04:26,504
und deswegen ist ein Keyword-Spam-DDoS natürlich erfolglos wäre

47
00:04:28,900 --> 00:04:34,100
Ihr alle werdet vermutlich die thanksgiving taklkingpoints der NSA gelesen haben.

48
00:04:34,100 --> 00:04:41,880
Ich weiß nicht, ob ihr darüber gestolpert seid, dass unter Punkt 4 etwas ganz wichtiges steht

49
00:04:41,880 --> 00:04:47,888
“NSA brings together the best linguists, analysts, mathematicians, engineers and computer scientists

50
00:04:47,888 --> 00:04:52,249
in the United States.“ 
und die Linguisten werden als erstes genannt.

51
00:04:52,249 --> 00:04:56,290
*verhaltenes Lachen*

52
00:04:56,290 --> 00:05:02,063
Also da sieht man, der NSA ist durchaus bewusst, dass Sprache ein wichtiges Medium ist

53
00:05:02,063 --> 00:05:08,603
und das auch für sie sehr wichtig ist. Insofern macht es durchaus Sinn, sich damit zu beschäftigen

54
00:05:08,603 --> 00:05:16,755
Zufälligerweise wurde vom Innenminister die neuste Analysesoftware geleakt, der "Advanced Security Toolkit"

55
00:05:16,755 --> 00:05:25,514
Entwickelt vom von-Leitner-institut für verteiltes Echtzeit-Java. *Gelächter*

56
00:05:27,530 --> 00:05:31,193
Wir gucken uns zunächst unsere heutige Mission an.

57
00:05:31,193 --> 00:05:35,913
Die heutige Aufgabe besteht darin, die deutsche Bloggerszene unter die Lupe zu nehmen

58
00:05:35,913 --> 00:05:40,192
die radikalisiert sich ja offenbar seit Regierungsübernahme durch die Große Koalition

59
00:05:40,192 --> 00:05:47,928
wichtig ist es, zu schauen, ob Aktionen in Vorbereitung sind, und ggf. radikale Subjekte zu identifizieren,

60
00:05:47,928 --> 00:05:59,747
die sich da besonders hervortun. Zunächst wählen wir unsere Targets, wir kriegen natürlich welche vorgeschlagen

61
00:05:59,747 --> 00:06:03,873
Leider kann ich nur eine kleine Auswahl möglicher Targets präsentieren. Ich hätte gerne noch viel mehr genommen

62
00:06:03,873 --> 00:06:06,241
Es gibt ein paar gesellschaftskritische Blogs und Newssites

63
00:06:06,241 --> 00:06:11,900
wie blog.fefe.de, indymedia, Mädchenmannschaft, Netzpolitik.org, rebellmarkt.blogger.de

64
00:06:11,900 --> 00:06:18,361
Und religiös motivierte Webseiten, wie kreuz.net, islambruderschaft.com-blog und Diskussionsforum salafistisches

65
00:06:18,361 --> 00:06:23,229
und wir bestätigen natürlich die Auswahl. Das ist eine sehr sinnvolle Auswahl

66
00:06:23,229 --> 00:06:31,681
Folgende Analysen sind möglich. Ich kann natürlich nur eine Auswahl an möglichen Analysetools heute zeigen

67
00:06:31,681 --> 00:06:36,417
Ich würde gerne viel mehr zeigen, aber die Zeit wird nicht reichen.

68
00:06:36,417 --> 00:06:42,361
Zunächst gucken wir uns an, was schreiben Autoren über mögliche sensible Ziele

69
00:06:42,361 --> 00:06:46,193
Wir machen also mal eine Zielanalyse.

70
00:06:46,193 --> 00:06:55,980
diese untersucht auf Basis von Named-Entity-Recognition die Kollokation zu möglichen Terrorzielen

71
00:06:55,980 --> 00:07:04,393
Wir müssen … was ist das denn? … wir gucken mal ins Handbuch rein, was Named Entities sind

72
00:07:04,393 --> 00:07:08,649
ist ja unser erster Tag heute

73
00:07:08,649 --> 00:07:19,577
Named-Entities sind zunächst mal Ausdrücke, die eine Etentität eindeutig von anderen Entitäten mit ähnlichen Attributen unterscheiden

74
00:07:19,577 --> 00:07:25,139
Man denkt spontan an Namen, aber es ist nicht so trivial zu sagen was ein Name ist

75
00:07:25,139 --> 00:07:31,690
Named-Entitiy-Recognition ist entsprechend das Verfahren, wie man solche Named Entities identifiziert

76
00:07:31,690 --> 00:07:43,889
Es gibt sicherlich unterschiedliche Klassen von Named Entities, bspw. Personen, Organisationen, Orte

77
00:07:43,889 --> 00:07:51,217
Manchmal ist auch nicht so deutlich zu was eine bestimmte Named Entity gehört. z.B. „der Bundestag“

78
00:07:51,217 --> 00:07:57,361
das kann sowohl ein geografischer Ort sein, als auch eine Organisation

79
00:08:02,100 --> 00:08:06,241
Jetzt müssen wir noch wissen, was Kollokationen sind

80
00:08:06,241 --> 00:08:12,409
Das sind statistisch überzufällig häufige Wortkombinationen

81
00:08:12,409 --> 00:08:22,849
d.h. “we define a collocation as a combination of two words, that exhibit a tendency to occur near each other in natural language that is to cooccur”

82
00:08:22,849 --> 00:08:27,369
also z.B. „ein Weg einschlagen“, „ein Weg gehen“

83
00:08:27,369 --> 00:08:31,761
Das sind typische Verbindungen zwischen den Worten „Weg“, „gehen“ bzw. „einschlagen“

84
00:08:31,761 --> 00:08:41,024
und diese Verbindungen bilden Kollokationen, wenn sie überzufällig sind

85
00:08:41,024 --> 00:08:44,929
wie wir mit statistischen Tests feststellen können

86
00:08:44,929 --> 00:08:48,313
und wir können die in natürlicher Sprache beobachten

87
00:08:48,313 --> 00:08:53,569
Ein Beispiel – ihr müsst das jetzt nicht lesen können – ich wollte ein Beispiel zeigen zum Wort „Spezialexperte“

88
00:08:53,569 --> 00:08:59,100
man sieht hier das “keyword in context”, also das gesuchte Schlüsselwort

89
00:08:59,100 --> 00:09:07,242
und man sieht die Kontexte dieses Wortes, also einen „ausgesuchten Spezialexperten für Internetfragen“ haben sie wohl nicht gefunden

90
00:09:07,242 --> 00:09:12,337
Wir müssen kein Ratespiel machen, aus welchem Blog das wohl stammen könnte

91
00:09:12,337 --> 00:09:15,217
Was man dann macht, bei einer Kollokationsanalse
man untersucht Kontexte

92
00:09:15,217 --> 00:09:22,457
z.B. hier fünf Wörter links, fünf Wörter rechts bis Satzanfang oder -ende

93
00:09:22,457 --> 00:09:28,833
Man zählt einfach die Wörter, die im blauen Bereich stehen

94
00:09:28,833 --> 00:09:35,832
und vergleicht die relative Frequenz mit Wörtern, die links und rechts im weißen Bereich stehen

95
00:09:35,832 --> 00:09:43,947
Wenn ein Wort signifikant häufiger im blauen Bereich vorkommt, kann man sagen, es ist eine Kollokation des Worts „Spezialexperte“

96
00:09:43,947 --> 00:09:49,529
Hier fällt bspw. auf „kriegen“ oder „Adobe-Spezialexperten“ *Gelächter*

97
00:09:49,529 --> 00:09:58,395
Man kann Kollokationen als Graphen visualisieren *Gelächter*

98
00:09:59,672 --> 00:10:05,961
Die Knoten bezeichnen Lexeme, (ich weiß jetzt nicht, was es da zu lachen gibt) *mehr Gelächter*

99
00:10:05,961 --> 00:10:12,170
(das ist ernste Linguistik!) und die Kanten bezeichnen „ist Kollokation von“

100
00:10:12,170 --> 00:10:18,625
Sie sehen also hier „die besten der besten, Sir“, Sarrazin und Mehdorn gehören dazu.

101
00:10:18,625 --> 00:10:24,258
Es wuchert ein bisschen weiter. „Adobe-Backup“, „Backup-Spezialexperten“ … interessant

102
00:10:24,258 --> 00:10:34,880
Ok. Wir sind im Bereich der Zielanalyse. Wir starten mal die Analyse.

103
00:10:34,880 --> 00:10:43,241
Was machen wir da eigentlich? Was wir machen ist, wir erkennen in allen Corpora alle Named Entities

104
00:10:43,241 --> 00:10:49,537
Wir berechnen das erstmal mit Methoden maschinellen Lernens.

105
00:10:49,537 --> 00:10:53,409
D.h. man untersucht bestimmte Kontexte in denen Named Entities stehen.

106
00:10:53,409 --> 00:10:59,361
Wir haben einen Trainings-Corpus, in dem steht bereits drin, was Named Entities sind

107
00:10:59,361 --> 00:11:07,569
bspw. dass „Bundestag“ eine Organisation ist und die Software lernt aus diesen Kontexten

108
00:11:07,569 --> 00:11:16,913
was typische Kontexte für solche Named Intities sind und versucht diese auf neue Corpora anzuwenden

109
00:11:16,913 --> 00:11:23,162
Was wir hier machen: wir identifizieren in allen Corpora, in allen Blogs, die wir untersuchen die Named Entities.

110
00:11:23,162 --> 00:11:28,309
wir kategorisieren diese Named Entities nach Personen, Organisationen, geografischen Orten und Sonstigen

111
00:11:28,309 --> 00:11:32,408
und dann berechnen wir die Kollokationen eben zu relevanten Named Entities.

112
00:11:32,408 --> 00:11:37,353
z.B. „Angela Merkel” könnte interessant sein oder sowas.

113
00:11:37,353 --> 00:11:45,281
Und dann schauen wir auch in den Kollokationen, ob darin irgendwelche Gefährderwörter sind.

114
00:11:45,281 --> 00:11:50,634
Also Wörter, die auf Anschlagsplanungen oder sonstiges hindeuten. Das machen wir jetzt.

115
00:11:50,634 --> 00:12:02,157
die Analyse ist offenbar abgeschlossen und Ergebnis ist, wir haben Gefahrenstufe 1 von 5, also nicht weiter tragisch

116
00:12:02,157 --> 00:12:12,730
die Software schlägt uns eine Überprüfung der Gefährdungslage in Hinblick auf Berlin vor

117
00:12:12,730 --> 00:12:17,377
also der Ortsangabe bei donalphonso, Rebellmarkt-Blogger

118
00:12:17,377 --> 00:12:31,769
Potentielles Ziel bei Fefe ist SPD *Gelächter* und bei der Mädchenmanschaft sollen wir nach Kristina Schröder als Person gucken *Gelächter*

119
00:12:31,769 --> 00:12:45,942
Wir haben jetzt zum Beispiel als Auftrag bekommen, zu schauen, warum donalphonso Böses über Berlin schreibt und ggf. etwas plant

120
00:12:45,942 --> 00:12:50,219
Wir können uns jetzt Kollokationsgraphen anzeigen lassen oder Geokollokationen

121
00:12:50,219 --> 00:13:00,588
D.h. wir haben eine Landkarte und darauf stehen an den Orten, über die donalphonso schreibt, die Kollokationen zu den Orten

122
00:13:00,588 --> 00:13:07,153
In Amerika schreibt er über Boyd und Kultur, Einzeltäter, verwirrt und „hassen Mail“ und sowas

123
00:13:07,153 --> 00:13:15,444
Deutschland, Mitteleuropa ist natürlich im Fokus. Das geht auch bis Italien runter

124
00:13:15,444 --> 00:13:20,444
Da sieht man auch, worüber donalphonso so schreibt.

125
00:13:20,444 --> 00:13:26,229
Wir nähern uns Berlin. Da sind zu viele Kollokationen als dass wir sie alle auswerten könnten

126
00:13:26,229 --> 00:13:35,804
Deswegen schauen wir uns den Kollokationsgraphen an und suchen nach Hinweisen auf Terror, der stattfinden könnte

127
00:13:35,804 --> 00:13:45,690
Ich lese einige vor: „Berlin“, „Slum“, „Reichshauptslum“, „arm“, „Transferleistung“, „abscheulich“, „Berliner Hipster“ *Gelächter*

128
00:13:45,690 --> 00:13:54,268
Das zeigt zwar eine sehr negative Haltung zu dem Gegenstand, aber ich würde nicht sagen terrorverdächtig.

129
00:13:54,268 --> 00:14:01,295
Das weitere potentielle Ziel waren die Organisationen „SPD“ bei Fefe

130
00:14:01,295 --> 00:14:13,572
Wir lassen uns den Kollokationsgraphen anschauen. Fefe und die SPD. *Gelächter*
*Applaus*

131
00:14:13,572 --> 00:14:17,789
hey „Verräterpartei“, „Umfallerpartei“, mal kurz zurück

132
00:14:17,789 --> 00:14:20,856
Insgesamt in der gesamten Liste fanden sich tatsächlich so Wörter wie:

133
00:14:20,856 --> 00:14:36,773
„erhängen“, „erzwingen“, „Spitzenkandidat“, „Verräterpartei“, „Umfallerpartei“, „Pest“, „Cholera“ *Gelächter, Applaus*

134
00:14:36,773 --> 00:14:42,277
Wenn wir uns den Kollokationsgraphen anschauen, dann merken wir schon, das sind Vorwurfshandlungen.

135
00:14:42,277 --> 00:14:54,019
Aber da wird nicht geplant, dass der Spitzenkandidat um die Ecke gebracht werden soll von Fefe

136
00:14:56,158 --> 00:15:02,477
Wir machen jetzt weiter mit dem Ideologiemonitor. Wir wollen jetzt mal messen …

137
00:15:02,477 --> 00:15:15,530
Es ist belegt, dass die NSA viele Softwarepatente für Algorithmen zu Named-Entity-Recognition angemeldet hat

138
00:15:15,530 --> 00:15:19,689
Es wurde in der Tat viel in dem Bereich Forschung betrieben vor einiger Zeit

139
00:15:19,689 --> 00:15:27,711
Aber man findet zunächst heraus, was interessante Targets sind und was über die gesagt wird

140
00:15:27,711 --> 00:15:34,234
Das kann man sicherlich noch besser machen, in dem man Idieologien misst.

141
00:15:34,234 --> 00:15:44,227
Was wir jetzt berechnen wollen ist die Ähnlichkeit von Texten, von Blogs zu bestimmten weltanschaulichen Ideologien

142
00:15:44,227 --> 00:15:53,428
Wir haben die Möglichkeit, linksextreme, rechtsextreme oder islamistische Einstellungen zu messen

143
00:15:53,428 --> 00:16:06,579
Das machen wir so, dass wir typische Kollokationen berechnen … also zu einem bestimmten Korpus

144
00:16:06,579 --> 00:16:11,990
Von diesem Korpus lernen wir. Das ist also das Vergleichsmodell.

145
00:16:11,990 --> 00:16:18,269
Wir nehmen mal die „Islambruderschaft“. Die hat ein Blog und da schreiben sie böse Sachen

146
00:16:18,269 --> 00:16:33,510
und wir lernen von diesem Blog: was sind typische Wortverbindungen, die wir als islamistisch betrachten können

147
00:16:33,510 --> 00:16:42,187
wir wollen gerne wissen, wer in einem salafistischen Diskussionsforum besonders viel von radikalislamischer Ideologie hat

148
00:16:42,187 --> 00:16:52,579
also das ist ein ganz fieses Untersuchungsprogramm, das wir hier starten. Ja, die Analyse läuft

149
00:16:52,579 --> 00:16:59,968
Das Ziel ist es, wie sind bestimte Texte von bestimmter Ideologie durchdrungen

150
00:16:59,968 --> 00:17:09,363
und wir gleichen ein salafistisches Diskussionsforum mit unserem Trainingskorpus ab

151
00:17:09,363 --> 00:17:15,395
und dieses Trainingscorpus ist ein Blog von der Islambruderschaft

152
00:17:15,395 --> 00:17:22,900
was wir bekommen sind Wortverbindungen, die womöglich auf islamistische Grundhaltungen verweisen

153
00:17:22,900 --> 00:17:24,799
– also ich hoffe, ihr denkt die Anführungszeichen immer mit –

154
00:17:24,799 --> 00:17:34,771
Wir haben hier „Allah -> Krieg“, „Bombe -> Jahr -> Feind“, „Kufr -> beleidigen“, „Gesetz -> Islam“, „Bedeutung -> Jihad“, „Allah -> Afghanistan“, „martern -> Kufr“, usw.

155
00:17:34,771 --> 00:17:41,750
Also es gibt eine ganze Reihe dieser Wortverbindungen, die wir aus diesem Korpus lernen

156
00:17:41,750 --> 00:17:49,819
und jetzt schauen wir, wie diese Wortverbindugnen in personenspezifischen Korpora von Mitgliedern

157
00:17:49,819 --> 00:17:56,851
in diesem Diskussionsforum vorkommen. Wir sehen hier einen User – natürlich ist der Nickname nicht echt

158
00:17:56,851 --> 00:18:02,371
man sieht es ein bisschen schlecht, aber hier sind rote Verbindungen angeleuchtet

159
00:18:02,371 --> 00:18:09,131
Das sind islamistische
*Gelächter*

160
00:18:09,131 --> 00:18:16,858
Das sind sämtliche Kollokationen in diesem Korpus mit der höchsten Typizität

161
00:18:16,858 --> 00:18:21,555
und solche Verdichtungspunkte verweisen auf bestimmte Themen

162
00:18:21,555 --> 00:18:28,546
Wir haben auch den User „JihadFan“ *Gelächter* – der aber offenbar auch nicht so jihadistisch unterwegs ist

163
00:18:28,546 --> 00:18:35,568
weil es sind relativ wenige – wir haben aber die Userin „Muslima“ – und leider sieht man das jetzt wirklich nicht so gut

164
00:18:35,568 --> 00:18:42,582
ich mach es mal ein bisschen größer – bei ihr sehen wir relativ viele rote Verbindungen

165
00:18:42,582 --> 00:18:48,386
wir können uns natürlich auch ein paar verdächtige Verbindungen anschauen

166
00:18:48,386 --> 00:18:54,595
jetzt müssen wir wieder klein werden – da sind solche Verbindungen wie „der -> ganzen -> Welt -> Frieden -> Krieg -> bringen“

167
00:18:54,595 --> 00:19:01,235
Da sind Verbindungen wie „Bombadierung -> Zivilist -> schlachten -> martern -> Invasoren“, „erfolgreiche -> Operation“

168
00:19:01,235 --> 00:19:12,603
oder Verbindungen wie „Koran -> Taliban -> edel -> Sieg“, die vielleicht auf das Schreiben über das Thema hindeuten

169
00:19:12,603 --> 00:19:17,838
das heißt, wir würden sagen, das wäre ein Ziel für weitere operative Maßnahmen, diese Userin,

170
00:19:17,838 --> 00:19:21,431
und das schicken wir ab und dann geht es weiter.

171
00:19:21,431 --> 00:19:35,946
Damit haben wir aber nichts mehr zu tun, denn wir sind ja nur Linguisten. *Gelächter, Applaus*

172
00:19:35,946 --> 00:19:42,990
Ich deute das als Zustimmung. *Gelächter* Gut, wir fahren mit weiteren Analyseschritten fort.

173
00:19:43,040 --> 00:19:59,379
Und zwar messen wir Radikalität. Radikalität ist etwas, das man so ohne weiteres erstmal nicht messen kann

174
00:19:59,379 --> 00:20:03,323
denn es ist ja selbst ein ideologisches Konzept

175
00:20:03,323 --> 00:20:13,590
Wir – vom Innenministerium – verstehen unter Radikalität zunächst eine stark negative Weltsicht

176
00:20:13,590 --> 00:20:20,406
wir verstehen darunter eine Intoleranz gegenüber abweichenden Auffassungen, also ein schwarz-weißes Weltbild

177
00:20:20,406 --> 00:20:26,147
wir verstehen darunter eine hohe emotionale Involviertheit

178
00:20:26,147 --> 00:20:37,683
und eine Neigung zu Verschwörungstheorien
*vereinzeltes Gelächter* Ja! *mehr Gelächter*

179
00:20:37,683 --> 00:20:48,990
Das ist nicht ganz vom Himmel gefallen. Es gibt tatsächlich Forschungsliteratur, die diese Punkte nennt

180
00:20:48,990 --> 00:20:55,966
wie operationalisieren wir das jetzt, also eine negative Weltsicht? Ich möchte euch zwei Ansätze vorstellen

181
00:20:55,966 --> 00:21:06,483
Es gibt also den sehr einfachen, listenbasierten Ansatz. Man sagt, wir haben eine bestimmte Liste von Wörten,

182
00:21:06,483 --> 00:21:16,109
deren Bedeutung wir kennen und gucken, wie häufig finden sich die Listenelemente in Texten

183
00:21:16,109 --> 00:21:21,700
Bspw. wenn wir „negative Weltsicht“ operationalisieren wollten, könnten wir sagen, wir suchen nach Phrasen

184
00:21:21,700 --> 00:21:26,531
oder auch Vokabeln, die skandalisieren, wie: „Blindheit“, „Blödheit“, „Bodenlosigkeit“, „Chaos“, „Debakel“,

185
00:21:26,531 --> 00:21:32,993
„Desaster“, „Dreistigkeit“, „Dummheit“, das könnte man alles anders nennen, könnte Indikator sein für negative Weltsicht

186
00:21:32,993 --> 00:21:39,443
Wir haben auch den Gebrauch von negativ wertenden Adjektiven. Nur mal die ersten: „abartig“, „aberwitzig“,

187
00:21:39,443 --> 00:21:45,850
„abfällig“, „abgedroschen“, „abgegriffen“, „abgeschmackt“, usw. Insgesamt 700, oder so

188
00:21:45,850 --> 00:21:50,771
das wäre also der listenbasierte Ansatz.

189
00:21:50,771 --> 00:21:56,747
Was wir natürlich auch machen können ist ein schwarzweißes Weltbild operationalisieren

190
00:21:56,747 --> 00:22:03,402
das kann man mit Hilfe von „semantischen Taxonomien“ machen. Semantische Taxonomien beschreiben die Relationen

191
00:22:03,402 --> 00:22:11,714
zwischen Wörtern in unserem Wortschatz, bspw. könnte auf schwarzweiß-Denken in Texten hindeuten

192
00:22:11,714 --> 00:22:25,202
eine hohe Frequenz von „polaren Antonymen“, also Gegensatzwörtern, die man ohne degradierte Form gebraucht

193
00:22:25,202 --> 00:22:30,645
also dass man sagt „lang“ und „kurz“ statt „länger …“ oder „kürzer als“.

194
00:22:30,645 --> 00:22:36,957
Noch deutlicher wird es vielleicht bei Wörtern, die gar nicht gradierbar sind, wie „wahr“ oder „falsch“,

195
00:22:36,957 --> 00:22:41,126
„tot oder lebendig“, „anwesend oder abwesend“, „dafür oder dagegen“. Da gibt es nichts dazwischen,

196
00:22:41,126 --> 00:22:51,959
die sind komplementär und ihr Gebrauch, könnte man meinen, lässt Rückschlüsse auf ein schwarzweißes Weltbild zu.

197
00:22:51,959 --> 00:22:57,733
Emotionale Involviertheit könnte man operationalisieren mit Hilfe von Gradpartikeln

198
00:22:57,733 --> 00:23:05,558
das ist sowas wie „ich finde das absolut toll“, oder „total toll“. Ja, nicht nur „toll“, sondern „total“

199
00:23:05,558 --> 00:23:10,403
Das wäre bspw. ein Gradpartikel aus dem absoluten Intensivierungsbereich

200
00:23:10,403 --> 00:23:21,210
wir können Gradpartikel unterscheiden nach Intensivierungsbereichen und es gibt unterschiedliche Abstufungen

201
00:23:21,210 --> 00:23:24,746
wie den „absoluten“ Intensivierungsbereich, in den „absolut“, „gänzlich“, „grundlegend“, „gründlich“,

202
00:23:24,746 --> 00:23:29,426
„im geringsten“, „komplett“, „längst“, „rein“ usw. reinfallen, den „extrem hohen“ Intensivierungsbereich:

203
00:23:29,426 --> 00:23:34,820
„höchst“, „äußerst“, „zutiefst“, „aufs äußerste“, „aufs höchste“, „aufs Tiefste“, „höchstlichst“, usw.

204
00:23:34,820 --> 00:23:40,200
und den hohen Intensivierungsbereich mit „sehr“, „stark“, „gewaltig“, „besonders“, „so“, „arg“, „übertrieben“ usw.

205
00:23:40,200 --> 00:23:45,966
Wenn wir die Distribution dieser Gradpartikel in Korpora messen, dann könnten wir sagen:

206
00:23:45,966 --> 00:23:55,534
vielleicht sind die Indikator für emotionale Involviertheit. Und die Neigung zu Verschwörungstheorien

207
00:23:55,534 --> 00:24:01,259
das ist natürlich besonders schwierig zu operationalisieren, da haben wir einfach

208
00:24:01,259 --> 00:24:09,674
eine Liste von Wörtern genommen, die darauf verweisen, dass vielleicht etwas nicht so ist, wie es sein könnte

209
00:24:09,674 --> 00:24:12,917
wenn man Wörter hat wie „angeblich“, „vermeintlich“, „scheinbar“, „behaupten“, „heucheln“,

210
00:24:12,917 --> 00:24:16,174
„verheimlichen“, „verschweigen“, „fingieren“, „vorgaukeln“, „entlarven“, usw

211
00:24:16,174 --> 00:24:20,633
das sind natürlich Wörter, die zumindest das Potential haben, darauf zu verweisen,

212
00:24:20,633 --> 00:24:25,134
dass die Welt nicht so ist, wie sie uns verkauft wird oder dargestellt wird.

213
00:24:25,134 --> 00:24:36,690
Und das findet man natürlich eher bei Personen, die Verschwörungstheorien anhängen

214
00:24:36,690 --> 00:24:44,573
Wenn man jetzt den Radikalitätsindex berechnet – das hier sind normalisierte Werte – dann kann man sehen *Gelächter*

215
00:24:44,573 --> 00:24:56,470
dass Fefe, knapp gefolgt von donalphonso und mit kleinem Abstand das salafistische Forum *lautes Gelächter*

216
00:24:56,470 --> 00:25:07,850
und weiterem Abstand kreuz.net hier aufschlagen. Fefe hat nirgendwo die erste Position, muss man dazu sagen

217
00:25:07,850 --> 00:25:11,707
also auch bei den Verschwörungen nicht, da schlägt kreuz.net Fefe noch um Längen

218
00:25:11,707 --> 00:25:15,440
– interessanterweise übrigens, wie ich fand –

219
00:25:15,440 --> 00:25:22,493
und donalphonso ist also tatsächlich ein großer Skandalisierer und Intensivierer, kann man feststellen

220
00:25:22,493 --> 00:25:27,796
wenn man sich noch einmal das Ranking anschaut, dann sieht das so aus … Fefe, donalphonso, salafistische …

221
00:25:27,796 --> 00:25:40,998
Also ob wir operative Maßnahmen einleiten überlasse ich euch. Ich würde sagen, wir behalten die im Auge.

222
00:25:40,998 --> 00:25:52,517
Das waren jetzt ein paar Techniken, die ich euch darstellen wollte, die wenig zu tun haben mit dem „Keywordbullshitter“

223
00:25:52,517 --> 00:26:01,989
den wir gesehen haben. Denn diese Keywords selbst spielen eine sehr geringe Rolle bei den Analysen, besonders wie zuletzt gesehen

224
00:26:01,989 --> 00:26:11,273
Ich denke die Linguistik und die NSA-Linguisten sind sicherlich sehr viel weiter um e-Mails zu filtern

225
00:26:11,273 --> 00:26:21,400
Ich denke, wenn man sich den Rechenschaftsbericht der G10-Kommission anschaut, die die deutschen Geheimdienste überwachen

226
00:26:21,400 --> 00:26:27,573
die hatten ja zunächst so dargestellt es wurden so wahnsinnig viele e-Mails gescreent, aber das meiste davon war Spam

227
00:26:27,573 --> 00:26:32,485
und wenn man sich den neueren Bericht anschaut, dann steht da, wir haben die Spamerkennung verbessert

228
00:26:32,485 --> 00:26:38,518
und es wurden deswegen sehr viel weniger e-Mails. Aber es ist auch die Rede von mehreren Ebenen des Screenings

229
00:26:38,518 --> 00:26:45,317
und es werden erst zu einem sehr späten Zeitpunkt e-Mails tatsächlich in die Hand genommen und qualitativ ausgewertet

230
00:26:45,317 --> 00:26:56,133
und ich denke, dass vielleicht der allererste Zugriff über ein Keyword erfolgt, das auch sehr allgemein gehalten sein kann

231
00:26:56,133 --> 00:27:03,137
dass die weiteren Ebenen dann natürlich viel feinere Analysen beinhalten, die eben Kollokation, semantische Taxonomien

232
00:27:03,137 --> 00:27:10,845
oder Topic-Modelling, über das ich heute leider nicht sprechen kann, benutzen

233
00:27:10,845 --> 00:27:18,446
Ja, ich bin noch nicht fertig. Vielleicht kennen einige von euch den Film „Alphaville“?

234
00:27:18,446 --> 00:27:27,560
Alphaville ist ein Film von Jean-Luc Godard, in dem es darum geht dass Lemmy Caution, ein Spion,

235
00:27:27,560 --> 00:27:38,750
in die Stadt Alphaville kommt, die von einem allmächtigen, diktatorischen, totalitären Computer beherrscht wird: Alpha 60

236
00:27:38,750 --> 00:27:46,866
und ein Teil seiner Aufgabe ist es, diesen Computer auzuschalten und den Erzeuger von Braun zu finden.

237
00:27:46,866 --> 00:27:53,873
Er spricht dann mit einem der Programmierer dieses Computers, einem Assistenten von von Braun

238
00:27:53,873 --> 00:28:03,690
und der Assistent fragt ihn: „Sind Sie auch ein Spion?“ – Ich kann den Screenshot wegen Urheberrecht leider nur so zeigen

239
00:28:03,690 --> 00:28:09,213
Darauf sagt Lemmy Caution: „Nein, das wissen Sie genau, ich bin nämlich ein freier Mann!“

240
00:28:09,213 --> 00:28:13,733
Daraufhin sagt der Assistent: „Ihre Antwort ist bedeutungslos. Wir wissen nichts.

241
00:28:13,733 --> 00:28:18,598
Wir registrieren, berechnen und ziehen unsere Schlussfolgerungen.“

242
00:28:18,598 --> 00:28:27,733
Und dieser Satz erfasst eigentlich das Problem, das wir mit den Diensten haben, relativ gut.

243
00:28:27,733 --> 00:28:36,624
Denn die Dienste unterwerfen unsere Lebensäußerungen einer Logik, die zunächst nicht unsere Logik ist

244
00:28:36,624 --> 00:28:45,592
sie werten sie nach bestimmten Mustern aus: „Wir registrieren, berechnen…“, sie ziehen Schlussfolgerungen daraus

245
00:28:45,592 --> 00:28:51,454
aber sie müssen sich dafür nicht rechtfertigen. Sie müssen ihre Methoden nicht offenlegen

246
00:28:51,454 --> 00:28:55,792
und ihre Logik nicht zur Diskussion stellen. Und genau das ist das Problem.

247
00:28:55,792 --> 00:29:05,153
Das ist aber ein Kennzeichen für alle totalitären Systeme, dass sie ihre Logik nicht rechtfertigen müssen.

248
00:29:05,153 --> 00:29:09,349
Wir wissen überhaupt nicht, was überhaupt verdächtig sein könnte

249
00:29:09,349 --> 00:29:16,909
und der Grund dafür ist, dass diese Dienste eben im Geheimen operieren können

250
00:29:16,909 --> 00:29:21,312
und unsere Aufgabe sollte es sein, diese Methoden öffentlich zu machen, diese Methoden zu diskutieren

251
00:29:21,312 --> 00:29:26,947
zu beweisen, dass diese Methoden fehlerhaft sind und unglaublich viele „false positives“ produzieren

252
00:29:26,947 --> 00:29:32,635
und dass wir es deswegen lieber lassen sollten und wir vielleicht ein paar Scheiben ins Glashaus werfen

253
00:29:32,635 --> 00:29:34,620
Vielen Dank

254
00:29:34,620 --> 00:29:54,923
*Applaus*

255
00:29:54,923 --> 00:29:58,339
Engel: Ja vielen Dank, Josh, für diesen richtig coolen Talk. Was auch cool ist:

256
00:29:58,339 --> 00:30:01,819
Was auch total cool ist, wir haben noch richtig viel Zeit für Fragen und Antworten

257
00:30:01,819 --> 00:30:06,659
Wir haben vier Saalmikrofone hier, wir haben zwei auf jeder Seite

258
00:30:06,659 --> 00:30:14,667
für Leute, denen es schwerer fällt, zum Saalmikro zu kommen, habe ich auch das tragbare Handmikro

259
00:30:14,667 --> 00:30:22,888
und wir können noch gucken, ob es Fragen aus dem Internet gibt und die dann den Signal Angle stellen

260
00:30:22,888 --> 00:30:26,549
seid nicht so schüchtern, wir haben noch eine halbe Stunde, das war ja wohl ein guter Input

261
00:30:26,549 --> 00:30:29,314
wenn ihr also eine Frage habt, dann bewegt euch dahin.

262
00:30:29,314 --> 00:30:36,758
Ja vielleicht fangt ihr an, euch zu den Mikrofonen zu bewegen, geht das auch für euch beide?

263
00:30:36,758 --> 00:30:40,438
Dann komm ich gleich zu dir, dann die erste Frage

264
00:30:40,438 --> 00:30:48,294
Frage: Wie ist denn das mit diesen Kollokationen und Kultureller Kontext? Also es könnte sein, dass wir jetzt bspw.

265
00:30:48,294 --> 00:30:58,710
da wollte jetzt ein Osama ein Konto eröffnen und das wurde ihm verweigert, weil er Osama heißt

266
00:30:58,710 --> 00:31:09,787
dass wir dann diese Kollokation quasi feststellen, aber dass der Name Osama ein recht geläufiger im arabischen Kontext ist

267
00:31:09,787 --> 00:31:17,774
wie wird damit umgegangen, dass das etwas ganz normales dort ist, für uns aber sofort verdächtig erscheint?

268
00:31:17,774 --> 00:31:24,813
Antwort: Vielen Dank, ich weiß nicht auf welcher Ebene ich die Frage beantworten soll.

269
00:31:24,813 --> 00:31:30,572
Aus linguistischer Perspektive kann man damit, glaube ich, recht gut umgehen, indem man weiteren Kontext dazu nimmt

270
00:31:30,572 --> 00:31:35,859
und relativ schnell disambiguieren könnte, dass es sich eben nicht um Osama bin Laden handelt,

271
00:31:35,859 --> 00:31:40,854
zumal der ja auch schon tot ist
*Gelächter*

272
00:31:40,854 --> 00:31:50,749
aus Sicht eines Analytikers, der vielleicht gar nicht versteht, was unter der Haube eines solchen Toolkits läuft, ist es erstmal egal

273
00:31:50,749 --> 00:31:58,705
denn er folgt seiner Logik, er hat seine Mission und wie gesagt, die Menge an false positives ist riesig

274
00:31:58,705 --> 00:32:14,270
das wird eben damit gerechtfertig, dass das, was auf dem Spiel steht, so unglaublich monströs ist, wenn es denn fiele, dass das jedes Mittel rechtfertigt

275
00:32:14,270 --> 00:32:19,117
E: Okay danke, dann haben wir noch eine Frage von dir und dann du als nächstes, bitteschön

276
00:32:19,117 --> 00:32:25,693
F: ja, mich würde interessieren, ob du dir mal die Mühe gemacht hast, mit diesen Methoden

277
00:32:25,693 --> 00:32:28,410
auch mal sowas wie die Pressemitteilungen des Innenministeriums zu analysieren

278
00:32:28,410 --> 00:32:33,699
weil da ist doch bestimmt auch eine Menge Schwarzmalerei und emotionaler Sprachgebrauch zu finden

279
00:32:33,699 --> 00:32:36,129
A: Sehr interessant, das ist eine gute Frage. Habe ich nicht gemacht

280
00:32:36,129 --> 00:32:41,820
Was ich gemacht habe, war bei Politikerinnen und Politikern, also Angela Merkel, usw.

281
00:32:41,820 --> 00:32:46,595
das trieft aber natürlich von positiven Darstellungen der Wirklichkeit

282
00:32:46,595 --> 00:32:50,251
weil als Regierungschefin ist man natürlich bemüht, die Wirklichkeit so zu konstruieren,

283
00:32:50,251 --> 00:33:01,200
dass sie in einem möglichst positiven Licht erscheint und es wäre sicherlich interessant das genauer anzuschauen

284
00:33:01,200 --> 00:33:03,122
E: Die nächste Frage von dir bitteschön

285
00:33:03,122 --> 00:33:10,843
F: Wäre es eigentlich möglich, so Konnotationsspam zu erzeugen

286
00:33:10,843 --> 00:33:14,986
in einem etwas komplexeren Zusammenhang mit ein paar Bots?

287
00:33:14,986 --> 00:33:25,309
A: Naja, hier kommt eine kluge Frage. Wenn wir jetzt schon wissen, dass Keyword-Bullshitting zu grob ist

288
00:33:25,309 --> 00:33:30,330
ob wir dann nicht klugerweisen unser Wissen nutzen können, um Texte automatisiert zu erstellen,

289
00:33:30,330 --> 00:33:38,478
die bestimmte Kollokationsprofile abbilden, bspw. Das können wir alles machen.

290
00:33:38,478 --> 00:33:45,715
Aber ich möchte noch einmal drauf hinweisen, was mir wirklich ganz zentral ist

291
00:33:45,715 --> 00:33:52,403
es hat, glaube ich, keinen Sinn, sich zu verstellen, sich zu verbergen in diesem Kontext

292
00:33:52,403 --> 00:33:57,138
was sich ändern muss, ist diese Logik, in der dieses Spiel gespielt wird

293
00:33:57,138 --> 00:34:04,820
Denn für jede Methode gibt es eine Gegenmethode. Das ist ein Wettrüsten, das in diesem Fall sehr wenig Sinn macht

294
00:34:04,820 --> 00:34:09,819
Natürlich ist Verschlüsselung und alles sehr sinnvoll, aber gegen Dinge, die geäußert werden

295
00:34:09,819 --> 00:34:17,187
und wir wollen uns eben auch öffentlich äußern, da sind wir gegen Ausspähung nicht gefeit.

296
00:34:17,187 --> 00:34:23,954
und ich bin der Meinung, dass wir uns durch diese Dinge nicht einschränken lassen sollten

297
00:34:23,954 --> 00:34:29,851
sondern dass wir uns eher darum bemühen sollten, die Logik der Dienste zu hinterfragen,

298
00:34:29,851 --> 00:34:35,723
sie aus dem Geheimen herauszuziehen und das zu diskutieren, was da passiert, das ist das Entscheidende

299
00:34:35,723 --> 00:34:42,514
E: Okay, die nächste Frage
*Applaus*

300
00:34:42,514 --> 00:34:46,427
die nächste Frage ist von mspro und danach hätten wir noch Fragen aus dem Internet

301
00:34:46,427 --> 00:34:51,432
F: Hallo, ich hätt da noch ne Frage zu deiner Anspielung am Anfang mit „Überwachen und Strafen“

302
00:34:51,432 --> 00:34:55,593
und deinem Schlussstatement. Das passt nicht so richtig zusammen. Du hast gesagt:

303
00:34:55,593 --> 00:35:04,240
sowohl im Glashaus, als auch beim Panoptikum geht es darum, dass ich weiß, dass der Überwacher da ist

304
00:35:04,240 --> 00:35:09,400
und weiß, nach welchen Kriterien er mich beurteilt, damit ich eine disziplinarische Wirkung habe

305
00:35:09,400 --> 00:35:15,456
jetzt sagst du aber, dass ja genau diese Opakheit der Geheimdienste nach ihren Verdachtskriterien das Problem ist

306
00:35:15,456 --> 00:35:22,575
das widerspricht sich total. Wenn ich nicht weiß, wonach ich als verdächtig betrachtet werde,

307
00:35:22,575 --> 00:35:27,550
diszipliniert mich das ja gar nicht. Irgendwie passt das nicht zusammen

308
00:35:27,550 --> 00:35:31,222
A: Danke für die Möglichkeit, das noch ein bisschen zu präzisieren. Ich denke,

309
00:35:31,222 --> 00:35:37,480
wir haben natürlich eine Ahnung. Das ist ja das Schlimme, wir haben nicht *mehr* als eine Ahnung davon,

310
00:35:37,480 --> 00:35:42,448
was denn als vermeintlich gefährlich betrachtet wird. Und genau das ist das Problem

311
00:35:42,448 --> 00:35:49,976
also das Nicht-Wissen darum ist vielleicht noch die totalere Methode uns zu überwachen,

312
00:35:49,976 --> 00:35:54,360
denn, ich möchte ein Beispiel geben: ich habe kürzlich ein Buch gelesen über ein maoistisches Gefängnis

313
00:35:54,360 --> 00:36:02,547
und da ist es so, die Verhöre finden so statt, dass der Verhörende ein Buch hat.

314
00:36:02,547 --> 00:36:10,284
und er sitzt dem Delinquenten gegenüber und sagt: „In diesem Buch steht alles, was du falsch gemacht hast,

315
00:36:10,284 --> 00:36:17,336
alle deine Sünden stehen hier geschrieben. Du musst nur gestehen.“ Aber er darf nie in das Buch schauen

316
00:36:17,336 --> 00:36:21,867
und er zermartert sich sein Gehirn unglaublich, weil er nicht weiß, was in diesem Buch steht

317
00:36:21,867 --> 00:36:25,960
und er überlegt sich, „was kann ich noch alles gestehen, damit ich dieses Buch abarbeiten kann?“

318
00:36:25,960 --> 00:36:32,712
und ich glaube gerade die Unwissenheit darüber ist die viel raffiniertere, perfidere Methode der Kontrolle

319
00:36:32,712 --> 00:36:37,696
und insofern schließt sich das nicht gegenseitig aus, weil unser Kopfkino,

320
00:36:37,696 --> 00:36:41,811
was alles gefährlich sein könnte, ist mächtig genug.

321
00:36:41,811 --> 00:36:47,320
E: Alles klar, danke. Dann haben wir jetzt Fragen aus dem Internet. Magst du die kurz stellen?

322
00:36:47,320 --> 00:36:55,842
F: Gibt es eine Instanz, die die Keyword-Listen überprüft, und wenn ja, welche ist das?

323
00:36:55,842 --> 00:37:02,968
A: Ja, sehr gute Frage! Keine Ahnung, weil wir wissen es nicht. Die leaken ab und zu

324
00:37:02,968 --> 00:37:06,560
– und ich habe mir überlegt, mal eine Zusammenstellung zu machen:

325
00:37:06,560 --> 00:37:10,272
es gibt die Echelon-Liste und es gibt ganz verschiedene Listen – also nein.

326
00:37:10,272 --> 00:37:16,408
die sind nicht validiert, aber man kann davon ausgehen, dass die schon irgendwie an Fallbeispielen überprüft sind

327
00:37:16,408 --> 00:37:20,239
denn sonst würde man sich ja unglaublich viel Arbeit machen. Aber wie und wo

328
00:37:20,239 --> 00:37:30,740
und wie man das wissenschaftlich nachvollziehen kann, das ist leider nicht beschrieben und nachlesbar.

329
00:37:30,740 --> 00:37:32,285
E: Da gibts wohl noch mehr Fragen aus dem Internet?

330
00:37:32,285 --> 00:37:38,432
F: Noch eine zweite: Brächte es was, wenn wir jetzt alle schön in unserem Dialekt schreiben,

331
00:37:38,432 --> 00:37:43,968
weil dann werden die Keywörter eventuell nicht erkannt, oder ist das sinnfrei?

332
00:37:43,968 --> 00:37:54,552
*Gelächter und Applaus*

333
00:37:54,552 --> 00:38:02,728
A: Also als Hess kann ich dir da sache, das det schon was bringe wärdd *Gelächter*

334
00:38:02,728 --> 00:38:10,336
also in der Tat, das hätte tatsächlich Chancen, es den Diensten schwerer zu machen, absolut

335
00:38:10,336 --> 00:38:16,993
es gibt natürlich Verfahren, mit denen man Ähnlichkeiten zwischen Wörtern messen kann, usw.

336
00:38:16,993 --> 00:38:21,845
das ist durchaus möglich. Aber es würde es schwerer machen.

337
00:38:21,845 --> 00:38:27,256
Es würde ja auch die Kommunikation erheblich schwerer machen, wenn wir alle im Dialekt schreiben

338
00:38:27,256 --> 00:38:31,709
es gibt dann keine Standardorthografie, aber es funktioniert natürlich auch. Wie in der Schweiz

339
00:38:31,709 --> 00:38:38,819
*Gelächter*

340
00:38:38,819 --> 00:38:42,568
E: okay, die nächsten beiden Fragen sind von euch und dann seid ihr beide da drüben dran

341
00:38:42,568 --> 00:38:47,128
F: Ja, mich würde interessieren, wie man mit der Schwierigkeit von Fremdsprachen umgeht

342
00:38:47,128 --> 00:38:53,894
oder allgemein der Vielfalt an Sprachen. Wie kann man ggf. einen Bezug herstellen,

343
00:38:53,894 --> 00:38:58,187
wenn der eine in Deutsch, der eine in Englisch schreibt. Oder wie analysiert man die Salafisten,

344
00:38:58,187 --> 00:39:01,528
wenn sie in ihrer Muttersprache sprechen.

345
00:39:01,528 --> 00:39:08,936
A: Ja, also grundsätzlich gibt es Software, die designt ist das sie sprachunabhängig funktioniert

346
00:39:08,936 --> 00:39:15,993
Zumindest wenn die Sprache sich klar in Wörter abgrenzen lässt, usw.

347
00:39:15,993 --> 00:39:23,392
Ich glaube, diese Software ist nicht so gut wie Tools, die sprachliches Wissen einbringen,

348
00:39:23,392 --> 00:39:30,516
aber nichtsdestotrotz wird sie eingesetzt. Siemens macht sowas, bspw. zur Autorenerkennung

349
00:39:30,516 --> 00:39:40,312
das wird eingesetzt und funktioniert eben auch tatsächlich sprachabstrakt.

350
00:39:40,312 --> 00:39:44,480
Man lernt Feature und es ist egal, in welcher Sprache man die lernt.

351
00:39:44,480 --> 00:39:48,218
es wird halt reicher und besser, wenn man sprachliches Wissen einbringt

352
00:39:48,218 --> 00:39:57,225
F: Ich hab eine Frage, die ein bisschen schwarz-weiß ist. Wenn man sagt, wir reden über diese Listen

353
00:39:57,225 --> 00:40:05,113
und die Worte, die darin stehen, dann ist doch das Problem, dass sie nicht mehr wertvoll sind, sobald sie bekannt sind

354
00:40:05,113 --> 00:40:11,300
d.h. man hat nur die binäre Option, solche Techniken nicht anzuwenden, oder die Listen nicht zu veröffentlichen

355
00:40:11,300 --> 00:40:14,288
oder kommt man irgendwie darum herum

356
00:40:14,288 --> 00:40:23,531
A: eine gute Frage. Ich glaube eben, es gibt überhaupt kein Entkommen.

357
00:40:23,531 --> 00:40:30,210
Klar, wenn die Listen bekannt sind, dann funktioniert es nicht mehr, wir können die wegschmeißen

358
00:40:30,210 --> 00:40:33,829
wir arbeiten ja schon nicht mehr mit Listen. Aber auch die anderen Verfahren.

359
00:40:33,829 --> 00:40:40,371
Wenn wir die kennen, können wir sie wegschmeißen. Ich glaube, dass dann die nächsten Verfahren kommen

360
00:40:40,371 --> 00:40:45,531
Verfahren, die klandestine Kommunikation erkennbar machen, die maximale Abweichung

361
00:40:45,531 --> 00:40:51,335
von normaler Kommunikation sichtbar machen und damit ist man wieder gefangen.

362
00:40:51,335 --> 00:40:57,339
Ich glaube, dieses Katz-und-Maus-Spiel existiert, aber ich glaube, wir müssen da raus,

363
00:40:57,339 --> 00:41:05,731
weil ich glaube, dass es das nicht bringt. Ich glaube, man soll es einfach lassen.

364
00:41:05,731 --> 00:41:11,715
*Applaus*
E: Okay, du bist als nächster dran

365
00:41:11,715 --> 00:41:18,376
F: Ich fühlte mich durch den Vortrag an den Fall des Staatssoziologen Andrej Holm erinnert,

366
00:41:18,376 --> 00:41:25,683
der als angebliches Mitglied der militanten Gruppe im Gefängnis gelandet ist und zwar deswegen,

367
00:41:25,683 --> 00:41:30,707
weil die Bekennerschreiben der militanten Gruppe angebliche Parallelen

368
00:41:30,707 --> 00:41:38,298
zu seiner wissentlichen Veröffentlichungen aufwiesen, was damals soweit in die Öffentlichkeit

369
00:41:38,298 --> 00:41:43,146
kolportiert wurde, dass es hieß, in beiden käme das Wort „Gentrifizierung“ vor,

370
00:41:43,146 --> 00:41:46,246
das damals noch ein bisschen seltener war als im Nachgang.

371
00:41:46,246 --> 00:41:52,110
Hast du dich mit dem Fall mal näher beschäftigt, wie die Behörden da scheinbar vorgegangen sind?

372
00:41:52,110 --> 00:41:58,787
A: Ja, ich hab auf den Datenspuren letztes Jahr einen Vortrag gehalten zu Autorenidentifizierung,

373
00:41:58,787 --> 00:42:06,250
gerade auch mit Aufhänger Andrej Holm. Ich denke, dass da ganz unterschiedliche Dinge passiert sind

374
00:42:06,250 --> 00:42:12,810
bspw. hat das BKA ein Gutachten gemacht und gesagt, dass Andrej Holm *nicht* der Autor ist

375
00:42:12,810 --> 00:42:25,523
der Tipp kam offenbar woanders her, von irgendwelchen Diensten, die wohl auf maschinelle Verfahren zurückgegriffen haben

376
00:42:25,523 --> 00:42:30,196
um da Ähnlichkeiten festzustellen. Wäre jetzt mein Tipp, aber das wissen wir natürlich auch nicht.

377
00:42:30,196 --> 00:42:37,663
Aber irgendwoher muss das ja gekommen sein. Wenn das BKA sagt, er wars wohl nicht, aufgrund der Sprachanalyse, ist schon interessant.

378
00:42:37,663 --> 00:42:44,915
Die Sprachdaten haben letztlich für den Fall keine große Rolle gespielt. Es wurde zwar kolpotiert in den Medien,

379
00:42:44,915 --> 00:42:50,300
aber für den Haftbefehl und weiteres waren andere Aspekte ausschlaggebender.

380
00:42:50,300 --> 00:42:52,341
E: Vielen Dank, du da hinten am Mikro bist als nächstes dran

381
00:42:52,341 --> 00:42:56,496
F: Ja, ich wollte sagen, dass es mich gefreut hat, dass du den Link zu Foucault gemacht hast,

382
00:42:56,496 --> 00:43:00,996
weil es ja bei „Überwachen & Strafen“ genau darum geht, dass wir dazu erzogen werden,

383
00:43:00,996 --> 00:43:10,236
uns selbst zu überwachen, was letztlich diese Schere im Kopf ist. Ich finde das ein sehr schönes Bild, dass du da diese Parallele gezogen hast.

384
00:43:10,236 --> 00:43:15,906
Meine Frage wollte ich eigentlich auch nach einem Beispiel für so ein False positive stellen,

385
00:43:15,906 --> 00:43:19,133
das wurde ja gerade mit diesem Fall beantwortet.

386
00:43:19,133 --> 00:43:27,645
A: Die spülen mal immer wieder in die Medien rein. Jemand hat in der Schweiz T-Shirts drucken lassen,

387
00:43:27,645 --> 00:43:32,993
– die haben da Schwierigkeiten mit dem Flughafen – „Südanflug“. Und hat die T-Shirts auch bezahlt

388
00:43:32,993 --> 00:43:40,748
und dann wurden die Tremata über den Umlauten weggemacht. Und dann stand da „Sudanflug“,

389
00:43:40,748 --> 00:43:48,988
was dann aber gleich „Sudan-Flug“ gelesen wurde. Und dann hat die Bank gleich den Staatsschutz informiert.

390
00:43:48,988 --> 00:43:57,906
Also so kuriose Fälle tauchen natürlich auf, wir haben auch von der Frau mit Schnellkochtopf gehört

391
00:43:57,906 --> 00:44:07,692
das sind Dinge, die tauchen tatsächlich immer wieder auf. Wir kriegen es in vielen Fällen auch gar nicht mit, was passiert.

392
00:44:07,692 --> 00:44:13,829
Man muss ja auch nicht informiert werden, wenn man Gegenstand von Überwachung ist. Ist ja auch so.

393
00:44:13,829 --> 00:44:18,206
Wenn es im Interesse der Bundesrepublik ist, muss man nicht informiert werden

394
00:44:18,206 --> 00:44:23,986
E: Ich hätte gerne Kooperation von Leuten der ersten Reihe, könnt ihr eure Sachen wegnehmen? Vielen Dank.

395
00:44:23,986 --> 00:44:26,917
Wir haben noch eine Frage aus dem Internet, wenn ich das richtig sehe, bitteschön

396
00:44:26,917 --> 00:44:34,364
F: Nicht aus dem Internet. Linguistik ist ja eine Geisteswissenschaft

397
00:44:34,364 --> 00:44:42,108
und die sind ja bekanntlich an den Unis *nicht* so gut finanziert. Ist es bekannt, oder hast du eine Idee davon,

398
00:44:42,108 --> 00:44:47,648
wie groß die Differenz zwischen der öffentlichen Forschung und der der Geheimdienste in der Linguistik

399
00:44:47,648 --> 00:44:53,112
oder gerade im Bezug darauf ist. Wenn man sich die Budgets so anguckt, könnte da ja eine echte Differenz sein.

400
00:44:53,112 --> 00:44:58,490
A: das ist eine interessante Frage. Richtig, Geistes- oder Kulturwissenschaften sind nicht so toll finanziert

401
00:44:58,490 --> 00:45:06,825
aber die Forschung findet zum Teil auch in der Informatik statt. Die Verfahren, die ich vorgestellt habe,

402
00:45:06,825 --> 00:45:12,816
haben zunächst mal nichts mit Überwachung zu tun. Ohne die Verfahren wäre Google keine so tolle Suchmaschine

403
00:45:12,816 --> 00:45:18,655
d.h. die Verfahren sind im Grunde erstmal abstrakt von ihrer Verwendung.

404
00:45:18,655 --> 00:45:27,810
Viel Forschung findet dann tatsächlich in Privatunternehmen statt, wobei die Unis glaube ich noch mithalten können,

405
00:45:27,810 --> 00:45:41,837
aber ich würde meinen, die NSA finanziert ja auch Forschung an Unis, auch in Deutschland, und es geht gut voran in dem Bereich

406
00:45:41,837 --> 00:45:50,810
Um das mal zu sagen: das ist zentrale Technologie, die brauchen wir. Wir erschließen uns Wissen, über Sprache

407
00:45:50,810 --> 00:46:00,810
Unsere Anfragen an die Welt funktionieren mit dem Medium Sprache. Wir suchen Informationen mit komplexen Anfragen,

408
00:46:00,810 --> 00:46:12,458
die alle erstmal sprachlicher Natur sind. Auch bei einer Google Bildersuche. Wir ordnen uns die Welt durch das Medium Sprache

409
00:46:12,458 --> 00:46:18,521
und das ist eine zentrale Technologie, in die auch in Zukunft sehr viel Geld fließen wird.

410
00:46:18,521 --> 00:46:21,929
E: Gut, ich habe noch mindestens drei Fragen gesehen, aber wir haben ja auch noch eine viertel Stunde Zeit

411
00:46:21,929 --> 00:46:24,570
du bist als nächstes dran.

412
00:46:24,570 --> 00:46:28,617
F: Ich würde mal gerne die Aktualität deiner vorgestellten Informationen hier überprüfen

413
00:46:28,617 --> 00:46:34,744
Erstmal würde ich gerne wissen, woher du die Information hast, dass solche Sachen benutzt werden, kommt das aus den Snowden-Files?

414
00:46:34,744 --> 00:46:42,512
Und: wie alt ist das ganze Zeug. Dieses Toolkit, kann ja auch sein, dass das schon fünf Jahre alt ist

415
00:46:42,512 --> 00:46:48,368
und das mittlerweile flächendeckende Liveüberwachung jeglicher Sprache stattfindet und alles viel intelligenter ist.

416
00:46:48,368 --> 00:46:56,586
A: Wichtige Frage natürlich, aber auch ganz wichtig: Das Toolkit war natürlich frei erfunden.

417
00:46:56,586 --> 00:47:00,632
Keine Ahnung, wie das aussieht, werden wir auch nicht zu Gesicht bekommen. Ist schon klar.

418
00:47:00,632 --> 00:47:04,685
– F: Das hab ich schon verstanden – A: Gut, klang jetzt eben so, tschuldigung.

419
00:47:04,685 --> 00:47:09,320
Also, wie alt sind die Verfahren: die Entwicklung geht weiter, es geht vor allem um Verfeinerungen

420
00:47:09,320 --> 00:47:15,979
in bestimmten Bereichen. Wie gesagt, Topic-Modelling hyped im Moment sehr, ist aber nicht grundlegend verschieden

421
00:47:15,979 --> 00:47:25,320
von Kollokationsanalysen. Es ist ein ähnliches Verfahren. Die Algorithmen für maschinelles Lernen werden besser.

422
00:47:25,320 --> 00:47:30,920
Die Rechenleistung wird besser. Wir können größere Daten anschauen, um von ihnen zu lernen, da tut sich eine Menge.

423
00:47:30,920 --> 00:47:41,311
Aber grundsätzlich würde ich sagen, viel Neues gibt es nicht. Wir hätten uns das Identifizieren von Frames angucken können

424
00:47:41,311 --> 00:47:50,191
aber ich würde meinen, es sind schon Technologien, die zum Einsatz kommen könnten und ausgereift genug sind,

425
00:47:50,191 --> 00:47:55,967
dass sie zum Einsatz kommen aber darüber, ob sie tatsächlich zum Einsatz kommen, weiß ich nichts.

426
00:47:55,967 --> 00:47:58,895
E: Alles klar, die nächste Frage ist von dir da hinten

427
00:47:58,895 --> 00:48:02,919
F: Vielen Dank erstmal, für den spannenden Vortrag,

428
00:48:02,919 --> 00:48:07,871
es war ein Ausflug in die Linguistik, den sogar ich als Ingenieur verstanden habe

429
00:48:07,871 --> 00:48:15,976
du hast vorhin zurecht gesagt, dass man vermutlich anstatt mit Bullshitting von Keywords

430
00:48:15,976 --> 00:48:24,559
es sichtbar machen sollte, was da passiert. Den Ansatz fand ich richtig.

431
00:48:24,559 --> 00:48:28,111
Im zweiten Satz fragte ich mich: was wären denn dann die Möglichkeiten

432
00:48:28,111 --> 00:48:33,671
wir haben ein paar absurde Beispiele gesehen, wie das mal in der Presse herauskommt

433
00:48:33,671 --> 00:48:37,466
du als jemand, der sich damit viel beschäftigt hat, was würdest du sagen,

434
00:48:37,466 --> 00:48:43,270
was sind so die Dinge, mit denen man sich, mit denen sich die Szene beschäftigen sollte?

435
00:48:43,270 --> 00:48:50,385
A: Ganz schwierig, ja. Ich glaube, es geht nur der Weg über die Politik.

436
00:48:50,385 --> 00:48:57,439
Es ist ein politisches Anliegen zu sagen, dass die Methoden öffentlich gemacht werden müssen

437
00:48:57,439 --> 00:49:04,764
dass sie gerechtfertigt werden müssen in Hinblick auf Vadilität, u.ä. Aber das ist ein politischer Weg.

438
00:49:04,764 --> 00:49:12,156
Das heißt Lobbying da, wo es wehtut. Man muss zu den Parteien gehen, die die Macht haben

439
00:49:12,156 --> 00:49:18,745
und man muss auch mit denen reden und die überzeugen. Es ist ein hartes Brot, aber wichtig.

440
00:49:18,745 --> 00:49:25,397
Man kann das nicht mit technischen Mitteln lösen. Ich weiß, das ist eigentlich unser Ansatz, aber das reicht nicht.

441
00:49:25,397 --> 00:49:27,186
E: OK, du hast die nächste Frage

442
00:49:27,186 --> 00:49:31,630
F: Wir haben uns jetzt hier kollokationsbasierte Sachen angeschaut.

443
00:49:31,630 --> 00:49:37,707
In wie weit kommen denn formale Grammatiken zum Einsatz, die auch die Satzsyntax berücksichtigen?

444
00:49:37,707 --> 00:49:44,804
Schauen wir uns den Satz an „auf keinen Fall sind unsere Politiker als Verbrecher und Dilettanten zu sehen“

445
00:49:44,804 --> 00:49:50,470
da wird man mit der Kollokationsanalyse schnell einen False positive haben, oder?

446
00:49:50,470 --> 00:50:02,597
A: Der Trend geht eindeutig weg von formalen Grammatiken, hin zu großen Datenmengen.

447
00:50:02,597 --> 00:50:07,677
Zu eher mehr Kontext angucken, stärkeres maschinelles Lernen auf größeren Corpora

448
00:50:07,677 --> 00:50:13,760
und eher der Google-Ansatz … F: wie Google Translate, so ähnlich A: … genau

449
00:50:13,760 --> 00:50:19,991
mit vielen Daten die Sache lösen. Und das ist für uns Linguisten natürlich total frustrierend.

450
00:50:19,991 --> 00:50:25,539
F: ja, ich komme selbst aus der Computerlinguistik, deshalb frage ich A: ja, das dachte ich mir schon.

451
00:50:25,539 --> 00:50:33,197
Aber ja, es ist so. Aber wir sind uns, denke ich einig, mit linguistischem Wissen kann man vieles besser machen.

452
00:50:33,197 --> 00:50:36,812
E: mspro, du hattest vorhin signalisiert, als wolltest du noch fragen, hast du es dir anders überlegt?

453
00:50:36,812 --> 00:50:39,367
– hat sich erledigt – alles klar, dann bist du als nächstes dran

454
00:50:39,367 --> 00:50:47,400
F: Was mir noch einfiel: wie würdest du das bewerten,

455
00:50:47,400 --> 00:50:52,125
wenn man eine Überlegung zu einer Theorie sprachlicher Bedeutung da mit hinein bringt?

456
00:50:52,125 --> 00:50:57,453
Was der Staat ja prinzipiell macht ist, er schmeißt sein Gewaltmonopol in unsere Sprache rein

457
00:50:57,453 --> 00:51:03,293
und macht Regelsysteme auf, in denen er nachher die Bedeutung von gewissen Aussagen festlegt

458
00:51:03,293 --> 00:51:10,223
und sagt: das hier ist wahrscheinlich eine kriminelle Äußerung oder die eines Kriminellen

459
00:51:10,223 --> 00:51:15,552
kann man schon beobachten, bzw. ich könnte mir vorstellen aus einer Sprechertheorie,

460
00:51:15,552 --> 00:51:24,324
dass das Verwüstungen in der Sprache anrichtet, dass der Staat Einfluss auf die Bedeutung unseres Sprachgebrauchs nimmt.

461
00:51:24,324 --> 00:51:31,427
A: Das ist eine spannende Hypothese zu sagen, dadurch dass der Staat die Definitionsmacht hier hat zu sagen,

462
00:51:31,427 --> 00:51:38,365
wie eine sprachliche Handlung verstanden werden soll, dass dadurch eine Bedeutungsverschiebung stattfindet,

463
00:51:38,365 --> 00:51:45,565
die ggf. tatsächlich im Sinne eines „Neusprech“ nur noch bestimmte Äußerungen ermöglicht

464
00:51:45,565 --> 00:51:50,164
das wäre eine spannende Hypothese, die mal zu überprüfen wäre

465
00:51:50,164 --> 00:51:56,116
F: ja, also wenn man eine ganz moderne Theorie so „freier Signifikation“ annimmt, dann …

466
00:51:56,116 --> 00:52:02,366
A: … dann haben wir immer noch Macht dann. Immerhin, subversiv können wir sein!

467
00:52:02,366 --> 00:52:11,391
Aber das ist eine interessante Frage. Ich glaube nicht, dass der Einfluss auf den Alltag schon so stark ist,

468
00:52:11,391 --> 00:52:14,727
das glaube ich nicht, aber warten wir es ab.

469
00:52:14,727 --> 00:52:16,817
E: Gut, du hast die nächste Frage

470
00:52:17,309 --> 00:52:20,659
Du sprachst gerade von den großen Datenmengen, die Datenmengen werden immer größer

471
00:52:20,659 --> 00:52:23,894
damit ja auch irgendwie die Erfolgsquote dieser Voraussagen,

472
00:52:23,894 --> 00:52:32,561
typischerweise selbst wenn die Algorithmen nicht besser werden, wenn die Datenmenge größer ist, wird es irgendwie besser

473
00:52:32,561 --> 00:52:40,288
Was wird denn passieren, wenn wir einmal so große Datenmengen haben und die Algorithmen sich dann zusätzlich verbessern,

474
00:52:40,288 --> 00:52:47,910
dass wir fast keine false positives mehr haben. Wir werden das dann nicht mehr mitbekommen

475
00:52:47,910 --> 00:52:51,965
und es werden nur noch die Leute tatsächlich … das Horrorszenario, das ich mir gerade vorstelle,

476
00:52:51,965 --> 00:53:02,142
es werden tatsächlich nur noch die echten Terroristen verhaftet. Und dann? Wie lange dauert es noch, bis es so weit ist?

477
00:53:02,142 --> 00:53:07,290
Ich glaube, wir müssen jetzt handeln, bevor es so weit kommt. Denn sonst wird der Kampf dagegen

478
00:53:07,290 --> 00:53:12,378
und die Rechtfertigung, dagegen Aktionen zu machen, immer schwieriger. Wie ist da deine Einschätzung?

479
00:53:12,378 --> 00:53:14,847
A: Ganz spannender Punkt, hab ich noch nicht darüber nachgedacht.

480
00:53:14,847 --> 00:53:20,981
Als erstes bin ich skeptisch, dass es so gut sein könnte, aber es ist ein spannender Punkt, ja

481
00:53:20,981 --> 00:53:27,160
wenn nur noch die Terroristen verhaftet werden … die echten … dann haben wir ein Problem, ja …

482
00:53:27,160 --> 00:53:35,785
*Gelächter, Applaus*

483
00:53:35,785 --> 00:53:40,760
(Einruf; wird nicht aufgegriffen)
E: Du bist als nächstes dran

484
00:53:40,760 --> 00:53:48,536
F: Wenn du dir mal die Berichte von Jeremy Scahill – das wurde im Tagesspiegel kolpotiert – anguckst,

485
00:53:48,536 --> 00:53:53,894
die werten ja nicht nur die linguistischen Beziehungen aus, sondern tatsächlich auch:

486
00:53:53,894 --> 00:53:59,357
wer hat mit wem telefoniert, wer ist mit wem verwandt und – eine ganz gefährliche Beziehung ist eben:

487
00:53:59,357 --> 00:54:04,776
„Vater ist Islamist”, auch wenn man ihn 16 Jahre nicht gesehen hat – das ist evtl. ziemlich tödlich

488
00:54:04,776 --> 00:54:12,281
und es scheint so zu sein, dass die ganzen Drohnenangriffe in zwei Zuständen laufen

489
00:54:12,281 --> 00:54:18,306
nämlich im militärischen, operativ aktiven Zustand und dass sie eine Liste abarbeiten, wenn sie

490
00:54:18,306 --> 00:54:30,427
gerade nicht operativ benötigt werden, wo eine Metadatenbank von oben nach unten nach einem Scoring abgearbeitet wird

491
00:54:30,427 --> 00:54:36,332
und dann ist das Linguistische, glaube ich, nicht das gefährlichste, wenn man die falsche Verwandtschaft hat

492
00:54:36,332 --> 00:54:42,729
A: ist richtig. Wir haben uns nur einen kleinen Teilbereich angeschaut von Daten,

493
00:54:42,729 --> 00:54:46,309
die aber natürlich sehr wertvoll sind, weil sie sehr viel tieferen Einblick in unser Leben geben

494
00:54:46,309 --> 00:54:58,128
als andere Daten. Gerade Radikalität zu messen – wovon ich nicht weiß, ob es stattfindet, etwas, was wir selbst vielleicht gar nicht wissen –

495
00:54:58,128 --> 00:55:02,579
aber die Metadaten sind sehr viel mächtiger, wenn es um so harte Fakten geht.

496
00:55:02,579 --> 00:55:05,310
Da sind die Metadaten natürlich interessanter.

497
00:55:05,310 --> 00:55:07,346
E: Du hast die nächste Frage

498
00:55:07,346 --> 00:55:12,720
F: Ich stimme zu, dass das ganz super wäre, wenn wir das auf der politischen Ebene besser in den Griff bekämen,

499
00:55:12,720 --> 00:55:20,310
aber mit einer üblichen pessimistischen Einstellung, gibt es nicht eigentlich schon jede Menge Beispiele,

500
00:55:20,310 --> 00:55:24,152
dass Politiker einfach auf den Zug aufspringen und das ganz super finden.

501
00:55:24,152 --> 00:55:27,775
„Ist doch eine tolle Methode, funktioniert doch großartig!” ?

502
00:55:27,775 --> 00:55:38,522
A: Ja! Was gemacht werden kann wird gemacht. Der Vortrag parallel ist ja über den „tiefen Staat“

503
00:55:38,522 --> 00:55:44,633
das wär dann zu überprüfen, ob wir nicht trotzdem zu Regularitäten kommen können, zu einer Gesetzgebung

504
00:55:44,633 --> 00:55:47,772
kommen können, die zunächst bestimmte Dinge zunächst mal verbietet. Ich finde das immer noch ein Ziel,

505
00:55:47,772 --> 00:55:52,242
das wir glaube ich teilen. Aber natürlich, der Zug fährt in eine andere Richtung.

506
00:55:52,242 --> 00:56:01,987
Aber was bei Snowden so unglaublich ist, ist, dass er Dinge in das Licht der Öffentlichkeit zerrt,

507
00:56:01,987 --> 00:56:07,139
aber sie müssen eben da sein! Solange es nur Gerüchte sind, kann man nichts machen,

508
00:56:07,139 --> 00:56:14,532
– und Desinformation ist eine wichtige Strategie – sind wir ausgeliefert.

509
00:56:14,532 --> 00:56:19,256
Aber sobald harte Fakten da sind, wird es interessant. Dann kann man darüber diskutieren

510
00:56:19,256 --> 00:56:22,516
und an dem Punkt sind wir jetzt wenigstens mal. Mal sehen, ob wir da nochmal hinkommen.

511
00:56:22,516 --> 00:56:26,870
E: Okay, die nächste Frage kommt aus der ersten Reihe

512
00:56:26,870 --> 00:56:31,829
F: Eher eine Ergänzung: Du hast gesagt, „was machen wir, wenn wir alle Terroristen fangen können?“

513
00:56:31,829 --> 00:56:35,928
Natürlich müssen wir uns dann immer noch wehren, natürlich gibt es dann immer noch keine Rechtfertigung,

514
00:56:35,928 --> 00:56:42,211
denn es wird immer noch alles gesammelt und – welche Datenbank ist 100% sicher?!

515
00:56:42,211 --> 00:56:47,620
Früher oder später kommen die Daten an die Öffentlichkeit! Will ich dann wirklich wissen,

516
00:56:47,620 --> 00:56:53,352
was man über mich weiß? Will ich, dass andere wissen können?

517
00:56:53,352 --> 00:56:55,810
Wir brauchen keine Rechtfertigung, um dagegen vorzugehen.

518
00:56:55,810 --> 00:56:59,848
Selbst wenn man nur noch die Terroristen fangen kann … wenn alle Daten gesammelt werden …

519
00:56:59,848 --> 00:57:02,538
Können wir nicht wollen!

520
00:57:02,538 --> 00:57:08,704
A: Danke, zumal auch das Konzept „Terrorist“ etwas ist, was man gesellschaftlich diskutieren kann.

521
00:57:08,704 --> 00:57:14,986
E: Noch eine Frage von da hinten. Ich würde sagen, die letzte Frage, weil die meisten schon aufbrechen

522
00:57:14,986 --> 00:57:26,812
F: Kurze Frage zum Thema false positive. Mal ein Forum zu etwas wie Medizin oder Sterbebegleitung gegen-gescannt?

523
00:57:26,812 --> 00:57:35,729
Auf die Themen schwarz-weiß, Negativität, und so? Thema Operation?

524
00:57:35,729 --> 00:57:40,216
Einfach so im Ranking im Vergleich zu Fefe, donalphonso, usw. liegen würde?

525
00:57:40,216 --> 00:57:45,969
A: Wäre interessant, habe ich nicht gemacht. Es gibt viel zu tun, viel zu rechnen

526
00:57:45,969 --> 00:57:52,490
F: na einfach von der Idee her, könnte da ja auch relativ viel false positive auftreten, oder?

527
00:57:52,490 --> 00:57:58,499
A: Klar … (durcheinander) … tschuldigung F: Rein aus dem Bauch heraus

528
00:57:58,499 --> 00:58:06,600
ist so die Richtung mal so ein Ansatz, wenn man sagt, man möchte viel false positive aufdecken.

529
00:58:06,600 --> 00:58:12,944
A: Ja, es ist ganz wichtig, dass wir die Entstehungskontexte und die Medien der Texte mit berücksichtigen müssten

530
00:58:12,944 --> 00:58:15,515
das haben wir jetzt überhaupt nicht gemacht, wir haben so getan, als seien alle Texte gleich,

531
00:58:15,515 --> 00:58:19,160
aber es ist natürlich nicht so. Wer sich mit der Thematik beschäftigt, merkt, dass Textsorten usw.

532
00:58:19,160 --> 00:58:22,535
einen unglaublichen Einfluss darauf haben, auf was wir da eigentlich messen.

533
00:58:22,535 --> 00:58:27,520
Deswegen hat die Fragestellerin völlig recht.

534
00:58:27,520 --> 00:58:34,350
Aber es gibt natürlich Methoden, Textsorten zu erkennen.

535
00:58:34,350 --> 00:58:39,408
E: Alles klar! Dann ganz vielen Dank nochmal an Josh und auch dass da noch so viel Zeit war…
