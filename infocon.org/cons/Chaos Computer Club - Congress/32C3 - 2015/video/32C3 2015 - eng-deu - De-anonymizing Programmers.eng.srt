1
00:00:08,690 --> 00:00:11,519
hi everyone thanks for coming and it's

2
00:00:11,519 --> 00:00:14,130
so good to see familiar faces again at

3
00:00:14,130 --> 00:00:16,590
this time of the year and today I'm

4
00:00:16,590 --> 00:00:19,070
going I'm going to do our annual

5
00:00:19,070 --> 00:00:21,930
traditional style metric talk and I'm

6
00:00:21,930 --> 00:00:23,400
from Princeton University

7
00:00:23,400 --> 00:00:26,039
my name is Eileen as he introduced me

8
00:00:26,039 --> 00:00:28,250
and I'm currently a postdoctoral

9
00:00:28,250 --> 00:00:32,640
research associate and we have been

10
00:00:32,640 --> 00:00:35,550
presenting at CCC for a few years now

11
00:00:35,550 --> 00:00:37,260
and they have been mostly about style

12
00:00:37,260 --> 00:00:40,230
amah tree but dear Rachel on the first

13
00:00:40,230 --> 00:00:42,690
day she gave the alternative keynote and

14
00:00:42,690 --> 00:00:45,329
it was non style metric this time and

15
00:00:45,329 --> 00:00:47,250
I'm going to keep the tradition alive

16
00:00:47,250 --> 00:00:49,110
and talk about style amma tree and

17
00:00:49,110 --> 00:00:52,350
machine learning today so what happened

18
00:00:52,350 --> 00:00:54,390
since last year last year I talked about

19
00:00:54,390 --> 00:00:56,280
the anonymizing program is for about

20
00:00:56,280 --> 00:00:59,640
like 15 minutes this year the anomaly

21
00:00:59,640 --> 00:01:01,890
the anonymization just became easier and

22
00:01:01,890 --> 00:01:04,229
that's kind of equivalent to the fact

23
00:01:04,229 --> 00:01:06,900
that there are more privacy concerns

24
00:01:06,900 --> 00:01:09,630
concerns for a program is now and also

25
00:01:09,630 --> 00:01:13,430
open source software developers and

26
00:01:13,430 --> 00:01:16,439
today we're going to talk about Salama

27
00:01:16,439 --> 00:01:17,790
tree and machine learning but at the

28
00:01:17,790 --> 00:01:19,680
same time we've released our most

29
00:01:19,680 --> 00:01:21,869
current paper on this it's on archive

30
00:01:21,869 --> 00:01:25,229
and on my website and if you want to

31
00:01:25,229 --> 00:01:27,270
read a summary of the stock or the paper

32
00:01:27,270 --> 00:01:29,880
you can also check our blog freedom to

33
00:01:29,880 --> 00:01:33,060
thinker let's start talking about

34
00:01:33,060 --> 00:01:35,460
stylistic finger prints by now if you

35
00:01:35,460 --> 00:01:37,049
are not familiar with style ama tree I

36
00:01:37,049 --> 00:01:39,350
will give you a brief introduction

37
00:01:39,350 --> 00:01:41,850
telemetry is the study of individual

38
00:01:41,850 --> 00:01:43,979
style most of the time it has been

39
00:01:43,979 --> 00:01:47,220
researched in writing style but we can

40
00:01:47,220 --> 00:01:49,020
see style AMA tree in fine arts for

41
00:01:49,020 --> 00:01:51,360
example artists can be identified by

42
00:01:51,360 --> 00:01:54,229
their brush strokes and in music

43
00:01:54,229 --> 00:01:58,770
musicians can be identified by the by

44
00:01:58,770 --> 00:02:00,360
the tones or rhythms that they are using

45
00:02:00,360 --> 00:02:03,450
and three years ago we presented that

46
00:02:03,450 --> 00:02:06,210
stoichiometry is also present in

47
00:02:06,210 --> 00:02:08,550
unconventional text and by

48
00:02:08,550 --> 00:02:09,940
unconventional text

49
00:02:09,940 --> 00:02:12,400
mean underground forums where sometimes

50
00:02:12,400 --> 00:02:15,850
cyber criminals are a variety of people

51
00:02:15,850 --> 00:02:19,240
engaging we can identify them as well

52
00:02:19,240 --> 00:02:22,210
and we have looked at translated text to

53
00:02:22,210 --> 00:02:25,390
see if translations can anonymize you

54
00:02:25,390 --> 00:02:28,060
and we saw that even when you take your

55
00:02:28,060 --> 00:02:30,730
English writing translate it to German

56
00:02:30,730 --> 00:02:33,220
Penta Japanese stand back to English we

57
00:02:33,220 --> 00:02:35,770
can still identify you and that sounds

58
00:02:35,770 --> 00:02:37,870
like a serious concern for someone who

59
00:02:37,870 --> 00:02:40,420
would like to remain anonymous and now

60
00:02:40,420 --> 00:02:42,640
we started investigating source code

61
00:02:42,640 --> 00:02:45,580
because if we are going to investigate

62
00:02:45,580 --> 00:02:48,250
style in language we can think of source

63
00:02:48,250 --> 00:02:50,410
code as another type of language it's a

64
00:02:50,410 --> 00:02:53,260
programming language and today I will

65
00:02:53,260 --> 00:02:55,450
give you the improvements in our source

66
00:02:55,450 --> 00:02:57,580
code authorship attribution method and

67
00:02:57,580 --> 00:03:00,070
at the end of the stop we will see that

68
00:03:00,070 --> 00:03:02,230
style that's expressed in code can be

69
00:03:02,230 --> 00:03:04,720
quantified and characterized and that's

70
00:03:04,720 --> 00:03:06,370
kind of the answer to our research

71
00:03:06,370 --> 00:03:10,510
question so what happens with supervised

72
00:03:10,510 --> 00:03:12,940
telemetry I say supervised telemetry

73
00:03:12,940 --> 00:03:14,590
because I'm going to talk about machine

74
00:03:14,590 --> 00:03:18,130
learning today we can identify style in

75
00:03:18,130 --> 00:03:22,120
some type of personal data or writing by

76
00:03:22,120 --> 00:03:24,550
using machine learning methods and I

77
00:03:24,550 --> 00:03:26,430
will give you a very common setting

78
00:03:26,430 --> 00:03:28,900
let's say that you have a set of

79
00:03:28,900 --> 00:03:32,050
documents with unknown authors and some

80
00:03:32,050 --> 00:03:34,330
with known authors and you would like to

81
00:03:34,330 --> 00:03:36,489
find out who these anonymous documents

82
00:03:36,489 --> 00:03:38,560
belong to so what you do is you take a

83
00:03:38,560 --> 00:03:41,230
machine learning classifier and then you

84
00:03:41,230 --> 00:03:43,989
train it based on the documents whose

85
00:03:43,989 --> 00:03:46,480
authorship is known and then you create

86
00:03:46,480 --> 00:03:49,890
a model for everyone for the people with

87
00:03:49,890 --> 00:03:53,170
non authorship documents and after that

88
00:03:53,170 --> 00:03:54,670
you can use your machine learning

89
00:03:54,670 --> 00:03:56,890
classifier to test and see who this

90
00:03:56,890 --> 00:03:59,050
anonymous document was written by and

91
00:03:59,050 --> 00:04:01,480
let's think about a common scenario for

92
00:04:01,480 --> 00:04:03,250
this there's a Lea stay anonymous

93
00:04:03,250 --> 00:04:05,650
blogger and Bob the abusive employer so

94
00:04:05,650 --> 00:04:08,739
Alice is blogging about abuses in Bob's

95
00:04:08,739 --> 00:04:11,860
company and Bob as he is abusive he is

96
00:04:11,860 --> 00:04:13,780
going to go ahead and collect everyone

97
00:04:13,780 --> 00:04:17,079
in his company's writing and then he's

98
00:04:17,079 --> 00:04:19,060
going to train a classifier so that he

99
00:04:19,060 --> 00:04:21,399
can identify who this anonymous blogger

100
00:04:21,399 --> 00:04:23,440
Alice's and Bob

101
00:04:23,440 --> 00:04:25,150
do this by using stoichiometry and

102
00:04:25,150 --> 00:04:29,310
machine learning I will give some other

103
00:04:29,310 --> 00:04:33,580
motivating or scary examples for example

104
00:04:33,580 --> 00:04:37,090
there was this case with a person called

105
00:04:37,090 --> 00:04:39,880
the connor or her her or his username

106
00:04:39,880 --> 00:04:42,430
was the connor on twitter and she

107
00:04:42,430 --> 00:04:45,070
tweeted that cisco just offered me a job

108
00:04:45,070 --> 00:04:46,750
not i have to wait the utility of a

109
00:04:46,750 --> 00:04:49,060
petty paycheck against the daily commute

110
00:04:49,060 --> 00:04:51,610
to San Jose and hating the work and then

111
00:04:51,610 --> 00:04:53,650
seaman Lovato who is the channel partner

112
00:04:53,650 --> 00:04:56,220
advocate for Cisco alert he saw this and

113
00:04:56,220 --> 00:04:59,290
that wasn't very good because you can

114
00:04:59,290 --> 00:05:01,900
then identify who the Connor is and her

115
00:05:01,900 --> 00:05:05,440
job offer might be in danger at that

116
00:05:05,440 --> 00:05:08,260
moment so but if Cisco takes all the

117
00:05:08,260 --> 00:05:10,120
cover letters that were submitted to

118
00:05:10,120 --> 00:05:12,070
Cisco and after that train a classifier

119
00:05:12,070 --> 00:05:15,010
and try to find who the Connor is by

120
00:05:15,010 --> 00:05:17,230
looking at her tweets because you can

121
00:05:17,230 --> 00:05:20,220
also identify people from their tweets

122
00:05:20,220 --> 00:05:22,840
but that wasn't necessary in this case

123
00:05:22,840 --> 00:05:25,870
because since you can find some cached

124
00:05:25,870 --> 00:05:29,370
information online she was identified as

125
00:05:29,370 --> 00:05:33,940
Connor Riley and unfortunately she lost

126
00:05:33,940 --> 00:05:37,810
the job offer after this so this is one

127
00:05:37,810 --> 00:05:39,220
example where this might have been

128
00:05:39,220 --> 00:05:40,990
applied so you need to understand like

129
00:05:40,990 --> 00:05:43,000
when we are talking about machine

130
00:05:43,000 --> 00:05:45,610
learning methods that make us make it

131
00:05:45,610 --> 00:05:47,410
possible to the anonymize people there

132
00:05:47,410 --> 00:05:49,570
might be some dangers associated with

133
00:05:49,570 --> 00:05:53,169
this or you might want to be more aware

134
00:05:53,169 --> 00:05:54,790
of how you're sharing your information

135
00:05:54,790 --> 00:05:57,220
online keeping in mind that you can

136
00:05:57,220 --> 00:06:01,240
always be we identified and what happens

137
00:06:01,240 --> 00:06:03,100
with source code for example there was

138
00:06:03,100 --> 00:06:06,070
this recent tweet and it says I just

139
00:06:06,070 --> 00:06:07,810
heard from an Internet Apple that they

140
00:06:07,810 --> 00:06:09,580
disallow her from contributing to open

141
00:06:09,580 --> 00:06:11,620
source on her own time that's illegal

142
00:06:11,620 --> 00:06:14,890
right it's probably illegal but Apple

143
00:06:14,890 --> 00:06:17,470
can probably find out if someone is

144
00:06:17,470 --> 00:06:18,940
contributing to open source code

145
00:06:18,940 --> 00:06:21,130
repositories by looking at the code that

146
00:06:21,130 --> 00:06:23,620
they have at Apple and then just compare

147
00:06:23,620 --> 00:06:25,900
any suspicious code - maybe we identify

148
00:06:25,900 --> 00:06:29,980
with this contributor is and because of

149
00:06:29,980 --> 00:06:31,720
that we are going to talk about your non

150
00:06:31,720 --> 00:06:33,250
amaizing programmers with code style

151
00:06:33,250 --> 00:06:35,169
Irma - today this has been joined work

152
00:06:35,169 --> 00:06:37,150
with my great collaborators and some

153
00:06:37,150 --> 00:06:40,750
of them are here with us today and why

154
00:06:40,750 --> 00:06:42,100
do we want to do source code style

155
00:06:42,100 --> 00:06:44,050
limiter like how can we first start

156
00:06:44,050 --> 00:06:46,030
doing this first of all we know that as

157
00:06:46,030 --> 00:06:48,370
any language source code as the

158
00:06:48,370 --> 00:06:50,320
programming language is learned on an

159
00:06:50,320 --> 00:06:53,170
individual basis and as a result you

160
00:06:53,170 --> 00:06:55,480
develop a unique coding style and that

161
00:06:55,480 --> 00:06:57,730
can potentially make you identifiable so

162
00:06:57,730 --> 00:06:59,470
we wanted to investigate if that's

163
00:06:59,470 --> 00:07:01,780
really possible do we leave any

164
00:07:01,780 --> 00:07:03,730
fingerprints in source code that might

165
00:07:03,730 --> 00:07:06,850
make us identifiable and why else would

166
00:07:06,850 --> 00:07:08,530
we do this like maybe we want to gain

167
00:07:08,530 --> 00:07:10,510
some software engineering insights for

168
00:07:10,510 --> 00:07:12,700
example we want to analyze how coding

169
00:07:12,700 --> 00:07:15,250
style changes over years or the

170
00:07:15,250 --> 00:07:17,350
differences between coding styles of

171
00:07:17,350 --> 00:07:19,690
more advanced and less advanced

172
00:07:19,690 --> 00:07:21,850
programmers or does your coding style

173
00:07:21,850 --> 00:07:23,500
change when you're trying to implement

174
00:07:23,500 --> 00:07:27,850
more sophisticated functionality and the

175
00:07:27,850 --> 00:07:30,220
main call or like the most motivating

176
00:07:30,220 --> 00:07:32,560
goal here would be to identify malicious

177
00:07:32,560 --> 00:07:34,660
programmers who are maybe trying to

178
00:07:34,660 --> 00:07:36,550
contribute malicious code or like

179
00:07:36,550 --> 00:07:39,690
backdoors to open source software and

180
00:07:39,690 --> 00:07:43,090
let's think about a common scenario alex

181
00:07:43,090 --> 00:07:45,520
is analyzing a library and there is

182
00:07:45,520 --> 00:07:47,320
malicious code in the library and both

183
00:07:47,320 --> 00:07:49,960
has a source code collection and he

184
00:07:49,960 --> 00:07:52,330
knows the authors so bob is going to

185
00:07:52,330 --> 00:07:53,860
search his collection with machine

186
00:07:53,860 --> 00:07:56,110
learning to find out who Alice's

187
00:07:56,110 --> 00:07:58,690
adversaries and a second scenario about

188
00:07:58,690 --> 00:08:01,090
plagiarism so you're a college student

189
00:08:01,090 --> 00:08:04,180
and you got an extension to your program

190
00:08:04,180 --> 00:08:06,460
in assignment and Bob your professor

191
00:08:06,460 --> 00:08:08,350
wants to know if you have plagiarized or

192
00:08:08,350 --> 00:08:10,150
not so he's going to train a classifier

193
00:08:10,150 --> 00:08:13,930
on all the submissions by the other

194
00:08:13,930 --> 00:08:16,000
students and then he can check if there

195
00:08:16,000 --> 00:08:17,890
are extreme similarities between coding

196
00:08:17,890 --> 00:08:20,110
styles and similarity that doesn't

197
00:08:20,110 --> 00:08:22,390
really belong to your former coding

198
00:08:22,390 --> 00:08:25,360
style unfortunately these two examples

199
00:08:25,360 --> 00:08:28,120
for kind of security infringing sorry

200
00:08:28,120 --> 00:08:31,690
security enhancing examples but source

201
00:08:31,690 --> 00:08:34,120
code style metric could also be very

202
00:08:34,120 --> 00:08:36,370
privacy infringing so you have to be

203
00:08:36,370 --> 00:08:38,169
very careful when you want to use that

204
00:08:38,169 --> 00:08:40,720
for example syed malik poor maybe some

205
00:08:40,720 --> 00:08:43,150
of you remember him from last year's

206
00:08:43,150 --> 00:08:45,790
talk he was sentenced to that because he

207
00:08:45,790 --> 00:08:48,700
was identified as the website programmer

208
00:08:48,700 --> 00:08:51,790
of a porn site and unfortunately the

209
00:08:51,790 --> 00:08:53,770
Iranian government found about this and

210
00:08:53,770 --> 00:08:55,570
he was sentenced to that but he managed

211
00:08:55,570 --> 00:08:57,400
to get out of this entire thing because

212
00:08:57,400 --> 00:08:59,050
like he was also a resident of another

213
00:08:59,050 --> 00:09:01,960
country but this is a dangerous case

214
00:09:01,960 --> 00:09:04,600
we're in like oppressive regimes your

215
00:09:04,600 --> 00:09:07,420
court might put you in a dangerous

216
00:09:07,420 --> 00:09:09,180
situation

217
00:09:09,180 --> 00:09:11,710
so I'll start talking about a little

218
00:09:11,710 --> 00:09:15,160
more technical stuff and show you how

219
00:09:15,160 --> 00:09:17,470
our work improves the state of the art

220
00:09:17,470 --> 00:09:20,920
and bring some novel contributions first

221
00:09:20,920 --> 00:09:24,310
of all this is a list of comparison to

222
00:09:24,310 --> 00:09:26,110
relate its work and there is not much

223
00:09:26,110 --> 00:09:29,440
related work as you can see and the only

224
00:09:29,440 --> 00:09:31,900
difference in the previous features used

225
00:09:31,900 --> 00:09:34,870
to represent coding style and ours is

226
00:09:34,870 --> 00:09:37,630
syntactic features so we use structural

227
00:09:37,630 --> 00:09:39,730
features to represent your coding style

228
00:09:39,730 --> 00:09:42,400
we don't just use your function names or

229
00:09:42,400 --> 00:09:44,860
variable names or SEC spaces and tabs

230
00:09:44,860 --> 00:09:47,410
that you use and as a classifier we use

231
00:09:47,410 --> 00:09:49,270
a random force and I'm going to show you

232
00:09:49,270 --> 00:09:51,420
why these are making very big

233
00:09:51,420 --> 00:09:55,930
differences in the results so in the

234
00:09:55,930 --> 00:09:57,910
past the highest accuracy that has been

235
00:09:57,910 --> 00:10:00,850
reached 2d anonymize programmers was 97

236
00:10:00,850 --> 00:10:03,370
percent and this is 2d anonymized 30

237
00:10:03,370 --> 00:10:06,880
programmers correctly but we can do

238
00:10:06,880 --> 00:10:10,030
anonymous 250 programmers with 98%

239
00:10:10,030 --> 00:10:13,480
accuracy so we are beating the highest

240
00:10:13,480 --> 00:10:15,340
accuracy in the past and we have a much

241
00:10:15,340 --> 00:10:17,170
more difficult machine learning problem

242
00:10:17,170 --> 00:10:19,300
because we have a much larger data set

243
00:10:19,300 --> 00:10:24,010
of 250 programmers the largest data set

244
00:10:24,010 --> 00:10:25,870
that has been used in the past

245
00:10:25,870 --> 00:10:28,750
is 46 programmers and they get 75%

246
00:10:28,750 --> 00:10:31,330
accuracy but after last year's

247
00:10:31,330 --> 00:10:33,580
talk we were able to scale our approach

248
00:10:33,580 --> 00:10:35,500
to one thousand and six hundred

249
00:10:35,500 --> 00:10:38,650
programmers and we get 94% accuracy in

250
00:10:38,650 --> 00:10:41,950
correctly identifying 14,000 and 400

251
00:10:41,950 --> 00:10:45,370
source code samples of these 1,600

252
00:10:45,370 --> 00:10:47,820
programmers so this is life scale

253
00:10:47,820 --> 00:10:50,020
authorship attribution this is life

254
00:10:50,020 --> 00:10:53,440
scale the anonymous ation how do we do

255
00:10:53,440 --> 00:10:55,210
this so we have our general machine

256
00:10:55,210 --> 00:10:57,490
learning setup first of all we need data

257
00:10:57,490 --> 00:10:59,330
with ground truth

258
00:10:59,330 --> 00:11:01,610
so we go to Google Code Jam it's an

259
00:11:01,610 --> 00:11:03,290
international annual programming

260
00:11:03,290 --> 00:11:05,930
competition and we collected a data set

261
00:11:05,930 --> 00:11:08,180
and it was in C++ because that was the

262
00:11:08,180 --> 00:11:10,270
most commonly used language in this

263
00:11:10,270 --> 00:11:12,770
competition and we had about a hundred

264
00:11:12,770 --> 00:11:15,649
thousand users from different years we

265
00:11:15,649 --> 00:11:18,200
have our data set so now what we have to

266
00:11:18,200 --> 00:11:21,440
do is we need to find the features and

267
00:11:21,440 --> 00:11:23,120
properties that are going to represent

268
00:11:23,120 --> 00:11:26,690
the coding styles of these people so we

269
00:11:26,690 --> 00:11:28,910
pre-process the data set the source code

270
00:11:28,910 --> 00:11:33,260
and we get the abstract syntax tree of

271
00:11:33,260 --> 00:11:36,320
the source code with using a fuzzy AST

272
00:11:36,320 --> 00:11:38,779
parser and after that we extract the

273
00:11:38,779 --> 00:11:40,790
features that represent coding style and

274
00:11:40,790 --> 00:11:43,399
then we feed these properties that are

275
00:11:43,399 --> 00:11:45,950
going to represent individual style in a

276
00:11:45,950 --> 00:11:47,330
random forest and machine learning

277
00:11:47,330 --> 00:11:49,610
classifier and then we do our

278
00:11:49,610 --> 00:11:51,470
classification with majority voting in

279
00:11:51,470 --> 00:11:54,910
of these like 302 random forest trees

280
00:11:54,910 --> 00:11:56,420
why did we use

281
00:11:56,420 --> 00:11:59,660
Odia so we have data from 2008 to 2014

282
00:11:59,660 --> 00:12:03,279
now we actually have 2015 status but and

283
00:12:03,279 --> 00:12:05,930
the most important point was that

284
00:12:05,930 --> 00:12:08,770
everyone in this competition is

285
00:12:08,770 --> 00:12:11,209
implementing the solution to the same

286
00:12:11,209 --> 00:12:13,610
programming tasks so they're

287
00:12:13,610 --> 00:12:15,170
implementing the same algorithmic

288
00:12:15,170 --> 00:12:17,600
functionality and the only thing or the

289
00:12:17,600 --> 00:12:19,430
most prevalent thing that can

290
00:12:19,430 --> 00:12:22,160
differentiate these source code samples

291
00:12:22,160 --> 00:12:24,920
are the right are the coding styles of

292
00:12:24,920 --> 00:12:27,200
these programmers and at the same time

293
00:12:27,200 --> 00:12:28,690
they have to implement this

294
00:12:28,690 --> 00:12:30,829
functionality in a very limited time

295
00:12:30,829 --> 00:12:32,360
which means that they don't have a

296
00:12:32,360 --> 00:12:33,980
chance to go back to the code

297
00:12:33,980 --> 00:12:36,800
improve it make it nicer and then

298
00:12:36,800 --> 00:12:38,390
copy/paste some stuff from Stack

299
00:12:38,390 --> 00:12:43,880
Overflow and as contestants are able to

300
00:12:43,880 --> 00:12:47,240
complete runs the problems get harder so

301
00:12:47,240 --> 00:12:50,270
we kind of have a control of when

302
00:12:50,270 --> 00:12:52,250
someone is implementing and more

303
00:12:52,250 --> 00:12:55,040
sophisticated functionality and as a

304
00:12:55,040 --> 00:12:57,440
result we can infer which programmers

305
00:12:57,440 --> 00:13:00,140
are maybe more advanced and as I said

306
00:13:00,140 --> 00:13:02,660
C++ was the most common language so we

307
00:13:02,660 --> 00:13:05,450
decided to go ahead with C++ in our

308
00:13:05,450 --> 00:13:08,000
experiments how do we do this how do we

309
00:13:08,000 --> 00:13:08,570
represent

310
00:13:08,570 --> 00:13:10,520
personal coding style first of all we

311
00:13:10,520 --> 00:13:12,230
have the source code sample here we see

312
00:13:12,230 --> 00:13:12,620
this

313
00:13:12,620 --> 00:13:15,350
the just five lines of code and from

314
00:13:15,350 --> 00:13:18,170
that we can look at lexical features for

315
00:13:18,170 --> 00:13:21,170
example integer n and is a lexical

316
00:13:21,170 --> 00:13:23,870
feature because you chose it as an and

317
00:13:23,870 --> 00:13:26,720
then bar and foo function names you

318
00:13:26,720 --> 00:13:28,580
chose those so those are lexical

319
00:13:28,580 --> 00:13:30,410
features that come from personal input

320
00:13:30,410 --> 00:13:33,110
and then we have layout features like

321
00:13:33,110 --> 00:13:35,630
the spaces and tabs and where you put

322
00:13:35,630 --> 00:13:37,390
the curly brackets and things like that

323
00:13:37,390 --> 00:13:41,600
but the important thing that was able to

324
00:13:41,600 --> 00:13:44,510
represent coding style in a very strong

325
00:13:44,510 --> 00:13:47,330
manner in our experiments was that we

326
00:13:47,330 --> 00:13:49,970
used structural features and we can do

327
00:13:49,970 --> 00:13:51,740
that by converting the source code

328
00:13:51,740 --> 00:13:54,260
sample to an abstract syntax tree and

329
00:13:54,260 --> 00:13:55,880
then you get the grammar and structure

330
00:13:55,880 --> 00:13:58,870
of the source code and here you can

331
00:13:58,870 --> 00:14:03,020
extract a rich set of features and these

332
00:14:03,020 --> 00:14:05,420
are also more difficult to change as

333
00:14:05,420 --> 00:14:08,660
opposed to just changing foo and n this

334
00:14:08,660 --> 00:14:12,080
because these are kind of embedded so we

335
00:14:12,080 --> 00:14:13,880
extract features from the source code we

336
00:14:13,880 --> 00:14:16,810
extract features such as edges nodes

337
00:14:16,810 --> 00:14:18,800
term frequency inverse document

338
00:14:18,800 --> 00:14:22,430
frequency or the average depth of a like

339
00:14:22,430 --> 00:14:25,040
statement node for example and then we

340
00:14:25,040 --> 00:14:27,350
built our feature set to represent

341
00:14:27,350 --> 00:14:30,530
programming style and why did we use a

342
00:14:30,530 --> 00:14:32,540
random for is first of all random

343
00:14:32,540 --> 00:14:35,870
forests by nature are multi class

344
00:14:35,870 --> 00:14:38,650
classifiers for example as opposed to a

345
00:14:38,650 --> 00:14:42,410
common support vector machine which is a

346
00:14:42,410 --> 00:14:46,160
2 class classifier random forest is more

347
00:14:46,160 --> 00:14:49,460
successful in classifying many classes

348
00:14:49,460 --> 00:14:51,110
as opposed to support vector machine

349
00:14:51,110 --> 00:14:53,750
classifying just two classes making a

350
00:14:53,750 --> 00:14:56,180
binary classification problem and also

351
00:14:56,180 --> 00:14:58,250
random for since they use decision trees

352
00:14:58,250 --> 00:15:00,590
and information gained during the

353
00:15:00,590 --> 00:15:02,870
training process they avoid overfitting

354
00:15:02,870 --> 00:15:05,360
so we want to make sure that we are not

355
00:15:05,360 --> 00:15:08,480
overfitting to a bias in the data set or

356
00:15:08,480 --> 00:15:12,050
to someone's very peculiar property and

357
00:15:12,050 --> 00:15:14,000
what we do is we get our data set we

358
00:15:14,000 --> 00:15:15,380
extract all the features and we do

359
00:15:15,380 --> 00:15:17,450
k-fold cross-validation which means that

360
00:15:17,450 --> 00:15:19,670
for example for each programmer we have

361
00:15:19,670 --> 00:15:22,040
nine source code samples we train on

362
00:15:22,040 --> 00:15:23,990
eight source code samples from

363
00:15:23,990 --> 00:15:26,420
programmer and then we tried to test the

364
00:15:26,420 --> 00:15:29,540
ninth one from all of them and see who

365
00:15:29,540 --> 00:15:32,300
it was written by and then we validate

366
00:15:32,300 --> 00:15:34,220
our method on a different data set to

367
00:15:34,220 --> 00:15:36,380
see like if the features that we

368
00:15:36,380 --> 00:15:40,399
obtained are really making sense let's

369
00:15:40,399 --> 00:15:43,040
talk about the general cases and here I

370
00:15:43,040 --> 00:15:45,860
will talk about how we were able to

371
00:15:45,860 --> 00:15:47,600
improve the method for example there's

372
00:15:47,600 --> 00:15:50,000
this general case who is this anonymous

373
00:15:50,000 --> 00:15:50,420
program

374
00:15:50,420 --> 00:15:52,220
this is programmer authorship

375
00:15:52,220 --> 00:15:53,779
attribution programmer the anonymous

376
00:15:53,779 --> 00:15:55,550
ation and maybe this can be applied to

377
00:15:55,550 --> 00:15:57,950
Satoshi Nakamoto who was the founder of

378
00:15:57,950 --> 00:16:00,520
Bitcoin and we don't really know who is

379
00:16:00,520 --> 00:16:03,950
what happens here so we have 1600

380
00:16:03,950 --> 00:16:07,130
programmers and each have 90 code

381
00:16:07,130 --> 00:16:09,500
samples and we do nine fold cross

382
00:16:09,500 --> 00:16:12,260
validation and we extract features from

383
00:16:12,260 --> 00:16:14,990
their code samples and once we train our

384
00:16:14,990 --> 00:16:19,160
classifier and test on the 14400 samples

385
00:16:19,160 --> 00:16:21,560
we get night four percent accuracy how

386
00:16:21,560 --> 00:16:24,110
can we do this with Satoshi Dom so if we

387
00:16:24,110 --> 00:16:26,510
had a suspect set for Satoshi what we do

388
00:16:26,510 --> 00:16:29,839
is we take the suspect sets previous

389
00:16:29,839 --> 00:16:32,870
code samples between a classifier on

390
00:16:32,870 --> 00:16:36,770
that and after that as test data we take

391
00:16:36,770 --> 00:16:40,130
bitcoins initial get commit the first

392
00:16:40,130 --> 00:16:43,490
original Bitcoin code and then we try to

393
00:16:43,490 --> 00:16:46,130
see who this was written by in the

394
00:16:46,130 --> 00:16:49,459
suspect set and many people ask us so

395
00:16:49,459 --> 00:16:52,279
who is Satoshi and the thing is we have

396
00:16:52,279 --> 00:16:54,920
a suspect set but unfortunately the main

397
00:16:54,920 --> 00:16:57,470
suspect in our set doesn't have any

398
00:16:57,470 --> 00:17:00,380
former code samples so we are just

399
00:17:00,380 --> 00:17:04,069
leaving this slide like this but happens

400
00:17:04,069 --> 00:17:05,900
if someone tries to obfuscate code so

401
00:17:05,900 --> 00:17:07,730
why do people off escape code they would

402
00:17:07,730 --> 00:17:10,189
do that to make their code become

403
00:17:10,189 --> 00:17:12,319
unrecognizable maybe they're

404
00:17:12,319 --> 00:17:14,329
plagiarizing maybe it's malicious code

405
00:17:14,329 --> 00:17:16,339
or maybe they're trying to be anonymous

406
00:17:16,339 --> 00:17:18,230
but we are gonna show that this is not

407
00:17:18,230 --> 00:17:20,540
gonna make them anonymous so our

408
00:17:20,540 --> 00:17:22,510
authorship attribution technique is

409
00:17:22,510 --> 00:17:25,459
impervious to of the shelf source code

410
00:17:25,459 --> 00:17:29,090
obfuscators and this is one example this

411
00:17:29,090 --> 00:17:31,190
is a commercial off-the-shelf obfuscator

412
00:17:31,190 --> 00:17:33,600
called stomachs and

413
00:17:33,600 --> 00:17:35,820
what it does is like it's available you

414
00:17:35,820 --> 00:17:37,860
can go online buy it and like it works

415
00:17:37,860 --> 00:17:40,679
for many languages what it does is if

416
00:17:40,679 --> 00:17:43,260
you look here it will take all the

417
00:17:43,260 --> 00:17:45,210
lexical features like the function names

418
00:17:45,210 --> 00:17:47,400
variable names and all the comments and

419
00:17:47,400 --> 00:17:50,340
also all the spaces and refactor them

420
00:17:50,340 --> 00:17:53,750
but it's not gonna make any difference

421
00:17:53,750 --> 00:17:57,720
in the structure of the program so like

422
00:17:57,720 --> 00:17:59,880
all the spaces are ripped everything is

423
00:17:59,880 --> 00:18:04,500
refactored characters are refactored

424
00:18:04,500 --> 00:18:08,010
with hexadecimal ASCII representations

425
00:18:08,010 --> 00:18:10,110
the same goes true for the numbers that

426
00:18:10,110 --> 00:18:13,860
are here but since the structure of the

427
00:18:13,860 --> 00:18:17,850
program remains unchanged we still get

428
00:18:17,850 --> 00:18:20,340
the same accuracy Indian anonymizing

429
00:18:20,340 --> 00:18:23,190
programmer programmers once we obfuscate

430
00:18:23,190 --> 00:18:26,570
them but such a common off-the-shelf

431
00:18:26,570 --> 00:18:29,010
obfuscator which is not changing the

432
00:18:29,010 --> 00:18:31,500
structure of the program and the example

433
00:18:31,500 --> 00:18:34,440
here is like we use 20 C++ programmers

434
00:18:34,440 --> 00:18:36,780
obfuscated their code we are able to do

435
00:18:36,780 --> 00:18:39,179
anonymize them with 99% accuracy with

436
00:18:39,179 --> 00:18:40,890
their original code and we are able to

437
00:18:40,890 --> 00:18:43,770
do anonymize them with 99% accuracy from

438
00:18:43,770 --> 00:18:46,140
their obfuscated code because we have

439
00:18:46,140 --> 00:18:48,510
the structural features which are very

440
00:18:48,510 --> 00:18:51,840
powerful what happens if we try to use a

441
00:18:51,840 --> 00:18:54,390
more sophisticated obfuscated or here

442
00:18:54,390 --> 00:18:56,220
our example would be Tigris it's a

443
00:18:56,220 --> 00:18:59,669
visualizer and enables you to apply many

444
00:18:59,669 --> 00:19:02,610
various kinds of obfuscation methods so

445
00:19:02,610 --> 00:19:05,309
we have code it's like 14 lines and we

446
00:19:05,309 --> 00:19:07,530
obfuscated it becomes like 800 lines

447
00:19:07,530 --> 00:19:10,620
it's completely unreadable so I don't

448
00:19:10,620 --> 00:19:11,880
think like if your is open-source

449
00:19:11,880 --> 00:19:15,409
software developer I'm not sure the

450
00:19:15,409 --> 00:19:18,390
people in your project would be happy if

451
00:19:18,390 --> 00:19:24,210
you contribute code like this but this

452
00:19:24,210 --> 00:19:26,820
works better at anonymizing your coding

453
00:19:26,820 --> 00:19:30,539
style so we took C program is for this

454
00:19:30,539 --> 00:19:32,820
experiment and then again we had 20

455
00:19:32,820 --> 00:19:35,130
programmers we are able to do anonymize

456
00:19:35,130 --> 00:19:37,970
them with 96% accuracy but when we

457
00:19:37,970 --> 00:19:40,559
obfuscated it with tygra's changing the

458
00:19:40,559 --> 00:19:43,020
structure of the program as well but the

459
00:19:43,020 --> 00:19:45,540
functionality remains the same we get 67

460
00:19:45,540 --> 00:19:46,680
percent accuracy

461
00:19:46,680 --> 00:19:49,650
there's almost a 30% drop in accuracy

462
00:19:49,650 --> 00:19:52,410
but compared to the random chance which

463
00:19:52,410 --> 00:19:56,160
is 5% that's like the 5% chance that you

464
00:19:56,160 --> 00:19:58,200
can correctly identify someone just

465
00:19:58,200 --> 00:20:02,070
randomly 67% is a very high number which

466
00:20:02,070 --> 00:20:04,230
shows that your code is certainly not

467
00:20:04,230 --> 00:20:07,350
completely anonymized once you apply

468
00:20:07,350 --> 00:20:09,870
this up for skater so this kind of gives

469
00:20:09,870 --> 00:20:12,090
the answer that obfuscation is not the

470
00:20:12,090 --> 00:20:15,020
solution to anonymization in source code

471
00:20:15,020 --> 00:20:17,370
but at first coding style throughout

472
00:20:17,370 --> 00:20:19,410
year so we want to see if coding style

473
00:20:19,410 --> 00:20:21,690
is consistent because if that's the case

474
00:20:21,690 --> 00:20:24,000
we can take someone's code from 10 years

475
00:20:24,000 --> 00:20:26,850
ago and then try to test on code from

476
00:20:26,850 --> 00:20:29,940
this year and for this we took 25 voters

477
00:20:29,940 --> 00:20:32,520
from 2012 trained a classifier on them

478
00:20:32,520 --> 00:20:35,190
and then our test data came from 2014

479
00:20:35,190 --> 00:20:36,990
and we were able to correctly identify

480
00:20:36,990 --> 00:20:41,190
this these with 96% accuracy and if we

481
00:20:41,190 --> 00:20:43,710
were trying to do this with in 2014 the

482
00:20:43,710 --> 00:20:47,280
accuracy was 98% so there's a 2% change

483
00:20:47,280 --> 00:20:49,320
in the accuracy which shows that coding

484
00:20:49,320 --> 00:20:51,210
style is somehow still persistent

485
00:20:51,210 --> 00:20:54,450
throughout years and we wanted to

486
00:20:54,450 --> 00:20:56,130
generalize our approach and we wanted to

487
00:20:56,130 --> 00:20:58,230
do this very quickly because we would

488
00:20:58,230 --> 00:21:00,870
like to see how feasible this is and

489
00:21:00,870 --> 00:21:02,730
like is this a general approach that can

490
00:21:02,730 --> 00:21:04,080
be applied to other programming

491
00:21:04,080 --> 00:21:06,090
languages and how easy would it be for

492
00:21:06,090 --> 00:21:07,830
someone else that wants to use our code

493
00:21:07,830 --> 00:21:09,420
just for a different programming

494
00:21:09,420 --> 00:21:11,790
language and for this we only use

495
00:21:11,790 --> 00:21:14,820
structural features and we use the ast

496
00:21:14,820 --> 00:21:17,760
generator that comes with Python to

497
00:21:17,760 --> 00:21:19,890
generate the AAS piece of Python source

498
00:21:19,890 --> 00:21:22,370
code and we were able to do anonymize

499
00:21:22,370 --> 00:21:25,610
229 program which just from there's

500
00:21:25,610 --> 00:21:29,130
abstract abstract syntax 3 features and

501
00:21:29,130 --> 00:21:31,230
structural features with 54 percent

502
00:21:31,230 --> 00:21:33,930
accuracy and if we do top 5 relaxed

503
00:21:33,930 --> 00:21:36,210
classification which means that you do

504
00:21:36,210 --> 00:21:38,460
classification I your classifier would

505
00:21:38,460 --> 00:21:40,410
return your probability saying that ok

506
00:21:40,410 --> 00:21:42,180
this is the most probable person and

507
00:21:42,180 --> 00:21:44,130
this is the second most probable person

508
00:21:44,130 --> 00:21:45,870
and if you look at the first 5

509
00:21:45,870 --> 00:21:48,690
probabilities if the program correct

510
00:21:48,690 --> 00:21:51,450
programmer is written that set then

511
00:21:51,450 --> 00:21:53,400
that's considered correct and in that

512
00:21:53,400 --> 00:21:54,240
case we are a

513
00:21:54,240 --> 00:21:58,800
to increase the accuracy to 76% and if

514
00:21:58,800 --> 00:22:01,050
we do this for 23 programmers we get 88

515
00:22:01,050 --> 00:22:03,420
percent accuracy and with top-five

516
00:22:03,420 --> 00:22:05,460
relaxed classification we get close to

517
00:22:05,460 --> 00:22:07,950
100% accuracy and wherever you do

518
00:22:07,950 --> 00:22:10,020
relaxed classification let's say that

519
00:22:10,020 --> 00:22:12,300
you have a huge data set and maybe you

520
00:22:12,300 --> 00:22:13,860
wanna you're willing to do some manual

521
00:22:13,860 --> 00:22:15,780
analysis but first you would like to

522
00:22:15,780 --> 00:22:17,940
start with reducing your suspect set

523
00:22:17,940 --> 00:22:20,010
size so you can just run relaxed

524
00:22:20,010 --> 00:22:21,780
classification and then maybe look at

525
00:22:21,780 --> 00:22:24,330
the top 10 manually to understand it

526
00:22:24,330 --> 00:22:29,340
better and in our results we see that we

527
00:22:29,340 --> 00:22:31,290
are bringing a new principled method

528
00:22:31,290 --> 00:22:33,450
with a robust inside syntactic feature

529
00:22:33,450 --> 00:22:36,020
set for the anonymizing programmers and

530
00:22:36,020 --> 00:22:38,760
this shows that there is a serious

531
00:22:38,760 --> 00:22:42,120
concern for anonymity when you're trying

532
00:22:42,120 --> 00:22:44,220
to be open-source software developer or

533
00:22:44,220 --> 00:22:46,679
just a programmer because we will soon

534
00:22:46,679 --> 00:22:50,490
talk about executable binaries where

535
00:22:50,490 --> 00:22:52,980
there is no source code and for future

536
00:22:52,980 --> 00:22:54,720
work we are planning to look at multiple

537
00:22:54,720 --> 00:22:56,640
authorship detection for example git

538
00:22:56,640 --> 00:22:58,470
repositories can we find the multiple

539
00:22:58,470 --> 00:23:01,710
authors and can we identify which part

540
00:23:01,710 --> 00:23:04,830
was exactly written by whom and we would

541
00:23:04,830 --> 00:23:06,690
also like to look into a non amaizing

542
00:23:06,690 --> 00:23:08,160
source code because we saw that

543
00:23:08,160 --> 00:23:10,170
obfuscation is not the answer to that

544
00:23:10,170 --> 00:23:12,929
and then what about Salama tree and

545
00:23:12,929 --> 00:23:15,150
executable binaries so executable

546
00:23:15,150 --> 00:23:17,040
binaries are compiled code when you

547
00:23:17,040 --> 00:23:20,640
compile code the coding style feature is

548
00:23:20,640 --> 00:23:24,030
still persist to the compiled version so

549
00:23:24,030 --> 00:23:25,920
this is what happens we have source code

550
00:23:25,920 --> 00:23:28,380
it's like 20 lines I don't have all of

551
00:23:28,380 --> 00:23:30,540
it here and then once you compile it you

552
00:23:30,540 --> 00:23:32,730
get binary zeros and ones like thousands

553
00:23:32,730 --> 00:23:35,550
of them and I don't think I can

554
00:23:35,550 --> 00:23:38,640
personally understand anything from this

555
00:23:38,640 --> 00:23:40,260
I don't think we can do naanum eyes it

556
00:23:40,260 --> 00:23:44,309
by just looking at it like this so now

557
00:23:44,309 --> 00:23:46,290
I'm going to talk about the second part

558
00:23:46,290 --> 00:23:50,070
of this talk and what happens when you

559
00:23:50,070 --> 00:23:52,470
compile code and you try to do anonymize

560
00:23:52,470 --> 00:23:54,059
programmers from their executable

561
00:23:54,059 --> 00:23:57,000
binaries and this is the paper that just

562
00:23:57,000 --> 00:23:59,070
went public today if you want you can

563
00:23:59,070 --> 00:24:02,340
look at it on my website why would we

564
00:24:02,340 --> 00:24:03,840
want to do that first of all the

565
00:24:03,840 --> 00:24:05,610
research question this coding style

566
00:24:05,610 --> 00:24:08,000
exists in binary code

567
00:24:08,000 --> 00:24:11,010
is there a threat to privacy and animate

568
00:24:11,010 --> 00:24:12,770
inanimate can with the anonymized

569
00:24:12,770 --> 00:24:15,720
programmers from compiled code and maybe

570
00:24:15,720 --> 00:24:17,940
at the end can be used as for malware

571
00:24:17,940 --> 00:24:22,290
family classification this is the

572
00:24:22,290 --> 00:24:24,000
approach they had in related work so

573
00:24:24,000 --> 00:24:26,310
since I've shown you the machine

574
00:24:26,310 --> 00:24:29,100
learning workflow that we had I think

575
00:24:29,100 --> 00:24:31,080
you you're kind of getting the idea how

576
00:24:31,080 --> 00:24:33,090
machine learning would work you have

577
00:24:33,090 --> 00:24:34,890
your data set you need to extract

578
00:24:34,890 --> 00:24:36,720
features that are going to present a

579
00:24:36,720 --> 00:24:39,750
class once you do that you feed it to

580
00:24:39,750 --> 00:24:42,300
the classifier and then test to see

581
00:24:42,300 --> 00:24:45,660
which class one sample belongs to and in

582
00:24:45,660 --> 00:24:48,750
related work they took executable

583
00:24:48,750 --> 00:24:51,330
binaries and then they disassembled them

584
00:24:51,330 --> 00:24:53,160
with reverse engineering methods and

585
00:24:53,160 --> 00:24:55,830
they obtained the control flow graphs as

586
00:24:55,830 --> 00:24:58,110
well so they extracted features from the

587
00:24:58,110 --> 00:25:00,210
assembly instructions and also the

588
00:25:00,210 --> 00:25:02,360
control flow graph they used some

589
00:25:02,360 --> 00:25:05,250
information gain methods to find the

590
00:25:05,250 --> 00:25:07,170
most prevalent stylistic features and

591
00:25:07,170 --> 00:25:09,270
then they use the support vector machine

592
00:25:09,270 --> 00:25:11,850
and I would like to remind you that we

593
00:25:11,850 --> 00:25:14,010
don't use support vector machines that

594
00:25:14,010 --> 00:25:16,220
much for multi-class classification

595
00:25:16,220 --> 00:25:18,690
problems that's why we use random force

596
00:25:18,690 --> 00:25:20,580
and then they Deanna Myers programmer

597
00:25:20,580 --> 00:25:23,220
and what we do is we take our dataset

598
00:25:23,220 --> 00:25:25,020
and we use the same data set with them

599
00:25:25,020 --> 00:25:27,630
so that we can make a real comparison we

600
00:25:27,630 --> 00:25:29,430
disassemble it with reverse engineering

601
00:25:29,430 --> 00:25:32,490
we also D compile it and the D

602
00:25:32,490 --> 00:25:35,490
compilation we can get the source code

603
00:25:35,490 --> 00:25:38,430
representation of the binary and again

604
00:25:38,430 --> 00:25:40,860
we can apply all the source code feature

605
00:25:40,860 --> 00:25:43,470
extraction methods such as the abstract

606
00:25:43,470 --> 00:25:46,350
syntax regeneration to this we also get

607
00:25:46,350 --> 00:25:48,510
the control flow graphs and then we run

608
00:25:48,510 --> 00:25:51,390
information gain on these to see what

609
00:25:51,390 --> 00:25:54,900
feature belongs to an author instead of

610
00:25:54,900 --> 00:25:57,150
just being a random property of the code

611
00:25:57,150 --> 00:25:59,520
and then we do a classification to D D

612
00:25:59,520 --> 00:26:02,090
on on to D anonymize the programmer and

613
00:26:02,090 --> 00:26:05,040
some features for these would be for

614
00:26:05,040 --> 00:26:07,110
example we have our common ASD features

615
00:26:07,110 --> 00:26:08,940
coming from the abstract syntax tree

616
00:26:08,940 --> 00:26:11,940
that's obtained from generating the

617
00:26:11,940 --> 00:26:14,610
structural properties and these are

618
00:26:14,610 --> 00:26:17,100
things like just node unigram in the

619
00:26:17,100 --> 00:26:19,560
abstract syntax tree AST by grams or

620
00:26:19,560 --> 00:26:21,420
edges and

621
00:26:21,420 --> 00:26:22,920
we do similar things for the control

622
00:26:22,920 --> 00:26:25,170
flow graphs and we get the unigram spy

623
00:26:25,170 --> 00:26:27,180
grams but remember that like since this

624
00:26:27,180 --> 00:26:29,670
is decompiled code the abstract syntax

625
00:26:29,670 --> 00:26:31,860
tree and control flow graph is like 10

626
00:26:31,860 --> 00:26:34,440
20 times stronger than the original one

627
00:26:34,440 --> 00:26:36,240
so we get a lot of features and they

628
00:26:36,240 --> 00:26:38,220
look very similar to each other because

629
00:26:38,220 --> 00:26:40,140
they have been reverse-engineered with

630
00:26:40,140 --> 00:26:44,190
the same tools and for example when we

631
00:26:44,190 --> 00:26:46,740
have 100 programmers we extract their

632
00:26:46,740 --> 00:26:49,980
features from their 900 binary

633
00:26:49,980 --> 00:26:52,550
executable samples and we get about

634
00:26:52,550 --> 00:26:56,640
200,000 features once we get all of our

635
00:26:56,640 --> 00:26:59,070
features once we run information gain on

636
00:26:59,070 --> 00:27:02,520
this we see that only 426 of them in

637
00:27:02,520 --> 00:27:04,950
this particular data set represent

638
00:27:04,950 --> 00:27:08,550
coding style so we focus on these 426

639
00:27:08,550 --> 00:27:12,000
features and what happens when we try to

640
00:27:12,000 --> 00:27:15,210
do anonymize 100 programmers so we

641
00:27:15,210 --> 00:27:16,890
wanted to see how much training data we

642
00:27:16,890 --> 00:27:18,570
need first of all like how many binary

643
00:27:18,570 --> 00:27:21,240
samples do I need to accurately D

644
00:27:21,240 --> 00:27:24,480
anonymize a programmer and with one

645
00:27:24,480 --> 00:27:27,870
binary sample and 100 programmers you

646
00:27:27,870 --> 00:27:30,600
can still identify them with 20%

647
00:27:30,600 --> 00:27:34,350
accuracy and once we use 8 training

648
00:27:34,350 --> 00:27:37,140
samples we got 78 percent accuracy

649
00:27:37,140 --> 00:27:40,440
Indian atomizing 100 programmers and it

650
00:27:40,440 --> 00:27:43,260
seems like if we had more source more

651
00:27:43,260 --> 00:27:45,420
binary samples you would be able to

652
00:27:45,420 --> 00:27:47,430
increase our our accuracy further but

653
00:27:47,430 --> 00:27:50,580
our data set wasn't really letting us do

654
00:27:50,580 --> 00:27:54,750
this with 100 programmers and relax

655
00:27:54,750 --> 00:27:57,870
classification which I mentioned towards

656
00:27:57,870 --> 00:28:00,270
the end of the first part with 100

657
00:28:00,270 --> 00:28:02,720
programmers when we relaxed the

658
00:28:02,720 --> 00:28:07,260
classification to a set of size 10 we

659
00:28:07,260 --> 00:28:10,620
get 95% accuracy in reducing our

660
00:28:10,620 --> 00:28:13,110
suspects outside so let's say that you

661
00:28:13,110 --> 00:28:15,330
start with 100 programmers and their

662
00:28:15,330 --> 00:28:17,520
binaries and you want to focus on 10 of

663
00:28:17,520 --> 00:28:20,970
them but 95% accuracy you're the correct

664
00:28:20,970 --> 00:28:24,300
programmer would be within that set of

665
00:28:24,300 --> 00:28:28,020
10 people and you also wanted to see

666
00:28:28,020 --> 00:28:29,640
what happens with a smaller data set

667
00:28:29,640 --> 00:28:32,790
size so here when we just

668
00:28:32,790 --> 00:28:35,580
with unrelaxed classification we can get

669
00:28:35,580 --> 00:28:39,000
close to 100% accuracy after like just

670
00:28:39,000 --> 00:28:41,550
relaxing it to a suspects at size of

671
00:28:41,550 --> 00:28:44,790
four and we are getting certainly 100%

672
00:28:44,790 --> 00:28:46,680
accuracy at the suspects at size eight

673
00:28:46,680 --> 00:28:51,450
and we also wanted to see what happens

674
00:28:51,450 --> 00:28:53,970
when we just use one training sample for

675
00:28:53,970 --> 00:28:55,620
twenty programmers so with twenty

676
00:28:55,620 --> 00:28:57,750
programmers if you just have one sample

677
00:28:57,750 --> 00:28:59,910
from twenty programmers you train on

678
00:28:59,910 --> 00:29:03,030
twenty files to generate twenty classes

679
00:29:03,030 --> 00:29:05,760
and then once samples are given to you

680
00:29:05,760 --> 00:29:08,280
you can correctly identify those samples

681
00:29:08,280 --> 00:29:10,650
with 75% accuracy and that's kind of

682
00:29:10,650 --> 00:29:11,250
scary

683
00:29:11,250 --> 00:29:13,500
so if you have just one binary out there

684
00:29:13,500 --> 00:29:15,330
that belongs to you and that's known and

685
00:29:15,330 --> 00:29:17,850
if you are in a suspect set size of

686
00:29:17,850 --> 00:29:21,920
twenty there is a 75% chance that your

687
00:29:21,920 --> 00:29:24,750
anonymous binary would be identified as

688
00:29:24,750 --> 00:29:27,240
it belongs to you and you wanted to

689
00:29:27,240 --> 00:29:30,060
scale this up so we went from 100

690
00:29:30,060 --> 00:29:33,090
programmers to 600 programmers and in

691
00:29:33,090 --> 00:29:35,340
this case we see that the accuracy is

692
00:29:35,340 --> 00:29:38,190
gradually decreasing and with 600

693
00:29:38,190 --> 00:29:41,190
programmers we get 52 percent accuracy

694
00:29:41,190 --> 00:29:43,440
and here I would like to mention that

695
00:29:43,440 --> 00:29:45,510
for example in the previous part we had

696
00:29:45,510 --> 00:29:48,270
1000 and 600 programmers but since we

697
00:29:48,270 --> 00:29:50,430
are using the same data set we had to

698
00:29:50,430 --> 00:29:54,240
compile the source code so that we can

699
00:29:54,240 --> 00:29:56,400
use it in a controlled setting with the

700
00:29:56,400 --> 00:30:01,440
same compilation options and we couldn't

701
00:30:01,440 --> 00:30:03,180
obtain one thousand and six hundred

702
00:30:03,180 --> 00:30:05,490
binaries after that compilation some

703
00:30:05,490 --> 00:30:07,980
code just didn't compile and like some

704
00:30:07,980 --> 00:30:10,530
programmers didn't have enough code

705
00:30:10,530 --> 00:30:12,240
because they were missing so we had to

706
00:30:12,240 --> 00:30:15,920
get rid of all of those programmers

707
00:30:23,290 --> 00:30:26,210
so there hasn't been much work done on

708
00:30:26,210 --> 00:30:28,850
this area there is one major paper that

709
00:30:28,850 --> 00:30:30,590
has been published by Rose emblem and

710
00:30:30,590 --> 00:30:32,660
it's a great paper it's the previous

711
00:30:32,660 --> 00:30:34,010
workflow that I have shown you in

712
00:30:34,010 --> 00:30:37,220
beginning of the second section and for

713
00:30:37,220 --> 00:30:40,340
example with 20 programmers they get 77

714
00:30:40,340 --> 00:30:42,410
percent accuracy and they use more

715
00:30:42,410 --> 00:30:44,540
training samples than us it's not very

716
00:30:44,540 --> 00:30:46,550
clear but the least number of training

717
00:30:46,550 --> 00:30:48,470
samples they use is 8 and it goes up to

718
00:30:48,470 --> 00:30:51,110
16 and we kind of know that when we use

719
00:30:51,110 --> 00:30:53,000
more samples we are going to get higher

720
00:30:53,000 --> 00:30:56,300
accuracy but in our case we with 100

721
00:30:56,300 --> 00:31:01,940
programmers we get 78% accuracy and for

722
00:31:01,940 --> 00:31:05,680
example when we look at their 100

723
00:31:05,680 --> 00:31:08,000
programmer data set we see that they get

724
00:31:08,000 --> 00:31:12,020
61% accuracy and we can get 78% accuracy

725
00:31:12,020 --> 00:31:14,810
and again they are using more training

726
00:31:14,810 --> 00:31:17,960
samples and at the end we are able to

727
00:31:17,960 --> 00:31:20,330
scale our approach to 600 programmers

728
00:31:20,330 --> 00:31:23,030
but their largest data set is almost 200

729
00:31:23,030 --> 00:31:25,520
programmers and their 200 programmer

730
00:31:25,520 --> 00:31:27,860
data set gets the same accuracy with our

731
00:31:27,860 --> 00:31:30,320
600 programmer data set which was a more

732
00:31:30,320 --> 00:31:32,150
difficult machine learning problem so

733
00:31:32,150 --> 00:31:35,620
this is a great improvement in accuracy

734
00:31:35,620 --> 00:31:38,600
what happens if we optimize code so is

735
00:31:38,600 --> 00:31:40,670
that kind of like the translation of

736
00:31:40,670 --> 00:31:43,340
obfuscation in binaries like are they

737
00:31:43,340 --> 00:31:46,760
going to anonymize code so for that for

738
00:31:46,760 --> 00:31:50,900
the first time in in the literature we

739
00:31:50,900 --> 00:31:53,090
wanted to try compiler optimization and

740
00:31:53,090 --> 00:31:54,950
stripping the symbols and we saw that

741
00:31:54,950 --> 00:31:56,810
with 100 programmers without any

742
00:31:56,810 --> 00:31:59,780
optimizations simply compiling code we

743
00:31:59,780 --> 00:32:01,700
can do anonymize 100 programmers with

744
00:32:01,700 --> 00:32:05,480
78% accuracy but after compilation once

745
00:32:05,480 --> 00:32:08,870
we stripped symbols from the winery's we

746
00:32:08,870 --> 00:32:11,600
get 66 percent accuracy and once we

747
00:32:11,600 --> 00:32:14,000
start applying more optimizations like

748
00:32:14,000 --> 00:32:16,220
the common level one optimization level

749
00:32:16,220 --> 00:32:18,260
to optimization which like which is

750
00:32:18,260 --> 00:32:20,510
cumulative it takes the previous optimal

751
00:32:20,510 --> 00:32:24,340
optimizations in it as well and it makes

752
00:32:24,340 --> 00:32:28,010
program more efficient and maybe faster

753
00:32:28,010 --> 00:32:30,290
and smaller

754
00:32:30,290 --> 00:32:32,710
see that the accuracy is not decreasing

755
00:32:32,710 --> 00:32:36,320
in a tragic way with the highest level

756
00:32:36,320 --> 00:32:38,570
of optimizations that we tried level 3

757
00:32:38,570 --> 00:32:41,570
we get 60% accuracy incorrectly the

758
00:32:41,570 --> 00:32:43,990
anonymizing these 100 programmers so

759
00:32:43,990 --> 00:32:46,010
compiler optimization is that our

760
00:32:46,010 --> 00:32:51,800
solution to anonymizing binaries we also

761
00:32:51,800 --> 00:32:53,960
wanted to see how we can find out

762
00:32:53,960 --> 00:32:56,360
features that are remaining in binaries

763
00:32:56,360 --> 00:32:58,550
that represent your coding style because

764
00:32:58,550 --> 00:33:01,160
since binaries are so cryptic it's

765
00:33:01,160 --> 00:33:03,620
difficult to tell what's going on what

766
00:33:03,620 --> 00:33:05,570
kind of transformations are happening

767
00:33:05,570 --> 00:33:09,470
after compilation so for this we came up

768
00:33:09,470 --> 00:33:12,620
with a machine learning setting where we

769
00:33:12,620 --> 00:33:16,330
have the same code samples and we have

770
00:33:16,330 --> 00:33:19,190
numeric representations of these code

771
00:33:19,190 --> 00:33:21,530
samples for the original code and the

772
00:33:21,530 --> 00:33:23,840
compiled code and what we tried to do

773
00:33:23,840 --> 00:33:27,980
was by taking the the compiled code can

774
00:33:27,980 --> 00:33:30,740
we predict the features in the original

775
00:33:30,740 --> 00:33:33,320
code that has not been compiled at all

776
00:33:33,320 --> 00:33:37,520
and once we did that we generated the

777
00:33:37,520 --> 00:33:40,340
predictions for the new features in the

778
00:33:40,340 --> 00:33:43,490
original code and we wanted to see how

779
00:33:43,490 --> 00:33:45,200
similar this is and there is not a very

780
00:33:45,200 --> 00:33:47,330
simple way to make a direct comparison

781
00:33:47,330 --> 00:33:50,420
between between these predictions so we

782
00:33:50,420 --> 00:33:52,340
looked at cosine distance similarity and

783
00:33:52,340 --> 00:33:56,270
we saw that the new predictions were 8%

784
00:33:56,270 --> 00:33:59,600
81% similar to the original code

785
00:33:59,600 --> 00:34:03,470
features we chose that and also we did

786
00:34:03,470 --> 00:34:05,180
one more experiment so we just took the

787
00:34:05,180 --> 00:34:07,460
original code features and we took the

788
00:34:07,460 --> 00:34:09,469
the compiled code features and we looked

789
00:34:09,469 --> 00:34:12,790
at the similarity between those two and

790
00:34:12,790 --> 00:34:16,940
the cosine distance was 0.35 so it was

791
00:34:16,940 --> 00:34:19,850
about 35% similarity with which is much

792
00:34:19,850 --> 00:34:22,310
less and this is kind of showing that

793
00:34:22,310 --> 00:34:24,469
like coding style and properties in

794
00:34:24,469 --> 00:34:27,020
compiled code are certainly getting

795
00:34:27,020 --> 00:34:29,810
transformed but this transformation is

796
00:34:29,810 --> 00:34:32,179
not wiping away all coding style

797
00:34:32,179 --> 00:34:34,489
features so somehow they still remain

798
00:34:34,489 --> 00:34:37,550
embedded in the binary and this might be

799
00:34:37,550 --> 00:34:40,130
a concern for the anonymization and

800
00:34:40,130 --> 00:34:43,280
remaining anonymous we also wanted to

801
00:34:43,280 --> 00:34:43,889
see

802
00:34:43,889 --> 00:34:47,129
if we can gain any insights and again we

803
00:34:47,129 --> 00:34:50,518
looked at the differences between the

804
00:34:50,518 --> 00:34:52,829
binaries of more advanced programmers

805
00:34:52,829 --> 00:34:56,099
that were able to advance to more

806
00:34:56,099 --> 00:34:58,769
difficult rounds and we saw that even in

807
00:34:58,769 --> 00:35:00,539
the binaries you can see when a

808
00:35:00,539 --> 00:35:03,720
programmer is more advanced as opposed

809
00:35:03,720 --> 00:35:06,269
to other programmers with a smaller

810
00:35:06,269 --> 00:35:09,539
skill set and for doing this in the data

811
00:35:09,539 --> 00:35:13,049
set and we generated two subsets the

812
00:35:13,049 --> 00:35:15,029
first one was with people that were only

813
00:35:15,029 --> 00:35:18,509
able to compete complete the same seven

814
00:35:18,509 --> 00:35:21,180
problems and the second one was people

815
00:35:21,180 --> 00:35:23,430
who were able to complete 14 problems

816
00:35:23,430 --> 00:35:26,220
including the 7 in the first subset and

817
00:35:26,220 --> 00:35:29,819
we just used the 7 samples that were

818
00:35:29,819 --> 00:35:33,210
same between these subsets and see how

819
00:35:33,210 --> 00:35:34,859
well we can do anonymize these

820
00:35:34,859 --> 00:35:37,410
programmers and for the more advanced

821
00:35:37,410 --> 00:35:39,720
programmers we got 88 percent accuracy

822
00:35:39,720 --> 00:35:42,720
incorrectly anonymizing their binary

823
00:35:42,720 --> 00:35:46,200
this is a 20 programmer dataset and for

824
00:35:46,200 --> 00:35:48,509
the less advanced programmers we got 80%

825
00:35:48,509 --> 00:35:51,809
accuracy so somehow there is more coding

826
00:35:51,809 --> 00:35:55,710
style present in the source code of the

827
00:35:55,710 --> 00:35:58,019
more advanced programmers and it's

828
00:35:58,019 --> 00:36:00,539
getting transformed better after being

829
00:36:00,539 --> 00:36:03,420
compiled and to validate this we tried

830
00:36:03,420 --> 00:36:05,789
the same setting with the 6 problem

831
00:36:05,789 --> 00:36:08,180
setting a subset that was only able to

832
00:36:08,180 --> 00:36:10,650
complete 6 problems and a subset that

833
00:36:10,650 --> 00:36:12,900
was only able to complete that was able

834
00:36:12,900 --> 00:36:15,150
to complete 12 problems including the

835
00:36:15,150 --> 00:36:17,999
six in the first subset and again we see

836
00:36:17,999 --> 00:36:20,309
the same result so the accuracy is lower

837
00:36:20,309 --> 00:36:24,359
because our training samples are less so

838
00:36:24,359 --> 00:36:26,700
our machine learning model might be less

839
00:36:26,700 --> 00:36:28,859
accurate and as opposed to using more

840
00:36:28,859 --> 00:36:31,289
samples so we can eat 7 percent accuracy

841
00:36:31,289 --> 00:36:33,329
incorrectly identifying those whereas we

842
00:36:33,329 --> 00:36:35,670
get 78 percent accuracy in the

843
00:36:35,670 --> 00:36:37,109
anonymizing the less advanced

844
00:36:37,109 --> 00:36:41,640
programmers so we have been working on

845
00:36:41,640 --> 00:36:43,289
Google Code Jam which is a very

846
00:36:43,289 --> 00:36:45,690
controlled environment for running these

847
00:36:45,690 --> 00:36:48,180
experiments for the reasons I explained

848
00:36:48,180 --> 00:36:50,999
to you and we get the question from many

849
00:36:50,999 --> 00:36:53,759
people asking that is it is this the

850
00:36:53,759 --> 00:36:54,700
anonymous age

851
00:36:54,700 --> 00:36:57,580
being so successful because of your

852
00:36:57,580 --> 00:37:00,880
Google Code Jam dataset and we wanted to

853
00:37:00,880 --> 00:37:02,740
see what would be the difference if we

854
00:37:02,740 --> 00:37:05,500
try to do the anonymization in the wild

855
00:37:05,500 --> 00:37:08,380
and we try to collect the data set from

856
00:37:08,380 --> 00:37:12,490
github so for this we price github and

857
00:37:12,490 --> 00:37:14,860
we found single authored repositories

858
00:37:14,860 --> 00:37:18,370
and these repositories had at least 500

859
00:37:18,370 --> 00:37:21,040
lines of code and they had to have like

860
00:37:21,040 --> 00:37:23,830
at least ten stars and these people

861
00:37:23,830 --> 00:37:26,380
should have several number of

862
00:37:26,380 --> 00:37:28,540
repositories on github so he had some

863
00:37:28,540 --> 00:37:30,910
requirements and after that we ended up

864
00:37:30,910 --> 00:37:33,370
with 49 programmers after all of our

865
00:37:33,370 --> 00:37:35,410
restrictions you can refer to our paper

866
00:37:35,410 --> 00:37:38,590
for the details of these datasets and we

867
00:37:38,590 --> 00:37:41,980
had 117 repositories but unfortunately

868
00:37:41,980 --> 00:37:44,050
again github code is sometimes very

869
00:37:44,050 --> 00:37:46,690
difficult to compile so after compiling

870
00:37:46,690 --> 00:37:50,230
these we ended up with 12 authors and 50

871
00:37:50,230 --> 00:37:56,920
binaries and on this data set we are

872
00:37:56,920 --> 00:37:58,570
able to do none wise the programmers

873
00:37:58,570 --> 00:38:01,480
with 62% accuracy and we try to generate

874
00:38:01,480 --> 00:38:04,180
the exact same data set from Google Code

875
00:38:04,180 --> 00:38:05,800
Jam use the exact same number of

876
00:38:05,800 --> 00:38:08,350
binaries for each programmer and we were

877
00:38:08,350 --> 00:38:11,140
getting 68 % accuracy so it shows that

878
00:38:11,140 --> 00:38:14,110
like this is a very promising result for

879
00:38:14,110 --> 00:38:16,180
running programmer the anonymization in

880
00:38:16,180 --> 00:38:20,980
the wild and for future work again we

881
00:38:20,980 --> 00:38:22,630
would like to look at anonymizing

882
00:38:22,630 --> 00:38:24,670
executable binaries because here we are

883
00:38:24,670 --> 00:38:26,650
showing your problem like there's a

884
00:38:26,650 --> 00:38:28,960
privacy problem here we are able to do

885
00:38:28,960 --> 00:38:30,580
an analyze program which with very high

886
00:38:30,580 --> 00:38:33,760
accuracies in a very simple machine

887
00:38:33,760 --> 00:38:36,400
learning setting and we can do this on

888
00:38:36,400 --> 00:38:38,860
the light scale and for the executable

889
00:38:38,860 --> 00:38:41,290
binaries we show that optimizations are

890
00:38:41,290 --> 00:38:44,760
not the result the solution to

891
00:38:44,760 --> 00:38:47,500
anonymization and we would also like to

892
00:38:47,500 --> 00:38:49,750
look at yan anonymizing collaborative

893
00:38:49,750 --> 00:38:51,820
binaries that have been written by

894
00:38:51,820 --> 00:38:54,730
multiple people and we would really like

895
00:38:54,730 --> 00:38:56,470
to find out if we can extend this to

896
00:38:56,470 --> 00:38:59,890
malware family classification but for

897
00:38:59,890 --> 00:39:02,950
that problem we need a dataset with some

898
00:39:02,950 --> 00:39:05,410
ground truth so if anyone in the

899
00:39:05,410 --> 00:39:06,570
audience is intro

900
00:39:06,570 --> 00:39:08,910
setting that and has some ground truth

901
00:39:08,910 --> 00:39:11,610
data a data set that we can work with at

902
00:39:11,610 --> 00:39:13,470
the end of the talk please come and talk

903
00:39:13,470 --> 00:39:18,030
to me that might be amazing for us and

904
00:39:18,030 --> 00:39:19,680
we have some available tools on these

905
00:39:19,680 --> 00:39:21,570
projects so you can find all of them

906
00:39:21,570 --> 00:39:23,550
online you can send us emails like if

907
00:39:23,550 --> 00:39:24,990
you want to run things on different

908
00:39:24,990 --> 00:39:27,270
settings we have announced these in our

909
00:39:27,270 --> 00:39:29,640
previous talks as well so we start with

910
00:39:29,640 --> 00:39:33,390
the main one program so the source

911
00:39:33,390 --> 00:39:35,520
called program idea animation one is on

912
00:39:35,520 --> 00:39:37,800
my github account so you can just like

913
00:39:37,800 --> 00:39:39,540
google for it and like find it and run

914
00:39:39,540 --> 00:39:43,770
it and we also have a authorship

915
00:39:43,770 --> 00:39:47,430
attribution framework where you can have

916
00:39:47,430 --> 00:39:50,370
some authors with known documents

917
00:39:50,370 --> 00:39:52,770
documents with known authors and then

918
00:39:52,770 --> 00:39:57,600
you might try to identify an anon and it

919
00:39:57,600 --> 00:39:59,310
will give you many machine learning

920
00:39:59,310 --> 00:40:01,680
options to do that and different ways to

921
00:40:01,680 --> 00:40:04,080
generate different features and so on so

922
00:40:04,080 --> 00:40:07,050
that you get a hands-on experience and

923
00:40:07,050 --> 00:40:09,000
like running this machine learning

924
00:40:09,000 --> 00:40:11,580
setting and see how anonymization works

925
00:40:11,580 --> 00:40:14,100
and on top of Jay styler we have an

926
00:40:14,100 --> 00:40:16,530
animal that's built so another mod uses

927
00:40:16,530 --> 00:40:18,540
Jay styler is the back engine and it's a

928
00:40:18,540 --> 00:40:20,100
framework that will help you

929
00:40:20,100 --> 00:40:23,460
Anana Mize your writing style so once

930
00:40:23,460 --> 00:40:26,100
you give it a suspect set and you are

931
00:40:26,100 --> 00:40:28,080
also in the suspect set and you want to

932
00:40:28,080 --> 00:40:30,090
make sure that in that suspect set your

933
00:40:30,090 --> 00:40:33,540
anonymized you can use an animal so that

934
00:40:33,540 --> 00:40:37,290
it will identify all the program all the

935
00:40:37,290 --> 00:40:40,350
altars in the suspect set and then it

936
00:40:40,350 --> 00:40:42,180
will give you certain recommendations

937
00:40:42,180 --> 00:40:44,520
and suggestions so that you can be make

938
00:40:44,520 --> 00:40:48,450
your writing more anonymous and this

939
00:40:48,450 --> 00:40:51,510
might be a very helpful tool for people

940
00:40:51,510 --> 00:40:53,940
for example in oppressed regimes or like

941
00:40:53,940 --> 00:40:56,130
who really want to make sure that they

942
00:40:56,130 --> 00:40:58,950
would like to write anonymously so that

943
00:40:58,950 --> 00:41:00,680
they don't want to get in trouble

944
00:41:00,680 --> 00:41:03,600
because even for example let's say that

945
00:41:03,600 --> 00:41:06,870
you are as with their like Alice and the

946
00:41:06,870 --> 00:41:09,930
abusive employer Bob example even if you

947
00:41:09,930 --> 00:41:13,080
are writing or blogging through tor and

948
00:41:13,080 --> 00:41:14,880
you think that your anonymous your

949
00:41:14,880 --> 00:41:16,290
writing style

950
00:41:16,290 --> 00:41:21,210
make you identifiable and I would like

951
00:41:21,210 --> 00:41:24,090
to thank all my collaborators for this

952
00:41:24,090 --> 00:41:25,950
great work without them it wouldn't have

953
00:41:25,950 --> 00:41:29,810
been possible and

954
00:41:38,300 --> 00:41:41,339
if you like I have some backup slides

955
00:41:41,339 --> 00:41:42,810
but if you think that you have a lot of

956
00:41:42,810 --> 00:41:47,190
questions we can just go to Q&A now and

957
00:41:47,190 --> 00:41:50,270
thanks for coming

958
00:41:57,619 --> 00:42:01,019
thank you very much we have about 20

959
00:42:01,019 --> 00:42:03,420
minutes for Q&A so there's plenty of

960
00:42:03,420 --> 00:42:05,490
room for questions the first two

961
00:42:05,490 --> 00:42:08,190
questions go to the Internet and the

962
00:42:08,190 --> 00:42:09,599
people who feel that I have to leave

963
00:42:09,599 --> 00:42:15,150
please do so quietly okay the first

964
00:42:15,150 --> 00:42:16,920
question is whether your technique also

965
00:42:16,920 --> 00:42:19,619
works on shell commands so that I can

966
00:42:19,619 --> 00:42:21,930
see who actually did something in my

967
00:42:21,930 --> 00:42:27,059
system also works on what can you speak

968
00:42:27,059 --> 00:42:29,339
a little louder I'm sorry it does it

969
00:42:29,339 --> 00:42:32,940
also work on shell commands so if you

970
00:42:32,940 --> 00:42:35,640
type or look at a session of someone

971
00:42:35,640 --> 00:42:37,950
locked in your computer to analyze with

972
00:42:37,950 --> 00:42:42,509
it so I'm not sure I understand the

973
00:42:42,509 --> 00:42:46,460
question are you asking about sections

974
00:42:46,460 --> 00:42:49,710
no if you have a unit a lot of unit

975
00:42:49,710 --> 00:42:51,839
command lines that you see that someone

976
00:42:51,839 --> 00:42:54,089
has entered somewhere can you also try

977
00:42:54,089 --> 00:42:56,369
to fight with your author of these

978
00:42:56,369 --> 00:43:00,420
command lines oh just just command lines

979
00:43:00,420 --> 00:43:03,480
so as long as you find the correct

980
00:43:03,480 --> 00:43:06,180
features for that I believe you can do

981
00:43:06,180 --> 00:43:06,359
it

982
00:43:06,359 --> 00:43:08,640
but this doesn't our research this

983
00:43:08,640 --> 00:43:11,400
current research does not exactly apply

984
00:43:11,400 --> 00:43:14,369
to that but since we can do this on

985
00:43:14,369 --> 00:43:18,749
various kinds of textual data and we

986
00:43:18,749 --> 00:43:20,460
have shown that like we can do it on

987
00:43:20,460 --> 00:43:22,680
like many other things that have other

988
00:43:22,680 --> 00:43:25,380
than mentioned in this presentation I

989
00:43:25,380 --> 00:43:27,509
believe it might it's it might be

990
00:43:27,509 --> 00:43:31,440
possible to do that okay next question

991
00:43:31,440 --> 00:43:34,999
from the internet do you also look at

992
00:43:34,999 --> 00:43:38,549
comments like style of writing comments

993
00:43:38,549 --> 00:43:42,390
or position of comments so for these

994
00:43:42,390 --> 00:43:44,730
data sets to make sure that there was no

995
00:43:44,730 --> 00:43:46,950
personally identifiable or identifiable

996
00:43:46,950 --> 00:43:49,859
information left that would just bias

997
00:43:49,859 --> 00:43:52,380
the classifier we removed the comment so

998
00:43:52,380 --> 00:43:55,019
we don't have comments in this but we

999
00:43:55,019 --> 00:43:56,880
also looked at it with comments and it

1000
00:43:56,880 --> 00:43:58,440
usually makes it just like the

1001
00:43:58,440 --> 00:44:01,849
anonymization accuracy just increases

1002
00:44:01,849 --> 00:44:05,070
before moving to questions from the room

1003
00:44:05,070 --> 00:44:07,290
please do remember that questions are

1004
00:44:07,290 --> 00:44:09,030
short short sentences and then you have

1005
00:44:09,030 --> 00:44:09,690
a question mark

1006
00:44:09,690 --> 00:44:13,290
first question over here hi what do you

1007
00:44:13,290 --> 00:44:15,480
think the chances are of having

1008
00:44:15,480 --> 00:44:17,370
something like a compiler switch to

1009
00:44:17,370 --> 00:44:19,710
automatically anonymize code by doing

1010
00:44:19,710 --> 00:44:22,230
structural refactoring switch then like

1011
00:44:22,230 --> 00:44:25,860
your mouth thing that you that's a very

1012
00:44:25,860 --> 00:44:27,810
good point and exactly it's kind of a

1013
00:44:27,810 --> 00:44:29,100
similar thing to do with inanimate

1014
00:44:29,100 --> 00:44:31,560
because you're just trying to like

1015
00:44:31,560 --> 00:44:34,080
convert the features that make you

1016
00:44:34,080 --> 00:44:36,960
anonymize able and that might be a good

1017
00:44:36,960 --> 00:44:39,090
experiment to try in the future so I

1018
00:44:39,090 --> 00:44:40,830
will keep that in mind when we are like

1019
00:44:40,830 --> 00:44:45,090
starting our anonymous ation work next

1020
00:44:45,090 --> 00:44:48,840
question over there yes thank you for

1021
00:44:48,840 --> 00:44:51,930
the talk in the beginning let's say I am

1022
00:44:51,930 --> 00:44:56,730
writing code for I'm in iran-iraq code

1023
00:44:56,730 --> 00:45:00,800
for a porn website and I want to

1024
00:45:00,800 --> 00:45:03,780
obviously completely anonymous Asian is

1025
00:45:03,780 --> 00:45:09,440
not possible anonymization can I produce

1026
00:45:09,440 --> 00:45:15,630
can I maximize my chances to to not be

1027
00:45:15,630 --> 00:45:21,360
identified and executed so first of all

1028
00:45:21,360 --> 00:45:23,160
with the site Malik for example he was

1029
00:45:23,160 --> 00:45:26,040
identified because his name was on the

1030
00:45:26,040 --> 00:45:27,830
column that was like a direct

1031
00:45:27,830 --> 00:45:31,380
identification but as you suggest if you

1032
00:45:31,380 --> 00:45:33,570
are very careful about being anonymous

1033
00:45:33,570 --> 00:45:36,360
maybe you can try to follow very strict

1034
00:45:36,360 --> 00:45:39,390
conventions and make sure that everyone

1035
00:45:39,390 --> 00:45:41,370
in that project is also following the

1036
00:45:41,370 --> 00:45:43,890
same conventions so that all of you look

1037
00:45:43,890 --> 00:45:46,020
very similar and you cannot be relied on

1038
00:45:46,020 --> 00:45:48,710
to fight you cannot be like

1039
00:45:48,710 --> 00:45:50,580
discriminated from each other in that

1040
00:45:50,580 --> 00:45:52,800
case so that might be one solution so

1041
00:45:52,800 --> 00:45:58,020
far or it might at least help you okay

1042
00:45:58,020 --> 00:46:00,450
next question over there my question is

1043
00:46:00,450 --> 00:46:03,960
I assume all those numbers that you had

1044
00:46:03,960 --> 00:46:07,590
where you had a set of people that you

1045
00:46:07,590 --> 00:46:09,300
programmed into the system and you were

1046
00:46:09,300 --> 00:46:11,190
giving them one sample of a person that

1047
00:46:11,190 --> 00:46:14,490
he knew was in that set have you ever

1048
00:46:14,490 --> 00:46:15,740
tried a giving

1049
00:46:15,740 --> 00:46:18,760
them a completely unrelated code sample

1050
00:46:18,760 --> 00:46:23,030
is the software able to tell that that's

1051
00:46:23,030 --> 00:46:25,460
someone else who is not part of the

1052
00:46:25,460 --> 00:46:27,710
reference set and if so at what

1053
00:46:27,710 --> 00:46:31,820
probability so you can look at the slide

1054
00:46:31,820 --> 00:46:33,170
and this is kind of a verification

1055
00:46:33,170 --> 00:46:36,770
problem in machine learning and this is

1056
00:46:36,770 --> 00:46:39,380
a one class two class kind of classifier

1057
00:46:39,380 --> 00:46:42,400
that might help you verify if the

1058
00:46:42,400 --> 00:46:46,100
anonymous code sample comes from someone

1059
00:46:46,100 --> 00:46:48,619
that is in your suspect set or like

1060
00:46:48,619 --> 00:46:52,310
that's in the set of programmers that

1061
00:46:52,310 --> 00:46:54,590
you trained the classifier on and for

1062
00:46:54,590 --> 00:46:57,200
this setting what we did was so we have

1063
00:46:57,200 --> 00:46:59,960
Mallory and Mallory claims that this

1064
00:46:59,960 --> 00:47:02,869
code has been written by her and we want

1065
00:47:02,869 --> 00:47:04,790
to find out if it was really written by

1066
00:47:04,790 --> 00:47:08,540
her so we have two classes the one only

1067
00:47:08,540 --> 00:47:11,060
samples from Mallory and the second one

1068
00:47:11,060 --> 00:47:13,369
has samples from random people which

1069
00:47:13,369 --> 00:47:17,119
represents the outside world it's anyone

1070
00:47:17,119 --> 00:47:19,970
but Mallory and in this case we can take

1071
00:47:19,970 --> 00:47:22,460
the code that Mallory is claiming to

1072
00:47:22,460 --> 00:47:25,340
have written and see if it was really

1073
00:47:25,340 --> 00:47:27,320
written by her like is it going to be

1074
00:47:27,320 --> 00:47:29,300
attributed to the outside world who is

1075
00:47:29,300 --> 00:47:31,040
not Mallory or is it going to be really

1076
00:47:31,040 --> 00:47:33,350
attributed to Mallory and for this case

1077
00:47:33,350 --> 00:47:36,859
we get 91% accuracy with a two

1078
00:47:36,859 --> 00:47:39,410
repetitions of such a setting and if you

1079
00:47:39,410 --> 00:47:40,910
want to find more details about the

1080
00:47:40,910 --> 00:47:42,920
probabilities of how we can like trash

1081
00:47:42,920 --> 00:47:45,619
hold the verification look at our first

1082
00:47:45,619 --> 00:47:48,230
paper we have the details of that or we

1083
00:47:48,230 --> 00:47:51,340
can chat later so but you haven't tried

1084
00:47:51,340 --> 00:47:54,440
when you don't know who it could have

1085
00:47:54,440 --> 00:47:56,600
been if you say okay we have like a

1086
00:47:56,600 --> 00:47:58,820
suspect list of 50 people you haven't

1087
00:47:58,820 --> 00:48:01,369
tried seeing if the if it would be

1088
00:48:01,369 --> 00:48:03,170
possible to determine that it's not one

1089
00:48:03,170 --> 00:48:05,770
of those people so with verification

1090
00:48:05,770 --> 00:48:09,200
like Venu so instead of this to class

1091
00:48:09,200 --> 00:48:11,060
setting let's think about the 50 class

1092
00:48:11,060 --> 00:48:14,030
setting with 50 programmers if a sample

1093
00:48:14,030 --> 00:48:16,670
is being attributed to one programmer

1094
00:48:16,670 --> 00:48:19,630
above as below a certain probability

1095
00:48:19,630 --> 00:48:21,950
then you might be able to say that this

1096
00:48:21,950 --> 00:48:23,359
looks like this person but this is

1097
00:48:23,359 --> 00:48:25,369
sketchy maybe this is not this person

1098
00:48:25,369 --> 00:48:26,330
because this is

1099
00:48:26,330 --> 00:48:29,960
not very confident classification does

1100
00:48:29,960 --> 00:48:32,780
that answer oh I think I'll just talk to

1101
00:48:32,780 --> 00:48:35,180
you in person okay the next question

1102
00:48:35,180 --> 00:48:37,100
over here

1103
00:48:37,100 --> 00:48:39,080
what about coding style guides most

1104
00:48:39,080 --> 00:48:40,790
languages have a developed coding style

1105
00:48:40,790 --> 00:48:42,260
guides and you have coding for mattes

1106
00:48:42,260 --> 00:48:44,180
you can run automatically would that

1107
00:48:44,180 --> 00:48:44,680
help

1108
00:48:44,680 --> 00:48:47,480
so yeah that's I think the previous

1109
00:48:47,480 --> 00:48:48,950
question was similar to that if you

1110
00:48:48,950 --> 00:48:50,870
follow strict conventions and if you

1111
00:48:50,870 --> 00:48:53,000
everyone does that that would normalize

1112
00:48:53,000 --> 00:48:55,100
that should normalize your writing style

1113
00:48:55,100 --> 00:48:58,760
to some degree or coding style and but

1114
00:48:58,760 --> 00:49:01,490
we saw with the compilation case that

1115
00:49:01,490 --> 00:49:03,110
compilation is also kind of a

1116
00:49:03,110 --> 00:49:05,060
normalization over your coding style

1117
00:49:05,060 --> 00:49:07,850
because it's converting everything to a

1118
00:49:07,850 --> 00:49:10,550
set set of rules and it becomes very

1119
00:49:10,550 --> 00:49:12,320
similar and even in that case we are

1120
00:49:12,320 --> 00:49:14,570
able to do anonymize programs but with

1121
00:49:14,570 --> 00:49:17,660
lower accuracy so that might help you be

1122
00:49:17,660 --> 00:49:21,050
more anonymous but I'm not sure if it

1123
00:49:21,050 --> 00:49:22,820
would be the exact solution but no

1124
00:49:22,820 --> 00:49:26,360
numbers how much it would change so the

1125
00:49:26,360 --> 00:49:29,150
problem with that experimental setting

1126
00:49:29,150 --> 00:49:31,190
was that we don't have such a data set

1127
00:49:31,190 --> 00:49:33,140
to test this song but like if someone

1128
00:49:33,140 --> 00:49:34,730
from the industry has a data set with

1129
00:49:34,730 --> 00:49:36,320
like where programmers are following

1130
00:49:36,320 --> 00:49:38,420
like straight combinations and so we

1131
00:49:38,420 --> 00:49:40,400
should be able to get more answers to

1132
00:49:40,400 --> 00:49:43,670
this question I think the Internet may

1133
00:49:43,670 --> 00:49:46,700
have a few more questions yes can you

1134
00:49:46,700 --> 00:49:48,620
use your technique to actually force

1135
00:49:48,620 --> 00:49:50,540
code to look like it was written by the

1136
00:49:50,540 --> 00:49:53,290
program

1137
00:49:55,090 --> 00:49:58,730
so yes this is possible with machine

1138
00:49:58,730 --> 00:50:00,470
learning because like for example with

1139
00:50:00,470 --> 00:50:02,660
Donna inanimate case that's where you

1140
00:50:02,660 --> 00:50:04,970
anonymize your writing style not coding

1141
00:50:04,970 --> 00:50:07,880
style what we do is like your written a

1142
00:50:07,880 --> 00:50:10,010
suspect set and you try to do anonymize

1143
00:50:10,010 --> 00:50:12,200
yourself in that suspect set and what

1144
00:50:12,200 --> 00:50:15,290
you do is try to like bring in features

1145
00:50:15,290 --> 00:50:17,750
that do not represent your style but if

1146
00:50:17,750 --> 00:50:19,490
you bring in features that belong to

1147
00:50:19,490 --> 00:50:20,360
someone else

1148
00:50:20,360 --> 00:50:22,070
exactly and you can see what those

1149
00:50:22,070 --> 00:50:24,140
features are then your style would be

1150
00:50:24,140 --> 00:50:26,690
more similar to that person so once you

1151
00:50:26,690 --> 00:50:30,440
have this framework for source code that

1152
00:50:30,440 --> 00:50:33,440
should be possible next question over

1153
00:50:33,440 --> 00:50:36,260
here hey you said there's a difference

1154
00:50:36,260 --> 00:50:38,210
between advanced and less advanced

1155
00:50:38,210 --> 00:50:40,580
programmers so my question is when you

1156
00:50:40,580 --> 00:50:42,590
have a given set of binaries can you

1157
00:50:42,590 --> 00:50:44,330
tell which ones were written by advanced

1158
00:50:44,330 --> 00:50:47,600
programmers that's a very good question

1159
00:50:47,600 --> 00:50:49,490
we haven't tried that but I think you

1160
00:50:49,490 --> 00:50:51,230
can come up with an experimental setting

1161
00:50:51,230 --> 00:50:54,170
to test that and we haven't done that

1162
00:50:54,170 --> 00:50:59,470
yet okay thank you hi two questions

1163
00:50:59,470 --> 00:51:02,180
first question have you considered using

1164
00:51:02,180 --> 00:51:05,930
scape grams where and like skip Engram

1165
00:51:05,930 --> 00:51:08,330
super n is greater than T then you get

1166
00:51:08,330 --> 00:51:11,030
more support second question how about

1167
00:51:11,030 --> 00:51:14,480
unsupervised learning yes I'll answer

1168
00:51:14,480 --> 00:51:16,840
both of them for the skip gram or like

1169
00:51:16,840 --> 00:51:20,150
multi and Gramps you can do that we

1170
00:51:20,150 --> 00:51:22,910
tried it it just takes a very long time

1171
00:51:22,910 --> 00:51:25,670
to extract those features and then to

1172
00:51:25,670 --> 00:51:28,760
run a classifier like that and we saw

1173
00:51:28,760 --> 00:51:30,800
that when you get more engrams or skip

1174
00:51:30,800 --> 00:51:33,680
grams or like a variety of powerful

1175
00:51:33,680 --> 00:51:35,660
features it doesn't really help

1176
00:51:35,660 --> 00:51:37,490
especially the source code authorship

1177
00:51:37,490 --> 00:51:39,260
attribution accuracy much because it's

1178
00:51:39,260 --> 00:51:41,540
already so high we also would like to

1179
00:51:41,540 --> 00:51:44,320
avoid overfitting to the data set by

1180
00:51:44,320 --> 00:51:47,510
generating very detailed features that

1181
00:51:47,510 --> 00:51:51,080
might bias the classifier at the same

1182
00:51:51,080 --> 00:51:52,960
time we are lucky that we have

1183
00:51:52,960 --> 00:51:55,599
Amazon research grant where we can run

1184
00:51:55,599 --> 00:51:58,359
our experiments on ec2 so it's making

1185
00:51:58,359 --> 00:52:01,359
things much faster but other than that I

1186
00:52:01,359 --> 00:52:04,869
wouldn't always want to extract like

1187
00:52:04,869 --> 00:52:07,240
thousands and maybe millions of features

1188
00:52:07,240 --> 00:52:09,700
if you're gonna go into such details and

1189
00:52:09,700 --> 00:52:12,460
for the second question yes you can do

1190
00:52:12,460 --> 00:52:14,470
unsupervised learning you can just try

1191
00:52:14,470 --> 00:52:17,109
to cluster these based on certain

1192
00:52:17,109 --> 00:52:20,829
properties found in code and these

1193
00:52:20,829 --> 00:52:22,869
properties could also be coding style

1194
00:52:22,869 --> 00:52:25,779
properties and that's possible but we

1195
00:52:25,779 --> 00:52:29,700
haven't gone through that setting Thanks

1196
00:52:29,700 --> 00:52:31,390
hello

1197
00:52:31,390 --> 00:52:34,990
so have you thought about researching

1198
00:52:34,990 --> 00:52:39,700
stuff using meta meta data of code to

1199
00:52:39,700 --> 00:52:42,309
actually classify it so like get come

1200
00:52:42,309 --> 00:52:45,730
get canids commit messages or workflow

1201
00:52:45,730 --> 00:52:48,309
or even set of youth libraries or

1202
00:52:48,309 --> 00:52:49,839
something like that and of course how to

1203
00:52:49,839 --> 00:52:56,829
protect from that so in the beginning I

1204
00:52:56,829 --> 00:52:59,710
started this project by using exactly a

1205
00:52:59,710 --> 00:53:01,630
data set like you describe it like all

1206
00:53:01,630 --> 00:53:03,579
the good comments messages and like it's

1207
00:53:03,579 --> 00:53:06,549
possible yes you can be anonymous those

1208
00:53:06,549 --> 00:53:09,489
programs and it probably makes it more

1209
00:53:09,489 --> 00:53:13,180
powerful but then with github it kind of

1210
00:53:13,180 --> 00:53:15,339
becomes a multi altered problem so it

1211
00:53:15,339 --> 00:53:17,109
relates to our future part where we

1212
00:53:17,109 --> 00:53:18,640
would like to look at multi author

1213
00:53:18,640 --> 00:53:21,190
source code authorship attribution and

1214
00:53:21,190 --> 00:53:23,380
the same for binaries and we are working

1215
00:53:23,380 --> 00:53:28,359
on that currently thank you yep hi using

1216
00:53:28,359 --> 00:53:30,099
your approach do you think it's possible

1217
00:53:30,099 --> 00:53:32,650
to abstract these models even more so

1218
00:53:32,650 --> 00:53:35,230
that it becomes possible to train on

1219
00:53:35,230 --> 00:53:37,809
data sets that are constructed from one

1220
00:53:37,809 --> 00:53:40,299
programming language and then do

1221
00:53:40,299 --> 00:53:42,430
classification on another programming

1222
00:53:42,430 --> 00:53:46,569
language or with text or samples from

1223
00:53:46,569 --> 00:53:48,910
another programming language and did you

1224
00:53:48,910 --> 00:53:51,849
do experiments in that direction thank

1225
00:53:51,849 --> 00:53:53,380
you that's a very good question we

1226
00:53:53,380 --> 00:53:54,970
haven't done experiments on that again

1227
00:53:54,970 --> 00:53:57,190
like it's difficult to find ground truth

1228
00:53:57,190 --> 00:53:59,319
data for this like even with Google

1229
00:53:59,319 --> 00:54:01,569
culture some programmers write in

1230
00:54:01,569 --> 00:54:04,290
multiple languages but

1231
00:54:04,290 --> 00:54:06,810
it's a very small set so we haven't

1232
00:54:06,810 --> 00:54:08,760
looked at that yet but like Miami for

1233
00:54:08,760 --> 00:54:11,280
example compare C and C++ yes you can do

1234
00:54:11,280 --> 00:54:13,710
cross training and testing because like

1235
00:54:13,710 --> 00:54:15,930
the nature of the two languages are very

1236
00:54:15,930 --> 00:54:21,360
similar Venu we are coding next question

1237
00:54:21,360 --> 00:54:24,510
goes to the Internet yes yes would that

1238
00:54:24,510 --> 00:54:27,660
also work on assembly because you do not

1239
00:54:27,660 --> 00:54:29,460
really have something like variable

1240
00:54:29,460 --> 00:54:36,750
names so with assembly I will go back to

1241
00:54:36,750 --> 00:54:40,830
the slide where we go so I just close it

1242
00:54:40,830 --> 00:54:43,680
just a second we have a bunch of

1243
00:54:43,680 --> 00:54:45,450
important features that come from

1244
00:54:45,450 --> 00:54:50,490
assembly and that's good

1245
00:54:50,490 --> 00:54:52,530
and it's very difficult to understand

1246
00:54:52,530 --> 00:54:54,620
what they actually mean because oh it's

1247
00:54:54,620 --> 00:55:02,180
oh I see okay here we go

1248
00:55:02,180 --> 00:55:05,910
so with assembly features here we get

1249
00:55:05,910 --> 00:55:08,400
assembly features from two different

1250
00:55:08,400 --> 00:55:10,380
disassemblers to make it stronger and

1251
00:55:10,380 --> 00:55:12,810
richer and we don't get that many but we

1252
00:55:12,810 --> 00:55:15,150
have like close to like 100 and

1253
00:55:15,150 --> 00:55:17,130
something and it's very difficult to

1254
00:55:17,130 --> 00:55:19,620
tell like what does exactly me because

1255
00:55:19,620 --> 00:55:21,830
like some of them are just uni grams and

1256
00:55:21,830 --> 00:55:25,560
it's very it looks very overfitting but

1257
00:55:25,560 --> 00:55:28,100
since we show in our reconstruction

1258
00:55:28,100 --> 00:55:30,360
experiments that somehow preserves

1259
00:55:30,360 --> 00:55:33,440
coding style in it somewhere as well

1260
00:55:33,440 --> 00:55:43,290
does that answer do you think it would

1261
00:55:43,290 --> 00:55:45,330
be possible to combine your research

1262
00:55:45,330 --> 00:55:47,670
with for example social graph analysis

1263
00:55:47,670 --> 00:55:52,110
to find cooperation yes you can do that

1264
00:55:52,110 --> 00:55:53,850
you can just add that as an extra

1265
00:55:53,850 --> 00:55:56,130
machine learning feature and just like

1266
00:55:56,130 --> 00:55:58,230
improve your classifier but in this

1267
00:55:58,230 --> 00:56:00,360
research we are particularly interested

1268
00:56:00,360 --> 00:56:03,060
in finding coding style and quantifying

1269
00:56:03,060 --> 00:56:05,310
coding styles so we wanted to exclude

1270
00:56:05,310 --> 00:56:08,600
like any other irrelevant information

1271
00:56:08,600 --> 00:56:13,130
which might make them more identifiable

1272
00:56:13,700 --> 00:56:16,740
did you do any research in the direction

1273
00:56:16,740 --> 00:56:17,860
of the

1274
00:56:17,860 --> 00:56:19,750
and compilers of the same language so

1275
00:56:19,750 --> 00:56:23,320
for example GCC analyzes better than ll

1276
00:56:23,320 --> 00:56:26,920
4m or can it help anonymize my code if I

1277
00:56:26,920 --> 00:56:29,040
use different compilers for different

1278
00:56:29,040 --> 00:56:32,650
binaries or projects I mix em match

1279
00:56:32,650 --> 00:56:35,290
might help another we haven't

1280
00:56:35,290 --> 00:56:37,450
investigated that question in particular

1281
00:56:37,450 --> 00:56:40,030
because when we look at related work we

1282
00:56:40,030 --> 00:56:42,760
see that compiler detection is kind of a

1283
00:56:42,760 --> 00:56:46,120
salt problem so as long as we know the

1284
00:56:46,120 --> 00:56:48,760
compiler because like it it can be

1285
00:56:48,760 --> 00:56:51,190
detected then we can come up with a

1286
00:56:51,190 --> 00:56:53,860
setting where source code has been

1287
00:56:53,860 --> 00:56:55,840
compiled in that setting or like try to

1288
00:56:55,840 --> 00:56:58,450
get rid of the properties that that

1289
00:56:58,450 --> 00:57:00,610
compiler would bring in it but as you

1290
00:57:00,610 --> 00:57:02,200
said if you like start mixing and

1291
00:57:02,200 --> 00:57:03,820
matching that might help you anonymize

1292
00:57:03,820 --> 00:57:05,530
it a little and that might be a good way

1293
00:57:05,530 --> 00:57:08,290
to start our anonymization experiments

1294
00:57:08,290 --> 00:57:12,670
thank you thanks hi I have a question

1295
00:57:12,670 --> 00:57:15,280
regarding the real-world application you

1296
00:57:15,280 --> 00:57:17,860
talked about what is the statistical

1297
00:57:17,860 --> 00:57:19,780
probability that this is just based on

1298
00:57:19,780 --> 00:57:22,120
pure luck I mean you have like 70 70 is

1299
00:57:22,120 --> 00:57:25,330
60 or 70% of the anonymization for 12

1300
00:57:25,330 --> 00:57:27,430
programmers how is the probability that

1301
00:57:27,430 --> 00:57:30,940
this is just random yes it's difficult

1302
00:57:30,940 --> 00:57:33,070
to talk about statistical significance

1303
00:57:33,070 --> 00:57:34,750
in this case because like we have a

1304
00:57:34,750 --> 00:57:36,850
smaller data set but at least we can

1305
00:57:36,850 --> 00:57:38,830
kind of compare it to the Google Code

1306
00:57:38,830 --> 00:57:40,540
Jam data set where we know there is

1307
00:57:40,540 --> 00:57:42,580
statistical significance that's why we

1308
00:57:42,580 --> 00:57:44,320
think that it might be possible and

1309
00:57:44,320 --> 00:57:46,660
sorry in our future work to like apply

1310
00:57:46,660 --> 00:57:49,210
these two larger real-world data sets

1311
00:57:49,210 --> 00:57:51,040
where we can talk about statistical

1312
00:57:51,040 --> 00:57:53,260
significance for sure and that's a very

1313
00:57:53,260 --> 00:57:55,000
good questions that we have been

1314
00:57:55,000 --> 00:57:58,570
thinking about thank you what may be the

1315
00:57:58,570 --> 00:58:01,920
last question goes for the internet oh

1316
00:58:01,920 --> 00:58:06,850
well yes so the question is what were

1317
00:58:06,850 --> 00:58:09,520
the most important in the random forest

1318
00:58:09,520 --> 00:58:18,070
analysis so the most important bonds are

1319
00:58:18,070 --> 00:58:21,250
by grams but do you like what work do

1320
00:58:21,250 --> 00:58:23,620
you mean real variables or are you

1321
00:58:23,620 --> 00:58:26,910
talking about features

1322
00:58:27,720 --> 00:58:30,940
so for source code authorship

1323
00:58:30,940 --> 00:58:32,830
attribution the most important features

1324
00:58:32,830 --> 00:58:36,190
for the random forests are word uni

1325
00:58:36,190 --> 00:58:37,630
Graham's first of all and Virginia

1326
00:58:37,630 --> 00:58:39,100
Graham's are things like your function

1327
00:58:39,100 --> 00:58:41,860
name or your integer or double choices

1328
00:58:41,860 --> 00:58:45,940
or things that come from your source

1329
00:58:45,940 --> 00:58:49,930
code and we have the by Graham's come

1330
00:58:49,930 --> 00:58:52,180
from the abstract syntax tree even

1331
00:58:52,180 --> 00:58:53,980
though they're percentage in the

1332
00:58:53,980 --> 00:58:55,930
information gained data set was less

1333
00:58:55,930 --> 00:58:58,450
than the word uni Graham's their

1334
00:58:58,450 --> 00:59:01,690
information gain is almost equivalent to

1335
00:59:01,690 --> 00:59:05,470
this entire information gain set so in

1336
00:59:05,470 --> 00:59:07,930
this case the ast by grams are the most

1337
00:59:07,930 --> 00:59:12,930
important okay thank you very much

