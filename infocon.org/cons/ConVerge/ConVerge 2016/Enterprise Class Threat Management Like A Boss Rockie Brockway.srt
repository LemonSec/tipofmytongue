1
00:00:00,000 --> 00:00:09,750
ok ok so that's me

2
00:00:09,750 --> 00:00:17,220
rocky I do a lot of stuff i do a red
purple teaming I do a lot of risk

3
00:00:17,220 --> 00:00:18,630
analysis I do

4
00:00:18,630 --> 00:00:23,189
vc so work for a number of big companies
but enough about me

5
00:00:23,880 --> 00:00:28,439
so if anybody was here last year I did
to talk on enterprise closet

6
00:00:28,439 --> 00:00:30,240
vulnerability management like a boss

7
00:00:30,240 --> 00:00:39,870
excuse me and so from a recap
perspective this document came out in

8
00:00:39,870 --> 00:00:44,610
2007 by this guy who's really smart you
should probably follow them on Twitter

9
00:00:44,610 --> 00:00:45,780
and look at his blog

10
00:00:45,780 --> 00:00:50,820
Gunnar Peterson but basically this .
this paper broke down

11
00:00:51,390 --> 00:01:00,449
essentially a essentially a a a
well-documented security program how it

12
00:01:00,449 --> 00:01:01,680
should look right

13
00:01:01,680 --> 00:01:04,830
all the components of a real security
program starting with risk management

14
00:01:04,830 --> 00:01:06,750
policy standards cetera

15
00:01:06,750 --> 00:01:09,630
breaking down in the processes like
vulnerability management like threat

16
00:01:09,630 --> 00:01:14,640
management which will be talking about
today so i encourage you to look that up

17
00:01:14,640 --> 00:01:21,360
and and you don't get a get a world it
may not suit you in

18
00:01:21,360 --> 00:01:26,189
you know every vertical depending on
what vertically you are actually a part

19
00:01:26,189 --> 00:01:28,979
of but i find it very very good

20
00:01:28,979 --> 00:01:33,150
so very briefly up here

21
00:01:33,780 --> 00:01:39,299
this is the over since 2009 to spend
trillions of dollars worldwide and

22
00:01:39,299 --> 00:01:42,840
information technology according to
gartner take that with a grain of salt

23
00:01:42,840 --> 00:01:48,570
it's gardener hello that here the number
of reaches from the verizon dir you can

24
00:01:48,570 --> 00:01:53,189
see that for the most part we're
spending a lot more money and for the

25
00:01:53,189 --> 00:01:57,929
most part the breaches still continue to
go up so i think that's a problem

26
00:02:02,640 --> 00:02:08,220
real briefly most organizations get that
protecting their business critical data

27
00:02:08,220 --> 00:02:10,080
is crucial

28
00:02:10,080 --> 00:02:14,190
all right did it's an important thing
but most people are going most

29
00:02:14,190 --> 00:02:19,709
organizations are going about it in
different ways right and and primarily

30
00:02:19,709 --> 00:02:22,890
two different ways that are incorrect

31
00:02:22,890 --> 00:02:25,859
from my perspective first is there
looking at security from a

32
00:02:25,860 --> 00:02:29,370
project-by-project perspective in other
words we need we need a new firewall we

33
00:02:29,370 --> 00:02:33,840
need to replace the antivirus we need
two factor authentication etc they

34
00:02:33,840 --> 00:02:39,060
individually that's you know those are
good initiatives but that's not how

35
00:02:39,060 --> 00:02:40,980
security program should be your own

36
00:02:40,980 --> 00:02:45,238
the other way is this evening looking
out from more of a compliance

37
00:02:45,239 --> 00:02:46,050
perspective

38
00:02:46,050 --> 00:02:52,050
ok and so while that does make business
sense because if you are in an

39
00:02:52,050 --> 00:02:55,650
organization or in vertical that that
you know has to comply with something

40
00:02:55,650 --> 00:02:59,970
and you are found non-compliant there's
a business impact

41
00:03:00,480 --> 00:03:04,950
that's called a fine all right so that
doesn't make sense but the unfortunate

42
00:03:04,950 --> 00:03:09,060
reality is that and all the old school
security nerds like me will always say

43
00:03:09,810 --> 00:03:13,410
and if if you've seen the you know if
you read my previous talk you've heard

44
00:03:13,410 --> 00:03:15,690
me say this right if you're compliant

45
00:03:15,690 --> 00:03:19,890
you're not secure but if you're secure

46
00:03:19,890 --> 00:03:23,548
you're also going to be compliant to
whatever compliance framework your

47
00:03:23,549 --> 00:03:28,170
organization may need to comply we're
all right so at the end of the day

48
00:03:28,170 --> 00:03:29,280
here's here

49
00:03:29,280 --> 00:03:34,560
here's kind of like that the big mission
statement here protecting protecting

50
00:03:34,560 --> 00:03:40,650
data is a function has to be treated as
a function of the business because there

51
00:03:40,650 --> 00:03:43,890
is significant financial ramifications
if you do not

52
00:03:44,459 --> 00:03:51,360
and so what we kind of take a look at it
from a from an overarching program

53
00:03:51,360 --> 00:03:54,299
perspective we want to look at
architecture

54
00:03:54,299 --> 00:03:56,120
ok enterprise

55
00:03:56,120 --> 00:04:00,049
security architecture architectures of
means of organizing complexity

56
00:04:00,049 --> 00:04:06,019
ok so if we can then basically use these
concepts of organizing complexity and

57
00:04:06,019 --> 00:04:12,980
apply this to our actual enterprise
security programs we now have an

58
00:04:12,980 --> 00:04:21,260
enterprise security architecture that
this will basically pay a simple way to

59
00:04:21,260 --> 00:04:25,580
the end irrespective of the size of your
organization but here's a framework now

60
00:04:25,580 --> 00:04:30,409
and we can follow this framework we can
prioritize initiatives because we're not

61
00:04:30,410 --> 00:04:34,039
going to be able to know organization is
is really going to be able to take

62
00:04:34,039 --> 00:04:35,990
everything on it once right

63
00:04:35,990 --> 00:04:41,300
mhm we have budgets to consider it
cetera but we're going to be able to

64
00:04:41,300 --> 00:04:45,169
prioritize our initiatives and say hey
guess what we know

65
00:04:45,830 --> 00:04:51,260
since now we understand what we're
trying to protect we know that these

66
00:04:51,260 --> 00:04:57,260
priorities let's say threat management
or identity management or simple

67
00:04:57,260 --> 00:05:00,200
third-party risk management policies
right

68
00:05:00,200 --> 00:05:04,909
these are initiatives that we need to
focus on and so year one year to year

69
00:05:04,910 --> 00:05:05,810
three

70
00:05:05,810 --> 00:05:12,080
now we can set a plan alright so this is
what the enterprise security

71
00:05:12,080 --> 00:05:16,880
architecture from the original Gunnar
Peterson document really kind of boils

72
00:05:16,880 --> 00:05:21,680
down to you have up here the
architecture components which are risk

73
00:05:21,680 --> 00:05:26,750
management policy and standards and then
actual design architecture right and

74
00:05:26,750 --> 00:05:31,190
those three are supported in some way
shape or form by processes defense in

75
00:05:31,190 --> 00:05:32,599
depth which is our stick

76
00:05:32,599 --> 00:05:37,520
this is our when we talk about security
this is what we typically think about

77
00:05:37,520 --> 00:05:43,849
the firewalls our network security
antivirus his endpoint security right so

78
00:05:43,849 --> 00:05:47,000
these are the controls that are really
kind of enforcing everything and then

79
00:05:47,000 --> 00:05:51,740
metrics metrics the area of the
enterprise security architecture that

80
00:05:51,740 --> 00:05:57,080
nobody knows well but it's exceptionally
critical because this is how we

81
00:05:57,080 --> 00:06:01,580
communicate our technical needs backup
into the business

82
00:06:02,150 --> 00:06:03,580
alright week

83
00:06:03,580 --> 00:06:09,550
expect business leaders to be those
experts and understand all the goofy

84
00:06:09,550 --> 00:06:14,650
stuff that we know right so we have to
we have to communicate that biometrics

85
00:06:14,650 --> 00:06:22,448
so today we're going to be talking about
threat management the problem one of the

86
00:06:22,449 --> 00:06:27,550
one of our enterprise security
architecture processes that management

87
00:06:27,550 --> 00:06:31,930
is typically broken down into okay we've
got controls and all those controls then

88
00:06:31,930 --> 00:06:37,840
have some semblance of logs etc that we
need to begin parsing through and

89
00:06:37,840 --> 00:06:38,888
figuring out

90
00:06:38,889 --> 00:06:43,780
hey is somebody actually attacking us or
do we have problems etcetera monitoring

91
00:06:43,780 --> 00:06:48,520
threat modeling which which I'll go into
a little bit towards the end incident

92
00:06:48,520 --> 00:06:52,690
response and threat intelligence which
has become

93
00:06:53,379 --> 00:06:59,020
I think this year's drink this year
security conference drink work so i'm

94
00:06:59,020 --> 00:07:01,960
not going to say too much because i
don't think we actually have much

95
00:07:01,960 --> 00:07:05,049
alcohol here but it happens

96
00:07:05,050 --> 00:07:08,199
ok so let's talk about challenges

97
00:07:08,199 --> 00:07:15,340
mhm challenges with building and act
building a solid threat management

98
00:07:15,340 --> 00:07:20,560
program includes Moore's law at the top
right Moore's Law processing power

99
00:07:20,560 --> 00:07:27,460
increases but doubles every 18 months i
believe is Moore's law but this then

100
00:07:27,460 --> 00:07:32,710
actually applies to malware and
everything else that is bad

101
00:07:32,710 --> 00:07:38,138
alright so we're constantly fighting
Moore's Law intelligence intelligence

102
00:07:38,139 --> 00:07:41,770
communication is actually very critical
supercritical from a threat management

103
00:07:41,770 --> 00:07:45,250
perspective right when you get into
enterprise environments

104
00:07:45,250 --> 00:07:51,849
if if let's say let's say server might
have some malware

105
00:07:51,849 --> 00:07:55,930
ok there's a number of people that have
to be involved in right

106
00:07:55,930 --> 00:07:58,539
the network teams probably need to be
involved in that so they can kind of

107
00:07:58,539 --> 00:08:02,650
maybe track down things like are their
command-and-control going to certain IP

108
00:08:02,650 --> 00:08:06,400
addresses the server teams need to be
obviously notified about all this

109
00:08:06,909 --> 00:08:10,629
if you are mature enough to have an
actual security operations center

110
00:08:10,629 --> 00:08:12,560
dedicated security people

111
00:08:12,560 --> 00:08:16,760
those guys are going to be spearheading
basically the entire you know monitoring

112
00:08:16,760 --> 00:08:20,990
and then potentially incident response
process right so there's a lot of

113
00:08:20,990 --> 00:08:25,760
communication that must be that you know
that must go into a good threat

114
00:08:25,760 --> 00:08:30,469
management program coordination
accountability accountability is

115
00:08:30,470 --> 00:08:38,089
critical obviously and and this is where
I've seen a number of threat management

116
00:08:38,089 --> 00:08:41,210
processes really kind of fall to pieces
right

117
00:08:41,210 --> 00:08:47,810
if you can design your threat management
process without but unfortunately not

118
00:08:47,810 --> 00:08:52,670
you know we don't have accountability in
terms of who's responsible and therefore

119
00:08:52,670 --> 00:08:55,790
at the end of the day potentially might
be

120
00:08:55,790 --> 00:09:00,140
you're losing their job because they
didn't do it properly then your threat

121
00:09:00,140 --> 00:09:04,220
management process is also not going to
function function as it should

122
00:09:04,970 --> 00:09:09,080
metrics I talked about talent is a
problem

123
00:09:09,080 --> 00:09:14,600
all right count is a huge problem
because for the most part you know

124
00:09:14,600 --> 00:09:17,570
they're there is- unemployment in
information security

125
00:09:17,570 --> 00:09:20,570
all right we don't have enough talent
out there

126
00:09:21,110 --> 00:09:31,550
so here's our challenges right and and
realistically when you talk to really

127
00:09:31,550 --> 00:09:39,859
good sock teams established mature
incident responders the their morale

128
00:09:39,860 --> 00:09:42,980
tends to to be like this

129
00:09:42,980 --> 00:09:46,280
now raise your hand if anybody actually
gets this reference

130
00:09:46,280 --> 00:09:49,640
12 awesome thank you

131
00:09:49,640 --> 00:09:53,569
all right so anyway threat management
goals

132
00:09:54,230 --> 00:10:00,150
so we want to obviously at the

133
00:10:00,150 --> 00:10:03,689
very top we must have buy-in from the
state goals

134
00:10:03,690 --> 00:10:07,410
ok once we have buying from the
stakeholders and that this is always a

135
00:10:07,410 --> 00:10:11,730
challenge because depending on where you
sit from a vertical perspective

136
00:10:12,300 --> 00:10:18,689
protecting the data may not be you know
one of the business needs according to

137
00:10:18,690 --> 00:10:22,350
the executives just kind of depends on
where you sit

138
00:10:22,350 --> 00:10:25,710
but the the buying is crucial

139
00:10:25,710 --> 00:10:31,530
now there's a number of things that we
want to utilize we want to utilize

140
00:10:31,530 --> 00:10:35,160
existing other processes as well
vulnerability management is a key

141
00:10:35,160 --> 00:10:39,810
example right corner building management
process on the one side of the house is

142
00:10:39,810 --> 00:10:44,609
all about understanding where you know
certain assets within the organization

143
00:10:44,610 --> 00:10:48,930
may have our abilities that might be
exploited by somebody who might be

144
00:10:48,930 --> 00:10:50,790
motivated to steal from you

145
00:10:50,790 --> 00:10:58,290
ok that's actually a threat model but
having up having that understanding of

146
00:10:58,290 --> 00:11:01,680
where those vulnerabilities are now
gives us the ability from a threat

147
00:11:01,680 --> 00:11:05,250
management perspective it's really kind
of look at it holistically and say okay

148
00:11:05,250 --> 00:11:11,640
now since we know where these
vulnerabilities are we can build our

149
00:11:11,640 --> 00:11:15,090
monitoring program and our incident
response programs accordingly

150
00:11:15,600 --> 00:11:20,820
right so that if X asset over here has
vulnerabilities and we know about it but

151
00:11:20,820 --> 00:11:25,500
we can't may be fixed because they they
control PLC's in a manufacturing plant

152
00:11:25,500 --> 00:11:30,330
network right then our threat management
process around monitoring an incident

153
00:11:30,330 --> 00:11:35,250
response can be built accordingly and
specifically for quicker detection

154
00:11:35,250 --> 00:11:40,530
ok and this is where this is where
monitoring really becomes one of the key

155
00:11:40,530 --> 00:11:48,060
components of your threat management
process threat prioritization is also

156
00:11:48,060 --> 00:11:49,410
very critical

157
00:11:49,410 --> 00:11:58,650
it's one thing if somebody falls victim
to a fish right and let's just say you

158
00:11:58,650 --> 00:12:01,079
know they click on something that they
probably shouldn't have

159
00:12:01,080 --> 00:12:07,470
ok so that's one instance who is that
person is that person of importance

160
00:12:07,470 --> 00:12:11,160
within your organization is that person
who just got phished

161
00:12:11,160 --> 00:12:15,420
let's say one of the people that
develops your intellectual property or

162
00:12:15,420 --> 00:12:17,250
is that person who just got fish

163
00:12:17,250 --> 00:12:23,399
let's say Merry in accounting still very
important potentially but different and

164
00:12:23,399 --> 00:12:28,290
and so being able to understand not just
what the attack is from a modern

165
00:12:28,290 --> 00:12:32,939
perspective but also who is it affecting
is crucial to prioritizing threats

166
00:12:34,110 --> 00:12:40,019
ok so at a very high level

167
00:12:41,220 --> 00:12:45,509
does anyone actually let me ask the
question does anybody know what the ASDs

168
00:12:45,509 --> 00:12:49,110
version - is anybody familiar with the
application security verification

169
00:12:49,110 --> 00:12:57,120
standard one awesome two better so

170
00:12:57,660 --> 00:13:03,389
hola put together basically a software
development / sdlc software development

171
00:13:03,389 --> 00:13:06,540
lifecycle framework called the
application security verification

172
00:13:06,540 --> 00:13:11,129
standard if anybody was familiar with
the old lost top 20

173
00:13:12,389 --> 00:13:18,779
I apologize because it's a complicated
mess and you know to a degree tends to

174
00:13:18,779 --> 00:13:21,630
be unimplemented well if that is a word

175
00:13:21,630 --> 00:13:29,160
I'm not sure that's a work but recently
the 2014 version of the of the SBS was

176
00:13:29,160 --> 00:13:34,139
released and i love it it's fantastic
and I'll kind of walk you through it

177
00:13:34,139 --> 00:13:35,279
real quick

178
00:13:35,279 --> 00:13:42,360
still in relation to just the base a SBS
bsbsbs greats down maturity of your

179
00:13:42,360 --> 00:13:46,800
software development and and software
development life cycle into levels 0

180
00:13:46,800 --> 00:13:52,589
that we don't really care about because
its level 0 right but levels 1 2 and 3

181
00:13:52,589 --> 00:13:56,610
and so if you meet these certain
criteria within your software

182
00:13:56,610 --> 00:14:01,740
development life cycle then you can
achieve level 1 maturity for you know

183
00:14:01,740 --> 00:14:03,630
according to the ASDs framework

184
00:14:03,630 --> 00:14:08,819
ok so it's a pretty simple set so the
levels

185
00:14:09,329 --> 00:14:15,929
opportunities level 1 and briefly just
you know indicates that an application

186
00:14:15,929 --> 00:14:19,379
can adequately defend itself against
application security vulnerabilities

187
00:14:19,379 --> 00:14:21,029
that are easy to discover

188
00:14:21,029 --> 00:14:26,189
ok that's pretty simple to to realize
now when you take a look at and i'll

189
00:14:26,189 --> 00:14:30,149
show you an example a little later but
when you take a look at the actual asds

190
00:14:30,149 --> 00:14:35,429
they just have a spreadsheet right and
they have a number of different sections

191
00:14:35,429 --> 00:14:41,220
and each section has a number of
requirements over here there's a level 1

192
00:14:41,220 --> 00:14:44,759
level 2 and level 3 column and if you
meet this requirement

193
00:14:45,749 --> 00:14:50,819
it's part of level 1 level 2 level 3 so
you can very easily gauge whether or not

194
00:14:50,819 --> 00:14:55,349
but where you actually sit from a
maturity constructive level 2 indicates

195
00:14:55,350 --> 00:14:59,069
an application and adequately defend
itself against prevalent application

196
00:14:59,069 --> 00:15:01,920
security vulnerabilities of moderate to
serious risk

197
00:15:01,920 --> 00:15:08,219
ok so we begin to start building in
things that are advancing the actual

198
00:15:08,220 --> 00:15:12,480
application development ensuring that
things like sequel injection and cross

199
00:15:12,480 --> 00:15:17,369
site scripting are tested for so you
know you can check that off and that's a

200
00:15:17,369 --> 00:15:23,790
requirement for level two very simple
level 30 and tend to note here that most

201
00:15:23,790 --> 00:15:27,748
organizations are likely going to fall
into level two

202
00:15:27,749 --> 00:15:30,959
ok level 3 tends to be very difficult to
achieve

203
00:15:31,679 --> 00:15:37,259
all right indicating that an application
can adequately defend itself against all

204
00:15:37,259 --> 00:15:40,739
advanced application security
vulnerabilities and shows principles of

205
00:15:40,739 --> 00:15:42,779
good security design

206
00:15:42,779 --> 00:15:50,639
now at this point for the most part when
you take a look at who should be trying

207
00:15:50,639 --> 00:15:53,459
to get a SBS level three

208
00:15:53,459 --> 00:15:58,109
we're really looking at critical
infrastructure we're looking at Medical

209
00:15:58,110 --> 00:16:02,939
anything that deals with human lives
right the automobile industry

210
00:16:03,449 --> 00:16:06,929
technically should really be looking at
level 3 just because at this point

211
00:16:06,929 --> 00:16:08,579
electric cars are what

212
00:16:08,579 --> 00:16:11,989
electric cars are computers with wheels
I'm a

213
00:16:11,990 --> 00:16:17,360
pewter happer that's a car now and all
it is is a computer

214
00:16:17,360 --> 00:16:25,790
so that's a problem but level three is
really for intended for what we what we

215
00:16:25,790 --> 00:16:28,130
consider irreplaceable data

216
00:16:28,130 --> 00:16:33,830
ok Josh corpsman also very smart guy
talks about irreplaceable vs relational

217
00:16:33,830 --> 00:16:42,819
data anybody had a credit card stolen so
hands you what happened what happened

218
00:16:42,819 --> 00:16:45,819
when you have your credit card soon

219
00:16:47,319 --> 00:16:51,878
haha replaceable data you're not liable
for that

220
00:16:51,879 --> 00:16:55,899
now let's talk about the other end of
the scale right

221
00:16:55,899 --> 00:17:00,009
intellectual property in human life and
to be irreplaceable data right

222
00:17:00,759 --> 00:17:07,630
if the what 11 herbs and spices recipe
for Kentucky Fried Chicken get stolen

223
00:17:08,199 --> 00:17:12,610
that's going to have a significant
business impact on that organization

224
00:17:12,609 --> 00:17:19,148
all right same with again let's say the
it what is it a bluetooth-enabled

225
00:17:19,148 --> 00:17:20,739
pacemaker

226
00:17:20,740 --> 00:17:24,609
you know comes in a range of somebody
who's like wow that's a bluetooth device

227
00:17:24,609 --> 00:17:26,619
how can I screw with it

228
00:17:26,619 --> 00:17:31,750
that's a problem right irreplaceable
name so realistically level three is in

229
00:17:31,750 --> 00:17:35,320
from my perspective here towards
organizations that are dealing with that

230
00:17:35,320 --> 00:17:36,850
that level of data

231
00:17:36,850 --> 00:17:43,090
ok so how can we take this and apply it
now - threat management

232
00:17:43,090 --> 00:17:52,090
all right again the framework itself now
I'm going to take a number of different

233
00:17:52,090 --> 00:17:53,289
levels

234
00:17:53,289 --> 00:17:58,120
the same one two three levels of the SVS
but i'm i'm now going basically apply it

235
00:17:58,120 --> 00:18:06,399
to or have applied to different elements
and variables of threat management

236
00:18:06,399 --> 00:18:07,539
programs

237
00:18:07,539 --> 00:18:11,350
so now we can adequately gauge our
maturity right

238
00:18:11,350 --> 00:18:19,120
that's the key point here right it's not
about for example what a pci audit do

239
00:18:19,120 --> 00:18:22,059
you scan for vulnerabilities

240
00:18:22,059 --> 00:18:25,220
yes or no ok that's

241
00:18:25,220 --> 00:18:29,539
kinda pointless it doesn't really tell
us how mature we are within our

242
00:18:29,539 --> 00:18:31,429
vulnerability management program

243
00:18:31,429 --> 00:18:37,280
alright so the whole point here is to be
able to now apply this framework and ask

244
00:18:37,280 --> 00:18:44,418
that question how mature is my threat
management process and how can not what

245
00:18:44,419 --> 00:18:50,179
what can I prioritize what can I look at
and how can i improve so again level 0

246
00:18:50,179 --> 00:18:52,640
we're not we're going to talk about
because its level 0

247
00:18:52,640 --> 00:19:00,230
ok level 1 level 1 indicates that the
organization can adequately defend

248
00:19:00,230 --> 00:19:04,940
itself against non-targeted threats that
are easy to discover such threats are

249
00:19:04,940 --> 00:19:10,789
typically discovered with minimal too
low effort and threats to that

250
00:19:10,789 --> 00:19:14,809
particular organization are going to
come likely from attackers using simple

251
00:19:14,809 --> 00:19:16,580
techniques and automated tools

252
00:19:16,580 --> 00:19:19,639
so if we can achieve level one

253
00:19:19,640 --> 00:19:24,799
this kind of low bar ok now we have an
understanding of our maturity

254
00:19:24,799 --> 00:19:29,990
so what does that really mean well in my
opinion

255
00:19:30,740 --> 00:19:38,210
I came up with this list that I feel is
good enough for an opportunistic level

256
00:19:38,210 --> 00:19:45,500
one threat management process using the
ASDs framework so we're looking at the

257
00:19:45,500 --> 00:19:48,530
organization does not have a dedicated
intersect or risk group

258
00:19:49,190 --> 00:19:52,850
there's a reliance had rudimentary
alerts right firewalls

259
00:19:52,850 --> 00:19:58,370
whatever no I PS antivirus no
centralized logging in other words no

260
00:19:58,370 --> 00:19:58,969
sim

261
00:19:58,970 --> 00:20:04,010
so we're not really correlating anything
there is a process in place for handling

262
00:20:04,010 --> 00:20:10,100
malware right that's typically a
helpdesk process the threat intelligence

263
00:20:10,100 --> 00:20:17,090
drink bullet here is sporadic things
like sands alerts or infoworld articles

264
00:20:17,090 --> 00:20:17,780
etc

265
00:20:17,780 --> 00:20:21,470
nothing really complex here there may be
an open source of commercial

266
00:20:21,470 --> 00:20:26,539
vulnerability scanning tool and you know
the organization is likely comfortable

267
00:20:26,539 --> 00:20:32,000
saying that I've achieve compliance with
let's say a NIST framework so therefore

268
00:20:32,000 --> 00:20:34,100
I'm secure not sure

269
00:20:34,100 --> 00:20:37,820
but what we're just going to keep it
like that

270
00:20:37,820 --> 00:20:40,970
alright so level 1a SBS for threat
management

271
00:20:41,690 --> 00:20:48,559
I think this makes a lot of sense so
let's talk about level two now the

272
00:20:48,559 --> 00:20:51,830
organization can adequately defend
itself against prevalent threats of

273
00:20:51,830 --> 00:20:57,350
moderate the serious capability
including hacktivists and non-targeted

274
00:20:57,350 --> 00:21:04,219
organized crime actors again like level
2 a-s vs straight plane

275
00:21:04,220 --> 00:21:08,750
you know plain vanilla ases most
organizations should target level two

276
00:21:08,750 --> 00:21:14,990
so what is this actually look at this
point we're talking about

277
00:21:14,990 --> 00:21:21,530
yes there is a dedicated infosec risk
group which does include dedicated

278
00:21:21,530 --> 00:21:28,520
monitoring resources that could be one
person but it still was still getting to

279
00:21:28,520 --> 00:21:34,429
where we want to be right there is an
integration with the existing level to

280
00:21:34,429 --> 00:21:37,190
vulnerability management process

281
00:21:37,190 --> 00:21:42,530
alright so we also have to have a level
two vulnerability management process

282
00:21:42,530 --> 00:21:47,149
that is looking at things like a sure
we're scanning vulnerabilities within

283
00:21:47,150 --> 00:21:52,250
the environment but also now how soon
are we mitigating these more abilities

284
00:21:52,250 --> 00:21:56,330
right and and the metrics associated
with time to remediation

285
00:21:56,960 --> 00:22:00,950
alright so the maturity of the
vulnerability management process is also

286
00:22:00,950 --> 00:22:03,950
actually communicator here

287
00:22:03,950 --> 00:22:09,799
basic monitoring framework and see
deployment anybody here in actual like a

288
00:22:09,799 --> 00:22:15,710
monitoring sock or or you know working
with sims some technologies a few

289
00:22:17,690 --> 00:22:20,690
it's it's a rough job right

290
00:22:20,690 --> 00:22:27,320
coral getting getting a piece of
software to adequately correlate logs

291
00:22:27,320 --> 00:22:33,620
from all of these vicarious sources is a
tough job and you have to go through the

292
00:22:33,620 --> 00:22:33,889
good

293
00:22:33,890 --> 00:22:39,050
ones that I've seen go through probably
a two to three year process of actually

294
00:22:39,050 --> 00:22:40,610
you know

295
00:22:40,610 --> 00:22:45,320
weeding out false positives and and
tuning it to the point that it's not

296
00:22:45,320 --> 00:22:52,040
overwhelming and it is a it's all it's a
hard job without a doubt there's

297
00:22:52,040 --> 00:22:54,050
documented Incident Response framework

298
00:22:54,050 --> 00:22:57,050
this is critical right

299
00:22:57,050 --> 00:23:02,480
mhm in addition to early detection which
is really at this point at this point

300
00:23:02,480 --> 00:23:05,240
from a threat management process early
detection is key

301
00:23:05,240 --> 00:23:09,650
all right but if you detect something

302
00:23:09,650 --> 00:23:14,030
now what are you going to do and this is
where a lot of organizations also

303
00:23:14,030 --> 00:23:18,680
stumble and we'll talk about a little
bit of all go through some examples but

304
00:23:18,680 --> 00:23:21,830
this is where that hole threat
prioritisation really really starts to

305
00:23:21,830 --> 00:23:22,790
have some value

306
00:23:22,790 --> 00:23:28,850
fantastic red purple team testing
simulating real world threat threat

307
00:23:28,850 --> 00:23:35,570
actors using real world techniques for
the last I don't know probably almost

308
00:23:35,570 --> 00:23:40,129
four years or maybe even five years now
we're going to get the real hardcore

309
00:23:40,130 --> 00:23:44,090
intersect pen testers have been not all
migrating over the purple team tests

310
00:23:44,090 --> 00:23:47,810
which is great and and for those of you
who don't know what that means

311
00:23:48,320 --> 00:23:52,580
the attacking red team's there are
attacking teams are usually referred to

312
00:23:52,580 --> 00:23:57,590
as read the defensive sock teams or
whatever the IR people etc are typically

313
00:23:57,590 --> 00:24:02,240
the blue team's and traditional
scenarios are red team attacks the

314
00:24:02,240 --> 00:24:04,460
organization the blue team doesn't know
about it

315
00:24:04,460 --> 00:24:08,870
they react and we see where they fall
all right we kind of figure out the gaps

316
00:24:08,870 --> 00:24:13,070
depending on the maturity of your threat
management process

317
00:24:13,640 --> 00:24:20,240
there's added value - purple team
testing which is the attacking teams are

318
00:24:20,240 --> 00:24:24,200
sitting side by side with the defensive
blue team's they're walking attacked

319
00:24:24,200 --> 00:24:28,040
chains and walking through actual attack
chains

320
00:24:28,040 --> 00:24:31,340
step 1 reconnaissance I just did this

321
00:24:31,340 --> 00:24:34,730
did you guys detectives ok step 2

322
00:24:34,730 --> 00:24:39,290
now i'm looking at you know whatever
we're talking about from you know

323
00:24:39,290 --> 00:24:43,700
exploitation to post exploitation etc
but the teams are working side by side

324
00:24:43,700 --> 00:24:46,429
running actual attacks

325
00:24:46,429 --> 00:24:51,679
and seeing where the sock teams you know
where the improvements and where the gap

326
00:24:51,679 --> 00:24:56,210
should should be a lot of value but
there's not a lot of value and purple

327
00:24:56,210 --> 00:24:58,129
team testing if you don't have a sock

328
00:24:58,129 --> 00:25:04,850
so again you know illustrating to the
the importance of getting the maturity

329
00:25:04,850 --> 00:25:10,730
level of the threat management process
and then open source intelligence or

330
00:25:10,730 --> 00:25:14,389
commercial threat intelligence sources
some other things here there's going to

331
00:25:14,389 --> 00:25:18,019
be a defined standard for reviewing
intelligence reviewing all the

332
00:25:18,019 --> 00:25:21,259
intelligence that's coming in with
escalation procedures

333
00:25:21,259 --> 00:25:29,360
here's our sim right so again this is
the necessity of the sim classification

334
00:25:29,360 --> 00:25:35,869
standards asset and data classification
standards are critical at this point for

335
00:25:35,869 --> 00:25:37,519
your threat management process

336
00:25:37,519 --> 00:25:41,210
it's one thing to know that ok hmm

337
00:25:41,210 --> 00:25:44,480
this acid over here has been infected
with malware

338
00:25:44,480 --> 00:25:47,929
it's another thing to know that this
acid over here that has been infected

339
00:25:47,929 --> 00:25:53,419
with malware has access to this level of
data and is owned by this level of

340
00:25:53,419 --> 00:25:56,360
person role within the organization

341
00:25:56,360 --> 00:26:03,678
alright so being able to understand the
lateral associations of that is infected

342
00:26:03,679 --> 00:26:08,539
with malware is very very critical and
that's really based on all the data

343
00:26:08,539 --> 00:26:12,710
classification standards that you know
that you can muster up the role based

344
00:26:12,710 --> 00:26:16,909
access pass to access control standards
as well

345
00:26:17,659 --> 00:26:23,090
again who has access to what and where
and when threat modeling standards are

346
00:26:23,090 --> 00:26:29,928
are also a requirement for this for
level two and i will go through i'll

347
00:26:29,929 --> 00:26:33,860
just you know briefly show three
different types of threat modeling's

348
00:26:33,860 --> 00:26:39,590
again it's it's not one size fits all
really kind of depends on your your

349
00:26:39,590 --> 00:26:44,749
comfort level and and which one may be
kind of speaks to you more advanced end

350
00:26:44,749 --> 00:26:48,169
. controls right so now we're starting
to talk about things like Microsoft

351
00:26:48,169 --> 00:26:48,799
minutes

352
00:26:48,799 --> 00:26:54,289
we're starting to talk about things like
of behavioral things are looking at the

353
00:26:54,289 --> 00:26:55,290
end .

354
00:26:55,290 --> 00:26:59,820
more than just your antivirus signatures
right

355
00:26:59,820 --> 00:27:05,909
so some type of behavior etc some
examples include amp falcon from

356
00:27:05,910 --> 00:27:12,240
CrowdStrike the carbon blacks of the
world arm so that guy's really important

357
00:27:12,240 --> 00:27:15,270
to all right

358
00:27:15,270 --> 00:27:20,730
I and I realize that this that word is
also can open up basically a gigantic

359
00:27:20,730 --> 00:27:23,880
can of worms like in terms of ok we're
kind of encryption are you talking about

360
00:27:24,510 --> 00:27:30,150
where when etc is it in transit is at
rest but at the end of the day you need

361
00:27:30,150 --> 00:27:35,460
to be you need to have that
understanding of what's important

362
00:27:35,460 --> 00:27:40,320
how is it classified when should those
classifications of data

363
00:27:40,320 --> 00:27:44,970
when should they be encrypted where and
when etc so I realized that that's a

364
00:27:44,970 --> 00:27:49,620
vague one but it is very that is kind of
complicated as well

365
00:27:49,620 --> 00:27:53,399
ok so so that's in my opinion

366
00:27:53,940 --> 00:27:57,930
level two how I feel that an
organization who wants to achieve a

367
00:27:57,930 --> 00:28:00,450
level to maturity from a threat
management process

368
00:28:00,450 --> 00:28:04,530
that's how it really that's how I think
it should look level 3

369
00:28:04,530 --> 00:28:10,860
now we are again talking about critical
infrastructure etc while we're most

370
00:28:10,860 --> 00:28:15,060
organizations are going to look to
achieve the maturity level two level

371
00:28:15,060 --> 00:28:16,889
three is pretty advanced

372
00:28:16,890 --> 00:28:21,300
so indicating that the organization can
adequately defend itself against all

373
00:28:21,300 --> 00:28:25,080
advanced security all advanced threats
showing principles of good security

374
00:28:25,080 --> 00:28:31,320
design requires a mature enterprise
security architecture the you know those

375
00:28:31,320 --> 00:28:34,320
the ESA model that I that I put up
earlier

376
00:28:35,700 --> 00:28:44,010
so what does this look like again we're
really talking about some mature stuff

377
00:28:44,010 --> 00:28:48,390
at this point we have to have this
threat prioritization standard typically

378
00:28:48,390 --> 00:28:52,890
broken down into triage suspect and then
incident right so at some point

379
00:28:54,230 --> 00:28:58,669
at some point levers need to be talked
about from and I our perspective

380
00:28:58,669 --> 00:29:02,450
in other words ok we know that our
domain controller has been breached

381
00:29:03,530 --> 00:29:09,110
that's bad now what levers are we going
to pull to minimize the damage and

382
00:29:09,110 --> 00:29:11,449
mythic be able to try to mitigate that
right

383
00:29:11,450 --> 00:29:17,690
do we you know and an example of a lever
could be the reset globally of all of

384
00:29:17,690 --> 00:29:23,030
your user bases passwords and the reset
of let's say the Kerberos ticket

385
00:29:23,030 --> 00:29:27,379
password which is a giant problem if
that thing is breached as well

386
00:29:27,380 --> 00:29:30,440
these are again

387
00:29:30,440 --> 00:29:36,590
it advanced levers you know front
advanced levels associated with the

388
00:29:36,590 --> 00:29:39,709
prioritisation but they need to be

389
00:29:39,710 --> 00:29:43,460
they need to be talking about just
talked about but documented and then run

390
00:29:43,460 --> 00:29:47,840
through from a tabletop respecter
incident response tabletop exercises if

391
00:29:47,840 --> 00:29:49,760
you can combine those with purple teams

392
00:29:49,760 --> 00:29:52,760
that's also really fun and valuable as
well for all parties

393
00:29:53,840 --> 00:30:02,899
mature I our framework right including
so including the racy the race he does

394
00:30:02,900 --> 00:30:09,470
framework forget what I frequent analyst
for actually stands for again it and and

395
00:30:09,470 --> 00:30:13,070
I mentioned the tabletop exercises right
so simulated things like the domain

396
00:30:13,070 --> 00:30:15,230
breach simulating things like ransom
work right

397
00:30:15,230 --> 00:30:19,309
what is the organization going to do in
this scenario when this asset is

398
00:30:19,309 --> 00:30:23,570
affected and that asset is owned by this
role within the organization

399
00:30:23,570 --> 00:30:30,260
how do we react all threat investigative
activity is documented in some type of

400
00:30:30,260 --> 00:30:32,270
internal content management system

401
00:30:32,270 --> 00:30:37,340
honey pots and in particular things like
deceptions everybody know what Dee cept

402
00:30:37,340 --> 00:30:42,830
is so deceptive is a really interesting
an interesting little honeypot

403
00:30:43,610 --> 00:30:51,559
basically there are techniques today
we're an attacker or adversary gets into

404
00:30:51,559 --> 00:31:00,470
a windows system and has the ability to
pull path either hashes or or clear text

405
00:31:00,470 --> 00:31:05,179
passwords out of memory right it's the
elsass process within windows

406
00:31:05,720 --> 00:31:12,650
so d cept basically is a honey hash
honey pot

407
00:31:12,650 --> 00:31:19,640
in other words it will place fake hashes
and password hashes into memory and when

408
00:31:19,640 --> 00:31:24,710
they get pulled your sock team can get
notified that

409
00:31:24,710 --> 00:31:29,240
hey this has just got pulled out of
memory and that's a fake password hash

410
00:31:30,470 --> 00:31:35,390
we have a problem and that problem
originates on this particular asset so

411
00:31:35,390 --> 00:31:39,890
you can really kind of all this you know
pull a couple of switches and say boom

412
00:31:39,890 --> 00:31:42,860
that's off the network right again

413
00:31:42,860 --> 00:31:47,750
level 3 star right not everybody has
that level of identity management

414
00:31:47,750 --> 00:31:52,790
controls to be able to say oh that host
is you know based on its MAC addresses

415
00:31:52,790 --> 00:31:54,110
no longer

416
00:31:54,110 --> 00:31:59,750
it allowed on this network but that's
one of those things that you would begin

417
00:31:59,750 --> 00:32:02,510
to work towards right

418
00:32:02,510 --> 00:32:07,220
uh rights management dlp that stuff and
I don't care if it's you know do p is

419
00:32:07,220 --> 00:32:08,540
another one of those

420
00:32:08,540 --> 00:32:11,990
Oh two to three years and maybe we get
it right all right

421
00:32:12,680 --> 00:32:16,130
I don't really care if it's homegrown or
not but but it

422
00:32:16,130 --> 00:32:20,450
we do have to have the ability to say
you know something that person who

423
00:32:20,450 --> 00:32:23,630
doesn't need to have access to that type
of data can't

424
00:32:23,630 --> 00:32:28,550
alright so a couple last things here

425
00:32:28,550 --> 00:32:32,810
I talked about identity access controls
on a network threat multipliers right

426
00:32:32,810 --> 00:32:36,560
threat multipliers are interesting and I
walk through a threat prioritization

427
00:32:36,560 --> 00:32:43,460
example in it in a second but threat
multipliers are things like okay well we

428
00:32:43,460 --> 00:32:49,220
know that this malware affected this
particular asset but we may also know

429
00:32:49,220 --> 00:32:52,490
that it was targeted and if it was
targeted

430
00:32:52,490 --> 00:32:59,030
what's that person's intent now we
probably aren't going to know that level

431
00:32:59,030 --> 00:33:02,120
of detail in an incident at the onset

432
00:33:02,120 --> 00:33:06,169
but as we begin to go through the IR
process that actually might come into

433
00:33:06,170 --> 00:33:06,950
play

434
00:33:06,950 --> 00:33:11,480
and if that intent is to say steal your
intellectual property for and it's an

435
00:33:11,480 --> 00:33:14,580
insider then we're going to prioritize
that a little

436
00:33:14,580 --> 00:33:19,980
a bit differently adversary capability
assessment this kind of goes along the

437
00:33:19,980 --> 00:33:27,990
lines of return on investment right data
data theft is a giant global business

438
00:33:27,990 --> 00:33:33,029
and i don't know i want to say that one
reports

439
00:33:33,029 --> 00:33:37,649
I think 2012-2013 stated that and i'm
not saying that this is completely true

440
00:33:37,649 --> 00:33:43,799
just i read this and it's the internet
so bare grain of salt but uh the global

441
00:33:43,799 --> 00:33:48,090
revenues for data theft exceeded the
global revenues of the illicit drug

442
00:33:48,090 --> 00:33:51,090
trade and I think 2013

443
00:33:51,720 --> 00:33:59,940
I'll let that sink in the revenues for
global data theft exceeded the illicit

444
00:33:59,940 --> 00:34:01,110
drug trade ribbon

445
00:34:01,110 --> 00:34:04,469
so that's a giant business all right

446
00:34:04,470 --> 00:34:09,899
every business has a budget and so when
we start talking about advancing and

447
00:34:09,899 --> 00:34:14,699
improving your threat management process
and especially things you know in the

448
00:34:14,699 --> 00:34:17,790
area of his incident response it's
important to kind of understand who

449
00:34:17,790 --> 00:34:24,570
might want to steal from you and what
are their capabilities we can begin to

450
00:34:24,570 --> 00:34:32,700
kind of model that adversary capability
level then we have a chance at beginning

451
00:34:32,699 --> 00:34:36,839
to build our enterprise security
architecture in such a way that over

452
00:34:36,839 --> 00:34:40,560
time the controls that were able to
build and prioritize and put into place

453
00:34:40,560 --> 00:34:42,060
over time

454
00:34:42,060 --> 00:34:47,219
drives that adversary return on
investment 20 and so if there's no

455
00:34:47,219 --> 00:34:50,759
profit in trying to steal something from
you

456
00:34:50,760 --> 00:34:54,389
you're doing a really good job because
that adversary is probably not going to

457
00:34:54,389 --> 00:34:55,320
continue

458
00:34:55,320 --> 00:35:02,250
no profit right ok so i just got

459
00:35:02,250 --> 00:35:06,810
things I'm not just gonna be my slide
here at this point before I kind of move

460
00:35:06,810 --> 00:35:12,000
on and i'm going to look at some some
things like metrics but before I move on

461
00:35:12,000 --> 00:35:15,060
I want to just kind of open it up right

462
00:35:15,060 --> 00:35:23,220
so I put together a framework for threat
Mary Fred management process utilizing

463
00:35:23,220 --> 00:35:33,200
the ASDs framework levels 1 level 2
level 3 feedback initial

464
00:35:33,200 --> 00:35:38,029
feedback questions improvements

465
00:35:38,030 --> 00:35:41,690
am I completely on the wrong planet

466
00:35:42,349 --> 00:35:45,349
anybody yes sir

467
00:35:57,500 --> 00:36:02,810
it's a good question right so I i will
also

468
00:36:03,440 --> 00:36:14,210
I'll evade your question in this way
most attacks are coming 40 days right

469
00:36:14,210 --> 00:36:18,560
they're coming through social
engineering and getting somebody to

470
00:36:18,560 --> 00:36:19,790
click on something

471
00:36:19,790 --> 00:36:22,849
not to say that that's not a problem
right

472
00:36:22,849 --> 00:36:27,050
who's there out there right we just had
to hack your hacking team breach

473
00:36:27,050 --> 00:36:34,190
last year and when the hacking team got
hacked and all of their zero-days got

474
00:36:34,190 --> 00:36:35,210
into the wild

475
00:36:35,210 --> 00:36:40,250
everybody's like oh shit guys were busy
you know we had any idea what was going

476
00:36:40,250 --> 00:36:45,619
on there so you're absolutely right in
terms that arm if somebody and and this

477
00:36:45,619 --> 00:36:48,859
cute this will get into threat modeling
in a second right

478
00:36:48,859 --> 00:36:54,319
if somebody's motivated enough to try to
steal something from you and that may

479
00:36:54,319 --> 00:36:57,259
include having that you know

480
00:36:57,260 --> 00:37:01,310
well I'm willing to spend 200 thousand
dollars on a zero-day if it's going to

481
00:37:01,310 --> 00:37:01,700
net

482
00:37:01,700 --> 00:37:08,569
you know if it's going to let me
whatever it's going to happen if you're

483
00:37:08,569 --> 00:37:12,680
really targeted you're going to get
breach that's really kind of at the end

484
00:37:12,680 --> 00:37:14,629
of the day right

485
00:37:14,630 --> 00:37:18,050
if you are specifically absolutely
targeted for something that somebody

486
00:37:18,050 --> 00:37:19,819
knows that they can make money off of

487
00:37:19,819 --> 00:37:27,170
by stealing from you they have as much
time to try to do that and I know that's

488
00:37:27,170 --> 00:37:31,550
a doom and gloom scenario but it's kind
of a reality

489
00:37:31,550 --> 00:37:36,619
now all of this is going to help right
because all of this is all about

490
00:37:36,619 --> 00:37:41,270
detecting the the way that they're doing
it earlier right

491
00:37:41,270 --> 00:37:44,509
so zero day doesn't necessarily mean
that it's automatically going to be able

492
00:37:44,510 --> 00:37:46,270
to get into your system

493
00:37:46,270 --> 00:37:52,420
and successfully exploit something it
may but we're also looking at the you

494
00:37:52,420 --> 00:37:56,230
know especially at level 3 we're talking
about behavioral and . controls were

495
00:37:56,230 --> 00:38:01,600
talking about you know segmenting this
data from these people write this

496
00:38:01,600 --> 00:38:05,410
there's a lot of hoops that that
adversary at level 3

497
00:38:05,410 --> 00:38:10,000
even even level 2 but definitely level
three we're going to have to jump

498
00:38:10,000 --> 00:38:14,770
through a ton of stuff to evade all this
detection that were building and at some

499
00:38:14,770 --> 00:38:19,840
point it's a high probability that we're
going to mess up the roots are going to

500
00:38:19,840 --> 00:38:22,330
mess up and you're going to see
something and it's going to trigger

501
00:38:22,330 --> 00:38:28,840
enough warning be like oh we have to
escalate who write the answer your

502
00:38:28,840 --> 00:38:32,560
question kinda get anybody else

503
00:38:35,260 --> 00:38:41,860
oh I'll show you

504
00:38:41,860 --> 00:38:47,230
yeah i'll show you a couple sighs hey ok
so I'm going to talk a little bit about

505
00:38:47,230 --> 00:38:49,060
metrics metrics are great

506
00:38:49,060 --> 00:38:52,330
ok again this is how we communicate back
up into the business

507
00:38:52,330 --> 00:38:58,810
how much on timeline ok so I'm a little
bit about metrics here

508
00:38:58,810 --> 00:39:03,190
here are some really good metrics that I
like to that I like to you know help

509
00:39:03,190 --> 00:39:07,990
organizations develop and I not about
making slides public opinion

510
00:39:07,990 --> 00:39:11,529
so if I'm if I'm going through these in
and you miss taking notes or whatever

511
00:39:11,530 --> 00:39:16,870
don't worry about it up easily up some
are incident metrics things like

512
00:39:16,870 --> 00:39:19,779
characteristics of that particular
incident timeline number of systems

513
00:39:19,780 --> 00:39:23,560
targeted attack metrics what's the
actual attack vector how sophisticated

514
00:39:23,560 --> 00:39:30,310
is the attack data metrics right so what
date is actually being targeted

515
00:39:30,310 --> 00:39:37,090
compromised etc incidents by status
right so this is really more of a

516
00:39:37,090 --> 00:39:43,120
instant the whole spa incident by status
thing is really more of a depending on

517
00:39:43,120 --> 00:39:50,020
how your organization is getting to
tracking these types of tickets and it

518
00:39:50,020 --> 00:39:54,759
might be a ticketing system they may
just be a completely homegrown sock

519
00:39:54,760 --> 00:39:57,319
driven process but

520
00:39:57,319 --> 00:40:01,160
no incidents by status whether or not
you know this is a new one has been

521
00:40:01,160 --> 00:40:06,109
reopened it actually fixed etc and some
of my favorites here meantime to

522
00:40:06,109 --> 00:40:07,279
compromise

523
00:40:07,279 --> 00:40:11,839
meantime the compromise is pretty cool
because when you start working with the

524
00:40:11,839 --> 00:40:17,660
the the Red the purple teams etc you can
begin gathering these types of

525
00:40:17,660 --> 00:40:23,390
Statistics how long did it take for that
particular you know through this

526
00:40:23,390 --> 00:40:27,589
particular vector how long did it take
to compromise this particular asset

527
00:40:27,589 --> 00:40:33,619
now we have a set of metrics that we can
begin over time hopefully improving

528
00:40:33,619 --> 00:40:34,279
right

529
00:40:34,279 --> 00:40:39,229
mhm hopefully the next year you do a
penetration test the mean time for that

530
00:40:39,229 --> 00:40:43,160
compromise is much reduced because hey
we had a whole year to begin developing

531
00:40:43,160 --> 00:40:44,509
let's say level two

532
00:40:44,509 --> 00:40:50,569
you know a series of level 2 threat
threat management processes and and now

533
00:40:50,569 --> 00:40:51,769
we detected that earlier

534
00:40:51,769 --> 00:41:00,439
awesome cost to disrupt all right so how
you know how much

535
00:41:00,440 --> 00:41:05,719
realistically would it take from a time
energy and and and money perspective to

536
00:41:05,719 --> 00:41:11,209
actually disrupt the business at a level
that is unacceptable adversary means

537
00:41:11,209 --> 00:41:13,038
every sorrow I we talked about

538
00:41:13,039 --> 00:41:19,339
ok so I'm going to talk a little bit
about I got three kind of example threat

539
00:41:19,339 --> 00:41:22,549
models that are really really
interesting

540
00:41:22,549 --> 00:41:25,549
the first one is the three tenants
threat model right

541
00:41:26,119 --> 00:41:30,589
this is the paper that this came from
its the quantitative metrics and risk

542
00:41:30,589 --> 00:41:34,339
assessment for three tenants model of
cybersecurity by jeff hughes and George

543
00:41:34,339 --> 00:41:39,949
Sibeko but we are really taking a look
at right

544
00:41:39,949 --> 00:41:45,859
these variables system when and
variables about the system's the attack

545
00:41:45,859 --> 00:41:48,828
surface kind of threat

546
00:41:48,829 --> 00:41:53,239
you know threat variables and then the
actual capabilities from being able to

547
00:41:53,239 --> 00:42:00,739
then kinda take situations and apply
this model to individual attack types

548
00:42:00,739 --> 00:42:06,170
and sin and situations is very valuable
and and again

549
00:42:06,700 --> 00:42:11,589
it's not a one size fits all thing right
so here's one of them

550
00:42:11,589 --> 00:42:18,369
here's another this is it looks even
more complicated but kind of again if

551
00:42:18,369 --> 00:42:24,760
the the diamond model of intrusion
analysis from this paper here is

552
00:42:24,760 --> 00:42:26,589
fascinating

553
00:42:26,589 --> 00:42:29,770
it's fascinating if you're a nerd like
me but it's fascinating

554
00:42:30,730 --> 00:42:34,930
and so this one is really kind of
talking about breaking it down in terms

555
00:42:34,930 --> 00:42:37,480
of here are the

556
00:42:37,480 --> 00:42:43,990
here are some of the factors or or I
don't want to say but the actual chain

557
00:42:43,990 --> 00:42:47,200
of events right so of it

558
00:42:47,200 --> 00:42:49,569
here are the variables of an attack
right you have a reconnaissance

559
00:42:49,570 --> 00:42:53,920
weaponization delivery exploitation
installation command and control that's

560
00:42:53,920 --> 00:42:58,599
the c2 and then the action on the
objective which typically is extra

561
00:42:58,599 --> 00:43:00,849
training data out of your another right

562
00:43:00,849 --> 00:43:06,160
so again i'm not going to go into any of
these in detail i leave that up to you

563
00:43:06,160 --> 00:43:10,149
know to you from an exercise perspective
but that paper itself is a fascinating

564
00:43:10,150 --> 00:43:12,460
read again if you're a nerd

565
00:43:12,460 --> 00:43:19,060
so Bruce potter did a talk at Derby con
for called threat modeling for reals

566
00:43:19,060 --> 00:43:24,880
I believe Adrian recorded it that's on
Adrian site iron geek.com take a look at

567
00:43:24,880 --> 00:43:25,450
it

568
00:43:25,450 --> 00:43:30,310
the great break down though is this
right here's a threat model actor does

569
00:43:30,310 --> 00:43:34,779
action to asset resulting in outcome
because of motivation

570
00:43:35,380 --> 00:43:38,950
that's easy right

571
00:43:39,609 --> 00:43:45,040
so again I kind of leave it to you and
to everybody to kind of look at some of

572
00:43:45,040 --> 00:43:50,170
these start models as you begin building
the threat management process and and

573
00:43:50,170 --> 00:43:54,940
see which one really kind of speaks to
you money seltzer is in

574
00:43:54,940 --> 00:44:02,800
he's a great guy and this is his
incident response template report that

575
00:44:02,800 --> 00:44:04,119
you can download

576
00:44:04,119 --> 00:44:08,650
it's open source it's just out there and
as part of your incident response

577
00:44:08,650 --> 00:44:16,170
process documentation of all of the
characteristics of of attacks is crucial

578
00:44:16,170 --> 00:44:21,210
- having not just the record of it but
understanding and begin you know being

579
00:44:21,210 --> 00:44:24,510
able to improve your instant response
capabilities

580
00:44:24,510 --> 00:44:29,880
alright so this is a this is a necklace
actually I think it's like a 15 or 16

581
00:44:29,880 --> 00:44:31,049
pages long

582
00:44:31,049 --> 00:44:34,349
each incident should have one of these

583
00:44:34,349 --> 00:44:38,220
and if you can build it into something
like a content management system like

584
00:44:38,220 --> 00:44:41,759
sharepoint and say okay I've got you
know as part of our incident response

585
00:44:41,760 --> 00:44:46,770
problem process if we are at look at the
point where pulling incident response

586
00:44:46,770 --> 00:44:52,319
triggers click new incident report food
bring this up and start documenting as

587
00:44:52,319 --> 00:44:56,339
you are actually you know trying to
learn it as you're responding to the

588
00:44:56,339 --> 00:45:02,308
actual incident incident lexicon this is
really kind of cool to this github

589
00:45:02,309 --> 00:45:07,589
project the various github project
basically it's the vocabulary of event

590
00:45:07,589 --> 00:45:09,270
recording an incident sharing

591
00:45:09,270 --> 00:45:14,970
so the set of metrics but having a
common lexicon is great

592
00:45:14,970 --> 00:45:19,828
so when you begin building let's say
your sock team and then the associated

593
00:45:19,829 --> 00:45:23,790
incident response portion of your of
your friend management process having

594
00:45:23,790 --> 00:45:26,790
that common language is great to have

595
00:45:28,260 --> 00:45:32,520
I'm gonna do a little bit of a demo even
though it's not really a demo it's just

596
00:45:32,520 --> 00:45:35,520
a it's an Excel spreadsheet

597
00:45:38,130 --> 00:45:44,520
let's forget how . one is ok

598
00:45:46,140 --> 00:45:50,190
oh where is my excel we are

599
00:45:50,190 --> 00:45:59,490
ok so this is an example of a threat
prioritization the system excel

600
00:45:59,490 --> 00:46:06,569
spreadsheet right so we start with up
here here's our inputs right

601
00:46:06,569 --> 00:46:09,869
we know we have assume and here's all
the things that are going into our sin

602
00:46:09,869 --> 00:46:15,329
right you have your IPS you're at your
antivirus your endpoint protection your

603
00:46:15,329 --> 00:46:19,710
limit the number is how many people are
familiar with microsoft index p.m. ET

604
00:46:19,710 --> 00:46:20,609
put it

605
00:46:20,609 --> 00:46:24,650
cool it hi

606
00:46:24,650 --> 00:46:29,270
amended but it is a very difficult
installation and maintenance maintenance

607
00:46:29,270 --> 00:46:36,470
in an enterprise environment but if you
can please look into it because it's

608
00:46:36,470 --> 00:46:38,990
it's looking at all these great
behavioral things

609
00:46:38,990 --> 00:46:51,740
what was that good

610
00:46:52,309 --> 00:46:53,890
55

611
00:46:53,890 --> 00:46:57,370
I've yeah okay everything before that

612
00:46:57,370 --> 00:47:05,200
okay talk to that guy that ok so here's
our inputs right now

613
00:47:05,200 --> 00:47:10,180
hmm the way we've got a model this is ok
fine

614
00:47:10,990 --> 00:47:15,759
from a triage perspective we have been
you know alerted that something is that

615
00:47:16,360 --> 00:47:21,400
let's see let's figure out what it is
and let's say it's a trojan okay fine

616
00:47:21,400 --> 00:47:25,570
how many are we looking at is it 20 to
50

617
00:47:25,570 --> 00:47:28,930
ok that's kind of bad for pi d now Corp
ID

618
00:47:28,930 --> 00:47:32,379
what we ended up doing and I don't have
a demo of this so i apologize what we

619
00:47:32,380 --> 00:47:36,370
ended up doing is just running writing a
little simple powershell script that

620
00:47:36,370 --> 00:47:40,210
says okay we know that this acid is
having a problem that acid is owned by

621
00:47:40,210 --> 00:47:41,290
this guy

622
00:47:41,290 --> 00:47:44,710
let's look them up in an active
directory and see what his role is

623
00:47:44,710 --> 00:47:46,210
within the organization

624
00:47:46,210 --> 00:47:51,400
now we can begin now we we have a level
of importance that we can put to that

625
00:47:51,400 --> 00:47:56,560
person and add to our actual threat
severity process so in this in this

626
00:47:56,560 --> 00:47:58,960
instance I'm just going to keep it at
five

627
00:47:58,960 --> 00:48:04,330
all right let's say he's a CEO and then
we can also say oh well that that

628
00:48:04,330 --> 00:48:11,049
particular asset is either is part of a
you know let's say a less critical group

629
00:48:11,050 --> 00:48:13,090
of assets or has access to

630
00:48:13,090 --> 00:48:17,260
maybe not as you know as critical of an
asset it just kind of depends right at

631
00:48:17,260 --> 00:48:19,330
the end of the day though you get this
score

632
00:48:19,330 --> 00:48:23,860
this is you know from this little guy
here gets calculated up and you can kind

633
00:48:23,860 --> 00:48:27,760
of adjust it according to your your
organization but at a certain threshold

634
00:48:28,690 --> 00:48:32,620
you're going to want to escalate that up
to the next level of response if it's

635
00:48:32,620 --> 00:48:35,770
below that threshold and that's probably
just something that the help desk can

636
00:48:35,770 --> 00:48:39,040
can can can deal with right

637
00:48:39,040 --> 00:48:42,070
if they're going to reimage of the
elevators malware great you know we're

638
00:48:42,070 --> 00:48:46,150
going to reimage something whatever that
process is so now if we're going up a

639
00:48:46,150 --> 00:48:49,150
level

640
00:48:51,269 --> 00:48:57,779
have to talk about ok we're escalating
this up into here we're going to take a

641
00:48:57,779 --> 00:49:04,739
look at when we break down actual
scenarios of what is bad within our

642
00:49:04,739 --> 00:49:06,089
organization

643
00:49:06,089 --> 00:49:11,130
we're going to look at things like we're
going to rank things in terms of here

644
00:49:11,130 --> 00:49:12,119
right

645
00:49:12,119 --> 00:49:16,829
so I I've got volume 1 through 5 and
here's the descriptions of what those

646
00:49:16,829 --> 00:49:20,880
levels are and whether or not they're
actually associated with and then I

647
00:49:20,880 --> 00:49:25,799
apologize the kill chain and then if we
actually have breaches we're going to

648
00:49:25,799 --> 00:49:29,909
rank these accordingly as well and
here's how we we kind of like describe

649
00:49:29,909 --> 00:49:37,919
those but then when you actually get
back to our escalated are escalated part

650
00:49:37,919 --> 00:49:39,749
of this process

651
00:49:39,749 --> 00:49:43,379
now we have the ability the the sock
team is going to analyze what they just

652
00:49:43,380 --> 00:49:48,209
got asked what just got escalated to
them and says okay based on that ranking

653
00:49:48,209 --> 00:49:53,759
what are we looking at are we looking at
breach one ok well now reach one is an

654
00:49:53,759 --> 00:49:57,869
indication of kill chain for and because
it's kill chain for here's how we're

655
00:49:57,869 --> 00:49:58,949
going to react

656
00:49:58,949 --> 00:50:03,779
all right we need to have at least one
hour response time the accountability is

657
00:50:03,779 --> 00:50:08,999
for the the lead of the the stock itself
the sea so needs to be notified and yes

658
00:50:08,999 --> 00:50:10,919
we're going to have to write a report

659
00:50:10,919 --> 00:50:14,459
ok threat prioritization it's the best

660
00:50:15,569 --> 00:50:22,859
the second thing I want to show and this
is really basically the last thing I

661
00:50:22,859 --> 00:50:24,089
will start with this

662
00:50:24,089 --> 00:50:28,288
remember i talked about the SBS excel
spreadsheet will just do

663
00:50:28,289 --> 00:50:32,400
sorry I

664
00:50:32,400 --> 00:50:37,410
this is the actual SVS expelled excel
spreadsheet the sdlc where the original

665
00:50:37,410 --> 00:50:44,640
asds right so they're not they're not
described here but you know the UH this

666
00:50:44,640 --> 00:50:50,098
a little bit version to hear the two
section to basically look at it so

667
00:50:50,099 --> 00:50:54,569
section 2 might be off authentication or
or I forget exactly specifically what it

668
00:50:54,569 --> 00:50:58,109
was but here are the things that ok
verify all pages and require

669
00:50:58,109 --> 00:51:03,119
authentication and yes that is a
requirement for level 1 therefore its

670
00:51:03,119 --> 00:51:06,839
requirement for level 2 and level 3
going on down the list now we can

671
00:51:06,839 --> 00:51:11,670
basically go through all this and begin
driving the maturity of our development

672
00:51:11,670 --> 00:51:12,839
process

673
00:51:12,839 --> 00:51:17,099
so here is his mind

674
00:51:17,099 --> 00:51:20,279
same thing right for threat management

675
00:51:20,789 --> 00:51:26,339
so now we can basically go through this
whole exercise and determine i'm going

676
00:51:26,339 --> 00:51:34,349
to blow this out a little bit here so
you can kind of see right but two factor

677
00:51:34,349 --> 00:51:37,200
authentication password bowl for
privileged accounts

678
00:51:37,200 --> 00:51:41,339
okay well that's pretty advanced so
that's going to make that's going to

679
00:51:41,339 --> 00:51:42,480
make that level three

680
00:51:42,480 --> 00:51:46,589
right but now we can we have this
framework that we can now begin looking

681
00:51:46,589 --> 00:51:51,029
at our threat management process and
determining where we fall and it's a

682
00:51:51,029 --> 00:51:54,900
pretty simple process is it's a pretty
simple exercise to go through and and

683
00:51:54,900 --> 00:51:58,589
once you determine where you sit now you
can be like okay where do I want to be

684
00:51:58,589 --> 00:52:02,759
who I want to be level to do I want to
be level 3 and what's it going to take

685
00:52:02,760 --> 00:52:08,369
to get there so of this is let me back

686
00:52:08,880 --> 00:52:14,220
get back here and watch this for another
second

687
00:52:14,220 --> 00:52:17,220
oops phone

688
00:52:18,880 --> 00:52:27,279
oh that's a little more time

689
00:52:31,150 --> 00:52:37,029
okay all right anyway so what I just
showed you that the the excel

690
00:52:37,029 --> 00:52:37,990
spreadsheet

691
00:52:37,990 --> 00:52:47,019
that's on github so also the right i put
it in the bowl XL excel spreadsheet and

692
00:52:47,019 --> 00:52:52,538
csv CSP is much easier to kind of like
just edit and tracking and do within get

693
00:52:52,539 --> 00:52:55,990
help from a change control perspective
but here's the thing my vulnerability

694
00:52:55,990 --> 00:52:59,229
management from last year's now there
and the threat management permission

695
00:52:59,230 --> 00:53:04,779
this year's is all there have fun and
please give me some input right

696
00:53:05,349 --> 00:53:09,039
go take these download them if you think
of things that could be you know

697
00:53:09,039 --> 00:53:12,160
improved upon in terms of the other
things that gets you to this particular

698
00:53:12,160 --> 00:53:13,180
level

699
00:53:13,180 --> 00:53:16,450
please do so I'll merge it in that'd be
great

700
00:53:16,450 --> 00:53:21,399
I would love all this to be you know
community collaborative so i think

701
00:53:21,400 --> 00:53:22,089
that's it

702
00:53:22,089 --> 00:53:25,089
mm and I have any questions

703
00:53:25,630 --> 00:53:30,940
I got I got one minute so Nick I'm
probably i'm thinking about doing

704
00:53:30,940 --> 00:53:35,380
identity management next applying
identity management to the SVS so then

705
00:53:35,380 --> 00:53:40,930
at that point every single process
within the within that you know that

706
00:53:40,930 --> 00:53:45,098
this set of processes of the enterprise
security architecture is then done right

707
00:53:45,099 --> 00:53:49,450
because the asp s is the sdlc last year
I did vulnerability management

708
00:53:49,450 --> 00:53:55,390
this is threat management that's what's
left so if anybody has any suggestions

709
00:53:55,390 --> 00:53:56,890
or wants to help out on that

710
00:53:56,890 --> 00:54:00,609
that's it so real quick any questions

711
00:54:00,609 --> 00:54:04,450
here's some references questions sir

712
00:54:04,960 --> 00:54:08,160
yes

713
00:54:08,160 --> 00:54:18,720
mhm mhm questions

714
00:54:20,309 --> 00:54:22,980
ok let's come out

