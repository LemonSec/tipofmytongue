1
00:00:09,840 --> 00:00:11,760
we were talking about a bunch of work

2
00:00:11,760 --> 00:00:13,860
that we've been doing over the past two

3
00:00:13,860 --> 00:00:15,240
and a half getting close to three years

4
00:00:15,240 --> 00:00:16,619
at this point actually you need to come

5
00:00:16,619 --> 00:00:18,060
back over here

6
00:00:18,060 --> 00:00:20,000
uh

7
00:00:20,000 --> 00:00:23,699
in terms of doing uh Assurance of AI

8
00:00:23,699 --> 00:00:26,130
systems

9
00:00:26,130 --> 00:00:29,308
[Music]

10
00:00:31,439 --> 00:00:33,920
foreign

11
00:00:39,780 --> 00:00:42,480
what we mean by Assurance it's it's a

12
00:00:42,480 --> 00:00:44,460
huge topic and I'm going to be talking

13
00:00:44,460 --> 00:00:46,739
to you guys about it a sort of very

14
00:00:46,739 --> 00:00:52,019
narrow slice of it right yeah yeah

15
00:00:52,860 --> 00:00:54,660
um can you guys hear me yeah all right

16
00:00:54,660 --> 00:00:55,860
cool

17
00:00:55,860 --> 00:00:56,520
um

18
00:00:56,520 --> 00:00:58,379
so what we're really all about is

19
00:00:58,379 --> 00:01:00,960
getting at all the different types of

20
00:01:00,960 --> 00:01:04,500
risks that you are tacitly adopting when

21
00:01:04,500 --> 00:01:05,939
you put one of these types of systems

22
00:01:05,939 --> 00:01:09,420
into production right and as I said even

23
00:01:09,420 --> 00:01:11,340
even then scoping it that way you're

24
00:01:11,340 --> 00:01:15,720
talking about a huge huge huge area

25
00:01:15,720 --> 00:01:17,299
um

26
00:01:17,299 --> 00:01:19,979
and I'm only gonna be talking about a

27
00:01:19,979 --> 00:01:22,680
very narrow very specific slice we'll

28
00:01:22,680 --> 00:01:25,860
we'll neck that down but uh in terms of

29
00:01:25,860 --> 00:01:28,439
sort of how we got into this or what

30
00:01:28,439 --> 00:01:30,479
we're doing uh part of a team we've been

31
00:01:30,479 --> 00:01:32,220
doing this for the past two and a half

32
00:01:32,220 --> 00:01:35,579
years a couple of different projects

33
00:01:35,579 --> 00:01:38,059
and

34
00:01:39,299 --> 00:01:41,040
so we kind of got started uh actually

35
00:01:41,040 --> 00:01:44,159
this was my colleague Andrea Brennan

36
00:01:44,159 --> 00:01:46,860
um was sort of asking these these three

37
00:01:46,860 --> 00:01:48,900
questions about these systems right and

38
00:01:48,900 --> 00:01:50,280
she uh

39
00:01:50,280 --> 00:01:52,680
fascinating super smart lady she comes

40
00:01:52,680 --> 00:01:54,180
at it from like a human interface and

41
00:01:54,180 --> 00:01:55,860
design perspective because she's a

42
00:01:55,860 --> 00:01:57,540
designer and an architect by background

43
00:01:57,540 --> 00:01:59,880
so she's asking like

44
00:01:59,880 --> 00:02:02,220
these questions at a huge level and she

45
00:02:02,220 --> 00:02:03,540
was putting together this project that

46
00:02:03,540 --> 00:02:04,680
she wanted to do in the coming year

47
00:02:04,680 --> 00:02:08,520
about doing uh this kind of work and our

48
00:02:08,520 --> 00:02:10,440
leadership above us was like that sounds

49
00:02:10,440 --> 00:02:13,200
super awesome do it now you've got two

50
00:02:13,200 --> 00:02:14,520
months go

51
00:02:14,520 --> 00:02:17,940
and uh so she roped me into it because

52
00:02:17,940 --> 00:02:20,940
for a long time I've been going around

53
00:02:20,940 --> 00:02:22,319
telling anybody who will listen this

54
00:02:22,319 --> 00:02:24,420
thing where it's like right now ai and

55
00:02:24,420 --> 00:02:28,340
ml systems are the specific domain of

56
00:02:28,340 --> 00:02:31,379
very specialized very highly educated

57
00:02:31,379 --> 00:02:34,680
practitioners right and there are very

58
00:02:34,680 --> 00:02:37,140
very few organizations on Earth that can

59
00:02:37,140 --> 00:02:39,599
keep a team of you know PhD level data

60
00:02:39,599 --> 00:02:42,540
scientists on staff to do maintenance

61
00:02:42,540 --> 00:02:45,660
and Ops on these types of systems and

62
00:02:45,660 --> 00:02:48,300
even if you had like the wealth of

63
00:02:48,300 --> 00:02:50,940
croesis that it would take to keep those

64
00:02:50,940 --> 00:02:53,040
people in those jobs they're going to

65
00:02:53,040 --> 00:02:54,780
get bored and leave anyway in my

66
00:02:54,780 --> 00:02:55,920
experience

67
00:02:55,920 --> 00:02:58,920
uh which is not like

68
00:02:58,920 --> 00:03:00,480
first I want to clarify something I'm

69
00:03:00,480 --> 00:03:01,440
going to make a bunch of broad

70
00:03:01,440 --> 00:03:02,940
statements in this talk about data

71
00:03:02,940 --> 00:03:04,319
scientists because I assume there aren't

72
00:03:04,319 --> 00:03:06,180
very many in the room

73
00:03:06,180 --> 00:03:08,220
um I'm not like I'm not trying to rag on

74
00:03:08,220 --> 00:03:09,959
them uh I'm just trying to be very

75
00:03:09,959 --> 00:03:11,519
candid about the fact that they have a

76
00:03:11,519 --> 00:03:13,560
very particular set of skills and they

77
00:03:13,560 --> 00:03:16,620
have a very particular set of incentives

78
00:03:16,620 --> 00:03:18,480
um that are very different from the

79
00:03:18,480 --> 00:03:21,900
skills and incentives we have and like

80
00:03:21,900 --> 00:03:24,420
they need support from us to be able to

81
00:03:24,420 --> 00:03:26,340
to do that so I just want to be very

82
00:03:26,340 --> 00:03:27,840
clear about that so I don't get yelled

83
00:03:27,840 --> 00:03:29,879
at later if I do Angry data scientists

84
00:03:29,879 --> 00:03:31,920
um like you enroll up on the I.T

85
00:03:31,920 --> 00:03:33,599
Department be like hey you guys are

86
00:03:33,599 --> 00:03:35,159
doing great with this computer thing we

87
00:03:35,159 --> 00:03:37,500
need you to run payroll this month no it

88
00:03:37,500 --> 00:03:38,879
would get like

89
00:03:38,879 --> 00:03:41,280
you would get sued out of existence

90
00:03:41,280 --> 00:03:43,860
um so in the same way that you wouldn't

91
00:03:43,860 --> 00:03:46,200
ask the IT department to do payroll you

92
00:03:46,200 --> 00:03:48,000
shouldn't expect your data science team

93
00:03:48,000 --> 00:03:50,340
to be you know operators or Engineers

94
00:03:50,340 --> 00:03:52,379
this stuff has to get moved over the

95
00:03:52,379 --> 00:03:53,459
fence

96
00:03:53,459 --> 00:03:56,819
right for people who can keep long-lived

97
00:03:56,819 --> 00:03:59,459
systems and keep them in check

98
00:03:59,459 --> 00:04:00,360
um

99
00:04:00,360 --> 00:04:02,940
so I've been saying that for ages and

100
00:04:02,940 --> 00:04:04,379
Andrew was like Hey you know how you're

101
00:04:04,379 --> 00:04:05,879
always talking about that well we're

102
00:04:05,879 --> 00:04:07,379
doing a bunch of work around that so

103
00:04:07,379 --> 00:04:10,200
time to put up or shut up

104
00:04:10,200 --> 00:04:12,000
which was awful because then I had to do

105
00:04:12,000 --> 00:04:14,180
work

106
00:04:18,120 --> 00:04:20,390
yeah I tried that it didn't go well ah

107
00:04:20,390 --> 00:04:22,220
[Music]

108
00:04:22,220 --> 00:04:24,479
it is indeed

109
00:04:24,479 --> 00:04:26,160
um so

110
00:04:26,160 --> 00:04:28,740
we we started looking around trying to

111
00:04:28,740 --> 00:04:30,419
to do this stuff and one of the things

112
00:04:30,419 --> 00:04:32,520
that we came across was this document

113
00:04:32,520 --> 00:04:36,000
it's the AI Assurance or the artificial

114
00:04:36,000 --> 00:04:37,800
intelligence ethics framework for the

115
00:04:37,800 --> 00:04:40,139
intelligence community

116
00:04:40,139 --> 00:04:41,400
um

117
00:04:41,400 --> 00:04:43,860
it's a fascinating document

118
00:04:43,860 --> 00:04:45,479
you should take a few minutes and go

119
00:04:45,479 --> 00:04:47,759
read it it's only four pages long and

120
00:04:47,759 --> 00:04:49,259
it's one of those classic Federal

121
00:04:49,259 --> 00:04:51,360
documents where they're like yeah we're

122
00:04:51,360 --> 00:04:52,740
going to give you this four-page PDF

123
00:04:52,740 --> 00:04:55,259
where we knock out 17 or 20 questions

124
00:04:55,259 --> 00:04:57,479
and it's going to take you you know

125
00:04:57,479 --> 00:05:00,180
this to answer right like you could

126
00:05:00,180 --> 00:05:02,220
murder Force trying to answer these

127
00:05:02,220 --> 00:05:04,199
questions and still not get there

128
00:05:04,199 --> 00:05:06,660
uh but I pulled out sort of a couple of

129
00:05:06,660 --> 00:05:08,820
important quotes and the the important

130
00:05:08,820 --> 00:05:10,259
one for the purposes of this talk is

131
00:05:10,259 --> 00:05:12,479
that second one this is not a guide or

132
00:05:12,479 --> 00:05:14,940
checklist right like there's nothing in

133
00:05:14,940 --> 00:05:17,400
here that you can actually do to do this

134
00:05:17,400 --> 00:05:19,440
stuff and so I start asking the question

135
00:05:19,440 --> 00:05:21,780
like well then what are we actually

136
00:05:21,780 --> 00:05:23,639
supposed to do

137
00:05:23,639 --> 00:05:25,340
um

138
00:05:25,340 --> 00:05:28,638
yes yes

139
00:05:31,139 --> 00:05:34,100
well yeah

140
00:05:35,639 --> 00:05:37,620
you said it not me

141
00:05:37,620 --> 00:05:39,660
um

142
00:05:39,660 --> 00:05:43,740
so like we we basically set out to kind

143
00:05:43,740 --> 00:05:44,880
of like

144
00:05:44,880 --> 00:05:47,280
figure out how to do this stuff

145
00:05:47,280 --> 00:05:49,259
and so I want to just kind of run

146
00:05:49,259 --> 00:05:51,960
through what they were really quickly so

147
00:05:51,960 --> 00:05:53,220
you guys understand what I talk about

148
00:05:53,220 --> 00:05:54,900
when I'm referring back to them later

149
00:05:54,900 --> 00:05:57,360
okay so just bear with me but

150
00:05:57,360 --> 00:05:59,580
the first one was the audit of the tool

151
00:05:59,580 --> 00:06:02,400
called fake finder it was actually built

152
00:06:02,400 --> 00:06:04,979
um by an internal team of data

153
00:06:04,979 --> 00:06:06,300
scientists

154
00:06:06,300 --> 00:06:08,280
so it was a great first one to try

155
00:06:08,280 --> 00:06:10,680
because we had Direct access to the

156
00:06:10,680 --> 00:06:12,180
people who built it I could literally

157
00:06:12,180 --> 00:06:13,800
walk over there and be like you know

158
00:06:13,800 --> 00:06:15,960
Mike Felipe what like what is this

159
00:06:15,960 --> 00:06:18,000
supposed to be doing

160
00:06:18,000 --> 00:06:20,699
um it's an open source Tool uh it's out

161
00:06:20,699 --> 00:06:21,900
there on GitHub I think I've got the

162
00:06:21,900 --> 00:06:23,340
GitHub link down there you can go find

163
00:06:23,340 --> 00:06:24,180
it

164
00:06:24,180 --> 00:06:27,240
and what they had actually done was they

165
00:06:27,240 --> 00:06:31,080
had taken the top five performing models

166
00:06:31,080 --> 00:06:33,060
in one of Facebook's debate detection

167
00:06:33,060 --> 00:06:34,580
challenges

168
00:06:34,580 --> 00:06:37,740
and they ensembled them together and

169
00:06:37,740 --> 00:06:39,960
they built a user interface around this

170
00:06:39,960 --> 00:06:41,639
thing so basically it was a website you

171
00:06:41,639 --> 00:06:44,340
could go you upload a video it runs it

172
00:06:44,340 --> 00:06:45,840
through these five different models and

173
00:06:45,840 --> 00:06:47,340
it gives you the results of them with

174
00:06:47,340 --> 00:06:48,539
like your confidence scores and

175
00:06:48,539 --> 00:06:49,800
everything

176
00:06:49,800 --> 00:06:51,960
um like I said this was literally two

177
00:06:51,960 --> 00:06:54,300
people we did this in two months we had

178
00:06:54,300 --> 00:06:58,199
no budget whatsoever so uh a huge driver

179
00:06:58,199 --> 00:07:00,479
in in this work for us was just like

180
00:07:00,479 --> 00:07:03,780
what can we do with no time and no money

181
00:07:03,780 --> 00:07:06,479
that's still useful

182
00:07:06,479 --> 00:07:07,620
um

183
00:07:07,620 --> 00:07:09,840
and uh you can see some of sort of the

184
00:07:09,840 --> 00:07:11,940
key lessons that we took away one of the

185
00:07:11,940 --> 00:07:13,620
things that I thought was like super

186
00:07:13,620 --> 00:07:16,319
interesting about this in particular one

187
00:07:16,319 --> 00:07:17,940
of the things that we found

188
00:07:17,940 --> 00:07:20,280
was uh so if you if you go look at like

189
00:07:20,280 --> 00:07:22,080
the kaggle competition that Facebook did

190
00:07:22,080 --> 00:07:25,919
it was a deep fake detection challenge

191
00:07:25,919 --> 00:07:28,080
but we started playing with the models

192
00:07:28,080 --> 00:07:30,360
it's a face swap detection challenge

193
00:07:30,360 --> 00:07:32,039
there's a bunch of them that actively

194
00:07:32,039 --> 00:07:33,720
crash if you give them a video without a

195
00:07:33,720 --> 00:07:37,259
human facing them which is like

196
00:07:37,259 --> 00:07:39,660
uh one of the things that we we kind of

197
00:07:39,660 --> 00:07:40,979
really started to think about in this in

198
00:07:40,979 --> 00:07:42,840
particular goes back to Andrea like I

199
00:07:42,840 --> 00:07:44,400
said a design you know interface person

200
00:07:44,400 --> 00:07:46,199
she was like this is a really poor job

201
00:07:46,199 --> 00:07:48,180
of communicating what this thing does to

202
00:07:48,180 --> 00:07:49,620
the user they like they have no idea

203
00:07:49,620 --> 00:07:51,060
what to expect because if you tell me

204
00:07:51,060 --> 00:07:53,160
this thing spots deep fake someone think

205
00:07:53,160 --> 00:07:55,139
deep fakes of anything but

206
00:07:55,139 --> 00:07:58,259
it's only looking for face swaps that's

207
00:07:58,259 --> 00:08:00,599
not a useless tool but you have to

208
00:08:00,599 --> 00:08:02,699
phrase that very differently to get

209
00:08:02,699 --> 00:08:05,819
useful you know impact out of it

210
00:08:05,819 --> 00:08:07,199
um so

211
00:08:07,199 --> 00:08:09,960
that was the first one we did

212
00:08:09,960 --> 00:08:13,080
the next one we did was Roberta which is

213
00:08:13,080 --> 00:08:15,120
a large language model

214
00:08:15,120 --> 00:08:16,080
um

215
00:08:16,080 --> 00:08:19,080
it is one of the many many many Forks of

216
00:08:19,080 --> 00:08:21,479
Google's Bert in particular we were

217
00:08:21,479 --> 00:08:23,460
working with hugging faces

218
00:08:23,460 --> 00:08:26,699
version of Roberta and so the way those

219
00:08:26,699 --> 00:08:29,340
large language models get built

220
00:08:29,340 --> 00:08:30,660
kind of fascinating its own right

221
00:08:30,660 --> 00:08:32,039
because

222
00:08:32,039 --> 00:08:34,919
they start off with a large language or

223
00:08:34,919 --> 00:08:37,740
with a huge Corpus of data like

224
00:08:37,740 --> 00:08:40,860
tons of data 100 languages

225
00:08:40,860 --> 00:08:41,399
um

226
00:08:41,399 --> 00:08:45,120
and they train these things very broadly

227
00:08:45,120 --> 00:08:47,700
and then you go back and do a second

228
00:08:47,700 --> 00:08:49,260
training pass

229
00:08:49,260 --> 00:08:51,420
to narrow down what it can actually do

230
00:08:51,420 --> 00:08:53,160
and so if you go look at like hugging

231
00:08:53,160 --> 00:08:55,980
faces of uh repos you'll see that they

232
00:08:55,980 --> 00:08:57,899
don't have just one Roberta model right

233
00:08:57,899 --> 00:08:59,880
it's like Roberta and then there's this

234
00:08:59,880 --> 00:09:01,560
size quantifier which is how much data

235
00:09:01,560 --> 00:09:03,060
it's been trained on and then there's a

236
00:09:03,060 --> 00:09:05,100
sort of a task annotation

237
00:09:05,100 --> 00:09:06,839
which is why I call out that we were

238
00:09:06,839 --> 00:09:08,700
specifically concerned with named entity

239
00:09:08,700 --> 00:09:10,320
recognition because

240
00:09:10,320 --> 00:09:12,360
like if you go and read our stuff we're

241
00:09:12,360 --> 00:09:14,220
always talking about you know hugging

242
00:09:14,220 --> 00:09:17,820
face Roberta XL ner

243
00:09:17,820 --> 00:09:20,760
so just because I was literally just a

244
00:09:20,760 --> 00:09:22,320
second ago saying it's very important to

245
00:09:22,320 --> 00:09:24,959
be precise so I would be a jackass if I

246
00:09:24,959 --> 00:09:27,420
didn't you know narrow my own stuff down

247
00:09:27,420 --> 00:09:29,880
immediately afterwards

248
00:09:29,880 --> 00:09:31,920
um this one was kind of different

249
00:09:31,920 --> 00:09:34,320
from the first one because with fake

250
00:09:34,320 --> 00:09:36,620
finder you've got a whole UI right

251
00:09:36,620 --> 00:09:39,959
there's deployment instructions there as

252
00:09:39,959 --> 00:09:41,640
an established usage pattern and

253
00:09:41,640 --> 00:09:42,899
everything right you know a user is

254
00:09:42,899 --> 00:09:43,920
going to go in and they're going to

255
00:09:43,920 --> 00:09:45,420
upload a video they're going to look at

256
00:09:45,420 --> 00:09:48,480
this chart that comes out and so forth

257
00:09:48,480 --> 00:09:50,580
we didn't have any of that kind of

258
00:09:50,580 --> 00:09:52,980
context looking at Roberta right so we

259
00:09:52,980 --> 00:09:55,800
had to drastically rethink the way that

260
00:09:55,800 --> 00:09:57,540
we were doing these things in a lot of

261
00:09:57,540 --> 00:10:01,500
ways because we made that shift

262
00:10:01,500 --> 00:10:03,000
um so those are the first two we did we

263
00:10:03,000 --> 00:10:04,620
actually have a third one ongoing now

264
00:10:04,620 --> 00:10:07,200
that has some stuff uh involving

265
00:10:07,200 --> 00:10:09,180
Hardware which is adding a new set of

266
00:10:09,180 --> 00:10:11,519
wrinkles to some of this stuff but

267
00:10:11,519 --> 00:10:13,200
hopefully I'll get a chance to talk to

268
00:10:13,200 --> 00:10:14,459
you about later

269
00:10:14,459 --> 00:10:15,899
so

270
00:10:15,899 --> 00:10:17,820
um

271
00:10:17,820 --> 00:10:19,680
I want to take a moment and just nod to

272
00:10:19,680 --> 00:10:23,580
like the bias ethics outcomes piece of

273
00:10:23,580 --> 00:10:25,440
this

274
00:10:25,440 --> 00:10:26,339
um

275
00:10:26,339 --> 00:10:29,279
that's a huge part of assurance uh in

276
00:10:29,279 --> 00:10:31,500
the sense that we've been doing it

277
00:10:31,500 --> 00:10:34,560
um it is

278
00:10:34,560 --> 00:10:37,019
massive we work with some folks at a law

279
00:10:37,019 --> 00:10:39,480
firm called B Hai there are a bunch of

280
00:10:39,480 --> 00:10:42,959
lawyers that specialize in AI stuff so

281
00:10:42,959 --> 00:10:44,820
those were fascinating and very

282
00:10:44,820 --> 00:10:46,620
expensive phone calls

283
00:10:46,620 --> 00:10:47,420
um

284
00:10:47,420 --> 00:10:50,160
but uh but really sharp guys are really

285
00:10:50,160 --> 00:10:51,839
cool to talk to

286
00:10:51,839 --> 00:10:53,519
and I'm not saying that stuff's not

287
00:10:53,519 --> 00:10:55,920
important and you absolutely like should

288
00:10:55,920 --> 00:10:57,600
consider it and think about it and like

289
00:10:57,600 --> 00:10:59,579
you know if you are dealing with one of

290
00:10:59,579 --> 00:11:01,140
these systems and you see something that

291
00:11:01,140 --> 00:11:02,940
gives you concerns in that vein raise it

292
00:11:02,940 --> 00:11:04,620
but

293
00:11:04,620 --> 00:11:08,279
that is not my specialty and I would not

294
00:11:08,279 --> 00:11:10,079
presume to lecture people about that

295
00:11:10,079 --> 00:11:11,640
because

296
00:11:11,640 --> 00:11:15,120
not not my place so I just wanted to let

297
00:11:15,120 --> 00:11:17,339
you know that that is like particularly

298
00:11:17,339 --> 00:11:19,620
if you go look at you know the the odni

299
00:11:19,620 --> 00:11:21,120
document I referenced earlier there's

300
00:11:21,120 --> 00:11:23,279
like three questions about security and

301
00:11:23,279 --> 00:11:25,560
the rest of it is is all about this sort

302
00:11:25,560 --> 00:11:27,800
of thing

303
00:11:28,140 --> 00:11:30,540
you know

304
00:11:30,540 --> 00:11:32,640
I mean someone's got to quantify how

305
00:11:32,640 --> 00:11:34,800
unethical the lawyers are being and only

306
00:11:34,800 --> 00:11:38,359
a lawyer is specialized enough to know

307
00:11:38,519 --> 00:11:40,740
foreign

308
00:11:40,740 --> 00:11:42,300
so with that being said what we're going

309
00:11:42,300 --> 00:11:43,620
to be talking about is the technical

310
00:11:43,620 --> 00:11:47,540
aspect of assurance and uh

311
00:11:47,880 --> 00:11:52,399
that's again much narrower

312
00:11:52,500 --> 00:11:54,360
it's one of those things at least when I

313
00:11:54,360 --> 00:11:56,820
started it seemed very intimidating to

314
00:11:56,820 --> 00:11:58,440
me because I'm like

315
00:11:58,440 --> 00:12:00,240
I don't know how you build hey I don't

316
00:12:00,240 --> 00:12:03,320
know how to build ml models or you know

317
00:12:03,320 --> 00:12:06,240
training data Maya like I took the two

318
00:12:06,240 --> 00:12:08,940
required statistics courses to get my

319
00:12:08,940 --> 00:12:10,920
degree in then you know great out of

320
00:12:10,920 --> 00:12:12,420
that

321
00:12:12,420 --> 00:12:14,040
um so

322
00:12:14,040 --> 00:12:17,279
but the thing is it's

323
00:12:17,279 --> 00:12:20,760
if you stop to think about it like it's

324
00:12:20,760 --> 00:12:22,440
because I'm sure you've all heard like

325
00:12:22,440 --> 00:12:24,959
the same you know news articles and

326
00:12:24,959 --> 00:12:27,000
think pieces that that I get all the

327
00:12:27,000 --> 00:12:29,220
time like AI is this revolutionary new

328
00:12:29,220 --> 00:12:31,260
thing it changes everything it's going

329
00:12:31,260 --> 00:12:32,700
to eat the world it's going to save us

330
00:12:32,700 --> 00:12:34,560
all it's going to kill us all like

331
00:12:34,560 --> 00:12:35,820
whatever you believe about it

332
00:12:35,820 --> 00:12:37,800
everybody's like you know it's totally

333
00:12:37,800 --> 00:12:39,060
way different than anything that came

334
00:12:39,060 --> 00:12:40,980
before uh which brings me to my next

335
00:12:40,980 --> 00:12:43,139
slide this is the single most important

336
00:12:43,139 --> 00:12:46,019
slide in this presentation

337
00:12:46,019 --> 00:12:47,540
foreign

338
00:12:47,540 --> 00:12:50,160
it's not special

339
00:12:50,160 --> 00:12:52,560
they didn't add a two okay it's still

340
00:12:52,560 --> 00:12:54,839
just zeros and ones it's all just

341
00:12:54,839 --> 00:12:57,360
software and computers and networks it's

342
00:12:57,360 --> 00:12:59,040
all the same stuff that you guys know

343
00:12:59,040 --> 00:13:00,959
and have to deal with I know that sounds

344
00:13:00,959 --> 00:13:03,720
really dumb and obvious I spent like a

345
00:13:03,720 --> 00:13:05,579
month grinding my wheels on stuff and I

346
00:13:05,579 --> 00:13:07,500
was like wait a minute

347
00:13:07,500 --> 00:13:09,300
this thing has an API it's sitting on

348
00:13:09,300 --> 00:13:12,540
AWS it's like this is a web form this is

349
00:13:12,540 --> 00:13:14,880
an express.js server this is python like

350
00:13:14,880 --> 00:13:17,459
I know these things I don't understand

351
00:13:17,459 --> 00:13:19,320
what this big Matrix of numbers over

352
00:13:19,320 --> 00:13:21,060
here is doing but I actually don't have

353
00:13:21,060 --> 00:13:22,560
to

354
00:13:22,560 --> 00:13:23,820
um

355
00:13:23,820 --> 00:13:25,860
again as dumb as that sounds that is the

356
00:13:25,860 --> 00:13:28,440
single most important thing it's just

357
00:13:28,440 --> 00:13:30,959
software and you guys already know how

358
00:13:30,959 --> 00:13:33,420
to deal with software

359
00:13:33,420 --> 00:13:35,639
uh if you forget literally everything

360
00:13:35,639 --> 00:13:40,519
else I said remember that just software

361
00:13:42,420 --> 00:13:44,220
so with that being said you do have to

362
00:13:44,220 --> 00:13:46,920
do analysis of the models

363
00:13:46,920 --> 00:13:48,979
um

364
00:13:49,500 --> 00:13:51,779
when they build these things you you

365
00:13:51,779 --> 00:13:53,399
train them on data and you select that

366
00:13:53,399 --> 00:13:54,420
data

367
00:13:54,420 --> 00:13:56,339
I like I like to think that AI actually

368
00:13:56,339 --> 00:13:57,959
stands for assumption intensifier

369
00:13:57,959 --> 00:14:00,660
because that's really all it does it uh

370
00:14:00,660 --> 00:14:02,639
it takes the assumptions that you made

371
00:14:02,639 --> 00:14:04,079
when you picture training data and lets

372
00:14:04,079 --> 00:14:05,639
you run those assumptions at internet

373
00:14:05,639 --> 00:14:09,000
scale uh congratulations I guess I don't

374
00:14:09,000 --> 00:14:12,420
know but uh keep in mind that even if

375
00:14:12,420 --> 00:14:14,040
you can't see them the assumptions that

376
00:14:14,040 --> 00:14:17,459
got made in selecting that data are now

377
00:14:17,459 --> 00:14:19,260
part of your stack and you're stuck with

378
00:14:19,260 --> 00:14:20,700
them

379
00:14:20,700 --> 00:14:22,560
um the other thing is don't get crazy

380
00:14:22,560 --> 00:14:25,440
hung up on this stuff right like

381
00:14:25,440 --> 00:14:27,540
you want to enumerate the risks so you

382
00:14:27,540 --> 00:14:29,100
know what you're looking for and you

383
00:14:29,100 --> 00:14:30,600
know what problems you might have down

384
00:14:30,600 --> 00:14:32,820
the road but you probably can't fix this

385
00:14:32,820 --> 00:14:35,040
model right this is probably not

386
00:14:35,040 --> 00:14:36,660
something that your team or anybody you

387
00:14:36,660 --> 00:14:39,060
have control over developed so you just

388
00:14:39,060 --> 00:14:41,160
kind of kind of like figure out what's

389
00:14:41,160 --> 00:14:43,079
in there and what it's doing what it's

390
00:14:43,079 --> 00:14:45,480
supposed to be doing I just know about

391
00:14:45,480 --> 00:14:47,160
that fact and sort of listed and

392
00:14:47,160 --> 00:14:49,380
document it right um

393
00:14:49,380 --> 00:14:52,500
it's it's actually the the smartest way

394
00:14:52,500 --> 00:14:53,880
that I found a tree these things is

395
00:14:53,880 --> 00:14:55,560
treat them like a black box library

396
00:14:55,560 --> 00:14:57,600
right like you went out and you bought

397
00:14:57,600 --> 00:15:00,360
some dll somewhere and you can use it

398
00:15:00,360 --> 00:15:02,160
like there's a bunch of you know net

399
00:15:02,160 --> 00:15:04,139
controls or whatever in it

400
00:15:04,139 --> 00:15:05,639
um but you can't see what's going on

401
00:15:05,639 --> 00:15:07,740
inside of them you just know I feed it

402
00:15:07,740 --> 00:15:12,420
this input I get this output right so

403
00:15:12,660 --> 00:15:14,779
thank you

404
00:15:15,380 --> 00:15:18,820
[Music]

405
00:15:19,440 --> 00:15:20,040
um

406
00:15:20,040 --> 00:15:22,860
dependency analysis is really beneficial

407
00:15:22,860 --> 00:15:25,019
here because just to install these

408
00:15:25,019 --> 00:15:28,320
things you need to know the dependencies

409
00:15:28,320 --> 00:15:30,300
um keep track of them the the Tuple of

410
00:15:30,300 --> 00:15:32,160
dependency and version is important

411
00:15:32,160 --> 00:15:35,639
because some of these things will be

412
00:15:35,639 --> 00:15:37,500
dependent on multiple versions of the

413
00:15:37,500 --> 00:15:38,820
same library but this is the way they

414
00:15:38,820 --> 00:15:41,420
get built uh it can get a little crazy

415
00:15:41,420 --> 00:15:43,860
and you you can have some interesting

416
00:15:43,860 --> 00:15:45,300
issues that arise out of trying to

417
00:15:45,300 --> 00:15:47,959
reconcile some of those differences but

418
00:15:47,959 --> 00:15:51,779
that's important and then

419
00:15:51,779 --> 00:15:54,120
the thing that I did to deal with the

420
00:15:54,120 --> 00:15:55,740
dependencies that I sort of found useful

421
00:15:55,740 --> 00:15:57,000
because again

422
00:15:57,000 --> 00:15:58,620
we want to get at the risks we're not

423
00:15:58,620 --> 00:16:00,240
trying to say oh like oh look I can pop

424
00:16:00,240 --> 00:16:01,680
this system although if you can that's

425
00:16:01,680 --> 00:16:03,060
great and it's super fun I totally

426
00:16:03,060 --> 00:16:04,440
recommend it

427
00:16:04,440 --> 00:16:05,720
um but

428
00:16:05,720 --> 00:16:08,160
what I found to be helpful was to go

429
00:16:08,160 --> 00:16:10,440
through and kind of bucketize the

430
00:16:10,440 --> 00:16:13,680
dependents or sorry not the dependencies

431
00:16:13,680 --> 00:16:15,180
the the

432
00:16:15,180 --> 00:16:16,800
yeah

433
00:16:16,800 --> 00:16:19,740
um so once you've got those dependencies

434
00:16:19,740 --> 00:16:21,240
you want to cross-reference them with

435
00:16:21,240 --> 00:16:23,639
your usual like vulnerability sources uh

436
00:16:23,639 --> 00:16:26,760
exploit DB the cve databases you know

437
00:16:26,760 --> 00:16:28,920
whatever you typically look at

438
00:16:28,920 --> 00:16:30,420
um and then you want to take those

439
00:16:30,420 --> 00:16:32,100
vulnerabilities that you found and you

440
00:16:32,100 --> 00:16:34,500
will find some I almost guarantee it

441
00:16:34,500 --> 00:16:36,300
and you want to kind of dump them into

442
00:16:36,300 --> 00:16:39,839
three basic groups right these are

443
00:16:39,839 --> 00:16:42,600
unlikely or impossible right

444
00:16:42,600 --> 00:16:45,300
this middle group is plausible and then

445
00:16:45,300 --> 00:16:46,800
these are the things that I think are

446
00:16:46,800 --> 00:16:48,899
likely right and

447
00:16:48,899 --> 00:16:50,699
um what you kind of need to do is look

448
00:16:50,699 --> 00:16:52,980
at your execution paths and think

449
00:16:52,980 --> 00:16:55,500
through like you know uh for instance on

450
00:16:55,500 --> 00:16:57,540
the fake finder audit I was looking at

451
00:16:57,540 --> 00:16:58,980
pillow there was a vulnerability in one

452
00:16:58,980 --> 00:17:00,300
of the versions of pillow which is a

453
00:17:00,300 --> 00:17:04,940
python image manipulation Library

454
00:17:05,040 --> 00:17:05,640
um

455
00:17:05,640 --> 00:17:07,740
and to trigger that vulnerability you

456
00:17:07,740 --> 00:17:09,480
had to be doing something with the alpha

457
00:17:09,480 --> 00:17:10,859
on the in the trade like there was a

458
00:17:10,859 --> 00:17:12,240
particular function it had to pass

459
00:17:12,240 --> 00:17:14,400
through and I knew based on the way we

460
00:17:14,400 --> 00:17:16,140
were using it it wasn't going to go

461
00:17:16,140 --> 00:17:17,939
through that function so I've still got

462
00:17:17,939 --> 00:17:20,220
it in my list it's plausible because it

463
00:17:20,220 --> 00:17:21,599
could be you know still getting used

464
00:17:21,599 --> 00:17:23,819
somewhere else that I'm not necessarily

465
00:17:23,819 --> 00:17:26,220
seeing but I didn't consider it likely

466
00:17:26,220 --> 00:17:27,660
because of the way our execution

467
00:17:27,660 --> 00:17:30,179
patterns Ran So thinking through it that

468
00:17:30,179 --> 00:17:33,860
way was was immensely helpful to me

469
00:17:35,820 --> 00:17:37,799
fuzzing is another

470
00:17:37,799 --> 00:17:40,679
really handy technique here um

471
00:17:40,679 --> 00:17:43,679
so when we did the Roberta audit

472
00:17:43,679 --> 00:17:45,660
I would literally use just like w fuzz

473
00:17:45,660 --> 00:17:47,700
and fluff right like your normal fuzzing

474
00:17:47,700 --> 00:17:50,460
tools the uh

475
00:17:50,460 --> 00:17:52,980
the tricky bit with using regular

476
00:17:52,980 --> 00:17:54,600
fuzzing tools like that or it's not

477
00:17:54,600 --> 00:17:55,980
tricky but

478
00:17:55,980 --> 00:17:57,419
what's going to determine the

479
00:17:57,419 --> 00:17:58,860
effectiveness of those tools when you're

480
00:17:58,860 --> 00:18:00,660
dealing with a language model is

481
00:18:00,660 --> 00:18:02,940
basically like how clever you are at

482
00:18:02,940 --> 00:18:06,720
putting together your word list right

483
00:18:06,720 --> 00:18:08,940
um if you think about it I mean that's

484
00:18:08,940 --> 00:18:10,980
what w fuzz does right like you're

485
00:18:10,980 --> 00:18:12,660
you're running through a word list and

486
00:18:12,660 --> 00:18:14,280
just jamming it in as an input into

487
00:18:14,280 --> 00:18:15,240
something

488
00:18:15,240 --> 00:18:17,700
so how you select that word list is

489
00:18:17,700 --> 00:18:20,580
going to be a really strong

490
00:18:20,580 --> 00:18:22,740
have a really strong impact on how

491
00:18:22,740 --> 00:18:25,380
effective that fuzzing actually is the

492
00:18:25,380 --> 00:18:26,760
other thing to keep in mind when you

493
00:18:26,760 --> 00:18:28,620
start fuzzing particularly large

494
00:18:28,620 --> 00:18:30,900
language models is as I said up front

495
00:18:30,900 --> 00:18:32,880
those things get trained on a hundred

496
00:18:32,880 --> 00:18:35,520
languages 100 plus

497
00:18:35,520 --> 00:18:38,280
um obviously 112 in remembrance case or

498
00:18:38,280 --> 00:18:39,360
something like that

499
00:18:39,360 --> 00:18:42,360
if you only use the ASCII chunk

500
00:18:42,360 --> 00:18:45,600
of the table you are not exercising

501
00:18:45,600 --> 00:18:48,660
things properly you need Unicode I had

502
00:18:48,660 --> 00:18:50,100
to write a big python script that went

503
00:18:50,100 --> 00:18:51,419
like

504
00:18:51,419 --> 00:18:53,640
huge chunks of the Unicode table to

505
00:18:53,640 --> 00:18:55,500
build out word lists but you you can

506
00:18:55,500 --> 00:18:56,820
still get good output you can actually

507
00:18:56,820 --> 00:18:59,580
get some pretty fascinating output uh

508
00:18:59,580 --> 00:19:02,220
one of the things that we found

509
00:19:02,220 --> 00:19:03,620
um

510
00:19:03,620 --> 00:19:06,299
combining languages yields some

511
00:19:06,299 --> 00:19:09,120
fascinating things so uh

512
00:19:09,120 --> 00:19:10,860
and this was uh two of my colleagues

513
00:19:10,860 --> 00:19:13,320
Ricardo calyx and JJ van Joseph they've

514
00:19:13,320 --> 00:19:16,140
actually got a paper out about this

515
00:19:16,140 --> 00:19:18,900
they found that

516
00:19:18,900 --> 00:19:21,419
there's this obscure Taiwanese dialect

517
00:19:21,419 --> 00:19:24,179
called cesion I think and there's this

518
00:19:24,179 --> 00:19:26,160
one very particular token and the token

519
00:19:26,160 --> 00:19:27,900
is like a sub piece of language okay

520
00:19:27,900 --> 00:19:30,240
like you can think of uh sun is a good

521
00:19:30,240 --> 00:19:32,460
example of a token right so Sun can be a

522
00:19:32,460 --> 00:19:34,320
word in its own right but it can also be

523
00:19:34,320 --> 00:19:37,080
like person or it can be part of a name

524
00:19:37,080 --> 00:19:39,900
like Jefferson so

525
00:19:39,900 --> 00:19:40,799
um

526
00:19:40,799 --> 00:19:43,200
it's just weird like

527
00:19:43,200 --> 00:19:46,860
symbol I.E the way it gets represented

528
00:19:46,860 --> 00:19:50,760
but if you just add that onto a word the

529
00:19:50,760 --> 00:19:52,799
way these language models treat it

530
00:19:52,799 --> 00:19:55,860
changes pretty drastically because it's

531
00:19:55,860 --> 00:19:58,440
a pretty rare token because I think

532
00:19:58,440 --> 00:20:00,900
16 000 people in the world speaks Asian

533
00:20:00,900 --> 00:20:03,660
or something like that so it's a uh

534
00:20:03,660 --> 00:20:05,700
things are kind of at the either very

535
00:20:05,700 --> 00:20:07,679
low or very high end of your training

536
00:20:07,679 --> 00:20:09,920
sets have the strange impact sometimes

537
00:20:09,920 --> 00:20:11,340
[Music]

538
00:20:11,340 --> 00:20:14,240
um for for computer vision stuff

539
00:20:14,240 --> 00:20:16,919
the we were we were working at video

540
00:20:16,919 --> 00:20:19,200
with videos but

541
00:20:19,200 --> 00:20:20,340
so

542
00:20:20,340 --> 00:20:22,500
the way those video models actually deal

543
00:20:22,500 --> 00:20:23,880
with anything

544
00:20:23,880 --> 00:20:24,780
um

545
00:20:24,780 --> 00:20:27,600
they don't look at videos they break it

546
00:20:27,600 --> 00:20:30,179
down into frames and then they run

547
00:20:30,179 --> 00:20:32,940
Vision models on the still frames right

548
00:20:32,940 --> 00:20:35,940
uh so so you can cheat

549
00:20:35,940 --> 00:20:38,700
and basically just generate big pixel

550
00:20:38,700 --> 00:20:41,220
arrays and get a similar fuzzing effect

551
00:20:41,220 --> 00:20:43,260
for those we wrote a lot of Python

552
00:20:43,260 --> 00:20:46,500
scripts again uh sort of the same caveat

553
00:20:46,500 --> 00:20:49,020
with the Unicode table applies right you

554
00:20:49,020 --> 00:20:50,700
think of pixels as being just sort of

555
00:20:50,700 --> 00:20:52,740
the RGB and what's this color but

556
00:20:52,740 --> 00:20:54,840
remember because of the way the models

557
00:20:54,840 --> 00:20:55,919
are looking at those things they're

558
00:20:55,919 --> 00:20:57,480
breaking down into numbers so you need

559
00:20:57,480 --> 00:20:58,919
to play with those other things like Hue

560
00:20:58,919 --> 00:21:01,919
and Alpha and saturation to again get

561
00:21:01,919 --> 00:21:06,140
full full Effectiveness from that so

562
00:21:07,440 --> 00:21:09,000
um and then at the end you've got to put

563
00:21:09,000 --> 00:21:11,039
it together like this this was this was

564
00:21:11,039 --> 00:21:14,039
the thing that we I I really thought was

565
00:21:14,039 --> 00:21:16,140
important that we do right uh because if

566
00:21:16,140 --> 00:21:18,059
you look at the AI or sorry the

567
00:21:18,059 --> 00:21:20,400
literature around security for for AI

568
00:21:20,400 --> 00:21:22,559
and ml systems people talk a lot about

569
00:21:22,559 --> 00:21:26,280
like you know backdooring models and uh

570
00:21:26,280 --> 00:21:29,280
can we uh can we do modeling version or

571
00:21:29,280 --> 00:21:31,440
can we ascertain the training data and

572
00:21:31,440 --> 00:21:34,080
like those are Nifty but they ignore the

573
00:21:34,080 --> 00:21:35,760
reality that these things are going to

574
00:21:35,760 --> 00:21:38,940
be jammed into a much larger system and

575
00:21:38,940 --> 00:21:41,460
that system is what users and attackers

576
00:21:41,460 --> 00:21:43,260
are going to interact with not

577
00:21:43,260 --> 00:21:46,679
necessarily the model itself right so

578
00:21:46,679 --> 00:21:48,539
um you need to sort of reflect that in

579
00:21:48,539 --> 00:21:51,900
your testing uh if you you know it's the

580
00:21:51,900 --> 00:21:53,280
same thing as having a bunch of unit

581
00:21:53,280 --> 00:21:54,900
tests and no integration tests right

582
00:21:54,900 --> 00:21:56,520
you're still going to find some Corner

583
00:21:56,520 --> 00:21:58,380
case that that bites you in the ass

584
00:21:58,380 --> 00:22:00,360
because you tested all the pieces

585
00:22:00,360 --> 00:22:01,679
individually but not the way they fit

586
00:22:01,679 --> 00:22:03,919
together

587
00:22:04,620 --> 00:22:07,100
thank you

588
00:22:07,820 --> 00:22:10,260
source code analysis if if you're

589
00:22:10,260 --> 00:22:12,840
dealing with open source systems and

590
00:22:12,840 --> 00:22:14,400
fortunately at least I have had the

591
00:22:14,400 --> 00:22:16,799
luxury of dealing primarily with them uh

592
00:22:16,799 --> 00:22:18,960
this has been incredibly fertile ground

593
00:22:18,960 --> 00:22:20,340
for me

594
00:22:20,340 --> 00:22:22,440
uh sem rep is one of my favorite tools I

595
00:22:22,440 --> 00:22:24,299
run that game like all our CI CD

596
00:22:24,299 --> 00:22:25,860
pipelines it's

597
00:22:25,860 --> 00:22:30,539
just using complex Red X rules to um

598
00:22:30,539 --> 00:22:33,059
to find bad coding patterns

599
00:22:33,059 --> 00:22:35,700
but like the the current Hardware audit

600
00:22:35,700 --> 00:22:38,100
that we have ongoing I've already broken

601
00:22:38,100 --> 00:22:39,780
part of that system like I have a

602
00:22:39,780 --> 00:22:42,000
working hack and it's because I found

603
00:22:42,000 --> 00:22:43,679
something that was flagged by one of my

604
00:22:43,679 --> 00:22:46,559
semcraft scans in our CI CD pipeline my

605
00:22:46,559 --> 00:22:48,419
boss foolishly foolishly got me a steak

606
00:22:48,419 --> 00:22:50,340
dinner so

607
00:22:50,340 --> 00:22:53,760
Whispers is another great one that uh is

608
00:22:53,760 --> 00:22:56,159
looking for like AWS Keys passwords

609
00:22:56,159 --> 00:22:57,900
stuff like that again those are things

610
00:22:57,900 --> 00:22:59,820
that like even if you're just doing with

611
00:22:59,820 --> 00:23:01,320
regular stuff I highly recommend

612
00:23:01,320 --> 00:23:03,240
throwing those in your cicd pipeline

613
00:23:03,240 --> 00:23:04,679
because

614
00:23:04,679 --> 00:23:05,640
um

615
00:23:05,640 --> 00:23:08,280
you know debuggers

616
00:23:08,280 --> 00:23:11,640
um manual manual source code analysis it

617
00:23:11,640 --> 00:23:13,559
has been has been big for me as well

618
00:23:13,559 --> 00:23:15,900
when we did fake finder okay bear with

619
00:23:15,900 --> 00:23:17,159
me for a minute this takes a bit to

620
00:23:17,159 --> 00:23:19,020
explain but it's

621
00:23:19,020 --> 00:23:20,880
it's quite possibly my favorite hack

622
00:23:20,880 --> 00:23:22,679
that I've ever done but it does require

623
00:23:22,679 --> 00:23:25,640
a bit of background so

624
00:23:26,640 --> 00:23:29,280
the way that system was originally built

625
00:23:29,280 --> 00:23:32,940
was spectacularly expensive

626
00:23:32,940 --> 00:23:36,120
uh it lived in AWS entirely

627
00:23:36,120 --> 00:23:40,559
it consisted of eight ec2 instances a UI

628
00:23:40,559 --> 00:23:45,299
an API and six for the underlying models

629
00:23:45,299 --> 00:23:48,120
ah an ECR registry to hold those model

630
00:23:48,120 --> 00:23:51,000
images and an EFS file share holding the

631
00:23:51,000 --> 00:23:54,840
model weights okay very important

632
00:23:54,840 --> 00:23:56,760
I was looking at the source code and I

633
00:23:56,760 --> 00:24:00,059
noticed that when a user uploaded the

634
00:24:00,059 --> 00:24:03,419
video file they saved it into the file

635
00:24:03,419 --> 00:24:04,620
system

636
00:24:04,620 --> 00:24:06,299
and this actually goes into my next

637
00:24:06,299 --> 00:24:07,980
slide a little bit but

638
00:24:07,980 --> 00:24:08,580
um

639
00:24:08,580 --> 00:24:11,700
they saved it into the file system and

640
00:24:11,700 --> 00:24:14,280
they did so in the most naive way

641
00:24:14,280 --> 00:24:16,500
possible they did not sanitize the input

642
00:24:16,500 --> 00:24:19,020
data at all they assumed that whatever

643
00:24:19,020 --> 00:24:21,299
file name the user handed them for this

644
00:24:21,299 --> 00:24:24,059
model was for this video was totally

645
00:24:24,059 --> 00:24:25,860
okay

646
00:24:25,860 --> 00:24:28,320
and so this allowed me to start

647
00:24:28,320 --> 00:24:30,419
overwriting files in the system and

648
00:24:30,419 --> 00:24:31,679
because it was being run with debug

649
00:24:31,679 --> 00:24:34,460
equals true

650
00:24:34,620 --> 00:24:36,739
um

651
00:24:37,380 --> 00:24:39,900
you look so sad but you have the same

652
00:24:39,900 --> 00:24:42,900
reaction that I did but I I won this one

653
00:24:42,900 --> 00:24:45,059
so I'm able to look back and laugh

654
00:24:45,059 --> 00:24:47,159
um so conveniently like would restart

655
00:24:47,159 --> 00:24:48,960
things when I broke everything

656
00:24:48,960 --> 00:24:51,059
um I was able to insert an endpoint into

657
00:24:51,059 --> 00:24:54,720
the API that would accept base64 encoded

658
00:24:54,720 --> 00:24:56,159
commands for me and do whatever I told

659
00:24:56,159 --> 00:24:57,179
it to

660
00:24:57,179 --> 00:24:59,880
I was all able to overwrite another file

661
00:24:59,880 --> 00:25:02,700
that was being passed via Moto 3 which

662
00:25:02,700 --> 00:25:05,039
is the interaction point for aws's API

663
00:25:05,039 --> 00:25:06,720
now that they were using to spin up new

664
00:25:06,720 --> 00:25:08,940
machines this file was being passed it

665
00:25:08,940 --> 00:25:11,900
as a startup script

666
00:25:14,460 --> 00:25:16,380
by the time it was over so the script

667
00:25:16,380 --> 00:25:18,000
that I wrote to attack this whole system

668
00:25:18,000 --> 00:25:21,240
it took about uh 30 minutes or so to run

669
00:25:21,240 --> 00:25:23,520
by the time this attack was done running

670
00:25:23,520 --> 00:25:28,080
I had taken seven of those ec2 instances

671
00:25:28,080 --> 00:25:31,380
over and enrolled them in my C2 server I

672
00:25:31,380 --> 00:25:34,020
had poisoned all of the images

673
00:25:34,020 --> 00:25:36,179
in their ECR

674
00:25:36,179 --> 00:25:39,000
okay with exact copies of those

675
00:25:39,000 --> 00:25:41,279
instances that did the exact same thing

676
00:25:41,279 --> 00:25:42,960
they were supposed to except that when

677
00:25:42,960 --> 00:25:44,460
they came up they also enrolled

678
00:25:44,460 --> 00:25:46,080
themselves in my CQ server so even if

679
00:25:46,080 --> 00:25:47,400
they blew it away and just pulled their

680
00:25:47,400 --> 00:25:49,500
images back down guess what I'm still in

681
00:25:49,500 --> 00:25:50,760
charge

682
00:25:50,760 --> 00:25:52,500
um I poisoned the weights on the EFS

683
00:25:52,500 --> 00:25:54,539
file share the only thing I didn't have

684
00:25:54,539 --> 00:25:56,880
control over was the actual UI server

685
00:25:56,880 --> 00:25:58,440
and I was literally sitting there going

686
00:25:58,440 --> 00:26:00,659
I don't care at this point I own

687
00:26:00,659 --> 00:26:03,539
everything else down the tune I showed

688
00:26:03,539 --> 00:26:04,559
that I

689
00:26:04,559 --> 00:26:06,779
the best part of it is I showed our I.T

690
00:26:06,779 --> 00:26:08,159
Department the guys were in charge of

691
00:26:08,159 --> 00:26:10,440
like our AWS instances what I had done

692
00:26:10,440 --> 00:26:11,940
and I was like I made them sit there

693
00:26:11,940 --> 00:26:14,039
while the script ran like the output and

694
00:26:14,039 --> 00:26:16,260
everything and uh

695
00:26:16,260 --> 00:26:18,840
the the head of the group that's

696
00:26:18,840 --> 00:26:21,360
responsible for the AWS stuff looked at

697
00:26:21,360 --> 00:26:23,520
me and he's like so so you're more like

698
00:26:23,520 --> 00:26:26,940
chaotic evil or neutral evil I'm just

699
00:26:26,940 --> 00:26:29,100
for our records we need to know uh but

700
00:26:29,100 --> 00:26:33,000
it was it was so fun to watch them uh so

701
00:26:33,000 --> 00:26:36,840
again uh the the normal tools have used

702
00:26:36,840 --> 00:26:39,059
for API testing are incredibly useful

703
00:26:39,059 --> 00:26:40,320
here

704
00:26:40,320 --> 00:26:42,840
um and and like I said don't just think

705
00:26:42,840 --> 00:26:45,960
about the model those interstitial

706
00:26:45,960 --> 00:26:48,840
bits right are they saving stuff to the

707
00:26:48,840 --> 00:26:50,100
file system are they putting stuff in

708
00:26:50,100 --> 00:26:52,559
the database like those are things that

709
00:26:52,559 --> 00:26:54,720
you can Target that you can pivot on uh

710
00:26:54,720 --> 00:26:57,419
that you can leak information from so

711
00:26:57,419 --> 00:26:59,640
consider those carefully as well when

712
00:26:59,640 --> 00:27:00,779
you're looking at the architecture of

713
00:27:00,779 --> 00:27:03,080
these things

714
00:27:07,799 --> 00:27:09,600
um

715
00:27:09,600 --> 00:27:11,400
you know and then again application

716
00:27:11,400 --> 00:27:13,740
testing um

717
00:27:13,740 --> 00:27:15,419
and I feel like I keep saying this over

718
00:27:15,419 --> 00:27:18,659
and over again this is very similar to

719
00:27:18,659 --> 00:27:21,120
the way you approach this in normal

720
00:27:21,120 --> 00:27:23,100
application testing right what are the

721
00:27:23,100 --> 00:27:25,140
component pieces how do they talk to

722
00:27:25,140 --> 00:27:26,640
each other what are the data types that

723
00:27:26,640 --> 00:27:28,020
flow between them the entity

724
00:27:28,020 --> 00:27:30,419
relationships I mean the same sorts of

725
00:27:30,419 --> 00:27:32,520
like mapping tools and things that you

726
00:27:32,520 --> 00:27:35,700
normally use again come in really handy

727
00:27:35,700 --> 00:27:36,720
here

728
00:27:36,720 --> 00:27:38,640
they you know

729
00:27:38,640 --> 00:27:40,679
again it's it's still just software

730
00:27:40,679 --> 00:27:42,179
testing you just have to keep a couple

731
00:27:42,179 --> 00:27:44,279
of weird little tweaks in mind to sort

732
00:27:44,279 --> 00:27:45,360
of get the most out of what you're

733
00:27:45,360 --> 00:27:46,919
trying to do

734
00:27:46,919 --> 00:27:49,380
um but but again like this is this is

735
00:27:49,380 --> 00:27:51,120
all things that that people who do this

736
00:27:51,120 --> 00:27:53,700
for a living are capable of it's just we

737
00:27:53,700 --> 00:27:55,140
tend to think that this is a different

738
00:27:55,140 --> 00:27:56,460
thing

739
00:27:56,460 --> 00:27:57,600
um

740
00:27:57,600 --> 00:27:59,880
one thing that is kind of different that

741
00:27:59,880 --> 00:28:01,200
I do want to take a minute to talk about

742
00:28:01,200 --> 00:28:02,700
is the development environments for

743
00:28:02,700 --> 00:28:03,779
these things

744
00:28:03,779 --> 00:28:05,659
um

745
00:28:05,659 --> 00:28:08,460
IPython is the big one and that

746
00:28:08,460 --> 00:28:11,460
is the construct that sits underneath of

747
00:28:11,460 --> 00:28:14,220
both collab and Jupiter notebook

748
00:28:14,220 --> 00:28:16,279
um

749
00:28:16,980 --> 00:28:18,960
those environments are frightening to me

750
00:28:18,960 --> 00:28:21,659
as a security person because I really I

751
00:28:21,659 --> 00:28:23,159
would like to know the person who made

752
00:28:23,159 --> 00:28:24,900
the Command Decision it's like what

753
00:28:24,900 --> 00:28:26,520
we're going to do is we're going to

754
00:28:26,520 --> 00:28:28,200
stand up a little web server on your

755
00:28:28,200 --> 00:28:29,820
computer but we're going to give it a

756
00:28:29,820 --> 00:28:31,200
bunch of permissions we're going to let

757
00:28:31,200 --> 00:28:33,240
it execute arbitrary Python and

758
00:28:33,240 --> 00:28:36,299
JavaScript code uh with with weird data

759
00:28:36,299 --> 00:28:38,520
files and we'll give it like user access

760
00:28:38,520 --> 00:28:41,039
to the system I I don't like who green

761
00:28:41,039 --> 00:28:42,480
like that

762
00:28:42,480 --> 00:28:43,200
um

763
00:28:43,200 --> 00:28:44,820
but that's how those things have to work

764
00:28:44,820 --> 00:28:47,520
right like if you go look at an ipy and

765
00:28:47,520 --> 00:28:49,620
B file which is the file format that

766
00:28:49,620 --> 00:28:51,659
needs to spit out it's

767
00:28:51,659 --> 00:28:54,720
it's actually a Json file

768
00:28:54,720 --> 00:28:58,380
that has HTML Python and JavaScript and

769
00:28:58,380 --> 00:29:00,840
raw text jumbled up together inside of

770
00:29:00,840 --> 00:29:01,620
it

771
00:29:01,620 --> 00:29:02,700
um

772
00:29:02,700 --> 00:29:07,620
and uh so I when we started

773
00:29:07,620 --> 00:29:08,700
hmm

774
00:29:08,700 --> 00:29:09,659
oh

775
00:29:09,659 --> 00:29:11,400
so uh when we started there was actually

776
00:29:11,400 --> 00:29:13,559
a thing going around it was a worm that

777
00:29:13,559 --> 00:29:14,880
was going around it was being passed

778
00:29:14,880 --> 00:29:16,140
through Jupiter notebooks and that

779
00:29:16,140 --> 00:29:18,299
started getting interested in that sort

780
00:29:18,299 --> 00:29:19,380
of thing and I started kind of like

781
00:29:19,380 --> 00:29:21,419
digging into it and seeing

782
00:29:21,419 --> 00:29:24,140
um so

783
00:29:25,080 --> 00:29:27,179
right here I am going to take a moment

784
00:29:27,179 --> 00:29:29,460
to my own horn I found two cves in

785
00:29:29,460 --> 00:29:30,720
Jupiter notebook

786
00:29:30,720 --> 00:29:32,640
technically technically it was the same

787
00:29:32,640 --> 00:29:35,039
one they had implemented the exact same

788
00:29:35,039 --> 00:29:37,279
mistake twice in two different places

789
00:29:37,279 --> 00:29:39,840
but if you go look at the databases two

790
00:29:39,840 --> 00:29:42,539
entries so I'm claiming it as two wings

791
00:29:42,539 --> 00:29:43,919
um

792
00:29:43,919 --> 00:29:47,179
uh long story short

793
00:29:47,220 --> 00:29:49,020
they're

794
00:29:49,020 --> 00:29:51,299
um like I said these things have access

795
00:29:51,299 --> 00:29:53,640
to the file system as the user that

796
00:29:53,640 --> 00:29:56,360
started it up

797
00:29:57,059 --> 00:29:59,640
um and so

798
00:29:59,640 --> 00:30:01,799
it gives you this nice little tree view

799
00:30:01,799 --> 00:30:03,299
of the file system off to the left side

800
00:30:03,299 --> 00:30:04,500
right like here's your directory

801
00:30:04,500 --> 00:30:06,360
structure here's everything you know all

802
00:30:06,360 --> 00:30:08,520
the files you can interact with

803
00:30:08,520 --> 00:30:11,039
the API underneath of that

804
00:30:11,039 --> 00:30:13,620
wasn't respecting settings about hidden

805
00:30:13,620 --> 00:30:17,580
files and so if you knew where a file

806
00:30:17,580 --> 00:30:20,159
was there was either hidden itself or in

807
00:30:20,159 --> 00:30:22,080
a hidden folder and you went and asked

808
00:30:22,080 --> 00:30:24,299
the API for it it would just cough it up

809
00:30:24,299 --> 00:30:26,039
and hand it over to you

810
00:30:26,039 --> 00:30:27,960
um which was super great

811
00:30:27,960 --> 00:30:31,320
because like I I literally went through

812
00:30:31,320 --> 00:30:33,120
and a bunch of the data scientists I

813
00:30:33,120 --> 00:30:34,860
work with I I stood over the shoulder I

814
00:30:34,860 --> 00:30:37,440
was like start Jupiter notebook for me

815
00:30:37,440 --> 00:30:39,960
so all I ask them to do and they all did

816
00:30:39,960 --> 00:30:41,760
the exact same thing they pulled up a

817
00:30:41,760 --> 00:30:43,500
terminal it's sitting there and killed

818
00:30:43,500 --> 00:30:45,360
it their home folder right

819
00:30:45,360 --> 00:30:46,860
Jupiter notebook

820
00:30:46,860 --> 00:30:49,620
starting like okay cool you've answered

821
00:30:49,620 --> 00:30:51,059
my question

822
00:30:51,059 --> 00:30:51,779
um

823
00:30:51,779 --> 00:30:53,399
because that means now I can dump

824
00:30:53,399 --> 00:30:56,520
right.ssh uh ID underscore RSA I've got

825
00:30:56,520 --> 00:30:58,679
their creds I can move across it

826
00:30:58,679 --> 00:30:59,600
um

827
00:30:59,600 --> 00:31:03,179
right uh the I wrote a fun POC for this

828
00:31:03,179 --> 00:31:05,399
that modified the dot bash RC file so

829
00:31:05,399 --> 00:31:07,440
when you started a new session it would

830
00:31:07,440 --> 00:31:09,360
just start sending commands and such

831
00:31:09,360 --> 00:31:11,460
back to me that was a fun one

832
00:31:11,460 --> 00:31:12,419
um

833
00:31:12,419 --> 00:31:14,640
another thing I noticed is when you

834
00:31:14,640 --> 00:31:17,460
start it by default it's token author it

835
00:31:17,460 --> 00:31:18,600
uses something called token

836
00:31:18,600 --> 00:31:21,059
authentication right so it creates a a

837
00:31:21,059 --> 00:31:23,399
randomized user token

838
00:31:23,399 --> 00:31:25,140
so this is a bit of a chicken and egg

839
00:31:25,140 --> 00:31:26,460
but this is actually how I first found

840
00:31:26,460 --> 00:31:27,840
it so it's kind of interesting at least

841
00:31:27,840 --> 00:31:29,940
to me I was trying to exploit this this

842
00:31:29,940 --> 00:31:34,320
xss vulnerability that existed and uh I

843
00:31:34,320 --> 00:31:36,539
found out that it wasn't properly hiding

844
00:31:36,539 --> 00:31:38,220
hidden files and so I realized I could

845
00:31:38,220 --> 00:31:40,200
probably dig out the file that had the

846
00:31:40,200 --> 00:31:43,740
token in it so uh theoretically like

847
00:31:43,740 --> 00:31:45,240
okay in theory you already have to be

848
00:31:45,240 --> 00:31:47,340
authenticated to be able to do that but

849
00:31:47,340 --> 00:31:49,140
the other possibility there is that

850
00:31:49,140 --> 00:31:50,880
somebody's running a compromised browser

851
00:31:50,880 --> 00:31:51,720
because

852
00:31:51,720 --> 00:31:53,100
you know how many people are doing that

853
00:31:53,100 --> 00:31:54,059
right

854
00:31:54,059 --> 00:31:55,620
um nobody

855
00:31:55,620 --> 00:31:58,020
uh so yeah there was a way to get out

856
00:31:58,020 --> 00:32:00,539
that token or that same hidden file in

857
00:32:00,539 --> 00:32:03,419
the home directory has the

858
00:32:03,419 --> 00:32:05,880
something notebooks.db it's literally

859
00:32:05,880 --> 00:32:08,399
like the root trust file the Jupiter

860
00:32:08,399 --> 00:32:09,899
notebook and Jupiter server used to

861
00:32:09,899 --> 00:32:12,000
decide which cells are trusted which

862
00:32:12,000 --> 00:32:14,580
trusted here meaning can be run without

863
00:32:14,580 --> 00:32:16,740
user interaction so if you start

864
00:32:16,740 --> 00:32:18,840
monkeying with that and It's tricky to

865
00:32:18,840 --> 00:32:20,820
do because there's a complicated

866
00:32:20,820 --> 00:32:22,919
signature algorithm that has to match up

867
00:32:22,919 --> 00:32:24,720
for it to think that the thing is so

868
00:32:24,720 --> 00:32:26,700
it's not trivial but you could in theory

869
00:32:26,700 --> 00:32:29,460
monkey with that that trust situation I

870
00:32:29,460 --> 00:32:30,659
was never able to get it actually

871
00:32:30,659 --> 00:32:32,760
working properly but maybe somebody

872
00:32:32,760 --> 00:32:35,100
smarter than you could

873
00:32:35,100 --> 00:32:37,219
um

874
00:32:37,380 --> 00:32:40,440
So based on that like

875
00:32:40,440 --> 00:32:44,399
managing the stuff major recommendations

876
00:32:44,399 --> 00:32:47,039
there's an allow root bit do not let

877
00:32:47,039 --> 00:32:49,679
them use that stop that

878
00:32:49,679 --> 00:32:51,419
um that's the first one

879
00:32:51,419 --> 00:32:54,059
uh and the the reason you'll usually see

880
00:32:54,059 --> 00:32:55,679
that is if they're running it in a

881
00:32:55,679 --> 00:32:59,159
Docker container instead of instead of

882
00:32:59,159 --> 00:33:00,899
structuring their Docker container with

883
00:33:00,899 --> 00:33:02,940
the proper permissions to run as a

884
00:33:02,940 --> 00:33:04,260
different user they'll just go oh we'll

885
00:33:04,260 --> 00:33:06,840
just set allow root equal true well no

886
00:33:06,840 --> 00:33:08,279
because particularly if that's a

887
00:33:08,279 --> 00:33:10,200
privileged container now I'm just out on

888
00:33:10,200 --> 00:33:11,640
your Hardware

889
00:33:11,640 --> 00:33:12,720
um

890
00:33:12,720 --> 00:33:14,880
that's actually one of the other things

891
00:33:14,880 --> 00:33:16,200
I found that's going on in the hardware

892
00:33:16,200 --> 00:33:18,419
audit there's one of these with allow we

893
00:33:18,419 --> 00:33:20,760
would end a privileged container sitting

894
00:33:20,760 --> 00:33:22,200
next to it so that's my current project

895
00:33:22,200 --> 00:33:24,480
is getting from now into that one

896
00:33:24,480 --> 00:33:25,380
um

897
00:33:25,380 --> 00:33:28,500
but um don't put it in system like

898
00:33:28,500 --> 00:33:30,539
sensitive places right home directories

899
00:33:30,539 --> 00:33:33,480
no us I saw one somebody would put it in

900
00:33:33,480 --> 00:33:36,539
uh just the file rudeness God why would

901
00:33:36,539 --> 00:33:40,620
you do this uh so wall goes off put like

902
00:33:40,620 --> 00:33:42,659
you know

903
00:33:42,659 --> 00:33:44,760
make C slash notebooks or something like

904
00:33:44,760 --> 00:33:46,080
that something where it's just that

905
00:33:46,080 --> 00:33:48,059
because I will give the the Jupiter

906
00:33:48,059 --> 00:33:49,919
folks credit it's very it won't let you

907
00:33:49,919 --> 00:33:51,960
Traverse above what the notebook

908
00:33:51,960 --> 00:33:54,360
directory is set at

909
00:33:54,360 --> 00:33:55,919
um so as long as you just narrow that

910
00:33:55,919 --> 00:33:59,220
down that that's very good and then uh

911
00:33:59,220 --> 00:34:01,399
foreign

912
00:34:03,740 --> 00:34:06,000
by default it only wants to listen on

913
00:34:06,000 --> 00:34:07,440
the loopback

914
00:34:07,440 --> 00:34:09,659
um again people being lazy will set it

915
00:34:09,659 --> 00:34:11,159
to zero zero not zero because I just

916
00:34:11,159 --> 00:34:13,520
want to listen to everything

917
00:34:13,520 --> 00:34:16,020
your facial expressions mirror my like

918
00:34:16,020 --> 00:34:19,560
day to day uh I feel like you and I must

919
00:34:19,560 --> 00:34:21,540
work with similar people

920
00:34:21,540 --> 00:34:23,659
um

921
00:34:25,379 --> 00:34:28,800
it really is it's

922
00:34:28,800 --> 00:34:31,040
I

923
00:34:31,040 --> 00:34:33,739
so uh

924
00:34:33,739 --> 00:34:36,300
my my thinking is and I've seen this

925
00:34:36,300 --> 00:34:38,940
sort of in a couple of of things that

926
00:34:38,940 --> 00:34:40,080
I've done over the past few years

927
00:34:40,080 --> 00:34:42,359
because I also did some work uh on some

928
00:34:42,359 --> 00:34:44,719
5G stuff with open 5gs

929
00:34:44,719 --> 00:34:48,599
and uh I I think what's happened in a

930
00:34:48,599 --> 00:34:51,480
lot of ways is that people who

931
00:34:51,480 --> 00:34:53,760
previously didn't do software for

932
00:34:53,760 --> 00:34:55,379
various reasons right status issues

933
00:34:55,379 --> 00:34:57,240
didn't really do software for 10 years

934
00:34:57,240 --> 00:34:59,520
uh RF people didn't really do software

935
00:34:59,520 --> 00:35:02,339
10 years ago but now you know

936
00:35:02,339 --> 00:35:03,980
um data science has brought

937
00:35:03,980 --> 00:35:05,540
statisticians and software

938
00:35:05,540 --> 00:35:07,500
software-defined radio has brought RF

939
00:35:07,500 --> 00:35:09,420
people into software and

940
00:35:09,420 --> 00:35:11,160
they're making a lot of the same

941
00:35:11,160 --> 00:35:13,260
mistakes and errors that we as software

942
00:35:13,260 --> 00:35:15,900
people made back in like the late 90s

943
00:35:15,900 --> 00:35:18,359
and early 2000s we were all like

944
00:35:18,359 --> 00:35:20,400
like you guys look like you're old

945
00:35:20,400 --> 00:35:21,540
enough to remember back in the day when

946
00:35:21,540 --> 00:35:23,460
we would be like oh we'll just put it

947
00:35:23,460 --> 00:35:24,900
behind the firewall and then this is

948
00:35:24,900 --> 00:35:27,780
fine right like it's like oh they're

949
00:35:27,780 --> 00:35:29,400
redoing all the same dumb crap that we

950
00:35:29,400 --> 00:35:30,780
did back then

951
00:35:30,780 --> 00:35:32,760
um which again going back to my earlier

952
00:35:32,760 --> 00:35:34,859
Point like they shouldn't have to be

953
00:35:34,859 --> 00:35:37,020
experts we are the experts in this thing

954
00:35:37,020 --> 00:35:38,640
we should be the ones supporting them

955
00:35:38,640 --> 00:35:40,200
and going hey you can't do this like

956
00:35:40,200 --> 00:35:41,760
this here's how you make it better right

957
00:35:41,760 --> 00:35:43,020
like

958
00:35:43,020 --> 00:35:45,020
um

959
00:35:45,300 --> 00:35:47,280
updating on these things gets

960
00:35:47,280 --> 00:35:49,880
interesting though

961
00:35:50,280 --> 00:35:52,920
yeah it gets ugly is actually what it

962
00:35:52,920 --> 00:35:54,180
gets

963
00:35:54,180 --> 00:35:54,900
um

964
00:35:54,900 --> 00:35:57,900
because they tend to end up super hard

965
00:35:57,900 --> 00:35:59,640
locked to

966
00:35:59,640 --> 00:36:02,760
one or two of typically those six

967
00:36:02,760 --> 00:36:04,380
libraries there's some other ones but

968
00:36:04,380 --> 00:36:07,680
those six are the big ones and um

969
00:36:07,680 --> 00:36:09,660
because those six tend to be tightly

970
00:36:09,660 --> 00:36:11,880
coupled to things like Cuda drivers

971
00:36:11,880 --> 00:36:13,619
kernel versions and all sorts of things

972
00:36:13,619 --> 00:36:15,480
it becomes a mess when you try to update

973
00:36:15,480 --> 00:36:17,660
them

974
00:36:18,839 --> 00:36:20,460
and and you have to you have to manage

975
00:36:20,460 --> 00:36:21,660
it carefully and the other thing you

976
00:36:21,660 --> 00:36:23,760
have to realize is that

977
00:36:23,760 --> 00:36:24,660
um

978
00:36:24,660 --> 00:36:26,460
so

979
00:36:26,460 --> 00:36:28,560
uh I've talked a lot about the fake

980
00:36:28,560 --> 00:36:30,540
finder on it when that was over they

981
00:36:30,540 --> 00:36:32,579
were like you found all this stuff and

982
00:36:32,579 --> 00:36:33,960
this stuff is really terrible and that's

983
00:36:33,960 --> 00:36:36,660
great like yes that's

984
00:36:36,660 --> 00:36:39,540
and then they were like now fix it I was

985
00:36:39,540 --> 00:36:40,260
like

986
00:36:40,260 --> 00:36:42,599
manner

987
00:36:42,599 --> 00:36:44,460
so that was like the next six weeks of

988
00:36:44,460 --> 00:36:47,099
my life and it was it was not fun

989
00:36:47,099 --> 00:36:48,540
um but we got it fixed and one of the

990
00:36:48,540 --> 00:36:49,980
things that I did

991
00:36:49,980 --> 00:36:52,680
was I realized that you didn't actually

992
00:36:52,680 --> 00:36:55,260
need ec2 instances for each model right

993
00:36:55,260 --> 00:36:57,960
like they were all using the same

994
00:36:57,960 --> 00:37:01,800
um API Factory pattern to talk so it's

995
00:37:01,800 --> 00:37:03,960
like you can add just one more parameter

996
00:37:03,960 --> 00:37:05,820
telling it which model you want and

997
00:37:05,820 --> 00:37:07,520
you'll get the exact same behavior and

998
00:37:07,520 --> 00:37:10,200
so I said it was crazy expensive to run

999
00:37:10,200 --> 00:37:11,760
I meant it this thing literally cost

1000
00:37:11,760 --> 00:37:15,359
like 900 a month just sitting in AWS not

1001
00:37:15,359 --> 00:37:17,640
doing anything just nine hundred dollars

1002
00:37:17,640 --> 00:37:20,280
just to exist

1003
00:37:20,280 --> 00:37:20,940
um

1004
00:37:20,940 --> 00:37:23,280
when we got rid of a bunch of those big

1005
00:37:23,280 --> 00:37:25,140
GPU enabled instances that were mostly

1006
00:37:25,140 --> 00:37:27,119
sitting there doing nothing

1007
00:37:27,119 --> 00:37:29,040
um it went we got it down to like 30 40

1008
00:37:29,040 --> 00:37:31,079
bucks a month which was a huge win in my

1009
00:37:31,079 --> 00:37:32,220
opinion

1010
00:37:32,220 --> 00:37:33,599
um and most people's opinion because you

1011
00:37:33,599 --> 00:37:35,880
know that's 760 some odd dollars right

1012
00:37:35,880 --> 00:37:37,380
whatever

1013
00:37:37,380 --> 00:37:38,460
um

1014
00:37:38,460 --> 00:37:41,160
one of the things that I did is I had to

1015
00:37:41,160 --> 00:37:43,560
bring all these different models down to

1016
00:37:43,560 --> 00:37:45,839
have the same set of dependencies so

1017
00:37:45,839 --> 00:37:47,339
that I can install them in the container

1018
00:37:47,339 --> 00:37:49,140
where they're going to be run

1019
00:37:49,140 --> 00:37:51,180
and uh

1020
00:37:51,180 --> 00:37:54,060
what I found was that actually changed

1021
00:37:54,060 --> 00:37:57,839
some of the outputs not like hugely but

1022
00:37:57,839 --> 00:38:00,060
when you're talking about probabilistic

1023
00:38:00,060 --> 00:38:03,540
data right like probabilistic outputs

1024
00:38:03,540 --> 00:38:05,160
um

1025
00:38:05,160 --> 00:38:07,140
you you get these changes you know

1026
00:38:07,140 --> 00:38:09,540
probabilities right it's not like uh you

1027
00:38:09,540 --> 00:38:11,160
know you run normal unit tests it's like

1028
00:38:11,160 --> 00:38:13,200
okay this added two and two and it got

1029
00:38:13,200 --> 00:38:15,240
four check it passes right this is like

1030
00:38:15,240 --> 00:38:16,800
this

1031
00:38:16,800 --> 00:38:19,320
this is approximating adding two and two

1032
00:38:19,320 --> 00:38:21,240
and it thinks that there's a 97 chance

1033
00:38:21,240 --> 00:38:23,220
that it's for uh but now when we update

1034
00:38:23,220 --> 00:38:25,320
it it's a 92 chance

1035
00:38:25,320 --> 00:38:27,960
and so the thing that um that I started

1036
00:38:27,960 --> 00:38:29,280
really thinking about there

1037
00:38:29,280 --> 00:38:31,740
was again I said all these models were

1038
00:38:31,740 --> 00:38:33,839
winners of a kaggle competition that's

1039
00:38:33,839 --> 00:38:36,780
important because they're trying to win

1040
00:38:36,780 --> 00:38:40,320
a contest right like they are focused

1041
00:38:40,320 --> 00:38:42,660
like a laser beam on that F1 square like

1042
00:38:42,660 --> 00:38:44,400
that is their dark and terrible God

1043
00:38:44,400 --> 00:38:46,020
right um

1044
00:38:46,020 --> 00:38:48,060
your F1 score is too low you don't get

1045
00:38:48,060 --> 00:38:51,540
to be Archduke of nirps uh no no prizes

1046
00:38:51,540 --> 00:38:52,800
for you

1047
00:38:52,800 --> 00:38:55,380
but but if you're me and you've got to

1048
00:38:55,380 --> 00:38:57,240
run this thing in production you'll

1049
00:38:57,240 --> 00:39:00,240
probably take a 0.5 drop in your F1

1050
00:39:00,240 --> 00:39:02,760
score to get rid of you know

1051
00:39:02,760 --> 00:39:05,880
three vulnerabilities right like uh so

1052
00:39:05,880 --> 00:39:07,619
so some of these things become an

1053
00:39:07,619 --> 00:39:09,060
interesting set of engineering

1054
00:39:09,060 --> 00:39:10,740
trade-offs where you start having to say

1055
00:39:10,740 --> 00:39:12,900
like okay if we update this we're gonna

1056
00:39:12,900 --> 00:39:14,040
have to change these other things and

1057
00:39:14,040 --> 00:39:16,079
hear the impacts on our performance so

1058
00:39:16,079 --> 00:39:17,579
you have to be very careful to not be

1059
00:39:17,579 --> 00:39:20,579
dogmatic on either side of this right

1060
00:39:20,579 --> 00:39:21,180
um

1061
00:39:21,180 --> 00:39:23,160
and again some of these things just age

1062
00:39:23,160 --> 00:39:24,720
very importantly I'm dealing with one

1063
00:39:24,720 --> 00:39:26,940
that was written two years ago right now

1064
00:39:26,940 --> 00:39:30,660
and it's it's really tough just trying

1065
00:39:30,660 --> 00:39:32,339
to get it to run now the way it's

1066
00:39:32,339 --> 00:39:35,579
supposed to but uh you know unit tests

1067
00:39:35,579 --> 00:39:37,980
and integration tests are important like

1068
00:39:37,980 --> 00:39:39,780
I said just don't get dogmatic about it

1069
00:39:39,780 --> 00:39:42,060
have be willing to have those

1070
00:39:42,060 --> 00:39:44,280
engineering conversations right like

1071
00:39:44,280 --> 00:39:48,320
this is I think a good meaning

1072
00:39:55,320 --> 00:39:56,520
so

1073
00:39:56,520 --> 00:39:58,740
um like I said just to kind of wrap

1074
00:39:58,740 --> 00:40:00,119
things up

1075
00:40:00,119 --> 00:40:02,280
you guys probably like I haven't told

1076
00:40:02,280 --> 00:40:04,140
you anything revolutionary you guys

1077
00:40:04,140 --> 00:40:06,240
already all know how to to kind of do

1078
00:40:06,240 --> 00:40:07,560
this stuff

1079
00:40:07,560 --> 00:40:08,940
um but hopefully I've kind of like

1080
00:40:08,940 --> 00:40:10,680
demystified it a little and made it seem

1081
00:40:10,680 --> 00:40:12,420
a little more approachable like

1082
00:40:12,420 --> 00:40:14,579
something you can you can tackle in your

1083
00:40:14,579 --> 00:40:17,960
own environments and uh

1084
00:40:18,180 --> 00:40:19,560
um

1085
00:40:19,560 --> 00:40:22,740
[Music]

1086
00:40:22,740 --> 00:40:24,359
they say I just I want to take a minute

1087
00:40:24,359 --> 00:40:26,820
and thanks to people uh I've got to

1088
00:40:26,820 --> 00:40:28,560
thank Andrea who brought me into this

1089
00:40:28,560 --> 00:40:30,599
this work um we really appreciate that

1090
00:40:30,599 --> 00:40:33,540
and my other colleagues who have been

1091
00:40:33,540 --> 00:40:35,400
really fantastic while I've basically

1092
00:40:35,400 --> 00:40:37,140
spent like two years breaking their toys

1093
00:40:37,140 --> 00:40:40,260
like non-stop they're like look at this

1094
00:40:40,260 --> 00:40:43,040
thing we built and I was like

1095
00:40:43,040 --> 00:40:45,359
uh but they've been super great about it

1096
00:40:45,359 --> 00:40:47,820
a very supportive so

1097
00:40:47,820 --> 00:40:49,800
um the the conference organizers for for

1098
00:40:49,800 --> 00:40:51,240
letting me come up here and you guys for

1099
00:40:51,240 --> 00:40:54,000
for listening to me so really appreciate

1100
00:40:54,000 --> 00:40:56,400
my wife putting up with my crap she came

1101
00:40:56,400 --> 00:40:57,599
out to

1102
00:40:57,599 --> 00:40:59,700
listen to me even though she probably

1103
00:40:59,700 --> 00:41:01,380
could have done that at home for free

1104
00:41:01,380 --> 00:41:03,900
although frequently would opt not to if

1105
00:41:03,900 --> 00:41:06,119
given the choice

1106
00:41:06,119 --> 00:41:08,180
um

1107
00:41:09,060 --> 00:41:11,160
and with that being said if anybody has

1108
00:41:11,160 --> 00:41:12,350
any questions

1109
00:41:12,350 --> 00:41:15,509
[Music]

1110
00:41:21,000 --> 00:41:23,119
um

1111
00:41:24,480 --> 00:41:26,000
yeah

1112
00:41:26,000 --> 00:41:28,880
so

1113
00:41:28,880 --> 00:41:31,680
lots of really ugly python is the short

1114
00:41:31,680 --> 00:41:33,359
answer to that oh

1115
00:41:33,359 --> 00:41:36,420
like a really really ugly python

1116
00:41:36,420 --> 00:41:37,560
um

1117
00:41:37,560 --> 00:41:39,240
so we we did a couple of different

1118
00:41:39,240 --> 00:41:42,480
things we used

1119
00:41:42,480 --> 00:41:44,400
um

1120
00:41:44,400 --> 00:41:46,020
they were doing a bunch of experim

1121
00:41:46,020 --> 00:41:47,880
experiments using something called

1122
00:41:47,880 --> 00:41:50,700
protagonist tagger which is this big

1123
00:41:50,700 --> 00:41:52,740
Corpus of data that's they've basically

1124
00:41:52,740 --> 00:41:56,220
taken a bunch of different novels and

1125
00:41:56,220 --> 00:41:58,220
um

1126
00:41:58,440 --> 00:42:00,060
you know people have gone through and

1127
00:42:00,060 --> 00:42:02,400
done this annotation process which I

1128
00:42:02,400 --> 00:42:04,320
don't entirely understand but they say

1129
00:42:04,320 --> 00:42:05,760
you know like this is a person the

1130
00:42:05,760 --> 00:42:07,560
places of things kind of thing

1131
00:42:07,560 --> 00:42:10,200
um so uh novels and things like that are

1132
00:42:10,200 --> 00:42:13,500
great sources for word lists uh

1133
00:42:13,500 --> 00:42:16,200
as dumb as it sounds Wikipedia like

1134
00:42:16,200 --> 00:42:18,060
anything with a bunch of text and a

1135
00:42:18,060 --> 00:42:19,740
readily available API that you can

1136
00:42:19,740 --> 00:42:21,060
scrape

1137
00:42:21,060 --> 00:42:22,680
um or you can use beautiful soup and

1138
00:42:22,680 --> 00:42:25,859
start scraping web pages uh that's

1139
00:42:25,859 --> 00:42:29,520
that's really helpful if you are

1140
00:42:29,520 --> 00:42:30,900
you know you're concerned with like

1141
00:42:30,900 --> 00:42:33,180
particular languages right

1142
00:42:33,180 --> 00:42:33,960
um

1143
00:42:33,960 --> 00:42:36,480
maybe you're worried about like East

1144
00:42:36,480 --> 00:42:38,640
Asian languages or middle eastern

1145
00:42:38,640 --> 00:42:40,619
languages you can start you know setting

1146
00:42:40,619 --> 00:42:42,720
Locale strings for for various places

1147
00:42:42,720 --> 00:42:44,820
and digging things up that way that's

1148
00:42:44,820 --> 00:42:46,079
probably the best advice I can give you

1149
00:42:46,079 --> 00:42:48,380
with that

1150
00:42:49,619 --> 00:42:52,099
okay

1151
00:42:52,960 --> 00:42:57,050
[Music]

1152
00:42:57,660 --> 00:43:00,359
I appreciate it

1153
00:43:00,359 --> 00:43:03,359
yeah

1154
00:43:05,400 --> 00:43:07,319
yeah well I like I said there's there's

1155
00:43:07,319 --> 00:43:09,359
been a whole group of people that's

1156
00:43:09,359 --> 00:43:12,000
you know engaged in like the broader

1157
00:43:12,000 --> 00:43:15,420
um the broader Assurance concept that

1158
00:43:15,420 --> 00:43:17,940
like I go talk to them and stuff but

1159
00:43:17,940 --> 00:43:19,680
they're they're the experts on that not

1160
00:43:19,680 --> 00:43:21,720
me but that's that's been sort of

1161
00:43:21,720 --> 00:43:23,760
fascinating its own right like I

1162
00:43:23,760 --> 00:43:25,920
remember seeing a meeting and

1163
00:43:25,920 --> 00:43:28,380
um we were we were kind of breaking

1164
00:43:28,380 --> 00:43:29,520
things out along like federally

1165
00:43:29,520 --> 00:43:31,260
protected classes right because that's

1166
00:43:31,260 --> 00:43:33,359
because of who we work with that's sort

1167
00:43:33,359 --> 00:43:34,500
of what we cared about and that's like

1168
00:43:34,500 --> 00:43:36,740
an actionable metric right like

1169
00:43:36,740 --> 00:43:39,599
I mean that's the other thing uh a lot

1170
00:43:39,599 --> 00:43:41,099
of this stuff is still particularly

1171
00:43:41,099 --> 00:43:42,900
legally really hazy there aren't any

1172
00:43:42,900 --> 00:43:44,819
rules so we're borrowing stuff from like

1173
00:43:44,819 --> 00:43:47,819
you know finance and fair housing and

1174
00:43:47,819 --> 00:43:49,680
fair lending standards and things like

1175
00:43:49,680 --> 00:43:51,420
that and kind of trying to like Cobble

1176
00:43:51,420 --> 00:43:53,460
some of that stuff together

1177
00:43:53,460 --> 00:43:56,579
um and what I found kind of fascinating

1178
00:43:56,579 --> 00:43:58,859
was like there was this whole very

1179
00:43:58,859 --> 00:44:00,599
academic discussion at one point about

1180
00:44:00,599 --> 00:44:02,640
why we picked you know federally

1181
00:44:02,640 --> 00:44:06,300
protected classes versus this um

1182
00:44:06,300 --> 00:44:07,800
I can't remember the name of it but it's

1183
00:44:07,800 --> 00:44:10,680
like this it's basic tone scale that you

1184
00:44:10,680 --> 00:44:13,560
can use as well or like oh you know this

1185
00:44:13,560 --> 00:44:15,180
is why we've done this but we had to go

1186
00:44:15,180 --> 00:44:18,060
through and justify things like that so

1187
00:44:18,060 --> 00:44:19,980
it's been a fascinating topic area to

1188
00:44:19,980 --> 00:44:21,599
work in

1189
00:44:21,599 --> 00:44:24,180
fair enough like I said we're doing a

1190
00:44:24,180 --> 00:44:26,419
bunch of

1191
00:44:27,260 --> 00:44:30,319
sure sure

1192
00:44:42,240 --> 00:44:45,279
[Music]

1193
00:44:53,960 --> 00:44:56,339
how do you

1194
00:44:56,339 --> 00:44:59,339
connected

1195
00:45:03,030 --> 00:45:06,139
[Music]

1196
00:45:09,980 --> 00:45:12,660
what's the best

1197
00:45:12,660 --> 00:45:15,799
or easier

1198
00:45:17,540 --> 00:45:22,800
it it hurts a lot

1199
00:45:22,800 --> 00:45:24,920
um

1200
00:45:25,260 --> 00:45:28,040
so

1201
00:45:28,940 --> 00:45:31,560
one one thing I've done in sort of one

1202
00:45:31,560 --> 00:45:34,319
of my own things is I I'm a maintainer

1203
00:45:34,319 --> 00:45:35,940
of an open source project called Network

1204
00:45:35,940 --> 00:45:37,380
ml

1205
00:45:37,380 --> 00:45:38,700
um it's a fascinating thing it sounds

1206
00:45:38,700 --> 00:45:39,839
like we wanted to see if we could use

1207
00:45:39,839 --> 00:45:41,700
machine learning to like

1208
00:45:41,700 --> 00:45:43,740
uh make determinations about Network

1209
00:45:43,740 --> 00:45:46,079
traffic based purely on headers

1210
00:45:46,079 --> 00:45:48,180
total sidebar but

1211
00:45:48,180 --> 00:45:49,560
um

1212
00:45:49,560 --> 00:45:51,180
yeah it's on GitHub you can go check it

1213
00:45:51,180 --> 00:45:53,700
out uh happy to give you the link

1214
00:45:53,700 --> 00:45:56,280
but um

1215
00:45:56,280 --> 00:45:59,099
I literally have basically kept the data

1216
00:45:59,099 --> 00:46:00,599
that I used to originally train it

1217
00:46:00,599 --> 00:46:03,480
around it like a compressed form and I I

1218
00:46:03,480 --> 00:46:08,099
have to retrain when I update these uh

1219
00:46:08,099 --> 00:46:11,040
some of these key libraries I just and

1220
00:46:11,040 --> 00:46:13,859
and that's that's probably like the best

1221
00:46:13,859 --> 00:46:16,140
thing that I've come up with is if you

1222
00:46:16,140 --> 00:46:19,260
can Implement some mechanisms to sort of

1223
00:46:19,260 --> 00:46:21,660
short circuit your training process so

1224
00:46:21,660 --> 00:46:23,880
you can rerun it with

1225
00:46:23,880 --> 00:46:25,680
updated

1226
00:46:25,680 --> 00:46:27,000
um

1227
00:46:27,000 --> 00:46:29,880
updated dependencies and then again make

1228
00:46:29,880 --> 00:46:32,160
sure like I basically have a loop where

1229
00:46:32,160 --> 00:46:33,900
I rerun the training and I check that

1230
00:46:33,900 --> 00:46:35,400
I'm within like plus or minus five

1231
00:46:35,400 --> 00:46:36,960
percent of where I was the last few

1232
00:46:36,960 --> 00:46:38,220
times

1233
00:46:38,220 --> 00:46:40,680
and that's kind of

1234
00:46:40,680 --> 00:46:42,359
now it's worth noting that's an open

1235
00:46:42,359 --> 00:46:44,040
source project I don't run production

1236
00:46:44,040 --> 00:46:46,440
systems so things may be very different

1237
00:46:46,440 --> 00:46:48,599
from your client right like a five

1238
00:46:48,599 --> 00:46:50,579
percent difference in outcomes may seem

1239
00:46:50,579 --> 00:46:52,260
like nothing to me but may be critical

1240
00:46:52,260 --> 00:46:54,060
to them

1241
00:46:54,060 --> 00:46:55,220
um

1242
00:46:55,220 --> 00:46:59,220
but there is there's not a great way to

1243
00:46:59,220 --> 00:47:00,359
handle that

1244
00:47:00,359 --> 00:47:01,380
um

1245
00:47:01,380 --> 00:47:03,839
I mean I I think the ultimate the

1246
00:47:03,839 --> 00:47:05,220
ultimate thing is like some of that

1247
00:47:05,220 --> 00:47:07,260
stuff needs to be regression tested more

1248
00:47:07,260 --> 00:47:10,020
before they put it out but I also

1249
00:47:10,020 --> 00:47:12,060
like if you've ever tried to interface

1250
00:47:12,060 --> 00:47:14,280
with Cuda you know what you're doing

1251
00:47:14,280 --> 00:47:17,660
anything with that is too

1252
00:47:25,619 --> 00:47:28,619
networking

1253
00:47:30,480 --> 00:47:32,819
that that's something that we do a lot

1254
00:47:32,819 --> 00:47:36,359
so what what we'll do is we will we'll

1255
00:47:36,359 --> 00:47:38,700
build our container images

1256
00:47:38,700 --> 00:47:39,780
um we'll build like base images

1257
00:47:39,780 --> 00:47:41,160
basically right

1258
00:47:41,160 --> 00:47:43,740
build a base Image Grab the hash of the

1259
00:47:43,740 --> 00:47:46,980
base image and then pin your Docker file

1260
00:47:46,980 --> 00:47:49,380
to that hash for a base run from there

1261
00:47:49,380 --> 00:47:52,380
uh pinning your dependencies also very

1262
00:47:52,380 --> 00:47:54,000
important here because again you need

1263
00:47:54,000 --> 00:47:57,960
like the repeatable builds become but

1264
00:47:57,960 --> 00:48:00,060
yeah that's that's definitely and and

1265
00:48:00,060 --> 00:48:02,400
the other thing too is if if you have

1266
00:48:02,400 --> 00:48:05,760
the ability right being able to stand up

1267
00:48:05,760 --> 00:48:08,579
your own private registry and use that

1268
00:48:08,579 --> 00:48:10,020
as opposed to having to go and grab

1269
00:48:10,020 --> 00:48:11,819
whatever is on your Docker Hub or what

1270
00:48:11,819 --> 00:48:13,740
have you that can also help with that

1271
00:48:13,740 --> 00:48:15,660
repeatability problem quite a bit

1272
00:48:15,660 --> 00:48:18,599
but it is a huge pain in the ass turn on

1273
00:48:18,599 --> 00:48:21,859
your own registry so

1274
00:48:21,900 --> 00:48:24,640
well okay yes tedious

1275
00:48:24,640 --> 00:48:27,690
[Music]

1276
00:48:30,859 --> 00:48:34,279
there is that

1277
00:48:40,400 --> 00:48:43,740
thank you guys I appreciate it

1278
00:48:43,740 --> 00:48:46,560
this talk was a part of our 2022 secure

1279
00:48:46,560 --> 00:48:49,020
West Virginia Lucky 13 conference if you

1280
00:48:49,020 --> 00:48:50,640
would like more information about this

1281
00:48:50,640 --> 00:48:52,319
talk or our speaker check the

1282
00:48:52,319 --> 00:48:54,480
description below and if you enjoyed the

1283
00:48:54,480 --> 00:48:56,280
content consider liking and sharing this

1284
00:48:56,280 --> 00:48:58,500
video for more information on secure

1285
00:48:58,500 --> 00:49:00,000
West Virginia or you want to stay

1286
00:49:00,000 --> 00:49:02,099
updated with the latest upcoming events

1287
00:49:02,099 --> 00:49:05,760
follow us on Twitter at securewbcon or

1288
00:49:05,760 --> 00:49:08,700
visit our website securewb.org

1289
00:49:08,700 --> 00:49:10,920
we would like also like to thank our

1290
00:49:10,920 --> 00:49:13,319
2022 sponsors for being a huge part of

1291
00:49:13,319 --> 00:49:16,460
Lucky 13 success

