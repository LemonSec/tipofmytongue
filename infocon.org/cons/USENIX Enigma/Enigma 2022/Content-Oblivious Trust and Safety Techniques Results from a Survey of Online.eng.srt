1
00:00:08,000 --> 00:00:10,080
hello and welcome to my talk

2
00:00:10,080 --> 00:00:11,759
i'm rhianna pfefferkorn a research

3
00:00:11,759 --> 00:00:13,120
scholar at the stanford internet

4
00:00:13,120 --> 00:00:15,360
observatory and this talk is titled

5
00:00:15,360 --> 00:00:16,960
content oblivious trust and safety

6
00:00:16,960 --> 00:00:17,920
techniques

7
00:00:17,920 --> 00:00:19,840
results from a survey of online service

8
00:00:19,840 --> 00:00:21,279
providers

9
00:00:21,279 --> 00:00:23,519
in this talk i'll discuss the findings

10
00:00:23,519 --> 00:00:25,519
from a research survey that i conducted

11
00:00:25,519 --> 00:00:27,279
last spring

12
00:00:27,279 --> 00:00:28,960
my motivation for undertaking this

13
00:00:28,960 --> 00:00:32,159
research was the ongoing hot topic in

14
00:00:32,159 --> 00:00:34,559
tech policy circles of how to do trust

15
00:00:34,559 --> 00:00:37,120
and safety in a world where increasingly

16
00:00:37,120 --> 00:00:40,239
more and more data is end and encrypted

17
00:00:40,239 --> 00:00:42,160
when i looked around at the kinds of

18
00:00:42,160 --> 00:00:44,239
policy discussions ongoing especially

19
00:00:44,239 --> 00:00:46,079
amongst regulators i saw that

20
00:00:46,079 --> 00:00:48,399
discussions about doing trust and safety

21
00:00:48,399 --> 00:00:50,320
in end-to-end encrypted environments

22
00:00:50,320 --> 00:00:53,039
tended to presume that the only possible

23
00:00:53,039 --> 00:00:55,360
way of doing trust and safety is to

24
00:00:55,360 --> 00:00:57,840
require access to the contents of users

25
00:00:57,840 --> 00:00:59,840
files and communications

26
00:00:59,840 --> 00:01:01,840
in particular two of the proposals that

27
00:01:01,840 --> 00:01:03,920
i frequently see are some that i'll

28
00:01:03,920 --> 00:01:06,000
discuss later on in this talk namely

29
00:01:06,000 --> 00:01:07,840
breaking end and encryption in order to

30
00:01:07,840 --> 00:01:10,240
maintain access to content and scanning

31
00:01:10,240 --> 00:01:11,840
everything proactively when it is

32
00:01:11,840 --> 00:01:13,920
uploaded or transmitted on a particular

33
00:01:13,920 --> 00:01:16,080
service otherwise known as upload

34
00:01:16,080 --> 00:01:17,600
filters

35
00:01:17,600 --> 00:01:19,680
my goal in undertaking this survey was

36
00:01:19,680 --> 00:01:22,080
to learn more about what i call content

37
00:01:22,080 --> 00:01:24,240
oblivious techniques that are already in

38
00:01:24,240 --> 00:01:25,759
use today

39
00:01:25,759 --> 00:01:27,439
throughout this talk i'll be using this

40
00:01:27,439 --> 00:01:28,720
terminology

41
00:01:28,720 --> 00:01:30,560
when i say content dependent trust and

42
00:01:30,560 --> 00:01:32,560
safety techniques i'm talking about

43
00:01:32,560 --> 00:01:34,720
techniques that as the name suggests are

44
00:01:34,720 --> 00:01:35,759
those that

45
00:01:35,759 --> 00:01:38,320
depend for their ability to operate on

46
00:01:38,320 --> 00:01:40,400
access to the content of file files and

47
00:01:40,400 --> 00:01:43,119
communications some examples include

48
00:01:43,119 --> 00:01:45,600
automated content scanning and review by

49
00:01:45,600 --> 00:01:48,159
human moderators who monitor the posts

50
00:01:48,159 --> 00:01:50,960
to a service for abusive content

51
00:01:50,960 --> 00:01:52,799
when i talk about content oblivious

52
00:01:52,799 --> 00:01:54,880
techniques i mean

53
00:01:54,880 --> 00:01:56,960
techniques that work without necessarily

54
00:01:56,960 --> 00:01:59,920
requiring access to content at will on

55
00:01:59,920 --> 00:02:01,680
the part of the provider

56
00:02:01,680 --> 00:02:03,200
some examples of these techniques

57
00:02:03,200 --> 00:02:05,280
include metadata analysis

58
00:02:05,280 --> 00:02:06,799
user reporting

59
00:02:06,799 --> 00:02:09,280
and limits on group size account actions

60
00:02:09,280 --> 00:02:11,360
or other functionality

61
00:02:11,360 --> 00:02:13,280
when i talk about user reports i class

62
00:02:13,280 --> 00:02:15,360
these as being content oblivious rather

63
00:02:15,360 --> 00:02:16,959
than content dependent as they might

64
00:02:16,959 --> 00:02:19,599
seem at first glance because it is not

65
00:02:19,599 --> 00:02:22,560
the provider's ability to gain access at

66
00:02:22,560 --> 00:02:24,239
will to content that is the reason that

67
00:02:24,239 --> 00:02:26,720
they are having this sort of abusive

68
00:02:26,720 --> 00:02:28,319
content brought to their attention

69
00:02:28,319 --> 00:02:30,720
rather it's the fact that a user has

70
00:02:30,720 --> 00:02:32,640
shared it with the provider that brings

71
00:02:32,640 --> 00:02:34,840
it to their

72
00:02:34,840 --> 00:02:37,120
attention some information about this

73
00:02:37,120 --> 00:02:39,200
survey i administered this during 10

74
00:02:39,200 --> 00:02:41,040
weeks between april and june of last

75
00:02:41,040 --> 00:02:42,959
year 2021

76
00:02:42,959 --> 00:02:44,879
i sent the survey out to individuals

77
00:02:44,879 --> 00:02:47,920
working at a variety of online services

78
00:02:47,920 --> 00:02:49,840
in particular i was trying to aim the

79
00:02:49,840 --> 00:02:51,920
survey at the providers of applications

80
00:02:51,920 --> 00:02:53,920
and services that focus on online

81
00:02:53,920 --> 00:02:56,720
communications and or data storage

82
00:02:56,720 --> 00:02:58,480
ultimately my analysis included the

83
00:02:58,480 --> 00:03:01,120
responses of 13 individuals from among

84
00:03:01,120 --> 00:03:03,200
the 58 people to whom i had originally

85
00:03:03,200 --> 00:03:06,480
distributed the survey a 22.4 response

86
00:03:06,480 --> 00:03:07,840
rate

87
00:03:07,840 --> 00:03:09,920
in terms of what the sample looks like

88
00:03:09,920 --> 00:03:11,120
several of the services that

89
00:03:11,120 --> 00:03:12,720
participated in the survey are

90
00:03:12,720 --> 00:03:14,640
end-to-end encrypted messaging apps but

91
00:03:14,640 --> 00:03:16,319
most of them are not

92
00:03:16,319 --> 00:03:18,319
not everybody allowed me to name the

93
00:03:18,319 --> 00:03:20,640
company or the service at issue in

94
00:03:20,640 --> 00:03:22,879
public but those that i can disclose

95
00:03:22,879 --> 00:03:24,959
participated in this survey include

96
00:03:24,959 --> 00:03:26,640
several under the what is now known as

97
00:03:26,640 --> 00:03:28,879
meta umbrella facebook messenger

98
00:03:28,879 --> 00:03:31,360
instagram messaging and whatsapp

99
00:03:31,360 --> 00:03:33,599
as well as wikimedia which responded on

100
00:03:33,599 --> 00:03:35,519
the part of the wikidata product in

101
00:03:35,519 --> 00:03:36,879
particular

102
00:03:36,879 --> 00:03:38,959
two link aggregation sites metafilter

103
00:03:38,959 --> 00:03:41,599
and lobsters and yahoo groups which is a

104
00:03:41,599 --> 00:03:44,080
now shuttered product offered by yahoo

105
00:03:44,080 --> 00:03:46,720
r.i.p

106
00:03:46,720 --> 00:03:49,200
in terms of the size of the participants

107
00:03:49,200 --> 00:03:51,440
these range from around 2 000 monthly

108
00:03:51,440 --> 00:03:53,120
active users on the low end that's

109
00:03:53,120 --> 00:03:56,159
lobsters up to 200 2 billion monthly

110
00:03:56,159 --> 00:03:58,799
active users that's whatsapp

111
00:03:58,799 --> 00:04:00,560
among the anonymous services that

112
00:04:00,560 --> 00:04:03,439
participated the median provider has

113
00:04:03,439 --> 00:04:05,519
well over 200 million monthly active

114
00:04:05,519 --> 00:04:06,720
users

115
00:04:06,720 --> 00:04:09,439
so even though there is only 13 people

116
00:04:09,439 --> 00:04:10,879
whose responses are included in the

117
00:04:10,879 --> 00:04:13,200
analysis collectively they represent

118
00:04:13,200 --> 00:04:16,079
service providers that serve

119
00:04:16,079 --> 00:04:18,478
probably the majority of the world's

120
00:04:18,478 --> 00:04:22,320
multiple billions of internet users

121
00:04:22,720 --> 00:04:24,400
the survey covered 12 different

122
00:04:24,400 --> 00:04:26,880
categories of online abuse

123
00:04:26,880 --> 00:04:28,240
i'll list them here and i'll read them

124
00:04:28,240 --> 00:04:29,680
out loud for you

125
00:04:29,680 --> 00:04:32,080
ip infringement spam

126
00:04:32,080 --> 00:04:34,400
phishing or malware child sex abuse

127
00:04:34,400 --> 00:04:36,639
imagery or csai for short

128
00:04:36,639 --> 00:04:38,320
child sexual exploitation such as

129
00:04:38,320 --> 00:04:41,280
grooving and enticement csc for short

130
00:04:41,280 --> 00:04:43,759
terrorism or violent extremism

131
00:04:43,759 --> 00:04:46,160
non-child sexual content pornography and

132
00:04:46,160 --> 00:04:47,759
obscenity

133
00:04:47,759 --> 00:04:49,840
diss and misinformation

134
00:04:49,840 --> 00:04:52,160
harassment threats extortion sex torture

135
00:04:52,160 --> 00:04:52,800
and

136
00:04:52,800 --> 00:04:54,479
intimidation

137
00:04:54,479 --> 00:04:55,680
hate speech

138
00:04:55,680 --> 00:04:58,000
self-harm and bots or inauthentic

139
00:04:58,000 --> 00:05:00,240
behavior as well as other

140
00:05:00,240 --> 00:05:02,000
if i had to do over again i might have

141
00:05:02,000 --> 00:05:04,000
changed these categories a little bit

142
00:05:04,000 --> 00:05:05,199
for one thing i would have classed

143
00:05:05,199 --> 00:05:07,520
sextortion under cse rather than

144
00:05:07,520 --> 00:05:09,280
breaking it out among other types of

145
00:05:09,280 --> 00:05:11,199
harassment and threats

146
00:05:11,199 --> 00:05:13,199
for another bots and authentic behavior

147
00:05:13,199 --> 00:05:15,199
are kind of the odd man out here because

148
00:05:15,199 --> 00:05:17,440
they're about actors and behavior rather

149
00:05:17,440 --> 00:05:19,520
than content to borrow the abcs

150
00:05:19,520 --> 00:05:21,360
developed by camille francois from whom

151
00:05:21,360 --> 00:05:22,960
we'll be hearing later on during the

152
00:05:22,960 --> 00:05:24,560
enigma conference

153
00:05:24,560 --> 00:05:26,320
however even though i might have made a

154
00:05:26,320 --> 00:05:29,039
few changes i think that overall i've

155
00:05:29,039 --> 00:05:31,039
captured the bulk of the types of online

156
00:05:31,039 --> 00:05:33,600
abuse commonly seen even if it may not

157
00:05:33,600 --> 00:05:37,440
necessarily capture the exact long tail

158
00:05:37,759 --> 00:05:39,600
to summarize the key findings from the

159
00:05:39,600 --> 00:05:40,639
survey

160
00:05:40,639 --> 00:05:42,880
i found that all 13 of the providers

161
00:05:42,880 --> 00:05:45,199
included in the analysis employ both

162
00:05:45,199 --> 00:05:47,520
content oblivious and content dependent

163
00:05:47,520 --> 00:05:48,800
techniques

164
00:05:48,800 --> 00:05:50,840
of those the most popular is user

165
00:05:50,840 --> 00:05:52,960
reports everyone who participated in the

166
00:05:52,960 --> 00:05:54,800
survey offers some type of abuse

167
00:05:54,800 --> 00:05:57,680
reporting of those 12 offer some kind of

168
00:05:57,680 --> 00:06:00,639
in-app reporting flow and the other one

169
00:06:00,639 --> 00:06:01,600
offered

170
00:06:01,600 --> 00:06:03,600
reports from outside the service such as

171
00:06:03,600 --> 00:06:05,759
sending an email to report an abusive

172
00:06:05,759 --> 00:06:07,840
piece of data on the service something i

173
00:06:07,840 --> 00:06:09,840
call off app reports

174
00:06:09,840 --> 00:06:12,560
less prevalent were techniques such as

175
00:06:12,560 --> 00:06:14,639
metadata automated content scanning and

176
00:06:14,639 --> 00:06:17,600
others which i'll go through in a moment

177
00:06:17,600 --> 00:06:19,680
i also asked providers what do they

178
00:06:19,680 --> 00:06:21,600
think is the most useful technique for

179
00:06:21,600 --> 00:06:24,560
detecting abuse here again user reports

180
00:06:24,560 --> 00:06:26,080
predominated

181
00:06:26,080 --> 00:06:27,919
i found that user reports were

182
00:06:27,919 --> 00:06:29,440
considered the most useful means of

183
00:06:29,440 --> 00:06:31,919
detecting abuse across 9 out of the 12

184
00:06:31,919 --> 00:06:34,400
abuse categories that i just showed you

185
00:06:34,400 --> 00:06:37,039
however i also found that the providers

186
00:06:37,039 --> 00:06:38,800
who participated in the survey did not

187
00:06:38,800 --> 00:06:41,520
consistently enable user reporting tools

188
00:06:41,520 --> 00:06:44,720
to report all 12 categories of abuse

189
00:06:44,720 --> 00:06:46,479
the outlier to this finding about the

190
00:06:46,479 --> 00:06:49,680
utility of user reports is csai

191
00:06:49,680 --> 00:06:51,840
there we saw a very strong consensus

192
00:06:51,840 --> 00:06:53,680
among participating providers that

193
00:06:53,680 --> 00:06:56,000
automated content scanning is the most

194
00:06:56,000 --> 00:06:58,880
useful way of detecting csai

195
00:06:58,880 --> 00:07:01,039
next let's walk through a few charts

196
00:07:01,039 --> 00:07:02,800
that show the findings that i've just

197
00:07:02,800 --> 00:07:05,440
summarized for you

198
00:07:05,440 --> 00:07:07,280
so first i asked

199
00:07:07,280 --> 00:07:10,000
what types of techniques do you use to

200
00:07:10,000 --> 00:07:12,400
detect preventive mitigated abuse

201
00:07:12,400 --> 00:07:14,240
here we see that the most common

202
00:07:14,240 --> 00:07:16,479
response was in-app reports

203
00:07:16,479 --> 00:07:18,880
followed by a tie between human review

204
00:07:18,880 --> 00:07:20,639
and off-app reports

205
00:07:20,639 --> 00:07:22,160
and after that we see another tie

206
00:07:22,160 --> 00:07:24,639
between metadata and automated scans

207
00:07:24,639 --> 00:07:27,440
and least commonly used were limits on

208
00:07:27,440 --> 00:07:28,960
sharing and forwarding content and

209
00:07:28,960 --> 00:07:30,720
limits on group size

210
00:07:30,720 --> 00:07:32,880
that makes sense because as said

211
00:07:32,880 --> 00:07:35,120
messaging apps comprise only a minority

212
00:07:35,120 --> 00:07:36,639
of the participants

213
00:07:36,639 --> 00:07:39,680
in the survey sample and these kinds of

214
00:07:39,680 --> 00:07:41,599
limits are really the sorts of features

215
00:07:41,599 --> 00:07:43,599
that you would only expect to find in a

216
00:07:43,599 --> 00:07:46,080
private communication type of setting

217
00:07:46,080 --> 00:07:47,280
group size limits and sharing and

218
00:07:47,280 --> 00:07:48,800
forwarding limits aren't really as

219
00:07:48,800 --> 00:07:50,400
pertinent for something like wikidata

220
00:07:50,400 --> 00:07:52,960
for example

221
00:07:53,440 --> 00:07:56,000
i next ask between these two content

222
00:07:56,000 --> 00:07:58,000
oblivious techniques metadata and user

223
00:07:58,000 --> 00:08:01,199
reports which one or both do the

224
00:08:01,199 --> 00:08:03,280
participants use to detect particular

225
00:08:03,280 --> 00:08:05,360
types of abuse

226
00:08:05,360 --> 00:08:07,360
here we see metadata in blue and user

227
00:08:07,360 --> 00:08:09,199
reports in red

228
00:08:09,199 --> 00:08:11,840
if you glance at this you can see pretty

229
00:08:11,840 --> 00:08:14,000
clearly that user reports are more

230
00:08:14,000 --> 00:08:16,240
popular than metadata for most

231
00:08:16,240 --> 00:08:17,759
categories

232
00:08:17,759 --> 00:08:20,560
we see a couple of tie areas for csei

233
00:08:20,560 --> 00:08:22,479
and bots where these two techniques are

234
00:08:22,479 --> 00:08:24,319
used in equal amounts

235
00:08:24,319 --> 00:08:26,000
and we also see what i consider to be

236
00:08:26,000 --> 00:08:29,120
some surprises for example the low usage

237
00:08:29,120 --> 00:08:31,440
of metadata in order to detect ip

238
00:08:31,440 --> 00:08:33,599
infringement as well as the fact that

239
00:08:33,599 --> 00:08:36,000
there is no particular category of abuse

240
00:08:36,000 --> 00:08:38,240
where everybody uses one or the other of

241
00:08:38,240 --> 00:08:41,039
these types of tools even in areas that

242
00:08:41,039 --> 00:08:43,839
tend to be lightning rods for regulatory

243
00:08:43,839 --> 00:08:47,360
action such as csai

244
00:08:48,080 --> 00:08:50,000
in what i think is the most interesting

245
00:08:50,000 --> 00:08:52,000
finding from the survey

246
00:08:52,000 --> 00:08:54,399
i asked the participants which of these

247
00:08:54,399 --> 00:08:56,640
three particular techniques

248
00:08:56,640 --> 00:08:58,240
automated scanning which is content

249
00:08:58,240 --> 00:08:59,440
dependent

250
00:08:59,440 --> 00:09:01,279
metadata and user reporting which are

251
00:09:01,279 --> 00:09:03,839
content oblivious do you the provider

252
00:09:03,839 --> 00:09:05,839
not the individual respondent find to be

253
00:09:05,839 --> 00:09:08,240
the most useful technique for detecting

254
00:09:08,240 --> 00:09:10,720
each type of abuse

255
00:09:10,720 --> 00:09:13,600
here we see again that user reports

256
00:09:13,600 --> 00:09:16,240
are the most commonly considered useful

257
00:09:16,240 --> 00:09:18,240
from the majority of the categories of

258
00:09:18,240 --> 00:09:20,240
abuse that i asked about

259
00:09:20,240 --> 00:09:22,480
and in some cases far outstrip the other

260
00:09:22,480 --> 00:09:24,080
two options

261
00:09:24,080 --> 00:09:27,279
the one exception is csai where we see a

262
00:09:27,279 --> 00:09:29,440
very strong consensus that automated

263
00:09:29,440 --> 00:09:32,160
scanning a content dependent technique

264
00:09:32,160 --> 00:09:34,800
is much more useful than either of the

265
00:09:34,800 --> 00:09:36,399
content oblivious techniques i asked

266
00:09:36,399 --> 00:09:37,760
about

267
00:09:37,760 --> 00:09:39,279
and we see a couple of areas where

268
00:09:39,279 --> 00:09:42,160
there's a tie we see a three-way tie for

269
00:09:42,160 --> 00:09:43,360
spam

270
00:09:43,360 --> 00:09:46,000
and for cse we see a tie between

271
00:09:46,000 --> 00:09:50,480
automated scanning and user reporting

272
00:09:50,480 --> 00:09:52,160
so what are the takeaways that we should

273
00:09:52,160 --> 00:09:55,360
take from these findings

274
00:09:55,360 --> 00:09:58,399
take as a given that end end encryption

275
00:09:58,399 --> 00:10:01,040
hinders access to content and therefore

276
00:10:01,040 --> 00:10:02,320
that means that end end encryption

277
00:10:02,320 --> 00:10:05,040
impedes automated scanning as a tool for

278
00:10:05,040 --> 00:10:06,560
detecting abuse because it's

279
00:10:06,560 --> 00:10:08,480
content-dependent but end-to-end

280
00:10:08,480 --> 00:10:10,480
encryption does not affect user

281
00:10:10,480 --> 00:10:12,240
reporting or metadata because those are

282
00:10:12,240 --> 00:10:14,240
content oblivious

283
00:10:14,240 --> 00:10:16,720
and as we just saw my survey results

284
00:10:16,720 --> 00:10:19,200
show that user reporting is deemed to be

285
00:10:19,200 --> 00:10:21,279
more useful than or as useful as

286
00:10:21,279 --> 00:10:23,200
automated scanning for every type of

287
00:10:23,200 --> 00:10:26,399
abuse with the sole exception of csai

288
00:10:26,399 --> 00:10:28,560
the implication therefore is that

289
00:10:28,560 --> 00:10:30,399
end-to-end encryption does not affect

290
00:10:30,399 --> 00:10:32,240
providers abuse detection efforts

291
00:10:32,240 --> 00:10:34,160
uniformly

292
00:10:34,160 --> 00:10:36,560
rather we can anticipate that the impact

293
00:10:36,560 --> 00:10:38,880
of end and encryption on abuse detection

294
00:10:38,880 --> 00:10:40,560
probably varies depending on what type

295
00:10:40,560 --> 00:10:42,880
of abuse we're talking about

296
00:10:42,880 --> 00:10:44,480
we can expect it to have the least

297
00:10:44,480 --> 00:10:46,560
impact where content oblivious tools

298
00:10:46,560 --> 00:10:48,320
such as user reports are considered to

299
00:10:48,320 --> 00:10:50,800
be much much more useful than automated

300
00:10:50,800 --> 00:10:52,000
scanning

301
00:10:52,000 --> 00:10:53,600
examples from the data include

302
00:10:53,600 --> 00:10:57,200
harassment hate speech and self-harm

303
00:10:57,200 --> 00:10:59,360
we can expect there to be some impact

304
00:10:59,360 --> 00:11:01,360
where content oblivious tools are deemed

305
00:11:01,360 --> 00:11:04,240
to be about as useful as automated

306
00:11:04,240 --> 00:11:05,360
scanning

307
00:11:05,360 --> 00:11:07,360
the examples we see there in the data

308
00:11:07,360 --> 00:11:10,240
include cse and spam

309
00:11:10,240 --> 00:11:12,160
and we can anticipate that there will be

310
00:11:12,160 --> 00:11:13,839
the greatest impact by end-to-end

311
00:11:13,839 --> 00:11:15,760
encryption on providers ability to

312
00:11:15,760 --> 00:11:18,079
detect abuse where content oblivious

313
00:11:18,079 --> 00:11:19,920
tools are considered to be much much

314
00:11:19,920 --> 00:11:22,399
less useful than automated scanning

315
00:11:22,399 --> 00:11:24,079
and the sole example that we see in the

316
00:11:24,079 --> 00:11:26,959
data there is csai

317
00:11:26,959 --> 00:11:29,440
if this is true if and an encryption's

318
00:11:29,440 --> 00:11:31,440
impact on abuse detection is less than

319
00:11:31,440 --> 00:11:33,040
you might otherwise assume

320
00:11:33,040 --> 00:11:35,040
that means that calls to break end end

321
00:11:35,040 --> 00:11:37,040
encryption or to compel automated

322
00:11:37,040 --> 00:11:39,920
scanning are largely a non-sequitur

323
00:11:39,920 --> 00:11:42,000
there's very little reason to break and

324
00:11:42,000 --> 00:11:44,160
end encryption if it's not impeding the

325
00:11:44,160 --> 00:11:45,920
thing that is considered to be the most

326
00:11:45,920 --> 00:11:49,360
useful tool overall user reports

327
00:11:49,360 --> 00:11:51,360
likewise there's very little reason to

328
00:11:51,360 --> 00:11:53,760
mandate a particular approach that

329
00:11:53,760 --> 00:11:55,920
already to date is not considered to be

330
00:11:55,920 --> 00:11:57,519
very useful at all

331
00:11:57,519 --> 00:12:01,519
that is automated content scanning

332
00:12:01,600 --> 00:12:03,200
i may just be preaching to the choir

333
00:12:03,200 --> 00:12:05,200
here as many enigma attendees may

334
00:12:05,200 --> 00:12:07,440
already know but what we see in these

335
00:12:07,440 --> 00:12:09,680
data is that abuse is not a uniform

336
00:12:09,680 --> 00:12:12,639
problem that requires uniform response

337
00:12:12,639 --> 00:12:14,480
looking at policy debates about how to

338
00:12:14,480 --> 00:12:16,720
regulate providers duty to fight abuse

339
00:12:16,720 --> 00:12:18,560
on their services we see that those

340
00:12:18,560 --> 00:12:21,519
debates tend to focus on csai as though

341
00:12:21,519 --> 00:12:23,360
that's representative of all online

342
00:12:23,360 --> 00:12:24,480
abuse

343
00:12:24,480 --> 00:12:26,480
but as these data confirm and as you may

344
00:12:26,480 --> 00:12:28,959
already have had a hunch csai is not

345
00:12:28,959 --> 00:12:30,880
like other types of abuse

346
00:12:30,880 --> 00:12:32,880
what works best against it does not work

347
00:12:32,880 --> 00:12:34,720
best against other types of abuse and

348
00:12:34,720 --> 00:12:36,399
vice versa

349
00:12:36,399 --> 00:12:38,800
even within the overall umbrella area of

350
00:12:38,800 --> 00:12:41,120
child safety even that's not an informed

351
00:12:41,120 --> 00:12:42,079
problem

352
00:12:42,079 --> 00:12:44,480
we see from the data that cse is not the

353
00:12:44,480 --> 00:12:46,800
same problem as csai

354
00:12:46,800 --> 00:12:49,040
from the data we saw that csc does not

355
00:12:49,040 --> 00:12:51,519
have the same strong consensus that csi

356
00:12:51,519 --> 00:12:54,720
has about the far and away more utility

357
00:12:54,720 --> 00:12:57,040
of automated scanning as the preferable

358
00:12:57,040 --> 00:12:59,519
tool for fighting abuse

359
00:12:59,519 --> 00:13:01,360
and that means that end-to-end

360
00:13:01,360 --> 00:13:03,920
encryption may affect detection of cse

361
00:13:03,920 --> 00:13:06,720
less than it detects csai

362
00:13:06,720 --> 00:13:09,120
if that's true then the overall impact

363
00:13:09,120 --> 00:13:11,200
of end-to-end encryption on child safety

364
00:13:11,200 --> 00:13:13,760
writ large is less than you might think

365
00:13:13,760 --> 00:13:15,839
if you were extrapolating from csai

366
00:13:15,839 --> 00:13:17,200
alone

367
00:13:17,200 --> 00:13:19,200
so if you're using csai as the sole

368
00:13:19,200 --> 00:13:21,360
basis for forecasting the impact

369
00:13:21,360 --> 00:13:23,200
end-to-end encryption is going to have

370
00:13:23,200 --> 00:13:25,120
on the trust and safety program

371
00:13:25,120 --> 00:13:26,320
you're not going to be able to do that

372
00:13:26,320 --> 00:13:27,839
accurately there will be a wild

373
00:13:27,839 --> 00:13:30,399
overestimate of how much impact you can

374
00:13:30,399 --> 00:13:31,680
expect

375
00:13:31,680 --> 00:13:33,200
and if you optimize your trust and

376
00:13:33,200 --> 00:13:34,720
safety program

377
00:13:34,720 --> 00:13:37,600
around the particular problem of csai

378
00:13:37,600 --> 00:13:39,440
that's going to lead to an ineffective

379
00:13:39,440 --> 00:13:41,600
approach to other types of abuse

380
00:13:41,600 --> 00:13:43,279
not just because

381
00:13:43,279 --> 00:13:45,279
the other types of abuse aren't

382
00:13:45,279 --> 00:13:47,279
necessarily as amenable to being

383
00:13:47,279 --> 00:13:49,680
addressed in quite the same way as

384
00:13:49,680 --> 00:13:52,560
csai is but also because

385
00:13:52,560 --> 00:13:55,920
when resources get focused on csai that

386
00:13:55,920 --> 00:13:58,160
leaves fewer resources available for

387
00:13:58,160 --> 00:13:59,519
figuring out how to contend with

388
00:13:59,519 --> 00:14:03,160
different types of abuse

389
00:14:03,279 --> 00:14:05,920
for policy makers the big takeaway that

390
00:14:05,920 --> 00:14:08,000
i want you to get from this talk is that

391
00:14:08,000 --> 00:14:09,600
there just is not a silver bullet for

392
00:14:09,600 --> 00:14:11,040
online abuse

393
00:14:11,040 --> 00:14:12,959
automated content scanning is too often

394
00:14:12,959 --> 00:14:15,040
treated as though it is a silver bullet

395
00:14:15,040 --> 00:14:17,680
and a cure-all for online abuse

396
00:14:17,680 --> 00:14:19,440
we see this in regulatory proposals

397
00:14:19,440 --> 00:14:21,600
around the world from canada to europe

398
00:14:21,600 --> 00:14:23,519
to india

399
00:14:23,519 --> 00:14:25,920
however the data show that automated

400
00:14:25,920 --> 00:14:27,839
content scanning will not have the

401
00:14:27,839 --> 00:14:30,639
upside that those seeking to mandate it

402
00:14:30,639 --> 00:14:32,399
might expect

403
00:14:32,399 --> 00:14:34,000
at the same time

404
00:14:34,000 --> 00:14:36,320
we can't pretend that content oblivious

405
00:14:36,320 --> 00:14:38,320
tools are a silver bullet for online

406
00:14:38,320 --> 00:14:39,519
abuse

407
00:14:39,519 --> 00:14:41,600
even though we saw that user reports a

408
00:14:41,600 --> 00:14:43,360
content oblivious technique are

409
00:14:43,360 --> 00:14:45,360
considered by and large to be very

410
00:14:45,360 --> 00:14:46,880
effective against a number of different

411
00:14:46,880 --> 00:14:49,760
categories of abuse nevertheless csci is

412
00:14:49,760 --> 00:14:52,160
still an outlier and so those of us who

413
00:14:52,160 --> 00:14:54,160
are advocating for the protection of end

414
00:14:54,160 --> 00:14:56,839
and encryption shouldn't pretend

415
00:14:56,839 --> 00:14:59,600
otherwise what's more even content

416
00:14:59,600 --> 00:15:02,079
oblivious tools even though they are not

417
00:15:02,079 --> 00:15:04,720
looking into doing content analysis

418
00:15:04,720 --> 00:15:06,800
nevertheless have their own privacy of

419
00:15:06,800 --> 00:15:08,240
impact

420
00:15:08,240 --> 00:15:10,240
for example

421
00:15:10,240 --> 00:15:12,399
there may be some areas where the

422
00:15:12,399 --> 00:15:14,399
collection of a large amount of metadata

423
00:15:14,399 --> 00:15:16,800
that a provider didn't previously gather

424
00:15:16,800 --> 00:15:19,199
as a means of serving as a proxy for

425
00:15:19,199 --> 00:15:22,000
looking at content might have its own

426
00:15:22,000 --> 00:15:24,639
degree of privacy intrusiveness

427
00:15:24,639 --> 00:15:26,639
even though likewise

428
00:15:26,639 --> 00:15:28,560
content analysis is necessarily privacy

429
00:15:28,560 --> 00:15:30,399
intrusive too

430
00:15:30,399 --> 00:15:31,839
there simply is just no

431
00:15:31,839 --> 00:15:33,600
one-size-fits-all answer for how to

432
00:15:33,600 --> 00:15:35,680
contend with online abuse

433
00:15:35,680 --> 00:15:38,959
as said the csai context is unique it

434
00:15:38,959 --> 00:15:40,720
can't be the basis for developing a

435
00:15:40,720 --> 00:15:42,720
trust and safety program much less

436
00:15:42,720 --> 00:15:44,639
passing a law

437
00:15:44,639 --> 00:15:45,920
as i noted

438
00:15:45,920 --> 00:15:48,079
mandating automated scanning or upload

439
00:15:48,079 --> 00:15:49,199
filters

440
00:15:49,199 --> 00:15:51,040
is to risk codifying a largely

441
00:15:51,040 --> 00:15:53,519
ineffective method or a method that may

442
00:15:53,519 --> 00:15:55,519
become ineffective in the future there's

443
00:15:55,519 --> 00:15:57,120
no guarantee that automated content

444
00:15:57,120 --> 00:15:58,880
scanning is going to continue to be as

445
00:15:58,880 --> 00:16:01,199
effective against csai as it is right

446
00:16:01,199 --> 00:16:02,399
now

447
00:16:02,399 --> 00:16:04,560
and in the meantime and encryption

448
00:16:04,560 --> 00:16:06,160
doesn't break the thing that does work

449
00:16:06,160 --> 00:16:08,880
well user reporting weakening to end

450
00:16:08,880 --> 00:16:10,560
encryption in order to preserve access

451
00:16:10,560 --> 00:16:12,480
to content would come with a large

452
00:16:12,480 --> 00:16:14,480
downside for privacy security and other

453
00:16:14,480 --> 00:16:17,279
values but without the upside that those

454
00:16:17,279 --> 00:16:18,959
proposing this as a solution might

455
00:16:18,959 --> 00:16:20,800
assume

456
00:16:20,800 --> 00:16:23,040
rather than instituting broad mandates

457
00:16:23,040 --> 00:16:25,199
that tie providers hands providers

458
00:16:25,199 --> 00:16:27,360
instead need from policy makers to

459
00:16:27,360 --> 00:16:29,920
maintain the ability to employ a suite

460
00:16:29,920 --> 00:16:32,079
of trust and safety tools that they can

461
00:16:32,079 --> 00:16:34,480
deploy for differing challenges

462
00:16:34,480 --> 00:16:36,399
and they need the legal flexibility to

463
00:16:36,399 --> 00:16:38,000
try new things

464
00:16:38,000 --> 00:16:40,240
test out new ideas discard old methods

465
00:16:40,240 --> 00:16:42,320
that no longer work and to evolve their

466
00:16:42,320 --> 00:16:44,720
strategies for fighting abuse

467
00:16:44,720 --> 00:16:45,839
after all

468
00:16:45,839 --> 00:16:47,839
abusive users are always evolving their

469
00:16:47,839 --> 00:16:50,399
strategies

470
00:16:50,399 --> 00:16:52,399
if you are a provider here's what i

471
00:16:52,399 --> 00:16:54,160
would like to see from you

472
00:16:54,160 --> 00:16:56,000
the low hanging fruit would be to invest

473
00:16:56,000 --> 00:16:57,600
in better and more granular user

474
00:16:57,600 --> 00:16:59,519
reporting functionality

475
00:16:59,519 --> 00:17:01,279
we saw from the chart that i showed you

476
00:17:01,279 --> 00:17:03,759
earlier that there are some gaps in the

477
00:17:03,759 --> 00:17:05,839
user reporting functions that are

478
00:17:05,839 --> 00:17:07,679
offered by the providers included in the

479
00:17:07,679 --> 00:17:10,160
survey despite the fact that those same

480
00:17:10,160 --> 00:17:11,679
providers had by and large said that

481
00:17:11,679 --> 00:17:13,679
they consider user reporting to be the

482
00:17:13,679 --> 00:17:16,640
most useful means of abuse detection

483
00:17:16,640 --> 00:17:18,720
this isn't to say that every single

484
00:17:18,720 --> 00:17:20,720
service should have an abuse reporting

485
00:17:20,720 --> 00:17:22,480
flow that addresses all 12 of the

486
00:17:22,480 --> 00:17:25,119
categories that i listed earlier but at

487
00:17:25,119 --> 00:17:28,000
least to focus on including the types of

488
00:17:28,000 --> 00:17:29,760
abuse that your users are likely to

489
00:17:29,760 --> 00:17:32,400
encounter on your particular service

490
00:17:32,400 --> 00:17:34,240
not only is this a means of empowering

491
00:17:34,240 --> 00:17:36,720
your users it may also defray the impact

492
00:17:36,720 --> 00:17:38,960
of end-to-end encryption on your trust

493
00:17:38,960 --> 00:17:40,799
and safety program in the event that you

494
00:17:40,799 --> 00:17:43,760
choose to deploy ete in the future

495
00:17:43,760 --> 00:17:46,400
that said i recognize that designing a

496
00:17:46,400 --> 00:17:49,360
good user reporting tool particularly

497
00:17:49,360 --> 00:17:51,200
one that is robust against itself being

498
00:17:51,200 --> 00:17:54,320
misused implicates ux and ui issues that

499
00:17:54,320 --> 00:17:57,200
are out of scope for this talk

500
00:17:57,200 --> 00:17:58,720
i would also like to see greater

501
00:17:58,720 --> 00:18:00,720
transparency from providers about your

502
00:18:00,720 --> 00:18:02,640
trust and safety programs and your

503
00:18:02,640 --> 00:18:04,160
research

504
00:18:04,160 --> 00:18:05,919
it would be highly useful to me as a

505
00:18:05,919 --> 00:18:07,679
researcher and probably to your users in

506
00:18:07,679 --> 00:18:09,760
the general public if we were to be able

507
00:18:09,760 --> 00:18:11,919
to see some before and after data on

508
00:18:11,919 --> 00:18:14,240
abuse detection efforts what happens

509
00:18:14,240 --> 00:18:16,000
before and after you make changes to

510
00:18:16,000 --> 00:18:18,559
your that's tooling what happens before

511
00:18:18,559 --> 00:18:20,000
and after you implement end-to-end

512
00:18:20,000 --> 00:18:22,160
encryption by default

513
00:18:22,160 --> 00:18:24,160
i'd also like to see some research from

514
00:18:24,160 --> 00:18:25,520
providers

515
00:18:25,520 --> 00:18:27,280
one thing that i didn't get from this

516
00:18:27,280 --> 00:18:29,200
particular survey that i ran was an

517
00:18:29,200 --> 00:18:31,520
answer about why is it that automated

518
00:18:31,520 --> 00:18:33,600
content scanning is not considered to be

519
00:18:33,600 --> 00:18:36,160
useful for most abuse types

520
00:18:36,160 --> 00:18:37,919
is the problem that the tech is just

521
00:18:37,919 --> 00:18:39,840
mostly immature subject to some

522
00:18:39,840 --> 00:18:42,240
exceptions such as csai and spam where

523
00:18:42,240 --> 00:18:45,280
we've had automated content scanning

524
00:18:45,280 --> 00:18:47,840
techniques around for decades

525
00:18:47,840 --> 00:18:50,000
or is the problem that some areas of

526
00:18:50,000 --> 00:18:52,720
abuse may just be inherently ill suited

527
00:18:52,720 --> 00:18:55,440
to being detected automatically because

528
00:18:55,440 --> 00:18:57,919
of contextual and cultural and human

529
00:18:57,919 --> 00:18:59,919
judgment specific issues

530
00:18:59,919 --> 00:19:01,520
i'd love to know whether there are any

531
00:19:01,520 --> 00:19:03,760
areas where automated content scanning

532
00:19:03,760 --> 00:19:06,000
shows promise where currently it doesn't

533
00:19:06,000 --> 00:19:07,679
look like that particular technique is

534
00:19:07,679 --> 00:19:10,400
particularly useful

535
00:19:10,400 --> 00:19:11,760
i'd also like to get some more

536
00:19:11,760 --> 00:19:13,360
information from providers about the

537
00:19:13,360 --> 00:19:16,000
role of user education and guidance i

538
00:19:16,000 --> 00:19:17,679
didn't ask about this as one of the

539
00:19:17,679 --> 00:19:20,080
techniques that i surveyed providers

540
00:19:20,080 --> 00:19:22,240
about but i would like to know more

541
00:19:22,240 --> 00:19:23,280
about

542
00:19:23,280 --> 00:19:26,400
how useful and how effective is it to

543
00:19:26,400 --> 00:19:28,240
undertake interventions such as applying

544
00:19:28,240 --> 00:19:30,480
labels for missing disinformation or

545
00:19:30,480 --> 00:19:32,640
phishing warnings or interposing child

546
00:19:32,640 --> 00:19:34,960
safety interventions to warn child users

547
00:19:34,960 --> 00:19:37,840
about a potentially unsafe interaction

548
00:19:37,840 --> 00:19:39,679
and finally if you think that your users

549
00:19:39,679 --> 00:19:42,000
know best i'd like to see you poll them

550
00:19:42,000 --> 00:19:44,240
about what anti-abuse functionality they

551
00:19:44,240 --> 00:19:46,080
would like to see so that they feel

552
00:19:46,080 --> 00:19:48,400
better equipped to use your platform

553
00:19:48,400 --> 00:19:50,960
safely

554
00:19:50,960 --> 00:19:52,320
if you're interested in reading this

555
00:19:52,320 --> 00:19:54,559
paper on which this talk is based you

556
00:19:54,559 --> 00:19:56,080
can find it here

557
00:19:56,080 --> 00:19:58,080
i'd love to get your feedback

558
00:19:58,080 --> 00:20:00,400
below you can find my email address and

559
00:20:00,400 --> 00:20:02,240
my twitter handle

560
00:20:02,240 --> 00:20:04,480
thank you so much for attending my talk

561
00:20:04,480 --> 00:20:07,480
today

