1
00:00:08,160 --> 00:00:11,120
ah hello everyone

2
00:00:11,120 --> 00:00:13,599
hello

3
00:00:14,799 --> 00:00:16,560
i know this is the harder one

4
00:00:16,560 --> 00:00:17,520
but

5
00:00:17,520 --> 00:00:21,439
i'll try to stick to my time and uh

6
00:00:21,439 --> 00:00:22,640
deliver

7
00:00:22,640 --> 00:00:24,320
you know a good talk

8
00:00:24,320 --> 00:00:25,199
so

9
00:00:25,199 --> 00:00:27,119
topic is context-driven security i'm

10
00:00:27,119 --> 00:00:29,760
excited to be talking about this topic

11
00:00:29,760 --> 00:00:31,840
i've been researching on it for the past

12
00:00:31,840 --> 00:00:33,040
three years

13
00:00:33,040 --> 00:00:35,120
in different

14
00:00:35,120 --> 00:00:37,440
under different research

15
00:00:37,440 --> 00:00:39,680
agendas so what i'm going to be

16
00:00:39,680 --> 00:00:43,360
presenting today is one of the research

17
00:00:43,360 --> 00:00:46,480
interests that i've pursued

18
00:00:46,480 --> 00:00:48,719
so context-driven security need for a

19
00:00:48,719 --> 00:00:51,680
critical shift in threat intelligence

20
00:00:51,680 --> 00:00:54,640
it's the year 2022 wake up

21
00:00:54,640 --> 00:00:56,960
january has come to an end it's february

22
00:00:56,960 --> 00:00:59,520
and we can comfortably say that internet

23
00:00:59,520 --> 00:01:02,000
has is now only present

24
00:01:02,000 --> 00:01:04,000
everything is connected to the internet

25
00:01:04,000 --> 00:01:06,479
patients have sensors on their bodies

26
00:01:06,479 --> 00:01:07,840
smart homes

27
00:01:07,840 --> 00:01:11,119
healthcare education transportation

28
00:01:11,119 --> 00:01:14,479
finance insurance electricity education

29
00:01:14,479 --> 00:01:16,000
again

30
00:01:16,000 --> 00:01:18,159
manufacturing cyber attacks have

31
00:01:18,159 --> 00:01:20,799
targeted every single sector

32
00:01:20,799 --> 00:01:22,479
and i i know that this crowd doesn't

33
00:01:22,479 --> 00:01:23,759
need to be convinced about the

34
00:01:23,759 --> 00:01:25,920
importance of security and that it needs

35
00:01:25,920 --> 00:01:28,159
to touch every single sector that i just

36
00:01:28,159 --> 00:01:29,280
mentioned

37
00:01:29,280 --> 00:01:30,560
uh but

38
00:01:30,560 --> 00:01:33,280
out of curiosity i wanted to look up

39
00:01:33,280 --> 00:01:36,000
which is the you know the top most

40
00:01:36,000 --> 00:01:38,479
the the most important threat vector

41
00:01:38,479 --> 00:01:40,880
which impacts all of these industries

42
00:01:40,880 --> 00:01:43,520
that i just mentioned so i'm gonna take

43
00:01:43,520 --> 00:01:44,960
a minute and show you the dreaded

44
00:01:44,960 --> 00:01:47,759
histogram

45
00:01:47,840 --> 00:01:50,240
malware continues to be the most

46
00:01:50,240 --> 00:01:51,840
effective

47
00:01:51,840 --> 00:01:54,640
attack vector across all the sectors i

48
00:01:54,640 --> 00:01:56,479
mentioned i'm not going to show you what

49
00:01:56,479 --> 00:01:57,680
the rest of them are they're not

50
00:01:57,680 --> 00:01:59,920
important for this talk

51
00:01:59,920 --> 00:02:02,240
for us research researchers what is also

52
00:02:02,240 --> 00:02:03,520
important is that

53
00:02:03,520 --> 00:02:04,880
the topic that we are pursuing like

54
00:02:04,880 --> 00:02:07,200
malware research in my case

55
00:02:07,200 --> 00:02:09,598
we also need to get data

56
00:02:09,598 --> 00:02:10,560
to

57
00:02:10,560 --> 00:02:12,000
you know help

58
00:02:12,000 --> 00:02:14,879
with evaluations to support uh you know

59
00:02:14,879 --> 00:02:17,280
the reason that we are doing so

60
00:02:17,280 --> 00:02:19,280
therefore malware research was an

61
00:02:19,280 --> 00:02:22,319
interesting topic for me

62
00:02:22,319 --> 00:02:23,920
so let's center

63
00:02:23,920 --> 00:02:26,080
the malware threat impact on enterprise

64
00:02:26,080 --> 00:02:27,360
networks

65
00:02:27,360 --> 00:02:29,840
for the purpose of this talk but the

66
00:02:29,840 --> 00:02:32,800
impact of this research is across

67
00:02:32,800 --> 00:02:34,319
sectors

68
00:02:34,319 --> 00:02:35,280
and

69
00:02:35,280 --> 00:02:37,760
as we all know machine learning has done

70
00:02:37,760 --> 00:02:40,879
an outstanding job with both defending

71
00:02:40,879 --> 00:02:44,080
and preventing against cyber attacks

72
00:02:44,080 --> 00:02:46,160
emanating from this specific threat

73
00:02:46,160 --> 00:02:47,599
vector

74
00:02:47,599 --> 00:02:50,400
in fact an ai visionary arthur samuel

75
00:02:50,400 --> 00:02:52,319
defines machine learning

76
00:02:52,319 --> 00:02:53,440
as

77
00:02:53,440 --> 00:02:57,519
the ability to learn without programming

78
00:02:57,519 --> 00:02:59,680
without explicitly programming and with

79
00:02:59,680 --> 00:03:02,720
data because machine learning uses data

80
00:03:02,720 --> 00:03:05,440
and learns from it so

81
00:03:05,440 --> 00:03:08,239
this um i know many of you have a

82
00:03:08,239 --> 00:03:09,680
background in machine learning but not

83
00:03:09,680 --> 00:03:11,040
all of you

84
00:03:11,040 --> 00:03:14,000
so the training phase uh is you know

85
00:03:14,000 --> 00:03:16,239
when you train the machine learning

86
00:03:16,239 --> 00:03:18,000
model with this knowledge that you've

87
00:03:18,000 --> 00:03:19,760
gathered from the data

88
00:03:19,760 --> 00:03:21,200
and machine learning

89
00:03:21,200 --> 00:03:23,280
because machine learning algorithms so

90
00:03:23,280 --> 00:03:24,879
there's data there's algorithms and

91
00:03:24,879 --> 00:03:26,799
therefore models

92
00:03:26,799 --> 00:03:29,599
the algorithms can can reason

93
00:03:29,599 --> 00:03:31,519
the properties of previously unseen

94
00:03:31,519 --> 00:03:33,120
samples because they've learned from the

95
00:03:33,120 --> 00:03:34,959
data

96
00:03:34,959 --> 00:03:36,720
in malware detection

97
00:03:36,720 --> 00:03:39,519
uh a previously unseen sample could be a

98
00:03:39,519 --> 00:03:41,280
new file that

99
00:03:41,280 --> 00:03:44,000
will be uh that will be you know

100
00:03:44,000 --> 00:03:46,319
testing this model that we just learned

101
00:03:46,319 --> 00:03:49,760
uh and you will find out whether the

102
00:03:49,760 --> 00:03:52,560
the network was indeed protected against

103
00:03:52,560 --> 00:03:55,439
this new file this malware file so it is

104
00:03:55,439 --> 00:03:58,400
important to emphasize the importance of

105
00:03:58,400 --> 00:04:00,640
uh the the importance of

106
00:04:00,640 --> 00:04:03,200
the data-driven nature of this approach

107
00:04:03,200 --> 00:04:05,280
and uh so

108
00:04:05,280 --> 00:04:07,360
like in the training phase a model

109
00:04:07,360 --> 00:04:09,760
created for malware attack detection and

110
00:04:09,760 --> 00:04:12,640
prevention uh it depends on the data and

111
00:04:12,640 --> 00:04:15,680
it has seen during the training phase so

112
00:04:15,680 --> 00:04:17,680
that's an important concept uh that

113
00:04:17,680 --> 00:04:20,079
needs to be kept in mind uh so that it

114
00:04:20,079 --> 00:04:21,358
can determine

115
00:04:21,358 --> 00:04:22,160
uh

116
00:04:22,160 --> 00:04:22,960
which

117
00:04:22,960 --> 00:04:25,759
features are statistically

118
00:04:25,759 --> 00:04:28,639
significant or relevant

119
00:04:28,639 --> 00:04:32,000
for predicting if the file was actually

120
00:04:32,000 --> 00:04:35,040
malignant or malicious or benign so the

121
00:04:35,040 --> 00:04:36,560
statistical significance is very

122
00:04:36,560 --> 00:04:38,800
important and that comes from the data

123
00:04:38,800 --> 00:04:41,440
that the model has been trained on

124
00:04:41,440 --> 00:04:43,040
so that's

125
00:04:43,040 --> 00:04:44,800
uh something to keep in mind while i

126
00:04:44,800 --> 00:04:46,479
continue with the talk and most

127
00:04:46,479 --> 00:04:48,639
companies have used machine learning or

128
00:04:48,639 --> 00:04:51,520
are using machine learning um

129
00:04:51,520 --> 00:04:53,600
to us to to some degree in their

130
00:04:53,600 --> 00:04:55,120
intuition detection and prevention

131
00:04:55,120 --> 00:04:57,280
systems but machine learning has its

132
00:04:57,280 --> 00:04:58,960
limitations obviously because machine

133
00:04:58,960 --> 00:05:01,280
learning is hard that is the topic of

134
00:05:01,280 --> 00:05:04,479
this this uh this panel and we are going

135
00:05:04,479 --> 00:05:06,160
to be talking about those limitations

136
00:05:06,160 --> 00:05:07,919
and the circumstances where these

137
00:05:07,919 --> 00:05:09,360
limitations

138
00:05:09,360 --> 00:05:11,039
are more pronounced

139
00:05:11,039 --> 00:05:13,280
so we are increasingly recognizing

140
00:05:13,280 --> 00:05:15,680
recognizing these limitations and some

141
00:05:15,680 --> 00:05:17,680
of these challenges

142
00:05:17,680 --> 00:05:20,320
come in the form of false alerts false

143
00:05:20,320 --> 00:05:22,800
alerts uh false positives false

144
00:05:22,800 --> 00:05:25,280
negatives false negatives happen

145
00:05:25,280 --> 00:05:27,520
when a model mistakes a malicious label

146
00:05:27,520 --> 00:05:30,160
for a benign file and false positives

147
00:05:30,160 --> 00:05:31,120
happen

148
00:05:31,120 --> 00:05:33,280
when harmless file or url or an

149
00:05:33,280 --> 00:05:35,039
indicator

150
00:05:35,039 --> 00:05:37,919
that is being scanned in the model that

151
00:05:37,919 --> 00:05:39,840
we just talked about the trained model

152
00:05:39,840 --> 00:05:42,080
uh that i just talked about

153
00:05:42,080 --> 00:05:44,880
that model incorrectly identifies it as

154
00:05:44,880 --> 00:05:46,960
malicious that's false positives so

155
00:05:46,960 --> 00:05:48,479
together they caught they're called

156
00:05:48,479 --> 00:05:50,639
false alerts

157
00:05:50,639 --> 00:05:51,759
and they can't

158
00:05:51,759 --> 00:05:55,680
carry um serious consequences for users

159
00:05:55,680 --> 00:05:58,479
you can imagine that right so you will

160
00:05:58,479 --> 00:06:00,479
continue to see benign files and if

161
00:06:00,479 --> 00:06:02,880
they're tagged as or labeled as

162
00:06:02,880 --> 00:06:04,080
malicious

163
00:06:04,080 --> 00:06:05,520
somebody needs to take care of that

164
00:06:05,520 --> 00:06:08,560
those those people are sock analysts and

165
00:06:08,560 --> 00:06:09,440
uh

166
00:06:09,440 --> 00:06:11,120
you would say that we can impose higher

167
00:06:11,120 --> 00:06:13,600
requirements on the model

168
00:06:13,600 --> 00:06:15,520
and both you know the machine learning

169
00:06:15,520 --> 00:06:18,720
model and the matrix that are defining

170
00:06:18,720 --> 00:06:21,520
uh you know the thresholds whether this

171
00:06:21,520 --> 00:06:22,800
will be

172
00:06:22,800 --> 00:06:24,880
labeled as malicious or benign you can

173
00:06:24,880 --> 00:06:26,160
increase

174
00:06:26,160 --> 00:06:27,840
those thresholds or

175
00:06:27,840 --> 00:06:29,680
you know impose higher requirements for

176
00:06:29,680 --> 00:06:32,160
your models

177
00:06:32,160 --> 00:06:33,520
even then

178
00:06:33,520 --> 00:06:36,479
even then it is it is very difficult to

179
00:06:36,479 --> 00:06:37,680
get rid of

180
00:06:37,680 --> 00:06:40,400
uh you know false positives and false

181
00:06:40,400 --> 00:06:43,280
negatives in fact uh

182
00:06:43,280 --> 00:06:45,440
i was looking around for some specific

183
00:06:45,440 --> 00:06:46,240
uh

184
00:06:46,240 --> 00:06:49,120
data around this and top companies the

185
00:06:49,120 --> 00:06:50,720
the products that they build

186
00:06:50,720 --> 00:06:53,520
uh each product sees terabytes of data

187
00:06:53,520 --> 00:06:56,400
every day and even if a fraction of that

188
00:06:56,400 --> 00:06:57,840
is false alert you can imagine the

189
00:06:57,840 --> 00:06:59,440
amount of time money

190
00:06:59,440 --> 00:07:01,280
goes into uh

191
00:07:01,280 --> 00:07:03,360
analyzing why are we seeing these false

192
00:07:03,360 --> 00:07:06,639
alerts and they can't just let pass

193
00:07:06,639 --> 00:07:09,440
those alerts and what they cause

194
00:07:09,440 --> 00:07:12,400
because of the amount they cause

195
00:07:12,400 --> 00:07:15,360
alert fatigue the analysts

196
00:07:15,360 --> 00:07:16,960
is not able to

197
00:07:16,960 --> 00:07:18,479
manually

198
00:07:18,479 --> 00:07:20,639
analyze those alerts

199
00:07:20,639 --> 00:07:23,280
after a point

200
00:07:23,280 --> 00:07:25,360
so

201
00:07:25,360 --> 00:07:26,479
problem

202
00:07:26,479 --> 00:07:27,840
now we've understood what we're going to

203
00:07:27,840 --> 00:07:30,639
be targeting let's talk about

204
00:07:30,639 --> 00:07:32,000
let's shift gears

205
00:07:32,000 --> 00:07:34,000
uh towards solutions

206
00:07:34,000 --> 00:07:36,880
so um that's what this this research i'm

207
00:07:36,880 --> 00:07:39,680
going to talk about is focus towards

208
00:07:39,680 --> 00:07:42,720
but breaking down the problem into p1 p2

209
00:07:42,720 --> 00:07:45,199
p1 is lack of enough representative data

210
00:07:45,199 --> 00:07:47,199
to test rules and that's why i was

211
00:07:47,199 --> 00:07:50,080
emphasizing on the training uh

212
00:07:50,080 --> 00:07:53,360
aspect of the the learning model that if

213
00:07:53,360 --> 00:07:56,080
there is no representation

214
00:07:56,080 --> 00:07:57,520
in the machine learning model it will be

215
00:07:57,520 --> 00:07:59,759
very challenging for the model to

216
00:07:59,759 --> 00:08:02,639
actually uh to find that

217
00:08:02,639 --> 00:08:03,599
uh

218
00:08:03,599 --> 00:08:05,840
you know to be able to label uh a new

219
00:08:05,840 --> 00:08:08,560
file and then the other problem is

220
00:08:08,560 --> 00:08:10,240
deluge of false alerts that i just

221
00:08:10,240 --> 00:08:13,039
talked about the too many uh to be dealt

222
00:08:13,039 --> 00:08:15,440
with even if you have prioritized them

223
00:08:15,440 --> 00:08:17,199
from low medium-hardened focusing only

224
00:08:17,199 --> 00:08:19,440
on the high ones even then they're just

225
00:08:19,440 --> 00:08:21,919
too many

226
00:08:21,919 --> 00:08:23,199
so

227
00:08:23,199 --> 00:08:25,440
for problem number one lack of enough

228
00:08:25,440 --> 00:08:27,840
representative thera

229
00:08:27,840 --> 00:08:29,520
one solution that

230
00:08:29,520 --> 00:08:30,639
we have

231
00:08:30,639 --> 00:08:32,159
in with that that we are pursuing is

232
00:08:32,159 --> 00:08:34,479
continuous learning uh

233
00:08:34,479 --> 00:08:37,760
and then add most recent data so

234
00:08:37,760 --> 00:08:40,159
new attack vectors new vulnerabilities

235
00:08:40,159 --> 00:08:41,360
keep coming in

236
00:08:41,360 --> 00:08:42,880
uh they're

237
00:08:42,880 --> 00:08:44,640
they're more they're

238
00:08:44,640 --> 00:08:47,519
the way they are attacking those attack

239
00:08:47,519 --> 00:08:49,760
patterns also keep changing uh the

240
00:08:49,760 --> 00:08:51,839
vulnerability might remain the same but

241
00:08:51,839 --> 00:08:54,480
the but the attack pattern might change

242
00:08:54,480 --> 00:08:57,440
so how do we include that into our

243
00:08:57,440 --> 00:08:58,800
learning model

244
00:08:58,800 --> 00:09:01,120
well you increase the data that is being

245
00:09:01,120 --> 00:09:03,120
used to train the model

246
00:09:03,120 --> 00:09:05,279
and i'm going to talk about that in in

247
00:09:05,279 --> 00:09:07,120
the upcoming slides and the other one is

248
00:09:07,120 --> 00:09:09,519
triaging alerts how do you triage alerts

249
00:09:09,519 --> 00:09:11,360
how do you prioritize even the high

250
00:09:11,360 --> 00:09:12,480
priority

251
00:09:12,480 --> 00:09:14,720
alerts

252
00:09:14,720 --> 00:09:16,560
this is this talk is about context

253
00:09:16,560 --> 00:09:19,360
adding context to security so

254
00:09:19,360 --> 00:09:21,279
the direction that we have taken is that

255
00:09:21,279 --> 00:09:24,959
you provide context to your alerts

256
00:09:24,959 --> 00:09:26,640
focusing on the first one first

257
00:09:26,640 --> 00:09:29,200
continuous learning uh add most recent

258
00:09:29,200 --> 00:09:30,160
data

259
00:09:30,160 --> 00:09:31,440
so

260
00:09:31,440 --> 00:09:33,680
continuous learning how does that happen

261
00:09:33,680 --> 00:09:34,720
uh

262
00:09:34,720 --> 00:09:36,959
we found that

263
00:09:36,959 --> 00:09:39,839
so enterprises are constantly you know

264
00:09:39,839 --> 00:09:42,880
uh analyzing their internal telemetry is

265
00:09:42,880 --> 00:09:46,000
coming from logs uh network data

266
00:09:46,000 --> 00:09:47,680
host-based data all of that is getting

267
00:09:47,680 --> 00:09:49,200
analyzed

268
00:09:49,200 --> 00:09:51,360
there is an additional source of data

269
00:09:51,360 --> 00:09:53,600
that can be included in that analysis

270
00:09:53,600 --> 00:09:55,120
and that comes from the internet there

271
00:09:55,120 --> 00:09:57,440
are lots of open source threat

272
00:09:57,440 --> 00:09:58,720
information

273
00:09:58,720 --> 00:10:01,519
that is easily and

274
00:10:01,519 --> 00:10:04,000
from what i have seen freely available

275
00:10:04,000 --> 00:10:07,040
to a degree there is noise in the free

276
00:10:07,040 --> 00:10:08,959
version but that's what i was able to

277
00:10:08,959 --> 00:10:10,560
access

278
00:10:10,560 --> 00:10:12,880
so free freely available open source

279
00:10:12,880 --> 00:10:15,680
open source threat intelligence

280
00:10:15,680 --> 00:10:18,079
written by

281
00:10:18,079 --> 00:10:19,440
sorry i should have moved that moved on

282
00:10:19,440 --> 00:10:21,120
to this one so open source threat

283
00:10:21,120 --> 00:10:24,000
intelligence uh aggregation is what uh

284
00:10:24,000 --> 00:10:25,120
we are

285
00:10:25,120 --> 00:10:27,279
we are we are pursuing as a way to

286
00:10:27,279 --> 00:10:30,399
increase the the learning of the models

287
00:10:30,399 --> 00:10:33,200
uh by increasing the data and this data

288
00:10:33,200 --> 00:10:35,279
is most recent and how do we get that

289
00:10:35,279 --> 00:10:38,560
i'll talk about that so these uh the

290
00:10:38,560 --> 00:10:41,200
open source intelligence actually uh

291
00:10:41,200 --> 00:10:43,760
covers is written by researchers

292
00:10:43,760 --> 00:10:46,720
on trending attacks and what are the

293
00:10:46,720 --> 00:10:49,279
defense mechanisms against those attacks

294
00:10:49,279 --> 00:10:51,200
these might be opinions these might be

295
00:10:51,200 --> 00:10:53,600
blocks these might be actual threat

296
00:10:53,600 --> 00:10:55,680
reports and at the same time these might

297
00:10:55,680 --> 00:10:57,839
these might exist in the dark web where

298
00:10:57,839 --> 00:11:01,519
people have recently encountered uh

299
00:11:01,519 --> 00:11:04,560
you know a new payload or uh

300
00:11:04,560 --> 00:11:07,200
a novel way of

301
00:11:07,200 --> 00:11:09,440
of using an existing vulnerability so

302
00:11:09,440 --> 00:11:11,519
all that getting discussed we can

303
00:11:11,519 --> 00:11:14,079
aggregate that data and that's what open

304
00:11:14,079 --> 00:11:16,160
source threat intelligence

305
00:11:16,160 --> 00:11:18,560
aggregation means and these can be very

306
00:11:18,560 --> 00:11:20,800
useful although unstructured

307
00:11:20,800 --> 00:11:22,640
so i want to show you what i'm referring

308
00:11:22,640 --> 00:11:24,720
to this is more of a

309
00:11:24,720 --> 00:11:25,600
more

310
00:11:25,600 --> 00:11:29,040
you know official and a a better version

311
00:11:29,040 --> 00:11:31,600
of what threat reports are and threat

312
00:11:31,600 --> 00:11:34,720
intelligence looks like uh from mcafee

313
00:11:34,720 --> 00:11:38,160
and this is on uh the sunburst trojan

314
00:11:38,160 --> 00:11:39,920
and uh

315
00:11:39,920 --> 00:11:42,399
so what they basically uh

316
00:11:42,399 --> 00:11:44,079
the the information that is included in

317
00:11:44,079 --> 00:11:46,720
the in these threat reports is

318
00:11:46,720 --> 00:11:49,920
uh how the the attack was discovered uh

319
00:11:49,920 --> 00:11:52,079
the the pattern the attack pattern of

320
00:11:52,079 --> 00:11:54,320
that specific malware uh the

321
00:11:54,320 --> 00:11:57,440
vulnerabilities that were used uh the

322
00:11:57,440 --> 00:11:59,279
indicators of compromise

323
00:11:59,279 --> 00:12:00,079
and

324
00:12:00,079 --> 00:12:02,399
attack patterns and so on and so forth

325
00:12:02,399 --> 00:12:04,000
so although these are unstructured

326
00:12:04,000 --> 00:12:06,560
reports uh these are essentially

327
00:12:06,560 --> 00:12:08,240
opinions written by security analysts

328
00:12:08,240 --> 00:12:11,920
who have varying degrees uh of expertise

329
00:12:11,920 --> 00:12:14,320
and uh and you know also based on the

330
00:12:14,320 --> 00:12:16,240
information available in hand at that

331
00:12:16,240 --> 00:12:17,519
point of time when they wrote that

332
00:12:17,519 --> 00:12:19,920
report so

333
00:12:19,920 --> 00:12:22,560
this is an essential source of new

334
00:12:22,560 --> 00:12:24,639
information that we can gather and you

335
00:12:24,639 --> 00:12:27,519
won't get this from uh binary and you

336
00:12:27,519 --> 00:12:29,600
know from from binaries by static

337
00:12:29,600 --> 00:12:32,079
analysis or behavioral analysis or

338
00:12:32,079 --> 00:12:34,240
dynamic analysis these are written

339
00:12:34,240 --> 00:12:36,800
in uh human you know understandable

340
00:12:36,800 --> 00:12:39,200
language and covers context which

341
00:12:39,200 --> 00:12:41,120
otherwise wouldn't be possible to

342
00:12:41,120 --> 00:12:44,000
capture in code

343
00:12:44,079 --> 00:12:45,839
so that's the advantage that we see in

344
00:12:45,839 --> 00:12:48,720
using this kind of threat information so

345
00:12:48,720 --> 00:12:50,000
our

346
00:12:50,000 --> 00:12:51,760
research uses knowledge graphs to

347
00:12:51,760 --> 00:12:56,000
capture this kind of information

348
00:12:56,000 --> 00:12:58,560
and it's a significant endeavor

349
00:12:58,560 --> 00:13:00,560
it's the data is unstructured how do you

350
00:13:00,560 --> 00:13:03,519
know what to capture how to capture how

351
00:13:03,519 --> 00:13:04,839
accurate that

352
00:13:04,839 --> 00:13:06,959
uh that

353
00:13:06,959 --> 00:13:08,800
that the data is that you've captured

354
00:13:08,800 --> 00:13:10,160
from these unstructured sources of

355
00:13:10,160 --> 00:13:11,519
information

356
00:13:11,519 --> 00:13:13,519
uh and it requires

357
00:13:13,519 --> 00:13:17,920
multi-disciplinary expertise uh in uh

358
00:13:17,920 --> 00:13:18,880
you know

359
00:13:18,880 --> 00:13:21,519
in in the domain in machine learning in

360
00:13:21,519 --> 00:13:23,200
natural language processing information

361
00:13:23,200 --> 00:13:24,399
extraction

362
00:13:24,399 --> 00:13:28,160
and uh of course about security

363
00:13:28,160 --> 00:13:30,240
so let's first talk about how do we

364
00:13:30,240 --> 00:13:32,320
generate a knowledge graph so first i'm

365
00:13:32,320 --> 00:13:33,920
going to show you what a knowledge graph

366
00:13:33,920 --> 00:13:36,480
looks like so for i know it's a little

367
00:13:36,480 --> 00:13:37,519
small

368
00:13:37,519 --> 00:13:39,040
but i'll try

369
00:13:39,040 --> 00:13:40,560
so these are small dots which are

370
00:13:40,560 --> 00:13:42,959
vertices of a large graph

371
00:13:42,959 --> 00:13:45,920
varying in sizes and these are connected

372
00:13:45,920 --> 00:13:48,720
by edges and these edges are essentially

373
00:13:48,720 --> 00:13:50,639
a relationship between

374
00:13:50,639 --> 00:13:52,720
between two uh

375
00:13:52,720 --> 00:13:55,120
between two of these vertices which

376
00:13:55,120 --> 00:13:57,040
means that these two vertices have a

377
00:13:57,040 --> 00:13:59,199
relationship there is a context which

378
00:13:59,199 --> 00:14:01,600
exists between this

379
00:14:01,600 --> 00:14:03,519
circle in this circle so this is

380
00:14:03,519 --> 00:14:05,920
different from a generic graph that you

381
00:14:05,920 --> 00:14:08,000
might have studied in maybe a graph

382
00:14:08,000 --> 00:14:10,800
analytics class or graph theory class

383
00:14:10,800 --> 00:14:12,720
and towards the right of this is

384
00:14:12,720 --> 00:14:14,160
actually a legend

385
00:14:14,160 --> 00:14:17,120
this was generated using neo4j and what

386
00:14:17,120 --> 00:14:20,160
this legend is uh so for example the the

387
00:14:20,160 --> 00:14:22,880
beautiful orange colored circle is about

388
00:14:22,880 --> 00:14:25,519
manware so these orange circles that

389
00:14:25,519 --> 00:14:28,959
you're seeing are malware uh which was

390
00:14:28,959 --> 00:14:30,560
recognized or

391
00:14:30,560 --> 00:14:34,079
the data about it was extracted from the

392
00:14:34,079 --> 00:14:36,560
reports that i just showed you

393
00:14:36,560 --> 00:14:38,399
the light colored ones are the light

394
00:14:38,399 --> 00:14:40,880
oranges malware family and then there

395
00:14:40,880 --> 00:14:43,760
are there is location-based information

396
00:14:43,760 --> 00:14:45,680
where was this where was the impact of

397
00:14:45,680 --> 00:14:48,560
the malware uh found uh what

398
00:14:48,560 --> 00:14:51,120
vulnerabilities were used to compromise

399
00:14:51,120 --> 00:14:52,399
the platform

400
00:14:52,399 --> 00:14:54,320
and so on and so forth

401
00:14:54,320 --> 00:14:56,079
i believe it all of this was captured

402
00:14:56,079 --> 00:14:59,600
only using threat reports and this was

403
00:14:59,600 --> 00:15:02,320
uh from 25 threat reports

404
00:15:02,320 --> 00:15:05,040
and and basically uh just a handful of

405
00:15:05,040 --> 00:15:07,760
malware information was collected

406
00:15:07,760 --> 00:15:10,639
um and then there is another one just so

407
00:15:10,639 --> 00:15:13,040
i can make the uh the concept a bit

408
00:15:13,040 --> 00:15:15,440
clearer so there is all of these are

409
00:15:15,440 --> 00:15:16,720
malwares which are connected to one

410
00:15:16,720 --> 00:15:19,279
another or they're aliases because not

411
00:15:19,279 --> 00:15:20,959
every security company will be using the

412
00:15:20,959 --> 00:15:23,360
same name uh so you need to capture the

413
00:15:23,360 --> 00:15:26,160
aliases so so that you can capture other

414
00:15:26,160 --> 00:15:29,120
details and then combine them and form a

415
00:15:29,120 --> 00:15:31,839
knowledge graph which can be used for

416
00:15:31,839 --> 00:15:34,160
excuse me use for further analysis now

417
00:15:34,160 --> 00:15:36,880
now let's pick one example so flubart

418
00:15:36,880 --> 00:15:39,279
malware has picked up again

419
00:15:39,279 --> 00:15:41,040
it's been around for the past three four

420
00:15:41,040 --> 00:15:43,600
years uh hard to tell when

421
00:15:43,600 --> 00:15:45,759
um because there is always some report

422
00:15:45,759 --> 00:15:48,480
which says that oh a version of it or an

423
00:15:48,480 --> 00:15:51,519
alias of it existed a year ago so i know

424
00:15:51,519 --> 00:15:54,720
it's a small one so i decided to zoom in

425
00:15:54,720 --> 00:15:56,320
now what you're seeing in front of you

426
00:15:56,320 --> 00:15:58,800
these dark colored oranges is one of

427
00:15:58,800 --> 00:16:00,320
them is flubot and the others are

428
00:16:00,320 --> 00:16:04,079
aliases of flu bot flubot malware

429
00:16:04,079 --> 00:16:05,440
and then there is you know same

430
00:16:05,440 --> 00:16:08,480
information location when what when was

431
00:16:08,480 --> 00:16:11,519
uh this flu bot uh you know detected in

432
00:16:11,519 --> 00:16:13,040
a certain location

433
00:16:13,040 --> 00:16:16,800
uh and and name of the the uh different

434
00:16:16,800 --> 00:16:17,839
countries

435
00:16:17,839 --> 00:16:20,959
uh and the impact on devices and so on

436
00:16:20,959 --> 00:16:22,399
and so forth but what is really

437
00:16:22,399 --> 00:16:24,720
interesting are these blue colored

438
00:16:24,720 --> 00:16:26,959
bubbles what these blue colored bubbles

439
00:16:26,959 --> 00:16:29,360
are attack patterns attack patterns

440
00:16:29,360 --> 00:16:30,800
which were captured from these threat

441
00:16:30,800 --> 00:16:31,920
reports

442
00:16:31,920 --> 00:16:34,880
and combining these will give you from

443
00:16:34,880 --> 00:16:37,279
multiple threat reports combining these

444
00:16:37,279 --> 00:16:40,800
can give you the entire kill chain of

445
00:16:40,800 --> 00:16:43,839
this specific malware and that's what

446
00:16:43,839 --> 00:16:45,360
the biggest

447
00:16:45,360 --> 00:16:47,360
takeaway or biggest advantage of using

448
00:16:47,360 --> 00:16:49,759
knowledge graphs is that by using this

449
00:16:49,759 --> 00:16:53,040
unstructured information written in

450
00:16:53,040 --> 00:16:55,120
indian language understood by humans you

451
00:16:55,120 --> 00:16:56,959
can capture this kind of

452
00:16:56,959 --> 00:17:00,240
details about that malware and

453
00:17:00,240 --> 00:17:02,720
extrapolating that consider many such

454
00:17:02,720 --> 00:17:05,119
malwares as part of a very large

455
00:17:05,119 --> 00:17:06,880
knowledge graph

456
00:17:06,880 --> 00:17:09,679
all of this combined can tell you uh

457
00:17:09,679 --> 00:17:13,119
attack patterns or infer attack patents

458
00:17:13,119 --> 00:17:14,880
with little information

459
00:17:14,880 --> 00:17:18,240
as in when a malware threat is evolving

460
00:17:18,240 --> 00:17:19,919
that's the advantage of using knowledge

461
00:17:19,919 --> 00:17:21,359
graphs and that's

462
00:17:21,359 --> 00:17:25,199
what this research is pursuing

463
00:17:25,199 --> 00:17:27,599
okay now adding context we talked about

464
00:17:27,599 --> 00:17:28,960
uh

465
00:17:28,960 --> 00:17:32,400
gathering data from the internet uh

466
00:17:32,400 --> 00:17:34,240
and how do we add context so that

467
00:17:34,240 --> 00:17:36,160
essentially we want to help the stock

468
00:17:36,160 --> 00:17:37,600
analysts right

469
00:17:37,600 --> 00:17:39,440
uh so problem number two was adding

470
00:17:39,440 --> 00:17:42,640
context but to get context you need to

471
00:17:42,640 --> 00:17:45,280
add context to your models if you're not

472
00:17:45,280 --> 00:17:47,520
adding context how will you get context

473
00:17:47,520 --> 00:17:49,120
as an output

474
00:17:49,120 --> 00:17:51,918
so uh

475
00:17:52,720 --> 00:17:55,039
provenance reasoning and trust these are

476
00:17:55,039 --> 00:17:56,960
some of the ways where context can be

477
00:17:56,960 --> 00:17:59,760
added and the the areas that i pursued

478
00:17:59,760 --> 00:18:00,799
so far

479
00:18:00,799 --> 00:18:03,679
um so provenance can come from wiki data

480
00:18:03,679 --> 00:18:05,840
wiki data is an is a very reliable

481
00:18:05,840 --> 00:18:07,280
source

482
00:18:07,280 --> 00:18:08,160
of

483
00:18:08,160 --> 00:18:10,240
information what can be done is the

484
00:18:10,240 --> 00:18:11,760
knowledge graph that i just showed you

485
00:18:11,760 --> 00:18:13,919
those bubbles if you click on one of

486
00:18:13,919 --> 00:18:15,679
those bubbles

487
00:18:15,679 --> 00:18:18,640
we have connected that to the to the

488
00:18:18,640 --> 00:18:20,320
concepts which have been described in

489
00:18:20,320 --> 00:18:22,799
wikidata you click on it and it will

490
00:18:22,799 --> 00:18:24,640
show you the description

491
00:18:24,640 --> 00:18:27,520
of a specific malware or a location

492
00:18:27,520 --> 00:18:29,520
and that's

493
00:18:29,520 --> 00:18:31,919
automated it has automatically been

494
00:18:31,919 --> 00:18:33,919
connected to wikidata now you would

495
00:18:33,919 --> 00:18:36,400
wonder why is it important and i'll tell

496
00:18:36,400 --> 00:18:38,799
you a very interesting example

497
00:18:38,799 --> 00:18:41,280
so there was this

498
00:18:41,280 --> 00:18:43,840
um attack on google a couple of years

499
00:18:43,840 --> 00:18:45,600
ago aurora

500
00:18:45,600 --> 00:18:48,400
you might have heard of it so

501
00:18:48,400 --> 00:18:50,880
when you are extracting information

502
00:18:50,880 --> 00:18:51,760
which

503
00:18:51,760 --> 00:18:53,760
is called aurora

504
00:18:53,760 --> 00:18:55,919
the extraction models will not

505
00:18:55,919 --> 00:18:58,000
understand that aurora was actually a

506
00:18:58,000 --> 00:18:59,039
campaign

507
00:18:59,039 --> 00:19:02,400
it will call aurora as the northern uh

508
00:19:02,400 --> 00:19:05,280
northern lights in i think in ireland

509
00:19:05,280 --> 00:19:06,480
somewhere

510
00:19:06,480 --> 00:19:07,280
right

511
00:19:07,280 --> 00:19:10,799
uh so that's that confusion is uh is

512
00:19:10,799 --> 00:19:13,039
obvious and we want to minimize those

513
00:19:13,039 --> 00:19:15,440
kind of uh those confusions when we are

514
00:19:15,440 --> 00:19:18,320
automating our systems so

515
00:19:18,320 --> 00:19:21,039
wiki data essentially was able to

516
00:19:21,039 --> 00:19:23,679
easily uh you know give us that uh

517
00:19:23,679 --> 00:19:26,240
definition of aurora and the campaign

518
00:19:26,240 --> 00:19:28,880
not our the northern lights

519
00:19:28,880 --> 00:19:30,480
the other one is open source threat

520
00:19:30,480 --> 00:19:33,760
intelligence uh sources so these threat

521
00:19:33,760 --> 00:19:35,840
reports are coming from somewhere

522
00:19:35,840 --> 00:19:39,280
right and that somewhere can become our

523
00:19:39,280 --> 00:19:41,679
um anchor

524
00:19:41,679 --> 00:19:43,600
many of these reports come from

525
00:19:43,600 --> 00:19:45,520
prestigious companies kaspersky

526
00:19:45,520 --> 00:19:49,440
microsoft security reports uh mcafee and

527
00:19:49,440 --> 00:19:53,360
so on and so forth uh that can be tied

528
00:19:53,360 --> 00:19:55,200
in fact we have tied that to the

529
00:19:55,200 --> 00:19:57,120
knowledge graph and that provides

530
00:19:57,120 --> 00:19:59,520
provenance and and for a security

531
00:19:59,520 --> 00:20:01,360
analyst it's important

532
00:20:01,360 --> 00:20:04,880
uh to at the time of analyzing

533
00:20:04,880 --> 00:20:07,200
false positives where did we get this

534
00:20:07,200 --> 00:20:08,799
information from

535
00:20:08,799 --> 00:20:11,520
it's it's a very quick way for them to

536
00:20:11,520 --> 00:20:14,000
go back and look at in fact trace the

537
00:20:14,000 --> 00:20:16,640
alert to the source of the information

538
00:20:16,640 --> 00:20:18,960
so that's why provenance is important

539
00:20:18,960 --> 00:20:21,200
reasoning comes from knowledge grabs and

540
00:20:21,200 --> 00:20:23,919
ontology we we followed the ontology or

541
00:20:23,919 --> 00:20:28,720
taxonomy based approach because um

542
00:20:28,720 --> 00:20:31,520
because we created knowledge graphs with

543
00:20:31,520 --> 00:20:33,679
certain questions in mind and those

544
00:20:33,679 --> 00:20:35,280
questions can be answered if you give

545
00:20:35,280 --> 00:20:36,960
them a structure

546
00:20:36,960 --> 00:20:38,880
and structure comes from

547
00:20:38,880 --> 00:20:41,600
classes classes can be

548
00:20:41,600 --> 00:20:44,400
can be defined in ontologies so i don't

549
00:20:44,400 --> 00:20:46,559
want to go into that because of the

550
00:20:46,559 --> 00:20:48,080
limited time we have and then there is

551
00:20:48,080 --> 00:20:49,919
trust that's an area that i'm still

552
00:20:49,919 --> 00:20:52,159
pursuing how do you add trust to to the

553
00:20:52,159 --> 00:20:54,559
models which are extracting data as well

554
00:20:54,559 --> 00:20:57,840
as to uh to the source of information

555
00:20:57,840 --> 00:21:00,240
uh so how do we get from how much time

556
00:21:00,240 --> 00:21:03,600
do i have one minute okay okay okay

557
00:21:03,600 --> 00:21:06,320
so how do we get from here to here i

558
00:21:06,320 --> 00:21:09,679
think that's a valid question i already

559
00:21:09,679 --> 00:21:12,400
talked about ontologies and then there's

560
00:21:12,400 --> 00:21:15,200
in information extraction models named

561
00:21:15,200 --> 00:21:16,880
entity recognition and relation

562
00:21:16,880 --> 00:21:18,159
extraction

563
00:21:18,159 --> 00:21:20,159
so it's it's a multi-disciplinary

564
00:21:20,159 --> 00:21:22,799
research uh

565
00:21:22,799 --> 00:21:24,640
where you need in uh

566
00:21:24,640 --> 00:21:26,159
well nlp

567
00:21:26,159 --> 00:21:27,679
and then there's disambiguation core

568
00:21:27,679 --> 00:21:30,799
referencing and deduplication

569
00:21:30,799 --> 00:21:34,080
with this large corpus of data comes

570
00:21:34,080 --> 00:21:36,400
noise there's there comes duplications

571
00:21:36,400 --> 00:21:40,000
there comes pronouns so you need to

572
00:21:40,000 --> 00:21:42,320
clear them all up so that your knowledge

573
00:21:42,320 --> 00:21:45,600
graph has minimal noise

574
00:21:45,600 --> 00:21:47,520
uh this is the

575
00:21:47,520 --> 00:21:50,240
architecture for the first malware

576
00:21:50,240 --> 00:21:52,159
knowledge graph that we created i don't

577
00:21:52,159 --> 00:21:54,400
want to get into it but it mostly talks

578
00:21:54,400 --> 00:21:56,240
it mostly covers what i already talked

579
00:21:56,240 --> 00:21:58,080
about

580
00:21:58,080 --> 00:22:01,600
so how do we use this knowledge graph

581
00:22:01,600 --> 00:22:02,960
we have a case study in one of the

582
00:22:02,960 --> 00:22:04,400
papers

583
00:22:04,400 --> 00:22:07,039
so you pose a query to this knowledge

584
00:22:07,039 --> 00:22:08,559
graph like

585
00:22:08,559 --> 00:22:10,480
there's an indicator of compromise

586
00:22:10,480 --> 00:22:12,799
coronavirus themed attacks and the

587
00:22:12,799 --> 00:22:14,960
relation which is the line that

588
00:22:14,960 --> 00:22:17,280
that that is connecting these these

589
00:22:17,280 --> 00:22:20,640
circles targets so you have a query

590
00:22:20,640 --> 00:22:23,039
corona wise streamed attacks targets and

591
00:22:23,039 --> 00:22:24,640
what it will give you is a set of

592
00:22:24,640 --> 00:22:25,679
results

593
00:22:25,679 --> 00:22:28,480
and these are the options that are

594
00:22:28,480 --> 00:22:30,559
potential answers

595
00:22:30,559 --> 00:22:33,039
and you get that with a confidence score

596
00:22:33,039 --> 00:22:35,600
and along with that also the data source

597
00:22:35,600 --> 00:22:37,120
from which

598
00:22:37,120 --> 00:22:37,919
uh

599
00:22:37,919 --> 00:22:40,480
this information was extracted so this

600
00:22:40,480 --> 00:22:43,200
is how we are adding context to the

601
00:22:43,200 --> 00:22:44,320
results

602
00:22:44,320 --> 00:22:46,960
of our predictions uh if that data

603
00:22:46,960 --> 00:22:48,960
exists and if that data does not exist

604
00:22:48,960 --> 00:22:51,200
then it becomes inference

605
00:22:51,200 --> 00:22:53,280
so parting notes

606
00:22:53,280 --> 00:22:56,080
end of the talk is we need to go beyond

607
00:22:56,080 --> 00:22:59,120
measuring the performance of models

608
00:22:59,120 --> 00:23:02,000
using accuracy precision f1 scores we

609
00:23:02,000 --> 00:23:04,159
want to be able to help

610
00:23:04,159 --> 00:23:06,640
analysts by inferring with confidence

611
00:23:06,640 --> 00:23:08,799
and context

612
00:23:08,799 --> 00:23:09,760
and then

613
00:23:09,760 --> 00:23:12,080
that's the research frontier it's

614
00:23:12,080 --> 00:23:14,559
triaging at scale and automation

615
00:23:14,559 --> 00:23:16,559
so i'll be happy to take questions now

616
00:23:16,559 --> 00:23:19,799
thank you

617
00:23:26,240 --> 00:23:28,320
you

