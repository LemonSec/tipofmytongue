1
00:00:08,080 --> 00:00:10,240
uh so my talk is

2
00:00:10,240 --> 00:00:12,240
long titled

3
00:00:12,240 --> 00:00:13,519
you can't always get what you want but

4
00:00:13,519 --> 00:00:14,880
you get what you need

5
00:00:14,880 --> 00:00:16,960
because when we deal with the very

6
00:00:16,960 --> 00:00:19,520
thorny issues of content moderation and

7
00:00:19,520 --> 00:00:21,680
into encrypted environment

8
00:00:21,680 --> 00:00:24,000
those problems are

9
00:00:24,000 --> 00:00:26,080
really difficult to solve so they're not

10
00:00:26,080 --> 00:00:28,160
always going to be perfect solutions

11
00:00:28,160 --> 00:00:31,199
paper came out in august

12
00:00:31,199 --> 00:00:32,000
um

13
00:00:32,000 --> 00:00:34,480
last august 2021

14
00:00:34,480 --> 00:00:35,840
it was published by the center for

15
00:00:35,840 --> 00:00:38,079
democracy and technology and the title

16
00:00:38,079 --> 00:00:39,760
of the paper is not the title of this

17
00:00:39,760 --> 00:00:42,480
talk it's it's titled outside looking in

18
00:00:42,480 --> 00:00:44,719
approaches to content moderation and

19
00:00:44,719 --> 00:00:48,160
into inter-encrypted systems

20
00:00:48,160 --> 00:00:50,800
and i have to thank also the folks who

21
00:00:50,800 --> 00:00:52,480
helped with it so there were others at

22
00:00:52,480 --> 00:00:55,440
cdt um it was a group effort

23
00:00:55,440 --> 00:00:56,879
and alonso who's our freedom of

24
00:00:56,879 --> 00:00:59,440
expression director greg nogin who leads

25
00:00:59,440 --> 00:01:02,239
our security and surveillance team

26
00:01:02,239 --> 00:01:04,319
also from brown we had cindy kamara

27
00:01:04,319 --> 00:01:06,960
who's also speaking this week and lucy

28
00:01:06,960 --> 00:01:08,479
kin who helped

29
00:01:08,479 --> 00:01:11,040
with that publication and i have to also

30
00:01:11,040 --> 00:01:13,600
thank my um co co-author and

31
00:01:13,600 --> 00:01:15,920
co-illustrator for the slides that she

32
00:01:15,920 --> 00:01:17,600
made um for me

33
00:01:17,600 --> 00:01:18,799
um

34
00:01:18,799 --> 00:01:21,439
this for this talk so so the first part

35
00:01:21,439 --> 00:01:23,439
of the paper and what's really important

36
00:01:23,439 --> 00:01:25,920
when we embark on this subject is

37
00:01:25,920 --> 00:01:27,200
understanding

38
00:01:27,200 --> 00:01:28,880
content moderation and then

39
00:01:28,880 --> 00:01:30,560
understanding

40
00:01:30,560 --> 00:01:32,240
into in decryption and then we put them

41
00:01:32,240 --> 00:01:34,240
together and we look at a variety of

42
00:01:34,240 --> 00:01:36,880
different proposals for how to do

43
00:01:36,880 --> 00:01:40,000
content moderation in indian encryption

44
00:01:40,000 --> 00:01:41,680
but when i start talking about content

45
00:01:41,680 --> 00:01:43,439
moderation first i want to be clear on

46
00:01:43,439 --> 00:01:45,119
the scope

47
00:01:45,119 --> 00:01:47,280
of what content moderation can do and

48
00:01:47,280 --> 00:01:50,079
can't do or what it aims to do so folks

49
00:01:50,079 --> 00:01:51,600
that are familiar with

50
00:01:51,600 --> 00:01:53,040
content moderation will know all this

51
00:01:53,040 --> 00:01:55,280
already so the first thing

52
00:01:55,280 --> 00:01:58,000
is that platforms engaging in content

53
00:01:58,000 --> 00:01:59,920
moderation are trying to remove

54
00:01:59,920 --> 00:02:02,560
substantial amounts of content at scale

55
00:02:02,560 --> 00:02:05,119
that are in violation of one local laws

56
00:02:05,119 --> 00:02:06,840
which is alleged because there's no

57
00:02:06,840 --> 00:02:09,758
court determination or ruling on that or

58
00:02:09,758 --> 00:02:11,760
and or to the terms of service of the

59
00:02:11,760 --> 00:02:13,200
platform

60
00:02:13,200 --> 00:02:15,120
another scope restriction is that in

61
00:02:15,120 --> 00:02:17,680
end-to-end encrypted systems we are

62
00:02:17,680 --> 00:02:21,040
necessarily limited to top-down platform

63
00:02:21,040 --> 00:02:22,640
approaches

64
00:02:22,640 --> 00:02:25,920
because um you know you that you have to

65
00:02:25,920 --> 00:02:27,599
sort of undertake them

66
00:02:27,599 --> 00:02:30,640
through a central service meaning that

67
00:02:30,640 --> 00:02:32,560
other like

68
00:02:32,560 --> 00:02:33,920
things that aren't top down would be for

69
00:02:33,920 --> 00:02:36,160
example you know you have

70
00:02:36,160 --> 00:02:39,519
page managers or subreddit moderators

71
00:02:39,519 --> 00:02:41,519
those things are not top down and

72
00:02:41,519 --> 00:02:43,120
they're content moderation

73
00:02:43,120 --> 00:02:44,720
mechanisms but you can't use that in

74
00:02:44,720 --> 00:02:47,120
intent encryption

75
00:02:47,120 --> 00:02:49,519
and then lastly another scope

76
00:02:49,519 --> 00:02:51,360
restriction is that it's not really

77
00:02:51,360 --> 00:02:53,519
possible it isn't possible to

78
00:02:53,519 --> 00:02:55,200
technically define

79
00:02:55,200 --> 00:02:56,080
um

80
00:02:56,080 --> 00:02:58,239
objective definition or distinction

81
00:02:58,239 --> 00:03:00,000
between what is acceptable content and

82
00:03:00,000 --> 00:03:02,560
what is not so there's nothing between

83
00:03:02,560 --> 00:03:04,480
two images this gets back to folks

84
00:03:04,480 --> 00:03:06,319
talking about disinformation nothing

85
00:03:06,319 --> 00:03:08,720
tells you technically the difference

86
00:03:08,720 --> 00:03:11,840
between two pieces of content um that is

87
00:03:11,840 --> 00:03:13,920
something that is not inherent to the

88
00:03:13,920 --> 00:03:16,080
content itself

89
00:03:16,080 --> 00:03:18,720
if that makes sense so um

90
00:03:18,720 --> 00:03:20,080
then

91
00:03:20,080 --> 00:03:22,000
in content moderation there are six

92
00:03:22,000 --> 00:03:24,000
phases i'm only going to go into depth

93
00:03:24,000 --> 00:03:26,239
on one of them that's relevant for this

94
00:03:26,239 --> 00:03:28,080
um but you have

95
00:03:28,080 --> 00:03:31,360
in the first phase definition

96
00:03:31,360 --> 00:03:33,840
where obviously the platform needs to

97
00:03:33,840 --> 00:03:35,599
define what's acceptable and what's not

98
00:03:35,599 --> 00:03:38,319
it needs to make that understood for a

99
00:03:38,319 --> 00:03:40,879
variety of different

100
00:03:40,879 --> 00:03:43,280
audiences internally

101
00:03:43,280 --> 00:03:46,560
to the users any sort of educating body

102
00:03:46,560 --> 00:03:48,720
third party auditor whatever

103
00:03:48,720 --> 00:03:50,959
in the detection phase obviously that is

104
00:03:50,959 --> 00:03:51,760
where

105
00:03:51,760 --> 00:03:53,120
you actually have to then take the

106
00:03:53,120 --> 00:03:55,040
definition of the content you're looking

107
00:03:55,040 --> 00:03:56,560
for that you're trying to remove or

108
00:03:56,560 --> 00:03:58,319
action in some way

109
00:03:58,319 --> 00:04:00,879
and and find it or have it reported to

110
00:04:00,879 --> 00:04:02,080
you and so on i'm actually going to go

111
00:04:02,080 --> 00:04:03,439
into much more depth on the detection

112
00:04:03,439 --> 00:04:04,640
phase because that's actually the face

113
00:04:04,640 --> 00:04:07,200
that matters the most in this um

114
00:04:07,200 --> 00:04:08,319
after that

115
00:04:08,319 --> 00:04:10,720
then there's evaluation so

116
00:04:10,720 --> 00:04:13,920
is that has the content been detected

117
00:04:13,920 --> 00:04:15,760
correctly you've been detected you know

118
00:04:15,760 --> 00:04:17,358
you have to

119
00:04:17,358 --> 00:04:18,959
take a step back before you move on to

120
00:04:18,959 --> 00:04:20,798
the next phase which is what a lot of us

121
00:04:20,798 --> 00:04:22,000
think of when we think of content

122
00:04:22,000 --> 00:04:23,680
moderation and that's the enforcement

123
00:04:23,680 --> 00:04:24,560
phase

124
00:04:24,560 --> 00:04:27,280
and there are so very many steps

125
00:04:27,280 --> 00:04:29,440
in enforcement

126
00:04:29,440 --> 00:04:31,759
or so many possible actions i guess is a

127
00:04:31,759 --> 00:04:33,199
better way of putting it

128
00:04:33,199 --> 00:04:35,840
it's not just removal it's all kinds of

129
00:04:35,840 --> 00:04:38,080
of possible things you can look at

130
00:04:38,080 --> 00:04:41,280
behavior you can look at content you can

131
00:04:41,280 --> 00:04:44,320
throttle behavior you can you know

132
00:04:44,320 --> 00:04:46,639
so the list is is really long we're not

133
00:04:46,639 --> 00:04:48,160
going to have time to go into it and

134
00:04:48,160 --> 00:04:50,240
it's also not necessarily

135
00:04:50,240 --> 00:04:52,320
important at least for the purposes of

136
00:04:52,320 --> 00:04:54,320
the paper that we wrote although

137
00:04:54,320 --> 00:04:56,320
we'll get to how we might look at this

138
00:04:56,320 --> 00:04:59,120
as for sort of future work um

139
00:04:59,120 --> 00:05:01,120
then there needs to be appeal so if

140
00:05:01,120 --> 00:05:02,720
you've made a decision about a piece of

141
00:05:02,720 --> 00:05:04,560
content users need to be able to appeal

142
00:05:04,560 --> 00:05:05,520
that

143
00:05:05,520 --> 00:05:07,199
and they probably want to because

144
00:05:07,199 --> 00:05:08,880
especially when you're using layers

145
00:05:08,880 --> 00:05:11,039
potentially of automation

146
00:05:11,039 --> 00:05:13,280
mistakes can be made

147
00:05:13,280 --> 00:05:14,639
and then that typically then pumps

148
00:05:14,639 --> 00:05:17,680
things back to the evaluation phase

149
00:05:17,680 --> 00:05:19,520
and so on and then lastly and this has

150
00:05:19,520 --> 00:05:21,600
not been a super linear it's not really

151
00:05:21,600 --> 00:05:23,600
linear in practice right but the the

152
00:05:23,600 --> 00:05:25,280
last phase we're mentioning is education

153
00:05:25,280 --> 00:05:27,759
so back when you know you're defining

154
00:05:27,759 --> 00:05:29,759
what is allowed and what isn't it's

155
00:05:29,759 --> 00:05:31,840
important that users actually understand

156
00:05:31,840 --> 00:05:33,039
what that means

157
00:05:33,039 --> 00:05:35,360
and the education process happens

158
00:05:35,360 --> 00:05:37,680
throughout so that there's clarity

159
00:05:37,680 --> 00:05:40,000
around you know what's happening

160
00:05:40,000 --> 00:05:43,440
um so with that in mind um i'm going to

161
00:05:43,440 --> 00:05:44,479
go a little bit deeper into the

162
00:05:44,479 --> 00:05:46,800
detection phase and leave the rest for

163
00:05:46,800 --> 00:05:48,400
another discussion

164
00:05:48,400 --> 00:05:50,000
in the detection phase of content

165
00:05:50,000 --> 00:05:53,280
moderation there are so many axes it

166
00:05:53,280 --> 00:05:56,319
isn't three it isn't just three sort of

167
00:05:56,319 --> 00:05:57,759
axes that we need to deal with it's

168
00:05:57,759 --> 00:06:00,880
multiple ones but that's hard to draw um

169
00:06:00,880 --> 00:06:02,800
so the three i think that matter the

170
00:06:02,800 --> 00:06:04,720
most is when

171
00:06:04,720 --> 00:06:07,360
uh platforms are coming up with a

172
00:06:07,360 --> 00:06:09,919
strategy for detection

173
00:06:09,919 --> 00:06:13,600
they can think about detecting it before

174
00:06:13,600 --> 00:06:16,160
right there's been

175
00:06:16,160 --> 00:06:18,080
an incident or they can deal with the

176
00:06:18,080 --> 00:06:19,440
after effects

177
00:06:19,440 --> 00:06:20,479
right

178
00:06:20,479 --> 00:06:23,680
so before you post or after you post

179
00:06:23,680 --> 00:06:26,160
there are ways to interrupt and detect

180
00:06:26,160 --> 00:06:29,360
content before for example it gets

181
00:06:29,360 --> 00:06:32,080
turned into viral content scale

182
00:06:32,080 --> 00:06:34,960
another axis that uh platforms might

183
00:06:34,960 --> 00:06:36,400
consider when doing content moderation

184
00:06:36,400 --> 00:06:38,319
is along the reactive

185
00:06:38,319 --> 00:06:41,440
proactive access do you wait for people

186
00:06:41,440 --> 00:06:44,080
to tell you that content is a problem

187
00:06:44,080 --> 00:06:46,960
or it's reported or yeah or do you

188
00:06:46,960 --> 00:06:49,520
actually go out and look for it do you

189
00:06:49,520 --> 00:06:50,800
go out and look for things that you

190
00:06:50,800 --> 00:06:52,319
don't want on your platform

191
00:06:52,319 --> 00:06:54,080
or things that violate term service or

192
00:06:54,080 --> 00:06:56,319
laws

193
00:06:56,319 --> 00:06:57,440
and then

194
00:06:57,440 --> 00:07:00,000
the other thing that detection needs to

195
00:07:00,000 --> 00:07:02,479
worry about is detecting content versus

196
00:07:02,479 --> 00:07:04,960
detecting metadata and like this isn't

197
00:07:04,960 --> 00:07:06,880
totally true but i think from a from the

198
00:07:06,880 --> 00:07:08,560
mental model i have in my head is that

199
00:07:08,560 --> 00:07:10,880
content obviously is the substance or

200
00:07:10,880 --> 00:07:12,400
the thing that's being uploaded and

201
00:07:12,400 --> 00:07:15,599
metadata often is around behavior so if

202
00:07:15,599 --> 00:07:17,520
you are worried about you know

203
00:07:17,520 --> 00:07:19,440
coordinated trolling behavior things

204
00:07:19,440 --> 00:07:21,360
like that you're probably monitoring and

205
00:07:21,360 --> 00:07:23,759
looking at metadata um

206
00:07:23,759 --> 00:07:25,440
if you're securing your system against

207
00:07:25,440 --> 00:07:27,120
some kind of attack like a lot of times

208
00:07:27,120 --> 00:07:28,479
that's used

209
00:07:28,479 --> 00:07:30,560
with metadata and that sort of thing um

210
00:07:30,560 --> 00:07:31,759
so again like there are many other

211
00:07:31,759 --> 00:07:32,960
dimensions to this but i wanted to

212
00:07:32,960 --> 00:07:35,599
highlight those three

213
00:07:35,599 --> 00:07:36,880
so now i'm going to shift to talking

214
00:07:36,880 --> 00:07:38,800
about encryption

215
00:07:38,800 --> 00:07:41,759
don't want to

216
00:07:41,840 --> 00:07:43,919
get too deep in it because a lot of you

217
00:07:43,919 --> 00:07:45,759
are subject matter experts but it's

218
00:07:45,759 --> 00:07:47,840
important i think to have a solid

219
00:07:47,840 --> 00:07:49,039
definition of what we're talking about

220
00:07:49,039 --> 00:07:51,120
with respect to encryption before

221
00:07:51,120 --> 00:07:53,360
we put the two together and then look at

222
00:07:53,360 --> 00:07:54,879
um proposals

223
00:07:54,879 --> 00:07:56,160
for it um

224
00:07:56,160 --> 00:08:00,080
so the um

225
00:08:00,080 --> 00:08:01,759
how exactly encryption is implemented in

226
00:08:01,759 --> 00:08:04,319
the system really depends on

227
00:08:04,319 --> 00:08:06,080
who gets access to the data and how

228
00:08:06,080 --> 00:08:08,879
that's sort of you know the point um and

229
00:08:08,879 --> 00:08:11,039
the point is that as few people as

230
00:08:11,039 --> 00:08:12,800
possible do except those that are

231
00:08:12,800 --> 00:08:14,800
authorized so because encryption can

232
00:08:14,800 --> 00:08:17,199
only guarantee confidentiality between

233
00:08:17,199 --> 00:08:20,479
parties that share an encryption key

234
00:08:20,479 --> 00:08:22,000
one of the most important considerations

235
00:08:22,000 --> 00:08:23,520
when deploying encryption is how to

236
00:08:23,520 --> 00:08:27,039
manage key sharing clearly

237
00:08:27,039 --> 00:08:28,800
in this shared exchange coupled with

238
00:08:28,800 --> 00:08:30,479
confidentiality of encryption this

239
00:08:30,479 --> 00:08:32,719
allows systems designers to protect data

240
00:08:32,719 --> 00:08:33,919
in transit

241
00:08:33,919 --> 00:08:36,080
you can protect it while it's at rest

242
00:08:36,080 --> 00:08:38,159
and you can protect data between

243
00:08:38,159 --> 00:08:40,159
endpoints

244
00:08:40,159 --> 00:08:42,320
what is encryption or what is end-to-end

245
00:08:42,320 --> 00:08:44,560
encryption even is surprisingly

246
00:08:44,560 --> 00:08:45,839
not

247
00:08:45,839 --> 00:08:48,480
agreed upon if you look at

248
00:08:48,480 --> 00:08:51,360
the ways in which

249
00:08:51,519 --> 00:08:54,720
the ways in which um it can be

250
00:08:54,720 --> 00:08:56,880
implemented differently

251
00:08:56,880 --> 00:08:59,279
so there's some agreement or some

252
00:08:59,279 --> 00:09:02,399
convergence around um use of for indian

253
00:09:02,399 --> 00:09:04,720
encrypted messaging for example use of

254
00:09:04,720 --> 00:09:06,399
the signal protocol

255
00:09:06,399 --> 00:09:08,880
there's an effort in the ietf to

256
00:09:08,880 --> 00:09:10,000
standardize something called the

257
00:09:10,000 --> 00:09:12,480
messaging layer security protocol

258
00:09:12,480 --> 00:09:14,480
um which could be used in messaging it

259
00:09:14,480 --> 00:09:16,320
could be used in video it could be used

260
00:09:16,320 --> 00:09:18,160
in a variety of different contexts

261
00:09:18,160 --> 00:09:20,560
but what the features are you know does

262
00:09:20,560 --> 00:09:23,519
intend encryption have to include um

263
00:09:23,519 --> 00:09:25,680
perfect forward secrecy or deniability

264
00:09:25,680 --> 00:09:27,200
or other kinds of features that is not

265
00:09:27,200 --> 00:09:29,519
necessarily agreed upon

266
00:09:29,519 --> 00:09:30,480
um

267
00:09:30,480 --> 00:09:32,160
and so it's worth defining and there's

268
00:09:32,160 --> 00:09:34,160
there's an effort in the ietf too to do

269
00:09:34,160 --> 00:09:34,839
that

270
00:09:34,839 --> 00:09:36,720
um

271
00:09:36,720 --> 00:09:38,800
other so so just to spark your

272
00:09:38,800 --> 00:09:40,560
imagination of what we're talking about

273
00:09:40,560 --> 00:09:43,839
concretely here then in um

274
00:09:43,839 --> 00:09:45,920
content moderation and encrypted systems

275
00:09:45,920 --> 00:09:47,760
we're talking about system services or

276
00:09:47,760 --> 00:09:49,920
apps that are end end encrypted if the

277
00:09:49,920 --> 00:09:52,640
keys used to decrypt and encrypt data

278
00:09:52,640 --> 00:09:54,480
are known only to the sender

279
00:09:54,480 --> 00:09:56,240
and the authorized recipients of the

280
00:09:56,240 --> 00:09:58,240
content so

281
00:09:58,240 --> 00:09:59,519
examples

282
00:09:59,519 --> 00:10:00,720
storage

283
00:10:00,720 --> 00:10:02,800
icloud messaging

284
00:10:02,800 --> 00:10:05,600
signal email

285
00:10:05,600 --> 00:10:08,160
pgp

286
00:10:09,760 --> 00:10:11,839
there are actually

287
00:10:11,839 --> 00:10:13,920
there are actually proposals for then

288
00:10:13,920 --> 00:10:15,200
how to

289
00:10:15,200 --> 00:10:17,040
do content moderation and encryption

290
00:10:17,040 --> 00:10:19,839
systems this is not an exhaustive list

291
00:10:19,839 --> 00:10:22,160
but it is i think um

292
00:10:22,160 --> 00:10:24,480
a thorough at least in august it was a

293
00:10:24,480 --> 00:10:26,320
really thorough go and looking at all

294
00:10:26,320 --> 00:10:28,160
the different proposals that we'd seen

295
00:10:28,160 --> 00:10:29,680
there was a

296
00:10:29,680 --> 00:10:32,480
report leaked out of the european

297
00:10:32,480 --> 00:10:35,600
council that had 12 proposals some of

298
00:10:35,600 --> 00:10:37,279
them included just you know straight up

299
00:10:37,279 --> 00:10:38,880
backdoors and other things like that we

300
00:10:38,880 --> 00:10:40,720
so we'd seen quite a few and we wanted

301
00:10:40,720 --> 00:10:42,480
to take them in turn

302
00:10:42,480 --> 00:10:44,880
and evaluate whether or not these

303
00:10:44,880 --> 00:10:46,800
approaches violated intent encryption

304
00:10:46,800 --> 00:10:48,959
that was the primary primary goal so

305
00:10:48,959 --> 00:10:51,440
these proposals there are five um i'm

306
00:10:51,440 --> 00:10:52,800
not probably going to have time to go

307
00:10:52,800 --> 00:10:55,040
into every single one of them um but the

308
00:10:55,040 --> 00:10:56,320
first one

309
00:10:56,320 --> 00:10:58,640
is user reporting so what happens i mean

310
00:10:58,640 --> 00:11:00,959
can you use you know blocking and user

311
00:11:00,959 --> 00:11:03,279
reporting user empowerment features

312
00:11:03,279 --> 00:11:04,000
in

313
00:11:04,000 --> 00:11:07,920
messaging apps to do content moderation

314
00:11:07,920 --> 00:11:09,680
and what does that look like

315
00:11:09,680 --> 00:11:12,720
what about metadata analysis i mean you

316
00:11:12,720 --> 00:11:14,480
probably want to reduce the amount of

317
00:11:14,480 --> 00:11:17,120
metadata you have in a secure private

318
00:11:17,120 --> 00:11:19,600
app but there is some can you use some

319
00:11:19,600 --> 00:11:22,399
of it can can is that possible

320
00:11:22,399 --> 00:11:24,399
another one is traceability this is a

321
00:11:24,399 --> 00:11:26,880
proposal that became really popular in

322
00:11:26,880 --> 00:11:29,519
india and in brazil actually in the

323
00:11:29,519 --> 00:11:31,279
legal framework

324
00:11:31,279 --> 00:11:32,160
to

325
00:11:32,160 --> 00:11:34,720
figure out how to trace

326
00:11:34,720 --> 00:11:37,120
messages that were being sent

327
00:11:37,120 --> 00:11:38,959
primarily through whatsapp so a lot of

328
00:11:38,959 --> 00:11:40,720
it was a concern over disinformation for

329
00:11:40,720 --> 00:11:42,399
example

330
00:11:42,399 --> 00:11:44,320
not there you know the the scheme

331
00:11:44,320 --> 00:11:45,519
doesn't have anything to do with looking

332
00:11:45,519 --> 00:11:47,279
at the content

333
00:11:47,279 --> 00:11:49,279
and the way that it's proposed but it

334
00:11:49,279 --> 00:11:51,839
just asks the platform um you know can

335
00:11:51,839 --> 00:11:52,639
you

336
00:11:52,639 --> 00:11:54,240
can you tell me where this came from who

337
00:11:54,240 --> 00:11:55,440
was the first person to send this

338
00:11:55,440 --> 00:11:57,120
message how many people have seen it

339
00:11:57,120 --> 00:11:59,760
that sort of thing and um and it seems

340
00:11:59,760 --> 00:12:01,360
like it doesn't break encryption because

341
00:12:01,360 --> 00:12:03,839
it's not talking about the content um

342
00:12:03,839 --> 00:12:05,360
but we'll get into that

343
00:12:05,360 --> 00:12:07,920
perceptual hatching hashing this is

344
00:12:07,920 --> 00:12:10,399
where you sort of are comparing

345
00:12:10,399 --> 00:12:12,560
known content that you already have a

346
00:12:12,560 --> 00:12:14,959
database of that isn't allowed you know

347
00:12:14,959 --> 00:12:16,720
it's not allowed can you just make sure

348
00:12:16,720 --> 00:12:18,079
that it never winds up on your platform

349
00:12:18,079 --> 00:12:19,279
ever again

350
00:12:19,279 --> 00:12:21,440
that's perceptual hashing

351
00:12:21,440 --> 00:12:22,800
meaning that you know it doesn't even

352
00:12:22,800 --> 00:12:24,160
have to be an exact match it could be

353
00:12:24,160 --> 00:12:26,399
kind of a match and it would get flagged

354
00:12:26,399 --> 00:12:27,760
and then taking it a step further

355
00:12:27,760 --> 00:12:30,160
predictive matching would be um you know

356
00:12:30,160 --> 00:12:31,040
could you

357
00:12:31,040 --> 00:12:33,279
take known stuff and come up with a way

358
00:12:33,279 --> 00:12:36,959
to find novel stuff that matches the

359
00:12:36,959 --> 00:12:38,959
the bad stuff right

360
00:12:38,959 --> 00:12:40,480
um so

361
00:12:40,480 --> 00:12:41,600
yeah the

362
00:12:41,600 --> 00:12:43,279
user reporting this is actually one of

363
00:12:43,279 --> 00:12:46,399
the ones we didn't think was terrible um

364
00:12:46,399 --> 00:12:49,040
in in it that it provides a lot of user

365
00:12:49,040 --> 00:12:50,560
agency so

366
00:12:50,560 --> 00:12:51,600
um

367
00:12:51,600 --> 00:12:52,560
you know

368
00:12:52,560 --> 00:12:54,720
proposed cryptographic schemes to enable

369
00:12:54,720 --> 00:12:56,240
the reporting by users to service

370
00:12:56,240 --> 00:12:58,560
writers of indian encrypted messages

371
00:12:58,560 --> 00:12:59,440
um

372
00:12:59,440 --> 00:13:00,800
seems like

373
00:13:00,800 --> 00:13:03,839
a fine a fine thing um you would want to

374
00:13:03,839 --> 00:13:05,440
make sure there'd be some privacy

375
00:13:05,440 --> 00:13:08,320
involved so if you've got two endpoints

376
00:13:08,320 --> 00:13:10,720
say one of the endpoints receives a

377
00:13:10,720 --> 00:13:12,399
piece of content that they want to

378
00:13:12,399 --> 00:13:13,920
report

379
00:13:13,920 --> 00:13:15,760
they can they can do that a variety of

380
00:13:15,760 --> 00:13:17,440
ways you could very much just like take

381
00:13:17,440 --> 00:13:20,160
a screenshot or walk your phone to

382
00:13:20,160 --> 00:13:22,160
law enforcement but you could also then

383
00:13:22,160 --> 00:13:23,600
maybe use the platform to do that as

384
00:13:23,600 --> 00:13:25,760
well you might want to ensure some

385
00:13:25,760 --> 00:13:27,680
degree of privacy if your platform is

386
00:13:27,680 --> 00:13:29,200
doing that so you might be able to

387
00:13:29,200 --> 00:13:31,120
achieve that with message franking which

388
00:13:31,120 --> 00:13:32,399
ensures that messages can only be

389
00:13:32,399 --> 00:13:34,079
decrypted and verified by the service

390
00:13:34,079 --> 00:13:36,560
provider and nobody else beyond the

391
00:13:36,560 --> 00:13:39,920
original sender and recipients

392
00:13:39,920 --> 00:13:40,959
so it does

393
00:13:40,959 --> 00:13:43,519
preserve confidentiality and privacy

394
00:13:43,519 --> 00:13:45,360
i don't think that there's

395
00:13:45,360 --> 00:13:47,040
necessarily a

396
00:13:47,040 --> 00:13:52,319
problem um with the expectations there

397
00:13:52,399 --> 00:13:54,720
and the problem one one issue though

398
00:13:54,720 --> 00:13:56,639
that it does lose deniability so if your

399
00:13:56,639 --> 00:13:59,600
platform was hoping to offer you know

400
00:13:59,600 --> 00:14:01,440
users something a little bit more in

401
00:14:01,440 --> 00:14:03,360
terms of features of

402
00:14:03,360 --> 00:14:04,959
intent encryption deniability wouldn't

403
00:14:04,959 --> 00:14:06,880
be possible because you know a sends a

404
00:14:06,880 --> 00:14:08,880
message to b b can authenticate that

405
00:14:08,880 --> 00:14:10,480
that message from a but cannot prove

406
00:14:10,480 --> 00:14:12,880
this to anyone else that's not going to

407
00:14:12,880 --> 00:14:14,320
be possible because you're trying to

408
00:14:14,320 --> 00:14:15,839
prove

409
00:14:15,839 --> 00:14:19,600
this this content came from somewhere um

410
00:14:19,600 --> 00:14:21,519
we would just suggest then that for

411
00:14:21,519 --> 00:14:23,760
platforms that are looking to do this

412
00:14:23,760 --> 00:14:25,360
message ranking and user reporting that

413
00:14:25,360 --> 00:14:27,199
they would just be very clear

414
00:14:27,199 --> 00:14:30,320
to users about the loss of deniability

415
00:14:30,320 --> 00:14:32,560
so metadata analysis metadata is data

416
00:14:32,560 --> 00:14:36,160
about data things like file size type

417
00:14:36,160 --> 00:14:39,760
of file date and time of the send

418
00:14:39,760 --> 00:14:42,639
who sent it who received it and more

419
00:14:42,639 --> 00:14:44,800
could potentially be detected and it's

420
00:14:44,800 --> 00:14:47,040
not always clear from the outside what

421
00:14:47,040 --> 00:14:49,360
kinds of metadata is being collected

422
00:14:49,360 --> 00:14:50,639
um

423
00:14:50,639 --> 00:14:53,120
we would not necessarily suggest

424
00:14:53,120 --> 00:14:54,320
creating

425
00:14:54,320 --> 00:14:55,920
more metadata

426
00:14:55,920 --> 00:14:58,079
to do analysis

427
00:14:58,079 --> 00:15:00,560
but in general what metadata is there

428
00:15:00,560 --> 00:15:03,120
might be a way of doing some degree of

429
00:15:03,120 --> 00:15:05,040
content moderation especially in in

430
00:15:05,040 --> 00:15:07,199
terms of behavior so

431
00:15:07,199 --> 00:15:08,800
again when we think about content

432
00:15:08,800 --> 00:15:10,240
moderation it isn't actually just

433
00:15:10,240 --> 00:15:11,600
content it's content and behavior

434
00:15:11,600 --> 00:15:13,600
moderation if you're abusing the system

435
00:15:13,600 --> 00:15:15,760
if you're spamming people etc there

436
00:15:15,760 --> 00:15:17,120
should be some recourse to that and you

437
00:15:17,120 --> 00:15:18,959
can use metadata to

438
00:15:18,959 --> 00:15:21,040
um to detect that and to do something

439
00:15:21,040 --> 00:15:24,079
about it other things like

440
00:15:24,079 --> 00:15:26,320
account information ip address the last

441
00:15:26,320 --> 00:15:28,399
time you logged in the volume of your

442
00:15:28,399 --> 00:15:30,160
activity the frequency of your posting

443
00:15:30,160 --> 00:15:32,880
other signals like that um

444
00:15:32,880 --> 00:15:35,360
again like wouldn't necessarily think

445
00:15:35,360 --> 00:15:38,079
that platforms should be tracking new

446
00:15:38,079 --> 00:15:39,680
things but just to use what's already

447
00:15:39,680 --> 00:15:40,880
there seems like

448
00:15:40,880 --> 00:15:42,800
a good idea

449
00:15:42,800 --> 00:15:44,800
as long as you know no new metadata is

450
00:15:44,800 --> 00:15:46,320
created

451
00:15:46,320 --> 00:15:48,320
for things beyond message delivery it is

452
00:15:48,320 --> 00:15:49,440
something though i think that's a bit

453
00:15:49,440 --> 00:15:51,120
controversial because we know that a lot

454
00:15:51,120 --> 00:15:52,240
can be

455
00:15:52,240 --> 00:15:54,480
gleaned from metadata and so

456
00:15:54,480 --> 00:15:56,639
platforms should always be reducing the

457
00:15:56,639 --> 00:15:58,560
amount of metadata that they keep for

458
00:15:58,560 --> 00:15:59,759
sure

459
00:15:59,759 --> 00:16:03,759
um so i will spend just um really really

460
00:16:03,759 --> 00:16:05,759
quickly

461
00:16:05,759 --> 00:16:07,839
so i can get to the end of my slides but

462
00:16:07,839 --> 00:16:09,920
so traceability

463
00:16:09,920 --> 00:16:12,959
i think of traceability as enhanced

464
00:16:12,959 --> 00:16:15,839
metadata it's exactly what we don't want

465
00:16:15,839 --> 00:16:18,880
platforms to do it's if platforms are

466
00:16:18,880 --> 00:16:21,440
probably not tracking every single

467
00:16:21,440 --> 00:16:23,440
origin of a message and who it passes

468
00:16:23,440 --> 00:16:24,959
through and who sees it how many you

469
00:16:24,959 --> 00:16:28,399
know that's a cree that's an extra ask

470
00:16:28,399 --> 00:16:30,480
that is taking an encrypted messaging

471
00:16:30,480 --> 00:16:32,880
system and building additional features

472
00:16:32,880 --> 00:16:34,959
on top of it to aid law enforcement the

473
00:16:34,959 --> 00:16:37,839
other thing that we realized and when

474
00:16:37,839 --> 00:16:40,160
when talking to people about how the law

475
00:16:40,160 --> 00:16:41,680
was being proposed in india and brazil

476
00:16:41,680 --> 00:16:43,040
was that there was an assumption

477
00:16:43,040 --> 00:16:45,759
actually that um the law enforcement or

478
00:16:45,759 --> 00:16:47,600
some agency had the content like

479
00:16:47,600 --> 00:16:49,040
somebody had

480
00:16:49,040 --> 00:16:50,720
forwarded them the message or they've

481
00:16:50,720 --> 00:16:52,480
seen it the point is they've already got

482
00:16:52,480 --> 00:16:54,639
it they're trying to detect it so yes

483
00:16:54,639 --> 00:16:56,560
it's not backdooring

484
00:16:56,560 --> 00:16:58,880
but but it is i think

485
00:16:58,880 --> 00:17:00,959
it does violate

486
00:17:00,959 --> 00:17:03,519
privacy since users haven't willingly

487
00:17:03,519 --> 00:17:04,559
shared

488
00:17:04,559 --> 00:17:06,799
this data it's a creation of new data

489
00:17:06,799 --> 00:17:08,959
about the data and i think it implicitly

490
00:17:08,959 --> 00:17:12,240
violates confidentiality

491
00:17:13,039 --> 00:17:16,160
so we would reject traceability

492
00:17:16,160 --> 00:17:18,079
and the paper goes into a lot more depth

493
00:17:18,079 --> 00:17:20,720
perceptual hash matching this is um

494
00:17:20,720 --> 00:17:22,799
you'll hear a lot about

495
00:17:22,799 --> 00:17:25,520
scanning server scanning client-side

496
00:17:25,520 --> 00:17:27,919
scanning going back to that axis where

497
00:17:27,919 --> 00:17:29,760
you could do it you know before it gets

498
00:17:29,760 --> 00:17:33,039
posted or after it gets posted um

499
00:17:33,039 --> 00:17:34,160
wouldn't or

500
00:17:34,160 --> 00:17:35,679
not not something that we would

501
00:17:35,679 --> 00:17:37,200
recommend um

502
00:17:37,200 --> 00:17:38,720
the

503
00:17:38,720 --> 00:17:40,000
the question there are a lot of

504
00:17:40,000 --> 00:17:41,600
questions in the paper about whether or

505
00:17:41,600 --> 00:17:43,919
not it's even effective um whether or

506
00:17:43,919 --> 00:17:46,880
not it's good enough

507
00:17:46,880 --> 00:17:48,480
and

508
00:17:48,480 --> 00:17:50,480
just in general were

509
00:17:50,480 --> 00:17:52,880
very sensitive as you'll have read after

510
00:17:52,880 --> 00:17:54,240
this paper came out there was one called

511
00:17:54,240 --> 00:17:55,760
bugs in your pockets that really goes

512
00:17:55,760 --> 00:17:58,640
with the notion of client-side scanning

513
00:17:58,640 --> 00:18:01,120
predictive modeling is essentially

514
00:18:01,120 --> 00:18:04,160
worse than perceptual hashing and so we

515
00:18:04,160 --> 00:18:06,160
also rejected it um

516
00:18:06,160 --> 00:18:07,760
for looking for a novel for novel

517
00:18:07,760 --> 00:18:09,840
content and encrypted system uh into

518
00:18:09,840 --> 00:18:11,039
encrypted

519
00:18:11,039 --> 00:18:12,320
systems

520
00:18:12,320 --> 00:18:13,919
we're definitely interested in doing

521
00:18:13,919 --> 00:18:15,679
future research a couple of things that

522
00:18:15,679 --> 00:18:17,760
we're interested in what are the bounds

523
00:18:17,760 --> 00:18:18,880
for meaningful privacy and

524
00:18:18,880 --> 00:18:21,840
confidentiality in large group chats

525
00:18:21,840 --> 00:18:23,679
that's something that seems to be a

526
00:18:23,679 --> 00:18:25,600
particular particularly different

527
00:18:25,600 --> 00:18:27,039
problem than if you just have two people

528
00:18:27,039 --> 00:18:29,679
trying to have a private conversation um

529
00:18:29,679 --> 00:18:31,600
we also are worried about post-detection

530
00:18:31,600 --> 00:18:34,880
actions so the the steps that follow

531
00:18:34,880 --> 00:18:37,280
detection in terms of

532
00:18:37,280 --> 00:18:40,960
um enforcement really matter quite a lot

533
00:18:40,960 --> 00:18:42,799
and so our research doesn't go into that

534
00:18:42,799 --> 00:18:44,000
but that's somewhere where we would like

535
00:18:44,000 --> 00:18:44,799
to

536
00:18:44,799 --> 00:18:47,280
look at more of cause depending on what

537
00:18:47,280 --> 00:18:49,840
you do i think actually can matter when

538
00:18:49,840 --> 00:18:52,000
whether or not you're doing um

539
00:18:52,000 --> 00:18:52,960
the

540
00:18:52,960 --> 00:18:55,440
metadata or the user reporting right

541
00:18:55,440 --> 00:18:56,480
um

542
00:18:56,480 --> 00:18:58,640
and then it's also interesting to think

543
00:18:58,640 --> 00:19:00,320
about what are some of the hard problems

544
00:19:00,320 --> 00:19:02,640
around repeat offenders and cross

545
00:19:02,640 --> 00:19:05,600
platform moderation practices and how

546
00:19:05,600 --> 00:19:08,080
might this fit into that

547
00:19:08,080 --> 00:19:10,240
so i have just this last slide but i

548
00:19:10,240 --> 00:19:11,840
feel like i have very little time to

549
00:19:11,840 --> 00:19:14,080
tell you about it um i think that

550
00:19:14,080 --> 00:19:15,760
there's um

551
00:19:15,760 --> 00:19:17,520
potentially something coming out this

552
00:19:17,520 --> 00:19:19,039
year at some point we'll get around to

553
00:19:19,039 --> 00:19:20,960
writing some of these things down

554
00:19:20,960 --> 00:19:24,320
but it goes back to how

555
00:19:24,320 --> 00:19:26,080
platforms and i'm thinking particularly

556
00:19:26,080 --> 00:19:28,320
of messaging apps implement some of

557
00:19:28,320 --> 00:19:31,360
these ideas so one thing that i think

558
00:19:31,360 --> 00:19:33,440
i'll give you just one example

559
00:19:33,440 --> 00:19:35,280
and then hopefully i can post these um

560
00:19:35,280 --> 00:19:38,720
somewhere maybe on twitter um

561
00:19:38,720 --> 00:19:40,320
let's say you know

562
00:19:40,320 --> 00:19:42,880
autocorrect in um

563
00:19:42,880 --> 00:19:44,320
in in on your keyboard when you're

564
00:19:44,320 --> 00:19:45,919
typing in messages kind of a great

565
00:19:45,919 --> 00:19:46,880
feature

566
00:19:46,880 --> 00:19:48,880
you could do similar things that apple

567
00:19:48,880 --> 00:19:51,280
was proposing for example around giving

568
00:19:51,280 --> 00:19:53,039
speed bumps if you're

569
00:19:53,039 --> 00:19:55,520
using certain language or if you have

570
00:19:55,520 --> 00:19:57,600
certain speech patterns like that might

571
00:19:57,600 --> 00:20:00,880
be kind of interesting to look at

572
00:20:00,880 --> 00:20:02,960
as an in-app feature

573
00:20:02,960 --> 00:20:05,039
but what we're worried about is that if

574
00:20:05,039 --> 00:20:07,760
that is a sort of machine learning um

575
00:20:07,760 --> 00:20:10,880
feature enabled feature that it is

576
00:20:10,880 --> 00:20:13,039
breaking the promise of into encryption

577
00:20:13,039 --> 00:20:14,799
because it's sort of leaking outside the

578
00:20:14,799 --> 00:20:17,520
app and it's sort of quote calling home

579
00:20:17,520 --> 00:20:19,679
that would be something that would not

580
00:20:19,679 --> 00:20:21,360
would not really work right it would not

581
00:20:21,360 --> 00:20:22,880
preserve confidentiality and it's a

582
00:20:22,880 --> 00:20:24,799
vector i think for um weakening

583
00:20:24,799 --> 00:20:26,159
encryption

584
00:20:26,159 --> 00:20:27,280
um

585
00:20:27,280 --> 00:20:29,600
so things like that are principles we

586
00:20:29,600 --> 00:20:32,400
want to write down so that you know if

587
00:20:32,400 --> 00:20:33,760
um you

588
00:20:33,760 --> 00:20:34,799
are

589
00:20:34,799 --> 00:20:35,679
running

590
00:20:35,679 --> 00:20:37,520
an indian encrypted platform and you

591
00:20:37,520 --> 00:20:40,240
want to improve user experience

592
00:20:40,240 --> 00:20:42,559
and user agency by introducing some of

593
00:20:42,559 --> 00:20:44,000
these features

594
00:20:44,000 --> 00:20:45,840
that you can do that without

595
00:20:45,840 --> 00:20:48,159
accidentally weakening your system or

596
00:20:48,159 --> 00:20:49,840
giving users some feature that they

597
00:20:49,840 --> 00:20:51,600
don't want that makes their

598
00:20:51,600 --> 00:20:53,120
conversations less confidential and that

599
00:20:53,120 --> 00:20:55,200
sort of thing it would be worth i think

600
00:20:55,200 --> 00:20:56,000
um

601
00:20:56,000 --> 00:20:57,280
thinking about that and writing them

602
00:20:57,280 --> 00:20:58,559
down so that would that was my last

603
00:20:58,559 --> 00:20:59,760
slide and that's sort of what i propose

604
00:20:59,760 --> 00:21:01,840
and i apologize about you know i feel

605
00:21:01,840 --> 00:21:04,240
like it's a bit unreadable but

606
00:21:04,240 --> 00:21:05,919
um anyway so the thing i think that is

607
00:21:05,919 --> 00:21:07,200
important to remember

608
00:21:07,200 --> 00:21:09,760
about this topic is that platforms are

609
00:21:09,760 --> 00:21:11,039
moderating

610
00:21:11,039 --> 00:21:13,280
into int encryption without breaking it

611
00:21:13,280 --> 00:21:15,440
um now is a really critical time to

612
00:21:15,440 --> 00:21:18,000
define what are the cr what are the

613
00:21:18,000 --> 00:21:20,159
required

614
00:21:20,159 --> 00:21:23,360
features of end-to-end encryption

615
00:21:23,360 --> 00:21:26,240
what breaks that and what doesn't

616
00:21:26,240 --> 00:21:28,140
thanks

617
00:21:28,140 --> 00:21:32,679
[Applause]

618
00:21:37,760 --> 00:21:39,840
you

