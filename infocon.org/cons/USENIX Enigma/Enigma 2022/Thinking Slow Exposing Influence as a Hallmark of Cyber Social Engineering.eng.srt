1
00:00:08,000 --> 00:00:10,639
alrighty so is it just me or is anyone

2
00:00:10,639 --> 00:00:13,120
else walking around with trust issues

3
00:00:13,120 --> 00:00:15,519
anybody else get nervous when that 5g

4
00:00:15,519 --> 00:00:17,760
symbol pops up on your cell phone is the

5
00:00:17,760 --> 00:00:19,920
tightness in my chest just my good old

6
00:00:19,920 --> 00:00:23,119
chronic anxiety or oh my god was the 5g

7
00:00:23,119 --> 00:00:25,199
kovic conspiracy theory true all along

8
00:00:25,199 --> 00:00:26,880
and now i'm the fool

9
00:00:26,880 --> 00:00:28,960
or how about this you open up your inbox

10
00:00:28,960 --> 00:00:30,720
and amongst the thousands of emails that

11
00:00:30,720 --> 00:00:33,120
you for sure will get to this week maybe

12
00:00:33,120 --> 00:00:34,800
you do have some money to spare for the

13
00:00:34,800 --> 00:00:37,040
prince down in his luck this time around

14
00:00:37,040 --> 00:00:38,640
okay now before you start rolling your

15
00:00:38,640 --> 00:00:41,120
eyes at the prince scam isn't it just a

16
00:00:41,120 --> 00:00:43,360
bit shocking that fishing still costs so

17
00:00:43,360 --> 00:00:45,760
much to our society from the breach of

18
00:00:45,760 --> 00:00:47,760
personal data to the security and

19
00:00:47,760 --> 00:00:50,079
integrity of our democratic processes

20
00:00:50,079 --> 00:00:52,800
phishing is still a massive threat

21
00:00:52,800 --> 00:00:55,840
93 of data breaches for example are

22
00:00:55,840 --> 00:00:57,760
perpetrated through the use of fishing

23
00:00:57,760 --> 00:01:00,079
and 70 of governmental breaches are

24
00:01:00,079 --> 00:01:02,399
associated with phishing according to

25
00:01:02,399 --> 00:01:05,438
the fbi's 2019 internet crime complaint

26
00:01:05,438 --> 00:01:07,680
center losses associated with phishing

27
00:01:07,680 --> 00:01:09,920
scams like business email compromise

28
00:01:09,920 --> 00:01:14,240
romance fraud etc exceeded 3.5 billion

29
00:01:14,240 --> 00:01:16,320
dollars in the u.s alone

30
00:01:16,320 --> 00:01:17,840
you've also seen that fishing can be

31
00:01:17,840 --> 00:01:19,840
leveraged as a tool

32
00:01:19,840 --> 00:01:22,720
against our democratic elections yet for

33
00:01:22,720 --> 00:01:24,960
zero day phishing automated detection

34
00:01:24,960 --> 00:01:27,200
such as blacklist machine learning is

35
00:01:27,200 --> 00:01:29,520
insufficient for phishing mitigation

36
00:01:29,520 --> 00:01:31,600
forcing the human user and potential

37
00:01:31,600 --> 00:01:33,439
victim to serve as the final line of

38
00:01:33,439 --> 00:01:36,000
defense against fishing attempts

39
00:01:36,000 --> 00:01:37,920
and our society is threatened by way

40
00:01:37,920 --> 00:01:39,840
more than the mammoth of fishing already

41
00:01:39,840 --> 00:01:42,240
is here in the u.s we've got electoral

42
00:01:42,240 --> 00:01:44,079
fraud claims being thrown around leading

43
00:01:44,079 --> 00:01:46,399
to protest riots and insurrection

44
00:01:46,399 --> 00:01:48,399
notwithstanding the foreign interference

45
00:01:48,399 --> 00:01:50,880
that has happened in our elections

46
00:01:50,880 --> 00:01:53,360
vaccine hesitancy is booming amiss a

47
00:01:53,360 --> 00:01:55,360
pandemic that is ongoing now for nearly

48
00:01:55,360 --> 00:01:56,560
two years

49
00:01:56,560 --> 00:01:58,799
and we have now arguably reached a point

50
00:01:58,799 --> 00:02:01,040
where science is akin to mere opinion

51
00:02:01,040 --> 00:02:03,840
often following along political lines

52
00:02:03,840 --> 00:02:05,920
i feel that i'm not completely wrong

53
00:02:05,920 --> 00:02:07,920
here when i venture to say that all of

54
00:02:07,920 --> 00:02:09,038
this

55
00:02:09,038 --> 00:02:11,120
and so much more has polarized us all

56
00:02:11,120 --> 00:02:14,080
into either unsettling apathy or fervent

57
00:02:14,080 --> 00:02:16,319
righteousness not to be a debbie downer

58
00:02:16,319 --> 00:02:19,040
but our democracies are at stake public

59
00:02:19,040 --> 00:02:20,720
health is in peril in the words

60
00:02:20,720 --> 00:02:23,120
impartial in news are now colloquially

61
00:02:23,120 --> 00:02:24,400
antonyms

62
00:02:24,400 --> 00:02:25,920
if you're picking up what i'm putting

63
00:02:25,920 --> 00:02:28,400
down here the overarching theme of all

64
00:02:28,400 --> 00:02:30,319
of this is that the web has increasingly

65
00:02:30,319 --> 00:02:33,200
become an ecosystem for deception cyber

66
00:02:33,200 --> 00:02:34,800
social engineering attacks such as

67
00:02:34,800 --> 00:02:36,080
phishing deceptive ads and

68
00:02:36,080 --> 00:02:38,480
disaffirmation have put internet users

69
00:02:38,480 --> 00:02:40,000
and even national security and

70
00:02:40,000 --> 00:02:42,160
democracies at great peril false

71
00:02:42,160 --> 00:02:43,760
information is greatly shaping the

72
00:02:43,760 --> 00:02:46,080
political social and economic landscapes

73
00:02:46,080 --> 00:02:48,560
of our society exacerbated and brought

74
00:02:48,560 --> 00:02:50,400
to light by social media

75
00:02:50,400 --> 00:02:52,080
all of this falls into what i call the

76
00:02:52,080 --> 00:02:54,160
deceptive text umbrella

77
00:02:54,160 --> 00:02:56,239
from purposefully deceptive texts of

78
00:02:56,239 --> 00:02:58,400
facts rumors half-truths or outright

79
00:02:58,400 --> 00:03:00,120
lies disseminated manipulative

80
00:03:00,120 --> 00:03:02,560
manipulatively we can see how all of

81
00:03:02,560 --> 00:03:04,400
these buzzwords are connected but you

82
00:03:04,400 --> 00:03:06,400
might be wondering okay but what's

83
00:03:06,400 --> 00:03:09,120
fishing doing here well phishing is a

84
00:03:09,120 --> 00:03:11,040
social engineering attack aimed at

85
00:03:11,040 --> 00:03:12,720
influencing users your deceptive

86
00:03:12,720 --> 00:03:14,640
arguments into taking an action such as

87
00:03:14,640 --> 00:03:16,560
clicking on a malicious link though

88
00:03:16,560 --> 00:03:18,720
phishing differs from disinformation for

89
00:03:18,720 --> 00:03:21,040
example in its modus operandi

90
00:03:21,040 --> 00:03:22,800
we argue that it overlaps with

91
00:03:22,800 --> 00:03:25,120
misleading media and its main purpose

92
00:03:25,120 --> 00:03:27,200
which is galvanization all of these

93
00:03:27,200 --> 00:03:29,280
types of texts within the deceptive text

94
00:03:29,280 --> 00:03:31,519
umbrella aim to galvanize users and to

95
00:03:31,519 --> 00:03:34,319
say clicking a link or developing an

96
00:03:34,319 --> 00:03:36,640
opinion by triggering these victims

97
00:03:36,640 --> 00:03:39,680
emotions disinformation misinformation

98
00:03:39,680 --> 00:03:42,720
phishing they are all tools of and for

99
00:03:42,720 --> 00:03:44,640
deception

100
00:03:44,640 --> 00:03:47,040
we know intuitively that deceptive texts

101
00:03:47,040 --> 00:03:49,040
are all in a state of constant change we

102
00:03:49,040 --> 00:03:50,959
saw it happening during the coven 19

103
00:03:50,959 --> 00:03:53,360
pandemic and the 2020 u.s general

104
00:03:53,360 --> 00:03:55,760
election for example but below the

105
00:03:55,760 --> 00:03:57,519
surface there are likely constants

106
00:03:57,519 --> 00:03:59,360
within these deceptive texts

107
00:03:59,360 --> 00:04:01,120
our research posits that they all

108
00:04:01,120 --> 00:04:03,680
leverage influence cues

109
00:04:03,680 --> 00:04:06,159
so towards this end we looked at several

110
00:04:06,159 --> 00:04:07,439
types of influence cues that are

111
00:04:07,439 --> 00:04:10,560
relevant and present in deceptive texts

112
00:04:10,560 --> 00:04:12,239
if you're not familiar with him

113
00:04:12,239 --> 00:04:13,840
psychology and marketing professor

114
00:04:13,840 --> 00:04:16,000
robert cialdini proposed six principles

115
00:04:16,000 --> 00:04:18,079
of persuasion that identify context in

116
00:04:18,079 --> 00:04:19,600
which people are more susceptible to

117
00:04:19,600 --> 00:04:22,079
influence so for example people are more

118
00:04:22,079 --> 00:04:23,759
likely to comply with requests made by

119
00:04:23,759 --> 00:04:26,479
figures of authority we act impulsively

120
00:04:26,479 --> 00:04:29,120
in the face of scarcity will reciprocate

121
00:04:29,120 --> 00:04:32,160
or repay favors there is sensitivity to

122
00:04:32,160 --> 00:04:35,360
herd mentality as a form of social proof

123
00:04:35,360 --> 00:04:37,600
we tend to comply to requests made by

124
00:04:37,600 --> 00:04:39,600
others based on shared liking or

125
00:04:39,600 --> 00:04:42,320
similarity and there's pressure to

126
00:04:42,320 --> 00:04:44,639
behave in line with prior commitments we

127
00:04:44,639 --> 00:04:46,479
also looked at attribution of blame or

128
00:04:46,479 --> 00:04:49,040
guilt and the use of

129
00:04:49,040 --> 00:04:52,000
emphasis such as capital letters

130
00:04:52,000 --> 00:04:54,800
the subjectivity or objectivity of the

131
00:04:54,800 --> 00:04:56,880
sentences in the text this is more so

132
00:04:56,880 --> 00:04:59,040
related to whether a sentence presented

133
00:04:59,040 --> 00:05:00,800
itself as an opinion or grounded by

134
00:05:00,800 --> 00:05:03,280
evidence so for example

135
00:05:03,280 --> 00:05:04,880
this makes me so angry would be

136
00:05:04,880 --> 00:05:06,960
subjective while

137
00:05:06,960 --> 00:05:09,199
according to the cdc injecting bleach

138
00:05:09,199 --> 00:05:11,199
doesn't actually really help with covid

139
00:05:11,199 --> 00:05:13,680
would be an example of an objective text

140
00:05:13,680 --> 00:05:15,440
we also looked at the framing of the

141
00:05:15,440 --> 00:05:17,120
message as either potentially causing a

142
00:05:17,120 --> 00:05:19,440
gain or a loss

143
00:05:19,440 --> 00:05:21,680
now few works have actually looked at

144
00:05:21,680 --> 00:05:23,680
these influence cues in the context of

145
00:05:23,680 --> 00:05:26,080
miss and disinformation but if we look

146
00:05:26,080 --> 00:05:28,400
at phishing research a large effort has

147
00:05:28,400 --> 00:05:30,320
already been made into investigating the

148
00:05:30,320 --> 00:05:32,320
extent to which chaldini's principles of

149
00:05:32,320 --> 00:05:34,639
persuasion are used in phishing emails

150
00:05:34,639 --> 00:05:37,120
and how users are susceptible to them

151
00:05:37,120 --> 00:05:38,800
and there's quite a few things we can

152
00:05:38,800 --> 00:05:40,880
gather from related work

153
00:05:40,880 --> 00:05:42,880
research on deception detection reveals

154
00:05:42,880 --> 00:05:45,440
that deceivers apply influence cues and

155
00:05:45,440 --> 00:05:47,360
messages to increase their appeal to the

156
00:05:47,360 --> 00:05:49,600
recipients we know that these influence

157
00:05:49,600 --> 00:05:51,520
cues are highly occurring in deceptive

158
00:05:51,520 --> 00:05:53,440
texts and that users are extremely

159
00:05:53,440 --> 00:05:55,680
susceptible to them we also know from

160
00:05:55,680 --> 00:05:57,440
our own work in related work that

161
00:05:57,440 --> 00:05:58,720
authority was the most frequent

162
00:05:58,720 --> 00:06:00,240
principle of persuasion in phishing

163
00:06:00,240 --> 00:06:02,639
emails followed by scarcity

164
00:06:02,639 --> 00:06:05,039
the user's personality is also a big

165
00:06:05,039 --> 00:06:07,360
factor at play extraversion for example

166
00:06:07,360 --> 00:06:09,440
has been found to lead to increased

167
00:06:09,440 --> 00:06:12,080
susceptibility to the commitment liking

168
00:06:12,080 --> 00:06:14,720
authority influence cues

169
00:06:14,720 --> 00:06:17,360
demographics is another huge factor

170
00:06:17,360 --> 00:06:19,120
young adults for example have been shown

171
00:06:19,120 --> 00:06:20,960
to be most vulnerable to the scarcity

172
00:06:20,960 --> 00:06:23,039
principle while older adults are more

173
00:06:23,039 --> 00:06:25,600
susceptible to reciprocation but

174
00:06:25,600 --> 00:06:27,280
all age groups are susceptible to

175
00:06:27,280 --> 00:06:28,560
authority

176
00:06:28,560 --> 00:06:30,560
in terms of hyper partisan and fake news

177
00:06:30,560 --> 00:06:31,919
we can actually see some similar

178
00:06:31,919 --> 00:06:34,240
findings news articles that support

179
00:06:34,240 --> 00:06:35,919
authority are shared and liked more

180
00:06:35,919 --> 00:06:37,600
often whereas articles high in

181
00:06:37,600 --> 00:06:40,479
reciprocity are shared least

182
00:06:40,479 --> 00:06:42,479
and psychology research has suggested

183
00:06:42,479 --> 00:06:44,960
that loss that is framing an outcome as

184
00:06:44,960 --> 00:06:47,039
a possible loss is more impactful than

185
00:06:47,039 --> 00:06:49,199
the possibility of a game so we know

186
00:06:49,199 --> 00:06:52,160
people are more driven to avoid a loss

187
00:06:52,160 --> 00:06:54,800
so the question arises influence cues

188
00:06:54,800 --> 00:06:57,039
all right cool but what can we do with

189
00:06:57,039 --> 00:06:58,560
these well

190
00:06:58,560 --> 00:07:00,880
if 2020 has taught us anything is that

191
00:07:00,880 --> 00:07:02,880
human beings just like our automated

192
00:07:02,880 --> 00:07:05,360
inventions are flawed looking again at

193
00:07:05,360 --> 00:07:07,280
fishing we know that training humans to

194
00:07:07,280 --> 00:07:09,520
detect phishing is difficult to navigate

195
00:07:09,520 --> 00:07:12,160
because users individual characteristics

196
00:07:12,160 --> 00:07:14,479
like age forgetfulness overconfidence

197
00:07:14,479 --> 00:07:16,880
hinder training efficacy we think oh

198
00:07:16,880 --> 00:07:18,960
yeah i for sure could detect phishing

199
00:07:18,960 --> 00:07:21,280
yet users often experience high

200
00:07:21,280 --> 00:07:22,960
victimization rates and simulated

201
00:07:22,960 --> 00:07:24,560
phishing attacks

202
00:07:24,560 --> 00:07:25,919
so

203
00:07:25,919 --> 00:07:27,680
what's the great magical solution that i

204
00:07:27,680 --> 00:07:29,759
have for you today well communications

205
00:07:29,759 --> 00:07:31,280
research points us towards the dangers

206
00:07:31,280 --> 00:07:33,599
of what's called selective exposure a

207
00:07:33,599 --> 00:07:35,680
theory akin to confirmation bias

208
00:07:35,680 --> 00:07:37,440
pertaining to the idea that we favor

209
00:07:37,440 --> 00:07:39,520
information that reinforces our prior

210
00:07:39,520 --> 00:07:41,759
beliefs research has also given us the

211
00:07:41,759 --> 00:07:43,840
understanding that false content can

212
00:07:43,840 --> 00:07:46,639
increase our beliefs in a falsehood so

213
00:07:46,639 --> 00:07:48,960
misinformation is actually extremely

214
00:07:48,960 --> 00:07:50,879
insidious but if we borrow from

215
00:07:50,879 --> 00:07:53,599
communications journalism psychology and

216
00:07:53,599 --> 00:07:55,599
even some related work in our own field

217
00:07:55,599 --> 00:07:57,520
we know that the ability to think to

218
00:07:57,520 --> 00:08:00,479
think deliberatively and analytically is

219
00:08:00,479 --> 00:08:02,400
generally associated with the rejection

220
00:08:02,400 --> 00:08:04,800
of misinformation and disinformation

221
00:08:04,800 --> 00:08:06,879
regardless of your political alignment

222
00:08:06,879 --> 00:08:08,000
therefore

223
00:08:08,000 --> 00:08:10,400
activating if you will this analytical

224
00:08:10,400 --> 00:08:12,639
thinking helping users slow down for

225
00:08:12,639 --> 00:08:15,199
just a second to think may act as an

226
00:08:15,199 --> 00:08:17,840
antidote to selective exposure

227
00:08:17,840 --> 00:08:19,520
we've recently even seen somewhat

228
00:08:19,520 --> 00:08:21,520
similar examples of this at work aiming

229
00:08:21,520 --> 00:08:23,759
to expose a source of information

230
00:08:23,759 --> 00:08:25,599
twitter has begun showing its users some

231
00:08:25,599 --> 00:08:27,199
labels indicating government or

232
00:08:27,199 --> 00:08:28,800
state-affiliated media accounts

233
00:08:28,800 --> 00:08:31,039
presumably with the hope that this will

234
00:08:31,039 --> 00:08:32,640
allow users to make more informed

235
00:08:32,640 --> 00:08:34,000
decisions

236
00:08:34,000 --> 00:08:36,320
so what if we could look beneath the

237
00:08:36,320 --> 00:08:38,320
surface of a text and bring awareness of

238
00:08:38,320 --> 00:08:40,559
the influence cues present in it this

239
00:08:40,559 --> 00:08:42,640
may in turn aid users by providing

240
00:08:42,640 --> 00:08:44,720
additional context in the message thus

241
00:08:44,720 --> 00:08:46,959
helping the user think analytically with

242
00:08:46,959 --> 00:08:49,040
the added bonus of benefiting future

243
00:08:49,040 --> 00:08:51,279
work aimed at the automatic detection of

244
00:08:51,279 --> 00:08:53,200
deceptive online content

245
00:08:53,200 --> 00:08:55,200
so what would that look like well a lot

246
00:08:55,200 --> 00:08:56,880
of recent works have looked at binary

247
00:08:56,880 --> 00:08:58,720
classification as the ultimate goal here

248
00:08:58,720 --> 00:09:00,480
is this disinformation or not is this

249
00:09:00,480 --> 00:09:03,120
phishing or not what if for now where

250
00:09:03,120 --> 00:09:05,279
we're being flooded by ambiguity and

251
00:09:05,279 --> 00:09:07,279
duplicitous information we can think of

252
00:09:07,279 --> 00:09:10,000
an intermediary step help users slow

253
00:09:10,000 --> 00:09:11,760
down and make a decision by adding

254
00:09:11,760 --> 00:09:13,519
friction to the process of consuming

255
00:09:13,519 --> 00:09:15,279
information online

256
00:09:15,279 --> 00:09:17,360
similar to the calorie label on any food

257
00:09:17,360 --> 00:09:19,360
you pick up at your supermarket what if

258
00:09:19,360 --> 00:09:21,040
whenever you are exposed to a piece of

259
00:09:21,040 --> 00:09:23,519
text online you were also you would you

260
00:09:23,519 --> 00:09:25,680
could also know what influence cues are

261
00:09:25,680 --> 00:09:27,680
present in the text and then you can

262
00:09:27,680 --> 00:09:29,839
make your own hopefully better informed

263
00:09:29,839 --> 00:09:31,600
decision

264
00:09:31,600 --> 00:09:33,519
what if we could see for example that

265
00:09:33,519 --> 00:09:35,680
this russian ira facebook ad was

266
00:09:35,680 --> 00:09:38,560
leveraging a wealth of influence cues

267
00:09:38,560 --> 00:09:40,320
towards this goal we needed to first

268
00:09:40,320 --> 00:09:42,800
curate a relatively large data set of 3

269
00:09:42,800 --> 00:09:45,519
000 diverse online pieces of text which

270
00:09:45,519 --> 00:09:47,040
we broke up into what we call

271
00:09:47,040 --> 00:09:48,800
purposefully deceptive texts hyper

272
00:09:48,800 --> 00:09:51,200
hyperpartisan news and mainstream center

273
00:09:51,200 --> 00:09:52,320
news

274
00:09:52,320 --> 00:09:54,000
for the deceptive text we randomly

275
00:09:54,000 --> 00:09:55,920
selected a thousand texts from a variety

276
00:09:55,920 --> 00:09:58,080
of data sets online these samples

277
00:09:58,080 --> 00:10:00,320
encompassed facebook ads used by the

278
00:10:00,320 --> 00:10:02,640
russian internet research agency made

279
00:10:02,640 --> 00:10:04,240
available by the us house of

280
00:10:04,240 --> 00:10:05,600
representatives permanent select

281
00:10:05,600 --> 00:10:07,839
committee on intelligence after facebook

282
00:10:07,839 --> 00:10:09,600
internal audits these texts were

283
00:10:09,600 --> 00:10:11,839
believed to have been exposed to 126

284
00:10:11,839 --> 00:10:15,600
million americans between 2015 and 2017.

285
00:10:15,600 --> 00:10:17,440
we also leverage fake news and phishing

286
00:10:17,440 --> 00:10:19,279
emails randomly selected from public

287
00:10:19,279 --> 00:10:21,200
data sets

288
00:10:21,200 --> 00:10:23,440
and we further selected a thousand hyper

289
00:10:23,440 --> 00:10:25,279
partisan news texts in another thousand

290
00:10:25,279 --> 00:10:28,079
mainstream news texts dated between 2016

291
00:10:28,079 --> 00:10:29,839
and 2019.

292
00:10:29,839 --> 00:10:31,600
these news techs are made up of right

293
00:10:31,600 --> 00:10:33,920
left and center leaning publishers these

294
00:10:33,920 --> 00:10:35,839
ratings are based on the all by all

295
00:10:35,839 --> 00:10:38,160
sides bias rating some examples of these

296
00:10:38,160 --> 00:10:40,000
are for the right leaning text a

297
00:10:40,000 --> 00:10:42,320
breitbart and national review for center

298
00:10:42,320 --> 00:10:45,279
mainstream media and pr and reuters and

299
00:10:45,279 --> 00:10:47,680
for left leaning media

300
00:10:47,680 --> 00:10:50,240
buzzfeed news and fox

301
00:10:50,240 --> 00:10:51,760
we also extracted some features from

302
00:10:51,760 --> 00:10:53,680
these texts specifically emotional

303
00:10:53,680 --> 00:10:55,519
salience features learned via sentiment

304
00:10:55,519 --> 00:10:56,640
analysis

305
00:10:56,640 --> 00:10:58,560
topical structure inferred by topic

306
00:10:58,560 --> 00:11:00,560
modeling and social linguistic features

307
00:11:00,560 --> 00:11:03,200
related to influence keywords

308
00:11:03,200 --> 00:11:04,640
the social linguistic features are

309
00:11:04,640 --> 00:11:06,720
captured using luke which is a natural

310
00:11:06,720 --> 00:11:08,160
language processing framework that

311
00:11:08,160 --> 00:11:10,640
connects commonly used words with

312
00:11:10,640 --> 00:11:12,800
categories because luke has over 70

313
00:11:12,800 --> 00:11:15,040
total categories which are not all

314
00:11:15,040 --> 00:11:17,760
overtly related to influence we manually

315
00:11:17,760 --> 00:11:19,760
selected seven categories as features

316
00:11:19,760 --> 00:11:22,320
related to influence so for the scarcity

317
00:11:22,320 --> 00:11:24,880
principle of influence we selected the

318
00:11:24,880 --> 00:11:26,720
luke category time

319
00:11:26,720 --> 00:11:29,040
for emotion we selected anxiety anger

320
00:11:29,040 --> 00:11:31,040
and sadness and for loss and gain

321
00:11:31,040 --> 00:11:34,160
framing we chose risk money and reward

322
00:11:34,160 --> 00:11:36,000
with our data set ready we then

323
00:11:36,000 --> 00:11:38,240
proceeded with a rigorous coding or

324
00:11:38,240 --> 00:11:40,000
labeling process

325
00:11:40,000 --> 00:11:41,839
we drafted a detailed coding manual

326
00:11:41,839 --> 00:11:43,920
defining all influence cues with several

327
00:11:43,920 --> 00:11:45,760
examples we conducted an initial

328
00:11:45,760 --> 00:11:47,600
training session with nine undergraduate

329
00:11:47,600 --> 00:11:50,240
students with workshop style training so

330
00:11:50,240 --> 00:11:51,760
that the coders could familiarize

331
00:11:51,760 --> 00:11:53,200
themselves with the coding platform the

332
00:11:53,200 --> 00:11:54,959
code book and the text

333
00:11:54,959 --> 00:11:57,120
after this two intercoder reliability

334
00:11:57,120 --> 00:11:59,360
pre-test pretext pre-tests were

335
00:11:59,360 --> 00:12:01,120
conducted where coders were asked to

336
00:12:01,120 --> 00:12:04,320
independently code 20 and then 40 texts

337
00:12:04,320 --> 00:12:06,639
each after these pre-tests a discussion

338
00:12:06,639 --> 00:12:08,800
and then a new training session followed

339
00:12:08,800 --> 00:12:10,160
to clarify any issues with the

340
00:12:10,160 --> 00:12:12,240
categories in the code book

341
00:12:12,240 --> 00:12:14,000
following these additional discussion

342
00:12:14,000 --> 00:12:15,760
and training sessions coders were then

343
00:12:15,760 --> 00:12:18,639
instructed to co-code 260 texts which

344
00:12:18,639 --> 00:12:20,880
served as our intercoder reliability

345
00:12:20,880 --> 00:12:22,959
sample to code to calculate the inner

346
00:12:22,959 --> 00:12:25,519
code of reliability we use three indexes

347
00:12:25,519 --> 00:12:28,079
uh cohen's kappa percent of agreement

348
00:12:28,079 --> 00:12:30,000
and pro and lease index which all range

349
00:12:30,000 --> 00:12:33,040
from 0.4 to 0.99 which is considered

350
00:12:33,040 --> 00:12:34,880
moderately satisfactory

351
00:12:34,880 --> 00:12:36,800
the remaining texts were divided equally

352
00:12:36,800 --> 00:12:38,880
between all the coders and the entire

353
00:12:38,880 --> 00:12:41,920
coding process then lasted three months

354
00:12:41,920 --> 00:12:44,959
now let's look at a couple of examples

355
00:12:44,959 --> 00:12:46,880
here we have a known phishing email

356
00:12:46,880 --> 00:12:49,040
allegedly from paypal very joyfully

357
00:12:49,040 --> 00:12:50,480
informing you that you've been charged

358
00:12:50,480 --> 00:12:53,519
175 dollars and you'll receive a mystery

359
00:12:53,519 --> 00:12:55,279
item in just a few days

360
00:12:55,279 --> 00:12:57,120
our coders identify the use of several

361
00:12:57,120 --> 00:12:58,880
influence cues such as authority and

362
00:12:58,880 --> 00:13:00,320
gain framing

363
00:13:00,320 --> 00:13:02,560
our automated methods also found very

364
00:13:02,560 --> 00:13:04,320
high positive sentiment and the use of

365
00:13:04,320 --> 00:13:07,519
reward time and money in the email

366
00:13:07,519 --> 00:13:10,240
and here's a russian ira facebook ad

367
00:13:10,240 --> 00:13:12,000
again this was one of the many used to

368
00:13:12,000 --> 00:13:14,480
target americans during the 2016 general

369
00:13:14,480 --> 00:13:16,399
election and this one's got everything

370
00:13:16,399 --> 00:13:19,120
it's got negative sentiment blame anger

371
00:13:19,120 --> 00:13:20,720
all of these indicating high use of

372
00:13:20,720 --> 00:13:23,120
emotional appeal

373
00:13:23,120 --> 00:13:25,200
with this data set in mind we developed

374
00:13:25,200 --> 00:13:27,440
the two level hierarchical learning

375
00:13:27,440 --> 00:13:30,160
based architecture that we call lumen

376
00:13:30,160 --> 00:13:31,760
on the first level lumen receives as

377
00:13:31,760 --> 00:13:33,279
input the predictive features that we

378
00:13:33,279 --> 00:13:35,440
extracted from the text specifically

379
00:13:35,440 --> 00:13:37,200
sentiment social linguistic and topic

380
00:13:37,200 --> 00:13:39,040
modeling features

381
00:13:39,040 --> 00:13:40,800
on its second level we employed a

382
00:13:40,800 --> 00:13:42,160
general purpose machine learning

383
00:13:42,160 --> 00:13:44,399
algorithm to predict the influence cues

384
00:13:44,399 --> 00:13:46,800
we went with random forest algorithm as

385
00:13:46,800 --> 00:13:48,320
it provides the level of importance for

386
00:13:48,320 --> 00:13:50,399
each feature without additional

387
00:13:50,399 --> 00:13:52,639
computational costs

388
00:13:52,639 --> 00:13:54,959
again our main priority here was to

389
00:13:54,959 --> 00:13:56,959
discover which topics or features were

390
00:13:56,959 --> 00:13:59,040
most important in detecting influence

391
00:13:59,040 --> 00:14:00,720
cues

392
00:14:00,720 --> 00:14:02,880
we then trained lumen using 5-fold

393
00:14:02,880 --> 00:14:04,720
cross-validation compared lumens

394
00:14:04,720 --> 00:14:06,240
performance across three other machine

395
00:14:06,240 --> 00:14:08,639
learning algorithms lumen was comparable

396
00:14:08,639 --> 00:14:11,440
to lstm in terms of the f1 microscore

397
00:14:11,440 --> 00:14:13,360
but offered better interpretability of

398
00:14:13,360 --> 00:14:14,639
both the data set and the

399
00:14:14,639 --> 00:14:16,880
decision-making process that lumen

400
00:14:16,880 --> 00:14:18,639
undergoes consequently providing

401
00:14:18,639 --> 00:14:22,079
invaluable insights for future selection

402
00:14:22,079 --> 00:14:24,000
now the big takeaway here is that

403
00:14:24,000 --> 00:14:25,519
although this is a relatively

404
00:14:25,519 --> 00:14:27,839
straightforward process to conduct a

405
00:14:27,839 --> 00:14:29,600
supervised prediction problem machine

406
00:14:29,600 --> 00:14:31,600
learning is indeed promising for the

407
00:14:31,600 --> 00:14:34,639
retrieval of influence cues in text

408
00:14:34,639 --> 00:14:36,880
we also came to some very interesting

409
00:14:36,880 --> 00:14:39,279
findings just by analyzing the 3000

410
00:14:39,279 --> 00:14:41,519
manually coded text overall most texts

411
00:14:41,519 --> 00:14:43,760
in the data set apply between 3 and six

412
00:14:43,760 --> 00:14:45,120
influence cues

413
00:14:45,120 --> 00:14:47,040
we hypothesize that these findings may

414
00:14:47,040 --> 00:14:48,880
reflect the potential appeal or

415
00:14:48,880 --> 00:14:50,720
popularity of texts of moderate

416
00:14:50,720 --> 00:14:52,480
complexity

417
00:14:52,480 --> 00:14:54,639
most sex also applied authority which is

418
00:14:54,639 --> 00:14:56,560
concerning because authority has been

419
00:14:56,560 --> 00:14:58,160
shown to be one of the most impactful

420
00:14:58,160 --> 00:15:01,040
principle uh principles of influence

421
00:15:01,040 --> 00:15:03,279
and user susceptibility to phishing it's

422
00:15:03,279 --> 00:15:04,560
also important to note that the

423
00:15:04,560 --> 00:15:06,800
frequency of influence queues varied by

424
00:15:06,800 --> 00:15:08,480
the type of text so

425
00:15:08,480 --> 00:15:11,040
for example the principle of persuasion

426
00:15:11,040 --> 00:15:13,120
commitment was most common in fake news

427
00:15:13,120 --> 00:15:15,199
articles while scarcity was most common

428
00:15:15,199 --> 00:15:17,680
in phishing emails

429
00:15:17,680 --> 00:15:19,760
contrary to psychology research that

430
00:15:19,760 --> 00:15:21,760
stipulates that people may be proactive

431
00:15:21,760 --> 00:15:23,600
towards avoiding a loss then gaining

432
00:15:23,600 --> 00:15:26,000
something our data set indicates maybe

433
00:15:26,000 --> 00:15:27,360
the opposite

434
00:15:27,360 --> 00:15:29,120
gain was more prevalent than loss

435
00:15:29,120 --> 00:15:30,720
especially in the case of phishing

436
00:15:30,720 --> 00:15:32,399
emails suggesting that attackers might

437
00:15:32,399 --> 00:15:33,759
be attempting to

438
00:15:33,759 --> 00:15:36,720
lure users to potential financial gain

439
00:15:36,720 --> 00:15:38,720
we also hypothesized that phishing

440
00:15:38,720 --> 00:15:40,639
emails exhibited these high rates of

441
00:15:40,639 --> 00:15:43,199
framing because successful phishing

442
00:15:43,199 --> 00:15:45,680
survives only via a direct action from

443
00:15:45,680 --> 00:15:47,839
the user such as clicking a link which

444
00:15:47,839 --> 00:15:50,320
may therefore motivate you attackers to

445
00:15:50,320 --> 00:15:54,079
implement framing as a key driving force

446
00:15:54,079 --> 00:15:55,920
in line with this the data set invoked

447
00:15:55,920 --> 00:15:57,680
an overall positive sentiment with

448
00:15:57,680 --> 00:15:59,440
phishing emails containing the most

449
00:15:59,440 --> 00:16:01,759
positive average sentiment and fake news

450
00:16:01,759 --> 00:16:04,560
with the most negative average sentiment

451
00:16:04,560 --> 00:16:05,920
and you might have noticed what's

452
00:16:05,920 --> 00:16:08,560
arguably our biggest overall takeaway

453
00:16:08,560 --> 00:16:10,560
which is deceptive texts vary in

454
00:16:10,560 --> 00:16:13,680
quantifiable ways by influence cues so

455
00:16:13,680 --> 00:16:16,000
let's go through a few examples

456
00:16:16,000 --> 00:16:18,880
when comparing the russian ira ads fake

457
00:16:18,880 --> 00:16:20,959
news and phishing emails we saw that

458
00:16:20,959 --> 00:16:23,120
fake news used notably more authority

459
00:16:23,120 --> 00:16:25,279
objectivity and blame and guilt and was

460
00:16:25,279 --> 00:16:27,120
much lower in sentiment compared to

461
00:16:27,120 --> 00:16:30,560
phishing emails and the ira facebook ads

462
00:16:30,560 --> 00:16:32,800
similarly right-leaning hyper-partisan

463
00:16:32,800 --> 00:16:34,480
news had a higher frequency of

464
00:16:34,480 --> 00:16:35,839
commitment and left-leaning

465
00:16:35,839 --> 00:16:38,240
hyper-partisan news while left-leaning

466
00:16:38,240 --> 00:16:41,279
news had more liking reciprocation and

467
00:16:41,279 --> 00:16:44,160
scarcity than right-leaning news

468
00:16:44,160 --> 00:16:45,680
another example is that left

469
00:16:45,680 --> 00:16:47,199
hyperpartisan news had the highest

470
00:16:47,199 --> 00:16:48,959
averages for anxiety

471
00:16:48,959 --> 00:16:52,399
sadness reward and time

472
00:16:52,399 --> 00:16:55,600
fishing evoked risk and money while fake

473
00:16:55,600 --> 00:16:58,720
news evoke the most anger

474
00:16:58,720 --> 00:17:00,800
this diversity across the text types

475
00:17:00,800 --> 00:17:02,959
gives evidence of the highly imbalanced

476
00:17:02,959 --> 00:17:05,280
application of influence cues in real

477
00:17:05,280 --> 00:17:08,480
deceptive or misleading campaigns

478
00:17:08,480 --> 00:17:10,559
with all of this in mind now let's take

479
00:17:10,559 --> 00:17:12,480
a look at the big picture

480
00:17:12,480 --> 00:17:14,240
our results highlight the promise of

481
00:17:14,240 --> 00:17:16,480
machine learning to expose influence

482
00:17:16,480 --> 00:17:18,720
cues and texts the goal of detecting

483
00:17:18,720 --> 00:17:21,119
these cues is to improve the accuracy of

484
00:17:21,119 --> 00:17:23,359
human detection of cyber social

485
00:17:23,359 --> 00:17:24,480
engineering

486
00:17:24,480 --> 00:17:26,799
threats potentially triggering users to

487
00:17:26,799 --> 00:17:28,960
think analytically to address new

488
00:17:28,960 --> 00:17:30,880
deceptive campaigns and improve user

489
00:17:30,880 --> 00:17:32,720
decision making when confronted with

490
00:17:32,720 --> 00:17:34,880
potentially suspicious texts the next

491
00:17:34,880 --> 00:17:36,880
generation of interventions focused on

492
00:17:36,880 --> 00:17:39,280
mitigating deception may very well

493
00:17:39,280 --> 00:17:41,679
benefit from exposing influence cues to

494
00:17:41,679 --> 00:17:43,679
users and could complement

495
00:17:43,679 --> 00:17:45,679
automatic detection

496
00:17:45,679 --> 00:17:47,600
and with that thank you very much to

497
00:17:47,600 --> 00:17:49,200
enigma for this platform and everyone

498
00:17:49,200 --> 00:17:50,720
watching in home or

499
00:17:50,720 --> 00:17:52,880
at home or in person ready for questions

500
00:17:52,880 --> 00:17:56,120
thank you

501
00:18:02,799 --> 00:18:04,879
you

