1
00:00:07,520 --> 00:00:10,240
alrighty so is it just me or is anyone

2
00:00:10,240 --> 00:00:12,719
else walking around with trust issues

3
00:00:12,719 --> 00:00:15,120
anybody else get nervous when that 5g

4
00:00:15,120 --> 00:00:17,359
symbol pops up on your cell phone is the

5
00:00:17,359 --> 00:00:19,520
tightness in my chest just my good old

6
00:00:19,520 --> 00:00:22,720
chronic anxiety or oh my god was the 5g

7
00:00:22,720 --> 00:00:24,720
kovic conspiracy theory true all along

8
00:00:24,720 --> 00:00:26,480
and now i'm the fool

9
00:00:26,480 --> 00:00:28,480
or how about this you open up your inbox

10
00:00:28,480 --> 00:00:30,320
and amongst the thousands of emails that

11
00:00:30,320 --> 00:00:32,719
you for sure will get to this week maybe

12
00:00:32,719 --> 00:00:34,320
you do have some money to spare for the

13
00:00:34,320 --> 00:00:36,640
prince down in his luck this time around

14
00:00:36,640 --> 00:00:38,239
okay now before you start rolling your

15
00:00:38,239 --> 00:00:40,719
eyes at the prince scam isn't it just a

16
00:00:40,719 --> 00:00:42,960
bit shocking that fishing still costs so

17
00:00:42,960 --> 00:00:44,559
much to our society

18
00:00:44,559 --> 00:00:46,399
from the breach of personal data to the

19
00:00:46,399 --> 00:00:48,640
security and integrity of our democratic

20
00:00:48,640 --> 00:00:51,199
processes phishing is still a massive

21
00:00:51,199 --> 00:00:52,320
threat

22
00:00:52,320 --> 00:00:55,199
93 percent of data breaches for example

23
00:00:55,199 --> 00:00:56,719
are perpetrated through the use of

24
00:00:56,719 --> 00:00:59,120
fishing and 70 percent of governmental

25
00:00:59,120 --> 00:01:01,359
breaches are associated with phishing

26
00:01:01,359 --> 00:01:04,319
according to the fbi's 2019 internet

27
00:01:04,319 --> 00:01:06,720
crime complaint center losses associated

28
00:01:06,720 --> 00:01:08,479
with phishing scams like business email

29
00:01:08,479 --> 00:01:11,680
compromise romance fraud etc exceeded

30
00:01:11,680 --> 00:01:15,920
3.5 billion dollars in the us alone

31
00:01:15,920 --> 00:01:17,439
we've also seen that fishing can be

32
00:01:17,439 --> 00:01:19,439
leveraged as a tool

33
00:01:19,439 --> 00:01:22,320
against our democratic elections yet for

34
00:01:22,320 --> 00:01:24,479
zero day phishing automated detection

35
00:01:24,479 --> 00:01:26,799
such as blacklist machine learning is

36
00:01:26,799 --> 00:01:29,119
insufficient for phishing mitigation

37
00:01:29,119 --> 00:01:31,200
forcing the human user and potential

38
00:01:31,200 --> 00:01:33,040
victim to serve as the final line of

39
00:01:33,040 --> 00:01:35,600
defense against fishing attempts

40
00:01:35,600 --> 00:01:37,520
and our society is threatened by way

41
00:01:37,520 --> 00:01:39,439
more than the mammoth of fishing already

42
00:01:39,439 --> 00:01:41,840
is here in the u.s we've got electoral

43
00:01:41,840 --> 00:01:43,680
fraud claims being thrown around leading

44
00:01:43,680 --> 00:01:46,000
to protest riots and insurrection

45
00:01:46,000 --> 00:01:48,000
notwithstanding the foreign interference

46
00:01:48,000 --> 00:01:50,479
that has happened in our elections

47
00:01:50,479 --> 00:01:52,960
vaccine hesitancy is booming amidst a

48
00:01:52,960 --> 00:01:54,960
pandemic that is ongoing now for nearly

49
00:01:54,960 --> 00:01:56,159
two years

50
00:01:56,159 --> 00:01:58,399
and we have now arguably reached a point

51
00:01:58,399 --> 00:02:00,640
where science is akin to mere opinion

52
00:02:00,640 --> 00:02:03,439
often following along political lines

53
00:02:03,439 --> 00:02:05,520
i feel that i'm not completely wrong

54
00:02:05,520 --> 00:02:07,520
here when i venture to say that all of

55
00:02:07,520 --> 00:02:08,639
this

56
00:02:08,639 --> 00:02:10,720
and so much more has polarized us all

57
00:02:10,720 --> 00:02:13,599
into either unsettling apathy or fervent

58
00:02:13,599 --> 00:02:15,920
righteousness not to be a debbie downer

59
00:02:15,920 --> 00:02:18,640
but our democracies are at stake public

60
00:02:18,640 --> 00:02:20,239
health is in peril and the words

61
00:02:20,239 --> 00:02:22,720
impartial and news are now colloquially

62
00:02:22,720 --> 00:02:24,000
antonyms

63
00:02:24,000 --> 00:02:25,520
if you're picking up what i'm putting

64
00:02:25,520 --> 00:02:27,920
down here the overarching theme of all

65
00:02:27,920 --> 00:02:29,920
of this is that the web has increasingly

66
00:02:29,920 --> 00:02:32,800
become an ecosystem for deception cyber

67
00:02:32,800 --> 00:02:34,400
social engineering attacks such as

68
00:02:34,400 --> 00:02:35,680
phishing deceptive ads and

69
00:02:35,680 --> 00:02:38,080
disaffirmation have put internet users

70
00:02:38,080 --> 00:02:39,599
and even national security and

71
00:02:39,599 --> 00:02:41,760
democracies at great peril false

72
00:02:41,760 --> 00:02:43,360
information is greatly shaping the

73
00:02:43,360 --> 00:02:45,680
political social and economic landscapes

74
00:02:45,680 --> 00:02:48,080
of our society exacerbated and brought

75
00:02:48,080 --> 00:02:50,480
to light by social media all of this

76
00:02:50,480 --> 00:02:52,239
falls into what i call the deceptive

77
00:02:52,239 --> 00:02:53,760
text umbrella

78
00:02:53,760 --> 00:02:55,840
from purposefully deceptive texts of

79
00:02:55,840 --> 00:02:58,000
facts rumors half-truths or outright

80
00:02:58,000 --> 00:02:59,720
lies disseminated manipulative

81
00:02:59,720 --> 00:03:02,159
manipulatively we can see how all of

82
00:03:02,159 --> 00:03:04,000
these buzzwords are connected but you

83
00:03:04,000 --> 00:03:06,000
might be wondering okay but what's

84
00:03:06,000 --> 00:03:08,720
fishing doing here well fishing is a

85
00:03:08,720 --> 00:03:10,640
social engineering attack aimed at

86
00:03:10,640 --> 00:03:12,239
influencing users your deceptive

87
00:03:12,239 --> 00:03:14,239
arguments into taking an action such as

88
00:03:14,239 --> 00:03:16,159
clicking on a malicious link though

89
00:03:16,159 --> 00:03:18,239
phishing differs from disinformation for

90
00:03:18,239 --> 00:03:20,560
example in its modus operandi

91
00:03:20,560 --> 00:03:22,400
we argue that it overlaps with

92
00:03:22,400 --> 00:03:24,720
misleading media and its main purpose

93
00:03:24,720 --> 00:03:26,799
which is galvanization all of these

94
00:03:26,799 --> 00:03:28,799
types of texts within the deceptive text

95
00:03:28,799 --> 00:03:31,840
umbrella aim to galvanize users and site

96
00:03:31,840 --> 00:03:34,319
clicking a link or developing an opinion

97
00:03:34,319 --> 00:03:37,040
by triggering these victims emotions

98
00:03:37,040 --> 00:03:40,000
disinformation misinformation phishing

99
00:03:40,000 --> 00:03:44,239
they are all tools of and for deception

100
00:03:44,239 --> 00:03:46,640
we know intuitively that deceptive texts

101
00:03:46,640 --> 00:03:48,640
are all in a state of constant change we

102
00:03:48,640 --> 00:03:50,480
saw it happening during the covet 19

103
00:03:50,480 --> 00:03:52,959
pandemic and the 2020 u.s general

104
00:03:52,959 --> 00:03:55,360
election for example but below the

105
00:03:55,360 --> 00:03:57,120
surface there are likely constants

106
00:03:57,120 --> 00:03:58,959
within these deceptive texts

107
00:03:58,959 --> 00:04:00,720
our research posits that they all

108
00:04:00,720 --> 00:04:03,280
leverage influence cues

109
00:04:03,280 --> 00:04:05,680
so towards this end we looked at several

110
00:04:05,680 --> 00:04:07,040
types of influence cues that are

111
00:04:07,040 --> 00:04:10,080
relevant and present in deceptive texts

112
00:04:10,080 --> 00:04:11,840
if you're not familiar with him

113
00:04:11,840 --> 00:04:13,760
psychology marketing professor robert

114
00:04:13,760 --> 00:04:15,680
cialdini proposed six principles of

115
00:04:15,680 --> 00:04:17,600
persuasion that identify context in

116
00:04:17,600 --> 00:04:19,199
which people are more susceptible to

117
00:04:19,199 --> 00:04:21,680
influence so for example people are more

118
00:04:21,680 --> 00:04:23,360
likely to comply with requests made by

119
00:04:23,360 --> 00:04:26,000
figures of authority we act impulsively

120
00:04:26,000 --> 00:04:28,720
in the face of scarcity will reciprocate

121
00:04:28,720 --> 00:04:31,759
or repay favors there is sensitivity to

122
00:04:31,759 --> 00:04:34,880
herd mentality as a form of social proof

123
00:04:34,880 --> 00:04:37,120
we tend to comply to requests made by

124
00:04:37,120 --> 00:04:39,120
others based on shared liking or

125
00:04:39,120 --> 00:04:41,919
similarity and there's pressure to

126
00:04:41,919 --> 00:04:44,240
behave in line with prior commitments we

127
00:04:44,240 --> 00:04:46,080
also looked at attribution of blame or

128
00:04:46,080 --> 00:04:48,560
guilt and the use of

129
00:04:48,560 --> 00:04:51,600
emphasis such as capital letters

130
00:04:51,600 --> 00:04:54,400
the subjectivity or objectivity of the

131
00:04:54,400 --> 00:04:56,479
sentences in the text this is more so

132
00:04:56,479 --> 00:04:58,560
related to whether a sentence presented

133
00:04:58,560 --> 00:05:00,400
itself as an opinion or grounded by

134
00:05:00,400 --> 00:05:03,440
evidence so for example uh this makes me

135
00:05:03,440 --> 00:05:06,479
so angry would be subjective while

136
00:05:06,479 --> 00:05:08,800
according to the cdc injecting bleach

137
00:05:08,800 --> 00:05:10,800
doesn't actually really help with covid

138
00:05:10,800 --> 00:05:13,280
would be an example of an objective text

139
00:05:13,280 --> 00:05:14,960
we also looked at the framing of the

140
00:05:14,960 --> 00:05:16,720
message as either potentially causing a

141
00:05:16,720 --> 00:05:18,960
gain or a loss

142
00:05:18,960 --> 00:05:21,280
now few works have actually looked at

143
00:05:21,280 --> 00:05:23,280
these influence cues in the context of

144
00:05:23,280 --> 00:05:25,680
miss and disinformation but if we look

145
00:05:25,680 --> 00:05:28,000
at phishing research a large effort has

146
00:05:28,000 --> 00:05:29,919
already been made into investigating the

147
00:05:29,919 --> 00:05:31,919
extent to which cialdini's principles of

148
00:05:31,919 --> 00:05:34,240
persuasion are used in phishing emails

149
00:05:34,240 --> 00:05:36,720
and how users are susceptible to them

150
00:05:36,720 --> 00:05:38,400
and there's quite a few things we can

151
00:05:38,400 --> 00:05:40,479
gather from related work

152
00:05:40,479 --> 00:05:42,479
research on deception detection reveals

153
00:05:42,479 --> 00:05:45,039
that deceivers apply influence cues and

154
00:05:45,039 --> 00:05:46,880
messages to increase their appeal to the

155
00:05:46,880 --> 00:05:49,199
recipients we know that these influence

156
00:05:49,199 --> 00:05:51,039
cues are highly occurring in deceptive

157
00:05:51,039 --> 00:05:52,960
texts and that users are extremely

158
00:05:52,960 --> 00:05:55,199
susceptible to them we also know from

159
00:05:55,199 --> 00:05:56,960
our own work in related work that

160
00:05:56,960 --> 00:05:58,319
authority was the most frequent

161
00:05:58,319 --> 00:05:59,840
principle of persuasion in phishing

162
00:05:59,840 --> 00:06:02,160
emails followed by scarcity

163
00:06:02,160 --> 00:06:04,560
the user's personality is also a big

164
00:06:04,560 --> 00:06:06,960
factor at play extraversion for example

165
00:06:06,960 --> 00:06:09,039
has been found to lead to increased

166
00:06:09,039 --> 00:06:11,199
susceptibility to the commitment

167
00:06:11,199 --> 00:06:14,240
liking authority influence cues

168
00:06:14,240 --> 00:06:16,960
demographics is another huge factor

169
00:06:16,960 --> 00:06:18,639
young adults for example have been shown

170
00:06:18,639 --> 00:06:20,560
to be most vulnerable to the scarcity

171
00:06:20,560 --> 00:06:22,560
principle while older adults are more

172
00:06:22,560 --> 00:06:25,199
susceptible to reciprocation but

173
00:06:25,199 --> 00:06:26,880
all age groups are susceptible to

174
00:06:26,880 --> 00:06:28,080
authority

175
00:06:28,080 --> 00:06:30,160
in terms of hyper partisan and fake news

176
00:06:30,160 --> 00:06:31,520
we can actually see some similar

177
00:06:31,520 --> 00:06:33,759
findings news articles that support

178
00:06:33,759 --> 00:06:35,440
authority are shared and liked more

179
00:06:35,440 --> 00:06:37,120
often whereas articles high in

180
00:06:37,120 --> 00:06:40,080
reciprocity are shared least

181
00:06:40,080 --> 00:06:42,080
and psychology research has suggested

182
00:06:42,080 --> 00:06:44,560
that loss that is framing an outcome as

183
00:06:44,560 --> 00:06:46,639
a possible loss is more impactful than

184
00:06:46,639 --> 00:06:48,800
the possibility of a gain so we know

185
00:06:48,800 --> 00:06:51,680
people are more driven to avoid a loss

186
00:06:51,680 --> 00:06:54,400
so the question arises influence cues

187
00:06:54,400 --> 00:06:56,639
all right cool but what can we do with

188
00:06:56,639 --> 00:06:58,160
these well

189
00:06:58,160 --> 00:07:00,400
if 2020 has taught us anything is that

190
00:07:00,400 --> 00:07:02,479
human beings just like our automated

191
00:07:02,479 --> 00:07:04,880
inventions are flawed looking again at

192
00:07:04,880 --> 00:07:06,800
fishing we know that training humans to

193
00:07:06,800 --> 00:07:09,120
detect phishing is difficult to navigate

194
00:07:09,120 --> 00:07:11,759
because users individual characteristics

195
00:07:11,759 --> 00:07:14,080
like age forgetfulness overconfidence

196
00:07:14,080 --> 00:07:16,479
hinder training efficacy we think oh

197
00:07:16,479 --> 00:07:18,560
yeah i for sure could detect phishing

198
00:07:18,560 --> 00:07:20,880
yet users often experience high

199
00:07:20,880 --> 00:07:22,560
victimization rates and simulated

200
00:07:22,560 --> 00:07:24,160
phishing attacks

201
00:07:24,160 --> 00:07:25,440
so

202
00:07:25,440 --> 00:07:27,280
what's the great magical solution that i

203
00:07:27,280 --> 00:07:29,280
have for you today well communications

204
00:07:29,280 --> 00:07:30,880
research points us towards the dangers

205
00:07:30,880 --> 00:07:33,199
of what's called selective exposure a

206
00:07:33,199 --> 00:07:35,280
theory akin to confirmation bias

207
00:07:35,280 --> 00:07:37,039
pertaining to the idea that we favor

208
00:07:37,039 --> 00:07:39,039
information that reinforces our prior

209
00:07:39,039 --> 00:07:41,360
beliefs research has also given us the

210
00:07:41,360 --> 00:07:43,360
understanding that false content can

211
00:07:43,360 --> 00:07:46,240
increase our beliefs in a falsehood so

212
00:07:46,240 --> 00:07:48,479
misinformation is actually extremely

213
00:07:48,479 --> 00:07:50,479
insidious but if we borrow from

214
00:07:50,479 --> 00:07:53,199
communications journalism psychology and

215
00:07:53,199 --> 00:07:55,120
even some related work in our own field

216
00:07:55,120 --> 00:07:57,120
we know that the ability to think to

217
00:07:57,120 --> 00:08:00,080
think deliberatively and analytically is

218
00:08:00,080 --> 00:08:02,000
generally associated with the rejection

219
00:08:02,000 --> 00:08:04,400
of misinformation and disinformation

220
00:08:04,400 --> 00:08:06,400
regardless of your political alignment

221
00:08:06,400 --> 00:08:07,599
therefore

222
00:08:07,599 --> 00:08:09,919
activating if you will this analytical

223
00:08:09,919 --> 00:08:12,160
thinking helping users slow down for

224
00:08:12,160 --> 00:08:14,720
just a second to think may act as an

225
00:08:14,720 --> 00:08:17,440
antidote to selective exposure

226
00:08:17,440 --> 00:08:19,039
we've recently even seen somewhat

227
00:08:19,039 --> 00:08:21,120
similar examples of this at work aiming

228
00:08:21,120 --> 00:08:23,280
to expose a source of information

229
00:08:23,280 --> 00:08:25,199
twitter has begun showing its users some

230
00:08:25,199 --> 00:08:26,800
labels indicating government or

231
00:08:26,800 --> 00:08:28,400
state-affiliated media accounts

232
00:08:28,400 --> 00:08:30,639
presumably with the hope that this will

233
00:08:30,639 --> 00:08:32,240
allow users to make more informed

234
00:08:32,240 --> 00:08:33,599
decisions

235
00:08:33,599 --> 00:08:35,919
so what if we could look beneath the

236
00:08:35,919 --> 00:08:37,919
surface of a text and bring awareness of

237
00:08:37,919 --> 00:08:40,080
the influence cues present in it this

238
00:08:40,080 --> 00:08:42,240
may in turn aid users by providing

239
00:08:42,240 --> 00:08:44,240
additional context in the message thus

240
00:08:44,240 --> 00:08:46,560
helping the user think analytically with

241
00:08:46,560 --> 00:08:48,560
the added bonus of benefiting future

242
00:08:48,560 --> 00:08:50,880
work aimed at the automatic detection of

243
00:08:50,880 --> 00:08:53,279
deceptive online content so what would

244
00:08:53,279 --> 00:08:55,200
that look like well a lot of recent

245
00:08:55,200 --> 00:08:56,480
works have looked at binary

246
00:08:56,480 --> 00:08:58,320
classification as the ultimate goal here

247
00:08:58,320 --> 00:09:00,080
is this disinformation or not is this

248
00:09:00,080 --> 00:09:02,720
phishing or not what if for now where

249
00:09:02,720 --> 00:09:04,800
we're being flooded by ambiguity and

250
00:09:04,800 --> 00:09:06,880
duplicitous information we can think of

251
00:09:06,880 --> 00:09:09,600
an intermediary step help users slow

252
00:09:09,600 --> 00:09:11,360
down and make a decision by adding

253
00:09:11,360 --> 00:09:13,040
friction to the process of consuming

254
00:09:13,040 --> 00:09:14,880
information online

255
00:09:14,880 --> 00:09:16,959
similar to the calorie label on any food

256
00:09:16,959 --> 00:09:18,959
you pick up at your supermarket what if

257
00:09:18,959 --> 00:09:20,640
whenever you were exposed to a piece of

258
00:09:20,640 --> 00:09:23,120
text online you were also you would you

259
00:09:23,120 --> 00:09:25,279
could also know what influence cues are

260
00:09:25,279 --> 00:09:27,279
present in the text and then you can

261
00:09:27,279 --> 00:09:29,440
make your own hopefully better informed

262
00:09:29,440 --> 00:09:31,200
decision

263
00:09:31,200 --> 00:09:33,120
what if we could see for example that

264
00:09:33,120 --> 00:09:35,200
this russian ira facebook ad was

265
00:09:35,200 --> 00:09:38,080
leveraging a wealth of influence cues

266
00:09:38,080 --> 00:09:39,920
towards this goal we needed to first

267
00:09:39,920 --> 00:09:42,320
curate a relatively large data set of 3

268
00:09:42,320 --> 00:09:45,040
000 diverse online pieces of text which

269
00:09:45,040 --> 00:09:46,640
we broke up into what we call

270
00:09:46,640 --> 00:09:48,399
purposefully deceptive texts

271
00:09:48,399 --> 00:09:50,480
hyper-partisan news and mainstream

272
00:09:50,480 --> 00:09:51,920
center news

273
00:09:51,920 --> 00:09:53,519
for the deceptive text we randomly

274
00:09:53,519 --> 00:09:55,519
selected a thousand texts from a variety

275
00:09:55,519 --> 00:09:57,680
of data sets online these samples

276
00:09:57,680 --> 00:09:59,920
encompassed facebook ads used by the

277
00:09:59,920 --> 00:10:02,240
russian internet research agency made

278
00:10:02,240 --> 00:10:03,839
available by the us house of

279
00:10:03,839 --> 00:10:05,200
representatives permanent select

280
00:10:05,200 --> 00:10:07,440
committee on intelligence after facebook

281
00:10:07,440 --> 00:10:09,200
internal audits these texts were

282
00:10:09,200 --> 00:10:11,440
believed to have been exposed to 126

283
00:10:11,440 --> 00:10:15,200
million americans between 2015 and 2017.

284
00:10:15,200 --> 00:10:17,040
we also leveraged fake news and phishing

285
00:10:17,040 --> 00:10:18,800
emails randomly selected from public

286
00:10:18,800 --> 00:10:20,800
data sets

287
00:10:20,800 --> 00:10:22,959
and we further selected a thousand hyper

288
00:10:22,959 --> 00:10:24,800
partisan news texts in another thousand

289
00:10:24,800 --> 00:10:27,680
mainstream news texts dated between 2016

290
00:10:27,680 --> 00:10:29,440
and 2019.

291
00:10:29,440 --> 00:10:31,200
these news tags are made up of right

292
00:10:31,200 --> 00:10:33,440
left and center leaning publishers these

293
00:10:33,440 --> 00:10:35,440
ratings are based on the all by all

294
00:10:35,440 --> 00:10:37,760
sides bias rating some examples of these

295
00:10:37,760 --> 00:10:39,600
are for the right leaning text a

296
00:10:39,600 --> 00:10:41,920
breitbart and national review for center

297
00:10:41,920 --> 00:10:44,880
mainstream media and pr and reuters and

298
00:10:44,880 --> 00:10:47,279
for left leaning media

299
00:10:47,279 --> 00:10:49,760
buzzfeed news and fox

300
00:10:49,760 --> 00:10:51,360
we also extracted some features from

301
00:10:51,360 --> 00:10:53,279
these texts specifically emotional

302
00:10:53,279 --> 00:10:55,120
salience features learned via sentiment

303
00:10:55,120 --> 00:10:56,240
analysis

304
00:10:56,240 --> 00:10:58,160
topical structure inferred by topic

305
00:10:58,160 --> 00:11:00,160
modeling and social linguistic features

306
00:11:00,160 --> 00:11:02,800
related to influence keywords

307
00:11:02,800 --> 00:11:04,240
the social linguistic features are

308
00:11:04,240 --> 00:11:06,240
captured using luke which is a natural

309
00:11:06,240 --> 00:11:07,760
language processing framework that

310
00:11:07,760 --> 00:11:10,160
connects commonly used words with

311
00:11:10,160 --> 00:11:12,320
categories because luke has over 70

312
00:11:12,320 --> 00:11:14,640
total categories which are not all

313
00:11:14,640 --> 00:11:17,360
overtly related to influence we manually

314
00:11:17,360 --> 00:11:19,360
selected seven categories as features

315
00:11:19,360 --> 00:11:21,920
related to influence so for the scarcity

316
00:11:21,920 --> 00:11:24,399
principle of influence we selected the

317
00:11:24,399 --> 00:11:26,320
luke category time

318
00:11:26,320 --> 00:11:28,720
for motion we selected anxiety anger and

319
00:11:28,720 --> 00:11:31,120
sadness and for loss and gain framing we

320
00:11:31,120 --> 00:11:33,760
chose risk money and reward

321
00:11:33,760 --> 00:11:35,600
with our data set ready we then

322
00:11:35,600 --> 00:11:37,839
proceeded with a rigorous coding or

323
00:11:37,839 --> 00:11:39,519
labeling process

324
00:11:39,519 --> 00:11:41,440
we drafted a detailed coding manual

325
00:11:41,440 --> 00:11:43,440
defining all influence cues with several

326
00:11:43,440 --> 00:11:45,360
examples we conducted an initial

327
00:11:45,360 --> 00:11:47,200
training session with nine undergraduate

328
00:11:47,200 --> 00:11:49,839
students with workshop style training so

329
00:11:49,839 --> 00:11:51,279
that the coders could familiarize

330
00:11:51,279 --> 00:11:52,800
themselves with the coding platform the

331
00:11:52,800 --> 00:11:54,560
code book and the text

332
00:11:54,560 --> 00:11:56,720
after this two intercoder reliability

333
00:11:56,720 --> 00:11:58,959
pre-test pretext pre-tests were

334
00:11:58,959 --> 00:12:00,720
conducted where coders were asked to

335
00:12:00,720 --> 00:12:03,920
independently code 20 and then 40 texts

336
00:12:03,920 --> 00:12:06,160
each after these pre-tests a discretion

337
00:12:06,160 --> 00:12:08,399
and then a new training session followed

338
00:12:08,399 --> 00:12:09,760
to clarify any issues with the

339
00:12:09,760 --> 00:12:11,839
categories in the code book

340
00:12:11,839 --> 00:12:13,600
following these additional discussion

341
00:12:13,600 --> 00:12:15,360
and training sessions coders were then

342
00:12:15,360 --> 00:12:18,240
instructed to co-code 260 texts which

343
00:12:18,240 --> 00:12:20,399
served as our intercoder reliability

344
00:12:20,399 --> 00:12:22,639
sample to co to calculate the inner code

345
00:12:22,639 --> 00:12:25,440
of reliability we use three indexes

346
00:12:25,440 --> 00:12:27,760
cohen's kappa percent of agreement and

347
00:12:27,760 --> 00:12:29,839
pro and leads index which all range from

348
00:12:29,839 --> 00:12:32,560
0.4 to 0.99 which is considered

349
00:12:32,560 --> 00:12:34,480
moderately satisfactory

350
00:12:34,480 --> 00:12:36,399
the remaining texts were divided equally

351
00:12:36,399 --> 00:12:38,399
between all the coders and the entire

352
00:12:38,399 --> 00:12:41,440
coding process then lasted three months

353
00:12:41,440 --> 00:12:44,560
now let's look at a couple of examples

354
00:12:44,560 --> 00:12:46,480
here we have a known phishing email

355
00:12:46,480 --> 00:12:48,639
allegedly from paypal very joyfully

356
00:12:48,639 --> 00:12:50,000
informing you that you've been charged

357
00:12:50,000 --> 00:12:51,680
175

358
00:12:51,680 --> 00:12:53,519
and you'll receive a mystery item in

359
00:12:53,519 --> 00:12:54,880
just a few days

360
00:12:54,880 --> 00:12:56,720
our coders identify the use of several

361
00:12:56,720 --> 00:12:58,480
influence cues such as authority and

362
00:12:58,480 --> 00:13:01,279
gain framing uh our automated methods

363
00:13:01,279 --> 00:13:03,360
also found very high positive sentiment

364
00:13:03,360 --> 00:13:05,600
and the use of reward time and money in

365
00:13:05,600 --> 00:13:07,040
the email

366
00:13:07,040 --> 00:13:08,240
and here's a

367
00:13:08,240 --> 00:13:10,560
russian ira facebook ad again this is

368
00:13:10,560 --> 00:13:12,399
one of the many used to target americans

369
00:13:12,399 --> 00:13:15,040
during the 2016 general election and

370
00:13:15,040 --> 00:13:16,320
this one's got everything it's got

371
00:13:16,320 --> 00:13:18,959
negative sentiment blame anger all of

372
00:13:18,959 --> 00:13:20,800
these indicating high use of emotional

373
00:13:20,800 --> 00:13:22,720
appeal

374
00:13:22,720 --> 00:13:24,800
with this data set in mind we developed

375
00:13:24,800 --> 00:13:27,040
the two level hierarchical learning

376
00:13:27,040 --> 00:13:29,760
based architecture that we call lumen

377
00:13:29,760 --> 00:13:31,360
on the first level lumen receives as

378
00:13:31,360 --> 00:13:32,880
input the predictive features that we

379
00:13:32,880 --> 00:13:35,040
extracted from the text specifically

380
00:13:35,040 --> 00:13:36,800
sentiment social linguistic and topic

381
00:13:36,800 --> 00:13:38,560
modeling features

382
00:13:38,560 --> 00:13:40,399
on its second level we employed a

383
00:13:40,399 --> 00:13:41,760
general purpose machine learning

384
00:13:41,760 --> 00:13:44,000
algorithm to predict the influence cues

385
00:13:44,000 --> 00:13:46,399
we went with random forest algorithm as

386
00:13:46,399 --> 00:13:47,920
it provides the level of importance for

387
00:13:47,920 --> 00:13:50,000
each feature without additional

388
00:13:50,000 --> 00:13:52,240
computational costs

389
00:13:52,240 --> 00:13:54,480
again our main priority here was to

390
00:13:54,480 --> 00:13:56,480
discover which topics or features were

391
00:13:56,480 --> 00:13:58,639
most important in detecting influence

392
00:13:58,639 --> 00:14:00,320
cues

393
00:14:00,320 --> 00:14:02,480
we then trained lumen um using five-fold

394
00:14:02,480 --> 00:14:04,320
cross-validation compared lumens

395
00:14:04,320 --> 00:14:05,839
performance across three other machine

396
00:14:05,839 --> 00:14:08,240
learning algorithms lumen was comparable

397
00:14:08,240 --> 00:14:11,040
to lstm in terms of the f1 microscore

398
00:14:11,040 --> 00:14:12,959
but offered better interpretability of

399
00:14:12,959 --> 00:14:14,240
both the data set and the

400
00:14:14,240 --> 00:14:16,480
decision-making process that lumen

401
00:14:16,480 --> 00:14:18,240
undergrows consequently providing

402
00:14:18,240 --> 00:14:21,600
invaluable insights for future selection

403
00:14:21,600 --> 00:14:23,600
now the big takeaway here is that

404
00:14:23,600 --> 00:14:25,120
although this is a relatively

405
00:14:25,120 --> 00:14:27,440
straightforward process to conduct a

406
00:14:27,440 --> 00:14:29,199
supervised prediction problem machine

407
00:14:29,199 --> 00:14:31,199
learning is indeed promising for the

408
00:14:31,199 --> 00:14:34,160
retrieval of influence cues in text

409
00:14:34,160 --> 00:14:36,399
we also came to some very interesting

410
00:14:36,399 --> 00:14:38,880
findings just by analyzing the 3000

411
00:14:38,880 --> 00:14:41,120
manually coded text overall most texts

412
00:14:41,120 --> 00:14:43,279
in the data set apply between 3 and six

413
00:14:43,279 --> 00:14:44,720
influence cues

414
00:14:44,720 --> 00:14:46,560
we hypothesize that these findings may

415
00:14:46,560 --> 00:14:48,399
reflect the potential appeal or

416
00:14:48,399 --> 00:14:50,320
popularity of texts of moderate

417
00:14:50,320 --> 00:14:52,079
complexity

418
00:14:52,079 --> 00:14:54,240
most sex also applied authority which is

419
00:14:54,240 --> 00:14:56,079
concerning because authority has been

420
00:14:56,079 --> 00:14:57,680
shown to be one of the most impactful

421
00:14:57,680 --> 00:15:00,560
principle principles of influence

422
00:15:00,560 --> 00:15:02,880
and user susceptibility to phishing it's

423
00:15:02,880 --> 00:15:04,079
also important to note that the

424
00:15:04,079 --> 00:15:06,399
frequency of influence cues varied by

425
00:15:06,399 --> 00:15:08,079
the type of text so

426
00:15:08,079 --> 00:15:10,560
for example the principle of persuasion

427
00:15:10,560 --> 00:15:12,720
commitment was most common in fake news

428
00:15:12,720 --> 00:15:14,800
articles while scarcity was most common

429
00:15:14,800 --> 00:15:17,279
in phishing emails

430
00:15:17,279 --> 00:15:19,360
contrary to psychology research that

431
00:15:19,360 --> 00:15:21,360
stipulates that people may be proactive

432
00:15:21,360 --> 00:15:23,199
towards avoiding a loss then gaining

433
00:15:23,199 --> 00:15:25,519
something our data set indicates maybe

434
00:15:25,519 --> 00:15:26,959
the opposite

435
00:15:26,959 --> 00:15:28,720
gain was more prevalent than loss

436
00:15:28,720 --> 00:15:30,320
especially in the case of phishing

437
00:15:30,320 --> 00:15:31,920
emails suggesting that attackers might

438
00:15:31,920 --> 00:15:35,040
be attempting to lure users to potential

439
00:15:35,040 --> 00:15:37,920
financial gain we also hypothesized that

440
00:15:37,920 --> 00:15:39,839
phishing emails exhibited these high

441
00:15:39,839 --> 00:15:41,920
rates of framing because successful

442
00:15:41,920 --> 00:15:44,639
phishing survives only via a direct

443
00:15:44,639 --> 00:15:46,639
action from the user such as clicking a

444
00:15:46,639 --> 00:15:49,120
link which may therefore motivate you

445
00:15:49,120 --> 00:15:51,440
attackers to implement framing as a key

446
00:15:51,440 --> 00:15:53,839
driving force

447
00:15:53,839 --> 00:15:55,600
line with this the data set invoked an

448
00:15:55,600 --> 00:15:57,680
overall positive sentiment with phishing

449
00:15:57,680 --> 00:15:59,920
emails containing the most positive

450
00:15:59,920 --> 00:16:01,600
average sentiment and fake news with the

451
00:16:01,600 --> 00:16:04,160
most negative average sentiment

452
00:16:04,160 --> 00:16:05,519
and you might have noticed what's

453
00:16:05,519 --> 00:16:08,079
arguably our biggest overall takeaway

454
00:16:08,079 --> 00:16:10,160
which is deceptive texts vary in

455
00:16:10,160 --> 00:16:13,199
quantifiable ways by influence queues so

456
00:16:13,199 --> 00:16:15,519
let's go through a few examples

457
00:16:15,519 --> 00:16:18,399
when comparing the russian ira ads fake

458
00:16:18,399 --> 00:16:20,480
news and phishing emails we saw that

459
00:16:20,480 --> 00:16:22,639
fake news used notably more authority

460
00:16:22,639 --> 00:16:24,880
objectivity and blame and guilt and was

461
00:16:24,880 --> 00:16:26,720
much lower in sentiment compared to

462
00:16:26,720 --> 00:16:30,160
phishing emails and the ira facebook ads

463
00:16:30,160 --> 00:16:32,320
similarly right leaning hyperpartisan

464
00:16:32,320 --> 00:16:34,000
news had a higher frequency of

465
00:16:34,000 --> 00:16:35,440
commitment than left-leaning

466
00:16:35,440 --> 00:16:37,759
hyper-partisan news while left-leaning

467
00:16:37,759 --> 00:16:40,800
news had more liking reciprocation and

468
00:16:40,800 --> 00:16:43,680
scarcity than right-leaning news

469
00:16:43,680 --> 00:16:45,279
another example is that left

470
00:16:45,279 --> 00:16:46,800
hyper-partisan news had the highest

471
00:16:46,800 --> 00:16:48,480
averages for anxiety

472
00:16:48,480 --> 00:16:52,000
sadness reward in time

473
00:16:52,000 --> 00:16:55,120
fishing evoked risk and money while fake

474
00:16:55,120 --> 00:16:58,240
news evoke the most anger

475
00:16:58,240 --> 00:17:00,399
this diversity across the text types

476
00:17:00,399 --> 00:17:02,560
gives evidence of the highly imbalanced

477
00:17:02,560 --> 00:17:04,880
application of influence cues in real

478
00:17:04,880 --> 00:17:08,079
deceptive or misleading campaigns

479
00:17:08,079 --> 00:17:10,160
with all of this in mind now let's take

480
00:17:10,160 --> 00:17:12,079
a look at the big picture

481
00:17:12,079 --> 00:17:13,839
our results highlight the promise of

482
00:17:13,839 --> 00:17:16,000
machine learning to expose influence

483
00:17:16,000 --> 00:17:18,319
cues and text the goal of detecting

484
00:17:18,319 --> 00:17:20,559
these queues is to improve the accuracy

485
00:17:20,559 --> 00:17:22,959
of human detection of cyber social

486
00:17:22,959 --> 00:17:25,439
engineering threats potentially

487
00:17:25,439 --> 00:17:27,679
triggering users to think analytically

488
00:17:27,679 --> 00:17:29,760
to address new deceptive campaigns and

489
00:17:29,760 --> 00:17:31,440
improve user decision making when

490
00:17:31,440 --> 00:17:33,360
confronted with potentially suspicious

491
00:17:33,360 --> 00:17:35,200
texts the next generation of

492
00:17:35,200 --> 00:17:37,039
interventions focused on mitigating

493
00:17:37,039 --> 00:17:39,840
deception may very well benefit from

494
00:17:39,840 --> 00:17:41,840
exposing influence cues to users and

495
00:17:41,840 --> 00:17:43,280
could complement

496
00:17:43,280 --> 00:17:45,200
automatic detection

497
00:17:45,200 --> 00:17:47,120
and with that thank you very much to

498
00:17:47,120 --> 00:17:48,799
enigma for this platform and everyone

499
00:17:48,799 --> 00:17:50,320
watching in home or

500
00:17:50,320 --> 00:17:52,480
at home or in person ready for questions

501
00:17:52,480 --> 00:17:55,640
thank you

502
00:18:01,840 --> 00:18:03,918
you

