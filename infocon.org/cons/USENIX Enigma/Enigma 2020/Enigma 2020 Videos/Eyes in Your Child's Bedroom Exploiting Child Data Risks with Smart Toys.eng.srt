1
00:00:16,120 --> 00:00:20,240
children talk to their toys often often

2
00:00:18,800 --> 00:00:23,000
confiding into them

3
00:00:20,240 --> 00:00:25,400
I surely do my days of like dollhouse

4
00:00:23,000 --> 00:00:27,170
making tea parties and everything but

5
00:00:25,400 --> 00:00:30,140
now we have reached into a stage of

6
00:00:27,170 --> 00:00:32,599
Technology where these toys can actually

7
00:00:30,140 --> 00:00:36,080
listen and remember and this is a code

8
00:00:32,598 --> 00:00:39,290
from fisher-price toys so the real

9
00:00:36,080 --> 00:00:41,030
question lies are these toys the friends

10
00:00:39,290 --> 00:00:43,430
whom they need or they are slowly

11
00:00:41,030 --> 00:00:46,550
turning into the dangerous foes whom

12
00:00:43,430 --> 00:00:48,800
they should be scared about so I haven't

13
00:00:46,550 --> 00:00:51,230
cut back to the chase and I will say the

14
00:00:48,800 --> 00:00:54,078
results of my talk here that many smart

15
00:00:51,230 --> 00:00:56,809
toys are insecure and dangerous but

16
00:00:54,079 --> 00:00:59,059
there are ways which we can help with

17
00:00:56,809 --> 00:01:00,980
and we can develop secure technologies

18
00:00:59,059 --> 00:01:03,820
and we can also make the users of their

19
00:01:00,980 --> 00:01:06,320
so that they can make smarter decisions

20
00:01:03,820 --> 00:01:08,660
so good evening everyone my name is

21
00:01:06,320 --> 00:01:10,910
sunshine oz and Alex actually did a

22
00:01:08,660 --> 00:01:14,420
phenomenal job in pronouncing my bengali

23
00:01:10,910 --> 00:01:16,520
version of it and almost a doctorate in

24
00:01:14,420 --> 00:01:18,590
from Indiana University Bloomington and

25
00:01:16,520 --> 00:01:21,470
my research focuses on the user side of

26
00:01:18,590 --> 00:01:23,869
privacy and security the reason why I

27
00:01:21,470 --> 00:01:26,150
focus on the human factors is because it

28
00:01:23,869 --> 00:01:30,020
is really very critical to build a

29
00:01:26,150 --> 00:01:31,520
digitally safe environment this work has

30
00:01:30,020 --> 00:01:34,908
been done in collaboration with several

31
00:01:31,520 --> 00:01:36,860
people in our lab and we are guided by

32
00:01:34,909 --> 00:01:39,140
dr. Jean Kamp whom we heard earlier and

33
00:01:36,860 --> 00:01:40,580
specially our project manager Joshua

34
00:01:39,140 --> 00:01:43,340
strife whom you will be seeing and

35
00:01:40,580 --> 00:01:45,798
hearing in the demo sessions plan out so

36
00:01:43,340 --> 00:01:48,080
when we talk about risks the basic

37
00:01:45,799 --> 00:01:51,409
concept of it is it is multivariate and

38
00:01:48,080 --> 00:01:54,670
it is it can lie from low to high and it

39
00:01:51,409 --> 00:01:57,320
can be in any field and it is dependent

40
00:01:54,670 --> 00:01:58,189
so when we talk about risks other than

41
00:01:57,320 --> 00:01:59,658
cybersecurity

42
00:01:58,189 --> 00:02:02,960
there are ways which we are developing

43
00:01:59,659 --> 00:02:04,670
to identify and mitigate them but when

44
00:02:02,960 --> 00:02:06,470
it comes to cybersecurity it becomes

45
00:02:04,670 --> 00:02:08,509
specially challenging because there are

46
00:02:06,470 --> 00:02:10,789
several types of invisible risks and it

47
00:02:08,508 --> 00:02:13,518
is all around us it can be in a public

48
00:02:10,789 --> 00:02:15,350
place it can be a small gathering it can

49
00:02:13,519 --> 00:02:18,260
be in a workplace and even in your

50
00:02:15,350 --> 00:02:21,590
child's bedroom isn't it very scary to

51
00:02:18,260 --> 00:02:23,450
think like that but it is true so we do

52
00:02:21,590 --> 00:02:25,400
have tools and risk analysis

53
00:02:23,450 --> 00:02:28,250
technologies where we have processes

54
00:02:25,400 --> 00:02:29,420
strategies to combat against them but

55
00:02:28,250 --> 00:02:31,880
often we

56
00:02:29,420 --> 00:02:34,519
that users are the problem here they are

57
00:02:31,880 --> 00:02:37,459
the weakest link but the question comes

58
00:02:34,520 --> 00:02:39,230
that are we at all giving users the

59
00:02:37,459 --> 00:02:42,110
proper information on the tools to

60
00:02:39,230 --> 00:02:45,109
combat against these attacks so what do

61
00:02:42,110 --> 00:02:47,330
we tell users that internet is a big bad

62
00:02:45,110 --> 00:02:49,850
world you have to protect your devices

63
00:02:47,330 --> 00:02:51,830
you have to protect against phishing and

64
00:02:49,850 --> 00:02:54,680
so on and we complain that they don't

65
00:02:51,830 --> 00:02:57,350
follow these but the question comes that

66
00:02:54,680 --> 00:02:59,900
are there any like top 10 steps we can

67
00:02:57,350 --> 00:03:02,120
do to achieve 100% security there is

68
00:02:59,900 --> 00:03:03,890
none because right now we live in a

69
00:03:02,120 --> 00:03:07,280
world which is highly interconnected

70
00:03:03,890 --> 00:03:09,200
from phone to refrigerator to washing

71
00:03:07,280 --> 00:03:10,610
machine to anything and everything is

72
00:03:09,200 --> 00:03:12,859
connected over the Internet

73
00:03:10,610 --> 00:03:16,880
that means it is susceptible to digital

74
00:03:12,860 --> 00:03:18,560
threats so right now a user is told or

75
00:03:16,880 --> 00:03:19,970
you have to protect your phone you have

76
00:03:18,560 --> 00:03:23,120
to protect your router you have to

77
00:03:19,970 --> 00:03:24,950
protect your cars even your toys which

78
00:03:23,120 --> 00:03:28,100
creates an information overload for the

79
00:03:24,950 --> 00:03:31,040
users so who are at fault here are they

80
00:03:28,100 --> 00:03:33,049
the users researchers tool education

81
00:03:31,040 --> 00:03:35,000
mitigation or actually it is a

82
00:03:33,049 --> 00:03:38,299
combination of all these factors let's

83
00:03:35,000 --> 00:03:40,900
find out so yes our goal is to build

84
00:03:38,299 --> 00:03:42,470
tools which are first usable

85
00:03:40,900 --> 00:03:44,540
privacy-preserving

86
00:03:42,470 --> 00:03:46,940
and it actually gives a security which

87
00:03:44,540 --> 00:03:49,040
we all deserve often usability comes

88
00:03:46,940 --> 00:03:51,530
like a testing factor rather than the

89
00:03:49,040 --> 00:03:53,920
initial analysis of a software or a tool

90
00:03:51,530 --> 00:03:56,540
but that's what we want to change

91
00:03:53,920 --> 00:03:58,700
especially when it comes to the

92
00:03:56,540 --> 00:04:01,340
vulnerable population our children who

93
00:03:58,700 --> 00:04:03,440
probably do not even have the right to

94
00:04:01,340 --> 00:04:06,230
say when when their data is out there

95
00:04:03,440 --> 00:04:07,850
for example somebody gets gives birth

96
00:04:06,230 --> 00:04:10,190
and they are like oh my child was born

97
00:04:07,850 --> 00:04:12,200
at the state and even their weight and

98
00:04:10,190 --> 00:04:14,630
every other details and social media and

99
00:04:12,200 --> 00:04:17,298
they did not even consent about it so we

100
00:04:14,630 --> 00:04:20,358
have to be more cognizant about this

101
00:04:17,298 --> 00:04:23,570
factor so that we can stop users such as

102
00:04:20,358 --> 00:04:26,539
this and I particularly kept the article

103
00:04:23,570 --> 00:04:29,389
which is 2 years old because this keeps

104
00:04:26,539 --> 00:04:32,030
coming up every single year and even

105
00:04:29,389 --> 00:04:35,000
last month when I did a quick search and

106
00:04:32,030 --> 00:04:38,119
we had to stop it so even after years of

107
00:04:35,000 --> 00:04:39,860
the first article was out there in 2015

108
00:04:38,120 --> 00:04:42,620
if I'm not wrong about these particular

109
00:04:39,860 --> 00:04:43,220
toys and still now after like 4 or 5

110
00:04:42,620 --> 00:04:45,800
years

111
00:04:43,220 --> 00:04:47,830
the still going on so we wanted to find

112
00:04:45,800 --> 00:04:51,590
out what exactly is the problem

113
00:04:47,830 --> 00:04:54,320
so first we investigated cloud pets toys

114
00:04:51,590 --> 00:04:56,989
it's a very cute unique on it's like I

115
00:04:54,320 --> 00:04:59,360
have seen and hacked it and it's really

116
00:04:56,990 --> 00:05:01,430
very fun to play around and it is true

117
00:04:59,360 --> 00:05:02,990
that it helps to be in touch with your

118
00:05:01,430 --> 00:05:05,540
grandparents they can talk to you

119
00:05:02,990 --> 00:05:07,910
through audio messages but when you put

120
00:05:05,540 --> 00:05:10,010
on the security lenses what we do find

121
00:05:07,910 --> 00:05:13,130
out it it has bluetooth connectivity and

122
00:05:10,010 --> 00:05:15,830
it has a range of 30 to 50 feet so what

123
00:05:13,130 --> 00:05:18,200
it does give you is a 30 to 50 feet

124
00:05:15,830 --> 00:05:19,669
range for any attacker to know where

125
00:05:18,200 --> 00:05:22,670
what your child is doing and even

126
00:05:19,670 --> 00:05:24,710
interact with it so you might think that

127
00:05:22,670 --> 00:05:26,750
it should have the basic authentication

128
00:05:24,710 --> 00:05:29,239
right now we live in an era of

129
00:05:26,750 --> 00:05:31,460
multi-factor authentication so it should

130
00:05:29,240 --> 00:05:33,740
at least have that but what we found out

131
00:05:31,460 --> 00:05:37,340
is there was not even a single password

132
00:05:33,740 --> 00:05:39,500
access given and when we try to connect

133
00:05:37,340 --> 00:05:41,750
with these toys it's literally shouting

134
00:05:39,500 --> 00:05:44,210
that oh I'm a cloud pet connect with me

135
00:05:41,750 --> 00:05:46,490
it is not even allowing the users to

136
00:05:44,210 --> 00:05:50,599
change the name to any kind of a dummy

137
00:05:46,490 --> 00:05:52,610
variable so here is a demo where we will

138
00:05:50,600 --> 00:05:55,070
show that how from a publicly available

139
00:05:52,610 --> 00:05:59,240
very simple code we could attack these

140
00:05:55,070 --> 00:06:02,870
toys so this is the quad pad you horn

141
00:05:59,240 --> 00:06:05,630
it's a toy designed for parents are

142
00:06:02,870 --> 00:06:07,520
going to be away and you want a method

143
00:06:05,630 --> 00:06:10,969
with which they can speak to the child

144
00:06:07,520 --> 00:06:13,250
and chocolate speak to that it works

145
00:06:10,970 --> 00:06:17,690
that a child when they want to speak to

146
00:06:13,250 --> 00:06:19,250
their parent simply pushes a palm heart

147
00:06:17,690 --> 00:06:25,460
light indicator comes on letting you

148
00:06:19,250 --> 00:06:28,070
know that it's being recorded turns off

149
00:06:25,460 --> 00:06:31,190
and gets sent to a phone the phone sends

150
00:06:28,070 --> 00:06:34,159
it across the cloud out it goes the

151
00:06:31,190 --> 00:06:36,350
other parent gets the message and then

152
00:06:34,160 --> 00:06:40,100
sends a message back comes back to the

153
00:06:36,350 --> 00:06:42,740
toy and the heart will blink saying it

154
00:06:40,100 --> 00:06:45,620
twice here then they push the poem and

155
00:06:42,740 --> 00:06:49,340
the pod delivers a message now the

156
00:06:45,620 --> 00:06:53,300
problem of toy is meant first of all the

157
00:06:49,340 --> 00:06:54,739
toy is constantly broadcasting and sang

158
00:06:53,300 --> 00:06:56,539
that it's a cloud pad

159
00:06:54,740 --> 00:06:58,970
any Bluetooth scanner to pick up

160
00:06:56,539 --> 00:07:03,590
Bluetooth Low Energy has a short range

161
00:06:58,970 --> 00:07:04,910
we said before roughly 30 to 50 feet but

162
00:07:03,590 --> 00:07:06,710
that's enough for me to be able to walk

163
00:07:04,910 --> 00:07:08,870
past a house or drive past house to tell

164
00:07:06,710 --> 00:07:12,068
you which room in the house this toy is

165
00:07:08,870 --> 00:07:18,050
in which is a location threat to child

166
00:07:12,069 --> 00:07:21,139
more so I am able to use a simple set of

167
00:07:18,050 --> 00:07:26,360
Java and go ahead and pair with this

168
00:07:21,139 --> 00:07:28,759
device once I've paired with it it'll

169
00:07:26,360 --> 00:07:31,099
pick up the characteristics and once I

170
00:07:28,759 --> 00:07:32,780
have the characteristics then I can

171
00:07:31,099 --> 00:07:37,219
begin to rewrite those characteristics

172
00:07:32,780 --> 00:07:38,900
in issue commands so as an example I can

173
00:07:37,220 --> 00:07:42,310
turn that heart light on and make it

174
00:07:38,900 --> 00:07:46,008
look like I'm recording when I'm not or

175
00:07:42,310 --> 00:07:47,599
because the message the request to

176
00:07:46,009 --> 00:07:51,409
record and the request for the heart

177
00:07:47,599 --> 00:07:53,419
light to come on are separate I can

178
00:07:51,409 --> 00:07:56,659
simply start recording without turning

179
00:07:53,419 --> 00:08:11,330
the heart light on and thereby mic your

180
00:07:56,659 --> 00:08:14,990
house no that's not the scariest I can

181
00:08:11,330 --> 00:08:16,940
send the audio across to the toy and

182
00:08:14,990 --> 00:08:21,500
once I've sent it across

183
00:08:16,940 --> 00:08:25,550
I can indicate then the message has

184
00:08:21,500 --> 00:08:28,759
arrived from a parent and then when the

185
00:08:25,550 --> 00:08:35,120
child reaches over to play that what do

186
00:08:28,759 --> 00:08:38,510
they get certainly not a message from

187
00:08:35,120 --> 00:08:41,390
the parents now while having it yellow

188
00:08:38,510 --> 00:08:44,149
Dalek item is kind of funny it isn't

189
00:08:41,390 --> 00:08:46,610
funny if the message were hey this is

190
00:08:44,149 --> 00:08:49,070
mommy don't wake up daddy I came home

191
00:08:46,610 --> 00:08:52,010
early just come outside the house at

192
00:08:49,070 --> 00:08:56,300
which point we have a social attack with

193
00:08:52,010 --> 00:08:58,130
a possible child abduction so what we

194
00:08:56,300 --> 00:09:00,500
see here is definitely a security

195
00:08:58,130 --> 00:09:02,720
failure which is happening but it is it

196
00:09:00,500 --> 00:09:05,480
was not the fault of the users was it

197
00:09:02,720 --> 00:09:06,860
what we see here is we are providing

198
00:09:05,480 --> 00:09:09,110
over power

199
00:09:06,860 --> 00:09:11,240
which probably it means but it is

200
00:09:09,110 --> 00:09:13,610
definitely under protected with no form

201
00:09:11,240 --> 00:09:15,980
of authentication done and even if you

202
00:09:13,610 --> 00:09:18,290
pick any other smart toy there is some

203
00:09:15,980 --> 00:09:20,210
form of authentication which you can

204
00:09:18,290 --> 00:09:22,010
enter your password and plaintext so

205
00:09:20,210 --> 00:09:25,250
they are not even following the basic

206
00:09:22,010 --> 00:09:28,069
policies and security out here so we

207
00:09:25,250 --> 00:09:30,350
thought it might be one organization or

208
00:09:28,070 --> 00:09:33,470
one company which is doing so so we

209
00:09:30,350 --> 00:09:35,990
tried something else a reputed brand

210
00:09:33,470 --> 00:09:39,140
name and we are kind of explored this

211
00:09:35,990 --> 00:09:41,570
toy as well so what we find here is it

212
00:09:39,140 --> 00:09:43,010
has more capability now it can

213
00:09:41,570 --> 00:09:45,050
understand when you are hugging the toy

214
00:09:43,010 --> 00:09:48,080
it's the friend you need that means it

215
00:09:45,050 --> 00:09:50,240
can understand how far it is the child

216
00:09:48,080 --> 00:09:53,030
is from the toy it can listen to your

217
00:09:50,240 --> 00:09:55,220
child it can adapt to it it can do video

218
00:09:53,030 --> 00:09:57,589
and audio recording which it is not seen

219
00:09:55,220 --> 00:10:01,430
but will show you how it is done and it

220
00:09:57,590 --> 00:10:03,110
has unlimited Wi-Fi content update so we

221
00:10:01,430 --> 00:10:05,420
may like let's look into its hardware

222
00:10:03,110 --> 00:10:07,640
right so it has dual core processor it

223
00:10:05,420 --> 00:10:10,130
has 2 megapixel camera which is decent

224
00:10:07,640 --> 00:10:12,530
enough to probably not give you a very

225
00:10:10,130 --> 00:10:15,710
high resolution picture but it can

226
00:10:12,530 --> 00:10:19,010
record and we will show you how clear it

227
00:10:15,710 --> 00:10:21,080
is then we looked into its software what

228
00:10:19,010 --> 00:10:24,170
we realize what it is nothing but a

229
00:10:21,080 --> 00:10:27,410
full-blown Android phone or Android

230
00:10:24,170 --> 00:10:29,240
device where you can install any number

231
00:10:27,410 --> 00:10:33,500
of application you want to because it's

232
00:10:29,240 --> 00:10:35,870
32 gigs storage it can how do you record

233
00:10:33,500 --> 00:10:39,650
it can video record it can even live

234
00:10:35,870 --> 00:10:40,880
tweet and that's what we could do so we

235
00:10:39,650 --> 00:10:42,980
will like probably it's a very

236
00:10:40,880 --> 00:10:46,400
sophisticated attack right we are biased

237
00:10:42,980 --> 00:10:48,620
in our own expertise so we went out in

238
00:10:46,400 --> 00:10:50,810
several risk awareness programs and we

239
00:10:48,620 --> 00:10:53,540
give this bears and a little bit of

240
00:10:50,810 --> 00:10:56,119
training to k-12 students and they could

241
00:10:53,540 --> 00:10:58,790
literally hack into this bear in like

242
00:10:56,120 --> 00:11:00,830
half an hour even with no prior security

243
00:10:58,790 --> 00:11:03,949
training and that's what we are building

244
00:11:00,830 --> 00:11:05,750
for our future as you can see there are

245
00:11:03,950 --> 00:11:08,480
basic codes which is running at the

246
00:11:05,750 --> 00:11:10,130
background and you can in your house

247
00:11:08,480 --> 00:11:12,610
very comfortable and you can get

248
00:11:10,130 --> 00:11:12,610
recorded

249
00:11:17,740 --> 00:11:22,190
we could not hear him but he was just

250
00:11:20,210 --> 00:11:32,390
saying that you can go ahead with your

251
00:11:22,190 --> 00:11:34,250
regular life so yeah that's what we are

252
00:11:32,390 --> 00:11:37,160
building for our children nowadays and

253
00:11:34,250 --> 00:11:39,710
as I said we could literary life tweet

254
00:11:37,160 --> 00:11:42,260
this video over Twitter and that's what

255
00:11:39,710 --> 00:11:45,980
can happen if we give this holiday toy

256
00:11:42,260 --> 00:11:48,020
to our kids so again what we see here is

257
00:11:45,980 --> 00:11:50,090
a trend right there are over power

258
00:11:48,020 --> 00:11:52,130
technology and we are not being

259
00:11:50,090 --> 00:11:54,050
responsible about it to again do a

260
00:11:52,130 --> 00:11:56,420
password authentication and you might

261
00:11:54,050 --> 00:11:58,180
feel ok it has happened in 2015 so

262
00:11:56,420 --> 00:12:01,120
probably they have improved over time

263
00:11:58,180 --> 00:12:04,670
but this particular test was done in

264
00:12:01,120 --> 00:12:06,950
2019 so even after four years after the

265
00:12:04,670 --> 00:12:09,620
hack was done we could still find these

266
00:12:06,950 --> 00:12:11,690
vulnerabilities so what we need right

267
00:12:09,620 --> 00:12:13,520
now we have to assess the situation and

268
00:12:11,690 --> 00:12:15,470
yes we are building new tools and

269
00:12:13,520 --> 00:12:17,720
mitigating tools but we are not

270
00:12:15,470 --> 00:12:19,670
improving upon them to understand the

271
00:12:17,720 --> 00:12:21,740
current trend hackers are not stopping

272
00:12:19,670 --> 00:12:24,110
they are building advanced technology

273
00:12:21,740 --> 00:12:26,120
every single minute and we are stopping

274
00:12:24,110 --> 00:12:28,330
once we are done ok this is resolved so

275
00:12:26,120 --> 00:12:31,490
let's go with another production and

276
00:12:28,330 --> 00:12:33,680
what we are lacking again is the user

277
00:12:31,490 --> 00:12:36,320
side we are not following the research

278
00:12:33,680 --> 00:12:38,660
which is out there for the last 25

279
00:12:36,320 --> 00:12:40,310
somewhat years and we are not building

280
00:12:38,660 --> 00:12:42,230
on those we are not understanding the

281
00:12:40,310 --> 00:12:44,479
risk of Airness mental models of our

282
00:12:42,230 --> 00:12:47,240
users who we are targeting and we also

283
00:12:44,480 --> 00:12:49,370
need developers education yes we know

284
00:12:47,240 --> 00:12:51,080
how to build tools and that's why we are

285
00:12:49,370 --> 00:12:53,000
in the technical zone but we have to

286
00:12:51,080 --> 00:12:54,980
also understand the users for whom we

287
00:12:53,000 --> 00:12:57,620
are building and definitely need the

288
00:12:54,980 --> 00:13:00,290
tools to protect us so that's what we

289
00:12:57,620 --> 00:13:01,880
did in our research as well so what we

290
00:13:00,290 --> 00:13:04,790
found out during our assessment is the

291
00:13:01,880 --> 00:13:08,839
first question do people at all care and

292
00:13:04,790 --> 00:13:11,030
we collected reviews from Amazon Morris

293
00:13:08,839 --> 00:13:14,089
off thousand reviews and we found that

294
00:13:11,030 --> 00:13:16,880
only 2% of our parents at all talked

295
00:13:14,089 --> 00:13:19,880
about the security breaches even after

296
00:13:16,880 --> 00:13:21,620
this was highly publicized case things

297
00:13:19,880 --> 00:13:23,689
are a little bit better in Reddit and

298
00:13:21,620 --> 00:13:24,640
probably if I go to other security

299
00:13:23,690 --> 00:13:27,010
focused blog

300
00:13:24,640 --> 00:13:28,720
I will find better results but these are

301
00:13:27,010 --> 00:13:32,080
not the only people who are buying the

302
00:13:28,720 --> 00:13:34,990
toys so as a mitigating solution there

303
00:13:32,080 --> 00:13:37,390
was Amazon who removed and killed off

304
00:13:34,990 --> 00:13:39,460
all of its cloud pets and fisher-price

305
00:13:37,390 --> 00:13:42,880
toys which is a great initiative you

306
00:13:39,460 --> 00:13:45,400
cannot find it there however we often

307
00:13:42,880 --> 00:13:47,680
forget about the second-hand markets now

308
00:13:45,400 --> 00:13:50,530
you can buy anything and everything

309
00:13:47,680 --> 00:13:52,750
which was ever available from eBay even

310
00:13:50,530 --> 00:13:54,370
Facebook marketplace and so on and when

311
00:13:52,750 --> 00:13:56,410
you are buying a secondhand product you

312
00:13:54,370 --> 00:13:58,330
know do not even know from whom you are

313
00:13:56,410 --> 00:14:00,520
buying really so it might be a hacker

314
00:13:58,330 --> 00:14:03,400
posing as somebody who's selling this

315
00:14:00,520 --> 00:14:05,110
item and selling this for your kids so

316
00:14:03,400 --> 00:14:08,290
this is something which I found last

317
00:14:05,110 --> 00:14:10,630
week and as you can see by febri get

318
00:14:08,290 --> 00:14:14,589
this toy even for a higher price than it

319
00:14:10,630 --> 00:14:17,740
actually was coated so we definitely

320
00:14:14,590 --> 00:14:19,960
cannot remove and also cannot protect

321
00:14:17,740 --> 00:14:22,300
the users from just removing these toys

322
00:14:19,960 --> 00:14:26,080
or these tools this will be available

323
00:14:22,300 --> 00:14:28,180
forever maybe so as a mitigation factor

324
00:14:26,080 --> 00:14:30,220
what we can really do is understand the

325
00:14:28,180 --> 00:14:31,989
users understand their mental models and

326
00:14:30,220 --> 00:14:34,660
it's not going to be successful all the

327
00:14:31,990 --> 00:14:36,640
time so what we did was we had this

328
00:14:34,660 --> 00:14:38,740
outreach session and we gathered

329
00:14:36,640 --> 00:14:40,540
information of our participants whether

330
00:14:38,740 --> 00:14:43,750
they are tall look at the privacy and

331
00:14:40,540 --> 00:14:45,250
security features of these tools and the

332
00:14:43,750 --> 00:14:47,410
resins which we got was not very

333
00:14:45,250 --> 00:14:49,840
encouraging nobody thought about these

334
00:14:47,410 --> 00:14:53,170
tools even when we asked about that then

335
00:14:49,840 --> 00:14:54,940
they are like it's just a toy their

336
00:14:53,170 --> 00:14:57,189
grandparents gave it to them so they are

337
00:14:54,940 --> 00:14:58,570
happy we are happy they enjoy we can

338
00:14:57,190 --> 00:15:00,700
talk to them and that's what they all

339
00:14:58,570 --> 00:15:03,160
worried about and I'm just thinking

340
00:15:00,700 --> 00:15:05,050
probably that's what my parents would

341
00:15:03,160 --> 00:15:08,170
have also thought if they had these kind

342
00:15:05,050 --> 00:15:11,290
of toys so what we did was we developed

343
00:15:08,170 --> 00:15:13,479
this beta version of this tool which

344
00:15:11,290 --> 00:15:15,219
gives them details about the threats

345
00:15:13,480 --> 00:15:17,410
which can be possessed in all these

346
00:15:15,220 --> 00:15:19,930
devices they can given the device name

347
00:15:17,410 --> 00:15:22,209
and they can learn about it right again

348
00:15:19,930 --> 00:15:24,819
it's not very greatly designed because

349
00:15:22,210 --> 00:15:26,310
we were testing the users however what

350
00:15:24,820 --> 00:15:28,540
we saw that there was a stark difference

351
00:15:26,310 --> 00:15:30,699
people were getting concerned about the

352
00:15:28,540 --> 00:15:32,770
privacy and security features and they

353
00:15:30,700 --> 00:15:35,410
wanted to learn more about it and that's

354
00:15:32,770 --> 00:15:37,779
what we want we are not getting paid to

355
00:15:35,410 --> 00:15:39,790
like just prohibit these

356
00:15:37,779 --> 00:15:41,850
tools are these technologies what we

357
00:15:39,790 --> 00:15:43,689
want is to give the users the

358
00:15:41,850 --> 00:15:47,649
information so that they can take

359
00:15:43,689 --> 00:15:49,300
informed decisions so then is the

360
00:15:47,649 --> 00:15:51,790
question the simple non technical

361
00:15:49,300 --> 00:15:53,139
education actually works our user

362
00:15:51,790 --> 00:15:55,209
studies at all worthwhile

363
00:15:53,139 --> 00:15:56,740
because you have to like set a team you

364
00:15:55,209 --> 00:15:58,719
have to understand the users there is a

365
00:15:56,740 --> 00:16:01,209
lot of work time and efforts going on

366
00:15:58,720 --> 00:16:04,360
there but I will leave you to these

367
00:16:01,209 --> 00:16:06,609
videos which I'll show that skirt see to

368
00:16:04,360 --> 00:16:07,930
my advice about a cam and you can tell

369
00:16:06,610 --> 00:16:11,100
me whether it can be effective or not

370
00:16:07,930 --> 00:16:11,099
sound please

371
00:16:18,639 --> 00:16:27,340
and it goes for organizations back

372
00:16:23,920 --> 00:16:27,339
[Music]

373
00:16:31,360 --> 00:16:41,100
[Music]

374
00:16:41,670 --> 00:16:47,349
so the question again comes the simple

375
00:16:44,800 --> 00:16:49,329
non technical education or user studies

376
00:16:47,350 --> 00:16:52,870
actually work and you can give me the

377
00:16:49,330 --> 00:16:54,820
answer to that there is also kind of a

378
00:16:52,870 --> 00:16:57,430
hindrance about usability issues right

379
00:16:54,820 --> 00:16:59,740
and we often come across okay we can

380
00:16:57,430 --> 00:17:01,449
probably build the tools and they will

381
00:16:59,740 --> 00:17:03,130
not adopt and that has happened to me

382
00:17:01,450 --> 00:17:05,230
when I was in the industry and that has

383
00:17:03,130 --> 00:17:07,329
happened to me when I am doing user

384
00:17:05,230 --> 00:17:08,710
studies as well but if people do not

385
00:17:07,329 --> 00:17:10,629
care about the risk

386
00:17:08,710 --> 00:17:12,700
why don't we provide incentives and

387
00:17:10,630 --> 00:17:15,310
economics and we have talked about it in

388
00:17:12,700 --> 00:17:17,230
our sessions as well if they do know

389
00:17:15,310 --> 00:17:18,849
about the risk why don't we talk about

390
00:17:17,230 --> 00:17:20,620
do not know about the risk why don't we

391
00:17:18,849 --> 00:17:23,260
talk about risk communication but based

392
00:17:20,619 --> 00:17:25,719
on their mental models for example if

393
00:17:23,260 --> 00:17:27,430
you talk to a child about risk of like

394
00:17:25,720 --> 00:17:28,960
oh it's a hot pan you will tell in a

395
00:17:27,430 --> 00:17:31,270
different way versus if you talk to an

396
00:17:28,960 --> 00:17:33,640
adult about any risk so we have to talk

397
00:17:31,270 --> 00:17:35,410
to the users accordingly as well and if

398
00:17:33,640 --> 00:17:38,110
they know and care probably we have to

399
00:17:35,410 --> 00:17:40,660
revisit our designs why is it always

400
00:17:38,110 --> 00:17:42,580
that usability comes at the end of any

401
00:17:40,660 --> 00:17:45,010
technological development why doesn't it

402
00:17:42,580 --> 00:17:47,080
come from the feasibility analysis and I

403
00:17:45,010 --> 00:17:49,060
have developed this incentivizing risk

404
00:17:47,080 --> 00:17:50,710
reduction based incentivization model

405
00:17:49,060 --> 00:17:52,720
which has been effective to not just

406
00:17:50,710 --> 00:17:54,400
like 20-some what people it has been

407
00:17:52,720 --> 00:17:57,400
effective for an organization which had

408
00:17:54,400 --> 00:18:00,040
more than 90,000 employees so these kind

409
00:17:57,400 --> 00:18:03,610
of methods are definitely effective and

410
00:18:00,040 --> 00:18:05,320
we should work for it however yes the

411
00:18:03,610 --> 00:18:07,030
user size are really cool and I'm a

412
00:18:05,320 --> 00:18:08,770
strong advocate for it but we should

413
00:18:07,030 --> 00:18:11,860
also develop tools

414
00:18:08,770 --> 00:18:15,639
what if actually the hack has happened

415
00:18:11,860 --> 00:18:19,030
now your tool is hacked how should we

416
00:18:15,640 --> 00:18:20,950
communicate it to our users for that we

417
00:18:19,030 --> 00:18:23,379
have developed this network threat

418
00:18:20,950 --> 00:18:25,840
detection tool where this tool kind of

419
00:18:23,380 --> 00:18:28,330
uses it's a very cute security turtle

420
00:18:25,840 --> 00:18:31,659
it's again it's in its nascent stage but

421
00:18:28,330 --> 00:18:33,580
it follows the traffic signal signaling

422
00:18:31,660 --> 00:18:35,380
where it converts from green light to

423
00:18:33,580 --> 00:18:37,840
yellow when somebody is trying to attack

424
00:18:35,380 --> 00:18:40,180
then it converts to red if it is

425
00:18:37,840 --> 00:18:42,580
actually if your toy or any other IOT

426
00:18:40,180 --> 00:18:44,230
device is actually attacked and I would

427
00:18:42,580 --> 00:18:47,679
be happy to talk more about it after

428
00:18:44,230 --> 00:18:49,990
this presentation so again the question

429
00:18:47,680 --> 00:18:51,180
is why such robust research is actually

430
00:18:49,990 --> 00:18:53,160
needed we can just develop the

431
00:18:51,180 --> 00:18:54,570
to Lynette can be out there we can think

432
00:18:53,160 --> 00:18:56,880
about the firewalls we can think about

433
00:18:54,570 --> 00:18:58,500
the networks and everything we probably

434
00:18:56,880 --> 00:19:01,020
we can just provide the authentication

435
00:18:58,500 --> 00:19:03,120
but it is also a fact that there are the

436
00:19:01,020 --> 00:19:04,980
users who are using it and they might be

437
00:19:03,120 --> 00:19:08,040
creating some problems which we have

438
00:19:04,980 --> 00:19:10,590
never thought about and also that toys

439
00:19:08,040 --> 00:19:13,560
are not only the unique tools which are

440
00:19:10,590 --> 00:19:16,169
getting hacked this was another example

441
00:19:13,560 --> 00:19:18,810
a crock-pot where we were able to hack

442
00:19:16,170 --> 00:19:21,210
it and even in our own lab we were able

443
00:19:18,810 --> 00:19:23,070
to manipulate the Lighting's of our

444
00:19:21,210 --> 00:19:26,400
house through this card because it was

445
00:19:23,070 --> 00:19:28,260
connected to the same network and we

446
00:19:26,400 --> 00:19:31,560
cannot avoid it even if you say okay I

447
00:19:28,260 --> 00:19:33,570
don't want to have any IOT device what

448
00:19:31,560 --> 00:19:35,129
about you go to Krugers Kroger's might

449
00:19:33,570 --> 00:19:37,590
not be the one you are going see suppose

450
00:19:35,130 --> 00:19:39,690
Walmart or any other grocery store you

451
00:19:37,590 --> 00:19:42,270
are using their discount coupons you are

452
00:19:39,690 --> 00:19:44,640
using your credit card so as long as you

453
00:19:42,270 --> 00:19:46,500
think that oh I will use cash for every

454
00:19:44,640 --> 00:19:49,200
other thing you cannot be protected from

455
00:19:46,500 --> 00:19:51,090
these kind of threats you might use it

456
00:19:49,200 --> 00:19:53,550
for your credit cards but what if you

457
00:19:51,090 --> 00:19:55,919
are actually using fitbit's or any other

458
00:19:53,550 --> 00:19:58,020
form of connected device in your

459
00:19:55,920 --> 00:20:00,390
everyday life anything which is

460
00:19:58,020 --> 00:20:02,100
connected over Bluetooth Wi-Fi or it is

461
00:20:00,390 --> 00:20:04,260
an interconnected to the big bad

462
00:20:02,100 --> 00:20:06,750
internet world needs protection and we

463
00:20:04,260 --> 00:20:08,970
have to provide the tools accordingly so

464
00:20:06,750 --> 00:20:10,920
I want to again reiterate that we

465
00:20:08,970 --> 00:20:12,960
definitely need the user aspect the

466
00:20:10,920 --> 00:20:15,780
human elements aspect to understand and

467
00:20:12,960 --> 00:20:17,310
create robust security technology and I

468
00:20:15,780 --> 00:20:19,590
would happy to talk more about it

469
00:20:17,310 --> 00:20:21,510
further thank you so much and our paper

470
00:20:19,590 --> 00:20:24,770
is here if you want to learn more about

471
00:20:21,510 --> 00:20:24,770
this research Thanks

472
00:20:26,960 --> 00:20:29,020
you

