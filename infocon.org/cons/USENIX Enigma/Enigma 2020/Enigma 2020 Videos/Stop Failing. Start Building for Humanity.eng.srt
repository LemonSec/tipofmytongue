1
00:00:15,920 --> 00:00:21,480
okay now so I want to talk to you about

2
00:00:18,690 --> 00:00:23,790
building for humans and I'm going to

3
00:00:21,480 --> 00:00:25,619
totally fail Matt's bar for a good

4
00:00:23,790 --> 00:00:28,259
security talk there is no math in here

5
00:00:25,619 --> 00:00:29,790
but we are going to talk about humans we

6
00:00:28,260 --> 00:00:31,380
are gonna go talk about failure and so

7
00:00:29,790 --> 00:00:33,870
we are going to talk about the impacts

8
00:00:31,380 --> 00:00:36,360
of failure on humans so please be aware

9
00:00:33,870 --> 00:00:38,730
that's in here I wanted to start with

10
00:00:36,360 --> 00:00:41,340
some perspective I want to look at what

11
00:00:38,730 --> 00:00:43,800
you and literally every human you know

12
00:00:41,340 --> 00:00:45,870
mean in comparison to the rest of

13
00:00:43,800 --> 00:00:48,510
humanity here you are

14
00:00:45,870 --> 00:00:50,640
notice with this ginormous screen you

15
00:00:48,510 --> 00:00:53,460
don't even fill in a pixel there are

16
00:00:50,640 --> 00:00:55,530
seven point seven billion people in the

17
00:00:53,460 --> 00:00:57,390
world four point four billion of them

18
00:00:55,530 --> 00:00:58,560
are online so if you're building for

19
00:00:57,390 --> 00:01:01,290
yourself and your family and your

20
00:00:58,560 --> 00:01:03,240
friends you are missing just a huge

21
00:01:01,290 --> 00:01:03,960
swath of people and why is that

22
00:01:03,240 --> 00:01:07,799
important

23
00:01:03,960 --> 00:01:09,180
edge cases when I was an undergrad we

24
00:01:07,799 --> 00:01:10,710
didn't think hey if I run a big

25
00:01:09,180 --> 00:01:13,290
computation a bunch of computers are

26
00:01:10,710 --> 00:01:15,240
gonna break in the middle right these

27
00:01:13,290 --> 00:01:17,369
days we plan for that edge cases are

28
00:01:15,240 --> 00:01:19,740
common at large scale and the same thing

29
00:01:17,369 --> 00:01:22,859
is true of humans at the scale Twitter's

30
00:01:19,740 --> 00:01:24,780
at a one-in-a-million chance happens 500

31
00:01:22,859 --> 00:01:27,089
times a day you want a bigger system

32
00:01:24,780 --> 00:01:29,520
with more users if something happens to

33
00:01:27,090 --> 00:01:31,469
one in a million users once a year at

34
00:01:29,520 --> 00:01:34,710
Google that is best expressed as six

35
00:01:31,469 --> 00:01:36,178
times a day you need to expect human

36
00:01:34,710 --> 00:01:37,829
edge cases because they are almost

37
00:01:36,179 --> 00:01:41,399
certainly much more common than you

38
00:01:37,829 --> 00:01:42,658
think and the thing I want you to take

39
00:01:41,399 --> 00:01:45,810
away from this talk more than anything

40
00:01:42,659 --> 00:01:47,429
is respect respect is a positive feeling

41
00:01:45,810 --> 00:01:50,069
or actions shown towards someone or

42
00:01:47,429 --> 00:01:52,590
something consider it important or held

43
00:01:50,069 --> 00:01:54,600
in high esteem or regard and it's also

44
00:01:52,590 --> 00:01:57,270
this process of honoring someone by

45
00:01:54,600 --> 00:01:59,280
exhibiting care concern or consideration

46
00:01:57,270 --> 00:02:00,869
for their needs and feelings I think

47
00:01:59,280 --> 00:02:03,719
this is what we need to be building into

48
00:02:00,869 --> 00:02:04,549
technology because every human deserves

49
00:02:03,719 --> 00:02:07,229
respect

50
00:02:04,549 --> 00:02:09,000
failure matters because it affects

51
00:02:07,229 --> 00:02:11,910
humans your system has no meaning

52
00:02:09,000 --> 00:02:13,980
outside of humans so I want to talk

53
00:02:11,910 --> 00:02:15,600
about the intellectual challenges of

54
00:02:13,980 --> 00:02:17,040
doing this kind of work some of the

55
00:02:15,600 --> 00:02:18,829
emotional challenges of doing this kind

56
00:02:17,040 --> 00:02:22,609
of work and then some of the

57
00:02:18,830 --> 00:02:25,170
organizational and company challenges

58
00:02:22,610 --> 00:02:27,030
when you build for Humanity you need to

59
00:02:25,170 --> 00:02:28,619
understand and build for the people who

60
00:02:27,030 --> 00:02:29,670
are affected by your system not just

61
00:02:28,620 --> 00:02:31,010
your users

62
00:02:29,670 --> 00:02:33,690
your users are easiest to identify

63
00:02:31,010 --> 00:02:36,179
because they're the ones talking to you

64
00:02:33,690 --> 00:02:38,910
but there are lots of other people

65
00:02:36,180 --> 00:02:42,540
Equifax sadly gave us a really good

66
00:02:38,910 --> 00:02:45,000
example of this because their users are

67
00:02:42,540 --> 00:02:47,310
financial institutions but they sell

68
00:02:45,000 --> 00:02:49,380
your information my information lots of

69
00:02:47,310 --> 00:02:52,020
people's information and when the

70
00:02:49,380 --> 00:02:54,120
hackers broke in and breached 150

71
00:02:52,020 --> 00:02:56,310
million people's information those

72
00:02:54,120 --> 00:02:59,360
people were affected by that system and

73
00:02:56,310 --> 00:03:02,250
if you work on a big influential product

74
00:02:59,360 --> 00:03:03,450
even more people are affected and those

75
00:03:02,250 --> 00:03:05,400
effects can be mixed they can be

76
00:03:03,450 --> 00:03:08,130
positive or negative or different

77
00:03:05,400 --> 00:03:10,980
effects in different places for example

78
00:03:08,130 --> 00:03:12,810
ride-sharing apps have decreased drunk

79
00:03:10,980 --> 00:03:15,238
driving in some places but they have

80
00:03:12,810 --> 00:03:18,870
other effects on accessibility labor

81
00:03:15,239 --> 00:03:20,880
markets things like that so why is this

82
00:03:18,870 --> 00:03:22,950
intellectually challenging turns out

83
00:03:20,880 --> 00:03:26,430
humans are way more complex than systems

84
00:03:22,950 --> 00:03:27,869
if you want to say use PGP I don't want

85
00:03:26,430 --> 00:03:29,850
to dunk on you PGP but it has a

86
00:03:27,870 --> 00:03:32,819
usability curve like a brick wall right

87
00:03:29,850 --> 00:03:36,180
if you want to get your career key

88
00:03:32,819 --> 00:03:39,149
signed you have to follow this 34 step

89
00:03:36,180 --> 00:03:41,250
long set of directions which is really

90
00:03:39,150 --> 00:03:44,400
complicated it's complicated to me I

91
00:03:41,250 --> 00:03:47,100
literally have a PhD in cryptography and

92
00:03:44,400 --> 00:03:49,590
it's complicated if you want to build a

93
00:03:47,100 --> 00:03:51,780
secure cryptographic protocol that is

94
00:03:49,590 --> 00:03:53,790
really hard but if you want to build one

95
00:03:51,780 --> 00:03:56,640
that can actually be used it turns out

96
00:03:53,790 --> 00:03:58,140
it's a lot harder part of the reason why

97
00:03:56,640 --> 00:04:00,420
it's hard is that different humans have

98
00:03:58,140 --> 00:04:02,670
contradictory needs and desires for

99
00:04:00,420 --> 00:04:04,200
example a bunch of people should not be

100
00:04:02,670 --> 00:04:05,399
sharing their real-time location with

101
00:04:04,200 --> 00:04:07,950
their spouse because their spouse is

102
00:04:05,400 --> 00:04:10,500
abusive and is a physical problem but

103
00:04:07,950 --> 00:04:12,450
there's other sets of people who need to

104
00:04:10,500 --> 00:04:13,859
share for physical safety reasons my

105
00:04:12,450 --> 00:04:16,858
husband shares his with me when he goes

106
00:04:13,859 --> 00:04:18,359
on long bike rides people who are

107
00:04:16,858 --> 00:04:19,918
walking home through dangerous

108
00:04:18,358 --> 00:04:22,979
neighborhoods might want to have a

109
00:04:19,918 --> 00:04:24,510
friend virtually follow along in order

110
00:04:22,979 --> 00:04:26,190
to understand this we have to do threat

111
00:04:24,510 --> 00:04:28,500
modeling all the way from humans and the

112
00:04:26,190 --> 00:04:31,289
societies they build all the way down to

113
00:04:28,500 --> 00:04:33,900
the hardware so when I do that I think

114
00:04:31,289 --> 00:04:36,570
about three things I think about targets

115
00:04:33,900 --> 00:04:38,219
and I think about all of my affected

116
00:04:36,570 --> 00:04:39,690
parties and I think about different

117
00:04:38,220 --> 00:04:41,070
sorts of life circumstances that will

118
00:04:39,690 --> 00:04:43,290
make them vulnerable in different ways

119
00:04:41,070 --> 00:04:45,810
for example they might be an invisible

120
00:04:43,290 --> 00:04:47,640
like an lgbtq+ person they might be

121
00:04:45,810 --> 00:04:49,440
experiencing a disability like limited

122
00:04:47,640 --> 00:04:53,039
sight hearing or fine motor control or

123
00:04:49,440 --> 00:04:55,320
dis or poverty or abuse right one in

124
00:04:53,040 --> 00:04:56,700
four women and one in nine men in the US

125
00:04:55,320 --> 00:05:01,740
I don't have figures for other genders

126
00:04:56,700 --> 00:05:03,120
in the u.s. experienced extreme domestic

127
00:05:01,740 --> 00:05:05,700
violence over the course of their

128
00:05:03,120 --> 00:05:07,380
lifetime these people are your users

129
00:05:05,700 --> 00:05:09,750
they are affected by your systems you

130
00:05:07,380 --> 00:05:12,750
just don't know who they are or somebody

131
00:05:09,750 --> 00:05:14,730
with the secret I live my life pretty

132
00:05:12,750 --> 00:05:16,650
openly but when I started having a

133
00:05:14,730 --> 00:05:18,360
miscarriage at work I did not want to

134
00:05:16,650 --> 00:05:20,940
have that conversation with my coworkers

135
00:05:18,360 --> 00:05:24,870
I suddenly had a secret even though I

136
00:05:20,940 --> 00:05:26,670
had not planned to have one then I move

137
00:05:24,870 --> 00:05:28,020
on to thinking about attackers and I

138
00:05:26,670 --> 00:05:30,030
like to think about attackers by

139
00:05:28,020 --> 00:05:31,500
thinking about what they want do they

140
00:05:30,030 --> 00:05:33,750
have a commercial objective they want to

141
00:05:31,500 --> 00:05:35,490
sell something a criminal objective they

142
00:05:33,750 --> 00:05:37,560
want to commit fraud or another crime a

143
00:05:35,490 --> 00:05:38,070
political objective they want to change

144
00:05:37,560 --> 00:05:40,290
the world

145
00:05:38,070 --> 00:05:42,570
a malicious objective where they want to

146
00:05:40,290 --> 00:05:45,210
hurt someone or a group of people maybe

147
00:05:42,570 --> 00:05:47,130
they just like chaos and attackers come

148
00:05:45,210 --> 00:05:48,030
with bonus features that make them even

149
00:05:47,130 --> 00:05:50,159
more dangerous

150
00:05:48,030 --> 00:05:51,750
so think about insider attackers they

151
00:05:50,160 --> 00:05:52,860
have privileged access to the inside of

152
00:05:51,750 --> 00:05:56,070
your system usually because they're an

153
00:05:52,860 --> 00:05:57,750
employee like Twitter had an engineer

154
00:05:56,070 --> 00:05:59,750
suborn by the Saudi government who

155
00:05:57,750 --> 00:06:02,370
exfiltrated data on their targets

156
00:05:59,750 --> 00:06:03,960
intimate attackers people like an

157
00:06:02,370 --> 00:06:05,820
untrustworthy roommate who have

158
00:06:03,960 --> 00:06:08,430
privileged access to your personal life

159
00:06:05,820 --> 00:06:11,550
a power figure somebody has power over

160
00:06:08,430 --> 00:06:13,530
you like maybe your employer and then

161
00:06:11,550 --> 00:06:15,660
you can mash up a bunch of features like

162
00:06:13,530 --> 00:06:18,000
this to make a attacker profiles which

163
00:06:15,660 --> 00:06:20,520
are particularly relevant to your system

164
00:06:18,000 --> 00:06:22,920
so for example advanced intimate

165
00:06:20,520 --> 00:06:24,450
persistent threat up to 40% of law

166
00:06:22,920 --> 00:06:26,670
enforcement officers commit domestic

167
00:06:24,450 --> 00:06:28,469
violence at some point and the targets

168
00:06:26,670 --> 00:06:30,540
of that domestic violence tend to have

169
00:06:28,470 --> 00:06:33,090
less recourse because the perpetrator

170
00:06:30,540 --> 00:06:35,700
has more access to the courts and to

171
00:06:33,090 --> 00:06:37,890
information right that's a good threat

172
00:06:35,700 --> 00:06:39,840
model think about suppressing political

173
00:06:37,890 --> 00:06:41,430
dissidents in an untargeted way in the

174
00:06:39,840 --> 00:06:44,010
wake of a coup the Turkish government

175
00:06:41,430 --> 00:06:46,380
decided hey you know what we're gonna do

176
00:06:44,010 --> 00:06:49,349
we're gonna arrest everyone who uses a

177
00:06:46,380 --> 00:06:51,320
particular chat app and the people who

178
00:06:49,350 --> 00:06:53,070
use the chat app and the dissidents I

179
00:06:51,320 --> 00:06:54,570
mean they overlapped

180
00:06:53,070 --> 00:06:57,370
but they were not the same group right

181
00:06:54,570 --> 00:06:58,900
also they arrested

182
00:06:57,370 --> 00:07:00,490
thousand people who didn't even have the

183
00:06:58,900 --> 00:07:03,400
chat up because they got confused but

184
00:07:00,490 --> 00:07:05,229
that was fifty thousand people you don't

185
00:07:03,400 --> 00:07:06,460
assume that your attackers and

186
00:07:05,229 --> 00:07:09,190
necessarily thought things through all

187
00:07:06,460 --> 00:07:12,580
the way and then you want to look at the

188
00:07:09,190 --> 00:07:14,350
system look at how the pieces of the

189
00:07:12,580 --> 00:07:16,510
system connect how information flows

190
00:07:14,350 --> 00:07:17,919
what happens if this fails what happens

191
00:07:16,510 --> 00:07:19,000
if this fails what happens that they

192
00:07:17,919 --> 00:07:21,729
both fail at once

193
00:07:19,000 --> 00:07:23,229
and then you want to look at the pieces

194
00:07:21,729 --> 00:07:25,419
of the system which are particularly

195
00:07:23,229 --> 00:07:28,060
important for respectful operation so

196
00:07:25,419 --> 00:07:29,919
for example information sharing I don't

197
00:07:28,060 --> 00:07:31,930
know every place a user can share

198
00:07:29,919 --> 00:07:33,400
information with another user do they

199
00:07:31,930 --> 00:07:36,280
understand what's going on how do they

200
00:07:33,400 --> 00:07:38,260
make it stop does it actually stop when

201
00:07:36,280 --> 00:07:40,270
they tell you to also you want to look

202
00:07:38,260 --> 00:07:41,860
at things like automated decision-making

203
00:07:40,270 --> 00:07:43,448
what are your false positives and false

204
00:07:41,860 --> 00:07:44,710
negatives and everything from your

205
00:07:43,449 --> 00:07:46,840
recommendation algorithms to an

206
00:07:44,710 --> 00:07:50,979
autopilot what happens if it's working

207
00:07:46,840 --> 00:07:54,190
correctly so people have thought an

208
00:07:50,979 --> 00:07:56,110
awful lot hey Facebook is targeting ads

209
00:07:54,190 --> 00:07:57,880
by listening to me through my phone and

210
00:07:56,110 --> 00:07:59,199
people have done a bunch of app tear

211
00:07:57,880 --> 00:08:01,080
downs on the Facebook app so we don't

212
00:07:59,199 --> 00:08:03,070
think that's what's happening but it is

213
00:08:01,080 --> 00:08:04,770
fascinating that we are still having

214
00:08:03,070 --> 00:08:07,210
this conversation after years and years

215
00:08:04,770 --> 00:08:10,750
that tells you that there's a difference

216
00:08:07,210 --> 00:08:12,669
between correct and right right the ad

217
00:08:10,750 --> 00:08:15,389
system is spitting out something which

218
00:08:12,669 --> 00:08:17,830
is very much correctly related to you

219
00:08:15,389 --> 00:08:21,160
creepily so right but it doesn't mean

220
00:08:17,830 --> 00:08:22,330
it's a good product experience look at

221
00:08:21,160 --> 00:08:23,889
the places where you have two systems

222
00:08:22,330 --> 00:08:25,479
meet people tend to look at systems in

223
00:08:23,889 --> 00:08:26,889
isolation and say oh this one works

224
00:08:25,479 --> 00:08:28,389
this one works and then you put them

225
00:08:26,889 --> 00:08:31,690
together and something bad happens in

226
00:08:28,389 --> 00:08:33,490
the middle so then you take all of those

227
00:08:31,690 --> 00:08:35,740
things and you mash them up and you

228
00:08:33,490 --> 00:08:38,380
create yourself some really high octane

229
00:08:35,740 --> 00:08:41,110
nightmare fuel right all of this stuff

230
00:08:38,380 --> 00:08:44,439
is ever changing its ever developing it

231
00:08:41,110 --> 00:08:46,450
will never ever be boring so I want to

232
00:08:44,440 --> 00:08:47,589
talk about the emotional challenges as

233
00:08:46,450 --> 00:08:51,279
well because we don't talk about this

234
00:08:47,589 --> 00:08:52,959
part enough why is doing this kind of

235
00:08:51,279 --> 00:08:54,760
work emotionally challenging well for

236
00:08:52,959 --> 00:08:57,010
one people are gonna yell at you if

237
00:08:54,760 --> 00:08:58,930
they're not happy as they formal Global

238
00:08:57,010 --> 00:09:00,819
lead for privacy technology at Google I

239
00:08:58,930 --> 00:09:05,069
promise you people will tell you when

240
00:09:00,820 --> 00:09:07,180
they're unhappy and it's really

241
00:09:05,070 --> 00:09:08,950
important that you listen to them if

242
00:09:07,180 --> 00:09:10,810
you're trying to build a system for them

243
00:09:08,950 --> 00:09:12,910
they may not be right about what the

244
00:09:10,810 --> 00:09:14,619
system does they may not be right about

245
00:09:12,910 --> 00:09:16,420
how it's affecting them but they are

246
00:09:14,620 --> 00:09:18,310
telling you that it is on making them

247
00:09:16,420 --> 00:09:20,800
unhappy and that's really important for

248
00:09:18,310 --> 00:09:22,510
you to hear also there's a lot of

249
00:09:20,800 --> 00:09:25,000
ambiguity there are no clear right

250
00:09:22,510 --> 00:09:27,520
answers in this space and to make good

251
00:09:25,000 --> 00:09:31,000
choices you have to understand how real

252
00:09:27,520 --> 00:09:32,410
people are being really hurt and it

253
00:09:31,000 --> 00:09:34,330
turns out that that's even harder when

254
00:09:32,410 --> 00:09:36,579
you consider the future it's much less

255
00:09:34,330 --> 00:09:38,050
predictable than the present back in the

256
00:09:36,580 --> 00:09:40,660
90s we had this thing called the white

257
00:09:38,050 --> 00:09:42,160
pages and in there is a big book that

258
00:09:40,660 --> 00:09:44,380
they handed out to everybody that had

259
00:09:42,160 --> 00:09:45,969
people's names and addresses and phone

260
00:09:44,380 --> 00:09:48,160
numbers and there was this really big

261
00:09:45,970 --> 00:09:50,500
threat model in the day which was bad

262
00:09:48,160 --> 00:09:52,270
pizza that somebody would call up and

263
00:09:50,500 --> 00:09:54,160
have terrible pizza delivered to your

264
00:09:52,270 --> 00:09:55,810
house and the pizza guy was gonna be

265
00:09:54,160 --> 00:09:58,260
super pissed that you didn't want to pay

266
00:09:55,810 --> 00:10:00,640
for it that was your big threat model

267
00:09:58,260 --> 00:10:02,770
nowadays one of your bigger threat

268
00:10:00,640 --> 00:10:04,270
models is called swatting and swatting

269
00:10:02,770 --> 00:10:07,480
is where somebody calls up the police

270
00:10:04,270 --> 00:10:09,670
and says hello please leah is currently

271
00:10:07,480 --> 00:10:11,589
murdering me right now in our house and

272
00:10:09,670 --> 00:10:14,099
you should show up to her house with

273
00:10:11,589 --> 00:10:15,250
many guns and the police get

274
00:10:14,100 --> 00:10:17,560
unsurprisingly

275
00:10:15,250 --> 00:10:19,270
kind of excited about this and they come

276
00:10:17,560 --> 00:10:20,500
over to my house with many many guns and

277
00:10:19,270 --> 00:10:22,750
when you have excited people with many

278
00:10:20,500 --> 00:10:25,000
many guns this is very dangerous people

279
00:10:22,750 --> 00:10:28,630
have been shot people have been killed

280
00:10:25,000 --> 00:10:30,820
by the actual police in real life and if

281
00:10:28,630 --> 00:10:34,330
you're uncomfortable right now I want

282
00:10:30,820 --> 00:10:37,330
you to sit with that feeling because

283
00:10:34,330 --> 00:10:40,600
here's the thing it's really easy to

284
00:10:37,330 --> 00:10:42,580
look away but to order to make good

285
00:10:40,600 --> 00:10:45,910
choices you have to understand the

286
00:10:42,580 --> 00:10:47,800
impact and if you turn away or you

287
00:10:45,910 --> 00:10:49,630
choose not to make those choices it

288
00:10:47,800 --> 00:10:51,729
doesn't make that the choices don't get

289
00:10:49,630 --> 00:10:53,950
made it means that the choices don't get

290
00:10:51,730 --> 00:10:57,100
made by somebody who cares by somebody

291
00:10:53,950 --> 00:10:58,360
who understands somebody will still make

292
00:10:57,100 --> 00:11:01,870
those choices but they won't be

293
00:10:58,360 --> 00:11:03,790
necessarily as good and there's

294
00:11:01,870 --> 00:11:06,730
something in our community that I think

295
00:11:03,790 --> 00:11:08,770
is a real problem in doing this sort of

296
00:11:06,730 --> 00:11:10,690
work which is that we prize purity and

297
00:11:08,770 --> 00:11:14,439
if we're gonna work with humans this is

298
00:11:10,690 --> 00:11:16,270
really really messy we prep prizes too

299
00:11:14,440 --> 00:11:18,880
with clean lines and maximum protection

300
00:11:16,270 --> 00:11:20,710
the only correct way to send a message

301
00:11:18,880 --> 00:11:22,780
is end-to-end encrypted through

302
00:11:20,710 --> 00:11:27,400
artisanal mix nets with keys signed by

303
00:11:22,780 --> 00:11:28,930
Edward Snowden but the pure choices we

304
00:11:27,400 --> 00:11:31,540
make them in our systems they may not

305
00:11:28,930 --> 00:11:33,819
serve our users we're trying to support

306
00:11:31,540 --> 00:11:35,439
people we want journalists to be doing

307
00:11:33,820 --> 00:11:36,520
their work we want human rights workers

308
00:11:35,440 --> 00:11:39,610
to be doing their work we want to

309
00:11:36,520 --> 00:11:41,079
parents and teachers and everybody to be

310
00:11:39,610 --> 00:11:42,970
able to do their work and they turns out

311
00:11:41,080 --> 00:11:44,380
they have they have work to do they have

312
00:11:42,970 --> 00:11:47,620
lives they have families they don't have

313
00:11:44,380 --> 00:11:49,689
time but also that encrypted computation

314
00:11:47,620 --> 00:11:52,690
I just mentioned would stand out like a

315
00:11:49,690 --> 00:11:54,190
beacon to oppressive governments when we

316
00:11:52,690 --> 00:11:58,330
make certain kinds of pure system

317
00:11:54,190 --> 00:12:01,420
choices they may not serve people so now

318
00:11:58,330 --> 00:12:03,900
I want to talk about some of the company

319
00:12:01,420 --> 00:12:06,280
challenges the organizational challenges

320
00:12:03,900 --> 00:12:08,439
what happens if your company is the one

321
00:12:06,280 --> 00:12:09,939
getting in the way and sometimes there

322
00:12:08,440 --> 00:12:11,470
are legitimate constraints if I had an

323
00:12:09,940 --> 00:12:13,150
infinite amount of money let me tell you

324
00:12:11,470 --> 00:12:15,160
I would be doing more user research than

325
00:12:13,150 --> 00:12:19,360
I am doing right now given that I work

326
00:12:15,160 --> 00:12:20,890
in a start-up but sometimes also the

327
00:12:19,360 --> 00:12:23,170
right answer is don't build that system

328
00:12:20,890 --> 00:12:25,990
but a lot of times that isn't we have

329
00:12:23,170 --> 00:12:27,969
managed to spread so much art and

330
00:12:25,990 --> 00:12:29,640
knowledge and science and culture that

331
00:12:27,970 --> 00:12:32,890
we just would not have access to

332
00:12:29,640 --> 00:12:34,420
otherwise my children can talk to their

333
00:12:32,890 --> 00:12:36,340
sick grandparents in another country

334
00:12:34,420 --> 00:12:38,199
right we have built a lot of things that

335
00:12:36,340 --> 00:12:39,790
are good and when we build something we

336
00:12:38,200 --> 00:12:42,310
take risks and when we don't build

337
00:12:39,790 --> 00:12:44,230
something we also take risks but

338
00:12:42,310 --> 00:12:45,489
sometimes legitimately your company is

339
00:12:44,230 --> 00:12:49,660
getting in the way of you doing

340
00:12:45,490 --> 00:12:52,660
respectful work I want to declare my

341
00:12:49,660 --> 00:12:55,089
bias here I think that in the long term

342
00:12:52,660 --> 00:12:58,959
building respectful systems is going to

343
00:12:55,090 --> 00:13:00,640
win because power governs so much of how

344
00:12:58,960 --> 00:13:03,640
humans interact with each other right

345
00:13:00,640 --> 00:13:06,189
and people are going to seek to level

346
00:13:03,640 --> 00:13:08,110
out structural inequality we can see

347
00:13:06,190 --> 00:13:11,140
this over and over and over again in

348
00:13:08,110 --> 00:13:13,960
human societies medieval carnival second

349
00:13:11,140 --> 00:13:16,630
sacrifices of the King and the same

350
00:13:13,960 --> 00:13:19,510
thing holds for companies that drive for

351
00:13:16,630 --> 00:13:22,300
reciprocity I can touch you you can

352
00:13:19,510 --> 00:13:24,130
touch me back is part of the push to

353
00:13:22,300 --> 00:13:25,780
regulate the tech industry and as

354
00:13:24,130 --> 00:13:27,180
engineers it can be really confusing

355
00:13:25,780 --> 00:13:28,589
somebody proposes

356
00:13:27,180 --> 00:13:30,599
regulation you're like well you send you

357
00:13:28,590 --> 00:13:31,800
one of this thing but it doesn't it

358
00:13:30,600 --> 00:13:36,390
looks like it's gonna do this an other

359
00:13:31,800 --> 00:13:39,000
thing entirely but all of these pieces

360
00:13:36,390 --> 00:13:43,080
of regulation they serve this drive

361
00:13:39,000 --> 00:13:44,940
towards reciprocity so I think respect

362
00:13:43,080 --> 00:13:46,470
is gonna win if you want to build

363
00:13:44,940 --> 00:13:47,550
respectful systems and you don't feel

364
00:13:46,470 --> 00:13:51,150
like you're doing enough of that already

365
00:13:47,550 --> 00:13:52,819
how do you make that happen the first

366
00:13:51,150 --> 00:13:56,340
thing you can do is help your company

367
00:13:52,820 --> 00:13:58,950
understand and prioritize respect tie

368
00:13:56,340 --> 00:14:01,020
what you're suggesting to doing to what

369
00:13:58,950 --> 00:14:03,360
an executive ones the executive probably

370
00:14:01,020 --> 00:14:04,980
wants happy users the executive probably

371
00:14:03,360 --> 00:14:07,050
wants to govern governments and

372
00:14:04,980 --> 00:14:10,230
regulators not to yell at them or shut

373
00:14:07,050 --> 00:14:12,359
them down if possible quantify what

374
00:14:10,230 --> 00:14:13,950
you're doing so I worked with a team who

375
00:14:12,360 --> 00:14:16,170
it was building a new product to replace

376
00:14:13,950 --> 00:14:18,360
an old product and when they launched

377
00:14:16,170 --> 00:14:20,939
this product to create a claim we looked

378
00:14:18,360 --> 00:14:22,860
at the user feedback the user feedback

379
00:14:20,940 --> 00:14:24,630
for the new product had the privacy

380
00:14:22,860 --> 00:14:26,790
complaint to drop through the floor and

381
00:14:24,630 --> 00:14:28,800
we could quantify that we can use that

382
00:14:26,790 --> 00:14:32,699
to argue forum doing more work of that

383
00:14:28,800 --> 00:14:35,430
sort in the future but you know it's a

384
00:14:32,700 --> 00:14:38,430
messy world and we can't quantify a huge

385
00:14:35,430 --> 00:14:40,650
amount of what we do so you can be

386
00:14:38,430 --> 00:14:42,479
demonstrably right you are demonstrably

387
00:14:40,650 --> 00:14:45,720
low right you will be trusted in the

388
00:14:42,480 --> 00:14:47,250
future so for example I worked with the

389
00:14:45,720 --> 00:14:49,560
team and they wanted to launch a feature

390
00:14:47,250 --> 00:14:52,080
and I said I have spidey sense right now

391
00:14:49,560 --> 00:14:53,729
and I don't think this is going to go

392
00:14:52,080 --> 00:14:56,160
well and they said well if you don't

393
00:14:53,730 --> 00:14:58,290
know what's gonna go rel probably I'll

394
00:14:56,160 --> 00:15:00,180
be fine and you won't we've and then

395
00:14:58,290 --> 00:15:02,370
they went ahead and launched it and TLDR

396
00:15:00,180 --> 00:15:05,880
we ended up serving porn on a clothing

397
00:15:02,370 --> 00:15:08,130
manufacturers website and let me tell

398
00:15:05,880 --> 00:15:10,560
you the next time I went to those VPS

399
00:15:08,130 --> 00:15:13,080
and said I have spidey sense they were

400
00:15:10,560 --> 00:15:16,109
like no we are not launching whatever

401
00:15:13,080 --> 00:15:19,950
you say not to launch right I was

402
00:15:16,110 --> 00:15:23,340
demonstrably right a number of times and

403
00:15:19,950 --> 00:15:25,590
they said okay we are going to trust

404
00:15:23,340 --> 00:15:26,970
your judgment now another thing that's

405
00:15:25,590 --> 00:15:28,770
really useful is remembering that how

406
00:15:26,970 --> 00:15:31,350
you eat an elephant is one bite at a

407
00:15:28,770 --> 00:15:33,030
time in a big company you usually can't

408
00:15:31,350 --> 00:15:36,240
change everything at once even if you

409
00:15:33,030 --> 00:15:37,920
are the CEO so make something better

410
00:15:36,240 --> 00:15:38,520
make a couple things better work with

411
00:15:37,920 --> 00:15:42,420
some

412
00:15:38,520 --> 00:15:43,829
and then you will get cheerleaders VP

413
00:15:42,420 --> 00:15:45,479
cheerleaders are super helpful

414
00:15:43,830 --> 00:15:48,089
all those VPS I talked about working

415
00:15:45,480 --> 00:15:49,290
with they were like oh yeah I want to

416
00:15:48,089 --> 00:15:50,550
build a good system it has to be

417
00:15:49,290 --> 00:15:52,140
respectful and then they went and told

418
00:15:50,550 --> 00:15:53,790
all their VP buddies about it and it was

419
00:15:52,140 --> 00:15:58,050
super super helpful when rolling that

420
00:15:53,790 --> 00:16:00,750
out further the second option here is to

421
00:15:58,050 --> 00:16:01,920
use your flexibility to design and build

422
00:16:00,750 --> 00:16:05,250
better where you are

423
00:16:01,920 --> 00:16:06,329
think about respect in small ways what

424
00:16:05,250 --> 00:16:07,890
happens if somebody's going to be

425
00:16:06,330 --> 00:16:09,480
unhappy about this recommendation I'm

426
00:16:07,890 --> 00:16:11,520
putting in front of them how should we

427
00:16:09,480 --> 00:16:13,709
build the system for that or you think

428
00:16:11,520 --> 00:16:15,300
about it in bigger ways how do we redo

429
00:16:13,709 --> 00:16:17,910
our monetization model so that we need

430
00:16:15,300 --> 00:16:19,370
less data how can I make this real-time

431
00:16:17,910 --> 00:16:21,300
location sharing feature work

432
00:16:19,370 --> 00:16:22,800
respectfully in a world that includes

433
00:16:21,300 --> 00:16:24,990
intimate partner abuse and stalking

434
00:16:22,800 --> 00:16:27,060
right the team that did that at Google

435
00:16:24,990 --> 00:16:28,560
it was the one feature team they said

436
00:16:27,060 --> 00:16:33,510
this is important and they worked on it

437
00:16:28,560 --> 00:16:34,859
and they made something really great the

438
00:16:33,510 --> 00:16:38,130
third option is that you can vote with

439
00:16:34,860 --> 00:16:40,680
your feet you can choose to use your

440
00:16:38,130 --> 00:16:41,970
skills to build respectful tech and I

441
00:16:40,680 --> 00:16:44,609
want to make really sure here that you

442
00:16:41,970 --> 00:16:46,320
understand what I'm saying being asked

443
00:16:44,610 --> 00:16:48,000
to make hard choices is not the same

444
00:16:46,320 --> 00:16:50,520
thing as not being able to make good

445
00:16:48,000 --> 00:16:52,560
choices in a world that has humans and

446
00:16:50,520 --> 00:16:54,660
old there is always going to be hard

447
00:16:52,560 --> 00:16:56,010
choices there is not one human good and

448
00:16:54,660 --> 00:16:58,529
they trade off against each other in

449
00:16:56,010 --> 00:17:00,630
unpredictable ways security privacy

450
00:16:58,529 --> 00:17:03,270
privacy for different sorts of people

451
00:17:00,630 --> 00:17:05,270
anti abuse availability there's so many

452
00:17:03,270 --> 00:17:07,770
many many things and they all trade off

453
00:17:05,270 --> 00:17:11,189
but I want to recognize that most of us

454
00:17:07,770 --> 00:17:13,260
have choices we are in demand we have a

455
00:17:11,189 --> 00:17:16,140
lot of privilege and we can choose to

456
00:17:13,260 --> 00:17:18,809
route to work on respectful systems you

457
00:17:16,140 --> 00:17:22,470
can change products if you want you can

458
00:17:18,809 --> 00:17:24,270
change your job and here's the thing it

459
00:17:22,470 --> 00:17:25,860
can be good for you to do that if you

460
00:17:24,270 --> 00:17:27,869
feel like you're trapped in where you

461
00:17:25,859 --> 00:17:30,059
are because you can look yourself in the

462
00:17:27,869 --> 00:17:31,830
eye in the mirror in the morning but

463
00:17:30,059 --> 00:17:35,280
here's the other thing it is good for

464
00:17:31,830 --> 00:17:37,980
the ecosystem if we as a field choose to

465
00:17:35,280 --> 00:17:39,149
work on respectful systems that sends a

466
00:17:37,980 --> 00:17:40,559
real message and the reason why is

467
00:17:39,150 --> 00:17:42,390
because if you were on a company the

468
00:17:40,559 --> 00:17:44,010
thing you have to pay attention to more

469
00:17:42,390 --> 00:17:49,820
than anything else is hiring and

470
00:17:44,010 --> 00:17:51,840
retention and so if you are building a

471
00:17:49,820 --> 00:17:53,970
respectful system and that becomes a

472
00:17:51,840 --> 00:17:55,918
competitive advantage that means boards

473
00:17:53,970 --> 00:17:57,780
and VCS will put a lot of pressure on

474
00:17:55,919 --> 00:18:00,360
companies to go and move in that

475
00:17:57,780 --> 00:18:02,428
direction and at humo we've made

476
00:18:00,360 --> 00:18:08,100
building with respect a hiring front

477
00:18:02,429 --> 00:18:10,410
part of our hiring process so I want you

478
00:18:08,100 --> 00:18:12,840
to build for humans it is not pure it is

479
00:18:10,410 --> 00:18:14,790
really messy but it is all of our

480
00:18:12,840 --> 00:18:16,830
responsibility including every one of

481
00:18:14,790 --> 00:18:18,870
you here you can learn how

482
00:18:16,830 --> 00:18:20,309
intellectually think about real-world

483
00:18:18,870 --> 00:18:23,909
threats and ameliorations they will

484
00:18:20,309 --> 00:18:26,220
never be boring it's always changing and

485
00:18:23,910 --> 00:18:28,320
you can learn the emotional part learn

486
00:18:26,220 --> 00:18:30,600
how to make decisions in the presence of

487
00:18:28,320 --> 00:18:31,889
feelings of uncertainty and discomfort

488
00:18:30,600 --> 00:18:35,550
it doesn't mean you're doing a bad job

489
00:18:31,890 --> 00:18:37,260
it means that it's hard and you can make

490
00:18:35,550 --> 00:18:39,000
these choices even if your company is

491
00:18:37,260 --> 00:18:41,429
hindering you you can help them

492
00:18:39,000 --> 00:18:43,830
understand and prioritize respect you

493
00:18:41,429 --> 00:18:47,750
can build better where you are and if

494
00:18:43,830 --> 00:18:47,750
you need to you can vote with your feet

495
00:18:47,990 --> 00:18:53,079
thank you

496
00:18:49,930 --> 00:18:53,079
[Applause]

