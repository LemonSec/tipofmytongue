1
00:00:10,970 --> 00:00:15,799
besides third-party libraries and

2
00:00:13,130 --> 00:00:17,840
third-party integrations ask any

3
00:00:15,799 --> 00:00:21,230
developer what other resources they use

4
00:00:17,840 --> 00:00:23,930
for work it's a pretty safe bad that

5
00:00:21,230 --> 00:00:26,480
Stack Overflow will feature even

6
00:00:23,930 --> 00:00:29,570
security experts we use this Q&A site

7
00:00:26,480 --> 00:00:31,340
that relies on community moderation to

8
00:00:29,570 --> 00:00:35,210
promote the best answer and weed out

9
00:00:31,340 --> 00:00:37,400
unhelpful programming advice a couple of

10
00:00:35,210 --> 00:00:40,210
years ago my I was still an undergrad

11
00:00:37,400 --> 00:00:43,480
yet my former supervisor needed advice

12
00:00:40,210 --> 00:00:45,800
he was programming an Android app and

13
00:00:43,480 --> 00:00:48,410
wanted to protect the privacy of its

14
00:00:45,800 --> 00:00:50,269
users but he couldn't figure out how to

15
00:00:48,410 --> 00:00:54,890
add a specific security feature that

16
00:00:50,270 --> 00:00:57,320
would do this and he was an expert so it

17
00:00:54,890 --> 00:00:58,820
clearly wasn't his fault as well it was

18
00:00:57,320 --> 00:01:02,629
the fall of the tool the framework he

19
00:00:58,820 --> 00:01:04,280
was using so if he couldn't do this how

20
00:01:02,629 --> 00:01:06,470
on earth would layman developers in

21
00:01:04,280 --> 00:01:10,310
security youn stand a chance to get it

22
00:01:06,470 --> 00:01:12,320
right when you realized he was stuck he

23
00:01:10,310 --> 00:01:14,149
did what most developers would do he

24
00:01:12,320 --> 00:01:16,369
googled the air Lennon on Stack Overflow

25
00:01:14,149 --> 00:01:20,000
and found a working solution to his

26
00:01:16,369 --> 00:01:22,429
exact problem within seconds looking at

27
00:01:20,000 --> 00:01:24,080
the websites view counter he realized he

28
00:01:22,429 --> 00:01:27,380
was not the only one with this

29
00:01:24,080 --> 00:01:29,270
particular error hundreds of thousands

30
00:01:27,380 --> 00:01:32,990
of people have had the very same problem

31
00:01:29,270 --> 00:01:34,429
so first the good news is led to vibrant

32
00:01:32,990 --> 00:01:36,740
discussions online a whole bunch of

33
00:01:34,429 --> 00:01:42,739
posts each of them with a long list of

34
00:01:36,740 --> 00:01:44,568
suggested answers to pick from and the

35
00:01:42,739 --> 00:01:47,420
website's indicators would ensure you

36
00:01:44,569 --> 00:01:49,759
would quickly spot the top answer so

37
00:01:47,420 --> 00:01:51,950
most of the time those answers come as a

38
00:01:49,759 --> 00:01:53,989
code snippet and that makes it

39
00:01:51,950 --> 00:01:56,119
incredibly easy to just copy that code

40
00:01:53,989 --> 00:01:59,420
straight into your software and think no

41
00:01:56,119 --> 00:02:01,819
more of it so that's a great user

42
00:01:59,420 --> 00:02:04,970
experience especially for developers

43
00:02:01,819 --> 00:02:07,000
with deadlines so what could possibly go

44
00:02:04,970 --> 00:02:07,000
wrong

45
00:02:07,330 --> 00:02:12,280
most people would be happy getting

46
00:02:10,098 --> 00:02:14,629
another coding problem out of the way

47
00:02:12,280 --> 00:02:16,610
however my supervisor recognized

48
00:02:14,629 --> 00:02:20,090
something that presumably hundreds of

49
00:02:16,610 --> 00:02:22,400
thousands of ordinary users couldn't the

50
00:02:20,090 --> 00:02:24,240
code example marked is the best answer

51
00:02:22,400 --> 00:02:27,300
and viewed by millions and

52
00:02:24,240 --> 00:02:29,910
a very severe unknown vulnerability and

53
00:02:27,300 --> 00:02:33,540
that vulnerability was very easy to

54
00:02:29,910 --> 00:02:36,870
exploit so all of a sudden a research

55
00:02:33,540 --> 00:02:38,940
group got really excited so how could

56
00:02:36,870 --> 00:02:41,580
this be exploited would it allow them to

57
00:02:38,940 --> 00:02:42,990
break into real-world applications what

58
00:02:41,580 --> 00:02:46,470
kind of data could be stolen and what

59
00:02:42,990 --> 00:02:48,390
kind of services could be compromised in

60
00:02:46,470 --> 00:02:50,790
a lab experiment the code snippet found

61
00:02:48,390 --> 00:02:53,190
on Stack Overflow ultimately allowed a

62
00:02:50,790 --> 00:02:55,620
research group to break into to capture

63
00:02:53,190 --> 00:02:59,520
credentials for American Express PayPal

64
00:02:55,620 --> 00:03:03,570
Facebook Twitter etc from Android apps

65
00:02:59,520 --> 00:03:05,370
with with over 200 million users so for

66
00:03:03,570 --> 00:03:07,410
some apps it was even possible to

67
00:03:05,370 --> 00:03:09,770
remotely inject an execute code for

68
00:03:07,410 --> 00:03:12,359
instance to delete data and apps and

69
00:03:09,770 --> 00:03:14,370
prior talks my supervisor happily

70
00:03:12,360 --> 00:03:16,050
demonstrated how they made a very

71
00:03:14,370 --> 00:03:19,290
popular antivirus that have delete

72
00:03:16,050 --> 00:03:23,250
itself from the users device so that's

73
00:03:19,290 --> 00:03:25,019
what possibly could have gone wrong so

74
00:03:23,250 --> 00:03:28,170
we were pretty sure that this was not a

75
00:03:25,020 --> 00:03:30,840
solitary case we were curious of how

76
00:03:28,170 --> 00:03:32,670
much of the advice on Stack Overflow was

77
00:03:30,840 --> 00:03:35,220
actually faulty and could really to

78
00:03:32,670 --> 00:03:39,269
could lead to full abilities if we used

79
00:03:35,220 --> 00:03:41,490
in the wild so we systematically

80
00:03:39,270 --> 00:03:44,100
collected more than 10,000 code examples

81
00:03:41,490 --> 00:03:47,130
from Stack Overflow and over a million

82
00:03:44,100 --> 00:03:48,720
Android apps from Google Play we

83
00:03:47,130 --> 00:03:50,490
developed technology that would allow us

84
00:03:48,720 --> 00:03:53,760
to measure the flow of insecure advice

85
00:03:50,490 --> 00:03:56,910
from Q&A sites into an app market just

86
00:03:53,760 --> 00:03:59,429
like a group play the results were not

87
00:03:56,910 --> 00:04:01,549
great so back haut creating

88
00:03:59,430 --> 00:04:05,190
vulnerabilities in apps was everywhere

89
00:04:01,550 --> 00:04:08,000
over a third of the code snippets given

90
00:04:05,190 --> 00:04:11,100
on Stack Overflow were insecure and

91
00:04:08,000 --> 00:04:14,310
those code examples were replicated

92
00:04:11,100 --> 00:04:19,350
without any changes and almost 200,000

93
00:04:14,310 --> 00:04:20,570
Google Play apps 97% of apps that reuse

94
00:04:19,350 --> 00:04:24,270
code from Stack Overflow

95
00:04:20,570 --> 00:04:26,400
applied insecure code among those high

96
00:04:24,270 --> 00:04:28,740
profile apps with an install base of

97
00:04:26,400 --> 00:04:30,810
over five billion users and it has some

98
00:04:28,740 --> 00:04:33,660
very significant sensitive categories

99
00:04:30,810 --> 00:04:35,669
like finance business health and social

100
00:04:33,660 --> 00:04:38,409
media

101
00:04:35,669 --> 00:04:40,769
so after we published our results we saw

102
00:04:38,409 --> 00:04:44,259
a vast amount of follow-up publications

103
00:04:40,769 --> 00:04:46,179
they represent that this problem

104
00:04:44,259 --> 00:04:48,219
occurred existed across programming

105
00:04:46,179 --> 00:04:51,698
languages and for a wide range of

106
00:04:48,219 --> 00:04:53,979
vulnerabilities buffer overflows SQL

107
00:04:51,699 --> 00:04:57,279
injections everything an attacker would

108
00:04:53,979 --> 00:04:59,639
imagine in their wildest dreams on top

109
00:04:57,279 --> 00:05:01,569
of that insecure advice was even over

110
00:04:59,639 --> 00:05:04,089
overflowing from one open-source

111
00:05:01,569 --> 00:05:07,889
community to another for instance from

112
00:05:04,089 --> 00:05:11,739
github to Stack Overflow and vice-versa

113
00:05:07,889 --> 00:05:14,109
on the other side we also identified a

114
00:05:11,739 --> 00:05:17,078
large amount of helpful advice that

115
00:05:14,109 --> 00:05:20,829
applied security best practices actually

116
00:05:17,079 --> 00:05:24,159
70% of code examples so there was even

117
00:05:20,829 --> 00:05:26,169
more good advice than bad advice and for

118
00:05:24,159 --> 00:05:27,969
each instance of bad advice there was

119
00:05:26,169 --> 00:05:28,709
also a good advice available on Stack

120
00:05:27,969 --> 00:05:31,509
Overflow

121
00:05:28,709 --> 00:05:36,369
however only 6% of Google Play apps

122
00:05:31,509 --> 00:05:38,439
reused those code examples so we wonder

123
00:05:36,369 --> 00:05:40,869
why was bad advice ending up in

124
00:05:38,439 --> 00:05:45,610
production code so often and good advice

125
00:05:40,869 --> 00:05:47,199
wasn't it simply didn't make sense so we

126
00:05:45,610 --> 00:05:49,389
took a closer look at these really

127
00:05:47,199 --> 00:05:51,579
nightmarish unsecure code suggestions

128
00:05:49,389 --> 00:05:53,619
those were a perfect example of Murphy's

129
00:05:51,579 --> 00:05:56,499
Law everything that could have gone

130
00:05:53,619 --> 00:05:58,649
wrong did go wrong they solved a very

131
00:05:56,499 --> 00:06:01,659
popular problem so there was high demand

132
00:05:58,649 --> 00:06:04,539
they had a highest community given score

133
00:06:01,659 --> 00:06:06,308
and they were even promoted to as the

134
00:06:04,539 --> 00:06:10,748
top answer coming with a green checkmark

135
00:06:06,309 --> 00:06:12,879
next to it so usually each of these

136
00:06:10,749 --> 00:06:14,169
mechanisms effectively nudged the best

137
00:06:12,879 --> 00:06:16,749
advice to the forefront of the

138
00:06:14,169 --> 00:06:18,758
conversation those are the incentives

139
00:06:16,749 --> 00:06:23,349
that motivate users to contribute and

140
00:06:18,759 --> 00:06:24,669
evaluate open source content so the the

141
00:06:23,349 --> 00:06:26,919
more the community accepts their

142
00:06:24,669 --> 00:06:28,869
suggestions and the more you rate and

143
00:06:26,919 --> 00:06:31,359
check the community the higher your

144
00:06:28,869 --> 00:06:33,779
reputation score the higher your

145
00:06:31,359 --> 00:06:36,339
reputation the more permissions you get

146
00:06:33,779 --> 00:06:39,849
ultimately leading to more influence and

147
00:06:36,339 --> 00:06:42,369
power on the community so Stack Overflow

148
00:06:39,849 --> 00:06:45,128
is pretty much driven by indicators and

149
00:06:42,369 --> 00:06:46,599
our hypothesis was that those were

150
00:06:45,129 --> 00:06:49,090
simply pointing in the wrong direction

151
00:06:46,599 --> 00:06:51,378
security-wise

152
00:06:49,090 --> 00:06:53,719
that give us an explanation why all of

153
00:06:51,379 --> 00:06:55,249
this has happened so we did some

154
00:06:53,719 --> 00:06:58,039
analysis and started with the most

155
00:06:55,249 --> 00:06:59,719
obvious thing to check the score it's

156
00:06:58,039 --> 00:07:01,938
the sum of people's up votes and down

157
00:06:59,719 --> 00:07:03,979
votes and shows what answer the

158
00:07:01,939 --> 00:07:05,860
community finds particularly helpful to

159
00:07:03,979 --> 00:07:08,479
the problem at hand

160
00:07:05,860 --> 00:07:10,990
well the communities seem to really have

161
00:07:08,479 --> 00:07:13,460
a thing for insecure posts unfortunately

162
00:07:10,990 --> 00:07:15,080
those posts who receive significantly

163
00:07:13,460 --> 00:07:19,099
more love from the community than

164
00:07:15,080 --> 00:07:21,198
security best practices the bad advice

165
00:07:19,099 --> 00:07:24,229
was even rewarded with a green checkmark

166
00:07:21,199 --> 00:07:26,389
a lot of the time not great that's what

167
00:07:24,229 --> 00:07:29,590
presented to you first that's where you

168
00:07:26,389 --> 00:07:32,029
look at first as a Stack Overflow user

169
00:07:29,590 --> 00:07:33,770
many users also try to trick the

170
00:07:32,029 --> 00:07:36,050
reputation system by duplicating

171
00:07:33,770 --> 00:07:39,139
accepted and popular answers across

172
00:07:36,050 --> 00:07:43,550
discussion threads to earn additional

173
00:07:39,139 --> 00:07:45,529
reputation points for free that's a

174
00:07:43,550 --> 00:07:48,680
dangerous multiplier if those posts are

175
00:07:45,529 --> 00:07:50,689
insecure and indeed we found out that

176
00:07:48,680 --> 00:07:55,219
insecure code had significantly more

177
00:07:50,689 --> 00:07:57,979
duplicates finally we had a look at the

178
00:07:55,219 --> 00:07:59,539
folks posting this stuff after my

179
00:07:57,979 --> 00:08:02,060
conference talks people have asked me

180
00:07:59,539 --> 00:08:05,089
whether we found any evidence that users

181
00:08:02,060 --> 00:08:06,800
did this on purpose in that you know

182
00:08:05,089 --> 00:08:09,050
it'd be kind of a cool attack you know

183
00:08:06,800 --> 00:08:11,300
just to just spread your buggy code on

184
00:08:09,050 --> 00:08:14,240
Stack Overflow and wait for someone to

185
00:08:11,300 --> 00:08:17,120
copy and paste it or think of a very

186
00:08:14,240 --> 00:08:19,009
powerful attacker or a nation-state that

187
00:08:17,120 --> 00:08:22,210
might be interested in distributing we

188
00:08:19,009 --> 00:08:24,710
cryptography on a massive scale

189
00:08:22,210 --> 00:08:27,609
however we we couldn't find any evidence

190
00:08:24,710 --> 00:08:30,409
and we think that it's rather unlikely

191
00:08:27,610 --> 00:08:32,390
but what we found was that over a third

192
00:08:30,409 --> 00:08:34,279
of the so-called highly trusted users

193
00:08:32,390 --> 00:08:39,380
users with a particularly high

194
00:08:34,279 --> 00:08:41,390
reputation score posted insecure code so

195
00:08:39,380 --> 00:08:43,760
all the very meaningful indicators on

196
00:08:41,390 --> 00:08:49,490
Stack Overflow were indeed pointing in

197
00:08:43,760 --> 00:08:53,380
the wrong direction so what now the

198
00:08:49,490 --> 00:08:55,790
solution is very simple right just don't

199
00:08:53,380 --> 00:08:58,850
don't use Stack Overflow that's

200
00:08:55,790 --> 00:09:00,709
dangerous that's the good old

201
00:08:58,850 --> 00:09:01,860
paternalistic security advice we just

202
00:09:00,709 --> 00:09:04,300
know too well

203
00:09:01,860 --> 00:09:06,009
we developed this amazing authentication

204
00:09:04,300 --> 00:09:09,279
method for you but you'll not allow to

205
00:09:06,009 --> 00:09:10,899
use simple passwords we developed this

206
00:09:09,279 --> 00:09:12,879
great framework that allows you to

207
00:09:10,899 --> 00:09:15,310
create apps but you're not allowed to

208
00:09:12,879 --> 00:09:17,670
use this incredibly helpful resource to

209
00:09:15,310 --> 00:09:20,529
figure out how to do that

210
00:09:17,670 --> 00:09:21,479
security is hard so you better learn it

211
00:09:20,529 --> 00:09:23,620
the hard way

212
00:09:21,480 --> 00:09:26,199
read a book stick to the official

213
00:09:23,620 --> 00:09:28,449
documentation download this additional

214
00:09:26,199 --> 00:09:31,779
tool you've probably never heard of to

215
00:09:28,449 --> 00:09:34,029
check your code and get it right solely

216
00:09:31,779 --> 00:09:36,100
so let's see how that works let's see

217
00:09:34,029 --> 00:09:37,749
what happens if you force developers

218
00:09:36,100 --> 00:09:41,559
into using alternatives to Stack

219
00:09:37,749 --> 00:09:43,269
Overflow well it's the very same thing

220
00:09:41,559 --> 00:09:46,480
we observed with end users and passwords

221
00:09:43,269 --> 00:09:49,899
they are less usable and force them into

222
00:09:46,480 --> 00:09:51,309
unsafe workarounds in other words they

223
00:09:49,899 --> 00:09:55,149
end up coach hopping on Stack Overflow

224
00:09:51,309 --> 00:09:56,769
once again a very surprising and

225
00:09:55,149 --> 00:09:59,889
disappointing example of this were

226
00:09:56,769 --> 00:10:01,779
simplified cryptographic api's those

227
00:09:59,889 --> 00:10:04,149
api's were specifically designed for

228
00:10:01,779 --> 00:10:07,839
non-experts with a goal to give them

229
00:10:04,149 --> 00:10:09,910
less options to fail they were testify

230
00:10:07,839 --> 00:10:12,879
experts and compared with standard API s

231
00:10:09,910 --> 00:10:16,000
and were actually found to perform the

232
00:10:12,879 --> 00:10:18,490
worst they didn't even like light that

233
00:10:16,000 --> 00:10:20,680
it even make life easier for developers

234
00:10:18,490 --> 00:10:23,290
as they were forced to look up the

235
00:10:20,680 --> 00:10:26,410
source code of the API to figure out how

236
00:10:23,290 --> 00:10:27,759
to use it and that's the complete

237
00:10:26,410 --> 00:10:30,370
opposite of what you want to achieve

238
00:10:27,759 --> 00:10:32,410
with an interface so those tools were

239
00:10:30,370 --> 00:10:34,779
oversimplified and only useful for a

240
00:10:32,410 --> 00:10:38,019
small rate use a small range of use

241
00:10:34,779 --> 00:10:41,189
cases that's why people quickly turn to

242
00:10:38,019 --> 00:10:44,620
the WEP again to look full eternities

243
00:10:41,189 --> 00:10:47,319
tools need to be useful for a wide range

244
00:10:44,620 --> 00:10:49,149
of use cases and the discussions on

245
00:10:47,319 --> 00:10:52,889
Stack Overflow will give you a pretty

246
00:10:49,149 --> 00:10:52,889
good impression of what those are so

247
00:10:53,279 --> 00:10:59,559
developers are users too they use the

248
00:10:56,889 --> 00:11:01,120
security tools we build for them and it

249
00:10:59,559 --> 00:11:03,579
seems to be as much of an impossible

250
00:11:01,120 --> 00:11:05,379
problem to alter their behavior and

251
00:11:03,579 --> 00:11:10,000
require them to change their incentives

252
00:11:05,379 --> 00:11:11,730
as it was for password users never

253
00:11:10,000 --> 00:11:14,199
underestimate the power of inertia

254
00:11:11,730 --> 00:11:16,060
that's a famous quote of Richard Thaler

255
00:11:14,199 --> 00:11:18,990
who came up with nudge

256
00:11:16,060 --> 00:11:21,609
and went on to win the Nobel Prize

257
00:11:18,990 --> 00:11:25,900
altering people's behavior to help them

258
00:11:21,610 --> 00:11:27,370
make better decisions is very hard it's

259
00:11:25,900 --> 00:11:30,069
not only security experts that have

260
00:11:27,370 --> 00:11:32,650
struggled with us how can you make

261
00:11:30,070 --> 00:11:35,260
people live a healthier life how can you

262
00:11:32,650 --> 00:11:37,090
make people pay their bills on time how

263
00:11:35,260 --> 00:11:40,270
can you make people work more

264
00:11:37,090 --> 00:11:42,630
effectively so those are some of the big

265
00:11:40,270 --> 00:11:45,850
questions behavior science try to solve

266
00:11:42,630 --> 00:11:48,280
and you can decide for yourself whether

267
00:11:45,850 --> 00:11:50,260
this has been accomplished so but

268
00:11:48,280 --> 00:11:52,510
Richard Thaler didn't just throw up his

269
00:11:50,260 --> 00:11:55,660
hands at this problem the quote

270
00:11:52,510 --> 00:11:57,569
continues that power can actually be

271
00:11:55,660 --> 00:12:00,459
harnessed

272
00:11:57,570 --> 00:12:02,440
so nudge theory tries to guide people

273
00:12:00,460 --> 00:12:04,120
towards better decisions without

274
00:12:02,440 --> 00:12:05,650
restricting their options or requiring

275
00:12:04,120 --> 00:12:08,560
them to change their incentives

276
00:12:05,650 --> 00:12:09,910
significantly based on behavioral

277
00:12:08,560 --> 00:12:12,250
science people are steered into a

278
00:12:09,910 --> 00:12:13,350
particular direction but preserve the

279
00:12:12,250 --> 00:12:16,030
freedom of choice

280
00:12:13,350 --> 00:12:18,070
so this proach has been shown to be very

281
00:12:16,030 --> 00:12:22,589
effective and is already applied all

282
00:12:18,070 --> 00:12:24,940
over the world translated to our problem

283
00:12:22,590 --> 00:12:27,010
developers can be nudged towards better

284
00:12:24,940 --> 00:12:29,650
security decisions without having their

285
00:12:27,010 --> 00:12:31,540
options restricted so they must be

286
00:12:29,650 --> 00:12:34,150
allowed to use resources like Stack

287
00:12:31,540 --> 00:12:38,709
Overflow and they don't need to change

288
00:12:34,150 --> 00:12:43,209
the way they use it so the intervention

289
00:12:38,710 --> 00:12:44,770
must be easy to avoid and cheap for

290
00:12:43,210 --> 00:12:47,230
instance putting fruit on a level in the

291
00:12:44,770 --> 00:12:50,260
store counts as a nudge banning junk

292
00:12:47,230 --> 00:12:52,510
food completely does not so we won't ban

293
00:12:50,260 --> 00:12:55,990
Stack Overflow but make it easier for

294
00:12:52,510 --> 00:12:57,910
developers to stay on a safe path we do

295
00:12:55,990 --> 00:13:00,130
all the hard security work we read all

296
00:12:57,910 --> 00:13:03,040
the books we develop and apply the

297
00:13:00,130 --> 00:13:05,290
security tools to the chief flat this

298
00:13:03,040 --> 00:13:09,670
way we harness observed behavior to help

299
00:13:05,290 --> 00:13:12,400
developers make better decisions so how

300
00:13:09,670 --> 00:13:14,650
did we do that we started off with the

301
00:13:12,400 --> 00:13:16,660
so called simplification nudge a classic

302
00:13:14,650 --> 00:13:18,010
nudge from the literature that promotes

303
00:13:16,660 --> 00:13:20,140
building your approach and already

304
00:13:18,010 --> 00:13:23,290
existing well established and widely

305
00:13:20,140 --> 00:13:25,090
used resources it's the easiest way to

306
00:13:23,290 --> 00:13:28,420
reach the majority of people as quickly

307
00:13:25,090 --> 00:13:29,930
as possible so we implemented this nudge

308
00:13:28,420 --> 00:13:32,510
by moving security advice

309
00:13:29,930 --> 00:13:34,370
to stackoverflow since everyone is

310
00:13:32,510 --> 00:13:36,800
looking at this platform we believe it

311
00:13:34,370 --> 00:13:40,070
could create could he create immediately

312
00:13:36,800 --> 00:13:43,550
awareness for the security issues across

313
00:13:40,070 --> 00:13:44,990
all languages and platforms and by using

314
00:13:43,550 --> 00:13:47,540
the treasure trove of stochastic

315
00:13:44,990 --> 00:13:49,550
Overflow discussions on offer you can

316
00:13:47,540 --> 00:13:51,620
learn the secure the security advice for

317
00:13:49,550 --> 00:13:54,800
the real-world problems most developers

318
00:13:51,620 --> 00:13:56,089
are struggling with this way you can

319
00:13:54,800 --> 00:13:58,760
make sure that you won't miss the

320
00:13:56,089 --> 00:14:02,270
popular use cases where help is

321
00:13:58,760 --> 00:14:05,450
desperately needed secondly we wanted to

322
00:14:02,270 --> 00:14:08,779
increase the convenience of the desired

323
00:14:05,450 --> 00:14:10,310
behavior reusing code examples from

324
00:14:08,779 --> 00:14:13,790
Stack Overflow is pretty much as

325
00:14:10,310 --> 00:14:15,649
convenient as it gets by designing a new

326
00:14:13,790 --> 00:14:18,079
choice architecture that steers people

327
00:14:15,649 --> 00:14:21,050
towards secure code we can keep this

328
00:14:18,080 --> 00:14:23,690
convenience so we developed a nudge

329
00:14:21,050 --> 00:14:25,399
system based on deep learning that knows

330
00:14:23,690 --> 00:14:29,120
what suggested code examples are about

331
00:14:25,399 --> 00:14:30,770
and whether they're insecure or not this

332
00:14:29,120 --> 00:14:32,870
allows us to perform different matches

333
00:14:30,770 --> 00:14:36,319
on a website itself for instance

334
00:14:32,870 --> 00:14:38,300
offering safety falls the default Lodge

335
00:14:36,320 --> 00:14:40,520
is one of the most effective matches

336
00:14:38,300 --> 00:14:43,939
from the literature it simply shows the

337
00:14:40,520 --> 00:14:46,279
best option first or nudge system

338
00:14:43,940 --> 00:14:48,800
Arirang search results for user queries

339
00:14:46,279 --> 00:14:51,080
such that the most helpful and secure

340
00:14:48,800 --> 00:14:55,540
advice comes first an insecure advice

341
00:14:51,080 --> 00:14:55,540
remains out of sight and below the fold

342
00:14:55,570 --> 00:15:00,500
additionally we warned about insecure

343
00:14:58,100 --> 00:15:02,330
advice within the discussion threats but

344
00:15:00,500 --> 00:15:05,240
always offer a way out of the warning

345
00:15:02,330 --> 00:15:06,890
situation so the natural system

346
00:15:05,240 --> 00:15:09,560
automatically looks up and recommend

347
00:15:06,890 --> 00:15:12,560
safe alternatives on Stack Overflow that

348
00:15:09,560 --> 00:15:13,550
practically do the same thing by

349
00:15:12,560 --> 00:15:15,920
following one of these recommendations

350
00:15:13,550 --> 00:15:20,959
the user gets a very similar but secure

351
00:15:15,920 --> 00:15:22,579
code example to reuse however since one

352
00:15:20,959 --> 00:15:25,189
cigarette warnings and recommendations

353
00:15:22,579 --> 00:15:28,160
are new UI users might still ignore them

354
00:15:25,190 --> 00:15:29,750
and care in cases where they might again

355
00:15:28,160 --> 00:15:31,699
the reuse insecure code we trigger a

356
00:15:29,750 --> 00:15:33,440
reminder nudge that's supposed to draw

357
00:15:31,700 --> 00:15:37,700
the users attention to the warnings and

358
00:15:33,440 --> 00:15:39,640
recommendations so we integrated all of

359
00:15:37,700 --> 00:15:42,990
these notches on Stack Overflow and

360
00:15:39,640 --> 00:15:44,670
tested them in a developer study

361
00:15:42,990 --> 00:15:47,310
we mainly needed to test two simple

362
00:15:44,670 --> 00:15:49,560
hypotheses first nudge developers

363
00:15:47,310 --> 00:15:51,869
achieve the same very same high level of

364
00:15:49,560 --> 00:15:54,959
productivity as they achieved with

365
00:15:51,870 --> 00:15:57,540
original stackoverflow and second

366
00:15:54,959 --> 00:16:00,630
nudging helps in reusing secure instead

367
00:15:57,540 --> 00:16:02,490
of insecure code so we divided

368
00:16:00,630 --> 00:16:04,529
participants into two groups and both

369
00:16:02,490 --> 00:16:07,560
had to solve several programming tasks

370
00:16:04,529 --> 00:16:11,370
that we caught acquire application of

371
00:16:07,560 --> 00:16:13,649
cryptographic api's by both groups were

372
00:16:11,370 --> 00:16:15,720
allowed to use Stack Overflow only one

373
00:16:13,649 --> 00:16:19,170
of the groups received the natural the

374
00:16:15,720 --> 00:16:21,420
other one was all control and since both

375
00:16:19,170 --> 00:16:25,500
groups had the same time constraints we

376
00:16:21,420 --> 00:16:27,449
were able to measure productivity so

377
00:16:25,500 --> 00:16:29,730
both groups created apps that function

378
00:16:27,450 --> 00:16:31,500
well and statistical testing revealed

379
00:16:29,730 --> 00:16:33,660
that there was no significant difference

380
00:16:31,500 --> 00:16:36,149
in functional correctness between the

381
00:16:33,660 --> 00:16:38,339
groups so it doesn't matter whether you

382
00:16:36,149 --> 00:16:40,020
were notched or not functional

383
00:16:38,339 --> 00:16:44,240
correctness will stay more or less the

384
00:16:40,020 --> 00:16:46,949
same so but what about security

385
00:16:44,240 --> 00:16:48,810
here we found statistical significance

386
00:16:46,950 --> 00:16:50,459
match developers significantly

387
00:16:48,810 --> 00:16:53,270
outperformed the control group in

388
00:16:50,459 --> 00:16:55,260
submitting secure solutions

389
00:16:53,270 --> 00:16:56,939
interestingly this effect was

390
00:16:55,260 --> 00:16:58,939
particularly strong for the problem with

391
00:16:56,940 --> 00:17:02,940
my supervisor discovered a few years ago

392
00:16:58,940 --> 00:17:06,209
so 66% of the control group delivered

393
00:17:02,940 --> 00:17:10,250
Warrnambool code 77% of notch

394
00:17:06,209 --> 00:17:13,050
participants achieved secure solutions

395
00:17:10,250 --> 00:17:15,089
so in summary our nudging interventions

396
00:17:13,050 --> 00:17:17,010
did not harm productivity but

397
00:17:15,089 --> 00:17:19,980
significantly increased code security

398
00:17:17,010 --> 00:17:22,309
and that was that's what we want to do a

399
00:17:19,980 --> 00:17:22,309
chief

400
00:17:23,179 --> 00:17:28,110
so to mean nuch theory seems like an

401
00:17:26,099 --> 00:17:29,730
interesting path to follow in usable

402
00:17:28,109 --> 00:17:31,709
security and privacy research I'm

403
00:17:29,730 --> 00:17:35,220
curious and excited to see whether the

404
00:17:31,710 --> 00:17:37,890
community will pursue it further what I

405
00:17:35,220 --> 00:17:39,059
particularly like about it is that the

406
00:17:37,890 --> 00:17:42,300
way it dramatically shifts

407
00:17:39,059 --> 00:17:44,250
responsibilities away from developers

408
00:17:42,300 --> 00:17:48,899
that may be laymen and security towards

409
00:17:44,250 --> 00:17:51,960
experts and security and beyond so our

410
00:17:48,900 --> 00:17:54,059
team for example consisted of security

411
00:17:51,960 --> 00:17:55,870
researchers data scientists economists

412
00:17:54,059 --> 00:17:59,420
and designers

413
00:17:55,870 --> 00:18:00,919
of course I won't claim much theory is

414
00:17:59,420 --> 00:18:03,890
the Silver Bullet to solve all usable

415
00:18:00,920 --> 00:18:05,870
security problems but I'd really like to

416
00:18:03,890 --> 00:18:08,390
see how much of the approach generalizes

417
00:18:05,870 --> 00:18:11,059
to other important problems our work

418
00:18:08,390 --> 00:18:12,440
gives only an initial study but it shows

419
00:18:11,059 --> 00:18:14,750
that there's potential for fixing

420
00:18:12,440 --> 00:18:18,140
important security issues encode on a

421
00:18:14,750 --> 00:18:20,059
very large scale and the urgency to take

422
00:18:18,140 --> 00:18:22,280
tech to take action is pretty high as

423
00:18:20,059 --> 00:18:26,809
the problem otherwise is much likely to

424
00:18:22,280 --> 00:18:28,760
worsen so I'm at the end of my talk but

425
00:18:26,809 --> 00:18:32,059
it's not the end of our sigilyph long

426
00:18:28,760 --> 00:18:33,830
story we'd love to see a happy ending

427
00:18:32,059 --> 00:18:37,460
where stackoverflow implements at least

428
00:18:33,830 --> 00:18:40,399
some of our ideas so we hope that this

429
00:18:37,460 --> 00:18:42,170
talk was a nudge itself all right thank

430
00:18:40,400 --> 00:18:43,300
you very much and now I'm happy to take

431
00:18:42,170 --> 00:18:49,280
questions

432
00:18:43,300 --> 00:18:49,280
[Applause]

