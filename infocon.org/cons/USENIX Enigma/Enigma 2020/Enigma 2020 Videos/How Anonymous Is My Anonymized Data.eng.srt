1
00:00:16,000 --> 00:00:21,220
I work with vulnerabilities analysis

2
00:00:19,030 --> 00:00:23,080
quite a bit and one of the things you

3
00:00:21,220 --> 00:00:24,759
need for that is data but it's often

4
00:00:23,080 --> 00:00:25,839
very hard to get hold of the data

5
00:00:24,760 --> 00:00:28,570
because it contains sensitive

6
00:00:25,840 --> 00:00:31,840
information so we anonymize it or

7
00:00:28,570 --> 00:00:34,000
sanitize it and I got to thinking about

8
00:00:31,840 --> 00:00:38,110
that a little bit and the result is is

9
00:00:34,000 --> 00:00:40,510
this talk we need to share data and

10
00:00:38,110 --> 00:00:42,970
that's not just computer science it's

11
00:00:40,510 --> 00:00:44,980
across the spectrum okay the National

12
00:00:42,970 --> 00:00:46,600
Institutes for health says we believe

13
00:00:44,980 --> 00:00:49,419
that data sharing is essential for

14
00:00:46,600 --> 00:00:51,760
expedited distress translation of

15
00:00:49,420 --> 00:00:54,129
research results into knowledge products

16
00:00:51,760 --> 00:00:57,160
and procedures to improve human health

17
00:00:54,129 --> 00:00:58,329
the European Commission says something

18
00:00:57,160 --> 00:01:00,819
similar although a little more

19
00:00:58,329 --> 00:01:02,860
indirectly data-driven innovation is a

20
00:01:00,820 --> 00:01:05,619
key enabler of growth and jobs in Europe

21
00:01:02,860 --> 00:01:07,590
the importance of data collected online

22
00:01:05,619 --> 00:01:10,509
and generated by the Internet of Things

23
00:01:07,590 --> 00:01:12,820
objects and the availability of big data

24
00:01:10,509 --> 00:01:15,009
analytics tools and artificial

25
00:01:12,820 --> 00:01:19,089
intelligence applications or technical

26
00:01:15,009 --> 00:01:20,710
drivers and I'll swing back to the to

27
00:01:19,090 --> 00:01:24,159
some issues with big data analytics

28
00:01:20,710 --> 00:01:26,649
tools later on in the talk and finally

29
00:01:24,159 --> 00:01:29,290
the one most direct to science from Karl

30
00:01:26,650 --> 00:01:30,909
Popper who says non reproducible single

31
00:01:29,290 --> 00:01:33,220
occurrences are of no significance to

32
00:01:30,909 --> 00:01:37,060
science so we want to be people to be

33
00:01:33,220 --> 00:01:39,280
able to reproduce our results and to do

34
00:01:37,060 --> 00:01:44,560
that they often need to access to the

35
00:01:39,280 --> 00:01:46,390
same data that we're using so sure so in

36
00:01:44,560 --> 00:01:48,250
fact psychology is having a huge problem

37
00:01:46,390 --> 00:01:50,680
with this right now because many of this

38
00:01:48,250 --> 00:01:54,100
seminal pay some of the seminal papers

39
00:01:50,680 --> 00:01:56,770
could not be reproduced so all of this

40
00:01:54,100 --> 00:01:58,658
requires a sharing of data but the

41
00:01:56,770 --> 00:02:02,798
sharing of data exposes private and

42
00:01:58,659 --> 00:02:05,229
other sensitive information so we

43
00:02:02,799 --> 00:02:07,509
sanitize or anonymize the data and I'm

44
00:02:05,229 --> 00:02:09,579
gonna use the true terms as synonyms

45
00:02:07,509 --> 00:02:12,430
although there's really a slight

46
00:02:09,579 --> 00:02:14,320
difference between the two the key point

47
00:02:12,430 --> 00:02:16,480
to take away from this talk is that anon

48
00:02:14,320 --> 00:02:18,940
ization is a problem of threats risks

49
00:02:16,480 --> 00:02:24,019
and relationships with some of each

50
00:02:18,940 --> 00:02:25,579
being unknown okay so

51
00:02:24,020 --> 00:02:27,320
it's a good idea to have a pretty good

52
00:02:25,580 --> 00:02:30,140
assistant model in mind so here's the

53
00:02:27,320 --> 00:02:32,480
system model that that I'm using use

54
00:02:30,140 --> 00:02:34,519
some raw data and you have some analysts

55
00:02:32,480 --> 00:02:36,920
so they go ahead and analyze it and

56
00:02:34,520 --> 00:02:39,500
prove some results there are other

57
00:02:36,920 --> 00:02:43,640
another group wants an access to it to

58
00:02:39,500 --> 00:02:46,580
do the work and so you go ahead and give

59
00:02:43,640 --> 00:02:49,220
them access but you sanitize the data

60
00:02:46,580 --> 00:02:53,210
first they do the same analysis the

61
00:02:49,220 --> 00:02:55,970
first group did and ideally you want the

62
00:02:53,210 --> 00:02:57,500
results to be the same however there's a

63
00:02:55,970 --> 00:02:59,720
catch to all this

64
00:02:57,500 --> 00:03:03,500
there are adversaries or nasty people

65
00:02:59,720 --> 00:03:05,690
whoops who want to de santé ties the

66
00:03:03,500 --> 00:03:08,270
data get out the private information and

67
00:03:05,690 --> 00:03:11,780
so to prevent that we have some sort of

68
00:03:08,270 --> 00:03:13,850
a privacy policy in place that helps

69
00:03:11,780 --> 00:03:17,870
that controls among other things this

70
00:03:13,850 --> 00:03:21,380
and how the sanitization is done but

71
00:03:17,870 --> 00:03:24,910
there's contradiction here this the

72
00:03:21,380 --> 00:03:29,209
threat model says what security controls

73
00:03:24,910 --> 00:03:32,000
are to thwart those but a breach occurs

74
00:03:29,209 --> 00:03:33,709
when it doesn't work but since you have

75
00:03:32,000 --> 00:03:36,370
personal or other confidential

76
00:03:33,709 --> 00:03:40,670
information in there you want to hide it

77
00:03:36,370 --> 00:03:42,380
and this can cause problem if it's not

78
00:03:40,670 --> 00:03:45,019
hidden this is gonna cause problems not

79
00:03:42,380 --> 00:03:46,790
only for the folks who have the data but

80
00:03:45,020 --> 00:03:52,220
also for the subjects about whom the

81
00:03:46,790 --> 00:03:54,019
data refers and so it's very important

82
00:03:52,220 --> 00:03:56,540
that that type of information be hidden

83
00:03:54,020 --> 00:03:59,480
but on the other hand we have utility

84
00:03:56,540 --> 00:04:02,090
other parts of the information have to

85
00:03:59,480 --> 00:04:03,649
be exposed for analysis I've done a lot

86
00:04:02,090 --> 00:04:05,750
of work in intrusion detection and we

87
00:04:03,650 --> 00:04:08,300
love getting raw traces broad network

88
00:04:05,750 --> 00:04:11,720
traces so we can analyze them and test

89
00:04:08,300 --> 00:04:15,200
our to test our tools medical data for

90
00:04:11,720 --> 00:04:19,329
example is used in epidemiological

91
00:04:15,200 --> 00:04:22,180
studies and many other types of studies

92
00:04:19,329 --> 00:04:25,550
by the way with intrusion detection to

93
00:04:22,180 --> 00:04:27,680
removing the packet bodies is what is

94
00:04:25,550 --> 00:04:31,600
often done but that still enables

95
00:04:27,680 --> 00:04:34,820
traffic analysis from the headers so

96
00:04:31,600 --> 00:04:36,470
there are two things so there so we want

97
00:04:34,820 --> 00:04:37,270
to know what do we mean by disclosure

98
00:04:36,470 --> 00:04:38,770
I'm

99
00:04:37,270 --> 00:04:40,330
not for defining the terms that we're

100
00:04:38,770 --> 00:04:42,789
using and there are actually two

101
00:04:40,330 --> 00:04:45,810
definitions of this the first one was

102
00:04:42,790 --> 00:04:48,520
done by Tour de lenio since a 77 paper

103
00:04:45,810 --> 00:04:51,670
where he said that a disclosure takes

104
00:04:48,520 --> 00:04:54,760
place if you release some anonymize data

105
00:04:51,670 --> 00:04:56,590
and from that you can attribute you can

106
00:04:54,760 --> 00:04:59,469
determine the value of an attribute more

107
00:04:56,590 --> 00:05:03,250
accurately than if the data were not

108
00:04:59,470 --> 00:05:05,620
released it's a great definition it's an

109
00:05:03,250 --> 00:05:06,250
ideal but it's not practical for various

110
00:05:05,620 --> 00:05:08,860
reasons

111
00:05:06,250 --> 00:05:10,180
Cynthia Dworkin came up with another one

112
00:05:08,860 --> 00:05:12,730
which is much better and much more

113
00:05:10,180 --> 00:05:14,350
widely used namely that the risk the

114
00:05:12,730 --> 00:05:17,230
privacy should not substantially

115
00:05:14,350 --> 00:05:21,490
increase as a result of participating in

116
00:05:17,230 --> 00:05:23,710
a database and she formalized this

117
00:05:21,490 --> 00:05:25,750
differential privacy and here's the

118
00:05:23,710 --> 00:05:28,390
formal definition you know after all any

119
00:05:25,750 --> 00:05:31,390
good computer security talk needs to

120
00:05:28,390 --> 00:05:33,460
have some math in it but the concept

121
00:05:31,390 --> 00:05:35,890
really is simple we have two databases a

122
00:05:33,460 --> 00:05:37,510
record in both databases has a different

123
00:05:35,890 --> 00:05:39,430
value in one of the fields of interest

124
00:05:37,510 --> 00:05:41,800
when is the anonymized

125
00:05:39,430 --> 00:05:43,240
the other is the non anonymized the

126
00:05:41,800 --> 00:05:45,010
equation simply says that the

127
00:05:43,240 --> 00:05:47,050
differences in the probabilities of in

128
00:05:45,010 --> 00:05:49,330
determining the information of the UH

129
00:05:47,050 --> 00:05:52,060
Nenana mise dataset knowing only what's

130
00:05:49,330 --> 00:05:53,740
in the anonymized data set can be made

131
00:05:52,060 --> 00:05:58,110
arbitrarily small that's what the

132
00:05:53,740 --> 00:06:00,790
epsilon the e to the Epsilon refers to

133
00:05:58,110 --> 00:06:03,100
now what ever scientists says

134
00:06:00,790 --> 00:06:04,300
arbitrarily small you have to be careful

135
00:06:03,100 --> 00:06:06,310
because they're not saying it can't be

136
00:06:04,300 --> 00:06:09,340
done they're saying it's very hard to do

137
00:06:06,310 --> 00:06:11,350
and Cynthia dork proved the theorem that

138
00:06:09,340 --> 00:06:14,169
drives this home the theorem says that

139
00:06:11,350 --> 00:06:16,990
when an anonymized data set is released

140
00:06:14,170 --> 00:06:18,250
there's always external information that

141
00:06:16,990 --> 00:06:20,320
can be combined with the released

142
00:06:18,250 --> 00:06:23,170
information that enables someone to

143
00:06:20,320 --> 00:06:28,120
figure out the hidden information except

144
00:06:23,170 --> 00:06:29,440
in the most trivial cases so let's take

145
00:06:28,120 --> 00:06:31,120
a look at how this can be done and I'm

146
00:06:29,440 --> 00:06:35,110
going to use Netflix as an opening

147
00:06:31,120 --> 00:06:37,420
example Netflix in 2006 held a contest

148
00:06:35,110 --> 00:06:39,700
to see if their recommendation system

149
00:06:37,420 --> 00:06:41,770
could be beaten or could be improved I

150
00:06:39,700 --> 00:06:43,420
should say they were the core training

151
00:06:41,770 --> 00:06:48,419
corpus had over a hundred million

152
00:06:43,420 --> 00:06:50,780
records in it with with user ID

153
00:06:48,420 --> 00:06:53,120
anonymized the date Anana

154
00:06:50,780 --> 00:06:56,500
I suck changed somewhat the movie in the

155
00:06:53,120 --> 00:06:58,760
rating and the records covered over

156
00:06:56,500 --> 00:07:03,260
17,500 movies and about half a million

157
00:06:58,760 --> 00:07:06,940
users so you can see the top top

158
00:07:03,260 --> 00:07:06,940
rectangle how they did the anonymization

159
00:07:07,270 --> 00:07:12,260
that was what the people trying to build

160
00:07:10,070 --> 00:07:13,580
better recommendation systems used but a

161
00:07:12,260 --> 00:07:16,219
couple of people at the University of

162
00:07:13,580 --> 00:07:18,200
Texas got curious they realized there's

163
00:07:16,220 --> 00:07:20,270
a public source for all that information

164
00:07:18,200 --> 00:07:24,050
as well the Internet Movie Database and

165
00:07:20,270 --> 00:07:28,400
so what they did was they took data from

166
00:07:24,050 --> 00:07:30,230
50 users records and from that started

167
00:07:28,400 --> 00:07:31,520
comparing the data in those records to

168
00:07:30,230 --> 00:07:34,520
what was on the Internet Movie Database

169
00:07:31,520 --> 00:07:36,919
and as a result they claimed to be able

170
00:07:34,520 --> 00:07:39,590
to do not eyes at least one of the users

171
00:07:36,919 --> 00:07:41,450
involved here basically the way they did

172
00:07:39,590 --> 00:07:44,030
it was if you look at the first one

173
00:07:41,450 --> 00:07:46,969
there's no match type the movie is

174
00:07:44,030 --> 00:07:49,489
Titanic and the stars are wrong so users

175
00:07:46,970 --> 00:07:52,610
six five six nine four six has not seen

176
00:07:49,490 --> 00:07:55,240
you but if you look at this the data is

177
00:07:52,610 --> 00:07:57,410
within statistical tolerance and

178
00:07:55,240 --> 00:08:00,200
everything else is the same so the

179
00:07:57,410 --> 00:08:05,900
record match so they used external

180
00:08:00,200 --> 00:08:08,960
information 2d anonymize the the

181
00:08:05,900 --> 00:08:11,239
anonymized information so this brings us

182
00:08:08,960 --> 00:08:14,719
to our threat model what's the threat

183
00:08:11,240 --> 00:08:16,520
model well first of all we can't we

184
00:08:14,720 --> 00:08:18,710
don't we never assume the adversaries of

185
00:08:16,520 --> 00:08:20,799
access to the raw data otherwise why is

186
00:08:18,710 --> 00:08:23,570
this a problem

187
00:08:20,800 --> 00:08:25,550
in some cases will assume that the

188
00:08:23,570 --> 00:08:27,320
adversary can inject things into the

189
00:08:25,550 --> 00:08:29,419
data without knowing what that data is

190
00:08:27,320 --> 00:08:31,460
and sometimes that can be used to derive

191
00:08:29,419 --> 00:08:33,949
structure or other information about the

192
00:08:31,460 --> 00:08:35,329
data but for this talk I'm simply going

193
00:08:33,950 --> 00:08:38,089
to assume that the adversaries have

194
00:08:35,330 --> 00:08:41,089
access to the sanitized data and not

195
00:08:38,089 --> 00:08:44,030
we're not able to corrupt the original

196
00:08:41,089 --> 00:08:48,680
data as it was being saved and in fact

197
00:08:44,030 --> 00:08:52,550
that's usually what people do assume so

198
00:08:48,680 --> 00:08:54,439
given the Netflix results which used

199
00:08:52,550 --> 00:08:56,750
external information the obvious

200
00:08:54,440 --> 00:09:00,580
question is great what information the

201
00:08:56,750 --> 00:09:03,370
adversary have access to well before

202
00:09:00,580 --> 00:09:06,850
1993 maybe that was actually a very

203
00:09:03,370 --> 00:09:09,070
good question because the information

204
00:09:06,850 --> 00:09:10,810
was not easily available if you wanted

205
00:09:09,070 --> 00:09:12,430
to get information about someone for

206
00:09:10,810 --> 00:09:15,459
example you typically had to go to where

207
00:09:12,430 --> 00:09:18,160
they were or hire someone to do that and

208
00:09:15,460 --> 00:09:20,620
look through court records County

209
00:09:18,160 --> 00:09:22,949
records things like that but then came

210
00:09:20,620 --> 00:09:25,600
the World Wide Web and all of a sudden

211
00:09:22,950 --> 00:09:27,820
all that information suddenly became

212
00:09:25,600 --> 00:09:29,380
widely available so it's not realistic

213
00:09:27,820 --> 00:09:32,020
to say well let's figure out what they

214
00:09:29,380 --> 00:09:33,610
have available it's probably much better

215
00:09:32,020 --> 00:09:36,850
to say well let's look at the

216
00:09:33,610 --> 00:09:39,760
relationships among the data records

217
00:09:36,850 --> 00:09:41,620
that might allow someone to ravit to

218
00:09:39,760 --> 00:09:43,420
determine the hidden information and

219
00:09:41,620 --> 00:09:47,830
then try to hide or break those

220
00:09:43,420 --> 00:09:51,219
relationships in some way for example if

221
00:09:47,830 --> 00:09:53,770
Paul works late in the evening and all

222
00:09:51,220 --> 00:09:56,860
someone has a record of people of times

223
00:09:53,770 --> 00:09:58,990
when the card reader recorded someone

224
00:09:56,860 --> 00:10:01,750
going in they'll be able to figure out

225
00:09:58,990 --> 00:10:03,460
which one what Paul's card is and I'll

226
00:10:01,750 --> 00:10:06,250
give you a very good example of that and

227
00:10:03,460 --> 00:10:09,940
a much more sensitive environment later

228
00:10:06,250 --> 00:10:11,070
on there are other aspects of the model

229
00:10:09,940 --> 00:10:14,380
as well

230
00:10:11,070 --> 00:10:15,970
temporal there are two types of temporal

231
00:10:14,380 --> 00:10:17,800
issues here the first one is that if

232
00:10:15,970 --> 00:10:20,589
threats don't remain constant they

233
00:10:17,800 --> 00:10:23,140
evolve for example in the United States

234
00:10:20,589 --> 00:10:25,750
during the Great Depression in 19 in the

235
00:10:23,140 --> 00:10:27,400
1930s many people joined the Communist

236
00:10:25,750 --> 00:10:31,180
Party because they saw it as a beacon of

237
00:10:27,400 --> 00:10:33,520
hope for the future but in the 1950s

238
00:10:31,180 --> 00:10:35,109
that often came back to bite people with

239
00:10:33,520 --> 00:10:37,900
a house on American Activities Committee

240
00:10:35,110 --> 00:10:40,089
and Senator McCarthy's committee and a

241
00:10:37,900 --> 00:10:42,130
few other committees that took any

242
00:10:40,089 --> 00:10:45,459
membership in the Communist Party at any

243
00:10:42,130 --> 00:10:47,529
time as meaning you were working for an

244
00:10:45,459 --> 00:10:51,069
adversary in this case the Soviet Union

245
00:10:47,529 --> 00:10:56,080
and unless you name names you were

246
00:10:51,070 --> 00:10:57,910
basically a traitor but now that ended

247
00:10:56,080 --> 00:11:00,100
around the late fifties early sixties

248
00:10:57,910 --> 00:11:02,650
now if you know someone who's a

249
00:11:00,100 --> 00:11:04,209
communist you may think well okay it's

250
00:11:02,650 --> 00:11:05,770
good good they can believe that in our

251
00:11:04,209 --> 00:11:07,689
system or maybe they're a little odd but

252
00:11:05,770 --> 00:11:10,199
you're not gonna see them as a threat to

253
00:11:07,690 --> 00:11:12,339
the United States so the threats change

254
00:11:10,200 --> 00:11:14,560
the other aspect of this that's

255
00:11:12,339 --> 00:11:17,710
important is if I release a data set

256
00:11:14,560 --> 00:11:20,140
and then I released another dataset

257
00:11:17,710 --> 00:11:21,910
later on individually you may not be

258
00:11:20,140 --> 00:11:24,160
able to do naanum eyes them put them

259
00:11:21,910 --> 00:11:26,079
together and you might be able to this

260
00:11:24,160 --> 00:11:27,610
becomes particularly touchy when two

261
00:11:26,080 --> 00:11:29,560
different organizations have the same

262
00:11:27,610 --> 00:11:32,589
data and they don't coordinate what

263
00:11:29,560 --> 00:11:37,000
they're hiding things like that have in

264
00:11:32,589 --> 00:11:39,130
fact happened in the past the other

265
00:11:37,000 --> 00:11:41,350
issue is what can you derive from the

266
00:11:39,130 --> 00:11:44,680
data and sometimes it's not really

267
00:11:41,350 --> 00:11:46,180
obvious a friendly attacker cracked a

268
00:11:44,680 --> 00:11:48,969
large number of passwords at a major

269
00:11:46,180 --> 00:11:51,579
university and it turned out that many

270
00:11:48,970 --> 00:11:53,620
accounts with male names had as their

271
00:11:51,580 --> 00:11:56,080
password variants of female names like

272
00:11:53,620 --> 00:11:59,500
Barbara one or Katie asterisk or things

273
00:11:56,080 --> 00:12:02,830
like that further many accounts with

274
00:11:59,500 --> 00:12:04,180
female names had male names or some had

275
00:12:02,830 --> 00:12:05,770
a variant of male names as their

276
00:12:04,180 --> 00:12:08,109
passwords so from this he could build up

277
00:12:05,770 --> 00:12:09,130
a pattern of who was dating whom which

278
00:12:08,110 --> 00:12:11,740
is not something you would normally

279
00:12:09,130 --> 00:12:13,779
expect and he did check with the people

280
00:12:11,740 --> 00:12:15,430
everybody knew him and trusted him so

281
00:12:13,779 --> 00:12:21,640
they basically found out that that was

282
00:12:15,430 --> 00:12:23,589
correct so what this really means is the

283
00:12:21,640 --> 00:12:25,630
threat model has to be complete and

284
00:12:23,589 --> 00:12:29,910
accurate and it's very hard to get to

285
00:12:25,630 --> 00:12:32,910
the complete model now the Netflix data

286
00:12:29,910 --> 00:12:37,240
use relationships that were very obvious

287
00:12:32,910 --> 00:12:39,310
the IMDB exact heads data similar to

288
00:12:37,240 --> 00:12:42,870
Netflix and the relationships where they

289
00:12:39,310 --> 00:12:45,880
are so it was a direct construction

290
00:12:42,870 --> 00:12:47,650
however they don't always the

291
00:12:45,880 --> 00:12:50,530
relationships are not always that direct

292
00:12:47,650 --> 00:12:54,430
and in fact maybe very mysterious this

293
00:12:50,530 --> 00:12:57,339
is an example if you want to hide names

294
00:12:54,430 --> 00:12:58,930
in a database that has names phone

295
00:12:57,339 --> 00:13:02,230
numbers social security numbers

296
00:12:58,930 --> 00:13:03,670
difficult dates of birth and gender you

297
00:13:02,230 --> 00:13:04,900
might think it's enough to hide the name

298
00:13:03,670 --> 00:13:08,170
and the phone number in the social

299
00:13:04,900 --> 00:13:10,470
security number unfortunately it's not

300
00:13:08,170 --> 00:13:12,939
Latanya Sweeney working at Harvard

301
00:13:10,470 --> 00:13:14,529
showed that about 87 percent of the

302
00:13:12,940 --> 00:13:16,480
households in the United States could be

303
00:13:14,529 --> 00:13:19,420
uniquely identified by those last three

304
00:13:16,480 --> 00:13:21,040
the ones in parentheses amusingly a

305
00:13:19,420 --> 00:13:22,569
couple of years later some people at

306
00:13:21,040 --> 00:13:23,910
Stanford did a similar thing and they

307
00:13:22,570 --> 00:13:27,840
basically said nope

308
00:13:23,910 --> 00:13:30,240
wrong only 63% so it was still a very

309
00:13:27,840 --> 00:13:33,210
large number from a relationship that

310
00:13:30,240 --> 00:13:35,340
one would normally not x1 would normally

311
00:13:33,210 --> 00:13:37,560
not think of this by the way is where

312
00:13:35,340 --> 00:13:39,780
deep learning comes into play because it

313
00:13:37,560 --> 00:13:41,670
can often show relationships that you

314
00:13:39,780 --> 00:13:47,010
don't know about the gym wouldn't have

315
00:13:41,670 --> 00:13:49,979
thought about now as far as things

316
00:13:47,010 --> 00:13:54,420
existing AOL is a very good example of

317
00:13:49,980 --> 00:13:56,190
this in March to May 2006 they collected

318
00:13:54,420 --> 00:13:59,819
search records and then they released

319
00:13:56,190 --> 00:14:03,180
them anonymizing all the users they put

320
00:13:59,820 --> 00:14:04,830
it out on Friday night at 5 p.m. by the

321
00:14:03,180 --> 00:14:07,949
way don't ever put anything on the web

322
00:14:04,830 --> 00:14:09,660
at Friday night at 5 p.m. okay when

323
00:14:07,950 --> 00:14:11,160
people came in on the Monday morning

324
00:14:09,660 --> 00:14:15,390
they immediately ordered it pulled off

325
00:14:11,160 --> 00:14:17,490
the web so the data was gone right no

326
00:14:15,390 --> 00:14:20,939
you don't forget things on the Internet

327
00:14:17,490 --> 00:14:22,800
okay the first thing was some reporters

328
00:14:20,940 --> 00:14:24,990
from the New York Times got very curious

329
00:14:22,800 --> 00:14:27,300
about how safe this data was could they

330
00:14:24,990 --> 00:14:29,130
be anonymized it and so they looked

331
00:14:27,300 --> 00:14:32,459
through the records and found user four

332
00:14:29,130 --> 00:14:35,310
four one seven four nine four four one

333
00:14:32,460 --> 00:14:38,510
seven seven four nine a lot of search

334
00:14:35,310 --> 00:14:42,000
records in there and it was about

335
00:14:38,510 --> 00:14:45,270
landscaping and around look around villa

336
00:14:42,000 --> 00:14:47,610
burned many people had the last name of

337
00:14:45,270 --> 00:14:50,370
Arnold and a number of other

338
00:14:47,610 --> 00:14:53,340
characteristics and from this they flew

339
00:14:50,370 --> 00:14:55,170
down to Georgia went through records and

340
00:14:53,340 --> 00:14:57,450
found that the lady was named Thelma

341
00:14:55,170 --> 00:14:59,370
Arnold and they know this because they

342
00:14:57,450 --> 00:15:01,710
knocked on her door Esther these were

343
00:14:59,370 --> 00:15:06,230
her queries and she said yes and I think

344
00:15:01,710 --> 00:15:10,770
I'm gonna unsubscribe from AOL now okay

345
00:15:06,230 --> 00:15:13,920
so here's using external data by the way

346
00:15:10,770 --> 00:15:18,510
AOL stalker a few days after it went

347
00:15:13,920 --> 00:15:20,790
down the AOL data went down AOL stalker

348
00:15:18,510 --> 00:15:22,740
came up it had all the data there so you

349
00:15:20,790 --> 00:15:25,349
could perform your own search queries

350
00:15:22,740 --> 00:15:25,950
and I know that slide is very hard to

351
00:15:25,350 --> 00:15:29,700
read

352
00:15:25,950 --> 00:15:31,230
it's a screenshot but I blew up a couple

353
00:15:29,700 --> 00:15:35,100
of lines here to show you the sort of

354
00:15:31,230 --> 00:15:37,070
information that AOL stalker has by the

355
00:15:35,100 --> 00:15:41,240
way AOL stalker is no longer around

356
00:15:37,070 --> 00:15:43,680
go to web archive.org and you'll find it

357
00:15:41,240 --> 00:15:46,650
so nothing really leaves the internet

358
00:15:43,680 --> 00:15:48,390
again this screenshot shows what happens

359
00:15:46,650 --> 00:15:49,709
when you search for a particular user in

360
00:15:48,390 --> 00:15:51,900
this case the same one as the New York

361
00:15:49,710 --> 00:15:53,730
Times reporters did you get how many

362
00:15:51,900 --> 00:15:56,069
pages they viewed how they rated the

363
00:15:53,730 --> 00:15:58,110
links the IP addresses and times when

364
00:15:56,070 --> 00:15:59,970
they viewed search query and if they

365
00:15:58,110 --> 00:16:02,670
click through you'll get the URL they

366
00:15:59,970 --> 00:16:06,180
click through as well and the ranking of

367
00:16:02,670 --> 00:16:07,890
that URL now this example illustrates a

368
00:16:06,180 --> 00:16:09,900
number of point a couple of points

369
00:16:07,890 --> 00:16:12,620
beyond don't put things on the internet

370
00:16:09,900 --> 00:16:15,030
that I you expect to take off okay

371
00:16:12,620 --> 00:16:16,470
first of all the way it was the

372
00:16:15,030 --> 00:16:18,110
anonymized involved absolutely no

373
00:16:16,470 --> 00:16:20,310
mathematics or computer science

374
00:16:18,110 --> 00:16:22,140
basically they simply look for external

375
00:16:20,310 --> 00:16:24,869
data that matched the release data and

376
00:16:22,140 --> 00:16:27,870
from that they could build a profile the

377
00:16:24,870 --> 00:16:29,940
relationships of the data and both the

378
00:16:27,870 --> 00:16:31,860
release information and the external

379
00:16:29,940 --> 00:16:35,190
information enabled the reason well

380
00:16:31,860 --> 00:16:36,930
reporters to put them together alone

381
00:16:35,190 --> 00:16:39,150
neither of them would have been useful

382
00:16:36,930 --> 00:16:40,800
but together they were both very useful

383
00:16:39,150 --> 00:16:44,670
and was sufficient to identify the user

384
00:16:40,800 --> 00:16:46,199
so this was an indirect relationship but

385
00:16:44,670 --> 00:16:49,079
it was a little bit more spooky than

386
00:16:46,200 --> 00:16:51,480
that the among the queries the user

387
00:16:49,080 --> 00:16:55,890
asked were things about nicotine

388
00:16:51,480 --> 00:16:57,360
addiction emphysema liver problems and a

389
00:16:55,890 --> 00:16:58,980
couple of other things and so they

390
00:16:57,360 --> 00:17:02,070
figured she was gonna be an asthmatic

391
00:16:58,980 --> 00:17:03,690
smoker who had health problems when they

392
00:17:02,070 --> 00:17:05,910
interviewed her she was the perfect

393
00:17:03,690 --> 00:17:07,470
picture of health it turned out she was

394
00:17:05,910 --> 00:17:09,959
a retired nurse and she had been doing

395
00:17:07,470 --> 00:17:11,250
web searches for her neighbors so that's

396
00:17:09,959 --> 00:17:17,310
an example of drawing the wrong

397
00:17:11,250 --> 00:17:20,190
conclusion from the data now these

398
00:17:17,310 --> 00:17:24,270
examples and the one I'm gonna give you

399
00:17:20,190 --> 00:17:27,839
next shows the need for a complete and

400
00:17:24,270 --> 00:17:29,970
accurate threat model okay it's accurate

401
00:17:27,839 --> 00:17:31,830
because you want to ensure that you

402
00:17:29,970 --> 00:17:33,660
handle the data that's considered that

403
00:17:31,830 --> 00:17:35,970
you considers serious you don't want

404
00:17:33,660 --> 00:17:38,370
released and also the data that the

405
00:17:35,970 --> 00:17:39,720
people who the data is about don't want

406
00:17:38,370 --> 00:17:46,229
and release that's something that's

407
00:17:39,720 --> 00:17:47,880
often overlooked so you want it complete

408
00:17:46,230 --> 00:17:50,380
for that reason you also want it

409
00:17:47,880 --> 00:17:52,000
accurate and you want to

410
00:17:50,380 --> 00:17:54,490
sure that people can't draw the wrong

411
00:17:52,000 --> 00:17:56,080
inferences because again is with well

412
00:17:54,490 --> 00:17:58,450
with helm Arnold it was very harmless

413
00:17:56,080 --> 00:18:00,909
but in other cases people may draw

414
00:17:58,450 --> 00:18:03,100
inferences that are very damaging to the

415
00:18:00,910 --> 00:18:05,170
subjects of the data or to you and you

416
00:18:03,100 --> 00:18:08,350
need to be aware of that possibility

417
00:18:05,170 --> 00:18:11,260
now as Heather said one of the areas I

418
00:18:08,350 --> 00:18:13,389
work in a lot is elections and in the

419
00:18:11,260 --> 00:18:17,140
United States elections of certain

420
00:18:13,390 --> 00:18:20,470
properties basically they use a secret

421
00:18:17,140 --> 00:18:21,910
anonymous ballot that means you not only

422
00:18:20,470 --> 00:18:24,760
can know and link the ballot to the

423
00:18:21,910 --> 00:18:27,610
voter the voter cannot prove how he or

424
00:18:24,760 --> 00:18:28,930
she voted the reason for that is first

425
00:18:27,610 --> 00:18:31,240
they don't want you to send your votes

426
00:18:28,930 --> 00:18:33,100
and secondly they don't want too large

427
00:18:31,240 --> 00:18:34,480
ugly proof people coming by it saying

428
00:18:33,100 --> 00:18:39,280
vote our way and prove it or we'll

429
00:18:34,480 --> 00:18:41,110
rearrange your kneecaps okay so that

430
00:18:39,280 --> 00:18:44,260
information is considered very very

431
00:18:41,110 --> 00:18:46,629
sensitive well in Ohio when you go to

432
00:18:44,260 --> 00:18:49,030
vote you walk in and you identify

433
00:18:46,630 --> 00:18:50,890
yourself I don't remember if Ohio

434
00:18:49,030 --> 00:18:53,830
requires ID I know that California

435
00:18:50,890 --> 00:18:55,960
doesn't and they sign you in on a poll

436
00:18:53,830 --> 00:18:57,730
book and it put in the time you walked

437
00:18:55,960 --> 00:19:00,130
in then you get the ballot you invoked

438
00:18:57,730 --> 00:19:02,410
in Ohio at the time this was done on an

439
00:19:00,130 --> 00:19:05,230
electronic voting machine and it printed

440
00:19:02,410 --> 00:19:06,640
up a paper copy of your votes this is

441
00:19:05,230 --> 00:19:08,830
called the voter verified paper audit

442
00:19:06,640 --> 00:19:12,520
trail and among the things that put on

443
00:19:08,830 --> 00:19:14,560
there was a time stamp now it turned out

444
00:19:12,520 --> 00:19:16,150
at the time the ballots were public

445
00:19:14,560 --> 00:19:17,950
record because they didn't have any

446
00:19:16,150 --> 00:19:20,410
names or identifying information on them

447
00:19:17,950 --> 00:19:22,420
and the poll books were public record

448
00:19:20,410 --> 00:19:24,820
because they didn't have any information

449
00:19:22,420 --> 00:19:26,500
about your ballot a couple of

450
00:19:24,820 --> 00:19:28,450
researchers did the equivalent of a

451
00:19:26,500 --> 00:19:30,610
Freedom of Information Act on Ohio and

452
00:19:28,450 --> 00:19:32,380
got that both of them and then they

453
00:19:30,610 --> 00:19:35,280
started matching up the time so the poll

454
00:19:32,380 --> 00:19:37,810
books with the times on the ballots and

455
00:19:35,280 --> 00:19:39,879
that gave them the names of voters and

456
00:19:37,810 --> 00:19:42,100
the papers really both amusing and

457
00:19:39,880 --> 00:19:43,990
terrifying because they described how

458
00:19:42,100 --> 00:19:45,909
people voted and in one case they said

459
00:19:43,990 --> 00:19:49,210
the name was not Jones but I'm going to

460
00:19:45,910 --> 00:19:51,430
use it that mr. and mrs. Jones may be

461
00:19:49,210 --> 00:19:53,350
very uncomfortable hearing that mr.

462
00:19:51,430 --> 00:19:56,830
Jones voted this way and mrs. Jones

463
00:19:53,350 --> 00:19:58,629
voted this way the opposite so from that

464
00:19:56,830 --> 00:20:01,480
they were able to derive information and

465
00:19:58,630 --> 00:20:03,399
the point here is that external

466
00:20:01,480 --> 00:20:06,639
requirements may make anonymous

467
00:20:03,399 --> 00:20:08,258
very very difficult by the way the Ohio

468
00:20:06,639 --> 00:20:10,299
solution was to make one of the many

469
00:20:08,259 --> 00:20:17,399
don't remember which no longer public

470
00:20:10,299 --> 00:20:20,168
record so where does this go well

471
00:20:17,399 --> 00:20:21,820
basically what can we do can we do

472
00:20:20,169 --> 00:20:24,429
anything other than saying throwing up

473
00:20:21,820 --> 00:20:27,099
our hands and saying we can't do this

474
00:20:24,429 --> 00:20:30,129
well we can re-evaluate how we anonymize

475
00:20:27,099 --> 00:20:31,509
the data ask how likely it is that an

476
00:20:30,129 --> 00:20:33,939
adversary could uncover the

477
00:20:31,509 --> 00:20:37,359
relationships in the data involving the

478
00:20:33,940 --> 00:20:39,639
fields we want to anonymize specifically

479
00:20:37,359 --> 00:20:41,649
what information would they need if the

480
00:20:39,639 --> 00:20:43,209
information is very closely held and

481
00:20:41,649 --> 00:20:45,998
you're certain of that that's one thing

482
00:20:43,210 --> 00:20:47,379
but if it's at all public you should

483
00:20:45,999 --> 00:20:48,339
assume that the adversaries have full

484
00:20:47,379 --> 00:20:50,769
access to it

485
00:20:48,339 --> 00:20:52,928
what might an adversary want to infer

486
00:20:50,769 --> 00:20:55,629
from the data you know what you don't

487
00:20:52,929 --> 00:20:57,729
want them to infer but what else might

488
00:20:55,629 --> 00:21:00,428
they infer that's damaging to you or to

489
00:20:57,729 --> 00:21:03,580
the people or that might be damaging so

490
00:21:00,429 --> 00:21:07,529
in other words ask what can be inferred

491
00:21:03,580 --> 00:21:10,389
what would people be able to discover

492
00:21:07,529 --> 00:21:13,479
and also pay particular attention to

493
00:21:10,389 --> 00:21:16,508
false inferences because those can often

494
00:21:13,479 --> 00:21:18,700
be much more damaging than for people

495
00:21:16,509 --> 00:21:21,460
then if the anonymize data is released

496
00:21:18,700 --> 00:21:24,489
and probably the biggest takeaway from

497
00:21:21,460 --> 00:21:26,619
this is to realize that anonymization is

498
00:21:24,489 --> 00:21:29,409
not simply a scientific or technical

499
00:21:26,619 --> 00:21:31,449
problem it's a social problem it's a

500
00:21:29,409 --> 00:21:33,820
political problem it's an organizational

501
00:21:31,450 --> 00:21:35,190
problem and it's a human problem and all

502
00:21:33,820 --> 00:21:39,369
of those have to be taken into account

503
00:21:35,190 --> 00:21:43,359
when you do the anonymization and a

504
00:21:39,369 --> 00:21:50,549
parting thought many people see privacy

505
00:21:43,359 --> 00:21:53,408
as an essential human need and the and

506
00:21:50,549 --> 00:21:55,809
the people who want to deny privacy to

507
00:21:53,409 --> 00:21:59,320
others often insist on keeping it

508
00:21:55,809 --> 00:22:01,029
themselves so I think the great Russian

509
00:21:59,320 --> 00:22:03,759
playwright Anton Chekhov said it best

510
00:22:01,029 --> 00:22:05,950
the personal life of every individual is

511
00:22:03,759 --> 00:22:07,690
based on secrecy and perhaps it is

512
00:22:05,950 --> 00:22:10,119
partly for that reason that civilized

513
00:22:07,690 --> 00:22:12,070
man is so nervously anxious that the

514
00:22:10,119 --> 00:22:13,599
personal privacy should be respected and

515
00:22:12,070 --> 00:22:15,330
this was written in the night in the

516
00:22:13,599 --> 00:22:17,929
early 1900s

517
00:22:15,330 --> 00:22:17,929
correctly

518
00:22:19,860 --> 00:22:26,659
[Laughter]

