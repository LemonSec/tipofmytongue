1
00:00:10,470 --> 00:00:18,420
hi welcome to the forever crypto war and

2
00:00:15,200 --> 00:00:19,860
forever figure out how to reset up the

3
00:00:18,420 --> 00:00:25,380
thing that you just set up five minutes

4
00:00:19,860 --> 00:00:28,220
ago it's great to be here this is a

5
00:00:25,380 --> 00:00:32,430
wonderful place to have a good panel and

6
00:00:28,220 --> 00:00:34,050
my panel consists of going down Riana

7
00:00:32,430 --> 00:00:36,210
Pfeffer Korn who is the associate

8
00:00:34,050 --> 00:00:38,280
directory of surveillance and

9
00:00:36,210 --> 00:00:42,540
cybersecurity at the Center for Internet

10
00:00:38,280 --> 00:00:44,910
and Society at Stanford Law School next

11
00:00:42,540 --> 00:00:46,980
down we have Matt blaze who is veteran

12
00:00:44,910 --> 00:00:53,129
of two crypto Wars and professor at

13
00:00:46,980 --> 00:00:56,580
Georgetown actually that was two down in

14
00:00:53,130 --> 00:00:58,380
the middle Daniel J Widener is founding

15
00:00:56,580 --> 00:01:01,080
director of the MIT Internet policy

16
00:00:58,380 --> 00:01:03,060
research initiative principal research

17
00:01:01,080 --> 00:01:04,700
scientists at the MIT computer science

18
00:01:03,060 --> 00:01:07,350
and artificial intelligence lab

19
00:01:04,700 --> 00:01:09,210
previously he was United States deputy

20
00:01:07,350 --> 00:01:11,189
chief technology officer for Internet

21
00:01:09,210 --> 00:01:13,169
policy in the White House a founder of

22
00:01:11,189 --> 00:01:17,520
the Center for Democracy and technology

23
00:01:13,170 --> 00:01:20,250
led the w3c public policy activities and

24
00:01:17,520 --> 00:01:24,390
was the deputy policy director of the EF

25
00:01:20,250 --> 00:01:27,120
F and me I'm John Kallis I am senior

26
00:01:24,390 --> 00:01:29,450
technology fellow at the ACLU I'm also

27
00:01:27,120 --> 00:01:33,030
veteran of two crypto Wars and

28
00:01:29,450 --> 00:01:35,940
co-founder of several crypto oriented

29
00:01:33,030 --> 00:01:38,250
startups so we're going to start off

30
00:01:35,940 --> 00:01:40,380
with short presentations from all of us

31
00:01:38,250 --> 00:01:41,670
and then we're going to talk among

32
00:01:40,380 --> 00:01:45,500
ourselves and then we're going to open

33
00:01:41,670 --> 00:01:45,500
it up and we're gonna start with Rihanna

34
00:01:50,330 --> 00:01:54,470
thanks everybody for coming like this

35
00:01:52,460 --> 00:01:57,440
early in the morning like first session

36
00:01:54,470 --> 00:01:59,060
first day is like a tough sledding here

37
00:01:57,440 --> 00:02:01,039
I want to start what sounds like maybe

38
00:01:59,060 --> 00:02:02,120
kind of an extraneous overview given

39
00:02:01,040 --> 00:02:04,640
that you guys are all veterans

40
00:02:02,120 --> 00:02:05,960
apparently of the crypto Wars of kurt

41
00:02:04,640 --> 00:02:07,790
encryption law in the u.s. we're going

42
00:02:05,960 --> 00:02:09,560
to get into talking about international

43
00:02:07,790 --> 00:02:10,760
law over this panel too I think Danny is

44
00:02:09,560 --> 00:02:13,010
going to talk to us about that

45
00:02:10,759 --> 00:02:15,500
but if United States law we're not the

46
00:02:13,010 --> 00:02:17,510
way that it is if it did not presently

47
00:02:15,500 --> 00:02:19,760
afford US companies the freedom around

48
00:02:17,510 --> 00:02:21,200
the encryption that it does we wouldn't

49
00:02:19,760 --> 00:02:23,899
be having this debate because we

50
00:02:21,200 --> 00:02:27,380
wouldn't have the iPhone and whatsapp

51
00:02:23,900 --> 00:02:30,560
and signal etc that we have today so

52
00:02:27,380 --> 00:02:33,200
currently strong encryption which I mean

53
00:02:30,560 --> 00:02:35,959
encryption that has not been undermined

54
00:02:33,200 --> 00:02:38,170
at the behest of any government is legal

55
00:02:35,959 --> 00:02:41,150
in the United States at least for now

56
00:02:38,170 --> 00:02:41,660
as you probably know it wasn't always

57
00:02:41,150 --> 00:02:43,760
the case

58
00:02:41,660 --> 00:02:46,579
encryption was regulated as a munition

59
00:02:43,760 --> 00:02:48,350
like a bomb up until the late 90s it was

60
00:02:46,580 --> 00:02:49,940
subject to certain export controls it's

61
00:02:48,350 --> 00:02:51,920
still regulated but now under the

62
00:02:49,940 --> 00:02:53,900
Commerce Department and so things are a

63
00:02:51,920 --> 00:02:55,609
bit more chill than they used to be but

64
00:02:53,900 --> 00:02:57,019
the idea of export grade crypto is that

65
00:02:55,610 --> 00:02:58,760
the Americans should have good security

66
00:02:57,019 --> 00:03:01,250
and the NSA should be able to pone

67
00:02:58,760 --> 00:03:03,109
everybody else so we saw stuff like 40

68
00:03:01,250 --> 00:03:04,730
bit session keys which now it takes like

69
00:03:03,110 --> 00:03:08,180
a decoder ring out of a cracker jack box

70
00:03:04,730 --> 00:03:10,700
to be able to crack and we have seen

71
00:03:08,180 --> 00:03:12,910
years and years later you can attribute

72
00:03:10,700 --> 00:03:16,280
the Freak log jam and drone attacks from

73
00:03:12,910 --> 00:03:18,049
2015-2016 to export grade crypto so it

74
00:03:16,280 --> 00:03:20,150
turned out that this was maybe kind of a

75
00:03:18,050 --> 00:03:23,330
nearsighted policy approach from behalf

76
00:03:20,150 --> 00:03:25,310
of the US government the 1990s gave us

77
00:03:23,330 --> 00:03:27,050
something else that's relevant today's

78
00:03:25,310 --> 00:03:28,760
encryption debate which is the

79
00:03:27,050 --> 00:03:31,760
communications assistance for Law

80
00:03:28,760 --> 00:03:33,620
Enforcement Act of 1994 or kaliya for

81
00:03:31,760 --> 00:03:36,079
short which was passed because even back

82
00:03:33,620 --> 00:03:38,209
then law enforcement was concerned about

83
00:03:36,080 --> 00:03:40,519
the going dark problem having their

84
00:03:38,209 --> 00:03:42,470
capabilities to investigate go dark do

85
00:03:40,519 --> 00:03:45,080
the advent of digital telephony and the

86
00:03:42,470 --> 00:03:47,030
internet so kulia mandates wiretap

87
00:03:45,080 --> 00:03:48,769
ability for certain regulated and these

88
00:03:47,030 --> 00:03:51,380
basically telecommunications providers

89
00:03:48,769 --> 00:03:53,989
as well as whoever the FCC decides is

90
00:03:51,380 --> 00:03:55,820
now providing essentially a substantial

91
00:03:53,989 --> 00:03:58,160
replacement for traditional local phone

92
00:03:55,820 --> 00:03:59,510
service and that now includes an two

93
00:03:58,160 --> 00:04:01,980
eight or connected VoIP as well as

94
00:03:59,510 --> 00:04:03,690
broadband their net theirs

95
00:04:01,980 --> 00:04:05,819
important limitations on CLIA for one

96
00:04:03,690 --> 00:04:07,680
thing even covered any of these the

97
00:04:05,819 --> 00:04:10,470
government cannot dictate how they

98
00:04:07,680 --> 00:04:12,390
comply with this mandate of making their

99
00:04:10,470 --> 00:04:13,799
networks by our table you have to comply

100
00:04:12,390 --> 00:04:15,809
with the goal the government cannot tell

101
00:04:13,799 --> 00:04:18,418
them how in addition there are a couple

102
00:04:15,810 --> 00:04:21,209
of very important compromises that are

103
00:04:18,418 --> 00:04:22,440
part of the final statute one is what

104
00:04:21,209 --> 00:04:25,260
we'll call the information services

105
00:04:22,440 --> 00:04:28,500
carve out Kalia does not apply at all to

106
00:04:25,260 --> 00:04:31,380
so-called information services which

107
00:04:28,500 --> 00:04:33,660
means email chat apps social media

108
00:04:31,380 --> 00:04:35,850
websites all of those are free to design

109
00:04:33,660 --> 00:04:37,740
encryption however they want they do not

110
00:04:35,850 --> 00:04:39,870
have to comply with this wiretap ability

111
00:04:37,740 --> 00:04:41,400
mandate and the other is what we'll call

112
00:04:39,870 --> 00:04:42,990
the encryption carve-out which says that

113
00:04:41,400 --> 00:04:45,239
even though entities that are covered by

114
00:04:42,990 --> 00:04:47,669
Kalia so telco carriers primarily are

115
00:04:45,240 --> 00:04:49,650
free to encrypt communications and throw

116
00:04:47,669 --> 00:04:51,840
away the keys to decrypt they only have

117
00:04:49,650 --> 00:04:53,909
to decrypt if they both provided the

118
00:04:51,840 --> 00:04:55,530
encryption themselves and they possess

119
00:04:53,910 --> 00:04:56,520
the information necessary to decrypt

120
00:04:55,530 --> 00:04:58,710
they don't have to keep that information

121
00:04:56,520 --> 00:05:00,919
and that was a compromise that was

122
00:04:58,710 --> 00:05:03,359
reached because civil libertarians and

123
00:05:00,919 --> 00:05:05,099
security experts showed up and pushed

124
00:05:03,360 --> 00:05:08,099
for these limitations during the

125
00:05:05,100 --> 00:05:09,450
negotiations over the building which so

126
00:05:08,099 --> 00:05:11,789
the bottom line is that Kalia does not

127
00:05:09,450 --> 00:05:13,979
require Apple or Facebook or signal or

128
00:05:11,789 --> 00:05:16,620
whoever to build an exceptional access

129
00:05:13,979 --> 00:05:18,180
as demanded by members of US government

130
00:05:16,620 --> 00:05:20,370
and the government cannot restrain the

131
00:05:18,180 --> 00:05:22,860
innovation of secure technologies under

132
00:05:20,370 --> 00:05:24,780
Kalia if Kalia had required those things

133
00:05:22,860 --> 00:05:25,560
back in 1994 we wouldn't be having this

134
00:05:24,780 --> 00:05:28,710
conversation

135
00:05:25,560 --> 00:05:30,690
now it's 2020 and encryption is in

136
00:05:28,710 --> 00:05:32,789
ubiquitous use by consumers because it's

137
00:05:30,690 --> 00:05:35,550
built-in by default to popular devices

138
00:05:32,789 --> 00:05:37,740
and applications which is exactly what

139
00:05:35,550 --> 00:05:38,940
United States law allows despite the

140
00:05:37,740 --> 00:05:41,010
fact that you'll hear our Attorney

141
00:05:38,940 --> 00:05:42,389
General and even members of the Senate

142
00:05:41,010 --> 00:05:44,490
who should know better who should know

143
00:05:42,389 --> 00:05:46,710
what CLIA says talking about how Apple

144
00:05:44,490 --> 00:05:48,300
and Facebook are creating lawless spaces

145
00:05:46,710 --> 00:05:49,919
and acting above the law but not above

146
00:05:48,300 --> 00:05:52,889
the law they're doing exactly what the

147
00:05:49,919 --> 00:05:54,870
law allows them to do although not for

148
00:05:52,889 --> 00:05:56,070
lack of trying on the part of federal

149
00:05:54,870 --> 00:05:58,260
law enforcement agencies they've been

150
00:05:56,070 --> 00:06:00,090
trying to roll back those compromises in

151
00:05:58,260 --> 00:06:02,219
CLIA that I talked about pretty much

152
00:06:00,090 --> 00:06:03,900
ever since it was passed the reason that

153
00:06:02,220 --> 00:06:05,460
in that two-way TV connected VoIP and

154
00:06:03,900 --> 00:06:08,159
broadband turn that are now part of

155
00:06:05,460 --> 00:06:10,739
Callias mandate are because federal law

156
00:06:08,160 --> 00:06:13,229
enforcement agencies pushed for them to

157
00:06:10,740 --> 00:06:15,040
be made part of it by the FCC which pass

158
00:06:13,229 --> 00:06:16,690
to rule in 2005

159
00:06:15,040 --> 00:06:18,190
expanding class coverage to include them

160
00:06:16,690 --> 00:06:20,110
even though they sound like they should

161
00:06:18,190 --> 00:06:21,310
count as information services the FCC

162
00:06:20,110 --> 00:06:24,870
basically said well to the extent that

163
00:06:21,310 --> 00:06:27,250
they act like telcos they're covered and

164
00:06:24,870 --> 00:06:29,110
federal agencies have pushed for even

165
00:06:27,250 --> 00:06:30,850
more extreme plans multiple times since

166
00:06:29,110 --> 00:06:32,770
then over the last decade that would

167
00:06:30,850 --> 00:06:34,300
have undermined the kaliya compromise by

168
00:06:32,770 --> 00:06:36,310
requiring that encrypted messaging

169
00:06:34,300 --> 00:06:38,410
services be backdoored have a way to

170
00:06:36,310 --> 00:06:40,660
decrypt all encrypted messages and get

171
00:06:38,410 --> 00:06:43,060
fines if they didn't cooperate those

172
00:06:40,660 --> 00:06:45,490
proposals have failed but the takeaway

173
00:06:43,060 --> 00:06:47,170
from those if you ask me is that law

174
00:06:45,490 --> 00:06:49,240
enforcement has a long track record of

175
00:06:47,170 --> 00:06:50,830
disregarding the compromises that they

176
00:06:49,240 --> 00:06:52,780
supposedly agreed to when it comes to

177
00:06:50,830 --> 00:06:54,880
encryption and surveillance so when you

178
00:06:52,780 --> 00:06:56,440
hear law enforcement officials say the

179
00:06:54,880 --> 00:06:58,180
word compromised in the encryption

180
00:06:56,440 --> 00:07:00,730
debate you should probably be kind of

181
00:06:58,180 --> 00:07:02,500
skeptical of that so that's clear

182
00:07:00,730 --> 00:07:04,180
we're the best encrypted devices clears

183
00:07:02,500 --> 00:07:07,600
about telco carriers devices are not

184
00:07:04,180 --> 00:07:09,400
subject to Kalia there's no Express law

185
00:07:07,600 --> 00:07:10,930
compelling a company to decrypt data

186
00:07:09,400 --> 00:07:13,840
that it doesn't hold that stored on

187
00:07:10,930 --> 00:07:15,310
end-users device it used to be that the

188
00:07:13,840 --> 00:07:16,750
Department of Justice and the FBI would

189
00:07:15,310 --> 00:07:19,630
try using a combination of search

190
00:07:16,750 --> 00:07:21,730
warrants plus orders under a 1789

191
00:07:19,630 --> 00:07:24,730
statute called the all writs Act to try

192
00:07:21,730 --> 00:07:26,170
and compel companies device makers to

193
00:07:24,730 --> 00:07:28,120
unlock devices for law enforcement and

194
00:07:26,170 --> 00:07:29,920
up until late 2015

195
00:07:28,120 --> 00:07:31,780
courts were signing these orders in

196
00:07:29,920 --> 00:07:33,430
Google and Apple were going along with

197
00:07:31,780 --> 00:07:35,020
it and there hadn't really been a lot of

198
00:07:33,430 --> 00:07:37,450
analysis about whether this was actually

199
00:07:35,020 --> 00:07:38,650
what the law required we finally saw in

200
00:07:37,450 --> 00:07:40,450
the pending come out at the end of

201
00:07:38,650 --> 00:07:42,429
February of 2016 from a federal

202
00:07:40,450 --> 00:07:45,039
magistrate judge in Brooklyn that's the

203
00:07:42,430 --> 00:07:46,300
lesser known Apple vs. FBI case which

204
00:07:45,040 --> 00:07:47,980
said that

205
00:07:46,300 --> 00:07:52,090
Kalea is a comprehensive statutory

206
00:07:47,980 --> 00:07:54,160
scheme around who has to provide access

207
00:07:52,090 --> 00:07:56,109
to law enforcement it does not have her

208
00:07:54,160 --> 00:07:58,900
Apple Apple is not part of that scheme

209
00:07:56,110 --> 00:08:01,510
and you can't use the all writs act to

210
00:07:58,900 --> 00:08:02,469
trump kaliya the government appeal but

211
00:08:01,510 --> 00:08:04,539
they dropped the case because the

212
00:08:02,470 --> 00:08:06,480
defendant magically remembered the

213
00:08:04,540 --> 00:08:08,560
passcode to his phone good timing that

214
00:08:06,480 --> 00:08:10,000
opinion came out less than two weeks

215
00:08:08,560 --> 00:08:12,490
after the original order in the

216
00:08:10,000 --> 00:08:14,290
better-known San Bernardino Apple versus

217
00:08:12,490 --> 00:08:16,600
FBI case originally there wasn't order

218
00:08:14,290 --> 00:08:18,340
that was a required Apple to build a

219
00:08:16,600 --> 00:08:20,200
custom version of iOS that would roll

220
00:08:18,340 --> 00:08:21,429
back several of the security protections

221
00:08:20,200 --> 00:08:24,760
not about encryption itself with other

222
00:08:21,430 --> 00:08:26,770
security protections built into iOS to

223
00:08:24,760 --> 00:08:28,000
install that on the San Bernardino

224
00:08:26,770 --> 00:08:29,710
shooters iPhone

225
00:08:28,000 --> 00:08:31,390
member clear prohibits the US government

226
00:08:29,710 --> 00:08:32,978
from telling even covered entities to

227
00:08:31,390 --> 00:08:35,020
adopt a specific design for complying

228
00:08:32,979 --> 00:08:37,510
with the law so even if Apple had been

229
00:08:35,020 --> 00:08:39,010
subject to CLIA which they were not in

230
00:08:37,510 --> 00:08:40,780
this context requiring Apple to create

231
00:08:39,010 --> 00:08:42,789
an implemental workaround for iPhone

232
00:08:40,780 --> 00:08:43,510
security is exactly what kaleo's intend

233
00:08:42,789 --> 00:08:45,730
to prohibit

234
00:08:43,510 --> 00:08:47,170
so two weeks after that when the judge

235
00:08:45,730 --> 00:08:49,240
in Brooklyn came out with this opinion

236
00:08:47,170 --> 00:08:50,650
he was signaling very clearly in the

237
00:08:49,240 --> 00:08:52,630
direction of the San Bernardino Court

238
00:08:50,650 --> 00:08:54,970
saying you know here's what CLIA doesn't

239
00:08:52,630 --> 00:08:56,110
doesn't do here's how he thinks that the

240
00:08:54,970 --> 00:08:57,400
court should come out of that but we

241
00:08:56,110 --> 00:08:59,470
think a decision on the merits

242
00:08:57,400 --> 00:09:02,260
ultimately in the San Bernardino case

243
00:08:59,470 --> 00:09:03,940
because on literally the eve of the

244
00:09:02,260 --> 00:09:05,110
court hearing that was supposed to

245
00:09:03,940 --> 00:09:07,420
happen to think about the merits of

246
00:09:05,110 --> 00:09:08,890
these legal arguments the government

247
00:09:07,420 --> 00:09:10,449
announced that they'd bought an exploit

248
00:09:08,890 --> 00:09:11,830
from the no third party for what turned

249
00:09:10,450 --> 00:09:14,050
out to be around nine hundred thousand

250
00:09:11,830 --> 00:09:17,110
taxpayer dollars to get into that phone

251
00:09:14,050 --> 00:09:18,760
and so against this backdrop apples

252
00:09:17,110 --> 00:09:20,380
continued to reengineer their devices to

253
00:09:18,760 --> 00:09:23,080
make it more difficult to decrypt data

254
00:09:20,380 --> 00:09:25,300
same for Google for Android phones will

255
00:09:23,080 --> 00:09:27,700
we see a rematch over the Pensacola

256
00:09:25,300 --> 00:09:28,260
Naval Base shooters iPhone unclear stay

257
00:09:27,700 --> 00:09:30,580
tuned

258
00:09:28,260 --> 00:09:32,950
so that's encrypted devices web

259
00:09:30,580 --> 00:09:34,630
encrypted messaging well I said chat

260
00:09:32,950 --> 00:09:36,460
apps count as in information services

261
00:09:34,630 --> 00:09:39,490
under Kalia so they don't need to follow

262
00:09:36,460 --> 00:09:41,890
Kalia the way that telco carriers do the

263
00:09:39,490 --> 00:09:43,900
Deo jailer the lesson from doing the San

264
00:09:41,890 --> 00:09:45,220
Bernardino case in public and open court

265
00:09:43,900 --> 00:09:47,110
and that was if they're good do these

266
00:09:45,220 --> 00:09:49,210
going dark type cases to try and compel

267
00:09:47,110 --> 00:09:51,310
companies to change their encryption for

268
00:09:49,210 --> 00:09:53,440
law enforcement access purposes they

269
00:09:51,310 --> 00:09:57,010
should do that under seal and do this

270
00:09:53,440 --> 00:09:59,820
only in sealed cases so when they from

271
00:09:57,010 --> 00:10:02,230
what we know from reports leaked

272
00:09:59,820 --> 00:10:04,839
information leaked to Reuters reporters

273
00:10:02,230 --> 00:10:07,720
in 2018 the government tried to compel

274
00:10:04,839 --> 00:10:09,940
Facebook in 2018 in a case in federal

275
00:10:07,720 --> 00:10:12,460
court out in Fresno to change the

276
00:10:09,940 --> 00:10:14,410
encryption for messenger voice calls

277
00:10:12,460 --> 00:10:16,270
which can be intend encrypted I don't

278
00:10:14,410 --> 00:10:20,560
think that and intended turn on by

279
00:10:16,270 --> 00:10:22,390
default tried to make them change the

280
00:10:20,560 --> 00:10:24,849
encryption and messenger we don't know

281
00:10:22,390 --> 00:10:27,490
exactly what they were asking to do we

282
00:10:24,850 --> 00:10:29,170
don't know what exactly happened or

283
00:10:27,490 --> 00:10:31,180
allegedly the court denied that motion

284
00:10:29,170 --> 00:10:32,620
by the government but we don't know what

285
00:10:31,180 --> 00:10:33,880
the government's legal argument was we

286
00:10:32,620 --> 00:10:36,000
don't know what laws they invokes we

287
00:10:33,880 --> 00:10:38,589
don't know what the courts reasoning was

288
00:10:36,000 --> 00:10:40,690
we can just infer that Facebook

289
00:10:38,589 --> 00:10:41,900
prevailed in that case not only because

290
00:10:40,690 --> 00:10:43,430
of the leaks to

291
00:10:41,900 --> 00:10:45,380
but also because Facebook has now

292
00:10:43,430 --> 00:10:47,329
announced plans to roll out end to end

293
00:10:45,380 --> 00:10:49,250
encryption across all of its messaging

294
00:10:47,330 --> 00:10:52,820
services the way that whatsapp currently

295
00:10:49,250 --> 00:10:55,670
is already by default so in summary

296
00:10:52,820 --> 00:10:58,070
these cases suggest that under current

297
00:10:55,670 --> 00:10:59,630
US law encrypted smartphone and an

298
00:10:58,070 --> 00:11:01,550
encrypted messaging providers can't be

299
00:10:59,630 --> 00:11:03,770
forced to change their encryption to

300
00:11:01,550 --> 00:11:05,150
allow law enforcement access those are

301
00:11:03,770 --> 00:11:06,680
all just the level federal court orders

302
00:11:05,150 --> 00:11:08,839
no this has been tested in courts of

303
00:11:06,680 --> 00:11:09,979
appeals much less the Supreme Court but

304
00:11:08,839 --> 00:11:12,440
that's the state of the law as it

305
00:11:09,980 --> 00:11:14,810
currently stands the United States so if

306
00:11:12,440 --> 00:11:16,550
that's the law as it is it is possible

307
00:11:14,810 --> 00:11:18,469
for Congress to pass another law change

308
00:11:16,550 --> 00:11:19,640
that we might see that happen or at

309
00:11:18,470 --> 00:11:20,480
least some efforts to make that happen

310
00:11:19,640 --> 00:11:22,910
in 2020

311
00:11:20,480 --> 00:11:24,820
especially under so there's some reports

312
00:11:22,910 --> 00:11:27,350
about a new bill that may be coming out

313
00:11:24,820 --> 00:11:29,540
sponsored by senators Lindsey Graham and

314
00:11:27,350 --> 00:11:32,510
Richard Blumenthal that would curtail

315
00:11:29,540 --> 00:11:35,750
section 230 immunity for child sex abuse

316
00:11:32,510 --> 00:11:37,490
material or c-sam on services on online

317
00:11:35,750 --> 00:11:38,600
platforms that's the law that says that

318
00:11:37,490 --> 00:11:40,520
online platforms can't be held liable

319
00:11:38,600 --> 00:11:42,320
for what their users saying do on the

320
00:11:40,520 --> 00:11:43,699
service this bill would change that part

321
00:11:42,320 --> 00:11:45,470
of section 230 wouldn't cover

322
00:11:43,700 --> 00:11:46,970
smartphones but the whites drafted an

323
00:11:45,470 --> 00:11:49,160
include messaging apps email cloud

324
00:11:46,970 --> 00:11:51,170
storage etc so all of the information

325
00:11:49,160 --> 00:11:52,550
services that Kalia currently says are

326
00:11:51,170 --> 00:11:54,560
free to design their encryption however

327
00:11:52,550 --> 00:11:55,699
they want on its face this bill is not

328
00:11:54,560 --> 00:11:57,349
about encryption it's about establishing

329
00:11:55,700 --> 00:11:59,510
a commission that would come up with a

330
00:11:57,350 --> 00:12:01,160
set of guidelines or best practices for

331
00:11:59,510 --> 00:12:03,110
companies to adhere to as a safe harbor

332
00:12:01,160 --> 00:12:04,939
in order to keep their 2:30 immunity but

333
00:12:03,110 --> 00:12:06,589
concretion is really the elephant in the

334
00:12:04,940 --> 00:12:08,480
room for this bill it's easy to foresee

335
00:12:06,589 --> 00:12:10,130
that those guidelines would condemn

336
00:12:08,480 --> 00:12:11,240
encryption designs that don't have an

337
00:12:10,130 --> 00:12:13,850
access mechanism for law enforcement

338
00:12:11,240 --> 00:12:16,250
built-in so it's a message to Facebook

339
00:12:13,850 --> 00:12:18,170
and to signal and so forth to give law

340
00:12:16,250 --> 00:12:20,029
enforcement a way to see the content of

341
00:12:18,170 --> 00:12:21,740
supposedly intend encrypted chats or be

342
00:12:20,029 --> 00:12:23,839
prepared to potentially pay through the

343
00:12:21,740 --> 00:12:25,580
nose through legal liability legal

344
00:12:23,839 --> 00:12:27,620
exposure for doing exactly what the law

345
00:12:25,580 --> 00:12:30,500
allows them to do so that's a different

346
00:12:27,620 --> 00:12:33,350
approach from previous attempts on

347
00:12:30,500 --> 00:12:35,300
behalf of the FBI FBI DOJ it's building

348
00:12:33,350 --> 00:12:37,580
on a successful passage of the cesta

349
00:12:35,300 --> 00:12:39,680
FASTA law which also enabled away at

350
00:12:37,580 --> 00:12:41,750
section 230 immunity and that's what the

351
00:12:39,680 --> 00:12:43,699
sort of the current zeitgeist against

352
00:12:41,750 --> 00:12:45,680
big tech and against section 230 has

353
00:12:43,700 --> 00:12:47,240
arguably gotten us because nothing says

354
00:12:45,680 --> 00:12:48,650
sticking it to big tech and standing up

355
00:12:47,240 --> 00:12:50,540
for the little guy like penalizing

356
00:12:48,650 --> 00:12:52,030
companies for providing good privacy and

357
00:12:50,540 --> 00:12:55,089
data security

358
00:12:52,030 --> 00:12:57,850
that's it from me you can at me if you

359
00:12:55,090 --> 00:13:10,990
want to know let me hand over to Matt I

360
00:12:57,850 --> 00:13:14,200
think I'll just stay here so I'm Matt

361
00:13:10,990 --> 00:13:17,820
Blais I was introduced as as the whole

362
00:13:14,200 --> 00:13:23,230
panel is as a veteran of two crypto Wars

363
00:13:17,820 --> 00:13:24,490
crypto war one was the 1990s and war two

364
00:13:23,230 --> 00:13:26,140
which were still in the middle

365
00:13:24,490 --> 00:13:28,150
during crypto war one we didn't know

366
00:13:26,140 --> 00:13:32,680
that it was gonna be necessary to number

367
00:13:28,150 --> 00:13:34,720
the crypto Wars but it turned out well

368
00:13:32,680 --> 00:13:37,569
what what's the difference between the

369
00:13:34,720 --> 00:13:40,060
crypto Wars is this one endless war well

370
00:13:37,570 --> 00:13:43,300
I think if we had to come up with a

371
00:13:40,060 --> 00:13:49,290
dividing line in crypto war one in the

372
00:13:43,300 --> 00:13:54,089
1990s the advocates of crypto

373
00:13:49,290 --> 00:13:56,920
cryptography and security were

374
00:13:54,090 --> 00:13:58,420
essentially visionaries or had to be a

375
00:13:56,920 --> 00:14:00,819
little bit visionary and had to have

376
00:13:58,420 --> 00:14:04,360
some faith that computers and the

377
00:14:00,820 --> 00:14:07,120
internet and electronic communication

378
00:14:04,360 --> 00:14:11,589
and the security of those things was

379
00:14:07,120 --> 00:14:12,960
going to be important any day now and we

380
00:14:11,589 --> 00:14:14,700
you know we didn't really even

381
00:14:12,960 --> 00:14:16,890
completely believe it ourselves

382
00:14:14,700 --> 00:14:20,980
certainly nobody would have predicted

383
00:14:16,890 --> 00:14:26,860
what the 21st century would have looked

384
00:14:20,980 --> 00:14:30,610
like back in 1990 or so and encryption

385
00:14:26,860 --> 00:14:32,860
to the extent that it was used was a

386
00:14:30,610 --> 00:14:35,980
pretty specialized thing it was mostly

387
00:14:32,860 --> 00:14:38,589
in the realm of military government

388
00:14:35,980 --> 00:14:41,350
communications was used by industry to

389
00:14:38,589 --> 00:14:44,320
some extent the dominant cipher

390
00:14:41,350 --> 00:14:48,460
algorithm was the data encryption

391
00:14:44,320 --> 00:14:50,530
standard with a 56 bit key which was you

392
00:14:48,460 --> 00:14:53,490
know really on the margins even then of

393
00:14:50,530 --> 00:14:58,800
what was vulnerable to exhaustive search

394
00:14:53,490 --> 00:15:02,260
and most importantly it was regulated

395
00:14:58,800 --> 00:15:04,060
essentially as a munition under the arms

396
00:15:02,260 --> 00:15:08,080
control

397
00:15:04,060 --> 00:15:10,180
a anti proliferation legal regime and

398
00:15:08,080 --> 00:15:12,160
what that meant was that it was

399
00:15:10,180 --> 00:15:14,890
perfectly legal to do all the encryption

400
00:15:12,160 --> 00:15:19,180
you wanted within the United States but

401
00:15:14,890 --> 00:15:22,300
if you wanted to export a product

402
00:15:19,180 --> 00:15:25,150
including software that used encryption

403
00:15:22,300 --> 00:15:27,640
you'd need a license the same type of

404
00:15:25,150 --> 00:15:33,370
license you'd need to export military

405
00:15:27,640 --> 00:15:34,930
weapons to a potential adversary and

406
00:15:33,370 --> 00:15:37,660
essentially they wouldn't give you this

407
00:15:34,930 --> 00:15:39,760
license if the encryption worked so you

408
00:15:37,660 --> 00:15:42,130
could get a you could easily get this

409
00:15:39,760 --> 00:15:44,080
license with you know with encryption

410
00:15:42,130 --> 00:15:47,080
with a 40 bit key trivial to

411
00:15:44,080 --> 00:15:50,170
exhaustively search but beyond that it

412
00:15:47,080 --> 00:15:52,270
was it was pretty hard and so the

413
00:15:50,170 --> 00:15:54,550
advocates of encryption had to sort of

414
00:15:52,270 --> 00:15:56,939
make two cases the first is hey this is

415
00:15:54,550 --> 00:15:59,170
going to be important someday which

416
00:15:56,940 --> 00:16:02,700
industry even didn't really believe

417
00:15:59,170 --> 00:16:06,579
until pretty late in the decade and

418
00:16:02,700 --> 00:16:09,400
secondly we need to change this law to

419
00:16:06,580 --> 00:16:12,130
allow for interoperable standards that

420
00:16:09,400 --> 00:16:13,900
really provide strong encryption in any

421
00:16:12,130 --> 00:16:16,180
kind of software that we're going to use

422
00:16:13,900 --> 00:16:18,040
including open source software which was

423
00:16:16,180 --> 00:16:22,000
sort of inherently exported as soon as

424
00:16:18,040 --> 00:16:24,640
you put it out on the internet so the

425
00:16:22,000 --> 00:16:29,020
government came up with what must have

426
00:16:24,640 --> 00:16:31,870
looked like a beautiful solution that

427
00:16:29,020 --> 00:16:34,090
would would that you could almost hear

428
00:16:31,870 --> 00:16:38,890
them congratulating themselves on how

429
00:16:34,090 --> 00:16:40,750
clever this was in 1991 and 1992 they

430
00:16:38,890 --> 00:16:43,120
designed something that's popularly

431
00:16:40,750 --> 00:16:44,470
known as the Clipper Chip but was

432
00:16:43,120 --> 00:16:47,020
officially called the escrowed

433
00:16:44,470 --> 00:16:49,840
encryption standard and the idea was

434
00:16:47,020 --> 00:16:53,110
that this was a cipher embedded in

435
00:16:49,840 --> 00:16:56,890
hardware that vendors of encryption

436
00:16:53,110 --> 00:16:59,680
products could embed in their in their

437
00:16:56,890 --> 00:17:02,199
products that would provide an 80 bit

438
00:16:59,680 --> 00:17:04,450
key so much stronger than the data

439
00:17:02,200 --> 00:17:07,000
encryption standard probably good enough

440
00:17:04,450 --> 00:17:10,420
to resist exhaustive search into you

441
00:17:07,000 --> 00:17:12,220
know well into the 21st century but with

442
00:17:10,420 --> 00:17:13,540
a little bit of a catch which is that oh

443
00:17:12,220 --> 00:17:14,829
by the way a copy of the key gets sent

444
00:17:13,540 --> 00:17:16,250
to the government they can decrypt it if

445
00:17:14,829 --> 00:17:20,599
they want

446
00:17:16,250 --> 00:17:22,880
this was controversial among the people

447
00:17:20,599 --> 00:17:26,270
who cared about encryption and so during

448
00:17:22,880 --> 00:17:32,809
the 1990s we basically were emboldened

449
00:17:26,270 --> 00:17:38,420
by the Clipper Chip and trying to fight

450
00:17:32,809 --> 00:17:41,510
to get the export laws changed crypto

451
00:17:38,420 --> 00:17:45,710
war ii started after we won crypto war

452
00:17:41,510 --> 00:17:47,809
one clipper trip died the export laws

453
00:17:45,710 --> 00:17:49,670
were essentially effectively rolled back

454
00:17:47,809 --> 00:17:52,840
so that strong encryption and consumer

455
00:17:49,670 --> 00:17:55,720
products is legal and can be exported

456
00:17:52,840 --> 00:17:59,870
you know for all practical purposes

457
00:17:55,720 --> 00:18:03,140
freely and you know we're very happily

458
00:17:59,870 --> 00:18:04,639
one tellingly even after September 11th

459
00:18:03,140 --> 00:18:09,200
when the government could have had

460
00:18:04,640 --> 00:18:12,580
anything they wanted in the encryption

461
00:18:09,200 --> 00:18:18,290
liberalisation didn't get rolled back

462
00:18:12,580 --> 00:18:20,540
shortly thereafter the FBI started to

463
00:18:18,290 --> 00:18:22,730
become the only organization on earth

464
00:18:20,540 --> 00:18:29,659
complaining that computer security is

465
00:18:22,730 --> 00:18:35,420
too good and has been lobbying for a

466
00:18:29,660 --> 00:18:37,400
rollback to restricted encryption not in

467
00:18:35,420 --> 00:18:40,280
the form of export laws but in the form

468
00:18:37,400 --> 00:18:43,790
of some kind of mandate whether by law

469
00:18:40,280 --> 00:18:47,590
or de-facto to allow for some sort of

470
00:18:43,790 --> 00:18:51,170
key escrow or equivalent mechanism in

471
00:18:47,590 --> 00:18:52,970
products that we use so an interesting

472
00:18:51,170 --> 00:18:55,960
distinction between crypto war one and

473
00:18:52,970 --> 00:18:59,150
crypto war two is that in crypto war one

474
00:18:55,960 --> 00:19:01,730
we the people who cared about strong

475
00:18:59,150 --> 00:19:03,290
encryption and security and privacy were

476
00:19:01,730 --> 00:19:06,800
the ones asking for a change

477
00:19:03,290 --> 00:19:09,139
in crypto war two we're trying to fight

478
00:19:06,800 --> 00:19:12,020
for the status quo and I think that's

479
00:19:09,140 --> 00:19:15,850
you know gives us a you know very

480
00:19:12,020 --> 00:19:18,080
different dynamic in the way this is

481
00:19:15,850 --> 00:19:20,750
playing out we are in a position of

482
00:19:18,080 --> 00:19:23,720
strength at the moment although you know

483
00:19:20,750 --> 00:19:26,600
that could that could change in that no

484
00:19:23,720 --> 00:19:28,930
news is good news on this so what I want

485
00:19:26,600 --> 00:19:36,580
to do is is make the case very brief

486
00:19:28,930 --> 00:19:39,970
for why the status quo is the the only

487
00:19:36,580 --> 00:19:43,780
tenable approach why allowing

488
00:19:39,970 --> 00:19:46,570
unrestricted encryption and is is really

489
00:19:43,780 --> 00:19:49,870
all we can do the first is I think

490
00:19:46,570 --> 00:19:53,230
everybody here believes this is really

491
00:19:49,870 --> 00:19:57,429
important computer security is not in

492
00:19:53,230 --> 00:19:59,680
fact too good in 2020 that it's actually

493
00:19:57,430 --> 00:20:02,460
kind of a mess and encryption is one of

494
00:19:59,680 --> 00:20:05,650
the very few tools we have that works

495
00:20:02,460 --> 00:20:07,240
and so the ability taking away one of

496
00:20:05,650 --> 00:20:09,820
these tools or making one of these tools

497
00:20:07,240 --> 00:20:14,140
more complicated or more expensive would

498
00:20:09,820 --> 00:20:16,480
be a disaster for Internet Security and

499
00:20:14,140 --> 00:20:19,710
for the security of the entire connected

500
00:20:16,480 --> 00:20:22,030
world commerce personal privacy and

501
00:20:19,710 --> 00:20:24,550
everything else I don't think that's a

502
00:20:22,030 --> 00:20:27,340
difficult case to make here the second

503
00:20:24,550 --> 00:20:30,940
is that any kind of key escrow mechanism

504
00:20:27,340 --> 00:20:33,580
is going to be designed from the same

505
00:20:30,940 --> 00:20:36,160
kind of position of ignorance of what

506
00:20:33,580 --> 00:20:39,220
the future of electronic communications

507
00:20:36,160 --> 00:20:42,940
looks like that clipper was designed

508
00:20:39,220 --> 00:20:47,320
with in the early 1990s so I'd like to

509
00:20:42,940 --> 00:20:50,080
go back to 1992 when clipper was

510
00:20:47,320 --> 00:20:52,240
designed 1993 when clipper was released

511
00:20:50,080 --> 00:20:54,820
to the public and look at what some of

512
00:20:52,240 --> 00:20:58,540
the very reasonable engineering design

513
00:20:54,820 --> 00:21:02,939
constraints that that system was built

514
00:20:58,540 --> 00:21:06,629
under the first was that in most

515
00:21:02,940 --> 00:21:12,700
encryption would be done in hardware and

516
00:21:06,630 --> 00:21:15,310
that adding $20 to the price of a device

517
00:21:12,700 --> 00:21:17,890
like a phone in order to be able to make

518
00:21:15,310 --> 00:21:22,750
it secure would be something completely

519
00:21:17,890 --> 00:21:24,820
reasonable to do the second so that

520
00:21:22,750 --> 00:21:27,150
essentially eliminates software

521
00:21:24,820 --> 00:21:29,290
encryption for anything and certainly

522
00:21:27,150 --> 00:21:31,720
interoperable software encryption right

523
00:21:29,290 --> 00:21:34,600
off the bat the world very quickly

524
00:21:31,720 --> 00:21:36,670
changed to a much more software oriented

525
00:21:34,600 --> 00:21:39,159
world we're adding Hardware as a

526
00:21:36,670 --> 00:21:40,930
requirement to do any encryption would

527
00:21:39,160 --> 00:21:44,110
be a ludicrous thing to

528
00:21:40,930 --> 00:21:46,660
require but back in the early 1990s that

529
00:21:44,110 --> 00:21:48,669
wasn't nearly as clear second is what's

530
00:21:46,660 --> 00:21:50,830
the killer app for this well the killer

531
00:21:48,670 --> 00:21:53,380
app was voice communication on plan

532
00:21:50,830 --> 00:21:56,770
blind phones that's how most

533
00:21:53,380 --> 00:21:58,750
communication in real time happened in

534
00:21:56,770 --> 00:22:00,760
the early 1990s I worked for a large

535
00:21:58,750 --> 00:22:02,830
company called the telephone company

536
00:22:00,760 --> 00:22:04,150
that had that as their business model

537
00:22:02,830 --> 00:22:08,770
they're not here anymore

538
00:22:04,150 --> 00:22:11,080
the the to the extent that people had

539
00:22:08,770 --> 00:22:13,600
mobile phones they were big clunky

540
00:22:11,080 --> 00:22:17,260
analog devices and basically only rich

541
00:22:13,600 --> 00:22:19,629
business people had them the idea of a

542
00:22:17,260 --> 00:22:21,430
smart phone the idea that a phone and a

543
00:22:19,630 --> 00:22:23,470
computer are the same thing and that

544
00:22:21,430 --> 00:22:30,210
they would fit in your pocket like this

545
00:22:23,470 --> 00:22:33,580
was a ridiculous fantasy in 1992 the

546
00:22:30,210 --> 00:22:37,050
another killer app for communication was

547
00:22:33,580 --> 00:22:41,770
email there was a real big concern that

548
00:22:37,050 --> 00:22:44,500
absent any regulations email encryption

549
00:22:41,770 --> 00:22:47,980
would proliferate an email would become

550
00:22:44,500 --> 00:22:51,400
unmonitored so far we have not been as

551
00:22:47,980 --> 00:22:56,500
good at this as the FBI predicted we

552
00:22:51,400 --> 00:22:59,560
would be the another killer application

553
00:22:56,500 --> 00:23:03,240
was fax that was sort of like the web

554
00:22:59,560 --> 00:23:06,310
but with telephones and Printers and

555
00:23:03,240 --> 00:23:09,700
every business had a fax machine the web

556
00:23:06,310 --> 00:23:12,700
did not exist the Internet was largely

557
00:23:09,700 --> 00:23:15,760
something that nerds had available to

558
00:23:12,700 --> 00:23:18,880
them at work it was not clear that it

559
00:23:15,760 --> 00:23:20,530
would ever catch on within 10 years

560
00:23:18,880 --> 00:23:22,660
every one of these underlying

561
00:23:20,530 --> 00:23:25,870
assumptions that clipper was designed

562
00:23:22,660 --> 00:23:28,900
under proved to be you know turned on

563
00:23:25,870 --> 00:23:30,669
its head and laughably false now let's

564
00:23:28,900 --> 00:23:33,190
imagine anything we do today let's

565
00:23:30,670 --> 00:23:36,550
assume that the government wins crypto

566
00:23:33,190 --> 00:23:38,770
war 2 and as some sort of design mandate

567
00:23:36,550 --> 00:23:42,550
based on engineering decisions that are

568
00:23:38,770 --> 00:23:47,710
perfectly valid right now become the

569
00:23:42,550 --> 00:23:50,050
standard for encryption we are going to

570
00:23:47,710 --> 00:23:53,140
be looking back at those engineering

571
00:23:50,050 --> 00:23:54,149
decisions 10 years from now as being

572
00:23:53,140 --> 00:23:56,880
equal

573
00:23:54,150 --> 00:24:01,470
laughably wrong - all of those things

574
00:23:56,880 --> 00:24:05,700
that we thought about with clipper once

575
00:24:01,470 --> 00:24:08,100
the 21st century rolled around we will I

576
00:24:05,700 --> 00:24:09,840
don't know what things are going to be

577
00:24:08,100 --> 00:24:11,610
wrong or how they're going to be wrong

578
00:24:09,840 --> 00:24:14,189
but I can certainly imagine being in a

579
00:24:11,610 --> 00:24:16,110
room 10 years from now and I'll be able

580
00:24:14,190 --> 00:24:19,860
to say hey remember when we all had

581
00:24:16,110 --> 00:24:21,389
phones you know and you know everyone

582
00:24:19,860 --> 00:24:23,100
will you know look around and the old

583
00:24:21,390 --> 00:24:24,750
people will sort of chuckle the young

584
00:24:23,100 --> 00:24:26,760
people won't have any idea what we're

585
00:24:24,750 --> 00:24:30,800
what we're talking about it'll be like

586
00:24:26,760 --> 00:24:34,050
payphones today the you know is

587
00:24:30,800 --> 00:24:35,430
real-time communication the normal way

588
00:24:34,050 --> 00:24:37,139
we communicate or will it be

589
00:24:35,430 --> 00:24:39,830
store-and-forward what's the

590
00:24:37,140 --> 00:24:42,120
relationship between storage and

591
00:24:39,830 --> 00:24:45,090
communication that's been flip-flopping

592
00:24:42,120 --> 00:24:48,479
several times which one you know does it

593
00:24:45,090 --> 00:24:50,520
make sense to store data in the cloud or

594
00:24:48,480 --> 00:24:52,440
locally the correct answer to that

595
00:24:50,520 --> 00:24:55,860
question in depends on the exact year

596
00:24:52,440 --> 00:24:59,010
you asked it and all of those all of

597
00:24:55,860 --> 00:25:01,679
those kinds of decisions are going to be

598
00:24:59,010 --> 00:25:06,180
either explicit or more dangerously

599
00:25:01,680 --> 00:25:10,050
implicit in any engineering mandates we

600
00:25:06,180 --> 00:25:12,060
design or are imposed on us for

601
00:25:10,050 --> 00:25:14,580
encryption going forward so I would

602
00:25:12,060 --> 00:25:17,730
argue that just as Clippers success

603
00:25:14,580 --> 00:25:20,250
would have been a disaster not just for

604
00:25:17,730 --> 00:25:23,640
the reasons we thought they would be a

605
00:25:20,250 --> 00:25:27,750
disaster in 1993 that the key escrow

606
00:25:23,640 --> 00:25:29,160
mechanism would get misused but they

607
00:25:27,750 --> 00:25:32,010
will be a disaster because they will

608
00:25:29,160 --> 00:25:36,840
completely hobble and constrain our

609
00:25:32,010 --> 00:25:39,270
ability to evolve from the engineering

610
00:25:36,840 --> 00:25:42,899
of the internet and computers as they

611
00:25:39,270 --> 00:25:48,480
exist right now so I think the only

612
00:25:42,900 --> 00:25:50,580
tenable approach is the status quo it's

613
00:25:48,480 --> 00:25:52,290
just the most Gen X thing overuse in the

614
00:25:50,580 --> 00:25:54,060
90s like fighting against the man and

615
00:25:52,290 --> 00:25:59,320
now you just want to maintain the status

616
00:25:54,060 --> 00:26:01,000
quo okay boomer

617
00:25:59,320 --> 00:26:03,010
yeah and and and I don't think that

618
00:26:01,000 --> 00:26:11,680
clipper was controversial at all we were

619
00:26:03,010 --> 00:26:15,070
all against it so hi everyone hi

620
00:26:11,680 --> 00:26:18,130
everyone good morning I just love that I

621
00:26:15,070 --> 00:26:22,800
get to play against Matt Blais as the

622
00:26:18,130 --> 00:26:26,410
conservative because I actually do have

623
00:26:22,800 --> 00:26:31,510
I think a somewhat different view then

624
00:26:26,410 --> 00:26:35,250
then matters sketched out and all I said

625
00:26:31,510 --> 00:26:39,640
I might have a quibble it's equivalent

626
00:26:35,250 --> 00:26:41,890
to say one thing about the kind of

627
00:26:39,640 --> 00:26:43,600
posture I'm gonna take up here I've

628
00:26:41,890 --> 00:26:45,880
spent a lot of time on this issue as

629
00:26:43,600 --> 00:26:48,429
Matt has and as Rihanna has as a

630
00:26:45,880 --> 00:26:51,130
advocate on this issue as a policymaker

631
00:26:48,430 --> 00:26:53,800
on this issue and I do have pretty

632
00:26:51,130 --> 00:26:58,000
strong advocacy views but I'm actually

633
00:26:53,800 --> 00:27:00,129
not going to make them here what I want

634
00:26:58,000 --> 00:27:03,580
to look at instead is kind of the

635
00:27:00,130 --> 00:27:06,250
trajectory of this policy debate and in

636
00:27:03,580 --> 00:27:08,379
particular the kinds of questions that I

637
00:27:06,250 --> 00:27:11,110
think the technical community is going

638
00:27:08,380 --> 00:27:12,450
to be called upon to engage in because I

639
00:27:11,110 --> 00:27:17,169
think they're going to be different

640
00:27:12,450 --> 00:27:20,770
Rihanna did a fantastic overview of the

641
00:27:17,170 --> 00:27:25,690
kind of legal and policy history which

642
00:27:20,770 --> 00:27:27,790
is and I'm repeating it here not to talk

643
00:27:25,690 --> 00:27:29,650
about the details which she did talk

644
00:27:27,790 --> 00:27:32,950
about but to point out the trajectory

645
00:27:29,650 --> 00:27:35,020
which I think we all kind of have as an

646
00:27:32,950 --> 00:27:37,180
innate assumption the trajectory is that

647
00:27:35,020 --> 00:27:39,400
the technical side of this debate the

648
00:27:37,180 --> 00:27:41,980
people in this room not to caricature

649
00:27:39,400 --> 00:27:47,950
all if you have one as matt said it that

650
00:27:41,980 --> 00:27:51,280
we won crypto war one and well I think

651
00:27:47,950 --> 00:27:54,070
there's a lot of ways that's true I

652
00:27:51,280 --> 00:27:56,800
think that there I think the policy

653
00:27:54,070 --> 00:27:59,470
world has for example come to accept the

654
00:27:56,800 --> 00:28:01,659
idea that there is real risk associated

655
00:27:59,470 --> 00:28:04,420
with any kind of exceptional access

656
00:28:01,660 --> 00:28:08,200
system and also the view that Matt

657
00:28:04,420 --> 00:28:11,170
suggested that messing with security

658
00:28:08,200 --> 00:28:11,930
generally has real risks I think that

659
00:28:11,170 --> 00:28:15,320
that

660
00:28:11,930 --> 00:28:16,880
has been internalized into the policy

661
00:28:15,320 --> 00:28:22,700
discussion around the world which is

662
00:28:16,880 --> 00:28:26,360
good because it's true but I think while

663
00:28:22,700 --> 00:28:27,800
that trajectory was happening and I will

664
00:28:26,360 --> 00:28:29,929
say that's been that's happened

665
00:28:27,800 --> 00:28:32,720
essentially exclusively in the u.s. or

666
00:28:29,930 --> 00:28:36,290
at least driven by US politics and the

667
00:28:32,720 --> 00:28:38,900
influence of US tech policy around the

668
00:28:36,290 --> 00:28:42,590
world there are a bunch of other things

669
00:28:38,900 --> 00:28:45,500
that have been happening not in the US

670
00:28:42,590 --> 00:28:47,389
and I want to pay attention to those

671
00:28:45,500 --> 00:28:50,720
urge you to pay attention to them

672
00:28:47,390 --> 00:28:52,040
because I think they point to the shape

673
00:28:50,720 --> 00:28:56,630
of the debate that we're going to have

674
00:28:52,040 --> 00:28:59,149
going forward back in 2010 at the same

675
00:28:56,630 --> 00:29:01,160
time that in the United States we are

676
00:28:59,150 --> 00:29:02,780
having a debate in the Obama

677
00:29:01,160 --> 00:29:04,970
administration about whether to amend

678
00:29:02,780 --> 00:29:08,389
Kalia to change some of the encryption

679
00:29:04,970 --> 00:29:10,250
rules India just declared that if

680
00:29:08,390 --> 00:29:12,620
BlackBerry wanted to do if RIM wanted to

681
00:29:10,250 --> 00:29:15,230
do business in India it would have to

682
00:29:12,620 --> 00:29:17,060
provide all of its services through what

683
00:29:15,230 --> 00:29:19,810
was then called the it was the

684
00:29:17,060 --> 00:29:22,159
BlackBerry Enterprise Server that would

685
00:29:19,810 --> 00:29:24,800
in some ways kind of meet the Kalia

686
00:29:22,160 --> 00:29:27,770
conditions that Rihanna described in

687
00:29:24,800 --> 00:29:29,330
which BlackBerry as the service provider

688
00:29:27,770 --> 00:29:31,670
would be able to decrypt any

689
00:29:29,330 --> 00:29:33,129
communication on demand from the Indian

690
00:29:31,670 --> 00:29:36,350
government so that's the way that

691
00:29:33,130 --> 00:29:40,220
hundreds of millions of people used

692
00:29:36,350 --> 00:29:47,629
encryption in India as early as 2010 in

693
00:29:40,220 --> 00:29:53,200
2016 the UK passed the last in a series

694
00:29:47,630 --> 00:29:55,460
of surveillance laws that updated the UK

695
00:29:53,200 --> 00:29:57,470
surveillance legal environment it was

696
00:29:55,460 --> 00:29:59,030
called pejoratively by a number of

697
00:29:57,470 --> 00:30:02,930
privacy advocates there the snoopers

698
00:29:59,030 --> 00:30:05,720
Charter and I'm going to talk a little

699
00:30:02,930 --> 00:30:07,970
bit more about what it did but it for

700
00:30:05,720 --> 00:30:11,000
the purposes of our debate it granted

701
00:30:07,970 --> 00:30:16,220
authority to the UK government in 2016

702
00:30:11,000 --> 00:30:18,860
to compel technical assistance for law

703
00:30:16,220 --> 00:30:20,810
enforcement by communications service

704
00:30:18,860 --> 00:30:23,270
providers to do exactly what as Rihanna

705
00:30:20,810 --> 00:30:24,639
said under US law communications service

706
00:30:23,270 --> 00:30:28,810
providers were not required

707
00:30:24,640 --> 00:30:32,410
to do in 2018 very much following the

708
00:30:28,810 --> 00:30:34,120
lead of the UK Australia passed a law

709
00:30:32,410 --> 00:30:36,280
that's been known as the assistance and

710
00:30:34,120 --> 00:30:39,729
access bill and it does more or less the

711
00:30:36,280 --> 00:30:42,190
same thing it says that anyone providing

712
00:30:39,730 --> 00:30:46,180
a broadly speaking a communication

713
00:30:42,190 --> 00:30:50,410
service in Australia can be required in

714
00:30:46,180 --> 00:30:54,270
secret to assist law enforcement by

715
00:30:50,410 --> 00:30:58,660
providing a plain text of any encrypted

716
00:30:54,270 --> 00:31:01,540
communication and today like right now

717
00:30:58,660 --> 00:31:05,790
India is actually debating another set

718
00:31:01,540 --> 00:31:08,230
of changes to their communications law

719
00:31:05,790 --> 00:31:09,790
which would actually do something

720
00:31:08,230 --> 00:31:14,770
similar to what Lindsey Graham is

721
00:31:09,790 --> 00:31:17,340
proposing would link requirement to be

722
00:31:14,770 --> 00:31:21,160
able to filter and detect illegal

723
00:31:17,340 --> 00:31:22,810
content on platforms in exchange for the

724
00:31:21,160 --> 00:31:24,730
liability limitations that they have

725
00:31:22,810 --> 00:31:27,639
that are the equivalent of the u.s.

726
00:31:24,730 --> 00:31:29,580
section 235 of limitations that's a

727
00:31:27,640 --> 00:31:33,940
debate that's happening right now so

728
00:31:29,580 --> 00:31:35,800
well on the one hand we can say that in

729
00:31:33,940 --> 00:31:39,880
the world that we all pay most attention

730
00:31:35,800 --> 00:31:43,379
to the United States Internet policy

731
00:31:39,880 --> 00:31:47,110
we've won and and perhaps are even on a

732
00:31:43,380 --> 00:31:49,810
still positive trajectory for this

733
00:31:47,110 --> 00:31:52,090
debate in the US the rest of the world

734
00:31:49,810 --> 00:31:54,010
is going in very very different

735
00:31:52,090 --> 00:31:57,100
directions and I want to just take a

736
00:31:54,010 --> 00:32:01,150
slightly more careful look at what the

737
00:31:57,100 --> 00:32:04,300
UK and Australia have done in in their

738
00:32:01,150 --> 00:32:07,330
two laws the UK law specifically

739
00:32:04,300 --> 00:32:12,040
provides that so-called technical

740
00:32:07,330 --> 00:32:15,189
capacity notices can be issued against

741
00:32:12,040 --> 00:32:16,690
any service provider either in the UK or

742
00:32:15,190 --> 00:32:19,770
anyone who's providing any kind of

743
00:32:16,690 --> 00:32:22,750
service from outside the UK

744
00:32:19,770 --> 00:32:26,710
interestingly there's some constraints

745
00:32:22,750 --> 00:32:28,210
on these technical capacity notices that

746
00:32:26,710 --> 00:32:30,670
ease these requirements that the

747
00:32:28,210 --> 00:32:32,770
government could impose to decrypt

748
00:32:30,670 --> 00:32:34,240
communication to redesign their systems

749
00:32:32,770 --> 00:32:38,110
in whatever way that law enforcement

750
00:32:34,240 --> 00:32:40,820
decides is important number one though

751
00:32:38,110 --> 00:32:42,559
technical capacities that can be

752
00:32:40,820 --> 00:32:45,789
mandated have to be technically

753
00:32:42,559 --> 00:32:49,340
reasonable now that's a very broad term

754
00:32:45,789 --> 00:32:51,919
and the UK law actually has a pretty

755
00:32:49,340 --> 00:32:54,168
elaborate process and a sort of a

756
00:32:51,919 --> 00:32:57,559
bureaucratic process which I don't say

757
00:32:54,169 --> 00:33:00,620
pejoratively a careful process for

758
00:32:57,559 --> 00:33:02,960
trying to evaluate whether a particular

759
00:33:00,620 --> 00:33:05,299
technical requirement is reasonable or

760
00:33:02,960 --> 00:33:07,280
not there's a commission that's set up

761
00:33:05,299 --> 00:33:11,559
the Commission has a technical advisory

762
00:33:07,280 --> 00:33:14,178
board but notably

763
00:33:11,559 --> 00:33:16,190
so-so so I think it's fair to say on the

764
00:33:14,179 --> 00:33:18,440
one hand the UK law is not just toying

765
00:33:16,190 --> 00:33:20,120
around with this and in fact in the UK

766
00:33:18,440 --> 00:33:21,880
those of you who know the the system

767
00:33:20,120 --> 00:33:25,010
there there's a much tighter integration

768
00:33:21,880 --> 00:33:28,250
between law enforcement intelligence and

769
00:33:25,010 --> 00:33:30,020
domestic cyber security capabilities and

770
00:33:28,250 --> 00:33:32,419
that is a lot of the same people who are

771
00:33:30,020 --> 00:33:34,429
responsible for electronic surveillance

772
00:33:32,419 --> 00:33:36,500
capabilities are also responsible for

773
00:33:34,429 --> 00:33:38,780
the domestic cyber security posture

774
00:33:36,500 --> 00:33:40,460
generally so they actually do have an

775
00:33:38,780 --> 00:33:43,610
incentive and and I think that actually

776
00:33:40,460 --> 00:33:45,710
the technical capacity to try to take

777
00:33:43,610 --> 00:33:48,168
into account these delicate balances of

778
00:33:45,710 --> 00:33:51,740
the sort that Matt described but

779
00:33:48,169 --> 00:33:54,260
nonetheless the UK gave itself the UK

780
00:33:51,740 --> 00:33:58,640
government gave itself voted itself the

781
00:33:54,260 --> 00:34:01,309
authority to impose exceptional access

782
00:33:58,640 --> 00:34:03,890
requirements among others on service

783
00:34:01,309 --> 00:34:05,960
providers what's striking partly about

784
00:34:03,890 --> 00:34:07,700
what the UK has done though I do think

785
00:34:05,960 --> 00:34:09,949
it's been it's a kind of a careful

786
00:34:07,700 --> 00:34:12,949
structure it's also a structure that by

787
00:34:09,949 --> 00:34:14,299
default is in secret and and and I think

788
00:34:12,949 --> 00:34:16,100
we'll probably all talk a little bit

789
00:34:14,300 --> 00:34:18,409
more about that so we don't actually

790
00:34:16,100 --> 00:34:20,659
know whether these authorities have been

791
00:34:18,409 --> 00:34:23,119
exercised or not we do know that some

792
00:34:20,659 --> 00:34:24,909
service providers has have had have what

793
00:34:23,119 --> 00:34:27,970
are now called technical capacity

794
00:34:24,909 --> 00:34:31,070
Canaries not unlike warrant Canaries

795
00:34:27,969 --> 00:34:32,839
mechanisms to try to indirectly signal

796
00:34:31,070 --> 00:34:37,490
to the world if a service provider has

797
00:34:32,840 --> 00:34:39,770
been ordered to make changes to their

798
00:34:37,489 --> 00:34:41,290
security services we but we don't know

799
00:34:39,770 --> 00:34:44,149
that any of those have been triggered

800
00:34:41,290 --> 00:34:46,940
Australia went a little further than

801
00:34:44,149 --> 00:34:49,730
this though in the same kind of

802
00:34:46,940 --> 00:34:51,730
structure they do have these mechanism

803
00:34:49,730 --> 00:34:53,949
for issuing

804
00:34:51,730 --> 00:34:55,599
to service providers so any of you who

805
00:34:53,949 --> 00:34:59,799
work for companies could be the subject

806
00:34:55,599 --> 00:35:03,700
of one of these requirements though as

807
00:34:59,800 --> 00:35:05,530
in the UK you sitting here might not

808
00:35:03,700 --> 00:35:07,660
even know about it because they're very

809
00:35:05,530 --> 00:35:10,780
strict secrecy requirements in Australia

810
00:35:07,660 --> 00:35:12,790
actually made it a crime to disclose the

811
00:35:10,780 --> 00:35:16,300
existence of these technical capacity

812
00:35:12,790 --> 00:35:19,210
notices what's interesting about the

813
00:35:16,300 --> 00:35:22,359
Australia law law is that the law makers

814
00:35:19,210 --> 00:35:26,010
they are in a pretty pretty lively

815
00:35:22,359 --> 00:35:28,328
debate actually recognized the risk of

816
00:35:26,010 --> 00:35:30,849
introducing systemic vulnerabilities

817
00:35:28,329 --> 00:35:32,829
into the communications infrastructure

818
00:35:30,849 --> 00:35:35,050
as a result of these exceptional access

819
00:35:32,829 --> 00:35:38,079
requirements and the law says that the

820
00:35:35,050 --> 00:35:40,119
TC NS cannot introduce systemic

821
00:35:38,079 --> 00:35:41,859
vulnerabilities but you now have to ask

822
00:35:40,119 --> 00:35:45,310
the question how would you know how

823
00:35:41,859 --> 00:35:46,630
would anyone know the Australian

824
00:35:45,310 --> 00:35:50,339
Government's a perfectly capable

825
00:35:46,630 --> 00:35:53,230
government and actually has very good

826
00:35:50,339 --> 00:35:55,960
kind of computer security people in the

827
00:35:53,230 --> 00:35:57,760
intelligence services they might know or

828
00:35:55,960 --> 00:35:59,560
they might not but they might not want

829
00:35:57,760 --> 00:36:01,210
to say or they may not be able to say

830
00:35:59,560 --> 00:36:06,220
but there isn't any kind of a

831
00:36:01,210 --> 00:36:08,500
transparent process some of us wrote a

832
00:36:06,220 --> 00:36:10,810
letter and testified as I think we ought

833
00:36:08,500 --> 00:36:12,780
to testified number of us testified in

834
00:36:10,810 --> 00:36:16,359
the Australia legislative process and

835
00:36:12,780 --> 00:36:19,990
pointed out in particular that some of

836
00:36:16,359 --> 00:36:22,390
the transparency some of the anti

837
00:36:19,990 --> 00:36:24,609
transparency requirements in the

838
00:36:22,390 --> 00:36:26,529
Australian law actually Rudd run

839
00:36:24,609 --> 00:36:29,410
headlong into some of the really

840
00:36:26,530 --> 00:36:32,290
important new security innovations such

841
00:36:29,410 --> 00:36:34,390
as certificate transparency message key

842
00:36:32,290 --> 00:36:36,849
transparency and binary transparency

843
00:36:34,390 --> 00:36:38,290
that the security community the internet

844
00:36:36,849 --> 00:36:43,300
security community is really coming to

845
00:36:38,290 --> 00:36:45,339
depend upon so specifically if if one of

846
00:36:43,300 --> 00:36:49,329
these law enforcement notices from

847
00:36:45,339 --> 00:36:53,109
Australia requires for example a change

848
00:36:49,329 --> 00:36:56,230
in a TLS key so that so that TLS traffic

849
00:36:53,109 --> 00:36:58,119
could be service leader cryptid or a

850
00:36:56,230 --> 00:37:00,490
change in the keys for messaging

851
00:36:58,119 --> 00:37:03,360
services or a change in software that

852
00:37:00,490 --> 00:37:05,189
users have on their own devices

853
00:37:03,360 --> 00:37:07,320
the service providers would be put in a

854
00:37:05,190 --> 00:37:11,220
very awkward position of having to

855
00:37:07,320 --> 00:37:14,430
either somehow try to squeeze that

856
00:37:11,220 --> 00:37:17,430
through these new technical transparency

857
00:37:14,430 --> 00:37:20,790
mechanisms that are being implemented or

858
00:37:17,430 --> 00:37:23,399
not and then risk criminal fines so

859
00:37:20,790 --> 00:37:27,029
there's a real interesting collision

860
00:37:23,400 --> 00:37:29,760
that's happening technically but I want

861
00:37:27,030 --> 00:37:31,830
to focus your attention also on what I

862
00:37:29,760 --> 00:37:33,510
think has happened on what these two

863
00:37:31,830 --> 00:37:38,069
laws signal for the direction of the

864
00:37:33,510 --> 00:37:40,470
policy debate these laws reflect a

865
00:37:38,070 --> 00:37:42,740
decision to do what's a kind of a very

866
00:37:40,470 --> 00:37:44,970
common and sometimes sensible

867
00:37:42,740 --> 00:37:47,270
legislative tactic which is the

868
00:37:44,970 --> 00:37:50,009
legislature was faced with his hard

869
00:37:47,270 --> 00:37:51,990
question should we require exceptional

870
00:37:50,010 --> 00:37:53,880
access or not and you have the Matt

871
00:37:51,990 --> 00:37:55,799
blazes to the world saying don't do it

872
00:37:53,880 --> 00:37:57,210
for all kinds of technical reasons you

873
00:37:55,800 --> 00:37:58,500
have the bill bars of the world saying

874
00:37:57,210 --> 00:38:03,780
we must we must we must

875
00:37:58,500 --> 00:38:06,000
and the legislators here what the

876
00:38:03,780 --> 00:38:07,380
legislators here is a complicated

877
00:38:06,000 --> 00:38:11,100
problem that they don't know how to

878
00:38:07,380 --> 00:38:12,480
resolve no hearings no no number of

879
00:38:11,100 --> 00:38:13,980
congressional hearings is actually going

880
00:38:12,480 --> 00:38:15,990
to get to the bottom of this question

881
00:38:13,980 --> 00:38:19,080
nor do they necessarily want to have to

882
00:38:15,990 --> 00:38:21,149
make a hard call on the question so what

883
00:38:19,080 --> 00:38:22,980
do they do they punt it to a process and

884
00:38:21,150 --> 00:38:25,050
I don't say punt pejoratively we make a

885
00:38:22,980 --> 00:38:26,490
lot of policy this way by saying well

886
00:38:25,050 --> 00:38:29,310
there's a hard technical question let's

887
00:38:26,490 --> 00:38:33,470
defer that to experts that's what the UK

888
00:38:29,310 --> 00:38:37,410
is done that's what Australia has done

889
00:38:33,470 --> 00:38:39,750
but they've done it in secret or with

890
00:38:37,410 --> 00:38:41,399
secrecy around it so that's going to

891
00:38:39,750 --> 00:38:43,860
pose a real challenge but I would

892
00:38:41,400 --> 00:38:48,240
suggest to you that this shift in the

893
00:38:43,860 --> 00:38:50,130
debate is is somewhat permanent it's a

894
00:38:48,240 --> 00:38:53,310
it's an attractive and in some ways

895
00:38:50,130 --> 00:38:55,920
elegant answer to a hard policy problem

896
00:38:53,310 --> 00:39:00,029
and so I want to look with you at what

897
00:38:55,920 --> 00:39:03,390
this new expert debate is going to look

898
00:39:00,030 --> 00:39:04,980
like in the last year the Carnegie

899
00:39:03,390 --> 00:39:08,009
Endowment for international peace which

900
00:39:04,980 --> 00:39:08,870
is a really distinguished policy

901
00:39:08,010 --> 00:39:11,490
think-tank

902
00:39:08,870 --> 00:39:14,339
I've got together a bunch of experts

903
00:39:11,490 --> 00:39:16,109
from different sides of this spectrum

904
00:39:14,340 --> 00:39:16,950
including former White House chief of

905
00:39:16,110 --> 00:39:20,480
staff and

906
00:39:16,950 --> 00:39:25,290
General Counsel's of the FBI and

907
00:39:20,480 --> 00:39:27,420
technical experts and try to look at

908
00:39:25,290 --> 00:39:30,240
what to do and they didn't exactly come

909
00:39:27,420 --> 00:39:31,950
to any hard and fast conclusions but

910
00:39:30,240 --> 00:39:35,250
they did say well maybe there are some

911
00:39:31,950 --> 00:39:38,879
areas some technical solution areas that

912
00:39:35,250 --> 00:39:41,310
we should look at and in particular as

913
00:39:38,880 --> 00:39:43,290
highlighted by a recent op-ed from Susan

914
00:39:41,310 --> 00:39:46,410
Landau who's a co-author of Matt and

915
00:39:43,290 --> 00:39:48,779
mine on on keys under doormats and Denis

916
00:39:46,410 --> 00:39:51,629
McDonough who was the White House chief

917
00:39:48,780 --> 00:39:54,089
of staff under President Obama they said

918
00:39:51,630 --> 00:39:55,980
well why don't we try looking harder at

919
00:39:54,089 --> 00:39:58,099
device encryption because maybe that's a

920
00:39:55,980 --> 00:40:02,310
little easier to solve than

921
00:39:58,099 --> 00:40:04,530
communications encryption the

922
00:40:02,310 --> 00:40:06,930
interesting thing is that experts in the

923
00:40:04,530 --> 00:40:09,390
UK when they've spoken publicly about

924
00:40:06,930 --> 00:40:11,730
this come to the exact opposite and Levy

925
00:40:09,390 --> 00:40:13,859
who's the was the technical director at

926
00:40:11,730 --> 00:40:18,089
GCHQ and is now the technical director

927
00:40:13,859 --> 00:40:19,890
of the UK cybersecurity Center said oh

928
00:40:18,089 --> 00:40:21,599
device encryption is really hard we

929
00:40:19,890 --> 00:40:25,259
shouldn't touch that let's just let's

930
00:40:21,599 --> 00:40:29,099
just focus on on messaging security so

931
00:40:25,260 --> 00:40:31,680
it shows that moving the debate to

932
00:40:29,099 --> 00:40:34,020
experts on the one hand gets you down to

933
00:40:31,680 --> 00:40:36,720
details in a sort in a way that we

934
00:40:34,020 --> 00:40:41,000
haven't exactly but it's not necessarily

935
00:40:36,720 --> 00:40:44,669
easy I want to end just by highlighting

936
00:40:41,000 --> 00:40:46,490
some questions that I think are gonna

937
00:40:44,670 --> 00:40:50,760
have to be answered one way or the other

938
00:40:46,490 --> 00:40:51,899
in this new policy debate that we I

939
00:40:50,760 --> 00:40:56,579
don't think really really know how to

940
00:40:51,900 --> 00:40:59,160
answer very well broadly speaking from

941
00:40:56,579 --> 00:41:01,079
the technical perspective just what what

942
00:40:59,160 --> 00:41:04,348
is the right way to measure technical

943
00:41:01,079 --> 00:41:06,180
feasibility of any particular technical

944
00:41:04,349 --> 00:41:09,210
capacity of notice that might be ordered

945
00:41:06,180 --> 00:41:11,368
by the US by the UK government or the

946
00:41:09,210 --> 00:41:13,260
Australian government and in particular

947
00:41:11,369 --> 00:41:15,359
how do we know when a vulnerability is

948
00:41:13,260 --> 00:41:21,690
systemic what does that mean how can we

949
00:41:15,359 --> 00:41:24,509
detect it and more broadly are we able

950
00:41:21,690 --> 00:41:29,280
to kind of assess the relative security

951
00:41:24,510 --> 00:41:30,619
costs of an exceptional access system as

952
00:41:29,280 --> 00:41:33,319
against the security cost

953
00:41:30,619 --> 00:41:35,390
that as all if you know are often

954
00:41:33,319 --> 00:41:37,549
accepted in the design of systems for

955
00:41:35,390 --> 00:41:41,328
the sake of convenience or cost or

956
00:41:37,549 --> 00:41:43,759
whatever else as the as the policy

957
00:41:41,329 --> 00:41:44,869
debate moves from the legislators who I

958
00:41:43,759 --> 00:41:46,880
think it basically just gotten

959
00:41:44,869 --> 00:41:49,009
frustrated with this and have decided

960
00:41:46,880 --> 00:41:52,430
they can't really make a lot of progress

961
00:41:49,009 --> 00:41:54,680
into these regulatory processes which

962
00:41:52,430 --> 00:41:58,129
may unfortunately be at least partially

963
00:41:54,680 --> 00:42:00,259
opaque we're gonna have to have good

964
00:41:58,130 --> 00:42:02,960
technical mechanisms for answering this

965
00:42:00,259 --> 00:42:07,539
it's not unlike you know mechanisms that

966
00:42:02,960 --> 00:42:11,390
we have for measuring the impact of of

967
00:42:07,539 --> 00:42:12,859
climate change on sea water rise we have

968
00:42:11,390 --> 00:42:14,269
measures for that kind of thing we don't

969
00:42:12,859 --> 00:42:15,740
have a lot of good measures in this

970
00:42:14,269 --> 00:42:19,519
space and then of course there are a

971
00:42:15,740 --> 00:42:21,709
number of significant policy issues

972
00:42:19,519 --> 00:42:22,788
broadly I think most of which are

973
00:42:21,710 --> 00:42:24,859
actually going to have to do with

974
00:42:22,789 --> 00:42:27,079
whether we can really seriously think of

975
00:42:24,859 --> 00:42:28,578
doing this in secret final thing I'll

976
00:42:27,079 --> 00:42:33,410
say about this about the question of

977
00:42:28,579 --> 00:42:38,119
secrecy is that in many ways we got to

978
00:42:33,410 --> 00:42:40,098
the least in the u.s. we got to crypto

979
00:42:38,119 --> 00:42:42,380
Wars to because of the Snowden

980
00:42:40,099 --> 00:42:44,059
disclosures got to crypto Wars too

981
00:42:42,380 --> 00:42:47,210
because right after the Snowden

982
00:42:44,059 --> 00:42:49,789
disclosures Apple and then and then

983
00:42:47,210 --> 00:42:52,279
Android said that they were moving to

984
00:42:49,789 --> 00:42:54,230
end end-to-end encryption because very

985
00:42:52,279 --> 00:42:56,349
very they very bluntly said they

986
00:42:54,230 --> 00:43:00,440
considered the NSA to be an adversary

987
00:42:56,349 --> 00:43:04,160
and they needed to up the ante on their

988
00:43:00,440 --> 00:43:06,349
security designs in order to to meet the

989
00:43:04,160 --> 00:43:09,769
the strength of an adversary like the

990
00:43:06,349 --> 00:43:11,779
NSA that's what got us device encryption

991
00:43:09,769 --> 00:43:13,879
by default in both of the smartphone

992
00:43:11,779 --> 00:43:17,710
ecosystems it's what got us the enter

993
00:43:13,880 --> 00:43:19,849
the impetus for HTTPS Everywhere

994
00:43:17,710 --> 00:43:21,259
probably a lot of you were really happy

995
00:43:19,849 --> 00:43:23,329
about it because it probably got people

996
00:43:21,259 --> 00:43:25,069
in your companies or your organization's

997
00:43:23,329 --> 00:43:26,390
to pay attention to what your security

998
00:43:25,069 --> 00:43:29,210
priorities much more than they did

999
00:43:26,390 --> 00:43:32,239
before Snowden but the immediate result

1000
00:43:29,210 --> 00:43:34,190
of that was that law enforcement saw

1001
00:43:32,239 --> 00:43:36,980
that the smartphones that they were used

1002
00:43:34,190 --> 00:43:38,690
to being able to relatively easy easily

1003
00:43:36,980 --> 00:43:43,540
get access to all of a sudden became a

1004
00:43:38,690 --> 00:43:46,900
lot harder to get access to so

1005
00:43:43,540 --> 00:43:49,630
I think that there's nothing about this

1006
00:43:46,900 --> 00:43:50,770
issue that's going away but I think the

1007
00:43:49,630 --> 00:43:53,850
questions that we're going to have to

1008
00:43:50,770 --> 00:43:56,710
ask ask and be able to answer with

1009
00:43:53,850 --> 00:43:58,360
technical authority are going to become

1010
00:43:56,710 --> 00:44:00,550
much more specific the kinds of

1011
00:43:58,360 --> 00:44:03,120
arguments that we were able to make in

1012
00:44:00,550 --> 00:44:06,100
97 and the risk of key recovery paper

1013
00:44:03,120 --> 00:44:08,380
based on on Matt's findings and other

1014
00:44:06,100 --> 00:44:11,620
technical findings kinds of arguments we

1015
00:44:08,380 --> 00:44:13,600
made in keys under doormats 2015 were

1016
00:44:11,620 --> 00:44:16,870
very high level arguments very high

1017
00:44:13,600 --> 00:44:19,120
level claims of risk which I still think

1018
00:44:16,870 --> 00:44:21,580
are true but I think we're gonna have to

1019
00:44:19,120 --> 00:44:23,859
get much more into details with specific

1020
00:44:21,580 --> 00:44:26,920
proposals and specific systems to try to

1021
00:44:23,860 --> 00:44:29,350
understand how to make kind of coherent

1022
00:44:26,920 --> 00:44:31,240
technology policy arguments about what

1023
00:44:29,350 --> 00:44:34,600
kinds of risks should and should not be

1024
00:44:31,240 --> 00:44:51,069
accepted so I'll leave it at that look

1025
00:44:34,600 --> 00:44:54,730
for it questions all right thank you

1026
00:44:51,070 --> 00:44:57,910
very much it's great to be here and when

1027
00:44:54,730 --> 00:45:02,560
I started off in this world in the very

1028
00:44:57,910 --> 00:45:04,420
start of crypto war 1 I was doing what

1029
00:45:02,560 --> 00:45:06,640
was then called social virtual reality

1030
00:45:04,420 --> 00:45:08,410
which fragmented into communications and

1031
00:45:06,640 --> 00:45:10,950
collaboration systems and social

1032
00:45:08,410 --> 00:45:13,600
networks in two different directions and

1033
00:45:10,950 --> 00:45:16,450
lots of people told me at the time that

1034
00:45:13,600 --> 00:45:19,900
they did not want to do collaboration

1035
00:45:16,450 --> 00:45:22,060
etc on the then pretty new public

1036
00:45:19,900 --> 00:45:24,400
internet without having some sort of

1037
00:45:22,060 --> 00:45:25,900
encryption in place because then anybody

1038
00:45:24,400 --> 00:45:29,140
could see them come up with whatever

1039
00:45:25,900 --> 00:45:31,390
ideas that they had there was no SSL and

1040
00:45:29,140 --> 00:45:33,790
so I sat down and I started coding up my

1041
00:45:31,390 --> 00:45:40,060
own things and it snowballed from there

1042
00:45:33,790 --> 00:45:42,790
and when I joined the ACLU one of the

1043
00:45:40,060 --> 00:45:44,500
things that they asked was Oh what do

1044
00:45:42,790 --> 00:45:46,240
you want to work on and I said oh not

1045
00:45:44,500 --> 00:45:49,390
encryption backdoors I've been doing

1046
00:45:46,240 --> 00:45:52,899
that for over 20 years the arguments

1047
00:45:49,390 --> 00:45:55,210
have not changed it's really boring how

1048
00:45:52,900 --> 00:45:56,710
about the threat

1049
00:45:55,210 --> 00:45:59,740
artificial intelligence and machine

1050
00:45:56,710 --> 00:46:04,420
learning and how those are unreliable

1051
00:45:59,740 --> 00:46:07,540
dot dot dot and well the world has found

1052
00:46:04,420 --> 00:46:11,230
me I have had to come back in my head

1053
00:46:07,540 --> 00:46:14,410
many times why is advice that Gandalf

1054
00:46:11,230 --> 00:46:16,780
gives about how the times choose you and

1055
00:46:14,410 --> 00:46:20,649
your measure as a person is how you

1056
00:46:16,780 --> 00:46:24,760
stand up to the times choosing you so

1057
00:46:20,650 --> 00:46:26,410
I'm going to start here and say thinking

1058
00:46:24,760 --> 00:46:28,180
about things that are not directly

1059
00:46:26,410 --> 00:46:31,450
encryption but the threats that we have

1060
00:46:28,180 --> 00:46:34,450
on it and a world that has encryption in

1061
00:46:31,450 --> 00:46:36,089
here it is a basic human right for two

1062
00:46:34,450 --> 00:46:39,240
people to talk confidentiality

1063
00:46:36,089 --> 00:46:41,710
conventionally no matter where they are

1064
00:46:39,240 --> 00:46:44,290
this is this is this is something that's

1065
00:46:41,710 --> 00:46:49,660
sacrosanct we as human beings need to

1066
00:46:44,290 --> 00:46:52,900
talk to each other and as we go into a

1067
00:46:49,660 --> 00:46:54,910
more internet world that expectation

1068
00:46:52,900 --> 00:46:58,150
just to be able to whisper in someone

1069
00:46:54,910 --> 00:47:04,598
else's ear is part of what makes us

1070
00:46:58,150 --> 00:47:06,820
human and so nothing goes past here I am

1071
00:47:04,599 --> 00:47:11,650
starting with the idea that we have

1072
00:47:06,820 --> 00:47:14,020
end-to-end encryption anyway also to

1073
00:47:11,650 --> 00:47:16,420
start off with public posts are

1074
00:47:14,020 --> 00:47:17,619
important I mean you know integrity and

1075
00:47:16,420 --> 00:47:20,380
availability which are the other

1076
00:47:17,619 --> 00:47:23,460
two-thirds of these the confidentiality

1077
00:47:20,380 --> 00:47:25,960
integrity availability model are are

1078
00:47:23,460 --> 00:47:27,670
important and yes availability is kind

1079
00:47:25,960 --> 00:47:29,530
of the whole point see what happens when

1080
00:47:27,670 --> 00:47:31,660
your favorite service goes down and

1081
00:47:29,530 --> 00:47:33,760
there's this huge gray area between

1082
00:47:31,660 --> 00:47:35,348
something that is private and something

1083
00:47:33,760 --> 00:47:38,320
that is public three people talking

1084
00:47:35,349 --> 00:47:39,750
looks a lot more like two despite the

1085
00:47:38,320 --> 00:47:42,310
fact that I mentioned the Ben Franklin

1086
00:47:39,750 --> 00:47:43,869
principle which I've used which is three

1087
00:47:42,310 --> 00:47:48,640
people can keep a secret if two of them

1088
00:47:43,869 --> 00:47:51,280
are dead to a truly public post which

1089
00:47:48,640 --> 00:47:54,460
you know you ought to be able to do a

1090
00:47:51,280 --> 00:47:56,920
certain amount of of checking on it but

1091
00:47:54,460 --> 00:48:00,520
there's this huge gray area in the

1092
00:47:56,920 --> 00:48:02,619
middle to know when it is on the one

1093
00:48:00,520 --> 00:48:04,690
hand you're utterly private on the other

1094
00:48:02,619 --> 00:48:06,520
hand everybody sees what you do and as

1095
00:48:04,690 --> 00:48:08,440
that slides into the middle there ought

1096
00:48:06,520 --> 00:48:10,540
to be some technology that does some

1097
00:48:08,440 --> 00:48:15,579
in the middle and this is not an easy

1098
00:48:10,540 --> 00:48:18,069
problem I'm just mentioning that now

1099
00:48:15,579 --> 00:48:20,560
today's crypto Wars are in fact driven

1100
00:48:18,069 --> 00:48:22,990
by a need to solve real problems which

1101
00:48:20,560 --> 00:48:25,660
is a euphemism for saying they found the

1102
00:48:22,990 --> 00:48:27,910
fourth horse being we used to talk about

1103
00:48:25,660 --> 00:48:37,210
the four horse being of the in FACA lips

1104
00:48:27,910 --> 00:48:39,279
and they were money laundering terrorism

1105
00:48:37,210 --> 00:48:41,020
kiddie porn and I forget what the fourth

1106
00:48:39,280 --> 00:48:45,430
one was but they moved they moved to

1107
00:48:41,020 --> 00:48:48,490
child abuse as the thing that they're

1108
00:48:45,430 --> 00:48:51,430
using as the reason why they have to

1109
00:48:48,490 --> 00:48:55,629
have the backdoors but that doesn't mean

1110
00:48:51,430 --> 00:48:57,790
that it's not a real problem and this is

1111
00:48:55,630 --> 00:49:00,250
also the point at my in my talk where I

1112
00:48:57,790 --> 00:49:03,009
feel like I need to do an aside kind of

1113
00:49:00,250 --> 00:49:05,319
like this were an episode of flea bag or

1114
00:49:03,010 --> 00:49:07,180
something it really bugs me about this

1115
00:49:05,319 --> 00:49:10,839
crypto war that I have to do things like

1116
00:49:07,180 --> 00:49:13,660
say I'm against child abuse I'm against

1117
00:49:10,839 --> 00:49:15,430
genocide I'm I don't like the fact that

1118
00:49:13,660 --> 00:49:17,560
I should have to say this in such a way

1119
00:49:15,430 --> 00:49:19,899
that it should sound like a surprise and

1120
00:49:17,560 --> 00:49:23,859
that you all should find it surprise and

1121
00:49:19,900 --> 00:49:26,380
perhaps be undecided on this issue okay

1122
00:49:23,859 --> 00:49:29,890
I'm done back to it these are real

1123
00:49:26,380 --> 00:49:32,650
problems we have child abuse intimate

1124
00:49:29,890 --> 00:49:34,740
partner abuse elder abuse that's up and

1125
00:49:32,650 --> 00:49:34,740
coming

1126
00:49:34,859 --> 00:49:41,859
Generation X is going to start retiring

1127
00:49:37,540 --> 00:49:49,270
inside a decade Millennials are what we

1128
00:49:41,859 --> 00:49:53,230
used to call 30 something's so so as you

1129
00:49:49,270 --> 00:49:56,109
end up with with your crazy relative who

1130
00:49:53,230 --> 00:49:59,740
does the stereotypical crazy relative

1131
00:49:56,109 --> 00:50:01,210
things it's going to be us and young

1132
00:49:59,740 --> 00:50:03,189
people and they're going to know how to

1133
00:50:01,210 --> 00:50:05,940
use computers and that isn't going to

1134
00:50:03,190 --> 00:50:09,730
change things in some dramatic ways

1135
00:50:05,940 --> 00:50:12,190
we're also seeing attacks on a set bit

1136
00:50:09,730 --> 00:50:16,089
norms and validity of governance at all

1137
00:50:12,190 --> 00:50:18,940
and that's the pretext and they're worth

1138
00:50:16,089 --> 00:50:22,000
solving now the way that we should solve

1139
00:50:18,940 --> 00:50:24,670
these is in fact to get community

1140
00:50:22,000 --> 00:50:27,190
managers user-experience people along in

1141
00:50:24,670 --> 00:50:29,950
with us and in many cases have them take

1142
00:50:27,190 --> 00:50:32,230
the lead I used to be them I'm not one

1143
00:50:29,950 --> 00:50:33,490
anymore I say that intentionally because

1144
00:50:32,230 --> 00:50:35,320
while we've been really good at

1145
00:50:33,490 --> 00:50:37,390
convincing crypt people not to roll

1146
00:50:35,320 --> 00:50:39,700
their own crypto we're really bad at

1147
00:50:37,390 --> 00:50:44,920
convincing cryptographers not to roll

1148
00:50:39,700 --> 00:50:49,319
their own UX and they're really bad at

1149
00:50:44,920 --> 00:50:51,460
it and it drives me up the wall

1150
00:50:49,320 --> 00:50:54,010
okay so we need some new design

1151
00:50:51,460 --> 00:50:57,610
principles we did privacy and security

1152
00:50:54,010 --> 00:51:00,220
by design I wrote up some some design

1153
00:50:57,610 --> 00:51:03,970
principles for a couple of workshops

1154
00:51:00,220 --> 00:51:07,330
that Rihanna and I were in we want to

1155
00:51:03,970 --> 00:51:09,339
have tools for mitigating abuse for the

1156
00:51:07,330 --> 00:51:11,140
platforms the people themselves and the

1157
00:51:09,340 --> 00:51:13,450
caregivers and this is also going to be

1158
00:51:11,140 --> 00:51:16,330
an interesting problem because in many

1159
00:51:13,450 --> 00:51:19,180
of the most pernicious types of abuse

1160
00:51:16,330 --> 00:51:23,770
the caregivers are the first suspect in

1161
00:51:19,180 --> 00:51:25,960
who the perp is so you can't assume

1162
00:51:23,770 --> 00:51:27,880
they're good and a lot of what we're

1163
00:51:25,960 --> 00:51:29,590
dealing with now is the assumption that

1164
00:51:27,880 --> 00:51:31,060
you're talking to somebody because you

1165
00:51:29,590 --> 00:51:34,030
want to talk to them and it's going to

1166
00:51:31,060 --> 00:51:36,310
be a pleasant conversation as opposed to

1167
00:51:34,030 --> 00:51:40,000
some picture that was sent out of the

1168
00:51:36,310 --> 00:51:42,310
blue so we want to rethink how we did

1169
00:51:40,000 --> 00:51:44,470
things when we did the internet we did

1170
00:51:42,310 --> 00:51:47,140
things because people were awful in

1171
00:51:44,470 --> 00:51:50,230
various ways that included control over

1172
00:51:47,140 --> 00:51:53,799
who had the microphone control over how

1173
00:51:50,230 --> 00:51:56,500
information was distributed and the

1174
00:51:53,800 --> 00:51:59,920
whole point was in many cases to flatten

1175
00:51:56,500 --> 00:52:02,620
the world now we have people being awful

1176
00:51:59,920 --> 00:52:04,360
to each other in new way because the

1177
00:52:02,620 --> 00:52:07,960
equivalent of shouting at your

1178
00:52:04,360 --> 00:52:11,440
television is you type really hard when

1179
00:52:07,960 --> 00:52:14,950
you do a tweet so we need to both enable

1180
00:52:11,440 --> 00:52:16,630
and constrain people and some of the

1181
00:52:14,950 --> 00:52:19,299
mitigations that we can talk about to

1182
00:52:16,630 --> 00:52:22,600
throw out include how do we handle

1183
00:52:19,300 --> 00:52:25,510
unsolicited combat contact we are about

1184
00:52:22,600 --> 00:52:27,520
to be in a world in which you can't just

1185
00:52:25,510 --> 00:52:30,490
make a phone call to another number that

1186
00:52:27,520 --> 00:52:32,650
is an optional feature is already

1187
00:52:30,490 --> 00:52:35,200
shipping in smartphone operating systems

1188
00:52:32,650 --> 00:52:36,790
that's the way the world's going so

1189
00:52:35,200 --> 00:52:38,410
you're going to have to have some sort

1190
00:52:36,790 --> 00:52:40,270
of introduction be that leave a

1191
00:52:38,410 --> 00:52:42,250
voicemail or what if where you can phone

1192
00:52:40,270 --> 00:52:44,530
somebody that ought that ought to extend

1193
00:52:42,250 --> 00:52:47,560
to a lot of other places there ought to

1194
00:52:44,530 --> 00:52:50,020
be easier reporting of abuse easier

1195
00:52:47,560 --> 00:52:52,270
blocking people so on and so forth but

1196
00:52:50,020 --> 00:52:55,180
again the assumption that this might not

1197
00:52:52,270 --> 00:52:57,730
be the thing that you really wanted to

1198
00:52:55,180 --> 00:53:00,040
be doing voluntary machine learning

1199
00:52:57,730 --> 00:53:01,570
advice on content fact checkers wouldn't

1200
00:53:00,040 --> 00:53:03,400
it be great if somebody sent me

1201
00:53:01,570 --> 00:53:07,690
something and I could say what does

1202
00:53:03,400 --> 00:53:10,210
Snopes say data provenance who sent it

1203
00:53:07,690 --> 00:53:12,220
limitations on for words limitations on

1204
00:53:10,210 --> 00:53:14,140
group size a lot of these are already

1205
00:53:12,220 --> 00:53:16,899
being done these are the sorts of things

1206
00:53:14,140 --> 00:53:19,060
that all can be helpful social graph

1207
00:53:16,900 --> 00:53:20,980
analytics which groups are talking to

1208
00:53:19,060 --> 00:53:24,220
which other groups who's talking among

1209
00:53:20,980 --> 00:53:26,320
themselves better handling of profiles

1210
00:53:24,220 --> 00:53:29,589
that aren't particularly jidam

1211
00:53:26,320 --> 00:53:32,440
legitimate without going so far as to

1212
00:53:29,589 --> 00:53:34,480
say i have to have the real person it's

1213
00:53:32,440 --> 00:53:38,020
it's there are ways to do this it's just

1214
00:53:34,480 --> 00:53:40,810
it's just hard we want to rethink things

1215
00:53:38,020 --> 00:53:43,450
like ux friction maybe it ought to be

1216
00:53:40,810 --> 00:53:46,060
that it takes a couple extra taps to

1217
00:53:43,450 --> 00:53:48,490
forward a certain type of thing that'll

1218
00:53:46,060 --> 00:53:52,410
slow people down we need to have UX

1219
00:53:48,490 --> 00:53:55,328
focus on the experience not engagement

1220
00:53:52,410 --> 00:53:57,730
context behind dependent behavior based

1221
00:53:55,329 --> 00:53:59,890
on personal status I mean for example if

1222
00:53:57,730 --> 00:54:02,260
you are a child you might have a

1223
00:53:59,890 --> 00:54:05,109
slightly different experience if you are

1224
00:54:02,260 --> 00:54:09,310
using something like screen time to

1225
00:54:05,109 --> 00:54:10,900
monitor your relatives you get a roll up

1226
00:54:09,310 --> 00:54:13,480
of who they've been talking to and all

1227
00:54:10,900 --> 00:54:15,220
all of these things can help we're

1228
00:54:13,480 --> 00:54:17,440
already seeing the beginnings of that on

1229
00:54:15,220 --> 00:54:19,450
on my watch here it behaves slightly

1230
00:54:17,440 --> 00:54:22,750
differently depending upon whether or

1231
00:54:19,450 --> 00:54:24,339
not you are above 65 or below 65 but

1232
00:54:22,750 --> 00:54:26,589
it's a default you can change it so you

1233
00:54:24,339 --> 00:54:28,450
can have extra heart monitoring if

1234
00:54:26,589 --> 00:54:30,430
you're if you're young you can turn off

1235
00:54:28,450 --> 00:54:33,669
the heart monitoring if it's just going

1236
00:54:30,430 --> 00:54:36,040
to adieu to irritate you so those sorts

1237
00:54:33,670 --> 00:54:39,400
of changing the way that things go are

1238
00:54:36,040 --> 00:54:41,560
all going to help a little and I think

1239
00:54:39,400 --> 00:54:44,470
that while I threw a bunch of spaghetti

1240
00:54:41,560 --> 00:54:46,029
against the wall that was merely to get

1241
00:54:44,470 --> 00:54:47,740
the conversation started there are

1242
00:54:46,030 --> 00:54:49,029
better people than me to think of these

1243
00:54:47,740 --> 00:54:51,928
things but that is a

1244
00:54:49,029 --> 00:54:54,909
least that we should go to undermine the

1245
00:54:51,929 --> 00:54:58,679
challenge to what we have to have which

1246
00:54:54,909 --> 00:54:58,679
is in fact an end-to-end encrypted world

1247
00:55:01,540 --> 00:55:05,610
[Applause]

1248
00:55:06,020 --> 00:55:12,779
[Music]

1249
00:55:08,039 --> 00:55:12,779
well some questions for each other

1250
00:55:13,259 --> 00:55:21,939
anybody want anybody got one that was

1251
00:55:15,759 --> 00:55:26,949
burning while we were all high yeah I do

1252
00:55:21,939 --> 00:55:30,609
this is Recaro I you mentioned Clipper

1253
00:55:26,949 --> 00:55:32,650
Chip Dan slide mentioned that MADD blaze

1254
00:55:30,609 --> 00:55:34,679
had something to do with that I think

1255
00:55:32,650 --> 00:55:38,109
that people forget the problem of having

1256
00:55:34,679 --> 00:55:39,699
key escrow and backdoors and code could

1257
00:55:38,109 --> 00:55:42,159
you spend at least two minutes

1258
00:55:39,699 --> 00:55:47,079
explaining what you did with the Clipper

1259
00:55:42,159 --> 00:55:50,859
Chip so I found a narrow technical

1260
00:55:47,079 --> 00:55:53,409
problem that made clipper easy to evade

1261
00:55:50,859 --> 00:55:56,859
while still taking advantage of the lord

1262
00:55:53,409 --> 00:55:58,569
of the clipper key escrow features were

1263
00:55:56,859 --> 00:56:01,328
easy to evade while still taking

1264
00:55:58,569 --> 00:56:03,849
advantage of the stronger cipher which

1265
00:56:01,329 --> 00:56:07,869
basically meant that there was no point

1266
00:56:03,849 --> 00:56:10,689
in this in this extensive thing so that

1267
00:56:07,869 --> 00:56:13,239
was a design flaw you know they could

1268
00:56:10,689 --> 00:56:16,149
probably have fixed the design flaw but

1269
00:56:13,239 --> 00:56:18,880
it Illustrated two really important

1270
00:56:16,150 --> 00:56:21,579
things that I think we now take to heart

1271
00:56:18,880 --> 00:56:24,219
as a given the first is that crypto

1272
00:56:21,579 --> 00:56:26,259
protocol design is really really really

1273
00:56:24,219 --> 00:56:29,499
hard you know this was designed by the

1274
00:56:26,259 --> 00:56:34,829
NSA which is really really good at it

1275
00:56:29,499 --> 00:56:37,718
and they missed a relatively simple

1276
00:56:34,829 --> 00:56:39,640
protocol failure and you know when you

1277
00:56:37,719 --> 00:56:41,919
design a mechanism that includes key

1278
00:56:39,640 --> 00:56:47,348
escrow you are designing a complex

1279
00:56:41,919 --> 00:56:48,669
cryptographic protocol that can fail in

1280
00:56:47,349 --> 00:56:50,769
ways that you don't anticipate

1281
00:56:48,669 --> 00:56:52,808
now this particular failure was a

1282
00:56:50,769 --> 00:56:54,729
failure that allowed you to use the

1283
00:56:52,809 --> 00:56:57,400
cipher more strongly but it could have

1284
00:56:54,729 --> 00:57:00,489
just as easily been a failure that

1285
00:56:57,400 --> 00:57:00,930
allowed anybody to decrypt communication

1286
00:57:00,489 --> 00:57:02,329
or

1287
00:57:00,930 --> 00:57:04,410
you know a man-in-the-middle

1288
00:57:02,329 --> 00:57:06,660
communication in some way that would

1289
00:57:04,410 --> 00:57:09,118
allow them to get access to it without

1290
00:57:06,660 --> 00:57:11,009
going through the escrow mechanism you

1291
00:57:09,119 --> 00:57:12,780
know and who for all we know clipper may

1292
00:57:11,010 --> 00:57:14,700
have also had some of those failures you

1293
00:57:12,780 --> 00:57:18,650
know people and a stopped looking at it

1294
00:57:14,700 --> 00:57:22,618
after the the first embarrassment

1295
00:57:18,650 --> 00:57:25,380
happened so you know I discovered the

1296
00:57:22,619 --> 00:57:27,710
first of them and so clipper itself went

1297
00:57:25,380 --> 00:57:30,599
away but the concept of key escrow

1298
00:57:27,710 --> 00:57:32,700
didn't now in the case of key escrow

1299
00:57:30,599 --> 00:57:35,309
there are two big problems which we also

1300
00:57:32,700 --> 00:57:37,890
take to heart have taken to heart now

1301
00:57:35,309 --> 00:57:40,020
the first is the obvious one which is

1302
00:57:37,890 --> 00:57:43,049
that there now needs to be a database of

1303
00:57:40,020 --> 00:57:46,109
keys and that needs to be protected in

1304
00:57:43,050 --> 00:57:49,290
some way and if it's not really really

1305
00:57:46,109 --> 00:57:51,450
really well protected it becomes a soft

1306
00:57:49,290 --> 00:57:54,150
target that gives you access to

1307
00:57:51,450 --> 00:57:56,790
everyone's communication that uses a

1308
00:57:54,150 --> 00:58:00,630
particular cipher that's bad

1309
00:57:56,790 --> 00:58:03,839
the other problem with key escrow is

1310
00:58:00,630 --> 00:58:06,920
it's expensive and a design constraint

1311
00:58:03,839 --> 00:58:11,880
and you know give essentially what

1312
00:58:06,920 --> 00:58:15,030
clipper did was created a an an

1313
00:58:11,880 --> 00:58:17,309
engineering economic that made it much

1314
00:58:15,030 --> 00:58:20,190
much cheaper to not bother with

1315
00:58:17,309 --> 00:58:21,990
encryption than to include it and I

1316
00:58:20,190 --> 00:58:24,420
think fundamentally that was the worst

1317
00:58:21,990 --> 00:58:27,000
problem with with clipper although it's

1318
00:58:24,420 --> 00:58:28,680
not the one that killed it I just make

1319
00:58:27,000 --> 00:58:31,740
one quick observation about the way I

1320
00:58:28,680 --> 00:58:35,399
think the policy world has responded to

1321
00:58:31,740 --> 00:58:38,848
that basic observation that it's very

1322
00:58:35,400 --> 00:58:41,670
hard to do this the from from the time

1323
00:58:38,849 --> 00:58:44,549
that Jim Comey when he was FBI director

1324
00:58:41,670 --> 00:58:48,869
kind of reopened the what the FBI calls

1325
00:58:44,549 --> 00:58:50,759
the go and dark issue Comey said yeah I

1326
00:58:48,869 --> 00:58:52,619
understand it's hard to do and I

1327
00:58:50,760 --> 00:58:55,530
understand government should not be

1328
00:58:52,619 --> 00:58:57,809
designing these systems you people in

1329
00:58:55,530 --> 00:58:59,670
Silicon Valley figure this out that is

1330
00:58:57,809 --> 00:59:01,500
you're building these systems you figure

1331
00:58:59,670 --> 00:59:04,650
out how to build this feature in we're

1332
00:59:01,500 --> 00:59:06,329
not going to tell you how to do it we're

1333
00:59:04,650 --> 00:59:12,000
just going to tell you that you have to

1334
00:59:06,329 --> 00:59:13,999
do it so so that kind of pushes the the

1335
00:59:12,000 --> 00:59:17,719
ball into the other court if

1336
00:59:13,999 --> 00:59:21,638
if you will I I don't think it changes

1337
00:59:17,719 --> 00:59:24,469
how hard the problem is I think it does

1338
00:59:21,639 --> 00:59:26,799
reflect in fact it reflects a

1339
00:59:24,469 --> 00:59:31,519
recognition of how hard the problem is

1340
00:59:26,799 --> 00:59:34,189
but it is a claim that it should be

1341
00:59:31,519 --> 00:59:36,348
solvable within kind of the same

1342
00:59:34,189 --> 00:59:38,359
security parameters as a lot of other

1343
00:59:36,349 --> 00:59:41,119
security systems are built and within

1344
00:59:38,359 --> 00:59:43,848
the same set of trade-offs that a lot of

1345
00:59:41,119 --> 00:59:45,259
other security systems exist in and and

1346
00:59:43,849 --> 00:59:47,359
again I think that's an argument that

1347
00:59:45,259 --> 00:59:49,339
requires kind of getting down to details

1348
00:59:47,359 --> 00:59:54,439
I don't think you can really have that

1349
00:59:49,339 --> 00:59:57,259
argument as to a the the highest level

1350
00:59:54,439 --> 00:59:58,908
abstraction of of an exceptional access

1351
00:59:57,259 --> 01:00:01,189
system I think you probably have to look

1352
00:59:58,909 --> 01:00:03,379
at particular cases and I think that's

1353
01:00:01,189 --> 01:00:04,939
ultimately where where this may be

1354
01:00:03,379 --> 01:00:07,159
heading yeah let me just add one quick

1355
01:00:04,939 --> 01:00:09,589
thing to that which is that one thing

1356
01:00:07,159 --> 01:00:12,529
that es crew does is it creates a really

1357
01:00:09,589 --> 01:00:13,909
bad failure mode right particularly when

1358
01:00:12,529 --> 01:00:15,379
you say you know let's leave it to

1359
01:00:13,909 --> 01:00:16,759
industry you can do all the crypto you

1360
01:00:15,379 --> 01:00:19,879
want just make sure you include a

1361
01:00:16,759 --> 01:00:23,059
backdoor what the failure mode is that

1362
01:00:19,879 --> 01:00:26,078
the backdoor is really crappy and then

1363
01:00:23,059 --> 01:00:28,429
it will be measured by whether it is

1364
01:00:26,079 --> 01:00:30,649
able to serve the needs of law

1365
01:00:28,429 --> 01:00:34,039
enforcement one way to serve the need of

1366
01:00:30,649 --> 01:00:37,098
law enforcement is all keys are a string

1367
01:00:34,039 --> 01:00:39,979
of all zeroes right that's that and that

1368
01:00:37,099 --> 01:00:42,619
works as a mechanism that will meet the

1369
01:00:39,979 --> 01:00:45,739
needs of law enforcement another way is

1370
01:00:42,619 --> 01:00:49,399
to put all keys in an Excel database on

1371
01:00:45,739 --> 01:00:52,009
the website of the of the vendor and

1372
01:00:49,399 --> 01:00:54,649
just anyone can download it and those

1373
01:00:52,009 --> 01:00:56,809
things all will work as a necro escrow

1374
01:00:54,649 --> 01:00:59,629
mechanism they just really really

1375
01:00:56,809 --> 01:01:02,119
seriously degrade the security and yet

1376
01:00:59,629 --> 01:01:04,788
they still become successful in the eyes

1377
01:01:02,119 --> 01:01:07,309
of the government and that's the failure

1378
01:01:04,789 --> 01:01:08,539
mode for a design mandate here and then

1379
01:01:07,309 --> 01:01:10,009
just want to follow up on something that

1380
01:01:08,539 --> 01:01:11,419
Denny was saying which is you know I

1381
01:01:10,009 --> 01:01:13,789
usually am very hard on law enforcement

1382
01:01:11,419 --> 01:01:15,439
I usually do a fairly soft on industry

1383
01:01:13,789 --> 01:01:17,089
as being the people that are building

1384
01:01:15,439 --> 01:01:18,828
these systems and have a hard time of

1385
01:01:17,089 --> 01:01:20,689
doing this because building secure

1386
01:01:18,829 --> 01:01:22,849
software is really hard we're terrible

1387
01:01:20,689 --> 01:01:24,469
at it but I gotta say you know everybody

1388
01:01:22,849 --> 01:01:27,030
wants to look like a genius when they're

1389
01:01:24,469 --> 01:01:28,650
raising series a but then

1390
01:01:27,030 --> 01:01:30,360
if you say or the wizards of the

1391
01:01:28,650 --> 01:01:31,590
geniuses of Silicon Valley look at all

1392
01:01:30,360 --> 01:01:33,840
the magical things we can do like

1393
01:01:31,590 --> 01:01:34,890
self-driving cars and artificial

1394
01:01:33,840 --> 01:01:36,390
intelligence and everything else and

1395
01:01:34,890 --> 01:01:38,580
then law enforcement comes student says

1396
01:01:36,390 --> 01:01:40,109
all right genius build this thing the

1397
01:01:38,580 --> 01:01:42,120
secure holding key that we're asking for

1398
01:01:40,110 --> 01:01:43,740
don't be surprised if they looked at you

1399
01:01:42,120 --> 01:01:44,940
kind of a scans with a raised eyebrow

1400
01:01:43,740 --> 01:01:46,830
and you're like well we can't do that

1401
01:01:44,940 --> 01:01:48,660
you know this is kind of like you know

1402
01:01:46,830 --> 01:01:50,880
to cool this industry accountable like

1403
01:01:48,660 --> 01:01:52,770
we kind of made this bed and now we're

1404
01:01:50,880 --> 01:01:54,600
kind of lying it you can dismiss this

1405
01:01:52,770 --> 01:01:56,370
like oh the nerd harder argument but

1406
01:01:54,600 --> 01:01:58,950
like if you want to be the super nerd

1407
01:01:56,370 --> 01:02:03,390
then you get asked to nerd harder well

1408
01:01:58,950 --> 01:02:06,569
show up and do it right adding one thing

1409
01:02:03,390 --> 01:02:09,960
in here when it came to the the new

1410
01:02:06,570 --> 01:02:12,660
Ghost user proposal I wrote a long set

1411
01:02:09,960 --> 01:02:15,720
of things that are on the ACLU website

1412
01:02:12,660 --> 01:02:18,000
and that's the more public version the

1413
01:02:15,720 --> 01:02:20,040
technical version goes goes into a lot

1414
01:02:18,000 --> 01:02:21,840
more detail where I did something

1415
01:02:20,040 --> 01:02:23,550
similar to what Matt did with clipper

1416
01:02:21,840 --> 01:02:27,480
and specifically called it out where I

1417
01:02:23,550 --> 01:02:32,430
showed how you could inevitably detect

1418
01:02:27,480 --> 01:02:35,430
the ghost ignore it lie to it etc so and

1419
01:02:32,430 --> 01:02:37,379
I definitely was reminded of the Clipper

1420
01:02:35,430 --> 01:02:41,549
thing that this was clipper again that

1421
01:02:37,380 --> 01:02:43,890
you're going to be able to just not play

1422
01:02:41,550 --> 01:02:47,130
the game or play a different game and

1423
01:02:43,890 --> 01:02:51,720
remember though with you put if you fast

1424
01:02:47,130 --> 01:02:54,960
forward you know Matt's vulnerability

1425
01:02:51,720 --> 01:02:59,180
discovery or you know Modi young found a

1426
01:02:54,960 --> 01:03:03,120
kind of related set of vulnerabilities a

1427
01:02:59,180 --> 01:03:06,180
year later I think put that in the

1428
01:03:03,120 --> 01:03:10,109
context of the UK law and the Australian

1429
01:03:06,180 --> 01:03:12,600
law where the valuation of those

1430
01:03:10,110 --> 01:03:14,790
vulnerabilities is going to happen in a

1431
01:03:12,600 --> 01:03:18,029
government process that forces a

1432
01:03:14,790 --> 01:03:20,040
discussion of trade-offs in some way and

1433
01:03:18,030 --> 01:03:24,150
says okay how bad is that

1434
01:03:20,040 --> 01:03:27,090
and are there mitigations and who could

1435
01:03:24,150 --> 01:03:28,950
do that and by the way and Rihanna's

1436
01:03:27,090 --> 01:03:32,280
been really a leader in pointing this

1437
01:03:28,950 --> 01:03:34,710
out it may also happen in secret but

1438
01:03:32,280 --> 01:03:36,810
whether it happens in secret or not and

1439
01:03:34,710 --> 01:03:38,880
I think we should all resist it

1440
01:03:36,810 --> 01:03:40,290
happening in secret I think there's

1441
01:03:38,880 --> 01:03:43,950
still a lot that we can

1442
01:03:40,290 --> 01:03:46,560
all contribute to a kind of a richer

1443
01:03:43,950 --> 01:03:48,330
technical analysis of exactly what these

1444
01:03:46,560 --> 01:03:49,770
concerns are and exactly what the

1445
01:03:48,330 --> 01:03:52,890
trade-offs are because eventually

1446
01:03:49,770 --> 01:03:54,870
they'll be unlike I mean the evaluation

1447
01:03:52,890 --> 01:03:56,580
of maths finding was basically the New

1448
01:03:54,870 --> 01:03:58,770
York Times it was basically kind of

1449
01:03:56,580 --> 01:04:02,640
popular reaction and people got all

1450
01:03:58,770 --> 01:04:04,140
upset and and and and so everyone the

1451
01:04:02,640 --> 01:04:05,879
government officials kind of backed off

1452
01:04:04,140 --> 01:04:08,040
and said okay well we don't want to you

1453
01:04:05,880 --> 01:04:10,350
know piss anyone off it sort of goes to

1454
01:04:08,040 --> 01:04:12,270
Rihanna's invocation of the you know the

1455
01:04:10,350 --> 01:04:13,200
kind of technical priesthood I think

1456
01:04:12,270 --> 01:04:14,820
we're going to be in a different

1457
01:04:13,200 --> 01:04:16,830
environment where there be going to be

1458
01:04:14,820 --> 01:04:19,920
people who are reasonably technically

1459
01:04:16,830 --> 01:04:21,750
competent who are going to evaluate kind

1460
01:04:19,920 --> 01:04:23,940
of the pros and cons of all these ideas

1461
01:04:21,750 --> 01:04:30,770
and we're gonna have to figure out how

1462
01:04:23,940 --> 01:04:33,900
to contribute to that okay next question

1463
01:04:30,770 --> 01:04:36,030
Eric grosse thank you all for spending

1464
01:04:33,900 --> 01:04:37,950
your time debating law enforcement on

1465
01:04:36,030 --> 01:04:41,040
this topic that gives me the luxury to

1466
01:04:37,950 --> 01:04:43,620
quietly design and build mice and

1467
01:04:41,040 --> 01:04:45,360
encrypted systems and I enjoy that a lot

1468
01:04:43,620 --> 01:04:48,180
more than those debates but I have a

1469
01:04:45,360 --> 01:04:50,610
question for you I regard the content

1470
01:04:48,180 --> 01:04:53,120
encryption in the communication and

1471
01:04:50,610 --> 01:04:56,160
storage systems I build as fait accompli

1472
01:04:53,120 --> 01:04:59,759
but they're still metadata which I'm

1473
01:04:56,160 --> 01:05:01,379
only lightly protecting I wonder if you

1474
01:04:59,760 --> 01:05:03,270
find in your debates with law

1475
01:05:01,380 --> 01:05:06,390
enforcement it would be useful to try

1476
01:05:03,270 --> 01:05:08,580
out the argument that today they still

1477
01:05:06,390 --> 01:05:10,140
have metadata available to them perhaps

1478
01:05:08,580 --> 01:05:14,580
only under a court order but at least

1479
01:05:10,140 --> 01:05:17,310
it's there available if they piss off

1480
01:05:14,580 --> 01:05:20,100
the software designers sufficient we may

1481
01:05:17,310 --> 01:05:22,049
choose to more tightly protect even the

1482
01:05:20,100 --> 01:05:24,480
metadata and they would be in a worse

1483
01:05:22,050 --> 01:05:26,520
way I don't actually want to go there

1484
01:05:24,480 --> 01:05:28,260
because as John was saying there are

1485
01:05:26,520 --> 01:05:30,960
actual problems out in the world that I

1486
01:05:28,260 --> 01:05:33,270
want law enforcement to help us with but

1487
01:05:30,960 --> 01:05:36,030
if they push me to the wall I'm willing

1488
01:05:33,270 --> 01:05:38,340
to do that do so I'm just wondering how

1489
01:05:36,030 --> 01:05:41,370
you feel that changes the dynamics of

1490
01:05:38,340 --> 01:05:43,200
the debate yeah I mean you know we're in

1491
01:05:41,370 --> 01:05:45,060
this golden age of metadata we're

1492
01:05:43,200 --> 01:05:47,640
creating much more of it than ever

1493
01:05:45,060 --> 01:05:50,430
before and metadata unlike your content

1494
01:05:47,640 --> 01:05:53,220
doesn't lie about what you're doing

1495
01:05:50,430 --> 01:05:55,078
you know metadata is you know tells you

1496
01:05:53,220 --> 01:05:57,240
who you're communicating with when you

1497
01:05:55,079 --> 01:05:59,520
were through communicating where you

1498
01:05:57,240 --> 01:06:01,709
were and so on and you know one

1499
01:05:59,520 --> 01:06:04,290
interesting distinction between content

1500
01:06:01,710 --> 01:06:07,290
protection and metadata protection is

1501
01:06:04,290 --> 01:06:09,900
it's really easy to do unilateral stuff

1502
01:06:07,290 --> 01:06:12,900
to do end-to-end content protection you

1503
01:06:09,900 --> 01:06:14,760
can encrypt content and to end and that

1504
01:06:12,900 --> 01:06:16,890
doesn't require help from the

1505
01:06:14,760 --> 01:06:19,109
infrastructure or only trivial help from

1506
01:06:16,890 --> 01:06:21,900
the infrastructure protecting metadata

1507
01:06:19,109 --> 01:06:24,690
is really hard to do and to end without

1508
01:06:21,900 --> 01:06:26,460
help extensive help from the

1509
01:06:24,690 --> 01:06:28,500
infrastructure itself you know I'm on

1510
01:06:26,460 --> 01:06:30,869
the board of tor tor is one way of

1511
01:06:28,500 --> 01:06:33,569
protecting metadata it's really you know

1512
01:06:30,869 --> 01:06:35,430
expensive it involves you know at least

1513
01:06:33,569 --> 01:06:37,470
three times more communication than you

1514
01:06:35,430 --> 01:06:39,390
would otherwise do you know it's not

1515
01:06:37,470 --> 01:06:42,328
clear that that scales well and it works

1516
01:06:39,390 --> 01:06:44,730
only for you know limited applications I

1517
01:06:42,329 --> 01:06:47,280
don't think even if we wanted to you

1518
01:06:44,730 --> 01:06:50,849
know as an industry as a community we're

1519
01:06:47,280 --> 01:06:53,130
gonna be able to do much about the

1520
01:06:50,849 --> 01:06:56,540
proliferation of metadata because it's

1521
01:06:53,130 --> 01:07:00,960
just a fundamentally harder thing to

1522
01:06:56,540 --> 01:07:03,210
protect you know that said law

1523
01:07:00,960 --> 01:07:06,150
enforcement has not in my experience

1524
01:07:03,210 --> 01:07:08,369
been terribly satisfied with the

1525
01:07:06,150 --> 01:07:11,819
argument that says hey look you've got

1526
01:07:08,369 --> 01:07:14,369
all this metadata you know the the anti

1527
01:07:11,819 --> 01:07:18,869
will inevitably get is yeah and we want

1528
01:07:14,369 --> 01:07:21,869
the content to go and that like you

1529
01:07:18,869 --> 01:07:23,970
bring up an interesting I think tension

1530
01:07:21,869 --> 01:07:26,670
in the policy debate which is that there

1531
01:07:23,970 --> 01:07:28,200
are a number of safety valves that I

1532
01:07:26,670 --> 01:07:30,119
think so far have prevented us from

1533
01:07:28,200 --> 01:07:33,720
seeing aggressive legislation at least

1534
01:07:30,119 --> 01:07:35,910
in the United States around encryption

1535
01:07:33,720 --> 01:07:37,770
design which is that there's kind of a

1536
01:07:35,910 --> 01:07:40,200
status quo where some things kind of

1537
01:07:37,770 --> 01:07:42,119
work okay I can't get into this

1538
01:07:40,200 --> 01:07:44,009
particular device unless I go and buy a

1539
01:07:42,119 --> 01:07:46,140
celebrate for however much taxpayer

1540
01:07:44,010 --> 01:07:48,000
money but I can go to Apple with a

1541
01:07:46,140 --> 01:07:49,859
warrant and get an iCloud backup from

1542
01:07:48,000 --> 01:07:52,890
the device Apple was in the news last

1543
01:07:49,859 --> 01:07:55,950
week for not encrypting backups from

1544
01:07:52,890 --> 01:07:57,450
phones and and and that's that's content

1545
01:07:55,950 --> 01:07:58,919
it's not metadata but the availability

1546
01:07:57,450 --> 01:08:00,129
of metadata and the availability of

1547
01:07:58,920 --> 01:08:02,890
things like backups

1548
01:08:00,130 --> 01:08:05,950
and cloud stored and so forth I think is

1549
01:08:02,890 --> 01:08:07,600
kind of a acts as a as a balancing act

1550
01:08:05,950 --> 01:08:09,790
where there's still enough available

1551
01:08:07,600 --> 01:08:12,009
that hopefully a law enforcement can

1552
01:08:09,790 --> 01:08:13,900
still do its job and solve the very real

1553
01:08:12,010 --> 01:08:16,030
problems are out there and so when we're

1554
01:08:13,900 --> 01:08:17,529
faced with a sort of a mandate of

1555
01:08:16,029 --> 01:08:19,179
progress of continually trying to

1556
01:08:17,529 --> 01:08:21,040
increment and making better and better

1557
01:08:19,180 --> 01:08:22,330
security and saying okay well how do we

1558
01:08:21,040 --> 01:08:24,609
protect metadata better how do we

1559
01:08:22,330 --> 01:08:26,260
protect backups better it's coming right

1560
01:08:24,609 --> 01:08:29,139
up against this tension of well that

1561
01:08:26,260 --> 01:08:30,880
also is going to conflict with changing

1562
01:08:29,140 --> 01:08:32,620
the state of affairs where there's still

1563
01:08:30,880 --> 01:08:35,529
the safety valve of enough information

1564
01:08:32,620 --> 01:08:37,029
out there to at least kind of keep law

1565
01:08:35,529 --> 01:08:38,889
enforcement at bay that I think we're

1566
01:08:37,029 --> 01:08:40,509
going to run right up further and

1567
01:08:38,890 --> 01:08:43,960
further against it as we progress here

1568
01:08:40,510 --> 01:08:47,950
so there Eric there's I think an

1569
01:08:43,960 --> 01:08:50,710
interesting tension actually in the the

1570
01:08:47,950 --> 01:08:52,359
way that we in the privacy community

1571
01:08:50,710 --> 01:08:55,090
approach this issue if you look at a lot

1572
01:08:52,359 --> 01:08:56,710
of the leading privacy debates now that

1573
01:08:55,090 --> 01:08:58,090
that get a lot that get a lot of

1574
01:08:56,710 --> 01:09:00,310
attention that go to the Supreme Court

1575
01:08:58,090 --> 01:09:01,840
you have you know debates like what

1576
01:09:00,310 --> 01:09:05,560
should law enforcement have to do to get

1577
01:09:01,840 --> 01:09:06,880
access to location metadata so so and

1578
01:09:05,560 --> 01:09:08,890
and you had you could hear a lot of

1579
01:09:06,880 --> 01:09:10,390
privacy advocates and privacy scholars

1580
01:09:08,890 --> 01:09:12,280
saying well actually the metadata is far

1581
01:09:10,390 --> 01:09:14,290
more revealing than the content and we

1582
01:09:12,279 --> 01:09:16,450
should be protecting the metadata at a

1583
01:09:14,290 --> 01:09:18,040
high or legal standard than we do the

1584
01:09:16,450 --> 01:09:20,410
content and there's good reason for that

1585
01:09:18,040 --> 01:09:23,019
because this mat said it doesn't lie and

1586
01:09:20,410 --> 01:09:26,349
it's also you know susceptible to

1587
01:09:23,020 --> 01:09:30,400
building much more comprehensive

1588
01:09:26,350 --> 01:09:32,710
pictures of a person's activity I guess

1589
01:09:30,399 --> 01:09:35,229
if I could Channel law enforcement for a

1590
01:09:32,710 --> 01:09:37,380
moment because I've spent a lot of time

1591
01:09:35,229 --> 01:09:41,859
with people in law enforcement and I

1592
01:09:37,380 --> 01:09:45,279
don't think their view is how did they

1593
01:09:41,859 --> 01:09:48,179
get a sort of a solution here that's

1594
01:09:45,279 --> 01:09:51,250
good enough they have the metadata today

1595
01:09:48,180 --> 01:09:57,240
so you're not really offering them much

1596
01:09:51,250 --> 01:10:01,750
by saying they can keep it they you know

1597
01:09:57,240 --> 01:10:03,309
for reasons that I I kind of respect the

1598
01:10:01,750 --> 01:10:05,610
law enforcement view of this issue

1599
01:10:03,310 --> 01:10:09,250
generally is that they need as much

1600
01:10:05,610 --> 01:10:12,099
capacity as much surveillance capacity

1601
01:10:09,250 --> 01:10:13,390
as is allowed in the US under the Fourth

1602
01:10:12,100 --> 01:10:16,300
Amendment

1603
01:10:13,390 --> 01:10:19,740
and I will just sort of push back a

1604
01:10:16,300 --> 01:10:22,720
little bit on John I understand the

1605
01:10:19,740 --> 01:10:25,150
importance of having private

1606
01:10:22,720 --> 01:10:27,190
conversations but we in fact don't have

1607
01:10:25,150 --> 01:10:29,769
either a human right or a right under

1608
01:10:27,190 --> 01:10:31,570
the US Constitution to any private

1609
01:10:29,770 --> 01:10:34,750
conversation at all we have that right

1610
01:10:31,570 --> 01:10:37,090
legally as constrained by law as

1611
01:10:34,750 --> 01:10:39,160
constrained by what courts when courts

1612
01:10:37,090 --> 01:10:40,990
decide government can intrude or not and

1613
01:10:39,160 --> 01:10:42,730
fundamentally the way that law

1614
01:10:40,990 --> 01:10:45,760
enforcement looks at this issue as you

1615
01:10:42,730 --> 01:10:47,559
know is that they're a bunch of

1616
01:10:45,760 --> 01:10:51,670
technical decisions that are being made

1617
01:10:47,560 --> 01:10:53,320
that in fact limit the legal authority

1618
01:10:51,670 --> 01:10:55,270
that law enforcement have they're not

1619
01:10:53,320 --> 01:10:57,639
they would say they're not trying to

1620
01:10:55,270 --> 01:11:00,310
change what the Fourth Amendment says

1621
01:10:57,640 --> 01:11:02,290
they think it's the technical community

1622
01:11:00,310 --> 01:11:06,490
that's trying to change what the Fourth

1623
01:11:02,290 --> 01:11:08,860
Amendment says and you know that's a

1624
01:11:06,490 --> 01:11:11,309
that's a sort of an abstract debate that

1625
01:11:08,860 --> 01:11:13,750
probably doesn't go very far I think

1626
01:11:11,310 --> 01:11:17,110
what I would say practically though to

1627
01:11:13,750 --> 01:11:20,200
your point is that I think that law

1628
01:11:17,110 --> 01:11:22,809
enforcement could use a lot of technical

1629
01:11:20,200 --> 01:11:24,820
assistance in understanding how to make

1630
01:11:22,810 --> 01:11:26,560
the most of metadata and had for

1631
01:11:24,820 --> 01:11:28,750
investigative purposes and how to make

1632
01:11:26,560 --> 01:11:31,780
the most of whatever data they do have

1633
01:11:28,750 --> 01:11:35,320
available and and I think that's been a

1634
01:11:31,780 --> 01:11:37,929
it's been a persistent problem the FBI

1635
01:11:35,320 --> 01:11:40,179
is not or much less local or state

1636
01:11:37,930 --> 01:11:42,940
police agencies is not necessarily the

1637
01:11:40,180 --> 01:11:45,310
sexiest place to work if you're if

1638
01:11:42,940 --> 01:11:47,160
you're technically really inclined but

1639
01:11:45,310 --> 01:11:49,990
maybe we should try to change that

1640
01:11:47,160 --> 01:11:53,370
because I don't I I think that some part

1641
01:11:49,990 --> 01:11:56,800
of what drives these problems is just

1642
01:11:53,370 --> 01:11:58,330
fundamental technical limitations in the

1643
01:11:56,800 --> 01:12:01,120
way that law enforcement conducts

1644
01:11:58,330 --> 01:12:04,720
investigations and I think if I think if

1645
01:12:01,120 --> 01:12:06,580
we could help with that generally it

1646
01:12:04,720 --> 01:12:11,980
would just take some of the pressure off

1647
01:12:06,580 --> 01:12:13,570
of this issue so yeah I I have a couple

1648
01:12:11,980 --> 01:12:16,509
of things one is that I said that it was

1649
01:12:13,570 --> 01:12:19,870
a fundamental human right it is not say

1650
01:12:16,510 --> 01:12:21,970
it was that if I was yes it is no it is

1651
01:12:19,870 --> 01:12:26,440
not enshrined in US law it's but that

1652
01:12:21,970 --> 01:12:28,570
merely means that that the US doesn't do

1653
01:12:26,440 --> 01:12:34,259
that that is not that's not what brights

1654
01:12:28,570 --> 01:12:34,259
are but anyway let's move let's move on

1655
01:12:34,440 --> 01:12:39,219
so I want to disagree they so there is

1656
01:12:37,989 --> 01:12:46,299
one other thing that I want to talk

1657
01:12:39,219 --> 01:12:47,760
about the techno music Sparrow anything

1658
01:12:46,300 --> 01:12:50,590
right now and we're finally starting

1659
01:12:47,760 --> 01:12:52,120
yeah yeah yeah that there are technical

1660
01:12:50,590 --> 01:12:54,699
things that we really do need to solve

1661
01:12:52,120 --> 01:12:55,960
that if you live in a world that has it

1662
01:12:54,699 --> 01:12:57,820
that has end-to-end encryption

1663
01:12:55,960 --> 01:12:59,500
everywhere and even if you have live in

1664
01:12:57,820 --> 01:13:02,019
a world that has a lot of data there are

1665
01:12:59,500 --> 01:13:05,170
things that we do not manage very well

1666
01:13:02,020 --> 01:13:07,420
for example ones digital assets are not

1667
01:13:05,170 --> 01:13:11,219
managed so that you can pass them on to

1668
01:13:07,420 --> 01:13:13,989
one's heirs one of the things that the

1669
01:13:11,219 --> 01:13:16,840
law enforcement people talked to me that

1670
01:13:13,989 --> 01:13:19,089
they find most heart-rending is for

1671
01:13:16,840 --> 01:13:21,040
example somebody gets murdered or a

1672
01:13:19,090 --> 01:13:23,199
horrible accident happens and they can't

1673
01:13:21,040 --> 01:13:26,019
open that phone up we really do need to

1674
01:13:23,199 --> 01:13:28,210
have a way that that you could say go to

1675
01:13:26,020 --> 01:13:30,580
somebody's heirs and say you know what

1676
01:13:28,210 --> 01:13:33,070
is their data say this is a problem also

1677
01:13:30,580 --> 01:13:35,500
worth solving but that doesn't mean that

1678
01:13:33,070 --> 01:13:40,330
we don't have a bunch of fundamental

1679
01:13:35,500 --> 01:13:43,210
rights so there are a whole bunch of

1680
01:13:40,330 --> 01:13:46,840
places where we can nerd harder the

1681
01:13:43,210 --> 01:13:48,699
problem that we have is that law

1682
01:13:46,840 --> 01:13:50,380
enforcement has a specific problem that

1683
01:13:48,699 --> 01:13:52,030
they want to solve and it is at the end

1684
01:13:50,380 --> 01:13:54,790
of the day get rid of encryption without

1685
01:13:52,030 --> 01:14:00,190
getting rid of encryption and that one

1686
01:13:54,790 --> 01:14:02,440
is extraordinarily hard and erricka

1687
01:14:00,190 --> 01:14:05,290
Portenoy for example wrote an excellent

1688
01:14:02,440 --> 01:14:07,000
article on how end-to-end encryption is

1689
01:14:05,290 --> 01:14:10,540
not merely syntactic but it's also

1690
01:14:07,000 --> 01:14:13,420
semantic and and and that's really

1691
01:14:10,540 --> 01:14:16,120
important to understand that that it

1692
01:14:13,420 --> 01:14:18,040
isn't just bits and bytes and that

1693
01:14:16,120 --> 01:14:19,269
continuing to talk about just bits and

1694
01:14:18,040 --> 01:14:21,880
bytes isn't going to get us anywhere

1695
01:14:19,270 --> 01:14:23,980
I've also been in places with the with

1696
01:14:21,880 --> 01:14:26,050
law enforcement who have said things

1697
01:14:23,980 --> 01:14:30,580
like the Fourth Amendment is an

1698
01:14:26,050 --> 01:14:33,250
obligation of the government to serve to

1699
01:14:30,580 --> 01:14:35,610
find things no matter where they do and

1700
01:14:33,250 --> 01:14:37,739
that if they don't find them the judge

1701
01:14:35,610 --> 01:14:39,750
punish them just like if we go back to

1702
01:14:37,739 --> 01:14:42,388
our bosses and say I'm sorry I couldn't

1703
01:14:39,750 --> 01:14:44,989
do that and every lawyer in the room

1704
01:14:42,389 --> 01:14:48,090
found that to be novel and innovative

1705
01:14:44,989 --> 01:14:49,259
all right I'm gonna we could go on

1706
01:14:48,090 --> 01:14:51,179
probably the whole day on this

1707
01:14:49,260 --> 01:14:52,710
conversation no it's amazing and I know

1708
01:14:51,179 --> 01:14:54,659
there are folks waiting to ask questions

1709
01:14:52,710 --> 01:14:57,150
unfortunately we are a little bit over

1710
01:14:54,659 --> 01:15:01,409
our schedule we have refreshments in the

1711
01:14:57,150 --> 01:15:04,049
back if we let's take a 20-25 min a

1712
01:15:01,409 --> 01:15:07,570
break and come back and most importantly

1713
01:15:04,050 --> 01:15:12,770
let's think our very first enigma panel

1714
01:15:07,570 --> 01:15:12,769
[Applause]

