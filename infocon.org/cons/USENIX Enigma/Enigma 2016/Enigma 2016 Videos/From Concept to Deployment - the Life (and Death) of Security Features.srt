1
00:00:00,198 --> 00:00:02,165


2
00:00:02,165 --> 00:00:05,032
♪♪

3
00:00:05,033 --> 00:00:07,264
[ Applause ]

4
00:00:07,264 --> 00:00:08,825
-Thank you.

5
00:00:08,825 --> 00:00:10,132
How many people have had security features

6
00:00:10,132 --> 00:00:12,594
go nowhere at all?

7
00:00:12,594 --> 00:00:14,495
I certainly have.

8
00:00:14,495 --> 00:00:16,000
We all come up with ideas

9
00:00:16,000 --> 00:00:18,000
that we think will improve security.

10
00:00:18,000 --> 00:00:20,198
And many of them are good ideas.

11
00:00:20,198 --> 00:00:23,363
During my PhD, I actually published some of these ideas.

12
00:00:23,363 --> 00:00:24,759
But here's the problem.

13
00:00:24,759 --> 00:00:26,297
Once the paper left the lab,

14
00:00:26,297 --> 00:00:27,627
I was on to the next thing.

15
00:00:27,627 --> 00:00:31,165
I didn't spend any time, invest any time,

16
00:00:31,165 --> 00:00:34,165
in actually selling these features.

17
00:00:34,165 --> 00:00:35,792
When I started up BlackBerry, I thought,

18
00:00:35,792 --> 00:00:37,660
"Hey, I've got an easy shot.

19
00:00:37,660 --> 00:00:41,032
I'll log a feature request, some magic will happen,

20
00:00:41,033 --> 00:00:43,792
and voilà -- everybody will be using my feature.

21
00:00:43,792 --> 00:00:46,165
But the real world doesn't work like that.

22
00:00:46,165 --> 00:00:49,825
And security features die all the time.

23
00:00:49,825 --> 00:00:53,957
What does it take to become a successful security feature?

24
00:00:53,957 --> 00:00:56,693
Well, let's take a look at an example -- Stack Cookies.

25
00:00:59,957 --> 00:01:01,759
There we go.

26
00:01:01,759 --> 00:01:04,593
In November of '96, Aleph One wrote an article

27
00:01:04,593 --> 00:01:08,297
for Phrack on "Smashing the Stack for Fun and Profit."

28
00:01:08,297 --> 00:01:10,726
In that article, he goes through in detail

29
00:01:10,726 --> 00:01:11,957
what it takes to exploit

30
00:01:11,957 --> 00:01:15,000
a stack-based buffer overflow vulnerability,

31
00:01:15,000 --> 00:01:17,429
trampling the return address.

32
00:01:17,429 --> 00:01:21,462
Well, in January '98,

33
00:01:21,462 --> 00:01:23,528
Crispin Cowan and a couple of other authors

34
00:01:23,528 --> 00:01:27,396
present a paper at Usenix Security, "StackGuard."

35
00:01:27,396 --> 00:01:28,594
Their goal is simple --

36
00:01:28,594 --> 00:01:30,627
to protect that return address on the stack.

37
00:01:30,627 --> 00:01:33,759
And the idea is also fairly simple, right?

38
00:01:33,759 --> 00:01:35,396
You put a cookie on the stack.

39
00:01:35,396 --> 00:01:38,099
Before you use the return address, you check the cookie.

40
00:01:38,099 --> 00:01:39,363
If the cookie's good,

41
00:01:39,363 --> 00:01:41,264
you have a high-probability chance

42
00:01:41,264 --> 00:01:43,923
that the return address is also good and you can use it.

43
00:01:43,924 --> 00:01:46,627
If the cookie's bad, abort the program.

44
00:01:46,627 --> 00:01:48,594
Don't touch the return address.

45
00:01:48,594 --> 00:01:50,857
But that's not the end of their story.

46
00:01:50,858 --> 00:01:54,198
In fact, that's just the beginning of their story.

47
00:01:56,231 --> 00:01:57,693
In August '98,

48
00:01:57,693 --> 00:02:01,033
they actually rewrite the patch, all right?

49
00:02:01,033 --> 00:02:02,462
StackGuard v2.

50
00:02:02,462 --> 00:02:04,627
And in May '99,

51
00:02:04,627 --> 00:02:07,066
they're at Linux Expo

52
00:02:07,066 --> 00:02:09,726
and they've actually got updated performance numbers.

53
00:02:09,726 --> 00:02:12,165
They'd recompiled a lot of the red hat packages

54
00:02:12,165 --> 00:02:14,000
to prove that the overhead

55
00:02:14,000 --> 00:02:17,396
in doing stack cookies wasn't that high.

56
00:02:17,396 --> 00:02:21,033
Next event on the timeline is January 2001,

57
00:02:21,033 --> 00:02:22,759
where ProPolice,

58
00:02:22,759 --> 00:02:24,131
which is done by some researchers

59
00:02:24,132 --> 00:02:28,066
at IBM Research Japan, is released.

60
00:02:28,066 --> 00:02:32,363
And this is another rewrite of the StackGuard patch.

61
00:02:32,363 --> 00:02:33,858
Next event on our timeline

62
00:02:33,858 --> 00:02:37,726
is actually Microsoft releasing Visual Studio in 2003.

63
00:02:37,726 --> 00:02:40,099
Now, Microsoft, when they released Visual Studio

64
00:02:40,099 --> 00:02:42,165
with Stack's matching defenses,

65
00:02:42,165 --> 00:02:44,792
didn't actually know about ProPolice,

66
00:02:44,792 --> 00:02:46,396
they didn't actually know about StackGuard.

67
00:02:46,396 --> 00:02:48,131
It was only after the release

68
00:02:48,132 --> 00:02:50,495
that they found out that these things existed.

69
00:02:52,891 --> 00:02:55,726
But that same year, Crispin and team,

70
00:02:55,726 --> 00:02:58,066
they're at the GCC Developers Conference, all right?

71
00:02:58,066 --> 00:02:59,957
And they're actually presenting the third version

72
00:02:59,957 --> 00:03:01,561
of the patch that they've written.

73
00:03:01,561 --> 00:03:05,528
So we're now at a total version of four versions of this patch.

74
00:03:05,528 --> 00:03:07,660
What's the end result of all of that work?

75
00:03:07,660 --> 00:03:11,957
Well, in 2005, June,

76
00:03:11,957 --> 00:03:15,528
GCC finally adopts ProPolice.

77
00:03:15,528 --> 00:03:16,858
Now, this is also interesting

78
00:03:16,858 --> 00:03:20,627
because the version they adopted wasn't actually ProPolice

79
00:03:20,627 --> 00:03:23,033
written by IBM Research Japan

80
00:03:23,033 --> 00:03:26,396
and it wasn't any of the three StackGuard patches.

81
00:03:26,396 --> 00:03:27,857
It was actually another version of the patch

82
00:03:27,858 --> 00:03:31,396
written by Richard Henderson at Red Hat.

83
00:03:31,396 --> 00:03:34,329
Now, once the patch had been adopted into GCC,

84
00:03:34,330 --> 00:03:35,660
the flood gates opened.

85
00:03:35,660 --> 00:03:38,297
And Red Hat appears to be the first major distro

86
00:03:38,297 --> 00:03:40,858
to include support for StackGuard, all right?

87
00:03:40,858 --> 00:03:43,891
That isn't overly surprising considering the final patch

88
00:03:43,891 --> 00:03:48,726
did come from someone at Red Hat.

89
00:03:48,726 --> 00:03:50,792
Ubuntu was in October 2006,

90
00:03:50,792 --> 00:03:54,792
SUSI was in December of 2006, Debian was in February of 2009,

91
00:03:54,792 --> 00:03:57,066
and Arch was in August 2011.

92
00:03:57,066 --> 00:03:59,264
Basically, Stack Cookies at that point

93
00:03:59,264 --> 00:04:00,957
had passed a tipping point.

94
00:04:00,957 --> 00:04:04,033
Now, the feature continued to get new improvements, all right?

95
00:04:04,033 --> 00:04:08,231
And in May 2013, the strong option was added.

96
00:04:08,231 --> 00:04:09,726
And adoption of that has been a lot quicker

97
00:04:09,726 --> 00:04:12,627
than the original work.

98
00:04:12,627 --> 00:04:14,726
What open -- oh. And finally --

99
00:04:14,726 --> 00:04:16,759
Sorry, can't forget this --

100
00:04:16,759 --> 00:04:22,363
In May -- sorry -- August 2013,

101
00:04:22,363 --> 00:04:24,561
that original '98 Usenix's paper

102
00:04:24,561 --> 00:04:26,462
won the Usenix Test of Time award.

103
00:04:26,462 --> 00:04:28,924
So, congratulations to the those authors.

104
00:04:28,924 --> 00:04:30,363
What opened the flood gates?

105
00:04:30,363 --> 00:04:32,363
It's fairly obvious.

106
00:04:32,363 --> 00:04:37,429
Adoption of the patch into GCC and Visual Studio.

107
00:04:37,429 --> 00:04:38,924
Let's take a look at another feature.

108
00:04:38,924 --> 00:04:40,957
I'm actually gonna use a feature developed internally

109
00:04:40,957 --> 00:04:43,198
within BlackBerry and is shipping on our Priv,

110
00:04:43,198 --> 00:04:45,527
which is our Android-based smartphone.

111
00:04:45,528 --> 00:04:47,000
If you take a look at Android permissions,

112
00:04:47,000 --> 00:04:49,132
there's five different permission levels --

113
00:04:49,132 --> 00:04:53,363
none, normal, dangerous, signature, and system.

114
00:04:53,363 --> 00:04:55,561
None -- well, that is what it sounds like.

115
00:04:55,561 --> 00:04:57,594
Normal permissions are automatically granted

116
00:04:57,594 --> 00:05:00,198
to any application that requests them.

117
00:05:00,198 --> 00:05:01,924
Dangerous permissions can be accepted

118
00:05:01,924 --> 00:05:03,957
or rejected by the end user.

119
00:05:03,957 --> 00:05:06,000
Signature permissions are only available

120
00:05:06,000 --> 00:05:10,132
to other applications that are signed with the same key.

121
00:05:10,132 --> 00:05:11,924
And system permissions are restricted

122
00:05:11,924 --> 00:05:14,099
to applications on the base system.

123
00:05:14,099 --> 00:05:16,924
What happens if you, as a third party developer,

124
00:05:16,924 --> 00:05:19,726
want to protect access to certain APIs?

125
00:05:19,726 --> 00:05:21,099
Well, you've really got three options.

126
00:05:21,099 --> 00:05:25,429
You've got normal, dangerous, and signature.

127
00:05:25,429 --> 00:05:28,626
Normal, as I said, is available to all applications.

128
00:05:28,627 --> 00:05:32,594
Dangerous puts enforcement in the hands of the end user.

129
00:05:32,594 --> 00:05:35,363
We've got three talks on usable security tomorrow.

130
00:05:35,363 --> 00:05:37,099
I don't think I'm giving anything away

131
00:05:37,099 --> 00:05:39,363
by saying that prompting the end user

132
00:05:39,363 --> 00:05:42,363
isn't always the best option, right?

133
00:05:42,363 --> 00:05:45,099
The third option -- signature.

134
00:05:45,099 --> 00:05:47,924
Well, signature might work for a small number of applications

135
00:05:47,924 --> 00:05:49,957
because you have to sign them all with the same key.

136
00:05:49,957 --> 00:05:51,198
But it doesn't scale.

137
00:05:51,198 --> 00:05:52,296
We've also got the problem

138
00:05:52,297 --> 00:05:54,000
that you have to install the application

139
00:05:54,000 --> 00:05:55,297
defining the permission

140
00:05:55,297 --> 00:05:57,000
before you install the application

141
00:05:57,000 --> 00:05:59,363
requesting the permission.

142
00:05:59,363 --> 00:06:01,000
So what did we do?

143
00:06:01,000 --> 00:06:03,528
Our solution within the security research group at BlackBerry

144
00:06:03,528 --> 00:06:06,396
was called "controlled open permissions."

145
00:06:08,528 --> 00:06:11,297
It allows the application package

146
00:06:11,297 --> 00:06:14,561
to be signed with different keys,

147
00:06:14,561 --> 00:06:16,792
but it doesn't offload enforcement

148
00:06:16,792 --> 00:06:18,263
on the end user.

149
00:06:18,264 --> 00:06:19,594
The concept's simple.

150
00:06:19,594 --> 00:06:22,264
The application requesting access to the content

151
00:06:22,264 --> 00:06:25,561
sends a token to the application hosting the content.

152
00:06:25,561 --> 00:06:27,495
The application hosting the content

153
00:06:27,495 --> 00:06:30,660
uses a verification publicly to verify the token.

154
00:06:30,660 --> 00:06:32,132
If the token successfully verifies,

155
00:06:32,132 --> 00:06:35,099
it sends the content back.

156
00:06:35,099 --> 00:06:38,659
So, how do we go about getting developers internally

157
00:06:38,660 --> 00:06:42,033
to use controlled open permissions?

158
00:06:42,033 --> 00:06:43,726
Well, we were lucky, all right?

159
00:06:43,726 --> 00:06:45,858
In our case, developers already realized

160
00:06:45,858 --> 00:06:46,957
that they had a problem

161
00:06:46,957 --> 00:06:48,726
and they were looking for a solution.

162
00:06:48,726 --> 00:06:51,759
In not -- Sorry.

163
00:06:51,759 --> 00:06:53,561
Not in all fields do people realize

164
00:06:53,561 --> 00:06:55,527
that there even is a problem.

165
00:06:55,528 --> 00:06:57,165
If you take a look at IOT,

166
00:06:57,165 --> 00:06:59,858
a lot of people are just now realizing

167
00:06:59,858 --> 00:07:03,462
that we have a big problem that needs solving.

168
00:07:03,462 --> 00:07:05,099
So the first step for us

169
00:07:05,099 --> 00:07:06,693
was actually convincing the developers

170
00:07:06,693 --> 00:07:09,527
that this would solve their problem.

171
00:07:09,528 --> 00:07:15,132
Selling your solution is entrepreneurship.

172
00:07:15,132 --> 00:07:17,099
It's less about the technical solution

173
00:07:17,099 --> 00:07:19,396
than it is about all that support and other stuff

174
00:07:19,396 --> 00:07:21,858
around the solution.

175
00:07:21,858 --> 00:07:24,660
For us, we had a short, concise description.

176
00:07:24,660 --> 00:07:27,660
We had prototype implementation.

177
00:07:27,660 --> 00:07:29,396
And we had detailed notes on how to use

178
00:07:29,396 --> 00:07:33,561
this prototype implementation.

179
00:07:33,561 --> 00:07:36,429
Conference papers are often too long,

180
00:07:36,429 --> 00:07:38,594
and you end up scaring away the exact people

181
00:07:38,594 --> 00:07:41,528
that you want to try and convince.

182
00:07:41,528 --> 00:07:43,165
We went to meetings.

183
00:07:43,165 --> 00:07:45,726
And, in fact, we even came in on the weekends,

184
00:07:45,726 --> 00:07:47,726
because in the transition of this research

185
00:07:47,726 --> 00:07:49,792
from prototype to implementation,

186
00:07:49,792 --> 00:07:52,066
the developers were using a hardware security module,

187
00:07:52,066 --> 00:07:54,000
or hardware signing module,

188
00:07:54,000 --> 00:07:55,891
that was out supporting different signatures,

189
00:07:55,891 --> 00:07:57,396
and that caused problems.

190
00:07:57,396 --> 00:08:00,396
Now, the key is someone had to work through those problems.

191
00:08:00,396 --> 00:08:01,825
And it gives you a lot of credibility

192
00:08:01,825 --> 00:08:04,231
if you work with the end users

193
00:08:04,231 --> 00:08:05,891
or the end developers

194
00:08:05,891 --> 00:08:09,429
to deploy and fix some of these issues.

195
00:08:09,429 --> 00:08:11,032
We all have --

196
00:08:11,033 --> 00:08:13,363
oh, the end result of this is we actually got the feature

197
00:08:13,363 --> 00:08:15,297
into the BlackBerry common infrastructure,

198
00:08:15,297 --> 00:08:17,198
which is a set of common libraries

199
00:08:17,198 --> 00:08:18,296
that all the BlackBerry-developed

200
00:08:18,297 --> 00:08:21,099
applications will use on the Priv.

201
00:08:21,099 --> 00:08:24,231
We all have a set of tools that we use for solving problems.

202
00:08:24,231 --> 00:08:25,924
This includes developers.

203
00:08:25,924 --> 00:08:27,395
It includes companies

204
00:08:27,396 --> 00:08:29,891
who are looking to satisfy customer requests.

205
00:08:29,891 --> 00:08:31,396
It includes product managers

206
00:08:31,396 --> 00:08:33,659
who are looking to find new features

207
00:08:33,659 --> 00:08:35,462
that customers are wanting.

208
00:08:35,462 --> 00:08:39,066
In fact, it includes most problems of life,

209
00:08:39,066 --> 00:08:41,627
including non-security related problems.

210
00:08:41,626 --> 00:08:44,560
So, how do we get our feature or tool to be used?

211
00:08:44,561 --> 00:08:46,000
Well, we need to make sure

212
00:08:46,000 --> 00:08:49,660
that the right feature gets into the diaper bag.

213
00:08:49,660 --> 00:08:53,000
Okay, why a diaper bag? Three reasons.

214
00:08:53,000 --> 00:08:57,033
First, diaper bag has limited space.

215
00:08:57,033 --> 00:08:59,561
We can't just keep throwing new features at the developer

216
00:08:59,561 --> 00:09:02,462
and expect them to use them all.

217
00:09:02,462 --> 00:09:05,231
How many Stack analysis tools are out there?

218
00:09:05,231 --> 00:09:06,462
Lots.

219
00:09:06,462 --> 00:09:08,396
How many do we expect the developer to use?

220
00:09:08,396 --> 00:09:11,098
One if we're lucky, right?

221
00:09:11,099 --> 00:09:13,660
And the fact that -- that -- that -- sorry.

222
00:09:13,660 --> 00:09:15,759
The static analysis tool that they use

223
00:09:15,759 --> 00:09:18,000
will be the one that they're most familiar with,

224
00:09:18,000 --> 00:09:19,957
the one that was mandated by management,

225
00:09:19,957 --> 00:09:22,660
or the one that everybody else seems to be using.

226
00:09:22,660 --> 00:09:25,363
Second, parents don't go into parenting

227
00:09:25,363 --> 00:09:28,264
with a five-day course on changing diapers.

228
00:09:28,264 --> 00:09:31,000
Yeah, I didn't think you thought -- sorry.

229
00:09:31,000 --> 00:09:32,660
You didn't think you'd hear about diapers in this talk,

230
00:09:32,660 --> 00:09:34,396
did you?

231
00:09:34,396 --> 00:09:36,759
All right, computer science students

232
00:09:36,759 --> 00:09:40,495
don't go into business even with a whole course on security

233
00:09:40,495 --> 00:09:42,231
a lot of the time.

234
00:09:42,231 --> 00:09:43,957
And Zachary Peterson has a talk about this

235
00:09:43,957 --> 00:09:46,957
on the third day of Enigma.

236
00:09:46,957 --> 00:09:48,264
Both the diaper on the left

237
00:09:48,264 --> 00:09:51,000
and the diaper on the right work.

238
00:09:51,000 --> 00:09:54,627
But which one do you think is in more people's diaper bags?

239
00:09:54,627 --> 00:09:56,858
People are comfortable with learning,

240
00:09:56,858 --> 00:10:00,462
and they're comfortable with messing up once or twice.

241
00:10:00,462 --> 00:10:01,891
But if they don't learn it quickly enough,

242
00:10:01,891 --> 00:10:04,198
they will switch.

243
00:10:04,198 --> 00:10:07,098
How many of us have had a lesson on using a compiler?

244
00:10:07,099 --> 00:10:09,066
I'm gonna guess almost none of us.

245
00:10:09,066 --> 00:10:12,429
There's 2,000 different command line options for GCC.

246
00:10:12,429 --> 00:10:13,824
That's a lot of options.

247
00:10:13,825 --> 00:10:17,627
I only know a very, very, very small number of those.

248
00:10:17,627 --> 00:10:22,032
We can't assume that people will use security tools directly.

249
00:10:22,033 --> 00:10:24,198
In fact, I've seen cases where the security checks

250
00:10:24,198 --> 00:10:27,297
were disabled in static analysis tools.

251
00:10:27,297 --> 00:10:29,363
We need to make it as easy as possible.

252
00:10:31,495 --> 00:10:33,726
And third, diaper bag

253
00:10:33,726 --> 00:10:38,132
is already filled part-way with necessary pieces.

254
00:10:38,132 --> 00:10:41,957
I wish I could tell my daughter to just go on the potty.

255
00:10:41,957 --> 00:10:44,198
And then I could just throw everything out of the diaper bag

256
00:10:44,198 --> 00:10:47,462
and use it to carry cooler things instead of diapers.

257
00:10:47,462 --> 00:10:49,792
But it doesn't work like that.

258
00:10:49,792 --> 00:10:51,363
We can't just tell a developer

259
00:10:51,363 --> 00:10:53,033
to throw out everything that they have been using

260
00:10:53,033 --> 00:10:56,099
and use this cool, new development environment.

261
00:10:56,099 --> 00:10:57,528
We still have Seed,

262
00:10:57,528 --> 00:10:59,462
even with the problems that it causes,

263
00:10:59,462 --> 00:11:02,924
because of the benefits that it also provides.

264
00:11:02,924 --> 00:11:04,363
The translation or transition

265
00:11:04,363 --> 00:11:07,495
from IPv4 to IPv6 has been really slow.

266
00:11:07,495 --> 00:11:09,165
And in fact, I'm not sure that IPv4

267
00:11:09,165 --> 00:11:11,759
is gonna be dead in my lifetime.

268
00:11:11,759 --> 00:11:13,132
A developer needs a compiler.

269
00:11:13,132 --> 00:11:15,231
They need a development environment.

270
00:11:15,231 --> 00:11:17,429
They need certain libraries and support.

271
00:11:17,429 --> 00:11:19,792
And that takes a large amount of space in the bag,

272
00:11:19,792 --> 00:11:22,000
and it leaves a very limited amount of space

273
00:11:22,000 --> 00:11:24,660
for other standalone tools.

274
00:11:24,660 --> 00:11:27,462
Okay, so how do you go about getting your security tool

275
00:11:27,462 --> 00:11:29,924
or feature into the diaper bag?

276
00:11:29,924 --> 00:11:31,329
Well, option one --

277
00:11:31,330 --> 00:11:35,330
convince the developer to throw something else out.

278
00:11:35,330 --> 00:11:37,165
What are they gonna stop using?

279
00:11:37,165 --> 00:11:40,429
Is there another tool that yours can replace entirely?

280
00:11:40,429 --> 00:11:42,396
Does your tool require relearning,

281
00:11:42,396 --> 00:11:45,165
or does it work similar to that old tool?

282
00:11:45,165 --> 00:11:47,560
Can you convince them to switch compilers?

283
00:11:47,561 --> 00:11:48,891
Is there another template library

284
00:11:48,891 --> 00:11:50,824
that has better cross-site scripting protections

285
00:11:50,825 --> 00:11:52,891
than the other one?

286
00:11:52,891 --> 00:11:54,824
Accession is an example

287
00:11:54,825 --> 00:11:57,693
of one tool trying to replace another.

288
00:11:57,693 --> 00:12:01,231
SSH gave administrators things that were really useful,

289
00:12:01,231 --> 00:12:03,363
like automatic log-ins and file transfer

290
00:12:03,363 --> 00:12:05,066
and other things.

291
00:12:05,066 --> 00:12:06,066
The resistance to switching

292
00:12:06,066 --> 00:12:07,363
means you need to be much better,

293
00:12:07,363 --> 00:12:08,825
not just a little bit better

294
00:12:08,825 --> 00:12:11,429
than the tool you're looking to replace.

295
00:12:11,429 --> 00:12:14,924
Option two -- make your tool small and easy to use.

296
00:12:14,924 --> 00:12:17,891
And I'm not talking small in terms of lines of code.

297
00:12:17,891 --> 00:12:20,198
I'm talking small in terms of cognitive load.

298
00:12:22,198 --> 00:12:23,693
There is a small amount of space

299
00:12:23,693 --> 00:12:26,132
in the diaper bag to add something new,

300
00:12:26,132 --> 00:12:29,891
especially if it fits well with the current workflow.

301
00:12:29,891 --> 00:12:32,791
Valgrind's an example of this.

302
00:12:32,792 --> 00:12:35,033
Compile your program with this extra library,

303
00:12:35,033 --> 00:12:38,033
and you get this extra error checking.

304
00:12:38,033 --> 00:12:39,594
Option three --

305
00:12:39,594 --> 00:12:40,858
add your feature or tool

306
00:12:40,858 --> 00:12:43,065
to something else that's already in there.

307
00:12:43,066 --> 00:12:46,297
That's what happened when StackGuard got included in GCC.

308
00:12:46,297 --> 00:12:49,231
And there's a whole field of compiler protections --

309
00:12:49,231 --> 00:12:51,594
shadow stacks, new warnings,

310
00:12:51,594 --> 00:12:53,957
new errors, those sorts of things --

311
00:12:53,957 --> 00:12:56,593
that are being introduced into compilers.

312
00:12:58,891 --> 00:13:00,858
Static analysis --

313
00:13:00,858 --> 00:13:02,263
can you add your rule

314
00:13:02,264 --> 00:13:04,660
to an existing static analysis tool,

315
00:13:04,660 --> 00:13:05,924
or do you really need to create

316
00:13:05,924 --> 00:13:09,363
a whole new static analysis tool kit?

317
00:13:09,363 --> 00:13:11,033
Now, with static analysis,

318
00:13:11,033 --> 00:13:13,792
just make sure you don't turn on everything all at once.

319
00:13:13,792 --> 00:13:16,066
You don't want to overwhelm them.

320
00:13:16,066 --> 00:13:17,429
And option four --

321
00:13:17,429 --> 00:13:20,264
okay, and I know I'm cheating just a little bit --

322
00:13:20,264 --> 00:13:22,495
don't put your feature in the diaper bag.

323
00:13:22,495 --> 00:13:25,396
Make the baby carry it.

324
00:13:25,396 --> 00:13:30,627
All right, developers operate within a specific environment.

325
00:13:30,627 --> 00:13:33,693
So make your feature part of that environment.

326
00:13:33,693 --> 00:13:36,396
ASLR -- address space lay at randomization --

327
00:13:36,396 --> 00:13:38,462
is an example of this.

328
00:13:38,462 --> 00:13:40,000
On mobile platforms,

329
00:13:40,000 --> 00:13:41,957
we have the sandboxing environment

330
00:13:41,957 --> 00:13:45,858
that's provided by default to all the application developers.

331
00:13:45,858 --> 00:13:49,462
If you take a look at most Android applications,

332
00:13:49,462 --> 00:13:50,759
they're written in Java.

333
00:13:50,759 --> 00:13:52,066
Why is that?

334
00:13:52,066 --> 00:13:54,396
Because Java's the default development environment

335
00:13:54,396 --> 00:13:57,693
that's provided to them.

336
00:13:57,693 --> 00:13:59,759
If you're gonna create a new smartphone,

337
00:13:59,759 --> 00:14:02,594
my suggestion -- don't do it in Ada.

338
00:14:02,594 --> 00:14:04,825
Although Ada might be secure,

339
00:14:04,825 --> 00:14:07,198
you're not gonna get that broad deployability

340
00:14:07,198 --> 00:14:10,165
that you're looking for.

341
00:14:10,165 --> 00:14:13,165
For StackGuard, getting the feature into GCC

342
00:14:13,165 --> 00:14:14,363
was their tipping point.

343
00:14:14,363 --> 00:14:16,132
And they didn't reach that tipping point

344
00:14:16,132 --> 00:14:18,165
by releasing the GCC patch.

345
00:14:18,165 --> 00:14:19,791
Remember, they released that GCC patch --

346
00:14:19,792 --> 00:14:22,957
the first version of it -- back in '98.

347
00:14:22,957 --> 00:14:24,759
You will not reach that tipping point

348
00:14:24,759 --> 00:14:27,066
just by releasing a patch with your paper.

349
00:14:29,264 --> 00:14:30,759
They reach the tipping point

350
00:14:30,759 --> 00:14:32,594
because others understood the problem

351
00:14:32,594 --> 00:14:34,561
and the value of their solution.

352
00:14:34,561 --> 00:14:36,099
Microsoft released first

353
00:14:36,099 --> 00:14:39,132
probably because the internal security team at Microsoft

354
00:14:39,132 --> 00:14:41,924
had less people to convince.

355
00:14:41,924 --> 00:14:44,165
SELinux is used partly

356
00:14:44,165 --> 00:14:47,891
because it's part of the Linux environment.

357
00:14:47,891 --> 00:14:49,560
But even they didn't get it in right away.

358
00:14:49,561 --> 00:14:50,759
They had to create

359
00:14:50,759 --> 00:14:52,693
the whole Linux security module's framework.

360
00:14:52,693 --> 00:14:55,891
And they had to listen to the feedback

361
00:14:55,891 --> 00:14:56,957
that they were getting,

362
00:14:56,957 --> 00:14:58,627
take those suggestions seriously,

363
00:14:58,627 --> 00:15:01,429
and work with them, not get discouraged.

364
00:15:01,429 --> 00:15:03,957
For controlled open permissions within BlackBerry,

365
00:15:03,957 --> 00:15:05,429
the tipping point was getting it

366
00:15:05,429 --> 00:15:07,891
into the BlackBerry common infrastructure.

367
00:15:07,891 --> 00:15:10,462
For many features, it's gonna be getting them

368
00:15:10,462 --> 00:15:15,593
into that developer diaper bag or onto the baby.

369
00:15:15,594 --> 00:15:18,693
However, that's not the only tipping point.

370
00:15:18,693 --> 00:15:20,231
And there's two others.

371
00:15:20,231 --> 00:15:22,825
The second is legislative changes.

372
00:15:22,825 --> 00:15:26,429
Not all security features are used because they're elegant.

373
00:15:26,429 --> 00:15:28,693
But promoting proper legislative frameworks

374
00:15:28,693 --> 00:15:29,924
is a whole nother talk

375
00:15:29,924 --> 00:15:32,462
and one I'm not gonna get into.

376
00:15:32,462 --> 00:15:34,429
And the third is public pressure.

377
00:15:34,429 --> 00:15:38,363
HTTPS has long been a part of the web developer diaper bag,

378
00:15:38,363 --> 00:15:41,297
but not everybody has used it.

379
00:15:41,297 --> 00:15:43,627
Edward Snowden is working on changing this --

380
00:15:43,627 --> 00:15:45,098
or has done a lot to change

381
00:15:45,099 --> 00:15:48,165
and help people to re-evaluate the security features

382
00:15:48,165 --> 00:15:50,791
that they are using.

383
00:15:50,792 --> 00:15:52,561
And things like Let's Encrypt

384
00:15:52,561 --> 00:15:56,693
are helping to provide even easier tools.

385
00:15:56,693 --> 00:15:58,462
What if your feature isn't for end developers, though?

386
00:15:58,462 --> 00:15:59,891
What if it's for users?

387
00:15:59,891 --> 00:16:01,495
Well, the approach is the same,

388
00:16:01,495 --> 00:16:03,660
but the target audience isn't.

389
00:16:03,660 --> 00:16:06,924
You need to convince the people in key areas

390
00:16:06,924 --> 00:16:08,693
that they have a problem

391
00:16:08,693 --> 00:16:11,396
and you have the solution to that problem.

392
00:16:11,396 --> 00:16:14,791
And remember, those people might not be security experts.

393
00:16:14,792 --> 00:16:16,231
I know on a couple of occasions

394
00:16:16,231 --> 00:16:18,726
I've had to take deep breath and relax

395
00:16:18,726 --> 00:16:22,792
in trying to explain and sell security.

396
00:16:22,792 --> 00:16:25,297
PointGuard, which is some of the subsequent work

397
00:16:25,297 --> 00:16:27,759
that Crispin did, it died.

398
00:16:27,759 --> 00:16:30,297
I've had security features die, as well.

399
00:16:30,297 --> 00:16:31,561
Cause of death --

400
00:16:31,561 --> 00:16:35,231
failure to pass that tipping point.

401
00:16:35,231 --> 00:16:38,264
For StackGuard, it took probably about six months

402
00:16:38,264 --> 00:16:40,594
to write the paper and initial prototype

403
00:16:40,594 --> 00:16:43,924
and seven years to pass the tipping point.

404
00:16:43,924 --> 00:16:47,693
Adding your feature to a tool that's already in the diaper bag

405
00:16:47,693 --> 00:16:49,462
is probably going to be easier

406
00:16:49,462 --> 00:16:51,363
than adding a new tool to the diaper bag.

407
00:16:51,363 --> 00:16:53,792
Although, that's just my personal experience.

408
00:16:53,792 --> 00:16:56,000
And I haven't found any bullet-proof approach.

409
00:16:56,000 --> 00:16:57,396
But things that help --

410
00:16:57,396 --> 00:17:01,396
elevator pitch, brief summary, and collaborations.

411
00:17:01,396 --> 00:17:03,858
And in fact, the closer the collaboration, the better.

412
00:17:03,858 --> 00:17:06,329
It's been suggested that the most successful way

413
00:17:06,329 --> 00:17:11,032
to transfer research into technology or into product

414
00:17:11,032 --> 00:17:14,593
is to transfer the people who worked on the research.

415
00:17:14,594 --> 00:17:17,462
It allows those most passionate about the research

416
00:17:17,462 --> 00:17:19,329
to help those who are responsible

417
00:17:19,329 --> 00:17:22,231
for its eventual deployment.

418
00:17:22,231 --> 00:17:24,098
Our goal as security professionals

419
00:17:24,098 --> 00:17:26,693
should be to change the world for the better.

420
00:17:26,693 --> 00:17:30,594
So let's all get out there and build better diaper bags.

421
00:17:30,594 --> 00:17:32,594
[ Applause ]

422
00:17:32,594 --> 00:17:31,594


