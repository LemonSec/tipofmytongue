1
00:00:08,710 --> 00:00:15,980
users are not the enemy that's a catch
phrase coined by Angela Sasse want to

2
00:00:15,980 --> 00:00:20,430
founders of the research domain of
usable security privacy and we've just

3
00:00:20,430 --> 00:00:26,529
heard two excellent talks on why we
should not happen at the serial position

4
00:00:26,529 --> 00:00:31,270
towards the end user and we should be
helping them and creating more usable

5
00:00:31,270 --> 00:00:39,250
security technology I would like to
extend this idea and say developers are

6
00:00:39,250 --> 00:00:44,739
not the enemy either and I think this is
a really key thing we as a mainly to be

7
00:00:44,739 --> 00:00:49,800
focusing on in the near future and in
the course of this talk I hope I'll be

8
00:00:49,800 --> 00:00:52,599
able to convince you of this idea and to
do that I'll give you a brief

9
00:00:52,600 --> 00:00:57,339
introduction on this migration from
looking at the end user looking to

10
00:00:57,339 --> 00:01:01,870
develop and then I'll dive in deep into
two stories which happened in my own

11
00:01:01,870 --> 00:01:06,720
room where we have been focusing on
developments may use the term developer

12
00:01:06,720 --> 00:01:12,300
fairly broadly here to mean anybody who
is on more technical side of things so

13
00:01:12,300 --> 00:01:15,810
people who develop code it also people
who that's akin figure systems

14
00:01:15,810 --> 00:01:23,009
administrators all security analysts so
the origins of usable security have as

15
00:01:23,009 --> 00:01:29,290
the last two talks shown focus on the
end user and very popular topic is

16
00:01:29,290 --> 00:01:33,600
warning message and you see one here and
it's filled with also technical details

17
00:01:33,600 --> 00:01:38,429
and what the end user usually actually
sees is probably something more like

18
00:01:38,430 --> 00:01:44,690
this

19
00:01:44,690 --> 00:01:53,570
and that is so true he mentioned the 13
big problems is a bit relation soyuz's

20
00:01:53,570 --> 00:01:57,710
see hundreds of these warnings and they
all look the same and the likelihood of

21
00:01:57,710 --> 00:02:02,740
it being attacked is so incredibly low
so there will be thousands and thousands

22
00:02:02,740 --> 00:02:08,369
of false positive warnings for every
single true warning and the reason

23
00:02:08,369 --> 00:02:13,950
behind bad is also human error so in
2013 in collaboration with Google we

24
00:02:13,950 --> 00:02:19,540
actually looked at all the disputes the
Google crawler could find a given year

25
00:02:19,540 --> 00:02:24,329
we found four and a half million unique
certificates of which six hundred and

26
00:02:24,330 --> 00:02:30,500
ten thousand certificates were bad I
they would cause a user to see warning

27
00:02:30,500 --> 00:02:35,980
message if they visit that side now each
of those certificates was installed by

28
00:02:35,980 --> 00:02:40,609
human and you will be some good if we
can help those administrators who are

29
00:02:40,610 --> 00:02:45,070
making mistakes they're considered the
system in a way that the user do not see

30
00:02:45,070 --> 00:02:49,030
false-positive warnings and if we manage
to do that the warning message design

31
00:02:49,030 --> 00:02:53,750
problem will become much much easier
because we don't have to differentiate

32
00:02:53,750 --> 00:02:56,190
between false and true positives anymore

33
00:02:56,190 --> 00:03:01,600
another good example of where usual
security is very active as passwords

34
00:03:01,600 --> 00:03:06,049
this is still one of the most popular
password is the most popular password in

35
00:03:06,050 --> 00:03:12,930
2015 and of course trying to get use to
secure passwords is a very interesting

36
00:03:12,930 --> 00:03:17,530
problem in many strategies exist so one
thing for instance which we are looking

37
00:03:17,530 --> 00:03:22,470
at is when a passphrase is like correct
horse battery staple as suggested by the

38
00:03:22,470 --> 00:03:26,609
xkcd comic is actually a better way to
create passwords and having these

39
00:03:26,610 --> 00:03:30,880
current eight characters numbers and
special symbols and things like that and

40
00:03:30,880 --> 00:03:36,060
that's a very worthwhile field of study
because passwords are so important

41
00:03:36,060 --> 00:03:41,940
everything about him the really bad
password mistakes aren't done by the end

42
00:03:41,940 --> 00:03:46,540
user than done by administrators and
developers who don't salted hash their

43
00:03:46,540 --> 00:03:51,190
passwords leading to password database
compromises affecting millions of users

44
00:03:51,190 --> 00:03:56,609
so we have a single actor with a lot of
technical skill making

45
00:03:56,610 --> 00:04:01,220
a small mistake and that affects
millions of users and is not hard to see

46
00:04:01,220 --> 00:04:06,950
why that happens what you see here is a
tutorial from Stack Overflow on how to

47
00:04:06,950 --> 00:04:12,230
store passwords securely using a bouncy
castle library and as you can see there

48
00:04:12,230 --> 00:04:15,570
are a lot of technical details again
right and they do have to be right

49
00:04:15,570 --> 00:04:20,810
entirely to make matters worse this
actually is now completely outdated so

50
00:04:20,810 --> 00:04:24,220
the first thing you shine on Stack
Overflow no longer shows you how to do

51
00:04:24,220 --> 00:04:28,200
it properly because it's just a couple
of years old and again if one mistake is

52
00:04:28,200 --> 00:04:33,270
made you might lose the whole thing is
another wonderful example of a developer

53
00:04:33,270 --> 00:04:38,370
making mistake this is the code of the
Apple go to sales so you just have one

54
00:04:38,370 --> 00:04:44,650
line too many and suddenly security goes
away and highly so we do live in a in an

55
00:04:44,650 --> 00:04:52,090
environment where a single small design
floor can have catastrophic for your

56
00:04:52,090 --> 00:04:57,849
entire system so looking at the end user
really is only the tip of the iceberg we

57
00:04:57,850 --> 00:04:58,590
need to look at

58
00:04:58,590 --> 00:05:04,020
administrators developers and security
analysts in much more detail and help

59
00:05:04,020 --> 00:05:09,060
them create secure systems and working
with developers incredibly fun

60
00:05:09,060 --> 00:05:13,850
developers are very creative people if
they have a problem they will find a

61
00:05:13,850 --> 00:05:15,710
solution

62
00:05:15,710 --> 00:05:19,820
sometimes security and safety won't be
foremost on their minds

63
00:05:19,820 --> 00:05:25,070
am without wheels will start with the
first story was played out in my group a

64
00:05:25,070 --> 00:05:29,390
couple of years ago and that's
concerning HTTPS an Android so one of my

65
00:05:29,390 --> 00:05:34,580
students was creating an app for our
work and you want to use SSL to protect

66
00:05:34,580 --> 00:05:39,180
the connection and she ran into problems
quite interesting because the default

67
00:05:39,180 --> 00:05:44,280
implementation of Android does do HDDs
nomination completely correctly however

68
00:05:44,280 --> 00:05:49,349
only if you have no special wishes in
our case my student want to work with a

69
00:05:49,350 --> 00:05:53,560
self-signed certificate and that doesn't
work out of the box so you have to write

70
00:05:53,560 --> 00:05:59,470
custom code to enable that and he did
what most of us do when you're with an

71
00:05:59,470 --> 00:06:04,140
error message he turned to Google and
ask what to do and he found a lot of

72
00:06:04,140 --> 00:06:05,979
forums covering this problem

73
00:06:05,980 --> 00:06:09,930
and while the night cruise was the
question what I'm getting an error of

74
00:06:09,930 --> 00:06:14,630
the type of job X net as ill as an
exception not trusted service

75
00:06:14,630 --> 00:06:17,940
certificate and then there's a lot of
texts ranting on how annoying that

76
00:06:17,940 --> 00:06:22,080
wasn't it kind of ended up with saying
as than 40 hours researching and trying

77
00:06:22,080 --> 00:06:26,570
to figure out this workaround for this
issue and the answer was a one-line it

78
00:06:26,570 --> 00:06:30,730
was just saying look at this at oriole
no link to tutorial which led to some

79
00:06:30,730 --> 00:06:33,400
source code which turned security off
entirely

80
00:06:33,400 --> 00:06:38,710
naturally that didn't make the air away
but it might not have been quite what

81
00:06:38,710 --> 00:06:43,770
the developers intended and my student
continue looking and found lots of code

82
00:06:43,770 --> 00:06:48,419
would look like mass so you'd find
tutorials saying well you can use this

83
00:06:48,420 --> 00:06:52,860
trust man room and a problem will go
away range you looking to the the two

84
00:06:52,860 --> 00:06:55,720
methods and you see where the security
should be happening there's also a

85
00:06:55,720 --> 00:07:04,500
common saying do nothing and that got us
thinking if if we a security experts are

86
00:07:04,500 --> 00:07:08,430
having a hard time finding code how to
do it correctly how much would be for

87
00:07:08,430 --> 00:07:13,760
all the other developers so we conducted
a large-scale analysis looked at 13,500

88
00:07:13,760 --> 00:07:19,930
popular free apps on Android and we
found thousands of apps containing code

89
00:07:19,930 --> 00:07:24,070
which potentially would turn on
validation all based on different kind

90
00:07:24,070 --> 00:07:27,409
of trust managers and actually there
were only a small number of trust

91
00:07:27,410 --> 00:07:33,600
managers which we being used by a lot of
apps now some of the names are quite

92
00:07:33,600 --> 00:07:39,540
obvious so the fake trust manager
although dummy trust manager you pretty

93
00:07:39,540 --> 00:07:42,870
much know what according to the
developer using one of those and other

94
00:07:42,870 --> 00:07:47,200
names a little bit more tricky so the
easy X 509 craftsmen the simple trust

95
00:07:47,200 --> 00:07:51,360
man in the open trust man all
potentially sound like something which

96
00:07:51,360 --> 00:07:55,160
is just taking the work away from you
and is offering you a simple but still

97
00:07:55,160 --> 00:08:03,760
secure solution that wasn't the case we
found many many apps which had

98
00:08:03,760 --> 00:08:05,680
potentially unsafe code

99
00:08:05,680 --> 00:08:10,130
just static analysis we weren't quite
sure if maybe was just for debug

100
00:08:10,130 --> 00:08:11,330
purposes

101
00:08:11,330 --> 00:08:14,780
cherry pick the hundred apps and
actually tried to attack them and see

102
00:08:14,780 --> 00:08:16,320
what happened and

103
00:08:16,320 --> 00:08:21,190
we found 4100 would actually lead
credentials and we found a whole host of

104
00:08:21,190 --> 00:08:24,270
things everything from credit card
details to Logans to all the big

105
00:08:24,270 --> 00:08:29,640
services and he's 41 apps had an install
base somewhere between thirty 985

106
00:08:29,640 --> 00:08:35,530
million use for this is a huge problem
with one of our favorite examples is a

107
00:08:35,530 --> 00:08:42,559
popular antivirus app on Android updated
its signature database by HBS get and

108
00:08:42,559 --> 00:08:45,599
unfortunately didn't do the nomination
correctly so that meant that we could

109
00:08:45,600 --> 00:08:50,300
potentially go in there and change
something so we tried it out so we set

110
00:08:50,300 --> 00:08:56,729
up a rogue DNS server and created a
database and gave a database a signature

111
00:08:56,730 --> 00:09:04,950
on out choosing entered some checks I
gave the database name and put it into

112
00:09:04,950 --> 00:09:09,350
the network in a way that the app would
have to talk to it to get updates so

113
00:09:09,350 --> 00:09:14,900
when we then stop the app and would
trigger the update process manually in

114
00:09:14,900 --> 00:09:19,920
this case but this will happen
automatically as well so as you see the

115
00:09:19,920 --> 00:09:23,620
update process went through without any
error messages so now we are still

116
00:09:23,620 --> 00:09:28,350
modest program to scan is now an
abbreviated version of the scanning

117
00:09:28,350 --> 00:09:33,180
process and actually finds a threatening
found out thing and we gave the program

118
00:09:33,180 --> 00:09:39,370
its own signature so it's found itself
is now asking what we should do so we

119
00:09:39,370 --> 00:09:44,470
said well removed not quite believing
that would work but to a great surprised

120
00:09:44,470 --> 00:09:50,730
antivirus program did actually managed
to kill itself for us

121
00:09:50,730 --> 00:09:57,890
developers took this with a good sense
of humor and benefits out within 3 days

122
00:09:57,890 --> 00:10:01,370
so they did react very quickly better
than most of the companies we contacted

123
00:10:01,370 --> 00:10:07,480
with these problems but here we have
experts I mean these really are people

124
00:10:07,480 --> 00:10:12,480
who know their stuff and they still
managed to make a mistake and that is

125
00:10:12,480 --> 00:10:18,180
completely normal we are humans we all
make mistakes so now we have the problem

126
00:10:18,180 --> 00:10:22,979
down how do we get to the solution and
this is where I'd like to continue on

127
00:10:22,980 --> 00:10:26,430
from Adrian's thought the usual security
science and we

128
00:10:26,430 --> 00:10:31,469
have a lot of methods with which we can
look at these problems and in this case

129
00:10:31,470 --> 00:10:36,100
we can actually very simple we conducted
a fairly small number of interviews with

130
00:10:36,100 --> 00:10:40,570
the developers to figure out what was
going on and we contacted eighty

131
00:10:40,570 --> 00:10:46,430
developers roundabouts and fourteen of
those agreed to do some interviews with

132
00:10:46,430 --> 00:10:50,250
us and we got a whole range of
interesting comments back comment so we

133
00:10:50,250 --> 00:10:54,680
had enormous developers who said things
like this one of our first mobile apps

134
00:10:54,680 --> 00:10:57,550
and when we noticed that there were
problems with a cell to have a good we

135
00:10:57,550 --> 00:11:00,540
just implemented the first solution we
found on the internet but that's exactly

136
00:11:00,540 --> 00:11:05,430
what the process we just call it a good
tutorial and it turns off security we

137
00:11:05,430 --> 00:11:09,469
also had more intimate developers who
said we use cell types of cancer testing

138
00:11:09,470 --> 00:11:12,760
purposes and the easiest way to make
them working as her moves at a

139
00:11:12,760 --> 00:11:17,260
validation somebody must've forgotten to
move that code again when we released a

140
00:11:17,260 --> 00:11:20,950
lap and this again is a very
understandable mistake you're working

141
00:11:20,950 --> 00:11:25,250
under deadline you add some code months
ago for testing purposes forget to

142
00:11:25,250 --> 00:11:29,660
remove it and you've destroyed security
we also had this is my favorite example

143
00:11:29,660 --> 00:11:35,600
a really expert developer up to a point
that he actually didn't believe us he

144
00:11:35,600 --> 00:11:39,690
said when i use wifi to look at the
traffic while Fox said that is proper as

145
00:11:39,690 --> 00:11:43,190
well protected data stream I could not
see any context information when I

146
00:11:43,190 --> 00:11:46,920
manually inspected the packets so I
really cannot see what the problem here

147
00:11:46,920 --> 00:11:51,979
so we have a developer who is tech savvy
enough to open wire fraud to see that

148
00:11:51,980 --> 00:11:57,010
communication is as well protected but
who despite her two nations couldn't

149
00:11:57,010 --> 00:12:02,050
understand that it was encrypted using
our key instead of his and again this is

150
00:12:02,050 --> 00:12:06,449
a very complex scenarios and is not read
something when we say that's a bad

151
00:12:06,450 --> 00:12:10,140
developer is just he's having to deal
with stuff which is not his area of

152
00:12:10,140 --> 00:12:14,150
expertise and finally will have some
developers who actually knew that there

153
00:12:14,150 --> 00:12:18,750
was a problem and did it for other
reasons so we had a blog reader who said

154
00:12:18,750 --> 00:12:23,130
the app accept all applicants because
some users wanted to connect to their

155
00:12:23,130 --> 00:12:27,459
blogs were self-signed suits and because
I'm when does not provide easy to use

156
00:12:27,459 --> 00:12:31,969
the cells have been warning message was
a lot easier to accept all self-signed

157
00:12:31,970 --> 00:12:36,430
certificates so they knew they were
doing something insecure but they said

158
00:12:36,430 --> 00:12:39,089
it would cost effective way of going
forward

159
00:12:39,089 --> 00:12:44,149
old so outstanding talk to all the
developers we actually had a wishlist

160
00:12:44,149 --> 00:12:50,589
and it wasn't long until just a couple
of points to his was one of the foremost

161
00:12:50,589 --> 00:12:56,180
issues and he's had to all the wish they
had and then we looked at how the

162
00:12:56,180 --> 00:13:01,449
Android system actually implemented the
SL nowadays and found that if we replace

163
00:13:01,449 --> 00:13:07,180
the trust manager with a new
implementation with more features we can

164
00:13:07,180 --> 00:13:11,638
actually affect all the broken apps so
we created a system which allows

165
00:13:11,639 --> 00:13:16,779
developers to do all the things they
wanted my configurations of coding and

166
00:13:16,779 --> 00:13:20,779
this is actually is capable of
retroactive Lee fixing all the broken

167
00:13:20,779 --> 00:13:27,249
apps in the 13,500 looked at the only
thing nineteen out with initially had

168
00:13:27,249 --> 00:13:31,329
implemented pinning would lose that
future because we completely ignored the

169
00:13:31,329 --> 00:13:34,959
old implementation updating those to
configure pinning

170
00:13:34,959 --> 00:13:40,839
would be easy so this is an instance
we're just talking with 15 developers

171
00:13:40,839 --> 00:13:45,370
gave us a fourteen developers game is
enough information to fix all the

172
00:13:45,370 --> 00:13:52,279
vulnerabilities found in 13,500 that's a
really good payoff and we found

173
00:13:52,279 --> 00:13:56,620
solutions are is really worth looking at
it now has the full story

174
00:13:56,620 --> 00:14:01,300
second one is going into even more
high-skilled area not smell announces

175
00:14:01,300 --> 00:14:07,050
the other couple of students who are
working in this area a lot and as you

176
00:14:07,050 --> 00:14:10,899
can imagine this is an area where you
really a lot of technical skill to be

177
00:14:10,899 --> 00:14:16,110
working so if you have a piece of
malware you to get the binary codes now

178
00:14:16,110 --> 00:14:21,620
the author of the malware had source
code and compare that to buy marine now

179
00:14:21,620 --> 00:14:27,269
you have to use a Decompiler to get the
code back again so you analyze it and

180
00:14:27,269 --> 00:14:36,300
that is a very Lawson messy procedure so
you have control flow brass and

181
00:14:36,300 --> 00:14:42,309
unfortunately most normally compiles
will have a lot of goto statements to go

182
00:14:42,309 --> 00:14:44,649
from the binary code to the

183
00:14:44,649 --> 00:14:50,069
the assembly of the sea cold just as an
example the sample of the zues malware

184
00:14:50,069 --> 00:14:57,930
has 1571 go to use in roughly 50,000
lines of code that's roughly one go-to

185
00:14:57,930 --> 00:15:04,118
person 32 lines of code that's a lot to
get your head around when you trying to

186
00:15:04,119 --> 00:15:06,999
analyze something would potentially
actually written in a way to make it

187
00:15:06,999 --> 00:15:12,869
hard to understand but even without the
go-to problem the code produced by for

188
00:15:12,869 --> 00:15:14,720
instance X-rays

189
00:15:14,720 --> 00:15:19,679
approach is not nice to read so what you
see here is a small snippet of the

190
00:15:19,679 --> 00:15:25,379
similar malware anybody like to hazard a
guess as to what we're seeing you I know

191
00:15:25,379 --> 00:15:30,040
I wouldn't so when I saw this really was
completely insightful to me that is

192
00:15:30,040 --> 00:15:36,879
actually the demand generation algorithm
so often has command control servers and

193
00:15:36,879 --> 00:15:43,069
this code is there to tell them where we
actually to go and as you can see this

194
00:15:43,069 --> 00:15:47,910
is not something which is easy to read
so what my students were doing was

195
00:15:47,910 --> 00:15:52,120
creating can control flow optimization
album to get rid of all the go to tools

196
00:15:52,120 --> 00:15:56,860
and that we worked really well so we can
have finished that project but then we

197
00:15:56,860 --> 00:16:02,160
started talking to journalists analysts
will working with may actually similar

198
00:16:02,160 --> 00:16:06,040
to the Android developers had a wishlist
they said we have a lot of problems

199
00:16:06,040 --> 00:16:10,620
because it's very hard to to read the
co-produced by x-rays and we sat down

200
00:16:10,620 --> 00:16:14,019
and looked at him not you figured out
there is a lot of stuff we do

201
00:16:14,019 --> 00:16:19,639
automatically to make their lives easier
so the original Decompiler which we

202
00:16:19,639 --> 00:16:24,149
build was called Dream and we made an
extended version called Dream plus plus

203
00:16:24,149 --> 00:16:29,339
which implement all the ability
improvement we could think of and the

204
00:16:29,339 --> 00:16:33,629
automatic transformation between what we
see here and what our competitors is now

205
00:16:33,629 --> 00:16:40,139
and this is only a lot lot simpler and
you can see here you have kind of two

206
00:16:40,139 --> 00:16:43,889
arrays with characters and you have a
single for lube and it selects

207
00:16:43,889 --> 00:16:48,769
characters based on a seed and that is
something which most computer science

208
00:16:48,769 --> 00:16:53,240
students given a little time will be
able to see it as a Bruin said Newman

209
00:16:53,240 --> 00:16:56,850
securities are signs we want to quantify
how good things are we shouldn't

210
00:16:56,850 --> 00:17:01,680
trust our gut instinct so what we did
was again we went back to the signs and

211
00:17:01,680 --> 00:17:05,760
we conducted a user study and in this
case we actually conducted a qualitative

212
00:17:05,760 --> 00:17:11,390
control experiment so we took three
Decompiler X-rays as the industry

213
00:17:11,390 --> 00:17:15,860
standard we took our dream Decompiler
will be removed or go to his name atop

214
00:17:15,859 --> 00:17:20,809
the dream prosperous Decompiler will
allow usability extensions and we had

215
00:17:20,809 --> 00:17:27,349
our malware analysts 386 malware
analysis tasks included 21 students who

216
00:17:27,349 --> 00:17:33,049
had completed how malware boot camp and
we contacted 9 professional malware

217
00:17:33,049 --> 00:17:38,639
analysts and had them complete all six
tasks and ask questions about what the

218
00:17:38,640 --> 00:17:44,309
code did to ensure the results were on
buyers we had to do a lot of drug

219
00:17:44,309 --> 00:17:47,760
dealing with the task also we
counterbalanced all the different Deacon

220
00:17:47,760 --> 00:17:52,690
pilots to the each Decompiler be used in
the same frequency at all positions in

221
00:17:52,690 --> 00:17:53,990
the study

222
00:17:53,990 --> 00:17:58,520
counterbalance hardened easy tasks all
in the effort to try and get as

223
00:17:58,520 --> 00:18:03,030
scientific an unbiased result as
possible and the results are really good

224
00:18:03,030 --> 00:18:09,080
so he isn't comments so even without
improve green Decompiler people were

225
00:18:09,080 --> 00:18:13,389
still saying this code is not very nice
comment was the code most look like a

226
00:18:13,390 --> 00:18:18,159
straightforward see translation of
machine called a general sense about

227
00:18:18,159 --> 00:18:22,860
what is going on I think I'd rather just
see the assembly how the with a

228
00:18:22,860 --> 00:18:27,689
usability improvements with things like
this coat looks like it was written by

229
00:18:27,690 --> 00:18:33,299
human even if many of the names of quite
an Eric but just the name index mobile

230
00:18:33,299 --> 00:18:38,809
makes the code much easier to read and
the results are really clear so with the

231
00:18:38,809 --> 00:18:44,260
students we saw the base all three times
as many tasks with the dream D plus

232
00:18:44,260 --> 00:18:50,549
cream plus plus Decompiler with x-rays
and even the experts who use x-ray the

233
00:18:50,549 --> 00:18:52,830
experts who use x-rays on a regular
basis

234
00:18:52,830 --> 00:18:58,178
still sold one and a half times as many
tasks with our usability improve

235
00:18:58,179 --> 00:19:04,559
Decompiler than with industry standard
and even nicer when we asked them how

236
00:19:04,559 --> 00:19:08,139
they lacked the different compilers we
got a very very clear answer

237
00:19:08,140 --> 00:19:13,220
so with the students you see on on the
rights we have clearly they liked X-rays

238
00:19:13,220 --> 00:19:18,500
the least dream was better and they like
cream puffs plus the most now you can

239
00:19:18,500 --> 00:19:23,150
see that analysts are a little bit more
diverse where comes to x-rays Moses

240
00:19:23,150 --> 00:19:26,970
dream and this is actually quite
understandable since they are very

241
00:19:26,970 --> 00:19:32,750
experienced with x-rays and don't have a
problem with that but the way they liked

242
00:19:32,750 --> 00:19:36,870
the usability enhancements will even
more than the students we're guessing

243
00:19:36,870 --> 00:19:39,459
because they actually see how much it
would help them in their everyday work

244
00:19:39,460 --> 00:19:46,310
so even though these are probably the
highest skill security people I i can

245
00:19:46,310 --> 00:19:50,149
think of the simple usability
improvements we found for them were

246
00:19:50,150 --> 00:19:55,430
really effective and really appreciated
and that's why I want to say

247
00:19:55,430 --> 00:20:00,550
developers are not the enemy we should
be trying to make our lives easier

248
00:20:00,550 --> 00:20:06,620
because any benefit Rican awful people
in this room will have trickle-down

249
00:20:06,620 --> 00:20:11,340
effects for all the users and problems
we installed on the system later don't

250
00:20:11,340 --> 00:20:15,429
even have to get through to the end user
and that is something we can get a lot

251
00:20:15,430 --> 00:20:20,960
of benefit with very little effort so if
you're developing code security relat

252
00:20:20,960 --> 00:20:27,610
relevant code is you have products which
target at security professionals do get

253
00:20:27,610 --> 00:20:32,229
in touch with israeli researchers and
have a look at what we can do for you to

254
00:20:32,230 --> 00:20:36,580
make your world a little safer and with
that kind thank you for your attention

