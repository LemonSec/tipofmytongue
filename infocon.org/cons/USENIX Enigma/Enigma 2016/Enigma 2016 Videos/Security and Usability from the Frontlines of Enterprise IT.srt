1
00:00:00,198 --> 00:00:00,660


2
00:00:00,660 --> 00:00:04,693
♪♪

3
00:00:06,561 --> 00:00:08,891
OBERHEIDE: All right,
and I usually use that

4
00:00:08,891 --> 00:00:11,660
self-loathing academic line
in nonacademic conferences,

5
00:00:11,660 --> 00:00:13,198
so I forgot to change the bio,
[Laughter]

6
00:00:13,198 --> 00:00:15,561
recognizing that this is
a USENIX conference.

7
00:00:15,561 --> 00:00:17,825
But it's been a while
since I've been in academia,

8
00:00:17,825 --> 00:00:20,957
but I miss it greatly.

9
00:00:20,957 --> 00:00:24,363
So, what we're gonna
talk about today

10
00:00:24,363 --> 00:00:28,462
is usability and security
in a slightly different area.

11
00:00:28,462 --> 00:00:31,363
When you traditionally think
about usability and security,

12
00:00:31,363 --> 00:00:35,033
you might think
about browser SSL warnings,

13
00:00:35,033 --> 00:00:39,957
convoluted password schemes,
or encryption usability.

14
00:00:39,957 --> 00:00:42,561
Does anyone out there know
if Johnny can encrypt yet?

15
00:00:42,561 --> 00:00:44,462
ATTENDEE: No!
-OBERHEIDE: I heard a no?

16
00:00:44,462 --> 00:00:45,726
I heard a no?

17
00:00:45,726 --> 00:00:47,495
Yeah, he's been trying
to do it for 20 years.

18
00:00:47,495 --> 00:00:49,000
ATTENDEE: Ha.

19
00:00:49,000 --> 00:00:51,792
OBERHEIDE: Maybe he should try
a different profession.

20
00:00:51,792 --> 00:00:54,099
One of the things that's common
across these different areas

21
00:00:54,099 --> 00:00:59,726
is that they're hyperfocused
on the end user themselves

22
00:00:59,726 --> 00:01:01,263
and what we're gonna talk
about today is

23
00:01:01,264 --> 00:01:07,462
a slightly nontraditional area
of usability in IT security.

24
00:01:07,462 --> 00:01:09,297
Why is IT security important?

25
00:01:09,297 --> 00:01:11,462
Well, the IT
and security operations

26
00:01:11,462 --> 00:01:15,561
of your average organization
might not have a direct impact

27
00:01:15,561 --> 00:01:18,165
on the average
consumer end user,

28
00:01:18,165 --> 00:01:22,627
but the indirect impact
can be very significant.

29
00:01:22,627 --> 00:01:26,198
So, Target, Adobe, Juniper --
all the breaches

30
00:01:26,198 --> 00:01:29,890
that you see in the headlines --
these result from a compromise

31
00:01:29,891 --> 00:01:33,000
of the IT infrastructure
of these organizations

32
00:01:33,000 --> 00:01:36,594
and the impact
can be direct on consumers,

33
00:01:36,594 --> 00:01:37,923
it can be indirect,

34
00:01:37,924 --> 00:01:42,000
and it can even result
in a metalevel of compromise.

35
00:01:42,000 --> 00:01:45,363
So, Target, for example,
was a very direct impact:

36
00:01:45,363 --> 00:01:48,891
over 40 million credit cards
records of consumers

37
00:01:48,891 --> 00:01:50,792
were affected.

38
00:01:50,792 --> 00:01:52,099
The Adobe breach,

39
00:01:52,099 --> 00:01:54,363
as a different example,
resulted in the compromise

40
00:01:54,363 --> 00:01:57,792
of over 150 million
user credentials,

41
00:01:57,792 --> 00:02:00,264
which then resulted
in indirect compromise

42
00:02:00,264 --> 00:02:02,923
from attacking those users'
accounts on other services,

43
00:02:02,924 --> 00:02:04,495
where they might share
the same password

44
00:02:04,495 --> 00:02:07,924
as the Adobe login.

45
00:02:07,924 --> 00:02:10,231
And even the most
recent backdoor

46
00:02:10,231 --> 00:02:14,263
in Juniper's NetScreen products,
one could reasonably assume,

47
00:02:14,264 --> 00:02:17,627
was the result of a compromise
of Juniper's IT infrastructure,

48
00:02:17,627 --> 00:02:20,891
in order for the adversary
to implant that backdoor.

49
00:02:20,891 --> 00:02:24,297
And we might not ever know the
full extent of that compromise,

50
00:02:24,297 --> 00:02:26,692
but it certainly had
a big impact on thousands

51
00:02:26,693 --> 00:02:31,264
of organizations that had
deployed NetScreen equipment.

52
00:02:31,264 --> 00:02:36,066
So, I would claim, on one hand,

53
00:02:36,066 --> 00:02:38,528
we're doing
a lot better in security,

54
00:02:38,528 --> 00:02:40,891
at least from
a technological perspective.

55
00:02:40,891 --> 00:02:44,033
We have hardened browsers
with exploit mitigations,

56
00:02:44,033 --> 00:02:48,329
we have autoupdating, we're
investing a lot in security,

57
00:02:48,330 --> 00:02:51,132
and we have relatively
safe languages and frameworks,

58
00:02:51,132 --> 00:02:53,726
as Matthew will tell us
about next.

59
00:02:53,726 --> 00:02:56,132
So we must be doing
some things right,

60
00:02:56,132 --> 00:02:57,561
in a world
where we have, literally,

61
00:02:57,561 --> 00:03:03,759
a $1 million bug bounty
for iOS 9 vulnerabilities.

62
00:03:03,759 --> 00:03:06,494
But if you asked your average
security practitioner,

63
00:03:06,495 --> 00:03:08,693
they'd probably paint
a very different picture

64
00:03:08,693 --> 00:03:10,594
in the face
of these daily breaches.

65
00:03:10,594 --> 00:03:13,594
So, security
technology's getting better,

66
00:03:13,594 --> 00:03:16,329
but the breaches are increasing
at an alarming rate.

67
00:03:16,330 --> 00:03:19,660
So there must be something wrong
here and I would claim

68
00:03:19,660 --> 00:03:23,660
that it's actually the IT
security industry that's failing

69
00:03:23,660 --> 00:03:29,329
and resulting in organizations
that can't protect themselves.

70
00:03:29,330 --> 00:03:31,165
So, there's no clear answer

71
00:03:31,165 --> 00:03:33,792
about where we're going wrong
in IT security.

72
00:03:33,792 --> 00:03:36,231
There's no single,
comprehensive answer.

73
00:03:36,231 --> 00:03:38,033
But what I want
to focus on today

74
00:03:38,033 --> 00:03:43,197
is the intersection
of security and usability

75
00:03:43,198 --> 00:03:45,066
on a few different principles

76
00:03:45,066 --> 00:03:47,495
that we might not
otherwise consider.

77
00:03:47,495 --> 00:03:49,924
Again, oftentimes,
security and usability research

78
00:03:49,924 --> 00:03:52,660
focuses squarely on the end user
and doesn't consider

79
00:03:52,660 --> 00:03:55,462
the full environment
in which they operate in,

80
00:03:55,462 --> 00:03:57,528
which includes the organizations

81
00:03:57,528 --> 00:04:00,759
that employ these corporate
end users and the industry

82
00:04:00,759 --> 00:04:04,726
in which these organizations
are involved in.

83
00:04:04,726 --> 00:04:07,891
And, in some ways,
the crap rolls downhill.

84
00:04:07,891 --> 00:04:10,759
You have a very complicated,
convoluted industry,

85
00:04:10,759 --> 00:04:13,231
which results in organizations
building unscalable

86
00:04:13,231 --> 00:04:15,660
and ineffective security
programs, which results

87
00:04:15,660 --> 00:04:18,891
in a lack of security
and usability and the controls

88
00:04:18,891 --> 00:04:21,792
that eventually hit
the end users.

89
00:04:21,791 --> 00:04:24,527
I wanted to share some of
these philosophies and stories

90
00:04:24,528 --> 00:04:27,363
based on my experience
building a security company,

91
00:04:27,363 --> 00:04:32,066
namely Duo Security, that
services a fairly diverse set

92
00:04:32,066 --> 00:04:35,758
of customers across, you know,
all segments of the market,

93
00:04:35,759 --> 00:04:37,099
all shapes and sizes,

94
00:04:37,099 --> 00:04:42,296
all types of security cultures
and user populations.

95
00:04:42,297 --> 00:04:45,297
So, I ask,
to you, the audience --

96
00:04:45,297 --> 00:04:47,627
I believe that these are
understudied areas

97
00:04:47,627 --> 00:04:49,396
of usability and security
and I hope,

98
00:04:49,396 --> 00:04:54,231
through this exploration, I will
create a spark for you guys.

99
00:04:54,231 --> 00:04:55,659
So, first,
the security industry,

100
00:04:55,660 --> 00:05:01,330
the $88 billion big kahuna
to tackle.

101
00:05:01,330 --> 00:05:03,462
The security industry,
one major problem

102
00:05:03,462 --> 00:05:05,890
with the industry
is it promotes,

103
00:05:05,891 --> 00:05:07,528
inadvertently at best,

104
00:05:07,528 --> 00:05:13,627
complexity and sophistication
over simplicity and usability.

105
00:05:13,627 --> 00:05:16,594
And, even anecdotally,
I can tell you that the words

106
00:05:16,594 --> 00:05:18,264
"simple" and "easy,"

107
00:05:18,264 --> 00:05:20,891
in the security industry,
when talking to customers,

108
00:05:20,891 --> 00:05:24,099
is looked at
in a negative light,

109
00:05:24,099 --> 00:05:28,296
that "simple" must mean
ineffective, less sophisticated,

110
00:05:28,297 --> 00:05:33,033
less secure, when, in reality,
that's not the case.

111
00:05:33,033 --> 00:05:36,858
And this is very, very Bad,
with a capital B.

112
00:05:36,858 --> 00:05:39,264
But if you look at how
the industry messages itself,

113
00:05:39,264 --> 00:05:41,528
it's not necessarily a surprise.

114
00:05:41,528 --> 00:05:46,363
We have aggressive visuals
and aggressive messaging.

115
00:05:46,363 --> 00:05:50,396
We position security as a battle
of good versus evil.

116
00:05:50,396 --> 00:05:53,429
We use terminology like
"kill chains,"

117
00:05:53,429 --> 00:05:57,363
"cyberweapons,"
and "nation-state actors."

118
00:05:57,363 --> 00:05:59,495
We quote Sun Tzu's
"The Art of War"

119
00:05:59,495 --> 00:06:03,594
as if we're riding into battle
as the keyboard cavalry

120
00:06:03,594 --> 00:06:05,561
and this militarization
of security

121
00:06:05,561 --> 00:06:09,032
is the antithesis of simplicity.

122
00:06:09,033 --> 00:06:11,132
It creates an us-versus-them
environment,

123
00:06:11,132 --> 00:06:15,660
where the real collateral damage
is the end users.

124
00:06:15,660 --> 00:06:19,330
We also have an obsession
with attribution,

125
00:06:19,330 --> 00:06:23,561
admiring attacks as opposed
to trying to stop them.

126
00:06:23,561 --> 00:06:25,231
And we absolve
ourselves of responsibility

127
00:06:25,231 --> 00:06:28,165
by pointing blame
at nation-states,

128
00:06:28,165 --> 00:06:30,627
when their attacks
are literally indistinguishable

129
00:06:30,627 --> 00:06:34,759
as the ones
perpetrated by teenagers.

130
00:06:34,759 --> 00:06:38,198
So, I hope you appreciate
the tongue-in-cheek hypocrisy

131
00:06:38,198 --> 00:06:39,890
of the title of my talk.

132
00:06:39,891 --> 00:06:43,066
There are no front lines
of security.

133
00:06:43,066 --> 00:06:44,659
This isn't a battle.

134
00:06:44,660 --> 00:06:46,660
We're not warriors;
we're guardians.

135
00:06:46,660 --> 00:06:49,198
We only exist to make
enabling technologies

136
00:06:49,198 --> 00:06:52,758
easy and safe for our end users.

137
00:06:52,759 --> 00:06:57,099
So, if you're a new IT admin
who's approaching this madness,

138
00:06:57,099 --> 00:07:00,957
if you will,
it's a little overwhelming.

139
00:07:00,957 --> 00:07:03,759
For every threat out there,
there's an antithreat,

140
00:07:03,759 --> 00:07:07,462
and that creates hundreds
of product categories

141
00:07:07,462 --> 00:07:10,462
in which you must purchase,
operationalize, and deploy

142
00:07:10,462 --> 00:07:13,495
to your end users
to protect them.

143
00:07:13,495 --> 00:07:15,891
Now, of course, individually,

144
00:07:15,891 --> 00:07:17,693
each of these solutions
is not foolproof.

145
00:07:17,693 --> 00:07:19,495
Attackers will always find
a way to bypass

146
00:07:19,495 --> 00:07:24,528
one mechanism or another,
so we preach defense in depth.

147
00:07:24,528 --> 00:07:27,396
That is, line up 30
of these things serially

148
00:07:27,396 --> 00:07:31,495
and hope that attackers not get
by every single one of them.

149
00:07:31,495 --> 00:07:35,099
So, we preach defense
in depth,

150
00:07:35,099 --> 00:07:38,231
but what that results
in is expense in depth.

151
00:07:38,231 --> 00:07:41,792
That is, organizations end up
purchasing security solutions

152
00:07:41,792 --> 00:07:45,131
that might be ineffective
or inappropriate

153
00:07:45,132 --> 00:07:46,792
for their deployment,

154
00:07:46,792 --> 00:07:49,429
with security budgets
that they don't have,

155
00:07:49,429 --> 00:07:51,890
with operational requirements
they can't meet,

156
00:07:51,891 --> 00:07:55,429
with a security staff
they can't recruit or retain.

157
00:07:55,429 --> 00:07:56,857
And the end result
is that we end up

158
00:07:56,858 --> 00:07:59,792
building unscalable security
programs in our organizations

159
00:07:59,792 --> 00:08:03,693
and end up focusing
on the wrong areas.

160
00:08:03,693 --> 00:08:05,957
So, if you're an organization,

161
00:08:05,957 --> 00:08:09,296
I would hope that you're
focusing on the bottom portion

162
00:08:09,297 --> 00:08:11,297
of this hierarchy
of needs here:

163
00:08:11,297 --> 00:08:14,099
the fact that you have
an actual security strategy,

164
00:08:14,099 --> 00:08:17,066
that you're able to recruit
and retain staff,

165
00:08:17,066 --> 00:08:19,527
and that you're focusing
on the fundamentals

166
00:08:19,528 --> 00:08:21,693
before you jump to the top
of the pyramid

167
00:08:21,693 --> 00:08:23,758
to focus on preventing
and detecting

168
00:08:23,759 --> 00:08:27,264
nation-state-sponsored
APT attacks.

169
00:08:27,264 --> 00:08:30,000
So what are the fundamentals?

170
00:08:30,000 --> 00:08:32,495
IF you listen to Eric Schmidt,
Obama asked him

171
00:08:32,495 --> 00:08:35,957
what the U.S. can be doing
better in cybersecurity,

172
00:08:35,957 --> 00:08:39,066
and Eric boiled it down
to three simple things --

173
00:08:39,066 --> 00:08:43,231
(1) strong authentication,
(2) up-to-date devices,

174
00:08:43,231 --> 00:08:45,693
and (3) using encryption.

175
00:08:45,693 --> 00:08:47,132
And I agree with this.

176
00:08:47,132 --> 00:08:50,296
And I actually think that this
is the new CIA of security;

177
00:08:50,297 --> 00:08:54,165
it's confidentiality of data,
it's integrity of devices,

178
00:08:54,165 --> 00:08:56,264
and it's authentication
of users.

179
00:08:56,264 --> 00:08:58,198
Availability?
Not very exciting.

180
00:08:58,198 --> 00:09:01,561
It's been voted off the acronym.
[Laughter]

181
00:09:01,561 --> 00:09:03,957
To use
a disease-control analogy,

182
00:09:03,957 --> 00:09:07,165
what we should be doing
is washing our hands.

183
00:09:07,165 --> 00:09:09,231
It's incredibly effective
at preventing the spread

184
00:09:09,231 --> 00:09:13,858
of disease and it's pretty easy
to do on a regular basis.

185
00:09:13,858 --> 00:09:16,462
But what we end up doing
is approaching

186
00:09:16,462 --> 00:09:20,330
homeopathic remedies
that are unproven.

187
00:09:20,330 --> 00:09:23,957
We approach problems
of disease control with overkill

188
00:09:23,957 --> 00:09:25,363
or with unusable solutions

189
00:09:25,363 --> 00:09:29,429
or outright
ridiculous approaches.

190
00:09:29,429 --> 00:09:32,033
Now, I would attest
that we're not actually

191
00:09:32,033 --> 00:09:35,066
practicing the basics
of security.

192
00:09:35,066 --> 00:09:37,957
At Duo, we see millions
of enterprise endpoints

193
00:09:37,957 --> 00:09:40,066
in mobile devices
on a daily basis,

194
00:09:40,066 --> 00:09:42,495
and we have some visibility
into whether these devices

195
00:09:42,495 --> 00:09:44,363
are up-to-date or not.

196
00:09:44,363 --> 00:09:45,957
Now, we're gonna start off
with Android here

197
00:09:45,957 --> 00:09:50,561
and, you know, full disclaimer,
Android is complicated,

198
00:09:50,561 --> 00:09:52,198
a very complicated ecosystem.

199
00:09:52,198 --> 00:09:53,627
I'll leave it at that.

200
00:09:53,627 --> 00:09:55,098
Users and organizations,

201
00:09:55,099 --> 00:09:56,957
even if they want
to update these devices,

202
00:09:56,957 --> 00:09:59,792
oftentimes can't, due
to this complicated ecosystem

203
00:09:59,792 --> 00:10:01,792
with a number of players.

204
00:10:01,792 --> 00:10:05,363
But we look across
our customer base,

205
00:10:05,363 --> 00:10:10,198
we see that 71% of Android
devices are out-of-date.

206
00:10:10,198 --> 00:10:11,924
That's not good.
It's complicated,

207
00:10:11,924 --> 00:10:14,000
but there's still certainly
a large risk there.

208
00:10:14,000 --> 00:10:17,495
But we'll give Android a pass.

209
00:10:17,495 --> 00:10:19,132
How about these OS X devices?

210
00:10:19,132 --> 00:10:21,329
I see a whole lot
of them in the audience,

211
00:10:21,330 --> 00:10:22,792
and it's a different ecosystem.

212
00:10:22,792 --> 00:10:26,462
Both users and organizations
have full control

213
00:10:26,462 --> 00:10:29,066
over whether these devices
are up-to-date or not,

214
00:10:29,066 --> 00:10:31,396
and yet, when we look
across our customer base,

215
00:10:31,396 --> 00:10:34,759
we see that, actually,
75% of OS X devices

216
00:10:34,759 --> 00:10:39,495
are out-of-date,
even more than Android devices.

217
00:10:39,495 --> 00:10:45,594
Now, what if we hold up
our poster child, iOS?

218
00:10:45,594 --> 00:10:47,594
It's hardened.

219
00:10:47,594 --> 00:10:50,000
All the updates are controlled
through a central party.

220
00:10:50,000 --> 00:10:53,495
There's this million-dollar
bounty to attack this device.

221
00:10:53,495 --> 00:10:56,099
It must be pretty good, right?

222
00:10:56,099 --> 00:10:59,330
In reality, we see that 50%
of iOS devices used

223
00:10:59,330 --> 00:11:02,495
by our customers
are actually out-of-date.

224
00:11:02,495 --> 00:11:04,594
So it's clear
we're failing to solve some

225
00:11:04,594 --> 00:11:08,000
of these fundamental
problems in security.

226
00:11:08,000 --> 00:11:09,594
Now, I would point out, too,

227
00:11:09,594 --> 00:11:11,858
that I think there's
some selection bias in this.

228
00:11:11,858 --> 00:11:13,231
These might be
optimistic numbers.

229
00:11:13,231 --> 00:11:15,396
This is from our customer base,
so, inherently,

230
00:11:15,396 --> 00:11:17,329
these organizations,
I would say,

231
00:11:17,330 --> 00:11:19,462
are probably more savvy
than average, given the fact

232
00:11:19,462 --> 00:11:21,561
that they're deploying
two-factor to their users.

233
00:11:21,561 --> 00:11:23,594
So the broader population
of organizations

234
00:11:23,594 --> 00:11:26,462
might be even worse.

235
00:11:26,462 --> 00:11:30,000
So, one thing we can do is
to start advocating

236
00:11:30,000 --> 00:11:33,462
and educating to focus
on the fundamentals of security.

237
00:11:33,462 --> 00:11:36,924
Of all of the compliance
frameworks, recommendations,

238
00:11:36,924 --> 00:11:40,231
and best practices I've seen,
I think, of all people,

239
00:11:40,231 --> 00:11:43,264
the FTC's Start
with Security program actually

240
00:11:43,264 --> 00:11:46,429
has some of the most sane
guidelines for organizations

241
00:11:46,429 --> 00:11:49,098
to focus on security
fundamentals.

242
00:11:49,099 --> 00:11:50,792
We also need positive models

243
00:11:50,792 --> 00:11:54,858
of security and positive
security architectures.

244
00:11:54,858 --> 00:11:58,098
For every threat, coming up
with an antithreat solution --

245
00:11:58,099 --> 00:12:00,165
or playing Whac-A-Mole
with every new threat

246
00:12:00,165 --> 00:12:03,098
that comes up
is not scalable, long-term,

247
00:12:03,099 --> 00:12:05,726
so why don't we invert our model
of security and focus

248
00:12:05,726 --> 00:12:07,957
on what kind of positive
security properties

249
00:12:07,957 --> 00:12:09,561
we want to enforce and maintain?

250
00:12:09,561 --> 00:12:13,066
And I think Google's Beyond Corp
is a good example of this.

251
00:12:13,066 --> 00:12:15,066
And if you ask me what kind of
security properties

252
00:12:15,066 --> 00:12:16,660
are important
for an organization

253
00:12:16,660 --> 00:12:20,462
that might be positive,
as opposed to negative,

254
00:12:20,462 --> 00:12:22,330
they're things like
strong user authentication

255
00:12:22,330 --> 00:12:23,726
and authorization,

256
00:12:23,726 --> 00:12:25,825
strong device authentication
and authorization,

257
00:12:25,825 --> 00:12:29,099
and a strong transport security.

258
00:12:29,099 --> 00:12:31,957
And, if you can do those things,
you probably solve 90%

259
00:12:31,957 --> 00:12:35,957
of the security problems for 90%
of the organizations out there.

260
00:12:35,957 --> 00:12:39,363
And that's the philosophy that
our customers are following.

261
00:12:39,363 --> 00:12:42,231
So, the industry
definitely sets up

262
00:12:42,231 --> 00:12:45,396
a challenging environment
for organizations to operate in,

263
00:12:45,396 --> 00:12:48,627
but it's not the only challenge
that organizations face.

264
00:12:48,627 --> 00:12:51,660
In the modern day, all companies
are technology companies

265
00:12:51,660 --> 00:12:54,000
in order to compete
in the market,

266
00:12:54,000 --> 00:12:55,825
so all companies need
an effective

267
00:12:55,825 --> 00:12:59,396
and user-friendly
IT security program.

268
00:12:59,396 --> 00:13:01,264
We've seen a lot of change

269
00:13:01,264 --> 00:13:04,099
over the past few decades,
both from a technological,

270
00:13:04,099 --> 00:13:06,561
as well as cultural perspective
in IT security.

271
00:13:06,561 --> 00:13:09,528
Certainly, we've come a long way
since the days of the mainframe,

272
00:13:09,528 --> 00:13:11,561
when all of your users
and devices and services

273
00:13:11,561 --> 00:13:13,693
were within your four walls.

274
00:13:13,693 --> 00:13:16,165
In IT 2.0,
we opened up our perimeter

275
00:13:16,165 --> 00:13:19,198
to allow for remote access
for remote workers

276
00:13:19,198 --> 00:13:21,000
and, in the modern day,
with cloud and mobile,

277
00:13:21,000 --> 00:13:23,165
with your users going mobile
and your services going

278
00:13:23,165 --> 00:13:25,759
to the cloud, really,

279
00:13:25,759 --> 00:13:28,297
the idea of a corporate network
is really just that:

280
00:13:28,297 --> 00:13:31,594
it's an idea,
versus a concrete realization.

281
00:13:31,594 --> 00:13:33,198
So, a lot of the legacy
security controls

282
00:13:33,198 --> 00:13:35,660
that we used to deploy
might not be relevant,

283
00:13:35,660 --> 00:13:37,693
when your network
is really independent

284
00:13:37,693 --> 00:13:40,198
of its network topology.

285
00:13:40,198 --> 00:13:42,858
Now, the old Jericho forum would
call this deperimeterization,

286
00:13:42,858 --> 00:13:45,165
but in reality, it's
a new virtual perimeter

287
00:13:45,165 --> 00:13:47,660
that is independent
of the network topology

288
00:13:47,660 --> 00:13:49,528
and it follows the same
end-to-end principle

289
00:13:49,528 --> 00:13:50,726
as the Internet.

290
00:13:50,726 --> 00:13:53,132
We've taken security technology
and controls

291
00:13:53,132 --> 00:13:57,165
and moved them from the core
of the network to the edges.

292
00:13:57,165 --> 00:13:58,693
At the same time,
organizations

293
00:13:58,693 --> 00:14:03,198
have struggled to change
along with the security culture.

294
00:14:03,198 --> 00:14:07,264
A lot of organizations are still
stuck in the mindset of control.

295
00:14:07,264 --> 00:14:09,363
Again, it's
an us-versus-them mentality,

296
00:14:09,363 --> 00:14:11,957
where the IT admins
are the good guys

297
00:14:11,957 --> 00:14:15,891
and the users are the bad guys,
trying to subvert their security

298
00:14:15,891 --> 00:14:18,593
and always causing problems
and doing stupid things.

299
00:14:18,594 --> 00:14:21,198
But if you think about
the end-user interactions

300
00:14:21,198 --> 00:14:23,098
with IT security,
it's always negative,

301
00:14:23,099 --> 00:14:26,792
whether it's the AV on your
laptop or the web filter,

302
00:14:26,792 --> 00:14:28,858
you know, blocking
your web access

303
00:14:28,858 --> 00:14:32,263
or the email filter marking
your messages as spam,

304
00:14:32,264 --> 00:14:34,330
that interaction
is always negative,

305
00:14:34,330 --> 00:14:36,693
and it crates a negative mindset
with the end user,

306
00:14:36,693 --> 00:14:39,824
regardless of whether it's right
from a security perspective,

307
00:14:39,825 --> 00:14:42,825
because users don't
understand what right is.

308
00:14:42,825 --> 00:14:49,858
So we have to change
this previously sort of named

309
00:14:49,858 --> 00:14:52,527
Department of No for IT, where
it's "No, you can't do that.

310
00:14:52,528 --> 00:14:53,957
No, you can't use this device.

311
00:14:53,957 --> 00:14:55,528
No, you can't access
that service."

312
00:14:55,528 --> 00:14:58,099
And, as Mike Hale
smartly pointed out,

313
00:14:58,099 --> 00:14:59,792
change to a Department
of Secure Enablement,

314
00:14:59,792 --> 00:15:01,264
where users are actually
partnering with users

315
00:15:01,264 --> 00:15:03,198
are actually partnering
with their end users

316
00:15:03,198 --> 00:15:06,792
in order to secure
the organization.

317
00:15:06,792 --> 00:15:09,759
And this is important,
because if you fail to do this,

318
00:15:09,759 --> 00:15:12,726
what results is what's known
as normalization of deviance

319
00:15:12,726 --> 00:15:15,000
and this is a topic
that Bruce Schneier

320
00:15:15,000 --> 00:15:17,660
actually talked about
in his last Crypto-Gram.

321
00:15:17,660 --> 00:15:21,065
And, originally, a sociologist
who investigated

322
00:15:21,066 --> 00:15:25,297
the Challenger o-ring debacle
noticed, in their research,

323
00:15:25,297 --> 00:15:27,660
that there were
certain behaviors and actions

324
00:15:27,660 --> 00:15:28,957
within an organization

325
00:15:28,957 --> 00:15:31,363
that, in a vacuum,
were considered deviant.

326
00:15:31,363 --> 00:15:33,396
They were considered so wrong
that you would never

327
00:15:33,396 --> 00:15:36,924
expect them to be acceptable,
and, yet, in an organization

328
00:15:36,924 --> 00:15:41,033
and cultural perspective,
they became socially acceptable;

329
00:15:41,033 --> 00:15:45,198
they became normalized and they
weren't looked at as negative.

330
00:15:45,198 --> 00:15:47,858
And this happens
in IT security all the time,

331
00:15:47,858 --> 00:15:53,726
when users are circumventing and
undermining security controls

332
00:15:53,726 --> 00:15:56,528
that don't mesh with how they
think about an organization

333
00:15:56,528 --> 00:15:58,363
or how they think
about their job.

334
00:15:58,363 --> 00:16:01,198
So, it's incredibly important
that IT organizations

335
00:16:01,198 --> 00:16:05,066
combat this normalization
of deviance,

336
00:16:05,066 --> 00:16:07,330
and one way to do that is
by making users part

337
00:16:07,330 --> 00:16:11,198
of the solution, rather
than part of the problem.

338
00:16:11,198 --> 00:16:12,824
One way that we've seen
organizations do this is

339
00:16:12,825 --> 00:16:15,264
by pushing security authority
and responsibility

340
00:16:15,264 --> 00:16:17,561
down to the leaves
of the organizations.

341
00:16:17,561 --> 00:16:19,627
And that might seem like
a radical idea,

342
00:16:19,627 --> 00:16:21,065
"That sounds really scary.

343
00:16:21,066 --> 00:16:23,693
I'm supposed to trust my users
to make security decisions?

344
00:16:23,693 --> 00:16:25,824
You know, they're stupid
and they always screw up.

345
00:16:25,825 --> 00:16:27,297
I don't think that'll work."

346
00:16:27,297 --> 00:16:29,429
But you have to give them
usable tools,

347
00:16:29,429 --> 00:16:31,858
not a few feet of rope.

348
00:16:31,858 --> 00:16:33,957
And this is a model
of shared responsibility,

349
00:16:33,957 --> 00:16:36,066
where it is IT
directly partnering

350
00:16:36,066 --> 00:16:39,264
and enlisting the end users
in their security program.

351
00:16:39,264 --> 00:16:41,462
And this can create
a positive security culture,

352
00:16:41,462 --> 00:16:43,198
where users aren't
subverting your controls;

353
00:16:43,198 --> 00:16:45,033
you're turning each user
into a trip wire

354
00:16:45,033 --> 00:16:47,825
for your organization.

355
00:16:47,825 --> 00:16:50,792
One example of this
that I really like, from Slack,

356
00:16:50,792 --> 00:16:53,396
who's one of our customers;
they created

357
00:16:53,396 --> 00:16:55,560
an anomaly detection system for
their production environment

358
00:16:55,561 --> 00:16:56,891
and this is something
that's common

359
00:16:56,891 --> 00:16:58,660
across a lot of organizations.

360
00:16:58,660 --> 00:17:00,231
You oftentimes
will raise alerts;

361
00:17:00,231 --> 00:17:02,891
they'll go over to a console
that your SOC

362
00:17:02,891 --> 00:17:04,263
or your security analyst
monitor

363
00:17:04,263 --> 00:17:06,791
and they spend all day
burning down these alerts,

364
00:17:06,791 --> 00:17:08,329
trying to figure out
what ground truth is

365
00:17:08,329 --> 00:17:10,098
for these anomalous conditions.

366
00:17:10,098 --> 00:17:11,462
And it's very difficult.

367
00:17:11,462 --> 00:17:13,891
You're essentially creating
work for yourself,

368
00:17:13,891 --> 00:17:16,264
trying to figure out
what's going on.

369
00:17:16,263 --> 00:17:18,362
Slack took a very
different approach,

370
00:17:18,363 --> 00:17:20,759
in that, when an anomaly
is detected,

371
00:17:20,759 --> 00:17:24,560
they directly contact the end
user who initiated that action

372
00:17:24,560 --> 00:17:27,329
and use our technology to ensure

373
00:17:27,329 --> 00:17:31,362
that this is an expected
outcome, an expected alert;

374
00:17:31,363 --> 00:17:33,396
or it's something
that the user's not expecting

375
00:17:33,396 --> 00:17:36,561
and maybe it's an actual
indicator of compromise.

376
00:17:36,561 --> 00:17:39,428
So, there are certainly
some pros to this approach,

377
00:17:39,429 --> 00:17:40,660
in terms of efficiency.

378
00:17:40,660 --> 00:17:43,066
Now, their security
analyst can work on things

379
00:17:43,066 --> 00:17:44,891
that actually move
the organization forward,

380
00:17:44,891 --> 00:17:47,561
as opposed to, you know,
burning down a list of alerts.

381
00:17:47,561 --> 00:17:49,165
They also have increased signal

382
00:17:49,165 --> 00:17:50,825
and they've shortened
their feedback loop,

383
00:17:50,825 --> 00:17:53,429
if there's a real
compromise going on.

384
00:17:53,429 --> 00:17:54,891
But, in reality,
what they've done

385
00:17:54,891 --> 00:17:58,033
is they've enlisted their end
users by pushing these alerts

386
00:17:58,033 --> 00:18:00,726
to the closest ground truth
they can find,

387
00:18:00,726 --> 00:18:02,693
the person who actually
performed the action,

388
00:18:02,693 --> 00:18:07,495
and create a more scalable
and automated security program.

389
00:18:07,495 --> 00:18:11,824
Another positive example
I've seen is that customers

390
00:18:11,825 --> 00:18:15,693
are starting to include
usability and user feedback

391
00:18:15,693 --> 00:18:18,792
more in their
IT purchasing process.

392
00:18:18,792 --> 00:18:22,165
So we actually see RFPs and POCs

393
00:18:22,165 --> 00:18:23,891
where getting feedback
from the users

394
00:18:23,891 --> 00:18:26,825
about how much
they like a solution

395
00:18:26,825 --> 00:18:29,231
is a critical part
of their buying decision

396
00:18:29,231 --> 00:18:31,132
and that's a trend
I'd like to see more of.

397
00:18:31,132 --> 00:18:34,033
We've actually won deals based
on the fact that

398
00:18:34,033 --> 00:18:37,593
a user population says,
"We like that one better"

399
00:18:37,594 --> 00:18:43,396
and that's a powerful statement,
when it comes to IT security.

400
00:18:43,396 --> 00:18:48,099
So, this raises a couple
questions in my mind.

401
00:18:48,099 --> 00:18:52,297
Does usable IT security
have an indirect positive impact

402
00:18:52,297 --> 00:18:54,231
on an organization's
security posture?

403
00:18:54,231 --> 00:18:57,165
I would say,
at least anecdotally, yes.

404
00:18:57,165 --> 00:19:00,132
One CISO that comes to mind:

405
00:19:00,132 --> 00:19:04,330
a CISO of a large healthcare
organization.

406
00:19:04,330 --> 00:19:05,824
While our technology solved

407
00:19:05,825 --> 00:19:09,099
a clear and present problem
for them, it was more of

408
00:19:09,099 --> 00:19:12,890
a spoonful of sugar that helped
the medicine go down.

409
00:19:12,891 --> 00:19:14,297
It was something that the users

410
00:19:14,297 --> 00:19:16,297
would actually like,
as opposed to revolt,

411
00:19:16,297 --> 00:19:17,660
and it kind of
greased the wheels

412
00:19:17,660 --> 00:19:20,231
for all rest
of the crappy security controls

413
00:19:20,231 --> 00:19:23,066
they had to deploy due
to their HIPAA environment.

414
00:19:23,066 --> 00:19:25,528
So, I would say

415
00:19:25,528 --> 00:19:29,726
that there is some potentially
measurable indirect impact,

416
00:19:29,726 --> 00:19:32,066
at least in terms
of the organizational capital

417
00:19:32,066 --> 00:19:34,957
and the trust that a CISO
or a security team's

418
00:19:34,957 --> 00:19:37,000
able to build
with their user population

419
00:19:37,000 --> 00:19:38,495
by deploying security controls

420
00:19:38,495 --> 00:19:42,000
that mesh with users'
modern expectations.

421
00:19:42,000 --> 00:19:44,759
On the other hand,
maybe there's a direct

422
00:19:44,759 --> 00:19:47,462
positive impact, too,
taking it a little further,

423
00:19:47,462 --> 00:19:50,924
that happy users can have
on an organization's security,

424
00:19:50,924 --> 00:19:52,825
and this might be
at a micro level.

425
00:19:52,825 --> 00:19:55,858
Maybe a happy user
is less likely to subvert

426
00:19:55,858 --> 00:19:58,066
their organization's
security controls.

427
00:19:58,066 --> 00:20:00,759
Maybe a happy user
is less susceptible

428
00:20:00,759 --> 00:20:03,594
to social engineering
or phishing attacks.

429
00:20:03,594 --> 00:20:04,957
And maybe, at a macro level,

430
00:20:04,957 --> 00:20:08,033
if you have a whole organization
of users who, you know,

431
00:20:08,033 --> 00:20:10,924
look positively
at their IT organization,

432
00:20:10,924 --> 00:20:15,033
maybe they're more resistant
to normalization of deviance.

433
00:20:15,033 --> 00:20:16,726
I think this is an area
where there's a lot

434
00:20:16,726 --> 00:20:20,429
of area for improvement
and research.

435
00:20:20,429 --> 00:20:23,396
So, while we undervalue,
in my opinion,

436
00:20:23,396 --> 00:20:26,759
the impact that organizations
and the industry has

437
00:20:26,759 --> 00:20:28,528
on the end-user experience,

438
00:20:28,528 --> 00:20:31,693
I think that we simply can't
ignore the end users themselves

439
00:20:31,693 --> 00:20:34,429
and I really enjoy this quote
from Chris Palmer, that

440
00:20:34,429 --> 00:20:36,000
"We should prefer
security systems

441
00:20:36,000 --> 00:20:40,000
that people can readily create
accurate mental models for,

442
00:20:40,000 --> 00:20:41,759
even if they are
strictly less powerful

443
00:20:41,759 --> 00:20:44,231
than what the state
of the art allows."

444
00:20:44,231 --> 00:20:47,858
In other words,
we can favor safer approaches

445
00:20:47,858 --> 00:20:49,330
over more sophisticated
approaches

446
00:20:49,330 --> 00:20:53,561
to result in greater security,
and we can do so by creating

447
00:20:53,561 --> 00:20:58,000
a more favorable environment
for users to operate in.

448
00:20:58,000 --> 00:21:01,891
One particularly morbid example
from the 1970s:

449
00:21:01,891 --> 00:21:03,924
a number of researchers
in the United Kingdom

450
00:21:03,924 --> 00:21:08,197
looked at an incredibly steep
decline in suicide rates

451
00:21:08,198 --> 00:21:12,033
and they noticed
that the suicide method

452
00:21:12,033 --> 00:21:15,396
stayed mostly uniform,
except for one method,

453
00:21:15,396 --> 00:21:17,792
which was carbon monoxide
poisoning by gas,

454
00:21:17,792 --> 00:21:20,792
and they saw
a steep dropoff from that.

455
00:21:20,792 --> 00:21:22,131
And what they eventually saw was

456
00:21:22,132 --> 00:21:24,627
that changes
in the gas production,

457
00:21:24,627 --> 00:21:26,924
moving from oil-based gas
to natural gas

458
00:21:26,924 --> 00:21:32,363
and a following reduction
in carbon monoxide to almost 0%,

459
00:21:32,363 --> 00:21:34,594
was the cause
of this steep decline.

460
00:21:34,594 --> 00:21:38,165
So, the UK didn't ban gas.

461
00:21:38,165 --> 00:21:40,528
They didn't change their
treatment of mental illness.

462
00:21:40,528 --> 00:21:43,825
What they inadvertently did was
they decreased the suicide rate

463
00:21:43,825 --> 00:21:48,066
by making a safer environment
for their citizens.

464
00:21:48,066 --> 00:21:53,462
Maybe a less morbid and more
stereotypical example is cars.

465
00:21:53,462 --> 00:21:57,429
We have seatbelts, airbags,
advanced safety controls,

466
00:21:57,429 --> 00:22:01,066
all aimed at reducing
the impact of a collision

467
00:22:01,066 --> 00:22:04,330
and reducing the chance
of injuries or fatalities.

468
00:22:04,330 --> 00:22:05,659
Now, we're not actually
addressing

469
00:22:05,660 --> 00:22:08,957
the underlying problem of people
being terrible drivers;

470
00:22:08,957 --> 00:22:13,627
we're just giving them a safer
environment to operate in.

471
00:22:13,627 --> 00:22:18,396
So does this mean we give up
on addressing end users?

472
00:22:18,396 --> 00:22:20,825
I'm not necessarily
in the camp of saying

473
00:22:20,825 --> 00:22:24,000
that user security training
is completely ineffective,

474
00:22:24,000 --> 00:22:26,033
but I would say that
we can better focus our efforts

475
00:22:26,033 --> 00:22:30,264
on influencing the user
behaviors that are safer,

476
00:22:30,264 --> 00:22:33,428
instead of making
them security experts.

477
00:22:33,429 --> 00:22:36,693
So, similar to what
Adrienne alluded to,

478
00:22:36,693 --> 00:22:40,726
maybe we can make it easier
to do good things and exhibit

479
00:22:40,726 --> 00:22:43,561
positive behaviors for security,
versus our current focus

480
00:22:43,561 --> 00:22:46,792
of just stopping users
form doing bad things.

481
00:22:46,792 --> 00:22:49,924
I think authentication
is a classic example of this,

482
00:22:49,924 --> 00:22:52,924
not only because of how
terrible passwords are,

483
00:22:52,924 --> 00:22:55,462
but how terribly
we've spun our wheels

484
00:22:55,462 --> 00:22:56,924
over the past few decades,
trying to come up

485
00:22:56,924 --> 00:23:00,825
with anything remotely better.

486
00:23:00,825 --> 00:23:03,132
So, we started Duo
about six years ago

487
00:23:03,132 --> 00:23:06,264
with the goal of making
logins more secure and usable

488
00:23:06,264 --> 00:23:08,065
and, at the time,
the state of the art

489
00:23:08,066 --> 00:23:12,495
was still really
the RSA SecurID token.

490
00:23:12,495 --> 00:23:13,924
So there's not a high bar
to start with.

491
00:23:13,924 --> 00:23:17,165
It was pretty low.

492
00:23:17,165 --> 00:23:22,792
What we realized is that
the RSA security technology

493
00:23:22,792 --> 00:23:25,000
that, still, people
in the audience have today,

494
00:23:25,000 --> 00:23:29,231
was actually invented in 1985,
which is when

495
00:23:29,231 --> 00:23:31,429
the "Back to the Future"
movie first came out.

496
00:23:31,429 --> 00:23:34,759
So, 30 years later, we not only
don't have hoverboards, yet,

497
00:23:34,759 --> 00:23:38,099
but we're still carrying
around these little dongles.

498
00:23:38,099 --> 00:23:39,759
And when you think about
how fast technology moves

499
00:23:39,759 --> 00:23:41,495
and how fast
security moves within it,

500
00:23:41,495 --> 00:23:43,264
it's really quite surprising.

501
00:23:43,264 --> 00:23:47,428
So we took a look at the state
of, you know, authentication.

502
00:23:47,429 --> 00:23:48,726
We saw that there were
hardware tokens;

503
00:23:48,726 --> 00:23:50,561
certainly, they have a poor
administrator experience,

504
00:23:50,561 --> 00:23:54,264
poor user experience;
they're very expensive.

505
00:23:54,264 --> 00:23:56,330
Phone calls and SMSes
rely on, you know,

506
00:23:56,330 --> 00:23:58,264
insecure and unreliable
telephony

507
00:23:58,264 --> 00:24:00,627
and software tokens, I'm sure
you all experience, kind of,

508
00:24:00,627 --> 00:24:03,297
the countdown-timer disorder
of trying to race it

509
00:24:03,297 --> 00:24:06,297
while you transcribe
a 6- or 8-digit number

510
00:24:06,297 --> 00:24:07,858
from one device to another.

511
00:24:07,858 --> 00:24:09,396
They're also based
on symmetric keys,

512
00:24:09,396 --> 00:24:11,495
which are suboptimal,
from a security point of view.

513
00:24:11,495 --> 00:24:13,099
And we threw all that out.
We said, "Hey.

514
00:24:13,099 --> 00:24:16,131
We have modern mobile devices."
They've got touchscreens,

515
00:24:16,132 --> 00:24:18,132
they've got apps,
they've got data service,

516
00:24:18,132 --> 00:24:20,693
you know, all these blindingly
obvious improvements,

517
00:24:20,693 --> 00:24:24,198
and we created Duo Push, which,
the operation is very simple:

518
00:24:24,198 --> 00:24:26,594
you receive a notification
on your phone and, to log in,

519
00:24:26,594 --> 00:24:28,363
you push the big, green button.

520
00:24:28,363 --> 00:24:30,000
Pretty foolproof.

521
00:24:30,000 --> 00:24:33,528
So, it was a clear increase
in usability.

522
00:24:33,528 --> 00:24:34,792
You know, if you can use
a remote control,

523
00:24:34,792 --> 00:24:36,131
you can use this.

524
00:24:36,132 --> 00:24:38,627
And users were able to create
that mental model

525
00:24:38,627 --> 00:24:41,858
of why it was securing
their logins.

526
00:24:41,858 --> 00:24:43,197
"Oh, I have this extra device
with me

527
00:24:43,198 --> 00:24:45,033
and I push the green button
to get in."

528
00:24:45,033 --> 00:24:46,428
And it was in their face,
but then,

529
00:24:46,429 --> 00:24:49,462
it would get out of their way
and let them do their job.

530
00:24:49,462 --> 00:24:51,000
And, as I mentioned,
easy and simple

531
00:24:51,000 --> 00:24:53,891
doesn't necessarily
mean less secure.

532
00:24:53,891 --> 00:24:55,396
We actually had
some improvements

533
00:24:55,396 --> 00:24:57,956
on the security underlying
this, that we could rely on

534
00:24:57,957 --> 00:25:00,330
and strong transport security
over the data network

535
00:25:00,330 --> 00:25:02,396
and we could actually rely
on asymmetric crypto,

536
00:25:02,396 --> 00:25:05,197
as opposed to symmetric crypto
with OTPs,

537
00:25:05,198 --> 00:25:08,132
which means that we can actually
embed private keys

538
00:25:08,132 --> 00:25:10,297
in these modern mobile devices.

539
00:25:10,297 --> 00:25:15,957
So, you might often see graphs
of security an usability,

540
00:25:15,957 --> 00:25:18,792
and it's often stated that,
if you increase security,

541
00:25:18,792 --> 00:25:20,462
you're decreasing usability,

542
00:25:20,462 --> 00:25:24,429
and if you increase usability,
you're decreasing security.

543
00:25:24,429 --> 00:25:26,561
And I disagree with this.
This is a fallacy

544
00:25:26,561 --> 00:25:28,528
that I think creates
a dangerous mindset

545
00:25:28,528 --> 00:25:33,660
that leads to compromise
and ineffective solutions.

546
00:25:33,660 --> 00:25:36,264
I think it is possible
to increase both security

547
00:25:36,264 --> 00:25:38,890
and usability, but there
might be other considerations.

548
00:25:38,891 --> 00:25:40,495
You know, maybe the right
representation

549
00:25:40,495 --> 00:25:43,428
is a Zooko Triangle
that includes compatibility.

550
00:25:43,429 --> 00:25:46,099
You know, certainly, if we
discard all legacy equipment

551
00:25:46,099 --> 00:25:49,956
and we ignored past decades
of computing history,

552
00:25:49,957 --> 00:25:52,231
it's easy to do security right.

553
00:25:52,231 --> 00:25:56,330
So, while incrementalism might
be bad for security design,

554
00:25:56,330 --> 00:26:00,131
it's absolutely critical
for security deployment.

555
00:26:00,132 --> 00:26:03,363
I would argue that, you know,
Duo Push increases both,

556
00:26:03,363 --> 00:26:06,429
but, certainly, SmartPhones
are not universal, quite yet.

557
00:26:06,429 --> 00:26:09,033
But, if you get security
and usability right,

558
00:26:09,033 --> 00:26:10,792
compatibility
will eventually play out

559
00:26:10,792 --> 00:26:13,197
as technology cycles through.

560
00:26:13,198 --> 00:26:16,759
We now see major providers,
like Twitter, Yahoo!, and Google

561
00:26:16,759 --> 00:26:20,264
adopting similar approaches,
not only for two-factor,

562
00:26:20,264 --> 00:26:24,197
but actually as a replacement
for passwords, altogether.

563
00:26:24,198 --> 00:26:27,528
So, the once holy grail
of replacing passwords

564
00:26:27,528 --> 00:26:30,033
is not so farfetched now,

565
00:26:30,033 --> 00:26:32,858
and this was done by introducing
a safer mechanism

566
00:26:32,858 --> 00:26:38,330
that also relies on the user
to be enlisted in security.

567
00:26:38,330 --> 00:26:42,561
So, to sum up: let's make sure
we focus not only directly

568
00:26:42,561 --> 00:26:45,759
on corporate end users,
but also on the environments,

569
00:26:45,759 --> 00:26:51,429
the organizations they operate
in, as well as the industry.

570
00:26:51,429 --> 00:26:53,396
Matthew, our next speaker, has
already done a lot of great work

571
00:26:53,396 --> 00:26:55,858
in this area; and Adrienne,
our previous speaker,

572
00:26:55,858 --> 00:26:57,594
while we might not be
running experiments

573
00:26:57,594 --> 00:27:00,495
at the same scale
as millions of end users,

574
00:27:00,495 --> 00:27:02,824
I think the impacts
can be equally powerful.

575
00:27:02,825 --> 00:27:06,660
So, it appears my top-secret
research agenda has been leaked.

576
00:27:06,660 --> 00:27:08,330
These are questions
that I commonly

577
00:27:08,330 --> 00:27:10,890
ask customers
in an informal way,

578
00:27:10,891 --> 00:27:14,198
but I think they're worthy
of more formal investigation.

579
00:27:14,198 --> 00:27:15,924
There's lots of academics
in the audience,

580
00:27:15,924 --> 00:27:18,132
so if these are
interesting topics to you,

581
00:27:18,132 --> 00:27:19,462
definitely come talk to me.

582
00:27:19,462 --> 00:27:21,264
There's also lots of current

583
00:27:21,264 --> 00:27:23,527
and future founders
of security companies,

584
00:27:23,528 --> 00:27:26,792
so we have to keep in mind
not only what products we build,

585
00:27:26,792 --> 00:27:28,726
but what companies
and markets we create,

586
00:27:28,726 --> 00:27:31,495
and keeping the focus
on usability and security.

587
00:27:31,495 --> 00:27:33,065
And lastly,
I think that this kind

588
00:27:33,066 --> 00:27:36,198
of crosspollination
between academia and industry

589
00:27:36,198 --> 00:27:38,132
is absolutely critical
in this kind of work,

590
00:27:38,132 --> 00:27:41,462
so I appreciate
USENIX hosting events ENIGMA,

591
00:27:41,462 --> 00:27:44,495
as well as WOOT,
to try to bridge this gap.

592
00:27:44,495 --> 00:27:45,726
Thank you.

593
00:27:45,726 --> 00:27:49,924
[ Applause ]

594
00:27:49,924 --> 00:27:55,132
♪♪

595
00:27:55,132 --> 00:27:54,132


