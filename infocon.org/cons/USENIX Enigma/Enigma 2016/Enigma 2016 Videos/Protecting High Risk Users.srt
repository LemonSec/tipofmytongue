1
00:00:00,198 --> 00:00:00,660


2
00:00:00,660 --> 00:00:05,099
♪♪

3
00:00:05,099 --> 00:00:08,363
GALPERIN: Hi, there. I'm here to talk with Morgan

4
00:00:08,363 --> 00:00:11,626
about the problem of protecting high-risk users.

5
00:00:11,627 --> 00:00:14,363
As Alex said, my name is Eva Galperin.

6
00:00:14,363 --> 00:00:16,099
I work for the Electronic Frontier Foundation,

7
00:00:16,099 --> 00:00:18,363
where I am not a technologist.

8
00:00:18,363 --> 00:00:21,165
I am a global policy analyst, which is a title

9
00:00:21,165 --> 00:00:23,660
that I've put together to sound as bland as possible

10
00:00:23,660 --> 00:00:25,957
when crossing borders into dangerous places.

11
00:00:25,957 --> 00:00:28,495
I work on EFF's international team,

12
00:00:28,495 --> 00:00:31,462
where I spend most of my time worrying about privacy

13
00:00:31,462 --> 00:00:33,363
and security for vulnerable populations,

14
00:00:33,363 --> 00:00:35,033
usually activists and journalists,

15
00:00:35,033 --> 00:00:37,528
the kind of people who piss off governments.

16
00:00:37,528 --> 00:00:41,099
To that end, I do trainings with activists and journalists

17
00:00:41,099 --> 00:00:44,660
and I have helped write "Surveillance Self-defense,"

18
00:00:44,660 --> 00:00:48,000
which is our privacy and security guide.

19
00:00:48,000 --> 00:00:50,561
And I work with this guy.

20
00:00:50,561 --> 00:00:52,924
MARQUIS-BOIRE: Hi, so I'm Morgan Marquis-Boire,

21
00:00:52,924 --> 00:00:54,561
and, as Alex mentioned, I'm currently

22
00:00:54,561 --> 00:00:56,330
the director of security at First Look Media,

23
00:00:56,330 --> 00:00:58,726
which, among other things, does publish The Intercept,

24
00:00:58,726 --> 00:01:01,594
bunch of troublemaking journalists that they are.

25
00:01:01,594 --> 00:01:04,924
I also publish research through the Citizen Lab

26
00:01:04,924 --> 00:01:06,594
at the University of Toronto, which is sort of

27
00:01:06,594 --> 00:01:09,297
a multidisciplinary think tank at the intersection

28
00:01:09,297 --> 00:01:13,561
of security, human rights, and some digital media.

29
00:01:13,561 --> 00:01:14,891
In addition to that,

30
00:01:14,891 --> 00:01:18,561
I advise a number of organizations about security,

31
00:01:18,561 --> 00:01:20,693
including sort of the Freedom of Press Foundation

32
00:01:20,693 --> 00:01:23,627
and Amnesty International.

33
00:01:23,627 --> 00:01:27,198
GALPERIN: And, together, we've done a very large pile of work.

34
00:01:27,198 --> 00:01:29,660
What's particularly interesting about the work that we've done

35
00:01:29,660 --> 00:01:31,693
is that it's multidisciplinary.

36
00:01:31,693 --> 00:01:34,330
It involves a lot of people and organizations

37
00:01:34,330 --> 00:01:38,297
that normally don't talk to each other, so we have NGOs,

38
00:01:38,297 --> 00:01:41,396
we have activists on the ground, we have academics,

39
00:01:41,396 --> 00:01:43,396
and we have people in private security.

40
00:01:43,396 --> 00:01:46,066
I would like to think that I'm Wonder Woman in this picture,

41
00:01:46,066 --> 00:01:48,165
but I'm probably the useless blue-haired girl

42
00:01:48,165 --> 00:01:50,891
who is half of the Wonder Twins, and we spend most of our time

43
00:01:50,891 --> 00:01:54,429
arguing over which one of us is Aquaman.

44
00:01:54,429 --> 00:01:57,495
MARQUIS-BOIRE: Right, so, this type of collaboration

45
00:01:57,495 --> 00:02:00,198
started, you know, close to five years ago,

46
00:02:00,198 --> 00:02:02,758
during sort of a series of events

47
00:02:02,759 --> 00:02:05,858
which kind of captured the attention of the world,

48
00:02:05,858 --> 00:02:09,099
you know, the so-called Arab Spring.

49
00:02:09,098 --> 00:02:11,825
In these sort of heady pre-ISIS days,

50
00:02:11,825 --> 00:02:15,000
we tracked a series of information operations

51
00:02:15,000 --> 00:02:16,726
that were occurring close to the beginning

52
00:02:16,726 --> 00:02:18,528
of the uprising in Syria,

53
00:02:18,528 --> 00:02:22,429
which, as many of you know, is still ongoing.

54
00:02:22,429 --> 00:02:27,759
Sort of about eight months or so after the civil unrest began,

55
00:02:27,759 --> 00:02:32,726
the Syrian government, pro-state, pro-Assad actors,

56
00:02:32,726 --> 00:02:34,495
decided that it was a very good idea

57
00:02:34,495 --> 00:02:36,429
to start monitoring the activities

58
00:02:36,429 --> 00:02:40,099
of prodemocracy dissidents, foreign NGO workers,

59
00:02:40,099 --> 00:02:42,429
and other people whose interests weren't strictly aligned

60
00:02:42,429 --> 00:02:46,693
with the governing regime and the way they did this was,

61
00:02:46,693 --> 00:02:50,231
you know, by implanting malware, spyware.

62
00:02:50,231 --> 00:02:51,561
You know, malware's so judgmental.

63
00:02:51,561 --> 00:02:53,660
It's really just software, but implanting

64
00:02:53,660 --> 00:02:56,462
this type of thing on their machines.

65
00:02:56,462 --> 00:02:58,528
And they primarily used social media to do it.

66
00:02:58,528 --> 00:03:00,066
I mean, there's been sort of a lot of discussion

67
00:03:00,066 --> 00:03:02,792
about the role that social media played during the Arab Spring.

68
00:03:02,792 --> 00:03:07,165
Obviously, YouTube and Facebook were very critical.

69
00:03:07,165 --> 00:03:08,560
And so, frequently, this was delivered

70
00:03:08,561 --> 00:03:11,066
in the form of phishing attacks, but also via sort of

71
00:03:11,066 --> 00:03:13,693
Skype, Messenger, and it was delivered

72
00:03:13,693 --> 00:03:16,033
to a variety of really high-profile figures.

73
00:03:16,033 --> 00:03:19,363
The man's face you see up there, his name is Burhan Ghalioun,

74
00:03:19,363 --> 00:03:21,792
and he's a professor at the Sorbonne in Paris,

75
00:03:21,792 --> 00:03:23,858
however, at the time, he was also the head

76
00:03:23,858 --> 00:03:25,726
of the Syrian Transnational Opposition.

77
00:03:25,726 --> 00:03:27,528
So, just one example.

78
00:03:27,528 --> 00:03:29,891
Like he was compromised and they used this to compromise

79
00:03:29,891 --> 00:03:33,132
his social media presences and then sort of seed malware,

80
00:03:33,132 --> 00:03:35,099
in an effort to sort of compromise his followers,

81
00:03:35,099 --> 00:03:38,429
so they could sort of keep track of, you know, groups

82
00:03:38,429 --> 00:03:41,660
with which they weren't entirely pleased.

83
00:03:41,660 --> 00:03:45,066
Now, "not entirely pleased" is something of a euphemism.

84
00:03:45,066 --> 00:03:48,957
As you'll be aware, the situation in Syria

85
00:03:48,957 --> 00:03:52,396
has been tumultuous, to say the least.

86
00:03:52,396 --> 00:03:56,494
There's been some very real-world negative effects

87
00:03:56,495 --> 00:03:59,693
for people that were, you know, compromised by these actors.

88
00:03:59,693 --> 00:04:03,198
One that, you know, sort of really sticks in my mind

89
00:04:03,198 --> 00:04:05,132
is the case of a man named Taymour Kareem

90
00:04:05,132 --> 00:04:07,264
who was kidnapped by the Syrian police.

91
00:04:07,264 --> 00:04:10,198
He was beaten. He was tortured.

92
00:04:10,198 --> 00:04:12,132
He said, "They broke my bones.

93
00:04:12,132 --> 00:04:14,957
I did not talk, but that did not matter

94
00:04:14,957 --> 00:04:17,231
because my computer was arrested before I was."

95
00:04:17,231 --> 00:04:19,659
They showed him these transcripts

96
00:04:19,660 --> 00:04:21,792
of his Skype conversations and his e-mails,

97
00:04:21,791 --> 00:04:24,825
which they had, you know, gathered from his computer,

98
00:04:24,825 --> 00:04:26,659
using what I would describe

99
00:04:26,660 --> 00:04:29,957
as really not very advanced malware at all.

100
00:04:29,957 --> 00:04:32,231
Following on from this, you know, we started

101
00:04:32,231 --> 00:04:34,528
writing these posts, as I said, close to about 5 years ago

102
00:04:34,528 --> 00:04:37,165
and we wrote about 14 on the situation in Syria

103
00:04:37,165 --> 00:04:38,891
and this led to us being contacted by,

104
00:04:38,891 --> 00:04:41,792
you know, other activists in the region.

105
00:04:41,792 --> 00:04:46,198
As you'll remember, the entire Middle East was

106
00:04:46,198 --> 00:04:48,924
in some disarray.

107
00:04:48,924 --> 00:04:51,132
And some of the most famous or well-known work

108
00:04:51,132 --> 00:04:55,858
to come out of this was on the now-infamous malware product,

109
00:04:55,858 --> 00:04:57,792
produced by the Italian company Hacking Team,

110
00:04:57,792 --> 00:05:01,198
known as Remote Control System.

111
00:05:01,198 --> 00:05:02,726
GALPERIN: So, this is sort of the story

112
00:05:02,726 --> 00:05:06,363
of how the Hacking Team sweater became unraveled,

113
00:05:06,363 --> 00:05:08,561
where you find that sort of first thread.

114
00:05:08,561 --> 00:05:09,825
I'm sitting around,

115
00:05:09,825 --> 00:05:11,890
having done a whole bunch of work with Morgan

116
00:05:11,891 --> 00:05:14,957
and I'm reading Slate and I see an article

117
00:05:14,957 --> 00:05:17,330
which describes a situation

118
00:05:17,330 --> 00:05:20,429
in which an unnamed Moroccan activist

119
00:05:20,429 --> 00:05:23,494
had had his computer compromised by the Moroccan government.

120
00:05:23,495 --> 00:05:25,099
And I said, "Gee, that sounds interesting."

121
00:05:25,099 --> 00:05:27,957
So I call Morgan up and I say, "Do you want to work on this?"

122
00:05:27,957 --> 00:05:30,825
and he says, "Well, do you know any activists in Morocco?"

123
00:05:30,825 --> 00:05:35,099
And, as it happens, I knew one activist in all of Morocco.

124
00:05:35,099 --> 00:05:38,462
His name was Hisham Almiraat and I had just spent

125
00:05:38,462 --> 00:05:40,693
some time with him at a conference in Porto.

126
00:05:40,693 --> 00:05:44,066
So I call up the one activist that I know in all of Morocco

127
00:05:44,066 --> 00:05:45,825
and I ask him, "Do you know who it is

128
00:05:45,825 --> 00:05:47,924
who has been compromised with this malware?"

129
00:05:47,924 --> 00:05:51,032
and he says, "Well, you got it in one because it's me."

130
00:05:51,033 --> 00:05:53,165
[ Marquis-Boire laughs ]

131
00:05:53,165 --> 00:05:55,363
I had him go ahead and send the sample to Morgan

132
00:05:55,363 --> 00:05:58,594
and Morgan and Citizen Lab wrote up a report

133
00:05:58,594 --> 00:06:01,396
and this was really the first evidence that we saw

134
00:06:01,396 --> 00:06:03,858
of Hacking Team's involvement

135
00:06:03,858 --> 00:06:11,132
in the compromising of activists in these sort of countries

136
00:06:11,132 --> 00:06:14,759
where the rule of law was not particularly strong.

137
00:06:14,759 --> 00:06:17,561
Now, this was not the end of things

138
00:06:17,561 --> 00:06:19,758
for these Moroccan activists because it turns out

139
00:06:19,759 --> 00:06:22,561
that it was not just Hisham who had been compromised.

140
00:06:22,561 --> 00:06:24,825
For these Moroccan activists who were being surveilled

141
00:06:24,825 --> 00:06:27,396
by the Moroccan government, many of these activists

142
00:06:27,396 --> 00:06:29,363
were members of an organization called Mamfakinch,

143
00:06:29,363 --> 00:06:33,693
which Hisham helped to found and which later fell apart

144
00:06:33,693 --> 00:06:35,825
because of pressure from the Moroccan government

145
00:06:35,825 --> 00:06:42,066
and a lot of these guys are currently being --

146
00:06:42,066 --> 00:06:45,462
sorry, they're on trial by the Moroccan government

147
00:06:45,462 --> 00:06:48,627
for a variety of sort of trumped-up charges,

148
00:06:48,627 --> 00:06:53,165
ranging from adultery to -- what was it?

149
00:06:53,165 --> 00:06:58,429
Threatening the national security of the state.

150
00:06:58,429 --> 00:07:01,957
MARQUIS-BOIRE: Yeah, so, yeah.

151
00:07:01,957 --> 00:07:05,792
Similarly, this man here, Ahmed Mansoor,

152
00:07:05,792 --> 00:07:07,099
he's an interesting character.

153
00:07:07,099 --> 00:07:10,296
He's currently an advisor to Humans Rights Watch.

154
00:07:10,297 --> 00:07:15,693
He lives in the UAE and he's one of the so-called UAE Five.

155
00:07:15,693 --> 00:07:18,627
You know, these five individuals had the distinction

156
00:07:18,627 --> 00:07:20,099
of being imprisoned by the government

157
00:07:20,099 --> 00:07:22,099
for signing a prodemocracy petition.

158
00:07:22,099 --> 00:07:25,363
Not a particularly popular move.

159
00:07:25,363 --> 00:07:26,858
He was released.

160
00:07:26,858 --> 00:07:30,891
His opinions on the value of democracy had not changed;

161
00:07:30,891 --> 00:07:32,759
unsurprisingly, his government's opinions

162
00:07:32,759 --> 00:07:39,264
on his opinions, also unchanged, and so, he found

163
00:07:39,264 --> 00:07:42,462
that the ramifications of this was that he was being followed

164
00:07:42,462 --> 00:07:43,858
and he was being beaten.

165
00:07:43,858 --> 00:07:45,726
He would actually have plainclothes thugs

166
00:07:45,726 --> 00:07:48,429
who would sort of assault him at university or on the street

167
00:07:48,429 --> 00:07:52,429
and he was really unaware of how they were tracking his location.

168
00:07:52,429 --> 00:07:54,429
He's a sharp man and he suspected

169
00:07:54,429 --> 00:07:58,957
that this was somehow done through his computer.

170
00:07:58,957 --> 00:08:00,924
And so he contacted me and I performed forensics

171
00:08:00,924 --> 00:08:07,066
on his computer, and lo, I found that his hunches,

172
00:08:07,066 --> 00:08:09,594
his instincts, were actually pretty good.

173
00:08:09,594 --> 00:08:13,296
He'd been sent a Word document which he had opened,

174
00:08:13,297 --> 00:08:14,561
not believing that a Word document

175
00:08:14,561 --> 00:08:15,924
could actually do anything bad.

176
00:08:15,924 --> 00:08:17,858
I know, right?

177
00:08:17,858 --> 00:08:19,429
GALPERIN: It was 2012. [laughs]

178
00:08:19,429 --> 00:08:21,032
MARQUIS-BOIRE: It was 2012, you know.

179
00:08:21,033 --> 00:08:23,231
It was a different time, a simpler time.

180
00:08:23,231 --> 00:08:25,363
But, yeah, he had opened this Word document

181
00:08:25,363 --> 00:08:27,429
which contained an exploit which had then implanted

182
00:08:27,429 --> 00:08:29,363
Hacking Team's malware onto his computer.

183
00:08:29,363 --> 00:08:33,066
Now, you know, they say that attribution is tricky,

184
00:08:33,066 --> 00:08:37,033
that nebulous "they," but sometimes it actually isn't

185
00:08:37,033 --> 00:08:38,890
because we found that, for a period,

186
00:08:38,890 --> 00:08:41,000
the command and control server for this malware

187
00:08:41,000 --> 00:08:43,495
actually pointed to a small IP address range

188
00:08:43,495 --> 00:08:47,561
which was owned by the office of the sheik in Abu Dhabi.

189
00:08:47,561 --> 00:08:48,858
I found it very difficult to figure out

190
00:08:48,858 --> 00:08:52,396
exactly who that was, but I have some suspicions.

191
00:08:52,396 --> 00:08:55,363
And so, this type of activity, of course,

192
00:08:55,363 --> 00:08:56,726
wasn't confined to the Middle East,

193
00:08:56,726 --> 00:08:58,891
although it was a very interesting time to observe it,

194
00:08:58,891 --> 00:09:01,363
largely because the conflict meant that I think a lot of

195
00:09:01,363 --> 00:09:06,264
sort of surveillance operations went into high drive.

196
00:09:06,264 --> 00:09:08,231
GALPERIN: All right, so it's not just the Middle East.

197
00:09:08,231 --> 00:09:09,462
What we have here are

198
00:09:09,462 --> 00:09:13,759
two reasonably well-known bloggers in Vietnam.

199
00:09:13,759 --> 00:09:16,792
This is Le Quoc Quan and Dieu Cay.

200
00:09:16,792 --> 00:09:19,528
As part of my work at EFF, I actually have spent

201
00:09:19,528 --> 00:09:24,495
a lot of time sort of doing activism on their behalf.

202
00:09:24,495 --> 00:09:27,033
As sort of, you know, prodemocracy,

203
00:09:27,033 --> 00:09:30,759
critical-of-the-government bloggers in Vietnam,

204
00:09:30,759 --> 00:09:34,132
they have been harassed, beaten,

205
00:09:34,132 --> 00:09:38,132
and repeatedly jailed over the years.

206
00:09:38,132 --> 00:09:41,132
As it turns out, not only did this turn out

207
00:09:41,132 --> 00:09:46,000
to be a problem for the bloggers, themselves, but,

208
00:09:46,000 --> 00:09:48,726
it turned out that the work

209
00:09:48,726 --> 00:09:52,462
that people outside of Vietnam were doing on their behalf

210
00:09:52,462 --> 00:09:57,693
also garnered the notice of the Vietnamese government.

211
00:09:57,693 --> 00:10:02,660
About two years ago, in January of 2014,

212
00:10:02,660 --> 00:10:06,396
I found myself targeted by the Vietnamese government

213
00:10:06,396 --> 00:10:09,165
with malware that they sent directly to me,

214
00:10:09,165 --> 00:10:10,560
which makes gathering the samples

215
00:10:10,561 --> 00:10:12,165
[singsong] supersimple. -[Laughter]

216
00:10:12,165 --> 00:10:13,693
Definitely appreciate. -It was very convenient.

217
00:10:13,693 --> 00:10:17,000
I was not the only person targeted at EFF.

218
00:10:17,000 --> 00:10:18,330
There were two of us.

219
00:10:18,330 --> 00:10:21,132
It was me and an activist, April Glaser,

220
00:10:21,132 --> 00:10:26,263
and we had been targeted with an e-mail made to look

221
00:10:26,264 --> 00:10:29,528
as if it was coming from a gentleman at Oxfam,

222
00:10:29,528 --> 00:10:35,231
offering to bring us to an "Asia conference" of some sort.

223
00:10:35,231 --> 00:10:39,165
Really, this did show a strong understanding

224
00:10:39,165 --> 00:10:42,033
of what motivates activists, but I think that,

225
00:10:42,033 --> 00:10:44,330
if they had really wanted us to click on the link,

226
00:10:44,330 --> 00:10:46,627
they should've offered free flights and hotels.

227
00:10:46,627 --> 00:10:48,363
[ Laughter ]

228
00:10:48,363 --> 00:10:50,726
So, having analyzed the sample, we discovered

229
00:10:50,726 --> 00:10:53,396
that this was actually part of a campaign

230
00:10:53,396 --> 00:10:58,198
going back to 2010, which Google first noticed.

231
00:10:58,198 --> 00:11:01,132
We also connected it to samples

232
00:11:01,132 --> 00:11:05,726
which were targeting a blogger in Los Angeles,

233
00:11:05,726 --> 00:11:07,528
who had also written on these subjects;

234
00:11:07,528 --> 00:11:12,660
and a mathematics professor at the University of Toulouse.

235
00:11:12,660 --> 00:11:15,924
What was particularly interesting about this campaign

236
00:11:15,924 --> 00:11:18,297
was not that the Vietnamese government

237
00:11:18,297 --> 00:11:20,891
had chosen to target me, though, of course, I thought

238
00:11:20,891 --> 00:11:22,198
this was very important. -[Marquis-Boire laughs]

239
00:11:22,198 --> 00:11:25,000
But that they had chosen to target my coworker,

240
00:11:25,000 --> 00:11:27,693
who had only been at EFF for a couple of months

241
00:11:27,693 --> 00:11:29,693
and whose entire contribution

242
00:11:29,693 --> 00:11:34,660
to sort of pro-Vietnamese blogger democracy campaigning

243
00:11:34,660 --> 00:11:36,462
was having written a single blog post

244
00:11:36,462 --> 00:11:39,033
that I had not had time to pen myself.

245
00:11:39,033 --> 00:11:41,231
So, this leads us to the very worrying conclusion

246
00:11:41,231 --> 00:11:43,429
that all it takes is one blog post

247
00:11:43,429 --> 00:11:45,396
to get on the Vietnamese government's radar.

248
00:11:48,792 --> 00:11:51,297
MARQUIS-BOIRE: So, you know, I'm gonna talk a little bit

249
00:11:51,297 --> 00:11:55,231
about this campaign, which we call Packrat,

250
00:11:55,231 --> 00:11:58,495
which, as you can tell from the map behind us,

251
00:11:58,495 --> 00:12:01,594
is focused mainly on South America.

252
00:12:01,594 --> 00:12:04,165
Speaking a little to the targeting

253
00:12:04,165 --> 00:12:07,726
of Eva and April by the Vietnamese government,

254
00:12:07,726 --> 00:12:09,957
at Citizen Lab, we spent several months

255
00:12:09,957 --> 00:12:11,429
you know, working on this campaign.

256
00:12:11,429 --> 00:12:13,726
Of course, that involves, you know, while you're doing this,

257
00:12:13,726 --> 00:12:15,693
you run a lot of malware samples in a sandbox.

258
00:12:15,693 --> 00:12:19,627
You know, occasionally, you might run these in sandboxes

259
00:12:19,627 --> 00:12:21,593
live to the Internet because you want to watch the traffic;

260
00:12:21,594 --> 00:12:26,462
you want to, perhaps, see what the attacker's behavior is like,

261
00:12:26,462 --> 00:12:28,660
stay true to the malware.

262
00:12:28,660 --> 00:12:31,791
In this case, these particular actors -- maybe they were

263
00:12:31,792 --> 00:12:34,858
having a bad day -- got very pissed off with this activity

264
00:12:34,858 --> 00:12:36,263
and decided it was a very good idea

265
00:12:36,264 --> 00:12:39,000
to threaten a member of the Citizen Lab team,

266
00:12:39,000 --> 00:12:41,033
you know, pointing out that they knew who we were,

267
00:12:41,033 --> 00:12:42,330
which I guess they really do, now.

268
00:12:42,330 --> 00:12:44,528
[Galperin laughs] -But decided, at the time,

269
00:12:44,528 --> 00:12:46,000
that they would sort of point out that they knew who we were

270
00:12:46,000 --> 00:12:47,429
and they knew where our families live

271
00:12:47,429 --> 00:12:51,264
and they were gonna shoot us, them, everybody.

272
00:12:51,264 --> 00:12:53,825
Which, you know, we sort of noted, moved on.

273
00:12:53,825 --> 00:12:58,330
And then, of course, they did it again about two weeks later.

274
00:12:58,330 --> 00:13:01,264
However, I mean, it's interesting, you know,

275
00:13:01,264 --> 00:13:03,495
like I guess if someone, you know, threatens to shoot you,

276
00:13:03,495 --> 00:13:05,792
you're kind of like "Oh, wow, that seems really bad."

277
00:13:05,792 --> 00:13:08,693
This is quite easy to contextualize

278
00:13:08,693 --> 00:13:10,759
in the scheme of these things because, you know,

279
00:13:10,759 --> 00:13:12,825
sitting in my house in San Francisco,

280
00:13:12,825 --> 00:13:15,528
looking at malware, it's like "Yeah, really?

281
00:13:15,528 --> 00:13:17,000
I grew up on the Internet.

282
00:13:17,000 --> 00:13:20,759
People threaten me every day. Have you been on Twitter?"

283
00:13:20,759 --> 00:13:24,693
But so this group had been active for about,

284
00:13:24,693 --> 00:13:26,066
we discovered, at least seven years.

285
00:13:26,066 --> 00:13:29,198
They targeted judges, lawyers, members of the ruling

286
00:13:29,198 --> 00:13:33,957
political family in Argentina, journalists, NGOs,

287
00:13:33,957 --> 00:13:36,066
and they're very active, and, in some ways,

288
00:13:36,066 --> 00:13:37,858
quite brazen, as you can tell from the threats.

289
00:13:37,858 --> 00:13:42,032
This woman, her name is Janet Hinostroza

290
00:13:42,033 --> 00:13:44,924
and she was hacked twice in 2013.

291
00:13:44,924 --> 00:13:47,264
Her e-mails were leaked and then published

292
00:13:47,264 --> 00:13:49,330
by a news organization who claimed that

293
00:13:49,330 --> 00:13:53,231
they got her Gmail contents via FOIA request.

294
00:13:53,231 --> 00:13:55,066
FOIA request.

295
00:13:55,066 --> 00:13:56,297
I don't know if there's anyone from Google in the audience.

296
00:13:56,297 --> 00:13:57,561
Maybe you can comment on that later.

297
00:13:57,561 --> 00:14:01,891
[laughing] But, however, you know, they targeted

298
00:14:01,891 --> 00:14:07,098
a lot of journalists and, quite pugnaciously,

299
00:14:07,099 --> 00:14:09,429
this woman, Martha Roldós,

300
00:14:09,429 --> 00:14:13,165
is an environmental activist and journalist from Ecuador

301
00:14:13,165 --> 00:14:16,593
and we discovered that she had been targeted 34 different times

302
00:14:16,594 --> 00:14:20,297
over this period by this group.

303
00:14:20,297 --> 00:14:24,924
Obviously, her pro-environmental position is very unpopular.

304
00:14:24,924 --> 00:14:28,759
So, I mean, these are just examples of,

305
00:14:28,759 --> 00:14:30,297
you know, the types of individuals,

306
00:14:30,297 --> 00:14:32,363
organizations that we've worked with and the type of activists

307
00:14:32,363 --> 00:14:34,858
that we've seen operating in this area.

308
00:14:34,858 --> 00:14:38,429
Sort of between us and others at Citizen Lab,

309
00:14:38,429 --> 00:14:40,329
we've, you know, seen the targeting

310
00:14:40,330 --> 00:14:43,429
of activists and journalists on, you know, all five continents.

311
00:14:43,429 --> 00:14:45,627
Well, maybe not Antarctica. Have we? No?

312
00:14:45,627 --> 00:14:48,065
GALPERIN: There's still time. -MARQUIS-BOIRE: There's time.

313
00:14:48,066 --> 00:14:50,165
But, yeah, so, I mean, as you'll notice,

314
00:14:50,165 --> 00:14:51,858
our primary interest group,

315
00:14:51,858 --> 00:14:54,132
in terms of people being targeted by governments,

316
00:14:54,132 --> 00:14:55,527
are sort of activists and journalists

317
00:14:55,528 --> 00:14:58,924
and human rights researchers and this is primarily 'cause

318
00:14:58,924 --> 00:15:00,396
they don't have security teams, right?

319
00:15:00,396 --> 00:15:04,065
So there's a distinct asymmetry problem there.

320
00:15:04,066 --> 00:15:05,759
Now, it's important to note that, when we say

321
00:15:05,759 --> 00:15:09,693
high-risk users, there's obviously a spectrum, right?

322
00:15:09,693 --> 00:15:12,726
The spectrum that I've been using

323
00:15:12,726 --> 00:15:14,792
when we've been discussing this is on a scale

324
00:15:14,792 --> 00:15:18,264
of zero to Edward Snowden, right?

325
00:15:18,264 --> 00:15:20,825
Do you have to hide in Russia? -[Laughter]

326
00:15:20,825 --> 00:15:24,198
And so, not all high-risk users are created equal

327
00:15:24,198 --> 00:15:27,396
and not all are equally desirable to governments.

328
00:15:27,396 --> 00:15:30,098
Whoa.

329
00:15:30,099 --> 00:15:32,165
GALPERIN: Which brings us to the question of

330
00:15:32,165 --> 00:15:35,000
"So what is it that you guys are doing all day?"

331
00:15:35,000 --> 00:15:37,528
Primarily, what we do,

332
00:15:37,528 --> 00:15:39,726
probably the thing that takes the most time,

333
00:15:39,726 --> 00:15:42,825
is outreach, community relations and trustbuilding,

334
00:15:42,825 --> 00:15:44,231
which is getting out on the ground

335
00:15:44,231 --> 00:15:46,330
and meeting that one guy in Morocco

336
00:15:46,330 --> 00:15:48,627
who's probably being targeted with malware.

337
00:15:48,627 --> 00:15:50,231
This takes a lot of time.

338
00:15:50,231 --> 00:15:52,066
Trust is not free.

339
00:15:52,066 --> 00:15:55,033
You have to build it up before somebody who is on the ground,

340
00:15:55,033 --> 00:15:58,462
who is possibly being threatened by their government,

341
00:15:58,462 --> 00:16:01,528
trusts you enough to give you full access to their computer.

342
00:16:01,528 --> 00:16:03,561
They better have spent some time with you,

343
00:16:03,561 --> 00:16:07,594
in order to understand that you're trustworthy.

344
00:16:07,594 --> 00:16:10,066
We also do actual incident response,

345
00:16:10,066 --> 00:16:15,099
so, forensics, malware analysis, and threat intelligence.

346
00:16:15,099 --> 00:16:20,396
This is sort of the meaty, technical part of the job.

347
00:16:20,396 --> 00:16:24,396
We also do a lot of education, so the easiest way

348
00:16:24,396 --> 00:16:26,957
to deal with this sort of malware problem

349
00:16:26,957 --> 00:16:31,000
is to somehow convince your vulnerable population

350
00:16:31,000 --> 00:16:34,066
not to install it on their computers, in the first place.

351
00:16:34,066 --> 00:16:36,462
As you can tell, most of these attacks

352
00:16:36,462 --> 00:16:38,858
are phishing and watering-hole attacks,

353
00:16:38,858 --> 00:16:41,296
and with a little bit of education,

354
00:16:41,297 --> 00:16:43,066
you can actually do a lot

355
00:16:43,066 --> 00:16:47,726
to cut down on the effectiveness of these kinds of attacks.

356
00:16:47,726 --> 00:16:51,594
As has been frequently pointed out, the vast majority

357
00:16:51,594 --> 00:16:55,528
of the vulnerable populations that we see

358
00:16:55,528 --> 00:16:58,825
are not being targeted by Spooky O'Day

359
00:16:58,825 --> 00:17:02,396
They are almost never using brand-new exploits.

360
00:17:02,396 --> 00:17:05,066
They're using old exploits for unpatched software,

361
00:17:05,066 --> 00:17:07,891
if they're even using exploits at all.

362
00:17:07,891 --> 00:17:10,330
And also, we do, like, a little bit

363
00:17:10,329 --> 00:17:11,956
of IT support and security help desk,

364
00:17:11,957 --> 00:17:14,627
so, sitting down with somebody and trying to work out

365
00:17:14,627 --> 00:17:16,462
whether this is a state-sponsored actor,

366
00:17:16,462 --> 00:17:19,462
or they just like clicked on some weird porn link.

367
00:17:19,462 --> 00:17:21,924
We also do a lot of policy research.

368
00:17:21,924 --> 00:17:23,759
The kind of work that we do

369
00:17:23,759 --> 00:17:26,858
often has very interesting legal ramifications.

370
00:17:26,858 --> 00:17:30,330
EFF is currently involved in a lawsuit in which

371
00:17:30,330 --> 00:17:32,890
we represent a gentleman living in Washington, DC

372
00:17:32,891 --> 00:17:35,858
who has been surveilled by the government of Ethiopia,

373
00:17:35,858 --> 00:17:40,033
who covertly installed FinFisher surveillance malware

374
00:17:40,033 --> 00:17:43,165
on his computer and used it to spy

375
00:17:43,165 --> 00:17:46,956
on his Skype conversations and Google searches,

376
00:17:46,957 --> 00:17:49,363
which, in the United States,

377
00:17:49,363 --> 00:17:52,561
is a violation of the wiretapping statute,

378
00:17:52,561 --> 00:17:55,659
so, we think that Ethiopia should pay.

379
00:17:55,660 --> 00:17:57,264
MARQUIS-BOIRE: [chuckle] Yeah.

380
00:17:57,264 --> 00:17:59,659
GALPERIN: You will pay.

381
00:17:59,660 --> 00:18:02,396
And, finally, we do a lot of advocacy.

382
00:18:02,396 --> 00:18:04,428
We think that you're really not going to see

383
00:18:04,429 --> 00:18:08,396
any kind of policy change among companies or countries,

384
00:18:08,396 --> 00:18:09,956
or even among NGOs,

385
00:18:09,957 --> 00:18:12,759
unless people are aware of what a very serious

386
00:18:12,759 --> 00:18:15,429
and severe problem this is and what people can do about it.

387
00:18:15,429 --> 00:18:18,858
And, last of all, we do follow-up,

388
00:18:18,858 --> 00:18:22,099
which is to say that, when you are working

389
00:18:22,099 --> 00:18:24,297
with an activist or a human rights worker

390
00:18:24,297 --> 00:18:27,924
whose computer has been compromised,

391
00:18:27,924 --> 00:18:30,462
often, the security researchers show up

392
00:18:30,462 --> 00:18:33,231
and they say, "Well, I have my sample. Bye"

393
00:18:33,231 --> 00:18:35,561
and what the activists really want to know is

394
00:18:35,561 --> 00:18:38,066
"Is it safe to use my computer again?

395
00:18:38,066 --> 00:18:39,660
Like am I still being surveilled?

396
00:18:39,660 --> 00:18:41,297
What's up?"

397
00:18:41,297 --> 00:18:45,066
And, to this end, Morgan and I spent the last

398
00:18:45,066 --> 00:18:48,495
about year and a half to two years embarked on

399
00:18:48,495 --> 00:18:51,758
what we refer to as the "We Could Be Heroes" Tour.

400
00:18:51,759 --> 00:18:55,198
We have given a number of talks, including

401
00:18:55,198 --> 00:18:58,264
I have given a keynote at Recon in Montreal

402
00:18:58,264 --> 00:19:01,758
and at AusCERT in Brisbane,

403
00:19:01,759 --> 00:19:03,660
in which we reached out to the security community

404
00:19:03,660 --> 00:19:06,858
and we said, "This is the kind of work that we have been doing.

405
00:19:06,858 --> 00:19:11,066
You should come and do this work with us."

406
00:19:11,066 --> 00:19:15,957
This is an approach that has run into a few stumbling blocks.

407
00:19:15,957 --> 00:19:18,891
MARQUIS-BOIRE: Yeah.

408
00:19:18,891 --> 00:19:22,528
Probably the one that is the easiest to articulate is

409
00:19:22,528 --> 00:19:24,627
that there's obviously a lot of moving parts to this.

410
00:19:24,627 --> 00:19:29,825
A lot of these are nebulous, non-time-constrained,

411
00:19:29,825 --> 00:19:34,033
difficult to assign in the form of a ticket or a bug.

412
00:19:34,033 --> 00:19:35,759
The bit that's probably easiest

413
00:19:35,759 --> 00:19:38,429
to segment and compartmentalize is the malware analysis

414
00:19:38,429 --> 00:19:40,099
and, obviously, in some ways, that's the most satisfying

415
00:19:40,099 --> 00:19:41,890
'cause it actually means that you've done a whole bunch

416
00:19:41,891 --> 00:19:44,330
of this stuff, first.

417
00:19:44,330 --> 00:19:46,000
I've had, you know, various colleagues helping out

418
00:19:46,000 --> 00:19:47,627
with this type of thing

419
00:19:47,627 --> 00:19:50,825
and there's generally a lot of frustration at the sort of

420
00:19:50,825 --> 00:19:53,759
unbounded nature of doing this type of work.

421
00:19:53,759 --> 00:19:55,363
And so, yeah, we actually found out

422
00:19:55,363 --> 00:19:57,957
that like a lot of people wanted to help out,

423
00:19:57,957 --> 00:20:01,561
however, found that actually doing this type of work

424
00:20:01,561 --> 00:20:02,890
wasn't simply malware analysis,

425
00:20:02,891 --> 00:20:06,528
which is sort of what they signed up to do.

426
00:20:06,528 --> 00:20:09,429
Sorry, user interfaces are really hard.

427
00:20:09,429 --> 00:20:13,099
So, I mean, to that end, you know, one of the reasons

428
00:20:13,099 --> 00:20:15,264
why we've actually been doing this work

429
00:20:15,264 --> 00:20:17,890
is that, you know, as Alex pointed out,

430
00:20:17,891 --> 00:20:19,231
there's a lot of people at large companies

431
00:20:19,231 --> 00:20:21,165
that care a lot about this sort of thing.

432
00:20:21,165 --> 00:20:22,659
It's very difficult for them to do

433
00:20:22,660 --> 00:20:24,297
this type of work in-depth,

434
00:20:24,297 --> 00:20:27,132
partially because it's non-timebounded

435
00:20:27,132 --> 00:20:29,198
and, secondly, there's frequently sort of

436
00:20:29,198 --> 00:20:30,726
a conflict with corporate interests.

437
00:20:30,726 --> 00:20:32,429
For instance, I mean, if, for instance,

438
00:20:32,429 --> 00:20:36,297
you have corporate interests with the Vietnamese government,

439
00:20:36,297 --> 00:20:40,528
then actively assisting people that they view as having

440
00:20:40,528 --> 00:20:42,297
an adversarial position to their authority

441
00:20:42,297 --> 00:20:46,561
may not work out well, in a business sense.

442
00:20:46,561 --> 00:20:49,330
And so there's kind of a broad spectrum

443
00:20:49,330 --> 00:20:50,890
that large corporations generally use

444
00:20:50,891 --> 00:20:53,363
to try to protect all of their users.

445
00:20:53,363 --> 00:20:55,165
It's very difficult for them to really been seen

446
00:20:55,165 --> 00:20:57,197
to be focusing on protecting

447
00:20:57,198 --> 00:20:59,858
sort of small groups of at-risk people.

448
00:20:59,858 --> 00:21:02,330
There is an area of the security industry

449
00:21:02,330 --> 00:21:04,462
that is ostensibly very interested in this,

450
00:21:04,462 --> 00:21:07,000
which is, obviously, threat intelligence.

451
00:21:07,000 --> 00:21:11,165
And, I mean, threat intelligence companies care, and, again,

452
00:21:11,165 --> 00:21:13,264
for very similar reasons, about malware and not people.

453
00:21:13,264 --> 00:21:16,000
As Eva mentioned, you know,

454
00:21:16,000 --> 00:21:17,825
the Tibetan community is actually a great example.

455
00:21:17,825 --> 00:21:20,297
The Tibetan community is actually largely sick

456
00:21:20,297 --> 00:21:21,627
of the security community.

457
00:21:21,627 --> 00:21:23,858
'Cause the security community is very, very interested

458
00:21:23,858 --> 00:21:26,693
in their targeting by the Chinese,

459
00:21:26,693 --> 00:21:29,297
almost completely disinterested in them

460
00:21:29,297 --> 00:21:30,726
and what their struggle is,

461
00:21:30,726 --> 00:21:33,891
which leads to sort of an uneasy relationship

462
00:21:33,891 --> 00:21:36,264
between the sort of threat intelligence industry

463
00:21:36,264 --> 00:21:39,033
and, you know, the populations that are targeted.

464
00:21:41,198 --> 00:21:42,726
GALPERIN: So, let's talk a little bit about

465
00:21:42,726 --> 00:21:45,132
what is actually being done.

466
00:21:45,132 --> 00:21:48,594
The first thing is state-sponsored warnings.

467
00:21:48,594 --> 00:21:54,495
I believe Google, Facebook, Yahoo, Microsoft, and Twitter

468
00:21:54,495 --> 00:21:57,428
have all either currently implemented warnings

469
00:21:57,429 --> 00:22:00,792
which tell users when they think they have been the victims

470
00:22:00,792 --> 00:22:03,824
of state-sponsored hacking or have pledged

471
00:22:03,825 --> 00:22:07,033
that they will do so in the near future

472
00:22:07,033 --> 00:22:09,296
and we think that this is a very good idea.

473
00:22:09,297 --> 00:22:14,396
Second of all, sort of ubiquity of two-factor authentication.

474
00:22:14,396 --> 00:22:15,792
As we pointed out before,

475
00:22:15,792 --> 00:22:18,165
a lot of these attacks are phishing attacks

476
00:22:18,165 --> 00:22:22,297
and they are attacks on password credentials

477
00:22:22,297 --> 00:22:24,594
and you can do a lot to fix that simply

478
00:22:24,594 --> 00:22:27,495
by implementing two-factor on your service.

479
00:22:27,495 --> 00:22:30,593
And, third, we have seen a sort of rise

480
00:22:30,594 --> 00:22:33,033
in ubiquitous encryption,

481
00:22:33,033 --> 00:22:35,593
which has been discussed in many of these other talks,

482
00:22:35,594 --> 00:22:39,330
so, we have seen more and more companies

483
00:22:39,330 --> 00:22:43,462
going over to SSL by default for their services.

484
00:22:43,462 --> 00:22:45,297
We have seen a greater use and awareness

485
00:22:45,297 --> 00:22:48,627
of end-to-end encrypted communications

486
00:22:48,627 --> 00:22:54,297
like, you know, Jabber with OTR or Signal.

487
00:22:54,297 --> 00:22:55,891
And we think that's great,

488
00:22:55,891 --> 00:23:00,627
but it's also an approach that has some limitations.

489
00:23:00,627 --> 00:23:03,033
MARQUIS-BOIRE: Yeah, so, you know, don't get me wrong.

490
00:23:03,033 --> 00:23:06,792
I'm pro-encryption, before you bust out the pitchforks.

491
00:23:06,792 --> 00:23:11,264
But a lot of the security education narrative, you know,

492
00:23:11,264 --> 00:23:15,428
is like "How can I protect myself from surveillance?"

493
00:23:15,429 --> 00:23:18,627
"Well, you should use PGP tour and OTR."

494
00:23:18,627 --> 00:23:22,396
And that's great, unless you're actually targeted,

495
00:23:22,396 --> 00:23:25,132
because, you know, it doesn't matter if you receive a link

496
00:23:25,132 --> 00:23:27,660
to a watering hole via a PGP-encrypted e-mail.

497
00:23:27,660 --> 00:23:29,000
It's still a link to a watering hole

498
00:23:29,000 --> 00:23:30,495
that you're opening in your vulnerable browser,

499
00:23:30,495 --> 00:23:32,296
so you're still compromised, the malware's still

500
00:23:32,297 --> 00:23:34,066
on your machine, and you're still screwed,

501
00:23:34,066 --> 00:23:36,066
despite the fact that you have, you know,

502
00:23:36,066 --> 00:23:38,165
followed laborious command-line instructions

503
00:23:38,165 --> 00:23:41,561
on how to generate and use your PGP keys.

504
00:23:41,561 --> 00:23:44,099
And so, you know, this is actually a sort of a problem

505
00:23:44,099 --> 00:23:47,099
in how advice is given to targeted communities

506
00:23:47,099 --> 00:23:49,165
and, you know, especially 'cause a lot of people

507
00:23:49,165 --> 00:23:51,693
don't really know about computer security

508
00:23:51,693 --> 00:23:54,561
and so they think that this advice is going to protect them.

509
00:23:54,561 --> 00:23:57,890
How can I possibly have been compromised by a state actor?

510
00:23:57,891 --> 00:24:00,924
I use OTR all the time.

511
00:24:00,924 --> 00:24:02,627
And this sort of combination of suggesting

512
00:24:02,627 --> 00:24:04,890
that people use secure messaging

513
00:24:04,891 --> 00:24:07,033
in order to protect themselves from mass surveillance,

514
00:24:07,033 --> 00:24:10,099
in order to protect themselves from targeted surveillance,

515
00:24:10,099 --> 00:24:13,825
which is really sort of problematic advice.

516
00:24:13,825 --> 00:24:15,726
GALPERIN: And even people who we consider to be experts

517
00:24:15,726 --> 00:24:18,396
in the field sometimes fall into the sort of trap

518
00:24:18,396 --> 00:24:21,462
of mischaracterizations of threats.

519
00:24:21,462 --> 00:24:26,033
This is a tweet from the grugq, who is, I think, probably one

520
00:24:26,033 --> 00:24:29,561
of the most high-profile public thinkers

521
00:24:29,561 --> 00:24:32,659
about operational security for activists, journalists,

522
00:24:32,660 --> 00:24:35,891
and other people who piss off governments, and he says here,

523
00:24:35,891 --> 00:24:38,363
"'Most vulnerable' is not a very useful metric.

524
00:24:38,363 --> 00:24:40,726
If you aren't targeted, basic protections are sufficient."

525
00:24:40,726 --> 00:24:42,396
And in this area, we agree.

526
00:24:42,396 --> 00:24:45,528
But "If you are targeted, none are."

527
00:24:45,528 --> 00:24:48,792
And, in this area, I disagree very strongly,

528
00:24:48,792 --> 00:24:51,890
and that's primarily because the variety of work

529
00:24:51,891 --> 00:24:55,462
that Morgan and I have done has been on governments

530
00:24:55,462 --> 00:24:58,825
that have very different capabilities from, say,

531
00:24:58,825 --> 00:25:04,000
the Five Eyes or Israel or China or Russia.

532
00:25:04,000 --> 00:25:05,858
MARQUIS-BOIRE: Yeah, so,

533
00:25:05,858 --> 00:25:08,561
people frequently threat-model very poorly.

534
00:25:08,561 --> 00:25:10,462
Like what people are very worried about is what

535
00:25:10,462 --> 00:25:12,363
they hear about in the media and there's been a lot

536
00:25:12,363 --> 00:25:14,693
of discussion about the capabilities of, you know,

537
00:25:14,693 --> 00:25:17,594
primarily the NSA, also the Five Eyes, you know,

538
00:25:17,594 --> 00:25:20,330
over the last couple of years, which means that, you know,

539
00:25:20,330 --> 00:25:23,297
sort of when people worry about threats, themselves,

540
00:25:23,297 --> 00:25:25,957
they actually worry about specific capabilities

541
00:25:25,957 --> 00:25:30,000
that, you know, vastly resourced governments have,

542
00:25:30,000 --> 00:25:33,099
whereas, there's a lot of people that aren't being targeted

543
00:25:33,099 --> 00:25:36,396
specifically by the NSA, at all.

544
00:25:36,396 --> 00:25:39,561
I would describe on a range, you know, [chuckle]

545
00:25:39,561 --> 00:25:42,264
much like zero to Snowden, on a range of Syria to the NSA,

546
00:25:42,264 --> 00:25:43,824
there's a lot of governments whose capabilities

547
00:25:43,825 --> 00:25:45,759
are not particularly impressive

548
00:25:45,759 --> 00:25:53,264
and even the more capable governments actually field teams

549
00:25:53,264 --> 00:25:55,527
that operate at different levels of proficiency.

550
00:25:55,528 --> 00:25:58,231
Frequently, the types of teams that we see targeting

551
00:25:58,231 --> 00:26:01,099
journalists, activists, and human rights researchers,

552
00:26:01,099 --> 00:26:05,792
unsurprisingly, do not bust out zero-day and firmware implants

553
00:26:05,792 --> 00:26:07,824
because these people don't have security teams,

554
00:26:07,825 --> 00:26:09,462
so it's not necessary.

555
00:26:09,462 --> 00:26:11,956
Like why tip your hand and show, you know,

556
00:26:11,957 --> 00:26:15,099
advanced capability when you don't need to?

557
00:26:15,099 --> 00:26:17,528
Another thing that's worth keeping in mind is that,

558
00:26:17,528 --> 00:26:20,561
even advanced actors will throw their nets

559
00:26:20,561 --> 00:26:23,824
or sort of cast their nets broadly, when it comes

560
00:26:23,825 --> 00:26:27,396
to targets that are desirable, but not essential.

561
00:26:27,396 --> 00:26:30,231
You know, recently, we saw the Russian government

562
00:26:30,231 --> 00:26:34,132
targeting stacks of journalists and so you send out

563
00:26:34,132 --> 00:26:37,594
2,000 reasonably nondescript phishing attempts, you know.

564
00:26:37,594 --> 00:26:40,132
There is science to this. There is business.

565
00:26:40,132 --> 00:26:41,561
There is metrics. There are statistics.

566
00:26:41,561 --> 00:26:44,924
They may expect their return on this operation to be 0.5%,

567
00:26:44,924 --> 00:26:48,033
and that's actually okay.

568
00:26:48,033 --> 00:26:52,197
GALPERIN: So, speaking of Russia, what is to be done?

569
00:26:52,198 --> 00:26:54,693
Obviously, this is a very hard problem,

570
00:26:54,693 --> 00:26:57,330
but we think that it's really important to at least try

571
00:26:57,330 --> 00:26:59,693
to solve it because the stakes are very high.

572
00:26:59,693 --> 00:27:02,627
We are talking about users who are potentially being

573
00:27:02,627 --> 00:27:06,825
imprisoned, tortured, killed, jailed, beaten up.

574
00:27:06,825 --> 00:27:09,198
And what we have here are some suggestions

575
00:27:09,198 --> 00:27:11,495
and we're not under the weird delusion

576
00:27:11,495 --> 00:27:13,462
that this is gonna solve everything,

577
00:27:13,462 --> 00:27:17,198
but we do think that this stuff is worth implementing.

578
00:27:17,198 --> 00:27:19,627
Let's talk, first, about what industry can do.

579
00:27:19,627 --> 00:27:22,033
We would really like to see the antivirus industry

580
00:27:22,033 --> 00:27:23,659
implement state-sponsored warnings.

581
00:27:23,660 --> 00:27:26,957
This is the industry with the most insight

582
00:27:26,957 --> 00:27:30,132
into attackers and the people who are being attacked.

583
00:27:30,132 --> 00:27:34,297
And I understand that, you know,

584
00:27:34,297 --> 00:27:39,396
activists in Vietnam or Syria or journalists in Argentina

585
00:27:39,396 --> 00:27:41,561
are not people with fat stacks of cash

586
00:27:41,561 --> 00:27:45,428
and, therefore, they may not interest large corporations,

587
00:27:45,429 --> 00:27:47,429
but we think that these are the people

588
00:27:47,429 --> 00:27:49,759
who really are in a position to do something about it.

589
00:27:49,759 --> 00:27:52,396
The second thing we'd really like to see people do is,

590
00:27:52,396 --> 00:27:54,462
when they issue their state- sponsored warnings, we'd like

591
00:27:54,462 --> 00:27:57,165
to see those state-sponsored warnings be useful.

592
00:27:57,165 --> 00:27:58,792
Twitter recently sent out

593
00:27:58,792 --> 00:28:00,528
a bunch of state-sponsored warnings

594
00:28:00,528 --> 00:28:04,957
which gave some kind of interesting advice.

595
00:28:04,957 --> 00:28:06,759
It ended with the advice that one of the ways

596
00:28:06,759 --> 00:28:08,495
in which to mitigate the harm was

597
00:28:08,495 --> 00:28:10,561
to connect to Twitter using Tor.

598
00:28:10,561 --> 00:28:12,726
Now, I'm not entirely sure what sort of attack

599
00:28:12,726 --> 00:28:17,759
is mitigated in this fashion, but I would really like to see

600
00:28:17,759 --> 00:28:19,957
these warnings give useful advice

601
00:28:19,957 --> 00:28:22,495
that is clearly linked to the attack.

602
00:28:22,495 --> 00:28:25,296
This is not like a big dis on Twitter.

603
00:28:25,297 --> 00:28:27,363
I would like to see them continue to send out

604
00:28:27,363 --> 00:28:29,297
state-sponsored warnings; state-sponsored warnings

605
00:28:29,297 --> 00:28:33,330
are a good idea, just make sure they're also useful.

606
00:28:33,330 --> 00:28:34,792
MARQUIS-BOIRE: Yeah, and, you know, sort of

607
00:28:34,792 --> 00:28:36,462
on a more personal note, as, you know,

608
00:28:36,462 --> 00:28:38,429
a sort of a security researcher that's spent a lot of time

609
00:28:38,429 --> 00:28:40,891
doing this, I think it is actually great

610
00:28:40,891 --> 00:28:44,165
for people to volunteer their security expertise

611
00:28:44,165 --> 00:28:45,825
to help people that can't afford to pay

612
00:28:45,825 --> 00:28:48,561
a $500-an-hour consulting fee.

613
00:28:48,561 --> 00:28:51,659
You know, there were some hurdles

614
00:28:51,660 --> 00:28:53,000
that I've sort of experienced

615
00:28:53,000 --> 00:28:54,561
over the last few years of doing this.

616
00:28:54,561 --> 00:28:57,231
One that pained me personally was that, you know,

617
00:28:57,231 --> 00:29:00,165
when you volunteer to do this, you may not be recognized

618
00:29:00,165 --> 00:29:03,099
as the rock-star security engineer that you are,

619
00:29:03,099 --> 00:29:05,396
largely 'cause, you know, people don't realize

620
00:29:05,396 --> 00:29:06,726
that your time is very valuable.

621
00:29:06,726 --> 00:29:08,462
People don't realize what it is that you do;

622
00:29:08,462 --> 00:29:10,462
they're not gonna realize how long it takes you

623
00:29:10,462 --> 00:29:13,099
and they're probably not gonna understand the output

624
00:29:13,099 --> 00:29:15,131
of your work, which is full of IDA screenshots

625
00:29:15,132 --> 00:29:16,891
and an explanation of this sort of

626
00:29:16,891 --> 00:29:19,165
rolling XOR function with, you know, multiple templates,

627
00:29:19,165 --> 00:29:20,924
which actually makes this really difficult to unpack

628
00:29:20,924 --> 00:29:22,330
and I'm really smart for doing this.

629
00:29:22,330 --> 00:29:26,000
And they're like "That's... Okay. So, what do I do now?

630
00:29:26,000 --> 00:29:28,561
Can I get access to my iCloud account again?" Right?

631
00:29:28,561 --> 00:29:32,131
I mean, and that's actually what you're gonna have to

632
00:29:32,132 --> 00:29:33,561
come to terms with and so, you know,

633
00:29:33,561 --> 00:29:37,066
your time will be wasted; it will not be appreciated.

634
00:29:37,066 --> 00:29:38,594
Not always, but sometimes,

635
00:29:38,594 --> 00:29:41,495
and so it really helps if you actually sort of select

636
00:29:41,495 --> 00:29:44,527
people to help that you actually really care about.

637
00:29:44,528 --> 00:29:49,429
To this end, we recommend that you...

638
00:29:49,429 --> 00:29:50,561
GALPERIN: Go to RightsCon. -MARQUIS-BOIRE: Note I have not

639
00:29:50,561 --> 00:29:52,362
received any money from RightsCon.

640
00:29:52,363 --> 00:29:55,330
[ Both laugh ]

641
00:29:55,330 --> 00:29:56,759
GALPERIN: Go to RightsCon.

642
00:29:56,759 --> 00:29:59,231
RightsCon Silicon Valley will be taking place

643
00:29:59,231 --> 00:30:01,693
March 30th through April 1, 2016,

644
00:30:01,693 --> 00:30:04,528
here in beautiful San Francisco.

645
00:30:04,528 --> 00:30:06,759
If you're a security researcher who is interested

646
00:30:06,759 --> 00:30:08,825
in meeting NGOs and activists on the ground

647
00:30:08,825 --> 00:30:10,825
and you want to sort of, you know, give this all a try,

648
00:30:10,825 --> 00:30:12,495
this is a very good place to do it.

649
00:30:12,495 --> 00:30:16,165
This is also where Morgan and I hope to be giving a talk

650
00:30:16,165 --> 00:30:19,330
about the specific kind of operational security problems

651
00:30:19,330 --> 00:30:21,197
that NGOs have and what they could be doing

652
00:30:21,198 --> 00:30:23,561
in order to really up their game.

653
00:30:23,561 --> 00:30:25,362
Thank you very much.

654
00:30:25,363 --> 00:30:29,594
[ Applause ]

655
00:30:29,594 --> 00:30:32,231
♪♪

656
00:30:35,132 --> 00:30:34,132


