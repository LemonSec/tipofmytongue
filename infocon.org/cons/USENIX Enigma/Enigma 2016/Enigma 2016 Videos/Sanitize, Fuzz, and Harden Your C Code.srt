1
00:00:00,033 --> 00:00:06,165


2
00:00:06,165 --> 00:00:08,957
SEREBRYANY: I'm indeed
Kostya Serebryany from Google.

3
00:00:08,957 --> 00:00:11,495
My team is called
Dynamic Testing Tools,

4
00:00:11,495 --> 00:00:13,495
and we're not the security guys.

5
00:00:13,495 --> 00:00:14,693
We're the compiler guys.

6
00:00:14,693 --> 00:00:18,528
We're doing the tools
for the security guys.

7
00:00:21,528 --> 00:00:24,791
Interesting thing up there.

8
00:00:24,792 --> 00:00:28,726
Today I will tell you
about three related things.

9
00:00:28,726 --> 00:00:32,396
First, you'll know about
so-called Sanitizers

10
00:00:32,396 --> 00:00:35,726
for dynamic analysis tools
for C++ code.

11
00:00:35,726 --> 00:00:37,263
Second, I will tell you

12
00:00:37,264 --> 00:00:40,330
about the fuzzing tools
we developed and we used.

13
00:00:40,330 --> 00:00:42,528
And last but not least,

14
00:00:42,528 --> 00:00:44,561
I will mention
hardening techniques

15
00:00:44,561 --> 00:00:47,924
that we developed
at Google for C++.

16
00:00:47,924 --> 00:00:51,429
My hope is
that many of you will start

17
00:00:51,429 --> 00:00:54,264
using these tools first
thing tomorrow morning

18
00:00:54,264 --> 00:00:55,957
when you get to your desktop.

19
00:00:59,033 --> 00:01:02,462
I joined Google about
eight and a half years ago,

20
00:01:02,462 --> 00:01:05,495
and soon after that,
we started using

21
00:01:05,495 --> 00:01:09,066
and deploying
Valgrind dynamic analysis tool

22
00:01:09,066 --> 00:01:12,231
on our C++ code base,
which at that time was already

23
00:01:12,231 --> 00:01:14,857
many tens of millions
of lines of code.

24
00:01:14,858 --> 00:01:18,594
By the way, how many of you
have heard about Valgrind?

25
00:01:18,594 --> 00:01:20,396
Good, good.

26
00:01:20,396 --> 00:01:22,726
So, Valgrind is based
on binary translation,

27
00:01:22,726 --> 00:01:27,198
and it's one of the weaknesses
of this tool.

28
00:01:27,198 --> 00:01:28,791
Still, we found lots of bugs,

29
00:01:28,792 --> 00:01:32,363
like many hundreds of bugs,
maybe even thousands.

30
00:01:32,363 --> 00:01:34,693
But the weakness of the tool,

31
00:01:34,693 --> 00:01:37,429
which has a huge CPU overhead,

32
00:01:37,429 --> 00:01:40,099
did not allow us to move
to a station

33
00:01:40,099 --> 00:01:42,198
where we would like
to see ourself,

34
00:01:42,198 --> 00:01:45,330
which is other developers
using the tools

35
00:01:45,330 --> 00:01:48,396
on their tests
without our intervention.

36
00:01:48,396 --> 00:01:49,891
We tried hard.

37
00:01:49,891 --> 00:01:51,594
We found lots
of interesting bugs.

38
00:01:51,594 --> 00:01:54,000
The developers
were happy to fix them.

39
00:01:54,000 --> 00:01:58,693
But they were not eager
to use the tools themselves.

40
00:01:58,693 --> 00:02:03,660
The reason -- just one --
too slow.

41
00:02:03,660 --> 00:02:07,890
So, after four years
of trying to deploy Valgrind,

42
00:02:07,891 --> 00:02:10,000
why then it was deployed?

43
00:02:10,000 --> 00:02:12,231
We started developing
our own tools,

44
00:02:12,231 --> 00:02:14,165
and the family
of tools we developed

45
00:02:14,165 --> 00:02:16,660
were called the Sanitizers.

46
00:02:16,660 --> 00:02:18,726
How many of you have heard
about the Sanitizers

47
00:02:18,726 --> 00:02:20,726
in the C++ context?

48
00:02:20,726 --> 00:02:23,693
That's too few. So, I hope --

49
00:02:23,693 --> 00:02:26,000
How many here have heard
about them now?

50
00:02:26,000 --> 00:02:28,528
[ Laughter ]

51
00:02:28,528 --> 00:02:30,363
Good.

52
00:02:30,363 --> 00:02:32,198
By the time
we started the Sanitizers,

53
00:02:32,198 --> 00:02:35,132
we already have
over 100 millions of lines --

54
00:02:35,132 --> 00:02:38,957
well, a 100 million
of lines of C++ code.

55
00:02:38,957 --> 00:02:43,297
The new tools are based
on compiled instrumentation.

56
00:02:43,297 --> 00:02:45,825
And today most of these tools

57
00:02:45,825 --> 00:02:49,462
are available in the two major
open-source compilers --

58
00:02:49,462 --> 00:02:52,131
LLVM and GCC.

59
00:02:52,132 --> 00:02:53,891
There are four major tools.

60
00:02:53,891 --> 00:02:57,297
"ASan" stands
for "Address Sanitizer."

61
00:02:57,297 --> 00:02:59,099
It detects things
like use-after-free,

62
00:02:59,099 --> 00:03:01,000
buffer overflows,
memory leaks,

63
00:03:01,000 --> 00:03:03,858
and all the traditional
suspects.

64
00:03:03,858 --> 00:03:07,264
TSAN, Thread Sanitizer,
finds concurrency bugs,

65
00:03:07,264 --> 00:03:11,000
which mostly means data races
and deadlocks.

66
00:03:11,000 --> 00:03:13,231
The third tool --
Memory Sanitizer --

67
00:03:13,231 --> 00:03:15,033
finds a single type
of bug today,

68
00:03:15,033 --> 00:03:18,791
which is users
of uninitialized memory.

69
00:03:18,792 --> 00:03:21,132
And last but not least, UBSan.

70
00:03:21,132 --> 00:03:23,528
U.B. stands for
"undefined behavior,"

71
00:03:23,528 --> 00:03:26,923
and it finds that, more or less

72
00:03:26,924 --> 00:03:28,924
all kinds
of other undefined behavior

73
00:03:28,924 --> 00:03:32,198
in C and C++.

74
00:03:32,198 --> 00:03:37,891
Let me give you just one example
of just one of these tools.

75
00:03:37,891 --> 00:03:41,594
The C++ example on this slide

76
00:03:41,594 --> 00:03:46,363
is the simplest I could come up
with for use-after-free bug.

77
00:03:46,363 --> 00:03:48,792
Probably most of you are
familiar with this kind of bug.

78
00:03:48,792 --> 00:03:51,198
You allocate memory,
then you de-allocate memory,

79
00:03:51,198 --> 00:03:57,066
and then you continue using
this memory for some purposes.

80
00:03:57,066 --> 00:03:59,429
If you want to find this bug
with Address Sanitizer,

81
00:03:59,429 --> 00:04:01,132
all you need

82
00:04:01,132 --> 00:04:05,792
is to compile the application
with a single, special switch.

83
00:04:05,792 --> 00:04:08,891
And again, this switch
is available in modern Clang

84
00:04:08,891 --> 00:04:12,066
and in modern GCC.

85
00:04:12,066 --> 00:04:13,627
If the bug happens
at run time --

86
00:04:13,627 --> 00:04:15,198
and this is a dynamic tool --

87
00:04:15,198 --> 00:04:19,891
it actually needs the bug
to happen at run time --

88
00:04:19,891 --> 00:04:24,066
the application will print
a lot of descriptive text,

89
00:04:24,066 --> 00:04:26,659
saying what kind
of bug happened,

90
00:04:26,660 --> 00:04:28,924
what is the address,

91
00:04:28,924 --> 00:04:31,032
what is the stack trace
of the bug,

92
00:04:31,033 --> 00:04:34,132
what is the stack trace
of allocation, de-allocation,

93
00:04:34,132 --> 00:04:36,429
et cetera.

94
00:04:36,429 --> 00:04:41,032
And after that,
it will immediately trap.

95
00:04:41,033 --> 00:04:43,495
The Sanitizers are fast.

96
00:04:43,495 --> 00:04:44,825
For most of these tools,

97
00:04:44,825 --> 00:04:46,825
the typical slowdown
is about 2x,

98
00:04:46,825 --> 00:04:49,066
compared to the Valgrind 20x.

99
00:04:49,066 --> 00:04:54,330
So, we were able to run
almost all of the unit tests

100
00:04:54,330 --> 00:04:59,825
on our huge code base
with the Sanitizers.

101
00:04:59,825 --> 00:05:01,957
Little bit more details
about the Chromium,

102
00:05:01,957 --> 00:05:03,858
which is an open-source project

103
00:05:03,858 --> 00:05:07,132
on which the Google Chrome
browser is based.

104
00:05:07,132 --> 00:05:11,396
Chromium is about
10 millions of lines of C++

105
00:05:11,396 --> 00:05:14,693
and a little bit of C code.

106
00:05:14,693 --> 00:05:16,395
And the unit tests

107
00:05:16,396 --> 00:05:20,561
are a very important part
of this source base.

108
00:05:20,561 --> 00:05:23,561
We have unit tests
for every single bit

109
00:05:23,561 --> 00:05:25,263
of our own code base,

110
00:05:25,264 --> 00:05:27,726
not necessarily for third-party
libraries that we're using,

111
00:05:27,726 --> 00:05:30,792
but at least
for our own code base.

112
00:05:30,792 --> 00:05:32,594
And with the Sanitizer,

113
00:05:32,594 --> 00:05:35,693
we were able to run
all of the unit tests

114
00:05:35,693 --> 00:05:38,164
for almost every commit,

115
00:05:38,165 --> 00:05:40,726
and we have multiple commits
every day.

116
00:05:40,726 --> 00:05:45,561
It means that if we find a bug,
a new regression,

117
00:05:45,561 --> 00:05:48,132
we can report it, revert it,

118
00:05:48,132 --> 00:05:50,231
or fix it within a few hours,

119
00:05:50,231 --> 00:05:54,462
not within a few days
or weeks as we had before.

120
00:05:54,462 --> 00:05:58,296
So, we found hundreds
of bugs this way,

121
00:05:58,297 --> 00:06:01,528
both old bugs
that were there for years

122
00:06:01,528 --> 00:06:05,627
and regressions.

123
00:06:05,627 --> 00:06:08,759
But the test coverage
is never perfect.

124
00:06:08,759 --> 00:06:10,528
It is actually
usually quite bad,

125
00:06:10,528 --> 00:06:14,594
but if you think about targets

126
00:06:14,594 --> 00:06:18,099
that the bad guys would look at,

127
00:06:18,099 --> 00:06:22,693
I would say that test coverage
is very poor almost always.

128
00:06:22,693 --> 00:06:25,462
So, the bugs
still slip into production,

129
00:06:25,462 --> 00:06:28,099
and this brings me
to the second part

130
00:06:28,099 --> 00:06:32,099
of my talk about fuzzing.

131
00:06:32,099 --> 00:06:34,495
Several people
mentioned fuzzing already,

132
00:06:34,495 --> 00:06:36,264
and this talk is too small

133
00:06:36,264 --> 00:06:38,363
to explain fuzzing
in more detail,

134
00:06:38,363 --> 00:06:42,000
but I will try to do it
in one sentence.

135
00:06:42,000 --> 00:06:46,000
Fuzzing is a huge family
of different techniques

136
00:06:46,000 --> 00:06:48,033
which have the same goal.

137
00:06:48,033 --> 00:06:52,429
We need to generate
lots of test inputs

138
00:06:52,429 --> 00:06:55,429
for the application,
for the API, and the test,

139
00:06:55,429 --> 00:06:57,527
with the goal

140
00:06:57,528 --> 00:06:59,726
to increase the code coverage

141
00:06:59,726 --> 00:07:03,561
and in the hope to make
the code misbehave.

142
00:07:03,561 --> 00:07:06,296
And if you make the code
misbehave, you found a bug.

143
00:07:06,297 --> 00:07:09,594
You reached your final goal.

144
00:07:09,594 --> 00:07:13,627
And if you want to find this
misbehavior more efficiently,

145
00:07:13,627 --> 00:07:14,924
it's a good idea

146
00:07:14,924 --> 00:07:18,626
to couple fuzzing
and one of the Sanitizers.

147
00:07:20,726 --> 00:07:22,825
At Google, there are
several teams that develop

148
00:07:22,825 --> 00:07:26,132
and use several
different frameworks

149
00:07:26,132 --> 00:07:28,264
or pieces of infrastructure

150
00:07:28,264 --> 00:07:31,528
that run many hundreds

151
00:07:31,528 --> 00:07:36,363
of fuzzers...

152
00:07:36,363 --> 00:07:38,396
several thousands of CPU cores

153
00:07:38,396 --> 00:07:41,627
fuzzing something every minute.

154
00:07:41,627 --> 00:07:43,495
And with fuzzing,

155
00:07:43,495 --> 00:07:47,033
we found at least
an order of magnitude more bugs

156
00:07:47,033 --> 00:07:48,627
than with the unit tests,

157
00:07:48,627 --> 00:07:51,363
maybe actually
two orders of magnitude.

158
00:07:51,363 --> 00:07:56,924
In Chromium alone,
we found at least 5,000 bugs,

159
00:07:56,924 --> 00:07:58,495
maybe more.

160
00:07:58,495 --> 00:08:02,792
And in FFMpeg package
of video codecs,

161
00:08:02,792 --> 00:08:06,395
we found more than 1,000 bugs.

162
00:08:06,396 --> 00:08:07,759
But I want to dive deeper

163
00:08:07,759 --> 00:08:10,891
into one specific fuzzing tool,

164
00:08:10,891 --> 00:08:12,495
which my team developed.

165
00:08:12,495 --> 00:08:14,396
The tool is called libFuzzer,

166
00:08:14,396 --> 00:08:17,495
and it performs guided
fuzzing for other libraries

167
00:08:17,495 --> 00:08:20,495
or for APIs.

168
00:08:20,495 --> 00:08:23,198
And this slide
explains how to use this tool.

169
00:08:23,198 --> 00:08:25,561
So, first of all,
if you're testing something,

170
00:08:25,561 --> 00:08:28,462
come up
with an initial test suite

171
00:08:28,462 --> 00:08:30,659
for the thing you are testing.

172
00:08:30,660 --> 00:08:33,825
In some cases, this initial
test corpus could be empty,

173
00:08:33,825 --> 00:08:36,099
but the more inputs you provide,

174
00:08:36,099 --> 00:08:38,726
the easier it will be
for the fuzzer.

175
00:08:38,726 --> 00:08:41,957
The next step is to implement
what we call a target function.

176
00:08:41,957 --> 00:08:44,363
Target function
is a simple C function

177
00:08:44,363 --> 00:08:47,726
that takes an area of bytes
as a parameter

178
00:08:47,726 --> 00:08:50,792
and does something interesting
with these bytes,

179
00:08:50,792 --> 00:08:55,858
parsing some data format,
for example.

180
00:08:55,858 --> 00:08:59,098
The next step is to build
your library or API

181
00:08:59,099 --> 00:09:02,396
and the target function
with a special compiler switch.

182
00:09:02,396 --> 00:09:04,462
Today it's available
only in LLVM.

183
00:09:04,462 --> 00:09:08,000
I hope we'll see it in GCC
at some point.

184
00:09:08,000 --> 00:09:09,924
You may also --
And you're encouraged also

185
00:09:09,924 --> 00:09:13,066
to add one of the Sanitizers
to get better results,

186
00:09:13,066 --> 00:09:18,165
to find bugs quickly
and with more detail.

187
00:09:18,165 --> 00:09:21,726
And then you just run this
application on multiple CPUs.

188
00:09:21,726 --> 00:09:23,198
The test corpus will grow.

189
00:09:23,198 --> 00:09:25,165
The test units
will be written back on disk,

190
00:09:25,165 --> 00:09:29,528
so you will have more
test inputs as the fuzzer runs.

191
00:09:29,528 --> 00:09:33,132
The bugs
will be reported to STDR,

192
00:09:33,132 --> 00:09:35,593
and the reproducer inputs
that trigger bugs

193
00:09:35,594 --> 00:09:38,891
will be also written on disk.

194
00:09:38,891 --> 00:09:40,858
Let me show you an example.

195
00:09:40,858 --> 00:09:44,593
FreeType library
is font-rendering library

196
00:09:44,594 --> 00:09:48,066
that is used
on every Android phone,

197
00:09:48,066 --> 00:09:49,594
that is used by Chromium,

198
00:09:49,594 --> 00:09:52,363
and in many other applications.

199
00:09:52,363 --> 00:09:57,297
And this target function
calls the FreeType API

200
00:09:57,297 --> 00:10:02,264
that opens a font in memory
and parses it.

201
00:10:02,264 --> 00:10:06,099
That's it --
five lines of code.

202
00:10:06,099 --> 00:10:07,957
Even though the target function
is very simple,

203
00:10:07,957 --> 00:10:10,297
we were able to find

204
00:10:10,297 --> 00:10:13,033
several dozens of bugs
in FreeType.

205
00:10:13,033 --> 00:10:15,462
Some of the bugs
are just stability bugs,

206
00:10:15,462 --> 00:10:21,858
but several may have
security implications,

207
00:10:21,858 --> 00:10:24,593
like buffer overflows,

208
00:10:24,594 --> 00:10:25,957
signed integer overflows,

209
00:10:25,957 --> 00:10:30,627
or...

210
00:10:30,627 --> 00:10:34,296
Well, leaks may lead --

211
00:10:34,297 --> 00:10:36,891
Memory leaks typically are not
considered as security bugs,

212
00:10:36,891 --> 00:10:41,132
but they are because
they can lead to DOS attacks.

213
00:10:41,132 --> 00:10:44,231
Let me show you something
even more relevant

214
00:10:44,231 --> 00:10:46,660
for a security conference.

215
00:10:46,660 --> 00:10:50,824
This is a target function
for OpenSSL.

216
00:10:50,825 --> 00:10:54,330
We have a little bit more code
here, but it's all boilerplate.

217
00:10:54,330 --> 00:10:56,033
If you know how OpenSSL works,

218
00:10:56,033 --> 00:11:00,165
you can write it
with closed eyes.

219
00:11:00,165 --> 00:11:01,627
And in this target function,

220
00:11:01,627 --> 00:11:05,891
we're testing a single
API function of OpenSSL,

221
00:11:05,891 --> 00:11:08,000
not the entire OpenSSL.

222
00:11:08,000 --> 00:11:12,759
Does this function
ring a bell to anyone?

223
00:11:12,759 --> 00:11:14,726
Come on. Anyone?

224
00:11:16,726 --> 00:11:19,825
So, this is the functional way

225
00:11:19,825 --> 00:11:23,297
the Heartbleed Bug was found
a couple of years ago.

226
00:11:23,297 --> 00:11:24,759
How many of you believe me

227
00:11:24,759 --> 00:11:27,033
that I can find
Heartbleed from scratch

228
00:11:27,033 --> 00:11:28,891
before the end of this talk?

229
00:11:34,330 --> 00:11:37,759
So...

230
00:11:37,759 --> 00:11:40,495
I'm running the fuzzer
without any initial corpus.

231
00:11:40,495 --> 00:11:42,594
It knows nothing about OpenSSL.

232
00:11:42,594 --> 00:11:45,924
It has no clue
about the data format.

233
00:11:45,924 --> 00:11:49,891
All it does -- it tries to
put some random bytes,

234
00:11:49,891 --> 00:11:54,329
mutate the existing tests.

235
00:11:54,330 --> 00:11:56,726
And if the mutation is good,

236
00:11:56,726 --> 00:11:59,165
based on the feedback
we get from the compiler,

237
00:11:59,165 --> 00:12:02,296
we add this mutation
back to the corpus.

238
00:12:02,297 --> 00:12:05,297
I haven't finished
talking about this

239
00:12:05,297 --> 00:12:07,957
when the fuzzer, coupled
with Address Sanitizer,

240
00:12:07,957 --> 00:12:09,231
found the bug.

241
00:12:09,231 --> 00:12:11,627
So, it is
a heap buffer overflow,

242
00:12:11,627 --> 00:12:13,627
as you can see on the screen.

243
00:12:16,132 --> 00:12:21,627
We were reading 43,000 bytes
out from somewhere.

244
00:12:21,627 --> 00:12:24,957
And the second frame
in the stack

245
00:12:24,957 --> 00:12:27,561
is something
"process heartbeat."

246
00:12:27,561 --> 00:12:28,792
I have no clue what it is.

247
00:12:28,792 --> 00:12:31,429
I am not an OpenSSL expert.

248
00:12:31,429 --> 00:12:33,824
But it sounds like "Heartbleed."

249
00:12:38,297 --> 00:12:40,891
Some of you may tell me,
"Hey, that's old news.

250
00:12:40,891 --> 00:12:43,726
Of course Heartbleed
was found with fuzzing."

251
00:12:43,726 --> 00:12:45,495
We all know this.

252
00:12:45,495 --> 00:12:47,495
That's not my point.

253
00:12:47,495 --> 00:12:51,165
My point is that it is nowadays

254
00:12:51,165 --> 00:12:54,660
so simple to make a fuzzer
for OpenSSL,

255
00:12:54,660 --> 00:12:58,065
and it will find
this bug so fast.

256
00:12:58,066 --> 00:13:02,033
You've seen --
a few seconds on this laptop.

257
00:13:02,033 --> 00:13:06,561
So, there is no reason
not to use fuzzing.

258
00:13:06,561 --> 00:13:10,066
This is a screenshot
of code search

259
00:13:10,066 --> 00:13:14,231
of the Chromium Project,
all public, all open-source.

260
00:13:14,231 --> 00:13:17,561
And we're trying to add fuzzers

261
00:13:17,561 --> 00:13:20,528
for every interesting API
that Chromium uses.

262
00:13:20,528 --> 00:13:25,033
That includes
the Chromium proper APIs

263
00:13:25,033 --> 00:13:30,924
and the APIs from third parties
that Chromium uses.

264
00:13:30,924 --> 00:13:34,165
We've made libFuzzer very simple
to use for everyone,

265
00:13:34,165 --> 00:13:36,000
and we're trying to
make it super easy

266
00:13:36,000 --> 00:13:37,264
for the Chromium developers

267
00:13:37,264 --> 00:13:41,792
and for other developers
at Google, as well.

268
00:13:41,792 --> 00:13:43,924
I believe that fuzzing --

269
00:13:43,924 --> 00:13:47,462
not just libFuzzer,
but fuzzing as a technique --

270
00:13:47,462 --> 00:13:53,759
should become a key feature
of everyone's testing process,

271
00:13:53,759 --> 00:13:57,528
just like unit tests are today.

272
00:13:57,528 --> 00:13:59,495
But fuzzing is not enough,

273
00:13:59,495 --> 00:14:02,264
and we know it at least
because of two things.

274
00:14:02,264 --> 00:14:05,528
First, every time
we add a new fuzzer

275
00:14:05,528 --> 00:14:08,099
to our testing process,
we find new bugs.

276
00:14:08,099 --> 00:14:12,858
It means that the existing
fuzzers are not enough.

277
00:14:12,858 --> 00:14:18,263
But we also
sometimes learn about bugs

278
00:14:18,264 --> 00:14:21,297
that actually slipped
into production.

279
00:14:21,297 --> 00:14:25,264
And sometimes we know about it
in bad ways.

280
00:14:25,264 --> 00:14:27,231
This leads me to
the last part of my talk,

281
00:14:27,231 --> 00:14:30,528
which is about code hardening.

282
00:14:30,528 --> 00:14:33,264
I will describe two threats

283
00:14:33,264 --> 00:14:36,561
and two mitigations
for these threats.

284
00:14:36,561 --> 00:14:39,099
Threat number one
is traditional --

285
00:14:39,099 --> 00:14:40,594
memory corruption --

286
00:14:40,594 --> 00:14:42,627
when the bad guys

287
00:14:42,627 --> 00:14:44,165
override your function pointer

288
00:14:44,165 --> 00:14:50,329
or virtual pointer
with something they control.

289
00:14:50,330 --> 00:14:52,660
This is not
a theoretical problem.

290
00:14:52,660 --> 00:14:56,759
We've seen it in the wild
many times.

291
00:14:56,759 --> 00:15:02,891
This is an oversimplified
example of the bug in question.

292
00:15:02,891 --> 00:15:04,891
Suppose
you have a buffer somewhere

293
00:15:04,891 --> 00:15:07,264
which is followed
by a function pointer.

294
00:15:09,594 --> 00:15:12,363
And if your code
has a buffer overflow,

295
00:15:12,363 --> 00:15:13,891
where there is a chance

296
00:15:13,891 --> 00:15:16,627
that the function pointer
will be overwritten

297
00:15:16,627 --> 00:15:18,660
with a pointer
to some bad code --

298
00:15:18,660 --> 00:15:20,033
it doesn't have
to be bad code.

299
00:15:20,033 --> 00:15:21,594
It's just the code
that the attacker

300
00:15:21,594 --> 00:15:26,297
can use for their purposes.

301
00:15:26,297 --> 00:15:29,363
If you build the application
in the regular way,

302
00:15:29,363 --> 00:15:31,495
the bad code
will actually be executed,

303
00:15:31,495 --> 00:15:34,759
if the attacker is skilled.

304
00:15:34,759 --> 00:15:37,330
If you add a couple
of compiler switches

305
00:15:37,330 --> 00:15:39,099
to build the application --

306
00:15:39,099 --> 00:15:43,000
the key one is
fsanitize equals the CFI --

307
00:15:43,000 --> 00:15:46,099
"CFI" stands
for "control-flow integrity" --

308
00:15:46,099 --> 00:15:49,066
your application
will immediately trap

309
00:15:49,066 --> 00:15:53,825
while attempting to execute
this incorrect address.

310
00:15:53,825 --> 00:15:56,363
There is also a diagnostic mode

311
00:15:56,363 --> 00:15:57,627
in this compiler feature

312
00:15:57,627 --> 00:15:59,231
which will not trap immediately,

313
00:15:59,231 --> 00:16:01,198
but will give you
a detailed explanation

314
00:16:01,198 --> 00:16:04,363
of what has happened.

315
00:16:04,363 --> 00:16:07,033
How does this work, in short?

316
00:16:07,033 --> 00:16:10,264
The compiler statically
computes the exact set

317
00:16:10,264 --> 00:16:13,957
of targets that are allowed

318
00:16:13,957 --> 00:16:18,000
for every given call site.

319
00:16:18,000 --> 00:16:21,627
Today this requires so-called
link-time optimization,

320
00:16:21,627 --> 00:16:25,396
which means that the compiler

321
00:16:25,396 --> 00:16:28,693
sees the entire application
as a whole,

322
00:16:28,693 --> 00:16:33,561
as if we were compiling it
as a single C++ file.

323
00:16:33,561 --> 00:16:36,462
And once we have computed
this allowed check,

324
00:16:36,462 --> 00:16:41,593
we insert
a constant-time checking code

325
00:16:41,594 --> 00:16:44,231
before every call site.

326
00:16:44,231 --> 00:16:47,297
So, the concept
of CFI and the way

327
00:16:47,297 --> 00:16:50,033
of doing this has been
known for a while,

328
00:16:50,033 --> 00:16:52,297
but what we have achieved

329
00:16:52,297 --> 00:16:54,957
is the speed of this check.

330
00:16:54,957 --> 00:16:56,297
Our check requires,

331
00:16:56,297 --> 00:17:00,957
at most, single-memory load
per indirect call

332
00:17:00,957 --> 00:17:02,792
or sometimes not at all.

333
00:17:05,000 --> 00:17:08,098
The second threat
is also quite popular --

334
00:17:08,098 --> 00:17:09,693
a stack-buffer-overflow

335
00:17:09,693 --> 00:17:14,263
overwriting a return address
on the stack,

336
00:17:14,263 --> 00:17:17,000
again by something
that the bad guys control.

337
00:17:17,000 --> 00:17:18,528
And again,
this is not theoretical.

338
00:17:18,528 --> 00:17:22,924
We've seen it in a few cases.

339
00:17:22,924 --> 00:17:25,363
This kind of mitigation
is even simpler.

340
00:17:27,924 --> 00:17:30,561
And so the example
is even simpler.

341
00:17:30,561 --> 00:17:34,462
Suppose we have
a buffer on stack...

342
00:17:34,462 --> 00:17:36,660
and there is an overflow

343
00:17:36,660 --> 00:17:41,726
that may corrupt data
behind the buffer.

344
00:17:41,726 --> 00:17:43,561
And so it happens that,

345
00:17:43,561 --> 00:17:45,396
if you computer
the offset correctly,

346
00:17:45,396 --> 00:17:47,197
you will corrupt
the return address.

347
00:17:47,198 --> 00:17:50,594
And instead of returning
to the caller,

348
00:17:50,594 --> 00:17:52,099
you will execute the code

349
00:17:52,099 --> 00:17:54,297
that the bad guys
want you to execute.

350
00:17:54,297 --> 00:17:56,957
So, if you compile in the
regular way, this will happen.

351
00:17:56,957 --> 00:18:01,264
If you compile with fsanitize
SafeStack, nothing will happen.

352
00:18:01,264 --> 00:18:03,231
So, is it good or bad?

353
00:18:03,231 --> 00:18:06,924
It is better than allowing
the bad guys

354
00:18:06,924 --> 00:18:08,197
to execute their code.

355
00:18:08,198 --> 00:18:11,165
We do not detect the bug,

356
00:18:11,165 --> 00:18:13,363
but we do not allow the exploit.

357
00:18:15,924 --> 00:18:17,297
How does this work?

358
00:18:17,297 --> 00:18:19,891
SafeStack
uses a well-known concept

359
00:18:19,891 --> 00:18:21,330
of shadow stack,

360
00:18:21,330 --> 00:18:24,792
which is a separate memory
region of the same size

361
00:18:24,792 --> 00:18:28,231
as the original stack
of every thread.

362
00:18:28,231 --> 00:18:32,396
At compile time,
we place all local variables

363
00:18:32,396 --> 00:18:35,825
that are potentially targets
for buffer overflows

364
00:18:35,825 --> 00:18:38,132
on this shadow stack.

365
00:18:38,132 --> 00:18:40,561
And if a buffer overflow
happens,

366
00:18:40,561 --> 00:18:42,131
some data is corrupt somewhere,

367
00:18:42,132 --> 00:18:44,297
but there is no chance

368
00:18:44,297 --> 00:18:48,396
the return address
will be affected.

369
00:18:48,396 --> 00:18:49,759
This technique
could be combined --

370
00:18:49,759 --> 00:18:51,726
'cause remember,
it was stack cookies

371
00:18:51,726 --> 00:18:55,099
that have been mentioned
on this conference a few times,

372
00:18:55,099 --> 00:18:58,693
although, frankly,
I don't see any reason for this.

373
00:19:01,132 --> 00:19:03,033
Both mitigation techniques
I have mentioned

374
00:19:03,033 --> 00:19:05,890
are not exactly free.

375
00:19:05,891 --> 00:19:09,396
Each of them incurs
1% or 2% CPU overhead

376
00:19:09,396 --> 00:19:12,066
and even greater code size.

377
00:19:12,066 --> 00:19:13,957
But if you are --

378
00:19:13,957 --> 00:19:16,792
if you have an application
that is security-sensitive,

379
00:19:16,792 --> 00:19:20,824
this is a good price to pay.

380
00:19:20,825 --> 00:19:23,561
To summarize my talk --

381
00:19:23,561 --> 00:19:25,792
and as many
mentioned here already --

382
00:19:25,792 --> 00:19:30,065
security could be
either in-depth or none at all.

383
00:19:30,066 --> 00:19:32,363
And if you want to
get some security,

384
00:19:32,363 --> 00:19:35,957
you should be using
the Sanitizers, fuzzers,

385
00:19:35,957 --> 00:19:37,660
and code-hardening techniques,

386
00:19:37,660 --> 00:19:41,396
and everything else, of course,
as well.

387
00:19:41,396 --> 00:19:44,659
And a slide
with index minus one.

388
00:19:44,660 --> 00:19:47,264
We also have all these tools
for the Linux kernel,

389
00:19:47,264 --> 00:19:48,858
not just for the user space.

390
00:19:48,858 --> 00:19:50,428
And this is a subs--

391
00:19:50,429 --> 00:19:52,627
You cannot really see it here.

392
00:19:52,627 --> 00:19:55,000
It is a subset of bugs
in the Linux kernel

393
00:19:55,000 --> 00:19:57,528
we found during
the last three months.

394
00:19:57,528 --> 00:20:00,660
As you maybe can see,
use-after-free

395
00:20:00,660 --> 00:20:05,858
is a quite popular feature
of the Linux kernel.

396
00:20:05,858 --> 00:20:08,825
All of the tools I discussed
are open-source and public,

397
00:20:08,825 --> 00:20:11,033
and the documentation
is available online.

398
00:20:11,033 --> 00:20:12,627
Thank you.

399
00:20:12,627 --> 00:20:15,627
[ Applause ]

400
00:20:15,627 --> 00:20:14,627


