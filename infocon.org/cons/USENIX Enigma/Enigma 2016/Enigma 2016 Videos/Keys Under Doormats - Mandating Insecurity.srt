1
00:00:00,198 --> 00:00:06,561


2
00:00:06,561 --> 00:00:08,231
RIVEST: I don't need
to use that, right?

3
00:00:08,231 --> 00:00:10,792
Yep.

4
00:00:10,792 --> 00:00:13,330
Good morning.
It's a pleasure to be here.

5
00:00:13,330 --> 00:00:15,561
As Andy suggested, I was
out here partly on business

6
00:00:15,561 --> 00:00:17,231
and partly to see the grandkids.

7
00:00:17,231 --> 00:00:20,099
So it's fun to --
fun to get out and do that.

8
00:00:20,099 --> 00:00:23,198
Um, happy to, uh, fill in
for the gap here.

9
00:00:23,198 --> 00:00:25,132
Thanks to the organizing
committee for organizing

10
00:00:25,132 --> 00:00:26,462
this wonderful conference,
first of all.

11
00:00:26,462 --> 00:00:27,858
It's a pleasure
to see everything

12
00:00:27,858 --> 00:00:30,132
that's happening here,
and all the talks are great.

13
00:00:30,132 --> 00:00:32,858
Um, and, uh, happy to take
this opportunity

14
00:00:32,858 --> 00:00:35,000
to talk a little bit about, uh,

15
00:00:35,000 --> 00:00:37,561
some work we did recently
on crypto policy.

16
00:00:37,561 --> 00:00:42,066
Uh, our "Keys Under Doormat"
paper appeared last year.

17
00:00:42,066 --> 00:00:43,957
And I'll talk
a little bit about that.

18
00:00:43,957 --> 00:00:46,132
This will be a short talk,

19
00:00:46,132 --> 00:00:49,561
uh, just overviewing the content
of that paper

20
00:00:49,561 --> 00:00:50,891
and hopefully good enough
for questions.

21
00:00:50,891 --> 00:00:54,428
I hope we'll have some time
for some good Q&A.

22
00:00:54,429 --> 00:00:59,264
So this is not technical
in the sense of, you know,

23
00:00:59,264 --> 00:01:01,561
crypto-development, no equations
or anything like that.

24
00:01:01,561 --> 00:01:03,660
This is a talk about policy.

25
00:01:03,660 --> 00:01:05,197
And it resonates very much

26
00:01:05,197 --> 00:01:07,000
with the talk
you heard yesterday from,

27
00:01:07,000 --> 00:01:09,792
uh, Amie Stepanovich, uh,
on crypto policy.

28
00:01:09,792 --> 00:01:11,858
So a lot of what I say
will resonate well with --

29
00:01:11,858 --> 00:01:13,957
with what she said.

30
00:01:13,957 --> 00:01:15,627
And also a bit with,
uh, a talk that,

31
00:01:15,627 --> 00:01:17,890
uh, Ava and Morgan
gave as well.

32
00:01:17,891 --> 00:01:20,297
So the title of the paper

33
00:01:20,297 --> 00:01:23,264
that we wrote is
"Keys Under Doormats."

34
00:01:23,264 --> 00:01:26,461
And I'll explain
the context for that.

35
00:01:26,462 --> 00:01:29,957
Uh, the subtitle, uh,
"Mandating Insecurity

36
00:01:29,957 --> 00:01:31,428
by Requiring Government Access

37
00:01:31,429 --> 00:01:33,066
to All Data
and Communications"

38
00:01:33,066 --> 00:01:34,759
sort of explains
what it's about.

39
00:01:34,759 --> 00:01:37,132
And there's quite a host
of us as co-authors --

40
00:01:37,132 --> 00:01:39,099
Hal Abelson, Ross Anderson,

41
00:01:39,099 --> 00:01:41,792
Steve Bellovin, Josh Benaloh,
Matt Blaze, Whit Diffie,

42
00:01:41,792 --> 00:01:43,363
John Gilmore
who's here somewhere.

43
00:01:43,363 --> 00:01:46,132
Hello, John!
Uh, Matt Green, Peter Neumann,

44
00:01:46,132 --> 00:01:47,924
Susan Landau, myself,
Jeff Schiller,

45
00:01:47,924 --> 00:01:49,660
Bruce Schneier,
Michael Specter,

46
00:01:49,660 --> 00:01:53,330
Danny Weitzner
participated in this.

47
00:01:53,330 --> 00:01:56,066
Uh, and many of us were
co-authors on an earlier report

48
00:01:56,066 --> 00:01:57,792
that I'll mention as well.

49
00:02:01,726 --> 00:02:04,792
So the context
for this paper, uh,

50
00:02:04,792 --> 00:02:07,891
begins back, well really
in the '80s but let --

51
00:02:07,891 --> 00:02:10,429
let's start with the '90s
where it's a little clearer.

52
00:02:10,429 --> 00:02:13,891
Um, at that point, uh,
I mean, the --

53
00:02:13,891 --> 00:02:17,363
the government has always had
a problematic relationship

54
00:02:17,363 --> 00:02:19,561
with crypto
and the public domain.

55
00:02:19,561 --> 00:02:22,891
And this, uh, first really
surfaced with some force

56
00:02:22,891 --> 00:02:26,329
in the '90s, uh,
when the US government, uh,

57
00:02:26,330 --> 00:02:28,033
expressed concern
about the development

58
00:02:28,033 --> 00:02:31,165
of crypto in the public domain.

59
00:02:31,165 --> 00:02:34,297
And they proposed, uh, a cure,

60
00:02:34,297 --> 00:02:36,429
if you'd like,
to the problem

61
00:02:36,429 --> 00:02:38,792
of unregulated crypto

62
00:02:38,792 --> 00:02:41,132
and everybody being able
to use crypto in the form

63
00:02:41,132 --> 00:02:44,099
of this wonderful device
called a Clipper Chip.

64
00:02:44,099 --> 00:02:45,857
Uh, so this was a circuit

65
00:02:45,858 --> 00:02:49,066
that everybody who used crypto
would have to use.

66
00:02:49,066 --> 00:02:51,033
And it had, uh,

67
00:02:51,033 --> 00:02:53,165
ways of doing key management

68
00:02:53,165 --> 00:02:55,462
that allowed
law enforcement access.

69
00:02:55,462 --> 00:02:57,626
In fact, there's something
called a "LEAF,"

70
00:02:57,627 --> 00:02:59,561
a Law Enforcement
Access Field there.

71
00:02:59,561 --> 00:03:02,297
And the idea would be
that everybody

72
00:03:02,297 --> 00:03:04,429
should use this and thereby

73
00:03:04,429 --> 00:03:07,264
we'd get reasonably good crypto
except for the fact

74
00:03:07,264 --> 00:03:10,924
that law enforcement
would have access as well.

75
00:03:10,924 --> 00:03:14,231
And, uh, so this caused
quite a stir and a lot

76
00:03:14,231 --> 00:03:15,858
of protests and a lot
of posters saying,

77
00:03:15,858 --> 00:03:18,297
"Big Brother Inside," saying
we shouldn't go there.

78
00:03:18,297 --> 00:03:20,759
And I've got other posters if
you want to see them sometime.

79
00:03:20,759 --> 00:03:23,957
Um, this proposal
was eventually abandoned

80
00:03:23,957 --> 00:03:26,066
after a lot of debate
back and forth.

81
00:03:26,066 --> 00:03:29,297
Um, partly because
the particular proposal

82
00:03:29,297 --> 00:03:33,132
that was made
was technically flawed.

83
00:03:33,132 --> 00:03:34,462
And people like Matt Blaze

84
00:03:34,462 --> 00:03:37,099
found problems
with the proposal

85
00:03:37,099 --> 00:03:38,923
that allowed, uh,

86
00:03:38,924 --> 00:03:40,495
the mechanisms to be defeated.

87
00:03:40,495 --> 00:03:43,132
Uh, and moreover
the whole policy

88
00:03:43,132 --> 00:03:45,132
seemed to be
a bit top-heavy

89
00:03:45,132 --> 00:03:47,858
and unworkable
in a variety of ways.

90
00:03:47,858 --> 00:03:52,660
Uh, the societal benefits
for encryption everywhere, uh,

91
00:03:52,660 --> 00:03:54,099
for everybody using
the best encryption

92
00:03:54,099 --> 00:03:55,560
they could seemed to outweigh

93
00:03:55,561 --> 00:03:57,792
the law enforcement concerns
at the time.

94
00:03:57,792 --> 00:04:00,594
There's no denying that
law enforcement has some issues

95
00:04:00,594 --> 00:04:02,660
with encryption, uh,
but on the whole,

96
00:04:02,660 --> 00:04:04,099
we have to judge
these things on terms

97
00:04:04,099 --> 00:04:05,923
of a societal balance.

98
00:04:05,924 --> 00:04:10,099
Where's the most benefit
for the most people.

99
00:04:10,099 --> 00:04:11,857
So this was, uh,
we thought abandoned.

100
00:04:11,858 --> 00:04:13,726
We thought
the crypto wars were over.

101
00:04:13,726 --> 00:04:18,726
But that turned out to be
only crypto wars 1.0.

102
00:04:18,726 --> 00:04:20,396
The original report...

103
00:04:20,396 --> 00:04:22,198
We wrote a report in '97 called

104
00:04:22,198 --> 00:04:24,066
"The Risks of Key Recovery,
Key Escrow

105
00:04:24,066 --> 00:04:26,198
and Trusted Third-Party
Encryption,"

106
00:04:26,198 --> 00:04:29,099
which, uh, still
reads very well today.

107
00:04:29,099 --> 00:04:31,066
And I recommend that you go
look at that

108
00:04:31,066 --> 00:04:33,561
if you're interested in
following these policy debates.

109
00:04:33,561 --> 00:04:35,626
Um, probably the main difference

110
00:04:35,627 --> 00:04:37,594
between then and now

111
00:04:37,594 --> 00:04:40,296
is that things
are much more global now.

112
00:04:40,297 --> 00:04:42,528
At the time, the policy debate

113
00:04:42,528 --> 00:04:45,396
was primarily
a US policy debate.

114
00:04:45,396 --> 00:04:49,297
And the focus was on
what should US policy be.

115
00:04:49,297 --> 00:04:52,066
And now, the question is really
how do we have any kind

116
00:04:52,066 --> 00:04:54,131
of global discussion
of these kinds of issues?

117
00:04:54,132 --> 00:04:57,396
"Is there any way forward that
would help law enforcement

118
00:04:57,396 --> 00:04:59,759
out of their problems?"
is sort of the --

119
00:04:59,759 --> 00:05:02,891
the question that's being asked.

120
00:05:02,891 --> 00:05:04,561
So now it's 2015.

121
00:05:04,561 --> 00:05:06,659
It's 20 years later

122
00:05:06,660 --> 00:05:09,264
and this issue
has surfaced again,

123
00:05:09,264 --> 00:05:12,924
primarily from
law enforcement in the US.

124
00:05:12,924 --> 00:05:14,594
That's the FBI.

125
00:05:14,594 --> 00:05:17,066
Not so much intelligence
agencies,

126
00:05:17,066 --> 00:05:18,924
they're pretty good
at getting the information

127
00:05:18,924 --> 00:05:21,000
they need by
whatever means they have.

128
00:05:21,000 --> 00:05:24,198
But law enforcement seems to be
a bit more troubled

129
00:05:24,198 --> 00:05:26,495
by the use
of encryption and the --

130
00:05:26,495 --> 00:05:30,033
the fact that criminals
can use, uh, cryptography,

131
00:05:30,033 --> 00:05:32,429
uh, effectively defeating
some of the, uh,

132
00:05:32,429 --> 00:05:34,032
access desires

133
00:05:34,033 --> 00:05:36,330
that the FBI has.

134
00:05:36,330 --> 00:05:38,890
So, uh, the phrase,
"Going dark,"

135
00:05:38,891 --> 00:05:40,825
is often used
although I think that,

136
00:05:40,825 --> 00:05:43,462
uh, misstates the position.

137
00:05:43,462 --> 00:05:45,099
I mean, law enforcement
has so many tools

138
00:05:45,099 --> 00:05:46,825
to get information
these days that --

139
00:05:46,825 --> 00:05:48,462
that it's almost scary.

140
00:05:48,462 --> 00:05:52,198
Um, but the concern is
that the law enforcement

141
00:05:52,198 --> 00:05:53,825
would not be able
to get access to data

142
00:05:53,825 --> 00:05:55,594
that it has a warrant

143
00:05:55,594 --> 00:05:57,627
to get an access to, um,

144
00:05:57,627 --> 00:05:59,627
and that's the concern.

145
00:05:59,627 --> 00:06:01,297
Uh, this is not
only a US issue now.

146
00:06:01,297 --> 00:06:02,957
England, the UK, has come up.

147
00:06:02,957 --> 00:06:04,792
David Cameron in England
has said, "You know,

148
00:06:04,792 --> 00:06:09,263
we would also like to have
a policy, uh, for access."

149
00:06:09,264 --> 00:06:12,198
They proposed revisions of
the Snooper's Charter and so on.

150
00:06:12,198 --> 00:06:13,495
Amie talked
about that yesterday.

151
00:06:13,495 --> 00:06:15,627
You've heard about
their concerns.

152
00:06:15,627 --> 00:06:19,759
Um, and so the proposal
that's floated

153
00:06:19,759 --> 00:06:23,660
is for something called,
"Exceptional Access."

154
00:06:23,660 --> 00:06:26,528
So rather than trying to do

155
00:06:26,528 --> 00:06:30,330
what they did with
the Clipper Chip scenario

156
00:06:30,330 --> 00:06:33,462
which is propose
a specific technical,

157
00:06:33,462 --> 00:06:35,858
uh, approach, they say,

158
00:06:35,858 --> 00:06:37,726
"Well, we don't care
how you do it.

159
00:06:37,726 --> 00:06:39,924
We just want to have access

160
00:06:39,924 --> 00:06:41,561
when we think
we're legally authorized

161
00:06:41,561 --> 00:06:43,099
to have access, um,

162
00:06:43,099 --> 00:06:45,462
and we'll call
that exceptional access,

163
00:06:45,462 --> 00:06:47,164
and we want all you
smart techie types

164
00:06:47,165 --> 00:06:49,693
to figure out
how that should work."

165
00:06:49,693 --> 00:06:52,890
And so that's -- that's sort
of the -- the positioning

166
00:06:52,891 --> 00:06:58,429
of the policy question
that's been raised by the FBI.

167
00:06:58,429 --> 00:07:00,594
So our report,
as I said, that just came out

168
00:07:00,594 --> 00:07:01,924
a few months ago,

169
00:07:01,924 --> 00:07:03,363
It's called
"Keys Under Doormats,"

170
00:07:03,363 --> 00:07:05,462
and it's a revisiting
of these issues

171
00:07:05,462 --> 00:07:06,825
in today's context.

172
00:07:06,825 --> 00:07:09,495
In many ways, the debate
has not changed.

173
00:07:09,495 --> 00:07:11,924
Uh, the issues
are still the same.

174
00:07:11,924 --> 00:07:13,594
Law enforcement wants access

175
00:07:13,594 --> 00:07:15,924
when it believes it's authorized
to have it.

176
00:07:15,924 --> 00:07:18,626
Uh, and the impact on society

177
00:07:18,627 --> 00:07:22,297
in terms of weakening of
the Internet infrastructure, uh,

178
00:07:22,297 --> 00:07:25,561
is still there,
in spades, even worse.

179
00:07:25,561 --> 00:07:27,099
Uh, our conclusion --

180
00:07:27,099 --> 00:07:28,924
Basically the world's
become more complicated

181
00:07:28,924 --> 00:07:30,231
since the '90s.

182
00:07:30,231 --> 00:07:32,429
Uh, the idea of providing
exceptional access

183
00:07:32,429 --> 00:07:34,726
for law enforcement
is even more dubious

184
00:07:34,726 --> 00:07:37,198
at this time
than it was then.

185
00:07:37,198 --> 00:07:40,032
So I'd like to follow through
and describe sort of

186
00:07:40,033 --> 00:07:41,693
our reasoning
and thinking on this.

187
00:07:41,693 --> 00:07:43,726
There's really a couple
of key points, I think,

188
00:07:43,726 --> 00:07:45,825
that are worth making.

189
00:07:48,297 --> 00:07:52,132
So the first is that I think
the problem specs are missing.

190
00:07:52,132 --> 00:07:54,693
If you're working in security,
you'd know that the first thing

191
00:07:54,693 --> 00:07:56,231
you want to do,
and what I do in my class

192
00:07:56,231 --> 00:07:58,891
is I ask students
to write a security policy.

193
00:07:58,891 --> 00:08:01,462
You know, this should happen.
That should not happen.

194
00:08:01,462 --> 00:08:03,825
You know, it should be clear
what your goal is in terms

195
00:08:03,825 --> 00:08:06,396
of who can access
what, when, and how.

196
00:08:06,396 --> 00:08:08,660
Uh, you know,
if you don't have a policy,

197
00:08:08,660 --> 00:08:10,561
there's no point
in talking about security

198
00:08:10,561 --> 00:08:12,924
because there's no such thing
as having a violation.

199
00:08:12,924 --> 00:08:14,462
There's no policy to violate.

200
00:08:14,462 --> 00:08:16,858
So the question is
what policy do you want to have?

201
00:08:16,858 --> 00:08:19,066
And that's distinct
from the implementation issues,

202
00:08:19,066 --> 00:08:21,231
the technical issues
as how you might try

203
00:08:21,231 --> 00:08:22,594
to achieve that policy.

204
00:08:22,594 --> 00:08:25,726
So writing a policy,
writing what the problem is,

205
00:08:25,726 --> 00:08:28,264
is really the first step with
any kind of security problem.

206
00:08:28,264 --> 00:08:30,132
And that's what
you'd want to do here,

207
00:08:30,132 --> 00:08:31,330
and that's what I think.

208
00:08:31,330 --> 00:08:32,924
It's not, uh,
the burden of

209
00:08:32,924 --> 00:08:34,957
the technical community
to try to specify.

210
00:08:34,957 --> 00:08:39,462
It's really what law enforcement
wants or thinks they want.

211
00:08:39,462 --> 00:08:41,330
So I sort of view
the situation

212
00:08:41,330 --> 00:08:43,396
with this metaphor
that's on the slide here.

213
00:08:43,395 --> 00:08:45,759
You know,
technology is usable

214
00:08:45,759 --> 00:08:47,363
by both the good guys
and the bad guys,

215
00:08:47,363 --> 00:08:49,363
and so you can imagine
when cars first came out,

216
00:08:49,363 --> 00:08:51,132
you know, police could say,
"The bad guys

217
00:08:51,132 --> 00:08:53,824
are using fast cars
to get away.

218
00:08:53,825 --> 00:08:55,297
Lets fix the problem
so they can't go

219
00:08:55,297 --> 00:08:57,693
faster than the police."

220
00:08:57,693 --> 00:08:59,792
What?
I mean, that's not a...

221
00:08:59,792 --> 00:09:01,198
That's an issue
statement, maybe,

222
00:09:01,198 --> 00:09:02,792
but it's not
a problem statement.

223
00:09:02,792 --> 00:09:04,396
It's not a security policy.

224
00:09:04,396 --> 00:09:07,462
It doesn't really say
who can do what when.

225
00:09:07,462 --> 00:09:09,660
You know, can a policemen
point a gadget at a car

226
00:09:09,660 --> 00:09:11,593
and make it slow down,
uh, you know.

227
00:09:11,594 --> 00:09:13,000
What happens?
I mean, there's lot --

228
00:09:13,000 --> 00:09:14,792
lots of issues that come to mind
if you had that.

229
00:09:14,792 --> 00:09:17,132
Maybe it's not a great metaphor
but, you know.

230
00:09:17,132 --> 00:09:18,660
You want to distinguish
between an issue,

231
00:09:18,660 --> 00:09:21,495
where there's an issue
and a security policy saying

232
00:09:21,495 --> 00:09:23,924
who can do what when,
who as access to what.

233
00:09:23,924 --> 00:09:26,462
How's this gonna work?

234
00:09:26,462 --> 00:09:30,033
So the first thing
you note about this debate

235
00:09:30,033 --> 00:09:32,726
is that there is
no problem statement.

236
00:09:32,726 --> 00:09:34,561
There an issue
that's been raised

237
00:09:34,561 --> 00:09:37,165
but there's no specifications
as to what ought to happen.

238
00:09:37,165 --> 00:09:39,000
There's no -- there's nothing
for the technical folks

239
00:09:39,000 --> 00:09:40,891
to start chewing on
and trying to implement

240
00:09:40,891 --> 00:09:43,396
because there's no
specification of what

241
00:09:43,396 --> 00:09:45,065
the desiderata is, you know.

242
00:09:45,066 --> 00:09:46,726
And there's many aspects
to that.

243
00:09:46,726 --> 00:09:50,099
One is, for example,
the issue of jurisdiction.

244
00:09:50,099 --> 00:09:52,264
And that's a huge one
and it may be a showstopper

245
00:09:52,264 --> 00:09:54,825
for trying to make
progress in this area.

246
00:09:54,825 --> 00:09:57,297
You know, it's not
just the US anymore, right?

247
00:09:57,297 --> 00:09:58,726
It's a global Internet.

248
00:09:58,726 --> 00:10:00,825
It's
a global communications system.

249
00:10:00,825 --> 00:10:02,957
Crypto is used everywhere, um,

250
00:10:02,957 --> 00:10:05,924
and if you're trying
to come up with some policy

251
00:10:05,924 --> 00:10:08,297
that regulates or controls
crypto in some way,

252
00:10:08,297 --> 00:10:12,660
you'd have to say what you want
to happen for, uh, you know,

253
00:10:12,660 --> 00:10:14,000
all over the planet.

254
00:10:14,000 --> 00:10:16,693
So it -- you know, US
law enforcement comes to Apple

255
00:10:16,693 --> 00:10:18,297
and says, "We want to get access
to that phone."

256
00:10:18,297 --> 00:10:19,924
Well, maybe the policy
says that should happen.

257
00:10:19,924 --> 00:10:21,957
Well, then
British law enforcement

258
00:10:21,957 --> 00:10:24,231
comes and says, "We want
access to this phone."

259
00:10:24,231 --> 00:10:25,726
And Chinese law
enforcement says,

260
00:10:25,726 --> 00:10:28,858
"We want access to that phone."
And Israeli says...

261
00:10:28,858 --> 00:10:31,429
Law enforcement says,
"We want access to that phone."

262
00:10:31,429 --> 00:10:33,429
And the Iranians
want access and so on, too.

263
00:10:33,429 --> 00:10:36,165
This is not just US law
enforcement we're talking about.

264
00:10:36,165 --> 00:10:39,098
We're talking about every law
enforcement, uh, on the planet.

265
00:10:39,099 --> 00:10:41,495
Some of them may be corrupt, uh,

266
00:10:41,495 --> 00:10:43,858
and have, uh --
or may be forging

267
00:10:43,858 --> 00:10:45,660
their warrants and so on, too.

268
00:10:45,660 --> 00:10:47,759
So what legal system
applies here?

269
00:10:47,759 --> 00:10:49,759
What is the policy
you want to have?

270
00:10:49,759 --> 00:10:51,198
It's not clear.
We can't just say,

271
00:10:51,198 --> 00:10:53,000
"In the US,
it works this way,"

272
00:10:53,000 --> 00:10:54,759
without thinking
about the global consequences

273
00:10:54,759 --> 00:10:57,099
and the global policy
you want you have.

274
00:10:57,099 --> 00:11:00,198
So I think that's a really
key question to ask here is,

275
00:11:00,198 --> 00:11:04,693
"What should
or what could the policy

276
00:11:04,693 --> 00:11:06,957
be globally
for law enforcement access?"

277
00:11:06,957 --> 00:11:10,066
Until you even try to start
answering that question,

278
00:11:10,066 --> 00:11:14,330
you don't have a goal even
to think about.

279
00:11:14,330 --> 00:11:17,132
In China, access iPhones of
traveling US officials, right?

280
00:11:17,132 --> 00:11:18,858
I mean, China's gonna
have some policy as well.

281
00:11:18,858 --> 00:11:21,858
Probably it will mirror
the US policy

282
00:11:21,858 --> 00:11:23,891
if the US takes the lead
on establishing policy,

283
00:11:23,891 --> 00:11:25,660
or maybe China
will have their own policies

284
00:11:25,660 --> 00:11:27,791
and go ahead
and demand access anyway.

285
00:11:27,792 --> 00:11:30,594
Or maybe they can hack
into the phones already,

286
00:11:30,594 --> 00:11:33,066
you know, but that's
a separate question.

287
00:11:33,066 --> 00:11:35,330
So what's the scope of

288
00:11:35,330 --> 00:11:36,891
what one might try
to do, you know?

289
00:11:36,891 --> 00:11:40,098
The problem specs aren't there.

290
00:11:40,099 --> 00:11:42,363
It's not just Apple, right?

291
00:11:42,363 --> 00:11:43,759
There are...

292
00:11:43,759 --> 00:11:45,594
We got an ecology, an ecosystem,

293
00:11:45,594 --> 00:11:47,363
built on apps, uh,

294
00:11:47,363 --> 00:11:50,000
the, uh, Android
and the iPhone App Stores

295
00:11:50,000 --> 00:11:53,363
together encompass
some 2 million apps.

296
00:11:53,363 --> 00:11:54,627
That's a lot of apps.

297
00:11:54,627 --> 00:11:57,132
Many of them use crypto,

298
00:11:57,132 --> 00:11:58,462
and they should, right?

299
00:11:58,462 --> 00:12:00,792
So how --
what's the policy on them?

300
00:12:00,792 --> 00:12:02,825
I know we're trying
to catch some bad guys, right?

301
00:12:02,825 --> 00:12:04,033
They're using technology
in a way

302
00:12:04,033 --> 00:12:05,528
that the FBI doesn't like.

303
00:12:05,528 --> 00:12:07,462
So if they can't use iMessage,

304
00:12:07,462 --> 00:12:09,792
they're gonna use
some other messaging app.

305
00:12:09,792 --> 00:12:11,528
You know,
they're very fluid.

306
00:12:11,528 --> 00:12:13,000
I mean, they use burner phones
all the time.

307
00:12:13,000 --> 00:12:15,594
You know, burner apps would just
be the next step.

308
00:12:15,594 --> 00:12:17,825
It's not clear
that trying to regulate

309
00:12:17,825 --> 00:12:20,726
just a few big manufacturers
gets them anywhere in terms

310
00:12:20,726 --> 00:12:23,495
of what law enforcement's
trying to achieve.

311
00:12:23,495 --> 00:12:24,924
So the scope

312
00:12:24,924 --> 00:12:26,824
of what one might want to do

313
00:12:26,825 --> 00:12:28,363
or what law enforcement
might want, uh,

314
00:12:28,363 --> 00:12:31,132
is very unclear,
both in terms of jurisdiction,

315
00:12:31,132 --> 00:12:34,627
in terms of what components,
technologies, what --

316
00:12:34,627 --> 00:12:36,098
what, uh, what apps,

317
00:12:36,099 --> 00:12:38,594
what software pieces
might be in the scope.

318
00:12:38,594 --> 00:12:40,528
There's no problem spec here.

319
00:12:40,528 --> 00:12:43,000
You can't think about,
uh, an issue like this,

320
00:12:43,000 --> 00:12:44,924
uh, without starting
off trying to say,

321
00:12:44,924 --> 00:12:47,462
"What's the problem? What's
the spec you want to have?"

322
00:12:47,462 --> 00:12:51,825
And that's harder probably
than the technical aspects

323
00:12:51,825 --> 00:12:53,396
of trying to achieve
some particular policy,

324
00:12:53,396 --> 00:12:55,791
to try and figure out
what a reasonable policy is.

325
00:12:55,792 --> 00:12:58,957
It's --
That may be unsolvable, right?

326
00:12:58,957 --> 00:13:02,363
Trying to come up with
a policy that works globally.

327
00:13:02,363 --> 00:13:05,231
Second thing is that the cure,

328
00:13:05,231 --> 00:13:06,693
if you try to imagine
doing something, the cure

329
00:13:06,693 --> 00:13:08,824
is probably worse
than the disease.

330
00:13:08,825 --> 00:13:11,660
All right,
we're talking about some, uh,

331
00:13:11,660 --> 00:13:15,165
policy, unimagined as yet,
is what it could be, uh,

332
00:13:15,165 --> 00:13:17,462
and then some technical
implementation, uh,

333
00:13:17,462 --> 00:13:19,825
that tries to implement
such a policy.

334
00:13:19,825 --> 00:13:22,693
So this disease
you're trying to cure,

335
00:13:22,693 --> 00:13:24,693
which is some bad guys
using some technology

336
00:13:24,693 --> 00:13:26,165
in a way that you don't like,

337
00:13:26,165 --> 00:13:28,165
and there's "the cure,"

338
00:13:28,165 --> 00:13:29,429
which is regulation

339
00:13:29,429 --> 00:13:31,000
of cryptography
or something like this,

340
00:13:31,000 --> 00:13:34,858
trying to achieve at least
this exceptional access

341
00:13:34,858 --> 00:13:37,329
that's claimed
to be desirable.

342
00:13:37,330 --> 00:13:39,396
So, uh,

343
00:13:39,396 --> 00:13:43,231
I think it's not hard
to make the case

344
00:13:43,231 --> 00:13:45,363
that no matter
how you try to slice it,

345
00:13:45,363 --> 00:13:48,132
the cure is going to be
worse than the disease

346
00:13:48,132 --> 00:13:52,000
in terms of enabling bad guys
doing bad things

347
00:13:52,000 --> 00:13:55,330
and causing harm
to our country and into --

348
00:13:55,330 --> 00:14:00,363
into the, uh, technology
infrastructure that we've got.

349
00:14:00,363 --> 00:14:02,693
Exceptional access
makes the Internet less secure,

350
00:14:02,693 --> 00:14:04,891
and I think there's
two ways it does that.

351
00:14:04,891 --> 00:14:06,264
One is directly,

352
00:14:06,264 --> 00:14:09,264
because it introduces new
intended vulnerabilities, right?

353
00:14:09,264 --> 00:14:11,198
Exceptional access means
there are people

354
00:14:11,198 --> 00:14:13,824
who can get access
that couldn't get access before,

355
00:14:13,825 --> 00:14:17,594
and that necessarily introduces
vulnerabilities, right?

356
00:14:17,594 --> 00:14:20,528
Those people
might abuse their power,

357
00:14:20,528 --> 00:14:24,099
uh, they might be
corrupt in some way.

358
00:14:24,099 --> 00:14:25,891
So there are new vulnerabilities

359
00:14:25,891 --> 00:14:27,165
that are definitely
going to be created.

360
00:14:27,165 --> 00:14:29,363
Those back doors,
if there are back doors, uh,

361
00:14:29,363 --> 00:14:33,297
might be usable
by malicious parties.

362
00:14:33,297 --> 00:14:35,264
So those are intended
vulnerabilities.

363
00:14:35,264 --> 00:14:39,264
And then there's an indirect
introduction of vulnerabilities

364
00:14:39,264 --> 00:14:42,462
because any such system
as this is, uh,

365
00:14:42,462 --> 00:14:44,098
necessarily complicated

366
00:14:44,099 --> 00:14:46,099
and will introduce
more vulnerabilities to it.

367
00:14:46,099 --> 00:14:48,561
It's, uh, if you start getting
into the details

368
00:14:48,561 --> 00:14:51,231
of what our cryptographic
infrastructure

369
00:14:51,231 --> 00:14:53,858
looks like and how
exceptional access might work,

370
00:14:53,858 --> 00:14:57,296
you realize this is very, very,
very complicated.

371
00:14:57,297 --> 00:14:58,495
Matt Green wrote a nice blog

372
00:14:58,495 --> 00:15:01,198
talking about
the Apple crypto ecostructure.

373
00:15:01,198 --> 00:15:02,396
He says, "You couldn't
pay me to try

374
00:15:02,396 --> 00:15:04,462
to put exceptional access
in this structure.

375
00:15:04,462 --> 00:15:06,561
It's really way too
complicated

376
00:15:06,561 --> 00:15:07,924
to think about, almost."

377
00:15:07,924 --> 00:15:11,429
So, uh,
the introduction of complexity

378
00:15:11,429 --> 00:15:14,363
is, uh, you know...

379
00:15:14,363 --> 00:15:16,099
Complexity
is the enemy of security.

380
00:15:16,099 --> 00:15:17,759
We'll definitely have
a lot of complexity

381
00:15:17,759 --> 00:15:20,528
if this ever went anywhere.

382
00:15:20,528 --> 00:15:23,495
One thing I did list here
is the opportunity cost, right?

383
00:15:23,495 --> 00:15:27,858
The -- We have
a cyber-security crisis.

384
00:15:27,858 --> 00:15:29,660
We have a lot of work

385
00:15:29,660 --> 00:15:31,593
that needs to be done
on keeping the bad guys

386
00:15:31,594 --> 00:15:32,891
out of our systems,

387
00:15:32,891 --> 00:15:36,132
and, you know, focusing
our best engineers,

388
00:15:36,132 --> 00:15:37,660
and a lot of the folks
in this room,

389
00:15:37,660 --> 00:15:40,000
on giving law enforcement
exceptional access,

390
00:15:40,000 --> 00:15:42,297
means they're not doing
something else.

391
00:15:42,297 --> 00:15:44,495
Right, so they're helping
law enforcement maybe

392
00:15:44,495 --> 00:15:46,693
with a certain class
of problems,

393
00:15:46,693 --> 00:15:48,098
but there's a lot of things
that are then gonna

394
00:15:48,099 --> 00:15:51,231
get overlooked or delayed
or not done or not done well.

395
00:15:51,231 --> 00:15:53,759
Uh, and I think there's
a huge opportunity cost,

396
00:15:53,759 --> 00:15:55,858
you know,
if we catch a few, uh,

397
00:15:55,858 --> 00:15:57,165
bad guys using crypto

398
00:15:57,165 --> 00:15:58,759
and then have
the power grid go down

399
00:15:58,759 --> 00:16:02,033
because we didn't get our SCADA
protection done in time.

400
00:16:02,033 --> 00:16:05,462
You know,
that's a serious problem.

401
00:16:05,462 --> 00:16:08,033
So I think we have to talk
about the opportunity cost here,

402
00:16:08,033 --> 00:16:10,066
too, because there is
a huge engineering cost

403
00:16:10,066 --> 00:16:13,957
of even trying to do
any kind of exceptional access.

404
00:16:13,957 --> 00:16:18,593
Um, so exceptional access makes
an essential tool, cryptography,

405
00:16:18,594 --> 00:16:20,693
uh, more expensive
and difficult to use, right?

406
00:16:20,693 --> 00:16:22,198
So there's obviously
gonna be some overhead.

407
00:16:22,198 --> 00:16:24,429
You have to think about
every time cryptography is --

408
00:16:24,429 --> 00:16:27,033
How would you make --
give exceptional access

409
00:16:27,033 --> 00:16:29,396
for this use of cryptography
or that use of cryptography?

410
00:16:29,396 --> 00:16:32,527
It's a lot of overhead,
engineering time, and then cost.

411
00:16:32,528 --> 00:16:35,462
You've got, uh, people to
manage keys and do other things.

412
00:16:35,462 --> 00:16:39,033
Uh, so I think there will be
a penalty for...

413
00:16:39,033 --> 00:16:42,297
And I think Amie mentioned this
in her talk, too, uh, yesterday.

414
00:16:42,297 --> 00:16:44,297
People will maybe
make bad choices

415
00:16:44,297 --> 00:16:45,924
and say, "We're not
gonna use cryptography,"

416
00:16:45,924 --> 00:16:48,033
or, "We're just gonna use weak
cryptography," or something.

417
00:16:48,033 --> 00:16:50,231
So I think that
there's a cost there

418
00:16:50,231 --> 00:16:52,363
that needs to be evaluated.

419
00:16:52,363 --> 00:16:54,627
Exceptional access
requires violation

420
00:16:54,627 --> 00:16:56,758
of best practices
in cryptography.

421
00:16:56,759 --> 00:17:00,099
So, forward security is one
of those best practices

422
00:17:00,099 --> 00:17:01,924
that we've been
moving rapidly towards,

423
00:17:01,924 --> 00:17:03,231
I'm pleased to say recently.

424
00:17:03,231 --> 00:17:06,231
So you know, the compromise
of cryptographic keys

425
00:17:06,231 --> 00:17:07,627
need not, uh,

426
00:17:07,627 --> 00:17:11,197
compromise encrypted
communications, uh, of the past.

427
00:17:11,198 --> 00:17:14,726
It may only compromise encrypted
communications going forward.

428
00:17:14,726 --> 00:17:16,297
That's why it's
called forward security.

429
00:17:16,297 --> 00:17:19,297
So exceptional access
sort of means

430
00:17:19,297 --> 00:17:22,363
you've got continued access
backwards in time

431
00:17:22,363 --> 00:17:25,099
and so it would violate certain
cryptographic best practice.

432
00:17:25,098 --> 00:17:27,494
Introduces new vulnerabilities
by breaking that,

433
00:17:27,494 --> 00:17:29,527
and we'd have to redesign all
the protocols that we're doing.

434
00:17:29,528 --> 00:17:32,627
TLS and things like that
may have to get redesigned.

435
00:17:32,627 --> 00:17:34,396
And authenticated encryption.

436
00:17:34,396 --> 00:17:36,825
That's not mentioned much,
but the binding together

437
00:17:36,825 --> 00:17:38,792
of confidentiality
and authentication

438
00:17:38,792 --> 00:17:41,197
with techniques
such as authenticated encryption

439
00:17:41,198 --> 00:17:44,099
means that someone
who has access to the keys

440
00:17:44,099 --> 00:17:46,890
can not only, uh,
read the traffic

441
00:17:46,891 --> 00:17:50,396
but they can also forge messages
reporting to be from the sender.

442
00:17:50,396 --> 00:17:52,956
And so you're giving
away capabilities

443
00:17:52,957 --> 00:17:54,462
that shouldn't be given away.

444
00:17:54,462 --> 00:17:56,033
You know,
if law enforcement

445
00:17:56,033 --> 00:17:58,065
had access to the keys,

446
00:17:58,066 --> 00:18:00,297
they might not be only able

447
00:18:00,297 --> 00:18:01,693
to read the traffic

448
00:18:01,693 --> 00:18:04,363
but also forge messages
from legitimate parties,

449
00:18:04,363 --> 00:18:06,462
and that's not clear
you want to go there at all.

450
00:18:09,363 --> 00:18:10,660
Maybe I'll just insert two.

451
00:18:10,660 --> 00:18:12,891
One of the other applications
that I like to spend

452
00:18:12,891 --> 00:18:14,957
a lot of time
thinking about, too, is voting.

453
00:18:14,957 --> 00:18:17,132
And people
talk about voting remotely

454
00:18:17,132 --> 00:18:19,033
and things
like this in encryption so,

455
00:18:19,033 --> 00:18:21,428
you know,
in terms of scope,

456
00:18:21,429 --> 00:18:24,627
should all communications be --
have law enforcement access?

457
00:18:24,627 --> 00:18:29,000
You know, the vote, the ballot
is supposed to be private.

458
00:18:29,000 --> 00:18:31,429
We'll hear more
about voting this afternoon.

459
00:18:31,429 --> 00:18:33,033
So I think
the likely consequence

460
00:18:33,033 --> 00:18:34,296
of exceptional access

461
00:18:34,297 --> 00:18:36,759
is long term damage
to our national security, right?

462
00:18:36,759 --> 00:18:39,726
We'll be spending time
doing stuff, uh, poorly,

463
00:18:39,726 --> 00:18:42,825
uh, that keeps us
from doing other things well

464
00:18:42,825 --> 00:18:44,957
that we ought to be
focusing on that probably

465
00:18:44,957 --> 00:18:46,693
is a higher priority.

466
00:18:46,693 --> 00:18:49,858
Um, and -- and, uh,
the cost benefit analysis

467
00:18:49,858 --> 00:18:52,000
is, uh, nowhere near clear.

468
00:18:52,000 --> 00:18:54,132
I think we've talked about
how many crooks

469
00:18:54,132 --> 00:18:55,594
are using cryptography
that you want to catch?

470
00:18:55,594 --> 00:18:58,165
How much damage would there be
of this other sort?

471
00:18:58,165 --> 00:19:01,297
My guess is that the evaluation
will say, you know,

472
00:19:01,297 --> 00:19:03,495
"Even if you could do
this stuff, you're making

473
00:19:03,495 --> 00:19:07,561
a mistake investing resources
going in that direction."

474
00:19:07,561 --> 00:19:09,099
There's many
unanswered questions.

475
00:19:09,099 --> 00:19:11,362
Justification
is one of these.

476
00:19:11,363 --> 00:19:13,462
Uh, the coverage,
what's the scope of policy

477
00:19:13,462 --> 00:19:15,363
you want, both technical --

478
00:19:15,363 --> 00:19:17,363
you know, does it include apps?
What about foreign apps?

479
00:19:17,363 --> 00:19:19,132
What about phones
coming from abroad?

480
00:19:19,132 --> 00:19:22,891
The jurisdictional issues, uh,
and so on.

481
00:19:22,891 --> 00:19:24,396
There's just lots and lots of

482
00:19:24,396 --> 00:19:26,033
detailed questions
that would have to be answered.

483
00:19:26,033 --> 00:19:28,527
Human rights, uh, you know,

484
00:19:28,528 --> 00:19:31,528
there was a nice talk yesterday
by Ava and Morgan about,

485
00:19:31,528 --> 00:19:33,363
uh, high risk individuals,
you know,

486
00:19:33,363 --> 00:19:35,627
putting exceptional access
for law enforcement

487
00:19:35,627 --> 00:19:37,363
for every possible law
enforcement agent

488
00:19:37,363 --> 00:19:39,066
on the planet, uh,
puts at risk

489
00:19:39,066 --> 00:19:40,957
those high risk individuals
even more.

490
00:19:40,957 --> 00:19:44,033
And I think that
deserves further discussion.

491
00:19:44,033 --> 00:19:47,099
Uh, you know, nothing happens
in crypto without standards.

492
00:19:47,099 --> 00:19:49,428
You can't just have, you know,
patchwork this and that.

493
00:19:49,429 --> 00:19:52,033
You'd have to have standards.
All of this would take, uh,

494
00:19:52,033 --> 00:19:53,296
a huge effort
to try to figure out

495
00:19:53,297 --> 00:19:55,858
what a standard was
for exceptional access.

496
00:19:55,858 --> 00:19:58,033
Uh, what's the cost
of implementing these things?

497
00:19:58,033 --> 00:20:00,000
Oversight,
compliance, regulation.

498
00:20:00,000 --> 00:20:01,363
You know,

499
00:20:01,363 --> 00:20:02,891
what if somebody implements
exceptional access poorly?

500
00:20:02,891 --> 00:20:04,660
How does that get evaluated?

501
00:20:04,660 --> 00:20:08,891
You have to submit
software for review?

502
00:20:08,891 --> 00:20:11,330
How's that gonna work?
Oversight of --

503
00:20:11,330 --> 00:20:13,033
of the whole exceptional
access program, you know.

504
00:20:13,033 --> 00:20:15,000
I think a program
like that would have

505
00:20:15,000 --> 00:20:16,561
to have a sunset clause saying,

506
00:20:16,561 --> 00:20:17,924
"If this isn't shown
to be effective,

507
00:20:17,924 --> 00:20:21,396
it should, uh, um,
you know, be closed down."

508
00:20:21,396 --> 00:20:23,363
Unintended consequences
such as the reduced use

509
00:20:23,363 --> 00:20:25,759
of crypto are hard to answer.

510
00:20:25,759 --> 00:20:28,924
So all of those would need
to be addressed.

511
00:20:28,924 --> 00:20:30,396
Um, what could you do?

512
00:20:30,396 --> 00:20:32,792
Um, you know, I think if you're
dealing with cryptography,

513
00:20:32,792 --> 00:20:34,231
as many of you are now,
you know, thinking

514
00:20:34,231 --> 00:20:37,858
about what exceptional access
might mean for the services

515
00:20:37,858 --> 00:20:40,956
and the products
that you're working on now.

516
00:20:40,957 --> 00:20:44,066
On saying, is there any way
that could make sense?

517
00:20:44,066 --> 00:20:46,594
And, uh, if not,
you know, speak up.

518
00:20:46,594 --> 00:20:49,165
Try to get your company
or your organization

519
00:20:49,165 --> 00:20:50,627
to speak up
on these issues, to say,

520
00:20:50,627 --> 00:20:53,197
you know, this is, uh,
very problematic for us,

521
00:20:53,198 --> 00:20:55,693
and try to keep crazy proposals

522
00:20:55,693 --> 00:20:57,594
about exceptional access

523
00:20:57,594 --> 00:21:00,528
that are poorly thought through
from going forward.

524
00:21:00,528 --> 00:21:03,000
So I encourage you to not just
sit back

525
00:21:03,000 --> 00:21:06,825
and watch what's going on,
but to speak up.

526
00:21:06,825 --> 00:21:08,132
So, for more information

527
00:21:08,132 --> 00:21:10,330
on our report,
you can find it online.

528
00:21:10,330 --> 00:21:11,924
Just Google for
"Keys Under Doormats."

529
00:21:11,924 --> 00:21:14,396
It's also on my website,
and there's a URL there.

530
00:21:14,396 --> 00:21:17,231
So there's lots of more issues
and complexity to this.

531
00:21:17,231 --> 00:21:20,363
I just wanted to, uh,
introduce you to the report

532
00:21:20,363 --> 00:21:21,594
if you haven't seen it

533
00:21:21,594 --> 00:21:23,330
and review some
of the issues here.

534
00:21:23,330 --> 00:21:25,627
And I'd be happy
to take, uh, questions.

535
00:21:25,627 --> 00:21:28,264
[ Applause ]

536
00:21:28,264 --> 00:21:30,197
Thank you.

537
00:21:35,957 --> 00:21:34,957


