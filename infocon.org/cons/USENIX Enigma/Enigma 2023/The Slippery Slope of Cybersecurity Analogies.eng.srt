1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:16,279 --> 00:00:19,680
tools that we have in cyber security is

3
00:00:19,680 --> 00:00:21,779
language words

4
00:00:21,779 --> 00:00:24,660
language shapes technology it allows us

5
00:00:24,660 --> 00:00:27,240
to be here to exchange ideas to debate

6
00:00:27,240 --> 00:00:30,840
them uh it's why Enigma exists

7
00:00:30,840 --> 00:00:32,940
analogies and metaphors have been used

8
00:00:32,940 --> 00:00:35,940
in cyber security for ages

9
00:00:35,940 --> 00:00:39,000
they outdate the internet and when you

10
00:00:39,000 --> 00:00:42,000
start paying attention you notice how

11
00:00:42,000 --> 00:00:44,520
complex they are how much they're used

12
00:00:44,520 --> 00:00:47,700
in our everyday language and for many of

13
00:00:47,700 --> 00:00:49,920
us in cyber security we feel like

14
00:00:49,920 --> 00:00:52,800
firefighters

15
00:00:52,800 --> 00:00:55,260
using analogies can help help people

16
00:00:55,260 --> 00:00:58,140
understand our message and explain

17
00:00:58,140 --> 00:01:00,960
really detailed technical Concepts but

18
00:01:00,960 --> 00:01:03,719
simplistic explanations can also lead to

19
00:01:03,719 --> 00:01:05,939
misconceptions

20
00:01:05,939 --> 00:01:07,979
in 1984

21
00:01:07,979 --> 00:01:10,140
one year after the internet was born

22
00:01:10,140 --> 00:01:13,020
Fred Cohen wrote a program that's spread

23
00:01:13,020 --> 00:01:14,640
by attaching itself to other software

24
00:01:14,640 --> 00:01:18,119
and he called that a computer virus one

25
00:01:18,119 --> 00:01:19,020
year

26
00:01:19,020 --> 00:01:21,240
in fact some analogies that we use in

27
00:01:21,240 --> 00:01:23,640
Computing and in cyber security pre-date

28
00:01:23,640 --> 00:01:26,159
the internet The OSI model for example

29
00:01:26,159 --> 00:01:29,280
has been used since the 70s and I still

30
00:01:29,280 --> 00:01:30,780
learned about it going to school to

31
00:01:30,780 --> 00:01:32,700
study computer science

32
00:01:32,700 --> 00:01:35,520
but that explosion of words has come

33
00:01:35,520 --> 00:01:37,560
with the internet the information Super

34
00:01:37,560 --> 00:01:41,040
Highway the web the cyberspace you can

35
00:01:41,040 --> 00:01:43,799
probably think of many many more and

36
00:01:43,799 --> 00:01:46,020
before we get to the modern day let's

37
00:01:46,020 --> 00:01:49,700
pause at one moment in history

38
00:01:50,220 --> 00:01:54,000
in 2006 Senator Ted Stevens you might

39
00:01:54,000 --> 00:01:57,560
recall made an Infamous line

40
00:02:00,500 --> 00:02:03,860
a series of tubes

41
00:02:03,860 --> 00:02:06,360
it's a series of tubes

42
00:02:06,360 --> 00:02:08,880
I think a lot of us like now still

43
00:02:08,880 --> 00:02:12,599
chuckle a little bit at that saying and

44
00:02:12,599 --> 00:02:15,660
it has persisted throughout history

45
00:02:15,660 --> 00:02:19,620
Ted Stevens was had an important role on

46
00:02:19,620 --> 00:02:21,239
the senate committee for Commerce

47
00:02:21,239 --> 00:02:23,099
science and transportation which had

48
00:02:23,099 --> 00:02:25,080
authority over many parts of the

49
00:02:25,080 --> 00:02:26,819
internet and they were debating

50
00:02:26,819 --> 00:02:29,940
important things about net neutrality

51
00:02:29,940 --> 00:02:31,680
the question is

52
00:02:31,680 --> 00:02:34,980
was that analogy helpful or harmful

53
00:02:34,980 --> 00:02:37,379
I'm going to argue with you that Ted

54
00:02:37,379 --> 00:02:38,940
Stevens was talking to his Senate

55
00:02:38,940 --> 00:02:41,160
colleagues and it wasn't as bad for them

56
00:02:41,160 --> 00:02:45,260
as it might feel to us even today

57
00:02:46,739 --> 00:02:49,500
but our words do matter and Ted Steven's

58
00:02:49,500 --> 00:02:52,379
words could have impacted even laws and

59
00:02:52,379 --> 00:02:54,239
norms and other things that had real

60
00:02:54,239 --> 00:02:57,360
world impact and the goal that I want to

61
00:02:57,360 --> 00:02:59,819
talk through today is that our audiences

62
00:02:59,819 --> 00:03:02,700
can be helped or harmed based on our

63
00:03:02,700 --> 00:03:05,160
cyber security analogies

64
00:03:05,160 --> 00:03:06,780
I'd also like to pause just for a second

65
00:03:06,780 --> 00:03:09,840
and thank uh Gene spafford at Purdue and

66
00:03:09,840 --> 00:03:11,819
Lee Metcalf at Carnegie Mellon the three

67
00:03:11,819 --> 00:03:13,140
of us have been thinking about these

68
00:03:13,140 --> 00:03:16,019
these topics for a little while

69
00:03:16,019 --> 00:03:18,300
so why are there so many analogies why

70
00:03:18,300 --> 00:03:20,280
do we use these so often

71
00:03:20,280 --> 00:03:22,739
um as I said there are languages rich

72
00:03:22,739 --> 00:03:25,080
with this from keys to Trojan horses to

73
00:03:25,080 --> 00:03:28,200
firewalls and we look for the needle in

74
00:03:28,200 --> 00:03:30,659
the haystack right we evict malware

75
00:03:30,659 --> 00:03:33,000
that's residents on our systems we

76
00:03:33,000 --> 00:03:35,819
debate baked in uh versus bolted on

77
00:03:35,819 --> 00:03:37,920
security there's no end to this language

78
00:03:37,920 --> 00:03:40,019
but of course we don't mean any of those

79
00:03:40,019 --> 00:03:42,180
things literally that's never been the

80
00:03:42,180 --> 00:03:44,760
point so let's consider three reasons

81
00:03:44,760 --> 00:03:46,799
why maybe they have persisted in the

82
00:03:46,799 --> 00:03:48,120
language

83
00:03:48,120 --> 00:03:50,879
first is analogies can help us learn it

84
00:03:50,879 --> 00:03:53,040
can help teach they were used with me

85
00:03:53,040 --> 00:03:55,140
when I was in school because it allowed

86
00:03:55,140 --> 00:03:57,720
my instructors to introduce a concept

87
00:03:57,720 --> 00:04:00,060
that we would get into details later so

88
00:04:00,060 --> 00:04:02,040
in a lock and a key shares some

89
00:04:02,040 --> 00:04:04,260
similarities with encryption but of

90
00:04:04,260 --> 00:04:06,060
course I went on to read books about

91
00:04:06,060 --> 00:04:08,159
encryption and to learn the details of

92
00:04:08,159 --> 00:04:10,319
how those things were both similar to

93
00:04:10,319 --> 00:04:14,340
the physical world and also different

94
00:04:14,340 --> 00:04:17,040
number two they can help us connect our

95
00:04:17,040 --> 00:04:19,380
mental models for how things work just

96
00:04:19,380 --> 00:04:22,340
like a trojan horse

97
00:04:22,380 --> 00:04:25,440
if an alert pops up for an average user

98
00:04:25,440 --> 00:04:27,419
and the description from the antivirus

99
00:04:27,419 --> 00:04:28,979
company says that this is a trojan horse

100
00:04:28,979 --> 00:04:31,020
I think the average person very

101
00:04:31,020 --> 00:04:33,360
intuitively and quickly understands that

102
00:04:33,360 --> 00:04:35,400
that's important they have some general

103
00:04:35,400 --> 00:04:37,320
sense even though they probably don't

104
00:04:37,320 --> 00:04:39,600
remember history class and they probably

105
00:04:39,600 --> 00:04:41,160
don't know exactly what the computer

106
00:04:41,160 --> 00:04:43,680
program is but they understand the kind

107
00:04:43,680 --> 00:04:45,720
of danger that they're faced with and

108
00:04:45,720 --> 00:04:47,580
that helps them make better decisions

109
00:04:47,580 --> 00:04:49,740
and so in that sense that's another

110
00:04:49,740 --> 00:04:52,620
reason I think we see analogies

111
00:04:52,620 --> 00:04:55,380
the third is that it can explain rather

112
00:04:55,380 --> 00:04:57,540
complex topics

113
00:04:57,540 --> 00:05:00,180
um in a very teachable easy to explain

114
00:05:00,180 --> 00:05:03,600
kind of way and if you ask the average

115
00:05:03,600 --> 00:05:05,580
person on the street what is a firewall

116
00:05:05,580 --> 00:05:07,560
see if we can take a survey out on the

117
00:05:07,560 --> 00:05:09,600
street I think people would generally

118
00:05:09,600 --> 00:05:11,580
tell you that this is a kind of

119
00:05:11,580 --> 00:05:14,040
technology that blocks bad things from

120
00:05:14,040 --> 00:05:15,780
getting to getting through onto my

121
00:05:15,780 --> 00:05:18,240
network they're not wrong right they

122
00:05:18,240 --> 00:05:19,979
have a general sense for that in fact

123
00:05:19,979 --> 00:05:21,300
they might understand a computer

124
00:05:21,300 --> 00:05:23,580
firewall more than they understand that

125
00:05:23,580 --> 00:05:25,080
the firewall has been around for a

126
00:05:25,080 --> 00:05:26,340
hundred years

127
00:05:26,340 --> 00:05:28,620
the firewall has been around in cars in

128
00:05:28,620 --> 00:05:31,020
buildings long before it existed in

129
00:05:31,020 --> 00:05:33,479
technology and yet people do understand

130
00:05:33,479 --> 00:05:35,880
the general sense for that

131
00:05:35,880 --> 00:05:38,820
so given these advantages what causes

132
00:05:38,820 --> 00:05:40,380
people to fail

133
00:05:40,380 --> 00:05:43,080
I want to talk about three

134
00:05:43,080 --> 00:05:46,020
first I think analogies omit and over

135
00:05:46,020 --> 00:05:48,660
generalize important details that matter

136
00:05:48,660 --> 00:05:50,479
in the conversations that we're having

137
00:05:50,479 --> 00:05:53,580
we have limited attention spans all

138
00:05:53,580 --> 00:05:56,940
humans and especially in headlines and

139
00:05:56,940 --> 00:05:58,979
media where we need to quickly capture

140
00:05:58,979 --> 00:06:01,560
people's attention the analogy can be

141
00:06:01,560 --> 00:06:03,000
the way to do that

142
00:06:03,000 --> 00:06:05,460
those short Snappy headlines just draw

143
00:06:05,460 --> 00:06:08,100
more clicks and not everybody knows

144
00:06:08,100 --> 00:06:09,960
enough to pick different words in those

145
00:06:09,960 --> 00:06:13,199
kinds of situations so when we explain

146
00:06:13,199 --> 00:06:16,080
email like a postcard going through the

147
00:06:16,080 --> 00:06:18,720
mail that is a pretty simplistic

148
00:06:18,720 --> 00:06:20,580
generalization it might help people

149
00:06:20,580 --> 00:06:23,160
understand privacy but there are a lot

150
00:06:23,160 --> 00:06:25,440
of nuances to that example that in some

151
00:06:25,440 --> 00:06:29,880
conversations require more more detail

152
00:06:29,880 --> 00:06:32,039
number two analogies can mislead

153
00:06:32,039 --> 00:06:34,860
sometimes even deliberately because they

154
00:06:34,860 --> 00:06:36,960
connect to some experience that's out of

155
00:06:36,960 --> 00:06:39,240
proportion and I think that's dangerous

156
00:06:39,240 --> 00:06:42,660
an example here are cyber weapons no

157
00:06:42,660 --> 00:06:44,160
cyber weapon has caused the same

158
00:06:44,160 --> 00:06:46,380
physical destruction as a kinetic weapon

159
00:06:46,380 --> 00:06:49,500
and worse we start to use analogies like

160
00:06:49,500 --> 00:06:52,680
cyber 911 or cyber Pearl Harbor which

161
00:06:52,680 --> 00:06:55,080
are not well connected to the physical

162
00:06:55,080 --> 00:06:57,180
world things and do a disservice to that

163
00:06:57,180 --> 00:06:59,060
conversation

164
00:06:59,060 --> 00:07:02,280
number three analogies in the worst case

165
00:07:02,280 --> 00:07:04,500
can have a normative Dimension and we

166
00:07:04,500 --> 00:07:05,880
saw that a little bit with Senator

167
00:07:05,880 --> 00:07:09,479
Stevens they can help the imaginary

168
00:07:09,479 --> 00:07:11,639
become reality if we start writing laws

169
00:07:11,639 --> 00:07:13,979
about the series of tubes that might

170
00:07:13,979 --> 00:07:15,900
lead to a very poor outcome and

171
00:07:15,900 --> 00:07:17,340
thankfully I couldn't find very many

172
00:07:17,340 --> 00:07:19,800
concrete examples of this but I do worry

173
00:07:19,800 --> 00:07:23,120
about the possibility of it

174
00:07:23,160 --> 00:07:25,680
so I'd like to present four ways that we

175
00:07:25,680 --> 00:07:28,440
use analogies four kinds and I'm going

176
00:07:28,440 --> 00:07:30,000
to start with the physical world because

177
00:07:30,000 --> 00:07:31,319
there's a lot of analogies to the

178
00:07:31,319 --> 00:07:33,599
physical world including of course the

179
00:07:33,599 --> 00:07:35,520
weakest link

180
00:07:35,520 --> 00:07:37,380
um cyber security Bears a lot in common

181
00:07:37,380 --> 00:07:39,720
with a chain no doubt about it there are

182
00:07:39,720 --> 00:07:41,280
many components that matter there are

183
00:07:41,280 --> 00:07:43,680
many people that matter the users are

184
00:07:43,680 --> 00:07:46,860
one developers system administrators uh

185
00:07:46,860 --> 00:07:49,080
the code that we use all of those things

186
00:07:49,080 --> 00:07:51,419
do help ensure that the system provides

187
00:07:51,419 --> 00:07:53,819
the security that we intend to and in

188
00:07:53,819 --> 00:07:56,520
that sense that's a pro for that analogy

189
00:07:56,520 --> 00:07:58,800
it is a way to describe that

190
00:07:58,800 --> 00:08:01,380
the trouble is when we say that the user

191
00:08:01,380 --> 00:08:04,199
for instance is the weakest link I think

192
00:08:04,199 --> 00:08:06,479
that does a disservice and a dishonest

193
00:08:06,479 --> 00:08:09,780
conversation to a really important part

194
00:08:09,780 --> 00:08:12,180
of cyber security which is users are

195
00:08:12,180 --> 00:08:15,720
targeted all the time and they are like

196
00:08:15,720 --> 00:08:17,699
the ones that the blowtorch is just

197
00:08:17,699 --> 00:08:20,280
firing on that link in the chain and so

198
00:08:20,280 --> 00:08:22,259
we need more defense for them and to

199
00:08:22,259 --> 00:08:24,660
call them the weakest link as an analogy

200
00:08:24,660 --> 00:08:28,580
does it get to that nuance

201
00:08:29,340 --> 00:08:31,279
what about cyber security and medical

202
00:08:31,279 --> 00:08:36,179
biologic analogies again in the Pro the

203
00:08:36,179 --> 00:08:38,039
the benefit of this analogy is that it's

204
00:08:38,039 --> 00:08:40,320
a term commonly understood things like

205
00:08:40,320 --> 00:08:43,200
viruses the average people especially

206
00:08:43,200 --> 00:08:44,459
now

207
00:08:44,459 --> 00:08:46,620
um understand Health they understand

208
00:08:46,620 --> 00:08:49,140
contamination they understand spread and

209
00:08:49,140 --> 00:08:50,940
in that sense they're right computer

210
00:08:50,940 --> 00:08:54,180
viruses do similar things like that

211
00:08:54,180 --> 00:08:56,760
the trouble is that digital defenses

212
00:08:56,760 --> 00:08:58,800
don't behave like biological defenses

213
00:08:58,800 --> 00:09:01,800
for all the advances in antivirus and

214
00:09:01,800 --> 00:09:04,080
host-based protection they don't learn

215
00:09:04,080 --> 00:09:06,180
the way that a biological system does

216
00:09:06,180 --> 00:09:08,519
and if somebody believes that the

217
00:09:08,519 --> 00:09:10,260
computer will just learn through

218
00:09:10,260 --> 00:09:12,180
exposure how to protect against a

219
00:09:12,180 --> 00:09:13,560
digital threat

220
00:09:13,560 --> 00:09:15,600
they will be worse off

221
00:09:15,600 --> 00:09:17,220
depends on the conversation that we're

222
00:09:17,220 --> 00:09:19,740
having with the people

223
00:09:19,740 --> 00:09:21,779
let's talk about cyber security and

224
00:09:21,779 --> 00:09:25,080
Military analogies these are ones that I

225
00:09:25,080 --> 00:09:27,000
see more and more

226
00:09:27,000 --> 00:09:29,339
um let me use the example of a blast

227
00:09:29,339 --> 00:09:32,160
radius that is a term a phrase that I

228
00:09:32,160 --> 00:09:34,440
see used in especially in in the media

229
00:09:34,440 --> 00:09:37,740
to describe not how energy from a bomb

230
00:09:37,740 --> 00:09:39,180
sort of propagates that's what the

231
00:09:39,180 --> 00:09:41,700
physical world blast radius is

232
00:09:41,700 --> 00:09:43,440
um but in terms of things like

233
00:09:43,440 --> 00:09:45,959
credential theft oh your password is

234
00:09:45,959 --> 00:09:48,240
compromised what's the blast radius of

235
00:09:48,240 --> 00:09:49,980
that impact

236
00:09:49,980 --> 00:09:52,860
in some sense it does give a sense of

237
00:09:52,860 --> 00:09:54,720
scope to the person about the damage

238
00:09:54,720 --> 00:09:57,360
which is it isn't just one system if you

239
00:09:57,360 --> 00:09:59,459
reused your password that that might

240
00:09:59,459 --> 00:10:01,500
have damage it might also affect other

241
00:10:01,500 --> 00:10:03,839
systems that's true there are secondary

242
00:10:03,839 --> 00:10:06,959
effects but they are not certainly

243
00:10:06,959 --> 00:10:09,420
confined to physical space and people

244
00:10:09,420 --> 00:10:11,220
who think about the blast radius of a

245
00:10:11,220 --> 00:10:13,500
bomb might think the same that mental

246
00:10:13,500 --> 00:10:15,720
that broken mental model about how it

247
00:10:15,720 --> 00:10:18,120
works on the internet that there's a

248
00:10:18,120 --> 00:10:19,980
physical Dimension to it

249
00:10:19,980 --> 00:10:21,779
I'll give you a bonus one here too since

250
00:10:21,779 --> 00:10:23,880
I used the picture of a castle when I

251
00:10:23,880 --> 00:10:25,680
was studying cyber security in school it

252
00:10:25,680 --> 00:10:27,420
was very often taught to us that cyber

253
00:10:27,420 --> 00:10:29,700
was like defending a castle there was a

254
00:10:29,700 --> 00:10:31,560
fixed boundary there were valuables

255
00:10:31,560 --> 00:10:33,839
inside the castle and that we needed to

256
00:10:33,839 --> 00:10:35,820
protect those things but of course

257
00:10:35,820 --> 00:10:38,279
modern networks are nothing like a

258
00:10:38,279 --> 00:10:40,680
castle users move the things of value

259
00:10:40,680 --> 00:10:42,899
are not physically in one place there's

260
00:10:42,899 --> 00:10:45,240
no hard perimeter to defend in the way

261
00:10:45,240 --> 00:10:48,779
that that we used to and so I don't talk

262
00:10:48,779 --> 00:10:50,760
about it in terms of Castle Defense

263
00:10:50,760 --> 00:10:54,560
anymore it's not a good analogy

264
00:10:55,260 --> 00:10:57,120
and let's talk about a fourth which are

265
00:10:57,120 --> 00:10:59,399
legal analogies in cyber security

266
00:10:59,399 --> 00:11:02,339
in fact the law has a long history of

267
00:11:02,339 --> 00:11:05,459
using legal analogies they compare for

268
00:11:05,459 --> 00:11:07,860
example digital files to paper files and

269
00:11:07,860 --> 00:11:09,540
filing cabinets to digital storage

270
00:11:09,540 --> 00:11:12,720
systems that means that the law doesn't

271
00:11:12,720 --> 00:11:14,640
have to change for every new technology

272
00:11:14,640 --> 00:11:16,560
that can be helpful

273
00:11:16,560 --> 00:11:18,720
trespassing is another way where we can

274
00:11:18,720 --> 00:11:20,579
use existing laws and apply them in the

275
00:11:20,579 --> 00:11:23,160
digital realm and in that sense they

276
00:11:23,160 --> 00:11:24,600
share a lot in common it's about

277
00:11:24,600 --> 00:11:26,399
accessing some system without

278
00:11:26,399 --> 00:11:28,620
authorization that can happen whether

279
00:11:28,620 --> 00:11:32,100
it's in my home or on my laptop

280
00:11:32,100 --> 00:11:34,920
but of course the con the the downside

281
00:11:34,920 --> 00:11:37,260
here is that courts have struggled to

282
00:11:37,260 --> 00:11:39,480
distinguish when the digital world is

283
00:11:39,480 --> 00:11:41,160
different than the than the physical

284
00:11:41,160 --> 00:11:43,560
world and in the case of trespassing

285
00:11:43,560 --> 00:11:47,339
what constitutes access is browsing the

286
00:11:47,339 --> 00:11:49,459
internet or browsing a website access

287
00:11:49,459 --> 00:11:53,220
what if I want to revoke my access uh it

288
00:11:53,220 --> 00:11:56,160
becomes very difficult in the details in

289
00:11:56,160 --> 00:11:57,899
terms of somebody walking into my house

290
00:11:57,899 --> 00:12:00,540
with a key or my authorization and

291
00:12:00,540 --> 00:12:03,420
accessing my computer the Nuance The

292
00:12:03,420 --> 00:12:05,519
Details Matter here quite a bit and the

293
00:12:05,519 --> 00:12:07,560
law struggles with this just as we ought

294
00:12:07,560 --> 00:12:10,880
to be careful in cyber security

295
00:12:11,640 --> 00:12:15,839
so there are pros and there are cons and

296
00:12:15,839 --> 00:12:18,240
the pi the time when we should be using

297
00:12:18,240 --> 00:12:20,220
analogies in cyber is in the best case

298
00:12:20,220 --> 00:12:22,079
when they are truthful and they are

299
00:12:22,079 --> 00:12:25,980
helpful in that instance very contextual

300
00:12:25,980 --> 00:12:27,720
but of course the negatives are also

301
00:12:27,720 --> 00:12:29,760
pitfalls and and we have to be careful

302
00:12:29,760 --> 00:12:31,680
that we don't pick analogies that are

303
00:12:31,680 --> 00:12:34,860
inaccurate uh incomplete or just the

304
00:12:34,860 --> 00:12:37,260
wrong type of conversation for the

305
00:12:37,260 --> 00:12:39,240
context that you might be in and

306
00:12:39,240 --> 00:12:40,800
sometimes the negatives will outweigh

307
00:12:40,800 --> 00:12:42,959
the positives and you must decide very

308
00:12:42,959 --> 00:12:44,639
carefully in a particular given

309
00:12:44,639 --> 00:12:47,459
conversation is this the correct and the

310
00:12:47,459 --> 00:12:50,660
best way to communicate

311
00:12:50,940 --> 00:12:53,399
let me give you one that I like I like

312
00:12:53,399 --> 00:12:56,339
the analogy of hygiene like the virus

313
00:12:56,339 --> 00:12:57,480
like things that people understand

314
00:12:57,480 --> 00:12:59,639
having basic behavior that everybody

315
00:12:59,639 --> 00:13:01,800
teaches their children like brushing

316
00:13:01,800 --> 00:13:04,079
their teeth washing their hands I think

317
00:13:04,079 --> 00:13:06,899
the concept of cyber hygiene can be

318
00:13:06,899 --> 00:13:09,360
effective in cyber security if we teach

319
00:13:09,360 --> 00:13:11,459
people to always check their links to

320
00:13:11,459 --> 00:13:13,019
always understand the impact of their

321
00:13:13,019 --> 00:13:16,200
passwords it can become basic routine

322
00:13:16,200 --> 00:13:18,540
that does help people help keep people

323
00:13:18,540 --> 00:13:22,440
safe and so that is one that I like

324
00:13:22,440 --> 00:13:24,480
so that said how can we avoid the

325
00:13:24,480 --> 00:13:26,220
misconceptions I want to give you three

326
00:13:26,220 --> 00:13:28,620
things to think about first is to

327
00:13:28,620 --> 00:13:30,899
recognize the audience that you are

328
00:13:30,899 --> 00:13:33,480
speaking with when you decide that an

329
00:13:33,480 --> 00:13:35,880
analogy might be appropriate this is

330
00:13:35,880 --> 00:13:39,000
about being context aware and a simple

331
00:13:39,000 --> 00:13:41,700
imperfect analogy might be fine it might

332
00:13:41,700 --> 00:13:43,620
be appropriate if you're having a casual

333
00:13:43,620 --> 00:13:45,779
conversation with friends where the

334
00:13:45,779 --> 00:13:47,399
stakes are very low

335
00:13:47,399 --> 00:13:49,019
knock yourself out

336
00:13:49,019 --> 00:13:51,779
but the more that we use analogies even

337
00:13:51,779 --> 00:13:53,820
in those situations the more normative

338
00:13:53,820 --> 00:13:55,920
they become the more people hear it even

339
00:13:55,920 --> 00:13:58,320
in casual conversation the more it is

340
00:13:58,320 --> 00:14:00,600
likely to stick so even when the stakes

341
00:14:00,600 --> 00:14:02,160
are low we ought to be a little bit

342
00:14:02,160 --> 00:14:04,440
careful

343
00:14:04,440 --> 00:14:07,740
number two we should try to refine the

344
00:14:07,740 --> 00:14:08,700
message

345
00:14:08,700 --> 00:14:10,800
don't forget the other tools in the

346
00:14:10,800 --> 00:14:12,360
language toolbox

347
00:14:12,360 --> 00:14:14,519
try using a story a personal experience

348
00:14:14,519 --> 00:14:16,019
when you need to help an audience

349
00:14:16,019 --> 00:14:17,820
understand some topic where you might

350
00:14:17,820 --> 00:14:20,459
otherwise feel drawn to an analogy

351
00:14:20,459 --> 00:14:22,560
I think about blast radius and the

352
00:14:22,560 --> 00:14:24,899
invasion of Ukraine the the Russians

353
00:14:24,899 --> 00:14:27,899
attacked satellite modems of tens of

354
00:14:27,899 --> 00:14:30,540
thousands of people with the byproduct

355
00:14:30,540 --> 00:14:32,519
that people they weren't trying to

356
00:14:32,519 --> 00:14:34,260
Target in Europe also had their internet

357
00:14:34,260 --> 00:14:35,579
cut out

358
00:14:35,579 --> 00:14:37,860
that is essentially what a blast radius

359
00:14:37,860 --> 00:14:39,899
is meant to describe but people might

360
00:14:39,899 --> 00:14:42,000
understand the story better by just

361
00:14:42,000 --> 00:14:45,500
explaining with a modern story

362
00:14:45,600 --> 00:14:49,019
third we have to respect our roles

363
00:14:49,019 --> 00:14:51,120
we have a lot of influence

364
00:14:51,120 --> 00:14:54,240
policymakers have influence uh expertise

365
00:14:54,240 --> 00:14:56,220
is very powerful and we have to be

366
00:14:56,220 --> 00:14:58,980
careful about that when using analogies

367
00:14:58,980 --> 00:15:00,000
we might we don't want to

368
00:15:00,000 --> 00:15:03,120
unintentionally reinforce some some

369
00:15:03,120 --> 00:15:05,519
message that we don't really want to

370
00:15:05,519 --> 00:15:08,519
propagate or to persist and that is

371
00:15:08,519 --> 00:15:11,399
including things like cyber 911 or cyber

372
00:15:11,399 --> 00:15:12,500
Pearl Harbor

373
00:15:12,500 --> 00:15:15,660
our words will matter a lot in those

374
00:15:15,660 --> 00:15:16,980
conversations and they will be

375
00:15:16,980 --> 00:15:19,320
remembered I also don't want analogies

376
00:15:19,320 --> 00:15:22,620
to unreasonably restrict our policy

377
00:15:22,620 --> 00:15:24,839
options unnecessarily

378
00:15:24,839 --> 00:15:26,940
so when we're talking about complex

379
00:15:26,940 --> 00:15:30,480
cyber security or setting policies we

380
00:15:30,480 --> 00:15:32,699
have to see the world as it is it's

381
00:15:32,699 --> 00:15:35,160
complex it's complicated it's

382
00:15:35,160 --> 00:15:36,600
unpredictable

383
00:15:36,600 --> 00:15:39,959
and the alternative is this incorrect or

384
00:15:39,959 --> 00:15:42,360
misleading mental model I think this is

385
00:15:42,360 --> 00:15:44,399
where the danger becomes can become

386
00:15:44,399 --> 00:15:46,260
reality

387
00:15:46,260 --> 00:15:48,779
so in closing we can all be effective

388
00:15:48,779 --> 00:15:51,060
communicators we can deliver the cyber

389
00:15:51,060 --> 00:15:53,279
security results that we want to when

390
00:15:53,279 --> 00:15:54,779
we're careful and deliberate about our

391
00:15:54,779 --> 00:15:56,699
language just as we need to be careful

392
00:15:56,699 --> 00:15:58,860
not to slide down the slippery slope

393
00:15:58,860 --> 00:16:02,000
thank you very much

