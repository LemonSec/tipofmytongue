1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:14,660 --> 00:00:17,160
I was once told to never stand in

3
00:00:17,160 --> 00:00:19,020
between an audience and their lunch so

4
00:00:19,020 --> 00:00:21,539
apologies for that I got to be the lucky

5
00:00:21,539 --> 00:00:23,100
one today

6
00:00:23,100 --> 00:00:25,199
um but uh my name is Sarah and I'm going

7
00:00:25,199 --> 00:00:27,300
to be talking about working on the front

8
00:00:27,300 --> 00:00:29,699
lines of privacy and security with

9
00:00:29,699 --> 00:00:31,679
vulnerable populations and I'm going to

10
00:00:31,679 --> 00:00:34,399
start with a small story in 2016

11
00:00:34,399 --> 00:00:37,140
post elections there was a lot of

12
00:00:37,140 --> 00:00:39,120
conversations around privacy and

13
00:00:39,120 --> 00:00:40,620
security and protecting yourself and I'm

14
00:00:40,620 --> 00:00:43,079
based in New York and there was

15
00:00:43,079 --> 00:00:45,480
um definitely a big conversation in New

16
00:00:45,480 --> 00:00:48,239
York about what it means for New York to

17
00:00:48,239 --> 00:00:51,480
be a sanctuary City for folks

18
00:00:51,480 --> 00:00:54,360
um and I was invited then post elections

19
00:00:54,360 --> 00:00:56,280
in 2016 I was invited to provide

20
00:00:56,280 --> 00:00:59,520
translation support for a group of

21
00:00:59,520 --> 00:01:01,800
software Engineers security Engineers

22
00:01:01,800 --> 00:01:04,260
that were giving a security talk or a

23
00:01:04,260 --> 00:01:06,540
security workshop for yemeni refugees in

24
00:01:06,540 --> 00:01:08,939
New York and I was not invited because

25
00:01:08,939 --> 00:01:11,280
of my privacy expertise or my security

26
00:01:11,280 --> 00:01:13,979
expertise or my community expertise I

27
00:01:13,979 --> 00:01:16,200
was invited specifically because I spoke

28
00:01:16,200 --> 00:01:17,939
Arabic and they needed translation

29
00:01:17,939 --> 00:01:22,979
support I said yes I went the the

30
00:01:22,979 --> 00:01:25,140
security Engineers were giving the con

31
00:01:25,140 --> 00:01:27,540
the security Workshop essentially talked

32
00:01:27,540 --> 00:01:29,640
about passwords about security about

33
00:01:29,640 --> 00:01:32,100
privacy all of that and they walked out

34
00:01:32,100 --> 00:01:34,619
of this Workshop essentially saying it

35
00:01:34,619 --> 00:01:37,860
was great no one had any questions

36
00:01:37,860 --> 00:01:40,439
a nice belt on the back and I'm going to

37
00:01:40,439 --> 00:01:42,299
leave you with the story here for now

38
00:01:42,299 --> 00:01:43,979
um and I'll Circle back to it later but

39
00:01:43,979 --> 00:01:45,900
that was essentially the context of this

40
00:01:45,900 --> 00:01:48,060
very entertaining security Workshop in

41
00:01:48,060 --> 00:01:49,860
2016.

42
00:01:49,860 --> 00:01:50,520
um

43
00:01:50,520 --> 00:01:52,979
so a bit of background about who I am I

44
00:01:52,979 --> 00:01:54,600
was here last year at Enigma and a lot

45
00:01:54,600 --> 00:01:56,460
of people asked me what I did and I

46
00:01:56,460 --> 00:01:57,479
always lets a very interesting

47
00:01:57,479 --> 00:01:58,860
conversations

48
00:01:58,860 --> 00:02:00,119
um because I have kind of a weird

49
00:02:00,119 --> 00:02:01,920
eclectic background or the work that I

50
00:02:01,920 --> 00:02:03,600
do is not very familiar I guess to a lot

51
00:02:03,600 --> 00:02:05,340
of people and this is essentially why

52
00:02:05,340 --> 00:02:06,899
inspired this talk that you're hearing

53
00:02:06,899 --> 00:02:08,639
today

54
00:02:08,639 --> 00:02:11,640
um very briefly I guess when people ask

55
00:02:11,640 --> 00:02:15,239
me what I do I work I'm a security

56
00:02:15,239 --> 00:02:17,280
expert who works for the benefit of

57
00:02:17,280 --> 00:02:19,260
Civil Society non-profits journalists

58
00:02:19,260 --> 00:02:21,780
and human rights Defenders what it means

59
00:02:21,780 --> 00:02:23,520
is that I've worked for many years with

60
00:02:23,520 --> 00:02:25,379
highly vulnerable populations highly

61
00:02:25,379 --> 00:02:28,200
targeted groups specifically and my work

62
00:02:28,200 --> 00:02:30,120
has taken me has taken me everywhere in

63
00:02:30,120 --> 00:02:31,680
the world I've I've worked in South

64
00:02:31,680 --> 00:02:33,540
America I've worked in East Asia in the

65
00:02:33,540 --> 00:02:35,760
Middle East in the US I've worked in

66
00:02:35,760 --> 00:02:37,920
higher risk environments such as the

67
00:02:37,920 --> 00:02:40,140
revolution in Iran such as a conflict in

68
00:02:40,140 --> 00:02:42,720
Ukraine in Myanmar and I've provided a

69
00:02:42,720 --> 00:02:45,720
lot of security expertise or advice on

70
00:02:45,720 --> 00:02:47,640
things such as protecting your data and

71
00:02:47,640 --> 00:02:50,099
your information on internet shutdowns

72
00:02:50,099 --> 00:02:51,420
and what it means to operate in the

73
00:02:51,420 --> 00:02:53,879
context of an Internet shutdown how to

74
00:02:53,879 --> 00:02:55,800
use circumvention technology what works

75
00:02:55,800 --> 00:02:57,060
and what context what works in another

76
00:02:57,060 --> 00:02:58,200
context

77
00:02:58,200 --> 00:03:00,720
and most recently I was the CTO and VP

78
00:03:00,720 --> 00:03:02,840
of security at the open technology fund

79
00:03:02,840 --> 00:03:05,519
which not a lot of people know about but

80
00:03:05,519 --> 00:03:07,379
actually is an organization that funds

81
00:03:07,379 --> 00:03:10,319
projects and Technologies based on

82
00:03:10,319 --> 00:03:12,239
countering censorship and surveillance

83
00:03:12,239 --> 00:03:14,340
they were the early funders of signal

84
00:03:14,340 --> 00:03:15,599
they're kind of like what kicked signal

85
00:03:15,599 --> 00:03:17,580
off the ground they're the one of the

86
00:03:17,580 --> 00:03:19,560
main funders of Tor and a lot of other

87
00:03:19,560 --> 00:03:21,480
kind of privacy and security either

88
00:03:21,480 --> 00:03:23,280
applications or research that you might

89
00:03:23,280 --> 00:03:25,620
have heard about I led the

90
00:03:25,620 --> 00:03:28,319
organization's efforts to identify and

91
00:03:28,319 --> 00:03:30,540
track emerging threats and to

92
00:03:30,540 --> 00:03:31,980
essentially Advance the field of

93
00:03:31,980 --> 00:03:34,200
information security for journalists

94
00:03:34,200 --> 00:03:36,180
human rights offenders and high-risk

95
00:03:36,180 --> 00:03:38,340
individuals

96
00:03:38,340 --> 00:03:41,280
when people ask me what a what I do

97
00:03:41,280 --> 00:03:43,379
basically and this is usually the the

98
00:03:43,379 --> 00:03:45,540
little bit of background that I give or

99
00:03:45,540 --> 00:03:47,640
I say essentially I am in the business

100
00:03:47,640 --> 00:03:50,400
of giving advice with very serious

101
00:03:50,400 --> 00:03:52,080
consequences

102
00:03:52,080 --> 00:03:54,480
why is it so serious

103
00:03:54,480 --> 00:03:56,879
um there is a real real danger with

104
00:03:56,879 --> 00:04:00,060
security guides and even trainers who

105
00:04:00,060 --> 00:04:02,040
tend to focus on a one-size-fits-all

106
00:04:02,040 --> 00:04:03,480
approach and we kind of heard from my

107
00:04:03,480 --> 00:04:06,299
colleagues earlier about this but there

108
00:04:06,299 --> 00:04:08,180
is a real danger in focusing on a

109
00:04:08,180 --> 00:04:10,980
one-size-fits-all approach which at best

110
00:04:10,980 --> 00:04:13,080
is pretty ignorant and at work is

111
00:04:13,080 --> 00:04:14,519
actually quite dangerous and can really

112
00:04:14,519 --> 00:04:17,459
have an impact on people's lives a lot

113
00:04:17,459 --> 00:04:19,079
of security researchers or security

114
00:04:19,079 --> 00:04:21,600
Engineers or experts are not always the

115
00:04:21,600 --> 00:04:25,020
best teachers for for a number of

116
00:04:25,020 --> 00:04:27,600
reasons but one of the main ones is

117
00:04:27,600 --> 00:04:29,940
about context and lacking context or not

118
00:04:29,940 --> 00:04:31,500
having enough context about the

119
00:04:31,500 --> 00:04:33,060
situation that you're in

120
00:04:33,060 --> 00:04:36,180
so we all know the Trope new signal you

121
00:04:36,180 --> 00:04:38,100
store we can apply it in any situation

122
00:04:38,100 --> 00:04:41,280
supposedly but for a long time living in

123
00:04:41,280 --> 00:04:43,020
the Middle East it was actually really

124
00:04:43,020 --> 00:04:44,880
really difficult to use signal you could

125
00:04:44,880 --> 00:04:45,840
be

126
00:04:45,840 --> 00:04:49,440
in any sort of situation Gathering and

127
00:04:49,440 --> 00:04:51,300
you're sending a signal message to

128
00:04:51,300 --> 00:04:53,340
someone you have no idea if they're

129
00:04:53,340 --> 00:04:54,780
receiving it you have no idea if it's

130
00:04:54,780 --> 00:04:56,580
sent there was just a lot of high

131
00:04:56,580 --> 00:04:58,440
latency and it was very very hard to

132
00:04:58,440 --> 00:05:00,060
rely on Signal and that was the advice

133
00:05:00,060 --> 00:05:02,040
that was being given especially in the

134
00:05:02,040 --> 00:05:03,900
context of a protest

135
00:05:03,900 --> 00:05:06,300
and sometimes it goes beyond latency

136
00:05:06,300 --> 00:05:09,180
sometimes signal is actually kind of

137
00:05:09,180 --> 00:05:11,340
banned or it's used as criminalized if

138
00:05:11,340 --> 00:05:12,960
someone stops you and see a signal on

139
00:05:12,960 --> 00:05:14,699
your phone that can get you into serious

140
00:05:14,699 --> 00:05:15,479
trouble

141
00:05:15,479 --> 00:05:17,820
so a lot of applications I guess a lot

142
00:05:17,820 --> 00:05:19,320
of applications are

143
00:05:19,320 --> 00:05:22,800
developed and tested in the US in Europe

144
00:05:22,800 --> 00:05:25,440
in the west generally but when it comes

145
00:05:25,440 --> 00:05:28,380
down to having to use it on the ground

146
00:05:28,380 --> 00:05:31,020
in different regions sometimes that can

147
00:05:31,020 --> 00:05:33,300
be incredibly dangerous or incredibly

148
00:05:33,300 --> 00:05:35,580
challenging especially for vulnerable

149
00:05:35,580 --> 00:05:36,900
populations

150
00:05:36,900 --> 00:05:39,539
so for the context of this talk when I

151
00:05:39,539 --> 00:05:41,160
mentioned vulnerable populations I'm

152
00:05:41,160 --> 00:05:42,360
talking about this specific group of

153
00:05:42,360 --> 00:05:44,340
people I'm talking about human rights

154
00:05:44,340 --> 00:05:45,900
offenders about journalists about

155
00:05:45,900 --> 00:05:48,360
activists about organizers vulnerable

156
00:05:48,360 --> 00:05:50,520
populations can Encompass a lot more but

157
00:05:50,520 --> 00:05:51,539
those are the folks that I have

158
00:05:51,539 --> 00:05:52,919
experience working with and this is

159
00:05:52,919 --> 00:05:54,240
basically what I'm talking about and

160
00:05:54,240 --> 00:05:56,160
what I'm referring to

161
00:05:56,160 --> 00:05:58,620
and security is very hard for these

162
00:05:58,620 --> 00:06:00,840
folks for a number of reasons a lot of

163
00:06:00,840 --> 00:06:02,820
them work independently they're

164
00:06:02,820 --> 00:06:04,020
independent journalists their

165
00:06:04,020 --> 00:06:07,020
Freelancers they lack the protection of

166
00:06:07,020 --> 00:06:09,660
a bigger organization which at times can

167
00:06:09,660 --> 00:06:11,400
have certain security practices or

168
00:06:11,400 --> 00:06:13,800
better security practices but here the

169
00:06:13,800 --> 00:06:15,300
responsibility the owners of the

170
00:06:15,300 --> 00:06:17,460
responsibility is on the individual

171
00:06:17,460 --> 00:06:18,600
itself

172
00:06:18,600 --> 00:06:21,060
so security is hard because of that you

173
00:06:21,060 --> 00:06:22,380
are essentially holding the entire

174
00:06:22,380 --> 00:06:25,380
responsibility of your own security

175
00:06:25,380 --> 00:06:28,080
if the person actually belongs to a

176
00:06:28,080 --> 00:06:32,039
larger organization uh most more often

177
00:06:32,039 --> 00:06:33,660
than not these organizations are

178
00:06:33,660 --> 00:06:36,419
severely under-resourced either from a

179
00:06:36,419 --> 00:06:39,180
Personnel perspective or financially and

180
00:06:39,180 --> 00:06:41,280
that really prevents them from investing

181
00:06:41,280 --> 00:06:44,580
in their privacy and security standing

182
00:06:44,580 --> 00:06:46,199
and then finally security is hard

183
00:06:46,199 --> 00:06:49,380
because really of digital security and

184
00:06:49,380 --> 00:06:52,259
literacy it is hard to recognize attacks

185
00:06:52,259 --> 00:06:55,020
and it is even harder to understand how

186
00:06:55,020 --> 00:06:56,880
to protect yourself against these

187
00:06:56,880 --> 00:06:59,340
attacks there's not enough information

188
00:06:59,340 --> 00:07:02,160
and that essentially makes it very

189
00:07:02,160 --> 00:07:03,479
difficult

190
00:07:03,479 --> 00:07:05,600
and the stakes are very high

191
00:07:05,600 --> 00:07:08,880
very often and you've again heard it

192
00:07:08,880 --> 00:07:10,620
from the previous two talks the stakes

193
00:07:10,620 --> 00:07:12,840
are high because digital attacks very

194
00:07:12,840 --> 00:07:14,639
often are

195
00:07:14,639 --> 00:07:17,280
um intersect with real world physical

196
00:07:17,280 --> 00:07:20,039
violence what you see on the screen is a

197
00:07:20,039 --> 00:07:22,080
project from this group called forensic

198
00:07:22,080 --> 00:07:23,880
architecture which is a research group

199
00:07:23,880 --> 00:07:25,759
based out of the University of London

200
00:07:25,759 --> 00:07:28,860
who they use basically architectural

201
00:07:28,860 --> 00:07:31,080
techniques and Technologies to

202
00:07:31,080 --> 00:07:33,120
investigate cases of Human Rights abuses

203
00:07:33,120 --> 00:07:34,860
in the world and they worked on this

204
00:07:34,860 --> 00:07:38,759
project in 2021 which shows essentially

205
00:07:38,759 --> 00:07:42,479
patterns of incidents between the

206
00:07:42,479 --> 00:07:44,400
physical and digital sphere the physical

207
00:07:44,400 --> 00:07:48,780
is in red the digital is in blue and

208
00:07:48,780 --> 00:07:51,919
they essentially shows how infections of

209
00:07:51,919 --> 00:07:55,620
spyware in this case Pegasus from NSO

210
00:07:55,620 --> 00:07:57,060
group how infections from spyware

211
00:07:57,060 --> 00:07:59,160
essentially are entangled with real

212
00:07:59,160 --> 00:08:02,460
world violence and extend in the

213
00:08:02,460 --> 00:08:05,099
professional and the personal spheres

214
00:08:05,099 --> 00:08:06,720
and networks of the folks who were

215
00:08:06,720 --> 00:08:09,120
targeted in this case again we're

216
00:08:09,120 --> 00:08:11,240
talking about journalists organizers

217
00:08:11,240 --> 00:08:15,780
human rights activists and all

218
00:08:15,780 --> 00:08:18,479
and the field is very complicated and

219
00:08:18,479 --> 00:08:19,979
that's part of why it's hard to talk

220
00:08:19,979 --> 00:08:22,020
about security and human rights because

221
00:08:22,020 --> 00:08:23,400
it really I mean there's so many

222
00:08:23,400 --> 00:08:25,379
different areas of expertise you could

223
00:08:25,379 --> 00:08:27,599
be talking or working on internet

224
00:08:27,599 --> 00:08:29,520
shutdowns you could be working on state

225
00:08:29,520 --> 00:08:31,259
surveillance you could be working on

226
00:08:31,259 --> 00:08:33,059
social media and online identity on

227
00:08:33,059 --> 00:08:35,580
organizational Security on reverse

228
00:08:35,580 --> 00:08:37,440
engineering phones of people who have

229
00:08:37,440 --> 00:08:39,000
been targeted and who have been hacked

230
00:08:39,000 --> 00:08:41,339
by nation state actors you could be

231
00:08:41,339 --> 00:08:43,740
talking about travel security and what

232
00:08:43,740 --> 00:08:45,120
it means to cross a border with

233
00:08:45,120 --> 00:08:46,620
sensitive information what it means to

234
00:08:46,620 --> 00:08:48,600
enter a different country really there's

235
00:08:48,600 --> 00:08:51,060
a lot of different categories here and

236
00:08:51,060 --> 00:08:52,500
they all kind of intersect together if

237
00:08:52,500 --> 00:08:54,300
you're doing this type of work so to

238
00:08:54,300 --> 00:08:55,800
illustrate it a little bit I'm going to

239
00:08:55,800 --> 00:08:58,440
walk through about four examples of what

240
00:08:58,440 --> 00:09:00,779
essentially a day in the life

241
00:09:00,779 --> 00:09:03,899
of someone like myself who works at this

242
00:09:03,899 --> 00:09:05,880
intersection of security and human

243
00:09:05,880 --> 00:09:07,680
rights or privacy and human rights what

244
00:09:07,680 --> 00:09:09,180
are some of the types of challenges that

245
00:09:09,180 --> 00:09:10,980
come up

246
00:09:10,980 --> 00:09:12,660
so the first example that I have is out

247
00:09:12,660 --> 00:09:15,060
of Egypt I was working with a group of

248
00:09:15,060 --> 00:09:16,680
folks who were actually coming into the

249
00:09:16,680 --> 00:09:18,060
country and trying to understand the

250
00:09:18,060 --> 00:09:20,700
situation there and how to essentially

251
00:09:20,700 --> 00:09:23,040
cross into the country how to how to

252
00:09:23,040 --> 00:09:25,980
navigate to just being around Cairo

253
00:09:25,980 --> 00:09:26,700
um

254
00:09:26,700 --> 00:09:29,399
in Egypt one of the big concerns is

255
00:09:29,399 --> 00:09:31,320
around device seizure you could be

256
00:09:31,320 --> 00:09:33,060
walking down the street in Cairo you

257
00:09:33,060 --> 00:09:34,920
will be stopped by the police the police

258
00:09:34,920 --> 00:09:37,019
will ask to see your phone and we'll go

259
00:09:37,019 --> 00:09:39,660
through your phone and then if you have

260
00:09:39,660 --> 00:09:42,060
certain apps on your phone that are kind

261
00:09:42,060 --> 00:09:44,580
of deemed suspicious like if you have

262
00:09:44,580 --> 00:09:46,860
signal or if you have a VPN or if you

263
00:09:46,860 --> 00:09:49,560
have Tor or if you have an LGBT dating

264
00:09:49,560 --> 00:09:51,720
app that could immediately mean that

265
00:09:51,720 --> 00:09:53,700
you'll be taken into interrogation taken

266
00:09:53,700 --> 00:09:55,500
into really just spending like a few

267
00:09:55,500 --> 00:09:57,120
days in jail

268
00:09:57,120 --> 00:09:58,980
um and being questioned about why you

269
00:09:58,980 --> 00:10:01,019
have this application on your phone

270
00:10:01,019 --> 00:10:03,360
however in the context of Egypt what's

271
00:10:03,360 --> 00:10:06,600
interesting is that also not having

272
00:10:06,600 --> 00:10:08,880
certain apps is deemed kind of

273
00:10:08,880 --> 00:10:11,040
suspicious so if you do not have

274
00:10:11,040 --> 00:10:12,839
Facebook if you kind of entered the

275
00:10:12,839 --> 00:10:14,700
situation telling yourself you know what

276
00:10:14,700 --> 00:10:16,320
I'm going to delete Facebook from my

277
00:10:16,320 --> 00:10:18,000
phone I'm going to sanitize my device a

278
00:10:18,000 --> 00:10:20,339
bit that way I will be protecting my

279
00:10:20,339 --> 00:10:23,339
information or my privacy if you do not

280
00:10:23,339 --> 00:10:25,740
have Facebook on your phone that is also

281
00:10:25,740 --> 00:10:27,720
deemed suspicious in the context of

282
00:10:27,720 --> 00:10:29,700
Egypt because who wouldn't have Facebook

283
00:10:29,700 --> 00:10:31,140
on their phone in Egypt everyone has

284
00:10:31,140 --> 00:10:33,720
Facebook on their phone in Egypt so

285
00:10:33,720 --> 00:10:36,660
having sometimes a device that is way

286
00:10:36,660 --> 00:10:39,839
too sanitized can get you in trouble or

287
00:10:39,839 --> 00:10:42,180
can raise suspicions and that doesn't

288
00:10:42,180 --> 00:10:44,700
only apply for the Egypt context that

289
00:10:44,700 --> 00:10:47,820
also applies in situations of uh

290
00:10:47,820 --> 00:10:49,980
domestic violence for example

291
00:10:49,980 --> 00:10:52,560
um where if your device is too sanitized

292
00:10:52,560 --> 00:10:53,880
and you've Deleted things like your

293
00:10:53,880 --> 00:10:55,380
search history that could also kind of

294
00:10:55,380 --> 00:10:59,160
raise suspicions from an abusive partner

295
00:10:59,160 --> 00:11:01,440
the second example I have is from

296
00:11:01,440 --> 00:11:05,399
Lebanon in 2019 Lebanon had a revolution

297
00:11:05,399 --> 00:11:07,560
I'm Lebanese I grew up there I spend the

298
00:11:07,560 --> 00:11:09,120
majority of my life there

299
00:11:09,120 --> 00:11:11,880
um I was there in 2019 at the beginning

300
00:11:11,880 --> 00:11:13,920
of the Revolution and I spent a lot of

301
00:11:13,920 --> 00:11:16,620
time working with activists and

302
00:11:16,620 --> 00:11:18,959
journalists on the ground on securing

303
00:11:18,959 --> 00:11:20,820
their devices

304
00:11:20,820 --> 00:11:23,040
um onto on protecting themselves on

305
00:11:23,040 --> 00:11:25,980
understanding the capabilities of the

306
00:11:25,980 --> 00:11:27,779
government and what they could surveil

307
00:11:27,779 --> 00:11:28,980
what they could intercept what they

308
00:11:28,980 --> 00:11:30,540
could see what they couldn't

309
00:11:30,540 --> 00:11:32,339
and I spent a lot of time there doing

310
00:11:32,339 --> 00:11:36,720
this and came back to the US covid

311
00:11:36,720 --> 00:11:38,880
happened mid-2020

312
00:11:38,880 --> 00:11:40,800
the George Floyd protest started

313
00:11:40,800 --> 00:11:41,700
happening

314
00:11:41,700 --> 00:11:45,959
myself and a few other activists from

315
00:11:45,959 --> 00:11:47,940
Lebanon very quickly and that first week

316
00:11:47,940 --> 00:11:50,160
essentially put together a guide a

317
00:11:50,160 --> 00:11:52,079
security guide for protests

318
00:11:52,079 --> 00:11:54,480
and it went quite viral which we were

319
00:11:54,480 --> 00:11:56,640
not expecting but what we did is

320
00:11:56,640 --> 00:11:58,860
essentially borrow a lot of advice that

321
00:11:58,860 --> 00:12:01,800
we had that we had learned in Lebanon

322
00:12:01,800 --> 00:12:03,839
that we had borrowed ourselves from

323
00:12:03,839 --> 00:12:06,720
Chile from Hong Kong from things that

324
00:12:06,720 --> 00:12:08,760
have happened on the ground there we put

325
00:12:08,760 --> 00:12:10,200
all this together essentially in a guide

326
00:12:10,200 --> 00:12:13,380
that we shared for protesters and

327
00:12:13,380 --> 00:12:16,880
demonstrators in the U.S

328
00:12:17,459 --> 00:12:19,860
more recently in the context of Myanmar

329
00:12:19,860 --> 00:12:21,120
and Ukraine

330
00:12:21,120 --> 00:12:23,700
I was asked to provide security Advice

331
00:12:23,700 --> 00:12:26,399
security and privacy advice on satellite

332
00:12:26,399 --> 00:12:28,579
communication for journalists

333
00:12:28,579 --> 00:12:31,019
what are the security implications of it

334
00:12:31,019 --> 00:12:32,459
what are the Privacy implications of it

335
00:12:32,459 --> 00:12:34,079
what does it mean to use Satellite

336
00:12:34,079 --> 00:12:35,700
Communication what does it mean to get

337
00:12:35,700 --> 00:12:37,620
data in and out of the country

338
00:12:37,620 --> 00:12:39,120
especially in the context of an Internet

339
00:12:39,120 --> 00:12:40,920
shutdown especially in the context of

340
00:12:40,920 --> 00:12:42,600
having to deal with the capabilities of

341
00:12:42,600 --> 00:12:44,459
the Russian government

342
00:12:44,459 --> 00:12:47,459
um can they triangulate my location can

343
00:12:47,459 --> 00:12:48,899
they find out where I am can I

344
00:12:48,899 --> 00:12:50,639
communicate safely with my colleagues

345
00:12:50,639 --> 00:12:52,139
can I get this information out of the

346
00:12:52,139 --> 00:12:54,480
country what are the real implications

347
00:12:54,480 --> 00:12:57,600
basically that my use of satellite

348
00:12:57,600 --> 00:12:59,220
equipment will have on my personal

349
00:12:59,220 --> 00:13:01,320
safety and on the safety of my

350
00:13:01,320 --> 00:13:03,500
colleagues

351
00:13:03,500 --> 00:13:06,180
and then my final example here is from

352
00:13:06,180 --> 00:13:08,639
Afghanistan a couple of years ago I was

353
00:13:08,639 --> 00:13:11,639
asked to provide essentially or to work

354
00:13:11,639 --> 00:13:13,260
with an organization a human rights

355
00:13:13,260 --> 00:13:15,660
organization in Afghanistan on

356
00:13:15,660 --> 00:13:17,579
essentially kind of

357
00:13:17,579 --> 00:13:20,100
bolstering their security their

358
00:13:20,100 --> 00:13:22,320
organizational security stands and I

359
00:13:22,320 --> 00:13:24,060
kind of went into this having some

360
00:13:24,060 --> 00:13:26,519
assumptions at least about the way that

361
00:13:26,519 --> 00:13:28,920
their I.T setup was I assumed that

362
00:13:28,920 --> 00:13:30,959
everyone had a computer I assumed that

363
00:13:30,959 --> 00:13:32,820
everyone had the email address or there

364
00:13:32,820 --> 00:13:35,279
were some accounts to to deal with and

365
00:13:35,279 --> 00:13:37,260
very quickly actually I learned that

366
00:13:37,260 --> 00:13:40,320
every about five employees were sharing

367
00:13:40,320 --> 00:13:42,540
one device

368
00:13:42,540 --> 00:13:45,000
um I learned that all these devices were

369
00:13:45,000 --> 00:13:46,500
actually quite old and hadn't been

370
00:13:46,500 --> 00:13:48,180
updated in a very long time and were

371
00:13:48,180 --> 00:13:50,760
barely working a lot of these devices

372
00:13:50,760 --> 00:13:53,220
had very questionable software as in

373
00:13:53,220 --> 00:13:56,279
pirated versions of Microsoft Word with

374
00:13:56,279 --> 00:13:57,860
a lot of vulnerabilities

375
00:13:57,860 --> 00:14:02,420
and in this case this organization had

376
00:14:02,420 --> 00:14:05,700
received a security training from folks

377
00:14:05,700 --> 00:14:08,519
who had come from the US

378
00:14:08,519 --> 00:14:10,860
given a security training for two days

379
00:14:10,860 --> 00:14:13,680
and giving them advice such as Google is

380
00:14:13,680 --> 00:14:15,060
dangerous like Google will steal your

381
00:14:15,060 --> 00:14:16,500
information don't use this don't use

382
00:14:16,500 --> 00:14:17,760
that actually let's set you up on

383
00:14:17,760 --> 00:14:19,980
Alternate Services we're going to set up

384
00:14:19,980 --> 00:14:21,480
an email account here we're going to set

385
00:14:21,480 --> 00:14:23,639
up like a data account here and what

386
00:14:23,639 --> 00:14:25,079
ended up happening is that they did all

387
00:14:25,079 --> 00:14:26,760
of this in about two days

388
00:14:26,760 --> 00:14:28,740
everyone eventually got locked out of

389
00:14:28,740 --> 00:14:30,420
their accounts they couldn't really

390
00:14:30,420 --> 00:14:32,100
reset passwords because it would lead

391
00:14:32,100 --> 00:14:33,660
them to a different email that they did

392
00:14:33,660 --> 00:14:35,399
not have access to anymore they couldn't

393
00:14:35,399 --> 00:14:38,220
have access to their data and to the

394
00:14:38,220 --> 00:14:39,779
research I mean it was just a mess like

395
00:14:39,779 --> 00:14:41,160
everything they were just locked out of

396
00:14:41,160 --> 00:14:42,959
accounts and all of that because

397
00:14:42,959 --> 00:14:44,940
essentially of this kind of parachuting

398
00:14:44,940 --> 00:14:48,079
in type of advice where security

399
00:14:48,079 --> 00:14:50,459
Security Experts essentially had come

400
00:14:50,459 --> 00:14:53,339
into this situation given them a certain

401
00:14:53,339 --> 00:14:55,199
type of advice changed everything in

402
00:14:55,199 --> 00:14:56,459
about two days and then walked out of

403
00:14:56,459 --> 00:14:58,939
the situation

404
00:14:59,339 --> 00:15:01,620
so those are some of the challenges and

405
00:15:01,620 --> 00:15:04,079
some of the I mean really like a day in

406
00:15:04,079 --> 00:15:06,839
the life of a security researcher who

407
00:15:06,839 --> 00:15:09,180
works with vulnerable populations or

408
00:15:09,180 --> 00:15:11,820
works on human rights cases

409
00:15:11,820 --> 00:15:13,680
if this seems interesting to you and

410
00:15:13,680 --> 00:15:15,180
you're like yes you know what like I

411
00:15:15,180 --> 00:15:16,380
want to be doing something like this

412
00:15:16,380 --> 00:15:18,959
like I want to be aligned with the work

413
00:15:18,959 --> 00:15:21,600
that I do what does it take to be a

414
00:15:21,600 --> 00:15:23,220
public interest technologist like how

415
00:15:23,220 --> 00:15:25,440
how do you build a career in this field

416
00:15:25,440 --> 00:15:26,820
and this is a lot of the questions that

417
00:15:26,820 --> 00:15:27,959
I had gotten last year when I was

418
00:15:27,959 --> 00:15:29,639
talking about the work that I did

419
00:15:29,639 --> 00:15:32,279
so there's not really One path into this

420
00:15:32,279 --> 00:15:33,540
work

421
00:15:33,540 --> 00:15:34,740
um because of a number of different

422
00:15:34,740 --> 00:15:37,079
reasons it's it's pretty challenging and

423
00:15:37,079 --> 00:15:38,699
sometimes impossible to think about how

424
00:15:38,699 --> 00:15:40,860
to get into this type of work because

425
00:15:40,860 --> 00:15:43,199
there is a lack of consistency there's a

426
00:15:43,199 --> 00:15:45,440
lack of structure there are not a lot of

427
00:15:45,440 --> 00:15:48,060
opportunities you can't easily go to a

428
00:15:48,060 --> 00:15:51,360
job database and find security human

429
00:15:51,360 --> 00:15:53,459
rights or secure Technologies public

430
00:15:53,459 --> 00:15:55,620
interest technologists

431
00:15:55,620 --> 00:15:58,260
um but there is a network of people that

432
00:15:58,260 --> 00:16:00,779
does that do this work like there is a

433
00:16:00,779 --> 00:16:02,699
Global Network a community of cyber

434
00:16:02,699 --> 00:16:05,100
security professionals who basically

435
00:16:05,100 --> 00:16:07,079
like their entire job is to protect and

436
00:16:07,079 --> 00:16:09,420
Safeguard Freedom human rights they're

437
00:16:09,420 --> 00:16:11,519
kind of like a cyber Justice League that

438
00:16:11,519 --> 00:16:13,260
works for the benefit of civil society

439
00:16:13,260 --> 00:16:15,540
and for the benefit of Human Rights they

440
00:16:15,540 --> 00:16:18,720
work to protect vulnerable populations

441
00:16:18,720 --> 00:16:19,920
um and there's a lot of people at the

442
00:16:19,920 --> 00:16:21,300
front line of this work I've been into

443
00:16:21,300 --> 00:16:22,980
I've been in this work for about a

444
00:16:22,980 --> 00:16:25,500
decade and I remember when I had and I

445
00:16:25,500 --> 00:16:26,940
came into it through the human rights

446
00:16:26,940 --> 00:16:29,760
angle and when I started doing it I

447
00:16:29,760 --> 00:16:31,440
remember the field was so small I mean

448
00:16:31,440 --> 00:16:33,060
we all knew each other we show up at a

449
00:16:33,060 --> 00:16:35,279
conference we were a handful of people

450
00:16:35,279 --> 00:16:38,339
100 200 right now we're talking about

451
00:16:38,339 --> 00:16:41,040
thousand plus colleagues that I can see

452
00:16:41,040 --> 00:16:42,480
and recognize when I go to these

453
00:16:42,480 --> 00:16:44,399
conferences so I've definitely seen this

454
00:16:44,399 --> 00:16:46,860
field evolve and it's become a lot more

455
00:16:46,860 --> 00:16:49,500
obvious today the intersection of

456
00:16:49,500 --> 00:16:51,120
technology and human rights or the

457
00:16:51,120 --> 00:16:53,339
intersection or understanding how

458
00:16:53,339 --> 00:16:55,980
technology has a very real and serious

459
00:16:55,980 --> 00:16:58,139
impact on people's lives and on human

460
00:16:58,139 --> 00:17:00,180
rights

461
00:17:00,180 --> 00:17:02,339
there are a lot of ways to get involved

462
00:17:02,339 --> 00:17:03,660
in this work

463
00:17:03,660 --> 00:17:05,099
there are a lot of conferences

464
00:17:05,099 --> 00:17:06,959
essentially that you can attend where

465
00:17:06,959 --> 00:17:08,459
you get to meet

466
00:17:08,459 --> 00:17:11,160
really like everyone kind of working on

467
00:17:11,160 --> 00:17:13,140
different aspects and different sides of

468
00:17:13,140 --> 00:17:15,599
this issue uh you may get to meet

469
00:17:15,599 --> 00:17:16,859
technologists you get to meet security

470
00:17:16,859 --> 00:17:18,780
expert you get to meet

471
00:17:18,780 --> 00:17:21,059
um the activists that are on the front

472
00:17:21,059 --> 00:17:23,819
lines of this work you get to meet

473
00:17:23,819 --> 00:17:25,079
um

474
00:17:25,079 --> 00:17:26,939
technologists human rights all the

475
00:17:26,939 --> 00:17:28,919
lawyers who are doing this work as well

476
00:17:28,919 --> 00:17:30,600
really kind of like everyone that's part

477
00:17:30,600 --> 00:17:32,280
of this community and you get to learn

478
00:17:32,280 --> 00:17:34,500
from them really like take the time to

479
00:17:34,500 --> 00:17:36,900
connect with experts take the time to

480
00:17:36,900 --> 00:17:38,820
talk to these people and to sit in on

481
00:17:38,820 --> 00:17:40,799
things that you might assume that you

482
00:17:40,799 --> 00:17:42,240
already know like someone is giving a

483
00:17:42,240 --> 00:17:44,280
security Workshop I'm a security

484
00:17:44,280 --> 00:17:46,140
professional like I know this I don't

485
00:17:46,140 --> 00:17:47,280
need to sit there but you will learn

486
00:17:47,280 --> 00:17:49,380
something because it's so context

487
00:17:49,380 --> 00:17:50,580
specific

488
00:17:50,580 --> 00:17:52,440
there are a lot of fellowships as well

489
00:17:52,440 --> 00:17:54,840
there are a lot of funding opportunities

490
00:17:54,840 --> 00:17:57,179
um OTF for instance the organization I

491
00:17:57,179 --> 00:18:00,179
used to work for supports research and

492
00:18:00,179 --> 00:18:01,980
app development application development

493
00:18:01,980 --> 00:18:04,620
Under the Umbrella of Internet freedom

494
00:18:04,620 --> 00:18:07,620
from last year Enigma essentially I

495
00:18:07,620 --> 00:18:09,179
connected a lot a lot of people who

496
00:18:09,179 --> 00:18:11,100
eventually applied for funding at OTF

497
00:18:11,100 --> 00:18:12,960
which was really wonderful to see and

498
00:18:12,960 --> 00:18:14,220
there are a lot of organizations that

499
00:18:14,220 --> 00:18:16,320
also do this work

500
00:18:16,320 --> 00:18:18,360
so back to my story

501
00:18:18,360 --> 00:18:20,580
we got the tech Bros we got the yemeni

502
00:18:20,580 --> 00:18:23,820
refugees but essentially as the security

503
00:18:23,820 --> 00:18:26,039
Engineers walked out I stayed with the

504
00:18:26,039 --> 00:18:28,380
with the folks in the room and we got to

505
00:18:28,380 --> 00:18:31,140
to speak we got to speak in Arabic and

506
00:18:31,140 --> 00:18:33,120
eventually the entire as as you probably

507
00:18:33,120 --> 00:18:35,100
expected the entire security Workshop

508
00:18:35,100 --> 00:18:37,380
kind of went over their heads

509
00:18:37,380 --> 00:18:39,299
most of these people did not even have

510
00:18:39,299 --> 00:18:42,179
email addresses they were sharing one

511
00:18:42,179 --> 00:18:44,520
device like one phone for the entire

512
00:18:44,520 --> 00:18:45,720
family

513
00:18:45,720 --> 00:18:47,820
and really their main worry was about

514
00:18:47,820 --> 00:18:49,620
human trafficking they had just gone to

515
00:18:49,620 --> 00:18:51,000
the US they were trying to understand

516
00:18:51,000 --> 00:18:53,220
how to navigate the job market and how

517
00:18:53,220 --> 00:18:55,260
to not enter like essentially a scheme

518
00:18:55,260 --> 00:18:57,780
of human trafficking

519
00:18:57,780 --> 00:19:01,620
and so talking about email 2fa password

520
00:19:01,620 --> 00:19:04,140
management that was really completely

521
00:19:04,140 --> 00:19:06,000
irrelevant for this group and it doesn't

522
00:19:06,000 --> 00:19:08,100
mean that these two planets can never

523
00:19:08,100 --> 00:19:10,559
intersect it just means that there there

524
00:19:10,559 --> 00:19:12,720
is work to be done

525
00:19:12,720 --> 00:19:14,340
and that work looks like a lot of

526
00:19:14,340 --> 00:19:15,960
different things right one is really be

527
00:19:15,960 --> 00:19:17,760
humble there's a lot that you don't know

528
00:19:17,760 --> 00:19:19,500
and this is where you should start even

529
00:19:19,500 --> 00:19:22,020
for me being Lebanese when I was in that

530
00:19:22,020 --> 00:19:23,760
context in 2019 in the middle of the

531
00:19:23,760 --> 00:19:26,220
Revolution I spent time talking to

532
00:19:26,220 --> 00:19:27,780
activists there and to journalists there

533
00:19:27,780 --> 00:19:29,520
to understand the context that I had

534
00:19:29,520 --> 00:19:31,980
essentially missed in the years of being

535
00:19:31,980 --> 00:19:33,960
in the US what was new what was

536
00:19:33,960 --> 00:19:35,460
different what do I need to know how do

537
00:19:35,460 --> 00:19:37,380
I work with you how do I co-design with

538
00:19:37,380 --> 00:19:38,700
you

539
00:19:38,700 --> 00:19:40,980
security advice basically that fits the

540
00:19:40,980 --> 00:19:43,620
context that you are in I still ask

541
00:19:43,620 --> 00:19:44,760
questions

542
00:19:44,760 --> 00:19:47,460
like I said attend workshops led by the

543
00:19:47,460 --> 00:19:49,380
community even if you think you know

544
00:19:49,380 --> 00:19:51,120
like I mean I've sat in on so many

545
00:19:51,120 --> 00:19:52,620
workshops talking about two-factor

546
00:19:52,620 --> 00:19:54,660
authentication and password management

547
00:19:54,660 --> 00:19:56,520
but I will still do it because I will

548
00:19:56,520 --> 00:19:58,500
always learn something new from the

549
00:19:58,500 --> 00:20:00,480
questions that arise from this very

550
00:20:00,480 --> 00:20:02,760
specific context of the people that

551
00:20:02,760 --> 00:20:05,100
we're working with

552
00:20:05,100 --> 00:20:07,500
the importance of harm reduction

553
00:20:07,500 --> 00:20:09,419
is very very crucial to meet people

554
00:20:09,419 --> 00:20:11,340
where they are and to understand the

555
00:20:11,340 --> 00:20:12,780
context again that they're working and

556
00:20:12,780 --> 00:20:14,720
telling folks to just not use Facebook

557
00:20:14,720 --> 00:20:17,280
doesn't make a lot of sense because in a

558
00:20:17,280 --> 00:20:19,500
lot of places in the world Facebook is

559
00:20:19,500 --> 00:20:21,480
equivalent to the internet this is how

560
00:20:21,480 --> 00:20:23,700
people communicate so telling them to

561
00:20:23,700 --> 00:20:25,380
not use it doesn't really make any sense

562
00:20:25,380 --> 00:20:27,660
and really could harm them instead how

563
00:20:27,660 --> 00:20:29,160
can you use it differently how can you

564
00:20:29,160 --> 00:20:31,500
use it in a way that feels safer or that

565
00:20:31,500 --> 00:20:33,539
protects your privacy a little bit more

566
00:20:33,539 --> 00:20:35,400
and always question your assumptions

567
00:20:35,400 --> 00:20:38,160
like the Afghanistan example I went in

568
00:20:38,160 --> 00:20:40,400
thinking there was at least a base six

569
00:20:40,400 --> 00:20:43,140
semi-functioning I.T setup quickly

570
00:20:43,140 --> 00:20:45,120
proven wrong question your assumptions

571
00:20:45,120 --> 00:20:47,220
ask questions

572
00:20:47,220 --> 00:20:48,840
and then finally designed from the

573
00:20:48,840 --> 00:20:51,720
margins I'm borrowing this term or this

574
00:20:51,720 --> 00:20:53,280
expression from a colleague of mine

575
00:20:53,280 --> 00:20:56,100
named after who's a researcher at an

576
00:20:56,100 --> 00:20:58,620
organization called article 19.

577
00:20:58,620 --> 00:21:01,440
who basically the idea is that when

578
00:21:01,440 --> 00:21:03,720
you're building tools you need to Center

579
00:21:03,720 --> 00:21:07,020
and design for the most high risk users

580
00:21:07,020 --> 00:21:09,120
technology is never neutral

581
00:21:09,120 --> 00:21:11,160
the way that we make it the way that we

582
00:21:11,160 --> 00:21:13,140
conceptualize it the way that we imagine

583
00:21:13,140 --> 00:21:15,600
where it fits in our culture the

584
00:21:15,600 --> 00:21:17,220
problems that it's going to solve these

585
00:21:17,220 --> 00:21:19,679
are all design choices that have a deep

586
00:21:19,679 --> 00:21:21,720
impact on society

587
00:21:21,720 --> 00:21:24,120
and very often people build tools for

588
00:21:24,120 --> 00:21:26,460
other people who kind of look like them

589
00:21:26,460 --> 00:21:28,260
and it doesn't really account for the

590
00:21:28,260 --> 00:21:30,299
needs of folks who have been

591
00:21:30,299 --> 00:21:32,340
historically marginalized and targeted

592
00:21:32,340 --> 00:21:34,799
so as you're building tools if this is

593
00:21:34,799 --> 00:21:36,539
your job and this is what you do always

594
00:21:36,539 --> 00:21:38,700
ask yourself like what is the worst case

595
00:21:38,700 --> 00:21:40,500
that can happen like what is the worst

596
00:21:40,500 --> 00:21:42,659
thing that could happen in in this

597
00:21:42,659 --> 00:21:44,400
situation or in a different context and

598
00:21:44,400 --> 00:21:47,100
we've seen it again this point has been

599
00:21:47,100 --> 00:21:49,020
driven home I think by by my colleagues

600
00:21:49,020 --> 00:21:51,240
as well and plan for the plan for those

601
00:21:51,240 --> 00:21:53,400
cases try to plan for those cases as

602
00:21:53,400 --> 00:21:55,559
much as possible in the Egypt example

603
00:21:55,559 --> 00:21:57,600
again we're talking about device seizure

604
00:21:57,600 --> 00:22:00,480
a very interesting case actually that

605
00:22:00,480 --> 00:22:04,200
the same calling afsan I worked on is uh

606
00:22:04,200 --> 00:22:08,460
when your phone is confiscated if the

607
00:22:08,460 --> 00:22:11,159
police were to find grinder on your

608
00:22:11,159 --> 00:22:13,260
phone and Grindr is an LGBT dating app

609
00:22:13,260 --> 00:22:15,720
if they find Grindr on your phone that

610
00:22:15,720 --> 00:22:17,640
means that they will take you to jail

611
00:22:17,640 --> 00:22:18,960
immediately

612
00:22:18,960 --> 00:22:22,260
what does it mean to design the

613
00:22:22,260 --> 00:22:24,480
application icon differently to make it

614
00:22:24,480 --> 00:22:27,120
look maybe like a calculator or like a

615
00:22:27,120 --> 00:22:29,340
notepad so that when you are in a

616
00:22:29,340 --> 00:22:32,220
situation in which your device is seized

617
00:22:32,220 --> 00:22:33,840
then it doesn't look like you have an

618
00:22:33,840 --> 00:22:36,720
LGBT dating app on your phone these are

619
00:22:36,720 --> 00:22:38,280
changes actually that Grindr has

620
00:22:38,280 --> 00:22:41,100
implemented after feedback from these

621
00:22:41,100 --> 00:22:42,179
researchers which was a really

622
00:22:42,179 --> 00:22:44,280
interesting case and I'm happy to share

623
00:22:44,280 --> 00:22:47,159
that research with folks afterwards

624
00:22:47,159 --> 00:22:49,320
I'm going to leave you with this very

625
00:22:49,320 --> 00:22:50,880
very wise quote

626
00:22:50,880 --> 00:22:53,039
the more we learn the more we discover

627
00:22:53,039 --> 00:22:55,860
how much we do not know

628
00:22:55,860 --> 00:22:58,740
said by none other than yodel thank you

629
00:22:58,740 --> 00:23:00,620
Yoda for your wisdom

630
00:23:00,620 --> 00:23:03,900
and with that we've got a few minutes

631
00:23:03,900 --> 00:23:06,900
for questions and then lunch and this is

632
00:23:06,900 --> 00:23:11,480
where you can find me here and outside

633
00:23:11,610 --> 00:23:15,060
[Applause]

