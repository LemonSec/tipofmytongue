1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:18,320 --> 00:00:22,920
is sneaky it tries to hide it tries to

3
00:00:22,920 --> 00:00:25,140
evade detection and to obfuscate its

4
00:00:25,140 --> 00:00:26,100
actions

5
00:00:26,100 --> 00:00:29,460
and it turns out that most of what we

6
00:00:29,460 --> 00:00:31,859
know about these sneaky behaviors comes

7
00:00:31,859 --> 00:00:34,320
from observing the malware samples in

8
00:00:34,320 --> 00:00:36,660
lab environments and in the next 20

9
00:00:36,660 --> 00:00:38,219
minutes I will tell you some of the

10
00:00:38,219 --> 00:00:40,140
lessons from the largest study of

11
00:00:40,140 --> 00:00:42,780
malware behavior in the wild where we

12
00:00:42,780 --> 00:00:44,640
looked at the how the behavior

13
00:00:44,640 --> 00:00:47,879
individual samples changes from one host

14
00:00:47,879 --> 00:00:52,680
to the next in one week to another

15
00:00:52,680 --> 00:00:55,860
now the main tool that we have today for

16
00:00:55,860 --> 00:00:58,320
analyzing for understanding uh malware

17
00:00:58,320 --> 00:01:00,000
behavior is called Dynamic malware

18
00:01:00,000 --> 00:01:03,840
analysis which involves collecting and

19
00:01:03,840 --> 00:01:07,020
analyzing execution traces

20
00:01:07,020 --> 00:01:10,020
um of these malware samples and this is

21
00:01:10,020 --> 00:01:11,760
in contrast to static analysis which

22
00:01:11,760 --> 00:01:14,280
involves analyzing the binaries

23
00:01:14,280 --> 00:01:16,619
now now Dynamic malware analysis has

24
00:01:16,619 --> 00:01:19,680
many applications such as creating rules

25
00:01:19,680 --> 00:01:21,720
and signatures for malware detection

26
00:01:21,720 --> 00:01:24,060
clustering malware samples into families

27
00:01:24,060 --> 00:01:26,220
and online detection understanding new

28
00:01:26,220 --> 00:01:28,680
malicious behaviors and campaigns attack

29
00:01:28,680 --> 00:01:31,400
attribution and many more

30
00:01:31,400 --> 00:01:35,759
and dynamic malware analysis is an

31
00:01:35,759 --> 00:01:37,560
experimental technique so you probably

32
00:01:37,560 --> 00:01:39,840
see something like this so

33
00:01:39,840 --> 00:01:41,299
um

34
00:01:41,299 --> 00:01:45,180
detection rates uh that are pretty high

35
00:01:45,180 --> 00:01:49,079
above 95 for fairly low false positive

36
00:01:49,079 --> 00:01:53,399
rates and if you the the situation is

37
00:01:53,399 --> 00:01:55,500
the same in research where there are

38
00:01:55,500 --> 00:01:58,200
many research papers published on new

39
00:01:58,200 --> 00:02:00,420
ideas for detecting malware most of them

40
00:02:00,420 --> 00:02:02,159
the evaluations report very high

41
00:02:02,159 --> 00:02:04,680
performance numbers uh to the point that

42
00:02:04,680 --> 00:02:06,540
there that they appear to leave very

43
00:02:06,540 --> 00:02:08,758
little room for improvement

44
00:02:08,758 --> 00:02:12,300
so this would make it seem that malware

45
00:02:12,300 --> 00:02:15,200
detection is a solved problem

46
00:02:15,200 --> 00:02:18,000
but unfortunately when these tools are

47
00:02:18,000 --> 00:02:20,760
deployed in the real world the

48
00:02:20,760 --> 00:02:22,500
performance is nowhere near to these

49
00:02:22,500 --> 00:02:25,080
numbers so in fact uh instead of

50
00:02:25,080 --> 00:02:26,879
reflecting a solved problem these

51
00:02:26,879 --> 00:02:28,860
numbers provide a false sense of

52
00:02:28,860 --> 00:02:29,879
security

53
00:02:29,879 --> 00:02:32,760
now we are fairly skeptical in this

54
00:02:32,760 --> 00:02:36,599
community uh so I bet that you can

55
00:02:36,599 --> 00:02:38,819
already think of a few reasons why this

56
00:02:38,819 --> 00:02:40,800
may be happening so I just want to

57
00:02:40,800 --> 00:02:42,239
clarify

58
00:02:42,239 --> 00:02:45,239
that

59
00:02:45,480 --> 00:02:47,760
this talk is not about

60
00:02:47,760 --> 00:02:51,120
flaws in experimental evaluations the

61
00:02:51,120 --> 00:02:54,540
base rate fallacy uh malware Evolution

62
00:02:54,540 --> 00:02:56,879
that leads to concept Drift actually for

63
00:02:56,879 --> 00:02:59,580
this one stick around for the next talk

64
00:02:59,580 --> 00:03:02,940
um or misleading marketing claims right

65
00:03:02,940 --> 00:03:06,060
even in the absence of all these

66
00:03:06,060 --> 00:03:09,959
problems the performance in the lab will

67
00:03:09,959 --> 00:03:11,640
not match the performance in the real

68
00:03:11,640 --> 00:03:12,480
world

69
00:03:12,480 --> 00:03:15,000
and to understand why let's take a

70
00:03:15,000 --> 00:03:16,860
closer look at how Dynamic analysis is

71
00:03:16,860 --> 00:03:18,599
done today

72
00:03:18,599 --> 00:03:20,519
so uh

73
00:03:20,519 --> 00:03:22,860
usually

74
00:03:22,860 --> 00:03:24,120
um

75
00:03:24,120 --> 00:03:26,400
most often actually the behavioral

76
00:03:26,400 --> 00:03:28,800
traces are collecting by executing the

77
00:03:28,800 --> 00:03:30,780
samples in a controlled environment

78
00:03:30,780 --> 00:03:33,959
called a Sandbox usually based on

79
00:03:33,959 --> 00:03:36,120
Virtual machines and this is an

80
00:03:36,120 --> 00:03:37,620
environment that prevents the malware

81
00:03:37,620 --> 00:03:40,319
samples from causing damage or for from

82
00:03:40,319 --> 00:03:42,000
from propagating

83
00:03:42,000 --> 00:03:45,440
however we know that in the real world

84
00:03:45,440 --> 00:03:49,440
the same hour sample may have different

85
00:03:49,440 --> 00:03:51,480
behaviors when it's executed on

86
00:03:51,480 --> 00:03:53,159
different hosts and at different times

87
00:03:53,159 --> 00:03:55,200
and researchers have coined the term

88
00:03:55,200 --> 00:03:56,940
split personalities for this type of

89
00:03:56,940 --> 00:03:58,200
behavior

90
00:03:58,200 --> 00:04:01,019
now this is not a New Concept

91
00:04:01,019 --> 00:04:03,840
um Security Professionals have known

92
00:04:03,840 --> 00:04:06,360
about split personalities for a while

93
00:04:06,360 --> 00:04:09,260
but this became

94
00:04:09,260 --> 00:04:12,540
a problem that that really came to the

95
00:04:12,540 --> 00:04:13,680
attention of the community there's

96
00:04:13,680 --> 00:04:15,299
something serious that needs to be fixed

97
00:04:15,299 --> 00:04:19,079
with a discovery of red pills which

98
00:04:19,079 --> 00:04:21,000
malware can use to detect that it's

99
00:04:21,000 --> 00:04:23,639
running inside of a virtual machine and

100
00:04:23,639 --> 00:04:26,340
therefore to uh to evade detection and

101
00:04:26,340 --> 00:04:27,419
Analysis

102
00:04:27,419 --> 00:04:30,080
now the first thread build dates from

103
00:04:30,080 --> 00:04:32,580
2004 but many more have been discovered

104
00:04:32,580 --> 00:04:35,280
since then and the research in response

105
00:04:35,280 --> 00:04:36,320
to this

106
00:04:36,320 --> 00:04:39,720
has followed mainly two directions the

107
00:04:39,720 --> 00:04:42,900
first one is program analysis techniques

108
00:04:42,900 --> 00:04:45,780
to detect split personalities in

109
00:04:45,780 --> 00:04:49,139
sandboxes and these mainly focused on

110
00:04:49,139 --> 00:04:52,740
time uh time-based triggers and sandbox

111
00:04:52,740 --> 00:04:55,919
evasion and on the other hand

112
00:04:55,919 --> 00:04:58,800
um the the other direction was towards

113
00:04:58,800 --> 00:05:01,560
developing better sandboxes by bringing

114
00:05:01,560 --> 00:05:03,780
them closer to bare metal or by adding

115
00:05:03,780 --> 00:05:07,320
aging artifacts or by randomizing the

116
00:05:07,320 --> 00:05:08,400
VMS

117
00:05:08,400 --> 00:05:09,660
so

118
00:05:09,660 --> 00:05:13,440
because all this past work focused on

119
00:05:13,440 --> 00:05:16,320
what malware does in a sandbox we asked

120
00:05:16,320 --> 00:05:19,320
ourselves what else could we learn about

121
00:05:19,320 --> 00:05:22,340
split personalities but by analyzing

122
00:05:22,340 --> 00:05:25,680
traces from the wild

123
00:05:25,680 --> 00:05:27,840
um and to begin answers this question

124
00:05:27,840 --> 00:05:29,280
let's take a look at some of the answers

125
00:05:29,280 --> 00:05:30,720
that the previous research did not

126
00:05:30,720 --> 00:05:33,900
answer so first of all is how do malware

127
00:05:33,900 --> 00:05:37,020
behaviors vary in the wild so how much

128
00:05:37,020 --> 00:05:39,660
variability there is between executions

129
00:05:39,660 --> 00:05:41,880
uh what parts of the behavior vary the

130
00:05:41,880 --> 00:05:43,080
most

131
00:05:43,080 --> 00:05:45,900
how does this impact malware Dynamic

132
00:05:45,900 --> 00:05:48,960
analysis perhaps it doesn't impact that

133
00:05:48,960 --> 00:05:51,840
much so we shouldn't worry about it and

134
00:05:51,840 --> 00:05:53,820
finally what can we do about it

135
00:05:53,820 --> 00:05:58,139
so now to put this um in a more on more

136
00:05:58,139 --> 00:06:01,440
concrete terms let's take a look at an

137
00:06:01,440 --> 00:06:06,060
example so here on this slide you have a

138
00:06:06,060 --> 00:06:08,340
portion of the pseudocode for the ramnet

139
00:06:08,340 --> 00:06:11,160
worm and one of the things that the uh

140
00:06:11,160 --> 00:06:14,940
this worm does is that it uh

141
00:06:14,940 --> 00:06:16,440
uh it tries to exploit a certain

142
00:06:16,440 --> 00:06:19,440
vulnerability this is on line 22 here

143
00:06:19,440 --> 00:06:22,800
with the aim of achieving privileged

144
00:06:22,800 --> 00:06:23,880
escalation

145
00:06:23,880 --> 00:06:26,419
now when this happens when the exploit

146
00:06:26,419 --> 00:06:28,860
executes this results in the creation of

147
00:06:28,860 --> 00:06:31,620
hundreds of Windows mutexes until the

148
00:06:31,620 --> 00:06:34,500
exploit succeeds however this only

149
00:06:34,500 --> 00:06:39,180
happens on Windows 7. on hosts that have

150
00:06:39,180 --> 00:06:43,560
not been patched and when the worm is

151
00:06:43,560 --> 00:06:46,259
run in a non-admin mode

152
00:06:46,259 --> 00:06:47,940
so who cares

153
00:06:47,940 --> 00:06:51,440
well if you are an engineer developing

154
00:06:51,440 --> 00:06:54,600
malware detection signatures and you

155
00:06:54,600 --> 00:06:56,880
base your signature on the trace that

156
00:06:56,880 --> 00:06:59,000
includes these hundreds of mutexes

157
00:06:59,000 --> 00:07:01,979
this signature may be ineffective on

158
00:07:01,979 --> 00:07:05,280
hosts where that have been patched or

159
00:07:05,280 --> 00:07:07,319
that where the worm is running in admin

160
00:07:07,319 --> 00:07:09,300
mode

161
00:07:09,300 --> 00:07:15,000
um now if you are a user of such tools

162
00:07:15,000 --> 00:07:17,160
um that include signatures based on

163
00:07:17,160 --> 00:07:19,319
these these types of signatures

164
00:07:19,319 --> 00:07:21,539
you may not know the true effectiveness

165
00:07:21,539 --> 00:07:23,639
of of the tool because this will depend

166
00:07:23,639 --> 00:07:26,639
on how prevalent this Trace is in the

167
00:07:26,639 --> 00:07:29,220
wild uh if if it's if it accounts for

168
00:07:29,220 --> 00:07:32,160
one percent or for 99 of the traces in

169
00:07:32,160 --> 00:07:33,840
the wild you will see very different

170
00:07:33,840 --> 00:07:35,580
results

171
00:07:35,580 --> 00:07:38,039
in what's worse even the vendor will be

172
00:07:38,039 --> 00:07:40,680
unable to estimate the effectiveness uh

173
00:07:40,680 --> 00:07:44,240
without collecting traces in the wild

174
00:07:44,639 --> 00:07:47,639
and then malware analysts are facing

175
00:07:47,639 --> 00:07:49,580
this problem of

176
00:07:49,580 --> 00:07:52,380
determining which part of the traces

177
00:07:52,380 --> 00:07:54,720
that are analyzing are representative of

178
00:07:54,720 --> 00:07:56,340
the worms of the of the malware's

179
00:07:56,340 --> 00:07:58,740
Behavior Uh in this case the trace that

180
00:07:58,740 --> 00:08:00,900
contains all the string of mutexes mutex

181
00:08:00,900 --> 00:08:02,400
Creations

182
00:08:02,400 --> 00:08:04,979
um is is not representative

183
00:08:04,979 --> 00:08:06,479
so now the reason why we don't know

184
00:08:06,479 --> 00:08:08,580
these things is because it's hard we

185
00:08:08,580 --> 00:08:11,520
need executions from the wild execution

186
00:08:11,520 --> 00:08:13,560
traces collected from Real World hosts

187
00:08:13,560 --> 00:08:16,080
right and it turns out that some

188
00:08:16,080 --> 00:08:18,000
security companies are already

189
00:08:18,000 --> 00:08:20,039
collecting such data so we partnered

190
00:08:20,039 --> 00:08:22,740
with one of these companies to conduct a

191
00:08:22,740 --> 00:08:24,479
large empirical study of split

192
00:08:24,479 --> 00:08:26,759
personalities in the wild

193
00:08:26,759 --> 00:08:30,240
so we collected 7.6 million execution

194
00:08:30,240 --> 00:08:33,799
traces uh coming from over 5 million

195
00:08:33,799 --> 00:08:38,099
real users machines this map shows the

196
00:08:38,099 --> 00:08:39,839
uh

197
00:08:39,839 --> 00:08:42,000
the geographic distribution and

198
00:08:42,000 --> 00:08:44,940
importantly this includes multiple

199
00:08:44,940 --> 00:08:48,000
traces per per sample

200
00:08:48,000 --> 00:08:51,660
now this data these execution traces

201
00:08:51,660 --> 00:08:54,060
represent real world infections because

202
00:08:54,060 --> 00:08:56,100
we do not distribute any samples to

203
00:08:56,100 --> 00:08:58,560
these hosts we do not provide inputs and

204
00:08:58,560 --> 00:09:01,019
we do not trigger the executions and the

205
00:09:01,019 --> 00:09:03,600
antivirus will block all known malware

206
00:09:03,600 --> 00:09:06,060
the executions are collected not for the

207
00:09:06,060 --> 00:09:08,339
purposes of our study but as the last

208
00:09:08,339 --> 00:09:10,160
line of defense

209
00:09:10,160 --> 00:09:12,600
and they're only collected when the

210
00:09:12,600 --> 00:09:15,120
antivirus cannot classify a sample as

211
00:09:15,120 --> 00:09:18,240
either benign or malicious and as soon

212
00:09:18,240 --> 00:09:21,300
as the sample does something that the AV

213
00:09:21,300 --> 00:09:23,100
will recognize as being malicious the

214
00:09:23,100 --> 00:09:25,820
execution is terminated

215
00:09:25,820 --> 00:09:29,580
finally no private user data is

216
00:09:29,580 --> 00:09:31,200
collected here

217
00:09:31,200 --> 00:09:32,940
so the first finding that I want to tell

218
00:09:32,940 --> 00:09:33,959
you about

219
00:09:33,959 --> 00:09:36,120
uh is that

220
00:09:36,120 --> 00:09:38,220
benign programs also have variable

221
00:09:38,220 --> 00:09:41,040
Behavior so if you look at a typical

222
00:09:41,040 --> 00:09:44,160
benign sample and you look at the

223
00:09:44,160 --> 00:09:47,580
difference between the longest 25 traces

224
00:09:47,580 --> 00:09:50,519
and the shortest 25 traces uh this

225
00:09:50,519 --> 00:09:54,180
difference is eight or more actions

226
00:09:54,180 --> 00:09:56,339
now

227
00:09:56,339 --> 00:09:59,220
potentially unwanted programs have more

228
00:09:59,220 --> 00:10:02,100
variability uh in this case the

229
00:10:02,100 --> 00:10:04,680
difference is 19 actions but malware

230
00:10:04,680 --> 00:10:07,019
samples have a lot more variability here

231
00:10:07,019 --> 00:10:09,959
the difference is going to be 59 actions

232
00:10:09,959 --> 00:10:14,240
so now the uh word clouds on this slide

233
00:10:14,240 --> 00:10:18,300
uh illustrate the relative of amount of

234
00:10:18,300 --> 00:10:19,920
variability for different types of

235
00:10:19,920 --> 00:10:22,640
actions note that file Creations

236
00:10:22,640 --> 00:10:25,920
are the type of actions that vary the

237
00:10:25,920 --> 00:10:28,800
most for all categories of of software

238
00:10:28,800 --> 00:10:31,380
and this is true both in terms of the

239
00:10:31,380 --> 00:10:34,800
number of actions as well as the

240
00:10:34,800 --> 00:10:36,839
parameters so the different file names

241
00:10:36,839 --> 00:10:38,459
that are created especially malware

242
00:10:38,459 --> 00:10:40,500
tends to create a lot of unique and

243
00:10:40,500 --> 00:10:42,120
random foundings

244
00:10:42,120 --> 00:10:44,040
so now there are many reasons for these

245
00:10:44,040 --> 00:10:45,620
uh behavioral differences

246
00:10:45,620 --> 00:10:47,940
there are of course malware implemented

247
00:10:47,940 --> 00:10:49,980
basic techniques but there are also

248
00:10:49,980 --> 00:10:52,200
differences in operating systems and and

249
00:10:52,200 --> 00:10:54,240
libraries like we've seen in the ramnet

250
00:10:54,240 --> 00:10:55,260
example

251
00:10:55,260 --> 00:10:57,240
malware may attempt some risky

252
00:10:57,240 --> 00:11:00,540
operations that fail on some hosts uh

253
00:11:00,540 --> 00:11:02,160
malware may receive different commands

254
00:11:02,160 --> 00:11:04,339
from its command and control Channel

255
00:11:04,339 --> 00:11:07,500
we've also seen differences between the

256
00:11:07,500 --> 00:11:09,180
first execution and the second execution

257
00:11:09,180 --> 00:11:11,519
of the same of the sample on the same

258
00:11:11,519 --> 00:11:13,620
host and that's because the initial

259
00:11:13,620 --> 00:11:15,779
installation performs a one-time

260
00:11:15,779 --> 00:11:18,959
operations random file names and many

261
00:11:18,959 --> 00:11:20,519
others so now

262
00:11:20,519 --> 00:11:23,399
most of the research has focused on

263
00:11:23,399 --> 00:11:25,800
addressing sound activation which is the

264
00:11:25,800 --> 00:11:28,079
first bullet here but as you see there

265
00:11:28,079 --> 00:11:29,519
are many other reasons for Behavioral

266
00:11:29,519 --> 00:11:33,120
variabilities so even so sandboxes

267
00:11:33,120 --> 00:11:36,300
sandbox traces cannot account for the

268
00:11:36,300 --> 00:11:39,420
range of behaviors that are encountered

269
00:11:39,420 --> 00:11:41,700
in the wild and that's even if you

270
00:11:41,700 --> 00:11:44,279
always catch sandbox evasion

271
00:11:44,279 --> 00:11:46,980
now there are a lot more results in our

272
00:11:46,980 --> 00:11:49,620
paper I encourage you to uh to read it

273
00:11:49,620 --> 00:11:51,959
if you're interested I want to spend the

274
00:11:51,959 --> 00:11:54,959
rest of this talk uh focusing on what

275
00:11:54,959 --> 00:11:57,180
these results mean for you so if the

276
00:11:57,180 --> 00:11:59,220
problem of split personalities affects

277
00:11:59,220 --> 00:12:01,980
your job then what can you do about it

278
00:12:01,980 --> 00:12:05,820
so I expect the most of you here do not

279
00:12:05,820 --> 00:12:08,940
work on malware analysis directly but

280
00:12:08,940 --> 00:12:11,399
you may need to use tools such as

281
00:12:11,399 --> 00:12:12,779
malware detection or malware

282
00:12:12,779 --> 00:12:15,000
classification to protect your

283
00:12:15,000 --> 00:12:17,940
organization so in this case my advice

284
00:12:17,940 --> 00:12:21,180
is trust but verify and to illustrate

285
00:12:21,180 --> 00:12:23,519
this we conducted an experiment with a

286
00:12:23,519 --> 00:12:27,300
malware clustering technique with the

287
00:12:27,300 --> 00:12:29,339
aim of understanding the impact of this

288
00:12:29,339 --> 00:12:31,320
Behavior variability of malware

289
00:12:31,320 --> 00:12:33,839
clustering now clustering is an

290
00:12:33,839 --> 00:12:35,880
unsupervised learning unsupervised

291
00:12:35,880 --> 00:12:38,160
machine learning technique and the goal

292
00:12:38,160 --> 00:12:41,000
here is to

293
00:12:41,000 --> 00:12:44,240
identify which samples

294
00:12:44,240 --> 00:12:46,500
are similar enough that they likely

295
00:12:46,500 --> 00:12:48,959
belong to the same family so usually the

296
00:12:48,959 --> 00:12:50,639
way this is done is a bunch of traces

297
00:12:50,639 --> 00:12:52,920
for different samples are provided to

298
00:12:52,920 --> 00:12:54,300
the clustering tool and the different

299
00:12:54,300 --> 00:12:56,579
clusters are produced that correspond to

300
00:12:56,579 --> 00:12:59,700
that indicate different families of

301
00:12:59,700 --> 00:13:00,680
malware

302
00:13:00,680 --> 00:13:03,959
now all the papers that I've read on

303
00:13:03,959 --> 00:13:06,660
this topic used only one Trace per

304
00:13:06,660 --> 00:13:09,839
sample so we decided to use four traces

305
00:13:09,839 --> 00:13:12,480
per sample just because we could

306
00:13:12,480 --> 00:13:13,139
um

307
00:13:13,139 --> 00:13:14,519
and

308
00:13:14,519 --> 00:13:15,899
um if

309
00:13:15,899 --> 00:13:21,079
uh clustering is really able to separate

310
00:13:21,079 --> 00:13:24,300
the malware families then we would

311
00:13:24,300 --> 00:13:25,680
expect to see something like this we

312
00:13:25,680 --> 00:13:28,320
would we would expect to see that all

313
00:13:28,320 --> 00:13:31,139
the traces of a sample would be placed

314
00:13:31,139 --> 00:13:33,779
in in the same cluster

315
00:13:33,779 --> 00:13:36,720
but actually what we see is this uh one

316
00:13:36,720 --> 00:13:38,820
third of the samples we experimented

317
00:13:38,820 --> 00:13:41,760
with exhibit sufficient variability that

318
00:13:41,760 --> 00:13:43,980
their traces are placed in more than one

319
00:13:43,980 --> 00:13:47,040
cluster with one percent of samples uh

320
00:13:47,040 --> 00:13:49,440
each Trace being placed in a separate

321
00:13:49,440 --> 00:13:51,180
cluster

322
00:13:51,180 --> 00:13:54,300
um and note that we only observe this

323
00:13:54,300 --> 00:13:57,540
because we used four samples four traces

324
00:13:57,540 --> 00:14:01,620
per per sample so uh this suggests that

325
00:14:01,620 --> 00:14:03,720
uh whenever you're doing clustering

326
00:14:03,720 --> 00:14:05,940
experiments with only one Trace per

327
00:14:05,940 --> 00:14:08,459
sample the results uh the resulting

328
00:14:08,459 --> 00:14:10,980
accuracy will be overestimated

329
00:14:10,980 --> 00:14:13,320
and what's even worse even independent

330
00:14:13,320 --> 00:14:15,000
evaluators and researchers and the

331
00:14:15,000 --> 00:14:17,399
vendors themselves will not be able to

332
00:14:17,399 --> 00:14:19,760
tell you how large the overestimation is

333
00:14:19,760 --> 00:14:22,620
without using traces in the wild so for

334
00:14:22,620 --> 00:14:24,300
this reason my advice is trust but

335
00:14:24,300 --> 00:14:27,300
verify evaluate the tool rigorously in

336
00:14:27,300 --> 00:14:31,019
your environment because even with the

337
00:14:31,019 --> 00:14:33,779
most rigorous evaluations the results

338
00:14:33,779 --> 00:14:36,000
May still not reflect what you are going

339
00:14:36,000 --> 00:14:37,620
to see in the future

340
00:14:37,620 --> 00:14:41,720
now if you are somebody Who develops

341
00:14:41,720 --> 00:14:45,779
rules for detecting malware my advice is

342
00:14:45,779 --> 00:14:48,000
to use traces from multiple executions

343
00:14:48,000 --> 00:14:49,199
in the wild

344
00:14:49,199 --> 00:14:51,060
so here I'm going to tell you about

345
00:14:51,060 --> 00:14:53,279
another experiment where we looked at

346
00:14:53,279 --> 00:14:55,800
the impact of variability on malware

347
00:14:55,800 --> 00:14:58,260
detection and in this experiment we

348
00:14:58,260 --> 00:15:00,600
focused on on one cry the the famous

349
00:15:00,600 --> 00:15:03,360
worm and ransomware

350
00:15:03,360 --> 00:15:03,959
um

351
00:15:03,959 --> 00:15:05,420
we

352
00:15:05,420 --> 00:15:08,820
we trained several supervised machine

353
00:15:08,820 --> 00:15:12,060
learning models to detect wannacry and

354
00:15:12,060 --> 00:15:13,620
in this case we also collected

355
00:15:13,620 --> 00:15:16,440
contemporaneous sandbox traces so these

356
00:15:16,440 --> 00:15:18,240
these traces were actually executed by

357
00:15:18,240 --> 00:15:21,060
two different sandboxes at the time

358
00:15:21,060 --> 00:15:23,100
around the time when we were doing the

359
00:15:23,100 --> 00:15:25,740
data collection in the wild

360
00:15:25,740 --> 00:15:27,720
um and we looked at two sandbox traces

361
00:15:27,720 --> 00:15:29,579
two two separate sandboxes because some

362
00:15:29,579 --> 00:15:31,880
of the best practices recommend

363
00:15:31,880 --> 00:15:35,519
combining some uh sandbox traces in

364
00:15:35,519 --> 00:15:36,720
order to account for Behavior

365
00:15:36,720 --> 00:15:38,279
variability

366
00:15:38,279 --> 00:15:40,139
so the results that I'm presenting here

367
00:15:40,139 --> 00:15:42,600
are in terms of the true positive rates

368
00:15:42,600 --> 00:15:45,420
or the detection rate for one percent

369
00:15:45,420 --> 00:15:47,339
false positives

370
00:15:47,339 --> 00:15:49,440
so when we train our models on Cuckoo

371
00:15:49,440 --> 00:15:52,940
sandbox and we test Uncle sandbox we get

372
00:15:52,940 --> 00:15:57,120
76 uh percent uh true positives

373
00:15:57,120 --> 00:15:59,579
when we test when we train on Cuckoo

374
00:15:59,579 --> 00:16:02,360
sandbox and test on Hubble sandbox

375
00:16:02,360 --> 00:16:04,980
we have a little bit of a performance

376
00:16:04,980 --> 00:16:07,260
drop but when we train on google sandbox

377
00:16:07,260 --> 00:16:09,720
and trade test on the wild we have a

378
00:16:09,720 --> 00:16:12,060
huge performance drop uh 18 true

379
00:16:12,060 --> 00:16:14,339
positives is basically useless so

380
00:16:14,339 --> 00:16:16,560
therefore we combined you know as

381
00:16:16,560 --> 00:16:19,320
recommended we combine the the sandbox

382
00:16:19,320 --> 00:16:23,160
traces uh and we trained on the combined

383
00:16:23,160 --> 00:16:24,899
sandbox traces and tested in the wild

384
00:16:24,899 --> 00:16:27,480
and uh we got a little bit of

385
00:16:27,480 --> 00:16:29,639
improvement but not much

386
00:16:29,639 --> 00:16:33,839
so to understand why this happens we try

387
00:16:33,839 --> 00:16:36,420
to visualize the feature space that

388
00:16:36,420 --> 00:16:39,079
these classifiers are operating on

389
00:16:39,079 --> 00:16:44,339
and so our features are

390
00:16:44,660 --> 00:16:47,639
accounts of token exactly extracted from

391
00:16:47,639 --> 00:16:51,600
wannacry parameters and so this is a

392
00:16:51,600 --> 00:16:53,579
high dimensional space so we use the

393
00:16:53,579 --> 00:16:55,199
projection into two Dimensions to

394
00:16:55,199 --> 00:16:58,199
visualize it here this means that the

395
00:16:58,199 --> 00:17:00,660
two axes the X and Y axis on this plot

396
00:17:00,660 --> 00:17:02,339
are not meaningful that the numbers on

397
00:17:02,339 --> 00:17:03,779
the axis are not meaningful but the

398
00:17:03,779 --> 00:17:05,579
relative distances between the points

399
00:17:05,579 --> 00:17:09,179
are so we can see here this this uh plot

400
00:17:09,179 --> 00:17:10,919
here only shows the two sandboxes we can

401
00:17:10,919 --> 00:17:14,280
see that the the traces in the sandbox

402
00:17:14,280 --> 00:17:16,439
are are pretty well uh pretty well

403
00:17:16,439 --> 00:17:19,500
clustered together but then when we look

404
00:17:19,500 --> 00:17:21,419
at what happens in the wild we see a lot

405
00:17:21,419 --> 00:17:24,359
more variability and in fact if we try

406
00:17:24,359 --> 00:17:27,119
to identify where the sandbox traces are

407
00:17:27,119 --> 00:17:29,340
on this second plot they are right here

408
00:17:29,340 --> 00:17:31,860
in this very small area and this is

409
00:17:31,860 --> 00:17:34,620
because sandboxes do not account for the

410
00:17:34,620 --> 00:17:38,460
broad range of behaviors in the wild it

411
00:17:38,460 --> 00:17:41,460
seems that models based on one sandbox

412
00:17:41,460 --> 00:17:43,620
tend to generate generalize well to

413
00:17:43,620 --> 00:17:45,720
another sample box but very poorly to

414
00:17:45,720 --> 00:17:48,120
behaviors observed in the wild so for

415
00:17:48,120 --> 00:17:50,640
this reason my advice is to use multiple

416
00:17:50,640 --> 00:17:54,360
traces from executions in the wild to

417
00:17:54,360 --> 00:17:56,400
the to create these rules

418
00:17:56,400 --> 00:17:59,820
now you may be wondering okay just how

419
00:17:59,820 --> 00:18:03,600
many uh different environments and it

420
00:18:03,600 --> 00:18:06,539
seems that three uh is a is a pretty

421
00:18:06,539 --> 00:18:09,660
good number after three we have we

422
00:18:09,660 --> 00:18:12,480
observe diminishing returns uh and this

423
00:18:12,480 --> 00:18:14,160
is actually good news because it

424
00:18:14,160 --> 00:18:16,140
suggests that there isn't an infinite

425
00:18:16,140 --> 00:18:18,720
number of environments uh where where

426
00:18:18,720 --> 00:18:21,360
the behavior will differ

427
00:18:21,360 --> 00:18:24,539
uh that after observing a few number of

428
00:18:24,539 --> 00:18:27,000
uh the same the sample in a few number

429
00:18:27,000 --> 00:18:29,340
of environments we can uh get a good

430
00:18:29,340 --> 00:18:31,980
coverage of of Its Behavior now

431
00:18:31,980 --> 00:18:34,799
behaviors also vary over time

432
00:18:34,799 --> 00:18:38,940
um here uh uh you you wanna collect

433
00:18:38,940 --> 00:18:41,100
executions three to four weeks apart

434
00:18:41,100 --> 00:18:42,960
however here

435
00:18:42,960 --> 00:18:44,880
um this seems to be less useful than

436
00:18:44,880 --> 00:18:46,799
executing the sample multiple machines

437
00:18:46,799 --> 00:18:49,919
in terms of improving the the coverage

438
00:18:49,919 --> 00:18:54,799
so now summarizing the current practices

439
00:18:55,140 --> 00:18:57,539
malware analysis tools are in demand

440
00:18:57,539 --> 00:19:00,840
there is a 5 billion malware analysis

441
00:19:00,840 --> 00:19:03,179
Market expected to grow over the next

442
00:19:03,179 --> 00:19:05,940
decade and today it relies heavily on

443
00:19:05,940 --> 00:19:08,280
Sandbox collected traces and this

444
00:19:08,280 --> 00:19:10,919
introduces a number of blind spots

445
00:19:10,919 --> 00:19:14,220
it we tend to overlook environment and

446
00:19:14,220 --> 00:19:16,620
time dependent Behavior especially when

447
00:19:16,620 --> 00:19:19,400
we're using only one Trace per sample

448
00:19:19,400 --> 00:19:22,320
we observe a narrow range of behaviors

449
00:19:22,320 --> 00:19:24,000
compared to what's happening in the wild

450
00:19:24,000 --> 00:19:27,059
even assuming that you have the perfect

451
00:19:27,059 --> 00:19:30,539
solution against sandbox evasion

452
00:19:30,539 --> 00:19:31,080
um

453
00:19:31,080 --> 00:19:34,320
well it's hard to determine which

454
00:19:34,320 --> 00:19:36,000
actions or parameters are representative

455
00:19:36,000 --> 00:19:38,360
of the Bowers behavior

456
00:19:38,360 --> 00:19:41,760
and this ultimately ends up in an

457
00:19:41,760 --> 00:19:43,559
overestimation of the accuracy of

458
00:19:43,559 --> 00:19:45,840
clustering in and detection

459
00:19:45,840 --> 00:19:47,880
so before I conclude I want to thank my

460
00:19:47,880 --> 00:19:50,340
collaborators first of all my student

461
00:19:50,340 --> 00:19:52,500
Erin avlaza guy who was the lead author

462
00:19:52,500 --> 00:19:55,200
of the study my student ID John Kaya and

463
00:19:55,200 --> 00:19:57,960
my former student currently Dr Zhu as

464
00:19:57,960 --> 00:20:00,240
well as my collaborators Leila bilge and

465
00:20:00,240 --> 00:20:03,120
David de balzarote this project is a

466
00:20:03,120 --> 00:20:05,039
great example of Industry Academia

467
00:20:05,039 --> 00:20:06,960
collaboration with thought-provoking

468
00:20:06,960 --> 00:20:09,840
findings and actionable implications and

469
00:20:09,840 --> 00:20:12,780
generally there is a lot of great

470
00:20:12,780 --> 00:20:15,059
science coming out of such

471
00:20:15,059 --> 00:20:16,440
collaborations I think we've heard

472
00:20:16,440 --> 00:20:19,440
another couple of examples today here at

473
00:20:19,440 --> 00:20:22,799
Enigma these collaborations will have a

474
00:20:22,799 --> 00:20:24,480
transformative effect on the next

475
00:20:24,480 --> 00:20:26,100
generation of security products and

476
00:20:26,100 --> 00:20:28,679
services so I invite you all to check

477
00:20:28,679 --> 00:20:30,720
them out and perhaps you will even find

478
00:20:30,720 --> 00:20:33,600
Opportunities to participate in these

479
00:20:33,600 --> 00:20:35,100
collaborations

480
00:20:35,100 --> 00:20:36,720
so now I want to leave you with two

481
00:20:36,720 --> 00:20:40,679
thoughts the first one is that malware

482
00:20:40,679 --> 00:20:42,600
analysis should be based on multiple

483
00:20:42,600 --> 00:20:45,840
executions from the wild that this can

484
00:20:45,840 --> 00:20:48,780
be done ethically and there are security

485
00:20:48,780 --> 00:20:50,880
companies today who are in a position to

486
00:20:50,880 --> 00:20:52,380
do it

487
00:20:52,380 --> 00:20:55,260
and the second one is that this is a

488
00:20:55,260 --> 00:20:58,200
radical shift in the way uh from the way

489
00:20:58,200 --> 00:21:00,660
the dynamic analysis is done today but

490
00:21:00,660 --> 00:21:03,780
it's a shift that can bring a unique new

491
00:21:03,780 --> 00:21:07,679
insights and if you're looking for the

492
00:21:07,679 --> 00:21:10,080
next big thing in a dynamic malware

493
00:21:10,080 --> 00:21:11,160
analysis

494
00:21:11,160 --> 00:21:12,960
this may be it

495
00:21:12,960 --> 00:21:14,810
thank you

496
00:21:14,810 --> 00:21:18,450
[Applause]

