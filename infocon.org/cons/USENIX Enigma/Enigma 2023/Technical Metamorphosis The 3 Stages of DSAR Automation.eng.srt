1
00:00:01,199 --> 00:00:04,199
foreign

2
00:00:14,719 --> 00:00:18,480
hi everyone my name is Alon and I'm an

3
00:00:18,480 --> 00:00:20,220
engineering manager on the technical

4
00:00:20,220 --> 00:00:23,400
privacy team at Uber I lead the team

5
00:00:23,400 --> 00:00:25,320
that builds automation systems for

6
00:00:25,320 --> 00:00:28,980
exporting user data at Uber we've tried

7
00:00:28,980 --> 00:00:30,779
to take a proactive approach to privacy

8
00:00:30,779 --> 00:00:32,880
so the main mission of my team is really

9
00:00:32,880 --> 00:00:34,739
to optimize automation as much as

10
00:00:34,739 --> 00:00:37,200
possible and then provide customers with

11
00:00:37,200 --> 00:00:40,079
tooling around their data uh this talk

12
00:00:40,079 --> 00:00:42,360
is going to focus on data subject access

13
00:00:42,360 --> 00:00:46,620
request automation so let's get started

14
00:00:46,620 --> 00:00:49,140
I'll be reviewing what exactly is a data

15
00:00:49,140 --> 00:00:52,620
subject access request and why uh why is

16
00:00:52,620 --> 00:00:54,480
that important and then for the benefit

17
00:00:54,480 --> 00:00:56,579
of other teams and kind of earlier

18
00:00:56,579 --> 00:00:59,460
stages of Planning and Development I'll

19
00:00:59,460 --> 00:01:01,379
be walking through the stages towards

20
00:01:01,379 --> 00:01:03,120
Automation and then sharing some of our

21
00:01:03,120 --> 00:01:06,020
learnings going through that process

22
00:01:06,020 --> 00:01:08,640
so what exactly is a data subject access

23
00:01:08,640 --> 00:01:11,220
request and why should you care about it

24
00:01:11,220 --> 00:01:13,439
well a data subject access request and

25
00:01:13,439 --> 00:01:14,580
from now on I'm going to refer to them

26
00:01:14,580 --> 00:01:16,920
by their common name these are is a

27
00:01:16,920 --> 00:01:19,200
legal right by which individuals have to

28
00:01:19,200 --> 00:01:20,580
access their personal data that's being

29
00:01:20,580 --> 00:01:23,580
processed by a business so for example a

30
00:01:23,580 --> 00:01:26,040
user can approach Uber and request data

31
00:01:26,040 --> 00:01:28,320
like their trip information or their

32
00:01:28,320 --> 00:01:30,900
order details they reach out to us and

33
00:01:30,900 --> 00:01:32,400
then at the end of that process they'd

34
00:01:32,400 --> 00:01:34,740
receive a compressed file with the

35
00:01:34,740 --> 00:01:37,439
requested data

36
00:01:37,439 --> 00:01:40,680
now data access rights are basically

37
00:01:40,680 --> 00:01:42,780
spread across a disparate regulatory

38
00:01:42,780 --> 00:01:45,799
landscape and as you can see in this map

39
00:01:45,799 --> 00:01:48,420
each one of these regulations has its

40
00:01:48,420 --> 00:01:50,640
own varying requirements penalties and

41
00:01:50,640 --> 00:01:53,220
stringent response times

42
00:01:53,220 --> 00:01:54,960
um and complying with all of these can

43
00:01:54,960 --> 00:01:56,640
pose a challenge for a business in

44
00:01:56,640 --> 00:01:59,939
defining a process to inventory and

45
00:01:59,939 --> 00:02:02,640
export data effectively

46
00:02:02,640 --> 00:02:06,180
um now beyond the fact that uh providing

47
00:02:06,180 --> 00:02:08,758
users with agency over their data is

48
00:02:08,758 --> 00:02:11,220
kind of the right thing to do uh privacy

49
00:02:11,220 --> 00:02:13,319
enforcement penalties can go up to the

50
00:02:13,319 --> 00:02:15,260
hundreds of millions of dollars or more

51
00:02:15,260 --> 00:02:17,640
the main reason behind showing you this

52
00:02:17,640 --> 00:02:19,440
map is not so much to educate you about

53
00:02:19,440 --> 00:02:22,080
these laws your legal departments can

54
00:02:22,080 --> 00:02:23,459
probably do that a lot better than I can

55
00:02:23,459 --> 00:02:26,099
I'm an engineer not an attorney but the

56
00:02:26,099 --> 00:02:28,260
the larger message here is these laws

57
00:02:28,260 --> 00:02:31,200
are coming up all over the world and you

58
00:02:31,200 --> 00:02:33,000
should be thinking of automation as a

59
00:02:33,000 --> 00:02:34,560
way of getting ahead of the story and

60
00:02:34,560 --> 00:02:36,599
trying to build compliance and trust

61
00:02:36,599 --> 00:02:39,780
with your customers preemptively

62
00:02:39,780 --> 00:02:41,580
okay so you're you're not going to

63
00:02:41,580 --> 00:02:43,800
arrive at a solution overnight so kind

64
00:02:43,800 --> 00:02:47,640
of let's break things down into stages

65
00:02:47,640 --> 00:02:50,700
so how do things look like in in the

66
00:02:50,700 --> 00:02:52,680
early stages you're gonna need to be

67
00:02:52,680 --> 00:02:55,200
able to answer questions like uh how do

68
00:02:55,200 --> 00:02:57,540
you ingest these requests who's going to

69
00:02:57,540 --> 00:03:00,300
actually undertake fulfillment and then

70
00:03:00,300 --> 00:03:02,400
what data do you need to provide so if

71
00:03:02,400 --> 00:03:04,440
you look at this slide this is a

72
00:03:04,440 --> 00:03:05,879
potential process

73
00:03:05,879 --> 00:03:09,239
a user will go ahead and submit these

74
00:03:09,239 --> 00:03:12,239
are request usually that request would

75
00:03:12,239 --> 00:03:14,400
be triaged and then it could be handed

76
00:03:14,400 --> 00:03:16,379
off to support staff who would undertake

77
00:03:16,379 --> 00:03:18,239
fulfillment and eventually transmit the

78
00:03:18,239 --> 00:03:19,860
output

79
00:03:19,860 --> 00:03:23,580
um now uh what does fulfill a manual

80
00:03:23,580 --> 00:03:25,620
fulfillment actually mean here it could

81
00:03:25,620 --> 00:03:26,819
be running

82
00:03:26,819 --> 00:03:29,940
um analytics queries uh on Presto or

83
00:03:29,940 --> 00:03:32,099
running SQL queries or making calls

84
00:03:32,099 --> 00:03:34,319
against your uh service apis it really

85
00:03:34,319 --> 00:03:37,159
depends kind of where your data lives

86
00:03:37,159 --> 00:03:40,860
but running composing and formatting

87
00:03:40,860 --> 00:03:43,140
outputs for every request has to be time

88
00:03:43,140 --> 00:03:45,360
consuming and cost prohibitive so it's

89
00:03:45,360 --> 00:03:47,580
kind of the most problematic step within

90
00:03:47,580 --> 00:03:50,640
this process another question you'll

91
00:03:50,640 --> 00:03:52,019
need to answer is what data do you

92
00:03:52,019 --> 00:03:53,519
actually need to provide or or how do

93
00:03:53,519 --> 00:03:56,459
you track data in a large organization

94
00:03:56,459 --> 00:03:58,980
so at Uber we have a privacy review

95
00:03:58,980 --> 00:04:01,680
process that kind of helps us build uh

96
00:04:01,680 --> 00:04:03,420
export backlog and then ensure that it

97
00:04:03,420 --> 00:04:04,879
remains holistic

98
00:04:04,879 --> 00:04:07,920
every time a new feature or product is

99
00:04:07,920 --> 00:04:10,379
being developed a cross-functional team

100
00:04:10,379 --> 00:04:14,760
of privacy Architects legal engineers

101
00:04:14,760 --> 00:04:17,040
and data analysts will review the data

102
00:04:17,040 --> 00:04:19,139
processing activities and then determine

103
00:04:19,139 --> 00:04:21,358
if they're in scope for our system or

104
00:04:21,358 --> 00:04:23,220
not

105
00:04:23,220 --> 00:04:26,880
so next I'd like to take a brief but

106
00:04:26,880 --> 00:04:29,280
required detour whenever you're

107
00:04:29,280 --> 00:04:31,080
deliberating these are automation the

108
00:04:31,080 --> 00:04:33,360
question of building versus buying is

109
00:04:33,360 --> 00:04:34,500
going to come up

110
00:04:34,500 --> 00:04:37,800
there are tons of vendor Solutions out

111
00:04:37,800 --> 00:04:40,800
there but honestly as an engineer my

112
00:04:40,800 --> 00:04:42,360
instinct is always the buildings myself

113
00:04:42,360 --> 00:04:44,639
I also have a great team and then the

114
00:04:44,639 --> 00:04:46,020
support of our leaderships to kind of

115
00:04:46,020 --> 00:04:47,400
build these types of tools internally

116
00:04:47,400 --> 00:04:49,560
but I realize not every organization is

117
00:04:49,560 --> 00:04:50,940
going to have the resource or the

118
00:04:50,940 --> 00:04:52,680
engineering bandwidth to want to take

119
00:04:52,680 --> 00:04:55,620
that on so let's review at least a few

120
00:04:55,620 --> 00:04:58,680
uh short criteria the first one is

121
00:04:58,680 --> 00:05:00,060
you'll need to consider the complexity

122
00:05:00,060 --> 00:05:02,400
of your system now this graph that you

123
00:05:02,400 --> 00:05:03,660
see here

124
00:05:03,660 --> 00:05:06,240
um on the in the slide is essentially

125
00:05:06,240 --> 00:05:08,460
Uber's microservices architecture and

126
00:05:08,460 --> 00:05:10,199
it's only really here to illustrate the

127
00:05:10,199 --> 00:05:13,020
systems can get pretty complex

128
00:05:13,020 --> 00:05:15,180
um now you'll need to consider if you're

129
00:05:15,180 --> 00:05:18,840
dealing with a static use case or you're

130
00:05:18,840 --> 00:05:20,400
continuously developing and evolving

131
00:05:20,400 --> 00:05:22,440
your system it can be a bit tricky to

132
00:05:22,440 --> 00:05:23,820
make sure vendor Solutions going to be

133
00:05:23,820 --> 00:05:27,180
able to keep up and then lastly

134
00:05:27,180 --> 00:05:29,340
um regardless of which illusion a

135
00:05:29,340 --> 00:05:30,900
solution you end up choosing you're

136
00:05:30,900 --> 00:05:32,580
going to need to make sure that it

137
00:05:32,580 --> 00:05:35,039
integrates properly with your Tech stack

138
00:05:35,039 --> 00:05:37,560
and with your infrastructure and I'd

139
00:05:37,560 --> 00:05:41,340
like to paraphrase a use case I recently

140
00:05:41,340 --> 00:05:43,020
read that was published by Venture beat

141
00:05:43,020 --> 00:05:45,000
where they describe a hospitality

142
00:05:45,000 --> 00:05:47,520
company that is attempting to automate

143
00:05:47,520 --> 00:05:49,800
their these are process they engage with

144
00:05:49,800 --> 00:05:51,960
a vendor and essentially build a proof

145
00:05:51,960 --> 00:05:54,620
of concept on top of the vendor solution

146
00:05:54,620 --> 00:05:57,000
and and that proof of concept is really

147
00:05:57,000 --> 00:05:58,020
promising

148
00:05:58,020 --> 00:06:00,000
uh but they end up not moving to

149
00:06:00,000 --> 00:06:01,919
production because somewhere in the

150
00:06:01,919 --> 00:06:04,560
process I.T steps in and says uh that

151
00:06:04,560 --> 00:06:06,360
they are concerned that the long-term

152
00:06:06,360 --> 00:06:07,800
maintenance costs are actually going to

153
00:06:07,800 --> 00:06:10,259
exceed the savings and if you try to

154
00:06:10,259 --> 00:06:11,940
look this up you'll see that this is

155
00:06:11,940 --> 00:06:13,979
kind of a trend that keeps coming up

156
00:06:13,979 --> 00:06:18,000
it's a pretty common problem and once

157
00:06:18,000 --> 00:06:19,919
your system kind of goes beyond the

158
00:06:19,919 --> 00:06:22,740
simplistic or the monolithic making an

159
00:06:22,740 --> 00:06:24,840
out of the box solution fit can be a bit

160
00:06:24,840 --> 00:06:27,318
challenging

161
00:06:27,560 --> 00:06:30,660
so now to go back to kind of the process

162
00:06:30,660 --> 00:06:33,060
towards automation

163
00:06:33,060 --> 00:06:35,580
um you have that manual process that I

164
00:06:35,580 --> 00:06:38,160
defined in stage one what's the problem

165
00:06:38,160 --> 00:06:39,600
with uh what's the problem with that

166
00:06:39,600 --> 00:06:41,039
process why can't you just use it

167
00:06:41,039 --> 00:06:42,300
indefinitely

168
00:06:42,300 --> 00:06:44,819
well things can change pretty rapidly

169
00:06:44,819 --> 00:06:46,860
and demand can escalate pretty quickly

170
00:06:46,860 --> 00:06:49,740
you could be faced with thousands of

171
00:06:49,740 --> 00:06:52,020
user requests and then the process by

172
00:06:52,020 --> 00:06:53,759
which you have an agent running

173
00:06:53,759 --> 00:06:56,160
templatized query just doesn't scale you

174
00:06:56,160 --> 00:06:58,199
can have your engineers kind of Step In

175
00:06:58,199 --> 00:07:00,120
to provide partial solutions that allow

176
00:07:00,120 --> 00:07:02,520
you to query key data sources and just

177
00:07:02,520 --> 00:07:04,440
process more requests and you end up

178
00:07:04,440 --> 00:07:06,479
with a process kind of similar to this

179
00:07:06,479 --> 00:07:08,759
where you have your support agents doing

180
00:07:08,759 --> 00:07:10,259
much of the work but then engineering

181
00:07:10,259 --> 00:07:12,660
doing another part of the work and then

182
00:07:12,660 --> 00:07:16,020
converging towards the end

183
00:07:16,020 --> 00:07:18,479
and then the next question is what's the

184
00:07:18,479 --> 00:07:19,979
problem with that why can't you have

185
00:07:19,979 --> 00:07:22,620
your support agents doing the bulk of

186
00:07:22,620 --> 00:07:24,180
the process and then have engineering

187
00:07:24,180 --> 00:07:25,860
step in to supplement where it's where

188
00:07:25,860 --> 00:07:27,240
needed

189
00:07:27,240 --> 00:07:30,240
um well it turns the process into a

190
00:07:30,240 --> 00:07:32,340
pretty cumbersome one you now need to

191
00:07:32,340 --> 00:07:34,080
coordinate across multiple departments

192
00:07:34,080 --> 00:07:35,819
including legal engineering and support

193
00:07:35,819 --> 00:07:37,819
to be able to fulfill requests and then

194
00:07:37,819 --> 00:07:40,620
you have Engineers now actively taking

195
00:07:40,620 --> 00:07:43,620
part in fulfillment which doesn't really

196
00:07:43,620 --> 00:07:45,240
give you a great return on investment

197
00:07:45,240 --> 00:07:48,180
and is not generally a good long-term

198
00:07:48,180 --> 00:07:50,160
solution

199
00:07:50,160 --> 00:07:53,099
um so uh the real question is could you

200
00:07:53,099 --> 00:07:54,419
avoid having to come up with partial

201
00:07:54,419 --> 00:07:55,740
Solutions and just go for full

202
00:07:55,740 --> 00:07:58,199
automation from from the start and

203
00:07:58,199 --> 00:07:59,759
honestly it's kind of an organizational

204
00:07:59,759 --> 00:08:02,419
question it's a bit of a a challenge

205
00:08:02,419 --> 00:08:04,380
Investments and initiatives like these

206
00:08:04,380 --> 00:08:07,139
content to lag it's hard to continuously

207
00:08:07,139 --> 00:08:09,240
make the case before things

208
00:08:09,240 --> 00:08:11,699
um actually start heating up so you need

209
00:08:11,699 --> 00:08:14,400
to be proactive in quantifying the full

210
00:08:14,400 --> 00:08:17,660
cost of manual fulfillment and then

211
00:08:17,660 --> 00:08:19,800
communicate those risks effectively with

212
00:08:19,800 --> 00:08:21,180
the business and generally you need to

213
00:08:21,180 --> 00:08:23,460
kind of make sure that the process stays

214
00:08:23,460 --> 00:08:27,500
ahead of the curve as you're evolving

215
00:08:27,620 --> 00:08:31,440
so now um finally what does an

216
00:08:31,440 --> 00:08:33,479
automation a fully automated solution

217
00:08:33,479 --> 00:08:36,120
actually look like I'll review our

218
00:08:36,120 --> 00:08:38,820
approach to Automation and we had kind

219
00:08:38,820 --> 00:08:40,380
of Three core requirements for our

220
00:08:40,380 --> 00:08:43,440
system the first one was

221
00:08:43,440 --> 00:08:46,580
um adaptability uh business practices

222
00:08:46,580 --> 00:08:50,100
change new features are released uh

223
00:08:50,100 --> 00:08:52,140
while old ones are discontinued and we

224
00:08:52,140 --> 00:08:53,580
needed to make sure our system can

225
00:08:53,580 --> 00:08:56,519
easily onboard new data and then just as

226
00:08:56,519 --> 00:08:58,140
easily off-board data that's no longer

227
00:08:58,140 --> 00:09:02,040
required the second was scale demand

228
00:09:02,040 --> 00:09:04,440
tends to grow so we wanted to build a

229
00:09:04,440 --> 00:09:06,000
system that could accommodate that

230
00:09:06,000 --> 00:09:07,920
growth without having to revisit our

231
00:09:07,920 --> 00:09:10,380
architecture later and then lastly is

232
00:09:10,380 --> 00:09:12,899
cost so in addition to minimizing kind

233
00:09:12,899 --> 00:09:14,459
of opportunity cost and operational

234
00:09:14,459 --> 00:09:16,440
costs we also wanted to minimize

235
00:09:16,440 --> 00:09:18,660
resource costs which in our case would

236
00:09:18,660 --> 00:09:21,779
be mainly compute

237
00:09:21,779 --> 00:09:25,680
um now no not every construct is um

238
00:09:25,680 --> 00:09:28,080
going to fit every unique use case uh

239
00:09:28,080 --> 00:09:30,420
perfectly I'm still pretty confident

240
00:09:30,420 --> 00:09:33,000
that uh reviewing our general approach

241
00:09:33,000 --> 00:09:35,220
here will will help provide a template

242
00:09:35,220 --> 00:09:37,380
that you'll be able to adapt we mainly

243
00:09:37,380 --> 00:09:39,720
wanted to focus on offline Warehouse

244
00:09:39,720 --> 00:09:40,860
data

245
00:09:40,860 --> 00:09:42,839
um but you know you might be focusing on

246
00:09:42,839 --> 00:09:45,720
real data in your real-time database

247
00:09:45,720 --> 00:09:47,279
systems

248
00:09:47,279 --> 00:09:50,760
um or your service apis like I mentioned

249
00:09:50,760 --> 00:09:52,140
so okay

250
00:09:52,140 --> 00:09:54,180
this is what our automation solution

251
00:09:54,180 --> 00:09:55,740
actually looked like then I kind of

252
00:09:55,740 --> 00:09:58,200
wanted to start with what specifically

253
00:09:58,200 --> 00:09:59,820
we achieved in stage three so I'd be

254
00:09:59,820 --> 00:10:02,220
able to contrast that with what I

255
00:10:02,220 --> 00:10:04,260
described in stage one this is an

256
00:10:04,260 --> 00:10:06,180
internal tool that allows our agents to

257
00:10:06,180 --> 00:10:08,760
submit these are requests on the left

258
00:10:08,760 --> 00:10:11,519
they're able to select a subject or

259
00:10:11,519 --> 00:10:13,920
subjects for the request and then on the

260
00:10:13,920 --> 00:10:16,200
right they're able to select the

261
00:10:16,200 --> 00:10:19,140
requested data now through these

262
00:10:19,140 --> 00:10:21,000
sequence of selections they're able to

263
00:10:21,000 --> 00:10:23,940
submit a high volume of requests

264
00:10:23,940 --> 00:10:26,339
covering a wide array of data pretty

265
00:10:26,339 --> 00:10:28,500
trivially and that's the contrast with

266
00:10:28,500 --> 00:10:30,420
what I was describing in stage one where

267
00:10:30,420 --> 00:10:32,640
you'd have an agent manually running

268
00:10:32,640 --> 00:10:34,740
queries and then compiling composing

269
00:10:34,740 --> 00:10:36,360
outputs for every user and request

270
00:10:36,360 --> 00:10:38,959
individually

271
00:10:39,480 --> 00:10:42,240
so to power the system we have two main

272
00:10:42,240 --> 00:10:45,540
components the first is our API layer

273
00:10:45,540 --> 00:10:48,300
which accepts requests from the UI you

274
00:10:48,300 --> 00:10:50,880
just saw which consists of a user or a

275
00:10:50,880 --> 00:10:52,620
grouping of users and then the required

276
00:10:52,620 --> 00:10:54,779
data it goes ahead and it stores those

277
00:10:54,779 --> 00:10:57,380
requests in our metadata storage

278
00:10:57,380 --> 00:11:00,420
and then our second component which is

279
00:11:00,420 --> 00:11:03,000
our batch processing orchestrator kicks

280
00:11:03,000 --> 00:11:04,740
in it runs on a fixed time-based

281
00:11:04,740 --> 00:11:07,500
recurrence it basically reads all of the

282
00:11:07,500 --> 00:11:09,540
previously queued requests it batches

283
00:11:09,540 --> 00:11:11,459
them together and then it breaks it down

284
00:11:11,459 --> 00:11:13,800
into the composite export operations and

285
00:11:13,800 --> 00:11:15,959
then kicks those off and I'll talk a bit

286
00:11:15,959 --> 00:11:18,000
more about that breakdown in just a

287
00:11:18,000 --> 00:11:19,500
minute

288
00:11:19,500 --> 00:11:22,560
so one thing that we found is that data

289
00:11:22,560 --> 00:11:25,079
requests tend to repeat so grouping

290
00:11:25,079 --> 00:11:27,540
related data together makes it a lot

291
00:11:27,540 --> 00:11:30,060
easier to set up requests and we call

292
00:11:30,060 --> 00:11:32,940
that grouping templates in our system so

293
00:11:32,940 --> 00:11:34,740
for example we could have a writer

294
00:11:34,740 --> 00:11:37,200
template that groups all of the commonly

295
00:11:37,200 --> 00:11:40,620
requested data by writers like their

296
00:11:40,620 --> 00:11:42,899
trip information their profile details

297
00:11:42,899 --> 00:11:45,240
their feedback from drivers and and so

298
00:11:45,240 --> 00:11:47,760
on in the UI you saw earlier essentially

299
00:11:47,760 --> 00:11:49,740
it boils down to making a single tick

300
00:11:49,740 --> 00:11:51,899
box selection which allows you to get

301
00:11:51,899 --> 00:11:53,940
all of that data in one go

302
00:11:53,940 --> 00:11:55,860
uh secondly like I mentioned we wanted

303
00:11:55,860 --> 00:11:57,779
to make sure that our system can onboard

304
00:11:57,779 --> 00:12:01,019
and off-board data uh easily

305
00:12:01,019 --> 00:12:02,880
and here is kind of a proposed data

306
00:12:02,880 --> 00:12:04,560
model that would allow us to kind of do

307
00:12:04,560 --> 00:12:06,779
that on the bottom we have our data

308
00:12:06,779 --> 00:12:08,459
source entity which essentially

309
00:12:08,459 --> 00:12:10,740
represents our underlying data and

310
00:12:10,740 --> 00:12:12,360
consists of things like the source table

311
00:12:12,360 --> 00:12:14,940
name and the required columns and then

312
00:12:14,940 --> 00:12:16,980
on the top we have our template entity

313
00:12:16,980 --> 00:12:19,440
which essentially is a container for

314
00:12:19,440 --> 00:12:23,040
data sources so I mentioned our writer

315
00:12:23,040 --> 00:12:24,480
template a minute ago but imagine now

316
00:12:24,480 --> 00:12:26,760
you have eaters also reaching out to

317
00:12:26,760 --> 00:12:28,560
request their data you kind of can

318
00:12:28,560 --> 00:12:30,720
create the underlying data sources like

319
00:12:30,720 --> 00:12:33,720
order details or historical promotion

320
00:12:33,720 --> 00:12:35,940
information you can create an either

321
00:12:35,940 --> 00:12:38,279
template and then you can group those

322
00:12:38,279 --> 00:12:40,440
data sources within that template to

323
00:12:40,440 --> 00:12:43,740
make it easier to submit those requests

324
00:12:43,740 --> 00:12:46,260
now more generally our API kind of

325
00:12:46,260 --> 00:12:49,800
allows us to easily update templates

326
00:12:49,800 --> 00:12:52,860
template memberships data sources or

327
00:12:52,860 --> 00:12:55,339
columns

328
00:12:55,399 --> 00:12:58,320
so now that we've kind of briefly talked

329
00:12:58,320 --> 00:13:00,540
about how do you set up requests how you

330
00:13:00,540 --> 00:13:03,060
define templates and data sources what

331
00:13:03,060 --> 00:13:04,980
does request processing actually look

332
00:13:04,980 --> 00:13:07,920
like on the back end well imagine you

333
00:13:07,920 --> 00:13:10,680
have thousands of user requests covering

334
00:13:10,680 --> 00:13:12,959
dozens of data sources all coming in at

335
00:13:12,959 --> 00:13:17,220
once those processes can be long running

336
00:13:17,220 --> 00:13:20,100
and computationally expensive so the way

337
00:13:20,100 --> 00:13:21,839
for us to scale is to really be able to

338
00:13:21,839 --> 00:13:24,300
break those down and we've done that

339
00:13:24,300 --> 00:13:26,459
through introducing the concept of a

340
00:13:26,459 --> 00:13:29,220
cuboid essentially it represents our

341
00:13:29,220 --> 00:13:32,519
minimal unit of execution and it's

342
00:13:32,519 --> 00:13:36,300
essentially a grouping of users data

343
00:13:36,300 --> 00:13:38,160
source over specific time range for

344
00:13:38,160 --> 00:13:40,200
which a specific pipeline is exporting

345
00:13:40,200 --> 00:13:43,560
data now we also use that concept to be

346
00:13:43,560 --> 00:13:45,899
able to scale our system so our system

347
00:13:45,899 --> 00:13:47,339
is configurable on any one of these

348
00:13:47,339 --> 00:13:49,860
Dimensions we can either process more

349
00:13:49,860 --> 00:13:52,320
users a wider time range or more data

350
00:13:52,320 --> 00:13:54,360
sources and then we could also customize

351
00:13:54,360 --> 00:13:56,220
how many operations we're running in

352
00:13:56,220 --> 00:13:58,380
parallel so all of those kind of come

353
00:13:58,380 --> 00:14:00,120
together to allow us to scale our system

354
00:14:00,120 --> 00:14:02,760
with our compute

355
00:14:02,760 --> 00:14:04,320
so to kind of illustrate what that

356
00:14:04,320 --> 00:14:06,839
actually means let's say you have this

357
00:14:06,839 --> 00:14:08,579
these are request coming in it covers

358
00:14:08,579 --> 00:14:10,740
users one through 300 which are

359
00:14:10,740 --> 00:14:13,320
requesting data from data source one

360
00:14:13,320 --> 00:14:16,560
covering the Years 2013 to 2017 and data

361
00:14:16,560 --> 00:14:19,740
source 2 covering 2015 and 2022. a

362
00:14:19,740 --> 00:14:21,420
possible way to break that down into

363
00:14:21,420 --> 00:14:23,279
cuboids would kind of be what what I'm

364
00:14:23,279 --> 00:14:25,680
showing here on the slide cuboid1 will

365
00:14:25,680 --> 00:14:28,980
cover users 1 through 150 of request for

366
00:14:28,980 --> 00:14:30,560
the data coming from data source one

367
00:14:30,560 --> 00:14:34,860
covering Years 2013 to 2015. now Q by 2

368
00:14:34,860 --> 00:14:36,899
basically covers the same user same data

369
00:14:36,899 --> 00:14:38,100
source but a different time range

370
00:14:38,100 --> 00:14:41,339
covering 2016 and 2017 in this case

371
00:14:41,339 --> 00:14:43,980
uh essentially we'll be running each one

372
00:14:43,980 --> 00:14:46,740
of these operations independently and

373
00:14:46,740 --> 00:14:48,720
then once they've all completed

374
00:14:48,720 --> 00:14:50,639
successfully our orchestrator can

375
00:14:50,639 --> 00:14:52,740
reconstruct the original request and

376
00:14:52,740 --> 00:14:54,660
then compose the outputs

377
00:14:54,660 --> 00:14:57,720
so one more view of our cuboid kind of

378
00:14:57,720 --> 00:15:00,420
in action here is imagine you have the

379
00:15:00,420 --> 00:15:02,639
request it was broken down into several

380
00:15:02,639 --> 00:15:04,860
cuboids the first two were successful

381
00:15:04,860 --> 00:15:07,860
but the third one fails due to uh

382
00:15:07,860 --> 00:15:10,019
infrastructure failure for example if

383
00:15:10,019 --> 00:15:11,639
you discard the entire request you'd be

384
00:15:11,639 --> 00:15:15,060
losing a lot of processing time so we

385
00:15:15,060 --> 00:15:17,000
built our system with checkpointing

386
00:15:17,000 --> 00:15:19,139
enabled so we can pick up from the

387
00:15:19,139 --> 00:15:21,600
latest failure without having to kind of

388
00:15:21,600 --> 00:15:23,339
reprocess previously successful

389
00:15:23,339 --> 00:15:25,860
operations here it really boils down to

390
00:15:25,860 --> 00:15:27,360
trying to salvage as many of these like

391
00:15:27,360 --> 00:15:30,120
green successful operations while only

392
00:15:30,120 --> 00:15:31,920
we're trying the the ones that failed

393
00:15:31,920 --> 00:15:34,860
this enables us to protect our system

394
00:15:34,860 --> 00:15:36,720
from overload and then from cascading

395
00:15:36,720 --> 00:15:39,500
failures as well

396
00:15:39,959 --> 00:15:42,360
so those are some of kind of our main

397
00:15:42,360 --> 00:15:44,100
Concepts behind our diesel automation

398
00:15:44,100 --> 00:15:46,620
system but it's important to call out

399
00:15:46,620 --> 00:15:48,600
that it kind of fits into a wider

400
00:15:48,600 --> 00:15:50,760
ecosystem of trying to provide customers

401
00:15:50,760 --> 00:15:53,459
with a richer experience through or

402
00:15:53,459 --> 00:15:55,380
richer insights even through data

403
00:15:55,380 --> 00:15:58,079
exports last year we released our

404
00:15:58,079 --> 00:16:00,240
privacy Center which is available

405
00:16:00,240 --> 00:16:03,480
through Uber Suite of apps and allows

406
00:16:03,480 --> 00:16:05,459
users to engage with additional features

407
00:16:05,459 --> 00:16:08,160
like explore your data which essentially

408
00:16:08,160 --> 00:16:10,079
allows users to visualize their data and

409
00:16:10,079 --> 00:16:11,880
kind of make more sense of it and then

410
00:16:11,880 --> 00:16:14,040
download your data which allows users to

411
00:16:14,040 --> 00:16:16,019
directly through the app request a copy

412
00:16:16,019 --> 00:16:18,899
of their most pertinent data from Uber

413
00:16:18,899 --> 00:16:22,139
uh the Privacy Center kind of was well

414
00:16:22,139 --> 00:16:25,079
received but in all honesty it's the

415
00:16:25,079 --> 00:16:27,060
investments in automation that allow us

416
00:16:27,060 --> 00:16:29,459
to focus on features like the Privacy

417
00:16:29,459 --> 00:16:32,160
Center so automation really is what

418
00:16:32,160 --> 00:16:33,779
allows us to build not only for truck

419
00:16:33,779 --> 00:16:37,019
for compliance but also for trust

420
00:16:37,019 --> 00:16:39,800
and I'm nearing the end here so I guess

421
00:16:39,800 --> 00:16:42,060
what am I really hoping you take from

422
00:16:42,060 --> 00:16:44,519
all this and and I have a few kind of uh

423
00:16:44,519 --> 00:16:47,040
parting taglines that I'll review the

424
00:16:47,040 --> 00:16:48,779
first one is write process right place

425
00:16:48,779 --> 00:16:51,300
right time so one thing you need to do

426
00:16:51,300 --> 00:16:54,240
is really understand your company's data

427
00:16:54,240 --> 00:16:55,740
profile and then be able to clearly

428
00:16:55,740 --> 00:16:57,660
assess do I need to build my own

429
00:16:57,660 --> 00:16:59,519
solution or

430
00:16:59,519 --> 00:17:02,279
um can I buy an existing solution would

431
00:17:02,279 --> 00:17:04,619
that be good enough the second is make

432
00:17:04,619 --> 00:17:06,119
the case for automation

433
00:17:06,119 --> 00:17:09,240
so you really need to kind of speak the

434
00:17:09,240 --> 00:17:10,919
language of the business and be able to

435
00:17:10,919 --> 00:17:13,140
clearly quantify the full cost of uh

436
00:17:13,140 --> 00:17:15,839
fulfillment and then also be able to

437
00:17:15,839 --> 00:17:18,240
gauge the level of savings that are

438
00:17:18,240 --> 00:17:20,160
possible through Automation and then

439
00:17:20,160 --> 00:17:21,780
lastly is uh kind of build a robust

440
00:17:21,780 --> 00:17:24,240
system which means basically build with

441
00:17:24,240 --> 00:17:26,640
a scale in mind and make sure that you

442
00:17:26,640 --> 00:17:28,559
can grow your system to accommodate

443
00:17:28,559 --> 00:17:31,559
additional demand and squeeze as much as

444
00:17:31,559 --> 00:17:33,540
you can out of your computer your

445
00:17:33,540 --> 00:17:34,620
resources

446
00:17:34,620 --> 00:17:38,340
uh and then I guess a final or parting

447
00:17:38,340 --> 00:17:40,620
notes before I end whether you're

448
00:17:40,620 --> 00:17:43,860
building for compliance or for trust I I

449
00:17:43,860 --> 00:17:45,780
really think it's kind of an endless

450
00:17:45,780 --> 00:17:48,780
journey and this is basically kind of

451
00:17:48,780 --> 00:17:50,280
these are automation is one of our

452
00:17:50,280 --> 00:17:53,100
Milestones on that Journey but uh in all

453
00:17:53,100 --> 00:17:55,740
honesty I think the the road is uh long

454
00:17:55,740 --> 00:17:58,380
and there's still many things to do that

455
00:17:58,380 --> 00:17:59,940
are coming up there's many things we

456
00:17:59,940 --> 00:18:01,320
still need to learn things we need to

457
00:18:01,320 --> 00:18:02,520
improve and things we need to get better

458
00:18:02,520 --> 00:18:04,440
and I think we're going to strive to do

459
00:18:04,440 --> 00:18:07,020
exactly that I'd like to really thank

460
00:18:07,020 --> 00:18:09,740
you for your time

