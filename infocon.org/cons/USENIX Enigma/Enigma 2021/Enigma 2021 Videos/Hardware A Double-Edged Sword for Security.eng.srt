1
00:00:09,040 --> 00:00:09,360
hi

2
00:00:09,360 --> 00:00:11,200
my name is nicole fern i'm a senior

3
00:00:11,200 --> 00:00:13,280
hardware security engineer for tortuga

4
00:00:13,280 --> 00:00:14,240
logic

5
00:00:14,240 --> 00:00:16,160
and i'm really excited to be here

6
00:00:16,160 --> 00:00:18,080
virtually with all of you to talk about

7
00:00:18,080 --> 00:00:19,920
how hardware can be a double-edged sword

8
00:00:19,920 --> 00:00:22,640
for security

9
00:00:23,439 --> 00:00:25,439
one of the main messages of this talk is

10
00:00:25,439 --> 00:00:27,439
that hardware now more than ever

11
00:00:27,439 --> 00:00:29,439
is essential to consider in the context

12
00:00:29,439 --> 00:00:31,359
of security

13
00:00:31,359 --> 00:00:34,719
if you plot the number of cves that

14
00:00:34,719 --> 00:00:36,960
have the word hardware in them over the

15
00:00:36,960 --> 00:00:38,079
years you'll see

16
00:00:38,079 --> 00:00:41,120
a definite trend of increasing focus

17
00:00:41,120 --> 00:00:43,280
on hardware as a place where attackers

18
00:00:43,280 --> 00:00:45,520
are looking for vulnerabilities

19
00:00:45,520 --> 00:00:48,239
and this is because hardware is truly a

20
00:00:48,239 --> 00:00:49,760
double-edged sword

21
00:00:49,760 --> 00:00:52,239
it's relied upon as a trust anchor but

22
00:00:52,239 --> 00:00:54,320
also can open systems up to

23
00:00:54,320 --> 00:00:56,719
attack

24
00:00:57,680 --> 00:00:59,920
a key question in all of this is who

25
00:00:59,920 --> 00:01:01,120
wields the sword

26
00:01:01,120 --> 00:01:04,000
whose responsibility is it to secure

27
00:01:04,000 --> 00:01:05,199
hardware

28
00:01:05,199 --> 00:01:07,439
hardware is not designed in a vacuum the

29
00:01:07,439 --> 00:01:09,119
hardware system is global

30
00:01:09,119 --> 00:01:11,840
it's complex it involves many different

31
00:01:11,840 --> 00:01:13,920
countries and organizations and all of

32
00:01:13,920 --> 00:01:15,680
them have different motivations when it

33
00:01:15,680 --> 00:01:16,320
comes to

34
00:01:16,320 --> 00:01:20,080
hardware security and this is what makes

35
00:01:20,080 --> 00:01:24,080
securing hardware incredibly challenging

36
00:01:25,040 --> 00:01:27,360
so to start with i want to talk a little

37
00:01:27,360 --> 00:01:28,479
bit more in detail

38
00:01:28,479 --> 00:01:31,360
about how hardware can be used to

39
00:01:31,360 --> 00:01:33,200
protect a system

40
00:01:33,200 --> 00:01:34,960
and over the course of the next few

41
00:01:34,960 --> 00:01:36,720
slides we'll see that

42
00:01:36,720 --> 00:01:39,280
while hardware security features are

43
00:01:39,280 --> 00:01:40,000
fantastic

44
00:01:40,000 --> 00:01:43,040
to include as protection for a larger

45
00:01:43,040 --> 00:01:43,920
system

46
00:01:43,920 --> 00:01:46,240
to provide any security at all these

47
00:01:46,240 --> 00:01:48,079
security features have to be implemented

48
00:01:48,079 --> 00:01:49,840
configured and used correctly

49
00:01:49,840 --> 00:01:54,640
which is not always straightforward

50
00:01:54,640 --> 00:01:57,040
hardware is a natural choice to be used

51
00:01:57,040 --> 00:01:58,479
as a trust anchor

52
00:01:58,479 --> 00:02:00,880
because hardware can provide services

53
00:02:00,880 --> 00:02:03,200
such as cryptographic acceleration

54
00:02:03,200 --> 00:02:05,920
secure storage in the form of one-time

55
00:02:05,920 --> 00:02:07,439
programmable memory

56
00:02:07,439 --> 00:02:09,440
and a whole host of other things that

57
00:02:09,440 --> 00:02:12,319
are difficult if not impossible to

58
00:02:12,319 --> 00:02:15,840
provide using just software alone

59
00:02:15,840 --> 00:02:18,239
we're seeing a definite trend towards

60
00:02:18,239 --> 00:02:18,879
using

61
00:02:18,879 --> 00:02:22,000
hardware subsystems that consolidate

62
00:02:22,000 --> 00:02:23,680
all of these security services and

63
00:02:23,680 --> 00:02:25,840
security functionality

64
00:02:25,840 --> 00:02:29,280
into into one ip core that's that's can

65
00:02:29,280 --> 00:02:30,239
be sold to

66
00:02:30,239 --> 00:02:32,640
anyone developing a system on chip

67
00:02:32,640 --> 00:02:34,080
commonly abbreviated as

68
00:02:34,080 --> 00:02:37,840
soc these roots of trust are subsystems

69
00:02:37,840 --> 00:02:40,239
focused exclusively on security

70
00:02:40,239 --> 00:02:43,200
and what they provide to in an soc

71
00:02:43,200 --> 00:02:43,920
designer

72
00:02:43,920 --> 00:02:46,480
is the ability to kind of optimize the

73
00:02:46,480 --> 00:02:48,720
security subsystem for security

74
00:02:48,720 --> 00:02:51,840
and then leave the remaining portions of

75
00:02:51,840 --> 00:02:53,599
the system

76
00:02:53,599 --> 00:02:56,080
open to being optimized for things like

77
00:02:56,080 --> 00:02:57,920
performance

78
00:02:57,920 --> 00:03:00,319
and so while this is you know great that

79
00:03:00,319 --> 00:03:01,840
we have dedicated

80
00:03:01,840 --> 00:03:06,239
ip being sold for security specifically

81
00:03:06,239 --> 00:03:08,319
um one thing to keep in mind is that you

82
00:03:08,319 --> 00:03:10,239
know it's not enough just to buy one of

83
00:03:10,239 --> 00:03:11,920
these hardware routes of trust from for

84
00:03:11,920 --> 00:03:13,120
example rambus

85
00:03:13,120 --> 00:03:16,159
or synopsis and just instantiate it in

86
00:03:16,159 --> 00:03:17,599
your design and assume

87
00:03:17,599 --> 00:03:20,720
you are secure

88
00:03:21,120 --> 00:03:23,760
purchasing and using security ip is kind

89
00:03:23,760 --> 00:03:24,159
of

90
00:03:24,159 --> 00:03:27,440
like buying a gate to secure your house

91
00:03:27,440 --> 00:03:30,480
in this picture shown on the slide you

92
00:03:30,480 --> 00:03:31,440
know

93
00:03:31,440 --> 00:03:34,000
the gate isn't providing any security

94
00:03:34,000 --> 00:03:35,599
because you can just walk through the

95
00:03:35,599 --> 00:03:37,280
lawn and circumvent it

96
00:03:37,280 --> 00:03:39,440
but that's not to say that in a

97
00:03:39,440 --> 00:03:41,360
different system in a different house in

98
00:03:41,360 --> 00:03:43,599
a different context that same gate

99
00:03:43,599 --> 00:03:46,560
might provide adequate security in a

100
00:03:46,560 --> 00:03:48,799
lawn with for example a fence or a wall

101
00:03:48,799 --> 00:03:51,120
surrounding it

102
00:03:51,120 --> 00:03:54,319
and this is similar to what what

103
00:03:54,319 --> 00:03:57,360
has to be true to secure an soc of

104
00:03:57,360 --> 00:04:00,640
course the security of an soc depends on

105
00:04:00,640 --> 00:04:03,120
the security of the hardware logic

106
00:04:03,120 --> 00:04:05,040
itself specifically the the root of

107
00:04:05,040 --> 00:04:06,239
trust logic

108
00:04:06,239 --> 00:04:08,480
but additionally it's highly dependent

109
00:04:08,480 --> 00:04:09,280
on the

110
00:04:09,280 --> 00:04:11,920
hardware configuration and integration

111
00:04:11,920 --> 00:04:12,560
of

112
00:04:12,560 --> 00:04:14,799
of that ip into the larger system and

113
00:04:14,799 --> 00:04:16,639
also it's dependent on how software

114
00:04:16,639 --> 00:04:20,160
uses and configures security features

115
00:04:20,160 --> 00:04:22,560
and this is can be complex to analyze in

116
00:04:22,560 --> 00:04:24,720
the context of an entire system because

117
00:04:24,720 --> 00:04:26,720
vulnerabilities hide in design

118
00:04:26,720 --> 00:04:27,680
complexity

119
00:04:27,680 --> 00:04:29,680
and interaction between different system

120
00:04:29,680 --> 00:04:32,320
components

121
00:04:33,199 --> 00:04:35,440
the cisco secure boot hardware tampering

122
00:04:35,440 --> 00:04:37,520
vulnerability is a great example

123
00:04:37,520 --> 00:04:39,840
of a route of trust that was improperly

124
00:04:39,840 --> 00:04:42,400
integrated into a larger system

125
00:04:42,400 --> 00:04:46,000
cisco used an fpga to provide

126
00:04:46,000 --> 00:04:48,080
you know the trust anchor for their

127
00:04:48,080 --> 00:04:50,639
entire device the entire router

128
00:04:50,639 --> 00:04:53,360
however the bitstream fpga the fpga

129
00:04:53,360 --> 00:04:54,160
bitstream

130
00:04:54,160 --> 00:04:55,600
which completely controls the

131
00:04:55,600 --> 00:04:57,600
functionality of the fpga

132
00:04:57,600 --> 00:05:00,160
was stored unprotected in spyflash and

133
00:05:00,160 --> 00:05:02,240
could be modified by an attacker

134
00:05:02,240 --> 00:05:04,639
the flash region was not protected from

135
00:05:04,639 --> 00:05:06,080
privileged software rights

136
00:05:06,080 --> 00:05:08,400
from the application cpu and it also

137
00:05:08,400 --> 00:05:11,039
wasn't encrypted so it's fairly

138
00:05:11,039 --> 00:05:13,919
easy for an attacker to you know

139
00:05:13,919 --> 00:05:14,560
overwrite

140
00:05:14,560 --> 00:05:17,039
the bitstream to accomplish their own

141
00:05:17,039 --> 00:05:19,120
functionality which had the consequence

142
00:05:19,120 --> 00:05:19,759
of

143
00:05:19,759 --> 00:05:22,400
completely bypassing secure boot or

144
00:05:22,400 --> 00:05:23,120
defeating

145
00:05:23,120 --> 00:05:24,960
secure boot which is one of the main

146
00:05:24,960 --> 00:05:26,560
security services

147
00:05:26,560 --> 00:05:28,720
this route of trust was providing for

148
00:05:28,720 --> 00:05:31,280
the router

149
00:05:32,720 --> 00:05:35,360
earlier i mentioned complexity and one

150
00:05:35,360 --> 00:05:36,000
thing that

151
00:05:36,000 --> 00:05:38,400
makes hardware complex is that it's

152
00:05:38,400 --> 00:05:40,639
highly configurable

153
00:05:40,639 --> 00:05:42,960
hardware needs to be configurable for

154
00:05:42,960 --> 00:05:45,280
both flexibility reasons and also

155
00:05:45,280 --> 00:05:47,520
fixability reasons

156
00:05:47,520 --> 00:05:51,360
if you can imagine once once a hardware

157
00:05:51,360 --> 00:05:52,240
design

158
00:05:52,240 --> 00:05:54,240
enters the physical world as silicon

159
00:05:54,240 --> 00:05:56,400
it's really really difficult

160
00:05:56,400 --> 00:05:58,560
almost impossible to edit that that

161
00:05:58,560 --> 00:05:59,759
functionality

162
00:05:59,759 --> 00:06:03,039
right once once the um silicon you know

163
00:06:03,039 --> 00:06:04,080
is

164
00:06:04,080 --> 00:06:07,039
taped out then that's it if you find a

165
00:06:07,039 --> 00:06:09,520
problem or a security vulnerability

166
00:06:09,520 --> 00:06:11,919
with the hardware design itself you have

167
00:06:11,919 --> 00:06:13,039
to work around it

168
00:06:13,039 --> 00:06:15,600
using things like microcode patches or

169
00:06:15,600 --> 00:06:18,639
firmware patches

170
00:06:18,840 --> 00:06:21,199
another option for providing

171
00:06:21,199 --> 00:06:22,960
configurability and hardware

172
00:06:22,960 --> 00:06:26,400
is is registers one common design

173
00:06:26,400 --> 00:06:28,160
practice is to use something called

174
00:06:28,160 --> 00:06:30,080
chicken bits chicken bits are kind of a

175
00:06:30,080 --> 00:06:32,479
special type of configuration register

176
00:06:32,479 --> 00:06:34,960
they are undocumented bits on a device

177
00:06:34,960 --> 00:06:35,840
that can be able

178
00:06:35,840 --> 00:06:38,000
then that can be used to disable certain

179
00:06:38,000 --> 00:06:39,600
functional security features

180
00:06:39,600 --> 00:06:43,680
or more generally any feature

181
00:06:43,680 --> 00:06:45,520
so why would someone include chicken

182
00:06:45,520 --> 00:06:46,960
bits in their design

183
00:06:46,960 --> 00:06:50,639
it provides the hardware designer

184
00:06:50,639 --> 00:06:53,759
the opportunity to chicken out of using

185
00:06:53,759 --> 00:06:56,639
a particular feature if a bug in the

186
00:06:56,639 --> 00:06:57,280
silicon

187
00:06:57,280 --> 00:07:01,520
in that feature is later discovered

188
00:07:01,759 --> 00:07:04,160
but clearly this has security

189
00:07:04,160 --> 00:07:05,360
implications

190
00:07:05,360 --> 00:07:08,400
and ramifications

191
00:07:10,000 --> 00:07:12,479
so the configuration space of hardware

192
00:07:12,479 --> 00:07:14,400
grows exponentially with design

193
00:07:14,400 --> 00:07:15,840
size and this can make it really

194
00:07:15,840 --> 00:07:18,000
difficult to determine the impact of

195
00:07:18,000 --> 00:07:21,120
a specific configuration on security

196
00:07:21,120 --> 00:07:22,639
you know imagine you're trying to write

197
00:07:22,639 --> 00:07:24,720
the firmware for

198
00:07:24,720 --> 00:07:27,440
a hardware component that has 100

199
00:07:27,440 --> 00:07:28,800
configuration bits

200
00:07:28,800 --> 00:07:31,120
it's it's really difficult to determine

201
00:07:31,120 --> 00:07:32,000
okay which bits

202
00:07:32,000 --> 00:07:34,880
influence security which bits influence

203
00:07:34,880 --> 00:07:36,800
functionality and to get it right

204
00:07:36,800 --> 00:07:39,840
and it's made even harder if the default

205
00:07:39,840 --> 00:07:40,560
values

206
00:07:40,560 --> 00:07:42,400
for those configuration bits and the

207
00:07:42,400 --> 00:07:43,919
registers

208
00:07:43,919 --> 00:07:46,639
lead to an insecure configuration and

209
00:07:46,639 --> 00:07:49,120
that's exactly what happened in this bmc

210
00:07:49,120 --> 00:07:50,319
vulnerability

211
00:07:50,319 --> 00:07:52,160
and that the default configuration

212
00:07:52,160 --> 00:07:53,360
resulted in

213
00:07:53,360 --> 00:07:56,000
the host cpu having arbitrary access to

214
00:07:56,000 --> 00:07:58,720
the bmc's entire memory space

215
00:07:58,720 --> 00:08:00,800
so to mitigate this vulnerability the

216
00:08:00,800 --> 00:08:03,360
firmware had to be updated to

217
00:08:03,360 --> 00:08:05,919
change the default configuration and

218
00:08:05,919 --> 00:08:06,800
secure

219
00:08:06,800 --> 00:08:12,160
the device

220
00:08:12,160 --> 00:08:15,039
the debug infrastructure is another

221
00:08:15,039 --> 00:08:16,560
example of

222
00:08:16,560 --> 00:08:18,720
hardware that's typically configurable

223
00:08:18,720 --> 00:08:19,840
and also has an

224
00:08:19,840 --> 00:08:22,879
impact on the overall security posture

225
00:08:22,879 --> 00:08:24,960
of the device

226
00:08:24,960 --> 00:08:28,000
nail gun is a vulnerability that

227
00:08:28,000 --> 00:08:30,160
shows how certain insecure

228
00:08:30,160 --> 00:08:32,880
configurations of arm's multi-core debug

229
00:08:32,880 --> 00:08:34,799
infrastructure can lead to

230
00:08:34,799 --> 00:08:36,799
privilege escalation that doesn't

231
00:08:36,799 --> 00:08:40,159
require physical access to the device so

232
00:08:40,159 --> 00:08:40,559
in

233
00:08:40,559 --> 00:08:43,760
arm's multi-core debug model one core

234
00:08:43,760 --> 00:08:46,480
can be used as a debug host for another

235
00:08:46,480 --> 00:08:46,959
core

236
00:08:46,959 --> 00:08:48,560
and so that's in contrast to the

237
00:08:48,560 --> 00:08:50,399
traditional debug model where

238
00:08:50,399 --> 00:08:53,920
the debug host is always an external

239
00:08:53,920 --> 00:08:55,200
debugger

240
00:08:55,200 --> 00:08:59,360
connected physically to the chip

241
00:09:00,320 --> 00:09:03,760
this vulnerability can be prevented by

242
00:09:03,760 --> 00:09:06,640
setting these four configuration signals

243
00:09:06,640 --> 00:09:07,839
correctly

244
00:09:07,839 --> 00:09:10,560
but how however the authors of the nail

245
00:09:10,560 --> 00:09:12,320
gun paper they noticed or

246
00:09:12,320 --> 00:09:14,880
they noted that a lot of devices that

247
00:09:14,880 --> 00:09:15,680
they looked at

248
00:09:15,680 --> 00:09:18,399
were set in the insecure configuration

249
00:09:18,399 --> 00:09:19,279
and

250
00:09:19,279 --> 00:09:22,000
they guessed this is because it severely

251
00:09:22,000 --> 00:09:23,040
restricts the

252
00:09:23,040 --> 00:09:24,959
debug functionality if you put it in the

253
00:09:24,959 --> 00:09:28,000
secure configuration so a lot of

254
00:09:28,000 --> 00:09:31,120
device vendors chose to just make it

255
00:09:31,120 --> 00:09:32,240
more flexible

256
00:09:32,240 --> 00:09:34,839
more usable more convenient but

257
00:09:34,839 --> 00:09:36,000
ultimately

258
00:09:36,000 --> 00:09:39,519
insecure another important point

259
00:09:39,519 --> 00:09:42,320
that this paper brings up is that there

260
00:09:42,320 --> 00:09:43,760
are a lot of different

261
00:09:43,760 --> 00:09:45,839
parties involved that make decisions

262
00:09:45,839 --> 00:09:47,839
that influence security so for this

263
00:09:47,839 --> 00:09:49,680
specific example

264
00:09:49,680 --> 00:09:52,640
arm provides the four signals in the

265
00:09:52,640 --> 00:09:55,279
architecture the debug architecture

266
00:09:55,279 --> 00:09:58,320
but then it's up to the soc vendor

267
00:09:58,320 --> 00:10:01,519
such as qualcomm who buys processors

268
00:10:01,519 --> 00:10:03,200
from arm and incorporates them

269
00:10:03,200 --> 00:10:06,480
into their chip they control how

270
00:10:06,480 --> 00:10:10,079
their customers set these

271
00:10:10,079 --> 00:10:12,640
for debug signals whether they're

272
00:10:12,640 --> 00:10:14,880
through fuses or through configuration

273
00:10:14,880 --> 00:10:16,959
registers or just hard coded that's up

274
00:10:16,959 --> 00:10:20,160
to the soc manufacturer

275
00:10:20,160 --> 00:10:22,959
and so their customers in the mobile

276
00:10:22,959 --> 00:10:24,720
device ecosystem this would be the

277
00:10:24,720 --> 00:10:26,240
people making mobile phones such as

278
00:10:26,240 --> 00:10:27,680
samsung or google they buy

279
00:10:27,680 --> 00:10:29,600
chip from qualcomm and then it's up to

280
00:10:29,600 --> 00:10:31,279
them to set

281
00:10:31,279 --> 00:10:33,440
fuses at the factory to the correct

282
00:10:33,440 --> 00:10:34,720
values or

283
00:10:34,720 --> 00:10:37,440
in their firmware stack write secure

284
00:10:37,440 --> 00:10:38,399
values to

285
00:10:38,399 --> 00:10:42,079
the configuration registers

286
00:10:43,440 --> 00:10:45,040
so it's pretty clear that security

287
00:10:45,040 --> 00:10:46,720
requires alignment across

288
00:10:46,720 --> 00:10:49,519
many stakeholders many companies and

289
00:10:49,519 --> 00:10:51,760
countries are involved in creating and

290
00:10:51,760 --> 00:10:54,399
using silicon chips and it's not easy to

291
00:10:54,399 --> 00:10:55,279
point to

292
00:10:55,279 --> 00:10:58,240
any individual stakeholder and say you

293
00:10:58,240 --> 00:10:58,880
know you

294
00:10:58,880 --> 00:11:03,760
are solely responsible for security

295
00:11:06,160 --> 00:11:07,839
so we've talked about how hardware

296
00:11:07,839 --> 00:11:09,760
security features have to be configured

297
00:11:09,760 --> 00:11:11,680
and used correctly to provide security

298
00:11:11,680 --> 00:11:13,440
but now i want to shift gears and talk

299
00:11:13,440 --> 00:11:14,480
about

300
00:11:14,480 --> 00:11:16,320
other hardware features that have

301
00:11:16,320 --> 00:11:18,000
nothing to do with security

302
00:11:18,000 --> 00:11:21,200
but make systems vulnerable to attacks

303
00:11:21,200 --> 00:11:23,920
i like to call this class of this class

304
00:11:23,920 --> 00:11:24,800
of issue

305
00:11:24,800 --> 00:11:27,200
when functional features become security

306
00:11:27,200 --> 00:11:28,160
problems

307
00:11:28,160 --> 00:11:30,079
there's a lot of complexity in modern

308
00:11:30,079 --> 00:11:31,200
hardware designs

309
00:11:31,200 --> 00:11:35,440
which comes from you know really

310
00:11:35,839 --> 00:11:37,760
really demanding requirements for

311
00:11:37,760 --> 00:11:38,959
performance from

312
00:11:38,959 --> 00:11:42,000
consumers we expect our devices to

313
00:11:42,000 --> 00:11:45,360
be extremely energy efficient responsive

314
00:11:45,360 --> 00:11:48,880
and always connected and to do this

315
00:11:48,880 --> 00:11:51,040
you know hardware designers have had to

316
00:11:51,040 --> 00:11:53,120
innovate a lot and that's where you

317
00:11:53,120 --> 00:11:55,200
you get things like direct memory access

318
00:11:55,200 --> 00:11:56,800
speculation

319
00:11:56,800 --> 00:12:00,639
etc etc and unfortunately these

320
00:12:00,639 --> 00:12:02,480
these functional performance features

321
00:12:02,480 --> 00:12:04,800
aren't always designed with security in

322
00:12:04,800 --> 00:12:07,120
mind

323
00:12:07,279 --> 00:12:08,959
a great example of this is dynamic

324
00:12:08,959 --> 00:12:10,720
voltage and frequency scaling

325
00:12:10,720 --> 00:12:13,519
dvfs is ubiquitous it's critical for

326
00:12:13,519 --> 00:12:15,200
energy efficiency

327
00:12:15,200 --> 00:12:17,920
what it is essentially is it's you know

328
00:12:17,920 --> 00:12:20,880
mechanism that allows software to manage

329
00:12:20,880 --> 00:12:23,360
the power consumption of the device so

330
00:12:23,360 --> 00:12:24,160
it can both

331
00:12:24,160 --> 00:12:27,360
modify and monitor power consumption and

332
00:12:27,360 --> 00:12:30,320
it's good to do this because the the

333
00:12:30,320 --> 00:12:31,920
operating system

334
00:12:31,920 --> 00:12:34,720
especially knows the workloads running

335
00:12:34,720 --> 00:12:35,760
on the device they know what

336
00:12:35,760 --> 00:12:37,600
applications are running and how much

337
00:12:37,600 --> 00:12:40,480
power they need so it's ideal for the

338
00:12:40,480 --> 00:12:42,320
operating system to

339
00:12:42,320 --> 00:12:45,680
control power consumption but this has

340
00:12:45,680 --> 00:12:47,760
the consequence that an operating

341
00:12:47,760 --> 00:12:49,680
the operating system can lower the

342
00:12:49,680 --> 00:12:51,839
voltage increase the frequency and

343
00:12:51,839 --> 00:12:52,320
inject

344
00:12:52,320 --> 00:12:54,959
faults during computation this is

345
00:12:54,959 --> 00:12:56,240
extremely relevant

346
00:12:56,240 --> 00:12:57,920
if you are relying on a trusted

347
00:12:57,920 --> 00:13:00,240
execution environment such as intel

348
00:13:00,240 --> 00:13:03,440
sgx or arm trust zone to protect you

349
00:13:03,440 --> 00:13:05,200
against a potentially malicious

350
00:13:05,200 --> 00:13:07,839
operating system

351
00:13:08,800 --> 00:13:12,079
being able to monitor power consumption

352
00:13:12,079 --> 00:13:13,440
from software also

353
00:13:13,440 --> 00:13:15,600
has implications for security the

354
00:13:15,600 --> 00:13:17,040
platypus attacks showed

355
00:13:17,040 --> 00:13:21,600
that using the interfaces for

356
00:13:21,600 --> 00:13:23,519
monitoring power that are available to

357
00:13:23,519 --> 00:13:25,200
unprivileged software

358
00:13:25,200 --> 00:13:27,440
you can perform a power side channel

359
00:13:27,440 --> 00:13:28,480
attack capable

360
00:13:28,480 --> 00:13:31,200
of recovering aes keys kernel as their

361
00:13:31,200 --> 00:13:32,560
offsets

362
00:13:32,560 --> 00:13:35,519
with no physical device access required

363
00:13:35,519 --> 00:13:35,839
and

364
00:13:35,839 --> 00:13:37,600
and that's that's pretty significant

365
00:13:37,600 --> 00:13:38,800
because typically when you think of

366
00:13:38,800 --> 00:13:40,079
fault injection

367
00:13:40,079 --> 00:13:42,320
and power side channel attacks you

368
00:13:42,320 --> 00:13:44,480
assume that the attacker has to have

369
00:13:44,480 --> 00:13:49,440
physical access to your device

370
00:13:49,440 --> 00:13:52,320
speculative and out of order execution

371
00:13:52,320 --> 00:13:53,839
is another great example

372
00:13:53,839 --> 00:13:57,519
of functionality added for performance

373
00:13:57,519 --> 00:13:58,320
reasons

374
00:13:58,320 --> 00:14:01,360
that is not transparent at all

375
00:14:01,360 --> 00:14:04,160
to the programmer's view of the

376
00:14:04,160 --> 00:14:06,320
processor

377
00:14:06,320 --> 00:14:08,160
which that was you know that was okay

378
00:14:08,160 --> 00:14:09,839
until the discovery of spectre and

379
00:14:09,839 --> 00:14:10,480
meltdown

380
00:14:10,480 --> 00:14:13,519
and then speculative execution

381
00:14:13,519 --> 00:14:16,000
micro architectural features were front

382
00:14:16,000 --> 00:14:17,519
and center with respect to

383
00:14:17,519 --> 00:14:21,120
security and you know it's unfortunate

384
00:14:21,120 --> 00:14:22,800
that those features are

385
00:14:22,800 --> 00:14:26,560
so opaque because

386
00:14:26,560 --> 00:14:29,040
you know not only addressing spectre and

387
00:14:29,040 --> 00:14:30,000
meltdown didn't

388
00:14:30,000 --> 00:14:32,720
involve only the processor vendors it

389
00:14:32,720 --> 00:14:33,440
didn't involve

390
00:14:33,440 --> 00:14:36,480
only companies like intel amd

391
00:14:36,480 --> 00:14:40,399
and arm it required a lot of

392
00:14:40,399 --> 00:14:42,240
a lot of involvement and contribution

393
00:14:42,240 --> 00:14:44,000
from the software community as well

394
00:14:44,000 --> 00:14:46,560
especially people developing compiler

395
00:14:46,560 --> 00:14:48,880
tool chains and operating systems

396
00:14:48,880 --> 00:14:51,120
all of these groups had to work together

397
00:14:51,120 --> 00:14:53,360
to come up with mitigations in a timely

398
00:14:53,360 --> 00:14:54,079
manner for

399
00:14:54,079 --> 00:14:58,160
spectre and meltdown

400
00:14:58,160 --> 00:15:00,639
so now that i've talked about all of the

401
00:15:00,639 --> 00:15:02,480
issues in hardware security all of the

402
00:15:02,480 --> 00:15:03,600
challenges in

403
00:15:03,600 --> 00:15:05,519
in the final few moments of this talk i

404
00:15:05,519 --> 00:15:08,079
want to present some solutions

405
00:15:08,079 --> 00:15:09,920
the first of which is industry-wide

406
00:15:09,920 --> 00:15:11,920
hardware security initiatives this

407
00:15:11,920 --> 00:15:13,600
category of solutions

408
00:15:13,600 --> 00:15:16,000
really is to address the challenge that

409
00:15:16,000 --> 00:15:18,480
security requires alignment between all

410
00:15:18,480 --> 00:15:20,079
the different stakeholders in the

411
00:15:20,079 --> 00:15:22,079
hardware ecosystem

412
00:15:22,079 --> 00:15:23,920
and so to foster alignment and

413
00:15:23,920 --> 00:15:25,120
communication

414
00:15:25,120 --> 00:15:27,120
you know you need these public

415
00:15:27,120 --> 00:15:28,320
initiatives that

416
00:15:28,320 --> 00:15:30,720
involve dozens and dozens of companies

417
00:15:30,720 --> 00:15:32,399
that are all contributing and working

418
00:15:32,399 --> 00:15:33,279
together

419
00:15:33,279 --> 00:15:35,759
and i've listed a few of these on this

420
00:15:35,759 --> 00:15:38,959
slide if you're interested

421
00:15:39,839 --> 00:15:42,399
another solution that can be implemented

422
00:15:42,399 --> 00:15:44,720
by an individual company or organization

423
00:15:44,720 --> 00:15:46,079
is something called a

424
00:15:46,079 --> 00:15:48,320
hardware security development lifecycle

425
00:15:48,320 --> 00:15:49,920
so this is for people who are designing

426
00:15:49,920 --> 00:15:51,199
hardware

427
00:15:51,199 --> 00:15:52,959
and this addresses the challenge that

428
00:15:52,959 --> 00:15:54,959
security issues can arise at different

429
00:15:54,959 --> 00:15:57,440
design stages so the idea is that you're

430
00:15:57,440 --> 00:15:58,079
going to

431
00:15:58,079 --> 00:16:01,120
as an organization dedicate resources to

432
00:16:01,120 --> 00:16:02,959
addressing security throughout

433
00:16:02,959 --> 00:16:05,360
the entire hardware development life

434
00:16:05,360 --> 00:16:07,759
cycle and by addressing it early on and

435
00:16:07,759 --> 00:16:10,720
consistently you're going to reduce risk

436
00:16:10,720 --> 00:16:12,480
and this is a good idea for

437
00:16:12,480 --> 00:16:13,759
organizations to

438
00:16:13,759 --> 00:16:17,040
implement but it's it's easier said than

439
00:16:17,040 --> 00:16:18,480
done there's a lot of technical

440
00:16:18,480 --> 00:16:19,199
challenges

441
00:16:19,199 --> 00:16:21,440
and this is where i believe that

442
00:16:21,440 --> 00:16:23,440
technical solutions can really play a

443
00:16:23,440 --> 00:16:24,959
major role in making this

444
00:16:24,959 --> 00:16:26,880
feasible for companies to implement

445
00:16:26,880 --> 00:16:28,959
under really intense

446
00:16:28,959 --> 00:16:31,600
time to market pressure and resource

447
00:16:31,600 --> 00:16:34,320
constraints

448
00:16:34,480 --> 00:16:37,360
so one technical solution to this

449
00:16:37,360 --> 00:16:37,920
problem

450
00:16:37,920 --> 00:16:39,600
i would like to bring up is hardware

451
00:16:39,600 --> 00:16:41,680
information flow analysis

452
00:16:41,680 --> 00:16:44,160
this is the technology that i work with

453
00:16:44,160 --> 00:16:44,800
on

454
00:16:44,800 --> 00:16:46,880
a daily basis so if you have any

455
00:16:46,880 --> 00:16:48,560
questions or this is something of

456
00:16:48,560 --> 00:16:50,079
interest to you please come and speak

457
00:16:50,079 --> 00:16:50,560
with me

458
00:16:50,560 --> 00:16:53,839
after the session a major

459
00:16:53,839 --> 00:16:56,399
problem that i see when people try to do

460
00:16:56,399 --> 00:16:59,040
security verification pre-silicon

461
00:16:59,040 --> 00:17:01,920
is that information flow is not a

462
00:17:01,920 --> 00:17:03,839
first-class concept in the existing

463
00:17:03,839 --> 00:17:04,880
tools

464
00:17:04,880 --> 00:17:07,439
which makes it really really awkward and

465
00:17:07,439 --> 00:17:08,720
really high effort

466
00:17:08,720 --> 00:17:12,880
to first off capture confidentiality and

467
00:17:12,880 --> 00:17:14,959
integrity requirements which are so

468
00:17:14,959 --> 00:17:16,400
central to security

469
00:17:16,400 --> 00:17:18,799
it's hard to capture those requirements

470
00:17:18,799 --> 00:17:19,520
in a way

471
00:17:19,520 --> 00:17:21,919
that you can actually verify in the

472
00:17:21,919 --> 00:17:25,039
context of your design implementation

473
00:17:25,039 --> 00:17:27,280
so if you employ something like hardware

474
00:17:27,280 --> 00:17:29,200
information flow tracking

475
00:17:29,200 --> 00:17:31,280
this streamlines the whole process and

476
00:17:31,280 --> 00:17:33,360
just makes it easier to specify and

477
00:17:33,360 --> 00:17:34,080
verify

478
00:17:34,080 --> 00:17:36,640
security requirements and hardware and

479
00:17:36,640 --> 00:17:38,880
again i'd be happy to talk with anyone

480
00:17:38,880 --> 00:17:42,160
after the session about this

481
00:17:43,600 --> 00:17:44,880
so we've seen that there are a lot of

482
00:17:44,880 --> 00:17:47,440
requirements for securing hardware

483
00:17:47,440 --> 00:17:49,200
you know first because hardware is a

484
00:17:49,200 --> 00:17:50,480
double edged sword

485
00:17:50,480 --> 00:17:52,559
if you have security features

486
00:17:52,559 --> 00:17:54,320
implemented in hardware that's great but

487
00:17:54,320 --> 00:17:55,520
these features have to be

488
00:17:55,520 --> 00:17:57,120
implemented configured and used

489
00:17:57,120 --> 00:17:58,640
correctly

490
00:17:58,640 --> 00:18:01,039
the other side of the coin is that

491
00:18:01,039 --> 00:18:01,760
features

492
00:18:01,760 --> 00:18:03,440
added in hardware to increase

493
00:18:03,440 --> 00:18:05,039
performance and usability

494
00:18:05,039 --> 00:18:07,200
really need to be considered from a

495
00:18:07,200 --> 00:18:09,360
security perspective

496
00:18:09,360 --> 00:18:11,600
you you can't just design functionality

497
00:18:11,600 --> 00:18:12,640
and assume that

498
00:18:12,640 --> 00:18:15,679
it's isolated from security because it's

499
00:18:15,679 --> 00:18:17,760
you know hard to really argue that

500
00:18:17,760 --> 00:18:19,760
anything is really isolated from

501
00:18:19,760 --> 00:18:23,120
from security and lastly security

502
00:18:23,120 --> 00:18:24,799
requires alignment across

503
00:18:24,799 --> 00:18:28,080
many different stakeholders and there's

504
00:18:28,080 --> 00:18:29,840
just many different groups of people

505
00:18:29,840 --> 00:18:32,400
involved in securing hardware besides

506
00:18:32,400 --> 00:18:33,840
just the people

507
00:18:33,840 --> 00:18:36,959
designing the hardware

508
00:18:37,280 --> 00:18:39,280
and so with that i would like to leave

509
00:18:39,280 --> 00:18:40,640
all of these different groups and

510
00:18:40,640 --> 00:18:42,559
stakeholders with some questions to

511
00:18:42,559 --> 00:18:44,640
think about after the talk

512
00:18:44,640 --> 00:18:47,280
if you're an ip provider or soc vendor

513
00:18:47,280 --> 00:18:49,039
you know what is your security strategy

514
00:18:49,039 --> 00:18:51,120
do you have a security strategy

515
00:18:51,120 --> 00:18:53,120
are you applying the same methodologies

516
00:18:53,120 --> 00:18:55,600
from functional verification to security

517
00:18:55,600 --> 00:18:57,440
and are you struggling you know so

518
00:18:57,440 --> 00:18:59,039
please come and talk with me after the

519
00:18:59,039 --> 00:19:00,720
session

520
00:19:00,720 --> 00:19:02,799
also how are you communicating security

521
00:19:02,799 --> 00:19:05,919
with those using your hardware or ip

522
00:19:05,919 --> 00:19:08,559
is it easy for your customers to use

523
00:19:08,559 --> 00:19:09,360
your

524
00:19:09,360 --> 00:19:11,440
your hardware in a secure way or do they

525
00:19:11,440 --> 00:19:12,720
have to read through

526
00:19:12,720 --> 00:19:15,039
500 pages of documentation to get it

527
00:19:15,039 --> 00:19:17,120
right

528
00:19:17,120 --> 00:19:19,600
if you are an oem or systems builder do

529
00:19:19,600 --> 00:19:21,440
you understand how hardware can affect

530
00:19:21,440 --> 00:19:22,400
your threat model

531
00:19:22,400 --> 00:19:24,559
and do you know how to configure and use

532
00:19:24,559 --> 00:19:27,039
the hardware in your device correctly

533
00:19:27,039 --> 00:19:28,799
and lastly if you're a software

534
00:19:28,799 --> 00:19:30,160
developer

535
00:19:30,160 --> 00:19:32,799
you should be asking yourself are you

536
00:19:32,799 --> 00:19:34,320
considering hardware in your threat

537
00:19:34,320 --> 00:19:35,760
model do you need to be considering

538
00:19:35,760 --> 00:19:37,760
hardware in your threat model

539
00:19:37,760 --> 00:19:40,880
and this is because you know in the

540
00:19:40,880 --> 00:19:42,880
the past few years we've seen attacks

541
00:19:42,880 --> 00:19:44,640
that were thought to require physical

542
00:19:44,640 --> 00:19:48,240
access to the device for example

543
00:19:48,240 --> 00:19:49,840
fault injection and side channel

544
00:19:49,840 --> 00:19:51,520
analysis these attacks are being

545
00:19:51,520 --> 00:19:52,080
performed

546
00:19:52,080 --> 00:19:54,880
from software which has imp implications

547
00:19:54,880 --> 00:19:55,520
if

548
00:19:55,520 --> 00:19:58,000
for example you are deploying something

549
00:19:58,000 --> 00:19:59,120
in the public cloud

550
00:19:59,120 --> 00:20:01,440
where there can be other tenants that

551
00:20:01,440 --> 00:20:03,120
share the hardware at the same time

552
00:20:03,120 --> 00:20:06,400
that your software is running so with

553
00:20:06,400 --> 00:20:06,960
that

554
00:20:06,960 --> 00:20:08,799
you know i'll leave you with the the

555
00:20:08,799 --> 00:20:10,159
parting message that

556
00:20:10,159 --> 00:20:11,520
you know hardware is truly a

557
00:20:11,520 --> 00:20:13,200
double-edged sword and we

558
00:20:13,200 --> 00:20:15,840
all wield it together and i would be

559
00:20:15,840 --> 00:20:21,840
happy to take questions now

560
00:20:27,600 --> 00:20:29,678
you

