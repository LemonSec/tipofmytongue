1
00:00:00,500 --> 00:00:04,740
awesome so I'm David and thanks you guys

2
00:00:04,740 --> 00:00:06,509
for being here this afternoon it's a

3
00:00:06,509 --> 00:00:08,400
pleasure to be here we'll be talking

4
00:00:08,400 --> 00:00:12,500
about beyond the lexical and passive DNS

5
00:00:12,830 --> 00:00:16,770
so um DMA zoom head of security research

6
00:00:16,770 --> 00:00:19,590
the Cisco umbrella and I'm a security

7
00:00:19,590 --> 00:00:21,359
researcher and data scientist on the

8
00:00:21,359 --> 00:00:23,279
team and with our team we basically

9
00:00:23,279 --> 00:00:25,500
analyze massive amounts of data and try

10
00:00:25,500 --> 00:00:27,779
to find like some relevant patterns for

11
00:00:27,779 --> 00:00:32,219
a threat detection so at Cisco umbrella

12
00:00:32,219 --> 00:00:33,630
we deal with massive amounts of data

13
00:00:33,630 --> 00:00:35,760
like I said and mainly its client

14
00:00:35,760 --> 00:00:38,370
domains interactions and our mission is

15
00:00:38,370 --> 00:00:41,670
to basically protect these users against

16
00:00:41,670 --> 00:00:44,059
threats online now currently

17
00:00:44,059 --> 00:00:45,960
traditionally the industry deals with

18
00:00:45,960 --> 00:00:47,460
this problem by convicting domains and

19
00:00:47,460 --> 00:00:49,739
blocking them but in the stock we

20
00:00:49,739 --> 00:00:52,050
proposed to have a new read definition

21
00:00:52,050 --> 00:00:53,730
of the problem by looking at both the

22
00:00:53,730 --> 00:00:55,920
user domains interactions but also the

23
00:00:55,920 --> 00:00:59,160
domain user interactions and furthermore

24
00:00:59,160 --> 00:01:01,230
when you look deeper into this way of

25
00:01:01,230 --> 00:01:03,180
modeling the problem you realize it's

26
00:01:03,180 --> 00:01:05,069
evolving over time so it's like a this

27
00:01:05,069 --> 00:01:07,100
massive worldwide beast that is

28
00:01:07,100 --> 00:01:09,930
breathing and living and we can monitor

29
00:01:09,930 --> 00:01:14,369
it over time basically so if you were to

30
00:01:14,369 --> 00:01:15,780
look at one single machine on the

31
00:01:15,780 --> 00:01:17,670
internet and the domains that it queries

32
00:01:17,670 --> 00:01:19,350
it's going to essentially evolve over

33
00:01:19,350 --> 00:01:21,840
time so the rate at which its interested

34
00:01:21,840 --> 00:01:23,310
in a domain is going to change and

35
00:01:23,310 --> 00:01:24,990
that's sort of like one of the insights

36
00:01:24,990 --> 00:01:26,369
and the clues that we're going to try to

37
00:01:26,369 --> 00:01:28,950
model and begin to build out in this

38
00:01:28,950 --> 00:01:30,689
talk or at least kind of immerse you a

39
00:01:30,689 --> 00:01:31,829
little bit more in our world in the way

40
00:01:31,829 --> 00:01:36,110
that we think about these problems and

41
00:01:36,110 --> 00:01:39,630
so we're gonna go deep into some of

42
00:01:39,630 --> 00:01:41,700
these so at least you get an idea of the

43
00:01:41,700 --> 00:01:44,759
power that we can take these features to

44
00:01:44,759 --> 00:01:47,250
describing our traffic but at a high

45
00:01:47,250 --> 00:01:49,020
level what we're gonna be doing is be

46
00:01:49,020 --> 00:01:51,030
taking some topological properties of a

47
00:01:51,030 --> 00:01:53,220
bipartite graphs and then translate them

48
00:01:53,220 --> 00:01:55,380
into a network security perspective or

49
00:01:55,380 --> 00:01:57,149
at least give us some ways of hopefully

50
00:01:57,149 --> 00:01:59,060
detecting some threats that are online

51
00:01:59,060 --> 00:02:01,350
so basically we represent the user

52
00:02:01,350 --> 00:02:03,240
domain interactions as a bipartite graph

53
00:02:03,240 --> 00:02:05,520
and when we look into the properties of

54
00:02:05,520 --> 00:02:07,890
those nodes we realize they're also

55
00:02:07,890 --> 00:02:09,840
evolving over time so if you take the

56
00:02:09,840 --> 00:02:11,849
degrees of the nodes and you take like

57
00:02:11,849 --> 00:02:13,800
snapshots every hour every minute

58
00:02:13,800 --> 00:02:15,330
you realize you could build time series

59
00:02:15,330 --> 00:02:18,330
on graphs now you might ask why is this

60
00:02:18,330 --> 00:02:20,550
relevant to our security community I

61
00:02:20,550 --> 00:02:22,410
would say landscape the idea is that

62
00:02:22,410 --> 00:02:23,880
this could be a solution to a textbook

63
00:02:23,880 --> 00:02:26,250
problem which is botany detection or DGA

64
00:02:26,250 --> 00:02:29,700
detection and traditionally we've been

65
00:02:29,700 --> 00:02:30,840
dealing with this problem for the past

66
00:02:30,840 --> 00:02:32,850
decade by using classical analysis of

67
00:02:32,850 --> 00:02:35,580
domain names by analyzing non resolving

68
00:02:35,580 --> 00:02:38,070
domains and represented them as graphs

69
00:02:38,070 --> 00:02:40,110
in fact and finally like some really

70
00:02:40,110 --> 00:02:42,360
this is like an established I would say

71
00:02:42,360 --> 00:02:44,070
expertise to do the reverse engineering

72
00:02:44,070 --> 00:02:46,410
of the samples and try and like to come

73
00:02:46,410 --> 00:02:47,790
up with the routine that generates the

74
00:02:47,790 --> 00:02:52,350
domains now that's also induced of to

75
00:02:52,350 --> 00:02:54,690
the sandbox analysis and in fact when

76
00:02:54,690 --> 00:02:56,970
you analyze the malware in a sandbox and

77
00:02:56,970 --> 00:02:58,320
you look at the traffic you'll realize

78
00:02:58,320 --> 00:03:00,450
you're looking at evolution over time of

79
00:03:00,450 --> 00:03:02,010
interactions between clients and domains

80
00:03:02,010 --> 00:03:04,560
in fact this is the somewhat the analogy

81
00:03:04,560 --> 00:03:06,510
we're using but then were exploited to

82
00:03:06,510 --> 00:03:12,390
millions of entities worldwide so an

83
00:03:12,390 --> 00:03:13,860
outline of this talk is that we're going

84
00:03:13,860 --> 00:03:15,030
to try to break it down into three parts

85
00:03:15,030 --> 00:03:16,800
so hopefully will give you some

86
00:03:16,800 --> 00:03:18,060
intuition and the graphs that we're

87
00:03:18,060 --> 00:03:19,140
dealing with and the properties that

88
00:03:19,140 --> 00:03:21,630
we're going to take and build out into

89
00:03:21,630 --> 00:03:23,280
signals and then we're going to try to

90
00:03:23,280 --> 00:03:26,370
enable or think inform you a little bit

91
00:03:26,370 --> 00:03:27,420
about the technology that we're using

92
00:03:27,420 --> 00:03:28,950
that so that we can do this at scale and

93
00:03:28,950 --> 00:03:30,810
at the speed that is required for us and

94
00:03:30,810 --> 00:03:32,670
then to look at specifically these

95
00:03:32,670 --> 00:03:34,140
graphs and some of the threats that

96
00:03:34,140 --> 00:03:36,540
we're going to try to detect so in that

97
00:03:36,540 --> 00:03:38,040
case where we're gonna be looking at is

98
00:03:38,040 --> 00:03:39,390
sub graphs and we're gonna try to like

99
00:03:39,390 --> 00:03:41,130
get into these sub graphs or these

100
00:03:41,130 --> 00:03:43,230
niches and look for very specific things

101
00:03:43,230 --> 00:03:45,180
because for example we need to have

102
00:03:45,180 --> 00:03:46,890
really low false positive rates and we

103
00:03:46,890 --> 00:03:48,420
do actually convict domains we

104
00:03:48,420 --> 00:03:50,010
essentially block the activity for our

105
00:03:50,010 --> 00:03:51,560
clients reaching out to those domains

106
00:03:51,560 --> 00:03:53,459
hopefully at the end we'll have some

107
00:03:53,459 --> 00:03:57,330
time for a demo and q and A's so stats

108
00:03:57,330 --> 00:03:59,340
are usually interesting and numbers are

109
00:03:59,340 --> 00:04:00,780
compelling so let's start with some

110
00:04:00,780 --> 00:04:03,900
numbers in fact so this is a an overview

111
00:04:03,900 --> 00:04:05,970
of two weeks worth of traffic we took a

112
00:04:05,970 --> 00:04:08,940
sample of 500,000 users taken from two

113
00:04:08,940 --> 00:04:10,560
resolvers one from north america and one

114
00:04:10,560 --> 00:04:12,900
from europe and then we sliced and diced

115
00:04:12,900 --> 00:04:15,510
the traffic with different methods and

116
00:04:15,510 --> 00:04:17,880
then the first insight is that there

117
00:04:17,880 --> 00:04:20,668
were 3,800 users that visited more than

118
00:04:20,668 --> 00:04:22,979
a hundred domains daily these are doma

119
00:04:22,979 --> 00:04:25,890
clients talking to a lot of things every

120
00:04:25,890 --> 00:04:27,600
hour and then if we

121
00:04:27,600 --> 00:04:29,340
tighten the noose further you'll realize

122
00:04:29,340 --> 00:04:31,890
there are 1500 users that are repeating

123
00:04:31,890 --> 00:04:33,750
themselves ten percent of the time and

124
00:04:33,750 --> 00:04:35,790
if you take that even stricter you'll

125
00:04:35,790 --> 00:04:38,640
find that you have 300 users over two

126
00:04:38,640 --> 00:04:40,020
weeks period that were repeating

127
00:04:40,020 --> 00:04:41,700
themselves 50 percent of the time

128
00:04:41,700 --> 00:04:43,410
so these clients are basically talking

129
00:04:43,410 --> 00:04:45,480
to the same stuff 50 percent of the time

130
00:04:45,480 --> 00:04:47,760
over two weeks period that's intriguing

131
00:04:47,760 --> 00:04:50,250
and the question is are these infected

132
00:04:50,250 --> 00:04:54,210
clients and now as you kind of look at

133
00:04:54,210 --> 00:04:55,980
the same period this two-week interval

134
00:04:55,980 --> 00:04:57,180
and you flip it around and you look at

135
00:04:57,180 --> 00:04:58,470
the domains that they're interacting

136
00:04:58,470 --> 00:05:00,120
with or just the random domains that

137
00:05:00,120 --> 00:05:02,070
were in that period over this two-week

138
00:05:02,070 --> 00:05:04,470
trended time then there's about 2.4

139
00:05:04,470 --> 00:05:06,120
million domains that we'd be looking at

140
00:05:06,120 --> 00:05:08,340
and what's interesting is that about

141
00:05:08,340 --> 00:05:10,620
6500 of those domains would have more

142
00:05:10,620 --> 00:05:13,020
than at least a hundred clients trended

143
00:05:13,020 --> 00:05:16,260
for two weeks going to them so that's

144
00:05:16,260 --> 00:05:18,650
every day for about a two week period

145
00:05:18,650 --> 00:05:21,660
consistently now as you look at those

146
00:05:21,660 --> 00:05:23,760
those those domains and you try to like

147
00:05:23,760 --> 00:05:25,380
ask a little bit more about them and you

148
00:05:25,380 --> 00:05:27,840
make a further qualification you say

149
00:05:27,840 --> 00:05:29,940
well how many of those domains had at

150
00:05:29,940 --> 00:05:31,950
least 10% of the clients repeating from

151
00:05:31,950 --> 00:05:36,060
one day just about or they trended and

152
00:05:36,060 --> 00:05:37,350
repeat another about 10 percent of the

153
00:05:37,350 --> 00:05:39,270
time from one day to the next over this

154
00:05:39,270 --> 00:05:40,830
two-week period then you would have

155
00:05:40,830 --> 00:05:43,290
found about 5,300 domains now if you

156
00:05:43,290 --> 00:05:44,850
were to kind of tighten this noose over

157
00:05:44,850 --> 00:05:46,860
the amount of repeating people to these

158
00:05:46,860 --> 00:05:48,840
domains over a two-week period on

159
00:05:48,840 --> 00:05:51,600
average to 50 percent you've be left

160
00:05:51,600 --> 00:05:54,030
with about 53 domains now the question

161
00:05:54,030 --> 00:05:57,540
is with these domains are they malicious

162
00:05:57,540 --> 00:06:00,600
meaning in your network you have these

163
00:06:00,600 --> 00:06:02,730
domains that have very obvious traffic

164
00:06:02,730 --> 00:06:04,470
going to them with a very specific

165
00:06:04,470 --> 00:06:06,600
client interactions and the question is

166
00:06:06,600 --> 00:06:08,220
if this was happening in your network

167
00:06:08,220 --> 00:06:09,870
would you have known and would you have

168
00:06:09,870 --> 00:06:11,460
been able to stop it if this was an

169
00:06:11,460 --> 00:06:14,790
attack so that brings us back to the

170
00:06:14,790 --> 00:06:16,860
definition of the graphs and how we

171
00:06:16,860 --> 00:06:20,670
analyze these signals over time so in

172
00:06:20,670 --> 00:06:22,920
fact the concept we use is quite known

173
00:06:22,920 --> 00:06:25,050
in graph theory but it's quite powerful

174
00:06:25,050 --> 00:06:27,210
so we represent that three-part tied

175
00:06:27,210 --> 00:06:29,100
graph so you'll have the three different

176
00:06:29,100 --> 00:06:31,800
sets of entities that are interacting in

177
00:06:31,800 --> 00:06:33,360
our traffic you have the clients talking

178
00:06:33,360 --> 00:06:35,310
to domains and then domains hosted on

179
00:06:35,310 --> 00:06:37,650
hosting IPs and then the relationship

180
00:06:37,650 --> 00:06:40,510
actually goes in both directions

181
00:06:40,510 --> 00:06:43,150
and with that now we can define some

182
00:06:43,150 --> 00:06:44,800
compelling features on each one of those

183
00:06:44,800 --> 00:06:46,870
nodes when they interact with the other

184
00:06:46,870 --> 00:06:48,790
nodes in the graph so you're looking at

185
00:06:48,790 --> 00:06:52,000
the degrees basically and these are like

186
00:06:52,000 --> 00:06:54,910
basically the foundational blocks or the

187
00:06:54,910 --> 00:06:57,010
building blocks for our analysis so

188
00:06:57,010 --> 00:06:59,020
we'll start with the first one so from

189
00:06:59,020 --> 00:07:01,510
the client point of view we can define

190
00:07:01,510 --> 00:07:04,030
the degree of the client as the number

191
00:07:04,030 --> 00:07:06,160
of unique domains it has been talking to

192
00:07:06,160 --> 00:07:07,840
over a period of time that's what we

193
00:07:07,840 --> 00:07:10,840
call the chattiness and again if you

194
00:07:10,840 --> 00:07:12,250
just flip that around you now look at

195
00:07:12,250 --> 00:07:13,630
that from the domain perspective and

196
00:07:13,630 --> 00:07:15,610
it's degree then you're just asking how

197
00:07:15,610 --> 00:07:17,500
many clients are interested in it and we

198
00:07:17,500 --> 00:07:19,450
call that just the popularity of a

199
00:07:19,450 --> 00:07:22,870
domain now if we take these two and we

200
00:07:22,870 --> 00:07:24,640
expand them with some more elaborate

201
00:07:24,640 --> 00:07:26,530
features we can define what we call the

202
00:07:26,530 --> 00:07:28,120
Jaccard similarity so this will goes

203
00:07:28,120 --> 00:07:30,730
from both the client side chattiness and

204
00:07:30,730 --> 00:07:32,830
popularity of the domain so as an

205
00:07:32,830 --> 00:07:34,510
example the Jaccard similarity of a

206
00:07:34,510 --> 00:07:37,480
chattiness of a client would be how much

207
00:07:37,480 --> 00:07:39,580
does the client repeat himself in going

208
00:07:39,580 --> 00:07:41,140
to the same domains from one hour to the

209
00:07:41,140 --> 00:07:42,760
next similarly for a domain it's gonna

210
00:07:42,760 --> 00:07:44,950
be how many clients come back to this

211
00:07:44,950 --> 00:07:47,580
domain from one hour to the to the next

212
00:07:47,580 --> 00:07:50,350
and the one thing I to add there is look

213
00:07:50,350 --> 00:07:52,090
that like the simplicity of this you

214
00:07:52,090 --> 00:07:53,800
start with a starting node and all

215
00:07:53,800 --> 00:07:55,030
you're asking is how many of the

216
00:07:55,030 --> 00:07:57,850
neighbors repeat in the subsequent hour

217
00:07:57,850 --> 00:07:59,980
and then further we now have another

218
00:07:59,980 --> 00:08:01,450
metric that we introduced called the

219
00:08:01,450 --> 00:08:03,550
spread now what that's asking in a very

220
00:08:03,550 --> 00:08:05,500
simple way saying when a client is may

221
00:08:05,500 --> 00:08:07,060
be reaching out to domains or all the

222
00:08:07,060 --> 00:08:08,860
domains basically the same and what we

223
00:08:08,860 --> 00:08:10,840
mean based in like graph theory is we

224
00:08:10,840 --> 00:08:12,820
just mean maybe do all the node degrees

225
00:08:12,820 --> 00:08:15,730
of those neighbors basically the same so

226
00:08:15,730 --> 00:08:18,550
for example here you have to if you have

227
00:08:18,550 --> 00:08:20,050
a client reaching out to a domain where

228
00:08:20,050 --> 00:08:22,870
there's a degree to g22 the two domains

229
00:08:22,870 --> 00:08:25,930
now the spread would vary if one of

230
00:08:25,930 --> 00:08:27,010
those did me and so it's very popular

231
00:08:27,010 --> 00:08:29,470
maybe this client went to a Google or a

232
00:08:29,470 --> 00:08:32,710
Facebook type like popular domain and

233
00:08:32,710 --> 00:08:34,030
then also went to a really like

234
00:08:34,030 --> 00:08:35,950
unpopular domain one that basically no

235
00:08:35,950 --> 00:08:37,270
one else on the internet except for

236
00:08:37,270 --> 00:08:39,159
someone in the know would actually be

237
00:08:39,159 --> 00:08:41,770
going to so the spread is basically the

238
00:08:41,770 --> 00:08:44,650
ratio between the median and average so

239
00:08:44,650 --> 00:08:47,050
based on these four building blocks now

240
00:08:47,050 --> 00:08:48,730
we can practically build a basic rule

241
00:08:48,730 --> 00:08:50,440
and then it will help us classify

242
00:08:50,440 --> 00:08:53,320
Internet traffic literally

243
00:08:53,320 --> 00:08:55,180
so this is a table where we basically

244
00:08:55,180 --> 00:08:58,029
broke down the internet or at least the

245
00:08:58,029 --> 00:09:00,220
internet that we analyze and see into

246
00:09:00,220 --> 00:09:01,899
these different blocks so we can see the

247
00:09:01,899 --> 00:09:05,470
the four the four features and then we

248
00:09:05,470 --> 00:09:07,630
have low and high and we'll go over a

249
00:09:07,630 --> 00:09:09,670
few of them because the the table can be

250
00:09:09,670 --> 00:09:12,190
quite long to describe so we'll start

251
00:09:12,190 --> 00:09:14,380
with low chattiness here so chattiness

252
00:09:14,380 --> 00:09:16,029
again is just clients the amount of

253
00:09:16,029 --> 00:09:17,470
things that it looks at and now if you

254
00:09:17,470 --> 00:09:19,779
watch this over time you can just ask

255
00:09:19,779 --> 00:09:22,540
for how many of those machines in your

256
00:09:22,540 --> 00:09:23,740
network that are going to a lot of

257
00:09:23,740 --> 00:09:26,199
different domains or a very few amount

258
00:09:26,199 --> 00:09:27,910
of domains over time so you might call

259
00:09:27,910 --> 00:09:29,440
these the high and the low types of

260
00:09:29,440 --> 00:09:31,240
chattiness and so if you were to look at

261
00:09:31,240 --> 00:09:33,759
machines that have low chattiness then

262
00:09:33,759 --> 00:09:35,440
you'd ask what type of machines are

263
00:09:35,440 --> 00:09:37,509
those well you might be able to kind of

264
00:09:37,509 --> 00:09:39,430
step back and think about it and from

265
00:09:39,430 --> 00:09:41,259
our perspective what we've seen is that

266
00:09:41,259 --> 00:09:43,360
some of some of the times will find IOT

267
00:09:43,360 --> 00:09:45,519
devices these are networked little

268
00:09:45,519 --> 00:09:47,740
devices that when they're online they're

269
00:09:47,740 --> 00:09:49,360
doing only very specific things there

270
00:09:49,360 --> 00:09:51,339
may be looking at servers for updates or

271
00:09:51,339 --> 00:09:53,980
maybe just doing update or downloads

272
00:09:53,980 --> 00:09:56,380
from specific servers or for example you

273
00:09:56,380 --> 00:09:59,139
may be heavier b2b machines where maybe

274
00:09:59,139 --> 00:10:00,940
they're just doing API calls to very

275
00:10:00,940 --> 00:10:03,430
specific services may be reaching out to

276
00:10:03,430 --> 00:10:05,350
very specific databases and so they

277
00:10:05,350 --> 00:10:07,120
don't have a wide spectrum of things

278
00:10:07,120 --> 00:10:08,860
that they're looking at so low

279
00:10:08,860 --> 00:10:10,540
chattiness means you have a small I

280
00:10:10,540 --> 00:10:12,880
would say circle of friends now if you

281
00:10:12,880 --> 00:10:14,620
take the high chattiness that will mean

282
00:10:14,620 --> 00:10:16,750
you are looking at the client talking to

283
00:10:16,750 --> 00:10:19,420
a lot of things that diverse I think so

284
00:10:19,420 --> 00:10:21,370
mail servers could be an example because

285
00:10:21,370 --> 00:10:22,750
you know when you receive a lot of

286
00:10:22,750 --> 00:10:24,940
emails you'll be freaking out and check

287
00:10:24,940 --> 00:10:27,760
in the from the to the the embedded URLs

288
00:10:27,760 --> 00:10:29,500
and you'll be asking all kinds of black

289
00:10:29,500 --> 00:10:31,600
lists online to check if the domain is

290
00:10:31,600 --> 00:10:33,010
malicious or not so that generates like

291
00:10:33,010 --> 00:10:34,930
a like a massive amount of diverse

292
00:10:34,930 --> 00:10:37,120
queries in terms of unique domains

293
00:10:37,120 --> 00:10:39,010
similarly if you're talking about some

294
00:10:39,010 --> 00:10:42,370
public eye pieces of large ISPs using us

295
00:10:42,370 --> 00:10:44,980
then they will have a wide variety of

296
00:10:44,980 --> 00:10:46,930
customers behind them and yet they will

297
00:10:46,930 --> 00:10:49,660
be querying a wide variety of I would

298
00:10:49,660 --> 00:10:52,750
say domains so now if we go deeper in

299
00:10:52,750 --> 00:10:54,819
the table let's focus maybe on the

300
00:10:54,819 --> 00:10:57,310
Jaccard similarity for clients and the

301
00:10:57,310 --> 00:10:58,449
first one is when you have low

302
00:10:58,449 --> 00:11:00,880
chattiness what that means the intuition

303
00:11:00,880 --> 00:11:03,220
is that you have in a client who's a

304
00:11:03,220 --> 00:11:05,680
customers behind are not repeating

305
00:11:05,680 --> 00:11:06,910
themselves very much

306
00:11:06,910 --> 00:11:08,200
and the intuition could be that these

307
00:11:08,200 --> 00:11:10,210
could be a VPN or proxy exit notes

308
00:11:10,210 --> 00:11:11,830
because they have a lot of churn and the

309
00:11:11,830 --> 00:11:13,720
customers using them they will very

310
00:11:13,720 --> 00:11:16,210
rarely repeat themselves in DNS queries

311
00:11:16,210 --> 00:11:18,580
and those machines that maybe repeat

312
00:11:18,580 --> 00:11:20,470
themselves a lot are potentially you're

313
00:11:20,470 --> 00:11:22,420
infected clients right so for example

314
00:11:22,420 --> 00:11:24,130
maybe there are coaches going through a

315
00:11:24,130 --> 00:11:25,600
series of domains that they're

316
00:11:25,600 --> 00:11:27,040
pre-programmed to be looking through

317
00:11:27,040 --> 00:11:29,620
potentially especially if they're denied

318
00:11:29,620 --> 00:11:31,630
service and they try to repeatedly look

319
00:11:31,630 --> 00:11:33,970
up something or you might have something

320
00:11:33,970 --> 00:11:35,800
that's repeating or another machine that

321
00:11:35,800 --> 00:11:37,690
has very similar behavior to that that

322
00:11:37,690 --> 00:11:39,490
is not infected and in fact it's benign

323
00:11:39,490 --> 00:11:41,620
for example maybe in an unintuitive

324
00:11:41,620 --> 00:11:43,900
twist is that you have mail servers

325
00:11:43,900 --> 00:11:45,940
actually a lot of mail servers tend to

326
00:11:45,940 --> 00:11:49,030
call internal machines but then actually

327
00:11:49,030 --> 00:11:52,090
face outwardly in public DNS queries

328
00:11:52,090 --> 00:11:54,190
looking at PTR records to those machines

329
00:11:54,190 --> 00:11:56,800
and so it actually surfaces as though

330
00:11:56,800 --> 00:11:58,300
these machines are actually fairly

331
00:11:58,300 --> 00:11:59,710
repetitive you'd think that they

332
00:11:59,710 --> 00:12:02,020
basically could be predicted what their

333
00:12:02,020 --> 00:12:03,730
behavior is but every once in a while

334
00:12:03,730 --> 00:12:05,260
they're actually interleaving also the

335
00:12:05,260 --> 00:12:10,240
spam and the email list lookups so let's

336
00:12:10,240 --> 00:12:11,680
talk about the architecture now because

337
00:12:11,680 --> 00:12:14,790
we're dealing with large-scale data and

338
00:12:14,790 --> 00:12:19,030
implementation so in this slide is just

339
00:12:19,030 --> 00:12:21,070
the kind of high-level view about what

340
00:12:21,070 --> 00:12:23,110
kind of size a magnitude of data that

341
00:12:23,110 --> 00:12:24,940
we're looking at in this case our DNS

342
00:12:24,940 --> 00:12:27,550
broad ENS logs and what this is

343
00:12:27,550 --> 00:12:28,930
basically just going to try to highlight

344
00:12:28,930 --> 00:12:32,500
is essentially that we kind of built out

345
00:12:32,500 --> 00:12:34,390
like a custom version or our own

346
00:12:34,390 --> 00:12:36,670
implementation that enables us to both

347
00:12:36,670 --> 00:12:38,380
represent this graph that we want to

348
00:12:38,380 --> 00:12:40,900
construct at the same time leverage the

349
00:12:40,900 --> 00:12:42,190
properties that we want to pre-compute

350
00:12:42,190 --> 00:12:44,740
and then actually store them for for

351
00:12:44,740 --> 00:12:46,270
being able to retrieve these signals

352
00:12:46,270 --> 00:12:48,760
over time and so one of those key

353
00:12:48,760 --> 00:12:50,740
components is actually using HBase which

354
00:12:50,740 --> 00:12:52,300
allows us to kind of do this in a

355
00:12:52,300 --> 00:12:54,220
flexible manner you want to say

356
00:12:54,220 --> 00:12:56,620
something about SPARC oh yeah and I

357
00:12:56,620 --> 00:12:59,080
think one of the big things in moving

358
00:12:59,080 --> 00:13:02,680
down like your own like forging forward

359
00:13:02,680 --> 00:13:04,270
on your own path in something like this

360
00:13:04,270 --> 00:13:05,890
where you're kind of this the way that

361
00:13:05,890 --> 00:13:07,330
we both us out was in a series of

362
00:13:07,330 --> 00:13:09,730
workflows in oszi which I had to like

363
00:13:09,730 --> 00:13:11,440
have these pig jobs and MapReduce jobs

364
00:13:11,440 --> 00:13:13,300
which broke down this big problem into

365
00:13:13,300 --> 00:13:15,310
blots of subproblems so essentially we

366
00:13:15,310 --> 00:13:17,470
constructed a tree of each of the little

367
00:13:17,470 --> 00:13:19,810
parts of this job like the breaking down

368
00:13:19,810 --> 00:13:20,620
of our DNS

369
00:13:20,620 --> 00:13:22,630
to pre aggregate various properties on

370
00:13:22,630 --> 00:13:25,630
this graph and of course the it's not

371
00:13:25,630 --> 00:13:27,130
fun doing this all on your own sometimes

372
00:13:27,130 --> 00:13:28,900
and we would have loved to use something

373
00:13:28,900 --> 00:13:30,940
like spark but the challenge is the time

374
00:13:30,940 --> 00:13:32,470
dependence of these graphs we have

375
00:13:32,470 --> 00:13:36,430
rotating numbers of I domains or client

376
00:13:36,430 --> 00:13:38,290
machines which I centrally made it

377
00:13:38,290 --> 00:13:40,060
really hard to index that stuff slave it

378
00:13:40,060 --> 00:13:44,710
with spark or graphics and this is just

379
00:13:44,710 --> 00:13:47,050
trying to notate like how we used HBase

380
00:13:47,050 --> 00:13:48,760
in the reason why we used it it is

381
00:13:48,760 --> 00:13:50,770
because of clever roki designs it

382
00:13:50,770 --> 00:13:53,050
enables us to both scale the problem of

383
00:13:53,050 --> 00:13:55,420
looking at large volumes of domains for

384
00:13:55,420 --> 00:13:57,490
their signals while also doing very

385
00:13:57,490 --> 00:13:59,620
specific strategic lookups for just

386
00:13:59,620 --> 00:14:03,850
maybe one or two domains so now let's

387
00:14:03,850 --> 00:14:05,230
get into the domain

388
00:14:05,230 --> 00:14:07,090
sorry the mode models we've built on top

389
00:14:07,090 --> 00:14:09,700
of these large data sets so the first

390
00:14:09,700 --> 00:14:11,320
one is basically a subgraph mining

391
00:14:11,320 --> 00:14:13,450
approach that will deal with clients

392
00:14:13,450 --> 00:14:16,330
pivoting two domains and this is like a

393
00:14:16,330 --> 00:14:18,400
high level of the small so what we are

394
00:14:18,400 --> 00:14:20,380
doing is we we are dealing with a client

395
00:14:20,380 --> 00:14:23,710
domain sessions and then we isolate the

396
00:14:23,710 --> 00:14:25,510
clients of interest and then further we

397
00:14:25,510 --> 00:14:27,760
want to extract the domains these

398
00:14:27,760 --> 00:14:29,530
clients have been talking to but then we

399
00:14:29,530 --> 00:14:31,150
don't want to block or convict domains

400
00:14:31,150 --> 00:14:32,920
that are false positives meaning benign

401
00:14:32,920 --> 00:14:35,080
so for that we'll use like some of those

402
00:14:35,080 --> 00:14:37,120
properties we defined earlier the pop

403
00:14:37,120 --> 00:14:40,000
the jacquard and the spread in fact when

404
00:14:40,000 --> 00:14:42,280
we isolate the first stage of clients

405
00:14:42,280 --> 00:14:45,070
those are also using the properties of

406
00:14:45,070 --> 00:14:46,540
earlier of the chattiness the jacquard

407
00:14:46,540 --> 00:14:48,610
and spread more specifically what we're

408
00:14:48,610 --> 00:14:50,500
doing is we're looking at clients that

409
00:14:50,500 --> 00:14:52,690
have a chattiness of more than 100

410
00:14:52,690 --> 00:14:54,280
meaning they're talking to more than 100

411
00:14:54,280 --> 00:14:57,130
unique domains every time slop so

412
00:14:57,130 --> 00:15:00,340
they're quite chatty and promiscuous the

413
00:15:00,340 --> 00:15:02,230
other one is the card similarity so we

414
00:15:02,230 --> 00:15:03,940
want to see those clients that are

415
00:15:03,940 --> 00:15:06,070
repeating themselves 80% or more of the

416
00:15:06,070 --> 00:15:08,440
time so they have like a purpose here

417
00:15:08,440 --> 00:15:10,480
and finally the spread has to be low

418
00:15:10,480 --> 00:15:13,210
meaning less than 10% meaning they are

419
00:15:13,210 --> 00:15:15,610
repeating themselves two domains that

420
00:15:15,610 --> 00:15:19,300
have a very tight spread of popularity

421
00:15:19,300 --> 00:15:22,090
so the domains are basically part of a

422
00:15:22,090 --> 00:15:23,800
VIP group and the clients are

423
00:15:23,800 --> 00:15:29,280
consistently going to them and yeah so

424
00:15:29,280 --> 00:15:31,900
given this criteria you might be like

425
00:15:31,900 --> 00:15:33,880
wondering why why this criteria but

426
00:15:33,880 --> 00:15:35,680
you're trying to do is create a function

427
00:15:35,680 --> 00:15:37,390
that essentially takes in a client it

428
00:15:37,390 --> 00:15:38,680
spits out a bunch of domains where

429
00:15:38,680 --> 00:15:40,060
basically the domains are the ones you

430
00:15:40,060 --> 00:15:41,560
want to block so basically you're trying

431
00:15:41,560 --> 00:15:43,300
to ensure something about these domains

432
00:15:43,300 --> 00:15:45,790
with those properties and that's what we

433
00:15:45,790 --> 00:15:48,400
basically try to do one and now there's

434
00:15:48,400 --> 00:15:49,660
this one last step where we have to

435
00:15:49,660 --> 00:15:53,290
filter through these fps so for example

436
00:15:53,290 --> 00:15:55,030
now that you have those that group that

437
00:15:55,030 --> 00:15:56,650
were that subset of domains you have

438
00:15:56,650 --> 00:15:58,270
those properties right you have the

439
00:15:58,270 --> 00:16:00,340
popularity of those that means how often

440
00:16:00,340 --> 00:16:02,410
clients are repeatedly going to them and

441
00:16:02,410 --> 00:16:04,240
on average maybe even the spread of

442
00:16:04,240 --> 00:16:05,620
those clients that are going to it and

443
00:16:05,620 --> 00:16:06,880
now you just ask yourself a simple

444
00:16:06,880 --> 00:16:08,740
question like what's the norm here and

445
00:16:08,740 --> 00:16:11,080
is anyone an outlier here and probably

446
00:16:11,080 --> 00:16:13,180
those are your FPS so just get rid of

447
00:16:13,180 --> 00:16:16,840
those one way of doing that just

448
00:16:16,840 --> 00:16:18,670
literally doing that you just take the

449
00:16:18,670 --> 00:16:20,230
average standard deviations of each of

450
00:16:20,230 --> 00:16:21,700
those metrics across that swath of

451
00:16:21,700 --> 00:16:23,170
domains that you're looking at you'll

452
00:16:23,170 --> 00:16:24,460
build out a polytope that looks like

453
00:16:24,460 --> 00:16:26,080
this and the domains that you're

454
00:16:26,080 --> 00:16:27,670
probably interested in aren't inside

455
00:16:27,670 --> 00:16:29,620
that polytope while the outliers are

456
00:16:29,620 --> 00:16:31,180
literally actually those domains that

457
00:16:31,180 --> 00:16:35,350
don't really make sense to block and if

458
00:16:35,350 --> 00:16:36,910
you look you want more details about

459
00:16:36,910 --> 00:16:38,260
this type of stuff maybe what it looks

460
00:16:38,260 --> 00:16:39,460
like from our perspective with our

461
00:16:39,460 --> 00:16:41,230
network traffic just look at our paper

462
00:16:41,230 --> 00:16:43,000
we have some more diagrams about some of

463
00:16:43,000 --> 00:16:44,470
the subsets of clients that kind of

464
00:16:44,470 --> 00:16:46,840
exhibit this type of behavior and then

465
00:16:46,840 --> 00:16:50,320
and then what do we actually get what's

466
00:16:50,320 --> 00:16:52,120
the actual output well here's your

467
00:16:52,120 --> 00:16:54,190
Conficker and there's your necker's and

468
00:16:54,190 --> 00:16:55,780
the interesting thing here is that these

469
00:16:55,780 --> 00:16:57,370
domains are now basically kind of

470
00:16:57,370 --> 00:16:59,320
grouped together based on the aggregates

471
00:16:59,320 --> 00:17:01,180
of these signals and that's what we want

472
00:17:01,180 --> 00:17:04,599
to ensure and I guess the takeaway here

473
00:17:04,599 --> 00:17:06,849
is that we detected algorithmically

474
00:17:06,849 --> 00:17:08,890
generated domain names without ever

475
00:17:08,890 --> 00:17:11,880
touching the lexical or annex domains

476
00:17:11,880 --> 00:17:14,170
now let's get into the second model

477
00:17:14,170 --> 00:17:15,939
we've built on top of these large graphs

478
00:17:15,939 --> 00:17:18,130
so here we're dealing with sub graph

479
00:17:18,130 --> 00:17:20,260
mining that deals with domain spiriting

480
00:17:20,260 --> 00:17:22,449
two domains so the intuition is quite

481
00:17:22,449 --> 00:17:24,189
simple we start with a seed of malicious

482
00:17:24,189 --> 00:17:25,810
domains and then we pivot through other

483
00:17:25,810 --> 00:17:28,150
malicious domains by going through the

484
00:17:28,150 --> 00:17:31,150
clients of interest in fact the high

485
00:17:31,150 --> 00:17:32,440
level would be something like this we

486
00:17:32,440 --> 00:17:34,210
start with a well-known field of deejays

487
00:17:34,210 --> 00:17:36,850
the Bembenek field and then we will join

488
00:17:36,850 --> 00:17:38,890
it with the client domain sessions and

489
00:17:38,890 --> 00:17:40,630
we end up with a set in the middle which

490
00:17:40,630 --> 00:17:43,060
is basically the clients talking to

491
00:17:43,060 --> 00:17:44,800
those domains from the Bembenek feed and

492
00:17:44,800 --> 00:17:46,660
then the next step is that we have two

493
00:17:46,660 --> 00:17:47,590
bucket the domain

494
00:17:47,590 --> 00:17:49,750
share the same properties that we

495
00:17:49,750 --> 00:17:54,190
described earlier so it's really simple

496
00:17:54,190 --> 00:17:55,779
you basically have a series of domains

497
00:17:55,779 --> 00:17:57,789
you have their signals and you basically

498
00:17:57,789 --> 00:17:59,320
want to perform a Google search you just

499
00:17:59,320 --> 00:18:01,600
say here's some bad thing

500
00:18:01,600 --> 00:18:03,100
go get me everything else that looks

501
00:18:03,100 --> 00:18:05,679
like it and so to be able to do that we

502
00:18:05,679 --> 00:18:07,510
just have to cache and somehow compress

503
00:18:07,510 --> 00:18:09,640
that signal so that it makes sense to at

504
00:18:09,640 --> 00:18:11,919
scale be able to query at this kind of

505
00:18:11,919 --> 00:18:15,250
speed or at this level and so the way

506
00:18:15,250 --> 00:18:16,659
that we do it is we use locality

507
00:18:16,659 --> 00:18:18,309
sensitive hashing over these time series

508
00:18:18,309 --> 00:18:19,779
which then essentially compresses those

509
00:18:19,779 --> 00:18:21,850
signals and then insurers with a high

510
00:18:21,850 --> 00:18:23,409
degree of probability that if two

511
00:18:23,409 --> 00:18:25,270
signals basically look the same look the

512
00:18:25,270 --> 00:18:26,830
same they're gonna get bucketed to the

513
00:18:26,830 --> 00:18:28,570
same place and so then you just have

514
00:18:28,570 --> 00:18:30,820
these buckets you just for any bucket

515
00:18:30,820 --> 00:18:32,559
that has a red marker maybe those are

516
00:18:32,559 --> 00:18:34,779
the militias you just say now anyone in

517
00:18:34,779 --> 00:18:36,970
there just block them maybe you'll get

518
00:18:36,970 --> 00:18:38,409
dupes but hopefully you're gonna get

519
00:18:38,409 --> 00:18:39,580
someone that you didn't have block

520
00:18:39,580 --> 00:18:41,529
before and keep in mind we're hashing

521
00:18:41,529 --> 00:18:43,840
and searching on the properties will

522
00:18:43,840 --> 00:18:46,899
define not the not on the traffic time

523
00:18:46,899 --> 00:18:50,890
series of volume and so in the end like

524
00:18:50,890 --> 00:18:52,450
if we can get through this presentation

525
00:18:52,450 --> 00:18:54,610
we'll give you a small taste of what it

526
00:18:54,610 --> 00:18:55,990
looks like so we'll have a little UI

527
00:18:55,990 --> 00:18:57,940
like this where we can actually perform

528
00:18:57,940 --> 00:18:59,980
this kind of search it's a very simple

529
00:18:59,980 --> 00:19:01,570
program it's a flask app that's and

530
00:19:01,570 --> 00:19:03,570
hitting our HBase tables in our network

531
00:19:03,570 --> 00:19:06,130
so this is a set of these domain

532
00:19:06,130 --> 00:19:07,720
starting with a seed one that we search

533
00:19:07,720 --> 00:19:09,970
for and those are the time series of the

534
00:19:09,970 --> 00:19:11,529
properties we'll define the four ones

535
00:19:11,529 --> 00:19:13,299
but then here if we look at the

536
00:19:13,299 --> 00:19:16,570
interface of our investigate product we

537
00:19:16,570 --> 00:19:18,340
can see that they also match on the

538
00:19:18,340 --> 00:19:21,580
domain volume pattern so over four days

539
00:19:21,580 --> 00:19:23,919
they have exactly the same behavior so

540
00:19:23,919 --> 00:19:25,539
you can see here to confirm the

541
00:19:25,539 --> 00:19:26,980
detection here based on two different

542
00:19:26,980 --> 00:19:31,990
signals over time and again in the paper

543
00:19:31,990 --> 00:19:33,669
we kind of go into like just a couple

544
00:19:33,669 --> 00:19:36,279
more subsets of domains or botnet type

545
00:19:36,279 --> 00:19:37,840
of traffic that we actually did catch

546
00:19:37,840 --> 00:19:40,419
with this type of stuff and you see

547
00:19:40,419 --> 00:19:42,549
again or like the takeaway to me and the

548
00:19:42,549 --> 00:19:44,350
most exciting thing about this is these

549
00:19:44,350 --> 00:19:46,899
signals the they're basically subsets

550
00:19:46,899 --> 00:19:48,399
like about 200 domains here that are

551
00:19:48,399 --> 00:19:50,230
represented about 200 there and what

552
00:19:50,230 --> 00:19:52,299
you're finding is that basically this is

553
00:19:52,299 --> 00:19:54,429
a family here and that's a family there

554
00:19:54,429 --> 00:19:57,220
and these waveforms tend to basically

555
00:19:57,220 --> 00:19:59,420
like carve out those families

556
00:19:59,420 --> 00:20:02,570
it's pretty nice property and again the

557
00:20:02,570 --> 00:20:04,910
takeaway seems to be that we can find

558
00:20:04,910 --> 00:20:06,590
algorithmically generated domain names

559
00:20:06,590 --> 00:20:09,370
but without ever touching the Wescott

560
00:20:09,370 --> 00:20:12,230
our final model I would say is the one

561
00:20:12,230 --> 00:20:14,360
where you pivot from domains malicious

562
00:20:14,360 --> 00:20:16,280
domains to the hosting IPs and back to

563
00:20:16,280 --> 00:20:17,680
domain so let's lock your typical

564
00:20:17,680 --> 00:20:20,720
passive DNS mining I would say but then

565
00:20:20,720 --> 00:20:23,060
we will show how it fits within the

566
00:20:23,060 --> 00:20:24,890
bigger framework that we define so

567
00:20:24,890 --> 00:20:27,440
simply put you start with domains you

568
00:20:27,440 --> 00:20:28,880
grab the hosting IPS and then you go

569
00:20:28,880 --> 00:20:30,890
back to other domains that might be

570
00:20:30,890 --> 00:20:32,720
malicious now the idea here is that we

571
00:20:32,720 --> 00:20:34,430
want to use those properties we defined

572
00:20:34,430 --> 00:20:36,830
earlier where let's say from a fast flux

573
00:20:36,830 --> 00:20:38,690
domains like the one I described in the

574
00:20:38,690 --> 00:20:41,480
talk of two days ago the Zbot fast flux

575
00:20:41,480 --> 00:20:42,830
domains so these are typically your

576
00:20:42,830 --> 00:20:45,230
malicious domains resolving to a few IPS

577
00:20:45,230 --> 00:20:46,970
that are part of a proxy network so

578
00:20:46,970 --> 00:20:48,170
they're all part of the same criminal

579
00:20:48,170 --> 00:20:50,240
infrastructure now if you grab the

580
00:20:50,240 --> 00:20:53,000
domain and all of the IPS and now you

581
00:20:53,000 --> 00:20:54,890
want to go back to some other eye some

582
00:20:54,890 --> 00:20:56,210
other domains you don't want to take

583
00:20:56,210 --> 00:20:58,130
everything on those IP do you wanna only

584
00:20:58,130 --> 00:21:00,380
take the domains but for example we're

585
00:21:00,380 --> 00:21:02,600
hosted on a specific range of hosting

586
00:21:02,600 --> 00:21:05,210
IPS as well as you only want to extract

587
00:21:05,210 --> 00:21:07,100
the IPS that we're hosting a specific

588
00:21:07,100 --> 00:21:09,320
range of domains like in numbers not

589
00:21:09,320 --> 00:21:11,660
like the the types of domains in a sense

590
00:21:11,660 --> 00:21:13,280
you're trying to tighten the noose

591
00:21:13,280 --> 00:21:15,170
around the chattiness of IPS in terms of

592
00:21:15,170 --> 00:21:17,510
hosting us and we would call it and also

593
00:21:17,510 --> 00:21:19,190
the popularity of domains in terms of

594
00:21:19,190 --> 00:21:22,040
how promiscuous they are in living on

595
00:21:22,040 --> 00:21:23,990
the IPS space and that ended up being

596
00:21:23,990 --> 00:21:29,300
very compelling to find the results well

597
00:21:29,300 --> 00:21:30,980
I would say by applying the other

598
00:21:30,980 --> 00:21:33,440
features we defined on this third I

599
00:21:33,440 --> 00:21:36,260
would say a method which is a little bit

600
00:21:36,260 --> 00:21:37,550
different from the client domain

601
00:21:37,550 --> 00:21:39,590
interaction we are still able to see

602
00:21:39,590 --> 00:21:41,180
some interesting patterns that you can

603
00:21:41,180 --> 00:21:44,300
kind of refer to in the paper similarly

604
00:21:44,300 --> 00:21:46,340
we can also see that these are DJ

605
00:21:46,340 --> 00:21:48,020
domains that were hosted on the Zbot

606
00:21:48,020 --> 00:21:49,850
fast flux proxy network but they also

607
00:21:49,850 --> 00:21:51,320
have like some interest interesting

608
00:21:51,320 --> 00:21:52,930
patterns from a client domain

609
00:21:52,930 --> 00:21:56,600
perspective so I guess in conclusion

610
00:21:56,600 --> 00:21:58,520
what we wanted to describe to you is

611
00:21:58,520 --> 00:22:01,250
this unifying framework where you model

612
00:22:01,250 --> 00:22:03,410
your traffic as a three part ID graph

613
00:22:03,410 --> 00:22:05,990
and you try to find and you try to

614
00:22:05,990 --> 00:22:08,120
basically the SEC the Internet in two

615
00:22:08,120 --> 00:22:10,340
classes and then eventually find threats

616
00:22:10,340 --> 00:22:12,860
we're not doing any lexical and

617
00:22:12,860 --> 00:22:16,070
no I would say annex domain analysis so

618
00:22:16,070 --> 00:22:17,299
the first model was basically around

619
00:22:17,299 --> 00:22:19,880
sitting with clients and then finding

620
00:22:19,880 --> 00:22:23,870
domains pivoting through those and then

621
00:22:23,870 --> 00:22:25,610
the second model was basically seated

622
00:22:25,610 --> 00:22:27,020
with domains that were malicious and

623
00:22:27,020 --> 00:22:28,490
then we found some other bad domains

624
00:22:28,490 --> 00:22:30,799
through the clients and finally the

625
00:22:30,799 --> 00:22:32,540
third one is basically kind of the

626
00:22:32,540 --> 00:22:35,330
passive DNS approach where you seed with

627
00:22:35,330 --> 00:22:36,799
domains and you find some other bad

628
00:22:36,799 --> 00:22:39,530
domains by strictly concentrating the

629
00:22:39,530 --> 00:22:41,390
behavior of the client of the hosting I

630
00:22:41,390 --> 00:22:49,480
piece a demo if you want yeah okay so

631
00:22:49,480 --> 00:22:52,220
sorry for the hunched over look and

632
00:22:52,220 --> 00:22:54,980
everything but hopefully you guys can

633
00:22:54,980 --> 00:22:58,600
see this so what I'm first going to do I

634
00:22:58,600 --> 00:23:00,530
kind of set things up because I just

635
00:23:00,530 --> 00:23:02,000
need to make sure things worked

636
00:23:02,000 --> 00:23:05,210
so hopefully the punchline isn't taken

637
00:23:05,210 --> 00:23:11,750
from us so if we go to investigate there

638
00:23:11,750 --> 00:23:14,720
we go okay so if we go to investigate

639
00:23:14,720 --> 00:23:16,730
that's one of our tools at Cisco

640
00:23:16,730 --> 00:23:19,100
umbrella we can kind of observe the

641
00:23:19,100 --> 00:23:20,720
query volume to this domain over the

642
00:23:20,720 --> 00:23:23,330
last 30 days and we see here that we've

643
00:23:23,330 --> 00:23:25,250
attributed this domain to necker's and

644
00:23:25,250 --> 00:23:26,870
it exhibits this type of pattern meaning

645
00:23:26,870 --> 00:23:29,210
like it it's kind of more or less been

646
00:23:29,210 --> 00:23:31,070
dormant and then recently in the last

647
00:23:31,070 --> 00:23:32,660
few days it's actually picked up in the

648
00:23:32,660 --> 00:23:34,790
amount of machines that are querying it

649
00:23:34,790 --> 00:23:39,049
is increased so if we were to put that

650
00:23:39,049 --> 00:23:43,820
domain into here then it kind of refresh

651
00:23:43,820 --> 00:23:46,220
there like a little it'll be a lot

652
00:23:46,220 --> 00:23:47,690
clearer with the next domain but I'll

653
00:23:47,690 --> 00:23:49,460
just finish with this what we have here

654
00:23:49,460 --> 00:23:52,460
is essentially a set of other domains

655
00:23:52,460 --> 00:23:55,460
that essentially have hopefully just by

656
00:23:55,460 --> 00:23:57,470
inspection not by mathematical

657
00:23:57,470 --> 00:23:59,240
techniques basically have essentially

658
00:23:59,240 --> 00:24:01,250
the same wave form as that initial don't

659
00:24:01,250 --> 00:24:02,750
mean that we actually plugged in there

660
00:24:02,750 --> 00:24:04,790
so the initial domain is the first one

661
00:24:04,790 --> 00:24:06,530
up there and that's the Associated

662
00:24:06,530 --> 00:24:08,600
waveform and then we found these other

663
00:24:08,600 --> 00:24:11,419
ones similarly by just hashing over

664
00:24:11,419 --> 00:24:13,370
those signals and looking for things in

665
00:24:13,370 --> 00:24:15,230
our sets that actually have those same

666
00:24:15,230 --> 00:24:17,570
signals so if I were to then just kind

667
00:24:17,570 --> 00:24:19,309
of copy-paste maybe one of these domains

668
00:24:19,309 --> 00:24:20,440
and then go

669
00:24:20,440 --> 00:24:24,970
look and investigate apparently this is

670
00:24:24,970 --> 00:24:27,430
also necker's - and has really this a

671
00:24:27,430 --> 00:24:29,830
similar query volume to it now these

672
00:24:29,830 --> 00:24:31,930
this query volume is again it's

673
00:24:31,930 --> 00:24:33,760
independent of these properties that

674
00:24:33,760 --> 00:24:35,320
we've been discussing query volume

675
00:24:35,320 --> 00:24:37,180
essentially says that every given

676
00:24:37,180 --> 00:24:39,070
customer that's querying a domain can

677
00:24:39,070 --> 00:24:41,020
have multiple votes all the properties

678
00:24:41,020 --> 00:24:42,550
that we've been describing that doesn't

679
00:24:42,550 --> 00:24:44,440
have that type of property sort or the

680
00:24:44,440 --> 00:24:46,030
properties of the graphs don't have this

681
00:24:46,030 --> 00:24:47,770
type of repetition like that or the in

682
00:24:47,770 --> 00:24:53,380
in its statistics so let's get another

683
00:24:53,380 --> 00:25:00,490
domain so here's another domain a

684
00:25:00,490 --> 00:25:02,560
different waveform and this one is

685
00:25:02,560 --> 00:25:04,750
attributed to picks ball and so

686
00:25:04,750 --> 00:25:06,430
apparently again this wing was dormant

687
00:25:06,430 --> 00:25:08,110
but then in recently in the last week or

688
00:25:08,110 --> 00:25:10,180
so it's picked up and the machines that

689
00:25:10,180 --> 00:25:13,330
are querying it has increased now if we

690
00:25:13,330 --> 00:25:15,880
go to here and we search for similar

691
00:25:15,880 --> 00:25:18,640
domains that have similar waveforms over

692
00:25:18,640 --> 00:25:19,900
those properties that we've been

693
00:25:19,900 --> 00:25:22,330
describing then that would look like for

694
00:25:22,330 --> 00:25:25,000
that domain that tops that top waveform

695
00:25:25,000 --> 00:25:27,100
and then these other domains here has

696
00:25:27,100 --> 00:25:28,720
similar waveforms hopefully just by

697
00:25:28,720 --> 00:25:30,730
inspection now to confirm it we can go

698
00:25:30,730 --> 00:25:35,400
to investigate maybe taking one of them

699
00:25:36,630 --> 00:25:40,210
and we find that this domain is also

700
00:25:40,210 --> 00:25:42,130
picks ball and has a similar waveform in

701
00:25:42,130 --> 00:25:43,720
terms of the query volume of the number

702
00:25:43,720 --> 00:25:45,550
of people going there and hopefully

703
00:25:45,550 --> 00:25:47,740
without being too repetitive maybe you

704
00:25:47,740 --> 00:25:48,930
guys are getting the point that this is

705
00:25:48,930 --> 00:25:52,740
staged we can look at another domain

706
00:25:52,740 --> 00:25:54,460
slightly different type of thread

707
00:25:54,460 --> 00:25:56,110
different type of query volume to this

708
00:25:56,110 --> 00:26:02,530
domain this is conficker now as we go to

709
00:26:02,530 --> 00:26:07,680
our search we now look for other domains

710
00:26:08,070 --> 00:26:11,310
find this

711
00:26:11,570 --> 00:26:14,190
and again we found another domain that

712
00:26:14,190 --> 00:26:16,110
was not a part of this but apparently

713
00:26:16,110 --> 00:26:17,490
through the graphical properties that

714
00:26:17,490 --> 00:26:19,259
we've been defining in those signals and

715
00:26:19,259 --> 00:26:21,960
then hashing we found it and it

716
00:26:21,960 --> 00:26:26,929
essentially has the same query volume so

