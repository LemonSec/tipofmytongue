1
00:00:00,000 --> 00:00:03,330
we are ready to go here long the last

2
00:00:03,330 --> 00:00:06,960
session of the day first talk will be

3
00:00:06,960 --> 00:00:10,530
kicked off with holly stewart and Peter

4
00:00:10,530 --> 00:00:14,820
Stella's hammer holly is a principal

5
00:00:14,820 --> 00:00:16,680
data scientist at Microsoft she's been

6
00:00:16,680 --> 00:00:19,109
there for five years peter is a

7
00:00:19,109 --> 00:00:21,810
co-founder of AV comparatives he's been

8
00:00:21,810 --> 00:00:24,269
there for 15 years and they're going to

9
00:00:24,269 --> 00:00:26,550
give us a talk today on prevalence

10
00:00:26,550 --> 00:00:29,490
weighted anti-malware testing take it

11
00:00:29,490 --> 00:00:32,219
away thank you um I'll kind of give you

12
00:00:32,219 --> 00:00:34,290
guys a quick overview of what we're

13
00:00:34,290 --> 00:00:37,440
going to talk about today what we want

14
00:00:37,440 --> 00:00:40,379
to discuss is a new model for scoring

15
00:00:40,379 --> 00:00:43,320
vendors in anti-malware tests and we

16
00:00:43,320 --> 00:00:46,230
want to look at customer impact and

17
00:00:46,230 --> 00:00:49,050
factor that into the test score so that

18
00:00:49,050 --> 00:00:51,270
a vendor's test score really as

19
00:00:51,270 --> 00:00:54,210
accurately as possible reflects what

20
00:00:54,210 --> 00:00:55,890
would happen in the real world with real

21
00:00:55,890 --> 00:00:59,579
customers true customer impact the way

22
00:00:59,579 --> 00:01:02,430
that we are measuring impact is by doing

23
00:01:02,430 --> 00:01:04,890
a couple things so first of all we're

24
00:01:04,890 --> 00:01:08,250
only looking at true malware samples the

25
00:01:08,250 --> 00:01:11,189
really bad stuff so you know we don't we

26
00:01:11,189 --> 00:01:12,869
don't look at things like adware

27
00:01:12,869 --> 00:01:14,549
potentially unwanted software other

28
00:01:14,549 --> 00:01:17,250
things that would likely be disputed in

29
00:01:17,250 --> 00:01:20,310
a test but truly the worst category of

30
00:01:20,310 --> 00:01:22,680
malware that pretty much everyone agree

31
00:01:22,680 --> 00:01:25,619
shouldn't be on anyone's computer the

32
00:01:25,619 --> 00:01:27,270
second thing that we're looking at is

33
00:01:27,270 --> 00:01:29,100
the prevalence of that malware and

34
00:01:29,100 --> 00:01:31,590
that's where the model really comes into

35
00:01:31,590 --> 00:01:33,840
play how do you take prevalence of a

36
00:01:33,840 --> 00:01:36,119
file or a family or other information

37
00:01:36,119 --> 00:01:38,579
about amount or group or category and

38
00:01:38,579 --> 00:01:41,640
translate that into a model and a test

39
00:01:41,640 --> 00:01:44,009
score that really represents the

40
00:01:44,009 --> 00:01:46,950
customer impact we've got a couple

41
00:01:46,950 --> 00:01:49,159
different models that will go through

42
00:01:49,159 --> 00:01:51,840
we'll go through with you today and

43
00:01:51,840 --> 00:01:53,490
we'll talk about a lot of the constraint

44
00:01:53,490 --> 00:01:55,560
because coming up with this kind of

45
00:01:55,560 --> 00:01:58,140
model it's really difficult for example

46
00:01:58,140 --> 00:02:01,200
take a malware family that is highly

47
00:02:01,200 --> 00:02:04,079
polymorphic and one sample within that

48
00:02:04,079 --> 00:02:06,659
family has an impact a customer impact

49
00:02:06,659 --> 00:02:09,628
of one because only one customer gets

50
00:02:09,628 --> 00:02:12,209
served that specific malware sample you

51
00:02:12,209 --> 00:02:13,180
may never have

52
00:02:13,180 --> 00:02:15,280
telemetry from that sample may be a

53
00:02:15,280 --> 00:02:17,829
vendor reported that sample to AV

54
00:02:17,829 --> 00:02:20,170
comparatives but they weren't willing to

55
00:02:20,170 --> 00:02:22,299
provide the telemetry that comes with

56
00:02:22,299 --> 00:02:24,730
that sample so how do you model that how

57
00:02:24,730 --> 00:02:27,760
do you score that when there's a really

58
00:02:27,760 --> 00:02:30,069
prevalent malware family but the sample

59
00:02:30,069 --> 00:02:31,659
that you test it only has an impact of

60
00:02:31,659 --> 00:02:33,189
one and what do you do when you don't

61
00:02:33,189 --> 00:02:35,739
have any elementary at all we'll talk

62
00:02:35,739 --> 00:02:38,500
about some of those constraints then

63
00:02:38,500 --> 00:02:40,629
we'll go through the models that we came

64
00:02:40,629 --> 00:02:44,049
up with and also show you some of the

65
00:02:44,049 --> 00:02:46,480
test results and some actions that we

66
00:02:46,480 --> 00:02:48,069
think is a community we should move

67
00:02:48,069 --> 00:02:51,549
forward with yeah it will be one without

68
00:02:51,549 --> 00:02:53,769
a test results are looking like you may

69
00:02:53,769 --> 00:02:56,859
expect a great diversity but yeah be

70
00:02:56,859 --> 00:03:01,930
surprised so let's take a really simple

71
00:03:01,930 --> 00:03:03,790
model to clarify what we're talking

72
00:03:03,790 --> 00:03:06,159
about here let's say we had only ten

73
00:03:06,159 --> 00:03:09,669
samples in a test set in a traditional

74
00:03:09,669 --> 00:03:11,859
scoring model each of those samples

75
00:03:11,859 --> 00:03:14,409
would count for ten percent but if you

76
00:03:14,409 --> 00:03:16,450
took those pen samples and you looked at

77
00:03:16,450 --> 00:03:18,190
how many customers they actually

78
00:03:18,190 --> 00:03:20,260
impacted you might find that one of

79
00:03:20,260 --> 00:03:22,030
those samples was incredibly prevalent

80
00:03:22,030 --> 00:03:24,180
sixty percent of all the telemetry

81
00:03:24,180 --> 00:03:26,199
revolved around around one of those

82
00:03:26,199 --> 00:03:28,329
samples the next highly prevalent one

83
00:03:28,329 --> 00:03:30,099
represents another ten percent and you

84
00:03:30,099 --> 00:03:31,659
go down to the last sample which might

85
00:03:31,659 --> 00:03:34,810
have point 0 0 1 percent impact right so

86
00:03:34,810 --> 00:03:36,400
if you look at the customer impact

87
00:03:36,400 --> 00:03:40,120
difficult one of those samples clearly

88
00:03:40,120 --> 00:03:42,519
if they missed a highly prevalent sample

89
00:03:42,519 --> 00:03:44,049
there would be a much greater customer

90
00:03:44,049 --> 00:03:45,790
impact than if they had missed one of

91
00:03:45,790 --> 00:03:47,560
the least prevalent ones so the model

92
00:03:47,560 --> 00:03:49,449
that we're talking about is really just

93
00:03:49,449 --> 00:03:51,489
accurately representing that prevalence

94
00:03:51,489 --> 00:03:53,889
model and putting it into the scoring

95
00:03:53,889 --> 00:04:00,040
system another one of the the

96
00:04:00,040 --> 00:04:01,659
difficulties is the ecosystem itself

97
00:04:01,659 --> 00:04:06,129
it's this is shows data from march early

98
00:04:06,129 --> 00:04:08,739
earlier this year and it ranks malware

99
00:04:08,739 --> 00:04:11,049
families by the most prevalent malware

100
00:04:11,049 --> 00:04:12,549
families all the way to the least

101
00:04:12,549 --> 00:04:15,459
prevalent families so it's a long tailed

102
00:04:15,459 --> 00:04:17,978
distribution system meaning that most of

103
00:04:17,978 --> 00:04:20,320
the impact comes in the very head of the

104
00:04:20,320 --> 00:04:22,389
curve the very top of the curve and

105
00:04:22,389 --> 00:04:24,170
there's very very small

106
00:04:24,170 --> 00:04:26,240
number of families that fit into that

107
00:04:26,240 --> 00:04:28,580
curve but if you look at the total

108
00:04:28,580 --> 00:04:30,440
number of malware families that were in

109
00:04:30,440 --> 00:04:33,560
the ecosystem in that month and we're

110
00:04:33,560 --> 00:04:34,670
only talking or not talking about

111
00:04:34,670 --> 00:04:35,810
exploits we're not talking about

112
00:04:35,810 --> 00:04:37,310
potentially unwanted we're just talking

113
00:04:37,310 --> 00:04:40,400
about that pretty small set of malware

114
00:04:40,400 --> 00:04:42,340
families that we all agree are truly

115
00:04:42,340 --> 00:04:44,840
impactful and bad for customers to have

116
00:04:44,840 --> 00:04:48,440
there were about five thousand different

117
00:04:48,440 --> 00:04:50,450
now our families and that represented

118
00:04:50,450 --> 00:04:55,540
4.6 million files so there's a lot of

119
00:04:55,540 --> 00:04:58,190
diversity within those malware families

120
00:04:58,190 --> 00:05:00,620
so there's a lot of variance and when

121
00:05:00,620 --> 00:05:02,540
you have lots of variants like that it

122
00:05:02,540 --> 00:05:04,340
means your model and your test that has

123
00:05:04,340 --> 00:05:05,780
to be super strong to be able to

124
00:05:05,780 --> 00:05:07,790
accommodate that kind of variance within

125
00:05:07,790 --> 00:05:10,400
your sample selection set and obviously

126
00:05:10,400 --> 00:05:13,220
the testers can't test the ecosystem we

127
00:05:13,220 --> 00:05:15,710
have 4.6 million files there's no system

128
00:05:15,710 --> 00:05:17,960
I've seen that can scale to actually

129
00:05:17,960 --> 00:05:21,170
fully represent the the ecosystem during

130
00:05:21,170 --> 00:05:23,330
a given month there's a couple of other

131
00:05:23,330 --> 00:05:25,280
constraints that Peter will talk about

132
00:05:25,280 --> 00:05:28,070
and I'll provide some color yeah there's

133
00:05:28,070 --> 00:05:31,250
some other other constraints what we try

134
00:05:31,250 --> 00:05:34,190
to do in our test so this we we need to

135
00:05:34,190 --> 00:05:36,590
put on only in this put your files so we

136
00:05:36,590 --> 00:05:38,510
have to look that there is no adware or

137
00:05:38,510 --> 00:05:40,430
potentially unwanted applications in

138
00:05:40,430 --> 00:05:42,680
there that it's really malicious there

139
00:05:42,680 --> 00:05:45,440
are no key no key loggers or legal key

140
00:05:45,440 --> 00:05:47,600
loggers because this leads to to some

141
00:05:47,600 --> 00:05:50,360
arguments with the vendors and the thing

142
00:05:50,360 --> 00:05:51,860
is that the number of new samples

143
00:05:51,860 --> 00:05:54,110
available that match that criteria is

144
00:05:54,110 --> 00:05:56,720
really limited for example also james's

145
00:05:56,720 --> 00:05:58,610
was one of the most prevalent families

146
00:05:58,610 --> 00:06:00,950
in march 2015 the most prevalent

147
00:06:00,950 --> 00:06:04,010
component was not a PE file it was only

148
00:06:04,010 --> 00:06:06,500
a script component in fact microsoft

149
00:06:06,500 --> 00:06:09,650
only saw 12 night my 12 newbie files for

150
00:06:09,650 --> 00:06:11,870
changes leading up to the test the test

151
00:06:11,870 --> 00:06:14,290
was done in March with roundabout

152
00:06:14,290 --> 00:06:17,780
131,000 files which is a huge base but

153
00:06:17,780 --> 00:06:19,370
it cannot really flick the whole

154
00:06:19,370 --> 00:06:24,500
ecosystem so this demonstrates this car

155
00:06:24,500 --> 00:06:26,690
CD of the of the samples especially for

156
00:06:26,690 --> 00:06:28,850
certain families that propagate through

157
00:06:28,850 --> 00:06:30,890
naam PE components that's the huge

158
00:06:30,890 --> 00:06:33,080
problem and in this rule with a daily

159
00:06:33,080 --> 00:06:34,970
churn of hundreds of thousands of new

160
00:06:34,970 --> 00:06:35,340
model

161
00:06:35,340 --> 00:06:38,250
malicious files per day combined with

162
00:06:38,250 --> 00:06:40,169
limited access to those files testers

163
00:06:40,169 --> 00:06:42,900
need really to I'll rely on sample

164
00:06:42,900 --> 00:06:44,970
versions of the real world with a bias

165
00:06:44,970 --> 00:06:47,639
toward malware the lends itself to being

166
00:06:47,639 --> 00:06:50,460
collected and tested and that's really

167
00:06:50,460 --> 00:06:52,710
not an easy task to solve this situation

168
00:06:52,710 --> 00:06:56,100
as it often happens in statistics we

169
00:06:56,100 --> 00:06:58,260
really need to try to create a model

170
00:06:58,260 --> 00:07:00,930
that best represents the real world so

171
00:07:00,930 --> 00:07:03,270
if you have a look at the the files

172
00:07:03,270 --> 00:07:06,900
itself the reasonably discovered files

173
00:07:06,900 --> 00:07:09,630
have been only twenty-three percent in

174
00:07:09,630 --> 00:07:13,350
the past 30 days and by Microsoft not

175
00:07:13,350 --> 00:07:14,729
not even all of the files have been

176
00:07:14,729 --> 00:07:16,950
obtainable maybe you can can speak a

177
00:07:16,950 --> 00:07:18,540
little more in title to the Terrell

178
00:07:18,540 --> 00:07:21,630
council sure so a lot of vendors like us

179
00:07:21,630 --> 00:07:24,240
when we detect a file we don't request

180
00:07:24,240 --> 00:07:26,370
that sample so the samples we request

181
00:07:26,370 --> 00:07:27,660
tend to be the things we don't detect

182
00:07:27,660 --> 00:07:30,510
yet so we've got some early warning

183
00:07:30,510 --> 00:07:31,889
telemetry that says that if I'll

184
00:07:31,889 --> 00:07:34,320
suspicious we request those files we've

185
00:07:34,320 --> 00:07:36,000
grabbed those files and we look at those

186
00:07:36,000 --> 00:07:37,979
files we add detection for the files

187
00:07:37,979 --> 00:07:39,750
that we already too thick we don't need

188
00:07:39,750 --> 00:07:43,229
those but for a tester when they are

189
00:07:43,229 --> 00:07:45,120
putting together their sample collection

190
00:07:45,120 --> 00:07:46,680
they need the files that everyone

191
00:07:46,680 --> 00:07:49,590
detects so it's often difficult to get a

192
00:07:49,590 --> 00:07:53,729
source a number of samples to that

193
00:07:53,729 --> 00:07:55,620
matches what we've actually seen in the

194
00:07:55,620 --> 00:07:57,450
ecosystem that month but now look at

195
00:07:57,450 --> 00:07:59,870
four percent may come from us obviously

196
00:07:59,870 --> 00:08:02,099
testers to build a diverse tests that

197
00:08:02,099 --> 00:08:03,479
are going to source samples from many

198
00:08:03,479 --> 00:08:05,760
different locations but still that

199
00:08:05,760 --> 00:08:09,389
represents 2323 percent of all the

200
00:08:09,389 --> 00:08:11,310
customer impact that we saw in that

201
00:08:11,310 --> 00:08:15,450
month the new files PE files that were

202
00:08:15,450 --> 00:08:17,250
seen versus all of the other file types

203
00:08:17,250 --> 00:08:20,010
and the old components which we still

204
00:08:20,010 --> 00:08:23,099
see in the ecosystem far outweigh these

205
00:08:23,099 --> 00:08:26,820
new these new PE this new PE group yeah

206
00:08:26,820 --> 00:08:29,160
leading up to the test as I explained

207
00:08:29,160 --> 00:08:31,650
before Microsoft only saw 12 files for

208
00:08:31,650 --> 00:08:33,750
chances and we had AV comparatives have

209
00:08:33,750 --> 00:08:38,669
seen even much more of that of it so

210
00:08:38,669 --> 00:08:40,020
let's have a look at the different

211
00:08:40,020 --> 00:08:43,349
models that we have evaluated the first

212
00:08:43,349 --> 00:08:46,110
one is really simple you take a file

213
00:08:46,110 --> 00:08:48,089
this in the test set and you look at the

214
00:08:48,089 --> 00:08:48,640
customer

215
00:08:48,640 --> 00:08:50,260
prevalence of that file so how many

216
00:08:50,260 --> 00:08:53,170
distinct computers reported that file

217
00:08:53,170 --> 00:08:55,090
either through unknown telemetry or

218
00:08:55,090 --> 00:08:57,280
through confirmed detections throughout

219
00:08:57,280 --> 00:08:59,620
a certain time period then you wait that

220
00:08:59,620 --> 00:09:01,540
across all the files that are in the

221
00:09:01,540 --> 00:09:03,610
test test set so and the prevalence of

222
00:09:03,610 --> 00:09:06,070
those files and the number of files that

223
00:09:06,070 --> 00:09:08,500
you miss become what is deducted from

224
00:09:08,500 --> 00:09:10,660
your test score and the files that are

225
00:09:10,660 --> 00:09:12,640
in the total tests that are your

226
00:09:12,640 --> 00:09:16,240
denominator pretty simple method however

227
00:09:16,240 --> 00:09:18,340
when we looked at this model and we

228
00:09:18,340 --> 00:09:21,580
compared it to the ecosystem we saw that

229
00:09:21,580 --> 00:09:24,970
there was a lot of discrepancies it just

230
00:09:24,970 --> 00:09:27,640
didn't fit the ecosystem curve and it

231
00:09:27,640 --> 00:09:29,440
mainly applied to really highly

232
00:09:29,440 --> 00:09:32,550
prevalent our families so in this chart

233
00:09:32,550 --> 00:09:36,880
the looks purple here it's dark blue on

234
00:09:36,880 --> 00:09:40,420
my computer this purple bar represents

235
00:09:40,420 --> 00:09:42,790
the ecosystem so the family prevalence

236
00:09:42,790 --> 00:09:45,250
of the ecosystem and then that teal bar

237
00:09:45,250 --> 00:09:49,450
is how this new model represented itself

238
00:09:49,450 --> 00:09:53,650
within the this test scoring paradigm

239
00:09:53,650 --> 00:09:55,990
and as you see a lot of the prevalent

240
00:09:55,990 --> 00:09:57,970
families were severely underrepresented

241
00:09:57,970 --> 00:10:00,040
some of the families that had a lot of

242
00:10:00,040 --> 00:10:02,110
samples and high prevalence like dorkbot

243
00:10:02,110 --> 00:10:04,650
and new pot dry were over-represented

244
00:10:04,650 --> 00:10:07,390
then so that's sort of the high

245
00:10:07,390 --> 00:10:09,790
prevalence families if you look at the

246
00:10:09,790 --> 00:10:11,590
moderate low and very low there's also

247
00:10:11,590 --> 00:10:14,350
some discrepancies there this model

248
00:10:14,350 --> 00:10:17,820
clearly doesn't fit the ecosystem curb

249
00:10:17,820 --> 00:10:22,630
so we tried again and again yeah and

250
00:10:22,630 --> 00:10:25,780
again so the next thing we started

251
00:10:25,780 --> 00:10:28,390
looking at is the family prevalence so

252
00:10:28,390 --> 00:10:30,490
why not just take the the sample

253
00:10:30,490 --> 00:10:33,700
prevalence alone view that in context of

254
00:10:33,700 --> 00:10:35,170
the overall prevalence of the malware

255
00:10:35,170 --> 00:10:37,000
family and we looked at two different

256
00:10:37,000 --> 00:10:40,630
models the first model upgrades or

257
00:10:40,630 --> 00:10:43,390
downgrade the prevalence of a sample

258
00:10:43,390 --> 00:10:45,190
based on the prevalence of the malware

259
00:10:45,190 --> 00:10:47,440
family so if you have a sample that

260
00:10:47,440 --> 00:10:49,630
affected ten customers and a highly

261
00:10:49,630 --> 00:10:52,390
prevalent family that sample counts more

262
00:10:52,390 --> 00:10:54,790
than a sample that also affected ten

263
00:10:54,790 --> 00:10:57,360
customers but is in a really tiny family

264
00:10:57,360 --> 00:11:00,160
the second family model that we looked

265
00:11:00,160 --> 00:11:00,970
at

266
00:11:00,970 --> 00:11:05,269
basically would force fit the samples of

267
00:11:05,269 --> 00:11:07,760
a particular family to the ecosystem

268
00:11:07,760 --> 00:11:11,740
curve so if the family in the ecosystem

269
00:11:11,740 --> 00:11:15,019
ecosystem represented twenty percent of

270
00:11:15,019 --> 00:11:17,420
all the malware encounters that people

271
00:11:17,420 --> 00:11:20,000
had in that time period then the test

272
00:11:20,000 --> 00:11:21,829
score for that sample set also

273
00:11:21,829 --> 00:11:26,060
represents twenty percent will let's

274
00:11:26,060 --> 00:11:28,220
talk about the next slide it shows the

275
00:11:28,220 --> 00:11:30,800
results of these two models so first

276
00:11:30,800 --> 00:11:34,459
model is on your left this is the

277
00:11:34,459 --> 00:11:37,399
upgrade downgrade model and you can see

278
00:11:37,399 --> 00:11:41,540
that clearly many of the families did

279
00:11:41,540 --> 00:11:43,610
not fit the ecosystem curve in this

280
00:11:43,610 --> 00:11:48,010
model several families are highly

281
00:11:48,010 --> 00:11:50,449
over-represented and some are severely

282
00:11:50,449 --> 00:11:54,290
under represented and it really depended

283
00:11:54,290 --> 00:11:56,420
on the the mix of the test set and how

284
00:11:56,420 --> 00:12:02,060
many samples were represented for each

285
00:12:02,060 --> 00:12:05,360
malware family so the next model that we

286
00:12:05,360 --> 00:12:09,680
tried was for spinning the score of the

287
00:12:09,680 --> 00:12:12,380
samples in a particular family to the

288
00:12:12,380 --> 00:12:13,730
prevalence of the family self that's

289
00:12:13,730 --> 00:12:19,160
this next one on your right and that one

290
00:12:19,160 --> 00:12:22,220
looks fantastic on paper you see that

291
00:12:22,220 --> 00:12:24,860
the t.o lines match up very well with

292
00:12:24,860 --> 00:12:28,670
the purple lines however when you look

293
00:12:28,670 --> 00:12:33,230
really closely at the scores if the

294
00:12:33,230 --> 00:12:35,959
tester for example had only selected a

295
00:12:35,959 --> 00:12:37,760
small number of files for one of the

296
00:12:37,760 --> 00:12:39,410
families and I think the examples here

297
00:12:39,410 --> 00:12:43,910
were brawn talk and dorkbot those few

298
00:12:43,910 --> 00:12:46,819
samples in that test set represented a

299
00:12:46,819 --> 00:12:50,120
huge portion of the test score so if a

300
00:12:50,120 --> 00:12:52,130
vendor happened to just miss a couple of

301
00:12:52,130 --> 00:12:54,079
those files their test score would be

302
00:12:54,079 --> 00:12:56,660
serially severely impacted even though

303
00:12:56,660 --> 00:12:58,579
there really that weren't that many

304
00:12:58,579 --> 00:13:01,910
samples in the test set what we realized

305
00:13:01,910 --> 00:13:04,490
is that that model although it looks

306
00:13:04,490 --> 00:13:06,709
really good on paper puts a lot of

307
00:13:06,709 --> 00:13:08,600
constraints on the tester they would

308
00:13:08,600 --> 00:13:11,029
have to have a perfect statistical model

309
00:13:11,029 --> 00:13:12,850
for every family that was

310
00:13:12,850 --> 00:13:14,949
the test and with the constraints that

311
00:13:14,949 --> 00:13:17,940
we talked about new files PE files

312
00:13:17,940 --> 00:13:20,370
samples that people were able to obtain

313
00:13:20,370 --> 00:13:24,220
this model really wasn't feasible it

314
00:13:24,220 --> 00:13:25,899
wasn't going to work in any kind of

315
00:13:25,899 --> 00:13:31,300
practical sense so we tried again so

316
00:13:31,300 --> 00:13:33,269
this last model that we tried

317
00:13:33,269 --> 00:13:36,430
incorporates file prevalence family

318
00:13:36,430 --> 00:13:38,110
prevalence and what we're calling

319
00:13:38,110 --> 00:13:41,139
partition prevalence so you guys saw

320
00:13:41,139 --> 00:13:43,449
some of those families that were grouped

321
00:13:43,449 --> 00:13:45,790
into a high moderate low very low

322
00:13:45,790 --> 00:13:49,389
partition rather than trying to force

323
00:13:49,389 --> 00:13:51,399
fit all the samples in a particular

324
00:13:51,399 --> 00:13:54,699
family to meet that ecosystem curve we

325
00:13:54,699 --> 00:13:57,579
force fit the group of families this

326
00:13:57,579 --> 00:13:59,680
means that the tester doesn't have to do

327
00:13:59,680 --> 00:14:02,410
an absolutely perfect job in selecting

328
00:14:02,410 --> 00:14:05,230
the statistically relevant set for each

329
00:14:05,230 --> 00:14:07,209
of the families they just need to focus

330
00:14:07,209 --> 00:14:09,880
on the general category families highly

331
00:14:09,880 --> 00:14:11,889
prevalent moderately prevalent low and

332
00:14:11,889 --> 00:14:14,019
very low this is a much more reasonable

333
00:14:14,019 --> 00:14:19,959
approach oh and a big call out to Fanny

334
00:14:19,959 --> 00:14:22,120
of Ecole Polytechnique of Montreal I

335
00:14:22,120 --> 00:14:24,360
don't know if she's in here but she hi

336
00:14:24,360 --> 00:14:26,649
thanks for the head tell breaks method

337
00:14:26,649 --> 00:14:29,829
it worked very well so what we did to

338
00:14:29,829 --> 00:14:31,990
come up with those categories is we use

339
00:14:31,990 --> 00:14:35,139
this some head tell breaks method to

340
00:14:35,139 --> 00:14:38,529
create the high you can look it up it's

341
00:14:38,529 --> 00:14:41,470
pretty standard statistical model the

342
00:14:41,470 --> 00:14:43,300
high moderate low and very low families

343
00:14:43,300 --> 00:14:45,279
and when you use this kind of model

344
00:14:45,279 --> 00:14:48,339
you'll see that the high category for

345
00:14:48,339 --> 00:14:50,319
example there were 15 families and that

346
00:14:50,319 --> 00:14:52,750
but those 15 families represent

347
00:14:52,750 --> 00:14:54,240
forty-eight percent of the entire

348
00:14:54,240 --> 00:14:57,610
ecosystem impact it's pretty huge so we

349
00:14:57,610 --> 00:15:01,569
use that to to rank the to create the

350
00:15:01,569 --> 00:15:05,050
test scores and apply that to the end

351
00:15:05,050 --> 00:15:08,019
result the family the sample prevalence

352
00:15:08,019 --> 00:15:12,519
and this category so the model what's

353
00:15:12,519 --> 00:15:14,740
still not a perfect fit and if you look

354
00:15:14,740 --> 00:15:16,870
at the distinct families you'll see that

355
00:15:16,870 --> 00:15:19,660
the family ecosystem prevalence still

356
00:15:19,660 --> 00:15:22,240
does not exactly match what the test

357
00:15:22,240 --> 00:15:25,230
score prevalent score would reflect

358
00:15:25,230 --> 00:15:26,860
however

359
00:15:26,860 --> 00:15:28,510
when you group those families into the

360
00:15:28,510 --> 00:15:30,760
high category it does perfectly match

361
00:15:30,760 --> 00:15:32,050
because this the nice thing about this

362
00:15:32,050 --> 00:15:34,000
model is that it forced fits everything

363
00:15:34,000 --> 00:15:35,380
that's in hi everything that's a

364
00:15:35,380 --> 00:15:37,570
moderate and low to the ecosystem curve

365
00:15:37,570 --> 00:15:40,120
so your test score will represent what

366
00:15:40,120 --> 00:15:44,550
what the ecosystem has been impacted by

367
00:15:45,030 --> 00:15:47,830
good let's come to the results we have

368
00:15:47,830 --> 00:15:52,450
seen we have done the table where you

369
00:15:52,450 --> 00:15:55,090
can see the vendor ranking with the

370
00:15:55,090 --> 00:15:57,340
traditional model and the vendor ranking

371
00:15:57,340 --> 00:16:00,250
of the prevalence model we used and the

372
00:16:00,250 --> 00:16:03,870
movement what you can see here is a

373
00:16:03,870 --> 00:16:07,410
movement between the middle field and

374
00:16:07,410 --> 00:16:09,880
but what you can see also is that the

375
00:16:09,880 --> 00:16:12,490
top vendors are stay on top even if you

376
00:16:12,490 --> 00:16:14,230
use the traditional model or if you use

377
00:16:14,230 --> 00:16:17,410
the prevalence model and the vendors

378
00:16:17,410 --> 00:16:19,960
with with a with a not-so-good detection

379
00:16:19,960 --> 00:16:22,810
are staying on the bottom so it's mostly

380
00:16:22,810 --> 00:16:24,370
in the middle field that that there are

381
00:16:24,370 --> 00:16:27,760
some shifts to the top or to the to the

382
00:16:27,760 --> 00:16:31,960
lower end the the thing what we have

383
00:16:31,960 --> 00:16:34,840
seen is the highest at the lowest score

384
00:16:34,840 --> 00:16:37,930
are really going in another way on the

385
00:16:37,930 --> 00:16:40,560
traditional model the highest score was

386
00:16:40,560 --> 00:16:43,330
ninety-nine point nine six percent and

387
00:16:43,330 --> 00:16:47,380
the lowest scores eighty-six percent by

388
00:16:47,380 --> 00:16:50,350
using the prevalence model the ranking

389
00:16:50,350 --> 00:16:52,510
was much more closer because of the

390
00:16:52,510 --> 00:16:55,780
prevalent stuff so it's for us much more

391
00:16:55,780 --> 00:17:02,400
difficult to show the the stuff the

392
00:17:02,400 --> 00:17:04,540
stuff how they are different in

393
00:17:04,540 --> 00:17:08,500
detection and if you have a look at the

394
00:17:08,500 --> 00:17:12,369
three vendors that the which did

395
00:17:12,369 --> 00:17:15,790
significantly worse using the new model

396
00:17:15,790 --> 00:17:18,640
all had more misses than their formerly

397
00:17:18,640 --> 00:17:20,700
closely and drank appears in highly

398
00:17:20,700 --> 00:17:24,040
prevalent families you can see this at

399
00:17:24,040 --> 00:17:26,890
killing or gamma rue chances are also at

400
00:17:26,890 --> 00:17:29,890
blood up in D those mrs. through their

401
00:17:29,890 --> 00:17:36,070
test cross really down so that that's

402
00:17:36,070 --> 00:17:38,360
the most most impressive part

403
00:17:38,360 --> 00:17:41,450
we have a look at another table if we

404
00:17:41,450 --> 00:17:44,540
look of the global vendor ranking and a

405
00:17:44,540 --> 00:17:46,610
regional detection score which is very

406
00:17:46,610 --> 00:17:49,460
very interesting so you can see that the

407
00:17:49,460 --> 00:17:51,679
top vendors are detecting in in each

408
00:17:51,679 --> 00:17:55,280
country and HQ location very good but if

409
00:17:55,280 --> 00:17:58,640
you look at the vendors which are not so

410
00:17:58,640 --> 00:18:00,440
good in detection they are missing in

411
00:18:00,440 --> 00:18:04,190
other geographical locations so some

412
00:18:04,190 --> 00:18:06,679
vendors in the top five had really very

413
00:18:06,679 --> 00:18:09,230
localized results performing very well

414
00:18:09,230 --> 00:18:12,799
in in in certain regions like Brazil

415
00:18:12,799 --> 00:18:15,500
China Colombia triptan career and the

416
00:18:15,500 --> 00:18:17,510
other vendors performing in the middle

417
00:18:17,510 --> 00:18:20,480
of the global test at really high scores

418
00:18:20,480 --> 00:18:22,370
for certain regions Canada Indonesia

419
00:18:22,370 --> 00:18:26,360
Russian Ukraine and the US so this

420
00:18:26,360 --> 00:18:28,490
difference could indicate that there is

421
00:18:28,490 --> 00:18:31,400
some market buyers for for for detection

422
00:18:31,400 --> 00:18:34,910
and that you can can see here in the

423
00:18:34,910 --> 00:18:40,880
table yeah going forward so we learned

424
00:18:40,880 --> 00:18:42,770
quite a few things from creating these

425
00:18:42,770 --> 00:18:45,530
models and I think one of the most

426
00:18:45,530 --> 00:18:47,169
important things that we learned is that

427
00:18:47,169 --> 00:18:49,940
it's nearly impossible to take a

428
00:18:49,940 --> 00:18:52,610
traditional scoring model and have it

429
00:18:52,610 --> 00:18:55,760
represent the ecosystem because to try

430
00:18:55,760 --> 00:18:59,419
to source the vast number of PE files

431
00:18:59,419 --> 00:19:01,820
that you would need to fill out certain

432
00:19:01,820 --> 00:19:03,980
categories for some some families it's

433
00:19:03,980 --> 00:19:07,610
it's not technically feasible so adding

434
00:19:07,610 --> 00:19:09,890
this layer of prevalence significantly

435
00:19:09,890 --> 00:19:13,780
improves the accuracy of the test score

436
00:19:13,780 --> 00:19:16,280
we also learned that building a good

437
00:19:16,280 --> 00:19:18,410
model is really complicated it took us

438
00:19:18,410 --> 00:19:21,440
lots of iterations to go through all of

439
00:19:21,440 --> 00:19:23,630
these different models and look at the

440
00:19:23,630 --> 00:19:25,460
scores and decide you know does this

441
00:19:25,460 --> 00:19:29,090
look fair does it seem fair and create

442
00:19:29,090 --> 00:19:30,740
these calculations to come up with a

443
00:19:30,740 --> 00:19:32,929
model wheat we finally landed on and

444
00:19:32,929 --> 00:19:35,450
it's by far not perfect I know that we

445
00:19:35,450 --> 00:19:38,240
will continue to evolve and make this

446
00:19:38,240 --> 00:19:40,910
better as we learn more and we try new

447
00:19:40,910 --> 00:19:43,280
things and I think the other thing that

448
00:19:43,280 --> 00:19:45,890
we learned to what Peter was just saying

449
00:19:45,890 --> 00:19:49,250
is that the the detailed local

450
00:19:49,250 --> 00:19:51,440
information the local prevalence can

451
00:19:51,440 --> 00:19:54,889
is really interesting so as you saw some

452
00:19:54,889 --> 00:19:56,570
vendors are really good on a global

453
00:19:56,570 --> 00:19:58,820
basis so if you're a corporate customer

454
00:19:58,820 --> 00:20:01,370
and you have employees who work in all

455
00:20:01,370 --> 00:20:03,379
parts of the world you're going to want

456
00:20:03,379 --> 00:20:05,240
to choose a vendor who's very strong

457
00:20:05,240 --> 00:20:08,809
globally or if you are a consumer and

458
00:20:08,809 --> 00:20:12,470
you're in one particular country you may

459
00:20:12,470 --> 00:20:14,929
want to know who's really strong in your

460
00:20:14,929 --> 00:20:17,629
market and choose that vendor to ensure

461
00:20:17,629 --> 00:20:18,799
that they're going to protect you

462
00:20:18,799 --> 00:20:20,629
against the threats that are most

463
00:20:20,629 --> 00:20:23,960
relevant in in your ecosystem so I think

464
00:20:23,960 --> 00:20:25,700
those results were we're super

465
00:20:25,700 --> 00:20:29,059
interesting and hopefully we can get

466
00:20:29,059 --> 00:20:31,580
more vendors to contribute that kind of

467
00:20:31,580 --> 00:20:34,460
detailed information so we can build out

468
00:20:34,460 --> 00:20:38,210
our our model and make it better make it

469
00:20:38,210 --> 00:20:41,330
more accurate yeah so what we really

470
00:20:41,330 --> 00:20:45,679
would like to see us to make this model

471
00:20:45,679 --> 00:20:48,289
were count and the white bias we need

472
00:20:48,289 --> 00:20:50,450
more vendors to submit telemetry data we

473
00:20:50,450 --> 00:20:52,190
cannot rely only on the telemetry

474
00:20:52,190 --> 00:20:55,009
telemetry data of some vendors we're

475
00:20:55,009 --> 00:20:56,809
getting a lot of telemetry data from

476
00:20:56,809 --> 00:20:59,120
from vendors and also from Microsoft of

477
00:20:59,120 --> 00:21:02,480
course but we need more to make this

478
00:21:02,480 --> 00:21:05,570
more accurate so we need consistent and

479
00:21:05,570 --> 00:21:08,000
reporting methodology so we need to have

480
00:21:08,000 --> 00:21:10,009
a look at distinct machines family

481
00:21:10,009 --> 00:21:12,590
prevalence common timeframes and

482
00:21:12,590 --> 00:21:14,480
locality specific data that would be

483
00:21:14,480 --> 00:21:17,000
ideal so one of the approaches is

484
00:21:17,000 --> 00:21:19,759
already done by thereby amts odeon team

485
00:21:19,759 --> 00:21:21,379
alpha testing standard organization with

486
00:21:21,379 --> 00:21:23,509
the real-time threadless the art et al

487
00:21:23,509 --> 00:21:26,929
and it looks good there is a meeting in

488
00:21:26,929 --> 00:21:29,419
October resembles will go forward in

489
00:21:29,419 --> 00:21:31,730
this case but for this we really need

490
00:21:31,730 --> 00:21:34,159
more vendors submitting more and more

491
00:21:34,159 --> 00:21:36,110
data that we can write on the on the

492
00:21:36,110 --> 00:21:39,340
status and there should be more accuracy

493
00:21:39,340 --> 00:21:42,320
prevalence data of files families and

494
00:21:42,320 --> 00:21:44,899
locality so that the reporting should be

495
00:21:44,899 --> 00:21:51,039
more a summary okay

496
00:21:53,210 --> 00:21:58,679
ok we have any questions wait please

497
00:21:58,679 --> 00:22:08,190
wait for Mike on it's coming on the data

498
00:22:08,190 --> 00:22:11,760
where you show the rank shifting i'm on

499
00:22:11,760 --> 00:22:14,610
the among the various vendors that was

500
00:22:14,610 --> 00:22:16,260
for a particular month right that was

501
00:22:16,260 --> 00:22:19,290
for one month of testing that was for

502
00:22:19,290 --> 00:22:22,140
one test this model was run for a March

503
00:22:22,140 --> 00:22:25,710
test in 2015 based on 130,000 one

504
00:22:25,710 --> 00:22:29,280
samples in our test that and before you

505
00:22:29,280 --> 00:22:34,559
ask Microsoft is not in there so but but

506
00:22:34,559 --> 00:22:36,900
it but they're all tested for the threat

507
00:22:36,900 --> 00:22:40,080
landscape as it existed in March of 2015

508
00:22:40,080 --> 00:22:41,760
yes that's right so no matter how many

509
00:22:41,760 --> 00:22:44,250
samples you use if you now look at April

510
00:22:44,250 --> 00:22:46,440
and May and June ask the threat

511
00:22:46,440 --> 00:22:49,049
landscape changes and then look at these

512
00:22:49,049 --> 00:22:51,270
results some of these patterns you

513
00:22:51,270 --> 00:22:54,330
should be able to see you know some of

514
00:22:54,330 --> 00:22:56,970
your conclusions would be you get a lot

515
00:22:56,970 --> 00:22:58,890
more insight if you look at separate

516
00:22:58,890 --> 00:23:00,870
months because now you can correct for

517
00:23:00,870 --> 00:23:03,570
the noise of the representation of

518
00:23:03,570 --> 00:23:05,370
particular samples in particular

519
00:23:05,370 --> 00:23:08,010
families and you would want samples that

520
00:23:08,010 --> 00:23:09,570
are relevant for the time period and

521
00:23:09,570 --> 00:23:11,220
what you do the test and in which you

522
00:23:11,220 --> 00:23:13,290
prevalence wait them so you would want

523
00:23:13,290 --> 00:23:15,419
to follow so for example in the next

524
00:23:15,419 --> 00:23:17,730
month if jenks kiss went really down in

525
00:23:17,730 --> 00:23:20,280
prevalent or it changed its models it

526
00:23:20,280 --> 00:23:21,780
was using different types of files to

527
00:23:21,780 --> 00:23:23,880
infect people then you obviously want to

528
00:23:23,880 --> 00:23:26,669
adjust your model and only rank you

529
00:23:26,669 --> 00:23:28,650
create a new methodology of your sample

530
00:23:28,650 --> 00:23:30,870
selection set and then prevalence way

531
00:23:30,870 --> 00:23:34,080
the impact based on the prevalence of

532
00:23:34,080 --> 00:23:36,090
those families that month but yes it

533
00:23:36,090 --> 00:23:37,620
would be interesting to trend the

534
00:23:37,620 --> 00:23:39,090
results it's not something we've done

535
00:23:39,090 --> 00:23:45,900
yet yes okay and the other cup right

536
00:23:45,900 --> 00:23:47,490
here

537
00:23:47,490 --> 00:23:50,920
a question are how do you verify are

538
00:23:50,920 --> 00:23:53,260
suspicious samples that come to you from

539
00:23:53,260 --> 00:23:55,240
vendors for example with generic

540
00:23:55,240 --> 00:23:58,090
projects and how do you recognize to

541
00:23:58,090 --> 00:24:01,350
which family dissemble belong that's it

542
00:24:01,350 --> 00:24:03,160
classification problem is hard actually

543
00:24:03,160 --> 00:24:05,890
that's a great question and we work

544
00:24:05,890 --> 00:24:08,380
really hard at doing that in fact so

545
00:24:08,380 --> 00:24:11,400
with the test sets that we've looked at

546
00:24:11,400 --> 00:24:14,500
andreas has a lot of algorithms to do

547
00:24:14,500 --> 00:24:17,559
some clustering oftentimes will just

548
00:24:17,559 --> 00:24:19,840
apply brute manpower to look at the

549
00:24:19,840 --> 00:24:21,490
samples and get them properly classified

550
00:24:21,490 --> 00:24:23,740
and then for the things that we can that

551
00:24:23,740 --> 00:24:26,170
are in that long tail we actually apply

552
00:24:26,170 --> 00:24:29,230
an average family prevalence wait to

553
00:24:29,230 --> 00:24:31,480
those because they're not classifiable

554
00:24:31,480 --> 00:24:33,670
but they still count because they're in

555
00:24:33,670 --> 00:24:35,470
that long tail so that's how we've

556
00:24:35,470 --> 00:24:36,940
handled the cases that we haven't been

557
00:24:36,940 --> 00:24:39,670
able to get to to classify you go and

558
00:24:39,670 --> 00:24:42,970
did I get you correctly are you solve

559
00:24:42,970 --> 00:24:45,190
the problem of polymorphic samples of

560
00:24:45,190 --> 00:24:48,309
this prevalence for families so for

561
00:24:48,309 --> 00:24:50,590
polymorphic samples what we do if we

562
00:24:50,590 --> 00:24:52,150
don't have to limit or e for that we

563
00:24:52,150 --> 00:24:53,710
assume there's always a telemetry of one

564
00:24:53,710 --> 00:24:56,770
and then we rank the highly polymorphic

565
00:24:56,770 --> 00:24:59,050
families according to the family

566
00:24:59,050 --> 00:25:01,960
prevalence so if I have a family

567
00:25:01,960 --> 00:25:04,960
prevalence of 100,000 it's going to be

568
00:25:04,960 --> 00:25:06,790
ranked much higher than a family

569
00:25:06,790 --> 00:25:08,070
prevalence of something that's you know

570
00:25:08,070 --> 00:25:12,730
1,000 and then that partition prevalence

571
00:25:12,730 --> 00:25:14,500
also apply so if I'm in the high

572
00:25:14,500 --> 00:25:16,840
category family again you get a second

573
00:25:16,840 --> 00:25:18,250
bump for being in the high category

574
00:25:18,250 --> 00:25:21,160
families rather than in the tail thank

575
00:25:21,160 --> 00:25:23,250
you

576
00:25:27,280 --> 00:25:29,870
I'd like to ask one question about your

577
00:25:29,870 --> 00:25:32,330
family definition is it based on

578
00:25:32,330 --> 00:25:34,820
Microsoft's signature names or is it

579
00:25:34,820 --> 00:25:36,950
based on several vendors signature names

580
00:25:36,950 --> 00:25:39,830
or is it something different so we do

581
00:25:39,830 --> 00:25:41,240
everything we can to get the proper

582
00:25:41,240 --> 00:25:43,100
classification the first classification

583
00:25:43,100 --> 00:25:45,770
we look at is our Microsoft signature

584
00:25:45,770 --> 00:25:50,450
name then a andreasen team also send

585
00:25:50,450 --> 00:25:52,520
what their family classification is

586
00:25:52,520 --> 00:25:54,920
we've got a lot of heuristic mechanisms

587
00:25:54,920 --> 00:25:56,900
that also apply classification so if

588
00:25:56,900 --> 00:25:58,970
it's in one fits detected by one of our

589
00:25:58,970 --> 00:26:01,340
generic families we we've actually got

590
00:26:01,340 --> 00:26:03,230
this very complex prioritization model

591
00:26:03,230 --> 00:26:05,360
ring where we look at first Microsoft

592
00:26:05,360 --> 00:26:07,040
family name if it's a real family not

593
00:26:07,040 --> 00:26:10,460
generic second what aundrea said it was

594
00:26:10,460 --> 00:26:14,000
third are our generic we have several

595
00:26:14,000 --> 00:26:15,740
different generic algorithms categorize

596
00:26:15,740 --> 00:26:17,840
it into families so we've got you know

597
00:26:17,840 --> 00:26:19,640
quite a long list and honestly I would

598
00:26:19,640 --> 00:26:23,720
love to add more context into that model

599
00:26:23,720 --> 00:26:25,790
so if you happen to be really good at

600
00:26:25,790 --> 00:26:28,310
classifying certain types of families it

601
00:26:28,310 --> 00:26:30,260
would be fantastic comes back to sharing

602
00:26:30,260 --> 00:26:32,000
telemetry and information to make this

603
00:26:32,000 --> 00:26:34,010
model better it would be great to get

604
00:26:34,010 --> 00:26:36,260
that from g data and pull that into the

605
00:26:36,260 --> 00:26:38,030
model so that we do even better

606
00:26:38,030 --> 00:26:39,740
classification of the samples that are

607
00:26:39,740 --> 00:26:42,050
in there yeah to really improve the

608
00:26:42,050 --> 00:26:43,490
model it's it's important that we're

609
00:26:43,490 --> 00:26:45,530
getting more and more data that's really

610
00:26:45,530 --> 00:26:48,440
based on data telemetry data and we

611
00:26:48,440 --> 00:26:52,010
would like to see more windows putting

612
00:26:52,010 --> 00:26:54,740
in more data in the telemetry stuff that

613
00:26:54,740 --> 00:26:57,730
would be really a good thing

614
00:27:03,710 --> 00:27:07,680
we're a VCR consider to a practice model

615
00:27:07,680 --> 00:27:12,420
or similar model to end your test two

616
00:27:12,420 --> 00:27:15,800
hundred and you a similar model 200 test

617
00:27:15,800 --> 00:27:18,210
at this time we don't have the data for

618
00:27:18,210 --> 00:27:19,680
it but if you would have the data it

619
00:27:19,680 --> 00:27:22,290
would be possible we had AV comparator

620
00:27:22,290 --> 00:27:24,780
doing already a detection behavior test

621
00:27:24,780 --> 00:27:29,280
of Android apks but at this time there's

622
00:27:29,280 --> 00:27:30,990
not such a prevalence model but it would

623
00:27:30,990 --> 00:27:33,240
be a good thing to do that there maybe

624
00:27:33,240 --> 00:27:37,280
we can ask Google to help us for that I

625
00:27:41,090 --> 00:27:44,550
have one question for it when you

626
00:27:44,550 --> 00:27:47,070
applied the new scoring model they range

627
00:27:47,070 --> 00:27:48,510
between the highest score and the lowest

628
00:27:48,510 --> 00:27:50,820
score narrowed considerably do you have

629
00:27:50,820 --> 00:27:52,350
any concerns about stack ranking

630
00:27:52,350 --> 00:27:55,080
products based on such a narrow window

631
00:27:55,080 --> 00:27:57,480
percentage differences indeed we have so

632
00:27:57,480 --> 00:27:58,860
we have to look what we can do with that

633
00:27:58,860 --> 00:28:00,630
because of the clustering what we are

634
00:28:00,630 --> 00:28:02,430
doing with the Eugene clusters it will

635
00:28:02,430 --> 00:28:05,460
get more and more difficult because the

636
00:28:05,460 --> 00:28:07,860
more wider this the the vendors the

637
00:28:07,860 --> 00:28:09,930
result so spread the easier it is but

638
00:28:09,930 --> 00:28:12,390
the closer they are that more

639
00:28:12,390 --> 00:28:14,850
difficulties gets it depends on the

640
00:28:14,850 --> 00:28:17,040
scale to write if you if you apply the

641
00:28:17,040 --> 00:28:18,570
scale so that you show the top on the

642
00:28:18,570 --> 00:28:21,990
bottom your graph is going to show who

643
00:28:21,990 --> 00:28:24,090
is significantly better than others when

644
00:28:24,090 --> 00:28:26,310
it comes to prevalence so you can change

645
00:28:26,310 --> 00:28:28,020
the scale on the way that it's presented

646
00:28:28,020 --> 00:28:29,340
so that you can still see the

647
00:28:29,340 --> 00:28:34,440
differences ok I've got so I just want

648
00:28:34,440 --> 00:28:36,450
to say a big thank you to AV comparators

649
00:28:36,450 --> 00:28:38,010
they've been working with us for a long

650
00:28:38,010 --> 00:28:40,740
time on this model and I have a lot of

651
00:28:40,740 --> 00:28:43,140
respect for the work that they put into

652
00:28:43,140 --> 00:28:46,080
selecting their test set and so thanks

653
00:28:46,080 --> 00:28:48,360
Peter for working with us so closely on

654
00:28:48,360 --> 00:28:49,740
it thank you all it was really

655
00:28:49,740 --> 00:28:51,600
impressive the huge database to see

656
00:28:51,600 --> 00:28:53,670
which microsoft airs about that stuff

657
00:28:53,670 --> 00:28:55,950
that's really impressive let's thank our

658
00:28:55,950 --> 00:28:58,080
speakers Holly and Peter

659
00:28:58,080 --> 00:29:06,889
[Applause]

