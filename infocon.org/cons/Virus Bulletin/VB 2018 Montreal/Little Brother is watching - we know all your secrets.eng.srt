1
00:00:00,000 --> 00:00:02,280
everyone sit down we're gonna start with

2
00:00:02,280 --> 00:00:05,870
the last talk of the day please welcome

3
00:00:05,870 --> 00:00:09,150
Stephen and Siegfried they are going to

4
00:00:09,150 --> 00:00:11,040
talk about the little brother that is

5
00:00:11,040 --> 00:00:15,350
watching all of us welcome thank you

6
00:00:15,350 --> 00:00:31,080
slides okay yeah thank you very much

7
00:00:31,080 --> 00:00:34,020
I'm Siegfried and this is Steven and we

8
00:00:34,020 --> 00:00:35,880
are both from Germany from a Research

9
00:00:35,880 --> 00:00:39,030
Institute called Fraunhofer and today we

10
00:00:39,030 --> 00:00:41,430
present our work on mobile tracking

11
00:00:41,430 --> 00:00:44,309
applications this work was conducted

12
00:00:44,309 --> 00:00:47,489
with our offensive security team called

13
00:00:47,489 --> 00:00:50,670
team sick team sick is basically a group

14
00:00:50,670 --> 00:00:53,399
of students and researchers meeting up

15
00:00:53,399 --> 00:00:55,110
in the spare time in looking into

16
00:00:55,110 --> 00:00:58,320
interesting security stuff so I also

17
00:00:58,320 --> 00:01:00,059
would like to mention a few members who

18
00:01:00,059 --> 00:01:01,859
were participating that researchers

19
00:01:01,859 --> 00:01:05,250
Stefan Hooper Alexander Benedict Daniel

20
00:01:05,250 --> 00:01:08,040
Julian Julius Kevin Michael Phillip and

21
00:01:08,040 --> 00:01:12,119
Siebert ok yeah I'm Siegfried as already

22
00:01:12,119 --> 00:01:14,280
mentioned I'm leading a research group

23
00:01:14,280 --> 00:01:16,350
at this institute called secure software

24
00:01:16,350 --> 00:01:19,259
engineering our main research focuses on

25
00:01:19,259 --> 00:01:21,630
static and dynamic code analysis of

26
00:01:21,630 --> 00:01:23,610
building new tools in order to

27
00:01:23,610 --> 00:01:25,740
automatically find vulnerabilities in

28
00:01:25,740 --> 00:01:28,770
binaries I'm a founder of this offensive

29
00:01:28,770 --> 00:01:31,079
security team and also a founder of a

30
00:01:31,079 --> 00:01:32,909
tool called code inspect which is an

31
00:01:32,909 --> 00:01:35,850
Android reverse engineering - Steven

32
00:01:35,850 --> 00:01:37,110
would you like to say a few words about

33
00:01:37,110 --> 00:01:39,390
yourself true thanks I'm the deputy head

34
00:01:39,390 --> 00:01:41,130
of the seeker software engineering group

35
00:01:41,130 --> 00:01:43,619
I'm also computer scientist and my main

36
00:01:43,619 --> 00:01:45,930
research focus is on static code

37
00:01:45,930 --> 00:01:48,630
analysis especially data flow analysis

38
00:01:48,630 --> 00:01:50,600
and I consider myself an ethical hacker

39
00:01:50,600 --> 00:01:52,439
good thank you

40
00:01:52,439 --> 00:01:55,530
GERD a short agenda for today so I will

41
00:01:55,530 --> 00:01:58,049
stall the short motivation give a little

42
00:01:58,049 --> 00:01:59,850
bit of background information about the

43
00:01:59,850 --> 00:02:02,579
topic then we will dig into our findings

44
00:02:02,579 --> 00:02:05,130
we have three categories first

45
00:02:05,130 --> 00:02:08,038
client-side authorization then some

46
00:02:08,038 --> 00:02:10,110
findings on client-side vulnerabilities

47
00:02:10,110 --> 00:02:11,940
and some findings on server-side

48
00:02:11,940 --> 00:02:13,340
vulnerabilities

49
00:02:13,340 --> 00:02:15,920
during our research we also found two

50
00:02:15,920 --> 00:02:17,870
Malabar families and Google Play Store

51
00:02:17,870 --> 00:02:19,879
which we will talk about a little bit of

52
00:02:19,879 --> 00:02:22,099
a responsible closure and a summary in

53
00:02:22,099 --> 00:02:27,080
the end good motivation so well

54
00:02:27,080 --> 00:02:28,910
surveillance or basic when you talk

55
00:02:28,910 --> 00:02:30,860
about tracking applications and there's

56
00:02:30,860 --> 00:02:32,870
also the word surveillance in my mind

57
00:02:32,870 --> 00:02:35,450
civilians exist for decades right there

58
00:02:35,450 --> 00:02:37,430
has been different catches out there

59
00:02:37,430 --> 00:02:40,459
they can track people but actually the

60
00:02:40,459 --> 00:02:43,910
most surveillance gadget or device is

61
00:02:43,910 --> 00:02:45,500
basically or a pocket the smartphone

62
00:02:45,500 --> 00:02:48,110
because it has a lot of sensors getting

63
00:02:48,110 --> 00:02:50,060
access to location information getting

64
00:02:50,060 --> 00:02:51,829
access to contacts and so on and so

65
00:02:51,829 --> 00:02:54,049
forth and this is also what spyware and

66
00:02:54,049 --> 00:02:55,790
read makes use of and I guess you guys

67
00:02:55,790 --> 00:02:58,250
are all aware of this but we ask ourself

68
00:02:58,250 --> 00:03:00,530
the question also although benign reason

69
00:03:00,530 --> 00:03:04,700
for tracking applications and we deliver

70
00:03:04,700 --> 00:03:06,980
the research and we find three kind of

71
00:03:06,980 --> 00:03:10,430
areas on a one hand side families found

72
00:03:10,430 --> 00:03:12,980
a lot of applications out there that

73
00:03:12,980 --> 00:03:15,110
whatever father wants to know where the

74
00:03:15,110 --> 00:03:16,849
kid is if it's safe or not like

75
00:03:16,849 --> 00:03:20,569
legitimate reasons couples you found a

76
00:03:20,569 --> 00:03:22,819
lot of track my boyfriend track my

77
00:03:22,819 --> 00:03:25,010
girlfriend applications probably they

78
00:03:25,010 --> 00:03:26,600
don't trust on each other or they

79
00:03:26,600 --> 00:03:28,730
probably they think the one is cheating

80
00:03:28,730 --> 00:03:31,579
on him or her whatever and so these

81
00:03:31,579 --> 00:03:34,010
escapes exists and also friends because

82
00:03:34,010 --> 00:03:35,389
friends I want to know where my body is

83
00:03:35,389 --> 00:03:37,400
and so on so there are legitimate

84
00:03:37,400 --> 00:03:39,290
reasons for those kind of tracking

85
00:03:39,290 --> 00:03:41,599
applications the question is not how do

86
00:03:41,599 --> 00:03:43,730
do you differentiate between both

87
00:03:43,730 --> 00:03:45,139
because from a technical perspective

88
00:03:45,139 --> 00:03:47,450
they are the same right so if you

89
00:03:47,450 --> 00:03:49,489
implement it somebody looked a little

90
00:03:49,489 --> 00:03:51,500
bit up and we found on a Google Android

91
00:03:51,500 --> 00:03:55,639
security report from 2017 a quote which

92
00:03:55,639 --> 00:03:57,680
describes commercial spyware which is

93
00:03:57,680 --> 00:04:00,169
considered the malicious part it says

94
00:04:00,169 --> 00:04:02,389
any application that transmits sensitive

95
00:04:02,389 --> 00:04:04,730
information off the device without user

96
00:04:04,730 --> 00:04:06,349
consent and does not display a

97
00:04:06,349 --> 00:04:08,870
persistent notification then this is

98
00:04:08,870 --> 00:04:11,090
happening so this means whatever if I

99
00:04:11,090 --> 00:04:12,380
would like to implement a benign

100
00:04:12,380 --> 00:04:15,169
tracking application I need to show for

101
00:04:15,169 --> 00:04:17,238
instant notification showing hey right

102
00:04:17,238 --> 00:04:18,649
now I'm accessing your location

103
00:04:18,649 --> 00:04:20,238
information and I'm sending it to your

104
00:04:20,238 --> 00:04:22,130
father or whatever then it should be

105
00:04:22,130 --> 00:04:23,570
fine and it should be able

106
00:04:23,570 --> 00:04:25,670
to put these kind of apps into the place

107
00:04:25,670 --> 00:04:27,410
though otherwise it's considered

108
00:04:27,410 --> 00:04:31,040
Melbourne so an hour focal or research

109
00:04:31,040 --> 00:04:33,430
focused only of those legitimate

110
00:04:33,430 --> 00:04:36,590
tracking applications well there's the

111
00:04:36,590 --> 00:04:38,900
research question how well is the

112
00:04:38,900 --> 00:04:40,880
collected data protected because a lot

113
00:04:40,880 --> 00:04:43,190
of sensitive data out there how well do

114
00:04:43,190 --> 00:04:46,150
these kind of experts protect my data

115
00:04:46,150 --> 00:04:48,530
for that while we looked up a little

116
00:04:48,530 --> 00:04:51,050
Play Store we typed in whatever track my

117
00:04:51,050 --> 00:04:53,060
girlfriend tracked my boyfriend and we

118
00:04:53,060 --> 00:04:55,730
download the first hits in totally

119
00:04:55,730 --> 00:04:58,400
nineteen different applications why

120
00:04:58,400 --> 00:05:00,380
nineteen there is no special reason we

121
00:05:00,380 --> 00:05:02,210
just collected a couple of application

122
00:05:02,210 --> 00:05:04,340
at some point we stopped and then we

123
00:05:04,340 --> 00:05:05,510
said hey let's look into those

124
00:05:05,510 --> 00:05:09,200
applications the focus here was not on

125
00:05:09,200 --> 00:05:11,600
the commercial and tracking application

126
00:05:11,600 --> 00:05:12,970
those are all freely available

127
00:05:12,970 --> 00:05:14,990
applications and you can use this

128
00:05:14,990 --> 00:05:16,580
because there has been a lot of research

129
00:05:16,580 --> 00:05:18,980
in the commercial tracking application

130
00:05:18,980 --> 00:05:23,900
world in the past as a spoiler of all of

131
00:05:23,900 --> 00:05:26,420
those 19 applications we found 37

132
00:05:26,420 --> 00:05:28,970
different vulnerabilities and also very

133
00:05:28,970 --> 00:05:31,310
high severe vulnerabilities any

134
00:05:31,310 --> 00:05:33,590
remaining talk we will explain a few of

135
00:05:33,590 --> 00:05:37,070
them good few words about background

136
00:05:37,070 --> 00:05:39,260
information very very simple setup just

137
00:05:39,260 --> 00:05:41,240
that we're the same page so how does

138
00:05:41,240 --> 00:05:42,770
this work if you have a tracking

139
00:05:42,770 --> 00:05:45,620
application basically you as an observer

140
00:05:45,620 --> 00:05:47,570
for instance the father installs the

141
00:05:47,570 --> 00:05:49,370
application it also the monitor person

142
00:05:49,370 --> 00:05:51,170
like a kit instance the same application

143
00:05:51,170 --> 00:05:53,390
and then in the beginning there is some

144
00:05:53,390 --> 00:05:55,880
form of pairing process going on they

145
00:05:55,880 --> 00:05:57,650
both are connected and then well

146
00:05:57,650 --> 00:05:59,720
obviously the monitor person collects

147
00:05:59,720 --> 00:06:02,210
all the sensitive data whatever incoming

148
00:06:02,210 --> 00:06:04,810
text messages on and it sends it to the

149
00:06:04,810 --> 00:06:07,520
cloud storage or tracking provider and

150
00:06:07,520 --> 00:06:10,720
observer pulls it very simple

151
00:06:10,720 --> 00:06:13,190
interestingly on the tracking provider

152
00:06:13,190 --> 00:06:14,210
there are very sensitive information

153
00:06:14,210 --> 00:06:16,850
like location information and call

154
00:06:16,850 --> 00:06:19,880
history incoming text messages incoming

155
00:06:19,880 --> 00:06:21,740
whatsapp messages and so on and so forth

156
00:06:21,740 --> 00:06:24,880
and a few application of those tracking

157
00:06:24,880 --> 00:06:27,910
applications also added

158
00:06:27,910 --> 00:06:30,290
cool functionality like adding a

159
00:06:30,290 --> 00:06:32,960
messenger inside the application so this

160
00:06:32,960 --> 00:06:35,000
means that the observer can chat with

161
00:06:35,000 --> 00:06:36,550
the observed person or

162
00:06:36,550 --> 00:06:39,100
can share pictures or images which is

163
00:06:39,100 --> 00:06:42,780
important for one part of the talk good

164
00:06:42,780 --> 00:06:45,100
let's start with the first kind of

165
00:06:45,100 --> 00:06:46,890
findings we call it client-side

166
00:06:46,890 --> 00:06:49,360
authorization for that we pick the

167
00:06:49,360 --> 00:06:52,120
example of premium features while an

168
00:06:52,120 --> 00:06:53,470
Android well if you developed

169
00:06:53,470 --> 00:06:55,690
application on for instance if you would

170
00:06:55,690 --> 00:06:57,400
like in that particular case of the

171
00:06:57,400 --> 00:06:58,780
application if you would like to remove

172
00:06:58,780 --> 00:07:01,930
the advertisement you need to pay 1 euro

173
00:07:01,930 --> 00:07:04,720
50 for instance I'm very well-known and

174
00:07:04,720 --> 00:07:07,570
we were curious is what we usually do

175
00:07:07,570 --> 00:07:10,930
how was it implemented in that case so

176
00:07:10,930 --> 00:07:12,460
and then we looked into your code and we

177
00:07:12,460 --> 00:07:14,740
found the following snippet share

178
00:07:14,740 --> 00:07:17,500
preferences get boolean with the key L

179
00:07:17,500 --> 00:07:20,740
ads and the value if the value is true

180
00:07:20,740 --> 00:07:23,140
then basically on the client side it

181
00:07:23,140 --> 00:07:25,960
disables the advertisement for those of

182
00:07:25,960 --> 00:07:27,760
you who are not so familiar with Android

183
00:07:27,760 --> 00:07:30,970
the share preferences is basically a key

184
00:07:30,970 --> 00:07:35,050
value based storage in form of an XML

185
00:07:35,050 --> 00:07:37,270
file and this XML file is then created

186
00:07:37,270 --> 00:07:40,720
and is part of the application or that

187
00:07:40,720 --> 00:07:42,970
the file system level so in this case

188
00:07:42,970 --> 00:07:44,920
it's set to false and if you for

189
00:07:44,920 --> 00:07:47,050
instance paid this one year of 50 and

190
00:07:47,050 --> 00:07:50,020
the this file is set to true and then

191
00:07:50,020 --> 00:07:52,150
the first line it Reds the value and if

192
00:07:52,150 --> 00:07:54,520
it's true then it question is can you

193
00:07:54,520 --> 00:07:57,970
manipulate this farm answer is yes there

194
00:07:57,970 --> 00:07:59,590
are two ways obviously if you're on a

195
00:07:59,590 --> 00:08:01,270
rooted device you can manipulate the

196
00:08:01,270 --> 00:08:04,600
file if you are an Android device in

197
00:08:04,600 --> 00:08:06,820
that case if the application allows the

198
00:08:06,820 --> 00:08:08,980
backup feature then you can backup the

199
00:08:08,980 --> 00:08:12,700
application including this XML file then

200
00:08:12,700 --> 00:08:14,980
you modify the XML file set the value to

201
00:08:14,980 --> 00:08:17,050
true and then you restore it and here we

202
00:08:17,050 --> 00:08:18,850
come this is nothing new this is well

203
00:08:18,850 --> 00:08:22,600
known so we learned yes we can change it

204
00:08:22,600 --> 00:08:25,360
and we can get rid of the advertisement

205
00:08:25,360 --> 00:08:27,670
of pain when we look further into those

206
00:08:27,670 --> 00:08:29,710
entries we found an another interesting

207
00:08:29,710 --> 00:08:32,140
world called SMS phone what does this

208
00:08:32,140 --> 00:08:35,740
mean this means if you if the observer

209
00:08:35,740 --> 00:08:37,960
would like to get all the text messages

210
00:08:37,960 --> 00:08:41,860
of your monitor person for instance and

211
00:08:41,860 --> 00:08:45,100
if you do not pay you only see the first

212
00:08:45,100 --> 00:08:48,230
X characters of that text message if you

213
00:08:48,230 --> 00:08:50,150
you see the complete text nudge this is

214
00:08:50,150 --> 00:08:52,240
their kind of business model whatever

215
00:08:52,240 --> 00:08:54,710
well you already learned yes we can

216
00:08:54,710 --> 00:08:57,230
manipulate this file and yes we can see

217
00:08:57,230 --> 00:08:59,500
the complete text message nevertheless

218
00:08:59,500 --> 00:09:02,030
we were interesting how did they

219
00:09:02,030 --> 00:09:04,580
implement this and this was quite

220
00:09:04,580 --> 00:09:07,580
interesting so this protocol basically

221
00:09:07,580 --> 00:09:09,650
boss the observer says hey I would like

222
00:09:09,650 --> 00:09:11,330
to get SMS SMS

223
00:09:11,330 --> 00:09:14,120
or a text message from the monitor

224
00:09:14,120 --> 00:09:16,310
person and the service says yeah sure

225
00:09:16,310 --> 00:09:18,800
here are all the text messages like the

226
00:09:18,800 --> 00:09:21,320
complete text messages text that is one

227
00:09:21,320 --> 00:09:23,090
text made to tractors three of the

228
00:09:23,090 --> 00:09:24,620
person I would like to know from the

229
00:09:24,620 --> 00:09:27,320
text messages so they are already at the

230
00:09:27,320 --> 00:09:30,740
client site so if they're already at the

231
00:09:30,740 --> 00:09:33,080
client side in full-length so how did

232
00:09:33,080 --> 00:09:35,450
they enforce them this check yes the

233
00:09:35,450 --> 00:09:38,210
answer is it was in the code so if you

234
00:09:38,210 --> 00:09:40,790
did not pay it just shows the fifty

235
00:09:40,790 --> 00:09:42,950
characters of the text message and if

236
00:09:42,950 --> 00:09:45,800
you paid this for euros or whatever

237
00:09:45,800 --> 00:09:48,200
it shows the complete text message to

238
00:09:48,200 --> 00:09:50,630
the observer and this is kind of yeah

239
00:09:50,630 --> 00:09:52,600
you shouldn't do this

240
00:09:52,600 --> 00:09:56,570
as a we are short summary for this part

241
00:09:56,570 --> 00:09:58,850
since we usually always see this with

242
00:09:58,850 --> 00:10:01,100
the ship preferences do not use the

243
00:10:01,100 --> 00:10:03,350
share preference for payment or license

244
00:10:03,350 --> 00:10:05,600
checks there are proper api's for this

245
00:10:05,600 --> 00:10:09,530
and use those use them instead okay so

246
00:10:09,530 --> 00:10:11,510
this was it for my part I will now hand

247
00:10:11,510 --> 00:10:13,490
over to Steven who will continue with

248
00:10:13,490 --> 00:10:15,170
the remaining part thanks secrets so I

249
00:10:15,170 --> 00:10:17,480
will now go over a client-side and

250
00:10:17,480 --> 00:10:20,120
communication vulnerabilities so before

251
00:10:20,120 --> 00:10:21,800
you can use those apps you have to log

252
00:10:21,800 --> 00:10:23,150
in which means you have to enter a user

253
00:10:23,150 --> 00:10:24,830
name which is your email address and

254
00:10:24,830 --> 00:10:26,660
your password and you click on OK and

255
00:10:26,660 --> 00:10:28,330
this whole thing gets sent to the server

256
00:10:28,330 --> 00:10:31,040
so what we did is we just put in our

257
00:10:31,040 --> 00:10:33,560
test account click on enter and we saw

258
00:10:33,560 --> 00:10:35,570
that they transfer to the server

259
00:10:35,570 --> 00:10:38,780
it was unprotected HTTP communication so

260
00:10:38,780 --> 00:10:40,370
that was good for us as a tickers

261
00:10:40,370 --> 00:10:42,110
because we can easily do Amanda middle

262
00:10:42,110 --> 00:10:44,390
attack here however we don't see our

263
00:10:44,390 --> 00:10:46,310
username your password we just see some

264
00:10:46,310 --> 00:10:49,730
garbled stuff first attempt to to get

265
00:10:49,730 --> 00:10:51,380
some sense out of that just do it

266
00:10:51,380 --> 00:10:53,720
multiple times and what you can see is

267
00:10:53,720 --> 00:10:56,240
when we do the same login request four

268
00:10:56,240 --> 00:10:59,240
times these are key value pairs

269
00:10:59,240 --> 00:11:02,089
and there are always two values that are

270
00:11:02,089 --> 00:11:03,740
identical like the green ones are always

271
00:11:03,740 --> 00:11:05,119
identical and the blue ones are always

272
00:11:05,119 --> 00:11:07,399
identical the keys are different but the

273
00:11:07,399 --> 00:11:09,470
values are always the same so the big

274
00:11:09,470 --> 00:11:11,869
question is what is going on here since

275
00:11:11,869 --> 00:11:13,610
our username and our password never

276
00:11:13,610 --> 00:11:15,649
changes that we entered this must have

277
00:11:15,649 --> 00:11:17,540
something to do with our username and

278
00:11:17,540 --> 00:11:19,720
our password so we looked into the code

279
00:11:19,720 --> 00:11:22,249
what these guys did is they had a

280
00:11:22,249 --> 00:11:25,490
hard-coded key inside the app they used

281
00:11:25,490 --> 00:11:28,459
this hard-coded key X or it would the

282
00:11:28,459 --> 00:11:31,189
username that you entered encoded the

283
00:11:31,189 --> 00:11:35,119
result with base64 and this is the green

284
00:11:35,119 --> 00:11:37,129
value that you have seen in the network

285
00:11:37,129 --> 00:11:39,889
trace now what they do since these are

286
00:11:39,889 --> 00:11:42,050
key value pairs is they have a

287
00:11:42,050 --> 00:11:44,389
predefined list of potential keys for

288
00:11:44,389 --> 00:11:46,790
the key value pairs they add random

289
00:11:46,790 --> 00:11:50,300
choose one entry of this list and take

290
00:11:50,300 --> 00:11:53,959
this as a key for the passwords the same

291
00:11:53,959 --> 00:11:55,819
thing happens they exert with the key

292
00:11:55,819 --> 00:11:58,399
encoded base64 and for the key value

293
00:11:58,399 --> 00:12:01,279
pairs they just choose randomly from a

294
00:12:01,279 --> 00:12:04,249
different distinct list of keys so if

295
00:12:04,249 --> 00:12:05,720
you want to reverse that you just have

296
00:12:05,720 --> 00:12:08,029
to look okay is this from the key list

297
00:12:08,029 --> 00:12:10,249
of username or key list of password undo

298
00:12:10,249 --> 00:12:12,980
base64 undo XOR of your run with all the

299
00:12:12,980 --> 00:12:15,939
credentials and and that is kind of bad

300
00:12:15,939 --> 00:12:18,769
now if you remember that original

301
00:12:18,769 --> 00:12:20,540
network trace there was also some other

302
00:12:20,540 --> 00:12:23,059
stuff like a a equals what node and data

303
00:12:23,059 --> 00:12:25,100
and this is just random garbage because

304
00:12:25,100 --> 00:12:27,049
they think their app is more secure if

305
00:12:27,049 --> 00:12:29,179
they put in some additional garbage in

306
00:12:29,179 --> 00:12:32,569
the network traffic and now not not

307
00:12:32,569 --> 00:12:36,040
really they are not really the winners

308
00:12:36,040 --> 00:12:38,600
so this totally doesn't help to secure

309
00:12:38,600 --> 00:12:41,809
anything now if you have a security

310
00:12:41,809 --> 00:12:43,999
problem inside your app that's not good

311
00:12:43,999 --> 00:12:45,379
but if you have a security problem

312
00:12:45,379 --> 00:12:47,839
inside your bag and that's way worse

313
00:12:47,839 --> 00:12:49,699
because this might allow people to

314
00:12:49,699 --> 00:12:52,490
actually go for the data that is not

315
00:12:52,490 --> 00:12:54,410
locally on your phone but that is inside

316
00:12:54,410 --> 00:12:55,759
the backend which is potentially all

317
00:12:55,759 --> 00:12:57,589
your data and this is why we came up

318
00:12:57,589 --> 00:12:59,660
with a cool vulnerability Awards here

319
00:12:59,660 --> 00:13:02,540
going from bad to worse starting with

320
00:13:02,540 --> 00:13:06,170
place number 4 this is called who needs

321
00:13:06,170 --> 00:13:09,049
authentication so as we can see this

322
00:13:09,049 --> 00:13:11,120
network request we captured here was

323
00:13:11,120 --> 00:13:12,520
HTTP again

324
00:13:12,520 --> 00:13:14,140
we have seen this all over the place

325
00:13:14,140 --> 00:13:16,570
this is nothing new then they transmit a

326
00:13:16,570 --> 00:13:19,779
user ID which is my user IDs the person

327
00:13:19,779 --> 00:13:21,820
who requests data note that this is just

328
00:13:21,820 --> 00:13:24,490
user ID there is no password whatsoever

329
00:13:24,490 --> 00:13:26,860
I just claimed who I want to be and

330
00:13:26,860 --> 00:13:30,339
that's all fine for that app next I need

331
00:13:30,339 --> 00:13:32,410
to provide the idea of the person of the

332
00:13:32,410 --> 00:13:34,839
track person for whom I want to get data

333
00:13:34,839 --> 00:13:37,870
again I can just claim I don't need to

334
00:13:37,870 --> 00:13:40,660
prove anything and the date for which

335
00:13:40,660 --> 00:13:42,730
date I want to get the location data of

336
00:13:42,730 --> 00:13:45,670
that person in that case also it's also

337
00:13:45,670 --> 00:13:47,260
important to note that this user ID

338
00:13:47,260 --> 00:13:48,910
doesn't need to have anything to do with

339
00:13:48,910 --> 00:13:52,000
that child ID which means that they I

340
00:13:52,000 --> 00:13:54,160
don't even need to have access to the

341
00:13:54,160 --> 00:13:55,990
data of that specific person I want to

342
00:13:55,990 --> 00:13:58,029
track I only need to know the ID of the

343
00:13:58,029 --> 00:14:00,970
person I want to track ask nicely and I

344
00:14:00,970 --> 00:14:02,529
get all the location records of that

345
00:14:02,529 --> 00:14:05,470
person on the date I requested of course

346
00:14:05,470 --> 00:14:06,970
since these are longitude and latitude

347
00:14:06,970 --> 00:14:10,000
we just piped it into Google Maps this

348
00:14:10,000 --> 00:14:12,010
is one of our test phones one of our

349
00:14:12,010 --> 00:14:13,720
students ran around with the test phone

350
00:14:13,720 --> 00:14:16,209
in the city of Darmstadt so you can

351
00:14:16,209 --> 00:14:18,790
actually get a live track of people

352
00:14:18,790 --> 00:14:24,250
moving around their daily business in

353
00:14:24,250 --> 00:14:26,110
the same app there was also a feature to

354
00:14:26,110 --> 00:14:28,149
extract the text messages that the

355
00:14:28,149 --> 00:14:31,000
observed person has received now the

356
00:14:31,000 --> 00:14:32,529
question is how do we get the text

357
00:14:32,529 --> 00:14:35,050
messages of a person it's easy we just

358
00:14:35,050 --> 00:14:37,959
have to ask nicely so we need the user

359
00:14:37,959 --> 00:14:40,390
ID of the person and we need to say we

360
00:14:40,390 --> 00:14:42,160
want a hundred text messages and the

361
00:14:42,160 --> 00:14:44,980
server politely replies and says ok this

362
00:14:44,980 --> 00:14:46,870
message was sent on that date with that

363
00:14:46,870 --> 00:14:48,459
content and was sent by that phone

364
00:14:48,459 --> 00:14:51,670
number off you go with all the data now

365
00:14:51,670 --> 00:14:53,950
what happens if I don't know the

366
00:14:53,950 --> 00:14:55,660
username of the person for whom I want

367
00:14:55,660 --> 00:14:58,060
to get the data I just leave this field

368
00:14:58,060 --> 00:15:00,100
blank I don't tell the server for whom I

369
00:15:00,100 --> 00:15:02,020
want to get data and so the server says

370
00:15:02,020 --> 00:15:04,089
yeah sure I just give it for all the

371
00:15:04,089 --> 00:15:07,540
users just pick what you need this is

372
00:15:07,540 --> 00:15:12,550
like a database thumb ok this was fourth

373
00:15:12,550 --> 00:15:14,800
place moving on to something worse this

374
00:15:14,800 --> 00:15:16,630
is third place of the vulnerability

375
00:15:16,630 --> 00:15:21,279
Awards some apps also allow you to

376
00:15:21,279 --> 00:15:24,160
exchange images for these images they

377
00:15:24,160 --> 00:15:26,470
put it on a cloud they require a user of

378
00:15:26,470 --> 00:15:29,230
and they also filter the images that you

379
00:15:29,230 --> 00:15:33,820
can see based on your user ID so to get

380
00:15:33,820 --> 00:15:36,010
more images you need to somehow bypass

381
00:15:36,010 --> 00:15:38,560
that authentication interestingly their

382
00:15:38,560 --> 00:15:40,420
back-end they use in the app even has a

383
00:15:40,420 --> 00:15:42,970
web front-end why you need a web

384
00:15:42,970 --> 00:15:44,740
front-end for something that is an API I

385
00:15:44,740 --> 00:15:48,220
don't know don't ask me you have paging

386
00:15:48,220 --> 00:15:50,650
solutions all you leakes to see like 30

387
00:15:50,650 --> 00:15:52,240
images per page and you can click

388
00:15:52,240 --> 00:15:52,780
through it

389
00:15:52,780 --> 00:15:55,780
we just took page 7 for no reason at all

390
00:15:55,780 --> 00:15:59,650
and you have to specify your user name

391
00:15:59,650 --> 00:16:01,690
and you have to authenticate normally

392
00:16:01,690 --> 00:16:03,160
however what you can do is the simple

393
00:16:03,160 --> 00:16:05,560
sequel injection on that user name this

394
00:16:05,560 --> 00:16:09,190
is really a t security 101 and yep you

395
00:16:09,190 --> 00:16:10,960
got the pictures and since they have

396
00:16:10,960 --> 00:16:13,630
this nice web front-end you can even

397
00:16:13,630 --> 00:16:15,340
conveniently browse through it so

398
00:16:15,340 --> 00:16:17,650
there's absolutely no need to create a

399
00:16:17,650 --> 00:16:19,960
normal script or whatever and since

400
00:16:19,960 --> 00:16:21,730
we're talking about tracker apps for

401
00:16:21,730 --> 00:16:23,160
example where boyfriends and girlfriends

402
00:16:23,160 --> 00:16:26,110
exchange images they usually talk about

403
00:16:26,110 --> 00:16:29,470
things like dinner or I don't think we

404
00:16:29,470 --> 00:16:32,530
have minors in the room do we okay

405
00:16:32,530 --> 00:16:35,860
other images so this means we're talking

406
00:16:35,860 --> 00:16:39,190
about a severe data breach here because

407
00:16:39,190 --> 00:16:41,410
people just put images on a back-end

408
00:16:41,410 --> 00:16:42,640
service without any proper

409
00:16:42,640 --> 00:16:45,150
authentication of whatsoever

410
00:16:45,150 --> 00:16:48,340
vulnerability was placed too so what is

411
00:16:48,340 --> 00:16:49,930
better than getting images getting

412
00:16:49,930 --> 00:16:53,080
credentials this app was created in a

413
00:16:53,080 --> 00:16:55,450
way that when I install it on a phone it

414
00:16:55,450 --> 00:16:58,540
generates a unique hardware token for my

415
00:16:58,540 --> 00:17:00,880
phone when I light or uninstall the app

416
00:17:00,880 --> 00:17:03,670
and install it back again it generates

417
00:17:03,670 --> 00:17:05,709
the same hardware token because it's the

418
00:17:05,709 --> 00:17:09,130
same device and it remembers me so the

419
00:17:09,130 --> 00:17:12,339
the abscess hey welcome back Steven even

420
00:17:12,339 --> 00:17:13,780
though I have not worked in or anything

421
00:17:13,780 --> 00:17:16,119
because it just recognizes this is the

422
00:17:16,119 --> 00:17:18,069
same hardware token and they have

423
00:17:18,069 --> 00:17:20,589
implemented in a way that if I tell the

424
00:17:20,589 --> 00:17:22,780
server the correct hardware token the

425
00:17:22,780 --> 00:17:24,699
server gives me my username in plain

426
00:17:24,699 --> 00:17:27,910
text and my password in plain text so we

427
00:17:27,910 --> 00:17:29,470
have an Oracle for user names and

428
00:17:29,470 --> 00:17:32,680
passwords here which means however if

429
00:17:32,680 --> 00:17:34,840
you want to exploit this Oracle we need

430
00:17:34,840 --> 00:17:37,300
to get this hardware token don't be

431
00:17:37,300 --> 00:17:39,850
confused here device ID is not an

432
00:17:39,850 --> 00:17:42,490
Android device ID like an I my this is

433
00:17:42,490 --> 00:17:44,940
hardware token that they generate

434
00:17:44,940 --> 00:17:47,049
brute-forcing this hardware token won't

435
00:17:47,049 --> 00:17:49,419
really work it's a bit too long it's a

436
00:17:49,419 --> 00:17:52,630
bit too complex to do guesswork we tried

437
00:17:52,630 --> 00:17:56,919
an empty one didn't really work but

438
00:17:56,919 --> 00:17:59,200
there is our old trusty friend the

439
00:17:59,200 --> 00:18:01,419
sequel injection in that case we had to

440
00:18:01,419 --> 00:18:02,890
be a bit more creative because the

441
00:18:02,890 --> 00:18:04,720
server back-end can only deal with one

442
00:18:04,720 --> 00:18:06,429
record at a time doesn't matter just set

443
00:18:06,429 --> 00:18:10,210
a limit and do a simple command on bash

444
00:18:10,210 --> 00:18:11,919
that's really not man metric to it and

445
00:18:11,919 --> 00:18:14,080
what you get is plaintext usernames and

446
00:18:14,080 --> 00:18:16,720
plaintext passwords and of course since

447
00:18:16,720 --> 00:18:18,340
we don't want a single one but we want

448
00:18:18,340 --> 00:18:20,350
more we can just iterate over it by

449
00:18:20,350 --> 00:18:22,960
gradually increasing the offset now

450
00:18:22,960 --> 00:18:25,270
since we're researchers we're whiteheads

451
00:18:25,270 --> 00:18:27,250
we don't want to just dump credential

452
00:18:27,250 --> 00:18:29,289
databases our goal is to find out how

453
00:18:29,289 --> 00:18:31,870
big the problem is so what we did is we

454
00:18:31,870 --> 00:18:35,169
just wanted to know how how many records

455
00:18:35,169 --> 00:18:37,750
there are and the service stopped

456
00:18:37,750 --> 00:18:39,820
responding at about 1.7 million of

457
00:18:39,820 --> 00:18:42,610
course if you're a bad guy you could

458
00:18:42,610 --> 00:18:44,620
also try to take these passwords and

459
00:18:44,620 --> 00:18:46,630
login to the Associated email accounts

460
00:18:46,630 --> 00:18:48,760
for example or see whether you can get

461
00:18:48,760 --> 00:18:50,470
into Facebook accounts or whatnot

462
00:18:50,470 --> 00:18:52,210
because people are known to reuse

463
00:18:52,210 --> 00:18:54,789
passwords all over the place right so

464
00:18:54,789 --> 00:18:56,950
this is a this is a leak that has

465
00:18:56,950 --> 00:18:59,169
consequences way beyond these tracker

466
00:18:59,169 --> 00:19:04,390
apps okay now moving on to a first place

467
00:19:04,390 --> 00:19:06,220
of the vulnerability awards and this is

468
00:19:06,220 --> 00:19:09,010
really something I I like would be the

469
00:19:09,010 --> 00:19:11,380
wrong word anyway they earned their

470
00:19:11,380 --> 00:19:14,200
first place now for those of you who are

471
00:19:14,200 --> 00:19:16,480
not familiar with Google firebase for

472
00:19:16,480 --> 00:19:19,950
the sake of our talk it's just another

473
00:19:19,950 --> 00:19:23,470
web-based database it has some other

474
00:19:23,470 --> 00:19:25,260
features but that's not important here

475
00:19:25,260 --> 00:19:27,700
so this app to give you some background

476
00:19:27,700 --> 00:19:30,909
if it first asks me for my username then

477
00:19:30,909 --> 00:19:33,400
I click on next and it says hi Steven

478
00:19:33,400 --> 00:19:35,710
and then I enter my password which means

479
00:19:35,710 --> 00:19:37,299
that it knows that I'm Steven even

480
00:19:37,299 --> 00:19:39,280
before I've entered my password so we

481
00:19:39,280 --> 00:19:41,380
ask ourselves what's going on here when

482
00:19:41,380 --> 00:19:43,270
you enter a username I click on next

483
00:19:43,270 --> 00:19:45,039
the app sends this request through the

484
00:19:45,039 --> 00:19:47,320
apps back-end server and the server

485
00:19:47,320 --> 00:19:50,620
replies with a user ID so it gives us an

486
00:19:50,620 --> 00:19:52,600
association between user

487
00:19:52,600 --> 00:19:56,140
email and user ID and this is the

488
00:19:56,140 --> 00:19:59,050
response with that ID it then connects

489
00:19:59,050 --> 00:20:02,230
to the Google firebase and already gets

490
00:20:02,230 --> 00:20:04,240
access to the data so there is no

491
00:20:04,240 --> 00:20:06,910
password involved yet it just accesses

492
00:20:06,910 --> 00:20:10,180
the firebase this is public data it just

493
00:20:10,180 --> 00:20:13,150
thought creates the correct URL and gets

494
00:20:13,150 --> 00:20:16,420
back my location data and it also gets

495
00:20:16,420 --> 00:20:18,190
back my user record including of course

496
00:20:18,190 --> 00:20:21,250
plaintext passwords so what we have is

497
00:20:21,250 --> 00:20:23,200
the app takes my email address

498
00:20:23,200 --> 00:20:26,170
translates it into a user ID and uses

499
00:20:26,170 --> 00:20:28,570
that to download my password why on

500
00:20:28,570 --> 00:20:30,850
earth should you do that the answer is

501
00:20:30,850 --> 00:20:33,220
in the app code so what these guys did

502
00:20:33,220 --> 00:20:35,740
is the app obtains my correct password

503
00:20:35,740 --> 00:20:38,590
lets me type in my password and else is

504
00:20:38,590 --> 00:20:40,930
string comparison and then tells me yep

505
00:20:40,930 --> 00:20:43,150
this is correct or not the password

506
00:20:43,150 --> 00:20:45,910
check is inside the app the server

507
00:20:45,910 --> 00:20:49,240
doesn't even care it's just the app that

508
00:20:49,240 --> 00:20:50,860
does is string comparison and then

509
00:20:50,860 --> 00:20:56,860
refuses to go on ok so what happens

510
00:20:56,860 --> 00:20:59,470
since this is public anyway you can you

511
00:20:59,470 --> 00:21:01,150
just need to put in your valid ID and

512
00:21:01,150 --> 00:21:03,130
download the data what happens if you

513
00:21:03,130 --> 00:21:07,960
put no idea oops we're back with the

514
00:21:07,960 --> 00:21:10,300
database dump and this is not only

515
00:21:10,300 --> 00:21:12,250
location data this is also the user

516
00:21:12,250 --> 00:21:15,370
credentials so in the end all the all

517
00:21:15,370 --> 00:21:19,680
the plaintext stuff yeah happens

518
00:21:19,680 --> 00:21:22,780
okay now very quickly concerning side

519
00:21:22,780 --> 00:21:24,220
loading malware while we were looking

520
00:21:24,220 --> 00:21:30,370
for our benign but vulnerable apps will

521
00:21:30,370 --> 00:21:32,560
also encounter two pieces of Melbourne

522
00:21:32,560 --> 00:21:35,140
these are the two what is interesting

523
00:21:35,140 --> 00:21:37,150
here is that these two are not the

524
00:21:37,150 --> 00:21:39,220
actual Melbourne they are downloaders

525
00:21:39,220 --> 00:21:42,100
for Melbourne which means when you stop

526
00:21:42,100 --> 00:21:44,500
this app this app will first perform an

527
00:21:44,500 --> 00:21:46,720
anti dynamic analysis check I'll show

528
00:21:46,720 --> 00:21:47,620
that in a second

529
00:21:47,620 --> 00:21:49,870
it will then extract some device

530
00:21:49,870 --> 00:21:52,420
information like your I my your model

531
00:21:52,420 --> 00:21:54,610
brand and so on we'll send it to a

532
00:21:54,610 --> 00:21:56,890
server and the server will decide

533
00:21:56,890 --> 00:21:59,080
whether melba should be installed or not

534
00:21:59,080 --> 00:22:01,660
if the server says no the app will just

535
00:22:01,660 --> 00:22:03,940
display a random error message we stop

536
00:22:03,940 --> 00:22:06,220
if the server says yes the

537
00:22:06,220 --> 00:22:08,559
pull download an apk file and use the

538
00:22:08,559 --> 00:22:11,140
social engineering to coerce me into

539
00:22:11,140 --> 00:22:13,720
clicking on install when the operating

540
00:22:13,720 --> 00:22:15,070
system dialog comes up for that

541
00:22:15,070 --> 00:22:18,700
secondary apk to not get caught these

542
00:22:18,700 --> 00:22:20,289
downloaders were in the Google Play

543
00:22:20,289 --> 00:22:22,600
Store they used a string of possession

544
00:22:22,600 --> 00:22:25,150
the first example they just translated

545
00:22:25,150 --> 00:22:27,510
their strings to ASCII characters

546
00:22:27,510 --> 00:22:29,799
represented them as hex numbers and that

547
00:22:29,799 --> 00:22:33,100
was kind of their strings and for anti

548
00:22:33,100 --> 00:22:35,610
dynamic analysis they use the capture

549
00:22:35,610 --> 00:22:38,470
the second piece of malware there was a

550
00:22:38,470 --> 00:22:41,169
bit more elaborated they used AAS with

551
00:22:41,169 --> 00:22:42,789
our hard-coded key and a hard-coded

552
00:22:42,789 --> 00:22:45,730
initialization vector and this was not

553
00:22:45,730 --> 00:22:47,740
only used for obfuscating static strings

554
00:22:47,740 --> 00:22:49,990
like URLs this was also used to

555
00:22:49,990 --> 00:22:51,850
obfuscate the network traffic with this

556
00:22:51,850 --> 00:22:54,490
command control server so my i'ma that

557
00:22:54,490 --> 00:22:58,510
was transferred or the the name of the

558
00:22:58,510 --> 00:23:01,299
device Brown this was also encoded with

559
00:23:01,299 --> 00:23:04,750
this static a s key for NG dynamic

560
00:23:04,750 --> 00:23:07,659
analysis it was just a button click so

561
00:23:07,659 --> 00:23:12,090
there was nothing fancy here okay and

562
00:23:12,090 --> 00:23:14,380
those were the vulnerabilities let me

563
00:23:14,380 --> 00:23:16,539
just quickly go over our responsible

564
00:23:16,539 --> 00:23:19,480
disclosure process we informed the

565
00:23:19,480 --> 00:23:22,059
members we gave them 90 days to fix the

566
00:23:22,059 --> 00:23:24,280
box at least 90 days this whole thing

567
00:23:24,280 --> 00:23:27,100
took took quite a Lamoille reactions

568
00:23:27,100 --> 00:23:27,820
were interesting

569
00:23:27,820 --> 00:23:30,039
some people said ok we'll fix it which

570
00:23:30,039 --> 00:23:32,169
is good some people didn't bother to

571
00:23:32,169 --> 00:23:34,720
reply I mean why should you care about

572
00:23:34,720 --> 00:23:37,390
having all your data in public there was

573
00:23:37,390 --> 00:23:38,679
even one guy who thought we were

574
00:23:38,679 --> 00:23:40,270
blackmailing him and he said how much

575
00:23:40,270 --> 00:23:42,520
money do you want so the problem is when

576
00:23:42,520 --> 00:23:44,830
you're applied when you're employed at a

577
00:23:44,830 --> 00:23:47,260
federal research institution in Germany

578
00:23:47,260 --> 00:23:48,640
you're not allowed to blackmail people

579
00:23:48,640 --> 00:23:51,750
so you can't earn money from that and

580
00:23:51,750 --> 00:23:54,250
that was even one dude who said it's not

581
00:23:54,250 --> 00:23:59,220
a it's not a bug it's a feature yeah ok

582
00:23:59,220 --> 00:24:01,600
we also had a nice chat with the US

583
00:24:01,600 --> 00:24:02,980
Federal Trade Commission that were very

584
00:24:02,980 --> 00:24:05,230
interested in our findings and with the

585
00:24:05,230 --> 00:24:07,120
Google app security initiative I think

586
00:24:07,120 --> 00:24:08,980
some people from Google or even here in

587
00:24:08,980 --> 00:24:12,340
the room and some apps were moved from

588
00:24:12,340 --> 00:24:14,380
the Play Store this is all nice however

589
00:24:14,380 --> 00:24:15,820
if you remove the app from the Play

590
00:24:15,820 --> 00:24:17,710
Store and you're vulnerable back-end is

591
00:24:17,710 --> 00:24:18,830
still out there it

592
00:24:18,830 --> 00:24:20,480
method that no one is accessing the back

593
00:24:20,480 --> 00:24:22,940
and legitimately anymore if if the back

594
00:24:22,940 --> 00:24:24,080
end is still giving out all the

595
00:24:24,080 --> 00:24:25,909
credentials for free and all the

596
00:24:25,909 --> 00:24:27,710
location data you didn't really solve

597
00:24:27,710 --> 00:24:32,990
the problem by pulling the app so to sum

598
00:24:32,990 --> 00:24:34,850
this up in case you want to create a

599
00:24:34,850 --> 00:24:37,370
known benign tracker app I mean

600
00:24:37,370 --> 00:24:39,799
everybody wants to write don't use plain

601
00:24:39,799 --> 00:24:42,559
text communications use some things such

602
00:24:42,559 --> 00:24:46,519
as HTTP and if you want to secure your

603
00:24:46,519 --> 00:24:47,929
app also make sure that you secure your

604
00:24:47,929 --> 00:24:49,610
back end because else the the whole

605
00:24:49,610 --> 00:24:52,730
effort is kind of wasted don't store any

606
00:24:52,730 --> 00:24:54,769
kind of sensitive data inside the app

607
00:24:54,769 --> 00:24:57,590
and also if you want to use a special

608
00:24:57,590 --> 00:24:59,750
features such as licensing checks

609
00:24:59,750 --> 00:25:02,720
payments or even trivial things like

610
00:25:02,720 --> 00:25:04,850
authentication or authorization use the

611
00:25:04,850 --> 00:25:06,830
API so that the operating system or some

612
00:25:06,830 --> 00:25:08,659
libraries have to offer

613
00:25:08,659 --> 00:25:10,730
don't try to to bake it on your own

614
00:25:10,730 --> 00:25:13,130
because that usually fails and gives you

615
00:25:13,130 --> 00:25:17,409
loft at conferences like Loras politan a

616
00:25:17,529 --> 00:25:20,059
table with all our findings the most

617
00:25:20,059 --> 00:25:23,299
important column is the right one so for

618
00:25:23,299 --> 00:25:25,549
almost all apps we had access to all the

619
00:25:25,549 --> 00:25:27,529
data that there was in the backend and

620
00:25:27,529 --> 00:25:31,070
and this is kind of the bad story about

621
00:25:31,070 --> 00:25:33,559
it because there was almost no app that

622
00:25:33,559 --> 00:25:36,860
was done at least properly enough to not

623
00:25:36,860 --> 00:25:40,519
give us all the data there is also the

624
00:25:40,519 --> 00:25:42,169
URL at the bottom it will also be at our

625
00:25:42,169 --> 00:25:44,570
summary slide in the very end where you

626
00:25:44,570 --> 00:25:46,850
can find the the reports the write-ups

627
00:25:46,850 --> 00:25:48,230
for the project and all the

628
00:25:48,230 --> 00:25:49,909
vulnerabilities we discovered including

629
00:25:49,909 --> 00:25:51,440
those that we could not fit into this

630
00:25:51,440 --> 00:25:55,039
talk due to time constraints yeah as I

631
00:25:55,039 --> 00:25:56,990
already said again the the URL with all

632
00:25:56,990 --> 00:26:00,549
the vulnerability write-ups and our

633
00:26:00,549 --> 00:26:02,809
contacts in case you want to get in

634
00:26:02,809 --> 00:26:04,789
touch with us after the conference will

635
00:26:04,789 --> 00:26:06,919
also be around at the conference and I

636
00:26:06,919 --> 00:26:10,690
think we we have time for

