1
00:00:00,060 --> 00:00:05,399
hey thanks for having me here today I'm

2
00:00:02,550 --> 00:00:07,680
really excited and you started seeing

3
00:00:05,400 --> 00:00:10,170
this this title up here and you're like

4
00:00:07,680 --> 00:00:14,670
oh cool like BuzzFeed has now written a

5
00:00:10,170 --> 00:00:15,929
presentation that's great and but but in

6
00:00:14,670 --> 00:00:18,119
seriousness this is kind of ended this

7
00:00:15,929 --> 00:00:19,650
has been a journey for me this this talk

8
00:00:18,119 --> 00:00:21,359
and I've been thinking like what does it

9
00:00:19,650 --> 00:00:23,279
make what what does it mean to be

10
00:00:21,359 --> 00:00:25,769
effective at doing dev SEC ops what is

11
00:00:23,279 --> 00:00:27,448
that what does that look like and then

12
00:00:25,769 --> 00:00:29,189
in here I a little bit later I introduce

13
00:00:27,449 --> 00:00:33,270
what I think is a framework that we can

14
00:00:29,189 --> 00:00:34,920
use that might be helpful for it so yeah

15
00:00:33,270 --> 00:00:38,730
so here here's me

16
00:00:34,920 --> 00:00:40,200
yeah I'm now over at Baraka and I have

17
00:00:38,730 --> 00:00:41,489
been in signal Sciences for the last

18
00:00:40,200 --> 00:00:43,350
five years and it's been really really

19
00:00:41,489 --> 00:00:45,839
great over there I have some courses on

20
00:00:43,350 --> 00:00:47,399
LinkedIn learning and I live in Austin

21
00:00:45,840 --> 00:00:49,050
Texas and I help with several the

22
00:00:47,399 --> 00:00:50,610
conference's down there in Austin and

23
00:00:49,050 --> 00:00:53,099
then I have a request at the end of the

24
00:00:50,610 --> 00:00:54,480
whole talk and it's gonna be for help

25
00:00:53,100 --> 00:00:56,250
we're working on the Deaf's a cop's

26
00:00:54,480 --> 00:00:58,858
handbook right now with the IT

27
00:00:56,250 --> 00:01:00,719
revolution over there with Jean Kim and

28
00:00:58,859 --> 00:01:04,199
I'd love to hear your stories about deaf

29
00:01:00,719 --> 00:01:06,090
sex devstack cops successes failures any

30
00:01:04,199 --> 00:01:08,520
of that any of that kind of stuff so and

31
00:01:06,090 --> 00:01:10,229
oh I'm actually really good at this this

32
00:01:08,520 --> 00:01:12,869
is I don't even see the subtitle but it

33
00:01:10,229 --> 00:01:15,210
says paying 1,500 hours to browse

34
00:01:12,869 --> 00:01:17,280
Twitter and hang out on slack and so I

35
00:01:15,210 --> 00:01:19,408
like the in-depth part too but but I

36
00:01:17,280 --> 00:01:21,030
actually specialize in this skill so if

37
00:01:19,409 --> 00:01:22,409
you want to skip straight to the slides

38
00:01:21,030 --> 00:01:24,150
and be able to have a copy of them

39
00:01:22,409 --> 00:01:26,220
because I have some links in here you

40
00:01:24,150 --> 00:01:27,509
can go to this bitly if you want to take

41
00:01:26,220 --> 00:01:29,009
a picture of it you can grab that real

42
00:01:27,509 --> 00:01:31,950
quick and I'll have this up at the end

43
00:01:29,009 --> 00:01:36,869
as well but you can get those get the

44
00:01:31,950 --> 00:01:38,670
slides right now alright and okay and

45
00:01:36,869 --> 00:01:40,530
one thing on Varick s so the place where

46
00:01:38,670 --> 00:01:42,960
I'm going I'm actually don't work there

47
00:01:40,530 --> 00:01:45,540
just yet but will here in a couple weeks

48
00:01:42,960 --> 00:01:47,369
but we're an enterprise platform that's

49
00:01:45,540 --> 00:01:49,350
a complete startup working on continuous

50
00:01:47,369 --> 00:01:50,939
verification taking a lot of the chaos

51
00:01:49,350 --> 00:01:53,100
engineering principles and applying that

52
00:01:50,939 --> 00:01:53,729
to see how we can make the world a

53
00:01:53,100 --> 00:01:55,589
better place

54
00:01:53,729 --> 00:01:58,500
okay so I think we should start out with

55
00:01:55,590 --> 00:02:00,149
dev sac ops and what does that mean what

56
00:01:58,500 --> 00:02:02,100
do we what do you think it means and I

57
00:02:00,149 --> 00:02:04,469
like the I think the best way to get

58
00:02:02,100 --> 00:02:06,630
started with that is to look at do some

59
00:02:04,469 --> 00:02:09,209
dev sec ops deep thoughts and so if

60
00:02:06,630 --> 00:02:11,220
you're familiar with Jack Handey this

61
00:02:09,209 --> 00:02:13,670
will be funny if not this will be weird

62
00:02:11,220 --> 00:02:13,670
so

63
00:02:13,700 --> 00:02:19,099
maybe in order to understand dev sack

64
00:02:16,440 --> 00:02:21,959
ops we have to look at the word itself

65
00:02:19,099 --> 00:02:31,140
basically it's made up of these three

66
00:02:21,959 --> 00:02:33,750
separate words de vie Seco and what do

67
00:02:31,140 --> 00:02:40,890
these words mean it's a mystery and

68
00:02:33,750 --> 00:02:42,810
that's why so is dev sec ops so okay but

69
00:02:40,890 --> 00:02:45,059
that leaves us to like okay what is it

70
00:02:42,810 --> 00:02:47,430
that's really that's it's it's a good

71
00:02:45,060 --> 00:02:49,200
Jack Handey idea but and and then why

72
00:02:47,430 --> 00:02:50,940
like why are we why are we talking about

73
00:02:49,200 --> 00:02:53,579
dev sec ops why is this a thing why is

74
00:02:50,940 --> 00:02:55,440
this important and I think we could

75
00:02:53,580 --> 00:02:59,220
first take a step back and we'll take a

76
00:02:55,440 --> 00:03:00,720
quick look at what is DevOps and you

77
00:02:59,220 --> 00:03:03,900
might feel like oh this is gonna be real

78
00:03:00,720 --> 00:03:07,709
special and I hope it is for you we can

79
00:03:03,900 --> 00:03:09,630
start and look at at the cloud right we

80
00:03:07,709 --> 00:03:12,299
start a decade ago take you taking a

81
00:03:09,630 --> 00:03:14,700
look at that and then we have this this

82
00:03:12,299 --> 00:03:17,220
idea of data and we liked it really big

83
00:03:14,700 --> 00:03:19,798
and we thought that's gonna be great and

84
00:03:17,220 --> 00:03:22,590
we have this new OSI model which I

85
00:03:19,799 --> 00:03:27,060
really appreciate because the the old

86
00:03:22,590 --> 00:03:29,280
one yeah yeah it's it was always hard

87
00:03:27,060 --> 00:03:31,560
right there's like which layer I don't

88
00:03:29,280 --> 00:03:34,920
know so this is much easier so I really

89
00:03:31,560 --> 00:03:37,130
appreciate that part of this and where

90
00:03:34,920 --> 00:03:41,070
are we going really like we see that

91
00:03:37,130 --> 00:03:44,730
over the years last 15 years we've moved

92
00:03:41,070 --> 00:03:46,440
from taking hardware to the cloud and

93
00:03:44,730 --> 00:03:48,119
the VMS and then now kind of moving in

94
00:03:46,440 --> 00:03:51,000
the surrealist space we're eliminating

95
00:03:48,120 --> 00:03:52,680
the waste that we often deal with and

96
00:03:51,000 --> 00:03:54,390
we're really concentrating on the value

97
00:03:52,680 --> 00:03:56,730
and we're isolating that and building

98
00:03:54,390 --> 00:03:59,339
that forward and we're able to utilize

99
00:03:56,730 --> 00:04:00,690
that more so why did I get why did I

100
00:03:59,340 --> 00:04:01,769
start talking about all this I said here

101
00:04:00,690 --> 00:04:03,450
we're gonna talk about DevOps and then I

102
00:04:01,769 --> 00:04:05,910
started talking about the cloud and big

103
00:04:03,450 --> 00:04:08,010
data and all that stuff and I think part

104
00:04:05,910 --> 00:04:10,700
of it is as we kind of move progression

105
00:04:08,010 --> 00:04:12,750
on that that graph is that we saw

106
00:04:10,700 --> 00:04:14,069
developers sort of took that

107
00:04:12,750 --> 00:04:15,900
internalised and said yeah okay we're

108
00:04:14,069 --> 00:04:18,180
now we're gonna get ops for free and

109
00:04:15,900 --> 00:04:19,470
security right because you know Amazon

110
00:04:18,180 --> 00:04:20,640
or Google or whoever they're gonna

111
00:04:19,470 --> 00:04:22,419
they're gonna manage that and that

112
00:04:20,640 --> 00:04:24,099
problem just sort of goes away

113
00:04:22,419 --> 00:04:26,710
and it is true that DevOps grew

114
00:04:24,099 --> 00:04:28,030
hand-in-hand with the cloud and there

115
00:04:26,710 --> 00:04:30,460
was a there was a thought that okay

116
00:04:28,030 --> 00:04:33,008
DevOps is this inevitable force that's

117
00:04:30,460 --> 00:04:34,979
going to happen instead of managing you

118
00:04:33,009 --> 00:04:36,819
know tens or hundreds of servers

119
00:04:34,979 --> 00:04:38,409
operations folks now had to manage

120
00:04:36,819 --> 00:04:41,139
thousands of servers and so therefore

121
00:04:38,409 --> 00:04:42,699
like a new model a new paradigm had to

122
00:04:41,139 --> 00:04:44,889
had to come forth and this is exactly

123
00:04:42,699 --> 00:04:46,659
what Tom Lehman Shelley says he says

124
00:04:44,889 --> 00:04:48,460
that DevOps is an inevitable result of

125
00:04:46,659 --> 00:04:49,779
needing to do efficient operations in a

126
00:04:48,460 --> 00:04:53,498
distributed computing and cloud

127
00:04:49,779 --> 00:04:55,840
environment I always like to say that it

128
00:04:53,499 --> 00:04:57,729
was this an epistemological breakthrough

129
00:04:55,840 --> 00:05:00,128
that you joined separate groups separate

130
00:04:57,729 --> 00:05:01,568
people and these separate silos around a

131
00:05:00,129 --> 00:05:05,469
common problem and they're able to

132
00:05:01,569 --> 00:05:07,150
deliver software together and and I felt

133
00:05:05,469 --> 00:05:09,699
we also we also thought about it in

134
00:05:07,150 --> 00:05:11,378
another way we also thought well DevOps

135
00:05:09,699 --> 00:05:13,629
we have this an equitable an equitable

136
00:05:11,379 --> 00:05:16,360
distribution of labor and the problem is

137
00:05:13,629 --> 00:05:19,120
sits where we have 10 developers for

138
00:05:16,360 --> 00:05:21,069
every one operations person and and that

139
00:05:19,120 --> 00:05:22,539
was kind of creating this natural silo

140
00:05:21,069 --> 00:05:25,389
through the organizational structures

141
00:05:22,539 --> 00:05:27,729
that existed and Damon Edwards who's one

142
00:05:25,389 --> 00:05:29,439
of the original guys who was in on on

143
00:05:27,729 --> 00:05:33,539
starting DevOps in the in the beginning

144
00:05:29,439 --> 00:05:35,919
and runs the DevOps Cafe podcast he says

145
00:05:33,539 --> 00:05:38,409
DevOps is not a technological problem

146
00:05:35,919 --> 00:05:39,430
but DevOps is a business problem and I

147
00:05:38,409 --> 00:05:41,620
agree with it and there's another

148
00:05:39,430 --> 00:05:43,330
there's another view as well you can

149
00:05:41,620 --> 00:05:44,680
look at it if you're coming from like a

150
00:05:43,330 --> 00:05:47,050
developer point of view you could just

151
00:05:44,680 --> 00:05:49,270
see DevOps was like another stop along

152
00:05:47,050 --> 00:05:51,219
the way from agile journey to dominance

153
00:05:49,270 --> 00:05:55,419
in the organization and the enterprise

154
00:05:51,219 --> 00:05:57,219
and that's not a far-off viewpoint even

155
00:05:55,419 --> 00:05:58,539
the practice of cloud system

156
00:05:57,219 --> 00:06:00,490
administration book which is a really

157
00:05:58,539 --> 00:06:02,649
great book and I totally recommend it

158
00:06:00,490 --> 00:06:04,599
says DevOps is the application the

159
00:06:02,649 --> 00:06:07,120
application of agile methodology to

160
00:06:04,599 --> 00:06:09,580
system administration and so ok that's

161
00:06:07,120 --> 00:06:12,219
fine for DevOps and now we we see like

162
00:06:09,580 --> 00:06:13,449
how that came about but still that

163
00:06:12,219 --> 00:06:15,639
leaves us with a question of like why

164
00:06:13,449 --> 00:06:17,710
dev stock ops and I asked this question

165
00:06:15,639 --> 00:06:21,219
myself and I was I was worried about

166
00:06:17,710 --> 00:06:22,659
this this myself like philosophically

167
00:06:21,219 --> 00:06:24,430
existentially is this the right approach

168
00:06:22,659 --> 00:06:27,969
that we should do and you start looking

169
00:06:24,430 --> 00:06:30,610
at things like dev QA SEC data gov and

170
00:06:27,969 --> 00:06:32,409
more ops right and and we start asking

171
00:06:30,610 --> 00:06:33,279
like where does this end can we just

172
00:06:32,409 --> 00:06:34,810
leave DevOps

173
00:06:33,279 --> 00:06:35,670
good enough alone and just say like that

174
00:06:34,810 --> 00:06:38,190
is you know

175
00:06:35,670 --> 00:06:39,690
and in from building to runtime and and

176
00:06:38,190 --> 00:06:44,880
all these other things are gonna fit in

177
00:06:39,690 --> 00:06:46,890
there which i think is fair but I think

178
00:06:44,880 --> 00:06:49,409
the key is we start seeing that security

179
00:06:46,890 --> 00:06:50,940
needed something different and whether

180
00:06:49,410 --> 00:06:52,050
it's a subset of DevOps or how we think

181
00:06:50,940 --> 00:06:54,450
about it

182
00:06:52,050 --> 00:06:56,100
the security finds itself in the same

183
00:06:54,450 --> 00:06:58,560
position that operations did whenever

184
00:06:56,100 --> 00:07:01,950
DevOps first arose in the very beginning

185
00:06:58,560 --> 00:07:04,560
so we have a hundred developers to ten

186
00:07:01,950 --> 00:07:07,890
operations people to one security person

187
00:07:04,560 --> 00:07:13,970
so natural silo ization across how this

188
00:07:07,890 --> 00:07:13,969
is a set up in many organizations and

189
00:07:14,750 --> 00:07:20,940
see silo ization it I like to make up

190
00:07:18,180 --> 00:07:23,400
words this I apologize for that

191
00:07:20,940 --> 00:07:25,620
and security like ops struggles to

192
00:07:23,400 --> 00:07:28,710
provide value in many organizations and

193
00:07:25,620 --> 00:07:32,700
I see that is a core problem that

194
00:07:28,710 --> 00:07:34,260
security faces well let's look at this

195
00:07:32,700 --> 00:07:36,180
quote from Steve blogan I got a couple

196
00:07:34,260 --> 00:07:38,310
quotes from some security authors that I

197
00:07:36,180 --> 00:07:40,050
think might be helpful for us and kind

198
00:07:38,310 --> 00:07:41,670
of illustrate the point here but

199
00:07:40,050 --> 00:07:43,860
companies are spending a great deal on

200
00:07:41,670 --> 00:07:45,720
security but we read of these massive

201
00:07:43,860 --> 00:07:47,640
computer related attacks and clearly

202
00:07:45,720 --> 00:07:49,200
something is wrong the root of the

203
00:07:47,640 --> 00:07:50,669
problem is twofold we're protecting the

204
00:07:49,200 --> 00:07:52,770
wrong things and we're hurting

205
00:07:50,670 --> 00:07:55,620
productivity in the process does that

206
00:07:52,770 --> 00:07:57,450
resonate with anybody yeah and that

207
00:07:55,620 --> 00:07:58,770
that's a that's a particularly damning

208
00:07:57,450 --> 00:08:00,659
statement right because it's coming from

209
00:07:58,770 --> 00:08:02,099
inside of security we're saying like hey

210
00:08:00,660 --> 00:08:04,650
like the breaches haven't stopped

211
00:08:02,100 --> 00:08:06,060
they've gotten worse and like people see

212
00:08:04,650 --> 00:08:08,250
us as the people that always slow things

213
00:08:06,060 --> 00:08:09,990
down and make a big mess at the mess of

214
00:08:08,250 --> 00:08:11,340
stuff and that's not a great place to

215
00:08:09,990 --> 00:08:12,810
live and that's not that's not a fun

216
00:08:11,340 --> 00:08:15,510
place to live and it's very similar to

217
00:08:12,810 --> 00:08:16,710
where Ops was a decade ago where the

218
00:08:15,510 --> 00:08:18,300
developers like we're trying to do this

219
00:08:16,710 --> 00:08:20,370
agile thing but like you guys aren't

220
00:08:18,300 --> 00:08:21,810
letting us because you know you you want

221
00:08:20,370 --> 00:08:24,690
to do like quarterly releases and stuff

222
00:08:21,810 --> 00:08:27,660
like that another one is this book by

223
00:08:24,690 --> 00:08:30,060
Michael Zalewski and it says security by

224
00:08:27,660 --> 00:08:32,100
risk assessment introduces a dangerous

225
00:08:30,060 --> 00:08:33,720
fallacy that structured inadequacy is

226
00:08:32,100 --> 00:08:36,420
almost as good as adequacy and that

227
00:08:33,720 --> 00:08:38,610
underfunded security effort underfunded

228
00:08:36,419 --> 00:08:40,530
security effort plus risk management are

229
00:08:38,610 --> 00:08:42,479
about as good as properly funded

230
00:08:40,530 --> 00:08:46,230
security work does that bother anybody

231
00:08:42,479 --> 00:08:48,510
in here yeah it should right and we're

232
00:08:46,230 --> 00:08:49,270
like okay like I want to do engineering

233
00:08:48,510 --> 00:08:51,880
but

234
00:08:49,270 --> 00:08:54,339
and in this book the first first couple

235
00:08:51,880 --> 00:08:56,890
chapters is kind of the the progress of

236
00:08:54,339 --> 00:08:59,080
security over the last few decades and

237
00:08:56,890 --> 00:09:01,000
how we kind of abandon engineering and

238
00:08:59,080 --> 00:09:03,550
in the 90s kind of went to this risk

239
00:09:01,000 --> 00:09:04,959
risk model and it's not not that that's

240
00:09:03,550 --> 00:09:06,250
completely wrong but like we've just

241
00:09:04,959 --> 00:09:07,930
sort of said like I'll accept the risk

242
00:09:06,250 --> 00:09:10,180
and do actuarial duties instead of

243
00:09:07,930 --> 00:09:13,870
actually building higher quality things

244
00:09:10,180 --> 00:09:15,040
I like and sometimes I actually should

245
00:09:13,870 --> 00:09:17,440
I'd like to show this slide out almost

246
00:09:15,040 --> 00:09:18,520
every presentation I get but I often ask

247
00:09:17,440 --> 00:09:19,450
the audience and it's like does that

248
00:09:18,520 --> 00:09:19,720
resonate with you or does that bother

249
00:09:19,450 --> 00:09:21,220
you

250
00:09:19,720 --> 00:09:22,990
and it really worries me when no one

251
00:09:21,220 --> 00:09:25,000
raises their hands and I'm like that's

252
00:09:22,990 --> 00:09:27,190
wrong audience wrong I need so I'm glad

253
00:09:25,000 --> 00:09:32,050
so we passed that test and I any we

254
00:09:27,190 --> 00:09:33,700
would write here okay so the sands 2018

255
00:09:32,050 --> 00:09:35,439
devstack ops survey says while

256
00:09:33,700 --> 00:09:37,180
engineering teams are busy deploying

257
00:09:35,440 --> 00:09:38,589
leading-edge technology security teams

258
00:09:37,180 --> 00:09:40,779
are still focused on fighting

259
00:09:38,589 --> 00:09:44,410
yesterday's battles does that resonate

260
00:09:40,779 --> 00:09:45,850
with us too right we feel that and we

261
00:09:44,410 --> 00:09:47,290
see that 95 percent of security

262
00:09:45,850 --> 00:09:49,750
professionals spend their time

263
00:09:47,290 --> 00:09:51,219
protecting legacy applications and this

264
00:09:49,750 --> 00:09:53,050
goes to the old axiom of like tech

265
00:09:51,220 --> 00:09:54,550
burden can only be transferred like you

266
00:09:53,050 --> 00:09:56,140
can't really destroy it it's it's only

267
00:09:54,550 --> 00:09:58,959
transferred and I feel like that's true

268
00:09:56,140 --> 00:10:00,819
with security where security burden is

269
00:09:58,959 --> 00:10:02,739
not created or destroyed it's merely

270
00:10:00,820 --> 00:10:04,660
transferred to other people and as

271
00:10:02,740 --> 00:10:07,329
things get get older like those those

272
00:10:04,660 --> 00:10:09,130
that that job sits over with the with

273
00:10:07,329 --> 00:10:11,160
security and then developers off doing

274
00:10:09,130 --> 00:10:13,540
like the newest cutting-edge things a

275
00:10:11,160 --> 00:10:16,480
friend of mine does some consulting work

276
00:10:13,540 --> 00:10:17,890
and he goes into places and and and will

277
00:10:16,480 --> 00:10:19,450
try to leave everybody nameless in this

278
00:10:17,890 --> 00:10:21,250
but a lot of times he'll work with folks

279
00:10:19,450 --> 00:10:22,779
that are doing kubernetes or service or

280
00:10:21,250 --> 00:10:24,010
whatever and he's like great great great

281
00:10:22,779 --> 00:10:25,450
how do you how do you get security

282
00:10:24,010 --> 00:10:28,180
involved and then he's like we do not

283
00:10:25,450 --> 00:10:29,950
tell them anything like thank you that

284
00:10:28,180 --> 00:10:31,660
that's you know and they're like big

285
00:10:29,950 --> 00:10:33,910
companies and you're like ok that's

286
00:10:31,660 --> 00:10:35,529
that's not a great strategy but they're

287
00:10:33,910 --> 00:10:36,670
always worried that like that that this

288
00:10:35,529 --> 00:10:40,630
sort of there's this divide that's

289
00:10:36,670 --> 00:10:43,479
continuing to happen and I think that

290
00:10:40,630 --> 00:10:45,010
it's helpful for us to look at like even

291
00:10:43,480 --> 00:10:47,230
on the agile application security book

292
00:10:45,010 --> 00:10:48,730
says many security teams work with a

293
00:10:47,230 --> 00:10:51,850
worldview where the goal is to inhibit

294
00:10:48,730 --> 00:10:55,029
change as much as possible and we see

295
00:10:51,850 --> 00:10:57,490
that across our industry so new

296
00:10:55,029 --> 00:10:58,990
technology increased organization

297
00:10:57,490 --> 00:11:00,220
focused on software delivery because

298
00:10:58,990 --> 00:11:02,089
everybody is talking about the the

299
00:11:00,220 --> 00:11:03,350
deploy cadence or how

300
00:11:02,089 --> 00:11:06,170
often frequently they're able to deliver

301
00:11:03,350 --> 00:11:08,240
I think that's why we needs dev SEC ops

302
00:11:06,170 --> 00:11:11,120
and so with that I'd like to look at

303
00:11:08,240 --> 00:11:14,029
what is a dev SEC op well what it what

304
00:11:11,120 --> 00:11:15,860
makes someone who is doing a DEP SEC ops

305
00:11:14,029 --> 00:11:17,569
what makes them successful what's

306
00:11:15,860 --> 00:11:19,550
helpful for them and it's good to

307
00:11:17,569 --> 00:11:21,680
realize first it's not a tool it's not a

308
00:11:19,550 --> 00:11:23,839
CI CD pipeline that you can put security

309
00:11:21,680 --> 00:11:25,638
in it can't be bought on an expo floor

310
00:11:23,839 --> 00:11:28,999
except probably at this expo floor I

311
00:11:25,639 --> 00:11:30,860
think it's probably care right but it's

312
00:11:28,999 --> 00:11:33,980
an inclusive person who's participating

313
00:11:30,860 --> 00:11:35,629
in a movement of putting security right

314
00:11:33,980 --> 00:11:37,370
in the middle of dev SEC ops which I

315
00:11:35,629 --> 00:11:39,139
think it's great I even like the

316
00:11:37,370 --> 00:11:41,089
placement of where this kind of landed

317
00:11:39,139 --> 00:11:43,399
in the end right security kind of sits

318
00:11:41,089 --> 00:11:45,319
there in the middle as a connector and

319
00:11:43,399 --> 00:11:47,480
so hopefully we'll see that as we kind

320
00:11:45,319 --> 00:11:49,279
of move through so the framework that

321
00:11:47,480 --> 00:11:51,889
I'd like to talk through that has the

322
00:11:49,279 --> 00:11:54,559
seven seven Habits is the measure

323
00:11:51,889 --> 00:11:55,730
framework so this is this is new and I'm

324
00:11:54,559 --> 00:11:57,259
just trying now for the first time so

325
00:11:55,730 --> 00:12:00,170
I'd love feedback if you guys think like

326
00:11:57,259 --> 00:12:03,860
measure is helpful or is missing stuff

327
00:12:00,170 --> 00:12:06,040
or maybe needs to be tweaked but the

328
00:12:03,860 --> 00:12:09,910
seven pieces are maker driven

329
00:12:06,040 --> 00:12:12,679
experimenting automating safety aware

330
00:12:09,910 --> 00:12:16,519
unrestrained sharing rugged izing and

331
00:12:12,679 --> 00:12:19,009
empathy first so let's move first into

332
00:12:16,519 --> 00:12:21,529
m4 maker driven so what do we mean when

333
00:12:19,009 --> 00:12:23,600
we talk about maker driven it's like

334
00:12:21,529 --> 00:12:24,949
people who actually own the idea that

335
00:12:23,600 --> 00:12:27,279
like we're software engineers first

336
00:12:24,949 --> 00:12:31,189
who's specialized in a discipline

337
00:12:27,279 --> 00:12:33,079
security right and I think we need to

338
00:12:31,189 --> 00:12:36,019
kind of adapt this security you must be

339
00:12:33,079 --> 00:12:37,370
able to write code and I see people on

340
00:12:36,019 --> 00:12:39,079
Twitter kind of debating this sometimes

341
00:12:37,370 --> 00:12:40,879
like oh you know you can do security at

342
00:12:39,079 --> 00:12:44,329
out writing code I think those days are

343
00:12:40,879 --> 00:12:45,980
passed and I'm actually concerned like

344
00:12:44,329 --> 00:12:47,870
why is this a hot take in our industry

345
00:12:45,980 --> 00:12:48,379
that like the security should be writing

346
00:12:47,870 --> 00:12:50,209
code

347
00:12:48,379 --> 00:12:52,189
this is a similar to where operations

348
00:12:50,209 --> 00:12:53,719
was like I don't need to do that I'm you

349
00:12:52,189 --> 00:12:56,300
know I just manage you know the Apache

350
00:12:53,720 --> 00:12:57,889
config and you know copy paste from wiki

351
00:12:56,300 --> 00:13:01,639
pages you know like a decade ago right

352
00:12:57,889 --> 00:13:03,290
so and I think it's security people it's

353
00:13:01,639 --> 00:13:04,879
not that you have to be developers first

354
00:13:03,290 --> 00:13:07,129
but be able to like speak the same

355
00:13:04,879 --> 00:13:08,179
language to developers build empathy and

356
00:13:07,129 --> 00:13:09,920
there's a lot of resources available

357
00:13:08,179 --> 00:13:11,779
today I mean two of my favorite

358
00:13:09,920 --> 00:13:14,170
developing the books are easily found

359
00:13:11,779 --> 00:13:14,170
here

360
00:13:15,399 --> 00:13:20,779
so and so I think that those are those

361
00:13:19,369 --> 00:13:22,639
are good resources but there's there's

362
00:13:20,779 --> 00:13:24,799
tons right like we know that like you

363
00:13:22,639 --> 00:13:26,569
can get get access to all this stuff I

364
00:13:24,799 --> 00:13:28,009
also think security has to adopt the

365
00:13:26,569 --> 00:13:30,319
maker mindset

366
00:13:28,009 --> 00:13:32,239
we're already using already using dsls

367
00:13:30,319 --> 00:13:35,709
we're already doing a lot of development

368
00:13:32,239 --> 00:13:38,269
type work and and so if even just like

369
00:13:35,709 --> 00:13:39,799
you know config for your pretty hair -

370
00:13:38,269 --> 00:13:40,040
laughs or other stuff like this I like

371
00:13:39,799 --> 00:13:42,379
this

372
00:13:40,040 --> 00:13:44,868
typing dots and slashes until things

373
00:13:42,379 --> 00:13:46,939
work right that's that's that's the

374
00:13:44,869 --> 00:13:49,459
that's the prayer they all we always

375
00:13:46,939 --> 00:13:51,049
hope but but I want to connect that in

376
00:13:49,459 --> 00:13:53,329
your mind if you is like security is

377
00:13:51,049 --> 00:13:55,549
already doing development work in any

378
00:13:53,329 --> 00:13:57,858
capacity even people that are that are

379
00:13:55,549 --> 00:13:59,449
kind of you know kind of managing the

380
00:13:57,859 --> 00:14:01,129
Laffer or whatever it is

381
00:13:59,449 --> 00:14:02,809
just like operations folks they were

382
00:14:01,129 --> 00:14:04,480
managing their their nginx and fig or

383
00:14:02,809 --> 00:14:06,559
their Apache config and thinking through

384
00:14:04,480 --> 00:14:08,029
you know okay now we're gonna do config

385
00:14:06,559 --> 00:14:09,108
management and chef and puppet we have a

386
00:14:08,029 --> 00:14:11,540
lot of these tools kind of a rise

387
00:14:09,109 --> 00:14:13,759
through that view point well I also like

388
00:14:11,540 --> 00:14:15,410
two of my friends Shannon leads over it

389
00:14:13,759 --> 00:14:17,149
into it Aaron Reinhard over a United

390
00:14:15,410 --> 00:14:19,160
Health Group care group they both said

391
00:14:17,149 --> 00:14:21,589
hey the entire security team must learn

392
00:14:19,160 --> 00:14:23,360
to code with the subtext of or you're

393
00:14:21,589 --> 00:14:26,540
fired but they tried not to say that cuz

394
00:14:23,360 --> 00:14:27,769
like that that makes people sad but they

395
00:14:26,540 --> 00:14:29,389
sort of said all right hey we're all

396
00:14:27,769 --> 00:14:31,399
gonna learn Python or whatever it is

397
00:14:29,389 --> 00:14:32,959
that you want to learn but you must do

398
00:14:31,399 --> 00:14:34,639
it and that was on everybody's like

399
00:14:32,959 --> 00:14:36,768
performance plans and these are kind of

400
00:14:34,639 --> 00:14:37,939
like large enterprise you know companies

401
00:14:36,769 --> 00:14:40,519
that you would you wouldn't expect that

402
00:14:37,939 --> 00:14:42,529
you would expect that it like a slack or

403
00:14:40,519 --> 00:14:47,029
some sort of like startup but but not

404
00:14:42,529 --> 00:14:48,290
like not one of these okay so but why is

405
00:14:47,029 --> 00:14:50,360
that why is that important well it

406
00:14:48,290 --> 00:14:52,969
builds empathy it provides familiarity

407
00:14:50,360 --> 00:14:54,709
with the tools has security people able

408
00:14:52,970 --> 00:14:57,439
to move into the pipeline and kind of

409
00:14:54,709 --> 00:14:59,179
experience that I know even when arrived

410
00:14:57,439 --> 00:15:00,529
like picked up service for their first

411
00:14:59,179 --> 00:15:02,089
time and I started just like trying to

412
00:15:00,529 --> 00:15:03,919
configure things and I had to like open

413
00:15:02,089 --> 00:15:05,569
up a bunch of like I am roles and

414
00:15:03,919 --> 00:15:07,339
permissions because I was like I just

415
00:15:05,569 --> 00:15:08,779
got to get this thing to work right but

416
00:15:07,339 --> 00:15:11,179
that that helps build empathy for you

417
00:15:08,779 --> 00:15:13,669
for you as a security person as we're

418
00:15:11,179 --> 00:15:15,499
dealing with developers like yeah I get

419
00:15:13,669 --> 00:15:17,119
that like when I write code I also do

420
00:15:15,499 --> 00:15:18,889
the same thing because I just want

421
00:15:17,119 --> 00:15:21,289
something to work and then and I try to

422
00:15:18,889 --> 00:15:22,730
go back and harden it later well another

423
00:15:21,289 --> 00:15:24,739
thing that I'd like to put it put as a

424
00:15:22,730 --> 00:15:26,660
premise here is a bug as a bug as a bug

425
00:15:24,739 --> 00:15:29,329
and we see that defect

426
00:15:26,660 --> 00:15:31,160
he studies range from 0.5 to 10 per

427
00:15:29,329 --> 00:15:33,019
thousand lines of code and the important

428
00:15:31,160 --> 00:15:33,740
part is not about those those studies

429
00:15:33,019 --> 00:15:36,050
which have been done over the last

430
00:15:33,740 --> 00:15:38,089
several decades but that defect density

431
00:15:36,050 --> 00:15:40,189
is never zero and so sometimes we think

432
00:15:38,089 --> 00:15:42,410
oh my application is just you know 100

433
00:15:40,190 --> 00:15:44,750
lines of code 200 lines of code

434
00:15:42,410 --> 00:15:47,060
there's a great example from from snick

435
00:15:44,750 --> 00:15:48,680
you write 222 lines of code that has

436
00:15:47,060 --> 00:15:50,300
five direct dependencies 54 total

437
00:15:48,680 --> 00:15:51,800
dependencies and I think for this crowd

438
00:15:50,300 --> 00:15:54,079
we probably know where this is going

439
00:15:51,800 --> 00:15:56,810
that's like ends up being 460 thousand

440
00:15:54,079 --> 00:15:58,939
lines of code and so then we get stuck

441
00:15:56,810 --> 00:16:00,619
just like resolving dependencies and and

442
00:15:58,939 --> 00:16:04,129
kind of dealing with with all those

443
00:16:00,620 --> 00:16:06,829
problems the the 2019 deficit cop survey

444
00:16:04,129 --> 00:16:10,519
showed that even companies so the blue

445
00:16:06,829 --> 00:16:12,319
is the the devops elite practices even

446
00:16:10,519 --> 00:16:14,930
the blue like they're there they're only

447
00:16:12,319 --> 00:16:16,160
have 38 percent lock down on their on

448
00:16:14,930 --> 00:16:18,439
the dependencies and how they're doing

449
00:16:16,160 --> 00:16:21,439
development so we have a lot of a lot of

450
00:16:18,439 --> 00:16:22,639
room to grow here also I'd like to put

451
00:16:21,439 --> 00:16:24,379
another premise out here is that you

452
00:16:22,639 --> 00:16:27,680
cannot train developers to write secure

453
00:16:24,379 --> 00:16:28,939
code so instead we focus on we need to

454
00:16:27,680 --> 00:16:31,339
instead focus on the methods that

455
00:16:28,939 --> 00:16:33,589
developers use because we don't train

456
00:16:31,339 --> 00:16:34,910
developers to write error free code and

457
00:16:33,589 --> 00:16:37,009
that's the same same thing whenever

458
00:16:34,910 --> 00:16:39,230
you're you're doing any other type of

459
00:16:37,009 --> 00:16:41,990
development so you focus on TDD BDD a

460
00:16:39,230 --> 00:16:44,509
TDD meaningful comments and commit

461
00:16:41,990 --> 00:16:47,000
messages the developers do teach on like

462
00:16:44,509 --> 00:16:48,259
code smells and refactoring and adding

463
00:16:47,000 --> 00:16:51,620
the right instrumentation in places

464
00:16:48,259 --> 00:16:52,970
where you can you can see the telemetry

465
00:16:51,620 --> 00:16:56,509
out of your application to let you know

466
00:16:52,970 --> 00:16:57,980
what's going on and this is a quote out

467
00:16:56,509 --> 00:16:59,269
of the agile application security book

468
00:16:57,980 --> 00:17:00,920
that says the goal should be to come up

469
00:16:59,269 --> 00:17:02,689
with a set of automated tests that probe

470
00:17:00,920 --> 00:17:04,699
and check security configurations and

471
00:17:02,689 --> 00:17:06,199
runtime system behavior there's security

472
00:17:04,699 --> 00:17:08,780
features that will execute every time

473
00:17:06,199 --> 00:17:11,059
the system is built and every time this

474
00:17:08,780 --> 00:17:12,349
every time it is deployed so we start

475
00:17:11,059 --> 00:17:14,209
connecting security in our minds with

476
00:17:12,349 --> 00:17:16,280
quality and that's something that

477
00:17:14,209 --> 00:17:19,730
happened in the dev SEC Ops community

478
00:17:16,280 --> 00:17:22,549
survey for 2019 let's see it says one in

479
00:17:19,730 --> 00:17:24,650
four people believe that security is

480
00:17:22,549 --> 00:17:27,408
synonymous with delivering quality

481
00:17:24,650 --> 00:17:29,150
that's the piece there so we're seeing a

482
00:17:27,409 --> 00:17:31,039
growth in that in that standpoint so

483
00:17:29,150 --> 00:17:32,570
what does maker driven really means so

484
00:17:31,039 --> 00:17:34,370
if we see security as part of

485
00:17:32,570 --> 00:17:36,620
engineering we view quality as a way to

486
00:17:34,370 --> 00:17:38,770
bring security in and we use code and

487
00:17:36,620 --> 00:17:41,989
not vendors to solve our problems

488
00:17:38,770 --> 00:17:44,300
okay let's flip over to e so E is

489
00:17:41,990 --> 00:17:46,820
experimenting and you know subtext there

490
00:17:44,300 --> 00:17:48,409
is and learning right so experiments

491
00:17:46,820 --> 00:17:50,570
need to be measured they need to be

492
00:17:48,410 --> 00:17:51,560
repeatable they need to the great part

493
00:17:50,570 --> 00:17:53,419
about doing experiments in your

494
00:17:51,560 --> 00:17:55,550
environment is you get results based on

495
00:17:53,420 --> 00:17:56,480
your actual needs one of my favorite

496
00:17:55,550 --> 00:17:59,440
experiments

497
00:17:56,480 --> 00:18:01,460
I spoke with Shannon leets over at RSA

498
00:17:59,440 --> 00:18:04,610
and then we also spoke at a DevOps

499
00:18:01,460 --> 00:18:06,650
Enterprise Summit on this on the wasp

500
00:18:04,610 --> 00:18:10,490
versus a real world so she had plotted

501
00:18:06,650 --> 00:18:11,990
out here overt into it just the what she

502
00:18:10,490 --> 00:18:13,880
thought was the blue would be the OWASP

503
00:18:11,990 --> 00:18:15,770
top 10 and where they would land and

504
00:18:13,880 --> 00:18:17,150
then broke up the adversaries and tried

505
00:18:15,770 --> 00:18:19,490
to track different adversaries to her

506
00:18:17,150 --> 00:18:21,590
system and see where they landed so you

507
00:18:19,490 --> 00:18:25,040
have some like the scanners kind of

508
00:18:21,590 --> 00:18:27,490
ended up in the green dots then red for

509
00:18:25,040 --> 00:18:30,230
advanced adversaries on the far left

510
00:18:27,490 --> 00:18:31,820
paid noise over here and the the orange

511
00:18:30,230 --> 00:18:33,290
and it's a great talk I won't try to

512
00:18:31,820 --> 00:18:35,389
summarize it all here but it put a lot

513
00:18:33,290 --> 00:18:37,190
of meaning in context and explanation

514
00:18:35,390 --> 00:18:39,080
around what's going on on their systems

515
00:18:37,190 --> 00:18:40,220
at Intuit and I thought that was that

516
00:18:39,080 --> 00:18:42,080
was really helpful for people to think

517
00:18:40,220 --> 00:18:43,760
about but you end up starting detecting

518
00:18:42,080 --> 00:18:45,379
what matter so start looking at

519
00:18:43,760 --> 00:18:47,210
instrumenting all the pieces for account

520
00:18:45,380 --> 00:18:49,580
takeover attempts understanding what

521
00:18:47,210 --> 00:18:51,910
areas of my site are under attack know

522
00:18:49,580 --> 00:18:55,659
what likely vector attacks are happening

523
00:18:51,910 --> 00:18:58,100
looking for abuse and misuse cases so

524
00:18:55,660 --> 00:19:00,170
Zane Lackey over at signal Sciences I

525
00:18:58,100 --> 00:19:01,580
love this this approach he says for many

526
00:19:00,170 --> 00:19:02,990
years in security we care we sort of

527
00:19:01,580 --> 00:19:04,879
decided we're just gonna seed home-field

528
00:19:02,990 --> 00:19:06,290
advantage but I think that we can't we

529
00:19:04,880 --> 00:19:09,110
can't do that right we actually know our

530
00:19:06,290 --> 00:19:11,210
systems and if we know them and doing

531
00:19:09,110 --> 00:19:12,709
that we were able to have better

532
00:19:11,210 --> 00:19:14,300
conclusions out of that and that's what

533
00:19:12,710 --> 00:19:15,830
experimenting necessitates it it

534
00:19:14,300 --> 00:19:17,930
actually necessitates that you

535
00:19:15,830 --> 00:19:20,120
understand your steady state of your

536
00:19:17,930 --> 00:19:21,530
system so having dashboards or

537
00:19:20,120 --> 00:19:23,570
monitoring and instrumentation that you

538
00:19:21,530 --> 00:19:26,360
actually know where where that lies in

539
00:19:23,570 --> 00:19:29,090
the normal world so some resources I

540
00:19:26,360 --> 00:19:31,219
think looking at Shannon Lisa stuff

541
00:19:29,090 --> 00:19:33,649
she's Deb's a cop's on Twitter and then

542
00:19:31,220 --> 00:19:35,420
here's a link to the YouTube on YouTube

543
00:19:33,650 --> 00:19:39,020
for the DevOps Enterprise summit 2018

544
00:19:35,420 --> 00:19:41,300
talk that I really like okay let's move

545
00:19:39,020 --> 00:19:43,129
to a so the automation of things when I

546
00:19:41,300 --> 00:19:45,590
was at signal Sciences I wrote this this

547
00:19:43,130 --> 00:19:48,410
white paper in it and I had this very

548
00:19:45,590 --> 00:19:50,810
marketing graph here which is identified

549
00:19:48,410 --> 00:19:51,800
resource miss utilization ad telemetry

550
00:19:50,810 --> 00:19:53,600
feedback loops

551
00:19:51,800 --> 00:19:55,490
then automated across your pipeline and

552
00:19:53,600 --> 00:19:57,469
then overall influence organization

553
00:19:55,490 --> 00:19:59,150
culture its own the the bottom its

554
00:19:57,470 --> 00:20:00,830
influence across team so as you do more

555
00:19:59,150 --> 00:20:03,260
you've grown you influence and then as

556
00:20:00,830 --> 00:20:05,179
you go higher you increase your actual

557
00:20:03,260 --> 00:20:06,890
effectiveness these don't have to go in

558
00:20:05,180 --> 00:20:08,600
order there's a feedback loop to it but

559
00:20:06,890 --> 00:20:10,040
I think there is there's helpful pieces

560
00:20:08,600 --> 00:20:12,679
and we often will look at automated as

561
00:20:10,040 --> 00:20:14,000
being our first step but I find these

562
00:20:12,680 --> 00:20:15,590
other two we're actually adding real

563
00:20:14,000 --> 00:20:17,180
telemetry and able to understand what's

564
00:20:15,590 --> 00:20:18,530
going on in our system that's that can

565
00:20:17,180 --> 00:20:21,770
be more helpful

566
00:20:18,530 --> 00:20:24,050
again another Shannon leaks reference

567
00:20:21,770 --> 00:20:25,970
here she has a secure software pipeline

568
00:20:24,050 --> 00:20:27,919
and each part of the pipeline there's

569
00:20:25,970 --> 00:20:29,570
questions like how do I secure my app

570
00:20:27,920 --> 00:20:31,610
and design what component is secure

571
00:20:29,570 --> 00:20:33,620
enough and build and deploy how do I

572
00:20:31,610 --> 00:20:35,149
secure secrets for the app so I find

573
00:20:33,620 --> 00:20:37,159
those as pretty helpful and we look

574
00:20:35,150 --> 00:20:39,980
across our DevOps Enterprise summit or a

575
00:20:37,160 --> 00:20:43,220
DevOps Enterprise devstack ops survey

576
00:20:39,980 --> 00:20:45,860
and across the across the pipeline here

577
00:20:43,220 --> 00:20:47,600
we see the blue is people that are kind

578
00:20:45,860 --> 00:20:50,030
of in the elite practice category and

579
00:20:47,600 --> 00:20:51,740
the orange is the they have no DevOps

580
00:20:50,030 --> 00:20:53,210
practice we see that there's

581
00:20:51,740 --> 00:20:55,430
outperformance there's still room to

582
00:20:53,210 --> 00:20:58,130
grow a lot of focus on like the build

583
00:20:55,430 --> 00:20:59,750
and CI or during the QA piece but

584
00:20:58,130 --> 00:21:00,980
throughout the whole process like is

585
00:20:59,750 --> 00:21:03,290
where we're trying to look and try to

586
00:21:00,980 --> 00:21:05,780
put security testing telemetry in place

587
00:21:03,290 --> 00:21:07,940
at those at those spots so looking for

588
00:21:05,780 --> 00:21:11,030
pre commit at build deploy at runtime

589
00:21:07,940 --> 00:21:13,220
and also in that survey there was a

590
00:21:11,030 --> 00:21:16,460
great piece that showed like even though

591
00:21:13,220 --> 00:21:19,190
it's a again blue is the the more devops

592
00:21:16,460 --> 00:21:20,720
elite they're they're actually using

593
00:21:19,190 --> 00:21:22,400
more of kind of the standard what we

594
00:21:20,720 --> 00:21:24,380
would consider standard security tooling

595
00:21:22,400 --> 00:21:26,330
so web application firewalls container

596
00:21:24,380 --> 00:21:28,130
applications security open source

597
00:21:26,330 --> 00:21:30,080
governance static analysis dynamic

598
00:21:28,130 --> 00:21:32,060
analysis so it's actually using more of

599
00:21:30,080 --> 00:21:33,139
kind of you know traditional approaches

600
00:21:32,060 --> 00:21:34,610
that we've used and then they've kind of

601
00:21:33,140 --> 00:21:35,720
put it across their pipeline in a lot of

602
00:21:34,610 --> 00:21:38,780
different places so I think that's

603
00:21:35,720 --> 00:21:40,850
pretty good well I think we can focus on

604
00:21:38,780 --> 00:21:42,740
looking at continuous delivery and how

605
00:21:40,850 --> 00:21:44,419
people deliver software there's a great

606
00:21:42,740 --> 00:21:46,790
book called continuous delivery by J's

607
00:21:44,420 --> 00:21:48,230
humble and David Farley and one of the

608
00:21:46,790 --> 00:21:49,670
things they stress in that book is

609
00:21:48,230 --> 00:21:52,030
continuous deliveries about how little

610
00:21:49,670 --> 00:21:54,140
you actually deliver at any one time and

611
00:21:52,030 --> 00:21:55,370
whenever I said signal Sciences we

612
00:21:54,140 --> 00:21:57,770
really spend a lot of time optimizing

613
00:21:55,370 --> 00:21:59,570
for total cycle time so from time to

614
00:21:57,770 --> 00:22:00,860
code commit to actually running in

615
00:21:59,570 --> 00:22:02,360
production and we want to try to keep

616
00:22:00,860 --> 00:22:05,330
that under five minutes as well

617
00:22:02,360 --> 00:22:06,800
we try to do and over over the last

618
00:22:05,330 --> 00:22:08,960
three and a half or four years we did

619
00:22:06,800 --> 00:22:10,280
over 15,000 deploys and we're really

620
00:22:08,960 --> 00:22:13,430
excited about that like we were able to

621
00:22:10,280 --> 00:22:15,110
push things live and it took some part

622
00:22:13,430 --> 00:22:17,000
of that part of that journey was we had

623
00:22:15,110 --> 00:22:18,469
to sometimes sit in a room uncomfortably

624
00:22:17,000 --> 00:22:20,660
and say okay who slowed down the build

625
00:22:18,470 --> 00:22:22,880
how do we make things faster how do we

626
00:22:20,660 --> 00:22:24,290
how do we continue to push this out how

627
00:22:22,880 --> 00:22:26,120
does each developer as they're pushing

628
00:22:24,290 --> 00:22:27,680
this out like on both the security and

629
00:22:26,120 --> 00:22:31,040
the reliability and availability of the

630
00:22:27,680 --> 00:22:33,440
system and and so we put a lot of

631
00:22:31,040 --> 00:22:35,090
security stuff in the pipeline so you

632
00:22:33,440 --> 00:22:38,030
can do software composition analysis

633
00:22:35,090 --> 00:22:40,010
language linters like scanning type

634
00:22:38,030 --> 00:22:43,270
stuff there's a gauntlet or monitoring

635
00:22:40,010 --> 00:22:45,590
telemetry all those types of pieces but

636
00:22:43,270 --> 00:22:47,120
kind of the the piece that you want to

637
00:22:45,590 --> 00:22:48,500
leave with is thinking all right deploys

638
00:22:47,120 --> 00:22:49,729
can be treated to treat it as standard

639
00:22:48,500 --> 00:22:51,320
or routine changes that have been

640
00:22:49,730 --> 00:22:52,640
pre-approved by management they don't

641
00:22:51,320 --> 00:22:54,379
require a heavyweight change review

642
00:22:52,640 --> 00:22:56,390
meeting so if you find yourself always

643
00:22:54,380 --> 00:23:00,260
doing cabs or whatever like that's

644
00:22:56,390 --> 00:23:02,480
that's maybe not so good okay so a

645
00:23:00,260 --> 00:23:04,190
couple resources on this I actually have

646
00:23:02,480 --> 00:23:06,290
two courses that I have on LinkedIn

647
00:23:04,190 --> 00:23:08,660
learning for this one's on building a

648
00:23:06,290 --> 00:23:11,000
secure continuous delivery pipeline and

649
00:23:08,660 --> 00:23:12,920
another one is on dev psych ops

650
00:23:11,000 --> 00:23:14,600
automated security testing so kind of

651
00:23:12,920 --> 00:23:18,440
more this is more of a development style

652
00:23:14,600 --> 00:23:20,090
of course alright so a super kind of

653
00:23:18,440 --> 00:23:21,410
running short on time let me let me kind

654
00:23:20,090 --> 00:23:22,909
of hustle through the next piece but I

655
00:23:21,410 --> 00:23:24,050
think the next piece I kind of went

656
00:23:22,910 --> 00:23:25,610
through that last one a little fast but

657
00:23:24,050 --> 00:23:28,220
I want to hit through on this one a

658
00:23:25,610 --> 00:23:30,169
little more so the S I think this might

659
00:23:28,220 --> 00:23:31,610
be really interesting for us as we kind

660
00:23:30,170 --> 00:23:34,160
of move over the next three to five

661
00:23:31,610 --> 00:23:36,530
years thinking about security and safety

662
00:23:34,160 --> 00:23:38,810
and how they kind of hook together so

663
00:23:36,530 --> 00:23:44,000
safety for complex systems I'd like to

664
00:23:38,810 --> 00:23:45,020
tell you two stories of failure okay you

665
00:23:44,000 --> 00:23:47,660
might have noticed I'm a little tall

666
00:23:45,020 --> 00:23:51,200
right so one of the problems of being

667
00:23:47,660 --> 00:23:53,030
tall is doorways and then they're not a

668
00:23:51,200 --> 00:23:55,010
normal problem for regular people right

669
00:23:53,030 --> 00:23:58,879
but I end up I end up having this

670
00:23:55,010 --> 00:24:00,980
situation and it's the those electric

671
00:23:58,880 --> 00:24:03,680
locks in the upper left-hand corner and

672
00:24:00,980 --> 00:24:05,780
then those hydraulic those hydraulic

673
00:24:03,680 --> 00:24:07,460
assist door openers and it's not usually

674
00:24:05,780 --> 00:24:10,740
a problem like on this door this is a

675
00:24:07,460 --> 00:24:13,020
very tall door so we're all square right

676
00:24:10,740 --> 00:24:14,850
and so but I want to zoom in here and

677
00:24:13,020 --> 00:24:16,170
just I'll tell you about a little story

678
00:24:14,850 --> 00:24:21,179
so I dropped my daughter off at school

679
00:24:16,170 --> 00:24:23,220
this is just last week and and I go in

680
00:24:21,180 --> 00:24:24,360
and I'm wearing a baseball hat and I'm

681
00:24:23,220 --> 00:24:26,810
just kind of taking her in and then all

682
00:24:24,360 --> 00:24:31,080
of a sudden boom like slammed into the

683
00:24:26,810 --> 00:24:32,879
this electronic walk situation here and

684
00:24:31,080 --> 00:24:35,030
I'm like oh geez did I just like have a

685
00:24:32,880 --> 00:24:38,250
concussion like I hit it pretty hard and

686
00:24:35,030 --> 00:24:39,060
and I thought well this is uh this is

687
00:24:38,250 --> 00:24:41,490
not good

688
00:24:39,060 --> 00:24:43,290
and so I sort of just you know winced

689
00:24:41,490 --> 00:24:44,910
you know put her in her classroom and

690
00:24:43,290 --> 00:24:46,680
then just walk back and like my pride is

691
00:24:44,910 --> 00:24:48,650
a little bit hurt a little embarrassing

692
00:24:46,680 --> 00:24:52,220
we've been telling you this story here

693
00:24:48,650 --> 00:24:54,810
but but why did why did this happen and

694
00:24:52,220 --> 00:24:56,730
so we can we can take like five wise and

695
00:24:54,810 --> 00:24:59,490
do some literature linear questioning on

696
00:24:56,730 --> 00:25:01,440
this so why why did I encounter this

697
00:24:59,490 --> 00:25:05,010
problem well okay we had we had to have

698
00:25:01,440 --> 00:25:06,900
security on the door right and why do we

699
00:25:05,010 --> 00:25:08,760
have that oh you got a locked doors for

700
00:25:06,900 --> 00:25:10,620
safety's it's a school well okay why do

701
00:25:08,760 --> 00:25:12,420
you need that well society problems

702
00:25:10,620 --> 00:25:15,209
school shootings stuff like that it's

703
00:25:12,420 --> 00:25:17,280
kind of depressing okay well even

704
00:25:15,210 --> 00:25:19,950
further but why look we can kind of go

705
00:25:17,280 --> 00:25:22,260
another route like why did we why did I

706
00:25:19,950 --> 00:25:24,450
experience that well it's a bad design

707
00:25:22,260 --> 00:25:25,980
new some I have actually googled this

708
00:25:24,450 --> 00:25:27,420
and like some designs have the whole

709
00:25:25,980 --> 00:25:29,790
system like mounting above the door

710
00:25:27,420 --> 00:25:32,040
which is which is really great also it's

711
00:25:29,790 --> 00:25:35,760
an old building so the door frames were

712
00:25:32,040 --> 00:25:37,530
automatically lower and oh yeah what why

713
00:25:35,760 --> 00:25:38,910
else did this happen I was wearing a hat

714
00:25:37,530 --> 00:25:41,910
so it was out of my peripheral vision

715
00:25:38,910 --> 00:25:44,130
and I I just I woke up late I was like

716
00:25:41,910 --> 00:25:46,650
God you just put on a hat and take the

717
00:25:44,130 --> 00:25:48,450
kid to school and why did that happen

718
00:25:46,650 --> 00:25:50,250
well I went to bed late and then why did

719
00:25:48,450 --> 00:25:52,770
I do that I was living life in a hurry

720
00:25:50,250 --> 00:25:54,120
so and I was less thoughtful and you

721
00:25:52,770 --> 00:25:56,520
could just kind of go down this this

722
00:25:54,120 --> 00:25:59,370
path and five wise is good for linear

723
00:25:56,520 --> 00:26:01,080
linear and simple systems but whenever

724
00:25:59,370 --> 00:26:02,340
you start dealing with complex systems

725
00:26:01,080 --> 00:26:03,990
which what I just described is not

726
00:26:02,340 --> 00:26:06,870
really a complex system now it does have

727
00:26:03,990 --> 00:26:09,920
like a human is a complex system kind of

728
00:26:06,870 --> 00:26:09,919
society is a complex system

729
00:26:10,250 --> 00:26:16,049
anyway so so those are the pieces as we

730
00:26:13,770 --> 00:26:18,539
kind of think about this and I I'd like

731
00:26:16,049 --> 00:26:19,620
to say like we extract complexity and

732
00:26:18,539 --> 00:26:21,600
that's kind of how we are able to

733
00:26:19,620 --> 00:26:24,209
rationalize as we move about through

734
00:26:21,600 --> 00:26:26,490
through through life right human beings

735
00:26:24,210 --> 00:26:27,960
we we kind of just abstract that to as a

736
00:26:26,490 --> 00:26:29,460
person we don't think about all the all

737
00:26:27,960 --> 00:26:30,990
the complexity that's involved inside of

738
00:26:29,460 --> 00:26:33,059
that society

739
00:26:30,990 --> 00:26:34,440
psychological we just have like too much

740
00:26:33,059 --> 00:26:36,658
cognitive load like we can't deal with

741
00:26:34,440 --> 00:26:39,450
everything all at the same time and so

742
00:26:36,659 --> 00:26:40,860
we suffer deals with the same thing

743
00:26:39,450 --> 00:26:42,720
through abstraction you earlier we

744
00:26:40,860 --> 00:26:45,418
talked about those 222 lines of code I

745
00:26:42,720 --> 00:26:47,549
write those those lines and then they

746
00:26:45,419 --> 00:26:49,080
were good right well that that's a

747
00:26:47,549 --> 00:26:50,340
that's a layer of abstraction like I'm

748
00:26:49,080 --> 00:26:54,029
dealing with the frameworks and pieces

749
00:26:50,340 --> 00:26:56,520
there so I'd like to instill in still

750
00:26:54,029 --> 00:26:57,000
this idea and you is that root causes a

751
00:26:56,520 --> 00:26:59,970
myth

752
00:26:57,000 --> 00:27:01,710
it lacks full picture this is whenever

753
00:26:59,970 --> 00:27:04,350
you kind of drive to root cause this

754
00:27:01,710 --> 00:27:05,940
instills kind of a blame like culture it

755
00:27:04,350 --> 00:27:09,600
forgets any organizational decisions

756
00:27:05,940 --> 00:27:11,250
that led up to it any of the prior legal

757
00:27:09,600 --> 00:27:13,949
and other type of ramifications that

758
00:27:11,250 --> 00:27:16,049
went into it and in his book drift into

759
00:27:13,950 --> 00:27:17,250
failure I'd like to read this quote

760
00:27:16,049 --> 00:27:17,879
because I find this this book could be

761
00:27:17,250 --> 00:27:20,610
super helpful

762
00:27:17,880 --> 00:27:22,890
so drifting into failure is a gradual

763
00:27:20,610 --> 00:27:24,959
incremental decline into zaspar driven

764
00:27:22,890 --> 00:27:26,850
by environmental pressure unruly

765
00:27:24,960 --> 00:27:30,240
technology and social processes that

766
00:27:26,850 --> 00:27:31,980
Norman normalize growing risk so norm no

767
00:27:30,240 --> 00:27:36,059
organization is exempt from drifting

768
00:27:31,980 --> 00:27:37,620
into failure and and we can look at

769
00:27:36,059 --> 00:27:39,090
another example that's maybe more

770
00:27:37,620 --> 00:27:41,760
interesting to us right if we look at

771
00:27:39,090 --> 00:27:44,879
the the Boeing stuff so they have the

772
00:27:41,760 --> 00:27:46,140
MCAS system which was if you build a

773
00:27:44,880 --> 00:27:48,390
bigger plane keeps the plane from

774
00:27:46,140 --> 00:27:50,880
stalling and it is essentially

775
00:27:48,390 --> 00:27:54,360
automation software and in certain

776
00:27:50,880 --> 00:27:56,580
situations the MCS commands the trim in

777
00:27:54,360 --> 00:27:59,129
this condition situations okay it'll

778
00:27:56,580 --> 00:28:01,139
take over the trim without notifying the

779
00:27:59,130 --> 00:28:04,230
pilots and Jay Paul Reid has a great

780
00:28:01,140 --> 00:28:05,970
great coverage on this he says these

781
00:28:04,230 --> 00:28:07,590
events unfold in and minutes and the

782
00:28:05,970 --> 00:28:09,899
system they were operating was pretty

783
00:28:07,590 --> 00:28:11,789
much like every every 737 they've been

784
00:28:09,899 --> 00:28:17,330
likely to operate in their careers ever

785
00:28:11,789 --> 00:28:17,330
and the the new so see you it

786
00:28:19,380 --> 00:28:26,410
so and this is in a context of them

787
00:28:21,700 --> 00:28:28,300
being told that the system oh geez there

788
00:28:26,410 --> 00:28:29,350
it is okay in a context of being told

789
00:28:28,300 --> 00:28:31,450
that the system that they were operating

790
00:28:29,350 --> 00:28:34,629
was pretty much like anything they've

791
00:28:31,450 --> 00:28:42,700
ever used before let me be I skip the

792
00:28:34,630 --> 00:28:44,470
first part sorry okay so the new safety

793
00:28:42,700 --> 00:28:45,460
automation the other thing he says in

794
00:28:44,470 --> 00:28:47,170
his article that I think is pretty

795
00:28:45,460 --> 00:28:49,480
helpful is the new safety automation is

796
00:28:47,170 --> 00:28:51,309
capable of overriding operator input in

797
00:28:49,480 --> 00:28:53,140
silence and in ways that were poorly

798
00:28:51,309 --> 00:28:56,520
documented by designers uncleared

799
00:28:53,140 --> 00:28:59,800
operators and promised by developers

800
00:28:56,520 --> 00:29:01,300
that nobody had to get training that

801
00:28:59,800 --> 00:29:02,710
nobody had to get training on so that

802
00:29:01,300 --> 00:29:03,700
was what that was a big key right and

803
00:29:02,710 --> 00:29:06,040
that was a selling point of the whole

804
00:29:03,700 --> 00:29:07,480
system that this safety automation now

805
00:29:06,040 --> 00:29:09,970
proved to be the system to become

806
00:29:07,480 --> 00:29:12,490
critically unrecoverable and at least in

807
00:29:09,970 --> 00:29:14,679
one case was the was the cause or or

808
00:29:12,490 --> 00:29:17,620
contributed a contributing factor to the

809
00:29:14,679 --> 00:29:19,330
crash there so has anybody does

810
00:29:17,620 --> 00:29:21,639
high-speed decisions about systems sound

811
00:29:19,330 --> 00:29:23,559
familiar to any of us right like this is

812
00:29:21,640 --> 00:29:26,050
this is this is important to us and his

813
00:29:23,559 --> 00:29:27,490
article Jay Paul Reid says this is why

814
00:29:26,050 --> 00:29:29,440
software developers really should pay

815
00:29:27,490 --> 00:29:31,270
attention to this because this is like

816
00:29:29,440 --> 00:29:32,980
Boeing's I care we're gonna fix it like

817
00:29:31,270 --> 00:29:36,250
we're gonna release a software patch to

818
00:29:32,980 --> 00:29:37,840
the system and the the growth of

819
00:29:36,250 --> 00:29:40,059
complexity in society has gotten ahead

820
00:29:37,840 --> 00:29:44,860
of how our understanding of how complex

821
00:29:40,059 --> 00:29:48,160
systems work and fail in his book Sydney

822
00:29:44,860 --> 00:29:49,510
Decker says this and this is a I just

823
00:29:48,160 --> 00:29:51,190
pulled this randomly off of the internet

824
00:29:49,510 --> 00:29:52,480
but this is a chart of how like

825
00:29:51,190 --> 00:29:54,580
serverless systems are hooked together

826
00:29:52,480 --> 00:29:55,929
right like is this easy to keep in our

827
00:29:54,580 --> 00:30:00,669
heads as we're like operating at high

828
00:29:55,929 --> 00:30:02,620
speed right no and my friend Matt Stein

829
00:30:00,670 --> 00:30:05,080
says this and I think this is it's very

830
00:30:02,620 --> 00:30:09,370
true it's like we we have made a huge

831
00:30:05,080 --> 00:30:11,590
error here but it puts the onus on

832
00:30:09,370 --> 00:30:15,129
security and operations to rationalise

833
00:30:11,590 --> 00:30:17,559
system models and Adrienne Cockroft says

834
00:30:15,130 --> 00:30:19,270
failures are a systems problem because

835
00:30:17,559 --> 00:30:20,950
there's not enough safety margin and so

836
00:30:19,270 --> 00:30:22,170
we're seeing more safety type discussion

837
00:30:20,950 --> 00:30:24,060
happen in the

838
00:30:22,170 --> 00:30:25,950
right now and we see failure as an

839
00:30:24,060 --> 00:30:28,620
inevitable byproduct of complex systems

840
00:30:25,950 --> 00:30:30,540
normal functioning so where does

841
00:30:28,620 --> 00:30:32,459
security fit in I think that we can add

842
00:30:30,540 --> 00:30:34,710
a safety margin we add telemetry and

843
00:30:32,460 --> 00:30:36,270
instrumentation we started participating

844
00:30:34,710 --> 00:30:37,470
in blameless retrospectives I think

845
00:30:36,270 --> 00:30:39,300
that's really helpful so instead of

846
00:30:37,470 --> 00:30:42,200
trying to be the the finger-pointing we

847
00:30:39,300 --> 00:30:44,490
we start kind of trying to go blameless

848
00:30:42,200 --> 00:30:45,630
and honestly I think there's more to

849
00:30:44,490 --> 00:30:47,040
explore in this area I think the

850
00:30:45,630 --> 00:30:49,530
overlaps between safety and security

851
00:30:47,040 --> 00:30:52,080
kind of in his book Sydney Decker sort

852
00:30:49,530 --> 00:30:53,639
of bifurcated to but I think that

853
00:30:52,080 --> 00:30:55,949
there's some some overlap that we can

854
00:30:53,640 --> 00:30:58,200
take a look at so some of these books

855
00:30:55,950 --> 00:31:00,660
and videos have been really helpful this

856
00:30:58,200 --> 00:31:02,670
youtube series understanding human error

857
00:31:00,660 --> 00:31:04,610
has been pretty instructive for me so

858
00:31:02,670 --> 00:31:07,020
I'd recommend it

859
00:31:04,610 --> 00:31:09,959
alright let's go to the U so

860
00:31:07,020 --> 00:31:12,000
unrestrained sharing so when we talk

861
00:31:09,960 --> 00:31:15,360
about this like often culture is one of

862
00:31:12,000 --> 00:31:17,660
those key aspects of DevOps and in the

863
00:31:15,360 --> 00:31:21,060
beginning part of DevOps we all said

864
00:31:17,660 --> 00:31:23,370
DevOps has no definition its culture and

865
00:31:21,060 --> 00:31:24,899
so eventually we kind of grew out of

866
00:31:23,370 --> 00:31:27,719
that and said we'll give it some more

867
00:31:24,900 --> 00:31:29,670
structure but the Kam's models like

868
00:31:27,720 --> 00:31:31,980
culture is the first the first piece in

869
00:31:29,670 --> 00:31:33,600
the Kam's model and i think that that

870
00:31:31,980 --> 00:31:35,790
fits for security as well a lot of times

871
00:31:33,600 --> 00:31:37,409
we we don't share kind of what we have

872
00:31:35,790 --> 00:31:40,020
inside of our organization with the

873
00:31:37,410 --> 00:31:41,280
other organizations so here's a good

874
00:31:40,020 --> 00:31:42,990
quote from Patrick Dubois the guy who

875
00:31:41,280 --> 00:31:44,550
coined the term DevOps he says culture

876
00:31:42,990 --> 00:31:47,400
is the most important aspect to DevOps

877
00:31:44,550 --> 00:31:48,990
succeeding in the enterprise and I think

878
00:31:47,400 --> 00:31:50,550
devstack ops is the extension of the

879
00:31:48,990 --> 00:31:52,890
DevOps culture for the inclusion of

880
00:31:50,550 --> 00:31:56,129
security security that's what we said at

881
00:31:52,890 --> 00:31:58,050
the very beginning right rich Smith over

882
00:31:56,130 --> 00:31:59,910
at Etsy he said a security team who

883
00:31:58,050 --> 00:32:03,030
embraces openness about what it does and

884
00:31:59,910 --> 00:32:05,250
why spreads understanding and we know

885
00:32:03,030 --> 00:32:08,310
this oh yeah hey good it comes they're

886
00:32:05,250 --> 00:32:10,830
sharing effects culture I think that

887
00:32:08,310 --> 00:32:12,330
that's just because one one you let one

888
00:32:10,830 --> 00:32:14,370
team know hey this is what we care about

889
00:32:12,330 --> 00:32:17,189
other team start participating in that

890
00:32:14,370 --> 00:32:18,659
so under strange sharing goes against

891
00:32:17,190 --> 00:32:20,670
what we see is our normal operating

892
00:32:18,660 --> 00:32:23,640
procedure and sometimes it might feel

893
00:32:20,670 --> 00:32:25,980
uncomfortable but it does break down

894
00:32:23,640 --> 00:32:28,950
silos and we see that as a that is a key

895
00:32:25,980 --> 00:32:30,780
piece here and I always kind of say

896
00:32:28,950 --> 00:32:32,880
these are the four keys that I view as

897
00:32:30,780 --> 00:32:35,340
culture so having a mutual understanding

898
00:32:32,880 --> 00:32:37,139
being able to share in the language

899
00:32:35,340 --> 00:32:38,549
having shared views and then be able to

900
00:32:37,139 --> 00:32:41,459
put tooling and collaborative to and in

901
00:32:38,549 --> 00:32:44,668
place for that I think is helpful and

902
00:32:41,460 --> 00:32:46,470
why is this important so ranked the top

903
00:32:44,669 --> 00:32:49,200
challenges of your application security

904
00:32:46,470 --> 00:32:50,340
processes okay they're almost the same I

905
00:32:49,200 --> 00:32:52,320
mean there's a little bit of variance

906
00:32:50,340 --> 00:32:54,600
between the two but I mean it's not that

907
00:32:52,320 --> 00:32:55,918
big but on the far left number one

908
00:32:54,600 --> 00:32:57,928
problem the developers say about

909
00:32:55,919 --> 00:33:00,960
security we find out about problems too

910
00:32:57,929 --> 00:33:03,090
late in the process and then then in the

911
00:33:00,960 --> 00:33:04,919
middle one over is there's the next one

912
00:33:03,090 --> 00:33:06,658
slows down development okay we I think

913
00:33:04,919 --> 00:33:08,580
we already knew that but the last one

914
00:33:06,659 --> 00:33:11,600
says it's not clear of what's expected

915
00:33:08,580 --> 00:33:14,908
of us so there's a there's a gap here

916
00:33:11,600 --> 00:33:16,918
there's a gap here so we need to make

917
00:33:14,909 --> 00:33:20,369
security we need to make invisible as

918
00:33:16,919 --> 00:33:21,899
visible adding security visibility and

919
00:33:20,369 --> 00:33:24,209
I'm gonna try to hustle through the last

920
00:33:21,899 --> 00:33:25,619
few slides here so security

921
00:33:24,210 --> 00:33:29,820
observability gives us more of what's

922
00:33:25,619 --> 00:33:31,049
happening below the surface and in Jason

923
00:33:29,820 --> 00:33:32,668
Chan over at Netflix he talks about

924
00:33:31,049 --> 00:33:35,009
doing a paved road approach treating

925
00:33:32,669 --> 00:33:37,740
secured deals normal making security as

926
00:33:35,009 --> 00:33:39,840
free if using the system and I think we

927
00:33:37,740 --> 00:33:41,490
can't leave the auditors out of this I'm

928
00:33:39,840 --> 00:33:43,740
working on a project called dear auditor

929
00:33:41,490 --> 00:33:45,389
I go to dear audit or gets a it's a love

930
00:33:43,740 --> 00:33:46,860
letter from DevOps to auditors saying

931
00:33:45,389 --> 00:33:50,070
like we promised to bring you along for

932
00:33:46,860 --> 00:33:51,809
the journey be happy to like it's in

933
00:33:50,070 --> 00:33:53,340
github we accept for requests and stuff

934
00:33:51,809 --> 00:33:56,369
would be happy to have you take a look

935
00:33:53,340 --> 00:33:57,840
at that d auditor org so other resources

936
00:33:56,369 --> 00:33:59,428
that I'd give you for this is check out

937
00:33:57,840 --> 00:34:01,049
the Phoenix project agile applications

938
00:33:59,429 --> 00:34:03,600
security and that dear auditor site that

939
00:34:01,049 --> 00:34:04,769
I mentioned ok let's talk about rugged

940
00:34:03,600 --> 00:34:09,270
ization I'm gonna try to fly through

941
00:34:04,769 --> 00:34:13,079
these so ruggedized ation where we're

942
00:34:09,270 --> 00:34:15,179
living with our system right now so I

943
00:34:13,079 --> 00:34:16,230
feel like I feel like we focused on two

944
00:34:15,179 --> 00:34:17,668
when we were thinking about rugged

945
00:34:16,230 --> 00:34:18,480
rugged software especially in the

946
00:34:17,668 --> 00:34:20,339
beginning we were thinking about

947
00:34:18,480 --> 00:34:23,609
software build materials so you know

948
00:34:20,339 --> 00:34:25,770
what you have everywhere and then we

949
00:34:23,609 --> 00:34:27,418
started thinking like ok with this we

950
00:34:25,770 --> 00:34:30,869
also need a favor short-lived systems

951
00:34:27,418 --> 00:34:31,560
have cattle not pets I really like how

952
00:34:30,869 --> 00:34:33,569
the and

953
00:34:31,560 --> 00:34:35,730
operations has been on board at this for

954
00:34:33,569 --> 00:34:38,159
a while so I think this is good but

955
00:34:35,730 --> 00:34:39,690
Sunil you he has the dive framework

956
00:34:38,159 --> 00:34:41,760
which is distributed immutable and

957
00:34:39,690 --> 00:34:43,770
ephemeral he's working on some some

958
00:34:41,760 --> 00:34:44,940
papers to kind of prove out that like

959
00:34:43,770 --> 00:34:47,389
just if you have these three

960
00:34:44,940 --> 00:34:47,389
characteristics

961
00:34:49,159 --> 00:34:55,139
okay okay okay okay yeah so we have

962
00:34:53,039 --> 00:34:56,970
these like this we have these three

963
00:34:55,139 --> 00:34:58,289
three pieces here or we look at okay if

964
00:34:56,969 --> 00:34:59,970
you have distributed systems immutable

965
00:34:58,289 --> 00:35:02,250
and ephemeral like you actually end up

966
00:34:59,970 --> 00:35:05,399
with a more secure secure state in the

967
00:35:02,250 --> 00:35:07,140
end so I'd recommend taking a look at

968
00:35:05,400 --> 00:35:08,640
his stuff so where do I think rugged

969
00:35:07,140 --> 00:35:10,288
ization is going or like if we actually

970
00:35:08,640 --> 00:35:12,538
have to be more rugged how does that

971
00:35:10,289 --> 00:35:14,549
look I think there's two key aspects

972
00:35:12,539 --> 00:35:16,140
over the next year or two years I think

973
00:35:14,549 --> 00:35:19,140
it's in deception and I believe it's in

974
00:35:16,140 --> 00:35:20,578
chaos engineering so deception this is

975
00:35:19,140 --> 00:35:24,598
stuff like you know deploying honeypot

976
00:35:20,579 --> 00:35:25,950
star pits man traps camouflage and ready

977
00:35:24,599 --> 00:35:27,210
I mean it's easy for us to get started

978
00:35:25,950 --> 00:35:29,038
the a player like we can just inject

979
00:35:27,210 --> 00:35:31,010
certain HTTP headers we see those we can

980
00:35:29,039 --> 00:35:34,619
you know put them off in other systems

981
00:35:31,010 --> 00:35:36,690
my friend Phillip Maddux is does the

982
00:35:34,619 --> 00:35:38,130
honey-pie project you can also check out

983
00:35:36,690 --> 00:35:39,809
deception logic that's some really great

984
00:35:38,130 --> 00:35:42,059
options for being able to get started

985
00:35:39,809 --> 00:35:44,430
with this in your infrastructure but I

986
00:35:42,059 --> 00:35:46,289
like to whenever I meet practitioners

987
00:35:44,430 --> 00:35:47,759
that are doing deception like there's

988
00:35:46,289 --> 00:35:50,880
some there's some pretty cool stuff that

989
00:35:47,760 --> 00:35:52,319
people are doing and a lot of them won't

990
00:35:50,880 --> 00:35:54,690
talk about it like as openly so

991
00:35:52,319 --> 00:35:55,890
hopefully we'll get more open discussion

992
00:35:54,690 --> 00:35:58,559
about it and so that would be really

993
00:35:55,890 --> 00:35:59,879
helpful I have some links to some good

994
00:35:58,559 --> 00:36:00,869
talks that I think that might be helpful

995
00:35:59,880 --> 00:36:03,599
if you're interested in the deception

996
00:36:00,869 --> 00:36:05,910
space also Adrian Cockroft says we're

997
00:36:03,599 --> 00:36:07,859
moving from disaster recovery to chaos

998
00:36:05,910 --> 00:36:09,089
engineering to resiliency he sees this

999
00:36:07,859 --> 00:36:11,038
as kind of the path of like how

1000
00:36:09,089 --> 00:36:13,890
engineering is moving in the world right

1001
00:36:11,039 --> 00:36:16,260
now and so this is empirical rather than

1002
00:36:13,890 --> 00:36:18,118
formal we don't use models to understand

1003
00:36:16,260 --> 00:36:20,700
what the system should do we run

1004
00:36:18,119 --> 00:36:22,740
experiments to learn what it does

1005
00:36:20,700 --> 00:36:24,299
Michael Nygaard says it's in his second

1006
00:36:22,740 --> 00:36:26,129
edition you have to get the second

1007
00:36:24,299 --> 00:36:28,140
edition for it but it's release it and

1008
00:36:26,130 --> 00:36:30,180
it's a really great book he's got a lot

1009
00:36:28,140 --> 00:36:32,730
of other design patterns but has a great

1010
00:36:30,180 --> 00:36:35,308
chapter on chaos engineering which i

1011
00:36:32,730 --> 00:36:36,839
think is helpful so these are

1012
00:36:35,309 --> 00:36:39,270
experiments that span from engineering

1013
00:36:36,839 --> 00:36:41,069
to security often they're manual opt out

1014
00:36:39,270 --> 00:36:42,660
but depending on your organization and

1015
00:36:41,069 --> 00:36:43,589
your tolerance for risk and all that

1016
00:36:42,660 --> 00:36:45,359
sort of stuff you might want to make

1017
00:36:43,589 --> 00:36:48,180
them opt in but they provide valuable

1018
00:36:45,359 --> 00:36:50,520
learnings so Aaron Reinhard did chaos

1019
00:36:48,180 --> 00:36:53,578
slinger they did Chapel but Netflix

1020
00:36:50,520 --> 00:36:55,049
chaos monkey as well and so here's some

1021
00:36:53,579 --> 00:36:56,140
here's a couple like links for you if

1022
00:36:55,049 --> 00:36:58,538
you're interested in this

1023
00:36:56,140 --> 00:37:00,759
there's Aaron Reinhart stock there's

1024
00:36:58,539 --> 00:37:04,390
release it the book for from Nygaard

1025
00:37:00,759 --> 00:37:06,279
Philip Maddox talk and then herb Todd I

1026
00:37:04,390 --> 00:37:09,699
can't say where he works but he did a

1027
00:37:06,279 --> 00:37:11,049
talk over at over at last con and I love

1028
00:37:09,699 --> 00:37:13,209
that talk so I would totally recommend

1029
00:37:11,049 --> 00:37:17,890
checking that out I guess that was a

1030
00:37:13,209 --> 00:37:19,868
year ago so yeah okay let's let's close

1031
00:37:17,890 --> 00:37:22,089
this down and we'll talk about empathy

1032
00:37:19,869 --> 00:37:25,059
so I think empathy is the last kind of

1033
00:37:22,089 --> 00:37:27,160
key here and having empathy based teams

1034
00:37:25,059 --> 00:37:29,640
is a is an approach that we can take

1035
00:37:27,160 --> 00:37:33,879
when we're kind of doing dev psych ops

1036
00:37:29,640 --> 00:37:35,410
well let's go back to the well when I

1037
00:37:33,880 --> 00:37:38,259
think of all the arguments this is oh

1038
00:37:35,410 --> 00:37:40,359
and I have had I realize how silly most

1039
00:37:38,259 --> 00:37:41,920
of them were and it makes me wonder why

1040
00:37:40,359 --> 00:37:48,308
he wanted to argue over such stupid

1041
00:37:41,920 --> 00:37:50,229
things I think I'll go ask him okay you

1042
00:37:48,309 --> 00:37:51,429
know and who hasn't found themselves at

1043
00:37:50,229 --> 00:37:53,169
some point in their career saying those

1044
00:37:51,429 --> 00:37:56,410
stupid developers right hurry but you've

1045
00:37:53,170 --> 00:37:57,849
had a friend say that right and then

1046
00:37:56,410 --> 00:37:59,319
I've had developers telling me it's like

1047
00:37:57,849 --> 00:38:01,420
you security people like you guys just

1048
00:37:59,319 --> 00:38:04,329
want machines powered off unplugged and

1049
00:38:01,420 --> 00:38:06,729
like but both kind of assume that the

1050
00:38:04,329 --> 00:38:08,679
other person is like ignorant right if

1051
00:38:06,729 --> 00:38:11,589
you catch kind of the drift on that and

1052
00:38:08,679 --> 00:38:14,289
another poll from the survey from the

1053
00:38:11,589 --> 00:38:15,578
DEF psych ops survey is that developers

1054
00:38:14,289 --> 00:38:17,199
continue to believe that security is

1055
00:38:15,579 --> 00:38:18,849
important but they don't have a lot of

1056
00:38:17,199 --> 00:38:20,799
time to spin on it so they've

1057
00:38:18,849 --> 00:38:22,059
continually said 50 percent forty eight

1058
00:38:20,799 --> 00:38:24,369
percent forty eight percent it's like I

1059
00:38:22,059 --> 00:38:27,429
love it I love security don't have time

1060
00:38:24,369 --> 00:38:29,199
to work on it and in the end we start

1061
00:38:27,429 --> 00:38:30,789
saying okay let's not be a blocker let's

1062
00:38:29,199 --> 00:38:33,969
be an enabler let's like help the

1063
00:38:30,789 --> 00:38:35,229
business move forward and so that's

1064
00:38:33,969 --> 00:38:37,239
that's kind of closing it up here but

1065
00:38:35,229 --> 00:38:38,529
I'll close up like this is our this is

1066
00:38:37,239 --> 00:38:40,390
the framework that I think they could be

1067
00:38:38,529 --> 00:38:43,449
helpful I would love any feedback on on

1068
00:38:40,390 --> 00:38:45,670
this and if you're like I you must miss

1069
00:38:43,449 --> 00:38:48,939
something or a different bullet points

1070
00:38:45,670 --> 00:38:50,259
or whatever like I'd be helpful also if

1071
00:38:48,939 --> 00:38:51,819
you're if you're interested in the book

1072
00:38:50,259 --> 00:38:53,049
and you want to share your story of how

1073
00:38:51,819 --> 00:38:54,999
you've done depth stuff hop steps I've

1074
00:38:53,049 --> 00:38:56,769
got transformations or had successes or

1075
00:38:54,999 --> 00:38:58,730
failures or anything you can email a

1076
00:38:56,769 --> 00:39:00,169
book in devstack office org and somebody

1077
00:38:58,730 --> 00:39:02,090
our core author team when we get in

1078
00:39:00,170 --> 00:39:03,470
touch with you and we'll interview you

1079
00:39:02,090 --> 00:39:04,940
and we'll get some quotes and stuff like

1080
00:39:03,470 --> 00:39:07,730
that put in there and we would love to

1081
00:39:04,940 --> 00:39:09,560
have your story include alright and

1082
00:39:07,730 --> 00:39:12,280
that's the the slides are there and I

1083
00:39:09,560 --> 00:39:15,020
think that's it so I appreciate it and

1084
00:39:12,280 --> 00:39:16,580
hope you hope you've learned an hour

1085
00:39:15,020 --> 00:39:18,320
optimistic I'm really optimistic about

1086
00:39:16,580 --> 00:39:20,619
dev sec ops I really think it's it is a

1087
00:39:18,320 --> 00:39:24,230
great growth place for us so hopefully

1088
00:39:20,619 --> 00:39:26,240
encourage you also appreciate it okay so

1089
00:39:24,230 --> 00:39:28,010
you just read the question up yeah okay

1090
00:39:26,240 --> 00:39:29,118
don't you think security developers are

1091
00:39:28,010 --> 00:39:30,680
a different breed that Security

1092
00:39:29,119 --> 00:39:33,890
Administration novel security people

1093
00:39:30,680 --> 00:39:35,899
need to code some need to coffee and

1094
00:39:33,890 --> 00:39:39,259
help devs

1095
00:39:35,900 --> 00:39:42,350
I think I get that viewpoint I just

1096
00:39:39,260 --> 00:39:45,380
think that and you know I could be wrong

1097
00:39:42,350 --> 00:39:46,520
right but operations operations adult

1098
00:39:45,380 --> 00:39:47,960
with the same thing right it's like well

1099
00:39:46,520 --> 00:39:48,950
operations people don't need to code

1100
00:39:47,960 --> 00:39:51,290
they're like they just write some

1101
00:39:48,950 --> 00:39:53,710
scripts and whatever but I think kind of

1102
00:39:51,290 --> 00:39:55,700
understanding that this the stuff that I

1103
00:39:53,710 --> 00:39:58,490
the way that I'm able to kind of

1104
00:39:55,700 --> 00:40:01,850
empathize with security that is that is

1105
00:39:58,490 --> 00:40:03,020
helpful yeah so I I don't know I mean I

1106
00:40:01,850 --> 00:40:05,000
guess there's there's an option for

1107
00:40:03,020 --> 00:40:06,230
security administration but even

1108
00:40:05,000 --> 00:40:09,020
operations folks like if you're not

1109
00:40:06,230 --> 00:40:10,609
writing code I find that to be something

1110
00:40:09,020 --> 00:40:12,740
that like I always recommend people to

1111
00:40:10,609 --> 00:40:14,779
do yeah I think that it's it's a safe

1112
00:40:12,740 --> 00:40:16,100
thing to to learn how to write code

1113
00:40:14,780 --> 00:40:19,430
because you will have security and your

1114
00:40:16,100 --> 00:40:21,740
your jobs in the future or so I was know

1115
00:40:19,430 --> 00:40:24,069
that's helpful or not happy to debate

1116
00:40:21,740 --> 00:40:26,600
that with with somebody if they want but

1117
00:40:24,070 --> 00:40:29,200
alright I guess that's it

1118
00:40:26,600 --> 00:40:29,200
Thanks

1119
00:40:30,870 --> 00:40:33,339
[Applause]

