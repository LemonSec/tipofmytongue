1
00:00:00,030 --> 00:00:03,809
thank you for the introduction this is

2
00:00:01,979 --> 00:00:05,580
actually the first time that I speak at

3
00:00:03,810 --> 00:00:10,260
a security conference outside of

4
00:00:05,580 --> 00:00:12,480
Microsoft thank you and so thank you for

5
00:00:10,260 --> 00:00:16,920
the invitation as well and being able to

6
00:00:12,480 --> 00:00:19,230
speak here as you saw from from what the

7
00:00:16,920 --> 00:00:21,510
BIOS said I've been dealing with product

8
00:00:19,230 --> 00:00:24,359
security response for quite a while and

9
00:00:21,510 --> 00:00:27,630
I'm here to talk about security response

10
00:00:24,359 --> 00:00:29,369
in the OSS context before I do that one

11
00:00:27,630 --> 00:00:32,098
other part of my value is that I am

12
00:00:29,369 --> 00:00:34,440
originally from Puerto Rico the picture

13
00:00:32,098 --> 00:00:37,949
that you see here is not Hawaii is porto

14
00:00:34,440 --> 00:00:40,349
rico it is very similar to Hawaii and it

15
00:00:37,950 --> 00:00:42,510
is on the Caribbean so if if it is

16
00:00:40,350 --> 00:00:46,440
closer to you than Hawaii and you like

17
00:00:42,510 --> 00:00:50,449
Hawaii great place to go visit and yes

18
00:00:46,440 --> 00:00:50,449
that is a shameless plug for my island

19
00:00:50,660 --> 00:00:56,370
one of the advantages of going in the

20
00:00:53,489 --> 00:00:59,070
afternoon is that I get to build on what

21
00:00:56,370 --> 00:01:00,510
other speakers have said and and I will

22
00:00:59,070 --> 00:01:02,309
do that intentionally and also

23
00:01:00,510 --> 00:01:04,979
unwittingly for some of you that are

24
00:01:02,309 --> 00:01:07,408
collaborators with me this morning

25
00:01:04,979 --> 00:01:10,110
Michael talked about the journey that we

26
00:01:07,409 --> 00:01:13,110
are under at Microsoft with regards to

27
00:01:10,110 --> 00:01:15,450
building our OSS security program and he

28
00:01:13,110 --> 00:01:18,479
talked about the four simple tasks that

29
00:01:15,450 --> 00:01:21,020
we have ahead of us one is identifying

30
00:01:18,479 --> 00:01:24,090
the OSS that has that is being used

31
00:01:21,020 --> 00:01:26,908
cataloging that OSS and then securing

32
00:01:24,090 --> 00:01:28,920
their OSS I'm here to talk about the

33
00:01:26,909 --> 00:01:31,049
fourth one which is really around how do

34
00:01:28,920 --> 00:01:35,220
we respond to security vulnerabilities

35
00:01:31,049 --> 00:01:37,470
in OSS I'm going to part of my focus is

36
00:01:35,220 --> 00:01:39,240
going to be about multi-party OSS

37
00:01:37,470 --> 00:01:42,710
response but I'm also going to talk

38
00:01:39,240 --> 00:01:45,990
about some general OSS response examples

39
00:01:42,710 --> 00:01:47,399
before I do that I do want to do a

40
00:01:45,990 --> 00:01:49,559
little bit of level setting because I

41
00:01:47,399 --> 00:01:51,119
will use some acronyms and they will

42
00:01:49,560 --> 00:01:53,220
feature in my slides so I want to make

43
00:01:51,119 --> 00:01:56,040
sure we're all on the same page

44
00:01:53,220 --> 00:01:58,350
the first one is nsrc which is the

45
00:01:56,040 --> 00:02:00,750
organization that I belong to the

46
00:01:58,350 --> 00:02:03,449
Microsoft Security Response Center we

47
00:02:00,750 --> 00:02:05,570
are the organization that has

48
00:02:03,450 --> 00:02:08,310
responsibility for protecting customers

49
00:02:05,570 --> 00:02:11,579
protecting Microsoft itself and

50
00:02:08,310 --> 00:02:13,530
protecting our brands so no pressure for

51
00:02:11,580 --> 00:02:16,650
this organization of course

52
00:02:13,530 --> 00:02:19,440
and you can think of nsrc as well as the

53
00:02:16,650 --> 00:02:21,930
next team as the piece heard Adobe was

54
00:02:19,440 --> 00:02:24,120
just speaking for pieces that's probably

55
00:02:21,930 --> 00:02:26,190
the most common term that is these

56
00:02:24,120 --> 00:02:28,770
organizations are known by the team that

57
00:02:26,190 --> 00:02:31,140
I represent that I lead portion of is

58
00:02:28,770 --> 00:02:33,420
the vulnerability response and

59
00:02:31,140 --> 00:02:35,369
remediation team we are the team that

60
00:02:33,420 --> 00:02:37,380
takes all of those vulnerability reports

61
00:02:35,370 --> 00:02:39,990
whether it's bounty whether it's

62
00:02:37,380 --> 00:02:41,760
customer or whether it is a security

63
00:02:39,990 --> 00:02:43,980
researcher we run them through our

64
00:02:41,760 --> 00:02:45,959
Security Response process triaging

65
00:02:43,980 --> 00:02:48,269
assessing developing and then obviously

66
00:02:45,959 --> 00:02:51,600
releasing a fix and again those two

67
00:02:48,270 --> 00:02:53,489
teams are normally known as p cert so

68
00:02:51,600 --> 00:02:54,570
you'll see them in in my slides maybe

69
00:02:53,489 --> 00:02:57,660
that's the way you want to think about

70
00:02:54,570 --> 00:03:00,239
it as as I talked about our program the

71
00:02:57,660 --> 00:03:03,450
last the next one is also part of MSR

72
00:03:00,239 --> 00:03:04,920
MSR C which is the SERP team serve as

73
00:03:03,450 --> 00:03:07,560
you see there stands for software and

74
00:03:04,920 --> 00:03:10,799
services incident response plan we

75
00:03:07,560 --> 00:03:13,350
jokingly say the SERP is a noun a bear

76
00:03:10,800 --> 00:03:16,230
of an adjective and an adverb is also a

77
00:03:13,350 --> 00:03:18,359
team this is my previous team we lead

78
00:03:16,230 --> 00:03:21,810
basically Tier three Incident Response

79
00:03:18,360 --> 00:03:24,630
so the highest highest severity response

80
00:03:21,810 --> 00:03:26,730
we do from the serve team and that might

81
00:03:24,630 --> 00:03:29,190
involve some there are strictly product

82
00:03:26,730 --> 00:03:31,679
security and some that are also part of

83
00:03:29,190 --> 00:03:34,350
what is typically a C cert or computer

84
00:03:31,680 --> 00:03:36,180
network security the last organization

85
00:03:34,350 --> 00:03:39,150
that I'll talk about Allen made is a

86
00:03:36,180 --> 00:03:41,700
made-up name the OSS program office

87
00:03:39,150 --> 00:03:43,260
that's basically Michael's umbrella

88
00:03:41,700 --> 00:03:45,510
organization he was speaking this

89
00:03:43,260 --> 00:03:47,640
morning of referred to them for the

90
00:03:45,510 --> 00:03:49,980
benefit of this slide as of this

91
00:03:47,640 --> 00:03:51,750
presentation as the OSS program office

92
00:03:49,980 --> 00:03:56,220
they are a partner and a key component

93
00:03:51,750 --> 00:03:57,690
obviously in our OSS security program to

94
00:03:56,220 --> 00:03:59,519
talked about our journey I'd like to

95
00:03:57,690 --> 00:04:01,890
start by saying you know we've been

96
00:03:59,519 --> 00:04:04,440
looking we we basically pulled into

97
00:04:01,890 --> 00:04:06,000
doing OSS response just because of the

98
00:04:04,440 --> 00:04:08,010
transformation that Microsoft has been

99
00:04:06,000 --> 00:04:09,720
going on there and part of that is

100
00:04:08,010 --> 00:04:11,070
obviously we're releasing a lot more

101
00:04:09,720 --> 00:04:13,410
open source that we were doing before

102
00:04:11,070 --> 00:04:14,730
and we're also adopting a lot more open

103
00:04:13,410 --> 00:04:17,399
source than we were before

104
00:04:14,730 --> 00:04:21,988
to give you a quick data point between

105
00:04:17,399 --> 00:04:25,169
2015 and 2017 so 3 inclusive years we

106
00:04:21,988 --> 00:04:27,479
only had two high severity incidents

107
00:04:25,169 --> 00:04:29,940
involving OSS

108
00:04:27,480 --> 00:04:33,330
and in the year's 2018 and so far in

109
00:04:29,940 --> 00:04:34,170
2019 we have seven or eight depending on

110
00:04:33,330 --> 00:04:36,750
how you count

111
00:04:34,170 --> 00:04:38,910
so major increase for us in terms of the

112
00:04:36,750 --> 00:04:42,360
high severity incidents that also

113
00:04:38,910 --> 00:04:45,180
happens at the at the mid-level that

114
00:04:42,360 --> 00:04:46,980
I'll go into in a minute so we've had to

115
00:04:45,180 --> 00:04:49,110
think about how do we define our

116
00:04:46,980 --> 00:04:51,600
response levels as a product security

117
00:04:49,110 --> 00:04:54,600
response organization and the first

118
00:04:51,600 --> 00:04:58,110
level for us that we define is simply

119
00:04:54,600 --> 00:05:01,830
non no Incident Response responsibility

120
00:04:58,110 --> 00:05:04,350
for nsrc for what will be that third

121
00:05:01,830 --> 00:05:07,050
task in Michaels diagram which is secure

122
00:05:04,350 --> 00:05:09,570
OSS we considered that kind of rhythm of

123
00:05:07,050 --> 00:05:11,510
the business code hygiene the OSS

124
00:05:09,570 --> 00:05:13,800
program office is managing those

125
00:05:11,510 --> 00:05:16,080
vulnerabilities in that process and

126
00:05:13,800 --> 00:05:18,030
maybe we have some documentation that we

127
00:05:16,080 --> 00:05:20,760
need to release but for the most most

128
00:05:18,030 --> 00:05:23,219
part we would not engage the next level

129
00:05:20,760 --> 00:05:24,870
is at high level which is the SERP which

130
00:05:23,220 --> 00:05:28,230
are with there's a very well-defined

131
00:05:24,870 --> 00:05:30,420
criteria for this high-risk incidents

132
00:05:28,230 --> 00:05:33,300
the first criteria is anything that's

133
00:05:30,420 --> 00:05:35,430
under active attack weather whether it's

134
00:05:33,300 --> 00:05:38,460
a Microsoft product or an OSS component

135
00:05:35,430 --> 00:05:39,870
that we happen to consume very clear if

136
00:05:38,460 --> 00:05:43,080
it's under active attack we want to have

137
00:05:39,870 --> 00:05:45,480
a very efficient an urgent response so

138
00:05:43,080 --> 00:05:47,310
that's a very clear sir also any

139
00:05:45,480 --> 00:05:49,080
high-risk Molnar ability that's either

140
00:05:47,310 --> 00:05:51,750
public or about to go public that

141
00:05:49,080 --> 00:05:53,669
affects again one of our products or one

142
00:05:51,750 --> 00:05:56,130
of the components that we use that also

143
00:05:53,670 --> 00:05:58,350
kind of meets that high criteria for

144
00:05:56,130 --> 00:06:00,680
high severity will be declare a SERP and

145
00:05:58,350 --> 00:06:04,260
then anything that has high brand risk

146
00:06:00,680 --> 00:06:06,660
so obviously there's a risk factor here

147
00:06:04,260 --> 00:06:09,300
or an access where we consider the

148
00:06:06,660 --> 00:06:12,020
rhythm of the business secure SS used to

149
00:06:09,300 --> 00:06:15,030
be relatively low risk code hygiene

150
00:06:12,020 --> 00:06:16,890
normal software development we have some

151
00:06:15,030 --> 00:06:19,440
at the high level that are high risk and

152
00:06:16,890 --> 00:06:21,810
then this is a part that we're kind of

153
00:06:19,440 --> 00:06:23,940
fine-tuning still which is what is that

154
00:06:21,810 --> 00:06:26,460
what we call the faucet middle where is

155
00:06:23,940 --> 00:06:31,410
that responsibility where we as a pisser

156
00:06:26,460 --> 00:06:33,210
can add value to OSS response and I'll

157
00:06:31,410 --> 00:06:36,680
be happy to talk to people today in the

158
00:06:33,210 --> 00:06:39,270
low or later if you have a clear magic

159
00:06:36,680 --> 00:06:41,340
formula for where that fits in your

160
00:06:39,270 --> 00:06:43,349
organization because we're certainly

161
00:06:41,340 --> 00:06:45,030
still struggling with what is the right

162
00:06:43,350 --> 00:06:47,310
balance and at the end of the day

163
00:06:45,030 --> 00:06:50,580
becomes a matter of resources you have

164
00:06:47,310 --> 00:06:52,440
limited resources limited responders so

165
00:06:50,580 --> 00:06:54,690
you cannot just tackle everything that's

166
00:06:52,440 --> 00:06:55,979
why we have the OSS program office

167
00:06:54,690 --> 00:06:59,310
building some tooling and some

168
00:06:55,979 --> 00:07:01,080
programmatic efforts but we also cannot

169
00:06:59,310 --> 00:07:02,790
treat everything like a SERP again we

170
00:07:01,080 --> 00:07:05,010
have limited resources are very

171
00:07:02,790 --> 00:07:06,750
expensive so we want to be somewhere in

172
00:07:05,010 --> 00:07:09,750
the middle we know there's some obvious

173
00:07:06,750 --> 00:07:11,970
cases like if a security researcher

174
00:07:09,750 --> 00:07:15,060
finds a vulnerability in an open source

175
00:07:11,970 --> 00:07:16,380
component and reports that we because we

176
00:07:15,060 --> 00:07:18,419
are using that component we are

177
00:07:16,380 --> 00:07:20,550
vulnerable that's very clearly something

178
00:07:18,419 --> 00:07:22,620
that we will get engaged if it's

179
00:07:20,550 --> 00:07:24,030
privately reported no need to be a SERP

180
00:07:22,620 --> 00:07:26,010
we can just manage that through our

181
00:07:24,030 --> 00:07:28,500
traditional product Security Response

182
00:07:26,010 --> 00:07:30,389
process but there are many weird

183
00:07:28,500 --> 00:07:32,900
scenarios that we're still struggling

184
00:07:30,389 --> 00:07:37,260
with what is the right level of response

185
00:07:32,900 --> 00:07:38,940
and when we look at that response level

186
00:07:37,260 --> 00:07:41,969
we also see that it's not going to be a

187
00:07:38,940 --> 00:07:44,160
very clear one organization has or one

188
00:07:41,970 --> 00:07:47,100
team has responsibility for driving it

189
00:07:44,160 --> 00:07:49,770
depending on the severity or the type of

190
00:07:47,100 --> 00:07:52,200
issue but in reality we are all going to

191
00:07:49,770 --> 00:07:54,359
be working together and so on in most of

192
00:07:52,200 --> 00:07:57,450
the scenarios so I try to represent that

193
00:07:54,360 --> 00:07:59,400
with this diagram and I like to say that

194
00:07:57,450 --> 00:08:01,770
the bubbles are representative but in

195
00:07:59,400 --> 00:08:05,880
reality they're not because that orange

196
00:08:01,770 --> 00:08:07,409
OS SPO office will be a lot larger as as

197
00:08:05,880 --> 00:08:09,030
Michael showed this morning there's a

198
00:08:07,410 --> 00:08:12,599
lotta balloon er abilities that need to

199
00:08:09,030 --> 00:08:14,130
be resolved for many of our products but

200
00:08:12,599 --> 00:08:16,530
it just wouldn't work out in the short

201
00:08:14,130 --> 00:08:19,740
so just think that in relationship

202
00:08:16,530 --> 00:08:20,760
there's a lot more um OSS program office

203
00:08:19,740 --> 00:08:22,889
will need abilities that they're

204
00:08:20,760 --> 00:08:25,590
managing there's a lot less on the SERP

205
00:08:22,889 --> 00:08:30,090
side again the high severity incidents

206
00:08:25,590 --> 00:08:33,510
so that big area of the Venn diagram is

207
00:08:30,090 --> 00:08:35,490
obviously that secure OSS tasks that

208
00:08:33,510 --> 00:08:37,559
Michael talked about and those will be

209
00:08:35,490 --> 00:08:39,779
managed by the OSS program office

210
00:08:37,559 --> 00:08:42,750
they'll be absolutely no nsrc engagement

211
00:08:39,779 --> 00:08:44,939
now there is that area where we will

212
00:08:42,750 --> 00:08:47,310
interface with the OSS program office

213
00:08:44,940 --> 00:08:49,260
and again the most common scenario will

214
00:08:47,310 --> 00:08:54,410
be a finder that reports a vulnerability

215
00:08:49,260 --> 00:08:56,840
in 100s S component we will use the pro

216
00:08:54,410 --> 00:08:59,510
and the tooling built by the OSS program

217
00:08:56,840 --> 00:09:02,300
office to find who's vulnerable and then

218
00:08:59,510 --> 00:09:04,030
get them into a remediation path the

219
00:09:02,300 --> 00:09:07,099
other the bullet number three there

220
00:09:04,030 --> 00:09:09,079
Michael alluded to it this morning this

221
00:09:07,100 --> 00:09:11,620
is a microscope owner ability reporting

222
00:09:09,080 --> 00:09:14,690
program and it's basically if any

223
00:09:11,620 --> 00:09:16,880
engineer or security professional and

224
00:09:14,690 --> 00:09:20,150
Microsoft finds a security vulnerability

225
00:09:16,880 --> 00:09:22,430
in a third-party component we don't want

226
00:09:20,150 --> 00:09:24,439
them to be reporting to the maintainer

227
00:09:22,430 --> 00:09:26,780
sort to a different organization if it's

228
00:09:24,440 --> 00:09:28,940
not always as but a third party we want

229
00:09:26,780 --> 00:09:31,160
to manage that to the nsrc so that's

230
00:09:28,940 --> 00:09:34,010
another instance where we take the

231
00:09:31,160 --> 00:09:35,810
report from the engineer or the team

232
00:09:34,010 --> 00:09:38,360
that found it and we communicate with

233
00:09:35,810 --> 00:09:41,239
the maintainer or with the company to

234
00:09:38,360 --> 00:09:43,850
get remediation there the other two

235
00:09:41,240 --> 00:09:45,400
areas of overlap is very clear hey

236
00:09:43,850 --> 00:09:49,310
there's a high severity

237
00:09:45,400 --> 00:09:52,520
incident we will jointly address this

238
00:09:49,310 --> 00:09:55,400
high severity high risk scenario and the

239
00:09:52,520 --> 00:09:59,630
last one hopefully will disappear over

240
00:09:55,400 --> 00:10:02,569
time which is the scenario of somebody

241
00:09:59,630 --> 00:10:04,730
has proven OSS vulnerability effects on

242
00:10:02,570 --> 00:10:08,000
Microsoft product but when we go to the

243
00:10:04,730 --> 00:10:10,580
tooling and the catalog of OSS the micro

244
00:10:08,000 --> 00:10:12,590
has build that team has built we don't

245
00:10:10,580 --> 00:10:15,110
show that we're using that anywhere so

246
00:10:12,590 --> 00:10:17,060
we don't know really the scope of the

247
00:10:15,110 --> 00:10:19,220
products that are affected we might know

248
00:10:17,060 --> 00:10:20,959
one instance that was reported to us but

249
00:10:19,220 --> 00:10:22,910
there is more and that's really the

250
00:10:20,960 --> 00:10:26,000
Scramble scenario where we need to go

251
00:10:22,910 --> 00:10:29,000
find who could be affected in this large

252
00:10:26,000 --> 00:10:31,100
software base that we that we own so

253
00:10:29,000 --> 00:10:32,480
those are the response relationships now

254
00:10:31,100 --> 00:10:35,090
I'd like to run through some cases just

255
00:10:32,480 --> 00:10:36,980
to basically share the lessons that we

256
00:10:35,090 --> 00:10:39,440
have learned as well as the struggles

257
00:10:36,980 --> 00:10:42,140
that we have had over over this time and

258
00:10:39,440 --> 00:10:44,620
again I welcome our experiences and

259
00:10:42,140 --> 00:10:47,540
sharing of ideas when it comes to this

260
00:10:44,620 --> 00:10:49,460
rather because I only have limited time

261
00:10:47,540 --> 00:10:51,890
I'm going to start with some of the key

262
00:10:49,460 --> 00:10:54,050
takeaways that hopefully you will see in

263
00:10:51,890 --> 00:10:56,360
the cases that I've run through rather

264
00:10:54,050 --> 00:10:59,660
than walk you through the cases and then

265
00:10:56,360 --> 00:11:01,550
hope that you extract the the lessons so

266
00:10:59,660 --> 00:11:03,680
the first one is especially when it

267
00:11:01,550 --> 00:11:07,040
comes to multi-party response is be

268
00:11:03,680 --> 00:11:07,939
ready to compromise for example one very

269
00:11:07,040 --> 00:11:09,469
simple

270
00:11:07,939 --> 00:11:11,299
instance of that is we have a posh

271
00:11:09,470 --> 00:11:13,669
Tuesday in Microsoft does the day we

272
00:11:11,299 --> 00:11:16,639
release other companies have patched

273
00:11:13,669 --> 00:11:18,919
Wednesday Oh II am Monday some companies

274
00:11:16,639 --> 00:11:21,259
do it once a quarter so just in the

275
00:11:18,919 --> 00:11:22,789
release timeline perspective just be

276
00:11:21,259 --> 00:11:24,499
ready to compromise because it will

277
00:11:22,789 --> 00:11:27,199
happen when you're working with multiple

278
00:11:24,499 --> 00:11:30,619
parties when it comes to your

279
00:11:27,199 --> 00:11:33,319
engineering teams there you still

280
00:11:30,619 --> 00:11:35,929
receiving a POC and several speakers

281
00:11:33,319 --> 00:11:37,878
have talked about just because there's a

282
00:11:35,929 --> 00:11:39,529
vulnerability in an OSS component

283
00:11:37,879 --> 00:11:41,299
doesn't mean that your product is

284
00:11:39,529 --> 00:11:43,519
affected or it doesn't mean that the

285
00:11:41,299 --> 00:11:45,379
severity is high enough in your product

286
00:11:43,519 --> 00:11:48,319
just because the separate is high in the

287
00:11:45,379 --> 00:11:50,689
OSS component that's very real for us

288
00:11:48,319 --> 00:11:53,238
and it's also very expensive and

289
00:11:50,689 --> 00:11:55,429
time-consuming to try to figure out what

290
00:11:53,239 --> 00:11:58,069
is the actual impact to your product of

291
00:11:55,429 --> 00:12:00,289
this third-party OSS dependency that you

292
00:11:58,069 --> 00:12:01,878
may have you know three levels down so

293
00:12:00,289 --> 00:12:03,709
the fact that there is no POC is

294
00:12:01,879 --> 00:12:06,079
something that we have had to train our

295
00:12:03,709 --> 00:12:08,388
teams to accept because they're used to

296
00:12:06,079 --> 00:12:12,108
having Park for all the traditional

297
00:12:08,389 --> 00:12:14,659
vulnerabilities that we get reported so

298
00:12:12,109 --> 00:12:17,149
it's a it's being a culture change the

299
00:12:14,659 --> 00:12:19,189
third one is especially for multi-party

300
00:12:17,149 --> 00:12:21,859
response is you know be part of the

301
00:12:19,189 --> 00:12:24,738
community use events like this to

302
00:12:21,859 --> 00:12:26,899
increase your contact your contacts or

303
00:12:24,739 --> 00:12:28,579
other companies because especially when

304
00:12:26,899 --> 00:12:31,099
it's multi-party a lot of it is

305
00:12:28,579 --> 00:12:33,019
dependent on trust I think you all know

306
00:12:31,099 --> 00:12:36,169
in this industry Trust is highly

307
00:12:33,019 --> 00:12:39,079
valuable and we depend on trust in many

308
00:12:36,169 --> 00:12:40,970
ways so you see any opportunity you have

309
00:12:39,079 --> 00:12:42,919
to build your contacts develop

310
00:12:40,970 --> 00:12:45,979
relationships because they'll come very

311
00:12:42,919 --> 00:12:47,569
very handy when it comes to multi-party

312
00:12:45,979 --> 00:12:50,779
response and we'll see that in a couple

313
00:12:47,569 --> 00:12:53,299
of the examples there will be an

314
00:12:50,779 --> 00:12:54,529
efficiencies to start I won't go into

315
00:12:53,299 --> 00:12:55,819
detail because we're gonna see one

316
00:12:54,529 --> 00:12:59,089
example of that

317
00:12:55,819 --> 00:13:01,309
OPSEC personal pet peeve pinging both in

318
00:12:59,089 --> 00:13:03,739
multi-party situations where something

319
00:13:01,309 --> 00:13:05,929
leaks that's extremely painful for

320
00:13:03,739 --> 00:13:09,079
everybody involved and nothing will pick

321
00:13:05,929 --> 00:13:11,179
you out of the trust circle faster than

322
00:13:09,079 --> 00:13:12,799
just not having to rob sack and having

323
00:13:11,179 --> 00:13:16,519
information leak when you're trying to

324
00:13:12,799 --> 00:13:18,379
solve a high severity incident another

325
00:13:16,519 --> 00:13:19,999
at somebody else mentioned this I think

326
00:13:18,379 --> 00:13:21,440
it may have been over what they assign

327
00:13:19,999 --> 00:13:24,350
like a team owner to

328
00:13:21,440 --> 00:13:26,780
a OSS component we have used this as

329
00:13:24,350 --> 00:13:29,900
well and it's proven helpful for us I'll

330
00:13:26,780 --> 00:13:33,350
actually show one example of this and

331
00:13:29,900 --> 00:13:36,110
the last you know stay stay up to speed

332
00:13:33,350 --> 00:13:37,430
with the high changing OSS world I don't

333
00:13:36,110 --> 00:13:39,800
think I have to tell you that you

334
00:13:37,430 --> 00:13:42,560
probably know this better than I do if I

335
00:13:39,800 --> 00:13:45,260
could add one that I regret not put in

336
00:13:42,560 --> 00:13:48,380
there is defined your response levels

337
00:13:45,260 --> 00:13:50,120
one of my first slides just be very good

338
00:13:48,380 --> 00:13:51,950
about defining what are your response

339
00:13:50,120 --> 00:13:54,020
levels if you're in the product security

340
00:13:51,950 --> 00:13:56,570
response because again you have limited

341
00:13:54,020 --> 00:13:58,510
resources you cannot possibly take

342
00:13:56,570 --> 00:14:01,040
everything I'm dying to talk to

343
00:13:58,510 --> 00:14:05,180
Christine to understand how they do 900

344
00:14:01,040 --> 00:14:07,910
a year so I'll be talking to you in the

345
00:14:05,180 --> 00:14:10,400
luau we've seen ok

346
00:14:07,910 --> 00:14:11,870
so let's run through some cases I added

347
00:14:10,400 --> 00:14:14,959
this one last night based on some

348
00:14:11,870 --> 00:14:16,790
discussions that I heard in in the

349
00:14:14,960 --> 00:14:20,090
conference so far the issue were

350
00:14:16,790 --> 00:14:23,959
electron here was in 2017

351
00:14:20,090 --> 00:14:26,510
there was a internal demo days security

352
00:14:23,960 --> 00:14:29,870
training day and one of our red teamers

353
00:14:26,510 --> 00:14:32,750
just basically owned one of our products

354
00:14:29,870 --> 00:14:36,080
by exploiting an RC vulnerability in

355
00:14:32,750 --> 00:14:38,270
electron and we have some of our

356
00:14:36,080 --> 00:14:41,090
corporate security folks attending that

357
00:14:38,270 --> 00:14:42,980
session and they merely email oh say oh

358
00:14:41,090 --> 00:14:45,350
my god we you guys need to declare a

359
00:14:42,980 --> 00:14:48,800
serpent or a high risk incident because

360
00:14:45,350 --> 00:14:51,440
of this one demo and we saw it and we

361
00:14:48,800 --> 00:14:53,540
said no this is just normal code hygiene

362
00:14:51,440 --> 00:14:55,910
they're using an old version of electron

363
00:14:53,540 --> 00:14:58,880
that just need to update it's secure OSS

364
00:14:55,910 --> 00:15:00,860
and they came back and said no you don't

365
00:14:58,880 --> 00:15:03,710
understand like there are multiple

366
00:15:00,860 --> 00:15:06,740
products that are using electron and

367
00:15:03,710 --> 00:15:08,600
they're all very outdated and they send

368
00:15:06,740 --> 00:15:09,860
us this table and I change the name of

369
00:15:08,600 --> 00:15:11,690
the product because I didn't want to

370
00:15:09,860 --> 00:15:14,930
shame anyone so I just put the category

371
00:15:11,690 --> 00:15:17,240
of product and they send us this list

372
00:15:14,930 --> 00:15:19,219
that send us how old these products or

373
00:15:17,240 --> 00:15:22,270
the component that they were using where

374
00:15:19,220 --> 00:15:25,339
and of course now we have this demo of

375
00:15:22,270 --> 00:15:27,620
owning one of our products and then they

376
00:15:25,339 --> 00:15:29,060
said and by the way we don't think this

377
00:15:27,620 --> 00:15:31,670
is all-inclusive we think there's more

378
00:15:29,060 --> 00:15:33,530
so ultimately we they declare again a

379
00:15:31,670 --> 00:15:35,089
high severity incident a serve we

380
00:15:33,530 --> 00:15:38,149
uncovered 14 prod

381
00:15:35,089 --> 00:15:39,829
that were using electron internally six

382
00:15:38,149 --> 00:15:41,809
different versions of electrons they

383
00:15:39,829 --> 00:15:45,620
were all over electron they were all

384
00:15:41,809 --> 00:15:47,540
very outdated carrying a lot of risk so

385
00:15:45,620 --> 00:15:49,699
we declare an incident with a very clear

386
00:15:47,540 --> 00:15:51,430
goal let's get all of those products

387
00:15:49,699 --> 00:15:54,620
updated to the latest stable version

388
00:15:51,430 --> 00:15:56,660
let's get some kind of commitment to a

389
00:15:54,620 --> 00:15:58,040
maintenance schedule so that we don't

390
00:15:56,660 --> 00:15:59,959
get into this situation again and

391
00:15:58,040 --> 00:16:02,029
through that process we actually had a

392
00:15:59,959 --> 00:16:03,888
team step up and said you know what we

393
00:16:02,029 --> 00:16:06,110
are the most current right now we have

394
00:16:03,889 --> 00:16:07,850
the most vested in this product we're

395
00:16:06,110 --> 00:16:09,980
actually going to maintain a Microsoft

396
00:16:07,850 --> 00:16:14,420
built of electron and we're going to

397
00:16:09,980 --> 00:16:16,639
invest in improving the security

398
00:16:14,420 --> 00:16:18,529
guarantees of electron and they met with

399
00:16:16,639 --> 00:16:20,870
the maintainer x' and that's actually

400
00:16:18,529 --> 00:16:23,209
worked out really well for us having

401
00:16:20,870 --> 00:16:25,100
this approach now there is not mandated

402
00:16:23,209 --> 00:16:27,109
that every team has to use it but it's

403
00:16:25,100 --> 00:16:29,389
highly recommended and many of them have

404
00:16:27,110 --> 00:16:33,470
I don't know if all of them have by this

405
00:16:29,389 --> 00:16:36,620
point so I'll talk about this one the CV

406
00:16:33,470 --> 00:16:38,930
is related to pop s s this is this

407
00:16:36,620 --> 00:16:41,569
really falls in the category of not

408
00:16:38,930 --> 00:16:44,029
really an OSS issue per se not really

409
00:16:41,569 --> 00:16:47,540
third party but more about collaboration

410
00:16:44,029 --> 00:16:50,779
between private companies OSS maintainer

411
00:16:47,540 --> 00:16:53,329
z' and companies that use OSS and this

412
00:16:50,779 --> 00:16:57,620
was an issue that affected really x86

413
00:16:53,329 --> 00:17:00,349
hardware but it was a bad implementation

414
00:16:57,620 --> 00:17:03,529
or a bad understanding of the software

415
00:17:00,350 --> 00:17:08,449
development manner of x86 that basically

416
00:17:03,529 --> 00:17:11,179
led to an issue in in Hardware D box so

417
00:17:08,449 --> 00:17:13,579
we checked the the issue with this

418
00:17:11,179 --> 00:17:15,049
interestingly enough is that we somebody

419
00:17:13,579 --> 00:17:18,139
in Microsoft discovered this in the

420
00:17:15,049 --> 00:17:21,589
summer of 2017 and at that point they

421
00:17:18,140 --> 00:17:23,659
said hey we cannot do we cannot take

422
00:17:21,589 --> 00:17:25,158
action because we think other parties

423
00:17:23,659 --> 00:17:28,309
will be affected so we really need to

424
00:17:25,159 --> 00:17:30,850
coordinate with lay notes we might need

425
00:17:28,309 --> 00:17:33,408
to coordinate with hypervisors etc and

426
00:17:30,850 --> 00:17:34,459
if you know what was happening in at the

427
00:17:33,409 --> 00:17:36,049
end of 2017

428
00:17:34,460 --> 00:17:37,909
we were also really scrambling with

429
00:17:36,049 --> 00:17:39,500
specter and meltdown we were actually

430
00:17:37,909 --> 00:17:41,840
working with a lot of the companies that

431
00:17:39,500 --> 00:17:44,270
would be affected by this so we said

432
00:17:41,840 --> 00:17:47,899
okay sure we'll do that but we kind of

433
00:17:44,270 --> 00:17:48,980
parted priority wise and then fast

434
00:17:47,899 --> 00:17:51,800
forward to 28

435
00:17:48,980 --> 00:17:55,460
and in the March timeframe late March

436
00:17:51,800 --> 00:17:57,590
timeframe we get a notification from

437
00:17:55,460 --> 00:17:59,930
Intel and almost at the same time by the

438
00:17:57,590 --> 00:18:03,110
linux foundation saying hey we uncovered

439
00:17:59,930 --> 00:18:04,640
this issue we think you're affected we

440
00:18:03,110 --> 00:18:06,500
checked that into the Linux kernel but

441
00:18:04,640 --> 00:18:08,450
you should really look into it and then

442
00:18:06,500 --> 00:18:09,770
we realize wow we've been this is the

443
00:18:08,450 --> 00:18:10,610
thing that we knew we've been sitting on

444
00:18:09,770 --> 00:18:12,350
this for a while

445
00:18:10,610 --> 00:18:14,629
now they've checked it in so we're about

446
00:18:12,350 --> 00:18:18,080
to be all day and so will many other

447
00:18:14,630 --> 00:18:19,790
parties like VMware San etc so we need

448
00:18:18,080 --> 00:18:21,919
to coordinate together and that's

449
00:18:19,790 --> 00:18:25,100
basically what happened at at the end of

450
00:18:21,920 --> 00:18:26,810
March early April we got a coalition

451
00:18:25,100 --> 00:18:29,600
together we briefed on what the issue

452
00:18:26,810 --> 00:18:32,149
was locally the checked-in didn't have a

453
00:18:29,600 --> 00:18:35,870
lot of details and we were able to all

454
00:18:32,150 --> 00:18:38,660
of us go out together in early May with

455
00:18:35,870 --> 00:18:41,570
a fix for this issue we got a lot of

456
00:18:38,660 --> 00:18:43,760
praise from from the media as an

457
00:18:41,570 --> 00:18:46,939
industry collaborating together and

458
00:18:43,760 --> 00:18:50,960
releasing a fix at the same time the

459
00:18:46,940 --> 00:18:53,600
next issue is sip Lib this was

460
00:18:50,960 --> 00:18:57,740
interesting from the point of view of we

461
00:18:53,600 --> 00:18:59,570
got notified in May that the researcher

462
00:18:57,740 --> 00:19:03,410
that uncovered this issue was going to

463
00:18:59,570 --> 00:19:05,540
go public in June and it was really

464
00:19:03,410 --> 00:19:07,490
interesting report for us because he

465
00:19:05,540 --> 00:19:09,560
said I don't think you're affected but

466
00:19:07,490 --> 00:19:12,320
you have some code snippets in your

467
00:19:09,560 --> 00:19:14,240
documentation online in this link that

468
00:19:12,320 --> 00:19:17,270
lead me to believe you might want to

469
00:19:14,240 --> 00:19:20,450
look into this at least or listen your

470
00:19:17,270 --> 00:19:23,750
sample code snippets and that report

471
00:19:20,450 --> 00:19:25,460
came in and if if you've been ever in

472
00:19:23,750 --> 00:19:27,050
the public security response side you'll

473
00:19:25,460 --> 00:19:30,560
see you get a lot of reports that are

474
00:19:27,050 --> 00:19:32,899
you know really bad quality reports or

475
00:19:30,560 --> 00:19:35,629
there's just not real issues here we get

476
00:19:32,900 --> 00:19:37,670
one that's not really a report against a

477
00:19:35,630 --> 00:19:41,510
product it's just saying hey in this

478
00:19:37,670 --> 00:19:44,030
documentation you have some sample code

479
00:19:41,510 --> 00:19:46,610
snippets that illustrate that this

480
00:19:44,030 --> 00:19:48,320
condition could be applicable so we

481
00:19:46,610 --> 00:19:49,909
actually had a fault there that we

482
00:19:48,320 --> 00:19:53,600
didn't quite know how to handle that

483
00:19:49,910 --> 00:19:56,750
issue the issue got a lot more attention

484
00:19:53,600 --> 00:19:58,969
once it got once it became public in

485
00:19:56,750 --> 00:20:00,830
June and we started just asking

486
00:19:58,970 --> 00:20:01,770
questions hey where is this in the

487
00:20:00,830 --> 00:20:04,770
company

488
00:20:01,770 --> 00:20:07,020
and the long story short here is by the

489
00:20:04,770 --> 00:20:08,879
time you like him around we didn't

490
00:20:07,020 --> 00:20:11,910
really have a good story about that

491
00:20:08,880 --> 00:20:14,400
report and what our impact was so once

492
00:20:11,910 --> 00:20:18,120
again we declare a SERP a high severity

493
00:20:14,400 --> 00:20:19,860
incident and we through the OSS program

494
00:20:18,120 --> 00:20:23,280
office we couldn't really get much out

495
00:20:19,860 --> 00:20:24,750
of the tools that we had so our team our

496
00:20:23,280 --> 00:20:26,540
dawnette team which was the most

497
00:20:24,750 --> 00:20:28,680
knowledgeable and impacted by this

498
00:20:26,540 --> 00:20:30,300
basically built guidance like the one

499
00:20:28,680 --> 00:20:33,240
that I'm showing you here on the slide

500
00:20:30,300 --> 00:20:34,649
and we basically had to use all of the

501
00:20:33,240 --> 00:20:36,780
Incident Response Teams that we have

502
00:20:34,650 --> 00:20:39,300
spread out in the company to try to

503
00:20:36,780 --> 00:20:41,910
figure out who is affected by this one

504
00:20:39,300 --> 00:20:44,129
issue and we provided some guidance as

505
00:20:41,910 --> 00:20:45,900
you can see there there were some other

506
00:20:44,130 --> 00:20:47,970
guidance in the bottom about next steps

507
00:20:45,900 --> 00:20:50,220
and what to do if you if you thought you

508
00:20:47,970 --> 00:20:52,200
were vulnerable but this is the very

509
00:20:50,220 --> 00:20:54,660
high tech way that we have to go find

510
00:20:52,200 --> 00:20:56,820
who was vulnerable basically write a

511
00:20:54,660 --> 00:20:59,810
document email a bunch of teams have

512
00:20:56,820 --> 00:21:03,300
them email other teams until we found

513
00:20:59,810 --> 00:21:06,000
one team that was impacted and we ended

514
00:21:03,300 --> 00:21:09,840
up releasing a fix in November of that

515
00:21:06,000 --> 00:21:12,090
year so the issue went public in June we

516
00:21:09,840 --> 00:21:14,939
release a fix for our affected product

517
00:21:12,090 --> 00:21:16,820
in November certainly certainly not

518
00:21:14,940 --> 00:21:19,020
ideal

519
00:21:16,820 --> 00:21:21,600
I'll finish I think this is the last

520
00:21:19,020 --> 00:21:24,720
example that I have this is another one

521
00:21:21,600 --> 00:21:27,209
of those of multi-party coordination who

522
00:21:24,720 --> 00:21:30,900
he remembers fragments Mac and segments

523
00:21:27,210 --> 00:21:33,560
Mac I see a couple knots so this was

524
00:21:30,900 --> 00:21:36,180
interesting it's a do s in the way IP

525
00:21:33,560 --> 00:21:38,520
fragments are handled there's two

526
00:21:36,180 --> 00:21:40,650
different ones we were only affected by

527
00:21:38,520 --> 00:21:44,370
the IP one we were not affected by the

528
00:21:40,650 --> 00:21:47,160
TCP one and this one was interesting

529
00:21:44,370 --> 00:21:49,949
because we received a report through

530
00:21:47,160 --> 00:21:52,770
from the researcher and we were working

531
00:21:49,950 --> 00:21:55,530
it through our normal cycle which is

532
00:21:52,770 --> 00:21:57,540
between 90 to 120 days is when we

533
00:21:55,530 --> 00:21:59,879
release fixes for something in the

534
00:21:57,540 --> 00:22:02,010
windows world so we were working that

535
00:21:59,880 --> 00:22:04,620
our normal pace thinking okay we have

536
00:22:02,010 --> 00:22:06,450
time and then all of a sudden we Google

537
00:22:04,620 --> 00:22:07,949
again through relationships that we had

538
00:22:06,450 --> 00:22:10,190
established with Google they brought out

539
00:22:07,950 --> 00:22:13,580
brought us into this multi particle

540
00:22:10,190 --> 00:22:15,630
conversation with other vendors and

541
00:22:13,580 --> 00:22:17,790
turns out that there was very

542
00:22:15,630 --> 00:22:19,950
risk that these issues were going to go

543
00:22:17,790 --> 00:22:22,050
public to the point that all of these

544
00:22:19,950 --> 00:22:27,810
companies were planning and I'm say

545
00:22:22,050 --> 00:22:30,210
companies I mean net bsd or FreeBSD Red

546
00:22:27,810 --> 00:22:32,580
Hat Google obviously and many others

547
00:22:30,210 --> 00:22:34,740
were planning to go public because they

548
00:22:32,580 --> 00:22:36,780
sense that there was a lot of chartres

549
00:22:34,740 --> 00:22:39,450
around this and people were discovering

550
00:22:36,780 --> 00:22:41,460
it and how we not had this relationships

551
00:22:39,450 --> 00:22:43,440
established already we will not have

552
00:22:41,460 --> 00:22:45,690
found out and we will basically have

553
00:22:43,440 --> 00:22:50,300
been all day now with technically we

554
00:22:45,690 --> 00:22:53,640
still we're but they were kind enough to

555
00:22:50,300 --> 00:22:55,770
hold some documentation for the issue

556
00:22:53,640 --> 00:22:57,450
that we were affected by until we were

557
00:22:55,770 --> 00:22:59,850
able to release in September we

558
00:22:57,450 --> 00:23:01,230
accelerated our cycle we were able to

559
00:22:59,850 --> 00:23:04,620
release in September

560
00:23:01,230 --> 00:23:08,910
most of them released mostly silently in

561
00:23:04,620 --> 00:23:10,800
August the net result was for us we flew

562
00:23:08,910 --> 00:23:13,410
under the radar there was no coverage

563
00:23:10,800 --> 00:23:15,120
about us being affected and there were

564
00:23:13,410 --> 00:23:16,620
no attacks against more importantly

565
00:23:15,120 --> 00:23:19,919
there were no attacks against any of our

566
00:23:16,620 --> 00:23:22,020
customers so overall a big win and it

567
00:23:19,920 --> 00:23:24,180
was all again a result of just having

568
00:23:22,020 --> 00:23:27,150
these relationships as establish and

569
00:23:24,180 --> 00:23:30,240
getting early early heads up oh I do

570
00:23:27,150 --> 00:23:33,270
have one more front see this one was

571
00:23:30,240 --> 00:23:35,730
very very recent who here was involved

572
00:23:33,270 --> 00:23:38,220
or knows about the front C issue okay

573
00:23:35,730 --> 00:23:40,050
several as well right so we were

574
00:23:38,220 --> 00:23:42,000
notified by the maintainer and this one

575
00:23:40,050 --> 00:23:44,760
I don't think it has a I have a

576
00:23:42,000 --> 00:23:46,680
screenshot here yeah I took it out it

577
00:23:44,760 --> 00:23:48,810
was so much similar to the SIB lip in

578
00:23:46,680 --> 00:23:51,390
the in the in the sense of and again

579
00:23:48,810 --> 00:23:54,149
talking about efficiency the first-ever

580
00:23:51,390 --> 00:23:56,880
case that we get for forefront see

581
00:23:54,150 --> 00:23:58,470
so we're as incident responders product

582
00:23:56,880 --> 00:24:00,420
security response professionals were

583
00:23:58,470 --> 00:24:02,160
like okay run see I kinda know what that

584
00:24:00,420 --> 00:24:04,260
is so we have to kind of learn what is

585
00:24:02,160 --> 00:24:07,200
run see in the process of responding and

586
00:24:04,260 --> 00:24:09,450
and then figure out okay who could be

587
00:24:07,200 --> 00:24:11,070
affected on Microsoft we again start

588
00:24:09,450 --> 00:24:13,680
that process this is one where we

589
00:24:11,070 --> 00:24:16,770
leverage heavily the OS OSS program

590
00:24:13,680 --> 00:24:18,780
office and eventually we we landed on on

591
00:24:16,770 --> 00:24:21,450
a very long list of teams that were

592
00:24:18,780 --> 00:24:24,180
affected but in reality only really one

593
00:24:21,450 --> 00:24:28,350
that needed to ship a fix the other ones

594
00:24:24,180 --> 00:24:29,520
just basically needed to patch and we

595
00:24:28,350 --> 00:24:33,330
have one month no

596
00:24:29,520 --> 00:24:35,129
and the message was hey we're going to

597
00:24:33,330 --> 00:24:37,439
go live in about a month it was like

598
00:24:35,130 --> 00:24:38,880
three and a half weeks but we're not

599
00:24:37,440 --> 00:24:40,950
sure the date because there multiple

600
00:24:38,880 --> 00:24:44,520
parties are affected so we're waiting to

601
00:24:40,950 --> 00:24:45,809
hear what is the right date so obvious

602
00:24:44,520 --> 00:24:48,059
you get a message like that you know

603
00:24:45,809 --> 00:24:49,710
that multiple parties know so you need

604
00:24:48,059 --> 00:24:51,540
to act fast because there's higher risk

605
00:24:49,710 --> 00:24:53,940
that things will go public but again

606
00:24:51,540 --> 00:24:55,678
you're getting notice ahead of time so

607
00:24:53,940 --> 00:24:58,140
at least you're not getting all date and

608
00:24:55,679 --> 00:25:00,420
you can work on accelerated timelines

609
00:24:58,140 --> 00:25:03,270
and ultimately we were able to release

610
00:25:00,420 --> 00:25:06,030
right on time without any measure any

611
00:25:03,270 --> 00:25:07,920
major incident so I'll go I like to go

612
00:25:06,030 --> 00:25:09,330
back to these key takeaways and

613
00:25:07,920 --> 00:25:13,530
learnings and just add a little bit more

614
00:25:09,330 --> 00:25:15,809
context and especially with the with the

615
00:25:13,530 --> 00:25:17,610
incidents that we just went through so

616
00:25:15,809 --> 00:25:19,559
be ready to compromise if you're in a

617
00:25:17,610 --> 00:25:21,540
multi-party situation please be ready to

618
00:25:19,559 --> 00:25:24,030
compromise and know that that's the

619
00:25:21,540 --> 00:25:26,070
nature of the business we've been in

620
00:25:24,030 --> 00:25:28,800
situations at Microsoft where we have

621
00:25:26,070 --> 00:25:30,870
had to release fixes silently which we

622
00:25:28,800 --> 00:25:34,230
hate to do but we've done it in order to

623
00:25:30,870 --> 00:25:36,570
maintain the ecosystem safe we have had

624
00:25:34,230 --> 00:25:38,640
other parties do the same for us

625
00:25:36,570 --> 00:25:40,139
it's kind of the nature of the game and

626
00:25:38,640 --> 00:25:44,340
it works really well to protect again

627
00:25:40,140 --> 00:25:46,470
the ecosystem there is no park this is

628
00:25:44,340 --> 00:25:49,230
more of an internal issue with your

629
00:25:46,470 --> 00:25:50,820
teams that you have to deal with if

630
00:25:49,230 --> 00:25:53,070
they're especially they're used to like

631
00:25:50,820 --> 00:25:54,870
our teens are in receiving a park we are

632
00:25:53,070 --> 00:25:57,360
very clear detailed explanation of the

633
00:25:54,870 --> 00:26:00,209
issue when something hits the fan and in

634
00:25:57,360 --> 00:26:01,949
the open source world you will not more

635
00:26:00,210 --> 00:26:03,890
than likely you will not have a park to

636
00:26:01,950 --> 00:26:08,280
prove that your product is affected and

637
00:26:03,890 --> 00:26:09,960
team to complain but you trying to again

638
00:26:08,280 --> 00:26:13,500
minimize the potential risks since

639
00:26:09,960 --> 00:26:15,270
proving the negative is so hard be part

640
00:26:13,500 --> 00:26:17,250
of any response communities I just went

641
00:26:15,270 --> 00:26:18,660
through a few examples of that a lot of

642
00:26:17,250 --> 00:26:21,179
that was actually built because the

643
00:26:18,660 --> 00:26:23,850
spectrum meltdown but also just

644
00:26:21,179 --> 00:26:25,440
communities like this developing knowing

645
00:26:23,850 --> 00:26:28,830
the contacts and then developing trust

646
00:26:25,440 --> 00:26:32,130
over time super has proven super helpful

647
00:26:28,830 --> 00:26:34,530
for us there will be in efficiencies I

648
00:26:32,130 --> 00:26:36,420
showed the example of the SIB live we

649
00:26:34,530 --> 00:26:39,240
went through the same thing in Runcie

650
00:26:36,420 --> 00:26:41,340
it's amazing how it's amazing to me

651
00:26:39,240 --> 00:26:42,570
anyway that we still have to do a lot of

652
00:26:41,340 --> 00:26:45,629
manual

653
00:26:42,570 --> 00:26:47,339
checks and and and ask people hey who do

654
00:26:45,629 --> 00:26:50,039
you think is using your product because

655
00:26:47,339 --> 00:26:52,289
again we have open source as well and a

656
00:26:50,039 --> 00:26:55,979
lot of free use and internally and

657
00:26:52,289 --> 00:26:57,690
sometimes code gets forked or they don't

658
00:26:55,979 --> 00:26:59,759
even fork the code they just take some

659
00:26:57,690 --> 00:27:01,739
code snippets or some code from some

660
00:26:59,759 --> 00:27:02,639
component and then incorporate it into

661
00:27:01,739 --> 00:27:04,529
theirs

662
00:27:02,639 --> 00:27:06,869
so we're developing relationships with

663
00:27:04,529 --> 00:27:09,029
the tools people that do analysis and

664
00:27:06,869 --> 00:27:10,559
code searches but ultimately there are

665
00:27:09,029 --> 00:27:13,320
going to be a lot of inefficiency it's

666
00:27:10,559 --> 00:27:15,479
just kind of get ready for that OPSEC I

667
00:27:13,320 --> 00:27:17,579
won't go into more details there I

668
00:27:15,479 --> 00:27:20,639
mentioned just one example but again I

669
00:27:17,579 --> 00:27:22,889
think there's more to see here this is

670
00:27:20,639 --> 00:27:24,658
not a universal recommendation but at

671
00:27:22,889 --> 00:27:26,849
least it's proven successful for us in

672
00:27:24,659 --> 00:27:30,089
this case and in another but consider

673
00:27:26,849 --> 00:27:31,739
that and stay on obviously stay on top

674
00:27:30,089 --> 00:27:34,049
again I think you know this better than

675
00:27:31,739 --> 00:27:36,389
than we do we're we're still on this

676
00:27:34,049 --> 00:27:38,639
journey but the other one is again

677
00:27:36,389 --> 00:27:40,258
defined your response levels for those

678
00:27:38,639 --> 00:27:42,689
of you that are in product security

679
00:27:40,259 --> 00:27:44,820
response because I know you won't be

680
00:27:42,690 --> 00:27:46,529
able to do everything I know we cannot

681
00:27:44,820 --> 00:27:49,109
do everything so I highly recommend

682
00:27:46,529 --> 00:27:50,940
define well what your response levels

683
00:27:49,109 --> 00:27:54,418
are and what those relationships are

684
00:27:50,940 --> 00:27:57,329
between you the different teams so that

685
00:27:54,419 --> 00:28:07,529
basically is my talk and I think I have

686
00:27:57,329 --> 00:28:09,539
five minutes oh oh no break okay what is

687
00:28:07,529 --> 00:28:11,579
your experience with the disclosure time

688
00:28:09,539 --> 00:28:13,320
embargoes do they practically work

689
00:28:11,579 --> 00:28:15,709
especially for big multi product

690
00:28:13,320 --> 00:28:18,718
coordinated bonds how can we do better

691
00:28:15,709 --> 00:28:22,440
yeah we've had this debate multiple

692
00:28:18,719 --> 00:28:26,519
times and over beers and over conference

693
00:28:22,440 --> 00:28:29,609
calls I personally am a believer of of

694
00:28:26,519 --> 00:28:32,039
these embargoes if the up side should

695
00:28:29,609 --> 00:28:33,899
have probably given you a hint I think

696
00:28:32,039 --> 00:28:36,629
it's the only way I think you know

697
00:28:33,899 --> 00:28:37,498
nobody likes them there's a lot of cons

698
00:28:36,629 --> 00:28:40,139
against it

699
00:28:37,499 --> 00:28:43,440
but honestly I don't know of another way

700
00:28:40,139 --> 00:28:45,779
to solve a big complicated security

701
00:28:43,440 --> 00:28:49,409
issue that affects multiple parties than

702
00:28:45,779 --> 00:28:52,200
to have some sort of embargo and I also

703
00:28:49,409 --> 00:28:53,999
like at my pier at Google we've gone

704
00:28:52,200 --> 00:28:55,290
back and forth on this and here a really

705
00:28:53,999 --> 00:28:57,570
good joke about

706
00:28:55,290 --> 00:29:00,030
you know the need for ndas and his

707
00:28:57,570 --> 00:29:02,428
comment was has anybody ever been taken

708
00:29:00,030 --> 00:29:04,379
to court because they broke an embargo

709
00:29:02,429 --> 00:29:06,600
or because it was proven that they broke

710
00:29:04,380 --> 00:29:08,549
an NDA as part of multi-party disclosure

711
00:29:06,600 --> 00:29:11,610
and the truth is I don't know that it

712
00:29:08,549 --> 00:29:14,010
has but ultimately I think embargoes

713
00:29:11,610 --> 00:29:15,770
have a place and and I can't think of

714
00:29:14,010 --> 00:29:18,770
another way that we can solve

715
00:29:15,770 --> 00:29:21,600
complicated issues without having this

716
00:29:18,770 --> 00:29:23,490
shared agreement that we're gonna work

717
00:29:21,600 --> 00:29:27,379
on it together and we'll go public

718
00:29:23,490 --> 00:29:27,380
together however long it takes us

719
00:29:27,740 --> 00:29:32,070
incident details are secret how do you

720
00:29:30,360 --> 00:29:33,928
solve teams starting at remediation

721
00:29:32,070 --> 00:29:37,350
independently from a book bound to

722
00:29:33,929 --> 00:29:43,710
report on aware of an ongoing incident

723
00:29:37,350 --> 00:29:45,540
incident details are secret so if I

724
00:29:43,710 --> 00:29:47,190
understand this question if I don't

725
00:29:45,540 --> 00:29:51,210
answer it try just come see me at the

726
00:29:47,190 --> 00:29:52,950
break so incident details are secret but

727
00:29:51,210 --> 00:29:54,840
ultimately especially if you're in the

728
00:29:52,950 --> 00:29:56,940
product Security Response organization

729
00:29:54,840 --> 00:29:59,699
you're not the one that's working on a

730
00:29:56,940 --> 00:30:01,350
fix so you need to eventually involve

731
00:29:59,700 --> 00:30:04,260
engineering teams that will be working

732
00:30:01,350 --> 00:30:06,750
on a fix so the way we manage this we do

733
00:30:04,260 --> 00:30:09,059
have we do implement information

734
00:30:06,750 --> 00:30:10,650
protection controls and we obviously

735
00:30:09,059 --> 00:30:15,299
develop a lot of software around this

736
00:30:10,650 --> 00:30:17,640
with SharePoint etc so we create tents

737
00:30:15,299 --> 00:30:19,679
for lack of a better word and we have

738
00:30:17,640 --> 00:30:21,809
security groups assigned so we we keep

739
00:30:19,679 --> 00:30:24,330
it on a need-to-know basis and then we

740
00:30:21,809 --> 00:30:26,190
apply information protection to make

741
00:30:24,330 --> 00:30:28,649
sure that only the people I need to know

742
00:30:26,190 --> 00:30:31,380
know and only the people I need to see

743
00:30:28,650 --> 00:30:34,200
the information can see it and they all

744
00:30:31,380 --> 00:30:36,510
understand we reinforce it in every

745
00:30:34,200 --> 00:30:38,130
meeting in every email that we send we

746
00:30:36,510 --> 00:30:41,340
reinforce the need for confidentiality

747
00:30:38,130 --> 00:30:45,900
and and only need to know for most cases

748
00:30:41,340 --> 00:30:46,889
that are high severity they're fairly

749
00:30:45,900 --> 00:30:48,750
quick to solve

750
00:30:46,890 --> 00:30:50,520
it's very rare something like the

751
00:30:48,750 --> 00:30:52,799
spectrum meltdown to reference that one

752
00:30:50,520 --> 00:30:55,590
those are exception that there's very

753
00:30:52,799 --> 00:30:57,780
few things that take that long but for

754
00:30:55,590 --> 00:31:00,230
the most part the incidents take a short

755
00:30:57,780 --> 00:31:02,850
amount of time so this is somewhat

756
00:31:00,230 --> 00:31:06,150
limited and again if it if I didn't

757
00:31:02,850 --> 00:31:08,580
answer your question please see me for

758
00:31:06,150 --> 00:31:09,210
cross company collaboration how much of

759
00:31:08,580 --> 00:31:12,750
the communique

760
00:31:09,210 --> 00:31:18,840
Eastern aisaka versus business social

761
00:31:12,750 --> 00:31:23,520
contacts I so I had never done anything

762
00:31:18,840 --> 00:31:26,429
to an Isaac I have done we have used I

763
00:31:23,520 --> 00:31:28,950
Cassie which I guess it's very similar

764
00:31:26,430 --> 00:31:33,240
to an Isaac we have to use like a see

765
00:31:28,950 --> 00:31:35,040
for several for several incidents crack

766
00:31:33,240 --> 00:31:38,310
wireless is one of those that we went

767
00:31:35,040 --> 00:31:41,970
through we try Cassie but for the most

768
00:31:38,310 --> 00:31:43,730
part there is in our organization and

769
00:31:41,970 --> 00:31:47,100
Isaac or even I can see that

770
00:31:43,730 --> 00:31:51,410
incorporates every company that needs to

771
00:31:47,100 --> 00:31:54,510
be part of one of these major incidents

772
00:31:51,410 --> 00:31:58,530
you think about Linux for example a lot

773
00:31:54,510 --> 00:32:00,060
of the Linux OS vendors they're not in

774
00:31:58,530 --> 00:32:01,649
many of these organizations so if you

775
00:32:00,060 --> 00:32:06,000
need to coordinate with them with red

776
00:32:01,650 --> 00:32:07,560
hat with FreeBSD etc you're not going to

777
00:32:06,000 --> 00:32:09,030
find them a lot of them you're not going

778
00:32:07,560 --> 00:32:10,590
to find one of these groups that

779
00:32:09,030 --> 00:32:11,910
incorporates all of them so at the end

780
00:32:10,590 --> 00:32:13,350
of that you might use one of these

781
00:32:11,910 --> 00:32:18,240
organizations but you might need to

782
00:32:13,350 --> 00:32:22,050
invite others to join we have used cert

783
00:32:18,240 --> 00:32:24,540
for in some cases just to help with

784
00:32:22,050 --> 00:32:27,060
coordination the fragments Mac I piece

785
00:32:24,540 --> 00:32:29,159
mark is one example crack wireless which

786
00:32:27,060 --> 00:32:34,409
wasn't really OSS but that's another one

787
00:32:29,160 --> 00:32:36,200
where where we use them and I think

788
00:32:34,410 --> 00:32:39,200
that's it

789
00:32:36,200 --> 00:32:39,200
perfect

