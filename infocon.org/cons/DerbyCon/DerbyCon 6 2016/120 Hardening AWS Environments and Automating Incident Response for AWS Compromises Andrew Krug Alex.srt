1
00:00:00,000 --> 00:00:04,440
alright we'll go ahead and get started
you're in hardening AWS environments and

2
00:00:04,440 --> 00:00:13,110
automating incident response i'm andrew
Krug and this is alex mccormick before

3
00:00:13,110 --> 00:00:16,740
we get started we're super excited like
to be here at Derby con i have been

4
00:00:16,740 --> 00:00:21,359
trying to come to derby con for probably
three or four years and I haven't been

5
00:00:21,359 --> 00:00:24,600
able to get a ticket so now i'm
convinced the best way to secure a

6
00:00:24,600 --> 00:00:28,650
ticket is just to create a software
project and present it at their become

7
00:00:28,650 --> 00:00:37,950
so we're really small team of people
that work on this tool suite called

8
00:00:37,950 --> 00:00:42,120
threat response that we released earlier
this year at black hat

9
00:00:42,120 --> 00:00:46,589
there's only four of us and we're
looking for other people to join us as

10
00:00:46,590 --> 00:00:51,840
contributors so if you're interested
please do talk to us we are not a

11
00:00:51,840 --> 00:00:56,910
product or a corporation absolutely
nobody pays us to make security software

12
00:00:56,910 --> 00:01:01,019
for amazon and everything that we're
going to talk about today is totally

13
00:01:01,020 --> 00:01:04,409
free open-source software that you can
go and get right now

14
00:01:10,820 --> 00:01:17,059
we all do have real day jobs though we
can't say where because of weird

15
00:01:17,060 --> 00:01:22,520
corporate policies yeah if you do find
out where we do work which is not hard

16
00:01:22,520 --> 00:01:27,440
at all because there's things like
linkedin these are not the opinions of

17
00:01:27,440 --> 00:01:32,570
our employer of course you can totally
get the slides for the presentation

18
00:01:32,570 --> 00:01:38,839
right now you are else they were wrong
in this deck so we tweeted them hash tag

19
00:01:38,840 --> 00:01:42,290
der beek on for this talk so if you want
those all the links are in the slides

20
00:01:42,290 --> 00:01:47,810
and they have been published so here's
the agenda for today this is you right

21
00:01:48,320 --> 00:01:51,350
so today's agenda we got four main parts

22
00:01:51,350 --> 00:01:54,740
we're going to talk a little bit about
the inspirations for how we started

23
00:01:54,740 --> 00:01:59,179
looking at incident response within AWS
we're going to cover some blog posts and

24
00:01:59,180 --> 00:02:03,680
some black cat videos so then we're
going to cover actual instant response

25
00:02:03,680 --> 00:02:07,820
than AWS introduce the tools that we
developed we're going to talk about

26
00:02:07,820 --> 00:02:12,530
advanced attacks and defenses in AWS and
then we'll wrap everything up with final

27
00:02:12,530 --> 00:02:20,480
tips and resources so let's start with
actually looking back past year in AWS

28
00:02:20,480 --> 00:02:24,768
security there's a lot of significant
blog post that influence us and just to

29
00:02:24,769 --> 00:02:25,880
reiterate eyes

30
00:02:25,880 --> 00:02:29,480
these are all links so get the slide
deck you can follow the links you can go

31
00:02:29,480 --> 00:02:34,340
read this blog post yourself Daniel
gradual act a lot of offensive stuff so

32
00:02:34,340 --> 00:02:36,440
assuming you get an AWS key

33
00:02:36,440 --> 00:02:41,000
what can you then do with that key to
disrupt other people's amazon accounts

34
00:02:41,000 --> 00:02:46,760
Tony deal with wente published a
forensics and AWS article which really

35
00:02:46,760 --> 00:02:52,010
inspired are a WS ir tool and an air
Cameron has a really cool blog post

36
00:02:52,010 --> 00:02:56,540
about how the read-only IM access
management policy is a little too

37
00:02:56,540 --> 00:03:03,410
permissive and can allow some bad things
to happen and then what we sort of saw

38
00:03:03,410 --> 00:03:08,150
during the summer was we saw this blog
articles boiled down into security

39
00:03:08,150 --> 00:03:12,829
research like legitimate techniques for
persisting long-term in AWS accounts

40
00:03:12,829 --> 00:03:16,400
which is sort of the first time that
we've really seen onstage people do

41
00:03:16,400 --> 00:03:22,040
things besides just mine bitcoins with
compromised keys so there was this paper

42
00:03:22,040 --> 00:03:23,959
that was put out account jumping posted

43
00:03:23,960 --> 00:03:27,470
section persistence and lateral movement
which we're going to get to a little bit

44
00:03:27,470 --> 00:03:31,490
later in the talk there's this great
talk by Loic Simon called access keys

45
00:03:31,490 --> 00:03:35,720
will kill you before you kill the
password which is all about how we don't

46
00:03:35,720 --> 00:03:39,710
seem to be learning from the mistakes
that we made with passwords we're still

47
00:03:39,710 --> 00:03:44,810
inventing new systems and storing
plaintext credentials on disk which is

48
00:03:44,810 --> 00:03:49,370
how your your AWS keys get stored and
then there was this talk which here in a

49
00:03:49,370 --> 00:03:55,640
version of now so we went to that
section very quickly we're going to do

50
00:03:55,640 --> 00:03:59,899
the incident response in AWS section
it's the most media section we've got

51
00:03:59,900 --> 00:04:05,000
five parts we you know modeled after the
five stages of incident response so we

52
00:04:05,000 --> 00:04:10,010
have some coverage of preparation
identification containment eradication

53
00:04:10,010 --> 00:04:13,640
and recovery but we're not going to talk
about recovery that's going to be

54
00:04:13,640 --> 00:04:18,860
specific to your organization so you can
figure that out on around let's talk

55
00:04:18,860 --> 00:04:23,720
about preparation so just real quickly
wanted to point out AWS just updated a

56
00:04:23,720 --> 00:04:28,190
new best practices guide that was
released in august you can go download

57
00:04:28,190 --> 00:04:34,280
that it's a full 70 or 80 pages best
practices for hardening and setting up

58
00:04:34,280 --> 00:04:39,650
your AWS counts the CIS center for
information security also has their

59
00:04:39,650 --> 00:04:44,630
foundations benchmarks so if you're in
the mood for checklists that's a

60
00:04:44,630 --> 00:04:47,390
document you may want to use it's a
great checklist

61
00:04:47,390 --> 00:04:52,490
it's good it's good things to look for
and if if you're doing an audit or

62
00:04:52,490 --> 00:04:56,690
something where you want someone else's
guidelines that you can use that's a

63
00:04:56,690 --> 00:04:59,870
good place to start and also develop an
incident response plan

64
00:05:00,680 --> 00:05:06,830
lastly in terms of things to get ready i
just want to point out if you're

65
00:05:06,830 --> 00:05:11,570
familiar with the awesome projects like
awesome ruby or awesome node there's a

66
00:05:11,570 --> 00:05:16,370
awesome incident response page and it
lists a bunch of incident response tools

67
00:05:16,370 --> 00:05:19,610
so if you don't know about it and you're
kind of in the mood of like I kinda want

68
00:05:19,610 --> 00:05:23,600
to know about some more tools go check
out this github page it's got lots of

69
00:05:23,600 --> 00:05:26,540
tools will tell you a little bit of
adamant and you can go to the actual

70
00:05:26,540 --> 00:05:31,550
tool page itself to download it and then
while looking at that i found awesome

71
00:05:31,550 --> 00:05:35,760
search which is another website that
shows you just awesome lists

72
00:05:35,760 --> 00:05:38,730
and so you can find all of those related
to security which will have things on

73
00:05:38,730 --> 00:05:45,090
like malware exploitation or even car
hacking so now that we've talked a

74
00:05:45,090 --> 00:05:48,150
little about about now kind of getting
your environment ready let's talk about

75
00:05:48,150 --> 00:05:52,320
hardening it like actually implementing
the things that we read about in the

76
00:05:52,320 --> 00:05:57,390
last section so we're gonna cover real
quickly recover about six tools that you

77
00:05:57,390 --> 00:06:00,300
can use they all have their own
strengths and weaknesses

78
00:06:00,300 --> 00:06:05,700
let's take a quick look at best
practices auditing so if you used any of

79
00:06:05,700 --> 00:06:10,440
us are probably familiar with trusted
advisor if you have a business or

80
00:06:10,440 --> 00:06:14,250
enterprise support plan you're probably
familiar with a little bit more its kind

81
00:06:14,250 --> 00:06:19,500
of restricted to those users it's going
to give you basic cost optimization

82
00:06:19,500 --> 00:06:25,680
security rules things that you can do
it's very simple it's very basic there's

83
00:06:25,680 --> 00:06:29,010
no programming against it you can't find
out like alert me when something bad

84
00:06:29,010 --> 00:06:32,880
happens it's just in the dashboard shows
up as the redbox so the best thing it

85
00:06:32,880 --> 00:06:37,890
has going for is it's very like c-suite
friendly you can like printed out with

86
00:06:37,890 --> 00:06:42,840
no red marks and be like hello executive
Lee I'm complying and then they're happy

87
00:06:42,840 --> 00:06:49,229
but the checks aren't that comprehensive
configured config rules are much more

88
00:06:49,230 --> 00:06:54,630
comprehensive these are actually to kind
of separate services so AWS config is

89
00:06:54,630 --> 00:07:00,030
really great it's a logging service that
works that deals with the configuration

90
00:07:00,030 --> 00:07:06,359
of a particular AWS resource so if you
create a ec2 instance that gets large

91
00:07:06,360 --> 00:07:10,860
and all the state information of that
ec2 instance gets large as well but what

92
00:07:10,860 --> 00:07:16,230
the pcs or is it attached to which discs
are attached to all those things any

93
00:07:16,230 --> 00:07:20,850
time of resources created updated or
deleted those all get locked so you get

94
00:07:20,850 --> 00:07:26,550
this fantastic historical record you can
answer questions like when did Joe have

95
00:07:26,550 --> 00:07:31,860
access to this specific resource you can
go look through your config lists figure

96
00:07:31,860 --> 00:07:35,010
out which policy is applied to him
figure out when you actually had access

97
00:07:35,010 --> 00:07:41,159
to a resource config rules its ability
to actually do things about those

98
00:07:41,160 --> 00:07:47,700
configuration items so you can put logic
in there to say if a ec2 instance is

99
00:07:47,700 --> 00:07:48,810
created

100
00:07:48,810 --> 00:07:53,550
but that ec2 instance is attached to a
VPC that is wide open to the world then

101
00:07:53,550 --> 00:07:57,810
we're going to report back to the users
you get a lot more granularity in terms

102
00:07:57,810 --> 00:08:00,600
of what you're looking at with configure
rules

103
00:08:00,600 --> 00:08:05,669
amazon to find some configure rules for
you and you can also write around

104
00:08:05,669 --> 00:08:13,109
there's also another tool called Prowler
probably was written by 20 de la Fuente

105
00:08:13,110 --> 00:08:18,570
it uses those center for information
security benchmarks all of their checks

106
00:08:18,570 --> 00:08:23,159
it's a single bass script but it checks
for all those checklist so if you have a

107
00:08:23,160 --> 00:08:26,639
client who wants you to evaluate whether
or not they're compliant within those

108
00:08:26,639 --> 00:08:27,600
standards

109
00:08:27,600 --> 00:08:31,410
here's one script you can run it's very
simple to setup you hit run and it will

110
00:08:31,410 --> 00:08:37,080
give you a yes-or-no when all those
checks getting a little bit more

111
00:08:37,080 --> 00:08:41,760
sophisticated to scout to this is
sophisticated in terms of the fact that

112
00:08:41,760 --> 00:08:45,839
you can add your own logic to it and
it's you know it's more than one file

113
00:08:45,839 --> 00:08:51,029
it's written in python but it's very
easy to set up its two commands you

114
00:08:51,029 --> 00:08:55,080
install the requirements and then you
run the program it generates a static

115
00:08:55,080 --> 00:09:00,510
HTML page that you can click through and
get the results of your actual analysis

116
00:09:00,510 --> 00:09:06,480
it has roughly sixty three checks right
now and you can always add around i

117
00:09:06,480 --> 00:09:09,660
really like scalp to encourage everyone
to check it out

118
00:09:09,660 --> 00:09:17,760
open source and it's written by ncc
group next going up further in the

119
00:09:17,760 --> 00:09:22,770
complexity to go we have cloud custodian
cloud custodian is a policy generator so

120
00:09:22,770 --> 00:09:26,160
in that sense it's a little closer to
configure and configure rules its

121
00:09:26,160 --> 00:09:33,300
evaluated actions in your AWS
environment it's stateless so just like

122
00:09:33,300 --> 00:09:36,479
all the other tools we talked about you
run it once you get your results back

123
00:09:36,480 --> 00:09:40,860
and it's up to you to you know throw
that in a cron job and check the results

124
00:09:40,860 --> 00:09:42,360
kind of thing

125
00:09:42,360 --> 00:09:48,060
it's very easy to use it's written by
Capital One the highest in terms of

126
00:09:48,060 --> 00:09:52,319
complexity is security monkey this is a
state full piece of infrastructure that

127
00:09:52,320 --> 00:09:56,850
you set up yourself security monkey kind
of did a lot of the things that Amazon

128
00:09:56,850 --> 00:09:57,690
took over

129
00:09:57,690 --> 00:10:03,810
cloud trail and cloud watch and config
they had insecurity monkey before amazon

130
00:10:03,810 --> 00:10:05,790
was really even kind of looking at it

131
00:10:05,790 --> 00:10:09,540
security monkey even though you have to
set it up yourself and it takes a little

132
00:10:09,540 --> 00:10:13,170
bit more you know esto to get going

133
00:10:13,170 --> 00:10:17,219
it can really pay off if if that's the
kind of granularity you need

134
00:10:18,270 --> 00:10:22,350
so which tool you should you use and the
obvious answer to that question is

135
00:10:22,350 --> 00:10:26,490
whatever is best for your environment so
would highly encourage you if you don't

136
00:10:26,490 --> 00:10:30,300
have something doing compliance checking
already start with something simple

137
00:10:30,300 --> 00:10:35,069
maybe Scout to or Prowler just throw
that in a you know throw in a cron job

138
00:10:35,070 --> 00:10:38,880
and have it sent you an email every time
you get alerts every time you know

139
00:10:38,880 --> 00:10:44,910
configuration fails and then as your
demands and the complexity of your

140
00:10:44,910 --> 00:10:51,630
project increase then you can move on to
more complex projects so that was the

141
00:10:51,630 --> 00:10:56,550
best practices auditing let's move on to
specifically auditing I am user and

142
00:10:56,550 --> 00:11:01,920
policy instances so the difference
between the section we just talked about

143
00:11:01,920 --> 00:11:07,140
is when we talk about auditing users and
policies were specifically looking at

144
00:11:07,140 --> 00:11:10,830
that one best practice of least
privilege everything that we're going to

145
00:11:10,830 --> 00:11:15,450
talk about in terms of attacks with AWS
access keys they're all irrelevant if

146
00:11:15,450 --> 00:11:20,130
you can successfully implement least
privilege and so the reason why

147
00:11:20,130 --> 00:11:25,080
companies or organizations have giant
problems with you know spinning up

148
00:11:25,080 --> 00:11:30,750
Bitcoin miners or acts like shutting
down you know live instances of

149
00:11:30,750 --> 00:11:35,400
production is because someone made a an
account that was to privileged and lick

150
00:11:35,400 --> 00:11:42,000
those keys somewhere so the first step
when you're trying to evaluate a policy

151
00:11:42,000 --> 00:11:46,530
or user is to use access advisor access
advisor is alright it's similar to

152
00:11:46,530 --> 00:11:54,510
trusted advisor it's only in the IM web
console you can't program against it but

153
00:11:54,510 --> 00:12:00,270
you get access to a list of services for
a particular user or particular policy

154
00:12:00,270 --> 00:12:04,710
that is allowed by that policy and then
you get whether or not that service was

155
00:12:04,710 --> 00:12:08,910
ever accessed fire user using that
policy you get to see very easily

156
00:12:08,910 --> 00:12:10,569
whether or not you need to let

157
00:12:10,570 --> 00:12:14,500
somebody had information to something if
they've never had had a reason to use

158
00:12:14,500 --> 00:12:20,950
say route 53 then you can remove those
all those permissions from their policy

159
00:12:20,950 --> 00:12:26,980
but again it's non-programmable
programmatic ball you can't see Cameron

160
00:12:26,980 --> 00:12:32,020
API against you can learn about it it's
kind of best for kind of spot checking

161
00:12:32,020 --> 00:12:36,939
people's user accounts it's also only
had the service level it's not at the

162
00:12:36,940 --> 00:12:41,560
API level so for example easy to you
might people might always be spinning up

163
00:12:41,560 --> 00:12:46,239
instances but you don't know if they're
actually terminating instances so do

164
00:12:46,240 --> 00:12:50,290
they actually need to have that
terminate instance permission allowed

165
00:12:50,290 --> 00:12:54,640
and so if you want to do that there's a
link up here it will run through a

166
00:12:54,640 --> 00:12:57,850
little bit more the details but you can
actually use cloud trails so if you

167
00:12:57,850 --> 00:13:02,500
don't know cloud trail macleod trail
logs all interactions you have with

168
00:13:02,500 --> 00:13:08,350
amazon AWS so whether it's through the
web console or through the sdk photo

169
00:13:08,350 --> 00:13:12,580
that kind of thing that all gets larger
and louder once you have that setup you

170
00:13:12,580 --> 00:13:17,680
can hold down those clouds profiles from
an s3 bucket and then in this example I

171
00:13:17,680 --> 00:13:22,329
just queried it with a tool called Jake
you and just grabbed every action and

172
00:13:22,330 --> 00:13:27,220
every service that my particular user
used and then I just built a policy

173
00:13:27,220 --> 00:13:30,550
around that this is all they ever do
just given permission to just do that

174
00:13:30,550 --> 00:13:36,160
there's another video you should check
out any of us just put out talked about

175
00:13:36,160 --> 00:13:40,600
this last year and kind of walk you
through how to use some of the other I

176
00:13:40,600 --> 00:13:47,800
am tuning services and last thing we
talked about preparation we really

177
00:13:47,800 --> 00:13:53,800
encourage you to practice have I our
game days or security simulations the

178
00:13:53,800 --> 00:13:58,270
caveat here is you need to tell us about
this before you do it but we simulate

179
00:13:58,270 --> 00:14:01,120
with you know red team's all the time
we're actually breaking into

180
00:14:01,120 --> 00:14:05,770
applications whether or not you are
doing it with AWS a whole other story

181
00:14:05,770 --> 00:14:09,520
you need to start thinking about what if
the attacker got one of my compromise

182
00:14:09,520 --> 00:14:10,540
keys

183
00:14:10,540 --> 00:14:13,540
one of the things that they could do

184
00:14:14,990 --> 00:14:21,410
your cover defecation yes so now we're
going to talk about identification like

185
00:14:21,410 --> 00:14:24,709
how do you know when you have been
breached

186
00:14:24,709 --> 00:14:28,699
one of the great ways to do that is just
by auditing cloud trail of course if you

187
00:14:28,700 --> 00:14:33,649
have a really savvy attacker they're
probably going to disrupt logging and

188
00:14:33,649 --> 00:14:36,649
that in and of itself is an artifact
that you've been compromised

189
00:14:37,790 --> 00:14:42,500
you can do that with cloud watch metrics
club watch metrics and cloud watch

190
00:14:42,500 --> 00:14:47,540
events which people actually don't know
that much about I fines because cloud

191
00:14:47,540 --> 00:14:51,920
watches just kind of one brand and then
they bury this nice events button with

192
00:14:51,920 --> 00:14:56,660
the tiniest orange text that just says
new like how are you supposed to even

193
00:14:56,660 --> 00:15:00,980
find that cloud watch events are great
though because they alert really really

194
00:15:00,980 --> 00:15:02,180
fast

195
00:15:02,180 --> 00:15:06,140
config rules take in all of the
information about all the states of

196
00:15:06,140 --> 00:15:10,520
items in your account so it can take up
to four minutes for a configuration item

197
00:15:10,520 --> 00:15:14,779
to kick off an alert where cloud watch
is going to notify you in probably 90

198
00:15:14,779 --> 00:15:19,130
seconds or less that something's gone
wrong so you have much less time that

199
00:15:19,130 --> 00:15:23,120
attackers persisting in your account if
you use cloud watch events to create

200
00:15:23,120 --> 00:15:28,640
alarms so there's a great AWS
CloudFormation template that you can

201
00:15:28,640 --> 00:15:31,850
pretty much just running your account
that will turn on security events in

202
00:15:31,850 --> 00:15:36,380
cloud trail this is really great for
anomalous things that we always want to

203
00:15:36,380 --> 00:15:41,540
be notified about like root account
logins somebody ever logs in with a AWS

204
00:15:41,540 --> 00:15:45,050
root account you want a notification to
go out to your team and everybody drops

205
00:15:45,050 --> 00:15:49,160
what they're doing and starts responding
so you can apply that and there's a link

206
00:15:49,160 --> 00:15:52,550
in the slides

207
00:15:52,550 --> 00:15:58,760
i'm also talking about containment rain
ok practice we so practice but we want

208
00:15:58,760 --> 00:16:01,850
to make the slides a little bit more fun
for this audience and we have one

209
00:16:01,850 --> 00:16:05,959
hundred percent more hacks then we had a
black hat so it's much more exciting so

210
00:16:05,959 --> 00:16:09,829
we built a command-line tool a part of
it as part of the threat response

211
00:16:09,829 --> 00:16:16,040
project called a WS ir I know it's not a
very exciting name but it does what it

212
00:16:16,040 --> 00:16:20,959
says which is that you can use it to
process a compromise hosting your

213
00:16:20,959 --> 00:16:25,939
accounts or something that gets hacked
like just a nap or a key compromise like

214
00:16:25,940 --> 00:16:27,449
I've leaky onto the internet

215
00:16:27,449 --> 00:16:32,488
and now i need to do all the right due
diligence things to mitigate that inside

216
00:16:32,489 --> 00:16:38,549
of my account so it's really simple
command to install via pin python I

217
00:16:38,549 --> 00:16:42,059
think we're even so real that were in
pai pai now like you don't have to just

218
00:16:42,059 --> 00:16:47,639
install from source wherein pie so you
just run this one command and get the IP

219
00:16:47,639 --> 00:16:52,589
address username and ssh key and then
we'll do all the things that needs to do

220
00:16:52,589 --> 00:16:57,899
to contain that instance including
shifting into an isolate security group

221
00:16:57,899 --> 00:17:03,359
preventing outbound access taking this
nap shots and also taking memory from

222
00:17:03,359 --> 00:17:08,459
that instance we have a Kiki compromise
will disable the key and we're currently

223
00:17:08,459 --> 00:17:13,230
in the process of adding features that
mitigate a temporary session token'

224
00:17:13,230 --> 00:17:17,519
attacks which were going to talk about
how scary session token' attacks can be

225
00:17:17,519 --> 00:17:25,199
in just a tiny bit so often what we also
see those that hosts compromise can lead

226
00:17:25,199 --> 00:17:29,700
to key compromise so if you pop a box
that has an iamb roll associated with it

227
00:17:29,700 --> 00:17:34,080
as an attacker sometimes you can use
that to escalate to having some

228
00:17:34,080 --> 00:17:36,210
temporary session tokens or keys

229
00:17:36,210 --> 00:17:41,580
has anybody ever heard of the metadata
service in AWS yeah it's it's a nice

230
00:17:41,580 --> 00:17:49,260
feature for developers because you can
just curl this URL 169 254 . 169 to 54 /

231
00:17:49,260 --> 00:17:54,240
later / metadata and from there if the
incidence is running a role you can

232
00:17:54,240 --> 00:17:59,220
actually query the roles and will say
here's the role of this incidence and

233
00:17:59,220 --> 00:18:06,090
then if you know the name of the role
you can go from the role to creds so

234
00:18:06,090 --> 00:18:11,850
this is karla balazs route and non-root
in the instance right so as an attacker

235
00:18:11,850 --> 00:18:15,750
for me this is like winning because now
I have those SES tokens which are valid

236
00:18:15,750 --> 00:18:20,460
on any other box i want to use them on
for about 15 minutes and so i can just

237
00:18:20,460 --> 00:18:24,899
keep asking for those for as long as i
have access to the instance so what

238
00:18:24,899 --> 00:18:30,899
though like I have those those creds as
a defender you can protect against this

239
00:18:30,899 --> 00:18:34,918
with iptables rule and you can at least
prevent non-privileged users from

240
00:18:34,919 --> 00:18:37,919
getting to that that binding if you
don't actually need this

241
00:18:38,470 --> 00:18:42,700
gonna have to do what it does so going
like throw that in your default am I

242
00:18:42,700 --> 00:18:50,919
builds so when key compromise you could
be compromised can also be the other way

243
00:18:50,919 --> 00:18:55,030
around like he compromised can lead to
host compromise where if somebody has an

244
00:18:55,030 --> 00:19:00,460
access key for your account they can
snap shot a disc spin up a new instance

245
00:19:00,460 --> 00:19:06,940
attached that snapshot dumped at sea
password crack passwords also win so it

246
00:19:06,940 --> 00:19:12,549
can work the other way around as well as
eradication mind to know that's you

247
00:19:13,390 --> 00:19:19,809
we live in different time zones so it's
hard pressed to rehearse so we're going

248
00:19:19,809 --> 00:19:25,389
to show we talked you know about a WS ir
and how it deals with isolation so

249
00:19:25,390 --> 00:19:30,220
actually isolating you're compromised
host eradication we decided to take a

250
00:19:30,220 --> 00:19:34,659
different approach we decided to look
specifically at the forensics trying to

251
00:19:34,659 --> 00:19:37,600
figure out what happened how do you even
know you eradicated something until you

252
00:19:37,600 --> 00:19:41,770
you know done your actual investigation
so the rest the rest of the eradication

253
00:19:41,770 --> 00:19:44,679
section we talk about collecting
evidence and actually being able to

254
00:19:44,679 --> 00:19:51,100
examine those that evidence with a WS ir
I'm gonna just this is running really

255
00:19:51,100 --> 00:19:51,879
fast

256
00:19:51,880 --> 00:19:55,240
don't worry about what it's saying just
know that lots of things are happening

257
00:19:55,240 --> 00:19:59,169
that's what we should be excited about
this is the tool running like you can

258
00:19:59,169 --> 00:20:03,340
you can try this at home in fact we
encourage you to try it at home and

259
00:20:03,340 --> 00:20:07,240
there's also running at five times speed
just want to wait but what it's doing is

260
00:20:07,240 --> 00:20:12,010
its grabbing a bunch of it so it
isolates the instance then it grabs all

261
00:20:12,010 --> 00:20:16,900
this data throws that an s3 bucket and
then gives you this command to run to

262
00:20:16,900 --> 00:20:21,640
launch what we call our threat response
workstation which is analysis

263
00:20:21,640 --> 00:20:26,980
am i that you can run inside amazon so
let's start talking about which data we

264
00:20:26,980 --> 00:20:33,010
want to collect so we collect AWS data
disk memory and network those are the

265
00:20:33,010 --> 00:20:35,980
you know the core elements are going to
collect when you're starting your

266
00:20:35,980 --> 00:20:44,230
investigation throw all that into an s3
bucket in terms of AWS data there's a

267
00:20:44,230 --> 00:20:48,789
lot of features within so we use photo
34 a WS ir there's a lot of features in

268
00:20:48,789 --> 00:20:51,620
the Amazon sdk to get even more
information

269
00:20:51,620 --> 00:20:55,790
shouldn't about an instance so we
grabbed easy to console output the

270
00:20:55,790 --> 00:21:00,020
screenshot of the console that happens
to have a GUI eight of us specific

271
00:21:00,020 --> 00:21:04,129
metadata so similar to things that would
be in config if you had that set up

272
00:21:04,130 --> 00:21:10,250
which devices are attached which network
devices are attached the IP addresses of

273
00:21:10,250 --> 00:21:15,860
those the am I ID so you know what your
base image was and then also you're

274
00:21:15,860 --> 00:21:19,040
going to want to collect relevant cloud
trail logs we're working on that feature

275
00:21:19,040 --> 00:21:26,720
now with WS ir so when eight of us are
runs it's going to take a snapshot of

276
00:21:26,720 --> 00:21:31,040
every disc associated with the
compromise host and store that within

277
00:21:31,040 --> 00:21:38,750
amazon but then how do you analyze it so
we decided to add a little workflow to

278
00:21:38,750 --> 00:21:45,050
make it easier for people to analyze it
with inside AWS so after you run into us

279
00:21:45,050 --> 00:21:48,800
by our post compromise you can create a
work station when you create the

280
00:21:48,800 --> 00:21:54,290
workstation you get this nice web UI
that lists all of the disks that were

281
00:21:54,290 --> 00:22:01,520
created you can then click a button and
what will happen is that disc its

282
00:22:01,520 --> 00:22:07,400
process with log2 timeline generates a
plan so file that plateau file gets

283
00:22:07,400 --> 00:22:11,720
dropped in s3 and then you can use the
Google tool called time sketch to

284
00:22:11,720 --> 00:22:17,660
analyze that plan so file is anyone here
familiar with time sketch some people

285
00:22:17,660 --> 00:22:21,350
yeah so it's a google project but they
won't they don't like calling it's not a

286
00:22:21,350 --> 00:22:25,850
project by google it's just code that
happens to be owned by Google like we're

287
00:22:25,850 --> 00:22:29,270
going to pretend that they still think
it's cool because we think it's cool

288
00:22:29,270 --> 00:22:32,900
this is an example of what it is it's a
it's a log viewer but it's meant to be

289
00:22:32,900 --> 00:22:38,990
collaborative you can have multiple
login comments on events that you see so

290
00:22:38,990 --> 00:22:44,330
we think it's pretty good way to analyze
a disc all this happens with two klicks

291
00:22:44,330 --> 00:22:45,290
from the user

292
00:22:45,290 --> 00:22:49,190
there is no setting up a larger timeline
there is no setting up like trying to

293
00:22:49,190 --> 00:22:55,400
import your own plastic stuff it's all
it's all done for you see you did disc

294
00:22:55,400 --> 00:22:58,730
you went through all those events and
you found all the bad things

295
00:22:58,730 --> 00:23:01,760
what about memory some memory really
excited about

296
00:23:02,300 --> 00:23:06,230
one of our team members Joel farrier
wrote this awesome tool called margarita

297
00:23:06,230 --> 00:23:10,310
Chaka it's completely standalone if you
don't want to use AWS I are you can use

298
00:23:10,310 --> 00:23:14,929
modern shocking around but Margaret
shotgun does is people familiar with

299
00:23:14,930 --> 00:23:18,020
lime like memory acquisition with lime

300
00:23:18,020 --> 00:23:22,129
so the thing about lions got to have
those kernel modules rebuilt and there's

301
00:23:22,130 --> 00:23:26,630
a lot of typing stuff over the network
and maybe that's in the clear so

302
00:23:26,630 --> 00:23:33,710
margarita shotgun wraps all of that we
precompiled most of the Amazon certified

303
00:23:33,710 --> 00:23:38,660
am eyes if you try to use it and you
don't find a kernel module that you need

304
00:23:38,660 --> 00:23:43,160
just ping us and we'll spin one up for
you and even more so we give you the

305
00:23:43,160 --> 00:23:46,970
ability to use your own warehouse of
kernel modules if you happen to not

306
00:23:46,970 --> 00:23:52,580
trust what we build for you but it's
gonna so Margaret shocking will SH into

307
00:23:52,580 --> 00:23:57,080
a compromise host figure out the colonel
grab the line kernel module for that

308
00:23:57,080 --> 00:24:01,850
particular host grab memory securely
copy that copy over the network and then

309
00:24:01,850 --> 00:24:07,159
drop it in an s3 bucket it can do this
all in parallel very low overhead it's a

310
00:24:07,160 --> 00:24:14,480
it's a really nice tool once it's in the
s3 bucket you can use the threat

311
00:24:14,480 --> 00:24:19,100
response workstation to actually view it
with volatility inside your web browser

312
00:24:19,100 --> 00:24:23,120
so you don't have to pull down that
several gigabyte memory data dump you

313
00:24:23,120 --> 00:24:27,169
can just do with volatility tools you
know the volatility instance is a docker

314
00:24:27,170 --> 00:24:30,770
container so each memory sample is like
totally isolated in its own fire

315
00:24:30,770 --> 00:24:34,730
environment so you know docker docker
security

316
00:24:34,730 --> 00:24:43,220
this'll yeah there's a lot of dr. stuff
going on here yeah I network we don't

317
00:24:43,220 --> 00:24:47,630
collect network data you have to have
VPC flogs turned on it's on it's enough

318
00:24:47,630 --> 00:24:51,440
to do list we will grab that if it's
available but you might get some network

319
00:24:51,440 --> 00:24:54,620
information from number from memory so
make sure you check out the memory

320
00:24:54,620 --> 00:24:55,429
section

321
00:24:55,430 --> 00:25:02,780
alright so in conclusion of the AWS with
ir section covered a lot of preparation

322
00:25:02,780 --> 00:25:07,910
tools are three threat response tools if
there's any takeaways from this it's

323
00:25:07,910 --> 00:25:11,360
make sure you customize your response to
whatever your organization right

324
00:25:11,360 --> 00:25:16,010
practice using with any of our tools

325
00:25:16,010 --> 00:25:20,240
you want to use if you find they don't
do what you want them to do feel free to

326
00:25:20,240 --> 00:25:25,520
just cherry-pick the parts you like just
take the code its MIT license you like

327
00:25:25,520 --> 00:25:28,940
to do is put a little copywriter there
and you're good to go

328
00:25:28,940 --> 00:25:37,100
alright so this is where we get to the
the hack sign stuff which is what you

329
00:25:37,100 --> 00:25:43,550
really want to see right so if you want
to make something for the AWS security

330
00:25:43,550 --> 00:25:47,270
goes to some by the way like you can
just take any word about a cloud an

331
00:25:47,270 --> 00:25:51,290
action or a place and an optional thing
to operate on and you can make product

332
00:25:51,290 --> 00:25:53,570
mad libs for the AWS team

333
00:25:53,570 --> 00:26:03,439
yeah I got some labs so i have from our
small batch print to threat response

334
00:26:03,440 --> 00:26:07,880
t-shirts which are very first tee shirts
that I have paid for for this to give

335
00:26:07,880 --> 00:26:12,440
away for people who can answer my trivia
questions and you'll have your choice of

336
00:26:12,440 --> 00:26:19,070
a fabulous large or a fabulous small
because i never get small t-shirts at

337
00:26:19,070 --> 00:26:25,310
security conferences so i will give you
a choice so I have these so who said

338
00:26:25,310 --> 00:26:34,340
defense without offence is just
compliance just shouted out know anybody

339
00:26:38,080 --> 00:26:46,330
the slides are on the internet it was
Dan Kaminsky so I will reserve one

340
00:26:46,330 --> 00:26:49,840
t-shirt for the person who asked the
least inane question at the end of the

341
00:26:49,840 --> 00:26:54,850
presentation but i love this i love this
talk because dan kaminsky says that we

342
00:26:54,850 --> 00:26:58,120
make keep making the same mistakes over
and over insecurity and we we aren't

343
00:26:58,120 --> 00:27:03,518
learning you know so we can be better
defenders by learning to be attackers

344
00:27:03,519 --> 00:27:07,840
and so we let's talk about how you would
model these advanced attacks in your

345
00:27:07,840 --> 00:27:12,699
environment logging disruption security
token service persistence and my new

346
00:27:12,700 --> 00:27:17,590
super cool backdoor toolkit that i'm
going to release today here at Derby con

347
00:27:17,590 --> 00:27:23,918
I'm not that proud of it but i don't
think anybody's ever done it so being

348
00:27:23,919 --> 00:27:31,269
first is worth something even if it
sucks so ground rules non-boring

349
00:27:31,269 --> 00:27:35,740
material ahead if i do a demo you have
to clap even if you think it's terrible

350
00:27:36,519 --> 00:27:42,279
or I will not finish the presentation
them feel guilty next door that they did

351
00:27:42,279 --> 00:27:44,230
not choose this talk

352
00:27:44,230 --> 00:27:51,039
ok so those are the rules so logging
disruption there are three variations of

353
00:27:51,039 --> 00:27:53,980
this attack that were published by
Daniel gray slacks earlier this year

354
00:27:53,980 --> 00:27:59,320
that everybody freaked out about I can't
believe they freaked about just turn it

355
00:27:59,320 --> 00:28:05,889
off right like stopped because that's a
really noisy attack you can also do

356
00:28:05,889 --> 00:28:09,939
things like stop regional logging and
global logging i also think that's kind

357
00:28:09,940 --> 00:28:10,929
of boring

358
00:28:10,929 --> 00:28:16,059
my favorite is make cloud trail operate
but make the logs totally unreadable

359
00:28:16,659 --> 00:28:22,210
so you can actually do anything with
them so this is your cloud trail like

360
00:28:22,210 --> 00:28:27,460
you think of cloud trail as the like
all-seeing eye of sour on right looks

361
00:28:27,460 --> 00:28:30,340
like a huge like

362
00:28:30,340 --> 00:28:38,918
you can tell you from Georgia he's also
never seen the lord of the rings I'm so

363
00:28:38,919 --> 00:28:41,110
sorry

364
00:28:41,110 --> 00:28:47,110
so cloud trail it it sees all the API
events it logs all the events and it

365
00:28:47,110 --> 00:28:51,370
puts them in an s3 bucket great right
like you can do things with those logs

366
00:28:51,370 --> 00:28:55,120
like detect evil like with little cloud
watching events and lemmings and things

367
00:28:55,690 --> 00:29:00,610
this is your cloud trail on Krypto
everything still happens it's still logs

368
00:29:00,610 --> 00:29:05,139
all the events but the events get
encrypted with a key that nothing can

369
00:29:05,140 --> 00:29:12,880
use besides the attacker so things don't
happen then like detecting evil so this

370
00:29:12,880 --> 00:29:17,320
basically makes it an exercise in
burning money like $MONEY in the account

371
00:29:17,320 --> 00:29:22,330
as an attacker because you're encrypting
against and encrypt only key to create

372
00:29:22,330 --> 00:29:26,500
this in the account is moderately
difficult from the API you have to set

373
00:29:26,500 --> 00:29:30,610
this flag called bypass policy lockout
safety check

374
00:29:31,210 --> 00:29:38,890
like why is that even a feature like why
can i do this it does come with a lot of

375
00:29:38,890 --> 00:29:42,669
warnings in the in the Amazon
documentation and that's like a big

376
00:29:42,669 --> 00:29:48,789
finger that says hey look here look here
hackers you can use this to do some cool

377
00:29:48,789 --> 00:29:54,070
stuff so what this requires a really
high level of privilege but it is really

378
00:29:54,070 --> 00:29:57,580
handy if you happen to come across a set
of high privilege keys for remaining

379
00:29:57,580 --> 00:30:04,090
undetected in the account and it's also
not necessarily undetectable so has

380
00:30:04,090 --> 00:30:07,928
anybody seen this on the internet like
this was a big thing the the moon

381
00:30:07,929 --> 00:30:11,049
balloon the terrorize people i would
describe this is not normal behavior

382
00:30:11,049 --> 00:30:16,809
right and i love this like lady with the
bike you know and the moon is coming at

383
00:30:16,809 --> 00:30:19,809
her and she's like what do I do with my
bike

384
00:30:20,900 --> 00:30:29,000
so I so this disruptive logging create
some not normal markers so creating

385
00:30:29,000 --> 00:30:32,870
encryption keys if this is not something
that you do regularly is going to get

386
00:30:32,870 --> 00:30:37,790
logged prior to somebody performing this
attack calling update trail on your

387
00:30:37,790 --> 00:30:40,820
cloud trails is probably also not
something that you do every day you

388
00:30:40,820 --> 00:30:45,230
don't change you're logging settings so
just detecting these two things and

389
00:30:45,230 --> 00:30:49,670
being able to sort of bounced back to a
known good state for your logging is

390
00:30:49,670 --> 00:30:55,220
something that you should be moderately
competent at so i put out a blog article

391
00:30:55,220 --> 00:30:58,370
on this part of a series i'm writing
called defense against the dark arts

392
00:30:59,540 --> 00:31:03,139
that's a four-part series that
deconstructs Daniel gray slacks blogs

393
00:31:03,140 --> 00:31:08,450
and proposes defenses and so there is
lambda code in this blog article that

394
00:31:08,450 --> 00:31:12,050
you can just drop into your account and
it will snap your cloud trail back to a

395
00:31:12,050 --> 00:31:19,159
known good state so this is that cloud
watch event pipeline in action like as a

396
00:31:19,160 --> 00:31:23,900
diagram so it's like putting little tiny
all-seeing eyes on cloud watch events

397
00:31:23,900 --> 00:31:28,040
that look for other things and they run
some lambda code so it's really simple

398
00:31:28,040 --> 00:31:33,320
it's just python so everything will
still happen so here's a video of that

399
00:31:33,320 --> 00:31:38,840
inaction by pretending to be an evil
attacker coming in like turning off

400
00:31:38,840 --> 00:31:42,679
logging i do it with clicking instead of
commands you know for theatrical ality

401
00:31:42,680 --> 00:31:47,870
so I'm doing bad things like let's
pretend bad things bad things bad things

402
00:31:47,870 --> 00:31:51,439
I turned off the log I turned off all
regions

403
00:31:51,440 --> 00:32:01,400
let's count to 10 now three four five
six seven eight nine ten somewhere in

404
00:32:01,400 --> 00:32:07,190
here there's lambda code firing in the
background and oh my god it's all put

405
00:32:07,190 --> 00:32:11,360
back to the way I think it should be so
you can do this in your account

406
00:32:12,380 --> 00:32:18,980
yeah

407
00:32:18,980 --> 00:32:22,820
so now let's talk about really scary
stuff

408
00:32:22,820 --> 00:32:28,668
I'm glad you remember the rules though
so security token service attacks

409
00:32:28,669 --> 00:32:33,679
security token service attacks are great
i love this because it's exploiting a

410
00:32:33,679 --> 00:32:38,360
feature right so that's what we do is
attackers we take things that are useful

411
00:32:38,360 --> 00:32:43,668
and we weaponize them so how do these
attacks happen they happen through

412
00:32:43,669 --> 00:32:48,020
metadata compromise like I showed you as
a result of a key compromise or some

413
00:32:48,020 --> 00:32:52,580
credentials lead through an application
running on a roll so it with the ec2

414
00:32:52,580 --> 00:32:56,899
command line you can generate these with
AWS sts get session token and you can

415
00:32:56,900 --> 00:33:01,070
specify a duration in seconds that that
session token will be valid for I think

416
00:33:01,070 --> 00:33:05,418
this can be up to like 72 hours or
something like some really high number i

417
00:33:05,419 --> 00:33:11,090
might be wrong about that but it's large
and so these session tokens are an

418
00:33:11,090 --> 00:33:14,870
access key a secret key and a token and
you can just plop that in a boat OH

419
00:33:14,870 --> 00:33:20,959
profile and you can go to town with that
token so we can't revoke temporary sts

420
00:33:20,960 --> 00:33:26,570
tokens which I think really sucks about
the I am dashboard and without cloud

421
00:33:26,570 --> 00:33:29,899
trail you have no way to know how many
of these tokens have basically been

422
00:33:29,900 --> 00:33:34,160
shredded in your account like by an
attacker and someone can actually come

423
00:33:34,160 --> 00:33:38,419
along and use these to like completely
end your account because if you just do

424
00:33:38,419 --> 00:33:44,540
disable access key or something all
those tokens are still valid so

425
00:33:44,540 --> 00:33:48,530
companies have like cease to be because
of attacks like this where they couldn't

426
00:33:48,530 --> 00:33:53,990
recover after all there instances were
terminated and all of their account s3

427
00:33:53,990 --> 00:33:57,650
buckets were depleted so has anybody
ever heard of the code space attack like

428
00:33:57,650 --> 00:34:00,740
two other guys have reference this this
weekend so I wish I had a better example

429
00:34:00,740 --> 00:34:06,350
but this is kind of the go-to so as a
company we all know Trust is hard to

430
00:34:06,350 --> 00:34:09,500
gain and really easy to lose and like
one breach

431
00:34:09,500 --> 00:34:14,840
can you know be the in game scenario so
how do you defend against this you don't

432
00:34:14,840 --> 00:34:19,100
but there is kind of a way so just
kidding

433
00:34:19,100 --> 00:34:24,529
there is a defense sort of which is that
you can either denying access to the

434
00:34:24,530 --> 00:34:28,790
creator of those tokens so you can
completely remove an account you can

435
00:34:28,790 --> 00:34:30,699
deny access to the name

436
00:34:30,699 --> 00:34:35,020
or my favorite is actually attaching a
policy that denies access to any

437
00:34:35,020 --> 00:34:39,310
temporary session token' issue before a
date timestamp so you can effectively

438
00:34:39,310 --> 00:34:44,619
draw a line in the sand and say nothing
before this moment it's valid anymore so

439
00:34:44,619 --> 00:34:46,000
if you have a breach

440
00:34:46,000 --> 00:34:51,040
that's something I would just do to
every account is attached this policy so

441
00:34:51,040 --> 00:34:55,359
it looks like this it's really simple
policy time based replication this is

442
00:34:55,359 --> 00:34:59,049
straight out of amazon docks so
one-and-done kind of policy too attached

443
00:34:59,050 --> 00:35:04,180
to all roles and we're gonna add this to
our CLI yorkie compromises here very

444
00:35:04,180 --> 00:35:09,368
soon so now that you have this like go
go defend your amazon accounts like tell

445
00:35:09,369 --> 00:35:12,730
other people how to defend against these
attacks so we can stop talking about

446
00:35:12,730 --> 00:35:18,849
them at conferences so now we get to my
favorite new type of attack which is

447
00:35:18,849 --> 00:35:23,770
back doors via API gateway so does
anybody use API gateway here for like

448
00:35:23,770 --> 00:35:24,579
real business

449
00:35:24,579 --> 00:35:29,470
ok ok couple it's relatively new it's
serverless so that means that Amazon

450
00:35:29,470 --> 00:35:33,730
like take some code like run Satori and
you can attach resti things to the other

451
00:35:33,730 --> 00:35:39,010
side so people say serverless is the
future i say serverless is the future of

452
00:35:39,010 --> 00:35:45,670
attacks because these are so new
auditing really hasn't liked caught up

453
00:35:45,670 --> 00:35:50,170
with service tech yet and you can be
really quiet so we can make backdoors we

454
00:35:50,170 --> 00:35:54,430
can exfiltrate data we can run a c2 for
a botnet we could run a ransomware back

455
00:35:54,430 --> 00:35:59,589
in and lots of other things and so I
made a backdooring tool for api gateway

456
00:35:59,589 --> 00:36:05,980
with a service framework so when why
would I make a backdoor tool so who said

457
00:36:05,980 --> 00:36:14,050
it was once my job to think is dark
Wizards do it was mad eye moody from

458
00:36:14,050 --> 00:36:18,040
harry potter and i love this like I love
this character because they actually

459
00:36:18,040 --> 00:36:23,650
chastise him in the movie for knowing
how to do bad things and I'm like I have

460
00:36:23,650 --> 00:36:28,210
been that guy like in in a business like
why do you know so much about attacks so

461
00:36:28,210 --> 00:36:33,430
you want a t-shirt so be sure to come up
and and grab your t-shirt like that you

462
00:36:33,430 --> 00:36:35,230
want now or later

463
00:36:35,230 --> 00:36:43,660
so my backdoor toolkit is called the Mad
King so imagine that you're you're

464
00:36:43,660 --> 00:36:44,319
working

465
00:36:44,320 --> 00:36:48,670
at a business bad things happen one of
your developers lead to super privileged

466
00:36:48,670 --> 00:36:53,620
access key you manage you think that you
save the day like you even clean account

467
00:36:53,620 --> 00:36:59,020
of sts tokens and then the attackers
still in your company and then you're

468
00:36:59,020 --> 00:37:01,600
very sad you're thinking how how did
they

469
00:37:01,600 --> 00:37:05,470
how could they do that you know maybe
you're moving your job packing your bags

470
00:37:05,470 --> 00:37:12,339
who knows so let's look at how that how
that works so i use a service framework

471
00:37:12,340 --> 00:37:18,280
called Zappa so it does anybody use
Zappa it's amazing because you can just

472
00:37:18,280 --> 00:37:19,210
like right

473
00:37:19,210 --> 00:37:24,580
django or flask and Zappa will shred
that until a million little tiny lambda

474
00:37:24,580 --> 00:37:29,799
functions and push it into an account
which i think is great so you just run

475
00:37:29,800 --> 00:37:35,320
one command staff and deploy production
and it starts deploying this backdoor

476
00:37:35,320 --> 00:37:40,960
into the account so we already have
access at this point but we want to stay

477
00:37:40,960 --> 00:37:45,670
beyond our keys being disabled or SDS
tokens being revoked and we want to do

478
00:37:45,670 --> 00:37:51,190
that rather quietly right so set up all
the API gateway routes uploads you know

479
00:37:51,190 --> 00:37:58,780
some lambda code and stuff and then at
the end what you get back is just a URL

480
00:37:58,780 --> 00:38:06,790
it's like this is your end . so it's not
as exciting as the video of it actually

481
00:38:06,790 --> 00:38:12,910
working this a web interface now that I
can hit at that end . so i put a few

482
00:38:12,910 --> 00:38:18,370
simple like POC buttons in this recon
disrupt and persist just so you can

483
00:38:18,370 --> 00:38:22,690
model these attacks in your environment
like you have this for your IR game day

484
00:38:22,690 --> 00:38:27,040
or whatever not to actually end people
so you can see it says running with

485
00:38:27,040 --> 00:38:30,910
stolen credentials from I get the
account ID i can stop instances i can

486
00:38:30,910 --> 00:38:36,430
terminate instances from here the
inventory takes a little bit of a long

487
00:38:36,430 --> 00:38:39,609
time to run because it has to worry all
regions globally that's kind of the only

488
00:38:39,610 --> 00:38:43,420
downside of services that you don't
really have cash without credit or

489
00:38:43,420 --> 00:38:45,800
something

490
00:38:45,800 --> 00:38:52,190
then optimize the attack school
attacking this is like a weekend's worth

491
00:38:52,190 --> 00:38:56,990
of API gateway persistence effort so but
I needed it so that i can profile the

492
00:38:56,990 --> 00:39:00,979
attacks so i can write detection
pipelines so we can stop cloud trail

493
00:39:00,980 --> 00:39:04,250
here we can delete cloud trails and i
also added a button that does that

494
00:39:04,250 --> 00:39:07,550
encrypted cloud trail so you can
practice that in your own environment

495
00:39:10,730 --> 00:39:15,320
this is me obviously being very confused
while I'm recording as to what's

496
00:39:15,320 --> 00:39:21,410
happened and so we'll get to the
exciting part at the end here where we

497
00:39:21,410 --> 00:39:24,529
actually see that I can generate
additional session tokens so one of the

498
00:39:24,530 --> 00:39:28,550
things that people don't seem to audit a
lot is that you can have to access keys

499
00:39:28,550 --> 00:39:32,690
and if a developer doesn't already have
to access keys you can just ask for

500
00:39:32,690 --> 00:39:36,200
another one and it will just spit that
out as long as you have appropriate

501
00:39:36,200 --> 00:39:39,680
privilege and so I added this kid
prudential feature and I made a copy and

502
00:39:39,680 --> 00:39:43,910
paste able so you can just take that and
chuck it into a boat OH profile the

503
00:39:43,910 --> 00:39:48,830
internet is going crazy with those
queues at any time you can also decide

504
00:39:48,830 --> 00:39:52,310
if it's not going well to click the burn
them all button just like the Mad King

505
00:39:52,310 --> 00:39:57,320
and it will terminate all the instances
in the account like by API gateway pivot

506
00:39:57,320 --> 00:40:04,820
so here we see it actually burning them
all so I click the button like there's

507
00:40:04,820 --> 00:40:08,150
little area running in lambda and the
account is actually just destroying

508
00:40:08,150 --> 00:40:11,150
itself

509
00:40:17,280 --> 00:40:23,820
so this is there for you to build your
alert pipelines it's not there for you

510
00:40:23,820 --> 00:40:27,180
to do bad things right so you could
throw this in a test environment or

511
00:40:27,180 --> 00:40:30,120
something and then like hook up your
cloud watch events and stuff and like

512
00:40:30,120 --> 00:40:38,160
revel in the glory of getting these
alerts and then sleep well yeah yeah so

513
00:40:38,160 --> 00:40:44,399
yeah do not have the wrong boto profile
at the time but we did in fact just burn

514
00:40:44,400 --> 00:40:49,710
the entire council that was my account
all those access Keys have been disabled

515
00:40:50,550 --> 00:40:56,100
don't even bother you just make amazon
really unhappy so what that is a really

516
00:40:56,100 --> 00:41:01,710
small payload like it's less than like
10 megabytes i think in total it gives

517
00:41:01,710 --> 00:41:05,280
you persistence in the account and
there's actually a nun deploy function

518
00:41:05,280 --> 00:41:09,600
that you can use that will tell it to
surgically clean up its own logs that's

519
00:41:09,600 --> 00:41:13,710
like a feature dash dash delete logs
zappa and I'll just like kind of go

520
00:41:13,710 --> 00:41:16,890
extract its own events from cloud trail
and cloud watch which i think is great

521
00:41:17,880 --> 00:41:21,960
most platforms probably aren't auditing
serverless yet so this is like a little

522
00:41:21,960 --> 00:41:25,590
bit of an arms race for a while and
there's no such thing as a security

523
00:41:25,590 --> 00:41:30,630
group for who can talk to an API gateway
that there's no firewall is just out

524
00:41:30,630 --> 00:41:34,140
there they rely on API keys to keep you
safe

525
00:41:35,970 --> 00:41:40,950
so now we're to the final tips and
resources section which i think is mine

526
00:41:40,950 --> 00:41:45,450
alright so how do we protect ourselves
from this stuff no less than what i call

527
00:41:45,450 --> 00:41:50,220
three dumb clouds steve gibson anybody
know Steve Gibson security now podcast

528
00:41:50,220 --> 00:41:54,689
guy he does that great stick about no
less than three dumb routers in your

529
00:41:54,690 --> 00:41:58,710
home to separate IOT devices from your
actual computers

530
00:41:58,710 --> 00:42:03,870
why wouldn't we do the same thing for
our AWS accounts and instead of running

531
00:42:03,870 --> 00:42:09,600
dev test production in one cloud why not
have them be separate clouds so you can

532
00:42:09,600 --> 00:42:14,220
have real security boundaries between
these and this actually shows one for

533
00:42:14,220 --> 00:42:19,080
consolidated billing almost don't count
that as a cloud but maybe we actually

534
00:42:19,080 --> 00:42:23,279
need for clouds or even five clouds so I
think we're going to see the evolution

535
00:42:23,280 --> 00:42:24,320
of

536
00:42:24,320 --> 00:42:30,020
ops teams and second ops having security
clouds that look outside into your

537
00:42:30,020 --> 00:42:34,370
production into your development and are
saying is this behavior normal am I

538
00:42:34,370 --> 00:42:38,720
still receiving logs and have all of the
alerting in that fashion where people

539
00:42:38,720 --> 00:42:42,230
don't care about multi-factor
authentication because we're security

540
00:42:42,230 --> 00:42:46,460
people like we don't we don't mind
jumping through all of these hoops just

541
00:42:46,460 --> 00:42:52,880
to get into the security cloud so we
love these companies that we showed off

542
00:42:52,880 --> 00:42:56,150
their stuff netflix capital one

543
00:42:56,150 --> 00:43:01,820
yelp and Prezi prezzies recently started
doing this huge collaboration with

544
00:43:01,820 --> 00:43:06,680
netflix augmenting their stuff so we
should really like applaud them like for

545
00:43:06,680 --> 00:43:10,609
taking their secret security sauce and
putting that out there online and if you

546
00:43:10,610 --> 00:43:15,620
have secret sauce like contact us and
we'll try and help you put it out online

547
00:43:15,620 --> 00:43:21,560
maybe as part of our project and we love
our contributors we need users to test

548
00:43:21,560 --> 00:43:23,720
our stuff because it's so young

549
00:43:23,720 --> 00:43:27,919
we need you to like break it and file
pull requests and tell us that we made

550
00:43:27,920 --> 00:43:32,690
bad assumptions about ir if those exist
in our tools which I'm sure that they do

551
00:43:32,690 --> 00:43:38,900
somewhere so please test our stuff and
let us know if it applies to you so if

552
00:43:38,900 --> 00:43:41,900
you want more information we have a
mailing list you can subscribe to

553
00:43:42,860 --> 00:43:48,110
we have a future roadmap feature roadmap
which I don't have time to talk about

554
00:43:48,110 --> 00:43:52,400
and take questions so we'll leave that
to the internet thanks to all these

555
00:43:52,400 --> 00:43:53,300
people

556
00:43:53,300 --> 00:43:56,570
amazon web services security
specifically these guys have been great

557
00:43:56,570 --> 00:44:01,790
and incredibly supportive of our project
der beek on staff Tony delafuente the

558
00:44:01,790 --> 00:44:06,259
person who did our slide illustrations
and our team member who can be with us

559
00:44:06,260 --> 00:44:11,120
today and seriously don't let me forget
to take questions at the end of this

560
00:44:12,559 --> 00:44:26,930
yes you can use a laugh it's just not
actually part of API gateway as a as a

561
00:44:26,930 --> 00:44:29,930
service

562
00:44:31,430 --> 00:45:24,529
yeah I'm way

563
00:45:25,119 --> 00:45:28,720
can't comment on all of that because I
just don't have like all of the

564
00:45:28,720 --> 00:45:32,410
information about inside AWS but what I
can tell you is that the security team

565
00:45:32,410 --> 00:45:36,788
there that we have worked with has been
incredibly receptive to our feedback so

566
00:45:36,789 --> 00:45:41,019
those guys don bailey who is a principal
security architect of AWS has been like

567
00:45:41,019 --> 00:45:46,299
a real advocate for getting more into
the response capabilities like into AWS

568
00:45:46,299 --> 00:45:49,329
as a whole

569
00:45:49,329 --> 00:45:57,819
yeah yeah having open source for API
endpoints and and things like that or

570
00:45:57,819 --> 00:46:00,579
just platform in general

571
00:46:00,579 --> 00:46:05,380
yeah we would love to see that but we
haven't had any dialogue at any point

572
00:46:05,380 --> 00:46:08,380
with anyone inside amazon that could
even speak to that

573
00:46:10,820 --> 00:46:13,820
go for it

574
00:46:16,670 --> 00:46:19,820
so right now our tools need to have a
very high level of access

575
00:46:19,820 --> 00:46:23,870
we're working on whittling that down
since we're getting better at being I am

576
00:46:23,870 --> 00:46:29,330
policy ninjas what that stuff does tend
to hurt your brain a little bit when

577
00:46:29,330 --> 00:46:33,500
you're trying to get down to a point of
really privileged policies so we're in

578
00:46:33,500 --> 00:46:38,510
the process of reducing it right now but
it does need create bucket list bucket

579
00:46:38,510 --> 00:46:45,470
upload bucket stop instance take
snapshot so that's high privilege i

580
00:46:45,470 --> 00:46:48,049
would consider

581
00:46:48,049 --> 00:46:52,130
any other questions thanks everybody

582
00:46:52,130 --> 00:46:52,789
you guys went great

