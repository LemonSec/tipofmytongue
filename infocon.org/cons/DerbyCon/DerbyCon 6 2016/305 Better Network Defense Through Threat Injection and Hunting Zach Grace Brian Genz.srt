1
00:00:00,350 --> 00:00:07,369
afternoon guys

2
00:00:07,370 --> 00:00:15,050
restart here so I'm Jack grace this is
friends and we talked about some network

3
00:00:15,050 --> 00:00:21,560
defense stuff and a little bit of purple
team talk here so this talk is kind of

4
00:00:21,560 --> 00:00:26,210
coming from his i spent number of years
beyond red team's and basically no you

5
00:00:26,210 --> 00:00:31,279
go in your place you find all these
bones and her team you go you're gonna

6
00:00:31,279 --> 00:00:34,909
go fix all the stuff and come back next
year and guess what

7
00:00:34,909 --> 00:00:39,979
same thing happens right you go you own
them and go well why did you guys catch

8
00:00:39,979 --> 00:00:43,339
this we did lots of other things was the
last time you know maybe the initial

9
00:00:43,339 --> 00:00:47,179
vector of getting in is different you
know maybe you know your fish last time

10
00:00:47,179 --> 00:00:52,010
and we found a network of all this time
to get us in or whatever but you didn't

11
00:00:52,010 --> 00:00:55,670
detect all the similar lateral movement
things that we did in Texas getting on

12
00:00:55,670 --> 00:01:00,530
your domain controller and dumping all
the hashes so what we realized is one of

13
00:01:00,530 --> 00:01:06,380
the big gaps you haven't current red
team is that the deliverable is really

14
00:01:06,380 --> 00:01:10,219
vulnerable focuses hey let's go fix all
these phones but you don't really have

15
00:01:10,219 --> 00:01:13,729
anything saying hey usually tax we did
you should start to work on your

16
00:01:13,729 --> 00:01:17,960
detection so if you take that that ready
report or test report what you want to

17
00:01:17,960 --> 00:01:20,390
call it and you give it to your sock

18
00:01:20,390 --> 00:01:24,200
they're gonna look and see there's
really nothing for me to do here right

19
00:01:24,200 --> 00:01:27,859
that I can maybe start to reduce in this
research but it's not very actionable

20
00:01:27,859 --> 00:01:32,600
for them and so what we wanted to work
on was ok so how can make that better

21
00:01:32,600 --> 00:01:35,719
and we still need to talk about the
issues about the vulnerabilities but how

22
00:01:35,719 --> 00:01:40,460
do we also give them something else that
sack team can use to come better

23
00:01:40,460 --> 00:01:43,460
defenders

24
00:01:45,650 --> 00:01:49,820
so what is the blue team we need a
training partner

25
00:01:50,480 --> 00:01:57,110
there's no teacher but the enemy right
friendly attack signatures and basically

26
00:01:57,110 --> 00:02:02,240
helping understand when you detect
something network understand it through

27
00:02:02,240 --> 00:02:06,410
the lens of the attacker understand the
context and what's going on in the big

28
00:02:06,410 --> 00:02:11,270
thing that I think is important and take
away from this is better visibility to

29
00:02:11,270 --> 00:02:13,340
understand what normal looks like

30
00:02:13,340 --> 00:02:22,220
and I Jake Williams this summer was
talking about some sort of a TV special

31
00:02:22,220 --> 00:02:25,790
and I don't remember what it's called
had something to do with the Secret

32
00:02:25,790 --> 00:02:29,630
Service and they were having trouble
training agents that were doing

33
00:02:29,630 --> 00:02:35,120
counterfeit detection and they kept
failing in the detection and what they

34
00:02:35,120 --> 00:02:39,620
found was that they didn't know what
correct money looked like what actual

35
00:02:39,620 --> 00:02:43,610
legitimate money looked like when you
get out into the street there's

36
00:02:43,610 --> 00:02:49,070
different textures different fields
different situations and I think once

37
00:02:49,070 --> 00:02:54,140
you translate that into our world you
know how do we actually know that we

38
00:02:54,140 --> 00:02:59,540
know what normal looks like what is
supposed to prop what's going to spawn

39
00:02:59,540 --> 00:03:05,269
this process and how can we detect
something when we've got lateral

40
00:03:05,269 --> 00:03:11,269
movement inside of our network now to
zachs . you might have a pen test report

41
00:03:11,269 --> 00:03:14,209
but for the folks that are doing the
detection

42
00:03:14,209 --> 00:03:21,320
where do they stop in this kill chain in
this tack vector and say when this jumps

43
00:03:21,320 --> 00:03:26,750
over to this machine here are the
artifacts that are created what normal

44
00:03:26,750 --> 00:03:29,390
looks like is this but here's what just
happened

45
00:03:29,390 --> 00:03:35,029
yeah so the the goal of what we're
trying to propose here is really to

46
00:03:35,030 --> 00:03:38,810
reduce that meantime detection so if you
ask any red team here you know

47
00:03:38,810 --> 00:03:42,020
compromise generally is very quick right
so it can be you know

48
00:03:42,020 --> 00:03:46,700
excluding the Recon portions of things
the actual sending the fish or whatever

49
00:03:46,700 --> 00:03:52,369
the pale it is happens within seconds to
maybe minutes but detection actually

50
00:03:52,370 --> 00:03:56,450
generally takes you know much much
longer so you know weeks to months to

51
00:03:56,450 --> 00:04:01,040
potentially never you know somebody push
yourself a pastebin or you get called by

52
00:04:01,040 --> 00:04:04,820
crabs right maybe that's you when you
know that you've been owned right so the

53
00:04:04,820 --> 00:04:08,420
goal is to try to take that from you
know that very long time frame down to a

54
00:04:08,420 --> 00:04:13,519
much shorter time frame and so what
we're proposing here's what we're

55
00:04:13,520 --> 00:04:20,810
calling the threat detection maturity
model so some of the background here

56
00:04:20,810 --> 00:04:25,370
we're looking at ways that we can have
tighter integration between red and blue

57
00:04:25,370 --> 00:04:30,380
team's I'm so from the blue team
perspective i'm on a hunt team and again

58
00:04:30,380 --> 00:04:35,120
emphasizing knowing what normal looks
like I think that that's there's more to

59
00:04:35,120 --> 00:04:39,290
that and there there's a lot of
different angles that we have to be

60
00:04:39,290 --> 00:04:44,600
familiar with what normal looks like in
different sectors and segments the

61
00:04:44,600 --> 00:04:48,740
network and then looking for anomalous
behavior no least frequency of

62
00:04:48,740 --> 00:04:54,470
occurrence know if we talk about
autoruns or shim cash or any number of

63
00:04:54,470 --> 00:04:57,740
things that might look at one machine
how do we scale that out how do we look

64
00:04:57,740 --> 00:05:02,750
at abnormal activities on the endpoints
but do it across all the endpoints and

65
00:05:02,750 --> 00:05:06,440
you know how do we have the discussions
with management to make sure instrument

66
00:05:06,440 --> 00:05:10,370
instrumentation is right so that we have
the visibility into those sections

67
00:05:10,970 --> 00:05:16,760
yeah so from the red team side where
we're gonna be talking something called

68
00:05:16,760 --> 00:05:21,260
through injection and the way we're
looking at this is a very specific

69
00:05:21,260 --> 00:05:26,030
single detectable thing so a simple
example that we're going to walk through

70
00:05:26,030 --> 00:05:30,979
later is you know registry-based
persistence and also if you put your

71
00:05:30,980 --> 00:05:35,510
persistence in all runs next time some
logs in orbits machine is going to keep

72
00:05:35,510 --> 00:05:41,360
your back shell and that's example of
like a thread injection and we talked a

73
00:05:41,360 --> 00:05:46,160
bit about you know the might attack
framework and using that as like a

74
00:05:46,160 --> 00:05:49,280
prioritize backlog for things that you
should be trying to detect

75
00:05:49,810 --> 00:05:56,139
the goal of this threat detection
maturity model is really like we said

76
00:05:56,139 --> 00:06:01,419
before to reduce that meantime detection
it gives a way to objectively measure

77
00:06:01,419 --> 00:06:06,310
those capabilities and really tracks and
progress over time we've seen instances

78
00:06:06,310 --> 00:06:10,660
already with this that were actually
able to show some return on investment

79
00:06:10,660 --> 00:06:14,500
so as you invest in new technologies you
can these new capabilities you can show

80
00:06:14,500 --> 00:06:18,070
your leadership that hey you spent that
money years working for it

81
00:06:18,820 --> 00:06:26,290
it's been pretty effective for us and
moving on to the might attack framework

82
00:06:26,290 --> 00:06:29,050
so how many people have heard of this
thing

83
00:06:29,050 --> 00:06:36,010
sweet so quite a few it's it's pretty
slick so we started doing this

84
00:06:36,010 --> 00:06:39,610
33 injection we actually started making
our own list like all the different

85
00:06:39,610 --> 00:06:44,800
resistance mechanisms different ways do
you let movement and and whatnot and

86
00:06:44,800 --> 00:06:49,479
then NFC and treat by sub teasing hey
Jed want to stop this frame working we

87
00:06:49,479 --> 00:06:50,710
won't look into the wall

88
00:06:50,710 --> 00:06:55,090
cool let's let's use that instead of
reinventing the wheel so this thing's

89
00:06:55,090 --> 00:06:59,830
not it is fairly comprehensive i'm sure
there's many others out there but if we

90
00:06:59,830 --> 00:07:03,640
think about the pareto principle and
let's do the 80 basically this should

91
00:07:03,640 --> 00:07:10,900
cover about the eighty percent is a good
starting point and sort the premise of

92
00:07:10,900 --> 00:07:15,520
this model is that the focus on the
latter half of the kill chain so if

93
00:07:15,520 --> 00:07:20,650
looking at the arrow here this is their
their version of the kill chain and not

94
00:07:20,650 --> 00:07:24,789
not focusing so much on like how do you
get in but what happens after you get it

95
00:07:24,789 --> 00:07:27,550
the things that attackers do once
they're inside your environment that you

96
00:07:27,550 --> 00:07:34,810
should use to try to detect that
presence and so here's just a portion of

97
00:07:34,810 --> 00:07:39,760
that attack framework and there's ten
different tactics across the top so

98
00:07:39,760 --> 00:07:43,000
these are kind of categories of things
that attackers are going to do so it's

99
00:07:43,000 --> 00:07:46,960
everything from persistent to command
control to lateral movements and these

100
00:07:46,960 --> 00:07:49,840
are the types of things that we should
be focusing on getting better at

101
00:07:49,840 --> 00:07:55,030
detecting so out 10 tactics that breaks
down to over a hundred twenty different

102
00:07:55,030 --> 00:08:00,400
techniques and one of the things that
we've been doing is taking these and

103
00:08:00,400 --> 00:08:02,289
actually prioritize and based on our own

104
00:08:02,289 --> 00:08:07,119
threat model so what what would work for
us for privatization probably wouldn't

105
00:08:07,119 --> 00:08:07,809
work for you

106
00:08:07,809 --> 00:08:12,279
good example is if you have an
organization that said say doing a lot

107
00:08:12,279 --> 00:08:18,308
of international travel a bioattack
where somebody may take a laptop rewrite

108
00:08:18,309 --> 00:08:23,139
your bios might be more prevalent see
you then say an organization that is

109
00:08:23,139 --> 00:08:28,449
only based in the US and it doesn't have
that same same kind of attack threat so

110
00:08:28,449 --> 00:08:34,990
these need to be part is based on your
threat model so this is kind of the the

111
00:08:34,990 --> 00:08:41,589
working model for us where we've got the
minor attack technique as the backlog of

112
00:08:41,589 --> 00:08:46,930
221 different techniques you can use to
do all those different tactics so

113
00:08:46,930 --> 00:08:52,420
persistence letter movement and such and
go through the crack is based on you

114
00:08:52,420 --> 00:08:57,009
know what it is that you think its most
relevant for your organization based on

115
00:08:57,009 --> 00:09:01,480
your own threat model so first thing
after you've done that privatization is

116
00:09:01,480 --> 00:09:06,130
you take that out and you filled out
what's called a use case so many red

117
00:09:06,130 --> 00:09:09,579
teamers probably don't know what to use
cases and that's more blue team

118
00:09:09,579 --> 00:09:14,979
terminology so you gotta start to speak
the same spot same thing but use cases

119
00:09:14,980 --> 00:09:18,490
something that blue team take it would
take and used to pull out different

120
00:09:18,490 --> 00:09:24,819
symbols correlation rules and so when
you're working together and moral purple

121
00:09:24,819 --> 00:09:29,050
fashion like this on you basically come
up this together right we're going to

122
00:09:29,050 --> 00:09:34,240
talk about different maturity levels and
what you want to do so with the violence

123
00:09:34,240 --> 00:09:38,769
example we may not want to automatically
detect and respond to that with DoD

124
00:09:38,769 --> 00:09:44,829
probably does so in their use case what
they want as their their maturity goals

125
00:09:44,829 --> 00:09:50,109
can be different than say my so once you
have the use case saying we want to

126
00:09:50,110 --> 00:09:59,259
second say bios level persistence
automatically then you go out and all

127
00:09:59,259 --> 00:10:02,050
that threaten jection so three
injections just going to be that simple

128
00:10:02,050 --> 00:10:07,449
small little attack that actually does
the thing that we're trying to detect so

129
00:10:07,449 --> 00:10:12,760
once we built that out we can simply go
and execute threat so if

130
00:10:12,760 --> 00:10:16,210
it was a simple registry-based
persistence you know it may be as simple

131
00:10:16,210 --> 00:10:20,290
as you know and in lutein registry file
that you run that and now the

132
00:10:20,290 --> 00:10:27,310
persistence is there and now we can try
to go in and haunting and final ads and

133
00:10:27,310 --> 00:10:30,310
the bottom square we talk about
adjusting detection methods

134
00:10:31,030 --> 00:10:36,730
personally I break this down into if
something is an artifact that we should

135
00:10:36,730 --> 00:10:41,350
have seen and we had a failed to detect
or we didn't meet the standards that we

136
00:10:41,350 --> 00:10:45,520
set out to me I think it's really
important that we not will be people

137
00:10:45,520 --> 00:10:49,510
overhead about this this is a
multi-pronged thing is that skill set is

138
00:10:49,510 --> 00:10:54,910
it instrumentation is it other so when
you have a failed detection you know do

139
00:10:54,910 --> 00:10:58,900
that lessons learned and we'll see in
the example of a few slides here where

140
00:10:58,900 --> 00:11:03,160
we come back and say repeat the
injection at this time with more

141
00:11:03,160 --> 00:11:07,540
visibility and his ex . then you can
come back and justify saying with this

142
00:11:07,540 --> 00:11:15,640
investment we now had this greater level
of visibility we stop this attack now so

143
00:11:15,640 --> 00:11:22,420
once the the taxpayer successfully
detected basically easel to figure out

144
00:11:22,420 --> 00:11:28,420
how much the honorees optimization
analyze these things so if there are you

145
00:11:28,420 --> 00:11:31,180
want to hunt these things that that's
one thing if you want to make this

146
00:11:31,180 --> 00:11:34,030
automatically detected as your
environment that that's something

147
00:11:34,030 --> 00:11:35,500
completely different

148
00:11:35,500 --> 00:11:39,100
so the goal is to you to keep it
maintained those and what we've got here

149
00:11:39,100 --> 00:11:44,650
is this repeat injection so when we've
done this at our org we basically have

150
00:11:44,650 --> 00:11:50,230
seen that will repeat these over and
over again and it may happen that you

151
00:11:50,230 --> 00:11:55,120
don't detect it at some point and an
example is you know we've had one where

152
00:11:55,120 --> 00:12:00,280
we run every quarter that's that's what
we want to do and we're on the first

153
00:12:00,280 --> 00:12:01,000
quarter

154
00:12:01,000 --> 00:12:05,260
everything's cool we detected we got the
alert will get the IR response the next

155
00:12:05,260 --> 00:12:06,400
quarter we do it again

156
00:12:06,400 --> 00:12:10,750
same thing happens to record to go into
this and we get no no response we're

157
00:12:10,750 --> 00:12:13,870
going to alert your team never knows
that need go take a look at this thing

158
00:12:13,870 --> 00:12:19,570
and we can go to be to have like what
what was going on here and what this

159
00:12:19,570 --> 00:12:23,020
actually has been showing us is that the
more we build this out and automate this

160
00:12:23,020 --> 00:12:24,199
we can find

161
00:12:24,200 --> 00:12:28,460
we're coming like issues with our
infrastructure so that particular

162
00:12:28,460 --> 00:12:32,840
instance or happen be log ingestion
issues so it didn't reach through the

163
00:12:32,840 --> 00:12:36,260
threshold that was required to actually
trigger that alert so this is actually

164
00:12:36,260 --> 00:12:43,790
become more of a QA process for us so
sure that your your your sims are highly

165
00:12:43,790 --> 00:12:47,719
complex and they have lots of data gets
fed into him in this can actually help

166
00:12:47,720 --> 00:12:52,190
you identify where you may have issues
of that data has stopped to something

167
00:12:52,190 --> 00:13:01,550
your sims or recipes so we go to
implement this methodology you can do it

168
00:13:02,180 --> 00:13:07,130
really in what we look at three phases
so the initial phase just sitting down

169
00:13:07,130 --> 00:13:11,750
together at the blue team and let's do
that specific for injection let's do

170
00:13:11,750 --> 00:13:14,870
this persistence okay can we detect this
yes we can detect this is a single

171
00:13:14,870 --> 00:13:18,470
instance ok now detect this across the
enterprise

172
00:13:18,470 --> 00:13:23,570
yep we can also do that cool so what
happens next well as ready we get to be

173
00:13:23,570 --> 00:13:28,040
sort of the various right let's do this
as more of a black box alright so we do

174
00:13:28,040 --> 00:13:32,810
that same for injection and let's do it
on a box and not announce it and now do

175
00:13:32,810 --> 00:13:36,709
we follow that same response level do we
get the flyer response if that's what

176
00:13:36,710 --> 00:13:42,950
our goal is or do we get that log
correlated that's what those goals as

177
00:13:42,950 --> 00:13:46,400
long as that's going well then we get to
kind of move this up into you really

178
00:13:46,400 --> 00:13:51,800
more red team engagement so 13 come in
do the things that we want to do what we

179
00:13:51,800 --> 00:13:57,620
want to make sure that that we're still
identifying the same types of tactics

180
00:13:57,620 --> 00:14:02,780
step we have built already and we talked
a bit about that more actually get to a

181
00:14:02,780 --> 00:14:09,800
phone call threat simulation it's now we
get to our projection hunting demo so

182
00:14:09,800 --> 00:14:14,329
we're using a really basic scenario here
really sufficient email get

183
00:14:14,330 --> 00:14:20,120
registry-based persistence attacker
probably going to dump ashes and try to

184
00:14:20,120 --> 00:14:24,230
get that local miniature has so they can
try to some lateral movement using pass

185
00:14:24,230 --> 00:14:29,060
the hash and once they mean that viral
access maybe find domain admin credit

186
00:14:29,060 --> 00:14:29,900
and ran with me

187
00:14:29,900 --> 00:14:33,410
the cats or something like that and then
they want to go and compromise to make

188
00:14:33,410 --> 00:14:43,699
controller and then absolutely like lots
of data that pretty standard scenario so

189
00:14:43,700 --> 00:14:50,510
the scenario we have we simulated a
resource-constrained blue team so we

190
00:14:50,510 --> 00:14:55,580
limited to sources of friends and
artifacts being basically not flow and

191
00:14:55,580 --> 00:14:59,780
local logs now I mean specifically
called out a limited capability for

192
00:14:59,780 --> 00:15:08,300
collecting volatile data for live
response essentially so the first one is

193
00:15:08,300 --> 00:15:11,569
where we're looking at autozone
persistence you know it's pretty

194
00:15:11,570 --> 00:15:12,950
straightforward

195
00:15:12,950 --> 00:15:16,280
I think most of you seen this but
basically what we're doing here is we're

196
00:15:16,280 --> 00:15:23,209
in HK land-run we're dropping in a
simple powershell script that's gonna

197
00:15:23,210 --> 00:15:30,020
kick back and get an agent after
somebody is put into their system so

198
00:15:30,020 --> 00:15:35,720
this is one specific instance there's a
pretty good list here also upon wiki so

199
00:15:35,720 --> 00:15:41,960
we're talking about one very simple one
here there's I think 35 or more listed

200
00:15:41,960 --> 00:15:46,460
out of that website so as you think
about the scenario we're talking to hear

201
00:15:46,460 --> 00:15:50,930
you know will do this for one and you
wanted to be able to identify and scale

202
00:15:50,930 --> 00:15:56,030
this but then not just this one right
there's also create user and about 30

203
00:15:56,030 --> 00:15:58,550
other places that they could stick
different persistence within the

204
00:15:58,550 --> 00:16:03,500
registry and this is just registry-based
there's there's many other versions of

205
00:16:03,500 --> 00:16:08,990
this but for this example this is
basically are very simple injection

206
00:16:08,990 --> 00:16:16,790
we've added that a load to the local
machine all run and if you're doing this

207
00:16:16,790 --> 00:16:20,689
on a single instance you can use auto
runs from sysinternals try to identify

208
00:16:20,690 --> 00:16:27,590
was just stuff within the various
registry-based settings there's also you

209
00:16:27,590 --> 00:16:31,070
know w mind that you can do three year
and a number of different places that

210
00:16:31,070 --> 00:16:35,780
persistence lives was in movies talk
earlier and use kind of getting hard

211
00:16:35,780 --> 00:16:39,860
time to Marcus on the fish that like we
keep coming up with all these really

212
00:16:39,860 --> 00:16:43,370
cool persistence mechanisms and keeps
and 20 runs to make it easier for people

213
00:16:43,370 --> 00:16:48,170
identify so this works pretty well on a
single instance but obviously as you

214
00:16:48,170 --> 00:16:54,800
want to scale us out to enterprise it
comes a little more difficult and we

215
00:16:54,800 --> 00:17:00,949
talked about how to do something that
side so that's the next one that we want

216
00:17:00,950 --> 00:17:06,770
to focus on was really pass the hash so
is anybody not her to pass the hash no

217
00:17:06,770 --> 00:17:08,060
good

218
00:17:08,060 --> 00:17:15,349
so really basic example we compromise
the machine we we don't hatch 'as and we

219
00:17:15,349 --> 00:17:22,069
using this remote access we had a system
proxy through interpreter to use PS back

220
00:17:22,069 --> 00:17:27,708
pieces that command to spray and look
for a local easier that had elevated

221
00:17:27,709 --> 00:17:37,310
privileges so again keeping with the
scenario of a resource-constrained blue

222
00:17:37,310 --> 00:17:43,370
team when we just pick some free tools
here so this is Flo bad i think Jason

223
00:17:43,370 --> 00:17:44,959
Smith is here

224
00:17:44,960 --> 00:17:50,600
so Jason Smith Chris sander I got some
really slick install tools or flow bad

225
00:17:50,600 --> 00:17:55,760
and there's a silk back end we see that
one host the one that got infected talk

226
00:17:55,760 --> 00:17:56,540
to

227
00:17:56,540 --> 00:18:01,399
we're going to call it digital ocean .
are you and so this is a GUI right but

228
00:18:01,400 --> 00:18:06,710
you'll see in just a minute that you
have the ability with globe and we

229
00:18:06,710 --> 00:18:10,940
specifically didn't want to focus on
tools but I use this because it builds

230
00:18:10,940 --> 00:18:14,210
proficiency to understand what the
queries are going to look like so that

231
00:18:14,210 --> 00:18:17,210
as you do the visual exploratory
analysis

232
00:18:18,140 --> 00:18:24,110
you're also going to have visibility on
what the RW filter syntax is for the

233
00:18:24,110 --> 00:18:29,780
queries so what we're doing is trying to
understand you know what happened on

234
00:18:29,780 --> 00:18:33,170
this one machine keeping in mind the
scenario we only have net flow which

235
00:18:33,170 --> 00:18:38,870
will serve to kind of differentiate the
scenario for you know the second

236
00:18:38,870 --> 00:18:42,739
iteration that we would do later on so
we want to know is there any lateral

237
00:18:42,740 --> 00:18:49,460
movement so essentially we're going to
look for the distant destination port

238
00:18:49,460 --> 00:18:50,540
445

239
00:18:50,540 --> 00:18:53,870
and again we're just putting this in
here but there's the visual you could

240
00:18:53,870 --> 00:19:02,030
build it zero in on these hosts and then
were further doing the data reduction so

241
00:19:02,030 --> 00:19:07,760
with that will flip over to the free
version of multi go and grab this is a

242
00:19:07,760 --> 00:19:13,280
simple example but we can visualize talk
to other people about . 133 talking to

243
00:19:13,280 --> 00:19:19,820
multiple hosts on 45 and then you know
this is just showing it if we wanted to

244
00:19:20,360 --> 00:19:26,780
it scales out to 10,000 in a different
scenario we can trace back a lot of

245
00:19:26,780 --> 00:19:31,129
different things but just using some
free tools to understand and get a

246
00:19:31,130 --> 00:19:36,770
better level of visibility I think helps
us say okay here's what we found what we

247
00:19:36,770 --> 00:19:43,370
detected and what we were able to pivot
into with just netflow and then the next

248
00:19:43,370 --> 00:19:47,479
thing we want to look at is what we find
on disk and memory keeping in mind that

249
00:19:47,480 --> 00:19:54,950
our scenario we were using the free
tools were resource constraint so this

250
00:19:54,950 --> 00:20:02,360
is just a mandiant redline collector
that we threw on the victim system and

251
00:20:02,360 --> 00:20:06,260
you certainly we're not here to do a
tutorial on doing the forensics on this

252
00:20:06,260 --> 00:20:11,420
we just want to show a few different
examples of you know here we saw this

253
00:20:11,420 --> 00:20:21,260
process ID 568 was powershell exe we
have a time and essentially that's 835

254
00:20:21,260 --> 00:20:25,490
blue so now i'm making a note i can
pivot over look at other evidence

255
00:20:25,490 --> 00:20:32,330
sources hopefully everything's UTC and
we see that you know pide 568 which is

256
00:20:32,330 --> 00:20:38,840
powershell dot exe talked out to that
potentially malicious digitalocean . are

257
00:20:38,840 --> 00:20:46,639
you import a TCP and then we look at pre
fetch and we see the the times that

258
00:20:46,640 --> 00:20:53,180
matched we see some 4624 successful
logon logon type 3

259
00:20:54,900 --> 00:21:02,190
and then you know we we take what we can
from that but I think that part of the

260
00:21:02,190 --> 00:21:07,350
value and demonstrating what you can get
in terms of visibility if you have

261
00:21:07,350 --> 00:21:12,719
toolset a right then the first iteration
is well we didn't have any live response

262
00:21:12,720 --> 00:21:17,070
so the next time we do it if we're able
to go back have the conversation about

263
00:21:17,070 --> 00:21:20,189
resources instrumentation training as
needed

264
00:21:20,190 --> 00:21:24,360
now maybe we can have a lot of response
capability and get that critical

265
00:21:24,360 --> 00:21:31,740
visibility into the host so here just
using f response to connect remotely to

266
00:21:31,740 --> 00:21:38,040
the victim machine and now from that we
were able to pull you know the disc the

267
00:21:38,040 --> 00:21:47,310
memory and do some other more involved
analysis volatility so it's cool to do

268
00:21:47,310 --> 00:21:51,060
all the stuff we still have to report
that out which is to one of the issues

269
00:21:51,060 --> 00:21:57,750
with current red team engagement reports
so as we start to provide this

270
00:21:57,750 --> 00:22:01,920
information back to the blue to me to
put into contact with them of you know

271
00:22:01,920 --> 00:22:05,790
here's the things you should be looking
for in terms of you know this attack

272
00:22:05,790 --> 00:22:09,420
that i had so we performed to pass the
hash attack so this might be an example

273
00:22:09,420 --> 00:22:15,450
of why provide back to Brian here to say
hey we did the thing here's what you

274
00:22:15,450 --> 00:22:18,900
should be looking for both locally and
on the network level so we have a couple

275
00:22:18,900 --> 00:22:23,190
different places we can look right so on
the host might be looking for Windows

276
00:22:23,190 --> 00:22:29,970
Event IDs 4624 as a type 3 log on so
that would indicate that came across the

277
00:22:29,970 --> 00:22:35,070
network as a hash and then conjunction
with that we also see in this case that

278
00:22:35,070 --> 00:22:40,080
a service was created so we use the PS
exact creative service so now he's got

279
00:22:40,080 --> 00:22:43,530
that data to kind of go back and and and
start to build out that that hunting

280
00:22:43,530 --> 00:22:47,670
capability to understand that and in
addition to that we've got to get you

281
00:22:47,670 --> 00:22:51,270
know some network artifacts so you
shovel before you know we've got the

282
00:22:51,270 --> 00:22:52,980
multi go and we start

283
00:22:52,980 --> 00:22:56,190
ok so we've got this one host here also
and start talking to all these other

284
00:22:56,190 --> 00:23:00,500
hosts out here that looks pretty
abnormal and we can see that in there

285
00:23:00,500 --> 00:23:05,480
the report here that you know that hosts
133 talk to every house on that subnet

286
00:23:05,480 --> 00:23:10,850
over 45 so that's something that
suspicious and that now he can start to

287
00:23:10,850 --> 00:23:12,469
look at and analyze from like that

288
00:23:12,470 --> 00:23:17,780
absolutely and so the same thing with
the registry persistence you know this

289
00:23:17,780 --> 00:23:24,950
is a little more basic but basically
we've got in that HD current user author

290
00:23:24,950 --> 00:23:30,020
on that some randomly generated name is
so if you don't know you're tooling

291
00:23:30,020 --> 00:23:33,800
using medical you're gonna end up with
something like this that looks pretty

292
00:23:33,800 --> 00:23:37,010
obvious and should be pretty obvious to
anybody who is haunting this type of

293
00:23:37,010 --> 00:23:41,000
stuff that this is not a normal he
should go in and investigate that

294
00:23:46,280 --> 00:23:51,290
so as we started building this out and
start with that part is listed started

295
00:23:51,290 --> 00:23:55,610
actually doing these things and
measuring how well we can detect this we

296
00:23:55,610 --> 00:24:00,830
start to build out some some fun metrics
and executives love these things

297
00:24:01,550 --> 00:24:07,190
it's amazing but what is actually trying
to show is these bars represent what we

298
00:24:07,190 --> 00:24:11,540
want that capability to be so we want an
instant response we get a new service

299
00:24:11,540 --> 00:24:14,990
created and they don't necessarily have
to respond to it but they need to review

300
00:24:14,990 --> 00:24:19,070
it so also you get a whole bunch of new
services get created on the subnet and

301
00:24:19,070 --> 00:24:22,310
then you have to leave immediately after
like I'm very interested in that we

302
00:24:22,310 --> 00:24:26,629
should go investigate that that seems
interesting and maybe its Bob and over

303
00:24:26,630 --> 00:24:30,620
here just installed a whole bunch of
stuff for random and across to do that

304
00:24:30,620 --> 00:24:35,750
we need to verify and validate that and
in this case we can see that there's

305
00:24:35,750 --> 00:24:39,350
there's places where we have major gaps
and this is where we can start refocus

306
00:24:39,350 --> 00:24:43,669
that effort to to tweak and get better
at that detection this is that ajust

307
00:24:43,670 --> 00:24:46,670
phase and now we can actually see what
this looks like

308
00:24:48,290 --> 00:24:52,490
so what this is shown here is basically
we can look at this from a training

309
00:24:52,490 --> 00:24:56,990
perspective as well for say overall
capabilities we can look at you know

310
00:24:56,990 --> 00:25:00,800
person sir prove a score or
what-have-you for determining this

311
00:25:00,800 --> 00:25:02,310
overtime so

312
00:25:02,310 --> 00:25:07,980
in this case the green line here makes a
pretty significant jump so that might

313
00:25:07,980 --> 00:25:11,490
represent where hey we bought this tool
we made this investment and now we can

314
00:25:11,490 --> 00:25:16,770
see the what we got for it this really
shown that ROI and we see sum1 here

315
00:25:16,770 --> 00:25:20,639
little blue line that actually like dips
quite a bit and maybe that's a whole

316
00:25:20,640 --> 00:25:25,230
bunch of new was a lateral movement
techniques came out so somebody watching

317
00:25:25,230 --> 00:25:29,580
you know talk here and we had a whole
bunch more to threat matrix and now

318
00:25:29,580 --> 00:25:33,300
we've got 10 more that we should be
checking for versus what we had

319
00:25:33,300 --> 00:25:41,909
previously so do the three injections
that is that very specific individual

320
00:25:41,910 --> 00:25:44,970
piece where we're going to do the one
thing see if we can detect it

321
00:25:44,970 --> 00:25:48,330
so threat simulation is kind of
modifying what we've got for our current

322
00:25:48,330 --> 00:25:53,040
red team engagements to tell us house
with giving something to this the

323
00:25:53,040 --> 00:25:58,260
defenders the soccer the hunt team to
try to identify the stuff and what it

324
00:25:58,260 --> 00:26:01,140
really means is that where we're
choosing specific techniques and tactics

325
00:26:01,140 --> 00:26:07,290
that either we know that we've you know
that these defenses out for or ones that

326
00:26:07,290 --> 00:26:11,940
we have are untested that we want to try
to identify if we can detect them or not

327
00:26:11,940 --> 00:26:18,330
and you may choose to do is a specific
type of actor malware Munich example

328
00:26:18,330 --> 00:26:22,379
would be you know if you're always doing
stuff with say power show you know his

329
00:26:22,380 --> 00:26:27,090
partials cool maybe next time you do it
with net commando more old-school to

330
00:26:27,090 --> 00:26:29,669
just give a different view and maybe
there's slightly different artifacts

331
00:26:29,670 --> 00:26:33,300
that come out of that but we want to set
out and see make sure we're still

332
00:26:33,300 --> 00:26:40,620
identifying that same type of behavior
regardless of tooling so just kind of

333
00:26:40,620 --> 00:26:44,580
giving a different look here so you know
if we were making some kind of report

334
00:26:44,580 --> 00:26:49,439
may be able to show here on my attack
framework that you know in its

335
00:26:49,440 --> 00:26:55,320
particular engagement we did well at
identifying the network scanning we

336
00:26:55,320 --> 00:27:00,659
didn't do so hot at se SI too so maybe
you know in some cases we're not getting

337
00:27:00,660 --> 00:27:04,500
the dns logs so you can actually hunt
dns command control stuff using

338
00:27:04,500 --> 00:27:08,040
something like a cobol strike where
you're popping all the stuff over 18s

339
00:27:08,040 --> 00:27:11,790
might not be able to identify if you
don't have the correct lock sources and

340
00:27:11,790 --> 00:27:15,250
so now i can use this say hey where we
kind of suck at c2 you want

341
00:27:15,250 --> 00:27:18,910
all those locks sources and now and
start to do some hunting on that

342
00:27:18,910 --> 00:27:29,200
periodicity of that beacon calling all
so for the most part I think most

343
00:27:29,200 --> 00:27:33,130
organizations contract with outside
their parties to do testing writes a

344
00:27:33,130 --> 00:27:36,640
good practice even if you have an
internal red team still probably want

345
00:27:36,640 --> 00:27:39,640
the outside perspective make sure you
know internal folks aren't missing

346
00:27:39,640 --> 00:27:43,870
anything and this is where we can work
with them to to get a little bit

347
00:27:43,870 --> 00:27:48,070
different deliverable so not just listen
phones and recommendations for you

348
00:27:48,070 --> 00:27:51,010
should change your network this way
should do some more segmentation should

349
00:27:51,010 --> 00:27:57,129
go fix that Tomcat top get over there
and really start to get down 20

350
00:27:57,130 --> 00:28:01,600
i did a fast cash attack on the network
or we logged into these default tomcat

351
00:28:01,600 --> 00:28:05,139
creds or we don't cash is over here and
here's the ways that you can try to

352
00:28:05,140 --> 00:28:11,380
detect this and really get more evidence
that the blue team as well so i'm

353
00:28:11,380 --> 00:28:17,020
guessing most most attackers have heard
of the netbios you're probably on a

354
00:28:17,020 --> 00:28:21,400
regular basis you know responder type of
attack and if I was named spoofing made

355
00:28:21,400 --> 00:28:24,280
defenders i'm sure it never heard of
that let alone seeing that on the

356
00:28:24,280 --> 00:28:28,540
network so if you were to perform that
type of attack during the money's

357
00:28:28,540 --> 00:28:33,550
engagements it may be printed to you
supply a pcap showing here's what that

358
00:28:33,550 --> 00:28:38,320
looks like on the wire right so if you
see that name come by the responder will

359
00:28:38,320 --> 00:28:42,010
send out that responds to it and you see
the request come back and see the

360
00:28:42,010 --> 00:28:46,330
credentials it snagged by the attacker
that's something that most offenders

361
00:28:46,330 --> 00:28:49,870
have never seen it would be very useful
if you actually supply that say here's

362
00:28:49,870 --> 00:28:52,659
what we're seeing and then they can
start to look at that from like a

363
00:28:52,660 --> 00:29:02,200
necklace perspective to try to identify
that type of behavior so some

364
00:29:02,200 --> 00:29:04,900
recommendations

365
00:29:04,900 --> 00:29:11,200
this is about measuring first of all how
are we doing that stuff for the blue

366
00:29:11,200 --> 00:29:16,150
team guys a little bit of an open kimono
kind of scenario you get you don't want

367
00:29:16,150 --> 00:29:20,380
to end up with egg on your face but I
gotta tell you for the red team guys

368
00:29:20,380 --> 00:29:22,490
like Zach we got a couple of other guys

369
00:29:22,490 --> 00:29:28,070
room here the humility and the
professional commitment that they have

370
00:29:28,070 --> 00:29:34,460
i've seen these guys walk out to our are
sock folks and have a very constructive

371
00:29:34,460 --> 00:29:38,960
but very calm and humble conversation
with a minute just to go so far because

372
00:29:38,960 --> 00:29:44,450
we were all in this together and I think
that this kind of approach it really

373
00:29:44,450 --> 00:29:48,590
goes a long ways to kind of building
that rapport and letting folks know that

374
00:29:48,590 --> 00:29:53,629
we are not coming here to beat up on you
but at the end of the day we need to

375
00:29:53,630 --> 00:29:58,940
find out what we can see and what we
can't see and just have a basically

376
00:29:58,940 --> 00:30:05,990
structured approach to identifying those
line them up and knocking down and you

377
00:30:05,990 --> 00:30:12,890
know the other point about the the blue
team if it's an internal and test you

378
00:30:12,890 --> 00:30:17,870
know that's one thing we can talk it in
if it's a external third-party you know

379
00:30:17,870 --> 00:30:22,610
that's something where we just need to
be explicit about saying we need the

380
00:30:22,610 --> 00:30:27,770
artifacts from this by the phase of the
attack however you for visit but

381
00:30:27,770 --> 00:30:33,170
understanding that we are there to
improve the overall security posture and

382
00:30:33,170 --> 00:30:37,429
don't be afraid to ask for what you need
from that and get that in the scope of

383
00:30:37,429 --> 00:30:43,640
work and then you know rotating the
testing firms or the testers within a

384
00:30:43,640 --> 00:30:49,280
firm might even go farther and saying
you know do some shadowing or whatever

385
00:30:49,280 --> 00:30:52,790
you want to call it you know have your
hunt teams it with the Red Team Red Team

386
00:30:52,790 --> 00:30:57,559
sit with the hunt team put everybody in
a mission room see what happens but i

387
00:30:57,559 --> 00:31:02,990
think that that cross learning is going
to be very beneficial the organization

388
00:31:02,990 --> 00:31:07,610
and then you know use this model to test
your security partners you know if you

389
00:31:07,610 --> 00:31:09,709
have a third-party sock

390
00:31:09,710 --> 00:31:14,570
let's see what they can see what they
can and again you know certainly there

391
00:31:14,570 --> 00:31:18,290
might be contractual considerations
there but ultimately we're looking for

392
00:31:18,290 --> 00:31:21,290
ground truth it's not who's right or
who's wrong

393
00:31:21,860 --> 00:31:27,080
it's what is the train what is the
landscape and are the decisions that

394
00:31:27,080 --> 00:31:28,178
we're making

395
00:31:28,179 --> 00:31:31,360
and then we are influencing management
to make are they aligned with that

396
00:31:31,360 --> 00:31:40,119
reality is is were red team lot of to
what Brian said nose is really be a

397
00:31:40,119 --> 00:31:44,289
partner I don't don't just come in and
be like I we totally hacked you guys

398
00:31:44,289 --> 00:31:48,610
like we don't all your passwords and you
know Jason Street right for us had a lot

399
00:31:48,610 --> 00:31:54,969
of examples like how you can do red team
fail and you know really uh putting out

400
00:31:54,970 --> 00:31:57,879
there that you've got to be more partner

401
00:31:57,879 --> 00:32:01,299
the whole goal is actually helping
people get more secure not just saying

402
00:32:01,299 --> 00:32:05,230
hey you guys suck here's all the stuff
that you go fix but saying hey here's

403
00:32:05,230 --> 00:32:09,490
how you can get better here are some
recommendations we have for you focusing

404
00:32:09,490 --> 00:32:12,940
on not just the vulnerabilities that are
identified but what attacks were

405
00:32:12,940 --> 00:32:16,360
performed on the network and helping
them understand what those attacks do

406
00:32:16,360 --> 00:32:20,379
and how you can they can detect him will
go along way to actually making them

407
00:32:20,379 --> 00:32:24,580
more secure not just reducing the the
small risk that's associated whatever

408
00:32:24,580 --> 00:32:30,158
the handful of vulnerabilities were that
you identified and you know one of

409
00:32:30,159 --> 00:32:33,580
things that I've noticed over the years
is that you really need to know your

410
00:32:33,580 --> 00:32:38,619
tools and go higher tools work and how
the the horses and everything like that

411
00:32:38,619 --> 00:32:41,830
works as well we're going to do this
stuff to actually be able to provide

412
00:32:41,830 --> 00:32:46,629
that type of info you know to understand
that when you do that pass the hash

413
00:32:46,629 --> 00:32:51,129
attacking new service its created and
the PS exact command actually create a

414
00:32:51,129 --> 00:32:55,059
new service drops binary and they're
like many testers don't understand it

415
00:32:55,059 --> 00:32:58,269
like there's all this communication and
all these things that happen behind that

416
00:32:58,269 --> 00:33:01,629
that one line and display that you you
set the module you run it and

417
00:33:01,629 --> 00:33:06,369
everything's cool and like now got show
but ok so foot foot on the other side

418
00:33:06,369 --> 00:33:10,178
and look at your own vmware you you you
know for your lab or whatever you

419
00:33:10,179 --> 00:33:15,369
compromise that boxing oh ok so this is
all things have changed you know if

420
00:33:15,369 --> 00:33:18,519
you're not very good at the defensive
stuff for really analyzing these things

421
00:33:18,519 --> 00:33:21,909
you can use stuff like ooh like you've
got a payload your hey I want to get

422
00:33:21,909 --> 00:33:25,779
this paper looks like go use something
like sandboxes to actually understand

423
00:33:25,779 --> 00:33:29,409
what that looks like and the better you
know your tools you better you're gonna

424
00:33:29,409 --> 00:33:33,490
be able to get to recommend how to
detect and defend against them and kind

425
00:33:33,490 --> 00:33:37,419
of fun thing from from my perspective is
better that he gets it at finding my

426
00:33:37,419 --> 00:33:38,169
stuff the

427
00:33:38,169 --> 00:33:42,970
the harder I have to work to find new
cool ways to to get around it and that

428
00:33:42,970 --> 00:33:48,999
just makes everybody better so that's
our talk is couple resources that we

429
00:33:48,999 --> 00:33:53,919
talked about four inches uzum the minor
attack framework I remember menu and

430
00:33:53,919 --> 00:33:57,970
check that out he had already and then
the bone wiki is a pretty cool place

431
00:33:57,970 --> 00:34:02,230
that has a lot of good info about kind
of like the with the attackers do in

432
00:34:02,230 --> 00:34:08,589
terms of perspective lateral movement to
to augment what you might be missing so

433
00:34:08,589 --> 00:34:17,230
thank you

434
00:34:18,000 --> 00:34:21,060
question

