1
00:00:00,000 --> 00:00:04,950
so we're gonna get started this is 42

2
00:00:03,090 --> 00:00:07,588
the answer to life the universe and

3
00:00:04,950 --> 00:00:09,300
everything offensive security and this

4
00:00:07,589 --> 00:00:11,519
we're gonna talk about the offensive use

5
00:00:09,300 --> 00:00:14,900
cases of machine learning and it

6
00:00:11,519 --> 00:00:18,359
represents probably the last year of our

7
00:00:14,900 --> 00:00:21,630
research he's mine for hours yeah I'm

8
00:00:18,359 --> 00:00:24,119
will Pierce mu hex and I'm a senior

9
00:00:21,630 --> 00:00:26,640
operator at Sandburg security and my job

10
00:00:24,119 --> 00:00:31,500
primarily focuses on research training

11
00:00:26,640 --> 00:00:34,110
and ops and my name is Nick lenders or

12
00:00:31,500 --> 00:00:36,300
monarchs guess on Twitter and I'm a team

13
00:00:34,110 --> 00:00:39,450
lead I do a lot of research DevOps as

14
00:00:36,300 --> 00:00:41,129
well and yeah I would say if to

15
00:00:39,450 --> 00:00:43,500
introduce me and will will is definitely

16
00:00:41,129 --> 00:00:44,760
the ml lover and it's really passionate

17
00:00:43,500 --> 00:00:46,530
about the field I would say I carry a

18
00:00:44,760 --> 00:00:48,180
little bit more skepticism so we're

19
00:00:46,530 --> 00:00:50,129
gonna hopefully do a bad bad cop good

20
00:00:48,180 --> 00:00:52,860
cop situation and balance each other out

21
00:00:50,129 --> 00:00:55,079
as we go through this presentation so

22
00:00:52,860 --> 00:00:57,960
first we need to sort of make the jokey

23
00:00:55,079 --> 00:01:00,239
slide about what is ml if you walk to

24
00:00:57,960 --> 00:01:02,100
the vendor booth of blackhat you'll see

25
00:01:00,239 --> 00:01:04,559
exactly what we mean there's a lot of

26
00:01:02,100 --> 00:01:06,630
booth babes yelling out datasheet

27
00:01:04,559 --> 00:01:08,850
keywords like next generation scientists

28
00:01:06,630 --> 00:01:10,939
I've even heard central cortex thrown

29
00:01:08,850 --> 00:01:13,048
around which is pretty pretty rough but

30
00:01:10,939 --> 00:01:15,149
it's effectively a lot of magic that

31
00:01:13,049 --> 00:01:17,549
gets investors goes public and makes a

32
00:01:15,150 --> 00:01:20,490
lot of money people make the joke it's a

33
00:01:17,549 --> 00:01:23,180
bunch of rebranded if statements but as

34
00:01:20,490 --> 00:01:27,330
we know this is obviously isn't the case

35
00:01:23,180 --> 00:01:29,009
so it really is mo so in my mind ml is

36
00:01:27,330 --> 00:01:32,600
just a set of techniques that aim to

37
00:01:29,009 --> 00:01:36,689
model a problem mathematically and so

38
00:01:32,600 --> 00:01:38,789
it's a it rolls up stats maths and

39
00:01:36,689 --> 00:01:41,850
computer science into one kind of

40
00:01:38,790 --> 00:01:44,340
overarching field and it's not news so

41
00:01:41,850 --> 00:01:46,619
it's actually a pretty old discipline we

42
00:01:44,340 --> 00:01:49,500
think it's new and its new it is new to

43
00:01:46,619 --> 00:01:51,299
us but it's been it's been around for a

44
00:01:49,500 --> 00:01:54,470
while the term machine learning was

45
00:01:51,299 --> 00:01:56,969
coined in the 50s by a scientist at IBM

46
00:01:54,470 --> 00:01:58,908
but effectively it gives us predictions

47
00:01:56,969 --> 00:02:01,110
without explicit programming so

48
00:01:58,909 --> 00:02:03,390
predictions being maybe rules that we

49
00:02:01,110 --> 00:02:06,299
get without it explicit the program

50
00:02:03,390 --> 00:02:09,000
being explicitly programmed to do so and

51
00:02:06,299 --> 00:02:10,200
it's growing fast so people just have so

52
00:02:09,000 --> 00:02:12,660
much data and then they're not really

53
00:02:10,199 --> 00:02:13,440
sure what to do with it and so machine

54
00:02:12,660 --> 00:02:16,350
learning is kind of

55
00:02:13,440 --> 00:02:18,450
come along and been that catalyst for

56
00:02:16,350 --> 00:02:20,549
for data utilization for organizations

57
00:02:18,450 --> 00:02:22,290
they sort of realized the power of it

58
00:02:20,550 --> 00:02:26,130
and they just applied huge amounts of

59
00:02:22,290 --> 00:02:27,450
compute it's still magic so when you

60
00:02:26,130 --> 00:02:29,579
when you get into the math it's still

61
00:02:27,450 --> 00:02:37,410
magic but is it is still mostly just

62
00:02:29,580 --> 00:02:39,780
math but why do we care so we care

63
00:02:37,410 --> 00:02:42,210
because it's coming to a product in a

64
00:02:39,780 --> 00:02:44,880
field near you literally everybody is

65
00:02:42,210 --> 00:02:47,240
applying it in their own ways so whether

66
00:02:44,880 --> 00:02:49,290
it's information security healthcare

67
00:02:47,240 --> 00:02:51,390
industrial control systems like

68
00:02:49,290 --> 00:02:53,640
everybody is implementing it into into

69
00:02:51,390 --> 00:02:55,739
their systems and it's no longer a math

70
00:02:53,640 --> 00:02:57,779
problem so you know while back it was

71
00:02:55,740 --> 00:02:59,220
like well we our algorithms aren't as

72
00:02:57,780 --> 00:03:01,770
efficient as they need to be so this is

73
00:02:59,220 --> 00:03:03,270
cool but there still need work it's no

74
00:03:01,770 --> 00:03:06,030
longer a math problem now it's just an

75
00:03:03,270 --> 00:03:08,610
engineering problem so it's how are

76
00:03:06,030 --> 00:03:10,350
these systems being implemented and our

77
00:03:08,610 --> 00:03:15,030
future we believe our future is going to

78
00:03:10,350 --> 00:03:16,260
be fought with ml so for example you in

79
00:03:15,030 --> 00:03:17,910
the future you're not going to have to

80
00:03:16,260 --> 00:03:20,340
bypass one model you're gonna have to

81
00:03:17,910 --> 00:03:23,579
bypass a model at every stage of the

82
00:03:20,340 --> 00:03:26,340
defensive process and it can be really

83
00:03:23,580 --> 00:03:28,470
really awesome so you can get good

84
00:03:26,340 --> 00:03:31,080
results with relatively small amounts of

85
00:03:28,470 --> 00:03:33,600
data you know if the problem is very

86
00:03:31,080 --> 00:03:35,910
specific but it can build relationships

87
00:03:33,600 --> 00:03:38,519
non-concurrent data it can bring out

88
00:03:35,910 --> 00:03:40,890
like there's operators Six Senses so you

89
00:03:38,520 --> 00:03:42,660
know how do I know which file-share to

90
00:03:40,890 --> 00:03:47,399
look in like what is it about a file

91
00:03:42,660 --> 00:03:50,010
share that gets you know gets my query

92
00:03:47,400 --> 00:03:52,170
into the hosts and it can go through

93
00:03:50,010 --> 00:03:54,450
just massive amounts of data way faster

94
00:03:52,170 --> 00:03:56,040
than any human can scroll through so it

95
00:03:54,450 --> 00:03:57,958
can very quickly bring you insights that

96
00:03:56,040 --> 00:04:02,310
you previously wouldn't have ever gotten

97
00:03:57,959 --> 00:04:04,680
to had it been a manual process and then

98
00:04:02,310 --> 00:04:06,090
we just describe offensive mmm so

99
00:04:04,680 --> 00:04:07,380
offensive ml is literally just the

100
00:04:06,090 --> 00:04:10,470
application of machine learning to

101
00:04:07,380 --> 00:04:13,070
offensive security problems and there

102
00:04:10,470 --> 00:04:16,589
are a ton of projects out there already

103
00:04:13,070 --> 00:04:18,779
and yeah you should go to them have a

104
00:04:16,589 --> 00:04:21,228
look it's it's a growing field and I

105
00:04:18,779 --> 00:04:23,940
highly recommend looking at all of these

106
00:04:21,228 --> 00:04:25,620
we're going to discuss using control

107
00:04:23,940 --> 00:04:27,180
relationships so sort of a bloodhound

108
00:04:25,620 --> 00:04:28,710
with out bloodhound

109
00:04:27,180 --> 00:04:30,030
we're gonna discuss detecting sandbox

110
00:04:28,710 --> 00:04:32,549
environments so if any of you saw that

111
00:04:30,030 --> 00:04:34,229
besides talk we'll go over that and then

112
00:04:32,550 --> 00:04:41,850
we're going to talk at verse Ariel ml

113
00:04:34,229 --> 00:04:42,960
where we steal a model for evasion so

114
00:04:41,850 --> 00:04:45,210
we're gonna get into the basics of

115
00:04:42,960 --> 00:04:48,419
collision course so starting with ml you

116
00:04:45,210 --> 00:04:51,948
can literally Google any tutorial and

117
00:04:48,419 --> 00:04:55,740
it'll come up with with something and so

118
00:04:51,949 --> 00:04:57,360
if you want to spam classification just

119
00:04:55,740 --> 00:04:59,310
Google spam classification machine

120
00:04:57,360 --> 00:05:01,699
learning if you want to detect cats if

121
00:04:59,310 --> 00:05:04,020
you want to detect dogs if you want to

122
00:05:01,699 --> 00:05:07,050
literally do anything with ML there's a

123
00:05:04,020 --> 00:05:09,090
lot of weird stuff and here we just have

124
00:05:07,050 --> 00:05:11,250
a bunch of links so you know there is

125
00:05:09,090 --> 00:05:13,590
somebody in your field or your interest

126
00:05:11,250 --> 00:05:19,199
that's working in ml that you just need

127
00:05:13,590 --> 00:05:20,369
to find them alright so talk a little

128
00:05:19,199 --> 00:05:22,229
bit more about the specifics

129
00:05:20,370 --> 00:05:24,449
obviously the tutorials aside the

130
00:05:22,229 --> 00:05:26,430
process generally breaks down like this

131
00:05:24,449 --> 00:05:28,860
where the first two steps are arguably

132
00:05:26,430 --> 00:05:30,960
the most important by far data is

133
00:05:28,860 --> 00:05:32,430
everywhere but what should we collect

134
00:05:30,960 --> 00:05:33,989
and usually where you're trying to use

135
00:05:32,430 --> 00:05:35,460
that data to answer a problem so

136
00:05:33,990 --> 00:05:36,659
sometimes you have the problem that

137
00:05:35,460 --> 00:05:38,698
comes first and then you ask yourself

138
00:05:36,659 --> 00:05:40,530
what data do I need to collect to solve

139
00:05:38,699 --> 00:05:41,970
this other times the data sitting in

140
00:05:40,530 --> 00:05:43,830
front of you and you sort of ask what

141
00:05:41,970 --> 00:05:45,930
problems could it solve if we were to

142
00:05:43,830 --> 00:05:47,760
make it actionable step three is to

143
00:05:45,930 --> 00:05:49,110
process and extract useful features so

144
00:05:47,760 --> 00:05:51,900
we call this this feature engineering

145
00:05:49,110 --> 00:05:53,639
we'll discuss that later on four would

146
00:05:51,900 --> 00:05:55,349
be to just download Python plus a bunch

147
00:05:53,639 --> 00:05:57,659
of ml libraries people have their

148
00:05:55,349 --> 00:05:59,669
favorites but you know generally you'll

149
00:05:57,659 --> 00:06:02,340
see a lot of numpy pandas a scikit-learn

150
00:05:59,669 --> 00:06:04,409
tensorflow and we prefer Kerris on top

151
00:06:02,340 --> 00:06:06,539
of tensorflow for the actual algorithm

152
00:06:04,409 --> 00:06:08,849
implementations step five would just be

153
00:06:06,539 --> 00:06:10,710
to write a ten line script which is not

154
00:06:08,849 --> 00:06:13,139
a joke they're generally literally less

155
00:06:10,710 --> 00:06:14,969
than ten lines and ml your heart out in

156
00:06:13,139 --> 00:06:16,849
fact you can do ml in less Python that

157
00:06:14,970 --> 00:06:20,190
it takes to write a webserver generally

158
00:06:16,849 --> 00:06:21,360
so the case study that we first tackled

159
00:06:20,190 --> 00:06:23,639
when we started getting into this was

160
00:06:21,360 --> 00:06:25,320
sandbox detection and will win over this

161
00:06:23,639 --> 00:06:27,720
in his b-sides presentation but

162
00:06:25,320 --> 00:06:29,789
sandboxes hold a special place in our

163
00:06:27,720 --> 00:06:31,650
heart as offenders they're obviously a

164
00:06:29,789 --> 00:06:33,539
dangerous place and we do a lot of

165
00:06:31,650 --> 00:06:35,400
custom tool development so getting our

166
00:06:33,539 --> 00:06:37,110
tools caught in the sandbox represents a

167
00:06:35,400 --> 00:06:39,299
huge hit to our operational

168
00:06:37,110 --> 00:06:40,560
effectiveness so the popularity is

169
00:06:39,300 --> 00:06:42,270
rising and we're trying to think

170
00:06:40,560 --> 00:06:44,370
about ways we can detect sandboxes with

171
00:06:42,270 --> 00:06:45,840
limited information the very act of

172
00:06:44,370 --> 00:06:48,210
querying that information is going to

173
00:06:45,840 --> 00:06:50,729
make us look malicious so you know we're

174
00:06:48,210 --> 00:06:52,380
trying to find minimal information to

175
00:06:50,730 --> 00:06:54,030
make the best decision possible about

176
00:06:52,380 --> 00:06:57,510
whether or not any particular host is a

177
00:06:54,030 --> 00:07:00,030
sandbox or not so the data that we chose

178
00:06:57,510 --> 00:07:01,380
is just a raw process list obviously the

179
00:07:00,030 --> 00:07:04,349
features you could have selected here

180
00:07:01,380 --> 00:07:06,240
you know are very extensive but a

181
00:07:04,350 --> 00:07:08,070
process list to us speaks outside of

182
00:07:06,240 --> 00:07:09,960
even the detection of a sandbox that's

183
00:07:08,070 --> 00:07:11,280
just a value a little bit a valuable bit

184
00:07:09,960 --> 00:07:12,810
of information that we already

185
00:07:11,280 --> 00:07:16,200
integrated into our toolkits so a

186
00:07:12,810 --> 00:07:17,729
sandbox we collect for detecting whether

187
00:07:16,200 --> 00:07:20,789
or not defensive products are installed

188
00:07:17,729 --> 00:07:22,860
or we collect them to get context around

189
00:07:20,790 --> 00:07:24,389
a particular user running a say payload

190
00:07:22,860 --> 00:07:25,710
so if you were to look at this process

191
00:07:24,389 --> 00:07:27,510
list and start thinking about what

192
00:07:25,710 --> 00:07:29,099
features you might extract you could

193
00:07:27,510 --> 00:07:30,810
start by saying well this looks like a

194
00:07:29,100 --> 00:07:33,300
sandbox because proc mana is running

195
00:07:30,810 --> 00:07:34,950
certainly don't like that and admin tack

196
00:07:33,300 --> 00:07:37,229
PC doesn't look like it's on a domain

197
00:07:34,950 --> 00:07:38,700
the user name is generic so we can start

198
00:07:37,229 --> 00:07:40,680
building out features like a bad user

199
00:07:38,700 --> 00:07:42,630
count or the number of sysinternals

200
00:07:40,680 --> 00:07:44,400
tools running but I think we can do

201
00:07:42,630 --> 00:07:46,050
better than this we can start thinking

202
00:07:44,400 --> 00:07:48,060
about what we call meta properties of

203
00:07:46,050 --> 00:07:49,770
the list so for instance the process ID

204
00:07:48,060 --> 00:07:53,250
in Windows is an incremental identifier

205
00:07:49,770 --> 00:07:55,590
that generally goes up as the longer the

206
00:07:53,250 --> 00:07:57,840
machine has been running so we could

207
00:07:55,590 --> 00:07:59,400
take the average pit and use that as an

208
00:07:57,840 --> 00:08:00,780
indicator of how long the machines been

209
00:07:59,400 --> 00:08:02,580
up which could tell us something about a

210
00:08:00,780 --> 00:08:05,429
sandbox we could also use what we call

211
00:08:02,580 --> 00:08:07,260
compression so a lot of users on real

212
00:08:05,430 --> 00:08:10,320
machines have multiple processes running

213
00:08:07,260 --> 00:08:12,090
that look what you say they look

214
00:08:10,320 --> 00:08:14,130
repeated so like Chrome opens up

215
00:08:12,090 --> 00:08:16,320
multiple processes for for each tab in

216
00:08:14,130 --> 00:08:18,630
window so if we took all of the process

217
00:08:16,320 --> 00:08:20,039
names and unique them then we took the

218
00:08:18,630 --> 00:08:21,330
ratio between them we would get a

219
00:08:20,039 --> 00:08:24,180
compression rate and this tells us

220
00:08:21,330 --> 00:08:25,950
something about how many repeated

221
00:08:24,180 --> 00:08:29,130
processes are running on a particular

222
00:08:25,950 --> 00:08:31,950
host and then once we have that

223
00:08:29,130 --> 00:08:33,299
information we we need to feed it into

224
00:08:31,950 --> 00:08:34,799
an algorithm so we need to effectively

225
00:08:33,299 --> 00:08:37,140
feature Engineering's that process of

226
00:08:34,799 --> 00:08:39,779
turning words into numbers such that we

227
00:08:37,140 --> 00:08:41,520
can introduce it into a network and so

228
00:08:39,779 --> 00:08:43,708
when you finally get your features we

229
00:08:41,520 --> 00:08:46,230
create our inputs and so this is just

230
00:08:43,708 --> 00:08:48,569
you know a numpy array with the rows

231
00:08:46,230 --> 00:08:51,209
being a sample so each of these are sand

232
00:08:48,570 --> 00:08:53,850
boxes and the columns being your

233
00:08:51,209 --> 00:08:54,390
features so we here we have process

234
00:08:53,850 --> 00:08:57,290
count you

235
00:08:54,390 --> 00:09:00,060
account and then the ratio between them

236
00:08:57,290 --> 00:09:02,730
then once we have our inputs we need to

237
00:09:00,060 --> 00:09:04,589
label them so label data in a supervised

238
00:09:02,730 --> 00:09:06,450
machine learning problem is huge so we

239
00:09:04,590 --> 00:09:08,040
need labelled data and we just went

240
00:09:06,450 --> 00:09:09,750
through manually we don't have so many

241
00:09:08,040 --> 00:09:11,790
that we can't do it

242
00:09:09,750 --> 00:09:14,250
in a manual fashion so we just went

243
00:09:11,790 --> 00:09:17,280
through me labeled all of our Sam boxes

244
00:09:14,250 --> 00:09:19,410
as you know zero is safe and one is the

245
00:09:17,280 --> 00:09:21,300
sandbox and this is eventually what will

246
00:09:19,410 --> 00:09:24,839
target with you know machine learning

247
00:09:21,300 --> 00:09:27,359
algorithm but binary classification zero

248
00:09:24,840 --> 00:09:30,720
one isn't the only kind so you can have

249
00:09:27,360 --> 00:09:32,520
multi label where your grouping sandbox

250
00:09:30,720 --> 00:09:34,830
into like categories so maybe you have a

251
00:09:32,520 --> 00:09:37,100
category for the United States a sandbox

252
00:09:34,830 --> 00:09:39,630
a United States versus Holland or

253
00:09:37,100 --> 00:09:41,100
Ireland or wherever so potentially you

254
00:09:39,630 --> 00:09:42,990
could get some additional insight so

255
00:09:41,100 --> 00:09:44,220
that way it's also another one that

256
00:09:42,990 --> 00:09:45,750
we'll discuss later but so just a

257
00:09:44,220 --> 00:09:48,930
regression problem where we're targeting

258
00:09:45,750 --> 00:09:51,810
a continuous variable so for example

259
00:09:48,930 --> 00:09:55,170
instead of 0 or 1 or some n categories

260
00:09:51,810 --> 00:09:58,979
we're targeting you know 1 through 9 a

261
00:09:55,170 --> 00:10:00,689
thousand for example but before we get

262
00:09:58,980 --> 00:10:02,700
into it we're gonna we're gonna just do

263
00:10:00,690 --> 00:10:05,250
a brief overview of a basic neural

264
00:10:02,700 --> 00:10:07,950
network so the smallest unit of a neural

265
00:10:05,250 --> 00:10:10,290
network is a node and nodes effectively

266
00:10:07,950 --> 00:10:12,120
carry values and between these nodes you

267
00:10:10,290 --> 00:10:15,180
have weights and they represent the

268
00:10:12,120 --> 00:10:17,610
strength of a connection and then inside

269
00:10:15,180 --> 00:10:19,319
of an output or inside of a hidden node

270
00:10:17,610 --> 00:10:23,160
you might have some sort of activation

271
00:10:19,320 --> 00:10:26,790
function and this gives some level of

272
00:10:23,160 --> 00:10:33,060
confidence or level of activation that

273
00:10:26,790 --> 00:10:35,969
the the node represents then you have

274
00:10:33,060 --> 00:10:37,469
layers to these nodes are distributed in

275
00:10:35,970 --> 00:10:39,030
two layers so you have a typically an

276
00:10:37,470 --> 00:10:40,470
input layer where all your features go

277
00:10:39,030 --> 00:10:43,110
in you have an arbitrary number of

278
00:10:40,470 --> 00:10:45,300
hidden layers that kind of pass

279
00:10:43,110 --> 00:10:47,760
activations to one another and then just

280
00:10:45,300 --> 00:10:49,620
have an output layer and this the number

281
00:10:47,760 --> 00:10:52,160
of nodes in the in each layer is going

282
00:10:49,620 --> 00:10:54,150
to differ depending on on your problem

283
00:10:52,160 --> 00:10:55,500
but then we have a network and the

284
00:10:54,150 --> 00:10:57,510
network is just you know all those

285
00:10:55,500 --> 00:10:59,880
layers strapped together with weights so

286
00:10:57,510 --> 00:11:03,060
those lines are the connections between

287
00:10:59,880 --> 00:11:05,400
but when we want to calculate our

288
00:11:03,060 --> 00:11:07,750
network we just go through so you see we

289
00:11:05,400 --> 00:11:10,240
introduce our features and these are

290
00:11:07,750 --> 00:11:11,610
scaled so depending on your activation

291
00:11:10,240 --> 00:11:13,390
function you have to scale them and

292
00:11:11,610 --> 00:11:14,920
effectively it's just super simple

293
00:11:13,390 --> 00:11:17,199
masters the weighted sum of the inputs

294
00:11:14,920 --> 00:11:20,020
pass into an activation function sounds

295
00:11:17,200 --> 00:11:21,610
more complicated than it is trust me and

296
00:11:20,020 --> 00:11:23,770
super simple so then we just go through

297
00:11:21,610 --> 00:11:27,940
my feed-forward those calculations for

298
00:11:23,770 --> 00:11:30,699
every node in the next layer and those

299
00:11:27,940 --> 00:11:32,470
in those inputs or those outputs sorry

300
00:11:30,700 --> 00:11:34,450
are those activations become inputs for

301
00:11:32,470 --> 00:11:35,950
the next layer and we just do that until

302
00:11:34,450 --> 00:11:38,880
we're all the way at the end our output

303
00:11:35,950 --> 00:11:40,750
layer and then so at the end we have our

304
00:11:38,880 --> 00:11:43,420
output which is effectively our

305
00:11:40,750 --> 00:11:45,940
prediction and let's say this was a

306
00:11:43,420 --> 00:11:48,520
sandbox our target was one our

307
00:11:45,940 --> 00:11:50,560
prediction was 0.67 we just subtract

308
00:11:48,520 --> 00:11:52,329
that and then we get our loss there are

309
00:11:50,560 --> 00:11:55,449
many ways to calculate loss but at a

310
00:11:52,330 --> 00:11:57,910
basic level this is what it is and then

311
00:11:55,450 --> 00:12:00,520
here's the magic of machine learning is

312
00:11:57,910 --> 00:12:02,350
effectively we need a way to take that

313
00:12:00,520 --> 00:12:04,780
loss and then back propagate it to

314
00:12:02,350 --> 00:12:06,160
update our weights and so we don't have

315
00:12:04,780 --> 00:12:08,350
time to go through into back propagation

316
00:12:06,160 --> 00:12:13,600
here because it's arguably the heaviest

317
00:12:08,350 --> 00:12:16,150
part of it but you in the incoming

318
00:12:13,600 --> 00:12:17,860
weights contribute to the error in

319
00:12:16,150 --> 00:12:20,260
different ways because they're different

320
00:12:17,860 --> 00:12:22,660
values and so back propagation is just

321
00:12:20,260 --> 00:12:25,439
that process of adjusting incoming

322
00:12:22,660 --> 00:12:29,439
weights to an output layer up or down

323
00:12:25,440 --> 00:12:31,420
such that the model learns and so for

324
00:12:29,440 --> 00:12:35,470
example if we up you know update our

325
00:12:31,420 --> 00:12:37,000
weights here in the last layer and then

326
00:12:35,470 --> 00:12:38,710
we feed forward we do those same

327
00:12:37,000 --> 00:12:41,350
calculations again using those new

328
00:12:38,710 --> 00:12:44,650
weights we get a new loss which is 0.125

329
00:12:41,350 --> 00:12:47,170
and our accuracy has gone up by 0.08 and

330
00:12:44,650 --> 00:12:48,370
the code to do this is super simple so

331
00:12:47,170 --> 00:12:50,979
when we were talking about like ten

332
00:12:48,370 --> 00:12:52,810
lines of code this is literally it so

333
00:12:50,980 --> 00:12:57,490
this is a modeling Kerris and you will

334
00:12:52,810 --> 00:12:59,560
get a neural network so the results for

335
00:12:57,490 --> 00:13:02,170
a sandbox stuff we had a hundred and

336
00:12:59,560 --> 00:13:03,609
thirty samples we had eighteen known

337
00:13:02,170 --> 00:13:06,099
sand boxes there are a few that we

338
00:13:03,610 --> 00:13:07,660
missed manually but our accuracy just

339
00:13:06,100 --> 00:13:10,330
from a very basic neural network was

340
00:13:07,660 --> 00:13:11,980
really high but there are lots of

341
00:13:10,330 --> 00:13:13,240
options for feature combinations so you

342
00:13:11,980 --> 00:13:15,100
don't have to use you can literally use

343
00:13:13,240 --> 00:13:17,560
anything you want whether it's a zero or

344
00:13:15,100 --> 00:13:19,810
one true or false the important thing is

345
00:13:17,560 --> 00:13:21,719
that it's their numbers and we'll get

346
00:13:19,810 --> 00:13:23,709
into more feature engineering later

347
00:13:21,720 --> 00:13:25,509
but ultimately is a great problem for

348
00:13:23,709 --> 00:13:27,670
mmm so it's just a very simple problem

349
00:13:25,509 --> 00:13:29,679
that humans can do very very quickly and

350
00:13:27,670 --> 00:13:31,628
it was a good introduction for us and so

351
00:13:29,679 --> 00:13:33,160
we ended up writing a tool it's just

352
00:13:31,629 --> 00:13:35,259
deep drop it's a machine learning

353
00:13:33,160 --> 00:13:37,660
enabled dropper and I really stat

354
00:13:35,259 --> 00:13:39,999
besides couple weeks ago but effectively

355
00:13:37,660 --> 00:13:42,519
just holds a trained model that allows

356
00:13:39,999 --> 00:13:44,470
you to it'll make drop decisions for you

357
00:13:42,519 --> 00:13:46,480
so when the process let's come back it's

358
00:13:44,470 --> 00:13:47,860
going to process it and then it's going

359
00:13:46,480 --> 00:13:49,749
to give you some prediction on that

360
00:13:47,860 --> 00:13:55,569
process list and then it's either gonna

361
00:13:49,749 --> 00:13:57,309
drop your malware or it's not all right

362
00:13:55,569 --> 00:13:59,050
so that's sort of our chizel II named

363
00:13:57,309 --> 00:14:00,429
collision course over with so from this

364
00:13:59,050 --> 00:14:02,439
point we're going to start tackling you

365
00:14:00,429 --> 00:14:03,790
know some of the external challenges of

366
00:14:02,439 --> 00:14:06,429
ml and also look at some more

367
00:14:03,790 --> 00:14:08,170
complicated examples but in that study

368
00:14:06,429 --> 00:14:09,399
that we just went through we sort of

369
00:14:08,170 --> 00:14:10,899
glossed over a lot of the data

370
00:14:09,399 --> 00:14:12,490
collection bit and it's going to become

371
00:14:10,899 --> 00:14:15,279
relevant especially if you start to try

372
00:14:12,490 --> 00:14:16,809
using this in in real offensive ops so

373
00:14:15,279 --> 00:14:18,129
the primary issue we run up against

374
00:14:16,809 --> 00:14:19,899
initially is just that offenders

375
00:14:18,129 --> 00:14:22,449
traditionally don't keep data um in fact

376
00:14:19,899 --> 00:14:24,040
in many ways it's frowned upon which is

377
00:14:22,449 --> 00:14:25,990
funny given the fact that vendors are

378
00:14:24,040 --> 00:14:27,670
allowed to keep data and then build

379
00:14:25,990 --> 00:14:29,470
algorithms off that data and then sell

380
00:14:27,670 --> 00:14:32,679
those algorithms back to the clients

381
00:14:29,470 --> 00:14:34,240
that were trained on their own data we

382
00:14:32,679 --> 00:14:35,889
start to ask questions like how can or

383
00:14:34,240 --> 00:14:37,689
should we anonymize our data if there is

384
00:14:35,889 --> 00:14:39,490
proper ways to do so and how much

385
00:14:37,689 --> 00:14:41,349
further could our field on the red side

386
00:14:39,490 --> 00:14:42,759
go if we were able to share data sets

387
00:14:41,350 --> 00:14:44,889
with each other and train on those data

388
00:14:42,759 --> 00:14:46,809
sets in many ways it's trying to teach

389
00:14:44,889 --> 00:14:48,639
somebody to use bloodhound but you have

390
00:14:46,809 --> 00:14:50,439
to have a test Active Directory data set

391
00:14:48,639 --> 00:14:53,079
so that you don't expose information

392
00:14:50,439 --> 00:14:54,759
about a real network there are potential

393
00:14:53,079 --> 00:14:56,888
solutions for this that me and will have

394
00:14:54,759 --> 00:14:59,199
thought about obviously this list is a

395
00:14:56,889 --> 00:15:00,790
short sub list of probably a lot of

396
00:14:59,199 --> 00:15:02,740
other solutions that that people could

397
00:15:00,790 --> 00:15:04,329
implement but one is we could only keep

398
00:15:02,740 --> 00:15:05,799
the model weights themselves so we just

399
00:15:04,329 --> 00:15:07,599
looked at how we would train a sandbox

400
00:15:05,799 --> 00:15:08,949
model and we would continue doing the

401
00:15:07,600 --> 00:15:10,959
process of feeding forward and back

402
00:15:08,949 --> 00:15:12,670
propping until our accuracy rate was

403
00:15:10,959 --> 00:15:15,008
something acceptable like for instance

404
00:15:12,670 --> 00:15:16,748
ninety-five percent once we got there we

405
00:15:15,009 --> 00:15:18,459
could effectively save the model and all

406
00:15:16,749 --> 00:15:19,990
of those weights and delete the data

407
00:15:18,459 --> 00:15:22,388
that we used to train the model with in

408
00:15:19,990 --> 00:15:24,999
the future the model is trained albeit

409
00:15:22,389 --> 00:15:26,799
on legacy data so to speak but we can

410
00:15:24,999 --> 00:15:28,029
use it to detect sandboxes in the future

411
00:15:26,799 --> 00:15:30,639
so this is going to vary depending on

412
00:15:28,029 --> 00:15:32,860
how the data deviates over time we could

413
00:15:30,639 --> 00:15:34,570
hash our features for like storage this

414
00:15:32,860 --> 00:15:36,760
is obviously a

415
00:15:34,570 --> 00:15:39,430
Lu's solution that has bypasses for it

416
00:15:36,760 --> 00:15:41,530
and it speaks to a lot of things about

417
00:15:39,430 --> 00:15:42,880
domain-specific knowledge so obviously

418
00:15:41,530 --> 00:15:44,410
the more familiar you are with the

419
00:15:42,880 --> 00:15:45,760
features themselves and maybe how they

420
00:15:44,410 --> 00:15:48,130
were hashed the better you might be able

421
00:15:45,760 --> 00:15:50,260
to extract the features from the hashes

422
00:15:48,130 --> 00:15:51,370
if you got access to them we could also

423
00:15:50,260 --> 00:15:53,170
just use models that don't require

424
00:15:51,370 --> 00:15:54,460
previous data this is something like

425
00:15:53,170 --> 00:15:56,079
levenshtein distance that we'll talk

426
00:15:54,460 --> 00:15:57,850
about or the model itself doesn't

427
00:15:56,080 --> 00:15:59,620
necessarily need to be trained can it

428
00:15:57,850 --> 00:16:01,960
effectively some algorithm that gets ran

429
00:15:59,620 --> 00:16:03,850
against data in real time so another

430
00:16:01,960 --> 00:16:05,980
challenge we have is the use of textual

431
00:16:03,850 --> 00:16:08,200
data so defenders work with almost

432
00:16:05,980 --> 00:16:09,910
parsed data exclusively and or there are

433
00:16:08,200 --> 00:16:11,410
systems in place to take their textual

434
00:16:09,910 --> 00:16:14,170
data and put them into a consistent

435
00:16:11,410 --> 00:16:15,760
format offenders don't necessarily do

436
00:16:14,170 --> 00:16:17,920
that in fact we don't really agree on

437
00:16:15,760 --> 00:16:20,319
the best way to represent our data as it

438
00:16:17,920 --> 00:16:22,860
speaks to pay load generation execution

439
00:16:20,320 --> 00:16:25,120
or any any aspect of our operation

440
00:16:22,860 --> 00:16:26,830
defenders also tend to get labeled data

441
00:16:25,120 --> 00:16:28,360
easier so you think about like an email

442
00:16:26,830 --> 00:16:31,780
reporting button and outlook when the

443
00:16:28,360 --> 00:16:33,430
spam email comes in by the action of the

444
00:16:31,780 --> 00:16:36,699
user clicking report this email is spam

445
00:16:33,430 --> 00:16:38,439
a label can get assigned to a data input

446
00:16:36,700 --> 00:16:40,720
and then be used to train models later

447
00:16:38,440 --> 00:16:42,970
on so as offenders we have to start

448
00:16:40,720 --> 00:16:44,830
thinking about labeling our data as we

449
00:16:42,970 --> 00:16:48,280
go through an operation or you know

450
00:16:44,830 --> 00:16:49,600
quickly after or shortly after so

451
00:16:48,280 --> 00:16:50,980
expanding on this idea of feature

452
00:16:49,600 --> 00:16:52,900
engineering which once again we kind of

453
00:16:50,980 --> 00:16:54,970
glossed over this is really the magic of

454
00:16:52,900 --> 00:16:56,949
ML in my eyes is you have a bunch of raw

455
00:16:54,970 --> 00:16:58,480
data and your feature engineering can

456
00:16:56,950 --> 00:17:00,460
sort of make or break your end model

457
00:16:58,480 --> 00:17:03,280
we're trying to target important meta

458
00:17:00,460 --> 00:17:04,660
properties of the data itself and domain

459
00:17:03,280 --> 00:17:07,210
knowledge which I assume everybody in

460
00:17:04,660 --> 00:17:08,950
here has is a great resource there so

461
00:17:07,210 --> 00:17:11,319
when you think about a process list

462
00:17:08,950 --> 00:17:12,819
knowing that process IDs increment and

463
00:17:11,319 --> 00:17:14,589
Windows or how they increment can be

464
00:17:12,819 --> 00:17:17,530
extremely valuable for extracting useful

465
00:17:14,589 --> 00:17:19,659
features we generally just use basic

466
00:17:17,530 --> 00:17:22,030
statistics or sort of put on our data

467
00:17:19,660 --> 00:17:23,770
analysis hat when we're trying to design

468
00:17:22,030 --> 00:17:25,119
features up front we could ask ourselves

469
00:17:23,770 --> 00:17:26,560
like what does the distribution of

470
00:17:25,119 --> 00:17:29,229
commands look like if we were trying to

471
00:17:26,560 --> 00:17:30,970
analyze them we could ask do new

472
00:17:29,230 --> 00:17:32,500
features line up with an existing label

473
00:17:30,970 --> 00:17:34,060
so if we create a new feature and we

474
00:17:32,500 --> 00:17:36,070
have labels that we already know are say

475
00:17:34,060 --> 00:17:37,750
a sandbox or not a sandbox do the

476
00:17:36,070 --> 00:17:39,399
features even visually or when we look

477
00:17:37,750 --> 00:17:41,050
at it with our human eye make sense are

478
00:17:39,400 --> 00:17:42,700
the features scaling properly or do they

479
00:17:41,050 --> 00:17:45,310
seem to go up when a sandbox is there

480
00:17:42,700 --> 00:17:46,930
and down when a sandbox isn't we want to

481
00:17:45,310 --> 00:17:48,429
try to reduce correlated features calls

482
00:17:46,930 --> 00:17:49,780
like feature noise and

483
00:17:48,430 --> 00:17:52,330
we can do this before a model is trained

484
00:17:49,780 --> 00:17:54,250
or after after it's trained we would

485
00:17:52,330 --> 00:17:56,169
effectively just take the train model

486
00:17:54,250 --> 00:18:00,070
and cycle features and see if it had an

487
00:17:56,170 --> 00:18:02,320
effect on our input or lack of effect so

488
00:18:00,070 --> 00:18:04,179
once we think about our data and the

489
00:18:02,320 --> 00:18:05,860
data processing that we have to perform

490
00:18:04,180 --> 00:18:07,990
on it then we're starting to design data

491
00:18:05,860 --> 00:18:10,060
pipelines and I know obviously there's

492
00:18:07,990 --> 00:18:13,090
some projects at the bottom that detail

493
00:18:10,060 --> 00:18:14,800
this out this is not a new problem to us

494
00:18:13,090 --> 00:18:16,899
and we think a lot of people are working

495
00:18:14,800 --> 00:18:18,040
hard to tackle these challenges but

496
00:18:16,900 --> 00:18:19,690
we're starting to think about how red

497
00:18:18,040 --> 00:18:21,730
teamers can build processes for managing

498
00:18:19,690 --> 00:18:23,200
our data and these apply both long and

499
00:18:21,730 --> 00:18:25,900
short term so there's a short term

500
00:18:23,200 --> 00:18:27,220
process that is like specific so you

501
00:18:25,900 --> 00:18:29,080
might only run it when you're actually

502
00:18:27,220 --> 00:18:30,760
performing an operation there's the long

503
00:18:29,080 --> 00:18:32,379
term data that you ideally keep even

504
00:18:30,760 --> 00:18:33,879
after an OP is ended which speaks back

505
00:18:32,380 --> 00:18:36,820
to the point earlier about keeping data

506
00:18:33,880 --> 00:18:38,740
this processes are these this processing

507
00:18:36,820 --> 00:18:40,810
requires engineering so we need to start

508
00:18:38,740 --> 00:18:43,360
early if we intend to train models later

509
00:18:40,810 --> 00:18:44,500
on so if you are at all interested in ml

510
00:18:43,360 --> 00:18:46,810
you need to start collecting this data

511
00:18:44,500 --> 00:18:48,760
now so that you have it later on these

512
00:18:46,810 --> 00:18:50,350
implementations will vary greatly by

513
00:18:48,760 --> 00:18:51,850
team TTP's so whether or not your tool

514
00:18:50,350 --> 00:18:53,709
is say multi player or single player

515
00:18:51,850 --> 00:18:55,990
could derive a lot about what sort of

516
00:18:53,710 --> 00:18:57,670
data you're extracting from it it's

517
00:18:55,990 --> 00:18:59,650
ideally passive so it shouldn't have an

518
00:18:57,670 --> 00:19:01,600
effect on the operators themselves but

519
00:18:59,650 --> 00:19:03,250
it will reduce some agnosticism and

520
00:19:01,600 --> 00:19:05,800
likely tie us down to the system later

521
00:19:03,250 --> 00:19:07,300
on this is like a rough abstract diagram

522
00:19:05,800 --> 00:19:09,370
of what I'm talking about

523
00:19:07,300 --> 00:19:11,409
up top you have the opt period processes

524
00:19:09,370 --> 00:19:13,540
so those are temporary and we have our

525
00:19:11,410 --> 00:19:15,010
long-term collection over on the left so

526
00:19:13,540 --> 00:19:15,370
we have our op running in the bottom

527
00:19:15,010 --> 00:19:17,320
right

528
00:19:15,370 --> 00:19:18,699
very classic we have operators who are

529
00:19:17,320 --> 00:19:21,010
interacting with the toolkit to run

530
00:19:18,700 --> 00:19:22,270
agents and a network and we want to sort

531
00:19:21,010 --> 00:19:25,330
of strap on a data source to that

532
00:19:22,270 --> 00:19:27,280
toolkit and start almost exfiltrating

533
00:19:25,330 --> 00:19:29,560
data out of the tool as it flows between

534
00:19:27,280 --> 00:19:31,060
so actions that operators are taking or

535
00:19:29,560 --> 00:19:32,620
actions that are occurring and in the

536
00:19:31,060 --> 00:19:34,870
network this could be something simple

537
00:19:32,620 --> 00:19:36,850
like a JSON file or a sequel light

538
00:19:34,870 --> 00:19:39,280
database or something more proper in the

539
00:19:36,850 --> 00:19:40,929
cloud but after that while the OP is

540
00:19:39,280 --> 00:19:42,700
ending or maybe when the OP ends we're

541
00:19:40,930 --> 00:19:44,530
gonna transition it into a parsing layer

542
00:19:42,700 --> 00:19:46,150
so this is where we anonymize our data

543
00:19:44,530 --> 00:19:47,889
this is where we make it safe for

544
00:19:46,150 --> 00:19:49,420
storage we also want to get different

545
00:19:47,890 --> 00:19:51,850
events that speak to different qualities

546
00:19:49,420 --> 00:19:54,400
of an OP into a singular format so we

547
00:19:51,850 --> 00:19:56,409
would want to maybe tag all of the

548
00:19:54,400 --> 00:19:57,910
actions that we could ever take it in an

549
00:19:56,410 --> 00:19:59,440
operation under like a numerical

550
00:19:57,910 --> 00:20:01,870
category and then we could start

551
00:19:59,440 --> 00:20:03,880
training off of that category using

552
00:20:01,870 --> 00:20:06,159
like the end label or the multi-label

553
00:20:03,880 --> 00:20:07,809
classification will explained we would

554
00:20:06,160 --> 00:20:09,400
store this data and then we could train

555
00:20:07,809 --> 00:20:11,590
and test models to our hearts content

556
00:20:09,400 --> 00:20:13,390
after the fact and hopefully we can

557
00:20:11,590 --> 00:20:15,929
glean some insights from those models

558
00:20:13,390 --> 00:20:17,770
and ending integrated into our tools and

559
00:20:15,930 --> 00:20:19,450
lastly just a note about team

560
00:20:17,770 --> 00:20:21,100
integration so development for these

561
00:20:19,450 --> 00:20:22,270
processes is going to be a requirement

562
00:20:21,100 --> 00:20:24,459
obviously everything we've explained

563
00:20:22,270 --> 00:20:25,780
needs to be built somehow we don't see

564
00:20:24,460 --> 00:20:26,830
this as an issue we think people are

565
00:20:25,780 --> 00:20:28,720
really getting on this train of

566
00:20:26,830 --> 00:20:30,159
designing their own tools or their own

567
00:20:28,720 --> 00:20:32,950
supporting platforms for running

568
00:20:30,160 --> 00:20:35,730
operations and it's helpful if you have

569
00:20:32,950 --> 00:20:38,140
access to the tool source code obviously

570
00:20:35,730 --> 00:20:40,929
consider the trust in the final solution

571
00:20:38,140 --> 00:20:43,240
will has a saying that smaadahl is made

572
00:20:40,929 --> 00:20:45,160
or broken by the ultimate results or

573
00:20:43,240 --> 00:20:46,809
trust and the results that it produces

574
00:20:45,160 --> 00:20:49,059
so if operators are going to be using

575
00:20:46,809 --> 00:20:50,889
these results or these models at all in

576
00:20:49,059 --> 00:20:52,030
real-world ops they need to be able to

577
00:20:50,890 --> 00:20:53,920
trust that the model is actually

578
00:20:52,030 --> 00:20:56,410
extracting useful information for them

579
00:20:53,920 --> 00:20:58,059
you'll start with isolated jobs like we

580
00:20:56,410 --> 00:20:59,350
went through sandboxes which speak to

581
00:20:58,059 --> 00:21:01,389
like a binary classification problem

582
00:20:59,350 --> 00:21:02,919
it's really simple you could also do

583
00:21:01,390 --> 00:21:04,750
things just like statistics for ops

584
00:21:02,920 --> 00:21:08,230
average number of commands or the count

585
00:21:04,750 --> 00:21:09,970
and distribution of commands all right

586
00:21:08,230 --> 00:21:12,429
so now we're going to talk a little bit

587
00:21:09,970 --> 00:21:14,500
about attack graph theory and

588
00:21:12,429 --> 00:21:16,510
particularly the the future of this as

589
00:21:14,500 --> 00:21:18,090
we see it so there's a current state of

590
00:21:16,510 --> 00:21:20,260
attack path

591
00:21:18,090 --> 00:21:22,240
exploitation that's very standard I

592
00:21:20,260 --> 00:21:23,650
imagine most people in here have used

593
00:21:22,240 --> 00:21:26,620
bloodhound or at least heard of it I

594
00:21:23,650 --> 00:21:28,330
certainly see some t-shirts neo4j is the

595
00:21:26,620 --> 00:21:29,709
base plane for this and neo4j is

596
00:21:28,330 --> 00:21:31,330
generally just an extremely powerful

597
00:21:29,710 --> 00:21:33,340
tool that we'll use as a reference for

598
00:21:31,330 --> 00:21:35,649
implementing some extensions on you know

599
00:21:33,340 --> 00:21:37,000
traditional bloodhound theory bloodhound

600
00:21:35,650 --> 00:21:39,070
works great when you have all of the

601
00:21:37,000 --> 00:21:40,480
information available to you but we

602
00:21:39,070 --> 00:21:42,580
believe that this information is going

603
00:21:40,480 --> 00:21:44,770
to degrade over time so whether or not

604
00:21:42,580 --> 00:21:46,809
it's there changes in the underlying OS

605
00:21:44,770 --> 00:21:48,820
or Active Directory the growing use of

606
00:21:46,809 --> 00:21:50,379
OSS that aren't as standardized or even

607
00:21:48,820 --> 00:21:52,270
network segmentation that stops us from

608
00:21:50,380 --> 00:21:53,650
querying that data altogether we're

609
00:21:52,270 --> 00:21:55,870
gonna have to start making inferences

610
00:21:53,650 --> 00:21:58,690
about the relationships between objects

611
00:21:55,870 --> 00:22:00,070
without knowing them for certain these

612
00:21:58,690 --> 00:22:01,510
networks are unknown but they're

613
00:22:00,070 --> 00:22:03,340
discrete which is good for our ml

614
00:22:01,510 --> 00:22:05,050
challenge effectively we can say well we

615
00:22:03,340 --> 00:22:06,459
don't know the user names permissions or

616
00:22:05,050 --> 00:22:08,169
all of the extended features of a

617
00:22:06,460 --> 00:22:10,300
network we certainly know that it's not

618
00:22:08,170 --> 00:22:12,850
infinite so we can sort of scope our

619
00:22:10,300 --> 00:22:14,889
problem that way in terms of data

620
00:22:12,850 --> 00:22:15,669
inference another nice quality of

621
00:22:14,890 --> 00:22:17,950
networks is that they

622
00:22:15,670 --> 00:22:19,600
require organization so networks as we

623
00:22:17,950 --> 00:22:21,250
think about them are a bunch of it's

624
00:22:19,600 --> 00:22:23,770
effectively a collection of assets and

625
00:22:21,250 --> 00:22:25,120
we label them textually and we organize

626
00:22:23,770 --> 00:22:27,070
them into clusters and put them in

627
00:22:25,120 --> 00:22:29,110
groups so humans are organizing these

628
00:22:27,070 --> 00:22:30,700
networks that way we know if we land in

629
00:22:29,110 --> 00:22:33,280
any network regardless of its size or

630
00:22:30,700 --> 00:22:36,970
its origin we can imply that there are

631
00:22:33,280 --> 00:22:38,080
is data organization going on we can

632
00:22:36,970 --> 00:22:39,280
then look at trying to infer

633
00:22:38,080 --> 00:22:41,139
relationships based on things like

634
00:22:39,280 --> 00:22:43,570
textual similarities so the fact that

635
00:22:41,140 --> 00:22:45,070
sequel developers have sequel in their

636
00:22:43,570 --> 00:22:46,780
name and they likely have access to

637
00:22:45,070 --> 00:22:48,760
sequel servers we don't have to query

638
00:22:46,780 --> 00:22:50,560
those servers to know that but as an

639
00:22:48,760 --> 00:22:52,570
attacker I immediately know that sequel

640
00:22:50,560 --> 00:22:55,000
developers and sequel servers share a

641
00:22:52,570 --> 00:22:56,889
common term sequel that might might tell

642
00:22:55,000 --> 00:22:58,210
me something about their relationship we

643
00:22:56,890 --> 00:22:59,980
could also use like local host

644
00:22:58,210 --> 00:23:02,500
information such as map drives local

645
00:22:59,980 --> 00:23:04,420
users or even external sources like

646
00:23:02,500 --> 00:23:05,770
LinkedIn or github you think about the

647
00:23:04,420 --> 00:23:08,560
number of people that put their job

648
00:23:05,770 --> 00:23:10,720
description on github um so just parsing

649
00:23:08,560 --> 00:23:12,250
or on not on github LinkedIn so you

650
00:23:10,720 --> 00:23:14,020
think about parsing LinkedIn you could

651
00:23:12,250 --> 00:23:15,970
collect a potential list of users and

652
00:23:14,020 --> 00:23:17,080
their job titles and immediately start

653
00:23:15,970 --> 00:23:18,370
inferring the sort of groups or

654
00:23:17,080 --> 00:23:20,110
permissions they would have in a network

655
00:23:18,370 --> 00:23:23,260
all without actually touching Active

656
00:23:20,110 --> 00:23:25,090
Directory itself so this is almost a

657
00:23:23,260 --> 00:23:27,490
layout of of what we mean when we say

658
00:23:25,090 --> 00:23:29,560
attack graph without knowledge it's

659
00:23:27,490 --> 00:23:30,910
discrete so we know the end of the

660
00:23:29,560 --> 00:23:33,550
attack graph but now we're starting to

661
00:23:30,910 --> 00:23:35,980
blend in this idea of fog of war so we

662
00:23:33,550 --> 00:23:38,020
know where we are and we might know the

663
00:23:35,980 --> 00:23:40,030
next few steps past us but we ultimately

664
00:23:38,020 --> 00:23:41,379
don't know what true relationships are

665
00:23:40,030 --> 00:23:43,629
held in the network so we can start

666
00:23:41,380 --> 00:23:46,030
exploring say a user a can take over

667
00:23:43,630 --> 00:23:48,310
user B we get access and we try to pivot

668
00:23:46,030 --> 00:23:49,899
to host C but we don't have privileges

669
00:23:48,310 --> 00:23:52,330
there so we walk back and effectively

670
00:23:49,900 --> 00:23:53,590
explore alternative paths obviously if

671
00:23:52,330 --> 00:23:54,610
we'd cleared this network from the

672
00:23:53,590 --> 00:23:55,990
beginning we would have all this

673
00:23:54,610 --> 00:23:57,520
information and we would know that the

674
00:23:55,990 --> 00:24:00,700
top path would not succeed and the

675
00:23:57,520 --> 00:24:02,650
middle path would but now this process

676
00:24:00,700 --> 00:24:06,310
of subsequent querying is really going

677
00:24:02,650 --> 00:24:07,390
to drive the success of our models when

678
00:24:06,310 --> 00:24:10,300
we don't have access to all that

679
00:24:07,390 --> 00:24:11,680
information upfront so I imagine when

680
00:24:10,300 --> 00:24:13,510
most people thought about that diagram

681
00:24:11,680 --> 00:24:15,460
they may be connected with this idea

682
00:24:13,510 --> 00:24:17,920
that as attackers we build Network maps

683
00:24:15,460 --> 00:24:19,840
as part of our day-to-day operations we

684
00:24:17,920 --> 00:24:21,400
assume relationships based on you know

685
00:24:19,840 --> 00:24:23,139
our experiences in a network or even

686
00:24:21,400 --> 00:24:24,850
pattern recognition like we've seen

687
00:24:23,140 --> 00:24:27,070
configurations in the network that speak

688
00:24:24,850 --> 00:24:29,469
to X so we expect those configurations

689
00:24:27,070 --> 00:24:29,679
to repeat we act on these assumptions

690
00:24:29,470 --> 00:24:31,360
with

691
00:24:29,680 --> 00:24:33,070
queries so we make an assumption we have

692
00:24:31,360 --> 00:24:34,540
a prior belief and we validate that

693
00:24:33,070 --> 00:24:36,820
assumption using a query that's

694
00:24:34,540 --> 00:24:38,530
effectively all attackers do we check

695
00:24:36,820 --> 00:24:40,060
access to a host we verify group

696
00:24:38,530 --> 00:24:41,710
membership or we collect new attack

697
00:24:40,060 --> 00:24:43,540
surface via that same enumeration

698
00:24:41,710 --> 00:24:45,340
process so many ways we can be thought

699
00:24:43,540 --> 00:24:47,139
of constantly transitioning between on

700
00:24:45,340 --> 00:24:48,909
some shion's and querying to validate

701
00:24:47,140 --> 00:24:50,500
those assumptions over time this

702
00:24:48,910 --> 00:24:52,480
information creates confidence that we

703
00:24:50,500 --> 00:24:56,200
can use to state confidently the

704
00:24:52,480 --> 00:24:57,700
security of a network cool so now we're

705
00:24:56,200 --> 00:25:00,310
gonna talk about simulating is mental

706
00:24:57,700 --> 00:25:01,830
models so we have a model and we kind of

707
00:25:00,310 --> 00:25:04,030
know the process that we go through

708
00:25:01,830 --> 00:25:06,429
mentally to get to where you want to go

709
00:25:04,030 --> 00:25:09,100
and I've broken it down into effectively

710
00:25:06,430 --> 00:25:11,200
we have a data layer so the information

711
00:25:09,100 --> 00:25:12,879
from the current context is let's say

712
00:25:11,200 --> 00:25:14,950
you land you fish somebody you land on a

713
00:25:12,880 --> 00:25:16,720
host you know you might have net stat

714
00:25:14,950 --> 00:25:18,310
information for example that's going to

715
00:25:16,720 --> 00:25:19,450
point to other hosts so maybe there's a

716
00:25:18,310 --> 00:25:22,240
connection on there that points to

717
00:25:19,450 --> 00:25:24,040
intranet so now without querying Active

718
00:25:22,240 --> 00:25:25,870
Directory or you have some sort of

719
00:25:24,040 --> 00:25:28,360
information that you can then start to

720
00:25:25,870 --> 00:25:30,399
build these paths out on the next piece

721
00:25:28,360 --> 00:25:32,050
is heuristic search or you know a

722
00:25:30,400 --> 00:25:34,180
heuristic rule and this is operator

723
00:25:32,050 --> 00:25:35,919
driven so it's like whatever for example

724
00:25:34,180 --> 00:25:37,990
those features or whatever those those

725
00:25:35,920 --> 00:25:40,360
rules that you use as an operator to

726
00:25:37,990 --> 00:25:43,540
move throughout a network this is that

727
00:25:40,360 --> 00:25:46,020
heuristic search um and then we can use

728
00:25:43,540 --> 00:25:47,470
simulation so Monte Carlo tree search

729
00:25:46,020 --> 00:25:49,930
we're going to go through a

730
00:25:47,470 --> 00:25:51,460
reinforcement learning example but then

731
00:25:49,930 --> 00:25:54,190
we can start simulating these things out

732
00:25:51,460 --> 00:25:55,660
using graphs and probabilities so if we

733
00:25:54,190 --> 00:25:57,730
say let's say we have a hundred users

734
00:25:55,660 --> 00:25:59,830
well our probability is you know one in

735
00:25:57,730 --> 00:26:01,660
a hundred for any given permission that

736
00:25:59,830 --> 00:26:03,189
it might be I mean you just go through

737
00:26:01,660 --> 00:26:04,900
and without creating the network but the

738
00:26:03,190 --> 00:26:07,030
information we have just simulated out

739
00:26:04,900 --> 00:26:08,860
to the nth degree and then the algorithm

740
00:26:07,030 --> 00:26:12,580
can you know back prop and then give us

741
00:26:08,860 --> 00:26:15,070
the best potential path we could take it

742
00:26:12,580 --> 00:26:16,780
hinges on the heuristic so you know if

743
00:26:15,070 --> 00:26:18,310
you're if you don't have a great you're

744
00:26:16,780 --> 00:26:22,240
a sick you're not going to have a great

745
00:26:18,310 --> 00:26:24,580
model and the simulation there could be

746
00:26:22,240 --> 00:26:26,740
passive but it could also be active so

747
00:26:24,580 --> 00:26:28,689
when we say it can assist an operator in

748
00:26:26,740 --> 00:26:31,540
finding a path we could also just hand

749
00:26:28,690 --> 00:26:32,980
it the the we could also put it in the

750
00:26:31,540 --> 00:26:36,690
driving seat where we allow it to

751
00:26:32,980 --> 00:26:38,800
execute commands and then infer output

752
00:26:36,690 --> 00:26:41,980
so in the day layer we just have you

753
00:26:38,800 --> 00:26:43,389
know your active host your outbound RDP

754
00:26:41,980 --> 00:26:46,479
history whatever it is that you're

755
00:26:43,389 --> 00:26:50,498
King for or you know for example we have

756
00:26:46,479 --> 00:26:51,729
Trevor really likes event logs so he

757
00:26:50,499 --> 00:26:53,019
could might he might have some

758
00:26:51,729 --> 00:26:54,459
particular thing that he's looking for

759
00:26:53,019 --> 00:26:56,559
in event logs that he's trying to

760
00:26:54,459 --> 00:26:58,929
correlate somewhere else and so for him

761
00:26:56,559 --> 00:27:01,959
he could throw that into as one of his

762
00:26:58,929 --> 00:27:03,369
data layers you have a heuristic Slayer

763
00:27:01,959 --> 00:27:06,879
this is like how can we relate that

764
00:27:03,369 --> 00:27:09,728
textual data and what strategies are

765
00:27:06,879 --> 00:27:11,289
used already and but effectively we just

766
00:27:09,729 --> 00:27:13,749
need some number to support our

767
00:27:11,289 --> 00:27:15,399
simulation so mass requires numbers and

768
00:27:13,749 --> 00:27:16,539
so we're always trying to go from text

769
00:27:15,399 --> 00:27:18,458
data which is the challenge that we

770
00:27:16,539 --> 00:27:21,700
mentioned into some sort of numerical

771
00:27:18,459 --> 00:27:24,729
value that is representative of our our

772
00:27:21,700 --> 00:27:26,320
textual data a heuristic for example

773
00:27:24,729 --> 00:27:28,869
could be just a simple if statement that

774
00:27:26,320 --> 00:27:31,450
say this is the most basic and it's the

775
00:27:28,869 --> 00:27:35,589
most flexible for people so for example

776
00:27:31,450 --> 00:27:37,629
if you know you know your user Billy Joe

777
00:27:35,589 --> 00:27:39,969
and you do a getting at local group and

778
00:27:37,629 --> 00:27:41,649
you see your user in the local admins

779
00:27:39,969 --> 00:27:43,709
group you can just write a simple if

780
00:27:41,649 --> 00:27:48,488
statement says you know if my user in

781
00:27:43,709 --> 00:27:50,469
output then sweet I'm admin so it

782
00:27:48,489 --> 00:27:52,450
doesn't necessarily require complexity

783
00:27:50,469 --> 00:27:54,879
but if you're tasked with building out

784
00:27:52,450 --> 00:27:58,479
these rules one by one it gets very

785
00:27:54,879 --> 00:28:00,070
difficult so for example you could think

786
00:27:58,479 --> 00:28:03,489
use like things like cosine similarity

787
00:28:00,070 --> 00:28:05,799
where you're bringing in relationships

788
00:28:03,489 --> 00:28:09,609
or you're projecting relationships onto

789
00:28:05,799 --> 00:28:11,408
a graph and then you're looking at the

790
00:28:09,609 --> 00:28:11,739
distance between these two points on a

791
00:28:11,409 --> 00:28:14,289
graph

792
00:28:11,739 --> 00:28:16,539
so effectively again we're in that one

793
00:28:14,289 --> 00:28:18,729
how to encoding we're just turning

794
00:28:16,539 --> 00:28:21,729
textual data into numbers and then we're

795
00:28:18,729 --> 00:28:23,709
using cosine similarity to build for

796
00:28:21,729 --> 00:28:27,429
example something like this graph here

797
00:28:23,709 --> 00:28:30,249
so this is a network of users and

798
00:28:27,429 --> 00:28:33,159
they're clustered by their group

799
00:28:30,249 --> 00:28:35,679
memberships so I just took their group

800
00:28:33,159 --> 00:28:37,869
memberships and then put them in as a

801
00:28:35,679 --> 00:28:40,059
string and then now that becomes like

802
00:28:37,869 --> 00:28:41,978
the one hot encoding piece and then we

803
00:28:40,059 --> 00:28:44,219
just cluster them and so it's

804
00:28:41,979 --> 00:28:46,809
interesting is sort of this distribution

805
00:28:44,219 --> 00:28:49,539
where all the DA's kind of pile up in

806
00:28:46,809 --> 00:28:51,369
the middle and this is fairly uniform

807
00:28:49,539 --> 00:28:53,559
across all of the networks that we've

808
00:28:51,369 --> 00:28:55,119
done it and so if you imagine let's say

809
00:28:53,559 --> 00:28:57,668
we've passwords braids or we have some

810
00:28:55,119 --> 00:28:59,320
credentials before

811
00:28:57,669 --> 00:29:01,209
getting into it over for is starting to

812
00:28:59,320 --> 00:29:05,619
query go down that path you could for

813
00:29:01,209 --> 00:29:07,929
example look at the distance between any

814
00:29:05,619 --> 00:29:10,238
given user and your target user or a

815
00:29:07,929 --> 00:29:11,829
target host and you could calculate that

816
00:29:10,239 --> 00:29:13,839
cosine similarity and you can just take

817
00:29:11,829 --> 00:29:17,168
a sum of that and you'd maybe get some

818
00:29:13,839 --> 00:29:19,359
reasonable assumption that this user is

819
00:29:17,169 --> 00:29:21,279
the best user to go after rather than

820
00:29:19,359 --> 00:29:24,158
starting with like three other users

821
00:29:21,279 --> 00:29:26,190
that aren't aren't useful to you the

822
00:29:24,159 --> 00:29:28,329
second one this is currently my favorite

823
00:29:26,190 --> 00:29:30,129
here is Tikun it's just levenshtein

824
00:29:28,329 --> 00:29:32,859
distance and it's a string edit metric

825
00:29:30,129 --> 00:29:34,329
but effectively and i should say these

826
00:29:32,859 --> 00:29:37,689
are the queries that you can use in

827
00:29:34,329 --> 00:29:40,629
neo4j to get this information but

828
00:29:37,690 --> 00:29:43,089
effectively it'll bring those sequel

829
00:29:40,629 --> 00:29:45,399
developers and sequel dev it'll score

830
00:29:43,089 --> 00:29:47,859
those based on the edit metric or the

831
00:29:45,399 --> 00:29:49,779
distance and it'll bring those

832
00:29:47,859 --> 00:29:51,279
relationships to the top so rather than

833
00:29:49,779 --> 00:29:53,440
you having to go through and scroll

834
00:29:51,279 --> 00:29:54,700
looking for sequel servers you can just

835
00:29:53,440 --> 00:29:56,950
run this against whatever information

836
00:29:54,700 --> 00:29:58,899
you have and it scan that those

837
00:29:56,950 --> 00:30:00,549
relationships by design of the algorithm

838
00:29:58,899 --> 00:30:04,539
are just going to bubble to the top for

839
00:30:00,549 --> 00:30:06,219
you okay so now we have heuristic we're

840
00:30:04,539 --> 00:30:09,429
just gonna go into the the shortest path

841
00:30:06,219 --> 00:30:10,899
or simulation so we have Dijkstra

842
00:30:09,429 --> 00:30:13,239
algorithm and this is the default in

843
00:30:10,899 --> 00:30:14,738
bloodhound and it's the shortest path

844
00:30:13,239 --> 00:30:16,179
algorithm it only goes one direction so

845
00:30:14,739 --> 00:30:19,149
is always gonna it's always going to

846
00:30:16,179 --> 00:30:21,669
find you the shortest path but it's like

847
00:30:19,149 --> 00:30:23,889
it's for GPS so it gives you gets you

848
00:30:21,669 --> 00:30:25,749
the fastest from point A to point B we

849
00:30:23,889 --> 00:30:28,149
know and love it like it's it's awesome

850
00:30:25,749 --> 00:30:29,919
there talks like the bloodhound guys

851
00:30:28,149 --> 00:30:31,478
have been I don't know how long has been

852
00:30:29,919 --> 00:30:34,629
out the past five years so they were

853
00:30:31,479 --> 00:30:36,219
well ahead of their time and it may be

854
00:30:34,629 --> 00:30:38,949
kind of sad that it took us this long to

855
00:30:36,219 --> 00:30:41,589
catch up so there ought talks are

856
00:30:38,950 --> 00:30:43,179
awesome the guys are awesome it's useful

857
00:30:41,589 --> 00:30:45,729
for mapping finding paths for problems

858
00:30:43,179 --> 00:30:48,429
but it's not the only one so for example

859
00:30:45,729 --> 00:30:50,799
an a-star algorithm this is also in

860
00:30:48,429 --> 00:30:53,829
neo4j let's let's suppose we want to

861
00:30:50,799 --> 00:30:57,668
take we want to apply a cost function so

862
00:30:53,829 --> 00:31:00,339
imagine we only have 15 queries in a

863
00:30:57,669 --> 00:31:02,499
network before you're you're gone so how

864
00:31:00,339 --> 00:31:05,168
do you maximize those 15 queries what's

865
00:31:02,499 --> 00:31:08,009
the maximum distance you can get in 15

866
00:31:05,169 --> 00:31:10,179
queries and what are the the best ones

867
00:31:08,009 --> 00:31:11,140
so it might help us avoid particular

868
00:31:10,179 --> 00:31:12,640
paths so

869
00:31:11,140 --> 00:31:14,260
for example in Active Directory you

870
00:31:12,640 --> 00:31:15,730
might get some relationship out but

871
00:31:14,260 --> 00:31:17,980
network segmentation prevents you from

872
00:31:15,730 --> 00:31:19,450
actually exploiting it and so a

873
00:31:17,980 --> 00:31:22,930
different algorithm like a star might

874
00:31:19,450 --> 00:31:23,950
help you get around that and in a

875
00:31:22,930 --> 00:31:27,190
reasonable way

876
00:31:23,950 --> 00:31:28,510
but for us we'd like so that's the

877
00:31:27,190 --> 00:31:30,000
passive side now we're going to talk the

878
00:31:28,510 --> 00:31:32,470
active site in a Q learning

879
00:31:30,000 --> 00:31:35,110
implementation so Q learning is like

880
00:31:32,470 --> 00:31:37,120
reinforcement 101 and I like it just

881
00:31:35,110 --> 00:31:38,399
because it is 101 but it's also it can

882
00:31:37,120 --> 00:31:43,209
be really powerful with the right

883
00:31:38,400 --> 00:31:45,700
decision here stick and it basically

884
00:31:43,210 --> 00:31:47,770
says free given action in a given state

885
00:31:45,700 --> 00:31:50,230
the environment returns a new state and

886
00:31:47,770 --> 00:31:52,480
a reward so you're an agent and you're

887
00:31:50,230 --> 00:31:54,430
going to perform some action against the

888
00:31:52,480 --> 00:31:57,250
target network that target networkers

889
00:31:54,430 --> 00:31:58,720
can give you back some output and then

890
00:31:57,250 --> 00:32:00,010
from that you're going to infer or

891
00:31:58,720 --> 00:32:04,090
you're going to give your agent some

892
00:32:00,010 --> 00:32:06,550
sort of reward and typically initial it

893
00:32:04,090 --> 00:32:09,280
requires like all the cue tables that is

894
00:32:06,550 --> 00:32:11,590
as it's called is initially with all

895
00:32:09,280 --> 00:32:13,629
zeros so it knows nothing about going in

896
00:32:11,590 --> 00:32:16,090
which is suboptimal for us like we can't

897
00:32:13,630 --> 00:32:20,530
go into a network learn it and then hack

898
00:32:16,090 --> 00:32:23,020
it we need to learn as we go and so this

899
00:32:20,530 --> 00:32:25,389
is kind of what it looks like so we have

900
00:32:23,020 --> 00:32:27,129
this the state the state action pairs so

901
00:32:25,390 --> 00:32:29,860
for example in this case we've used

902
00:32:27,130 --> 00:32:32,200
leviston distance to pre-fill our cue

903
00:32:29,860 --> 00:32:34,870
table so it already has some knowledge

904
00:32:32,200 --> 00:32:36,400
that we would already use so we've

905
00:32:34,870 --> 00:32:38,830
prefilled the cue tables so when it goes

906
00:32:36,400 --> 00:32:43,120
to select an action it's incentivized to

907
00:32:38,830 --> 00:32:44,560
you know it's incentivized by the reward

908
00:32:43,120 --> 00:32:47,790
so it's going to see a positive reward

909
00:32:44,560 --> 00:32:50,889
it's going to wait that action higher so

910
00:32:47,790 --> 00:32:53,020
versus an action that has zero points so

911
00:32:50,890 --> 00:32:56,140
in most of your 11 seem distance if you

912
00:32:53,020 --> 00:32:58,960
use it it will be 0 so effectively we'll

913
00:32:56,140 --> 00:33:02,830
select an action and the environment

914
00:32:58,960 --> 00:33:06,400
will give us you know some output so on

915
00:33:02,830 --> 00:33:07,870
the right you see directory of and we

916
00:33:06,400 --> 00:33:11,230
give it some reward and then we just

917
00:33:07,870 --> 00:33:14,409
refill refill the cue table this is

918
00:33:11,230 --> 00:33:16,210
useful when it's all zeros but it's like

919
00:33:14,410 --> 00:33:19,290
you can have all your states and all

920
00:33:16,210 --> 00:33:22,120
your actions so for example here we have

921
00:33:19,290 --> 00:33:24,220
shell on sequel dev so it's not just an

922
00:33:22,120 --> 00:33:25,280
admin you can set whatever states you

923
00:33:24,220 --> 00:33:26,690
want it to be

924
00:33:25,280 --> 00:33:28,460
and then you can set any number of

925
00:33:26,690 --> 00:33:31,010
actions so for example if in your

926
00:33:28,460 --> 00:33:33,260
toolkit if you have 99 commands you

927
00:33:31,010 --> 00:33:35,810
could just take every host like if you

928
00:33:33,260 --> 00:33:37,670
want to do LS an action just be LS for

929
00:33:35,810 --> 00:33:39,770
every single host and then you'd have

930
00:33:37,670 --> 00:33:41,150
some entry in the cue table so when it

931
00:33:39,770 --> 00:33:45,590
does that whether or not it was

932
00:33:41,150 --> 00:33:47,720
successful it would look so super

933
00:33:45,590 --> 00:33:50,240
awesome actually this is on this is also

934
00:33:47,720 --> 00:33:52,160
at besides so there's a script out on my

935
00:33:50,240 --> 00:33:53,510
github called op bot and this is it's

936
00:33:52,160 --> 00:33:55,010
the basic implementation or a

937
00:33:53,510 --> 00:33:58,580
combination of reinforcement learning

938
00:33:55,010 --> 00:34:00,800
and levenshtein distance super awesome

939
00:33:58,580 --> 00:34:03,949
there's a ton of other algorithms that

940
00:34:00,800 --> 00:34:05,930
you could potentially use so for example

941
00:34:03,950 --> 00:34:10,130
Dempster shape Schaefer is just like the

942
00:34:05,930 --> 00:34:12,380
theory of evidence that came up but

943
00:34:10,130 --> 00:34:13,940
effectively we're just all data

944
00:34:12,380 --> 00:34:16,040
processors like that's literally all we

945
00:34:13,940 --> 00:34:17,300
do is we just take in data we filter it

946
00:34:16,040 --> 00:34:19,210
we come up with some reasonable

947
00:34:17,300 --> 00:34:21,650
assumption and then we make it query

948
00:34:19,210 --> 00:34:24,110
attack graph theory we think is the

949
00:34:21,650 --> 00:34:27,440
future especially now that we're gonna

950
00:34:24,110 --> 00:34:31,580
need to start inferring data as you know

951
00:34:27,440 --> 00:34:34,070
our access to data goes away but here's

952
00:34:31,580 --> 00:34:36,350
the basic like razor or a black box so

953
00:34:34,070 --> 00:34:38,300
they're not a guarantee so there are no

954
00:34:36,350 --> 00:34:40,790
more guarantees in a world where we

955
00:34:38,300 --> 00:34:42,410
don't have information where we have to

956
00:34:40,790 --> 00:34:44,929
infer so there's no precise

957
00:34:42,409 --> 00:34:46,370
probabilities there's an you know

958
00:34:44,929 --> 00:34:48,200
nothing like that so we just have to

959
00:34:46,370 --> 00:34:50,569
rely on our domain knowledge and our

960
00:34:48,199 --> 00:34:54,859
heuristic search to make up for that

961
00:34:50,570 --> 00:34:57,800
fact and given you you can go look at

962
00:34:54,860 --> 00:35:01,850
the script but we're gonna get into the

963
00:34:57,800 --> 00:35:03,830
next more exciting bit time alright so

964
00:35:01,850 --> 00:35:05,569
we've kind of covered a collision course

965
00:35:03,830 --> 00:35:06,980
like a case study where we looked at

966
00:35:05,570 --> 00:35:09,200
sandbox detection and we looked at some

967
00:35:06,980 --> 00:35:10,550
data processing and then the last

968
00:35:09,200 --> 00:35:12,740
section was primarily talking about

969
00:35:10,550 --> 00:35:15,470
operating so offensive ml applied to

970
00:35:12,740 --> 00:35:16,609
doing what we do as operators and it's

971
00:35:15,470 --> 00:35:18,169
just a note that that cue learning

972
00:35:16,610 --> 00:35:20,180
process with levenshtein distance of say

973
00:35:18,170 --> 00:35:22,340
LS a host is not unlike what many

974
00:35:20,180 --> 00:35:23,899
operators would do but now we're going

975
00:35:22,340 --> 00:35:26,210
to get into adversarial attacks which

976
00:35:23,900 --> 00:35:28,700
we're actually pretty excited about so

977
00:35:26,210 --> 00:35:31,310
adversarial ml is attacking existing

978
00:35:28,700 --> 00:35:32,600
models the definition varies I've heard

979
00:35:31,310 --> 00:35:34,610
it described generally as just the

980
00:35:32,600 --> 00:35:37,730
application of an adversarial mindset to

981
00:35:34,610 --> 00:35:38,230
ml but it's the same stuff different de

982
00:35:37,730 --> 00:35:41,140
essential

983
00:35:38,230 --> 00:35:42,670
ml is coming about and it's has a focus

984
00:35:41,140 --> 00:35:44,290
on effectiveness and efficiency so

985
00:35:42,670 --> 00:35:46,450
that's the metric by which they judge

986
00:35:44,290 --> 00:35:48,730
the usefulness of a model or the utility

987
00:35:46,450 --> 00:35:50,379
of a model models are not designed to be

988
00:35:48,730 --> 00:35:52,150
secure or robust so there's this growing

989
00:35:50,380 --> 00:35:53,800
field in ml where we're realizing that

990
00:35:52,150 --> 00:35:55,420
we're designing models to solve problems

991
00:35:53,800 --> 00:35:56,920
but we're not making them resilient

992
00:35:55,420 --> 00:35:59,230
against attacks against those models

993
00:35:56,920 --> 00:36:00,910
this has all been proven mainly in the

994
00:35:59,230 --> 00:36:03,160
lab it's not necessarily theoretical

995
00:36:00,910 --> 00:36:05,200
it's just it's hard to build many of the

996
00:36:03,160 --> 00:36:07,420
demonstrations that we've seen and that

997
00:36:05,200 --> 00:36:09,220
are public lack practical use so maybe

998
00:36:07,420 --> 00:36:11,200
in most cases they're creating a

999
00:36:09,220 --> 00:36:14,200
classifier and then creating a Jennifer

1000
00:36:11,200 --> 00:36:15,640
our generator and then pitting them

1001
00:36:14,200 --> 00:36:18,009
against each other but they built both

1002
00:36:15,640 --> 00:36:19,779
halves there's two basic approaches to

1003
00:36:18,010 --> 00:36:21,460
this a white box approach where we have

1004
00:36:19,780 --> 00:36:24,730
access to the original model the

1005
00:36:21,460 --> 00:36:26,770
architecture the features we effectively

1006
00:36:24,730 --> 00:36:29,200
have a lot of insight into how we might

1007
00:36:26,770 --> 00:36:30,580
best attack that model there's the black

1008
00:36:29,200 --> 00:36:32,230
box such as the alternative approach

1009
00:36:30,580 --> 00:36:34,119
where we only have access to the outputs

1010
00:36:32,230 --> 00:36:35,590
so we can give it an input we can get

1011
00:36:34,119 --> 00:36:37,210
outputs but we don't have a lot of

1012
00:36:35,590 --> 00:36:38,560
insight into how it's actually creating

1013
00:36:37,210 --> 00:36:41,080
those although we can make some

1014
00:36:38,560 --> 00:36:43,450
reasonable assumptions there's a lot of

1015
00:36:41,080 --> 00:36:45,190
previous works here so you know deep

1016
00:36:43,450 --> 00:36:47,618
word bug is a black box generation of

1017
00:36:45,190 --> 00:36:49,300
adversarial text the guys at skylight

1018
00:36:47,619 --> 00:36:50,740
cyber looked at reversing a client-side

1019
00:36:49,300 --> 00:36:53,140
modeled by paths i Lance

1020
00:36:50,740 --> 00:36:54,879
there's also robustness toolbox from IBM

1021
00:36:53,140 --> 00:36:56,470
that discusses not only common attacks

1022
00:36:54,880 --> 00:36:58,510
that are used for adversarial ml but

1023
00:36:56,470 --> 00:37:00,000
also defenses so it's just a great

1024
00:36:58,510 --> 00:37:01,720
reference point for a lot of the

1025
00:37:00,000 --> 00:37:04,330
algorithms that are being applied to

1026
00:37:01,720 --> 00:37:05,560
attack these networks but for our case

1027
00:37:04,330 --> 00:37:07,060
study in this regard we're actually

1028
00:37:05,560 --> 00:37:08,500
going to look at an email security

1029
00:37:07,060 --> 00:37:11,920
company called Proofpoint

1030
00:37:08,500 --> 00:37:14,290
they represent about 230,000 domains

1031
00:37:11,920 --> 00:37:17,680
based on my analysis at the rapid7 sonar

1032
00:37:14,290 --> 00:37:20,440
data it includes 590 government domains

1033
00:37:17,680 --> 00:37:22,390
and over a little over 2,000 educational

1034
00:37:20,440 --> 00:37:25,570
domains they openly promote their use of

1035
00:37:22,390 --> 00:37:28,150
ml so you'll see the terms ml x and c LX

1036
00:37:25,570 --> 00:37:30,760
used in their data sheets a lot these

1037
00:37:28,150 --> 00:37:32,350
refer to their you know generalized ml

1038
00:37:30,760 --> 00:37:35,050
model and Cl X as their closed-loop

1039
00:37:32,350 --> 00:37:37,089
system used for customers so about a

1040
00:37:35,050 --> 00:37:40,930
year ago will came to me and who's doing

1041
00:37:37,090 --> 00:37:44,320
some testing on in the email mail

1042
00:37:40,930 --> 00:37:46,390
gateway on an OP and he noticed that

1043
00:37:44,320 --> 00:37:48,640
scores were included in the response

1044
00:37:46,390 --> 00:37:50,710
headers from an email and proof point so

1045
00:37:48,640 --> 00:37:52,089
effectively as the email had transited

1046
00:37:50,710 --> 00:37:53,770
through proof point it had

1047
00:37:52,090 --> 00:37:55,510
petted it scores into the header of that

1048
00:37:53,770 --> 00:37:57,100
email and we've highlighted them there

1049
00:37:55,510 --> 00:37:58,360
there's obviously a lot of them but

1050
00:37:57,100 --> 00:38:00,310
these Leakey inputs create an

1051
00:37:58,360 --> 00:38:01,870
opportunity for us to attack this model

1052
00:38:00,310 --> 00:38:03,370
so essentially we have control over the

1053
00:38:01,870 --> 00:38:05,200
inputs and now we can gain access to

1054
00:38:03,370 --> 00:38:07,000
their outputs so we have a few

1055
00:38:05,200 --> 00:38:09,460
theoretical attacks we can lay out based

1056
00:38:07,000 --> 00:38:11,230
on this step one we need to collect a

1057
00:38:09,460 --> 00:38:12,550
data set and this data set is our data

1058
00:38:11,230 --> 00:38:14,560
set so we're speaking to the fact that

1059
00:38:12,550 --> 00:38:16,450
we would need to send some X number of

1060
00:38:14,560 --> 00:38:18,250
emails to steal scores and line them up

1061
00:38:16,450 --> 00:38:19,899
we ideally want this data set to be as

1062
00:38:18,250 --> 00:38:22,600
big as possible but you know we might be

1063
00:38:19,900 --> 00:38:24,040
limited there to is to copy the model so

1064
00:38:22,600 --> 00:38:26,350
this is effectively we're gonna build a

1065
00:38:24,040 --> 00:38:28,120
copycat model based on those inputs and

1066
00:38:26,350 --> 00:38:29,890
outputs so that we have effectively a

1067
00:38:28,120 --> 00:38:31,930
little proof point clone model so we

1068
00:38:29,890 --> 00:38:33,549
want a model that we can play with and

1069
00:38:31,930 --> 00:38:35,890
extract insights from and use offline

1070
00:38:33,550 --> 00:38:37,750
that reasonably represents the

1071
00:38:35,890 --> 00:38:40,569
Proofpoint model as it as it stands

1072
00:38:37,750 --> 00:38:42,280
inside of their network the 3a attack

1073
00:38:40,570 --> 00:38:44,050
would be to extract info from that model

1074
00:38:42,280 --> 00:38:45,910
manually so we like this attack

1075
00:38:44,050 --> 00:38:48,880
particularly for the use of writing

1076
00:38:45,910 --> 00:38:50,500
phishing emails as it means that we can

1077
00:38:48,880 --> 00:38:52,210
get actionable insights from the data

1078
00:38:50,500 --> 00:38:53,620
really quickly but we could do really

1079
00:38:52,210 --> 00:38:55,660
basic approaches like take the end

1080
00:38:53,620 --> 00:38:57,819
highest lowest emails and unique their

1081
00:38:55,660 --> 00:39:00,580
words or toggle inputs to discover the

1082
00:38:57,820 --> 00:39:01,990
most impactful tokens and something like

1083
00:39:00,580 --> 00:39:03,910
that would look like this where we take

1084
00:39:01,990 --> 00:39:06,069
emails in and we get back a scored data

1085
00:39:03,910 --> 00:39:08,040
set we pipe it into a skort copycat

1086
00:39:06,070 --> 00:39:10,630
classifier and extract those insights

1087
00:39:08,040 --> 00:39:11,860
attack B would be the same process for

1088
00:39:10,630 --> 00:39:13,840
one and two but we might make a

1089
00:39:11,860 --> 00:39:16,360
generator to effectively learn the

1090
00:39:13,840 --> 00:39:18,340
insights itself so we sect effectively

1091
00:39:16,360 --> 00:39:20,500
build a generator and we say target the

1092
00:39:18,340 --> 00:39:22,270
maximum score and play against this

1093
00:39:20,500 --> 00:39:24,070
classifier until you can generate

1094
00:39:22,270 --> 00:39:27,130
content that's reasonably able to bypass

1095
00:39:24,070 --> 00:39:28,360
you know proof point spam filter for

1096
00:39:27,130 --> 00:39:29,890
would be to automate those improvements

1097
00:39:28,360 --> 00:39:31,540
we could use the generator to fix our

1098
00:39:29,890 --> 00:39:33,759
candidates or to just generate good

1099
00:39:31,540 --> 00:39:36,610
content from scratch and that attack

1100
00:39:33,760 --> 00:39:38,110
looks like this so there's some clear

1101
00:39:36,610 --> 00:39:40,300
challenges here when me and will first

1102
00:39:38,110 --> 00:39:42,490
started talking about this first task is

1103
00:39:40,300 --> 00:39:44,320
we need some initial and email content

1104
00:39:42,490 --> 00:39:46,120
so we have to find a sufficient data set

1105
00:39:44,320 --> 00:39:47,890
for sending in inputs I don't

1106
00:39:46,120 --> 00:39:49,540
necessarily have 10,000 emails laying

1107
00:39:47,890 --> 00:39:51,220
around you could send in something like

1108
00:39:49,540 --> 00:39:53,500
Wikipedia articles but we want it to be

1109
00:39:51,220 --> 00:39:55,120
representative of the like email lexicon

1110
00:39:53,500 --> 00:39:57,340
we want it to be grammatically similar

1111
00:39:55,120 --> 00:39:59,980
to emails that we would type we have the

1112
00:39:57,340 --> 00:40:01,210
issue of bulk email delivery so we need

1113
00:39:59,980 --> 00:40:03,100
to send in these emails and collect

1114
00:40:01,210 --> 00:40:04,810
scores the scores themselves are applied

1115
00:40:03,100 --> 00:40:05,770
after they transit through proof points

1116
00:40:04,810 --> 00:40:07,180
so it's

1117
00:40:05,770 --> 00:40:08,380
if we have a proof point inbox because

1118
00:40:07,180 --> 00:40:10,000
we can simply send the emails to

1119
00:40:08,380 --> 00:40:12,700
ourselves it's much harder if we don't

1120
00:40:10,000 --> 00:40:14,350
and in terms of final outcomes if we do

1121
00:40:12,700 --> 00:40:16,390
the generator approach it will likely

1122
00:40:14,350 --> 00:40:18,160
create somewhat gibberish that's gonna

1123
00:40:16,390 --> 00:40:20,410
require human intervention to actually

1124
00:40:18,160 --> 00:40:22,180
make useful and bypassing this model is

1125
00:40:20,410 --> 00:40:23,859
obviously only one part of the total

1126
00:40:22,180 --> 00:40:26,730
defenses that we might need to get past

1127
00:40:23,860 --> 00:40:29,230
including like user action or sandbox

1128
00:40:26,730 --> 00:40:31,570
sandboxing of the payload or even link

1129
00:40:29,230 --> 00:40:34,240
rewriting so in terms of collecting a

1130
00:40:31,570 --> 00:40:36,190
dataset we chose effectively two data

1131
00:40:34,240 --> 00:40:37,270
sets to send in and we're going to refer

1132
00:40:36,190 --> 00:40:38,920
to these as like our text-based

1133
00:40:37,270 --> 00:40:40,870
candidates and our link based candidates

1134
00:40:38,920 --> 00:40:42,580
our text based candidates were from the

1135
00:40:40,870 --> 00:40:44,319
Enron data set and this is a really

1136
00:40:42,580 --> 00:40:47,170
common data set used for like spam ham

1137
00:40:44,320 --> 00:40:49,450
classification and our links are the is

1138
00:40:47,170 --> 00:40:51,340
CX URL data set which is pre classified

1139
00:40:49,450 --> 00:40:52,990
we just took a random sampling of these

1140
00:40:51,340 --> 00:40:54,130
links and sent them in because

1141
00:40:52,990 --> 00:40:55,990
ultimately we don't care about the fact

1142
00:40:54,130 --> 00:40:57,610
that their pre labeled we used bounce

1143
00:40:55,990 --> 00:40:58,959
backs to collect the scores so we

1144
00:40:57,610 --> 00:41:00,820
delivered the messages through mailgun

1145
00:40:58,960 --> 00:41:02,770
and received them into an s3 bucket and

1146
00:41:00,820 --> 00:41:05,350
in our collection runs effectively the

1147
00:41:02,770 --> 00:41:07,420
two primary ones are we sent in 13,000

1148
00:41:05,350 --> 00:41:09,520
links inside of a generic template and

1149
00:41:07,420 --> 00:41:13,000
we sent in 15,000 raw subjects and

1150
00:41:09,520 --> 00:41:14,830
bodies that cloned the enron inboxes so

1151
00:41:13,000 --> 00:41:18,160
the attack sort of lays out like this in

1152
00:41:14,830 --> 00:41:19,930
in in a technical sense we effectively

1153
00:41:18,160 --> 00:41:21,879
post an email candidate to mailgun which

1154
00:41:19,930 --> 00:41:23,680
delivers it to proof point per point

1155
00:41:21,880 --> 00:41:26,260
will score that candidate and add in

1156
00:41:23,680 --> 00:41:27,940
headers to the email then we're

1157
00:41:26,260 --> 00:41:29,950
effectively delivering the message to a

1158
00:41:27,940 --> 00:41:32,050
non-existent mailbox at a domain that

1159
00:41:29,950 --> 00:41:33,640
sits behind Proofpoint so by the time

1160
00:41:32,050 --> 00:41:35,410
the message hits the target mail server

1161
00:41:33,640 --> 00:41:37,990
it will effectively bounce back the

1162
00:41:35,410 --> 00:41:40,480
return path to our Amazon s3 bucket

1163
00:41:37,990 --> 00:41:43,029
where we we can extract the data and we

1164
00:41:40,480 --> 00:41:45,430
effectively have scored emails so after

1165
00:41:43,030 --> 00:41:46,900
we did this we open this up and actively

1166
00:41:45,430 --> 00:41:48,730
started looking at these scores to try

1167
00:41:46,900 --> 00:41:50,860
to make sense of them once again there's

1168
00:41:48,730 --> 00:41:52,120
13 scores that proof point in beds and

1169
00:41:50,860 --> 00:41:54,760
their headers and we weren't really sure

1170
00:41:52,120 --> 00:41:56,109
which ones were valuable to us we can

1171
00:41:54,760 --> 00:41:59,020
immediately see some of them stand out

1172
00:41:56,110 --> 00:42:00,760
like priority ml X log and Cl X and once

1173
00:41:59,020 --> 00:42:02,770
again we can see that those line up with

1174
00:42:00,760 --> 00:42:06,010
the datasheet terminology that we saw

1175
00:42:02,770 --> 00:42:07,540
prior we did some basic correlation on

1176
00:42:06,010 --> 00:42:09,820
these scores to try to discover a score

1177
00:42:07,540 --> 00:42:11,710
that speaks generally about the security

1178
00:42:09,820 --> 00:42:13,300
of an email so if we see a score that's

1179
00:42:11,710 --> 00:42:15,280
at least seeing some correlation with

1180
00:42:13,300 --> 00:42:16,690
other scores then it probably means that

1181
00:42:15,280 --> 00:42:19,000
as other scores are changing this score

1182
00:42:16,690 --> 00:42:21,520
is changing as well so it spans

1183
00:42:19,000 --> 00:42:23,680
you know some score set so to speak so

1184
00:42:21,520 --> 00:42:25,359
the ml x log stands out to us it has

1185
00:42:23,680 --> 00:42:27,399
relationships with spam fish and the

1186
00:42:25,359 --> 00:42:28,960
core ml X and we can also see their

1187
00:42:27,400 --> 00:42:31,300
generalized score has like a one to one

1188
00:42:28,960 --> 00:42:33,910
to their spam score and a one to one to

1189
00:42:31,300 --> 00:42:35,500
the ml X score so we took the ml X score

1190
00:42:33,910 --> 00:42:37,149
and we laid it out in a histogram but

1191
00:42:35,500 --> 00:42:40,270
check out distribution in terms of our

1192
00:42:37,150 --> 00:42:41,619
text based sampling it's definitely

1193
00:42:40,270 --> 00:42:43,329
leaning more towards the right

1194
00:42:41,619 --> 00:42:44,770
effectively we have a lot of candidates

1195
00:42:43,329 --> 00:42:46,690
that were scored 9 9 9

1196
00:42:44,770 --> 00:42:48,759
as far as we're aware is like a perfect

1197
00:42:46,690 --> 00:42:50,650
score but when we analyze our linked

1198
00:42:48,760 --> 00:42:52,180
targeted samples we see a much better

1199
00:42:50,650 --> 00:42:54,310
distribution so we can see that our

1200
00:42:52,180 --> 00:42:56,379
links are hovering around the 500 mark

1201
00:42:54,310 --> 00:42:58,480
we get a really nice curve out of it

1202
00:42:56,380 --> 00:43:00,369
another good thing is if we took these

1203
00:42:58,480 --> 00:43:02,020
raw animal X log scores and actually

1204
00:43:00,369 --> 00:43:04,119
line them up in an ordered fashion we

1205
00:43:02,020 --> 00:43:05,680
actually see the sigmoid curve that that

1206
00:43:04,119 --> 00:43:10,810
effectively proves that we're seeing

1207
00:43:05,680 --> 00:43:13,390
activation of these scores so obviously

1208
00:43:10,810 --> 00:43:15,730
the first step is to to copy a model so

1209
00:43:13,390 --> 00:43:18,549
just going out you can look what are

1210
00:43:15,730 --> 00:43:23,050
some likely candidates for how do people

1211
00:43:18,550 --> 00:43:24,250
do spam ham classification and we went

1212
00:43:23,050 --> 00:43:25,780
out and we just built these models in

1213
00:43:24,250 --> 00:43:28,510
care so we built an LS TM and then we

1214
00:43:25,780 --> 00:43:30,430
built a regular neural network just like

1215
00:43:28,510 --> 00:43:33,640
the one you saw earlier at the sandbox

1216
00:43:30,430 --> 00:43:35,589
so it's not any different and then we

1217
00:43:33,640 --> 00:43:37,210
just selected the label for the ml x log

1218
00:43:35,589 --> 00:43:40,900
score we just felt that that was the

1219
00:43:37,210 --> 00:43:44,920
most general and our data kind of

1220
00:43:40,900 --> 00:43:47,380
supported it and we found that January

1221
00:43:44,920 --> 00:43:49,089
values were between 1 and 99 that wasn't

1222
00:43:47,380 --> 00:43:51,490
true so it seems like in their data so

1223
00:43:49,089 --> 00:43:54,339
there's some like hard-coded values like

1224
00:43:51,490 --> 00:43:56,859
10 15 is for outbound emails is what you

1225
00:43:54,339 --> 00:43:58,900
almost always see and we came to the

1226
00:43:56,859 --> 00:44:00,609
fact that larger equals safer so

1227
00:43:58,900 --> 00:44:02,589
traditionally you would say in on the

1228
00:44:00,609 --> 00:44:05,680
flip side you know lower is usually

1229
00:44:02,589 --> 00:44:07,869
safer but it really doesn't matter it

1230
00:44:05,680 --> 00:44:10,029
says about the activation and so we did

1231
00:44:07,869 --> 00:44:12,069
is we created those those models and

1232
00:44:10,030 --> 00:44:14,770
then we just trained them on on proof

1233
00:44:12,069 --> 00:44:16,869
points output so we we created we

1234
00:44:14,770 --> 00:44:18,880
vectorize our inputs and then we just

1235
00:44:16,869 --> 00:44:21,970
use it that great regression to target

1236
00:44:18,880 --> 00:44:23,500
their output score so our model is

1237
00:44:21,970 --> 00:44:26,348
effectively we just want to get as close

1238
00:44:23,500 --> 00:44:27,310
as possible to to their output so it

1239
00:44:26,349 --> 00:44:29,500
doesn't matter what it is whether it's a

1240
00:44:27,310 --> 00:44:30,819
Wikipedia article or an email we just

1241
00:44:29,500 --> 00:44:32,440
want to make sure that our

1242
00:44:30,819 --> 00:44:33,970
classification is close

1243
00:44:32,440 --> 00:44:36,819
- there's whether it's correct or not

1244
00:44:33,970 --> 00:44:40,629
and so these are kind of the results

1245
00:44:36,819 --> 00:44:44,050
that we got and these are points so on a

1246
00:44:40,630 --> 00:44:50,530
scale of you know 0 to 99 if for example

1247
00:44:44,050 --> 00:44:52,420
our we predicted a 400 or we would be or

1248
00:44:50,530 --> 00:44:55,480
if proof points are I predict predicted

1249
00:44:52,420 --> 00:44:58,630
to 400 we'd be within 42 points of their

1250
00:44:55,480 --> 00:45:01,750
score and so and this was consistent

1251
00:44:58,630 --> 00:45:03,730
across all but obviously we see the

1252
00:45:01,750 --> 00:45:05,290
neural network I kind of thought the

1253
00:45:03,730 --> 00:45:07,750
lsdm would do better just based on

1254
00:45:05,290 --> 00:45:09,160
sequences but the neural network with

1255
00:45:07,750 --> 00:45:09,880
the bag of words was just it was

1256
00:45:09,160 --> 00:45:13,480
incredible

1257
00:45:09,880 --> 00:45:17,260
and even 42 like we're within 42 points

1258
00:45:13,480 --> 00:45:19,750
of this spam filters on every uh

1259
00:45:17,260 --> 00:45:21,970
Navarrete so it's a mean it's a mean

1260
00:45:19,750 --> 00:45:24,130
absolute error so on average we're we're

1261
00:45:21,970 --> 00:45:26,680
42 points away from their predicted

1262
00:45:24,130 --> 00:45:28,150
scores for links and then 69 points away

1263
00:45:26,680 --> 00:45:30,490
so it effectively means we just have

1264
00:45:28,150 --> 00:45:35,140
their model pegged at least to it to a

1265
00:45:30,490 --> 00:45:37,209
certain extent so attack these two to

1266
00:45:35,140 --> 00:45:38,740
kind of gain insights into our model so

1267
00:45:37,210 --> 00:45:41,050
now we've confirmed that our model is

1268
00:45:38,740 --> 00:45:43,810
good and we we have a decent offline

1269
00:45:41,050 --> 00:45:45,730
copy we can start to play with emails

1270
00:45:43,810 --> 00:45:50,410
and we can start to build attacks that

1271
00:45:45,730 --> 00:45:51,520
will bypass their filter and so for

1272
00:45:50,410 --> 00:45:52,540
example we could take a phishing email

1273
00:45:51,520 --> 00:45:55,140
click here for cats

1274
00:45:52,540 --> 00:45:58,150
we could make misspellings we could

1275
00:45:55,140 --> 00:45:59,890
remove words we could you know anything

1276
00:45:58,150 --> 00:46:01,359
we can do to change that score and then

1277
00:45:59,890 --> 00:46:04,990
we can just submit it to our copycat

1278
00:46:01,359 --> 00:46:06,549
model and then get some reasonable we

1279
00:46:04,990 --> 00:46:09,399
chose the toggle input so we basically

1280
00:46:06,550 --> 00:46:12,040
just took we just toggled those values

1281
00:46:09,400 --> 00:46:13,630
on and off so we could find and then we

1282
00:46:12,040 --> 00:46:15,279
scored every or we could score every

1283
00:46:13,630 --> 00:46:16,599
possible combination of tokens it's a

1284
00:46:15,280 --> 00:46:18,849
bit like fuzzing a network so you just

1285
00:46:16,599 --> 00:46:20,619
take all your words and then just turn

1286
00:46:18,849 --> 00:46:22,770
them all off so until you get everything

1287
00:46:20,619 --> 00:46:24,819
it's pretty computationally expensive

1288
00:46:22,770 --> 00:46:27,069
but effectively to extract information

1289
00:46:24,819 --> 00:46:29,890
to get sort of like good words or bad

1290
00:46:27,069 --> 00:46:31,240
words out we make a base prediction and

1291
00:46:29,890 --> 00:46:33,520
then we just go through and alter those

1292
00:46:31,240 --> 00:46:35,560
and make it alter the tokens and then we

1293
00:46:33,520 --> 00:46:38,619
make a new prediction and we just added

1294
00:46:35,560 --> 00:46:40,990
to a rolling list until we got just a

1295
00:46:38,619 --> 00:46:43,060
list of words that we were able to pull

1296
00:46:40,990 --> 00:46:45,509
out of the model so these are the good

1297
00:46:43,060 --> 00:46:48,240
words so these are the top 10 words

1298
00:46:45,510 --> 00:46:50,190
that proof points model think are good

1299
00:46:48,240 --> 00:46:53,089
so if you add these top ten words to

1300
00:46:50,190 --> 00:46:55,590
your email you get nine nine nine nine

1301
00:46:53,090 --> 00:46:57,180
these are the med they're kind of in the

1302
00:46:55,590 --> 00:46:59,970
middle and then these are the bad ones

1303
00:46:57,180 --> 00:47:01,440
so well there's a slide in a second now

1304
00:46:59,970 --> 00:47:03,750
I'm so this is for text so this is just

1305
00:47:01,440 --> 00:47:06,990
for emails and then these are the ones

1306
00:47:03,750 --> 00:47:09,980
for links and so these if you have these

1307
00:47:06,990 --> 00:47:12,450
words in your links you get top scores

1308
00:47:09,980 --> 00:47:14,400
so if we look at confirming the insights

1309
00:47:12,450 --> 00:47:17,160
for our texts so the top ten highest

1310
00:47:14,400 --> 00:47:19,620
scoring words got triple nine the random

1311
00:47:17,160 --> 00:47:21,810
ten words in the middle got about 640 so

1312
00:47:19,620 --> 00:47:23,370
ideally we'd be trying to hit 500 or

1313
00:47:21,810 --> 00:47:26,100
ninety nine divided by two so whatever

1314
00:47:23,370 --> 00:47:28,170
that midpoint is but the top ten lowest

1315
00:47:26,100 --> 00:47:30,990
scoring words it didn't even accept it

1316
00:47:28,170 --> 00:47:33,180
so it said this looks too much like spam

1317
00:47:30,990 --> 00:47:35,189
we're not going to accept your email so

1318
00:47:33,180 --> 00:47:38,609
for us that was like yeah we know it's

1319
00:47:35,190 --> 00:47:40,470
spam because you told us it was and then

1320
00:47:38,610 --> 00:47:44,280
for the links it's the same thing so our

1321
00:47:40,470 --> 00:47:45,779
prediction 378 the real is 300 and these

1322
00:47:44,280 --> 00:47:48,050
are just coming from all the good words

1323
00:47:45,780 --> 00:47:50,880
in the and the bad words

1324
00:47:48,050 --> 00:47:52,890
so we effectively just stole proof

1325
00:47:50,880 --> 00:47:54,810
points model that we have offline that

1326
00:47:52,890 --> 00:47:57,330
we can just do whatever we want with now

1327
00:47:54,810 --> 00:48:01,020
and we can play with emails we can

1328
00:47:57,330 --> 00:48:03,420
bypass our filter and you know we have a

1329
00:48:01,020 --> 00:48:04,830
list of good and bad words that we can

1330
00:48:03,420 --> 00:48:07,710
just add so you could potentially add

1331
00:48:04,830 --> 00:48:11,390
these to an email make the text white

1332
00:48:07,710 --> 00:48:14,160
and there you serve your phishing email

1333
00:48:11,390 --> 00:48:16,770
it's this one type but so in terms of

1334
00:48:14,160 --> 00:48:21,149
disclosure we haven't told proof point

1335
00:48:16,770 --> 00:48:23,280
this we we just know now but it's like

1336
00:48:21,150 --> 00:48:25,710
it's different so models are interesting

1337
00:48:23,280 --> 00:48:28,860
they represent a learned vector it's not

1338
00:48:25,710 --> 00:48:32,100
like a Lal bin or a next way that you

1339
00:48:28,860 --> 00:48:34,230
can just patch they're trained so it's

1340
00:48:32,100 --> 00:48:37,200
like I don't know what proof points

1341
00:48:34,230 --> 00:48:38,880
process is to retrain their model on

1342
00:48:37,200 --> 00:48:41,819
their data set that they have that we

1343
00:48:38,880 --> 00:48:43,290
effectively stole so that the retraining

1344
00:48:41,820 --> 00:48:46,080
process is just going to be very

1345
00:48:43,290 --> 00:48:48,660
difficult they can obviously stop

1346
00:48:46,080 --> 00:48:52,230
leaking outputs that would be probably a

1347
00:48:48,660 --> 00:48:54,210
good first step but it's our models

1348
00:48:52,230 --> 00:48:55,950
going to degrade over time so as they

1349
00:48:54,210 --> 00:48:58,210
retrain their models daily or whatever

1350
00:48:55,950 --> 00:49:01,000
their processes like we have some window

1351
00:48:58,210 --> 00:49:03,910
to use this model but as long as they

1352
00:49:01,000 --> 00:49:06,490
keep their their outputs available to us

1353
00:49:03,910 --> 00:49:09,009
okay so then you know what percentage

1354
00:49:06,490 --> 00:49:11,109
considered a viable bypass so what point

1355
00:49:09,010 --> 00:49:12,339
we're like yeah we can bypass 50% of

1356
00:49:11,109 --> 00:49:15,430
time we're going to tell you about it

1357
00:49:12,339 --> 00:49:18,400
it's not like we can exploit RDP I'm you

1358
00:49:15,430 --> 00:49:21,910
can't just can't add a signature so some

1359
00:49:18,400 --> 00:49:23,589
final thoughts uh yeah so just to put

1360
00:49:21,910 --> 00:49:24,129
this in context obviously application

1361
00:49:23,589 --> 00:49:26,109
whitelisting

1362
00:49:24,130 --> 00:49:28,240
you know got popular two or three years

1363
00:49:26,109 --> 00:49:30,250
ago and it effectively was just a vendor

1364
00:49:28,240 --> 00:49:31,629
pitch as long as it got sales like I see

1365
00:49:30,250 --> 00:49:32,980
vendors in blackhat now that used to

1366
00:49:31,630 --> 00:49:34,210
have a polite listing on their vendor

1367
00:49:32,980 --> 00:49:36,220
board now they don't and now they're

1368
00:49:34,210 --> 00:49:37,930
touting ml it's the same vendor so I'm

1369
00:49:36,220 --> 00:49:40,750
wondering what exactly their product

1370
00:49:37,930 --> 00:49:43,149
does do and another thing we'll enjoyed

1371
00:49:40,750 --> 00:49:44,650
was endgame put out a competition to you

1372
00:49:43,150 --> 00:49:47,470
know give a GPU to anybody who could

1373
00:49:44,650 --> 00:49:49,540
bypass some static sample analysis and

1374
00:49:47,470 --> 00:49:50,980
the winner just added emojis to all of

1375
00:49:49,540 --> 00:49:53,290
the samples like in the headers of the

1376
00:49:50,980 --> 00:49:54,760
file and and bypassed it so these data

1377
00:49:53,290 --> 00:49:56,770
scientists are solving defensive

1378
00:49:54,760 --> 00:49:58,780
problems and they might not necessarily

1379
00:49:56,770 --> 00:50:01,270
have the domain knowledge to accurately

1380
00:49:58,780 --> 00:50:03,160
you know create so secure and robust

1381
00:50:01,270 --> 00:50:04,869
models and will statement is if you

1382
00:50:03,160 --> 00:50:06,339
don't understand X before ml you

1383
00:50:04,869 --> 00:50:10,450
probably won't stand it or won't

1384
00:50:06,339 --> 00:50:13,900
understand it after but it's not all bad

1385
00:50:10,450 --> 00:50:15,368
so we can obviously use this so I'm in

1386
00:50:13,900 --> 00:50:17,170
the future I'm thinking of intelligent

1387
00:50:15,369 --> 00:50:19,750
agents so you're pushing models

1388
00:50:17,170 --> 00:50:21,280
client-side so for example because the

1389
00:50:19,750 --> 00:50:22,810
model is just weights of math you could

1390
00:50:21,280 --> 00:50:25,750
write all your weights to excel sheet

1391
00:50:22,810 --> 00:50:27,359
and your model goes with your payload so

1392
00:50:25,750 --> 00:50:29,710
you no longer have to make a web request

1393
00:50:27,359 --> 00:50:31,779
Genetic Programming client-side so you

1394
00:50:29,710 --> 00:50:35,080
could come up with new strains of

1395
00:50:31,780 --> 00:50:36,670
malware client-side using jet you know

1396
00:50:35,080 --> 00:50:40,299
rootkit so we're just going to go lower

1397
00:50:36,670 --> 00:50:41,680
into the OS but effectively we do want

1398
00:50:40,300 --> 00:50:43,150
to help vendors improve their products

1399
00:50:41,680 --> 00:50:46,569
and make sure that this isn't just the

1400
00:50:43,150 --> 00:50:48,250
next issue that we're gonna see you know

1401
00:50:46,570 --> 00:50:49,270
application wise think it was cool until

1402
00:50:48,250 --> 00:50:52,390
everybody realized there's a ton of

1403
00:50:49,270 --> 00:50:53,770
stuff they could execute things um so

1404
00:50:52,390 --> 00:50:55,509
these are some other fun projects so

1405
00:50:53,770 --> 00:50:58,150
what other defenses leaked outputs

1406
00:50:55,510 --> 00:50:59,950
Windows Defender email attachments my

1407
00:50:58,150 --> 00:51:02,980
dream is to have like an email chat bot

1408
00:50:59,950 --> 00:51:05,109
or a LinkedIn chat bot that gets you to

1409
00:51:02,980 --> 00:51:06,520
level feed you a document so it's going

1410
00:51:05,109 --> 00:51:07,630
to warm you up as a chat bot and then

1411
00:51:06,520 --> 00:51:10,480
it's going to send you a document at

1412
00:51:07,630 --> 00:51:11,830
some point or you can just add data

1413
00:51:10,480 --> 00:51:15,580
extraction to ten year

1414
00:51:11,830 --> 00:51:17,950
J ultimately it's a ton of fun like just

1415
00:51:15,580 --> 00:51:19,710
pressing enter and watching your model

1416
00:51:17,950 --> 00:51:22,450
train and see how it does every time

1417
00:51:19,710 --> 00:51:23,950
machine learnings here to stay so don't

1418
00:51:22,450 --> 00:51:25,810
sleep on it if you're on the red side

1419
00:51:23,950 --> 00:51:28,509
it's all funny until you know it's all

1420
00:51:25,810 --> 00:51:32,560
if rebranded if statements until you get

1421
00:51:28,510 --> 00:51:34,240
caught by it and you don't know why all

1422
00:51:32,560 --> 00:51:35,650
the bypasses are going to become part of

1423
00:51:34,240 --> 00:51:38,649
all offensive toolkits they're already

1424
00:51:35,650 --> 00:51:41,050
part of ours and m/l understand could

1425
00:51:38,650 --> 00:51:42,760
just be quickly become a job requirement

1426
00:51:41,050 --> 00:51:44,320
especially if you're gonna operate into

1427
00:51:42,760 --> 00:51:45,640
the future let's say you know three to

1428
00:51:44,320 --> 00:51:50,290
five years from now it could very

1429
00:51:45,640 --> 00:51:52,120
quickly become very useful so I I'm like

1430
00:51:50,290 --> 00:51:53,590
a little speaker box at the office

1431
00:51:52,120 --> 00:51:56,109
everyone's sick of me saying talking

1432
00:51:53,590 --> 00:51:58,240
about ml but it might be nothing and it

1433
00:51:56,110 --> 00:51:59,530
could be everything it's likely gonna be

1434
00:51:58,240 --> 00:52:01,450
somewhere in the middle but only time

1435
00:51:59,530 --> 00:52:03,640
will tell like it's here to stay it's

1436
00:52:01,450 --> 00:52:06,879
going to mature so it's it's worth your

1437
00:52:03,640 --> 00:52:09,819
time to invest in it so you won't say

1438
00:52:06,880 --> 00:52:11,680
some thanks to some people and we are

1439
00:52:09,820 --> 00:52:15,940
out of time so you can come find us

1440
00:52:11,680 --> 00:52:17,020
after code will be up at the end and as

1441
00:52:15,940 --> 00:52:19,180
we do I would do want to thank Nancy

1442
00:52:17,020 --> 00:52:21,490
folder BYU for providing guidance and

1443
00:52:19,180 --> 00:52:23,399
all of you for obviously attending this

1444
00:52:21,490 --> 00:52:28,658
talk thank you

1445
00:52:23,400 --> 00:52:28,659
[Applause]

