1
00:00:14,800 --> 00:00:15,920
is

2
00:00:55,680 --> 00:00:57,840
behind you

3
00:01:25,680 --> 00:01:39,840
is

4
00:02:08,320 --> 00:02:13,840
so hello eva hi there how's everything 
going over there in san francisco  

5
00:02:15,040 --> 00:02:17,519
it is six o'clock in the morning and it is dark

6
00:02:21,200 --> 00:02:24,560
we're going to have to work on the 
time zone as well it's 8 a.m here so  

7
00:02:26,320 --> 00:02:31,120
well well first of all let me start by 
introducing you in spanish for everyone else  

8
00:02:31,680 --> 00:02:37,360
let me tell you something i got a molar removed 
yesterday and i was afraid i couldn't be here  

9
00:02:37,360 --> 00:02:42,720
but i'm such a big fan of your work especially 
with the stalker where what you did over there  

10
00:02:42,720 --> 00:02:48,880
and all the malware research you've done so 
let me quickly read this bo in spanish so

11
00:03:15,920 --> 00:03:17,839
is

12
00:03:57,120 --> 00:04:00,080
so without further ado i'm just gonna let you talk  

13
00:04:00,080 --> 00:04:03,520
to eva and i'm sure everyone's 
gonna enjoy her presentation

14
00:04:08,480 --> 00:04:19,279
thank you so much for having me um all 
right ah there now uh so it is uh 6 23 a.m  

15
00:04:19,279 --> 00:04:28,479
in the city of san francisco uh and i am generally 
not awake at this hour unless uh i am still up  

16
00:04:29,680 --> 00:04:36,160
so please bear with me it is possible that the sun 
may come up over the course of this presentation  

17
00:04:36,160 --> 00:04:43,280
which will have some effect on the lighting but 
in the meantime welcome to my spooky living room  

18
00:04:44,080 --> 00:04:52,080
uh so normally around this time i would start by 
asking people how many of you have heard of the  

19
00:04:52,080 --> 00:04:59,599
electronic frontier foundation but we are giving 
all of our talks remotely now and uh it is a it is  

20
00:04:59,600 --> 00:05:05,200
a different time there is plague uh and i have no 
idea how many of you have heard of the electronic  

21
00:05:05,200 --> 00:05:10,800
frontier foundation so in order to make this a 
little bit faster uh i will explain who we are and  

22
00:05:10,800 --> 00:05:17,520
what we do uh i am the director of cyber security 
at the electronic frontier foundation and i run a  

23
00:05:17,520 --> 00:05:28,799
sort of a subset of people inside of eff called uh 
the threat lab and uh what eff does is uh we are  

24
00:05:29,600 --> 00:05:37,360
the leading digital civil liberties organization 
in the world uh we are worldwide uh we have uh  

25
00:05:37,360 --> 00:05:45,520
more than 14 000 members all over the world uh 
who send us money in exchange for uh stickers  

26
00:05:45,520 --> 00:05:52,320
and t-shirts and uh it we we turn all of those 
stickers and t-shirts into digital civil liberties

27
00:05:54,400 --> 00:06:02,880
we have sort of three classes of tool that 
we use in order to deal with uh with civil  

28
00:06:02,880 --> 00:06:10,000
liberties problems because uh the internet 
is global it has global problems and it if  

29
00:06:10,000 --> 00:06:16,800
you have only one tool in your toolbox uh you 
are going to be a very limited sort of engineer  

30
00:06:17,600 --> 00:06:28,400
so uh we have a legal team uh eff started 
out primarily as a as a legal organization  

31
00:06:28,400 --> 00:06:36,000
in the united states in 1990 which 
means that we just turned 30 years old  

32
00:06:36,800 --> 00:06:41,680
eff is a millennial uh it eats a lot of 
avocado toast and cannot afford a house

33
00:06:44,080 --> 00:06:49,599
so we have been doing we have been doing law 
for 30 years i have not been doing law for  

34
00:06:49,600 --> 00:06:52,640
any of that time and have definitely 
not been doing anything for 30 years  

35
00:06:53,840 --> 00:07:03,440
but eff was involved in many of the very early 
cases in the united states having to do with uh  

36
00:07:04,160 --> 00:07:11,280
your with your data and with your increasingly 
digital lives one of the things that's really  

37
00:07:11,280 --> 00:07:19,520
changed in the last 30 years is um that 
our work used to be considered a sort of  

38
00:07:20,080 --> 00:07:28,080
niche this was a thing for nerds uh and uh the 
big change that we've seen in the last 30 years is  

39
00:07:28,080 --> 00:07:35,599
that every single one of our issues is now at the 
center of people's lives uh because your digital  

40
00:07:35,600 --> 00:07:42,160
life and your real life are not different anymore 
and pretending that they are is a waste of time  

41
00:07:42,720 --> 00:07:50,480
so things that our legal team has done in the past 
that are kind of important um our legal team won a  

42
00:07:50,480 --> 00:07:58,480
case in the united states that got the ruling that 
uh your email deserves the same fourth amendment  

43
00:07:58,480 --> 00:08:05,680
constitutional protections as your physical mail 
in your mailbox uh later the third party doctrine  

44
00:08:05,680 --> 00:08:11,920
came along and essentially eviscerated this 
because we do not own uh our own mail servers  

45
00:08:11,920 --> 00:08:19,360
we tend to use uh mail servers and mail services 
used by someone else and then the fourth amendment  

46
00:08:19,360 --> 00:08:26,240
right is uh is theirs so as we all know there is 
no cloud there is only somebody else's computer  

47
00:08:27,280 --> 00:08:36,959
uh eff also sued uh both of verizon oh sorry not 
verizon we sued at t and also the us government  

48
00:08:37,919 --> 00:08:49,439
back in 2006 over its warrantless wiretapping 
program so the nsa set up secret rooms in

49
00:08:51,840 --> 00:09:01,120
intel intelcos all over the united states copied 
everybody's data and used it in order to uh to  

50
00:09:01,120 --> 00:09:08,320
spy on their communications whether they were 
americans or not now i am of the opinion that  

51
00:09:08,320 --> 00:09:15,920
uh i take a sort of human rights-based approach 
to uh to internet freedom which is to say that  

52
00:09:15,920 --> 00:09:22,160
every single person on earth deserves privacy 
and they deserve a certain amount of security  

53
00:09:22,160 --> 00:09:32,719
and and free speech um the nsa does not agree with 
me and their mandate is essentially uh that they  

54
00:09:32,720 --> 00:09:40,000
may spy on anyone outside of the united states 
but that americans are a special class of people  

55
00:09:40,000 --> 00:09:46,640
and if they want to do domestic spying uh it is in 
fact much harder and so we spent a bunch of time  

56
00:09:46,640 --> 00:09:52,960
uh and a series of lawsuits working on 
proving that this is unconstitutional  

57
00:09:54,240 --> 00:10:00,960
most of this program has been eviscerated but we 
don't know what kind of programs have replaced  

58
00:10:00,960 --> 00:10:14,000
it so that's pretty disturbing um there was uh in 
2013 a leak by some guy named edward snowden who  

59
00:10:14,000 --> 00:10:21,200
released a bunch of documents having to do with 
uh with this case in fact it was the very first  

60
00:10:21,200 --> 00:10:30,160
document that snowden leaked was a document from 
verizon having to do with their deal with the nsa  

61
00:10:31,520 --> 00:10:39,199
and uh we filed a lawsuit based on that 
against the u.s government uh so that's  

62
00:10:39,200 --> 00:10:45,840
you know that's 2013. uh we've had seven long 
years in which to file lawsuits since then  

63
00:10:46,960 --> 00:10:54,480
which is fortunate because uh lawsuits take a 
long time we had uh one copyright case which we  

64
00:10:54,480 --> 00:11:03,440
nicknamed the dancing baby case uh or 
lens versus universal that lasted i think  

65
00:11:05,280 --> 00:11:14,720
seven or eight years and the baby who whose 
video was at the center of this case uh was in uh  

66
00:11:15,520 --> 00:11:20,960
it's already quite tall and and quite 
old by the time the this case finished up  

67
00:11:22,160 --> 00:11:29,199
so these are the the sorts of things that we do 
uh we do impact litigation in the united states  

68
00:11:29,760 --> 00:11:36,960
uh because that is where we have our entire floor 
of vicious attack lawyers you may notice that  

69
00:11:37,520 --> 00:11:43,360
the united states is not the internet and the u.s 
law is not the law all over the world and in fact  

70
00:11:43,360 --> 00:11:53,680
it shouldn't be so even though u.s companies 
have a kind of oversized impact on uh on how  

71
00:11:53,680 --> 00:11:58,239
the internet works because frequently 
american companies control the platforms  

72
00:11:59,920 --> 00:12:07,040
the internet is global and countries do have 
to take local laws into account and for that  

73
00:12:07,040 --> 00:12:11,760
purpose we have an international team we have 
people who are located all over the world  

74
00:12:12,720 --> 00:12:18,960
including a couple of people on our team who 
are focused just on issues in in latin america  

75
00:12:18,960 --> 00:12:25,760
and who publish on our issues in spanish 
for for those of you who are playing along  

76
00:12:26,400 --> 00:12:36,240
um so we have an international team we have a 
a team of activists because sometimes the thing  

77
00:12:36,960 --> 00:12:42,720
the way that you solve the internet's problems is 
not to file a lawsuit somewhere in a united states  

78
00:12:42,720 --> 00:12:55,200
court but to get people out in the streets to have 
people protest to have people uh sign petitions  

79
00:12:55,200 --> 00:13:02,640
uh to have them write to the ftc so there's all 
kinds of stuff that uh that our activists do and  

80
00:13:02,640 --> 00:13:10,240
our activists are particularly good at explaining 
technology to ordinary people and also explaining  

81
00:13:10,240 --> 00:13:17,920
the law to engineers which incidentally turns 
out to be its own sort of problem in the same  

82
00:13:17,920 --> 00:13:28,640
way that i have never met a worse security trainer 
than professional infosec people i have rarely met  

83
00:13:30,080 --> 00:13:35,120
worse lawyers than engineers because for some 
strange reason we keep believing you can hack  

84
00:13:35,120 --> 00:13:41,680
the law we're like well there's this loophole in 
the uh in the language right here and this means  

85
00:13:41,680 --> 00:13:46,079
that i can do whatever i want and the truth is 
that when you end up in front of a judge and you  

86
00:13:46,080 --> 00:13:53,360
make this kind of argument the judge is not amused 
you do not get points for being funny so uh our  

87
00:13:53,360 --> 00:13:59,360
activism team has done all kinds of amazing things 
over the years and uh my personal favorite is  

88
00:13:59,360 --> 00:14:10,240
the time that we uh borrowed a uh blimp from 
greenpeace and we flew it over the uh data center  

89
00:14:10,240 --> 00:14:15,840
in utah that the nsa has uh you know where they 
store all the information that they that they  

90
00:14:15,840 --> 00:14:24,240
get from spying on people i and the nsa did not 
enjoy uh our our surveillance not even slightly

91
00:14:26,720 --> 00:14:31,760
so we have activists our activists are amazing 
and finally we have engineers because sometimes  

92
00:14:31,760 --> 00:14:36,960
you can solve the problem by building a 
tool not always in fact most of the time no  

93
00:14:38,080 --> 00:14:42,640
most of the time when people look at a problem and 
they say we should build an app for that they're  

94
00:14:42,640 --> 00:14:47,520
wrong but every once in a while the answer really 
is there should be an app for that there should be  

95
00:14:47,520 --> 00:14:56,560
a chrome extension for that there should be a uh a 
working group for that and for this reason we have  

96
00:14:56,560 --> 00:15:03,680
our our team of engineers and our engineers 
work on a couple of really important projects  

97
00:15:03,680 --> 00:15:09,040
uh again this is where i would look around 
and i would ask people you know who uh who  

98
00:15:09,040 --> 00:15:17,839
knows about certbot uh cert bot is a uh is a eff 
project which we launched in order to make sure  

99
00:15:17,840 --> 00:15:24,480
that uh you could install ssl certificates on uh 
on your website and therefore encrypt your traffic  

100
00:15:24,480 --> 00:15:33,200
in um in motion and uh and you can do it in just a 
few clicks and you can do it for free because one  

101
00:15:33,200 --> 00:15:40,080
of the big complaints that we had about people 
uh use moving over uh their websites to https  

102
00:15:40,080 --> 00:15:45,760
was uh it costs money and it's not easy 
enough so we said fine we'll fix that  

103
00:15:47,280 --> 00:15:52,880
eff also makes a tool called privacy 
badger which is a browser extension which  

104
00:15:54,000 --> 00:15:58,160
eats cookies tracking cookies because 
we think tracking cookies are bad  

105
00:15:58,800 --> 00:16:06,000
we also work with our activists to publish 
a uh to publish a guide called surveillance  

106
00:16:06,000 --> 00:16:13,520
self-defense which you can get to 
at ssd.eff.org and also a guide for  

107
00:16:14,800 --> 00:16:18,800
people who are in from in information security 
and who want to do trainings in their community  

108
00:16:19,840 --> 00:16:28,480
and this is called the security education 
companion and it is located at sec dot e-f-f-o-r-g  

109
00:16:29,040 --> 00:16:32,480
and it's translated into a number of 
languages and i think this includes spanish  

110
00:16:33,200 --> 00:16:41,440
so uh we have all of these projects and inside 
of my of the group of engineers who build web  

111
00:16:41,440 --> 00:16:48,400
extensions and explain technology to lawyers 
and uh continuously tell governments that uh  

112
00:16:48,400 --> 00:16:56,959
backdooring and encryption is a terrible idea 
uh we uh we have a subgroup and that subgroup is  

113
00:16:56,960 --> 00:17:03,440
called threat lab and this is the subgroup that i 
am in charge of they have i've gone mad with power  

114
00:17:04,000 --> 00:17:08,880
it is really common for people to believe that 
because i'm the director of cyber security that i  

115
00:17:08,880 --> 00:17:17,599
somehow run all of eff this is absolutely not true 
i have a tiny team and we do a very very small  

116
00:17:17,599 --> 00:17:24,560
and specific thing which is that we spend our time 
thinking about the needs of vulnerable populations  

117
00:17:26,319 --> 00:17:35,280
very often when we talk about internet security we 
don't ask security for whom who deserves security  

118
00:17:35,280 --> 00:17:43,520
who deserves privacy who is being put at the at 
the center of this discourse and who is left out  

119
00:17:43,520 --> 00:17:50,800
in the margins and as it happens uh in information 
security uh you go to private conferences and you  

120
00:17:50,800 --> 00:17:58,000
get out on the floor and uh you go to all of the 
booths and they're all selling products uh most  

121
00:17:58,000 --> 00:18:06,240
of those products are are enterprise based the 
idea is that the people who deserve security are  

122
00:18:06,240 --> 00:18:15,520
companies or governments governments deserve 
security but uh uh only deserve security  

123
00:18:15,520 --> 00:18:24,080
if they can pay for it uh which really leaves out 
a whole lot of of the population of the world uh  

124
00:18:24,080 --> 00:18:32,240
and this is extremely worrisome so the people who 
usually get left out uh are everybody who is not  

125
00:18:32,240 --> 00:18:37,360
uh who is not rich and everybody who's not a 
government uh everybody who is not your sort of  

126
00:18:38,960 --> 00:18:46,560
default white man living in santa clara 
california and that's a lot of people  

127
00:18:46,560 --> 00:18:52,720
so i spent a lot of time thinking about what the 
internet looks like uh if you live in the global  

128
00:18:52,720 --> 00:19:01,520
south or if you share your devices in a way that a 
lot of uh a lot of people do uh outside of of the  

129
00:19:01,520 --> 00:19:06,560
uh united states i spend a lot of time thinking 
about what the internet looks like if you are an  

130
00:19:06,560 --> 00:19:15,919
activist or a journalist or anyone who regularly 
angers governments because let me tell you in  

131
00:19:15,920 --> 00:19:20,240
order to be a good activist or journalist chances 
are you're going to piss off the people in power  

132
00:19:20,960 --> 00:19:27,680
and i work to protect the people who piss off 
the people in power because i think that the  

133
00:19:27,680 --> 00:19:32,320
people in power already have enough power thank 
you very much they already have security teams  

134
00:19:32,320 --> 00:19:36,080
so uh we are the security team for the 
people who cannot afford security teams  

135
00:19:37,440 --> 00:19:43,600
and to this end uh there are a bunch of things 
that we do uh one of them is malware analysis  

136
00:19:44,160 --> 00:19:49,040
uh so over the years uh we 
have put out a bunch of reports  

137
00:19:49,040 --> 00:19:57,360
on uh on apts that were targeting civil 
society journalists activists lawyers  

138
00:19:58,880 --> 00:20:09,520
usually people who have angered authoritarian 
governments like kazakhstan um or uh vietnam and  

139
00:20:09,520 --> 00:20:16,400
uh we have we have published reports about this 
also lebanon um so we did this this sort of apt  

140
00:20:16,400 --> 00:20:21,360
work uh apt work is really interesting 
it's actually my favorite thing to do

141
00:20:23,440 --> 00:20:29,520
over the course of working on apts the person 
with whom i was doing most of my research  

142
00:20:30,400 --> 00:20:40,240
who was not an employee of the electronic frontier 
foundation uh was outed as a serial rapist it  

143
00:20:40,240 --> 00:20:48,240
turned out he had been running around for two 
decades raping women and uh i read an interview  

144
00:20:48,240 --> 00:20:54,320
with one of the survivors of his abuse and one 
of the things that really struck me in that  

145
00:20:54,320 --> 00:21:03,120
interview the thing that broke my heart was how 
scared she was she was absolutely terrified of uh  

146
00:21:03,840 --> 00:21:11,439
of this guy uh breaking into her computer 
or breaking into her phone i everyone who  

147
00:21:12,080 --> 00:21:18,240
spoke to the journalist for the story had a 
a sticker over their camera uh everybody was  

148
00:21:18,240 --> 00:21:25,280
extremely nervous and one of the reasons was that 
this guy had in fact uh threatened to uh to hack  

149
00:21:25,280 --> 00:21:32,160
anybody who who stood up to him and certainly had 
threatened to hack the women that he had sexually  

150
00:21:32,160 --> 00:21:38,880
assaulted and this was one of the reasons why it 
took so long for the for the story to come out now  

151
00:21:40,320 --> 00:21:46,560
i read this and i i was heartbroken and 
i was also angry i was so angry and i  

152
00:21:46,560 --> 00:21:51,919
did what angry people all over the world 
have done for many years now i tweeted  

153
00:21:53,680 --> 00:22:01,040
and what i tweeted was that if you are a woman 
who has been sexually assaulted by uh by a hacker  

154
00:22:01,600 --> 00:22:07,679
that you could contact me and i would make sure 
that your device got a full forensic analysis

155
00:22:10,160 --> 00:22:17,200
ten thousand retweets later i had somehow 
started a project and so i was being contacted  

156
00:22:17,200 --> 00:22:27,040
by uh victims of sexual assault uh several times 
a day uh it was i think some days it got as  

157
00:22:27,040 --> 00:22:37,680
high as you know 12 or 15 different uh different 
contacts and it was exhausting um but i learned  

158
00:22:37,680 --> 00:22:39,840
some very important things from this experience  

159
00:22:40,800 --> 00:22:45,919
uh the first is that the problem was not what 
i thought it was and this was something that i  

160
00:22:45,920 --> 00:22:49,680
really should have learned a long time ago from 
traveling all over the world and helping to do  

161
00:22:49,680 --> 00:22:55,520
uh privacy and security trainings for people in 
vulnerable populations which is that frequently uh

162
00:22:57,920 --> 00:23:08,800
nice white americans show up in strange countries 
to talk to journalists and activists about  

163
00:23:08,800 --> 00:23:17,440
freedom and we think we know what the problem 
is we think that we understand the the problem  

164
00:23:17,440 --> 00:23:23,200
and the tools that you should be using and how you 
should fix everything and all you need is for us  

165
00:23:23,200 --> 00:23:31,600
to to show up in and show you the way uh this is 
absolutely not true uh for the most part i have  

166
00:23:31,600 --> 00:23:37,520
never seen anyone as bad at information security 
training as information security professionals  

167
00:23:37,520 --> 00:23:44,560
because we are so incredibly bad at teaching and 
we're so incredibly bad at listening uh to people  

168
00:23:44,560 --> 00:23:48,639
in vulnerable populations because all we want to 
do is get up in front of people and prove that  

169
00:23:48,640 --> 00:23:56,480
we have a complete mastery of the topic uh and 
frequently after we give these kinds of speeches  

170
00:23:56,480 --> 00:24:01,840
everybody just ends up scared um and sometimes 
they end up so scared that they engage in  

171
00:24:01,840 --> 00:24:07,679
what i call privacy nihilism which is why should 
i bother to lock anything down why should i keep  

172
00:24:07,680 --> 00:24:13,200
anything private uh why should i even try because 
the government sees everything all the time anyway  

173
00:24:13,760 --> 00:24:20,480
and this is a very dangerous way of thinking 
because if privacy was really dead governments  

174
00:24:20,480 --> 00:24:25,760
wouldn't have to keep trying to kill it all the 
time i wouldn't be nearly as busy if privacy was  

175
00:24:25,760 --> 00:24:33,840
already dead so there's uh there's a lot of work 
to do and it starts with the premise that you can  

176
00:24:33,840 --> 00:24:41,919
in fact uh sort of carve out an area of privacy 
and security for yourself but in order to do that  

177
00:24:41,920 --> 00:24:51,440
uh users need to understand where their data is 
going and who has access to their data and how  

178
00:24:51,440 --> 00:24:57,040
they have access to their data so eff works on 
projects that make these these things more clear  

179
00:24:57,040 --> 00:25:02,560
that communicates them to people in vulnerable 
populations and also that encourages companies  

180
00:25:02,560 --> 00:25:11,919
and governments to engage in best practices that 
uh that support uh sort of privacy and security  

181
00:25:11,920 --> 00:25:18,560
by default um because you shouldn't have to 
become an information security professional  

182
00:25:18,560 --> 00:25:25,040
in order to uh in order to be a journalist 
reporting on on your government you shouldn't  

183
00:25:25,680 --> 00:25:36,160
have to you know get a degree in id in order to 
become a uh an activist this work is mostly being  

184
00:25:36,160 --> 00:25:43,520
done by people who uh have are speaking truth 
to power and they're busy they don't have time  

185
00:25:43,520 --> 00:25:51,840
to be to have an entire security team or to get 
a degree in computer science i and so the more  

186
00:25:51,840 --> 00:26:00,959
we can encourage companies to treat uh vulnerable 
populations as uh the the center of their concern  

187
00:26:01,600 --> 00:26:11,199
instead of uh being out on the periphery the 
better and the reason for for that is this um if  

188
00:26:12,080 --> 00:26:23,199
you start with an engineer a white male engineer 
in santa clara uh you will never get to the  

189
00:26:23,200 --> 00:26:36,480
journalist in syria or the activist in uh tanzania 
or the blogger in vietnam but if you start  

190
00:26:36,480 --> 00:26:45,280
with these people as your users if you start by 
centering the experience of uh of people who are  

191
00:26:46,800 --> 00:26:54,480
in the global south people who are not white 
people who are a part of lgbtq communities  

192
00:26:54,480 --> 00:27:00,640
people who have angered the uh their various 
governments uh then you will have achieved  

193
00:27:00,640 --> 00:27:05,840
privacy and security for everybody and 
that's a that's a much nicer feeling  

194
00:27:06,560 --> 00:27:12,560
uh so there are uh one of the things that i did 
as a as a result of this project that i worked on  

195
00:27:13,200 --> 00:27:19,840
um was i helped to start an organization 
called the coalition against stalkerware  

196
00:27:20,880 --> 00:27:27,440
and the coalition against stalkerware is more than 
30 organized 30 more than 20 organizations now  

197
00:27:28,640 --> 00:27:38,640
from the security industry to academics to people 
who are working sort of on the ground directly  

198
00:27:38,640 --> 00:27:46,240
with victims of of domestic abuse and we are all 
working together in order to both spread awareness  

199
00:27:46,240 --> 00:27:52,400
about the existence of stalkerware but also to 
change the way that uh the security industry  

200
00:27:52,400 --> 00:28:01,200
and law enforcement use stalkerware so that it's 
possible to see when um when this sort of thing is  

201
00:28:01,200 --> 00:28:06,880
uh is present on a device and one of the reasons 
that uh that we're particularly well situated  

202
00:28:06,880 --> 00:28:14,880
for this is because the kind of software that 
tracks everything that you're doing on your phone  

203
00:28:14,880 --> 00:28:18,000
if you're a government is actually not 
that different from the kind of software  

204
00:28:18,000 --> 00:28:25,280
that tracks everything that you're doing uh if 
you are trying to spy on your spouse and in the  

205
00:28:25,280 --> 00:28:30,160
same way that i keep telling governments 
that this sort of extremely invasive uh  

206
00:28:31,120 --> 00:28:38,560
uh the the sort of extremely invasive surveillance 
is uh is abusive uh especially mass surveillance  

207
00:28:38,560 --> 00:28:46,320
where you're just surveilling everybody by default 
um for the for the same reason i'm trying to to  

208
00:28:46,320 --> 00:28:53,040
reach out to to the individuals who think that it 
is somehow okay to spy on their spouse who think  

209
00:28:53,040 --> 00:29:00,960
that it's okay to spy on their kids who think 
it's okay to spy on their co-workers or the people  

210
00:29:00,960 --> 00:29:09,040
that they go to school with uh because they're 
untrustworthy somehow and uh this in and of itself  

211
00:29:09,040 --> 00:29:15,040
is abuse which i think is a very important point 
to make there are a couple of other projects that  

212
00:29:15,040 --> 00:29:21,680
threat lab has worked on that i am extremely proud 
of uh one of them is the atlas of surveillance  

213
00:29:23,120 --> 00:29:30,320
one of the things that we did was we worked 
with the university of nevada at reno and uh  

214
00:29:30,320 --> 00:29:38,560
we produced a map of the united states that shows 
you the different technologies that the police are  

215
00:29:38,560 --> 00:29:47,120
using and the way that we got that information was 
largely by uh searching through through the police  

216
00:29:47,120 --> 00:29:52,080
financial data and searching through the news 
because it turns out that when law enforcement  

217
00:29:52,080 --> 00:29:57,760
buys a new toy that they think that is going to be 
very exciting for surveillance they tend to tell  

218
00:29:58,400 --> 00:30:05,840
newspapers so we've been we've been tracking 
this with great diligence and suddenly in the  

219
00:30:05,840 --> 00:30:12,159
united states people have developed a very strong 
interest in uh the way that uh that local police  

220
00:30:12,160 --> 00:30:22,320
departments uh spy on uh on protesters for example 
i in san francisco where i live uh recently there  

221
00:30:22,320 --> 00:30:32,000
was a set of uh private security cameras that 
was uh that gave access to uh to law enforcement  

222
00:30:32,000 --> 00:30:39,680
during a protest and uh eff has filed a lawsuit 
in uh in relation to this particular thing  

223
00:30:40,480 --> 00:30:48,000
um from a more international perspective uh eff 
has put out a project called crocodile hunter  

224
00:30:48,640 --> 00:31:00,480
crocodile hunter is a way of uh is a software for 
uh detecting the use of uh cell site simulators  

225
00:31:00,480 --> 00:31:06,800
and this is particularly interesting again at 
protests at places where uh people who who piss  

226
00:31:06,800 --> 00:31:14,240
off governments gather uh and uh the reason 
for this uh all over the world is that uh  

227
00:31:15,120 --> 00:31:20,560
we bring our phones to protests we bring 
our phones with us everywhere we carry  

228
00:31:20,560 --> 00:31:26,960
tracking devices around in our pockets and uh 
governments and law enforcement frequently try  

229
00:31:26,960 --> 00:31:34,240
to take advantage of that i and to spy on uh on 
your phone communications so the more that we can  

230
00:31:34,240 --> 00:31:38,560
we can catch them and that we can understand about 
the way that these cell site simulators are being  

231
00:31:38,560 --> 00:31:46,720
used uh especially by authoritarian governments 
especially against their uh political enemies uh  

232
00:31:46,720 --> 00:31:53,760
the safer all of those communities can be 
uh crocodile hunter is up on github uh and  

233
00:31:54,640 --> 00:32:00,640
all of our projects are open source projects 
everybody can contribute everybody can make  

234
00:32:00,640 --> 00:32:08,480
a pull request uh anyone can deploy crocodile 
hunter uh in their local area and see whether or  

235
00:32:09,040 --> 00:32:15,680
what kind of results they get uh at local 
protests and other sort of suspicious events  

236
00:32:15,680 --> 00:32:19,040
where they think that the government is 
going to be using cell site simulators  

237
00:32:20,560 --> 00:32:27,120
so these these are the kinds of 
projects that we do um last of all  

238
00:32:27,120 --> 00:32:33,120
i want to talk about what you can do the and 
i think that that's really the most important  

239
00:32:33,120 --> 00:32:39,760
thing because we are a community of hackers 
we are a community of people who build stuff  

240
00:32:39,760 --> 00:32:46,080
who always think about the future and who 
think about uh the potential impact of our work  

241
00:32:46,800 --> 00:32:55,440
and uh just like eff in 1990 was very niche it was 
just a bunch of nerds and now our issues are sort  

242
00:32:55,440 --> 00:33:01,280
of at the central at the center of everyone's 
lives uh the same thing is true of information  

243
00:33:01,280 --> 00:33:09,840
security professionals this didn't even used 
to be a job uh when i was starting out but uh  

244
00:33:11,520 --> 00:33:16,879
suddenly when everybody's life is digital 
protecting people's information security  

245
00:33:16,880 --> 00:33:24,320
becomes extremely central uh to their well-being 
and the ability to get around that security is  

246
00:33:24,320 --> 00:33:32,480
extremely invasive uh and is often used in 
order to facilitate uh human rights abuses  

247
00:33:32,480 --> 00:33:38,960
so this is a very deep concern to me uh what 
can you do uh a couple of different things  

248
00:33:39,680 --> 00:33:43,200
the first is you can join the 
electronic frontier foundation  

249
00:33:43,200 --> 00:33:51,200
again we have 14 000 members all over the world 
uh we are not just a a u.s organization we are not  

250
00:33:51,200 --> 00:34:01,200
just concerned about protecting americans because 
honestly why bother um but uh anyway you can join  

251
00:34:01,200 --> 00:34:06,240
you can join eff we will send you stickers we 
will send you hoodies we will send you t-shirts  

252
00:34:06,240 --> 00:34:12,000
and in exchange for your money we will work on 
digital civil liberties and you will pay my rent

253
00:34:14,880 --> 00:34:20,719
in addition to this you can contribute to any 
one of our open source projects everything is  

254
00:34:20,719 --> 00:34:26,480
up on github again i really encourage people 
to look over the stuff because it's really  

255
00:34:26,480 --> 00:34:31,840
important and because that's an area in which 
everyone can really contribute individually uh  

256
00:34:31,840 --> 00:34:39,440
if you run a a local organization uh you may wish 
to reach out to the electronic frontiers alliance  

257
00:34:39,440 --> 00:34:48,480
which is a group of uh sort of like-minded 
organizations uh that is kind of corralled by  

258
00:34:48,480 --> 00:34:54,480
the eff uh we talk about digital civil liberties 
issues in uh different uh in different parts  

259
00:34:54,480 --> 00:35:03,200
of the world and among different populations um 
and do a lot of security trainings uh so there's  

260
00:35:03,200 --> 00:35:12,080
there's efa uh and then finally security research 
um you can publish your own security research  

261
00:35:12,080 --> 00:35:18,799
there's this notion that somehow in order to be 
a hacker in order to publish research you need  

262
00:35:18,800 --> 00:35:28,640
permission you need somebody to bless you as a as 
a hacker to confer legitimacy upon you and that's  

263
00:35:28,640 --> 00:35:38,560
simply not true uh so many of us are self-taught 
and we're self-motivated and we don't wait around  

264
00:35:38,560 --> 00:35:43,840
for somebody else to put a crown on our heads 
and say like congratulations now you are a hacker  

265
00:35:44,400 --> 00:35:49,360
the way that you become a hacker is by hacking 
stuff by taking it apart and seeing how it works  

266
00:35:49,920 --> 00:35:57,920
um one of the most interesting projects that i'm 
involved in right now is a project that looks at  

267
00:35:57,920 --> 00:36:04,800
the software which is being used by students 
for distance learning right now during covid19  

268
00:36:04,800 --> 00:36:11,360
so it turns out that not only are they using a lot 
of software for uh for the classes but also that  

269
00:36:11,360 --> 00:36:21,200
they have a special software uh for proctoring 
exams uh this is proctorio and exam soft and also  

270
00:36:21,200 --> 00:36:27,919
that this software is not very secure and that it 
doesn't work very well and it's not even that it's  

271
00:36:27,920 --> 00:36:33,760
very invasive and also doesn't do a particularly 
good job of preventing cheating so this is one  

272
00:36:33,760 --> 00:36:39,280
of the issues that we're looking at right 
now and every one of you has a community  

273
00:36:39,280 --> 00:36:45,120
every one of you has a group of people that you 
care about a group of people that you know a lot  

274
00:36:45,120 --> 00:36:53,600
about whose needs you know and understand in a way 
that i absolutely don't and uh go out and serve  

275
00:36:53,600 --> 00:37:00,000
that community think about what they need think 
about how they get left out of the conversation  

276
00:37:00,720 --> 00:37:06,560
uh and this is the most important thing i think 
that anybody uh who is attending this conference  

277
00:37:06,560 --> 00:37:12,560
can possibly do it's really essential and 
my hope is that we can all do it together

278
00:37:20,880 --> 00:37:21,840
do we have time for questions

279
00:37:29,040 --> 00:37:34,400
so great great talk really really impressive work 
i've actually had the pleasure with working with  

280
00:37:34,400 --> 00:37:42,000
eff and the combination of them understanding 
law and technology was like very very helpful  

281
00:37:42,000 --> 00:37:49,120
it was about a security research and i think my 
question would be what are the requirements for

282
00:37:52,800 --> 00:37:56,880
do they only work with organization can 
any individual do in security research  

283
00:37:56,880 --> 00:38:02,080
contact them and get advice and there's also 
hundreds of questions or dozens of questions  

284
00:38:02,080 --> 00:38:08,240
in the chat that i'll be going through all 
right uh well uh eff has a project called  

285
00:38:08,240 --> 00:38:14,479
the coders rights project uh where we will 
directly counsel uh security researchers  

286
00:38:15,520 --> 00:38:21,600
who uh i mean ideally we counsel them before they 
do their security research so that they can do it  

287
00:38:21,600 --> 00:38:32,640
in a responsible way that is unlikely to make them 
the target of a lawsuit however we also provide  

288
00:38:33,440 --> 00:38:39,920
legal advice and assistance to people 
who are already under threat so this is  

289
00:38:40,880 --> 00:38:47,680
one of the most interesting parts of what we 
do great great okay first question then how do  

290
00:38:47,680 --> 00:38:54,960
you manage internally all the problems that you 
assist um regarding victims of stock stalker work

291
00:38:57,760 --> 00:38:58,960
you want to know like

292
00:39:03,680 --> 00:39:08,480
it should be such a large volume of victims 
right there's a tremendous volume of victims  

293
00:39:08,480 --> 00:39:14,880
and this is one of the reasons why i started 
the coalition against stalker was that helping  

294
00:39:14,880 --> 00:39:21,280
individual victims one by one is really good work 
but we needed to think about the bigger picture  

295
00:39:21,280 --> 00:39:28,640
we needed to think about how to solve things for 
more people for people who don't know who i am who  

296
00:39:28,640 --> 00:39:35,920
cannot email me who i have never read a profile of 
me in a magazine or anything like that people who  

297
00:39:35,920 --> 00:39:40,480
are just afraid and don't have that information 
and so one of the things that we've really  

298
00:39:40,480 --> 00:39:46,480
worked on is getting the av industry to change 
the way that it that it treats this software  

299
00:39:46,480 --> 00:39:55,600
and to uh label it as malicious so the victims 
of uh of this kind of abuse have the choice of  

300
00:39:55,600 --> 00:40:00,720
removing this stalker ware or at least have the 
ability to know that they are being spied on  

301
00:40:02,720 --> 00:40:11,359
understandable so what do you think or how should 
governments regulate the idea of protecting  

302
00:40:11,360 --> 00:40:19,680
privacy and security of the nation but then they 
abuse their technology they got to spy on the same  

303
00:40:19,680 --> 00:40:27,359
people so the question is how should we approach 
or attempt to regulate this problem it depends  

304
00:40:28,000 --> 00:40:31,120
on a couple of different things 
it depends on which government  

305
00:40:31,120 --> 00:40:36,640
uh it depends on how much you believe uh that 
the government can effectively regulate itself  

306
00:40:38,400 --> 00:40:43,120
and a lot of the time what you do is you look at 
the previous behavior of that government or where  

307
00:40:43,120 --> 00:40:53,279
the where the government is going i tend to err 
on the side of technology which is uh rather than  

308
00:40:53,280 --> 00:41:02,000
waiting for the government to magically decide to 
uh to rein itself in and curve its abuses i try  

309
00:41:02,000 --> 00:41:07,600
to make those abuses as difficult as possible 
to perpetrate using the technology by default  

310
00:41:09,280 --> 00:41:18,640
okay what do you think is the biggest problem 
with populations with basically not technology or  

311
00:41:18,640 --> 00:41:22,080
basically starting to adopt the technology 
what are the biggest challenges there  

312
00:41:22,880 --> 00:41:32,400
there are a lot of challenges there the first 
is is often just access to access to tools  

313
00:41:32,400 --> 00:41:40,640
access to bandwidth access to power uh are all 
extremely important issues uh there was a um  

314
00:41:41,920 --> 00:41:48,480
there was a situation that was brought up to me 
uh the last time that i spoke in india where it  

315
00:41:48,480 --> 00:41:55,760
turned out that much of the population does not 
have access to power in their home and so they  

316
00:41:55,760 --> 00:42:04,160
go to a shop in order to recharge their phones and 
it turned out that the people who ran the shops  

317
00:42:04,160 --> 00:42:14,000
uh were grabbing the the whatsapp data uh from uh 
these phones and selling uh the whatsapp data of  

318
00:42:14,560 --> 00:42:22,640
uh women uh two men rated according to their 
attractiveness so this is incredibly invasive  

319
00:42:22,640 --> 00:42:28,080
and it is one of those things that would only 
happen if you're regularly handing over your phone  

320
00:42:28,080 --> 00:42:33,759
to someone else in order to charge it um 
and this is one of those things that uh  

321
00:42:34,640 --> 00:42:39,839
most of us do not think of because we 
think of our devices as our own as devices  

322
00:42:39,840 --> 00:42:46,080
that we do not share uh we think of power as 
ubiquitous unless we're on a plane flight then  

323
00:42:46,880 --> 00:42:52,560
power can be very hard to find uh so those are the 
those are the sorts of things that we think about  

324
00:42:53,440 --> 00:43:01,920
okay so next question what do you think 
about gdpr um respect the privacy of data and  

325
00:43:01,920 --> 00:43:06,800
why why would what is why is it so complicated 
to implement something like this in america  

326
00:43:07,360 --> 00:43:11,840
especially with the data protection 
and confidentiality of data

327
00:43:14,080 --> 00:43:20,319
so once upon a time somebody asked i think it was 
i think it was mahatma gandhi what he thought of  

328
00:43:20,320 --> 00:43:29,200
western civilization and he said i think it would 
be a good idea um what i think of okay sort of uh  

329
00:43:30,000 --> 00:43:38,800
privacy and security regulation is it would be a 
good idea uh the gdpr is difficult to implement uh  

330
00:43:38,800 --> 00:43:45,200
and absolutely confusing to the majority of 
the people that i uh that i have worked with  

331
00:43:45,200 --> 00:43:56,640
and talked to um and it is written in such a way 
that i it can possibly be abused uh in order to  

332
00:43:56,640 --> 00:44:05,279
gather data on people who are not you so the the 
way that they that the holders of this data uh  

333
00:44:05,840 --> 00:44:11,440
make sure that they're handing it over to 
you and not to your stalker ex-boyfriend  

334
00:44:12,400 --> 00:44:19,920
is frequently inadequate so i am concerned about 
pr about data privacy and i am concerned about  

335
00:44:19,920 --> 00:44:26,160
the ways in which the gdpr is implemented i 
think pointing to the gdpr as some sort of  

336
00:44:26,160 --> 00:44:32,480
perfect document that we need to implement in 
the united states is uh is missing the point uh  

337
00:44:32,480 --> 00:44:37,760
we need something which is better than the gdpr 
i we need that in europe we need it in the united  

338
00:44:37,760 --> 00:44:44,160
states and we need it everywhere everywhere 
else in the world and if you don't trust  

339
00:44:44,160 --> 00:44:50,640
governments and you don't trust regulation 
then we need these technologies to exist  

340
00:44:52,080 --> 00:44:56,960
by default in ways that cannot 
be backdoored all over the world

341
00:44:59,760 --> 00:45:08,800
okay next um how do you think we can find 
a balance between security and privacy

342
00:45:10,880 --> 00:45:17,680
i think we need to stop thinking about security 
and privacy as separate issues or as issues  

343
00:45:17,680 --> 00:45:22,399
that are fundamentally opposed to one another 
that instead of thinking about security versus  

344
00:45:22,400 --> 00:45:29,760
privacy we should think about privacy for whom 
security for whom and we should try to provide  

345
00:45:30,560 --> 00:45:37,040
privacy and security to the people who are usually 
left out on the periphery the people who uh are  

346
00:45:37,040 --> 00:45:43,840
thought not to deserve privacy and security not 
to deserve uh tools that work for them tools that  

347
00:45:43,840 --> 00:45:52,400
take their lives into account i and i think that's 
especially important uh privacy and security are  

348
00:45:52,400 --> 00:46:04,400
not uh are not opposites okay and next what do 
you think about privacy of data and regulations  

349
00:46:04,400 --> 00:46:10,720
oh okay what are the regulations that governments 
should adopt to protect user data and privacy  

350
00:46:12,160 --> 00:46:18,560
again i am skeptical of a purely regulatory 
approach uh because governments differ i and  

351
00:46:18,560 --> 00:46:24,400
their ability to regulate themselves also 
differs um i honestly cannot think of many  

352
00:46:24,400 --> 00:46:28,480
governments that i would trust to regulate 
themselves effectively in this area i think  

353
00:46:28,480 --> 00:46:34,400
that the best thing that we can do is implement 
uh uh end-to-end encryption in as much of our  

354
00:46:34,400 --> 00:46:42,000
communication as possible uh in order to protect 
it from being intercepted by uh by third parties  

355
00:46:42,000 --> 00:46:47,680
including governments and law enforcement okay 
and the last question that we got here is uh  

356
00:46:48,240 --> 00:46:55,839
what advice would you give to someone who's just 
starting in security and i guess privacy as well  

357
00:46:56,640 --> 00:47:03,759
i think that the best advice that i could 
give is don't wait for permission don't  

358
00:47:03,760 --> 00:47:07,360
wait for permission to become a hacker don't 
wait for permission to become an activist  

359
00:47:08,560 --> 00:47:16,799
get out there and take things apart figure out how 
they work uh everyone is an expert in something  

360
00:47:16,800 --> 00:47:24,720
everyone has a group of people that they care 
about and that they understand better than anybody  

361
00:47:24,720 --> 00:47:30,560
else and thinking about how to protect the people 
who are left out of the conversation is something  

362
00:47:30,560 --> 00:47:36,160
that anyone can do you don't need a degree you 
don't need a certificate you don't need a specific  

363
00:47:36,160 --> 00:47:42,799
training you don't need to be working at you know 
some fortune 500 company uh you just need to care  

364
00:47:44,640 --> 00:47:52,319
great and i think we got some additional questions 
here and i don't know if you are very familiar  

365
00:47:52,320 --> 00:47:59,200
with latin america but they're asking how do you 
see latin america in five years regarding security  

366
00:47:59,200 --> 00:48:08,879
and privacy i am very hesitant to describe latin 
america as a monolith uh this whole idea that  

367
00:48:08,880 --> 00:48:13,200
all of latin america is the same that if their 
governments are the same that they're all equally  

368
00:48:13,200 --> 00:48:19,279
trustworthy or not trustworthy uh i think that 
this is actually a very common uh american way of  

369
00:48:19,280 --> 00:48:24,320
looking at uh at the world that there's uh there's 
america and then there's there's everything else  

370
00:48:24,960 --> 00:48:33,280
uh and also that latin america is somehow by 
right uh an american uh sphere of influence  

371
00:48:33,280 --> 00:48:39,120
what we used to call the monroe doctrine uh i 
think this is also [ __ ] uh everybody deserves  

372
00:48:39,120 --> 00:48:44,720
to to run their own goddamn governments uh 
having said that where is it going to go  

373
00:48:46,240 --> 00:48:51,839
i am going to cheat i am going to tell you that 
i think that in some ways it will get better  

374
00:48:52,480 --> 00:48:58,720
i in that we will have uh new technologies 
that allow us to protect ourselves  

375
00:48:58,720 --> 00:49:04,080
against uh spying by governments and 
law enforcement and abusive spouses  

376
00:49:05,360 --> 00:49:09,440
but that in some ways it 
is also going to get worse  

377
00:49:11,120 --> 00:49:18,240
that when governments have power and when law 
enforcement has power they tend to abuse it  

378
00:49:18,240 --> 00:49:24,959
and i don't think that we have seen the end 
of those abuses by a long shot uh and i think  

379
00:49:24,960 --> 00:49:29,200
that the people who are listening to this 
talk are the people who are best equipped  

380
00:49:29,200 --> 00:49:38,399
to to see those abuses when they're happening and 
to alert the world yeah tell me about it i think  

381
00:49:38,400 --> 00:49:44,320
we've covered all the questions so far it was 
great having you here really interesting stuff  

382
00:49:44,320 --> 00:49:57,840
and i hope we'll see see you in person next 
year that that is also my hope thank you

383
00:49:59,840 --> 00:50:11,840
yes

384
00:50:23,680 --> 00:50:25,839
uh

385
00:50:38,800 --> 00:50:39,840
gracias

386
00:50:54,240 --> 00:50:57,839
thanks for all that was amazing presentation and  

387
00:50:59,040 --> 00:51:06,320
i've been waiting in chile i hope you've 
been here soon eh khabib see you later

388
00:51:20,320 --> 00:51:21,840
oh

389
00:51:44,080 --> 00:51:49,840
sandbox

390
00:51:53,680 --> 00:51:53,759
you

