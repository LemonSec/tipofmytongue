1
00:00:15,679 --> 00:00:17,199
good afternoon everybody

2
00:00:17,199 --> 00:00:20,480
uh so glad to see you guys and my name

3
00:00:20,480 --> 00:00:21,520
is montang

4
00:00:21,520 --> 00:00:24,160
and chi-chang is my current speaker at

5
00:00:24,160 --> 00:00:25,279
this time

6
00:00:25,279 --> 00:00:28,960
hi guys today we are going to talk about

7
00:00:28,960 --> 00:00:31,119
our recent research progress about

8
00:00:31,119 --> 00:00:33,760
artificial intelligence security

9
00:00:33,760 --> 00:00:37,040
and the title is model robustness well

10
00:00:37,040 --> 00:00:40,480
heart data privacy

11
00:00:40,800 --> 00:00:43,600
before i started i want to introduce our

12
00:00:43,600 --> 00:00:44,000
team

13
00:00:44,000 --> 00:00:46,800
first we are from tencent due to lab of

14
00:00:46,800 --> 00:00:49,039
tencent platform department

15
00:00:49,039 --> 00:00:52,000
and tencent security reform department

16
00:00:52,000 --> 00:00:52,719
has been

17
00:00:52,719 --> 00:00:55,680
that had been raised tencent for 16

18
00:00:55,680 --> 00:00:56,559
years

19
00:00:56,559 --> 00:00:59,680
and that came to the protection of qq

20
00:00:59,680 --> 00:01:02,640
the chats tencent games and some other

21
00:01:02,640 --> 00:01:04,799
critical products

22
00:01:04,799 --> 00:01:07,600
our interests include tencent account

23
00:01:07,600 --> 00:01:09,760
security ai security

24
00:01:09,760 --> 00:01:12,159
and fraud and scamping insurance

25
00:01:12,159 --> 00:01:12,880
detection

26
00:01:12,880 --> 00:01:16,240
and mobile app security and so on

27
00:01:16,240 --> 00:01:20,240
tencent joshua lab was funded in 2019 by

28
00:01:20,240 --> 00:01:22,799
tencent security reform department

29
00:01:22,799 --> 00:01:25,439
focusing on red teaming and ai security

30
00:01:25,439 --> 00:01:27,200
research

31
00:01:27,200 --> 00:01:29,920
okay let's come back to the topic in

32
00:01:29,920 --> 00:01:30,799
this talk

33
00:01:30,799 --> 00:01:32,960
we want to discuss the existing

34
00:01:32,960 --> 00:01:33,840
challenges of

35
00:01:33,840 --> 00:01:37,280
ai at first and discuss the relationship

36
00:01:37,280 --> 00:01:38,240
between ai

37
00:01:38,240 --> 00:01:40,320
and security including the

38
00:01:40,320 --> 00:01:41,600
vulnerabilities of

39
00:01:41,600 --> 00:01:44,720
ai components and new attacks targeting

40
00:01:44,720 --> 00:01:47,759
on ai systems and some other things

41
00:01:47,759 --> 00:01:49,280
and then we will introduce the

42
00:01:49,280 --> 00:01:51,840
background and motivations of this work

43
00:01:51,840 --> 00:01:55,040
including some fundamental concepts

44
00:01:55,040 --> 00:01:57,840
such as adversarial attacks adversarial

45
00:01:57,840 --> 00:02:00,880
training and model privacy attacks

46
00:02:00,880 --> 00:02:03,200
after that we are willing to introduce

47
00:02:03,200 --> 00:02:06,159
how to steal data from model gradient

48
00:02:06,159 --> 00:02:09,038
illustrate our experiments and discuss

49
00:02:09,038 --> 00:02:10,160
how to

50
00:02:10,160 --> 00:02:12,959
defend such attacks at the end we will

51
00:02:12,959 --> 00:02:14,239
conclude this

52
00:02:14,239 --> 00:02:16,640
talk and present some other interesting

53
00:02:16,640 --> 00:02:19,040
studies

54
00:02:19,040 --> 00:02:21,599
i think everyone here has held how

55
00:02:21,599 --> 00:02:22,400
incredible

56
00:02:22,400 --> 00:02:25,520
powerful and successful ai is many

57
00:02:25,520 --> 00:02:26,080
different

58
00:02:26,080 --> 00:02:28,160
tasks that could not be solved with

59
00:02:28,160 --> 00:02:29,280
software before

60
00:02:29,280 --> 00:02:32,160
are now solvable thanks to deep learning

61
00:02:32,160 --> 00:02:33,519
and neural networks

62
00:02:33,519 --> 00:02:35,760
and gradient descent of those

63
00:02:35,760 --> 00:02:37,760
technologies that are working really

64
00:02:37,760 --> 00:02:38,400
well

65
00:02:38,400 --> 00:02:41,599
and they call them ai absolutely

66
00:02:41,599 --> 00:02:44,640
the time has come for ai this possible

67
00:02:44,640 --> 00:02:46,959
because several developments that are

68
00:02:46,959 --> 00:02:48,879
currently coinciding

69
00:02:48,879 --> 00:02:51,760
first the computing power of computer

70
00:02:51,760 --> 00:02:52,640
processors

71
00:02:52,640 --> 00:02:55,840
has increased rapidly second

72
00:02:55,840 --> 00:02:58,560
huge amounts of data are available today

73
00:02:58,560 --> 00:02:59,519
from the cloud

74
00:02:59,519 --> 00:03:02,800
and high mobile bandwidth this is

75
00:03:02,800 --> 00:03:03,519
important

76
00:03:03,519 --> 00:03:06,319
because ai systems are particularly

77
00:03:06,319 --> 00:03:08,080
useful when it comes to

78
00:03:08,080 --> 00:03:10,640
identifying patterns in large amount of

79
00:03:10,640 --> 00:03:11,680
the data

80
00:03:11,680 --> 00:03:14,879
besides software developers are now able

81
00:03:14,879 --> 00:03:16,720
to write on programs

82
00:03:16,720 --> 00:03:19,920
that work in a similar baby to the human

83
00:03:19,920 --> 00:03:20,879
brain

84
00:03:20,879 --> 00:03:23,599
artificial intelligence has long since

85
00:03:23,599 --> 00:03:24,000
found

86
00:03:24,000 --> 00:03:27,040
its way into our everyday lives for

87
00:03:27,040 --> 00:03:28,319
example

88
00:03:28,319 --> 00:03:31,920
50 16 percent of jamming already used

89
00:03:31,920 --> 00:03:33,040
voice assistance

90
00:03:33,040 --> 00:03:36,239
such as a modding's a lecture or apple's

91
00:03:36,239 --> 00:03:39,680
theory smartphones are able to recognize

92
00:03:39,680 --> 00:03:42,480
whether somebody is traveling by food

93
00:03:42,480 --> 00:03:46,080
or in a car and thanks to intelligent

94
00:03:46,080 --> 00:03:49,120
everything facebook twitter and the like

95
00:03:49,120 --> 00:03:51,680
offer us exactly the information that

96
00:03:51,680 --> 00:03:53,920
interests us

97
00:03:53,920 --> 00:03:57,280
so how to build an ai system you know

98
00:03:57,280 --> 00:03:59,200
before an estimate is

99
00:03:59,200 --> 00:04:02,480
being used it will go through many

100
00:04:02,480 --> 00:04:03,360
processes

101
00:04:03,360 --> 00:04:05,840
typically if an ai engineer starts to

102
00:04:05,840 --> 00:04:06,400
develop

103
00:04:06,400 --> 00:04:08,799
an ai system the first thing is to

104
00:04:08,799 --> 00:04:11,200
collect the data

105
00:04:11,200 --> 00:04:13,200
usually for different application

106
00:04:13,200 --> 00:04:14,480
scenarios there

107
00:04:14,480 --> 00:04:17,120
may be different data types such as

108
00:04:17,120 --> 00:04:17,918
images

109
00:04:17,918 --> 00:04:21,358
videos texts and so on data preparation

110
00:04:21,358 --> 00:04:22,880
is equally important

111
00:04:22,880 --> 00:04:26,000
because it significantly determines the

112
00:04:26,000 --> 00:04:28,320
robustness of the ai model

113
00:04:28,320 --> 00:04:31,520
so in this process engineers must

114
00:04:31,520 --> 00:04:33,759
carefully to check the data and select

115
00:04:33,759 --> 00:04:35,199
the bad ones

116
00:04:35,199 --> 00:04:38,080
after that ai engineers use those data

117
00:04:38,080 --> 00:04:40,080
to train a deep neural network

118
00:04:40,080 --> 00:04:42,720
and then evaluate the qualities of the

119
00:04:42,720 --> 00:04:44,400
trained model

120
00:04:44,400 --> 00:04:46,720
that is to use the data out of the

121
00:04:46,720 --> 00:04:47,520
training set

122
00:04:47,520 --> 00:04:50,400
to test the record procession or some

123
00:04:50,400 --> 00:04:50,800
other

124
00:04:50,800 --> 00:04:53,840
evaluation criteria of the model once

125
00:04:53,840 --> 00:04:56,720
the radio is satisfied the requirement

126
00:04:56,720 --> 00:04:59,840
the model will be deployed the most

127
00:04:59,840 --> 00:05:03,120
common way is to deploy the ai model as

128
00:05:03,120 --> 00:05:04,560
a cloud service

129
00:05:04,560 --> 00:05:08,160
it rises it provides users with an

130
00:05:08,160 --> 00:05:11,520
in inference api which takes users data

131
00:05:11,520 --> 00:05:11,919
in

132
00:05:11,919 --> 00:05:14,160
and then outputs the prediction results

133
00:05:14,160 --> 00:05:15,440
of the ai model

134
00:05:15,440 --> 00:05:18,320
just like a black box however each

135
00:05:18,320 --> 00:05:18,880
process

136
00:05:18,880 --> 00:05:21,440
of developing an ai system may be

137
00:05:21,440 --> 00:05:24,080
attacked by attackers

138
00:05:24,080 --> 00:05:26,479
so let's think about the relationship

139
00:05:26,479 --> 00:05:27,440
between ai

140
00:05:27,440 --> 00:05:30,479
and security i think on

141
00:05:30,479 --> 00:05:33,680
on one hand security challenges ai

142
00:05:33,680 --> 00:05:36,160
the first challenge is that the

143
00:05:36,160 --> 00:05:38,000
components of ai systems

144
00:05:38,000 --> 00:05:42,080
make contains vulnerabilities aic jumps

145
00:05:42,080 --> 00:05:44,639
usually contains many many fundamental

146
00:05:44,639 --> 00:05:45,520
components

147
00:05:45,520 --> 00:05:48,000
you know such as deep learning

148
00:05:48,000 --> 00:05:48,800
frameworks

149
00:05:48,800 --> 00:05:52,560
tensorflow cafe pie touch and so on

150
00:05:52,560 --> 00:05:54,960
and the accelerate framework such as

151
00:05:54,960 --> 00:05:56,479
tensor rt

152
00:05:56,479 --> 00:05:59,759
uh software packages you know most of

153
00:05:59,759 --> 00:06:02,880
ai aggregated by python and use a lot of

154
00:06:02,880 --> 00:06:04,240
python packages

155
00:06:04,240 --> 00:06:07,759
such as opencv numpai pandas and so on

156
00:06:07,759 --> 00:06:09,600
of those components may contain

157
00:06:09,600 --> 00:06:10,880
vulnerabilities

158
00:06:10,880 --> 00:06:14,240
for example back hunters had found 37

159
00:06:14,240 --> 00:06:16,479
vulnerabilities of tensorflow

160
00:06:16,479 --> 00:06:18,960
once those vulnerabilities are adopted

161
00:06:18,960 --> 00:06:21,440
by attackers the ai systems will be

162
00:06:21,440 --> 00:06:22,400
vulnerable

163
00:06:22,400 --> 00:06:25,840
vulnerable to be attacked besides

164
00:06:25,840 --> 00:06:28,319
so have a match it matched a lot of

165
00:06:28,319 --> 00:06:32,080
attacks targeting ai systems

166
00:06:32,080 --> 00:06:35,600
as they know data algorithm and model

167
00:06:35,600 --> 00:06:38,479
as three most significant components in

168
00:06:38,479 --> 00:06:39,280
ai

169
00:06:39,280 --> 00:06:42,160
but unfortunately of the of them have

170
00:06:42,160 --> 00:06:44,479
been proven to be vulnerable

171
00:06:44,479 --> 00:06:47,840
first the data used for training an ai

172
00:06:47,840 --> 00:06:50,400
model may be attacked by data poisoning

173
00:06:50,400 --> 00:06:51,360
attack

174
00:06:51,360 --> 00:06:54,479
in most cases a large amount of data is

175
00:06:54,479 --> 00:06:57,039
typically required to train the model

176
00:06:57,039 --> 00:07:00,080
so ai engineers cannot check each data

177
00:07:00,080 --> 00:07:02,160
during the data preparation

178
00:07:02,160 --> 00:07:05,120
this makes attackers have a option

179
00:07:05,120 --> 00:07:07,199
opportunities to modify the part of the

180
00:07:07,199 --> 00:07:08,000
data

181
00:07:08,000 --> 00:07:10,400
and make the train model with a hidden

182
00:07:10,400 --> 00:07:11,360
backdoor

183
00:07:11,360 --> 00:07:14,160
when this backdoor model takes a normal

184
00:07:14,160 --> 00:07:15,120
data in

185
00:07:15,120 --> 00:07:17,840
it offers normal results but when it

186
00:07:17,840 --> 00:07:19,120
takes a specially

187
00:07:19,120 --> 00:07:21,680
modified data in it will output a

188
00:07:21,680 --> 00:07:24,000
certain incorrect result

189
00:07:24,000 --> 00:07:27,440
second previous work has proven it that

190
00:07:27,440 --> 00:07:30,319
ai across based on deep neural networks

191
00:07:30,319 --> 00:07:32,240
are vulnerable to be followed by

192
00:07:32,240 --> 00:07:35,360
adversarial examples and

193
00:07:35,360 --> 00:07:38,479
an adversarial example is an example

194
00:07:38,479 --> 00:07:39,199
that

195
00:07:39,199 --> 00:07:42,560
we apply some small perturbations on

196
00:07:42,560 --> 00:07:44,400
making the prediction of the neural

197
00:07:44,400 --> 00:07:46,960
network changes to another label

198
00:07:46,960 --> 00:07:50,000
and for most cases such modification

199
00:07:50,000 --> 00:07:52,879
on an image usually cannot be notified

200
00:07:52,879 --> 00:07:54,479
by human eyes

201
00:07:54,479 --> 00:07:58,160
besides as you know various ai services

202
00:07:58,160 --> 00:08:00,960
are available on the cloud they send the

203
00:08:00,960 --> 00:08:01,680
data in

204
00:08:01,680 --> 00:08:04,800
it outputs the prediction results

205
00:08:04,800 --> 00:08:07,840
for example image classification we send

206
00:08:07,840 --> 00:08:10,080
an image to acquiring the

207
00:08:10,080 --> 00:08:13,599
ai service then it outputs the label and

208
00:08:13,599 --> 00:08:15,199
its corresponding

209
00:08:15,199 --> 00:08:17,599
confidence however based on that

210
00:08:17,599 --> 00:08:19,759
attackers may utilize

211
00:08:19,759 --> 00:08:22,560
the outputs of multiple queries as a

212
00:08:22,560 --> 00:08:23,440
target loss

213
00:08:23,440 --> 00:08:26,879
to retain a new model and the model is

214
00:08:26,879 --> 00:08:29,199
similar to the one provided by the ai

215
00:08:29,199 --> 00:08:30,879
service

216
00:08:30,879 --> 00:08:34,399
so that they can achieve the purpose of

217
00:08:34,399 --> 00:08:37,279
model stealing

218
00:08:38,240 --> 00:08:40,958
the last but not the least the risk of

219
00:08:40,958 --> 00:08:42,240
ai abuse is

220
00:08:42,240 --> 00:08:45,760
a is also a significant security problem

221
00:08:45,760 --> 00:08:48,399
let's take about that what will happen

222
00:08:48,399 --> 00:08:51,120
when we use ai in a runway

223
00:08:51,120 --> 00:08:52,959
i think it may be a weapon of the

224
00:08:52,959 --> 00:08:56,160
underground industry for example defeat

225
00:08:56,160 --> 00:08:59,440
an air-based technology giving a few

226
00:08:59,440 --> 00:09:01,360
pieces of somebody's words

227
00:09:01,360 --> 00:09:04,399
it can imitate his war her words to

228
00:09:04,399 --> 00:09:07,920
make a fake core or giving a photo of a

229
00:09:07,920 --> 00:09:09,120
target person

230
00:09:09,120 --> 00:09:12,880
it can swap the target phase to a video

231
00:09:12,880 --> 00:09:15,440
then the other underground industry can

232
00:09:15,440 --> 00:09:17,600
use this method to bypass the

233
00:09:17,600 --> 00:09:21,120
face and disproving besides capture

234
00:09:21,120 --> 00:09:23,839
it also has been an effective tool to

235
00:09:23,839 --> 00:09:25,600
solve captures

236
00:09:25,600 --> 00:09:29,200
so ai is a double urgent sword

237
00:09:29,200 --> 00:09:31,680
it makes our lives more convenient but

238
00:09:31,680 --> 00:09:33,920
also brings some security from

239
00:09:33,920 --> 00:09:37,279
pro plants

240
00:09:37,279 --> 00:09:40,080
on the other hand ai also enables

241
00:09:40,080 --> 00:09:42,480
security for example they use

242
00:09:42,480 --> 00:09:46,399
ai to steer with protection rules

243
00:09:46,399 --> 00:09:48,560
traditional methods to achieve that

244
00:09:48,560 --> 00:09:50,640
highly depends on the experimental

245
00:09:50,640 --> 00:09:52,000
experience

246
00:09:52,000 --> 00:09:54,640
technically those methods of their valve

247
00:09:54,640 --> 00:09:57,040
responds a response by sending

248
00:09:57,040 --> 00:10:00,080
attack pillows and zinc infer the rules

249
00:10:00,080 --> 00:10:01,920
through multiple attempts

250
00:10:01,920 --> 00:10:05,040
this process is very label intensive and

251
00:10:05,040 --> 00:10:06,560
time-consuming

252
00:10:06,560 --> 00:10:08,880
with ai technologies they can use

253
00:10:08,880 --> 00:10:10,240
pre-trained model

254
00:10:10,240 --> 00:10:12,560
to link the security experience hiding

255
00:10:12,560 --> 00:10:13,839
in the payloads

256
00:10:13,839 --> 00:10:17,040
and to utilize the attention mechanisms

257
00:10:17,040 --> 00:10:17,519
to

258
00:10:17,519 --> 00:10:20,079
locate as part of the payloads that

259
00:10:20,079 --> 00:10:22,959
contributes to the detection results

260
00:10:22,959 --> 00:10:26,399
after that we can use a recommendation

261
00:10:26,399 --> 00:10:27,680
model to re

262
00:10:27,680 --> 00:10:30,720
to link the pro abilities of the

263
00:10:30,720 --> 00:10:34,320
candidate characters it does not require

264
00:10:34,320 --> 00:10:37,120
accessing manual invention and can run

265
00:10:37,120 --> 00:10:38,079
on a larger

266
00:10:38,079 --> 00:10:41,839
scale okay let's reach out to continuous

267
00:10:41,839 --> 00:10:44,079
talk

268
00:10:45,680 --> 00:10:49,519
thanks moyu hello guys i'm back

269
00:10:49,519 --> 00:10:52,320
let me introduce the background and the

270
00:10:52,320 --> 00:10:53,279
motivation

271
00:10:53,279 --> 00:10:56,880
of our work as we know machine learning

272
00:10:56,880 --> 00:10:58,640
algorithms acceptor

273
00:10:58,640 --> 00:11:02,160
imposed as numeric vectors a diverse

274
00:11:02,160 --> 00:11:03,519
attack refers to

275
00:11:03,519 --> 00:11:07,040
an attack method in which the attacker

276
00:11:07,040 --> 00:11:09,519
perturbs the input of the model

277
00:11:09,519 --> 00:11:12,640
resulting in wrong prediction

278
00:11:12,640 --> 00:11:15,440
the perturbed import data is called

279
00:11:15,440 --> 00:11:17,760
adversarial examples

280
00:11:17,760 --> 00:11:21,279
as the image shows here starting with

281
00:11:21,279 --> 00:11:23,279
the image of a panda

282
00:11:23,279 --> 00:11:26,079
the attackers add small perturbations to

283
00:11:26,079 --> 00:11:27,519
the original

284
00:11:27,519 --> 00:11:30,560
image which results in the model

285
00:11:30,560 --> 00:11:34,160
labeling this image as a cocktail shaker

286
00:11:34,160 --> 00:11:37,279
with high confidence

287
00:11:37,279 --> 00:11:39,440
the process of adding these

288
00:11:39,440 --> 00:11:40,399
perturbations

289
00:11:40,399 --> 00:11:43,600
is easy as the formula shows we

290
00:11:43,600 --> 00:11:44,480
emphasize

291
00:11:44,480 --> 00:11:47,839
that the adversarial attack has affected

292
00:11:47,839 --> 00:11:50,240
the various air tasks

293
00:11:50,240 --> 00:11:53,600
including image classification object

294
00:11:53,600 --> 00:11:54,560
detection

295
00:11:54,560 --> 00:11:58,720
auto speech recognition and so on

296
00:11:58,720 --> 00:12:02,240
as i made sure the audio is

297
00:12:02,240 --> 00:12:06,399
added small perturbations but um

298
00:12:06,399 --> 00:12:09,920
the translation of the radio uh

299
00:12:09,920 --> 00:12:15,279
audio is quite a different uh yeah

300
00:12:15,760 --> 00:12:18,480
before adding the perturbations and the

301
00:12:18,480 --> 00:12:19,760
translation is

302
00:12:19,760 --> 00:12:23,440
it was the best of times it was the

303
00:12:23,440 --> 00:12:25,120
worst of times

304
00:12:25,120 --> 00:12:29,040
but after adding some

305
00:12:29,040 --> 00:12:32,000
uh perturbation the translation will

306
00:12:32,000 --> 00:12:33,200
become

307
00:12:33,200 --> 00:12:36,480
it is our truth and universally

308
00:12:36,480 --> 00:12:40,560
acknowledged that a single yeah

309
00:12:40,560 --> 00:12:44,639
unfortunately almost all existing models

310
00:12:44,639 --> 00:12:47,920
are vulnerable to this attack which can

311
00:12:47,920 --> 00:12:48,959
be regarded

312
00:12:48,959 --> 00:12:54,399
as a natural defect of learning models

313
00:12:58,480 --> 00:13:01,440
fat failure rate failure adversarial

314
00:13:01,440 --> 00:13:02,480
training

315
00:13:02,480 --> 00:13:05,440
in which a network is trained on other

316
00:13:05,440 --> 00:13:06,079
virtual

317
00:13:06,079 --> 00:13:09,600
examples is one of the most promising

318
00:13:09,600 --> 00:13:11,600
ways to defend

319
00:13:11,600 --> 00:13:16,240
against adversarial attacks simply put

320
00:13:16,240 --> 00:13:18,880
adversarial training introduce adverse

321
00:13:18,880 --> 00:13:20,160
examples as

322
00:13:20,160 --> 00:13:23,600
part of training data the problem

323
00:13:23,600 --> 00:13:27,519
can be formulated as solving a min max

324
00:13:27,519 --> 00:13:30,639
optimization problem during training

325
00:13:30,639 --> 00:13:34,959
a model with the inner maximization

326
00:13:34,959 --> 00:13:38,000
generating other virtual examples by

327
00:13:38,000 --> 00:13:41,440
maximizing the classification laws

328
00:13:41,440 --> 00:13:46,079
and the outer minimization finding model

329
00:13:46,079 --> 00:13:50,000
model parameters by minimizing the loss

330
00:13:50,000 --> 00:13:53,440
of the virtual examples which generated

331
00:13:53,440 --> 00:13:57,120
from the inner maximization

332
00:13:57,120 --> 00:13:58,820
as the figures show

333
00:13:58,820 --> 00:14:00,560
[Music]

334
00:14:00,560 --> 00:14:04,320
before the model of the model

335
00:14:04,320 --> 00:14:07,120
when the model is trained by

336
00:14:07,120 --> 00:14:08,240
transitional

337
00:14:08,240 --> 00:14:11,519
method when we import the virtual

338
00:14:11,519 --> 00:14:12,079
example

339
00:14:12,079 --> 00:14:14,720
the model will make a wrong prediction

340
00:14:14,720 --> 00:14:15,199
but

341
00:14:15,199 --> 00:14:17,279
after where yours or the virtual

342
00:14:17,279 --> 00:14:18,800
training method

343
00:14:18,800 --> 00:14:22,560
the module can make a correct prediction

344
00:14:22,560 --> 00:14:25,760
uh on a virtual example

345
00:14:25,760 --> 00:14:28,720
it means that the robustness of the

346
00:14:28,720 --> 00:14:29,839
model

347
00:14:29,839 --> 00:14:32,959
has been improved

348
00:14:34,079 --> 00:14:37,519
on the other hand in machine learning

349
00:14:37,519 --> 00:14:38,320
failed

350
00:14:38,320 --> 00:14:41,519
and often overlooked danger within

351
00:14:41,519 --> 00:14:42,720
machine learning

352
00:14:42,720 --> 00:14:46,000
is the research on privacy attacks

353
00:14:46,000 --> 00:14:49,680
against machining systems

354
00:14:49,680 --> 00:14:53,680
here we introduce two classic privacy

355
00:14:53,680 --> 00:14:54,800
attacks

356
00:14:54,800 --> 00:14:57,760
the first is called the membership in

357
00:14:57,760 --> 00:14:59,519
first attack

358
00:14:59,519 --> 00:15:02,639
the attacker aims to determine

359
00:15:02,639 --> 00:15:05,680
whether a data point is part of training

360
00:15:05,680 --> 00:15:06,320
data

361
00:15:06,320 --> 00:15:10,480
just by observing models output

362
00:15:10,480 --> 00:15:14,079
membership informants can cause security

363
00:15:14,079 --> 00:15:17,519
and the privacy concerns in cases

364
00:15:17,519 --> 00:15:21,120
where the target model has been changed

365
00:15:21,120 --> 00:15:24,720
on system information yeah

366
00:15:24,720 --> 00:15:28,079
what's more the attackers may not only

367
00:15:28,079 --> 00:15:31,040
want to know whether the piece of data

368
00:15:31,040 --> 00:15:31,839
point is

369
00:15:31,839 --> 00:15:37,120
in the training site but also wants to

370
00:15:37,120 --> 00:15:41,839
reconstruct the underlying data

371
00:15:41,920 --> 00:15:45,199
given just a black box accessed to a

372
00:15:45,199 --> 00:15:48,720
class fair that is the second

373
00:15:48,720 --> 00:15:53,040
attack called the motor inverter attack

374
00:15:53,040 --> 00:15:55,839
in this attack the taggers are given

375
00:15:55,839 --> 00:15:58,320
only the label or names

376
00:15:58,320 --> 00:16:01,600
and access to a model and

377
00:16:01,600 --> 00:16:04,720
that returns a class confidence call

378
00:16:04,720 --> 00:16:08,000
then the corresponding

379
00:16:08,000 --> 00:16:11,600
data can be recovered by the attacker

380
00:16:11,600 --> 00:16:15,279
through continuous import and other port

381
00:16:15,279 --> 00:16:18,320
as i made sure

382
00:16:18,800 --> 00:16:22,320
if the attacker gave a label

383
00:16:22,320 --> 00:16:26,320
named bird the training date uh the

384
00:16:26,320 --> 00:16:28,959
the part in training data will be

385
00:16:28,959 --> 00:16:30,480
recovered

386
00:16:30,480 --> 00:16:34,480
with higher confidence yeah

387
00:16:35,440 --> 00:16:38,639
now back to our work uh in this

388
00:16:38,639 --> 00:16:42,320
uh our presentation we focus on how to

389
00:16:42,320 --> 00:16:42,800
steal

390
00:16:42,800 --> 00:16:46,240
data from model gradients

391
00:16:46,240 --> 00:16:49,360
it's a new type of privacy attack

392
00:16:49,360 --> 00:16:53,040
first we gave a brief introduction

393
00:16:53,040 --> 00:16:56,800
to the gradient which is fundamental to

394
00:16:56,800 --> 00:16:58,880
machine learning

395
00:16:58,880 --> 00:17:01,920
as when uh during training model very

396
00:17:01,920 --> 00:17:02,639
import

397
00:17:02,639 --> 00:17:05,439
the training data to the model and the

398
00:17:05,439 --> 00:17:06,720
get

399
00:17:06,720 --> 00:17:09,199
calculates the difference between the

400
00:17:09,199 --> 00:17:09,760
current

401
00:17:09,760 --> 00:17:13,359
output and the expected output

402
00:17:13,359 --> 00:17:17,280
by a loss function then we back forward

403
00:17:17,280 --> 00:17:21,199
the loss and calculate the gradient

404
00:17:21,199 --> 00:17:25,039
which stores all the partial derivative

405
00:17:25,039 --> 00:17:28,640
information of a multivariable function

406
00:17:28,640 --> 00:17:32,080
to update the parameters of the model

407
00:17:32,080 --> 00:17:35,919
like to give this is a gradient

408
00:17:35,919 --> 00:17:38,320
this is the process of creating a

409
00:17:38,320 --> 00:17:40,080
descent

410
00:17:40,080 --> 00:17:43,280
code and simply we we can take the

411
00:17:43,280 --> 00:17:45,280
gradient as a

412
00:17:45,280 --> 00:17:50,399
meaningless matrix yeah

413
00:17:51,039 --> 00:17:54,160
but we want to steal data

414
00:17:54,160 --> 00:17:57,440
from the gradient before we

415
00:17:57,440 --> 00:18:01,039
introduce our attack mass knowledge

416
00:18:01,039 --> 00:18:04,320
i will explain our

417
00:18:04,320 --> 00:18:07,440
threat model as we know exchanging

418
00:18:07,440 --> 00:18:08,240
gradient

419
00:18:08,240 --> 00:18:11,360
is widely used in multi-node

420
00:18:11,360 --> 00:18:14,240
machine learning system such as

421
00:18:14,240 --> 00:18:15,120
federated

422
00:18:15,120 --> 00:18:18,720
learning people believe that

423
00:18:18,720 --> 00:18:21,919
the model trend in this way can

424
00:18:21,919 --> 00:18:25,039
protect data privacy because the

425
00:18:25,039 --> 00:18:28,799
training data will not be leaked

426
00:18:28,799 --> 00:18:32,639
by gradient exchange

427
00:18:32,799 --> 00:18:35,840
however we will prove that if the

428
00:18:35,840 --> 00:18:37,600
attacker

429
00:18:37,600 --> 00:18:41,600
gets the model gradients

430
00:18:41,600 --> 00:18:44,960
travel still or reconstruct

431
00:18:44,960 --> 00:18:49,200
data from it

432
00:18:49,200 --> 00:18:53,600
so the exchanging gradient

433
00:18:53,600 --> 00:18:56,480
provides a false sense of security

434
00:18:56,480 --> 00:18:59,200
especially when adopting advertiser

435
00:18:59,200 --> 00:19:03,200
training to enhance model robustness

436
00:19:03,200 --> 00:19:08,000
yeah it's an interesting finding

437
00:19:08,000 --> 00:19:11,360
look here is a demo

438
00:19:11,360 --> 00:19:15,679
they initialized a piece of random data

439
00:19:15,679 --> 00:19:19,280
and imported

440
00:19:19,280 --> 00:19:22,480
it into robust model understand the

441
00:19:22,480 --> 00:19:24,559
model to get a

442
00:19:24,559 --> 00:19:28,559
gradient way

443
00:19:28,559 --> 00:19:31,760
the way calculate continuous reduce the

444
00:19:31,760 --> 00:19:34,720
distance between the current gradient

445
00:19:34,720 --> 00:19:35,039
and

446
00:19:35,039 --> 00:19:38,480
the liquid gradient through iterations

447
00:19:38,480 --> 00:19:42,400
so that the random data is optimized

448
00:19:42,400 --> 00:19:45,120
to look very similar to the original

449
00:19:45,120 --> 00:19:46,799
input

450
00:19:46,799 --> 00:19:50,000
from the gif we can say compare

451
00:19:50,000 --> 00:19:53,360
comparing the gradient produced by the

452
00:19:53,360 --> 00:19:56,000
standard model and a robust model

453
00:19:56,000 --> 00:19:58,720
it can be clearly that the robust model

454
00:19:58,720 --> 00:19:59,039
is

455
00:19:59,039 --> 00:20:01,919
more vulnerable under the reconstructed

456
00:20:01,919 --> 00:20:02,960
data

457
00:20:02,960 --> 00:20:06,480
based on it is much clearer

458
00:20:06,480 --> 00:20:10,559
thus we claim that the model robustness

459
00:20:10,559 --> 00:20:13,520
will have a negative impact on data

460
00:20:13,520 --> 00:20:14,240
privacy

461
00:20:14,240 --> 00:20:17,200
in some cases

462
00:20:18,480 --> 00:20:21,600
to prove that we did not come to this

463
00:20:21,600 --> 00:20:22,480
conclusion

464
00:20:22,480 --> 00:20:26,000
by accident we select multiple

465
00:20:26,000 --> 00:20:28,799
modal act architectures and the data

466
00:20:28,799 --> 00:20:30,000
sites

467
00:20:30,000 --> 00:20:32,960
the detailed experimental parameters are

468
00:20:32,960 --> 00:20:33,600
listed

469
00:20:33,600 --> 00:20:38,240
in the table for evaluation metrics

470
00:20:38,240 --> 00:20:41,679
we use psnr mse

471
00:20:41,679 --> 00:20:45,120
and fmse the first two metrics

472
00:20:45,120 --> 00:20:48,240
are used to measure the quality of

473
00:20:48,240 --> 00:20:51,600
data reconstruction and the third is

474
00:20:51,600 --> 00:20:54,559
also to measure the distance between the

475
00:20:54,559 --> 00:20:56,320
reconstructed data

476
00:20:56,320 --> 00:21:00,840
and the original data on the model

477
00:21:00,840 --> 00:21:02,340
prediction

478
00:21:02,340 --> 00:21:04,080
[Music]

479
00:21:04,080 --> 00:21:07,200
the reconstructions are shown in this

480
00:21:07,200 --> 00:21:10,960
slide the first row represents the

481
00:21:10,960 --> 00:21:12,960
original important image

482
00:21:12,960 --> 00:21:15,760
the second row is the reconstruction

483
00:21:15,760 --> 00:21:18,320
from standard model gradient

484
00:21:18,320 --> 00:21:21,039
and the last row is a reconstruction

485
00:21:21,039 --> 00:21:22,400
from robustum

486
00:21:22,400 --> 00:21:26,320
modal gradient we can clearly see that

487
00:21:26,320 --> 00:21:29,120
the variable quality in the third row is

488
00:21:29,120 --> 00:21:31,280
better than the second row

489
00:21:31,280 --> 00:21:33,760
another conclusion is always hold

490
00:21:33,760 --> 00:21:34,880
regardless of

491
00:21:34,880 --> 00:21:38,400
model architectures or data sites

492
00:21:38,400 --> 00:21:41,840
for standard model the reconstructed

493
00:21:41,840 --> 00:21:42,320
data

494
00:21:42,320 --> 00:21:45,679
appears to have more mosaic and

495
00:21:45,679 --> 00:21:49,360
some position information of the mid

496
00:21:49,360 --> 00:21:52,480
is lost for example the

497
00:21:52,480 --> 00:21:55,280
the location of the bird in the

498
00:21:55,280 --> 00:21:56,320
secondary

499
00:21:56,320 --> 00:21:59,679
row is lost on the contrary for a button

500
00:21:59,679 --> 00:22:00,799
model

501
00:22:00,799 --> 00:22:03,840
so reconstruction is much clearer

502
00:22:03,840 --> 00:22:07,039
and the location of object in image

503
00:22:07,039 --> 00:22:10,080
is maintained

504
00:22:11,200 --> 00:22:14,640
from the evaluation matrix the results

505
00:22:14,640 --> 00:22:15,039
tell

506
00:22:15,039 --> 00:22:18,000
us that adversarial training pose a more

507
00:22:18,000 --> 00:22:19,120
serious risk

508
00:22:19,120 --> 00:22:23,199
of privacy leakage

509
00:22:23,919 --> 00:22:26,960
to to illustrate

510
00:22:26,960 --> 00:22:30,159
that this attack is valid for all phases

511
00:22:30,159 --> 00:22:30,480
of

512
00:22:30,480 --> 00:22:33,679
model training we save different states

513
00:22:33,679 --> 00:22:34,799
of the models

514
00:22:34,799 --> 00:22:37,679
and test the attack the blue line and

515
00:22:37,679 --> 00:22:40,000
the orange line represent the natural

516
00:22:40,000 --> 00:22:43,600
and robust accuracy under universal

517
00:22:43,600 --> 00:22:45,440
training respectively

518
00:22:45,440 --> 00:22:48,559
and the green and yellow line

519
00:22:48,559 --> 00:22:50,880
presents the nature and the robust

520
00:22:50,880 --> 00:22:52,320
occurs under

521
00:22:52,320 --> 00:22:54,720
standard training respectively the

522
00:22:54,720 --> 00:22:55,679
x-axis

523
00:22:55,679 --> 00:22:58,240
represents the number of training epochs

524
00:22:58,240 --> 00:23:02,640
and the y-axis in presence accuracy

525
00:23:03,280 --> 00:23:06,960
the attack results for mo for models

526
00:23:06,960 --> 00:23:09,440
with different training stages

527
00:23:09,440 --> 00:23:13,280
stages are shown below this blue

528
00:23:13,280 --> 00:23:15,120
representing the quality of

529
00:23:15,120 --> 00:23:16,799
reconstruction based on

530
00:23:16,799 --> 00:23:19,360
the virtual train adversarial gradient

531
00:23:19,360 --> 00:23:21,440
and the orange representing the quality

532
00:23:21,440 --> 00:23:23,840
of reconstruction based on standard

533
00:23:23,840 --> 00:23:25,039
gradient

534
00:23:25,039 --> 00:23:27,840
it can be clearly synthesized the robust

535
00:23:27,840 --> 00:23:28,720
models are

536
00:23:28,720 --> 00:23:32,080
always more vulnerable regardless of

537
00:23:32,080 --> 00:23:37,840
training stage states or stages

538
00:23:38,159 --> 00:23:41,120
on the other hand we emphasize that the

539
00:23:41,120 --> 00:23:43,360
choice of the initial value of the

540
00:23:43,360 --> 00:23:44,559
target to be

541
00:23:44,559 --> 00:23:48,320
optimized will affect the efficiency

542
00:23:48,320 --> 00:23:50,880
and the effectiveness of the

543
00:23:50,880 --> 00:23:52,480
optimization

544
00:23:52,480 --> 00:23:55,760
thus the quality of data reconstruction

545
00:23:55,760 --> 00:23:59,279
is related to the initialization value

546
00:23:59,279 --> 00:24:02,559
of random data a good reconstruction

547
00:24:02,559 --> 00:24:03,440
stability

548
00:24:03,440 --> 00:24:06,559
can obtain a high quality image

549
00:24:06,559 --> 00:24:10,000
regardless of the initial value

550
00:24:10,000 --> 00:24:13,600
so we selected 10 random numbers

551
00:24:13,600 --> 00:24:17,360
as cs for random data initialization and

552
00:24:17,360 --> 00:24:18,080
the fix

553
00:24:18,080 --> 00:24:20,880
are gradient through attack it can be

554
00:24:20,880 --> 00:24:21,840
seen

555
00:24:21,840 --> 00:24:25,520
that the reconstruction based on the

556
00:24:25,520 --> 00:24:29,039
gradient of the standard model has worse

557
00:24:29,039 --> 00:24:32,559
stability and is more sensitive to the

558
00:24:32,559 --> 00:24:33,919
initial value

559
00:24:33,919 --> 00:24:37,120
in addition it will also cause the loss

560
00:24:37,120 --> 00:24:37,440
of

561
00:24:37,440 --> 00:24:40,720
location information as shown in the

562
00:24:40,720 --> 00:24:44,240
first row on the contrary a better

563
00:24:44,240 --> 00:24:46,400
stability can be obtained

564
00:24:46,400 --> 00:24:49,679
under robust model this confirms the

565
00:24:49,679 --> 00:24:51,200
privacy risk brought

566
00:24:51,200 --> 00:24:56,159
by universal training from another angle

567
00:24:56,799 --> 00:24:59,919
we also try to find a trade-off between

568
00:24:59,919 --> 00:25:00,799
robustness

569
00:25:00,799 --> 00:25:03,760
and privacy so we set different

570
00:25:03,760 --> 00:25:05,200
robustness

571
00:25:05,200 --> 00:25:08,480
parameters to gather the robust models

572
00:25:08,480 --> 00:25:09,679
and the funds that

573
00:25:09,679 --> 00:25:12,640
as robustness increases the quality of

574
00:25:12,640 --> 00:25:14,000
data recovery is

575
00:25:14,000 --> 00:25:17,360
better but when robustness reaches a

576
00:25:17,360 --> 00:25:20,400
threshold the quality of recovery will

577
00:25:20,400 --> 00:25:21,200
decrease

578
00:25:21,200 --> 00:25:23,919
rapidly

579
00:25:24,640 --> 00:25:28,880
last but not least we discussed several

580
00:25:28,880 --> 00:25:32,320
we will give some possible defenses

581
00:25:32,320 --> 00:25:35,440
the first is the differential privacy

582
00:25:35,440 --> 00:25:40,080
which as elaborate noise to the gradient

583
00:25:40,080 --> 00:25:42,240
so that to cover the information

584
00:25:42,240 --> 00:25:43,200
contained in

585
00:25:43,200 --> 00:25:47,039
it however adding noise will reduce the

586
00:25:47,039 --> 00:25:48,960
accuracy of the model

587
00:25:48,960 --> 00:25:51,440
and how to find the balance is a

588
00:25:51,440 --> 00:25:53,039
challenge problem

589
00:25:53,039 --> 00:25:56,080
the second is to use cryptographic

590
00:25:56,080 --> 00:25:59,279
technique to encrypt as an update

591
00:25:59,279 --> 00:26:02,559
even if the hacker hijacks the grading

592
00:26:02,559 --> 00:26:05,520
information the original import cannot

593
00:26:05,520 --> 00:26:05,840
be

594
00:26:05,840 --> 00:26:09,840
recovered from the encrypted information

595
00:26:09,840 --> 00:26:11,840
but

596
00:26:11,840 --> 00:26:15,120
encrypting meanings of parameters at a

597
00:26:15,120 --> 00:26:18,000
german training model will bring an

598
00:26:18,000 --> 00:26:18,799
affordable

599
00:26:18,799 --> 00:26:22,000
computation overhead so

600
00:26:22,000 --> 00:26:25,360
it is a unrealistic

601
00:26:25,360 --> 00:26:27,520
the third possible difference is to

602
00:26:27,520 --> 00:26:29,440
combine standard training

603
00:26:29,440 --> 00:26:32,159
and the adversarial training to design a

604
00:26:32,159 --> 00:26:35,120
privacy preserving algorithm

605
00:26:35,120 --> 00:26:37,279
which can not only enhance the

606
00:26:37,279 --> 00:26:40,080
robustness of the model to defend

607
00:26:40,080 --> 00:26:43,200
universal attacks but also

608
00:26:43,200 --> 00:26:46,799
resist the gradient leakage attack

609
00:26:46,799 --> 00:26:50,400
but as so far there's

610
00:26:50,400 --> 00:26:53,919
no related algorithms so

611
00:26:53,919 --> 00:26:59,679
it will be our future work to design it

612
00:26:59,679 --> 00:27:02,720
finally we have four conclusions

613
00:27:02,720 --> 00:27:05,679
the first is security is still one of

614
00:27:05,679 --> 00:27:06,559
the biggest

615
00:27:06,559 --> 00:27:09,919
challenge challenge in deploying ai

616
00:27:09,919 --> 00:27:11,039
systems

617
00:27:11,039 --> 00:27:14,799
the second is that they list the three

618
00:27:14,799 --> 00:27:18,080
most significant security challenges of

619
00:27:18,080 --> 00:27:21,120
ai the third is that training data

620
00:27:21,120 --> 00:27:24,159
of ai model can be stolen according to

621
00:27:24,159 --> 00:27:25,760
the gradient

622
00:27:25,760 --> 00:27:29,360
and the last is that our ultimate goals

623
00:27:29,360 --> 00:27:31,919
to build the secure and the trustworthy

624
00:27:31,919 --> 00:27:35,760
ai systems

625
00:27:35,760 --> 00:27:38,799
yeah in the appendix we list

626
00:27:38,799 --> 00:27:43,279
some other interesting study of ours

627
00:27:43,279 --> 00:27:46,080
for example

628
00:27:47,440 --> 00:27:51,039
not graphic the information

629
00:27:51,039 --> 00:27:53,440
hiding is one of the important ways to

630
00:27:53,440 --> 00:27:54,480
ensure data

631
00:27:54,480 --> 00:27:57,840
we try to implement a case that image

632
00:27:57,840 --> 00:28:00,399
hiding in another image

633
00:28:00,399 --> 00:28:03,120
and the mosaic recovery where your

634
00:28:03,120 --> 00:28:04,240
sac2sac

635
00:28:04,240 --> 00:28:07,360
model to restore mosaic text

636
00:28:07,360 --> 00:28:10,399
and for esx metrics

637
00:28:10,399 --> 00:28:13,360
we build a ais metrics to provide

638
00:28:13,360 --> 00:28:14,480
developers and

639
00:28:14,480 --> 00:28:16,960
your servers a better guidance on the

640
00:28:16,960 --> 00:28:20,480
security problems of es systems

641
00:28:20,480 --> 00:28:26,000
and for a shredded document

642
00:28:26,320 --> 00:28:28,640
the reconstruction of traded text

643
00:28:28,640 --> 00:28:30,799
documents with metrics

644
00:28:30,799 --> 00:28:34,320
learning are designed

645
00:28:34,320 --> 00:28:37,600
proposed about us yeah so

646
00:28:37,600 --> 00:28:39,679
we are looking for we also looking

647
00:28:39,679 --> 00:28:41,760
forward to sharing more research

648
00:28:41,760 --> 00:28:43,840
progress with all your guests in the

649
00:28:43,840 --> 00:28:46,240
future

650
00:28:46,240 --> 00:28:49,600
so above is all the content

651
00:28:49,600 --> 00:28:52,640
we shared this time if you have any

652
00:28:52,640 --> 00:28:54,880
questions please contact the relevant

653
00:28:54,880 --> 00:28:56,480
email address

654
00:28:56,480 --> 00:28:59,840
thank you guys bye

