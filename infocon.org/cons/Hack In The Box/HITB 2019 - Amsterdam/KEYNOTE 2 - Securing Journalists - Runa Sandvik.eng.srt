1
00:00:19,180 --> 00:00:24,850
good morning thank you for coming I also

2
00:00:23,560 --> 00:00:28,750
want to thank the organizers for

3
00:00:24,850 --> 00:00:32,770
inviting me back to speak again it's

4
00:00:28,750 --> 00:00:34,380
always a pleasure to be here so I'm

5
00:00:32,770 --> 00:00:36,489
going to talk a bit about securing

6
00:00:34,380 --> 00:00:39,520
journalists and the work that we do at

7
00:00:36,489 --> 00:00:43,269
the New York Times some of the work that

8
00:00:39,520 --> 00:00:46,390
we've done with other media works or

9
00:00:43,270 --> 00:00:48,040
with nonprofits in the same space the

10
00:00:46,390 --> 00:00:51,150
challenges that we have and sort of why

11
00:00:48,040 --> 00:00:56,980
and the intersection of media and

12
00:00:51,150 --> 00:01:02,559
security so unique and so fun so I'm

13
00:00:56,980 --> 00:01:05,170
just some quick intro originally from

14
00:01:02,559 --> 00:01:07,230
Oslo Norway I now live in New York City

15
00:01:05,170 --> 00:01:11,470
living in a couple of other places in

16
00:01:07,230 --> 00:01:14,620
between my husband and I hacked a sniper

17
00:01:11,470 --> 00:01:17,010
rifle back in 2015 because it was fun

18
00:01:14,620 --> 00:01:22,420
and it was something that you could do

19
00:01:17,010 --> 00:01:24,820
last year I got a certified in sake

20
00:01:22,420 --> 00:01:28,300
figured it would be a nice hobby outside

21
00:01:24,820 --> 00:01:30,970
of InfoSec and I previously worked on

22
00:01:28,300 --> 00:01:32,560
the Tor project and secure drop and I'm

23
00:01:30,970 --> 00:01:36,030
now the senior director of information

24
00:01:32,560 --> 00:01:38,350
security at the New York Times so the

25
00:01:36,030 --> 00:01:40,660
timeline for sort of the type of work

26
00:01:38,350 --> 00:01:42,669
that I've done is back in 2009 I started

27
00:01:40,660 --> 00:01:44,410
working for the Tor project as part of

28
00:01:42,670 --> 00:01:48,700
Google Summer of Code so back then

29
00:01:44,410 --> 00:01:50,830
Google would give nonprofits works or

30
00:01:48,700 --> 00:01:54,400
projects funding to take on summer

31
00:01:50,830 --> 00:01:56,679
interns so initially I worked for toward

32
00:01:54,400 --> 00:01:58,600
doing research and development and I

33
00:01:56,680 --> 00:02:02,410
sort of stayed on and volunteered to

34
00:01:58,600 --> 00:02:04,990
maintain the project that I took on and

35
00:02:02,410 --> 00:02:07,390
a couple of years in the Tor project I

36
00:02:04,990 --> 00:02:10,508
think this was back in 2011 the Tor

37
00:02:07,390 --> 00:02:12,790
project got funding from if I remember

38
00:02:10,508 --> 00:02:14,859
correctly the State Department to train

39
00:02:12,790 --> 00:02:18,940
reporters so I ended up leading that

40
00:02:14,860 --> 00:02:20,769
project back then traveled to Turkey to

41
00:02:18,940 --> 00:02:23,700
Train reporters they are both local and

42
00:02:20,769 --> 00:02:26,360
foreign reporters in Turkey

43
00:02:23,700 --> 00:02:29,819
and it sort of just spiraled from there

44
00:02:26,360 --> 00:02:33,209
back then people weren't really talking

45
00:02:29,819 --> 00:02:34,679
about securing reporters we talked about

46
00:02:33,209 --> 00:02:39,890
securing in the enterprise we talked

47
00:02:34,680 --> 00:02:42,150
about more traditional traditional

48
00:02:39,890 --> 00:02:44,160
security of you oh but I think then

49
00:02:42,150 --> 00:02:49,800
since then in a more recent years maybe

50
00:02:44,160 --> 00:02:51,090
since like 2015 to today ish we've sort

51
00:02:49,800 --> 00:02:54,349
of started talking a bit more about

52
00:02:51,090 --> 00:02:58,260
securing reporters securing cars

53
00:02:54,349 --> 00:02:59,850
securing healthcare and so we sort of

54
00:02:58,260 --> 00:03:02,399
seen this like space develop where we

55
00:02:59,850 --> 00:03:04,799
you have these sort of niche areas of

56
00:03:02,400 --> 00:03:07,799
securing a thing that is very unique

57
00:03:04,799 --> 00:03:10,380
very specific that has challenges that

58
00:03:07,799 --> 00:03:12,900
you don't necessarily see elsewhere and

59
00:03:10,380 --> 00:03:15,329
so from the work that I did with tor I

60
00:03:12,900 --> 00:03:18,739
worked for free freedom of the press

61
00:03:15,330 --> 00:03:22,530
with secure drop which is this

62
00:03:18,739 --> 00:03:24,180
whistleblowing system that allows media

63
00:03:22,530 --> 00:03:26,580
words for a while anyone who sets out

64
00:03:24,180 --> 00:03:30,090
the system to anonymously receive tips

65
00:03:26,580 --> 00:03:31,620
from the public so I think I forget the

66
00:03:30,090 --> 00:03:33,420
number I want to say there's around 30

67
00:03:31,620 --> 00:03:38,100
orgs I'd have that system set up today

68
00:03:33,420 --> 00:03:40,679
and we are one of them so initially I

69
00:03:38,100 --> 00:03:42,420
was then hired to do security just for

70
00:03:40,680 --> 00:03:45,030
the newsroom that was her the scope of

71
00:03:42,420 --> 00:03:46,619
my role then over the past three years

72
00:03:45,030 --> 00:03:49,200
we've sort of had a change in leadership

73
00:03:46,620 --> 00:03:50,760
change in people on the team so my role

74
00:03:49,200 --> 00:03:52,890
has sort of expanded to be not just

75
00:03:50,760 --> 00:03:54,450
security but take the work that I'm

76
00:03:52,890 --> 00:03:56,790
doing there and really expand it to the

77
00:03:54,450 --> 00:03:58,380
rest of the org as well which I think

78
00:03:56,790 --> 00:04:01,048
makes a lot of sense because you now

79
00:03:58,380 --> 00:04:04,709
have you have a number of different

80
00:04:01,049 --> 00:04:07,890
teams that do different but sort of

81
00:04:04,709 --> 00:04:09,239
overlapping work in the context of the

82
00:04:07,890 --> 00:04:11,819
newsroom so you have information

83
00:04:09,239 --> 00:04:13,049
security that does a lot of stuff on the

84
00:04:11,819 --> 00:04:15,660
enterprise side of the company or the

85
00:04:13,049 --> 00:04:16,829
business side of the company but also

86
00:04:15,660 --> 00:04:19,228
something in the newsroom

87
00:04:16,829 --> 00:04:20,880
you have physical security again that

88
00:04:19,228 --> 00:04:23,669
they deal with facilities they deal with

89
00:04:20,880 --> 00:04:25,830
the physical security of executives they

90
00:04:23,669 --> 00:04:28,020
deal with a lot of other sort of groups

91
00:04:25,830 --> 00:04:28,530
of staff but they also work in the

92
00:04:28,020 --> 00:04:31,849
newsroom

93
00:04:28,530 --> 00:04:36,119
so what we're now doing is that we have

94
00:04:31,849 --> 00:04:37,200
cross team collaboration in ways in

95
00:04:36,120 --> 00:04:39,450
which that

96
00:04:37,200 --> 00:04:42,539
three four plus years ago we didn't have

97
00:04:39,450 --> 00:04:46,979
them but I will get back to that in a

98
00:04:42,540 --> 00:04:48,720
bit so yeah I'm gonna talk a bit more

99
00:04:46,980 --> 00:04:50,550
about sort of threat models in the

100
00:04:48,720 --> 00:04:53,880
context of media what is it that we see

101
00:04:50,550 --> 00:04:58,460
that I think is a bit unique to the

102
00:04:53,880 --> 00:05:01,140
space some of the challenges ensuring

103
00:04:58,460 --> 00:05:03,560
the safety of the people that we protect

104
00:05:01,140 --> 00:05:08,750
it's sort of one thing to secure a

105
00:05:03,560 --> 00:05:11,340
twitter account or your G Suites the

106
00:05:08,750 --> 00:05:13,560
deployment then securing the

107
00:05:11,340 --> 00:05:16,650
communication between a reporter and a

108
00:05:13,560 --> 00:05:18,780
source when you are not really in a

109
00:05:16,650 --> 00:05:20,729
position to enforce any security

110
00:05:18,780 --> 00:05:25,369
settings when you can drive the

111
00:05:20,730 --> 00:05:29,370
conversation talked a bit about how to

112
00:05:25,370 --> 00:05:33,150
evaluate the capabilities of your threat

113
00:05:29,370 --> 00:05:34,860
actors so in the context of security and

114
00:05:33,150 --> 00:05:37,919
especially when we talk about reporters

115
00:05:34,860 --> 00:05:39,990
or individuals we also talk about threat

116
00:05:37,920 --> 00:05:42,480
modeling you sort of have to know who's

117
00:05:39,990 --> 00:05:44,070
interested in the data that you have the

118
00:05:42,480 --> 00:05:46,920
reason which that they could get it to

119
00:05:44,070 --> 00:05:48,390
what they would be willing to do so I'll

120
00:05:46,920 --> 00:05:51,240
talk a bit about how we do that as well

121
00:05:48,390 --> 00:05:52,830
and then talk a bit about the sort of

122
00:05:51,240 --> 00:05:55,160
work that we've done over the past three

123
00:05:52,830 --> 00:05:58,010
years to really build a culture of

124
00:05:55,160 --> 00:06:03,930
security and then how we can take

125
00:05:58,010 --> 00:06:10,349
lessons learned at the times to support

126
00:06:03,930 --> 00:06:13,970
and empower media works elsewhere just

127
00:06:10,350 --> 00:06:13,970
make sure I get some water over here

128
00:06:32,930 --> 00:06:43,920
okay cool so if you haven't worked a lot

129
00:06:39,270 --> 00:06:46,530
with a newsroom Saussure a couple of

130
00:06:43,920 --> 00:06:48,420
different things that I always expected

131
00:06:46,530 --> 00:06:50,210
walking into the New York Times that I

132
00:06:48,420 --> 00:06:52,800
never really found

133
00:06:50,210 --> 00:06:54,710
the newsroom is a very dead Ryan

134
00:06:52,800 --> 00:06:57,990
deadline-driven and product-focused

135
00:06:54,710 --> 00:07:01,229
meaning at the end of the day the goal

136
00:06:57,990 --> 00:07:02,820
is to get the story out on time towards

137
00:07:01,230 --> 00:07:08,040
the end of the day around like 4 or 5

138
00:07:02,820 --> 00:07:09,510
o'clock that's when in most cases the

139
00:07:08,040 --> 00:07:11,820
reporters are expected to deliver

140
00:07:09,510 --> 00:07:14,430
whatever story they were they set out to

141
00:07:11,820 --> 00:07:15,960
write that day whether that was a story

142
00:07:14,430 --> 00:07:19,980
they came up with because something

143
00:07:15,960 --> 00:07:23,099
happened on their desk or they were

144
00:07:19,980 --> 00:07:25,470
assigned a story earlier in the day by

145
00:07:23,100 --> 00:07:30,420
their editor like that sort of deadline

146
00:07:25,470 --> 00:07:31,740
time basically and the main goal what

147
00:07:30,420 --> 00:07:33,600
the newsroom really cares about is

148
00:07:31,740 --> 00:07:35,130
getting that story out the door we can't

149
00:07:33,600 --> 00:07:37,200
have a state where we don't have any

150
00:07:35,130 --> 00:07:38,520
stories ready or where tomorrow the

151
00:07:37,200 --> 00:07:40,380
front page of the New York Times is

152
00:07:38,520 --> 00:07:41,729
blank we always have to get something

153
00:07:40,380 --> 00:07:44,640
out we always have to have to get that

154
00:07:41,730 --> 00:07:46,350
story out so the idea that something

155
00:07:44,640 --> 00:07:49,860
like information security should ever

156
00:07:46,350 --> 00:07:52,170
block us getting a story out it's just

157
00:07:49,860 --> 00:07:54,330
not that's just not a discussion it's

158
00:07:52,170 --> 00:07:56,480
not a topic which means that in some

159
00:07:54,330 --> 00:07:59,550
cases we may find ourselves in

160
00:07:56,480 --> 00:08:02,580
discussions where we have to for a short

161
00:07:59,550 --> 00:08:05,340
period of time except less security and

162
00:08:02,580 --> 00:08:07,979
more risk to ensure that the story is

163
00:08:05,340 --> 00:08:09,630
published so there's a sort of some of

164
00:08:07,980 --> 00:08:11,730
the interesting discussions that we have

165
00:08:09,630 --> 00:08:16,130
to have where it's very very clear that

166
00:08:11,730 --> 00:08:18,660
we cannot block the work that happens

167
00:08:16,130 --> 00:08:22,380
now we're journalists file for more than

168
00:08:18,660 --> 00:08:23,580
150 150 countries each year which means

169
00:08:22,380 --> 00:08:25,590
that you have reporters that are

170
00:08:23,580 --> 00:08:28,289
traveling at any point in time you have

171
00:08:25,590 --> 00:08:30,090
reporters that are based in different

172
00:08:28,290 --> 00:08:32,330
countries so I think that if I remember

173
00:08:30,090 --> 00:08:35,159
correctly we have like something like 23

174
00:08:32,330 --> 00:08:41,000
foreign bureaus so we have a bureau in

175
00:08:35,159 --> 00:08:44,098
Moscow Berlin London Hong Kong Paris

176
00:08:41,000 --> 00:08:46,110
Beijing Shanghai and we also have

177
00:08:44,099 --> 00:08:47,850
reporters going in and out of very

178
00:08:46,110 --> 00:08:49,950
high-risk countries we do have someone

179
00:08:47,850 --> 00:08:52,020
currently based in Iran we have people

180
00:08:49,950 --> 00:08:55,140
going in and out of Syria so you have

181
00:08:52,020 --> 00:08:56,490
people that are like remote and also

182
00:08:55,140 --> 00:08:58,319
traveling and traveling in high-risk

183
00:08:56,490 --> 00:09:00,900
countries and somehow you go to find a

184
00:08:58,320 --> 00:09:03,300
way to secure those people as well and

185
00:09:00,900 --> 00:09:04,770
whatever it is that the day are up to

186
00:09:03,300 --> 00:09:08,650
right

187
00:09:04,770 --> 00:09:13,120
we have a newsroom that has to click on

188
00:09:08,650 --> 00:09:15,130
links and open attachments so depending

189
00:09:13,120 --> 00:09:17,830
on who you ask in this community in

190
00:09:15,130 --> 00:09:19,810
information security you will get this

191
00:09:17,830 --> 00:09:21,340
advice that you should never open an

192
00:09:19,810 --> 00:09:23,130
email or click on a link or open an

193
00:09:21,340 --> 00:09:26,440
attachment from someone you don't know

194
00:09:23,130 --> 00:09:28,210
in the newsroom context that doesn't

195
00:09:26,440 --> 00:09:30,460
work because they get their information

196
00:09:28,210 --> 00:09:31,930
from people they don't know they have to

197
00:09:30,460 --> 00:09:34,480
click on these links they have to open

198
00:09:31,930 --> 00:09:36,870
these emails which means that our job is

199
00:09:34,480 --> 00:09:39,190
now how can you empower someone to do so

200
00:09:36,870 --> 00:09:41,050
securely are there tools that you can

201
00:09:39,190 --> 00:09:43,510
deploy that will allow them to do this

202
00:09:41,050 --> 00:09:46,569
is there training that you can roll out

203
00:09:43,510 --> 00:09:48,189
that will help them understand what to

204
00:09:46,570 --> 00:09:50,470
do and what not to throw even what to

205
00:09:48,190 --> 00:09:52,090
look for when they open amo are there

206
00:09:50,470 --> 00:09:55,600
ways in which that you can like empower

207
00:09:52,090 --> 00:10:01,600
them to minimize that risk knowing that

208
00:09:55,600 --> 00:10:03,580
it's still going to be a risk so with

209
00:10:01,600 --> 00:10:07,990
that the solutions that we create have

210
00:10:03,580 --> 00:10:10,390
to be usable and reliable so before I

211
00:10:07,990 --> 00:10:12,940
came to the times I was I was sort of

212
00:10:10,390 --> 00:10:16,030
doing a lot of consulting work workshops

213
00:10:12,940 --> 00:10:19,690
public speaking training of reporters in

214
00:10:16,030 --> 00:10:22,060
the UK and Norway and so one thing that

215
00:10:19,690 --> 00:10:23,770
I was doing as part of that just for

216
00:10:22,060 --> 00:10:25,930
myself was that I would come up with

217
00:10:23,770 --> 00:10:28,600
these sort of scenarios that our

218
00:10:25,930 --> 00:10:30,489
reporter might have and then figure out

219
00:10:28,600 --> 00:10:32,740
how I would secure them or in that case

220
00:10:30,490 --> 00:10:34,600
myself and sort of really just try it

221
00:10:32,740 --> 00:10:36,850
out to see how well it worked or didn't

222
00:10:34,600 --> 00:10:41,560
work so one thing that I did a lot of

223
00:10:36,850 --> 00:10:43,120
back then was travel security so I would

224
00:10:41,560 --> 00:10:44,650
have a travel laptop and I would have a

225
00:10:43,120 --> 00:10:45,790
travel phone and I would really sort of

226
00:10:44,650 --> 00:10:48,310
think about the different types of

227
00:10:45,790 --> 00:10:51,189
advice that we would give reporters or

228
00:10:48,310 --> 00:10:53,739
high-risk folks and just see how well

229
00:10:51,190 --> 00:10:56,590
that advice would work for myself and I

230
00:10:53,740 --> 00:10:58,450
found that you can you can absolutely go

231
00:10:56,590 --> 00:11:01,480
so far on the scale that you are very

232
00:10:58,450 --> 00:11:03,430
secure but it's not very usable so if

233
00:11:01,480 --> 00:11:06,390
you find yourself in a situation where

234
00:11:03,430 --> 00:11:09,280
you have to send an email really quickly

235
00:11:06,390 --> 00:11:11,080
you're going to be out of luck versus

236
00:11:09,280 --> 00:11:12,490
you can go so far on the usable side

237
00:11:11,080 --> 00:11:14,680
that you can send an email very quickly

238
00:11:12,490 --> 00:11:17,290
but it may not be as secure as you would

239
00:11:14,680 --> 00:11:18,420
like and so somewhere on that line there

240
00:11:17,290 --> 00:11:21,160
is a balance

241
00:11:18,420 --> 00:11:23,890
between what is usable what is secure

242
00:11:21,160 --> 00:11:27,699
and what's going to work for you or for

243
00:11:23,890 --> 00:11:29,380
the reporter at that point in time there

244
00:11:27,700 --> 00:11:31,210
are various systems that we certainly

245
00:11:29,380 --> 00:11:34,470
could use in the newsroom lake cubes

246
00:11:31,210 --> 00:11:37,270
which is from a technical perspective

247
00:11:34,470 --> 00:11:41,590
incredibly neat and I would also say

248
00:11:37,270 --> 00:11:44,949
secure but from a usable perspective for

249
00:11:41,590 --> 00:11:46,540
a non-technical user they may not be the

250
00:11:44,950 --> 00:11:48,700
best so maybe that's a system that we

251
00:11:46,540 --> 00:11:51,390
can leverage in a very different context

252
00:11:48,700 --> 00:11:53,950
maybe it's something that we use for a

253
00:11:51,390 --> 00:11:56,680
pointing time project with people that

254
00:11:53,950 --> 00:11:58,960
do have some tech background where we

255
00:11:56,680 --> 00:12:00,670
have dedicated support to ensure that if

256
00:11:58,960 --> 00:12:03,250
they need help they have that quickly

257
00:12:00,670 --> 00:12:06,000
and they don't have to wait for someone

258
00:12:03,250 --> 00:12:08,140
to respond to an email three days later

259
00:12:06,000 --> 00:12:09,550
and things like that so there are ways

260
00:12:08,140 --> 00:12:12,819
in which that we can leverage solutions

261
00:12:09,550 --> 00:12:15,250
that are more secure than usable but at

262
00:12:12,820 --> 00:12:16,930
that point you have to then consider the

263
00:12:15,250 --> 00:12:20,050
level of support the time it's going to

264
00:12:16,930 --> 00:12:22,180
take the requirement that you would have

265
00:12:20,050 --> 00:12:25,150
for the people from the newsroom using

266
00:12:22,180 --> 00:12:26,709
the system and cetera so it's really a

267
00:12:25,150 --> 00:12:27,959
long list but we do try and figure that

268
00:12:26,710 --> 00:12:31,300
out

269
00:12:27,960 --> 00:12:36,730
it's really going back a bit to the

270
00:12:31,300 --> 00:12:42,160
email example if you are trying to

271
00:12:36,730 --> 00:12:44,110
empower someone and to securely I should

272
00:12:42,160 --> 00:12:45,310
say securely open open their email and

273
00:12:44,110 --> 00:12:46,900
click on these links from people that

274
00:12:45,310 --> 00:12:49,170
they don't know there aren't a whole lot

275
00:12:46,900 --> 00:12:55,329
of technical solutions out there that

276
00:12:49,170 --> 00:12:57,040
ensures that they have that they can do

277
00:12:55,330 --> 00:12:59,320
that without taking on any amount of

278
00:12:57,040 --> 00:13:03,069
risk there are some solutions out there

279
00:12:59,320 --> 00:13:04,480
that can check the email that can vet

280
00:13:03,070 --> 00:13:06,520
the link but at that point you're

281
00:13:04,480 --> 00:13:08,200
talking privacy and potentially security

282
00:13:06,520 --> 00:13:09,579
concerns on top of that as well so

283
00:13:08,200 --> 00:13:10,960
there's sort of like some balance

284
00:13:09,580 --> 00:13:12,370
between the technical tools and the

285
00:13:10,960 --> 00:13:15,750
knowledge you want to give the newsroom

286
00:13:12,370 --> 00:13:18,120
and we focus a whole lot on awareness

287
00:13:15,750 --> 00:13:20,530
relationship building and building trust

288
00:13:18,120 --> 00:13:21,730
because ultimately reporters are going

289
00:13:20,530 --> 00:13:25,319
to find themselves in a whole lot of

290
00:13:21,730 --> 00:13:26,830
weird situations whether it's travel

291
00:13:25,320 --> 00:13:29,920
communicating with their source

292
00:13:26,830 --> 00:13:30,610
receiving a document that they've never

293
00:13:29,920 --> 00:13:32,329
seen before

294
00:13:30,610 --> 00:13:35,480
getting a link for

295
00:13:32,330 --> 00:13:38,090
some random source and be to some extent

296
00:13:35,480 --> 00:13:41,300
need to rely on them to do the right

297
00:13:38,090 --> 00:13:43,160
thing and to loop us in at the right

298
00:13:41,300 --> 00:13:45,380
point in time and you're not going to

299
00:13:43,160 --> 00:13:47,719
get that chain without building trust

300
00:13:45,380 --> 00:13:53,060
and doing a lot of awareness-raising in

301
00:13:47,720 --> 00:13:54,170
the newsroom now get back to a bit of

302
00:13:53,060 --> 00:13:59,689
that as well

303
00:13:54,170 --> 00:14:02,780
let's see cool so I touched on some of

304
00:13:59,690 --> 00:14:04,040
this but so in the in the newsroom so

305
00:14:02,780 --> 00:14:07,550
the newsroom of the New York Times is

306
00:14:04,040 --> 00:14:11,500
around 1,500 people today I think it's

307
00:14:07,550 --> 00:14:14,839
gonna be about 1600 by year and I think

308
00:14:11,500 --> 00:14:18,710
1200 of those are reporters and then you

309
00:14:14,840 --> 00:14:20,060
got news admin support staff we got some

310
00:14:18,710 --> 00:14:23,660
dedicated training staff for the

311
00:14:20,060 --> 00:14:25,160
newsroom editors and sort of other

312
00:14:23,660 --> 00:14:29,030
groups of people that will timidly

313
00:14:25,160 --> 00:14:32,329
support the work that the reporters are

314
00:14:29,030 --> 00:14:36,199
doing and from there you have the

315
00:14:32,330 --> 00:14:39,260
concept of desks so international as a

316
00:14:36,200 --> 00:14:43,310
desk Metro which writes about New York

317
00:14:39,260 --> 00:14:47,090
in New York City is a desk science is a

318
00:14:43,310 --> 00:14:51,829
desk and we've got a bunch of different

319
00:14:47,090 --> 00:14:54,800
bureaus now individuals desks and

320
00:14:51,830 --> 00:14:57,440
bureaus are all going to have different

321
00:14:54,800 --> 00:14:59,420
threats and concerns so someone who

322
00:14:57,440 --> 00:15:01,580
works on investigations is going to have

323
00:14:59,420 --> 00:15:04,400
different requirements than someone who

324
00:15:01,580 --> 00:15:07,370
works on obituaries for example the

325
00:15:04,400 --> 00:15:10,939
person working on investigations may

326
00:15:07,370 --> 00:15:15,010
need security communications may need

327
00:15:10,940 --> 00:15:18,290
encrypted email may need a way to speak

328
00:15:15,010 --> 00:15:21,860
outside of the corporate email messaging

329
00:15:18,290 --> 00:15:26,719
setup may need a travel laptop travel

330
00:15:21,860 --> 00:15:30,170
phone know how to vet documents that

331
00:15:26,720 --> 00:15:33,940
they're getting from sources and the

332
00:15:30,170 --> 00:15:35,900
government for example versus obituaries

333
00:15:33,940 --> 00:15:38,450
potentially just need the sort of

334
00:15:35,900 --> 00:15:40,130
baseline security for securing email

335
00:15:38,450 --> 00:15:42,030
accounts with a password manager and

336
00:15:40,130 --> 00:15:44,010
two-factor authentication

337
00:15:42,030 --> 00:15:45,990
and get a reminder to keep their

338
00:15:44,010 --> 00:15:47,490
software up-to-date they may not

339
00:15:45,990 --> 00:15:51,150
necessarily need all of these other

340
00:15:47,490 --> 00:15:55,230
things that investigations needs so it

341
00:15:51,150 --> 00:15:57,360
would be I don't think it would go over

342
00:15:55,230 --> 00:16:00,380
a while if we were to just roll out this

343
00:15:57,360 --> 00:16:03,300
super intensive slightly paranoid

344
00:16:00,380 --> 00:16:05,250
awareness scheme to the entire newsroom

345
00:16:03,300 --> 00:16:08,250
when only a portion of staff actually

346
00:16:05,250 --> 00:16:09,840
need that same with the bureau's Moscow

347
00:16:08,250 --> 00:16:14,250
is going to have very different security

348
00:16:09,840 --> 00:16:16,080
concerns than say la for example and

349
00:16:14,250 --> 00:16:18,620
we're talking not just digital but also

350
00:16:16,080 --> 00:16:20,610
physical security I think there are

351
00:16:18,620 --> 00:16:23,960
considerations that you'd make for a

352
00:16:20,610 --> 00:16:27,660
bureau in say Moscow than you would in

353
00:16:23,960 --> 00:16:29,430
LA but these are sort of the many

354
00:16:27,660 --> 00:16:31,319
different sort of layers that we have to

355
00:16:29,430 --> 00:16:34,500
consider when we think about how we roll

356
00:16:31,320 --> 00:16:39,030
out the different features that that we

357
00:16:34,500 --> 00:16:41,030
want to offer so different individuals

358
00:16:39,030 --> 00:16:43,050
will have different levels of comfort or

359
00:16:41,030 --> 00:16:45,870
knowledge so you have to look very

360
00:16:43,050 --> 00:16:48,000
quickly in a conversation figure out do

361
00:16:45,870 --> 00:16:50,340
they know about passwords two-factor do

362
00:16:48,000 --> 00:16:51,990
they know that they should keep software

363
00:16:50,340 --> 00:16:54,630
up-to-date and sort of figure out where

364
00:16:51,990 --> 00:16:57,120
we can start in the conversation which

365
00:16:54,630 --> 00:16:58,350
is sort of fine if you're one on one if

366
00:16:57,120 --> 00:17:00,330
you're in a big group of people though

367
00:16:58,350 --> 00:17:02,940
that becomes a bit more challenging if

368
00:17:00,330 --> 00:17:07,800
you're trying to tailor your content to

369
00:17:02,940 --> 00:17:09,540
the majority of the audience they all

370
00:17:07,800 --> 00:17:13,609
have different workflows and day to day

371
00:17:09,540 --> 00:17:16,020
schedules I frequently have reporters

372
00:17:13,609 --> 00:17:18,000
canceling last-minute or just no showing

373
00:17:16,020 --> 00:17:20,129
two meetings with me because something

374
00:17:18,000 --> 00:17:22,290
else popped up breaking news some

375
00:17:20,130 --> 00:17:23,610
different story a source sent something

376
00:17:22,290 --> 00:17:25,889
that they thought would be interesting

377
00:17:23,609 --> 00:17:28,169
they were so into writing their story

378
00:17:25,890 --> 00:17:29,580
that they lost track of time that

379
00:17:28,170 --> 00:17:31,590
happens and we just have to accommodate

380
00:17:29,580 --> 00:17:34,139
for that it can be frustrating when

381
00:17:31,590 --> 00:17:36,270
people no-show when you may time out of

382
00:17:34,140 --> 00:17:44,240
your day to meet with them yes but that

383
00:17:36,270 --> 00:17:44,240
is also a part of the work and

384
00:17:44,470 --> 00:17:50,000
finally reporters frequently use a mix

385
00:17:47,450 --> 00:17:52,160
of personal and corporate accounts which

386
00:17:50,000 --> 00:17:53,870
i think is one of the biggest challenges

387
00:17:52,160 --> 00:17:56,720
that we have when it comes to securing a

388
00:17:53,870 --> 00:17:58,300
newsroom and I would say that it's fine

389
00:17:56,720 --> 00:18:01,640
for a reporter this would absolutely

390
00:17:58,300 --> 00:18:03,350
continue to do that we have sources in

391
00:18:01,640 --> 00:18:06,110
some cases that just straight up say I

392
00:18:03,350 --> 00:18:09,590
will not communicate with you on your

393
00:18:06,110 --> 00:18:11,209
corporate email for whatever reason

394
00:18:09,590 --> 00:18:13,970
maybe they don't like Google a lot of

395
00:18:11,210 --> 00:18:18,470
media works use Google these days maybe

396
00:18:13,970 --> 00:18:20,270
they trust another platform maybe they

397
00:18:18,470 --> 00:18:22,910
are familiar with the types of

398
00:18:20,270 --> 00:18:26,420
enterprise controls that you typically

399
00:18:22,910 --> 00:18:28,910
have on email and they just want to

400
00:18:26,420 --> 00:18:31,520
avoid that there could be like a number

401
00:18:28,910 --> 00:18:33,290
of different reasons but the reporter

402
00:18:31,520 --> 00:18:35,660
will always meet the source where their

403
00:18:33,290 --> 00:18:38,180
ad so if the source is saying actually I

404
00:18:35,660 --> 00:18:40,190
want to speak over here I want to use

405
00:18:38,180 --> 00:18:43,280
this app or I want to use this type of

406
00:18:40,190 --> 00:18:46,130
email service or I want to communicate

407
00:18:43,280 --> 00:18:48,560
through letters that we leave in Central

408
00:18:46,130 --> 00:18:50,270
Park at random points in time ultimately

409
00:18:48,560 --> 00:18:52,010
that is what the journalist is going to

410
00:18:50,270 --> 00:18:54,110
do which means that that is something

411
00:18:52,010 --> 00:18:55,400
that we have to be able to support so

412
00:18:54,110 --> 00:18:58,310
again that goes back to the awareness

413
00:18:55,400 --> 00:19:00,290
raising and empowerment and giving them

414
00:18:58,310 --> 00:19:02,120
the tools that they need to secure their

415
00:19:00,290 --> 00:19:03,740
own accounts I can't enforce the

416
00:19:02,120 --> 00:19:06,229
security of someone's personal twitter

417
00:19:03,740 --> 00:19:08,210
account I can teach them how to set it

418
00:19:06,230 --> 00:19:10,340
up I can help them understand why it's

419
00:19:08,210 --> 00:19:13,040
really important but at the end of the

420
00:19:10,340 --> 00:19:15,439
day it is it is on the reporter to take

421
00:19:13,040 --> 00:19:20,990
those steps and to come ask when they're

422
00:19:15,440 --> 00:19:23,600
when they're not sure so that is a lot

423
00:19:20,990 --> 00:19:24,770
of challenges and I would say a lot of

424
00:19:23,600 --> 00:19:26,810
fun that's sort of one of the things

425
00:19:24,770 --> 00:19:29,480
that I that I personally love about the

426
00:19:26,810 --> 00:19:32,570
work that I do is that I see all of this

427
00:19:29,480 --> 00:19:34,730
as just one big puzzle and I love

428
00:19:32,570 --> 00:19:36,260
puzzles I love trying to figure out the

429
00:19:34,730 --> 00:19:38,570
many ways in which that you can solve a

430
00:19:36,260 --> 00:19:40,160
problem the many ways in which that

431
00:19:38,570 --> 00:19:41,929
something can go wrong and really sort

432
00:19:40,160 --> 00:19:46,640
of come up with that perfect balance

433
00:19:41,930 --> 00:19:48,680
between usable and secure so I included

434
00:19:46,640 --> 00:19:52,220
two use cases that I think will just

435
00:19:48,680 --> 00:19:54,549
highlight what I just talked about where

436
00:19:52,220 --> 00:19:56,299
one is

437
00:19:54,549 --> 00:19:59,629
let's say that we're just going to

438
00:19:56,299 --> 00:20:01,970
secure the main account on Twitter so

439
00:19:59,629 --> 00:20:05,119
it's a corporate account we have a team

440
00:20:01,970 --> 00:20:07,940
that's very responsive and work very

441
00:20:05,119 --> 00:20:10,399
closely with us so if we wanted to

442
00:20:07,940 --> 00:20:12,049
secure that account we already start

443
00:20:10,399 --> 00:20:16,070
with considering the ways in which that

444
00:20:12,049 --> 00:20:19,460
the account can be hacked which can be

445
00:20:16,070 --> 00:20:22,820
something like let's say that plain

446
00:20:19,460 --> 00:20:25,759
account no two-factor password is

447
00:20:22,820 --> 00:20:28,970
password guessing that password would be

448
00:20:25,759 --> 00:20:32,090
fairly easy so we can ensure that they

449
00:20:28,970 --> 00:20:34,369
have a strong unique password at which

450
00:20:32,090 --> 00:20:36,678
point you could you can still guess it

451
00:20:34,369 --> 00:20:38,449
not very likely but let's say that

452
00:20:36,679 --> 00:20:41,840
that's possible

453
00:20:38,450 --> 00:20:44,389
you can successfully fish someone with

454
00:20:41,840 --> 00:20:47,570
access to the account okay and we can

455
00:20:44,389 --> 00:20:48,949
add two factor to the account at which

456
00:20:47,570 --> 00:20:50,330
point you'd have to get the past for the

457
00:20:48,950 --> 00:20:56,570
two-factor code and then get into the

458
00:20:50,330 --> 00:20:58,970
account you can get access through a

459
00:20:56,570 --> 00:21:01,309
third-party integration at which point

460
00:20:58,970 --> 00:21:03,409
we can say okay let's just limit the use

461
00:21:01,309 --> 00:21:06,259
of third-party integrations either we

462
00:21:03,409 --> 00:21:08,450
can say let's just not let's agree to

463
00:21:06,259 --> 00:21:11,240
just not use the month at all and let us

464
00:21:08,450 --> 00:21:16,009
know if that has to change or we can say

465
00:21:11,240 --> 00:21:19,220
we trust these three you can add those

466
00:21:16,009 --> 00:21:22,279
if you need to use something else let us

467
00:21:19,220 --> 00:21:25,970
know and we can review which ones you

468
00:21:22,279 --> 00:21:28,159
want to add then you've got the context

469
00:21:25,970 --> 00:21:32,210
of DMS if someone makes it into your

470
00:21:28,159 --> 00:21:34,759
Twitter account you're not going to know

471
00:21:32,210 --> 00:21:40,210
the steps that they take unless you see

472
00:21:34,759 --> 00:21:42,710
it so if they follow unfollow or tweet

473
00:21:40,210 --> 00:21:44,509
you're not going to necessarily see the

474
00:21:42,710 --> 00:21:46,639
actions that they take which means that

475
00:21:44,509 --> 00:21:49,279
if they just read all the DMS that you

476
00:21:46,639 --> 00:21:55,668
have you're not going to know that they

477
00:21:49,279 --> 00:21:57,889
did that so then to limit the exposure I

478
00:21:55,669 --> 00:22:00,740
should say or the risk of someone just

479
00:21:57,889 --> 00:22:03,049
silently reading all the DMS that you

480
00:22:00,740 --> 00:22:04,700
have associated with your account we can

481
00:22:03,049 --> 00:22:08,240
as you can just say that

482
00:22:04,700 --> 00:22:10,580
we limits how and when the account is

483
00:22:08,240 --> 00:22:14,600
used for games if it is used for games

484
00:22:10,580 --> 00:22:21,620
at all so there are some services that

485
00:22:14,600 --> 00:22:23,719
offer DMS for support for example I

486
00:22:21,620 --> 00:22:28,100
recently had to deal with an airline

487
00:22:23,720 --> 00:22:30,080
about my frequent flyer miles and i DM

488
00:22:28,100 --> 00:22:31,399
them for support and they responded

489
00:22:30,080 --> 00:22:33,800
saying here just give us your full name

490
00:22:31,400 --> 00:22:36,260
your date of birth and your address and

491
00:22:33,800 --> 00:22:37,909
I said no thank you I'm gonna call

492
00:22:36,260 --> 00:22:40,520
instead because if I give that

493
00:22:37,910 --> 00:22:43,580
information via DM and their their

494
00:22:40,520 --> 00:22:45,080
Twitter account is hacked someone's

495
00:22:43,580 --> 00:22:47,000
gonna have access to a whole lot of

496
00:22:45,080 --> 00:22:50,629
personal data there's no sitting inside

497
00:22:47,000 --> 00:22:52,280
of their DMS and I want to avoid that

498
00:22:50,630 --> 00:22:54,050
type of scenario for the newsroom

499
00:22:52,280 --> 00:22:56,780
so we'd sort of come up with some

500
00:22:54,050 --> 00:23:00,169
guidelines or rules that make sense for

501
00:22:56,780 --> 00:23:05,020
us and then what we've also done and

502
00:23:00,170 --> 00:23:09,590
Twitter has really ramped up in the last

503
00:23:05,020 --> 00:23:17,120
six months I would say is providing sort

504
00:23:09,590 --> 00:23:19,970
of VIP urgent assistance to larger maybe

505
00:23:17,120 --> 00:23:22,729
high-risk orgs so we now have an

506
00:23:19,970 --> 00:23:24,710
escalation channel - Twitter's or if

507
00:23:22,730 --> 00:23:27,920
something were to happen either with any

508
00:23:24,710 --> 00:23:30,970
of our corporate accounts or with VIP

509
00:23:27,920 --> 00:23:37,220
accounts that we monitor we will get

510
00:23:30,970 --> 00:23:39,530
faster support and faster response than

511
00:23:37,220 --> 00:23:42,140
we perhaps otherwise would get which i

512
00:23:39,530 --> 00:23:45,710
think is super super helpful and I think

513
00:23:42,140 --> 00:23:47,750
that is something that we will need on

514
00:23:45,710 --> 00:23:49,070
other platforms as well and it's sort of

515
00:23:47,750 --> 00:23:52,430
been a hit or miss whether or not the

516
00:23:49,070 --> 00:23:57,980
platforms are prepared to engage with us

517
00:23:52,430 --> 00:23:59,840
on that scale so that's sort of one

518
00:23:57,980 --> 00:24:04,940
example of like securing a corporate

519
00:23:59,840 --> 00:24:07,820
account which fairly easy it does

520
00:24:04,940 --> 00:24:09,830
require that you communicate with the

521
00:24:07,820 --> 00:24:10,939
team they don't see account but

522
00:24:09,830 --> 00:24:12,620
providing that you're not a jerk

523
00:24:10,940 --> 00:24:16,250
building that relationship should not be

524
00:24:12,620 --> 00:24:18,169
a problem so to make it a bit more

525
00:24:16,250 --> 00:24:18,500
complex though let's say that your

526
00:24:18,170 --> 00:24:19,850
commune

527
00:24:18,500 --> 00:24:21,710
caning with a sore so you have a

528
00:24:19,850 --> 00:24:24,110
reporter you are supporting a reporter

529
00:24:21,710 --> 00:24:25,850
who's communicating with a source again

530
00:24:24,110 --> 00:24:29,300
you can sort of consider the ways in

531
00:24:25,850 --> 00:24:34,129
which that either end of the comms can

532
00:24:29,300 --> 00:24:38,590
be compromised in this case which means

533
00:24:34,130 --> 00:24:41,080
that we can talk about in-person

534
00:24:38,590 --> 00:24:43,310
intimidation we can talk about

535
00:24:41,080 --> 00:24:44,780
surveillance we can talk about metadata

536
00:24:43,310 --> 00:24:46,520
we can talk about the compromise of

537
00:24:44,780 --> 00:24:49,490
their accounts if either of them are

538
00:24:46,520 --> 00:24:51,680
traveling we can talk about search and

539
00:24:49,490 --> 00:24:55,250
seizure at the border there are so many

540
00:24:51,680 --> 00:24:57,470
ways in which that that level of

541
00:24:55,250 --> 00:25:00,380
communication can be intercepted and

542
00:24:57,470 --> 00:25:03,830
compromised that things start getting

543
00:25:00,380 --> 00:25:05,000
very complex very quickly and I think

544
00:25:03,830 --> 00:25:07,460
the best thing that you can do is just

545
00:25:05,000 --> 00:25:10,510
provide the reporter with the tools and

546
00:25:07,460 --> 00:25:12,560
with the knowledge that they need

547
00:25:10,510 --> 00:25:14,090
another thing that sort of makes this a

548
00:25:12,560 --> 00:25:16,520
bit challenging is that the reporter and

549
00:25:14,090 --> 00:25:19,189
the source will almost always have

550
00:25:16,520 --> 00:25:22,100
different levels of technology which

551
00:25:19,190 --> 00:25:24,860
means that you can equip a reporter to

552
00:25:22,100 --> 00:25:26,600
use tor and tails and signal and

553
00:25:24,860 --> 00:25:29,659
encrypted email and know how to get

554
00:25:26,600 --> 00:25:31,429
something from secure drop but if the

555
00:25:29,660 --> 00:25:34,160
source only knows how to send a regular

556
00:25:31,430 --> 00:25:36,410
email that's not going to work that is

557
00:25:34,160 --> 00:25:39,260
where the journalist will have to meet

558
00:25:36,410 --> 00:25:44,420
them at initially it's always possible

559
00:25:39,260 --> 00:25:46,280
to to educate a source in how to use

560
00:25:44,420 --> 00:25:49,610
some of these other tools maybe you can

561
00:25:46,280 --> 00:25:51,230
get them on signal maybe you can get

562
00:25:49,610 --> 00:25:53,990
them comfortable with making a whatsapp

563
00:25:51,230 --> 00:25:56,870
phone call for example but that still

564
00:25:53,990 --> 00:25:59,120
requires the reporter to take some time

565
00:25:56,870 --> 00:26:01,070
to get them set up and if that

566
00:25:59,120 --> 00:26:04,820
communication happens by email for

567
00:26:01,070 --> 00:26:06,530
example you are leaving a trace showing

568
00:26:04,820 --> 00:26:08,240
that the reporter was engaging with the

569
00:26:06,530 --> 00:26:12,770
source at that point in time talking

570
00:26:08,240 --> 00:26:15,260
about how to set up secure comms now I

571
00:26:12,770 --> 00:26:17,660
don't know how many saw this from it

572
00:26:15,260 --> 00:26:19,670
came out yesterday the DOJ announced

573
00:26:17,660 --> 00:26:22,420
that it has charged a former

574
00:26:19,670 --> 00:26:24,860
intelligence analyst with providing

575
00:26:22,420 --> 00:26:27,370
classified information to a reporter and

576
00:26:24,860 --> 00:26:29,750
the indictment it's pretty interesting

577
00:26:27,370 --> 00:26:31,750
and it's also fairly short so if you

578
00:26:29,750 --> 00:26:33,400
have time you should dig it up and

579
00:26:31,750 --> 00:26:36,450
read it and I think it's like page five

580
00:26:33,400 --> 00:26:39,460
and six that sort of outlines the many

581
00:26:36,450 --> 00:26:42,510
different times that the source and the

582
00:26:39,460 --> 00:26:50,140
reporter communicated and you see the

583
00:26:42,510 --> 00:26:52,300
source uses a non non secret non

584
00:26:50,140 --> 00:26:54,880
classified computer to research the

585
00:26:52,300 --> 00:26:57,879
reporter then attends the reporter's

586
00:26:54,880 --> 00:27:01,030
book event the day after then he uses a

587
00:26:57,880 --> 00:27:03,100
top-secret computer to search for

588
00:27:01,030 --> 00:27:05,350
classified information about the people

589
00:27:03,100 --> 00:27:07,780
that the reporter specifically indicated

590
00:27:05,350 --> 00:27:09,580
that he was interested in then you have

591
00:27:07,780 --> 00:27:11,050
this like long thread where the source

592
00:27:09,580 --> 00:27:13,870
of the reporter are communicating back

593
00:27:11,050 --> 00:27:17,110
and forth with regular texts and an

594
00:27:13,870 --> 00:27:19,899
email then about six months and the

595
00:27:17,110 --> 00:27:23,919
reporter contacts the source to set up

596
00:27:19,900 --> 00:27:26,830
encrypted cops and so you have this like

597
00:27:23,920 --> 00:27:28,710
metadata trail all throughout this

598
00:27:26,830 --> 00:27:33,280
interaction that shows that they were

599
00:27:28,710 --> 00:27:34,870
communicating and so if at the end of

600
00:27:33,280 --> 00:27:37,930
the day if the source is not familiar

601
00:27:34,870 --> 00:27:39,010
with how to securely communicate with a

602
00:27:37,930 --> 00:27:40,870
reporter you're going to have a

603
00:27:39,010 --> 00:27:43,480
challenge of how do you bootstrap that

604
00:27:40,870 --> 00:27:46,389
how do you set them up for that without

605
00:27:43,480 --> 00:27:52,900
leaving this much metadata just hanging

606
00:27:46,390 --> 00:27:54,520
around which just means that you have to

607
00:27:52,900 --> 00:27:55,900
essentially find that like baseline

608
00:27:54,520 --> 00:28:01,300
could they just meet in person for

609
00:27:55,900 --> 00:28:03,070
example and they're just there's no sort

610
00:28:01,300 --> 00:28:04,659
of like one-size-fits-all it sort of

611
00:28:03,070 --> 00:28:06,669
really depends on the reporter it

612
00:28:04,660 --> 00:28:08,200
depends on the story they're working on

613
00:28:06,670 --> 00:28:10,750
it depends on what we're expecting to

614
00:28:08,200 --> 00:28:13,270
get from the source so we really try and

615
00:28:10,750 --> 00:28:14,050
like engineer a little like toolbox

616
00:28:13,270 --> 00:28:17,230
alike

617
00:28:14,050 --> 00:28:20,440
we can try x and y and z and then with

618
00:28:17,230 --> 00:28:25,260
the reporter come up with the the method

619
00:28:20,440 --> 00:28:28,570
that's going to work the best we also

620
00:28:25,260 --> 00:28:31,210
say that the whatever policy we said in

621
00:28:28,570 --> 00:28:33,850
the newsroom must follow best practice

622
00:28:31,210 --> 00:28:37,120
and it can't be something custom I would

623
00:28:33,850 --> 00:28:39,850
rather have a newsroom that is raising

624
00:28:37,120 --> 00:28:43,360
the bar for making signal and what's up

625
00:28:39,850 --> 00:28:45,520
common and acceptable and accepted same

626
00:28:43,360 --> 00:28:47,169
with tor entails and these other tools

627
00:28:45,520 --> 00:28:49,030
making encrypted comes the default

628
00:28:47,170 --> 00:28:51,150
rather than us trying to roll something

629
00:28:49,030 --> 00:28:54,070
that is unique

630
00:28:51,150 --> 00:28:55,980
possibly faulty and ultimately it's

631
00:28:54,070 --> 00:28:59,100
going to put more people at risk and

632
00:28:55,980 --> 00:29:02,260
over time it may be seen as more

633
00:28:59,100 --> 00:29:03,939
suspicious to use something custom by

634
00:29:02,260 --> 00:29:06,360
the New York Times than it is to make a

635
00:29:03,940 --> 00:29:09,850
what's up call for example so we try to

636
00:29:06,360 --> 00:29:13,510
focus on solutions that are well known

637
00:29:09,850 --> 00:29:16,480
known to be secure have been vetted used

638
00:29:13,510 --> 00:29:19,810
by the general public

639
00:29:16,480 --> 00:29:23,500
and so we do work on educating the

640
00:29:19,810 --> 00:29:27,010
newsroom and through articles that we

641
00:29:23,500 --> 00:29:29,860
write workshops that we do we do try and

642
00:29:27,010 --> 00:29:34,110
also educate future and current sources

643
00:29:29,860 --> 00:29:34,110
even if we don't know who they are so

644
00:29:36,030 --> 00:29:43,120
another sort of challenge that we've

645
00:29:38,230 --> 00:29:46,630
seen is sort of the rise of online

646
00:29:43,120 --> 00:29:50,379
threats and harassment it's not new but

647
00:29:46,630 --> 00:29:52,720
I would say in the past two years maybe

648
00:29:50,380 --> 00:29:54,670
three years we've seen online threats

649
00:29:52,720 --> 00:29:57,250
and harassment escalate in a way that

650
00:29:54,670 --> 00:30:04,120
just sort of feels free different it's

651
00:29:57,250 --> 00:30:07,870
persistent it's it's persistent it's a

652
00:30:04,120 --> 00:30:09,780
higher volume and it sort of feels very

653
00:30:07,870 --> 00:30:14,139
different than what we perhaps saw

654
00:30:09,780 --> 00:30:17,160
before and I would also I would I would

655
00:30:14,140 --> 00:30:19,810
also argue that you have reporters who

656
00:30:17,160 --> 00:30:21,400
maybe because of who they are or what

657
00:30:19,810 --> 00:30:25,560
they write about have just like gotten

658
00:30:21,400 --> 00:30:27,910
used to this like low-level Wiltern just

659
00:30:25,560 --> 00:30:29,260
harassment on social media and they

660
00:30:27,910 --> 00:30:31,750
gotten to the point where that's just

661
00:30:29,260 --> 00:30:34,050
like it's like whatever they got used to

662
00:30:31,750 --> 00:30:37,480
it the bar is a bit higher now for what

663
00:30:34,050 --> 00:30:39,580
will rattle them or upset them or cause

664
00:30:37,480 --> 00:30:43,060
them to report something but now you

665
00:30:39,580 --> 00:30:48,659
also have a lot of new reporters often

666
00:30:43,060 --> 00:30:48,659
younger reporters getting this sort of

667
00:30:48,840 --> 00:30:55,689
firehose on Twitter in a way that is new

668
00:30:53,020 --> 00:30:57,970
for them it is to some extent a bit new

669
00:30:55,690 --> 00:31:00,760
for us to see the escalation and we're

670
00:30:57,970 --> 00:31:03,760
trying to figure out how do we best meet

671
00:31:00,760 --> 00:31:07,450
the needs of the newsroom in this case

672
00:31:03,760 --> 00:31:11,920
can we educate staff on what to do what

673
00:31:07,450 --> 00:31:13,930
not to do how do you handle harassment

674
00:31:11,920 --> 00:31:16,450
or threats who do you report it to other

675
00:31:13,930 --> 00:31:19,060
times what kind of support can the

676
00:31:16,450 --> 00:31:20,320
company provide what would it look like

677
00:31:19,060 --> 00:31:23,460
if you had to report it to law

678
00:31:20,320 --> 00:31:25,689
enforcement and then unfortunately

679
00:31:23,460 --> 00:31:27,640
educate law enforcement to Scylla they

680
00:31:25,690 --> 00:31:28,720
fully understand what it is that you're

681
00:31:27,640 --> 00:31:31,140
dealing with and that it's not just

682
00:31:28,720 --> 00:31:33,310
someone blowing off steam for example

683
00:31:31,140 --> 00:31:35,200
and this is sort of a challenge that we

684
00:31:33,310 --> 00:31:37,360
do share with a lot of other media works

685
00:31:35,200 --> 00:31:38,910
as well as something that we do talk

686
00:31:37,360 --> 00:31:42,070
about we all try to sort of figure out

687
00:31:38,910 --> 00:31:43,600
how do we best support the newsroom

688
00:31:42,070 --> 00:31:45,760
knowing that we're not going to be able

689
00:31:43,600 --> 00:31:48,370
to eliminate online threats and

690
00:31:45,760 --> 00:31:50,560
harassment so how can we focus on

691
00:31:48,370 --> 00:31:52,419
digital physical emotional support for

692
00:31:50,560 --> 00:31:56,830
the newsroom and in that way build a

693
00:31:52,420 --> 00:31:59,470
resilient newsroom now that is a huge

694
00:31:56,830 --> 00:32:02,350
challenge and undertaking and one of the

695
00:31:59,470 --> 00:32:04,990
things that The Times did about a year

696
00:32:02,350 --> 00:32:09,090
and a bit ago was that we created a

697
00:32:04,990 --> 00:32:13,210
cross collaborative teams across team

698
00:32:09,090 --> 00:32:15,129
collaborative team to focus on this

699
00:32:13,210 --> 00:32:17,170
challenge specifically so you had wraps

700
00:32:15,130 --> 00:32:20,710
from InfoSec and physical security and

701
00:32:17,170 --> 00:32:22,330
legal and that topic did get the space

702
00:32:20,710 --> 00:32:25,590
it needed to be discussed so we could

703
00:32:22,330 --> 00:32:28,750
all come up with solutions and then a

704
00:32:25,590 --> 00:32:30,820
month ago now we also hired a VP of

705
00:32:28,750 --> 00:32:33,760
corporate security who is going to focus

706
00:32:30,820 --> 00:32:35,379
a bit more on the physical safety and on

707
00:32:33,760 --> 00:32:38,250
all on threats and harassment of our

708
00:32:35,380 --> 00:32:42,190
staff which i think is a fantastic move

709
00:32:38,250 --> 00:32:48,610
and then finally we also now focus more

710
00:32:42,190 --> 00:32:51,880
on proactive steps prior to research and

711
00:32:48,610 --> 00:32:54,520
publication so last summer two people on

712
00:32:51,880 --> 00:32:58,030
my team Kristin Kaczynski Nena Kapoor

713
00:32:54,520 --> 00:33:00,370
came up with what they call the daxing

714
00:32:58,030 --> 00:33:02,950
workshop where initially it was a

715
00:33:00,370 --> 00:33:06,429
dusting service if you filled out a

716
00:33:02,950 --> 00:33:09,340
Google Form with just like your name and

717
00:33:06,430 --> 00:33:11,769
like some online handles and it's

718
00:33:09,340 --> 00:33:14,620
essentially gave us your permission to

719
00:33:11,769 --> 00:33:17,169
dock see you we would spend about our

720
00:33:14,620 --> 00:33:19,239
air over and I have seeing how much we

721
00:33:17,169 --> 00:33:21,009
could find out about you then we would

722
00:33:19,240 --> 00:33:23,110
sit down in person and show you

723
00:33:21,009 --> 00:33:24,460
everything that we found and then talk

724
00:33:23,110 --> 00:33:27,789
about ways in which that you can lock

725
00:33:24,460 --> 00:33:29,470
down or delete it completely and that

726
00:33:27,789 --> 00:33:31,690
was such a popular service that it's now

727
00:33:29,470 --> 00:33:34,269
turned into a workshop where we will

728
00:33:31,690 --> 00:33:36,370
teach reporters how to docks themselves

729
00:33:34,269 --> 00:33:39,070
for the purpose of ensuring that when

730
00:33:36,370 --> 00:33:41,768
they do publish that next story about

731
00:33:39,070 --> 00:33:44,860
alright for example it's not going to

732
00:33:41,769 --> 00:33:46,659
have a huge blowback on them and the

733
00:33:44,860 --> 00:33:48,639
same way it would as if they're like

734
00:33:46,659 --> 00:33:50,590
home address and phone number and

735
00:33:48,639 --> 00:33:53,979
favorite pad and everything was just

736
00:33:50,590 --> 00:33:56,769
publicly available and that is something

737
00:33:53,980 --> 00:34:01,480
that we continue with today and that has

738
00:33:56,769 --> 00:34:03,460
had a huge impact in the news room and

739
00:34:01,480 --> 00:34:07,210
now we do see editors and reporters

740
00:34:03,460 --> 00:34:09,730
reach out saying I started investigating

741
00:34:07,210 --> 00:34:11,889
this thing I'm planning a profile about

742
00:34:09,730 --> 00:34:13,300
this person at that point they don't

743
00:34:11,889 --> 00:34:15,730
even know when they're going to publish

744
00:34:13,300 --> 00:34:17,740
which means that we have a lot of time

745
00:34:15,730 --> 00:34:23,339
to really get this right and really help

746
00:34:17,739 --> 00:34:26,379
them lock things down a couple of other

747
00:34:23,339 --> 00:34:28,659
fun things that we've done so when I

748
00:34:26,379 --> 00:34:31,779
started back in 2016 there was a

749
00:34:28,659 --> 00:34:34,929
security team but we didn't have a whole

750
00:34:31,780 --> 00:34:38,109
lot of presence in the newsroom so I

751
00:34:34,929 --> 00:34:43,240
figured what is a good way to introduce

752
00:34:38,109 --> 00:34:45,310
yourself to 1,400 people back then and

753
00:34:43,239 --> 00:34:47,589
at the same time bootstrap the team that

754
00:34:45,310 --> 00:34:50,349
you're on so I started sending at

755
00:34:47,589 --> 00:34:53,259
monthly phishing tests started fishing

756
00:34:50,349 --> 00:34:56,400
the newsroom on a monthly basis and at

757
00:34:53,260 --> 00:34:59,740
the end of each test it was I would

758
00:34:56,400 --> 00:35:03,490
summarize it and publish on our internal

759
00:34:59,740 --> 00:35:05,649
site how many people opened the email I

760
00:35:03,490 --> 00:35:06,939
mean if people click the link how many

761
00:35:05,650 --> 00:35:09,460
people enter their usernames and

762
00:35:06,940 --> 00:35:13,540
passwords and then I would note the top

763
00:35:09,460 --> 00:35:15,490
five desks so the you know the Metro and

764
00:35:13,540 --> 00:35:18,190
international and cooking and those

765
00:35:15,490 --> 00:35:20,330
groups top five that that failed or had

766
00:35:18,190 --> 00:35:22,430
the highest number of people

767
00:35:20,330 --> 00:35:23,960
enter their usernames and passwords that

768
00:35:22,430 --> 00:35:26,899
created some competition within the

769
00:35:23,960 --> 00:35:29,570
newsroom which seemed like that was a

770
00:35:26,900 --> 00:35:31,040
popular move and to the point where

771
00:35:29,570 --> 00:35:33,470
people knew that we were sending out the

772
00:35:31,040 --> 00:35:34,910
tests every month so they knew that

773
00:35:33,470 --> 00:35:37,310
something was gonna come and it's like

774
00:35:34,910 --> 00:35:38,868
oh it's June 2nd there has some inner

775
00:35:37,310 --> 00:35:40,040
fishing test something's gonna come at

776
00:35:38,869 --> 00:35:41,330
some point in time so they would all

777
00:35:40,040 --> 00:35:43,100
talk about it and they would sort of

778
00:35:41,330 --> 00:35:44,600
chat with us on the hallway trying to

779
00:35:43,100 --> 00:35:46,339
figure out when are we sending the test

780
00:35:44,600 --> 00:35:48,740
what is it gonna look like what are you

781
00:35:46,340 --> 00:35:51,050
doing with the people who didn't do so

782
00:35:48,740 --> 00:35:53,720
well the month before and it also really

783
00:35:51,050 --> 00:35:55,670
helped them shape who we engage with how

784
00:35:53,720 --> 00:35:58,669
we train them how often we train them

785
00:35:55,670 --> 00:36:00,530
and just how we communicate what fishing

786
00:35:58,670 --> 00:36:02,920
is and how you do to avoid it because

787
00:36:00,530 --> 00:36:05,360
you can give the same message to someone

788
00:36:02,920 --> 00:36:06,860
multiple times but if they DIF that

789
00:36:05,360 --> 00:36:08,420
doesn't land if they don't fully

790
00:36:06,860 --> 00:36:10,130
understand what it is that you're trying

791
00:36:08,420 --> 00:36:12,860
to communicate you're gonna have to

792
00:36:10,130 --> 00:36:15,800
switch it up so that also really helped

793
00:36:12,860 --> 00:36:17,450
us see like who needed more help and who

794
00:36:15,800 --> 00:36:22,820
needed help in a different way that we

795
00:36:17,450 --> 00:36:24,470
hadn't done it before we also so this

796
00:36:22,820 --> 00:36:29,660
has sort of changed slightly but back

797
00:36:24,470 --> 00:36:31,730
then in 2016 17 we would have one full

798
00:36:29,660 --> 00:36:34,368
hour for information security training

799
00:36:31,730 --> 00:36:36,380
with every new hire in the newsroom so

800
00:36:34,369 --> 00:36:38,930
we would do that on a I think it was

801
00:36:36,380 --> 00:36:41,000
bi-weekly business back then since then

802
00:36:38,930 --> 00:36:43,700
our onboarding program has changed and

803
00:36:41,000 --> 00:36:46,820
we now have 30 minutes with all new

804
00:36:43,700 --> 00:36:48,618
hires at the company so and then on top

805
00:36:46,820 --> 00:36:51,500
of that we do some additional training

806
00:36:48,619 --> 00:36:54,020
with certain desks so we have then the

807
00:36:51,500 --> 00:36:56,780
opportunity to provide that basic the

808
00:36:54,020 --> 00:36:59,359
baseline digital security here's what

809
00:36:56,780 --> 00:37:01,190
you absolutely need to know and then we

810
00:36:59,359 --> 00:37:03,279
also do engage with different desks to

811
00:37:01,190 --> 00:37:05,720
talk about here's how you research

812
00:37:03,280 --> 00:37:07,400
securely here's how you research a

813
00:37:05,720 --> 00:37:09,560
company where they're disclosing that

814
00:37:07,400 --> 00:37:12,859
you the New York Times is interested in

815
00:37:09,560 --> 00:37:15,980
looking into this here's what you should

816
00:37:12,859 --> 00:37:18,830
consider for travel we've done brown bag

817
00:37:15,980 --> 00:37:21,170
lunches with legal to talk about border

818
00:37:18,830 --> 00:37:25,310
searches especially in the context of

819
00:37:21,170 --> 00:37:27,650
the US what the law says what's sort of

820
00:37:25,310 --> 00:37:29,720
like gray area and what you shouldn't

821
00:37:27,650 --> 00:37:32,510
shouldn't do what the company can do for

822
00:37:29,720 --> 00:37:34,220
you if you do get detained so talk about

823
00:37:32,510 --> 00:37:37,190
what the law does

824
00:37:34,220 --> 00:37:38,990
and then we can talk about also what you

825
00:37:37,190 --> 00:37:41,750
can do from a security perspective and

826
00:37:38,990 --> 00:37:44,990
what we then our team can do for the

827
00:37:41,750 --> 00:37:46,550
newsroom in that context so you then get

828
00:37:44,990 --> 00:37:50,689
to train people on that very sort of

829
00:37:46,550 --> 00:37:52,340
unique topic challenge specific area in

830
00:37:50,690 --> 00:37:54,110
a way that talking about that in an

831
00:37:52,340 --> 00:37:58,280
onboarding wouldn't necessarily make

832
00:37:54,110 --> 00:38:00,590
sense one because the audience is sort

833
00:37:58,280 --> 00:38:03,380
of too broad but also on morning is like

834
00:38:00,590 --> 00:38:05,390
this crazy I think it's like a three day

835
00:38:03,380 --> 00:38:06,890
if not full week experience and you're

836
00:38:05,390 --> 00:38:08,330
sort of getting this firehose about

837
00:38:06,890 --> 00:38:10,819
anything and everything that you should

838
00:38:08,330 --> 00:38:14,509
know about the company so we try to save

839
00:38:10,820 --> 00:38:18,500
that for a bit later we do a lot of

840
00:38:14,510 --> 00:38:20,840
awareness through newsletters weekly

841
00:38:18,500 --> 00:38:23,630
tips we sent out advisories when things

842
00:38:20,840 --> 00:38:26,020
pop up and we do national cybersecurity

843
00:38:23,630 --> 00:38:29,120
Awareness Month so the first one was

844
00:38:26,020 --> 00:38:33,230
last year we had cake that was really

845
00:38:29,120 --> 00:38:35,480
popular and lock-picking was I think the

846
00:38:33,230 --> 00:38:37,700
most popular workshop that we did last

847
00:38:35,480 --> 00:38:39,980
year to the point where and the

848
00:38:37,700 --> 00:38:44,480
Washington DC bureau wanted lock-picking

849
00:38:39,980 --> 00:38:46,520
as well so we organized that for them so

850
00:38:44,480 --> 00:38:47,900
we do focus a lot on culture as part of

851
00:38:46,520 --> 00:38:50,420
the security program and building

852
00:38:47,900 --> 00:38:52,760
awareness we also do as I mentioned

853
00:38:50,420 --> 00:38:55,280
earlier build a lot of relationships

854
00:38:52,760 --> 00:38:56,510
with vendors and teams because there are

855
00:38:55,280 --> 00:38:58,970
so many different people that will

856
00:38:56,510 --> 00:39:02,060
ultimately engage with the newsroom in

857
00:38:58,970 --> 00:39:04,399
some way shape or form if we can educate

858
00:39:02,060 --> 00:39:06,560
them they can then educate the people

859
00:39:04,400 --> 00:39:09,440
that they talk to and really as a team

860
00:39:06,560 --> 00:39:13,370
of I think we're now ten at an

861
00:39:09,440 --> 00:39:14,870
organization of five thousand you are

862
00:39:13,370 --> 00:39:20,450
going to need to find other people who

863
00:39:14,870 --> 00:39:23,120
can help support your mission so in

864
00:39:20,450 --> 00:39:25,250
terms of supporting in the mission how

865
00:39:23,120 --> 00:39:30,799
can we take the lessons learned at the

866
00:39:25,250 --> 00:39:32,510
times and empower other media works so

867
00:39:30,800 --> 00:39:35,780
one thing that we can do is sort of

868
00:39:32,510 --> 00:39:40,160
share experiences and intelligence and

869
00:39:35,780 --> 00:39:43,330
so the lessons learned so for the past

870
00:39:40,160 --> 00:39:45,890
year we've had a little sort of group of

871
00:39:43,330 --> 00:39:47,190
folks from security teams that media

872
00:39:45,890 --> 00:39:49,400
works that are

873
00:39:47,190 --> 00:39:52,410
getting together on like multi calls

874
00:39:49,400 --> 00:39:54,060
in-person meetups sharing the type of

875
00:39:52,410 --> 00:39:57,779
challenges that they have what they're

876
00:39:54,060 --> 00:39:59,910
thinking about travel comes up a lot

877
00:39:57,780 --> 00:40:01,800
what they're thinking about just digital

878
00:39:59,910 --> 00:40:04,049
security what about data retention

879
00:40:01,800 --> 00:40:05,640
policies for email what about social

880
00:40:04,050 --> 00:40:09,690
media nor talk about some of these

881
00:40:05,640 --> 00:40:11,370
challenges that I may be unique for the

882
00:40:09,690 --> 00:40:15,840
space but certainly not unique to

883
00:40:11,370 --> 00:40:19,740
individual mediaworks talked a bit about

884
00:40:15,840 --> 00:40:21,150
secure supporting users with accounts so

885
00:40:19,740 --> 00:40:23,189
the whole personal corporate accountant

886
00:40:21,150 --> 00:40:25,680
piece is just really really tricky like

887
00:40:23,190 --> 00:40:27,810
you have no way to like enforce security

888
00:40:25,680 --> 00:40:30,990
settings in that space so you do really

889
00:40:27,810 --> 00:40:34,950
rely on ensuring that the end user knows

890
00:40:30,990 --> 00:40:36,750
what to do and what not to do we also

891
00:40:34,950 --> 00:40:40,140
then focus on have reporters can

892
00:40:36,750 --> 00:40:42,030
securely use Twitter and Facebook and

893
00:40:40,140 --> 00:40:43,680
these other platforms instead of saying

894
00:40:42,030 --> 00:40:46,530
no you shouldn't use it it will lead to

895
00:40:43,680 --> 00:40:48,180
much metadata or it's not secure or

896
00:40:46,530 --> 00:40:50,820
Facebook would give out your data in

897
00:40:48,180 --> 00:40:54,480
response to a court order would you try

898
00:40:50,820 --> 00:40:56,280
and just sort of know we try and help

899
00:40:54,480 --> 00:40:58,680
the reporters just be aware of the

900
00:40:56,280 --> 00:41:01,650
challenges be aware of the risks and

901
00:40:58,680 --> 00:41:06,660
then sort of show one how to how to do

902
00:41:01,650 --> 00:41:08,460
it yeah

903
00:41:06,660 --> 00:41:11,910
and two final pieces are not everyone's

904
00:41:08,460 --> 00:41:15,480
got personal or professional contacts I

905
00:41:11,910 --> 00:41:16,859
will I will say that the network that

906
00:41:15,480 --> 00:41:18,420
I've built up over the years with the

907
00:41:16,860 --> 00:41:20,730
people that have had the pleasure of

908
00:41:18,420 --> 00:41:22,410
communicating with are also sort of the

909
00:41:20,730 --> 00:41:24,540
same network that I reach out to now

910
00:41:22,410 --> 00:41:26,970
when someone needs help with their

911
00:41:24,540 --> 00:41:29,430
snapchat account for example in some

912
00:41:26,970 --> 00:41:31,879
cases we're not going to have a

913
00:41:29,430 --> 00:41:34,640
corporate New York Times to whatever

914
00:41:31,880 --> 00:41:37,200
relationship with the other org and so

915
00:41:34,640 --> 00:41:39,210
there are times when we then leverage

916
00:41:37,200 --> 00:41:40,859
more personal contacts to get to the

917
00:41:39,210 --> 00:41:43,080
right contact at the company and get the

918
00:41:40,860 --> 00:41:44,910
assistance that we need it works today

919
00:41:43,080 --> 00:41:47,880
but it's a bit unfortunate that media

920
00:41:44,910 --> 00:41:50,520
works don't have that level of contact

921
00:41:47,880 --> 00:41:52,710
at these companies so we're really

922
00:41:50,520 --> 00:41:54,630
trying to build that out now and ensure

923
00:41:52,710 --> 00:41:57,540
that that is also shared among all the

924
00:41:54,630 --> 00:42:00,089
other media works so that if a reporter

925
00:41:57,540 --> 00:42:02,788
does have an issue there is sort

926
00:42:00,089 --> 00:42:06,089
official ish Channel and place to get

927
00:42:02,789 --> 00:42:08,729
them the help and then finally online

928
00:42:06,089 --> 00:42:10,380
threats and harassment is sort of it's a

929
00:42:08,729 --> 00:42:14,339
topic that everyone's talking about it's

930
00:42:10,380 --> 00:42:16,650
not unique to two media by by any means

931
00:42:14,339 --> 00:42:18,630
but it is now a conversation that is

932
00:42:16,650 --> 00:42:20,849
flowing both within Media works and now

933
00:42:18,630 --> 00:42:23,969
also with I mean we've seen Twitter and

934
00:42:20,849 --> 00:42:26,369
Facebook talk about it for a while but I

935
00:42:23,969 --> 00:42:28,349
think there's a lot of talk and

936
00:42:26,369 --> 00:42:30,689
everyone's now very interested in

937
00:42:28,349 --> 00:42:35,189
finding more solutions to the challenges

938
00:42:30,689 --> 00:42:37,739
that we're seeing so I think that was my

939
00:42:35,189 --> 00:42:39,959
last slide yeah with that I do have

940
00:42:37,739 --> 00:42:42,089
about 15 minutes for Q&A if anyone's got

941
00:42:39,959 --> 00:42:45,419
questions either here or I'll hang

942
00:42:42,089 --> 00:42:49,009
around outside as well I think thank you

943
00:42:45,420 --> 00:42:49,009
thank you very much true enough

944
00:42:52,190 --> 00:42:59,940
any questions from the floor or indeed

945
00:42:57,270 --> 00:43:02,220
questions during coffee break over

946
00:42:59,940 --> 00:43:03,570
coffee thank you again to Runa for

947
00:43:02,220 --> 00:43:05,370
coming back on to the hack in the vox

948
00:43:03,570 --> 00:43:05,430
stage another round of applause please

949
00:43:05,370 --> 00:43:08,989
[Applause]

950
00:43:05,430 --> 00:43:08,989
[Music]

951
00:43:15,500 --> 00:43:17,560
you

