1
00:00:06,000 --> 00:00:07,759
alex what's up man

2
00:00:07,759 --> 00:00:09,679
how are you i

3
00:00:09,679 --> 00:00:12,080
i'm fine thanks it's just the early

4
00:00:12,080 --> 00:00:14,920
morning here in israel what time is it

5
00:00:14,920 --> 00:00:16,960
wrong uh

6
00:00:16,960 --> 00:00:21,279
9 30 for me it's super early morning

7
00:00:22,560 --> 00:00:24,000
yeah we know the pain we know the pain

8
00:00:24,000 --> 00:00:26,240
man thanks for joining us bro uh so we

9
00:00:26,240 --> 00:00:28,240
have like about half an hour you wanna

10
00:00:28,240 --> 00:00:29,279
tell us a little bit about what you're

11
00:00:29,279 --> 00:00:31,439
going to be presenting shortly in uh

12
00:00:31,439 --> 00:00:34,160
in in the conference

13
00:00:34,160 --> 00:00:36,239
yeah sure um

14
00:00:36,239 --> 00:00:40,000
so uh the idea of this talk is to just

15
00:00:40,000 --> 00:00:42,320
to basically to demonstrate people how

16
00:00:42,320 --> 00:00:46,239
to perform um a ira teaming uh and it's

17
00:00:46,239 --> 00:00:47,600
a it's a new

18
00:00:47,600 --> 00:00:49,520
thing it's a

19
00:00:49,520 --> 00:00:51,199
most probably it's one of the first

20
00:00:51,199 --> 00:00:53,920
topics on how practically you can do

21
00:00:53,920 --> 00:00:54,800
that

22
00:00:54,800 --> 00:00:57,120
there were a lot of presentations like

23
00:00:57,120 --> 00:01:00,480
on particular examples so how people

24
00:01:00,480 --> 00:01:03,199
breaks uh different different ai

25
00:01:03,199 --> 00:01:06,159
applications but there are no like

26
00:01:06,159 --> 00:01:08,720
step-by-step guide on how you can

27
00:01:08,720 --> 00:01:11,600
perform those types of assessments

28
00:01:11,600 --> 00:01:15,680
so i think that's uh basically uh

29
00:01:15,680 --> 00:01:18,159
ai security uh

30
00:01:18,159 --> 00:01:19,920
is something that we

31
00:01:19,920 --> 00:01:22,000
should uh

32
00:01:22,000 --> 00:01:26,000
take into account in the next 10 years

33
00:01:26,000 --> 00:01:28,640
because it's uh it's something that will

34
00:01:28,640 --> 00:01:30,159
be everywhere

35
00:01:30,159 --> 00:01:32,799
basically actually you started adversar

36
00:01:32,799 --> 00:01:35,360
specifically to target ai right and ai

37
00:01:35,360 --> 00:01:38,400
security issues right

38
00:01:38,400 --> 00:01:41,520
yeah yeah exactly like uh

39
00:01:41,520 --> 00:01:42,720
yeah

40
00:01:42,720 --> 00:01:44,560
can you tell us a little bit more about

41
00:01:44,560 --> 00:01:46,399
like

42
00:01:46,399 --> 00:01:49,200
what you guys are working on

43
00:01:49,200 --> 00:01:52,000
yeah um so

44
00:01:52,000 --> 00:01:53,600
i was into

45
00:01:53,600 --> 00:01:56,399
different areas of uh cyber security

46
00:01:56,399 --> 00:01:57,600
from uh

47
00:01:57,600 --> 00:02:00,799
network security to uh databases and up

48
00:02:00,799 --> 00:02:02,479
to applications

49
00:02:02,479 --> 00:02:06,799
and i think like four five years ago

50
00:02:06,799 --> 00:02:09,119
we develop

51
00:02:09,119 --> 00:02:11,200
a platform to

52
00:02:11,200 --> 00:02:14,160
detect anomalous behavior anomalous user

53
00:02:14,160 --> 00:02:15,360
behavior

54
00:02:15,360 --> 00:02:16,560
um

55
00:02:16,560 --> 00:02:20,160
and we used we decided to use ai we

56
00:02:20,160 --> 00:02:22,640
decided to use a lot of different

57
00:02:22,640 --> 00:02:25,280
fancy machine learning uh technologies

58
00:02:25,280 --> 00:02:28,879
to detect uh unusual behavior and detect

59
00:02:28,879 --> 00:02:30,160
hackers

60
00:02:30,160 --> 00:02:31,360
um

61
00:02:31,360 --> 00:02:34,560
and at some point of time i i found the

62
00:02:34,560 --> 00:02:37,640
research paper about

63
00:02:37,640 --> 00:02:40,720
vulnerabilities in

64
00:02:40,720 --> 00:02:42,560
deep learning networks so

65
00:02:42,560 --> 00:02:45,200
when where you basically can change few

66
00:02:45,200 --> 00:02:47,440
pixels in such way that ai will

67
00:02:47,440 --> 00:02:48,720
recognize

68
00:02:48,720 --> 00:02:51,760
cad instead of dog and and so on

69
00:02:51,760 --> 00:02:54,239
uh and i read this paper like the detail

70
00:02:54,239 --> 00:02:57,200
that mathematic details and i was like

71
00:02:57,200 --> 00:03:01,120
wait what like is is that so easy and is

72
00:03:01,120 --> 00:03:02,800
that so

73
00:03:02,800 --> 00:03:04,959
that it's not just

74
00:03:04,959 --> 00:03:06,879
it's so easy but the problem is that

75
00:03:06,879 --> 00:03:09,200
it's the architecture flow it's a

76
00:03:09,200 --> 00:03:13,440
fundamental flow of all uh ai systems or

77
00:03:13,440 --> 00:03:15,680
at least the deep learning algorithms

78
00:03:15,680 --> 00:03:18,879
which are uh currently everywhere

79
00:03:18,879 --> 00:03:19,760
and

80
00:03:19,760 --> 00:03:22,720
i realized that we won't be able to

81
00:03:22,720 --> 00:03:23,599
build

82
00:03:23,599 --> 00:03:25,360
a system

83
00:03:25,360 --> 00:03:29,360
based on ai to find hackers

84
00:03:29,360 --> 00:03:31,760
unless we solve the problem of

85
00:03:31,760 --> 00:03:33,680
protecting ai

86
00:03:33,680 --> 00:03:36,319
and that's how actually uh adverse

87
00:03:36,319 --> 00:03:39,760
started so um

88
00:03:39,760 --> 00:03:42,799
uh pristine i just said

89
00:03:42,799 --> 00:03:44,799
so when you talk about like you know ai

90
00:03:44,799 --> 00:03:46,879
and and actually testing the systems

91
00:03:46,879 --> 00:03:48,799
right they're all black boxes right i

92
00:03:48,799 --> 00:03:50,159
mean they're not exactly you're not

93
00:03:50,159 --> 00:03:51,360
going to go to the automobile

94
00:03:51,360 --> 00:03:52,720
manufacturer and they're not going to

95
00:03:52,720 --> 00:03:53,840
give you the model file right they're

96
00:03:53,840 --> 00:03:55,120
just going to give you the end result or

97
00:03:55,120 --> 00:03:57,360
end product and say that's that right so

98
00:03:57,360 --> 00:03:59,360
how do you how do you even begin to

99
00:03:59,360 --> 00:04:00,720
start testing something like that as you

100
00:04:00,720 --> 00:04:02,319
know how do you make it reproducible how

101
00:04:02,319 --> 00:04:04,319
do you make sure that actually the the

102
00:04:04,319 --> 00:04:06,000
inputs that you're giving into the ai

103
00:04:06,000 --> 00:04:08,159
system are are being measured correctly

104
00:04:08,159 --> 00:04:10,000
as in what which parts of the system are

105
00:04:10,000 --> 00:04:11,280
being fooled

106
00:04:11,280 --> 00:04:12,480
if you talk about like a self-driving

107
00:04:12,480 --> 00:04:14,560
car for example right like the sign

108
00:04:14,560 --> 00:04:16,160
recognition the lane there's lane

109
00:04:16,160 --> 00:04:17,519
guidance there's lots of different

110
00:04:17,519 --> 00:04:19,440
systems that interconnected how do you

111
00:04:19,440 --> 00:04:21,519
then pinpoint which where the floor lies

112
00:04:21,519 --> 00:04:23,120
right as in which sensor is causing the

113
00:04:23,120 --> 00:04:25,280
problem

114
00:04:25,280 --> 00:04:27,759
yeah i i think yeah you're touching here

115
00:04:27,759 --> 00:04:30,639
the the the few areas the the one area

116
00:04:30,639 --> 00:04:33,280
is uh like a white box like box type of

117
00:04:33,280 --> 00:04:34,160
thing

118
00:04:34,160 --> 00:04:36,320
uh the interesting uh the interesting

119
00:04:36,320 --> 00:04:39,040
thing about ai is that uh

120
00:04:39,040 --> 00:04:40,800
many of the vulnerabilities are

121
00:04:40,800 --> 00:04:42,320
transferable

122
00:04:42,320 --> 00:04:46,639
so if you if you try to uh

123
00:04:46,639 --> 00:04:49,440
so if you basically find a vulnerability

124
00:04:49,440 --> 00:04:50,400
in

125
00:04:50,400 --> 00:04:53,840
some uh open source algorithm there is a

126
00:04:53,840 --> 00:04:56,560
big chance that uh

127
00:04:56,560 --> 00:04:58,800
that vulnerability can be transferred to

128
00:04:58,800 --> 00:05:01,280
the other algorithm uh of course you

129
00:05:01,280 --> 00:05:04,080
need to do some kind of adjustments it's

130
00:05:04,080 --> 00:05:06,000
kind of the same thing

131
00:05:06,000 --> 00:05:08,880
uh as we had in um

132
00:05:08,880 --> 00:05:12,240
exploited development so uh

133
00:05:12,240 --> 00:05:16,320
there are various you know um

134
00:05:16,320 --> 00:05:19,039
operating systems and there are various

135
00:05:19,039 --> 00:05:21,440
commons you need to implement in the

136
00:05:21,440 --> 00:05:23,840
exploit to be able to work in in a

137
00:05:23,840 --> 00:05:26,800
different environment

138
00:05:26,800 --> 00:05:27,600
but

139
00:05:27,600 --> 00:05:31,360
in general the the vulnerability is uh

140
00:05:31,360 --> 00:05:34,320
transferable so in order to

141
00:05:34,320 --> 00:05:37,280
uh be able to

142
00:05:37,280 --> 00:05:39,199
make this vulnerability more

143
00:05:39,199 --> 00:05:41,520
transferable and i will tell more

144
00:05:41,520 --> 00:05:43,759
details about that in in the

145
00:05:43,759 --> 00:05:45,120
presentation

146
00:05:45,120 --> 00:05:47,919
uh that you need uh

147
00:05:47,919 --> 00:05:50,639
to test it on as much

148
00:05:50,639 --> 00:05:53,840
different ai systems as possible

149
00:05:53,840 --> 00:05:57,440
uh and if you test your exploit in in

150
00:05:57,440 --> 00:05:59,919
various system the more systems you have

151
00:05:59,919 --> 00:06:02,400
the more chances that it will work

152
00:06:02,400 --> 00:06:05,600
uh on uh other like um

153
00:06:05,600 --> 00:06:07,680
black box

154
00:06:07,680 --> 00:06:09,199
scenario

155
00:06:09,199 --> 00:06:12,800
uh and in order to do that uh there are

156
00:06:12,800 --> 00:06:14,319
different tricks

157
00:06:14,319 --> 00:06:15,199
uh

158
00:06:15,199 --> 00:06:17,680
so you need to take into account all

159
00:06:17,680 --> 00:06:18,840
types of

160
00:06:18,840 --> 00:06:20,319
environment uh

161
00:06:20,319 --> 00:06:22,880
specific issues like you need to take

162
00:06:22,880 --> 00:06:25,039
into account that in

163
00:06:25,039 --> 00:06:28,080
physical 3d environment there can be

164
00:06:28,080 --> 00:06:29,440
um

165
00:06:29,440 --> 00:06:31,680
well

166
00:06:31,759 --> 00:06:34,400
the the transferability is one thing

167
00:06:34,400 --> 00:06:37,360
yes uh and the other thing is that it

168
00:06:37,360 --> 00:06:40,880
should work in different uh environments

169
00:06:40,880 --> 00:06:41,680
uh

170
00:06:41,680 --> 00:06:42,479
and

171
00:06:42,479 --> 00:06:43,680
if we talk about the physical

172
00:06:43,680 --> 00:06:45,280
environment we should take into account

173
00:06:45,280 --> 00:06:46,319
that

174
00:06:46,319 --> 00:06:47,440
uh

175
00:06:47,440 --> 00:06:50,639
this for example the the road sign that

176
00:06:50,639 --> 00:06:53,120
we want to to build to

177
00:06:53,120 --> 00:06:54,639
uh

178
00:06:54,639 --> 00:06:58,160
uh hug a cell driving system

179
00:06:58,160 --> 00:07:00,080
it should work uh

180
00:07:00,080 --> 00:07:03,360
in different um

181
00:07:03,360 --> 00:07:06,880
uh with different lights uh on different

182
00:07:06,880 --> 00:07:08,160
uh

183
00:07:08,160 --> 00:07:10,160
distance to object

184
00:07:10,160 --> 00:07:11,599
uh

185
00:07:11,599 --> 00:07:13,280
in different

186
00:07:13,280 --> 00:07:14,639
so

187
00:07:14,639 --> 00:07:15,919
we should take into account the

188
00:07:15,919 --> 00:07:18,319
different color rendering

189
00:07:18,319 --> 00:07:22,160
uh specifics of particular video

190
00:07:22,160 --> 00:07:24,000
device

191
00:07:24,000 --> 00:07:25,919
so there are many things that should be

192
00:07:25,919 --> 00:07:28,319
taken into account and basically when

193
00:07:28,319 --> 00:07:31,759
you construct the the the exploit

194
00:07:31,759 --> 00:07:33,199
uh

195
00:07:33,199 --> 00:07:35,039
you need to

196
00:07:35,039 --> 00:07:36,319
uh

197
00:07:36,319 --> 00:07:37,680
like fuzz

198
00:07:37,680 --> 00:07:40,160
all types of uh

199
00:07:40,160 --> 00:07:42,720
things that uh can happen

200
00:07:42,720 --> 00:07:44,879
well

201
00:07:44,879 --> 00:07:46,479
when you think about the models right as

202
00:07:46,479 --> 00:07:48,400
you said most of the ai systems or

203
00:07:48,400 --> 00:07:49,919
self-driving car systems they're kind of

204
00:07:49,919 --> 00:07:52,080
like using the same

205
00:07:52,080 --> 00:07:53,599
networks basically

206
00:07:53,599 --> 00:07:55,039
there's the same different networks that

207
00:07:55,039 --> 00:07:57,440
they've employed in different ways

208
00:07:57,440 --> 00:07:58,960
so the transferability as you're

209
00:07:58,960 --> 00:08:00,400
mentioning again if i discover an

210
00:08:00,400 --> 00:08:01,919
exploit that works in this particular

211
00:08:01,919 --> 00:08:03,199
model most likely it's going to work

212
00:08:03,199 --> 00:08:04,720
against the rest

213
00:08:04,720 --> 00:08:06,800
but from an ai researcher's standpoint

214
00:08:06,800 --> 00:08:09,599
right like when you even begin to get it

215
00:08:09,599 --> 00:08:11,039
solved as in let's just say you find a

216
00:08:11,039 --> 00:08:12,560
problem with tesla side driving car

217
00:08:12,560 --> 00:08:14,080
right it's not going to be just a tesla

218
00:08:14,080 --> 00:08:15,360
problem it's probably going to affect

219
00:08:15,360 --> 00:08:17,680
volvo it'll probably affect maybe bobby

220
00:08:17,680 --> 00:08:18,960
effect uh you know any other

221
00:08:18,960 --> 00:08:21,039
self-driving car manufacturers as well

222
00:08:21,039 --> 00:08:23,680
so how would you suggest to ai

223
00:08:23,680 --> 00:08:25,520
researchers if they wanted to start you

224
00:08:25,520 --> 00:08:28,080
know looking fuzzing for ai model

225
00:08:28,080 --> 00:08:29,680
vulnerabilities how would you go about

226
00:08:29,680 --> 00:08:32,000
doing it

227
00:08:32,080 --> 00:08:36,159
uh sure so the first of all like um

228
00:08:36,159 --> 00:08:38,159
we we have a framework we call the

229
00:08:38,159 --> 00:08:40,880
awareness assessment insurance

230
00:08:40,880 --> 00:08:44,080
uh so first of all um in terms of

231
00:08:44,080 --> 00:08:46,000
awareness

232
00:08:46,000 --> 00:08:48,399
is it's basically uh

233
00:08:48,399 --> 00:08:50,160
important thing to to build a threat

234
00:08:50,160 --> 00:08:52,480
model to understand like what are

235
00:08:52,480 --> 00:08:53,279
their

236
00:08:53,279 --> 00:08:54,720
particular

237
00:08:54,720 --> 00:08:58,640
uh attacks can happen uh because you you

238
00:08:58,640 --> 00:09:02,399
basically cannot protect from everything

239
00:09:02,399 --> 00:09:05,040
uh so it's a it's a it's a fundamental

240
00:09:05,040 --> 00:09:07,279
flow and it's a trait it's usually it's

241
00:09:07,279 --> 00:09:10,800
a trade-off between uh security and

242
00:09:10,800 --> 00:09:14,560
accuracy uh so in order to protect the

243
00:09:14,560 --> 00:09:16,000
system

244
00:09:16,000 --> 00:09:18,000
uh

245
00:09:18,000 --> 00:09:20,320
you have to understand what are the what

246
00:09:20,320 --> 00:09:23,120
are the threats uh

247
00:09:23,120 --> 00:09:26,720
uh so first step is to uh

248
00:09:26,720 --> 00:09:28,880
uh if if you know the threads then you

249
00:09:28,880 --> 00:09:31,200
can construct some uh that you can

250
00:09:31,200 --> 00:09:33,440
perform some kind of uh assessment or

251
00:09:33,440 --> 00:09:35,440
pen testing and basically

252
00:09:35,440 --> 00:09:39,519
uh find uh what kind of attacks uh

253
00:09:39,519 --> 00:09:42,880
can break your system

254
00:09:42,880 --> 00:09:45,279
um

255
00:09:45,279 --> 00:09:47,760
then when you uh found the the

256
00:09:47,760 --> 00:09:50,480
vulnerabilities uh that's the then you

257
00:09:50,480 --> 00:09:52,399
have the most complex uh

258
00:09:52,399 --> 00:09:54,320
problem how to fix that

259
00:09:54,320 --> 00:09:56,399
um

260
00:09:56,399 --> 00:09:58,959
so and this is uh

261
00:09:58,959 --> 00:10:01,519
yes i i will mention in details in the

262
00:10:01,519 --> 00:10:04,000
presentation but the problem currently

263
00:10:04,000 --> 00:10:07,760
is that it's not like a sql injection

264
00:10:07,760 --> 00:10:08,880
where you

265
00:10:08,880 --> 00:10:12,000
kind of know how to fix it now

266
00:10:12,000 --> 00:10:13,760
uh

267
00:10:13,760 --> 00:10:15,600
it's uh

268
00:10:15,600 --> 00:10:19,360
it's a vulnerability that if you

269
00:10:19,360 --> 00:10:22,959
let's say i i can create

270
00:10:22,959 --> 00:10:24,640
some uh

271
00:10:24,640 --> 00:10:27,760
advertarial stop sign and you will take

272
00:10:27,760 --> 00:10:30,560
this uh photo as you know still elon

273
00:10:30,560 --> 00:10:34,720
musk says that uh in uh

274
00:10:34,720 --> 00:10:37,519
test ai day just a week ago

275
00:10:37,519 --> 00:10:39,760
uh there was a one question like about

276
00:10:39,760 --> 00:10:41,120
the adversarial examples for

277
00:10:41,120 --> 00:10:43,360
self-driving cars so he said that

278
00:10:43,360 --> 00:10:44,160
uh

279
00:10:44,160 --> 00:10:46,640
you haven't seen you know in a while but

280
00:10:46,640 --> 00:10:48,640
if he will see

281
00:10:48,640 --> 00:10:51,360
they will just train the system

282
00:10:51,360 --> 00:10:52,240
uh

283
00:10:52,240 --> 00:10:54,480
to prevent such attacks because they

284
00:10:54,480 --> 00:10:56,560
will have the example so they will put

285
00:10:56,560 --> 00:10:58,720
this example in a training center that's

286
00:10:58,720 --> 00:10:59,440
it

287
00:10:59,440 --> 00:11:01,360
but it doesn't work like this so if you

288
00:11:01,360 --> 00:11:02,320
put this

289
00:11:02,320 --> 00:11:03,920
on the training set

290
00:11:03,920 --> 00:11:06,720
you will protect just from this example

291
00:11:06,720 --> 00:11:08,480
yes or and

292
00:11:08,480 --> 00:11:11,600
a little bit of similar examples but not

293
00:11:11,600 --> 00:11:12,399
the

294
00:11:12,399 --> 00:11:14,560
entire

295
00:11:14,560 --> 00:11:17,518
list of examples

296
00:11:18,640 --> 00:11:20,399
so in order to

297
00:11:20,399 --> 00:11:23,920
protect the system currently we have um

298
00:11:23,920 --> 00:11:26,240
three

299
00:11:26,399 --> 00:11:29,600
high level uh ways of how to do that

300
00:11:29,600 --> 00:11:30,399
uh

301
00:11:30,399 --> 00:11:33,360
one is adversarial uh one is to do

302
00:11:33,360 --> 00:11:36,079
something with training so

303
00:11:36,079 --> 00:11:38,480
uh different types of adversarial

304
00:11:38,480 --> 00:11:39,600
training

305
00:11:39,600 --> 00:11:41,200
um

306
00:11:41,200 --> 00:11:44,560
distillation so something when we train

307
00:11:44,560 --> 00:11:45,760
the system

308
00:11:45,760 --> 00:11:48,800
augmentation and etc

309
00:11:48,800 --> 00:11:50,880
uh there are different approaches some

310
00:11:50,880 --> 00:11:53,760
of them will uh work good some of them

311
00:11:53,760 --> 00:11:55,120
were

312
00:11:55,120 --> 00:11:58,560
not good but in general uh

313
00:11:58,560 --> 00:12:00,079
those approaches

314
00:12:00,079 --> 00:12:01,440
uh

315
00:12:01,440 --> 00:12:02,399
are

316
00:12:02,399 --> 00:12:04,320
can cost you a lot because you need to

317
00:12:04,320 --> 00:12:06,000
retrain the system

318
00:12:06,000 --> 00:12:07,680
and uh

319
00:12:07,680 --> 00:12:09,920
it can cost you like at least the same

320
00:12:09,920 --> 00:12:11,279
amount of

321
00:12:11,279 --> 00:12:13,839
time and money as to train

322
00:12:13,839 --> 00:12:16,800
system uh without adversarial examples

323
00:12:16,800 --> 00:12:19,680
or probably like 10 times more because

324
00:12:19,680 --> 00:12:21,680
you need to train it with

325
00:12:21,680 --> 00:12:24,160
various types of adversarial examples

326
00:12:24,160 --> 00:12:26,800
the problem here is that you

327
00:12:26,800 --> 00:12:31,200
still won't be able to catch all of them

328
00:12:31,200 --> 00:12:35,600
uh so then we have a second uh but but

329
00:12:35,600 --> 00:12:38,079
you should do that it's like uh it's

330
00:12:38,079 --> 00:12:41,200
like a basic thing it's like to uh

331
00:12:41,200 --> 00:12:44,240
wash your teeth so

332
00:12:44,320 --> 00:12:45,839
you know nothing else at least you do

333
00:12:45,839 --> 00:12:47,040
this

334
00:12:47,040 --> 00:12:48,959
yeah at first training it's something

335
00:12:48,959 --> 00:12:50,639
that you should do

336
00:12:50,639 --> 00:12:52,399
um

337
00:12:52,399 --> 00:12:54,959
uh and in some ways adversarial training

338
00:12:54,959 --> 00:12:56,240
can uh

339
00:12:56,240 --> 00:12:59,120
can help you to make the system more uh

340
00:12:59,120 --> 00:13:00,720
accurate

341
00:13:00,720 --> 00:13:06,000
um so it's just a it's a good way of

342
00:13:06,000 --> 00:13:09,440
training the system like to make it

343
00:13:09,440 --> 00:13:11,839
better like if that if you just don't

344
00:13:11,839 --> 00:13:14,399
care about security uh

345
00:13:14,399 --> 00:13:16,880
just simple resettle chatting may can

346
00:13:16,880 --> 00:13:18,800
make your system uh

347
00:13:18,800 --> 00:13:20,800
better in terms of factors

348
00:13:20,800 --> 00:13:23,040
second thing is to

349
00:13:23,040 --> 00:13:25,680
uh uh

350
00:13:25,680 --> 00:13:26,480
uh

351
00:13:26,480 --> 00:13:29,440
do something with the model itself uh

352
00:13:29,440 --> 00:13:30,639
there are

353
00:13:30,639 --> 00:13:34,800
different activation functions that

354
00:13:35,279 --> 00:13:37,200
have better

355
00:13:37,200 --> 00:13:41,440
uh work better in adversarial

356
00:13:41,440 --> 00:13:43,360
circumstances

357
00:13:43,360 --> 00:13:45,920
you can add some layers so you can do

358
00:13:45,920 --> 00:13:47,440
something with

359
00:13:47,440 --> 00:13:50,480
the architecture of the model

360
00:13:50,480 --> 00:13:53,040
the advantages here is that you can

361
00:13:53,040 --> 00:13:53,920
really

362
00:13:53,920 --> 00:13:55,920
do uh

363
00:13:55,920 --> 00:13:57,680
something good but

364
00:13:57,680 --> 00:14:00,720
uh the disadvantage is that you can uh

365
00:14:00,720 --> 00:14:02,160
a lot

366
00:14:02,160 --> 00:14:05,279
you can have less accuracy when you do

367
00:14:05,279 --> 00:14:08,000
some such kind of changes

368
00:14:08,000 --> 00:14:10,880
the third approach is to do some kind of

369
00:14:10,880 --> 00:14:12,240
um

370
00:14:12,240 --> 00:14:14,639
input uh

371
00:14:14,639 --> 00:14:18,720
something with input like if you have a

372
00:14:18,720 --> 00:14:20,320
uh

373
00:14:20,320 --> 00:14:23,040
images you can do a jpeg compression so

374
00:14:23,040 --> 00:14:26,480
you can do something to avoid uh

375
00:14:26,480 --> 00:14:28,880
those adverse several examples

376
00:14:28,880 --> 00:14:32,320
uh this approach probably one of the

377
00:14:32,320 --> 00:14:34,959
best ones but the disadvantage of this

378
00:14:34,959 --> 00:14:36,480
approach is that

379
00:14:36,480 --> 00:14:37,839
it's very

380
00:14:37,839 --> 00:14:41,040
uh specific to particular

381
00:14:41,040 --> 00:14:44,800
application so you cannot uh

382
00:14:44,800 --> 00:14:47,680
use it like very broadly so if you

383
00:14:47,680 --> 00:14:49,440
have a

384
00:14:49,440 --> 00:14:51,120
um uh

385
00:14:51,120 --> 00:14:52,800
approach to

386
00:14:52,800 --> 00:14:53,760
uh

387
00:14:53,760 --> 00:14:55,360
let's say detect the particular

388
00:14:55,360 --> 00:14:57,519
adversarial examples for the roadsides

389
00:14:57,519 --> 00:15:00,240
and do something with in physical world

390
00:15:00,240 --> 00:15:03,839
with this camera input it won't be

391
00:15:03,839 --> 00:15:06,880
transferable to facial recognition

392
00:15:06,880 --> 00:15:09,839
it's domain specific

393
00:15:10,160 --> 00:15:13,920
yeah so we have three options and um

394
00:15:13,920 --> 00:15:16,160
and we have detection

395
00:15:16,160 --> 00:15:17,680
like it's uh

396
00:15:17,680 --> 00:15:19,760
um additional

397
00:15:19,760 --> 00:15:21,839
in addition to all of this

398
00:15:21,839 --> 00:15:22,720
so

399
00:15:22,720 --> 00:15:25,279
those three approaches is like about

400
00:15:25,279 --> 00:15:27,199
known known uh

401
00:15:27,199 --> 00:15:29,920
known unknowns and the detection is

402
00:15:29,920 --> 00:15:32,240
about unknown unknowns

403
00:15:32,240 --> 00:15:34,800
and uh at adversary uh are you guys

404
00:15:34,800 --> 00:15:36,880
actually looking into the possibility of

405
00:15:36,880 --> 00:15:39,360
using like a q learning function

406
00:15:39,360 --> 00:15:41,040
in order to generate adversarial

407
00:15:41,040 --> 00:15:43,759
examples so rewarding the the model for

408
00:15:43,759 --> 00:15:45,920
producing better adversarial examples

409
00:15:45,920 --> 00:15:48,240
that would then be able to whatever full

410
00:15:48,240 --> 00:15:50,639
facial recognition or a sign detector or

411
00:15:50,639 --> 00:15:53,600
whatever link guidance

412
00:15:53,920 --> 00:15:56,079
uh

413
00:15:56,079 --> 00:15:58,160
it's interesting idea we we haven't

414
00:15:58,160 --> 00:15:59,920
tried that uh

415
00:15:59,920 --> 00:16:02,079
so yeah like uh use reinforcement

416
00:16:02,079 --> 00:16:03,759
learning to uh

417
00:16:03,759 --> 00:16:06,639
yeah to find to drive the uh

418
00:16:06,639 --> 00:16:08,880
zero

419
00:16:09,839 --> 00:16:11,680
i think we um

420
00:16:11,680 --> 00:16:12,480
we

421
00:16:12,480 --> 00:16:14,880
we don't use the particular q learning

422
00:16:14,880 --> 00:16:18,959
but in in the our uh next flight we

423
00:16:18,959 --> 00:16:20,839
yeah

424
00:16:20,839 --> 00:16:22,480
we uh

425
00:16:22,480 --> 00:16:24,639
we randomly

426
00:16:24,639 --> 00:16:27,360
search for something and then test it in

427
00:16:27,360 --> 00:16:29,759
in in different areas

428
00:16:29,759 --> 00:16:32,320
so um would you equate your your

429
00:16:32,320 --> 00:16:34,639
technique to kind of like fuzzing as in

430
00:16:34,639 --> 00:16:36,560
like it's fuzzy for ai or is it would

431
00:16:36,560 --> 00:16:39,519
you use a different term for it

432
00:16:39,519 --> 00:16:40,639
uh

433
00:16:40,639 --> 00:16:42,959
no i think so the the technique is

434
00:16:42,959 --> 00:16:46,079
basically uh uh is based on the

435
00:16:46,079 --> 00:16:48,959
adversarial octopus we call that the

436
00:16:48,959 --> 00:16:52,320
cell octopus because it uh it has uh

437
00:16:52,320 --> 00:16:53,920
eight legs

438
00:16:53,920 --> 00:16:54,880
so

439
00:16:54,880 --> 00:16:58,240
there are uh at least eight uh different

440
00:16:58,240 --> 00:17:00,160
uh techniques to

441
00:17:00,160 --> 00:17:01,199
uh

442
00:17:01,199 --> 00:17:03,920
to make the exploit

443
00:17:03,920 --> 00:17:06,559
better

444
00:17:06,559 --> 00:17:09,599
so some techniques help the exploit to

445
00:17:09,599 --> 00:17:12,480
be more transferable

446
00:17:12,480 --> 00:17:14,079
those are

447
00:17:14,079 --> 00:17:16,160
ensemble learning

448
00:17:16,160 --> 00:17:19,359
for example some techniques help uh

449
00:17:19,359 --> 00:17:22,720
exploit be uh more imperceptible

450
00:17:22,720 --> 00:17:26,799
uh so we use smoothing for uh

451
00:17:26,799 --> 00:17:29,760
uh to make it less imperceptible so that

452
00:17:29,760 --> 00:17:32,880
for example if you see here it's also

453
00:17:32,880 --> 00:17:35,440
like kind of adversarial example

454
00:17:35,440 --> 00:17:38,960
uh but you you can you can see that it's

455
00:17:38,960 --> 00:17:40,960
it's something strange so

456
00:17:40,960 --> 00:17:43,760
we use more smoothing for

457
00:17:43,760 --> 00:17:45,440
and some techniques

458
00:17:45,440 --> 00:17:47,440
we use for uh

459
00:17:47,440 --> 00:17:48,880
more

460
00:17:48,880 --> 00:17:51,520
accuracy

461
00:17:51,760 --> 00:17:53,840
so

462
00:17:53,840 --> 00:17:56,559
some of them for example we use fuzzing

463
00:17:56,559 --> 00:17:57,919
to

464
00:17:57,919 --> 00:18:00,160
uh

465
00:18:00,160 --> 00:18:02,320
uh too fast the

466
00:18:02,320 --> 00:18:05,280
the face detection frame

467
00:18:05,280 --> 00:18:08,240
because one of the uh interesting uh

468
00:18:08,240 --> 00:18:10,960
things in fact in hacking facial

469
00:18:10,960 --> 00:18:13,840
recognition system is that you basically

470
00:18:13,840 --> 00:18:18,799
should uh break two uh ai systems uh

471
00:18:18,799 --> 00:18:20,080
all together

472
00:18:20,080 --> 00:18:22,799
because you have a face detection and

473
00:18:22,799 --> 00:18:25,440
then uh you have face recognition so

474
00:18:25,440 --> 00:18:27,360
it's two ai systems

475
00:18:27,360 --> 00:18:30,080
uh the problem here is that sometimes if

476
00:18:30,080 --> 00:18:31,840
you if you make

477
00:18:31,840 --> 00:18:34,720
some some exploit for facial recognition

478
00:18:34,720 --> 00:18:36,720
system it can break the functionality of

479
00:18:36,720 --> 00:18:38,480
space detection system

480
00:18:38,480 --> 00:18:42,480
and it won't detect your your face uh

481
00:18:42,480 --> 00:18:44,559
and sometimes the phase detection

482
00:18:44,559 --> 00:18:47,039
algorithms are different and making

483
00:18:47,039 --> 00:18:50,000
different frames so in order to

484
00:18:50,000 --> 00:18:53,440
uh bypass it we use fuzzing to fast the

485
00:18:53,440 --> 00:18:57,200
different types of frames in to for

486
00:18:57,200 --> 00:18:59,679
frame detection that's cool man

487
00:18:59,679 --> 00:19:01,200
you mentioned about detection just now

488
00:19:01,200 --> 00:19:03,440
briefly where where and what do you

489
00:19:03,440 --> 00:19:06,080
actually detect um in terms of

490
00:19:06,080 --> 00:19:07,280
maybe

491
00:19:07,280 --> 00:19:08,400
and

492
00:19:08,400 --> 00:19:10,080
data poisoning attack or something right

493
00:19:10,080 --> 00:19:12,640
on the model

494
00:19:12,640 --> 00:19:15,600
how does that work

495
00:19:16,720 --> 00:19:19,360
uh so can you can you

496
00:19:19,360 --> 00:19:21,520
mention something about detection as a

497
00:19:21,520 --> 00:19:23,280
method of protection just now right so

498
00:19:23,280 --> 00:19:25,840
how how would the detection again often

499
00:19:25,840 --> 00:19:28,880
attack against an ai system work

500
00:19:28,880 --> 00:19:30,799
ah okay uh

501
00:19:30,799 --> 00:19:33,039
there are uh in general there are two

502
00:19:33,039 --> 00:19:34,960
types of uh

503
00:19:34,960 --> 00:19:38,960
two big categories of detection uh

504
00:19:38,960 --> 00:19:41,039
for uh attacks

505
00:19:41,039 --> 00:19:42,320
uh

506
00:19:42,320 --> 00:19:45,600
one area is is uh like supervised

507
00:19:45,600 --> 00:19:47,520
learning based another is unsupervised

508
00:19:47,520 --> 00:19:51,280
learning based so uh for one type we

509
00:19:51,280 --> 00:19:55,120
just uh train uh it's basically the

510
00:19:55,120 --> 00:19:56,799
training ai

511
00:19:56,799 --> 00:19:57,600
uh

512
00:19:57,600 --> 00:19:59,600
to recognize

513
00:19:59,600 --> 00:20:00,880
uh

514
00:20:00,880 --> 00:20:03,280
uh adversarial and other serial examples

515
00:20:03,280 --> 00:20:06,080
so you basically have a lot of examples

516
00:20:06,080 --> 00:20:08,159
of attacks and a lot of examples of

517
00:20:08,159 --> 00:20:10,240
normal behavior and you train the

518
00:20:10,240 --> 00:20:13,039
specific system to do that but it's just

519
00:20:13,039 --> 00:20:14,480
it's a it's a different system so you

520
00:20:14,480 --> 00:20:15,520
don't

521
00:20:15,520 --> 00:20:18,640
touch your ai you're just building the

522
00:20:18,640 --> 00:20:22,240
another ai uh to

523
00:20:22,240 --> 00:20:25,039
uh to perform detection i got an ai

524
00:20:25,039 --> 00:20:27,120
because you like ai so i made an ai to

525
00:20:27,120 --> 00:20:29,678
detect uae

526
00:20:30,400 --> 00:20:33,960
yeah yeah

527
00:20:38,720 --> 00:20:40,159
we've got like nine minutes before your

528
00:20:40,159 --> 00:20:43,039
talk uh maybe one last question so about

529
00:20:43,039 --> 00:20:45,600
the trustworthiness of ai right

530
00:20:45,600 --> 00:20:47,520
i think everybody is concerned about how

531
00:20:47,520 --> 00:20:49,360
safe are these systems as in like can i

532
00:20:49,360 --> 00:20:51,360
really lift my hands off the wheel right

533
00:20:51,360 --> 00:20:53,280
like in a self-driving car

534
00:20:53,280 --> 00:20:55,200
um what do you think it's going to take

535
00:20:55,200 --> 00:20:58,320
for general people to adopt the you know

536
00:20:58,320 --> 00:21:00,000
letting ai just kind of like run their

537
00:21:00,000 --> 00:21:01,360
lives you know what i mean and making

538
00:21:01,360 --> 00:21:03,039
more important decisions for them as in

539
00:21:03,039 --> 00:21:04,320
like self-driving car would say it would

540
00:21:04,320 --> 00:21:05,919
be a big one right like

541
00:21:05,919 --> 00:21:07,840
letting a machine

542
00:21:07,840 --> 00:21:11,520
be in charge of your life at speed

543
00:21:12,559 --> 00:21:13,679
what do you think it's going to take for

544
00:21:13,679 --> 00:21:16,400
people to to feel more safe as in that

545
00:21:16,400 --> 00:21:18,000
that the ai system is trustworthy

546
00:21:18,000 --> 00:21:19,840
because it's black box right like nobody

547
00:21:19,840 --> 00:21:21,520
knows what's gone into it nobody knows

548
00:21:21,520 --> 00:21:23,039
what kind of resilience testing has been

549
00:21:23,039 --> 00:21:24,080
done nobody knows what kind of

550
00:21:24,080 --> 00:21:26,480
adversarial examples have has it been

551
00:21:26,480 --> 00:21:27,600
shown

552
00:21:27,600 --> 00:21:29,120
you know you don't want to be that guy

553
00:21:29,120 --> 00:21:30,960
that was in that particular car at that

554
00:21:30,960 --> 00:21:32,720
particular time that something happened

555
00:21:32,720 --> 00:21:34,960
right

556
00:21:35,280 --> 00:21:36,880
yeah yeah uh

557
00:21:36,880 --> 00:21:39,200
you know it's uh i

558
00:21:39,200 --> 00:21:41,520
the year ago when it was possible to

559
00:21:41,520 --> 00:21:45,039
travel i i i traveled a lot around the

560
00:21:45,039 --> 00:21:48,080
world i was asking people

561
00:21:48,080 --> 00:21:50,159
exactly the same question like would you

562
00:21:50,159 --> 00:21:52,640
trust a self-driving car would you sit

563
00:21:52,640 --> 00:21:54,240
in the cell driving car and was asking

564
00:21:54,240 --> 00:21:55,440
people like

565
00:21:55,440 --> 00:21:59,679
everywhere uh in amazon jungle in

566
00:21:59,679 --> 00:22:02,559
albania like completely everywhere

567
00:22:02,559 --> 00:22:05,520
most of the people uh uh were saying

568
00:22:05,520 --> 00:22:09,200
like no i won't trust that like never

569
00:22:09,200 --> 00:22:11,520
so when i came to israel the first time

570
00:22:11,520 --> 00:22:15,440
i said in in the taxi the guy said

571
00:22:15,440 --> 00:22:17,440
when we will have self-driving cars i'm

572
00:22:17,440 --> 00:22:19,130
so tired of writing

573
00:22:19,130 --> 00:22:21,760
[Laughter]

574
00:22:21,760 --> 00:22:23,840
and i was like wow it's it's so

575
00:22:23,840 --> 00:22:26,080
different you know it's it's it's really

576
00:22:26,080 --> 00:22:28,799
different so like in some places of the

577
00:22:28,799 --> 00:22:31,440
world we already

578
00:22:31,440 --> 00:22:33,600
more than trust those systems in some

579
00:22:33,600 --> 00:22:36,320
places uh we don't so

580
00:22:36,320 --> 00:22:37,280
uh

581
00:22:37,280 --> 00:22:39,840
i don't know it's like any uh like any

582
00:22:39,840 --> 00:22:42,480
uh type of new invention

583
00:22:42,480 --> 00:22:44,960
uh we will need time but

584
00:22:44,960 --> 00:22:45,919
uh

585
00:22:45,919 --> 00:22:49,039
since corona happened i i see that

586
00:22:49,039 --> 00:22:49,840
the

587
00:22:49,840 --> 00:22:53,440
the speed of adoption is like

588
00:22:53,440 --> 00:22:56,159
very high it's like much higher than

589
00:22:56,159 --> 00:22:58,080
than we expected

590
00:22:58,080 --> 00:22:59,679
so

591
00:22:59,679 --> 00:23:02,880
like there are good things uh like

592
00:23:02,880 --> 00:23:05,360
like people saying here if your lives if

593
00:23:05,360 --> 00:23:07,679
i've given you the lime uh make a

594
00:23:07,679 --> 00:23:08,880
lemonade

595
00:23:08,880 --> 00:23:10,880
so

596
00:23:10,880 --> 00:23:12,799
here we have the same with corona so

597
00:23:12,799 --> 00:23:14,559
there are a lot of disadvantages but

598
00:23:14,559 --> 00:23:17,520
there are many advantages here as well

599
00:23:17,520 --> 00:23:19,280
but now fair enough thanks so much for

600
00:23:19,280 --> 00:23:20,960
joining us bro uh we'll let you get

601
00:23:20,960 --> 00:23:22,240
ready for your talk in about five

602
00:23:22,240 --> 00:23:24,159
minutes and then we'll be watching it uh

603
00:23:24,159 --> 00:23:25,919
in the track shortly

604
00:23:25,919 --> 00:23:28,000
thanks for joining us thanks yeah thanks

605
00:23:28,000 --> 00:23:30,480
for inviting me have a nice day see you

606
00:23:30,480 --> 00:23:34,200
soon brother ciao

