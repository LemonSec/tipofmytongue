1
00:00:14,720 --> 00:00:17,430
all right good afternoon everyone hear
me

2
00:00:17,430 --> 00:00:23,520
excellent alright so my very vague and
mysterious title the observer effect and

3
00:00:23,520 --> 00:00:27,990
cyber feng shui i'll be talking about
today before we get started or before

4
00:00:27,990 --> 00:00:29,729
people wander out I wanted to talk

5
00:00:29,730 --> 00:00:34,110
basically in a nutshell what my talk is
so if you guys fall asleep or wander out

6
00:00:34,110 --> 00:00:38,040
to the coffee machines out there at
least you'll try to remember this

7
00:00:38,040 --> 00:00:42,510
so basically what this talk is about is
using existing hardware or misusing

8
00:00:42,510 --> 00:00:47,370
existing hardware and non-traditional
way to be able to build a trusted botnet

9
00:00:47,370 --> 00:00:49,589
or a trusted implant network

10
00:00:49,590 --> 00:00:55,020
we're on an offensive operation you can
detect if someone is trying to

11
00:00:55,020 --> 00:01:00,360
virtualize you or debug you to be able
to create device specific key material

12
00:01:00,360 --> 00:01:06,750
so that you can't be viewed or decrypted
on another system and then lastly to run

13
00:01:06,750 --> 00:01:12,540
an encrypted mode so it makes it very
difficult to be reverse engineered so

14
00:01:12,540 --> 00:01:15,570
this is a technical talk but you're all
pretty technical

15
00:01:15,570 --> 00:01:19,169
it does cover a lot of topics this is
kind of three topics crammed into one

16
00:01:19,830 --> 00:01:25,408
I will be moving fairly quickly but if
you have any questions about clarifying

17
00:01:25,409 --> 00:01:28,020
of acronyms or terms or concepts

18
00:01:28,020 --> 00:01:32,759
please raise your hand at any time
because most likely there are five other

19
00:01:32,760 --> 00:01:36,600
people they're just too shy to ask the
same question or I did a really bad job

20
00:01:36,600 --> 00:01:39,658
explaining something so I'd rather have
you know as soon as possible i gave a

21
00:01:39,659 --> 00:01:45,090
talk it a conference in las vegas and i
asked any questions I told him the same

22
00:01:45,090 --> 00:01:48,570
thing no questions at the end no
questions did all right we'll see you at

23
00:01:48,570 --> 00:01:52,289
the bar and everyone got up in line and
ask the same clarifying question one

24
00:01:52,290 --> 00:01:55,409
after another that they were too
embarrassed about so please if you have

25
00:01:55,409 --> 00:01:58,409
a question raise your hand

26
00:01:59,100 --> 00:02:02,548
more broad or typical questions you
please hold to the end

27
00:02:02,549 --> 00:02:08,519
so really quickly oh my i live in denver
colorado where it's always sunny and not

28
00:02:08,519 --> 00:02:09,570
humid

29
00:02:09,570 --> 00:02:13,530
unlike here I lead the low levels
computer architecture group so that

30
00:02:13,530 --> 00:02:16,049
means mostly i play in system management
mode

31
00:02:16,049 --> 00:02:21,269
I right hypervisors or write my own bios
I'm one of Sergei brought us is lying

32
00:02:21,269 --> 00:02:25,859
sack co-conspirators and I like ultra
running or mountaineering cetera

33
00:02:27,300 --> 00:02:31,290
we're going to talk about why this is a
problem and introduce kind of what we're

34
00:02:31,290 --> 00:02:35,190
going to talk about the Triforce those
of you who are Zelda fans so there's

35
00:02:35,190 --> 00:02:38,970
three pieces to this there's the
software dynamic root of trust which

36
00:02:38,970 --> 00:02:43,230
allows you to make sure that you're not
being run in a virtualized environment

37
00:02:43,230 --> 00:02:46,649
or make sure that there's not too
introspective hypervisor or debugger

38
00:02:46,650 --> 00:02:49,710
which builds off of trusted computing

39
00:02:49,710 --> 00:02:53,280
we're going to talk about
device-specific keys so that's using the

40
00:02:53,280 --> 00:02:57,360
physically includable functions are
called or puffs and then talk about some

41
00:02:57,360 --> 00:03:01,650
crypto on top of that that provides some
extra capabilities and then the last one

42
00:03:01,650 --> 00:03:05,490
is a secure execution enclave which
helps defend against reverse engineering

43
00:03:05,490 --> 00:03:10,320
and that's encrypted execution and we'll
put it all together and then it draws a

44
00:03:10,320 --> 00:03:13,320
couple conclusions

45
00:03:16,200 --> 00:03:21,179
so on a red team so I'm going to be
talking as if I'm a red team and I'm

46
00:03:21,180 --> 00:03:26,070
legally doing all of this stuff and so
when I say it's bad or it's hard it

47
00:03:26,070 --> 00:03:31,380
means that the defenders are doing a
good job but you can also assume that

48
00:03:31,380 --> 00:03:34,079
this would be something you might want
to defend against in the future

49
00:03:34,080 --> 00:03:39,720
so after you've got in and got a
foothold in the network next generation

50
00:03:39,720 --> 00:03:44,100
Navy's introspective hypervisors like we
saw in the last talk using a Librium I

51
00:03:44,100 --> 00:03:49,049
or Jack tough for some of the other
tools fire I has a hypervisor basically

52
00:03:49,050 --> 00:03:53,400
they are now able to try to infer more
and more about what your application is

53
00:03:53,400 --> 00:03:58,680
doing and they're trying to flag it as
soon as possible and so also what

54
00:03:58,680 --> 00:04:02,160
happens is you'll have a reputation
based file system

55
00:04:02,160 --> 00:04:05,970
all right AV where once it finds an odd
file on your corporate network if it's

56
00:04:05,970 --> 00:04:09,900
nowhere else it might actually ship that
file off somewhere else for someone to

57
00:04:09,900 --> 00:04:14,220
do some analysis on and so as you're
trying to be you know really persistent

58
00:04:14,220 --> 00:04:18,480
on a network you want to make sure that
you're not giving up your tactics

59
00:04:18,480 --> 00:04:22,500
techniques and procedures your TTP's as
long as possible because you want to

60
00:04:22,500 --> 00:04:23,940
maintain presence on there

61
00:04:23,940 --> 00:04:26,940
you also want to make sure that you're
not burning your capabilities are giving

62
00:04:26,940 --> 00:04:30,000
them too much information about what
your capabilities are and so it's very

63
00:04:30,000 --> 00:04:34,680
important especially if you're dealing
with the very high level red team where

64
00:04:34,680 --> 00:04:35,500
you're using

65
00:04:35,500 --> 00:04:39,310
fairly expensive say zero-day or new
type of attack

66
00:04:39,310 --> 00:04:42,310
you don't want to give that up and make
that public in case someone catches it

67
00:04:43,360 --> 00:04:47,080
so the three tools basically we're going
to bootstrap so the first one when you

68
00:04:47,080 --> 00:04:51,070
get on your kind of initial stage one
dropped a biner you have execution

69
00:04:51,070 --> 00:04:54,940
control you want to figure out whether
or not there's something on there that's

70
00:04:54,940 --> 00:04:57,190
trying to see what you're doing and so
that could be

71
00:04:57,190 --> 00:05:01,480
am i running on fire I am i running in a
debugger or am i running on the system i

72
00:05:01,480 --> 00:05:02,650
think i'm running on

73
00:05:02,650 --> 00:05:08,109
so this is the observer effect basically
which most people complete with the

74
00:05:08,110 --> 00:05:10,360
Heisenberg uncertainty theorem where you
think

75
00:05:10,360 --> 00:05:13,360
which the action of observing changes
the result

76
00:05:13,360 --> 00:05:17,020
and so basically the presence of
introspection and introspective software

77
00:05:17,020 --> 00:05:20,500
running on the system will in fact
change the behavior of that system and

78
00:05:20,500 --> 00:05:24,400
you can try to find that that's what
we'll talk about number two

79
00:05:24,400 --> 00:05:26,770
so we're going to generate
device-specific keys that allow you to

80
00:05:26,770 --> 00:05:30,969
tie cryptography to a certain host or
certain device that's kind of getting

81
00:05:30,970 --> 00:05:33,760
cozy once ran and we're feeling
comfortable that were no one's kind of

82
00:05:33,760 --> 00:05:38,320
prying into what we're doing we can kind
of work on that the Feng Shui of the

83
00:05:38,320 --> 00:05:42,040
hardware and kind of get more
comfortable and then the last one is is

84
00:05:42,040 --> 00:05:45,280
a the opaque execution environment this
i'm going to go very quickly

85
00:05:45,970 --> 00:05:49,900
this is the talk i gave couple times
last year called hairs are an anti

86
00:05:49,900 --> 00:05:54,280
reverse engineering basically a
capability to run a program encrypted at

87
00:05:54,280 --> 00:05:58,690
near-native speed on cots hardware so
that i'm going to skip over very quickly

88
00:05:58,690 --> 00:06:02,169
but at least just provide you a place to
go look for more information

89
00:06:02,770 --> 00:06:07,240
so let's get going right here so first a
little bit of background for

90
00:06:07,240 --> 00:06:11,200
introspection so trusted computing on
the defense side it's basically a field

91
00:06:11,200 --> 00:06:15,190
of security that tries to establish a
root of trust which is something either

92
00:06:15,190 --> 00:06:20,320
hardware back or software back then you
go from there and so you trying to make

93
00:06:20,320 --> 00:06:23,380
sure that you know what's running on the
system and only that can run on a system

94
00:06:23,380 --> 00:06:27,340
or at least you know if something has
gone awry and you kind of extend that

95
00:06:27,340 --> 00:06:31,750
which called a chain of trust or trust
chain you think that the trusted

96
00:06:31,750 --> 00:06:34,570
computing group is kind of the main
force behind this which is kind of a

97
00:06:34,570 --> 00:06:38,469
coalition and you see microsoft and
their palladium effort was similar to

98
00:06:38,470 --> 00:06:42,790
that and then they kind of provided the
TPM and now they have other extensions

99
00:06:42,790 --> 00:06:47,810
on top of that you know for a defensive
operation if you actually deployed this

100
00:06:47,810 --> 00:06:52,010
I would be pretty popular and very
helpful because you can look for you

101
00:06:52,010 --> 00:06:56,030
know Colonel rootkits pretty early on in
the game it's actually becoming much

102
00:06:56,030 --> 00:06:58,309
more popular so windows

103
00:06:58,310 --> 00:07:02,930
I think of us as of eight now it uses a
UEFI secure boot and so if you try to

104
00:07:02,930 --> 00:07:08,360
load an unsigned or a legitimate driver
will actually prevent that from

105
00:07:08,360 --> 00:07:13,730
happening and so you'll know whether or
not your kernel is safe and also tpms

106
00:07:13,730 --> 00:07:17,990
are very very common on x86 platforms
most most computers come with them

107
00:07:18,680 --> 00:07:22,280
so this gives you the ability that you
kind of ensure that only signed or known

108
00:07:22,280 --> 00:07:26,239
good boot loaders can execute and then
you can follow that path all the way up

109
00:07:26,240 --> 00:07:30,410
another feature that's provided by
trusted computing that's less commonly

110
00:07:30,410 --> 00:07:33,889
used is called remote access station
which is basically proving to a remote

111
00:07:33,889 --> 00:07:39,770
entity in a very strong way that you are
entrusted state so saying yes i am

112
00:07:39,770 --> 00:07:43,789
running the drm client that you want me
to or yes i have not been hacked

113
00:07:45,979 --> 00:07:51,229
so there's different measurement types
so static and dynamic and then hardware

114
00:07:51,229 --> 00:07:54,050
and software base for each type so
static measurement

115
00:07:54,050 --> 00:07:57,890
basically you start with some bootrom
that's hopefully you know not rewritable

116
00:07:57,890 --> 00:08:02,630
in on the cpu or in the initial rom on
the motherboard and then you kind of

117
00:08:02,630 --> 00:08:03,740
measure every step

118
00:08:03,740 --> 00:08:07,729
thereafter the problem with this is that
if you have some legacy software you

119
00:08:07,729 --> 00:08:09,740
need to run that doesn't measure the
next piece

120
00:08:09,740 --> 00:08:14,150
so this was a common with pci option
roms you'll get into the issue where the

121
00:08:14,150 --> 00:08:14,630
chest

122
00:08:14,630 --> 00:08:19,850
the chain of trust kind of gets broken
and so let's count down side with static

123
00:08:19,850 --> 00:08:24,110
measurement that's basically UEFI secure
boot to combat these concerns

124
00:08:24,710 --> 00:08:29,239
Intel's trusted execution technology txt
provide dynamic measurement or basically

125
00:08:29,240 --> 00:08:33,440
you can run and you can boot up an
entirely hose system and then basically

126
00:08:33,440 --> 00:08:34,400
click a button

127
00:08:34,400 --> 00:08:39,530
so to speak and then read reset the cpu
into a trusted state and then be able to

128
00:08:39,530 --> 00:08:42,079
attest that you've done that
successfully and so that's what the the

129
00:08:42,080 --> 00:08:48,200
t boot tool does for linux represent
that chain of trust so tpms or a

130
00:08:48,200 --> 00:08:53,120
hardware-based tool they have registered
platform configuration registers pcrs

131
00:08:53,120 --> 00:08:56,180
and they really only have two things you
can either erase them back to their

132
00:08:56,180 --> 00:08:59,420
initial value or you can extend them so
you can

133
00:08:59,420 --> 00:09:03,290
you can't really write directly to them
because that would kind of break the

134
00:09:03,290 --> 00:09:07,250
purpose if you could just set them to
arbitrary values their extended by C is

135
00:09:07,250 --> 00:09:12,980
basically by shaw wanting the old value
of the pcr and the hash of the new

136
00:09:12,980 --> 00:09:17,720
software you're measuring and that means
that you will hatch at the end as long

137
00:09:17,720 --> 00:09:21,530
as every piece of that chain was you
know the same should be the same for

138
00:09:21,530 --> 00:09:26,600
every time and you can detect a single
link in that chain being broken and

139
00:09:26,600 --> 00:09:31,760
obviously unless you can reverse sha-1
you can't set arbitrary values remote

140
00:09:31,760 --> 00:09:37,220
attestation basically typically uses the
the TPM they have a key burned into it

141
00:09:37,220 --> 00:09:41,390
signed by the manufacturing the AI k
which is not exportable and basically

142
00:09:41,390 --> 00:09:45,110
you use that to sign those values and
what's called a quote and provide that

143
00:09:45,110 --> 00:09:48,590
to someone else you can basically show
that you've loaded up in a certain

144
00:09:48,590 --> 00:09:52,340
condition and everything is looking good
to a remote entity

145
00:09:57,500 --> 00:10:02,570
our goal is to make sure that there's no
other process whatever regardless of

146
00:10:02,570 --> 00:10:06,680
what privilege level it's running at is
trying to basically cross that I

147
00:10:06,680 --> 00:10:09,589
isolation boundary to introspect and
what we're doing

148
00:10:09,590 --> 00:10:15,110
so you know the x86 platform has done a
very good job of trying to trick

149
00:10:15,110 --> 00:10:17,960
developers into thinking they're running
in their own little world

150
00:10:17,960 --> 00:10:22,460
they have virtual memory they have all
kind of handled in hardware operating

151
00:10:22,460 --> 00:10:23,030
system

152
00:10:23,030 --> 00:10:26,240
multiplan texting so you don't have to
worry about that but

153
00:10:26,840 --> 00:10:31,490
so you kind of have this development
mindset that you're pretty much running

154
00:10:31,490 --> 00:10:34,970
only on the computer and there's nothing
else outside of you but that's clearly

155
00:10:34,970 --> 00:10:39,260
not the case with virtual machine
introspection for example and then once

156
00:10:39,260 --> 00:10:41,900
you find introspection or if you find
introspection

157
00:10:41,900 --> 00:10:45,829
maybe you'll do you change your tech
TTP's for that system you might try to

158
00:10:45,830 --> 00:10:49,490
quickly pivot somewhere else in the
network just to get off of that system

159
00:10:49,490 --> 00:10:54,590
you might like delete yourself or try to
do a lot of weird things to make the

160
00:10:54,590 --> 00:10:58,100
forensics analyst job much harder if
you're doing a lot of random stuff just

161
00:10:58,100 --> 00:11:02,180
to make them their day more complicated
and also you don't want to drop anything

162
00:11:02,180 --> 00:11:06,079
else on there because you might lose
more capabilities and so the different

163
00:11:06,080 --> 00:11:10,060
responses them that's kind of depending
on your operation you're running but

164
00:11:10,060 --> 00:11:13,239
it's really helpful to know if someone
is running or if you're running on a

165
00:11:13,240 --> 00:11:19,330
honey pot so out there in the open this
is something I've not done this is just

166
00:11:19,330 --> 00:11:21,520
a tool out there but it's kind of good
start

167
00:11:21,520 --> 00:11:25,750
paranoid fish it's a tool you can get on
github it's open source and basically it

168
00:11:25,750 --> 00:11:30,400
uses all the techniques that open
malware samples have used to try to

169
00:11:30,400 --> 00:11:33,640
figure out if there's a debugger and so
this is a really great tool if you're a

170
00:11:33,640 --> 00:11:37,990
navy vendor to figure out okay am I
going to be flagged by this or if you're

171
00:11:37,990 --> 00:11:41,860
a malware author you want to make sure
you're hitting all of these because this

172
00:11:41,860 --> 00:11:44,590
is kind of open knowledge by now

173
00:11:44,590 --> 00:11:48,250
and so this is a screenshot you'll see
it's checking I mean some of these are

174
00:11:48,250 --> 00:11:54,160
pretty comical like is debugger
president etc and if your AV is

175
00:11:54,160 --> 00:11:57,160
returning yes there's a debugger
president's probably not the greatest so

176
00:11:57,160 --> 00:12:01,510
this is a great resource but we want to
talk a little bit further down about how

177
00:12:01,510 --> 00:12:08,230
to misuse our architectural features so
cpus have worked very very hard and

178
00:12:08,230 --> 00:12:11,770
intel and AMD and all the chip
manufacturers work very hard to provide

179
00:12:11,770 --> 00:12:14,500
the disillusion of of isolation

180
00:12:14,500 --> 00:12:17,680
so back in the das days if an
application was misbehaving it could

181
00:12:17,680 --> 00:12:23,199
just overwrite the colonel and crash the
system now you have cpu assisted virtual

182
00:12:23,200 --> 00:12:26,620
memory you have that also for
hypervisors to multiplex between

183
00:12:26,620 --> 00:12:28,090
operating systems

184
00:12:28,090 --> 00:12:32,230
you have really nice multitasking so an
application doesn't necessarily even

185
00:12:32,230 --> 00:12:35,050
know when it's not being scheduled to
run

186
00:12:35,050 --> 00:12:39,400
however many of these are shared
resources and when you have a shared

187
00:12:39,400 --> 00:12:42,699
resource there is some form of side
channel there that allows you to

188
00:12:42,700 --> 00:12:46,480
determine a little bit of information
about is there something else running

189
00:12:46,480 --> 00:12:50,710
what is it doing maybe or how much is
the load is it consuming

190
00:12:50,710 --> 00:12:55,540
there are two specific talk to the
closing keynote by sophia and then

191
00:12:55,540 --> 00:13:02,230
tomorrow honors is talking on a very
specific CPU cache site channel so if

192
00:13:02,230 --> 00:13:06,790
you want the really nitty-gritty details
i'd recommend go with them go to this

193
00:13:06,790 --> 00:13:13,300
talks so again shared resources you have
the CPU cache the cpu pipeline timing

194
00:13:13,300 --> 00:13:16,240
and load information and all of these
right here are kind of hard to

195
00:13:16,240 --> 00:13:20,950
completely emulate and isolate and so
you can measure them and how they change

196
00:13:20,950 --> 00:13:22,440
you can infer other behavior

197
00:13:22,440 --> 00:13:28,140
and then you can see whether what what
other process may be doing so we work on

198
00:13:28,140 --> 00:13:33,630
a program called cash teller basically
use the shared cache in a multi core

199
00:13:33,630 --> 00:13:37,710
system to be able to figure out the
pattern of instruction actresses of

200
00:13:37,710 --> 00:13:43,170
another function running another
application we were using the same

201
00:13:43,170 --> 00:13:48,630
technique that the aes break was using a
primer and probe and then we could from

202
00:13:48,630 --> 00:13:54,390
userspace be able to trigger say vmx it
with the cpuid instruction we could

203
00:13:54,390 --> 00:13:59,760
trigger an estimate smm interrupt or
just an operating system call back and

204
00:13:59,760 --> 00:14:05,130
we could see whether or not there was a
cash impact so cpuid should typically

205
00:14:05,130 --> 00:14:09,120
not impact the cash at all unless
there's a virtual is a hypervisor

206
00:14:09,120 --> 00:14:13,320
running in which case they'll trap the
VMM the vm will impact the cactus by

207
00:14:13,320 --> 00:14:17,790
executing and then when you go back you
can kind of see that and then my

208
00:14:17,790 --> 00:14:21,000
co-worker who's was working on the
machine learning side of this was

209
00:14:21,000 --> 00:14:24,270
looking at using binary classifiers to
be able to Train

210
00:14:24,270 --> 00:14:27,750
what a normalish system looks like and
then see how easily it would be to

211
00:14:27,750 --> 00:14:32,340
detect rootkits or other kind of
suspicious behavior

212
00:14:32,340 --> 00:14:38,040
oddly enough it's very difficult to tell
between a rootkit and an antivirus

213
00:14:38,040 --> 00:14:38,910
system

214
00:14:38,910 --> 00:14:43,110
machine learning at the time was just
not quite good enough so take that for

215
00:14:43,110 --> 00:14:46,650
what you may but for us it doesn't
matter if we see something out there

216
00:14:46,650 --> 00:14:49,709
that either another root kit or
antivirus and kind of want to be

217
00:14:49,710 --> 00:14:55,890
suspicious so you have two cores one is
priming the cash and then synchronizing

218
00:14:55,890 --> 00:14:59,640
and then waiting basically for that cash
impact the other one is calling that

219
00:14:59,640 --> 00:15:01,830
test function so out

220
00:15:01,830 --> 00:15:10,140
0xp to the trigger and sm m s cpuid for
a vm call back or just calling a

221
00:15:10,140 --> 00:15:14,250
function like this directory and then it
will probe for the access pattern once

222
00:15:14,250 --> 00:15:17,670
that's been completed so this writing
this was very complicated because we

223
00:15:17,670 --> 00:15:21,810
couldn't touch the cash ourselves
otherwise we can kind of dilute or

224
00:15:21,810 --> 00:15:27,750
corrupt our output but once you've got a
working it was pretty reliable and so we

225
00:15:27,750 --> 00:15:31,260
were able to show that you can pretty
much take our system have it run and it

226
00:15:31,260 --> 00:15:34,620
will tell you if there's a rootkit
running in any level of

227
00:15:34,620 --> 00:15:39,150
or any ring on the cpu nice thing was
this runs in pure userspace you don't

228
00:15:39,150 --> 00:15:43,890
need that much privilege and it provides
fairly granular data so you can see is

229
00:15:43,890 --> 00:15:46,890
there a vm and then is that bpms
behavior changing

230
00:15:47,730 --> 00:15:51,750
we went from that and there's a paper
out there called conquer which is a way

231
00:15:51,750 --> 00:15:55,980
to basically use a whole bunch of
randomized gadgets to both checksum to

232
00:15:55,980 --> 00:15:59,880
make sure you've been loaded properly
and then also to be able to establish a

233
00:15:59,880 --> 00:16:06,990
sort of trust this is kind of a software
Intel txt and so what you need is it

234
00:16:06,990 --> 00:16:10,830
just a trusted time source and then some
random seed to prevent replay attacks

235
00:16:10,830 --> 00:16:15,720
and then you can see whether or not that
the challenge has been reverse engineer

236
00:16:15,720 --> 00:16:20,640
emulated or otherwise interfere with so
some of these gadgets will talk about

237
00:16:20,640 --> 00:16:25,380
briefly so you want to make sure you
have a cpuid gadget to make sure you

238
00:16:25,380 --> 00:16:28,620
trigger a BMX it if you do this
thousands of times you know you're the

239
00:16:28,620 --> 00:16:32,190
time sku will actually show that there's
probably a hypervisor their

240
00:16:32,190 --> 00:16:36,480
self-modifying code to detect a split
tlb which we'll talk about a little bit

241
00:16:36,480 --> 00:16:37,140
later

242
00:16:37,140 --> 00:16:40,470
and also you want to make sure you hook
the either the ivt the interrupt vector

243
00:16:40,470 --> 00:16:44,010
table or interrupt descriptor table to
make sure you're not running in virtual

244
00:16:44,010 --> 00:16:49,110
8086 mode on top of that you could also
basically put this whole multi-core cash

245
00:16:49,110 --> 00:16:54,480
analysis inside of that to make sure
it's been loaded properly so you can use

246
00:16:54,480 --> 00:16:58,920
this and we have a use this to basically
detect if there's a kind of manual

247
00:16:58,920 --> 00:17:02,579
analysis someone trying to reverse
engineer that challenge binary we can

248
00:17:02,580 --> 00:17:07,290
detect a virtual machine presence or SMI
in different than we expect

249
00:17:07,290 --> 00:17:11,159
I'm sorry had to write assistant manager
mode rootkit and then I had to either

250
00:17:11,160 --> 00:17:14,400
install it or not install it and then my
co-worker had to see if he could find it

251
00:17:14,400 --> 00:17:15,030
or not

252
00:17:15,030 --> 00:17:19,020
so you can either use local hardware
that's trusted or you can do it over the

253
00:17:19,020 --> 00:17:21,900
network to provide the timing
information obviously over the network

254
00:17:21,900 --> 00:17:25,350
you're going to have a little bit of
kind of skew in there with latency

255
00:17:25,349 --> 00:17:29,340
but it's a little bit easier than
carrying around trusted hardware and

256
00:17:29,340 --> 00:17:32,760
then you can use that resulting checksum
to drive in front from the puffs will

257
00:17:32,760 --> 00:17:33,690
talk about later

258
00:17:33,690 --> 00:17:37,800
our extended other things so we kind of
put this all on the thing called secure

259
00:17:37,800 --> 00:17:38,580
node

260
00:17:38,580 --> 00:17:41,919
basically we took Conqueror and we put
into our boot loader

261
00:17:41,920 --> 00:17:47,590
and our bootloader replaced all the bios
functionality so it didn't recall didn't

262
00:17:47,590 --> 00:17:51,699
rely on the tour of the bios at all
other than to load itself and so we

263
00:17:51,700 --> 00:17:54,160
wanted to do is you want to make sure
that we were loaded properly and not

264
00:17:54,160 --> 00:17:57,610
being hooked or corrupted by that
possibly malicious bioscrip reboot

265
00:17:57,610 --> 00:18:02,560
environment we wrote it for fpga that
you can put in the pci slot that was

266
00:18:02,560 --> 00:18:08,080
able to detect an act as the remote
server for the trusted time device USB

267
00:18:08,080 --> 00:18:11,919
device with a microcontroller and kinda
like an arduino or a teensy or remote

268
00:18:11,920 --> 00:18:16,540
server and then there's a virtual TPM on
this device that would unlock or enable

269
00:18:16,540 --> 00:18:19,990
that allow you to kind of prove that you
are in the rainbow chance is provided

270
00:18:19,990 --> 00:18:25,570
software dynamic root of trust so have
an overview here so the bootloader when

271
00:18:25,570 --> 00:18:30,760
its first load is untrusted because it's
it could very well have been patched

272
00:18:30,760 --> 00:18:37,780
when it was being loaded it will request
a challenge which is basically a lot of

273
00:18:37,780 --> 00:18:43,510
these gallant challenges and gadgets
linked together a random order with some

274
00:18:43,510 --> 00:18:44,800
seeds and whatnot

275
00:18:44,800 --> 00:18:47,980
there are different every time to run
the replay attack it starts the timer

276
00:18:47,980 --> 00:18:51,730
see the challenges received it runs it
in this environment so this could be

277
00:18:51,730 --> 00:18:56,260
doing cash analysis that can be doing
calling I BTW entries quite a bit or

278
00:18:56,260 --> 00:19:00,220
setting and i'm setting different ivt
entries and then once the checksum is

279
00:19:00,220 --> 00:19:04,240
done or the gadgets are done then it
will stop the timer and and have the

280
00:19:04,240 --> 00:19:06,880
hardware the trusted source verify that

281
00:19:06,880 --> 00:19:10,360
and then also within those two gadgets
its self measuring as well to make sure

282
00:19:10,360 --> 00:19:13,750
both the challenge has been loaded
properly and boot loader and so if

283
00:19:13,750 --> 00:19:17,980
everything is ok now we have a trusted
bootlegger that we can go in and be able

284
00:19:17,980 --> 00:19:24,100
to do this so i do have a demo of it but
because this was defensive software the

285
00:19:24,100 --> 00:19:28,149
goal with defensive software is to not
you interact with the user experience at

286
00:19:28,150 --> 00:19:34,690
all so it's basically just a computer
booting but i'll walk you through this

287
00:19:34,690 --> 00:19:36,490
kind of slowly as we

288
00:19:36,490 --> 00:19:39,490
oh that's not right

289
00:19:40,100 --> 00:19:47,840
alright so so what we've done in this
environment is we basically put our boot

290
00:19:47,840 --> 00:19:52,280
loader on USB device and then we told it
to load the host operating system this

291
00:19:52,280 --> 00:19:55,940
case windows and so what we've done is
we've started off as a boot loader and

292
00:19:55,940 --> 00:19:58,010
then we replaced all of ET handlers

293
00:19:58,010 --> 00:20:01,730
so what the operating system would
typically call back into to ask for say

294
00:20:01,730 --> 00:20:06,799
hey load this file or print to disk is
now calling our code and now that is

295
00:20:06,799 --> 00:20:07,668
doing that

296
00:20:07,669 --> 00:20:12,080
it's finding the devices okay it's
starting up other processors to make

297
00:20:12,080 --> 00:20:15,020
sure that they haven't been changed like
they're I VT is not pointing somewhere

298
00:20:15,020 --> 00:20:18,559
else so it starts up all the other cpus
and put them into a kind of a deadlock

299
00:20:18,559 --> 00:20:23,030
and then it's basically doing that
challenge really quickly

300
00:20:23,030 --> 00:20:28,520
sending it back and then it's going to
boot the operating system successfully

301
00:20:28,520 --> 00:20:32,240
but what would happen if you failed is
the TPM utilities we built which are

302
00:20:32,240 --> 00:20:36,620
basically software TPM would fail to be
able to unseal your VPN or attestation

303
00:20:36,620 --> 00:20:41,059
keys and so that was just a quick demo
of using secure note for a particular

304
00:20:41,059 --> 00:20:42,049
purpose

305
00:20:42,049 --> 00:20:50,389
alright so there are some caveats
obviously that was pretty noticeable

306
00:20:50,390 --> 00:20:53,960
whenever you turn your computer on you
have to like do something we were able

307
00:20:53,960 --> 00:20:55,370
to run this institute

308
00:20:55,370 --> 00:21:00,020
so we could have dropped it on a window
system freeze the colonel run all of our

309
00:21:00,020 --> 00:21:03,679
stuff and we have built our own USB
stack so we can talk directly to the USB

310
00:21:03,679 --> 00:21:09,530
device or to the server and then be able
to go back from there but that there are

311
00:21:09,530 --> 00:21:14,149
some challenges with this in an
offensive concept because you know you a

312
00:21:14,150 --> 00:21:17,390
lot of the normal trusted computing
requires physical presence like

313
00:21:17,390 --> 00:21:22,370
provisioning a TPM or setting in a key
and EFI you don't have that ability

314
00:21:22,370 --> 00:21:26,299
that's what we're gonna talk about
office a little bit and also if you

315
00:21:26,299 --> 00:21:30,139
alert the user it'sit's you draw
attention to yourself if you have it in

316
00:21:30,140 --> 00:21:31,549
a defensive concept

317
00:21:31,549 --> 00:21:36,679
you can kind of the IT guys all that's
fine just ignore that error and also the

318
00:21:36,679 --> 00:21:41,840
basic vm detection is not really enough
anymore because windows

319
00:21:42,500 --> 00:21:47,030
linux basically all kind of come with vm
hypervisors kind of running by default

320
00:21:47,030 --> 00:21:52,790
Windows 10 and credential guard kvm and
then also all the cloud instances if

321
00:21:52,790 --> 00:21:57,830
there is a vm their hypervisor that's
not really a no go anymore otherwise if

322
00:21:57,830 --> 00:22:00,949
you're malware and you just saw a vm and
you did nothing you wouldn't be able to

323
00:22:00,950 --> 00:22:06,590
run any Windows 10 box so that that's
pretty challenging and so the nice thing

324
00:22:06,590 --> 00:22:09,379
about this is that we can measure the
cash impact while doing different things

325
00:22:09,380 --> 00:22:11,930
like reading certain regions of memory

326
00:22:11,930 --> 00:22:16,700
so if we were to from the past talk they
were basically trapping on certain page

327
00:22:16,700 --> 00:22:22,010
eight pages they were being accessed by
crypto we could access those pages and

328
00:22:22,010 --> 00:22:25,280
see if there was cash and back from a
hypervisor trapping on those EPT

329
00:22:25,280 --> 00:22:29,330
instances or apt violations and then we
would know that there was a hypervisor

330
00:22:29,330 --> 00:22:32,960
specifically looking at the pages that
have sensitive information and then we

331
00:22:32,960 --> 00:22:34,400
can change our procedures

332
00:22:34,400 --> 00:22:37,310
so this is a way that you can make it
more granular and get more information

333
00:22:37,310 --> 00:22:38,300
out of it

334
00:22:38,300 --> 00:22:48,620
all right onto us so physically in
clinical functions in a nutshell they

335
00:22:48,620 --> 00:22:53,389
take manufacturing variance and expose
it when typically manufacturers want to

336
00:22:53,390 --> 00:22:54,710
hide that information

337
00:22:54,710 --> 00:22:58,340
so what is manufacturing variants
basically as computers have gotten

338
00:22:58,340 --> 00:22:59,899
smaller and smaller and smaller

339
00:22:59,900 --> 00:23:04,550
it's impossible to build them exactly
the same you can't have two chips of ram

340
00:23:04,550 --> 00:23:07,940
there are exactly identical they might
be like a few atoms one way or another

341
00:23:07,940 --> 00:23:12,680
and so there are always tolerances in
the data sheet like you will do this for

342
00:23:12,680 --> 00:23:17,300
this much wattage or what not even if a
particular chip might not need quite as

343
00:23:17,300 --> 00:23:18,169
much power

344
00:23:18,170 --> 00:23:21,860
another one might need to know a little
bit less or whatnot and so they have a

345
00:23:21,860 --> 00:23:25,699
lot of things that are tolerance and so
puffs are ways that you can use software

346
00:23:25,700 --> 00:23:29,300
to it specifically expose those
differences and get a different result

347
00:23:29,300 --> 00:23:31,970
on every device

348
00:23:31,970 --> 00:23:36,380
so basically you give it a challenge and
you get a device specific unique or

349
00:23:36,380 --> 00:23:39,260
device specific or unique response

350
00:23:39,260 --> 00:23:43,850
the goal would be is for these responses
to be very static between running this

351
00:23:43,850 --> 00:23:46,639
with the same challenge you want to get
the similar response to the same

352
00:23:46,640 --> 00:23:51,260
response but then if you run the same
challenge in the same algorithm in a

353
00:23:51,260 --> 00:23:53,190
different box and this is not just like

354
00:23:53,190 --> 00:23:57,780
a Mac versus a pc this is two of the
exact same dells that rolled off the

355
00:23:57,780 --> 00:24:00,210
assembly line right next to each other

356
00:24:00,210 --> 00:24:03,570
you want to get very different results
so you can tell whether or not you've

357
00:24:03,570 --> 00:24:06,030
been moved or offloaded or whatnot

358
00:24:06,030 --> 00:24:13,980
I will caveat that puffs physically on
clinical functions can be cloned so

359
00:24:13,980 --> 00:24:18,810
before a smartass says oh they're
chemical in there is a paper about using

360
00:24:18,810 --> 00:24:23,610
a fit of focused ion beam that they can
actually go through and rear out chips

361
00:24:23,610 --> 00:24:25,830
to make them more similar to other ones

362
00:24:25,830 --> 00:24:29,909
so if that is in your threat model
someone who has a very expensive fit and

363
00:24:29,910 --> 00:24:32,340
lots of time and physical access

364
00:24:32,340 --> 00:24:36,179
you know maybe this is probably not the
technique for you but at that point they

365
00:24:36,180 --> 00:24:44,190
would just hire an assassin probably all
right so why we want puffs generating

366
00:24:44,190 --> 00:24:48,120
device specific data is great we can use
that as a device specific key so we can

367
00:24:48,120 --> 00:24:49,260
basically proved

368
00:24:49,260 --> 00:24:53,430
yes we're running in a trust estate and
we're on this hardware and as soon as we

369
00:24:53,430 --> 00:24:56,730
get offloaded to spur ski and they're
trying to figure out this piece of

370
00:24:56,730 --> 00:25:00,960
malware does when they run it and they
run that same function on their system

371
00:25:00,960 --> 00:25:03,570
they're going to get a completely
different response and maybe you won't

372
00:25:03,570 --> 00:25:08,550
be able to decrypt your actual
capability so puffs because they're very

373
00:25:08,550 --> 00:25:13,440
very tied to hardware they specifically
require techniques tuned for each piece

374
00:25:13,440 --> 00:25:17,460
of hardware for each class of hardware
new techniques are under active

375
00:25:17,460 --> 00:25:18,360
development

376
00:25:18,360 --> 00:25:23,040
I have two of them that are new today
and i'll be talking later about an open

377
00:25:23,040 --> 00:25:26,159
source library we're gonna be releasing
to make it easier for other people to

378
00:25:26,160 --> 00:25:30,840
add new ones and collaborate on that
another caveat with puffs is they are

379
00:25:30,840 --> 00:25:35,490
temperature and hardware age-dependent
you know if you're turning your computer

380
00:25:35,490 --> 00:25:37,710
on in the morning and it's a little bit
cold

381
00:25:37,710 --> 00:25:40,410
you might get a slightly different
answer because some things will expand

382
00:25:40,410 --> 00:25:43,410
or contract when they get warm vs you
run the same thing in the afternoon

383
00:25:44,220 --> 00:25:48,300
so that's a challenge to get to overcome
so little bit more background on some

384
00:25:48,300 --> 00:25:54,180
crypto stuff from your secret sharing SS
basically you can take a sensitive piece

385
00:25:54,180 --> 00:25:59,040
of information so crypto key and you can
split it in two end pieces which require

386
00:25:59,040 --> 00:26:02,280
a quorum of n to recover the secret

387
00:26:02,280 --> 00:26:05,129
and what's really nice about this you
can think of it like really simple

388
00:26:05,130 --> 00:26:08,490
say my password is password and I give
one friend

389
00:26:08,490 --> 00:26:11,850
the word word and I give the other
friend the word pass only if they

390
00:26:11,850 --> 00:26:14,189
combine them together and they get my
password

391
00:26:14,190 --> 00:26:18,480
the problem is that i just reduced each
one of their search space is quite

392
00:26:18,480 --> 00:26:22,590
drastically and so the nice thing about
your secret sharing is it doesn't do

393
00:26:22,590 --> 00:26:25,709
that even if you have M minus 1 pieces

394
00:26:25,710 --> 00:26:31,170
you still have the same size search
basis if you had one or zero pieces if

395
00:26:31,170 --> 00:26:35,910
you're interested in the great wikipedia
article but it uses points on a high

396
00:26:35,910 --> 00:26:37,200
dimensional function

397
00:26:37,200 --> 00:26:42,510
alright so error-correcting codes really
briefly there's a lot of different types

398
00:26:42,510 --> 00:26:45,270
of them but they were originally kind of
developed for transmission on noisy

399
00:26:45,270 --> 00:26:46,110
channels

400
00:26:46,110 --> 00:26:49,500
you're going to increase data size to be
able to add either detection or

401
00:26:49,500 --> 00:26:53,970
correction capabilities and then also
the depending on how much extra data you

402
00:26:53,970 --> 00:26:54,900
put on there

403
00:26:54,900 --> 00:26:59,400
you'll get additional input and so the
the real math and this is how you can

404
00:26:59,400 --> 00:27:03,150
add as little amount of information or
data that maximize the amount of

405
00:27:03,150 --> 00:27:07,260
information so that will kind of jump
into one example of a puff

406
00:27:07,260 --> 00:27:13,200
so this is a scanning electron
microscope of AD capped SRAM chip and so

407
00:27:13,200 --> 00:27:17,460
there's a lot of cells there which
represent kind of a bit on this ram bank

408
00:27:17,460 --> 00:27:20,400
so you'll see SRAM RI ram

409
00:27:20,400 --> 00:27:25,260
they're either on register banks or cash
or they also sometimes embedded devices

410
00:27:25,260 --> 00:27:28,830
a lot of arm devices come with Iran
themselves which are used by sometimes

411
00:27:28,830 --> 00:27:32,010
graphics cards they're much faster than
in dram

412
00:27:32,010 --> 00:27:35,970
I'm so if you look really closely it's
kinda hard to tell they are actually

413
00:27:35,970 --> 00:27:39,930
like a slightly different shape and
they're all shaped the same but if you

414
00:27:39,930 --> 00:27:43,050
were to like draw lines or zoom in
really closely you see that would be a

415
00:27:43,050 --> 00:27:48,270
couple pictures off and that's basically
will actually is how we're going to

416
00:27:48,270 --> 00:27:52,050
develop this puff and so because of that
and sometimes the size or bigger or

417
00:27:52,050 --> 00:27:56,190
smaller than their first powered on
before they're written to each cell

418
00:27:56,190 --> 00:28:00,330
tends to either be a 0 or a 1 and if you
turn it off and then turn it back on

419
00:28:00,330 --> 00:28:00,810
again

420
00:28:00,810 --> 00:28:06,750
each cell again 10 to the same variable
to the same same value and so because of

421
00:28:06,750 --> 00:28:10,140
that with SRAM it's really easy to the
easiest one to explain basically you

422
00:28:10,140 --> 00:28:15,210
just turn on the SRAM or added on to
turn on the power and then you can read

423
00:28:15,210 --> 00:28:17,360
out a certain address and said the
challenge

424
00:28:17,360 --> 00:28:21,379
is basically the address and how much
you want to read out and then the

425
00:28:21,380 --> 00:28:26,330
responses those bit values and so since
HS ram chip has slightly different

426
00:28:26,330 --> 00:28:29,780
manufacturing you know giving the same
challenge we're proud of different

427
00:28:29,780 --> 00:28:35,899
output on different s RAM chips so

428
00:28:35,900 --> 00:28:42,290
oh yeah okay so I talked about this
already basically you want to combine

429
00:28:42,290 --> 00:28:46,490
this with some other techniques and so I
already gave you the background on it

430
00:28:46,490 --> 00:28:49,820
we're going is error correcting code and
shamir secret sharing to be able to

431
00:28:49,820 --> 00:28:53,600
improve the reliability and so what we
do is we provision each puff

432
00:28:53,600 --> 00:28:58,399
by measuring that device in different
environments to see how likely it is to

433
00:28:58,400 --> 00:29:02,780
change how many bits change over time or
in different temperatures and then we

434
00:29:02,780 --> 00:29:07,309
can kind of get an expected failure rate
or probability of matching for each kind

435
00:29:07,309 --> 00:29:08,450
of device class

436
00:29:08,450 --> 00:29:12,169
we then use error correcting code to
correct the small errors so we can add

437
00:29:12,169 --> 00:29:15,830
in more or less extra data to make sure
that we can match with that provisioned

438
00:29:15,830 --> 00:29:19,760
information and then we can use from
your secret sharing to go without an

439
00:29:19,760 --> 00:29:24,080
extra error handling by setting the mfn
ratio but also you can combine multiple

440
00:29:24,080 --> 00:29:27,320
pops with different challenges or even
different device hardware so you could

441
00:29:27,320 --> 00:29:31,668
tie it so two pieces of SRAM have to be
exactly the same if someone even

442
00:29:31,669 --> 00:29:34,309
switches at a different one with maybe
one that they've done some hardware

443
00:29:34,309 --> 00:29:40,340
attack on you won't be able to be able
to get the same result so that's kind of

444
00:29:40,340 --> 00:29:45,139
the crypto right there to make a little
bit more reliable so sources much more

445
00:29:45,140 --> 00:29:48,919
interesting to figure out depending on
your environment

446
00:29:48,919 --> 00:29:52,460
what you have so s remember we talked
about those are common on embedded

447
00:29:52,460 --> 00:30:00,020
devices all cpus typically use SRAM for
cash and for register banks the

448
00:30:00,020 --> 00:30:02,690
challenges is typically you're not
running early enough in the boot process

449
00:30:02,690 --> 00:30:07,490
to be able to use them is the bios or
the end of the bootrom has already gone

450
00:30:07,490 --> 00:30:12,770
in and change those values fpgas or
think the original source of puffs and

451
00:30:12,770 --> 00:30:19,160
they're also very uh , again on embedded
devices or custom hardware and then many

452
00:30:19,160 --> 00:30:24,740
of the atom processors that Intel is
making for netbooks had an fpga also on

453
00:30:24,740 --> 00:30:26,919
die as well so you could use that

454
00:30:26,919 --> 00:30:29,919
nand flash you find in a lot of places

455
00:30:30,820 --> 00:30:35,080
eeprom and then ram sticks which is the
one that's the most experimental talk

456
00:30:35,080 --> 00:30:35,859
about

457
00:30:35,859 --> 00:30:39,249
so if you combine all these you can
create a really specific device

458
00:30:39,249 --> 00:30:43,119
fingerprint use that as your root of
trust kind of key and that means if

459
00:30:43,119 --> 00:30:46,809
someone finds a very suspicious binary
on their system and they ship it off to

460
00:30:46,809 --> 00:30:49,210
kaspersky or semantic to look at

461
00:30:49,210 --> 00:30:54,039
you've environmentally keep that device
that's the kind of the formal name to a

462
00:30:54,039 --> 00:30:57,190
very specific piece of hardware and then
you have to ship the whole box to them

463
00:30:57,190 --> 00:31:00,340
if they want to do any analysis and get
the same results

464
00:31:00,340 --> 00:31:07,449
sorry so fpga is the way that they
typically do puffs you create two

465
00:31:07,450 --> 00:31:10,480
oscillators that you oscillate exact
same frequency

466
00:31:10,480 --> 00:31:14,200
but since there are slight differences
in how far the different gates are away

467
00:31:15,039 --> 00:31:20,350
sometimes one oscillator will be the
other one will come around and also a

468
00:31:20,350 --> 00:31:24,309
little bit faster so you can kind of
move them around physically on where you

469
00:31:24,309 --> 00:31:28,178
put them in the gate fabric and then be
able to kind of race them and then the

470
00:31:28,179 --> 00:31:34,059
output bit stream is going to be a
pretty unique stream to that region and

471
00:31:34,059 --> 00:31:40,749
kind of those two combinations of
regions for flash you when you program

472
00:31:40,749 --> 00:31:45,879
flashy basically apply current to a cell
or block for a specified time and so

473
00:31:45,879 --> 00:31:49,629
this festival specified time is the
tolerance basically and you'll see that

474
00:31:49,629 --> 00:31:51,009
in your data sheet

475
00:31:51,009 --> 00:31:54,009
however since each cell might be
slightly larger or smaller

476
00:31:54,519 --> 00:31:58,989
it might take a little bit less power to
actually hit that inflection point and

477
00:31:58,989 --> 00:32:02,619
change it so you do is you kind of start
writing a cell and then you cancel it

478
00:32:02,619 --> 00:32:07,149
before you hittin that maximum amount of
time or current and then you see if it's

479
00:32:07,149 --> 00:32:10,268
changed you do a little bit more and see
if it's changed a little bit more and

480
00:32:10,269 --> 00:32:13,570
then you can kind of figure out okay
this one took no three iterations to

481
00:32:13,570 --> 00:32:17,320
stick this one took one iteration to
stick this one took five and so you can

482
00:32:17,320 --> 00:32:22,658
kind of go through each cell and be able
to develop a very specific response

483
00:32:24,960 --> 00:32:29,880
he problems very similar basically you
program by applying current for some

484
00:32:29,880 --> 00:32:32,730
specified amount of time usually like
eight milliseconds or whatnot

485
00:32:32,730 --> 00:32:37,620
if you write and then kind of cancel the
right to early you will start to have

486
00:32:37,620 --> 00:32:43,379
errors those bits that have failed or
because they have you again smaller

487
00:32:43,380 --> 00:32:45,510
slightly different

488
00:32:45,510 --> 00:32:49,830
the nice thing with e problem is is that
every ram stick has eeprom on it

489
00:32:49,830 --> 00:32:54,120
it's exposed over this sm bus which you
can access the software so if your

490
00:32:54,120 --> 00:32:55,709
target has ram

491
00:32:55,710 --> 00:33:01,529
it's on like a normal dim you have this
available you have this available to you

492
00:33:01,529 --> 00:33:05,370
usually it's used to store timing
information so Ram overclocking software

493
00:33:05,370 --> 00:33:10,199
will go in and change these values but
we have access it now so the last one

494
00:33:10,200 --> 00:33:14,159
I'm a caveat to this is one is very new
and we're still trying to figure out how

495
00:33:14,159 --> 00:33:17,279
good it is or if it's even reliable
enough just to even go down that route

496
00:33:17,279 --> 00:33:19,409
using row hammer

497
00:33:19,409 --> 00:33:23,429
so real quick i'm guessing you guys
don't know a row hammer is but you read

498
00:33:23,429 --> 00:33:27,240
from a certain row in a dram and you
actually build up basically static

499
00:33:27,240 --> 00:33:32,850
electricity that might kind of spark out
and hit a nearby row which causes a bit

500
00:33:32,850 --> 00:33:33,360
flip

501
00:33:33,360 --> 00:33:37,678
so this was like the biggest also must
exploit ever last year they were able to

502
00:33:37,679 --> 00:33:42,120
do that and get exploit the remote code
execution by flipping bits and the was

503
00:33:42,120 --> 00:33:44,070
amazing go read if you don't know what
it is

504
00:33:44,070 --> 00:33:49,408
the hypothesis we working under and and
talking to some of our developers said

505
00:33:49,409 --> 00:33:52,409
that this seems like it might make sense

506
00:33:52,409 --> 00:33:56,669
basically that the bits that are
flipping on each row are minutely closer

507
00:33:56,669 --> 00:33:57,600
or more

508
00:33:57,600 --> 00:34:00,809
I have a little bit more connectivity
between them and so you'll divide

509
00:34:00,809 --> 00:34:05,879
basically device and no specific pattern
to flipping and so you know hammer the

510
00:34:05,880 --> 00:34:09,060
same kind of regions America allocate
some memory and known physical address

511
00:34:09,060 --> 00:34:12,330
you row hammer them once and whichever
bits flip

512
00:34:12,330 --> 00:34:14,909
that's kind of your puff source and then
you come back later you do the same

513
00:34:14,909 --> 00:34:19,440
thing again and now you have you no
assurances that you're on the same exact

514
00:34:19,440 --> 00:34:24,839
names i mentioned before we're writing
this all up clothes cleaning up the code

515
00:34:24,839 --> 00:34:28,440
and getting the last signatures from the
corporate overlords to build release

516
00:34:28,440 --> 00:34:28,830
this

517
00:34:28,830 --> 00:34:32,668
so hopefully soon it'll be up there on
get help for anyone but if people are

518
00:34:32,668 --> 00:34:34,138
really interested in this

519
00:34:34,139 --> 00:34:36,560
if you hit me up on Twitter whatever i
can probably get you

520
00:34:36,560 --> 00:34:41,029
some stuff earlier but basically we're
trying to make it super easy for other

521
00:34:41,030 --> 00:34:44,780
people to come up with new puff sources
and then basically just drop it on any

522
00:34:44,780 --> 00:34:48,590
system it will characterize what
hardware is available to it and then be

523
00:34:48,590 --> 00:34:55,520
able to kind of you know provide puff
access now we have a key

524
00:34:56,060 --> 00:34:59,060
now we're on to how to use it

525
00:35:02,910 --> 00:35:08,160
so you can use it for a root russki so
typical earth at TPM remote station as

526
00:35:08,160 --> 00:35:11,460
the attestation identity key you can use
it for data at rest

527
00:35:12,000 --> 00:35:17,970
so if you're trying to seal data to a
specific key or just specific device or

528
00:35:17,970 --> 00:35:21,480
even you can add in by extending it and
software you could also tie it to a

529
00:35:21,480 --> 00:35:26,010
certain operating system version or
system configuration or you can also use

530
00:35:26,010 --> 00:35:30,990
it as you know in data in transit
protection so you could you know add in

531
00:35:30,990 --> 00:35:35,160
a pki on top of that and then you could
have if you have multiple implants on a

532
00:35:35,160 --> 00:35:38,759
network you can make sure that you're
coming from a certain device and other

533
00:35:38,760 --> 00:35:42,000
devices will only trust the implants
that their talk should be talking to

534
00:35:42,000 --> 00:35:46,559
some kind of bootstrap this to a botnet
that is not going to get taken over very

535
00:35:46,559 --> 00:35:52,440
easily because the pki is not there and
so basically we're using pki which is a

536
00:35:52,440 --> 00:35:56,880
real headache to set up for offenders to
be able to use that same technique to

537
00:35:56,880 --> 00:36:03,180
make sure that no one is trying to do it
and takeover of our of our botnet and so

538
00:36:03,180 --> 00:36:08,220
the last step of the Triforce zelda
theme encrypted execution

539
00:36:08,220 --> 00:36:12,419
so this kind of started off as an
academic research looking at how you

540
00:36:12,420 --> 00:36:15,720
might be able to change the instruction
set and so there are a lot of papers out

541
00:36:15,720 --> 00:36:21,118
there using fpga to simulate certain
cpus or modifications to the open spark

542
00:36:21,119 --> 00:36:23,460
cpu architecture

543
00:36:23,460 --> 00:36:27,539
it's becoming very popular now so in
tell when they're skylake processors

544
00:36:27,539 --> 00:36:34,740
came out with the sgx secure guard
extensions which basically provides on

545
00:36:34,740 --> 00:36:39,149
cpu encryption and decryption so anytime
you're running anything outside of cash

546
00:36:39,150 --> 00:36:43,200
it gets encrypted as it goes to memory
which is pretty cool stuff against only

547
00:36:43,200 --> 00:36:47,250
in the latest skylake processors and it
seems like they forgot to implement a

548
00:36:47,250 --> 00:36:51,210
very important register so it's not a
full implementation but it's pretty

549
00:36:51,210 --> 00:36:52,020
exciting

550
00:36:52,020 --> 00:36:55,230
and then last year's topic was hairs
which is basically way to do the same

551
00:36:55,230 --> 00:37:01,020
thing but not with sgx so how do we do
that real quick background so i

552
00:37:01,020 --> 00:37:06,480
mentioned split tlb earlier tlb is a
cash that basically stores translation

553
00:37:06,480 --> 00:37:10,170
between virtual addresses and physical
addresses if you look at how the paging

554
00:37:10,170 --> 00:37:14,550
hierarchy looks there's a lot of lookups
and accessing memory and a system is

555
00:37:14,550 --> 00:37:18,720
paratively very very slow so that's
already in the CPU cache it's much much

556
00:37:18,720 --> 00:37:21,839
faster and so this is like a cash for
those translations

557
00:37:22,470 --> 00:37:26,609
physically they are separate entities
they figured all it'll be over the

558
00:37:26,610 --> 00:37:31,290
lifetime of the cpu slightly faster to
put the data tlb a little bit closer the

559
00:37:31,290 --> 00:37:34,800
data fetch logic and the instruction lot
of TLC a little bit closer to the

560
00:37:34,800 --> 00:37:37,830
instruction to lb and so this is a
picture from the Intel software

561
00:37:37,830 --> 00:37:42,509
developer manuals showing that there are
separate instruction and data tlb and so

562
00:37:42,510 --> 00:37:46,470
what you'll see is with teal be
splitting which first came out in packs

563
00:37:46,470 --> 00:37:50,609
of your security and then soft shadow
Walker and whatnot is basically during

564
00:37:50,610 --> 00:37:52,800
normal operation these TL bees are in
sync

565
00:37:52,800 --> 00:37:56,700
basically if you were to you know read
out code at a certain address

566
00:37:56,700 --> 00:37:59,819
disassemble it and then you see what it
does and actually jump to that same

567
00:37:59,820 --> 00:38:00,720
memory address

568
00:38:00,720 --> 00:38:04,439
you're going to actually execute the
code is red with the split tlb you're

569
00:38:04,440 --> 00:38:07,380
actually moving from a parent of
enjoyment architecture to Harvard

570
00:38:07,380 --> 00:38:12,480
architecture and now you are basically
breaking that assumption

571
00:38:12,480 --> 00:38:15,780
so if you have something like patch
guard it's making sure the Colonel's ok

572
00:38:15,780 --> 00:38:19,590
you actually then schedule that task
that you just said is fine from match

573
00:38:19,590 --> 00:38:23,310
guard your order to be running something
else at a different address and so this

574
00:38:23,310 --> 00:38:31,470
is the shadow Walker rootkit another AAS
extension after the AAS caching attack

575
00:38:32,130 --> 00:38:35,520
Intel came out with these asni
instructions which are basically

576
00:38:35,520 --> 00:38:39,870
hardware logic to AAS much faster than
more protected to support hundred

577
00:38:39,870 --> 00:38:43,230
twenty-eight to music that a yes they're
very common like you can find a lot of

578
00:38:43,230 --> 00:38:46,680
things they provide these primitives but
they still require a lot of engineering

579
00:38:46,680 --> 00:38:51,540
one cool research project was called
tracer which store the aes encryption

580
00:38:51,540 --> 00:38:56,910
keys in the debug registers on the cpu
so if you came up with a can of canned

581
00:38:56,910 --> 00:39:00,839
air and froze the ram and pull them off
and put them on another system ram will

582
00:39:00,840 --> 00:39:05,400
hold its values for a few minutes old
ram attack treasure would prevent those

583
00:39:05,400 --> 00:39:08,730
encryption keys from being discovered
and that was a pretty cool work and so

584
00:39:08,730 --> 00:39:13,020
actually built on top of that where i
hoisted that up and i created a

585
00:39:13,020 --> 00:39:17,430
hypervisor that does split tlb where the
AAS key is stored and protected debug

586
00:39:17,430 --> 00:39:21,690
registers and I transparently segregate
out code and data fetches different

587
00:39:21,690 --> 00:39:22,620
regions of memory

588
00:39:22,620 --> 00:39:25,759
so all data fetches including from the
application is

589
00:39:25,760 --> 00:39:31,160
self or from an operating system are
routed to the encrypted pages

590
00:39:31,160 --> 00:39:34,430
so if you were to open up program while
it's running attached to it the debugger

591
00:39:34,430 --> 00:39:36,109
and single step through it

592
00:39:36,110 --> 00:39:40,550
i have a video if you want to see you
later of IDA freaking out it says you're

593
00:39:40,550 --> 00:39:42,170
jumping to the middle of instruction

594
00:39:42,170 --> 00:39:46,100
you're executing data because it is to
seeing a s code and it thinks you're

595
00:39:46,100 --> 00:39:50,150
just jumping through a s encrypted data
actually when we first did it we found a

596
00:39:50,150 --> 00:39:55,430
bug and the error message it was trying
to read out of memory wasn't still

597
00:39:55,430 --> 00:39:59,779
encrypted and it didn't have a null
terminator into the program while it was

598
00:39:59,780 --> 00:40:03,740
airing buffer overflow itself and it
just popped up like a really long

599
00:40:03,740 --> 00:40:08,990
garbled string and then crash so it's
it's pretty good preventing some memory

600
00:40:08,990 --> 00:40:09,560
leaks

601
00:40:09,560 --> 00:40:13,100
that being said if the cpu and this is
hard when forced is fetching an

602
00:40:13,100 --> 00:40:14,060
instruction

603
00:40:14,060 --> 00:40:18,380
it'll get routed transparently to the
decrypted execute only memory regions

604
00:40:18,380 --> 00:40:23,240
and so the program will run basically as
normal and because we're using the TLB

605
00:40:23,240 --> 00:40:26,540
it's actually pretty fast over seeing
around two percent performance hit

606
00:40:34,660 --> 00:40:35,368
ok

607
00:40:35,369 --> 00:40:38,249
so with these capabilities you can make
it way harder for someone to reverse

608
00:40:38,249 --> 00:40:42,299
engineer if you you know have a
device-specific encryption key that is

609
00:40:42,299 --> 00:40:46,499
basically environmental keying - that's
very specific device and you make it

610
00:40:46,499 --> 00:40:50,038
hard to reverse engineer on that
platform requiring it to be offloaded

611
00:40:50,039 --> 00:40:51,359
for analysis

612
00:40:51,359 --> 00:40:54,359
you're going to make it much more
difficult for introspection

613
00:40:54,359 --> 00:40:58,348
you can use this to prevent detection of
which puffs challenges are used so if

614
00:40:58,349 --> 00:40:59,309
say you

615
00:40:59,309 --> 00:41:04,859
you know if you were had that device and
you knew exactly what regions of say

616
00:41:04,859 --> 00:41:10,019
SRAM you were looking at you could turn
it on and grab those SRAM values at a

617
00:41:10,019 --> 00:41:13,410
certain address and then you be able to
slowly recover that key

618
00:41:13,410 --> 00:41:16,799
so if you kind of doing a staged
approach you might be able to kind of

619
00:41:16,799 --> 00:41:21,960
protect that with those challenges are a
little bit better and make it much more

620
00:41:21,960 --> 00:41:26,730
difficult to to be able to recover those
puffs challenges and then you can

621
00:41:26,730 --> 00:41:30,359
basically create a software TPM you can
have all that kind of attached to

622
00:41:30,359 --> 00:41:34,319
station key stored in the puffs and then
you have kind of an opaque palladium

623
00:41:34,319 --> 00:41:39,029
style execution environment and now you
have basically a software TPM and you

624
00:41:39,029 --> 00:41:42,900
can use all the trusted computing
primitives that mostly the NSA built on

625
00:41:42,900 --> 00:41:46,049
top of that so thank you guys

626
00:41:46,049 --> 00:41:51,180
you can use all the stuff i talked about
so I kind of skip over this pretty

627
00:41:51,180 --> 00:41:54,749
quickly but you have a chain of trust
you can measure other parts if you have

628
00:41:54,749 --> 00:41:57,899
I can remember the flame malware

629
00:41:58,499 --> 00:42:02,459
i believe it was split itself up into
multiple processes to make it more or

630
00:42:02,460 --> 00:42:03,539
less suspicious

631
00:42:03,539 --> 00:42:08,430
so for example all the network i oh was
run through a patch to Internet Explorer

632
00:42:08,430 --> 00:42:12,450
process because that looks a lot less
suspicious than notepad or word talking

633
00:42:12,450 --> 00:42:13,859
out to the network

634
00:42:13,859 --> 00:42:16,890
so you could actually basically have
measurements of all your system

635
00:42:16,890 --> 00:42:20,339
components and combine those that can
trust to make sure that your malware is

636
00:42:20,339 --> 00:42:26,339
intact and and not being looked at the
nice thing with the the hairs and SG x

637
00:42:26,339 --> 00:42:29,460
is even an operating systems if you have
Colonel privileges and you're trying to

638
00:42:29,460 --> 00:42:33,420
look down on it and with STX even if you
have hypervisor privileges and you're

639
00:42:33,420 --> 00:42:35,069
trying to look down on it

640
00:42:35,069 --> 00:42:39,960
you won't be able to see what it's doing
its kind of in that wrapped Enclave and

641
00:42:39,960 --> 00:42:42,930
our i'll reverse engineering these
enclaves very very difficult

642
00:42:42,930 --> 00:42:46,799
so it helps you prevent you know burning
those capabilities or have shown your

643
00:42:46,799 --> 00:42:48,079
hand obviously

644
00:42:48,079 --> 00:42:52,069
this is pretty advanced stuff so they
know that's probably not you know a kid

645
00:42:52,069 --> 00:42:57,049
in his mom's basement but it's you know
it's still will help you avoid giving up

646
00:42:57,049 --> 00:42:57,979
the specifics

647
00:42:57,979 --> 00:43:08,930
so with all of those combined so we have
the observer effect again this is the

648
00:43:08,930 --> 00:43:12,229
kind of repeat but ensuring they were
executing privately

649
00:43:12,229 --> 00:43:15,229
we've got cozy on a home you know all
the kind of in and out of all of our

650
00:43:15,229 --> 00:43:18,739
Hardware in a very very specific layer
and then we have encrypted Cape

651
00:43:18,739 --> 00:43:22,489
execution to put it all together so this
would be perhaps how you might run

652
00:43:22,489 --> 00:43:27,079
through an operation on the red team so
the attacker somehow deliver the initial

653
00:43:27,079 --> 00:43:28,130
exploit

654
00:43:28,130 --> 00:43:31,549
I can characterize the environment and
figure out how much introspection or if

655
00:43:31,549 --> 00:43:32,690
there's introspection

656
00:43:32,690 --> 00:43:36,619
if there is a mite scrub the system and
change tactics to go somewhere else if

657
00:43:36,619 --> 00:43:40,190
not it could establish that device key
by looking around and trying to see what

658
00:43:40,190 --> 00:43:41,690
sources are available

659
00:43:41,690 --> 00:43:46,369
it could then once it has that you could
use typical pki set up a TLS where the

660
00:43:46,369 --> 00:43:50,839
keys device-specific - Ricky you can't
get the next stage of the the payload or

661
00:43:50,839 --> 00:43:54,440
the next chunk of the malware and then
you can kind of wrap it up in an

662
00:43:54,440 --> 00:43:58,519
executed in an enclave and then it can
use remote station the Sailor protocol

663
00:43:58,519 --> 00:44:03,529
to go back to the attacker servants a
yes I've been loaded all components are

664
00:44:03,529 --> 00:44:04,219
fine

665
00:44:04,219 --> 00:44:08,239
there hasn't been someone looking at us
and that's a nice way to make sure that

666
00:44:08,239 --> 00:44:12,229
you're not being too closely examined

667
00:44:12,229 --> 00:44:15,948
so again

668
00:44:15,949 --> 00:44:19,549
inclusion basically when you're doing a
really advanced red team exercise you

669
00:44:19,549 --> 00:44:22,640
want to make sure that you're not
tipping your hand and I think as threat

670
00:44:22,640 --> 00:44:26,690
intelligence goes from being a buzzword
is or where just a feed of IP addresses

671
00:44:26,690 --> 00:44:30,140
to something a little bit more
meaningful you really want to make sure

672
00:44:30,140 --> 00:44:33,769
that your tactics techniques and
procedures and tools

673
00:44:33,769 --> 00:44:37,038
don't necessarily get it up in one of
those feeds because that means anyone

674
00:44:37,039 --> 00:44:43,339
with a Splunk or fire I device might
catch your your red team we shown that

675
00:44:43,339 --> 00:44:49,400
features present in most systems provide
a lot of a kind of building blocks for

676
00:44:49,400 --> 00:44:55,519
these trusted computing features that
are usually add on so a TPM or intel txt

677
00:44:55,519 --> 00:45:00,689
is a chipset addition you need to be
usually by the vpro expensive cpus for

678
00:45:00,690 --> 00:45:04,470
and then you can kind of compose all
this into a softy p.m. and provider to

679
00:45:04,470 --> 00:45:05,549
trust

680
00:45:05,550 --> 00:45:10,140
also when I make a note this is just
technology i always make this regardless

681
00:45:10,140 --> 00:45:14,220
of my talk is office or answer
defense-oriented you know technology is

682
00:45:14,220 --> 00:45:17,549
not prescribe any morals and people
could say I'm a terrible person because

683
00:45:17,550 --> 00:45:19,950
now some bad guy is going to take this

684
00:45:19,950 --> 00:45:23,339
but at the same time you could use it
for Trina why use it for trusted

685
00:45:23,339 --> 00:45:24,150
implants

686
00:45:24,150 --> 00:45:27,660
I could also now take system that
doesn't have a TPM i could add this and

687
00:45:27,660 --> 00:45:31,348
add trust to some legacy device I'm
being forced to run on my system or if I

688
00:45:31,349 --> 00:45:34,560
have a piece of hardware that has not
only maybe fpgas on it

689
00:45:34,560 --> 00:45:39,210
I can now add trusted that or if you're
you know operating in a contested

690
00:45:39,210 --> 00:45:42,690
network so the NSA's i ad director

691
00:45:42,690 --> 00:45:47,220
Deborah Plunkett basically says the
NSA's assuming that there are actors on

692
00:45:47,220 --> 00:45:50,640
our networks and so we need to find ways
to operate in a contested environment

693
00:45:50,640 --> 00:45:53,640
and be able to kind of create these
little islands of trust to be able to

694
00:45:53,640 --> 00:45:56,640
operate not lose our information and
then move on to the next one

695
00:45:56,640 --> 00:45:59,879
this is a way that you can kind of do
that in a very dynamic fashion

696
00:45:59,880 --> 00:46:04,230
I think future work into pki for
offensive networks

697
00:46:04,230 --> 00:46:08,190
pki is obviously not a very solve
problem in practice even on defensive

698
00:46:08,190 --> 00:46:13,920
stuff seems like every couple days
there's another you know challenge or

699
00:46:13,920 --> 00:46:18,390
issue I think it'd be really interesting
to see if you add on the other things of

700
00:46:18,390 --> 00:46:20,190
meeting stealth and persistence

701
00:46:20,190 --> 00:46:24,750
what a offensive pki network and kind of
web of trust for implants and buttons

702
00:46:24,750 --> 00:46:28,410
would look like and so with that I like
to thank you all for your time

703
00:46:29,069 --> 00:46:32,279
I have a ton of references which you can
get online are there any questions

704
00:46:38,870 --> 00:46:41,870
do we have any questions

705
00:46:43,420 --> 00:46:47,530
if you if you put this all together how
much time does it take to prepare and

706
00:46:47,530 --> 00:46:50,020
then how much overhead do you have

707
00:46:50,020 --> 00:46:56,380
so the encrypted execution part which is
a wallet actually running is two percent

708
00:46:56,380 --> 00:47:01,270
or less cpu hit is a little bit of
startup time but that's usually measured

709
00:47:01,270 --> 00:47:08,079
in fractions of seconds if you have the
puffs so obviously it depends on what

710
00:47:08,079 --> 00:47:11,260
type of puff you're running so if you're
using an eeprom or flash puffs for an

711
00:47:11,260 --> 00:47:12,160
ice cream puff

712
00:47:12,160 --> 00:47:16,029
it's on the order of milliseconds if
you're trying to do the row hammer one

713
00:47:16,030 --> 00:47:19,270
and you have ran that's pretty resistant
to row hammer or maybe completely

714
00:47:19,270 --> 00:47:20,049
resistant

715
00:47:20,049 --> 00:47:22,540
you may have to be hammering away at
those roads are really really long time

716
00:47:22,540 --> 00:47:25,990
at least two provision and fine rose
that are typically likely to do that and

717
00:47:25,990 --> 00:47:30,430
so that would be probably when you
establish later if you wanted to add

718
00:47:30,430 --> 00:47:34,569
additional assumptions but you know for
the other ones if they're there an fpga

719
00:47:34,569 --> 00:47:39,460
or SRAM are pretty fast and then the
software dynamic her to trust you saw

720
00:47:39,460 --> 00:47:44,559
that demo it's just so it's quite quick
and the timing on it we want to make

721
00:47:44,559 --> 00:47:48,190
sure it doesn't go too long if it runs
too long that's indicated that someone

722
00:47:48,190 --> 00:47:54,040
is trying to to interact or execution
over targets seconds or less

723
00:47:54,040 --> 00:47:58,240
except for Oh hammer yeah and i know i
saw people reporting on different

724
00:47:58,240 --> 00:48:01,540
hardware and some people were getting
bit flips really really fast and real

725
00:48:01,540 --> 00:48:04,720
hammer just their systems and other
people were running I ran on one of my

726
00:48:04,720 --> 00:48:05,680
new systems in it

727
00:48:05,680 --> 00:48:09,160
I got nothing so that that's probably
the biggest variable and that could take

728
00:48:09,160 --> 00:48:15,819
you know hours if you really wanted to
but probably not any more questions

729
00:48:22,250 --> 00:48:25,580
so it's more defensive than offensive
question

730
00:48:25,580 --> 00:48:31,910
ok but that whole split TCB approach
don't we use that somehow to basically a

731
00:48:31,910 --> 00:48:35,839
block in for Alex two from breaking case
in our

732
00:48:35,840 --> 00:48:42,890
by doing what basically free speed data
and code like frequently they get an

733
00:48:42,890 --> 00:48:46,730
info leak you know from a data point or
somewhere and they use that to get their

734
00:48:46,730 --> 00:48:47,630
addresses

735
00:48:47,630 --> 00:48:53,630
so can we use the speed TCB to basically
completely break the link between the

736
00:48:53,630 --> 00:48:54,140
two

737
00:48:54,140 --> 00:49:05,180
yes so there is a paper that cited stuff
I did called hide em or hide them and

738
00:49:05,180 --> 00:49:10,040
basically did that exact thing but they
actually put really juicy looking

739
00:49:10,040 --> 00:49:11,690
gadgets on the data side

740
00:49:11,690 --> 00:49:15,050
so when they loaded it they're like oh
man this has so many awesome gadgets is

741
00:49:15,050 --> 00:49:18,470
going to be perfect but they were all
kind of like honey gadgets and so they

742
00:49:18,470 --> 00:49:22,879
would immediately alert and the code was
you know the real code and so yeah you

743
00:49:22,880 --> 00:49:24,890
could totally use that technique

744
00:49:24,890 --> 00:49:27,589
another advantage of Harvard
architecture say you find like a code

745
00:49:27,590 --> 00:49:30,950
injection attack like you have one kind
of thing you want to pivot to say right

746
00:49:30,950 --> 00:49:34,279
to another process like the internet
explorer when you do that you're going

747
00:49:34,280 --> 00:49:37,520
to be ready to the data page which will
never get executed and so kind of

748
00:49:37,520 --> 00:49:41,090
pivoting through your system and doing
that code injection attacks only work

749
00:49:41,090 --> 00:49:44,540
and so yeah it's definitely useful for
that too

750
00:49:47,890 --> 00:49:52,990
any other questions all right thank you
very much makeup

751
00:49:52,990 --> 00:49:58,629
thank you

