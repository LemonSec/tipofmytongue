1
00:00:14,710 --> 00:00:16,470
thank you good morning everybody

2
00:00:16,470 --> 00:00:19,830
as he said this is the ghost speed
tracer talk

3
00:00:19,830 --> 00:00:25,348
i'm richard johnson with cisco talus and
i am the research manager of a small

4
00:00:25,349 --> 00:00:29,789
team that does one ability research
primarily doing two developments

5
00:00:29,789 --> 00:00:35,280
vulnerability discovery using father's
writing crash triage tools we do a

6
00:00:35,280 --> 00:00:40,559
little bit of work on mitigations we
have free century which is a use a free

7
00:00:40,559 --> 00:00:45,360
mitigation we have a recent MBR blocker
code that's all open source on github

8
00:00:45,360 --> 00:00:49,890
that will prevent things like full disk
encryption based now

9
00:00:49,890 --> 00:00:53,909
ransomware things like that we saw with
petty recently and then we do some other

10
00:00:53,909 --> 00:00:55,500
reverse engineering type stuff

11
00:00:55,500 --> 00:01:01,559
so the agenda for today's talk is
essentially to briefly discuss a few

12
00:01:01,559 --> 00:01:04,679
different applications for tracing that
you may come across in your day-to-day

13
00:01:04,680 --> 00:01:12,030
jobs whether that be four you know
program recovery or things like

14
00:01:12,030 --> 00:01:17,070
understanding code coverage or corpus
distillation and then talk a little bit

15
00:01:17,070 --> 00:01:20,759
about the work that's been done and
guided buzzing up till now this talk

16
00:01:20,760 --> 00:01:23,940
isn't about a new fuzzer or anything
like that this is about understanding

17
00:01:23,940 --> 00:01:28,590
how tracing engines can be used in
guided buzzers and how to optimize the

18
00:01:28,590 --> 00:01:32,580
design and this performance of the
tracing engine so we'll talk about

19
00:01:32,580 --> 00:01:37,590
binary translation which is a one method
for essentially instrumental binaries on

20
00:01:37,590 --> 00:01:41,880
the fly as you execute them and allows
you to augment the functionalities that

21
00:01:41,880 --> 00:01:45,210
you can record a trace and also the
mechanisms that are built into your

22
00:01:45,210 --> 00:01:51,059
cpu's like the Intel BTS branched
restore or the new features like until

23
00:01:51,060 --> 00:01:55,979
process of choice and then I've got some
demos and a whole suite of tracer is

24
00:01:55,979 --> 00:01:59,548
based upon all the technologies that
you'll hear will go through each one of

25
00:01:59,549 --> 00:02:02,700
them and do a quick live demos and show
you how they operate and how they

26
00:02:02,700 --> 00:02:03,479
compare

27
00:02:03,479 --> 00:02:08,280
as far as performance goes and then at
the end i have a live demo of the new

28
00:02:08,280 --> 00:02:14,280
Intel PT processor features inside of
AFL and Hong funds for linux

29
00:02:14,280 --> 00:02:19,140
so essentially the goals are to
understand the attributes of the tracing

30
00:02:19,140 --> 00:02:23,250
and what makes the trays are better for
different applications and how to

31
00:02:23,250 --> 00:02:25,450
increase the performance of that

32
00:02:25,450 --> 00:02:28,899
and then just generally understand the
architecture of if you're going to write

33
00:02:28,900 --> 00:02:33,459
one of these tracing engines what's
involved and if not then how to possibly

34
00:02:33,459 --> 00:02:40,150
integrate the tracing and as I've
written into your own software so for

35
00:02:40,150 --> 00:02:44,890
tracing you know we can use it and
software engineering practices we might

36
00:02:44,890 --> 00:02:47,859
be a little more interested in the
security applications for malware

37
00:02:47,860 --> 00:02:52,569
analysis depending on the racing engine
you decide to use they have different

38
00:02:52,569 --> 00:02:57,940
attributes for anti debugging and
detection from our lair but they're used

39
00:02:57,940 --> 00:03:02,319
all the time for things like behavior
analysis and sand boxes or and unpacking

40
00:03:02,319 --> 00:03:04,208
malware things like that

41
00:03:04,209 --> 00:03:09,640
the microsoft had a mitigation bounty
that was collected from a tool called k

42
00:03:09,640 --> 00:03:14,230
bouncer and that uses at racing engine
based upon last branch record and i'll

43
00:03:14,230 --> 00:03:19,090
briefly touch on that and then other
things that build shadow stacks or do

44
00:03:19,090 --> 00:03:25,120
data flow analysis also need a
high-performance racing engine in my

45
00:03:25,120 --> 00:03:29,739
day-to-day job we mostly are looking for
bugs so we applied racing to corpus

46
00:03:29,739 --> 00:03:33,940
distillation so that we can find the
minimal set of inputs that we want to

47
00:03:33,940 --> 00:03:40,000
target for tracing particular Network
protocol or file parser we use it for

48
00:03:40,000 --> 00:03:43,780
guided fuzzing which allows us to use
the techniques that have been developed

49
00:03:43,780 --> 00:03:49,930
and mutational fuzzing and iteratively
work towards a more refined state and

50
00:03:49,930 --> 00:03:53,530
determine which inputs we should
continue buzzing so that we're not

51
00:03:53,530 --> 00:03:54,819
wasting our time

52
00:03:54,819 --> 00:03:59,108
overlapping or you know continuing to
mutate files that don't get us to any

53
00:03:59,109 --> 00:04:04,329
interesting code paths and then finally
in crash analysis we are released tools

54
00:04:04,329 --> 00:04:08,769
couple years ago that focused on things
like when you get a crash and you

55
00:04:08,769 --> 00:04:11,019
observe that it's a read access
violation

56
00:04:11,019 --> 00:04:15,010
how can we use tracing to actually track
the memory as it executes the program

57
00:04:15,010 --> 00:04:18,849
and determine whether or not there's
constraints on that that would truly

58
00:04:18,849 --> 00:04:22,089
make it only read AV or if you
manipulate the input whether or not you

59
00:04:22,089 --> 00:04:25,690
can reach something like an execution
control or heap corruption or something

60
00:04:25,690 --> 00:04:26,620
like those

61
00:04:26,620 --> 00:04:30,700
and so those tools are out there already
those are on our github

62
00:04:30,700 --> 00:04:37,219
I at github / Talos cash bond of the
most low tools in particular are

63
00:04:37,220 --> 00:04:42,350
are some of the things that I've done in
the past for that and then also now gb

64
00:04:42,350 --> 00:04:47,030
has hooks that are available that expose
some of the underlying racing engines

65
00:04:47,030 --> 00:04:50,719
that i'm going to discuss that allow you
to essentially if your stack is

66
00:04:50,720 --> 00:04:53,300
corrupted completely and you don't know
where you came from

67
00:04:53,300 --> 00:04:56,810
you can actually ask you to dump the
hardware buffers and the hardware all

68
00:04:56,810 --> 00:05:01,940
actually have the last few branches that
you executed so we're doing recovery of

69
00:05:01,940 --> 00:05:04,940
bad crash states that can also be useful

70
00:05:05,570 --> 00:05:09,980
so at how do you start working with
racing engines

71
00:05:09,980 --> 00:05:14,150
basically there's no api is that we're
all pretty familiar with probably your

72
00:05:14,150 --> 00:05:19,909
ptrace on the unix positive side the bug
engine and even signals can be used as a

73
00:05:19,910 --> 00:05:23,990
debugger based feedback mechanism and
the linux kernel they have a pretty

74
00:05:23,990 --> 00:05:28,160
robust and developed tracing
infrastructure currently now named the

75
00:05:28,160 --> 00:05:30,800
linux tracing toolkit

76
00:05:30,800 --> 00:05:35,630
that's all built in and includes
everything from k probes to access to

77
00:05:35,630 --> 00:05:39,800
these Hardware tracing mechanisms and on
the windows side we have things like

78
00:05:39,800 --> 00:05:42,860
Nirvana and at verifier and the shim
engine

79
00:05:42,860 --> 00:05:47,450
these things are not well known by most
people i would say the best reference

80
00:05:47,450 --> 00:05:52,070
source for that kind of thing for using
these hooking engines is Alex I desk is

81
00:05:52,070 --> 00:05:54,080
talk last year at recon

82
00:05:54,080 --> 00:05:57,859
that's great talk its esoteric cooking
or something along those lines and it

83
00:05:57,860 --> 00:06:02,060
goes through how the Nirvana system
works so you can capture system wide

84
00:06:02,060 --> 00:06:08,240
interrupts and system calls basically
with a single pointer control so really

85
00:06:08,240 --> 00:06:09,169
cool stuff

86
00:06:09,169 --> 00:06:13,460
I'm a verifier actually is really cool i
was using it's because it exports a

87
00:06:13,460 --> 00:06:16,370
layer that allows you to essentially
just defined data structures for the

88
00:06:16,370 --> 00:06:19,940
hook points that you need and it's fully
supported by the system and you know

89
00:06:19,940 --> 00:06:24,020
it's not going away so you don't have to
fight with whether or not your engines

90
00:06:24,020 --> 00:06:28,219
overriding are using some you know
esoteric functionality or you know

91
00:06:28,220 --> 00:06:31,160
creating the process than stopping it
and injecting a library or something

92
00:06:31,160 --> 00:06:34,160
like that you can just go ahead and use
a supported API

93
00:06:35,510 --> 00:06:40,159
and then the stuff that's closer to what
the topic of interest today would be the

94
00:06:40,160 --> 00:06:45,560
linux / subsystem that typically has
been used to expose counters like you

95
00:06:45,560 --> 00:06:51,320
know cache misses and you know number of
seconds for this particular instruction

96
00:06:51,320 --> 00:06:53,540
to execute things like that for
profiling

97
00:06:53,540 --> 00:06:58,010
but they have now extended it to include
wrappers for things like the Intel PT

98
00:06:58,010 --> 00:07:02,030
infrastructure as well and then on the
windows side there's an API called

99
00:07:02,030 --> 00:07:05,780
windows pdh and it's so poorly
documented I couldn't even find the

100
00:07:05,780 --> 00:07:09,229
definition for what PH supposed to stand
for

101
00:07:09,230 --> 00:07:12,680
it's you know it's a performance
monitoring tool kit when you go into the

102
00:07:12,680 --> 00:07:16,760
process monitor or something like that
and you see statistics about the process

103
00:07:16,760 --> 00:07:20,690
executing that's where that's coming
from there isn't really any current

104
00:07:20,690 --> 00:07:25,790
support in Windows natively for doing
granular program tracing like block

105
00:07:25,790 --> 00:07:27,530
coverage or anything like that

106
00:07:27,530 --> 00:07:33,799
so who typically if you were on if
you're developing software and you want

107
00:07:33,800 --> 00:07:37,940
to collect coverage the traditional
tools would things be things like g ,

108
00:07:37,940 --> 00:07:41,810
and Elka that the compiler will
instrument every one of your functions

109
00:07:41,810 --> 00:07:45,440
and this is typically applied to
function level coverage as opposed to

110
00:07:45,440 --> 00:07:49,250
block level logic coverage that will
allow you to track which decisions were

111
00:07:49,250 --> 00:07:53,390
made inside your program so you get an
idea of reach ability and the past and

112
00:07:53,390 --> 00:07:57,950
execution over time but you don't have
the ability to determine did we fully

113
00:07:57,950 --> 00:07:58,849
cover

114
00:07:58,850 --> 00:08:03,860
you know all the the decisions that were
made in here that it can do a mapping to

115
00:08:03,860 --> 00:08:09,080
line based coverage so you can see which
lines were executed but it's not as well

116
00:08:09,080 --> 00:08:13,820
exported are exposed to things that are
appropriate for fuzzing or finding

117
00:08:13,820 --> 00:08:18,890
vulnerabilities in an automated fashion
and then the granddaddy of the binary

118
00:08:18,890 --> 00:08:23,030
translation that a lot of academic
research has been done on is val grand

119
00:08:23,030 --> 00:08:30,440
ave el Grande you have cool tools like
memcache d on that and there's paint

120
00:08:30,440 --> 00:08:31,040
checker

121
00:08:31,040 --> 00:08:34,789
that's built into that as well it's
always been a good platform to develop

122
00:08:34,789 --> 00:08:38,839
ideas on but it's not cross platform and
its really slow

123
00:08:38,840 --> 00:08:41,810
it's has a robust but

124
00:08:41,809 --> 00:08:46,099
you know not a very performant engine so
so basically we need to look at

125
00:08:46,100 --> 00:08:51,020
something that's cross-platform and you
know more performance the to pull off

126
00:08:51,020 --> 00:08:56,150
what we're trying to do and your typical
tools a choice there are dynamo Rio and

127
00:08:56,150 --> 00:09:01,520
pin and then we've also developed tools
and open source them based upon dynast

128
00:09:01,520 --> 00:09:07,579
which is another academic toolkit that
works primarily on linux but it has some

129
00:09:07,580 --> 00:09:11,420
hope for working on windows soon and
allows you to do static binary writing

130
00:09:11,420 --> 00:09:14,990
so we'll get into the attributes of each
of these and a little bit more

131
00:09:14,990 --> 00:09:18,500
there's new ones coming on the block
like Frida and some others that

132
00:09:18,500 --> 00:09:22,910
incorporate the JavaScript v8
just-in-time compiler engine but they're

133
00:09:22,910 --> 00:09:23,750
not quite

134
00:09:23,750 --> 00:09:26,720
they're also not targeting level
granularity and I don't think there's

135
00:09:26,720 --> 00:09:28,940
performance as the other options

136
00:09:28,940 --> 00:09:32,270
so on the hardware side

137
00:09:32,839 --> 00:09:36,170
I mean you probably interacted at least
with this verse one single steps and

138
00:09:36,170 --> 00:09:40,670
break points and you may have heard
about the Intel branch trace flag which

139
00:09:40,670 --> 00:09:44,150
will convert single steps over to basic
block steps

140
00:09:44,150 --> 00:09:47,420
so instead of doing a single step it
will actually fire interrupt

141
00:09:47,420 --> 00:09:51,949
every time you do a branch instead and
then they'll be our last branch record

142
00:09:51,950 --> 00:09:56,060
that's the one that I mentioned was used
for mitigations and highly performant

143
00:09:56,060 --> 00:09:59,599
use its own set of registers but it
doesn't like to record much of a trace

144
00:09:59,600 --> 00:10:05,930
and branched race tour was the next next
mechanism that was designed to be able

145
00:10:05,930 --> 00:10:11,420
to capture all blocked races into a ring
buffer interactive mode programming but

146
00:10:11,420 --> 00:10:15,560
it's not very fast either it's actually
slower than any of the software DVI

147
00:10:15,560 --> 00:10:19,790
approaches and i'll show you the most of
that but the latest hotness

148
00:10:19,790 --> 00:10:24,980
ever since last year so Intel's included
something called intel processor trace

149
00:10:24,980 --> 00:10:28,550
and that's like the exciting new stuff
because it's actually designed with

150
00:10:28,550 --> 00:10:32,930
performance in mind and it's kind of a
highlight for where I'm trying to take

151
00:10:32,930 --> 00:10:38,420
the tracing technologies and just a
mention i'm not doing any we're

152
00:10:38,420 --> 00:10:42,650
currently on the arm course site
functionality but it's also similar to

153
00:10:42,650 --> 00:10:45,850
the branch to a store where you can do
branched racing

154
00:10:45,850 --> 00:10:52,449
natively into the in the core so we'll
switch contacts a little bit and talk

155
00:10:52,449 --> 00:10:55,899
about you know what is evolutionary
testing or guided buzzing where they

156
00:10:55,899 --> 00:10:57,339
come from that sort of thing

157
00:10:57,339 --> 00:11:01,899
originally evolutionary testing was
really appropriated in government

158
00:11:01,899 --> 00:11:06,610
research people that we're doing white
box testing of hardens and critical

159
00:11:06,610 --> 00:11:12,519
systems so I you know aircraft operating
systems or other things that you would

160
00:11:12,519 --> 00:11:16,389
use you know set compr you know reduce
compilers that are verified and they

161
00:11:16,389 --> 00:11:20,350
need to ensure that they're doing the
highest grade of testing possible

162
00:11:21,069 --> 00:11:26,290
and so the main thing there is that some
of the techniques that they adopted or

163
00:11:26,290 --> 00:11:31,630
created aren't immediately usable
against binary targets because they went

164
00:11:31,630 --> 00:11:36,310
from a sense of collecting attributes
about the software like probable

165
00:11:36,310 --> 00:11:39,459
vulnerable locations you know maybe an
integer overflow detector something

166
00:11:39,459 --> 00:11:43,660
would say that you know if we can reach
this area code then with user control

167
00:11:43,660 --> 00:11:47,620
input it's likely this vulnerability and
so then they would use evolutionary

168
00:11:47,620 --> 00:11:52,899
testing to get from point A to point B
you can apply this in binaries it is

169
00:11:52,899 --> 00:11:53,800
more difficult

170
00:11:53,800 --> 00:11:56,979
so there isn't really a good framework
for a direct application of those tools

171
00:11:56,980 --> 00:12:00,819
and of course none of them were ever
made open source or anything like that

172
00:12:00,819 --> 00:12:05,889
and discussed as far as the internal
designs but they were applied and

173
00:12:05,889 --> 00:12:09,819
effectively used for preventing denial
service and that sort of thing and

174
00:12:09,819 --> 00:12:17,649
critical systems in the framework of
doing water bill analysis for what we do

175
00:12:17,649 --> 00:12:23,560
essentially the idea is to you know
cheaply without a lot of user

176
00:12:23,560 --> 00:12:27,939
interaction without having to write
protocol definitions or do a lot of

177
00:12:27,939 --> 00:12:30,250
upfront work to just you know

178
00:12:30,250 --> 00:12:33,759
refine the methods that we've been doing
for the last 10 years and um fuzzing so

179
00:12:33,759 --> 00:12:39,550
this pretty much allows us to approach
apply evolutionary algorithms which are

180
00:12:39,550 --> 00:12:43,660
based around the core principles of the
way that genetics work in the sense that

181
00:12:43,660 --> 00:12:48,759
the strongest population when introduced
to another similarly strong population

182
00:12:48,759 --> 00:12:54,399
will mutate and create generations past
that have attributes from both and

183
00:12:54,399 --> 00:12:59,199
ideally those attributes that you see
this this input over here games a lot of

184
00:12:59,199 --> 00:12:59,410
code

185
00:12:59,410 --> 00:13:03,279
coverage and incorporates this
functionality and if we merge that are

186
00:13:03,279 --> 00:13:07,240
keep manipulating that will get deeper
and further into the parsers and so

187
00:13:07,240 --> 00:13:11,829
essentially that's all that the
evolutionary algorithms really do for

188
00:13:11,829 --> 00:13:16,989
buzzing or and applied to any approach
really is to continually allow you to

189
00:13:16,990 --> 00:13:22,930
iterate through you know dumb brute
force methods and continue to get the

190
00:13:22,930 --> 00:13:27,638
right population just through iterative
testing so it's basically just a really

191
00:13:27,639 --> 00:13:32,050
cheap way to find security bugs and the
most popular father out there right now

192
00:13:32,860 --> 00:13:37,540
can I actually get a raise your hands if
you do buzzing and you've used American

193
00:13:37,540 --> 00:13:38,560
fuzzy lop

194
00:13:38,560 --> 00:13:43,599
let me get that raise your hands okay so
maybe ten fifteen percent of you guys so

195
00:13:43,600 --> 00:13:47,860
Americans Elop is an extremely
successful fuzzer i'll highlight some of

196
00:13:47,860 --> 00:13:51,670
the attributes in a minute but if you
used a American flop then you're already

197
00:13:51,670 --> 00:13:57,189
using evolutionary testing and you'll
know that it's much more successful than

198
00:13:57,189 --> 00:14:04,029
using a typical off-the-shelf dumb
father so it has its merits the first

199
00:14:04,029 --> 00:14:09,459
public talk really the introduce these
ideas was very sparks & Hamilton's black

200
00:14:09,459 --> 00:14:14,649
hat 2006 talk called Sidewinder really
cool they were doing this came out of

201
00:14:14,649 --> 00:14:17,649
their academic research but i think they
were also targeted the government sector

202
00:14:18,220 --> 00:14:21,160
I mean if you look at the slides they've
got an ICBM missiles or something you

203
00:14:21,160 --> 00:14:25,209
know on the slide deck and everything
but I had some really cool attributes to

204
00:14:25,209 --> 00:14:26,199
their approach

205
00:14:26,199 --> 00:14:30,969
they were the first ones to publicly
discuss using genetic algorithms in

206
00:14:30,970 --> 00:14:36,189
opposing context so that's kind of there
when they never open source that became

207
00:14:36,189 --> 00:14:38,500
public but their side x really good

208
00:14:38,500 --> 00:14:42,279
they use a context-free grammar to
describe the inputs and then they

209
00:14:42,279 --> 00:14:43,930
manipulated the grammar itself

210
00:14:43,930 --> 00:14:50,680
so rather than take a byte stream of
your network or file format it would

211
00:14:50,680 --> 00:14:55,000
actually define a context-free grammar
that relates fields and has de limiters

212
00:14:55,000 --> 00:14:59,620
and things along those lines that
structure that describes the input would

213
00:14:59,620 --> 00:15:04,360
then be manipulated and used as a model
for generating further inputs and so you

214
00:15:04,360 --> 00:15:07,660
saw stuff like this also out of the blue
group and produce

215
00:15:08,380 --> 00:15:12,100
and their work and the main problem with
that of course is you have the upfront

216
00:15:12,100 --> 00:15:14,860
cost of developing the model to start
with

217
00:15:14,860 --> 00:15:20,620
they didn't get to the point of model
refinement that was automatic where you

218
00:15:20,620 --> 00:15:24,370
can have a loose model saying you know I
know this is jesus data i know this is

219
00:15:24,370 --> 00:15:30,790
some sort of tlv set of fields but they
did which would eventually allow you to

220
00:15:30,790 --> 00:15:34,300
kind of refine that down but they did
introduce the idea of using a grammar

221
00:15:34,300 --> 00:15:37,839
and causing the grammar as opposed to
fuzzing the bites themselves which is

222
00:15:37,840 --> 00:15:40,120
interesting

223
00:15:40,120 --> 00:15:45,100
they had a pretty slow tracing engine
that's major drawback of their system

224
00:15:45,100 --> 00:15:51,730
but they did have a pretty cool process
or you know evaluation for fitness which

225
00:15:51,730 --> 00:15:55,690
is the other key part of the genetic
testing genetic algorithms and they use

226
00:15:55,690 --> 00:16:00,280
the Markov process which so this is a
demonstration of the grammar kind of

227
00:16:00,280 --> 00:16:05,110
here on the right where each one of
those represents you know if you start

228
00:16:05,110 --> 00:16:10,120
with a then you wrap it and what s is in
and so on so you build a string of a set

229
00:16:10,120 --> 00:16:15,400
of numbers in the bottom left is you
know 10 247 sensually you walk through

230
00:16:15,400 --> 00:16:19,569
those steps on your series of input and
then you output at the bottom

231
00:16:19,570 --> 00:16:25,600
XA bbad X so that's the mutator
algorithm and then they're a valuation

232
00:16:25,600 --> 00:16:30,670
algorithm is this Markov process which
essentially allows you to evolve waited

233
00:16:30,670 --> 00:16:36,849
whether or not you'll go down certain
paths or whether or not you are more

234
00:16:36,850 --> 00:16:41,590
likely to keep an input that went down
certain pads is based upon an overtime

235
00:16:41,590 --> 00:16:47,740
evaluation of all input scene and so
cheaply creating a log of where all

236
00:16:47,740 --> 00:16:52,330
these inputs have been is actually not
an easy thing to design i would say this

237
00:16:52,330 --> 00:16:56,140
was a good model and then it took about
10 years until we ran into American

238
00:16:56,140 --> 00:16:59,680
fuzzy lot to get this next best model in
between

239
00:16:59,680 --> 00:17:03,489
everybody seems to want to write out
these really verbose logs and of all

240
00:17:03,490 --> 00:17:07,959
blocks sitting and then post process
that and then kind of try to merge those

241
00:17:07,959 --> 00:17:12,280
results together rather than keep a
continuous flow of things that self

242
00:17:12,280 --> 00:17:17,589
weight and create a model iteratively
just like you're creating your inputs

243
00:17:17,589 --> 00:17:22,540
iteratively but yeah so basically the it
was never open source which is too bad

244
00:17:22,540 --> 00:17:26,740
had some great concepts and people kind
of forgot about them because the next

245
00:17:26,740 --> 00:17:31,630
year we had Jared amat talking about his
evolutionary buzzing system at the time

246
00:17:31,630 --> 00:17:34,720
the pie a framework was really pretty
popular

247
00:17:34,720 --> 00:17:40,030
it was able to do code coverage using
some of these tracing mechanisms but it

248
00:17:40,030 --> 00:17:44,200
was still pretty slow it used the
debugger API or used the French tres

249
00:17:44,200 --> 00:17:51,970
flag but Jared took a very very academic
approach this was for his PhD thesis and

250
00:17:51,970 --> 00:17:56,530
essentially he ended up trying to get
closer to what scientists do when

251
00:17:56,530 --> 00:17:59,590
they're tracking actual biological
evolution which includes a lot more

252
00:17:59,590 --> 00:18:04,959
variables and environmental analysis and
essentially just made it overly complex

253
00:18:04,960 --> 00:18:09,280
people by making all these variables and
not having a good like data management

254
00:18:09,280 --> 00:18:09,910
layer

255
00:18:09,910 --> 00:18:13,000
he just threw it into a sequel database
which had to be queried on every

256
00:18:13,000 --> 00:18:16,870
iteration and so you know we've gone
from a point where you might get one

257
00:18:16,870 --> 00:18:22,989
iteration every few seconds or every 30
seconds to getting you know thousands of

258
00:18:22,990 --> 00:18:24,550
iterations a second

259
00:18:24,550 --> 00:18:28,360
just through increasing the performance
and applying this so generally speaking

260
00:18:28,360 --> 00:18:31,870
the value that Jared brought was just a
little more awareness he made an

261
00:18:31,870 --> 00:18:35,229
open-source you did it in a toolkit
other people were using and familiar

262
00:18:35,230 --> 00:18:40,450
with but do more or less not great
engineering practices it just never

263
00:18:40,450 --> 00:18:42,280
panned out as something beyond it

264
00:18:42,280 --> 00:18:45,510
an idea

265
00:18:45,510 --> 00:18:52,230
and then that brings us to today all the
way from two thousand seven to twenty

266
00:18:52,230 --> 00:18:58,530
thirteen Michaels LS key release the
American fuzzy lop and this is truly a

267
00:18:58,530 --> 00:19:03,000
revolution and that like the next
generation of doing the testing

268
00:19:03,000 --> 00:19:06,960
he started with these ideas and Tavis
Normandy also was starting with these

269
00:19:06,960 --> 00:19:09,240
ideas back in two thousand seven

270
00:19:09,240 --> 00:19:13,590
Michael Zaleski wrote a compiler plug-in
and at the time I didn't actually pay a

271
00:19:13,590 --> 00:19:17,639
lot of attention because i have always
been interested in third-party black box

272
00:19:17,640 --> 00:19:22,470
testing at the time I was working at
Microsoft so you know I had internal

273
00:19:22,470 --> 00:19:25,560
source code but we couldn't use anything
that was open source so anything I

274
00:19:25,560 --> 00:19:30,540
wanted to evaluate that wasn't our own
code was black box binary stuff so I

275
00:19:30,540 --> 00:19:35,490
didn't really look into the first
iteration bunny the buzzer

276
00:19:35,490 --> 00:19:39,930
but I had a lot of similar ideas as
American fuzzy laughs oh it was out

277
00:19:39,930 --> 00:19:42,900
there and just never caught on anywhere

278
00:19:42,900 --> 00:19:47,070
Tavis or MIDI took and we'll Drury took
a different approach they were writing

279
00:19:47,070 --> 00:19:48,600
flyer at the time

280
00:19:48,600 --> 00:19:52,679
flare was built on Val grind as a
tracing engine and it was basically

281
00:19:52,680 --> 00:19:56,820
allowed you to tear apart the outer
layers of a program where there might be

282
00:19:56,820 --> 00:20:01,439
check sums or compression and get right
into the deep internals of the program

283
00:20:01,440 --> 00:20:05,970
and start buzzing at that layer and of
course these guys at some point all

284
00:20:05,970 --> 00:20:09,600
ended up merging together under the
google security banner and now i think

285
00:20:09,600 --> 00:20:14,159
you know these ideas are flowing
internally and things like that but but

286
00:20:14,160 --> 00:20:18,000
American fuzzy la essentially is a
compile-time in instrumentation

287
00:20:18,510 --> 00:20:24,210
it was out of the box anyways but it's a
simplified the approach to the genetic

288
00:20:24,210 --> 00:20:29,970
algorithm specifically in keeping track
of your entire execution time so if

289
00:20:29,970 --> 00:20:32,010
you're fuzzing something for weeks on
end

290
00:20:32,010 --> 00:20:36,660
it keeps a memory mapped by Turay that
essentially what it does is it takes a

291
00:20:36,660 --> 00:20:41,040
source block and a destination block the
you know the branch it x or them

292
00:20:41,040 --> 00:20:46,860
together and creates a bit of a hash
that fits into like 64k hash table and

293
00:20:46,860 --> 00:20:51,240
essentially indexes into that hash are
keeping the number of times that edge

294
00:20:51,240 --> 00:20:53,010
has been traversed

295
00:20:53,010 --> 00:20:57,060
and the number of times that increases
that will increase if you go into loops

296
00:20:57,060 --> 00:20:58,590
or that will increase

297
00:20:58,590 --> 00:21:02,550
you know any time it's observed to
execute that particular edge and over

298
00:21:02,550 --> 00:21:06,300
time you can determine whether or not a
new input is interesting

299
00:21:06,300 --> 00:21:10,530
compared to the entire set of observed
inputs over time so that way you can

300
00:21:10,530 --> 00:21:14,399
keep drilling down and he does this
through a shared memory map which we've

301
00:21:14,400 --> 00:21:19,410
taken the trouble to port over to cygwin
so that we can use this is the basis for

302
00:21:19,410 --> 00:21:23,700
windows posing as well but using the
memory map between the child process

303
00:21:23,700 --> 00:21:27,660
that's being buzzed and the observer
process of course is a pretty fast

304
00:21:27,660 --> 00:21:33,150
mechanism it's it's actually engineered
to be idiot proof and to be very fast

305
00:21:33,150 --> 00:21:38,250
and to work out of the box and you know
it took the compiler approach which is

306
00:21:38,250 --> 00:21:39,990
much more performance in general

307
00:21:39,990 --> 00:21:44,760
so you don't have to use translation
engine and at the end of the day it's

308
00:21:44,760 --> 00:21:50,040
actually found a lot of good bugs up
here on the right

309
00:21:50,610 --> 00:21:54,389
that's you got it even has a gooey which
you know is pretty rare in the fuzzing

310
00:21:54,390 --> 00:21:58,170
instance but it's cool because in
particular this gooey allows you to

311
00:21:58,170 --> 00:22:02,340
track over time and see you know on the
far right there its kind of gives you

312
00:22:02,340 --> 00:22:06,689
some stats on how many passes that have
you seen it evaluates when new pads are

313
00:22:06,690 --> 00:22:12,690
discovered which inputs are generating
the most new paths and then keeps a

314
00:22:12,690 --> 00:22:17,400
corpus and the cool thing about the
corpus is that can be reused in other

315
00:22:17,400 --> 00:22:19,890
buzzing techniques as well

316
00:22:19,890 --> 00:22:24,900
so for example every input that it keeps
around and adds to its population or

317
00:22:24,900 --> 00:22:27,090
pool of inputs that it might fuzz

318
00:22:27,090 --> 00:22:32,699
each one of those exercises a different
functionality in the program and so if

319
00:22:32,700 --> 00:22:36,480
you go and target something that is
closed source and doesn't have the

320
00:22:36,480 --> 00:22:40,140
ability to be instrumented through
American fuzzy lop or is too slow when

321
00:22:40,140 --> 00:22:45,210
instrumented like Microsoft Word or you
know any of the meter application suites

322
00:22:45,210 --> 00:22:46,920
that do productivity

323
00:22:46,920 --> 00:22:51,750
then you can actually take a known good
set of different and minimized inputs

324
00:22:51,750 --> 00:22:57,330
and use more traditional buzzing systems
like we're dams or zu f or any of the

325
00:22:57,330 --> 00:23:00,320
other ones which is pretty cool

326
00:23:00,320 --> 00:23:05,029
and uh I brought a fork server into the
mix as well which is just a much more

327
00:23:05,029 --> 00:23:08,690
efficient way of spotting processes when
your linux you get a copy on write some

328
00:23:08,690 --> 00:23:12,799
for you no duplication of the address
space so just pretty much

329
00:23:12,799 --> 00:23:18,049
instantaneously can spin up a new
process to test and it has a couple

330
00:23:18,049 --> 00:23:21,500
other cool things in their proper
persistent mode fuzzing which allows you

331
00:23:21,500 --> 00:23:25,159
to directly instrument some functions
and say this is the function that I want

332
00:23:25,159 --> 00:23:28,909
to start buzzing at and then at the end
of that you write the little function

333
00:23:28,909 --> 00:23:32,870
does memory clean up for you and then it
will look back and start again

334
00:23:32,870 --> 00:23:37,070
so I'm working on something similar to
that in the window space by generating

335
00:23:37,070 --> 00:23:41,450
threads so you know you identify where
the thread create occurred that then

336
00:23:41,450 --> 00:23:42,230
later on

337
00:23:42,230 --> 00:23:46,100
reads the input that you're interested
in and then you basically allow that

338
00:23:46,100 --> 00:23:49,969
thread to go through this process which
usually is reading in data putting it

339
00:23:49,970 --> 00:23:54,259
into structures and passing it back to
application to do something with it at a

340
00:23:54,259 --> 00:23:59,389
higher level you can just respond
threads there so we can escape the 40

341
00:23:59,389 --> 00:24:04,008
model and just go with the native
threading model instead those that might

342
00:24:04,009 --> 00:24:08,750
have seen my talk last year we did some
work to bring windows native forking

343
00:24:08,750 --> 00:24:13,730
using undocumented api's and the windows
kernel and turns out to be a real pain

344
00:24:13,730 --> 00:24:14,330
in the ass

345
00:24:14,330 --> 00:24:19,639
at the end of the day if you use Windows
system calls to write your own version

346
00:24:19,639 --> 00:24:20,539
of a fork

347
00:24:20,539 --> 00:24:25,309
the windows higher level eight like
subsystem like CS RSS are not really

348
00:24:25,309 --> 00:24:29,269
aware of this new process that you
generated so it works ok for wrapping

349
00:24:29,269 --> 00:24:32,990
libraries directly if you're writing
your own rappers but it doesn't work for

350
00:24:32,990 --> 00:24:39,649
you want to run a bunch of iterations of
adobe reader really fast but yeah back

351
00:24:39,649 --> 00:24:42,590
to the American flop the main
observations here

352
00:24:42,590 --> 00:24:47,059
keep it simple stupid definitely does
still apply doesn't matter how technical

353
00:24:47,059 --> 00:24:51,769
your application of the technology is
actually producing a tool that is easy

354
00:24:51,769 --> 00:24:55,370
to use right out of the box has you know
configuration options and warnings when

355
00:24:55,370 --> 00:24:56,959
you're not using it correctly

356
00:24:56,960 --> 00:25:01,970
AFL for example will analyze your set of
inputs that you start with right off the

357
00:25:01,970 --> 00:25:05,450
bat and will execute through each one
and it will tell you i think it was too

358
00:25:05,450 --> 00:25:09,260
big of inputs here you don't need a 3
megabytes sample of a PDF to do PDF

359
00:25:09,260 --> 00:25:09,860
buzzing

360
00:25:09,860 --> 00:25:13,909
and in fact the bigger the number of
bytes that you have the less likely that

361
00:25:13,910 --> 00:25:18,140
a single bit flip is going to cause a
substantial change the program so

362
00:25:18,140 --> 00:25:23,030
minimizing your input set down to the
smallest trigger possible to execute

363
00:25:23,030 --> 00:25:27,230
that type of code is the way to increase
efficiency in your search space

364
00:25:27,230 --> 00:25:33,890
essentially but yea performance is a top
priority which I find to be heavily

365
00:25:33,890 --> 00:25:38,720
lacking in almost every security tool
out there and my talk last year I the

366
00:25:38,720 --> 00:25:43,280
specifically focused on you know cost
reduction and the importance of

367
00:25:43,280 --> 00:25:46,970
performance in security testing an
automated testing at the end of the day

368
00:25:46,970 --> 00:25:52,010
if I can do fifty percent optimization
for performance than i have about half

369
00:25:52,010 --> 00:25:56,090
as many course as I would have otherwise
to compete with the other guys out there

370
00:25:56,090 --> 00:26:01,580
that are doing closing at scale so we
are in a phase of doing security testing

371
00:26:01,580 --> 00:26:06,260
automatically that performances matters
because you got guys like you know the

372
00:26:06,260 --> 00:26:09,679
googles and the Amazons and others out
there that were that are in a position

373
00:26:09,679 --> 00:26:15,169
to scale infinitely so optimizing and
reducing your costs set to be able to

374
00:26:15,169 --> 00:26:19,490
compete in that market is important than
the last

375
00:26:20,210 --> 00:26:23,390
well now there's a couple more ok so
then that song for us it's another

376
00:26:23,390 --> 00:26:29,059
father from Roberts wiki google it
wasn't very interesting until 2015

377
00:26:29,059 --> 00:26:33,350
it basically was a pretty much done
father was easy to use but was a lot

378
00:26:33,350 --> 00:26:35,870
going on with it and put in 2015

379
00:26:35,870 --> 00:26:40,010
he started adding guided fuzzing
features and specifically going after

380
00:26:40,010 --> 00:26:44,000
wrapping the linux perf interface so
that racing engines were about to

381
00:26:44,000 --> 00:26:44,690
discuss

382
00:26:44,690 --> 00:26:48,110
he basically has interfaces for all of
them right now out of the box

383
00:26:48,110 --> 00:26:53,090
unfortunately he did add intel processor
Trey support and I was unable to get it

384
00:26:53,090 --> 00:26:58,399
to work and I'll talk to mention why a
little bit later but it is pretty cool

385
00:26:58,400 --> 00:27:03,890
it does block coverage now and initially
it also was kind of weak and only kept

386
00:27:03,890 --> 00:27:06,169
one input rather than a whole corpus

387
00:27:06,169 --> 00:27:09,919
he didn't have a good algorithm for
tracking the performance of a single

388
00:27:09,919 --> 00:27:14,230
input overtime kind of the only the
strong survive in the case of

389
00:27:14,230 --> 00:27:20,770
this day it's only the elite survive and
and genetic testing but it's cool it's

390
00:27:20,770 --> 00:27:24,970
cross platform and it actually now also
has source-based instrumentation and if

391
00:27:24,970 --> 00:27:29,200
you're writing your own father's and
you're trying to optimize or you know

392
00:27:29,200 --> 00:27:34,270
tweak something specifically to certain
target hunk was a lot easier to hack on

393
00:27:34,270 --> 00:27:38,530
the AFL is the FL has the curses
interface and it's interleaved it's one

394
00:27:38,530 --> 00:27:41,559
like 10,000 lines see source file

395
00:27:41,559 --> 00:27:44,649
it's kind of a pain in the ass to
actually hack on and do anything with a

396
00:27:44,650 --> 00:27:50,020
hunk was a much more approachable code
base but now and I now has all the main

397
00:27:50,020 --> 00:27:53,260
features that you pretty much need to do
corporate tracking overtime uses a bloom

398
00:27:53,260 --> 00:27:56,799
filter determine whether or not it's
likely that you already generated this

399
00:27:56,799 --> 00:28:02,500
things like that and then RP and those
guys out in Greece

400
00:28:02,500 --> 00:28:06,730
just recently a couple months ago
release something called corazon

401
00:28:06,730 --> 00:28:10,630
I'm not sure it's public or not yet he
sent us a copy to review its pretty cool

402
00:28:10,630 --> 00:28:16,270
it adds in pretty much all the features
that were good about AFL and honk was

403
00:28:16,270 --> 00:28:21,760
but he's also trying to bring back in
some data type awareness in a sense that

404
00:28:21,760 --> 00:28:26,590
he's isolated inputs into kind of
different buckets

405
00:28:26,590 --> 00:28:31,959
you know things that are chunks formats
like mp4 video files or things that

406
00:28:31,960 --> 00:28:35,919
might be container formats like Word
documents that were using structured

407
00:28:35,919 --> 00:28:41,470
storage or you know xml-based compressed
files that are actually a series of

408
00:28:41,470 --> 00:28:43,000
inputs below that

409
00:28:43,000 --> 00:28:48,010
so essentially allows you to create a
higher level container data definition

410
00:28:48,010 --> 00:28:53,379
and then tear it apart and then do all
the good fuzzing underneath and some

411
00:28:53,380 --> 00:28:54,790
additional stuff with

412
00:28:54,790 --> 00:28:59,320
some of the type model you can get as
deep into that as you walk you write

413
00:28:59,320 --> 00:29:03,520
your own custom see réaliser function
that knows how to take it apart and then

414
00:29:03,520 --> 00:29:08,170
from there he manipulates the model
internally so it's one step towards

415
00:29:08,170 --> 00:29:12,100
being more specific about your data
which makes it more efficient in the

416
00:29:12,100 --> 00:29:16,060
long run a lot of formats if they have
compression or check sums or something

417
00:29:16,060 --> 00:29:20,050
like that you need to write special
hooks to fix that up anyways this all

418
00:29:20,050 --> 00:29:26,080
integrated into the system but the only
real problem with it is it's using a

419
00:29:26,080 --> 00:29:28,270
really really slow tracing engine again

420
00:29:28,270 --> 00:29:31,960
so that's kind of where I found
opportunity to you know work on this

421
00:29:31,960 --> 00:29:34,840
area and give away these tracer so
people can speed up there

422
00:29:34,840 --> 00:29:40,120
cool ideas a couple other honorable
mentions we won't talk about them at all

423
00:29:40,120 --> 00:29:46,300
in detail just simply you know your oxen
Koretz metal as is out there also

424
00:29:46,300 --> 00:29:47,379
working the same space

425
00:29:47,380 --> 00:29:51,010
he kind of took the duct tape approach
we're off the shell tracer is off the

426
00:29:51,010 --> 00:29:55,120
shelf mutators let's just you know throw
some Python glue in there together and

427
00:29:55,120 --> 00:29:57,699
hey I've got a tool

428
00:29:57,700 --> 00:30:01,390
you know you're not going to end up with
a well-engineered system that way and

429
00:30:01,390 --> 00:30:04,540
that's pretty much my evaluation it's
cool

430
00:30:04,540 --> 00:30:07,990
he wrote a web interface as well for its
kind of manage it i think that's the

431
00:30:07,990 --> 00:30:13,210
value-add there something like you know
what grinder Artie was putting out there

432
00:30:13,210 --> 00:30:18,850
but I'm i did actually look at the
causing current racer code plugin which

433
00:30:18,850 --> 00:30:24,280
was the pen tool that they use and that
also was written back before anybody

434
00:30:24,280 --> 00:30:29,080
really took a look at how to do things
performing Lee and then come fuzz if you

435
00:30:29,080 --> 00:30:33,939
are a fan of doing know Jas space stuff
is a similar real implementation of a

436
00:30:33,940 --> 00:30:38,200
coverage driven father using a San code
coverage feedback and so it's just easy

437
00:30:38,200 --> 00:30:40,810
to set up and also very very hackable

438
00:30:40,810 --> 00:30:44,260
so well after all that

439
00:30:44,800 --> 00:30:48,879
what do we get out of that what it was
the properties that are interesting and

440
00:30:48,880 --> 00:30:52,870
things that we want to survive the next
evolution of other creation

441
00:30:52,870 --> 00:30:56,560
well obviously we need fast racing
engine if you're doing code coverage

442
00:30:56,560 --> 00:31:00,520
drive German fuzzing then we need to be
trying to get the fastest code coverage

443
00:31:00,520 --> 00:31:01,810
engine possible

444
00:31:01,810 --> 00:31:05,500
that's accurate and we need to come up
with algorithms to track it over time

445
00:31:05,500 --> 00:31:06,490
right

446
00:31:06,490 --> 00:31:06,940
so

447
00:31:06,940 --> 00:31:11,890
with the logging functionality has often
been overlooked as a really key point in

448
00:31:11,890 --> 00:31:15,820
doing efficient racing and Intel
themselves has recognized this and

449
00:31:15,820 --> 00:31:20,649
that's one of the reasons that the new
cpu supported Intel PT is so awesome is

450
00:31:20,650 --> 00:31:24,610
they actually created a very very
lightweight base logging mechanism which

451
00:31:24,610 --> 00:31:29,860
makes it way faster and then also on top
of that we don't want to get overly

452
00:31:29,860 --> 00:31:31,689
complicated with evolutionary algorithm

453
00:31:31,690 --> 00:31:36,040
what we're using now the lightweight
stuff works so why change it was not

454
00:31:36,040 --> 00:31:40,690
pollute the simplicity of design and if
we can get portable systems that are

455
00:31:40,690 --> 00:31:43,630
easy to use with extra helper tools like
somebody's come with

456
00:31:43,630 --> 00:31:48,070
that's cool if not you can I just borrow
them from those code bases and reuse

457
00:31:48,070 --> 00:31:48,550
them

458
00:31:48,550 --> 00:31:52,480
my recommendation is if you're going to
be writing your own system from scratch

459
00:31:52,480 --> 00:31:59,470
or want to use something that's a good
basis to develop on top of Hong fuzz was

460
00:31:59,470 --> 00:32:03,130
probably my highly recommended approach
if you just want to go for something

461
00:32:03,130 --> 00:32:03,700
today

462
00:32:03,700 --> 00:32:09,820
use AFL that hands down it found shell
shocked if found so many bugs after the

463
00:32:09,820 --> 00:32:15,129
facts but I like there's hundreds of
bugs attributed to AFL anna boch is

464
00:32:15,130 --> 00:32:20,140
pretty much writing this whole buzzing
system around the AFL it seems but bit

465
00:32:20,140 --> 00:32:21,970
shaken out bugs everywhere it's really
good

466
00:32:21,970 --> 00:32:26,320
free bugs essentially all right so
binary translation

467
00:32:26,320 --> 00:32:32,320
this is a hold of this section
essentially the idea is that you have a

468
00:32:32,320 --> 00:32:38,379
jet engine for your native instruction
set architecture right so you have x86

469
00:32:38,380 --> 00:32:42,970
to x86 shit and it knows how to
disassemble a new data flow analysis all

470
00:32:42,970 --> 00:32:49,360
the internal compiler types of logic
that you would expect but it's targeting

471
00:32:49,360 --> 00:32:54,100
binaries and it's allowing you to
interleave your own instructions in into

472
00:32:54,100 --> 00:32:59,320
the cached and optimized version of the
binary so the general idea is real

473
00:32:59,320 --> 00:33:00,100
simple

474
00:33:00,100 --> 00:33:04,540
you hook the execution of a program
through a custom loader that replaces

475
00:33:04,540 --> 00:33:10,360
the LDS Oh on linux or windows and
essentially it performs all the runtime

476
00:33:10,360 --> 00:33:15,070
linking and loading of your dependents
libraries and instead of executing

477
00:33:15,070 --> 00:33:16,179
immediately

478
00:33:16,180 --> 00:33:18,580
it loads each individual functions

479
00:33:18,580 --> 00:33:22,870
into a code cache or depending on what
Modi rented but generally speaking what

480
00:33:22,870 --> 00:33:26,830
they do is they find the entry point
start executing at every branch if it's

481
00:33:26,830 --> 00:33:28,059
a new block

482
00:33:28,059 --> 00:33:31,600
they then bring it into a code cache to
make a copy of it and at that point in

483
00:33:31,600 --> 00:33:36,189
time they allow you to modify the code
in its cash from then on every execution

484
00:33:36,190 --> 00:33:41,679
of that basic block will be from the
code cache and it keeps a read-only

485
00:33:41,679 --> 00:33:47,019
memory mapping of the original binary
for any static data references or things

486
00:33:47,019 --> 00:33:51,010
like that so you don't have any
stability problems or any issues with

487
00:33:51,010 --> 00:33:55,750
the traditional x86 is it data is a code
and you just assembly because that

488
00:33:55,750 --> 00:34:00,039
runtime is able to discover where the
new code is and it keeps the copy of

489
00:34:00,039 --> 00:34:04,600
anything that's needs to be there for
the future so very robust it works very

490
00:34:04,600 --> 00:34:05,199
well

491
00:34:05,200 --> 00:34:09,609
works on depending on the engine of
choice it works on arm it works on x86

492
00:34:09,609 --> 00:34:10,779
that works

493
00:34:10,780 --> 00:34:14,020
you know that a lot of these were
developed back in commercial unix days

494
00:34:14,020 --> 00:34:15,099
so it works

495
00:34:15,099 --> 00:34:18,879
some of these engines go back to working
on spark in each box and things like

496
00:34:18,879 --> 00:34:24,489
that but generally what we care about is
that it allows you to do highly granular

497
00:34:24,489 --> 00:34:28,868
instrumentation previous work that we
did we actually did all the way down to

498
00:34:28,869 --> 00:34:32,919
instruction level instrumentation to
track data flow in this particular case

499
00:34:32,918 --> 00:34:38,799
we only need to do block-based
instrumentation so one just side note

500
00:34:38,800 --> 00:34:43,210
here is the there's a lot of schoolwork
still going on in the software TDI

501
00:34:43,210 --> 00:34:44,230
engines

502
00:34:44,230 --> 00:34:48,820
vmware in particular is continually
doing more work there

503
00:34:48,820 --> 00:34:54,399
they bought dynamo Rio but through via
the purchase of determining actually

504
00:34:54,399 --> 00:34:57,819
determine was a company that did in
memory

505
00:34:58,599 --> 00:35:03,430
anti exploit technology essentially
using the demo reel injun the guys that

506
00:35:03,430 --> 00:35:07,990
were at MIT Lincoln labs wrote dynamo
rios an extension on top of a HP

507
00:35:07,990 --> 00:35:15,848
platform and they brought it to x86
architecture and essentially developed

508
00:35:15,849 --> 00:35:19,900
to the point where it was capable of
being the basic infrastructure for a

509
00:35:19,900 --> 00:35:24,760
commercial product and then later on
vmware bought them and ended up open

510
00:35:24,760 --> 00:35:27,849
sourcing dynamo Rio and the long run as
a bsd license which is pretty awesome

511
00:35:28,680 --> 00:35:32,910
so anyways the well as we talk about
these different TDI engines

512
00:35:32,910 --> 00:35:36,598
usually the question comes up you know y
is 1 10 times faster than another

513
00:35:36,599 --> 00:35:40,770
they're performing essentially the same
thing and all that has to do with how

514
00:35:40,770 --> 00:35:44,130
they perform how they linked the basic
blocks together in memory

515
00:35:44,130 --> 00:35:48,450
they create these traces that are hot
flows of code because these are designed

516
00:35:48,450 --> 00:35:53,910
to do optimization at their core but at
a higher level optimization typically

517
00:35:53,910 --> 00:35:57,899
it's typically like groups of functions
that need to be optimized and you know

518
00:35:57,900 --> 00:36:01,740
access more frequently as opposed to
block level stuff for instruction level

519
00:36:01,740 --> 00:36:06,118
but yeah the main advantages it works
everywhere

520
00:36:06,119 --> 00:36:10,559
essentially if you get the right kit can
be faster and it is faster than most of

521
00:36:10,559 --> 00:36:13,950
the hardware tracing engines that are
were available up until two years ago

522
00:36:13,950 --> 00:36:19,710
and it's easier in a way the sense you
can also do you're hooking engine

523
00:36:19,710 --> 00:36:23,550
directly in the DPI engine

524
00:36:23,550 --> 00:36:27,569
you don't need to use other frameworks
for doing you're hooking so it's easier

525
00:36:27,569 --> 00:36:31,410
to do things like turning on and off
your trace based upon the code that you

526
00:36:31,410 --> 00:36:36,089
observe executing and things like that
so more dynamic things that you can

527
00:36:36,089 --> 00:36:39,390
still do with other engines but it takes
more work

528
00:36:39,390 --> 00:36:42,509
the main disadvantage is by design

529
00:36:42,510 --> 00:36:47,190
this introduces a new context switch
into your software architecture

530
00:36:47,190 --> 00:36:51,240
so normally context which is occur when
you execute system calls and what has to

531
00:36:51,240 --> 00:36:55,500
happen is the cpu need to store all
flags and registers to memory and then

532
00:36:55,500 --> 00:36:58,200
go ahead and switch over into criminal
context

533
00:36:58,200 --> 00:37:02,308
well this adds a layer because the
broker the translation engine itself is

534
00:37:02,309 --> 00:37:07,319
another context layer so it has its own
execution state over here that's the one

535
00:37:07,319 --> 00:37:11,730
that's loading code into its cash and
your program has its execution state

536
00:37:11,730 --> 00:37:15,599
that's actually executing the cash
because of that you get a new contacts

537
00:37:15,599 --> 00:37:20,760
which and context switches are expensive
due to non code locality right so when

538
00:37:20,760 --> 00:37:26,849
your cpu load memory into its l three RL
two buffers essentially those are of a

539
00:37:26,849 --> 00:37:30,150
limited size so if you start executing
code somewhere else completely different

540
00:37:30,150 --> 00:37:35,190
memory invalidates all the cached
translate like memory translation and so

541
00:37:35,190 --> 00:37:38,280
if that's where a lot of the overhead
comes from

542
00:37:40,010 --> 00:37:42,920
the only other thing is that each one of
these also has to have their own

543
00:37:42,920 --> 00:37:47,300
disassemblers built in so unlike a
hardware-based engine where it's

544
00:37:47,300 --> 00:37:51,830
natively in the dye of the cpu in this
case you're relying a lot on their

545
00:37:51,830 --> 00:37:56,270
ability to decode the same instructions
so this isn't such a big deal and

546
00:37:56,270 --> 00:38:02,210
compiler oriented things it can be if
you like use the ICC compiler and turn

547
00:38:02,210 --> 00:38:06,320
on all their heavy optimizations and
that emits code that maybe dynamo Rio or

548
00:38:06,320 --> 00:38:12,140
pin the hasn't tweet hasn't been updated
with your pretty stable pen because that

549
00:38:12,140 --> 00:38:17,210
is developed by Intel it uses the said
decompiler so you're if you need a

550
00:38:17,210 --> 00:38:20,990
software-based and as close to
instruction support as possible then you

551
00:38:20,990 --> 00:38:24,890
would use that demo reel supports just
about everything you can imagine but

552
00:38:24,890 --> 00:38:27,410
there's academic work on doing

553
00:38:27,410 --> 00:38:32,270
compatibility testing across
disassemblers and it's in general shown

554
00:38:32,270 --> 00:38:36,500
that you know not all of them have a
hundred percent compatibility so you may

555
00:38:36,500 --> 00:38:41,060
or may not have instruction support for
certain features of the ice ax and if

556
00:38:41,060 --> 00:38:44,750
you're up against some malicious code
that's aware of that they can use that

557
00:38:44,750 --> 00:38:52,310
to do detection or possibly break out of
your monitored process but another but

558
00:38:52,310 --> 00:38:55,790
it's generally a really great tool to
use especially for doing things like

559
00:38:55,790 --> 00:39:00,080
security testing against you know clean
software that's not an actively

560
00:39:00,080 --> 00:39:05,420
defensive nature right so i'm not going
to bother saying much about vulgar

561
00:39:05,420 --> 00:39:07,250
entirety said what I wanted to

562
00:39:07,250 --> 00:39:11,870
it's just out there it's obligatory it's
accessible but I kind of wish people

563
00:39:11,870 --> 00:39:15,680
would stop writing stuff on top of it
because it's not portable and all that

564
00:39:15,680 --> 00:39:21,740
work needs to be re-implemented and also
don don mario has a dr memory tool which

565
00:39:21,740 --> 00:39:27,080
is essentially like the chase and crash
analyzer or being exploitable in a way

566
00:39:27,080 --> 00:39:32,960
one of alguns best features is that if
you run an X program crashed through it

567
00:39:32,960 --> 00:39:36,620
will give you a nice dump and tell you
you know this memory buffer was

568
00:39:36,620 --> 00:39:37,400
corrupted

569
00:39:37,400 --> 00:39:41,840
and all sorts of things like that so
that was one of the only reasons to use

570
00:39:41,840 --> 00:39:44,180
valgrind up until recently but now

571
00:39:44,180 --> 00:39:48,230
dr. memories cross-platform and it runs
twice as fast and does all the same

572
00:39:48,230 --> 00:39:55,490
stuff so i would recommend moving away
from valgrind let me get another raise

573
00:39:55,490 --> 00:40:00,439
of hands who is done any work with a DVI
is played with pen tools anything like

574
00:40:00,440 --> 00:40:01,040
that

575
00:40:01,040 --> 00:40:07,520
ok cool alright so a fair number of
people if you get into doing dynamic

576
00:40:07,520 --> 00:40:11,630
binary instrumentation pin is typically
the first tool kit you'll come across

577
00:40:11,630 --> 00:40:16,940
because it's getting some widespread
adoption it's easy to use it has high

578
00:40:16,940 --> 00:40:20,300
level API is that are really you know
fairly straightforward

579
00:40:20,870 --> 00:40:25,250
it's i have an example here in a second
but you know it takes like 10 lines of

580
00:40:25,250 --> 00:40:29,090
code to get up and running and doing
blox racing problem is that based upon

581
00:40:29,090 --> 00:40:30,200
their design

582
00:40:30,200 --> 00:40:33,589
you're not able to do things like if you
only want to hit trace

583
00:40:33,590 --> 00:40:36,440
you only want to observe whether or not
a block was executed you don't care

584
00:40:36,440 --> 00:40:39,440
about how many times where it came from
just that you hit that code

585
00:40:39,950 --> 00:40:45,049
you can't do that in because they don't
give you your hook until after that's

586
00:40:45,050 --> 00:40:46,670
already been built into a trace

587
00:40:46,670 --> 00:40:51,590
they loaded the code they've analyzed
the code they've put into these you know

588
00:40:51,590 --> 00:40:55,430
has that they know will get executed in
sequence and then they let you look at

589
00:40:55,430 --> 00:40:55,970
it

590
00:40:55,970 --> 00:40:59,180
the problem with that is that they're
optimizations happened before yours do

591
00:40:59,180 --> 00:41:02,660
and so they're not aware of any changes
that you might make the code and they

592
00:41:02,660 --> 00:41:07,190
can optimize it so it ends up being
quite a bit slower and also because they

593
00:41:07,190 --> 00:41:11,570
done the optimization early and they
don't give you like an intermediate

594
00:41:11,570 --> 00:41:17,210
language that is direct access to the
opcodes you're more or less limited to

595
00:41:17,210 --> 00:41:21,110
injecting trampolines at arbitrary
locations so that could be useful but

596
00:41:21,110 --> 00:41:23,780
once again code locality reasons

597
00:41:23,780 --> 00:41:28,520
oftentimes you'll be jumping somewhere
completely different memory and so you

598
00:41:28,520 --> 00:41:35,180
incur a large overhead in fact so here's
an example of you know how simple it is

599
00:41:35,180 --> 00:41:40,160
to get into this trace function is just
a callback you register call back at the

600
00:41:40,160 --> 00:41:40,799
beginning of

601
00:41:40,800 --> 00:41:45,900
your library and you say I want to see
every time you've created a trace

602
00:41:45,900 --> 00:41:49,770
traces are generated whenever a back
edge or indirect branch is taken okay

603
00:41:50,400 --> 00:41:54,000
and so you get to enter the trace then
you walk the basic blocks on the trace

604
00:41:54,000 --> 00:41:57,900
them for each basic block in this case
we're inserting a call back to analysis

605
00:41:57,900 --> 00:42:00,900
function that analysis function can do
whatever you want

606
00:42:01,620 --> 00:42:06,779
you know typically it would be something
to log base o'clock execution and let me

607
00:42:06,780 --> 00:42:09,810
pull up a little demo here I could just
show you interactively what kind of

608
00:42:09,810 --> 00:42:12,810
performance we're talking about

609
00:42:17,800 --> 00:42:24,760
right so get to play the game where I
don't get to see what i'm typing

610
00:42:25,330 --> 00:42:28,330
let me zoom in here first

611
00:42:39,180 --> 00:42:42,180
all rights so

612
00:42:46,220 --> 00:42:49,879
so as you can see i have several engines
here based upon <operand> twelve

613
00:42:49,880 --> 00:42:53,750
</operand> branch this store until
process of trays dine is how we doing on

614
00:42:53,750 --> 00:42:54,109
time

615
00:42:54,109 --> 00:42:57,980
ok alright so in pain and all that so
we'll do it in real quick

616
00:42:58,609 --> 00:43:10,220
basically what this demo does iterates
through about a hundred arbitrary PNG

617
00:43:10,220 --> 00:43:15,140
files using the PNG test program that
comes with the library and all I'm

618
00:43:15,140 --> 00:43:19,069
trying to demonstrate here is a visual
example of the performance

619
00:43:19,670 --> 00:43:24,109
obviously i started off with the slowest
one first pin while it can do tracing

620
00:43:24,109 --> 00:43:29,750
and this is all doing code coverage
based stuff it'll take roughly a minute

621
00:43:29,750 --> 00:43:35,660
or so to fully execute this and once
again the main reasons for that are the

622
00:43:35,660 --> 00:43:40,970
engine design that generates traces
based upon black edges and using some of

623
00:43:40,970 --> 00:43:46,368
the older literature and that their
approach to that and also because it's

624
00:43:46,369 --> 00:43:49,520
later on in the optimization phase you
get to your instrumentation

625
00:43:49,520 --> 00:43:53,210
I'm not even gonna bother letting it
finish I guess I'm really short on time

626
00:43:53,210 --> 00:43:58,190
so just the US and see that and then
we'll talk about <time> twelve </time>

627
00:43:58,190 --> 00:44:02,420
and flip back and you'll see the
difference between diamond rio and pin

628
00:44:02,420 --> 00:44:07,310
so basically I called Donna Maria the
connoisseur's binary but dynamic binary

629
00:44:07,310 --> 00:44:12,290
translation of the reasons are numerous
but primarily it's because you get to

630
00:44:12,290 --> 00:44:16,400
actually go down and synthesize
instructions directly into the program

631
00:44:16,400 --> 00:44:22,369
at arbitrary locations so instead of
that one function that that was like

632
00:44:22,369 --> 00:44:24,470
five lines to put your hook in there

633
00:44:24,470 --> 00:44:27,140
you got to do a little bit more work but
you can get down to the point where

634
00:44:27,140 --> 00:44:30,920
you're literally adding an arbitrary
assembly instructions anywhere you want

635
00:44:30,920 --> 00:44:34,580
you can do live in this analysis on your
flags and registers to make sure that

636
00:44:34,580 --> 00:44:38,509
you're not traveling on anything else I
mean it's as deep as you want to get

637
00:44:38,510 --> 00:44:43,849
into the weeds and basically do runtime
assembly injection dineymarie is the way

638
00:44:43,849 --> 00:44:45,109
to go

639
00:44:45,109 --> 00:44:49,790
I'll i would say beyond what I've
already said is essentially it's also

640
00:44:49,790 --> 00:44:53,630
portable it's actively developed all the
time its and get hubs bsd license you

641
00:44:53,630 --> 00:44:54,890
can ship it yourself

642
00:44:54,890 --> 00:44:58,819
pen is a commercial license you can't
ship it with your code

643
00:44:58,820 --> 00:45:02,720
it's closed source has a lot of reasons
that's not great to use other than the

644
00:45:02,720 --> 00:45:05,060
only thing he has going for it is high
level API

645
00:45:05,060 --> 00:45:10,670
daniel has all the other good stuff it
also has in the doctor memory

646
00:45:10,670 --> 00:45:13,790
they're trying to isolate this out and
this is really promising for the future

647
00:45:13,790 --> 00:45:17,450
they have a shadow memory system which
is very important for doing data flow

648
00:45:17,450 --> 00:45:21,740
tracking and so if you want to build
advanced tools advanced crash analyzers

649
00:45:21,740 --> 00:45:24,350
all that framework is already there

650
00:45:24,350 --> 00:45:29,180
it's really tightly integrated into the
dr memory toolkit right now so you want

651
00:45:29,180 --> 00:45:33,620
to modify that but they're working to
bring that outside and make it more of a

652
00:45:33,620 --> 00:45:37,580
library you can build standalone tools
as well the usage model for dynamo Rio

653
00:45:37,580 --> 00:45:43,069
has all kinds of different up ways of
operating there's just a lot to say a

654
00:45:43,070 --> 00:45:47,210
whole talk on security focus tools for
Don Mario is probably in the future for

655
00:45:47,210 --> 00:45:52,400
me because it's it's just really cool
but to give an example it is quite a bit

656
00:45:52,400 --> 00:45:53,390
more complicated

657
00:45:53,390 --> 00:45:57,560
I left the instruction or the comments
on this one so it's not as dense but

658
00:45:57,560 --> 00:46:01,970
basically as you can see here when the
basic block is first seen from the

659
00:46:01,970 --> 00:46:06,049
program you're able to instrument it
before it's stored in the cache and so

660
00:46:06,050 --> 00:46:09,680
you can get down to the point of
actually modifying each individual

661
00:46:09,680 --> 00:46:10,910
instruction

662
00:46:10,910 --> 00:46:15,589
it has multiple faces similar to a
compiler so depending on the phase of

663
00:46:15,590 --> 00:46:18,830
optimization that you want to hook in
you get different levels of

664
00:46:18,830 --> 00:46:26,540
instrumentation ability and it's not all
that complicated but as you can see here

665
00:46:26,540 --> 00:46:30,860
I'm having to save the arithmetic flags
because i'm going to inject the

666
00:46:30,860 --> 00:46:34,250
increments instruction which will
manipulate the flags if you get an

667
00:46:34,250 --> 00:46:38,120
overflow and then you know it actually

668
00:46:38,120 --> 00:46:41,930
yeah each individual operand you have to
convert and tell it how to generate and

669
00:46:41,930 --> 00:46:46,700
things like that but if you want to go
through the work you can get as deep and

670
00:46:46,700 --> 00:46:52,669
injectable code is you want and there's
about twenty percent execution runtime

671
00:46:52,670 --> 00:46:55,460
overhead for dynamo Rio without any
instrumentation

672
00:46:55,460 --> 00:46:58,670
but if you write your tools

673
00:46:58,670 --> 00:47:03,050
well and actually go through the effort
very little overhead has incurred on top

674
00:47:03,050 --> 00:47:06,920
of that base twenty percent so you can
write very efficient tools and i'll give

675
00:47:06,920 --> 00:47:09,110
you an example of that

676
00:47:09,110 --> 00:47:22,880
and just visually you can see that this
plug-in is doing the exact same thing

677
00:47:22,880 --> 00:47:24,680
and it's just skimming through it

678
00:47:24,680 --> 00:47:27,680
the other one was going to take over a
minute and should I believe have the

679
00:47:27,680 --> 00:47:29,450
output a time at the bottom here

680
00:47:29,450 --> 00:47:34,370
the end of the day that takes 11 seconds
so this is a six to eight times speed

681
00:47:34,370 --> 00:47:37,520
increase just right off the top without
doing a lot of extra work

682
00:47:37,520 --> 00:47:41,360
that's using the function that I just
showed you so using the right engine

683
00:47:41,360 --> 00:47:45,350
doing a little extra work up front and
you're saving yourself you know hundreds

684
00:47:45,350 --> 00:47:50,180
or thousands of hours in the future of
your planning executing and getting more

685
00:47:50,180 --> 00:47:54,859
money more bang for your buck out of
your hardware and then

686
00:47:55,490 --> 00:47:58,910
sorry I'm hoping I don't go over on time
we've got a few more things to cover

687
00:47:58,910 --> 00:48:07,549
dynasty is a really huge like developed
over time across two universities and

688
00:48:07,550 --> 00:48:10,910
using the government kind of platform
which is never a good sign

689
00:48:10,910 --> 00:48:14,839
the cool thing about dinosaurs actually
that part Miller the guy that invented

690
00:48:14,840 --> 00:48:19,340
the coin the term fuzzing back in 91 and
the whole story about electricity

691
00:48:19,340 --> 00:48:25,220
through with a pile of line causing an
input to be modified as terminal then do

692
00:48:25,220 --> 00:48:29,419
eunuchs crashes whatever the hell that
get that guy is a professor at

693
00:48:29,420 --> 00:48:35,360
university of wisconsin and he runs a
basically security in binary team over

694
00:48:35,360 --> 00:48:39,470
there and he and the University a
mission

695
00:48:39,470 --> 00:48:42,680
maryland I think are the other guys
working on the engine together

696
00:48:42,680 --> 00:48:48,830
it's super fast it's awesome if you can
use it use it uh it right now works

697
00:48:48,830 --> 00:48:52,960
really well on you know boo - 14 and

698
00:48:52,960 --> 00:48:57,369
if you get the compile situation figured
out just right you have to sell compile

699
00:48:57,369 --> 00:49:01,180
certain things and use the OS provided
libraries for certain things and if you

700
00:49:01,180 --> 00:49:06,279
don't get the right recipe you're fucked
but but - when it does work it's as fast

701
00:49:06,280 --> 00:49:11,560
as it's going to get its it statically
rights to disk so all of the problem

702
00:49:11,560 --> 00:49:15,369
code locality go out the window there is
no separate cash there's no separate

703
00:49:15,369 --> 00:49:21,310
code contacts which occurred so we have
a tool that we release last year already

704
00:49:21,310 --> 00:49:27,460
for AFL called AFL dynast and it allows
you to basically modify commercial

705
00:49:27,460 --> 00:49:32,589
libraries off-the-shelf stuff you know
enterprise-grade software instrument

706
00:49:32,589 --> 00:49:37,839
them using this and use AFL all the good
engineering and that engine to buzz

707
00:49:37,839 --> 00:49:44,680
tests like software that matters so it's
a great tool use it if you can I have a

708
00:49:44,680 --> 00:49:49,990
docker image or dr. config file up on
our github as well as part of the AFL

709
00:49:49,990 --> 00:49:52,899
dynast if you want to skip all the
headache of figuring out how to get it

710
00:49:52,900 --> 00:49:56,859
run yourself just use that or you know
copied instructions out on your local

711
00:49:56,859 --> 00:49:58,210
host whatever

712
00:49:58,210 --> 00:50:03,550
the other thing i will say so we really
really really really badly want this to

713
00:50:03,550 --> 00:50:08,560
work on windows so bad that we went in
and we wrote support for PE locations

714
00:50:08,560 --> 00:50:12,099
and some patches a year ago over a year
ago

715
00:50:13,580 --> 00:50:18,440
and had some good conversations but they
are slow is held to like no effort

716
00:50:18,440 --> 00:50:21,500
trying to get this to run on windows
it's like it's like when you know that

717
00:50:21,500 --> 00:50:24,680
there's this thing in here that just
needs just a little bit of work and it's

718
00:50:24,680 --> 00:50:28,100
such a complicated system that reverse
engineering it and trying to fix all the

719
00:50:28,100 --> 00:50:32,630
gotchas that eventually build up over
time you're building a production grade

720
00:50:32,630 --> 00:50:33,530
system like this

721
00:50:33,530 --> 00:50:40,040
there's all kinds of lino case edge case
scenarios but hopefully it does it can

722
00:50:40,040 --> 00:50:43,880
work on windows in a dynamic mode as
opposed to static rewriting but you lose

723
00:50:43,880 --> 00:50:46,340
all the benefits and it can only do

724
00:50:46,340 --> 00:50:49,340
trampoline injection so use on a memory
of if your going to do dynamic

725
00:50:51,050 --> 00:50:58,520
yeah so here's actually our code that we
use in the AFL compatible a plugin for

726
00:50:58,520 --> 00:51:04,070
financed at it also has kind of a you
know Annoying API it's a little higher

727
00:51:04,070 --> 00:51:08,210
level but it doesn't get you anything
extra so you gotta do work like walk to

728
00:51:08,210 --> 00:51:11,210
the control flow graph yourself through
iterators it's not a big deal

729
00:51:11,990 --> 00:51:16,250
yeah i mean these are all pretty easy to
use really for what you get out of it

730
00:51:17,570 --> 00:51:21,290
you can tune binary translation
basically by only instrument indirect

731
00:51:21,290 --> 00:51:25,460
branches waiting until your input seen
there's all kinds of ways you know make

732
00:51:25,460 --> 00:51:30,230
sure you only instrument the threads
that are actually parsing the data

733
00:51:30,230 --> 00:51:34,460
there's lots of ways to apply this to
more you know heavyweight software in

734
00:51:34,460 --> 00:51:41,870
the end way which I had 20 more minutes
so basically i'm going to skip through

735
00:51:41,870 --> 00:51:45,259
the old-school hardware stuff it doesn't
really matter if you're going to do

736
00:51:45,260 --> 00:51:49,250
hardware tracing you need to learn how
to do program interrupts that's the

737
00:51:49,250 --> 00:51:52,160
lowest level stuff and let me tell you
if you're doing it on windows these days

738
00:51:52,160 --> 00:51:55,670
it's a real pain in the ass because of
all the patch guarded anti-rootkit

739
00:51:55,670 --> 00:51:59,690
technologies doing low-level programming
on the linux kernel is still easy and

740
00:51:59,690 --> 00:52:05,690
fun it's a joy doing on Windows is just
a horrible but you you know you might be

741
00:52:05,690 --> 00:52:09,050
familiar with interrupts already
obviously using try catch at a higher

742
00:52:09,050 --> 00:52:12,350
level but at the lower level doing
single steps or if you're into demo

743
00:52:12,350 --> 00:52:15,350
scene stuff that's how they wrote to the
monitor

744
00:52:16,100 --> 00:52:18,230
you know there's all kinds of stuff and

745
00:52:18,230 --> 00:52:22,280
but I want to get to Intel PT

746
00:52:22,910 --> 00:52:26,569
so basically when you program a cpu and
you're doing this low-level programming

747
00:52:26,570 --> 00:52:30,710
there's a whole series of instructions
not normally accessible to you in user

748
00:52:30,710 --> 00:52:33,619
mode for standard application
programming and these are the model

749
00:52:33,619 --> 00:52:38,330
specific registers or msrs and what they
allow you to do is put the cpu into

750
00:52:38,330 --> 00:52:42,529
special operating modes and including
some of these tracing functions it's

751
00:52:42,530 --> 00:52:49,190
also how you would do things like set up
SMS memory or you know enable anything

752
00:52:49,190 --> 00:52:52,820
in the PM you pro anything that's on
core that is not part of your typical

753
00:52:52,820 --> 00:52:58,820
operation of the cpu those are
configured through ms our registers and

754
00:52:58,820 --> 00:53:01,490
they're called model-specific because
they change over time and they add

755
00:53:01,490 --> 00:53:07,160
features to the architectures that
evolved and so things like that and so

756
00:53:07,160 --> 00:53:11,180
one of those things with the branched
restore that was the best tech until

757
00:53:11,180 --> 00:53:16,759
Intel PT and as you can see this is all
actually happens right in the pipe cpu

758
00:53:16,760 --> 00:53:21,710
pipeline itself so in this case the
instructions are being loaded for memory

759
00:53:21,710 --> 00:53:26,900
and pushed into the cpu pipeline in the
case of branches if you flip one flag in

760
00:53:26,900 --> 00:53:29,900
these MSR structures over here

761
00:53:30,859 --> 00:53:35,480
you know you can turn on LOL BRB TS or
whatever and what ends up happening here

762
00:53:35,480 --> 00:53:41,900
is that you load x 1 d 9 into your eax
register you load some other registers

763
00:53:41,900 --> 00:53:45,140
with some flags and whatnot the or a
structure that you . -

764
00:53:45,140 --> 00:53:50,690
and then you simply execute MSR right
which is a privileged instruction and

765
00:53:50,690 --> 00:53:55,070
that will rights to that specific
register essentially the configuration

766
00:53:55,070 --> 00:53:59,030
you're looking for if you do it all
right then essentially you can turn on

767
00:53:59,030 --> 00:54:00,200
lb our first

768
00:54:00,200 --> 00:54:03,439
this is actually 64 reserved registers
that you normally don't get to touch

769
00:54:03,440 --> 00:54:07,190
there there there as fast as normal
register access so it's pretty much a

770
00:54:07,190 --> 00:54:09,200
free Tracy mechanism

771
00:54:09,200 --> 00:54:13,819
it can only do 60 for branches though so
at the time of that filling up

772
00:54:13,820 --> 00:54:17,960
normally it would just do a ring buffer
if you have BTS enabled instead it will

773
00:54:17,960 --> 00:54:23,930
fire interrupt and write that out to ram
but it's using an older mechanism that's

774
00:54:23,930 --> 00:54:25,609
not in the die

775
00:54:25,609 --> 00:54:29,480
a well it doesn't bypass the MMU so it's
quite slow

776
00:54:29,480 --> 00:54:36,049
so intel processor trace this is the the
good stuff

777
00:54:36,049 --> 00:54:40,160
uh essentially what we're looking at is
a new processor feature that lets you do

778
00:54:40,160 --> 00:54:45,410
full system tracing for five to fifty
percent overhead for recording this is

779
00:54:45,410 --> 00:54:50,989
by far the fastest racing system has
ever been developed its and it works now

780
00:54:50,989 --> 00:54:55,549
it's been out for about a year and a
half it supported by Intel system studio

781
00:54:55,549 --> 00:55:00,170
if you get the right formula once again
i think its windows 8.1 and sky like a

782
00:55:00,170 --> 00:55:06,380
certain models linux / subsystem since
4.1 has also exposed this

783
00:55:06,380 --> 00:55:09,950
these features so all I gotta do is
execute on the command line I've got it

784
00:55:09,950 --> 00:55:13,759
here in a second to enable the feature
do whatever business you want to do

785
00:55:13,759 --> 00:55:16,999
stop the log then I'll write it up the
disc and you can post process it

786
00:55:18,319 --> 00:55:25,999
the the tracer itself is kind of like
bring three because it has observability

787
00:55:25,999 --> 00:55:31,669
over everything happening in sm m in
hypervisors in your kernel in userspace

788
00:55:31,670 --> 00:55:37,279
the whole range of code protection level
or operating level of your CPU so it

789
00:55:37,279 --> 00:55:41,869
while currently doesn't have the ability
to stop and interrupt this is a passive

790
00:55:41,869 --> 00:55:47,329
monitor the at the moment it is in the
space where it's undetectable by the

791
00:55:47,329 --> 00:55:51,259
higher layers so you could write a
hypervisor for example that would make

792
00:55:51,259 --> 00:55:55,430
it impossible for a colonel to ever be
able to detect that this is enabled

793
00:55:55,940 --> 00:56:00,410
so if you're looking at doing tracing
applied to malware analysis

794
00:56:00,410 --> 00:56:04,220
that's where the hardware traces are
really important because at the end of

795
00:56:04,220 --> 00:56:07,700
the day there's always going to be
artifacts that that software layer of

796
00:56:07,700 --> 00:56:12,379
translation for hooking that is going to
be detectable in this case you're at a

797
00:56:12,380 --> 00:56:17,059
low enough level that it's and it's
outside the MMU so there's no way to

798
00:56:17,059 --> 00:56:21,259
detect cache poisoning or anything else
occurring when you can lock it down

799
00:56:21,259 --> 00:56:22,819
because you're that low level

800
00:56:22,819 --> 00:56:27,920
it's the only mechanism that can be used
to do sm tracing for example and then

801
00:56:27,920 --> 00:56:30,890
the other big thing they brought to the
table so they bypass the

802
00:56:30,890 --> 00:56:35,569
the caches and the MMU super important

803
00:56:35,569 --> 00:56:41,900
no but no address translation impact and
then they also created a heavily

804
00:56:41,900 --> 00:56:48,289
optimized log format and this is also in
broad well it wasn't supported in

805
00:56:48,289 --> 00:56:53,180
virtualization mode p.m. but it is now
supported and skylights so you can

806
00:56:53,180 --> 00:56:59,328
essentially do filtering based upon cr3
which holds your the pde the pointer to

807
00:56:59,329 --> 00:57:04,369
the page tables and essentially you can
say that i only want to trace things

808
00:57:04,369 --> 00:57:07,369
that are operating on this virtual
machine or that's how you can filter it

809
00:57:07,369 --> 00:57:11,390
out and figure out which mode to trace
and you can also filter based upon the

810
00:57:11,390 --> 00:57:14,868
CPL level so if you only want to trace
kernel space or only one of Tracy's user

811
00:57:14,869 --> 00:57:16,670
space you can do that

812
00:57:16,670 --> 00:57:20,630
the format itself is kind of a bitch

813
00:57:20,630 --> 00:57:26,390
there's taken not so essentially for to
reduce the amount of space they they can

814
00:57:26,390 --> 00:57:31,700
do about i think they said like one bite
her branch and total that's on average

815
00:57:31,700 --> 00:57:37,220
they do one bit per branch if it's a
conditional branch they do a if it's a

816
00:57:37,220 --> 00:57:41,240
indirect branch and they record the
destination address and then they have

817
00:57:41,240 --> 00:57:44,959
other things like you know interrupts
that are accessible the log or timing

818
00:57:44,960 --> 00:57:47,059
information things like that

819
00:57:47,059 --> 00:57:50,180
it's a pretty gnarly format but
fortunately there is an open-source

820
00:57:50,180 --> 00:57:55,308
cross-platform library available from
intel on github and it's called ipt

821
00:57:55,309 --> 00:57:58,579
which is pretty crucial

822
00:57:58,579 --> 00:58:03,049
uh and there's also a standalone kernal
library that's separate from the /

823
00:58:03,049 --> 00:58:03,920
subsystem

824
00:58:03,920 --> 00:58:08,960
it's a lot easier to understand and read
if you want to do your own manipulation

825
00:58:08,960 --> 00:58:14,089
of the API because it's 90 pages of sort
of of Intel Developer manuals and the

826
00:58:14,089 --> 00:58:16,940
you know if you look at those manuals
it's just like page after page of

827
00:58:16,940 --> 00:58:19,640
different flags you can set different
operating modes and if you're in

828
00:58:19,640 --> 00:58:22,970
hypervisor if you're in this and that
it's sucks

829
00:58:22,970 --> 00:58:26,359
so writing your own driver believe me
it's not fun

830
00:58:26,359 --> 00:58:32,960
the general way to use it is essentially
to enable it in the cpu each core has

831
00:58:32,960 --> 00:58:33,950
its own

832
00:58:33,950 --> 00:58:39,950
lpt operating mode in cash so you
essentially need to be in ring 0 or

833
00:58:39,950 --> 00:58:41,770
below in order to an a

834
00:58:41,770 --> 00:58:46,030
this stuff because the requirement for
ms our programming you enabled on your

835
00:58:46,030 --> 00:58:50,350
CPU itself all the stuff happens in the
compressed log off line

836
00:58:50,350 --> 00:58:56,680
the log itself actually can't really be
used intelligently without knowing

837
00:58:56,680 --> 00:59:00,549
something about the processing state
when it was being recorded meeting you

838
00:59:00,550 --> 00:59:03,940
need the memory maps and you need the
original binaries in order to decode the

839
00:59:03,940 --> 00:59:05,620
logs into something useful

840
00:59:05,620 --> 00:59:10,450
it really creates that process space and
then parses a log over top of it for our

841
00:59:10,450 --> 00:59:13,210
function and fuzzy and things like that

842
00:59:13,210 --> 00:59:17,110
the reason this is important is it comes
into how you do your design of the

843
00:59:17,110 --> 00:59:18,070
coating log

844
00:59:18,070 --> 00:59:23,230
you need to do it before you exit the
program obviously and also right now I'm

845
00:59:23,230 --> 00:59:27,580
trying to figure out if it's better to
take an entire core and pin that to

846
00:59:27,580 --> 00:59:33,340
doing trying to do near real-time
decoding versus doing a phased and

847
00:59:33,340 --> 00:59:37,480
execute get a lot of the compressed log
back and then decoded but i have a live

848
00:59:37,480 --> 00:59:38,830
demo that in a second

849
00:59:38,830 --> 00:59:44,350
here's how you can use it like right now
off of the / subsystem it's really easy

850
00:59:44,350 --> 00:59:48,640
to access and there's a few tools that
come with perfect let you do things like

851
00:59:48,640 --> 00:59:49,480
you know

852
00:59:49,480 --> 00:59:55,930
visualize your call graph tree or you
know gather stats along those lines and

853
00:59:55,930 --> 01:00:00,759
then also the simple PT kernel module
which is what i use also comes with

854
01:00:00,760 --> 01:00:06,670
standalone tool just spt command and
execute whatever you want and then that

855
01:00:06,670 --> 01:00:10,360
writes out a side band file which is
your memory map information necessary to

856
01:00:10,360 --> 01:00:14,410
coat it as well as the log files
themselves and then you can of course

857
01:00:14,410 --> 01:00:16,960
printed out like this and see your call
graphs of the wall

858
01:00:16,960 --> 01:00:21,340
all right real quick let me get a demo
the AFL's what I've been working hard on

859
01:00:26,260 --> 01:00:38,890
excuse the poor typing here so yeah I've
implemented this in Hong photos as well

860
01:00:38,890 --> 01:00:39,879
as a FL

861
01:00:39,880 --> 01:00:42,760
just because of time constraints i'm
going to just show you the AFL one

862
01:00:42,760 --> 01:00:45,760
because that's kind of the decor

863
01:00:51,430 --> 01:00:57,790
sorry i was trying to get some i can
copy and paste I don't have to do all

864
01:00:57,790 --> 01:01:00,790
this typing off

865
01:01:03,970 --> 01:01:07,868
so basically i added a flag to FL

866
01:01:08,650 --> 01:01:12,849
its capital p that will do the process
of tracing where is my mouth

867
01:01:21,780 --> 01:01:26,280
yeah

868
01:01:26,280 --> 01:01:34,350
yeah

869
01:01:35,970 --> 01:01:42,270
so this is actually on something that's
really quick

870
01:01:42,270 --> 01:01:46,200
it's not using PNG test that we saw
earlier this is using a custom rapper i

871
01:01:46,200 --> 01:01:49,200
wrote for lip Eng that essentially

872
01:01:59,400 --> 01:02:04,740
yeah

873
01:02:06,490 --> 01:02:21,819
I need to run as root because because
Intel PT mode requires root privileges

874
01:02:21,820 --> 01:02:27,730
basically so this is one of those things
where AFL's letting me know that if i

875
01:02:27,730 --> 01:02:35,260
run without disabling the core pattern
here then going to will try to snag my

876
01:02:35,260 --> 01:02:38,260
crashes from me and we don't want that
to happen right

877
01:02:40,000 --> 01:02:49,360
ok let's try that one last time
hopefully this will do the trick and

878
01:02:49,360 --> 01:02:51,700
felt won't yell at me again

879
01:02:51,700 --> 01:02:57,339
of course it does very sorry about this
i should have had this already set up

880
01:03:05,150 --> 01:03:21,260
so what this is doing is telling the cpu
scaling to disable an NFL course wants

881
01:03:21,260 --> 01:03:24,260
to get all your cpu power

882
01:03:24,799 --> 01:03:27,799
Jesus

883
01:03:31,269 --> 01:03:42,339
yeah

884
01:03:47,690 --> 01:03:50,690
am I not root the root

885
01:04:02,470 --> 01:04:04,200
that's the problem

886
01:04:04,200 --> 01:04:12,480
I think that works here we go

887
01:04:12,990 --> 01:04:17,399
so what we're about to see is that of
course there's some set of bullshit that

888
01:04:17,400 --> 01:04:21,390
needs to be fixed but here's a FL
running using the Intel PT hardware

889
01:04:21,390 --> 01:04:25,980
support racing engine and as you can see
we're getting pretty decent performance

890
01:04:25,980 --> 01:04:31,650
700 executions a second just to give you
an idea natively this gets about 2,000

891
01:04:31,650 --> 01:04:36,329
executions per second so overhead is
just over fifty percent so the next step

892
01:04:36,329 --> 01:04:38,369
and conclusions I no amount of time here

893
01:04:38,369 --> 01:04:42,359
basically this is all being migrated to
windows as well

894
01:04:42,900 --> 01:04:46,290
recon two weeks i should hopefully have
a code release for you

895
01:04:46,290 --> 01:04:50,609
all the racing engines that I've talked
about showing you today are soon to be

896
01:04:50,609 --> 01:04:54,690
open source they're just need to package
them up and put them on github so feel

897
01:04:54,690 --> 01:04:57,150
free to contact me of line

898
01:04:57,150 --> 01:05:00,210
rich in seattle on twitter is probably
the easiest way

899
01:05:00,210 --> 01:05:03,270
and with that I would like to just thank
you guys

900
01:05:04,470 --> 01:05:07,470
yes thank you

901
01:05:08,220 --> 01:05:17,368
yeah i'll be around so you guys can grab
me out for Q&A

