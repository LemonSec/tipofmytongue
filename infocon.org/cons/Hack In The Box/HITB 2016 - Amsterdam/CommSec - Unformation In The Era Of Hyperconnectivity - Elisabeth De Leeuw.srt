1
00:00:15,850 --> 00:00:21,759
I hope you will be interested in what F
but it was talk this afternoon can you

2
00:00:21,760 --> 00:00:23,440
hear me

3
00:00:23,440 --> 00:00:29,740
maybe I should change something yeah
this is better isaac i would like to

4
00:00:29,740 --> 00:00:35,949
discuss something about what I think
emerging your technologies are doing to

5
00:00:35,950 --> 00:00:43,750
information and also what we can do
about that

6
00:00:44,290 --> 00:00:50,650
what we are willing to do about that i
called it information in the area of

7
00:00:50,650 --> 00:00:55,629
hyper connectivity because I think
connectivity to a very important factor

8
00:00:55,629 --> 00:01:01,570
that this changing a lot in the world of
information not exactly to data with to

9
00:01:01,570 --> 00:01:09,700
information first on the high level i
will discuss some regulations in the

10
00:01:09,700 --> 00:01:17,380
field of data protection because that's
one way of approaching information and

11
00:01:17,380 --> 00:01:24,490
trying to protect informations the legal
way to do that and we have the safe

12
00:01:24,490 --> 00:01:27,820
harbor and regulation which

13
00:01:29,320 --> 00:01:31,190
No

14
00:01:31,190 --> 00:01:40,550
will be replaced by the data shields
regulation and but the data sheet

15
00:01:40,550 --> 00:01:43,550
regulation does not

16
00:01:44,570 --> 00:01:47,210
limited collection and

17
00:01:47,210 --> 00:01:54,470
the retention of data and also there are
questions to the enforcement of the

18
00:01:54,470 --> 00:01:57,470
regulations and so

19
00:01:58,290 --> 00:02:07,530
it could be said that it's not a strong
regulation to to protect data in Europe

20
00:02:07,530 --> 00:02:16,590
we have to general data protection
regulation and as part of that there's a

21
00:02:16,590 --> 00:02:21,690
data breach notification an obligation
to notify and

22
00:02:22,530 --> 00:02:29,910
so also security and randomization and
encryption at an obligation as part of

23
00:02:29,910 --> 00:02:36,780
that regulation so that's I think a
great thing to protect data but the

24
00:02:36,780 --> 00:02:44,400
question is how will organization which
comply with this regulation and how we

25
00:02:44,400 --> 00:02:46,200
can we enforce it

26
00:02:46,200 --> 00:02:56,190
the appliance because it is also to do
with governance with IT governance and

27
00:02:56,190 --> 00:03:01,739
issued do not know that you are doing
things around the wrong way then you

28
00:03:01,739 --> 00:03:11,160
cannot modify anybody about you were
doing it the wrong way so it's a it is

29
00:03:11,160 --> 00:03:19,560
something but it's not not complete it's
not perfect and then once we also have a

30
00:03:19,560 --> 00:03:26,670
proposal for a new law for their
intelligence services and

31
00:03:28,270 --> 00:03:34,090
in a nutshell at the regulation says
well okay we will continue to wear

32
00:03:34,090 --> 00:03:43,090
tap the internet and we will do so even
more when you look at the budget we will

33
00:03:43,090 --> 00:03:48,070
increase the typing of the internet for
15 million in two thousand fifteen to

34
00:03:48,070 --> 00:03:57,280
thirty food and five million arrows in
2019 and well that's only about money

35
00:03:57,280 --> 00:04:02,320
which is of course not an important it's
an indicated but also apart from thats

36
00:04:04,050 --> 00:04:04,660
the

37
00:04:04,660 --> 00:04:12,640
technology will improve so affect these
numbers tell me that the interception

38
00:04:12,640 --> 00:04:16,089
will arrange by like effector three or
four at least

39
00:04:16,600 --> 00:04:29,950
so of course this has to be done in
accordance with other regulations but

40
00:04:29,950 --> 00:04:32,940
also it

41
00:04:32,940 --> 00:04:35,249
and it is clear that

42
00:04:35,249 --> 00:04:37,249
a

43
00:04:37,249 --> 00:04:45,169
that intelligence services do not always
comply with the circulations and in some

44
00:04:45,169 --> 00:05:00,139
cases that may go on noticed and well in
the traffic a terrific between the US

45
00:05:00,139 --> 00:05:05,419
and Europe we have the passenger name
record regulation

46
00:05:07,009 --> 00:05:15,020
still this regulation has fake
definitions about what that may be

47
00:05:15,020 --> 00:05:21,318
collected and our must be collected and
not and the duration of the storages and

48
00:05:21,319 --> 00:05:29,089
and as for the effectiveness of the
collection of the data

49
00:05:29,749 --> 00:05:34,399
there is no obligation to share the data
is the member states and that of course

50
00:05:35,419 --> 00:05:39,049
well it may harm where the effectiveness

51
00:05:39,050 --> 00:05:45,409
also you may have names on the list but
then when the surgeon for false

52
00:05:45,409 --> 00:05:48,870
identities on board or people

53
00:05:48,870 --> 00:05:52,740
who what well are somehow

54
00:05:55,260 --> 00:05:56,039
a

55
00:05:56,040 --> 00:06:01,500
manipulating their identity they will go
unnoticed

56
00:06:02,340 --> 00:06:11,969
this way well this is all about
regulations and hopefully they are kept

57
00:06:13,920 --> 00:06:20,520
but also in the indicates with the
iphone

58
00:06:21,160 --> 00:06:24,640
us we have seen that

59
00:06:25,430 --> 00:06:28,920
the US has asked the

60
00:06:28,920 --> 00:06:30,440
for

61
00:06:30,440 --> 00:06:34,730
the exception to be broken but

62
00:06:36,490 --> 00:06:39,529
they didn't manage

63
00:06:39,529 --> 00:06:43,669
soon enough so that just ask Israeli

64
00:06:44,240 --> 00:06:51,889
a company to to break the encryption and
they succeeded so

65
00:06:52,889 --> 00:07:02,909
regulations and I may be effective but
only to a certain extent and deaf yet

66
00:07:02,909 --> 00:07:06,810
if you have a deaf power and enough
money combination of the two

67
00:07:06,810 --> 00:07:12,419
then you can always work one way or
another the regulations the regulations

68
00:07:12,419 --> 00:07:26,430
are all about data protection so that of
protection from the point of view of it

69
00:07:26,430 --> 00:07:32,310
the current and past state of Technology
the than one scientific potential for

70
00:07:32,310 --> 00:07:37,439
government policy has noticed death and
they said that the current legal

71
00:07:37,439 --> 00:07:44,610
frameworks for the in particular for the
intelligence services focus on the

72
00:07:44,610 --> 00:07:50,550
collection and sharing of data but that
should be supplemented by new standards

73
00:07:50,550 --> 00:07:56,520
for the analysis and use of data and big
data processes and of course that's a

74
00:07:56,520 --> 00:08:05,039
very serious problem because in excess
controls we always talked about and this

75
00:08:05,039 --> 00:08:11,550
great sets of information where it's in
the big data analysis there are new sets

76
00:08:11,550 --> 00:08:17,129
of information created and that's a
special fields special subset of

77
00:08:17,129 --> 00:08:20,129
information that is to be protected

78
00:08:22,379 --> 00:08:27,029
well then i would like to were talked
briefly about the society

79
00:08:27,029 --> 00:08:31,560
this is a conference on take another
year but I think technology has a great

80
00:08:31,560 --> 00:08:38,339
impact ER on society disease and i would
like to say something about this

81
00:08:38,339 --> 00:08:48,690
violence surveillances vs secretive
society and well in effect and in fact I

82
00:08:48,690 --> 00:08:56,399
think surveillance societies will often
be very secretive societies

83
00:08:56,399 --> 00:09:01,140
well I don't have to explain to you what
surveillances

84
00:09:01,820 --> 00:09:10,310
apart from that I think we must be aware
of the fact that we are exposing

85
00:09:10,310 --> 00:09:19,489
ourselves on social media etc so we are
willing way so to say secret of the

86
00:09:19,490 --> 00:09:25,520
secret wishes ideas to do with the fact
that in the cyber

87
00:09:26,060 --> 00:09:29,180
the world it's easy to hide a

88
00:09:30,810 --> 00:09:39,839
and there are many places where you can
act and see and or even you yourself

89
00:09:39,840 --> 00:09:42,120
will be invisible

90
00:09:42,120 --> 00:09:48,150
now why is that so important to say it's
not it's not only to do with a

91
00:09:48,150 --> 00:09:49,560
commonality

92
00:09:49,560 --> 00:09:54,329
it has also to do with the type of
society religion we have seen in the

93
00:09:54,330 --> 00:10:02,880
20th century and that our guys have been
well maybe the core in from an

94
00:10:02,880 --> 00:10:12,510
instrument of a totalitarian regimes and
watch for Nazi and Nazi regimes and this

95
00:10:12,510 --> 00:10:21,240
was only paper and there was no big data
and Isis or this on this archive only

96
00:10:21,240 --> 00:10:23,610
small data analysis

97
00:10:23,610 --> 00:10:27,180
so just very very slow very very limited
in scope

98
00:10:28,620 --> 00:10:36,030
now the question is what do all the new
technologies we have with big data

99
00:10:36,030 --> 00:10:41,670
analysis with exposure through social
media with exposure so the Internet of

100
00:10:41,670 --> 00:10:44,099
Things the emerging internet of things

101
00:10:44,100 --> 00:10:48,300
what will they do to our society I do
have to question

102
00:10:48,300 --> 00:10:53,699
I don't have the answer but i really
want to and to be aware of it and

103
00:10:53,700 --> 00:10:58,140
through where evidence part of the
discussion and

104
00:10:58,140 --> 00:11:01,260
of IT security and the other protection

105
00:11:03,540 --> 00:11:13,140
now i find this word information and
information the word information in my

106
00:11:13,140 --> 00:11:19,380
opinion has to do with the facts in that
in that and analytics we generate new

107
00:11:19,380 --> 00:11:22,710
information and

108
00:11:22,710 --> 00:11:30,480
the new information can also mean that
information that beforehand was not

109
00:11:30,480 --> 00:11:36,330
personalized you can when you start with
not personalized information then you

110
00:11:36,330 --> 00:11:39,330
can end up with personalized information

111
00:11:39,900 --> 00:11:46,949
so that's a ligament pics are very
intrusive and also the volume of the

112
00:11:46,950 --> 00:11:57,450
information is increasing exponentially
ality exponential apart from the fact

113
00:11:57,450 --> 00:12:05,460
that the information is growing
exponential this hyper-connectivity so

114
00:12:05,460 --> 00:12:13,950
all the data will be available almost
everywhere and

115
00:12:14,990 --> 00:12:18,649
they will be kept for long periods of
times so

116
00:12:19,800 --> 00:12:25,709
there will be no a non-fact of place
left

117
00:12:25,709 --> 00:12:32,310
maybe in yet why do we collect all this
data

118
00:12:32,880 --> 00:12:44,670
why do we analyzes well we are acting on
a number of dilemmas and the few of the

119
00:12:44,670 --> 00:12:49,620
important he must have to do with need
to know or just need to share

120
00:12:49,620 --> 00:12:53,070
we want to share in order to make the
world more secure

121
00:12:53,610 --> 00:12:55,920
we want to

122
00:12:55,920 --> 00:12:56,760
a

123
00:12:56,760 --> 00:13:04,350
to pay the price of privacy because we
want to be safe and indicates of the

124
00:13:04,350 --> 00:13:06,250
attacks of 911

125
00:13:06,250 --> 00:13:11,890
it was concluded that the damage
services in the United States had to

126
00:13:11,890 --> 00:13:18,400
share information and then from that
information somehow it goes the

127
00:13:18,400 --> 00:13:28,720
wikileaks and the similar things to
happen but even more important i think

128
00:13:28,720 --> 00:13:35,020
is that a what I already set is that I
started with the fact that in that

129
00:13:35,020 --> 00:13:39,490
analytics we end up with more
information that the output is greater

130
00:13:39,490 --> 00:13:45,610
than the input volume of information is
greater than the input and then many

131
00:13:45,610 --> 00:13:48,610
many who is an ex NSA

132
00:13:49,510 --> 00:13:52,510
i know this i think

133
00:13:53,360 --> 00:14:01,760
that he is a whistleblower as a matter
of fact and he says we are not only that

134
00:14:01,760 --> 00:14:06,410
we are collecting so much data but also
on top of that

135
00:14:07,750 --> 00:14:15,010
we analyze this data and the volume of
information we are generating causes to

136
00:14:15,010 --> 00:14:23,200
be the answer in no information at all
so

137
00:14:25,010 --> 00:14:35,810
an overdose of information somehow to
Anson - no information of a tall and he

138
00:14:35,810 --> 00:14:43,160
says that that's cause it's a great
danger because we act as if we know

139
00:14:43,160 --> 00:14:45,469
everything whereas effect

140
00:14:45,470 --> 00:14:50,960
maybe we do not so much even we don't
know nothing of me

141
00:14:50,960 --> 00:14:56,240
no drug thing so the question is and we
want to know

142
00:14:56,240 --> 00:15:02,510
we want to have information but we also
have to know where to stop knowing and

143
00:15:02,510 --> 00:15:09,590
because otherwise it will be ineffective
of a cantar product of so I found this

144
00:15:09,590 --> 00:15:11,960
picture of a site

145
00:15:11,960 --> 00:15:19,850
no subpoena and and then you may ask
what is try to sleep in it I didn't know

146
00:15:19,850 --> 00:15:25,400
that either but it's what's called a
model and analysis of this type of drug

147
00:15:25,400 --> 00:15:29,780
and on the left and you see the state of

148
00:15:30,840 --> 00:15:42,330
nerves when people do not use photos and
on the right you see the state of to

149
00:15:42,330 --> 00:15:47,850
predator the nerves in the brain when
they do use part of so you see that the

150
00:15:47,850 --> 00:15:53,340
connectivity is much much more higher
and net

151
00:15:53,340 --> 00:16:01,950
it's made of four so to say i use it as
a metaphor to think about what can

152
00:16:01,950 --> 00:16:05,850
happen to society when we have too much
connections

153
00:16:05,850 --> 00:16:10,410
it may be feel feel a great to have some
persons to use platters

154
00:16:10,410 --> 00:16:17,310
but in fact i think it would we will end
up not with information better

155
00:16:17,310 --> 00:16:18,689
information

156
00:16:18,690 --> 00:16:26,130
well also I found out this word and then
I looked it up and then some other

157
00:16:26,130 --> 00:16:32,130
people have in fact that this world as
well so but typically Oscar Wilde for

158
00:16:32,130 --> 00:16:37,560
example says you've got it wrong and
that's what it's all about information

159
00:16:38,310 --> 00:16:45,119
now what challenges that we are facing
with regards to the things i have

160
00:16:45,120 --> 00:16:53,970
discussed of course one important point
is a democratic governance not only a

161
00:16:53,970 --> 00:16:59,190
governance in terms of technology but
also Democratic Governors so

162
00:17:00,000 --> 00:17:04,470
people who are involved in politics etc
they should understand what's going on

163
00:17:04,470 --> 00:17:07,470
and should be able to anticipate on it

164
00:17:08,220 --> 00:17:14,010
also we need some sort of balance of
powers in terms of access to information

165
00:17:14,010 --> 00:17:21,180
and also the power of comprehension last
thing by the last thing I mean that

166
00:17:22,589 --> 00:17:29,610
in this field it's often difficult to
make accurate policies because the

167
00:17:29,610 --> 00:17:35,459
policymakers cannot dive deep into the
bits and parts in order to find out

168
00:17:35,460 --> 00:17:39,299
what's going on so but insects

169
00:17:39,299 --> 00:17:42,960
somebody shoot and then make a fella
policy minute

170
00:17:42,960 --> 00:17:50,909
in terms of for democracy then we have
them

171
00:17:51,690 --> 00:17:59,309
technological challenges we should
strive for balance the application of

172
00:17:59,309 --> 00:18:06,840
technologies the cyber intelligence and
cyber security intelligence should keep

173
00:18:06,840 --> 00:18:14,100
it with the cyber arms race with a call
cyber arms race and

174
00:18:15,260 --> 00:18:21,140
data protection should keep pace with
cyber intelligence so

175
00:18:22,179 --> 00:18:30,999
and I think on a very high level and
then talk about my data protection and

176
00:18:30,999 --> 00:18:39,759
information security etc we should
strike force stronger mimicry with the

177
00:18:39,759 --> 00:18:41,049
world of attackers

178
00:18:41,049 --> 00:18:47,980
so we need a emerging technologies which
are threatening us and we should use the

179
00:18:47,980 --> 00:18:54,639
same technologies in order to protect
ourselves and also last but not least we

180
00:18:54,639 --> 00:19:00,189
need somewhere with cyber security cyber
infrastructure and I think there's some

181
00:19:00,190 --> 00:19:05,950
things in particular with regard to the
world word wrap that can be improved the

182
00:19:05,950 --> 00:19:16,600
will not go into details about that but
now when we look at the concept of

183
00:19:16,600 --> 00:19:18,800
information and

184
00:19:18,800 --> 00:19:20,620
the

185
00:19:20,620 --> 00:19:27,429
the intrusion of privacy and all these
things that are going on when we look at

186
00:19:27,430 --> 00:19:30,430
the regulation to touch regulation for

187
00:19:31,370 --> 00:19:37,520
the intelligence services one thing that
has to be set has been set is that they

188
00:19:37,520 --> 00:19:46,910
really need a great powers to collect
all sorts of data and not only focusing

189
00:19:46,910 --> 00:19:52,760
on particular individuals or groups of
something but more generic polish and

190
00:19:52,760 --> 00:19:57,410
the reason for that has been that the
surfaces say okay

191
00:19:59,090 --> 00:20:03,379
we most of the time we do not know who
is acting on the internet because

192
00:20:04,870 --> 00:20:08,800
people were doing something wrong in our
perception

193
00:20:09,890 --> 00:20:14,390
they will be using sugar names are there
will be and then I was or something like

194
00:20:14,390 --> 00:20:15,080
that

195
00:20:15,080 --> 00:20:21,230
so for the expiration we could somehow
try and look at the identity

196
00:20:21,230 --> 00:20:26,360
infrastructure on the web and my
suggestion is that blockchain technology

197
00:20:26,360 --> 00:20:28,760
might be of help there

198
00:20:28,760 --> 00:20:35,450
and if somebody's interested in
discussing that with me and greater

199
00:20:35,450 --> 00:20:38,600
detail a I would like that very much

200
00:20:38,600 --> 00:20:45,169
and when we have a stronger
infrastructure then intelligence

201
00:20:45,170 --> 00:20:55,250
services would be able to focus more on
individuals who are a risk or groups who

202
00:20:55,250 --> 00:20:59,990
are risks and then in terms of retention
they should also

203
00:21:01,549 --> 00:21:07,519
be able to decide which information they
have to keep and which information it

204
00:21:07,519 --> 00:21:10,759
can be thrown away after one day or one
week or something

205
00:21:11,509 --> 00:21:17,809
and also when you have an identity
infrastructure and stronger and identity

206
00:21:17,809 --> 00:21:20,809
infrastructure then you could

207
00:21:21,539 --> 00:21:25,889
a filter well I effect implicitly I said
that already

208
00:21:26,399 --> 00:21:31,199
you can somehow filter information and
then throw everything away

209
00:21:31,739 --> 00:21:35,399
that is not relevant anymore very fast
after analysis

210
00:21:36,989 --> 00:21:40,409
that's it thank you

211
00:21:44,190 --> 00:21:59,399
if there are any questions so we like
you be such a yeah yeah yeah

212
00:21:59,399 --> 00:22:06,330
yeah mhm I can say something i'm not an
expert in blockchain technology that's

213
00:22:06,330 --> 00:22:08,668
first type of but I understand

214
00:22:08,669 --> 00:22:09,750
a

215
00:22:09,750 --> 00:22:17,220
character free in terms of what can I
use it for now

216
00:22:17,220 --> 00:22:22,050
I've been thinking about on high level i
do in a central location is and he is of

217
00:22:22,050 --> 00:22:30,330
course some sort of a example in every
block information is stored and then

218
00:22:30,330 --> 00:22:37,620
within a block the information is
encrypted but not only in itself but in

219
00:22:37,620 --> 00:22:43,709
connection was a proceeding block of
proceeding blocks so that means is that

220
00:22:43,710 --> 00:22:46,890
if i take a block out of it at that

221
00:22:46,890 --> 00:22:54,210
I have to approach the information set
in connection with each other

222
00:22:54,210 --> 00:23:07,260
if I want to decrypt and change the
information in a legitimate way

223
00:23:08,010 --> 00:23:13,650
so what we see in identity management

224
00:23:14,310 --> 00:23:21,870
we have the problem of a source
documents or search information which

225
00:23:21,870 --> 00:23:27,300
means that when I go to a fortune

226
00:23:27,300 --> 00:23:31,200
I can say okay give me your birth
certificate to give me a passport give

227
00:23:31,200 --> 00:23:35,550
me something to prove that i am not who
I am the audience

228
00:23:36,150 --> 00:23:41,400
then if it's a good forger then he will
do that develop a and then Here I am

229
00:23:41,400 --> 00:23:42,990
just a new person

230
00:23:42,990 --> 00:23:54,750
the model here the the advantage of the
block chain model is that no set from

231
00:23:54,750 --> 00:23:57,720
information stance on its own

232
00:23:57,720 --> 00:24:05,460
so you always need some sort of short
our group of something to go back to in

233
00:24:05,460 --> 00:24:08,160
order to proceed

234
00:24:08,160 --> 00:24:14,910
so everything is connected so you cannot
just say I take one element out of the

235
00:24:14,910 --> 00:24:16,880
chain and then

236
00:24:16,880 --> 00:24:19,880
falsify it because you have to go back
to the chain

237
00:24:20,990 --> 00:24:29,810
somehow that's why this algorithm can
threaten in principle identity

238
00:24:29,810 --> 00:24:35,060
management in general not only for
internet or for IT applications but also

239
00:24:35,060 --> 00:24:41,960
for national governments to to define
our righteous study identities or for

240
00:24:41,960 --> 00:24:43,310
their citizens

241
00:24:43,310 --> 00:24:49,100
ok

242
00:24:52,010 --> 00:24:55,490
yeah

243
00:24:56,750 --> 00:24:58,280
okay thank you

