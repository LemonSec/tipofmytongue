1
00:00:17,670 --> 00:00:22,230
you hey there we go I think this is
working here we go great thank you very

2
00:00:22,230 --> 00:00:25,619
much as a lovely intro a good morning
amsterdam it's a great honor to be here

3
00:00:25,619 --> 00:00:29,130
and kick off jack in the box 2016 with
you on

4
00:00:29,130 --> 00:00:32,610
I'm going to talk a little bit today
about the history of the crypto Wars and

5
00:00:32,610 --> 00:00:35,339
try to get you excited about what

6
00:00:35,340 --> 00:00:40,290
what's coming up next as as you heard
the intro and really remember the

7
00:00:40,290 --> 00:00:43,410
operations team and Twitter and later
worked on the information security team

8
00:00:43,410 --> 00:00:45,930
is part of that team

9
00:00:45,930 --> 00:00:49,440
one of the things that I do is I brought
Twitter to a hundred percent always on

10
00:00:49,440 --> 00:00:53,610
SL and worked with some of the initial
law enforcement response when we were

11
00:00:53,610 --> 00:00:57,870
very young company and you know I
learned a lot while I was at Apple

12
00:00:57,870 --> 00:01:03,930
dealing with law enforcement and you
know it's it's a very difficult a very

13
00:01:03,930 --> 00:01:04,890
difficult world when you

14
00:01:04,890 --> 00:01:07,680
we run a start-up and you have to
interact with law enforcement you may

15
00:01:07,680 --> 00:01:11,159
have never done that before and you know
all in all I've been at this for quite

16
00:01:11,159 --> 00:01:15,810
some time and in a sword before I tell
you where we're going with the crypto

17
00:01:15,810 --> 00:01:20,070
Wars I want to go back and talk about
where we've been and I think right now

18
00:01:20,070 --> 00:01:25,109
security versus privacy is one of the
largest debates of our time and in

19
00:01:25,109 --> 00:01:28,020
October of 1977

20
00:01:28,020 --> 00:01:32,310
George Dava was an American computer
scientist and photographer who received

21
00:01:32,310 --> 00:01:36,869
a gag order from the NSA and he received
this while working on a patent

22
00:01:36,869 --> 00:01:42,000
application for a stream cipher device
and the NSA really only knew about this

23
00:01:42,000 --> 00:01:46,439
because of a long-term voluntary
cooperation between academic researchers

24
00:01:46,439 --> 00:01:51,809
and the and the NSA and this was known
as the invention Secrecy Act of nineteen

25
00:01:51,810 --> 00:01:56,100
fifty-one and the Act gave them the
power to block patents in the interest

26
00:01:56,100 --> 00:02:02,280
of national security and now under this
system the academics and cryptographers

27
00:02:02,280 --> 00:02:06,359
would submit copies of technical papers
to the agency before publication and

28
00:02:06,359 --> 00:02:10,350
this gave the agency an opportunity to
request the suppression of any sensitive

29
00:02:10,350 --> 00:02:14,519
material and you know at the time model
mathematicians abided by this agreement

30
00:02:14,520 --> 00:02:18,180
seeing it as a threat to the free
exchange of ideas and the free exchange

31
00:02:18,180 --> 00:02:23,010
of ideas is what our industry depends on
to to be successful and to meet the

32
00:02:23,010 --> 00:02:27,280
goals of cybersecurity and and other
requirements and you know

33
00:02:27,280 --> 00:02:31,930
this sort of pervasive problem was with
us all the way through the eighties and

34
00:02:31,930 --> 00:02:37,090
in the nineties in fact we share put a
book called applied cryptography and at

35
00:02:37,090 --> 00:02:37,870
the time

36
00:02:37,870 --> 00:02:42,400
um you know it was legal to publish
because of the United States having the

37
00:02:42,400 --> 00:02:44,830
First Amendment and a right to speak
freely

38
00:02:44,830 --> 00:02:48,250
it was legal to publish a book on
cryptography but if you would take the

39
00:02:48,250 --> 00:02:52,900
same exact source code and put it on a
floppy disk in 1994

40
00:02:52,900 --> 00:02:56,500
it was illegal you are not allowed to
actually shift that across lines because

41
00:02:56,500 --> 00:03:00,700
it was considered to be ammunition in
fact last night someone told me a lovely

42
00:03:00,700 --> 00:03:04,929
story that if you had taken the source
code of the of the book and you put the

43
00:03:04,930 --> 00:03:07,300
book in a rocket and fired across the
border

44
00:03:07,300 --> 00:03:11,800
it was the munition and at that point it
would no longer be illegal to transmit

45
00:03:11,800 --> 00:03:14,650
anywhere because guess what you would
just find another country so it was fine

46
00:03:14,650 --> 00:03:21,250
on the problem is is that the the NSA
tried to use export regulations and

47
00:03:21,250 --> 00:03:26,170
later deliberately manipulated
cryptography to weaken it to create

48
00:03:26,170 --> 00:03:31,268
multiple forms of photography some for
export and some porn on export and you

49
00:03:31,269 --> 00:03:34,540
know if you were using ciphers above 56
bit

50
00:03:34,540 --> 00:03:37,900
you weren't allowed to do that because
perhaps the NSA couldn't break the

51
00:03:37,900 --> 00:03:42,400
ciphers back then on this all sort of
changes in the late nineties because

52
00:03:42,400 --> 00:03:48,310
Phil Zimmerman comes along and releases
pgp and this limited use of strong

53
00:03:48,310 --> 00:03:49,750
encryption are

54
00:03:49,750 --> 00:03:55,090
this begins to greatly concerned the US
government because it's not about easy

55
00:03:55,090 --> 00:03:59,980
access to strong encryption it's about
ubiquitous and simple access where the

56
00:03:59,980 --> 00:04:05,410
world is encrypted by default and the US
government tried to publicly ensure and

57
00:04:05,410 --> 00:04:10,209
retain its ability to decrypt traffic so
they fought us using technical methods

58
00:04:10,209 --> 00:04:14,109
such as key escrow the insertion of
vulnerabilities into the commercial

59
00:04:14,109 --> 00:04:18,668
encryption ecosystem and by directly
attacking systems networks and endpoint

60
00:04:18,668 --> 00:04:22,570
communications at targets would use and
you know fearing the widespread adoption

61
00:04:22,570 --> 00:04:23,800
of encryption

62
00:04:23,800 --> 00:04:29,020
we had this in 1993 we had the Clipper
Chip and the Clipper Chip was introduced

63
00:04:29,020 --> 00:04:33,159
by Clinton's administration and it was a
sort of hybrid a hardware software

64
00:04:33,160 --> 00:04:38,590
device which used key escrow and it
truly express the intent of the time

65
00:04:38,590 --> 00:04:43,900
which was that the FBI or other
companies would permanently have a

66
00:04:43,900 --> 00:04:48,340
mechanism where they could have your
keys and an encryption should come with

67
00:04:48,340 --> 00:04:52,450
a back door and you know George dominant
from the seventies

68
00:04:52,450 --> 00:04:57,909
who is you know terribly affected by the
NSA gag order was a strong outspoken

69
00:04:57,910 --> 00:05:02,770
opponent against this and you know this
is not the right way to provide strong

70
00:05:02,770 --> 00:05:08,020
cryptographic tools to the public so an
immediate backlash from technical

71
00:05:08,020 --> 00:05:12,520
experts privacy advocates and industry
leaders are bought this device and

72
00:05:12,520 --> 00:05:14,799
eventually in 1994

73
00:05:14,800 --> 00:05:19,660
the device was was broken at the same
time they took a different approach they

74
00:05:19,660 --> 00:05:22,900
tried to sign into law a bill which was
eventually signed in with much

75
00:05:22,900 --> 00:05:26,739
opposition called Kalia Kalia is the
communications assistant for law

76
00:05:26,740 --> 00:05:31,690
enforcement act and that was signed into
law by president clinton and clear was

77
00:05:31,690 --> 00:05:35,500
sort of a direct reaction to the the
changing tide of the telecommunications

78
00:05:35,500 --> 00:05:39,820
industry the telecommunications industry
was then moving from old analog switches

79
00:05:39,820 --> 00:05:43,480
to digital switches which are much
harder to wiretap it's not like I can

80
00:05:43,480 --> 00:05:47,230
walk up and grab a pair of alligator
clips and clip onto a binding post and

81
00:05:47,230 --> 00:05:48,820
hear your conversation anymore

82
00:05:48,820 --> 00:05:52,719
the telephone companies had to
fundamentally redesign their systems and

83
00:05:52,720 --> 00:05:56,200
if you go and look in like a cisco
manual today you'll actually see

84
00:05:56,200 --> 00:06:01,390
references to kalia commands for for
intercepting communications this uh this

85
00:06:01,390 --> 00:06:06,669
was expanded multiple times in 2004 it
was up

86
00:06:06,670 --> 00:06:10,960
it was expanded to include ISPs and
voice over IP providers like skype in a

87
00:06:10,960 --> 00:06:15,010
few years later the FBI began to push
legislation to try to expand this to all

88
00:06:15,010 --> 00:06:19,840
online communications and this died in
very the set very similar way with much

89
00:06:19,840 --> 00:06:24,969
uproar much fighting from the industry
and it it did resurfaced in 2010 and you

90
00:06:24,970 --> 00:06:28,090
know we sort of Mark 2010 is the
beginning of the FBI is going dark

91
00:06:28,090 --> 00:06:33,669
campaign and it came back again in 2013
and you know the problem with the

92
00:06:33,670 --> 00:06:38,350
proposal as as the electronic frontier
foundation stated was that it would

93
00:06:38,350 --> 00:06:42,610
allow the FBI to find non-compliant
companies for not providing back doors

94
00:06:42,610 --> 00:06:44,380
and in 2014

95
00:06:44,380 --> 00:06:49,480
you know we see this issue again with
them asking for a national discussion

96
00:06:49,480 --> 00:06:51,380
about the use of encryption

97
00:06:51,380 --> 00:06:55,760
so you know in 1994 we thought we had
won this debate already because

98
00:06:55,760 --> 00:07:00,590
cryptographer mad blaze had discovered
holes in the Clipper Chip and the export

99
00:07:00,590 --> 00:07:03,739
controls were relaxed and we started to
see increased security on the internet

100
00:07:03,740 --> 00:07:07,640
where it suddenly you know hundred
twenty-eight bit 256-bit encryption was

101
00:07:07,640 --> 00:07:11,360
available and you know for the most part
we thought this issue is just said and

102
00:07:11,360 --> 00:07:16,130
done and the really interesting part is
that it's like did we actually win

103
00:07:16,130 --> 00:07:20,540
because I don't think we did the the
impact of the weakening of our

104
00:07:20,540 --> 00:07:25,790
cryptosystems at least in the last year
has introduced three major SL

105
00:07:25,790 --> 00:07:27,410
vulnerabilities freak

106
00:07:27,410 --> 00:07:31,550
log jam and round and this these
vulnerabilities would not have existed

107
00:07:31,550 --> 00:07:37,280
if not for the fact that we had
government attempting to weaken SL you

108
00:07:37,280 --> 00:07:41,719
know over 20 years ago and you know for
the third time in a year we have another

109
00:07:41,720 --> 00:07:46,250
vulnerability and I'm you know these
restrictions were originally designed to

110
00:07:46,250 --> 00:07:50,900
give them an advantage but the impact is
a catastrophic failure of security for

111
00:07:50,900 --> 00:07:56,210
everyone and you know more recently we
saw in the 2013 sort of Snowden

112
00:07:56,210 --> 00:08:00,680
revelations information about NSA bull
run an essay bull run was interesting

113
00:08:00,680 --> 00:08:04,730
because we had one in the courts in the
eff and and US Congress and public

114
00:08:04,730 --> 00:08:09,710
opinion had said no to the Clipper Chip
and no to weakening encryption but the

115
00:08:09,710 --> 00:08:13,340
NSA was working on it all along with
projects like Bull Run which created new

116
00:08:13,340 --> 00:08:17,780
vulnerabilities in mist cryptography
standards and the weakening of sort of

117
00:08:17,780 --> 00:08:22,099
the global cryptography market and
attacking major libraries like RSA and

118
00:08:22,100 --> 00:08:26,120
we still don't know the full extent of
what what this has done to us and you

119
00:08:26,120 --> 00:08:30,260
know why why why continue on this is why
do i do I keep pressing this issue and

120
00:08:30,260 --> 00:08:33,080
it's because if you look at someone like
Amnesty International

121
00:08:33,080 --> 00:08:36,680
you know they believe that in a digital
age access to and use of encryption is

122
00:08:36,679 --> 00:08:41,598
an enabler to the right to privacy you
know encryption is an enabler of freedom

123
00:08:41,599 --> 00:08:45,410
of expression information and opinion
and it has an impact on the rights of

124
00:08:45,410 --> 00:08:49,520
individuals and especially it's a
critical tool for human rights defenders

125
00:08:49,520 --> 00:08:54,050
activists and journalists all who rely
on this with an increasing frequency to

126
00:08:54,050 --> 00:08:58,520
protect security and others from of
unlawful surveillance and the real

127
00:08:58,520 --> 00:09:01,339
question is what does what does that
look like if we have your biggest

128
00:09:01,339 --> 00:09:04,280
question was it look like in the face of
terrorism and crime

129
00:09:04,280 --> 00:09:09,650
you know in my home state in san
bernardino california a deplorable act

130
00:09:09,650 --> 00:09:15,439
of terrorism was executed by seed fruit
and touchscreen Malik they killed 14

131
00:09:15,440 --> 00:09:22,820
people in December second 2015 and this
is not you know this is an action from a

132
00:09:22,820 --> 00:09:28,010
few individuals a few distraught
individuals and we cannot allow these

133
00:09:28,010 --> 00:09:31,760
sort of activities to to dominate the
privacy and security of the many

134
00:09:31,760 --> 00:09:33,830
terrorism is deplorable

135
00:09:33,830 --> 00:09:38,030
it's awful it's an attack on our general
way of life but we cannot allow that to

136
00:09:38,030 --> 00:09:44,959
remove our privacy for kinda iphone 5c
and the iphone 5c unlike the later

137
00:09:44,960 --> 00:09:49,490
versions of the Apple iPhone had
slightly weaker Security and the FBI had

138
00:09:49,490 --> 00:09:54,230
found one of his phones in the trash and
I asks apple through a standard court

139
00:09:54,230 --> 00:09:58,610
order for his iCloud account backups and
any other data that Apple could provide

140
00:09:58,610 --> 00:10:03,110
and out provided everything they could
but they did not provide access to the

141
00:10:03,110 --> 00:10:07,940
phone directly because the device is
protected by a number of security

142
00:10:07,940 --> 00:10:12,110
mechanisms which are introduced so
there's a brute force protection on the

143
00:10:12,110 --> 00:10:14,750
device if you try to type in a code too
many times the device will self-destruct

144
00:10:14,750 --> 00:10:19,250
of the operating system updates are
signed and you know in later models like

145
00:10:19,250 --> 00:10:23,330
the the six and a success they have a
hardware enclave where your keys are

146
00:10:23,330 --> 00:10:29,839
stored so the issue a court order on
your in figure 2016 the demands that

147
00:10:29,839 --> 00:10:36,350
Apple build a custom build of the iOS
operating system to remove the automatic

148
00:10:36,350 --> 00:10:40,550
eraser and pin limits that are on the
phone and if we kind of go back and look

149
00:10:40,550 --> 00:10:41,959
at the history of crypto Wars

150
00:10:41,960 --> 00:10:45,140
this is very similar to what was
occurring with things like the Clipper

151
00:10:45,140 --> 00:10:48,140
Chip it's like you just just build us
something that we can get into

152
00:10:48,140 --> 00:10:55,100
I'm interestingly enough they tried to
use a very old law from 1789 called the

153
00:10:55,100 --> 00:10:59,930
all writs act to compel Apple is
unlocking the phone and you know the

154
00:10:59,930 --> 00:11:03,319
Apple CEO at the time Tim Cook said this
is an unprecedented use of the law and

155
00:11:03,320 --> 00:11:07,910
in fact we've seen the all writs a ques
many times to to compel companies and

156
00:11:07,910 --> 00:11:10,880
it's probably not what it was originally
intended for

157
00:11:10,880 --> 00:11:15,320
and you know the implications of this
are quite chilling so that the

158
00:11:15,320 --> 00:11:18,320
government can use a single act to make
it easier to unlock your phone

159
00:11:18,860 --> 00:11:23,630
they would have the power to reach into
anyone's device to capture data and you

160
00:11:23,630 --> 00:11:24,740
know later

161
00:11:24,740 --> 00:11:29,810
you know Tim Cook response is this would
set a dangerous precedent and you could

162
00:11:29,810 --> 00:11:33,469
imagine what would happen if you know
you had like ass and a samsung smart TV

163
00:11:33,470 --> 00:11:38,480
or a nest device and suddenly along
comes a and a court order to reprogram

164
00:11:38,480 --> 00:11:41,540
your device to turn it into a tool of
surveillance in your home it's it's

165
00:11:41,540 --> 00:11:42,949
really not acceptable

166
00:11:42,950 --> 00:11:47,720
I'm and you know Apple could not provide
this would not provided and put up quite

167
00:11:47,720 --> 00:11:52,130
a fight from you know the first part of
this year and they would not provide a

168
00:11:52,130 --> 00:11:56,180
back door into the phone instantly
enough the FBI later claimed that they

169
00:11:56,180 --> 00:12:01,430
were able to access the phone using a
currently unknown vulnerability and

170
00:12:01,430 --> 00:12:03,319
there's a lot of speculation in March

171
00:12:03,320 --> 00:12:07,070
what company had actually provided that
vulnerability whether i was celebrate or

172
00:12:07,070 --> 00:12:10,640
other companies but currently we don't
we don't know what they used

173
00:12:10,640 --> 00:12:18,140
um so you know it's very similar to what
happens in November 2015 with the Paris

174
00:12:18,140 --> 00:12:24,290
attacks where the you know where ISIL
actually claimed that they had used

175
00:12:24,290 --> 00:12:29,360
telegram to his telegram to announce the
attack and the idea here is that you

176
00:12:29,360 --> 00:12:29,930
know

177
00:12:29,930 --> 00:12:34,040
should these activities be used as a
pretext to monitor citizens and suppress

178
00:12:34,040 --> 00:12:38,120
dissidents and you know I think it comes
back to kind of a central point which is

179
00:12:38,120 --> 00:12:41,990
that it's not possible to make a message
in technology that secure for everyone

180
00:12:41,990 --> 00:12:43,130
except for the criminals

181
00:12:43,130 --> 00:12:47,900
it's just not possible this this is
different than the view that James

182
00:12:47,900 --> 00:12:51,860
coming to visit the current director of
the FBI has to say because he believes

183
00:12:51,860 --> 00:12:56,480
the technology is a tool for dangerous
people which I don't agree with you on

184
00:12:56,480 --> 00:13:00,260
that and also the law has not kept pace
with the technology and it's created a

185
00:13:00,260 --> 00:13:04,580
significant public safety issue which
they sort of refer to consistently is

186
00:13:04,580 --> 00:13:09,230
going dark and you know if we look at
someone like Oliver day who wrote

187
00:13:09,230 --> 00:13:12,650
securing change you know this is
encryption does it really make survey

188
00:13:12,650 --> 00:13:14,180
targeted surveillance harder

189
00:13:14,180 --> 00:13:17,900
you know we have cash with Barry Bonds
fake mustaches hats hair blankets hair

190
00:13:17,900 --> 00:13:20,959
dyes there's many ways to hide and you
know here's a kiss

191
00:13:20,960 --> 00:13:22,089
Snowden typing in his

192
00:13:22,089 --> 00:13:27,670
announcer with a blanket over his head
which is kind of funny I'm yeah so um in

193
00:13:27,670 --> 00:13:28,599
2015

194
00:13:28,600 --> 00:13:31,600
uh I guess sort of frustrated by this
problem the justice department tries a

195
00:13:31,600 --> 00:13:35,050
new argument and they say you know what
law enforcement really needed was to

196
00:13:35,050 --> 00:13:38,019
have us companies hold copies of
encryption keys that the government

197
00:13:38,019 --> 00:13:41,949
could get your information from them and
you know the problem is the companies

198
00:13:41,949 --> 00:13:44,920
are keeping stockpiles of encryption
keys it really increases the surface

199
00:13:44,920 --> 00:13:48,910
area of the attack and if i'm able to
breach a single company i get the

200
00:13:48,910 --> 00:13:53,649
encryption keys from many people and you
could imagine anyone from from you know

201
00:13:53,649 --> 00:13:58,540
hackers to foreign spies and not the
good hackers in this room of course but

202
00:13:58,540 --> 00:14:03,069
I'm you know but you know the same day
uh you know director , he said that the

203
00:14:03,069 --> 00:14:06,309
administration had decided if they
should seek legislation or not which is

204
00:14:06,309 --> 00:14:10,540
completely insane because they had been
seeking legislation since the early

205
00:14:10,540 --> 00:14:15,579
versions of kalia to regulate encryption
and that the way the cyber security

206
00:14:15,579 --> 00:14:20,709
community should should invent
mechanisms for the government to access

207
00:14:20,709 --> 00:14:24,790
the encrypted information without
weakening security almost relegating the

208
00:14:24,790 --> 00:14:25,689
problem

209
00:14:25,689 --> 00:14:31,360
- you know - something that we could
solve all sitting in a garage and I

210
00:14:31,360 --> 00:14:35,740
think at one point he actually said I I
think silicon valley is full of folks

211
00:14:35,740 --> 00:14:39,879
who stood in the garage years ago that
they would never be told your dreams are

212
00:14:39,879 --> 00:14:41,350
too hard to achieve

213
00:14:41,350 --> 00:14:46,149
well unfortunately for the director
there's a difference between dreams and

214
00:14:46,149 --> 00:14:49,149
math and math is what protects us

215
00:14:50,050 --> 00:14:58,300
so his idea of going dark is not really
what's happening in fact we currently

216
00:14:58,300 --> 00:15:00,639
live in sort of a golden age of
surveillance

217
00:15:00,639 --> 00:15:03,399
there's more information about you on
the Internet and there's more

218
00:15:03,399 --> 00:15:07,959
information about you and social media
and there ever has been to see the

219
00:15:07,959 --> 00:15:09,998
decision to make a statement that we're
going dark

220
00:15:09,999 --> 00:15:13,209
and in this world is not is not entirely
true

221
00:15:13,209 --> 00:15:18,069
you know and the great irony of this is
that their quest to access the data

222
00:15:18,069 --> 00:15:23,319
encrypted on one iphone made it such
that they open the encryption debate to

223
00:15:23,319 --> 00:15:29,019
the world and you know this conversation
if it wasn't started years ago it's it's

224
00:15:29,019 --> 00:15:29,860
going now

225
00:15:29,860 --> 00:15:33,200
now the Department center for law

226
00:15:33,200 --> 00:15:36,320
they release a lengthy paper on this if
you like to read it i'm not going to get

227
00:15:36,320 --> 00:15:40,700
into too much detail here but in short
they cite the fact that end-to-end

228
00:15:40,700 --> 00:15:45,320
encryption is unlikely to be widely
adopted and I think that it's beholden

229
00:15:45,320 --> 00:15:49,400
to everyone in this room to make sure
that actually happens on you know this

230
00:15:49,400 --> 00:15:52,610
that that software ecosystems that we
work in a fragmented

231
00:15:52,610 --> 00:15:55,700
so you know for many years it was very
hard to encrypt information because you

232
00:15:55,700 --> 00:15:59,390
had to fight with varying libraries and
all manner of problems and and now we

233
00:15:59,390 --> 00:16:02,990
want to move to a world that has
encryption by default and you know keep

234
00:16:02,990 --> 00:16:07,190
in mind that regardless of of what
changes at the end points that they

235
00:16:07,190 --> 00:16:11,120
still have access to incredible amounts
of unencrypted made a data from phone

236
00:16:11,120 --> 00:16:14,360
switches and other centralized
communication points that that they can

237
00:16:14,360 --> 00:16:18,080
readily use and the other argument is
that this is this has never been about

238
00:16:18,080 --> 00:16:22,040
one phone phones are not safe

239
00:16:22,040 --> 00:16:24,949
they're not something that you can eat
you just crack into and that's it you

240
00:16:24,950 --> 00:16:25,970
broke into one phone

241
00:16:25,970 --> 00:16:30,020
we need technical solutions to break
into devices and that if we were to

242
00:16:30,020 --> 00:16:31,850
create code that could open one phone

243
00:16:31,850 --> 00:16:37,400
it could open millions of locks not one
and you know repeatedly we heard from

244
00:16:37,400 --> 00:16:41,720
the FBI that that they were not they
were not trying to set a precedent they

245
00:16:41,720 --> 00:16:45,320
were not trying to send a message and
that they could create this magic

246
00:16:45,320 --> 00:16:49,520
targeted order that would only focus on
one phone and I think we all know that

247
00:16:49,520 --> 00:16:53,960
you write software once it runs in a lot
of places you know later we learned that

248
00:16:53,960 --> 00:16:57,680
there is 63 ongoing phone unlocking
cases in fact a hundred and seventy five

249
00:16:57,680 --> 00:17:02,810
cases existed in New York on you know
and the request could come for

250
00:17:02,810 --> 00:17:04,310
additional phones as well

251
00:17:04,310 --> 00:17:09,020
and you know why why haven't we seen any
any new legislation about this and I

252
00:17:09,020 --> 00:17:12,020
think it's mainly because we already had
this fight we had this fight 20 years

253
00:17:12,020 --> 00:17:13,129
ago

254
00:17:13,130 --> 00:17:16,970
you know there's a great tweet that came
up a while and it was like I'll please

255
00:17:16,970 --> 00:17:18,319
give us all the keys

256
00:17:18,319 --> 00:17:21,919
what could go wrong and then later we
find out that there's a group called apt

257
00:17:21,920 --> 00:17:25,190
six that had spent years inside of US
government networks consult conducting

258
00:17:25,190 --> 00:17:32,000
espionage and it's you know the FBI
isn't alone in this problem in you know

259
00:17:32,000 --> 00:17:36,410
blackberry in april of 2016 and I
apologize because another sponsor here

260
00:17:36,410 --> 00:17:37,580
but this happened

261
00:17:37,580 --> 00:17:40,820
the reality was it is that there was a
global encryption key that was used to

262
00:17:40,820 --> 00:17:44,810
encrypt many phones and they actually
made a statement saying that tech

263
00:17:44,810 --> 00:17:46,340
companies should not refuse

264
00:17:46,340 --> 00:17:51,168
a reasonable lawful access request but
the reality of it was is that there is

265
00:17:51,169 --> 00:17:52,610
still a global key

266
00:17:52,610 --> 00:17:56,178
so again we have a case a weakening
encryption to provide law enforcement

267
00:17:56,179 --> 00:17:58,640
axis and this is not not okay

268
00:17:58,640 --> 00:18:02,029
please if you build cryptosystems in the
future please don't do this please don't

269
00:18:02,029 --> 00:18:03,710
make one key for everyone

270
00:18:03,710 --> 00:18:08,990
um you know much of the legislation that
we talked about it says let's build a

271
00:18:08,990 --> 00:18:12,620
weakness let's build a back door and and
the idea is that there's a there's a

272
00:18:12,620 --> 00:18:15,469
belief that back doors will actually
work

273
00:18:15,470 --> 00:18:19,309
we frankly have to believe that there's
a set of criminals that know how to hide

274
00:18:19,309 --> 00:18:22,580
themselves better than the best argument

275
00:18:22,580 --> 00:18:26,870
James Bond type person and hiding
yourself really isn't that easy

276
00:18:26,870 --> 00:18:30,620
you know there's a number of places
where you can actually make mistakes and

277
00:18:30,620 --> 00:18:36,559
you know give away information about
yourself everything from device back up

278
00:18:36,559 --> 00:18:41,330
ski backups a lot of regulation right
now is focusing around touch ID and

279
00:18:41,330 --> 00:18:45,110
fingerprint scanner so can you be
compelled to give up your fingerprint to

280
00:18:45,110 --> 00:18:49,309
unlock a phone and an apple made the
change recently in the operating system

281
00:18:49,309 --> 00:18:51,770
that if you don't unlock your phone in
like 48 hours

282
00:18:51,770 --> 00:18:54,710
you can't use touch ID anymore so you
can imagine like your phone gets taken

283
00:18:54,710 --> 00:18:59,149
away from you and then the the day later
when the court order shows up they're

284
00:18:59,149 --> 00:19:01,908
not able to unlock your phone so that's
that's a good good work on the part of

285
00:19:01,909 --> 00:19:06,620
Apple you know you may send uh
incriminating evidence by non-encrypted

286
00:19:06,620 --> 00:19:09,979
means you might use cloud storage and
you might actually call someone and

287
00:19:09,980 --> 00:19:11,299
leave behind metadata

288
00:19:11,299 --> 00:19:15,168
I this is a lot to ask of your average
criminal

289
00:19:16,279 --> 00:19:20,120
now despite that the encryption war
continues

290
00:19:20,120 --> 00:19:23,539
you know some countries have already
gone ahead and outlawed encryption and

291
00:19:23,539 --> 00:19:27,080
the new crypto Wars are pretty much
global there's at least six countries in

292
00:19:27,080 --> 00:19:32,899
Europe to go after and and encryption in
the style of the way what's app works

293
00:19:32,899 --> 00:19:36,559
Turkey has laws against that Pakistan
has laws against that there's proposals

294
00:19:36,559 --> 00:19:41,000
in the UK which we'll get to in a minute
and then the net that the netherlands

295
00:19:41,000 --> 00:19:45,260
god bless they love supporting at the
support encryption so it's fantastic and

296
00:19:45,260 --> 00:19:49,190
you know the idea is that the encryption
genie has sort of left the bottle a long

297
00:19:49,190 --> 00:19:50,149
long time ago

298
00:19:50,149 --> 00:19:52,399
we're not going to be able to put
encryption back in the box and we can't

299
00:19:52,399 --> 00:19:56,989
stop people from using encryption and
you know with encryption encryption is

300
00:19:56,990 --> 00:19:59,270
our best defense against mass
surveillance

301
00:19:59,270 --> 00:20:04,460
and as we have more mass surveillance we
experience less privacy and what the FBI

302
00:20:04,460 --> 00:20:07,370
wants in the United States has been
achieved in some other countries much to

303
00:20:07,370 --> 00:20:09,800
the detriment of privacy and security
worldwide

304
00:20:09,800 --> 00:20:15,919
I'm when we go and look at these
countries you know China Malaysia Russia

305
00:20:15,920 --> 00:20:20,450
really really bad that the levels of
surveillance are extremely high and we

306
00:20:20,450 --> 00:20:25,370
have other countries which is slightly
better but the thing is is that are

307
00:20:25,370 --> 00:20:29,959
still in in the United States we have
the NSA proposing that you know

308
00:20:29,960 --> 00:20:32,780
ubiquitous encryption on the Internet is
a major threat to their ability to

309
00:20:32,780 --> 00:20:35,780
prosecute and 22 monitor you

310
00:20:35,780 --> 00:20:40,220
so you have to remember that this this
is the way that they view the world and

311
00:20:40,220 --> 00:20:46,430
I I see these estimates and the the work
that they've done as you know like the

312
00:20:46,430 --> 00:20:50,540
these revelations from from Snowden and
2013 they feel that it's put the sort of

313
00:20:50,540 --> 00:20:54,350
encryption world forward seven years
that they think that we are in a

314
00:20:54,350 --> 00:20:59,240
position now globally with the use of
encryption that we would not have gotten

315
00:20:59,240 --> 00:21:03,680
to without the sort of leak of this
information and I I tell you that's

316
00:21:03,680 --> 00:21:06,650
that's good because we should encrypt
all the things it's more of a more or

317
00:21:06,650 --> 00:21:11,270
less to me it's a manifesto it's a to-do
list for us as engineers to to hurt the

318
00:21:11,270 --> 00:21:14,420
ability of those that would take away
our privacy and our freedom

319
00:21:14,420 --> 00:21:18,530
I'm so you know where where is this all
going

320
00:21:19,550 --> 00:21:24,649
I think that there's going to be an ad
arise in additional encryption products

321
00:21:24,650 --> 00:21:26,030
across the board

322
00:21:26,030 --> 00:21:30,139
Apple's well on their way with secure
enclaves we're seeing more encryption

323
00:21:30,140 --> 00:21:33,560
being deployed in fact if we look at the
let's encrypt project which I'll talk

324
00:21:33,560 --> 00:21:34,429
about in a second

325
00:21:34,430 --> 00:21:39,530
let's encrypt has been very successful
but the real thing is we also will

326
00:21:39,530 --> 00:21:42,530
expect government to introduce more
legislation to come after strong

327
00:21:42,530 --> 00:21:46,460
encryption and promote impossible back
doors and in fact we already have that

328
00:21:46,460 --> 00:21:46,970
today

329
00:21:46,970 --> 00:21:51,290
so in the UK there's been proposals for
what's called the snoopers Charter and

330
00:21:51,290 --> 00:21:55,010
this is designed to make the acquisition
and disclosure communications the

331
00:21:55,010 --> 00:22:01,340
government easier and it also pretty
much makes hacking of endpoints legal

332
00:22:01,340 --> 00:22:05,750
for the government to do and the prime
minister david cameron wanted to say in

333
00:22:05,750 --> 00:22:07,950
2015 that they wanted to ban and

334
00:22:07,950 --> 00:22:11,850
encryption and they wanted to eliminate
any data that the government could not

335
00:22:11,850 --> 00:22:15,120
actually read you know once again it
doesn't work this way

336
00:22:15,120 --> 00:22:17,760
there's no such thing as good guy
encryption and there's no such thing as

337
00:22:17,760 --> 00:22:19,110
bad guy encryption

338
00:22:19,110 --> 00:22:26,370
you cannot make it work because math so
one of the other aspects of the snoopers

339
00:22:26,370 --> 00:22:28,979
Charter was to maintain records of
everyone's internet browsing activity

340
00:22:28,980 --> 00:22:33,299
social media email correspondence voice
calls internet gaming mobile phone

341
00:22:33,299 --> 00:22:36,990
messaging services to store those
records for 12 months at a cost to the

342
00:22:36,990 --> 00:22:41,429
country of 1.8 billion dollars if we
have true end-to-end encryption and

343
00:22:41,429 --> 00:22:44,820
always on TLS this is impossible guys is
not possible

344
00:22:44,820 --> 00:22:48,629
um you know going back to us for a
moment

345
00:22:48,630 --> 00:22:52,470
ber Feinstein introduces legislation in
april twenty sixteen which is absolutely

346
00:22:52,470 --> 00:22:55,649
ridiculous from privacy standpoint

347
00:22:55,649 --> 00:22:59,158
everything that we expected the worst
things we expected we were not

348
00:22:59,159 --> 00:23:00,510
disappointed

349
00:23:00,510 --> 00:23:05,820
they wanted to make all online data
intelligible in fact in some cases uh it

350
00:23:05,820 --> 00:23:09,120
would almost outlaw things like
compression like basic impression of

351
00:23:09,120 --> 00:23:13,709
data are password-protected zip files on
the bill defines this is anything that

352
00:23:13,710 --> 00:23:18,360
could be decrypted decipher Dakota
demodulated the obvious skated and the

353
00:23:18,360 --> 00:23:23,158
the reaches of this is the very far and
it's currently written we believe that

354
00:23:23,159 --> 00:23:28,260
it would actually outlaw forward secrecy
and forward secrecy is essentially

355
00:23:28,260 --> 00:23:31,260
having a new key on each transaction
which no one can recover if the master

356
00:23:31,260 --> 00:23:36,570
keys are collected but you know when i
go back and look at the netherlands once

357
00:23:36,570 --> 00:23:39,539
again i see the Dutch government backing
strong encryption and condemning back

358
00:23:39,539 --> 00:23:41,220
doors so Bravo

359
00:23:41,220 --> 00:23:49,230
this has serious chilling effects across
major populations like for example in

360
00:23:49,230 --> 00:23:53,789
the United States a staggering number of
Americans according to this washington

361
00:23:53,789 --> 00:23:56,490
post article and stop using the internet
the way they used to

362
00:23:56,490 --> 00:24:00,480
and this is because of things like the
revelations from Edward Snowden

363
00:24:00,480 --> 00:24:06,240
pervasive monitoring by governments and
continued breaches of personal data on

364
00:24:06,240 --> 00:24:09,779
the internet once again because
companies failed to encrypt and protect

365
00:24:09,779 --> 00:24:14,549
data at rest and this limiting of ideas

366
00:24:14,549 --> 00:24:19,019
the limiting of opinions that they may
express online is not the world that we

367
00:24:19,019 --> 00:24:20,590
should strive for

368
00:24:20,590 --> 00:24:25,720
so what can you do many of you in the
room develop and work with technologies

369
00:24:25,720 --> 00:24:26,679
on a daily basis

370
00:24:26,679 --> 00:24:31,659
i'm sure many of your own web servers um
if you're in charge of http-based

371
00:24:31,659 --> 00:24:34,960
servers and and services i highly
recommend that you implement always on

372
00:24:34,960 --> 00:24:40,480
HTTPS there are other technologies that
can enhance the security of your web

373
00:24:40,480 --> 00:24:42,490
service for like example

374
00:24:42,490 --> 00:24:47,679
hpk P&H sts a perfect forward secrecy
and there's a number of tools available

375
00:24:47,679 --> 00:24:52,419
to you things like SL labs and you can
also get yourself added to the to the

376
00:24:52,419 --> 00:24:56,380
preload listing chrome which will make
sure that the browser by default always

377
00:24:56,380 --> 00:25:01,690
talks HTTPS and if you think it's hard
it's it's not um if you use something

378
00:25:01,690 --> 00:25:06,520
like let's encrypt uh let's encrypt as a
service that simplifies the process of

379
00:25:06,520 --> 00:25:10,090
deploying and installing ssl
certificates into web browsers and

380
00:25:10,090 --> 00:25:15,850
Mozilla has graciously created a site
that will tell you how to configure your

381
00:25:15,850 --> 00:25:20,678
software to have the strongest possible
secure cipher suites and this is

382
00:25:20,679 --> 00:25:23,830
available online for free and you know
and it's been working

383
00:25:23,830 --> 00:25:29,740
because when we look at let's encrypt in
the last days i think this is a almost

384
00:25:29,740 --> 00:25:30,640
last wha

385
00:25:30,640 --> 00:25:35,169
less than a year less than a year we've
seen 3.7 million certificates issued and

386
00:25:35,169 --> 00:25:39,100
installed by let's encrypt and that's a
much greater much greater view of

387
00:25:39,100 --> 00:25:42,879
security that we've seen in the past and
you know if you're not running a web

388
00:25:42,880 --> 00:25:46,360
server in your developer you know
encrypt data at risk at rest encrypted

389
00:25:46,360 --> 00:25:46,870
in transit

390
00:25:46,870 --> 00:25:51,070
even within your own network and you
know one thing i see a lot that's a lot

391
00:25:51,070 --> 00:25:54,520
of grant proposals were people try to
reinvent a secure messaging wheel please

392
00:25:54,520 --> 00:25:55,840
please don't do that anymore

393
00:25:55,840 --> 00:26:01,899
um I don't think that many people are
capable of writing strong end-to-end

394
00:26:01,899 --> 00:26:05,199
encryption and there are open source
libraries out there for implementing

395
00:26:05,200 --> 00:26:09,370
this and we should work together on
secure messaging we should not silo this

396
00:26:09,370 --> 00:26:14,709
this knowledge if you're an end user and
asthma and all of us our end users

397
00:26:14,710 --> 00:26:17,740
um no your vulnerabilities know your
threat model you know you will have a

398
00:26:17,740 --> 00:26:20,190
very different world if you're a
security researcher

399
00:26:20,190 --> 00:26:24,480
I or journalists working in a country
that's fighting for democracy there

400
00:26:24,480 --> 00:26:29,159
it's very different you know promote
end-to-end encryption and the places you

401
00:26:29,159 --> 00:26:30,000
work

402
00:26:30,000 --> 00:26:33,659
use strong passwords use password
managers we've probably said these

403
00:26:33,659 --> 00:26:38,009
things a thousand times in the in the
security community but we still need to

404
00:26:38,009 --> 00:26:41,759
keep pushing these issues and you know
other options for you with things like

405
00:26:41,759 --> 00:26:45,360
tour and HTTPS Everywhere that can
protect you and from political

406
00:26:45,360 --> 00:26:49,740
standpoint demand your representatives
and governments block anti encryption

407
00:26:49,740 --> 00:26:50,429
bills

408
00:26:50,429 --> 00:26:54,090
you can help the eff you can help the
ACLU and other privacy promoting

409
00:26:54,090 --> 00:26:57,750
organizations with your donations and
your time and while we can have this

410
00:26:57,750 --> 00:26:59,129
fight with technology

411
00:26:59,129 --> 00:27:02,908
it doesn't really end and so we solve
the problem with proper legislation and

412
00:27:02,909 --> 00:27:06,840
pressing cases and I feel that in this
we can work together to make the

413
00:27:06,840 --> 00:27:09,840
internet more secure and I thank you for
your time

414
00:27:09,840 --> 00:27:12,840
it's been an honor to speak to you

415
00:27:14,540 --> 00:27:15,649
yeah

