1
00:00:42,960 --> 00:00:51,170
so today's talk my topic is hack object

2
00:00:47,070 --> 00:00:55,980
detector like training a neural network

3
00:00:51,170 --> 00:00:58,950
No so a little bit about myself and I'm

4
00:00:55,980 --> 00:01:02,250
a security researcher in battle-ax lab

5
00:00:58,950 --> 00:01:06,479
as a profession and I'm also an amateur

6
00:01:02,250 --> 00:01:10,340
player in League of Legends ok so

7
00:01:06,479 --> 00:01:13,020
today's today's agenda covers first is a

8
00:01:10,340 --> 00:01:16,009
background object detector so a

9
00:01:13,020 --> 00:01:19,890
deception of course and we will accept

10
00:01:16,009 --> 00:01:21,720
evaporate more on this topic introducing

11
00:01:19,890 --> 00:01:24,149
some concept help you to understand more

12
00:01:21,720 --> 00:01:27,390
because I know a lot of people come from

13
00:01:24,149 --> 00:01:31,680
cybersecurity but with less AI knowledge

14
00:01:27,390 --> 00:01:34,710
and I think this track is more popular

15
00:01:31,680 --> 00:01:38,520
recently but it's not it's a kind of

16
00:01:34,710 --> 00:01:41,339
traditional cybersecurity track and the

17
00:01:38,520 --> 00:01:44,789
second topic we will discuss we will dig

18
00:01:41,340 --> 00:01:48,000
in more we will see or what's what's the

19
00:01:44,789 --> 00:01:52,080
object deception is and then we will

20
00:01:48,000 --> 00:01:55,860
introduce a new trick doing on top of

21
00:01:52,080 --> 00:01:59,548
the trick me introduced we will propose

22
00:01:55,860 --> 00:02:01,799
a small trick to enhance deception

23
00:01:59,549 --> 00:02:05,430
performance and there's a one more thing

24
00:02:01,799 --> 00:02:10,080
it's a little bit introduction about our

25
00:02:05,430 --> 00:02:14,970
ripple so some concept what is object

26
00:02:10,080 --> 00:02:17,519
detector so as we know there as deep

27
00:02:14,970 --> 00:02:20,780
learning is evolving very fast some in

28
00:02:17,519 --> 00:02:23,940
some tasks especially in computer vision

29
00:02:20,780 --> 00:02:26,820
people scientists have used the neural

30
00:02:23,940 --> 00:02:29,100
network to localize the object in a

31
00:02:26,820 --> 00:02:32,930
camera seeing and giving confidence

32
00:02:29,100 --> 00:02:39,120
about what the object actually is by

33
00:02:32,930 --> 00:02:44,970
returning a score and an adverse or at a

34
00:02:39,120 --> 00:02:48,360
visceral example it's kind of more known

35
00:02:44,970 --> 00:02:51,239
to smaller people is that it's a kind of

36
00:02:48,360 --> 00:02:54,840
picture that can fool your network by

37
00:02:51,239 --> 00:02:56,550
applying small perturbation and on top

38
00:02:54,840 --> 00:02:58,800
of these two technique

39
00:02:56,550 --> 00:03:04,320
we were into this object detector

40
00:02:58,800 --> 00:03:06,900
deception so here is a concrete example

41
00:03:04,320 --> 00:03:10,049
of what object detector is so we take

42
00:03:06,900 --> 00:03:13,140
the yellow v2 it's a very classical

43
00:03:10,050 --> 00:03:15,750
object detector which consists of nine

44
00:03:13,140 --> 00:03:19,049
convolutional layer three max pooling

45
00:03:15,750 --> 00:03:22,200
and some fully conducting layer so by

46
00:03:19,050 --> 00:03:27,060
getting the first image input from the

47
00:03:22,200 --> 00:03:32,310
very left top to the very rights button

48
00:03:27,060 --> 00:03:34,800
it returns the object looks like local

49
00:03:32,310 --> 00:03:37,140
location and it's prediction score and

50
00:03:34,800 --> 00:03:39,260
on the right you can see its

51
00:03:37,140 --> 00:03:45,000
implementation in tensorflow

52
00:03:39,260 --> 00:03:48,030
so how we stack the structure up so what

53
00:03:45,000 --> 00:03:50,940
object detector can do so I find a small

54
00:03:48,030 --> 00:03:59,730
video from YouTube and I hope you can

55
00:03:50,940 --> 00:04:03,709
enjoy that you should have sound but if

56
00:03:59,730 --> 00:04:03,709
it had sound its looks much cooler

57
00:04:19,440 --> 00:04:31,640
the digital audio so basically

58
00:04:35,010 --> 00:04:39,550
[Applause]

59
00:04:43,480 --> 00:04:49,420
[Applause]

60
00:04:46,310 --> 00:04:49,420
[Music]

61
00:04:54,320 --> 00:04:57,440
[Music]

62
00:05:04,110 --> 00:05:12,940
okay so so this is my idea is to show

63
00:05:09,700 --> 00:05:15,700
you what object detector is application

64
00:05:12,940 --> 00:05:19,360
scenario so you can be applied to smart

65
00:05:15,700 --> 00:05:22,630
robotics like self self-driving car and

66
00:05:19,360 --> 00:05:26,380
also surveillance camera may being

67
00:05:22,630 --> 00:05:30,389
beings a factory like molten monitoring

68
00:05:26,380 --> 00:05:34,450
the walkers behavior prevents like

69
00:05:30,389 --> 00:05:39,150
dangerous the prevents them from

70
00:05:34,450 --> 00:05:39,150
performing some dangerous thing

71
00:05:39,270 --> 00:05:47,229
so as for adverse for example this is a

72
00:05:43,510 --> 00:05:52,690
famous research paper published on ICA

73
00:05:47,230 --> 00:05:56,680
are on 2015 in Goodfellow so they find

74
00:05:52,690 --> 00:06:01,330
that as for AI classifies a

75
00:05:56,680 --> 00:06:03,310
classification model if the original

76
00:06:01,330 --> 00:06:05,830
picture be classified correctly as a

77
00:06:03,310 --> 00:06:11,500
panda by playing very small perturbation

78
00:06:05,830 --> 00:06:14,380
on top of that the the AI classification

79
00:06:11,500 --> 00:06:18,250
model we actually see this modified

80
00:06:14,380 --> 00:06:21,789
picture as given with even higher

81
00:06:18,250 --> 00:06:26,970
confidence so the so that we can see the

82
00:06:21,789 --> 00:06:26,969
AI model make a very confident mistake

83
00:06:27,390 --> 00:06:33,190
so so this this Technic actually

84
00:06:31,660 --> 00:06:36,100
inspired a lot of more and more

85
00:06:33,190 --> 00:06:39,100
researcher in this area to study what if

86
00:06:36,100 --> 00:06:41,740
the adversarial phenomena happens on

87
00:06:39,100 --> 00:06:44,650
object detector since this year very

88
00:06:41,740 --> 00:06:47,470
similar similar architecture the post

89
00:06:44,650 --> 00:06:53,099
connected consists of several

90
00:06:47,470 --> 00:06:55,990
convolution on-air and Max bullying so

91
00:06:53,100 --> 00:06:57,760
object detector deception is the

92
00:06:55,990 --> 00:07:04,360
combination with object detector and

93
00:06:57,760 --> 00:07:07,599
Edward anniversary example and as by dou

94
00:07:04,360 --> 00:07:11,560
X lab we have demonstrates the viability

95
00:07:07,600 --> 00:07:15,550
of how to conduct such attack in

96
00:07:11,560 --> 00:07:17,890
real-world scenario and it shows that by

97
00:07:15,550 --> 00:07:21,100
by showing such at the reservation in

98
00:07:17,890 --> 00:07:24,010
front of a baby the inception module of

99
00:07:21,100 --> 00:07:27,190
a self-driving car may be the starter

100
00:07:24,010 --> 00:07:29,530
car can find the target from the camera

101
00:07:27,190 --> 00:07:35,020
so it's actually a real threat in deep

102
00:07:29,530 --> 00:07:37,690
learning deep learning system and more

103
00:07:35,020 --> 00:07:42,880
recent I'm already too related work is

104
00:07:37,690 --> 00:07:45,010
there researcher have doing just just

105
00:07:42,880 --> 00:07:50,190
like what we were going to show today is

106
00:07:45,010 --> 00:07:53,560
there this sticker will find the people

107
00:07:50,190 --> 00:07:57,430
objects make them disappear under such

108
00:07:53,560 --> 00:08:00,910
detection so let me here's a little bit

109
00:07:57,430 --> 00:08:03,310
messed but I'll get quickly I can assure

110
00:08:00,910 --> 00:08:06,660
you these are correct but if you want to

111
00:08:03,310 --> 00:08:09,820
see the process you can see the scissor

112
00:08:06,660 --> 00:08:12,100
formulation so you know neural network

113
00:08:09,820 --> 00:08:14,710
training process that our objective is

114
00:08:12,100 --> 00:08:16,960
to find a set of weights in the

115
00:08:14,710 --> 00:08:18,789
architecture that can minimize the

116
00:08:16,960 --> 00:08:22,020
difference between the model output and

117
00:08:18,790 --> 00:08:25,720
and the real and the real-world

118
00:08:22,020 --> 00:08:28,270
information so in order to minimizes

119
00:08:25,720 --> 00:08:32,950
this distribution they use back

120
00:08:28,270 --> 00:08:36,460
propagation to learn to to adjust the

121
00:08:32,950 --> 00:08:39,160
mistake as for the object detector

122
00:08:36,460 --> 00:08:41,680
deception process it's the kind of

123
00:08:39,159 --> 00:08:44,439
reversed one so with the modal model

124
00:08:41,679 --> 00:08:47,380
weights unchanged we only modified the

125
00:08:44,440 --> 00:08:52,840
picture inputs which is a perturbation

126
00:08:47,380 --> 00:08:56,260
as a delta and to find such a delta

127
00:08:52,840 --> 00:08:59,020
applying to all inputs it can print the

128
00:08:56,260 --> 00:09:05,040
target outputs choose a distribution you

129
00:08:59,020 --> 00:09:05,040
want and and to achieve your attack goal

130
00:09:05,850 --> 00:09:12,540
so so here's a little bit abstraction so

131
00:09:10,420 --> 00:09:16,660
let's say that convolution is a

132
00:09:12,540 --> 00:09:19,839
multiplication of weights and input X

133
00:09:16,660 --> 00:09:24,040
and there's a many element wise

134
00:09:19,840 --> 00:09:27,700
operation like the karela MX fully so so

135
00:09:24,040 --> 00:09:30,670
we can have their gradients like their

136
00:09:27,700 --> 00:09:34,090
transpose of weights

137
00:09:30,670 --> 00:09:38,920
use H&M represents the liquor radio and

138
00:09:34,090 --> 00:09:42,930
the Z max pooling so actually you know

139
00:09:38,920 --> 00:09:42,930
come you know object detector model

140
00:09:43,710 --> 00:09:48,280
since it consists of convolution max

141
00:09:46,360 --> 00:09:52,300
fully and a curator we can see them as a

142
00:09:48,280 --> 00:09:56,050
series of matrix multiplication it

143
00:09:52,300 --> 00:09:58,660
repeatedly and since the target we

144
00:09:56,050 --> 00:10:03,339
attack is a scalar output like a

145
00:09:58,660 --> 00:10:06,880
confidence it's white whitey I would

146
00:10:03,340 --> 00:10:09,040
represent white target so we can we can

147
00:10:06,880 --> 00:10:11,800
have the relationship we know the

148
00:10:09,040 --> 00:10:14,050
relationship between the input and the

149
00:10:11,800 --> 00:10:18,189
target is actually proportional to each

150
00:10:14,050 --> 00:10:26,140
other they are there are many matrix

151
00:10:18,190 --> 00:10:31,050
multiplications transpose so so this is

152
00:10:26,140 --> 00:10:31,050
how we actually control the motor output

153
00:10:31,410 --> 00:10:39,100
and this is the basic of the deception

154
00:10:34,420 --> 00:10:41,380
technique so also if you are interested

155
00:10:39,100 --> 00:10:42,940
you can see these two research is

156
00:10:41,380 --> 00:10:46,150
actually very similar to each other

157
00:10:42,940 --> 00:10:48,400
except for the on left they use many

158
00:10:46,150 --> 00:10:52,390
picture which is data we see the

159
00:10:48,400 --> 00:10:56,410
distribution they are the two are

160
00:10:52,390 --> 00:11:02,080
average operation among many image as a

161
00:10:56,410 --> 00:11:04,300
attack target so so since we notice this

162
00:11:02,080 --> 00:11:06,910
similarity the howard tray on your

163
00:11:04,300 --> 00:11:10,660
network ends it object detector

164
00:11:06,910 --> 00:11:13,150
deception we are inspired by this why

165
00:11:10,660 --> 00:11:17,530
not like initialize the input picture

166
00:11:13,150 --> 00:11:20,079
with a proper picture value so then so

167
00:11:17,530 --> 00:11:23,819
then it might lead to a better so better

168
00:11:20,080 --> 00:11:27,880
performance in the deception process so

169
00:11:23,820 --> 00:11:31,570
this is just with logic we just inspired

170
00:11:27,880 --> 00:11:35,950
by this so but they actually think it's

171
00:11:31,570 --> 00:11:38,980
work why because when training we think

172
00:11:35,950 --> 00:11:41,920
there by proper initialization we can

173
00:11:38,980 --> 00:11:43,790
have the picker why a people to pick a

174
00:11:41,920 --> 00:11:46,319
turtle why terrines

175
00:11:43,790 --> 00:11:49,829
optimization process which leads to a

176
00:11:46,320 --> 00:11:54,240
more effective combination of our

177
00:11:49,830 --> 00:11:56,970
gradients on Delta X and when we're

178
00:11:54,240 --> 00:11:59,430
showing the adversarial sticker in front

179
00:11:56,970 --> 00:12:02,300
of the camera it actually performing the

180
00:11:59,430 --> 00:12:05,810
multiplication multi metric

181
00:12:02,300 --> 00:12:11,219
multiplication back and result seeing

182
00:12:05,810 --> 00:12:15,930
more effective Delta Y change so we did

183
00:12:11,220 --> 00:12:17,940
such experiment so we take the yellow v2

184
00:12:15,930 --> 00:12:22,020
motto faster you'll of a two out and

185
00:12:17,940 --> 00:12:26,310
change its output we only take the class

186
00:12:22,020 --> 00:12:31,160
the talked a people out which is a YT

187
00:12:26,310 --> 00:12:33,719
here and we use of course the end-to-end

188
00:12:31,160 --> 00:12:36,510
differential differentiable object

189
00:12:33,720 --> 00:12:38,730
detector and we all talked like to

190
00:12:36,510 --> 00:12:41,520
twelve thousand twelve hundred images

191
00:12:38,730 --> 00:12:46,710
that contain e are attack target people

192
00:12:41,520 --> 00:12:49,949
and use the atom optimizer and the loss

193
00:12:46,710 --> 00:12:51,450
function so so we initially initialize a

194
00:12:49,950 --> 00:12:54,930
picture

195
00:12:51,450 --> 00:12:59,040
the original is initial value that had

196
00:12:54,930 --> 00:13:01,829
very small variance versus the improved

197
00:12:59,040 --> 00:13:05,730
version is there the initialize the

198
00:13:01,830 --> 00:13:09,390
picture has larger variance which which

199
00:13:05,730 --> 00:13:14,220
means it has more uncertainty at the

200
00:13:09,390 --> 00:13:20,600
starting point so in the attacking

201
00:13:14,220 --> 00:13:24,270
process we find that we think the attack

202
00:13:20,600 --> 00:13:27,480
it's not to improve the attack

203
00:13:24,270 --> 00:13:31,290
performance it's not free because we can

204
00:13:27,480 --> 00:13:34,290
see the in order to get such sticker it

205
00:13:31,290 --> 00:13:38,550
cost more the green light represents

206
00:13:34,290 --> 00:13:41,010
improved the method it has dr. loss so

207
00:13:38,550 --> 00:13:44,550
in theory we want to lost smallest

208
00:13:41,010 --> 00:13:46,950
possible right and at but and after

209
00:13:44,550 --> 00:13:49,640
every iteration we have a larger wire

210
00:13:46,950 --> 00:13:54,570
which results in more effective

211
00:13:49,640 --> 00:13:56,910
perturbation and in this way the sticker

212
00:13:54,570 --> 00:14:04,200
itself may have more color maybe

213
00:13:56,910 --> 00:14:06,810
or colorful because it spreads see from

214
00:14:04,200 --> 00:14:11,180
the starting point to the other

215
00:14:06,810 --> 00:14:15,959
color space and this is a time-lapse

216
00:14:11,180 --> 00:14:20,189
photography you can see on the left side

217
00:14:15,960 --> 00:14:22,830
its original method and the on the right

218
00:14:20,190 --> 00:14:27,150
side is the image from our improved

219
00:14:22,830 --> 00:14:30,630
method so the color is gradually moving

220
00:14:27,150 --> 00:14:36,480
from starting points from the end point

221
00:14:30,630 --> 00:14:38,700
and and we can use such images input to

222
00:14:36,480 --> 00:14:39,960
fool the object detector to hide to

223
00:14:38,700 --> 00:14:42,390
achieve Yoko

224
00:14:39,960 --> 00:14:45,660
in this scenario we can use this sticker

225
00:14:42,390 --> 00:14:54,600
to kind people handle people detection

226
00:14:45,660 --> 00:14:57,870
from the camera so so as I said to to

227
00:14:54,600 --> 00:15:00,720
hind people from object detector is to

228
00:14:57,870 --> 00:15:04,860
show the sticker so about how to improve

229
00:15:00,720 --> 00:15:07,200
the its effectiveness so so the one in

230
00:15:04,860 --> 00:15:10,890
one case is there it shows a sticker

231
00:15:07,200 --> 00:15:15,480
right in front of it and and then we use

232
00:15:10,890 --> 00:15:19,380
hand or use other trick to to block it

233
00:15:15,480 --> 00:15:21,420
like not showing it at all and then see

234
00:15:19,380 --> 00:15:28,640
the model output and see what's there

235
00:15:21,420 --> 00:15:31,589
differences and here is a short key so

236
00:15:28,640 --> 00:15:36,210
actually so you can see a little pulse

237
00:15:31,590 --> 00:15:39,690
here the X and x axis is actually the

238
00:15:36,210 --> 00:15:43,110
time and YX is what our output target y

239
00:15:39,690 --> 00:15:45,480
here so when the line dropped down we

240
00:15:43,110 --> 00:15:48,330
actually shows a sticker to the camera

241
00:15:45,480 --> 00:15:51,900
so that the motor output is smaller and

242
00:15:48,330 --> 00:15:55,650
then we block our address or sticker and

243
00:15:51,900 --> 00:15:58,980
the motor Apple get speaker so the the

244
00:15:55,650 --> 00:16:02,880
deeper the confidence time drop the more

245
00:15:58,980 --> 00:16:05,310
more effective the adversary's example

246
00:16:02,880 --> 00:16:09,210
is so you can see the improved the

247
00:16:05,310 --> 00:16:10,739
version it has a larger curve when we

248
00:16:09,210 --> 00:16:13,730
make sure

249
00:16:10,740 --> 00:16:17,910
make the sticker in front of the camera

250
00:16:13,730 --> 00:16:25,250
which which also improved proof that

251
00:16:17,910 --> 00:16:28,829
it's more effective and and of course we

252
00:16:25,250 --> 00:16:30,990
we think this is a phenomena there exist

253
00:16:28,830 --> 00:16:33,300
in all of the object detector no matter

254
00:16:30,990 --> 00:16:36,810
in which frame argue right

255
00:16:33,300 --> 00:16:40,800
we just won share with everyone there

256
00:16:36,810 --> 00:16:43,140
how to make such pattern and and if you

257
00:16:40,800 --> 00:16:46,770
are interested in like creating one you

258
00:16:43,140 --> 00:16:52,470
can see more detail in the in the Cote

259
00:16:46,770 --> 00:17:04,439
not showing the link and thank you for

260
00:16:52,470 --> 00:17:05,819
listening he thank you so much Jay so we

261
00:17:04,439 --> 00:17:08,160
have some time now for Question and

262
00:17:05,819 --> 00:17:10,349
Answer so I thought I would throw it

263
00:17:08,160 --> 00:17:14,730
open to the floor first any questions

264
00:17:10,349 --> 00:17:17,819
from the floor you get a prize if Jay

265
00:17:14,730 --> 00:17:21,030
likes your question yeah yeah don't have

266
00:17:17,819 --> 00:17:26,879
to be very technical but also like its

267
00:17:21,030 --> 00:17:30,030
application scenario don't be shy no

268
00:17:26,880 --> 00:17:32,100
okay if not then I'll ask we'll look at

269
00:17:30,030 --> 00:17:35,490
the questions that we got from slide

270
00:17:32,100 --> 00:17:38,040
over there on the screen the top voted

271
00:17:35,490 --> 00:17:40,770
Christian is from pokey are you here

272
00:17:38,040 --> 00:17:43,200
pokey cuz you're gonna pay you in a

273
00:17:40,770 --> 00:17:46,830
price because yours oh you beat the

274
00:17:43,200 --> 00:17:49,050
previous record you have 13 votes how

275
00:17:46,830 --> 00:17:52,439
can we mitigate this type of deception

276
00:17:49,050 --> 00:17:55,590
deception deception okay yes I think

277
00:17:52,440 --> 00:17:58,380
this is already good question because

278
00:17:55,590 --> 00:18:00,809
it's uh actually we don't want such a

279
00:17:58,380 --> 00:18:04,290
phenomenal existing our current system

280
00:18:00,809 --> 00:18:08,879
right because we leave more autonomy out

281
00:18:04,290 --> 00:18:14,149
there to AI assistant so so as we have

282
00:18:08,880 --> 00:18:16,830
shown that the output was controlled by

283
00:18:14,150 --> 00:18:19,470
carefully crafted inputs the

284
00:18:16,830 --> 00:18:23,070
perturbation and since the perturbation

285
00:18:19,470 --> 00:18:24,540
is the perturbation equals to the

286
00:18:23,070 --> 00:18:28,230
adversary example equal

287
00:18:24,540 --> 00:18:30,389
to the special X input so so this

288
00:18:28,230 --> 00:18:34,100
perturbation actually leverage the

289
00:18:30,390 --> 00:18:38,340
gradient information by by multiply

290
00:18:34,100 --> 00:18:43,459
multiply on the gradients we have we can

291
00:18:38,340 --> 00:18:47,520
bend the target output to a direction to

292
00:18:43,460 --> 00:18:51,780
abnormal direction so in order to

293
00:18:47,520 --> 00:18:56,240
mitigate this maybe we can look into how

294
00:18:51,780 --> 00:19:01,590
to prevent the gradient information

295
00:18:56,240 --> 00:19:04,970
exposed to like malicious people and

296
00:19:01,590 --> 00:19:08,310
also maybe we can from model

297
00:19:04,970 --> 00:19:10,890
manufacturer perspective maybe we can do

298
00:19:08,310 --> 00:19:14,520
some special trick in training the

299
00:19:10,890 --> 00:19:19,050
neural network to obtaining such a way

300
00:19:14,520 --> 00:19:22,410
so that the evil ways

301
00:19:19,050 --> 00:19:27,360
malicious inputs the model can cannot

302
00:19:22,410 --> 00:19:28,740
have a very big very big shift from the

303
00:19:27,360 --> 00:19:32,850
normal distribution

304
00:19:28,740 --> 00:19:34,860
maybe we can shrink the weights shrink

305
00:19:32,850 --> 00:19:38,219
the weights itself to a smaller smaller

306
00:19:34,860 --> 00:19:42,959
version and so there with the assist the

307
00:19:38,220 --> 00:19:46,380
image input is between 0 and to 255

308
00:19:42,960 --> 00:19:48,120
I cannot exceed this so we can in this

309
00:19:46,380 --> 00:19:52,230
way maybe we can control the model

310
00:19:48,120 --> 00:19:54,899
output but I think it's need it more

311
00:19:52,230 --> 00:19:56,790
proof and need more experiment to see if

312
00:19:54,900 --> 00:20:05,820
this work this is only a research idea

313
00:19:56,790 --> 00:20:08,580
so maybe a maybe a paper thank you um

314
00:20:05,820 --> 00:20:12,689
that present is that gift is for the

315
00:20:08,580 --> 00:20:15,689
prize rather is for Pocky ok well done I

316
00:20:12,690 --> 00:20:18,230
think that's the record 15 votes already

317
00:20:15,690 --> 00:20:23,400
well done

318
00:20:18,230 --> 00:20:26,760
ok how about the next question oh the

319
00:20:23,400 --> 00:20:28,080
cheap general cheap tricks or ok quick

320
00:20:26,760 --> 00:20:30,210
and dirty tricks I guess that can

321
00:20:28,080 --> 00:20:31,919
achieve object detection I'm presuming

322
00:20:30,210 --> 00:20:33,990
that's what you mean with a small

323
00:20:31,920 --> 00:20:38,610
perturbation such as whether a certain

324
00:20:33,990 --> 00:20:40,140
color or shape is more successful so

325
00:20:38,610 --> 00:20:43,080
we actually did the experiment by

326
00:20:40,140 --> 00:20:47,670
printing random number or random color

327
00:20:43,080 --> 00:20:50,520
as a sticker to show but it doesn't it

328
00:20:47,670 --> 00:20:54,890
doesn't have any effective effective net

329
00:20:50,520 --> 00:20:58,470
Sounders object detector but I think

330
00:20:54,890 --> 00:21:00,299
it's more like a functionality question

331
00:20:58,470 --> 00:21:03,570
about the model itself

332
00:21:00,299 --> 00:21:06,990
maybe the object detector are less

333
00:21:03,570 --> 00:21:10,250
sensitive or less effective for some

334
00:21:06,990 --> 00:21:15,780
scenario maybe it can be improved by a

335
00:21:10,250 --> 00:21:18,750
training process but I said that there's

336
00:21:15,780 --> 00:21:24,470
very existence as a attack technique

337
00:21:18,750 --> 00:21:27,570
except for this one there's also some

338
00:21:24,470 --> 00:21:31,530
you can search adversary example and

339
00:21:27,570 --> 00:21:33,418
they creates something similar but the

340
00:21:31,530 --> 00:21:36,418
idea is the same they want to achieve

341
00:21:33,419 --> 00:21:40,620
the same goal so yeah I think this is

342
00:21:36,419 --> 00:21:42,450
the answer okay before I go to the next

343
00:21:40,620 --> 00:21:44,689
question on slide or any questions from

344
00:21:42,450 --> 00:21:44,690
the floor

345
00:21:45,080 --> 00:21:51,389
no perhaps you'd like to go to the next

346
00:21:48,630 --> 00:21:57,030
one James what's the difference between

347
00:21:51,390 --> 00:22:01,799
a sticker and poster attack so poster

348
00:21:57,030 --> 00:22:07,350
attack so can can the who is gah when -

349
00:22:01,799 --> 00:22:10,379
can you elaborate elaborate a first time

350
00:22:07,350 --> 00:22:13,918
just like oh I want picture got one is

351
00:22:10,380 --> 00:22:16,850
small one is big one then Oh what's the

352
00:22:13,919 --> 00:22:16,850
difference this side

353
00:22:17,010 --> 00:22:26,250
oh you mean the size there is two video

354
00:22:22,440 --> 00:22:31,049
on the prestige so yeah maybe answer

355
00:22:26,250 --> 00:22:33,830
this one yeah also the difference by so

356
00:22:31,049 --> 00:22:37,410
we study the paper they published there

357
00:22:33,830 --> 00:22:39,510
so we saw they call their code theory so

358
00:22:37,410 --> 00:22:45,150
there they are attacking objective is to

359
00:22:39,510 --> 00:22:52,060
minimize to let the sticker lowering the

360
00:22:45,150 --> 00:22:55,450
model output sets of images this is a

361
00:22:52,060 --> 00:22:59,950
is generate it under this this

362
00:22:55,450 --> 00:23:03,490
assumption versus our the the the other

363
00:22:59,950 --> 00:23:05,530
work the only attack the picture from a

364
00:23:03,490 --> 00:23:08,860
single image and they generate you to

365
00:23:05,530 --> 00:23:11,410
use their a perturbation as the as a

366
00:23:08,860 --> 00:23:14,139
tool to fool object detector so there's

367
00:23:11,410 --> 00:23:27,460
a there's a some differences between how

368
00:23:14,140 --> 00:23:32,340
they got the sticker but I mean so let's

369
00:23:27,460 --> 00:23:37,900
say there may be maybe we can talk a

370
00:23:32,340 --> 00:23:42,189
after offline is her yeah and yeah this

371
00:23:37,900 --> 00:23:46,240
is the answer for the question thank you

372
00:23:42,190 --> 00:23:48,580
any more questions from the floor if not

373
00:23:46,240 --> 00:23:51,790
can we go back to the next question on

374
00:23:48,580 --> 00:23:53,770
slide oh can you reliably fool multiple

375
00:23:51,790 --> 00:23:57,730
or diverse sets of object detection with

376
00:23:53,770 --> 00:24:00,100
the same adversarial example okay

377
00:23:57,730 --> 00:24:03,790
so today in today's slides we didn't

378
00:24:00,100 --> 00:24:06,490
talk about black box attack which is to

379
00:24:03,790 --> 00:24:10,780
use adverse or sticker are generated

380
00:24:06,490 --> 00:24:15,820
from this particular object detector to

381
00:24:10,780 --> 00:24:19,149
food another one pow-pow since as far to

382
00:24:15,820 --> 00:24:21,340
to our knowledge I'd say that this

383
00:24:19,150 --> 00:24:26,170
sticker have some sort of transfer

384
00:24:21,340 --> 00:24:29,379
ability it means there by leverages

385
00:24:26,170 --> 00:24:32,410
gradient information you have from one

386
00:24:29,380 --> 00:24:36,280
model the sticker you generated can also

387
00:24:32,410 --> 00:24:40,000
have effectiveness on the model you

388
00:24:36,280 --> 00:24:43,960
don't know despite of the different song

389
00:24:40,000 --> 00:24:46,840
model structure and training data so

390
00:24:43,960 --> 00:24:49,750
this phenomena I haven't been explained

391
00:24:46,840 --> 00:24:53,889
about the there are also research show

392
00:24:49,750 --> 00:24:57,840
they want to explain what happened so so

393
00:24:53,890 --> 00:25:00,790
this question can move reliably for

394
00:24:57,840 --> 00:25:03,370
multiple sets of object detector with

395
00:25:00,790 --> 00:25:05,649
same address for example a reliability

396
00:25:03,370 --> 00:25:07,840
or maybe no but multi

397
00:25:05,650 --> 00:25:13,590
diverse sets of object detector maybe

398
00:25:07,840 --> 00:25:13,590
yes okay and let's answer for this one

399
00:25:16,080 --> 00:25:23,110
okay next question let's answer the this

400
00:25:21,580 --> 00:25:24,970
one in your opinion could be could there

401
00:25:23,110 --> 00:25:33,059
be government interest in this could

402
00:25:24,970 --> 00:25:37,840
pick up from an interest it depends on

403
00:25:33,059 --> 00:25:40,530
if the if system is so important that it

404
00:25:37,840 --> 00:25:43,809
be used to a you know a scenario that's

405
00:25:40,530 --> 00:25:46,210
so leave out to the AI system to make

406
00:25:43,809 --> 00:25:49,480
the decision that is so important there

407
00:25:46,210 --> 00:25:51,940
the government is interested so I think

408
00:25:49,480 --> 00:25:53,740
if that's true I think maybe the

409
00:25:51,940 --> 00:26:02,200
government is interested will be

410
00:25:53,740 --> 00:26:04,840
interested in such technique can we use

411
00:26:02,200 --> 00:26:07,809
deep learning to increasingly create new

412
00:26:04,840 --> 00:26:10,178
malicious input to break existing

413
00:26:07,809 --> 00:26:11,950
objects the enter can we use deep

414
00:26:10,179 --> 00:26:13,870
learning to continuously create new

415
00:26:11,950 --> 00:26:15,880
malicious inputs to break existing

416
00:26:13,870 --> 00:26:22,600
object detector which is improving at

417
00:26:15,880 --> 00:26:26,020
the same time it it means which is

418
00:26:22,600 --> 00:26:28,330
improving at the same time I mean it

419
00:26:26,020 --> 00:26:32,580
means that as object detector grows

420
00:26:28,330 --> 00:26:35,470
stronger the attack was stronger or

421
00:26:32,580 --> 00:26:38,980
continuous or it means June how here can

422
00:26:35,470 --> 00:26:41,700
you cut can you can you elaborate on

423
00:26:38,980 --> 00:26:41,700
your question please

424
00:26:41,950 --> 00:26:48,010
[Music]

425
00:26:43,200 --> 00:26:50,710
so I guess as object detector actually

426
00:26:48,010 --> 00:26:52,690
evolved because you want to constantly

427
00:26:50,710 --> 00:26:55,450
actually are prevent this kind of

428
00:26:52,690 --> 00:26:57,490
attacks I guess a malicious attacker can

429
00:26:55,450 --> 00:26:59,350
also do the same so like just now the

430
00:26:57,490 --> 00:27:02,440
sticker example can you also use deep

431
00:26:59,350 --> 00:27:04,919
learning to create new stickers to

432
00:27:02,440 --> 00:27:11,860
actually try and break existing

433
00:27:04,920 --> 00:27:15,070
detectors yeah seeing if so in plaque

434
00:27:11,860 --> 00:27:19,539
box sitting so if the object detector

435
00:27:15,070 --> 00:27:24,850
evolved or with new structure in my

436
00:27:19,539 --> 00:27:29,919
like make may reduce the effectiveness

437
00:27:24,850 --> 00:27:33,189
for the odd sticker or but but if they

438
00:27:29,919 --> 00:27:35,859
obtain like the training data and the

439
00:27:33,190 --> 00:27:38,379
object detect detector structure they

440
00:27:35,859 --> 00:27:40,059
can train one and by training while and

441
00:27:38,379 --> 00:27:44,049
use that information to create a

442
00:27:40,059 --> 00:27:48,279
stronger sticker and then I make the

443
00:27:44,049 --> 00:27:51,129
attack more more effective I think

444
00:27:48,279 --> 00:27:53,619
that's that that can be exact the

445
00:27:51,129 --> 00:28:03,469
dynamic dynamic between the attack and

446
00:27:53,619 --> 00:28:06,709
defenses feel yeah oh thank you

447
00:28:03,470 --> 00:28:06,710
[Music]

448
00:28:13,049 --> 00:28:17,889
similar to the question before on the

449
00:28:15,519 --> 00:28:19,419
government interest and then the next

450
00:28:17,889 --> 00:28:21,219
one maybe you can take both of them what

451
00:28:19,419 --> 00:28:26,049
what was the biggest challenge you faced

452
00:28:21,220 --> 00:28:32,830
in this project for seeing having a

453
00:28:26,049 --> 00:28:35,649
financial incentive so so as a so since

454
00:28:32,830 --> 00:28:39,849
are working for PI 2 and we are using

455
00:28:35,649 --> 00:28:41,649
such technique so not not only in

456
00:28:39,849 --> 00:28:42,849
computer vision but also in some other

457
00:28:41,649 --> 00:28:47,289
fields

458
00:28:42,849 --> 00:28:51,178
maybe maybe so it's the kind of kind

459
00:28:47,289 --> 00:28:54,820
advanced research we haven't deal with

460
00:28:51,179 --> 00:28:58,359
real we haven't found there somebody use

461
00:28:54,820 --> 00:29:04,210
this as to do something but we think

462
00:28:58,359 --> 00:29:07,720
this is a meaningful project there and

463
00:29:04,210 --> 00:29:11,409
we want to show that the the model used

464
00:29:07,720 --> 00:29:13,269
by everybody but you can buy by just

465
00:29:11,409 --> 00:29:15,999
changing a few lines of code you can

466
00:29:13,269 --> 00:29:18,849
generate such sticker so we we think

467
00:29:15,999 --> 00:29:21,909
it's kind of it's a problem we want to

468
00:29:18,849 --> 00:29:27,609
share as for financial incentive maybe

469
00:29:21,909 --> 00:29:31,920
not for this this stage I'm not I didn't

470
00:29:27,609 --> 00:29:33,189
have too much source of on this second

471
00:29:31,920 --> 00:29:37,070
[Music]

472
00:29:33,190 --> 00:29:40,250
okay which question so we've given the

473
00:29:37,070 --> 00:29:42,470
prize for the most up voted question now

474
00:29:40,250 --> 00:29:45,410
is the prize for your favorite question

475
00:29:42,470 --> 00:29:47,210
my favorite question yes my favorite

476
00:29:45,410 --> 00:29:49,460
question is the first question the first

477
00:29:47,210 --> 00:29:53,150
one the first one who asked the first

478
00:29:49,460 --> 00:29:54,890
one I think the most Awkward well he

479
00:29:53,150 --> 00:29:56,810
already got a prize what's your what's

480
00:29:54,890 --> 00:30:00,940
your second favorite question favorite

481
00:29:56,810 --> 00:30:07,370
oh can you turn back to the

482
00:30:00,940 --> 00:30:13,040
transferability oh this one pop whoosh

483
00:30:07,370 --> 00:30:15,409
oh yeah this I think this is a very good

484
00:30:13,040 --> 00:30:26,629
question okay where's my bush okay well

485
00:30:15,410 --> 00:30:28,070
done okay big round of applause for Jay

486
00:30:26,630 --> 00:30:29,870
for being such a good sport and

487
00:30:28,070 --> 00:30:33,429
answering so many questions and for

488
00:30:29,870 --> 00:30:33,429
great presentation well done thank you

