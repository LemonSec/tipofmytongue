1
00:00:09,920 --> 00:00:12,160
the chaos of supply chain security risk

2
00:00:12,160 --> 00:00:17,639
with my system of trust not engineering

3
00:00:48,559 --> 00:00:51,039
the next session is taming the uh chaos

4
00:00:51,039 --> 00:00:52,960
of supply chain security risk with

5
00:00:52,960 --> 00:00:56,879
miters system of trust um by um

6
00:00:56,879 --> 00:00:59,120
robert martin um so in the past we have

7
00:00:59,120 --> 00:01:02,000
seen many um supply chain issues for

8
00:01:02,000 --> 00:01:03,840
instance in the past there was

9
00:01:03,840 --> 00:01:06,400
authors inserting malicious code in npm

10
00:01:06,400 --> 00:01:08,479
packages or

11
00:01:08,479 --> 00:01:10,159
in terms of physical security there are

12
00:01:10,159 --> 00:01:13,520
servers that was embedded with malicious

13
00:01:13,520 --> 00:01:14,640
chips

14
00:01:14,640 --> 00:01:16,159
on the way

15
00:01:16,159 --> 00:01:18,400
so

16
00:01:19,040 --> 00:01:22,159
the speaker will introduce new methods

17
00:01:22,159 --> 00:01:24,159
or systems to tackle this sort of

18
00:01:24,159 --> 00:01:25,759
problem so

19
00:01:25,759 --> 00:01:27,439
let's welcome

20
00:01:27,439 --> 00:01:31,758
robert martin with an approach

21
00:01:33,220 --> 00:01:34,720
[Applause]

22
00:01:34,720 --> 00:01:35,920
good morning

23
00:01:35,920 --> 00:01:38,320
thank you for this opportunity to

24
00:01:38,320 --> 00:01:41,200
talk to you about mitre's system of

25
00:01:41,200 --> 00:01:42,479
trust

26
00:01:42,479 --> 00:01:45,840
which is aimed at helping with

27
00:01:45,840 --> 00:01:49,040
the broad problem of supply chain

28
00:01:49,040 --> 00:01:50,399
security

29
00:01:50,399 --> 00:01:52,560
i hope to

30
00:01:52,560 --> 00:01:55,439
give you a good understanding of what

31
00:01:55,439 --> 00:01:57,759
motivated it and

32
00:01:57,759 --> 00:02:00,079
what we're trying to do with it

33
00:02:00,079 --> 00:02:02,960
uh my name is robert martin

34
00:02:02,960 --> 00:02:05,759
i go by bob but

35
00:02:05,759 --> 00:02:08,720
you may know some of my work i helped

36
00:02:08,720 --> 00:02:09,919
with the

37
00:02:09,919 --> 00:02:12,400
common vulnerabilities and exposures the

38
00:02:12,400 --> 00:02:14,400
cve effort

39
00:02:14,400 --> 00:02:17,760
which we mitre launched 22 years ago

40
00:02:17,760 --> 00:02:20,879
and then about 18 years ago

41
00:02:20,879 --> 00:02:22,400
we created

42
00:02:22,400 --> 00:02:24,879
the common weakness enumeration

43
00:02:24,879 --> 00:02:28,720
of to list the weaknesses and software

44
00:02:28,720 --> 00:02:31,520
that lead to vulnerabilities

45
00:02:31,520 --> 00:02:33,840
so just as a

46
00:02:33,840 --> 00:02:38,720
kind of level setting so we're all

47
00:02:38,720 --> 00:02:40,160
together here

48
00:02:40,160 --> 00:02:41,920
on

49
00:02:41,920 --> 00:02:44,080
what i'm going to be talking about

50
00:02:44,080 --> 00:02:46,959
when we think about supply chains they

51
00:02:46,959 --> 00:02:48,560
basically

52
00:02:48,560 --> 00:02:49,920
bring

53
00:02:49,920 --> 00:02:52,640
harvested materials

54
00:02:52,640 --> 00:02:55,280
and created materials

55
00:02:55,280 --> 00:02:58,800
and bring them together into

56
00:02:58,800 --> 00:03:00,160
intermediate

57
00:03:00,160 --> 00:03:01,360
goods

58
00:03:01,360 --> 00:03:04,560
that then follow some pattern and get

59
00:03:04,560 --> 00:03:06,720
created into

60
00:03:06,720 --> 00:03:09,599
goods that then are distributed

61
00:03:09,599 --> 00:03:13,440
and and end up in the end user's hands

62
00:03:13,440 --> 00:03:14,640
and then

63
00:03:14,640 --> 00:03:18,239
often there's a disposal step now the

64
00:03:18,239 --> 00:03:20,720
reason supply chains are hard

65
00:03:20,720 --> 00:03:23,680
is because they're international

66
00:03:23,680 --> 00:03:26,720
very few supply chains

67
00:03:26,720 --> 00:03:29,840
happen locally

68
00:03:29,840 --> 00:03:33,519
and this is because one uh the very

69
00:03:33,519 --> 00:03:36,640
economical uh rates

70
00:03:36,640 --> 00:03:39,280
that sea transportation

71
00:03:39,280 --> 00:03:42,720
have taken over the last couple decades

72
00:03:42,720 --> 00:03:47,040
and that does not seem to be changing so

73
00:03:47,040 --> 00:03:48,879
we can expect

74
00:03:48,879 --> 00:03:49,680
that

75
00:03:49,680 --> 00:03:52,799
supply chains are going to be global

76
00:03:52,799 --> 00:03:54,319
for

77
00:03:54,319 --> 00:03:57,439
time going forward

78
00:03:57,439 --> 00:04:00,480
so that general pattern of taking

79
00:04:00,480 --> 00:04:02,000
materials

80
00:04:02,000 --> 00:04:03,920
following a design

81
00:04:03,920 --> 00:04:06,560
going through some type of production

82
00:04:06,560 --> 00:04:08,400
and then distribution

83
00:04:08,400 --> 00:04:11,040
process to a customer

84
00:04:11,040 --> 00:04:13,680
fits many different kinds of supply

85
00:04:13,680 --> 00:04:15,280
chains

86
00:04:15,280 --> 00:04:18,399
whether it's talking about seafood

87
00:04:18,399 --> 00:04:21,600
and the fish supply chain

88
00:04:21,600 --> 00:04:23,520
where you're harvesting landing

89
00:04:23,520 --> 00:04:24,880
distributing

90
00:04:24,880 --> 00:04:29,080
and then providing to the consumer or

91
00:04:29,080 --> 00:04:31,520
microelectronics or chips

92
00:04:31,520 --> 00:04:32,800
where you're

93
00:04:32,800 --> 00:04:35,919
using tools to build

94
00:04:35,919 --> 00:04:39,919
masks that then get created in fabs

95
00:04:39,919 --> 00:04:43,520
and then packaged and provisioned and

96
00:04:43,520 --> 00:04:47,120
put into all kinds of devices

97
00:04:47,120 --> 00:04:49,520
or you're talking about software

98
00:04:49,520 --> 00:04:52,000
where you're assembling packages and

99
00:04:52,000 --> 00:04:54,639
frameworks and components

100
00:04:54,639 --> 00:04:57,280
you're putting them into some build

101
00:04:57,280 --> 00:04:58,479
process

102
00:04:58,479 --> 00:05:00,960
test package and release

103
00:05:00,960 --> 00:05:03,040
so it really doesn't matter whether

104
00:05:03,040 --> 00:05:04,639
you're doing fish

105
00:05:04,639 --> 00:05:06,720
chips or software

106
00:05:06,720 --> 00:05:09,520
supply chain has many of the same

107
00:05:09,520 --> 00:05:11,759
activities and processes

108
00:05:11,759 --> 00:05:13,840
and risks

109
00:05:13,840 --> 00:05:17,120
the other thing that's changed over the

110
00:05:17,120 --> 00:05:19,120
last 15 years

111
00:05:19,120 --> 00:05:22,720
is that we've gone from where computers

112
00:05:22,720 --> 00:05:24,880
were an i.t

113
00:05:24,880 --> 00:05:25,680
thing

114
00:05:25,680 --> 00:05:27,280
in companies

115
00:05:27,280 --> 00:05:30,479
to now we have software-enabled

116
00:05:30,479 --> 00:05:33,600
automation in almost every

117
00:05:33,600 --> 00:05:35,759
aspect of our life

118
00:05:35,759 --> 00:05:38,560
at the same time that was happening

119
00:05:38,560 --> 00:05:41,360
we went from building software

120
00:05:41,360 --> 00:05:45,120
as a bespoke a separate thing

121
00:05:45,120 --> 00:05:48,240
where you wrote pretty much all of it

122
00:05:48,240 --> 00:05:52,000
except for maybe the drivers to talk to

123
00:05:52,000 --> 00:05:53,600
the hardware

124
00:05:53,600 --> 00:05:54,639
to now

125
00:05:54,639 --> 00:05:56,960
it's basically an assembly

126
00:05:56,960 --> 00:05:59,600
where you're using other people's work

127
00:05:59,600 --> 00:06:03,039
to bring it together to actually produce

128
00:06:03,039 --> 00:06:05,520
the capability you're looking at so when

129
00:06:05,520 --> 00:06:08,880
you combine those two things together

130
00:06:08,880 --> 00:06:10,960
now when something goes wrong in

131
00:06:10,960 --> 00:06:12,240
software

132
00:06:12,240 --> 00:06:13,919
it could end up

133
00:06:13,919 --> 00:06:16,479
harming property or lives

134
00:06:16,479 --> 00:06:19,520
so the consequences of mistakes

135
00:06:19,520 --> 00:06:22,720
in software or attacks against software

136
00:06:22,720 --> 00:06:25,120
have dramatically shifted in the last 10

137
00:06:25,120 --> 00:06:27,120
years

138
00:06:27,120 --> 00:06:28,160
and this

139
00:06:28,160 --> 00:06:30,400
is just a depiction of many of the

140
00:06:30,400 --> 00:06:31,680
industries

141
00:06:31,680 --> 00:06:34,759
that have really adopted

142
00:06:34,759 --> 00:06:37,280
software-enabled automation

143
00:06:37,280 --> 00:06:38,319
and

144
00:06:38,319 --> 00:06:40,080
you know have

145
00:06:40,080 --> 00:06:41,199
very

146
00:06:41,199 --> 00:06:44,639
much benefited from that capability

147
00:06:44,639 --> 00:06:47,440
and often haven't realized

148
00:06:47,440 --> 00:06:49,840
the responsibility

149
00:06:49,840 --> 00:06:52,560
in safety and security

150
00:06:52,560 --> 00:06:56,400
that they're taking on by using software

151
00:06:56,400 --> 00:06:59,120
and automation

152
00:06:59,120 --> 00:07:02,960
so when people talk about supply chains

153
00:07:02,960 --> 00:07:04,880
often they focus

154
00:07:04,880 --> 00:07:06,880
on attacks

155
00:07:06,880 --> 00:07:09,199
and intentional

156
00:07:09,199 --> 00:07:10,960
misbehaviors

157
00:07:10,960 --> 00:07:12,720
you know

158
00:07:12,720 --> 00:07:14,960
and things that they need to protect

159
00:07:14,960 --> 00:07:18,080
against and i will offer that

160
00:07:18,080 --> 00:07:21,039
it's also needs to be balanced

161
00:07:21,039 --> 00:07:24,160
with a look at the unintentional acts

162
00:07:24,160 --> 00:07:27,360
poor quality vulnerable software

163
00:07:27,360 --> 00:07:28,880
which are

164
00:07:28,880 --> 00:07:32,560
can take your systems down

165
00:07:32,560 --> 00:07:35,440
and cause harm to your organizations

166
00:07:35,440 --> 00:07:36,560
as

167
00:07:36,560 --> 00:07:40,240
easily as intentional acts or maybe more

168
00:07:40,240 --> 00:07:41,919
easily

169
00:07:41,919 --> 00:07:43,280
so

170
00:07:43,280 --> 00:07:46,880
what are supply chain risks that you

171
00:07:46,880 --> 00:07:48,800
need to manage

172
00:07:48,800 --> 00:07:51,520
there's many different perspectives

173
00:07:51,520 --> 00:07:53,680
whether it's services that you've

174
00:07:53,680 --> 00:07:54,960
outsourced

175
00:07:54,960 --> 00:07:57,840
or you're trying to understand how to

176
00:07:57,840 --> 00:07:59,039
acquire

177
00:07:59,039 --> 00:08:01,840
goods that can be trustworthy and

178
00:08:01,840 --> 00:08:03,440
dependable

179
00:08:03,440 --> 00:08:05,919
or you're worried about counterfeits

180
00:08:05,919 --> 00:08:08,319
or you have some high value

181
00:08:08,319 --> 00:08:11,280
item that you're trying to purchase and

182
00:08:11,280 --> 00:08:13,440
you're worried about the

183
00:08:13,440 --> 00:08:16,960
ict and software in it

184
00:08:16,960 --> 00:08:18,400
or you're just worried about the

185
00:08:18,400 --> 00:08:20,160
supplier and whether they're going to be

186
00:08:20,160 --> 00:08:21,440
around

187
00:08:21,440 --> 00:08:24,479
or your data or their data

188
00:08:24,479 --> 00:08:27,280
or you're just trying to make a make by

189
00:08:27,280 --> 00:08:28,639
decision

190
00:08:28,639 --> 00:08:32,080
all of these end up having different

191
00:08:32,080 --> 00:08:33,519
concerns

192
00:08:33,519 --> 00:08:34,799
and

193
00:08:34,799 --> 00:08:38,479
we end up thinking about the risks

194
00:08:38,479 --> 00:08:40,640
differently and so we spend a lot of

195
00:08:40,640 --> 00:08:41,760
time

196
00:08:41,760 --> 00:08:44,159
trying to understand each other

197
00:08:44,159 --> 00:08:46,800
as buyers and sellers

198
00:08:46,800 --> 00:08:50,000
as providers and consumers

199
00:08:50,000 --> 00:08:52,000
you know talk about

200
00:08:52,000 --> 00:08:55,760
supply chain and supply chain risks

201
00:08:55,760 --> 00:08:56,480
so

202
00:08:56,480 --> 00:09:00,000
we have noticed that when it comes to

203
00:09:00,000 --> 00:09:02,560
the question of what are supply chain

204
00:09:02,560 --> 00:09:05,600
risks what am i going to manage

205
00:09:05,600 --> 00:09:08,320
that people either start with a blank

206
00:09:08,320 --> 00:09:11,360
sheet of paper or a whiteboard and start

207
00:09:11,360 --> 00:09:14,800
writing down a list of things that occur

208
00:09:14,800 --> 00:09:16,720
to them they may have

209
00:09:16,720 --> 00:09:20,240
experienced firsthand or heard about

210
00:09:20,240 --> 00:09:21,360
or

211
00:09:21,360 --> 00:09:24,160
they say well the project over there

212
00:09:24,160 --> 00:09:26,880
seems to have a good handle on this

213
00:09:26,880 --> 00:09:29,279
let's borrow what they have

214
00:09:29,279 --> 00:09:32,240
both of these have problems

215
00:09:32,240 --> 00:09:35,200
one when you do a blank sheet of paper

216
00:09:35,200 --> 00:09:37,920
the words you use the way you think

217
00:09:37,920 --> 00:09:39,519
about the problem

218
00:09:39,519 --> 00:09:41,600
may be totally different than anyone

219
00:09:41,600 --> 00:09:43,519
else and so you're going to have a hard

220
00:09:43,519 --> 00:09:46,560
time communicating and understanding and

221
00:09:46,560 --> 00:09:48,560
leveraging other people's efforts and

222
00:09:48,560 --> 00:09:49,519
work

223
00:09:49,519 --> 00:09:52,000
and on the when you borrow from another

224
00:09:52,000 --> 00:09:53,120
project

225
00:09:53,120 --> 00:09:55,760
they may have a totally different sense

226
00:09:55,760 --> 00:09:56,959
of risk

227
00:09:56,959 --> 00:09:59,120
and risk aversion

228
00:09:59,120 --> 00:10:01,760
they may have different consequences to

229
00:10:01,760 --> 00:10:02,880
failure

230
00:10:02,880 --> 00:10:04,399
and their technology

231
00:10:04,399 --> 00:10:06,720
and personnel mix may be totally

232
00:10:06,720 --> 00:10:09,200
different and so you end up having to do

233
00:10:09,200 --> 00:10:11,440
a lot of adjustments

234
00:10:11,440 --> 00:10:14,560
so this is kind of the landscape

235
00:10:14,560 --> 00:10:16,800
now third-party risk management is a

236
00:10:16,800 --> 00:10:19,440
part of this but many people don't

237
00:10:19,440 --> 00:10:21,279
understand the very

238
00:10:21,279 --> 00:10:24,640
detailed set of risks that third-party

239
00:10:24,640 --> 00:10:27,680
risk management and ties entail

240
00:10:27,680 --> 00:10:30,160
also they don't think about attackers

241
00:10:30,160 --> 00:10:31,519
and counterfeits

242
00:10:31,519 --> 00:10:33,519
they may not understand all the

243
00:10:33,519 --> 00:10:35,200
different kinds of

244
00:10:35,200 --> 00:10:38,160
natural disasters and hazards i think

245
00:10:38,160 --> 00:10:39,519
most of us

246
00:10:39,519 --> 00:10:42,160
were surprised by the impact of the

247
00:10:42,160 --> 00:10:43,839
covid virus

248
00:10:43,839 --> 00:10:46,560
on our world economy

249
00:10:46,560 --> 00:10:47,600
also

250
00:10:47,600 --> 00:10:50,079
you know human hazards where

251
00:10:50,079 --> 00:10:53,519
um either in you know

252
00:10:53,519 --> 00:10:57,680
national corruption or civil disruption

253
00:10:57,680 --> 00:11:00,560
or corporate corruption can impact

254
00:11:00,560 --> 00:11:02,880
your supply chain

255
00:11:02,880 --> 00:11:06,640
so what i'm offering we call

256
00:11:06,640 --> 00:11:08,959
our supply chain security system of

257
00:11:08,959 --> 00:11:10,160
trust

258
00:11:10,160 --> 00:11:13,519
and it's basically a starting point

259
00:11:13,519 --> 00:11:16,560
and a vocabulary of what

260
00:11:16,560 --> 00:11:19,360
supply chain risks you may

261
00:11:19,360 --> 00:11:21,519
need to pay attention to

262
00:11:21,519 --> 00:11:23,279
and what we've done is we've been

263
00:11:23,279 --> 00:11:24,480
collecting

264
00:11:24,480 --> 00:11:27,040
from every source we can find

265
00:11:27,040 --> 00:11:30,320
any mention of a supply chain risk

266
00:11:30,320 --> 00:11:32,480
and putting it together and organizing

267
00:11:32,480 --> 00:11:34,079
it now

268
00:11:34,079 --> 00:11:37,279
if we just do that we'll have a huge

269
00:11:37,279 --> 00:11:40,800
list of risks that no organization could

270
00:11:40,800 --> 00:11:44,720
actually use so the other part of system

271
00:11:44,720 --> 00:11:46,079
of trust

272
00:11:46,079 --> 00:11:48,160
is a method for

273
00:11:48,160 --> 00:11:52,079
profiling or down selecting very quickly

274
00:11:52,079 --> 00:11:54,839
to a subset that actually you can

275
00:11:54,839 --> 00:11:58,560
evaluate and do your business with

276
00:11:58,560 --> 00:12:00,399
so that's the premise of what i'm going

277
00:12:00,399 --> 00:12:02,079
to be talking about

278
00:12:02,079 --> 00:12:04,320
now what is the basis of trust what are

279
00:12:04,320 --> 00:12:06,240
we talking about here

280
00:12:06,240 --> 00:12:08,880
we basically look at it in three

281
00:12:08,880 --> 00:12:10,639
dimensions

282
00:12:10,639 --> 00:12:12,720
risks from the supplier

283
00:12:12,720 --> 00:12:16,560
the supplies themselves and the services

284
00:12:16,560 --> 00:12:19,680
and we basically come up with 14

285
00:12:19,680 --> 00:12:22,079
top level risk areas

286
00:12:22,079 --> 00:12:26,000
that comprise the independent risks

287
00:12:26,000 --> 00:12:28,480
that you may need to assess

288
00:12:28,480 --> 00:12:30,399
and manage

289
00:12:30,399 --> 00:12:31,839
as you

290
00:12:31,839 --> 00:12:33,680
work with suppliers

291
00:12:33,680 --> 00:12:36,160
and the items they supply you or the

292
00:12:36,160 --> 00:12:37,279
services

293
00:12:37,279 --> 00:12:38,560
they provide

294
00:12:38,560 --> 00:12:41,120
now what are some examples so external

295
00:12:41,120 --> 00:12:43,040
influence

296
00:12:43,040 --> 00:12:44,639
here are some

297
00:12:44,639 --> 00:12:47,680
of the things that often are considered

298
00:12:47,680 --> 00:12:48,720
to be

299
00:12:48,720 --> 00:12:51,279
external influence risks

300
00:12:51,279 --> 00:12:52,480
similarly

301
00:12:52,480 --> 00:12:55,519
financial stability i mean if you pick

302
00:12:55,519 --> 00:12:58,000
a company to be your supplier

303
00:12:58,000 --> 00:12:59,360
you don't want them to go out of

304
00:12:59,360 --> 00:13:02,160
business next quarter you'd like them to

305
00:13:02,160 --> 00:13:04,800
be around and continue

306
00:13:04,800 --> 00:13:07,200
to provide you product that you selected

307
00:13:07,200 --> 00:13:08,399
them for

308
00:13:08,399 --> 00:13:09,760
similarly

309
00:13:09,760 --> 00:13:12,399
if they have a good product you want to

310
00:13:12,399 --> 00:13:13,600
make sure

311
00:13:13,600 --> 00:13:16,000
that it continues to be

312
00:13:16,000 --> 00:13:18,480
uh and fulfill what you need out of it

313
00:13:18,480 --> 00:13:20,639
so there's a

314
00:13:20,639 --> 00:13:23,839
whole set of risks that can come from

315
00:13:23,839 --> 00:13:25,120
your the

316
00:13:25,120 --> 00:13:27,680
failure to follow good hygiene

317
00:13:27,680 --> 00:13:30,240
so those are three examples

318
00:13:30,240 --> 00:13:32,959
this picture here is showing you an

319
00:13:32,959 --> 00:13:36,079
overview and i just showed you these

320
00:13:36,079 --> 00:13:37,200
parts

321
00:13:37,200 --> 00:13:39,839
at this top level

322
00:13:39,839 --> 00:13:43,440
and so there's more areas and i

323
00:13:43,440 --> 00:13:45,920
will offer you a place to go find out

324
00:13:45,920 --> 00:13:47,440
more about these

325
00:13:47,440 --> 00:13:50,320
but it really goes deeper so it's very

326
00:13:50,320 --> 00:13:53,200
basically think of it as a mind map

327
00:13:53,200 --> 00:13:55,680
where the center of the mind map

328
00:13:55,680 --> 00:13:58,000
is things that are common across all

329
00:13:58,000 --> 00:14:01,040
industries and out towards the edges are

330
00:14:01,040 --> 00:14:03,519
the risks that are specific to

331
00:14:03,519 --> 00:14:06,480
particular industries for instance

332
00:14:06,480 --> 00:14:07,920
counterfeits

333
00:14:07,920 --> 00:14:10,000
are something many industries worry

334
00:14:10,000 --> 00:14:12,480
about and have to deal with but how do

335
00:14:12,480 --> 00:14:15,360
you detect and manage counterfeits is

336
00:14:15,360 --> 00:14:18,639
very different if it's microelectronics

337
00:14:18,639 --> 00:14:20,800
or counterfeit software

338
00:14:20,800 --> 00:14:24,720
counterfeit sushi or handbags

339
00:14:24,720 --> 00:14:26,320
this

340
00:14:26,320 --> 00:14:29,920
knowledge we've put together a data

341
00:14:29,920 --> 00:14:34,160
model to knit together this

342
00:14:34,160 --> 00:14:36,720
hierarchy this vocabulary

343
00:14:36,720 --> 00:14:39,279
and it includes weighting so that you

344
00:14:39,279 --> 00:14:41,360
can score the risks

345
00:14:41,360 --> 00:14:44,160
and we've actually had to build a

346
00:14:44,160 --> 00:14:46,639
content management system

347
00:14:46,639 --> 00:14:49,120
so that we can do the second part of

348
00:14:49,120 --> 00:14:50,720
what i talked about

349
00:14:50,720 --> 00:14:52,160
which is

350
00:14:52,160 --> 00:14:54,959
come down to a sub set

351
00:14:54,959 --> 00:14:58,320
and do that actively and coherently

352
00:14:58,320 --> 00:15:00,720
so we've been doing a lot of piloting of

353
00:15:00,720 --> 00:15:01,680
this

354
00:15:01,680 --> 00:15:03,839
and one of the things we saw was the

355
00:15:03,839 --> 00:15:07,440
need to also be able to

356
00:15:07,440 --> 00:15:08,959
pull the

357
00:15:08,959 --> 00:15:11,839
stat subset that profile

358
00:15:11,839 --> 00:15:13,839
into a spreadsheet

359
00:15:13,839 --> 00:15:15,440
so that people can

360
00:15:15,440 --> 00:15:18,800
take it to a protected enclave and do

361
00:15:18,800 --> 00:15:21,680
the assessment because once you start

362
00:15:21,680 --> 00:15:24,320
actually putting answers to the risk

363
00:15:24,320 --> 00:15:27,360
questions it can get very sensitive very

364
00:15:27,360 --> 00:15:28,480
quickly

365
00:15:28,480 --> 00:15:30,639
so we've been doing several rounds of

366
00:15:30,639 --> 00:15:31,760
piloting

367
00:15:31,760 --> 00:15:35,680
these numbers there 11 3 1 6

368
00:15:35,680 --> 00:15:38,839
22 12 and so on are the number of

369
00:15:38,839 --> 00:15:42,720
organizations that we've piloted against

370
00:15:42,720 --> 00:15:44,639
and we've also been looking at how to

371
00:15:44,639 --> 00:15:46,560
present this material

372
00:15:46,560 --> 00:15:48,880
because once you get a lot of data it's

373
00:15:48,880 --> 00:15:50,240
very easy

374
00:15:50,240 --> 00:15:52,720
to miss the important things

375
00:15:52,720 --> 00:15:55,440
and so you know in the u.s

376
00:15:55,440 --> 00:15:57,920
if you're trying to work for

377
00:15:57,920 --> 00:16:00,560
the government you have to fill out a

378
00:16:00,560 --> 00:16:04,639
security clearance that's 18 19 pages of

379
00:16:04,639 --> 00:16:05,759
questions

380
00:16:05,759 --> 00:16:07,600
but if you answer

381
00:16:07,600 --> 00:16:11,040
yes i am a convicted felon

382
00:16:11,040 --> 00:16:13,600
it's a show stopper it's over it doesn't

383
00:16:13,600 --> 00:16:16,320
matter what you've answered to the other

384
00:16:16,320 --> 00:16:17,920
18 pages

385
00:16:17,920 --> 00:16:20,560
so there are similar risks

386
00:16:20,560 --> 00:16:22,639
in different industries that if they

387
00:16:22,639 --> 00:16:23,839
occur

388
00:16:23,839 --> 00:16:26,800
if that's it you need to know that

389
00:16:26,800 --> 00:16:29,600
nothing else matters and so we've been

390
00:16:29,600 --> 00:16:31,279
working how to

391
00:16:31,279 --> 00:16:34,800
fold that into our system of trust

392
00:16:34,800 --> 00:16:36,800
so to kind of

393
00:16:36,800 --> 00:16:37,920
walk through

394
00:16:37,920 --> 00:16:40,560
we have a data model the data model is

395
00:16:40,560 --> 00:16:42,959
being used to build the system of trust

396
00:16:42,959 --> 00:16:46,560
content the content is a hierarchy of

397
00:16:46,560 --> 00:16:49,120
the different kinds of risks that you

398
00:16:49,120 --> 00:16:52,320
may need to deal with for your supplier

399
00:16:52,320 --> 00:16:54,000
supply and service

400
00:16:54,000 --> 00:16:55,440
providers

401
00:16:55,440 --> 00:16:58,000
you come into it with a particular point

402
00:16:58,000 --> 00:16:59,680
of view

403
00:16:59,680 --> 00:17:02,959
and that lets you get a subset of the

404
00:17:02,959 --> 00:17:04,480
system of trust

405
00:17:04,480 --> 00:17:07,760
and then you assess against that subset

406
00:17:07,760 --> 00:17:09,839
if you have a different point of view

407
00:17:09,839 --> 00:17:12,160
you end up with a different part of the

408
00:17:12,160 --> 00:17:13,760
system of trust

409
00:17:13,760 --> 00:17:17,679
set of risks and you assess against that

410
00:17:17,679 --> 00:17:20,079
so what is the success

411
00:17:20,079 --> 00:17:22,400
here i'm showing you

412
00:17:22,400 --> 00:17:24,160
11 companies

413
00:17:24,160 --> 00:17:26,000
that we assessed

414
00:17:26,000 --> 00:17:27,839
using what we called

415
00:17:27,839 --> 00:17:33,280
pilot 1 which is a profile looking at

416
00:17:33,280 --> 00:17:35,600
financial issues

417
00:17:35,600 --> 00:17:37,600
cyber security issues and a couple

418
00:17:37,600 --> 00:17:39,760
others i'll show you the details in a

419
00:17:39,760 --> 00:17:43,440
moment it's basically five of the seven

420
00:17:43,440 --> 00:17:46,240
supplier risk areas but i wanted to show

421
00:17:46,240 --> 00:17:48,080
you in the upper left

422
00:17:48,080 --> 00:17:50,080
you can see in the middle there's this

423
00:17:50,080 --> 00:17:52,640
little blue area whereas if you look in

424
00:17:52,640 --> 00:17:55,200
the bottom right there's a much bigger

425
00:17:55,200 --> 00:17:58,000
blue area and just think of that as the

426
00:17:58,000 --> 00:18:01,039
risk surface area so there's a lot more

427
00:18:01,039 --> 00:18:04,960
risk going on in company 11 than any

428
00:18:04,960 --> 00:18:05,760
other

429
00:18:05,760 --> 00:18:08,160
of the companies and it becomes very

430
00:18:08,160 --> 00:18:10,720
apparent when you look at it this way

431
00:18:10,720 --> 00:18:13,600
but let's look at it a little closer

432
00:18:13,600 --> 00:18:16,720
so if the way to read this chart

433
00:18:16,720 --> 00:18:19,039
is the midi axis

434
00:18:19,039 --> 00:18:22,320
the external influences you can see here

435
00:18:22,320 --> 00:18:24,320
it's plotted to zero

436
00:18:24,320 --> 00:18:28,240
what that means is we saw no information

437
00:18:28,240 --> 00:18:30,320
saying that risk

438
00:18:30,320 --> 00:18:31,120
is

439
00:18:31,120 --> 00:18:33,280
present

440
00:18:33,280 --> 00:18:36,640
from any of the sub categories so if you

441
00:18:36,640 --> 00:18:38,320
look in the upper right

442
00:18:38,320 --> 00:18:40,160
you can see what those

443
00:18:40,160 --> 00:18:42,240
different subcategories

444
00:18:42,240 --> 00:18:44,880
of external influence are

445
00:18:44,880 --> 00:18:46,320
for this

446
00:18:46,320 --> 00:18:47,600
profile

447
00:18:47,600 --> 00:18:50,080
whereas if you look at the other areas

448
00:18:50,080 --> 00:18:51,919
there was something

449
00:18:51,919 --> 00:18:53,840
that was saying there was additional

450
00:18:53,840 --> 00:18:54,720
risk

451
00:18:54,720 --> 00:18:57,120
sometimes it was quite a bit of risk

452
00:18:57,120 --> 00:18:58,799
sometimes it wasn't

453
00:18:58,799 --> 00:19:01,280
but this just shows you and this was one

454
00:19:01,280 --> 00:19:02,640
of our early

455
00:19:02,640 --> 00:19:04,640
assessments

456
00:19:04,640 --> 00:19:07,039
that it's fairly straightforward to do

457
00:19:07,039 --> 00:19:10,880
this and very repeatable and very

458
00:19:10,880 --> 00:19:13,120
straightforward to do over and over

459
00:19:13,120 --> 00:19:14,960
again

460
00:19:14,960 --> 00:19:18,720
so in the tool that we built the content

461
00:19:18,720 --> 00:19:20,799
manager we call it the risk model

462
00:19:20,799 --> 00:19:22,160
manager

463
00:19:22,160 --> 00:19:25,840
one of the things we've done on top of

464
00:19:25,840 --> 00:19:29,039
putting all these risks is we've started

465
00:19:29,039 --> 00:19:30,480
to catalog

466
00:19:30,480 --> 00:19:32,480
well where do you get the answer to

467
00:19:32,480 --> 00:19:35,120
these risk questions

468
00:19:35,120 --> 00:19:38,000
some of those questions can be answered

469
00:19:38,000 --> 00:19:41,520
from public and private data sources

470
00:19:41,520 --> 00:19:44,320
so we've started to put those into the

471
00:19:44,320 --> 00:19:45,200
tool

472
00:19:45,200 --> 00:19:46,400
and then

473
00:19:46,400 --> 00:19:49,200
assign them to the risk questions that

474
00:19:49,200 --> 00:19:51,120
they can help you answer

475
00:19:51,120 --> 00:19:53,200
and then when you actually go to do an

476
00:19:53,200 --> 00:19:54,559
assessment

477
00:19:54,559 --> 00:19:58,080
they actually are offered up so i know

478
00:19:58,080 --> 00:20:00,080
it's pretty small but

479
00:20:00,080 --> 00:20:02,960
these slides will be available

480
00:20:02,960 --> 00:20:05,679
you can see here's one way of assessing

481
00:20:05,679 --> 00:20:06,400
it

482
00:20:06,400 --> 00:20:09,360
and then here's another way and

483
00:20:09,360 --> 00:20:11,360
we're also starting to put in some

484
00:20:11,360 --> 00:20:14,240
automated assessments and some of these

485
00:20:14,240 --> 00:20:15,679
data sources

486
00:20:15,679 --> 00:20:18,840
are very well structured and can be

487
00:20:18,840 --> 00:20:22,240
automated another way of getting insight

488
00:20:22,240 --> 00:20:24,640
into these risks and here i'm showing

489
00:20:24,640 --> 00:20:25,360
you

490
00:20:25,360 --> 00:20:27,760
the taxonomy again

491
00:20:27,760 --> 00:20:31,600
is to look at third-party assessments

492
00:20:31,600 --> 00:20:34,520
now one example of that is the

493
00:20:34,520 --> 00:20:36,080
telecommunications industry

494
00:20:36,080 --> 00:20:37,600
association's

495
00:20:37,600 --> 00:20:40,720
supply chain security 9001

496
00:20:40,720 --> 00:20:43,840
which has about 96 different

497
00:20:43,840 --> 00:20:45,280
requirements

498
00:20:45,280 --> 00:20:47,360
and if your

499
00:20:47,360 --> 00:20:49,760
supplier has been certified against that

500
00:20:49,760 --> 00:20:52,480
by a third party it means they've met

501
00:20:52,480 --> 00:20:55,039
all these requirements well many of

502
00:20:55,039 --> 00:20:58,240
these requirements actually speak

503
00:20:58,240 --> 00:21:01,840
to the risks in system of trust and so

504
00:21:01,840 --> 00:21:05,520
we've been working with tia to map those

505
00:21:05,520 --> 00:21:07,440
so that if you

506
00:21:07,440 --> 00:21:09,919
tell the system of trust

507
00:21:09,919 --> 00:21:12,799
system that yes this was a

508
00:21:12,799 --> 00:21:14,240
tiaa

509
00:21:14,240 --> 00:21:17,919
scs 9001 certified company

510
00:21:17,919 --> 00:21:20,880
then inside system of trust

511
00:21:20,880 --> 00:21:24,320
for the applicable risks it'll say

512
00:21:24,320 --> 00:21:26,159
well that means that they've met the

513
00:21:26,159 --> 00:21:28,080
following requirements

514
00:21:28,080 --> 00:21:30,559
which are relevant to this risk

515
00:21:30,559 --> 00:21:32,960
and you can use that as part of your

516
00:21:32,960 --> 00:21:34,559
assessment

517
00:21:34,559 --> 00:21:35,679
so

518
00:21:35,679 --> 00:21:38,159
there's other sources of this kind of

519
00:21:38,159 --> 00:21:39,919
data

520
00:21:39,919 --> 00:21:43,280
the in the control systems and

521
00:21:43,280 --> 00:21:45,360
automation world

522
00:21:45,360 --> 00:21:47,320
isa iec

523
00:21:47,320 --> 00:21:48,960
62443

524
00:21:48,960 --> 00:21:52,159
is very very common for certifying

525
00:21:52,159 --> 00:21:54,320
products and

526
00:21:54,320 --> 00:21:56,480
company capabilities

527
00:21:56,480 --> 00:21:59,039
so we're going to work with them to map

528
00:21:59,039 --> 00:21:59,919
that

529
00:21:59,919 --> 00:22:02,240
as well as iso

530
00:22:02,240 --> 00:22:05,440
20 243

531
00:22:05,440 --> 00:22:08,000
from the open group the trusted

532
00:22:08,000 --> 00:22:10,880
technology providers

533
00:22:10,880 --> 00:22:14,000
certification which looks at malicious

534
00:22:14,000 --> 00:22:16,000
taint and counterfeit

535
00:22:16,000 --> 00:22:18,799
so this is just another insight you can

536
00:22:18,799 --> 00:22:19,760
bring

537
00:22:19,760 --> 00:22:20,559
that

538
00:22:20,559 --> 00:22:21,520
can

539
00:22:21,520 --> 00:22:23,919
make your assessment quicker

540
00:22:23,919 --> 00:22:24,640
so

541
00:22:24,640 --> 00:22:27,280
system of trust in general is trying to

542
00:22:27,280 --> 00:22:30,480
let us do side-by-side assessments

543
00:22:30,480 --> 00:22:31,360
and

544
00:22:31,360 --> 00:22:34,400
make sure that you can have consistency

545
00:22:34,400 --> 00:22:37,120
and bring this down to something that

546
00:22:37,120 --> 00:22:38,960
you don't have to be a supply chain

547
00:22:38,960 --> 00:22:41,919
expert to actually use

548
00:22:41,919 --> 00:22:44,480
but i want to turn the corner and now

549
00:22:44,480 --> 00:22:48,159
talk about the software supply chain

550
00:22:48,159 --> 00:22:51,200
now many of you may be aware

551
00:22:51,200 --> 00:22:52,320
that

552
00:22:52,320 --> 00:22:55,760
two years ago company solar winds

553
00:22:55,760 --> 00:22:59,520
had was attacked and what happened was

554
00:22:59,520 --> 00:23:02,799
bad actors got onto their networks

555
00:23:02,799 --> 00:23:06,559
looked around understood how they worked

556
00:23:06,559 --> 00:23:08,720
how their systems ran

557
00:23:08,720 --> 00:23:10,400
and then they

558
00:23:10,400 --> 00:23:13,440
uh adjusted the build system

559
00:23:13,440 --> 00:23:15,440
so that it actually

560
00:23:15,440 --> 00:23:16,799
inserted

561
00:23:16,799 --> 00:23:18,400
malicious code

562
00:23:18,400 --> 00:23:20,080
into the build

563
00:23:20,080 --> 00:23:23,039
as it was creating the software and what

564
00:23:23,039 --> 00:23:24,640
that

565
00:23:24,640 --> 00:23:26,000
resulted in

566
00:23:26,000 --> 00:23:28,320
was solarwinds

567
00:23:28,320 --> 00:23:30,960
packaging up and signing

568
00:23:30,960 --> 00:23:34,480
trojan software and sending it out to

569
00:23:34,480 --> 00:23:36,960
its customers so

570
00:23:36,960 --> 00:23:39,600
18 000 organizations

571
00:23:39,600 --> 00:23:41,440
received that

572
00:23:41,440 --> 00:23:44,320
tainted software and some of them were

573
00:23:44,320 --> 00:23:47,360
subsequently visited by the bad actors

574
00:23:47,360 --> 00:23:48,240
so

575
00:23:48,240 --> 00:23:49,120
um

576
00:23:49,120 --> 00:23:52,320
in january of 2021

577
00:23:52,320 --> 00:23:54,559
mitre wrote a paper

578
00:23:54,559 --> 00:23:55,520
the

579
00:23:55,520 --> 00:23:57,520
references on the bottom of the screen

580
00:23:57,520 --> 00:23:58,400
here

581
00:23:58,400 --> 00:23:59,520
about

582
00:23:59,520 --> 00:24:01,679
how that could have been avoided of

583
00:24:01,679 --> 00:24:04,000
course one part was to secure the

584
00:24:04,000 --> 00:24:06,640
environment so people can't just wander

585
00:24:06,640 --> 00:24:09,600
around and learn what's how you do

586
00:24:09,600 --> 00:24:11,760
business and what's going on and

587
00:24:11,760 --> 00:24:14,400
make changes to your build system

588
00:24:14,400 --> 00:24:17,520
but another part of it was to introduce

589
00:24:17,520 --> 00:24:20,559
a software build material but not only

590
00:24:20,559 --> 00:24:23,840
introduce it as something you do

591
00:24:23,840 --> 00:24:26,799
for your customer but rather use it

592
00:24:26,799 --> 00:24:29,919
inside the software factory

593
00:24:29,919 --> 00:24:33,120
inside your software development process

594
00:24:33,120 --> 00:24:34,080
and

595
00:24:34,080 --> 00:24:35,600
have signing

596
00:24:35,600 --> 00:24:38,799
of each step by the actor who does

597
00:24:38,799 --> 00:24:40,720
that process

598
00:24:40,720 --> 00:24:42,240
and then

599
00:24:42,240 --> 00:24:45,360
actually daisy chain those so that you

600
00:24:45,360 --> 00:24:47,760
have an understanding of

601
00:24:47,760 --> 00:24:50,000
what went from one

602
00:24:50,000 --> 00:24:53,679
stop to another and then compare it

603
00:24:53,679 --> 00:24:56,080
to what was supposed to happen

604
00:24:56,080 --> 00:24:58,720
now there was a project called in toto

605
00:24:58,720 --> 00:25:00,480
in the linux foundation

606
00:25:00,480 --> 00:25:03,279
that lays out how to do this but the

607
00:25:03,279 --> 00:25:04,960
general idea

608
00:25:04,960 --> 00:25:07,600
is one that i think makes a lot of sense

609
00:25:07,600 --> 00:25:10,080
a lot of people have started working

610
00:25:10,080 --> 00:25:12,480
towards that and i'm about to tell you

611
00:25:12,480 --> 00:25:13,440
about

612
00:25:13,440 --> 00:25:15,600
another way of doing that

613
00:25:15,600 --> 00:25:18,240
but the idea here is you could then say

614
00:25:18,240 --> 00:25:20,320
okay i now

615
00:25:20,320 --> 00:25:22,240
know that what was supposed to happen

616
00:25:22,240 --> 00:25:23,600
did happen

617
00:25:23,600 --> 00:25:26,799
the people the processes the tools that

618
00:25:26,799 --> 00:25:29,840
were supposed to be used were used and

619
00:25:29,840 --> 00:25:32,559
therefore it's safe to release and then

620
00:25:32,559 --> 00:25:35,440
some version of the s-bomb

621
00:25:35,440 --> 00:25:38,400
can be shared with the consumer so they

622
00:25:38,400 --> 00:25:41,360
can use it to manage the software in

623
00:25:41,360 --> 00:25:44,559
operation in their on plate

624
00:25:44,559 --> 00:25:46,080
so

625
00:25:46,080 --> 00:25:48,720
part of the thing i just talked about is

626
00:25:48,720 --> 00:25:50,720
the software bill material

627
00:25:50,720 --> 00:25:53,360
now i think a lot of people

628
00:25:53,360 --> 00:25:56,000
have a little bit of confusion about

629
00:25:56,000 --> 00:25:58,480
what is a software bill of materials and

630
00:25:58,480 --> 00:26:00,240
that's because there's actually three

631
00:26:00,240 --> 00:26:01,360
kinds

632
00:26:01,360 --> 00:26:03,440
and they're very related but they are

633
00:26:03,440 --> 00:26:06,799
separate so one i'm showing here

634
00:26:06,799 --> 00:26:10,400
is the source code or build

635
00:26:10,400 --> 00:26:13,279
software build materials so it knows all

636
00:26:13,279 --> 00:26:15,520
about all the components that are being

637
00:26:15,520 --> 00:26:16,880
brought together

638
00:26:16,880 --> 00:26:19,279
the tools that are being used

639
00:26:19,279 --> 00:26:20,720
and

640
00:26:20,720 --> 00:26:25,679
you know out comes out the end product

641
00:26:25,679 --> 00:26:28,240
then there's the software build material

642
00:26:28,240 --> 00:26:30,559
of that targeted image

643
00:26:30,559 --> 00:26:34,000
which can be firmware disk images

644
00:26:34,000 --> 00:26:37,440
container images package feeds all kinds

645
00:26:37,440 --> 00:26:39,279
of different things so

646
00:26:39,279 --> 00:26:41,279
you can have a software

647
00:26:41,279 --> 00:26:44,960
build material of that targeted image

648
00:26:44,960 --> 00:26:47,760
and it relates to the build

649
00:26:47,760 --> 00:26:49,200
s-bomb

650
00:26:49,200 --> 00:26:50,960
but it's not the same

651
00:26:50,960 --> 00:26:53,440
and then when you install and start

652
00:26:53,440 --> 00:26:55,279
operating software

653
00:26:55,279 --> 00:26:57,360
you actually have that

654
00:26:57,360 --> 00:27:01,440
operational s-bomb which now reflects

655
00:27:01,440 --> 00:27:02,559
the

656
00:27:02,559 --> 00:27:06,320
linking to the local dynamic libraries

657
00:27:06,320 --> 00:27:09,200
and the service interfaces

658
00:27:09,200 --> 00:27:11,919
available on a specific device

659
00:27:11,919 --> 00:27:15,039
so these are all related they're kind of

660
00:27:15,039 --> 00:27:16,000
different

661
00:27:16,000 --> 00:27:18,000
life cycle points

662
00:27:18,000 --> 00:27:19,360
but they

663
00:27:19,360 --> 00:27:21,120
you should make sure

664
00:27:21,120 --> 00:27:22,880
when you're talking to people about

665
00:27:22,880 --> 00:27:24,080
s-bombs

666
00:27:24,080 --> 00:27:26,320
which of these or

667
00:27:26,320 --> 00:27:28,240
how many of these you actually are

668
00:27:28,240 --> 00:27:29,840
interested in

669
00:27:29,840 --> 00:27:30,960
so

670
00:27:30,960 --> 00:27:32,559
here in the u.s

671
00:27:32,559 --> 00:27:35,440
we put together some guidance on

672
00:27:35,440 --> 00:27:37,200
you know

673
00:27:37,200 --> 00:27:39,279
what kind of

674
00:27:39,279 --> 00:27:42,000
standards or formats were out there that

675
00:27:42,000 --> 00:27:43,440
could be used

676
00:27:43,440 --> 00:27:46,320
to depict a software bill material

677
00:27:46,320 --> 00:27:49,200
in a standardized way and the three that

678
00:27:49,200 --> 00:27:51,600
were talked about quite heavily

679
00:27:51,600 --> 00:27:54,080
is the software package data exchange

680
00:27:54,080 --> 00:27:55,440
spdx

681
00:27:55,440 --> 00:27:59,360
which is captured in iso standard theos

682
00:27:59,360 --> 00:28:01,840
cyclone dx

683
00:28:01,840 --> 00:28:03,200
format

684
00:28:03,200 --> 00:28:04,559
as well as

685
00:28:04,559 --> 00:28:06,720
squid tags another which is also

686
00:28:06,720 --> 00:28:10,080
captured in a iso standard

687
00:28:10,080 --> 00:28:11,039
my

688
00:28:11,039 --> 00:28:14,840
self and several colleagues put together

689
00:28:14,840 --> 00:28:17,440
another standards effort

690
00:28:17,440 --> 00:28:19,919
out of the object management group and

691
00:28:19,919 --> 00:28:22,320
the consortium for information and

692
00:28:22,320 --> 00:28:24,080
software quality

693
00:28:24,080 --> 00:28:24,960
and

694
00:28:24,960 --> 00:28:27,279
we were trying to meet these

695
00:28:27,279 --> 00:28:28,720
requirements

696
00:28:28,720 --> 00:28:32,320
the then these were the use cases we

697
00:28:32,320 --> 00:28:34,320
were thinking about

698
00:28:34,320 --> 00:28:38,159
and basically this has been driving

699
00:28:38,159 --> 00:28:40,480
standards work and

700
00:28:40,480 --> 00:28:42,000
we ended up

701
00:28:42,000 --> 00:28:43,760
merging our work

702
00:28:43,760 --> 00:28:46,960
with the spdx work

703
00:28:46,960 --> 00:28:49,840
because they started coming to the same

704
00:28:49,840 --> 00:28:51,200
architecture

705
00:28:51,200 --> 00:28:53,440
going forward

706
00:28:53,440 --> 00:28:54,640
also

707
00:28:54,640 --> 00:28:56,240
swit tags

708
00:28:56,240 --> 00:28:59,840
really aren't going to be able to

709
00:28:59,840 --> 00:29:01,279
capture

710
00:29:01,279 --> 00:29:04,000
the full

711
00:29:04,000 --> 00:29:07,279
software build material as we go forward

712
00:29:07,279 --> 00:29:11,600
now ntia national telecommunications

713
00:29:11,600 --> 00:29:13,679
uh industries

714
00:29:13,679 --> 00:29:15,200
and information

715
00:29:15,200 --> 00:29:18,080
administration as part of the us

716
00:29:18,080 --> 00:29:19,919
department of commerce

717
00:29:19,919 --> 00:29:22,320
did a lot of the leadership and

718
00:29:22,320 --> 00:29:23,760
coordination

719
00:29:23,760 --> 00:29:26,080
in their work on software builds

720
00:29:26,080 --> 00:29:30,399
material very focused on end users

721
00:29:30,399 --> 00:29:32,080
and what do they need

722
00:29:32,080 --> 00:29:34,720
and those who provide end users with

723
00:29:34,720 --> 00:29:35,840
products

724
00:29:35,840 --> 00:29:38,159
what i just talked to you about

725
00:29:38,159 --> 00:29:40,960
the work in the object management group

726
00:29:40,960 --> 00:29:43,440
was aimed at the tools

727
00:29:43,440 --> 00:29:44,480
that are

728
00:29:44,480 --> 00:29:47,120
provided to those who build

729
00:29:47,120 --> 00:29:50,240
software-based products so

730
00:29:50,240 --> 00:29:51,919
basically the

731
00:29:51,919 --> 00:29:54,240
package managers the development

732
00:29:54,240 --> 00:29:57,360
environments the build choreography and

733
00:29:57,360 --> 00:30:00,559
so on so that was our target

734
00:30:00,559 --> 00:30:03,600
and what we came up with and it'll be

735
00:30:03,600 --> 00:30:07,279
coming out in a couple of months

736
00:30:07,279 --> 00:30:10,640
is a core billow material standard

737
00:30:10,640 --> 00:30:13,360
that actually can

738
00:30:13,360 --> 00:30:16,080
be a build material of software

739
00:30:16,080 --> 00:30:17,919
or of hardware

740
00:30:17,919 --> 00:30:18,960
and

741
00:30:18,960 --> 00:30:21,760
then you can have license information

742
00:30:21,760 --> 00:30:23,679
and other information

743
00:30:23,679 --> 00:30:26,320
and that means you can not only

744
00:30:26,320 --> 00:30:28,720
be talking to those who care about

745
00:30:28,720 --> 00:30:29,919
software

746
00:30:29,919 --> 00:30:32,960
but also hardware and systems

747
00:30:32,960 --> 00:30:35,600
and we think that's a more balanced way

748
00:30:35,600 --> 00:30:36,399
of

749
00:30:36,399 --> 00:30:38,159
dealing with this because

750
00:30:38,159 --> 00:30:40,320
most people who are worried about their

751
00:30:40,320 --> 00:30:42,799
software are very worried about the

752
00:30:42,799 --> 00:30:45,120
environment and the actual

753
00:30:45,120 --> 00:30:49,200
devices as well as the software

754
00:30:49,200 --> 00:30:53,120
in the u.s um the um there's a

755
00:30:53,120 --> 00:30:56,159
task force that has started to put

756
00:30:56,159 --> 00:30:58,159
together what should a hardware bill

757
00:30:58,159 --> 00:30:59,440
materials

758
00:30:59,440 --> 00:31:01,520
be and we're trying to

759
00:31:01,520 --> 00:31:03,679
work with them so that

760
00:31:03,679 --> 00:31:05,520
they can make use of

761
00:31:05,520 --> 00:31:08,159
the spdx standard

762
00:31:08,159 --> 00:31:09,120
and

763
00:31:09,120 --> 00:31:10,240
there's

764
00:31:10,240 --> 00:31:12,399
many other types of things that we're

765
00:31:12,399 --> 00:31:13,760
capturing

766
00:31:13,760 --> 00:31:15,919
providence pedigree

767
00:31:15,919 --> 00:31:20,159
the build profile the defects and so i

768
00:31:20,159 --> 00:31:22,799
encourage you to if you're interested in

769
00:31:22,799 --> 00:31:24,720
software builds material

770
00:31:24,720 --> 00:31:26,960
you can come help us test what we've

771
00:31:26,960 --> 00:31:29,200
come up with over the last two and a

772
00:31:29,200 --> 00:31:30,399
half years

773
00:31:30,399 --> 00:31:33,039
and then the ntia work is actually

774
00:31:33,039 --> 00:31:36,000
shifted to our department of homeland

775
00:31:36,000 --> 00:31:37,519
security's

776
00:31:37,519 --> 00:31:40,480
cyber security infrastructure security

777
00:31:40,480 --> 00:31:42,080
agency

778
00:31:42,080 --> 00:31:44,960
the gentleman leading that alan friedman

779
00:31:44,960 --> 00:31:49,120
has had moved from ntia to cisa

780
00:31:49,120 --> 00:31:52,000
this is a real quick chart just showing

781
00:31:52,000 --> 00:31:52,799
you

782
00:31:52,799 --> 00:31:55,600
uh the architecture of our software bill

783
00:31:55,600 --> 00:31:58,159
materials and the only thing i want to

784
00:31:58,159 --> 00:31:59,519
show you is

785
00:31:59,519 --> 00:32:02,480
the top two thirds to the right

786
00:32:02,480 --> 00:32:04,080
is that core

787
00:32:04,080 --> 00:32:06,799
how do you manage a bill material and

788
00:32:06,799 --> 00:32:10,159
it's only the very bottom that has four

789
00:32:10,159 --> 00:32:13,440
objects that are unique to software

790
00:32:13,440 --> 00:32:15,440
and so we believe

791
00:32:15,440 --> 00:32:18,159
you can put other objects there for

792
00:32:18,159 --> 00:32:22,159
hardware and for networks and so on

793
00:32:22,159 --> 00:32:24,320
so i want to go back to the software

794
00:32:24,320 --> 00:32:26,720
supply chain now

795
00:32:26,720 --> 00:32:29,519
you know as you build software

796
00:32:29,519 --> 00:32:32,159
there's um you know a lot of different

797
00:32:32,159 --> 00:32:33,679
ways you can do it

798
00:32:33,679 --> 00:32:36,480
but um there's also a lot of ways that

799
00:32:36,480 --> 00:32:37,919
can be attacked

800
00:32:37,919 --> 00:32:38,640
and

801
00:32:38,640 --> 00:32:40,080
manipulated

802
00:32:40,080 --> 00:32:42,960
and so uh an effort called the supply

803
00:32:42,960 --> 00:32:45,120
chain levels for software artifacts

804
00:32:45,120 --> 00:32:48,480
salsa has been aiming to look at that

805
00:32:48,480 --> 00:32:50,080
set of attacks

806
00:32:50,080 --> 00:32:51,760
and come up with well what kinds of

807
00:32:51,760 --> 00:32:53,519
things can you do

808
00:32:53,519 --> 00:32:56,960
to mitigate or remove those attacks and

809
00:32:56,960 --> 00:32:59,360
they've organized it into

810
00:32:59,360 --> 00:33:01,279
different levels so that you don't have

811
00:33:01,279 --> 00:33:02,240
to

812
00:33:02,240 --> 00:33:04,320
track down every single

813
00:33:04,320 --> 00:33:07,200
combination but you can say hey i want

814
00:33:07,200 --> 00:33:09,840
to salsa level two

815
00:33:09,840 --> 00:33:12,640
capability from my provider because

816
00:33:12,640 --> 00:33:15,760
those are the attacks i'm worried about

817
00:33:15,760 --> 00:33:17,279
and one of the interesting things

818
00:33:17,279 --> 00:33:18,960
they've done is

819
00:33:18,960 --> 00:33:21,919
well a lot of the things you do

820
00:33:21,919 --> 00:33:25,200
are going to be at attestations about

821
00:33:25,200 --> 00:33:28,720
how the software was built or how it was

822
00:33:28,720 --> 00:33:31,519
tested or how it was compiled and so

823
00:33:31,519 --> 00:33:34,559
they've come up with a way of capturing

824
00:33:34,559 --> 00:33:36,399
those attestations

825
00:33:36,399 --> 00:33:38,880
that allows us to start standardizing

826
00:33:38,880 --> 00:33:39,600
them

827
00:33:39,600 --> 00:33:41,519
so that we can actually

828
00:33:41,519 --> 00:33:43,279
have someone

829
00:33:43,279 --> 00:33:46,080
document what they did and somebody else

830
00:33:46,080 --> 00:33:48,159
can read that and understand it because

831
00:33:48,159 --> 00:33:50,720
we have a structured way of talking

832
00:33:50,720 --> 00:33:53,039
about these different kinds of

833
00:33:53,039 --> 00:33:55,720
attestations

834
00:33:55,720 --> 00:33:57,440
attestations

835
00:33:57,440 --> 00:33:59,360
come throughout the life cycle of

836
00:33:59,360 --> 00:34:00,559
software

837
00:34:00,559 --> 00:34:02,960
whether it's analysis of the

838
00:34:02,960 --> 00:34:04,399
requirements

839
00:34:04,399 --> 00:34:07,519
of the architecture the code itself

840
00:34:07,519 --> 00:34:08,960
or

841
00:34:08,960 --> 00:34:11,480
the operational environment so

842
00:34:11,480 --> 00:34:13,839
attestations about what was done in the

843
00:34:13,839 --> 00:34:16,480
results are all part of

844
00:34:16,480 --> 00:34:18,960
what you really need to understand about

845
00:34:18,960 --> 00:34:21,599
those who are providing you software and

846
00:34:21,599 --> 00:34:22,879
what was done

847
00:34:22,879 --> 00:34:25,359
to make sure it actually

848
00:34:25,359 --> 00:34:28,239
has no vulnerabilities has no quality

849
00:34:28,239 --> 00:34:31,440
defects is not going to expose your

850
00:34:31,440 --> 00:34:32,719
organization

851
00:34:32,719 --> 00:34:34,399
if you use

852
00:34:34,399 --> 00:34:36,239
so the last thing i want to talk to you

853
00:34:36,239 --> 00:34:37,280
about

854
00:34:37,280 --> 00:34:39,839
is a new working group that's being

855
00:34:39,839 --> 00:34:42,960
formed out of the ietf

856
00:34:42,960 --> 00:34:44,480
called skit

857
00:34:44,480 --> 00:34:46,399
it's a supply chain integrity

858
00:34:46,399 --> 00:34:49,119
transparency and trust working group

859
00:34:49,119 --> 00:34:53,040
and basically it's a confidential ledger

860
00:34:53,040 --> 00:34:56,239
hardware route of trust-based capability

861
00:34:56,239 --> 00:34:58,560
to register claims

862
00:34:58,560 --> 00:34:59,760
and

863
00:34:59,760 --> 00:35:02,000
be able to get a signed receipt for

864
00:35:02,000 --> 00:35:04,720
those so you know when they were made by

865
00:35:04,720 --> 00:35:08,880
whom but it's also a permissioned ledger

866
00:35:08,880 --> 00:35:12,320
so not everyone can get at it and so

867
00:35:12,320 --> 00:35:13,839
here are the

868
00:35:13,839 --> 00:35:15,280
basically

869
00:35:15,280 --> 00:35:17,200
outline of the things we're trying to

870
00:35:17,200 --> 00:35:18,320
accomplish

871
00:35:18,320 --> 00:35:20,240
and the links are there for you to go

872
00:35:20,240 --> 00:35:23,200
read but let me just talk about how you

873
00:35:23,200 --> 00:35:25,119
would actually use it

874
00:35:25,119 --> 00:35:27,359
so if we go back to that software

875
00:35:27,359 --> 00:35:29,119
development

876
00:35:29,119 --> 00:35:31,359
process that i talked about before and

877
00:35:31,359 --> 00:35:32,240
that we

878
00:35:32,240 --> 00:35:34,240
saw in the early

879
00:35:34,240 --> 00:35:37,119
fish chips and software as well as in

880
00:35:37,119 --> 00:35:38,800
the

881
00:35:38,800 --> 00:35:40,880
solarwinds attack

882
00:35:40,880 --> 00:35:44,480
what if instead of an in toto

883
00:35:44,480 --> 00:35:46,960
you know kind of here's the road map and

884
00:35:46,960 --> 00:35:48,640
did you do everything

885
00:35:48,640 --> 00:35:51,359
we actually have a skit ledger and we

886
00:35:51,359 --> 00:35:54,400
can have skip policies in there as well

887
00:35:54,400 --> 00:35:55,680
as evidence

888
00:35:55,680 --> 00:35:58,880
and so the policies could be you cannot

889
00:35:58,880 --> 00:36:01,839
commit code until you have evidence of

890
00:36:01,839 --> 00:36:03,119
the f that

891
00:36:03,119 --> 00:36:05,119
all the commits have been signed by the

892
00:36:05,119 --> 00:36:07,119
approved developers and so there are

893
00:36:07,119 --> 00:36:08,880
approved developers not just any

894
00:36:08,880 --> 00:36:10,079
developers

895
00:36:10,079 --> 00:36:11,119
and so

896
00:36:11,119 --> 00:36:13,680
the next step after that you know

897
00:36:13,680 --> 00:36:16,240
you want source providence from you've

898
00:36:16,240 --> 00:36:18,240
got an acceptable list of

899
00:36:18,240 --> 00:36:22,079
where this uh come from and so on so

900
00:36:22,079 --> 00:36:24,720
if you start getting that evidence then

901
00:36:24,720 --> 00:36:27,920
you can start moving down that process

902
00:36:27,920 --> 00:36:30,640
and so the idea here is

903
00:36:30,640 --> 00:36:32,160
not that you

904
00:36:32,160 --> 00:36:34,640
wait until the end and compare to see if

905
00:36:34,640 --> 00:36:36,880
the things you expected were done

906
00:36:36,880 --> 00:36:38,640
but actually you can gate this

907
00:36:38,640 --> 00:36:41,119
internally and so

908
00:36:41,119 --> 00:36:43,599
the idea here is that this could be done

909
00:36:43,599 --> 00:36:44,800
inside

910
00:36:44,800 --> 00:36:47,280
the software development factory in the

911
00:36:47,280 --> 00:36:49,359
side the organization

912
00:36:49,359 --> 00:36:51,440
so they have confidence

913
00:36:51,440 --> 00:36:52,160
and

914
00:36:52,160 --> 00:36:54,320
they have backup data to tell their

915
00:36:54,320 --> 00:36:56,800
customers that there's a reason to have

916
00:36:56,800 --> 00:36:59,680
assurance or for an auditor or if

917
00:36:59,680 --> 00:37:02,640
something goes wrong for them to support

918
00:37:02,640 --> 00:37:04,400
an

919
00:37:04,400 --> 00:37:06,160
investigation

920
00:37:06,160 --> 00:37:08,480
but another way of looking at this

921
00:37:08,480 --> 00:37:11,040
is from the outside from the market

922
00:37:11,040 --> 00:37:11,920
so

923
00:37:11,920 --> 00:37:13,680
if my company

924
00:37:13,680 --> 00:37:15,760
has a policy that says

925
00:37:15,760 --> 00:37:18,720
software coming into our organization

926
00:37:18,720 --> 00:37:22,320
needs the following types of attestation

927
00:37:22,320 --> 00:37:25,040
uh from the following types of

928
00:37:25,040 --> 00:37:26,320
testers

929
00:37:26,320 --> 00:37:29,040
so that's kind of a gating policy

930
00:37:29,040 --> 00:37:31,680
so someone who creates software the

931
00:37:31,680 --> 00:37:33,680
factor we just saw

932
00:37:33,680 --> 00:37:35,760
they can actually

933
00:37:35,760 --> 00:37:38,400
collect those different asset stations

934
00:37:38,400 --> 00:37:39,839
as we just saw

935
00:37:39,839 --> 00:37:43,760
and put them into a external ledger and

936
00:37:43,760 --> 00:37:46,079
that i can then when i try to get

937
00:37:46,079 --> 00:37:47,200
software

938
00:37:47,200 --> 00:37:49,359
they can check to see if the right kinds

939
00:37:49,359 --> 00:37:52,000
of things were done and therefore i can

940
00:37:52,000 --> 00:37:54,720
now bring the software in

941
00:37:54,720 --> 00:37:55,839
so this

942
00:37:55,839 --> 00:37:57,280
architecture

943
00:37:57,280 --> 00:38:00,800
is available out in this rfc

944
00:38:00,800 --> 00:38:03,119
and then the counter signing

945
00:38:03,119 --> 00:38:05,200
of that evidence when you put it into

946
00:38:05,200 --> 00:38:09,280
the ledger is captured in this other rfc

947
00:38:09,280 --> 00:38:10,000
but

948
00:38:10,000 --> 00:38:13,040
this isn't just for software so if we go

949
00:38:13,040 --> 00:38:15,520
look at the fish

950
00:38:15,520 --> 00:38:19,359
supply chain you can say well

951
00:38:19,359 --> 00:38:21,839
there's certain things that you want to

952
00:38:21,839 --> 00:38:22,880
happen

953
00:38:22,880 --> 00:38:24,320
with the fish

954
00:38:24,320 --> 00:38:26,720
you know it needs to be kept cold it

955
00:38:26,720 --> 00:38:29,200
needs to be to be fresh it needs to have

956
00:38:29,200 --> 00:38:31,440
been caught in a certain number of days

957
00:38:31,440 --> 00:38:33,599
so there's all these criteria these

958
00:38:33,599 --> 00:38:34,720
gates

959
00:38:34,720 --> 00:38:37,040
and then you can collect the evidence

960
00:38:37,040 --> 00:38:39,520
that lets you know you've actually

961
00:38:39,520 --> 00:38:41,520
met those criteria

962
00:38:41,520 --> 00:38:44,160
and similar for microelectronics

963
00:38:44,160 --> 00:38:47,520
you know when you you've got criteria

964
00:38:47,520 --> 00:38:48,960
against the

965
00:38:48,960 --> 00:38:52,240
um you know um

966
00:38:52,240 --> 00:38:56,240
eda tools the mask the packaging and so

967
00:38:56,240 --> 00:38:59,200
on and so you can collect that evidence

968
00:38:59,200 --> 00:39:01,359
and use to make sure that the right

969
00:39:01,359 --> 00:39:02,880
things are happening

970
00:39:02,880 --> 00:39:07,040
in that supply chain so while the ietf

971
00:39:07,040 --> 00:39:08,160
effort

972
00:39:08,160 --> 00:39:11,920
is chartered to work on software first

973
00:39:11,920 --> 00:39:14,800
we're doing it in a way that we don't

974
00:39:14,800 --> 00:39:18,160
block the ability to use this for any

975
00:39:18,160 --> 00:39:20,079
kind of supply chain

976
00:39:20,079 --> 00:39:22,560
in an organization

977
00:39:22,560 --> 00:39:24,320
because the bottom line of all of this

978
00:39:24,320 --> 00:39:25,200
is

979
00:39:25,200 --> 00:39:28,880
you know what when you manufacture goods

980
00:39:28,880 --> 00:39:32,160
and deliver goods it's no longer just a

981
00:39:32,160 --> 00:39:33,200
flow

982
00:39:33,200 --> 00:39:36,560
from the you know creation

983
00:39:36,560 --> 00:39:37,920
to the use

984
00:39:37,920 --> 00:39:40,960
there's this two-way street now

985
00:39:40,960 --> 00:39:44,640
about the quality the pedigree

986
00:39:44,640 --> 00:39:45,440
and

987
00:39:45,440 --> 00:39:48,000
re why should i have assurance

988
00:39:48,000 --> 00:39:51,280
and so all these things are focused on

989
00:39:51,280 --> 00:39:53,040
enabling that

990
00:39:53,040 --> 00:39:53,920
so

991
00:39:53,920 --> 00:39:56,880
i'd like to leave the stage by talking

992
00:39:56,880 --> 00:39:59,280
you know telling you that we think that

993
00:39:59,280 --> 00:40:02,320
the questions about how do i

994
00:40:02,320 --> 00:40:03,359
assess

995
00:40:03,359 --> 00:40:05,520
supply chain risks

996
00:40:05,520 --> 00:40:07,599
we think system of trust

997
00:40:07,599 --> 00:40:09,440
is a part of that

998
00:40:09,440 --> 00:40:13,119
and also the skit and s-bombs are going

999
00:40:13,119 --> 00:40:15,920
to be part of that in the software area

1000
00:40:15,920 --> 00:40:18,160
i've been doing a lot of talking to

1001
00:40:18,160 --> 00:40:19,920
different groups

1002
00:40:19,920 --> 00:40:22,800
i'll be ungrained

1003
00:40:22,800 --> 00:40:25,839
hex in taiwan conference

1004
00:40:25,839 --> 00:40:27,359
after tonight

1005
00:40:27,359 --> 00:40:28,240
and

1006
00:40:28,240 --> 00:40:30,800
um we've been doing a lot of engagement

1007
00:40:30,800 --> 00:40:32,880
in the government as well to educate

1008
00:40:32,880 --> 00:40:34,000
them

1009
00:40:34,000 --> 00:40:37,599
and we're going to be licensing this

1010
00:40:37,599 --> 00:40:41,200
making it available for free

1011
00:40:41,200 --> 00:40:43,920
and doing education and training

1012
00:40:43,920 --> 00:40:46,720
hopefully get a lot of people

1013
00:40:46,720 --> 00:40:49,920
involved so if you have ideas about

1014
00:40:49,920 --> 00:40:53,119
supply chain security and like to get

1015
00:40:53,119 --> 00:40:56,160
involved please reach out to me

1016
00:40:56,160 --> 00:40:59,599
it's sot mitre.org

1017
00:40:59,599 --> 00:41:02,400
we've already got many organizations

1018
00:41:02,400 --> 00:41:05,359
it's just a snapshot of the kinds of

1019
00:41:05,359 --> 00:41:06,960
organizations

1020
00:41:06,960 --> 00:41:09,920
that we have involved already

1021
00:41:09,920 --> 00:41:13,119
some of these we've signed ndas

1022
00:41:13,119 --> 00:41:15,920
some were in the process

1023
00:41:15,920 --> 00:41:18,640
and we're also going to have a working

1024
00:41:18,640 --> 00:41:19,440
group

1025
00:41:19,440 --> 00:41:21,839
so that we can do this in a more

1026
00:41:21,839 --> 00:41:23,520
scalable way

1027
00:41:23,520 --> 00:41:25,920
but there's papers out there to talk

1028
00:41:25,920 --> 00:41:28,960
about all these things i've talked about

1029
00:41:28,960 --> 00:41:30,880
and there's a website

1030
00:41:30,880 --> 00:41:34,880
and again you can contact me through sot

1031
00:41:34,880 --> 00:41:36,560
mitre.org

1032
00:41:36,560 --> 00:41:39,839
with that i thank you and i'm ready for

1033
00:41:39,839 --> 00:41:42,400
questions

1034
00:41:45,280 --> 00:41:48,720
um we thank robert for the um fantastic

1035
00:41:48,720 --> 00:41:53,839
uh talk so um is there any questions

1036
00:41:57,440 --> 00:41:58,960
okay so there's a there's a few

1037
00:41:58,960 --> 00:42:02,079
questions from um uh some some of our

1038
00:42:02,079 --> 00:42:04,319
online audience so um one of the

1039
00:42:04,319 --> 00:42:06,560
question is uh what's the difference

1040
00:42:06,560 --> 00:42:08,800
between miters system of trust and other

1041
00:42:08,800 --> 00:42:11,040
supply chain security frameworks so for

1042
00:42:11,040 --> 00:42:12,880
instance c s

1043
00:42:12,880 --> 00:42:17,119
c dash uh scrm from anasd

1044
00:42:17,119 --> 00:42:19,920
so what we're trying to do is be

1045
00:42:19,920 --> 00:42:21,760
comprehensive

1046
00:42:21,760 --> 00:42:24,319
and consistent across the different

1047
00:42:24,319 --> 00:42:25,760
domains

1048
00:42:25,760 --> 00:42:28,000
most of the other

1049
00:42:28,000 --> 00:42:29,599
frameworks

1050
00:42:29,599 --> 00:42:30,800
have very

1051
00:42:30,800 --> 00:42:32,800
focused

1052
00:42:32,800 --> 00:42:34,800
areas where they've been concentrating

1053
00:42:34,800 --> 00:42:35,599
on

1054
00:42:35,599 --> 00:42:38,640
so they may do a good job in certain

1055
00:42:38,640 --> 00:42:41,839
kind of products in certain industries

1056
00:42:41,839 --> 00:42:45,359
but they don't reflect like cyber and

1057
00:42:45,359 --> 00:42:46,560
software

1058
00:42:46,560 --> 00:42:49,599
and or they don't address

1059
00:42:49,599 --> 00:42:52,720
pharma and food stuff as well as

1060
00:42:52,720 --> 00:42:53,839
you know

1061
00:42:53,839 --> 00:42:54,800
you know

1062
00:42:54,800 --> 00:42:56,960
goods and services

1063
00:42:56,960 --> 00:42:59,359
so we're trying to bring these all

1064
00:42:59,359 --> 00:43:00,480
together

1065
00:43:00,480 --> 00:43:01,280
and

1066
00:43:01,280 --> 00:43:04,880
we think a lot of these other frameworks

1067
00:43:04,880 --> 00:43:08,079
like i was showing with the tia

1068
00:43:08,079 --> 00:43:10,960
ses 9001

1069
00:43:10,960 --> 00:43:12,880
if you follow those

1070
00:43:12,880 --> 00:43:14,960
you will have fulfilled

1071
00:43:14,960 --> 00:43:18,400
a subset of what's in system of trust

1072
00:43:18,400 --> 00:43:22,160
but by looking at this more broad look

1073
00:43:22,160 --> 00:43:24,480
you may see some things that you're not

1074
00:43:24,480 --> 00:43:25,680
addressing

1075
00:43:25,680 --> 00:43:27,839
so i don't know if people are

1076
00:43:27,839 --> 00:43:31,680
familiar with mitre's attack framework

1077
00:43:31,680 --> 00:43:33,119
where we

1078
00:43:33,119 --> 00:43:34,480
help people

1079
00:43:34,480 --> 00:43:36,960
think about how attackers

1080
00:43:36,960 --> 00:43:39,920
behave when they get into your networks

1081
00:43:39,920 --> 00:43:43,680
and the vocabulary for describing that

1082
00:43:43,680 --> 00:43:46,560
think about what we're doing is the

1083
00:43:46,560 --> 00:43:49,920
equivalent of that for supply chain

1084
00:43:49,920 --> 00:43:51,839
we want to be able to give you that

1085
00:43:51,839 --> 00:43:53,200
framework

1086
00:43:53,200 --> 00:43:54,880
in which to

1087
00:43:54,880 --> 00:43:57,040
make sure that you're addressing the

1088
00:43:57,040 --> 00:43:59,599
things you need and you can bring the

1089
00:43:59,599 --> 00:44:01,440
different solutions

1090
00:44:01,440 --> 00:44:04,720
that are already out there together

1091
00:44:04,720 --> 00:44:07,440
um but you know in a more comprehensive

1092
00:44:07,440 --> 00:44:09,599
way

1093
00:44:09,599 --> 00:44:12,240
okay so um from my understanding of your

1094
00:44:12,240 --> 00:44:15,280
um answer to this question is that um

1095
00:44:15,280 --> 00:44:18,720
uh so stuffs like uh c scrm will provide

1096
00:44:18,720 --> 00:44:21,200
you some information to work with uh in

1097
00:44:21,200 --> 00:44:24,000
the framework of like system of trust

1098
00:44:24,000 --> 00:44:25,359
um so

1099
00:44:25,359 --> 00:44:27,119
that way you will figure out like uh you

1100
00:44:27,119 --> 00:44:28,800
have the scrm

1101
00:44:28,800 --> 00:44:31,200
um and then what else you need right so

1102
00:44:31,200 --> 00:44:33,280
right so

1103
00:44:33,280 --> 00:44:35,599
okay actually um

1104
00:44:35,599 --> 00:44:38,079
maybe is there anyone else who wants to

1105
00:44:38,079 --> 00:44:41,359
ask a question um

1106
00:44:41,680 --> 00:44:42,880
um

1107
00:44:42,880 --> 00:44:44,720
if not i think we can um field another

1108
00:44:44,720 --> 00:44:47,599
question um from online some of our

1109
00:44:47,599 --> 00:44:48,880
online audience

1110
00:44:48,880 --> 00:44:51,119
so

1111
00:44:54,079 --> 00:44:56,640
one of the question is

1112
00:44:56,640 --> 00:44:58,800
if a company want wants to introduce

1113
00:44:58,800 --> 00:45:01,200
some defense mechanisms of supply chain

1114
00:45:01,200 --> 00:45:03,520
into our process what's the first step

1115
00:45:03,520 --> 00:45:05,760
so there's like the system of trust

1116
00:45:05,760 --> 00:45:06,960
um

1117
00:45:06,960 --> 00:45:07,680
so

1118
00:45:07,680 --> 00:45:10,240
what do they do like if they want to buy

1119
00:45:10,240 --> 00:45:12,400
some server they want to implement they

1120
00:45:12,400 --> 00:45:14,720
want to deploy some software uh what

1121
00:45:14,720 --> 00:45:16,079
would be the first step

1122
00:45:16,079 --> 00:45:18,640
right so um

1123
00:45:18,640 --> 00:45:21,040
system of trust is showing you what the

1124
00:45:21,040 --> 00:45:22,960
risks are

1125
00:45:22,960 --> 00:45:26,480
but when you go to assess those risks

1126
00:45:26,480 --> 00:45:27,760
you may

1127
00:45:27,760 --> 00:45:30,240
either find that there are mitigations

1128
00:45:30,240 --> 00:45:31,359
in place

1129
00:45:31,359 --> 00:45:33,599
or defend defenses

1130
00:45:33,599 --> 00:45:35,440
so the idea is

1131
00:45:35,440 --> 00:45:38,720
you know people who have solutions

1132
00:45:38,720 --> 00:45:40,800
that can protect against some of these

1133
00:45:40,800 --> 00:45:42,160
risks

1134
00:45:42,160 --> 00:45:44,240
will be able to show

1135
00:45:44,240 --> 00:45:45,040
hey

1136
00:45:45,040 --> 00:45:47,280
my solution addresses

1137
00:45:47,280 --> 00:45:49,520
system of trust risk

1138
00:45:49,520 --> 00:45:52,640
87 92 48

1139
00:45:52,640 --> 00:45:55,280
and you know so if those are of concern

1140
00:45:55,280 --> 00:45:56,240
to you

1141
00:45:56,240 --> 00:45:58,480
i have something you can

1142
00:45:58,480 --> 00:46:00,880
use to help manage that

1143
00:46:00,880 --> 00:46:03,359
so it gives them a way of telling their

1144
00:46:03,359 --> 00:46:04,560
story

1145
00:46:04,560 --> 00:46:06,960
about what their product and capability

1146
00:46:06,960 --> 00:46:08,160
does

1147
00:46:08,160 --> 00:46:09,599
without having to

1148
00:46:09,599 --> 00:46:13,520
you know write the story themselves

1149
00:46:13,680 --> 00:46:16,160
okay so um if i understand correctly um

1150
00:46:16,160 --> 00:46:18,640
so for like if i want to deploy certain

1151
00:46:18,640 --> 00:46:21,680
service on my servers um i will use the

1152
00:46:21,680 --> 00:46:24,400
system of trust as a checklist to see um

1153
00:46:24,400 --> 00:46:26,880
if there is stuff that i need to pay

1154
00:46:26,880 --> 00:46:28,640
attention to and then for the stuff that

1155
00:46:28,640 --> 00:46:30,240
i need to pay attention to then i should

1156
00:46:30,240 --> 00:46:33,200
look for solutions in that space um

1157
00:46:33,200 --> 00:46:36,319
right and the solution

1158
00:46:36,720 --> 00:46:38,879
because

1159
00:46:39,200 --> 00:46:41,280
every vendor will tell you

1160
00:46:41,280 --> 00:46:43,920
install my stuff it will solve your

1161
00:46:43,920 --> 00:46:45,440
problems

1162
00:46:45,440 --> 00:46:46,720
but

1163
00:46:46,720 --> 00:46:48,720
what problems are you trying to get

1164
00:46:48,720 --> 00:46:49,760
solved

1165
00:46:49,760 --> 00:46:52,160
let's have a list of those

1166
00:46:52,160 --> 00:46:55,119
and then figure out which technologies

1167
00:46:55,119 --> 00:46:58,480
can actually address those risks

1168
00:46:58,480 --> 00:47:00,800
because what often i find

1169
00:47:00,800 --> 00:47:01,920
is

1170
00:47:01,920 --> 00:47:04,240
a solution does help

1171
00:47:04,240 --> 00:47:05,359
but there's

1172
00:47:05,359 --> 00:47:07,359
edges and gaps

1173
00:47:07,359 --> 00:47:09,920
that are left unaddressed and you need

1174
00:47:09,920 --> 00:47:13,359
to bring more than one solution to bear

1175
00:47:13,359 --> 00:47:16,480
but you need that comprehensive view

1176
00:47:16,480 --> 00:47:18,560
in order to understand

1177
00:47:18,560 --> 00:47:21,280
how much was addressed by this tool how

1178
00:47:21,280 --> 00:47:24,079
much is addressed by this procedure you

1179
00:47:24,079 --> 00:47:27,440
know and how they come together

1180
00:47:27,440 --> 00:47:30,240
okay i see so um in a way the system of

1181
00:47:30,240 --> 00:47:33,359
trust um is a way for us to um kind of

1182
00:47:33,359 --> 00:47:36,720
look at the stuff we buy um like as a

1183
00:47:36,720 --> 00:47:39,200
service provider like the stuff we buy

1184
00:47:39,200 --> 00:47:41,920
um and if they cover all the

1185
00:47:41,920 --> 00:47:42,800
um

1186
00:47:42,800 --> 00:47:44,560
possible scenarios that we might need to

1187
00:47:44,560 --> 00:47:46,079
deal with

1188
00:47:46,079 --> 00:47:50,000
right i see cool um so anyone from

1189
00:47:50,000 --> 00:47:54,160
onsite wants to ask a question

1190
00:48:02,400 --> 00:48:04,880
hello rapper and thanks for your

1191
00:48:04,880 --> 00:48:06,960
interest in talk and here i have a

1192
00:48:06,960 --> 00:48:08,800
question because miter is always very

1193
00:48:08,800 --> 00:48:10,800
fantastic for us because you always

1194
00:48:10,800 --> 00:48:13,520
develop a useful and high impact

1195
00:48:13,520 --> 00:48:16,800
framework like a cwe or micro att and ck

1196
00:48:16,800 --> 00:48:18,880
framework so i would like to know when

1197
00:48:18,880 --> 00:48:21,280
you design uh in this type of supply

1198
00:48:21,280 --> 00:48:24,960
chain of trust system system of trust uh

1199
00:48:24,960 --> 00:48:26,720
what kind of experience

1200
00:48:26,720 --> 00:48:28,559
you can learn from the test when you

1201
00:48:28,559 --> 00:48:31,760
develop the cwe and to develop the

1202
00:48:31,760 --> 00:48:34,640
mitoti and ck what kind of experience

1203
00:48:34,640 --> 00:48:36,720
you can learn from the pacific period

1204
00:48:36,720 --> 00:48:39,359
and to apply in this time

1205
00:48:39,359 --> 00:48:42,400
since i'm the creator of cwe

1206
00:48:42,400 --> 00:48:45,920
i have a lot of lessons and

1207
00:48:46,640 --> 00:48:48,720
good experiences and bad

1208
00:48:48,720 --> 00:48:51,119
about things to do and not do

1209
00:48:51,119 --> 00:48:54,400
but i think one of the biggest things is

1210
00:48:54,400 --> 00:48:56,559
um

1211
00:48:56,559 --> 00:48:59,440
look for ways to get feedback

1212
00:48:59,440 --> 00:49:02,559
make it easy for people to comment

1213
00:49:02,559 --> 00:49:05,040
and offer corrections

1214
00:49:05,040 --> 00:49:07,920
and point out missing areas

1215
00:49:07,920 --> 00:49:08,720
or

1216
00:49:08,720 --> 00:49:11,200
you know things to help evolve

1217
00:49:11,200 --> 00:49:13,280
and so one of the things we hope to get

1218
00:49:13,280 --> 00:49:14,960
done this fall

1219
00:49:14,960 --> 00:49:16,640
is actually

1220
00:49:16,640 --> 00:49:19,599
we're going to have the comprehensive

1221
00:49:19,599 --> 00:49:21,119
system of trust

1222
00:49:21,119 --> 00:49:24,240
on our website and we hope to have it in

1223
00:49:24,240 --> 00:49:25,119
a way

1224
00:49:25,119 --> 00:49:27,599
that people can come and just

1225
00:49:27,599 --> 00:49:29,280
basically click

1226
00:49:29,280 --> 00:49:30,960
and leave a comment

1227
00:49:30,960 --> 00:49:33,359
and so that we can more actively and

1228
00:49:33,359 --> 00:49:34,960
dynamically

1229
00:49:34,960 --> 00:49:38,319
get people's inputs and feedback about

1230
00:49:38,319 --> 00:49:40,800
you know i need more understanding of

1231
00:49:40,800 --> 00:49:43,680
this or did you think about

1232
00:49:43,680 --> 00:49:44,400
this

1233
00:49:44,400 --> 00:49:47,760
sub category of risk so i think one of

1234
00:49:47,760 --> 00:49:49,760
the things we've learned is

1235
00:49:49,760 --> 00:49:52,400
you know there's a wealth of information

1236
00:49:52,400 --> 00:49:55,760
out there that individuals have

1237
00:49:55,760 --> 00:49:58,079
maybe they don't individually know

1238
00:49:58,079 --> 00:50:00,880
everything but they may know a missing

1239
00:50:00,880 --> 00:50:01,760
piece

1240
00:50:01,760 --> 00:50:03,920
and so if we can make it easy for them

1241
00:50:03,920 --> 00:50:05,280
to contribute

1242
00:50:05,280 --> 00:50:07,920
we're all collectively going to have a

1243
00:50:07,920 --> 00:50:08,880
better

1244
00:50:08,880 --> 00:50:12,880
cwe or system of trust and uh that

1245
00:50:12,880 --> 00:50:15,119
that's one of the things i found

1246
00:50:15,119 --> 00:50:17,280
is that people are very

1247
00:50:17,280 --> 00:50:19,760
in in interested in

1248
00:50:19,760 --> 00:50:20,640
you know

1249
00:50:20,640 --> 00:50:23,520
making use of it but also

1250
00:50:23,520 --> 00:50:26,400
there it's you know not perfect the day

1251
00:50:26,400 --> 00:50:29,680
it was born so we need to allow a way

1252
00:50:29,680 --> 00:50:31,599
for that to evolve

1253
00:50:31,599 --> 00:50:33,920
as a community effort

1254
00:50:33,920 --> 00:50:36,960
so um look forward to people helping do

1255
00:50:36,960 --> 00:50:41,480
that for a system of trust

1256
00:50:43,839 --> 00:50:47,520
okay um thanks um so um i think there's

1257
00:50:47,520 --> 00:50:51,119
one last question from online so um

1258
00:50:51,119 --> 00:50:53,119
the question is um

1259
00:50:53,119 --> 00:50:56,640
so are you aware of like any ci cd tools

1260
00:50:56,640 --> 00:50:58,880
that kind of implement this um system of

1261
00:50:58,880 --> 00:51:01,760
cross um or

1262
00:51:01,760 --> 00:51:03,599
can be used for this purpose

1263
00:51:03,599 --> 00:51:05,359
or do you expect that to be something

1264
00:51:05,359 --> 00:51:06,880
that yeah that's gonna appear in the

1265
00:51:06,880 --> 00:51:08,720
future

1266
00:51:08,720 --> 00:51:10,880
so because system of trust is so

1267
00:51:10,880 --> 00:51:12,559
comprehensive

1268
00:51:12,559 --> 00:51:15,359
you know there are tools out there

1269
00:51:15,359 --> 00:51:18,000
that they're called you know vendor

1270
00:51:18,000 --> 00:51:20,559
illumination or supply chain

1271
00:51:20,559 --> 00:51:23,520
illumination tools that can do some of

1272
00:51:23,520 --> 00:51:24,319
this

1273
00:51:24,319 --> 00:51:26,640
you know they'll point out

1274
00:51:26,640 --> 00:51:29,520
um you know companies that may be in

1275
00:51:29,520 --> 00:51:31,040
financial

1276
00:51:31,040 --> 00:51:32,480
hardship

1277
00:51:32,480 --> 00:51:33,280
or

1278
00:51:33,280 --> 00:51:34,880
that are in

1279
00:51:34,880 --> 00:51:37,599
you know flood prone areas

1280
00:51:37,599 --> 00:51:40,400
so there's going to be pieces of this

1281
00:51:40,400 --> 00:51:42,559
um there's also

1282
00:51:42,559 --> 00:51:45,920
you know when you look at products

1283
00:51:45,920 --> 00:51:47,599
your traditional

1284
00:51:47,599 --> 00:51:51,520
software quality software testing tools

1285
00:51:51,520 --> 00:51:54,319
security testing tools

1286
00:51:54,319 --> 00:51:56,000
they can collect some of this

1287
00:51:56,000 --> 00:51:57,280
information

1288
00:51:57,280 --> 00:52:00,319
but this is a big tree

1289
00:52:00,319 --> 00:52:01,680
to hang

1290
00:52:01,680 --> 00:52:04,559
that kind of information on to give you

1291
00:52:04,559 --> 00:52:06,960
that overarching understanding of your

1292
00:52:06,960 --> 00:52:09,440
risks

1293
00:52:10,160 --> 00:52:12,400
i see um thanks so um due to time

1294
00:52:12,400 --> 00:52:14,640
constraint um we'll probably end here

1295
00:52:14,640 --> 00:52:17,119
and um to contact you they can use the

1296
00:52:17,119 --> 00:52:20,319
email right sot at miter

1297
00:52:20,319 --> 00:52:22,480
um

1298
00:52:23,200 --> 00:52:25,760
and the slides will be available right

1299
00:52:25,760 --> 00:52:29,040
yeah i believe i offered the pdf to the

1300
00:52:29,040 --> 00:52:32,240
organizers so okay um cool so um we'll

1301
00:52:32,240 --> 00:52:34,480
end the session here and let's um

1302
00:52:34,480 --> 00:52:36,319
thank robot with another round of

1303
00:52:36,319 --> 00:52:37,920
applause

1304
00:52:37,920 --> 00:52:39,760
thank you

1305
00:52:39,760 --> 00:52:41,520
take care

1306
00:52:41,520 --> 00:52:44,720
um thank you

