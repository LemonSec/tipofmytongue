1
00:00:01,890 --> 00:00:23,490
okay okay well thanks thanks for the
opportunity to speak so I'm gonna post

2
00:00:23,490 --> 00:00:29,418
august the University of Luxembourg and
I'm going to talk to you about an

3
00:00:29,419 --> 00:00:33,820
interesting well what I would expect to
be an interesting crypto primitive for

4
00:00:33,820 --> 00:00:38,949
an audience like this which is a
password authenticated key exchange and

5
00:00:38,949 --> 00:00:44,839
more specifically the modeling of this
primitive in the crypt a world tour in

6
00:00:44,840 --> 00:00:51,940
the provable security world so it's
basically a two-part talk where I start

7
00:00:51,940 --> 00:00:57,079
by explaining what password
authenticated key exchanges and maybe

8
00:00:57,079 --> 00:01:01,390
giving you I i've been asked to give a
maybe a small definitely not exhaustive

9
00:01:01,390 --> 00:01:06,450
list of some of the protocols that
exists and then I'll talk to you about

10
00:01:06,450 --> 00:01:11,530
security model definitions and
specifically some little differences

11
00:01:11,530 --> 00:01:16,030
between models that bother me and I'll
tell you why they bother me and how I've

12
00:01:16,030 --> 00:01:22,159
tried to maybe not correct them because
that's a bit that's that's a bit 22

13
00:01:22,159 --> 00:01:29,820
would be a bit too too exaggerated but
I'm trying to understand them and I'm

14
00:01:29,820 --> 00:01:38,210
trying to interpret them or over or make
adjustments to to to help out so it's

15
00:01:38,210 --> 00:01:42,429
the Alice and Bob setting of the crypto
world of course where you have Alice and

16
00:01:42,430 --> 00:01:48,119
Bob who are trying to run some
cryptographic service over a network and

17
00:01:48,119 --> 00:01:52,130
to do so they need to share some session
key for that only they don't know what

18
00:01:52,130 --> 00:01:57,560
the quality of that networkers in the
sense that there might be some attacker

19
00:01:57,560 --> 00:02:03,000
in the middle so the best way to do that
is to run a key exchange algorithm that

20
00:02:03,000 --> 00:02:07,920
has authentication attached to or
incorporated into it and password

21
00:02:07,920 --> 00:02:15,650
authenticated key exchange uses as a
trusted set up passwords so Alice and

22
00:02:15,650 --> 00:02:21,739
Bob each hold the password and the basic
basic correctness requirement or

23
00:02:21,739 --> 00:02:26,620
function basic correctness requirement
of this primitive is that if the two

24
00:02:26,620 --> 00:02:30,879
entities are running this protocol then
they're going to end up with the same

25
00:02:30,879 --> 00:02:36,260
session key if and only if they had the
same password now this can be a little

26
00:02:36,260 --> 00:02:41,780
bit modified one user can have a hash of
the password on the other one can hold

27
00:02:41,780 --> 00:02:45,250
the actual password but those are small
differences that don't change the

28
00:02:45,250 --> 00:02:47,030
functionality very much

29
00:02:47,030 --> 00:02:50,580
something I didn't write on the slide is
the session key they obtained as high

30
00:02:50,580 --> 00:02:56,170
entropy whereas the password of courses
is low entropy so it's a way to kind of

31
00:02:56,170 --> 00:03:01,750
bootstrap high entropy security from
from the low entropy secret which is

32
00:03:01,750 --> 00:03:09,680
quite unique in the crypt of course as
you all know this is a fundamentally

33
00:03:09,680 --> 00:03:12,769
different from usual key exchange
protocols which rely on public

34
00:03:12,769 --> 00:03:18,670
infrastructure or shared secret keys
that are a yes keys or things like that

35
00:03:18,670 --> 00:03:23,879
passwords being well entropy they can be
brute forced so you can have a kind of a

36
00:03:23,879 --> 00:03:29,069
kind of a a secret key that is the
password and to have a public key that

37
00:03:29,069 --> 00:03:34,670
corresponds to that passwords just not
going to work of course the brute

38
00:03:34,670 --> 00:03:38,890
forcing of pastors as possible only
assuming that they can be verified so

39
00:03:38,890 --> 00:03:44,319
it's the verification of guesses that's
crucial to pay attention to in these

40
00:03:44,319 --> 00:03:52,030
protocols and there are two types of we
usually classified the attacks on takes

41
00:03:52,030 --> 00:03:57,390
between offline dictionary attacks first
where what happens is you have all this

42
00:03:57,390 --> 00:04:01,849
data flying around on the network
between honest users so these are these

43
00:04:01,849 --> 00:04:07,099
arrows represent either protocol runs of
the protocol itself or they can

44
00:04:07,099 --> 00:04:08,340
represent you

45
00:04:08,340 --> 00:04:13,080
session keys that are used in higher
level applications all this data

46
00:04:13,080 --> 00:04:17,209
ends in one way or another on the
password or input to the protocol of

47
00:04:17,209 --> 00:04:21,079
course an offline attack the adversary
who is the network gets to see all of

48
00:04:21,079 --> 00:04:24,940
that and tries to correlate the
information that it sees with pass from

49
00:04:24,940 --> 00:04:30,120
guesses of its own and this is only
useful for him if he can do this in with

50
00:04:30,120 --> 00:04:36,370
efficiently computable functions and
some some dictionary attacks are

51
00:04:36,370 --> 00:04:40,680
essentially eavesdroppers that are
trying to correlate pass from data with

52
00:04:40,680 --> 00:04:43,390
with what is what's what's flying around
on the net

53
00:04:43,390 --> 00:04:48,440
an example of a bad pic protocol that
would do this as something like this

54
00:04:48,440 --> 00:04:53,760
where you just you want to authenticate
a diffie-hellman key exchange by just

55
00:04:53,760 --> 00:04:58,650
buying the password to the
diffie-hellman key exchange itself using

56
00:04:58,650 --> 00:05:03,940
a hash this is obviously a vector for an
offline dictionary attack on the

57
00:05:03,940 --> 00:05:06,160
password

58
00:05:06,160 --> 00:05:09,140
unpaid protocols when they're trying to
prove things we want to eliminate

59
00:05:09,140 --> 00:05:15,490
offline attacks completely and we can do
this it's possible to do this I say it's

60
00:05:15,490 --> 00:05:18,330
possible to prove it at least because
then it depends on what you consider

61
00:05:18,330 --> 00:05:23,310
proven depending on what what kind of
idealization you make an approval

62
00:05:23,310 --> 00:05:28,340
security frameworks also few words about
that later an online dictionary attacks

63
00:05:28,340 --> 00:05:32,340
you have something a little bit
different you have an honest user which

64
00:05:32,340 --> 00:05:37,560
is expecting to talk to somebody to
somebody else that's honest and engages

65
00:05:37,560 --> 00:05:44,290
in a protocol run but is actually
talking to a malicious adversary who is

66
00:05:44,290 --> 00:05:49,630
trying to infer information on the
password like that that's an online

67
00:05:49,630 --> 00:05:53,430
attack the online attack me there's
interaction basically and testing is

68
00:05:53,430 --> 00:05:58,160
done directly through this interaction
and the the the prototype of such an

69
00:05:58,160 --> 00:06:03,669
attack is a simple log-in what's what's
particular about online dictionary

70
00:06:03,669 --> 00:06:07,500
attacks that in the paid service when
you're trying to model it it's something

71
00:06:07,500 --> 00:06:10,930
that we can avoid something that's
inherent to the service and the crypto

72
00:06:10,930 --> 00:06:15,880
can't do anything about at least not at
this level so we had to factor that

73
00:06:15,880 --> 00:06:21,050
somehow into the security model what we
can do is eliminate them but we can try

74
00:06:21,050 --> 00:06:22,470
to do is make sure

75
00:06:22,470 --> 00:06:29,060
that login attempts are the only
possible ways of attacking the system so

76
00:06:29,060 --> 00:06:35,940
here's a slight a DUI last night which
which which kind of recaps a few some

77
00:06:35,940 --> 00:06:39,969
protocols that exists out there
basically paying research started as

78
00:06:39,970 --> 00:06:43,670
early as 1992 with encrypted key
exchange which you may have heard of

79
00:06:43,670 --> 00:06:51,200
that was invented by Bulova and merit
and it basically entails a symmetric

80
00:06:51,200 --> 00:06:54,570
encryption of addition Helmand key
exchange with the symmetric key itself

81
00:06:54,570 --> 00:07:02,380
being the the encryption key so it has
been analyzed in what's called the ideal

82
00:07:02,380 --> 00:07:06,300
site for model crypto but it's very
difficult to implement to avoid offline

83
00:07:06,300 --> 00:07:11,890
dictionary tax it's tricky to implement
another example is speak with you may

84
00:07:11,890 --> 00:07:15,830
have also heard of these two are kind of
the most known because they're also the

85
00:07:15,830 --> 00:07:19,039
ones that have caused the most trouble
if from a patent point of view

86
00:07:19,040 --> 00:07:23,300
I've heard I've heard that people tried
to deploy peaks but it's hard to do so

87
00:07:23,300 --> 00:07:28,090
because they keep getting they keep
getting patent roadblocks and it seems

88
00:07:28,090 --> 00:07:32,239
to be essentially due to these 20 lot of
protocols are kind of variations on

89
00:07:32,240 --> 00:07:39,220
these two especially on one example of
this is the pack and PPK protocols that

90
00:07:39,220 --> 00:07:48,140
came out and 2000 pack provides explicit
mutual authentication PPK prize implicit

91
00:07:48,140 --> 00:07:52,130
authentication so they're different
security properties you can look at

92
00:07:52,130 --> 00:07:56,840
there is a protocol from 2001 which was
kind of an important one at least from

93
00:07:56,840 --> 00:08:02,039
the theory community will from castro
skin you know where the idea here is

94
00:08:02,040 --> 00:08:06,960
they were able to prove secure their
protocol and the specific the sports

95
00:08:06,960 --> 00:08:11,409
specific about this protocol is that it
doesn't require any random oracles are

96
00:08:11,410 --> 00:08:14,840
ideal ciphers to get approved to go
through so it's a standard model

97
00:08:14,840 --> 00:08:21,919
protocol but it comes with a different
caveat that that's I don't want to get

98
00:08:21,919 --> 00:08:27,570
into right now it's also much less it's
also less practical a lot of protocol

99
00:08:27,570 --> 00:08:29,169
spun off of this last one

100
00:08:29,169 --> 00:08:35,519
in the sense that there are secure
without idealized assumptions are still

101
00:08:35,519 --> 00:08:41,769
there security using standard number
theoretical assumptions but they also

102
00:08:41,769 --> 00:08:45,930
cost more to implement I mean there they
they they have a lot more than a lot

103
00:08:45,930 --> 00:08:49,638
more group multiplication and
exponentiation these than the ones that

104
00:08:49,639 --> 00:08:54,699
rely on random oracles so they tend to
be much less practical theoretically

105
00:08:54,699 --> 00:08:57,599
efficient but they're much less
practical and I don't think they've been

106
00:08:57,600 --> 00:09:04,570
implemented so much and there are other
there so there's the JPEG protocol by

107
00:09:04,570 --> 00:09:10,730
how and Ryan from 2008 which is secure
in the random oracle model but is a

108
00:09:10,730 --> 00:09:14,160
structure the structure is sufficiently
different from the previous protocols

109
00:09:14,160 --> 00:09:18,529
that this one isn't bothered by
Pattinson I think it seems somodevilla

110
00:09:18,529 --> 00:09:24,230
for instance use this in some of their
own and some of their features I don't

111
00:09:24,230 --> 00:09:29,550
think they use it anymore I can't recall
why there's also a protocol by a

112
00:09:29,550 --> 00:09:34,969
dragonfly by drunk by Dan Harkins from
2008 which kind of looks like the speak

113
00:09:34,970 --> 00:09:40,620
protocol from jablon but is sufficiently
different that maybe it it it it's not

114
00:09:40,620 --> 00:09:44,040
bothered by patents and there's a whole
bunch of other protocols that theory

115
00:09:44,040 --> 00:09:49,050
people have have come up with with over
time so it's not like there isn't a lack

116
00:09:49,050 --> 00:09:54,250
of protocols but maybe we're out so good
at communicating that and I'll talk a

117
00:09:54,250 --> 00:09:58,980
little bit about security models and the
problems that I kind of have with them

118
00:09:58,980 --> 00:10:03,230
so first there are many models in the
literature starting with the blog a

119
00:10:03,230 --> 00:10:09,019
rogue wave and flashing LED model which
I'll just called BPR that was a

120
00:10:09,019 --> 00:10:12,730
so-called in distinguishing bility based
model and there's a model by Boyko

121
00:10:12,730 --> 00:10:18,190
McKenzie and Patel which is one of the
simulation based models Kennedy and is

122
00:10:18,190 --> 00:10:23,579
listed for other authors don't recall
came up with a model for pay cuts

123
00:10:23,579 --> 00:10:28,660
universally composable and yet another
one goal duration

124
00:10:28,660 --> 00:10:32,540
Lyndell came up with a model just so
that they could have a framework to show

125
00:10:32,540 --> 00:10:38,560
that take as possible under standard
complexity theoretic assumptions so that

126
00:10:38,560 --> 00:10:42,089
that's already a lot of models so it's
hard to describe it's hard to see which

127
00:10:42,089 --> 00:10:46,009
one is the good one if there is a good
one which is already kind of something

128
00:10:46,009 --> 00:10:50,240
that bothered me but it gets a little
bit worse than that so within within

129
00:10:50,240 --> 00:10:54,639
though the pool models that exists the
most successful ones have been the blog

130
00:10:54,639 --> 00:11:00,819
points about rogue away one which all
described as soon as an important role

131
00:11:00,819 --> 00:11:08,040
play at al from 2005 so we're going to
focus on these and already in this kind

132
00:11:08,040 --> 00:11:12,589
of some class of models their little
technical differences between models

133
00:11:12,589 --> 00:11:18,769
that make it kind of difficult to assess
security somehow so it's it's I find it

134
00:11:18,769 --> 00:11:22,300
difficult as someone who looks at this
alot I can't imagine what it's like for

135
00:11:22,300 --> 00:11:26,430
someone who's a practitioner who wants
to get some assurance that our protocol

136
00:11:26,430 --> 00:11:32,969
is is correct or is secure so I'll get
into the descriptive description of the

137
00:11:32,970 --> 00:11:39,600
BPR model and how it works but we start
with as a fixed collection of users

138
00:11:39,600 --> 00:11:40,600
which is usually do

139
00:11:40,600 --> 00:11:45,600
separated between a bunch of clients and
servers that's not very strict and our

140
00:11:45,600 --> 00:11:50,759
adversaries in polynomial time adversary
which just represents the network and

141
00:11:50,759 --> 00:11:54,519
it's the one that communicates with
these users now before your for your

142
00:11:54,519 --> 00:11:59,319
security game begins each client is
given as a signed a password for

143
00:11:59,319 --> 00:12:03,880
simplicity is like that uniformly at
random from my password from a password

144
00:12:03,880 --> 00:12:10,579
set any server is assigned a vector of
passwords from all of the clients so

145
00:12:10,579 --> 00:12:15,599
these things can change also from from
paper paper more specifically the the

146
00:12:15,600 --> 00:12:19,660
attackers and going to talk to users
it's going to talk to user instances and

147
00:12:19,660 --> 00:12:24,360
you can think of a user instance as you
want to run of the protocol being

148
00:12:24,360 --> 00:12:26,029
attempted by that user

149
00:12:26,029 --> 00:12:30,610
so we just indexed these instances with
them with integers

150
00:12:30,610 --> 00:12:34,690
how an instance functions as it gets
instructions from the adversary and

151
00:12:34,690 --> 00:12:39,510
reacts to those it reacts according to
protocol specification eventually it

152
00:12:39,510 --> 00:12:43,579
might compute some kind of my computer
session key or it might reject messages

153
00:12:43,579 --> 00:12:48,250
but if it computes a session key and
then it thinks it should it should it

154
00:12:48,250 --> 00:12:53,640
thinks it shares the ski with what it
believes to be at parker and the way the

155
00:12:53,640 --> 00:12:58,180
adversary communicates and model of
these instances vaya queries various

156
00:12:58,180 --> 00:13:01,959
queries so for instance use the send
enquiry which delivers messages of the

157
00:13:01,959 --> 00:13:06,109
adversaries choice to these instances
and see what happens if a response is

158
00:13:06,110 --> 00:13:08,339
generated the adversary gets it

159
00:13:08,339 --> 00:13:13,810
the execute query just runs the protocol
honestly between two instances and gives

160
00:13:13,810 --> 00:13:19,630
the adversary access to a whole pool of
honest protocol runs to eavesdrop on and

161
00:13:19,630 --> 00:13:26,320
the reveal prairie basically what we do
is we don't know which one calling the

162
00:13:26,320 --> 00:13:33,670
algorithms are our session kids are
going to be run and are there is also a

163
00:13:33,670 --> 00:13:38,010
pessimistic we assume that the adversary
can just obtain any session Kia wants by

164
00:13:38,010 --> 00:13:44,420
looking at serving the network the idea
being that if a session has disclosed

165
00:13:44,420 --> 00:13:49,339
that shouldn't damage the security of
other protocols and we have the special

166
00:13:49,339 --> 00:13:53,230
test query which is used only to measure
the adversary success and a model like

167
00:13:53,230 --> 00:13:59,680
this so the test Cory works is it gets
in it it it it once it's invoked by the

168
00:13:59,680 --> 00:14:05,019
adversary you flip a bit and what you
get with the anderson gets in return is

169
00:14:05,019 --> 00:14:10,899
either a random key if this bit was no
or the actual session key that was

170
00:14:10,899 --> 00:14:16,279
computed if the bit is set to 1 and the
adversaries goal in the whole game the

171
00:14:16,279 --> 00:14:19,769
way we measure of the adversary security
is to check for us whether it can still

172
00:14:19,769 --> 00:14:25,930
check can output correct guess on this
bit her she wins the game if the bits

173
00:14:25,930 --> 00:14:29,420
are equal and it loses otherwise

174
00:14:29,420 --> 00:14:32,900
so what we want to hear so we're trying
to measure the Sandman what we call the

175
00:14:32,900 --> 00:14:39,600
Symantec Security of the session key
advantage in winning is typically what

176
00:14:39,600 --> 00:14:46,090
is typically this for ordinary
authenticated key exchange the advantage

177
00:14:46,090 --> 00:14:51,260
is defined as being twice the
probability that it wins 2-1 and when

178
00:14:51,260 --> 00:14:57,710
you're looking at high entropy high
entropy based protocols we require this

179
00:14:57,710 --> 00:15:01,170
to be negligible we can we can do that
because the because of the the other

180
00:15:01,170 --> 00:15:06,040
long-term key material is its high
entropy but for patrons a bit

181
00:15:06,040 --> 00:15:11,130
differently can't do that because we
have to factor in the fact that there

182
00:15:11,130 --> 00:15:14,810
are online dictionary attacks that are
possible and these will succeed

183
00:15:14,810 --> 00:15:18,969
depending on the size the password space
surrendering those negligible as an

184
00:15:18,970 --> 00:15:23,460
option anymore so if the change your
requirement for a little bit the

185
00:15:23,460 --> 00:15:27,690
requirement on the bound we want now is
this we want to make sure that the

186
00:15:27,690 --> 00:15:31,390
advantage of smaller than a constant
times the number of sand quarry is

187
00:15:31,390 --> 00:15:37,900
divided by the size of the passwords
base plus some negligible chance so here

188
00:15:37,900 --> 00:15:41,819
she is just some constant it represents
into an early should represent the

189
00:15:41,820 --> 00:15:47,880
number of passwords that can be ruled
out but in one login attempt but so

190
00:15:47,880 --> 00:15:52,040
ideally would want this to be one the
number of sankara's basically measures

191
00:15:52,040 --> 00:15:55,719
the number of interactions with intense
with instances and you don't use the

192
00:15:55,720 --> 00:16:03,250
bathroom space just taking longer than I
thought so the definition is only

193
00:16:03,250 --> 00:16:06,900
meaningful after we've had a restriction
however because we don't want to be

194
00:16:06,900 --> 00:16:12,470
testing aqui that's already been
revealed to the adversary so where we

195
00:16:12,470 --> 00:16:16,060
need to what we need to add as a
restriction has that the user instance

196
00:16:16,060 --> 00:16:20,469
can be tested if its partner or if
itself has been has already been

197
00:16:20,470 --> 00:16:28,300
revealed and that's where a lot of
problems begin at least for me so maybe

198
00:16:28,300 --> 00:16:32,640
I'll skip skip a few things here to get
to the point the point is that we don't

199
00:16:32,640 --> 00:16:36,010
really know what a partner is anyway
this is the thing that changes from

200
00:16:36,010 --> 00:16:39,819
paper to paper intuitively instances and
want to be part of her

201
00:16:39,820 --> 00:16:43,280
heard if they had a correct exchange but
we don't know how to form we can't seem

202
00:16:43,280 --> 00:16:48,790
to formalize this very well or
consistently across papers assessing

203
00:16:48,790 --> 00:16:51,490
secure least from my point of view it
seems to make assessing security

204
00:16:51,490 --> 00:16:57,300
difficult I don't see how you would how
you can trust the security in one model

205
00:16:57,300 --> 00:17:00,910
of a protocol that securing one model
but that doesn't carry over to another

206
00:17:00,910 --> 00:17:07,750
mall so what I guess one take away from
the stock is that there are a lot of

207
00:17:07,750 --> 00:17:13,109
technical variables that that are used
to keep track of what instances key

208
00:17:13,109 --> 00:17:17,659
moments in instances life during the
during the execution would be one that's

209
00:17:17,660 --> 00:17:22,240
willing to use a session key when it
stops 12 instances are partnered and

210
00:17:22,240 --> 00:17:26,640
these are things that change all the
time so it in the paper what I tried to

211
00:17:26,640 --> 00:17:33,490
do is come up with a consistent way to
to put all these to put all these

212
00:17:33,490 --> 00:17:38,060
together which kind of sounds like I've
added so I'm gonna skip all this because

213
00:17:38,060 --> 00:17:44,190
these are details that are not going to
take too far but it kinda sounds like

214
00:17:44,190 --> 00:17:48,470
I'm just proposed another model but I
don't see it that way I just see it as

215
00:17:48,470 --> 00:17:52,660
an adjustment to the ones that kind of
exist and I couldn't see myself

216
00:17:52,660 --> 00:17:58,100
complaining about certain things without
trying to suggest something not to

217
00:17:58,100 --> 00:18:02,439
replace but at least to try to explain
the others

218
00:18:02,440 --> 00:18:07,790
one thing that I found particularly
annoying as in the partnering definition

219
00:18:07,790 --> 00:18:11,780
there are two different kinds of
philosophies some of them are going to

220
00:18:11,780 --> 00:18:16,200
have a partnering definition of this
formula list of technical conditions and

221
00:18:16,200 --> 00:18:21,870
on two instances and these instances are
unique in satisfying these conditions or

222
00:18:21,870 --> 00:18:26,820
sometimes this condition has dropped and
I found that this causes a bug at least

223
00:18:26,820 --> 00:18:31,840
in it causes a bug in certain models
definitional II and I wanted to try to

224
00:18:31,840 --> 00:18:34,559
fix this bug so that

225
00:18:34,559 --> 00:18:39,129
so at least it made more sense to me and
maybe it'll make more sense to other

226
00:18:39,129 --> 00:18:40,789
people as well

227
00:18:40,789 --> 00:18:46,139
this unique Mustang has also bugged me
and another way so in the paper I show

228
00:18:46,139 --> 00:18:49,498
that if I ignore it I keep in the
partnering definition and it causes

229
00:18:49,499 --> 00:18:54,499
trouble definition it causes a bug in in
in in one of the models which bothers me

230
00:18:54,499 --> 00:19:01,029
but ignoring it completely is ill
advised as well so I'm going to I won't

231
00:19:01,029 --> 00:19:05,669
go it would not go over the bug because
it's again it's technical and I'm

232
00:19:05,669 --> 00:19:17,940
running out of time but ok so the thing
so now I'll talk about what happens if

233
00:19:17,940 --> 00:19:22,499
you try to eliminate uniqueness
completely from the definition so you

234
00:19:22,499 --> 00:19:26,740
need to some of the partners something
you would require an authenticated key

235
00:19:26,740 --> 00:19:31,039
exchange protocols and natural
requirement I want if two instances are

236
00:19:31,039 --> 00:19:34,210
partnered they should be they should be
uniquely partner there shouldn't be a

237
00:19:34,210 --> 00:19:39,419
third one hanging around but this
requirement on land off as vanished from

238
00:19:39,419 --> 00:19:44,240
authenticated key exchange papers not
just past four runs and that that's a

239
00:19:44,240 --> 00:19:47,690
little strange because one of the first
the very first paper on authenticated

240
00:19:47,690 --> 00:19:55,059
key exchange have this as a property
that was proven so I found a weird one

241
00:19:55,059 --> 00:20:00,749
reason I guess for this is that some
people it seems to be assumed that maybe

242
00:20:00,749 --> 00:20:07,580
session key security implies uniqueness
of partners but by reason of this for

243
00:20:07,580 --> 00:20:13,100
multiple partners would imply violating
the partnering so I have to put

244
00:20:13,100 --> 00:20:16,469
partnering because if you have
uniqueness or not then partner is

245
00:20:16,470 --> 00:20:21,279
formally invalidated this would imply a
legal way to distinguish session keys

246
00:20:21,279 --> 00:20:26,999
from random and therefore would be
captured by the definition but first can

247
00:20:26,999 --> 00:20:32,429
get the store maybe somebody has been I
could not any straightforward way and

248
00:20:32,429 --> 00:20:36,649
secondly even if it did or password
based key exchange this wouldn't even

249
00:20:36,649 --> 00:20:41,639
help us because the security bound thats
optimal intakes isn't even enough

250
00:20:41,639 --> 00:20:47,549
double bound so we can guarantee unique
partners with negligible problem with

251
00:20:47,549 --> 00:20:54,279
overwhelming probability even if we just
rely on session he Securi now it's in

252
00:20:54,279 --> 00:20:58,409
the literature the pics that you find a
security proves don't suffer from this

253
00:20:58,409 --> 00:21:03,109
because of the way the partners are
partnering function is defined it takes

254
00:21:03,109 --> 00:21:07,619
as it takes it's a function of the
randomness of both partners so there's

255
00:21:07,619 --> 00:21:11,019
always gonna be the randomness of the
partner included in the way the

256
00:21:11,019 --> 00:21:15,200
partnering functions computed in the
paper

257
00:21:15,200 --> 00:21:20,759
protocol which is kind of convoluted but
that shows that you can create a pic

258
00:21:20,759 --> 00:21:25,609
kind of cake that allows multiple
partners with a non negligible

259
00:21:25,609 --> 00:21:30,178
probability but at the same time has a
security proof in a model where you

260
00:21:30,179 --> 00:21:35,739
don't pay attention to this uniqueness
stuff so so I really think that

261
00:21:35,739 --> 00:21:39,659
uniqueness of partners among other
things ought to be an explicitly proven

262
00:21:39,659 --> 00:21:44,379
property even if it's easy to do it's
very it's it's it's almost the first

263
00:21:44,379 --> 00:21:48,089
thing you prove when you're going
through the pics security proof I find

264
00:21:48,089 --> 00:21:50,869
it would make a more complete and a
clear model and that it wouldn't be

265
00:21:50,869 --> 00:21:52,428
making more sense

266
00:21:52,429 --> 00:21:55,739
mathematically because if you have i
mean I say make more sense

267
00:21:55,739 --> 00:22:01,059
mathematically because the definitions
if they have bugs on them then it's kind

268
00:22:01,059 --> 00:22:04,320
of I find it pointless to try to do
something mathematically with

269
00:22:04,320 --> 00:22:09,249
definitions that are bugs in them if
you're not precise at it it's just not

270
00:22:09,249 --> 00:22:14,399
as not real mathematics somehow so if we
want to do this in a provably secure way

271
00:22:14,399 --> 00:22:21,879
we need to make it as mathematically
credible as possible so i think i think

272
00:22:21,879 --> 00:22:25,149
im young done so I'll just stop there
and I'm happy to take questions

