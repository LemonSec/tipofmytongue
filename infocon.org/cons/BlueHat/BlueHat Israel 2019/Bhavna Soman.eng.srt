1
00:00:00,000 --> 00:00:02,729
[Music]

2
00:00:11,190 --> 00:00:15,389
<font color="#E5E5E5">all right a little</font><font color="#CCCCCC"> bit about me my name</font>

3
00:00:13,260 --> 00:00:16,830
<font color="#CCCCCC">is Bhavna</font><font color="#E5E5E5"> somin I'm a</font><font color="#CCCCCC"> security</font>

4
00:00:15,389 --> 00:00:20,310
researcher<font color="#E5E5E5"> with</font><font color="#CCCCCC"> the</font><font color="#E5E5E5"> Windows Defender</font>

5
00:00:16,830 --> 00:00:22,500
research team<font color="#E5E5E5"> in the past I used</font><font color="#CCCCCC"> to work</font>

6
00:00:20,310 --> 00:00:26,009
in threat intelligence and doing<font color="#E5E5E5"> a PD</font>

7
00:00:22,500 --> 00:00:28,859
<font color="#CCCCCC">Response</font><font color="#E5E5E5"> in my day job</font><font color="#CCCCCC"> right now I</font><font color="#E5E5E5"> work</font>

8
00:00:26,009 --> 00:00:31,590
on classifying<font color="#E5E5E5"> malware in</font><font color="#CCCCCC"> real time</font>

9
00:00:28,859 --> 00:00:34,140
<font color="#E5E5E5">building models for that so this project</font>

10
00:00:31,590 --> 00:00:36,720
<font color="#E5E5E5">kind of came about as an amalgamation of</font>

11
00:00:34,140 --> 00:00:38,070
<font color="#E5E5E5">my past</font><font color="#CCCCCC"> doing threat intelligence and</font>

12
00:00:36,720 --> 00:00:42,239
what I do right now<font color="#E5E5E5"> with machine</font>

13
00:00:38,070 --> 00:00:44,309
learning<font color="#E5E5E5"> so when most of us</font><font color="#CCCCCC"> hear threat</font>

14
00:00:42,239 --> 00:00:47,339
intelligence we think of the automated

15
00:00:44,309 --> 00:00:49,860
<font color="#E5E5E5">IOC feeds but there is a much richer</font>

16
00:00:47,340 --> 00:00:51,660
data set that<font color="#E5E5E5"> describes the act the</font>

17
00:00:49,860 --> 00:00:54,890
actions of threat actors you know<font color="#E5E5E5"> their</font>

18
00:00:51,660 --> 00:00:58,230
tools tactics procedures victims<font color="#E5E5E5"> etc and</font>

19
00:00:54,890 --> 00:01:01,050
much<font color="#CCCCCC"> of</font><font color="#E5E5E5"> this data is unstructured it's</font>

20
00:00:58,230 --> 00:01:03,059
contained in blogs white papers<font color="#CCCCCC"> incident</font>

21
00:01:01,050 --> 00:01:05,369
<font color="#E5E5E5">response reports that people have to</font>

22
00:01:03,059 --> 00:01:07,860
read and analyze<font color="#E5E5E5"> and that's kind of the</font>

23
00:01:05,369 --> 00:01:11,369
bulk of the work<font color="#CCCCCC"> that a TI analyst has</font>

24
00:01:07,860 --> 00:01:14,940
to do<font color="#E5E5E5"> let me</font><font color="#CCCCCC"> show you an</font><font color="#E5E5E5"> example of the</font>

25
00:01:11,369 --> 00:01:17,429
kind<font color="#E5E5E5"> of workflow they follow so maybe</font>

26
00:01:14,940 --> 00:01:20,369
you're an analyst<font color="#E5E5E5"> who works for an org</font>

27
00:01:17,429 --> 00:01:23,250
<font color="#E5E5E5">that's concerned about attacks from an</font>

28
00:01:20,369 --> 00:01:25,560
Eastern European country<font color="#E5E5E5"> so you go out</font>

29
00:01:23,250 --> 00:01:26,670
<font color="#CCCCCC">and</font><font color="#E5E5E5"> start to do some</font><font color="#CCCCCC"> reading</font><font color="#E5E5E5"> maybe you</font>

30
00:01:25,560 --> 00:01:30,390
learn<font color="#E5E5E5"> about you know these three</font>

31
00:01:26,670 --> 00:01:32,520
attackers<font color="#E5E5E5"> apt 28 and 29 which have been</font>

32
00:01:30,390 --> 00:01:35,039
active since 2007 and eight<font color="#E5E5E5"> and then</font>

33
00:01:32,520 --> 00:01:38,520
<font color="#CCCCCC">dragonfly which is kind</font><font color="#E5E5E5"> of newer circle</font>

34
00:01:35,039 --> 00:01:39,509
2011<font color="#CCCCCC"> and</font><font color="#E5E5E5"> you read up about you know</font>

35
00:01:38,520 --> 00:01:41,640
their tools tactics and procedures

36
00:01:39,509 --> 00:01:44,459
dragonfly is focused more on cyber

37
00:01:41,640 --> 00:01:47,610
espionage 28 and 29 have more political

38
00:01:44,459 --> 00:01:50,340
<font color="#E5E5E5">targets with 28 focusing more on Eastern</font>

39
00:01:47,610 --> 00:01:53,429
European governments and then<font color="#E5E5E5"> 29 more on</font>

40
00:01:50,340 --> 00:01:54,899
Western political<font color="#E5E5E5"> institutions so you</font>

41
00:01:53,429 --> 00:01:57,840
read up all of this information about

42
00:01:54,899 --> 00:02:00,899
<font color="#E5E5E5">them and then maybe you create like this</font>

43
00:01:57,840 --> 00:02:03,090
<font color="#CCCCCC">shoebox</font><font color="#E5E5E5"> of TTP's which is you know like</font>

44
00:02:00,899 --> 00:02:04,649
<font color="#E5E5E5">okay</font><font color="#CCCCCC"> so this particular apt</font><font color="#E5E5E5"> uses spear</font>

45
00:02:03,090 --> 00:02:07,470
<font color="#CCCCCC">fishing</font><font color="#E5E5E5"> and then they drop off the</font><font color="#CCCCCC"> SCADA</font>

46
00:02:04,649 --> 00:02:10,250
<font color="#E5E5E5">PowerShell</font><font color="#CCCCCC"> to get you know do you put</font>

47
00:02:07,470 --> 00:02:14,340
that<font color="#E5E5E5"> malware implant</font><font color="#CCCCCC"> so on and so forth</font>

48
00:02:10,250 --> 00:02:17,520
<font color="#CCCCCC">but this data is not really it's</font><font color="#E5E5E5"> very</font>

49
00:02:14,340 --> 00:02:19,830
complex it's not<font color="#CCCCCC"> useful yet so if you're</font>

50
00:02:17,520 --> 00:02:21,150
a really good T I analyzed<font color="#CCCCCC"> you create a</font>

51
00:02:19,830 --> 00:02:23,760
graph like<font color="#CCCCCC"> this</font>

52
00:02:21,150 --> 00:02:25,650
connecting the<font color="#CCCCCC"> TTP's</font><font color="#E5E5E5"> between these</font><font color="#CCCCCC"> two</font>

53
00:02:23,760 --> 00:02:26,970
actors and now you can<font color="#E5E5E5"> start to make a</font>

54
00:02:25,650 --> 00:02:29,879
<font color="#E5E5E5">little bit more sense you can clearly</font>

55
00:02:26,970 --> 00:02:32,640
see at a glance which TTP's are common

56
00:02:29,879 --> 00:02:34,440
between these<font color="#E5E5E5"> three</font><font color="#CCCCCC"> in fact you can see</font>

57
00:02:32,640 --> 00:02:36,359
<font color="#E5E5E5">that there's not that</font><font color="#CCCCCC"> much</font><font color="#E5E5E5"> that</font><font color="#CCCCCC"> is</font>

58
00:02:34,440 --> 00:02:37,769
common between<font color="#E5E5E5"> them in fact</font><font color="#CCCCCC"> apd 28 has a</font>

59
00:02:36,360 --> 00:02:40,290
very complicated networking

60
00:02:37,769 --> 00:02:44,069
<font color="#CCCCCC">infrastructure which is mostly absent</font>

61
00:02:40,290 --> 00:02:46,379
from the other two<font color="#E5E5E5"> maybe you go a step</font>

62
00:02:44,069 --> 00:02:49,048
further and then you overlay<font color="#E5E5E5"> this data</font>

63
00:02:46,379 --> 00:02:52,018
with the prevalence<font color="#E5E5E5"> of each technique so</font>

64
00:02:49,049 --> 00:02:54,510
now the size of the bubble is dependent

65
00:02:52,019 --> 00:02:58,319
<font color="#E5E5E5">on how prevalent each technique is in</font>

66
00:02:54,510 --> 00:03:00,269
general<font color="#E5E5E5"> not</font><font color="#CCCCCC"> just with</font><font color="#E5E5E5"> these attackers so</font>

67
00:02:58,319 --> 00:03:04,708
now you can<font color="#E5E5E5"> start to use</font><font color="#CCCCCC"> this graph to</font>

68
00:03:00,269 --> 00:03:06,659
<font color="#CCCCCC">maybe drive some data based conclusions</font>

69
00:03:04,709 --> 00:03:08,489
for your organization<font color="#E5E5E5"> maybe</font><font color="#CCCCCC"> you can</font>

70
00:03:06,659 --> 00:03:10,739
recommend<font color="#CCCCCC"> that</font><font color="#E5E5E5"> you know you focus your</font>

71
00:03:08,489 --> 00:03:13,230
network defenses or choke points on

72
00:03:10,739 --> 00:03:16,260
detecting<font color="#E5E5E5"> you know obfuscated PowerShell</font>

73
00:03:13,230 --> 00:03:18,209
or credential<font color="#E5E5E5"> damping tools because you</font>

74
00:03:16,260 --> 00:03:19,950
can show clearly<font color="#CCCCCC"> that those are the</font>

75
00:03:18,209 --> 00:03:22,019
<font color="#E5E5E5">techniques</font><font color="#CCCCCC"> that will effectively help</font>

76
00:03:19,950 --> 00:03:23,640
disrupt the tool chain of the attackers

77
00:03:22,019 --> 00:03:24,930
that you're concerned about<font color="#E5E5E5"> and then you</font>

78
00:03:23,640 --> 00:03:27,388
might<font color="#E5E5E5"> recommend that you know hey</font><font color="#CCCCCC"> let's</font>

79
00:03:24,930 --> 00:03:29,010
not<font color="#E5E5E5"> focus</font><font color="#CCCCCC"> so much on time</font><font color="#E5E5E5"> stamping and</font>

80
00:03:27,389 --> 00:03:31,769
<font color="#E5E5E5">boot kits which you know they're really</font>

81
00:03:29,010 --> 00:03:34,230
<font color="#E5E5E5">cool but</font><font color="#CCCCCC"> in terms of</font><font color="#E5E5E5"> your you know</font>

82
00:03:31,769 --> 00:03:36,840
return on investment they will mean less

83
00:03:34,230 --> 00:03:39,599
for your organization so<font color="#CCCCCC"> this is the</font>

84
00:03:36,840 --> 00:03:42,690
kind<font color="#E5E5E5"> of manual</font><font color="#CCCCCC"> work that ti analysts do</font>

85
00:03:39,599 --> 00:03:46,410
and what we're<font color="#E5E5E5"> gonna try and think</font><font color="#CCCCCC"> about</font>

86
00:03:42,690 --> 00:03:53,069
is what if this<font color="#E5E5E5"> was as automated and as</font>

87
00:03:46,410 --> 00:03:54,418
easy as IOC feeds are today so can we do

88
00:03:53,069 --> 00:03:56,638
<font color="#E5E5E5">this with machine learning</font><font color="#CCCCCC"> that was the</font>

89
00:03:54,419 --> 00:03:58,709
question<font color="#E5E5E5"> I</font><font color="#CCCCCC"> was trying</font><font color="#E5E5E5"> to answer if we</font>

90
00:03:56,639 --> 00:04:01,410
could our input would be<font color="#E5E5E5"> you know all of</font>

91
00:03:58,709 --> 00:04:03,840
this<font color="#E5E5E5"> written material blogs white papers</font>

92
00:04:01,410 --> 00:04:06,269
<font color="#E5E5E5">maybe past</font><font color="#CCCCCC"> incident response reports</font>

93
00:04:03,840 --> 00:04:08,129
from your org<font color="#CCCCCC"> and then there'd be this</font>

94
00:04:06,269 --> 00:04:10,079
black box of machine learning<font color="#CCCCCC"> which can</font>

95
00:04:08,129 --> 00:04:11,819
extract you know the actor names the

96
00:04:10,079 --> 00:04:14,069
tool names the techniques<font color="#E5E5E5"> that they're</font>

97
00:04:11,819 --> 00:04:16,649
using<font color="#E5E5E5"> and extract the relationships</font>

98
00:04:14,069 --> 00:04:20,548
between them and then<font color="#E5E5E5"> the output would</font>

99
00:04:16,649 --> 00:04:22,260
<font color="#CCCCCC">be the type of graphs that we've seen so</font>

100
00:04:20,548 --> 00:04:24,570
we're<font color="#E5E5E5"> going to focus on building this</font>

101
00:04:22,260 --> 00:04:27,060
black box for<font color="#E5E5E5"> the rest of the talk this</font>

102
00:04:24,570 --> 00:04:28,949
is<font color="#E5E5E5"> my agenda</font><font color="#CCCCCC"> I will introduce the</font>

103
00:04:27,060 --> 00:04:31,380
concept<font color="#CCCCCC"> of named entity extraction</font><font color="#E5E5E5"> I</font>

104
00:04:28,949 --> 00:04:33,480
will talk about<font color="#E5E5E5"> how you can</font><font color="#CCCCCC"> use a</font>

105
00:04:31,380 --> 00:04:35,520
<font color="#E5E5E5">machine learning</font><font color="#CCCCCC"> /</font><font color="#E5E5E5"> deep learning way</font>

106
00:04:33,480 --> 00:04:38,490
to build<font color="#E5E5E5"> your own cyber energy extractor</font>

107
00:04:35,520 --> 00:04:40,380
using<font color="#CCCCCC"> open-source</font><font color="#E5E5E5"> data</font><font color="#CCCCCC"> the training data</font>

108
00:04:38,490 --> 00:04:42,930
what kind<font color="#E5E5E5"> of feature extraction we used</font>

109
00:04:40,380 --> 00:04:45,780
the models that<font color="#E5E5E5"> work for us</font><font color="#CCCCCC"> and then</font><font color="#E5E5E5"> you</font>

110
00:04:42,930 --> 00:04:47,400
know successes and failures<font color="#CCCCCC"> I will give</font>

111
00:04:45,780 --> 00:04:50,669
you a short demo of<font color="#CCCCCC"> the tool</font><font color="#E5E5E5"> that we've</font>

112
00:04:47,400 --> 00:04:53,549
built<font color="#E5E5E5"> and I will wrap it up by how this</font>

113
00:04:50,670 --> 00:04:56,100
can<font color="#E5E5E5"> help drive impact all right what's</font>

114
00:04:53,550 --> 00:04:57,570
named at any extraction this is an

115
00:04:56,100 --> 00:05:00,420
article<font color="#CCCCCC"> that appeared in The</font><font color="#E5E5E5"> Times of</font>

116
00:04:57,570 --> 00:05:02,849
Israel<font color="#CCCCCC"> a</font><font color="#E5E5E5"> while back</font><font color="#CCCCCC"> if I pop the text</font>

117
00:05:00,420 --> 00:05:05,190
<font color="#E5E5E5">from this</font><font color="#CCCCCC"> article</font><font color="#E5E5E5"> into any off-the-shelf</font>

118
00:05:02,850 --> 00:05:07,980
text analytics toolkit like the ones

119
00:05:05,190 --> 00:05:10,110
provided by Azure or Google<font color="#E5E5E5"> I can very</font>

120
00:05:07,980 --> 00:05:12,630
easily<font color="#CCCCCC"> extract the entities that this</font>

121
00:05:10,110 --> 00:05:14,600
text is talking about<font color="#E5E5E5"> for</font><font color="#CCCCCC"> example this</font>

122
00:05:12,630 --> 00:05:17,610
is what the output<font color="#CCCCCC"> would look like</font>

123
00:05:14,600 --> 00:05:18,780
Israel and<font color="#CCCCCC"> America and our geopolitical</font>

124
00:05:17,610 --> 00:05:21,150
entities

125
00:05:18,780 --> 00:05:23,489
static and<font color="#CCCCCC"> Bunnell tiwari are people and</font>

126
00:05:21,150 --> 00:05:25,770
even<font color="#E5E5E5"> though static doesn't sound like</font>

127
00:05:23,490 --> 00:05:27,360
the name<font color="#CCCCCC"> of a person the algorithm</font><font color="#E5E5E5"> is</font>

128
00:05:25,770 --> 00:05:29,700
intelligent enough<font color="#E5E5E5"> that based on the</font>

129
00:05:27,360 --> 00:05:31,650
context<font color="#CCCCCC"> unit which it appears</font><font color="#E5E5E5"> it can</font>

130
00:05:29,700 --> 00:05:34,530
extract<font color="#CCCCCC"> that and identify that correctly</font>

131
00:05:31,650 --> 00:05:37,830
<font color="#E5E5E5">as the name of</font><font color="#CCCCCC"> a person but</font><font color="#E5E5E5"> when I apply</font>

132
00:05:34,530 --> 00:05:40,169
<font color="#CCCCCC">these</font><font color="#E5E5E5"> toolkits on an apt report they</font>

133
00:05:37,830 --> 00:05:43,380
<font color="#E5E5E5">completely fail so for example if I have</font>

134
00:05:40,170 --> 00:05:44,610
this type of<font color="#CCCCCC"> text and if I pop this into</font>

135
00:05:43,380 --> 00:05:46,909
like<font color="#CCCCCC"> an off-the-shelf</font><font color="#E5E5E5"> text analytics</font>

136
00:05:44,610 --> 00:05:49,770
toolkit it does not<font color="#E5E5E5"> extract any entities</font>

137
00:05:46,910 --> 00:05:51,360
the output<font color="#CCCCCC"> that</font><font color="#E5E5E5"> I would expect</font><font color="#CCCCCC"> looks</font>

138
00:05:49,770 --> 00:05:53,070
something<font color="#CCCCCC"> like</font><font color="#E5E5E5"> this like dropping</font>

139
00:05:51,360 --> 00:05:55,680
elephant<font color="#CCCCCC"> china strats and</font><font color="#E5E5E5"> patchwork</font>

140
00:05:53,070 --> 00:05:57,480
<font color="#E5E5E5">there the actors and</font><font color="#CCCCCC"> spear-phishing and</font>

141
00:05:55,680 --> 00:05:59,340
watering<font color="#E5E5E5"> hole are the techniques</font><font color="#CCCCCC"> and I</font>

142
00:05:57,480 --> 00:06:01,560
want them to<font color="#E5E5E5"> extract this and and they</font>

143
00:05:59,340 --> 00:06:05,039
kind<font color="#E5E5E5"> of don't do that right</font><font color="#CCCCCC"> now so</font><font color="#E5E5E5"> we</font>

144
00:06:01,560 --> 00:06:07,560
decided<font color="#E5E5E5"> to build our own</font><font color="#CCCCCC"> let's talk</font>

145
00:06:05,040 --> 00:06:10,670
about how we can<font color="#E5E5E5"> get the training data</font>

146
00:06:07,560 --> 00:06:13,560
for<font color="#E5E5E5"> building the cyber energy extractor</font>

147
00:06:10,670 --> 00:06:15,450
for<font color="#E5E5E5"> our training</font><font color="#CCCCCC"> data we used apt</font><font color="#E5E5E5"> notes</font>

148
00:06:13,560 --> 00:06:17,430
which is<font color="#CCCCCC"> a publicly available github</font>

149
00:06:15,450 --> 00:06:20,729
repository that's maintained by security

150
00:06:17,430 --> 00:06:22,200
<font color="#CCCCCC">researchers it has links to white papers</font>

151
00:06:20,730 --> 00:06:25,320
going back<font color="#CCCCCC"> way in the past</font><font color="#E5E5E5"> and it also</font>

152
00:06:22,200 --> 00:06:27,930
has tools<font color="#CCCCCC"> to download them etc</font><font color="#E5E5E5"> so we use</font>

153
00:06:25,320 --> 00:06:29,820
that<font color="#E5E5E5"> and</font><font color="#CCCCCC"> we used publicly available ti</font>

154
00:06:27,930 --> 00:06:33,450
blogs<font color="#E5E5E5"> that were collected by our team</font>

155
00:06:29,820 --> 00:06:37,980
since June 2018<font color="#E5E5E5"> in all</font><font color="#CCCCCC"> regard</font><font color="#E5E5E5"> about</font>

156
00:06:33,450 --> 00:06:39,900
<font color="#CCCCCC">2,700 documents</font><font color="#E5E5E5"> and the top graph you</font>

157
00:06:37,980 --> 00:06:41,850
<font color="#E5E5E5">can</font><font color="#CCCCCC"> see the</font><font color="#E5E5E5"> distribution of tokens</font>

158
00:06:39,900 --> 00:06:44,880
within our documents you<font color="#E5E5E5"> can see that on</font>

159
00:06:41,850 --> 00:06:46,590
average<font color="#CCCCCC"> each document</font><font color="#E5E5E5"> had about</font><font color="#CCCCCC"> 2000</font>

160
00:06:44,880 --> 00:06:48,600
and on the tail end there are<font color="#CCCCCC"> some</font>

161
00:06:46,590 --> 00:06:53,190
<font color="#CCCCCC">documents</font><font color="#E5E5E5"> that had upwards of</font><font color="#CCCCCC"> seventy</font>

162
00:06:48,600 --> 00:06:55,560
<font color="#CCCCCC">eighty thousand tokens on</font><font color="#E5E5E5"> average most</font>

163
00:06:53,190 --> 00:06:56,850
of these<font color="#CCCCCC"> tokens</font><font color="#E5E5E5"> belong to the outside</font>

164
00:06:55,560 --> 00:06:59,430
class that is they were neither a

165
00:06:56,850 --> 00:07:01,680
malware name nor a technique technique

166
00:06:59,430 --> 00:07:04,620
phrase or anything like<font color="#E5E5E5"> that the lower</font>

167
00:07:01,680 --> 00:07:06,960
graph shows<font color="#CCCCCC"> us the distribution</font><font color="#E5E5E5"> of the</font>

168
00:07:04,620 --> 00:07:08,370
terms that<font color="#E5E5E5"> we care about</font><font color="#CCCCCC"> within these</font>

169
00:07:06,960 --> 00:07:11,340
documents<font color="#E5E5E5"> so you</font><font color="#CCCCCC"> can see that it's very</font>

170
00:07:08,370 --> 00:07:14,670
<font color="#CCCCCC">low for malware tokens actor tokens</font><font color="#E5E5E5"> and</font>

171
00:07:11,340 --> 00:07:17,340
technique tokens so this tells us two

172
00:07:14,670 --> 00:07:21,090
things<font color="#CCCCCC"> one</font><font color="#E5E5E5"> that</font><font color="#CCCCCC"> our data set is very</font>

173
00:07:17,340 --> 00:07:23,280
<font color="#E5E5E5">small we have only</font><font color="#CCCCCC"> 2,700 documents and</font>

174
00:07:21,090 --> 00:07:24,810
second<font color="#E5E5E5"> that we have a massive</font><font color="#CCCCCC"> class</font>

175
00:07:23,280 --> 00:07:26,609
<font color="#CCCCCC">imbalance so if we were to train a</font>

176
00:07:24,810 --> 00:07:29,640
classifier we'd have to take<font color="#E5E5E5"> that into</font>

177
00:07:26,610 --> 00:07:33,210
account<font color="#CCCCCC"> also we'd have to guard against</font>

178
00:07:29,640 --> 00:07:36,060
overfitting<font color="#E5E5E5"> and from past experience we</font>

179
00:07:33,210 --> 00:07:38,099
know that deep learning algorithms<font color="#E5E5E5"> don't</font>

180
00:07:36,060 --> 00:07:41,220
tend to<font color="#E5E5E5"> work as well with such a small</font>

181
00:07:38,100 --> 00:07:43,140
data set<font color="#CCCCCC"> so we'll try some traditional</font>

182
00:07:41,220 --> 00:07:44,580
machine learning methods in addition to

183
00:07:43,140 --> 00:07:48,960
the more<font color="#E5E5E5"> sophisticated deep learning</font>

184
00:07:44,580 --> 00:07:50,760
<font color="#CCCCCC">ones to label our training data</font><font color="#E5E5E5"> we</font>

185
00:07:48,960 --> 00:07:53,190
relied on the<font color="#CCCCCC"> carretera set</font><font color="#E5E5E5"> which is</font>

186
00:07:50,760 --> 00:07:56,340
provided by Myra Myra is an American

187
00:07:53,190 --> 00:07:58,440
nonprofit<font color="#E5E5E5"> it kind of just contains a</font>

188
00:07:56,340 --> 00:08:00,000
JSON structure with all<font color="#CCCCCC"> the with the</font>

189
00:07:58,440 --> 00:08:02,010
list of all<font color="#CCCCCC"> the actor names</font><font color="#E5E5E5"> their</font>

190
00:08:00,000 --> 00:08:04,310
aliases<font color="#CCCCCC"> and</font><font color="#E5E5E5"> the techniques they use and</font>

191
00:08:02,010 --> 00:08:07,860
I<font color="#E5E5E5"> just put in a screenshot of</font><font color="#CCCCCC"> that there</font>

192
00:08:04,310 --> 00:08:10,170
<font color="#CCCCCC">we used the</font><font color="#E5E5E5"> data as a list of tags and</font>

193
00:08:07,860 --> 00:08:13,560
then we annotated<font color="#E5E5E5"> our corpus using</font>

194
00:08:10,170 --> 00:08:16,050
longest<font color="#CCCCCC"> extend pattern matching the</font>

195
00:08:13,560 --> 00:08:18,480
thing<font color="#E5E5E5"> to note about</font><font color="#CCCCCC"> mitre is that it's</font>

196
00:08:16,050 --> 00:08:21,120
kind of out of<font color="#E5E5E5"> date there it's not under</font>

197
00:08:18,480 --> 00:08:23,160
active maintenance<font color="#E5E5E5"> so there are a</font><font color="#CCCCCC"> lot of</font>

198
00:08:21,120 --> 00:08:25,410
actors that have come<font color="#CCCCCC"> up in recent times</font>

199
00:08:23,160 --> 00:08:26,640
<font color="#E5E5E5">that are present in our dataset but</font>

200
00:08:25,410 --> 00:08:28,740
which are<font color="#CCCCCC"> not present in</font><font color="#E5E5E5"> the Myra</font>

201
00:08:26,640 --> 00:08:30,510
<font color="#CCCCCC">dataset so they kind of got tagged</font>

202
00:08:28,740 --> 00:08:33,090
<font color="#E5E5E5">incorrectly which makes our training</font>

203
00:08:30,510 --> 00:08:34,590
data<font color="#E5E5E5"> very noisy but</font><font color="#CCCCCC"> since</font><font color="#E5E5E5"> that</font><font color="#CCCCCC"> is the</font>

204
00:08:33,090 --> 00:08:36,090
<font color="#E5E5E5">best we can do short of manual</font>

205
00:08:34,590 --> 00:08:38,580
annotation<font color="#E5E5E5"> that's what we went with</font>

206
00:08:36,090 --> 00:08:43,800
and<font color="#E5E5E5"> we'll keep this in mind when we do</font>

207
00:08:38,580 --> 00:08:47,010
<font color="#CCCCCC">our evaluations for models this is how</font>

208
00:08:43,799 --> 00:08:49,709
we did<font color="#E5E5E5"> the tagging we use the</font><font color="#CCCCCC"> IOB style</font>

209
00:08:47,010 --> 00:08:51,330
<font color="#E5E5E5">which is inside outside beginning it's</font>

210
00:08:49,710 --> 00:08:53,850
very<font color="#E5E5E5"> common in natural language</font>

211
00:08:51,330 --> 00:08:54,810
processing based tasks<font color="#E5E5E5"> so here you can</font>

212
00:08:53,850 --> 00:08:57,270
see that<font color="#CCCCCC"> Bennell tabari</font>

213
00:08:54,810 --> 00:08:58,060
is a whole phrase that indicates one

214
00:08:57,270 --> 00:09:00,520
person

215
00:08:58,060 --> 00:09:04,660
so the first token in that phrase<font color="#E5E5E5"> will</font>

216
00:09:00,520 --> 00:09:06,430
be tagged<font color="#E5E5E5"> with a</font><font color="#CCCCCC"> B</font><font color="#E5E5E5"> - token</font><font color="#CCCCCC"> tag and all</font>

217
00:09:04,660 --> 00:09:08,469
the subsequent tokens in that phrase

218
00:09:06,430 --> 00:09:11,079
will be tagged<font color="#E5E5E5"> with I - person I -</font>

219
00:09:08,470 --> 00:09:13,960
<font color="#CCCCCC">person and so on</font><font color="#E5E5E5"> I am meaning inside and</font>

220
00:09:11,080 --> 00:09:17,110
B indicating beginning<font color="#E5E5E5"> so if we have</font>

221
00:09:13,960 --> 00:09:18,040
like a similar text blob<font color="#CCCCCC"> from our domain</font>

222
00:09:17,110 --> 00:09:21,040
where you know we're<font color="#E5E5E5"> talking about</font>

223
00:09:18,040 --> 00:09:23,800
numbered<font color="#CCCCCC"> panda this</font><font color="#E5E5E5"> is just I</font><font color="#CCCCCC"> think</font><font color="#E5E5E5"> this</font>

224
00:09:21,040 --> 00:09:26,500
is<font color="#E5E5E5"> from Wikipedia</font><font color="#CCCCCC"> this</font><font color="#E5E5E5"> is how that</font><font color="#CCCCCC"> would</font>

225
00:09:23,800 --> 00:09:29,020
get tagged<font color="#E5E5E5"> where so numbered</font><font color="#CCCCCC"> panda is a</font>

226
00:09:26,500 --> 00:09:31,030
phrase that<font color="#E5E5E5"> indicates a bad actor so the</font>

227
00:09:29,020 --> 00:09:34,090
first token in that phrase will be B -

228
00:09:31,030 --> 00:09:38,020
bad actor and the Panda<font color="#E5E5E5"> will be</font><font color="#CCCCCC"> I - bad</font>

229
00:09:34,090 --> 00:09:40,450
actor<font color="#E5E5E5"> and and so on</font><font color="#CCCCCC"> alright let's</font><font color="#E5E5E5"> talk</font>

230
00:09:38,020 --> 00:09:42,670
<font color="#CCCCCC">about feature extraction for our feature</font>

231
00:09:40,450 --> 00:09:44,560
extraction we broadly use two types of

232
00:09:42,670 --> 00:09:47,410
features<font color="#E5E5E5"> we used the traditional</font>

233
00:09:44,560 --> 00:09:50,439
<font color="#E5E5E5">features which are common for natural</font>

234
00:09:47,410 --> 00:09:52,810
language tasks such as word type<font color="#E5E5E5"> part of</font>

235
00:09:50,440 --> 00:09:56,380
speech lemma<font color="#E5E5E5"> etc and then</font><font color="#CCCCCC"> we used word</font>

236
00:09:52,810 --> 00:09:58,810
embeddings<font color="#E5E5E5"> in very simple terms word</font>

237
00:09:56,380 --> 00:10:01,990
embeddings<font color="#E5E5E5"> are vector representations of</font>

238
00:09:58,810 --> 00:10:04,109
<font color="#E5E5E5">words such that the semantic or the</font>

239
00:10:01,990 --> 00:10:06,550
contextual<font color="#CCCCCC"> meaning of the word is</font>

240
00:10:04,110 --> 00:10:10,090
captured<font color="#CCCCCC"> by the numeric vector that is</font>

241
00:10:06,550 --> 00:10:12,760
<font color="#E5E5E5">extracted</font><font color="#CCCCCC"> so that would mean something</font>

242
00:10:10,090 --> 00:10:14,410
<font color="#E5E5E5">like for example if</font><font color="#CCCCCC"> two words have very</font>

243
00:10:12,760 --> 00:10:16,300
similar<font color="#E5E5E5"> meaning or if they appear in the</font>

244
00:10:14,410 --> 00:10:18,400
same context a lot<font color="#CCCCCC"> then</font><font color="#E5E5E5"> we would expect</font>

245
00:10:16,300 --> 00:10:20,800
<font color="#CCCCCC">that the cosine</font><font color="#E5E5E5"> similarity of their word</font>

246
00:10:18,400 --> 00:10:22,959
vectors would<font color="#E5E5E5"> be very high and we</font>

247
00:10:20,800 --> 00:10:26,859
extracted our word embeddings using word

248
00:10:22,960 --> 00:10:28,480
<font color="#CCCCCC">two back with hundred dimensions this is</font>

249
00:10:26,860 --> 00:10:30,280
just a screenshot<font color="#CCCCCC"> of generic word</font>

250
00:10:28,480 --> 00:10:31,810
embeddings<font color="#E5E5E5"> I kind of wanted to give you</font>

251
00:10:30,280 --> 00:10:33,850
the<font color="#E5E5E5"> idea of what they mean and here we</font>

252
00:10:31,810 --> 00:10:35,770
can see<font color="#E5E5E5"> that words that appear in a</font>

253
00:10:33,850 --> 00:10:38,650
similar context get clustered together

254
00:10:35,770 --> 00:10:40,569
<font color="#E5E5E5">and what we want is that since our days</font>

255
00:10:38,650 --> 00:10:42,850
since our word<font color="#E5E5E5"> embeddings were trained</font>

256
00:10:40,570 --> 00:10:45,070
on<font color="#E5E5E5"> a cyber specific cyber domain</font>

257
00:10:42,850 --> 00:10:46,990
specific data<font color="#E5E5E5"> we would want the words</font>

258
00:10:45,070 --> 00:10:48,580
that<font color="#CCCCCC"> clustered together would be that</font>

259
00:10:46,990 --> 00:10:51,160
they cluster based on<font color="#CCCCCC"> that meaning in</font>

260
00:10:48,580 --> 00:10:53,560
which<font color="#E5E5E5"> they're used in that context</font><font color="#CCCCCC"> so</font>

261
00:10:51,160 --> 00:10:55,719
this is a visualization<font color="#E5E5E5"> of our word</font>

262
00:10:53,560 --> 00:10:57,939
embeddings visualized in tensor board

263
00:10:55,720 --> 00:11:00,160
and since our domains

264
00:10:57,940 --> 00:11:02,350
<font color="#CCCCCC">since</font><font color="#E5E5E5"> our since these are trained on</font>

265
00:11:00,160 --> 00:11:04,810
cyber data we see that that kind<font color="#E5E5E5"> of</font>

266
00:11:02,350 --> 00:11:06,850
<font color="#E5E5E5">meaning is encapsulated in the points</font>

267
00:11:04,810 --> 00:11:09,939
that cluster together here we can see

268
00:11:06,850 --> 00:11:12,310
<font color="#E5E5E5">that the points closest to</font><font color="#CCCCCC"> a PT</font><font color="#E5E5E5"> 28</font>

269
00:11:09,940 --> 00:11:14,980
two of the<font color="#CCCCCC"> points closest are just</font>

270
00:11:12,310 --> 00:11:17,380
aliases of<font color="#CCCCCC"> it</font><font color="#E5E5E5"> sofa C and</font><font color="#CCCCCC"> T G</font><font color="#E5E5E5"> for</font><font color="#CCCCCC"> one two</font>

271
00:11:14,980 --> 00:11:20,230
<font color="#CCCCCC">seven and</font><font color="#E5E5E5"> then</font><font color="#CCCCCC"> two</font><font color="#E5E5E5"> two others are</font>

272
00:11:17,380 --> 00:11:23,410
related to it<font color="#E5E5E5"> by attribution here's</font>

273
00:11:20,230 --> 00:11:25,770
<font color="#E5E5E5">another example when we</font><font color="#CCCCCC"> look at the</font>

274
00:11:23,410 --> 00:11:28,750
words closest to dog call we see that

275
00:11:25,770 --> 00:11:31,360
<font color="#CCCCCC">the closest words are Purim</font><font color="#E5E5E5"> shutter</font>

276
00:11:28,750 --> 00:11:34,720
speed and are you happy<font color="#CCCCCC"> and all of these</font>

277
00:11:31,360 --> 00:11:40,540
names are the names of malware<font color="#E5E5E5"> that are</font>

278
00:11:34,720 --> 00:11:42,550
used by<font color="#E5E5E5"> one</font><font color="#CCCCCC"> particular apt apt</font><font color="#E5E5E5"> 37 when</font>

279
00:11:40,540 --> 00:11:44,829
we visualized<font color="#E5E5E5"> all the</font><font color="#CCCCCC"> vectors together</font>

280
00:11:42,550 --> 00:11:47,229
<font color="#E5E5E5">we can see that the green and blue</font>

281
00:11:44,830 --> 00:11:49,540
tokens which indicate actor names and

282
00:11:47,230 --> 00:11:52,240
malware names are clustered on<font color="#E5E5E5"> one side</font>

283
00:11:49,540 --> 00:11:56,010
<font color="#E5E5E5">whereas the tokens occurring which occur</font>

284
00:11:52,240 --> 00:11:56,010
in techniques are clustered separately

285
00:11:56,340 --> 00:12:02,710
<font color="#CCCCCC">all right let's talk about</font><font color="#E5E5E5"> the</font>

286
00:11:58,420 --> 00:12:05,500
<font color="#E5E5E5">architecture</font><font color="#CCCCCC"> we had a very simple</font>

287
00:12:02,710 --> 00:12:08,140
architecture we used the blogs and<font color="#E5E5E5"> the</font>

288
00:12:05,500 --> 00:12:10,840
white papers that<font color="#CCCCCC"> I talked about</font><font color="#E5E5E5"> and we</font>

289
00:12:08,140 --> 00:12:13,150
used<font color="#CCCCCC"> HTML and PDF parsers to extract the</font>

290
00:12:10,840 --> 00:12:15,670
<font color="#CCCCCC">text then we</font><font color="#E5E5E5"> put them through some very</font>

291
00:12:13,150 --> 00:12:18,100
<font color="#E5E5E5">simple text pre-processing just removal</font>

292
00:12:15,670 --> 00:12:19,810
of unprintable characters and then we

293
00:12:18,100 --> 00:12:23,080
extracted<font color="#E5E5E5"> the word</font><font color="#CCCCCC"> m</font><font color="#E5E5E5"> bearings as I</font>

294
00:12:19,810 --> 00:12:27,280
described<font color="#E5E5E5"> we split our data corpus into</font>

295
00:12:23,080 --> 00:12:29,140
two<font color="#CCCCCC"> 8024 the</font><font color="#E5E5E5"> training and test</font><font color="#CCCCCC"> sled we</font>

296
00:12:27,280 --> 00:12:31,600
extracted the<font color="#E5E5E5"> traditional features that</font>

297
00:12:29,140 --> 00:12:33,160
<font color="#CCCCCC">I talked about</font><font color="#E5E5E5"> earlier</font><font color="#CCCCCC"> combine them with</font>

298
00:12:31,600 --> 00:12:35,110
<font color="#E5E5E5">the word embeddings</font><font color="#CCCCCC"> and this is the</font>

299
00:12:33,160 --> 00:12:38,250
<font color="#E5E5E5">training data that we use to train our</font>

300
00:12:35,110 --> 00:12:38,250
model and then test it

301
00:12:38,530 --> 00:12:43,930
the first model<font color="#CCCCCC"> that we tried out is</font>

302
00:12:40,870 --> 00:12:45,640
conditional random fields or CRFs<font color="#CCCCCC"> this</font>

303
00:12:43,930 --> 00:12:49,359
is a statistical modeling method it's

304
00:12:45,640 --> 00:12:52,170
not deep learning<font color="#CCCCCC"> it's it's pretty close</font>

305
00:12:49,360 --> 00:12:56,350
<font color="#E5E5E5">to</font><font color="#CCCCCC"> hidden Markov models you can kind of</font>

306
00:12:52,170 --> 00:12:57,610
simple way<font color="#CCCCCC"> think of</font><font color="#E5E5E5"> it as logistic</font>

307
00:12:56,350 --> 00:13:00,160
regression for sequence labeling

308
00:12:57,610 --> 00:13:01,740
problems<font color="#E5E5E5"> it's in fact commonly used in</font>

309
00:13:00,160 --> 00:13:04,569
<font color="#CCCCCC">natural language processing tasks</font>

310
00:13:01,740 --> 00:13:08,170
biological sequencing<font color="#E5E5E5"> and even computer</font>

311
00:13:04,570 --> 00:13:10,390
vision we<font color="#E5E5E5"> can say that it has short term</font>

312
00:13:08,170 --> 00:13:13,060
<font color="#E5E5E5">memory and let me explain a little bit</font>

313
00:13:10,390 --> 00:13:15,250
about<font color="#CCCCCC"> what that</font><font color="#E5E5E5"> means we have the</font><font color="#CCCCCC"> matrix</font>

314
00:13:13,060 --> 00:13:16,780
you see on the screen<font color="#CCCCCC"> is a transition</font>

315
00:13:15,250 --> 00:13:18,760
weights matrix and it shows the

316
00:13:16,780 --> 00:13:21,370
transition weights<font color="#E5E5E5"> between the various</font>

317
00:13:18,760 --> 00:13:21,880
<font color="#CCCCCC">classes</font><font color="#E5E5E5"> so you can see that the the</font>

318
00:13:21,370 --> 00:13:25,090
likely

319
00:13:21,880 --> 00:13:28,630
of transition from an<font color="#CCCCCC"> O</font><font color="#E5E5E5"> class to a</font><font color="#CCCCCC"> B bad</font>

320
00:13:25,090 --> 00:13:30,910
actor class is positive<font color="#E5E5E5"> but when you see</font>

321
00:13:28,630 --> 00:13:32,470
the likelihood of<font color="#E5E5E5"> transact the</font>

322
00:13:30,910 --> 00:13:35,230
transition<font color="#E5E5E5"> from an oak glass to an iPad</font>

323
00:13:32,470 --> 00:13:36,850
actor class directly<font color="#CCCCCC"> you see that it's a</font>

324
00:13:35,230 --> 00:13:38,830
<font color="#E5E5E5">very low number</font><font color="#CCCCCC"> and that makes sense</font>

325
00:13:36,850 --> 00:13:41,230
because<font color="#E5E5E5"> in a sentence</font><font color="#CCCCCC"> you might have an</font>

326
00:13:38,830 --> 00:13:43,060
<font color="#E5E5E5">O term</font><font color="#CCCCCC"> but you'd have a betta</font><font color="#E5E5E5"> be bad</font>

327
00:13:41,230 --> 00:13:45,610
actor term and then<font color="#E5E5E5"> you'd have an item</font>

328
00:13:43,060 --> 00:13:47,859
<font color="#E5E5E5">that is why the the likelihood</font><font color="#CCCCCC"> of going</font>

329
00:13:45,610 --> 00:13:50,050
<font color="#E5E5E5">straight</font><font color="#CCCCCC"> from an ode to an inside phrase</font>

330
00:13:47,860 --> 00:13:52,290
is very very low and<font color="#E5E5E5"> that makes sense</font>

331
00:13:50,050 --> 00:13:54,280
<font color="#E5E5E5">and this is what we mean by when we say</font>

332
00:13:52,290 --> 00:13:56,079
CRFs have<font color="#CCCCCC"> short term</font><font color="#E5E5E5"> memory</font>

333
00:13:54,280 --> 00:13:58,209
that is the probability<font color="#CCCCCC"> of a particular</font>

334
00:13:56,080 --> 00:13:59,980
<font color="#E5E5E5">class occurring is dependent on the</font>

335
00:13:58,210 --> 00:14:03,790
proper on the classes that are occurring

336
00:13:59,980 --> 00:14:06,340
around<font color="#E5E5E5"> it</font><font color="#CCCCCC"> and</font><font color="#E5E5E5"> in our experiment we tried</font>

337
00:14:03,790 --> 00:14:08,770
two versions of the CRF one<font color="#CCCCCC"> within</font>

338
00:14:06,340 --> 00:14:11,380
<font color="#E5E5E5">bearings and one without embeddings just</font>

339
00:14:08,770 --> 00:14:12,790
with the traditional features<font color="#CCCCCC"> and that</font>

340
00:14:11,380 --> 00:14:15,460
was<font color="#E5E5E5"> because</font><font color="#CCCCCC"> we kind</font><font color="#E5E5E5"> of wanted to</font>

341
00:14:12,790 --> 00:14:16,689
<font color="#E5E5E5">illustrate you know we wanted to make</font>

342
00:14:15,460 --> 00:14:21,100
sure<font color="#E5E5E5"> that the word and bearings were</font>

343
00:14:16,690 --> 00:14:24,700
adding value to the model<font color="#E5E5E5"> we also tried</font>

344
00:14:21,100 --> 00:14:26,890
a model based on<font color="#E5E5E5"> LS TM and LS TM is a</font>

345
00:14:24,700 --> 00:14:29,710
special type of recurrent neural network

346
00:14:26,890 --> 00:14:31,930
in our architecture<font color="#E5E5E5"> we had two stacked</font>

347
00:14:29,710 --> 00:14:33,990
bi-directional lsdm layers with<font color="#E5E5E5"> dropout</font>

348
00:14:31,930 --> 00:14:36,489
<font color="#E5E5E5">for</font><font color="#CCCCCC"> our loss function we used</font>

349
00:14:33,990 --> 00:14:38,610
categorical cross<font color="#CCCCCC"> entropy and we use</font>

350
00:14:36,490 --> 00:14:40,660
softmax activation for the final<font color="#E5E5E5"> layer</font>

351
00:14:38,610 --> 00:14:43,570
<font color="#CCCCCC">the problem</font><font color="#E5E5E5"> that we're trying to</font><font color="#CCCCCC"> solve</font>

352
00:14:40,660 --> 00:14:45,430
is called custom domain specific custom

353
00:14:43,570 --> 00:14:47,710
<font color="#CCCCCC">entity extraction and this type of</font>

354
00:14:45,430 --> 00:14:49,150
<font color="#E5E5E5">architecture is quite typical</font><font color="#CCCCCC"> for</font><font color="#E5E5E5"> that</font>

355
00:14:47,710 --> 00:14:52,720
<font color="#CCCCCC">problem based on the</font><font color="#E5E5E5"> available</font>

356
00:14:49,150 --> 00:14:54,939
literature<font color="#CCCCCC"> the</font><font color="#E5E5E5"> only thing that that</font><font color="#CCCCCC"> we</font>

357
00:14:52,720 --> 00:14:56,950
added sort<font color="#E5E5E5"> of is adding the drop out</font>

358
00:14:54,940 --> 00:14:59,080
layers and that's because you know like

359
00:14:56,950 --> 00:15:00,700
I'd mentioned earlier<font color="#E5E5E5"> since we have a</font>

360
00:14:59,080 --> 00:15:03,100
really<font color="#E5E5E5"> small data set we're at risk of</font>

361
00:15:00,700 --> 00:15:04,810
overfitting<font color="#E5E5E5"> so we added the drop out</font>

362
00:15:03,100 --> 00:15:06,300
layers to improve the generalization of

363
00:15:04,810 --> 00:15:09,599
the model

364
00:15:06,300 --> 00:15:11,859
<font color="#E5E5E5">all right let's come to the assessments</font>

365
00:15:09,600 --> 00:15:14,050
first I wanted<font color="#E5E5E5"> to share with you the</font>

366
00:15:11,860 --> 00:15:16,600
recall counts to give you an idea<font color="#CCCCCC"> of how</font>

367
00:15:14,050 --> 00:15:18,849
many<font color="#E5E5E5"> entities of each type were to be</font>

368
00:15:16,600 --> 00:15:20,950
extracted<font color="#CCCCCC"> in our dataset and</font><font color="#E5E5E5"> you</font><font color="#CCCCCC"> can</font><font color="#E5E5E5"> see</font>

369
00:15:18,850 --> 00:15:22,900
the<font color="#CCCCCC"> after of the bad that there were</font>

370
00:15:20,950 --> 00:15:25,870
very few technique entities and that's a

371
00:15:22,900 --> 00:15:28,750
<font color="#E5E5E5">limitation of our training data said</font><font color="#CCCCCC"> the</font>

372
00:15:25,870 --> 00:15:30,490
yellow bars are the<font color="#CCCCCC"> LS TM</font><font color="#E5E5E5"> the blue ones</font>

373
00:15:28,750 --> 00:15:32,550
are<font color="#E5E5E5"> CRF without embeddings</font>

374
00:15:30,490 --> 00:15:36,930
and the red ones are<font color="#CCCCCC"> the CRF with</font>

375
00:15:32,550 --> 00:15:39,660
<font color="#E5E5E5">weddings we can see that</font><font color="#CCCCCC"> for the actor</font>

376
00:15:36,930 --> 00:15:42,000
class the lsdm does much much<font color="#E5E5E5"> better</font>

377
00:15:39,660 --> 00:15:43,589
<font color="#CCCCCC">than</font><font color="#E5E5E5"> the others but in all the</font><font color="#CCCCCC"> other</font>

378
00:15:42,000 --> 00:15:45,540
classes<font color="#CCCCCC"> they're kind of their</font>

379
00:15:43,589 --> 00:15:47,040
performance is<font color="#E5E5E5"> pretty similar where the</font>

380
00:15:45,540 --> 00:15:52,560
<font color="#E5E5E5">trade offs could involves just you know</font>

381
00:15:47,040 --> 00:15:54,930
<font color="#E5E5E5">efficiency here we see the recall and</font>

382
00:15:52,560 --> 00:15:56,640
<font color="#CCCCCC">precision</font><font color="#E5E5E5"> and we have the positive</font>

383
00:15:54,930 --> 00:15:58,199
precision and positive recall here

384
00:15:56,640 --> 00:16:01,560
because we have class<font color="#CCCCCC"> imbalance so</font>

385
00:15:58,200 --> 00:16:03,870
that's why we can see that<font color="#E5E5E5"> the precision</font>

386
00:16:01,560 --> 00:16:06,869
for<font color="#E5E5E5"> all the</font><font color="#CCCCCC"> algorithms</font><font color="#E5E5E5"> particularly the</font>

387
00:16:03,870 --> 00:16:09,660
CRFs is really really high but in terms

388
00:16:06,870 --> 00:16:14,100
of recall we see that the<font color="#E5E5E5"> lsdm quite</font>

389
00:16:09,660 --> 00:16:16,620
clearly outperforms the CRFs<font color="#CCCCCC"> this is</font>

390
00:16:14,100 --> 00:16:18,959
great but we<font color="#CCCCCC"> want to test the</font>

391
00:16:16,620 --> 00:16:21,480
<font color="#CCCCCC">performance</font><font color="#E5E5E5"> of our models on unseen</font>

392
00:16:18,959 --> 00:16:24,689
tokens<font color="#E5E5E5"> what we want to know is you know</font>

393
00:16:21,480 --> 00:16:26,040
<font color="#E5E5E5">like if the algorithm sees a new actor</font>

394
00:16:24,690 --> 00:16:29,160
<font color="#CCCCCC">named that</font><font color="#E5E5E5"> it has not</font><font color="#CCCCCC"> encountered before</font>

395
00:16:26,040 --> 00:16:30,599
<font color="#CCCCCC">will it be able</font><font color="#E5E5E5"> to find that</font><font color="#CCCCCC"> - to</font>

396
00:16:29,160 --> 00:16:32,880
determine<font color="#CCCCCC"> their fitness for that</font>

397
00:16:30,600 --> 00:16:34,860
particular use case<font color="#E5E5E5"> we judge their</font>

398
00:16:32,880 --> 00:16:37,649
performance<font color="#E5E5E5"> on just the unseen tokens</font>

399
00:16:34,860 --> 00:16:40,320
and here we can<font color="#E5E5E5"> see a very</font><font color="#CCCCCC"> very</font>

400
00:16:37,649 --> 00:16:42,240
different<font color="#E5E5E5"> picture we can see</font><font color="#CCCCCC"> that there</font>

401
00:16:40,320 --> 00:16:44,339
is<font color="#E5E5E5"> a huge performance drop in both the</font>

402
00:16:42,240 --> 00:16:46,620
lsdm and the CRF without embeddings

403
00:16:44,339 --> 00:16:50,339
<font color="#E5E5E5">whereas the CRF</font><font color="#CCCCCC"> with embeddings</font>

404
00:16:46,620 --> 00:16:52,920
it has almost precision<font color="#E5E5E5"> and it is the</font>

405
00:16:50,339 --> 00:16:55,529
only<font color="#E5E5E5"> one that has any</font><font color="#CCCCCC"> sort of recall on</font>

406
00:16:52,920 --> 00:16:57,180
the<font color="#E5E5E5"> unseen tokens and that's very</font>

407
00:16:55,529 --> 00:16:59,189
important for<font color="#E5E5E5"> us which is</font><font color="#CCCCCC"> why this</font><font color="#E5E5E5"> will</font>

408
00:16:57,180 --> 00:17:05,879
be the model<font color="#CCCCCC"> that</font><font color="#E5E5E5"> I showed you in our</font>

409
00:16:59,190 --> 00:17:08,819
demo<font color="#E5E5E5"> all right it's demo time</font><font color="#CCCCCC"> so this is</font>

410
00:17:05,880 --> 00:17:12,179
<font color="#E5E5E5">just a toy web application</font><font color="#CCCCCC"> that was</font>

411
00:17:08,819 --> 00:17:15,480
created<font color="#CCCCCC"> I'll be</font><font color="#E5E5E5"> entering like text into</font>

412
00:17:12,179 --> 00:17:17,819
the text box blobs of text<font color="#E5E5E5"> from you know</font>

413
00:17:15,480 --> 00:17:19,829
<font color="#E5E5E5">other white papers</font><font color="#CCCCCC"> and stuff</font><font color="#E5E5E5"> and we'll</font>

414
00:17:17,819 --> 00:17:23,089
see<font color="#E5E5E5"> when I run the model on it the</font>

415
00:17:19,829 --> 00:17:23,089
<font color="#E5E5E5">entities get extracted</font>

416
00:17:28,430 --> 00:17:31,300
<font color="#E5E5E5">all right</font>

417
00:17:34,610 --> 00:17:40,279
so here we can<font color="#E5E5E5"> see that</font><font color="#CCCCCC"> pond storm which</font>

418
00:17:37,100 --> 00:17:42,289
<font color="#CCCCCC">is also I think an alias for a</font><font color="#E5E5E5"> PT 28 the</font>

419
00:17:40,279 --> 00:17:45,500
algorithm could correctly<font color="#CCCCCC"> identify all</font>

420
00:17:42,289 --> 00:17:48,700
instances of<font color="#CCCCCC"> the actor as well as the</font>

421
00:17:45,500 --> 00:17:48,700
techniques<font color="#CCCCCC"> that</font><font color="#E5E5E5"> it's using</font>

422
00:17:53,460 --> 00:18:00,030
now let's try<font color="#E5E5E5"> some other text</font><font color="#CCCCCC"> the text</font>

423
00:17:57,750 --> 00:18:01,860
that I'm going to<font color="#E5E5E5"> put here is the the</font>

424
00:18:00,030 --> 00:18:05,220
various blobs are not related but<font color="#E5E5E5"> I just</font>

425
00:18:01,860 --> 00:18:08,899
wanted<font color="#E5E5E5"> to illustrate the different types</font>

426
00:18:05,220 --> 00:18:08,900
of<font color="#CCCCCC"> entities that our model</font><font color="#E5E5E5"> can find</font>

427
00:18:16,400 --> 00:18:20,960
and here again<font color="#E5E5E5"> we</font><font color="#CCCCCC"> can</font><font color="#E5E5E5"> see</font><font color="#CCCCCC"> that</font><font color="#E5E5E5"> it</font>

428
00:18:19,040 --> 00:18:23,389
correctly finds<font color="#E5E5E5"> the actor which is</font>

429
00:18:20,960 --> 00:18:24,770
called<font color="#CCCCCC"> at mimic</font><font color="#E5E5E5"> and the techniques that</font>

430
00:18:23,390 --> 00:18:26,600
<font color="#E5E5E5">it's using which is</font><font color="#CCCCCC"> spearfishing and</font>

431
00:18:24,770 --> 00:18:28,190
watering<font color="#CCCCCC"> hole etc</font><font color="#E5E5E5"> and the second</font>

432
00:18:26,600 --> 00:18:30,740
paragraph is<font color="#CCCCCC"> about a</font><font color="#E5E5E5"> different piece</font><font color="#CCCCCC"> of</font>

433
00:18:28,190 --> 00:18:33,230
malware<font color="#CCCCCC"> havoc threat and again in that</font>

434
00:18:30,740 --> 00:18:46,040
<font color="#CCCCCC">blob it identifies correctly the malware</font>

435
00:18:33,230 --> 00:18:49,940
families<font color="#E5E5E5"> etc</font><font color="#CCCCCC"> I wanted</font><font color="#E5E5E5"> to give I wanted</font>

436
00:18:46,040 --> 00:18:52,220
<font color="#E5E5E5">to give one</font><font color="#CCCCCC"> more example</font><font color="#E5E5E5"> about</font><font color="#CCCCCC"> how this</font>

437
00:18:49,940 --> 00:18:55,070
model is not just doing pattern matching

438
00:18:52,220 --> 00:18:56,960
or text recognition<font color="#CCCCCC"> it is</font><font color="#E5E5E5"> extracting and</font>

439
00:18:55,070 --> 00:18:59,270
identifying these<font color="#E5E5E5"> entities based on the</font>

440
00:18:56,960 --> 00:19:01,130
context<font color="#E5E5E5"> in which they appear</font><font color="#CCCCCC"> so if I</font>

441
00:18:59,270 --> 00:19:02,750
<font color="#E5E5E5">just type a dummy sentence basically</font>

442
00:19:01,130 --> 00:19:05,000
this is fancy<font color="#CCCCCC"> bear and we know</font><font color="#E5E5E5"> that</font>

443
00:19:02,750 --> 00:19:08,120
fancy bear is the<font color="#E5E5E5"> name of</font><font color="#CCCCCC"> a common is</font>

444
00:19:05,000 --> 00:19:10,760
the name<font color="#E5E5E5"> of an actor</font><font color="#CCCCCC"> and if I</font><font color="#E5E5E5"> run the</font>

445
00:19:08,120 --> 00:19:12,139
model on it it<font color="#E5E5E5"> doesn't say that</font><font color="#CCCCCC"> there is</font>

446
00:19:10,760 --> 00:19:13,910
any actor present and<font color="#CCCCCC"> that is that it as</font>

447
00:19:12,140 --> 00:19:15,440
it should be because this sentence does

448
00:19:13,910 --> 00:19:16,730
not<font color="#E5E5E5"> look like it's talking about an</font>

449
00:19:15,440 --> 00:19:20,210
actor it's probably<font color="#E5E5E5"> talking</font><font color="#CCCCCC"> about a</font>

450
00:19:16,730 --> 00:19:22,490
teddy bear<font color="#E5E5E5"> but then if I put in another</font>

451
00:19:20,210 --> 00:19:24,860
sentence where the context is<font color="#CCCCCC"> more clear</font>

452
00:19:22,490 --> 00:19:28,160
<font color="#CCCCCC">where fancy bear is used in the context</font>

453
00:19:24,860 --> 00:19:29,959
of<font color="#E5E5E5"> an attacker</font><font color="#CCCCCC"> and</font><font color="#E5E5E5"> then we run</font><font color="#CCCCCC"> the model</font>

454
00:19:28,160 --> 00:19:33,250
<font color="#E5E5E5">on it</font><font color="#CCCCCC"> we'll see that the model is</font><font color="#E5E5E5"> able</font>

455
00:19:29,960 --> 00:19:33,250
<font color="#E5E5E5">to identify</font><font color="#CCCCCC"> the actor</font>

456
00:19:36,300 --> 00:19:42,340
yeah so this<font color="#E5E5E5"> is</font><font color="#CCCCCC"> the</font><font color="#E5E5E5"> really key piece</font>

457
00:19:39,940 --> 00:19:44,890
<font color="#CCCCCC">here the</font><font color="#E5E5E5"> algorithm is able to identify</font>

458
00:19:42,340 --> 00:19:46,449
<font color="#CCCCCC">the actor</font><font color="#E5E5E5"> based on the context in</font><font color="#CCCCCC"> which</font>

459
00:19:44,890 --> 00:19:52,630
<font color="#E5E5E5">they appear and it's not just doing</font>

460
00:19:46,450 --> 00:19:55,600
pattern matching cool so this<font color="#CCCCCC"> is just v1</font>

461
00:19:52,630 --> 00:19:56,890
we have a lot<font color="#CCCCCC"> of work to do</font><font color="#E5E5E5"> we want to</font>

462
00:19:55,600 --> 00:19:58,629
try<font color="#CCCCCC"> attention networks which is</font>

463
00:19:56,890 --> 00:20:01,060
<font color="#E5E5E5">apparently the latest and greatest thing</font>

464
00:19:58,630 --> 00:20:02,500
<font color="#E5E5E5">in natural language processing I</font>

465
00:20:01,060 --> 00:20:04,540
mentioned<font color="#E5E5E5"> that our data set is quite</font>

466
00:20:02,500 --> 00:20:07,690
<font color="#E5E5E5">small so</font><font color="#CCCCCC"> we want to explore data</font>

467
00:20:04,540 --> 00:20:08,350
augmentation using generative methods<font color="#CCCCCC"> we</font>

468
00:20:07,690 --> 00:20:10,630
want to do more<font color="#E5E5E5"> sophisticated</font>

469
00:20:08,350 --> 00:20:11,740
relationship extraction<font color="#E5E5E5"> right now we're</font>

470
00:20:10,630 --> 00:20:13,870
doing it with<font color="#CCCCCC"> just very</font><font color="#E5E5E5"> naive</font>

471
00:20:11,740 --> 00:20:18,010
co-occurrence<font color="#CCCCCC"> and also work</font><font color="#E5E5E5"> on</font>

472
00:20:13,870 --> 00:20:20,800
extracting temporal relationships<font color="#E5E5E5"> I want</font>

473
00:20:18,010 --> 00:20:22,960
to close it<font color="#E5E5E5"> by talking about the impact</font>

474
00:20:20,800 --> 00:20:25,710
<font color="#E5E5E5">that this type of</font><font color="#CCCCCC"> automation can</font><font color="#E5E5E5"> have in</font>

475
00:20:22,960 --> 00:20:29,050
the<font color="#CCCCCC"> beginning I showed you this slide</font>

476
00:20:25,710 --> 00:20:29,740
<font color="#E5E5E5">where our imaginary threat</font><font color="#CCCCCC"> analyst kind</font>

477
00:20:29,050 --> 00:20:31,629
of you know<font color="#E5E5E5"> help their organization</font>

478
00:20:29,740 --> 00:20:34,540
<font color="#CCCCCC">decide where to focus</font><font color="#E5E5E5"> some of their</font>

479
00:20:31,630 --> 00:20:37,270
detection<font color="#CCCCCC"> zhh we created a</font><font color="#E5E5E5"> similar graph</font>

480
00:20:34,540 --> 00:20:39,520
<font color="#E5E5E5">from the data set that we we got we</font>

481
00:20:37,270 --> 00:20:41,560
extracted automatically<font color="#E5E5E5"> all</font><font color="#CCCCCC"> the TTP is</font>

482
00:20:39,520 --> 00:20:45,639
used by a commodity malware family

483
00:20:41,560 --> 00:20:47,530
<font color="#CCCCCC">emotive</font><font color="#E5E5E5"> and a spate of other apt actors</font>

484
00:20:45,640 --> 00:20:50,200
there are some tenders and snakes<font color="#E5E5E5"> and</font>

485
00:20:47,530 --> 00:20:52,090
stuff<font color="#E5E5E5"> in there</font><font color="#CCCCCC"> but here clearly</font><font color="#E5E5E5"> you can</font>

486
00:20:50,200 --> 00:20:54,700
see<font color="#CCCCCC"> the overlap between the techniques</font>

487
00:20:52,090 --> 00:20:57,639
that<font color="#CCCCCC"> commodity malware used</font><font color="#E5E5E5"> today and</font>

488
00:20:54,700 --> 00:20:59,530
that<font color="#E5E5E5"> ABT's use we can see that our</font>

489
00:20:57,640 --> 00:21:01,390
<font color="#CCCCCC">scattered powershell process</font><font color="#E5E5E5"> hallowing</font>

490
00:20:59,530 --> 00:21:02,800
scripting<font color="#E5E5E5"> these are all techniques that</font>

491
00:21:01,390 --> 00:21:05,740
<font color="#E5E5E5">we think are complicated but they're</font>

492
00:21:02,800 --> 00:21:07,990
used by commodity malware so this type

493
00:21:05,740 --> 00:21:10,060
<font color="#CCCCCC">of automated</font><font color="#E5E5E5"> insight can be used by can</font>

494
00:21:07,990 --> 00:21:12,820
make the job of<font color="#CCCCCC"> a</font><font color="#E5E5E5"> TI analyst much easier</font>

495
00:21:10,060 --> 00:21:15,010
and can help them<font color="#E5E5E5"> drive their</font>

496
00:21:12,820 --> 00:21:17,530
organization<font color="#E5E5E5"> to help to put detections</font>

497
00:21:15,010 --> 00:21:21,100
and<font color="#CCCCCC"> chokepoints in these places so that</font>

498
00:21:17,530 --> 00:21:23,800
they can not<font color="#CCCCCC"> only detect and suppress</font>

499
00:21:21,100 --> 00:21:28,929
<font color="#CCCCCC">the</font><font color="#E5E5E5"> annoying commodity malware but</font><font color="#CCCCCC"> also</font>

500
00:21:23,800 --> 00:21:31,720
the<font color="#CCCCCC"> high profile</font><font color="#E5E5E5"> apt</font><font color="#CCCCCC"> attacks in</font>

501
00:21:28,930 --> 00:21:32,980
<font color="#E5E5E5">conclusion I hope I've convinced you</font>

502
00:21:31,720 --> 00:21:36,700
that it's time<font color="#CCCCCC"> for threat intelligence</font>

503
00:21:32,980 --> 00:21:39,160
to move beyond IOC feeds<font color="#E5E5E5"> there is a rich</font>

504
00:21:36,700 --> 00:21:41,590
unstructured data set<font color="#CCCCCC"> that can be</font>

505
00:21:39,160 --> 00:21:43,240
extracted<font color="#E5E5E5"> with machine</font><font color="#CCCCCC"> learning and we</font>

506
00:21:41,590 --> 00:21:46,000
can make the graphs<font color="#E5E5E5"> of the</font><font color="#CCCCCC"> timelines</font>

507
00:21:43,240 --> 00:21:46,970
that<font color="#E5E5E5"> we saw with</font><font color="#CCCCCC"> that</font><font color="#E5E5E5"> and we can use</font>

508
00:21:46,000 --> 00:21:48,590
this data<font color="#CCCCCC"> to me</font>

509
00:21:46,970 --> 00:21:51,930
better decisions for the security of our

510
00:21:48,590 --> 00:21:55,149
orgs<font color="#E5E5E5"> that's all I have for</font><font color="#CCCCCC"> you thank</font><font color="#E5E5E5"> you</font>

511
00:21:51,930 --> 00:21:57,659
[Applause]

512
00:21:55,150 --> 00:21:57,659
[Music]

