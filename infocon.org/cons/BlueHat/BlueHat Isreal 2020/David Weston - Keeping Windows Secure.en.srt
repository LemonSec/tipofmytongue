1
00:00:11,250 --> 00:00:15,340
all right

2
00:00:12,760 --> 00:00:17,050
Shalom blue hat so you might think

3
00:00:15,340 --> 00:00:19,029
because I'm up here on stage of the

4
00:00:17,050 --> 00:00:21,790
security conference of my expertise in

5
00:00:19,029 --> 00:00:24,250
security but in reality my true passion

6
00:00:21,790 --> 00:00:26,470
is kebab and I can tell you without a

7
00:00:24,250 --> 00:00:29,140
doubt the best kebab in Israel is in

8
00:00:26,470 --> 00:00:31,869
Haifa you get the Amba you get the bread

9
00:00:29,140 --> 00:00:34,210
it's amazing so when I have the

10
00:00:31,869 --> 00:00:36,160
opportunity to speak here at blue hat

11
00:00:34,210 --> 00:00:37,390
and this is my fourth blue hat I'm one

12
00:00:36,160 --> 00:00:40,239
of the select few

13
00:00:37,390 --> 00:00:41,770
yeah Kiwi the other folks that have have

14
00:00:40,239 --> 00:00:43,540
come here you know one of the things

15
00:00:41,770 --> 00:00:45,430
that keeps me coming back is the energy

16
00:00:43,540 --> 00:00:47,530
and the enthusiasm this really feels

17
00:00:45,430 --> 00:00:50,320
like the Eurovision of security you walk

18
00:00:47,530 --> 00:00:53,020
in here in ten seconds Tsar's asking me

19
00:00:50,320 --> 00:00:55,090
about hyper-v fuzzing I see Luca talking

20
00:00:53,020 --> 00:00:57,130
about jailbreak it really is a great

21
00:00:55,090 --> 00:00:58,720
energy here so when I thought about what

22
00:00:57,130 --> 00:01:01,450
I wanted to talk about it's really

23
00:00:58,720 --> 00:01:03,519
getting back to my research roots so

24
00:01:01,450 --> 00:01:05,019
about 12 years ago I joined Microsoft as

25
00:01:03,520 --> 00:01:06,909
one of the first folks kind of doing

26
00:01:05,019 --> 00:01:09,880
full-time PES testing in Windows and

27
00:01:06,909 --> 00:01:11,439
just recently I rejoined that team and I

28
00:01:09,880 --> 00:01:13,570
was amazed at the progress that's been

29
00:01:11,439 --> 00:01:14,740
made in the last 12 years so I thought I

30
00:01:13,570 --> 00:01:17,649
would kind of share some of that with

31
00:01:14,740 --> 00:01:20,169
you and where we're at today we have

32
00:01:17,650 --> 00:01:22,270
five point seven million source code

33
00:01:20,170 --> 00:01:24,580
files that's not lines of code that's

34
00:01:22,270 --> 00:01:26,140
source code files and if you look at

35
00:01:24,580 --> 00:01:27,940
some people's code you know they got

36
00:01:26,140 --> 00:01:30,100
that 10,000 line function in there

37
00:01:27,940 --> 00:01:32,770
there's quite a few lines of code lots

38
00:01:30,100 --> 00:01:35,408
of opportunity for bugs on top of that

39
00:01:32,770 --> 00:01:37,840
we have 1,100 pull requests into our get

40
00:01:35,409 --> 00:01:41,350
today and that averages out to something

41
00:01:37,840 --> 00:01:44,229
like 19 commits per minute a lot of code

42
00:01:41,350 --> 00:01:47,320
velocity a lot going on there we in

43
00:01:44,229 --> 00:01:49,960
addition have 3600 different developers

44
00:01:47,320 --> 00:01:51,369
committing to Windows not all of them

45
00:01:49,960 --> 00:01:53,559
are great at security I'm going to tell

46
00:01:51,370 --> 00:01:56,110
you that straight out and then of course

47
00:01:53,560 --> 00:01:58,119
there's 440 branches because there's all

48
00:01:56,110 --> 00:02:00,070
sorts of different projects so when

49
00:01:58,119 --> 00:02:01,240
inevitably people ask me like how did

50
00:02:00,070 --> 00:02:03,339
this bug get through

51
00:02:01,240 --> 00:02:05,470
I made this live two point this to them

52
00:02:03,340 --> 00:02:07,900
which is this is a very difficult and

53
00:02:05,470 --> 00:02:11,769
challenging job but I think we're up to

54
00:02:07,900 --> 00:02:14,019
the task on top of having lots of code

55
00:02:11,769 --> 00:02:15,790
windows itself is evolving very quickly

56
00:02:14,019 --> 00:02:17,140
so it started out you know though

57
00:02:15,790 --> 00:02:18,810
probably the most of the ways that you

58
00:02:17,140 --> 00:02:20,739
experienced Windows is on the desktop

59
00:02:18,810 --> 00:02:22,710
probably some of you are still running

60
00:02:20,740 --> 00:02:25,050
Windows 7 you play a couple games you

61
00:02:22,710 --> 00:02:27,060
Ida open whatever it is you do but in

62
00:02:25,050 --> 00:02:29,700
reality windows powers lots of things

63
00:02:27,060 --> 00:02:33,990
today from the conventional desktop PC

64
00:02:29,700 --> 00:02:35,790
to running Xbox to IOT to hololens and

65
00:02:33,990 --> 00:02:37,920
the cloud and just about anything you

66
00:02:35,790 --> 00:02:39,690
can imagine and so just because you have

67
00:02:37,920 --> 00:02:41,549
code that you're able to secure in one

68
00:02:39,690 --> 00:02:43,200
environment we all know once that's

69
00:02:41,550 --> 00:02:46,020
converted into a different use case

70
00:02:43,200 --> 00:02:47,700
things can change very rapidly a great

71
00:02:46,020 --> 00:02:49,470
example of this as I can remember 12

72
00:02:47,700 --> 00:02:51,750
years ago we didn't think anyone would

73
00:02:49,470 --> 00:02:54,120
be crazy enough to put the DirectX on

74
00:02:51,750 --> 00:02:55,770
the attack surface nowadays remoting

75
00:02:54,120 --> 00:02:57,510
graphics is a very common thing and the

76
00:02:55,770 --> 00:02:59,730
threat model changes very very quickly

77
00:02:57,510 --> 00:03:01,980
so it's really important to understand

78
00:02:59,730 --> 00:03:04,709
and take advantage of this and so when

79
00:03:01,980 --> 00:03:06,540
we think about the Microsoft of 15 years

80
00:03:04,710 --> 00:03:08,340
ago we were just getting our feet wet on

81
00:03:06,540 --> 00:03:11,549
what was essentially our our security

82
00:03:08,340 --> 00:03:13,710
process 1.0 or SDL it was very much

83
00:03:11,550 --> 00:03:15,270
locked into this kind of waterfall model

84
00:03:13,710 --> 00:03:17,220
it was like we're gonna spend three

85
00:03:15,270 --> 00:03:19,590
months pecking when it's been five

86
00:03:17,220 --> 00:03:21,300
months doing design review then we're

87
00:03:19,590 --> 00:03:24,180
gonna like ride it all on a Visio

88
00:03:21,300 --> 00:03:27,090
document have an STL the reality is that

89
00:03:24,180 --> 00:03:31,080
worked pretty well when we had three and

90
00:03:27,090 --> 00:03:33,180
five-year development life cycles now

91
00:03:31,080 --> 00:03:35,460
I'm lucky if I get three to five weeks

92
00:03:33,180 --> 00:03:38,190
you know we're actually getting updates

93
00:03:35,460 --> 00:03:40,080
with features we're constantly revising

94
00:03:38,190 --> 00:03:42,359
and distributing the operating system

95
00:03:40,080 --> 00:03:44,490
about twice a year so this type of

96
00:03:42,360 --> 00:03:46,380
process simply isn't going to work going

97
00:03:44,490 --> 00:03:47,850
forward we learned a lot from it but we

98
00:03:46,380 --> 00:03:51,180
want to take the best things that work

99
00:03:47,850 --> 00:03:53,820
well and create a more agile process and

100
00:03:51,180 --> 00:03:56,580
so our evolved strategy is really I

101
00:03:53,820 --> 00:03:58,380
think the best of what we learned from

102
00:03:56,580 --> 00:04:00,300
those days and honestly learned through

103
00:03:58,380 --> 00:04:02,549
a lot of battle scars so really have

104
00:04:00,300 --> 00:04:04,740
three key points and all of it is

105
00:04:02,550 --> 00:04:07,080
grounded actually in intelligence

106
00:04:04,740 --> 00:04:09,480
understanding things because back to the

107
00:04:07,080 --> 00:04:11,670
concept you know Windows is so gigantic

108
00:04:09,480 --> 00:04:13,769
the reality is even if we had an army of

109
00:04:11,670 --> 00:04:16,200
10,000 security engineers we couldn't

110
00:04:13,770 --> 00:04:18,450
review every line of code so instead we

111
00:04:16,200 --> 00:04:20,789
need to be really really intelligent

112
00:04:18,450 --> 00:04:22,680
about where we focus our resources and

113
00:04:20,790 --> 00:04:24,780
what we ask our developers to do so we

114
00:04:22,680 --> 00:04:26,760
do that in a couple ways the first basis

115
00:04:24,780 --> 00:04:28,590
for that is threat intelligence so we

116
00:04:26,760 --> 00:04:30,780
use a lot of what we can detect from

117
00:04:28,590 --> 00:04:33,119
implants in the wild exploitation

118
00:04:30,780 --> 00:04:35,489
approaches that we see from attackers

119
00:04:33,120 --> 00:04:36,210
and we create a risk profile based on

120
00:04:35,490 --> 00:04:37,800
that that

121
00:04:36,210 --> 00:04:39,448
allow us to figure out where we want us

122
00:04:37,800 --> 00:04:42,090
to have our security engineers spend

123
00:04:39,449 --> 00:04:43,830
their time the second thing is obviously

124
00:04:42,090 --> 00:04:46,289
red teaming in our own internal efforts

125
00:04:43,830 --> 00:04:48,380
at making attackers help a lot and then

126
00:04:46,289 --> 00:04:51,780
of course community events like this and

127
00:04:48,380 --> 00:04:53,639
from that information we focus in three

128
00:04:51,780 --> 00:04:56,669
different areas the first is we want to

129
00:04:53,639 --> 00:04:58,410
scale to developers those 3,600 people

130
00:04:56,669 --> 00:04:59,880
we don't just want them to commit code

131
00:04:58,410 --> 00:05:02,819
we actually want them to engage in

132
00:04:59,880 --> 00:05:05,130
security testing so we provide scalable

133
00:05:02,819 --> 00:05:08,039
fuzzing infrastructure know-how static

134
00:05:05,130 --> 00:05:10,169
analysis etc number two is we want to

135
00:05:08,039 --> 00:05:12,210
take our security Talent the security

136
00:05:10,169 --> 00:05:14,130
engineers who are a relatively small

137
00:05:12,210 --> 00:05:16,020
ratio when compared to developers and we

138
00:05:14,130 --> 00:05:18,270
want to focus in areas that matter the

139
00:05:16,020 --> 00:05:19,500
most and then number three is if we see

140
00:05:18,270 --> 00:05:21,419
a repeated mistake

141
00:05:19,500 --> 00:05:23,310
we want to invalidate that mistake by

142
00:05:21,419 --> 00:05:25,139
moving they safer languages updating the

143
00:05:23,310 --> 00:05:26,880
operating system or changing the

144
00:05:25,139 --> 00:05:29,940
compiler and I'll show you some examples

145
00:05:26,880 --> 00:05:31,770
of that so when we think about this is

146
00:05:29,940 --> 00:05:34,620
there's really a discovery funnel that

147
00:05:31,770 --> 00:05:36,659
we want to focus our energy on the idea

148
00:05:34,620 --> 00:05:38,130
is we want to mimic the development

149
00:05:36,659 --> 00:05:40,320
lifecycle and figure out where is the

150
00:05:38,130 --> 00:05:42,090
best place to apply the right technique

151
00:05:40,320 --> 00:05:43,919
so if you think about code starting with

152
00:05:42,090 --> 00:05:46,469
a pool request we want to have static

153
00:05:43,919 --> 00:05:48,150
analysis that catches bugs as early as

154
00:05:46,470 --> 00:05:49,949
possible because that's the cheapest

155
00:05:48,150 --> 00:05:51,719
possible point now anybody who's ever

156
00:05:49,949 --> 00:05:54,570
worked with static analysis knows that

157
00:05:51,719 --> 00:05:56,400
it can be noisy it can be nasty etc but

158
00:05:54,570 --> 00:05:58,169
if you can just trim off a few of the

159
00:05:56,400 --> 00:06:00,150
common bug classes very early at the

160
00:05:58,169 --> 00:06:01,289
compiler or static analysis those are

161
00:06:00,150 --> 00:06:04,229
things you don't have to go hunt down

162
00:06:01,289 --> 00:06:06,300
later similarly at the unit test or

163
00:06:04,229 --> 00:06:07,590
build integration perspective we'd like

164
00:06:06,300 --> 00:06:09,990
to be able to automatically generate

165
00:06:07,590 --> 00:06:11,909
fuzzing a numerator attack surface and

166
00:06:09,990 --> 00:06:13,800
give feedback to those developers and

167
00:06:11,909 --> 00:06:15,270
once they're ready to actually test

168
00:06:13,800 --> 00:06:17,130
their code and most often that's

169
00:06:15,270 --> 00:06:19,859
internally we want to use things like a

170
00:06:17,130 --> 00:06:21,599
SAN and dynamic analysis to catch again

171
00:06:19,860 --> 00:06:23,639
more low-hanging fruit with some of

172
00:06:21,599 --> 00:06:26,849
those techniques and that really lives

173
00:06:23,639 --> 00:06:28,680
our pen testers and our red teamers to

174
00:06:26,849 --> 00:06:29,789
focus on the places where developers

175
00:06:28,680 --> 00:06:32,639
simply aren't going to have the

176
00:06:29,789 --> 00:06:34,620
expertise or the history and skill set

177
00:06:32,639 --> 00:06:36,960
to target that and that's why we want to

178
00:06:34,620 --> 00:06:38,849
create this funnel that will allow us to

179
00:06:36,960 --> 00:06:41,638
focus our resources in the most valuable

180
00:06:38,849 --> 00:06:43,590
places so the first question is really

181
00:06:41,639 --> 00:06:46,289
how do we scale security in Windows the

182
00:06:43,590 --> 00:06:48,150
challenges of scales are enormous the

183
00:06:46,289 --> 00:06:49,979
first is you know fuzzing is great in

184
00:06:48,150 --> 00:06:51,960
concept but a bad fuzz

185
00:06:49,980 --> 00:06:53,670
is not worth very much so the question

186
00:06:51,960 --> 00:06:56,340
is how do we make an average developer

187
00:06:53,670 --> 00:06:58,740
fuzz like a rockstar security engineer

188
00:06:56,340 --> 00:07:01,229
that's a real challenge number two is

189
00:06:58,740 --> 00:07:03,630
static analysis sounds great it sounds

190
00:07:01,230 --> 00:07:05,340
great in practice but in reality it has

191
00:07:03,630 --> 00:07:07,409
lots of challenges from a precision

192
00:07:05,340 --> 00:07:09,810
standpoint it can take up resource

193
00:07:07,410 --> 00:07:11,610
configuring and it's challenging so in

194
00:07:09,810 --> 00:07:13,830
practice rolling it out the scales we're

195
00:07:11,610 --> 00:07:16,410
talking about is ridiculously

196
00:07:13,830 --> 00:07:17,789
challenging engineering problem and the

197
00:07:16,410 --> 00:07:20,010
last thing we want to do is make it

198
00:07:17,790 --> 00:07:22,170
super difficult for you to shoot

199
00:07:20,010 --> 00:07:24,120
yourself in the foot so beyond those

200
00:07:22,170 --> 00:07:26,190
things like banning certain api's or

201
00:07:24,120 --> 00:07:27,930
having basic kind of hygiene approaches

202
00:07:26,190 --> 00:07:29,670
we want to be able to instrument the

203
00:07:27,930 --> 00:07:31,650
compiler and other places to simply

204
00:07:29,670 --> 00:07:33,510
remove concepts that developers tend to

205
00:07:31,650 --> 00:07:37,109
get wrong especially when they have to

206
00:07:33,510 --> 00:07:39,120
move fast so the first thing we need to

207
00:07:37,110 --> 00:07:41,010
do is focus the organization on where

208
00:07:39,120 --> 00:07:42,720
there are challenges when we have so

209
00:07:41,010 --> 00:07:44,099
many commits happening the first thing

210
00:07:42,720 --> 00:07:46,470
you have to ask yourself is where is

211
00:07:44,100 --> 00:07:48,540
code being introduced that actually has

212
00:07:46,470 --> 00:07:50,520
some risk so we addressed this by

213
00:07:48,540 --> 00:07:53,220
actually creating an automated system

214
00:07:50,520 --> 00:07:55,560
for automatically enumerated attack

215
00:07:53,220 --> 00:07:57,510
surface and we call that ways or windows

216
00:07:55,560 --> 00:07:59,280
automated attack surface enumerator and

217
00:07:57,510 --> 00:08:01,170
essentially what it does is it takes

218
00:07:59,280 --> 00:08:03,570
every single build that were is a

219
00:08:01,170 --> 00:08:05,400
candidate for flight it sets that build

220
00:08:03,570 --> 00:08:06,840
up in a VM environment and it runs a

221
00:08:05,400 --> 00:08:09,359
combination of static and dynamic

222
00:08:06,840 --> 00:08:11,580
analysis so it can actually use some of

223
00:08:09,360 --> 00:08:14,100
our dbi frameworks to figure out at an

224
00:08:11,580 --> 00:08:16,050
argument level whether a parameter has

225
00:08:14,100 --> 00:08:18,510
changed to a function where there's a

226
00:08:16,050 --> 00:08:20,610
new RPC interface the new ActiveX

227
00:08:18,510 --> 00:08:23,250
control get added is there a decom

228
00:08:20,610 --> 00:08:25,200
interface is there a new I octal etc etc

229
00:08:23,250 --> 00:08:27,450
and we take that information and we

230
00:08:25,200 --> 00:08:29,159
generate fuzzing tasks and requirements

231
00:08:27,450 --> 00:08:32,669
on our developer and that's the first

232
00:08:29,160 --> 00:08:34,410
level of scale here's just an example of

233
00:08:32,669 --> 00:08:36,929
what we can get out of this waste

234
00:08:34,409 --> 00:08:40,140
database what you can see is we have an

235
00:08:36,929 --> 00:08:43,020
enormous number of system calls 1,700 in

236
00:08:40,140 --> 00:08:45,449
total and just in the last oh s we added

237
00:08:43,020 --> 00:08:47,220
another 80 for system calls so waste

238
00:08:45,450 --> 00:08:49,680
will automatically discover that and

239
00:08:47,220 --> 00:08:51,750
generate in some cases syscall our stubs

240
00:08:49,680 --> 00:08:54,780
or other test collateral that will allow

241
00:08:51,750 --> 00:08:57,390
us to automatically go and put some

242
00:08:54,780 --> 00:09:00,290
security engineering muscle on to these

243
00:08:57,390 --> 00:09:03,449
critical attack surfaces like the kernel

244
00:09:00,290 --> 00:09:03,719
now it's one thing to have the attacks

245
00:09:03,450 --> 00:09:05,490
there

246
00:09:03,720 --> 00:09:07,320
another thing is to actually get quality

247
00:09:05,490 --> 00:09:09,330
security tests the way that

248
00:09:07,320 --> 00:09:10,800
traditionally works is someone sort of

249
00:09:09,330 --> 00:09:12,450
figures out their threat model which can

250
00:09:10,800 --> 00:09:14,010
be challenging in and of itself I

251
00:09:12,450 --> 00:09:15,420
remember one time I was in a threat

252
00:09:14,010 --> 00:09:17,310
model meeting where we were discussing

253
00:09:15,420 --> 00:09:21,979
the risks of a function that returns

254
00:09:17,310 --> 00:09:24,390
void that's not a great use of of

255
00:09:21,980 --> 00:09:25,890
resources so we want to really focus our

256
00:09:24,390 --> 00:09:27,870
developers on places where they can make

257
00:09:25,890 --> 00:09:30,360
a difference the second thing is they

258
00:09:27,870 --> 00:09:32,520
might run right the test harness and

259
00:09:30,360 --> 00:09:35,340
develop fuzzing on their own and that

260
00:09:32,520 --> 00:09:37,199
can range in quality tremendously

261
00:09:35,340 --> 00:09:39,360
depending on the experience at skillset

262
00:09:37,200 --> 00:09:41,430
of the developer so here's a great

263
00:09:39,360 --> 00:09:42,900
example of where it worked well we

264
00:09:41,430 --> 00:09:45,870
actually had an agent across a

265
00:09:42,900 --> 00:09:48,090
hypervisor boundary that handled DHCP

266
00:09:45,870 --> 00:09:49,710
traffic so what we were able to do with

267
00:09:48,090 --> 00:09:51,480
this particular developer is they took

268
00:09:49,710 --> 00:09:53,660
all their mocks and stubs they

269
00:09:51,480 --> 00:09:56,610
redirected a lot of the code exercised

270
00:09:53,660 --> 00:09:59,010
into Lib buzzer which generated quality

271
00:09:56,610 --> 00:10:00,630
test cases for them the performance and

272
00:09:59,010 --> 00:10:02,550
throughput was tremendous we actually

273
00:10:00,630 --> 00:10:04,950
got two hundred thousand iterations for

274
00:10:02,550 --> 00:10:08,189
setec did on this self-contained parser

275
00:10:04,950 --> 00:10:12,090
we landed on 72% code coverage we found

276
00:10:08,190 --> 00:10:14,610
for vulns and two RCE remote bugs in a

277
00:10:12,090 --> 00:10:16,590
brand new DHCP stack this is exactly

278
00:10:14,610 --> 00:10:18,210
what we want to see and this is one but

279
00:10:16,590 --> 00:10:20,310
by a developer who doesn't have any

280
00:10:18,210 --> 00:10:22,260
security expertise just by having

281
00:10:20,310 --> 00:10:24,089
quality tools so this is a great example

282
00:10:22,260 --> 00:10:25,500
of how it can be done manually the

283
00:10:24,090 --> 00:10:27,710
question is how do we make developers

284
00:10:25,500 --> 00:10:30,840
rockstars so this is just simple to do

285
00:10:27,710 --> 00:10:33,060
how do we make this easy and our

286
00:10:30,840 --> 00:10:36,210
approach to this is actually to take the

287
00:10:33,060 --> 00:10:38,880
Microsoft risk detection platform or MSR

288
00:10:36,210 --> 00:10:41,400
D which is actually a platform built on

289
00:10:38,880 --> 00:10:43,050
top of the Azure cloud which extends all

290
00:10:41,400 --> 00:10:45,750
of the tools that we use internally to

291
00:10:43,050 --> 00:10:48,839
Microsoft to external folks and so the

292
00:10:45,750 --> 00:10:51,180
the the use cases are pretty simple you

293
00:10:48,839 --> 00:10:52,260
provide a fuzz target of our binary or a

294
00:10:51,180 --> 00:10:54,719
build of the thing you'd like to

295
00:10:52,260 --> 00:10:57,120
exercise or fuzz you give us symbols and

296
00:10:54,720 --> 00:10:59,100
as much metadata as possible you give us

297
00:10:57,120 --> 00:11:00,780
a test harness to exercise that code

298
00:10:59,100 --> 00:11:02,880
maybe with a specially named function

299
00:11:00,780 --> 00:11:06,480
and any corpuses or metadata whether

300
00:11:02,880 --> 00:11:09,240
that's packets API calls files depending

301
00:11:06,480 --> 00:11:11,370
on the fuzz surface and MS RD abstracts

302
00:11:09,240 --> 00:11:13,560
all of this and provides hyperscale

303
00:11:11,370 --> 00:11:15,000
fuzzing and really when you think about

304
00:11:13,560 --> 00:11:16,739
the quality of fuzzing it comes down to

305
00:11:15,000 --> 00:11:17,590
a few things one is the quality of your

306
00:11:16,740 --> 00:11:19,720
test cases

307
00:11:17,590 --> 00:11:21,730
the quality or fuzzer and then how fast

308
00:11:19,720 --> 00:11:24,280
can you scale that and we aim to solve

309
00:11:21,730 --> 00:11:27,490
all three of those problems in this MS

310
00:11:24,280 --> 00:11:29,410
RD system and so for example a developer

311
00:11:27,490 --> 00:11:31,450
can simply mock up a test and they can

312
00:11:29,410 --> 00:11:33,160
run lib buzzer they can have sis call

313
00:11:31,450 --> 00:11:35,530
our stubs automatically generated from

314
00:11:33,160 --> 00:11:38,230
symbols and we can even use can colic or

315
00:11:35,530 --> 00:11:39,970
constraint solving fuzzing to get deeper

316
00:11:38,230 --> 00:11:41,950
code coverage than would be possible and

317
00:11:39,970 --> 00:11:44,080
it's really difficult to figure on its

318
00:11:41,950 --> 00:11:46,000
own so this system is actually plugged

319
00:11:44,080 --> 00:11:48,100
directly into the engineering systems in

320
00:11:46,000 --> 00:11:50,560
Windows which would allow you to simply

321
00:11:48,100 --> 00:11:52,660
you know in your daily workflow as a

322
00:11:50,560 --> 00:11:56,859
developer generate hyper scale fuzzing

323
00:11:52,660 --> 00:11:58,240
with quality security features in it so

324
00:11:56,860 --> 00:11:59,260
let's look a little bit about what some

325
00:11:58,240 --> 00:12:00,880
of the fuzzers that have been integrated

326
00:11:59,260 --> 00:12:02,860
the first one I want to point out as a

327
00:12:00,880 --> 00:12:04,660
fuzzer called sage which actually

328
00:12:02,860 --> 00:12:07,180
developed by our research organization

329
00:12:04,660 --> 00:12:09,670
and what sage does in a nutshell is it

330
00:12:07,180 --> 00:12:12,280
converts all of the code paths that are

331
00:12:09,670 --> 00:12:15,040
controlled by tainted data into an

332
00:12:12,280 --> 00:12:17,470
elaborate a mathematical function so

333
00:12:15,040 --> 00:12:20,170
what we can simply do is use a z3 or

334
00:12:17,470 --> 00:12:23,140
constraint solver to convert those code

335
00:12:20,170 --> 00:12:26,439
paths into a solvable math problem and

336
00:12:23,140 --> 00:12:28,750
the z33 constraint solver will generate

337
00:12:26,440 --> 00:12:30,880
inputs that can solve that function

338
00:12:28,750 --> 00:12:32,680
leading to code coverage and state

339
00:12:30,880 --> 00:12:34,900
coverage so if we look at this very

340
00:12:32,680 --> 00:12:36,430
basic function you can see if you're

341
00:12:34,900 --> 00:12:38,770
able to submit the string bad

342
00:12:36,430 --> 00:12:40,630
exclamation point you'll actually drive

343
00:12:38,770 --> 00:12:42,520
up the count to 4 and trigger the crash

344
00:12:40,630 --> 00:12:45,250
function now this is a simple example

345
00:12:42,520 --> 00:12:46,569
but in reality this is very much what it

346
00:12:45,250 --> 00:12:49,180
was like what it would look like to

347
00:12:46,570 --> 00:12:50,890
exercise the simple protocol so what

348
00:12:49,180 --> 00:12:54,370
sage will do is start with an initial

349
00:12:50,890 --> 00:12:55,630
input it will generate constraints for

350
00:12:54,370 --> 00:12:57,580
all of these if statements and

351
00:12:55,630 --> 00:12:59,410
understand that because of taint

352
00:12:57,580 --> 00:13:01,180
tracking and dynamic analysis it has

353
00:12:59,410 --> 00:13:03,310
control of that input across a trust

354
00:13:01,180 --> 00:13:06,729
boundary and it will go through a series

355
00:13:03,310 --> 00:13:09,010
of generational approaches using the

356
00:13:06,730 --> 00:13:11,920
constraint solver until it finally

357
00:13:09,010 --> 00:13:14,020
generates the input that would net new

358
00:13:11,920 --> 00:13:15,640
basic block coverage and in this

359
00:13:14,020 --> 00:13:17,770
particular case that basic block

360
00:13:15,640 --> 00:13:19,300
actually leads to a crash so that's a

361
00:13:17,770 --> 00:13:21,819
simple way of where someone can start

362
00:13:19,300 --> 00:13:24,400
with a test stub that maybe has 10%

363
00:13:21,820 --> 00:13:27,370
coverage and end up with 90 or a hundred

364
00:13:24,400 --> 00:13:28,600
percent on the tainted surface now the

365
00:13:27,370 --> 00:13:30,250
second thing we want to do beyond this

366
00:13:28,600 --> 00:13:30,720
sort of fuzzing dynamic analysis we want

367
00:13:30,250 --> 00:13:33,000
to provide

368
00:13:30,720 --> 00:13:34,980
static analysis at scale we do that two

369
00:13:33,000 --> 00:13:37,949
places first is on the developers

370
00:13:34,980 --> 00:13:39,750
desktop for high-throughput iteration we

371
00:13:37,949 --> 00:13:42,180
run a number of rules they're actually

372
00:13:39,750 --> 00:13:44,250
147 across seven different engines and

373
00:13:42,180 --> 00:13:46,050
we find bugs there early and where

374
00:13:44,250 --> 00:13:48,180
they're cheapest to fix more

375
00:13:46,050 --> 00:13:50,969
sophisticated static analysis is run

376
00:13:48,180 --> 00:13:52,949
directly in the engineering system it

377
00:13:50,970 --> 00:13:54,899
where it has to deal with a lot more

378
00:13:52,949 --> 00:13:57,149
scale and performance issues and that's

379
00:13:54,899 --> 00:13:59,639
run basically every time a build is

380
00:13:57,149 --> 00:14:03,120
generated in Windows across those 400

381
00:13:59,639 --> 00:14:04,740
back branches so very quickly every time

382
00:14:03,120 --> 00:14:07,110
a pull request goes in and that gets

383
00:14:04,740 --> 00:14:09,389
submitted to a build we actually run two

384
00:14:07,110 --> 00:14:11,939
different types of basic static analysis

385
00:14:09,389 --> 00:14:14,069
the first is AST or AB sites abstract

386
00:14:11,939 --> 00:14:15,480
syntax tree pre fast which is something

387
00:14:14,069 --> 00:14:17,790
you might be familiar with from Visual

388
00:14:15,480 --> 00:14:19,529
Studio but we also bought recently at

389
00:14:17,790 --> 00:14:22,019
Microsoft a little company called Cemil

390
00:14:19,529 --> 00:14:23,970
and github which has a very different

391
00:14:22,019 --> 00:14:25,829
approach to static analysis and we're

392
00:14:23,970 --> 00:14:28,019
now starting to scale up our Cemil rules

393
00:14:25,829 --> 00:14:29,878
which have been very valuable the thing

394
00:14:28,019 --> 00:14:33,060
I wanted to point out here is two things

395
00:14:29,879 --> 00:14:36,540
first is to do static analysis on a

396
00:14:33,060 --> 00:14:40,410
single build of Windows it takes 56 VMs

397
00:14:36,540 --> 00:14:43,019
running for 24 hours it's a pretty big

398
00:14:40,410 --> 00:14:44,639
scale engineering problem number two is

399
00:14:43,019 --> 00:14:46,589
even though a lot of these rules are

400
00:14:44,639 --> 00:14:50,610
noisy and they might be limited in scope

401
00:14:46,589 --> 00:14:52,500
we generated 8,000 bugs and 2,700

402
00:14:50,610 --> 00:14:54,389
different defects fixed in a single

403
00:14:52,500 --> 00:14:56,459
calendar year so it is really effective

404
00:14:54,389 --> 00:14:59,189
at the scale for again eliminating some

405
00:14:56,459 --> 00:15:00,388
of the more basic issues an example of

406
00:14:59,189 --> 00:15:03,029
how those can be made even more

407
00:15:00,389 --> 00:15:05,490
effective is something we call sal or so

408
00:15:03,029 --> 00:15:08,939
source code annotation language in the

409
00:15:05,490 --> 00:15:11,129
basic form running a generic static

410
00:15:08,939 --> 00:15:13,259
analysis capability we're often lacking

411
00:15:11,129 --> 00:15:15,269
information around context so for

412
00:15:13,259 --> 00:15:16,379
example as a developer's writing their

413
00:15:15,269 --> 00:15:18,420
code they might be able to add

414
00:15:16,379 --> 00:15:20,220
annotations that are specific that would

415
00:15:18,420 --> 00:15:22,800
tell things to the static analysis

416
00:15:20,220 --> 00:15:24,860
engine like hey this type of behavior

417
00:15:22,800 --> 00:15:27,420
should never happen if this particular

418
00:15:24,860 --> 00:15:29,459
you know value goes out of this range

419
00:15:27,420 --> 00:15:31,259
then you should flag a contract

420
00:15:29,459 --> 00:15:33,359
violation and I wanted to give you an

421
00:15:31,259 --> 00:15:35,490
example of where this can actually net

422
00:15:33,360 --> 00:15:37,050
quality bugs so what you have here is a

423
00:15:35,490 --> 00:15:39,709
basic vulnerable function this is

424
00:15:37,050 --> 00:15:42,990
actually a zero-day that we found in a

425
00:15:39,709 --> 00:15:44,819
particularly scary Network stack and an

426
00:15:42,990 --> 00:15:47,820
interesting contract violation here

427
00:15:44,820 --> 00:15:49,740
vulnerable function returns just a

428
00:15:47,820 --> 00:15:52,290
buffer that's two bytes but it's

429
00:15:49,740 --> 00:15:55,350
actually assigned to a header structure

430
00:15:52,290 --> 00:15:57,689
that's 16 bytes and so when we

431
00:15:55,350 --> 00:15:59,459
dereference the ID field of that header

432
00:15:57,690 --> 00:16:01,800
structure we're actually gonna go out of

433
00:15:59,459 --> 00:16:03,510
bounds so static analysis on its own

434
00:16:01,800 --> 00:16:05,490
didn't catch this because of the intra

435
00:16:03,510 --> 00:16:07,439
procedural nature but as soon as we

436
00:16:05,490 --> 00:16:09,899
added this Sal annotation here that

437
00:16:07,440 --> 00:16:11,640
tells that when a contract is violated

438
00:16:09,899 --> 00:16:14,070
by and by what size the buffer is

439
00:16:11,640 --> 00:16:16,110
expected to be we actually net out and

440
00:16:14,070 --> 00:16:17,610
find this issue so here's a great

441
00:16:16,110 --> 00:16:19,860
example of a bug that could have easily

442
00:16:17,610 --> 00:16:21,660
turned into a horrible thing you know

443
00:16:19,860 --> 00:16:23,820
it's the next sort of marketed headline

444
00:16:21,660 --> 00:16:26,329
driving vulnerability that's eliminated

445
00:16:23,820 --> 00:16:30,269
pretty simply in our engineering systems

446
00:16:26,329 --> 00:16:32,550
so we aren't limited actually at all for

447
00:16:30,269 --> 00:16:34,620
static analysis engines most of our

448
00:16:32,550 --> 00:16:37,680
limitations aren't writing quality rules

449
00:16:34,620 --> 00:16:39,690
and getting the noise level down to

450
00:16:37,680 --> 00:16:41,819
something that's acceptable to assign to

451
00:16:39,690 --> 00:16:45,630
developers I mentioned we filed about

452
00:16:41,820 --> 00:16:47,220
8,000 bugs only 2,700 were fixed if we

453
00:16:45,630 --> 00:16:49,020
employed all the latest and greatest

454
00:16:47,220 --> 00:16:51,029
plug-in techniques we would probably

455
00:16:49,020 --> 00:16:53,550
drive that noise ratio way up and

456
00:16:51,029 --> 00:16:55,350
developers were trust our tools less so

457
00:16:53,550 --> 00:16:56,790
the cost that battle we fight is pretty

458
00:16:55,350 --> 00:16:59,160
similar to the battle you would fight

459
00:16:56,790 --> 00:17:01,380
and say developing an EDR which is if

460
00:16:59,160 --> 00:17:03,480
you make it too noisy no one will look

461
00:17:01,380 --> 00:17:05,429
at the alerts if you make it too scoped

462
00:17:03,480 --> 00:17:06,569
you'll miss all the good bugs so the

463
00:17:05,429 --> 00:17:08,610
reality is we have lots of different

464
00:17:06,569 --> 00:17:10,379
frameworks but we're constantly battling

465
00:17:08,609 --> 00:17:12,479
with how to tune them into a way that we

466
00:17:10,380 --> 00:17:15,630
can get more actionable bugs which is

467
00:17:12,480 --> 00:17:17,760
the hard currency we care about and then

468
00:17:15,630 --> 00:17:20,040
finally you know I look at static

469
00:17:17,760 --> 00:17:21,240
analysis as a really good proving ground

470
00:17:20,040 --> 00:17:23,188
for something that should be in the

471
00:17:21,240 --> 00:17:25,559
compiler if it's something we can catch

472
00:17:23,189 --> 00:17:27,059
reliably in static analysis I'd like for

473
00:17:25,559 --> 00:17:29,010
that condition to just not be possible

474
00:17:27,059 --> 00:17:31,559
at all so we have a great relationship

475
00:17:29,010 --> 00:17:34,200
with our visual studio team and open

476
00:17:31,559 --> 00:17:36,750
source compilers like clang in LLVM were

477
00:17:34,200 --> 00:17:39,419
able to convert more of the things that

478
00:17:36,750 --> 00:17:42,120
we see regularly mistakes at the

479
00:17:39,419 --> 00:17:43,710
developer level into compiler changes so

480
00:17:42,120 --> 00:17:45,149
I wanted to highlight three areas in

481
00:17:43,710 --> 00:17:47,850
which we're looking to make sure that

482
00:17:45,150 --> 00:17:49,770
developers can't fail the first is a lot

483
00:17:47,850 --> 00:17:51,600
of investment in memory safe languages

484
00:17:49,770 --> 00:17:53,400
there's lots of experimentation for

485
00:17:51,600 --> 00:17:54,840
things like rust in Windows where we're

486
00:17:53,400 --> 00:17:56,850
looking at how do we take these newer

487
00:17:54,840 --> 00:17:58,470
systems languages and apply them to

488
00:17:56,850 --> 00:18:00,360
critical code bases

489
00:17:58,470 --> 00:18:01,740
you're a fan of rust you might have been

490
00:18:00,360 --> 00:18:04,110
following some of the blogs coming at a

491
00:18:01,740 --> 00:18:07,230
mess or see a lot of activity and energy

492
00:18:04,110 --> 00:18:10,020
there similarly we are using some of the

493
00:18:07,230 --> 00:18:12,090
C++ standard library updates for

494
00:18:10,020 --> 00:18:14,070
constructs like span which make it much

495
00:18:12,090 --> 00:18:15,629
simpler to deal with binary buffers

496
00:18:14,070 --> 00:18:18,240
without doing a bunch of sophisticated

497
00:18:15,630 --> 00:18:20,340
pointer math that can rely in things

498
00:18:18,240 --> 00:18:22,830
like out of bound indexes or integer

499
00:18:20,340 --> 00:18:24,539
overflows and GSL span is something

500
00:18:22,830 --> 00:18:26,760
we're using quite widely in high risk

501
00:18:24,539 --> 00:18:28,890
code bases in Windows specifically in

502
00:18:26,760 --> 00:18:31,379
places like hyper-v and then the last

503
00:18:28,890 --> 00:18:33,150
thing is we are updating some of our

504
00:18:31,380 --> 00:18:35,309
allocator wrappers in this particular

505
00:18:33,150 --> 00:18:36,659
case X allocate pool and we think this

506
00:18:35,309 --> 00:18:39,000
will solve a lot of the habitual

507
00:18:36,659 --> 00:18:42,020
problems we see in kernel code that's

508
00:18:39,000 --> 00:18:43,230
red light related to buffer handling

509
00:18:42,020 --> 00:18:44,400
okay

510
00:18:43,230 --> 00:18:46,230
now that I've talked to you a little bit

511
00:18:44,400 --> 00:18:48,720
about scale let's talk to you about how

512
00:18:46,230 --> 00:18:50,220
we make our precious security

513
00:18:48,720 --> 00:18:51,960
engineering talent who are hunting

514
00:18:50,220 --> 00:18:54,659
vulnerabilities and windows more

515
00:18:51,960 --> 00:18:56,280
efficient so there's really three big

516
00:18:54,659 --> 00:18:59,460
challenges to doing vulnerability

517
00:18:56,280 --> 00:19:01,168
hunting the first is we only have a very

518
00:18:59,460 --> 00:19:04,710
small number of security engineers

519
00:19:01,169 --> 00:19:06,480
relative to the giant army of engineers

520
00:19:04,710 --> 00:19:08,309
and no matter how many we add we'll

521
00:19:06,480 --> 00:19:10,169
probably never have enough so having a

522
00:19:08,309 --> 00:19:11,520
good strategy on where to deploy them is

523
00:19:10,169 --> 00:19:14,520
a never-ending problem that we're

524
00:19:11,520 --> 00:19:16,470
constantly tuning the second is because

525
00:19:14,520 --> 00:19:18,389
these folks are scarce we want to make

526
00:19:16,470 --> 00:19:20,669
every time they do an engagement as

527
00:19:18,390 --> 00:19:22,620
valuable as possible so there's a lot of

528
00:19:20,669 --> 00:19:24,299
discussion on how to create tooling and

529
00:19:22,620 --> 00:19:26,820
frameworks that will result in more

530
00:19:24,299 --> 00:19:28,350
efficiency there and then last pieces is

531
00:19:26,820 --> 00:19:30,149
we want to understand how effective

532
00:19:28,350 --> 00:19:31,379
they're being if we deploy our best

533
00:19:30,150 --> 00:19:33,059
security talent somewhere and they're

534
00:19:31,380 --> 00:19:35,850
not finding bugs we want to make sure

535
00:19:33,059 --> 00:19:37,559
we're moving them somewhere else so

536
00:19:35,850 --> 00:19:40,110
prioritizing security reviews is

537
00:19:37,559 --> 00:19:41,668
honestly just a dark art we have a

538
00:19:40,110 --> 00:19:44,219
pretty simple way we think about

539
00:19:41,669 --> 00:19:45,870
deploying but we're constantly tuning

540
00:19:44,220 --> 00:19:47,970
this and you can be caught off guard so

541
00:19:45,870 --> 00:19:50,668
for example we'd like to make sure that

542
00:19:47,970 --> 00:19:52,200
we're always deploying folks in the area

543
00:19:50,669 --> 00:19:54,690
of highest impact with the highest

544
00:19:52,200 --> 00:19:56,850
probability of a vulnerability being

545
00:19:54,690 --> 00:19:58,679
found externally why is that we know

546
00:19:56,850 --> 00:20:00,299
we're not gonna find all the bugs so

547
00:19:58,679 --> 00:20:01,770
what we want to focus is on finding the

548
00:20:00,299 --> 00:20:04,020
bugs that are most likely going to be

549
00:20:01,770 --> 00:20:05,549
converted into exploits and I bet a lot

550
00:20:04,020 --> 00:20:06,960
of you are thinking your head how would

551
00:20:05,549 --> 00:20:10,020
you do that how do you predict that and

552
00:20:06,960 --> 00:20:11,340
the answer is it's very challenging so

553
00:20:10,020 --> 00:20:12,120
we use a couple of different data

554
00:20:11,340 --> 00:20:14,280
sources for the

555
00:20:12,120 --> 00:20:15,989
the first is you know we kind of have a

556
00:20:14,280 --> 00:20:17,790
lot of data coming in to Microsoft on

557
00:20:15,990 --> 00:20:19,740
what attackers are actually doing at

558
00:20:17,790 --> 00:20:21,510
least in the raw sense so we can take a

559
00:20:19,740 --> 00:20:23,370
lot of those threat detection 'z break

560
00:20:21,510 --> 00:20:25,650
them down and figure out what surfaces

561
00:20:23,370 --> 00:20:27,149
are most interesting the second thing is

562
00:20:25,650 --> 00:20:29,550
we can actually look at zero-day

563
00:20:27,150 --> 00:20:31,710
exploits and as at least a proxy for how

564
00:20:29,550 --> 00:20:33,419
good we're doing so if zero two exploits

565
00:20:31,710 --> 00:20:35,370
are trending down even if bugs are

566
00:20:33,420 --> 00:20:36,210
trending up we can say things like well

567
00:20:35,370 --> 00:20:37,649
we're adding the right platform

568
00:20:36,210 --> 00:20:39,540
mitigations and we're finding the right

569
00:20:37,650 --> 00:20:41,130
bugs now the challenge with that is

570
00:20:39,540 --> 00:20:42,480
we're not going to detect all the zero

571
00:20:41,130 --> 00:20:44,700
days there's plenty that we probably

572
00:20:42,480 --> 00:20:46,320
miss but again we're constantly looking

573
00:20:44,700 --> 00:20:49,080
for better data sources that are gonna

574
00:20:46,320 --> 00:20:51,330
tune us in to very specific areas but

575
00:20:49,080 --> 00:20:52,830
probably the best source of Intel that I

576
00:20:51,330 --> 00:20:53,939
get is probably gonna be here at this

577
00:20:52,830 --> 00:20:55,830
conference where someone's going to

578
00:20:53,940 --> 00:20:57,690
knock me over at the side and say have

579
00:20:55,830 --> 00:20:59,520
you looked at this function you guys are

580
00:20:57,690 --> 00:21:00,930
doing a terrible job on this binary and

581
00:20:59,520 --> 00:21:02,730
I'll take a lot of that Intel and we

582
00:21:00,930 --> 00:21:04,830
actually convert it back into security

583
00:21:02,730 --> 00:21:06,090
reviews some of the best stuff I find is

584
00:21:04,830 --> 00:21:08,520
actually through relationships in the

585
00:21:06,090 --> 00:21:09,929
community or through bounty participants

586
00:21:08,520 --> 00:21:13,950
who are giving us information on how to

587
00:21:09,930 --> 00:21:16,590
improve so here's a great example where

588
00:21:13,950 --> 00:21:20,180
we would deploy security reviews hyper-v

589
00:21:16,590 --> 00:21:22,889
kind of important you might think hey

590
00:21:20,180 --> 00:21:24,420
pentesting hyper-v how difficult can

591
00:21:22,890 --> 00:21:27,510
that be we understand the security

592
00:21:24,420 --> 00:21:29,400
boundaries in reality the threat model

593
00:21:27,510 --> 00:21:32,129
for hyper-v looks like this and I would

594
00:21:29,400 --> 00:21:33,660
say that this is a very generous summary

595
00:21:32,130 --> 00:21:35,970
of what the attack surface actually

596
00:21:33,660 --> 00:21:38,220
looks like we've got dozens of virtual

597
00:21:35,970 --> 00:21:39,690
device modules we've got multiple

598
00:21:38,220 --> 00:21:42,030
different architectures all the slightly

599
00:21:39,690 --> 00:21:44,280
different hypervisor design we've got

600
00:21:42,030 --> 00:21:46,649
Gen two VMs Gen 1 all which have

601
00:21:44,280 --> 00:21:48,240
different components so this is actually

602
00:21:46,650 --> 00:21:49,260
an example of how our security team

603
00:21:48,240 --> 00:21:51,300
would look at the different components

604
00:21:49,260 --> 00:21:53,330
and make sure that they're scheduling

605
00:21:51,300 --> 00:21:56,250
security reviews as those are updated

606
00:21:53,330 --> 00:21:57,960
meanwhile as we're Penn 10-8 seeing this

607
00:21:56,250 --> 00:22:00,720
new code is constantly coming and

608
00:21:57,960 --> 00:22:02,250
changing so I actually want to take you

609
00:22:00,720 --> 00:22:04,110
quickly through what it's like to do a

610
00:22:02,250 --> 00:22:06,210
pen test in Windows from a manual

611
00:22:04,110 --> 00:22:09,030
standpoint so we can tell you how we're

612
00:22:06,210 --> 00:22:11,400
improving that over time so TLS 1.3

613
00:22:09,030 --> 00:22:13,379
pretty critical in Windows is the new

614
00:22:11,400 --> 00:22:15,390
protocol we just implemented for the new

615
00:22:13,380 --> 00:22:17,550
standard it secures most of

616
00:22:15,390 --> 00:22:19,470
communications and windows thus the

617
00:22:17,550 --> 00:22:22,169
world really enough said about the risk

618
00:22:19,470 --> 00:22:23,610
there so the first thing you have to do

619
00:22:22,170 --> 00:22:25,080
when you're trying to do a pen test in

620
00:22:23,610 --> 00:22:27,360
Windows is you've got to get a test info

621
00:22:25,080 --> 00:22:29,158
as a pen tester this is a lot more

622
00:22:27,360 --> 00:22:30,748
challenging than you think you got to go

623
00:22:29,159 --> 00:22:32,039
knock on a devs office you're like

624
00:22:30,749 --> 00:22:33,419
where's your test cases do you have

625
00:22:32,039 --> 00:22:35,369
tests collateral do you have protocol

626
00:22:33,419 --> 00:22:37,739
documentation depending on the dev

627
00:22:35,369 --> 00:22:39,570
they're gonna say like talk to the hand

628
00:22:37,739 --> 00:22:41,279
I'm busy trying to land this code by a

629
00:22:39,570 --> 00:22:43,439
certain date it's actually just getting

630
00:22:41,279 --> 00:22:45,600
up a debugging and test environment is

631
00:22:43,440 --> 00:22:48,149
the first hassle it's actually a lot of

632
00:22:45,600 --> 00:22:49,769
work the second thing you want to do is

633
00:22:48,149 --> 00:22:51,779
again you're just being handed a big

634
00:22:49,769 --> 00:22:53,879
blob of code and if you're lucky a spec

635
00:22:51,779 --> 00:22:55,739
so the question is is where do you focus

636
00:22:53,879 --> 00:22:58,109
yourself thinking back to that big map

637
00:22:55,739 --> 00:23:00,299
maybe you're a security expert but

638
00:22:58,109 --> 00:23:02,070
you're not an expert in TLS so trying to

639
00:23:00,299 --> 00:23:05,039
figure out where things matter the most

640
00:23:02,070 --> 00:23:06,480
is very complicated so this is the first

641
00:23:05,039 --> 00:23:08,100
area where we can have some level of

642
00:23:06,480 --> 00:23:09,749
automation so we have great code search

643
00:23:08,100 --> 00:23:12,269
tools that will allow you to scope down

644
00:23:09,749 --> 00:23:13,529
look for particularly API calls pretty

645
00:23:12,269 --> 00:23:15,929
similar to what you might get in

646
00:23:13,529 --> 00:23:18,090
something like Ida but very targeted

647
00:23:15,929 --> 00:23:20,129
towards source code and then we're fans

648
00:23:18,090 --> 00:23:21,959
of tools like a site tools understand

649
00:23:20,129 --> 00:23:24,090
which will give you metrics and other

650
00:23:21,960 --> 00:23:25,820
things that might allow you to manually

651
00:23:24,090 --> 00:23:28,379
determine places where there are is risk

652
00:23:25,820 --> 00:23:31,019
so here's an example of a heat map we

653
00:23:28,379 --> 00:23:33,389
generated from TLS 1.3 this is inside

654
00:23:31,019 --> 00:23:35,009
tools understand and some of the things

655
00:23:33,389 --> 00:23:35,998
we're looking at here are hey what are

656
00:23:35,009 --> 00:23:38,460
the functions with the highest

657
00:23:35,999 --> 00:23:40,200
cyclomatic complexity that might be an

658
00:23:38,460 --> 00:23:43,440
indicator of risk maybe that's a place

659
00:23:40,200 --> 00:23:44,820
to start focusing so once you have a

660
00:23:43,440 --> 00:23:46,679
test environment up and you have an idea

661
00:23:44,820 --> 00:23:48,539
of where to go maybe you're going to set

662
00:23:46,679 --> 00:23:50,519
up a just basic buzzer to get things

663
00:23:48,539 --> 00:23:52,830
going in most cases you're going to get

664
00:23:50,519 --> 00:23:54,809
really shallow coverage in the case of

665
00:23:52,830 --> 00:23:57,480
TLS 1.3 it's a really complicated

666
00:23:54,809 --> 00:23:58,859
protocol so sending a bunch of bytes to

667
00:23:57,480 --> 00:23:59,669
an endpoint it's probably not going to

668
00:23:58,859 --> 00:24:01,350
get you very far

669
00:23:59,669 --> 00:24:03,840
but at least to get you to understand if

670
00:24:01,350 --> 00:24:05,820
your test environments working fuzzing

671
00:24:03,840 --> 00:24:07,678
phase 2 is where we will actually start

672
00:24:05,820 --> 00:24:10,470
doing more specific things so maybe now

673
00:24:07,679 --> 00:24:12,090
are creating a Sahara and one of the

674
00:24:10,470 --> 00:24:14,340
things that were really interested in

675
00:24:12,090 --> 00:24:16,559
for a remote protocol is our recovering

676
00:24:14,340 --> 00:24:18,480
state so if you just look at block

677
00:24:16,559 --> 00:24:20,700
coverage you might think yeah I got 80%

678
00:24:18,480 --> 00:24:22,139
block coverage everything is great but

679
00:24:20,700 --> 00:24:23,759
if you're not covering all of the

680
00:24:22,139 --> 00:24:25,918
different permutations of that state

681
00:24:23,759 --> 00:24:28,919
machine you're not doing very much to

682
00:24:25,919 --> 00:24:30,359
those protocols ask me how I know there

683
00:24:28,919 --> 00:24:33,059
are plenty of protocols where we have

684
00:24:30,359 --> 00:24:35,879
great block base coverage or line based

685
00:24:33,059 --> 00:24:38,279
coverage but we will get nsrc cases in

686
00:24:35,879 --> 00:24:39,240
them afterwards so kind of getting that

687
00:24:38,279 --> 00:24:41,370
going

688
00:24:39,240 --> 00:24:43,230
is important and again part of being

689
00:24:41,370 --> 00:24:45,418
able to do fuzzing well here is being

690
00:24:43,230 --> 00:24:46,679
able to disable integrity checks and

691
00:24:45,419 --> 00:24:48,539
other things that would get into your

692
00:24:46,679 --> 00:24:50,940
way so just being able to say things

693
00:24:48,539 --> 00:24:54,510
like can we disable H Mac during testing

694
00:24:50,940 --> 00:24:56,159
or critical components to success so

695
00:24:54,510 --> 00:24:57,658
fuzzing phase 3 is where things get a

696
00:24:56,159 --> 00:24:59,159
bit more serious we're pretty happy with

697
00:24:57,659 --> 00:25:02,700
our fuzzer we want to do an optimization

698
00:24:59,159 --> 00:25:04,350
pass and we want to make sure that we're

699
00:25:02,700 --> 00:25:06,419
not leaving any bugs on the table so

700
00:25:04,350 --> 00:25:08,189
using something like a sin to instrument

701
00:25:06,419 --> 00:25:10,350
some of the critical functions will make

702
00:25:08,190 --> 00:25:12,360
sure that we're able to get more bugs

703
00:25:10,350 --> 00:25:14,340
than we would normally and it will

704
00:25:12,360 --> 00:25:16,408
increase some of the classes for attack

705
00:25:14,340 --> 00:25:19,049
one thing I wanted to call out here that

706
00:25:16,409 --> 00:25:20,700
I think is pretty novel is previously we

707
00:25:19,049 --> 00:25:23,039
really didn't have a good way for

708
00:25:20,700 --> 00:25:25,230
detecting information leaks across a

709
00:25:23,039 --> 00:25:27,059
remote protocol which are critical to

710
00:25:25,230 --> 00:25:28,950
vulnerabilities like heartbleed or just

711
00:25:27,059 --> 00:25:30,720
general primitives and exploitation of a

712
00:25:28,950 --> 00:25:32,940
remote protocol so we've actually

713
00:25:30,720 --> 00:25:35,460
started to build instrumentation that

714
00:25:32,940 --> 00:25:37,049
will allow us to hook sinks and do some

715
00:25:35,460 --> 00:25:39,000
information leak detection we'll look at

716
00:25:37,049 --> 00:25:41,100
the buffers not just being sent out but

717
00:25:39,000 --> 00:25:42,809
the buffers coming back with Sentinel

718
00:25:41,100 --> 00:25:45,959
values that allow us to do information

719
00:25:42,809 --> 00:25:47,700
leakage detection static analysis will

720
00:25:45,960 --> 00:25:50,400
obviously happen this is a place where

721
00:25:47,700 --> 00:25:52,140
we actually leverage Cemil internally

722
00:25:50,400 --> 00:25:54,179
pretty heavily we find it's actually a

723
00:25:52,140 --> 00:25:55,950
great tool for guiding pen testers into

724
00:25:54,179 --> 00:25:59,610
more additional places to look while

725
00:25:55,950 --> 00:26:01,620
that fuzzing is going and then finally

726
00:25:59,610 --> 00:26:03,270
we'll start to do a lot more deep

727
00:26:01,620 --> 00:26:05,340
instrumentation around code coverage

728
00:26:03,270 --> 00:26:06,870
this is a place where you can wait for a

729
00:26:05,340 --> 00:26:09,299
code coverage build that's gonna happen

730
00:26:06,870 --> 00:26:10,860
massively but often pen testers just

731
00:26:09,299 --> 00:26:12,510
want to be able to very quickly make an

732
00:26:10,860 --> 00:26:14,399
adjustment to their fuzzer and get

733
00:26:12,510 --> 00:26:16,890
immediate code coverage so we're often

734
00:26:14,400 --> 00:26:18,539
looking at some of the code tools that

735
00:26:16,890 --> 00:26:20,730
might exist out there and idle and in

736
00:26:18,539 --> 00:26:23,330
other places yes we use either Python

737
00:26:20,730 --> 00:26:26,460
lighthouse some of the common plugins

738
00:26:23,330 --> 00:26:27,750
and then finally we want to take some of

739
00:26:26,460 --> 00:26:29,370
those collateral and give it to the

740
00:26:27,750 --> 00:26:32,549
future team so they can leverage it

741
00:26:29,370 --> 00:26:35,039
so for TLS 1.3 this was a lot of work

742
00:26:32,549 --> 00:26:36,750
but it actually paid dividends here's an

743
00:26:35,039 --> 00:26:38,370
example of a protocol we're just now

744
00:26:36,750 --> 00:26:40,230
turning on in customer environments

745
00:26:38,370 --> 00:26:41,149
where we actually found a double free

746
00:26:40,230 --> 00:26:43,500
RCE

747
00:26:41,150 --> 00:26:45,240
before it got out into the environment

748
00:26:43,500 --> 00:26:47,610
so this is a good example where the

749
00:26:45,240 --> 00:26:49,980
manual cost here was probably worth it

750
00:26:47,610 --> 00:26:52,439
we want to see it up level it and just

751
00:26:49,980 --> 00:26:55,440
so you know I'm not talking crap here

752
00:26:52,440 --> 00:26:56,760
here's actually a demo of the bug so

753
00:26:55,440 --> 00:26:59,100
we're gonna do here is just fire up a

754
00:26:56,760 --> 00:27:02,220
browser we're running a TLS 1.3 IAS

755
00:26:59,100 --> 00:27:04,379
server in the VM so just connect there

756
00:27:02,220 --> 00:27:05,400
simple hello protocol and now we're

757
00:27:04,380 --> 00:27:06,090
going to man in the middle of that

758
00:27:05,400 --> 00:27:08,370
traffic

759
00:27:06,090 --> 00:27:10,560
the reason this crashed probably some of

760
00:27:08,370 --> 00:27:12,899
you can guess is knocking down CLS in

761
00:27:10,560 --> 00:27:15,090
this particular case knock down L SAS so

762
00:27:12,900 --> 00:27:17,040
those devices and now in a non normal

763
00:27:15,090 --> 00:27:19,800
state and as I said this is a good

764
00:27:17,040 --> 00:27:21,360
example of I think of a positive case

765
00:27:19,800 --> 00:27:23,879
where we found the bug before it got out

766
00:27:21,360 --> 00:27:26,010
there but many cases that is challenging

767
00:27:23,880 --> 00:27:29,280
to do depending on the complexity of the

768
00:27:26,010 --> 00:27:31,200
protocol so I've showed you a lot of the

769
00:27:29,280 --> 00:27:33,149
manual work that happens there the real

770
00:27:31,200 --> 00:27:35,010
question is how do we get rid of that so

771
00:27:33,150 --> 00:27:37,380
we can find more bugs which is our goal

772
00:27:35,010 --> 00:27:39,600
and to do that we've actually built a

773
00:27:37,380 --> 00:27:42,180
full-featured security research platform

774
00:27:39,600 --> 00:27:43,919
so a couple of interesting things about

775
00:27:42,180 --> 00:27:47,160
this platform one is internally we call

776
00:27:43,920 --> 00:27:48,540
it TKO we wrote it and rust because the

777
00:27:47,160 --> 00:27:50,490
a lot of the code that needs to be

778
00:27:48,540 --> 00:27:52,260
pushed here is preeminent pretty similar

779
00:27:50,490 --> 00:27:53,880
to a normal environment and it would be

780
00:27:52,260 --> 00:27:55,290
embarrassing if the security team had

781
00:27:53,880 --> 00:27:57,300
memory corruption issues in our test

782
00:27:55,290 --> 00:28:00,030
environment so we built it in rust to

783
00:27:57,300 --> 00:28:02,100
get a feel for whether or not Russ is

784
00:28:00,030 --> 00:28:04,170
ready for production and of course to

785
00:28:02,100 --> 00:28:06,780
eliminate some of that the second thing

786
00:28:04,170 --> 00:28:09,540
is we wanted a couple of requirements

787
00:28:06,780 --> 00:28:12,420
the first is we wanted guaranteed 100%

788
00:28:09,540 --> 00:28:14,970
deterministic repro of even stateful

789
00:28:12,420 --> 00:28:16,650
based crashes so what that means in a

790
00:28:14,970 --> 00:28:19,170
nutshell is we chose to build this on

791
00:28:16,650 --> 00:28:22,260
box a full system emulator which would

792
00:28:19,170 --> 00:28:24,780
allow us to get a VM into a state where

793
00:28:22,260 --> 00:28:26,730
we are have most state coverage and then

794
00:28:24,780 --> 00:28:29,340
trigger the fuzzer once the VM is in

795
00:28:26,730 --> 00:28:31,500
that deterministic state beyond that we

796
00:28:29,340 --> 00:28:33,060
wanted to be able to create plug-ins for

797
00:28:31,500 --> 00:28:35,190
things like crash bucketing code

798
00:28:33,060 --> 00:28:36,960
coverage corpus management and all the

799
00:28:35,190 --> 00:28:39,030
basic things that exist today and a

800
00:28:36,960 --> 00:28:42,360
bunch of disparate manual tools in a

801
00:28:39,030 --> 00:28:43,500
simple place on the last bit is we

802
00:28:42,360 --> 00:28:45,360
wanted to be able to take something

803
00:28:43,500 --> 00:28:47,190
that's running on a researchers desktop

804
00:28:45,360 --> 00:28:49,620
and effortlessly move it into a hyper

805
00:28:47,190 --> 00:28:51,960
scale cloud and TKO fills all of those

806
00:28:49,620 --> 00:28:53,969
requirements for us so the first

807
00:28:51,960 --> 00:28:56,220
interesting about TKO is it's again like

808
00:28:53,970 --> 00:28:58,650
I said it's built on box it's about one

809
00:28:56,220 --> 00:29:00,510
100th of native speed but the fact that

810
00:28:58,650 --> 00:29:03,000
we get a hundred percent reproduction

811
00:29:00,510 --> 00:29:05,960
and that we can snapshot fuzzing at any

812
00:29:03,000 --> 00:29:07,669
given time is incredibly valuable and we

813
00:29:05,960 --> 00:29:10,130
being able to build Colonel debuggers on

814
00:29:07,669 --> 00:29:12,110
top of this basic fuzzing frameworks

815
00:29:10,130 --> 00:29:14,179
we've implemented things like Cisco lor

816
00:29:12,110 --> 00:29:16,309
and Lib buzzer on top of it and we have

817
00:29:14,179 --> 00:29:19,669
a runtime API that makes this super easy

818
00:29:16,309 --> 00:29:22,490
to extend it and rust so here's a great

819
00:29:19,669 --> 00:29:26,270
example of a case study of accelerating

820
00:29:22,490 --> 00:29:29,330
variant finding on top of TKO so in July

821
00:29:26,270 --> 00:29:31,850
GPZ really reported five different nsrc

822
00:29:29,330 --> 00:29:33,770
cases in the PE file format so it's very

823
00:29:31,850 --> 00:29:35,990
clear we have a challenge in PE and we

824
00:29:33,770 --> 00:29:40,940
want to find more so we built a simple

825
00:29:35,990 --> 00:29:42,679
PE fuzzer on top of a TKO and what TKO

826
00:29:40,940 --> 00:29:44,960
gave us the ability to do was actually

827
00:29:42,679 --> 00:29:47,149
snapshot the system once we're pretty

828
00:29:44,960 --> 00:29:50,779
deep in the PE fuzzer parser state and

829
00:29:47,149 --> 00:29:53,870
then do it a dynamic mutation iteration

830
00:29:50,779 --> 00:29:55,520
and code injection starting from the

831
00:29:53,870 --> 00:29:58,010
point where the PE parser is already

832
00:29:55,520 --> 00:29:59,899
pretty deep in code coverage the result

833
00:29:58,010 --> 00:30:01,789
of that is not only did we find all the

834
00:29:59,899 --> 00:30:04,129
MS or C cases that we previously missed

835
00:30:01,789 --> 00:30:07,690
but we found one additional bug all

836
00:30:04,130 --> 00:30:10,070
within three days of the initial report

837
00:30:07,690 --> 00:30:12,950
so here's a really simple example of how

838
00:30:10,070 --> 00:30:15,230
easy it is to take a TKO snapshot so you

839
00:30:12,950 --> 00:30:17,149
can build a test harness that drives the

840
00:30:15,230 --> 00:30:19,460
system state into where you are ready to

841
00:30:17,149 --> 00:30:21,860
be fuzz maybe you have to send five or

842
00:30:19,460 --> 00:30:23,990
six different initialization api's maybe

843
00:30:21,860 --> 00:30:25,820
you have to load a particular PE with a

844
00:30:23,990 --> 00:30:28,640
particular header but essentially all

845
00:30:25,820 --> 00:30:32,360
you have to do is fire off a particular

846
00:30:28,640 --> 00:30:35,179
CPU ID and that CPU ID has a handler and

847
00:30:32,360 --> 00:30:36,740
that will trigger a snapshot and so in a

848
00:30:35,179 --> 00:30:38,360
few lines of rust we're able to

849
00:30:36,740 --> 00:30:39,860
immediately take a full system staged

850
00:30:38,360 --> 00:30:44,000
snapshot which has guaranteed

851
00:30:39,860 --> 00:30:46,219
reproduction here's what a TKO fuzzer

852
00:30:44,000 --> 00:30:48,110
looks like you can actually set a

853
00:30:46,220 --> 00:30:50,210
mutation callback and that can be on a

854
00:30:48,110 --> 00:30:52,760
particular instruction breakpoint system

855
00:30:50,210 --> 00:30:56,770
state etc in this particular case we're

856
00:30:52,760 --> 00:30:56,770
just fuzzing the PE structures in memory

857
00:30:57,220 --> 00:31:01,880
we can also set things like breakpoints

858
00:30:59,929 --> 00:31:03,590
again breakpoints in a conventional

859
00:31:01,880 --> 00:31:05,840
world where you're using a programmatic

860
00:31:03,590 --> 00:31:07,549
debugger can be really difficult because

861
00:31:05,840 --> 00:31:09,799
you don't have snapshotting and some of

862
00:31:07,549 --> 00:31:11,450
those other constructs and takeo that's

863
00:31:09,799 --> 00:31:13,490
a breeze you basically just take a

864
00:31:11,450 --> 00:31:16,159
callback on whatever a particular memory

865
00:31:13,490 --> 00:31:18,260
read/write physical breakpoint whatever

866
00:31:16,159 --> 00:31:19,610
you want and you can trigger fuzzing

867
00:31:18,260 --> 00:31:22,110
from that

868
00:31:19,610 --> 00:31:25,290
so here's an example of taking that

869
00:31:22,110 --> 00:31:27,270
previously super manual challenge around

870
00:31:25,290 --> 00:31:30,330
TLS and converting into something

871
00:31:27,270 --> 00:31:32,760
trivial to do in TKO in this particular

872
00:31:30,330 --> 00:31:35,280
case we just wanted to instrument how

873
00:31:32,760 --> 00:31:37,440
often a particular function that

874
00:31:35,280 --> 00:31:39,389
controls TLS day is called whether

875
00:31:37,440 --> 00:31:41,640
that's read or write and what the

876
00:31:39,390 --> 00:31:44,430
particular structure was at that time

877
00:31:41,640 --> 00:31:47,010
and so something that took us months of

878
00:31:44,430 --> 00:31:49,080
our sorry days of instrumenting normal

879
00:31:47,010 --> 00:31:51,840
code is actually implemented in just a

880
00:31:49,080 --> 00:31:53,639
few minutes with again 1/100 scale which

881
00:31:51,840 --> 00:31:57,209
is pretty impressive and solves a pretty

882
00:31:53,640 --> 00:31:59,310
challenging problem here here's another

883
00:31:57,210 --> 00:32:00,240
example where we utilize TKO to do

884
00:31:59,310 --> 00:32:02,220
things that used to be really

885
00:32:00,240 --> 00:32:05,430
challenging what you see on this heat

886
00:32:02,220 --> 00:32:07,920
map in blue are reads from a hyper-v

887
00:32:05,430 --> 00:32:10,140
guest to a host and what you see in red

888
00:32:07,920 --> 00:32:12,120
are rights and we're actually able to do

889
00:32:10,140 --> 00:32:15,960
with TKO is find out places where we're

890
00:32:12,120 --> 00:32:18,030
double fetching so we're able to read

891
00:32:15,960 --> 00:32:20,340
information and then before we process

892
00:32:18,030 --> 00:32:24,330
it or we go back and read it again a

893
00:32:20,340 --> 00:32:26,669
guest can change that information to a

894
00:32:24,330 --> 00:32:28,830
buffer that we can no longer validate so

895
00:32:26,670 --> 00:32:30,570
we had a number of double fetch issues

896
00:32:28,830 --> 00:32:32,100
over time in the kernel

897
00:32:30,570 --> 00:32:33,540
they actually manifest themselves in

898
00:32:32,100 --> 00:32:35,580
hyper-v as well and they're very

899
00:32:33,540 --> 00:32:37,560
challenging to find traditionally I take

900
00:32:35,580 --> 00:32:40,230
a lot of code review or manual effort

901
00:32:37,560 --> 00:32:42,149
with static analysis with hyper-v TKO

902
00:32:40,230 --> 00:32:44,130
they're pretty trivial to find and this

903
00:32:42,150 --> 00:32:45,840
heat map gives us exactly the place we

904
00:32:44,130 --> 00:32:49,140
want to look in the code or we can

905
00:32:45,840 --> 00:32:50,909
simply build a fuzzer on top of so

906
00:32:49,140 --> 00:32:52,070
beyond just this type of pen testing

907
00:32:50,910 --> 00:32:54,480
we're looking broadly for

908
00:32:52,070 --> 00:32:57,000
vulnerabilities we also focus ourselves

909
00:32:54,480 --> 00:32:59,010
on red teaming quite often and the goal

910
00:32:57,000 --> 00:33:01,140
here is a little different than what we

911
00:32:59,010 --> 00:33:02,850
would seek to find and just standard pen

912
00:33:01,140 --> 00:33:04,590
testing so I wanted to give a quick case

913
00:33:02,850 --> 00:33:06,570
study on how we found a vulnerability

914
00:33:04,590 --> 00:33:10,260
that's been called externally

915
00:33:06,570 --> 00:33:12,360
Dasia blue in RDP so I wanted to quickly

916
00:33:10,260 --> 00:33:14,520
refresh folks on the why we do red

917
00:33:12,360 --> 00:33:16,919
teaming at all in essence what we really

918
00:33:14,520 --> 00:33:19,350
want to do is not just make believe but

919
00:33:16,920 --> 00:33:20,990
we want to model the way that attackers

920
00:33:19,350 --> 00:33:23,730
would operate as closely as possible

921
00:33:20,990 --> 00:33:26,010
that allows us to test our mitigations

922
00:33:23,730 --> 00:33:28,260
innovate internally new attack

923
00:33:26,010 --> 00:33:30,120
techniques and generally get stronger

924
00:33:28,260 --> 00:33:31,340
metrics on how well we're doing in the

925
00:33:30,120 --> 00:33:33,989
real world

926
00:33:31,340 --> 00:33:35,879
we also do things like identify security

927
00:33:33,990 --> 00:33:37,260
gaps in detection that are beyond just

928
00:33:35,880 --> 00:33:39,419
what we seek to remediate in the

929
00:33:37,260 --> 00:33:41,010
platform if we build an exploit we can

930
00:33:39,419 --> 00:33:42,809
actually share that with our blue team's

931
00:33:41,010 --> 00:33:44,640
who build detections on top of this and

932
00:33:42,809 --> 00:33:46,710
again this might give us a probabilistic

933
00:33:44,640 --> 00:33:48,390
model for detecting of vulnerability or

934
00:33:46,710 --> 00:33:50,880
a technique we have yet to see in the

935
00:33:48,390 --> 00:33:52,799
real world and then finally we are able

936
00:33:50,880 --> 00:33:54,660
to take some of this information and in

937
00:33:52,799 --> 00:33:57,360
places like one hunt which is our annual

938
00:33:54,660 --> 00:34:00,360
red blue team event actually create a

939
00:33:57,360 --> 00:34:01,830
sort of a pseudo incident or a MOX

940
00:34:00,360 --> 00:34:03,600
incident and see how well we're

941
00:34:01,830 --> 00:34:05,908
communicating how well our information

942
00:34:03,600 --> 00:34:09,210
is exchanged and really demonstrate the

943
00:34:05,909 --> 00:34:11,700
real-world impact so RTP was actually a

944
00:34:09,210 --> 00:34:13,230
place where we know many in many cases

945
00:34:11,699 --> 00:34:15,330
these ports are exposed and they're used

946
00:34:13,230 --> 00:34:17,159
within our own infrastructure so we were

947
00:34:15,330 --> 00:34:19,259
really concerned about a number of RDP

948
00:34:17,159 --> 00:34:21,119
scenarios most of you are probably

949
00:34:19,260 --> 00:34:23,429
familiar with some of the recent RDP

950
00:34:21,119 --> 00:34:24,629
exploits that target server-side but

951
00:34:23,429 --> 00:34:27,290
they're actually a number of scenarios

952
00:34:24,629 --> 00:34:29,668
where a you can attack from a

953
00:34:27,290 --> 00:34:31,590
potentially malicious server back to the

954
00:34:29,668 --> 00:34:33,299
client that might be interesting the

955
00:34:31,590 --> 00:34:36,030
first is if an attacker could get on a

956
00:34:33,300 --> 00:34:37,859
jump box and send back an X plate from

957
00:34:36,030 --> 00:34:40,109
that jump box the client you could

958
00:34:37,859 --> 00:34:41,759
target high-value assets from a jump box

959
00:34:40,109 --> 00:34:44,359
in fact that's something we've done in

960
00:34:41,760 --> 00:34:46,950
Red Team tradecraft previously and then

961
00:34:44,359 --> 00:34:48,929
increasingly in Windows we're using RDP

962
00:34:46,949 --> 00:34:51,629
to interact with containers or other

963
00:34:48,929 --> 00:34:53,369
local VMS where the client itself is

964
00:34:51,629 --> 00:34:55,379
actually the trust boundary so the

965
00:34:53,369 --> 00:34:56,879
server exists inside of VM and the

966
00:34:55,379 --> 00:34:58,650
client exists on the host

967
00:34:56,879 --> 00:35:02,310
those are both scenarios we want to test

968
00:34:58,650 --> 00:35:05,490
for so we went ahead and targeted the

969
00:35:02,310 --> 00:35:07,740
client code and in essence we found lots

970
00:35:05,490 --> 00:35:09,899
of interesting things so from a single

971
00:35:07,740 --> 00:35:14,220
Red Team case study we found nine

972
00:35:09,900 --> 00:35:16,590
critical RDP vulnerabilities and three

973
00:35:14,220 --> 00:35:18,750
important those are the CBE's up there

974
00:35:16,590 --> 00:35:22,170
one of them is called external lead Asia

975
00:35:18,750 --> 00:35:24,119
blue it took 33 days in total to

976
00:35:22,170 --> 00:35:27,359
weaponize that exploit on Windows 10

977
00:35:24,119 --> 00:35:29,220
thirteen days to find the bugs twenty

978
00:35:27,359 --> 00:35:31,319
days to actually write the exploit and

979
00:35:29,220 --> 00:35:32,700
that includes bypassing a lot of the

980
00:35:31,320 --> 00:35:34,740
mitigations that are native in Windows

981
00:35:32,700 --> 00:35:36,180
10 so I wanted to show you two of the

982
00:35:34,740 --> 00:35:38,520
primitives that we pulled out of this

983
00:35:36,180 --> 00:35:40,680
the first is a memory right which is

984
00:35:38,520 --> 00:35:42,480
again the Dasia blue vulnerability it's

985
00:35:40,680 --> 00:35:43,649
in the custom serialization layer of

986
00:35:42,480 --> 00:35:45,510
Artie

987
00:35:43,650 --> 00:35:48,119
and you can see in essence what we have

988
00:35:45,510 --> 00:35:51,150
here is a fully controlled size to a mem

989
00:35:48,119 --> 00:35:54,240
copy and that gives us an arbitrary Heep

990
00:35:51,150 --> 00:35:57,000
corruption of attacker controlled length

991
00:35:54,240 --> 00:35:59,339
so pretty powerful primitive now just

992
00:35:57,000 --> 00:36:01,050
writing over a remote protocol is not

993
00:35:59,339 --> 00:36:02,670
enough we either need to take that right

994
00:36:01,050 --> 00:36:05,220
and convert it to an information leak or

995
00:36:02,670 --> 00:36:07,349
in this case we have a second bug in

996
00:36:05,220 --> 00:36:09,209
this case it's an arbitrary read so

997
00:36:07,349 --> 00:36:11,579
again we control in this case the source

998
00:36:09,210 --> 00:36:13,859
pointer from a mem copy that's copied

999
00:36:11,579 --> 00:36:16,319
back to the attacker so we can leak

1000
00:36:13,859 --> 00:36:18,390
arbitrary memory including uninitialized

1001
00:36:16,319 --> 00:36:20,700
heap data which is a primitive that's

1002
00:36:18,390 --> 00:36:23,520
critical for rebuilding the remote code

1003
00:36:20,700 --> 00:36:24,899
execution explained so this is what it

1004
00:36:23,520 --> 00:36:28,200
looks like to actually build the deja

1005
00:36:24,900 --> 00:36:31,170
boo' x-play stage 1 we're doing lfhe

1006
00:36:28,200 --> 00:36:34,348
preparation stage 2 we're doing some

1007
00:36:31,170 --> 00:36:35,700
information leakage stage 3 we're taking

1008
00:36:34,349 --> 00:36:38,309
the information leak pointers and

1009
00:36:35,700 --> 00:36:39,990
creating an arbitrary vtable call

1010
00:36:38,309 --> 00:36:42,300
through that ends a remote code

1011
00:36:39,990 --> 00:36:44,729
execution rather than showing you a

1012
00:36:42,300 --> 00:36:46,650
Visio why don't we just look at the

1013
00:36:44,730 --> 00:36:50,910
exploit in practice so you can use here

1014
00:36:46,650 --> 00:36:53,910
we're using Kali Linux which is our

1015
00:36:50,910 --> 00:36:55,828
preferred exploit environment and we've

1016
00:36:53,910 --> 00:36:57,149
got a malicious server and a trusted

1017
00:36:55,829 --> 00:37:02,069
client so we're actually going to

1018
00:36:57,150 --> 00:37:03,480
connect across of course say yes we're

1019
00:37:02,069 --> 00:37:06,390
now triggering both the read and the

1020
00:37:03,480 --> 00:37:10,040
write and we have full code execution in

1021
00:37:06,390 --> 00:37:13,558
the client had admin so again it thanks

1022
00:37:10,040 --> 00:37:16,259
thank you so if this was a jump box or a

1023
00:37:13,559 --> 00:37:17,520
sentinel box or anything in a in a

1024
00:37:16,260 --> 00:37:20,400
critical infrastructure and I'm sure

1025
00:37:17,520 --> 00:37:22,500
many of you either use SSH or RDP for

1026
00:37:20,400 --> 00:37:25,589
this than any client that would connect

1027
00:37:22,500 --> 00:37:27,210
there it would be fully exploited so

1028
00:37:25,589 --> 00:37:29,640
we've gotten a lot of information here

1029
00:37:27,210 --> 00:37:32,309
from both our pen testers and at scale

1030
00:37:29,640 --> 00:37:34,770
the question is is how can we iterate

1031
00:37:32,309 --> 00:37:37,200
the platform to remove more of this from

1032
00:37:34,770 --> 00:37:39,089
the battlefield so to speak so our first

1033
00:37:37,200 --> 00:37:40,828
approach on things we've been doing

1034
00:37:39,089 --> 00:37:43,020
recently is killing more and more bugs

1035
00:37:40,829 --> 00:37:45,690
at the compiler level so two great

1036
00:37:43,020 --> 00:37:47,790
examples of this are in it all so in it

1037
00:37:45,690 --> 00:37:49,710
all automatically initializes local

1038
00:37:47,790 --> 00:37:52,020
arrays scalars or structures to zero

1039
00:37:49,710 --> 00:37:53,940
which prevents basic information leaks

1040
00:37:52,020 --> 00:37:55,410
which are actually a pretty systemic

1041
00:37:53,940 --> 00:37:56,410
issue traditionally in the Windows

1042
00:37:55,410 --> 00:37:57,940
kernel and

1043
00:37:56,410 --> 00:38:00,339
you've been able to eliminate lots of

1044
00:37:57,940 --> 00:38:02,080
those so some great work there from nsrc

1045
00:38:00,340 --> 00:38:03,940
and other folks who worked on that it's

1046
00:38:02,080 --> 00:38:05,920
now shipped in the latest windows and

1047
00:38:03,940 --> 00:38:08,950
we're following that up with an initial

1048
00:38:05,920 --> 00:38:11,440
mitigation that targets what we call a

1049
00:38:08,950 --> 00:38:13,839
type confusion bug so illegitimate

1050
00:38:11,440 --> 00:38:16,990
castings are a real systemic problem

1051
00:38:13,840 --> 00:38:19,600
again pretty big rancor on the root

1052
00:38:16,990 --> 00:38:21,729
cause around nsrc issues and so we built

1053
00:38:19,600 --> 00:38:23,740
a medication called cass guard which

1054
00:38:21,730 --> 00:38:25,840
looks for static cast some objects and

1055
00:38:23,740 --> 00:38:28,120
prevents illegal down cast which are

1056
00:38:25,840 --> 00:38:30,430
pretty systemic in what we see are on

1057
00:38:28,120 --> 00:38:32,170
type confusion issues this code is

1058
00:38:30,430 --> 00:38:34,509
feature complete and we plan on shipping

1059
00:38:32,170 --> 00:38:36,280
it in a future version of Windows if you

1060
00:38:34,510 --> 00:38:37,870
want a really detailed explanation you

1061
00:38:36,280 --> 00:38:41,560
can see some of the microsoft talks from

1062
00:38:37,870 --> 00:38:44,440
the recent ccp pecan conference so cass

1063
00:38:41,560 --> 00:38:47,410
card in a nutshell essentially generates

1064
00:38:44,440 --> 00:38:49,570
a bitmap that looks for downcast that

1065
00:38:47,410 --> 00:38:51,339
would be out of nominal range you can

1066
00:38:49,570 --> 00:38:53,500
see some of the basic assembly here a

1067
00:38:51,340 --> 00:38:55,450
lot of this is heavily perf optimized

1068
00:38:53,500 --> 00:38:57,550
depending on the scenario but here's a

1069
00:38:55,450 --> 00:38:59,230
basic example in this case we're taking

1070
00:38:57,550 --> 00:39:02,200
a void function pointer and we're

1071
00:38:59,230 --> 00:39:04,630
casting it to our cast here that has a

1072
00:39:02,200 --> 00:39:06,939
foo public function and a bar private

1073
00:39:04,630 --> 00:39:09,070
variable depending on the attackers

1074
00:39:06,940 --> 00:39:11,920
control that void pointer they would now

1075
00:39:09,070 --> 00:39:13,600
be able to point memory in without cast

1076
00:39:11,920 --> 00:39:15,910
guard into a place that could be

1077
00:39:13,600 --> 00:39:18,069
converted into code execution with cast

1078
00:39:15,910 --> 00:39:22,060
guard that actually can generate an

1079
00:39:18,070 --> 00:39:23,500
immediate runtime error path mitigations

1080
00:39:22,060 --> 00:39:25,930
are another place in which we're seeing

1081
00:39:23,500 --> 00:39:27,640
some systemic issues and I wanted to

1082
00:39:25,930 --> 00:39:30,509
give you a good example of how we're

1083
00:39:27,640 --> 00:39:33,250
addressing that in real time so about

1084
00:39:30,510 --> 00:39:34,750
1/3 of all access control and half of

1085
00:39:33,250 --> 00:39:37,180
all race conditions found in the last

1086
00:39:34,750 --> 00:39:39,580
six months are related to illegal use of

1087
00:39:37,180 --> 00:39:41,890
path and what you can see is about in

1088
00:39:39,580 --> 00:39:44,259
2015 to about six months ago

1089
00:39:41,890 --> 00:39:45,850
access control vulnerabilities were just

1090
00:39:44,260 --> 00:39:49,060
a tiny part of the things we had to

1091
00:39:45,850 --> 00:39:51,339
address and just recently in the last

1092
00:39:49,060 --> 00:39:53,680
six months you can see from that read

1093
00:39:51,340 --> 00:39:55,270
there that access control is approaching

1094
00:39:53,680 --> 00:39:57,700
about half of the issues we're seeing

1095
00:39:55,270 --> 00:39:59,080
from nsrc so this is a great example of

1096
00:39:57,700 --> 00:40:03,009
where we want to take intelligence and

1097
00:39:59,080 --> 00:40:05,080
create some platform mitigations

1098
00:40:03,010 --> 00:40:07,450
obviously developers are having a hard

1099
00:40:05,080 --> 00:40:08,740
time addressing this as point fixes so

1100
00:40:07,450 --> 00:40:09,460
we think that's a perfect candidate for

1101
00:40:08,740 --> 00:40:11,709
platform

1102
00:40:09,460 --> 00:40:13,869
fix's so let's talk really quickly about

1103
00:40:11,710 --> 00:40:15,730
where this is coming from so path

1104
00:40:13,869 --> 00:40:17,380
redirection attacks and time of check

1105
00:40:15,730 --> 00:40:20,650
time of use have been around for some

1106
00:40:17,380 --> 00:40:22,210
time but James Forshaw of GPZ actually

1107
00:40:20,650 --> 00:40:24,010
did some great work documenting how

1108
00:40:22,210 --> 00:40:26,080
those can be used and produced some tool

1109
00:40:24,010 --> 00:40:28,060
sets so there's four different blogs

1110
00:40:26,080 --> 00:40:30,069
here that really contributed to the

1111
00:40:28,060 --> 00:40:30,849
community understanding of these types

1112
00:40:30,070 --> 00:40:33,790
of issues

1113
00:40:30,849 --> 00:40:35,440
more recently sandbox escaper has taken

1114
00:40:33,790 --> 00:40:38,680
very similar approaches and found even

1115
00:40:35,440 --> 00:40:41,560
more bugs in other system services this

1116
00:40:38,680 --> 00:40:43,660
class of issue really comes from time of

1117
00:40:41,560 --> 00:40:45,099
check time of use so validating a file

1118
00:40:43,660 --> 00:40:47,170
and then using it again without

1119
00:40:45,099 --> 00:40:48,670
revalidating it without understanding of

1120
00:40:47,170 --> 00:40:51,339
the attacker has full control of it

1121
00:40:48,670 --> 00:40:53,200
after that point in time and this is

1122
00:40:51,339 --> 00:40:55,119
mostly targeted at high privileges

1123
00:40:53,200 --> 00:40:58,180
services which will allow what we call a

1124
00:40:55,119 --> 00:41:01,540
local privilege escalation so walk you

1125
00:40:58,180 --> 00:41:03,490
through a canonical case of this so in

1126
00:41:01,540 --> 00:41:05,500
this particular case Malory makes a call

1127
00:41:03,490 --> 00:41:08,580
to an IPC service that's running at

1128
00:41:05,500 --> 00:41:11,040
system perhaps Mallory is running as at

1129
00:41:08,580 --> 00:41:14,020
standard user level and wants to achieve

1130
00:41:11,040 --> 00:41:16,270
full local privilege escalation

1131
00:41:14,020 --> 00:41:19,000
so that service would impersonate or

1132
00:41:16,270 --> 00:41:20,710
switch to a context of Mallory to do an

1133
00:41:19,000 --> 00:41:21,670
operation it wouldn't be running a

1134
00:41:20,710 --> 00:41:23,500
system it would be running in the

1135
00:41:21,670 --> 00:41:28,170
credentials of Mallory maybe write a

1136
00:41:23,500 --> 00:41:31,869
file the surface closes that handle and

1137
00:41:28,170 --> 00:41:33,339
then Mallory races to replace it maybe

1138
00:41:31,869 --> 00:41:37,060
using an op block or some other

1139
00:41:33,339 --> 00:41:40,000
concurrent a signaling approach and then

1140
00:41:37,060 --> 00:41:43,060
when the service reverts the system that

1141
00:41:40,000 --> 00:41:48,070
file is deleted so this is a really good

1142
00:41:43,060 --> 00:41:49,990
example of how a privilege escalation

1143
00:41:48,070 --> 00:41:52,330
based on path works and practice now the

1144
00:41:49,990 --> 00:41:53,229
question is how do we mitigate that so

1145
00:41:52,330 --> 00:41:54,970
we've actually got three different

1146
00:41:53,230 --> 00:41:56,920
mitigations that we'll be shipping in a

1147
00:41:54,970 --> 00:41:59,140
future version of Windows the first is

1148
00:41:56,920 --> 00:42:00,640
our hard link mitigation that's going to

1149
00:41:59,140 --> 00:42:03,400
require a write permission to a link to

1150
00:42:00,640 --> 00:42:04,868
destination before creation it's already

1151
00:42:03,400 --> 00:42:07,270
out there and windows insider preview

1152
00:42:04,869 --> 00:42:08,920
and it's bouncy eligible which is I'm

1153
00:42:07,270 --> 00:42:10,180
here to talk to you about so if you want

1154
00:42:08,920 --> 00:42:11,890
to take a look and find some issues in

1155
00:42:10,180 --> 00:42:13,779
that we'd appreciate it or if you want

1156
00:42:11,890 --> 00:42:16,118
to tell us it's working well that would

1157
00:42:13,780 --> 00:42:18,670
be great too we also have a junction

1158
00:42:16,119 --> 00:42:21,099
mitigation so newly created junctions

1159
00:42:18,670 --> 00:42:23,480
gain a marker the web or essentially

1160
00:42:21,099 --> 00:42:25,790
markup medium il this will allow serve

1161
00:42:23,480 --> 00:42:27,950
owners to disambiguate where a file came

1162
00:42:25,790 --> 00:42:31,509
from without running in a particular

1163
00:42:27,950 --> 00:42:33,620
impersonation context and so we'll be

1164
00:42:31,510 --> 00:42:35,750
weaving that through Windows on a future

1165
00:42:33,620 --> 00:42:38,330
version and then finally we're making a

1166
00:42:35,750 --> 00:42:40,730
change to the way system temp is handled

1167
00:42:38,330 --> 00:42:42,799
so today's system temps value is world

1168
00:42:40,730 --> 00:42:46,490
writable and we'll be making a change

1169
00:42:42,800 --> 00:42:48,230
there for a new Akal path so that's

1170
00:42:46,490 --> 00:42:49,819
great this is a good example of where

1171
00:42:48,230 --> 00:42:51,560
we're taking our best information from

1172
00:42:49,820 --> 00:42:53,180
our own internal pen testing the

1173
00:42:51,560 --> 00:42:55,190
question is is how effective are we

1174
00:42:53,180 --> 00:42:58,009
being at this and this is always a

1175
00:42:55,190 --> 00:42:59,990
really complicated question to answer so

1176
00:42:58,010 --> 00:43:01,070
being able to say how many bugs we

1177
00:42:59,990 --> 00:43:03,709
should have found or could have found

1178
00:43:01,070 --> 00:43:05,690
based on our resourcing is a difficult

1179
00:43:03,710 --> 00:43:07,310
question to answer so a lot of our focus

1180
00:43:05,690 --> 00:43:09,200
is on making sure that we're getting our

1181
00:43:07,310 --> 00:43:11,000
pen testers and our developers as

1182
00:43:09,200 --> 00:43:13,160
effective as possible and as efficient

1183
00:43:11,000 --> 00:43:15,710
as possible and one of our key metrics

1184
00:43:13,160 --> 00:43:17,390
for that is our fixed rates so you can

1185
00:43:15,710 --> 00:43:19,520
look back in 2018

1186
00:43:17,390 --> 00:43:21,529
just the year and a half ago our fixed

1187
00:43:19,520 --> 00:43:23,390
rate was at a pretty miserable 38

1188
00:43:21,530 --> 00:43:26,960
percent so that means if all the bugs we

1189
00:43:23,390 --> 00:43:29,120
found static analysis fuzzing reports

1190
00:43:26,960 --> 00:43:30,890
you name it only about 38% of those were

1191
00:43:29,120 --> 00:43:33,170
fixed and there's a bunch of reasons why

1192
00:43:30,890 --> 00:43:34,940
maybe didn't have the right detail a lot

1193
00:43:33,170 --> 00:43:37,040
of times fuzzers are non deterministic

1194
00:43:34,940 --> 00:43:39,890
so repro an issue is difficult for a

1195
00:43:37,040 --> 00:43:41,060
busy developer static analysis is noisy

1196
00:43:39,890 --> 00:43:43,129
you name it

1197
00:43:41,060 --> 00:43:44,600
so with investments in better tools and

1198
00:43:43,130 --> 00:43:46,880
a lot of things i showed you today

1199
00:43:44,600 --> 00:43:49,850
our fixed rate is actually skyrocketed

1200
00:43:46,880 --> 00:43:51,770
to in 2019 ninety-eight percent of all

1201
00:43:49,850 --> 00:43:56,470
bugs security bugs followed in Windows

1202
00:43:51,770 --> 00:43:59,180
were actually fixed so in conclusion

1203
00:43:56,470 --> 00:44:01,370
we're really evolving our practices

1204
00:43:59,180 --> 00:44:03,109
constantly to provide the most secure

1205
00:44:01,370 --> 00:44:06,290
platform we're not just taking the

1206
00:44:03,110 --> 00:44:08,000
template of STL from 2004 we're taking

1207
00:44:06,290 --> 00:44:09,980
the best of that information as well as

1208
00:44:08,000 --> 00:44:11,990
the best of open source and what we can

1209
00:44:09,980 --> 00:44:14,690
learn from the community to continue to

1210
00:44:11,990 --> 00:44:16,339
involve the OS security team is not the

1211
00:44:14,690 --> 00:44:18,320
only team responsible for security in

1212
00:44:16,340 --> 00:44:20,870
Windows we want to scale out to that

1213
00:44:18,320 --> 00:44:22,910
developer army and convert them from

1214
00:44:20,870 --> 00:44:24,890
folks that we see as generating bugs to

1215
00:44:22,910 --> 00:44:26,750
folks as we see as partners and securing

1216
00:44:24,890 --> 00:44:28,609
the operating system we're constantly

1217
00:44:26,750 --> 00:44:31,280
looking to improve our security research

1218
00:44:28,610 --> 00:44:33,020
how we measure it where we focus it what

1219
00:44:31,280 --> 00:44:35,180
our tool sets is our goal is to be most

1220
00:44:33,020 --> 00:44:36,300
more efficient and then finally we want

1221
00:44:35,180 --> 00:44:37,950
to take the best

1222
00:44:36,300 --> 00:44:40,950
information we have on the trends we

1223
00:44:37,950 --> 00:44:42,870
have to continue to make durable

1224
00:44:40,950 --> 00:44:44,220
platform improvements I've showed you a

1225
00:44:42,870 --> 00:44:46,620
couple of examples of where that's

1226
00:44:44,220 --> 00:44:48,240
happening within the compiler that's

1227
00:44:46,620 --> 00:44:49,710
happening in places like hyper-v or

1228
00:44:48,240 --> 00:44:51,779
we're experimenting with components

1229
00:44:49,710 --> 00:44:52,950
written in more safe languages and of

1230
00:44:51,780 --> 00:44:54,270
course some of the things like path

1231
00:44:52,950 --> 00:44:56,430
length mitigations are where we're

1232
00:44:54,270 --> 00:44:58,980
learning from the community I'm getting

1233
00:44:56,430 --> 00:45:00,930
better and now what's that I wanted to

1234
00:44:58,980 --> 00:45:03,930
close with we're hiring so if you're

1235
00:45:00,930 --> 00:45:05,490
interested in doing similar work come

1236
00:45:03,930 --> 00:45:06,299
find myself or anybody else from

1237
00:45:05,490 --> 00:45:08,459
Microsoft

1238
00:45:06,300 --> 00:45:11,420
with that thank you very much Tel Aviv

1239
00:45:08,460 --> 00:45:11,420
and I'll see you soon

