1
00:00:00,030 --> 00:00:03,539
I already have on stage with me

2
00:00:01,530 --> 00:00:06,960
Alexandra couch Alaska senior software

3
00:00:03,540 --> 00:00:09,960
engineer at uipath

4
00:00:06,960 --> 00:00:11,519
so his he has a very varied background

5
00:00:09,960 --> 00:00:14,400
and I know that many of you who have

6
00:00:11,519 --> 00:00:16,859
been waiting for this sock so I without

7
00:00:14,400 --> 00:00:20,010
further ado let's talk about fuzzing the

8
00:00:16,859 --> 00:00:24,810
sack for fun and profit give a big

9
00:00:20,010 --> 00:00:26,550
welcome to Alex thank you everyone and

10
00:00:24,810 --> 00:00:28,890
welcome to fuzz this tag for fun and

11
00:00:26,550 --> 00:00:32,308
profit I know it's the second day it's

12
00:00:28,890 --> 00:00:34,440
late you've made it so far keep going so

13
00:00:32,308 --> 00:00:36,089
first of all we've seen Jeff's

14
00:00:34,440 --> 00:00:38,820
presentation early today

15
00:00:36,090 --> 00:00:43,020
can any way anyone notice where I stole

16
00:00:38,820 --> 00:00:45,059
the title team from anyone okay

17
00:00:43,020 --> 00:00:47,160
so maybe it's reading an old article

18
00:00:45,059 --> 00:00:49,649
called smashing the stacks for fun and

19
00:00:47,160 --> 00:00:52,110
profit so that's the inspiration for the

20
00:00:49,649 --> 00:00:53,910
name it's really cool article it's

21
00:00:52,110 --> 00:00:56,219
basically about buffer overflows so if

22
00:00:53,910 --> 00:01:00,209
anybody's interested shout out to that

23
00:00:56,219 --> 00:01:02,969
give it a try so Who am I I'm a security

24
00:01:00,210 --> 00:01:05,339
enthusiastic open source support and

25
00:01:02,969 --> 00:01:07,580
contributor and currently a senior

26
00:01:05,339 --> 00:01:10,229
software engineer at uipath and

27
00:01:07,580 --> 00:01:15,960
hopefully some of you will recognize the

28
00:01:10,229 --> 00:01:20,670
last reference there exactly my contact

29
00:01:15,960 --> 00:01:23,970
if anyone is interested now all right I

30
00:01:20,670 --> 00:01:26,430
know it's late for most of you it might

31
00:01:23,970 --> 00:01:28,950
might be hungry already but let's do

32
00:01:26,430 --> 00:01:30,780
this and now after that we can go back

33
00:01:28,950 --> 00:01:34,979
to drinking beers and killing our brain

34
00:01:30,780 --> 00:01:37,439
cells so after this talk I want each and

35
00:01:34,979 --> 00:01:37,798
every one of you to learn three simple

36
00:01:37,439 --> 00:01:40,710
things

37
00:01:37,799 --> 00:01:42,930
what is fuzzing why is it important and

38
00:01:40,710 --> 00:01:44,789
how it works and for that you'll ever

39
00:01:42,930 --> 00:01:47,729
learn the types of fuzzing and the state

40
00:01:44,790 --> 00:01:49,200
of the art the Letran limitations on the

41
00:01:47,729 --> 00:01:50,610
state of the art and how we can overcome

42
00:01:49,200 --> 00:01:53,759
this with song with the new tool you're

43
00:01:50,610 --> 00:01:58,409
going to introduce today so what is

44
00:01:53,759 --> 00:01:59,759
fuzzing from Wikipedia fuzzing is an

45
00:01:58,409 --> 00:02:01,469
automated software testing technique

46
00:01:59,759 --> 00:02:05,100
that involves providing invalid or

47
00:02:01,469 --> 00:02:07,469
unexpected data to an input to a

48
00:02:05,100 --> 00:02:09,690
computer program the program is then

49
00:02:07,469 --> 00:02:11,910
monitored for its behavior and we can

50
00:02:09,690 --> 00:02:12,840
see if anything like crashes memory

51
00:02:11,910 --> 00:02:14,849
release or

52
00:02:12,840 --> 00:02:15,870
exceptions happen from that said input

53
00:02:14,849 --> 00:02:19,140
okay

54
00:02:15,870 --> 00:02:20,730
all maybe it's a bit too formal is

55
00:02:19,140 --> 00:02:25,018
trying and visualize this so basically

56
00:02:20,730 --> 00:02:26,790
what happens you generate an input which

57
00:02:25,019 --> 00:02:29,160
you feed it to the target program and

58
00:02:26,790 --> 00:02:31,739
then you monitor the behavior this goes

59
00:02:29,160 --> 00:02:33,090
on basically in an infinite loop until

60
00:02:31,739 --> 00:02:35,310
you did take some interesting behavior

61
00:02:33,090 --> 00:02:36,870
and that behavior you can probably

62
00:02:35,310 --> 00:02:38,730
generate a crash or a security exploit

63
00:02:36,870 --> 00:02:40,680
and you can either use it for a

64
00:02:38,730 --> 00:02:42,359
defensive purpose to patch it or for an

65
00:02:40,680 --> 00:02:44,040
attack purpose to see what you can get

66
00:02:42,360 --> 00:02:47,569
out of it so that's basically fighting

67
00:02:44,040 --> 00:02:51,510
in a nutshell from a high point of view

68
00:02:47,569 --> 00:02:53,220
now before you the number one program

69
00:02:51,510 --> 00:02:55,440
excuse for legitimately slacking off

70
00:02:53,220 --> 00:02:59,549
with compiling nowadays people can use

71
00:02:55,440 --> 00:03:00,810
fuzzing for the same excuse and I really

72
00:02:59,549 --> 00:03:02,640
encourage it's actually do your fuzzing

73
00:03:00,810 --> 00:03:05,190
setup you can just run all of your

74
00:03:02,640 --> 00:03:07,708
course let it files for 24 hours or even

75
00:03:05,190 --> 00:03:12,200
more and just have a valid reason to

76
00:03:07,709 --> 00:03:16,260
just slack off now why is this important

77
00:03:12,200 --> 00:03:18,238
well first of all fixing a bug at the

78
00:03:16,260 --> 00:03:19,888
deployment stage is more it can be more

79
00:03:18,239 --> 00:03:22,920
than a hundred times more costly than

80
00:03:19,889 --> 00:03:25,709
fixing it at the development stage also

81
00:03:22,920 --> 00:03:28,170
just to give you an idea over 70% of the

82
00:03:25,709 --> 00:03:30,709
security vulnerabilities patched by

83
00:03:28,170 --> 00:03:33,420
Microsoft in 2006 were found by fuzzing

84
00:03:30,709 --> 00:03:34,950
then also there's a thing called SDL the

85
00:03:33,420 --> 00:03:37,768
Microsoft security development life

86
00:03:34,950 --> 00:03:40,530
cycle where the and this is basically

87
00:03:37,769 --> 00:03:43,139
the security Bible for the MS teams and

88
00:03:40,530 --> 00:03:48,389
this states that fuzzing is a mandatory

89
00:03:43,139 --> 00:03:49,709
step in their life cycle how it works so

90
00:03:48,389 --> 00:03:52,410
let's get a bit into the actual

91
00:03:49,709 --> 00:03:53,790
technical details you may assume

92
00:03:52,410 --> 00:03:56,849
something black magic and it just

93
00:03:53,790 --> 00:03:59,280
somehow generates the magic into it

94
00:03:56,849 --> 00:04:03,000
without any knowledge whatsoever how

95
00:03:59,280 --> 00:04:05,790
actually it's all quite easy to

96
00:04:03,000 --> 00:04:07,799
understand that let's get into it first

97
00:04:05,790 --> 00:04:09,060
of all let's define the types of fuzzing

98
00:04:07,799 --> 00:04:11,819
so you can define it into three

99
00:04:09,060 --> 00:04:14,310
categories based on the following how is

100
00:04:11,819 --> 00:04:17,190
how it generates the inputs that it

101
00:04:14,310 --> 00:04:19,079
actually gives to the target so based on

102
00:04:17,190 --> 00:04:21,478
listen can be either generation based or

103
00:04:19,079 --> 00:04:23,010
mutation base generation based means

104
00:04:21,478 --> 00:04:23,640
that you generate the inputs from

105
00:04:23,010 --> 00:04:26,490
scratch

106
00:04:23,640 --> 00:04:28,770
while enemy mutation based buzzer

107
00:04:26,490 --> 00:04:30,840
he start with the pull of inputs also

108
00:04:28,770 --> 00:04:32,669
called seeds and you mutate them each

109
00:04:30,840 --> 00:04:34,520
time with each round to generate new

110
00:04:32,669 --> 00:04:37,469
seeds for the target

111
00:04:34,520 --> 00:04:40,380
the second category can be either white

112
00:04:37,470 --> 00:04:42,060
box gray box or black box I'm certain

113
00:04:40,380 --> 00:04:44,490
most of you know what the black box

114
00:04:42,060 --> 00:04:46,470
means basically have no prior knowledge

115
00:04:44,490 --> 00:04:47,880
of the target it's a complete back box

116
00:04:46,470 --> 00:04:49,830
you can just give it something and

117
00:04:47,880 --> 00:04:51,630
inputs and monitor it salt would have no

118
00:04:49,830 --> 00:04:53,310
knowledge of what's happening inside of

119
00:04:51,630 --> 00:04:55,409
it so that's the back black box approach

120
00:04:53,310 --> 00:04:57,270
on the other hand you have the white box

121
00:04:55,410 --> 00:04:59,580
you have full knowledge of it you know

122
00:04:57,270 --> 00:05:01,859
the codes and the behavior everything

123
00:04:59,580 --> 00:05:03,900
and then there's something in the middle

124
00:05:01,860 --> 00:05:05,550
called grey box you know something but

125
00:05:03,900 --> 00:05:09,810
not all of it and we will focus on this

126
00:05:05,550 --> 00:05:12,449
later on more later on and the last but

127
00:05:09,810 --> 00:05:14,789
not least category a father can be dumb

128
00:05:12,449 --> 00:05:17,190
or smart and this basically means if he

129
00:05:14,789 --> 00:05:19,590
takes into account the structure of the

130
00:05:17,190 --> 00:05:21,090
program input so if it takes into

131
00:05:19,590 --> 00:05:21,750
account the grammar of the inputs it's a

132
00:05:21,090 --> 00:05:24,030
smart fuzzer

133
00:05:21,750 --> 00:05:26,159
if it takes not nothing into account and

134
00:05:24,030 --> 00:05:29,369
it just for example Randleman sleeps

135
00:05:26,159 --> 00:05:31,229
bytes it's a dumb father now the current

136
00:05:29,370 --> 00:05:32,880
state of the art can be categorized as

137
00:05:31,229 --> 00:05:35,039
the following it's a mutation based

138
00:05:32,880 --> 00:05:37,620
buzzer with a gray box approach but it's

139
00:05:35,039 --> 00:05:39,539
also it's quite dumb it takes not none

140
00:05:37,620 --> 00:05:41,909
it's nothing in turns out about the

141
00:05:39,539 --> 00:05:43,979
structure of the inputs the current

142
00:05:41,909 --> 00:05:46,530
state of the art is the ASL father the

143
00:05:43,979 --> 00:05:47,758
american falls love hopefully most of

144
00:05:46,530 --> 00:05:50,729
you are familiar with it since you are

145
00:05:47,759 --> 00:05:55,020
deaf camp and this is how it actually

146
00:05:50,729 --> 00:05:57,180
looks in the CLI now why is it so

147
00:05:55,020 --> 00:05:59,330
successful there are a few reasons for

148
00:05:57,180 --> 00:06:01,979
it first of all it runs out of the box

149
00:05:59,330 --> 00:06:05,219
it's easy to deploy and configure and

150
00:06:01,979 --> 00:06:07,909
it's it's fast it's open source and I

151
00:06:05,219 --> 00:06:10,830
have to emphasize this it's really fast

152
00:06:07,909 --> 00:06:13,560
now let me put it like this the first

153
00:06:10,830 --> 00:06:16,080
rule of false club must be fat second

154
00:06:13,560 --> 00:06:18,210
rule of fast lock it has to be fast why

155
00:06:16,080 --> 00:06:18,840
is this so important well think of it

156
00:06:18,210 --> 00:06:21,630
like this

157
00:06:18,840 --> 00:06:25,560
if your company wants to automatically

158
00:06:21,630 --> 00:06:27,060
test software and you each time it runs

159
00:06:25,560 --> 00:06:30,419
the test it takes for example five

160
00:06:27,060 --> 00:06:32,789
minutes to actually get an interesting

161
00:06:30,419 --> 00:06:34,560
result sometimes have to run million

162
00:06:32,789 --> 00:06:36,839
thousands if not millions and millions

163
00:06:34,560 --> 00:06:38,969
of tests so that accumulates to a large

164
00:06:36,839 --> 00:06:39,210
amount of time so the faster it is the

165
00:06:38,969 --> 00:06:43,039
bet

166
00:06:39,210 --> 00:06:47,460
and less resources you use for it now

167
00:06:43,039 --> 00:06:49,050
AFL has an impressive trophy case it has

168
00:06:47,460 --> 00:06:51,870
more than hundreds of bugs if not

169
00:06:49,050 --> 00:06:53,190
thousands I couldn't actually find the

170
00:06:51,870 --> 00:06:55,410
list to summarize all of them like an

171
00:06:53,190 --> 00:06:57,539
exact number but the full list can be

172
00:06:55,410 --> 00:07:00,060
found here at this link and it includes

173
00:06:57,539 --> 00:07:03,509
tons of high-value targets such as open

174
00:07:00,060 --> 00:07:04,949
ssl open SSH anyone SSM peg and I

175
00:07:03,509 --> 00:07:07,530
encourage you to check the full list and

176
00:07:04,949 --> 00:07:11,490
see for example a software you're using

177
00:07:07,530 --> 00:07:14,820
has as well as that have been found with

178
00:07:11,490 --> 00:07:16,530
AFL now let's learn from our mistakes

179
00:07:14,820 --> 00:07:18,750
for example most of you are probably

180
00:07:16,530 --> 00:07:22,380
familiar with heartbleed one of the most

181
00:07:18,750 --> 00:07:25,289
notorious bugs that have been found in

182
00:07:22,380 --> 00:07:27,090
recent history and for example there's

183
00:07:25,289 --> 00:07:28,560
an interesting blog post about it that

184
00:07:27,090 --> 00:07:30,840
I've linked in my presentation that

185
00:07:28,560 --> 00:07:32,610
actually talks and presents heartbleed

186
00:07:30,840 --> 00:07:34,258
and how it could have been found if

187
00:07:32,610 --> 00:07:36,900
someone actually actually used the

188
00:07:34,259 --> 00:07:41,940
fuzzer on open SSL before releasing it

189
00:07:36,900 --> 00:07:44,429
and within let's say a couple of hours

190
00:07:41,940 --> 00:07:47,699
of actually configuring everything AFL

191
00:07:44,430 --> 00:07:50,340
is able to find and pinpoint the problem

192
00:07:47,699 --> 00:07:52,320
in less than 24 hours the fuzzing open

193
00:07:50,340 --> 00:07:53,909
SSL that was that would have been a huge

194
00:07:52,320 --> 00:07:56,669
win if someone actually took the time

195
00:07:53,909 --> 00:08:02,070
and first open SSL before launching it

196
00:07:56,669 --> 00:08:04,979
in that state now how is it so fast well

197
00:08:02,070 --> 00:08:07,590
it's a coverage guided fuzzing and I'll

198
00:08:04,979 --> 00:08:09,180
explain more on that in a minute and it

199
00:08:07,590 --> 00:08:12,448
uses lightweight instrumentation for

200
00:08:09,180 --> 00:08:15,270
that so this is the gray box I was

201
00:08:12,449 --> 00:08:16,889
talking about earlier so you might or

202
00:08:15,270 --> 00:08:19,740
might not have access the full program

203
00:08:16,889 --> 00:08:20,460
but you obviously have the binary to

204
00:08:19,740 --> 00:08:23,400
file it right

205
00:08:20,460 --> 00:08:25,349
so what ASL does it has lightweight

206
00:08:23,400 --> 00:08:28,710
instrumentation to the binary and such

207
00:08:25,349 --> 00:08:32,010
that it gathers code coverage from each

208
00:08:28,710 --> 00:08:33,870
execution now let's see how the coverage

209
00:08:32,010 --> 00:08:35,549
measurement actually works what's the

210
00:08:33,870 --> 00:08:37,589
magic behind it so imagine when you have

211
00:08:35,549 --> 00:08:40,500
an is when you have a when you need

212
00:08:37,589 --> 00:08:42,779
branches right for each if you basically

213
00:08:40,500 --> 00:08:46,400
create the code branch in your execution

214
00:08:42,779 --> 00:08:49,620
path and sequential leaves and so on

215
00:08:46,400 --> 00:08:51,870
basically each each of these branching

216
00:08:49,620 --> 00:08:56,060
represents a part in your execution

217
00:08:51,870 --> 00:08:59,100
but ASL does for each of these if some

218
00:08:56,060 --> 00:09:01,020
points of branching introduces a

219
00:08:59,100 --> 00:09:03,840
lightweight instrumentation which can

220
00:09:01,020 --> 00:09:05,730
actually be presented in these three

221
00:09:03,840 --> 00:09:07,230
simple lines of code will not go into

222
00:09:05,730 --> 00:09:08,880
further details about this but this is

223
00:09:07,230 --> 00:09:10,680
all the light of instrumentation it does

224
00:09:08,880 --> 00:09:12,510
and based on this it can actually

225
00:09:10,680 --> 00:09:14,540
measure each time you hit a new

226
00:09:12,510 --> 00:09:17,430
execution part in your execution and

227
00:09:14,540 --> 00:09:19,530
that's quite important because you want

228
00:09:17,430 --> 00:09:21,120
to be able to measure the paths the

229
00:09:19,530 --> 00:09:25,290
inputs that are actually interesting

230
00:09:21,120 --> 00:09:27,420
based on the new path execution now

231
00:09:25,290 --> 00:09:30,150
let's look at the actual architecture of

232
00:09:27,420 --> 00:09:32,790
ASL as you can see we have the the

233
00:09:30,150 --> 00:09:35,850
initial seed corpus here the mutation

234
00:09:32,790 --> 00:09:37,260
operators which actually mutate the

235
00:09:35,850 --> 00:09:39,420
inputs over and over for each iteration

236
00:09:37,260 --> 00:09:41,880
then it feeds the input to your target

237
00:09:39,420 --> 00:09:44,069
binary which has the instrumentation

238
00:09:41,880 --> 00:09:47,300
added to it based on this

239
00:09:44,070 --> 00:09:51,380
instrumentation the fuzzer is then

240
00:09:47,300 --> 00:09:55,140
obtains code coverage and takes into a

241
00:09:51,380 --> 00:09:57,080
stylus it evaluates the inputs and then

242
00:09:55,140 --> 00:10:00,000
this goes on and on in an infinite loop

243
00:09:57,080 --> 00:10:04,170
generating more and more inputs and

244
00:10:00,000 --> 00:10:05,850
which are fitted to the fuzzy in in

245
00:10:04,170 --> 00:10:07,979
order to generate interesting behavior

246
00:10:05,850 --> 00:10:11,310
and this is how you actually find

247
00:10:07,980 --> 00:10:13,050
crashes now what are the limitations the

248
00:10:11,310 --> 00:10:16,199
shortcomings in ASL and its occurrence

249
00:10:13,050 --> 00:10:18,150
in its current state and to best show

250
00:10:16,200 --> 00:10:21,060
this we can actually take a quote from

251
00:10:18,150 --> 00:10:22,650
the actual creator of AFL and it goes

252
00:10:21,060 --> 00:10:24,869
something like this one of the most

253
00:10:22,650 --> 00:10:26,370
significant limitation and AFL files is

254
00:10:24,870 --> 00:10:28,320
that it's mutation engine is a syntax

255
00:10:26,370 --> 00:10:30,150
blind and optimized for compact data

256
00:10:28,320 --> 00:10:31,590
formats any general-purpose processors

257
00:10:30,150 --> 00:10:33,990
will have a harder time dealing with

258
00:10:31,590 --> 00:10:36,780
more verbose dialects such as SQL or

259
00:10:33,990 --> 00:10:38,280
HTTP you can improve your odds in a

260
00:10:36,780 --> 00:10:40,319
variety of ways and the results can be

261
00:10:38,280 --> 00:10:41,910
surprising good but ultimately it's

262
00:10:40,320 --> 00:10:44,220
never easy to get from set to key few

263
00:10:41,910 --> 00:10:46,620
equal bar the content like minus 1 but

264
00:10:44,220 --> 00:10:48,960
by randomly flipping bits so that's the

265
00:10:46,620 --> 00:10:51,360
major issue AFL nowadays and with most

266
00:10:48,960 --> 00:10:53,130
files editors are quite fast they're

267
00:10:51,360 --> 00:10:55,560
done they're completely unaware of the

268
00:10:53,130 --> 00:10:57,630
infrastructure and they just do more or

269
00:10:55,560 --> 00:11:02,449
less bit flipping on the inputs in order

270
00:10:57,630 --> 00:11:04,939
to generate new input seeds now how can

271
00:11:02,450 --> 00:11:07,670
how do we overcome this

272
00:11:04,940 --> 00:11:10,400
what's the solution are we introduced

273
00:11:07,670 --> 00:11:13,610
small gray box fuzzing this there's a

274
00:11:10,400 --> 00:11:16,400
new paper and told it has been published

275
00:11:13,610 --> 00:11:17,900
I encourage you to go and read the paper

276
00:11:16,400 --> 00:11:19,550
if you want on the link and also you can

277
00:11:17,900 --> 00:11:23,510
find the tool fully implemented and

278
00:11:19,550 --> 00:11:25,280
published on github so what's new what

279
00:11:23,510 --> 00:11:29,030
do we add to FL in order to make it

280
00:11:25,280 --> 00:11:31,339
better we add a virtual structure smart

281
00:11:29,030 --> 00:11:33,439
mutation operators and a validity basis

282
00:11:31,340 --> 00:11:35,840
for our schedule so let's talk about

283
00:11:33,440 --> 00:11:38,930
each of them in the virtual structure

284
00:11:35,840 --> 00:11:41,390
think of it as a tree so instead of a FL

285
00:11:38,930 --> 00:11:43,370
just operating on a bit level for

286
00:11:41,390 --> 00:11:45,620
mutating the seeds now we operate on a

287
00:11:43,370 --> 00:11:50,030
chunk level in such a way that we can

288
00:11:45,620 --> 00:11:52,340
presume validity of the input seeds the

289
00:11:50,030 --> 00:11:53,689
second addition are the small mutation

290
00:11:52,340 --> 00:11:55,610
operator so instead of just doing random

291
00:11:53,690 --> 00:11:59,120
bit flips we now operate on the chunk

292
00:11:55,610 --> 00:12:00,980
level of the input seeds this again

293
00:11:59,120 --> 00:12:03,890
maintains validity and that adds a lot

294
00:12:00,980 --> 00:12:07,010
more flexibility in what we can generate

295
00:12:03,890 --> 00:12:10,370
and last but not least is the power base

296
00:12:07,010 --> 00:12:12,350
schedule on based on the validity so how

297
00:12:10,370 --> 00:12:14,840
does the FL smart architecture schema

298
00:12:12,350 --> 00:12:17,420
look like as you can see probably on the

299
00:12:14,840 --> 00:12:19,430
left side we can recognize recognize the

300
00:12:17,420 --> 00:12:22,760
older schema right here basically the

301
00:12:19,430 --> 00:12:24,920
the infinite loop with the seed

302
00:12:22,760 --> 00:12:28,100
generation mutation and feedback loop

303
00:12:24,920 --> 00:12:31,510
but now we also add the structure

304
00:12:28,100 --> 00:12:34,730
validity into the equation

305
00:12:31,510 --> 00:12:37,220
let's presenter a little bit the virtual

306
00:12:34,730 --> 00:12:39,710
structure so in order for the new tool

307
00:12:37,220 --> 00:12:40,910
to work what the user has to do you

308
00:12:39,710 --> 00:12:44,240
actually have to be fine

309
00:12:40,910 --> 00:12:49,310
manually a virtual structure in the form

310
00:12:44,240 --> 00:12:51,290
of an XML file this can take from tens

311
00:12:49,310 --> 00:12:53,900
of minutes or 3040 minutes to a couple

312
00:12:51,290 --> 00:12:55,880
of hours and this actually has a huge

313
00:12:53,900 --> 00:12:57,380
impact on the end result the more time

314
00:12:55,880 --> 00:12:59,900
it takes and the more granular you

315
00:12:57,380 --> 00:13:02,990
define your grammar the better chances

316
00:12:59,900 --> 00:13:04,819
for your configuration to find

317
00:13:02,990 --> 00:13:09,170
interesting behaviors and news new

318
00:13:04,820 --> 00:13:14,540
crashes this is the only extra overheads

319
00:13:09,170 --> 00:13:18,290
you have as opposed to FL FL which just

320
00:13:14,540 --> 00:13:18,740
runs out to the Box the second edition

321
00:13:18,290 --> 00:13:20,899
is smart

322
00:13:18,740 --> 00:13:22,640
station operators so you have smart

323
00:13:20,899 --> 00:13:24,620
addition smart deletion and smart

324
00:13:22,640 --> 00:13:28,670
splicing which operate on a chunk level

325
00:13:24,620 --> 00:13:33,140
now so let's take the smart addition as

326
00:13:28,670 --> 00:13:36,819
you can see we have two seeds s1 and s2

327
00:13:33,140 --> 00:13:39,529
and a new seed which will actually have

328
00:13:36,820 --> 00:13:41,690
constructed from the two older seeds in

329
00:13:39,529 --> 00:13:43,520
the such a way that we take valid chunks

330
00:13:41,690 --> 00:13:45,920
from each of them and you add them

331
00:13:43,520 --> 00:13:48,740
together in a way that we maintain the

332
00:13:45,920 --> 00:13:51,020
validity of the input seed so this is

333
00:13:48,740 --> 00:13:53,149
the smart addition after that we have

334
00:13:51,020 --> 00:13:56,000
the smarted deletion where we can just

335
00:13:53,149 --> 00:13:58,820
delete a chunk in the same manner based

336
00:13:56,000 --> 00:14:00,950
on validity and then the smart splicing

337
00:13:58,820 --> 00:14:03,649
where we can actually find chunks of the

338
00:14:00,950 --> 00:14:07,310
same type and replace them from one

339
00:14:03,649 --> 00:14:11,180
input seed to another now this may seem

340
00:14:07,310 --> 00:14:14,869
quite like okay trivial idea but it has

341
00:14:11,180 --> 00:14:16,939
a huge impact on the end result now last

342
00:14:14,870 --> 00:14:21,440
but not least the validity based power

343
00:14:16,940 --> 00:14:23,450
scheduler so until now how IFL works the

344
00:14:21,440 --> 00:14:25,490
validity can is basically would be a

345
00:14:23,450 --> 00:14:30,410
binary functions either valid or not

346
00:14:25,490 --> 00:14:32,360
instead we proposed a gradual validity

347
00:14:30,410 --> 00:14:35,719
function where we have a percentage on

348
00:14:32,360 --> 00:14:38,149
how valid the actual inputs it is and

349
00:14:35,720 --> 00:14:42,290
how we and how this works basically

350
00:14:38,149 --> 00:14:44,690
influence gradient descent and if the

351
00:14:42,290 --> 00:14:49,040
validity of the input seed is more than

352
00:14:44,690 --> 00:14:51,290
50% and the initial power are treated by

353
00:14:49,040 --> 00:14:53,870
FL is less than the total amount we

354
00:14:51,290 --> 00:14:59,060
double it if the validity is less than

355
00:14:53,870 --> 00:15:00,920
50% we maintain the old AFL power

356
00:14:59,060 --> 00:15:06,079
scheduler otherwise we gave it the

357
00:15:00,920 --> 00:15:09,020
maximum value now a what we obtained

358
00:15:06,079 --> 00:15:13,130
with a FL smart we have more than 40 to

359
00:15:09,020 --> 00:15:17,689
0 days attributed to this tool 22 CVS

360
00:15:13,130 --> 00:15:21,110
and Counting in high value targets one

361
00:15:17,690 --> 00:15:23,779
of them being actually being SSM peg and

362
00:15:21,110 --> 00:15:25,910
you can see here seven CVS which have

363
00:15:23,779 --> 00:15:28,430
been concurrently attributed three of

364
00:15:25,910 --> 00:15:30,680
them of high severity which are hip

365
00:15:28,430 --> 00:15:32,670
buffer overflows he buffer ovaries and

366
00:15:30,680 --> 00:15:35,430
he buffer override

367
00:15:32,670 --> 00:15:40,469
and this can lead to some potentially

368
00:15:35,430 --> 00:15:42,630
serious attacks now if you got a taste

369
00:15:40,470 --> 00:15:44,760
for fuzzing I actually encourage you to

370
00:15:42,630 --> 00:15:46,560
go to the next presentation on one of my

371
00:15:44,760 --> 00:15:47,960
informal colleagues and friends Radu and

372
00:15:46,560 --> 00:15:50,760
he will actually present the more

373
00:15:47,960 --> 00:15:53,730
hands-on approach how we can use tools

374
00:15:50,760 --> 00:15:58,830
like these for a concrete example of a

375
00:15:53,730 --> 00:16:00,360
fuzzing the test and I encourage each

376
00:15:58,830 --> 00:16:03,390
and every one of you to try if else mark

377
00:16:00,360 --> 00:16:11,160
yourself thank you

378
00:16:03,390 --> 00:16:14,160
[Applause]

379
00:16:11,160 --> 00:16:14,160
questions

380
00:16:21,070 --> 00:16:27,399
I'll get to you promise hello thank you

381
00:16:26,290 --> 00:16:32,649
for the presentation

382
00:16:27,399 --> 00:16:35,740
the my question is so your improve the

383
00:16:32,649 --> 00:16:39,420
phasing algorithm by self by working

384
00:16:35,740 --> 00:16:44,050
that chunk level not bit level and

385
00:16:39,420 --> 00:16:49,089
implement some logic in is not so random

386
00:16:44,050 --> 00:16:52,389
but how do you how can you determine if

387
00:16:49,089 --> 00:16:55,660
the chunk is valid or not how do you

388
00:16:52,389 --> 00:17:00,430
build a set of chunks of valid chunks

389
00:16:55,660 --> 00:17:02,469
okay someone has to manually look up the

390
00:17:00,430 --> 00:17:05,139
grammar and understand it you define the

391
00:17:02,470 --> 00:17:08,980
XML tree and then we use a third party

392
00:17:05,140 --> 00:17:11,559
tool called pitch which actually has has

393
00:17:08,980 --> 00:17:13,179
been inside it a tool that you can

394
00:17:11,559 --> 00:17:15,280
actually measure the validity based on

395
00:17:13,179 --> 00:17:17,740
your grammar definition this is how we

396
00:17:15,280 --> 00:17:21,010
actually determine the validity so

397
00:17:17,740 --> 00:17:24,179
basically and how big of a percentage it

398
00:17:21,010 --> 00:17:27,780
can valid validly parse of the chunk

399
00:17:24,179 --> 00:17:32,169
okay so for example if I want to test

400
00:17:27,780 --> 00:17:35,500
HTTP service I have to choose words from

401
00:17:32,169 --> 00:17:43,330
the HTTP I don't know

402
00:17:35,500 --> 00:17:45,850
header or something like that or like if

403
00:17:43,330 --> 00:17:47,379
you can parse if you for example the

404
00:17:45,850 --> 00:17:49,510
target are the headers and in can parse

405
00:17:47,380 --> 00:17:51,580
only let's say a few words or a few

406
00:17:49,510 --> 00:17:55,360
lines from it which represent 20% of the

407
00:17:51,580 --> 00:17:55,960
full chunk that then is 20% valid okay

408
00:17:55,360 --> 00:17:59,559
thank you

409
00:17:55,960 --> 00:18:02,590
Oh next question I'll pass it to the

410
00:17:59,559 --> 00:18:04,629
gentleman on yes nice presentation

411
00:18:02,590 --> 00:18:10,949
I was curious as to what the impact is

412
00:18:04,630 --> 00:18:15,150
of making the AFL smart dumb person

413
00:18:10,950 --> 00:18:18,100
running times so running times are quite

414
00:18:15,150 --> 00:18:22,260
significantly faster for example for SSM

415
00:18:18,100 --> 00:18:22,260
peg if you have how we can measure the

416
00:18:22,559 --> 00:18:26,980
how good it is basically on the number

417
00:18:24,820 --> 00:18:28,658
of paths it discovers in in a certain

418
00:18:26,980 --> 00:18:30,340
amount of time so for example for a

419
00:18:28,659 --> 00:18:33,360
certain peg which is quite a heavy-duty

420
00:18:30,340 --> 00:18:35,820
library if it has for example

421
00:18:33,360 --> 00:18:38,639
X amount of pads with AFL smart we can

422
00:18:35,820 --> 00:18:40,700
actually obtain on almost three times as

423
00:18:38,639 --> 00:18:44,729
many pads in the same amount of time

424
00:18:40,700 --> 00:18:47,119
that's gone I encourage you to read the

425
00:18:44,730 --> 00:18:49,049
paper for the actual full I was going to

426
00:18:47,119 --> 00:18:53,779
let's take a question from the other

427
00:18:49,049 --> 00:18:56,249
side we'll get you in the back as well

428
00:18:53,779 --> 00:18:59,309
yeah a nice presentation I got a

429
00:18:56,249 --> 00:19:01,110
question so do you or how much grammas

430
00:18:59,309 --> 00:19:03,899
you're supporting with the two quick

431
00:19:01,110 --> 00:19:06,689
easy easy to add a new one or it's hard

432
00:19:03,899 --> 00:19:10,350
and so right now I think they're about

433
00:19:06,690 --> 00:19:12,720
ten or so grammars for like pngs and

434
00:19:10,350 --> 00:19:15,238
whatnot the most common formats like WAV

435
00:19:12,720 --> 00:19:17,970
format so they're about ten of them

436
00:19:15,239 --> 00:19:20,159
already available on the github repo and

437
00:19:17,970 --> 00:19:22,049
then it depends on on what kind of

438
00:19:20,159 --> 00:19:23,399
grammar you want to add so if you want

439
00:19:22,049 --> 00:19:24,899
to add something quite simple it can

440
00:19:23,399 --> 00:19:27,059
take from for example a couple of hours

441
00:19:24,899 --> 00:19:29,219
if you want to add the grammar quite

442
00:19:27,059 --> 00:19:33,029
complex such as a PDF you can take maybe

443
00:19:29,220 --> 00:19:35,759
days it depends on you but the main

444
00:19:33,029 --> 00:19:37,739
advantage is that once you design and

445
00:19:35,759 --> 00:19:40,259
implement the grammar file you can use

446
00:19:37,739 --> 00:19:42,480
it any for any any files in campaign and

447
00:19:40,259 --> 00:19:44,609
you can basically anyone if someone does

448
00:19:42,480 --> 00:19:48,840
it they can share it with everyone so

449
00:19:44,609 --> 00:19:50,939
it's only on one time cost oh thank you

450
00:19:48,840 --> 00:20:00,119
I know we have a question in the back

451
00:19:50,940 --> 00:20:03,779
there hello I have a question given the

452
00:20:00,119 --> 00:20:05,459
emergency stand up sorry to interrupt

453
00:20:03,779 --> 00:20:08,700
please stand up so we can see okay thank

454
00:20:05,460 --> 00:20:10,980
you given the emergence of the dossing

455
00:20:08,700 --> 00:20:13,139
as a service and generally attacking as

456
00:20:10,980 --> 00:20:15,480
a service how much of it is would you

457
00:20:13,139 --> 00:20:19,619
say is posing as a service against

458
00:20:15,480 --> 00:20:24,389
unknown targets fighting in the service

459
00:20:19,619 --> 00:20:27,090
I'd say it's quite far in the future

460
00:20:24,389 --> 00:20:29,070
because let's say it's a bit of an art

461
00:20:27,090 --> 00:20:32,260
to actually

462
00:20:29,070 --> 00:20:34,330
each target is different and you need to

463
00:20:32,260 --> 00:20:36,220
for a lot of targets you may need to

464
00:20:34,330 --> 00:20:38,980
create additional scaffolding to

465
00:20:36,220 --> 00:20:42,310
actually help you attack specific parts

466
00:20:38,980 --> 00:20:45,790
of that target so it's not as easy as it

467
00:20:42,310 --> 00:20:48,310
sounds for suta greatest service out of

468
00:20:45,790 --> 00:20:51,129
it for simple things that just parse a

469
00:20:48,310 --> 00:20:52,990
specific file you like pngs

470
00:20:51,130 --> 00:20:54,580
yeah you could have it as a surface but

471
00:20:52,990 --> 00:20:57,610
if you want to file the protocol that

472
00:20:54,580 --> 00:20:59,679
has the complex grammar it can be quite

473
00:20:57,610 --> 00:21:01,479
difficult and it's hard to provide the

474
00:20:59,680 --> 00:21:04,960
service out of the box for it you have

475
00:21:01,480 --> 00:21:08,980
to to tailor it to your specific needs

476
00:21:04,960 --> 00:21:13,330
and would it be able to tailor a fuzzer

477
00:21:08,980 --> 00:21:15,880
to attack a certain protocol but we did

478
00:21:13,330 --> 00:21:18,669
that would that further be portable to

479
00:21:15,880 --> 00:21:22,090
various types of applications using that

480
00:21:18,670 --> 00:21:24,220
protocol well yet a degree so for

481
00:21:22,090 --> 00:21:27,159
example an analogy would be let's take a

482
00:21:24,220 --> 00:21:29,080
pen testing so pen testing is a service

483
00:21:27,160 --> 00:21:31,900
you have a lot of tools that can find

484
00:21:29,080 --> 00:21:33,790
low-hanging fruits but there's no not

485
00:21:31,900 --> 00:21:35,800
one tool they can find high severity

486
00:21:33,790 --> 00:21:37,600
bugs quite easily you need the appendix

487
00:21:35,800 --> 00:21:40,210
a to go manually in there and try

488
00:21:37,600 --> 00:21:42,490
different things to find the bug so it's

489
00:21:40,210 --> 00:21:47,020
kind of the same way okay thank you oh

490
00:21:42,490 --> 00:21:50,040
do more questions who's up for it we

491
00:21:47,020 --> 00:21:50,040
have one over here

492
00:21:52,999 --> 00:21:58,940
thanks for the presentation the question

493
00:21:55,519 --> 00:22:01,700
is does FL smart support my article

494
00:21:58,940 --> 00:22:05,899
formats so if you've written the grammar

495
00:22:01,700 --> 00:22:07,489
or the XML for HTTP and you also have

496
00:22:05,899 --> 00:22:10,189
one for mime

497
00:22:07,489 --> 00:22:13,659
can you reference the mind format from

498
00:22:10,190 --> 00:22:17,779
the HTTP format so that you can generate

499
00:22:13,659 --> 00:22:20,179
test cases that have both interesting

500
00:22:17,779 --> 00:22:22,429
question not right now but that's a cool

501
00:22:20,179 --> 00:22:27,249
feature and I encourage you to create a

502
00:22:22,429 --> 00:22:30,049
br for it do we have one more question

503
00:22:27,249 --> 00:22:31,140
do we know I guess that's a wrap thank

504
00:22:30,049 --> 00:22:35,779
you so much Alex

505
00:22:31,140 --> 00:22:35,779
[Applause]

