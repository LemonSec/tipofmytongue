1
00:00:00,320 --> 00:00:04,400
so um our first presentation of the day

2
00:00:04,400 --> 00:00:06,160
will be from

3
00:00:06,160 --> 00:00:08,400
emanuel

4
00:00:08,400 --> 00:00:12,480
he has been a long time um you know

5
00:00:12,480 --> 00:00:15,360
member of the deaf camp community and i

6
00:00:15,360 --> 00:00:18,560
i it's my pleasure to introduce him and

7
00:00:18,560 --> 00:00:20,640
i'm very keen on learning from him you

8
00:00:20,640 --> 00:00:22,160
know a deep learning approach to

9
00:00:22,160 --> 00:00:24,720
phishing detection which has been top of

10
00:00:24,720 --> 00:00:27,519
mind for everyone in the past year and a

11
00:00:27,519 --> 00:00:30,080
half and will be for a long time radu

12
00:00:30,080 --> 00:00:31,760
we're really happy to have you here

13
00:00:31,760 --> 00:00:34,559
thank you for opening death camp and

14
00:00:34,559 --> 00:00:36,640
let's have an awesome presentation i'll

15
00:00:36,640 --> 00:00:39,120
be standing by for your questions so be

16
00:00:39,120 --> 00:00:41,280
sure to drop them there over to you

17
00:00:41,280 --> 00:00:42,320
radho

18
00:00:42,320 --> 00:00:44,160
thank you andra for the introduction are

19
00:00:44,160 --> 00:00:46,320
you able to hear me well

20
00:00:46,320 --> 00:00:48,800
yes you're coming through just fine

21
00:00:48,800 --> 00:00:50,480
okay thanks so

22
00:00:50,480 --> 00:00:52,960
hello everyone my name is radu i'm a

23
00:00:52,960 --> 00:00:54,559
security research engineer in the

24
00:00:54,559 --> 00:00:56,160
application and right intelligence team

25
00:00:56,160 --> 00:00:56,840
at

26
00:00:56,840 --> 00:00:59,039
keysight i would like to talk about a

27
00:00:59,039 --> 00:01:01,600
project that started as a hackathon idea

28
00:01:01,600 --> 00:01:03,600
really together with some of my

29
00:01:03,600 --> 00:01:05,680
colleagues so we wanted to enrich the

30
00:01:05,680 --> 00:01:07,680
functionality of an internal pipeline

31
00:01:07,680 --> 00:01:09,600
that delivers threat intelligence to our

32
00:01:09,600 --> 00:01:11,119
customers

33
00:01:11,119 --> 00:01:13,520
more exactly we try to find out if a

34
00:01:13,520 --> 00:01:15,280
deep neural network can discriminate

35
00:01:15,280 --> 00:01:19,439
between phishing and legitimate pages

36
00:01:20,479 --> 00:01:22,720
a few words about phishing first based

37
00:01:22,720 --> 00:01:24,640
on the interaction environment between

38
00:01:24,640 --> 00:01:26,479
an adversary and its target

39
00:01:26,479 --> 00:01:28,240
there are multiple types of phishing

40
00:01:28,240 --> 00:01:30,640
attacks for example there is the email

41
00:01:30,640 --> 00:01:33,040
phishing attacks that we all know of

42
00:01:33,040 --> 00:01:34,960
well the other where the adversary sends

43
00:01:34,960 --> 00:01:36,960
an email to its target an email designed

44
00:01:36,960 --> 00:01:38,960
to convince the target to

45
00:01:38,960 --> 00:01:41,119
access uh to access a malicious link or

46
00:01:41,119 --> 00:01:42,799
file

47
00:01:42,799 --> 00:01:44,560
the malicious link usually points to a

48
00:01:44,560 --> 00:01:46,720
phishing page designed to look like a

49
00:01:46,720 --> 00:01:48,399
legitimate page in order to increase the

50
00:01:48,399 --> 00:01:50,000
chance of the target being tricked into

51
00:01:50,000 --> 00:01:51,600
sharing its private information with the

52
00:01:51,600 --> 00:01:53,680
attacker this will be the focus of our

53
00:01:53,680 --> 00:01:55,040
talk

54
00:01:55,040 --> 00:01:56,560
there is also the matter of social

55
00:01:56,560 --> 00:01:58,320
account fishing where an attacker

56
00:01:58,320 --> 00:02:00,079
attempts to impersonate the avatar of a

57
00:02:00,079 --> 00:02:02,320
specific target in order to trick other

58
00:02:02,320 --> 00:02:04,079
people from its entourage to click on

59
00:02:04,079 --> 00:02:05,759
malicious links or actually asking for

60
00:02:05,759 --> 00:02:07,680
payment

61
00:02:07,680 --> 00:02:08,560
another

62
00:02:08,560 --> 00:02:10,160
another type of phishing attack is the

63
00:02:10,160 --> 00:02:12,400
voice fishing or wishing in this type of

64
00:02:12,400 --> 00:02:14,480
attack an adversary usually attempts to

65
00:02:14,480 --> 00:02:16,800
present itself as the target or as a

66
00:02:16,800 --> 00:02:17,760
relative

67
00:02:17,760 --> 00:02:19,920
to obtain private details from entities

68
00:02:19,920 --> 00:02:23,680
that have a contract with the target

69
00:02:23,680 --> 00:02:25,599
now back to website phishing to

70
00:02:25,599 --> 00:02:27,200
introduce the context of the project

71
00:02:27,200 --> 00:02:29,200
allow me to say a few words about rap

72
00:02:29,200 --> 00:02:31,280
sheet one of our products

73
00:02:31,280 --> 00:02:33,440
rap sheet is a system that is designed

74
00:02:33,440 --> 00:02:35,760
to autonomously collect and keep track

75
00:02:35,760 --> 00:02:37,920
of ips that are shown to be related with

76
00:02:37,920 --> 00:02:40,239
malicious activities

77
00:02:40,239 --> 00:02:41,680
this information related to the

78
00:02:41,680 --> 00:02:44,319
activities of a malicious ip

79
00:02:44,319 --> 00:02:46,480
ips is stored in documents that we call

80
00:02:46,480 --> 00:02:48,319
rap sheets one for each ip that the

81
00:02:48,319 --> 00:02:51,360
system finds rap sheets can be created

82
00:02:51,360 --> 00:02:53,680
for phishing pages as well this works

83
00:02:53,680 --> 00:02:54,720
like this

84
00:02:54,720 --> 00:02:56,800
a feature receives an url as an input

85
00:02:56,800 --> 00:02:58,800
and attempts to download the html page

86
00:02:58,800 --> 00:03:01,120
located at that url if something is

87
00:03:01,120 --> 00:03:02,879
found then a screenshot of the render

88
00:03:02,879 --> 00:03:05,840
page is taken as well

89
00:03:05,840 --> 00:03:08,159
then the html page is analyzed by a set

90
00:03:08,159 --> 00:03:10,959
of antiviruses and phishing classifiers

91
00:03:10,959 --> 00:03:13,200
the results are aggregated and a voting

92
00:03:13,200 --> 00:03:14,800
system decides if a rap sheet will be

93
00:03:14,800 --> 00:03:16,319
created

94
00:03:16,319 --> 00:03:18,239
because antivirus antiviruses often lack

95
00:03:18,239 --> 00:03:20,480
signatures for certain phishing pages we

96
00:03:20,480 --> 00:03:22,000
have developed our own phishing

97
00:03:22,000 --> 00:03:24,400
classifiers internally while trying to

98
00:03:24,400 --> 00:03:26,000
improve the predictions for such a

99
00:03:26,000 --> 00:03:28,480
classifier we often found ourselves

100
00:03:28,480 --> 00:03:30,480
looking um both at the screenshot

101
00:03:30,480 --> 00:03:32,480
features and the url

102
00:03:32,480 --> 00:03:33,920
to establish whether the domain is

103
00:03:33,920 --> 00:03:35,680
legitimate or not

104
00:03:35,680 --> 00:03:37,200
then we thought why not train a deep

105
00:03:37,200 --> 00:03:39,120
neural network on the screenshots that

106
00:03:39,120 --> 00:03:41,440
we were already collecting a network

107
00:03:41,440 --> 00:03:43,120
that would apply the same logic that is

108
00:03:43,120 --> 00:03:44,879
taking into consideration both the

109
00:03:44,879 --> 00:03:47,120
screenshot features and the url

110
00:03:47,120 --> 00:03:48,799
that way we could come up with a new

111
00:03:48,799 --> 00:03:52,159
detection in the voting system

112
00:03:52,560 --> 00:03:54,400
studying the literature we came across a

113
00:03:54,400 --> 00:03:56,159
research paper that we considered to be

114
00:03:56,159 --> 00:03:57,920
tangent to our problem

115
00:03:57,920 --> 00:04:00,319
in fact we have decided to consider this

116
00:04:00,319 --> 00:04:02,400
paper's approach as a starting point for

117
00:04:02,400 --> 00:04:06,319
our project and build upon its ideas

118
00:04:06,959 --> 00:04:09,760
the approach is well summarized in this

119
00:04:09,760 --> 00:04:11,840
picture from the paper first we start

120
00:04:11,840 --> 00:04:14,080
with a list of trusted websites the

121
00:04:14,080 --> 00:04:17,279
trust is granted by the website's domain

122
00:04:17,279 --> 00:04:18,959
then we train a neural network with the

123
00:04:18,959 --> 00:04:21,199
purpose of learning a trusted website

124
00:04:21,199 --> 00:04:23,520
identity we train such a network with

125
00:04:23,520 --> 00:04:25,199
various screenshots taken from each of

126
00:04:25,199 --> 00:04:27,120
the legitimate websites they would be

127
00:04:27,120 --> 00:04:28,960
represented by the points in the green

128
00:04:28,960 --> 00:04:31,120
center zone

129
00:04:31,120 --> 00:04:33,040
once the knowledge base is established

130
00:04:33,040 --> 00:04:35,040
pages with vis with similar visual

131
00:04:35,040 --> 00:04:36,720
appearances to the learned ones are

132
00:04:36,720 --> 00:04:39,680
considered phishing attempts

133
00:04:39,680 --> 00:04:41,280
they would be represented by the points

134
00:04:41,280 --> 00:04:43,040
in the in the red zone

135
00:04:43,040 --> 00:04:46,320
pages with different or unknown features

136
00:04:46,320 --> 00:04:48,400
are to be considered other legitimate

137
00:04:48,400 --> 00:04:50,400
pages that are not yet part of the

138
00:04:50,400 --> 00:04:52,880
trusted website zone

139
00:04:52,880 --> 00:04:54,800
one limitation of this kind of approach

140
00:04:54,800 --> 00:04:57,280
is that it might be able to detect only

141
00:04:57,280 --> 00:04:59,600
phishing pages associated with the

142
00:04:59,600 --> 00:05:01,600
websites in the trusted list

143
00:05:01,600 --> 00:05:04,479
but at the same time a large advantage

144
00:05:04,479 --> 00:05:06,880
is that new legitimate websites can be

145
00:05:06,880 --> 00:05:08,720
incorporated without too much effort

146
00:05:08,720 --> 00:05:11,360
into the existing existing model without

147
00:05:11,360 --> 00:05:15,120
changing the neural network architecture

148
00:05:15,759 --> 00:05:17,440
with this approach established it is

149
00:05:17,440 --> 00:05:19,759
time to think about producing a data set

150
00:05:19,759 --> 00:05:22,560
we have consulted alexa to 500 to decide

151
00:05:22,560 --> 00:05:25,759
upon what sites should we start with

152
00:05:25,759 --> 00:05:28,000
to obtain screenshots for legitimate and

153
00:05:28,000 --> 00:05:31,120
phishing sites we mainly had two sources

154
00:05:31,120 --> 00:05:33,280
firstly we used our own phishing sites

155
00:05:33,280 --> 00:05:34,479
collectors

156
00:05:34,479 --> 00:05:35,919
going manually through the data to

157
00:05:35,919 --> 00:05:37,039
curate it

158
00:05:37,039 --> 00:05:38,639
we have also contacted the paper's

159
00:05:38,639 --> 00:05:40,800
authors as they were willing to share

160
00:05:40,800 --> 00:05:43,120
their data set and we have used it

161
00:05:43,120 --> 00:05:45,199
to cross-reference with what we have

162
00:05:45,199 --> 00:05:46,960
since we're starters we wanted to train

163
00:05:46,960 --> 00:05:48,720
a model only with the data from our

164
00:05:48,720 --> 00:05:49,919
collectors

165
00:05:49,919 --> 00:05:51,280
let's see a couple of examples of

166
00:05:51,280 --> 00:05:54,080
phishing pages that we encounter

167
00:05:54,080 --> 00:05:56,479
in this example we have a phishing page

168
00:05:56,479 --> 00:05:57,759
for um

169
00:05:57,759 --> 00:05:59,120
for amazon

170
00:05:59,120 --> 00:06:01,520
website and and with and as we can see

171
00:06:01,520 --> 00:06:02,720
there is um

172
00:06:02,720 --> 00:06:04,560
a large degree of similarity between the

173
00:06:04,560 --> 00:06:07,600
two a bit of a small difference here

174
00:06:07,600 --> 00:06:09,360
they are quite similar

175
00:06:09,360 --> 00:06:11,600
the same can be said about this example

176
00:06:11,600 --> 00:06:13,840
a fishing page for ebay

177
00:06:13,840 --> 00:06:15,759
there are some differences but overall

178
00:06:15,759 --> 00:06:17,919
they're quite similar

179
00:06:17,919 --> 00:06:20,080
but we have also this kind of phishing

180
00:06:20,080 --> 00:06:22,000
pages in which the attacker

181
00:06:22,000 --> 00:06:23,520
would only care about using certain

182
00:06:23,520 --> 00:06:26,479
colors of or logos of the legitimate

183
00:06:26,479 --> 00:06:28,160
website hoping that it will be enough to

184
00:06:28,160 --> 00:06:30,000
treat the target

185
00:06:30,000 --> 00:06:31,440
um

186
00:06:31,440 --> 00:06:33,199
in the same manner here we have a

187
00:06:33,199 --> 00:06:36,160
phishing page for paypal the attacker

188
00:06:36,160 --> 00:06:37,680
only

189
00:06:37,680 --> 00:06:38,880
includes the

190
00:06:38,880 --> 00:06:40,720
paypal logo and a

191
00:06:40,720 --> 00:06:42,319
credential phishing form which is

192
00:06:42,319 --> 00:06:43,759
somewhat similar to the one of the

193
00:06:43,759 --> 00:06:46,479
legitimate page

194
00:06:46,479 --> 00:06:48,560
but we encountered this kind of examples

195
00:06:48,560 --> 00:06:50,160
as well in which the attacker would

196
00:06:50,160 --> 00:06:52,080
include the credential phishing form

197
00:06:52,080 --> 00:06:54,639
that is not at all present normally in

198
00:06:54,639 --> 00:06:55,599
the

199
00:06:55,599 --> 00:06:57,120
in the application

200
00:06:57,120 --> 00:06:58,880
so we can we have this kind of situation

201
00:06:58,880 --> 00:07:00,840
as well

202
00:07:00,840 --> 00:07:03,280
um to conclude uh looking at the

203
00:07:03,280 --> 00:07:04,639
screenshots we have noticed that there

204
00:07:04,639 --> 00:07:06,319
are phishing attempts that try to

205
00:07:06,319 --> 00:07:08,240
closely mimic the legitimate websites as

206
00:07:08,240 --> 00:07:10,720
expected but there are also phishing

207
00:07:10,720 --> 00:07:12,160
sites that

208
00:07:12,160 --> 00:07:14,400
just have some basic identifiers such as

209
00:07:14,400 --> 00:07:16,880
logos and standard text or colors that

210
00:07:16,880 --> 00:07:18,800
you would usually expect to find on the

211
00:07:18,800 --> 00:07:21,440
corresponding legitimate website

212
00:07:21,440 --> 00:07:23,759
there are even cases of attackers adding

213
00:07:23,759 --> 00:07:25,280
fishing forms to applications that do

214
00:07:25,280 --> 00:07:27,440
not have such a feature

215
00:07:27,440 --> 00:07:31,280
as this kind of variation was not enough

216
00:07:31,280 --> 00:07:32,960
the variation is increased by different

217
00:07:32,960 --> 00:07:34,720
website languages and changes in the

218
00:07:34,720 --> 00:07:36,800
page design that need to be taken into

219
00:07:36,800 --> 00:07:38,560
consideration as well when trying to

220
00:07:38,560 --> 00:07:40,080
build

221
00:07:40,080 --> 00:07:41,919
such a model

222
00:07:41,919 --> 00:07:43,759
based on these observations we decided

223
00:07:43,759 --> 00:07:45,280
that in order to learn a website

224
00:07:45,280 --> 00:07:47,680
identity because that is our purpose we

225
00:07:47,680 --> 00:07:49,759
should include phishing samples in the

226
00:07:49,759 --> 00:07:52,080
training step as well such that

227
00:07:52,080 --> 00:07:53,759
the features that are characteristic to

228
00:07:53,759 --> 00:07:55,759
a website can be picked up both from

229
00:07:55,759 --> 00:07:58,160
legitimate and from phishing sites and

230
00:07:58,160 --> 00:07:59,680
this can be regarded as a form of

231
00:07:59,680 --> 00:08:01,919
augmentation

232
00:08:01,919 --> 00:08:04,160
after we collected collected the data we

233
00:08:04,160 --> 00:08:06,479
have split it into three categories

234
00:08:06,479 --> 00:08:08,960
namely training validation and test

235
00:08:08,960 --> 00:08:10,560
the training data set contains the

236
00:08:10,560 --> 00:08:13,280
screenshots from 55 trusted websites

237
00:08:13,280 --> 00:08:14,960
with both legitimate and phishing

238
00:08:14,960 --> 00:08:18,400
samples amounting to 2380 screenshots

239
00:08:18,400 --> 00:08:20,160
to help the model generalize a little

240
00:08:20,160 --> 00:08:22,240
better we have included four forms of

241
00:08:22,240 --> 00:08:24,000
augmentation applied to the training

242
00:08:24,000 --> 00:08:24,960
data

243
00:08:24,960 --> 00:08:26,879
firstly we applied brightness control to

244
00:08:26,879 --> 00:08:28,639
mimic certain pop-ups that show up

245
00:08:28,639 --> 00:08:31,360
sometimes when reaching a website

246
00:08:31,360 --> 00:08:33,679
secondly when we apply the random

247
00:08:33,679 --> 00:08:35,679
cropping to force the model to pick up

248
00:08:35,679 --> 00:08:37,440
certain relevant features and color

249
00:08:37,440 --> 00:08:38,799
palettes

250
00:08:38,799 --> 00:08:40,958
also as i mentioned mentioned earlier we

251
00:08:40,958 --> 00:08:43,039
decided to include the screenshots of

252
00:08:43,039 --> 00:08:44,560
sites in different languages and

253
00:08:44,560 --> 00:08:46,880
phishing samples in the training step as

254
00:08:46,880 --> 00:08:48,880
well so that the model can pick up

255
00:08:48,880 --> 00:08:51,200
relevant features both from legitimate

256
00:08:51,200 --> 00:08:53,360
and from phishing sites

257
00:08:53,360 --> 00:08:55,200
the validation data set contains

258
00:08:55,200 --> 00:08:56,880
different screenshots for the same

259
00:08:56,880 --> 00:08:58,240
websites that are present in the

260
00:08:58,240 --> 00:09:00,880
training data set and the test data set

261
00:09:00,880 --> 00:09:02,959
contains two types of screenshots either

262
00:09:02,959 --> 00:09:04,720
for known sites that appear in the

263
00:09:04,720 --> 00:09:07,200
training set and for unknown sites

264
00:09:07,200 --> 00:09:09,200
and by unknown i mean sites for which

265
00:09:09,200 --> 00:09:10,720
there aren't screenshots in the training

266
00:09:10,720 --> 00:09:12,080
data set

267
00:09:12,080 --> 00:09:14,080
we added new sites because we wanted to

268
00:09:14,080 --> 00:09:16,160
see how the trend model behaves when

269
00:09:16,160 --> 00:09:18,240
facing with screenshots of sites that

270
00:09:18,240 --> 00:09:20,720
are not in the initial list

271
00:09:20,720 --> 00:09:22,880
we added the screenshots with new sites

272
00:09:22,880 --> 00:09:24,399
both for legitimate and for phishing

273
00:09:24,399 --> 00:09:26,560
pages

274
00:09:26,560 --> 00:09:28,880
as for the type of the neural network we

275
00:09:28,880 --> 00:09:30,880
have chosen a convolutional architecture

276
00:09:30,880 --> 00:09:32,800
frequently used for image classification

277
00:09:32,800 --> 00:09:33,839
tasks

278
00:09:33,839 --> 00:09:35,440
convolutional layers are nothing new

279
00:09:35,440 --> 00:09:37,519
they've been around since 89 they've

280
00:09:37,519 --> 00:09:39,279
been proposed by yan le khan which is

281
00:09:39,279 --> 00:09:41,120
now the chief ai scientist at facebook

282
00:09:41,120 --> 00:09:43,360
now meta this is a high level

283
00:09:43,360 --> 00:09:44,959
representation of how a convolutional

284
00:09:44,959 --> 00:09:48,000
neural network looks like

285
00:09:48,000 --> 00:09:50,240
we have an input image that is filtered

286
00:09:50,240 --> 00:09:52,560
with uh with which is iterated with

287
00:09:52,560 --> 00:09:54,640
filters of certain sizes

288
00:09:54,640 --> 00:09:56,560
uh convolution layers are then applied

289
00:09:56,560 --> 00:09:58,399
sequentially to smaller region of the

290
00:09:58,399 --> 00:10:00,480
input image their role is to transform

291
00:10:00,480 --> 00:10:02,640
the input volume in thinner volume with

292
00:10:02,640 --> 00:10:04,959
larger and larger depths each layer is

293
00:10:04,959 --> 00:10:06,480
responsible of learning different types

294
00:10:06,480 --> 00:10:07,760
of features

295
00:10:07,760 --> 00:10:09,600
the shallow layers that have smaller

296
00:10:09,600 --> 00:10:11,680
depths are learning features with small

297
00:10:11,680 --> 00:10:14,079
complexity such as directed edges

298
00:10:14,079 --> 00:10:15,760
while the deeper layers with thinner

299
00:10:15,760 --> 00:10:17,360
volumes are picking up more complex

300
00:10:17,360 --> 00:10:19,600
features such as shapes group of objects

301
00:10:19,600 --> 00:10:21,200
and various patterns

302
00:10:21,200 --> 00:10:23,200
this process of convolving applying

303
00:10:23,200 --> 00:10:25,760
non-linearity and pulling is repeated a

304
00:10:25,760 --> 00:10:27,920
couple of rounds until the spatial

305
00:10:27,920 --> 00:10:30,800
information is extracted from the image

306
00:10:30,800 --> 00:10:34,000
finally you get an output layer

307
00:10:34,000 --> 00:10:35,360
uh that is a

308
00:10:35,360 --> 00:10:37,440
probability over all the categories to

309
00:10:37,440 --> 00:10:39,839
be recognized the training part is

310
00:10:39,839 --> 00:10:41,680
assured by back propagating the

311
00:10:41,680 --> 00:10:44,000
classification error so when you make a

312
00:10:44,000 --> 00:10:45,839
mistake that error is back propagated

313
00:10:45,839 --> 00:10:47,920
throughout the entire network updating

314
00:10:47,920 --> 00:10:50,719
the parameters

315
00:10:51,360 --> 00:10:53,279
one disadvantage of such networks is

316
00:10:53,279 --> 00:10:55,760
that they are very data hungry they need

317
00:10:55,760 --> 00:10:57,519
to train on millions of millions of

318
00:10:57,519 --> 00:10:59,360
samples to perform well

319
00:10:59,360 --> 00:11:02,160
to overcome this a powerful technique is

320
00:11:02,160 --> 00:11:04,079
available which is called transfer

321
00:11:04,079 --> 00:11:05,040
learning

322
00:11:05,040 --> 00:11:06,720
transfer learning allows you to use a

323
00:11:06,720 --> 00:11:08,560
pre-trained network a network that was

324
00:11:08,560 --> 00:11:10,800
trained on a large volume of data for

325
00:11:10,800 --> 00:11:12,959
another somewhat similar classification

326
00:11:12,959 --> 00:11:16,480
task with a smaller amount of data

327
00:11:16,480 --> 00:11:19,200
you do that by basically keeping up

328
00:11:19,200 --> 00:11:20,959
the layer structure of the pre-trained

329
00:11:20,959 --> 00:11:23,839
model and replacing the final deployers

330
00:11:23,839 --> 00:11:25,519
then you must fine-tune the new

331
00:11:25,519 --> 00:11:27,920
architecture to the data available on

332
00:11:27,920 --> 00:11:29,760
the task that interests you

333
00:11:29,760 --> 00:11:32,079
the fine tuning part refers to blocking

334
00:11:32,079 --> 00:11:33,680
the weights of certain layers so that

335
00:11:33,680 --> 00:11:35,760
the propagation won't affect them or

336
00:11:35,760 --> 00:11:37,839
adding new layers or changing the value

337
00:11:37,839 --> 00:11:41,279
of some parameters or all of the above

338
00:11:41,279 --> 00:11:43,120
for our task we took a pre-trained

339
00:11:43,120 --> 00:11:45,279
architecture removed the output layer

340
00:11:45,279 --> 00:11:47,839
and adjusted for our problem

341
00:11:47,839 --> 00:11:50,720
um we tried various pre-trained networks

342
00:11:50,720 --> 00:11:52,399
but the one that showcased better

343
00:11:52,399 --> 00:11:54,959
results with the smaller number of

344
00:11:54,959 --> 00:11:57,200
parameters was efficient net together

345
00:11:57,200 --> 00:11:59,360
with the layers that we added we had the

346
00:11:59,360 --> 00:12:01,700
total of 37 million parameters

347
00:12:01,700 --> 00:12:03,760
[Music]

348
00:12:03,760 --> 00:12:05,760
further on we took this network and

349
00:12:05,760 --> 00:12:07,440
integrated it into an architecture

350
00:12:07,440 --> 00:12:10,240
called cms network the cms network aims

351
00:12:10,240 --> 00:12:12,320
at learning how much different images

352
00:12:12,320 --> 00:12:15,040
are amongst themselves based on a

353
00:12:15,040 --> 00:12:16,639
similarity function

354
00:12:16,639 --> 00:12:18,800
in a cms architecture the input is

355
00:12:18,800 --> 00:12:21,360
represented by a triplet of images the

356
00:12:21,360 --> 00:12:22,880
convention

357
00:12:22,880 --> 00:12:24,560
the convention is that the first image

358
00:12:24,560 --> 00:12:27,040
is called an anchor

359
00:12:27,040 --> 00:12:29,200
this is the baseline image the second

360
00:12:29,200 --> 00:12:31,519
image is called the positive sample and

361
00:12:31,519 --> 00:12:33,600
it represents an image similar to the

362
00:12:33,600 --> 00:12:35,519
anchor

363
00:12:35,519 --> 00:12:37,760
in our case an image of the same website

364
00:12:37,760 --> 00:12:39,360
the third image is called the negative

365
00:12:39,360 --> 00:12:40,800
sample and it should be an image

366
00:12:40,800 --> 00:12:42,720
different than the anchor in our case

367
00:12:42,720 --> 00:12:44,399
the negative sample will be the image of

368
00:12:44,399 --> 00:12:46,399
a website different from bank of america

369
00:12:46,399 --> 00:12:47,920
from which we have chosen the anchor and

370
00:12:47,920 --> 00:12:50,320
positive sample we feed this triplet

371
00:12:50,320 --> 00:12:51,760
into the model based on transfer

372
00:12:51,760 --> 00:12:53,600
learning that we talked about earlier

373
00:12:53,600 --> 00:12:55,120
which we can perceive as an embedding

374
00:12:55,120 --> 00:12:56,959
model since the model will produce

375
00:12:56,959 --> 00:12:59,120
embedding arrays representation of the

376
00:12:59,120 --> 00:13:01,360
website in the embedding space

377
00:13:01,360 --> 00:13:03,200
the learning objective is then to have a

378
00:13:03,200 --> 00:13:05,760
model that outputs similar embeddings

379
00:13:05,760 --> 00:13:07,680
for the anchor and the positive sample

380
00:13:07,680 --> 00:13:09,839
so for image of the same website and

381
00:13:09,839 --> 00:13:12,079
respectively very different embeddings

382
00:13:12,079 --> 00:13:13,519
for the samples of the different

383
00:13:13,519 --> 00:13:16,079
websites to put it differently the model

384
00:13:16,079 --> 00:13:17,680
weights have to be adjusted during

385
00:13:17,680 --> 00:13:20,079
learning such that the distance from the

386
00:13:20,079 --> 00:13:22,399
anchor to the positive sample is small

387
00:13:22,399 --> 00:13:24,320
while the difference from the anchor to

388
00:13:24,320 --> 00:13:27,200
the negative sample is large

389
00:13:27,200 --> 00:13:28,880
to satisfy this condition we have to

390
00:13:28,880 --> 00:13:30,480
define a loss function in the following

391
00:13:30,480 --> 00:13:31,440
manner

392
00:13:31,440 --> 00:13:33,440
giving a triplet of anchor positive and

393
00:13:33,440 --> 00:13:35,680
negative samples

394
00:13:35,680 --> 00:13:38,160
we define d of mp as the euclidean

395
00:13:38,160 --> 00:13:39,839
distance between the bendings of the

396
00:13:39,839 --> 00:13:41,839
anchor and the positive sample in the

397
00:13:41,839 --> 00:13:44,320
same manner we define d of n n as the

398
00:13:44,320 --> 00:13:46,079
euclidean distance between the beddings

399
00:13:46,079 --> 00:13:49,199
of the anchor and the negative sample

400
00:13:49,199 --> 00:13:51,279
a good embedding model would make d of

401
00:13:51,279 --> 00:13:54,320
mp smaller than d of a and n

402
00:13:54,320 --> 00:13:56,560
but in practice we add an alpha

403
00:13:56,560 --> 00:13:59,040
parameter margin to push the distance

404
00:13:59,040 --> 00:14:00,560
further apart from each other and make

405
00:14:00,560 --> 00:14:02,800
the model more robust

406
00:14:02,800 --> 00:14:04,639
as the loss function should return a

407
00:14:04,639 --> 00:14:07,279
value larger or equal to zero we define

408
00:14:07,279 --> 00:14:09,519
the loss as the maximum between the

409
00:14:09,519 --> 00:14:11,120
difference of the distances plus the

410
00:14:11,120 --> 00:14:13,760
margin and zero this means that if the

411
00:14:13,760 --> 00:14:15,360
difference is negative then the loss

412
00:14:15,360 --> 00:14:17,440
will be zero

413
00:14:17,440 --> 00:14:19,680
a negative difference means that d of

414
00:14:19,680 --> 00:14:22,399
amp is smaller than d of n n and this is

415
00:14:22,399 --> 00:14:23,920
exactly what we want

416
00:14:23,920 --> 00:14:26,000
the goal here is to penalize the model

417
00:14:26,000 --> 00:14:28,320
only when the difference is very large

418
00:14:28,320 --> 00:14:30,880
when the negative sample is closer

419
00:14:30,880 --> 00:14:34,959
to the anchor than the positive sample

420
00:14:36,480 --> 00:14:37,839
now that we have finished with the

421
00:14:37,839 --> 00:14:40,639
theory let's see how the training went

422
00:14:40,639 --> 00:14:43,360
we used tensorflow gpu python library to

423
00:14:43,360 --> 00:14:44,560
code this up

424
00:14:44,560 --> 00:14:46,079
the model was trained on a machine with

425
00:14:46,079 --> 00:14:47,839
an nvidia rtx

426
00:14:47,839 --> 00:14:51,279
1319 gpu and 64 gigabytes of ram the

427
00:14:51,279 --> 00:14:53,279
triplets are selected at random from the

428
00:14:53,279 --> 00:14:55,279
existing data respecting the anchor

429
00:14:55,279 --> 00:14:57,519
positive and negative convention and

430
00:14:57,519 --> 00:14:59,360
then they are fed to the model

431
00:14:59,360 --> 00:15:01,360
the screenshots of the unknown websites

432
00:15:01,360 --> 00:15:03,199
in the training set are only used as

433
00:15:03,199 --> 00:15:06,079
negative samples

434
00:15:06,240 --> 00:15:07,279
we can

435
00:15:07,279 --> 00:15:08,800
illustrate the model's training

436
00:15:08,800 --> 00:15:10,880
improvement over time by doing a disney

437
00:15:10,880 --> 00:15:13,600
plot disney stands for t distributed

438
00:15:13,600 --> 00:15:15,760
stochastic neighboring bearing a fancy

439
00:15:15,760 --> 00:15:17,600
name for an algorithm that basically

440
00:15:17,600 --> 00:15:19,600
reduces a high dimensional vector a

441
00:15:19,600 --> 00:15:21,680
representation of the website to a

442
00:15:21,680 --> 00:15:23,519
two-dimensional vector through a series

443
00:15:23,519 --> 00:15:25,279
of repeated projections so that we can

444
00:15:25,279 --> 00:15:27,279
plot it in the 2d space

445
00:15:27,279 --> 00:15:29,040
this will help us visualize how the

446
00:15:29,040 --> 00:15:30,959
embeddings of different websites are

447
00:15:30,959 --> 00:15:32,800
distributed in the embedding space as

448
00:15:32,800 --> 00:15:35,440
the training progresses

449
00:15:35,440 --> 00:15:37,519
initially without any training the

450
00:15:37,519 --> 00:15:39,040
embeddings are distributed quite

451
00:15:39,040 --> 00:15:41,120
randomly across the embedding space but

452
00:15:41,120 --> 00:15:43,120
after a few iterations we can see how

453
00:15:43,120 --> 00:15:45,440
multiple clusters emerge and as the

454
00:15:45,440 --> 00:15:47,759
training progresses the clusters start

455
00:15:47,759 --> 00:15:50,240
to separate separate quite nicely each

456
00:15:50,240 --> 00:15:52,839
cluster representing a specific

457
00:15:52,839 --> 00:15:55,600
website a thing to note here is that the

458
00:15:55,600 --> 00:15:58,320
axis value axis values have no practical

459
00:15:58,320 --> 00:16:00,160
meaning for a disney plot this is just

460
00:16:00,160 --> 00:16:02,000
something that can help us visualize how

461
00:16:02,000 --> 00:16:05,440
the training task progresses

462
00:16:05,680 --> 00:16:07,120
after the training is complete we have

463
00:16:07,120 --> 00:16:08,639
to produce predictions for the

464
00:16:08,639 --> 00:16:10,399
validation and test samples the

465
00:16:10,399 --> 00:16:11,920
prediction is done in the following

466
00:16:11,920 --> 00:16:14,399
manner firstly we compute the embeddings

467
00:16:14,399 --> 00:16:15,920
of all the screenshots in the training

468
00:16:15,920 --> 00:16:17,199
data set

469
00:16:17,199 --> 00:16:18,880
then we fit the test image into the

470
00:16:18,880 --> 00:16:20,399
embedding model

471
00:16:20,399 --> 00:16:22,959
to obtain its embedding then we have to

472
00:16:22,959 --> 00:16:24,720
find the minimum distance

473
00:16:24,720 --> 00:16:26,079
um

474
00:16:26,079 --> 00:16:27,839
between the embeddings of the test image

475
00:16:27,839 --> 00:16:30,160
and the bendings of the training images

476
00:16:30,160 --> 00:16:31,920
the matched site will be the site of the

477
00:16:31,920 --> 00:16:34,480
closest embeddings

478
00:16:34,480 --> 00:16:36,639
this approach worked quite well we

479
00:16:36,639 --> 00:16:39,120
obtained the good preliminary results um

480
00:16:39,120 --> 00:16:42,720
from 40 uh of 489 screenshots of

481
00:16:42,720 --> 00:16:45,120
phishing pages targeting all the 55

482
00:16:45,120 --> 00:16:46,880
websites in the

483
00:16:46,880 --> 00:16:48,560
uh in the initial list in the training

484
00:16:48,560 --> 00:16:49,440
set

485
00:16:49,440 --> 00:16:50,560
in the test

486
00:16:50,560 --> 00:16:52,639
in the in the training set we correctly

487
00:16:52,639 --> 00:16:55,360
in the test set we correctly labeled 390

488
00:16:55,360 --> 00:16:56,800
screenshots of their corresponding

489
00:16:56,800 --> 00:16:58,800
legitimate pages

490
00:16:58,800 --> 00:17:00,160
so um

491
00:17:00,160 --> 00:17:03,600
an accuracy of approximate um

492
00:17:03,600 --> 00:17:06,319
of a of 80 percent

493
00:17:06,319 --> 00:17:08,400
uh the miss label is mislabeling is

494
00:17:08,400 --> 00:17:10,079
mainly caused by the small numbers of

495
00:17:10,079 --> 00:17:13,359
phishing samples for specific websites

496
00:17:13,359 --> 00:17:15,359
um

497
00:17:15,359 --> 00:17:17,760
if if you recall we also included

498
00:17:17,760 --> 00:17:20,160
a number of uh legitimate

499
00:17:20,160 --> 00:17:22,480
of of screenshots for legitimate pages

500
00:17:22,480 --> 00:17:24,000
that were not present in the trusted

501
00:17:24,000 --> 00:17:24,880
list

502
00:17:24,880 --> 00:17:27,640
and from those we correctly labeled

503
00:17:27,640 --> 00:17:30,840
154 screenshots as unknown legitimate

504
00:17:30,840 --> 00:17:33,280
websites in this case the mislabeling is

505
00:17:33,280 --> 00:17:35,919
attributed to some unknown sites being

506
00:17:35,919 --> 00:17:37,440
somewhat similar to the sites in the

507
00:17:37,440 --> 00:17:39,200
trusted list

508
00:17:39,200 --> 00:17:41,600
now let's look how

509
00:17:41,600 --> 00:17:44,160
the model performs against

510
00:17:44,160 --> 00:17:46,320
some

511
00:17:46,320 --> 00:17:49,840
some some screenshots

512
00:17:51,200 --> 00:17:52,480
okay so

513
00:17:52,480 --> 00:17:54,080
um

514
00:17:54,080 --> 00:17:55,919
after you train a model

515
00:17:55,919 --> 00:17:56,720
then

516
00:17:56,720 --> 00:17:59,600
you can load the weights um in order to

517
00:17:59,600 --> 00:18:02,880
um uh to have to make up predictions so

518
00:18:02,880 --> 00:18:06,400
um here in the initial step we are

519
00:18:06,400 --> 00:18:08,720
loading the model that we trained and we

520
00:18:08,720 --> 00:18:11,919
read the embeddings for the training um

521
00:18:11,919 --> 00:18:13,679
for the training samples which are we

522
00:18:13,679 --> 00:18:15,280
are using um

523
00:18:15,280 --> 00:18:17,200
um further on

524
00:18:17,200 --> 00:18:19,520
here we have two functions the first uh

525
00:18:19,520 --> 00:18:21,919
the first one is used to plot the test

526
00:18:21,919 --> 00:18:24,320
image against the most uh similar image

527
00:18:24,320 --> 00:18:26,480
that is found in the most similar

528
00:18:26,480 --> 00:18:28,480
embedding that is found in the training

529
00:18:28,480 --> 00:18:30,000
data set

530
00:18:30,000 --> 00:18:32,080
and here

531
00:18:32,080 --> 00:18:33,440
we are

532
00:18:33,440 --> 00:18:35,120
here we have a function that

533
00:18:35,120 --> 00:18:37,280
sends the embedding of

534
00:18:37,280 --> 00:18:39,120
the test image

535
00:18:39,120 --> 00:18:40,480
to the embedding model creates an

536
00:18:40,480 --> 00:18:42,799
embedding and compares it against all

537
00:18:42,799 --> 00:18:44,640
the embeddings of

538
00:18:44,640 --> 00:18:45,760
the

539
00:18:45,760 --> 00:18:48,000
websites in the training data set

540
00:18:48,000 --> 00:18:50,400
in the first example um

541
00:18:50,400 --> 00:18:52,559
we chose um

542
00:18:52,559 --> 00:18:54,960
on an easier test sample we have a

543
00:18:54,960 --> 00:18:57,600
fishing of adobe

544
00:18:57,600 --> 00:18:59,039
adobe page

545
00:18:59,039 --> 00:19:00,480
in this case the classification was

546
00:19:00,480 --> 00:19:02,640
correct as you can see the predicate

547
00:19:02,640 --> 00:19:03,760
predicted

548
00:19:03,760 --> 00:19:05,200
the model correctly predicted the

549
00:19:05,200 --> 00:19:07,520
phishing page as pertaining to adobe and

550
00:19:07,520 --> 00:19:10,559
the most similar image found was this

551
00:19:10,559 --> 00:19:12,559
which is a um

552
00:19:12,559 --> 00:19:13,840
which is a

553
00:19:13,840 --> 00:19:16,160
phishing sample using the training set

554
00:19:16,160 --> 00:19:17,520
as you can see they are quite similar

555
00:19:17,520 --> 00:19:18,880
although there are a few differences but

556
00:19:18,880 --> 00:19:22,000
the model correctly determined that

557
00:19:22,000 --> 00:19:23,600
this is the most similar image and

558
00:19:23,600 --> 00:19:25,520
correctly assigned it as being a fishing

559
00:19:25,520 --> 00:19:27,200
to the adobe

560
00:19:27,200 --> 00:19:29,520
in the second example we have something

561
00:19:29,520 --> 00:19:31,760
a little different we have a test image

562
00:19:31,760 --> 00:19:33,120
that is a

563
00:19:33,120 --> 00:19:35,679
phishing page of paypal written in

564
00:19:35,679 --> 00:19:37,200
german

565
00:19:37,200 --> 00:19:38,720
we did not have such samples in the

566
00:19:38,720 --> 00:19:41,440
training set and uh even

567
00:19:41,440 --> 00:19:43,600
even though we did not have the model

568
00:19:43,600 --> 00:19:45,440
still managed to correctly predict it as

569
00:19:45,440 --> 00:19:47,679
being a phishing page of paypal

570
00:19:47,679 --> 00:19:49,919
and as we can see the most similar image

571
00:19:49,919 --> 00:19:52,080
found was

572
00:19:52,080 --> 00:19:55,600
a legitimate image of the paypal website

573
00:19:55,600 --> 00:19:57,840
in the third example we have something

574
00:19:57,840 --> 00:19:59,440
even more different we have a phishing

575
00:19:59,440 --> 00:20:02,240
page for netflix

576
00:20:02,240 --> 00:20:03,679
um

577
00:20:03,679 --> 00:20:05,919
but here we have a different language

578
00:20:05,919 --> 00:20:07,280
language and different bankrupt

579
00:20:07,280 --> 00:20:09,280
background as well so we did not have

580
00:20:09,280 --> 00:20:11,679
such this kind of images in the training

581
00:20:11,679 --> 00:20:13,679
set in this case the model again

582
00:20:13,679 --> 00:20:16,080
correctly predicted that is a

583
00:20:16,080 --> 00:20:18,480
phishing page of netflix and the more

584
00:20:18,480 --> 00:20:21,760
similar image as we can see it's um

585
00:20:21,760 --> 00:20:23,520
it's a page of um

586
00:20:23,520 --> 00:20:24,720
it's a

587
00:20:24,720 --> 00:20:26,720
legitimate page of netflix but the

588
00:20:26,720 --> 00:20:28,320
language is different and the background

589
00:20:28,320 --> 00:20:31,120
is different as well

590
00:20:31,360 --> 00:20:33,120
if you recall there are also

591
00:20:33,120 --> 00:20:35,760
cases in which the attacker would add

592
00:20:35,760 --> 00:20:37,760
a phishing form to

593
00:20:37,760 --> 00:20:39,520
applications that do not normally have

594
00:20:39,520 --> 00:20:40,640
one

595
00:20:40,640 --> 00:20:42,559
we decided to test this as well and see

596
00:20:42,559 --> 00:20:45,840
how the model performs

597
00:20:46,159 --> 00:20:48,960
this is the phishing page um and again

598
00:20:48,960 --> 00:20:50,720
the model correctly predicted it as

599
00:20:50,720 --> 00:20:53,520
being official for office excel

600
00:20:53,520 --> 00:20:55,200
and um

601
00:20:55,200 --> 00:20:56,799
we can see that

602
00:20:56,799 --> 00:20:58,799
our decision to include phishing pages

603
00:20:58,799 --> 00:21:00,559
in the training step as well to extend

604
00:21:00,559 --> 00:21:02,480
the identity website

605
00:21:02,480 --> 00:21:04,320
really helped because the most similar

606
00:21:04,320 --> 00:21:06,480
image that was found

607
00:21:06,480 --> 00:21:10,480
is a fishing fishing page

608
00:21:10,480 --> 00:21:11,600
in the fifth

609
00:21:11,600 --> 00:21:14,159
fifth example we have we will see if the

610
00:21:14,159 --> 00:21:16,720
model can distinguish between legitimate

611
00:21:16,720 --> 00:21:18,640
pages and the phishing from the

612
00:21:18,640 --> 00:21:21,280
trustings from the trusted list initial

613
00:21:21,280 --> 00:21:22,159
list

614
00:21:22,159 --> 00:21:24,080
in this case we have a test image which

615
00:21:24,080 --> 00:21:25,679
is a legitimate screenshot of

616
00:21:25,679 --> 00:21:27,679
geeks4geeks

617
00:21:27,679 --> 00:21:29,760
if we ask the model about it he will say

618
00:21:29,760 --> 00:21:31,919
that is on an unknown site which is

619
00:21:31,919 --> 00:21:32,880
correct

620
00:21:32,880 --> 00:21:34,559
and if we

621
00:21:34,559 --> 00:21:36,799
and the most similar image that is found

622
00:21:36,799 --> 00:21:39,840
is a page of a different website but as

623
00:21:39,840 --> 00:21:41,600
we can see there are some similarities

624
00:21:41,600 --> 00:21:43,280
in how the

625
00:21:43,280 --> 00:21:44,559
um

626
00:21:44,559 --> 00:21:46,080
certain objects in the page are

627
00:21:46,080 --> 00:21:48,400
organized another interesting example

628
00:21:48,400 --> 00:21:51,039
for me was this um screenshot of a

629
00:21:51,039 --> 00:21:52,960
legitimate page again the model

630
00:21:52,960 --> 00:21:55,360
correctly correctly predicted as being a

631
00:21:55,360 --> 00:21:58,960
unknown site but as we can see um even

632
00:21:58,960 --> 00:21:59,919
though the

633
00:21:59,919 --> 00:22:01,440
website is different there are some

634
00:22:01,440 --> 00:22:04,000
similarities in how the object objects

635
00:22:04,000 --> 00:22:07,120
are distributed across uh the website

636
00:22:07,120 --> 00:22:09,760
so um again uh the modli correctly

637
00:22:09,760 --> 00:22:13,840
predicted uh what was going on here

638
00:22:15,200 --> 00:22:17,440
okay

639
00:22:17,440 --> 00:22:20,080
now we have to ask ourselves of course

640
00:22:20,080 --> 00:22:22,880
as security researchers if we can bypass

641
00:22:22,880 --> 00:22:24,840
this model

642
00:22:24,840 --> 00:22:26,480
um

643
00:22:26,480 --> 00:22:27,280
um

644
00:22:27,280 --> 00:22:29,760
for example let's uh think about a model

645
00:22:29,760 --> 00:22:32,720
designed to detect spam emails

646
00:22:32,720 --> 00:22:35,600
usually these models are built uh based

647
00:22:35,600 --> 00:22:38,400
on some keywords in the indicative of or

648
00:22:38,400 --> 00:22:40,799
of spam or non-spam

649
00:22:40,799 --> 00:22:43,039
these keywords are given certain weights

650
00:22:43,039 --> 00:22:45,440
during training and the resulted model

651
00:22:45,440 --> 00:22:47,360
computes a metric for the likeness of an

652
00:22:47,360 --> 00:22:49,200
email being spun

653
00:22:49,200 --> 00:22:51,120
but the spawn motors knowing this

654
00:22:51,120 --> 00:22:52,159
they've started to introduce

655
00:22:52,159 --> 00:22:54,400
misspellings intentionally to certain

656
00:22:54,400 --> 00:22:56,480
words in the email this is the reason

657
00:22:56,480 --> 00:22:59,120
why sometimes spam is written like this

658
00:22:59,120 --> 00:23:01,280
and it's a good way of bypassing such a

659
00:23:01,280 --> 00:23:03,039
detection every stick

660
00:23:03,039 --> 00:23:05,440
and similarly in our situation one

661
00:23:05,440 --> 00:23:08,000
approach is to bypass the mod one

662
00:23:08,000 --> 00:23:09,919
approach to bypass the model is to come

663
00:23:09,919 --> 00:23:10,720
up with

664
00:23:10,720 --> 00:23:12,799
images that visually resemble the

665
00:23:12,799 --> 00:23:14,880
screenshots of legitimate

666
00:23:14,880 --> 00:23:17,360
website but they have some imperceptible

667
00:23:17,360 --> 00:23:20,480
differences such as some added noise or

668
00:23:20,480 --> 00:23:22,640
maybe some small offsets in the position

669
00:23:22,640 --> 00:23:24,799
of certain websites in certain objects

670
00:23:24,799 --> 00:23:26,480
in the website

671
00:23:26,480 --> 00:23:28,720
but this topic of adversarial machine

672
00:23:28,720 --> 00:23:31,120
learning is for another presentation

673
00:23:31,120 --> 00:23:33,200
uh this was my presentation i hope that

674
00:23:33,200 --> 00:23:35,679
you enjoy it thank you very much for uh

675
00:23:35,679 --> 00:23:37,360
your attention

676
00:23:37,360 --> 00:23:38,960
thank you so much

677
00:23:38,960 --> 00:23:41,520
please don't go anywhere this was really

678
00:23:41,520 --> 00:23:43,360
exciting and i think that it is

679
00:23:43,360 --> 00:23:45,120
definitely in thank you for ending this

680
00:23:45,120 --> 00:23:46,720
with

681
00:23:46,720 --> 00:23:49,600
one of the cutest things ever um this

682
00:23:49,600 --> 00:23:52,159
was a very insightful uh and detailed

683
00:23:52,159 --> 00:23:55,039
presentation so thank you for walking us

684
00:23:55,039 --> 00:23:58,159
through your entire research which i bet

685
00:23:58,159 --> 00:24:00,240
there you took a lot of effort and

686
00:24:00,240 --> 00:24:01,279
energy

687
00:24:01,279 --> 00:24:02,240
so

688
00:24:02,240 --> 00:24:04,080
i have just a couple of questions for

689
00:24:04,080 --> 00:24:07,039
you so we can um you know understand

690
00:24:07,039 --> 00:24:08,480
your experience with the community as

691
00:24:08,480 --> 00:24:10,559
well and kind of you know how this

692
00:24:10,559 --> 00:24:13,440
became a key topic of interest for you

693
00:24:13,440 --> 00:24:15,360
so what was the trigger for this

694
00:24:15,360 --> 00:24:17,279
particular piece of research what led

695
00:24:17,279 --> 00:24:20,320
you to devote you know so much time and

696
00:24:20,320 --> 00:24:24,480
and effort uh into this particular topic

697
00:24:24,480 --> 00:24:27,360
um thank you for the question as i've

698
00:24:27,360 --> 00:24:29,360
mentioned at the beginning

699
00:24:29,360 --> 00:24:32,400
this kind of started as a project for um

700
00:24:32,400 --> 00:24:34,880
for hackathon we noticed that

701
00:24:34,880 --> 00:24:37,120
we have something in our pipeline some

702
00:24:37,120 --> 00:24:39,440
kind of information that we pulled

703
00:24:39,440 --> 00:24:41,279
that wasn't used

704
00:24:41,279 --> 00:24:42,720
and

705
00:24:42,720 --> 00:24:44,159
we saw that

706
00:24:44,159 --> 00:24:46,320
there is this repeated the action that

707
00:24:46,320 --> 00:24:48,960
we do we were looking at the url we were

708
00:24:48,960 --> 00:24:50,640
looking at the screenshots to determine

709
00:24:50,640 --> 00:24:53,120
if something is phishing or not and um

710
00:24:53,120 --> 00:24:54,240
we

711
00:24:54,240 --> 00:24:56,559
wanted to see if um

712
00:24:56,559 --> 00:24:57,840
if um

713
00:24:57,840 --> 00:25:01,039
such an approach is

714
00:25:01,039 --> 00:25:03,440
could lead to good results and also i

715
00:25:03,440 --> 00:25:06,320
was trying to get acquainted with

716
00:25:06,320 --> 00:25:07,120
this

717
00:25:07,120 --> 00:25:08,880
this field of machine learning and deep

718
00:25:08,880 --> 00:25:10,720
learning in particular

719
00:25:10,720 --> 00:25:12,840
which i think

720
00:25:12,840 --> 00:25:17,039
um can is a is a help is a tool that can

721
00:25:17,039 --> 00:25:19,360
help you in certain situations

722
00:25:19,360 --> 00:25:21,039
definitely and we definitely need to

723
00:25:21,039 --> 00:25:23,520
scale the impact the positive impact of

724
00:25:23,520 --> 00:25:25,279
technologies like the one that you just

725
00:25:25,279 --> 00:25:28,240
talked about the entire mechanism behind

726
00:25:28,240 --> 00:25:30,240
detecting fishing at scale simply

727
00:25:30,240 --> 00:25:33,360
because we see it we see it generally

728
00:25:33,360 --> 00:25:35,440
not just globally in english but now we

729
00:25:35,440 --> 00:25:37,360
see it a lot happening in romanian as

730
00:25:37,360 --> 00:25:40,559
well uh they've seen an uptick in

731
00:25:40,559 --> 00:25:43,440
in phishing attempts as a user uh and

732
00:25:43,440 --> 00:25:45,200
obviously reporting them but i always

733
00:25:45,200 --> 00:25:47,279
check them i run them through virustotal

734
00:25:47,279 --> 00:25:49,120
and they're always

735
00:25:49,120 --> 00:25:50,799
you know domains they come from domains

736
00:25:50,799 --> 00:25:53,200
that have zero detection so there's

737
00:25:53,200 --> 00:25:55,440
clearly kind of a

738
00:25:55,440 --> 00:25:57,200
cat and mouse game that happens in

739
00:25:57,200 --> 00:25:59,200
security with many many things but this

740
00:25:59,200 --> 00:26:01,279
is at scale and we definitely need a lot

741
00:26:01,279 --> 00:26:03,039
more help with this

742
00:26:03,039 --> 00:26:04,640
have you um

743
00:26:04,640 --> 00:26:06,960
shared any of your research with other

744
00:26:06,960 --> 00:26:09,200
people in the community until this

745
00:26:09,200 --> 00:26:12,799
presentation i want to do what kind of

746
00:26:12,799 --> 00:26:14,720
you know what are their concerns and

747
00:26:14,720 --> 00:26:17,520
worries around fishing and how much does

748
00:26:17,520 --> 00:26:21,200
it impact their jobs from what you know

749
00:26:21,200 --> 00:26:22,480
um

750
00:26:22,480 --> 00:26:23,360
i've

751
00:26:23,360 --> 00:26:25,840
i've worked at multiple blog posts um

752
00:26:25,840 --> 00:26:28,720
during my time at keysight

753
00:26:28,720 --> 00:26:31,039
um i've been posting things about

754
00:26:31,039 --> 00:26:35,120
fuzzing about malware analysis

755
00:26:35,120 --> 00:26:37,520
this is

756
00:26:37,600 --> 00:26:39,360
this was kind of a new project for me as

757
00:26:39,360 --> 00:26:41,520
i wasn't um

758
00:26:41,520 --> 00:26:43,520
i didn't wear myself into this field of

759
00:26:43,520 --> 00:26:46,000
machine learning and deploying before

760
00:26:46,000 --> 00:26:47,120
and

761
00:26:47,120 --> 00:26:49,039
there are a lot of resources online if

762
00:26:49,039 --> 00:26:51,039
you want to learn about it and you want

763
00:26:51,039 --> 00:26:53,679
to see how it can you it can be used you

764
00:26:53,679 --> 00:26:57,600
can see presentations about

765
00:26:58,080 --> 00:26:59,600
deep learning and machine learning in

766
00:26:59,600 --> 00:27:01,919
general being used for

767
00:27:01,919 --> 00:27:03,840
malware detection and for other other

768
00:27:03,840 --> 00:27:05,039
things in

769
00:27:05,039 --> 00:27:09,279
in the security field a lot of books and

770
00:27:09,279 --> 00:27:10,400
blogs

771
00:27:10,400 --> 00:27:13,200
and videos about us and maybe if someone

772
00:27:13,200 --> 00:27:14,960
needs something specific if it's working

773
00:27:14,960 --> 00:27:17,440
out a problem and is thinking whether

774
00:27:17,440 --> 00:27:19,279
this method could be used

775
00:27:19,279 --> 00:27:21,360
uh maybe we can discuss further on on

776
00:27:21,360 --> 00:27:22,900
the specific issue um

777
00:27:22,900 --> 00:27:24,240
[Music]

778
00:27:24,240 --> 00:27:25,039
on

779
00:27:25,039 --> 00:27:26,720
the social media or

780
00:27:26,720 --> 00:27:28,960
to drive through direct contact

781
00:27:28,960 --> 00:27:30,720
i think that would be very helpful

782
00:27:30,720 --> 00:27:31,679
because

783
00:27:31,679 --> 00:27:33,600
obviously collaboration is kind of

784
00:27:33,600 --> 00:27:36,960
fundamental to everyone's work in this

785
00:27:36,960 --> 00:27:38,880
industry and beyond it as well because

786
00:27:38,880 --> 00:27:40,960
we need everyone's help and contribution

787
00:27:40,960 --> 00:27:43,600
to really make a difference um i wanted

788
00:27:43,600 --> 00:27:45,600
to ask you besides you know being an

789
00:27:45,600 --> 00:27:47,600
active member of the community i wanted

790
00:27:47,600 --> 00:27:51,200
to ask you a bit kind of what role dev

791
00:27:51,200 --> 00:27:54,880
cam played for you in your career and in

792
00:27:54,880 --> 00:27:56,960
your personal development as well

793
00:27:56,960 --> 00:27:59,039
because obviously this is not your first

794
00:27:59,039 --> 00:28:02,080
time at deaf camp so um could you tell

795
00:28:02,080 --> 00:28:03,760
us a bit about that

796
00:28:03,760 --> 00:28:05,760
um

797
00:28:05,760 --> 00:28:08,000
um i could say that

798
00:28:08,000 --> 00:28:09,520
there are a lot of

799
00:28:09,520 --> 00:28:12,559
presentations that uh were published

800
00:28:12,559 --> 00:28:15,200
that sparked my interest for a certain

801
00:28:15,200 --> 00:28:16,399
area

802
00:28:16,399 --> 00:28:18,480
and um

803
00:28:18,480 --> 00:28:20,480
seeing them and understanding what the

804
00:28:20,480 --> 00:28:22,480
researcher was confronted with when

805
00:28:22,480 --> 00:28:24,640
trying to solve a specific issue

806
00:28:24,640 --> 00:28:25,520
really

807
00:28:25,520 --> 00:28:27,679
paved the way for

808
00:28:27,679 --> 00:28:30,640
the understanding or maybe

809
00:28:30,640 --> 00:28:33,760
help me in a certain direction so

810
00:28:33,760 --> 00:28:35,520
it's a really good starting point if you

811
00:28:35,520 --> 00:28:39,039
want to understand what is

812
00:28:39,039 --> 00:28:40,880
what are the

813
00:28:40,880 --> 00:28:44,399
how can you talk tackle a specific issue

814
00:28:44,399 --> 00:28:46,320
that's really nice to hear and i think

815
00:28:46,320 --> 00:28:48,399
that it probably helps a lot of people

816
00:28:48,399 --> 00:28:50,880
who maybe don't have yet the courage to

817
00:28:50,880 --> 00:28:54,240
kind of speak uh or share stuff publicly

818
00:28:54,240 --> 00:28:56,480
about their work or their interests

819
00:28:56,480 --> 00:28:58,799
and really glad to see that there's a

820
00:28:58,799 --> 00:29:01,440
lot there's been a kind of an uptick a

821
00:29:01,440 --> 00:29:04,080
bigger number of people sharing what

822
00:29:04,080 --> 00:29:06,080
they learn and sharing their journeys

823
00:29:06,080 --> 00:29:08,080
and ensuring their personal worries or

824
00:29:08,080 --> 00:29:10,080
feelings of imposter syndrome that

825
00:29:10,080 --> 00:29:13,039
everyone gets every now and then as much

826
00:29:13,039 --> 00:29:13,840
as

827
00:29:13,840 --> 00:29:16,399
we're incredibly you know passionate and

828
00:29:16,399 --> 00:29:18,080
interested in trying to do our best day

829
00:29:18,080 --> 00:29:20,320
after day um i think this is very

830
00:29:20,320 --> 00:29:22,720
helpful for others um what was it like

831
00:29:22,720 --> 00:29:24,799
for you to kind of speak at def camp for

832
00:29:24,799 --> 00:29:27,760
the first time do you remember

833
00:29:27,760 --> 00:29:30,480
i actually wanted to um

834
00:29:30,480 --> 00:29:33,279
to talk about that um

835
00:29:33,279 --> 00:29:34,320
you know

836
00:29:34,320 --> 00:29:36,720
speaking in public doesn't come easy for

837
00:29:36,720 --> 00:29:40,159
many people certainly for me

838
00:29:40,320 --> 00:29:41,840
but

839
00:29:41,840 --> 00:29:45,918
i don't know what helps is uh that

840
00:29:46,159 --> 00:29:47,520
is this thing that

841
00:29:47,520 --> 00:29:49,279
you had access to a lot of resources

842
00:29:49,279 --> 00:29:51,440
that were open sourced and

843
00:29:51,440 --> 00:29:53,760
you used to learn and you

844
00:29:53,760 --> 00:29:55,840
you now have

845
00:29:55,840 --> 00:29:57,679
access to everything you need to learn

846
00:29:57,679 --> 00:29:59,360
mathematics to learn machine learning to

847
00:29:59,360 --> 00:30:01,360
learn security to learn penetration

848
00:30:01,360 --> 00:30:03,200
testing and renting and you can find a

849
00:30:03,200 --> 00:30:04,559
lot of them

850
00:30:04,559 --> 00:30:06,960
open source and maybe if you offer just

851
00:30:06,960 --> 00:30:08,880
a little bit of perspective

852
00:30:08,880 --> 00:30:11,520
like what you worked on what was hard

853
00:30:11,520 --> 00:30:13,760
for you and how you approached it maybe

854
00:30:13,760 --> 00:30:17,200
someone will find um

855
00:30:17,200 --> 00:30:19,200
well we'll find that more than

856
00:30:19,200 --> 00:30:22,640
interesting i mean actually helpful

857
00:30:22,640 --> 00:30:25,200
and i think it's a

858
00:30:25,200 --> 00:30:26,399
a way to

859
00:30:26,399 --> 00:30:30,240
give it give it forward so to speak

860
00:30:30,240 --> 00:30:33,440
and it's also a good training because um

861
00:30:33,440 --> 00:30:35,200
in these days you don't have it's not

862
00:30:35,200 --> 00:30:36,720
sufficient

863
00:30:36,720 --> 00:30:39,039
to you actually have to talk and to

864
00:30:39,039 --> 00:30:41,520
people and

865
00:30:41,520 --> 00:30:43,840
you you have to express your ideas

866
00:30:43,840 --> 00:30:46,480
because um

867
00:30:46,480 --> 00:30:47,440
you can

868
00:30:47,440 --> 00:30:49,039
whatever you are working at might have a

869
00:30:49,039 --> 00:30:51,200
bigger impact if you do that

870
00:30:51,200 --> 00:30:53,360
in a positive manner

871
00:30:53,360 --> 00:30:55,600
that is so true and thank you for

872
00:30:55,600 --> 00:30:57,200
mentioning all of these things and for

873
00:30:57,200 --> 00:30:58,640
sharing your experience i think that it

874
00:30:58,640 --> 00:31:00,640
matters a lot and the fact that you're

875
00:31:00,640 --> 00:31:02,640
leading by example and showing people

876
00:31:02,640 --> 00:31:04,480
that it doesn't have to be perfect for

877
00:31:04,480 --> 00:31:06,240
you to start you know getting better at

878
00:31:06,240 --> 00:31:08,480
something whether it's research whether

879
00:31:08,480 --> 00:31:10,559
it's developing your skills whether it's

880
00:31:10,559 --> 00:31:12,320
starting to talk about your work in

881
00:31:12,320 --> 00:31:15,760
public as scary and and you know uh as

882
00:31:15,760 --> 00:31:17,279
intimidating as it can be in the

883
00:31:17,279 --> 00:31:19,120
beginning you start to get more

884
00:31:19,120 --> 00:31:21,440
comfortable with it and it just starts

885
00:31:21,440 --> 00:31:22,960
to be you know the deeper you're

886
00:31:22,960 --> 00:31:25,600
connected with a community the easier it

887
00:31:25,600 --> 00:31:27,279
feels because it becomes familiar

888
00:31:27,279 --> 00:31:29,440
territory and it feels comfortable and

889
00:31:29,440 --> 00:31:31,120
you know that you're among people who

890
00:31:31,120 --> 00:31:34,000
want to learn from you uh and that

891
00:31:34,000 --> 00:31:35,840
really changes kind of the mood and

892
00:31:35,840 --> 00:31:38,159
makes you feel more comfortable so it

893
00:31:38,159 --> 00:31:40,080
was such a pleasure to to have you with

894
00:31:40,080 --> 00:31:40,799
us

895
00:31:40,799 --> 00:31:43,200
thank you for kicking off

896
00:31:43,200 --> 00:31:46,799
um def camp 2021 and i just want to

897
00:31:46,799 --> 00:31:48,399
remind everyone that you can connect

898
00:31:48,399 --> 00:31:51,440
with radu on the platform so reach out

899
00:31:51,440 --> 00:31:54,880
find him um you know read his blog posts

900
00:31:54,880 --> 00:31:57,840
and then we can all uh kind of go from

901
00:31:57,840 --> 00:31:59,600
there so thanks again rano i hope you

902
00:31:59,600 --> 00:32:01,600
enjoyed the rest of the conference

903
00:32:01,600 --> 00:32:03,039
thank you very much for your attention

904
00:32:03,039 --> 00:32:06,480
and have a nice day everyone

