1
00:00:00,299 --> 00:00:01,920
all right time is precious so we're

2
00:00:01,920 --> 00:00:04,319
going to get started welcome to best

3
00:00:04,319 --> 00:00:08,340
practices are the worst my name is Colt

4
00:00:08,340 --> 00:00:10,019
Blackmore my lovely co-host this evening

5
00:00:10,019 --> 00:00:12,179
is Garrett Hamilton by our powers

6
00:00:12,179 --> 00:00:13,799
combined we are cap no we're not we're

7
00:00:13,799 --> 00:00:16,139
not Captain Planet uh we are the

8
00:00:16,139 --> 00:00:19,020
co-founders of reach security uh I'll

9
00:00:19,020 --> 00:00:20,400
introduce Garrett

10
00:00:20,400 --> 00:00:22,140
I'll save his his little talk track for

11
00:00:22,140 --> 00:00:24,539
later uh Garrett has spent uh the bulk

12
00:00:24,539 --> 00:00:26,039
of the the past decade at Palo Alto

13
00:00:26,039 --> 00:00:28,019
networks where he did lots of crazy

14
00:00:28,019 --> 00:00:29,580
awesome things you can go and read about

15
00:00:29,580 --> 00:00:31,019
them on LinkedIn we're not going to get

16
00:00:31,019 --> 00:00:33,780
into any of that stuff today uh because

17
00:00:33,780 --> 00:00:35,640
this poor guy also got saddled while he

18
00:00:35,640 --> 00:00:37,980
was there with best practices and

19
00:00:37,980 --> 00:00:40,559
compliance programs so he has some

20
00:00:40,559 --> 00:00:42,480
pretty strong opinions on this

21
00:00:42,480 --> 00:00:45,660
particular topic I have not been nearly

22
00:00:45,660 --> 00:00:47,820
as faithful to my employers as Garrett

23
00:00:47,820 --> 00:00:49,980
has so I've been surround from Palo Alto

24
00:00:49,980 --> 00:00:52,739
to silence to proofpoint and I've also

25
00:00:52,739 --> 00:00:55,739
never been stuck with compliance from

26
00:00:55,739 --> 00:00:57,360
like a program management perspective

27
00:00:57,360 --> 00:00:59,760
but I do build things by writing code so

28
00:00:59,760 --> 00:01:02,280
I can say quite confidently that there's

29
00:01:02,280 --> 00:01:04,440
more or less nothing worse than having

30
00:01:04,440 --> 00:01:06,299
to follow some best practice or hit some

31
00:01:06,299 --> 00:01:08,460
compliance Target that makes the thing

32
00:01:08,460 --> 00:01:11,040
you're building less secure like that's

33
00:01:11,040 --> 00:01:14,159
that's pretty much uh the worst uh so

34
00:01:14,159 --> 00:01:15,960
Garrett and I now are at reached

35
00:01:15,960 --> 00:01:17,400
security uh we're not going to get into

36
00:01:17,400 --> 00:01:18,900
the ins and outs of what reach security

37
00:01:18,900 --> 00:01:21,119
does uh per se that's not the subject of

38
00:01:21,119 --> 00:01:23,040
today's topic you could kind of roughly

39
00:01:23,040 --> 00:01:24,180
think of it as the opposite of best

40
00:01:24,180 --> 00:01:26,040
practices which is not the worst

41
00:01:26,040 --> 00:01:28,140
practices that'll make more sense as we

42
00:01:28,140 --> 00:01:29,460
go you'll get at least a little bit of a

43
00:01:29,460 --> 00:01:30,720
glimpse into the kind of stuff we're

44
00:01:30,720 --> 00:01:31,860
doing

45
00:01:31,860 --> 00:01:33,960
um so best practices

46
00:01:33,960 --> 00:01:36,420
what are they like

47
00:01:36,420 --> 00:01:39,479
what do we actually mean when we say

48
00:01:39,479 --> 00:01:42,180
best practices as in are these the

49
00:01:42,180 --> 00:01:45,119
practices that are the best as in there

50
00:01:45,119 --> 00:01:46,740
are no better practices there's nothing

51
00:01:46,740 --> 00:01:48,840
else out there like this is the BL indol

52
00:01:48,840 --> 00:01:51,000
that's it I uh

53
00:01:51,000 --> 00:01:53,520
I don't think anybody actually thinks

54
00:01:53,520 --> 00:01:55,200
that that's the case

55
00:01:55,200 --> 00:01:57,060
um I think if we went around the room

56
00:01:57,060 --> 00:01:59,880
did a poll the vast majority of you

57
00:01:59,880 --> 00:02:02,100
would at least agree that best is one of

58
00:02:02,100 --> 00:02:03,299
those words that like marketing type

59
00:02:03,299 --> 00:02:04,920
people will shove into just about

60
00:02:04,920 --> 00:02:07,320
anything uh and hope that it sticks in

61
00:02:07,320 --> 00:02:08,459
people's heads and they tend to like

62
00:02:08,459 --> 00:02:10,560
associate something with the best so I

63
00:02:10,560 --> 00:02:12,780
I'm not trying to start beef like with

64
00:02:12,780 --> 00:02:15,000
any of you mayonnaise lovers for example

65
00:02:15,000 --> 00:02:18,660
but uh Best Foods is not the best food

66
00:02:18,660 --> 00:02:20,400
and best practices are not the practices

67
00:02:20,400 --> 00:02:22,800
that are the best so

68
00:02:22,800 --> 00:02:25,379
if best practices aren't the best

69
00:02:25,379 --> 00:02:28,440
practices what are they actually

70
00:02:28,440 --> 00:02:29,340
well there are a lot of different

71
00:02:29,340 --> 00:02:30,840
definitions that we can consider here so

72
00:02:30,840 --> 00:02:32,280
I'll give a simple one to to get us

73
00:02:32,280 --> 00:02:35,160
warmed up best practices are

74
00:02:35,160 --> 00:02:36,599
shortcuts

75
00:02:36,599 --> 00:02:38,400
so if love means never having to say

76
00:02:38,400 --> 00:02:40,080
you're sorry hear what best practice

77
00:02:40,080 --> 00:02:41,580
means never having to think about what

78
00:02:41,580 --> 00:02:43,080
you're doing or why you're doing it

79
00:02:43,080 --> 00:02:44,819
because somebody else already did that

80
00:02:44,819 --> 00:02:46,200
work like they flexed their big monkey

81
00:02:46,200 --> 00:02:47,640
brain they wrote some white papers they

82
00:02:47,640 --> 00:02:49,200
went out to security conferences they

83
00:02:49,200 --> 00:02:51,599
gave some talks and now nobody gets to

84
00:02:51,599 --> 00:02:54,000
question the

85
00:02:54,000 --> 00:02:57,780
the value the security expertise they

86
00:02:57,780 --> 00:02:59,519
don't get to question the wisdom of this

87
00:02:59,519 --> 00:03:00,959
thing that has now been enshrined as a

88
00:03:00,959 --> 00:03:03,000
best practice it just it is and so you

89
00:03:03,000 --> 00:03:05,580
have to do it there is an upside to this

90
00:03:05,580 --> 00:03:08,040
like if some executive comes running up

91
00:03:08,040 --> 00:03:09,060
to you huffing and puffing about

92
00:03:09,060 --> 00:03:10,920
something you're trying to do you get to

93
00:03:10,920 --> 00:03:12,360
hold up on your hand and say like sorry

94
00:03:12,360 --> 00:03:13,800
skip there's nothing we can do here it's

95
00:03:13,800 --> 00:03:15,420
the best practice we got to do it and

96
00:03:15,420 --> 00:03:18,300
and shut that down but

97
00:03:18,300 --> 00:03:20,159
um half the time maybe more often than

98
00:03:20,159 --> 00:03:22,620
not a lot of these best practices are

99
00:03:22,620 --> 00:03:24,540
net negative

100
00:03:24,540 --> 00:03:26,940
as far as your your security goes so for

101
00:03:26,940 --> 00:03:30,780
example uh passwords I refuse to believe

102
00:03:30,780 --> 00:03:31,860
that there's a single person in this

103
00:03:31,860 --> 00:03:33,780
room that's not

104
00:03:33,780 --> 00:03:35,640
annoyingly familiar with this particular

105
00:03:35,640 --> 00:03:37,920
case uh passwords passwords are super

106
00:03:37,920 --> 00:03:39,300
important and like all super important

107
00:03:39,300 --> 00:03:41,760
things uh that means they need rules and

108
00:03:41,760 --> 00:03:43,440
so a long time ago in a cubicle far far

109
00:03:43,440 --> 00:03:45,720
away the good Folks at nist the National

110
00:03:45,720 --> 00:03:48,299
Institute of Standards and Technology uh

111
00:03:48,299 --> 00:03:51,420
put together special publication 863 and

112
00:03:51,420 --> 00:03:54,299
in Sp 863 they included an appendix that

113
00:03:54,299 --> 00:03:56,040
appendix is basically a little primer on

114
00:03:56,040 --> 00:03:57,780
information Theory and password security

115
00:03:57,780 --> 00:03:59,879
what do they put in there like a lot of

116
00:03:59,879 --> 00:04:01,260
fancy stuff to try to make themselves

117
00:04:01,260 --> 00:04:03,420
look like a super smart mathematician

118
00:04:03,420 --> 00:04:04,620
type people so like they talk about

119
00:04:04,620 --> 00:04:06,239
entropy and Randomness and guessability

120
00:04:06,239 --> 00:04:08,700
of passwords and they even threw in an

121
00:04:08,700 --> 00:04:10,260
equation which is a slightly weird way

122
00:04:10,260 --> 00:04:12,780
of writing it but I'll allow it for how

123
00:04:12,780 --> 00:04:14,280
to calculate entropy this is very stupid

124
00:04:14,280 --> 00:04:15,480
by the way because if you know what a

125
00:04:15,480 --> 00:04:17,339
byte is I can explain entropy to you in

126
00:04:17,339 --> 00:04:18,899
plain English and it's very simple but

127
00:04:18,899 --> 00:04:20,279
they put all this stuff in there to try

128
00:04:20,279 --> 00:04:22,380
to look like you know security Ballers

129
00:04:22,380 --> 00:04:26,820
basically back in in 2004 and uh it went

130
00:04:26,820 --> 00:04:29,520
horribly wrong so within a year or two

131
00:04:29,520 --> 00:04:31,380
the whole world very quickly realized

132
00:04:31,380 --> 00:04:32,759
that

133
00:04:32,759 --> 00:04:34,560
it's terrible like these things are

134
00:04:34,560 --> 00:04:35,759
recommending are terrible what were

135
00:04:35,759 --> 00:04:38,880
those things well users need to

136
00:04:38,880 --> 00:04:40,800
use uppercase and lowercase letters they

137
00:04:40,800 --> 00:04:42,300
need to include special characters they

138
00:04:42,300 --> 00:04:43,979
need to include numbers and all of their

139
00:04:43,979 --> 00:04:45,600
passwords no matter what so we don't get

140
00:04:45,600 --> 00:04:46,620
to control it we're going to make you do

141
00:04:46,620 --> 00:04:48,000
all these things which of course just

142
00:04:48,000 --> 00:04:49,380
leads people to choose less secure

143
00:04:49,380 --> 00:04:51,120
passwords because that's human behavior

144
00:04:51,120 --> 00:04:52,199
you're not going to change it with rules

145
00:04:52,199 --> 00:04:54,720
and the other requirement is that they

146
00:04:54,720 --> 00:04:56,520
had to rotate passwords frequently 90

147
00:04:56,520 --> 00:04:58,500
days was not a hard requirement from

148
00:04:58,500 --> 00:05:00,419
appendix a but it's kind of what people

149
00:05:00,419 --> 00:05:02,220
settled on based on the calculations

150
00:05:02,220 --> 00:05:04,199
that were were in the primer

151
00:05:04,199 --> 00:05:07,020
some places do 90 days 30 days 180 days

152
00:05:07,020 --> 00:05:10,139
but it's still very very common so

153
00:05:10,139 --> 00:05:11,699
even though we all realized it was bad

154
00:05:11,699 --> 00:05:12,960
we're kind of stuck with it because nist

155
00:05:12,960 --> 00:05:14,340
is nist and when they say JUMP everybody

156
00:05:14,340 --> 00:05:16,500
else says how high uh you think about

157
00:05:16,500 --> 00:05:18,060
the talk that was going on in this room

158
00:05:18,060 --> 00:05:20,240
right before us it was about PCI DSS

159
00:05:20,240 --> 00:05:23,639
even though 13 14 years later nist comes

160
00:05:23,639 --> 00:05:25,500
back and says hey guys all that stuff we

161
00:05:25,500 --> 00:05:26,880
said before it was It was kind of dumb

162
00:05:26,880 --> 00:05:30,120
don't do that even now many years beyond

163
00:05:30,120 --> 00:05:31,860
that you'll still see a lot of this

164
00:05:31,860 --> 00:05:33,780
stuff pop up in things like PCI DSS

165
00:05:33,780 --> 00:05:36,060
because it was part of nist and the lag

166
00:05:36,060 --> 00:05:38,160
time for correcting all of these uh

167
00:05:38,160 --> 00:05:40,440
really silly things is quite long so

168
00:05:40,440 --> 00:05:41,940
maybe in 10 more years we'll be free of

169
00:05:41,940 --> 00:05:43,560
this garbage but for now we still have

170
00:05:43,560 --> 00:05:45,720
to live with it so what is the the

171
00:05:45,720 --> 00:05:47,759
lesson here I think it's pretty simple

172
00:05:47,759 --> 00:05:49,800
and that is when it comes to security

173
00:05:49,800 --> 00:05:52,440
like be naive Channel your inner child

174
00:05:52,440 --> 00:05:55,259
uh ask why ask lots of questions in

175
00:05:55,259 --> 00:05:57,740
general some would even say

176
00:05:57,740 --> 00:06:00,780
that this is a sacred obligation

177
00:06:00,780 --> 00:06:02,280
never thought I'd get to drop Heidegger

178
00:06:02,280 --> 00:06:04,440
in a Tech conference but I'm very proud

179
00:06:04,440 --> 00:06:06,780
of this thank you all for showing up I'm

180
00:06:06,780 --> 00:06:08,940
not actually done yet but still

181
00:06:08,940 --> 00:06:10,380
um

182
00:06:10,380 --> 00:06:12,360
so

183
00:06:12,360 --> 00:06:14,759
ask questions take nothing for granted

184
00:06:14,759 --> 00:06:17,539
right be naive uh be in a word

185
00:06:17,539 --> 00:06:19,620
thoughtful so that's the first

186
00:06:19,620 --> 00:06:21,479
definition right first definition of

187
00:06:21,479 --> 00:06:24,539
best practices is shortcuts but if we

188
00:06:24,539 --> 00:06:25,680
want to be a little bit more eloquent

189
00:06:25,680 --> 00:06:29,220
about it it's uh the Outsourcing of

190
00:06:29,220 --> 00:06:32,600
what is it the Outsourcing of

191
00:06:32,660 --> 00:06:34,919
Outsourcing of thoughtfulness if we want

192
00:06:34,919 --> 00:06:36,360
to be fancy about it but there are a lot

193
00:06:36,360 --> 00:06:37,800
of other definitions so we're going to

194
00:06:37,800 --> 00:06:39,900
run through a few and uh Garrett what

195
00:06:39,900 --> 00:06:42,120
else we got

196
00:06:42,120 --> 00:06:45,380
all right Clicker

197
00:06:45,660 --> 00:06:47,699
we asked for two mics and so we're just

198
00:06:47,699 --> 00:06:49,080
going to keep on to this handoff for the

199
00:06:49,080 --> 00:06:50,639
remainder of this I promise we'll try to

200
00:06:50,639 --> 00:06:52,860
get better at it so categorically best

201
00:06:52,860 --> 00:06:54,060
practices we're going to be talking

202
00:06:54,060 --> 00:06:55,440
through a few of them one of those is

203
00:06:55,440 --> 00:06:57,479
the bare minimum

204
00:06:57,479 --> 00:06:59,580
going into this we didn't realize that

205
00:06:59,580 --> 00:07:01,440
so many speakers including the Keynotes

206
00:07:01,440 --> 00:07:03,060
were going to completely slam

207
00:07:03,060 --> 00:07:05,699
multi-factor authentication but we are

208
00:07:05,699 --> 00:07:07,380
too uh so we're going to talk about

209
00:07:07,380 --> 00:07:09,539
multi-factor authentication what the

210
00:07:09,539 --> 00:07:11,520
bare minimum looks like and why not talk

211
00:07:11,520 --> 00:07:13,620
about how how multi-factor

212
00:07:13,620 --> 00:07:15,960
authentication applies to phishing so

213
00:07:15,960 --> 00:07:18,600
assuming all of you are practitioners in

214
00:07:18,600 --> 00:07:19,919
here I'm going to blast real quick

215
00:07:19,919 --> 00:07:22,800
through a rudimentary example of fishing

216
00:07:22,800 --> 00:07:25,319
fishing starts with an email okay we're

217
00:07:25,319 --> 00:07:27,300
all on the same page URL comes in the

218
00:07:27,300 --> 00:07:28,560
body of the email Kicking It Old School

219
00:07:28,560 --> 00:07:30,000
comes through a password encrypted

220
00:07:30,000 --> 00:07:31,979
document with a you know the passwords

221
00:07:31,979 --> 00:07:34,020
in the body whatever it might be URLs in

222
00:07:34,020 --> 00:07:36,419
there victim finds a way to get to it

223
00:07:36,419 --> 00:07:38,160
gets redirected to a compromise

224
00:07:38,160 --> 00:07:40,199
WordPress site why so specific on

225
00:07:40,199 --> 00:07:43,080
compromise WordPress site about 10 of

226
00:07:43,080 --> 00:07:44,940
the the attacks that we observe from

227
00:07:44,940 --> 00:07:46,139
customer environments we analyze their

228
00:07:46,139 --> 00:07:47,940
threat Telemetry use compromise

229
00:07:47,940 --> 00:07:49,380
WordPress sites as part of the attack

230
00:07:49,380 --> 00:07:51,419
chain hint if everything about best

231
00:07:51,419 --> 00:07:52,800
practice maybe go and look up how you

232
00:07:52,800 --> 00:07:54,840
might be identify WordPress in your

233
00:07:54,840 --> 00:07:57,000
network traffic and other other places

234
00:07:57,000 --> 00:07:59,340
all right URL talks about cheese that's

235
00:07:59,340 --> 00:08:00,539
why I chose this one the other reason

236
00:08:00,539 --> 00:08:02,280
why I chose this one also is because it

237
00:08:02,280 --> 00:08:03,660
uses SharePoint so let's imagine the

238
00:08:03,660 --> 00:08:05,520
victim is going through Office 365

239
00:08:05,520 --> 00:08:08,099
trying to log in passes credentials to

240
00:08:08,099 --> 00:08:10,440
that fake office 365. where does

241
00:08:10,440 --> 00:08:11,759
multi-factor authentication come into

242
00:08:11,759 --> 00:08:12,840
play

243
00:08:12,840 --> 00:08:14,160
right here

244
00:08:14,160 --> 00:08:16,020
this is the place where best practices

245
00:08:16,020 --> 00:08:18,780
from jamf to AWS to the 20 other vendors

246
00:08:18,780 --> 00:08:19,979
you can look up right now in best

247
00:08:19,979 --> 00:08:21,780
practices will tell you multi-factor

248
00:08:21,780 --> 00:08:23,460
authentication is the end-all be-all

249
00:08:23,460 --> 00:08:25,800
just to play it's going to be awesome

250
00:08:25,800 --> 00:08:27,720
but somehow we have attacks in the news

251
00:08:27,720 --> 00:08:28,680
where they had multi-factor

252
00:08:28,680 --> 00:08:31,740
authentication in place and a hacker man

253
00:08:31,740 --> 00:08:33,599
here himself is able to get into the

254
00:08:33,599 --> 00:08:35,458
organization

255
00:08:35,458 --> 00:08:36,839
so

256
00:08:36,839 --> 00:08:38,219
hopefully by the end of the day you

257
00:08:38,219 --> 00:08:39,479
realize that multi-factor authentication

258
00:08:39,479 --> 00:08:41,039
isn't the end-all be-all kind of a

259
00:08:41,039 --> 00:08:44,820
spoiler for our conversation here but

260
00:08:44,820 --> 00:08:46,980
the reason why we say best practices are

261
00:08:46,980 --> 00:08:48,360
the bare minimum is because if you just

262
00:08:48,360 --> 00:08:50,160
did what they told you I mean the

263
00:08:50,160 --> 00:08:52,080
vendors of the man told you to do when

264
00:08:52,080 --> 00:08:53,700
it comes to deploying security and

265
00:08:53,700 --> 00:08:55,019
stopping phishing you would have stopped

266
00:08:55,019 --> 00:08:56,580
likely at multi-factor authentication

267
00:08:56,580 --> 00:08:58,560
and this idea of being thoughtful

268
00:08:58,560 --> 00:09:00,000
through security is not to think about

269
00:09:00,000 --> 00:09:02,339
one single type of control or one single

270
00:09:02,339 --> 00:09:03,959
type of technology and how to stop

271
00:09:03,959 --> 00:09:05,760
threats but how to think how can we use

272
00:09:05,760 --> 00:09:08,339
all of our Tools in place so I'm going

273
00:09:08,339 --> 00:09:10,260
to get into that before I do I have to

274
00:09:10,260 --> 00:09:11,820
bring up Baldwin and we have a saying

275
00:09:11,820 --> 00:09:12,839
here at reach which is always be

276
00:09:12,839 --> 00:09:14,459
cogitating if you've seen this movie I

277
00:09:14,459 --> 00:09:16,200
was just told by somebody who's 30 years

278
00:09:16,200 --> 00:09:18,660
old I was like in diapers when it was

279
00:09:18,660 --> 00:09:20,700
that happened but uh

280
00:09:20,700 --> 00:09:23,339
um it's always be closing in the sales

281
00:09:23,339 --> 00:09:25,200
world but here it's always because let's

282
00:09:25,200 --> 00:09:27,120
be thoughtful about how we can prevent

283
00:09:27,120 --> 00:09:28,560
phishing

284
00:09:28,560 --> 00:09:30,480
now we talked about how multi-factor

285
00:09:30,480 --> 00:09:32,100
authentication doesn't actually mitigate

286
00:09:32,100 --> 00:09:33,779
phishing if you don't trust me we can

287
00:09:33,779 --> 00:09:34,800
talk about the different ways

288
00:09:34,800 --> 00:09:36,480
multi-factor authentication gets

289
00:09:36,480 --> 00:09:39,120
supplied SMS

290
00:09:39,120 --> 00:09:40,620
I can think of three can anybody think

291
00:09:40,620 --> 00:09:42,920
of more than one way to fish SMS

292
00:09:42,920 --> 00:09:45,540
authentication codes Sim swapping

293
00:09:45,540 --> 00:09:47,700
calling T-Mobile and saying I'm you and

294
00:09:47,700 --> 00:09:48,959
telling convincing them to give me the

295
00:09:48,959 --> 00:09:51,300
authentication code and man the middle

296
00:09:51,300 --> 00:09:54,120
attacks we have the authentication the

297
00:09:54,120 --> 00:09:56,279
push notification

298
00:09:56,279 --> 00:09:57,660
I guess there's push notification

299
00:09:57,660 --> 00:09:59,640
fatigue now from what I'm hearing so

300
00:09:59,640 --> 00:10:01,140
there's that and then you have the hard

301
00:10:01,140 --> 00:10:02,820
token and the hard token is probably the

302
00:10:02,820 --> 00:10:04,740
best way to mitigate phishing risk don't

303
00:10:04,740 --> 00:10:06,180
know how many of you have actually

304
00:10:06,180 --> 00:10:08,519
deployed hard tokens uh they're

305
00:10:08,519 --> 00:10:10,260
expensive we have them but we're a small

306
00:10:10,260 --> 00:10:12,300
company so it makes a lot easier but

307
00:10:12,300 --> 00:10:13,500
obviously if you can do that in a more

308
00:10:13,500 --> 00:10:15,300
focused way that's beneficial so

309
00:10:15,300 --> 00:10:16,860
multi-factor authentication doesn't stop

310
00:10:16,860 --> 00:10:18,779
phishing based on the news well what is

311
00:10:18,779 --> 00:10:19,860
it good at

312
00:10:19,860 --> 00:10:21,240
because I want to roll it completely out

313
00:10:21,240 --> 00:10:22,680
it's good at stopping Brute Force

314
00:10:22,680 --> 00:10:24,600
attacks credential stuffing that's what

315
00:10:24,600 --> 00:10:27,060
that one means and password reuse so if

316
00:10:27,060 --> 00:10:28,260
you're using something like have I been

317
00:10:28,260 --> 00:10:31,019
pwn to check out passwords inside your

318
00:10:31,019 --> 00:10:32,760
organization we use it for our uh

319
00:10:32,760 --> 00:10:33,959
infrastructure and when you create an

320
00:10:33,959 --> 00:10:35,580
account at reach we will check it

321
00:10:35,580 --> 00:10:37,620
against a database of known compromised

322
00:10:37,620 --> 00:10:39,360
passwords those are all things that are

323
00:10:39,360 --> 00:10:42,180
helpful but it's not helpful at stopping

324
00:10:42,180 --> 00:10:43,920
the credentials for being fished so how

325
00:10:43,920 --> 00:10:45,480
do we approach this problem well we

326
00:10:45,480 --> 00:10:47,220
don't rule out products like OCTA I'm

327
00:10:47,220 --> 00:10:48,899
going to talk about vendors now and how

328
00:10:48,899 --> 00:10:51,060
they can actually work together and help

329
00:10:51,060 --> 00:10:52,920
push notification press plus number

330
00:10:52,920 --> 00:10:55,019
challenge if you're not an OCTA customer

331
00:10:55,019 --> 00:10:56,940
and you use Azure as an example

332
00:10:56,940 --> 00:10:58,260
conditional access you have these

333
00:10:58,260 --> 00:11:00,540
capabilities available to you as well

334
00:11:00,540 --> 00:11:02,399
that one to two seconds you might be

335
00:11:02,399 --> 00:11:04,440
able to apply to a user as they try to

336
00:11:04,440 --> 00:11:07,140
push that apply or that ok button and

337
00:11:07,140 --> 00:11:09,240
you introduce a number Challenge on that

338
00:11:09,240 --> 00:11:11,040
so that's at the credential passing now

339
00:11:11,040 --> 00:11:12,779
what about the entire attack when

340
00:11:12,779 --> 00:11:15,480
hackerman has access stop them from

341
00:11:15,480 --> 00:11:17,040
logging in from places that you don't

342
00:11:17,040 --> 00:11:19,260
support as an Enterprise business

343
00:11:19,260 --> 00:11:20,940
um

344
00:11:20,940 --> 00:11:22,860
there's no best practices that say don't

345
00:11:22,860 --> 00:11:24,839
allow people to log in from a not proxy

346
00:11:24,839 --> 00:11:26,519
anonymizers but there's literally a

347
00:11:26,519 --> 00:11:28,019
switch in Octa that you can turn on to

348
00:11:28,019 --> 00:11:29,399
stop that from happening there's a

349
00:11:29,399 --> 00:11:30,899
switch you can stop them from logging

350
00:11:30,899 --> 00:11:32,760
from Tor I've only heard one customer

351
00:11:32,760 --> 00:11:34,740
come up to me or Prospect come up to me

352
00:11:34,740 --> 00:11:37,140
and say oh well we need Tor and that

353
00:11:37,140 --> 00:11:38,220
person's sitting up here in the front

354
00:11:38,220 --> 00:11:39,360
you can ask them later what that

355
00:11:39,360 --> 00:11:40,980
actually what the requirement was but I

356
00:11:40,980 --> 00:11:42,720
was told they needed it for a reason you

357
00:11:42,720 --> 00:11:43,620
probably don't need it from an

358
00:11:43,620 --> 00:11:45,660
Enterprise security standpoint and last

359
00:11:45,660 --> 00:11:47,160
but not least let's assume that the from

360
00:11:47,160 --> 00:11:48,300
your threat modeling from your threat

361
00:11:48,300 --> 00:11:49,740
informed decision making let's assume

362
00:11:49,740 --> 00:11:52,019
that they already have the password that

363
00:11:52,019 --> 00:11:54,360
they have the token they're now in what

364
00:11:54,360 --> 00:11:55,740
can you do

365
00:11:55,740 --> 00:11:57,060
let's pay attention to where they're

366
00:11:57,060 --> 00:11:58,380
logging in from a lot of these attacks

367
00:11:58,380 --> 00:12:00,660
come from the cloud I picked on Alibaba

368
00:12:00,660 --> 00:12:02,160
sorry if you're an Alibaba user or

369
00:12:02,160 --> 00:12:04,260
you're a rep from Alibaba

370
00:12:04,260 --> 00:12:06,240
um you can actually stop them from

371
00:12:06,240 --> 00:12:08,519
logging in from specific csps or cloud

372
00:12:08,519 --> 00:12:10,200
service Riders if you see this

373
00:12:10,200 --> 00:12:12,000
connection coming in and you see it

374
00:12:12,000 --> 00:12:13,200
coming in from a new device or new

375
00:12:13,200 --> 00:12:14,399
Regional you never recognize before

376
00:12:14,399 --> 00:12:15,899
you're in able to apply security

377
00:12:15,899 --> 00:12:17,579
controls and boot them out troll them

378
00:12:17,579 --> 00:12:19,079
reset their session have to have them go

379
00:12:19,079 --> 00:12:20,880
through the entire process advise your

380
00:12:20,880 --> 00:12:22,260
operations teams time from a learning

381
00:12:22,260 --> 00:12:24,120
standpoint to look at that alert it buys

382
00:12:24,120 --> 00:12:25,380
your user more time to approve that

383
00:12:25,380 --> 00:12:28,440
notification one more time and on the on

384
00:12:28,440 --> 00:12:30,480
their side what I'm getting as we talked

385
00:12:30,480 --> 00:12:32,040
a lot about MFA and SSO I don't want to

386
00:12:32,040 --> 00:12:33,060
leave them high and dry there are

387
00:12:33,060 --> 00:12:34,380
advantages but when you think about

388
00:12:34,380 --> 00:12:35,880
stopping fishing we have to think about

389
00:12:35,880 --> 00:12:38,160
all of the steps and so here at reach we

390
00:12:38,160 --> 00:12:39,000
think about how can you use email

391
00:12:39,000 --> 00:12:40,320
security it's not just about the

392
00:12:40,320 --> 00:12:42,660
categories of of saying this this this

393
00:12:42,660 --> 00:12:44,339
email is bad or this email is fishing

394
00:12:44,339 --> 00:12:45,959
this email's malware but using things

395
00:12:45,959 --> 00:12:47,820
like URL rewriting again things like

396
00:12:47,820 --> 00:12:49,800
safe linking and Microsoft can also be

397
00:12:49,800 --> 00:12:51,600
used or safe attachments can also be

398
00:12:51,600 --> 00:12:54,000
used with Microsoft applying those for

399
00:12:54,000 --> 00:12:56,399
attacks that might be unknown initially

400
00:12:56,399 --> 00:12:57,600
to the vendor so don't rely on the

401
00:12:57,600 --> 00:12:58,920
vendor getting right the first time give

402
00:12:58,920 --> 00:13:01,200
them time to figure it out that enables

403
00:13:01,200 --> 00:13:03,480
capabilities like browser isolation so

404
00:13:03,480 --> 00:13:04,980
one of the things we do here at reach is

405
00:13:04,980 --> 00:13:06,839
we actually enable customers to focus on

406
00:13:06,839 --> 00:13:08,519
where might you apply these types of new

407
00:13:08,519 --> 00:13:10,620
security controls to start saves you

408
00:13:10,620 --> 00:13:12,120
money on licensing for example if you're

409
00:13:12,120 --> 00:13:13,380
looking at browser isolation where the

410
00:13:13,380 --> 00:13:14,820
500 people you want to deploy it to

411
00:13:14,820 --> 00:13:17,519
versus maybe 5 000 your business but

412
00:13:17,519 --> 00:13:19,079
being able to say for all those all

413
00:13:19,079 --> 00:13:21,180
those URLs that were Rewritten I want to

414
00:13:21,180 --> 00:13:23,700
proxy and isolate that traffic and stop

415
00:13:23,700 --> 00:13:25,139
the phishing from ever occurring them

416
00:13:25,139 --> 00:13:26,760
ever arriving at the WordPress site as

417
00:13:26,760 --> 00:13:28,860
an example okay so what else can we use

418
00:13:28,860 --> 00:13:31,920
how many of you are using uh an EDR

419
00:13:31,920 --> 00:13:34,200
product that how many of you use an EDR

420
00:13:34,200 --> 00:13:37,579
to stop phishing or detect fishing

421
00:13:38,160 --> 00:13:41,100
hell yeah that's more like statistically

422
00:13:41,100 --> 00:13:42,420
that's more than we actually hear from

423
00:13:42,420 --> 00:13:44,040
folks so even three out of this room is

424
00:13:44,040 --> 00:13:46,139
is really awesome uh I'd love to talk

425
00:13:46,139 --> 00:13:47,459
about talk to you about how you're doing

426
00:13:47,459 --> 00:13:50,100
it afterwards uh but Sentinel one and a

427
00:13:50,100 --> 00:13:51,420
number of other products Microsoft just

428
00:13:51,420 --> 00:13:52,800
released some capabilities native you

429
00:13:52,800 --> 00:13:55,320
can actually identify uh URL traffic or

430
00:13:55,320 --> 00:13:57,060
and also domains but that's not so

431
00:13:57,060 --> 00:13:59,519
useful in this case uh

432
00:13:59,519 --> 00:14:01,200
using something like 701 you can take

433
00:14:01,200 --> 00:14:02,760
that same approach to saying I want to

434
00:14:02,760 --> 00:14:04,380
look for compromised WordPress sites

435
00:14:04,380 --> 00:14:05,519
reach crease these rules free

436
00:14:05,519 --> 00:14:07,200
automatically you do your threat model

437
00:14:07,200 --> 00:14:08,579
exercise and make some threat informed

438
00:14:08,579 --> 00:14:10,079
decisions to figure out exactly how

439
00:14:10,079 --> 00:14:11,279
you're being attacked identify what

440
00:14:11,279 --> 00:14:13,500
sites are most nefarious inside of your

441
00:14:13,500 --> 00:14:14,399
business

442
00:14:14,399 --> 00:14:16,320
I want to go ahead and identify

443
00:14:16,320 --> 00:14:18,540
WordPress sites that can be used with

444
00:14:18,540 --> 00:14:20,279
credential phishing to look at forms for

445
00:14:20,279 --> 00:14:21,300
example that could they could be

446
00:14:21,300 --> 00:14:22,320
submitted to

447
00:14:22,320 --> 00:14:24,959
if I do that correctly I have my most

448
00:14:24,959 --> 00:14:26,459
attacked people from a phishing

449
00:14:26,459 --> 00:14:28,920
standpoint receiving this type of policy

450
00:14:28,920 --> 00:14:30,779
and I'm able to now step in at the

451
00:14:30,779 --> 00:14:32,940
redirect where I arrive as well as

452
00:14:32,940 --> 00:14:34,980
submission of credentials I introduced A

453
00:14:34,980 --> 00:14:36,480
New Concept because this again is about

454
00:14:36,480 --> 00:14:38,880
thinking through your threat model

455
00:14:38,880 --> 00:14:40,980
thinking through your attack exposure as

456
00:14:40,980 --> 00:14:43,199
a company one of the things I talked

457
00:14:43,199 --> 00:14:44,459
about products one of the things you

458
00:14:44,459 --> 00:14:46,740
want to be mindful of too is where do

459
00:14:46,740 --> 00:14:48,180
the risk hot spots live inside your

460
00:14:48,180 --> 00:14:50,399
business do you know right now for

461
00:14:50,399 --> 00:14:52,860
certain not not like my executives are

462
00:14:52,860 --> 00:14:54,120
most attacked because that's what we

463
00:14:54,120 --> 00:14:56,699
hear that could be true but do you know

464
00:14:56,699 --> 00:14:58,860
for certain who the top 20 people inside

465
00:14:58,860 --> 00:15:00,240
your business who are most attacked and

466
00:15:00,240 --> 00:15:03,060
most at risk if they were compromised to

467
00:15:03,060 --> 00:15:04,260
hurt your business

468
00:15:04,260 --> 00:15:05,880
if you don't

469
00:15:05,880 --> 00:15:08,339
go figure it out and start to Tinker and

470
00:15:08,339 --> 00:15:10,440
play with applying more more stringent

471
00:15:10,440 --> 00:15:12,420
or strict security policies you have a

472
00:15:12,420 --> 00:15:13,740
net new security initiative like

473
00:15:13,740 --> 00:15:16,560
hardening MFA and SSO go focus on

474
00:15:16,560 --> 00:15:18,540
rolling out to those folks first we do

475
00:15:18,540 --> 00:15:20,100
all that modeling on our side so we have

476
00:15:20,100 --> 00:15:21,839
most fish most attacked overall most

477
00:15:21,839 --> 00:15:24,600
impacted by malware list goes on and on

478
00:15:24,600 --> 00:15:27,000
but thinking about the human aspect and

479
00:15:27,000 --> 00:15:28,620
hypertuctor Workforce and how you apply

480
00:15:28,620 --> 00:15:30,000
those controls is really important and

481
00:15:30,000 --> 00:15:31,680
gets you to actually pick up speed we

482
00:15:31,680 --> 00:15:33,360
find that about three to four percent of

483
00:15:33,360 --> 00:15:34,440
the population in a given customer

484
00:15:34,440 --> 00:15:36,600
environment can account for between 70

485
00:15:36,600 --> 00:15:38,760
and 80 percent of all the risk or the

486
00:15:38,760 --> 00:15:40,800
attacks inside the business think of a

487
00:15:40,800 --> 00:15:42,660
tax not just in volume because spam

488
00:15:42,660 --> 00:15:43,860
doesn't mean anything and stealing

489
00:15:43,860 --> 00:15:45,480
Netflix accounts is so what but think

490
00:15:45,480 --> 00:15:46,860
about risk in terms of also the

491
00:15:46,860 --> 00:15:48,480
attackers what they want to get out of

492
00:15:48,480 --> 00:15:50,279
the attack itself

493
00:15:50,279 --> 00:15:52,139
last but not least I spent seven years

494
00:15:52,139 --> 00:15:53,880
at pal to network so I'd be remiss if I

495
00:15:53,880 --> 00:15:55,920
didn't include them uh this capability

496
00:15:55,920 --> 00:15:57,660
rolled out about four or five years ago

497
00:15:57,660 --> 00:15:59,760
almost no one deploys it if you have

498
00:15:59,760 --> 00:16:01,500
pallets and RX go check it out if you're

499
00:16:01,500 --> 00:16:03,720
afraid of deploying it to everybody try

500
00:16:03,720 --> 00:16:05,399
it on some of those risky use inside of

501
00:16:05,399 --> 00:16:06,480
your business

502
00:16:06,480 --> 00:16:07,680
but this will go ahead and actually

503
00:16:07,680 --> 00:16:10,440
prevent the post of credentials to

504
00:16:10,440 --> 00:16:13,860
websites so if you're using SSO

505
00:16:13,860 --> 00:16:15,420
why should credentials have any other

506
00:16:15,420 --> 00:16:17,940
path to the internet then uh for example

507
00:16:17,940 --> 00:16:19,500
SSO itself

508
00:16:19,500 --> 00:16:22,019
pay attention to unknown categories

509
00:16:22,019 --> 00:16:23,399
categories of high risk or just do it

510
00:16:23,399 --> 00:16:24,540
for everything depend on your threat

511
00:16:24,540 --> 00:16:27,000
model and prevent your users from

512
00:16:27,000 --> 00:16:30,360
posting Enterprise creds to websites

513
00:16:30,360 --> 00:16:32,160
that are

514
00:16:32,160 --> 00:16:33,839
well just any website or they're

515
00:16:33,839 --> 00:16:36,000
unauthorized prevent them from doing

516
00:16:36,000 --> 00:16:37,560
that there's a bunch of technicality on

517
00:16:37,560 --> 00:16:38,940
how this feature Works happy to explain

518
00:16:38,940 --> 00:16:40,019
it afterwards I think there's probably

519
00:16:40,019 --> 00:16:41,160
some pellets and other people in here

520
00:16:41,160 --> 00:16:42,600
that can also explain it

521
00:16:42,600 --> 00:16:44,699
but highly valuable so what did we just

522
00:16:44,699 --> 00:16:46,259
discuss we discussed that the best

523
00:16:46,259 --> 00:16:48,120
practices tell you multi-factor

524
00:16:48,120 --> 00:16:50,220
authentication is the end-all be-all for

525
00:16:50,220 --> 00:16:52,500
that stage where I just got this so I'm

526
00:16:52,500 --> 00:16:54,899
going to use laser pointer uh

527
00:16:54,899 --> 00:16:57,060
end-all be-all for stopping fishing when

528
00:16:57,060 --> 00:16:58,440
in reality it's just a speed bump

529
00:16:58,440 --> 00:17:00,959
evident by the way in which we're seeing

530
00:17:00,959 --> 00:17:02,759
attacks happen in the news when you

531
00:17:02,759 --> 00:17:04,559
think about how to prevent a phishing

532
00:17:04,559 --> 00:17:06,359
attack it's much more complex I just

533
00:17:06,359 --> 00:17:07,380
spent

534
00:17:07,380 --> 00:17:09,119
eight minutes talking about it right

535
00:17:09,119 --> 00:17:10,980
there's so much more that you can do in

536
00:17:10,980 --> 00:17:12,540
terms of how you want to approach diving

537
00:17:12,540 --> 00:17:14,099
fishing so in your threat and form

538
00:17:14,099 --> 00:17:15,480
decision making think about how all the

539
00:17:15,480 --> 00:17:17,099
products can work together

540
00:17:17,099 --> 00:17:20,280
that is why best practices uh on their

541
00:17:20,280 --> 00:17:24,240
own are the minimum so Colt is going to

542
00:17:24,240 --> 00:17:25,380
talk about another category of best

543
00:17:25,380 --> 00:17:27,299
practices uh this one's going to go more

544
00:17:27,299 --> 00:17:29,940
into the dev side of the world so uh you

545
00:17:29,940 --> 00:17:32,340
know let's see what happens

546
00:17:32,340 --> 00:17:35,460
is terrible all right so best practices

547
00:17:35,460 --> 00:17:37,380
are also

548
00:17:37,380 --> 00:17:40,440
one size fits all another way of saying

549
00:17:40,440 --> 00:17:42,960
this is they're good but like on average

550
00:17:42,960 --> 00:17:45,240
um as a data Science Guy this is one

551
00:17:45,240 --> 00:17:48,419
that really turns my butter so let's say

552
00:17:48,419 --> 00:17:49,799
you wanted to get like a really nice

553
00:17:49,799 --> 00:17:51,600
suit a really nice dress or whatever you

554
00:17:51,600 --> 00:17:53,940
like to wear uh do you want something

555
00:17:53,940 --> 00:17:55,980
that was made for the average person or

556
00:17:55,980 --> 00:17:57,059
do you want something that was tailored

557
00:17:57,059 --> 00:17:59,400
for you it's kind of obvious right if

558
00:17:59,400 --> 00:18:01,440
you go and take the the measurements of

559
00:18:01,440 --> 00:18:03,539
a thousand people and you build

560
00:18:03,539 --> 00:18:05,520
or make some article of clothing that's

561
00:18:05,520 --> 00:18:06,780
the average of all those measurements

562
00:18:06,780 --> 00:18:09,179
it's actually very unlikely to fit any

563
00:18:09,179 --> 00:18:10,380
of those thousand people because it's

564
00:18:10,380 --> 00:18:11,400
just an average across all of them

565
00:18:11,400 --> 00:18:13,320
that's the problem with averages they

566
00:18:13,320 --> 00:18:14,940
don't actually fit anyone it's just a

567
00:18:14,940 --> 00:18:16,440
generalization across the group and it's

568
00:18:16,440 --> 00:18:18,600
not super helpful so why am I talking

569
00:18:18,600 --> 00:18:19,980
about this well let's look at an example

570
00:18:19,980 --> 00:18:23,640
uh AWS if you build things in AWS you

571
00:18:23,640 --> 00:18:26,640
will probably have encountered uh aws's

572
00:18:26,640 --> 00:18:28,919
best practices for IAM identity and

573
00:18:28,919 --> 00:18:32,220
access management there are 14 items on

574
00:18:32,220 --> 00:18:34,200
the list you can Google this and find

575
00:18:34,200 --> 00:18:36,720
them we care about a couple of the the

576
00:18:36,720 --> 00:18:37,919
top three like these are the ones that

577
00:18:37,919 --> 00:18:40,200
AWS says are most important so here's

578
00:18:40,200 --> 00:18:42,419
Number One require human users to use

579
00:18:42,419 --> 00:18:44,520
Federation with an identity provider to

580
00:18:44,520 --> 00:18:46,559
access AWS using temporary credentials

581
00:18:46,559 --> 00:18:48,840
not very well written but there are two

582
00:18:48,840 --> 00:18:50,340
key Concepts here one of them is

583
00:18:50,340 --> 00:18:51,780
Federation with an identity provider

584
00:18:51,780 --> 00:18:53,880
which we all just call SSO there's no

585
00:18:53,880 --> 00:18:55,620
need to be fancy about it and the other

586
00:18:55,620 --> 00:18:57,299
is these temporary credentials because

587
00:18:57,299 --> 00:18:58,799
you can also use credentials that are

588
00:18:58,799 --> 00:19:00,720
static and last forever so that's that's

589
00:19:00,720 --> 00:19:02,820
one and then third on the list which is

590
00:19:02,820 --> 00:19:05,400
an addendum to that is require our old

591
00:19:05,400 --> 00:19:08,100
friend MFA uh Garrett did a perfectly

592
00:19:08,100 --> 00:19:10,020
good job of deconstructing MFA we don't

593
00:19:10,020 --> 00:19:12,120
need to dig into that more here we just

594
00:19:12,120 --> 00:19:14,039
need to again Channel our inner child

595
00:19:14,039 --> 00:19:16,980
and ask questions like why why are these

596
00:19:16,980 --> 00:19:19,559
best practices what is the the concern

597
00:19:19,559 --> 00:19:21,660
what's the the hesitation what are

598
00:19:21,660 --> 00:19:23,640
people worried about here

599
00:19:23,640 --> 00:19:25,620
they're worried about this and the

600
00:19:25,620 --> 00:19:27,120
Thousand incidents just like it that

601
00:19:27,120 --> 00:19:29,340
have been happening uh for the last

602
00:19:29,340 --> 00:19:31,679
decade give or take so this is just a

603
00:19:31,679 --> 00:19:33,480
couple weeks ago Toyota comes out and

604
00:19:33,480 --> 00:19:35,820
discloses that uh somebody over there

605
00:19:35,820 --> 00:19:37,860
had accidentally committed secret keys

606
00:19:37,860 --> 00:19:40,200
to accessing their Cloud infrastructure

607
00:19:40,200 --> 00:19:43,320
into a code repository that was publicly

608
00:19:43,320 --> 00:19:45,360
visible happened to be uploaded to

609
00:19:45,360 --> 00:19:48,179
GitHub and as a result of that several

610
00:19:48,179 --> 00:19:50,340
hundred thousand customers data was

611
00:19:50,340 --> 00:19:52,559
exposed it's kind of a big deal Owen by

612
00:19:52,559 --> 00:19:53,460
the way

613
00:19:53,460 --> 00:19:55,200
all the bad stuff here it happened five

614
00:19:55,200 --> 00:19:57,539
years ago so they exposed the keys five

615
00:19:57,539 --> 00:20:00,000
years ago uh and then just now realized

616
00:20:00,000 --> 00:20:02,460
it uh was it October 7th or whatever

617
00:20:02,460 --> 00:20:04,620
yeah October 7th uh that's a pretty long

618
00:20:04,620 --> 00:20:06,480
window to have those things hanging out

619
00:20:06,480 --> 00:20:08,100
there in the wind so so not not very

620
00:20:08,100 --> 00:20:09,299
good

621
00:20:09,299 --> 00:20:11,039
um so how does a data leak like this

622
00:20:11,039 --> 00:20:13,280
work pretty straightforward you've got

623
00:20:13,280 --> 00:20:15,720
an engineer who builds stuff by writing

624
00:20:15,720 --> 00:20:19,500
code Hello nice to meet you and some of

625
00:20:19,500 --> 00:20:20,700
the code that that engineer writes is

626
00:20:20,700 --> 00:20:23,220
going to go up into a cloud like AWS and

627
00:20:23,220 --> 00:20:24,660
in order to access and interact with

628
00:20:24,660 --> 00:20:26,880
that cloud they're going to use secret

629
00:20:26,880 --> 00:20:28,620
Keys you can think of these as like

630
00:20:28,620 --> 00:20:30,960
passwords but for machines so they don't

631
00:20:30,960 --> 00:20:33,720
have the same flaws and foibles as human

632
00:20:33,720 --> 00:20:35,760
generated passwords they're much more

633
00:20:35,760 --> 00:20:37,380
secure but they're still basically

634
00:20:37,380 --> 00:20:39,600
passwords so you have those and by

635
00:20:39,600 --> 00:20:41,700
default they're static they don't change

636
00:20:41,700 --> 00:20:43,799
they don't expire but they are assigned

637
00:20:43,799 --> 00:20:46,140
directly to the identity of a human and

638
00:20:46,140 --> 00:20:47,580
now what can happen is

639
00:20:47,580 --> 00:20:49,320
if that engineer is let's say

640
00:20:49,320 --> 00:20:51,600
inexperienced or the development team

641
00:20:51,600 --> 00:20:54,360
just has pissport practices they can

642
00:20:54,360 --> 00:20:56,400
accidentally end up committing those or

643
00:20:56,400 --> 00:20:58,740
commingling those secret keys with the

644
00:20:58,740 --> 00:21:00,360
code so that it ends up in the code

645
00:21:00,360 --> 00:21:02,700
repository let's say git Mercurial

646
00:21:02,700 --> 00:21:04,440
something like that and then it gets

647
00:21:04,440 --> 00:21:06,000
synced up in some cases to a public

648
00:21:06,000 --> 00:21:07,919
Cloud which a GitHub is an example of

649
00:21:07,919 --> 00:21:09,720
but that's not the only way things can

650
00:21:09,720 --> 00:21:11,039
go wrong here right you could also just

651
00:21:11,039 --> 00:21:12,900
have a CI CD pipeline that runs locally

652
00:21:12,900 --> 00:21:14,580
that picks up those Secrets because now

653
00:21:14,580 --> 00:21:17,520
they're in the code and builds them out

654
00:21:17,520 --> 00:21:18,780
and deploys them out to a customer it

655
00:21:18,780 --> 00:21:20,220
could be a react app so it's deploying

656
00:21:20,220 --> 00:21:21,840
like a front-end through the browser it

657
00:21:21,840 --> 00:21:23,160
could be a local application like

658
00:21:23,160 --> 00:21:24,660
Microsoft Office it could be a million

659
00:21:24,660 --> 00:21:26,580
different things but either way the

660
00:21:26,580 --> 00:21:28,020
secret keys that give access to

661
00:21:28,020 --> 00:21:29,340
production and all your customer data

662
00:21:29,340 --> 00:21:32,159
those get exposed and now the return of

663
00:21:32,159 --> 00:21:33,480
hacker man

664
00:21:33,480 --> 00:21:35,760
not a great situation now the theory

665
00:21:35,760 --> 00:21:37,620
here the reason AWS has these best

666
00:21:37,620 --> 00:21:38,520
practices

667
00:21:38,520 --> 00:21:40,559
watch the little key there because this

668
00:21:40,559 --> 00:21:42,780
is stupidly subtle terrible slide Choice

669
00:21:42,780 --> 00:21:46,679
by me uh by making these Keys temporary

670
00:21:46,679 --> 00:21:48,659
we cut this whole problem off at the

671
00:21:48,659 --> 00:21:49,919
knees like we're not going to eliminate

672
00:21:49,919 --> 00:21:51,960
it entirely but we do dramatically

673
00:21:51,960 --> 00:21:54,360
reduce the problem there and the idea is

674
00:21:54,360 --> 00:21:56,100
this you still got the engineer there

675
00:21:56,100 --> 00:21:57,480
might still be an experience there might

676
00:21:57,480 --> 00:21:59,460
still be on a pretty crappy development

677
00:21:59,460 --> 00:22:00,900
team doing stupid things all the time

678
00:22:00,900 --> 00:22:03,659
none of that changes but now in order to

679
00:22:03,659 --> 00:22:05,340
get their access keys they have to go

680
00:22:05,340 --> 00:22:07,440
through SSO and they do that in the same

681
00:22:07,440 --> 00:22:08,820
way that they would check their email or

682
00:22:08,820 --> 00:22:10,380
go into work data request time off or

683
00:22:10,380 --> 00:22:11,820
any of the other billion things you do

684
00:22:11,820 --> 00:22:14,220
with your Enterprise corporate resources

685
00:22:14,220 --> 00:22:16,260
that are managed by SSO

686
00:22:16,260 --> 00:22:19,440
The Far Side of that process now gives

687
00:22:19,440 --> 00:22:21,659
you back the temporary key and so okay

688
00:22:21,659 --> 00:22:24,000
maybe this key still gets committed to

689
00:22:24,000 --> 00:22:25,320
code maybe it still ends up in GitHub

690
00:22:25,320 --> 00:22:27,659
still gets deployed through UI anything

691
00:22:27,659 --> 00:22:30,000
like that but the key is temporary it's

692
00:22:30,000 --> 00:22:31,919
only good for like an hour

693
00:22:31,919 --> 00:22:33,679
or if you're

694
00:22:33,679 --> 00:22:36,059
really not mindful of security maybe

695
00:22:36,059 --> 00:22:37,620
you'll allow it to live for an entire

696
00:22:37,620 --> 00:22:39,539
day but usually it's between one and

697
00:22:39,539 --> 00:22:41,520
eight hours is what most people do and

698
00:22:41,520 --> 00:22:43,080
that means

699
00:22:43,080 --> 00:22:44,640
you're kind of okay right like you

700
00:22:44,640 --> 00:22:46,380
leaked the key hackerman is maybe still

701
00:22:46,380 --> 00:22:47,700
there if he finds it fast enough you

702
00:22:47,700 --> 00:22:48,780
might be able to do something with it

703
00:22:48,780 --> 00:22:50,880
but if you if you do everything else

704
00:22:50,880 --> 00:22:52,380
correctly so that there's no escalation

705
00:22:52,380 --> 00:22:54,840
path once they get into AWS uh you're

706
00:22:54,840 --> 00:22:57,419
kind of in an okay State here as far as

707
00:22:57,419 --> 00:22:59,880
this threat model goes right that's the

708
00:22:59,880 --> 00:23:01,140
idea

709
00:23:01,140 --> 00:23:03,080
people think at least

710
00:23:03,080 --> 00:23:05,520
that's not true at least not exactly

711
00:23:05,520 --> 00:23:07,500
because what did we just do

712
00:23:07,500 --> 00:23:09,179
we added phishing to a threat model

713
00:23:09,179 --> 00:23:11,039
where it did not exist before like

714
00:23:11,039 --> 00:23:12,960
static Keys okay they have problems they

715
00:23:12,960 --> 00:23:14,940
can leak you can expose them in source

716
00:23:14,940 --> 00:23:16,679
code whatever but what do we already

717
00:23:16,679 --> 00:23:19,080
know is like the single biggest attack

718
00:23:19,080 --> 00:23:20,940
Vector on companies around the world

719
00:23:20,940 --> 00:23:23,880
it's phishing and you just added it to

720
00:23:23,880 --> 00:23:25,200
the authentication path for your

721
00:23:25,200 --> 00:23:27,240
production systems by following the best

722
00:23:27,240 --> 00:23:29,039
practice I'm not saying you shouldn't

723
00:23:29,039 --> 00:23:30,720
follow the best practice but I am saying

724
00:23:30,720 --> 00:23:32,220
that there are trade-offs here and you

725
00:23:32,220 --> 00:23:33,299
have to think about them very very

726
00:23:33,299 --> 00:23:34,980
carefully and understand the risks that

727
00:23:34,980 --> 00:23:36,360
you're accepting when you make a

728
00:23:36,360 --> 00:23:37,980
decision like this it's not a

729
00:23:37,980 --> 00:23:40,320
one-size-fits-all decision but this

730
00:23:40,320 --> 00:23:42,360
isn't even the only bad thing we also

731
00:23:42,360 --> 00:23:44,340
introduced several new attack services

732
00:23:44,340 --> 00:23:46,020
that did not exist before what do I mean

733
00:23:46,020 --> 00:23:47,520
by attack surface for example

734
00:23:47,520 --> 00:23:49,200
centralized access

735
00:23:49,200 --> 00:23:51,000
axis is compromised like you fish

736
00:23:51,000 --> 00:23:52,440
someone's account

737
00:23:52,440 --> 00:23:54,179
you compromise them that's what access

738
00:23:54,179 --> 00:23:56,280
is when you centralize access you also

739
00:23:56,280 --> 00:23:58,020
centralize compromise what I mean by

740
00:23:58,020 --> 00:23:59,700
that is if you're running everything

741
00:23:59,700 --> 00:24:01,080
through SSO then I could fish your

742
00:24:01,080 --> 00:24:04,260
Office 365 account and if AWS production

743
00:24:04,260 --> 00:24:07,080
is part of sso2 I can jump from your

744
00:24:07,080 --> 00:24:09,000
email to production

745
00:24:09,000 --> 00:24:10,799
like Legally Legally spit there's

746
00:24:10,799 --> 00:24:12,120
nothing getting my way there unless you

747
00:24:12,120 --> 00:24:13,380
go out of your way to implement extra

748
00:24:13,380 --> 00:24:16,440
controls that's very problematic and if

749
00:24:16,440 --> 00:24:18,539
I get somebody who's like I.T or

750
00:24:18,539 --> 00:24:21,480
security engineering which doesn't maybe

751
00:24:21,480 --> 00:24:22,919
happen as often but we know what happens

752
00:24:22,919 --> 00:24:24,659
just ask the folks at Uber from like a

753
00:24:24,659 --> 00:24:27,600
month ago like bad stuff does happen uh

754
00:24:27,600 --> 00:24:29,400
now I can pivot like anywhere I can get

755
00:24:29,400 --> 00:24:30,600
into your Sentinel one or your

756
00:24:30,600 --> 00:24:32,039
crowdstrike or your firewalls or a

757
00:24:32,039 --> 00:24:33,419
million other things shut all your

758
00:24:33,419 --> 00:24:35,340
security down like I can I can open you

759
00:24:35,340 --> 00:24:37,740
wide up like you are a patient on the

760
00:24:37,740 --> 00:24:39,179
operating table and I'm the surgeon it's

761
00:24:39,179 --> 00:24:41,280
bad it's really bad so again I'm not

762
00:24:41,280 --> 00:24:43,320
saying don't use SSO but be aware of the

763
00:24:43,320 --> 00:24:45,299
risk that goes along with this

764
00:24:45,299 --> 00:24:47,340
um not something we need to dwell on but

765
00:24:47,340 --> 00:24:48,600
there's a supply chain risk here too

766
00:24:48,600 --> 00:24:49,980
right if you're delegating

767
00:24:49,980 --> 00:24:51,419
authentication to your systems to

768
00:24:51,419 --> 00:24:53,460
somebody third party like OCTA you have

769
00:24:53,460 --> 00:24:54,900
to worry about them getting breached and

770
00:24:54,900 --> 00:24:56,220
of course what happened to OCTA in

771
00:24:56,220 --> 00:24:57,840
January of this year they got breached

772
00:24:57,840 --> 00:24:59,340
they didn't handle it that well it's a

773
00:24:59,340 --> 00:25:00,419
whole thing you can read about it online

774
00:25:00,419 --> 00:25:02,760
again don't need to dwell on that much

775
00:25:02,760 --> 00:25:04,740
more interesting cryptographic Doom this

776
00:25:04,740 --> 00:25:06,720
is a phrase from Moxie Marlins Moxie

777
00:25:06,720 --> 00:25:09,000
Marlin Spike if you use signal on your

778
00:25:09,000 --> 00:25:10,740
phone it's the guy who one of the guys

779
00:25:10,740 --> 00:25:12,900
who developed all that stuff

780
00:25:12,900 --> 00:25:13,740
um

781
00:25:13,740 --> 00:25:16,020
very important in the context of SSO

782
00:25:16,020 --> 00:25:18,120
because what is SSO built on

783
00:25:18,120 --> 00:25:20,039
cryptographic protocols what do we know

784
00:25:20,039 --> 00:25:22,380
about those they're very very hard for

785
00:25:22,380 --> 00:25:24,299
people to implement correctly when

786
00:25:24,299 --> 00:25:26,279
non-experts do it there's a 100 chance

787
00:25:26,279 --> 00:25:27,419
it's going to fail it's going to fail

788
00:25:27,419 --> 00:25:29,760
catastrophically and even when experts

789
00:25:29,760 --> 00:25:31,200
do it they're still like a 98 chance

790
00:25:31,200 --> 00:25:32,279
that it's going to fail because it's

791
00:25:32,279 --> 00:25:35,279
just almost impossible to do well so

792
00:25:35,279 --> 00:25:37,380
when you accept SSO you're accepting

793
00:25:37,380 --> 00:25:39,000
this risk

794
00:25:39,000 --> 00:25:40,679
um I get pushed back on this from

795
00:25:40,679 --> 00:25:42,480
basically everybody when I talk to them

796
00:25:42,480 --> 00:25:44,159
about it even even my own team at reach

797
00:25:44,159 --> 00:25:46,380
but let's look at some some actual

798
00:25:46,380 --> 00:25:47,520
numbers here so you might say well

799
00:25:47,520 --> 00:25:48,960
sample's been around for 20 years right

800
00:25:48,960 --> 00:25:50,100
that's one of the protocols security

801
00:25:50,100 --> 00:25:51,720
assertion markup language it's been

802
00:25:51,720 --> 00:25:54,059
around for two decades The Kinks have

803
00:25:54,059 --> 00:25:55,740
probably been worked out by now that is

804
00:25:55,740 --> 00:25:57,360
absolutely not the case we don't even

805
00:25:57,360 --> 00:25:59,400
have to go back that far 2018 the

806
00:25:59,400 --> 00:26:02,520
research team at Duo found

807
00:26:02,520 --> 00:26:04,740
just a complete blanket vulnerability

808
00:26:04,740 --> 00:26:06,299
across essentially every implementation

809
00:26:06,299 --> 00:26:08,100
of saml that was out there it affected

810
00:26:08,100 --> 00:26:10,620
every company you could use this to log

811
00:26:10,620 --> 00:26:12,539
into the SSO account so basically any

812
00:26:12,539 --> 00:26:14,760
person at any company in the world like

813
00:26:14,760 --> 00:26:19,799
uh One login ping Duo itself uh OCTA all

814
00:26:19,799 --> 00:26:21,480
were affected OCTA also lied about being

815
00:26:21,480 --> 00:26:23,039
affected they got blasted for it on

816
00:26:23,039 --> 00:26:24,419
Twitter definitely recommend looking it

817
00:26:24,419 --> 00:26:26,400
up because drama is always fun

818
00:26:26,400 --> 00:26:27,600
um but it's just really really bad when

819
00:26:27,600 --> 00:26:29,580
this stuff goes wrong and it lays the

820
00:26:29,580 --> 00:26:31,200
entire company bare because it's

821
00:26:31,200 --> 00:26:32,460
Authentication

822
00:26:32,460 --> 00:26:34,260
and have things been like good since

823
00:26:34,260 --> 00:26:37,980
2018 absolutely not 2019 to 2022 we see

824
00:26:37,980 --> 00:26:39,600
still thousands of these things there

825
00:26:39,600 --> 00:26:40,919
was one like the day I made the slide

826
00:26:40,919 --> 00:26:42,179
there was a new one which I thought

827
00:26:42,179 --> 00:26:44,460
about putting on it but I didn't so

828
00:26:44,460 --> 00:26:45,779
there's just a ton of stuff and it's not

829
00:26:45,779 --> 00:26:48,539
like these are open source uh developers

830
00:26:48,539 --> 00:26:50,760
like hobbyists like these are the

831
00:26:50,760 --> 00:26:51,779
companies you really really trust right

832
00:26:51,779 --> 00:26:53,520
Palo Alto networks Microsoft they're a

833
00:26:53,520 --> 00:26:55,980
big deal uh Sam was not the only one the

834
00:26:55,980 --> 00:26:57,419
much more widely deployed although

835
00:26:57,419 --> 00:26:59,279
younger example going on right now is

836
00:26:59,279 --> 00:27:01,380
oidc open ID connect built on oauth

837
00:27:01,380 --> 00:27:02,820
nothing is everywhere if you've ever

838
00:27:02,820 --> 00:27:03,900
logged into something through Google

839
00:27:03,900 --> 00:27:05,100
logged into something through Facebook

840
00:27:05,100 --> 00:27:07,200
oauth oidc

841
00:27:07,200 --> 00:27:08,940
same exact problems as Samuels just

842
00:27:08,940 --> 00:27:10,799
based on Json instead of XML but

843
00:27:10,799 --> 00:27:12,059
otherwise it's pretty much the same

844
00:27:12,059 --> 00:27:14,880
stuff and it's a disaster so again not

845
00:27:14,880 --> 00:27:16,559
saying don't use it not saying don't do

846
00:27:16,559 --> 00:27:19,980
it but understand the risks what all the

847
00:27:19,980 --> 00:27:21,900
the factors in play are and like make an

848
00:27:21,900 --> 00:27:24,840
informed decision is the idea here

849
00:27:24,840 --> 00:27:26,820
um I would say kind of my hot take on

850
00:27:26,820 --> 00:27:28,200
this whole thing is

851
00:27:28,200 --> 00:27:31,260
centralization is okay obviously there

852
00:27:31,260 --> 00:27:33,779
are upsides it improves manageability so

853
00:27:33,779 --> 00:27:35,580
it's great for it in that sense but for

854
00:27:35,580 --> 00:27:37,380
security if you can keep something

855
00:27:37,380 --> 00:27:38,940
separate so that at least there's no

856
00:27:38,940 --> 00:27:41,820
pivot from checking email to accessing

857
00:27:41,820 --> 00:27:43,799
the most sensitive Financial records of

858
00:27:43,799 --> 00:27:45,720
the company or production engineering or

859
00:27:45,720 --> 00:27:46,919
any of these other really sensitive

860
00:27:46,919 --> 00:27:49,620
things just my hot take if you do want

861
00:27:49,620 --> 00:27:51,419
to centralize stuff though you do kind

862
00:27:51,419 --> 00:27:53,760
of have some options so

863
00:27:53,760 --> 00:27:56,039
in the the vein of cryptographic Doom

864
00:27:56,039 --> 00:27:58,679
there are things you can do OCTA has

865
00:27:58,679 --> 00:27:59,940
basically web hooks for example that

866
00:27:59,940 --> 00:28:01,260
they make available we're not going to

867
00:28:01,260 --> 00:28:02,460
get into the details are kind of

868
00:28:02,460 --> 00:28:03,720
technical but if you're interested come

869
00:28:03,720 --> 00:28:05,400
by other each security booth like

870
00:28:05,400 --> 00:28:06,600
tomorrow I'll tell you what we do in

871
00:28:06,600 --> 00:28:08,460
reach to secure OCTA from itself so that

872
00:28:08,460 --> 00:28:10,260
even if all of their stuff breaks our

873
00:28:10,260 --> 00:28:11,940
logins are actually still secure it's

874
00:28:11,940 --> 00:28:13,980
possible to do it just requires some

875
00:28:13,980 --> 00:28:16,200
work so these things can be done so

876
00:28:16,200 --> 00:28:19,080
that's pretty good the the good news is

877
00:28:19,080 --> 00:28:20,460
all the stuff that Garrett talked about

878
00:28:20,460 --> 00:28:22,860
you can also still do so that even if

879
00:28:22,860 --> 00:28:24,840
you have SSO risk you have cryptographic

880
00:28:24,840 --> 00:28:27,539
risk you can still lock things down as

881
00:28:27,539 --> 00:28:29,400
much as possible to keep them reasonably

882
00:28:29,400 --> 00:28:31,260
secure I'm not going to talk about the

883
00:28:31,260 --> 00:28:33,419
same examples Garrett did because those

884
00:28:33,419 --> 00:28:35,279
are examples of how reach protects

885
00:28:35,279 --> 00:28:36,539
customers and the things we look at and

886
00:28:36,539 --> 00:28:38,640
recommend there but another cool thing

887
00:28:38,640 --> 00:28:39,960
we did with reach basically the first

888
00:28:39,960 --> 00:28:40,980
thing we did after we built it was

889
00:28:40,980 --> 00:28:42,659
pointed out itself so these are examples

890
00:28:42,659 --> 00:28:44,940
of how we use reach to secure reach

891
00:28:44,940 --> 00:28:46,620
these are the kinds of things the engine

892
00:28:46,620 --> 00:28:48,000
thinks about when we present it with

893
00:28:48,000 --> 00:28:49,440
security data and give it a problem to

894
00:28:49,440 --> 00:28:51,240
solve so I'll give you three options for

895
00:28:51,240 --> 00:28:54,419
the AWS example option number one

896
00:28:54,419 --> 00:28:57,120
MFA we've been crabbing on MFA for like

897
00:28:57,120 --> 00:28:58,500
the last 20 minutes like why are we

898
00:28:58,500 --> 00:28:59,940
mentioning it now there is that one form

899
00:28:59,940 --> 00:29:01,380
of MFA that is actually quite effective

900
00:29:01,380 --> 00:29:03,120
against phishing and that is web authent

901
00:29:03,120 --> 00:29:05,700
it's not entirely correct to say that

902
00:29:05,700 --> 00:29:07,200
100 blocks all fishing all the time

903
00:29:07,200 --> 00:29:09,659
that's actually not true but it's a

904
00:29:09,659 --> 00:29:10,980
reasonable approximation like that's

905
00:29:10,980 --> 00:29:12,900
basically the truth for any threat model

906
00:29:12,900 --> 00:29:15,600
you really care about so there is that

907
00:29:15,600 --> 00:29:17,220
and it's if you're willing to do it it's

908
00:29:17,220 --> 00:29:18,779
super useful you don't need to do it for

909
00:29:18,779 --> 00:29:20,220
the whole company if you have a thousand

910
00:29:20,220 --> 00:29:21,240
ten thousand a hundred thousand people

911
00:29:21,240 --> 00:29:22,799
like that's a lot of Hardware tokens for

912
00:29:22,799 --> 00:29:24,299
example to manage you might not want to

913
00:29:24,299 --> 00:29:25,860
do it nobody's going to blame you

914
00:29:25,860 --> 00:29:28,200
but there's probably between two and

915
00:29:28,200 --> 00:29:29,279
five percent of the company that

916
00:29:29,279 --> 00:29:30,779
actually has the super sensitive access

917
00:29:30,779 --> 00:29:32,399
that you care about so just do it for

918
00:29:32,399 --> 00:29:34,740
them you can assign them based on people

919
00:29:34,740 --> 00:29:36,120
groups to find an active directory you

920
00:29:36,120 --> 00:29:38,340
can assign it to the sensitive apps you

921
00:29:38,340 --> 00:29:39,960
have options so you can lock those

922
00:29:39,960 --> 00:29:41,039
things down to make them more secure

923
00:29:41,039 --> 00:29:42,960
that's the best option if you're willing

924
00:29:42,960 --> 00:29:45,360
to do the leg work but we got a couple

925
00:29:45,360 --> 00:29:47,760
more there's also

926
00:29:47,760 --> 00:29:49,860
separating the apps in single sign-on so

927
00:29:49,860 --> 00:29:51,360
that the single is no longer part of the

928
00:29:51,360 --> 00:29:53,039
equation so you can make it so that

929
00:29:53,039 --> 00:29:54,779
somebody can go log in check their email

930
00:29:54,779 --> 00:29:56,340
and then when they try to Pivot to a

931
00:29:56,340 --> 00:29:58,140
different application different resource

932
00:29:58,140 --> 00:30:00,059
they still have to log in again even if

933
00:30:00,059 --> 00:30:01,440
they just did it five minutes ago you

934
00:30:01,440 --> 00:30:02,880
can always require login always require

935
00:30:02,880 --> 00:30:04,559
MFA to that other thing that is not

936
00:30:04,559 --> 00:30:05,820
going to stop them from getting fished

937
00:30:05,820 --> 00:30:08,820
on either side but it will at least shut

938
00:30:08,820 --> 00:30:11,340
down the pivots from Office 365 or

939
00:30:11,340 --> 00:30:13,200
SharePoint or whatever into the

940
00:30:13,200 --> 00:30:14,520
sensitive data

941
00:30:14,520 --> 00:30:16,559
so it's somewhat useful but you can also

942
00:30:16,559 --> 00:30:19,080
take this a step further you can say

943
00:30:19,080 --> 00:30:21,120
add an additional Factor so maybe

944
00:30:21,120 --> 00:30:22,679
everybody uses Google Authenticator

945
00:30:22,679 --> 00:30:25,260
one-time password OTP to log into stuff

946
00:30:25,260 --> 00:30:26,880
by default but for the sensitive

947
00:30:26,880 --> 00:30:28,500
resources now they got to do something

948
00:30:28,500 --> 00:30:30,720
else they have to do octave verify push

949
00:30:30,720 --> 00:30:31,740
notification with the number challenge

950
00:30:31,740 --> 00:30:34,080
or something like that it's both

951
00:30:34,080 --> 00:30:36,059
effective in an absolute sense and then

952
00:30:36,059 --> 00:30:38,700
also just to sort of

953
00:30:38,700 --> 00:30:40,320
a side effect of the way things work

954
00:30:40,320 --> 00:30:42,240
most attacks are going to be completely

955
00:30:42,240 --> 00:30:44,340
broken just by the fact that you have a

956
00:30:44,340 --> 00:30:45,480
third Factor because the attackers

957
00:30:45,480 --> 00:30:47,220
weren't planning on that it breaks all

958
00:30:47,220 --> 00:30:48,539
the assumptions that they made in their

959
00:30:48,539 --> 00:30:50,100
attack and so it ends up just kind of

960
00:30:50,100 --> 00:30:53,100
working twice over which is is handy so

961
00:30:53,100 --> 00:30:55,919
again super useful options now

962
00:30:55,919 --> 00:30:59,700
none of this stuff is a shortcut it's

963
00:30:59,700 --> 00:31:03,260
not what was your thing

964
00:31:03,360 --> 00:31:04,980
yeah what was your name yeah it's not a

965
00:31:04,980 --> 00:31:07,080
bare minimum that's it it's not a very

966
00:31:07,080 --> 00:31:08,640
minimum and it's not once I see 12. it's

967
00:31:08,640 --> 00:31:11,039
it's tailored it's looking at your

968
00:31:11,039 --> 00:31:12,299
specific risks understanding your

969
00:31:12,299 --> 00:31:14,940
company choosing the right options for

970
00:31:14,940 --> 00:31:17,760
you and so if we were gonna Hazard an

971
00:31:17,760 --> 00:31:20,340
actual best practice it would be

972
00:31:20,340 --> 00:31:23,700
don't use the best practice measure cut

973
00:31:23,700 --> 00:31:25,679
like do the right thing for you

974
00:31:25,679 --> 00:31:27,840
uh but there is one more

975
00:31:27,840 --> 00:31:29,880
are we in time

976
00:31:29,880 --> 00:31:31,080
all right we're just going to keep going

977
00:31:31,080 --> 00:31:32,820
there's nobody after us so we can ride

978
00:31:32,820 --> 00:31:33,960
this thing till the wheels come off it's

979
00:31:33,960 --> 00:31:35,399
all good

980
00:31:35,399 --> 00:31:37,320
um one more thing not super serious well

981
00:31:37,320 --> 00:31:38,640
it's super serious but it's not super

982
00:31:38,640 --> 00:31:40,620
serious because it's not a ton that you

983
00:31:40,620 --> 00:31:42,539
would potentially do about it uh best

984
00:31:42,539 --> 00:31:45,120
practices are Big Brother

985
00:31:45,120 --> 00:31:47,340
uh you may be familiar with this example

986
00:31:47,340 --> 00:31:49,679
you may not it probably depends on how

987
00:31:49,679 --> 00:31:51,240
closely you followed all the Edward

988
00:31:51,240 --> 00:31:53,100
Snowden stuff when the data started to

989
00:31:53,100 --> 00:31:56,700
come out of that but in the early 2000s

990
00:31:56,700 --> 00:31:59,460
the NSA kind of wormed their way into a

991
00:31:59,460 --> 00:32:01,200
standardizing discussion around a new

992
00:32:01,200 --> 00:32:02,460
random number generator you may have

993
00:32:02,460 --> 00:32:04,860
heard of it it's called dual ecdrbg it's

994
00:32:04,860 --> 00:32:06,600
a dual elliptic curve deterministic

995
00:32:06,600 --> 00:32:09,779
random bit generator this is like

996
00:32:09,779 --> 00:32:12,000
I think it became standardized in 2004

997
00:32:12,000 --> 00:32:14,279
and ANSI x dot whatever standardization

998
00:32:14,279 --> 00:32:15,299
body

999
00:32:15,299 --> 00:32:17,159
so they went to a lot of trouble just to

1000
00:32:17,159 --> 00:32:18,960
get it standardized and then they went

1001
00:32:18,960 --> 00:32:21,779
over to RSA which used to be an

1002
00:32:21,779 --> 00:32:22,919
important company I actually have no

1003
00:32:22,919 --> 00:32:24,120
idea what they even do today but they

1004
00:32:24,120 --> 00:32:26,100
used to be kind of a big deal and they

1005
00:32:26,100 --> 00:32:27,600
paid them 10 million dollars to make

1006
00:32:27,600 --> 00:32:29,580
this random number generator the default

1007
00:32:29,580 --> 00:32:32,820
uh for be safe which was kind of the

1008
00:32:32,820 --> 00:32:35,100
industry standard for fips 142 validated

1009
00:32:35,100 --> 00:32:36,480
cryptographic modules which if you do

1010
00:32:36,480 --> 00:32:38,159
any government work like you know what a

1011
00:32:38,159 --> 00:32:40,080
pain fips is and you've experienced this

1012
00:32:40,080 --> 00:32:42,120
if not just understand that

1013
00:32:42,120 --> 00:32:43,860
cryptography is always a pain but it's

1014
00:32:43,860 --> 00:32:44,940
particularly a pain when you want to

1015
00:32:44,940 --> 00:32:46,140
sell to the government because they have

1016
00:32:46,140 --> 00:32:48,419
requirements governments are weird like

1017
00:32:48,419 --> 00:32:51,659
that so they paid RSA 10 million dollars

1018
00:32:51,659 --> 00:32:52,380
um

1019
00:32:52,380 --> 00:32:53,880
they got it in there as the default of

1020
00:32:53,880 --> 00:32:57,779
be safe and there was a period of like

1021
00:32:57,779 --> 00:32:59,700
I guess it would have been nine ten

1022
00:32:59,700 --> 00:33:01,799
years where in theory

1023
00:33:01,799 --> 00:33:03,179
because they controlled the random

1024
00:33:03,179 --> 00:33:04,860
number generator and therefore could

1025
00:33:04,860 --> 00:33:06,720
predict what random numbers were going

1026
00:33:06,720 --> 00:33:08,220
to be generated they could decrypt all

1027
00:33:08,220 --> 00:33:09,539
the traffic they could do whatever they

1028
00:33:09,539 --> 00:33:12,179
want that stuff and uh complete

1029
00:33:12,179 --> 00:33:13,860
visibility into anything most

1030
00:33:13,860 --> 00:33:14,880
interesting Fallout from this whole

1031
00:33:14,880 --> 00:33:16,200
thing was that Juniper was actually

1032
00:33:16,200 --> 00:33:17,880
affected so at one point all Juniper

1033
00:33:17,880 --> 00:33:19,679
well actually for like a decade Juniper

1034
00:33:19,679 --> 00:33:21,419
firewalls were backdoored and the wrong

1035
00:33:21,419 --> 00:33:22,679
person could decrypt all that stuff

1036
00:33:22,679 --> 00:33:24,120
which is super fun that's what you want

1037
00:33:24,120 --> 00:33:26,340
from your security vendor so

1038
00:33:26,340 --> 00:33:29,100
that's it for us Jason take a picture

1039
00:33:29,100 --> 00:33:30,600
even though there's no light it's not

1040
00:33:30,600 --> 00:33:32,399
going to be a very good picture

1041
00:33:32,399 --> 00:33:35,220
get up here you want this slide Pulp

1042
00:33:35,220 --> 00:33:36,779
Fiction slide everybody loves Pulp

1043
00:33:36,779 --> 00:33:39,360
Fiction if not get out we don't want you

1044
00:33:39,360 --> 00:33:41,600
here

1045
00:33:43,140 --> 00:33:45,659
all right that's gonna be dark as hell

1046
00:33:45,659 --> 00:33:46,679
um

1047
00:33:46,679 --> 00:33:47,940
if you have questions of course we're

1048
00:33:47,940 --> 00:33:49,260
happy to talk more best practices come

1049
00:33:49,260 --> 00:33:50,820
up to us after that's fine otherwise

1050
00:33:50,820 --> 00:33:52,500
thank you for showing up at the end of

1051
00:33:52,500 --> 00:33:54,120
the day hopefully you're a little more

1052
00:33:54,120 --> 00:33:55,919
awake than we are right now and uh come

1053
00:33:55,919 --> 00:33:57,000
find us at the booth we're in number

1054
00:33:57,000 --> 00:33:59,220
four uh one floor down we'll be around

1055
00:33:59,220 --> 00:34:03,310
until the thing closes thanks guys

1056
00:34:03,310 --> 00:34:06,909
[Applause]

