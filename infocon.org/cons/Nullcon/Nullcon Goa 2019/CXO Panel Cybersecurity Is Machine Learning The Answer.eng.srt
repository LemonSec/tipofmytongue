1
00:00:02,639 --> 00:00:07,089
so we are back after the short D break

2
00:00:05,170 --> 00:00:09,730
to witness the last but not the least

3
00:00:07,089 --> 00:00:11,530
boardroom discussion for the table it is

4
00:00:09,730 --> 00:00:13,450
pretty interesting to note debates on

5
00:00:11,530 --> 00:00:15,428
whether machine learning can train

6
00:00:13,450 --> 00:00:17,830
intelligent systems to crack jokes but

7
00:00:15,429 --> 00:00:20,350
today we look forward to an interesting

8
00:00:17,830 --> 00:00:22,448
debate on is machine learning the answer

9
00:00:20,350 --> 00:00:24,250
to cybersecurity and for this boredom

10
00:00:22,449 --> 00:00:26,710
discussion that will tickle your little

11
00:00:24,250 --> 00:00:29,019
gray cells we have with us a moderator

12
00:00:26,710 --> 00:00:30,699
Rahul Shashi founder and chief

13
00:00:29,019 --> 00:00:32,680
technology officer of the artificial

14
00:00:30,699 --> 00:00:34,960
intelligence based information security

15
00:00:32,680 --> 00:00:37,600
company cloud SEC and Indian on subpoena

16
00:00:34,960 --> 00:00:39,430
security expert white hat hacker and a

17
00:00:37,600 --> 00:00:42,100
very popular speaker at Alcorn we

18
00:00:39,430 --> 00:00:44,440
welcome you so our panelists for this

19
00:00:42,100 --> 00:00:46,600
discussion are soomi's Kulkarni

20
00:00:44,440 --> 00:00:49,149
chief information security officer at

21
00:00:46,600 --> 00:00:50,920
instars pharmaceuticals Limited he is

22
00:00:49,149 --> 00:00:53,649
responsible for corporate information

23
00:00:50,920 --> 00:00:55,059
security risk assessment Incident

24
00:00:53,649 --> 00:00:58,930
Response internal audit and compliance

25
00:00:55,059 --> 00:01:01,690
activities including ISO 27001 Indian IG

26
00:00:58,930 --> 00:01:03,760
Act and GDP are on a global scale next

27
00:01:01,690 --> 00:01:05,378
we have with us Satish bahara head of

28
00:01:03,760 --> 00:01:08,259
platform infrastructure and cyber

29
00:01:05,379 --> 00:01:10,420
security at Bank bazaar he has over 14

30
00:01:08,260 --> 00:01:12,850
years of proven success in developing

31
00:01:10,420 --> 00:01:15,189
managing in advising global enterprise

32
00:01:12,850 --> 00:01:16,750
clients and technology platforms cyber

33
00:01:15,189 --> 00:01:18,850
strategy and enterprise security

34
00:01:16,750 --> 00:01:21,130
architecture finally we have with us

35
00:01:18,850 --> 00:01:23,710
Reba sauce chief information officer

36
00:01:21,130 --> 00:01:25,899
hydrocarbons and group head reliance

37
00:01:23,710 --> 00:01:28,240
internal audit Reliance Industries he

38
00:01:25,900 --> 00:01:30,820
has a career of more than 21 years in

39
00:01:28,240 --> 00:01:32,619
financial and IT audit advisory and risk

40
00:01:30,820 --> 00:01:34,600
management roles and has the group head

41
00:01:32,619 --> 00:01:36,400
of corporate an IT audit and audit

42
00:01:34,600 --> 00:01:38,259
operations while working at Shell he

43
00:01:36,400 --> 00:01:40,270
also implemented continuous auditing and

44
00:01:38,259 --> 00:01:42,070
data analytics techniques to improve the

45
00:01:40,270 --> 00:01:44,170
efficiency and effectiveness of process

46
00:01:42,070 --> 00:01:45,429
controls testing we welcome you all

47
00:01:44,170 --> 00:01:49,350
could we have a round of applause for

48
00:01:45,430 --> 00:01:51,290
everyone over you round

49
00:01:49,350 --> 00:01:54,089
[Applause]

50
00:01:51,290 --> 00:01:54,990
hey guys thanks a lot for the

51
00:01:54,090 --> 00:01:58,680
introduction Angelina

52
00:01:54,990 --> 00:02:00,630
so the idea we just discussed is in

53
00:01:58,680 --> 00:02:01,409
Dudley and the idea is to make it much

54
00:02:00,630 --> 00:02:04,048
free-flowing

55
00:02:01,409 --> 00:02:05,640
which means will I mean we will talk

56
00:02:04,049 --> 00:02:07,680
maybe for 50 minutes and then we'll open

57
00:02:05,640 --> 00:02:08,940
it for questions that way you know this

58
00:02:07,680 --> 00:02:10,800
is a community when right that's all

59
00:02:08,940 --> 00:02:13,680
null conspirator was all about so we

60
00:02:10,800 --> 00:02:15,300
will make sure you communicate to us and

61
00:02:13,680 --> 00:02:17,130
then you know if you can answer those

62
00:02:15,300 --> 00:02:19,020
questions you know that way it will be

63
00:02:17,130 --> 00:02:22,230
more fun that's what you know we think

64
00:02:19,020 --> 00:02:23,760
we will do so obviously that the topic

65
00:02:22,230 --> 00:02:27,510
of discussion is machine learning and

66
00:02:23,760 --> 00:02:30,000
artificial intelligence I'll start with

67
00:02:27,510 --> 00:02:31,649
with throwing a question at the panel

68
00:02:30,000 --> 00:02:33,000
about you know what what is their

69
00:02:31,650 --> 00:02:35,040
perspective of machine learning and

70
00:02:33,000 --> 00:02:36,209
artificial intelligences and you know I

71
00:02:35,040 --> 00:02:40,048
mean maybe a little bit of introduction

72
00:02:36,209 --> 00:02:41,760
would actually help us understand you

73
00:02:40,049 --> 00:02:43,769
know because everyone uses this word

74
00:02:41,760 --> 00:02:45,870
right in the inefficient machine

75
00:02:43,769 --> 00:02:47,130
learning and if every startup in my my

76
00:02:45,870 --> 00:02:49,170
own startup actually uses that

77
00:02:47,130 --> 00:02:50,970
particular thing everywhere so it's it's

78
00:02:49,170 --> 00:02:52,500
very important to understand have a bit

79
00:02:50,970 --> 00:02:54,780
of introduction about those and then we

80
00:02:52,500 --> 00:02:58,430
will go into questions the SUNY so you

81
00:02:54,780 --> 00:03:01,260
want to start with your your yes yes

82
00:02:58,430 --> 00:03:02,670
yeah so I think though you have asked me

83
00:03:01,260 --> 00:03:04,590
but I want to pass it to the audience

84
00:03:02,670 --> 00:03:06,809
first I think we have been a very nice

85
00:03:04,590 --> 00:03:09,359
sessions earlier the breach response is

86
00:03:06,810 --> 00:03:11,910
as well as the the CI a-- part of it and

87
00:03:09,359 --> 00:03:13,560
i think we really want to either out

88
00:03:11,910 --> 00:03:15,060
mention that we really want it to be

89
00:03:13,560 --> 00:03:20,480
more interactive and more knowledgeable

90
00:03:15,060 --> 00:03:22,920
session so i think how many of the

91
00:03:20,480 --> 00:03:25,738
people sitting here knows about the

92
00:03:22,920 --> 00:03:27,179
differences between the AI and the ml i

93
00:03:25,739 --> 00:03:29,910
mean except the alphabet difference

94
00:03:27,180 --> 00:03:31,380
that's all I mean so I mean so I just

95
00:03:29,910 --> 00:03:34,200
want to know anybody can talk just

96
00:03:31,380 --> 00:03:36,000
anything I mean we all know the full

97
00:03:34,200 --> 00:03:39,410
forms obviously say artificial

98
00:03:36,000 --> 00:03:39,410
intelligence and the machine learning

99
00:03:40,820 --> 00:03:58,280
all right there is one response what

100
00:03:43,440 --> 00:04:00,050
else all right so any any

101
00:03:58,280 --> 00:04:05,900
difference between the AI and the ML

102
00:04:00,050 --> 00:04:08,620
part of it anybody can just very nice

103
00:04:05,900 --> 00:04:08,620
nice thought

104
00:04:12,130 --> 00:04:27,530
nice nice Google answers it's a good one

105
00:04:17,709 --> 00:04:28,700
anything else all right so good one so

106
00:04:27,530 --> 00:04:31,039
the reason I ask because I don't know

107
00:04:28,700 --> 00:04:45,409
the difference so that was just Assad

108
00:04:31,040 --> 00:04:46,640
with XI learning is like the foundation

109
00:04:45,410 --> 00:04:48,470
of AI okay

110
00:04:46,640 --> 00:04:49,640
yeah she learning has two components

111
00:04:48,470 --> 00:04:51,350
supervised and unsupervised learning

112
00:04:49,640 --> 00:04:53,510
does the main model that you're looking

113
00:04:51,350 --> 00:04:55,100
at what happens is once you get machine

114
00:04:53,510 --> 00:04:57,349
learning up to certain level maturity

115
00:04:55,100 --> 00:04:59,990
you move it from telling you something

116
00:04:57,350 --> 00:05:01,280
to actually taking a decision hey I get

117
00:04:59,990 --> 00:05:03,140
you to the point where it's taking

118
00:05:01,280 --> 00:05:05,750
decisions big difference is the

119
00:05:03,140 --> 00:05:07,310
decision-making yeah okay that's the

120
00:05:05,750 --> 00:05:09,080
main difference between a suit okay

121
00:05:07,310 --> 00:05:11,030
machine learning is just awareness and

122
00:05:09,080 --> 00:05:13,310
understand when you take this the next

123
00:05:11,030 --> 00:05:15,200
level which is you apply some logic or

124
00:05:13,310 --> 00:05:17,180
some rules hips to take a decision or do

125
00:05:15,200 --> 00:05:23,020
some action you know to this the minor

126
00:05:17,180 --> 00:05:23,020
area okay so it goes all the way

127
00:05:24,039 --> 00:05:27,880
generally no but as you can you can

128
00:05:27,050 --> 00:05:30,229
actually take it to the next level

129
00:05:27,880 --> 00:05:32,810
machine learning has its limitations

130
00:05:30,229 --> 00:05:35,150
yeah we can get it to the topic at hand

131
00:05:32,810 --> 00:05:36,470
now I think I we about earlier with the

132
00:05:35,150 --> 00:05:38,330
cyber secure and I guess this is a

133
00:05:36,470 --> 00:05:39,710
machine learning discussion okay she

134
00:05:38,330 --> 00:05:43,430
learning has its own limitations will

135
00:05:39,710 --> 00:05:47,930
get it to make things very simple and in

136
00:05:43,430 --> 00:05:50,300
elements term see today's word we have

137
00:05:47,930 --> 00:05:54,590
lot of data lot of work to do and

138
00:05:50,300 --> 00:05:58,280
anything which is repeatable and which

139
00:05:54,590 --> 00:06:01,460
has a predictable outcome we teach the

140
00:05:58,280 --> 00:06:04,219
machine to do so going back 30 years

141
00:06:01,460 --> 00:06:05,840
back right or maybe like hundred years

142
00:06:04,220 --> 00:06:09,890
back when you have Industrial Revolution

143
00:06:05,840 --> 00:06:10,739
what it did is basically human being was

144
00:06:09,890 --> 00:06:13,800
working

145
00:06:10,740 --> 00:06:17,550
and we created machines and machines

146
00:06:13,800 --> 00:06:20,370
were able to do repeated work at a

147
00:06:17,550 --> 00:06:23,699
larger scale and they didn't complain

148
00:06:20,370 --> 00:06:28,620
and they didn't add asleep they can work

149
00:06:23,699 --> 00:06:30,479
24 by 7 right and today's would you you

150
00:06:28,620 --> 00:06:33,389
imagine like you know there there is a

151
00:06:30,479 --> 00:06:35,669
soft so there is a huge amount of people

152
00:06:33,389 --> 00:06:38,880
maybe like you know 20 or 30 or maybe

153
00:06:35,669 --> 00:06:42,270
hundred people who are monitoring your

154
00:06:38,880 --> 00:06:46,229
logs your graphs or something imagine

155
00:06:42,270 --> 00:06:48,630
this there are certain patterns and if I

156
00:06:46,229 --> 00:06:51,419
can teach the pattern per machine

157
00:06:48,630 --> 00:06:54,360
I don't need to have a bigger Sobti

158
00:06:51,419 --> 00:06:57,710
I need to look into the outcomes of the

159
00:06:54,360 --> 00:07:01,530
machine what it is showing me as an only

160
00:06:57,710 --> 00:07:04,560
in a you know in a prospective similarly

161
00:07:01,530 --> 00:07:08,520
machine learning is just repetitive or

162
00:07:04,560 --> 00:07:10,740
automation however if the machine can

163
00:07:08,520 --> 00:07:14,698
take a decision whether say this is

164
00:07:10,740 --> 00:07:17,280
anomaly or not that is a I all right so

165
00:07:14,699 --> 00:07:21,090
I think let me I think let me simplify

166
00:07:17,280 --> 00:07:24,000
it AI is more focused on the success

167
00:07:21,090 --> 00:07:26,039
part of it while machine learning is

168
00:07:24,000 --> 00:07:29,520
more focused on the accuracy part of it

169
00:07:26,039 --> 00:07:32,039
I mean both are two sides of a coin I

170
00:07:29,520 --> 00:07:34,560
mean you cannot exactly extensions you

171
00:07:32,039 --> 00:07:36,719
can't really separate them if you really

172
00:07:34,560 --> 00:07:37,919
need a right successful result so I

173
00:07:36,719 --> 00:07:41,099
think I'm going to read out something

174
00:07:37,919 --> 00:07:45,000
that I've written three lines machine

175
00:07:41,099 --> 00:07:50,430
learning is about finding the patterns

176
00:07:45,000 --> 00:07:52,349
in the data so that the outcome is more

177
00:07:50,430 --> 00:07:55,979
predictive that is something what it is

178
00:07:52,349 --> 00:07:58,979
all about yes in a way right I mean

179
00:07:55,979 --> 00:08:00,870
everyone has said one thing if we have a

180
00:07:58,979 --> 00:08:03,120
large amount of data and machine

181
00:08:00,870 --> 00:08:05,849
learnings job is to tell you out of that

182
00:08:03,120 --> 00:08:07,860
large amount of data which is that data

183
00:08:05,849 --> 00:08:12,150
you should be looking at for it suddenly

184
00:08:07,860 --> 00:08:14,370
you have 100 100 network connections in

185
00:08:12,150 --> 00:08:15,599
your sock and out of those 100 if you

186
00:08:14,370 --> 00:08:17,009
want to figure out which one is

187
00:08:15,599 --> 00:08:20,099
malicious yes you can use machine

188
00:08:17,009 --> 00:08:21,690
learning now if we go step about say you

189
00:08:20,099 --> 00:08:23,099
know I I just don't need to predict

190
00:08:21,690 --> 00:08:23,490
which is thread and which is not a

191
00:08:23,099 --> 00:08:24,640
thread

192
00:08:23,490 --> 00:08:27,340
I need a product

193
00:08:24,640 --> 00:08:29,680
which have which has a correlation with

194
00:08:27,340 --> 00:08:31,239
something else and some historical data

195
00:08:29,680 --> 00:08:33,159
and present you with something a little

196
00:08:31,240 --> 00:08:35,980
more valuable a decision-making process

197
00:08:33,159 --> 00:08:37,569
that will go into AI so that's that's

198
00:08:35,980 --> 00:08:39,490
pretty much in the cybersecurity world

199
00:08:37,570 --> 00:08:42,280
how it would be and I think I think you

200
00:08:39,490 --> 00:08:43,919
know it's good to start that now we have

201
00:08:42,280 --> 00:08:47,709
a great introduction on machine learning

202
00:08:43,919 --> 00:08:49,569
so uh I mean so one of the perspectives

203
00:08:47,710 --> 00:08:51,850
we you know we're trying to cover here

204
00:08:49,570 --> 00:08:53,850
is from a vendor who is building a

205
00:08:51,850 --> 00:08:57,370
software in machine learning and AI and

206
00:08:53,850 --> 00:09:00,250
to industry leaders like in the pharma

207
00:08:57,370 --> 00:09:01,930
and alliance who is adopting fiber

208
00:09:00,250 --> 00:09:03,850
security solutions powered by machine

209
00:09:01,930 --> 00:09:07,030
learning so what is your decision making

210
00:09:03,850 --> 00:09:09,370
process waters deep the evaluation

211
00:09:07,030 --> 00:09:11,230
criteria you guys follow when a vendor

212
00:09:09,370 --> 00:09:12,640
comes and pitches you with machine

213
00:09:11,230 --> 00:09:14,560
learning solutions how do you decide

214
00:09:12,640 --> 00:09:16,330
which one to go for and which one not to

215
00:09:14,560 --> 00:09:19,780
go for because every one every every

216
00:09:16,330 --> 00:09:20,890
vendor have this right now right so how

217
00:09:19,780 --> 00:09:23,740
do you make that this is the first

218
00:09:20,890 --> 00:09:24,970
questions so we this is to two questions

219
00:09:23,740 --> 00:09:26,740
your first principles

220
00:09:24,970 --> 00:09:28,210
okay is this a solution looking for a

221
00:09:26,740 --> 00:09:29,770
problem which is the problem I'm looking

222
00:09:28,210 --> 00:09:31,480
for a solution for I think good good

223
00:09:29,770 --> 00:09:33,460
good good first to the question yeah I

224
00:09:31,480 --> 00:09:36,460
see too many solutions looking for

225
00:09:33,460 --> 00:09:38,740
problems okay the second thing is to

226
00:09:36,460 --> 00:09:41,350
understand what technology actually does

227
00:09:38,740 --> 00:09:43,450
okay machine learning AI any technology

228
00:09:41,350 --> 00:09:45,610
is actually enabler to get starting time

229
00:09:43,450 --> 00:09:49,120
and all technology actually comes down

230
00:09:45,610 --> 00:09:51,940
to three things technologies and amplify

231
00:09:49,120 --> 00:09:56,190
what you know what you can learn okay

232
00:09:51,940 --> 00:09:59,770
they amplify what you can execute or do

233
00:09:56,190 --> 00:10:03,210
tasks as actions and they can amplify

234
00:09:59,770 --> 00:10:06,340
what you can communicate or share okay

235
00:10:03,210 --> 00:10:08,910
all technology touches on one of these

236
00:10:06,340 --> 00:10:11,320
three domains high-tech machinery

237
00:10:08,910 --> 00:10:14,260
machine learning helps you learn

238
00:10:11,320 --> 00:10:16,360
understand gain knowledge in a massive

239
00:10:14,260 --> 00:10:18,760
form by being able to process all the

240
00:10:16,360 --> 00:10:20,770
data all the insights information based

241
00:10:18,760 --> 00:10:23,590
on data to gain insights you go from

242
00:10:20,770 --> 00:10:26,170
data which is input to insights

243
00:10:23,590 --> 00:10:27,790
what's the insights it's this supervised

244
00:10:26,170 --> 00:10:29,500
or unsupervised learning it says okay

245
00:10:27,790 --> 00:10:31,270
based on the patterns I've discovered in

246
00:10:29,500 --> 00:10:33,640
this data these are the natural

247
00:10:31,270 --> 00:10:36,430
relationships that I'm finding in the

248
00:10:33,640 --> 00:10:37,770
data that's inside that says listen if

249
00:10:36,430 --> 00:10:40,620
you get this type of data

250
00:10:37,770 --> 00:10:42,360
this is an indicator of something else a

251
00:10:40,620 --> 00:10:45,630
predictor or an outcome

252
00:10:42,360 --> 00:10:47,820
okay now machine learning gets you to

253
00:10:45,630 --> 00:10:48,930
that point so what I try to do is to

254
00:10:47,820 --> 00:10:50,790
understand what does this solution

255
00:10:48,930 --> 00:10:55,410
actually do so what is it you selling me

256
00:10:50,790 --> 00:10:56,939
okay okay the second part of the problem

257
00:10:55,410 --> 00:10:57,620
is when I look at the solution and say

258
00:10:56,940 --> 00:11:00,060
okay fine

259
00:10:57,620 --> 00:11:02,010
most of these machine learning solutions

260
00:11:00,060 --> 00:11:03,420
have natural limitations

261
00:11:02,010 --> 00:11:05,580
I can talk to you what what those

262
00:11:03,420 --> 00:11:08,069
limitations are the first one is

263
00:11:05,580 --> 00:11:10,980
limitations on inputs as in garbage in

264
00:11:08,070 --> 00:11:12,540
garbage out okay and how machine

265
00:11:10,980 --> 00:11:14,970
learning solutions have this problem

266
00:11:12,540 --> 00:11:16,620
okay so at least you have good data

267
00:11:14,970 --> 00:11:18,390
you're gonna get you won't get good

268
00:11:16,620 --> 00:11:20,340
results today so does that mean the

269
00:11:18,390 --> 00:11:21,930
quality of data matters a lot

270
00:11:20,340 --> 00:11:23,250
passing is the passing to the algorithm

271
00:11:21,930 --> 00:11:24,810
right of course it does because it

272
00:11:23,250 --> 00:11:26,640
influences how the machine learning

273
00:11:24,810 --> 00:11:27,959
algorithms develop you remember and

274
00:11:26,640 --> 00:11:30,360
machine learning algorithm is not static

275
00:11:27,960 --> 00:11:31,590
League learns it evolves at the time the

276
00:11:30,360 --> 00:11:32,850
second one is what is called the

277
00:11:31,590 --> 00:11:35,310
constraints with the boundary condition

278
00:11:32,850 --> 00:11:37,350
so we use a bunch of algorithms on mini

279
00:11:35,310 --> 00:11:39,000
areas around the field whether it's an

280
00:11:37,350 --> 00:11:41,400
optimization model with this prediction

281
00:11:39,000 --> 00:11:44,460
model always a sentiment analysis they

282
00:11:41,400 --> 00:11:47,520
all have boundary constraints these are

283
00:11:44,460 --> 00:11:49,200
assumptions which you are assuming into

284
00:11:47,520 --> 00:11:51,840
that model because what you're using

285
00:11:49,200 --> 00:11:53,310
using the model to reflect the real

286
00:11:51,840 --> 00:11:55,170
world something that's happening in the

287
00:11:53,310 --> 00:11:56,819
real world is having to be modeled in

288
00:11:55,170 --> 00:11:57,780
that machine level algorithm because

289
00:11:56,820 --> 00:11:59,940
that's what you're looking at you look

290
00:11:57,780 --> 00:12:02,790
at does this algorithm correctly reflect

291
00:11:59,940 --> 00:12:04,170
the real world okay second part of the

292
00:12:02,790 --> 00:12:06,329
problem you find is those assumptions

293
00:12:04,170 --> 00:12:08,160
use the order problem as in they don't

294
00:12:06,330 --> 00:12:10,170
really reflect the assumptions you have

295
00:12:08,160 --> 00:12:11,699
in the real world second issue are

296
00:12:10,170 --> 00:12:14,459
understood within the solution you're

297
00:12:11,700 --> 00:12:16,350
looking at the third one is actually

298
00:12:14,460 --> 00:12:17,670
okay so what is the output of this thing

299
00:12:16,350 --> 00:12:21,030
what is the software actually do for me

300
00:12:17,670 --> 00:12:23,250
okay is the output something that is

301
00:12:21,030 --> 00:12:24,720
actionable and this to me is the big

302
00:12:23,250 --> 00:12:27,570
difference when you start to switch from

303
00:12:24,720 --> 00:12:30,750
machine learning into AI okay most

304
00:12:27,570 --> 00:12:31,980
resilient link solutions require given

305
00:12:30,750 --> 00:12:33,780
outcome it requires a human

306
00:12:31,980 --> 00:12:35,340
interpretation so someone has to make a

307
00:12:33,780 --> 00:12:38,760
judgment on what that machine learning

308
00:12:35,340 --> 00:12:40,740
model is doing because very few models

309
00:12:38,760 --> 00:12:43,230
can truly reflect them on the real world

310
00:12:40,740 --> 00:12:45,510
so the human brain is still

311
00:12:43,230 --> 00:12:48,090
fundamentally important to do a sanity

312
00:12:45,510 --> 00:12:51,210
check on whether that outcome is

313
00:12:48,090 --> 00:12:52,950
actually reasonable realistic

314
00:12:51,210 --> 00:12:55,950
it's goes to the question that's

315
00:12:52,950 --> 00:12:58,440
machinery replaceable security no no

316
00:12:55,950 --> 00:13:01,200
because you still need the human context

317
00:12:58,440 --> 00:13:04,080
of looking that outcome this is the

318
00:13:01,200 --> 00:13:06,030
reality you can train machine learning

319
00:13:04,080 --> 00:13:08,730
models and they take a very long time to

320
00:13:06,030 --> 00:13:11,370
train and require huge amounts of data

321
00:13:08,730 --> 00:13:13,260
to actually become perfected okay

322
00:13:11,370 --> 00:13:15,930
so machine learning models really

323
00:13:13,260 --> 00:13:17,370
involved I mean all of us have many of

324
00:13:15,930 --> 00:13:18,900
these large corporates are building and

325
00:13:17,370 --> 00:13:21,630
evolving this machine learning models

326
00:13:18,900 --> 00:13:24,930
today it will always take us two three

327
00:13:21,630 --> 00:13:27,810
four years of information to able to get

328
00:13:24,930 --> 00:13:30,239
us the model that's correct okay that is

329
00:13:27,810 --> 00:13:32,130
why it takes us a long time to sort out

330
00:13:30,240 --> 00:13:33,870
false positives you guys understand the

331
00:13:32,130 --> 00:13:35,280
concept of false positives machine

332
00:13:33,870 --> 00:13:37,200
learning has got false positives which

333
00:13:35,280 --> 00:13:38,790
is why you train it this is called

334
00:13:37,200 --> 00:13:40,560
supervised learning to train the model

335
00:13:38,790 --> 00:13:42,240
this is right this is wrong

336
00:13:40,560 --> 00:13:46,709
that training or the model is the

337
00:13:42,240 --> 00:13:50,490
problem okay I just want to add to it

338
00:13:46,710 --> 00:13:55,110
also like whatever we are talking today

339
00:13:50,490 --> 00:13:57,870
mostly supervised moves but the real AI

340
00:13:55,110 --> 00:14:00,630
I see is more into unsupervised form

341
00:13:57,870 --> 00:14:02,340
that's where the intelligence of the

342
00:14:00,630 --> 00:14:05,460
machine comes in the picture it can take

343
00:14:02,340 --> 00:14:09,060
its own regime right the supervised mode

344
00:14:05,460 --> 00:14:13,470
is something like you can say that it's

345
00:14:09,060 --> 00:14:16,260
your experience so I always give analogy

346
00:14:13,470 --> 00:14:17,280
like you know what is a bad day and what

347
00:14:16,260 --> 00:14:22,460
is a good guy

348
00:14:17,280 --> 00:14:26,130
it bad day is mostly a person who has

349
00:14:22,460 --> 00:14:28,910
experienced bad things in Islam he has

350
00:14:26,130 --> 00:14:33,540
learned the bad things how to execute

351
00:14:28,910 --> 00:14:34,980
something in a bad way a good day has

352
00:14:33,540 --> 00:14:37,709
seen a brighter sight

353
00:14:34,980 --> 00:14:39,750
maybe like you know we say this as a we

354
00:14:37,710 --> 00:14:42,480
are categorizing this activity to be as

355
00:14:39,750 --> 00:14:45,900
good or bad right this is called packing

356
00:14:42,480 --> 00:14:47,820
this is super biased means this is our

357
00:14:45,900 --> 00:14:50,490
experience and depending on this

358
00:14:47,820 --> 00:14:54,060
experience whenever there is a situation

359
00:14:50,490 --> 00:14:56,310
which comes this 15 20 or maybe 30 40

360
00:14:54,060 --> 00:15:00,270
years of experience helps you to take a

361
00:14:56,310 --> 00:15:02,969
decision now nobody knows whether this

362
00:15:00,270 --> 00:15:05,130
decision is right or wrong for me my

363
00:15:02,970 --> 00:15:07,980
perception this is right

364
00:15:05,130 --> 00:15:11,220
because these are tagged as right things

365
00:15:07,980 --> 00:15:15,480
to do but there is nothing called right

366
00:15:11,220 --> 00:15:17,760
or wrong so you know even if you pack

367
00:15:15,480 --> 00:15:22,350
your data even if you do a supervised

368
00:15:17,760 --> 00:15:25,710
learning you still have not achieved

369
00:15:22,350 --> 00:15:29,250
100% efficiency even if you tell that

370
00:15:25,710 --> 00:15:31,080
this scenario is good and this scenario

371
00:15:29,250 --> 00:15:35,280
is bad and you have millions of

372
00:15:31,080 --> 00:15:37,500
scenarios like that we cannot be 99%

373
00:15:35,280 --> 00:15:39,689
efficient then she cannot achieve yes

374
00:15:37,500 --> 00:15:42,090
that's where I disagree with you in in a

375
00:15:39,690 --> 00:15:43,650
way I mean I agree also as disagree also

376
00:15:42,090 --> 00:15:46,320
remember the example I was talking about

377
00:15:43,650 --> 00:15:48,240
see with both Rui and so they share is

378
00:15:46,320 --> 00:15:50,550
one thing you know one you need a large

379
00:15:48,240 --> 00:15:53,280
amount of data to train and get this

380
00:15:50,550 --> 00:15:55,530
system smarter second is the data needs

381
00:15:53,280 --> 00:15:57,540
to be quality in the data needs to be

382
00:15:55,530 --> 00:15:59,579
tracked properly to get reliable results

383
00:15:57,540 --> 00:16:01,709
very important it very important so I

384
00:15:59,580 --> 00:16:03,660
mean to add to that particular thing

385
00:16:01,710 --> 00:16:06,060
right I mean this is a meme hood going

386
00:16:03,660 --> 00:16:07,530
on over the Internet which says if for

387
00:16:06,060 --> 00:16:10,739
machine learning models are asked to

388
00:16:07,530 --> 00:16:12,689
jump into a well and for babies human

389
00:16:10,740 --> 00:16:13,980
babies are asked to jump into a well the

390
00:16:12,690 --> 00:16:15,300
machine learning models will jump into

391
00:16:13,980 --> 00:16:17,400
the well because that's what the data

392
00:16:15,300 --> 00:16:19,770
set and the humans won't jump into the

393
00:16:17,400 --> 00:16:23,069
well because you know they have more

394
00:16:19,770 --> 00:16:24,060
logic but this is the argument I had but

395
00:16:23,070 --> 00:16:26,430
that's not how it is

396
00:16:24,060 --> 00:16:29,989
how many of you have babies how babies

397
00:16:26,430 --> 00:16:29,989
or have fina baby

398
00:16:37,670 --> 00:16:46,500
or maybe thinking of having babies ready

399
00:16:41,150 --> 00:16:48,660
so if you see the big so have you seen

400
00:16:46,500 --> 00:16:50,430
the babies right when the babies when

401
00:16:48,660 --> 00:16:52,290
they cry you lift them up a little bit

402
00:16:50,430 --> 00:16:54,270
and the babies will stop time you lift

403
00:16:52,290 --> 00:16:55,860
them up and you start moving around the

404
00:16:54,270 --> 00:16:58,530
babies will completely stop crying let's

405
00:16:55,860 --> 00:17:02,610
have you you know stop babies crying you

406
00:16:58,530 --> 00:17:03,810
know how the sinus and why does it do

407
00:17:02,610 --> 00:17:05,880
that when you lift up and start walking

408
00:17:03,810 --> 00:17:08,669
why would why do babies stop crying

409
00:17:05,880 --> 00:17:11,010
the way scientists figured this out is

410
00:17:08,670 --> 00:17:13,079
they put a big they put took a mouse and

411
00:17:11,010 --> 00:17:15,810
took a couple of baby mosses they put

412
00:17:13,079 --> 00:17:17,099
them in a basket and then they created a

413
00:17:15,810 --> 00:17:20,490
panic a situation they introduced a

414
00:17:17,099 --> 00:17:22,379
catch so what what the mother most cat

415
00:17:20,490 --> 00:17:25,829
does is it picks up the baby mouse and

416
00:17:22,380 --> 00:17:27,690
tries to run out of that basket now the

417
00:17:25,829 --> 00:17:30,210
moment the baby mouse are picked up from

418
00:17:27,690 --> 00:17:33,780
the basket the mouse's will stop

419
00:17:30,210 --> 00:17:35,550
wiggling because their natural instincts

420
00:17:33,780 --> 00:17:37,379
they have survival instincts tells that

421
00:17:35,550 --> 00:17:39,480
we are in a panic situation me and my

422
00:17:37,380 --> 00:17:43,050
mom is in a panic situation if I don't

423
00:17:39,480 --> 00:17:45,420
stop wiggling I will die in the process

424
00:17:43,050 --> 00:17:48,210
of evolution hundreds of mouse or mices

425
00:17:45,420 --> 00:17:50,310
died to get that - Oh survival instinct

426
00:17:48,210 --> 00:17:53,580
into that mouse which said that you know

427
00:17:50,310 --> 00:17:55,620
when you are picked up stop crying and

428
00:17:53,580 --> 00:17:57,899
that's the same process baby stress as

429
00:17:55,620 --> 00:17:59,939
well that means certain things we do are

430
00:17:57,900 --> 00:18:01,800
part of our DNA are part of our

431
00:17:59,940 --> 00:18:04,350
evolution process that is part of the

432
00:18:01,800 --> 00:18:06,419
data which we had in the past so I think

433
00:18:04,350 --> 00:18:08,219
I think over a period of time right

434
00:18:06,420 --> 00:18:11,580
these data is going to keep accumulating

435
00:18:08,220 --> 00:18:12,750
and we might be able to reach but means

436
00:18:11,580 --> 00:18:14,580
machines would be able to reach where

437
00:18:12,750 --> 00:18:16,830
humans are again not in the short time

438
00:18:14,580 --> 00:18:18,659
it's gonna take time but it's gonna be

439
00:18:16,830 --> 00:18:21,240
there but this this is another this is

440
00:18:18,660 --> 00:18:22,320
another thing that makes us distinct so

441
00:18:21,240 --> 00:18:25,290
you need to understand distinction

442
00:18:22,320 --> 00:18:27,210
between machines and humans as humans

443
00:18:25,290 --> 00:18:29,190
we've got a set of qualities which

444
00:18:27,210 --> 00:18:32,850
machines will never have that's the

445
00:18:29,190 --> 00:18:34,020
concept of empathy and ethics you cannot

446
00:18:32,850 --> 00:18:37,110
teach a machine ethics

447
00:18:34,020 --> 00:18:41,010
okay you cannot teach a machine empathy

448
00:18:37,110 --> 00:18:44,790
now both empathy and ethics come from

449
00:18:41,010 --> 00:18:47,879
human qualities it comes from the life

450
00:18:44,790 --> 00:18:49,960
experience we have how we've seen people

451
00:18:47,880 --> 00:18:54,999
interact okay it

452
00:18:49,960 --> 00:18:58,419
very difficult to codify that okay we

453
00:18:54,999 --> 00:19:01,480
have in our subconscious okay and I have

454
00:18:58,419 --> 00:19:04,570
human biology we have a subconscious

455
00:19:01,480 --> 00:19:07,899
which is actually processing and sensing

456
00:19:04,570 --> 00:19:12,210
data can we call it gut instinct okay

457
00:19:07,899 --> 00:19:15,219
which often triggers the way we interact

458
00:19:12,210 --> 00:19:16,809
we are not perfectly rational people

459
00:19:15,220 --> 00:19:20,909
because if we did we'd be pure machines

460
00:19:16,809 --> 00:19:23,710
cuz that's pure it algebraic rationality

461
00:19:20,909 --> 00:19:25,840
we don't operate like that we actually

462
00:19:23,710 --> 00:19:28,299
bring other sets of information about

463
00:19:25,840 --> 00:19:33,100
the world around us into how we process

464
00:19:28,299 --> 00:19:36,519
information emotion subconscious okay

465
00:19:33,100 --> 00:19:38,350
and then the value system ethical your

466
00:19:36,519 --> 00:19:40,480
value system comes into play when we

467
00:19:38,350 --> 00:19:42,219
make decisions some decisions have more

468
00:19:40,480 --> 00:19:44,710
or less of that depend what it is okay

469
00:19:42,220 --> 00:19:47,710
now that is where the problem is going

470
00:19:44,710 --> 00:19:49,960
to be even with artificial intelligence

471
00:19:47,710 --> 00:19:52,509
it is very difficult to get it to that

472
00:19:49,960 --> 00:19:54,909
point which is why my point was my the

473
00:19:52,509 --> 00:19:56,499
point I was making is yes machine

474
00:19:54,909 --> 00:19:59,200
learning will be an enabler

475
00:19:56,499 --> 00:20:01,659
which is complimentary to the human

476
00:19:59,200 --> 00:20:04,360
qualities we have but they are not a

477
00:20:01,659 --> 00:20:05,470
substitute the challenge we're gonna

478
00:20:04,360 --> 00:20:07,600
have is the following

479
00:20:05,470 --> 00:20:10,509
it's like me giving you a mini to drop

480
00:20:07,600 --> 00:20:12,730
okay you need a set of skills to drive

481
00:20:10,509 --> 00:20:16,059
that mini but tomorrow

482
00:20:12,730 --> 00:20:17,919
okay I give you a Formula One car brain

483
00:20:16,059 --> 00:20:19,090
you see the skills you need to have to

484
00:20:17,919 --> 00:20:21,970
actually be able to drive it properly

485
00:20:19,090 --> 00:20:23,769
same problem the ceiling and I I the

486
00:20:21,970 --> 00:20:25,779
user is not whether to replace or not

487
00:20:23,769 --> 00:20:27,730
this will actually force us to acquire

488
00:20:25,779 --> 00:20:30,159
additional skills and competencies to be

489
00:20:27,730 --> 00:20:32,559
able to use them properly as neighbors

490
00:20:30,159 --> 00:20:34,990
that's the challenge of achieving an AI

491
00:20:32,559 --> 00:20:37,570
for any profession cybersecurity or

492
00:20:34,990 --> 00:20:40,450
otherwise okay that's the real challenge

493
00:20:37,570 --> 00:20:43,570
we place machine learning is maths it's

494
00:20:40,450 --> 00:20:45,340
not magic I mean magic it's myths this

495
00:20:43,570 --> 00:20:47,740
adds to you know another question which

496
00:20:45,340 --> 00:20:50,019
one the throw do you think I mean do you

497
00:20:47,740 --> 00:20:51,669
think regulating an AI which is which is

498
00:20:50,019 --> 00:20:54,490
the topic of discussion all over you

499
00:20:51,669 --> 00:20:56,350
know I mean we should regulate the

500
00:20:54,490 --> 00:20:58,480
research in AI and machine learning do

501
00:20:56,350 --> 00:21:00,639
you think it's a smart approach or a you

502
00:20:58,480 --> 00:21:02,559
know what do you think how do you think

503
00:21:00,639 --> 00:21:03,139
we should go ahead with it or I think

504
00:21:02,559 --> 00:21:04,670
definitely

505
00:21:03,140 --> 00:21:07,070
not an easy question I think stop the

506
00:21:04,670 --> 00:21:09,380
recording first I think I can have

507
00:21:07,070 --> 00:21:13,270
anybody to talk other party soup yeah I

508
00:21:09,380 --> 00:21:16,100
think it's yeah alright so regulating ml

509
00:21:13,270 --> 00:21:20,470
rate of corn I don't think it should be

510
00:21:16,100 --> 00:21:23,570
I don't think it will be probably

511
00:21:20,470 --> 00:21:25,940
considering the data protection the

512
00:21:23,570 --> 00:21:27,200
draft will of the personal identifier

513
00:21:25,940 --> 00:21:29,660
information which is on his way in India

514
00:21:27,200 --> 00:21:31,670
and obviously the legislation already

515
00:21:29,660 --> 00:21:34,130
out for the GDP are part of it which

516
00:21:31,670 --> 00:21:36,500
which is probably focusing on the PII

517
00:21:34,130 --> 00:21:40,430
and the sensible the sensitive data

518
00:21:36,500 --> 00:21:43,250
itself so I I don't think that machine

519
00:21:40,430 --> 00:21:46,010
learning should be a regulation such as

520
00:21:43,250 --> 00:21:49,550
my left and and and and we thing for me

521
00:21:46,010 --> 00:21:53,990
the mother thing okay I think in the

522
00:21:49,550 --> 00:21:58,460
early stages where you are actually

523
00:21:53,990 --> 00:22:01,340
developing evolving and trying to make

524
00:21:58,460 --> 00:22:03,620
sense of what else AI how I can achieve

525
00:22:01,340 --> 00:22:07,310
things so trying to simulate the human

526
00:22:03,620 --> 00:22:11,360
brain I think we should not have it

527
00:22:07,310 --> 00:22:14,030
lately but yes there is always two sides

528
00:22:11,360 --> 00:22:16,820
of a coin I believe so

529
00:22:14,030 --> 00:22:20,930
anything whatever we are building should

530
00:22:16,820 --> 00:22:25,159
be regulated also he is not only used in

531
00:22:20,930 --> 00:22:29,750
cybersecurity but also used in attacking

532
00:22:25,160 --> 00:22:32,710
the systems so you have BOTS which can

533
00:22:29,750 --> 00:22:37,210
simulate entirely the human behavior you

534
00:22:32,710 --> 00:22:40,640
go to a website and you hover your mouse

535
00:22:37,210 --> 00:22:43,520
you start typing something how a human

536
00:22:40,640 --> 00:22:47,020
being behaves on a website and there are

537
00:22:43,520 --> 00:22:50,389
very advanced bought protection engines

538
00:22:47,020 --> 00:22:53,750
where you know you will say that okay I

539
00:22:50,390 --> 00:22:56,320
get so many queries per second or you

540
00:22:53,750 --> 00:23:01,400
know you know your bot management now

541
00:22:56,320 --> 00:23:03,530
you particularly do not want to go and

542
00:23:01,400 --> 00:23:07,310
block a human user that's a business

543
00:23:03,530 --> 00:23:10,960
loss so now there are lot of AI enabled

544
00:23:07,310 --> 00:23:13,960
bots available in the dark market

545
00:23:10,960 --> 00:23:16,750
let's select the entire human behavior

546
00:23:13,960 --> 00:23:18,250
and what managers have failed oh by the

547
00:23:16,750 --> 00:23:20,980
way many of them are humans actually

548
00:23:18,250 --> 00:23:21,340
they outsource this you know the CAPTCHA

549
00:23:20,980 --> 00:23:23,200
right

550
00:23:21,340 --> 00:23:25,120
most of the CAPTCHA breaking solutions

551
00:23:23,200 --> 00:23:26,950
are outsourced to countries like I don't

552
00:23:25,120 --> 00:23:28,929
know which all countries but outsource

553
00:23:26,950 --> 00:23:30,340
to our the country so people will be

554
00:23:28,930 --> 00:23:31,960
following those captures and giving it

555
00:23:30,340 --> 00:23:33,909
back to you so many services are there

556
00:23:31,960 --> 00:23:38,680
on the doctor yeah yeah let me turn that

557
00:23:33,910 --> 00:23:40,510
word around a IML is a technology all

558
00:23:38,680 --> 00:23:43,360
technologies are neutral they neither

559
00:23:40,510 --> 00:23:45,010
good nor bad it's only humans that make

560
00:23:43,360 --> 00:23:46,719
value judgments as to which the things

561
00:23:45,010 --> 00:23:50,830
are good or bad I'll take two examples

562
00:23:46,720 --> 00:23:54,160
we have guns it can be used for good can

563
00:23:50,830 --> 00:23:55,689
just go bad we have nuclear energy can

564
00:23:54,160 --> 00:23:58,420
be used for good can be used for bad

565
00:23:55,690 --> 00:24:00,880
what makes it good or bad is not the

566
00:23:58,420 --> 00:24:02,920
technology it's how we as humans

567
00:24:00,880 --> 00:24:04,810
actually use it so the question is what

568
00:24:02,920 --> 00:24:06,730
are you regulating the technology or the

569
00:24:04,810 --> 00:24:08,440
use of the technology that's the first

570
00:24:06,730 --> 00:24:10,660
big concept did you have to be cleared

571
00:24:08,440 --> 00:24:13,630
away absolutely not I mean I said that's

572
00:24:10,660 --> 00:24:16,240
actually the the key yeah historically

573
00:24:13,630 --> 00:24:18,430
historically all regulation is playing

574
00:24:16,240 --> 00:24:19,270
catch-up with technology never been

575
00:24:18,430 --> 00:24:21,700
ahead of the curve

576
00:24:19,270 --> 00:24:24,040
yeah yeah make sure the problem you've

577
00:24:21,700 --> 00:24:27,790
got and this is this always be the the

578
00:24:24,040 --> 00:24:31,480
challenges ultimately the only thing we

579
00:24:27,790 --> 00:24:33,490
will be able to do okay unfortunately

580
00:24:31,480 --> 00:24:36,280
this is gonna come back to human values

581
00:24:33,490 --> 00:24:38,560
and behaviors okay it's our own morality

582
00:24:36,280 --> 00:24:42,070
that defines how we use the technology

583
00:24:38,560 --> 00:24:44,889
for good or bad yeah okay extremely

584
00:24:42,070 --> 00:24:47,409
difficult to regulate morality

585
00:24:44,890 --> 00:24:50,590
absolutely very very difficult Danny

586
00:24:47,410 --> 00:24:52,720
however we can have to make some very

587
00:24:50,590 --> 00:24:56,230
tough calls probably the next 10-15

588
00:24:52,720 --> 00:24:58,030
years about AI okay because the speeding

589
00:24:56,230 --> 00:25:00,730
which is dis evolving if it is

590
00:24:58,030 --> 00:25:03,550
misapplied to have catastrophic advanced

591
00:25:00,730 --> 00:25:07,060
having issues just like nuclear fission

592
00:25:03,550 --> 00:25:09,370
yeah okay I don't think you're gonna

593
00:25:07,060 --> 00:25:11,980
subtract this problem in regulation I'm

594
00:25:09,370 --> 00:25:14,620
sure okay and if you look at the debates

595
00:25:11,980 --> 00:25:16,240
going on right now around AI a lot of

596
00:25:14,620 --> 00:25:18,010
people are starting to talk about listen

597
00:25:16,240 --> 00:25:19,540
we need to have a different way of

598
00:25:18,010 --> 00:25:21,570
thinking about how we use AI going

599
00:25:19,540 --> 00:25:24,870
forward so that the uses of

600
00:25:21,570 --> 00:25:28,280
I applied in the right places okay I can

601
00:25:24,870 --> 00:25:32,419
use the same argument going on with

602
00:25:28,280 --> 00:25:35,910
genetics right genetics is a technology

603
00:25:32,420 --> 00:25:37,350
human cloning has all sorts of problems

604
00:25:35,910 --> 00:25:40,170
that come with human cook with human

605
00:25:37,350 --> 00:25:42,120
cloning we don't learn humans for a

606
00:25:40,170 --> 00:25:45,510
reason all right

607
00:25:42,120 --> 00:25:47,909
same thing with AI we will have to make

608
00:25:45,510 --> 00:25:49,260
very similar cause of would a AI that

609
00:25:47,910 --> 00:25:50,970
we're doing with human cloning today

610
00:25:49,260 --> 00:25:52,560
because they are ethical and moral

611
00:25:50,970 --> 00:25:55,500
issues they'll have to be considered as

612
00:25:52,560 --> 00:25:57,270
we go through okay that's the challenge

613
00:25:55,500 --> 00:25:59,400
you got it yeah no I mean just to

614
00:25:57,270 --> 00:26:00,720
summarize I mean everyone in the panel

615
00:25:59,400 --> 00:26:03,600
agreed that it should not be regulated

616
00:26:00,720 --> 00:26:05,580
what should be regulated as the use not

617
00:26:03,600 --> 00:26:07,260
the technology and I completely agree

618
00:26:05,580 --> 00:26:08,550
with all of them because see this is a

619
00:26:07,260 --> 00:26:10,170
budding field right this is a field

620
00:26:08,550 --> 00:26:11,850
which is we're constantly research and

621
00:26:10,170 --> 00:26:14,610
development is happening and we haven't

622
00:26:11,850 --> 00:26:16,080
reached anywhere yet and when the search

623
00:26:14,610 --> 00:26:18,179
is ongoing when you start putting

624
00:26:16,080 --> 00:26:21,060
regulating things right it's like how we

625
00:26:18,180 --> 00:26:22,680
regulated marijuana it was secure for a

626
00:26:21,060 --> 00:26:24,210
lot of things but then we regulated it

627
00:26:22,680 --> 00:26:27,990
and then nothing is happening there same

628
00:26:24,210 --> 00:26:30,420
way it will go to we would not progress

629
00:26:27,990 --> 00:26:32,130
at all and you have to look at see you

630
00:26:30,420 --> 00:26:34,260
look at the room which you sit in right

631
00:26:32,130 --> 00:26:36,690
now the speakers the microphones the

632
00:26:34,260 --> 00:26:38,430
lights the lamps all of them are

633
00:26:36,690 --> 00:26:41,520
twenty-year-old technology it has an

634
00:26:38,430 --> 00:26:42,990
advanced a bit in the last 20 years I

635
00:26:41,520 --> 00:26:44,520
mean in the past many of have you seen

636
00:26:42,990 --> 00:26:46,770
it that is exactly the same way these

637
00:26:44,520 --> 00:26:49,680
are but look at the phones you have look

638
00:26:46,770 --> 00:26:51,240
at the technology advances which is

639
00:26:49,680 --> 00:26:52,560
primarily going on in this machine

640
00:26:51,240 --> 00:26:55,230
learning and AI in that you know now we

641
00:26:52,560 --> 00:26:58,080
don't need hardware changes to take a

642
00:26:55,230 --> 00:26:59,700
smarter picture we can do it with Y

643
00:26:58,080 --> 00:27:01,470
leveraging machine learning and that's a

644
00:26:59,700 --> 00:27:02,970
reason the world is investing a huge

645
00:27:01,470 --> 00:27:05,250
amount of money in machine learning

646
00:27:02,970 --> 00:27:06,690
researches that means this is a field

647
00:27:05,250 --> 00:27:08,430
which is going to advance because there

648
00:27:06,690 --> 00:27:10,980
is money right now to do a lot of

649
00:27:08,430 --> 00:27:12,240
research and it will advance and what is

650
00:27:10,980 --> 00:27:14,460
going to happen eventually in the next

651
00:27:12,240 --> 00:27:16,500
you know five six seven years is these

652
00:27:14,460 --> 00:27:18,180
light bulbs are going to have a some

653
00:27:16,500 --> 00:27:20,820
amount of AI or machine learning in it

654
00:27:18,180 --> 00:27:25,650
it might start learning from your facial

655
00:27:20,820 --> 00:27:27,270
expressions on what mood you are to you

656
00:27:25,650 --> 00:27:29,580
know what song it should play back to

657
00:27:27,270 --> 00:27:31,320
you again based on your stress level of

658
00:27:29,580 --> 00:27:32,970
the time level except extra that's the

659
00:27:31,320 --> 00:27:34,500
only advancements these technologies

660
00:27:32,970 --> 00:27:36,450
around us can make and

661
00:27:34,500 --> 00:27:39,150
and regulating at this point of time

662
00:27:36,450 --> 00:27:41,190
would not be a great idea at all so yeah

663
00:27:39,150 --> 00:27:43,770
so I'm happy that we all agreed on that

664
00:27:41,190 --> 00:27:45,179
so I think I know you are a moderator

665
00:27:43,770 --> 00:27:50,129
but I want to take the privilege and ask

666
00:27:45,179 --> 00:27:51,390
more one more question right so I just

667
00:27:50,130 --> 00:27:54,330
wanted to throw the questions to the

668
00:27:51,390 --> 00:27:56,070
audience as well that what are the what

669
00:27:54,330 --> 00:27:57,990
are the applications of machine learning

670
00:27:56,070 --> 00:28:00,240
in the in the world of cyber security

671
00:27:57,990 --> 00:28:02,880
and what other low-hanging fruits can be

672
00:28:00,240 --> 00:28:04,650
leveraged probably oh yeah by the way

673
00:28:02,880 --> 00:28:06,720
you guys want to answer some because you

674
00:28:04,650 --> 00:28:08,070
would have adopted some exam level of

675
00:28:06,720 --> 00:28:09,750
machine learning in your offices right

676
00:28:08,070 --> 00:28:15,439
yeah yeah so they simply passed Maya I

677
00:28:09,750 --> 00:28:15,440
can I can I can come down I don't mind

678
00:28:15,630 --> 00:28:22,380
[Music]

679
00:28:18,860 --> 00:28:25,189
this is Santa Barbara from PCs I had

680
00:28:22,380 --> 00:28:29,070
their cybersecurity services delivery

681
00:28:25,190 --> 00:28:32,669
there are three distinct areas where we

682
00:28:29,070 --> 00:28:35,610
view the play of AI machine learning in

683
00:28:32,669 --> 00:28:39,059
cybersecurity first is they used to

684
00:28:35,610 --> 00:28:43,649
defend that you've talked about there

685
00:28:39,059 --> 00:28:47,418
are some very good anti-malware products

686
00:28:43,650 --> 00:28:51,390
available and around for quite a while

687
00:28:47,419 --> 00:28:52,010
that are very effective in malware

688
00:28:51,390 --> 00:28:54,750
detection

689
00:28:52,010 --> 00:28:57,330
no human being tries to write signatures

690
00:28:54,750 --> 00:28:59,429
and all that right in a couple of years

691
00:28:57,330 --> 00:29:04,110
no human we will try to write same rules

692
00:28:59,429 --> 00:29:07,320
either the second thing is the use of AI

693
00:29:04,110 --> 00:29:09,649
to carry out attacks at scale that you

694
00:29:07,320 --> 00:29:13,500
haven't seen before

695
00:29:09,650 --> 00:29:15,870
very personalized phishing attacks which

696
00:29:13,500 --> 00:29:18,270
are not possible to scale using human

697
00:29:15,870 --> 00:29:20,070
manpower and the third thing is the

698
00:29:18,270 --> 00:29:23,250
security of the AI systems themselves

699
00:29:20,070 --> 00:29:26,129
house absolute my systemic poisoning of

700
00:29:23,250 --> 00:29:28,620
the training data those consequences I

701
00:29:26,130 --> 00:29:31,320
also wanted to add that there are many

702
00:29:28,620 --> 00:29:35,158
standardization efforts so the the wish

703
00:29:31,320 --> 00:29:38,129
for no regulation I think is it is it's

704
00:29:35,159 --> 00:29:40,590
not going to happen there is a whole you

705
00:29:38,130 --> 00:29:42,990
know ISO subcommittee newly formed just

706
00:29:40,590 --> 00:29:47,699
about seven eight months ago on the

707
00:29:42,990 --> 00:29:50,549
topic of AI there are number of British

708
00:29:47,700 --> 00:29:52,980
standards dealing with AI and the ethics

709
00:29:50,549 --> 00:29:54,690
of development of BI systems so

710
00:29:52,980 --> 00:29:57,269
regulation is going to happen

711
00:29:54,690 --> 00:30:00,299
and you're not going to be able to wish

712
00:29:57,269 --> 00:30:02,730
it away look at that we add to what

713
00:30:00,299 --> 00:30:03,559
you're saying there look at the nuclear

714
00:30:02,730 --> 00:30:07,230
arms race

715
00:30:03,559 --> 00:30:09,980
yeah ultimately everyone had to develop

716
00:30:07,230 --> 00:30:15,120
AI to maintain the balance of power

717
00:30:09,980 --> 00:30:16,889
returns okay so even if you regulate you

718
00:30:15,120 --> 00:30:18,750
actually have a fundamental problem

719
00:30:16,889 --> 00:30:21,510
which is if you don't develop your

720
00:30:18,750 --> 00:30:23,159
capability you actually are defensively

721
00:30:21,510 --> 00:30:25,260
in a bed in a worse position and

722
00:30:23,159 --> 00:30:27,450
somebody does and this is where we can

723
00:30:25,260 --> 00:30:29,850
have unless you have it in the current

724
00:30:27,450 --> 00:30:32,429
world order this will be an issue in

725
00:30:29,850 --> 00:30:35,039
terms of it's a form of power or so X

726
00:30:32,429 --> 00:30:36,510
will have to get resolved but you act

727
00:30:35,039 --> 00:30:38,940
something great point you raise I mean

728
00:30:36,510 --> 00:30:40,679
to add to what you said I mean one of

729
00:30:38,940 --> 00:30:43,139
the future of cyber security right and

730
00:30:40,679 --> 00:30:45,750
from an attacker perspective is a

731
00:30:43,139 --> 00:30:47,549
concept called adversarial learning what

732
00:30:45,750 --> 00:30:49,500
it does is these machine learning models

733
00:30:47,549 --> 00:30:51,330
right I mean they are based on certain

734
00:30:49,500 --> 00:30:54,059
data and their job is to make certain

735
00:30:51,330 --> 00:30:56,580
predictions now you reverse engineer the

736
00:30:54,059 --> 00:30:58,110
models and figure out certain bugs

737
00:30:56,580 --> 00:31:00,840
I wouldn't say bugs actually certain

738
00:30:58,110 --> 00:31:02,070
certain flaws in the models and you can

739
00:31:00,840 --> 00:31:04,529
actually fool these machine learning

740
00:31:02,070 --> 00:31:08,129
models for example if a machine learning

741
00:31:04,529 --> 00:31:11,250
models predicting my is is looking at my

742
00:31:08,130 --> 00:31:13,559
face and doing a simple face match all

743
00:31:11,250 --> 00:31:15,929
right you can actually do a adversely

744
00:31:13,559 --> 00:31:17,610
learning on that model and maybe use

745
00:31:15,929 --> 00:31:21,149
some other picture maybe even a picture

746
00:31:17,610 --> 00:31:23,519
of a potato to trick that thing in the

747
00:31:21,149 --> 00:31:25,918
thing is my face so that's one of the

748
00:31:23,519 --> 00:31:28,380
future and I'm pretty sure we have six

749
00:31:25,919 --> 00:31:29,850
seven years down the line all all the

750
00:31:28,380 --> 00:31:32,970
SQL injection and all the exercise

751
00:31:29,850 --> 00:31:35,250
things will be outdated and adversive

752
00:31:32,970 --> 00:31:39,929
learning would be one of the key

753
00:31:35,250 --> 00:31:44,220
evolving cyber security issues so I

754
00:31:39,929 --> 00:31:46,380
think are we trying to say here that the

755
00:31:44,220 --> 00:31:48,179
large scale of data probably in the

756
00:31:46,380 --> 00:31:50,789
cloud probably the endpoints wherever

757
00:31:48,179 --> 00:31:52,669
they reside I mean are those the are

758
00:31:50,789 --> 00:31:55,139
those the instance is basically

759
00:31:52,669 --> 00:31:56,760
applicable to have the machine learning

760
00:31:55,139 --> 00:31:58,168
algorithm and to get the better output

761
00:31:56,760 --> 00:32:00,360
in that sense I mean to have more

762
00:31:58,169 --> 00:32:01,230
visibility more accuracy of the desired

763
00:32:00,360 --> 00:32:02,850
output

764
00:32:01,230 --> 00:32:04,950
you cannot have accurate models without

765
00:32:02,850 --> 00:32:06,780
data naturally em so you you have to

766
00:32:04,950 --> 00:32:08,669
accumulate data this is why the David

767
00:32:06,780 --> 00:32:10,379
Lee conversation right without that is

768
00:32:08,669 --> 00:32:11,730
now accuracy in the model yep that

769
00:32:10,380 --> 00:32:13,559
that's the one problem so most

770
00:32:11,730 --> 00:32:15,000
organizations this whole digital

771
00:32:13,559 --> 00:32:17,309
transformation what you're seeing is a

772
00:32:15,000 --> 00:32:18,900
push in an aggregate de to build the

773
00:32:17,309 --> 00:32:20,040
intelligence to actually enable also the

774
00:32:18,900 --> 00:32:23,190
business processes yeah

775
00:32:20,040 --> 00:32:25,760
it's unfortunately that's the way the

776
00:32:23,190 --> 00:32:28,740
technology works yeah okay

777
00:32:25,760 --> 00:32:31,590
the application in use cases of machine

778
00:32:28,740 --> 00:32:34,200
learning and AI right go beyond the farm

779
00:32:31,590 --> 00:32:35,879
or just into defensive and the attack

780
00:32:34,200 --> 00:32:38,790
and defense mindset when it comes to

781
00:32:35,880 --> 00:32:40,740
security this is a series of problems we

782
00:32:38,790 --> 00:32:42,389
have today let's look at basic problems

783
00:32:40,740 --> 00:32:44,640
around passwords for example hmm

784
00:32:42,390 --> 00:32:46,230
multi-factor authentication with machine

785
00:32:44,640 --> 00:32:47,370
learning behind it actually changes and

786
00:32:46,230 --> 00:32:49,320
gets rid of the entire need for

787
00:32:47,370 --> 00:32:51,540
passwords that's one use case we don't

788
00:32:49,320 --> 00:32:53,159
know yeah let's take the problem how

789
00:32:51,540 --> 00:32:54,629
many organizations has actually managed

790
00:32:53,160 --> 00:32:58,860
to get data classification right please

791
00:32:54,630 --> 00:33:00,150
put up your hands any organizations have

792
00:32:58,860 --> 00:33:01,979
actually managed to get data

793
00:33:00,150 --> 00:33:09,780
classification right in the organization

794
00:33:01,980 --> 00:33:12,870
I'd like to see an engineer is none is

795
00:33:09,780 --> 00:33:16,350
none why because data classification is

796
00:33:12,870 --> 00:33:19,049
a pain and all organizations struggle

797
00:33:16,350 --> 00:33:26,790
with it guess what brilliant use case

798
00:33:19,049 --> 00:33:29,429
for machine learning exactly so there

799
00:33:26,790 --> 00:33:31,678
are some very positive use cases that

800
00:33:29,429 --> 00:33:32,010
actually enable security with machine

801
00:33:31,679 --> 00:33:36,000
learning

802
00:33:32,010 --> 00:33:37,830
nai okay to actually get any prove these

803
00:33:36,000 --> 00:33:39,720
security postures that you haven't said

804
00:33:37,830 --> 00:33:42,750
data classification good LD add the

805
00:33:39,720 --> 00:33:50,040
quality of data to the algorithm to get

806
00:33:42,750 --> 00:33:51,990
it going on contradiction between among

807
00:33:50,040 --> 00:33:53,639
the entire community so on the other

808
00:33:51,990 --> 00:33:55,080
room we are talking about the DPOs the

809
00:33:53,640 --> 00:33:57,540
data protection and all the stuff right

810
00:33:55,080 --> 00:33:58,949
the regularization and this other room

811
00:33:57,540 --> 00:34:02,700
next to that room we are talking about

812
00:33:58,950 --> 00:34:04,080
do not regular eyes right not recorded

813
00:34:02,700 --> 00:34:06,360
but that's this may be just come out

814
00:34:04,080 --> 00:34:07,889
from you so how do we address such kind

815
00:34:06,360 --> 00:34:09,629
of thing when we talk about it appetite

816
00:34:07,890 --> 00:34:11,909
gdpr and all the stuff but at the same

817
00:34:09,629 --> 00:34:13,080
time i'm not saying that we are trying

818
00:34:11,909 --> 00:34:15,340
to be extra greedy to get the best

819
00:34:13,080 --> 00:34:17,650
outcome or output but

820
00:34:15,340 --> 00:34:20,020
I agree completely strongly agree with

821
00:34:17,650 --> 00:34:22,000
him that that's the essence

822
00:34:20,020 --> 00:34:32,500
regularization is the essential thing

823
00:34:22,000 --> 00:34:34,510
otherwise we are going to privacy is

824
00:34:32,500 --> 00:34:36,940
coming from all right I just want to

825
00:34:34,510 --> 00:34:39,820
make one point before that so we are

826
00:34:36,940 --> 00:34:43,270
talking about AI and ml but before that

827
00:34:39,820 --> 00:34:47,230
you have data pre-processing right so

828
00:34:43,270 --> 00:34:49,989
preparing data for AI and ml and what we

829
00:34:47,230 --> 00:34:56,560
are feeding to AI and ml engine is and

830
00:34:49,989 --> 00:34:59,799
experience it is not personal no no that

831
00:34:56,560 --> 00:35:02,170
is the mandatory input for AI and ml

832
00:34:59,800 --> 00:35:06,010
I'll tell you the thing here is we are

833
00:35:02,170 --> 00:35:08,620
giving a scenario if scenario a B and C

834
00:35:06,010 --> 00:35:11,100
happens then the outcome is D that

835
00:35:08,620 --> 00:35:15,430
doesn't relate to a person called Satish

836
00:35:11,100 --> 00:35:18,190
right so it's a human you know it's it's

837
00:35:15,430 --> 00:35:20,649
a male or female ha I should may all

838
00:35:18,190 --> 00:35:23,860
females is not a P I yeah right

839
00:35:20,650 --> 00:35:26,500
a pan number other number is a bi yes

840
00:35:23,860 --> 00:35:28,810
yes I so we need to categorize and we

841
00:35:26,500 --> 00:35:31,330
need to sanitize the data before we feed

842
00:35:28,810 --> 00:35:33,730
to the system you can be personalized

843
00:35:31,330 --> 00:35:36,610
the data before it becomes PII that's it

844
00:35:33,730 --> 00:35:38,040
is the main point but but you're missing

845
00:35:36,610 --> 00:35:41,200
the point

846
00:35:38,040 --> 00:35:45,550
still not there why do we have data

847
00:35:41,200 --> 00:35:47,740
privacy because data privacy comes from

848
00:35:45,550 --> 00:35:49,020
a fundamental human right right to

849
00:35:47,740 --> 00:35:52,569
freedom

850
00:35:49,020 --> 00:35:54,160
most constitutions if you are if we knew

851
00:35:52,570 --> 00:35:56,890
as a country of signed up to the UN

852
00:35:54,160 --> 00:35:59,140
charter of Human Rights you'll see the

853
00:35:56,890 --> 00:36:03,400
right to freedom Yeah right is actually

854
00:35:59,140 --> 00:36:05,440
the freedom of life data privacy comes

855
00:36:03,400 --> 00:36:06,760
up as one of those freedoms for you to

856
00:36:05,440 --> 00:36:08,950
have freedom of life you need to have

857
00:36:06,760 --> 00:36:13,270
freedom of privacy we have to operate

858
00:36:08,950 --> 00:36:15,790
without surveillance ok now if you look

859
00:36:13,270 --> 00:36:18,550
at what GDP is doing and all previous

860
00:36:15,790 --> 00:36:20,020
versions of GV they are not they allow

861
00:36:18,550 --> 00:36:24,640
for the fact that you actually capture

862
00:36:20,020 --> 00:36:27,880
PII data provided it is consensual with

863
00:36:24,640 --> 00:36:29,140
agreement yeah ok what it is doing is

864
00:36:27,880 --> 00:36:31,450
actually regulating the

865
00:36:29,140 --> 00:36:34,118
usage of it absolutely it goes back

866
00:36:31,450 --> 00:36:36,759
again to the usage of the data whether

867
00:36:34,119 --> 00:36:38,980
that's sitting gdpr or HIPPA whatever

868
00:36:36,760 --> 00:36:40,660
regulation you've got it's the usage has

869
00:36:38,980 --> 00:36:44,079
been regulated on top of it it's going

870
00:36:40,660 --> 00:36:46,299
one step further okay because we're all

871
00:36:44,079 --> 00:36:49,539
smart and so if you understand how the

872
00:36:46,299 --> 00:36:51,250
legal systems work is we've tried to go

873
00:36:49,539 --> 00:36:53,289
around the usage of that through

874
00:36:51,250 --> 00:36:54,789
contracts it's basically every time you

875
00:36:53,289 --> 00:36:56,500
sign those terms and conditions you sign

876
00:36:54,789 --> 00:36:59,650
away your rights all right

877
00:36:56,500 --> 00:37:01,480
so Europe woke up to this problem ages

878
00:36:59,650 --> 00:37:03,549
ago makers - waking up to this problem

879
00:37:01,480 --> 00:37:05,230
this is not an internet even if you sign

880
00:37:03,549 --> 00:37:07,538
away your rights in a contract we will

881
00:37:05,230 --> 00:37:09,309
still protect them because we believe

882
00:37:07,539 --> 00:37:11,980
it's a fundamental human right that is

883
00:37:09,309 --> 00:37:14,529
protected by our constitutional rights

884
00:37:11,980 --> 00:37:18,190
so what did have what happens this is

885
00:37:14,529 --> 00:37:22,740
basically saying it is preventing legal

886
00:37:18,190 --> 00:37:25,779
entities yes from using an abusing data

887
00:37:22,740 --> 00:37:28,720
that infringes on your right to privacy

888
00:37:25,779 --> 00:37:30,849
that's the essence of Gd P R and D PA

889
00:37:28,720 --> 00:37:31,269
and it's been like that for a very long

890
00:37:30,849 --> 00:37:33,250
time

891
00:37:31,269 --> 00:37:36,038
absolutely all right so usage is the

892
00:37:33,250 --> 00:37:38,230
issue not the processing exactly just

893
00:37:36,039 --> 00:37:39,670
and the difference it should do there's

894
00:37:38,230 --> 00:37:41,289
one more advancement in machine learning

895
00:37:39,670 --> 00:37:43,539
which is coming you might want to take

896
00:37:41,289 --> 00:37:45,819
it down it's called transfer learning

897
00:37:43,539 --> 00:37:48,160
this is a solution transfer learning is

898
00:37:45,819 --> 00:37:49,180
a solution which is coming up primarily

899
00:37:48,160 --> 00:37:51,368
to solve this problem

900
00:37:49,180 --> 00:37:53,288
see if you me that's right you don't

901
00:37:51,369 --> 00:37:55,000
need PII data to be sent to machine

902
00:37:53,289 --> 00:37:56,529
learning systems but certain certain

903
00:37:55,000 --> 00:37:58,930
systems require a PI data as well

904
00:37:56,529 --> 00:38:01,420
because if they want to calculate rauch

905
00:37:58,930 --> 00:38:02,799
a sheep like how many Diwali posts they

906
00:38:01,420 --> 00:38:05,109
would need my second name actually and

907
00:38:02,799 --> 00:38:06,759
how many people from a particular state

908
00:38:05,109 --> 00:38:08,828
actually was doing something else oh

909
00:38:06,759 --> 00:38:10,240
they need a PII information so what they

910
00:38:08,829 --> 00:38:13,809
are doing is what transfer learning does

911
00:38:10,240 --> 00:38:15,098
is they don't transfer the PII

912
00:38:13,809 --> 00:38:18,250
information to the machine learning

913
00:38:15,099 --> 00:38:20,440
fifth are training systems rather they

914
00:38:18,250 --> 00:38:22,089
do the training on the local mobile

915
00:38:20,440 --> 00:38:24,910
phone or the local computer or your own

916
00:38:22,089 --> 00:38:27,460
your local browser and the model only

917
00:38:24,910 --> 00:38:29,950
goes back to the service not your data

918
00:38:27,460 --> 00:38:32,529
so this this is called transfer learning

919
00:38:29,950 --> 00:38:34,808
and it's a new thing which is come are

920
00:38:32,529 --> 00:38:36,150
you referring to the metadata Miami TX

921
00:38:34,809 --> 00:38:37,980
is definitely it

922
00:38:36,150 --> 00:38:40,290
actually exactly and it happens on your

923
00:38:37,980 --> 00:38:45,840
individuals machines not going back all

924
00:38:40,290 --> 00:38:50,700
right you've got this problem okay which

925
00:38:45,840 --> 00:38:54,030
is do clinical trials yeah yeah clinical

926
00:38:50,700 --> 00:38:56,339
trials is the last year's absolute right

927
00:38:54,030 --> 00:38:59,100
what we do is in clinical trials we

928
00:38:56,340 --> 00:39:01,200
separate the identity from the data now

929
00:38:59,100 --> 00:39:03,680
why do you want you to use the data and

930
00:39:01,200 --> 00:39:07,740
why do you wanna use machine learning

931
00:39:03,680 --> 00:39:12,299
because the use of that data gives a

932
00:39:07,740 --> 00:39:13,680
beneficial outcome to mankind as you do

933
00:39:12,300 --> 00:39:15,450
those travel give you an example this is

934
00:39:13,680 --> 00:39:17,100
how we discover new drugs we're starting

935
00:39:15,450 --> 00:39:19,500
to see the correlation between genetics

936
00:39:17,100 --> 00:39:21,240
and disease exactly now you need to

937
00:39:19,500 --> 00:39:24,840
understand that correlation in genetics

938
00:39:21,240 --> 00:39:27,629
is unique to you and your DNA profile is

939
00:39:24,840 --> 00:39:30,630
you it's your identity no one else is

940
00:39:27,630 --> 00:39:33,960
what they prefer but if you can operate

941
00:39:30,630 --> 00:39:36,690
machine learning on that actually build

942
00:39:33,960 --> 00:39:39,390
models that predict disease this huge

943
00:39:36,690 --> 00:39:41,430
benefit for Humanity what you have to do

944
00:39:39,390 --> 00:39:45,000
is understand how you use it in a way

945
00:39:41,430 --> 00:39:47,839
that does not bring the down sides of

946
00:39:45,000 --> 00:39:50,580
pork is the negative aspects of them I

947
00:39:47,840 --> 00:39:52,860
simply protecting identity this is why

948
00:39:50,580 --> 00:39:55,529
you D personalized information into it

949
00:39:52,860 --> 00:40:01,170
okay right so it's not that you don't do

950
00:39:55,530 --> 00:40:02,670
it you just be personalized okay just to

951
00:40:01,170 --> 00:40:04,410
add to that I'll tell you the future

952
00:40:02,670 --> 00:40:06,930
right I mean what is going to happen is

953
00:40:04,410 --> 00:40:08,520
more companies I want to come up who

954
00:40:06,930 --> 00:40:10,440
will go is going to do clinical trials

955
00:40:08,520 --> 00:40:12,030
you will go to the clinics but you start

956
00:40:10,440 --> 00:40:15,450
getting the results on your mobile phone

957
00:40:12,030 --> 00:40:17,250
and with the GDP regulations and with

958
00:40:15,450 --> 00:40:18,839
because they can't now take out the data

959
00:40:17,250 --> 00:40:20,280
back to the server what they do is they

960
00:40:18,840 --> 00:40:22,860
lower do a transfer learning on your

961
00:40:20,280 --> 00:40:25,260
application now start feeding that data

962
00:40:22,860 --> 00:40:27,060
back to the server so so you can and

963
00:40:25,260 --> 00:40:31,050
then the next five six years you can see

964
00:40:27,060 --> 00:40:33,110
more more advancements in in those sort

965
00:40:31,050 --> 00:40:35,220
of applications around you the

966
00:40:33,110 --> 00:40:38,310
evolutions are happening something like

967
00:40:35,220 --> 00:40:40,080
this like you know you had application

968
00:40:38,310 --> 00:40:42,270
previously we had a client-server

969
00:40:40,080 --> 00:40:44,700
technology and then we went to

970
00:40:42,270 --> 00:40:47,790
serverless technology and now your

971
00:40:44,700 --> 00:40:49,680
mobile phones your handheld devices will

972
00:40:47,790 --> 00:40:52,950
be doing the 90% of the

973
00:40:49,680 --> 00:40:56,190
data only goes to the so called data

974
00:40:52,950 --> 00:40:59,279
centers where we build models and again

975
00:40:56,190 --> 00:41:02,099
sent back to your application or to your

976
00:40:59,280 --> 00:41:03,780
device so basically our smartphones if

977
00:41:02,099 --> 00:41:07,890
you remember or if you if you really

978
00:41:03,780 --> 00:41:10,200
know having eight course and even a

979
00:41:07,890 --> 00:41:15,150
server in a data center may not have a

980
00:41:10,200 --> 00:41:21,540
post so this is how the technology is

981
00:41:15,150 --> 00:41:24,840
coming and as three clients we can

982
00:41:21,540 --> 00:41:28,349
afford a smart phone with eight course

983
00:41:24,840 --> 00:41:32,430
we are actually giving and processing

984
00:41:28,349 --> 00:41:37,590
and taking the heavy lift off of the

985
00:41:32,430 --> 00:41:40,200
entire application lifecycle so from the

986
00:41:37,590 --> 00:41:43,140
server to client you know the

987
00:41:40,200 --> 00:41:44,910
infrastructure client was previously the

988
00:41:43,140 --> 00:41:46,589
lightest phone and the server was a

989
00:41:44,910 --> 00:41:49,830
heavier who is doing the heavy lifting

990
00:41:46,590 --> 00:41:52,760
but now the scenario is changing most of

991
00:41:49,830 --> 00:41:55,619
the work is done at the client side and

992
00:41:52,760 --> 00:42:00,330
it goes back to the data center as

993
00:41:55,619 --> 00:42:02,760
aggregator and hardly it has to do more

994
00:42:00,330 --> 00:42:07,440
data processing so you know it is not

995
00:42:02,760 --> 00:42:13,880
logical it is more on statistical data

996
00:42:07,440 --> 00:42:13,880
analysis yeah yeah question in the back

997
00:42:14,570 --> 00:42:19,830
thank you guys I'll just give a

998
00:42:17,460 --> 00:42:21,810
counter-argument here B's on data

999
00:42:19,830 --> 00:42:24,089
analysis based on ml that we are doing

1000
00:42:21,810 --> 00:42:26,849
right now a lot of companies are slowly

1001
00:42:24,089 --> 00:42:29,369
moving towards cloud providers right

1002
00:42:26,849 --> 00:42:31,710
they are moving to e waz CPU etc

1003
00:42:29,369 --> 00:42:34,050
whatever is available we are talking

1004
00:42:31,710 --> 00:42:36,990
about here that it is good to have the

1005
00:42:34,050 --> 00:42:39,720
data ingested to have a lunar module

1006
00:42:36,990 --> 00:42:42,180
running on top of it that will be

1007
00:42:39,720 --> 00:42:44,399
beneficial in all ways but are we

1008
00:42:42,180 --> 00:42:46,680
equally comfortable when these data Pro

1009
00:42:44,400 --> 00:42:48,630
or these cloud providers are crunching

1010
00:42:46,680 --> 00:42:51,299
the numbers of the existing

1011
00:42:48,630 --> 00:42:53,070
organizations moving there is that

1012
00:42:51,300 --> 00:42:55,080
something that is also desirable and

1013
00:42:53,070 --> 00:42:57,109
goes with the same solution and the

1014
00:42:55,080 --> 00:43:00,990
answer that we are talking about here so

1015
00:42:57,109 --> 00:43:03,540
each organization is different in our

1016
00:43:00,990 --> 00:43:05,580
case no yeah they are see

1017
00:43:03,540 --> 00:43:07,230
the problems that come with it so laser

1018
00:43:05,580 --> 00:43:09,210
localization is the debate going on

1019
00:43:07,230 --> 00:43:11,910
right now only big one so that's one

1020
00:43:09,210 --> 00:43:13,890
problem that's not the only problem so

1021
00:43:11,910 --> 00:43:15,870
my question then here is you know how

1022
00:43:13,890 --> 00:43:17,730
are we so different from the customers

1023
00:43:15,870 --> 00:43:19,650
that we are catering to and V being

1024
00:43:17,730 --> 00:43:21,540
customers to the cloud providers then

1025
00:43:19,650 --> 00:43:25,890
we're going to be the same thing when we

1026
00:43:21,540 --> 00:43:27,720
are using that data to come out for 4G

1027
00:43:25,890 --> 00:43:33,720
I've seen the dark side of that

1028
00:43:27,720 --> 00:43:35,310
conversation it's like this ultimately

1029
00:43:33,720 --> 00:43:40,220
because it's a question of who do you

1030
00:43:35,310 --> 00:43:43,170
hold accountable right so increasingly

1031
00:43:40,220 --> 00:43:44,490
you have you have a difference in

1032
00:43:43,170 --> 00:43:47,460
regulation across the globe

1033
00:43:44,490 --> 00:43:48,810
okay what is permitted in one part of

1034
00:43:47,460 --> 00:43:50,040
the world is not permitted in another

1035
00:43:48,810 --> 00:43:53,100
part of the world I'll give you a real

1036
00:43:50,040 --> 00:43:56,240
example GDP our visa vie Sai Baba

1037
00:43:53,100 --> 00:44:00,150
why does safe-harbor go out the window

1038
00:43:56,240 --> 00:44:02,669
because when safe-harbor was taken to

1039
00:44:00,150 --> 00:44:04,830
supreme court in europe and they

1040
00:44:02,670 --> 00:44:06,630
actually compared us practices with

1041
00:44:04,830 --> 00:44:09,440
regards to protection of their privacy

1042
00:44:06,630 --> 00:44:12,900
the european supreme court actually said

1043
00:44:09,440 --> 00:44:14,880
US standards on their privacy do not

1044
00:44:12,900 --> 00:44:17,090
meet the principles of safe harbor which

1045
00:44:14,880 --> 00:44:20,550
we have agreed okay

1046
00:44:17,090 --> 00:44:24,840
secondly country is always changing

1047
00:44:20,550 --> 00:44:26,880
politicians all right that's life all

1048
00:44:24,840 --> 00:44:28,740
right so you may have agreed something

1049
00:44:26,880 --> 00:44:31,550
in good faith at one point in time but

1050
00:44:28,740 --> 00:44:34,919
you cannot predict the future okay

1051
00:44:31,550 --> 00:44:40,440
thirdly data once you let it go doesn't

1052
00:44:34,920 --> 00:44:42,030
come back that's life right so if you

1053
00:44:40,440 --> 00:44:46,410
have a responsibility and an

1054
00:44:42,030 --> 00:44:49,140
accountability to protect data you need

1055
00:44:46,410 --> 00:44:50,879
to be clear that you understand where

1056
00:44:49,140 --> 00:44:53,879
that data is going and how you can

1057
00:44:50,880 --> 00:44:55,530
protect in all locations all right these

1058
00:44:53,880 --> 00:44:57,210
a these are very interesting debate

1059
00:44:55,530 --> 00:44:59,240
coming up and it's already happening in

1060
00:44:57,210 --> 00:45:02,340
Europe all the right to be forgotten

1061
00:44:59,240 --> 00:45:04,080
good luck with that one

1062
00:45:02,340 --> 00:45:08,780
most companies don't know what they do

1063
00:45:04,080 --> 00:45:14,220
they've got so how could I forget you

1064
00:45:08,780 --> 00:45:17,190
more lawsuits and one continent is

1065
00:45:14,220 --> 00:45:20,310
actually imposing right to forget and

1066
00:45:17,190 --> 00:45:21,270
working so much on data security another

1067
00:45:20,310 --> 00:45:23,940
continent

1068
00:45:21,270 --> 00:45:28,280
you see countries who really track

1069
00:45:23,940 --> 00:45:33,030
people face by face and we talk about

1070
00:45:28,280 --> 00:45:36,210
our own rights you go out every video

1071
00:45:33,030 --> 00:45:39,110
camera is being watched and you have AI

1072
00:45:36,210 --> 00:45:43,500
AM L based face recognition technologies

1073
00:45:39,110 --> 00:45:47,250
recently with a crowd of 50,000 they

1074
00:45:43,500 --> 00:45:50,790
actually identified and captured a guy

1075
00:45:47,250 --> 00:45:54,270
who has who is being a default are in

1076
00:45:50,790 --> 00:45:55,950
Lowell yeah who can tell me why we're

1077
00:45:54,270 --> 00:45:59,430
having why we have data localization

1078
00:45:55,950 --> 00:46:03,529
laws any views why is that becoming an

1079
00:45:59,430 --> 00:46:03,529
issue why is that becoming important

1080
00:46:04,040 --> 00:46:12,930
sorry so law enforcement agencies look

1081
00:46:11,250 --> 00:46:17,880
for law enforcement yes there's one

1082
00:46:12,930 --> 00:46:20,669
that's one year economic complete

1083
00:46:17,880 --> 00:46:23,580
differentiation okay

1084
00:46:20,670 --> 00:46:26,190
ability to tax do you understand how

1085
00:46:23,580 --> 00:46:31,920
this is all becoming an issue this one

1086
00:46:26,190 --> 00:46:34,020
more data privacy itself who knows okay

1087
00:46:31,920 --> 00:46:35,810
I'm assuming you guys have some idea of

1088
00:46:34,020 --> 00:46:38,190
the laws in data privacy

1089
00:46:35,810 --> 00:46:40,070
Homeland Security Act to understands how

1090
00:46:38,190 --> 00:46:44,100
that act actually works

1091
00:46:40,070 --> 00:46:46,950
okay under Homeland Security Act the US

1092
00:46:44,100 --> 00:46:48,750
government can access any data that

1093
00:46:46,950 --> 00:46:51,720
you've processed with Microsoft Google

1094
00:46:48,750 --> 00:46:53,550
any of the tech companies and they can

1095
00:46:51,720 --> 00:46:55,790
give I quote order to those companies to

1096
00:46:53,550 --> 00:46:58,380
give them the data without informing you

1097
00:46:55,790 --> 00:47:01,470
gross violation of safe harbor this is

1098
00:46:58,380 --> 00:47:03,900
why it without the DOE okay I think I

1099
00:47:01,470 --> 00:47:06,480
also heard that I also had on 29th of

1100
00:47:03,900 --> 00:47:08,280
March the noise about to change

1101
00:47:06,480 --> 00:47:10,800
yeah so the u.s. is having to change

1102
00:47:08,280 --> 00:47:12,890
this conversation because you have local

1103
00:47:10,800 --> 00:47:16,090
legislation in different countries that

1104
00:47:12,890 --> 00:47:17,830
do not necessarily enforce the same

1105
00:47:16,090 --> 00:47:20,290
and it's of privacy or even the same

1106
00:47:17,830 --> 00:47:21,940
sense of integrity across the globe it

1107
00:47:20,290 --> 00:47:25,630
is driven by country specific

1108
00:47:21,940 --> 00:47:27,540
legislation okay next one who

1109
00:47:25,630 --> 00:47:29,890
understands e-discovery

1110
00:47:27,540 --> 00:47:42,100
anyone heard the concept be discovery

1111
00:47:29,890 --> 00:47:45,339
what is he discovery provided they're

1112
00:47:42,100 --> 00:47:47,319
tamper proof hi it's not just the

1113
00:47:45,340 --> 00:47:50,080
insurance company oke discovering many

1114
00:47:47,320 --> 00:47:55,630
countries is the problem a court order

1115
00:47:50,080 --> 00:47:57,460
any court in in US UK Europe can

1116
00:47:55,630 --> 00:48:00,010
actually give an instruction to a

1117
00:47:57,460 --> 00:48:03,370
company to provide all data related to a

1118
00:48:00,010 --> 00:48:07,120
legal matter irrespective of where the

1119
00:48:03,370 --> 00:48:08,890
data exists in the world yeah okay now

1120
00:48:07,120 --> 00:48:11,040
this is where companies are having fun

1121
00:48:08,890 --> 00:48:14,319
cuz they don't know where the data is

1122
00:48:11,040 --> 00:48:18,160
right by default if you cannot provide

1123
00:48:14,320 --> 00:48:20,710
that data to the court okay you are

1124
00:48:18,160 --> 00:48:23,259
technically in contempt of court in the

1125
00:48:20,710 --> 00:48:24,910
u.s. you will be disbarred if the

1126
00:48:23,260 --> 00:48:29,710
following happens this is a very simple

1127
00:48:24,910 --> 00:48:32,020
example if you take a US Attorney if I

1128
00:48:29,710 --> 00:48:34,810
use it only gets a instruction to

1129
00:48:32,020 --> 00:48:37,720
provide electronic data to a court in

1130
00:48:34,810 --> 00:48:39,700
the US and he fails to provide some

1131
00:48:37,720 --> 00:48:43,180
piece of electronic data let's take an

1132
00:48:39,700 --> 00:48:46,839
email and the prosecution can generate

1133
00:48:43,180 --> 00:48:48,490
or produce that email to the court they

1134
00:48:46,840 --> 00:48:49,960
can basically hold them in contempt of

1135
00:48:48,490 --> 00:48:53,290
court now under the US system they are

1136
00:48:49,960 --> 00:48:54,670
guilty you see the problem here because

1137
00:48:53,290 --> 00:48:56,890
we are not able to control the

1138
00:48:54,670 --> 00:48:58,540
localization of data it becomes you

1139
00:48:56,890 --> 00:49:00,790
almost big start to breaking the law by

1140
00:48:58,540 --> 00:49:02,520
default in me nearest he discoveries got

1141
00:49:00,790 --> 00:49:05,050
a series of problems in this discussion

1142
00:49:02,520 --> 00:49:07,960
data localization starts to break down

1143
00:49:05,050 --> 00:49:11,830
these problems many country will have to

1144
00:49:07,960 --> 00:49:13,450
wind up actually here again I hope

1145
00:49:11,830 --> 00:49:16,000
you'll learn few things and I will learn

1146
00:49:13,450 --> 00:49:17,669
a lot from you guys as well so thanks a

1147
00:49:16,000 --> 00:49:19,710
lot thanks a lot for the panelist well

1148
00:49:17,670 --> 00:49:21,300
thank you

1149
00:49:19,710 --> 00:49:23,400
we thank you all for being a part of

1150
00:49:21,300 --> 00:49:25,170
this enlightening cyber intelligent

1151
00:49:23,400 --> 00:49:26,460
boardroom discussion I think we can take

1152
00:49:25,170 --> 00:49:28,910
questions offline you can meet our

1153
00:49:26,460 --> 00:49:28,910
panelists

