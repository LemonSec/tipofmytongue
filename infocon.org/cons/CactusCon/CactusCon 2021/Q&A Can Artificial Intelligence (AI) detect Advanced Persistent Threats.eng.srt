1
00:00:00,240 --> 00:00:03,920
four three

2
00:00:05,279 --> 00:00:10,639
hey everyone ryan here again with the

3
00:00:07,120 --> 00:00:12,879
cactus con crew and i am here

4
00:00:10,639 --> 00:00:17,600
to talk on artificial intelligence

5
00:00:12,880 --> 00:00:20,880
welcome and thank you for being with us

6
00:00:17,600 --> 00:00:20,880
hey guys this is ankur

7
00:00:21,279 --> 00:00:25,279
before we get going with our q a i'm

8
00:00:23,199 --> 00:00:28,800
going to go ahead and announce

9
00:00:25,279 --> 00:00:30,400
the winner of our previous

10
00:00:28,800 --> 00:00:34,239
giveaway in fact i'm going to go ahead

11
00:00:30,400 --> 00:00:34,239
and choose a winner right now

12
00:00:35,600 --> 00:00:38,320
survey says

13
00:00:39,200 --> 00:00:42,640
so we had two different giveaways going

14
00:00:41,200 --> 00:00:45,200
this interval we had a

15
00:00:42,640 --> 00:00:46,320
second towel of your choice and that

16
00:00:45,200 --> 00:00:47,520
goes to

17
00:00:46,320 --> 00:00:49,520
uh i'll probably butcher the

18
00:00:47,520 --> 00:00:52,879
pronunciation uh

19
00:00:49,520 --> 00:00:54,559
cubacon i'm not sure

20
00:00:52,879 --> 00:00:57,280
so thank you very much for entering the

21
00:00:54,559 --> 00:00:58,879
giveaway and your towel will be

22
00:00:57,280 --> 00:01:01,039
available to you you get to choose the

23
00:00:58,879 --> 00:01:02,640
size the logo from our store

24
00:01:01,039 --> 00:01:04,879
and we'll get it out to you we will

25
00:01:02,640 --> 00:01:08,960
contact you after the event

26
00:01:04,879 --> 00:01:14,560
and we also have another

27
00:01:08,960 --> 00:01:14,559
giveaway that we are trying to

28
00:01:15,680 --> 00:01:19,280
um we will get that uh out shortly i

29
00:01:18,640 --> 00:01:22,240
guess

30
00:01:19,280 --> 00:01:23,040
so for now ankur thank you again for

31
00:01:22,240 --> 00:01:25,600
presenting

32
00:01:23,040 --> 00:01:27,680
uh great talk i personally have quite a

33
00:01:25,600 --> 00:01:28,559
fondness for artificial intelligence and

34
00:01:27,680 --> 00:01:31,119
i work for

35
00:01:28,560 --> 00:01:32,240
blackberry formerly silence so i mean

36
00:01:31,119 --> 00:01:34,799
obviously that's

37
00:01:32,240 --> 00:01:36,000
that's a big thing for us right yeah it

38
00:01:34,799 --> 00:01:37,680
is

39
00:01:36,000 --> 00:01:39,040
i was with my former company for seven

40
00:01:37,680 --> 00:01:40,960
years and it took

41
00:01:39,040 --> 00:01:42,479
finally moved on and one of the big

42
00:01:40,960 --> 00:01:45,280
things that was like yeah

43
00:01:42,479 --> 00:01:46,240
i want to be a part of that was the ai

44
00:01:45,280 --> 00:01:48,399
and the machine learning

45
00:01:46,240 --> 00:01:50,560
and you know just how it really is going

46
00:01:48,399 --> 00:01:52,240
to shape a lot of what we're doing

47
00:01:50,560 --> 00:01:53,600
i would say in the future but you know

48
00:01:52,240 --> 00:01:56,158
now so

49
00:01:53,600 --> 00:01:56,960
great talk thank you very much uh any

50
00:01:56,159 --> 00:01:58,560
comments

51
00:01:56,960 --> 00:02:00,240
or or questions or anything yourself

52
00:01:58,560 --> 00:02:01,920
before we get to the general user

53
00:02:00,240 --> 00:02:04,560
questions

54
00:02:01,920 --> 00:02:06,719
uh uh some information we have a hacking

55
00:02:04,560 --> 00:02:08,318
club at asu double sec so do check us

56
00:02:06,719 --> 00:02:11,359
out we do very interesting

57
00:02:08,318 --> 00:02:12,000
talks and if you are a sponsor or

58
00:02:11,360 --> 00:02:13,840
company

59
00:02:12,000 --> 00:02:15,040
who want to interact with students want

60
00:02:13,840 --> 00:02:16,959
to give them some

61
00:02:15,040 --> 00:02:18,799
information about how to get started in

62
00:02:16,959 --> 00:02:21,760
the field how to find

63
00:02:18,800 --> 00:02:23,840
internships and jobs uh yeah uh do join

64
00:02:21,760 --> 00:02:26,799
us on our discord channel there is

65
00:02:23,840 --> 00:02:27,120
uh there are people from double sec here

66
00:02:26,800 --> 00:02:29,520
uh

67
00:02:27,120 --> 00:02:30,879
knight being errors so do talk to them

68
00:02:29,520 --> 00:02:34,239
if you are interested

69
00:02:30,879 --> 00:02:36,160
thank you awesome devil sec i believe

70
00:02:34,239 --> 00:02:36,720
you had a bit of a presence at cactus

71
00:02:36,160 --> 00:02:40,959
con

72
00:02:36,720 --> 00:02:43,680
last year with double sec we did

73
00:02:40,959 --> 00:02:45,519
our team was uh there last year to

74
00:02:43,680 --> 00:02:48,800
support me during my talk so

75
00:02:45,519 --> 00:02:51,360
a big shout out to you guys

76
00:02:48,800 --> 00:02:52,640
yeah very cool um love when we uh

77
00:02:51,360 --> 00:02:55,120
support the education

78
00:02:52,640 --> 00:02:55,760
and helping people funnel into our our

79
00:02:55,120 --> 00:02:58,000
pipeline

80
00:02:55,760 --> 00:02:59,440
right yeah so all right a couple

81
00:02:58,000 --> 00:03:00,800
different questions first off i'll just

82
00:02:59,440 --> 00:03:02,640
throw it out there someone asked will

83
00:03:00,800 --> 00:03:05,360
there be powerpoints available

84
00:03:02,640 --> 00:03:07,279
yes so anker has already provided his

85
00:03:05,360 --> 00:03:09,599
actually but we will be posting

86
00:03:07,280 --> 00:03:11,360
links we're going to update the website

87
00:03:09,599 --> 00:03:12,799
postcon i don't know if it's going to be

88
00:03:11,360 --> 00:03:14,239
sunday or a couple days after or when

89
00:03:12,800 --> 00:03:15,840
we'll get to it but we're going to have

90
00:03:14,239 --> 00:03:17,200
links to the youtube video to this

91
00:03:15,840 --> 00:03:19,519
youtube q a

92
00:03:17,200 --> 00:03:21,200
the individual sessions and posting

93
00:03:19,519 --> 00:03:23,360
slides as they're provided by

94
00:03:21,200 --> 00:03:24,640
our presenters so getting to some

95
00:03:23,360 --> 00:03:26,640
questions here we've got about five

96
00:03:24,640 --> 00:03:28,399
minutes to answer some questions

97
00:03:26,640 --> 00:03:30,319
um where in the network is the core

98
00:03:28,400 --> 00:03:34,080
function of the ai working at

99
00:03:30,319 --> 00:03:36,958
and can the ai be fed false data sets

100
00:03:34,080 --> 00:03:38,480
yeah so ai is working on the network

101
00:03:36,959 --> 00:03:39,840
traffic that we captured at the

102
00:03:38,480 --> 00:03:43,119
interface of both

103
00:03:39,840 --> 00:03:45,200
uh public and private network the logs

104
00:03:43,120 --> 00:03:47,280
that we collected from snort which was a

105
00:03:45,200 --> 00:03:49,920
interesting detection system

106
00:03:47,280 --> 00:03:51,360
the logs that we collected from the

107
00:03:49,920 --> 00:03:55,359
individual machines

108
00:03:51,360 --> 00:03:59,120
they include host logs dns logs

109
00:03:55,360 --> 00:04:02,000
access logs to the apache server

110
00:03:59,120 --> 00:04:04,560
samba server any storage components like

111
00:04:02,000 --> 00:04:07,680
we had nexus we collected logs from

112
00:04:04,560 --> 00:04:10,879
that we extracted about 84

113
00:04:07,680 --> 00:04:11,680
features from the network traffic and

114
00:04:10,879 --> 00:04:15,920
the host

115
00:04:11,680 --> 00:04:16,798
logs so that's where the ai component is

116
00:04:15,920 --> 00:04:19,358
working

117
00:04:16,798 --> 00:04:20,719
so second question is very interesting

118
00:04:19,358 --> 00:04:22,960
there are

119
00:04:20,720 --> 00:04:24,720
cases where you can trick the ai model

120
00:04:22,960 --> 00:04:28,159
itself

121
00:04:24,720 --> 00:04:31,840
so you can feed the fake data

122
00:04:28,160 --> 00:04:34,160
and try to trick the ai model to

123
00:04:31,840 --> 00:04:35,119
do the incorrect prediction or what you

124
00:04:34,160 --> 00:04:38,560
can do is

125
00:04:35,120 --> 00:04:39,919
uh interact with ai model in such a way

126
00:04:38,560 --> 00:04:42,720
that you just

127
00:04:39,919 --> 00:04:43,680
identify what sort of detection ai model

128
00:04:42,720 --> 00:04:46,639
is using just

129
00:04:43,680 --> 00:04:47,280
identify all its feature set so there

130
00:04:46,639 --> 00:04:49,759
has been

131
00:04:47,280 --> 00:04:50,638
active research in this direction where

132
00:04:49,759 --> 00:04:54,000
the

133
00:04:50,639 --> 00:04:54,560
researchers are trying to protect the ai

134
00:04:54,000 --> 00:04:56,880
models

135
00:04:54,560 --> 00:04:58,000
against this class known as adversarial

136
00:04:56,880 --> 00:04:59,919
attack so

137
00:04:58,000 --> 00:05:01,199
yeah you can check those out like i

138
00:04:59,919 --> 00:05:03,680
posted a link of

139
00:05:01,199 --> 00:05:05,039
defense scan that deals with that

140
00:05:03,680 --> 00:05:08,160
particular problem

141
00:05:05,039 --> 00:05:11,840
but we did not address that problem in

142
00:05:08,160 --> 00:05:11,840
this research

143
00:05:13,120 --> 00:05:18,800
awesome thank you and

144
00:05:16,479 --> 00:05:20,560
another question for you is how did you

145
00:05:18,800 --> 00:05:23,520
avoid data bias

146
00:05:20,560 --> 00:05:25,039
using the collection methodology similar

147
00:05:23,520 --> 00:05:28,159
pitfalls to the kd

148
00:05:25,039 --> 00:05:31,120
99 come to mind so

149
00:05:28,160 --> 00:05:32,479
there will be a data bias when apt

150
00:05:31,120 --> 00:05:35,280
attacks are concerned

151
00:05:32,479 --> 00:05:36,320
considered so basically the typical

152
00:05:35,280 --> 00:05:40,080
duration of

153
00:05:36,320 --> 00:05:41,840
an apt attack is 70 to 72 days

154
00:05:40,080 --> 00:05:44,159
and if you look at the sony hack that

155
00:05:41,840 --> 00:05:47,520
happened for 143

156
00:05:44,160 --> 00:05:48,000
days so how do i you identify signal

157
00:05:47,520 --> 00:05:50,479
from

158
00:05:48,000 --> 00:05:52,160
such huge amount of network traffic so

159
00:05:50,479 --> 00:05:55,039
we tried to focus on the

160
00:05:52,160 --> 00:05:55,520
models that do anomaly detection and we

161
00:05:55,039 --> 00:05:57,440
tried

162
00:05:55,520 --> 00:05:58,639
using the benchmarking methods like

163
00:05:57,440 --> 00:06:02,719
precision

164
00:05:58,639 --> 00:06:04,880
uh which are more uh focused towards the

165
00:06:02,720 --> 00:06:07,360
positive samples of the

166
00:06:04,880 --> 00:06:09,520
machine learning classifications as

167
00:06:07,360 --> 00:06:12,080
opposed to roc or receiver of

168
00:06:09,520 --> 00:06:14,000
operating characteristics uh that

169
00:06:12,080 --> 00:06:16,318
include false positive rates and that

170
00:06:14,000 --> 00:06:19,360
can induce that kind of bias

171
00:06:16,319 --> 00:06:21,199
so the models that we considered like

172
00:06:19,360 --> 00:06:23,440
one class svm

173
00:06:21,199 --> 00:06:24,240
lstm stack auto encoder and stack auto

174
00:06:23,440 --> 00:06:26,160
encoder

175
00:06:24,240 --> 00:06:28,560
they try to do anomaly detection

176
00:06:26,160 --> 00:06:31,759
basically try to identify

177
00:06:28,560 --> 00:06:34,400
the positive class of samples from this

178
00:06:31,759 --> 00:06:34,800
huge amount of data another thing that

179
00:06:34,400 --> 00:06:37,840
we

180
00:06:34,800 --> 00:06:39,600
did was uh we collected the data for

181
00:06:37,840 --> 00:06:40,960
different phases of apt attack over

182
00:06:39,600 --> 00:06:43,440
multiple days

183
00:06:40,960 --> 00:06:45,440
like on monday we just baselined the

184
00:06:43,440 --> 00:06:47,600
normal traffic how it looks like

185
00:06:45,440 --> 00:06:48,880
on tuesday although we had normal

186
00:06:47,600 --> 00:06:50,560
traffic going on

187
00:06:48,880 --> 00:06:52,400
we just performed the reconnaissance

188
00:06:50,560 --> 00:06:54,800
activities and

189
00:06:52,400 --> 00:06:56,638
so forth like on wednesday we had the

190
00:06:54,800 --> 00:06:59,599
foothold establishment phase

191
00:06:56,639 --> 00:07:00,960
so that way it was kind of easier to

192
00:06:59,599 --> 00:07:04,000
distinguish

193
00:07:00,960 --> 00:07:04,560
like what does the normal traffic look

194
00:07:04,000 --> 00:07:07,280
like

195
00:07:04,560 --> 00:07:08,800
as a baseline and then use our anomaly

196
00:07:07,280 --> 00:07:11,840
detection models to

197
00:07:08,800 --> 00:07:11,840
do the prediction

198
00:07:12,400 --> 00:07:19,599
awesome all right very very cool um

199
00:07:16,639 --> 00:07:20,880
i was uh giving a random panel talk one

200
00:07:19,599 --> 00:07:23,280
one day for work

201
00:07:20,880 --> 00:07:25,360
and uh one of the audience members uh

202
00:07:23,280 --> 00:07:28,000
wasn't wasn't prepared for this question

203
00:07:25,360 --> 00:07:30,319
can you easily and succinctly define the

204
00:07:28,000 --> 00:07:32,000
difference between ai and machine

205
00:07:30,319 --> 00:07:35,680
learning

206
00:07:32,000 --> 00:07:38,639
yeah i can i can uh

207
00:07:35,680 --> 00:07:39,840
it got to be very very interesting for a

208
00:07:38,639 --> 00:07:42,080
lot of folks who weren't you know

209
00:07:39,840 --> 00:07:44,159
yet aware um you obviously are a master

210
00:07:42,080 --> 00:07:45,359
of your craft and again we really really

211
00:07:44,160 --> 00:07:46,960
thank you there are a couple other

212
00:07:45,360 --> 00:07:48,080
questions but time-wise we gotta wrap

213
00:07:46,960 --> 00:07:50,560
this up so

214
00:07:48,080 --> 00:07:51,919
hey ankur thank you very much again and

215
00:07:50,560 --> 00:07:52,800
this will all be available on youtube

216
00:07:51,919 --> 00:07:56,080
for folks to watch

217
00:07:52,800 --> 00:07:58,879
later yeah thanks a lot everyone for uh

218
00:07:56,080 --> 00:08:00,878
hosting me and thanks a lot to uh my

219
00:07:58,879 --> 00:08:04,000
colleagues at bishopfox

220
00:08:00,879 --> 00:08:07,919
and blackberry uh hello and

221
00:08:04,000 --> 00:08:13,840
thanks everyone for joining my talk

222
00:08:07,919 --> 00:08:13,840
all right thank you very much

