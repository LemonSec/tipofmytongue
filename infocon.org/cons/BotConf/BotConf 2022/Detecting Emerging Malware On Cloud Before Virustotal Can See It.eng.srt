1
00:00:01,040 --> 00:00:03,120
um so the

2
00:00:03,120 --> 00:00:05,040
the next talk is not about the virus

3
00:00:05,040 --> 00:00:07,279
total

4
00:00:07,279 --> 00:00:10,240
um it's so it's about detecting uh

5
00:00:10,240 --> 00:00:12,400
emerging threats uh

6
00:00:12,400 --> 00:00:14,240
before they reach fires total before

7
00:00:14,240 --> 00:00:17,440
they are shared and so on and uh so

8
00:00:17,440 --> 00:00:20,160
andreas and anastasia

9
00:00:20,160 --> 00:00:22,080
have the floor thank you

10
00:00:22,080 --> 00:00:24,160
well i'm not andreas yeah yeah not andre

11
00:00:24,160 --> 00:00:25,680
sorry hey yuri

12
00:00:25,680 --> 00:00:27,840
andreas unfortunately uh was supposed to

13
00:00:27,840 --> 00:00:29,119
talk

14
00:00:29,119 --> 00:00:31,599
unfortunately he could not come so um

15
00:00:31,599 --> 00:00:33,280
i'm um

16
00:00:33,280 --> 00:00:35,120
you're undressed today no you're

17
00:00:35,120 --> 00:00:37,200
undressed today yeah i'm andreas today

18
00:00:37,200 --> 00:00:39,440
yeah yuri

19
00:00:39,440 --> 00:00:40,559
and

20
00:00:40,559 --> 00:00:44,160
anastasia you have the floor thank you

21
00:00:44,320 --> 00:00:45,680
so

22
00:00:45,680 --> 00:00:47,600
we're going to talk about today about

23
00:00:47,600 --> 00:00:50,000
the work that we've been doing for uh

24
00:00:50,000 --> 00:00:51,920
probably a year

25
00:00:51,920 --> 00:00:52,800
to

26
00:00:52,800 --> 00:00:55,360
try to develop the machinery to detect

27
00:00:55,360 --> 00:00:59,039
emerging malware in the cloud at scale

28
00:00:59,039 --> 00:01:01,199
using fuzzy hashing

29
00:01:01,199 --> 00:01:04,159
and uh there is a large team worked on

30
00:01:04,159 --> 00:01:06,159
this project and

31
00:01:06,159 --> 00:01:08,960
anastasia polycova uh

32
00:01:08,960 --> 00:01:10,799
and me yuri zufoish you're going to

33
00:01:10,799 --> 00:01:13,600
present today but i want to mention by

34
00:01:13,600 --> 00:01:15,759
name that uh gantan

35
00:01:15,759 --> 00:01:17,920
ali hon yang

36
00:01:17,920 --> 00:01:19,360
made a

37
00:01:19,360 --> 00:01:20,880
very significant contribution more than

38
00:01:20,880 --> 00:01:22,240
i did

39
00:01:22,240 --> 00:01:23,759
leading this group

40
00:01:23,759 --> 00:01:24,840
and

41
00:01:24,840 --> 00:01:29,119
andreas so we are from alibaba cloud

42
00:01:29,119 --> 00:01:30,479
but

43
00:01:30,479 --> 00:01:32,640
andreas is from dhamma academy of

44
00:01:32,640 --> 00:01:35,040
alibaba so this is a research

45
00:01:35,040 --> 00:01:38,560
unit of alibaba group

46
00:01:38,840 --> 00:01:41,200
and so uh

47
00:01:41,200 --> 00:01:43,040
in the picture uh we kind of like to

48
00:01:43,040 --> 00:01:45,280
think about uh ourselves sometimes as

49
00:01:45,280 --> 00:01:46,320
minions

50
00:01:46,320 --> 00:01:47,040
we

51
00:01:47,040 --> 00:01:50,399
believe to serve

52
00:01:51,200 --> 00:01:54,720
so um so these are the speakers today

53
00:01:54,720 --> 00:01:57,679
without andreas

54
00:01:58,479 --> 00:01:59,680
so with that

55
00:01:59,680 --> 00:02:00,640
i'll let

56
00:02:00,640 --> 00:02:03,840
anastasia take over

57
00:02:04,000 --> 00:02:05,920
thank you yuri thank you dominica for

58
00:02:05,920 --> 00:02:06,840
farm

59
00:02:06,840 --> 00:02:10,080
reference so i'm anastasia palikova i'm

60
00:02:10,080 --> 00:02:12,560
secure senior security engineer of

61
00:02:12,560 --> 00:02:15,440
alibaba innovation security lab and

62
00:02:15,440 --> 00:02:16,560
today

63
00:02:16,560 --> 00:02:19,920
we will start with security reasons why

64
00:02:19,920 --> 00:02:22,400
did we start this research and

65
00:02:22,400 --> 00:02:25,280
how it goes what we achieve

66
00:02:25,280 --> 00:02:28,800
but first first things first why

67
00:02:28,800 --> 00:02:31,920
um when you work in a

68
00:02:31,920 --> 00:02:33,599
big company and you have a lot of

69
00:02:33,599 --> 00:02:36,000
customers in the scale of basically

70
00:02:36,000 --> 00:02:37,760
everything is huge

71
00:02:37,760 --> 00:02:40,560
you start to treasure little things and

72
00:02:40,560 --> 00:02:42,720
the little things become big so

73
00:02:42,720 --> 00:02:45,280
third-party validation of any iocs you

74
00:02:45,280 --> 00:02:47,680
have comes with a price

75
00:02:47,680 --> 00:02:50,879
first is a latency and latency from the

76
00:02:50,879 --> 00:02:53,920
both sides in our case first of all when

77
00:02:53,920 --> 00:02:56,640
we talk about validation of the

78
00:02:56,640 --> 00:02:58,640
show value in our case

79
00:02:58,640 --> 00:03:01,120
we're talking about not one child value

80
00:03:01,120 --> 00:03:03,360
we need to validate manually somehow but

81
00:03:03,360 --> 00:03:05,760
we are talking about huge pipeline of

82
00:03:05,760 --> 00:03:08,400
the show values we need to validate

83
00:03:08,400 --> 00:03:11,280
so we need to build the whole pipeline

84
00:03:11,280 --> 00:03:13,920
put them into the queue validate them

85
00:03:13,920 --> 00:03:16,159
with virustotal usually because we use

86
00:03:16,159 --> 00:03:17,040
it

87
00:03:17,040 --> 00:03:20,480
and then wait for results and then

88
00:03:20,480 --> 00:03:23,040
interpret this result so latency comes

89
00:03:23,040 --> 00:03:25,760
from the boss side from our pipeline and

90
00:03:25,760 --> 00:03:27,280
from

91
00:03:27,280 --> 00:03:29,440
third party validation in our case of

92
00:03:29,440 --> 00:03:31,280
aristotle

93
00:03:31,280 --> 00:03:34,480
um of course license are not free so we

94
00:03:34,480 --> 00:03:36,400
need to pay to virustodo to get an

95
00:03:36,400 --> 00:03:39,120
access to the data obviously

96
00:03:39,120 --> 00:03:40,480
and

97
00:03:40,480 --> 00:03:42,239
it's not very

98
00:03:42,239 --> 00:03:43,840
bad i would say

99
00:03:43,840 --> 00:03:45,519
as long as you have a budget you can

100
00:03:45,519 --> 00:03:47,840
afford it but it creates a huge

101
00:03:47,840 --> 00:03:50,400
dependency of your security program and

102
00:03:50,400 --> 00:03:53,439
your security software to one particular

103
00:03:53,439 --> 00:03:55,760
third-party vendor who provides you with

104
00:03:55,760 --> 00:03:58,400
validation and then dependency can bite

105
00:03:58,400 --> 00:04:01,200
you back one day for example what if why

106
00:04:01,200 --> 00:04:03,519
aristotle decided to go out of the

107
00:04:03,519 --> 00:04:06,959
market on the country or work with only

108
00:04:06,959 --> 00:04:09,760
particular companies or revoke our

109
00:04:09,760 --> 00:04:11,760
license for some reason how we're going

110
00:04:11,760 --> 00:04:15,200
to proceed should our security program

111
00:04:15,200 --> 00:04:17,759
stop or what we're going to do of course

112
00:04:17,759 --> 00:04:19,040
in case

113
00:04:19,040 --> 00:04:21,279
of our team we're serving the cloud

114
00:04:21,279 --> 00:04:23,919
customers it's not acceptable at all we

115
00:04:23,919 --> 00:04:26,639
need to continue operation

116
00:04:26,639 --> 00:04:27,759
second

117
00:04:27,759 --> 00:04:30,160
reason is ambiguous vt result

118
00:04:30,160 --> 00:04:32,639
interpretation probably

119
00:04:32,639 --> 00:04:35,919
you all seen this very frustrating page

120
00:04:35,919 --> 00:04:38,240
when virustotal just returned you no

121
00:04:38,240 --> 00:04:40,320
results found i have no idea what you're

122
00:04:40,320 --> 00:04:41,680
talking about

123
00:04:41,680 --> 00:04:44,160
how we should interpret that

124
00:04:44,160 --> 00:04:46,160
is it malicious

125
00:04:46,160 --> 00:04:48,800
is it brand new is it benign we don't

126
00:04:48,800 --> 00:04:50,080
know

127
00:04:50,080 --> 00:04:52,960
so that's frustrating but not that

128
00:04:52,960 --> 00:04:56,160
frustrating like very unclear result for

129
00:04:56,160 --> 00:04:58,400
example we all know that the virus total

130
00:04:58,400 --> 00:05:01,759
has around 60 different aging engines

131
00:05:01,759 --> 00:05:04,560
that contributes to detection

132
00:05:04,560 --> 00:05:07,759
and when you validate a challenge and

133
00:05:07,759 --> 00:05:09,120
only two

134
00:05:09,120 --> 00:05:12,400
of the 60 agents tell you yeah we think

135
00:05:12,400 --> 00:05:14,160
that's malicious what are you going to

136
00:05:14,160 --> 00:05:15,919
do are you going to trust

137
00:05:15,919 --> 00:05:18,080
how you're going to validate it if you

138
00:05:18,080 --> 00:05:19,280
don't have

139
00:05:19,280 --> 00:05:21,680
any resources to go deep inside of the

140
00:05:21,680 --> 00:05:25,840
malware binary and reverse engineer it

141
00:05:25,840 --> 00:05:28,160
is it's malicious is it false positive

142
00:05:28,160 --> 00:05:29,039
on

143
00:05:29,039 --> 00:05:30,720
this two vendor site is it false

144
00:05:30,720 --> 00:05:32,639
negative to others

145
00:05:32,639 --> 00:05:35,600
how we should treat it

146
00:05:35,600 --> 00:05:38,639
and of course there is some geopolitics

147
00:05:38,639 --> 00:05:40,960
stuff like malware targeting chinese

148
00:05:40,960 --> 00:05:44,479
customers in underreported to aristotle

149
00:05:44,479 --> 00:05:46,960
a lot of other co-workers in

150
00:05:46,960 --> 00:05:50,639
alibaba cloud use completely different

151
00:05:50,639 --> 00:05:54,479
source of ti than virus total and

152
00:05:54,479 --> 00:05:57,199
a lot of malware goes under the radar

153
00:05:57,199 --> 00:05:59,280
when we're talking about chinese market

154
00:05:59,280 --> 00:06:01,840
and malware targeting chinese customers

155
00:06:01,840 --> 00:06:03,440
i know you have heard about chinese

156
00:06:03,440 --> 00:06:05,360
malware a lot as it was for the previous

157
00:06:05,360 --> 00:06:07,039
day and for this day probably we will

158
00:06:07,039 --> 00:06:08,720
hear again and again

159
00:06:08,720 --> 00:06:09,680
but

160
00:06:09,680 --> 00:06:12,479
when it goes to analytics

161
00:06:12,479 --> 00:06:15,199
and to reverse engineering or some data

162
00:06:15,199 --> 00:06:17,919
about this malware best you can do find

163
00:06:17,919 --> 00:06:19,759
something in mandarin

164
00:06:19,759 --> 00:06:22,000
that you need to translate using google

165
00:06:22,000 --> 00:06:24,400
translator and virustotal usually

166
00:06:24,400 --> 00:06:28,479
absolutely not aware about this malware

167
00:06:28,479 --> 00:06:30,720
last but not least cloud specific

168
00:06:30,720 --> 00:06:32,800
threats

169
00:06:32,800 --> 00:06:35,440
you know as any as a cloud provider

170
00:06:35,440 --> 00:06:38,319
alibaba shares security responsibility

171
00:06:38,319 --> 00:06:40,639
with the customers so we cannot be

172
00:06:40,639 --> 00:06:43,600
responsible for everything some binaries

173
00:06:43,600 --> 00:06:45,440
belongs to the customer and those

174
00:06:45,440 --> 00:06:47,759
binaries are part of their business and

175
00:06:47,759 --> 00:06:49,280
their operation

176
00:06:49,280 --> 00:06:52,720
but if we can see only the value how can

177
00:06:52,720 --> 00:06:53,440
we

178
00:06:53,440 --> 00:06:55,680
guess is it a binary balance to the

179
00:06:55,680 --> 00:06:58,160
customer is it a malware is it

180
00:06:58,160 --> 00:07:01,199
well-known binary we already seen

181
00:07:01,199 --> 00:07:02,720
nobody knows

182
00:07:02,720 --> 00:07:05,599
so considered all of this problem we

183
00:07:05,599 --> 00:07:07,840
decided that we need to start our own

184
00:07:07,840 --> 00:07:11,440
research and we need to take our

185
00:07:11,440 --> 00:07:13,840
validation ioc validation at least

186
00:07:13,840 --> 00:07:16,880
partly at home and not ship everything

187
00:07:16,880 --> 00:07:17,919
to the

188
00:07:17,919 --> 00:07:20,800
vendors outside because of all these

189
00:07:20,800 --> 00:07:23,199
problems listed about

190
00:07:23,199 --> 00:07:25,440
and there is a tale of

191
00:07:25,440 --> 00:07:27,199
two cities

192
00:07:27,199 --> 00:07:30,400
this is a virus total and our cloud

193
00:07:30,400 --> 00:07:32,560
so in our cloud we gather particular

194
00:07:32,560 --> 00:07:34,880
information about binaries we gather

195
00:07:34,880 --> 00:07:38,000
chavalio and md5 failure

196
00:07:38,000 --> 00:07:41,840
and if we have some suspicions about

197
00:07:41,840 --> 00:07:44,000
this particular binary we going in check

198
00:07:44,000 --> 00:07:46,160
it with varus total like hey what do you

199
00:07:46,160 --> 00:07:48,319
think does it look like any malware you

200
00:07:48,319 --> 00:07:49,199
know

201
00:07:49,199 --> 00:07:52,639
but unfortunately and sadly too often we

202
00:07:52,639 --> 00:07:54,720
receive the replay like i have no idea

203
00:07:54,720 --> 00:07:57,520
what that no results found

204
00:07:57,520 --> 00:08:00,720
and again it we start to frustrate what

205
00:08:00,720 --> 00:08:02,400
we should do with that how we should

206
00:08:02,400 --> 00:08:04,160
classify it

207
00:08:04,160 --> 00:08:05,039
so

208
00:08:05,039 --> 00:08:08,560
it leads us to the idea so maybe we try

209
00:08:08,560 --> 00:08:10,639
to verify

210
00:08:10,639 --> 00:08:13,759
not the right data we asking for the

211
00:08:13,759 --> 00:08:14,800
wrong

212
00:08:14,800 --> 00:08:16,400
question and we

213
00:08:16,400 --> 00:08:18,319
receive the incorrect answer

214
00:08:18,319 --> 00:08:20,800
this is how we start to gather and

215
00:08:20,800 --> 00:08:24,319
collect fuzzy hash

216
00:08:24,400 --> 00:08:27,638
come on

217
00:08:30,160 --> 00:08:31,840
i'm sorry

218
00:08:31,840 --> 00:08:34,479
so fuzzy hash i believe most of us know

219
00:08:34,479 --> 00:08:38,080
what it is fuzzy hash is a contextual

220
00:08:38,080 --> 00:08:41,839
hash that basically can consist of three

221
00:08:41,839 --> 00:08:44,800
different blocks first is a block size

222
00:08:44,800 --> 00:08:48,399
second is hash one and divided by uh

223
00:08:48,399 --> 00:08:50,480
column the hash two

224
00:08:50,480 --> 00:08:53,279
in this example we provide you with

225
00:08:53,279 --> 00:08:55,120
ssd fuzzy hash

226
00:08:55,120 --> 00:08:56,480
values for

227
00:08:56,480 --> 00:08:58,880
fenix miner family

228
00:08:58,880 --> 00:09:01,120
let's talk about distance

229
00:09:01,120 --> 00:09:02,080
if you

230
00:09:02,080 --> 00:09:04,640
look a little bit closer to all these

231
00:09:04,640 --> 00:09:06,000
hash values

232
00:09:06,000 --> 00:09:07,279
i believe

233
00:09:07,279 --> 00:09:10,320
nobody needs to be genius security

234
00:09:10,320 --> 00:09:12,880
researcher or data analytic

235
00:09:12,880 --> 00:09:13,839
to

236
00:09:13,839 --> 00:09:17,200
notice this eyeballing

237
00:09:17,200 --> 00:09:21,440
you know um common parts and i believe

238
00:09:21,440 --> 00:09:22,880
i balance simul

239
00:09:22,880 --> 00:09:25,839
similarity in between several hashes

240
00:09:25,839 --> 00:09:28,000
and some difference

241
00:09:28,000 --> 00:09:31,200
so yeah let's show some respect

242
00:09:31,200 --> 00:09:33,279
this minor tries its best

243
00:09:33,279 --> 00:09:36,640
and if we cannot look for the fuzzy

244
00:09:36,640 --> 00:09:38,800
hashes as deep in our case and we can

245
00:09:38,800 --> 00:09:40,640
look only on

246
00:09:40,640 --> 00:09:44,640
md5 or chavalio we will never ever guess

247
00:09:44,640 --> 00:09:47,360
that this chavalo or md5 value belongs

248
00:09:47,360 --> 00:09:48,720
to the same aware family they are

249
00:09:48,720 --> 00:09:51,200
completely different but because fuzzy

250
00:09:51,200 --> 00:09:53,200
hash is contextual we can see the

251
00:09:53,200 --> 00:09:55,760
similarity with the bar eye

252
00:09:55,760 --> 00:09:58,080
and we can see the difference and if my

253
00:09:58,080 --> 00:10:00,160
sore red eyes can see the difference in

254
00:10:00,160 --> 00:10:02,160
similarity machine can see it even

255
00:10:02,160 --> 00:10:03,680
better i believe

256
00:10:03,680 --> 00:10:04,399
so

257
00:10:04,399 --> 00:10:07,200
why not to try

258
00:10:07,920 --> 00:10:09,920
so the one term we need to know is the

259
00:10:09,920 --> 00:10:12,560
distance what is the distance uh

260
00:10:12,560 --> 00:10:15,839
distance is a function of two uh

261
00:10:15,839 --> 00:10:18,399
of two fuzzy hash values

262
00:10:18,399 --> 00:10:21,760
and it basically shows how similar they

263
00:10:21,760 --> 00:10:22,959
are

264
00:10:22,959 --> 00:10:26,880
usually distance lie in um

265
00:10:26,880 --> 00:10:28,640
in a range from

266
00:10:28,640 --> 00:10:30,000
zero to one

267
00:10:30,000 --> 00:10:33,600
or from one to 100 depends on algorithm

268
00:10:33,600 --> 00:10:34,480
you use

269
00:10:34,480 --> 00:10:37,040
but basically it's bigger the d is

270
00:10:37,040 --> 00:10:40,720
bigger the distance is less similar

271
00:10:40,720 --> 00:10:44,000
your character is up

272
00:10:44,560 --> 00:10:47,519
ok i believe that every second security

273
00:10:47,519 --> 00:10:50,320
engineer every first security team

274
00:10:50,320 --> 00:10:52,959
once came up with this idea and think

275
00:10:52,959 --> 00:10:53,920
okay

276
00:10:53,920 --> 00:10:56,240
fuzzy hash it looks so great we both can

277
00:10:56,240 --> 00:10:58,480
cure the world if we implement that

278
00:10:58,480 --> 00:11:00,720
why nobody did

279
00:11:00,720 --> 00:11:02,320
in a large scale

280
00:11:02,320 --> 00:11:05,680
because the idea looks much more simpler

281
00:11:05,680 --> 00:11:08,000
than implementation itself

282
00:11:08,000 --> 00:11:11,040
and why did we dare to try why did we

283
00:11:11,040 --> 00:11:12,959
give it a try why we start to work on

284
00:11:12,959 --> 00:11:15,200
this project

285
00:11:15,200 --> 00:11:16,800
because we have some advantages and some

286
00:11:16,800 --> 00:11:18,959
privileges of course

287
00:11:18,959 --> 00:11:20,640
i'm not trying to

288
00:11:20,640 --> 00:11:22,880
tell that our team is any better than

289
00:11:22,880 --> 00:11:24,000
yours

290
00:11:24,000 --> 00:11:27,360
but probably our data set is bigger and

291
00:11:27,360 --> 00:11:29,120
first obstacle

292
00:11:29,120 --> 00:11:33,040
every security team runs it i is a

293
00:11:33,040 --> 00:11:35,680
question do you have enough data

294
00:11:35,680 --> 00:11:38,800
because even i don't have enough data

295
00:11:38,800 --> 00:11:41,279
and i have like very few lonely show

296
00:11:41,279 --> 00:11:43,279
values i'm going to compare to each

297
00:11:43,279 --> 00:11:45,200
other

298
00:11:45,200 --> 00:11:46,640
games over

299
00:11:46,640 --> 00:11:49,200
if i cannot benchmark them and if i if i

300
00:11:49,200 --> 00:11:51,760
cannot measure the difference in between

301
00:11:51,760 --> 00:11:54,320
known malware or known benign files and

302
00:11:54,320 --> 00:11:56,800
my unknown hashes

303
00:11:56,800 --> 00:11:58,240
how should it work

304
00:11:58,240 --> 00:12:00,639
no we need a huge database of hashes and

305
00:12:00,639 --> 00:12:03,760
we need to label them we need at least

306
00:12:03,760 --> 00:12:05,839
a little bit of knowledges what is

307
00:12:05,839 --> 00:12:08,399
malicious what's not

308
00:12:08,399 --> 00:12:11,279
algorithm and computing power

309
00:12:11,279 --> 00:12:13,279
this obstacle can scare

310
00:12:13,279 --> 00:12:16,000
almost anybody away because when you

311
00:12:16,000 --> 00:12:17,200
start to

312
00:12:17,200 --> 00:12:20,160
think about okay fuzzy hash is pretty

313
00:12:20,160 --> 00:12:22,720
long and to be honest fed

314
00:12:22,720 --> 00:12:24,639
line we need to find the similarity in

315
00:12:24,639 --> 00:12:26,240
between and we need to compare it

316
00:12:26,240 --> 00:12:29,200
pairwise one by one choose a million

317
00:12:29,200 --> 00:12:31,600
differential values how can they afford

318
00:12:31,600 --> 00:12:34,800
it what our gram should we use and

319
00:12:34,800 --> 00:12:38,480
especially if you going to rely on

320
00:12:38,480 --> 00:12:40,800
publicly available algorithms like for

321
00:12:40,800 --> 00:12:43,440
example java library for fuzzy hash

322
00:12:43,440 --> 00:12:46,079
probably first try and first run

323
00:12:46,079 --> 00:12:48,720
will scare you with a bill for cloud

324
00:12:48,720 --> 00:12:51,680
computing or for your own hardware and a

325
00:12:51,680 --> 00:12:53,920
lot of team will give up on this project

326
00:12:53,920 --> 00:12:56,000
um not blaming anyone it's really

327
00:12:56,000 --> 00:12:57,200
expensive if you're gonna do it like

328
00:12:57,200 --> 00:12:58,160
that

329
00:12:58,160 --> 00:12:59,360
use cases

330
00:12:59,360 --> 00:13:01,680
we all like security research and we

331
00:13:01,680 --> 00:13:03,920
will do it for free like let's be honest

332
00:13:03,920 --> 00:13:05,920
because it's it's fun it's interesting

333
00:13:05,920 --> 00:13:07,680
it's something we love to do

334
00:13:07,680 --> 00:13:10,480
but who's gonna pay for our toys if we

335
00:13:10,480 --> 00:13:12,320
have no use cases

336
00:13:12,320 --> 00:13:14,399
and especially for expensive project you

337
00:13:14,399 --> 00:13:16,240
need to justify the budget you need to

338
00:13:16,240 --> 00:13:18,959
have use cases you need to

339
00:13:18,959 --> 00:13:20,480
make your

340
00:13:20,480 --> 00:13:23,360
research productized and applicable to

341
00:13:23,360 --> 00:13:24,639
something

342
00:13:24,639 --> 00:13:26,639
and of course great team

343
00:13:26,639 --> 00:13:28,000
um

344
00:13:28,000 --> 00:13:31,120
again i'm not telling the my team is

345
00:13:31,120 --> 00:13:32,160
you know

346
00:13:32,160 --> 00:13:34,639
greater than yours but the one

347
00:13:34,639 --> 00:13:36,880
advantages we have our team is very

348
00:13:36,880 --> 00:13:40,160
diverse we have everybody we have uh

349
00:13:40,160 --> 00:13:42,800
data scientists we have engineering part

350
00:13:42,800 --> 00:13:46,079
we have securities and we have analytics

351
00:13:46,079 --> 00:13:48,959
so this has led us to spread the task

352
00:13:48,959 --> 00:13:50,800
and work faster and build the whole

353
00:13:50,800 --> 00:13:52,480
pipeline

354
00:13:52,480 --> 00:13:54,480
and productize all the research our

355
00:13:54,480 --> 00:13:57,440
scientists provide us

356
00:13:57,440 --> 00:14:00,000
okay so as a code provider we have all

357
00:14:00,000 --> 00:14:02,000
of that we have a lot of use case we

358
00:14:02,000 --> 00:14:04,480
have a lot of problems we see samples we

359
00:14:04,480 --> 00:14:07,600
have no idea about every day in enormous

360
00:14:07,600 --> 00:14:08,720
amount

361
00:14:08,720 --> 00:14:11,279
uh algorithms can be in computing power

362
00:14:11,279 --> 00:14:13,680
computing power is not a problem to the

363
00:14:13,680 --> 00:14:15,440
certain level considering that we have

364
00:14:15,440 --> 00:14:17,360
the whole cloud behind us

365
00:14:17,360 --> 00:14:20,160
but again we need to be modest and

366
00:14:20,160 --> 00:14:22,320
optimize all the algorithms

367
00:14:22,320 --> 00:14:24,959
and to optimize them what do we need

368
00:14:24,959 --> 00:14:27,120
we need a good engineer engineers we

369
00:14:27,120 --> 00:14:29,360
need to get we need good scientists and

370
00:14:29,360 --> 00:14:31,440
we need somebody who is able to validate

371
00:14:31,440 --> 00:14:34,079
the result of this research

372
00:14:34,079 --> 00:14:36,639
so great team comes into the place and

373
00:14:36,639 --> 00:14:39,199
if we have all four

374
00:14:39,199 --> 00:14:42,240
answers on the place why not to try

375
00:14:42,240 --> 00:14:45,120
let's start with sample collection let's

376
00:14:45,120 --> 00:14:47,279
see what do we have and how big the

377
00:14:47,279 --> 00:14:49,920
sample size is

378
00:14:49,920 --> 00:14:51,120
so

379
00:14:51,120 --> 00:14:52,240
uh

380
00:14:52,240 --> 00:14:54,399
at the bottom of the slide you can see

381
00:14:54,399 --> 00:14:56,800
an example of the data we gather from

382
00:14:56,800 --> 00:14:58,959
you have customers machines

383
00:14:58,959 --> 00:15:02,399
we do it with special software like xdr

384
00:15:02,399 --> 00:15:04,720
and logs like every other cloud vendor

385
00:15:04,720 --> 00:15:05,519
does

386
00:15:05,519 --> 00:15:07,120
because there is no

387
00:15:07,120 --> 00:15:08,320
no secret

388
00:15:08,320 --> 00:15:10,720
so first of all we

389
00:15:10,720 --> 00:15:13,040
take md5 because it's relatively short

390
00:15:13,040 --> 00:15:14,800
level relatively easy to take and

391
00:15:14,800 --> 00:15:17,600
relatively inexpensive second we take

392
00:15:17,600 --> 00:15:19,839
chavalio which is already longer and

393
00:15:19,839 --> 00:15:21,519
more expensive

394
00:15:21,519 --> 00:15:24,560
and the last one is deep which is to be

395
00:15:24,560 --> 00:15:27,440
one is pretty fat and pretty expensive

396
00:15:27,440 --> 00:15:29,279
to take not even

397
00:15:29,279 --> 00:15:32,320
compare but just to get it and gather

398
00:15:32,320 --> 00:15:33,920
but anyway

399
00:15:33,920 --> 00:15:36,000
we start to work and we and we gather

400
00:15:36,000 --> 00:15:38,320
all of the about from the cloud security

401
00:15:38,320 --> 00:15:39,279
product

402
00:15:39,279 --> 00:15:43,040
so our ssd library size in the cloud is

403
00:15:43,040 --> 00:15:46,800
100 million and we're still counting

404
00:15:46,800 --> 00:15:49,680
what do you think 100 million samples

405
00:15:49,680 --> 00:15:53,880
is it a good news or bad news

406
00:15:55,199 --> 00:15:58,079
okay your best guess

407
00:15:58,720 --> 00:16:00,720
well i would say that for data

408
00:16:00,720 --> 00:16:02,959
scientists it's a really good news

409
00:16:02,959 --> 00:16:05,040
big data everything's supposed to be

410
00:16:05,040 --> 00:16:08,240
classified very tightly we can find a

411
00:16:08,240 --> 00:16:10,399
lot of connectivities in the graph

412
00:16:10,399 --> 00:16:12,560
everything looks amazing for engineering

413
00:16:12,560 --> 00:16:14,560
part it looks terrifying it looks

414
00:16:14,560 --> 00:16:16,720
frustrating it looks like how we're

415
00:16:16,720 --> 00:16:18,160
going to do this

416
00:16:18,160 --> 00:16:20,560
and how this miracle in between of

417
00:16:20,560 --> 00:16:22,959
engineering and science happening

418
00:16:22,959 --> 00:16:27,040
yuri will tell you right now

419
00:16:27,839 --> 00:16:29,600
i think we probably need to speed up a

420
00:16:29,600 --> 00:16:32,160
little bit since we are between us and

421
00:16:32,160 --> 00:16:33,680
lunch

422
00:16:33,680 --> 00:16:36,160
that would be my guess

423
00:16:36,160 --> 00:16:37,519
so yes as

424
00:16:37,519 --> 00:16:39,600
anastasia mentioned that

425
00:16:39,600 --> 00:16:42,160
i was able to assemble a great team uh

426
00:16:42,160 --> 00:16:44,720
that comprises of different

427
00:16:44,720 --> 00:16:46,800
specialties and that allowed us to

428
00:16:46,800 --> 00:16:48,720
execute not only the scientific portion

429
00:16:48,720 --> 00:16:52,000
but the engineering implementation and

430
00:16:52,000 --> 00:16:52,720
what

431
00:16:52,720 --> 00:16:54,800
challenges obviously that we were trying

432
00:16:54,800 --> 00:16:56,959
to solve is how

433
00:16:56,959 --> 00:16:58,720
how to process the library and by the

434
00:16:58,720 --> 00:17:00,560
way the library it's important to know

435
00:17:00,560 --> 00:17:03,440
note that the 100 million

436
00:17:03,440 --> 00:17:06,160
samples was collected from the customers

437
00:17:06,160 --> 00:17:07,599
who

438
00:17:07,599 --> 00:17:10,079
authorized the security software that

439
00:17:10,079 --> 00:17:12,720
actually make it possible so

440
00:17:12,720 --> 00:17:15,119
and what we wanted to do is to compare

441
00:17:15,119 --> 00:17:17,119
essentially each of the symbol to each

442
00:17:17,119 --> 00:17:18,880
of the sample right to calculate

443
00:17:18,880 --> 00:17:21,199
pairwise similarity but if you try to do

444
00:17:21,199 --> 00:17:24,400
it on 100 million times 100 million uh

445
00:17:24,400 --> 00:17:27,039
even the cloud provider even large one

446
00:17:27,039 --> 00:17:30,720
uh will not be able to process it

447
00:17:30,720 --> 00:17:34,160
in any uh limited time or cost so we did

448
00:17:34,160 --> 00:17:36,160
uh quite a lot of

449
00:17:36,160 --> 00:17:39,520
tricks to reduce the space so for

450
00:17:39,520 --> 00:17:43,039
example uh we limited the block size uh

451
00:17:43,039 --> 00:17:46,480
to let's say half equal or double we

452
00:17:46,480 --> 00:17:49,520
also implemented pretty

453
00:17:49,520 --> 00:17:52,640
interesting uh optimization our engineer

454
00:17:52,640 --> 00:17:54,240
implemented

455
00:17:54,240 --> 00:17:57,919
the way to scan only for those that have

456
00:17:57,919 --> 00:17:59,039
seven

457
00:17:59,039 --> 00:18:01,440
characters matching uh as a

458
00:18:01,440 --> 00:18:03,039
pre-filtering so

459
00:18:03,039 --> 00:18:07,520
uh in in this uh steps uh um also oh and

460
00:18:07,520 --> 00:18:09,440
by the way you also need uh redundancy

461
00:18:09,440 --> 00:18:11,520
cleanup because a lot of zeros and

462
00:18:11,520 --> 00:18:13,120
binaries for example

463
00:18:13,120 --> 00:18:15,039
uh manifest

464
00:18:15,039 --> 00:18:18,559
themselves in a long character um

465
00:18:18,559 --> 00:18:21,039
repeating characters so uh there's a

466
00:18:21,039 --> 00:18:23,840
uh it's it's a usual

467
00:18:23,840 --> 00:18:26,160
practice so with all this pre-filtering

468
00:18:26,160 --> 00:18:28,400
we reduced it to

469
00:18:28,400 --> 00:18:30,799
manageable for us as a large cloud

470
00:18:30,799 --> 00:18:31,840
provider

471
00:18:31,840 --> 00:18:34,240
and but still nevertheless we ran for

472
00:18:34,240 --> 00:18:37,679
several uh days uh the algorithm that

473
00:18:37,679 --> 00:18:40,559
created the initial space and spent

474
00:18:40,559 --> 00:18:44,720
probably about 50 000 instance hours

475
00:18:44,720 --> 00:18:45,580
which

476
00:18:45,580 --> 00:18:47,360
[Music]

477
00:18:47,360 --> 00:18:50,400
i'm glad we had the resources for it

478
00:18:50,400 --> 00:18:52,559
so what what we

479
00:18:52,559 --> 00:18:54,320
constructed

480
00:18:54,320 --> 00:18:55,600
is a

481
00:18:55,600 --> 00:18:58,000
basically a pairwise similarity between

482
00:18:58,000 --> 00:19:00,320
the 100 million uh

483
00:19:00,320 --> 00:19:02,000
uh samples

484
00:19:02,000 --> 00:19:03,600
and uh what

485
00:19:03,600 --> 00:19:05,840
what can you do with this right

486
00:19:05,840 --> 00:19:09,840
uh you create a large graph so this is a

487
00:19:09,840 --> 00:19:12,240
representation of the graph there is

488
00:19:12,240 --> 00:19:15,760
just a kind of foundational uh storage

489
00:19:15,760 --> 00:19:17,520
layer

490
00:19:17,520 --> 00:19:18,320
but

491
00:19:18,320 --> 00:19:19,760
uh what

492
00:19:19,760 --> 00:19:21,520
the next important question once you

493
00:19:21,520 --> 00:19:23,840
constructed the representation

494
00:19:23,840 --> 00:19:26,640
of your library

495
00:19:26,640 --> 00:19:29,200
what do you do next when new binaries

496
00:19:29,200 --> 00:19:31,840
appear so that's where we added a

497
00:19:31,840 --> 00:19:34,000
pipeline to detect

498
00:19:34,000 --> 00:19:35,840
new sha values

499
00:19:35,840 --> 00:19:37,600
which is pretty

500
00:19:37,600 --> 00:19:39,440
straightforward

501
00:19:39,440 --> 00:19:40,960
although at scale nothing is

502
00:19:40,960 --> 00:19:42,320
straightforward

503
00:19:42,320 --> 00:19:44,799
and we compare the

504
00:19:44,799 --> 00:19:47,120
the ones that we see for the first time

505
00:19:47,120 --> 00:19:49,440
we compare to our graph and we

506
00:19:49,440 --> 00:19:51,760
evolve this graph

507
00:19:51,760 --> 00:19:53,919
in close to real time so we are not

508
00:19:53,919 --> 00:19:55,679
re-running it's like for several days we

509
00:19:55,679 --> 00:19:56,720
can

510
00:19:56,720 --> 00:20:00,480
do it daily or hourly

511
00:20:01,120 --> 00:20:01,919
so

512
00:20:01,919 --> 00:20:02,720
what

513
00:20:02,720 --> 00:20:06,480
what this uh produces is a very very

514
00:20:06,480 --> 00:20:08,799
nice

515
00:20:08,880 --> 00:20:11,280
representation so once you construct the

516
00:20:11,280 --> 00:20:13,520
graph obviously

517
00:20:13,520 --> 00:20:15,600
there are a few challenges with this uh

518
00:20:15,600 --> 00:20:17,440
in order to even construct the graph we

519
00:20:17,440 --> 00:20:19,600
had to make it in parallel

520
00:20:19,600 --> 00:20:20,480
and

521
00:20:20,480 --> 00:20:23,039
do a lot of tricks that from the graph

522
00:20:23,039 --> 00:20:24,400
theory

523
00:20:24,400 --> 00:20:26,559
that andreas actually was

524
00:20:26,559 --> 00:20:30,000
the driving force for it scientifically

525
00:20:30,000 --> 00:20:30,799
but

526
00:20:30,799 --> 00:20:32,159
it allowed us

527
00:20:32,159 --> 00:20:34,720
to not only create eye candy

528
00:20:34,720 --> 00:20:36,400
visualizations

529
00:20:36,400 --> 00:20:38,159
which will

530
00:20:38,159 --> 00:20:42,640
add more in the paper but also

531
00:20:42,640 --> 00:20:43,840
uh

532
00:20:43,840 --> 00:20:46,320
seeing it as subgraphs

533
00:20:46,320 --> 00:20:50,799
uh connecting uh known and unknown uh

534
00:20:50,799 --> 00:20:53,200
malware samples out of hundred million

535
00:20:53,200 --> 00:20:56,400
uh samples we approximately had uh one

536
00:20:56,400 --> 00:20:57,919
percent labeled

537
00:20:57,919 --> 00:21:01,280
um so mostly by our researchers at a

538
00:21:01,280 --> 00:21:02,480
certain

539
00:21:02,480 --> 00:21:03,840
point of time

540
00:21:03,840 --> 00:21:05,280
and

541
00:21:05,280 --> 00:21:07,039
that created

542
00:21:07,039 --> 00:21:10,960
different opportunities to

543
00:21:11,360 --> 00:21:13,760
to do two different kind of analysis

544
00:21:13,760 --> 00:21:17,600
so if you have this graph representation

545
00:21:17,600 --> 00:21:18,640
you can

546
00:21:18,640 --> 00:21:21,200
do both um

547
00:21:21,200 --> 00:21:23,440
lookups essentially or analysis with the

548
00:21:23,440 --> 00:21:25,840
prior information with the seed right so

549
00:21:25,840 --> 00:21:28,480
when you are trying to see what your new

550
00:21:28,480 --> 00:21:31,200
malware when new binary is connected to

551
00:21:31,200 --> 00:21:32,640
what

552
00:21:32,640 --> 00:21:34,960
what similarity it has

553
00:21:34,960 --> 00:21:37,280
and when you don't have a seed what do

554
00:21:37,280 --> 00:21:38,799
you do

555
00:21:38,799 --> 00:21:41,679
that's what we did at scale as well by

556
00:21:41,679 --> 00:21:44,640
clustering the large graph that we had

557
00:21:44,640 --> 00:21:45,679
into

558
00:21:45,679 --> 00:21:48,080
sub-graphs without having any seed

559
00:21:48,080 --> 00:21:49,200
information

560
00:21:49,200 --> 00:21:52,159
so in a way

561
00:21:52,159 --> 00:21:55,520
if you if you have a sub-graph where you

562
00:21:55,520 --> 00:21:56,840
know one of the

563
00:21:56,840 --> 00:21:59,520
binaries you know that pretty much the

564
00:21:59,520 --> 00:22:01,919
whole sub graph is probably bad

565
00:22:01,919 --> 00:22:04,799
but if you have a sub graph that is has

566
00:22:04,799 --> 00:22:07,840
high similarity but nothing is unknown

567
00:22:07,840 --> 00:22:11,120
then you're just waiting for

568
00:22:11,120 --> 00:22:13,440
security researcher or virustotal or

569
00:22:13,440 --> 00:22:15,919
somebody to confirm at least one member

570
00:22:15,919 --> 00:22:17,679
of this graph and then you can propagate

571
00:22:17,679 --> 00:22:20,080
it right through the subgraph but you

572
00:22:20,080 --> 00:22:22,480
did the homework and you this sub graph

573
00:22:22,480 --> 00:22:27,679
is waiting to be uh annotated basically

574
00:22:27,679 --> 00:22:30,320
um what what's interesting uh is the

575
00:22:30,320 --> 00:22:32,960
difference between polymorphic and code

576
00:22:32,960 --> 00:22:34,720
reuse similarities

577
00:22:34,720 --> 00:22:38,840
so for uh polymorphic we

578
00:22:38,840 --> 00:22:40,799
set uh

579
00:22:40,799 --> 00:22:44,000
a higher threshold so let's say 97

580
00:22:44,000 --> 00:22:46,080
uh because it changes a lot

581
00:22:46,080 --> 00:22:48,720
uh and oh another trick that we used uh

582
00:22:48,720 --> 00:22:51,520
for polymorphic uh

583
00:22:51,520 --> 00:22:53,039
malware is

584
00:22:53,039 --> 00:22:54,799
because it changes so much and there are

585
00:22:54,799 --> 00:22:56,480
so many different uh

586
00:22:56,480 --> 00:22:57,280
uh

587
00:22:57,280 --> 00:23:01,120
very similar uh ssd uh fuzzy hashes so

588
00:23:01,120 --> 00:23:05,120
we just stopped at 5 000

589
00:23:05,120 --> 00:23:06,640
similar ssd

590
00:23:06,640 --> 00:23:10,000
and we just don't add them uh anymore

591
00:23:10,000 --> 00:23:11,520
because uh

592
00:23:11,520 --> 00:23:13,760
more like there's no difference of value

593
00:23:13,760 --> 00:23:16,000
between five thousand to a hundred

594
00:23:16,000 --> 00:23:18,640
thousand of uh different flavors of the

595
00:23:18,640 --> 00:23:20,320
same thing polymorphic but for the code

596
00:23:20,320 --> 00:23:22,159
reuse

597
00:23:22,159 --> 00:23:24,240
something like 80

598
00:23:24,240 --> 00:23:27,520
ish percent is more appropriate

599
00:23:27,520 --> 00:23:29,919
because it doesn't have all the same

600
00:23:29,919 --> 00:23:31,919
components

601
00:23:31,919 --> 00:23:33,600
and

602
00:23:33,600 --> 00:23:35,280
also we

603
00:23:35,280 --> 00:23:37,760
observed that sometimes even lower

604
00:23:37,760 --> 00:23:41,039
percentage signifies a certain

605
00:23:41,039 --> 00:23:42,240
reuse

606
00:23:42,240 --> 00:23:44,080
or shared library

607
00:23:44,080 --> 00:23:45,919
in which case

608
00:23:45,919 --> 00:23:48,159
we didn't do it yet but we can do a

609
00:23:48,159 --> 00:23:50,240
component analysis and actually compare

610
00:23:50,240 --> 00:23:54,720
the binaries rather than the sha values

611
00:23:56,240 --> 00:23:59,600
so uh that actually uh

612
00:23:59,600 --> 00:24:01,440
as as being a leader of this group i

613
00:24:01,440 --> 00:24:03,679
just want to emphasize that maybe if

614
00:24:03,679 --> 00:24:05,440
somebody wants to do some

615
00:24:05,440 --> 00:24:07,440
this project at scale

616
00:24:07,440 --> 00:24:10,159
what is what was super important is to

617
00:24:10,159 --> 00:24:12,240
have one team where scientists and

618
00:24:12,240 --> 00:24:14,159
researchers and security researchers and

619
00:24:14,159 --> 00:24:16,400
engineers work together instead of just

620
00:24:16,400 --> 00:24:19,120
throwing the scientific prototype to

621
00:24:19,120 --> 00:24:21,520
engineering department and wait like for

622
00:24:21,520 --> 00:24:24,799
half a year or a year for execution so

623
00:24:24,799 --> 00:24:26,080
you you got to have a very tight

624
00:24:26,080 --> 00:24:28,640
collaboration and essentially the same

625
00:24:28,640 --> 00:24:29,679
team

626
00:24:29,679 --> 00:24:31,360
they all need to be in the same team to

627
00:24:31,360 --> 00:24:34,400
produce these results at scale quickly

628
00:24:34,400 --> 00:24:35,679
so now

629
00:24:35,679 --> 00:24:38,080
i give anastasia back

630
00:24:38,080 --> 00:24:40,240
to dig a little bit deeper

631
00:24:40,240 --> 00:24:42,480
okay let's take a look at the real case

632
00:24:42,480 --> 00:24:44,240
scenario because

633
00:24:44,240 --> 00:24:46,320
yeah i will try to go fast because

634
00:24:46,320 --> 00:24:48,240
everybody is hungry and i will keep it

635
00:24:48,240 --> 00:24:50,080
nice and fast

636
00:24:50,080 --> 00:24:53,840
so um let's start with our old

637
00:24:53,840 --> 00:24:56,320
well-known malware sword ddos and

638
00:24:56,320 --> 00:24:58,080
probably you know that this mower is

639
00:24:58,080 --> 00:25:00,640
polymorphic one what does polymorphic

640
00:25:00,640 --> 00:25:03,200
means it means that this type of malware

641
00:25:03,200 --> 00:25:06,559
can change its copies during the

642
00:25:06,559 --> 00:25:08,159
self-replication

643
00:25:08,159 --> 00:25:08,810
and

644
00:25:08,810 --> 00:25:10,480
[Music]

645
00:25:10,480 --> 00:25:12,960
sergio dos is well known as a malware

646
00:25:12,960 --> 00:25:16,640
for linux machines but in the last

647
00:25:16,640 --> 00:25:18,880
several years and in the last months it

648
00:25:18,880 --> 00:25:20,720
starts to adopt new techniques for

649
00:25:20,720 --> 00:25:23,279
example it starts to infect the windows

650
00:25:23,279 --> 00:25:24,720
machine as well which has come as a

651
00:25:24,720 --> 00:25:26,960
surprise to be honest because it's not

652
00:25:26,960 --> 00:25:28,960
really easy to adapt something that was

653
00:25:28,960 --> 00:25:32,159
created for linux to infect the windows

654
00:25:32,159 --> 00:25:34,640
machine considering the all the layers

655
00:25:34,640 --> 00:25:36,159
they have inside of the separation

656
00:25:36,159 --> 00:25:39,679
system and even more it adapts the

657
00:25:39,679 --> 00:25:41,760
technologies to exploit vulnerable

658
00:25:41,760 --> 00:25:45,200
container services so now your malware

659
00:25:45,200 --> 00:25:47,600
can be run not only on your instance but

660
00:25:47,600 --> 00:25:49,760
in on all the containers of your

661
00:25:49,760 --> 00:25:51,679
instance in the cloud which

662
00:25:51,679 --> 00:25:53,919
would give which give it um

663
00:25:53,919 --> 00:25:56,159
a great scale to be honest and more

664
00:25:56,159 --> 00:25:59,039
possible ways to make money and perform

665
00:25:59,039 --> 00:26:01,520
the ddos attack like it used to be

666
00:26:01,520 --> 00:26:02,320
so

667
00:26:02,320 --> 00:26:05,360
sergio dos has a special function random

668
00:26:05,360 --> 00:26:07,600
md5 and this function

669
00:26:07,600 --> 00:26:09,360
works to

670
00:26:09,360 --> 00:26:12,320
change the hash value the chevy

671
00:26:12,320 --> 00:26:14,080
md5 and

672
00:26:14,080 --> 00:26:16,159
the charm for

673
00:26:16,159 --> 00:26:18,880
new samples of this mower

674
00:26:18,880 --> 00:26:22,320
but it still has a well-known pattern of

675
00:26:22,320 --> 00:26:25,039
creating the directory it used to run

676
00:26:25,039 --> 00:26:27,279
this directory usually locates in your

677
00:26:27,279 --> 00:26:29,120
serving or tmp

678
00:26:29,120 --> 00:26:31,520
and it it has

679
00:26:31,520 --> 00:26:32,400
10

680
00:26:32,400 --> 00:26:35,360
random letters no numbers um all

681
00:26:35,360 --> 00:26:39,039
lowercase this uh all the difference 10

682
00:26:39,039 --> 00:26:41,520
10 letters name for the directory when

683
00:26:41,520 --> 00:26:43,120
it starts

684
00:26:43,120 --> 00:26:45,520
a different fresh value can bypass

685
00:26:45,520 --> 00:26:47,440
threat intelligence like various total

686
00:26:47,440 --> 00:26:50,559
and sore exploit this function a lot

687
00:26:50,559 --> 00:26:54,000
so alibaba quote has a lot of rules we

688
00:26:54,000 --> 00:26:56,960
gather them over the years to

689
00:26:56,960 --> 00:26:59,200
investigate how does it work

690
00:26:59,200 --> 00:27:00,640
what

691
00:27:00,640 --> 00:27:03,760
features this malware has and how we can

692
00:27:03,760 --> 00:27:06,000
and all the samples we can keep will

693
00:27:06,000 --> 00:27:08,320
label it and we keep in our database

694
00:27:08,320 --> 00:27:10,000
let's consider one example how

695
00:27:10,000 --> 00:27:12,559
polymorphic polymorphic

696
00:27:12,559 --> 00:27:14,559
detection invasion works

697
00:27:14,559 --> 00:27:17,360
let's um take a look at the picture

698
00:27:17,360 --> 00:27:18,840
first initial

699
00:27:18,840 --> 00:27:21,919
um malware binary that

700
00:27:21,919 --> 00:27:24,480
was dropped at the machine has very

701
00:27:24,480 --> 00:27:27,760
particular md5 as you can see it on the

702
00:27:27,760 --> 00:27:29,039
first line

703
00:27:29,039 --> 00:27:31,760
then during the self-replication process

704
00:27:31,760 --> 00:27:34,240
this malware create the copy and modify

705
00:27:34,240 --> 00:27:37,760
this copy with a rand md5 function

706
00:27:37,760 --> 00:27:39,679
basically what it does it does part in

707
00:27:39,679 --> 00:27:41,039
the

708
00:27:41,039 --> 00:27:43,440
end of the file with random data random

709
00:27:43,440 --> 00:27:44,399
strings

710
00:27:44,399 --> 00:27:47,279
and change the directory also also it

711
00:27:47,279 --> 00:27:50,159
loves to change the directory from user

712
00:27:50,159 --> 00:27:53,520
bin to bin from user bin to tmp and vice

713
00:27:53,520 --> 00:27:56,240
versa so in one moment

714
00:27:56,240 --> 00:27:58,480
several seconds we have completely

715
00:27:58,480 --> 00:28:01,120
different file with different size

716
00:28:01,120 --> 00:28:04,799
different md5 hash and absolutely

717
00:28:04,799 --> 00:28:06,799
different location

718
00:28:06,799 --> 00:28:09,840
but we still know the algorithm how it

719
00:28:09,840 --> 00:28:11,679
names the directory and some other

720
00:28:11,679 --> 00:28:13,360
patterns of the behavior because we've

721
00:28:13,360 --> 00:28:16,159
been observing this malware a lot let's

722
00:28:16,159 --> 00:28:18,480
take a look at the fuzzy hash on these

723
00:28:18,480 --> 00:28:20,799
two samples we just discussed

724
00:28:20,799 --> 00:28:22,559
so md5

725
00:28:22,559 --> 00:28:24,880
looks completely different it's like

726
00:28:24,880 --> 00:28:26,640
there is nothing else there is nothing

727
00:28:26,640 --> 00:28:29,760
in common but they cannot trick fuzzy

728
00:28:29,760 --> 00:28:32,240
hash that easily because again fuzzy

729
00:28:32,240 --> 00:28:34,960
hash is context contextual

730
00:28:34,960 --> 00:28:38,320
uh contextual value so when we see

731
00:28:38,320 --> 00:28:41,120
the same samples but from the half of

732
00:28:41,120 --> 00:28:43,279
the hash view from says dipsha

733
00:28:43,279 --> 00:28:47,200
we can for we can clearly identify where

734
00:28:47,200 --> 00:28:51,360
this random md5 function works and how

735
00:28:51,360 --> 00:28:53,600
it changed the value and it's not

736
00:28:53,600 --> 00:28:55,200
significant

737
00:28:55,200 --> 00:28:58,240
so if we looking for similarity and

738
00:28:58,240 --> 00:29:00,960
similarity is an opposite of distance

739
00:29:00,960 --> 00:29:03,440
distance um shows

740
00:29:03,440 --> 00:29:05,360
how far away

741
00:29:05,360 --> 00:29:07,279
samples from each other and similarities

742
00:29:07,279 --> 00:29:09,360
are an opposite how close they are

743
00:29:09,360 --> 00:29:12,080
related how much they have in common

744
00:29:12,080 --> 00:29:15,440
usually the range lies in between um

745
00:29:15,440 --> 00:29:17,919
zero and one when zero is

746
00:29:17,919 --> 00:29:20,159
like this binary has nothing in common

747
00:29:20,159 --> 00:29:22,080
completely different and one these

748
00:29:22,080 --> 00:29:24,080
binaries are similar completely

749
00:29:24,080 --> 00:29:25,200
identical

750
00:29:25,200 --> 00:29:27,440
and again if we take the ds

751
00:29:27,440 --> 00:29:30,000
if we take the similarity function

752
00:29:30,000 --> 00:29:31,840
from two of these

753
00:29:31,840 --> 00:29:33,840
hash values we can see that that's

754
00:29:33,840 --> 00:29:35,520
significantly high

755
00:29:35,520 --> 00:29:38,159
it's very close to one

756
00:29:38,159 --> 00:29:39,039
so

757
00:29:39,039 --> 00:29:41,360
from the our point of view this is the

758
00:29:41,360 --> 00:29:42,640
same malware

759
00:29:42,640 --> 00:29:44,480
it doesn't matter that the file has a

760
00:29:44,480 --> 00:29:45,679
different

761
00:29:45,679 --> 00:29:47,679
size and different location and

762
00:29:47,679 --> 00:29:50,960
different sha or md5 value this is the

763
00:29:50,960 --> 00:29:52,640
same

764
00:29:52,640 --> 00:29:54,960
let's take a look at them real example

765
00:29:54,960 --> 00:29:57,200
this is sub graph extracted from our b

766
00:29:57,200 --> 00:29:58,240
graph

767
00:29:58,240 --> 00:30:01,120
and this is sub graph for x ordinance

768
00:30:01,120 --> 00:30:03,840
all the blue dots are unknown binaries

769
00:30:03,840 --> 00:30:05,919
we see them for the first time we have

770
00:30:05,919 --> 00:30:07,679
no idea what it is

771
00:30:07,679 --> 00:30:10,080
and we try to compare the new binaries

772
00:30:10,080 --> 00:30:12,000
with some uh with something we already

773
00:30:12,000 --> 00:30:14,960
know and we know about sordidos right

774
00:30:14,960 --> 00:30:17,520
so if you look at the distance you can

775
00:30:17,520 --> 00:30:20,080
see that the that similarity is pretty

776
00:30:20,080 --> 00:30:23,440
close to one even the

777
00:30:23,440 --> 00:30:27,120
the least one uh 0.79 it's still pretty

778
00:30:27,120 --> 00:30:30,240
close to once and uh half for example

779
00:30:30,240 --> 00:30:31,520
so

780
00:30:31,520 --> 00:30:32,720
from

781
00:30:32,720 --> 00:30:35,200
data science point of view that's enough

782
00:30:35,200 --> 00:30:37,600
to prove that this is malware guilty by

783
00:30:37,600 --> 00:30:40,080
association looks the same if something

784
00:30:40,080 --> 00:30:42,159
walks like a dog flies like a duck and

785
00:30:42,159 --> 00:30:43,679
looks like a dog it's probably a dog

786
00:30:43,679 --> 00:30:44,640
right

787
00:30:44,640 --> 00:30:45,600
but

788
00:30:45,600 --> 00:30:47,679
from the point of view of security

789
00:30:47,679 --> 00:30:50,799
engineers how should i know okay that

790
00:30:50,799 --> 00:30:53,840
looks similar but i need to verify is it

791
00:30:53,840 --> 00:30:56,240
the same malware is it the malware at

792
00:30:56,240 --> 00:30:57,039
all

793
00:30:57,039 --> 00:30:59,519
so unfortunately we had a problem to

794
00:30:59,519 --> 00:31:01,600
share internal tool screenshot and

795
00:31:01,600 --> 00:31:03,519
everything because of server because

796
00:31:03,519 --> 00:31:07,360
logs gathered by our internal

797
00:31:07,360 --> 00:31:10,240
proprietary security software but what i

798
00:31:10,240 --> 00:31:12,320
actually did i went to the machines and

799
00:31:12,320 --> 00:31:13,919
pulled all the logs

800
00:31:13,919 --> 00:31:16,720
provided by these binaries running and

801
00:31:16,720 --> 00:31:18,159
what we can see that they have

802
00:31:18,159 --> 00:31:21,440
absolutely identical behavior to all the

803
00:31:21,440 --> 00:31:23,760
malicious sort the dos file it's the

804
00:31:23,760 --> 00:31:25,039
same

805
00:31:25,039 --> 00:31:26,480
i verified

806
00:31:26,480 --> 00:31:28,640
i approve the algorithm algorithm got

807
00:31:28,640 --> 00:31:30,240
productized

808
00:31:30,240 --> 00:31:32,320
and let's take a look at the results

809
00:31:32,320 --> 00:31:34,559
what do we get what did we get

810
00:31:34,559 --> 00:31:35,440
so

811
00:31:35,440 --> 00:31:38,399
sergio doss on virus total the first sha

812
00:31:38,399 --> 00:31:40,559
you can see very old one and very

813
00:31:40,559 --> 00:31:42,480
significantly

814
00:31:42,480 --> 00:31:44,240
malicious i would say

815
00:31:44,240 --> 00:31:46,799
almost all the virus total genes

816
00:31:46,799 --> 00:31:48,960
consider it malicious and report it very

817
00:31:48,960 --> 00:31:49,760
well

818
00:31:49,760 --> 00:31:51,840
but what to do with other

819
00:31:51,840 --> 00:31:53,840
uh 200

820
00:31:53,840 --> 00:31:56,880
11 000 samples we have

821
00:31:56,880 --> 00:31:59,679
that's a lot right so we start to try we

822
00:31:59,679 --> 00:32:01,760
start to verify it again with different

823
00:32:01,760 --> 00:32:03,840
vendors to see how much overlapped we

824
00:32:03,840 --> 00:32:05,919
have we already know they are malicious

825
00:32:05,919 --> 00:32:08,320
we already we already validated them

826
00:32:08,320 --> 00:32:10,240
with our system but what about other

827
00:32:10,240 --> 00:32:12,880
vendors and apparently that

828
00:32:12,880 --> 00:32:15,760
we find out very interesting thing avira

829
00:32:15,760 --> 00:32:18,240
has a very good overlap

830
00:32:18,240 --> 00:32:20,080
73 persons

831
00:32:20,080 --> 00:32:23,120
that's impressive but why aristotle has

832
00:32:23,120 --> 00:32:25,159
only one person and

833
00:32:25,159 --> 00:32:26,880
1.2

834
00:32:26,880 --> 00:32:29,919
uh persons of overlap how come

835
00:32:29,919 --> 00:32:31,840
you probably know that avira contributes

836
00:32:31,840 --> 00:32:34,720
to virus total result as well

837
00:32:34,720 --> 00:32:35,679
but

838
00:32:35,679 --> 00:32:37,440
you know business-wise i guess they

839
00:32:37,440 --> 00:32:39,360
don't contribute everything because they

840
00:32:39,360 --> 00:32:41,120
need to sell us to sell their own

841
00:32:41,120 --> 00:32:44,080
licenses and maybe that was a huge delay

842
00:32:44,080 --> 00:32:46,000
but we tried to verify it

843
00:32:46,000 --> 00:32:48,880
not on the very fresh data as well

844
00:32:48,880 --> 00:32:51,039
nothing actually changed so it's

845
00:32:51,039 --> 00:32:53,679
possible possibly it is a delay problem

846
00:32:53,679 --> 00:32:55,760
possibly it is a limitation of

847
00:32:55,760 --> 00:32:57,600
contribution of other vendors to

848
00:32:57,600 --> 00:33:00,640
virustotal itself but

849
00:33:00,640 --> 00:33:04,080
that looks a little bit frustrating

850
00:33:04,080 --> 00:33:06,320
so yeah polymorphic techniques can

851
00:33:06,320 --> 00:33:08,840
bypass virustotal

852
00:33:08,840 --> 00:33:11,760
and i think we get we get a pretty good

853
00:33:11,760 --> 00:33:14,080
results to labeling all of this stuff

854
00:33:14,080 --> 00:33:15,039
itself

855
00:33:15,039 --> 00:33:17,039
but let's quickly take

856
00:33:17,039 --> 00:33:17,919
um

857
00:33:17,919 --> 00:33:20,159
the take a look from the different point

858
00:33:20,159 --> 00:33:22,480
of view we've been talking about

859
00:33:22,480 --> 00:33:23,760
difference

860
00:33:23,760 --> 00:33:26,399
our threat actors tries to introduce

861
00:33:26,399 --> 00:33:29,039
into the malware to make it look like

862
00:33:29,039 --> 00:33:31,440
something new but what about similarity

863
00:33:31,440 --> 00:33:34,559
itself let's talk about code reuse

864
00:33:34,559 --> 00:33:37,120
code reuse is actually a technique that

865
00:33:37,120 --> 00:33:40,799
shares in between malicious software and

866
00:33:40,799 --> 00:33:42,640
behind software as well because we have

867
00:33:42,640 --> 00:33:46,080
the same libraries we have the same to

868
00:33:46,080 --> 00:33:48,240
be honest github when everybody is copy

869
00:33:48,240 --> 00:33:50,880
and paste takeover flow you name it if

870
00:33:50,880 --> 00:33:52,320
code quartz exists somebody is going to

871
00:33:52,320 --> 00:33:55,120
use it even if it's not the best quality

872
00:33:55,120 --> 00:33:58,559
like i i've seen it already many times

873
00:33:58,559 --> 00:34:01,440
so this is an opposite

874
00:34:01,440 --> 00:34:03,360
approach what we're trying to do we're

875
00:34:03,360 --> 00:34:04,960
trying to find

876
00:34:04,960 --> 00:34:07,519
the piece of shared code in between of

877
00:34:07,519 --> 00:34:09,599
different malware samples and malware

878
00:34:09,599 --> 00:34:10,639
families

879
00:34:10,639 --> 00:34:13,359
why because we want to know

880
00:34:13,359 --> 00:34:15,520
we want to track the malware campaigns

881
00:34:15,520 --> 00:34:18,719
and we want to know

882
00:34:18,719 --> 00:34:21,359
the evolution of malware families it

883
00:34:21,359 --> 00:34:23,280
works absolutely the same but in this

884
00:34:23,280 --> 00:34:25,119
case we targeted not the difference but

885
00:34:25,119 --> 00:34:27,040
similarity itself the target and sharing

886
00:34:27,040 --> 00:34:29,599
code and i have a few cute pictures from

887
00:34:29,599 --> 00:34:31,280
our data scientist to show you the

888
00:34:31,280 --> 00:34:32,800
result

889
00:34:32,800 --> 00:34:34,960
and this is a graph from ransomware for

890
00:34:34,960 --> 00:34:37,599
ransomware and from miners

891
00:34:37,599 --> 00:34:39,839
it shows the shared code

892
00:34:39,839 --> 00:34:41,359
in between of

893
00:34:41,359 --> 00:34:44,159
different samples inside of the families

894
00:34:44,159 --> 00:34:45,839
what do you think why they look so

895
00:34:45,839 --> 00:34:47,679
different

896
00:34:47,679 --> 00:34:50,159
it because it looks like the ransomware

897
00:34:50,159 --> 00:34:53,599
reuse quote much less and they have very

898
00:34:53,599 --> 00:34:56,879
few significant families and the miners

899
00:34:56,879 --> 00:34:59,680
almost all of them look the same

900
00:34:59,680 --> 00:35:01,839
how comes

901
00:35:01,839 --> 00:35:03,119
mostly

902
00:35:03,119 --> 00:35:05,599
this is my opinion but i believe that it

903
00:35:05,599 --> 00:35:08,320
has some some you know rational business

904
00:35:08,320 --> 00:35:10,720
behind that the ransomware is pretty

905
00:35:10,720 --> 00:35:11,680
unique

906
00:35:11,680 --> 00:35:14,640
uh it's relatively expensive

907
00:35:14,640 --> 00:35:17,760
malware it has different um encryption

908
00:35:17,760 --> 00:35:20,640
keys it has different set of exploits to

909
00:35:20,640 --> 00:35:22,240
get to the machine

910
00:35:22,240 --> 00:35:23,760
and it has

911
00:35:23,760 --> 00:35:26,320
different techniques of getting the

912
00:35:26,320 --> 00:35:29,119
payment interact interact with the user

913
00:35:29,119 --> 00:35:32,079
and index the whole file system that

914
00:35:32,079 --> 00:35:34,560
works with different file systems that

915
00:35:34,560 --> 00:35:36,720
you need to index then cipher then

916
00:35:36,720 --> 00:35:37,920
encrypt

917
00:35:37,920 --> 00:35:40,960
so yeah it's not that much to reuse to

918
00:35:40,960 --> 00:35:43,200
be honest and they have several families

919
00:35:43,200 --> 00:35:45,760
but overall it's it doesn't look very

920
00:35:45,760 --> 00:35:49,280
similar and miners what what i want to

921
00:35:49,280 --> 00:35:52,560
do as a hacker to create

922
00:35:52,560 --> 00:35:53,680
like a

923
00:35:53,680 --> 00:35:56,400
malware with a minor i use the normal

924
00:35:56,400 --> 00:35:58,800
miner absolutely legitimate software

925
00:35:58,800 --> 00:36:00,640
that people use for mining and they need

926
00:36:00,640 --> 00:36:03,119
to weaponize it so what i need to do i

927
00:36:03,119 --> 00:36:05,440
need to create a harness that will

928
00:36:05,440 --> 00:36:07,280
deliver

929
00:36:07,280 --> 00:36:10,000
my miner to the target machine exploit

930
00:36:10,000 --> 00:36:12,400
some vulnerability right so most of the

931
00:36:12,400 --> 00:36:14,720
code are still the same it is the same

932
00:36:14,720 --> 00:36:16,880
miners the same

933
00:36:16,880 --> 00:36:19,040
algorithms the same protocols just the

934
00:36:19,040 --> 00:36:21,440
hardness for delivery and droppers are

935
00:36:21,440 --> 00:36:23,760
different everything else is the same

936
00:36:23,760 --> 00:36:25,760
this is why they looked

937
00:36:25,760 --> 00:36:27,119
pretty different

938
00:36:27,119 --> 00:36:31,200
but the difference can be even greater

939
00:36:32,400 --> 00:36:35,520
so this is mirai and engine tesla mirae

940
00:36:35,520 --> 00:36:36,480
is

941
00:36:36,480 --> 00:36:39,280
one of the first open source malware

942
00:36:39,280 --> 00:36:40,880
everybody can pick up and use

943
00:36:40,880 --> 00:36:44,320
supervisory to reuse super easy to add

944
00:36:44,320 --> 00:36:46,880
new exploits to weaponize it and asian

945
00:36:46,880 --> 00:36:50,160
tesla is a remote access trojan

946
00:36:50,160 --> 00:36:53,280
very highly obfuscated very highly

947
00:36:53,280 --> 00:36:56,240
packed so in this case it's really hard

948
00:36:56,240 --> 00:36:57,920
to find shared code because of the

949
00:36:57,920 --> 00:36:59,839
application techniques

950
00:36:59,839 --> 00:37:03,359
but anyway we still managed to do this

951
00:37:03,359 --> 00:37:05,680
let's go to the finals i know everybody

952
00:37:05,680 --> 00:37:08,640
is hungry so to recap the flow

953
00:37:08,640 --> 00:37:10,560
searching for the graph and you're

954
00:37:10,560 --> 00:37:12,880
searching the graph for new binaries

955
00:37:12,880 --> 00:37:15,680
is much faster than any third-party

956
00:37:15,680 --> 00:37:17,920
validation because we have everything at

957
00:37:17,920 --> 00:37:19,839
home we know exactly what we are looking

958
00:37:19,839 --> 00:37:22,079
for we optimize all the data we optimize

959
00:37:22,079 --> 00:37:24,240
all the algorithms for search we know

960
00:37:24,240 --> 00:37:26,240
exactly this is

961
00:37:26,240 --> 00:37:27,440
our

962
00:37:27,440 --> 00:37:28,800
uh

963
00:37:28,800 --> 00:37:31,040
our two and we know how to use it

964
00:37:31,040 --> 00:37:33,040
in-home validation approach remove

965
00:37:33,040 --> 00:37:36,640
uncertainty of vt result interpretation

966
00:37:36,640 --> 00:37:38,880
because we label everything we know

967
00:37:38,880 --> 00:37:40,960
where it belongs we have all the samples

968
00:37:40,960 --> 00:37:42,640
here we can take a look we can reverse

969
00:37:42,640 --> 00:37:44,720
them if they want virustotal does not

970
00:37:44,720 --> 00:37:46,560
provide this information

971
00:37:46,560 --> 00:37:49,040
and present workforce implemented in

972
00:37:49,040 --> 00:37:51,040
security products in alibaba and we're

973
00:37:51,040 --> 00:37:53,920
still working on expand of you know

974
00:37:53,920 --> 00:37:56,400
expansion to expand our contribution to

975
00:37:56,400 --> 00:37:58,640
this product

976
00:37:58,640 --> 00:38:01,200
one question is deep essential basically

977
00:38:01,200 --> 00:38:02,079
no

978
00:38:02,079 --> 00:38:04,480
any other fuzzy hash you can afford will

979
00:38:04,480 --> 00:38:05,359
do

980
00:38:05,359 --> 00:38:07,920
for example lzgd

981
00:38:07,920 --> 00:38:10,800
is bigger one it takes a lot of space on

982
00:38:10,800 --> 00:38:13,599
your on your disk but

983
00:38:13,599 --> 00:38:15,359
it's much more

984
00:38:15,359 --> 00:38:17,760
accurate i would say in it and it can

985
00:38:17,760 --> 00:38:19,359
track like swap the data and

986
00:38:19,359 --> 00:38:21,839
fragmentation and everything so it's not

987
00:38:21,839 --> 00:38:24,160
critical to use exactly ssd everything

988
00:38:24,160 --> 00:38:25,119
that

989
00:38:25,119 --> 00:38:27,359
listed here skills you need whatever you

990
00:38:27,359 --> 00:38:29,280
can adapt whatever you can support

991
00:38:29,280 --> 00:38:32,640
whatever you have capabilities so please

992
00:38:32,640 --> 00:38:35,119
take a look and try to build it

993
00:38:35,119 --> 00:38:38,160
okay okay take aways from everything so

994
00:38:38,160 --> 00:38:40,000
successful malware

995
00:38:40,000 --> 00:38:42,640
evolves and comes back again and again

996
00:38:42,640 --> 00:38:44,880
um nobody knew that we're going to be

997
00:38:44,880 --> 00:38:47,760
talking about miray and sordidos after

998
00:38:47,760 --> 00:38:49,599
seven eight years

999
00:38:49,599 --> 00:38:50,880
after the first release but they're

1000
00:38:50,880 --> 00:38:53,760
still here it's super easy malware to

1001
00:38:53,760 --> 00:38:55,839
adopt it's super easy to change super

1002
00:38:55,839 --> 00:38:57,359
inexpensive to

1003
00:38:57,359 --> 00:38:59,839
use and you don't even need to fire your

1004
00:38:59,839 --> 00:39:01,599
super expensive

1005
00:39:01,599 --> 00:39:03,839
zero day and they works just fine just

1006
00:39:03,839 --> 00:39:06,480
modify it sell it and go

1007
00:39:06,480 --> 00:39:07,359
so

1008
00:39:07,359 --> 00:39:10,160
we cannot get rid of this in in in the

1009
00:39:10,160 --> 00:39:12,079
near future i believe

1010
00:39:12,079 --> 00:39:13,920
big companies face specific malware

1011
00:39:13,920 --> 00:39:16,640
threats and we have unique security

1012
00:39:16,640 --> 00:39:19,440
needs so it's easy to overgrow

1013
00:39:19,440 --> 00:39:22,960
even best third-party validation

1014
00:39:22,960 --> 00:39:24,880
so far we find out that the label

1015
00:39:24,880 --> 00:39:27,040
propagation clustering are two major

1016
00:39:27,040 --> 00:39:29,680
techniques in ssd graph framework if it

1017
00:39:29,680 --> 00:39:31,200
does sounds

1018
00:39:31,200 --> 00:39:33,280
a little bit intimidating no worries

1019
00:39:33,280 --> 00:39:35,200
it's absolutely standard algorithms to

1020
00:39:35,200 --> 00:39:37,599
work with the big data label propagation

1021
00:39:37,599 --> 00:39:39,359
allows us to provide the attribution to

1022
00:39:39,359 --> 00:39:41,599
the family and clustering just allow us

1023
00:39:41,599 --> 00:39:44,000
to gather naturally

1024
00:39:44,000 --> 00:39:45,920
data without labeling

1025
00:39:45,920 --> 00:39:47,440
to the to the clusters we're going to

1026
00:39:47,440 --> 00:39:48,800
investigate

1027
00:39:48,800 --> 00:39:52,000
and besides the everything we listed

1028
00:39:52,000 --> 00:39:54,880
the potential use can be

1029
00:39:54,880 --> 00:39:57,440
even detect the supply chain pollution

1030
00:39:57,440 --> 00:39:59,359
and if you don't know what supply chain

1031
00:39:59,359 --> 00:40:02,480
pollution is probably everybody seen

1032
00:40:02,480 --> 00:40:03,359
this

1033
00:40:03,359 --> 00:40:04,960
sshd

1034
00:40:04,960 --> 00:40:07,440
malicious server that looks exactly like

1035
00:40:07,440 --> 00:40:09,200
a sshd but

1036
00:40:09,200 --> 00:40:12,400
it has a trojan side so this is exactly

1037
00:40:12,400 --> 00:40:13,359
uh

1038
00:40:13,359 --> 00:40:15,760
pollution of the supply chain when you

1039
00:40:15,760 --> 00:40:17,599
install something benign and you believe

1040
00:40:17,599 --> 00:40:19,040
that this is a part of the system but

1041
00:40:19,040 --> 00:40:21,920
it's already got screwed somewhere

1042
00:40:21,920 --> 00:40:23,760
it's pretty much it's it's the last word

1043
00:40:23,760 --> 00:40:25,599
i wouldn't just want to tell to

1044
00:40:25,599 --> 00:40:27,760
aristotle guys we still love you

1045
00:40:27,760 --> 00:40:29,119
for sure

1046
00:40:29,119 --> 00:40:30,720
we still love you we're still with you

1047
00:40:30,720 --> 00:40:33,920
you contribute to community great but

1048
00:40:33,920 --> 00:40:36,640
for us it's time to go it's time to grow

1049
00:40:36,640 --> 00:40:38,880
and we are here for that thank you very

1050
00:40:38,880 --> 00:40:41,119
much

1051
00:40:46,480 --> 00:40:48,720
just just one last uh uh note that i

1052
00:40:48,720 --> 00:40:50,960
would like uh we're five minutes late

1053
00:40:50,960 --> 00:40:52,960
already okay thank you

1054
00:40:52,960 --> 00:40:55,280
for the invitation and alibaba for

1055
00:40:55,280 --> 00:40:57,359
making this trip possible so and the

1056
00:40:57,359 --> 00:40:59,200
paper will be published upcoming

1057
00:40:59,200 --> 00:41:03,720
conference paper thank you

