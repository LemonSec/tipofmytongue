1
00:00:01,020 --> 00:00:03,419
yeah hello everyone my name is Daniel

2
00:00:03,419 --> 00:00:05,880
I'm a security researcher at front of

3
00:00:05,880 --> 00:00:08,340
fke in Germany I also do some teaching

4
00:00:08,340 --> 00:00:11,160
at University of Bonn and my work scope

5
00:00:11,160 --> 00:00:13,320
usually is analysis of malware in

6
00:00:13,320 --> 00:00:15,480
general reverse engineering and Analysis

7
00:00:15,480 --> 00:00:17,880
automation I had a chance to present a

8
00:00:17,880 --> 00:00:19,800
couple times a podcast before and I'm

9
00:00:19,800 --> 00:00:22,680
very happy to be back here since this is

10
00:00:22,680 --> 00:00:23,580
absolutely one of my favorite

11
00:00:23,580 --> 00:00:25,320
conferences and thank you to the

12
00:00:25,320 --> 00:00:27,720
organizers for running it every year

13
00:00:27,720 --> 00:00:30,000
so what am I going to talk about

14
00:00:30,000 --> 00:00:31,619
um as Eric already said it's going to be

15
00:00:31,619 --> 00:00:33,300
about a framework for code similarity

16
00:00:33,300 --> 00:00:35,340
analysis and for the structure of the

17
00:00:35,340 --> 00:00:36,480
talk I first want to give a short

18
00:00:36,480 --> 00:00:38,399
motivation how I ended up doing that

19
00:00:38,399 --> 00:00:40,980
then talk about the system itself the

20
00:00:40,980 --> 00:00:42,300
algorithms that are used for code

21
00:00:42,300 --> 00:00:44,219
similarity and how do you framework are

22
00:00:44,219 --> 00:00:46,440
structured I'm talking about the

23
00:00:46,440 --> 00:00:47,820
framework in particular because we are

24
00:00:47,820 --> 00:00:49,620
sharing all of this as open source as

25
00:00:49,620 --> 00:00:52,500
well and then I'm going over some use

26
00:00:52,500 --> 00:00:54,660
cases that I see for this type of

27
00:00:54,660 --> 00:00:57,840
analysis and do some case studies to

28
00:00:57,840 --> 00:00:59,280
motivate them and then give an outlook

29
00:00:59,280 --> 00:01:01,500
on what we where we want to go from the

30
00:01:01,500 --> 00:01:04,379
stage where we already are so for the

31
00:01:04,379 --> 00:01:07,380
motivation who remembers this

32
00:01:07,380 --> 00:01:09,420
so this has been a couple years ago

33
00:01:09,420 --> 00:01:12,119
already so it was 2017.

34
00:01:12,119 --> 00:01:15,119
um this is some famous Warner cry

35
00:01:15,119 --> 00:01:18,560
um probably one of the most important

36
00:01:18,560 --> 00:01:21,479
exploits weaponized and ransomware in

37
00:01:21,479 --> 00:01:23,220
the last couple of years it had so much

38
00:01:23,220 --> 00:01:24,479
impact that everyone was probably

39
00:01:24,479 --> 00:01:26,460
wondering who was responsible for that

40
00:01:26,460 --> 00:01:27,960
so this discretion of attack attribution

41
00:01:27,960 --> 00:01:30,600
was uh very important and then there was

42
00:01:30,600 --> 00:01:33,780
this tweet who knows about this tweet

43
00:01:33,780 --> 00:01:36,420
I mean if you if you post some hashes

44
00:01:36,420 --> 00:01:39,659
and addresses I'm super curious um so I

45
00:01:39,659 --> 00:01:42,000
went and looked at it at the time and if

46
00:01:42,000 --> 00:01:43,320
you look at it in particular you see

47
00:01:43,320 --> 00:01:45,479
this so okay those functions look very

48
00:01:45,479 --> 00:01:47,880
similar and the interesting thing here

49
00:01:47,880 --> 00:01:49,680
is one of them is Warner cry and the

50
00:01:49,680 --> 00:01:51,720
other one is a another family called

51
00:01:51,720 --> 00:01:53,340
control P that has been covered by

52
00:01:53,340 --> 00:01:54,540
semantic before

53
00:01:54,540 --> 00:01:57,240
and was attributed to Lazarus so this

54
00:01:57,240 --> 00:01:59,280
was a clear pointer towards yeah might

55
00:01:59,280 --> 00:02:01,979
be Lazarus we're not sure yet but I was

56
00:02:01,979 --> 00:02:04,020
completely impressed by um basically

57
00:02:04,020 --> 00:02:05,880
this this because it was pretty quickly

58
00:02:05,880 --> 00:02:08,160
after the attack and

59
00:02:08,160 --> 00:02:10,318
um I told myself I want to be able to do

60
00:02:10,318 --> 00:02:12,660
that as well and I tried to figure out a

61
00:02:12,660 --> 00:02:14,760
way to maybe get into a position to find

62
00:02:14,760 --> 00:02:17,940
such links quickly and even today

63
00:02:17,940 --> 00:02:20,280
um many of the basic blocks are shown in

64
00:02:20,280 --> 00:02:22,140
this function are basically unique still

65
00:02:22,140 --> 00:02:24,540
all across my PDF which is for more than

66
00:02:24,540 --> 00:02:27,000
1500 different families so if you're

67
00:02:27,000 --> 00:02:29,520
able to basically find a bit pinpoint

68
00:02:29,520 --> 00:02:31,260
such blocks it might be really

69
00:02:31,260 --> 00:02:33,360
interesting to discover links that you

70
00:02:33,360 --> 00:02:35,760
are not assuming or know about

71
00:02:35,760 --> 00:02:38,819
so coaching RTA analysis in general I

72
00:02:38,819 --> 00:02:40,260
think has some very high potential to

73
00:02:40,260 --> 00:02:43,440
help analysis to isolate there

74
00:02:43,440 --> 00:02:46,500
analysis um I've been using bindiff for

75
00:02:46,500 --> 00:02:49,080
almost 15 years now I think and that has

76
00:02:49,080 --> 00:02:51,599
been always been one of my go-to's be it

77
00:02:51,599 --> 00:02:54,420
for transferring labels between Ida idbs

78
00:02:54,420 --> 00:02:55,680
and everything like this or just

79
00:02:55,680 --> 00:02:57,060
comparing things

80
00:02:57,060 --> 00:02:58,860
and um

81
00:02:58,860 --> 00:03:00,900
my feeling is most of the existing

82
00:03:00,900 --> 00:03:02,580
solutions that are available are rather

83
00:03:02,580 --> 00:03:05,340
one-to-one comparisons so benefit like I

84
00:03:05,340 --> 00:03:06,720
said or diaphora which is another

85
00:03:06,720 --> 00:03:08,400
excellent open source tool in that

86
00:03:08,400 --> 00:03:11,099
context so you can only compare two

87
00:03:11,099 --> 00:03:12,959
binaries and most of the other solutions

88
00:03:12,959 --> 00:03:14,700
that would enable you to do one against

89
00:03:14,700 --> 00:03:17,280
many are proprietary so there are some

90
00:03:17,280 --> 00:03:18,480
companies that are offering software

91
00:03:18,480 --> 00:03:20,640
services like that or they are not fully

92
00:03:20,640 --> 00:03:22,080
open source at least so I thought hey

93
00:03:22,080 --> 00:03:23,879
let's see what we can do here

94
00:03:23,879 --> 00:03:26,700
so this is where mcreat is coming in so

95
00:03:26,700 --> 00:03:28,620
my goal was basically to analyze code

96
00:03:28,620 --> 00:03:31,019
sharing as well as the use of

97
00:03:31,019 --> 00:03:33,000
third-party libraries in malicious

98
00:03:33,000 --> 00:03:34,500
software because if we are able to sort

99
00:03:34,500 --> 00:03:36,900
out those libraries we might not have to

100
00:03:36,900 --> 00:03:38,720
look at all of the functions we can

101
00:03:38,720 --> 00:03:41,040
shape our Focus towards the more

102
00:03:41,040 --> 00:03:43,920
interesting parts and sometimes even the

103
00:03:43,920 --> 00:03:46,140
ReUse of third-party libraries can be

104
00:03:46,140 --> 00:03:48,120
interesting

105
00:03:48,120 --> 00:03:49,080
um so

106
00:03:49,080 --> 00:03:51,299
on another hand I wanted to create

107
00:03:51,299 --> 00:03:53,580
another tool that basically enables you

108
00:03:53,580 --> 00:03:56,159
to interact better with my PDR so my

109
00:03:56,159 --> 00:03:58,200
feeling I don't get a lot of feedback

110
00:03:58,200 --> 00:04:00,659
for malapedia

111
00:04:00,659 --> 00:04:02,700
um it's I guess most people are just

112
00:04:02,700 --> 00:04:04,980
using the library and looking at what is

113
00:04:04,980 --> 00:04:06,959
basically published in blocks and stuff

114
00:04:06,959 --> 00:04:09,659
like that but I'm way more a fan of the

115
00:04:09,659 --> 00:04:11,220
binary Corpus that's below it and I

116
00:04:11,220 --> 00:04:13,560
thought okay maybe if I start providing

117
00:04:13,560 --> 00:04:15,180
another tool that allows you to interact

118
00:04:15,180 --> 00:04:17,100
with the Corpus itself

119
00:04:17,100 --> 00:04:19,500
people get additional good ideas what to

120
00:04:19,500 --> 00:04:22,079
do with it and for this project that I'm

121
00:04:22,079 --> 00:04:23,820
going to talk about we didn't want to

122
00:04:23,820 --> 00:04:25,620
reinvent the wheel basically um there's

123
00:04:25,620 --> 00:04:27,479
so much research on code similarity

124
00:04:27,479 --> 00:04:29,100
analysis already that I wanted to reuse

125
00:04:29,100 --> 00:04:30,600
some of the proven techniques that are

126
00:04:30,600 --> 00:04:32,820
there so for the requirements what I

127
00:04:32,820 --> 00:04:34,800
wanted to have is a similarity measure

128
00:04:34,800 --> 00:04:36,780
that is first reliable and then

129
00:04:36,780 --> 00:04:38,100
interpretable so you can still

130
00:04:38,100 --> 00:04:39,660
understand why functions are matched to

131
00:04:39,660 --> 00:04:42,060
each other it should at least scale into

132
00:04:42,060 --> 00:04:44,580
tens of millions of functions so that's

133
00:04:44,580 --> 00:04:46,979
not you pile everything that you have in

134
00:04:46,979 --> 00:04:49,020
there but you still rather want to work

135
00:04:49,020 --> 00:04:51,600
on a data set that you have some

136
00:04:51,600 --> 00:04:53,820
knowledge and ideas about so basically

137
00:04:53,820 --> 00:04:57,720
having labels on it comes really in well

138
00:04:57,720 --> 00:04:59,160
for some of the additional functionality

139
00:04:59,160 --> 00:05:01,740
that I'm going to talk about and another

140
00:05:01,740 --> 00:05:04,440
thing that I was aiming for is if you're

141
00:05:04,440 --> 00:05:06,660
indexing a function what's the average

142
00:05:06,660 --> 00:05:08,759
size of a function let's say 80 bytes

143
00:05:08,759 --> 00:05:10,800
you don't want to do indexing that is

144
00:05:10,800 --> 00:05:12,840
like 10 times the size of the function

145
00:05:12,840 --> 00:05:14,460
because otherwise you cannot achieve

146
00:05:14,460 --> 00:05:17,460
scalability and at least at the time

147
00:05:17,460 --> 00:05:19,740
when we started working on that for me

148
00:05:19,740 --> 00:05:21,600
it was not a high priority to do a cross

149
00:05:21,600 --> 00:05:23,699
fitness or cross-architecture if you

150
00:05:23,699 --> 00:05:25,500
look at many of the academic research on

151
00:05:25,500 --> 00:05:27,240
the topic they are mostly interested in

152
00:05:27,240 --> 00:05:29,639
vulnerability Discovery or rediscovery

153
00:05:29,639 --> 00:05:32,419
and cross architecture in particular

154
00:05:32,419 --> 00:05:34,380
mapedia especially at the time when we

155
00:05:34,380 --> 00:05:36,120
started working on that was still a lot

156
00:05:36,120 --> 00:05:38,160
of 32-bit codes so I rather wanted to

157
00:05:38,160 --> 00:05:41,400
focus on 32-bit info

158
00:05:41,400 --> 00:05:43,800
so how does it work um there's a very

159
00:05:43,800 --> 00:05:46,940
good survey paper on code similarity

160
00:05:46,940 --> 00:05:51,479
research by um and Caballero I think and

161
00:05:51,479 --> 00:05:53,880
they said basically you have more than

162
00:05:53,880 --> 00:05:56,160
50 papers on code similarity published

163
00:05:56,160 --> 00:05:58,919
since 2010 so there should be a lot

164
00:05:58,919 --> 00:06:00,539
where you can look and get some ideas on

165
00:06:00,539 --> 00:06:02,880
what you want to do however if you look

166
00:06:02,880 --> 00:06:04,139
at how many of them are doing malware

167
00:06:04,139 --> 00:06:06,539
stuff it's it's getting narrower and

168
00:06:06,539 --> 00:06:08,039
there's only one that basically ever

169
00:06:08,039 --> 00:06:09,600
looked at um

170
00:06:09,600 --> 00:06:12,060
how is free and open source Library

171
00:06:12,060 --> 00:06:14,280
usage found in Melbourne how can we work

172
00:06:14,280 --> 00:06:15,600
with that so I thought okay there's

173
00:06:15,600 --> 00:06:17,639
still some room to do uh in in this

174
00:06:17,639 --> 00:06:19,979
regard so mcreit the tool that I'm

175
00:06:19,979 --> 00:06:21,800
talking about basically combines

176
00:06:21,800 --> 00:06:24,360
quasi-identical and fuzzy code matching

177
00:06:24,360 --> 00:06:25,800
um quasi identical is really good

178
00:06:25,800 --> 00:06:27,660
because most of the statically link code

179
00:06:27,660 --> 00:06:30,120
will be linked in the very exact same

180
00:06:30,120 --> 00:06:32,940
fashion so that helps you to sort that

181
00:06:32,940 --> 00:06:35,100
out really quickly and the other one is

182
00:06:35,100 --> 00:06:37,500
always useful if code has been slightly

183
00:06:37,500 --> 00:06:39,900
modified or recompiled in order to find

184
00:06:39,900 --> 00:06:41,940
something there as well so we are aiming

185
00:06:41,940 --> 00:06:44,039
for both the basic block and the

186
00:06:44,039 --> 00:06:46,080
function level with this at least for

187
00:06:46,080 --> 00:06:48,960
the quasi-identical thingy and overall

188
00:06:48,960 --> 00:06:51,900
we want to do efficient one to many

189
00:06:51,900 --> 00:06:54,060
matching so um is that what I basically

190
00:06:54,060 --> 00:06:55,620
meant you want to have one sample that

191
00:06:55,620 --> 00:06:57,479
you're interested in you slap it against

192
00:06:57,479 --> 00:06:59,220
the this service and then you get a

193
00:06:59,220 --> 00:07:01,319
response where does this have similarity

194
00:07:01,319 --> 00:07:02,580
in all of the different things that have

195
00:07:02,580 --> 00:07:04,740
been matched and the techniques used

196
00:07:04,740 --> 00:07:06,240
here are on the one hand hashmaps

197
00:07:06,240 --> 00:07:08,340
because they are very efficient with

198
00:07:08,340 --> 00:07:11,520
access and locality sensitive hashing in

199
00:07:11,520 --> 00:07:13,380
particular minhesh in order to also

200
00:07:13,380 --> 00:07:15,720
speed up the fuzzy part

201
00:07:15,720 --> 00:07:18,120
um there are several co-authors so for

202
00:07:18,120 --> 00:07:19,740
this presentation it's mostly manual and

203
00:07:19,740 --> 00:07:22,020
Dania but I also want to mention Paul

204
00:07:22,020 --> 00:07:24,000
and Stefan to help me with my earlier

205
00:07:24,000 --> 00:07:26,759
research on the evaluation prototype

206
00:07:26,759 --> 00:07:30,479
that I use in my PhD thesis so the

207
00:07:30,479 --> 00:07:32,580
overall workflow is something like this

208
00:07:32,580 --> 00:07:34,680
as input you might have share code you

209
00:07:34,680 --> 00:07:36,840
might have an XC it could be a PE file

210
00:07:36,840 --> 00:07:39,960
could be an L file a program Library you

211
00:07:39,960 --> 00:07:41,639
first disassemble that so you get the

212
00:07:41,639 --> 00:07:43,680
functions and then you do the index

213
00:07:43,680 --> 00:07:45,900
thing so on one card one hand what you

214
00:07:45,900 --> 00:07:47,819
want to do in interactive is that you

215
00:07:47,819 --> 00:07:50,400
want to White card all of the addresses

216
00:07:50,400 --> 00:07:52,199
in there because if your code is

217
00:07:52,199 --> 00:07:53,340
basically

218
00:07:53,340 --> 00:07:56,940
a memory dump and U2 aslr or loading it

219
00:07:56,940 --> 00:07:58,979
might be anywhere in the memory you have

220
00:07:58,979 --> 00:08:00,479
static addresses in there and they

221
00:08:00,479 --> 00:08:01,979
basically screw up the matching for you

222
00:08:01,979 --> 00:08:04,620
and if you wipe out those or basically

223
00:08:04,620 --> 00:08:06,539
if code was reused you have a way better

224
00:08:06,539 --> 00:08:09,060
chance to find the code again

225
00:08:09,060 --> 00:08:10,979
yeah so this is our quasi identical

226
00:08:10,979 --> 00:08:13,080
representation and we put it in a

227
00:08:13,080 --> 00:08:15,240
database and for the Min heshing you

228
00:08:15,240 --> 00:08:17,759
need a way to describe the functions and

229
00:08:17,759 --> 00:08:19,680
for me that's token and metrics-based

230
00:08:19,680 --> 00:08:22,500
features I'm going to talk about them in

231
00:08:22,500 --> 00:08:24,360
a minute and then you throw them into

232
00:08:24,360 --> 00:08:26,039
Min hashing and also put that in your

233
00:08:26,039 --> 00:08:27,000
database

234
00:08:27,000 --> 00:08:28,620
so in more detail

235
00:08:28,620 --> 00:08:30,599
this position independent code testing

236
00:08:30,599 --> 00:08:32,700
is a technique that has been described

237
00:08:32,700 --> 00:08:36,080
in 2009 by the fine focus of third CC

238
00:08:36,080 --> 00:08:39,839
and they basically found out that you if

239
00:08:39,839 --> 00:08:42,120
you have a large amount of code you can

240
00:08:42,120 --> 00:08:43,640
drastically reduce

241
00:08:43,640 --> 00:08:46,020
the number of unique functions that you

242
00:08:46,020 --> 00:08:48,120
have in there and I thought okay that is

243
00:08:48,120 --> 00:08:49,800
something that I want to do as well um

244
00:08:49,800 --> 00:08:51,240
the two functions that you can see here

245
00:08:51,240 --> 00:08:53,040
just by the first Glimpse you would say

246
00:08:53,040 --> 00:08:55,140
they are similar to each other right

247
00:08:55,140 --> 00:08:56,640
they look very similar it's the same

248
00:08:56,640 --> 00:08:59,700
amount of blocks the edges look the same

249
00:08:59,700 --> 00:09:01,860
blocks are even the same size but

250
00:09:01,860 --> 00:09:04,440
they're not identical so there are some

251
00:09:04,440 --> 00:09:06,600
slight differences in there and with the

252
00:09:06,600 --> 00:09:08,399
pick hashing we basically index the

253
00:09:08,399 --> 00:09:09,779
whole function and if even if there's

254
00:09:09,779 --> 00:09:11,640
basically some slight differences like

255
00:09:11,640 --> 00:09:13,380
in stack use or something like this you

256
00:09:13,380 --> 00:09:15,779
get another hash so it really is for

257
00:09:15,779 --> 00:09:18,540
exact reuse basically so how does this

258
00:09:18,540 --> 00:09:19,920
pick hashing work we use the instruction

259
00:09:19,920 --> 00:09:22,500
bytes here and as I said for example

260
00:09:22,500 --> 00:09:24,240
here on the stack we have a reservation

261
00:09:24,240 --> 00:09:28,019
of 134 hex bytes we might end up with

262
00:09:28,019 --> 00:09:29,580
this hashing procedure with this number

263
00:09:29,580 --> 00:09:31,320
what we're using here is basically just

264
00:09:31,320 --> 00:09:34,800
a prefix of the sharp 256 representation

265
00:09:34,800 --> 00:09:37,440
if we hit the other function we have a

266
00:09:37,440 --> 00:09:41,519
different hash so this is sad but we

267
00:09:41,519 --> 00:09:42,839
don't need to do anything about it

268
00:09:42,839 --> 00:09:44,880
because like I said it's still a very

269
00:09:44,880 --> 00:09:47,040
good technique if you want to do um

270
00:09:47,040 --> 00:09:48,899
recognition of aesthetic dealing code

271
00:09:48,899 --> 00:09:50,640
because that is basically always exactly

272
00:09:50,640 --> 00:09:52,380
the same

273
00:09:52,380 --> 00:09:54,240
we're also doing this on basic log level

274
00:09:54,240 --> 00:09:55,920
so this is where it's getting a bit more

275
00:09:55,920 --> 00:09:57,060
interesting

276
00:09:57,060 --> 00:09:59,100
again it might happen that your blocks

277
00:09:59,100 --> 00:10:01,800
are not the same but you at least have a

278
00:10:01,800 --> 00:10:03,180
higher chance that they're maybe even

279
00:10:03,180 --> 00:10:04,680
already blocks that are the same and

280
00:10:04,680 --> 00:10:06,180
even those can be good indicators where

281
00:10:06,180 --> 00:10:08,100
to look at and the old id of this

282
00:10:08,100 --> 00:10:10,019
framework is to point you towards those

283
00:10:10,019 --> 00:10:12,480
blocks in the first place so this is

284
00:10:12,480 --> 00:10:14,000
some good

285
00:10:14,000 --> 00:10:17,060
technique if you want to identify

286
00:10:17,060 --> 00:10:20,880
candidates for potential code reuse

287
00:10:20,880 --> 00:10:23,940
so what's Min hashing

288
00:10:23,940 --> 00:10:26,519
um ultimately it's an algorithm that

289
00:10:26,519 --> 00:10:30,660
does independent permutations in a sense

290
00:10:30,660 --> 00:10:32,940
that it allows you to do really fast an

291
00:10:32,940 --> 00:10:35,700
estimate of set similarity what a set

292
00:10:35,700 --> 00:10:37,980
similarity say you have two sets here

293
00:10:37,980 --> 00:10:40,740
one is C1 and C2 and they have some

294
00:10:40,740 --> 00:10:43,560
overlap in this case the circle and also

295
00:10:43,560 --> 00:10:45,300
the Pentagon and they have some

296
00:10:45,300 --> 00:10:47,820
different parts in there there's

297
00:10:47,820 --> 00:10:49,500
basically the Jakarta similarity

298
00:10:49,500 --> 00:10:51,660
coefficient that gives you a measure on

299
00:10:51,660 --> 00:10:53,640
how similar those two sets are and

300
00:10:53,640 --> 00:10:55,500
normally you would take the same parts

301
00:10:55,500 --> 00:10:58,399
and divide them the by the amount of

302
00:10:58,399 --> 00:11:01,380
different elements that you can observe

303
00:11:01,380 --> 00:11:04,500
in there in total so that will two sets

304
00:11:04,500 --> 00:11:06,660
here would have a jackass similarity of

305
00:11:06,660 --> 00:11:08,940
0.5

306
00:11:08,940 --> 00:11:10,860
um it's very scalable

307
00:11:10,860 --> 00:11:12,779
um it still allows us to do um those

308
00:11:12,779 --> 00:11:14,399
signal single lookups also in

309
00:11:14,399 --> 00:11:16,019
logarithmic time which is really good

310
00:11:16,019 --> 00:11:17,579
because that means that when we are

311
00:11:17,579 --> 00:11:19,920
later doing this one-to-many lookup we

312
00:11:19,920 --> 00:11:22,200
don't have to throw all of our functions

313
00:11:22,200 --> 00:11:23,880
against all of the other ones but we can

314
00:11:23,880 --> 00:11:25,500
limit ourselves to candidates that we

315
00:11:25,500 --> 00:11:27,420
really only want to match with that

316
00:11:27,420 --> 00:11:29,700
and because of those reasons it has been

317
00:11:29,700 --> 00:11:31,620
used in the past for example for the

318
00:11:31,620 --> 00:11:34,260
indexing or similarity analysis on text

319
00:11:34,260 --> 00:11:35,760
documents I think it was also the

320
00:11:35,760 --> 00:11:38,160
original technique that it was used in

321
00:11:38,160 --> 00:11:40,320
the artavista search engine for example

322
00:11:40,320 --> 00:11:41,940
and had found many different

323
00:11:41,940 --> 00:11:44,100
applications later on like in genome

324
00:11:44,100 --> 00:11:47,100
sequencing and also I think in 2012 was

325
00:11:47,100 --> 00:11:48,660
the first time it was used for for code

326
00:11:48,660 --> 00:11:50,040
analysis

327
00:11:50,040 --> 00:11:52,260
yeah so how are we doing this in

328
00:11:52,260 --> 00:11:54,300
particular here's another function and

329
00:11:54,300 --> 00:11:56,820
now we want to Index this one using Min

330
00:11:56,820 --> 00:11:59,820
hashing as I said we can do tokens so if

331
00:11:59,820 --> 00:12:01,860
you think that code is more or less like

332
00:12:01,860 --> 00:12:03,959
a text document the new instructions

333
00:12:03,959 --> 00:12:06,000
could be words in there right and if we

334
00:12:06,000 --> 00:12:07,860
want to say two of them might be similar

335
00:12:07,860 --> 00:12:10,140
it's likely that you have similar

336
00:12:10,140 --> 00:12:12,660
instruction sequences in here and that's

337
00:12:12,660 --> 00:12:13,800
basically what we're doing here we're

338
00:12:13,800 --> 00:12:16,740
taking those sequences of instructions

339
00:12:16,740 --> 00:12:19,200
like this push ESI movies are something

340
00:12:19,200 --> 00:12:21,600
push ESI then the next one move us I

341
00:12:21,600 --> 00:12:24,959
purchase I call and put them into these

342
00:12:24,959 --> 00:12:27,779
this these smaller bits and we also do

343
00:12:27,779 --> 00:12:29,459
some abstraction because some for

344
00:12:29,459 --> 00:12:31,380
instructions you can typically say okay

345
00:12:31,380 --> 00:12:33,120
with the move then it's interacting

346
00:12:33,120 --> 00:12:35,040
somehow with memory if it's push or pop

347
00:12:35,040 --> 00:12:36,600
then it might be interaction with stack

348
00:12:36,600 --> 00:12:38,760
there might be arithmetic instructions

349
00:12:38,760 --> 00:12:41,399
and this basically helps that you um

350
00:12:41,399 --> 00:12:44,459
introduce some fuzziness that will allow

351
00:12:44,459 --> 00:12:47,279
you to do those not exact matches but

352
00:12:47,279 --> 00:12:49,740
more but you would call similar but not

353
00:12:49,740 --> 00:12:52,380
identical matches so this is a lot of

354
00:12:52,380 --> 00:12:53,700
those abstractions that we are doing

355
00:12:53,700 --> 00:12:56,639
here and then ultimately that since it's

356
00:12:56,639 --> 00:12:58,980
called Min hashing we use a set of

357
00:12:58,980 --> 00:13:01,740
different hash functions we pick the

358
00:13:01,740 --> 00:13:03,600
smallest value of those and we basically

359
00:13:03,600 --> 00:13:05,760
can generate this sequence that's

360
00:13:05,760 --> 00:13:08,339
describing our function this way so for

361
00:13:08,339 --> 00:13:09,720
each of the functions we are able to

362
00:13:09,720 --> 00:13:12,540
Define this unique fingerprint

363
00:13:12,540 --> 00:13:14,760
and the other range of features that we

364
00:13:14,760 --> 00:13:17,579
are using um my thought was okay or that

365
00:13:17,579 --> 00:13:18,959
has been used in literature a lot is

366
00:13:18,959 --> 00:13:20,160
that you describe a function

367
00:13:20,160 --> 00:13:22,860
statistically you can say how many calls

368
00:13:22,860 --> 00:13:24,480
are in this function how large is the

369
00:13:24,480 --> 00:13:27,060
largest basic block how many call

370
00:13:27,060 --> 00:13:29,220
instruct or control flow instructions

371
00:13:29,220 --> 00:13:31,200
are in there how large is the stack

372
00:13:31,200 --> 00:13:33,360
that's being used and um

373
00:13:33,360 --> 00:13:35,820
if we're using those exact values we

374
00:13:35,820 --> 00:13:37,680
don't have any fuzziness so we we need

375
00:13:37,680 --> 00:13:39,300
to represent that in a way that those

376
00:13:39,300 --> 00:13:40,500
values become

377
00:13:40,500 --> 00:13:43,200
measurable again and one way to do that

378
00:13:43,200 --> 00:13:45,120
for example is quantization so if I have

379
00:13:45,120 --> 00:13:47,880
a maximum block size for example a 14

380
00:13:47,880 --> 00:13:49,620
I would probably also want another

381
00:13:49,620 --> 00:13:51,720
function that has a largest block of 13

382
00:13:51,720 --> 00:13:54,360
or 15 so that the neighbors and what we

383
00:13:54,360 --> 00:13:56,160
can basically do is um with this

384
00:13:56,160 --> 00:13:58,800
quantization throw them into buckets so

385
00:13:58,800 --> 00:14:00,899
they will be matched later on

386
00:14:00,899 --> 00:14:03,899
and after this procedure we basically

387
00:14:03,899 --> 00:14:06,060
end up with tokens again that are

388
00:14:06,060 --> 00:14:07,139
similar to the ones that I've shown

389
00:14:07,139 --> 00:14:09,360
before and we do the same thing of

390
00:14:09,360 --> 00:14:12,420
hashing selecting the representation and

391
00:14:12,420 --> 00:14:14,700
can add that to our sequence as well so

392
00:14:14,700 --> 00:14:16,620
ultimately we will have this numerical

393
00:14:16,620 --> 00:14:19,800
sequence that is describing our function

394
00:14:19,800 --> 00:14:22,860
in a more abstract fashion and now our

395
00:14:22,860 --> 00:14:25,320
hope is if we use that on similar

396
00:14:25,320 --> 00:14:27,779
functions a lot of this representation

397
00:14:27,779 --> 00:14:30,959
will create an overlap so for example we

398
00:14:30,959 --> 00:14:33,060
have two different functions here one

399
00:14:33,060 --> 00:14:35,339
has this section this sequence is shown

400
00:14:35,339 --> 00:14:37,380
here this is the other sequence and I've

401
00:14:37,380 --> 00:14:38,700
highlighted basically all of the

402
00:14:38,700 --> 00:14:41,220
positions where we ended up with the

403
00:14:41,220 --> 00:14:44,040
same values and just like I've explained

404
00:14:44,040 --> 00:14:46,079
with the jackass similarity we can count

405
00:14:46,079 --> 00:14:48,420
how many of them are exactly the same

406
00:14:48,420 --> 00:14:50,160
and divide them through the length of

407
00:14:50,160 --> 00:14:52,139
the signature and in this case we would

408
00:14:52,139 --> 00:14:54,060
end up with a similarity score of 75

409
00:14:54,060 --> 00:14:55,620
percent

410
00:14:55,620 --> 00:14:58,740
now I I told you basically you don't

411
00:14:58,740 --> 00:15:01,019
want to match your function against your

412
00:15:01,019 --> 00:15:03,480
whole Corpus because um just for an

413
00:15:03,480 --> 00:15:05,279
example say you have a matter sample

414
00:15:05,279 --> 00:15:08,160
that contains 700 functions the database

415
00:15:08,160 --> 00:15:09,959
that I will later be using will be

416
00:15:09,959 --> 00:15:12,899
having seven million functions and you

417
00:15:12,899 --> 00:15:14,279
normally have to compare everything

418
00:15:14,279 --> 00:15:16,199
against everything else that it's

419
00:15:16,199 --> 00:15:18,240
already five billion comparisons so this

420
00:15:18,240 --> 00:15:20,100
completely explodes the larger your data

421
00:15:20,100 --> 00:15:22,500
is and this is where another technique

422
00:15:22,500 --> 00:15:24,839
of many hashing basically comes in which

423
00:15:24,839 --> 00:15:27,420
is a banding so this is basically the

424
00:15:27,420 --> 00:15:30,959
idea if you already have

425
00:15:30,959 --> 00:15:33,240
similar subsequences even in your Min

426
00:15:33,240 --> 00:15:35,100
hash we can use that for indexing as

427
00:15:35,100 --> 00:15:38,160
well because if those subsequents are

428
00:15:38,160 --> 00:15:40,500
the same it's more likely that the whole

429
00:15:40,500 --> 00:15:42,300
thing will be the same and this allows

430
00:15:42,300 --> 00:15:44,699
us to basically determine candidates for

431
00:15:44,699 --> 00:15:46,079
the function matching that we later on

432
00:15:46,079 --> 00:15:47,160
have to do

433
00:15:47,160 --> 00:15:48,920
so basically you spend some extra

434
00:15:48,920 --> 00:15:52,260
storage or memory in order to have very

435
00:15:52,260 --> 00:15:54,660
good candidate selection

436
00:15:54,660 --> 00:15:57,600
okay so there has been a lot of work

437
00:15:57,600 --> 00:16:00,060
going into deciding how those features

438
00:16:00,060 --> 00:16:01,980
would look like I'm not going to go into

439
00:16:01,980 --> 00:16:03,899
details here that's basically from my

440
00:16:03,899 --> 00:16:05,639
PhD thesis that has been published in

441
00:16:05,639 --> 00:16:08,279
the meantime one idea was basically just

442
00:16:08,279 --> 00:16:10,860
um to along those numerical features to

443
00:16:10,860 --> 00:16:12,839
find those that are not correlated to

444
00:16:12,839 --> 00:16:14,940
each other because if you think the

445
00:16:14,940 --> 00:16:17,040
number of basic blocks is probably very

446
00:16:17,040 --> 00:16:18,480
highly correlated with the number of

447
00:16:18,480 --> 00:16:21,000
edges that your function might have and

448
00:16:21,000 --> 00:16:23,699
and so on already nesting depth and the

449
00:16:23,699 --> 00:16:25,199
function complexity that different

450
00:16:25,199 --> 00:16:27,899
measures there are at least in the

451
00:16:27,899 --> 00:16:29,420
expresses

452
00:16:29,420 --> 00:16:32,339
expressive Nest not really valuable to

453
00:16:32,339 --> 00:16:34,380
use in parallel so we did some

454
00:16:34,380 --> 00:16:36,000
optimization here and ended up with the

455
00:16:36,000 --> 00:16:37,920
parameters that have all this just shown

456
00:16:37,920 --> 00:16:40,680
to you now how can you basically work

457
00:16:40,680 --> 00:16:42,899
with that and interact with the system

458
00:16:42,899 --> 00:16:45,720
so um you can like I said we have some

459
00:16:45,720 --> 00:16:47,459
indexing on basic block level on

460
00:16:47,459 --> 00:16:50,459
function level on whole sample level you

461
00:16:50,459 --> 00:16:52,860
could query with all of those elements

462
00:16:52,860 --> 00:16:54,660
basically let's let's take a function

463
00:16:54,660 --> 00:16:56,699
for example we have this function and

464
00:16:56,699 --> 00:16:58,920
now we have to ask the system which in

465
00:16:58,920 --> 00:17:01,440
turn will ask the database what's in our

466
00:17:01,440 --> 00:17:05,699
database mapedia for example but also

467
00:17:05,699 --> 00:17:07,919
some open source reference code so it

468
00:17:07,919 --> 00:17:09,780
could be the visual studio runtime

469
00:17:09,780 --> 00:17:11,579
because that's something that if you're

470
00:17:11,579 --> 00:17:13,799
using either for example you always want

471
00:17:13,799 --> 00:17:16,439
to be have sorted out and automatically

472
00:17:16,439 --> 00:17:19,140
letting adding labels there with its

473
00:17:19,140 --> 00:17:21,020
flow technology already

474
00:17:21,020 --> 00:17:24,059
similar things for for Gita for example

475
00:17:24,059 --> 00:17:26,099
but you might have custom libraries that

476
00:17:26,099 --> 00:17:27,780
you want to add in there as well and

477
00:17:27,780 --> 00:17:29,880
maybe also some new malware that you

478
00:17:29,880 --> 00:17:31,380
have not labeled yet and you want to

479
00:17:31,380 --> 00:17:33,660
figure out what it is or later on want

480
00:17:33,660 --> 00:17:36,480
to Cluster and if we query the system

481
00:17:36,480 --> 00:17:39,059
now with a single function the response

482
00:17:39,059 --> 00:17:41,340
will typically be something like this so

483
00:17:41,340 --> 00:17:42,780
it will tell you

484
00:17:42,780 --> 00:17:45,120
um after typically fractions of a second

485
00:17:45,120 --> 00:17:48,200
in which other malware samples

486
00:17:48,200 --> 00:17:51,000
this function was matched with a score

487
00:17:51,000 --> 00:17:54,299
of typically more than 50 or 65 percent

488
00:17:54,299 --> 00:17:55,559
and

489
00:17:55,559 --> 00:17:57,660
the interesting thing that you now can

490
00:17:57,660 --> 00:17:59,820
do is you can basically look at in how

491
00:17:59,820 --> 00:18:01,559
many different mava families have I

492
00:18:01,559 --> 00:18:03,780
found something like this this basically

493
00:18:03,780 --> 00:18:06,240
gives you an idea of the frequency how

494
00:18:06,240 --> 00:18:08,580
often this function exists across what

495
00:18:08,580 --> 00:18:11,640
we Define as mava families and this we

496
00:18:11,640 --> 00:18:14,160
can use for our advantage because it on

497
00:18:14,160 --> 00:18:15,900
the one hand allows us to introduce

498
00:18:15,900 --> 00:18:18,179
weights because functions that are rare

499
00:18:18,179 --> 00:18:20,039
are probably more interesting to us or

500
00:18:20,039 --> 00:18:21,600
give us a better indication that it's

501
00:18:21,600 --> 00:18:23,820
related to a certain level family or

502
00:18:23,820 --> 00:18:26,100
they might be even unique and those are

503
00:18:26,100 --> 00:18:27,960
then characteristic for a certain family

504
00:18:27,960 --> 00:18:30,000
so might be good for identification

505
00:18:30,000 --> 00:18:32,220
later on as well

506
00:18:32,220 --> 00:18:34,080
yeah and what we can do then is

507
00:18:34,080 --> 00:18:36,179
basically aggregate every function match

508
00:18:36,179 --> 00:18:39,240
on Sample level and then we end up with

509
00:18:39,240 --> 00:18:41,520
this type of scoring where we can use

510
00:18:41,520 --> 00:18:43,919
this frequency analysis so basically

511
00:18:43,919 --> 00:18:46,980
valuing those parts or matches that are

512
00:18:46,980 --> 00:18:49,980
less common higher to get higher

513
00:18:49,980 --> 00:18:52,500
frequency scores or even those unique

514
00:18:52,500 --> 00:18:54,240
scores which typically are already a

515
00:18:54,240 --> 00:18:56,340
very good indication at what mava family

516
00:18:56,340 --> 00:18:58,919
we might be looking at

517
00:18:58,919 --> 00:19:00,780
okay

518
00:19:00,780 --> 00:19:01,980
so

519
00:19:01,980 --> 00:19:03,900
as I said we are going to release that

520
00:19:03,900 --> 00:19:05,880
how is the device system basically built

521
00:19:05,880 --> 00:19:07,860
first off we need a database at the time

522
00:19:07,860 --> 00:19:10,440
we decided to this would be mongodb

523
00:19:10,440 --> 00:19:12,960
um the there's an interface for it so if

524
00:19:12,960 --> 00:19:15,299
you ever want to feel the need that it

525
00:19:15,299 --> 00:19:16,919
has to be some

526
00:19:16,919 --> 00:19:18,900
relational database you could possibly

527
00:19:18,900 --> 00:19:21,120
adapt that as well the core of the

528
00:19:21,120 --> 00:19:22,740
system really is This mcgrid Server

529
00:19:22,740 --> 00:19:24,419
which is your interaction interface it's

530
00:19:24,419 --> 00:19:27,120
basically an rest API server that

531
00:19:27,120 --> 00:19:29,640
provides you the capability of indexing

532
00:19:29,640 --> 00:19:31,380
um but also to generate matching jobs

533
00:19:31,380 --> 00:19:34,080
because um those typically take at least

534
00:19:34,080 --> 00:19:35,820
a couple seconds so they should be

535
00:19:35,820 --> 00:19:37,500
handled asynchronously

536
00:19:37,500 --> 00:19:38,940
um in the in the back side of the system

537
00:19:38,940 --> 00:19:41,700
using a queue and that's what those

538
00:19:41,700 --> 00:19:43,679
workers are for you can have multiple of

539
00:19:43,679 --> 00:19:46,020
them in parallel they're also using um

540
00:19:46,020 --> 00:19:49,500
all of your CPU cores if you want so and

541
00:19:49,500 --> 00:19:51,299
they basically this this whole back end

542
00:19:51,299 --> 00:19:53,760
is producing those results for you in

543
00:19:53,760 --> 00:19:55,440
order to interact with the system you've

544
00:19:55,440 --> 00:19:57,299
already seen some screenshots there's

545
00:19:57,299 --> 00:20:00,360
also a web UI which is also python based

546
00:20:00,360 --> 00:20:03,539
and flask and is talking to the rest API

547
00:20:03,539 --> 00:20:06,240
essentially and for this we also wrote a

548
00:20:06,240 --> 00:20:08,940
python client Library

549
00:20:08,940 --> 00:20:09,480
um

550
00:20:09,480 --> 00:20:11,880
that's you can use to also directly

551
00:20:11,880 --> 00:20:14,460
interact with the back-end server for

552
00:20:14,460 --> 00:20:17,340
good measure we also threw in a HTTP

553
00:20:17,340 --> 00:20:20,280
reverse proxy in there to basically just

554
00:20:20,280 --> 00:20:22,919
simplify if you want to host it with TLS

555
00:20:22,919 --> 00:20:26,160
or any other encryption enabled

556
00:20:26,160 --> 00:20:28,140
yeah so all of this is basically just a

557
00:20:28,140 --> 00:20:30,120
single Docker compose if you want to run

558
00:20:30,120 --> 00:20:32,100
this framework at home if you want to or

559
00:20:32,100 --> 00:20:34,020
at work it's basically just cloning the

560
00:20:34,020 --> 00:20:35,640
repo doing one Docker compost up and

561
00:20:35,640 --> 00:20:37,260
then it should be up and running

562
00:20:37,260 --> 00:20:39,000
at least for me that worked a couple of

563
00:20:39,000 --> 00:20:41,220
times and I've been trying to to do that

564
00:20:41,220 --> 00:20:42,539
now for half a year even with the

565
00:20:42,539 --> 00:20:44,700
updates and I managed to not break my

566
00:20:44,700 --> 00:20:47,400
system so I'm confident that this this

567
00:20:47,400 --> 00:20:48,660
is a good idea

568
00:20:48,660 --> 00:20:50,400
all right so how can you interact with

569
00:20:50,400 --> 00:20:52,380
that um first off this web interface

570
00:20:52,380 --> 00:20:54,419
obviously you can use the browser for

571
00:20:54,419 --> 00:20:55,620
that

572
00:20:55,620 --> 00:20:56,280
um

573
00:20:56,280 --> 00:20:58,320
there's mcgrid's client also has

574
00:20:58,320 --> 00:20:59,880
basically a command line interface that

575
00:20:59,880 --> 00:21:02,039
allows you to use some of the main

576
00:21:02,039 --> 00:21:04,080
features like throwing new samples into

577
00:21:04,080 --> 00:21:07,740
the database or exporting data importing

578
00:21:07,740 --> 00:21:09,900
data and those kind of things and

579
00:21:09,900 --> 00:21:12,480
Country I'm also developing an Ida

580
00:21:12,480 --> 00:21:14,340
plugin that basically whenever you look

581
00:21:14,340 --> 00:21:16,140
at a function tells you what are similar

582
00:21:16,140 --> 00:21:17,340
functions to the function that I'm

583
00:21:17,340 --> 00:21:19,080
currently looking at and do I have

584
00:21:19,080 --> 00:21:20,940
labels available for that

585
00:21:20,940 --> 00:21:23,580
and let's have a look at that basically

586
00:21:23,580 --> 00:21:26,039
in action so the second part of this

587
00:21:26,039 --> 00:21:28,020
presentation the smallest intended to be

588
00:21:28,020 --> 00:21:30,860
a live demo

589
00:21:31,380 --> 00:21:35,520
so the system itself looks like this and

590
00:21:35,520 --> 00:21:38,280
what's been shown there is basically if

591
00:21:38,280 --> 00:21:40,740
you load in data set like mypedia you

592
00:21:40,740 --> 00:21:43,340
essentially have all of your families

593
00:21:43,340 --> 00:21:46,679
listed as need entries here and then you

594
00:21:46,679 --> 00:21:48,600
can start basically from here even

595
00:21:48,600 --> 00:21:51,840
diving deeper into them you might have

596
00:21:51,840 --> 00:21:54,000
after samples photos those different

597
00:21:54,000 --> 00:21:57,240
families this on the next hand at some

598
00:21:57,240 --> 00:21:59,400
point takes you to function level

599
00:21:59,400 --> 00:22:01,260
uh let's have a function that's more

600
00:22:01,260 --> 00:22:04,799
interesting but it's not that small

601
00:22:04,799 --> 00:22:06,539
yeah like this one

602
00:22:06,539 --> 00:22:09,240
and it can also render the CFG for you

603
00:22:09,240 --> 00:22:11,400
so you basically have a little bit of

604
00:22:11,400 --> 00:22:13,679
assembly exploration directly in your

605
00:22:13,679 --> 00:22:15,780
browser looking at the function and

606
00:22:15,780 --> 00:22:18,059
what's also almost possible in real time

607
00:22:18,059 --> 00:22:20,100
is that it tells you which of the basic

608
00:22:20,100 --> 00:22:23,000
blocks is found in how many other

609
00:22:23,000 --> 00:22:25,440
families in that part so here we for

610
00:22:25,440 --> 00:22:27,480
example have 18 families to me that

611
00:22:27,480 --> 00:22:28,799
would be likely an indication that it's

612
00:22:28,799 --> 00:22:30,539
not rare code it's probably coming from

613
00:22:30,539 --> 00:22:34,679
some library or from other open source

614
00:22:34,679 --> 00:22:36,240
that was just compiled into this mava

615
00:22:36,240 --> 00:22:38,720
sample for example the second part

616
00:22:38,720 --> 00:22:41,700
essentially is we want to do queries for

617
00:22:41,700 --> 00:22:44,760
anything against anything else so I've

618
00:22:44,760 --> 00:22:47,100
prepared an example for that you might

619
00:22:47,100 --> 00:22:51,179
have heard that the Conti group lost

620
00:22:51,179 --> 00:22:54,000
their source code last year let's put it

621
00:22:54,000 --> 00:22:56,400
that way and that enabled other people

622
00:22:56,400 --> 00:22:57,730
to basically reuse

623
00:22:57,730 --> 00:22:58,080
[Music]

624
00:22:58,080 --> 00:22:59,220
um

625
00:22:59,220 --> 00:23:02,460
this source code say what I wanted to do

626
00:23:02,460 --> 00:23:05,220
say exactly about that

627
00:23:05,220 --> 00:23:07,320
um yeah so there was news about it

628
00:23:07,320 --> 00:23:09,419
basically that stated that the logic

629
00:23:09,419 --> 00:23:12,179
bits group started to generate a new

630
00:23:12,179 --> 00:23:13,679
variant that is reusing basically the

631
00:23:13,679 --> 00:23:16,559
quantity source code and I was

632
00:23:16,559 --> 00:23:18,539
interested in can the system basically

633
00:23:18,539 --> 00:23:20,280
tell you that it's reuse of the quantity

634
00:23:20,280 --> 00:23:22,679
source code how similar is it do we even

635
00:23:22,679 --> 00:23:24,900
maybe find some more stuff so I took the

636
00:23:24,900 --> 00:23:27,179
sample level reference there at the time

637
00:23:27,179 --> 00:23:29,280
the database had run about 6 000

638
00:23:29,280 --> 00:23:30,960
unpacked member samples for 1400

639
00:23:30,960 --> 00:23:32,820
families seven million functions like I

640
00:23:32,820 --> 00:23:35,460
said and the disassembly plus matching

641
00:23:35,460 --> 00:23:38,039
typically takes around 30-ish seconds so

642
00:23:38,039 --> 00:23:40,320
that's 700 functions in that case

643
00:23:40,320 --> 00:23:43,799
and with the results we can now see

644
00:23:43,799 --> 00:23:46,020
that there's three families matching so

645
00:23:46,020 --> 00:23:47,340
it's not just County but two more

646
00:23:47,340 --> 00:23:51,379
families anyone has an idea why

647
00:23:51,960 --> 00:23:54,299
well there have been copycats before so

648
00:23:54,299 --> 00:23:55,919
um both of the other ones also basically

649
00:23:55,919 --> 00:23:58,200
recycle the source code even before that

650
00:23:58,200 --> 00:23:59,880
and

651
00:23:59,880 --> 00:24:01,380
um that's that's why we get multiple

652
00:24:01,380 --> 00:24:02,880
hits here

653
00:24:02,880 --> 00:24:07,260
um I've also generated this graphical

654
00:24:07,260 --> 00:24:09,659
representation

655
00:24:09,659 --> 00:24:11,460
um if you're using or have been using

656
00:24:11,460 --> 00:24:12,780
either a lot you you might know that

657
00:24:12,780 --> 00:24:14,640
there's this blue bar typically at the

658
00:24:14,640 --> 00:24:17,820
top right I'm very let's say not very

659
00:24:17,820 --> 00:24:19,559
but a bit unhappy that it's just one

660
00:24:19,559 --> 00:24:21,000
dimension and I thought you can possibly

661
00:24:21,000 --> 00:24:24,299
do something cooler with that and this

662
00:24:24,299 --> 00:24:27,000
is at least in the same spirit and each

663
00:24:27,000 --> 00:24:28,320
of the bars that you can see here

664
00:24:28,320 --> 00:24:30,179
divided by the Black Blocks is one of

665
00:24:30,179 --> 00:24:32,280
the functions so you at least get an

666
00:24:32,280 --> 00:24:33,900
idea of how large the function is as

667
00:24:33,900 --> 00:24:37,080
well and the coloring basically acts

668
00:24:37,080 --> 00:24:39,780
like a heat map the blue colors are

669
00:24:39,780 --> 00:24:42,600
basically uh the dark Blues For example

670
00:24:42,600 --> 00:24:44,159
it was only matched to one other family

671
00:24:44,159 --> 00:24:46,260
light blue is two or three families

672
00:24:46,260 --> 00:24:48,360
green is more common red is already very

673
00:24:48,360 --> 00:24:50,340
common and if you see something purple

674
00:24:50,340 --> 00:24:52,400
like this this is likely matched in 64

675
00:24:52,400 --> 00:24:54,840
128 different families and it's super

676
00:24:54,840 --> 00:24:57,480
common so um just by looking at the

677
00:24:57,480 --> 00:24:59,820
structure of a binary like this you get

678
00:24:59,820 --> 00:25:01,200
a better idea probably What's Happening

679
00:25:01,200 --> 00:25:03,120
Here in the end so if if there's

680
00:25:03,120 --> 00:25:04,860
suddenly a block of very common code

681
00:25:04,860 --> 00:25:06,840
that means okay that's likely library

682
00:25:06,840 --> 00:25:08,700
and I probably never want to look at

683
00:25:08,700 --> 00:25:11,460
that code because it's not unique or

684
00:25:11,460 --> 00:25:13,260
interesting to my investigation

685
00:25:13,260 --> 00:25:15,600
and the second row basically tells you

686
00:25:15,600 --> 00:25:18,320
that as well in my demo database I have

687
00:25:18,320 --> 00:25:21,000
versions of all visual C runtime

688
00:25:21,000 --> 00:25:23,039
pre-compiled in all different flags that

689
00:25:23,039 --> 00:25:25,620
are possible and those functions are

690
00:25:25,620 --> 00:25:28,200
basically immediately recognized as well

691
00:25:28,200 --> 00:25:31,320
and finally the last row so all of them

692
00:25:31,320 --> 00:25:32,520
basically have the same structure as you

693
00:25:32,520 --> 00:25:33,960
can also see it tells you what's the

694
00:25:33,960 --> 00:25:36,059
best foreign match that we have found

695
00:25:36,059 --> 00:25:39,179
for a particular function in here

696
00:25:39,179 --> 00:25:40,500
and

697
00:25:40,500 --> 00:25:42,659
if we're looking in where we have

698
00:25:42,659 --> 00:25:44,039
matched something you can basically

699
00:25:44,039 --> 00:25:45,659
attend that point get down to the

700
00:25:45,659 --> 00:25:47,820
function level we have a look for

701
00:25:47,820 --> 00:25:50,400
example at this 75 functions we can see

702
00:25:50,400 --> 00:25:52,980
that both conti and Mio which is one of

703
00:25:52,980 --> 00:25:56,880
those copycats have been matched

704
00:25:56,880 --> 00:25:59,340
and what we can also do is basically

705
00:25:59,340 --> 00:26:01,260
play a bit

706
00:26:01,260 --> 00:26:03,419
in the browser and then get this

707
00:26:03,419 --> 00:26:05,880
similarity view for this the two

708
00:26:05,880 --> 00:26:07,620
functions that we have seen here with

709
00:26:07,620 --> 00:26:09,240
the coloring blue meaning and there's an

710
00:26:09,240 --> 00:26:10,500
exact match

711
00:26:10,500 --> 00:26:12,419
um so even the byte sequence is exactly

712
00:26:12,419 --> 00:26:14,340
the same green meaning at least the

713
00:26:14,340 --> 00:26:16,620
instruction sequences are the same and

714
00:26:16,620 --> 00:26:18,539
red meaning okay that's uh changes too

715
00:26:18,539 --> 00:26:20,700
much that I could find a simple match in

716
00:26:20,700 --> 00:26:21,900
the in the other function representation

717
00:26:21,900 --> 00:26:24,179
that I have here and that at least gives

718
00:26:24,179 --> 00:26:27,360
you also potentially an idea which

719
00:26:27,360 --> 00:26:29,340
functions you want to look at or where

720
00:26:29,340 --> 00:26:31,020
in a function you you want to look at

721
00:26:31,020 --> 00:26:33,779
and later on I'm at least looking that I

722
00:26:33,779 --> 00:26:36,120
also can basically re-implement this

723
00:26:36,120 --> 00:26:37,860
type of visualization directly in either

724
00:26:37,860 --> 00:26:39,960
so you don't have to jump in between the

725
00:26:39,960 --> 00:26:42,659
web framework and the other thing

726
00:26:42,659 --> 00:26:46,980
so what is this usable for well um

727
00:26:46,980 --> 00:26:49,799
I guess one idea would be if you have a

728
00:26:49,799 --> 00:26:51,419
mirror that you don't know which family

729
00:26:51,419 --> 00:26:53,460
it might be your rules have not

730
00:26:53,460 --> 00:26:55,320
triggered on it or whatever you could

731
00:26:55,320 --> 00:26:57,360
just query the system with it to get to

732
00:26:57,360 --> 00:27:00,179
close best possible match for it in

733
00:27:00,179 --> 00:27:01,559
order to get an idea of what it might be

734
00:27:01,559 --> 00:27:03,659
so map identification is certainly one

735
00:27:03,659 --> 00:27:07,140
use case and a library

736
00:27:07,140 --> 00:27:10,559
usage detection as well

737
00:27:10,559 --> 00:27:12,480
so that's what I've shown you so

738
00:27:12,480 --> 00:27:14,400
basically it means the same we typically

739
00:27:14,400 --> 00:27:16,679
see in the

740
00:27:16,679 --> 00:27:18,960
upper address part of binaries we will

741
00:27:18,960 --> 00:27:21,000
typically see those libraries the the

742
00:27:21,000 --> 00:27:23,159
front part in many times contains the

743
00:27:23,159 --> 00:27:24,600
intrinsic code for the for the family

744
00:27:24,600 --> 00:27:27,659
that we really want to look at and can

745
00:27:27,659 --> 00:27:29,820
also look at the functions itself now

746
00:27:29,820 --> 00:27:32,340
since we already have all of the code

747
00:27:32,340 --> 00:27:34,559
indexed what else can we do with that in

748
00:27:34,559 --> 00:27:37,559
2019 together with Felix we presented on

749
00:27:37,559 --> 00:27:39,419
Yara signator which was basically an

750
00:27:39,419 --> 00:27:41,520
approach to automatically generate Yara

751
00:27:41,520 --> 00:27:43,799
rules but that was based on instruction

752
00:27:43,799 --> 00:27:45,659
engrams so we basically also use the

753
00:27:45,659 --> 00:27:47,460
disassembly but disregarded the

754
00:27:47,460 --> 00:27:49,620
structure and the approach basically is

755
00:27:49,620 --> 00:27:51,480
if I have all of this index and

756
00:27:51,480 --> 00:27:53,340
available I can look at which

757
00:27:53,340 --> 00:27:55,140
instruction sequences are only happening

758
00:27:55,140 --> 00:27:58,080
in certain families and it's probably a

759
00:27:58,080 --> 00:27:59,460
good idea to use these parts to

760
00:27:59,460 --> 00:28:01,500
automatically generate Garrow rules so

761
00:28:01,500 --> 00:28:03,419
that's what we've been using and doing

762
00:28:03,419 --> 00:28:05,880
there and we can do the same basically

763
00:28:05,880 --> 00:28:08,760
with this framework now as well take for

764
00:28:08,760 --> 00:28:11,460
example family Ram course that we also

765
00:28:11,460 --> 00:28:14,100
heard about yesterday I think what we

766
00:28:14,100 --> 00:28:15,659
now can do is basically generate this

767
00:28:15,659 --> 00:28:17,520
unique block report so we this gives us

768
00:28:17,520 --> 00:28:19,500
all of the basic blocks that are only

769
00:28:19,500 --> 00:28:22,320
found across all of our ram car samples

770
00:28:22,320 --> 00:28:25,080
and none of the other mobile samples

771
00:28:25,080 --> 00:28:27,600
there's also statistic basically which

772
00:28:27,600 --> 00:28:29,820
of the samples contains most of the

773
00:28:29,820 --> 00:28:32,039
Unicode so sometimes happens that you

774
00:28:32,039 --> 00:28:34,320
are looking at a mava family you mostly

775
00:28:34,320 --> 00:28:35,880
have those regular release builds and

776
00:28:35,880 --> 00:28:38,340
suddenly there's a debug build and this

777
00:28:38,340 --> 00:28:39,779
might stand out because it's having more

778
00:28:39,779 --> 00:28:41,400
unique blocks compared to the other ones

779
00:28:41,400 --> 00:28:44,340
for example and ultimately what this

780
00:28:44,340 --> 00:28:46,620
feature also gives you is the CR World

781
00:28:46,620 --> 00:28:49,080
Generation and for that it uses all of

782
00:28:49,080 --> 00:28:52,320
the uniquely identified blocks for the

783
00:28:52,320 --> 00:28:53,940
family that you're looking at

784
00:28:53,940 --> 00:28:57,539
so what it does here is basically it

785
00:28:57,539 --> 00:28:59,400
looks at in how many different samples

786
00:28:59,400 --> 00:29:02,220
have I found this certain basic block

787
00:29:02,220 --> 00:29:04,799
here and it also pre-renderize it in the

788
00:29:04,799 --> 00:29:06,960
escaped representation that you could

789
00:29:06,960 --> 00:29:11,100
use in Yara and basically a reference to

790
00:29:11,100 --> 00:29:13,679
your presentation Dominica and basically

791
00:29:13,679 --> 00:29:17,100
I've aimed for favoring those sections

792
00:29:17,100 --> 00:29:18,840
that at least we'll have one four bytes

793
00:29:18,840 --> 00:29:22,020
atom in the end that's not zero

794
00:29:22,020 --> 00:29:24,720
yeah and ultimately this the scoring

795
00:29:24,720 --> 00:29:26,940
allows us to do a little approximation

796
00:29:26,940 --> 00:29:28,679
for the multi-cover multi set

797
00:29:28,679 --> 00:29:30,899
multi-cover problem and minimize the

798
00:29:30,899 --> 00:29:33,419
number of basic blocks we need to select

799
00:29:33,419 --> 00:29:35,460
in order to basically cover every sample

800
00:29:35,460 --> 00:29:37,620
I think in this way it's um with seven

801
00:29:37,620 --> 00:29:40,919
no ten different basic blocks so all of

802
00:29:40,919 --> 00:29:43,500
ram costs can be covered with 20 blocks

803
00:29:43,500 --> 00:29:46,980
and the reason for that is 20s

804
00:29:46,980 --> 00:29:49,740
2 times 10 right okay there's another

805
00:29:49,740 --> 00:29:52,200
view for example if you look at Ram

806
00:29:52,200 --> 00:29:54,120
Cross or the ramcast representation in

807
00:29:54,120 --> 00:29:56,640
my PDR you'd see that two big clusters

808
00:29:56,640 --> 00:29:58,860
so um Ram cross I guess had a rewrite

809
00:29:58,860 --> 00:30:01,740
when they entered version number three

810
00:30:01,740 --> 00:30:03,600
this is uh this this clustering block

811
00:30:03,600 --> 00:30:05,700
down here and all of the other versions

812
00:30:05,700 --> 00:30:08,159
before and this is why we need to select

813
00:30:08,159 --> 00:30:09,960
more code in order to cover the newer

814
00:30:09,960 --> 00:30:12,480
Ram plus versions along the the older

815
00:30:12,480 --> 00:30:14,820
versions basically yes now I'm already

816
00:30:14,820 --> 00:30:18,120
showing you the next feature basically

817
00:30:18,120 --> 00:30:21,240
which is a cross compare across

818
00:30:21,240 --> 00:30:22,740
a range of samples that you have

819
00:30:22,740 --> 00:30:24,600
pre-selected and this matching Matrix

820
00:30:24,600 --> 00:30:27,840
again this time red means less matched

821
00:30:27,840 --> 00:30:30,419
blue means more matched also gives you

822
00:30:30,419 --> 00:30:32,100
an idea where there were higher

823
00:30:32,100 --> 00:30:34,200
development jumps in the evolution of a

824
00:30:34,200 --> 00:30:36,360
certain FF family so maybe there have

825
00:30:36,360 --> 00:30:38,159
any features introduced there was

826
00:30:38,159 --> 00:30:40,140
refactoring and this this might give you

827
00:30:40,140 --> 00:30:42,539
a decent idea which path of Mavis

828
00:30:42,539 --> 00:30:44,220
samples in this undefined blob that you

829
00:30:44,220 --> 00:30:46,200
would otherwise our collection that you

830
00:30:46,200 --> 00:30:48,419
might have there want to look at in more

831
00:30:48,419 --> 00:30:51,059
specific ways yeah that's once again

832
00:30:51,059 --> 00:30:53,520
navigatable so you can click them and

833
00:30:53,520 --> 00:30:56,039
then basically get the same result for a

834
00:30:56,039 --> 00:30:58,679
one-to-one match that's based on the one

835
00:30:58,679 --> 00:31:00,360
against everything that we already had

836
00:31:00,360 --> 00:31:01,919
before

837
00:31:01,919 --> 00:31:04,620
okay so we had this

838
00:31:04,620 --> 00:31:06,720
now finally

839
00:31:06,720 --> 00:31:08,460
um any motivation I was talking about

840
00:31:08,460 --> 00:31:10,919
Wanna Cry so I wanted to see can I

841
00:31:10,919 --> 00:31:12,840
reproduce basically the findings that I

842
00:31:12,840 --> 00:31:15,059
had and presented in the street so

843
00:31:15,059 --> 00:31:17,399
coming back to this and

844
00:31:17,399 --> 00:31:20,340
um well the idea here is what we want to

845
00:31:20,340 --> 00:31:22,200
do is identify functions that are used

846
00:31:22,200 --> 00:31:24,779
in few other functions so

847
00:31:24,779 --> 00:31:26,460
at least they have to be used in other

848
00:31:26,460 --> 00:31:27,899
functions and we can go back to this

849
00:31:27,899 --> 00:31:29,940
diagram that I've already showed so this

850
00:31:29,940 --> 00:31:32,039
is for this specific one acry sample

851
00:31:32,039 --> 00:31:34,260
that has been referenced in this tweet

852
00:31:34,260 --> 00:31:37,140
and if we look closer and especially

853
00:31:37,140 --> 00:31:38,700
look closer at the different matches

854
00:31:38,700 --> 00:31:40,980
that we have here we suddenly realized

855
00:31:40,980 --> 00:31:42,720
that there are matches to more families

856
00:31:42,720 --> 00:31:45,600
than just counterpy um and those of you

857
00:31:45,600 --> 00:31:47,580
that are familiar with the specific

858
00:31:47,580 --> 00:31:49,380
threat actor here you will recognize

859
00:31:49,380 --> 00:31:50,940
probably some of the other names as well

860
00:31:50,940 --> 00:31:54,960
so Romeos is a short handle for the

861
00:31:54,960 --> 00:31:58,320
Romeo Sarah Sierra part so some of those

862
00:31:58,320 --> 00:32:00,659
samples that had been already detailed

863
00:32:00,659 --> 00:32:03,600
in the novetta report for example Jonah

864
00:32:03,600 --> 00:32:07,320
is another family that's specific to

865
00:32:07,320 --> 00:32:09,539
this threat actor as far as I know and

866
00:32:09,539 --> 00:32:11,039
this part is really interesting because

867
00:32:11,039 --> 00:32:15,120
it's using an as implementation that's

868
00:32:15,120 --> 00:32:17,159
at least according to the system only

869
00:32:17,159 --> 00:32:18,840
found in in those two families as well

870
00:32:18,840 --> 00:32:20,880
so let's even if there's

871
00:32:20,880 --> 00:32:23,960
code reuse that might have been public

872
00:32:23,960 --> 00:32:26,760
it might be specific because only this

873
00:32:26,760 --> 00:32:28,919
actor is using it and you cannot find it

874
00:32:28,919 --> 00:32:30,539
in other Marvel families so that's still

875
00:32:30,539 --> 00:32:33,840
probably a good hint here

876
00:32:33,840 --> 00:32:36,419
yes and with that basically it gives you

877
00:32:36,419 --> 00:32:38,880
some capability to do lead generation

878
00:32:38,880 --> 00:32:40,799
I'd say because you can filter the

879
00:32:40,799 --> 00:32:43,380
amount of families that you want to look

880
00:32:43,380 --> 00:32:45,120
at or different

881
00:32:45,120 --> 00:32:48,059
hits for families that you want to look

882
00:32:48,059 --> 00:32:49,559
at so those functions that have only

883
00:32:49,559 --> 00:32:52,500
matched few other families and then

884
00:32:52,500 --> 00:32:53,940
basically you can go over them and then

885
00:32:53,940 --> 00:32:55,740
decide that's the human part in here

886
00:32:55,740 --> 00:32:57,240
because that's not what the system does

887
00:32:57,240 --> 00:32:59,100
for you you still have to decide is this

888
00:32:59,100 --> 00:33:00,480
function characteristic is its

889
00:33:00,480 --> 00:33:03,059
functionality characteristic

890
00:33:03,059 --> 00:33:06,059
and that's a sense basically select

891
00:33:06,059 --> 00:33:08,039
What's

892
00:33:08,039 --> 00:33:09,720
um

893
00:33:09,720 --> 00:33:13,019
proof in binary you want to base any of

894
00:33:13,019 --> 00:33:14,820
your conclusions on let's put it that

895
00:33:14,820 --> 00:33:15,480
way

896
00:33:15,480 --> 00:33:17,460
yeah so this is the function that I

897
00:33:17,460 --> 00:33:19,200
initially showed um

898
00:33:19,200 --> 00:33:20,940
from the Idaho screenshot which is from

899
00:33:20,940 --> 00:33:23,640
one of crying Contra p and as you can

900
00:33:23,640 --> 00:33:25,799
see here this is also a lot of literal

901
00:33:25,799 --> 00:33:27,899
code reuse which is what the blue is

902
00:33:27,899 --> 00:33:30,179
indicating and all of those blocks

903
00:33:30,179 --> 00:33:32,279
indeed are only found into those two

904
00:33:32,279 --> 00:33:34,980
families still today so um

905
00:33:34,980 --> 00:33:36,659
at least if you are looking at sequences

906
00:33:36,659 --> 00:33:38,580
of a couple instructions they quickly

907
00:33:38,580 --> 00:33:40,679
become somewhat unique or unique enough

908
00:33:40,679 --> 00:33:43,080
that you can basically say it's likely

909
00:33:43,080 --> 00:33:45,000
reuse that's based on the same source

910
00:33:45,000 --> 00:33:46,440
code

911
00:33:46,440 --> 00:33:48,419
so the last aspect that I want to talk

912
00:33:48,419 --> 00:33:50,880
about is um there have been many

913
00:33:50,880 --> 00:33:53,159
projects I basically aimed for label

914
00:33:53,159 --> 00:33:55,980
transfer so um what's really helpful for

915
00:33:55,980 --> 00:33:58,019
an analysis is if I have an idea I'm

916
00:33:58,019 --> 00:33:59,220
looking at a function and it has been

917
00:33:59,220 --> 00:34:00,480
analyzed before I don't want to

918
00:34:00,480 --> 00:34:02,100
re-analyze it obviously because I'm

919
00:34:02,100 --> 00:34:04,500
spending my effort twice so if I get an

920
00:34:04,500 --> 00:34:06,240
idea of how this function was named in

921
00:34:06,240 --> 00:34:08,460
the past that's probably really valuable

922
00:34:08,460 --> 00:34:13,080
to me this is a very complex problem if

923
00:34:13,080 --> 00:34:14,040
you

924
00:34:14,040 --> 00:34:16,080
think about it for a longer time that's

925
00:34:16,080 --> 00:34:17,699
probably the reason why there are so

926
00:34:17,699 --> 00:34:19,440
many projects that try to solve that

927
00:34:19,440 --> 00:34:21,899
from different angles and that's

928
00:34:21,899 --> 00:34:24,000
absolutely not very I want to go I want

929
00:34:24,000 --> 00:34:25,379
to keep it simple

930
00:34:25,379 --> 00:34:28,859
so my ideas at least if you have renamed

931
00:34:28,859 --> 00:34:31,320
stuff in your idb or probably there will

932
00:34:31,320 --> 00:34:33,899
be in a gitre integration at some point

933
00:34:33,899 --> 00:34:36,359
maybe as well you can simply upload that

934
00:34:36,359 --> 00:34:38,159
for your specific sample that's already

935
00:34:38,159 --> 00:34:40,020
in encrypt so you basically just have

936
00:34:40,020 --> 00:34:42,359
another tag it was called like that and

937
00:34:42,359 --> 00:34:44,639
later on due to code similarity analysis

938
00:34:44,639 --> 00:34:46,859
it might show up simply that this is a

939
00:34:46,859 --> 00:34:48,179
label that has been given to a similar

940
00:34:48,179 --> 00:34:50,119
function before

941
00:34:50,119 --> 00:34:52,739
idbs are not openly or widely shared so

942
00:34:52,739 --> 00:34:54,480
it's not an issue that there will be too

943
00:34:54,480 --> 00:34:57,359
much data to Index this way but we will

944
00:34:57,359 --> 00:34:59,400
try to also provide some reference data

945
00:34:59,400 --> 00:35:00,720
at these four for libraries like open

946
00:35:00,720 --> 00:35:02,760
SSR zlib and many of the other things

947
00:35:02,760 --> 00:35:05,040
that you at least sometimes will find in

948
00:35:05,040 --> 00:35:08,160
Navaira as well but at least I've been

949
00:35:08,160 --> 00:35:10,440
at least one of our teams that's doing a

950
00:35:10,440 --> 00:35:12,540
bit reversing I think was interested to

951
00:35:12,540 --> 00:35:14,520
have a functionality like this so we try

952
00:35:14,520 --> 00:35:17,040
to to at least do that in this way as

953
00:35:17,040 --> 00:35:17,760
well

954
00:35:17,760 --> 00:35:20,040
all right that's almost everything

955
00:35:20,040 --> 00:35:21,300
already

956
00:35:21,300 --> 00:35:23,400
um there are still certainly some

957
00:35:23,400 --> 00:35:25,079
limitations for this for them I've been

958
00:35:25,079 --> 00:35:28,020
showing here um this is really just a

959
00:35:28,020 --> 00:35:29,579
first version that we are releasing so

960
00:35:29,579 --> 00:35:31,560
everything that I've shown you

961
00:35:31,560 --> 00:35:34,380
um is fully functional at least from my

962
00:35:34,380 --> 00:35:37,020
perspective but we are not web designers

963
00:35:37,020 --> 00:35:38,400
we have front-end designers or whatever

964
00:35:38,400 --> 00:35:40,020
it certainly needs some usability

965
00:35:40,020 --> 00:35:42,000
improvements so what I really for

966
00:35:42,000 --> 00:35:44,339
example would like to have for this

967
00:35:44,339 --> 00:35:46,440
visual visualization here is uh that you

968
00:35:46,440 --> 00:35:48,480
would be able to click those

969
00:35:48,480 --> 00:35:50,400
because then you are directly at the

970
00:35:50,400 --> 00:35:52,920
potentially interesting function right

971
00:35:52,920 --> 00:35:55,520
now it's just a PNG it could be an SVG

972
00:35:55,520 --> 00:35:58,680
but yeah we first have to learn how to

973
00:35:58,680 --> 00:36:01,920
craft svgs from JavaScript I guess we'll

974
00:36:01,920 --> 00:36:04,079
see yeah but there will be more

975
00:36:04,079 --> 00:36:06,300
usability improvements in future

976
00:36:06,300 --> 00:36:08,760
um and I hope that I also have

977
00:36:08,760 --> 00:36:11,579
interested one or two of you to

978
00:36:11,579 --> 00:36:13,260
potentially want to use that so you can

979
00:36:13,260 --> 00:36:15,839
provide feedback to me as well another

980
00:36:15,839 --> 00:36:17,339
thing that I want to address and want to

981
00:36:17,339 --> 00:36:20,880
solve in the future is data exchange so

982
00:36:20,880 --> 00:36:23,040
um obviously I can make the

983
00:36:23,040 --> 00:36:25,500
core data set of my video available to

984
00:36:25,500 --> 00:36:26,820
all of you but that means that all of

985
00:36:26,820 --> 00:36:28,619
you have to index it again and I don't

986
00:36:28,619 --> 00:36:31,140
want us to spend so many cycles doing

987
00:36:31,140 --> 00:36:34,020
the same stuff so we are looking at or

988
00:36:34,020 --> 00:36:35,820
thinking about ways to display

989
00:36:35,820 --> 00:36:37,920
distribute pre-processed data that's

990
00:36:37,920 --> 00:36:41,099
more efficient to reuse so not so much

991
00:36:41,099 --> 00:36:43,800
energy is burned this way for

992
00:36:43,800 --> 00:36:45,480
architecture support as I mentioned

993
00:36:45,480 --> 00:36:48,740
right now it's only Intel 32 and 64 bits

994
00:36:48,740 --> 00:36:51,180
my colleague is already looking at

995
00:36:51,180 --> 00:36:54,180
implementing it with.net as well

996
00:36:54,180 --> 00:36:57,540
and I this had one or two people also

997
00:36:57,540 --> 00:36:59,040
ask for arm so maybe this will be coming

998
00:36:59,040 --> 00:37:00,599
at some point as well

999
00:37:00,599 --> 00:37:03,599
yeah and another thing that I was just I

1000
00:37:03,599 --> 00:37:05,640
think two days thinking about right now

1001
00:37:05,640 --> 00:37:07,440
we are only indexing using pcash and

1002
00:37:07,440 --> 00:37:09,780
minhesh but it might make sense to

1003
00:37:09,780 --> 00:37:11,640
provide additional indexing for other

1004
00:37:11,640 --> 00:37:14,099
aspects of the code so which the eyes

1005
00:37:14,099 --> 00:37:15,720
are used which strings are used in the

1006
00:37:15,720 --> 00:37:19,380
functions and lots of PNF metadata we

1007
00:37:19,380 --> 00:37:22,380
heard about the impact or Rich header

1008
00:37:22,380 --> 00:37:24,420
before so making that available and

1009
00:37:24,420 --> 00:37:26,339
searchable in there as well sounds like

1010
00:37:26,339 --> 00:37:27,660
a good idea

1011
00:37:27,660 --> 00:37:28,800
okay

1012
00:37:28,800 --> 00:37:31,140
with that I want to summarize so what

1013
00:37:31,140 --> 00:37:33,480
I've been presenting to you is mcreit

1014
00:37:33,480 --> 00:37:35,220
which is short for the miniature based

1015
00:37:35,220 --> 00:37:36,780
code relationship and investigation

1016
00:37:36,780 --> 00:37:39,900
toolkit the idea here was it's a

1017
00:37:39,900 --> 00:37:41,760
framework for this quasi-identical

1018
00:37:41,760 --> 00:37:43,859
matching and for the one-to-many code

1019
00:37:43,859 --> 00:37:47,400
matching in a somewhat efficient way for

1020
00:37:47,400 --> 00:37:48,359
me

1021
00:37:48,359 --> 00:37:50,940
it's I guess it's definitely scalable to

1022
00:37:50,940 --> 00:37:52,740
tens of thousands of boundaries but not

1023
00:37:52,740 --> 00:37:54,300
the corporated

1024
00:37:54,300 --> 00:37:55,800
um you you might be having but then

1025
00:37:55,800 --> 00:37:57,420
again you still want to have those

1026
00:37:57,420 --> 00:37:59,220
labels and you probably don't have them

1027
00:37:59,220 --> 00:38:01,260
for all of your samples anyway

1028
00:38:01,260 --> 00:38:03,240
there will be a paper on that as well

1029
00:38:03,240 --> 00:38:05,520
that's um basically describing the use

1030
00:38:05,520 --> 00:38:08,220
cases that I've been going over and

1031
00:38:08,220 --> 00:38:10,740
um for me at least that's the four main

1032
00:38:10,740 --> 00:38:13,020
use cases that I see for using it like

1033
00:38:13,020 --> 00:38:14,339
this code and notification and Library

1034
00:38:14,339 --> 00:38:17,280
filtering hunting label transfer

1035
00:38:17,280 --> 00:38:19,200
um but maybe if you start using it you

1036
00:38:19,200 --> 00:38:21,300
might come up with no idea and can

1037
00:38:21,300 --> 00:38:23,220
provide us with feedback yes all of this

1038
00:38:23,220 --> 00:38:25,200
is already fully open sourced it's

1039
00:38:25,200 --> 00:38:27,780
available on GitHub and one more thing

1040
00:38:27,780 --> 00:38:29,760
if you want to play with the

1041
00:38:29,760 --> 00:38:32,040
instance that I've been using here in

1042
00:38:32,040 --> 00:38:34,560
the demo I have about

1043
00:38:34,560 --> 00:38:37,640
30 of those tokens

1044
00:38:37,640 --> 00:38:40,200
because I cannot host that for all of

1045
00:38:40,200 --> 00:38:42,420
you that's a computationally too

1046
00:38:42,420 --> 00:38:45,180
expensive my PBS find that's a static

1047
00:38:45,180 --> 00:38:46,859
website but this thing actually does

1048
00:38:46,859 --> 00:38:48,839
Cycles

1049
00:38:48,839 --> 00:38:50,880
um but for at least for for simple

1050
00:38:50,880 --> 00:38:53,099
trials and stuff it's fine so come see

1051
00:38:53,099 --> 00:38:55,020
me after the presentations if you if you

1052
00:38:55,020 --> 00:38:56,880
want to play it's a limited account you

1053
00:38:56,880 --> 00:38:59,160
can only upload the samples up to one

1054
00:38:59,160 --> 00:39:02,400
megabyte I think uh but it works

1055
00:39:02,400 --> 00:39:04,740
okay and with that

1056
00:39:04,740 --> 00:39:06,180
thank you very much for your attention

1057
00:39:06,180 --> 00:39:14,649
[Applause]

1058
00:39:16,680 --> 00:39:18,780
okay

1059
00:39:18,780 --> 00:39:21,920
any questions

1060
00:39:28,260 --> 00:39:30,119
thank you for the talk and it's really

1061
00:39:30,119 --> 00:39:32,760
great to to have this open source

1062
00:39:32,760 --> 00:39:34,859
framework released

1063
00:39:34,859 --> 00:39:37,920
um any insight about the hardware

1064
00:39:37,920 --> 00:39:42,420
requirements to yeah so uh

1065
00:39:42,420 --> 00:39:46,140
this here is running on four cores and I

1066
00:39:46,140 --> 00:39:48,359
think 16 gigabytes so it's even likely

1067
00:39:48,359 --> 00:39:49,740
to run the whole map PDF thing on a

1068
00:39:49,740 --> 00:39:51,000
laptop

1069
00:39:51,000 --> 00:39:52,260
so

1070
00:39:52,260 --> 00:39:54,540
um I guess if you want to throw a lot of

1071
00:39:54,540 --> 00:39:56,099
stuff at it you have to have more

1072
00:39:56,099 --> 00:39:58,680
Hardware I think it's more CPU it gets

1073
00:39:58,680 --> 00:39:59,579
you

1074
00:39:59,579 --> 00:40:02,400
further than Ram even

1075
00:40:02,400 --> 00:40:04,680
so I think the because the ram is really

1076
00:40:04,680 --> 00:40:06,240
only needed for representing of

1077
00:40:06,240 --> 00:40:08,339
candidates and those are already batched

1078
00:40:08,339 --> 00:40:10,920
so that it shouldn't explode and CPUs

1079
00:40:10,920 --> 00:40:12,599
just means faster

1080
00:40:12,599 --> 00:40:15,200
yep

1081
00:40:15,359 --> 00:40:17,960
yep

1082
00:40:24,119 --> 00:40:26,520
thank you very much for the I think it's

1083
00:40:26,520 --> 00:40:29,220
a lot of work you've done

1084
00:40:29,220 --> 00:40:31,920
and personally I think

1085
00:40:31,920 --> 00:40:34,260
a couple of years back actually Telus

1086
00:40:34,260 --> 00:40:36,359
released first

1087
00:40:36,359 --> 00:40:37,820
sorry first

1088
00:40:37,820 --> 00:40:42,800
yeah they released the same like um

1089
00:40:43,220 --> 00:40:46,140
lsh with Jacquard distance but on the

1090
00:40:46,140 --> 00:40:49,619
common common lines uh so and and that's

1091
00:40:49,619 --> 00:40:51,960
the tool I tried it's it's like exactly

1092
00:40:51,960 --> 00:40:54,480
the same but um it's running on apache's

1093
00:40:54,480 --> 00:40:56,099
Park and

1094
00:40:56,099 --> 00:40:58,680
um I tried it in our environment and it

1095
00:40:58,680 --> 00:41:01,200
was like so much data that it crushed it

1096
00:41:01,200 --> 00:41:04,140
you know I collect one hour data on the

1097
00:41:04,140 --> 00:41:05,880
command lines and I think the malware

1098
00:41:05,880 --> 00:41:08,700
one is much much better like looking at

1099
00:41:08,700 --> 00:41:10,200
the malware code instead of the command

1100
00:41:10,200 --> 00:41:12,839
lines from the computers uh executions

1101
00:41:12,839 --> 00:41:15,780
and the question with this one so you

1102
00:41:15,780 --> 00:41:17,820
actually store it in the database and

1103
00:41:17,820 --> 00:41:19,920
you every time run your card distance on

1104
00:41:19,920 --> 00:41:22,740
the every like new sample you just run

1105
00:41:22,740 --> 00:41:24,480
it on the whole database in order to

1106
00:41:24,480 --> 00:41:27,780
identify uh where it matches or yeah

1107
00:41:27,780 --> 00:41:29,880
only on the on the candidates basically

1108
00:41:29,880 --> 00:41:32,040
so if you do a query your query sample

1109
00:41:32,040 --> 00:41:34,200
you can decide to store it in a database

1110
00:41:34,200 --> 00:41:36,000
as well but um if you don't know what it

1111
00:41:36,000 --> 00:41:37,560
is you have to label it afterwards

1112
00:41:37,560 --> 00:41:39,780
anyway right if you do a query it's

1113
00:41:39,780 --> 00:41:41,400
handled like those that are indexed

1114
00:41:41,400 --> 00:41:43,800
already so it means just straightforward

1115
00:41:43,800 --> 00:41:45,839
disassembly then generating the Min

1116
00:41:45,839 --> 00:41:47,579
hashes for it and then you can do the

1117
00:41:47,579 --> 00:41:51,540
same candidate selection so usually that

1118
00:41:51,540 --> 00:41:53,880
means not running against everything but

1119
00:41:53,880 --> 00:41:55,560
rather one or two percent of the

1120
00:41:55,560 --> 00:41:57,000
functions that really are close enough

1121
00:41:57,000 --> 00:42:00,480
so you need to do the actual comparisons

1122
00:42:00,480 --> 00:42:03,540
hmm so this this candidate selection is

1123
00:42:03,540 --> 00:42:06,960
what actually keeps it fast okay

1124
00:42:06,960 --> 00:42:08,880
um and one another suggestion maybe have

1125
00:42:08,880 --> 00:42:11,280
you tried to presenting it in a graph so

1126
00:42:11,280 --> 00:42:13,859
you can have the links and basically

1127
00:42:13,859 --> 00:42:15,359
connections between different malware

1128
00:42:15,359 --> 00:42:17,520
who connects to who and because on the

1129
00:42:17,520 --> 00:42:20,099
table it's a little bit different yes

1130
00:42:20,099 --> 00:42:22,440
let me Branch out

1131
00:42:22,440 --> 00:42:25,440
uh

1132
00:42:26,220 --> 00:42:29,160
so let's see if I can find that quickly

1133
00:42:29,160 --> 00:42:31,220
um

1134
00:42:31,500 --> 00:42:33,599
that must be very much in the end I

1135
00:42:33,599 --> 00:42:35,720
guess

1136
00:42:37,220 --> 00:42:39,240
like this

1137
00:42:39,240 --> 00:42:40,140
um

1138
00:42:40,140 --> 00:42:42,060
so that was the reference data set that

1139
00:42:42,060 --> 00:42:44,700
I used in my main PhD thesis and that's

1140
00:42:44,700 --> 00:42:47,040
everything against everything and the

1141
00:42:47,040 --> 00:42:48,240
good thing is even that is not really

1142
00:42:48,240 --> 00:42:50,400
expensive in a sense that's only n log n

1143
00:42:50,400 --> 00:42:52,680
and not n square and shown here is

1144
00:42:52,680 --> 00:42:54,839
basically every relationship with a

1145
00:42:54,839 --> 00:42:58,079
similarity with 10 or more and the some

1146
00:42:58,079 --> 00:42:59,160
of the interesting clusters we have

1147
00:42:59,160 --> 00:43:01,140
there this is all of the Zeus families

1148
00:43:01,140 --> 00:43:02,760
you could say a lot of code for example

1149
00:43:02,760 --> 00:43:06,240
the panda vmsus thingy split off at a

1150
00:43:06,240 --> 00:43:08,520
certain point but those purple and

1151
00:43:08,520 --> 00:43:10,380
orange ones are the ones that um

1152
00:43:10,380 --> 00:43:12,000
basically still link those two families

1153
00:43:12,000 --> 00:43:14,579
you have two different drydex clusters

1154
00:43:14,579 --> 00:43:16,800
that's because it's 32 and 64-bit the

1155
00:43:16,800 --> 00:43:19,440
system cannot put them together and even

1156
00:43:19,440 --> 00:43:21,480
the Friday explains the ransomware spun

1157
00:43:21,480 --> 00:43:23,339
off from DirectX is clustered into the

1158
00:43:23,339 --> 00:43:25,440
same sample so it at least Works a

1159
00:43:25,440 --> 00:43:27,380
certain degree but you also have those

1160
00:43:27,380 --> 00:43:29,880
trash clusters that are linked together

1161
00:43:29,880 --> 00:43:31,380
because of open source air and I wasn't

1162
00:43:31,380 --> 00:43:33,180
able to discern it at that point so

1163
00:43:33,180 --> 00:43:35,579
that's external plus some other malware

1164
00:43:35,579 --> 00:43:36,480
in there

1165
00:43:36,480 --> 00:43:39,780
you know so it's generally possible I

1166
00:43:39,780 --> 00:43:41,400
think one of the main benefits of this

1167
00:43:41,400 --> 00:43:44,040
framework is actually to um lift all of

1168
00:43:44,040 --> 00:43:45,960
that to a point where you can interact

1169
00:43:45,960 --> 00:43:46,920
with it

1170
00:43:46,920 --> 00:43:49,500
so I think um how I basically built this

1171
00:43:49,500 --> 00:43:51,240
this web thing and everything is just my

1172
00:43:51,240 --> 00:43:54,420
view on how I believe you can use it but

1173
00:43:54,420 --> 00:43:56,520
you have a client you can use all of the

1174
00:43:56,520 --> 00:44:00,200
raw data in different purposes

1175
00:44:02,760 --> 00:44:04,800
okay that's going to be the last

1176
00:44:04,800 --> 00:44:07,099
question

1177
00:44:15,540 --> 00:44:16,800
thanks

1178
00:44:16,800 --> 00:44:19,980
nice talk great results

1179
00:44:19,980 --> 00:44:21,359
um so I'm going to ask you about

1180
00:44:21,359 --> 00:44:22,859
attribution

1181
00:44:22,859 --> 00:44:25,440
you know like code analysis is used for

1182
00:44:25,440 --> 00:44:27,300
attribution sometimes it's like not

1183
00:44:27,300 --> 00:44:31,260
really uh high confidence so what's your

1184
00:44:31,260 --> 00:44:33,300
criteria to follow

1185
00:44:33,300 --> 00:44:35,640
um to give confidence to this code

1186
00:44:35,640 --> 00:44:38,640
matching and similarities to say okay

1187
00:44:38,640 --> 00:44:41,280
this is quite likely the same thing or

1188
00:44:41,280 --> 00:44:44,339
the same actor or the same tool or the

1189
00:44:44,339 --> 00:44:46,140
same origin basically

1190
00:44:46,140 --> 00:44:47,460
yeah

1191
00:44:47,460 --> 00:44:49,980
um it's hard to express confidence in

1192
00:44:49,980 --> 00:44:54,319
that way basically the system is um

1193
00:44:54,680 --> 00:44:57,480
how to say it's just straightforward

1194
00:44:57,480 --> 00:44:59,520
giving you the result but you still have

1195
00:44:59,520 --> 00:45:02,160
to do interpretation in a sense you can

1196
00:45:02,160 --> 00:45:03,900
cluster together if I have multiple

1197
00:45:03,900 --> 00:45:05,940
functions that are linking between two

1198
00:45:05,940 --> 00:45:07,500
or three families that's at least a good

1199
00:45:07,500 --> 00:45:09,300
idea or indication that you might want

1200
00:45:09,300 --> 00:45:10,440
to look at it but you still have to

1201
00:45:10,440 --> 00:45:13,200
decide is this now really characteristic

1202
00:45:13,200 --> 00:45:14,940
or that was written by a human and not

1203
00:45:14,940 --> 00:45:16,800
taken from somewhere or linked for some

1204
00:45:16,800 --> 00:45:20,040
reason and just rare So ultimately it

1205
00:45:20,040 --> 00:45:22,079
will be a game of Statistics the more

1206
00:45:22,079 --> 00:45:24,780
quality data you have for reference the

1207
00:45:24,780 --> 00:45:27,180
marketers the automatic deductions you

1208
00:45:27,180 --> 00:45:29,099
will be able to make but it's really

1209
00:45:29,099 --> 00:45:31,380
hard to give a good answer otherwise I

1210
00:45:31,380 --> 00:45:32,220
think

1211
00:45:32,220 --> 00:45:36,319
so we are not jobless yet so

1212
00:45:37,319 --> 00:45:39,300
thank you very much thank you

1213
00:45:39,300 --> 00:45:43,199
[Applause]

