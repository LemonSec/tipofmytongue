1
00:00:02,320 --> 00:00:05,759
hello everyone

2
00:00:03,439 --> 00:00:07,120
my name is assaf nedler and together

3
00:00:05,759 --> 00:00:09,519
with jordan garzan

4
00:00:07,120 --> 00:00:10,719
we're presenting this talk titled

5
00:00:09,519 --> 00:00:14,879
in-line detection

6
00:00:10,719 --> 00:00:14,879
of copy-paste botnet cnc

7
00:00:15,519 --> 00:00:20,000
both jordan and myself are data

8
00:00:17,600 --> 00:00:22,000
scientists and security researchers for

9
00:00:20,000 --> 00:00:23,920
akamai technologies

10
00:00:22,000 --> 00:00:27,920
our emails are listed below if you want

11
00:00:23,920 --> 00:00:27,920
to reach out to us after the conference

12
00:00:28,880 --> 00:00:34,000
the agenda of the talk has three parts

13
00:00:31,760 --> 00:00:36,559
in the first part we'll define the term

14
00:00:34,000 --> 00:00:39,040
of copy piece botnets and then we'll

15
00:00:36,559 --> 00:00:41,440
discuss how to possibly shut down

16
00:00:39,040 --> 00:00:44,719
bothered communication to these botnets

17
00:00:41,440 --> 00:00:47,440
using inline url filtering

18
00:00:44,719 --> 00:00:48,480
in the second part i'll display a system

19
00:00:47,440 --> 00:00:50,800
overview

20
00:00:48,480 --> 00:00:51,519
of a system that processes repetitive

21
00:00:50,800 --> 00:00:54,320
patterns

22
00:00:51,520 --> 00:00:56,840
of copy paste spotlight urls to identify

23
00:00:54,320 --> 00:00:58,399
new botnets and shut down their

24
00:00:56,840 --> 00:01:00,480
communication

25
00:00:58,399 --> 00:01:02,800
lastly i'll hand over the stage to

26
00:01:00,480 --> 00:01:06,158
jordan to discuss the analysis of the

27
00:01:02,800 --> 00:01:06,158
system and the takeaways

28
00:01:07,600 --> 00:01:10,798
bots often communicate with their

29
00:01:09,439 --> 00:01:14,880
command control server

30
00:01:10,799 --> 00:01:17,280
over the http or https protocol

31
00:01:14,880 --> 00:01:19,280
therefore a common defensive approach to

32
00:01:17,280 --> 00:01:20,240
block botnet command and control

33
00:01:19,280 --> 00:01:23,439
communication

34
00:01:20,240 --> 00:01:24,479
over this protocols is by using url

35
00:01:23,439 --> 00:01:27,360
blacklist

36
00:01:24,479 --> 00:01:29,280
so that if a bot attempts to communicate

37
00:01:27,360 --> 00:01:32,799
with its command control server

38
00:01:29,280 --> 00:01:34,159
by reaching out to its url and that url

39
00:01:32,799 --> 00:01:37,439
is known in advance

40
00:01:34,159 --> 00:01:38,390
and listed within the url blacklist then

41
00:01:37,439 --> 00:01:39,839
we can block the

42
00:01:38,390 --> 00:01:41,759
[Music]

43
00:01:39,840 --> 00:01:43,119
the primary drawback to be a real

44
00:01:41,759 --> 00:01:45,119
blacklist

45
00:01:43,119 --> 00:01:47,280
is that they commonly suffer from a high

46
00:01:45,119 --> 00:01:49,280
false negative rate that is misses

47
00:01:47,280 --> 00:01:50,640
because they are not updated frequently

48
00:01:49,280 --> 00:01:54,399
enough and therefore they don't

49
00:01:50,640 --> 00:01:56,719
generalize to new upcoming botnets

50
00:01:54,399 --> 00:01:58,079
therefore we are interested in detecting

51
00:01:56,719 --> 00:01:59,039
botanic command and control

52
00:01:58,079 --> 00:02:02,639
communication

53
00:01:59,040 --> 00:02:08,160
over the http and https protocol in line

54
00:02:02,640 --> 00:02:10,560
despite not using url blacklist

55
00:02:08,160 --> 00:02:11,840
this is where we define the term of copy

56
00:02:10,560 --> 00:02:14,879
paste botnets

57
00:02:11,840 --> 00:02:16,800
we know thus far that the source code of

58
00:02:14,879 --> 00:02:20,640
botnets and their cnc server

59
00:02:16,800 --> 00:02:23,520
is often leaked out and published online

60
00:02:20,640 --> 00:02:25,599
there's a talk from bottom 2018 called

61
00:02:23,520 --> 00:02:28,800
mirai beyond the aftermath

62
00:02:25,599 --> 00:02:31,518
in which the authors discussed at least

63
00:02:28,800 --> 00:02:33,519
five bot botnets resource code leaked

64
00:02:31,519 --> 00:02:36,640
out to the internet

65
00:02:33,519 --> 00:02:39,040
we also seen 2020 tweets and blogs

66
00:02:36,640 --> 00:02:41,200
about other botanists resourceful leaked

67
00:02:39,040 --> 00:02:43,920
out onto the internet

68
00:02:41,200 --> 00:02:46,079
so from this perspective of bot owners

69
00:02:43,920 --> 00:02:48,079
they would often choose to copy and

70
00:02:46,080 --> 00:02:49,599
reuse leaked source code to save

71
00:02:48,080 --> 00:02:51,440
development time and effort

72
00:02:49,599 --> 00:02:53,920
rather than develop the botnet from

73
00:02:51,440 --> 00:02:53,920
scratch

74
00:02:57,040 --> 00:03:02,400
when bot herders copy source code of

75
00:02:59,840 --> 00:03:05,040
previous botnets they also inherit some

76
00:03:02,400 --> 00:03:06,959
similarities to these botanists

77
00:03:05,040 --> 00:03:09,440
so for instance when we're looking at

78
00:03:06,959 --> 00:03:10,879
new variants of the spy our command

79
00:03:09,440 --> 00:03:12,800
control urls

80
00:03:10,879 --> 00:03:15,679
we're seeing a pattern that repeats

81
00:03:12,800 --> 00:03:19,040
itself we're seeing that new urls still

82
00:03:15,680 --> 00:03:21,280
end with the main in a file called bt

83
00:03:19,040 --> 00:03:24,159
version checker

84
00:03:21,280 --> 00:03:25,440
the question is can we infer that if we

85
00:03:24,159 --> 00:03:29,120
see a new url

86
00:03:25,440 --> 00:03:32,959
within http communication that ends with

87
00:03:29,120 --> 00:03:35,920
main slash bt version checker.p

88
00:03:32,959 --> 00:03:36,879
can we assume that despite the url not

89
00:03:35,920 --> 00:03:39,119
being listed

90
00:03:36,879 --> 00:03:40,480
within a url blacklist this is still

91
00:03:39,120 --> 00:03:42,640
likely to be

92
00:03:40,480 --> 00:03:47,840
a command controlled url used by a new

93
00:03:42,640 --> 00:03:47,839
variant of spy

94
00:03:48,319 --> 00:03:52,720
so with this question in mind we're

95
00:03:50,480 --> 00:03:55,200
considering how can we detect and

96
00:03:52,720 --> 00:03:57,599
identify that this url is indeed a new

97
00:03:55,200 --> 00:04:00,079
url used by spy eye

98
00:03:57,599 --> 00:04:03,518
so one way of doing that is applying

99
00:04:00,080 --> 00:04:05,599
known system of malicious url detection

100
00:04:03,519 --> 00:04:07,040
using classifiers based on batch

101
00:04:05,599 --> 00:04:09,359
learning online learning and

102
00:04:07,040 --> 00:04:11,599
representation learning

103
00:04:09,360 --> 00:04:13,519
these approaches commonly lie on

104
00:04:11,599 --> 00:04:14,640
traditional machine learning and neural

105
00:04:13,519 --> 00:04:17,440
networks

106
00:04:14,640 --> 00:04:18,320
which despite providing very good

107
00:04:17,440 --> 00:04:21,440
results

108
00:04:18,320 --> 00:04:23,040
they are not very suitable to reside on

109
00:04:21,440 --> 00:04:26,400
high performing http

110
00:04:23,040 --> 00:04:29,600
proxies to scan inline communication

111
00:04:26,400 --> 00:04:31,440
due to their computational resources

112
00:04:29,600 --> 00:04:32,720
so this is where we're kind of looking

113
00:04:31,440 --> 00:04:36,000
for a solution that

114
00:04:32,720 --> 00:04:39,040
is able to scan urls and make a decision

115
00:04:36,000 --> 00:04:41,919
while still not not resulting in

116
00:04:39,040 --> 00:04:44,720
a lot of latency and not blocking inline

117
00:04:41,919 --> 00:04:44,719
communication

118
00:04:46,560 --> 00:04:51,680
the solution that we're aiming for as

119
00:04:48,880 --> 00:04:54,560
regular expressions

120
00:04:51,680 --> 00:04:55,199
because new upcoming technologies such

121
00:04:54,560 --> 00:04:58,639
as intel

122
00:04:55,199 --> 00:05:02,160
hyperscan allows taking a set of urls

123
00:04:58,639 --> 00:05:02,479
compiling them in advance to a model

124
00:05:02,160 --> 00:05:04,960
that

125
00:05:02,479 --> 00:05:05,919
knows how to run is possible for running

126
00:05:04,960 --> 00:05:10,320
in real time

127
00:05:05,919 --> 00:05:10,639
on proxies so the idea is that if we'll

128
00:05:10,320 --> 00:05:13,280
have

129
00:05:10,639 --> 00:05:15,360
a set of records regular expressions we

130
00:05:13,280 --> 00:05:17,840
can compile them in advance

131
00:05:15,360 --> 00:05:20,320
into a model using the intel hyperscan

132
00:05:17,840 --> 00:05:22,000
engine and then we can put and deploy

133
00:05:20,320 --> 00:05:24,960
this model on an http

134
00:05:22,000 --> 00:05:27,440
proxy and apply the regular expressions

135
00:05:24,960 --> 00:05:31,440
within the model to every url that is

136
00:05:27,440 --> 00:05:31,440
browsed on the http proxy

137
00:05:32,800 --> 00:05:38,240
from from this point on if any url

138
00:05:35,919 --> 00:05:40,159
matches these regular expressions we'll

139
00:05:38,240 --> 00:05:41,440
be able to block that

140
00:05:40,160 --> 00:05:43,919
and therefore shut down the

141
00:05:41,440 --> 00:05:46,080
communication of the botnets

142
00:05:43,919 --> 00:05:47,198
so therefore our motivation is to design

143
00:05:46,080 --> 00:05:50,159
a system that does

144
00:05:47,199 --> 00:05:52,160
two things the first of them is to

145
00:05:50,160 --> 00:05:54,400
identify url patterns

146
00:05:52,160 --> 00:05:57,280
of command control c and cs and the

147
00:05:54,400 --> 00:05:59,599
second one of them is to characterize

148
00:05:57,280 --> 00:06:00,960
these url patterns using your regular

149
00:05:59,600 --> 00:06:03,600
expressions

150
00:06:00,960 --> 00:06:06,638
so that we can later compile the set of

151
00:06:03,600 --> 00:06:08,960
regular expressions that we produce

152
00:06:06,639 --> 00:06:11,039
into a model that can run on a high

153
00:06:08,960 --> 00:06:14,799
performance http proxy

154
00:06:11,039 --> 00:06:14,800
and block botnet communication

155
00:06:17,919 --> 00:06:21,198
there are several challenges for

156
00:06:19,600 --> 00:06:24,319
reaching that goal

157
00:06:21,199 --> 00:06:26,479
the first challenge is that we start by

158
00:06:24,319 --> 00:06:29,120
collecting data set of familiar and

159
00:06:26,479 --> 00:06:31,919
known command control urls

160
00:06:29,120 --> 00:06:32,240
so the data set that we compiled thus

161
00:06:31,919 --> 00:06:34,719
far

162
00:06:32,240 --> 00:06:36,880
contained more than 150 000 command

163
00:06:34,720 --> 00:06:38,560
controlled urls that we want to learn

164
00:06:36,880 --> 00:06:41,120
from and generalize

165
00:06:38,560 --> 00:06:42,720
so this poses a challenge of scalability

166
00:06:41,120 --> 00:06:45,440
for such a system

167
00:06:42,720 --> 00:06:47,440
moreover these data sets are updated on

168
00:06:45,440 --> 00:06:51,199
an hourly basis

169
00:06:47,440 --> 00:06:53,680
whenever new cnc urls are emerging

170
00:06:51,199 --> 00:06:55,680
so we're in the process of scaling

171
00:06:53,680 --> 00:06:56,960
enough and identifying new command

172
00:06:55,680 --> 00:06:58,960
control urls by

173
00:06:56,960 --> 00:07:01,520
collecting formally known command

174
00:06:58,960 --> 00:07:03,359
controlled urls at scale

175
00:07:01,520 --> 00:07:05,680
second challenge is that we're dealing

176
00:07:03,360 --> 00:07:07,599
with the trade offense of sensitivity

177
00:07:05,680 --> 00:07:10,319
versus specificity

178
00:07:07,599 --> 00:07:11,840
that is we want to produce regular

179
00:07:10,319 --> 00:07:14,319
expressions

180
00:07:11,840 --> 00:07:17,280
that are not too accurate to never

181
00:07:14,319 --> 00:07:20,720
generalize to new command control urls

182
00:07:17,280 --> 00:07:23,198
but on the other end not too generalized

183
00:07:20,720 --> 00:07:25,520
to avoid blocking legitimate urls and

184
00:07:23,199 --> 00:07:27,680
matching them them

185
00:07:25,520 --> 00:07:29,599
and lastly with regards to performance

186
00:07:27,680 --> 00:07:31,840
which we already discussed

187
00:07:29,599 --> 00:07:33,680
we want to create regix that will be

188
00:07:31,840 --> 00:07:36,080
able to compile in advance

189
00:07:33,680 --> 00:07:37,840
using an engine for instance like hindu

190
00:07:36,080 --> 00:07:40,159
intel hyperscan

191
00:07:37,840 --> 00:07:42,318
to provide acceptable performance and

192
00:07:40,160 --> 00:07:43,199
not something that is too complex that

193
00:07:42,319 --> 00:07:45,759
won't be able

194
00:07:43,199 --> 00:07:47,840
to run on a high performing proxy

195
00:07:45,759 --> 00:07:50,639
without providing too much latency for

196
00:07:47,840 --> 00:07:50,638
the end users

197
00:07:53,039 --> 00:07:58,800
now we're moving to the overview of the

198
00:07:56,840 --> 00:08:00,799
system

199
00:07:58,800 --> 00:08:02,800
the first point in which we start the

200
00:08:00,800 --> 00:08:06,160
system is constructing

201
00:08:02,800 --> 00:08:09,039
a language model of url paths

202
00:08:06,160 --> 00:08:10,400
so we start with a data set of urls that

203
00:08:09,039 --> 00:08:12,560
we know to be

204
00:08:10,400 --> 00:08:13,840
related to botnet command control

205
00:08:12,560 --> 00:08:17,039
communications and

206
00:08:13,840 --> 00:08:20,719
as stated before we have more than 150

207
00:08:17,039 --> 00:08:21,280
000 examples of this the language model

208
00:08:20,720 --> 00:08:23,759
maps

209
00:08:21,280 --> 00:08:25,280
each and every one of these url paths

210
00:08:23,759 --> 00:08:28,479
into a point

211
00:08:25,280 --> 00:08:30,000
within a large hyperspace so within that

212
00:08:28,479 --> 00:08:33,439
space

213
00:08:30,000 --> 00:08:34,159
points of points corresponding to url

214
00:08:33,440 --> 00:08:36,800
paths

215
00:08:34,159 --> 00:08:37,760
are in proximity only if their share of

216
00:08:36,799 --> 00:08:40,799
similarity

217
00:08:37,760 --> 00:08:43,679
that is they share sets

218
00:08:40,799 --> 00:08:45,839
of characters between each other so for

219
00:08:43,679 --> 00:08:46,399
instance if we're looking at the set of

220
00:08:45,839 --> 00:08:49,680
points

221
00:08:46,399 --> 00:08:52,720
corresponding to the malicious url

222
00:08:49,680 --> 00:08:56,160
paths of spy eye all of them ending with

223
00:08:52,720 --> 00:08:58,480
bd virgin checker.php we'd expect these

224
00:08:56,160 --> 00:09:01,439
points to be within proximity within the

225
00:08:58,480 --> 00:09:03,760
resulted language model

226
00:09:01,440 --> 00:09:04,480
the second thing that we do is that we

227
00:09:03,760 --> 00:09:06,319
cluster

228
00:09:04,480 --> 00:09:07,600
points within the language model

229
00:09:06,320 --> 00:09:10,720
corresponding

230
00:09:07,600 --> 00:09:10,720
to url paths

231
00:09:14,640 --> 00:09:18,240
by this point we have clusters of point

232
00:09:17,200 --> 00:09:21,360
corresponding

233
00:09:18,240 --> 00:09:24,720
to url paths known to be related

234
00:09:21,360 --> 00:09:25,519
to command controls now we take every

235
00:09:24,720 --> 00:09:27,839
cluster

236
00:09:25,519 --> 00:09:30,240
and we transform this cluster into a nav

237
00:09:27,839 --> 00:09:31,920
regular expression which is just a set

238
00:09:30,240 --> 00:09:35,920
of order conditions between

239
00:09:31,920 --> 00:09:37,839
all of the url paths within that cluster

240
00:09:35,920 --> 00:09:38,240
so for instance for these examples with

241
00:09:37,839 --> 00:09:41,360
the

242
00:09:38,240 --> 00:09:42,880
bd version checker we're starting with a

243
00:09:41,360 --> 00:09:45,600
regular expression that says

244
00:09:42,880 --> 00:09:47,680
it's either the first url path or

245
00:09:45,600 --> 00:09:48,160
exactly the second or exactly the

246
00:09:47,680 --> 00:09:50,719
certain

247
00:09:48,160 --> 00:09:54,240
and so on and so forth just a set of or

248
00:09:50,720 --> 00:09:56,800
condition for each one of the urls

249
00:09:54,240 --> 00:09:57,839
the the output regular expression is

250
00:09:56,800 --> 00:10:00,479
naive because

251
00:09:57,839 --> 00:10:02,640
it's too specific right it's not able to

252
00:10:00,480 --> 00:10:04,240
generalize to anything else that's not

253
00:10:02,640 --> 00:10:06,319
showing within the cluster but it

254
00:10:04,240 --> 00:10:09,279
describes very accurately everything

255
00:10:06,320 --> 00:10:09,279
within the cluster

256
00:10:10,720 --> 00:10:13,839
at this point what we're trying to

257
00:10:12,720 --> 00:10:16,240
optimize is

258
00:10:13,839 --> 00:10:18,640
compress that into regular expression

259
00:10:16,240 --> 00:10:21,279
that is able to capture of the url

260
00:10:18,640 --> 00:10:23,040
paths within the cluster but also able

261
00:10:21,279 --> 00:10:25,200
to generalize

262
00:10:23,040 --> 00:10:27,920
we achieved that using a genetic

263
00:10:25,200 --> 00:10:30,320
algorithm proposed by bertolier over

264
00:10:27,920 --> 00:10:32,640
four consecutive paper

265
00:10:30,320 --> 00:10:34,240
that attempts to shorten the regular

266
00:10:32,640 --> 00:10:36,959
expression that we created

267
00:10:34,240 --> 00:10:39,040
that is the naive regular expression and

268
00:10:36,959 --> 00:10:42,000
shorten that into a form that still

269
00:10:39,040 --> 00:10:43,199
captures all of the urls within that

270
00:10:42,000 --> 00:10:45,279
cluster

271
00:10:43,200 --> 00:10:46,720
therefore being able to generalize to

272
00:10:45,279 --> 00:10:49,680
new command controls

273
00:10:46,720 --> 00:10:49,680
url paths

274
00:10:51,760 --> 00:10:54,880
the main problem now is that the

275
00:10:53,839 --> 00:10:57,600
resulted

276
00:10:54,880 --> 00:10:58,320
regular expression might also match

277
00:10:57,600 --> 00:11:02,560
benign

278
00:10:58,320 --> 00:11:05,519
legitimate urls now

279
00:11:02,560 --> 00:11:06,640
the genetic algorithm supports getting

280
00:11:05,519 --> 00:11:10,160
both

281
00:11:06,640 --> 00:11:12,079
um but not both uh url paths that we

282
00:11:10,160 --> 00:11:13,839
want to match on and url path

283
00:11:12,079 --> 00:11:15,519
that we don't want to match up but due

284
00:11:13,839 --> 00:11:18,720
to scale

285
00:11:15,519 --> 00:11:19,519
we have a limited set of malicious urls

286
00:11:18,720 --> 00:11:22,240
that we want

287
00:11:19,519 --> 00:11:24,399
match on but we have a very very large

288
00:11:22,240 --> 00:11:27,680
number of urls we don't want to match on

289
00:11:24,399 --> 00:11:30,000
so the way in which we narrow that down

290
00:11:27,680 --> 00:11:32,319
is that we take the records that we got

291
00:11:30,000 --> 00:11:35,120
before the generalized regex

292
00:11:32,320 --> 00:11:37,440
we apply it to rail traffic we see what

293
00:11:35,120 --> 00:11:40,560
it matches on it if it ever matches on

294
00:11:37,440 --> 00:11:41,920
b9 urls then we say specifically that we

295
00:11:40,560 --> 00:11:43,199
don't want to match for them and

296
00:11:41,920 --> 00:11:46,000
penalize

297
00:11:43,200 --> 00:11:46,399
the model for matching on these b9 urls

298
00:11:46,000 --> 00:11:49,120
this

299
00:11:46,399 --> 00:11:49,600
penalization causes the records to

300
00:11:49,120 --> 00:11:52,160
change

301
00:11:49,600 --> 00:11:54,639
so that it both match the command

302
00:11:52,160 --> 00:11:57,760
control urls within the cluster but

303
00:11:54,639 --> 00:11:59,440
never matches the false positive in the

304
00:11:57,760 --> 00:12:01,519
benign urls

305
00:11:59,440 --> 00:12:03,680
and henceforth we're solving this

306
00:12:01,519 --> 00:12:04,160
problem iteratively so in each step we

307
00:12:03,680 --> 00:12:06,160
either

308
00:12:04,160 --> 00:12:08,719
generalize the model or penalize the

309
00:12:06,160 --> 00:12:11,199
model for matching b9 urls

310
00:12:08,720 --> 00:12:12,639
until eventually we converge into a

311
00:12:11,200 --> 00:12:16,160
regular expression that

312
00:12:12,639 --> 00:12:19,279
matches all the europe's url paths

313
00:12:16,160 --> 00:12:21,760
within each one of the clusters but

314
00:12:19,279 --> 00:12:25,839
also never match benign and legitimate

315
00:12:21,760 --> 00:12:25,839
urls that we have within our data sets

316
00:12:28,160 --> 00:12:32,240
so at this point i'll hand over the

317
00:12:30,320 --> 00:12:36,399
state to jordan to talk about the

318
00:12:32,240 --> 00:12:36,399
analysis of the system and the takeaways

319
00:12:37,760 --> 00:12:42,000
thanks assaf for presenting the first

320
00:12:39,279 --> 00:12:44,240
part hi everyone i'm jordan

321
00:12:42,000 --> 00:12:45,519
here we're gonna dive more into the

322
00:12:44,240 --> 00:12:47,600
technical details

323
00:12:45,519 --> 00:12:48,560
we're gonna cover the distance between

324
00:12:47,600 --> 00:12:51,440
url's pass

325
00:12:48,560 --> 00:12:52,638
the clustering the rejects generation

326
00:12:51,440 --> 00:12:55,839
the setups

327
00:12:52,639 --> 00:12:57,600
the results so let's start

328
00:12:55,839 --> 00:12:59,680
with the distance that we use between

329
00:12:57,600 --> 00:13:01,839
urls fast so the idea is to build this

330
00:12:59,680 --> 00:13:04,800
distance

331
00:13:01,839 --> 00:13:06,480
between path what i mean by path is the

332
00:13:04,800 --> 00:13:09,199
last part of the url

333
00:13:06,480 --> 00:13:11,200
what is located after the domain

334
00:13:09,200 --> 00:13:13,279
basically we need to fit this matrix

335
00:13:11,200 --> 00:13:14,639
symmetric matrix of course the diagonal

336
00:13:13,279 --> 00:13:17,839
is zero

337
00:13:14,639 --> 00:13:21,519
and we use the smith's waterman and i

338
00:13:17,839 --> 00:13:24,959
will explain why

339
00:13:21,519 --> 00:13:26,800
let's take a look at those three paths

340
00:13:24,959 --> 00:13:28,479
and the question that i want to ask you

341
00:13:26,800 --> 00:13:31,920
is do they look similar

342
00:13:28,480 --> 00:13:33,839
i'll leave you two seconds

343
00:13:31,920 --> 00:13:36,399
of course they have to be consoled

344
00:13:33,839 --> 00:13:40,639
together so we need to find a distance

345
00:13:36,399 --> 00:13:43,920
that put them close to each other

346
00:13:40,639 --> 00:13:46,000
let's take let's test leverston distance

347
00:13:43,920 --> 00:13:48,479
and smith's watermelon distance i didn't

348
00:13:46,000 --> 00:13:50,560
explain yet what is miss waterman but we

349
00:13:48,480 --> 00:13:52,240
still we can compute them

350
00:13:50,560 --> 00:13:54,079
between a and b we have one for

351
00:13:52,240 --> 00:13:56,160
levenshtein and 28 for smith's

352
00:13:54,079 --> 00:13:58,719
watermelon

353
00:13:56,160 --> 00:14:00,240
level 10 says basically how much the

354
00:13:58,720 --> 00:14:02,480
strings are different

355
00:14:00,240 --> 00:14:06,079
whereas smith's watermelons tells you

356
00:14:02,480 --> 00:14:06,079
how much the strings are similar

357
00:14:06,480 --> 00:14:09,760
if we compute now the distance between a

358
00:14:09,040 --> 00:14:12,319
and c

359
00:14:09,760 --> 00:14:15,439
for livingston distance we have 50 and

360
00:14:12,320 --> 00:14:18,240
for smith's waterman we have 20.

361
00:14:15,440 --> 00:14:20,560
so between a and b and aac for limitless

362
00:14:18,240 --> 00:14:21,360
change we have a variation of 5 000

363
00:14:20,560 --> 00:14:25,359
percent

364
00:14:21,360 --> 00:14:27,680
so we cannot use use levenstein distance

365
00:14:25,360 --> 00:14:29,760
otherwise those three will not be

366
00:14:27,680 --> 00:14:32,959
clustered together

367
00:14:29,760 --> 00:14:34,880
so what is smith waterman it is it is

368
00:14:32,959 --> 00:14:37,760
used in the biology fields

369
00:14:34,880 --> 00:14:39,839
basically to find the basic use case is

370
00:14:37,760 --> 00:14:43,519
to find the common ancestors

371
00:14:39,839 --> 00:14:46,720
between two people they compare

372
00:14:43,519 --> 00:14:50,959
the dna sequences and they try to find

373
00:14:46,720 --> 00:14:50,959
nucleotides that shared in common

374
00:14:52,000 --> 00:14:58,480
so how do we get 20 between a

375
00:14:55,279 --> 00:15:01,360
and c it's basically

376
00:14:58,480 --> 00:15:03,040
the longest best match the red part is

377
00:15:01,360 --> 00:15:05,519
20.

378
00:15:03,040 --> 00:15:07,120
of course we have more parameters in the

379
00:15:05,519 --> 00:15:08,639
space one command we have three power

380
00:15:07,120 --> 00:15:11,279
trapped three parameters

381
00:15:08,639 --> 00:15:11,680
match and match and gap penalty those

382
00:15:11,279 --> 00:15:13,920
are

383
00:15:11,680 --> 00:15:15,839
basically rewards that you give to the

384
00:15:13,920 --> 00:15:20,240
algorithms

385
00:15:15,839 --> 00:15:22,320
to make if in fine this alignment

386
00:15:20,240 --> 00:15:23,360
if you have any question on it we can

387
00:15:22,320 --> 00:15:28,160
answer

388
00:15:23,360 --> 00:15:30,240
after the talk so we have three issues

389
00:15:28,160 --> 00:15:32,639
the first issue is that swiss waterman

390
00:15:30,240 --> 00:15:36,160
can return any number between 0

391
00:15:32,639 --> 00:15:39,199
and n with n the length of the path

392
00:15:36,160 --> 00:15:40,959
in our data set big strings can get

393
00:15:39,199 --> 00:15:43,839
bigger score this is basically the same

394
00:15:40,959 --> 00:15:46,079
issue and the clustering algorithm

395
00:15:43,839 --> 00:15:48,320
works with edit distance not with

396
00:15:46,079 --> 00:15:50,560
similarity distance

397
00:15:48,320 --> 00:15:51,920
so first of all for the first two issues

398
00:15:50,560 --> 00:15:55,439
we need to normalize

399
00:15:51,920 --> 00:15:59,360
the distance by dividing all the

400
00:15:55,440 --> 00:16:02,800
distance by the max between

401
00:15:59,360 --> 00:16:07,279
the the two the two paths and this gives

402
00:16:02,800 --> 00:16:09,839
us a number between zero and hundred

403
00:16:07,279 --> 00:16:11,519
and to convert the similarity distance

404
00:16:09,839 --> 00:16:13,600
to edit distance we switch

405
00:16:11,519 --> 00:16:15,360
the distance with the absolute value

406
00:16:13,600 --> 00:16:19,440
basically the 20

407
00:16:15,360 --> 00:16:23,199
becomes 80 the 70 becomes

408
00:16:19,440 --> 00:16:25,360
30 etc

409
00:16:23,199 --> 00:16:27,359
let's take a look now at the clustering

410
00:16:25,360 --> 00:16:29,199
we have a distance we can blend we can

411
00:16:27,360 --> 00:16:33,120
plot them so we can cluster them

412
00:16:29,199 --> 00:16:34,399
we can form groups we use db scan which

413
00:16:33,120 --> 00:16:37,199
is a popular

414
00:16:34,399 --> 00:16:38,000
unsupervised clustering algorithm it

415
00:16:37,199 --> 00:16:41,359
takes

416
00:16:38,000 --> 00:16:42,560
as parameters two parameters epsilon and

417
00:16:41,360 --> 00:16:44,959
minimal points

418
00:16:42,560 --> 00:16:46,079
epsilon tells you basically what is the

419
00:16:44,959 --> 00:16:49,040
minimum distance

420
00:16:46,079 --> 00:16:51,199
between two clusters to be in between

421
00:16:49,040 --> 00:16:54,000
two points to be in the same clusters

422
00:16:51,199 --> 00:16:55,599
and minimal point is the number the

423
00:16:54,000 --> 00:16:59,279
minimum number of points

424
00:16:55,600 --> 00:17:00,079
to create a cluster and to smith what

425
00:16:59,279 --> 00:17:02,639
are two

426
00:17:00,079 --> 00:17:03,519
db scans you can pass the argument smith

427
00:17:02,639 --> 00:17:07,919
what am

428
00:17:03,519 --> 00:17:11,199
which is pretty cool that's a ydb scan

429
00:17:07,919 --> 00:17:13,360
here as opposed to many cases in data

430
00:17:11,199 --> 00:17:15,039
science we understand what is epsilon we

431
00:17:13,359 --> 00:17:18,159
understand what is minimum point

432
00:17:15,039 --> 00:17:20,240
if we choose epsilon equal 20

433
00:17:18,160 --> 00:17:21,439
we are basically saying to the algorithm

434
00:17:20,240 --> 00:17:24,720
okay group the paths

435
00:17:21,439 --> 00:17:27,679
that are 80 similar so in our case

436
00:17:24,720 --> 00:17:29,280
we want to choose epsilon of minimal

437
00:17:27,679 --> 00:17:34,320
points

438
00:17:29,280 --> 00:17:34,320
so it fits to our use case

439
00:17:34,960 --> 00:17:38,400
in this part we have the distance we

440
00:17:38,000 --> 00:17:41,200
have

441
00:17:38,400 --> 00:17:42,240
the clusters and now we need to extract

442
00:17:41,200 --> 00:17:45,280
the rejects

443
00:17:42,240 --> 00:17:46,400
and for every clusters we need to

444
00:17:45,280 --> 00:17:49,280
extract

445
00:17:46,400 --> 00:17:49,919
one rejects and we play a game called

446
00:17:49,280 --> 00:17:52,480
rejects

447
00:17:49,919 --> 00:17:53,280
golf maybe those of you have played

448
00:17:52,480 --> 00:17:56,400
before

449
00:17:53,280 --> 00:17:58,720
i will explain the rules the rules the

450
00:17:56,400 --> 00:17:59,120
goal is basically to catch a list of

451
00:17:58,720 --> 00:18:02,559
work

452
00:17:59,120 --> 00:18:03,918
with a regex without catching another

453
00:18:02,559 --> 00:18:06,240
list of words

454
00:18:03,919 --> 00:18:07,039
here on the screenshot that you see here

455
00:18:06,240 --> 00:18:09,760
it's uh

456
00:18:07,039 --> 00:18:10,160
it's an api released by the researchers

457
00:18:09,760 --> 00:18:14,000
that

458
00:18:10,160 --> 00:18:16,640
wrote algorithm will use that

459
00:18:14,000 --> 00:18:18,400
solve the game automatically with

460
00:18:16,640 --> 00:18:20,720
genetic algorithm

461
00:18:18,400 --> 00:18:21,840
for example in on our list on our left

462
00:18:20,720 --> 00:18:24,480
side you have

463
00:18:21,840 --> 00:18:25,199
list of conferences and on the right

464
00:18:24,480 --> 00:18:27,840
side

465
00:18:25,200 --> 00:18:28,880
you have a list of our names and it

466
00:18:27,840 --> 00:18:32,240
found the reject

467
00:18:28,880 --> 00:18:36,080
c pipe capital r that capital e

468
00:18:32,240 --> 00:18:39,200
that fits of course in our case

469
00:18:36,080 --> 00:18:40,639
we need to catch instead of conferences

470
00:18:39,200 --> 00:18:44,160
we need to touch

471
00:18:40,640 --> 00:18:48,880
cnc path and instead of not catching

472
00:18:44,160 --> 00:18:48,880
our names we'll put the benign data

473
00:18:49,840 --> 00:18:56,240
so what is genetic algorithm

474
00:18:53,120 --> 00:18:57,280
i will go over it in two minutes if you

475
00:18:56,240 --> 00:18:59,200
have more questions

476
00:18:57,280 --> 00:19:00,720
you're more than welcome to ask after

477
00:18:59,200 --> 00:19:02,880
the talk

478
00:19:00,720 --> 00:19:06,080
so the goal of genetic algorithm is to

479
00:19:02,880 --> 00:19:07,840
find the best solution to a function

480
00:19:06,080 --> 00:19:09,520
in this case it's called a fitness

481
00:19:07,840 --> 00:19:11,360
function i will explain

482
00:19:09,520 --> 00:19:12,960
what is the fitness function the

483
00:19:11,360 --> 00:19:13,360
difference between reinforcement

484
00:19:12,960 --> 00:19:16,240
learning

485
00:19:13,360 --> 00:19:18,159
basically doesn't choose the classic

486
00:19:16,240 --> 00:19:20,880
graduate descents

487
00:19:18,160 --> 00:19:21,679
and it's an iterative process that at

488
00:19:20,880 --> 00:19:24,559
each step

489
00:19:21,679 --> 00:19:25,360
apply evolution mechanism to find the

490
00:19:24,559 --> 00:19:26,960
best solution

491
00:19:25,360 --> 00:19:28,799
of course you can find the best solution

492
00:19:26,960 --> 00:19:31,600
randomly and it works

493
00:19:28,799 --> 00:19:33,600
but this algorithm has proven results

494
00:19:31,600 --> 00:19:36,000
already

495
00:19:33,600 --> 00:19:37,760
this is the flow you start with a group

496
00:19:36,000 --> 00:19:38,559
of basic solutions for example one

497
00:19:37,760 --> 00:19:41,200
solution

498
00:19:38,559 --> 00:19:41,600
for objects would be pass one by past

499
00:19:41,200 --> 00:19:44,480
two

500
00:19:41,600 --> 00:19:46,799
bypass three and then you apply

501
00:19:44,480 --> 00:19:49,600
evolution mechanism

502
00:19:46,799 --> 00:19:51,679
which are crossover and mutation

503
00:19:49,600 --> 00:19:52,080
crossover is basically the mars red and

504
00:19:51,679 --> 00:19:54,559
fire

505
00:19:52,080 --> 00:19:55,918
the father that mix their dna to create

506
00:19:54,559 --> 00:19:59,760
children

507
00:19:55,919 --> 00:20:03,120
and mutation you take one solution and

508
00:19:59,760 --> 00:20:06,799
you just modify a part of it

509
00:20:03,120 --> 00:20:10,799
and until you reach the criterion

510
00:20:06,799 --> 00:20:12,639
we will get to the criterion

511
00:20:10,799 --> 00:20:15,039
so this is how they represent on the

512
00:20:12,640 --> 00:20:17,120
left side the rejects they represent it

513
00:20:15,039 --> 00:20:19,280
with a tree

514
00:20:17,120 --> 00:20:20,639
this is a regex in java so for the

515
00:20:19,280 --> 00:20:22,320
python guys

516
00:20:20,640 --> 00:20:24,159
that sees the plus plus this is

517
00:20:22,320 --> 00:20:26,000
possessive quantifiers it doesn't

518
00:20:24,159 --> 00:20:28,000
exist in python in other languages for

519
00:20:26,000 --> 00:20:29,840
example

520
00:20:28,000 --> 00:20:32,240
and the two fitness functions are the

521
00:20:29,840 --> 00:20:34,879
sum of level 10 distance between

522
00:20:32,240 --> 00:20:35,440
detected strings and the desired string

523
00:20:34,880 --> 00:20:38,799
we want

524
00:20:35,440 --> 00:20:42,000
to minimize this sum of course and

525
00:20:38,799 --> 00:20:45,440
the length of the rejects the short

526
00:20:42,000 --> 00:20:46,480
the shorter the rejects the better i put

527
00:20:45,440 --> 00:20:49,679
here

528
00:20:46,480 --> 00:20:51,360
the parameters that they used and that

529
00:20:49,679 --> 00:20:52,720
we took and that worked well

530
00:20:51,360 --> 00:20:55,360
in our case instead you want to

531
00:20:52,720 --> 00:20:55,360
reproduce

532
00:20:55,679 --> 00:20:59,840
so we have the clusters we extract the

533
00:20:57,919 --> 00:21:02,720
rejects and then

534
00:20:59,840 --> 00:21:04,000
we test this rejects against our benign

535
00:21:02,720 --> 00:21:07,200
data set

536
00:21:04,000 --> 00:21:10,240
if it doesn't catch anything

537
00:21:07,200 --> 00:21:12,880
we keep these rejects otherwise

538
00:21:10,240 --> 00:21:14,640
we retrain we take the first positive

539
00:21:12,880 --> 00:21:16,640
and then we put

540
00:21:14,640 --> 00:21:18,480
on the list to not catch remember the

541
00:21:16,640 --> 00:21:21,840
game rejects gulf

542
00:21:18,480 --> 00:21:25,120
we can do it n times and after end times

543
00:21:21,840 --> 00:21:28,080
if we still find false positive

544
00:21:25,120 --> 00:21:29,039
we don't use these rejects it will be

545
00:21:28,080 --> 00:21:31,760
maybe clearer

546
00:21:29,039 --> 00:21:34,158
with the data so we start with the data

547
00:21:31,760 --> 00:21:36,640
the setup

548
00:21:34,159 --> 00:21:39,039
we use the big machine on aws because

549
00:21:36,640 --> 00:21:41,760
it's a cpu consuming

550
00:21:39,039 --> 00:21:44,480
for the smith waterman computation and

551
00:21:41,760 --> 00:21:48,000
for the rejects extraction

552
00:21:44,480 --> 00:21:51,600
we used 106k cnc pass

553
00:21:48,000 --> 00:21:54,880
and more than one million parts of b9

554
00:21:51,600 --> 00:21:56,480
with we took it from accommodation

555
00:21:54,880 --> 00:21:59,280
traffic from alexa

556
00:21:56,480 --> 00:21:59,280
and publicly

557
00:22:02,559 --> 00:22:05,840
so again the loop we have the cluster on

558
00:22:05,200 --> 00:22:08,000
the left

559
00:22:05,840 --> 00:22:09,840
we extract rejects we create first

560
00:22:08,000 --> 00:22:12,240
positive we took the first positive we

561
00:22:09,840 --> 00:22:15,360
inject them into an algorithm

562
00:22:12,240 --> 00:22:19,120
and we get another rejects

563
00:22:15,360 --> 00:22:23,840
same for another cluster etc etc

564
00:22:19,120 --> 00:22:27,678
etc this is how we get

565
00:22:23,840 --> 00:22:30,158
rejects without any force positive

566
00:22:27,679 --> 00:22:31,360
about the results first of all we did

567
00:22:30,159 --> 00:22:34,559
the cross-validation

568
00:22:31,360 --> 00:22:35,918
we took all the data that we have until

569
00:22:34,559 --> 00:22:39,440
2018

570
00:22:35,919 --> 00:22:42,799
we train on it and we

571
00:22:39,440 --> 00:22:44,960
we tested it against the data that we

572
00:22:42,799 --> 00:22:48,240
got after 2018

573
00:22:44,960 --> 00:22:53,360
and we saw that from only 12 urls

574
00:22:48,240 --> 00:22:55,200
12 paths you can have 26.3

575
00:22:53,360 --> 00:22:57,280
accuracy of course without force

576
00:22:55,200 --> 00:23:01,120
positive

577
00:22:57,280 --> 00:23:04,480
so it's very very cool you need only 12

578
00:23:01,120 --> 00:23:06,158
paths to detect all the variants for

579
00:23:04,480 --> 00:23:08,640
these signatures

580
00:23:06,159 --> 00:23:09,840
even if you have more than 12 of course

581
00:23:08,640 --> 00:23:14,000
you can see on the table

582
00:23:09,840 --> 00:23:14,000
you get 100 cash

583
00:23:14,720 --> 00:23:23,360
with this data set we we ended up with

584
00:23:17,919 --> 00:23:26,480
34 rejects that detected more than 1.3k

585
00:23:23,360 --> 00:23:27,439
new cnc urls also we took those 34

586
00:23:26,480 --> 00:23:31,120
widgets

587
00:23:27,440 --> 00:23:34,559
we tested them against vt urls

588
00:23:31,120 --> 00:23:37,840
and we discovered 10.2

589
00:23:34,559 --> 00:23:37,840
cnc there

590
00:23:38,080 --> 00:23:45,199
conclusion so using a genji algorithm

591
00:23:41,360 --> 00:23:48,639
and clustering based on smith waterman

592
00:23:45,200 --> 00:23:52,960
and db scan we were able to construct

593
00:23:48,640 --> 00:23:57,200
34 with jaxes let's identify 1.3k

594
00:23:52,960 --> 00:24:00,240
new c2 urls for every clusters

595
00:23:57,200 --> 00:24:05,840
you need only 12 urls

596
00:24:00,240 --> 00:24:05,840
path to create a powerful signatures

597
00:24:06,159 --> 00:24:12,559
cluster rejects is the future

598
00:24:10,000 --> 00:24:14,080
cluster we need to cluster rejections

599
00:24:12,559 --> 00:24:17,840
within the same family

600
00:24:14,080 --> 00:24:21,199
so this is the next goal

601
00:24:17,840 --> 00:24:23,760
and we are seeking of releasing the code

602
00:24:21,200 --> 00:24:24,799
that is a mix between python and java

603
00:24:23,760 --> 00:24:26,720
because the

604
00:24:24,799 --> 00:24:28,320
the part of the object rejects

605
00:24:26,720 --> 00:24:30,840
extraction is written in java

606
00:24:28,320 --> 00:24:32,480
and our code is with is written in

607
00:24:30,840 --> 00:24:35,039
python

608
00:24:32,480 --> 00:24:35,520
i put here the link of the java code

609
00:24:35,039 --> 00:24:39,760
instead

610
00:24:35,520 --> 00:24:46,879
you want to test it thank you very much

611
00:24:39,760 --> 00:24:46,879
i hope you enjoy q a

