1
00:00:04,220 --> 00:00:09,780
yes hello everyone so my name is Daniele

2
00:00:07,080 --> 00:00:11,280
and today I'm going to present on the

3
00:00:09,780 --> 00:00:14,340
PDA which is a project that I've now

4
00:00:11,280 --> 00:00:16,529
been pursuing for almost two years first

5
00:00:14,340 --> 00:00:19,080
before we get into it let me take my

6
00:00:16,529 --> 00:00:20,910
co-workers on this one so Martin had a

7
00:00:19,080 --> 00:00:24,209
lot with the revelation framework and

8
00:00:20,910 --> 00:00:25,740
statistics that we've used to present

9
00:00:24,210 --> 00:00:28,529
some of the results that are later in

10
00:00:25,740 --> 00:00:31,709
the store and Stefan basically program

11
00:00:28,529 --> 00:00:33,930
most of the website and platform that's

12
00:00:31,710 --> 00:00:36,480
basically used to deliver the data and

13
00:00:33,930 --> 00:00:38,579
interact with with my PDF and my

14
00:00:36,480 --> 00:00:41,129
supervisor and I'm always happy when I

15
00:00:38,579 --> 00:00:42,780
can talk to him and exchange ideas so

16
00:00:41,129 --> 00:00:44,250
the outline for the store is basically I

17
00:00:42,780 --> 00:00:46,289
start with a summary so you get

18
00:00:44,250 --> 00:00:46,770
directing to the topic and what's it all

19
00:00:46,289 --> 00:00:48,840
about

20
00:00:46,770 --> 00:00:51,510
then I go back about two years in time

21
00:00:48,840 --> 00:00:54,030
motivating how we came to that idea and

22
00:00:51,510 --> 00:00:56,519
what basically has happened unto them I

23
00:00:54,030 --> 00:00:58,559
give a layout of the approach that we

24
00:00:56,520 --> 00:01:01,469
have followed and then present my PDA

25
00:00:58,559 --> 00:01:03,599
itself and the next step is basically

26
00:01:01,469 --> 00:01:05,280
showing you what you can do with this

27
00:01:03,600 --> 00:01:08,909
corpus so essentially what I'm

28
00:01:05,280 --> 00:01:10,799
presenting here is a very clean corpus

29
00:01:08,909 --> 00:01:13,530
of malware of unpacked nerve actually

30
00:01:10,799 --> 00:01:17,040
and then going a bit in the future so

31
00:01:13,530 --> 00:01:18,600
for the summary what's map idea so from

32
00:01:17,040 --> 00:01:20,790
the intention is basically a free

33
00:01:18,600 --> 00:01:22,619
independent put resource for

34
00:01:20,790 --> 00:01:24,150
confidential labeled unpick reference

35
00:01:22,619 --> 00:01:27,630
samples from other memories inversions

36
00:01:24,150 --> 00:01:30,570
so everything in one sentence basically

37
00:01:27,630 --> 00:01:32,939
means I try to have a good coverage of

38
00:01:30,570 --> 00:01:35,279
many families then have the abortions

39
00:01:32,939 --> 00:01:37,679
tracked as well trying to limit it to as

40
00:01:35,280 --> 00:01:40,020
many as few symbols as possible so I

41
00:01:37,680 --> 00:01:42,360
want to have a small corpus that's still

42
00:01:40,020 --> 00:01:44,490
very representative and I'm very happy

43
00:01:42,360 --> 00:01:47,789
to share this kind of data at the same

44
00:01:44,490 --> 00:01:49,408
time along with the samples it makes

45
00:01:47,790 --> 00:01:51,630
sense to track all the meta data because

46
00:01:49,409 --> 00:01:53,130
right now if you think about it how are

47
00:01:51,630 --> 00:01:54,600
you going to find blog posts on

48
00:01:53,130 --> 00:01:56,280
something you're going Google and that's

49
00:01:54,600 --> 00:01:58,079
a lot of effort otherwise we could

50
00:01:56,280 --> 00:01:59,729
basically directly attach those

51
00:01:58,079 --> 00:02:01,350
references to the samples so you have

52
00:01:59,729 --> 00:02:03,929
everything in one place so it's one of

53
00:02:01,350 --> 00:02:06,210
the ideas here and since we have a nice

54
00:02:03,930 --> 00:02:08,280
corpus and we can also basically test

55
00:02:06,210 --> 00:02:09,840
and develop our yaro rules against it so

56
00:02:08,280 --> 00:02:12,680
that's the some of the ideas here

57
00:02:09,840 --> 00:02:13,770
so looking about one week ago I had

58
00:02:12,680 --> 00:02:15,000
roughly

59
00:02:13,770 --> 00:02:17,790
two and a half thousand member samples

60
00:02:15,000 --> 00:02:19,560
there for around 670 families and I'm

61
00:02:17,790 --> 00:02:22,350
targeting multi-platforms not only

62
00:02:19,560 --> 00:02:24,440
Windows malware but also embedded stuff

63
00:02:22,350 --> 00:02:26,460
I at least of apks OSX

64
00:02:24,440 --> 00:02:30,150
JavaScript's because that's a thing as

65
00:02:26,460 --> 00:02:32,040
well and everything in that corpus so

66
00:02:30,150 --> 00:02:34,050
the contributions of this work because

67
00:02:32,040 --> 00:02:35,429
there's also paper to it ever we

68
00:02:34,050 --> 00:02:37,350
released later on

69
00:02:35,430 --> 00:02:39,630
first we define some requirements that

70
00:02:37,350 --> 00:02:41,519
we think are useful thing to follow if

71
00:02:39,630 --> 00:02:44,130
you're basically creating such a corpus

72
00:02:41,520 --> 00:02:46,350
and then we provide our vision or our

73
00:02:44,130 --> 00:02:49,410
take on this corpus and the platform as

74
00:02:46,350 --> 00:02:51,480
well and the second part is basically we

75
00:02:49,410 --> 00:02:52,890
do a comprehensive quantitative static

76
00:02:51,480 --> 00:02:54,690
analysis so basically looking at the

77
00:02:52,890 --> 00:02:57,269
structure across all of those families

78
00:02:54,690 --> 00:03:02,370
and provide some results on that as well

79
00:02:57,270 --> 00:03:07,530
so how did all of this begin so who was

80
00:03:02,370 --> 00:03:10,470
at what come 2015 so some of you guys I

81
00:03:07,530 --> 00:03:13,740
have to do it that way might remember

82
00:03:10,470 --> 00:03:16,710
that there was distinct so quite a bunch

83
00:03:13,740 --> 00:03:20,100
of TTA talks and yeah I'm one of those

84
00:03:16,710 --> 00:03:22,770
guys so I basically presented on my

85
00:03:20,100 --> 00:03:25,230
previous project which was DG archive so

86
00:03:22,770 --> 00:03:27,410
basically a clean collection of Agra

87
00:03:25,230 --> 00:03:30,269
from Berkeley generated domain names

88
00:03:27,410 --> 00:03:32,850
however as much renting there was on

89
00:03:30,270 --> 00:03:34,050
DJ's I still feel from the feedback I

90
00:03:32,850 --> 00:03:36,450
received that's a good project because

91
00:03:34,050 --> 00:03:39,330
um when you provide created systemize

92
00:03:36,450 --> 00:03:41,609
data you can do really good stuff with

93
00:03:39,330 --> 00:03:42,959
it and also since it was launched I had

94
00:03:41,610 --> 00:03:45,390
more than one and a half million queries

95
00:03:42,959 --> 00:03:48,990
to DG archive so it seemed League is

96
00:03:45,390 --> 00:03:51,929
also used by some people in 2015 there

97
00:03:48,990 --> 00:03:55,500
was another thing does anyone recall

98
00:03:51,930 --> 00:03:58,920
this slide it's actually from a

99
00:03:55,500 --> 00:04:01,800
lightning talk so there was this plug

100
00:03:58,920 --> 00:04:03,780
watt plug X so basically when Crowder

101
00:04:01,800 --> 00:04:05,820
gave his lightning talk on that we have

102
00:04:03,780 --> 00:04:07,350
a synonym problem basically with malware

103
00:04:05,820 --> 00:04:08,970
so everyone is preferring to stuff in a

104
00:04:07,350 --> 00:04:10,820
different way and we cannot really come

105
00:04:08,970 --> 00:04:12,780
to consensus and what he basically

106
00:04:10,820 --> 00:04:15,420
proposed us let's let's try to do

107
00:04:12,780 --> 00:04:17,220
something and fix it I didn't really

108
00:04:15,420 --> 00:04:19,469
talk to him but I thought also it was a

109
00:04:17,220 --> 00:04:20,340
good idea because when I basically came

110
00:04:19,470 --> 00:04:22,710
back from kampf

111
00:04:20,339 --> 00:04:26,010
I looked at all the data that I had so

112
00:04:22,710 --> 00:04:27,150
I'm from several years I had basically

113
00:04:26,010 --> 00:04:28,530
the idea I'm

114
00:04:27,150 --> 00:04:30,299
sitting on a pile of Investigations that

115
00:04:28,530 --> 00:04:32,070
I've done and debated I structured

116
00:04:30,300 --> 00:04:33,780
amidst them normally probably by date I

117
00:04:32,070 --> 00:04:35,250
have to sample I might have a dumb might

118
00:04:33,780 --> 00:04:37,739
have unpacked samples might have an ID

119
00:04:35,250 --> 00:04:40,889
be some some text and write up for it

120
00:04:37,740 --> 00:04:43,979
and what is somewhat structured is still

121
00:04:40,889 --> 00:04:45,539
mess and what came to me is basically it

122
00:04:43,979 --> 00:04:48,750
might be a good idea to do this in a way

123
00:04:45,539 --> 00:04:51,240
more structured fashion so I thought

124
00:04:48,750 --> 00:04:52,800
having a code centric inventory that's

125
00:04:51,240 --> 00:04:54,300
basically focusing on static analysis

126
00:04:52,800 --> 00:04:56,490
would be like really really good because

127
00:04:54,300 --> 00:04:58,229
we can basically resolve over our

128
00:04:56,490 --> 00:04:59,490
synonym and naming problem with it

129
00:04:58,229 --> 00:05:01,109
because it's it's like a rosetta stone

130
00:04:59,490 --> 00:05:03,449
where you have pieces that you can refer

131
00:05:01,110 --> 00:05:05,250
to and basically put just a lame label

132
00:05:03,449 --> 00:05:07,530
on it because code is basically the

133
00:05:05,250 --> 00:05:10,710
basis that we can find consensus on when

134
00:05:07,530 --> 00:05:12,448
we try to name stuff I guess yeah and

135
00:05:10,710 --> 00:05:15,210
another thing that I've learned from

136
00:05:12,449 --> 00:05:17,220
ggrf is basically we as a mother

137
00:05:15,210 --> 00:05:18,830
research community should definitely

138
00:05:17,220 --> 00:05:21,570
start thinking about preservation

139
00:05:18,830 --> 00:05:24,150
because when I tried to recover as many

140
00:05:21,570 --> 00:05:27,240
ggs as possible I ran into stuff like a

141
00:05:24,150 --> 00:05:31,049
Zener wall or TDS s that were active

142
00:05:27,240 --> 00:05:34,110
around 2008 2011 or more and it's very

143
00:05:31,050 --> 00:05:36,810
hard to find samples for those families

144
00:05:34,110 --> 00:05:38,340
by today's standards so even if I'm very

145
00:05:36,810 --> 00:05:39,870
sure that they are somewhere in the in

146
00:05:38,340 --> 00:05:42,150
the deaths of virustotal and hidden

147
00:05:39,870 --> 00:05:44,820
there it's hard to find those examples

148
00:05:42,150 --> 00:05:47,820
that consist or basically contain the

149
00:05:44,820 --> 00:05:49,260
DGA code especially if it's not like a

150
00:05:47,820 --> 00:05:51,419
first stage drop or something but a

151
00:05:49,260 --> 00:05:52,800
module that's being pulled it can be

152
00:05:51,419 --> 00:05:55,320
hard to find the kind of stuff so

153
00:05:52,800 --> 00:05:57,270
basically having this this archived

154
00:05:55,320 --> 00:05:57,900
repository of mother families might be a

155
00:05:57,270 --> 00:06:00,719
good idea

156
00:05:57,900 --> 00:06:01,409
from the perspective as well so for

157
00:06:00,720 --> 00:06:04,409
related work

158
00:06:01,409 --> 00:06:05,580
um so Erica's not here this year but at

159
00:06:04,409 --> 00:06:07,800
least I want to have him in my slides

160
00:06:05,580 --> 00:06:09,780
he's been doing this but mess of our

161
00:06:07,800 --> 00:06:11,729
project which is basically a wiki like

162
00:06:09,780 --> 00:06:14,280
structure also trying to cover many

163
00:06:11,729 --> 00:06:17,490
different malware families but in that

164
00:06:14,280 --> 00:06:18,900
sense it's just metadata that's also the

165
00:06:17,490 --> 00:06:21,570
zoo that was referenced yesterday

166
00:06:18,900 --> 00:06:23,460
because um you were using it as a label

167
00:06:21,570 --> 00:06:26,400
injection when you do we're doing

168
00:06:23,460 --> 00:06:28,349
clustering I think there is basically

169
00:06:26,400 --> 00:06:30,120
it's still mostly pecked malware and

170
00:06:28,349 --> 00:06:31,289
it's only semi structure that's caught

171
00:06:30,120 --> 00:06:34,590
that way because you sometimes have

172
00:06:31,289 --> 00:06:36,930
folders that basically contain the same

173
00:06:34,590 --> 00:06:38,960
family or you have one folder containing

174
00:06:36,930 --> 00:06:40,950
more than one family and stuff like that

175
00:06:38,960 --> 00:06:44,010
virus pay is a quite

176
00:06:40,950 --> 00:06:45,479
new project it seems to follow some same

177
00:06:44,010 --> 00:06:47,190
ideas that I've been doing with my PDA

178
00:06:45,480 --> 00:06:49,350
but I think it's more focused on

179
00:06:47,190 --> 00:06:50,820
knowledge exchanged and actually trying

180
00:06:49,350 --> 00:06:53,460
to build this kind of archive that I'm

181
00:06:50,820 --> 00:06:56,130
pursuing here and finally you have

182
00:06:53,460 --> 00:06:58,140
projects like ID ransomware that's also

183
00:06:56,130 --> 00:06:59,219
I guess keep their collection but it's

184
00:06:58,140 --> 00:07:02,210
basically hidden and not accessible

185
00:06:59,220 --> 00:07:06,570
directly so basically that's also only

186
00:07:02,210 --> 00:07:08,340
metadata yeah so also the title is

187
00:07:06,570 --> 00:07:10,230
basically inventor rising Netscape and

188
00:07:08,340 --> 00:07:12,419
what do I mean by that

189
00:07:10,230 --> 00:07:14,790
so it's basically a kind of a sling now

190
00:07:12,420 --> 00:07:16,410
it sounds a bit like cartography and

191
00:07:14,790 --> 00:07:17,910
that's basically what I basically my

192
00:07:16,410 --> 00:07:21,030
vision for this project in the in the

193
00:07:17,910 --> 00:07:22,530
long run is so cartography in a

194
00:07:21,030 --> 00:07:25,950
historical sense is basically done with

195
00:07:22,530 --> 00:07:28,320
baselines and the fun facts basically in

196
00:07:25,950 --> 00:07:28,920
bond is one of the older ones of such

197
00:07:28,320 --> 00:07:30,840
baselines

198
00:07:28,920 --> 00:07:33,270
so in bond we have this distance of

199
00:07:30,840 --> 00:07:35,400
round about two kilometers which has

200
00:07:33,270 --> 00:07:38,609
been used to measure a very long stretch

201
00:07:35,400 --> 00:07:40,710
of land afterwards so you basically have

202
00:07:38,610 --> 00:07:42,510
this plate which basically tells you

203
00:07:40,710 --> 00:07:44,969
what it was used for it's basically a

204
00:07:42,510 --> 00:07:47,130
pillar somewhere involved and from a

205
00:07:44,970 --> 00:07:48,780
theory you'd measure other points that

206
00:07:47,130 --> 00:07:51,450
you can see in a distance and then by

207
00:07:48,780 --> 00:07:53,429
the angle it's derived basically the

208
00:07:51,450 --> 00:07:55,710
disband that's basically width between

209
00:07:53,430 --> 00:07:58,560
those points that you're measuring

210
00:07:55,710 --> 00:08:00,419
and in those times basically it has been

211
00:07:58,560 --> 00:08:02,220
used to to cover the whole distance from

212
00:08:00,420 --> 00:08:04,200
Athens uruk's so run about four

213
00:08:02,220 --> 00:08:06,630
kilometers and that kind of started in

214
00:08:04,200 --> 00:08:08,490
Bonn so it was just some fun fact that I

215
00:08:06,630 --> 00:08:11,700
wanted to bring up here so apply to

216
00:08:08,490 --> 00:08:13,560
malware we could do that as well I guess

217
00:08:11,700 --> 00:08:15,240
so if we are trying to collect some

218
00:08:13,560 --> 00:08:18,660
reference points for families and

219
00:08:15,240 --> 00:08:21,060
versions we could measure code somehow

220
00:08:18,660 --> 00:08:22,260
or at least do an indexation on it so

221
00:08:21,060 --> 00:08:24,450
that's basically my vision for this

222
00:08:22,260 --> 00:08:26,789
whole thing so I thought okay let's give

223
00:08:24,450 --> 00:08:29,729
it a shot and that was basically run

224
00:08:26,790 --> 00:08:34,140
about two years ago so for the approach

225
00:08:29,730 --> 00:08:35,640
I thought it might make sense to go one

226
00:08:34,140 --> 00:08:39,049
step back and try to do it's just

227
00:08:35,640 --> 00:08:41,098
somatically from the start so what are

228
00:08:39,049 --> 00:08:42,929
probably some goats that you would want

229
00:08:41,099 --> 00:08:45,960
to pursue if you build another corpus so

230
00:08:42,929 --> 00:08:48,660
I thought there's this work from 2007

231
00:08:45,960 --> 00:08:50,670
2012 by Christian Russell and he defined

232
00:08:48,660 --> 00:08:52,230
some prudent practices that's one people

233
00:08:50,670 --> 00:08:53,620
people would should follow if you are

234
00:08:52,230 --> 00:08:55,360
doing Mary experiments

235
00:08:53,620 --> 00:08:57,130
and I thought okay that's reviewed and

236
00:08:55,360 --> 00:08:59,530
try if you can find some things that we

237
00:08:57,130 --> 00:09:01,450
can reapply and from that we basically

238
00:08:59,530 --> 00:09:03,040
found our own requirements that are

239
00:09:01,450 --> 00:09:05,200
basically more tailored to our special

240
00:09:03,040 --> 00:09:08,170
case which is basically looking at

241
00:09:05,200 --> 00:09:09,670
static analysis so some of the major

242
00:09:08,170 --> 00:09:12,310
goals that you might have in mind there

243
00:09:09,670 --> 00:09:14,170
is you want representative data I think

244
00:09:12,310 --> 00:09:16,719
that's pretty obvious because you want

245
00:09:14,170 --> 00:09:19,360
to have coverage in multiple angles at

246
00:09:16,720 --> 00:09:21,130
the same time it has to be temporal in a

247
00:09:19,360 --> 00:09:24,040
good sense so you can probably do some

248
00:09:21,130 --> 00:09:25,600
historical analysis on malware it

249
00:09:24,040 --> 00:09:27,939
doesn't make sense to them into a

250
00:09:25,600 --> 00:09:29,680
platform because you still can out a

251
00:09:27,940 --> 00:09:32,410
piece of the corpus afterwards if you

252
00:09:29,680 --> 00:09:34,719
want to do that and if you want to do

253
00:09:32,410 --> 00:09:36,670
some analysis on the evolution of

254
00:09:34,720 --> 00:09:40,180
families you need to have different

255
00:09:36,670 --> 00:09:43,030
abortions as well a second design goal

256
00:09:40,180 --> 00:09:45,459
was basically to have everything and

257
00:09:43,030 --> 00:09:46,870
then accessible format so it's it has to

258
00:09:45,460 --> 00:09:49,300
be easy to work with so that's very

259
00:09:46,870 --> 00:09:51,490
important and for me it was of utmost

260
00:09:49,300 --> 00:09:53,290
impatience to have unpacked samples

261
00:09:51,490 --> 00:09:54,370
because just putting labels on packed

262
00:09:53,290 --> 00:09:57,069
samples doesn't really help

263
00:09:54,370 --> 00:09:58,780
so unpack this cool and to some degree

264
00:09:57,070 --> 00:10:00,640
it also makes sense to clean an app

265
00:09:58,780 --> 00:10:02,530
because if you have process injection

266
00:10:00,640 --> 00:10:04,210
you might have some fragments that are

267
00:10:02,530 --> 00:10:06,579
not really related to the family but are

268
00:10:04,210 --> 00:10:08,500
still present in memory done that you're

269
00:10:06,580 --> 00:10:10,030
doing so you have to do some

270
00:10:08,500 --> 00:10:12,880
post-processing to you have actually

271
00:10:10,030 --> 00:10:16,060
really cool data and while we're on it

272
00:10:12,880 --> 00:10:17,500
um let's not just up with levels but do

273
00:10:16,060 --> 00:10:21,310
all of this just made our data think

274
00:10:17,500 --> 00:10:23,650
directly in the same run basically yeah

275
00:10:21,310 --> 00:10:25,839
and finally um I thought okay this

276
00:10:23,650 --> 00:10:28,000
should not be academically isolated so

277
00:10:25,840 --> 00:10:30,640
let's see if we can find some practical

278
00:10:28,000 --> 00:10:31,930
use with it as well so first off it

279
00:10:30,640 --> 00:10:34,090
probably has to be topical and

280
00:10:31,930 --> 00:10:35,829
maintainer so it's not just today now

281
00:10:34,090 --> 00:10:38,670
dump this the Soul corpus thing but I

282
00:10:35,830 --> 00:10:41,200
will try to have this maintained and

283
00:10:38,670 --> 00:10:43,900
basically that's the collaborative

284
00:10:41,200 --> 00:10:45,580
aspect to it and I invite basically all

285
00:10:43,900 --> 00:10:47,290
of you to contribute to this kind of

286
00:10:45,580 --> 00:10:50,050
repository because I guess it benefits

287
00:10:47,290 --> 00:10:51,459
all of us and finally it probably ought

288
00:10:50,050 --> 00:10:53,260
to make sense to provide some tooling so

289
00:10:51,460 --> 00:10:56,590
that you can basically work with it so

290
00:10:53,260 --> 00:10:58,780
for me it was quite important and that's

291
00:10:56,590 --> 00:11:00,520
still a lot of work to have good Yara

292
00:10:58,780 --> 00:11:02,199
coverage of all of the covers because

293
00:11:00,520 --> 00:11:05,140
that really helps us solve maybe this

294
00:11:02,200 --> 00:11:06,790
identification problem now finally I'm

295
00:11:05,140 --> 00:11:09,760
from of her that I'm working for

296
00:11:06,790 --> 00:11:11,349
as nonprofit organizations so we can

297
00:11:09,760 --> 00:11:13,900
step in to some degree as something

298
00:11:11,350 --> 00:11:17,710
vendor-neutral and maybe we can reach

299
00:11:13,900 --> 00:11:20,410
some consensual branch ophea okay let's

300
00:11:17,710 --> 00:11:22,450
go back to to Christians work so like I

301
00:11:20,410 --> 00:11:24,699
said it's basically a list of things to

302
00:11:22,450 --> 00:11:27,430
consider when you're doing experiments

303
00:11:24,700 --> 00:11:29,080
with malware and it's basically 18

304
00:11:27,430 --> 00:11:31,930
different aspects that are organized

305
00:11:29,080 --> 00:11:33,550
into four categories so first you want

306
00:11:31,930 --> 00:11:36,459
to ensure that you have the correct data

307
00:11:33,550 --> 00:11:39,219
set but that means you probably have to

308
00:11:36,460 --> 00:11:41,380
divide between good wear and malware

309
00:11:39,220 --> 00:11:42,700
that you want to keep balanced across

310
00:11:41,380 --> 00:11:44,890
the families that you're using a new

311
00:11:42,700 --> 00:11:47,260
experimentation that you separate

312
00:11:44,890 --> 00:11:48,850
training data from a relation data that

313
00:11:47,260 --> 00:11:51,130
you have to think about artifacts and a

314
00:11:48,850 --> 00:11:52,930
lot that kind of stuff and there's

315
00:11:51,130 --> 00:11:54,520
basically things to consider since we

316
00:11:52,930 --> 00:11:56,469
are building a malware corpus the the

317
00:11:54,520 --> 00:11:59,340
good path aspect and the experiment

318
00:11:56,470 --> 00:12:02,560
aspect to it basically does not really

319
00:11:59,340 --> 00:12:04,840
affect us but just there's some some

320
00:12:02,560 --> 00:12:07,209
good ideas to put in secondly you want

321
00:12:04,840 --> 00:12:09,220
to do transparency in how you publish

322
00:12:07,210 --> 00:12:10,900
the results so that means that you

323
00:12:09,220 --> 00:12:12,940
publish the data set that you explain

324
00:12:10,900 --> 00:12:14,530
where the labels are coming from which

325
00:12:12,940 --> 00:12:17,100
expert experiment setup we have been

326
00:12:14,530 --> 00:12:19,390
using and that you also do very

327
00:12:17,100 --> 00:12:21,160
scrutinized analysis of your results so

328
00:12:19,390 --> 00:12:22,630
when you do for example the

329
00:12:21,160 --> 00:12:24,910
classification method that you explain

330
00:12:22,630 --> 00:12:27,760
how true positives and false positives

331
00:12:24,910 --> 00:12:30,120
and false negatives basically constitute

332
00:12:27,760 --> 00:12:32,950
themselves and then why are happening

333
00:12:30,120 --> 00:12:34,810
then you want to do realism because you

334
00:12:32,950 --> 00:12:36,700
can live in your ivory tower and do all

335
00:12:34,810 --> 00:12:38,920
your isolated experiments that you want

336
00:12:36,700 --> 00:12:40,720
and if you want other people to use it

337
00:12:38,920 --> 00:12:41,920
you probably have to look at relevance

338
00:12:40,720 --> 00:12:43,660
and that means that you have to look at

339
00:12:41,920 --> 00:12:45,250
the real world and in that sense

340
00:12:43,660 --> 00:12:47,110
basically that the experiments should be

341
00:12:45,250 --> 00:12:48,760
designed in a way that's similar to come

342
00:12:47,110 --> 00:12:51,910
over basically encountered in the wild

343
00:12:48,760 --> 00:12:54,130
and finally safety is also something to

344
00:12:51,910 --> 00:12:57,730
consider because if you're working with

345
00:12:54,130 --> 00:12:59,740
malware you might potentially post harm

346
00:12:57,730 --> 00:13:01,240
to outside parties so you have to think

347
00:12:59,740 --> 00:13:05,020
about the deployment and containment

348
00:13:01,240 --> 00:13:08,470
that you have to put in place so for us

349
00:13:05,020 --> 00:13:10,960
um we basically came down to six things

350
00:13:08,470 --> 00:13:13,360
that we thought would be good

351
00:13:10,960 --> 00:13:15,310
requirements for the good novel corpus

352
00:13:13,360 --> 00:13:17,770
and it's basically limited to static

353
00:13:15,310 --> 00:13:18,760
analysis in that sense so I already said

354
00:13:17,770 --> 00:13:21,579
that so

355
00:13:18,760 --> 00:13:23,500
of content makes sense we want you to

356
00:13:21,579 --> 00:13:26,229
cross-platform because only doing

357
00:13:23,500 --> 00:13:28,870
Windows is kind of not no longer the

358
00:13:26,230 --> 00:13:32,050
time now unpack examples accurate labels

359
00:13:28,870 --> 00:13:34,360
do the documentation part because we

360
00:13:32,050 --> 00:13:36,910
want to explain how we came to the data

361
00:13:34,360 --> 00:13:40,300
and basically what the context of it and

362
00:13:36,910 --> 00:13:43,000
finally um that's something probably

363
00:13:40,300 --> 00:13:44,560
debatable but I think the creation

364
00:13:43,000 --> 00:13:46,540
should be controlled in a sense because

365
00:13:44,560 --> 00:13:48,760
I want to ensure that the format that

366
00:13:46,540 --> 00:13:51,279
we've been using to set up this corpus

367
00:13:48,760 --> 00:13:53,740
um still stays the same and stays intact

368
00:13:51,279 --> 00:13:56,769
and also this dissemination should be

369
00:13:53,740 --> 00:13:57,910
limited so it's not that you can just go

370
00:13:56,769 --> 00:14:01,240
to the website and download everything

371
00:13:57,910 --> 00:14:02,649
but we employ some basic vetting here so

372
00:14:01,240 --> 00:14:04,570
that we can at least to some degree

373
00:14:02,649 --> 00:14:10,600
ensure that the data is not flowing

374
00:14:04,570 --> 00:14:12,490
wildly so for presentative content um we

375
00:14:10,600 --> 00:14:15,160
want to look at relevant malware that

376
00:14:12,490 --> 00:14:18,160
means if you do it that way is probably

377
00:14:15,160 --> 00:14:20,500
also useful for for incident handlers or

378
00:14:18,160 --> 00:14:23,380
for other instances in the real world

379
00:14:20,500 --> 00:14:25,810
and that might be doing research

380
00:14:23,380 --> 00:14:27,910
one thing is we favor quality over

381
00:14:25,810 --> 00:14:29,709
quantity so it's it's not the goal

382
00:14:27,910 --> 00:14:34,810
basically to roll the corpus as fast as

383
00:14:29,709 --> 00:14:36,069
possible but rather look beyond what we

384
00:14:34,810 --> 00:14:40,479
can now call something that you pick up

385
00:14:36,069 --> 00:14:42,689
barrier so um if you look at how most

386
00:14:40,480 --> 00:14:44,889
campaigns are operated you will find

387
00:14:42,690 --> 00:14:47,199
polymorphism in in how packers are

388
00:14:44,889 --> 00:14:50,019
basically applied to to certain versions

389
00:14:47,199 --> 00:14:52,660
of malware but beyond this pickup area

390
00:14:50,019 --> 00:14:53,889
it comes down to way less different

391
00:14:52,660 --> 00:14:55,750
versions that you can actually observe

392
00:14:53,889 --> 00:14:57,360
in the wild and that means we can

393
00:14:55,750 --> 00:14:59,709
basically limit ourselves to only

394
00:14:57,360 --> 00:15:02,050
representants of a version for one

395
00:14:59,709 --> 00:15:04,630
family and that really is an aspect that

396
00:15:02,050 --> 00:15:08,019
helps down boiling down this data set to

397
00:15:04,630 --> 00:15:09,550
only DD necessary parts so just to give

398
00:15:08,019 --> 00:15:11,970
you an example for that and we've been

399
00:15:09,550 --> 00:15:15,579
doing another config data mining since

400
00:15:11,970 --> 00:15:16,660
2012 as well and if you look at Citadel

401
00:15:15,579 --> 00:15:19,329
for example which was a very popular

402
00:15:16,660 --> 00:15:22,529
family at that time we had run about

403
00:15:19,329 --> 00:15:24,880
100,000 unique cetera samples over time

404
00:15:22,529 --> 00:15:27,490
if you run all of them do dynamic

405
00:15:24,880 --> 00:15:29,880
analysis very similar to what we've seen

406
00:15:27,490 --> 00:15:32,850
bye-bye syrup yesterday

407
00:15:29,880 --> 00:15:34,560
you probably cannot identify many more

408
00:15:32,850 --> 00:15:36,990
than like twenty one versions for all of

409
00:15:34,560 --> 00:15:39,239
those samples so if you're only

410
00:15:36,990 --> 00:15:41,370
interested in archiving the code and the

411
00:15:39,240 --> 00:15:42,780
evolution of Citadella in that sense you

412
00:15:41,370 --> 00:15:44,990
can probably achieve a data reduction

413
00:15:42,780 --> 00:15:47,400
factor of maybe four and a half thousand

414
00:15:44,990 --> 00:15:48,780
so in that sense we would not be

415
00:15:47,400 --> 00:15:50,730
interested in in storing all of the

416
00:15:48,780 --> 00:15:52,410
Citadelle samples but only one per

417
00:15:50,730 --> 00:15:53,940
version and that's something that you

418
00:15:52,410 --> 00:15:55,560
can also observe for for a bunch of

419
00:15:53,940 --> 00:15:57,270
other families as well so there's

420
00:15:55,560 --> 00:15:58,229
there's a huge amount of timber going

421
00:15:57,270 --> 00:16:00,150
around s procs

422
00:15:58,230 --> 00:16:01,560
but there's normally only some

423
00:16:00,150 --> 00:16:04,980
mainstream versions because they are

424
00:16:01,560 --> 00:16:06,449
maintained by some novel author and then

425
00:16:04,980 --> 00:16:08,520
he has to basically publish that as well

426
00:16:06,450 --> 00:16:09,840
and that basically ensures that there's

427
00:16:08,520 --> 00:16:11,100
not that much flowing around so

428
00:16:09,840 --> 00:16:13,850
basically this is called maintenance

429
00:16:11,100 --> 00:16:17,130
aspect that you have on the side of a

430
00:16:13,850 --> 00:16:19,170
normal malware developer basically

431
00:16:17,130 --> 00:16:21,660
effects them as well so they probably

432
00:16:19,170 --> 00:16:24,300
have to have some distribution channels

433
00:16:21,660 --> 00:16:26,280
and are not as fast as pushing versions

434
00:16:24,300 --> 00:16:29,040
or it is not if you look at trust all of

435
00:16:26,280 --> 00:16:32,970
the MLB landscape yeah cross-platform

436
00:16:29,040 --> 00:16:34,589
yes 2017 so let's be real we had some

437
00:16:32,970 --> 00:16:36,330
major incidents over the last year that

438
00:16:34,590 --> 00:16:40,230
basically affected monitor system so

439
00:16:36,330 --> 00:16:42,030
just do it that way so be it Mirai Lukas

440
00:16:40,230 --> 00:16:44,220
is basically twittering a lot about

441
00:16:42,030 --> 00:16:46,290
recent mother on Android and stuff like

442
00:16:44,220 --> 00:16:46,880
that so just incorporate all of that as

443
00:16:46,290 --> 00:16:50,699
well

444
00:16:46,880 --> 00:16:52,470
for unpacked samples um there's

445
00:16:50,700 --> 00:16:54,150
basically essentially if you want to do

446
00:16:52,470 --> 00:16:55,920
effective static analysis because you

447
00:16:54,150 --> 00:16:57,720
don't want to worry about Packers you

448
00:16:55,920 --> 00:16:59,130
just directly want to be sure that

449
00:16:57,720 --> 00:17:02,580
you're working on the actual maverick

450
00:16:59,130 --> 00:17:05,760
code and yet discuss discussable if you

451
00:17:02,580 --> 00:17:07,500
want to do dumping or unpacking and my

452
00:17:05,760 --> 00:17:09,810
opinion the dumping is actually a better

453
00:17:07,500 --> 00:17:12,449
way to approach this because normally

454
00:17:09,810 --> 00:17:14,129
some of the intermediates parts that may

455
00:17:12,449 --> 00:17:16,350
be acquired during the unpacking process

456
00:17:14,130 --> 00:17:19,140
of the Packer itself are not really of

457
00:17:16,349 --> 00:17:22,139
interest unless you are doing analysis

458
00:17:19,140 --> 00:17:25,050
of Packers and dumps usually also

459
00:17:22,140 --> 00:17:27,060
contain some more runtime data and this

460
00:17:25,050 --> 00:17:29,669
can be decrypted strings at times you

461
00:17:27,060 --> 00:17:31,950
may may have some dynamic API usage so

462
00:17:29,670 --> 00:17:34,440
basically you have saw more API coverage

463
00:17:31,950 --> 00:17:37,160
then you would have any cleany disk

464
00:17:34,440 --> 00:17:39,150
unpacked sample and do not have to vary

465
00:17:37,160 --> 00:17:41,430
finding the routine that's basically

466
00:17:39,150 --> 00:17:45,029
doing DD api imports and stuff like that

467
00:17:41,430 --> 00:17:46,590
and there's also way easier to autumn

468
00:17:45,029 --> 00:17:48,630
because like I said you can normally

469
00:17:46,590 --> 00:17:49,668
just run it at a certain point decide

470
00:17:48,630 --> 00:17:52,890
that you want to take it down now

471
00:17:49,669 --> 00:17:54,899
furthermore I think dumps also can serve

472
00:17:52,890 --> 00:17:56,399
as some kind of normalization because

473
00:17:54,899 --> 00:17:59,520
there's certain other families that only

474
00:17:56,399 --> 00:18:01,739
exist as share code so having them honor

475
00:17:59,520 --> 00:18:03,960
this basically would mean that you have

476
00:18:01,740 --> 00:18:05,820
to find that exact point where desert

477
00:18:03,960 --> 00:18:07,860
share code is staged by some loader into

478
00:18:05,820 --> 00:18:09,750
memory or whatever but if you say okay

479
00:18:07,860 --> 00:18:11,100
I'm really just interested in dumping it

480
00:18:09,750 --> 00:18:12,870
then basically I have the same

481
00:18:11,100 --> 00:18:14,580
representation which is memory mapped

482
00:18:12,870 --> 00:18:16,469
and initialized for the share code and

483
00:18:14,580 --> 00:18:19,710
for every other program basically as

484
00:18:16,470 --> 00:18:23,190
well yeah accurate neighbors and

485
00:18:19,710 --> 00:18:25,350
metadata so basically this whole project

486
00:18:23,190 --> 00:18:28,919
is somewhat centered around family

487
00:18:25,350 --> 00:18:30,600
identification so that means we first

488
00:18:28,919 --> 00:18:33,750
need to find some accurate labels for

489
00:18:30,600 --> 00:18:35,580
the families in the first place but also

490
00:18:33,750 --> 00:18:37,470
there should be for example plugins

491
00:18:35,580 --> 00:18:39,240
checked if we are able to find those

492
00:18:37,470 --> 00:18:41,669
plugins so say you are you have a

493
00:18:39,240 --> 00:18:43,409
banking malware which is different

494
00:18:41,669 --> 00:18:45,600
information stealer plugins and we're

495
00:18:43,409 --> 00:18:46,640
also interested in to archiving those as

496
00:18:45,600 --> 00:18:49,949
well

497
00:18:46,640 --> 00:18:51,929
documentation yeah like I said so

498
00:18:49,950 --> 00:18:54,390
looking at Christians proven practices

499
00:18:51,929 --> 00:18:56,580
basically explaining how we got to the

500
00:18:54,390 --> 00:18:58,380
dumps is something of importance or

501
00:18:56,580 --> 00:19:01,320
basically where we are getting the

502
00:18:58,380 --> 00:19:03,029
samples from so that basically allows to

503
00:19:01,320 --> 00:19:04,649
ensure that we have accountability and

504
00:19:03,029 --> 00:19:07,049
repository bility so when we are doing

505
00:19:04,649 --> 00:19:08,070
experiments you can do them as well and

506
00:19:07,049 --> 00:19:09,570
hopefully we end up with the same

507
00:19:08,070 --> 00:19:12,000
results

508
00:19:09,570 --> 00:19:14,460
tracking the origin of samples normally

509
00:19:12,000 --> 00:19:18,690
means since I get most of the samples

510
00:19:14,460 --> 00:19:20,940
from publications of AV companies thread

511
00:19:18,690 --> 00:19:22,980
into companies and they like I probably

512
00:19:20,940 --> 00:19:24,360
try to include a reference where

513
00:19:22,980 --> 00:19:27,000
basically got aware of the hash in the

514
00:19:24,360 --> 00:19:29,309
first place and explaining the dumping

515
00:19:27,000 --> 00:19:32,279
method and environment stuff we we get

516
00:19:29,309 --> 00:19:34,139
into debt in a couple of minutes yeah

517
00:19:32,279 --> 00:19:37,529
controlled creation and dissemination so

518
00:19:34,140 --> 00:19:39,840
the last point here like I said we want

519
00:19:37,529 --> 00:19:42,570
to ensure that the structure of the

520
00:19:39,840 --> 00:19:44,070
whole repository stays intact even over

521
00:19:42,570 --> 00:19:45,809
the course of time with having more

522
00:19:44,070 --> 00:19:48,720
users and having them contribute to the

523
00:19:45,809 --> 00:19:51,090
data and limiting access is basically

524
00:19:48,720 --> 00:19:53,220
needed to avoid harm to the general

525
00:19:51,090 --> 00:19:55,379
public because if you just download the

526
00:19:53,220 --> 00:19:57,270
stuff let it run that's probably not a

527
00:19:55,380 --> 00:19:59,130
good idea or you might have some use

528
00:19:57,270 --> 00:20:00,810
that are not really into familiar with

529
00:19:59,130 --> 00:20:02,850
how you treat malware and they might

530
00:20:00,810 --> 00:20:04,020
just download in a double-click it and I

531
00:20:02,850 --> 00:20:05,689
don't want to be blamed for that kind of

532
00:20:04,020 --> 00:20:08,970
stuff okay

533
00:20:05,690 --> 00:20:11,790
so how are we going to put this now into

534
00:20:08,970 --> 00:20:13,560
practice I will first explain some of

535
00:20:11,790 --> 00:20:15,690
the terminology so basically what I mean

536
00:20:13,560 --> 00:20:17,520
if I call something a family or

537
00:20:15,690 --> 00:20:19,740
something is unpacked and stuff like

538
00:20:17,520 --> 00:20:21,330
that then I explain the collection

539
00:20:19,740 --> 00:20:23,880
approach again in some more detail and

540
00:20:21,330 --> 00:20:26,820
are we produced or stamps and finally

541
00:20:23,880 --> 00:20:28,860
how the course is organized so if you're

542
00:20:26,820 --> 00:20:31,770
later on working with it so that's

543
00:20:28,860 --> 00:20:34,110
probably of interest to you and also how

544
00:20:31,770 --> 00:20:39,810
much data we already have in there right

545
00:20:34,110 --> 00:20:42,510
now so what's another family it's from a

546
00:20:39,810 --> 00:20:44,909
modern standpoint I guess it's not

547
00:20:42,510 --> 00:20:46,800
really cleanly defined what a malware

548
00:20:44,910 --> 00:20:50,760
family is and everyone probably has

549
00:20:46,800 --> 00:20:53,010
their slight different fuzzy definition

550
00:20:50,760 --> 00:20:55,080
of it so I'm just going to try and give

551
00:20:53,010 --> 00:20:57,629
you my current definition where the meta

552
00:20:55,080 --> 00:20:59,250
family is so basically all samples that

553
00:20:57,630 --> 00:21:01,500
you can find that belong to the same

554
00:20:59,250 --> 00:21:04,530
project from a developer's point of view

555
00:21:01,500 --> 00:21:06,690
so basically the way we are tracking

556
00:21:04,530 --> 00:21:10,110
families means that someone normally has

557
00:21:06,690 --> 00:21:11,910
the responsibility has created the code

558
00:21:10,110 --> 00:21:14,030
is maintaining the code and that's

559
00:21:11,910 --> 00:21:16,430
basically what defines a family for me

560
00:21:14,030 --> 00:21:20,670
what this allows you is that you can

561
00:21:16,430 --> 00:21:23,160
basically also group those components to

562
00:21:20,670 --> 00:21:25,140
this family that only work in context of

563
00:21:23,160 --> 00:21:27,750
the family so be it some customized

564
00:21:25,140 --> 00:21:29,250
loader some plugins that are interacting

565
00:21:27,750 --> 00:21:31,770
with the the main module of the family

566
00:21:29,250 --> 00:21:33,240
and stuff like that but it also allows

567
00:21:31,770 --> 00:21:35,580
you to basically deal with stuff like

568
00:21:33,240 --> 00:21:37,080
source code leaks so look at Zeus I'm

569
00:21:35,580 --> 00:21:38,730
not going to call everything

570
00:21:37,080 --> 00:21:41,280
Zeus that's basically derived from Zeus

571
00:21:38,730 --> 00:21:43,590
so we can split off stuff like Citadel

572
00:21:41,280 --> 00:21:47,340
isin and came over Peter peer-led later

573
00:21:43,590 --> 00:21:48,870
stuff in the same way you can also look

574
00:21:47,340 --> 00:21:51,120
at the same project that has been a

575
00:21:48,870 --> 00:21:54,419
rewrite so there's a couple of families

576
00:21:51,120 --> 00:21:57,060
in there like three or four I guess that

577
00:21:54,420 --> 00:21:59,010
basically are the very same malware but

578
00:21:57,060 --> 00:22:00,870
rewritten in another language so you

579
00:21:59,010 --> 00:22:02,910
would have someone start off with Delfy

580
00:22:00,870 --> 00:22:05,040
and suddenly he thinks it's cooler so he

581
00:22:02,910 --> 00:22:08,550
rewrites this bar in the same way just

582
00:22:05,040 --> 00:22:09,629
in in C for example what's an unpacked

583
00:22:08,550 --> 00:22:12,330
sample

584
00:22:09,630 --> 00:22:15,150
so for me that's a direct representative

585
00:22:12,330 --> 00:22:18,000
of the family so there's no longer other

586
00:22:15,150 --> 00:22:20,100
third party code involved that's usually

587
00:22:18,000 --> 00:22:22,950
used to protect or obfuscate or whatever

588
00:22:20,100 --> 00:22:26,399
you want it so I'm third party in that

589
00:22:22,950 --> 00:22:27,990
sense basically I have another family or

590
00:22:26,400 --> 00:22:29,429
maybe a sample that I've created with

591
00:22:27,990 --> 00:22:32,370
the Builder and then apply the Packer to

592
00:22:29,429 --> 00:22:34,230
it the amp example would be basically

593
00:22:32,370 --> 00:22:37,110
again the sample without the background

594
00:22:34,230 --> 00:22:39,360
stuff however this does not include for

595
00:22:37,110 --> 00:22:41,100
example addressing deification so if the

596
00:22:39,360 --> 00:22:43,918
obfuscation is part of the mother family

597
00:22:41,100 --> 00:22:45,809
itself unpacking to me does not mean

598
00:22:43,919 --> 00:22:47,400
that I have to remove this office Keshan

599
00:22:45,809 --> 00:22:50,309
because it's basically a feature of the

600
00:22:47,400 --> 00:22:54,200
family and for example can can help to

601
00:22:50,309 --> 00:22:57,389
identify it and from a classic sense

602
00:22:54,200 --> 00:22:59,220
because that's just basically how I when

603
00:22:57,390 --> 00:23:00,659
I got into it but what we meant when

604
00:22:59,220 --> 00:23:02,220
we're talking about unpack now where it

605
00:23:00,659 --> 00:23:05,280
would be something that you are able to

606
00:23:02,220 --> 00:23:07,830
run from disk again so basically the

607
00:23:05,280 --> 00:23:09,570
probably unmapped version that's on this

608
00:23:07,830 --> 00:23:12,600
you double-click it and NMFS running

609
00:23:09,570 --> 00:23:14,668
directly opposed to that what's dump

610
00:23:12,600 --> 00:23:17,428
sample well with the memory capture of

611
00:23:14,669 --> 00:23:19,350
the malware and normally will then

612
00:23:17,429 --> 00:23:21,210
include some initialized data and that's

613
00:23:19,350 --> 00:23:23,399
an issue if you want to go back to the

614
00:23:21,210 --> 00:23:25,650
the unpacked runnable sampler from from

615
00:23:23,400 --> 00:23:27,900
a dump sample you normally or sometimes

616
00:23:25,650 --> 00:23:31,140
after the point at this initial data

617
00:23:27,900 --> 00:23:32,429
initialized data basically will

618
00:23:31,140 --> 00:23:35,789
interfere with you in the sample will

619
00:23:32,429 --> 00:23:38,340
just crash but dumping can also include

620
00:23:35,789 --> 00:23:40,799
that you look at some oxidative modules

621
00:23:38,340 --> 00:23:44,010
that amalgam I have or some of the other

622
00:23:40,799 --> 00:23:46,049
memory that it has allocated weights for

623
00:23:44,010 --> 00:23:47,970
example storing some of its imports or

624
00:23:46,049 --> 00:23:50,900
some additional codes that it is jumping

625
00:23:47,970 --> 00:23:54,960
to and that you also track that as well

626
00:23:50,900 --> 00:23:58,740
so once more tests this quality over

627
00:23:54,960 --> 00:24:01,020
quantity thing the philosophy that I've

628
00:23:58,740 --> 00:24:03,570
been pursuing as I rather want to extend

629
00:24:01,020 --> 00:24:06,570
the coverage as many families right now

630
00:24:03,570 --> 00:24:10,530
as possible then going deep into a

631
00:24:06,570 --> 00:24:12,570
single family so I could basically say I

632
00:24:10,530 --> 00:24:14,190
want to have the best coverage of dried

633
00:24:12,570 --> 00:24:16,830
eggs and trick bottom what but it would

634
00:24:14,190 --> 00:24:20,010
probably take a lot of my time that I

635
00:24:16,830 --> 00:24:21,960
can allocate to things and right now

636
00:24:20,010 --> 00:24:23,700
still the ideas to get a good coverage

637
00:24:21,960 --> 00:24:25,950
in in the white sense

638
00:24:23,700 --> 00:24:28,110
so that's basically this dis quality

639
00:24:25,950 --> 00:24:31,590
thing that you can use it to identify as

640
00:24:28,110 --> 00:24:34,340
many different families as possible just

641
00:24:31,590 --> 00:24:36,870
a stronger emphasis on verification then

642
00:24:34,340 --> 00:24:39,510
by now I've been doing a lot of manual

643
00:24:36,870 --> 00:24:42,120
work to ensure the basically this is a

644
00:24:39,510 --> 00:24:45,330
very clean corpus so that's also a way

645
00:24:42,120 --> 00:24:48,389
to push quality but a lot of effort let

646
00:24:45,330 --> 00:24:50,639
me tell you that it can also mean that

647
00:24:48,390 --> 00:24:53,790
we prioritize on families that are more

648
00:24:50,640 --> 00:24:55,710
active or more impactful normally I'm

649
00:24:53,790 --> 00:24:57,720
somewhat following my filter bubble and

650
00:24:55,710 --> 00:25:00,690
look at the blog posted I would normally

651
00:24:57,720 --> 00:25:03,000
encounter and probably prefer those as

652
00:25:00,690 --> 00:25:05,820
well so by having more contributors

653
00:25:03,000 --> 00:25:10,130
probably this basically will have the

654
00:25:05,820 --> 00:25:14,760
impact of widening what we consider as

655
00:25:10,130 --> 00:25:16,560
something should be prioritized in the

656
00:25:14,760 --> 00:25:18,810
long run it is a really good idea to

657
00:25:16,560 --> 00:25:20,610
write some means of quality assurance so

658
00:25:18,810 --> 00:25:22,440
say you have a Yara rule for every of

659
00:25:20,610 --> 00:25:24,600
the families you can also ensure that

660
00:25:22,440 --> 00:25:26,850
your yards do not have false positives

661
00:25:24,600 --> 00:25:28,669
on other families and in the same way

662
00:25:26,850 --> 00:25:30,959
that they are still recently enough to

663
00:25:28,670 --> 00:25:33,630
find new versions whenever you add them

664
00:25:30,960 --> 00:25:34,710
to the corpus and we've got two data

665
00:25:33,630 --> 00:25:37,650
origins

666
00:25:34,710 --> 00:25:40,680
I prefer public sources where possible

667
00:25:37,650 --> 00:25:42,510
and basically everything that similar

668
00:25:40,680 --> 00:25:46,320
PDS also found a virustotal so it's like

669
00:25:42,510 --> 00:25:47,910
97% so I really want to have stuff that

670
00:25:46,320 --> 00:25:53,040
can be obtained in another fashion as

671
00:25:47,910 --> 00:25:55,260
well okay I said we do multi-platform

672
00:25:53,040 --> 00:25:57,960
stuff because it makes sense to track

673
00:25:55,260 --> 00:25:59,430
that as as we are progressing but I'm

674
00:25:57,960 --> 00:26:01,080
still having a strong focus on Windows

675
00:25:59,430 --> 00:26:02,910
malware because there's at least where

676
00:26:01,080 --> 00:26:05,010
the most families are still documented

677
00:26:02,910 --> 00:26:07,560
where we have the most history so that's

678
00:26:05,010 --> 00:26:10,470
basically what I've been focusing on

679
00:26:07,560 --> 00:26:12,659
with the doms the method that I employ

680
00:26:10,470 --> 00:26:14,940
there is basically to have very fixed VM

681
00:26:12,660 --> 00:26:18,870
states that I used to derive the doms

682
00:26:14,940 --> 00:26:20,580
from and what's the benefit of that well

683
00:26:18,870 --> 00:26:22,709
I have very known and fixed system

684
00:26:20,580 --> 00:26:26,070
parameters to it so for example even if

685
00:26:22,710 --> 00:26:28,500
it's using a SLR most of the static

686
00:26:26,070 --> 00:26:30,600
windows API function offsets will remain

687
00:26:28,500 --> 00:26:31,950
the same in all of the different memory

688
00:26:30,600 --> 00:26:34,560
segments that you will encounter them

689
00:26:31,950 --> 00:26:35,879
and this allows you to apply some

690
00:26:34,560 --> 00:26:39,059
techniques

691
00:26:35,879 --> 00:26:41,009
to rapidly extract those windows API

692
00:26:39,059 --> 00:26:42,529
functions on arbitrary dumps as long as

693
00:26:41,009 --> 00:26:45,389
they have to be produced by this

694
00:26:42,529 --> 00:26:49,109
basically environment so I'm using

695
00:26:45,389 --> 00:26:51,658
mostly Windows XP and Windows 7 and no

696
00:26:49,109 --> 00:26:53,968
one's gasping but it's so oh it why are

697
00:26:51,659 --> 00:26:57,179
using like with operating systems that

698
00:26:53,969 --> 00:26:59,190
are like more than 10 years old it's

699
00:26:57,179 --> 00:27:01,079
pretty easy because it still feels like

700
00:26:59,190 --> 00:27:03,589
most novice feeling most at home there

701
00:27:01,079 --> 00:27:05,668
because you have fewer embedded

702
00:27:03,589 --> 00:27:10,369
protection systems by the operating

703
00:27:05,669 --> 00:27:12,899
system directly so my goal is basically

704
00:27:10,369 --> 00:27:15,958
maximizing execution success so I want

705
00:27:12,899 --> 00:27:19,649
to have the most vulnerable system

706
00:27:15,959 --> 00:27:21,539
darris and that works kind of good as

707
00:27:19,649 --> 00:27:24,178
well what can you do as well of course

708
00:27:21,539 --> 00:27:25,619
you should install all the runtimes you

709
00:27:24,179 --> 00:27:28,289
want to have all the dotnet runtimes

710
00:27:25,619 --> 00:27:30,418
because you really have to give you

711
00:27:28,289 --> 00:27:32,249
malware a place to feel home and it has

712
00:27:30,419 --> 00:27:34,019
to run and has not a crash so I'm really

713
00:27:32,249 --> 00:27:35,639
interested in producing dumps so I have

714
00:27:34,019 --> 00:27:38,940
to make it for the memory as easy as

715
00:27:35,639 --> 00:27:41,789
possible to run you have a three are two

716
00:27:38,940 --> 00:27:44,519
dumping our methodologies is pretty

717
00:27:41,789 --> 00:27:46,019
simple I guess you just run it wait if

718
00:27:44,519 --> 00:27:47,429
the memory that has basically changed

719
00:27:46,019 --> 00:27:50,099
during execution and then filter down to

720
00:27:47,429 --> 00:27:52,379
what you think is the unpacked version

721
00:27:50,099 --> 00:27:53,939
so basically the dump and then you

722
00:27:52,379 --> 00:27:55,799
potentially repeat it because you missed

723
00:27:53,940 --> 00:27:59,909
something or there's nothing to

724
00:27:55,799 --> 00:28:02,209
basically extract or what frequently

725
00:27:59,909 --> 00:28:05,190
happens you have to inject manually and

726
00:28:02,209 --> 00:28:07,649
that's quite painful so um if I had to

727
00:28:05,190 --> 00:28:10,709
guess I guess I've spent more than 600

728
00:28:07,649 --> 00:28:13,978
hours of doing this unpacking and

729
00:28:10,709 --> 00:28:17,099
dumping already so on the other hand I

730
00:28:13,979 --> 00:28:18,959
think that's sadly the only way how to

731
00:28:17,099 --> 00:28:21,178
get dumped for some of the families

732
00:28:18,959 --> 00:28:22,739
because what you can observe there's

733
00:28:21,179 --> 00:28:24,449
basically something it gets mapped is

734
00:28:22,739 --> 00:28:26,999
fingerprinting your environment and will

735
00:28:24,449 --> 00:28:28,739
unwrap itself if it's not happy and

736
00:28:26,999 --> 00:28:31,319
that's totally something that most sand

737
00:28:28,739 --> 00:28:33,329
boxes will not give you or even if they

738
00:28:31,319 --> 00:28:35,609
gave it to you you might just drown in

739
00:28:33,329 --> 00:28:38,819
the data so I've quite some experience I

740
00:28:35,609 --> 00:28:40,589
guess with unpacking and stuff so in

741
00:28:38,819 --> 00:28:43,139
many cases it was more natural to me to

742
00:28:40,589 --> 00:28:47,849
just look quickly at something and then

743
00:28:43,139 --> 00:28:49,649
try to cover it up that way in many

744
00:28:47,849 --> 00:28:51,750
cases what you can dump there

745
00:28:49,650 --> 00:28:53,610
already fine but sometimes like I said

746
00:28:51,750 --> 00:28:55,200
you will have some overlay or for

747
00:28:53,610 --> 00:28:56,550
example the packet sample and the amp

748
00:28:55,200 --> 00:28:58,380
example in the beginning of the same

749
00:28:56,550 --> 00:29:00,000
buffer or something so it makes sense to

750
00:28:58,380 --> 00:29:01,320
basically cut off the tail and things

751
00:29:00,000 --> 00:29:03,450
like that in order to to clean up the

752
00:29:01,320 --> 00:29:05,970
malware because if you're later applying

753
00:29:03,450 --> 00:29:07,470
static analysis methods to it you really

754
00:29:05,970 --> 00:29:09,150
only want the coat of the extra mega

755
00:29:07,470 --> 00:29:10,160
family and not the chef that's basically

756
00:29:09,150 --> 00:29:13,650
on its tail

757
00:29:10,160 --> 00:29:15,360
yeah for identification um yeah the

758
00:29:13,650 --> 00:29:17,070
better your coverage is the faster you

759
00:29:15,360 --> 00:29:18,840
can do it otherwise it's also manual

760
00:29:17,070 --> 00:29:20,850
investigation has someone basically

761
00:29:18,840 --> 00:29:22,139
blocked somewhere about those strings

762
00:29:20,850 --> 00:29:26,219
that I've just found in this buffer that

763
00:29:22,140 --> 00:29:28,320
I'm looking at so a lot of work so let's

764
00:29:26,220 --> 00:29:30,810
of Michelle if you're interested in how

765
00:29:28,320 --> 00:29:33,270
the data is stored basically it's it's

766
00:29:30,810 --> 00:29:35,129
more or less this tree like structure so

767
00:29:33,270 --> 00:29:37,110
on top level you would have platform dot

768
00:29:35,130 --> 00:29:38,250
family name and for example let's take

769
00:29:37,110 --> 00:29:40,620
you also on something that I'm very

770
00:29:38,250 --> 00:29:42,540
familiar with because I have been

771
00:29:40,620 --> 00:29:44,989
looking at it for a couple years

772
00:29:42,540 --> 00:29:47,310
below the family folder you would have

773
00:29:44,990 --> 00:29:48,900
ideally folders perversion

774
00:29:47,310 --> 00:29:52,050
so that basically allows you a direct

775
00:29:48,900 --> 00:29:56,640
grouping in those folders you would have

776
00:29:52,050 --> 00:29:58,649
samples stored as 256 and along them we

777
00:29:56,640 --> 00:30:00,150
would have the dumps with basically the

778
00:29:58,650 --> 00:30:02,700
base address from where they have been

779
00:30:00,150 --> 00:30:05,520
dumped as well as unpacked samples in

780
00:30:02,700 --> 00:30:07,200
some cases not all cases and that's

781
00:30:05,520 --> 00:30:09,660
basically the whole repository structure

782
00:30:07,200 --> 00:30:12,150
for all of the data that's right right

783
00:30:09,660 --> 00:30:13,680
now in there along with the data we have

784
00:30:12,150 --> 00:30:15,540
a JSON file that gives you some meta

785
00:30:13,680 --> 00:30:17,760
information like the block reference

786
00:30:15,540 --> 00:30:20,310
that I've just mentioned the last time

787
00:30:17,760 --> 00:30:22,560
it was updated aliases for the family

788
00:30:20,310 --> 00:30:25,379
actors that have been observed using the

789
00:30:22,560 --> 00:30:27,450
family and all that kind of stuff

790
00:30:25,380 --> 00:30:31,080
for many of them there's also the Yarra

791
00:30:27,450 --> 00:30:33,420
folder sorted by DLP with roots in there

792
00:30:31,080 --> 00:30:35,399
so basically everything beyond TP whites

793
00:30:33,420 --> 00:30:37,980
are already contributions by users of

794
00:30:35,400 --> 00:30:41,220
the framework and you would have one

795
00:30:37,980 --> 00:30:42,170
yarra file per Yarra rule because it

796
00:30:41,220 --> 00:30:44,600
also eases

797
00:30:42,170 --> 00:30:47,520
versioning and management of the stuff

798
00:30:44,600 --> 00:30:50,520
so now the good thing about this kind of

799
00:30:47,520 --> 00:30:52,770
file system like structure is this is

800
00:30:50,520 --> 00:30:54,720
basically our git repository format so

801
00:30:52,770 --> 00:30:57,480
if you want to have the data set it's as

802
00:30:54,720 --> 00:30:59,370
easy as doing git clone and you have all

803
00:30:57,480 --> 00:31:02,280
of the data at once and if you want to

804
00:30:59,370 --> 00:31:03,179
do updates you do a pull request yet you

805
00:31:02,280 --> 00:31:04,830
get pull and then

806
00:31:03,180 --> 00:31:07,140
you have the most recent version of it

807
00:31:04,830 --> 00:31:09,179
so it was our vision of having it in a

808
00:31:07,140 --> 00:31:10,860
convenient way so that you can do the

809
00:31:09,180 --> 00:31:17,280
same experiments or whatever you want to

810
00:31:10,860 --> 00:31:18,870
like with the data set so this commit as

811
00:31:17,280 --> 00:31:20,190
shown there is basically the route

812
00:31:18,870 --> 00:31:21,719
commit and it's also the commit that

813
00:31:20,190 --> 00:31:24,360
we've been using for our of the analysis

814
00:31:21,720 --> 00:31:27,870
that I'm going to show in a few minutes

815
00:31:24,360 --> 00:31:30,929
and this at that time was based on 17 or

816
00:31:27,870 --> 00:31:33,169
almost 1,800 samples with run about 600

817
00:31:30,930 --> 00:31:35,400
families if we look at the distribution

818
00:31:33,170 --> 00:31:37,980
and of course we notice the majority

819
00:31:35,400 --> 00:31:40,260
that's also probably the reason why I'm

820
00:31:37,980 --> 00:31:41,070
because I'm feeling most at home with

821
00:31:40,260 --> 00:31:44,100
Windows malware

822
00:31:41,070 --> 00:31:45,570
I normally try to include Android

823
00:31:44,100 --> 00:31:46,949
whenever I see someone talking about

824
00:31:45,570 --> 00:31:48,510
Android malware and stuff like that and

825
00:31:46,950 --> 00:31:50,760
and same for the other families and

826
00:31:48,510 --> 00:31:54,240
everything was basically multi-platform

827
00:31:50,760 --> 00:31:55,890
is written in Java or some JavaScript

828
00:31:54,240 --> 00:31:57,930
like for example used by Tola and stuff

829
00:31:55,890 --> 00:32:00,960
like that so basically Chrome extensions

830
00:31:57,930 --> 00:32:06,120
are not we've got to unpacking and

831
00:32:00,960 --> 00:32:08,670
dumping about 90% of the window stuff is

832
00:32:06,120 --> 00:32:10,469
actually at least from a family

833
00:32:08,670 --> 00:32:12,240
perspective dump with at least one dump

834
00:32:10,470 --> 00:32:14,040
so sometimes our families we have

835
00:32:12,240 --> 00:32:16,470
multiple samples but only one dump

836
00:32:14,040 --> 00:32:19,080
because like I said quality or coverage

837
00:32:16,470 --> 00:32:22,740
first in that sense I want at least one

838
00:32:19,080 --> 00:32:24,720
representative for it and Jefferson are

839
00:32:22,740 --> 00:32:27,840
just unpacked so also gathers probably

840
00:32:24,720 --> 00:32:31,290
75% of the samples are definitely in

841
00:32:27,840 --> 00:32:34,139
some unpacked state yeah so those 24

842
00:32:31,290 --> 00:32:36,120
percent are missing right now okay so

843
00:32:34,140 --> 00:32:38,070
how do we make this stuff accessible I

844
00:32:36,120 --> 00:32:39,770
already ate said to you that this just

845
00:32:38,070 --> 00:32:43,439
get repository that you can check out

846
00:32:39,770 --> 00:32:46,050
but just also website because the title

847
00:32:43,440 --> 00:32:48,090
was basically a collaborative approach

848
00:32:46,050 --> 00:32:49,740
to it so first let me start with the

849
00:32:48,090 --> 00:32:51,449
mission statement what I want to

850
00:32:49,740 --> 00:32:53,670
basically achieve with this map edia

851
00:32:51,450 --> 00:32:55,170
thing and then explain some of the the

852
00:32:53,670 --> 00:32:58,170
trust mechanisms that we have

853
00:32:55,170 --> 00:33:00,360
implemented in order to ensure basically

854
00:32:58,170 --> 00:33:03,330
access limitation and also contribution

855
00:33:00,360 --> 00:33:05,939
quality defects of it that's listed

856
00:33:03,330 --> 00:33:07,919
there is already accessible so if I'm

857
00:33:05,940 --> 00:33:10,140
just going to fast you can also I think

858
00:33:07,920 --> 00:33:12,360
just go to on Google and or research

859
00:33:10,140 --> 00:33:15,960
from a PDF it should show up in the top

860
00:33:12,360 --> 00:33:16,949
five I guess so the the primary goal as

861
00:33:15,960 --> 00:33:19,170
I said for this

862
00:33:16,950 --> 00:33:21,450
project as a whole is basically to

863
00:33:19,170 --> 00:33:24,210
provide a community driven independent

864
00:33:21,450 --> 00:33:26,130
resource for this whole identification

865
00:33:24,210 --> 00:33:27,510
stuff so basically if you have an

866
00:33:26,130 --> 00:33:31,500
account on there you can propose changes

867
00:33:27,510 --> 00:33:33,030
to the data set so if you know of a

868
00:33:31,500 --> 00:33:34,950
family that's currently not in there you

869
00:33:33,030 --> 00:33:36,899
can propose it if you have some samples

870
00:33:34,950 --> 00:33:38,520
for a family that I don't have or

871
00:33:36,900 --> 00:33:40,080
versions that you have identified and

872
00:33:38,520 --> 00:33:43,110
just want to see them in the data set as

873
00:33:40,080 --> 00:33:45,270
well you can do all of that so basically

874
00:33:43,110 --> 00:33:46,590
what's then happening is there's a group

875
00:33:45,270 --> 00:33:49,170
of peer reviewers that will basically

876
00:33:46,590 --> 00:33:52,139
review your contribution and then

877
00:33:49,170 --> 00:33:54,270
there's probably accepted or otherwise

878
00:33:52,140 --> 00:33:56,220
rejected with a note what you should

879
00:33:54,270 --> 00:33:57,990
improve in order to have it in there so

880
00:33:56,220 --> 00:34:00,750
basically just how you would submit

881
00:33:57,990 --> 00:34:03,480
stuff to a conference or similar we are

882
00:34:00,750 --> 00:34:06,240
opting the traffic live protocol mock

883
00:34:03,480 --> 00:34:07,740
just his personal experiences with that

884
00:34:06,240 --> 00:34:10,560
and I hope it's the turning or better

885
00:34:07,740 --> 00:34:12,418
and in this project so most for the

886
00:34:10,560 --> 00:34:15,000
non-critical data is basically t.o.p

887
00:34:12,418 --> 00:34:16,199
wide so you will inventory and that's

888
00:34:15,000 --> 00:34:18,750
what you will see if you go to the

889
00:34:16,199 --> 00:34:20,428
website is basically openly accessible

890
00:34:18,750 --> 00:34:22,080
as well as the aggregated statistics

891
00:34:20,429 --> 00:34:22,950
that I'm going to talk about any

892
00:34:22,080 --> 00:34:24,929
references as well

893
00:34:22,949 --> 00:34:27,270
everything else is ember so if you have

894
00:34:24,929 --> 00:34:29,429
an excess or basically in account for

895
00:34:27,270 --> 00:34:31,460
the platform the basically means you

896
00:34:29,429 --> 00:34:34,530
have to keep it to yourself in your

897
00:34:31,460 --> 00:34:36,929
institution there's some resources

898
00:34:34,530 --> 00:34:39,510
within there that are designated

899
00:34:36,929 --> 00:34:40,860
otherwise so you already saw this you

900
00:34:39,510 --> 00:34:43,169
are think there might be teal pea green

901
00:34:40,860 --> 00:34:44,790
so there's other ways to share some

902
00:34:43,168 --> 00:34:47,730
components but the majority of the data

903
00:34:44,790 --> 00:34:50,310
is really intended to stay on the yeah

904
00:34:47,730 --> 00:34:52,800
and if you want to get an account there

905
00:34:50,310 --> 00:34:55,409
we use some basic form of wetting

906
00:34:52,800 --> 00:34:58,290
so basically existing community members

907
00:34:55,409 --> 00:35:01,830
have to vouch for you so basically we

908
00:34:58,290 --> 00:35:04,529
know who is accountable if you do stupid

909
00:35:01,830 --> 00:35:05,790
stuff and this might fall back to them

910
00:35:04,530 --> 00:35:07,590
so that's basically a system is very

911
00:35:05,790 --> 00:35:10,020
established and stuff like opps trust

912
00:35:07,590 --> 00:35:13,050
and such and we are basically just using

913
00:35:10,020 --> 00:35:15,570
and orient ourselves on that yeah I

914
00:35:13,050 --> 00:35:18,900
talked about this peer reviewer thing so

915
00:35:15,570 --> 00:35:21,150
if you won't have data to contribute but

916
00:35:18,900 --> 00:35:23,850
a good at math analysis and have a good

917
00:35:21,150 --> 00:35:25,620
rest of the damaja landscape you can

918
00:35:23,850 --> 00:35:27,360
also do reviews here so that's also a

919
00:35:25,620 --> 00:35:29,790
way to contribute to this project and a

920
00:35:27,360 --> 00:35:30,339
platform like I said normally two modes

921
00:35:29,790 --> 00:35:32,829
are require

922
00:35:30,339 --> 00:35:35,920
to either accept or reject a proposal so

923
00:35:32,829 --> 00:35:38,349
you get some more sort of grounds to

924
00:35:35,920 --> 00:35:40,359
base a decision on and what we're also

925
00:35:38,349 --> 00:35:42,279
planning to do is doing some achievement

926
00:35:40,359 --> 00:35:44,049
stuff so if you're frequently reviewing

927
00:35:42,279 --> 00:35:45,519
things right now it's just fantasy

928
00:35:44,049 --> 00:35:45,849
points and you can not do anything with

929
00:35:45,519 --> 00:35:47,649
it

930
00:35:45,849 --> 00:35:49,529
but in the long run I guess we might

931
00:35:47,650 --> 00:35:52,089
provide some more services that

932
00:35:49,529 --> 00:35:54,039
basically will have some quota because

933
00:35:52,089 --> 00:35:57,009
they are more computationally intensive

934
00:35:54,039 --> 00:35:58,660
and basically more contributions would

935
00:35:57,009 --> 00:36:01,599
allow you to get a higher quota to that

936
00:35:58,660 --> 00:36:03,609
kind of stuff so if you want to defend

937
00:36:01,599 --> 00:36:08,769
the earthworm together with the freedom

938
00:36:03,609 --> 00:36:10,690
fighters okay so in summary I'm the

939
00:36:08,769 --> 00:36:14,069
baseline data set that I'm offering you

940
00:36:10,690 --> 00:36:18,009
right here is run about 670 families

941
00:36:14,069 --> 00:36:20,109
2,500 samples with very clean labels I

942
00:36:18,009 --> 00:36:21,999
hope and already some contextual

943
00:36:20,109 --> 00:36:24,549
enrichment but there's many many gaps

944
00:36:21,999 --> 00:36:26,019
that want to be filled and it basically

945
00:36:24,549 --> 00:36:28,809
would allow us to have this kind of

946
00:36:26,019 --> 00:36:30,669
rosetta stone that basically tracks all

947
00:36:28,809 --> 00:36:32,049
the aliases that different people are

948
00:36:30,670 --> 00:36:33,789
referring to when they talk about my

949
00:36:32,049 --> 00:36:37,359
other families or actors for that

950
00:36:33,789 --> 00:36:38,859
instance and depending on how active

951
00:36:37,359 --> 00:36:40,239
this thing is going it can also

952
00:36:38,859 --> 00:36:42,009
basically become something like a

953
00:36:40,239 --> 00:36:43,839
newsfeed because um if you keep the

954
00:36:42,009 --> 00:36:45,700
references edit for families all the

955
00:36:43,839 --> 00:36:48,819
time you see what's happening or it's

956
00:36:45,700 --> 00:36:50,019
more on VOC at the time and get all of

957
00:36:48,819 --> 00:36:52,029
the blog posts directly from one

958
00:36:50,019 --> 00:36:55,180
resource so it's kind of an aggregator

959
00:36:52,029 --> 00:36:56,739
switch might hopefully become that thing

960
00:36:55,180 --> 00:36:58,269
so it would be really good because then

961
00:36:56,739 --> 00:37:01,809
I don't have to crawl my Twitter feed

962
00:36:58,269 --> 00:37:03,430
all the time we are using basically the

963
00:37:01,809 --> 00:37:07,150
reference data of I miss for the Fred

964
00:37:03,430 --> 00:37:09,640
Hector repository and whenever we are

965
00:37:07,150 --> 00:37:11,109
not able to reflect something that we

966
00:37:09,640 --> 00:37:14,589
want to do in my PDA we also contribute

967
00:37:11,109 --> 00:37:16,839
a Mac and like adding an an actor into

968
00:37:14,589 --> 00:37:19,499
their directory or merging some of the

969
00:37:16,839 --> 00:37:22,538
areas and stuff like that so I'm miss

970
00:37:19,499 --> 00:37:25,180
really good thing then again we also

971
00:37:22,539 --> 00:37:26,739
want to cluster automation support so

972
00:37:25,180 --> 00:37:30,190
basically everything that you can access

973
00:37:26,739 --> 00:37:32,769
on the website also has a REST API so if

974
00:37:30,190 --> 00:37:34,450
you want to do searches there's a Python

975
00:37:32,769 --> 00:37:36,578
client ready for you where you can just

976
00:37:34,450 --> 00:37:39,788
directly integrated to stuff that you

977
00:37:36,579 --> 00:37:42,489
already have okay so now I've been

978
00:37:39,789 --> 00:37:43,640
talking a lot about the project and the

979
00:37:42,489 --> 00:37:46,160
data set and what

980
00:37:43,640 --> 00:37:47,810
I want to do is basically do a bit of

981
00:37:46,160 --> 00:37:50,600
showcasing what you can do with that

982
00:37:47,810 --> 00:37:53,600
kind of data so I had this vision they

983
00:37:50,600 --> 00:37:55,190
want to compare across many mother

984
00:37:53,600 --> 00:37:57,560
families and find if there are some

985
00:37:55,190 --> 00:38:02,270
similarities or what basically is some

986
00:37:57,560 --> 00:38:04,580
of the trends of malware authors are so

987
00:38:02,270 --> 00:38:06,110
the data they've been used in this thing

988
00:38:04,580 --> 00:38:08,150
is basically the decommitted I just

989
00:38:06,110 --> 00:38:11,060
referenced so around about 1200 dumped

990
00:38:08,150 --> 00:38:15,860
files for almost or for for 6 families

991
00:38:11,060 --> 00:38:18,110
and in this presentation I'm only going

992
00:38:15,860 --> 00:38:20,150
to address three things so we have

993
00:38:18,110 --> 00:38:23,660
compared PE headers across all of those

994
00:38:20,150 --> 00:38:25,130
families we did some very cursory code

995
00:38:23,660 --> 00:38:27,440
analysis because that's like a rabbit

996
00:38:25,130 --> 00:38:29,090
hole and it totally would not fit the

997
00:38:27,440 --> 00:38:31,400
time slot of this presentation if we had

998
00:38:29,090 --> 00:38:33,500
already presented all of the results we

999
00:38:31,400 --> 00:38:35,270
have there and on the other hand we know

1000
00:38:33,500 --> 00:38:37,070
API usage which is very interesting

1001
00:38:35,270 --> 00:38:39,710
because I guess that's one of the

1002
00:38:37,070 --> 00:38:42,020
cornerstones the vs analysts most rely

1003
00:38:39,710 --> 00:38:43,700
on when we are looking at now there so

1004
00:38:42,020 --> 00:38:46,190
that's the whole inventory of Emily's

1005
00:38:43,700 --> 00:38:47,390
right now it's probably still easy for

1006
00:38:46,190 --> 00:38:50,060
you to find something that's not in

1007
00:38:47,390 --> 00:38:52,279
there but that's basically also one of

1008
00:38:50,060 --> 00:38:54,470
the problems because if you're looking

1009
00:38:52,280 --> 00:38:57,350
at a lot of stuff in parallel you have

1010
00:38:54,470 --> 00:38:59,629
to aggregate to some degree so what I'm

1011
00:38:57,350 --> 00:39:04,190
now going to do is in most of the times

1012
00:38:59,630 --> 00:39:06,290
basically look at the aggregated samples

1013
00:39:04,190 --> 00:39:08,690
per family and then compare the results

1014
00:39:06,290 --> 00:39:11,390
on that level so let's do a very short

1015
00:39:08,690 --> 00:39:15,440
recap of what Pierre does look like so

1016
00:39:11,390 --> 00:39:17,569
that's your usual PA header for example

1017
00:39:15,440 --> 00:39:19,670
one of the more famous things here that

1018
00:39:17,570 --> 00:39:21,980
you normally look for is probably the MZ

1019
00:39:19,670 --> 00:39:23,480
magic the EPE magic so basically the

1020
00:39:21,980 --> 00:39:24,520
cornerstones that we used to to find

1021
00:39:23,480 --> 00:39:27,410
stuff in Dom's

1022
00:39:24,520 --> 00:39:29,530
then there's also this dust string thing

1023
00:39:27,410 --> 00:39:32,240
that might or might not be very common

1024
00:39:29,530 --> 00:39:33,880
there's a rich header that might contain

1025
00:39:32,240 --> 00:39:36,319
some interesting information

1026
00:39:33,880 --> 00:39:39,800
there's the Machine field that tells you

1027
00:39:36,320 --> 00:39:41,480
if it's either 32 or 64 bits then the

1028
00:39:39,800 --> 00:39:44,720
number of sections we have you also

1029
00:39:41,480 --> 00:39:46,940
heard earlier yesterday about that and a

1030
00:39:44,720 --> 00:39:48,950
timestamp and for example with the

1031
00:39:46,940 --> 00:39:50,510
timestamp normally he was nervous you

1032
00:39:48,950 --> 00:39:53,299
don't really know if you can trust the

1033
00:39:50,510 --> 00:39:55,730
timestamp but if we were able to compare

1034
00:39:53,300 --> 00:39:57,070
this across 400 50 families we might get

1035
00:39:55,730 --> 00:39:58,750
a trend how often these times

1036
00:39:57,070 --> 00:40:02,050
might be an actual value that's

1037
00:39:58,750 --> 00:40:04,240
basically realistic or not there's also

1038
00:40:02,050 --> 00:40:06,730
characteristics fears that defines how

1039
00:40:04,240 --> 00:40:09,339
the malware basically can be loaded on

1040
00:40:06,730 --> 00:40:11,650
the system you might have a linker info

1041
00:40:09,340 --> 00:40:14,950
that tells you some more about how this

1042
00:40:11,650 --> 00:40:16,570
thing was potentially compiled which

1043
00:40:14,950 --> 00:40:18,910
operate which system is required in

1044
00:40:16,570 --> 00:40:20,890
order to be able to run it the subsystem

1045
00:40:18,910 --> 00:40:22,720
in that case it's like value 3 so it

1046
00:40:20,890 --> 00:40:24,670
means a console application instead of a

1047
00:40:22,720 --> 00:40:26,740
UI application

1048
00:40:24,670 --> 00:40:28,960
dreg characteristics those contain a

1049
00:40:26,740 --> 00:40:31,479
bits information about the security that

1050
00:40:28,960 --> 00:40:33,700
this file is capable of ending on for

1051
00:40:31,480 --> 00:40:36,130
example if it supports a sauna or not

1052
00:40:33,700 --> 00:40:38,080
and then finally you also have those 11

1053
00:40:36,130 --> 00:40:41,650
data directories and that also contain

1054
00:40:38,080 --> 00:40:43,870
some interesting data so the above

1055
00:40:41,650 --> 00:40:46,000
diagram may or may not include some

1056
00:40:43,870 --> 00:40:49,690
Easter eggs and it's up to you to find

1057
00:40:46,000 --> 00:40:51,040
them so for your presentations it will

1058
00:40:49,690 --> 00:40:53,050
be in that kind of table so on the left

1059
00:40:51,040 --> 00:40:54,430
side I'm across all of the samples and

1060
00:40:53,050 --> 00:40:55,000
on the right side aggregated for

1061
00:40:54,430 --> 00:40:57,279
families

1062
00:40:55,000 --> 00:40:59,440
so let's first have a look at how often

1063
00:40:57,280 --> 00:41:03,970
you will normally encounter some kind of

1064
00:40:59,440 --> 00:41:05,920
MZ or PE magic at all and here the first

1065
00:41:03,970 --> 00:41:07,779
the good news is taking this as an

1066
00:41:05,920 --> 00:41:11,080
indicator for the availability of a peer

1067
00:41:07,780 --> 00:41:13,240
of PE headers in a good 95 percent of

1068
00:41:11,080 --> 00:41:15,279
the families you actually find this

1069
00:41:13,240 --> 00:41:21,339
stuff and you can extract information

1070
00:41:15,280 --> 00:41:24,040
from some kind of PE header so then what

1071
00:41:21,340 --> 00:41:26,830
you can see here is I have some more

1072
00:41:24,040 --> 00:41:30,190
that I can basically extract from that

1073
00:41:26,830 --> 00:41:31,779
are having MZ bad check so sometimes you

1074
00:41:30,190 --> 00:41:35,320
can see the mail rest basically just

1075
00:41:31,780 --> 00:41:38,410
deleting TMZ or just CPE but otherwise

1076
00:41:35,320 --> 00:41:39,820
the the header stays intact but only

1077
00:41:38,410 --> 00:41:42,040
basically just one part of the story

1078
00:41:39,820 --> 00:41:44,320
because there's more funky stuff

1079
00:41:42,040 --> 00:41:47,320
happening so some of the reasons why you

1080
00:41:44,320 --> 00:41:50,590
might not find a B era in that case so

1081
00:41:47,320 --> 00:41:52,360
for a good 30 families you would have 18

1082
00:41:50,590 --> 00:41:54,520
times position independent code that's

1083
00:41:52,360 --> 00:41:57,550
basically not in need of a header

1084
00:41:54,520 --> 00:41:59,020
seven times basically the segments that

1085
00:41:57,550 --> 00:42:01,000
executed with therapy stop with some

1086
00:41:59,020 --> 00:42:03,550
data and in five cases you would have

1087
00:42:01,000 --> 00:42:05,560
now a tea instead and for seven families

1088
00:42:03,550 --> 00:42:08,350
you can find that five of them basically

1089
00:42:05,560 --> 00:42:09,759
null the whole PE header so some more

1090
00:42:08,350 --> 00:42:10,600
effort you can basically extract it

1091
00:42:09,760 --> 00:42:12,700
before it's now

1092
00:42:10,600 --> 00:42:15,370
and for two families you can also

1093
00:42:12,700 --> 00:42:16,660
observe that it's xorg so one does it

1094
00:42:15,370 --> 00:42:20,350
with a one-bite pattern the other one

1095
00:42:16,660 --> 00:42:22,990
with a four bite pattern so it's a bit

1096
00:42:20,350 --> 00:42:25,450
inconsistent so up there you can see 27

1097
00:42:22,990 --> 00:42:27,279
verses 37 families the reason for that

1098
00:42:25,450 --> 00:42:29,850
is basically that only some versions of

1099
00:42:27,280 --> 00:42:31,980
some families are using those

1100
00:42:29,850 --> 00:42:34,509
destruction of PE headers

1101
00:42:31,980 --> 00:42:37,710
yeah drawstrings also available in like

1102
00:42:34,510 --> 00:42:40,990
90% of the cases in general you will

1103
00:42:37,710 --> 00:42:43,180
find three different variants for those

1104
00:42:40,990 --> 00:42:44,859
so basically the most prominent this

1105
00:42:43,180 --> 00:42:46,390
program cannot be run in DOS mode but

1106
00:42:44,860 --> 00:42:48,520
the other ones are basically tired

1107
00:42:46,390 --> 00:42:51,250
mostly tired to data feed so that's one

1108
00:42:48,520 --> 00:42:55,000
of the easy ways how to spot wall in

1109
00:42:51,250 --> 00:42:57,310
compiled stuff rich headers are a less a

1110
00:42:55,000 --> 00:42:59,590
bit less common so you will only find

1111
00:42:57,310 --> 00:43:02,049
them across all of the families in run

1112
00:42:59,590 --> 00:43:03,880
about 60 percent of the cases it's a

1113
00:43:02,050 --> 00:43:08,650
propriety staring at by the Microsoft

1114
00:43:03,880 --> 00:43:11,350
basically encodes how many times things

1115
00:43:08,650 --> 00:43:12,880
have been compiled with Microsoft Visual

1116
00:43:11,350 --> 00:43:15,069
Studio and also with the different

1117
00:43:12,880 --> 00:43:17,380
versions of widgets to do that may have

1118
00:43:15,070 --> 00:43:19,390
been present on the system over time and

1119
00:43:17,380 --> 00:43:21,280
there's a paper from Jim but this year

1120
00:43:19,390 --> 00:43:24,339
that goes in a bit more detail about

1121
00:43:21,280 --> 00:43:26,080
that it's really interesting the next

1122
00:43:24,340 --> 00:43:29,050
thing that we might have a look at so

1123
00:43:26,080 --> 00:43:32,200
say we have a PE header the vast

1124
00:43:29,050 --> 00:43:34,480
majority again is 30 but 32-bit images

1125
00:43:32,200 --> 00:43:36,669
one reason for that is that I've been

1126
00:43:34,480 --> 00:43:39,370
using 32-bit windows a lot to dump that

1127
00:43:36,670 --> 00:43:41,850
stuff but for about 15 families you

1128
00:43:39,370 --> 00:43:45,009
would find that they also have 64 bits

1129
00:43:41,850 --> 00:43:46,870
modules so for example some of the more

1130
00:43:45,010 --> 00:43:49,060
modern bankers like after a trip but

1131
00:43:46,870 --> 00:43:50,710
basically dynamically decide which of

1132
00:43:49,060 --> 00:43:53,710
the modules they want to use try decks

1133
00:43:50,710 --> 00:43:55,150
the same and things like that and at the

1134
00:43:53,710 --> 00:43:57,280
other hand what was a bit surprising to

1135
00:43:55,150 --> 00:43:59,260
me almost every 4th family basically has

1136
00:43:57,280 --> 00:44:03,490
their main module as a DLL opposed to an

1137
00:43:59,260 --> 00:44:05,910
exit file we forgot to those security

1138
00:44:03,490 --> 00:44:08,370
measures as expected

1139
00:44:05,910 --> 00:44:11,200
Marvis not really keen on basically

1140
00:44:08,370 --> 00:44:13,779
having those so for example if we talk

1141
00:44:11,200 --> 00:44:16,600
about relocatable mavar like SLR

1142
00:44:13,780 --> 00:44:19,660
might be a sense might make sense to

1143
00:44:16,600 --> 00:44:21,069
just deactivate it because it may ensure

1144
00:44:19,660 --> 00:44:23,618
that your members running a bit more

1145
00:44:21,070 --> 00:44:27,219
steadily say for an X I guess

1146
00:44:23,619 --> 00:44:28,420
so only in about half of the cases you

1147
00:44:27,219 --> 00:44:31,299
would find those security features

1148
00:44:28,420 --> 00:44:34,839
activated time stems like I said are

1149
00:44:31,299 --> 00:44:36,969
really interesting so for almost 90% we

1150
00:44:34,839 --> 00:44:40,359
have a non zero or not definite time

1151
00:44:36,969 --> 00:44:41,499
value definite time with you because def

1152
00:44:40,359 --> 00:44:43,719
before contained in the back that

1153
00:44:41,499 --> 00:44:46,839
basically always included the same

1154
00:44:43,719 --> 00:44:49,479
timestamp there and you can also read

1155
00:44:46,839 --> 00:44:50,979
about that and now let's have a look at

1156
00:44:49,479 --> 00:44:52,808
time times in a bit more detail because

1157
00:44:50,979 --> 00:44:54,249
that's basically what I just said so if

1158
00:44:52,809 --> 00:44:57,549
you want to look at the age of the

1159
00:44:54,249 --> 00:44:59,200
corpus we can for example check when

1160
00:44:57,549 --> 00:45:02,109
those files have appeared for the first

1161
00:44:59,200 --> 00:45:03,729
time on virustotal and if you don't have

1162
00:45:02,109 --> 00:45:06,549
data it looks some more like this so

1163
00:45:03,729 --> 00:45:09,129
about 90% of all the samples that I have

1164
00:45:06,549 --> 00:45:12,788
in there are basically 2013 and later

1165
00:45:09,130 --> 00:45:16,380
so going more in this preservation

1166
00:45:12,789 --> 00:45:18,910
direction if you have basically a lot of

1167
00:45:16,380 --> 00:45:20,979
samples that are identified and predates

1168
00:45:18,910 --> 00:45:22,690
basically this border I'm really happy

1169
00:45:20,979 --> 00:45:24,839
to take them and integrate them as well

1170
00:45:22,690 --> 00:45:26,979
just to increase the historical coverage

1171
00:45:24,839 --> 00:45:31,749
and the other sample right now is a

1172
00:45:26,979 --> 00:45:34,538
GoSee sample from 2006 so if you want to

1173
00:45:31,749 --> 00:45:37,629
estimate dpe timestamp accuracy what we

1174
00:45:34,539 --> 00:45:39,819
can do is basically use the field from

1175
00:45:37,630 --> 00:45:43,150
the PE header and the virustotal field

1176
00:45:39,819 --> 00:45:45,430
and do the difference of them so looking

1177
00:45:43,150 --> 00:45:48,190
at those 1200 times I have to start with

1178
00:45:45,430 --> 00:45:51,279
I can detect them that don't have a PE

1179
00:45:48,190 --> 00:45:53,799
header then those that have enough mud

1180
00:45:51,279 --> 00:45:56,469
field so they are not really useful in

1181
00:45:53,799 --> 00:45:58,210
doing this kind of analysis another 30

1182
00:45:56,469 --> 00:45:59,999
don't have a virustotal time stamp

1183
00:45:58,210 --> 00:46:02,410
because they are not on virustotal

1184
00:45:59,999 --> 00:46:04,118
you will find some time stamped and

1185
00:46:02,410 --> 00:46:05,859
there are certainly fakes because they

1186
00:46:04,119 --> 00:46:07,599
are in the future so basically they

1187
00:46:05,859 --> 00:46:09,098
would have been submitted to viruses

1188
00:46:07,599 --> 00:46:11,289
before they have been compiled so it

1189
00:46:09,099 --> 00:46:12,759
doesn't make sense and we can also

1190
00:46:11,289 --> 00:46:15,910
filter down to this this range like

1191
00:46:12,759 --> 00:46:17,739
earliest sample until now so I did this

1192
00:46:15,910 --> 00:46:21,609
late October so that's the the upper

1193
00:46:17,739 --> 00:46:24,430
border and this was with 949 Canada

1194
00:46:21,609 --> 00:46:26,049
timestamp pairs that we can look at and

1195
00:46:24,430 --> 00:46:29,140
see the distribution looks somehow like

1196
00:46:26,049 --> 00:46:30,849
this so mine again this is basically the

1197
00:46:29,140 --> 00:46:32,799
number of samples and what we can

1198
00:46:30,849 --> 00:46:34,599
observe here a good 10 percent are

1199
00:46:32,799 --> 00:46:35,210
basically so basically this black tie

1200
00:46:34,599 --> 00:46:37,040
and direct

1201
00:46:35,210 --> 00:46:38,960
to the left is a submitted to virustotal

1202
00:46:37,040 --> 00:46:42,140
on the very same day that you can find

1203
00:46:38,960 --> 00:46:45,820
the EDP time stamp a good 30% are within

1204
00:46:42,140 --> 00:46:50,118
the first week 50% within one month so

1205
00:46:45,820 --> 00:46:52,190
at least in many cases it's it's likely

1206
00:46:50,119 --> 00:46:53,780
that EP attempts them will be somewhat

1207
00:46:52,190 --> 00:46:54,950
correct so sometimes you have to

1208
00:46:53,780 --> 00:46:56,599
consider what's happening after the

1209
00:46:54,950 --> 00:46:58,250
compilation maybe the guy gives his

1210
00:46:56,599 --> 00:47:00,470
malware to someone else or it depends on

1211
00:46:58,250 --> 00:47:02,359
a Pacolet it's basically as an external

1212
00:47:00,470 --> 00:47:04,189
service it has to be delivered to spam

1213
00:47:02,359 --> 00:47:06,080
campaign so the basically explained

1214
00:47:04,190 --> 00:47:09,290
explains why you might have some some

1215
00:47:06,080 --> 00:47:11,560
gap there so altogether about 80% of the

1216
00:47:09,290 --> 00:47:16,609
time stamps live within one year of the

1217
00:47:11,560 --> 00:47:19,490
pre-computation term so 206 samples fall

1218
00:47:16,609 --> 00:47:21,619
out of this range a good third of them

1219
00:47:19,490 --> 00:47:23,089
has a PT background so that's something

1220
00:47:21,619 --> 00:47:26,089
that you can observe sometimes you get

1221
00:47:23,089 --> 00:47:28,070
an apt report published and some one to

1222
00:47:26,089 --> 00:47:30,080
three weeks earlier push those samples

1223
00:47:28,070 --> 00:47:31,700
referenced in there onto virustotal

1224
00:47:30,080 --> 00:47:34,060
and they have been withheld before

1225
00:47:31,700 --> 00:47:37,279
that's probably one of the reasons there

1226
00:47:34,060 --> 00:47:39,080
sometimes you have leak builders so if

1227
00:47:37,280 --> 00:47:42,050
you are now using Citadel builder it

1228
00:47:39,080 --> 00:47:43,670
will still contain the same stuff as for

1229
00:47:42,050 --> 00:47:45,650
four years ago or something so this

1230
00:47:43,670 --> 00:47:49,490
means why you might have fresh samples

1231
00:47:45,650 --> 00:47:51,140
with a very old time stamp for some

1232
00:47:49,490 --> 00:47:52,848
families I know that they've been using

1233
00:47:51,140 --> 00:47:56,060
forgery because some other fields also

1234
00:47:52,849 --> 00:47:56,780
faked and for the rest I have no idea

1235
00:47:56,060 --> 00:47:58,700
voids that

1236
00:47:56,780 --> 00:48:02,000
so probably also for Tory or some some

1237
00:47:58,700 --> 00:48:05,480
other results then again we had a look

1238
00:48:02,000 --> 00:48:07,520
at the compilation of those families so

1239
00:48:05,480 --> 00:48:10,910
using detected easy or similar methods

1240
00:48:07,520 --> 00:48:14,359
we can identify run about 500 data

1241
00:48:10,910 --> 00:48:16,450
points across those families and here

1242
00:48:14,359 --> 00:48:19,040
Microsoft which I see is by far the most

1243
00:48:16,450 --> 00:48:21,680
common compiler chain that's been used

1244
00:48:19,040 --> 00:48:24,890
to to create malware one data point

1245
00:48:21,680 --> 00:48:28,580
kinda sticks out there so we see six is

1246
00:48:24,890 --> 00:48:31,759
used almost as much as the more recent

1247
00:48:28,580 --> 00:48:34,009
ones which was a bit surprising then

1248
00:48:31,760 --> 00:48:37,330
again we see six also gives you

1249
00:48:34,010 --> 00:48:40,339
basically linking against the standard

1250
00:48:37,330 --> 00:48:41,990
runtime that's always on Windows so that

1251
00:48:40,339 --> 00:48:43,849
basically also ensures that your your

1252
00:48:41,990 --> 00:48:44,930
problems your program is not crashing if

1253
00:48:43,849 --> 00:48:47,690
it's basically not finding its

1254
00:48:44,930 --> 00:48:49,009
dependencies yeah we also have Richard

1255
00:48:47,690 --> 00:48:52,910
us for runner BOTS

1256
00:48:49,010 --> 00:48:55,670
760 different samples and basically in

1257
00:48:52,910 --> 00:48:58,580
all cases it's consistent with d-link

1258
00:48:55,670 --> 00:49:01,280
afield so you would have a matching a

1259
00:48:58,580 --> 00:49:04,549
product ID in the originator compared to

1260
00:49:01,280 --> 00:49:06,020
the compiler linker field data there

1261
00:49:04,550 --> 00:49:07,670
directly is are not touching here

1262
00:49:06,020 --> 00:49:10,370
because that's also way too much data

1263
00:49:07,670 --> 00:49:12,560
but there's going to be a paper so for

1264
00:49:10,370 --> 00:49:15,710
control flow graphs we did some very

1265
00:49:12,560 --> 00:49:18,320
fast or cursory disassembly on all those

1266
00:49:15,710 --> 00:49:22,570
families what you can find there your

1267
00:49:18,320 --> 00:49:26,960
average map is probably around 440

1268
00:49:22,570 --> 00:49:30,440
functions in size so most of the members

1269
00:49:26,960 --> 00:49:33,170
basically around dead size now what's

1270
00:49:30,440 --> 00:49:35,240
very interesting if you look at the

1271
00:49:33,170 --> 00:49:37,100
correlation between for example function

1272
00:49:35,240 --> 00:49:40,250
of basic log functions and instruction

1273
00:49:37,100 --> 00:49:42,920
and stuff like that they seem to have a

1274
00:49:40,250 --> 00:49:45,860
very high linear correlation so normally

1275
00:49:42,920 --> 00:49:47,780
you would have roundabout ish nine to

1276
00:49:45,860 --> 00:49:50,560
ten basic parts per function and fifty

1277
00:49:47,780 --> 00:49:52,760
to sixty instructions per function and

1278
00:49:50,560 --> 00:49:54,500
this was a bit surprising because that

1279
00:49:52,760 --> 00:49:58,430
basically means that there has to be

1280
00:49:54,500 --> 00:50:00,950
some connections in the code that are

1281
00:49:58,430 --> 00:50:04,370
probably worth looking deeper on and on

1282
00:50:00,950 --> 00:50:06,560
the other hand maybe personal coding

1283
00:50:04,370 --> 00:50:08,900
style is not as expressive as we hope

1284
00:50:06,560 --> 00:50:11,090
when we are using these kinds of codes

1285
00:50:08,900 --> 00:50:13,820
of fingerprinting authors but that's

1286
00:50:11,090 --> 00:50:17,120
basically research in the future okay

1287
00:50:13,820 --> 00:50:19,850
pdb information what you basically have

1288
00:50:17,120 --> 00:50:23,600
to speed up a bit can see there is

1289
00:50:19,850 --> 00:50:26,360
basically in at least 50 cases the PDB

1290
00:50:23,600 --> 00:50:27,830
string basically gave also one name of

1291
00:50:26,360 --> 00:50:29,240
the mellow family so if you're wondering

1292
00:50:27,830 --> 00:50:31,430
where all those names are coming from

1293
00:50:29,240 --> 00:50:36,529
PDB strings or at least one of those

1294
00:50:31,430 --> 00:50:39,049
sources yeah windows API usage so I

1295
00:50:36,530 --> 00:50:40,700
still want to cover that so I think I've

1296
00:50:39,050 --> 00:50:42,410
published a tool earlier this year which

1297
00:50:40,700 --> 00:50:44,319
is API scout and it's basically

1298
00:50:42,410 --> 00:50:47,859
something that helps you with API record

1299
00:50:44,320 --> 00:50:50,060
reconstruction for known environments so

1300
00:50:47,860 --> 00:50:52,340
we first want to look at the usage

1301
00:50:50,060 --> 00:50:54,290
styles of malware so basically are they

1302
00:50:52,340 --> 00:50:54,680
using an import table doing dynamic

1303
00:50:54,290 --> 00:50:56,420
loading

1304
00:50:54,680 --> 00:50:58,520
are they having association at that kind

1305
00:50:56,420 --> 00:50:59,390
of stuff and then the frequencies with

1306
00:50:58,520 --> 00:51:01,880
which if you

1307
00:50:59,390 --> 00:51:04,308
I used so the idea here is basically you

1308
00:51:01,880 --> 00:51:06,980
can brute force a memory buffer and find

1309
00:51:04,309 --> 00:51:09,170
ostatic offsets so if you're doing

1310
00:51:06,980 --> 00:51:12,140
dynamic analysis you are very familiar

1311
00:51:09,170 --> 00:51:14,619
probably with this import address table

1312
00:51:12,140 --> 00:51:17,720
format and the way that normal

1313
00:51:14,619 --> 00:51:19,519
basically unpack azure dampers work is

1314
00:51:17,720 --> 00:51:22,868
basically that they pass the structure

1315
00:51:19,519 --> 00:51:25,339
and reconstruct it but in many cases you

1316
00:51:22,869 --> 00:51:27,740
will also run into some issues basically

1317
00:51:25,339 --> 00:51:30,470
dumping and fixing them so what I

1318
00:51:27,740 --> 00:51:32,479
thought would be a good idea is

1319
00:51:30,470 --> 00:51:34,399
basically just looking at every D word

1320
00:51:32,480 --> 00:51:35,960
in a buffer and checking if it's

1321
00:51:34,400 --> 00:51:38,140
potentially one of those api's and

1322
00:51:35,960 --> 00:51:40,970
that's basically what if you I scared us

1323
00:51:38,140 --> 00:51:42,710
it's also having an Ida plugin so you

1324
00:51:40,970 --> 00:51:45,109
can directly use the database that you

1325
00:51:42,710 --> 00:51:46,940
have for your operating system get all

1326
00:51:45,109 --> 00:51:50,240
of those various resolved and can

1327
00:51:46,940 --> 00:51:52,400
directly apply them it seems to be a

1328
00:51:50,240 --> 00:51:54,558
very accurate approach as well because

1329
00:51:52,400 --> 00:51:56,990
I've been testing it on good wear and a

1330
00:51:54,559 --> 00:51:58,339
perform good currently it's not working

1331
00:51:56,990 --> 00:52:03,410
on either seven because the pipe in API

1332
00:51:58,339 --> 00:52:05,119
is totally broken usage styles so across

1333
00:52:03,410 --> 00:52:07,609
three hundred eighty families that are

1334
00:52:05,119 --> 00:52:09,980
not dotnet so I directly interacting

1335
00:52:07,609 --> 00:52:13,430
with the windows API it looks like this

1336
00:52:09,980 --> 00:52:16,009
so the majority of the families is using

1337
00:52:13,430 --> 00:52:19,940
standard imports so a good forty six

1338
00:52:16,009 --> 00:52:21,680
percent and on the other hand almost the

1339
00:52:19,940 --> 00:52:23,170
same fraction is doing dynamic imports

1340
00:52:21,680 --> 00:52:26,660
another fifty percent that's here so

1341
00:52:23,170 --> 00:52:30,109
those are very easily reconstructed with

1342
00:52:26,660 --> 00:52:32,210
API code which is very good news on the

1343
00:52:30,109 --> 00:52:34,940
other hand our fist occasion for API

1344
00:52:32,210 --> 00:52:36,710
usage seems not to be that common

1345
00:52:34,940 --> 00:52:40,430
actually so um they're some of the

1346
00:52:36,710 --> 00:52:42,950
methods listed but less than I think

1347
00:52:40,430 --> 00:52:45,169
twenty families right now but I still

1348
00:52:42,950 --> 00:52:46,788
have to go deeper and this statistics

1349
00:52:45,170 --> 00:52:48,410
will be updated over time so this is

1350
00:52:46,789 --> 00:52:50,900
this number of obfuscated families will

1351
00:52:48,410 --> 00:52:52,549
decrease potentially now little face

1352
00:52:50,900 --> 00:52:56,869
what's the most common a P I call a

1353
00:52:52,549 --> 00:53:01,250
cross off to semele s what what you

1354
00:52:56,869 --> 00:53:03,079
protect no sleep why sleep I guess

1355
00:53:01,250 --> 00:53:05,089
basically if you want to orchestrate

1356
00:53:03,079 --> 00:53:07,220
autonomous behavior sleep is like very

1357
00:53:05,089 --> 00:53:09,410
generic you can use it to delay C&C

1358
00:53:07,220 --> 00:53:11,509
communication you can use it to delay

1359
00:53:09,410 --> 00:53:13,170
execution and basically orchestrate how

1360
00:53:11,509 --> 00:53:16,400
a program is running

1361
00:53:13,170 --> 00:53:20,970
so many of the other ones probably also

1362
00:53:16,400 --> 00:53:22,740
beautiful specs for dll it's very much

1363
00:53:20,970 --> 00:53:25,169
the same but I was not really happy

1364
00:53:22,740 --> 00:53:26,250
because if you look at it that way and

1365
00:53:25,170 --> 00:53:28,230
you still end up with like three

1366
00:53:26,250 --> 00:53:30,290
thousand seven hundred different API is

1367
00:53:28,230 --> 00:53:32,550
used across all of those families and

1368
00:53:30,290 --> 00:53:33,140
the graph for those looks a bit like

1369
00:53:32,550 --> 00:53:37,110
that

1370
00:53:33,140 --> 00:53:39,120
however there's very good news the

1371
00:53:37,110 --> 00:53:42,270
pattern of this graph basically tells us

1372
00:53:39,120 --> 00:53:44,670
that the composition of the API set you

1373
00:53:42,270 --> 00:53:47,220
finds for a family is probably rather

1374
00:53:44,670 --> 00:53:49,230
unique so the API footprint has met that

1375
00:53:47,220 --> 00:53:50,879
Marva has might help you to identify it

1376
00:53:49,230 --> 00:53:52,380
and that's probably also a reason why

1377
00:53:50,880 --> 00:53:56,790
impatient in fuzzy and stuff like that

1378
00:53:52,380 --> 00:53:58,260
kind of performs quite well yeah I'm

1379
00:53:56,790 --> 00:54:00,540
gonna skip that so basically I've also

1380
00:53:58,260 --> 00:54:02,700
been doing API constic context groups so

1381
00:54:00,540 --> 00:54:04,980
I labeled another 3,000 offer IP I calls

1382
00:54:02,700 --> 00:54:06,930
into groups so we end up with like QR

1383
00:54:04,980 --> 00:54:09,420
execution string all the kind of stuff

1384
00:54:06,930 --> 00:54:11,399
because otherwise you run into this

1385
00:54:09,420 --> 00:54:13,020
issue that if you look at network you

1386
00:54:11,400 --> 00:54:15,300
have different ways to achieve the same

1387
00:54:13,020 --> 00:54:19,290
effect so it could do HTTP yourself

1388
00:54:15,300 --> 00:54:22,230
using sock or basic do the via 32 dll

1389
00:54:19,290 --> 00:54:24,690
you can use Windsor or use the HTTP hi

1390
00:54:22,230 --> 00:54:26,640
other videos and that basically this API

1391
00:54:24,690 --> 00:54:30,090
contact groups is a way to to merge them

1392
00:54:26,640 --> 00:54:32,970
to some degree and looking at it that

1393
00:54:30,090 --> 00:54:35,520
way um we can see that not every malware

1394
00:54:32,970 --> 00:54:37,049
seems to be using network if we think of

1395
00:54:35,520 --> 00:54:38,370
modern or some of you ran some of your

1396
00:54:37,050 --> 00:54:39,810
families they are just showing you an

1397
00:54:38,370 --> 00:54:41,460
email address but you have to contact

1398
00:54:39,810 --> 00:54:42,390
their order and stuff like that so that

1399
00:54:41,460 --> 00:54:46,110
might be a reason why they are not

1400
00:54:42,390 --> 00:54:48,029
calling out to the C&C servers same for

1401
00:54:46,110 --> 00:54:49,140
the other data as well but what I'm

1402
00:54:48,030 --> 00:54:50,880
doing right now is mostly showing you

1403
00:54:49,140 --> 00:54:52,560
data and the slides that will be

1404
00:54:50,880 --> 00:54:54,750
available directly not after the

1405
00:54:52,560 --> 00:54:57,029
presentation so you can read it up also

1406
00:54:54,750 --> 00:55:00,150
by yourself okay so what's the future

1407
00:54:57,030 --> 00:55:01,830
for this project of course we want to

1408
00:55:00,150 --> 00:55:04,230
maintain this data set an extended I

1409
00:55:01,830 --> 00:55:05,910
hope that you like it that much that you

1410
00:55:04,230 --> 00:55:07,560
want to have not an account for it and

1411
00:55:05,910 --> 00:55:09,920
want to interact with the data so that

1412
00:55:07,560 --> 00:55:12,420
would be like a really cool thing and

1413
00:55:09,920 --> 00:55:15,060
since it's focused on identification we

1414
00:55:12,420 --> 00:55:18,930
probably extend some of the aspects here

1415
00:55:15,060 --> 00:55:20,460
as well for for research I guess but I

1416
00:55:18,930 --> 00:55:22,890
showed to you today is basically only

1417
00:55:20,460 --> 00:55:24,300
scratching the surface and the next step

1418
00:55:22,890 --> 00:55:25,519
have already begun is basically looking

1419
00:55:24,300 --> 00:55:28,609
deeper into it

1420
00:55:25,519 --> 00:55:30,738
doing basically code indexation across

1421
00:55:28,609 --> 00:55:33,259
all of those families so the major goal

1422
00:55:30,739 --> 00:55:34,969
would be to identify unique code or

1423
00:55:33,259 --> 00:55:37,009
shared code across all of those

1424
00:55:34,969 --> 00:55:39,199
different families and ultimately

1425
00:55:37,009 --> 00:55:42,289
getting a better idea how functionality

1426
00:55:39,199 --> 00:55:46,339
is encoded into malware across all of

1427
00:55:42,289 --> 00:55:48,559
those different families okay so

1428
00:55:46,339 --> 00:55:50,569
basically the public launches today if

1429
00:55:48,559 --> 00:55:52,249
you want to have access to it come talk

1430
00:55:50,569 --> 00:55:54,049
to me so I run by the principle of no

1431
00:55:52,249 --> 00:55:56,089
mattress so if you talk to me you

1432
00:55:54,049 --> 00:55:58,669
already did no one met so that's a good

1433
00:55:56,089 --> 00:56:00,828
thing otherwise there's some existing

1434
00:55:58,669 --> 00:56:02,538
users who can now also invite further

1435
00:56:00,829 --> 00:56:05,059
users so that's the way how I want to

1436
00:56:02,539 --> 00:56:07,959
grow this thing organically with that

1437
00:56:05,059 --> 00:56:07,959
thank you for your attention

1438
00:56:14,350 --> 00:56:18,380
thanks Daniel for you're working for

1439
00:56:17,240 --> 00:56:29,720
your talk

1440
00:56:18,380 --> 00:56:31,310
are there any questions Tom there thank

1441
00:56:29,720 --> 00:56:35,830
you for your talk very interesting

1442
00:56:31,310 --> 00:56:39,200
project you you talked a lot about

1443
00:56:35,830 --> 00:56:41,120
executables and I think you just briefly

1444
00:56:39,200 --> 00:56:44,799
mentioned something about JavaScript or

1445
00:56:41,120 --> 00:56:47,480
Java archive like adwin grad families

1446
00:56:44,800 --> 00:56:50,000
how many of those do you have covered

1447
00:56:47,480 --> 00:56:52,340
also like PowerShell malware and all

1448
00:56:50,000 --> 00:56:55,520
kind of like non-executable malware

1449
00:56:52,340 --> 00:56:57,110
types that you have covered yet it kind

1450
00:56:55,520 --> 00:57:00,259
of depends on since I'm mostly looking

1451
00:56:57,110 --> 00:57:02,210
at public sources those are less likely

1452
00:57:00,260 --> 00:57:04,490
to encounter in public archives likelike

1453
00:57:02,210 --> 00:57:06,080
VT and stuff like that so if you have

1454
00:57:04,490 --> 00:57:07,580
pointers to them I'm very happy so I

1455
00:57:06,080 --> 00:57:08,960
think right now it's maybe like 30

1456
00:57:07,580 --> 00:57:12,430
families or something so it's not as

1457
00:57:08,960 --> 00:57:15,530
much certainly as the other ones okay I

1458
00:57:12,430 --> 00:57:25,549
think there is a question just right

1459
00:57:15,530 --> 00:57:28,700
there Anna thanks for the talk was seems

1460
00:57:25,550 --> 00:57:34,130
like a really great tool my question is

1461
00:57:28,700 --> 00:57:35,930
very simple can I get an axis so that's

1462
00:57:34,130 --> 00:57:37,190
basically what I just said so come talk

1463
00:57:35,930 --> 00:57:40,220
to me and we can arrange the kind of

1464
00:57:37,190 --> 00:57:46,100
stuff okay there is a last question over

1465
00:57:40,220 --> 00:57:48,859
there I don't know great research when

1466
00:57:46,100 --> 00:57:51,620
describing the mob our families are you

1467
00:57:48,860 --> 00:57:55,340
just focused on static parts or do you

1468
00:57:51,620 --> 00:57:57,560
also describe based on the behavior so

1469
00:57:55,340 --> 00:57:58,880
right now it's really focused on static

1470
00:57:57,560 --> 00:58:00,890
analysis because I want to have clean

1471
00:57:58,880 --> 00:58:02,840
dumps because that is something that we

1472
00:58:00,890 --> 00:58:05,720
can disassemble and then dive into so

1473
00:58:02,840 --> 00:58:07,700
that's the idea here I do not intend for

1474
00:58:05,720 --> 00:58:10,129
example to have like cocoa reports for

1475
00:58:07,700 --> 00:58:11,660
all of that stuff so that's probably

1476
00:58:10,130 --> 00:58:13,160
also not representative because you

1477
00:58:11,660 --> 00:58:15,350
always have to pecker in front because

1478
00:58:13,160 --> 00:58:17,420
there's no clean up example and you

1479
00:58:15,350 --> 00:58:19,630
don't know where basically to cut into

1480
00:58:17,420 --> 00:58:21,980
the the runtime behavior more or less

1481
00:58:19,630 --> 00:58:23,480
but it's basically is something that you

1482
00:58:21,980 --> 00:58:25,070
could do by just using the data for

1483
00:58:23,480 --> 00:58:26,640
example so if there's another one who

1484
00:58:25,070 --> 00:58:31,760
wants to pick up that stuff and

1485
00:58:26,640 --> 00:58:34,450
present those of runtimes happy to do so

1486
00:58:31,760 --> 00:58:37,610
okay thanks Daniel

1487
00:58:34,450 --> 00:58:37,609
[Music]

