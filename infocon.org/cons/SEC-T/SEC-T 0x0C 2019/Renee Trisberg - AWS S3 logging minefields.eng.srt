1
00:00:04,149 --> 00:00:09,260
hello mama

2
00:00:06,380 --> 00:00:14,690
yeah you can hear me so Rene Trish Berg

3
00:00:09,260 --> 00:00:18,350
from Estonia and reading logs since end

4
00:00:14,690 --> 00:00:23,539
of 90s so quite a long time today we are

5
00:00:18,350 --> 00:00:28,550
talking about AWS s3 access logs and not

6
00:00:23,539 --> 00:00:32,000
about logs in s3 so only about what

7
00:00:28,550 --> 00:00:34,129
happens if you're requesting data from

8
00:00:32,000 --> 00:00:36,829
s3 or you are putting data in history

9
00:00:34,129 --> 00:00:39,399
and then using AWS standard tools have

10
00:00:36,829 --> 00:00:45,829
to get traces of it

11
00:00:39,399 --> 00:00:49,100
let's check AWS documentation first they

12
00:00:45,829 --> 00:00:52,370
are telling that this access log is very

13
00:00:49,100 --> 00:00:54,679
good for auditing and security purposes

14
00:00:52,370 --> 00:00:56,629
and then if you scroll down there is

15
00:00:54,679 --> 00:00:58,969
another section in the documentation

16
00:00:56,629 --> 00:00:59,928
where they claim that the logging is

17
00:00:58,969 --> 00:01:03,229
delivered

18
00:00:59,929 --> 00:01:07,120
best effort basis and so my first

19
00:01:03,229 --> 00:01:07,120
question was what is the best effort

20
00:01:07,689 --> 00:01:15,679
Midas take the set is one bucket since

21
00:01:11,890 --> 00:01:17,659
2017 about 10 million plops and I am

22
00:01:15,680 --> 00:01:21,500
adding each and every day new blobs and

23
00:01:17,659 --> 00:01:26,930
little bit reading the information has

24
00:01:21,500 --> 00:01:30,979
anyone seen s3 access logs before it is

25
00:01:26,930 --> 00:01:35,299
yeah kind of standard Apache log with a

26
00:01:30,979 --> 00:01:37,850
little bit additional fields and we are

27
00:01:35,299 --> 00:01:40,030
right security specialist it means that

28
00:01:37,850 --> 00:01:43,990
for us the parsing these logs is

29
00:01:40,030 --> 00:01:43,990
relatively simple

30
00:01:44,480 --> 00:01:48,680
[Applause]

31
00:01:49,220 --> 00:01:58,710
this is the the specific Rex is again

32
00:01:54,990 --> 00:02:02,699
from AWS documentation site and they are

33
00:01:58,710 --> 00:02:07,770
using it in product called Athena to bar

34
00:02:02,700 --> 00:02:13,340
cs3 access logs and then there is 11:15

35
00:02:07,770 --> 00:02:18,500
bases worth of documentation that

36
00:02:13,340 --> 00:02:18,500
describes in great details

37
00:02:18,510 --> 00:02:25,890
I had couple of questions and I was not

38
00:02:23,180 --> 00:02:28,730
happy with the existing documentation

39
00:02:25,890 --> 00:02:36,179
because it turned out they are missing

40
00:02:28,730 --> 00:02:39,420
something so I brought my own parcel

41
00:02:36,180 --> 00:02:44,239
pattern the format was quite

42
00:02:39,420 --> 00:02:48,540
straightforward since 2012 up to the

43
00:02:44,239 --> 00:02:51,720
spring this year they are keeping

44
00:02:48,540 --> 00:02:57,390
contract and they are avoiding to change

45
00:02:51,720 --> 00:02:59,640
the log format and back in 2012 they

46
00:02:57,390 --> 00:03:03,268
said that in case of we need to add

47
00:02:59,640 --> 00:03:04,920
something then we will not change any of

48
00:03:03,269 --> 00:03:10,890
the existing fields but we will only

49
00:03:04,920 --> 00:03:14,488
append to the end of the record yeah but

50
00:03:10,890 --> 00:03:19,890
these the logical fields after parsing

51
00:03:14,489 --> 00:03:23,880
but let's look at the structures so on

52
00:03:19,890 --> 00:03:27,119
the upper left side you see all the

53
00:03:23,880 --> 00:03:31,530
fields since 2012 and then something

54
00:03:27,120 --> 00:03:37,760
happened in March 2019 they were

55
00:03:31,530 --> 00:03:41,160
developing in production they added

56
00:03:37,760 --> 00:03:43,709
something they removed added again

57
00:03:41,160 --> 00:03:46,620
removed again and then they got it

58
00:03:43,709 --> 00:03:48,600
stable in April 2000 nineteen if you

59
00:03:46,620 --> 00:03:52,320
read the documentation then there is

60
00:03:48,600 --> 00:03:53,940
zero about this change and the current

61
00:03:52,320 --> 00:03:56,638
documentation only tells the tape we

62
00:03:53,940 --> 00:03:58,709
have this format and if you need to

63
00:03:56,639 --> 00:04:01,280
analyze your historical logs then you're

64
00:03:58,709 --> 00:04:04,200
quite screws

65
00:04:01,280 --> 00:04:09,120
what is the physical layer of AWS s3

66
00:04:04,200 --> 00:04:11,220
access logs it's quite simple to

67
00:04:09,120 --> 00:04:14,370
configure just go to your s3 bucket

68
00:04:11,220 --> 00:04:16,769
configurations check I want to have all

69
00:04:14,370 --> 00:04:20,250
my requests log and you need to specify

70
00:04:16,769 --> 00:04:25,430
another bucket in s3 where the logs get

71
00:04:20,250 --> 00:04:33,840
stored and you will have a bunch of

72
00:04:25,430 --> 00:04:35,760
smaller or bigger files generated if you

73
00:04:33,840 --> 00:04:37,520
first start looking you actually you

74
00:04:35,760 --> 00:04:41,669
can't understand when they are

75
00:04:37,520 --> 00:04:44,250
submitting those files to your s3 login

76
00:04:41,669 --> 00:04:51,419
pocket but let's use some statistics

77
00:04:44,250 --> 00:04:55,860
first since 2017 I have about 21 million

78
00:04:51,419 --> 00:05:00,210
log records generated by s3 about and

79
00:04:55,860 --> 00:05:03,210
these log records are in 6 million files

80
00:05:00,210 --> 00:05:05,940
so on average they have like 4 records

81
00:05:03,210 --> 00:05:12,419
per file have you seen such a small log

82
00:05:05,940 --> 00:05:17,180
files before here's the distribution

83
00:05:12,419 --> 00:05:24,650
over time so how many new files are

84
00:05:17,180 --> 00:05:27,900
created new log files per day and that

85
00:05:24,650 --> 00:05:30,659
statistic is only about my relatively

86
00:05:27,900 --> 00:05:34,830
small pocket but working with customers

87
00:05:30,660 --> 00:05:40,110
I can estimate that the nearest to AWS

88
00:05:34,830 --> 00:05:42,270
has about 2200 hosts serving s3 and it

89
00:05:40,110 --> 00:05:44,520
works in the way that when something

90
00:05:42,270 --> 00:05:46,789
happens some event happens in one of

91
00:05:44,520 --> 00:05:48,990
those hosts they were not delivered

92
00:05:46,790 --> 00:05:51,630
immediately they start collecting

93
00:05:48,990 --> 00:05:54,090
additional additional events and then

94
00:05:51,630 --> 00:05:59,370
finally sometime they close the log file

95
00:05:54,090 --> 00:06:02,969
and ship it best effort delivery

96
00:05:59,370 --> 00:06:07,340
what is the average time or Delta when

97
00:06:02,970 --> 00:06:11,220
event happened and you are seeing it

98
00:06:07,340 --> 00:06:14,099
from your local eatery we all like

99
00:06:11,220 --> 00:06:18,139
real-time log monitoring's and the blue

100
00:06:14,100 --> 00:06:23,090
line is in minutes you see that average

101
00:06:18,139 --> 00:06:28,229
delivery time is bit less than one hour

102
00:06:23,090 --> 00:06:33,330
for all the events we have in happening

103
00:06:28,229 --> 00:06:37,349
but another statistics I created it's a

104
00:06:33,330 --> 00:06:42,050
bit more interesting and I asked from

105
00:06:37,350 --> 00:06:46,919
information what is the average minimum

106
00:06:42,050 --> 00:06:50,430
Delta for events happening at specific

107
00:06:46,919 --> 00:06:54,479
minutes in the holes so if you need to

108
00:06:50,430 --> 00:06:57,570
attack someone's s3 bucket you discover

109
00:06:54,479 --> 00:07:00,240
that their bucket is is open or if you

110
00:06:57,570 --> 00:07:04,169
manage to steal credentials then do it

111
00:07:00,240 --> 00:07:10,410
in the beginning of our because then you

112
00:07:04,169 --> 00:07:13,859
have something like 70 minutes current

113
00:07:10,410 --> 00:07:16,139
lead that they have no clue that you are

114
00:07:13,860 --> 00:07:21,169
there and if you do it end of the hour

115
00:07:16,139 --> 00:07:21,169
they might discover it after 17 minutes

116
00:07:22,729 --> 00:07:29,700
have they improved during last three

117
00:07:26,610 --> 00:07:34,050
years the answer is no it's exactly the

118
00:07:29,700 --> 00:07:39,150
same it was 2017 and you see 2019

119
00:07:34,050 --> 00:07:42,840
exactly the same who has seen the Tom

120
00:07:39,150 --> 00:07:44,359
Hanks movie when he was delivery guy and

121
00:07:42,840 --> 00:07:54,090
got lost

122
00:07:44,360 --> 00:08:01,910
yeah who can explain how the hell some

123
00:07:54,090 --> 00:08:01,909
of the events are in transit 237 days

124
00:08:02,449 --> 00:08:10,889
is it us post they're using now this is

125
00:08:07,830 --> 00:08:13,198
my record that the event happened in the

126
00:08:10,889 --> 00:08:16,460
beginning of year and then finally I

127
00:08:13,199 --> 00:08:22,289
caught it in my logs almost a year later

128
00:08:16,460 --> 00:08:24,469
and is it very bad no no it's not that

129
00:08:22,289 --> 00:08:27,990
bad because maturity of the events are

130
00:08:24,469 --> 00:08:32,820
actually arriving quite fast but from my

131
00:08:27,990 --> 00:08:37,370
typist dataset I know that some events

132
00:08:32,820 --> 00:08:41,250
are taking quite quite long time and

133
00:08:37,370 --> 00:08:44,970
then some events have never arrived the

134
00:08:41,250 --> 00:08:47,970
only way for me to to analyze when event

135
00:08:44,970 --> 00:08:50,519
has arrived or not is checking put

136
00:08:47,970 --> 00:08:54,120
requests I am I know that the blob

137
00:08:50,519 --> 00:08:55,829
exists in the in the blob store and then

138
00:08:54,120 --> 00:08:59,579
if I don't have corresponding put

139
00:08:55,829 --> 00:09:04,859
request it means the this log entry has

140
00:08:59,579 --> 00:09:08,969
got lost in transit is this the only

141
00:09:04,860 --> 00:09:12,329
issue with AWS access logging no the

142
00:09:08,970 --> 00:09:20,699
documentation we have a favorite we have

143
00:09:12,329 --> 00:09:26,870
user agents if you need to attack a log

144
00:09:20,699 --> 00:09:26,870
record integrity what would you try

145
00:09:29,730 --> 00:09:40,900
let's change our user agent it's so

146
00:09:33,880 --> 00:09:49,660
simple it should not work but yeah it

147
00:09:40,900 --> 00:09:52,870
works they are not escaping user agent

148
00:09:49,660 --> 00:09:56,199
ref error and couple of other fields

149
00:09:52,870 --> 00:10:08,220
coming directly from your HTTP headers

150
00:09:56,200 --> 00:10:14,160
is it zero day no that post is from

151
00:10:08,220 --> 00:10:17,410
their forum and people are complaining

152
00:10:14,160 --> 00:10:20,800
at least twice per year pointing back to

153
00:10:17,410 --> 00:10:24,339
the first post made in 2012 please

154
00:10:20,800 --> 00:10:29,530
AWS fix it because it might cause issues

155
00:10:24,340 --> 00:10:33,220
for example if you discovered that your

156
00:10:29,530 --> 00:10:34,959
pocket was open and you want to start

157
00:10:33,220 --> 00:10:38,770
analyzing the logs first thing you do

158
00:10:34,960 --> 00:10:41,920
you Google how can I analyze my s3

159
00:10:38,770 --> 00:10:45,100
access logs you find article that hey we

160
00:10:41,920 --> 00:10:46,780
have service called Athena in s3 copy

161
00:10:45,100 --> 00:10:48,610
and paste those scripts you have your

162
00:10:46,780 --> 00:10:51,670
table you can select from the table and

163
00:10:48,610 --> 00:10:58,690
this is my important file and the result

164
00:10:51,670 --> 00:11:03,699
is 0 records returned why because I had

165
00:10:58,690 --> 00:11:06,130
my double quotes in my user agent if you

166
00:11:03,700 --> 00:11:08,500
ask select me all the records where the

167
00:11:06,130 --> 00:11:11,620
key is null or any other field is null

168
00:11:08,500 --> 00:11:16,890
then yes I see those records but all the

169
00:11:11,620 --> 00:11:16,890
fields are null I'm screwed

170
00:11:17,370 --> 00:11:24,880
will some other vendors solve that kind

171
00:11:22,690 --> 00:11:27,790
of issue so we know what's the format

172
00:11:24,880 --> 00:11:31,510
official format from description and I

173
00:11:27,790 --> 00:11:35,339
can tell now even we I'm working for for

174
00:11:31,510 --> 00:11:39,360
aspectx and your when using specs and

175
00:11:35,340 --> 00:11:41,430
using the official official

176
00:11:39,360 --> 00:11:44,459
description of them of the format

177
00:11:41,430 --> 00:11:46,890
exactly the same will occur you are

178
00:11:44,459 --> 00:11:48,839
looking for specific file or access to

179
00:11:46,890 --> 00:11:53,220
the specific file and even we are

180
00:11:48,839 --> 00:11:55,079
telling no no matches but we are hinting

181
00:11:53,220 --> 00:11:57,870
you that hey something went wrong and

182
00:11:55,079 --> 00:11:59,729
then you need to do it it's your

183
00:11:57,870 --> 00:12:01,649
responsibility to understand your logs

184
00:11:59,730 --> 00:12:03,269
it actually doesn't matter if you are

185
00:12:01,649 --> 00:12:06,149
talking about these three logs or your

186
00:12:03,269 --> 00:12:08,040
own logs you need to know how the logs

187
00:12:06,149 --> 00:12:11,010
are written how these logs are combined

188
00:12:08,040 --> 00:12:14,939
or these logs vulnerable or not Apache

189
00:12:11,010 --> 00:12:18,870
logs since they zero still were not

190
00:12:14,940 --> 00:12:23,970
vulnerable for a username part poisoning

191
00:12:18,870 --> 00:12:27,899
in just sending one one pad username and

192
00:12:23,970 --> 00:12:30,800
if you are using Splunk then worst case

193
00:12:27,899 --> 00:12:35,190
what happens is that they went get

194
00:12:30,800 --> 00:12:37,260
internal timestamp two weeks from now so

195
00:12:35,190 --> 00:12:39,450
all the queries you are doing for my

196
00:12:37,260 --> 00:12:42,630
last five minutes or my last hour you

197
00:12:39,450 --> 00:12:49,529
will not see the records but you will

198
00:12:42,630 --> 00:12:53,310
see sometimes later and basically that's

199
00:12:49,529 --> 00:13:00,000
it so my message is yeah I have one

200
00:12:53,310 --> 00:13:04,469
minute or so my primary message is that

201
00:13:00,000 --> 00:13:08,310
e from vendor site it is impossible to

202
00:13:04,470 --> 00:13:10,380
give you package that analyzes all the

203
00:13:08,310 --> 00:13:13,529
possible log information great Co nice

204
00:13:10,380 --> 00:13:16,079
dashboards and and also achieving

205
00:13:13,529 --> 00:13:17,880
accuracy now it's impossible it's always

206
00:13:16,079 --> 00:13:22,170
case-by-case you need to know your data

207
00:13:17,880 --> 00:13:26,610
you need to know if something is is or

208
00:13:22,170 --> 00:13:32,779
seems relevant or not I'm not even going

209
00:13:26,610 --> 00:13:32,779
to minor details I have my minute

210
00:13:35,709 --> 00:13:45,089
about numeric values so for some strange

211
00:13:40,810 --> 00:13:48,489
reasons if the field is missing then

212
00:13:45,089 --> 00:13:51,910
they've standard least used - and some

213
00:13:48,490 --> 00:13:54,699
in some some places - one as describing

214
00:13:51,910 --> 00:13:56,649
missing fields imagine yours the pack

215
00:13:54,699 --> 00:13:59,349
and her business not responding not

216
00:13:56,649 --> 00:14:01,060
responding in the logs you get minus 1

217
00:13:59,350 --> 00:14:05,019
and you are doing aggregations over

218
00:14:01,060 --> 00:14:07,810
response times everything is fine except

219
00:14:05,019 --> 00:14:10,740
the aggregation time thank you okay

220
00:14:07,810 --> 00:14:10,739
thank you very much

