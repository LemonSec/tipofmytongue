1
00:00:21,750 --> 00:00:25,859
[Music]

2
00:00:42,840 --> 00:00:45,840
so

3
00:00:47,920 --> 00:00:52,079
all right i'd like to uh introduce wolf

4
00:00:50,800 --> 00:00:55,360
girlidge today

5
00:00:52,079 --> 00:00:57,520
uh he's advisory ciso over at duo

6
00:00:55,360 --> 00:00:58,480
and he's going to be speaking on design

7
00:00:57,520 --> 00:01:01,920
thinking

8
00:00:58,480 --> 00:01:02,559
for secure development so wolfe if you

9
00:01:01,920 --> 00:01:05,280
want to

10
00:01:02,559 --> 00:01:05,280
share your screen

11
00:01:11,280 --> 00:01:17,680
you got it you see my slides

12
00:01:14,799 --> 00:01:18,159
yep looks good life is good all right

13
00:01:17,680 --> 00:01:19,920
thanks

14
00:01:18,159 --> 00:01:21,680
uh thanks everyone for joining this

15
00:01:19,920 --> 00:01:25,119
session you know it's

16
00:01:21,680 --> 00:01:28,240
uh it is a shame not to be

17
00:01:25,119 --> 00:01:29,520
in person it's also a little bit

18
00:01:28,240 --> 00:01:32,240
exciting

19
00:01:29,520 --> 00:01:33,840
because originally i had uh i went man

20
00:01:32,240 --> 00:01:35,679
corncon sounds pretty cool but there's

21
00:01:33,840 --> 00:01:38,159
there's no way that i can

22
00:01:35,680 --> 00:01:40,000
make it fit in my agenda so it's uh it's

23
00:01:38,159 --> 00:01:42,960
a you know honor to be here with you

24
00:01:40,000 --> 00:01:42,960
all virtually today

25
00:01:43,680 --> 00:01:47,040
i as already mentioned them wolfgang

26
00:01:46,399 --> 00:01:50,320
gorlick

27
00:01:47,040 --> 00:01:53,439
i am over at duo where i focus

28
00:01:50,320 --> 00:01:56,960
in on as an advisor you see so

29
00:01:53,439 --> 00:02:00,559
in on xero trust

30
00:01:56,960 --> 00:02:03,439
passwordless the the front end of

31
00:02:00,560 --> 00:02:04,880
identity and access management we just

32
00:02:03,439 --> 00:02:06,320
uh wrapped up a

33
00:02:04,880 --> 00:02:08,160
session here before with machine

34
00:02:06,320 --> 00:02:10,799
learning so i dabble in that a little

35
00:02:08,160 --> 00:02:12,799
bit as it pertains to authentication

36
00:02:10,800 --> 00:02:14,800
uh but predominantly i've been

37
00:02:12,800 --> 00:02:18,720
struggling with

38
00:02:14,800 --> 00:02:20,959
this thought for a while now

39
00:02:18,720 --> 00:02:22,400
and uh um a little bit over a year a

40
00:02:20,959 --> 00:02:23,360
little bit over a year about a year ago

41
00:02:22,400 --> 00:02:26,400
now

42
00:02:23,360 --> 00:02:28,800
on a keynote uh at circle city county i

43
00:02:26,400 --> 00:02:30,879
stood on the stage and said does

44
00:02:28,800 --> 00:02:32,319
security have a design problem do we

45
00:02:30,879 --> 00:02:36,079
have a design problem right our

46
00:02:32,319 --> 00:02:39,280
our problems that we're facing today

47
00:02:36,080 --> 00:02:41,120
less about the the security properties

48
00:02:39,280 --> 00:02:43,200
of the technology we can marshal

49
00:02:41,120 --> 00:02:45,040
less about the controls that we can put

50
00:02:43,200 --> 00:02:46,319
in place less about the things that we

51
00:02:45,040 --> 00:02:47,840
can tell people to do and the

52
00:02:46,319 --> 00:02:50,799
engineering feats that

53
00:02:47,840 --> 00:02:52,640
we can accomplish and more about the

54
00:02:50,800 --> 00:02:56,239
experiences that we create

55
00:02:52,640 --> 00:02:58,399
for for our communities

56
00:02:56,239 --> 00:03:00,560
uh and i'm still struggling with it i

57
00:02:58,400 --> 00:03:02,480
think the answer is yes

58
00:03:00,560 --> 00:03:04,000
and what do we do about it is where i'm

59
00:03:02,480 --> 00:03:06,159
at now so i want to give you

60
00:03:04,000 --> 00:03:07,599
a an update and take you through that

61
00:03:06,159 --> 00:03:10,879
and specifically i'm going to be

62
00:03:07,599 --> 00:03:13,760
looking at these principles applied

63
00:03:10,879 --> 00:03:15,760
to secure development which is uh part

64
00:03:13,760 --> 00:03:16,720
of my background i've been doing

65
00:03:15,760 --> 00:03:19,840
development for

66
00:03:16,720 --> 00:03:20,640
for many years i ran a devops team for a

67
00:03:19,840 --> 00:03:23,920
while did

68
00:03:20,640 --> 00:03:26,159
open source sim and open source uh

69
00:03:23,920 --> 00:03:27,679
covert channels project and powershell

70
00:03:26,159 --> 00:03:30,000
and a few other things

71
00:03:27,680 --> 00:03:33,360
i don't think i've written code anytime

72
00:03:30,000 --> 00:03:35,920
soon or anytime recently which is sad

73
00:03:33,360 --> 00:03:37,040
and i won't be doing it anytime soon but

74
00:03:35,920 --> 00:03:40,640
the concept of

75
00:03:37,040 --> 00:03:42,560
of secure development is is one

76
00:03:40,640 --> 00:03:45,119
where i think we can make a tremendous

77
00:03:42,560 --> 00:03:46,799
amount of stride due to the fact that

78
00:03:45,120 --> 00:03:48,239
everything runs software these days as

79
00:03:46,799 --> 00:03:50,000
we all know right everything we bought i

80
00:03:48,239 --> 00:03:53,200
just bought some light bulbs

81
00:03:50,000 --> 00:03:54,720
and um they were immediately wanting to

82
00:03:53,200 --> 00:03:55,439
connect to my wi-fi and i wasn't even

83
00:03:54,720 --> 00:03:57,760
trying to buy

84
00:03:55,439 --> 00:03:59,200
a smart light bulb it was just oh

85
00:03:57,760 --> 00:04:01,359
there's a light bulb that looks like it

86
00:03:59,200 --> 00:04:03,119
no it's it's all wired in and of course

87
00:04:01,360 --> 00:04:05,040
running software

88
00:04:03,120 --> 00:04:07,680
so let's let's talk a little bit about

89
00:04:05,040 --> 00:04:10,159
that but first i want to take you back

90
00:04:07,680 --> 00:04:10,799
um to where i think everything went

91
00:04:10,159 --> 00:04:14,079
wrong

92
00:04:10,799 --> 00:04:15,840
and that's where uh this this amazing

93
00:04:14,080 --> 00:04:17,199
thing happened where we decided that hey

94
00:04:15,840 --> 00:04:20,320
wouldn't it be great

95
00:04:17,199 --> 00:04:22,160
if we put people on the computers i i

96
00:04:20,320 --> 00:04:23,759
pinpointed the exact point in time

97
00:04:22,160 --> 00:04:25,440
everything went wrong and ladies and

98
00:04:23,759 --> 00:04:28,320
gentlemen that would be the point

99
00:04:25,440 --> 00:04:31,040
and uh it all started with with this bad

100
00:04:28,320 --> 00:04:31,599
boy this is the original mouse prototype

101
00:04:31,040 --> 00:04:34,720
by doug

102
00:04:31,600 --> 00:04:36,639
engelbart uh doug engelbart uh was uh

103
00:04:34,720 --> 00:04:39,440
was a futurist was a genius

104
00:04:36,639 --> 00:04:41,280
uh watch his mother raw demos one of the

105
00:04:39,440 --> 00:04:43,919
things i loved about doug engelbart

106
00:04:41,280 --> 00:04:44,719
especially coming on the heels of an ai

107
00:04:43,919 --> 00:04:48,159
talk

108
00:04:44,720 --> 00:04:49,120
was his focus on intelligence

109
00:04:48,160 --> 00:04:52,400
augmentation

110
00:04:49,120 --> 00:04:53,919
in other words not ai but ia not how can

111
00:04:52,400 --> 00:04:55,359
we make the machine smarter but how can

112
00:04:53,919 --> 00:04:57,599
we make the machines

113
00:04:55,360 --> 00:04:59,680
make us smarter and one of his first

114
00:04:57,600 --> 00:05:00,800
absolute was this lovely piece of wood

115
00:04:59,680 --> 00:05:02,960
which of course you guys will all

116
00:05:00,800 --> 00:05:04,960
recognize as the mouse now he

117
00:05:02,960 --> 00:05:07,120
he refined it he made it better right he

118
00:05:04,960 --> 00:05:07,840
he went through a series of steps and

119
00:05:07,120 --> 00:05:10,160
eventually

120
00:05:07,840 --> 00:05:11,039
it did indeed look like a mouse as we

121
00:05:10,160 --> 00:05:12,400
can see in the left

122
00:05:11,039 --> 00:05:14,880
this thing on the right you may be like

123
00:05:12,400 --> 00:05:16,638
what is that

124
00:05:14,880 --> 00:05:19,440
it's interesting from an innovation

125
00:05:16,639 --> 00:05:22,720
perspective how the mental models

126
00:05:19,440 --> 00:05:24,880
of which innovators use dictate

127
00:05:22,720 --> 00:05:26,400
the way the innovators view their

128
00:05:24,880 --> 00:05:30,240
eventual innovation

129
00:05:26,400 --> 00:05:30,799
in uh in this world that doug eaglebart

130
00:05:30,240 --> 00:05:32,960
lived in

131
00:05:30,800 --> 00:05:34,479
he have originally viewed mastering the

132
00:05:32,960 --> 00:05:35,280
computer like mastering a musical

133
00:05:34,479 --> 00:05:36,960
instrument

134
00:05:35,280 --> 00:05:39,440
and therefore the mouse was invented in

135
00:05:36,960 --> 00:05:40,080
this chord uh control was invented as

136
00:05:39,440 --> 00:05:42,479
well

137
00:05:40,080 --> 00:05:43,440
to add more buttons what was also

138
00:05:42,479 --> 00:05:46,719
fascinating

139
00:05:43,440 --> 00:05:49,039
is a six month six month six

140
00:05:46,720 --> 00:05:50,880
month course was developed by doug

141
00:05:49,039 --> 00:05:54,080
engelbart and his uh

142
00:05:50,880 --> 00:05:55,120
his uh you know uh tas to teach people

143
00:05:54,080 --> 00:05:56,960
how to use

144
00:05:55,120 --> 00:05:58,639
these two wonderful things to drive a

145
00:05:56,960 --> 00:06:00,880
computer

146
00:05:58,639 --> 00:06:02,560
so great innovation but also not exactly

147
00:06:00,880 --> 00:06:04,880
user friendly

148
00:06:02,560 --> 00:06:06,880
xerox sees this of course about uh this

149
00:06:04,880 --> 00:06:07,199
is the the early 70s x is like we need

150
00:06:06,880 --> 00:06:08,400
to

151
00:06:07,199 --> 00:06:10,800
put these everywhere we're going to mass

152
00:06:08,400 --> 00:06:11,840
produce them they hire a company to do

153
00:06:10,800 --> 00:06:13,520
some engineering

154
00:06:11,840 --> 00:06:15,758
they come up with this design it looks

155
00:06:13,520 --> 00:06:18,400
much more familiar to us in terms of

156
00:06:15,759 --> 00:06:18,880
of old school mice and there's a couple

157
00:06:18,400 --> 00:06:21,198
of things

158
00:06:18,880 --> 00:06:22,400
intriguing about this one it was very

159
00:06:21,199 --> 00:06:25,520
expensive

160
00:06:22,400 --> 00:06:27,520
xerox's mental model was a precision

161
00:06:25,520 --> 00:06:29,280
instrument not a musical instrument but

162
00:06:27,520 --> 00:06:30,560
a precision scientific instrument and

163
00:06:29,280 --> 00:06:33,359
therefore

164
00:06:30,560 --> 00:06:34,000
these devices were very expensive

165
00:06:33,360 --> 00:06:37,280
costing more

166
00:06:34,000 --> 00:06:38,639
than most computers cost today uh also

167
00:06:37,280 --> 00:06:40,638
you'll notice one of them is flipped up

168
00:06:38,639 --> 00:06:41,919
and you'll notice the trackball is metal

169
00:06:40,639 --> 00:06:45,919
that is important why

170
00:06:41,919 --> 00:06:48,479
because they had a weekly

171
00:06:45,919 --> 00:06:50,159
maintenance process actually had a

172
00:06:48,479 --> 00:06:52,479
members of the janitorial staff on a

173
00:06:50,160 --> 00:06:55,759
weekly basis go computer to computer

174
00:06:52,479 --> 00:06:57,280
disassemble the mouse clean it re

175
00:06:55,759 --> 00:06:59,120
and then the engineering team would run

176
00:06:57,280 --> 00:07:00,479
it through a process to realign it

177
00:06:59,120 --> 00:07:02,319
to make sure that precision piece of

178
00:07:00,479 --> 00:07:05,840
equipment worked well

179
00:07:02,319 --> 00:07:06,240
of course the mice that uh that we all

180
00:07:05,840 --> 00:07:08,719
know

181
00:07:06,240 --> 00:07:09,680
today come from from apple and

182
00:07:08,720 --> 00:07:11,280
oftentimes we give

183
00:07:09,680 --> 00:07:13,520
apple the credit right steve jobs

184
00:07:11,280 --> 00:07:15,198
brought it but what was intriguing about

185
00:07:13,520 --> 00:07:17,120
steve jobs is he didn't actually design

186
00:07:15,199 --> 00:07:18,880
the mouse he saw it of course in xerox

187
00:07:17,120 --> 00:07:20,319
and he knew his computer needed one he's

188
00:07:18,880 --> 00:07:20,880
like can i i don't know how to build a

189
00:07:20,319 --> 00:07:23,520
mouse

190
00:07:20,880 --> 00:07:24,159
he hired a guy named dave kelly and and

191
00:07:23,520 --> 00:07:26,639
team

192
00:07:24,160 --> 00:07:27,520
and that team would go on design the

193
00:07:26,639 --> 00:07:29,120
mouse and the

194
00:07:27,520 --> 00:07:30,799
the history of his roy fasting i won't

195
00:07:29,120 --> 00:07:32,560
get into it now because it'll probably

196
00:07:30,800 --> 00:07:33,520
bore off you guys but i'm reading about

197
00:07:32,560 --> 00:07:35,440
like wow they

198
00:07:33,520 --> 00:07:37,440
like measure the acoustics and and the

199
00:07:35,440 --> 00:07:39,120
click feel and they figured out like

200
00:07:37,440 --> 00:07:40,479
how users would use these things and how

201
00:07:39,120 --> 00:07:42,240
long it would take to pick it up and how

202
00:07:40,479 --> 00:07:45,758
do you make it more intuitive

203
00:07:42,240 --> 00:07:49,120
and uh and also also how do you lower

204
00:07:45,759 --> 00:07:51,280
the cost the company that

205
00:07:49,120 --> 00:07:53,599
apple hired to make the first mouse

206
00:07:51,280 --> 00:07:56,719
which of course would go on and be the

207
00:07:53,599 --> 00:07:58,639
ancestor dollar mice uh was one that

208
00:07:56,720 --> 00:08:00,479
eventually turned into ideo and if you

209
00:07:58,639 --> 00:08:02,000
want to know more about design thinking

210
00:08:00,479 --> 00:08:03,680
check out anything by ideal they have a

211
00:08:02,000 --> 00:08:07,440
whole course on this

212
00:08:03,680 --> 00:08:09,919
it is a process of empathy it's a

213
00:08:07,440 --> 00:08:11,919
process of defining the problem

214
00:08:09,919 --> 00:08:13,520
within how the user defines it and how

215
00:08:11,919 --> 00:08:14,799
we define it right as a music instrument

216
00:08:13,520 --> 00:08:16,400
it's a scientific instrument i don't

217
00:08:14,800 --> 00:08:19,520
know let's ask the user

218
00:08:16,400 --> 00:08:21,120
how they think about it and prototyping

219
00:08:19,520 --> 00:08:23,919
and testing

220
00:08:21,120 --> 00:08:25,759
in the world that i work in and dual as

221
00:08:23,919 --> 00:08:26,960
part of cisco we also have a design

222
00:08:25,759 --> 00:08:28,720
thinking process

223
00:08:26,960 --> 00:08:30,239
that collapses these into a discover

224
00:08:28,720 --> 00:08:32,959
define explore stage

225
00:08:30,240 --> 00:08:35,519
but fundamentally it's the same concept

226
00:08:32,958 --> 00:08:38,799
and in my office actually have the ideo

227
00:08:35,519 --> 00:08:41,599
poster hanging just to remind me

228
00:08:38,799 --> 00:08:43,679
to start with empathy and think about

229
00:08:41,599 --> 00:08:45,760
rapid prototyping

230
00:08:43,679 --> 00:08:47,359
now what does this mean compared to

231
00:08:45,760 --> 00:08:49,120
technology well think about it like the

232
00:08:47,360 --> 00:08:49,839
last time you had to do like an itil

233
00:08:49,120 --> 00:08:52,720
design

234
00:08:49,839 --> 00:08:53,120
right the seven step itil process is

235
00:08:52,720 --> 00:08:54,720
looking

236
00:08:53,120 --> 00:08:57,760
at capacity and availability and

237
00:08:54,720 --> 00:08:59,920
continuity nowhere in there

238
00:08:57,760 --> 00:09:01,519
do they talk about the the person using

239
00:08:59,920 --> 00:09:03,439
the system nowhere in there do they talk

240
00:09:01,519 --> 00:09:05,200
about the person perhaps misusing the

241
00:09:03,440 --> 00:09:07,040
system the criminal the adversary

242
00:09:05,200 --> 00:09:09,440
instead they talk all about here's how

243
00:09:07,040 --> 00:09:10,079
he we the prior availability here's how

244
00:09:09,440 --> 00:09:11,920
we make some

245
00:09:10,080 --> 00:09:14,000
it's a very much an engineering process

246
00:09:11,920 --> 00:09:15,439
it's a very much a xerox process

247
00:09:14,000 --> 00:09:18,240
and again i think it's important to

248
00:09:15,440 --> 00:09:20,720
contrast xerox versus apple

249
00:09:18,240 --> 00:09:22,399
engineering versus design thinking and

250
00:09:20,720 --> 00:09:24,720
the the result was

251
00:09:22,399 --> 00:09:26,480
amazing back in the day the result uh

252
00:09:24,720 --> 00:09:29,519
was a 400 dollar

253
00:09:26,480 --> 00:09:31,200
uh mouse at xerox which

254
00:09:29,519 --> 00:09:34,160
you know in those days about three times

255
00:09:31,200 --> 00:09:38,640
over so it's about 1200 in today's money

256
00:09:34,160 --> 00:09:40,719
turned into a 25 apple mouse

257
00:09:38,640 --> 00:09:43,760
curiously interesting fact by the way

258
00:09:40,720 --> 00:09:46,000
the the apple miles has stayed around 25

259
00:09:43,760 --> 00:09:47,040
with factor when you factor in inflation

260
00:09:46,000 --> 00:09:50,240
it's about 75

261
00:09:47,040 --> 00:09:53,760
today which 75 dollars in 2020 money

262
00:09:50,240 --> 00:09:54,959
is about 25 in that money also six month

263
00:09:53,760 --> 00:09:56,560
guests forget it

264
00:09:54,959 --> 00:09:58,479
no we're doing six minutes anyone can

265
00:09:56,560 --> 00:10:01,839
pick this up and go

266
00:09:58,480 --> 00:10:03,680
and uh this really i think highlights

267
00:10:01,839 --> 00:10:05,279
the power of design this really i think

268
00:10:03,680 --> 00:10:07,839
highlights the power of thinking about

269
00:10:05,279 --> 00:10:10,560
how the people will use the technology

270
00:10:07,839 --> 00:10:11,680
will will work with it how the people we

271
00:10:10,560 --> 00:10:13,359
are

272
00:10:11,680 --> 00:10:14,800
building these experiences for will

273
00:10:13,360 --> 00:10:17,839
navigate it and how to

274
00:10:14,800 --> 00:10:19,519
do cost control and much better

275
00:10:17,839 --> 00:10:21,440
solutions

276
00:10:19,519 --> 00:10:22,800
of course it all begins with empathy

277
00:10:21,440 --> 00:10:25,440
which is not something

278
00:10:22,800 --> 00:10:26,800
that we're very good at right it's not

279
00:10:25,440 --> 00:10:30,240
something we're wired into

280
00:10:26,800 --> 00:10:32,560
the the two parents of cyber security

281
00:10:30,240 --> 00:10:33,760
is is technology where i configure

282
00:10:32,560 --> 00:10:36,800
something and therefore

283
00:10:33,760 --> 00:10:38,240
it works uh hopefully that's why so many

284
00:10:36,800 --> 00:10:40,079
of us got into it right we type in the

285
00:10:38,240 --> 00:10:42,079
code and it does what we say we do

286
00:10:40,079 --> 00:10:43,760
we wear it and it just stays wired in

287
00:10:42,079 --> 00:10:45,040
computers don't walk off they behave

288
00:10:43,760 --> 00:10:47,439
when we tell them to

289
00:10:45,040 --> 00:10:49,120
um and the other parent of course is the

290
00:10:47,440 --> 00:10:50,959
military where you've got

291
00:10:49,120 --> 00:10:53,040
command and control right these are

292
00:10:50,959 --> 00:10:55,199
these two mindsets

293
00:10:53,040 --> 00:10:56,719
are not conducive for empathy they're

294
00:10:55,200 --> 00:10:58,880
not conducive for

295
00:10:56,720 --> 00:11:00,560
securing something like devops so let's

296
00:10:58,880 --> 00:11:02,240
talk a little bit about devops devops is

297
00:11:00,560 --> 00:11:03,599
very easy to secure i'm going to put up

298
00:11:02,240 --> 00:11:04,000
a slide that's all you really need to

299
00:11:03,600 --> 00:11:05,600
know

300
00:11:04,000 --> 00:11:07,279
all you need to do is do these things

301
00:11:05,600 --> 00:11:08,560
code review design review code inventory

302
00:11:07,279 --> 00:11:10,959
inventory container security cloud

303
00:11:08,560 --> 00:11:12,800
security sas iscsca

304
00:11:10,959 --> 00:11:13,760
do change monitoring fim because you

305
00:11:12,800 --> 00:11:15,439
never know what's going to happen with

306
00:11:13,760 --> 00:11:17,360
those file integrities do infrastructure

307
00:11:15,440 --> 00:11:20,800
vulnerability managing rasp laugh

308
00:11:17,360 --> 00:11:23,120
and do a pen test and you are all set

309
00:11:20,800 --> 00:11:24,959
that's really all you need to know uh if

310
00:11:23,120 --> 00:11:27,600
you're looking for devops security

311
00:11:24,959 --> 00:11:30,160
you're all set uh feel free to hang out

312
00:11:27,600 --> 00:11:33,839
for the next half hour to talk about

313
00:11:30,160 --> 00:11:35,839
why it's not that easy because

314
00:11:33,839 --> 00:11:37,680
oftentimes when we look at these as a

315
00:11:35,839 --> 00:11:39,440
checklist we look at these from an

316
00:11:37,680 --> 00:11:41,199
engineering perspective when we look at

317
00:11:39,440 --> 00:11:44,560
these from an itel perspective

318
00:11:41,200 --> 00:11:46,720
we're like all right we can do that but

319
00:11:44,560 --> 00:11:48,319
any benefit of devops goes right out the

320
00:11:46,720 --> 00:11:51,360
window because now we've effectively

321
00:11:48,320 --> 00:11:51,360
shackled it to the floor

322
00:11:52,959 --> 00:11:57,040
and i think this is is seen time and

323
00:11:55,839 --> 00:11:58,560
time again

324
00:11:57,040 --> 00:12:00,160
you can imagine a developer you can

325
00:11:58,560 --> 00:12:01,439
imagine a developer talking to her

326
00:12:00,160 --> 00:12:03,279
friend saying hey i'm gonna go take a

327
00:12:01,440 --> 00:12:05,600
walk before schmidt planning

328
00:12:03,279 --> 00:12:08,000
i'm friends again it sounds fine uh oh

329
00:12:05,600 --> 00:12:09,839
by the way it you know it might rain

330
00:12:08,000 --> 00:12:11,440
and uh security we know the answer it's

331
00:12:09,839 --> 00:12:12,800
like wait i got this i got this i'm

332
00:12:11,440 --> 00:12:15,279
going to protect you

333
00:12:12,800 --> 00:12:16,160
from the rain don't worry about it here

334
00:12:15,279 --> 00:12:19,279
you go

335
00:12:16,160 --> 00:12:22,079
and will that keep you dry absolutely is

336
00:12:19,279 --> 00:12:24,399
that conducive to a usable experience

337
00:12:22,079 --> 00:12:26,000
certainly not by the way quick shout out

338
00:12:24,399 --> 00:12:28,320
to the uncomfortable who designed this

339
00:12:26,000 --> 00:12:29,760
umbrella and a number of the transition

340
00:12:28,320 --> 00:12:31,040
slides in this deck if you want to see

341
00:12:29,760 --> 00:12:34,800
some really

342
00:12:31,040 --> 00:12:36,839
uncomfortable uh examples of engineering

343
00:12:34,800 --> 00:12:38,319
industrial engineering go take a look at

344
00:12:36,839 --> 00:12:41,680
them

345
00:12:38,320 --> 00:12:44,480
but if we think about adding sec

346
00:12:41,680 --> 00:12:46,800
in in devops it's got to start with that

347
00:12:44,480 --> 00:12:50,800
empathy so let's talk a little bit

348
00:12:46,800 --> 00:12:52,399
about empathy from a design perspective

349
00:12:50,800 --> 00:12:53,920
there's really two directions i know we

350
00:12:52,399 --> 00:12:56,880
all know the two wolves but there

351
00:12:53,920 --> 00:12:57,760
is these two two things inside that we

352
00:12:56,880 --> 00:12:59,839
gotta handle

353
00:12:57,760 --> 00:13:02,399
it's our developers of course who i'm

354
00:12:59,839 --> 00:13:05,040
sure are happy and excited and engaged

355
00:13:02,399 --> 00:13:09,120
to work with the security team

356
00:13:05,040 --> 00:13:12,160
but it's also the adversaries and

357
00:13:09,120 --> 00:13:14,639
i believe my my fundamental hypothesis

358
00:13:12,160 --> 00:13:15,839
is that the design thinking that works

359
00:13:14,639 --> 00:13:17,519
for the users

360
00:13:15,839 --> 00:13:19,200
is the same design thinking that works

361
00:13:17,519 --> 00:13:22,079
for the adversaries

362
00:13:19,200 --> 00:13:24,639
um because humans are human we share a

363
00:13:22,079 --> 00:13:28,319
common firmware we share common wet wear

364
00:13:24,639 --> 00:13:31,440
we we have uh idiosyncrasies and

365
00:13:28,320 --> 00:13:33,440
cognitive biases you know we're we're

366
00:13:31,440 --> 00:13:36,079
a whole bunch of biological hacks and a

367
00:13:33,440 --> 00:13:37,839
trench coat pretending to be human

368
00:13:36,079 --> 00:13:40,160
and because of these things i think

369
00:13:37,839 --> 00:13:41,680
these same concepts apply

370
00:13:40,160 --> 00:13:43,360
but you have to apply them in opposite

371
00:13:41,680 --> 00:13:45,599
directions let's talk about what that

372
00:13:43,360 --> 00:13:47,360
what that means and what that looks like

373
00:13:45,600 --> 00:13:49,600
first off

374
00:13:47,360 --> 00:13:50,560
intentionally or accidentally we're

375
00:13:49,600 --> 00:13:52,560
we're always

376
00:13:50,560 --> 00:13:53,680
creating experience every time we put in

377
00:13:52,560 --> 00:13:54,959
place a control

378
00:13:53,680 --> 00:13:57,920
every time we ask someone to use

379
00:13:54,959 --> 00:13:59,119
multi-factor we're creating experience

380
00:13:57,920 --> 00:14:00,479
right where they have to get their phone

381
00:13:59,120 --> 00:14:01,440
or get their token or whatever to

382
00:14:00,480 --> 00:14:04,720
authenticate

383
00:14:01,440 --> 00:14:06,720
uh every time we we put in place a

384
00:14:04,720 --> 00:14:08,079
level file encryption we're creating

385
00:14:06,720 --> 00:14:09,920
experience where they now have to

386
00:14:08,079 --> 00:14:13,359
decrypt that and whatnot

387
00:14:09,920 --> 00:14:16,880
and i think what is important is that we

388
00:14:13,360 --> 00:14:18,240
think mindfully about how to design that

389
00:14:16,880 --> 00:14:22,000
experience

390
00:14:18,240 --> 00:14:25,680
there's two fundamental ways

391
00:14:22,000 --> 00:14:28,079
that uh research shows that experiences

392
00:14:25,680 --> 00:14:29,680
uh are catalogued one is the paths that

393
00:14:28,079 --> 00:14:31,680
people take right and the others the

394
00:14:29,680 --> 00:14:35,040
choices they make

395
00:14:31,680 --> 00:14:38,160
this is being studied by um

396
00:14:35,040 --> 00:14:41,199
occupational industrial psychology uh

397
00:14:38,160 --> 00:14:44,639
quick call if anyone knows

398
00:14:41,199 --> 00:14:45,839
any industrial or you know industrial

399
00:14:44,639 --> 00:14:48,160
psych

400
00:14:45,839 --> 00:14:50,000
students who are looking for a master's

401
00:14:48,160 --> 00:14:54,240
program or i'm sorry master's

402
00:14:50,000 --> 00:14:56,000
thesis or research collaborator

403
00:14:54,240 --> 00:14:57,440
please send them my way because i want

404
00:14:56,000 --> 00:14:59,440
to dig deeper into this it's one of the

405
00:14:57,440 --> 00:15:00,800
things that i'm looking at in 2021 i

406
00:14:59,440 --> 00:15:02,399
want to work with

407
00:15:00,800 --> 00:15:04,479
some of the psychologists to roy hammer

408
00:15:02,399 --> 00:15:06,480
this home but paths they take how do you

409
00:15:04,480 --> 00:15:08,240
measure those paths you measure them

410
00:15:06,480 --> 00:15:10,160
by the number of steps you measure them

411
00:15:08,240 --> 00:15:11,680
by the familiarity of each step

412
00:15:10,160 --> 00:15:13,360
is it easy to go to each step or is this

413
00:15:11,680 --> 00:15:15,680
something new that causes me friction

414
00:15:13,360 --> 00:15:18,320
that slows me down that makes me think

415
00:15:15,680 --> 00:15:19,040
and of course the friction at each step

416
00:15:18,320 --> 00:15:20,880
as well we

417
00:15:19,040 --> 00:15:22,319
talk a lot in security about oh we can't

418
00:15:20,880 --> 00:15:23,439
we can't add friction i'm going to

419
00:15:22,320 --> 00:15:25,600
challenge the fact

420
00:15:23,440 --> 00:15:27,040
about adding friction a little bit but

421
00:15:25,600 --> 00:15:29,040
we do need to be cognizant of the

422
00:15:27,040 --> 00:15:31,519
friction

423
00:15:29,040 --> 00:15:33,519
and along the same way with choices the

424
00:15:31,519 --> 00:15:35,120
number of choices the predictability if

425
00:15:33,519 --> 00:15:38,320
i choose

426
00:15:35,120 --> 00:15:40,160
this road to to take them to work

427
00:15:38,320 --> 00:15:41,759
do i get there every single day if i

428
00:15:40,160 --> 00:15:43,600
choose this tool

429
00:15:41,759 --> 00:15:45,759
does it work predictably every single

430
00:15:43,600 --> 00:15:49,040
day if i choose this option

431
00:15:45,759 --> 00:15:49,920
in jenkins can i have a predictability

432
00:15:49,040 --> 00:15:51,599
of each choice

433
00:15:49,920 --> 00:15:52,880
it's really intriguing if you want to

434
00:15:51,600 --> 00:15:54,959
mess with someone lower the

435
00:15:52,880 --> 00:15:58,000
predictability of choosing

436
00:15:54,959 --> 00:16:00,160
just by a couple percentage points it

437
00:15:58,000 --> 00:16:01,759
greatly slows down how fast people are

438
00:16:00,160 --> 00:16:02,560
able to make choices and move from steps

439
00:16:01,759 --> 00:16:04,480
to step

440
00:16:02,560 --> 00:16:06,000
and finally the cognitive load at each

441
00:16:04,480 --> 00:16:07,680
choice how much thinking do we need to

442
00:16:06,000 --> 00:16:09,680
do cognitive load would be

443
00:16:07,680 --> 00:16:11,519
you know effectively the friction that

444
00:16:09,680 --> 00:16:12,800
the choice incurs

445
00:16:11,519 --> 00:16:14,880
now how do we apply these things we

446
00:16:12,800 --> 00:16:17,040
apply them two ways we apply them

447
00:16:14,880 --> 00:16:18,480
to make it easier on our users and we

448
00:16:17,040 --> 00:16:21,120
apply it to make it harder on

449
00:16:18,480 --> 00:16:21,680
adversaries now i know it's like yeah

450
00:16:21,120 --> 00:16:24,000
yeah

451
00:16:21,680 --> 00:16:25,439
that's just your your opinion man i

452
00:16:24,000 --> 00:16:27,519
totally understand

453
00:16:25,440 --> 00:16:28,480
uh there is a lot of psychology being

454
00:16:27,519 --> 00:16:31,440
done on this

455
00:16:28,480 --> 00:16:32,000
uh i point you guys to soups as a great

456
00:16:31,440 --> 00:16:35,040
source

457
00:16:32,000 --> 00:16:37,120
of information to dig into and again if

458
00:16:35,040 --> 00:16:38,079
you know any students who are like man i

459
00:16:37,120 --> 00:16:39,519
really want to

460
00:16:38,079 --> 00:16:42,160
figure out how i could use industrial

461
00:16:39,519 --> 00:16:43,519
psych to solve the problem of devops

462
00:16:42,160 --> 00:16:45,680
security who would i talk to

463
00:16:43,519 --> 00:16:48,320
say hey by the way for this crazy guy at

464
00:16:45,680 --> 00:16:51,599
corncon here's his information

465
00:16:48,320 --> 00:16:53,519
so let's talk a bit about one really

466
00:16:51,600 --> 00:16:56,000
good example this and it's still an

467
00:16:53,519 --> 00:16:57,279
apple example not an apple fanboy but

468
00:16:56,000 --> 00:17:00,000
apple has done

469
00:16:57,279 --> 00:17:01,439
uh more to give us design examples than

470
00:17:00,000 --> 00:17:04,880
so many other companies

471
00:17:01,440 --> 00:17:05,520
uh early days early days we gave people

472
00:17:04,880 --> 00:17:07,679
phones

473
00:17:05,520 --> 00:17:09,280
and we said thou shalt and we locked the

474
00:17:07,679 --> 00:17:12,559
phone down and life was

475
00:17:09,280 --> 00:17:14,079
good i remember having uh blackberries

476
00:17:12,559 --> 00:17:15,918
and being able to put in

477
00:17:14,079 --> 00:17:18,240
passcodes and encryption and everything

478
00:17:15,919 --> 00:17:20,079
else then apple comes out

479
00:17:18,240 --> 00:17:21,679
everyone wants an apple right if you're

480
00:17:20,079 --> 00:17:24,720
the cool kid you've got the apple

481
00:17:21,679 --> 00:17:27,839
and so there's this flight

482
00:17:24,720 --> 00:17:29,679
to to byod now the problem was

483
00:17:27,839 --> 00:17:30,879
most of the people were not locking

484
00:17:29,679 --> 00:17:33,280
their phone

485
00:17:30,880 --> 00:17:34,160
um it slowed people down it added

486
00:17:33,280 --> 00:17:36,160
friction

487
00:17:34,160 --> 00:17:37,919
um it didn't get people into the device

488
00:17:36,160 --> 00:17:38,480
there's a famous rant steve jobs has

489
00:17:37,919 --> 00:17:40,000
about

490
00:17:38,480 --> 00:17:41,520
how you shouldn't add the lock screen

491
00:17:40,000 --> 00:17:42,960
and anyways

492
00:17:41,520 --> 00:17:44,799
you know we're trying to enable people

493
00:17:42,960 --> 00:17:46,400
to make them better we need to you know

494
00:17:44,799 --> 00:17:47,120
enable them to realize their highest

495
00:17:46,400 --> 00:17:50,000
esprit

496
00:17:47,120 --> 00:17:51,360
we get we get it we get it it was bad

497
00:17:50,000 --> 00:17:52,880
because people were walking around with

498
00:17:51,360 --> 00:17:54,240
unlocked phones and you could get in and

499
00:17:52,880 --> 00:17:56,720
do things

500
00:17:54,240 --> 00:17:58,480
so apple had this idea about adding a

501
00:17:56,720 --> 00:18:01,200
touch sensor right which is touch id and

502
00:17:58,480 --> 00:18:02,960
now face id

503
00:18:01,200 --> 00:18:04,240
and when they did it they looked at how

504
00:18:02,960 --> 00:18:05,520
people were using they looked at the

505
00:18:04,240 --> 00:18:06,480
paths they're taking they're picking up

506
00:18:05,520 --> 00:18:07,280
their phone they're hitting the home

507
00:18:06,480 --> 00:18:09,440
button and they're

508
00:18:07,280 --> 00:18:10,720
then browsing their apps pick up the

509
00:18:09,440 --> 00:18:12,080
phone hit the home button browse the

510
00:18:10,720 --> 00:18:12,559
apps pick up the home button hit you

511
00:18:12,080 --> 00:18:14,320
know

512
00:18:12,559 --> 00:18:16,240
that is the familiar path that people

513
00:18:14,320 --> 00:18:17,360
are taking um they also looked at the

514
00:18:16,240 --> 00:18:19,440
defaults are we

515
00:18:17,360 --> 00:18:21,039
we asking people to turn on pin codes or

516
00:18:19,440 --> 00:18:22,080
not how does that enrollment process

517
00:18:21,039 --> 00:18:24,720
look

518
00:18:22,080 --> 00:18:25,678
and they ran through a bunch of uh you

519
00:18:24,720 --> 00:18:27,760
know

520
00:18:25,679 --> 00:18:30,080
workflows and research projects and they

521
00:18:27,760 --> 00:18:33,600
determined hey if we put

522
00:18:30,080 --> 00:18:35,039
this touch id sensor on the home screen

523
00:18:33,600 --> 00:18:36,320
it's going to behave exactly like

524
00:18:35,039 --> 00:18:37,120
they're used to right we hit the home

525
00:18:36,320 --> 00:18:39,439
button

526
00:18:37,120 --> 00:18:41,199
you open up apps we go and they did that

527
00:18:39,440 --> 00:18:43,520
they did that and they paired that

528
00:18:41,200 --> 00:18:45,039
very simple familiar path with a very

529
00:18:43,520 --> 00:18:46,639
smart default choice

530
00:18:45,039 --> 00:18:48,320
to say hey you know enroll your

531
00:18:46,640 --> 00:18:50,799
fingerprint and

532
00:18:48,320 --> 00:18:51,760
within a year of the phone rolling out

533
00:18:50,799 --> 00:18:55,360
the adoption

534
00:18:51,760 --> 00:18:57,520
of the lock screen went from around 20

535
00:18:55,360 --> 00:18:59,840
to over 80 within a year within a year

536
00:18:57,520 --> 00:19:02,160
why it's a simple familiar

537
00:18:59,840 --> 00:19:02,879
and they knew what to do and at the same

538
00:19:02,160 --> 00:19:06,000
time was a

539
00:19:02,880 --> 00:19:07,039
much better security experience as we

540
00:19:06,000 --> 00:19:08,960
all know

541
00:19:07,039 --> 00:19:10,640
with uh with touch id versus walking

542
00:19:08,960 --> 00:19:11,520
around with your computer or your i'm

543
00:19:10,640 --> 00:19:15,679
sorry your phone

544
00:19:11,520 --> 00:19:17,840
unlocked so when we talk about the

545
00:19:15,679 --> 00:19:20,720
paths they take let's first look at the

546
00:19:17,840 --> 00:19:22,720
the user side of things

547
00:19:20,720 --> 00:19:25,679
and the user side of things we know is

548
00:19:22,720 --> 00:19:28,320
is effectively the devops world right

549
00:19:25,679 --> 00:19:29,440
um we we build code we design code we've

550
00:19:28,320 --> 00:19:31,840
got a path

551
00:19:29,440 --> 00:19:33,200
to determined and we know if we don't do

552
00:19:31,840 --> 00:19:35,760
a good job

553
00:19:33,200 --> 00:19:36,880
from uh a experience perspective we add

554
00:19:35,760 --> 00:19:38,400
friction in

555
00:19:36,880 --> 00:19:40,160
the developers are just going to chew

556
00:19:38,400 --> 00:19:43,440
away right around and

557
00:19:40,160 --> 00:19:44,160
and get their work done without engaging

558
00:19:43,440 --> 00:19:45,919
us

559
00:19:44,160 --> 00:19:46,960
we also know the path the adversaries

560
00:19:45,919 --> 00:19:48,799
are going to take there's many ways to

561
00:19:46,960 --> 00:19:49,600
do this as a kill chain and the attack

562
00:19:48,799 --> 00:19:52,559
path

563
00:19:49,600 --> 00:19:53,760
but fundamentally if we look at some

564
00:19:52,559 --> 00:19:56,399
threat modeling

565
00:19:53,760 --> 00:19:57,600
if we look at the overall process

566
00:19:56,400 --> 00:19:59,760
criminals do

567
00:19:57,600 --> 00:20:01,600
effectively the same path depending on

568
00:19:59,760 --> 00:20:02,480
the attack and we know too if we don't

569
00:20:01,600 --> 00:20:04,320
have

570
00:20:02,480 --> 00:20:05,919
good friction if we don't have the right

571
00:20:04,320 --> 00:20:08,158
number of steps if we don't have

572
00:20:05,919 --> 00:20:09,840
things in the way the attackers are

573
00:20:08,159 --> 00:20:11,760
going to mission impossible style into

574
00:20:09,840 --> 00:20:14,240
our apps and our environments and then

575
00:20:11,760 --> 00:20:16,080
we have a breach

576
00:20:14,240 --> 00:20:17,360
so we can start thinking about all those

577
00:20:16,080 --> 00:20:20,240
different controls i mentioned

578
00:20:17,360 --> 00:20:20,879
earlier and where they go on the path

579
00:20:20,240 --> 00:20:23,520
now the

580
00:20:20,880 --> 00:20:24,559
the key thing is inserting those in a

581
00:20:23,520 --> 00:20:28,080
way

582
00:20:24,559 --> 00:20:30,960
that reduces uh

583
00:20:28,080 --> 00:20:31,840
friction of the insertion right so using

584
00:20:30,960 --> 00:20:34,559
automation

585
00:20:31,840 --> 00:20:35,840
using better tooling working with the

586
00:20:34,559 --> 00:20:37,280
people we can talk about that in a

587
00:20:35,840 --> 00:20:40,480
little bit but the point is

588
00:20:37,280 --> 00:20:41,918
we want to insert security controls that

589
00:20:40,480 --> 00:20:44,240
are easy on devops

590
00:20:41,919 --> 00:20:45,440
but are hard on attackers and by looking

591
00:20:44,240 --> 00:20:46,720
at those two paths

592
00:20:45,440 --> 00:20:48,559
we can start to see that a lot of

593
00:20:46,720 --> 00:20:50,000
security controls we roll out

594
00:20:48,559 --> 00:20:51,760
attackers don't even care about right

595
00:20:50,000 --> 00:20:53,360
it's not on their attack path

596
00:20:51,760 --> 00:20:55,919
it's not on their procedure all it's

597
00:20:53,360 --> 00:20:59,199
doing is adding friction and pain

598
00:20:55,919 --> 00:21:01,200
to our developers by contrast there's a

599
00:20:59,200 --> 00:21:04,240
lot of controls we can put in place

600
00:21:01,200 --> 00:21:07,760
they're completely invisible to to the

601
00:21:04,240 --> 00:21:10,480
developer that uh have tremendous

602
00:21:07,760 --> 00:21:12,158
stopping power

603
00:21:10,480 --> 00:21:14,320
so when we plan this out let's talk

604
00:21:12,159 --> 00:21:17,679
about uh life cycles

605
00:21:14,320 --> 00:21:18,639
of doing this and how to do this design

606
00:21:17,679 --> 00:21:20,559
process

607
00:21:18,640 --> 00:21:22,159
uh fundamentally you start with the

608
00:21:20,559 --> 00:21:24,158
vision you look at what the business is

609
00:21:22,159 --> 00:21:26,159
trying to achieve what the security

610
00:21:24,159 --> 00:21:27,280
functions are doing what controls you

611
00:21:26,159 --> 00:21:28,720
have in place

612
00:21:27,280 --> 00:21:30,960
and what that tooling looks like can you

613
00:21:28,720 --> 00:21:33,440
plan out the implementation this is the

614
00:21:30,960 --> 00:21:34,799
overall process oftentimes we want to

615
00:21:33,440 --> 00:21:37,200
jump right into the tooling

616
00:21:34,799 --> 00:21:38,720
it's what's exciting it's what's fun

617
00:21:37,200 --> 00:21:41,600
everyone wants a whole bunch of blinking

618
00:21:38,720 --> 00:21:43,919
boxes and wants to talk about the latest

619
00:21:41,600 --> 00:21:46,240
code scanners and latest tools but if we

620
00:21:43,919 --> 00:21:49,520
really start thinking about the

621
00:21:46,240 --> 00:21:50,960
functionality uh and that workflow right

622
00:21:49,520 --> 00:21:52,639
the paths are taking the choice they're

623
00:21:50,960 --> 00:21:54,400
making at these different levels

624
00:21:52,640 --> 00:21:56,000
i believe we can do better in tooling

625
00:21:54,400 --> 00:21:57,679
instead of just jumping

626
00:21:56,000 --> 00:22:00,080
right into going oh yeah it's simple

627
00:21:57,679 --> 00:22:02,799
just just deploy this

628
00:22:00,080 --> 00:22:02,799
so for example

629
00:22:03,840 --> 00:22:08,000
let's assume we're talking about sassed

630
00:22:06,000 --> 00:22:09,919
and dashed or inactive or software

631
00:22:08,000 --> 00:22:11,600
composition nests

632
00:22:09,919 --> 00:22:13,919
when we start looking at these tools we

633
00:22:11,600 --> 00:22:16,719
want to start off by looking at

634
00:22:13,919 --> 00:22:17,520
the the tool chain that the devops team

635
00:22:16,720 --> 00:22:20,320
is using

636
00:22:17,520 --> 00:22:22,158
we want to look at uh their automation

637
00:22:20,320 --> 00:22:23,678
layer we want to look at how to break

638
00:22:22,159 --> 00:22:25,600
the build we want to have conversations

639
00:22:23,679 --> 00:22:28,480
about should we break the build

640
00:22:25,600 --> 00:22:29,360
or should we just alert we want to look

641
00:22:28,480 --> 00:22:32,159
for ways

642
00:22:29,360 --> 00:22:33,840
that these tools can be run

643
00:22:32,159 --> 00:22:34,799
automatically we want to look at ways

644
00:22:33,840 --> 00:22:36,399
these tools can be

645
00:22:34,799 --> 00:22:38,720
launched from the automation layer

646
00:22:36,400 --> 00:22:40,080
without a lot of problems and that's all

647
00:22:38,720 --> 00:22:41,600
on the usability side right

648
00:22:40,080 --> 00:22:43,120
we want to make sure that fundamentally

649
00:22:41,600 --> 00:22:46,399
we're reducing

650
00:22:43,120 --> 00:22:48,320
the attack surface and reducing the

651
00:22:46,400 --> 00:22:51,200
vulnerable lines of code that the

652
00:22:48,320 --> 00:22:51,200
criminals get in

653
00:22:52,640 --> 00:22:56,960
and another side of that is also making

654
00:22:55,039 --> 00:22:58,400
sure that we're taking a look for this

655
00:22:56,960 --> 00:23:01,760
configuration

656
00:22:58,400 --> 00:23:03,600
uh i find it really fascinating that as

657
00:23:01,760 --> 00:23:06,320
our code has gotten better

658
00:23:03,600 --> 00:23:06,639
uh the likelihood of us making mistakes

659
00:23:06,320 --> 00:23:10,080
has

660
00:23:06,640 --> 00:23:12,080
also gotten significantly faster so

661
00:23:10,080 --> 00:23:13,280
the attackers are moving from the the

662
00:23:12,080 --> 00:23:15,439
hardened systems

663
00:23:13,280 --> 00:23:18,000
up the stack to where we're making these

664
00:23:15,440 --> 00:23:18,000
mistakes

665
00:23:19,679 --> 00:23:22,880
so we're going to write a single line of

666
00:23:21,440 --> 00:23:24,159
code when we write that single line code

667
00:23:22,880 --> 00:23:24,720
it's going to increase the attack

668
00:23:24,159 --> 00:23:27,840
surface

669
00:23:24,720 --> 00:23:31,520
we want to pair additional controls

670
00:23:27,840 --> 00:23:34,240
to scan that and and find things now the

671
00:23:31,520 --> 00:23:35,200
the security mindset is scan all the

672
00:23:34,240 --> 00:23:37,120
things right

673
00:23:35,200 --> 00:23:39,360
we will find all the things we'll find

674
00:23:37,120 --> 00:23:41,760
all the problems we will not be breached

675
00:23:39,360 --> 00:23:43,439
we will let them know what we see

676
00:23:41,760 --> 00:23:44,799
and of course you talk to any developer

677
00:23:43,440 --> 00:23:47,840
team and they

678
00:23:44,799 --> 00:23:51,600
are sometimes surprisingly

679
00:23:47,840 --> 00:23:54,879
less than pleased with that approach

680
00:23:51,600 --> 00:23:57,678
so at this point we start talking about

681
00:23:54,880 --> 00:23:59,039
the the paths they take we want to look

682
00:23:57,679 --> 00:24:01,279
at how they handle

683
00:23:59,039 --> 00:24:03,360
bugs how they handle defects we want to

684
00:24:01,279 --> 00:24:04,640
make security defects look just like any

685
00:24:03,360 --> 00:24:08,799
other security defect we

686
00:24:04,640 --> 00:24:12,159
also this is really key

687
00:24:08,799 --> 00:24:15,600
only want to act on the defects that are

688
00:24:12,159 --> 00:24:17,840
known to be exploited by attackers when

689
00:24:15,600 --> 00:24:19,279
achieving their objectives now you say

690
00:24:17,840 --> 00:24:20,480
well wait wait a minute wait a minute

691
00:24:19,279 --> 00:24:22,320
isn't the whole idea about

692
00:24:20,480 --> 00:24:23,760
sas and dasa you'll find all the things

693
00:24:22,320 --> 00:24:25,520
that attacker could possibly do

694
00:24:23,760 --> 00:24:27,679
ever and make a big list and give to

695
00:24:25,520 --> 00:24:33,520
developers they fix it yes

696
00:24:27,679 --> 00:24:37,279
yes it is it is the reality is

697
00:24:33,520 --> 00:24:40,639
um i used to uh i used to run an oasp

698
00:24:37,279 --> 00:24:41,919
chapter i was uh an early very strong

699
00:24:40,640 --> 00:24:44,880
believer

700
00:24:41,919 --> 00:24:46,480
in the os top ten um and i was really

701
00:24:44,880 --> 00:24:48,080
glad when those top ten include the

702
00:24:46,480 --> 00:24:50,159
misconfigurations by the way i believe

703
00:24:48,080 --> 00:24:52,720
that security is not the control

704
00:24:50,159 --> 00:24:54,480
security is the context which you will

705
00:24:52,720 --> 00:24:55,919
find in the misconfigurations in the

706
00:24:54,480 --> 00:24:58,799
hosting infrastructure

707
00:24:55,919 --> 00:25:00,240
um but when we started with os type 10

708
00:24:58,799 --> 00:25:01,520
we thought hey if we just told everyone

709
00:25:00,240 --> 00:25:02,880
all the things they did wrong they would

710
00:25:01,520 --> 00:25:05,279
fix it life would be good

711
00:25:02,880 --> 00:25:06,240
what we really found is year after year

712
00:25:05,279 --> 00:25:08,000
after year

713
00:25:06,240 --> 00:25:09,360
it's like sql injection and cross-site

714
00:25:08,000 --> 00:25:12,799
scripting right

715
00:25:09,360 --> 00:25:14,639
the the main scanners on the market will

716
00:25:12,799 --> 00:25:15,840
find a thousand things wrong of those

717
00:25:14,640 --> 00:25:17,600
thousand things wrong

718
00:25:15,840 --> 00:25:19,039
only ten of them actually matter the

719
00:25:17,600 --> 00:25:21,279
trick in

720
00:25:19,039 --> 00:25:22,320
this world when looking at the past they

721
00:25:21,279 --> 00:25:24,400
take our

722
00:25:22,320 --> 00:25:26,240
developers and our adversaries is

723
00:25:24,400 --> 00:25:27,279
defined and surface those ten things

724
00:25:26,240 --> 00:25:30,640
reliably

725
00:25:27,279 --> 00:25:33,039
and not talk about the 990 things that

726
00:25:30,640 --> 00:25:35,039
would just bury the developers in excess

727
00:25:33,039 --> 00:25:37,039
work

728
00:25:35,039 --> 00:25:38,960
that again goes back to that empathy

729
00:25:37,039 --> 00:25:42,640
right

730
00:25:38,960 --> 00:25:44,480
so we also can look at uniting code

731
00:25:42,640 --> 00:25:46,320
quality and security right the pass they

732
00:25:44,480 --> 00:25:48,480
take much like hey i pick up my iphone

733
00:25:46,320 --> 00:25:51,360
and i hit the home button and i go

734
00:25:48,480 --> 00:25:52,159
today our dev team is looking at code

735
00:25:51,360 --> 00:25:55,600
quality

736
00:25:52,159 --> 00:25:56,799
they've got tqm programs it is a source

737
00:25:55,600 --> 00:25:59,520
of concern

738
00:25:56,799 --> 00:26:01,200
we can bundle security and i think it's

739
00:25:59,520 --> 00:26:02,960
absolutely important we make security

740
00:26:01,200 --> 00:26:04,400
another defect just like any other

741
00:26:02,960 --> 00:26:07,279
defect so it looks

742
00:26:04,400 --> 00:26:07,919
feels and and operates the same another

743
00:26:07,279 --> 00:26:09,840
thing i say

744
00:26:07,919 --> 00:26:11,600
quite frequently is when work looks like

745
00:26:09,840 --> 00:26:12,799
work work gets done

746
00:26:11,600 --> 00:26:14,559
and that's just another way of saying

747
00:26:12,799 --> 00:26:16,080
when the pass that they take looks like

748
00:26:14,559 --> 00:26:17,760
any other path they're more likely to

749
00:26:16,080 --> 00:26:19,360
take it it's familiar

750
00:26:17,760 --> 00:26:21,120
and it'll get done so if we can do the

751
00:26:19,360 --> 00:26:21,678
same thing with the vulnerabilities we

752
00:26:21,120 --> 00:26:23,279
find

753
00:26:21,679 --> 00:26:26,400
we have a much greater chance of

754
00:26:23,279 --> 00:26:27,919
securing our systems

755
00:26:26,400 --> 00:26:29,840
all right now let's talk about the the

756
00:26:27,919 --> 00:26:31,200
approaches to security the opposite side

757
00:26:29,840 --> 00:26:34,240
of things

758
00:26:31,200 --> 00:26:36,400
from a criminal perspective

759
00:26:34,240 --> 00:26:37,919
we talk about defensive development we

760
00:26:36,400 --> 00:26:39,039
want to do a few different things right

761
00:26:37,919 --> 00:26:40,320
we want to make sure that we're doing

762
00:26:39,039 --> 00:26:43,600
threat modeling regularly

763
00:26:40,320 --> 00:26:45,678
obviously uh it is always intriguing the

764
00:26:43,600 --> 00:26:49,199
functionality that we build

765
00:26:45,679 --> 00:26:50,240
um and the things that we create that

766
00:26:49,200 --> 00:26:52,640
seem so simple

767
00:26:50,240 --> 00:26:55,120
seems so obvious seems so great that

768
00:26:52,640 --> 00:26:56,000
they get misused right oath tokens right

769
00:26:55,120 --> 00:26:58,879
now are

770
00:26:56,000 --> 00:27:00,080
are um you know in the news because

771
00:26:58,880 --> 00:27:02,480
they're being leveraged

772
00:27:00,080 --> 00:27:04,158
as ways to get in systems at the time

773
00:27:02,480 --> 00:27:05,919
developers and the people who built the

774
00:27:04,159 --> 00:27:07,520
oath and odc standards are like hey this

775
00:27:05,919 --> 00:27:08,720
is great this is great we can pass

776
00:27:07,520 --> 00:27:10,639
around token

777
00:27:08,720 --> 00:27:11,840
you know we i know you you can use this

778
00:27:10,640 --> 00:27:14,720
token to authorize

779
00:27:11,840 --> 00:27:15,600
the user and we can create uh

780
00:27:14,720 --> 00:27:18,080
distributed

781
00:27:15,600 --> 00:27:18,840
federated uh authorizations and with

782
00:27:18,080 --> 00:27:21,760
oitc

783
00:27:18,840 --> 00:27:23,760
authentication awesome well i don't know

784
00:27:21,760 --> 00:27:27,120
that we necessarily thought

785
00:27:23,760 --> 00:27:29,840
through is all the great ways

786
00:27:27,120 --> 00:27:31,600
that this new experience for users

787
00:27:29,840 --> 00:27:33,039
creates for criminals to pass around

788
00:27:31,600 --> 00:27:34,879
tokens and do things

789
00:27:33,039 --> 00:27:36,240
uh in the pharisees now that said that

790
00:27:34,880 --> 00:27:38,080
we didn't think that there are threat

791
00:27:36,240 --> 00:27:39,360
models and everything but the point is

792
00:27:38,080 --> 00:27:41,600
is that when we build these things we

793
00:27:39,360 --> 00:27:43,520
stand them up the people who are doing

794
00:27:41,600 --> 00:27:44,559
it don't necessarily think about what

795
00:27:43,520 --> 00:27:46,000
the criminals may

796
00:27:44,559 --> 00:27:47,600
be going through because we're thinking

797
00:27:46,000 --> 00:27:48,480
about it from the user's perspective

798
00:27:47,600 --> 00:27:50,639
right we've got a

799
00:27:48,480 --> 00:27:52,399
a mental model much like doug and bart

800
00:27:50,640 --> 00:27:54,240
with his his musical instrument we got a

801
00:27:52,399 --> 00:27:56,080
mental model that an app is an app

802
00:27:54,240 --> 00:27:58,000
but to a criminal an app is a

803
00:27:56,080 --> 00:27:59,279
vulnerability that i'm using to pivot

804
00:27:58,000 --> 00:28:00,960
we find those things with threat

805
00:27:59,279 --> 00:28:02,399
modeling we find those things with abuse

806
00:28:00,960 --> 00:28:05,279
case to development

807
00:28:02,399 --> 00:28:06,479
with having someone who is focused on

808
00:28:05,279 --> 00:28:09,120
how the criminals think

809
00:28:06,480 --> 00:28:10,640
embedded in the devops team and of

810
00:28:09,120 --> 00:28:11,840
course we look for controls we write

811
00:28:10,640 --> 00:28:15,360
codes and tests

812
00:28:11,840 --> 00:28:19,039
um and finally we integrate

813
00:28:15,360 --> 00:28:19,600
the tasks for those controls within the

814
00:28:19,039 --> 00:28:22,720
overall

815
00:28:19,600 --> 00:28:25,918
process one of the more mature devops

816
00:28:22,720 --> 00:28:29,360
teams i've had the privilege to

817
00:28:25,919 --> 00:28:31,520
work with and partner with really

818
00:28:29,360 --> 00:28:33,039
took this to the next level and use the

819
00:28:31,520 --> 00:28:36,158
controls

820
00:28:33,039 --> 00:28:38,879
uh as a set of uh

821
00:28:36,159 --> 00:28:40,080
outcomes much like you would use you

822
00:28:38,880 --> 00:28:40,799
know i'm going to add such a shopping

823
00:28:40,080 --> 00:28:42,960
cart and add

824
00:28:40,799 --> 00:28:44,720
you know your unit tests right they

825
00:28:42,960 --> 00:28:46,159
added as a set of outcomes and they

826
00:28:44,720 --> 00:28:47,760
test against that why because they

827
00:28:46,159 --> 00:28:49,200
realized that

828
00:28:47,760 --> 00:28:50,799
if you have a controlled place that's

829
00:28:49,200 --> 00:28:54,000
great but it doesn't always

830
00:28:50,799 --> 00:28:57,840
stay in place let's test and

831
00:28:54,000 --> 00:28:58,240
hammer on it i think a good example of

832
00:28:57,840 --> 00:29:01,918
this

833
00:28:58,240 --> 00:29:03,600
is um back to my umbrella story right

834
00:29:01,919 --> 00:29:06,799
you know it's gonna rain i was in

835
00:29:03,600 --> 00:29:08,480
um zurich before the world closed before

836
00:29:06,799 --> 00:29:09,279
the great reboot i love that term by the

837
00:29:08,480 --> 00:29:10,960
way the great

838
00:29:09,279 --> 00:29:12,880
reboot i don't know who started that

839
00:29:10,960 --> 00:29:14,480
term but it's such a good

840
00:29:12,880 --> 00:29:16,720
way of thinking about this pandemic

841
00:29:14,480 --> 00:29:18,240
we're on so before we turned it off and

842
00:29:16,720 --> 00:29:20,640
turned it back on again

843
00:29:18,240 --> 00:29:22,480
i was in zurich and i knew it rained in

844
00:29:20,640 --> 00:29:23,840
zurich and so i did my threat model like

845
00:29:22,480 --> 00:29:26,559
i will bring an umbrella i did not bring

846
00:29:23,840 --> 00:29:28,639
a concrete umbrella i know better

847
00:29:26,559 --> 00:29:30,639
i brought in my umbrella i brought my

848
00:29:28,640 --> 00:29:34,000
wife we're going out to dinner

849
00:29:30,640 --> 00:29:36,080
uh and uh so we we get in the car

850
00:29:34,000 --> 00:29:37,279
we go to dinner we get out of the or get

851
00:29:36,080 --> 00:29:39,918
in the car go out

852
00:29:37,279 --> 00:29:41,600
to the downtown get out of the car we

853
00:29:39,919 --> 00:29:43,039
walked maybe a half block and the sky's

854
00:29:41,600 --> 00:29:45,600
open it's raining

855
00:29:43,039 --> 00:29:47,520
and uh so i've got my threat model it

856
00:29:45,600 --> 00:29:48,559
rains in zurich i've got my control i've

857
00:29:47,520 --> 00:29:52,559
got an umbrella

858
00:29:48,559 --> 00:29:54,000
um this is the point where we shine

859
00:29:52,559 --> 00:29:56,559
right as security people this is our

860
00:29:54,000 --> 00:29:58,320
moment we've done our work and that was

861
00:29:56,559 --> 00:29:59,440
the moment when my wife turned to me and

862
00:29:58,320 --> 00:30:02,639
goes

863
00:29:59,440 --> 00:30:02,640
didn't you bring an umbrella

864
00:30:04,480 --> 00:30:10,640
yes where is it in the hotel

865
00:30:08,720 --> 00:30:12,000
a little fat a lot of good it does this

866
00:30:10,640 --> 00:30:14,559
right now right

867
00:30:12,000 --> 00:30:16,320
where's the control do you need it i use

868
00:30:14,559 --> 00:30:17,440
this story just to simply illustrate the

869
00:30:16,320 --> 00:30:20,000
point that

870
00:30:17,440 --> 00:30:21,600
we put things in place if we don't test

871
00:30:20,000 --> 00:30:23,520
them we don't know if they're still

872
00:30:21,600 --> 00:30:24,959
effective the other thing we need to

873
00:30:23,520 --> 00:30:27,520
remember is putting these things in

874
00:30:24,960 --> 00:30:29,520
place to increase the steps the attacker

875
00:30:27,520 --> 00:30:31,600
needs to take

876
00:30:29,520 --> 00:30:33,360
and we for a long time didn't know how

877
00:30:31,600 --> 00:30:36,080
many steps that that was

878
00:30:33,360 --> 00:30:37,840
verizon in 2019 and 2020 put out their

879
00:30:36,080 --> 00:30:39,600
reports some really good data

880
00:30:37,840 --> 00:30:41,360
that shows us about 10 right if we can

881
00:30:39,600 --> 00:30:42,480
increase the number of steps attacker

882
00:30:41,360 --> 00:30:45,520
needs to take

883
00:30:42,480 --> 00:30:48,320
to 10 or more we can cut the success

884
00:30:45,520 --> 00:30:49,279
of that attack in half we can cut that

885
00:30:48,320 --> 00:30:51,840
success

886
00:30:49,279 --> 00:30:51,840
below 50

887
00:30:52,399 --> 00:30:56,320
so we want to add those steps where it

888
00:30:53,919 --> 00:30:56,320
counts

889
00:30:57,039 --> 00:31:00,559
and validate those controls to make sure

890
00:30:58,799 --> 00:31:02,399
they're actually effective

891
00:31:00,559 --> 00:31:04,320
now when things go wrong when there's an

892
00:31:02,399 --> 00:31:07,439
incident when there's a breach

893
00:31:04,320 --> 00:31:07,439
this is another area

894
00:31:07,600 --> 00:31:11,519
which provides for a really great

895
00:31:09,600 --> 00:31:14,000
feedback loop

896
00:31:11,519 --> 00:31:15,200
when there when there is a response we

897
00:31:14,000 --> 00:31:16,480
want to feed that back to threat

898
00:31:15,200 --> 00:31:18,399
modeling just like we do with

899
00:31:16,480 --> 00:31:19,760
our pen test just like we do with their

900
00:31:18,399 --> 00:31:21,439
internal reports

901
00:31:19,760 --> 00:31:22,720
uh for the teams that are running bug

902
00:31:21,440 --> 00:31:23,360
bounties just like we do with bug

903
00:31:22,720 --> 00:31:25,600
bounties

904
00:31:23,360 --> 00:31:27,439
and feed that back in so that we can

905
00:31:25,600 --> 00:31:30,320
open the aperture

906
00:31:27,440 --> 00:31:31,919
or close the aperture of the control in

907
00:31:30,320 --> 00:31:33,200
this case we're talking again about our

908
00:31:31,919 --> 00:31:36,320
code quality sca

909
00:31:33,200 --> 00:31:36,720
is test so we open the aperture to look

910
00:31:36,320 --> 00:31:39,200
at

911
00:31:36,720 --> 00:31:40,960
more of the the findings because maybe

912
00:31:39,200 --> 00:31:42,960
there's a class of bugs that

913
00:31:40,960 --> 00:31:44,640
we thought were not a big deal until

914
00:31:42,960 --> 00:31:46,720
they started being attacked

915
00:31:44,640 --> 00:31:48,720
or or close it to make sure that we're

916
00:31:46,720 --> 00:31:49,360
really just focusing on the ones that

917
00:31:48,720 --> 00:31:52,080
matter

918
00:31:49,360 --> 00:31:54,000
so we're acting as much as possible out

919
00:31:52,080 --> 00:31:56,720
of that space where it is adding steps

920
00:31:54,000 --> 00:31:56,720
to the attacker

921
00:31:58,080 --> 00:32:01,199
and then doing that validation

922
00:32:00,080 --> 00:32:04,080
integration with

923
00:32:01,200 --> 00:32:04,080
that's a response

924
00:32:04,720 --> 00:32:10,480
i want to talk a bit about adoption um

925
00:32:08,159 --> 00:32:11,600
and then we will hit the conclusion and

926
00:32:10,480 --> 00:32:13,440
and get uh

927
00:32:11,600 --> 00:32:14,959
get you guys onto the next section by

928
00:32:13,440 --> 00:32:19,919
the top of the hour

929
00:32:14,960 --> 00:32:22,000
i think uh the the successful control

930
00:32:19,919 --> 00:32:23,519
oftentimes we talked about in terms of

931
00:32:22,000 --> 00:32:27,120
defense and depth how

932
00:32:23,519 --> 00:32:29,600
deeply have we stacked those controls

933
00:32:27,120 --> 00:32:31,760
right how deeply have we lined them up

934
00:32:29,600 --> 00:32:32,158
so that no one can possibly get past

935
00:32:31,760 --> 00:32:33,640
them

936
00:32:32,159 --> 00:32:35,600
but as we're seeing with the

937
00:32:33,640 --> 00:32:39,120
misconfigurations as we're seeing

938
00:32:35,600 --> 00:32:41,120
with um the the unevenness of controls

939
00:32:39,120 --> 00:32:44,320
as we're seeing with breach after breach

940
00:32:41,120 --> 00:32:46,320
of common things like ec two buckets

941
00:32:44,320 --> 00:32:49,600
being left open and whatnot

942
00:32:46,320 --> 00:32:52,559
um it's less about how deep

943
00:32:49,600 --> 00:32:54,959
the security is and more about how

944
00:32:52,559 --> 00:32:57,279
widely it's adopted

945
00:32:54,960 --> 00:32:59,679
there's a couple different tricks here

946
00:32:57,279 --> 00:33:00,480
to get controls widely adopted in

947
00:32:59,679 --> 00:33:02,399
general

948
00:33:00,480 --> 00:33:04,399
and in particular with our devops team

949
00:33:02,399 --> 00:33:08,239
the first one i want to talk about

950
00:33:04,399 --> 00:33:11,518
is and this may sound

951
00:33:08,240 --> 00:33:12,240
strange but making security actually

952
00:33:11,519 --> 00:33:14,799
something that

953
00:33:12,240 --> 00:33:15,960
is is attractive uh i want to take you

954
00:33:14,799 --> 00:33:19,279
back to

955
00:33:15,960 --> 00:33:21,519
1929 in 1929 you know flying

956
00:33:19,279 --> 00:33:23,279
what was new uh we didn't have an air

957
00:33:21,519 --> 00:33:25,519
force in america yet

958
00:33:23,279 --> 00:33:27,440
uh pilots were our heroes they were

959
00:33:25,519 --> 00:33:30,880
amazing their things they were doing

960
00:33:27,440 --> 00:33:31,600
and uh the u.s army corps contacted this

961
00:33:30,880 --> 00:33:34,080
guy named

962
00:33:31,600 --> 00:33:35,199
mccreedy uh who worked with boston home

963
00:33:34,080 --> 00:33:36,799
say look we need

964
00:33:35,200 --> 00:33:38,159
safety goggles we need good safety

965
00:33:36,799 --> 00:33:39,360
goggles we need something that will

966
00:33:38,159 --> 00:33:42,960
protect

967
00:33:39,360 --> 00:33:44,080
uh our our pilots and they came up with

968
00:33:42,960 --> 00:33:45,760
a design

969
00:33:44,080 --> 00:33:47,840
that you all will probably recognize

970
00:33:45,760 --> 00:33:50,158
today and the design

971
00:33:47,840 --> 00:33:50,959
would be the ray-bans right the ray-bans

972
00:33:50,159 --> 00:33:54,320
which

973
00:33:50,960 --> 00:33:56,000
had anti-glare and one fog up and would

974
00:33:54,320 --> 00:33:58,480
protect the pilot's eyes

975
00:33:56,000 --> 00:34:00,320
uh almost no one thinks of a ray-ban as

976
00:33:58,480 --> 00:34:01,440
a pair of safety goggles this is not the

977
00:34:00,320 --> 00:34:03,360
way we think

978
00:34:01,440 --> 00:34:04,799
because ray-bans are cool right i mean

979
00:34:03,360 --> 00:34:07,279
who doesn't want to wear

980
00:34:04,799 --> 00:34:08,800
cool pair of sunglasses part of the

981
00:34:07,279 --> 00:34:10,239
reason they're cool is because they were

982
00:34:08,800 --> 00:34:11,520
used by pilots

983
00:34:10,239 --> 00:34:13,279
part of the reason they're cool is

984
00:34:11,520 --> 00:34:15,759
because some of our like uh

985
00:34:13,280 --> 00:34:16,639
back in the day our our celebrities like

986
00:34:15,760 --> 00:34:19,359
james dean

987
00:34:16,639 --> 00:34:21,040
and audrey hepburn started wearing

988
00:34:19,359 --> 00:34:22,960
ray-bans right in movies like

989
00:34:21,040 --> 00:34:25,119
rebel without a cause and breakfast at

990
00:34:22,960 --> 00:34:28,879
tiffany's and suddenly i was like wow

991
00:34:25,119 --> 00:34:29,520
ratings are awesome and so the adoption

992
00:34:28,879 --> 00:34:32,159
rate

993
00:34:29,520 --> 00:34:34,480
of what was formerly a security control

994
00:34:32,159 --> 00:34:36,079
formerly a safety issue went through the

995
00:34:34,480 --> 00:34:38,079
roof

996
00:34:36,079 --> 00:34:39,440
in the security world i had a similar

997
00:34:38,079 --> 00:34:42,800
experience with this

998
00:34:39,440 --> 00:34:43,760
back in the day where it was very

999
00:34:42,800 --> 00:34:46,079
expensive

1000
00:34:43,760 --> 00:34:46,800
for our users to use a certain piece of

1001
00:34:46,079 --> 00:34:49,119
software

1002
00:34:46,800 --> 00:34:50,960
that certain piece of software had a

1003
00:34:49,119 --> 00:34:54,159
multi-factor token

1004
00:34:50,960 --> 00:34:56,560
and because only the the you know top

1005
00:34:54,159 --> 00:34:57,200
dogs in our firm the audrey hepburns and

1006
00:34:56,560 --> 00:34:59,839
the

1007
00:34:57,200 --> 00:35:00,399
james deans of our company had access to

1008
00:34:59,839 --> 00:35:02,480
this

1009
00:35:00,400 --> 00:35:03,920
only they had access to the multi-factor

1010
00:35:02,480 --> 00:35:06,560
authentication

1011
00:35:03,920 --> 00:35:08,240
a weird thing happened in that suddenly

1012
00:35:06,560 --> 00:35:08,960
people wanted more of these multi-factor

1013
00:35:08,240 --> 00:35:11,598
tokens

1014
00:35:08,960 --> 00:35:12,800
it was it became a status symbol to say

1015
00:35:11,599 --> 00:35:16,079
yeah i'm also one of the

1016
00:35:12,800 --> 00:35:19,680
the you know big dogs who who has this

1017
00:35:16,079 --> 00:35:20,800
particular access and you wouldn't think

1018
00:35:19,680 --> 00:35:22,240
about it right just like you wouldn't

1019
00:35:20,800 --> 00:35:24,079
think ray-bans

1020
00:35:22,240 --> 00:35:25,759
would be safety goggles you won't think

1021
00:35:24,079 --> 00:35:29,200
a security token

1022
00:35:25,760 --> 00:35:31,839
would be a attractive feature

1023
00:35:29,200 --> 00:35:33,200
my point here is adoption of the

1024
00:35:31,839 --> 00:35:34,640
security tool chain is

1025
00:35:33,200 --> 00:35:36,399
is the missing link and to get it

1026
00:35:34,640 --> 00:35:38,720
adopted we need to

1027
00:35:36,400 --> 00:35:40,000
first find our our developers who are

1028
00:35:38,720 --> 00:35:42,560
audrey hepburn's

1029
00:35:40,000 --> 00:35:43,599
and our james deans and we need to get

1030
00:35:42,560 --> 00:35:46,078
them on board

1031
00:35:43,599 --> 00:35:47,440
because those role models are going to

1032
00:35:46,079 --> 00:35:48,400
make the security control more

1033
00:35:47,440 --> 00:35:50,720
attractive

1034
00:35:48,400 --> 00:35:52,720
and also back to the empathy side of

1035
00:35:50,720 --> 00:35:56,160
things help give us feedback

1036
00:35:52,720 --> 00:35:56,160
as to whether or not the control is

1037
00:35:56,839 --> 00:36:00,320
appropriate

1038
00:35:58,320 --> 00:36:01,920
so another example of this that was

1039
00:36:00,320 --> 00:36:06,000
pretty snazzy where

1040
00:36:01,920 --> 00:36:08,880
the um the devops team

1041
00:36:06,000 --> 00:36:09,760
adopted zero trust for their application

1042
00:36:08,880 --> 00:36:13,599
workloads

1043
00:36:09,760 --> 00:36:16,400
they did it why because they wanted to

1044
00:36:13,599 --> 00:36:18,400
have a resilient application if you're

1045
00:36:16,400 --> 00:36:20,160
from with chaos engineering

1046
00:36:18,400 --> 00:36:21,520
they ruined taking a chaos engineering

1047
00:36:20,160 --> 00:36:22,720
perspective and they're also thinking

1048
00:36:21,520 --> 00:36:26,160
about chaos engineering

1049
00:36:22,720 --> 00:36:27,839
not only as what uh bad stuff could come

1050
00:36:26,160 --> 00:36:29,200
down the pipeline but what bad stuff

1051
00:36:27,839 --> 00:36:30,720
that criminals could do to us

1052
00:36:29,200 --> 00:36:32,640
so they adopt the zero trust

1053
00:36:30,720 --> 00:36:35,359
architecture uh and

1054
00:36:32,640 --> 00:36:36,720
and then they have a zero day exploit at

1055
00:36:35,359 --> 00:36:38,720
their perimeter

1056
00:36:36,720 --> 00:36:40,399
and because of the way zero trust worked

1057
00:36:38,720 --> 00:36:41,759
every time the criminals would break in

1058
00:36:40,400 --> 00:36:43,119
it was a kubernetes controller every

1059
00:36:41,760 --> 00:36:43,839
time the kubernetes controller was

1060
00:36:43,119 --> 00:36:45,440
breached

1061
00:36:43,839 --> 00:36:47,279
the criminals would deploy the tools and

1062
00:36:45,440 --> 00:36:49,200
try to scan around the environment

1063
00:36:47,280 --> 00:36:50,320
recognized that that was unusual that it

1064
00:36:49,200 --> 00:36:53,200
wasn't trusted

1065
00:36:50,320 --> 00:36:54,480
they would detrust or de-auth that

1066
00:36:53,200 --> 00:36:56,399
kubernetes controller

1067
00:36:54,480 --> 00:36:57,920
they'd run an ansible playbook to erase

1068
00:36:56,400 --> 00:37:00,240
it reload it

1069
00:36:57,920 --> 00:37:01,359
and uh and again people the criminals

1070
00:37:00,240 --> 00:37:03,040
would try and get in

1071
00:37:01,359 --> 00:37:05,119
and this went on for several times

1072
00:37:03,040 --> 00:37:08,320
before instant response

1073
00:37:05,119 --> 00:37:10,880
was engaged why this is cool is because

1074
00:37:08,320 --> 00:37:13,200
it was such a cool story internally

1075
00:37:10,880 --> 00:37:14,800
that much like ray bans much like my

1076
00:37:13,200 --> 00:37:16,160
tokens back in the day suddenly all the

1077
00:37:14,800 --> 00:37:17,440
other devops teams were like really how

1078
00:37:16,160 --> 00:37:18,399
are you doing that how are you

1079
00:37:17,440 --> 00:37:20,480
architecting

1080
00:37:18,400 --> 00:37:22,079
your abs so that they're that resilient

1081
00:37:20,480 --> 00:37:23,839
so that even if someone is not

1082
00:37:22,079 --> 00:37:24,880
accidentally but as maliciously messing

1083
00:37:23,839 --> 00:37:27,040
with them we can protect

1084
00:37:24,880 --> 00:37:30,720
and suddenly the adoption rate for the

1085
00:37:27,040 --> 00:37:30,720
security control went through the roof

1086
00:37:31,520 --> 00:37:38,400
but then also comes to

1087
00:37:34,880 --> 00:37:40,720
um another point right in in both

1088
00:37:38,400 --> 00:37:42,079
the the aviators and the zero trust

1089
00:37:40,720 --> 00:37:45,759
story i just gave

1090
00:37:42,079 --> 00:37:48,320
um we we have a

1091
00:37:45,760 --> 00:37:50,480
a a unique property in terms of who's

1092
00:37:48,320 --> 00:37:52,320
working with us and

1093
00:37:50,480 --> 00:37:54,640
i first was this when i was thinking

1094
00:37:52,320 --> 00:37:56,560
about flying both of these examples are

1095
00:37:54,640 --> 00:37:58,319
flag i'm sorry but i still miss the

1096
00:37:56,560 --> 00:38:02,240
world and i can't wait to

1097
00:37:58,320 --> 00:38:03,520
record con 2021 to hopefully i'm on a

1098
00:38:02,240 --> 00:38:05,520
plane to come visit

1099
00:38:03,520 --> 00:38:07,119
but i'm sure if you've flown anytime

1100
00:38:05,520 --> 00:38:08,800
within the past couple years you've used

1101
00:38:07,119 --> 00:38:10,240
luggage your luggage of those wheels

1102
00:38:08,800 --> 00:38:14,240
wheeled luggage it's just the way we do

1103
00:38:10,240 --> 00:38:16,839
things i was really surprised to learn

1104
00:38:14,240 --> 00:38:18,319
that we actually were landing on the

1105
00:38:16,839 --> 00:38:21,520
moon

1106
00:38:18,320 --> 00:38:24,320
and doing significant uh

1107
00:38:21,520 --> 00:38:26,400
scientific achievements before the

1108
00:38:24,320 --> 00:38:27,359
wheeled luggage was invented before the

1109
00:38:26,400 --> 00:38:30,400
wheeled luggage

1110
00:38:27,359 --> 00:38:32,240
rolled out and the reason was the

1111
00:38:30,400 --> 00:38:35,440
wheeled luggage um

1112
00:38:32,240 --> 00:38:37,279
was a a insight by a pilot called robert

1113
00:38:35,440 --> 00:38:38,640
plath so robert plath was like look this

1114
00:38:37,280 --> 00:38:40,160
is terrible i'm sick of carrying

1115
00:38:38,640 --> 00:38:42,799
carrying around my luggage i'll put

1116
00:38:40,160 --> 00:38:44,960
wheels on it he comes up with this idea

1117
00:38:42,800 --> 00:38:46,640
he does a a batch for himself a batch

1118
00:38:44,960 --> 00:38:47,520
for his friends and again these are

1119
00:38:46,640 --> 00:38:49,440
pilots and

1120
00:38:47,520 --> 00:38:52,240
and stewardesses these are the cool kids

1121
00:38:49,440 --> 00:38:54,160
back in the the 1970s and 80s

1122
00:38:52,240 --> 00:38:55,680
um and and suddenly everyone's like oh

1123
00:38:54,160 --> 00:38:57,040
yeah how can the cool kids have those

1124
00:38:55,680 --> 00:38:59,040
that cool luggage

1125
00:38:57,040 --> 00:39:00,800
and everyone wants it right and what

1126
00:38:59,040 --> 00:39:03,759
ends up happening is robert plath

1127
00:39:00,800 --> 00:39:04,160
goes ahead and and leaves being a pilot

1128
00:39:03,760 --> 00:39:08,240
to

1129
00:39:04,160 --> 00:39:10,240
form um a a roll-on luggage

1130
00:39:08,240 --> 00:39:11,439
company now you might say well no one

1131
00:39:10,240 --> 00:39:13,118
ever thought to put wheels yeah of

1132
00:39:11,440 --> 00:39:14,640
course people put wheels on luggage

1133
00:39:13,119 --> 00:39:16,880
before we landed on the moon there was

1134
00:39:14,640 --> 00:39:17,598
another guy called bernard saddle who

1135
00:39:16,880 --> 00:39:19,760
did it and

1136
00:39:17,599 --> 00:39:21,280
but he was not a pilot he was not the

1137
00:39:19,760 --> 00:39:22,000
inside guy he did not know how people

1138
00:39:21,280 --> 00:39:25,119
worked

1139
00:39:22,000 --> 00:39:28,560
and so because he did not

1140
00:39:25,119 --> 00:39:31,200
understand the the ins and outs

1141
00:39:28,560 --> 00:39:31,920
the previous inventor uh made luggage

1142
00:39:31,200 --> 00:39:34,000
that didn't

1143
00:39:31,920 --> 00:39:36,240
uh didn't get anywhere right and so my

1144
00:39:34,000 --> 00:39:38,800
point here is we need good adoption

1145
00:39:36,240 --> 00:39:40,160
the controls need to to shine to the

1146
00:39:38,800 --> 00:39:42,000
people who matter who are the

1147
00:39:40,160 --> 00:39:44,319
influencers within the devops team

1148
00:39:42,000 --> 00:39:45,920
and also we need to make sure that we

1149
00:39:44,320 --> 00:39:49,119
understand the person doing the job

1150
00:39:45,920 --> 00:39:51,599
is really the right person to ask about

1151
00:39:49,119 --> 00:39:53,040
how to improve the job fundamentally

1152
00:39:51,599 --> 00:39:55,359
good security

1153
00:39:53,040 --> 00:39:56,560
is is usable security we get to usable

1154
00:39:55,359 --> 00:39:59,598
security

1155
00:39:56,560 --> 00:40:02,960
by working closely with the devops folks

1156
00:39:59,599 --> 00:40:04,240
and again starting with empathy final

1157
00:40:02,960 --> 00:40:06,560
thoughts

1158
00:40:04,240 --> 00:40:09,839
uh let's let's put a couple more links

1159
00:40:06,560 --> 00:40:12,078
on the chain and bring all this together

1160
00:40:09,839 --> 00:40:13,200
point number one i want to make start

1161
00:40:12,079 --> 00:40:15,440
with empathy

1162
00:40:13,200 --> 00:40:16,640
good security is as little security as

1163
00:40:15,440 --> 00:40:18,400
possible

1164
00:40:16,640 --> 00:40:20,160
not security that's in the way of our

1165
00:40:18,400 --> 00:40:21,520
users but security that's in the way of

1166
00:40:20,160 --> 00:40:22,879
the criminals

1167
00:40:21,520 --> 00:40:25,680
we can do that by designing for

1168
00:40:22,880 --> 00:40:26,640
usability i provided a framework earlier

1169
00:40:25,680 --> 00:40:28,960
on how to do that

1170
00:40:26,640 --> 00:40:30,319
reducing the friction reducing effort

1171
00:40:28,960 --> 00:40:32,800
for devs

1172
00:40:30,319 --> 00:40:34,640
and defining designing for defensibility

1173
00:40:32,800 --> 00:40:37,839
by increasing the effort

1174
00:40:34,640 --> 00:40:39,759
by using uh adding more steps as we saw

1175
00:40:37,839 --> 00:40:42,319
the verizon data breach report

1176
00:40:39,760 --> 00:40:44,079
adding more complexity as i provided in

1177
00:40:42,319 --> 00:40:46,800
the zero trust example

1178
00:40:44,079 --> 00:40:48,720
and really making for a unexpected

1179
00:40:46,800 --> 00:40:52,000
unusual environment for our criminals

1180
00:40:48,720 --> 00:40:53,759
adversaries and our pen testers

1181
00:40:52,000 --> 00:40:55,599
can weigh these things out i don't

1182
00:40:53,760 --> 00:40:58,560
believe that there needs to be this

1183
00:40:55,599 --> 00:41:00,079
constant tug of war between the two

1184
00:40:58,560 --> 00:41:01,759
point two i want to leave you with we

1185
00:41:00,079 --> 00:41:03,200
want to find ways that we can secure

1186
00:41:01,760 --> 00:41:05,760
without slowing

1187
00:41:03,200 --> 00:41:07,598
this comes from understanding our data

1188
00:41:05,760 --> 00:41:08,560
and how it's being used in the

1189
00:41:07,599 --> 00:41:11,440
environment

1190
00:41:08,560 --> 00:41:13,279
it comes from understanding our business

1191
00:41:11,440 --> 00:41:14,400
activities and how people are using the

1192
00:41:13,280 --> 00:41:17,599
technologies

1193
00:41:14,400 --> 00:41:19,520
in our environment so we know how the

1194
00:41:17,599 --> 00:41:20,800
users are working and in this case of

1195
00:41:19,520 --> 00:41:22,480
course it comes from understanding the

1196
00:41:20,800 --> 00:41:24,319
devops workflow

1197
00:41:22,480 --> 00:41:25,680
and the same time then threat modeling

1198
00:41:24,319 --> 00:41:27,520
and adversarial path

1199
00:41:25,680 --> 00:41:28,799
so we know the path the good guys are

1200
00:41:27,520 --> 00:41:30,240
taking and we know the path that

1201
00:41:28,800 --> 00:41:31,839
criminals are taking

1202
00:41:30,240 --> 00:41:34,160
and by knowing those two things we can

1203
00:41:31,839 --> 00:41:36,319
introduce security that hopefully

1204
00:41:34,160 --> 00:41:37,520
does not stop the user that's the worst

1205
00:41:36,319 --> 00:41:39,839
case scenario

1206
00:41:37,520 --> 00:41:40,880
does not slow the user we can do that if

1207
00:41:39,839 --> 00:41:42,400
we need to

1208
00:41:40,880 --> 00:41:43,920
uh and as a matter of fact there's

1209
00:41:42,400 --> 00:41:45,119
there's some interesting research which

1210
00:41:43,920 --> 00:41:47,599
i don't have time to talk about today

1211
00:41:45,119 --> 00:41:49,040
that shows that some amount of slowing

1212
00:41:47,599 --> 00:41:50,720
is actually a good thing because it

1213
00:41:49,040 --> 00:41:51,920
makes users feel that

1214
00:41:50,720 --> 00:41:54,560
there is security that they are

1215
00:41:51,920 --> 00:41:55,599
protected is invisible to the user is

1216
00:41:54,560 --> 00:41:57,839
where we're aiming

1217
00:41:55,599 --> 00:41:59,440
and there are certain cases where people

1218
00:41:57,839 --> 00:42:00,720
uh put in place security that actually

1219
00:41:59,440 --> 00:42:02,480
speeds up the user

1220
00:42:00,720 --> 00:42:03,919
by getting out of the way by providing

1221
00:42:02,480 --> 00:42:06,560
smarter defaults

1222
00:42:03,920 --> 00:42:08,800
um the iphone example i gave earlier i

1223
00:42:06,560 --> 00:42:11,119
also know a devops team

1224
00:42:08,800 --> 00:42:12,319
that built a smart package a very secure

1225
00:42:11,119 --> 00:42:15,440
package

1226
00:42:12,319 --> 00:42:17,040
for the the fedramp environment and by

1227
00:42:15,440 --> 00:42:19,520
using this package they're actually able

1228
00:42:17,040 --> 00:42:21,839
to decrease the amount of time it took

1229
00:42:19,520 --> 00:42:22,880
from close to two years down to six

1230
00:42:21,839 --> 00:42:25,520
months to deploy

1231
00:42:22,880 --> 00:42:27,520
code significant increase in speed in

1232
00:42:25,520 --> 00:42:29,200
that particular example

1233
00:42:27,520 --> 00:42:31,839
while also having a significant increase

1234
00:42:29,200 --> 00:42:31,839
in security

1235
00:42:32,160 --> 00:42:35,279
so i would argue that friction isn't the

1236
00:42:34,400 --> 00:42:39,599
problem

1237
00:42:35,280 --> 00:42:44,160
it just isn't it is the

1238
00:42:39,599 --> 00:42:46,160
uh thoughtless adding of security

1239
00:42:44,160 --> 00:42:47,920
three make sure we're securing in layers

1240
00:42:46,160 --> 00:42:50,560
we don't know this right uh

1241
00:42:47,920 --> 00:42:52,160
look at the features to code the bugs

1242
00:42:50,560 --> 00:42:53,359
look for the flaws in architecture and

1243
00:42:52,160 --> 00:42:55,118
design

1244
00:42:53,359 --> 00:42:57,680
make sure we're addressing all three

1245
00:42:55,119 --> 00:42:59,599
using application security testing

1246
00:42:57,680 --> 00:43:00,799
for bugs and pen testing and threat

1247
00:42:59,599 --> 00:43:05,200
intel to

1248
00:43:00,800 --> 00:43:07,359
focus our flaws fourth

1249
00:43:05,200 --> 00:43:08,480
start with empathy think about design

1250
00:43:07,359 --> 00:43:11,359
process

1251
00:43:08,480 --> 00:43:12,720
think about it in terms of how people

1252
00:43:11,359 --> 00:43:14,880
work and act

1253
00:43:12,720 --> 00:43:15,759
if there are issues we need to

1254
00:43:14,880 --> 00:43:18,720
troubleshoot

1255
00:43:15,760 --> 00:43:20,640
we can work on it with education better

1256
00:43:18,720 --> 00:43:22,879
incentives better investments

1257
00:43:20,640 --> 00:43:24,560
and this mod this four eyes model uh

1258
00:43:22,880 --> 00:43:26,560
comes from spencer greenberg

1259
00:43:24,560 --> 00:43:28,480
fernando montenegro also had a great

1260
00:43:26,560 --> 00:43:29,839
talk in that converge so if you want to

1261
00:43:28,480 --> 00:43:31,119
know more about using this as a

1262
00:43:29,839 --> 00:43:33,920
diagnostic tool

1263
00:43:31,119 --> 00:43:35,599
i'd point you to them fundamentally just

1264
00:43:33,920 --> 00:43:37,200
remember every time someone picks up a

1265
00:43:35,599 --> 00:43:38,800
mouse right this is where we went wrong

1266
00:43:37,200 --> 00:43:40,480
we introduced the mouse every time

1267
00:43:38,800 --> 00:43:41,760
someone picks up a mouse

1268
00:43:40,480 --> 00:43:43,359
they're making a choice to either

1269
00:43:41,760 --> 00:43:44,640
strengthen or lessen our security

1270
00:43:43,359 --> 00:43:46,720
posture

1271
00:43:44,640 --> 00:43:48,879
by working with empathy and kindness by

1272
00:43:46,720 --> 00:43:50,720
working on adoption

1273
00:43:48,880 --> 00:43:52,560
we can really implement stronger

1274
00:43:50,720 --> 00:43:54,879
security controls and more effective

1275
00:43:52,560 --> 00:43:58,480
security controls

1276
00:43:54,880 --> 00:44:00,000
that is all i have for you guys today

1277
00:43:58,480 --> 00:44:01,680
if you want to continue this

1278
00:44:00,000 --> 00:44:04,560
conversation and know more

1279
00:44:01,680 --> 00:44:09,520
here is my email address and in my

1280
00:44:04,560 --> 00:44:11,359
website where i blog in these topics

1281
00:44:09,520 --> 00:44:13,920
all right well thank you it was really

1282
00:44:11,359 --> 00:44:17,598
great for you to uh

1283
00:44:13,920 --> 00:44:21,359
come here in a pinch and fill in uh for

1284
00:44:17,599 --> 00:44:23,200
the speaker that we had leave and uh

1285
00:44:21,359 --> 00:44:25,119
it was a great presentation i think the

1286
00:44:23,200 --> 00:44:28,640
audience really enjoyed it so

1287
00:44:25,119 --> 00:44:30,800
let me uh wrap up and

1288
00:44:28,640 --> 00:44:34,560
if you if you want you can head over and

1289
00:44:30,800 --> 00:44:40,400
uh chat with people in our discord

1290
00:44:34,560 --> 00:44:40,400
great thanks so much thank you

