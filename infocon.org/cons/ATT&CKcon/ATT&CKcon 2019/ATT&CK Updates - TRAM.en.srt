1
00:00:01,140 --> 00:00:02,150
- [Announcer] Join me in welcoming

2
00:00:02,150 --> 00:00:04,718
Jackie Lasky and Sarah Yoder.

3
00:00:04,719 --> 00:00:07,886
(audience applauding)

4
00:00:09,550 --> 00:00:11,236
- Do we each get one?

5
00:00:11,236 --> 00:00:12,319
- Okay, okay.

6
00:00:17,338 --> 00:00:19,820
- [Jackie] Hi, so I'm
Jackie Lasky and this is...

7
00:00:19,820 --> 00:00:20,949
- [Sarah] Sarah Yoder.

8
00:00:20,949 --> 00:00:23,370
- So we're two cybersecurity
engineers here at MITRE.

9
00:00:23,370 --> 00:00:24,910
And today we're just going
to share with you some of our

10
00:00:24,910 --> 00:00:26,870
methodology behind TRAM.

11
00:00:26,870 --> 00:00:28,520
Which is our project that
we've been working on

12
00:00:28,520 --> 00:00:31,762
to create an easier way to
map threat reports to ATT&CK.

13
00:00:36,690 --> 00:00:38,809
So we'll start with how does information

14
00:00:38,810 --> 00:00:40,920
get into the ATT&CK site?

15
00:00:40,920 --> 00:00:42,730
This usually starts
with finding open source

16
00:00:42,730 --> 00:00:45,190
threat reporting, so looking
at common vendors like

17
00:00:45,190 --> 00:00:48,110
FireEye, SecureList, Cybereason,
those kind of things.

18
00:00:48,110 --> 00:00:50,360
And basically, choosing reports based on

19
00:00:50,360 --> 00:00:51,720
the content that's in them.

20
00:00:51,720 --> 00:00:54,000
So we're always looking
for new reports on new APT

21
00:00:54,000 --> 00:00:56,280
groups, on malware, things like that.

22
00:00:56,280 --> 00:00:57,530
And then when we have our report,

23
00:00:57,530 --> 00:00:59,610
we'll finally go through
and we'll start from

24
00:00:59,610 --> 00:01:02,030
beginning to end reading
the report and looking for

25
00:01:02,030 --> 00:01:03,920
different attack techniques
that are in there.

26
00:01:03,920 --> 00:01:05,310
And some of you that may have been in the

27
00:01:05,310 --> 00:01:07,330
CTI workshop yesterday
have learned that this is a

28
00:01:07,330 --> 00:01:09,853
really manual process
and it takes a long time.

29
00:01:10,700 --> 00:01:12,500
We usually start when we're
going through a report with

30
00:01:12,500 --> 00:01:13,920
looking for the tactics.

31
00:01:13,920 --> 00:01:16,440
We'll kind of highlight
along the way any verbs

32
00:01:16,440 --> 00:01:19,470
or any tactics that we may think
and obviously trying to do.

33
00:01:19,470 --> 00:01:21,690
And then when we're done, we'll
kind of repeat this process

34
00:01:21,690 --> 00:01:23,860
and look for all the
techniques in the report.

35
00:01:23,860 --> 00:01:26,260
So it takes a really long time
to be able to cross reference

36
00:01:26,260 --> 00:01:28,470
the tactics, the sentences,
and going and looking for the

37
00:01:28,470 --> 00:01:29,870
techniques that they map to.

38
00:01:31,500 --> 00:01:33,660
Yeah, so all the data that's
added into our ATT&CK site

39
00:01:33,660 --> 00:01:35,979
is done manually, which means it's hard to

40
00:01:35,980 --> 00:01:37,560
keep it up to date.

41
00:01:37,560 --> 00:01:40,080
We usually often have a
huge backlog of reports

42
00:01:40,080 --> 00:01:42,250
that are unanalyzed and
we have to prioritize

43
00:01:42,250 --> 00:01:43,730
some over others.

44
00:01:43,730 --> 00:01:46,550
So we also have things like
human error, so two analysts

45
00:01:46,550 --> 00:01:48,009
may look at a report
and have two different

46
00:01:48,010 --> 00:01:50,420
interpretations of the same text.

47
00:01:50,420 --> 00:01:53,240
This also introduces things
like availability bias.

48
00:01:53,240 --> 00:01:55,869
So basically what that means
is that you're more likely

49
00:01:55,870 --> 00:01:57,520
to think of the attack
techniques that you're already

50
00:01:57,520 --> 00:01:59,440
familiar with or that you already know of,

51
00:01:59,440 --> 00:02:01,410
which can cause you to overlook
some of the less common

52
00:02:01,410 --> 00:02:02,929
techniques that are out there.

53
00:02:02,930 --> 00:02:05,290
So it's also a challenge that we have.

54
00:02:05,290 --> 00:02:06,670
And then also training new team members

55
00:02:06,670 --> 00:02:07,840
is really hard to do two.

56
00:02:07,840 --> 00:02:10,460
ATT&CK is a huge site and
it's continuously growing

57
00:02:10,460 --> 00:02:12,730
every day, so it's a lot to take in

58
00:02:12,730 --> 00:02:14,030
when you first start here.

59
00:02:15,010 --> 00:02:17,000
So that's where our solution
called the threat report.

60
00:02:17,000 --> 00:02:18,730
attack mapper comes in.

61
00:02:18,730 --> 00:02:21,579
We call it TRAM for short,
and basically, obviously

62
00:02:21,580 --> 00:02:23,800
as Katie said, this project
grew out of a need to be able

63
00:02:23,800 --> 00:02:26,900
to automate some of the
stuff that we do here.

64
00:02:26,900 --> 00:02:29,400
So we're just going to give
a quick little overview

65
00:02:29,400 --> 00:02:31,840
of sort of the details
to our technical approach

66
00:02:31,840 --> 00:02:33,730
as we started this project.

67
00:02:33,730 --> 00:02:35,100
We don't have a lot of time
to get in too big of the

68
00:02:35,100 --> 00:02:37,700
details, but you can
always find this after.

69
00:02:37,700 --> 00:02:40,369
So the first step in our
process was to get data in and

70
00:02:40,370 --> 00:02:43,170
how we did this is we use
the stix and taxii server

71
00:02:43,170 --> 00:02:45,149
and basically we just
grabbed down all the example

72
00:02:45,150 --> 00:02:47,540
data from each techniques
page and we're going to use

73
00:02:47,540 --> 00:02:49,072
that for our training dataset.

74
00:02:50,100 --> 00:02:52,700
So before we could do that, a
lot of the texts in the world

75
00:02:52,700 --> 00:02:54,070
is unstructured raw text.

76
00:02:54,070 --> 00:02:56,450
So in some human language. So
we had to be able to get it

77
00:02:56,450 --> 00:02:58,720
into some language that the
computer can understand.

78
00:02:58,720 --> 00:03:00,770
So this is where a lot
of our data normalization

79
00:03:00,770 --> 00:03:03,000
and natural language processing occurs.

80
00:03:03,000 --> 00:03:05,470
So doing a lot of things
like removing stop words,

81
00:03:05,470 --> 00:03:07,750
doing our STEMI lemmatization,
things like that.

82
00:03:07,750 --> 00:03:10,420
That's all going to occur in this step.

83
00:03:10,420 --> 00:03:12,750
And then once we've got
the data in a good format,

84
00:03:12,750 --> 00:03:14,880
We can start building
and training our models.

85
00:03:14,880 --> 00:03:17,769
So to do this, we use
Python's logistic regression,

86
00:03:17,770 --> 00:03:20,660
which is a supervised
learning classification method

87
00:03:20,660 --> 00:03:22,810
and essentially what each
technique has is they have

88
00:03:22,810 --> 00:03:24,480
their own model built for them.

89
00:03:24,480 --> 00:03:26,840
So we'll have a positive and
a negative class that we build

90
00:03:26,840 --> 00:03:28,300
for each technique.

91
00:03:28,300 --> 00:03:30,787
So the positive class consists
of the examples from the

92
00:03:30,787 --> 00:03:33,170
ATT&CK site, and then the
negative class consists

93
00:03:33,170 --> 00:03:35,549
of a variety of things, so
maybe like true negatives

94
00:03:35,550 --> 00:03:37,840
or sentences that don't
relate to any technique all,

95
00:03:37,840 --> 00:03:40,090
or maybe other techniques,
examples, to also

96
00:03:40,090 --> 00:03:42,263
differentiate between
different techniques.

97
00:03:43,190 --> 00:03:46,880
Yeah. So after we've trained
and built our models,

98
00:03:46,880 --> 00:03:49,540
we had to collect a good
reliable test dataset that we

99
00:03:49,540 --> 00:03:52,019
could use. So we did this using our own

100
00:03:52,020 --> 00:03:53,020
Feedly CTI RSS feed.

101
00:03:53,990 --> 00:03:56,030
They have a Python API where
you can just kind of grab

102
00:03:56,030 --> 00:03:58,110
a bunch of reports that
you want to look at

103
00:03:58,110 --> 00:04:00,680
and we use that to collect
sort of the test dataset

104
00:04:00,680 --> 00:04:01,683
that we used.

105
00:04:02,670 --> 00:04:05,190
So once we had our test data,
we were able to transform

106
00:04:05,190 --> 00:04:07,520
our test data with the
models that we built from

107
00:04:07,520 --> 00:04:08,580
the previous step.

108
00:04:08,580 --> 00:04:09,860
So this is where we can
perform a lot of our

109
00:04:09,860 --> 00:04:12,100
cross validation and
checking how our models are

110
00:04:12,100 --> 00:04:14,623
performing as we go through this process.

111
00:04:16,100 --> 00:04:19,020
And then once we have ran
our reports, our test reports

112
00:04:19,019 --> 00:04:21,310
through the models, we
get sort of a print out

113
00:04:21,310 --> 00:04:23,170
that the analyst can look at and decide

114
00:04:23,170 --> 00:04:25,650
whether they approve or
reject the, basically the

115
00:04:25,650 --> 00:04:27,310
techniques that were found in the model.

116
00:04:27,310 --> 00:04:29,160
So they'll have a list of all
the techniques that were found

117
00:04:29,160 --> 00:04:31,580
in the report and they can
go through and decide whether

118
00:04:31,580 --> 00:04:34,330
they like them or not and then
we can also add in ones that

119
00:04:34,330 --> 00:04:35,323
are missed as well.

120
00:04:36,310 --> 00:04:38,430
And to pull it all together,
we have a feedback loop

121
00:04:38,430 --> 00:04:40,870
to have to be able to improve
our model as we go through.

122
00:04:40,870 --> 00:04:42,920
So we use a database to be able
to track the different true

123
00:04:42,920 --> 00:04:45,900
positives, false positives,
true negatives, things like

124
00:04:45,900 --> 00:04:47,810
that, so that we can include
it and make the model better

125
00:04:47,810 --> 00:04:50,690
each time and we use a serialized
format in Python called a

126
00:04:50,690 --> 00:04:53,350
pickle file so that we can
reload and rebuild the models

127
00:04:53,350 --> 00:04:55,907
whenever new data gets
added to the ATT&CK site.

128
00:04:56,760 --> 00:04:58,090
So this is still... Along the way,

129
00:04:58,090 --> 00:05:00,560
we had a lot of challenges
that we still had to overcome.

130
00:05:00,560 --> 00:05:02,580
But the most obvious challenge
is extracting meaning from

131
00:05:02,580 --> 00:05:04,750
text is still really hard to do.

132
00:05:04,750 --> 00:05:06,450
Humans are still needed in this process.

133
00:05:06,450 --> 00:05:09,000
We haven't got rid of us
yet, we still are using us.

134
00:05:09,000 --> 00:05:11,070
So we still need to be
part of that process

135
00:05:11,070 --> 00:05:13,050
and improving the feedback loop, improving

136
00:05:13,050 --> 00:05:14,890
the models as we go.

137
00:05:14,890 --> 00:05:16,280
But the problem almost always comes back

138
00:05:16,280 --> 00:05:18,369
to not having enough data to train with.

139
00:05:18,370 --> 00:05:20,520
So this can lead to things
like imbalanced datasets.

140
00:05:20,520 --> 00:05:22,909
So maybe having a really
large negative class

141
00:05:22,910 --> 00:05:24,840
of training examples, but
a really small positive

142
00:05:24,840 --> 00:05:26,469
class of examples that are good.

143
00:05:26,470 --> 00:05:27,960
So that's one of the challenges we had

144
00:05:27,960 --> 00:05:30,210
to face as we went through this.

145
00:05:30,210 --> 00:05:31,840
We had some techniques in
ATT&CK that don't have any

146
00:05:31,840 --> 00:05:33,969
examples at all, or maybe
they only have one or two

147
00:05:33,970 --> 00:05:36,700
examples, so for those kinds
of cases, we had to look at

148
00:05:36,700 --> 00:05:39,789
them on a case by case basis
and sort of build out regular

149
00:05:39,790 --> 00:05:41,590
expressions and string
matching kind of things

150
00:05:41,590 --> 00:05:43,830
to be able to kind of handle those cases

151
00:05:43,830 --> 00:05:46,423
that we couldn't build,
build enough models for.

152
00:05:47,704 --> 00:05:49,680
- [Sarah] Cool. So now
I'm going to go over

153
00:05:49,680 --> 00:05:50,690
just how it looks.

154
00:05:50,690 --> 00:05:53,930
So, because we have a short
time slot, a lot of this

155
00:05:53,930 --> 00:05:55,129
demo we're just going to skip through.

156
00:05:55,129 --> 00:05:58,320
So at this point in the tool,

157
00:05:58,320 --> 00:06:00,450
we would assume that the
analyst has gone online,

158
00:06:00,450 --> 00:06:02,420
found a report that they're interested in,

159
00:06:02,420 --> 00:06:06,700
they grabbed the URL and ran
it through our tool TRAM.

160
00:06:06,700 --> 00:06:09,560
So when they go to analyze
that report, this is the view

161
00:06:09,560 --> 00:06:12,960
that they would see and as
you can see, if they click on

162
00:06:12,960 --> 00:06:15,500
the highlighted sentence,
it'll show you a couple of

163
00:06:15,500 --> 00:06:17,710
techniques that TRAM found.

164
00:06:17,710 --> 00:06:21,489
So in this example, a
spearphishing link and attachment.

165
00:06:21,490 --> 00:06:24,160
Going back to what Jackie
said, sometimes the computer

166
00:06:24,160 --> 00:06:28,410
still has trouble distinguishing
very similar techniques.

167
00:06:28,410 --> 00:06:33,210
From here, we go ahead and
reject spearphishing link,

168
00:06:33,210 --> 00:06:35,960
since that wasn't what the
sentence was talking about,

169
00:06:35,960 --> 00:06:40,210
and confirm or accept the
spearfishing attachment

170
00:06:40,210 --> 00:06:42,039
since that was correct and as you can see,

171
00:06:42,040 --> 00:06:44,830
it got rid of the spearphishing
link from the list

172
00:06:44,830 --> 00:06:47,020
and add spearfishing attachment down

173
00:06:47,020 --> 00:06:50,193
into the confirmed techniques.

174
00:06:51,940 --> 00:06:54,923
So from here, as Jackie mentioned,

175
00:06:57,230 --> 00:07:00,110
the models will be updated
based on the accept

176
00:07:00,110 --> 00:07:03,340
or rejects as an analyst
goes through this report.

177
00:07:03,340 --> 00:07:08,090
So you would follow this process
for the rest of the report,

178
00:07:08,090 --> 00:07:11,193
and you can then export it as a PDF.

179
00:07:14,670 --> 00:07:18,440
So at the bottom of the PDF,
you would get a chart that

180
00:07:18,440 --> 00:07:21,500
looks like this, that has all
of the confirmed techniques

181
00:07:21,500 --> 00:07:24,030
from the report that you analyzed.

182
00:07:24,030 --> 00:07:26,520
So we hope that this is
a useful little snippet

183
00:07:26,520 --> 00:07:28,919
that the analysts can use
to share with maybe other

184
00:07:28,920 --> 00:07:31,020
members on your team or
for us of the use case.

185
00:07:31,020 --> 00:07:34,440
We'll probably be feeding
this into ATT&CK to get more

186
00:07:34,440 --> 00:07:35,813
information into the site.

187
00:07:37,870 --> 00:07:40,690
So why does this matter?

188
00:07:40,690 --> 00:07:44,450
Other than our use case, which
was to automate our jobs,

189
00:07:44,450 --> 00:07:46,900
we hope that it's useful for you as well.

190
00:07:46,900 --> 00:07:49,330
We know that mapping
reports to ATT&CK can be

191
00:07:49,330 --> 00:07:50,200
kind of overwhelming.

192
00:07:50,200 --> 00:07:52,330
There's a lot of
techniques to choose from.

193
00:07:52,330 --> 00:07:55,440
And so we hope that this is
a good starting place since

194
00:07:55,440 --> 00:07:57,770
there's only a handful of
techniques that the analyst needs

195
00:07:57,770 --> 00:08:00,103
to review per sentence.

196
00:08:01,410 --> 00:08:04,340
As Jackie mentioned, remembering 266

197
00:08:04,340 --> 00:08:06,859
and growing, techniques, is hard.

198
00:08:06,860 --> 00:08:10,050
And there's many techniques
that sometimes I forget about

199
00:08:10,930 --> 00:08:13,740
and so luckily the computer
doesn't have that problem,

200
00:08:13,740 --> 00:08:15,403
so it can remember them for us.

201
00:08:16,450 --> 00:08:18,950
And next, we hope that you
can use reporting that's

202
00:08:18,950 --> 00:08:22,440
important to you. So whether
that's an internal report

203
00:08:22,440 --> 00:08:25,460
source or, if you feel like
ATT&CK doesn't have enough

204
00:08:25,460 --> 00:08:28,349
information on maybe the
financial sector or healthcare,

205
00:08:28,350 --> 00:08:31,060
whatever your use case may
be, we would hope that you can

206
00:08:31,060 --> 00:08:34,110
use this to get more
data for the techniques

207
00:08:34,110 --> 00:08:35,163
that you care about.

208
00:08:38,549 --> 00:08:42,990
So some takeaways. Many
people have talked about

209
00:08:42,990 --> 00:08:46,820
ATT&CK helping to frame
behaviors, moving away from

210
00:08:46,820 --> 00:08:50,950
IOCs and we hope that you
can use a lot of what other

211
00:08:50,950 --> 00:08:53,100
people are discussing today.

212
00:08:53,100 --> 00:08:56,480
Mainly our four main attack use cases,

213
00:08:56,480 --> 00:08:58,990
which are detections, kind
of this sock assessments

214
00:08:58,990 --> 00:09:01,610
and gap analysis can track adversaries you

215
00:09:01,610 --> 00:09:03,880
care about using a cyber
threat intelligence.

216
00:09:03,880 --> 00:09:07,490
And then potentially
emulate those adversaries.

217
00:09:07,490 --> 00:09:10,750
We acknowledged that mapping
data to ATT&CK is hard,

218
00:09:10,750 --> 00:09:12,910
but that's where we hope
that TRAM can come in

219
00:09:12,910 --> 00:09:14,252
and make that easier.

220
00:09:15,500 --> 00:09:18,173
So with that, we have
some time for questions.

221
00:09:19,010 --> 00:09:22,290
Oh, most importantly, this will
be open source and available

222
00:09:22,290 --> 00:09:24,839
to the community, hopefully
by the end of the year.

223
00:09:26,280 --> 00:09:29,447
(audience applauding)

224
00:09:35,654 --> 00:09:37,970
Yep? Microphone's coming.

225
00:09:37,970 --> 00:09:38,803
- [Jackie] Okay.

226
00:09:41,231 --> 00:09:43,390
- [Questioner 1] Hi
ladies. This is fantastic.

227
00:09:43,390 --> 00:09:46,900
I've been wondering if
you've had any, I guess,

228
00:09:46,900 --> 00:09:49,900
experience or if the community's
had an experience with

229
00:09:49,900 --> 00:09:53,069
overlapping this with like
a tip, whether it's mis or a

230
00:09:53,070 --> 00:09:57,180
commercial tool and,
integrating those two things?

231
00:09:57,180 --> 00:09:59,839
- [Sarah] Yeah, so we're still
really early in this process

232
00:09:59,840 --> 00:10:03,530
on (murmurs) but, I could
see as it gets more mature

233
00:10:03,530 --> 00:10:05,480
and if the community can
help make it even better,

234
00:10:05,480 --> 00:10:08,713
that maybe that definitely
would be an option to be used.

235
00:10:14,070 --> 00:10:16,490
- [Questioner 2] Just a real
quick technical question

236
00:10:16,490 --> 00:10:18,230
on your NLP.

237
00:10:18,230 --> 00:10:21,980
Was that the only
library or learning model

238
00:10:21,980 --> 00:10:23,500
that you considered or were there maybe

239
00:10:23,500 --> 00:10:25,420
a couple other candidates?

240
00:10:25,420 --> 00:10:26,719
- [Jackie] We were mostly
just using the natural

241
00:10:26,720 --> 00:10:28,320
language tool kit in Python.

242
00:10:28,320 --> 00:10:29,667
It's one that I was already familiar with

243
00:10:29,667 --> 00:10:31,300
and we definitely, both of us

244
00:10:31,300 --> 00:10:33,209
kind of have a small background.

245
00:10:33,210 --> 00:10:35,100
I have a computer science
major, but I've never, I don't

246
00:10:35,100 --> 00:10:37,150
have a PhD in AI or
machine learning, you know,

247
00:10:37,150 --> 00:10:39,730
so, I just kind of went with
what I was familiar with

248
00:10:39,730 --> 00:10:41,110
and what she's was familiar with.

249
00:10:41,110 --> 00:10:42,580
Using our backgrounds and that's kind of

250
00:10:42,580 --> 00:10:45,763
how he went from there in the
limited time that we had, so.

251
00:10:49,510 --> 00:10:50,343
Any others?

252
00:10:51,760 --> 00:10:54,500
- [Questioner 3] Sorry,
I wasn't if it's my turn.

253
00:10:54,500 --> 00:10:57,991
I got my PhD from YouTube,
on machine learning

254
00:10:57,991 --> 00:10:58,824
(audiences laughing)

255
00:10:58,824 --> 00:11:00,074
so we're in good company.

256
00:11:02,940 --> 00:11:07,020
When you do the release and opensource

257
00:11:07,020 --> 00:11:10,010
Jupiter notebook, perhaps?

258
00:11:10,010 --> 00:11:12,000
- [Jackie] Our old code used
to be on Jupyter notebook,

259
00:11:12,000 --> 00:11:14,570
but we're actually, we
have it in a web app now,

260
00:11:14,570 --> 00:11:17,523
so no more Jupyter notebooks.
Unless people want them.

261
00:11:18,907 --> 00:11:22,160
(Jackie laughs)

262
00:11:22,160 --> 00:11:24,290
- Thank you. It's a great effort.

263
00:11:24,290 --> 00:11:26,990
You did great job on this. I
think that the community can

264
00:11:26,990 --> 00:11:30,190
really run with this, so I appreciate it.

265
00:11:30,190 --> 00:11:31,083
- [Jackie] Awesome.

266
00:11:35,974 --> 00:11:36,993
Any others?

267
00:11:38,120 --> 00:11:40,120
- [Sarah] We have one in the front here.

268
00:11:42,010 --> 00:11:43,653
- [Announcer] Getting
your exercise today, huh?

269
00:11:51,540 --> 00:11:52,860
- [Questioner 4] So if I'm
understanding it right,

270
00:11:52,860 --> 00:11:55,260
basically it's going to be a web app

271
00:11:55,260 --> 00:11:57,600
that's going to be hosted
by you guys, correct?

272
00:11:57,600 --> 00:12:00,420
- [Sarah] No, sir. It's
actually all run locally, so.

273
00:12:00,420 --> 00:12:01,252
- Okay.

274
00:12:01,253 --> 00:12:03,160
'cause the next place I was
going was how you were going to

275
00:12:03,160 --> 00:12:05,329
de-conflict potentially if
two people submit the same

276
00:12:05,330 --> 00:12:08,040
report and then train it, but.

277
00:12:08,040 --> 00:12:10,069
- [Sarah] Yeah, so right
now it's run locally

278
00:12:10,070 --> 00:12:11,636
on the user's system.

279
00:12:11,636 --> 00:12:14,620
Looking, we have looked
into having it in more of a

280
00:12:14,620 --> 00:12:17,200
centralized location so that
multiple analysts would be able

281
00:12:17,200 --> 00:12:22,200
to use it at the same time,
to kind of curb your thought

282
00:12:22,560 --> 00:12:25,560
of deconfliction were we have
some features that are in the

283
00:12:25,560 --> 00:12:28,630
works to kind of tag reports
that would say like, Sarah is

284
00:12:28,630 --> 00:12:31,350
working on this one, Jackie's
working on this other,

285
00:12:31,350 --> 00:12:33,080
so that hopefully the
same analyst isn't working

286
00:12:33,080 --> 00:12:34,830
on the same report.

287
00:12:34,830 --> 00:12:35,750
- [Questioner 4] Would you have the option

288
00:12:35,750 --> 00:12:37,810
to send the reports back to you

289
00:12:37,810 --> 00:12:40,733
guys to then update the ATT&CK matrix?

290
00:12:42,110 --> 00:12:43,470
- [Sarah] Yeah. Through our normal

291
00:12:43,470 --> 00:12:45,680
contribution methods, yep.

292
00:12:45,680 --> 00:12:49,040
We would love to get more reports in

293
00:12:49,040 --> 00:12:51,810
that we didn't have to
do ourselves so yeah,

294
00:12:51,810 --> 00:12:52,920
definitely interested there.

295
00:12:52,920 --> 00:12:53,870
- [Jackie] Yeah, we think
it'll definitely help

296
00:12:53,870 --> 00:12:56,330
increase community
contributions that way too.

297
00:12:56,330 --> 00:12:58,380
Cause that'll give you guys
a way to find reports, have

298
00:12:58,380 --> 00:13:01,500
them mapped and give them
to us as well, so. Great.

299
00:13:01,500 --> 00:13:02,333
- [Sarah] Thanks.

300
00:13:02,333 --> 00:13:06,196
- [Jackie] Yeah.

301
00:13:06,196 --> 00:13:08,440
(murmurs)

302
00:13:08,440 --> 00:13:09,500
- [Announcer] I think
Sarah and Jackie have

303
00:13:09,500 --> 00:13:12,220
generously offered to
do live demos for folks,

304
00:13:12,220 --> 00:13:16,480
not on stage, but folks in
McLean, pull them aside.

305
00:13:16,480 --> 00:13:18,930
It's, it's a pretty slick
tool and I'm pretty excited

306
00:13:18,930 --> 00:13:21,109
to hopefully opensource
that in the near future,

307
00:13:21,110 --> 00:13:23,590
so there are no other questions,
catch them during break

308
00:13:23,590 --> 00:13:25,220
during the reception
tonight 'cause they've done

309
00:13:25,220 --> 00:13:26,500
some great work here.

310
00:13:26,500 --> 00:13:28,723
Please join me in
thanking Sarah and Jackie.

311
00:13:28,723 --> 00:13:31,890
(audience applauding)

