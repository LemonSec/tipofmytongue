1
00:00:01,110 --> 00:00:04,373
- [Katie] Please join me in
welcoming David and Andy.

2
00:00:04,373 --> 00:00:07,380
(audience applauding)

3
00:00:07,380 --> 00:00:08,460
- All right, good morning.

4
00:00:08,460 --> 00:00:10,560
Katie, thank you very
much for the introduction.

5
00:00:10,560 --> 00:00:12,650
We're excited to be here today to tell you

6
00:00:12,650 --> 00:00:13,690
about Nationwide's journey

7
00:00:13,690 --> 00:00:16,129
to operationalizing the
MITRE ATT&CK framework.

8
00:00:16,129 --> 00:00:19,090
Like any good story, it started
off with a lot of promise,

9
00:00:19,090 --> 00:00:20,950
this MITRE ATT&CK thing,
how great this could be

10
00:00:20,950 --> 00:00:23,210
for our organization, and
then we tried to do it

11
00:00:23,210 --> 00:00:25,848
in our own environment and
realized how tough it was,

12
00:00:25,848 --> 00:00:28,540
and we tried our own ways
and ended up realizing

13
00:00:28,540 --> 00:00:31,330
and going into despair as
we realized we had no idea

14
00:00:31,330 --> 00:00:34,239
what we were doing, and
realizing the enormity

15
00:00:34,240 --> 00:00:36,530
of this situation, and
getting to the point

16
00:00:36,530 --> 00:00:38,930
where we almost gave up on MITRE ATT&CK,

17
00:00:38,930 --> 00:00:41,220
almost threw it in the trash
because we just didn't know

18
00:00:41,220 --> 00:00:43,860
how to figure out how to
get value out of this,

19
00:00:43,860 --> 00:00:46,960
but then we stumbled upon this
thing called intelligence.

20
00:00:46,960 --> 00:00:50,510
It kinda shed some light
on how we could actually go

21
00:00:50,510 --> 00:00:52,470
about doing this, gave us some focus,

22
00:00:52,470 --> 00:00:56,608
gave us some prioritization,
allowed us to see the light

23
00:00:56,608 --> 00:00:59,430
to be able to seize the day,
do all those famous things

24
00:00:59,430 --> 00:01:02,140
like slaying dragons and, ultimately,

25
00:01:02,140 --> 00:01:04,610
being able to operationalize
this within our own environment

26
00:01:04,610 --> 00:01:07,420
so, not quite a Hollywood story here,

27
00:01:07,420 --> 00:01:09,500
but we're really excited about the journey

28
00:01:09,500 --> 00:01:11,710
that we've been on over
the last several years

29
00:01:11,710 --> 00:01:13,800
and to be able to talk
to you today about that.

30
00:01:13,800 --> 00:01:16,910
But first, we're gonna hit
our introductions here.

31
00:01:16,910 --> 00:01:19,440
- I'm Andy Kettell,
I've been in IT security

32
00:01:19,440 --> 00:01:20,730
for the last 20 years,

33
00:01:20,730 --> 00:01:22,860
and spent the last four
in Nationwide Insurance

34
00:01:22,860 --> 00:01:24,820
in their Cyber Security Operations Center.

35
00:01:24,820 --> 00:01:28,169
I'm also our ATT&CK champion,
spreading all the goodness

36
00:01:28,170 --> 00:01:29,570
that we can do with ATT&CK.

37
00:01:29,570 --> 00:01:32,440
- Awesome, and David
Westin, I spent 20 years

38
00:01:32,440 --> 00:01:34,380
as an intelligence officer
in the Marine Corps,

39
00:01:34,380 --> 00:01:36,339
spent the last four years helping

40
00:01:36,340 --> 00:01:38,680
to stand up the capabilities
at US Cyber Command,

41
00:01:38,680 --> 00:01:40,980
ended up retiring at the end of 2017,

42
00:01:40,980 --> 00:01:42,740
joining Nationwide early in 2018

43
00:01:42,740 --> 00:01:44,160
and have been there since then.

44
00:01:44,160 --> 00:01:45,590
So we also have a couple other folks

45
00:01:45,590 --> 00:01:46,850
that have been on this journey.

46
00:01:46,850 --> 00:01:48,470
One of the big key
lessons that we learned,

47
00:01:48,470 --> 00:01:49,550
I think Tony mentioned it,

48
00:01:49,550 --> 00:01:51,670
was it can't just be a
couple folks doing this.

49
00:01:51,670 --> 00:01:53,850
We've have quite the village
that've helped us out

50
00:01:53,850 --> 00:01:55,899
over the last year in particular.

51
00:01:55,900 --> 00:01:58,270
One of our associates is
actually across town right now,

52
00:01:58,270 --> 00:02:00,580
giving a presentation
at another conference,

53
00:02:00,580 --> 00:02:02,480
very similar to the
presentation we're giving here,

54
00:02:02,480 --> 00:02:04,630
except focusing on the
collection tools that we use

55
00:02:04,630 --> 00:02:09,630
and spending, so, we also have
the Columbus Collaboratory,

56
00:02:09,777 --> 00:02:12,750
that's a group of seven
different companies,

57
00:02:12,750 --> 00:02:14,560
seven of the largest
companies in Columbus, Ohio

58
00:02:14,560 --> 00:02:18,170
that banded together to focus
on cybersecurity challenges.

59
00:02:18,170 --> 00:02:20,470
That's another topic, if
anybody's interested offline,

60
00:02:20,470 --> 00:02:23,030
that we'd love to chat with you about.

61
00:02:23,030 --> 00:02:26,190
So we're gonna start by
focusing on how it didn't work,

62
00:02:26,190 --> 00:02:28,040
and I'm gonna give this over to Andy.

63
00:02:30,520 --> 00:02:32,950
- Yep, so like with many
organizations, getting started

64
00:02:32,950 --> 00:02:34,933
with ATT&CK can be quite challenging.

65
00:02:36,020 --> 00:02:39,660
Understanding what ATT&CK
is, who should we involve,

66
00:02:39,660 --> 00:02:43,520
how do we use this, is few
questions we wanted to answer.

67
00:02:43,520 --> 00:02:46,980
So we put together a
project with the approach

68
00:02:46,980 --> 00:02:49,869
of looking at, taking the MITRE techniques

69
00:02:49,870 --> 00:02:51,910
and lining them up with
our security tools,

70
00:02:51,910 --> 00:02:54,890
and also, the second focus
of testing out our endpoints

71
00:02:54,890 --> 00:02:58,489
to identify any potential
security threats.

72
00:02:58,490 --> 00:03:03,440
So we started off, (mumbles) yep.

73
00:03:03,440 --> 00:03:05,270
So we started as Project Squishee.

74
00:03:05,270 --> 00:03:06,910
It's a great name.

75
00:03:06,910 --> 00:03:09,299
Here's what we ended up
doing is we had members

76
00:03:09,300 --> 00:03:10,770
from the Attack and Penetration team,

77
00:03:10,770 --> 00:03:13,612
as well as security tool
engineers, come together

78
00:03:13,612 --> 00:03:15,859
and performing some of these tests.

79
00:03:15,860 --> 00:03:19,670
Like any great road trip, we
were high energy, excited,

80
00:03:19,670 --> 00:03:22,420
we had all the techniques,
the MITRE framework,

81
00:03:22,420 --> 00:03:25,119
we had security tools to look at,

82
00:03:25,120 --> 00:03:28,690
and we had all these techniques
we wanted to assess against.

83
00:03:28,690 --> 00:03:32,280
We started off testing each
technique one at a time.

84
00:03:32,280 --> 00:03:35,380
We went very deep and very
wide on those techniques,

85
00:03:35,380 --> 00:03:38,630
sometimes knocking down lines
of defenses on the endpoints

86
00:03:38,630 --> 00:03:40,363
and retesting it again and again.

87
00:03:41,370 --> 00:03:43,230
Great approach, very thorough,

88
00:03:43,230 --> 00:03:44,380
got a lot of good understanding

89
00:03:44,380 --> 00:03:47,740
of how the ATT&CK techniques operated,

90
00:03:47,740 --> 00:03:49,973
but then leadership started
coming to us, saying,

91
00:03:49,973 --> 00:03:52,100
are you done testing all the techniques?

92
00:03:52,100 --> 00:03:54,170
You've been doing this for a while.

93
00:03:54,170 --> 00:03:55,709
What are the results?

94
00:03:55,710 --> 00:03:58,750
And then we kind of started
understanding a few months

95
00:03:58,750 --> 00:04:01,200
into the project that
our current methodologies

96
00:04:01,200 --> 00:04:03,980
and approach, it'll
probably take several years

97
00:04:03,980 --> 00:04:06,673
going through this, and
it wasn't working out.

98
00:04:08,330 --> 00:04:12,380
So for our first attempt, we
learned a lot of what to do

99
00:04:12,380 --> 00:04:15,067
and what not to do with
the MITRE framework.

100
00:04:15,068 --> 00:04:18,800
The primary thing is the lack of focus.

101
00:04:18,800 --> 00:04:21,300
When we get done with testing
a technique, we went forward

102
00:04:21,300 --> 00:04:23,090
and grabbed another technique.

103
00:04:23,090 --> 00:04:24,690
No real rhyme or reason.

104
00:04:24,690 --> 00:04:26,190
Maybe it was something
we heard in the news,

105
00:04:26,190 --> 00:04:28,210
some approach that someone in the AP team

106
00:04:28,210 --> 00:04:31,659
wanted to test out, so we
didn't really have that focus

107
00:04:31,660 --> 00:04:33,550
that really drove a lot of this.

108
00:04:33,550 --> 00:04:36,900
We also weren't really
formalized in how we wanted

109
00:04:36,900 --> 00:04:40,414
to document this, so we would
forward, we went forward,

110
00:04:40,415 --> 00:04:43,070
testing out a technique,
and when we're done,

111
00:04:43,070 --> 00:04:44,170
we moved on to another one,

112
00:04:44,170 --> 00:04:46,840
but we really didn't capture consistently

113
00:04:46,840 --> 00:04:48,815
how the results were done.

114
00:04:48,815 --> 00:04:53,815
That also led to a lack of participation,

115
00:04:54,190 --> 00:04:57,210
because while the Attack and
Pen team was working on it,

116
00:04:57,210 --> 00:04:59,359
the other engineers were participating,

117
00:04:59,360 --> 00:05:01,700
but they weren't able to
be active in that project.

118
00:05:01,700 --> 00:05:04,813
So we had some participation
(mumbles) that came up as well.

119
00:05:08,020 --> 00:05:10,810
- So, by the summer of 2018,

120
00:05:10,810 --> 00:05:14,320
we'd been trying to
operationalize MITRE ATT&CK

121
00:05:14,320 --> 00:05:15,849
for about 15 months, and we would go

122
00:05:15,850 --> 00:05:18,410
and the ATT&CK framework was
going nowhere at Nationwide

123
00:05:18,410 --> 00:05:19,960
except maybe into the trash.

124
00:05:19,960 --> 00:05:22,640
We just, we had no excitement
around this framework,

125
00:05:22,640 --> 00:05:25,169
we had no, nobody really still
understood what it could do

126
00:05:25,170 --> 00:05:28,000
for us, nobody, none of our
leadership could find value

127
00:05:28,000 --> 00:05:29,730
in what we were trying to do.

128
00:05:29,730 --> 00:05:31,180
So, I like stories.

129
00:05:31,180 --> 00:05:34,020
I think stories help embrace new concepts,

130
00:05:34,020 --> 00:05:37,289
especially tricky concepts,
and one of the challenges

131
00:05:37,290 --> 00:05:38,930
we were having is we
couldn't tell our story

132
00:05:38,930 --> 00:05:41,117
for what we were trying to do with ATT&CK.

133
00:05:41,117 --> 00:05:44,330
If you'd asked us what our
story was for MITRE ATT&CK

134
00:05:44,330 --> 00:05:46,070
back in the summer of 2018,

135
00:05:46,070 --> 00:05:47,800
it would be something similar to this.

136
00:05:47,800 --> 00:05:52,360
Hey, boss, we've got this
240-some odd techniques

137
00:05:52,360 --> 00:05:54,060
that tell you everything
that all threat actors

138
00:05:54,060 --> 00:05:56,073
are gonna be able to
do in our environment.

139
00:05:56,073 --> 00:05:58,219
We've kind of looked through those,

140
00:05:58,220 --> 00:06:00,680
I think we're pretty good
against most of those techniques,

141
00:06:00,680 --> 00:06:03,140
we've got some other ones that
we probably could work on,

142
00:06:03,140 --> 00:06:05,080
and we're gonna go and
we're gonna deep dive

143
00:06:05,080 --> 00:06:06,039
into a couple of techniques

144
00:06:06,040 --> 00:06:07,790
and see what we can come up with.

145
00:06:07,790 --> 00:06:09,980
Kind of boring, not really
giving any excitement,

146
00:06:09,980 --> 00:06:11,900
not really giving what leadership needs,

147
00:06:11,900 --> 00:06:15,573
which is an understanding
of what's gonna affect him

148
00:06:15,573 --> 00:06:18,669
and his job, what's gonna
kind of get him in trouble,

149
00:06:18,670 --> 00:06:21,330
and so let's add that
intelligence into there

150
00:06:21,330 --> 00:06:23,219
and let's change the story.

151
00:06:23,220 --> 00:06:25,830
So if we came across,
so we added intelligence

152
00:06:25,830 --> 00:06:27,539
and our story started sounding like this.

153
00:06:27,540 --> 00:06:29,520
Hey, boss, our research indicates

154
00:06:29,520 --> 00:06:31,960
that there are 27 threat
actors that are known

155
00:06:31,960 --> 00:06:34,450
to target similar peers in our finance

156
00:06:34,450 --> 00:06:35,789
and insurance industry.

157
00:06:35,790 --> 00:06:37,680
Those 27 threat actors are known

158
00:06:37,680 --> 00:06:40,950
to use 91 specific
techniques in their attacks.

159
00:06:40,950 --> 00:06:44,360
Additionally, we can further
prioritize those techniques

160
00:06:44,360 --> 00:06:46,860
based on widespread use
and ease of execution.

161
00:06:46,860 --> 00:06:48,337
We are gonna test those 91 techniques,

162
00:06:48,337 --> 00:06:51,099
and we're gonna come up with
mitigations and detections,

163
00:06:51,100 --> 00:06:52,850
we're gonna implement those environment

164
00:06:52,850 --> 00:06:55,720
to protect against the
most likely threat actors

165
00:06:55,720 --> 00:06:57,660
that are facing our industry.

166
00:06:57,660 --> 00:06:58,890
That's a lot better story.

167
00:06:58,890 --> 00:07:00,210
That's something that tells to risk,

168
00:07:00,210 --> 00:07:02,489
that tells senior
leadership, gets them excited

169
00:07:02,490 --> 00:07:05,550
about what's gonna, what's
most likely to affect them,

170
00:07:05,550 --> 00:07:08,149
and in effect, our company, and
what's gonna keep them safe,

171
00:07:08,149 --> 00:07:09,960
what's gonna keep our company safe

172
00:07:09,960 --> 00:07:11,972
and keep our CISO's job safe.

173
00:07:14,930 --> 00:07:17,630
Okay, so, the process
that we ended up using

174
00:07:17,630 --> 00:07:19,390
at Nationwide was five-step process.

175
00:07:19,390 --> 00:07:20,223
We're gonna talk heavily

176
00:07:20,223 --> 00:07:22,200
about the threat intelligence phase here,

177
00:07:22,200 --> 00:07:24,409
but there are four other
phases, and I will tell you

178
00:07:24,410 --> 00:07:26,260
that the best thing to say

179
00:07:26,260 --> 00:07:28,750
is that once we figured out
the threat intelligence phase,

180
00:07:28,750 --> 00:07:30,730
everything else kind of fell into place,

181
00:07:30,730 --> 00:07:32,420
and we'll talk about this
slide here in a second,

182
00:07:32,420 --> 00:07:35,030
but really, the threat
intelligence faced was the roadmap

183
00:07:35,030 --> 00:07:37,000
that we used, and once we had that down,

184
00:07:37,000 --> 00:07:38,450
everything was pretty simple.

185
00:07:39,320 --> 00:07:41,460
So I talked a second ago
about 27 threat actors.

186
00:07:41,460 --> 00:07:43,806
That's what we ended up
with, that we were focused on

187
00:07:43,806 --> 00:07:46,010
at Nationwide, focused on the finance

188
00:07:46,010 --> 00:07:47,289
and insurance industry.

189
00:07:47,290 --> 00:07:50,770
How we got there was
actually almost pure luck.

190
00:07:50,770 --> 00:07:52,717
In the summer of 2018, we had an intern

191
00:07:52,718 --> 00:07:54,900
and we gave her a typical intern project,

192
00:07:54,900 --> 00:07:56,561
hey, go figure out all the threats

193
00:07:56,562 --> 00:07:59,820
that could potentially affect Nationwide.

194
00:07:59,820 --> 00:08:02,340
So she, we did this project
actually completely separate

195
00:08:02,340 --> 00:08:05,390
from MITRE ATT&CK and if
you remember, at the time,

196
00:08:05,390 --> 00:08:07,360
MITRE ATT&CK for us was going nowhere.

197
00:08:07,360 --> 00:08:09,370
We were basically getting
ready to scrap that.

198
00:08:09,370 --> 00:08:11,430
Turns out that putting those two together

199
00:08:11,430 --> 00:08:13,230
is when we realized that
we had a lot of value

200
00:08:13,230 --> 00:08:14,520
for our organization.

201
00:08:14,520 --> 00:08:17,299
But, so the 27 threat actors, so, again,

202
00:08:17,300 --> 00:08:18,710
we gave this intern a project.

203
00:08:18,710 --> 00:08:20,662
She went out and she did a whole bunch

204
00:08:20,663 --> 00:08:22,260
of opensource research,
trying to figure out,

205
00:08:22,260 --> 00:08:25,370
and she ended up finding
the spreadsheet out there

206
00:08:25,370 --> 00:08:27,680
that had a couple of hundred
different threat actors.

207
00:08:27,680 --> 00:08:29,560
This spreadsheet had a
number of different tabs

208
00:08:29,560 --> 00:08:31,780
based on geographic location.

209
00:08:31,780 --> 00:08:34,725
It had a whole bunch of columns
that I think we mentioned,

210
00:08:34,725 --> 00:08:38,500
a threat actor has 12 or
13 other different names,

211
00:08:38,500 --> 00:08:39,559
so it had columns for those.

212
00:08:39,559 --> 00:08:41,569
It talked about the ATT&CKs
that they were involved in,

213
00:08:41,570 --> 00:08:43,050
but it had a really neat column on there

214
00:08:43,049 --> 00:08:44,319
that talked about the industries

215
00:08:44,320 --> 00:08:46,440
that each of the threat
actors were known to target.

216
00:08:46,440 --> 00:08:48,490
We saw that as something
that we could be able

217
00:08:48,490 --> 00:08:51,190
to take advantage of in our organization.

218
00:08:51,190 --> 00:08:52,800
So we did a bunch more research.

219
00:08:52,800 --> 00:08:56,199
We fine-tuned that spreadsheet.

220
00:08:56,200 --> 00:08:58,220
We added a few threat
actors that we knew about

221
00:08:58,220 --> 00:08:59,170
that weren't on there.

222
00:08:59,170 --> 00:09:01,829
We kind of cleaned up some of
the work that was in there.

223
00:09:01,830 --> 00:09:04,580
We still had this big spreadsheet
of data and we're like,

224
00:09:04,580 --> 00:09:08,860
okay, so we need to make this
more valuable to Nationwide.

225
00:09:08,860 --> 00:09:10,940
And that's where we came
up with a scoring system

226
00:09:10,940 --> 00:09:12,390
like you see on the screen here.

227
00:09:12,390 --> 00:09:14,800
So this scoring system,
but again, it's very basic.

228
00:09:14,800 --> 00:09:16,630
All we did was we started taking a look

229
00:09:16,630 --> 00:09:19,689
at just kinda guessing at what each

230
00:09:19,690 --> 00:09:23,440
of the threat actors'
capability and intent were.

231
00:09:23,440 --> 00:09:26,010
So intent for us, we're
a US-based company,

232
00:09:26,010 --> 00:09:29,610
so if the threat actor
was targeting overseas

233
00:09:29,610 --> 00:09:31,390
and not targeting anywhere in the US,

234
00:09:31,390 --> 00:09:33,930
we're not gonna care about it as much.

235
00:09:33,930 --> 00:09:36,380
If they're targeting, if
they're financially motivating,

236
00:09:36,380 --> 00:09:37,213
we'll give them a point.

237
00:09:37,213 --> 00:09:40,680
If they're targeting the finance industry,

238
00:09:40,680 --> 00:09:41,512
we'll give them a point.

239
00:09:41,513 --> 00:09:43,830
If they're targeting the
finance and insurance industry,

240
00:09:43,830 --> 00:09:44,800
we'll give them a point.

241
00:09:44,800 --> 00:09:45,800
They're targeting Nationwide,

242
00:09:45,800 --> 00:09:47,800
we'll give them a whole bunch of points.

243
00:09:49,160 --> 00:09:51,130
Point is that it wasn't very scientific.

244
00:09:51,130 --> 00:09:54,500
It was just, it was kind of
name, let's go throw a number

245
00:09:54,500 --> 00:09:56,120
on there, and we really
didn't worry about,

246
00:09:56,120 --> 00:09:58,420
so much about being exact on that.

247
00:09:58,420 --> 00:09:59,779
Same thing with capability.

248
00:09:59,779 --> 00:10:01,790
As we went through our research,

249
00:10:01,790 --> 00:10:04,689
as we were studying the
different threat actors,

250
00:10:04,690 --> 00:10:05,810
if somebody had come out and said,

251
00:10:05,810 --> 00:10:07,319
this is a really capable threat actor,

252
00:10:07,320 --> 00:10:09,290
these are very
sophisticated threat actors,

253
00:10:09,290 --> 00:10:10,180
we'll give them more points.

254
00:10:10,180 --> 00:10:12,199
If they were saying they're
kind of more script kiddie-like,

255
00:10:12,200 --> 00:10:13,830
we wouldn't give them a lot of points.

256
00:10:13,830 --> 00:10:17,200
And, ultimately, if they
had additional resources

257
00:10:17,200 --> 00:10:18,690
behind them, we'll add up,

258
00:10:18,690 --> 00:10:20,820
we'll give them a few more points, again,

259
00:10:20,820 --> 00:10:24,420
on a scale of one to five, and
then we aged off that number.

260
00:10:24,420 --> 00:10:27,449
So if we hadn't seen a
threat actor, any activity

261
00:10:27,450 --> 00:10:29,570
in the last six months,
12 months, et cetera,

262
00:10:29,570 --> 00:10:31,230
we'd start taking away half a point here

263
00:10:31,230 --> 00:10:33,340
and half a point there, so
that way, we didn't end up

264
00:10:33,340 --> 00:10:35,370
with our top threat actor being somebody

265
00:10:35,370 --> 00:10:37,900
that nobody's heard of since 2011.

266
00:10:37,900 --> 00:10:40,530
So, ultimately, we have
this great spreadsheet now.

267
00:10:40,530 --> 00:10:42,650
It still isn't, we've got a
whole bunch of numbers on it,

268
00:10:42,650 --> 00:10:45,040
but it still isn't telling a full story.

269
00:10:45,040 --> 00:10:47,370
So what we realized that we needed to do,

270
00:10:47,370 --> 00:10:50,010
what any self-respecting
intel shop would do,

271
00:10:50,010 --> 00:10:51,633
which is we put it into a chart.

272
00:10:52,670 --> 00:10:54,498
- And it's a very brave chart indeed.

273
00:10:54,499 --> 00:10:57,440
Here's where we actually
take in threat intelligence

274
00:10:57,440 --> 00:10:59,770
and visualize the threat actors,

275
00:10:59,770 --> 00:11:03,430
and we can now quickly learn
a lot about our adversaries.

276
00:11:03,430 --> 00:11:05,829
One thing we picked up
as a great aha moment

277
00:11:05,830 --> 00:11:08,290
is that they were evenly
spread across the chart,

278
00:11:08,290 --> 00:11:11,020
and they weren't clustered
in any one central area.

279
00:11:11,020 --> 00:11:12,439
This is also the first time we're able

280
00:11:12,440 --> 00:11:16,250
to take threat intelligence
and the MITRE ATT&CK framework,

281
00:11:16,250 --> 00:11:20,750
and start bringing awareness
to our security teams

282
00:11:20,750 --> 00:11:23,020
and to our leadership who
especially liked the chart

283
00:11:23,020 --> 00:11:25,699
because now it really
brought home, almost a face,

284
00:11:25,700 --> 00:11:26,810
to some of these threat actors

285
00:11:26,810 --> 00:11:28,402
that are operating against us.

286
00:11:30,570 --> 00:11:32,820
As many security professionals,
we want to sit there

287
00:11:32,820 --> 00:11:34,870
and try to evaluate
every single technique,

288
00:11:34,870 --> 00:11:37,053
every single threat, every single tool.

289
00:11:38,180 --> 00:11:40,939
Following this approach, we're
now able to take that down

290
00:11:40,940 --> 00:11:45,940
to the top 27 threat actors
that are operating against us.

291
00:11:46,150 --> 00:11:49,300
We're able to look at the
TTPs that they're using

292
00:11:49,300 --> 00:11:53,449
and we want to give those
the highest prioritization

293
00:11:53,450 --> 00:11:56,213
and understanding of how
they're working against us.

294
00:11:57,400 --> 00:12:00,829
So now we're armed with a focus.

295
00:12:00,830 --> 00:12:02,700
We know who we're gonna go after

296
00:12:02,700 --> 00:12:05,110
and we know who we're looking into,

297
00:12:05,110 --> 00:12:07,130
and we can move on to the what.

298
00:12:07,130 --> 00:12:08,439
- So to get the what, we went back

299
00:12:08,440 --> 00:12:12,100
to the MITRE ATT&CK website,
a great resource to be able

300
00:12:12,100 --> 00:12:14,140
to pull down the techniques
that are associated

301
00:12:14,140 --> 00:12:15,610
with each of these threat actors.

302
00:12:15,610 --> 00:12:20,610
So we went there, we went
to the ATT&CK, what is the,

303
00:12:22,200 --> 00:12:23,033
drawing a blank on that.

304
00:12:23,033 --> 00:12:23,866
- [Andy] Navigator.

305
00:12:23,866 --> 00:12:26,290
- The Navigator, thank you
very much, I appreciate that,

306
00:12:26,290 --> 00:12:28,740
and went to the Navigator,
you put in a threat actor,

307
00:12:28,740 --> 00:12:31,080
it gives you all the techniques
associated with that.

308
00:12:31,080 --> 00:12:32,830
27, there's 22 different techniques

309
00:12:32,830 --> 00:12:34,390
that are associated with them.

310
00:12:34,390 --> 00:12:37,220
So we did that, but we realized
that with 27 threat actors,

311
00:12:37,220 --> 00:12:39,170
not all of them were on
the MITRE ATT&CK sites.

312
00:12:39,170 --> 00:12:40,880
We had to do a lot of research ourselves.

313
00:12:40,880 --> 00:12:43,640
We used our own intelligence
collection service.

314
00:12:43,640 --> 00:12:45,947
We use Recorded Future,
but any of the other

315
00:12:45,947 --> 00:12:48,910
typical intelligence collection services

316
00:12:48,910 --> 00:12:51,020
are gonna be able to give
you a similar capability

317
00:12:51,020 --> 00:12:52,870
to be able to dive into each
one of the threat actors,

318
00:12:52,870 --> 00:12:55,240
to be able to understand, how do they,

319
00:12:55,240 --> 00:12:56,840
the anatomy of how they attacked,

320
00:12:56,840 --> 00:12:58,930
and then to understand the
techniques associated with that,

321
00:12:58,930 --> 00:13:02,290
so we spent a lot of time, we
grabbed research from FS-ISAC,

322
00:13:02,290 --> 00:13:04,699
from our friends in the
Columbus Collaboratory,

323
00:13:04,700 --> 00:13:07,090
from Twitter, anywhere we
could find it, we just,

324
00:13:07,090 --> 00:13:09,180
we threw it all together into a big pile.

325
00:13:09,180 --> 00:13:11,870
Again, we're not so worried
about being right or wrong

326
00:13:11,870 --> 00:13:14,020
so much as we're trying to
just get as much information

327
00:13:14,020 --> 00:13:15,949
on each of these threat
actors as possible.

328
00:13:15,950 --> 00:13:18,030
So we tried to put it into ATT&CK.

329
00:13:18,030 --> 00:13:19,480
We started off by trying to put everything

330
00:13:19,480 --> 00:13:21,340
into ATT&CK Navigator,
realized that we wanted

331
00:13:21,340 --> 00:13:23,770
to shape the data a
little bit differently.

332
00:13:23,770 --> 00:13:25,960
We want to be able to put a heat map

333
00:13:25,960 --> 00:13:28,770
for how many, the widespread
use of certain techniques.

334
00:13:28,770 --> 00:13:31,500
So we did, we exported all
of that into a spreadsheet

335
00:13:31,500 --> 00:13:34,160
'cause we like spreadsheets,
and we ended up

336
00:13:34,160 --> 00:13:36,579
with something that looks like this.

337
00:13:36,580 --> 00:13:39,550
So all of the yellow on
there were where we had one

338
00:13:39,550 --> 00:13:41,800
or two threat actors that
were using a technique,

339
00:13:41,800 --> 00:13:45,130
the ones that are closer to
red, we had more threat actors

340
00:13:45,130 --> 00:13:47,300
that were using those
techniques, up until things

341
00:13:47,300 --> 00:13:49,030
like PowerShell, I think eight or nine,

342
00:13:49,030 --> 00:13:50,600
the threat actors that we had noted

343
00:13:50,600 --> 00:13:52,040
were using that technique.

344
00:13:52,040 --> 00:13:53,230
But still kind of clunky.

345
00:13:53,230 --> 00:13:55,510
There's still, it's still
a little bit messy here.

346
00:13:55,510 --> 00:13:57,520
We're still not being able
to tell the full story.

347
00:13:57,520 --> 00:14:00,350
And the problem is that
this, you're still talking

348
00:14:00,350 --> 00:14:03,300
to this huge spreadsheet
and it's still cluttered

349
00:14:03,300 --> 00:14:04,589
with a bunch of information on here.

350
00:14:04,590 --> 00:14:05,423
So we're gonna go ahead

351
00:14:05,423 --> 00:14:07,110
and we're gonna remove
all of the techniques

352
00:14:07,110 --> 00:14:08,620
that we're not gonna focus on.

353
00:14:08,620 --> 00:14:11,430
And now you get what I think
Blake had mentioned earlier

354
00:14:11,430 --> 00:14:14,319
about not being able to
put all your MITRE ATT&CK

355
00:14:14,320 --> 00:14:15,153
on one slide.

356
00:14:15,153 --> 00:14:16,740
We've got our MITRE ATT&CK on one slide.

357
00:14:16,740 --> 00:14:19,424
These are the things that we
care about at our organization.

358
00:14:19,424 --> 00:14:21,240
And the neat thing on this one

359
00:14:21,240 --> 00:14:24,420
is I've actually presented
this up to our CIO as far as,

360
00:14:24,420 --> 00:14:26,900
on a PowerPoint slide similar to this,

361
00:14:26,900 --> 00:14:30,860
and it's something unlike, as
everybody else struggles with,

362
00:14:30,860 --> 00:14:33,440
trying to get this, what
a MITRE ATT&CK looks like

363
00:14:33,440 --> 00:14:35,050
in one area, but most importantly,

364
00:14:35,050 --> 00:14:36,560
we have a manageable project.

365
00:14:36,560 --> 00:14:40,410
So we started with 240-plus
techniques, and we had no idea

366
00:14:40,410 --> 00:14:42,040
where to start with on that.

367
00:14:42,040 --> 00:14:43,593
Now we have 91 techniques.

368
00:14:43,594 --> 00:14:46,270
Some tactics that only
have four techniques

369
00:14:46,270 --> 00:14:47,555
that we need to focus on.

370
00:14:47,556 --> 00:14:50,130
This is something that
you can actually get into.

371
00:14:50,130 --> 00:14:54,010
It's kinda like, just you're
taking that first bite

372
00:14:54,010 --> 00:14:54,843
of the apple.

373
00:14:54,843 --> 00:14:56,439
You need to be able to take
it before you can move on,

374
00:14:56,440 --> 00:14:58,930
and this is, this enabled us to do that.

375
00:14:58,930 --> 00:15:02,620
So, in our mind, this was the
most important thing for us,

376
00:15:02,620 --> 00:15:03,730
was to get to this point.

377
00:15:03,730 --> 00:15:06,793
Once we had 91 techniques,
everything else,

378
00:15:07,950 --> 00:15:10,658
my favorite action character
growing up, GI Joe,

379
00:15:10,658 --> 00:15:13,750
we had the information and
knowing is half the battle,

380
00:15:13,750 --> 00:15:15,800
and quite honestly, that's true.

381
00:15:15,800 --> 00:15:17,479
So the next thing that we need to do

382
00:15:17,480 --> 00:15:18,680
is we need to actually put that

383
00:15:18,680 --> 00:15:19,829
into the rest of our process.

384
00:15:19,830 --> 00:15:22,059
We talked over five-step
process that we had.

385
00:15:22,059 --> 00:15:24,520
Once we had this, everything else

386
00:15:24,520 --> 00:15:26,620
really just kind of fell right into place.

387
00:15:26,620 --> 00:15:28,150
So we, the next thing that we did

388
00:15:28,150 --> 00:15:31,319
with each one of those 91
techniques was we tested those.

389
00:15:31,320 --> 00:15:33,941
So we have an Attack and
Penetration team at Nationwide

390
00:15:33,941 --> 00:15:37,299
that we ended up using to test
these, but quite honestly,

391
00:15:37,299 --> 00:15:42,299
the red canary, atomic
red team scripts were used

392
00:15:42,500 --> 00:15:45,700
on quite a great majority
of these to be able to test,

393
00:15:45,700 --> 00:15:46,910
so you don't necessarily need

394
00:15:46,910 --> 00:15:48,910
your own Attack and
Penetration to do this.

395
00:15:48,910 --> 00:15:51,150
As we tested these, we realized
that there were some things

396
00:15:51,150 --> 00:15:54,709
that did work in our environment,
that we had some things

397
00:15:54,710 --> 00:15:56,037
that didn't work in our environment.

398
00:15:56,037 --> 00:15:58,825
For those that our Attack
team was able to execute

399
00:15:58,825 --> 00:16:02,560
in our environment, we went
back to the MITRE ATT&CK site,

400
00:16:02,560 --> 00:16:05,209
pulled down the
recommendations for mitigations

401
00:16:05,210 --> 00:16:06,913
and detections, each recommendation

402
00:16:06,913 --> 00:16:09,710
we'd put onto a separate
line onto our spreadsheet

403
00:16:09,710 --> 00:16:13,170
'cause we like spreadsheets,
and we then used that

404
00:16:13,170 --> 00:16:15,500
and we started working with
our infrastructure folks

405
00:16:15,500 --> 00:16:18,330
and started talking to them,
hey, in our environment,

406
00:16:18,330 --> 00:16:20,310
can we execute this recommendation?

407
00:16:20,310 --> 00:16:22,000
If we can execute this
recommendation, we did.

408
00:16:22,000 --> 00:16:26,530
If we could not, we pushed,
we modified that in some way

409
00:16:26,530 --> 00:16:27,959
that would work for us.

410
00:16:27,960 --> 00:16:29,630
So a lot of the recommendations

411
00:16:29,630 --> 00:16:31,439
were secure config recommendations,

412
00:16:31,440 --> 00:16:32,960
very easy to do in our environment.

413
00:16:32,960 --> 00:16:34,600
There were other ones that we couldn't do

414
00:16:34,600 --> 00:16:36,550
because of the way our network is set up.

415
00:16:36,550 --> 00:16:38,089
And there were still
others that we realized,

416
00:16:38,090 --> 00:16:39,950
if we put them together
into a big project,

417
00:16:39,950 --> 00:16:42,510
we could actually get a
resourcing and funding for that,

418
00:16:42,510 --> 00:16:44,740
and because we were able
to talk and tell the story

419
00:16:44,740 --> 00:16:47,870
about how this is impacted,
that these are threat actors

420
00:16:47,870 --> 00:16:50,329
that are specifically
targeting our industry,

421
00:16:50,329 --> 00:16:52,079
made it a lot easier to get the funding

422
00:16:52,080 --> 00:16:55,680
to be able to get those projects started.

423
00:16:55,680 --> 00:16:57,920
Then the last thing that we
did was the leadership phase.

424
00:16:57,920 --> 00:17:01,310
In the first go around, we kept
everything very close hold.

425
00:17:01,310 --> 00:17:04,230
We actually classified a lot
of the data that was coming out

426
00:17:04,230 --> 00:17:05,973
of there, and so only a
few people actually knew

427
00:17:05,973 --> 00:17:07,119
what was going on.

428
00:17:07,119 --> 00:17:09,550
Well, only a few people
knowing what's going on

429
00:17:09,550 --> 00:17:11,780
doesn't get people excited
about what we're doing here

430
00:17:11,780 --> 00:17:12,839
with MITRE ATT&CK.

431
00:17:12,839 --> 00:17:15,000
We split the script for this time.

432
00:17:15,000 --> 00:17:16,109
We told everybody.

433
00:17:16,109 --> 00:17:18,990
We had weekly updates
where we would share,

434
00:17:18,990 --> 00:17:20,420
here's the techniques that we tested,

435
00:17:20,420 --> 00:17:22,640
here's what we were successful on,

436
00:17:22,640 --> 00:17:24,090
what we were not successful on,

437
00:17:24,089 --> 00:17:25,889
here are the mitigations, detections,

438
00:17:25,890 --> 00:17:27,200
and here's what we're doing about that.

439
00:17:27,200 --> 00:17:29,180
We had monthly meetings
with executive leaders

440
00:17:29,180 --> 00:17:31,660
where they had an opportunity
to help ask questions

441
00:17:31,660 --> 00:17:33,700
and understand what this
MITRE ATT&CK thing was

442
00:17:33,700 --> 00:17:35,860
and how we were implementing
in our environment.

443
00:17:35,860 --> 00:17:38,780
And when we were done with the
first testing phase, we said,

444
00:17:38,780 --> 00:17:40,220
we need to go on a road show.

445
00:17:40,220 --> 00:17:43,040
So we spent two months
going throughout Nationwide,

446
00:17:43,040 --> 00:17:43,903
talking about MITRE ATT&CK,

447
00:17:43,903 --> 00:17:45,800
talking about all the
different techniques,

448
00:17:45,800 --> 00:17:47,419
walking through each
one of those techniques,

449
00:17:47,420 --> 00:17:49,000
the 91 techniques, and showing them

450
00:17:49,000 --> 00:17:51,370
where we're protecting Nationwide

451
00:17:51,370 --> 00:17:52,731
against the most likely threat actors

452
00:17:52,731 --> 00:17:54,766
to target our industry.

453
00:17:54,766 --> 00:17:56,680
And then we also took it on the road

454
00:17:56,680 --> 00:17:58,570
to outside of Nationwide, you see us here.

455
00:17:58,570 --> 00:18:00,602
We've also got a somebody
over at another conference

456
00:18:00,603 --> 00:18:02,490
talking about ATT&CK.

457
00:18:02,490 --> 00:18:04,250
We're excited about it,
but that was really one

458
00:18:04,250 --> 00:18:06,640
of the things that we
found was very beneficial

459
00:18:06,640 --> 00:18:09,451
for operationalizing this.

460
00:18:09,451 --> 00:18:13,010
So where did we end up
with all this, all of this?

461
00:18:13,010 --> 00:18:14,120
With a lot of work.

462
00:18:14,120 --> 00:18:16,449
So there was a lot of
recommendations that came out

463
00:18:16,450 --> 00:18:17,900
of the work that we did.

464
00:18:17,900 --> 00:18:19,200
We've implemented a lot of those.

465
00:18:19,200 --> 00:18:20,460
We still have a number of projects

466
00:18:20,460 --> 00:18:22,930
that we're working on right
now, but most importantly,

467
00:18:22,930 --> 00:18:26,240
we ended up with a change in our culture.

468
00:18:26,240 --> 00:18:29,810
So, if you had asked me 18
months ago what our culture was

469
00:18:29,810 --> 00:18:30,643
at Nationwide, I'd tell you

470
00:18:30,643 --> 00:18:32,690
it was a compliance-based culture.

471
00:18:32,690 --> 00:18:34,683
We worried about audits, we
worried about regulations.

472
00:18:34,683 --> 00:18:36,184
If you asked me today,

473
00:18:36,184 --> 00:18:38,999
we talk about
intelligence-driven operations.

474
00:18:38,999 --> 00:18:41,420
We focus on what is the
most important threats

475
00:18:41,420 --> 00:18:43,350
to our environment, and we actually go out

476
00:18:43,350 --> 00:18:45,580
and we start making our security,

477
00:18:45,580 --> 00:18:48,169
sure our security controls are covering

478
00:18:48,170 --> 00:18:50,130
against those most likely threats.

479
00:18:50,130 --> 00:18:52,440
That is a huge change,
and that's all because

480
00:18:52,440 --> 00:18:53,730
of what we did with MITRE ATT&CK,

481
00:18:53,730 --> 00:18:55,500
and because we started prioritizing,

482
00:18:55,500 --> 00:18:58,400
'cause we focused our
efforts just on those 91,

483
00:18:58,400 --> 00:19:00,450
just on those threat actors and techniques

484
00:19:00,450 --> 00:19:02,723
that were targeting our network.

485
00:19:04,980 --> 00:19:06,050
So are we done?

486
00:19:06,050 --> 00:19:07,827
No, so we've got a whole
bunch more that we're doing

487
00:19:07,827 --> 00:19:09,140
and I'm gonna show you a few things.

488
00:19:09,140 --> 00:19:12,390
So we, Andy showed you that
chart that we had earlier

489
00:19:12,390 --> 00:19:14,050
that had a whole bunch of threat actors.

490
00:19:14,050 --> 00:19:15,010
That was just a first go.

491
00:19:15,010 --> 00:19:16,430
We've winged it.

492
00:19:16,430 --> 00:19:18,840
I'm not gonna try to lie up here.

493
00:19:18,840 --> 00:19:21,000
We basically just said, hey,
let's just throw this out

494
00:19:21,000 --> 00:19:22,650
and see what happens and what sticks.

495
00:19:22,650 --> 00:19:24,780
So, over the time, we've refined that.

496
00:19:24,780 --> 00:19:26,410
We've gotten down to
a better understanding

497
00:19:26,410 --> 00:19:28,460
of certain threat actors
that are targeting us.

498
00:19:28,460 --> 00:19:30,260
Well, we threw this up
about six months ago.

499
00:19:30,260 --> 00:19:33,090
This specific one, we're
still refining from there,

500
00:19:33,090 --> 00:19:36,020
but we realized that,
obviously, with MITRE coming out

501
00:19:36,020 --> 00:19:38,080
with new techniques, with
threat actors coming out

502
00:19:38,080 --> 00:19:40,360
with new techniques, we always
have to iterate through this,

503
00:19:40,360 --> 00:19:41,639
and we did so.

504
00:19:41,639 --> 00:19:45,640
So we had 19 new techniques
that came out of this.

505
00:19:45,641 --> 00:19:48,980
The time that we updated
this chart, went ahead

506
00:19:48,980 --> 00:19:52,007
and tested those, mitigated
and put in new mitigations

507
00:19:52,007 --> 00:19:55,090
and detections on those, and
we're constantly reviewing that

508
00:19:55,090 --> 00:19:57,379
monthly and a quarterly basis.

509
00:19:57,380 --> 00:20:00,460
We talked earlier about
prioritization of the techniques.

510
00:20:00,460 --> 00:20:02,580
So we've talked about
widespread use as the first way

511
00:20:02,580 --> 00:20:03,413
that we prioritize.

512
00:20:03,413 --> 00:20:06,370
We've gone back and we've
looked at it again and we said,

513
00:20:06,370 --> 00:20:08,406
hey, that not only widespread
use, ease of execution,

514
00:20:08,406 --> 00:20:11,010
how dangerous is it in our environment.

515
00:20:11,010 --> 00:20:12,970
That's led us to a one to 91 ranking

516
00:20:12,970 --> 00:20:15,660
of the techniques in our environment,

517
00:20:15,660 --> 00:20:18,207
and we've added the 19 new
ones that we've done now,

518
00:20:18,207 --> 00:20:19,910
but what this does is this enables us

519
00:20:19,910 --> 00:20:21,140
to have that conversation.

520
00:20:21,140 --> 00:20:22,310
Now I can have a conversation,

521
00:20:22,310 --> 00:20:24,010
if there's two different
projects that need funding

522
00:20:24,010 --> 00:20:26,080
or two different projects
that need resources,

523
00:20:26,080 --> 00:20:28,293
was that project dealing
with one of these top couple

524
00:20:28,293 --> 00:20:32,193
of techniques, or was it
dealing with one that's 89 or 90

525
00:20:32,193 --> 00:20:34,180
on the ranking chart?

526
00:20:34,180 --> 00:20:36,270
I'm sure gonna get the
funding for the top five

527
00:20:36,270 --> 00:20:37,220
than I was before.

528
00:20:37,220 --> 00:20:39,000
This is something that
we didn't have before.

529
00:20:39,000 --> 00:20:41,174
We couldn't have those
conversations, and quite honestly,

530
00:20:41,174 --> 00:20:43,747
we were spending a lot of
time focusing on techniques

531
00:20:43,747 --> 00:20:46,483
that didn't matter to us at Nationwide.

532
00:20:46,483 --> 00:20:48,580
I said, now we actually, every single time

533
00:20:48,580 --> 00:20:51,280
we talk about new projects, we
talk about in prioritization.

534
00:20:51,280 --> 00:20:54,129
Where does that, where does
that rank as far as priority?

535
00:20:55,560 --> 00:20:57,639
- Intelligence driving
security, this is an area

536
00:20:57,640 --> 00:20:59,440
that has me excited the most.

537
00:20:59,440 --> 00:21:03,515
A lot of us receive our news
from intelligence feeds.

538
00:21:03,515 --> 00:21:07,030
It's typically just threat
actors, what they're doing,

539
00:21:07,030 --> 00:21:09,040
maybe some malware,
what's happening there,

540
00:21:09,040 --> 00:21:10,970
and a little story of what happened.

541
00:21:10,970 --> 00:21:14,350
They got into an environment,
the normal stories

542
00:21:14,350 --> 00:21:15,459
that we typically hear.

543
00:21:15,460 --> 00:21:18,370
Here, we're taking that
intelligence and we're combining it

544
00:21:18,370 --> 00:21:22,976
with the ATT&CK framework
to capture a strong message

545
00:21:22,977 --> 00:21:25,140
that goes across our entire organization.

546
00:21:25,140 --> 00:21:28,153
There, the ATT&CK framework
is now a common language.

547
00:21:28,153 --> 00:21:31,349
We'd still have the information
about what the ATT&CK is.

548
00:21:31,349 --> 00:21:34,360
We still maybe include
a visual representation

549
00:21:34,361 --> 00:21:38,040
of how the ATT&CK was
executed, but now, we lay out,

550
00:21:38,040 --> 00:21:41,017
technique by technique, how
that ATT&CK was performed.

551
00:21:41,017 --> 00:21:42,782
This is invaluable.

552
00:21:42,782 --> 00:21:45,679
Here, we have an anatomy
of a breach, an example

553
00:21:45,680 --> 00:21:47,790
of what we try to use, and we hand it off

554
00:21:47,790 --> 00:21:49,560
to one of our security engineers.

555
00:21:49,560 --> 00:21:51,810
Our security engineers,
they know our environment,

556
00:21:51,810 --> 00:21:53,020
they know our security tools,

557
00:21:53,020 --> 00:21:54,530
they know our lines of defense.

558
00:21:54,530 --> 00:21:57,200
Taking in information like
this, intelligence-driven,

559
00:21:57,200 --> 00:21:59,950
and adding MITRE to that,
they can quickly start looking

560
00:21:59,950 --> 00:22:02,130
at where do I need to step in,

561
00:22:02,130 --> 00:22:04,040
where can I implement the kill chain?

562
00:22:04,040 --> 00:22:06,713
And we found that to be a huge success.

563
00:22:09,660 --> 00:22:13,640
So key takeaways, lessons
learned from the first project,

564
00:22:13,640 --> 00:22:16,060
helped drive some of the behaviors

565
00:22:16,060 --> 00:22:18,669
and the success from
project that we took on.

566
00:22:18,670 --> 00:22:20,740
The key one there is focus.

567
00:22:20,740 --> 00:22:22,130
You have to have focus.

568
00:22:22,130 --> 00:22:25,750
Documentation of how we're
gonna do the assessment process

569
00:22:25,750 --> 00:22:29,370
was key and involving
a large team of people.

570
00:22:29,370 --> 00:22:32,060
I know one of our feedback we
heard from the first project

571
00:22:32,060 --> 00:22:34,050
is that, the Attack and
Pen team would go off

572
00:22:34,050 --> 00:22:37,050
and do a finding and throw
that onto our IT organization.

573
00:22:37,050 --> 00:22:39,720
Here in this project, they
were on board day one.

574
00:22:39,720 --> 00:22:41,590
We were engaging them,
we're asking them questions

575
00:22:41,590 --> 00:22:43,350
on how should this attack work?

576
00:22:43,350 --> 00:22:46,030
And we were also spreading the good news

577
00:22:46,030 --> 00:22:47,800
about what ATT&CK can do for them.

578
00:22:47,800 --> 00:22:49,790
So we had, the other key takeaway too

579
00:22:49,790 --> 00:22:51,070
is involved leadership.

580
00:22:51,070 --> 00:22:53,260
When they're onboard on a weekly basis,

581
00:22:53,260 --> 00:22:57,450
and we have quarterly readouts
too of major findings that,

582
00:22:57,450 --> 00:22:59,960
or recommendations we come
up with, but involving them

583
00:22:59,960 --> 00:23:02,913
on a constant basis was invaluable.

584
00:23:03,830 --> 00:23:05,641
- All right, so that's our story.

585
00:23:05,642 --> 00:23:07,640
I think we've got a couple of minutes,

586
00:23:07,640 --> 00:23:09,740
if there's anybody that has any questions.

587
00:23:19,932 --> 00:23:21,040
- Thanks for sharing that.

588
00:23:21,040 --> 00:23:24,430
So as you implemented
these 91 ATT&CK controls,

589
00:23:24,430 --> 00:23:26,130
did you get any other benefits?

590
00:23:26,130 --> 00:23:27,130
Did the red team quit

591
00:23:27,130 --> 00:23:28,800
'cause they couldn't
hack into anything more?

592
00:23:28,800 --> 00:23:30,649
Did you have more visibility in the stock?

593
00:23:30,650 --> 00:23:31,483
Too many alerts?

594
00:23:31,483 --> 00:23:33,560
What were some of the other effects?

595
00:23:33,560 --> 00:23:38,560
- For us, the effects are
just, for a lot of the changes

596
00:23:38,700 --> 00:23:41,430
we had to implement, those
teams are overwhelmed.

597
00:23:41,430 --> 00:23:43,780
They have a lot of news
coming out, a lot of changes

598
00:23:43,780 --> 00:23:45,060
they have to look at dawn.

599
00:23:45,060 --> 00:23:47,970
Here, we're saying, hey, I
need these recommendations done

600
00:23:47,970 --> 00:23:49,632
because we have 27 threat
actors that are operating

601
00:23:49,632 --> 00:23:52,240
in finance insurance sector
that are coming at us,

602
00:23:52,240 --> 00:23:54,330
so help prioritize the
work they need to do.

603
00:23:54,330 --> 00:23:57,270
And it's also wasn't a
one of those audit-driven,

604
00:23:57,270 --> 00:23:59,150
oh, we have a finding,
oh, we gotta solve it.

605
00:23:59,150 --> 00:24:02,190
It's like, hey, this is a
real world type of attack

606
00:24:02,190 --> 00:24:03,280
that's coming at us.

607
00:24:03,280 --> 00:24:05,470
So that helped drive the
behavior and thinking.

608
00:24:05,470 --> 00:24:06,980
Before, they're thinking
like, oh, I gotta go

609
00:24:06,980 --> 00:24:09,600
and implement this in a casual timeframe.

610
00:24:09,600 --> 00:24:11,379
They felt engaged, they
thought they were onboard

611
00:24:11,380 --> 00:24:13,040
in the whole process, so.

612
00:24:13,040 --> 00:24:14,560
- I think that's the most exciting thing

613
00:24:14,560 --> 00:24:17,758
is that people believe
in what they're doing.

614
00:24:17,758 --> 00:24:20,970
They believe in why they
need to make these changes

615
00:24:20,970 --> 00:24:21,803
to the environment.

616
00:24:21,803 --> 00:24:24,870
So, before we did this, we
would get a lot of pushback

617
00:24:24,870 --> 00:24:26,489
from our infrastructure folks.

618
00:24:26,490 --> 00:24:28,910
We're adding work to their workload.

619
00:24:28,910 --> 00:24:31,220
Now we're talking about,
hey, this is an actual threat

620
00:24:31,220 --> 00:24:32,414
to your environment.

621
00:24:32,414 --> 00:24:34,873
It's not just a regulatory piece or audit.

622
00:24:34,873 --> 00:24:37,530
This is an actual threat actor

623
00:24:37,530 --> 00:24:39,134
that is known to target this area,

624
00:24:39,134 --> 00:24:41,640
and we're putting in
controls to stop that.

625
00:24:41,640 --> 00:24:43,213
That tells a much better story for them.

626
00:24:43,213 --> 00:24:44,940
It gives them much more excitement

627
00:24:44,940 --> 00:24:47,693
and reason to act and act quickly.

628
00:24:51,740 --> 00:24:54,330
- It seems like one of your, there we go,

629
00:24:54,330 --> 00:24:57,970
it seems like one of your
successes was filtering

630
00:24:57,970 --> 00:24:59,673
according to industry.

631
00:24:59,673 --> 00:25:01,657
I was wondering if you think

632
00:25:01,657 --> 00:25:05,909
maybe that's something the
community can add to Navigator,

633
00:25:05,910 --> 00:25:09,560
where just like we can break
it down into threat actors,

634
00:25:09,560 --> 00:25:11,541
maybe we could all help gather intel

635
00:25:11,541 --> 00:25:15,790
and break it into industries,
to help others get past

636
00:25:15,790 --> 00:25:18,100
that learning curve maybe.

637
00:25:18,100 --> 00:25:21,367
- Yeah, I'll let MITRE take
that one on for action.

638
00:25:21,367 --> 00:25:22,300
(people laughing)

639
00:25:22,300 --> 00:25:24,810
But I mean, obviously, one
of the biggest concerns

640
00:25:24,810 --> 00:25:29,147
by doing this is there
are 266 now techniques.

641
00:25:29,147 --> 00:25:32,270
What about those other,
I can't do public math,

642
00:25:32,270 --> 00:25:35,110
but 266 minus 91 is a lot.

643
00:25:35,110 --> 00:25:36,870
What are we doing with
all of those techniques?

644
00:25:36,870 --> 00:25:38,979
And so we don't want to do
necessarily is make sure

645
00:25:38,980 --> 00:25:40,560
that we're forgetting
about those other ones,

646
00:25:40,560 --> 00:25:43,480
and that's kind of the
sequel to some of the stuff

647
00:25:43,480 --> 00:25:44,490
we're doing is we're going back

648
00:25:44,490 --> 00:25:46,400
and we're going through some
of those other techniques.

649
00:25:46,400 --> 00:25:48,420
So I wouldn't necessarily,
I'd be a little hesitant

650
00:25:48,420 --> 00:25:53,040
because of the, it gave us
a start, but we still need

651
00:25:53,040 --> 00:25:54,700
to go through some of
the other techniques.

652
00:25:54,700 --> 00:25:57,110
- I'll jump in with my emcee
privilege as the Attack team

653
00:25:57,110 --> 00:25:58,699
and say it's really tough 'cause sometimes

654
00:25:58,700 --> 00:26:01,500
in the opensource reports we
do from the Attack team side,

655
00:26:01,500 --> 00:26:03,150
those industries aren't always identified.

656
00:26:03,150 --> 00:26:05,560
So you're gonna be hearing from
my colleague, John Wonders.

657
00:26:05,560 --> 00:26:06,879
He's gonna talk about an exciting effort

658
00:26:06,880 --> 00:26:08,270
called the attack sightings,

659
00:26:08,270 --> 00:26:10,190
where hopefully we can get
some of that industry data

660
00:26:10,190 --> 00:26:13,670
to do something along the
lines of what you asked about.

661
00:26:13,670 --> 00:26:14,620
All right, so we're at time.

662
00:26:14,620 --> 00:26:16,612
Thank you, Andy and
David, for a great talk.

663
00:26:16,613 --> 00:26:19,863
(audience applauding)

