1
00:00:00,370 --> 00:00:03,330
- Next up, we have a team
from Temple University.

2
00:00:03,330 --> 00:00:04,890
We have Aunshul Rege

3
00:00:04,890 --> 00:00:06,609
Who's an associate professor there along

4
00:00:06,610 --> 00:00:09,090
with PhD student, Rachel Bleiman.

5
00:00:09,090 --> 00:00:10,850
- Great, hi everyone.

6
00:00:10,850 --> 00:00:12,120
My name is Aunshul Rege

7
00:00:12,120 --> 00:00:13,420
I'm an associate professor

8
00:00:13,420 --> 00:00:16,390
with the Department of
Criminal Justice at Temple.

9
00:00:16,390 --> 00:00:17,223
And I'm here today

10
00:00:17,223 --> 00:00:19,730
with my amazing graduate
research assistant,

11
00:00:19,730 --> 00:00:20,690
Rachel Bleiman.

12
00:00:20,690 --> 00:00:22,510
And today we wanna share with you

13
00:00:22,510 --> 00:00:24,270
how we are using PRE-ATT&CK

14
00:00:24,270 --> 00:00:26,870
and ATTA&CK in the social sciences

15
00:00:26,870 --> 00:00:30,420
for cyber security and cyber
crime education and research.

16
00:00:30,420 --> 00:00:33,240
We wanna thank Mitre for the
opportunity to let us share

17
00:00:33,240 --> 00:00:34,860
what we're doing with you all today.

18
00:00:34,860 --> 00:00:36,380
And of course we want

19
00:00:36,380 --> 00:00:39,550
thank our funders National
Science Foundation

20
00:00:40,410 --> 00:00:43,059
because without them we
couldn't do what we're doing.

21
00:00:45,000 --> 00:00:46,870
So on the agenda we're gonna talk about

22
00:00:46,870 --> 00:00:48,400
how we're using PRE-ATT&CK

23
00:00:48,400 --> 00:00:51,330
for cyber crime and security education.

24
00:00:51,330 --> 00:00:53,059
Rachel is then gonna share with you

25
00:00:53,060 --> 00:00:54,460
how we've been using ATT&CK

26
00:00:54,460 --> 00:00:57,140
for some of our research datasets.

27
00:00:57,140 --> 00:00:59,840
And then we're gonna end with a summary

28
00:00:59,840 --> 00:01:03,140
and talk about where we'd
like to go with, you know,

29
00:01:03,140 --> 00:01:05,573
what we're doing in
education and research.

30
00:01:07,180 --> 00:01:10,520
So let's get started with
that first component.

31
00:01:10,520 --> 00:01:14,610
How are we using MITRE
PRE-ATT&CK framework

32
00:01:14,610 --> 00:01:16,780
in security education?

33
00:01:16,780 --> 00:01:20,380
I teach a cybercrime course
in the social sciences.

34
00:01:20,380 --> 00:01:22,710
The emphasis here is on the human aspects

35
00:01:22,710 --> 00:01:24,539
of cyber attacks and security

36
00:01:24,540 --> 00:01:28,710
with an emphasis within
that on social engineering.

37
00:01:28,710 --> 00:01:31,860
The class is composed of students
from multiple disciplines.

38
00:01:31,860 --> 00:01:34,710
So we have not just
social science students

39
00:01:34,710 --> 00:01:38,244
but we also have computer
science and engineering students.

40
00:01:38,244 --> 00:01:41,440
We've got grouped them up in
about eight different groups

41
00:01:41,440 --> 00:01:45,750
that have both social and
computer science students in them.

42
00:01:45,750 --> 00:01:47,890
The objectives of one
of the assignments that

43
00:01:47,890 --> 00:01:52,590
they have is we're trying to
map the PRE-ATT&CK framework

44
00:01:52,590 --> 00:01:55,180
to social engineering case studies

45
00:01:55,180 --> 00:01:59,050
to help students learn how
these frameworks can be used

46
00:01:59,050 --> 00:02:00,550
to conduct threat intelligence

47
00:02:00,550 --> 00:02:02,880
but also to understand the limitations

48
00:02:02,880 --> 00:02:06,283
of both the case studies
and the framework.

49
00:02:06,284 --> 00:02:08,520
So we've got about six social
engineering case studies

50
00:02:08,520 --> 00:02:10,970
with a lot of details

51
00:02:10,970 --> 00:02:14,780
and students will be required
to look at the overall mapping

52
00:02:14,780 --> 00:02:16,427
to the PRE-ATT&CK framework,

53
00:02:16,427 --> 00:02:19,390
the specific action on certain tactics

54
00:02:19,390 --> 00:02:21,339
and techniques that they find

55
00:02:21,340 --> 00:02:24,860
and then identify mitigation
strategies identified

56
00:02:24,860 --> 00:02:27,800
in the framework and
also extend beyond that.

57
00:02:27,800 --> 00:02:29,120
This was our first attempt

58
00:02:29,120 --> 00:02:31,050
this semester to try something like this,

59
00:02:31,050 --> 00:02:33,463
but we're hoping to
learn and grow in this.

60
00:02:38,450 --> 00:02:39,670
So students, like I said,

61
00:02:39,670 --> 00:02:44,149
we're gonna be given six
different case studies

62
00:02:44,150 --> 00:02:46,360
within each study they
would then map it all

63
00:02:46,360 --> 00:02:47,910
to the overall framework

64
00:02:47,910 --> 00:02:50,710
as you can see by the
highlighted boxes here.

65
00:02:50,710 --> 00:02:54,530
So if they find certain
components, they would map it on.

66
00:02:54,530 --> 00:02:57,710
But then the idea here is we want them

67
00:02:57,710 --> 00:03:00,610
to think about things like

68
00:03:00,610 --> 00:03:02,720
what is the proportion of mapping?

69
00:03:02,720 --> 00:03:04,430
How much of the case study were you able

70
00:03:04,430 --> 00:03:07,350
to successfully map onto the framework?

71
00:03:07,350 --> 00:03:11,710
Because in this gets them to
think about the implications.

72
00:03:11,710 --> 00:03:13,610
What does this mean for the case study?

73
00:03:13,610 --> 00:03:16,270
Right? Do we see certain patterns?

74
00:03:16,270 --> 00:03:18,270
Can we identify if certain tactics

75
00:03:18,270 --> 00:03:19,990
and techniques are useful?

76
00:03:19,990 --> 00:03:21,740
And of course then what
are the implications

77
00:03:21,740 --> 00:03:23,600
for PRE-ATT&CK in the sense

78
00:03:23,600 --> 00:03:26,980
that how well does it apply
to social engineering?

79
00:03:26,980 --> 00:03:30,410
Now we're aware that PRE-ATT&CK
is gonna be restructured

80
00:03:30,410 --> 00:03:31,810
and possibly merged with ATT&CK

81
00:03:31,810 --> 00:03:35,260
but this is what we're doing.

82
00:03:35,260 --> 00:03:36,230
In the fall semester,

83
00:03:36,230 --> 00:03:39,433
we'll be adapting this
project moving in the future.

84
00:03:41,740 --> 00:03:44,000
So once they've done this overall mapping

85
00:03:44,000 --> 00:03:48,010
they then have to zoom
into a specific tactic

86
00:03:48,010 --> 00:03:52,850
and try to identify things
along the lines of techniques,

87
00:03:52,850 --> 00:03:56,090
similar techniques that fall
under that tactic to again,

88
00:03:56,090 --> 00:03:59,760
identify relationships,
see if they can come up

89
00:03:59,760 --> 00:04:03,130
with any detection measures as
identified in the framework.

90
00:04:03,130 --> 00:04:05,700
And of course dive into
the difficulty level

91
00:04:05,700 --> 00:04:07,540
for the adversary.

92
00:04:07,540 --> 00:04:10,280
But in addition to this,

93
00:04:10,280 --> 00:04:12,540
we want them to think about mitigation

94
00:04:12,540 --> 00:04:13,730
for social engineering.

95
00:04:13,730 --> 00:04:17,529
So currently, if you look at, you know,

96
00:04:17,529 --> 00:04:20,909
MITRE's ATT&CK website under mitigations

97
00:04:20,910 --> 00:04:23,660
they have mitigations listed
for enterprise and mobile.

98
00:04:24,940 --> 00:04:28,940
And we are trying to get our
students to think about well,

99
00:04:28,940 --> 00:04:30,660
what would something similar look like

100
00:04:30,660 --> 00:04:33,090
for PRE-ATT&CK for social engineering?

101
00:04:33,090 --> 00:04:35,479
What would be those mitigation strategies?

102
00:04:35,480 --> 00:04:38,250
And if none exists,
students are then encouraged

103
00:04:38,250 --> 00:04:39,850
to recommend mitigations.

104
00:04:39,850 --> 00:04:42,990
And these might take the
form of for instance, policy

105
00:04:42,990 --> 00:04:44,850
or training and awareness, right?

106
00:04:44,850 --> 00:04:47,163
Moving beyond that technical domain.

107
00:04:48,870 --> 00:04:52,040
So the overall then objective here is

108
00:04:52,040 --> 00:04:54,580
that students learn about
threat intelligence,

109
00:04:54,580 --> 00:04:58,620
about mapping, about
identifying patterns and trends

110
00:04:58,620 --> 00:05:01,810
and also about mitigation.

111
00:05:01,810 --> 00:05:04,470
So these are efforts
in the education space.

112
00:05:04,470 --> 00:05:06,700
I'm now gonna pass it on
to Rachel to talk about

113
00:05:06,700 --> 00:05:09,880
what we're doing or the datasets.

114
00:05:09,880 --> 00:05:10,713
So Rachel.

115
00:05:11,670 --> 00:05:12,760
- Thanks Aunshul.

116
00:05:14,000 --> 00:05:17,020
So through our cybersecurity
in action research

117
00:05:17,020 --> 00:05:22,020
and education lab website,
which is sites.temple.edu/care

118
00:05:22,060 --> 00:05:25,090
we offer free downloads of
the course projects along

119
00:05:25,090 --> 00:05:27,369
with two datasets that we've created

120
00:05:27,370 --> 00:05:31,530
and we have recently mapped
onto the MITRE ATT&CK Framework.

121
00:05:31,530 --> 00:05:35,450
Both of these data sets are
updated on a monthly basis.

122
00:05:35,450 --> 00:05:38,210
The first data set we
have, is a repository

123
00:05:38,210 --> 00:05:40,440
of social engineering incidents.

124
00:05:40,440 --> 00:05:45,130
We currently have 623
incidents recorded spanning

125
00:05:45,130 --> 00:05:48,890
from 2011 up through August, 2020.

126
00:05:48,890 --> 00:05:50,780
The second dataset consists

127
00:05:50,780 --> 00:05:53,900
of ransomware attacks against
critical infrastructure.

128
00:05:53,900 --> 00:05:57,840
And this dataset has 747 incidents,

129
00:05:57,840 --> 00:06:02,363
ranging from November of 2013
up through September of 2020.

130
00:06:03,260 --> 00:06:04,770
All of the incidents that we gather

131
00:06:04,770 --> 00:06:07,680
for both of these datasets
is completely based

132
00:06:07,680 --> 00:06:09,480
on publicly disclosed information

133
00:06:09,480 --> 00:06:12,220
that we collect from Google alerts.

134
00:06:12,220 --> 00:06:13,480
And a couple of months ago,

135
00:06:13,480 --> 00:06:15,480
we received some feedback from people

136
00:06:15,480 --> 00:06:17,710
who use the ransomware dataset

137
00:06:17,710 --> 00:06:20,690
and they asked if we could map
it onto the attack framework.

138
00:06:20,690 --> 00:06:21,760
So we did that

139
00:06:21,760 --> 00:06:24,620
and we decided to also map
the social engineering dataset

140
00:06:24,620 --> 00:06:25,983
onto the framework as well.

141
00:06:28,950 --> 00:06:31,950
So on the table on the left
here are some of the variables

142
00:06:31,950 --> 00:06:34,659
that we record in the
social engineering dataset,

143
00:06:34,660 --> 00:06:38,440
including dates, who the target
is and where they're located

144
00:06:38,440 --> 00:06:40,860
what social engineering tactic is used.

145
00:06:40,860 --> 00:06:44,490
The monetary cost of the
attack, who the attacker is

146
00:06:44,490 --> 00:06:46,990
and some information about
the ploy of the attack.

147
00:06:48,200 --> 00:06:49,450
About 50%

148
00:06:49,450 --> 00:06:52,800
of the social engineering
tactics in our dataset mapped

149
00:06:52,800 --> 00:06:55,780
onto the attack techniques or software.

150
00:06:55,780 --> 00:06:58,809
The primary techniques we were
able to match we're phishing

151
00:06:58,810 --> 00:07:01,480
and spear phishing, but there
were also some instances

152
00:07:01,480 --> 00:07:04,920
of malware that mapped onto
the software and the framework.

153
00:07:04,920 --> 00:07:07,240
And then we also mapped about 23%

154
00:07:07,240 --> 00:07:11,490
of the attackers onto the
attack group slash attacker.

155
00:07:11,490 --> 00:07:15,210
So group 32 or Lazarus
group appeared several times

156
00:07:15,210 --> 00:07:16,489
and was the most common

157
00:07:16,490 --> 00:07:21,163
while groups 59, 92 and 94
were also repeatedly mapped.

158
00:07:23,290 --> 00:07:26,190
Moving onto the critical
infrastructure ransomware dataset,

159
00:07:26,190 --> 00:07:28,840
our variables record
information about the date

160
00:07:28,840 --> 00:07:31,419
and location of the
attack, who is targeted,

161
00:07:31,420 --> 00:07:33,330
what strain of ransomware is used

162
00:07:33,330 --> 00:07:35,560
and details about the ransom.

163
00:07:35,560 --> 00:07:38,870
And in our transition
from the ninth iteration

164
00:07:38,870 --> 00:07:41,130
to the 10th iteration of the dataset,

165
00:07:41,130 --> 00:07:43,900
we began mapping onto
the ATT&CK framework.

166
00:07:43,900 --> 00:07:47,030
We first removed all incidents
where the strain was recorded

167
00:07:47,030 --> 00:07:50,897
as NotPetya as the ATT&CK
Framework defines NotPetya

168
00:07:50,897 --> 00:07:53,640
as a wiperware and not a ransomware.

169
00:07:53,640 --> 00:07:56,130
We then mapped the
ransomware strain variable

170
00:07:56,130 --> 00:07:59,850
onto the attack software ID about 56%

171
00:07:59,850 --> 00:08:02,490
of the strains mapped
onto the tax software.

172
00:08:02,490 --> 00:08:04,300
And these eight softwares are the ones

173
00:08:04,300 --> 00:08:06,880
that appeared in our dataset repeatedly

174
00:08:06,880 --> 00:08:10,190
and included Maze LockerGoga, NetWalker,

175
00:08:10,190 --> 00:08:14,393
Ragnar Locker, Robinhood,
Ryuk, Sam Sam and WannaCry.

176
00:08:18,040 --> 00:08:19,910
And we did experience some challenges

177
00:08:19,910 --> 00:08:21,280
and found some limitations

178
00:08:21,280 --> 00:08:24,679
with mapping our dataset
onto the attack framework.

179
00:08:24,680 --> 00:08:26,640
In the social engineering dataset,

180
00:08:26,640 --> 00:08:28,770
many of the social engineering tactics

181
00:08:28,770 --> 00:08:31,770
do not currently exist in
the framework such as whaling

182
00:08:31,770 --> 00:08:33,260
and vishing.

183
00:08:33,260 --> 00:08:35,860
And while our mapping results
did show that about half

184
00:08:35,860 --> 00:08:38,350
of the tactics mapped over the bulk

185
00:08:38,350 --> 00:08:40,670
of our incidents in this
dataset are phishing

186
00:08:40,669 --> 00:08:41,900
and spear phishing attacks

187
00:08:41,900 --> 00:08:43,510
which the framework does include

188
00:08:43,510 --> 00:08:46,100
which raised that percentage for us.

189
00:08:46,100 --> 00:08:48,380
We had very few techniques besides vishing

190
00:08:48,380 --> 00:08:50,600
that maps onto the framework.

191
00:08:50,600 --> 00:08:52,480
And in the ransomware dataset,

192
00:08:52,480 --> 00:08:55,170
we were unable to map a
portion of the strains.

193
00:08:55,170 --> 00:08:57,870
Some strains that appear
frequently the datasets such

194
00:08:57,870 --> 00:08:59,930
as revil and has been around

195
00:08:59,930 --> 00:09:04,260
for some time does not does
not yet exist in the framework

196
00:09:04,260 --> 00:09:05,890
and other strains that are newer,

197
00:09:05,890 --> 00:09:08,973
such as ransom X are also
not yet in the framework.

198
00:09:11,570 --> 00:09:12,720
- Great. Thanks Rachel.

199
00:09:12,720 --> 00:09:15,490
So I'm just gonna bring
everything to a close here

200
00:09:15,490 --> 00:09:17,660
and share with you some
of, some of the reasons

201
00:09:17,660 --> 00:09:20,730
why we're using this right
in the education space.

202
00:09:20,730 --> 00:09:23,210
I as an educator
certainly found PRE-ATT&CK

203
00:09:23,210 --> 00:09:25,250
to be extremely useful

204
00:09:25,250 --> 00:09:28,210
because it helps her students
develop the ability to map

205
00:09:28,210 --> 00:09:30,430
and understand threat intelligence

206
00:09:30,430 --> 00:09:33,140
and also the ability to
understand challenges

207
00:09:33,140 --> 00:09:34,380
and limitations.

208
00:09:34,380 --> 00:09:35,830
I think what's really cool is we're trying

209
00:09:35,830 --> 00:09:38,450
to map social engineering cases

210
00:09:38,450 --> 00:09:41,100
which is not typically done.

211
00:09:41,100 --> 00:09:44,350
So I think that's an interesting
exercise in and of itself,

212
00:09:44,350 --> 00:09:46,770
from the social science perspective.

213
00:09:46,770 --> 00:09:48,069
What else will like about this?

214
00:09:48,070 --> 00:09:49,530
Is it isn't technical enough?

215
00:09:49,530 --> 00:09:52,000
So all disciplines can engage.

216
00:09:52,000 --> 00:09:53,430
I have a lot of social science students

217
00:09:53,430 --> 00:09:55,120
who can actually participate in this

218
00:09:55,120 --> 00:09:58,480
and get a top level understanding
of threat intelligence.

219
00:09:58,480 --> 00:10:02,210
So I think that this is a
really, really cool exercise

220
00:10:02,210 --> 00:10:06,380
for my students to try out
from a dataset perspective.

221
00:10:06,380 --> 00:10:09,210
Interestingly, when
Rachel and I started this,

222
00:10:09,210 --> 00:10:11,460
we were struggling to get data because

223
00:10:11,460 --> 00:10:14,040
for obvious reasons,
companies don't wanna share it

224
00:10:14,040 --> 00:10:15,380
or government doesn't wanna share it.

225
00:10:15,380 --> 00:10:18,090
So we said, you know what,
let's create our own dataset

226
00:10:18,090 --> 00:10:21,410
and we'll share it with other
folks in the academic domain.

227
00:10:21,410 --> 00:10:22,949
And so we've had a lot of educators

228
00:10:22,950 --> 00:10:27,560
and students of course request
this data which was great

229
00:10:27,560 --> 00:10:32,560
because it it's allowed us to
fulfill sort of our objective

230
00:10:32,730 --> 00:10:35,290
of sharing this with the
wider academic community.

231
00:10:35,290 --> 00:10:37,880
But interestingly we got a lot
of requests from governments,

232
00:10:37,880 --> 00:10:40,170
not just in the US but around the world

233
00:10:40,170 --> 00:10:42,709
and also industry from all over the world

234
00:10:42,710 --> 00:10:46,100
that was interested in, in
getting a copy of our dataset,

235
00:10:46,100 --> 00:10:48,410
said, hey, let's, you know,
see if we can look at trends

236
00:10:48,410 --> 00:10:51,350
and patterns across ransomware strains,

237
00:10:51,350 --> 00:10:54,300
comparing the data to
their own internal datasets

238
00:10:54,300 --> 00:10:56,329
or raising awareness and for training.

239
00:10:56,330 --> 00:10:59,500
And what was really cool is mapping it

240
00:10:59,500 --> 00:11:03,470
onto MITRE really really improve
the quality of our dataset.

241
00:11:03,470 --> 00:11:07,130
It gave our data set a lot of
credibility, and we got a lot

242
00:11:07,130 --> 00:11:09,450
of responses saying, thank
you for mapping this.

243
00:11:09,450 --> 00:11:11,333
This is gonna help us out big time.

244
00:11:12,890 --> 00:11:14,890
So that is,

245
00:11:14,890 --> 00:11:16,410
ah you know,

246
00:11:16,410 --> 00:11:18,689
the really cool thing is
it was after we mapped it

247
00:11:18,690 --> 00:11:21,160
onto the MITRE Framework we actually got,

248
00:11:21,160 --> 00:11:24,089
the dataset was actually
picked up by a Security Week

249
00:11:24,090 --> 00:11:25,840
and also mentioned,

250
00:11:25,840 --> 00:11:27,740
our lab was mentioned in Bleeping Computer

251
00:11:27,740 --> 00:11:29,670
which was again, another big win for us.

252
00:11:29,670 --> 00:11:32,670
Cause we're a team of trying
to do something like this.

253
00:11:32,670 --> 00:11:35,589
And it's lovely to see that our
efforts are having an impact

254
00:11:35,590 --> 00:11:37,340
and benefiting the wider community.

255
00:11:39,400 --> 00:11:41,850
So one of the things that we wanna do is,

256
00:11:41,850 --> 00:11:44,670
like I said we're aware that
PRE-ATT&XK and ATT&CK are going

257
00:11:44,670 --> 00:11:47,199
to be restructured merging.

258
00:11:47,200 --> 00:11:49,720
And I know that PRE-ATTACK and ATT&CK

259
00:11:49,720 --> 00:11:52,180
has helped me in the social science space,

260
00:11:52,180 --> 00:11:55,010
right helped me with my
education and research efforts.

261
00:11:55,010 --> 00:11:56,790
But I would love to do, is to see

262
00:11:56,790 --> 00:12:00,660
how we in the social science
domain, through our education

263
00:12:00,660 --> 00:12:02,790
and research efforts can contribute back

264
00:12:02,790 --> 00:12:04,020
to PRE-ATT&CK and ATT&CK

265
00:12:04,020 --> 00:12:06,600
And this is what our
previous speaker mentioned

266
00:12:06,600 --> 00:12:09,590
as well as how can we be a contributing?

267
00:12:09,590 --> 00:12:12,290
We're trying to create data repositories.

268
00:12:12,290 --> 00:12:15,890
I remember, you know,
where do we go to get data?

269
00:12:15,890 --> 00:12:17,689
Right. So we're looking at indictments,

270
00:12:17,690 --> 00:12:20,870
we're looking at social
engineering case studies.

271
00:12:20,870 --> 00:12:23,210
We can conduct focus groups and interviews

272
00:12:23,210 --> 00:12:24,800
with social engineers.

273
00:12:24,800 --> 00:12:26,689
And we're also trying to weave it into

274
00:12:26,690 --> 00:12:29,110
what we've best started at Temple is a

275
00:12:29,110 --> 00:12:33,450
Collegiate Social Engineering
Capture the Flag competition

276
00:12:33,450 --> 00:12:34,360
and training event.

277
00:12:34,360 --> 00:12:39,360
So can we use MITRE ATT&CK
Frameworks to sort of shape

278
00:12:39,970 --> 00:12:43,960
that exercise and in turn
use student experiences

279
00:12:43,960 --> 00:12:46,820
to then contribute back to this framework.

280
00:12:46,820 --> 00:12:48,490
So if anyone's interested in any of this,

281
00:12:48,490 --> 00:12:50,920
we are definitely seeking collaboration.

282
00:12:50,920 --> 00:12:53,660
We'd love to hear not just
from academic communities

283
00:12:53,660 --> 00:12:57,199
but also from industry and
government and of course MITRE.

284
00:12:57,200 --> 00:12:59,430
So that's everything that I had.

285
00:12:59,430 --> 00:13:01,630
We can I guess, take it up for questions

286
00:13:02,730 --> 00:13:03,563
- Fantastic talk.

287
00:13:03,563 --> 00:13:05,370
And like people are going
nuts over this data set.

288
00:13:05,370 --> 00:13:07,050
And like I said, I love that
you touch at the end at like

289
00:13:07,050 --> 00:13:09,540
how it was truly a
grassroots effort to like,

290
00:13:09,540 --> 00:13:11,790
you know, compile that
and build it yourself.

291
00:13:11,790 --> 00:13:14,030
I think the biggest
question is like you said,

292
00:13:14,030 --> 00:13:16,510
I love the idea of, like I said no matter

293
00:13:16,510 --> 00:13:18,140
how technical things are it's all,

294
00:13:18,140 --> 00:13:19,510
there's a human element to all this work.

295
00:13:19,510 --> 00:13:20,930
My biggest question is you know,

296
00:13:20,930 --> 00:13:23,880
have you seen themes in
terms of the mitigations

297
00:13:23,880 --> 00:13:24,950
that your students are putting together

298
00:13:24,950 --> 00:13:26,870
for these attacks that you can share

299
00:13:26,870 --> 00:13:27,740
with the wider community,

300
00:13:27,740 --> 00:13:29,480
the things that we can do to kind of

301
00:13:29,480 --> 00:13:31,600
you know, prevent, or at least mitigate

302
00:13:31,600 --> 00:13:36,440
to some degree, these layer
eight human-based behaviors?

303
00:13:36,440 --> 00:13:37,273
- Yeah.

304
00:13:37,273 --> 00:13:39,017
Yeah and that's a great question.

305
00:13:39,017 --> 00:13:42,630
And you know, I'm gonna respond,
respond in two parts here.

306
00:13:42,630 --> 00:13:47,000
I guess, one is it's primarily
been policy, you know,

307
00:13:47,000 --> 00:13:49,930
appropriate behavior, what to
click on what not to click on.

308
00:13:49,930 --> 00:13:52,949
So a bit more on the education
and training aspects of this.

309
00:13:52,950 --> 00:13:56,150
But I love that because it's
a multidisciplinary class,

310
00:13:56,150 --> 00:13:57,569
you're getting computer scientists

311
00:13:57,570 --> 00:13:58,723
who really think about this.

312
00:13:58,723 --> 00:14:00,540
This is the next generation of workforce

313
00:14:00,540 --> 00:14:02,569
of computer scientists who
are gonna be developers

314
00:14:02,570 --> 00:14:03,760
and defenders.

315
00:14:03,760 --> 00:14:06,300
And so thinking about
using these frameworks,

316
00:14:06,300 --> 00:14:08,760
not just in the technical aspect,

317
00:14:08,760 --> 00:14:11,650
but also on the human domain, right,

318
00:14:11,650 --> 00:14:14,850
that for, I think it's really
getting them to think about

319
00:14:14,850 --> 00:14:17,420
that as they go out and
design and defense systems.

320
00:14:17,420 --> 00:14:19,569
So that's, I know it's impossible

321
00:14:19,570 --> 00:14:22,979
to really give your and your question a,

322
00:14:22,979 --> 00:14:24,670
an effective response in
the short time we have

323
00:14:24,670 --> 00:14:28,030
but I'm happy to carry on that
conversation in this life.

324
00:14:28,030 --> 00:14:28,880
- That makes a lot of sense.

325
00:14:28,880 --> 00:14:30,790
Like you said, you can
only build a wall so strong

326
00:14:30,790 --> 00:14:32,880
if someone's just gonna open
the door, what's the point

327
00:14:32,880 --> 00:14:34,040
but yeah, with that, thank you.

328
00:14:34,040 --> 00:14:35,240
Thanks again for a great presentation.

329
00:14:35,240 --> 00:14:36,073
That was really excellent.

330
00:14:36,073 --> 00:14:37,890
Except there's a lot of
slack activity going on.

331
00:14:37,890 --> 00:14:39,330
So definitely hang around
and ask some questions,

332
00:14:39,330 --> 00:14:40,830
but--
- Great. Thank you all.

