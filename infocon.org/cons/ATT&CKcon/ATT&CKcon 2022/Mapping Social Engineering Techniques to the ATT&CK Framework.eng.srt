1
00:00:12,000 --> 00:00:14,160
but to kick off our first talk of the

2
00:00:14,160 --> 00:00:15,519
session

3
00:00:15,519 --> 00:00:17,039
from temple university we're going to

4
00:00:17,039 --> 00:00:19,600
have professor anshul reggae couture

5
00:00:19,600 --> 00:00:22,800
williams and rachel blayman

6
00:00:22,800 --> 00:00:24,800
matt talked about leveraging attack for

7
00:00:24,800 --> 00:00:27,039
insider threat professor reggae's team

8
00:00:27,039 --> 00:00:29,039
has been putting attack to another

9
00:00:29,039 --> 00:00:31,760
unique use with social engineering

10
00:00:31,760 --> 00:00:33,200
since entrepreneur rachel spoke at

11
00:00:33,200 --> 00:00:36,000
attack on power hour we've kept in touch

12
00:00:36,000 --> 00:00:39,360
working most of my co-mc jamie williams

13
00:00:39,360 --> 00:00:41,360
so i'm really excited for them to share

14
00:00:41,360 --> 00:00:43,440
the unique way that they've been using

15
00:00:43,440 --> 00:00:45,600
attack in the classroom so please

16
00:00:45,600 --> 00:00:47,760
welcome to the stage anchor couture and

17
00:00:47,760 --> 00:00:50,160
rachel

18
00:00:51,890 --> 00:00:53,840
[Applause]

19
00:00:53,840 --> 00:00:58,760
the slider note it's the big green arrow

20
00:00:59,840 --> 00:01:01,840
so hello everyone

21
00:01:01,840 --> 00:01:04,239
um my name is couture williams and i am

22
00:01:04,239 --> 00:01:06,320
here on behalf of the care lab to

23
00:01:06,320 --> 00:01:09,520
introduce our paper or our presentation

24
00:01:09,520 --> 00:01:12,000
sorry so i'm in academic mode

25
00:01:12,000 --> 00:01:13,760
exploring how students map social

26
00:01:13,760 --> 00:01:16,000
engineering techniques to the attack

27
00:01:16,000 --> 00:01:18,000
framework during a real-time cyber

28
00:01:18,000 --> 00:01:21,119
security exercise

29
00:01:21,360 --> 00:01:22,960
um and before i begin i just want to

30
00:01:22,960 --> 00:01:25,119
introduce the lab and ourselves and tell

31
00:01:25,119 --> 00:01:26,320
you a little bit about what it is that

32
00:01:26,320 --> 00:01:29,119
we do um as i said i'm katura so i'm a

33
00:01:29,119 --> 00:01:31,360
graduate student and a graduate research

34
00:01:31,360 --> 00:01:33,360
assistant in the care lab um there's

35
00:01:33,360 --> 00:01:36,079
rachel blymon to my left and dr anchor

36
00:01:36,079 --> 00:01:38,960
reggae the head of the lab to my right

37
00:01:38,960 --> 00:01:41,200
we are a part of the nsf-funded

38
00:01:41,200 --> 00:01:44,159
woman-led cybersecurity research lab

39
00:01:44,159 --> 00:01:46,000
with a that has a human and

40
00:01:46,000 --> 00:01:48,560
socio-behavioral focus um each of us

41
00:01:48,560 --> 00:01:50,000
sort of specializes in something

42
00:01:50,000 --> 00:01:52,079
different but broadly the lab is

43
00:01:52,079 --> 00:01:54,000
interested in critical infrastructure

44
00:01:54,000 --> 00:01:56,240
ransomware surveillance and privacy

45
00:01:56,240 --> 00:01:58,640
social engineering and cyber security

46
00:01:58,640 --> 00:02:01,280
education

47
00:02:01,759 --> 00:02:04,079
so i just want to transition into you

48
00:02:04,079 --> 00:02:05,840
know talking about our presentation and

49
00:02:05,840 --> 00:02:07,840
give you a quick overview of what social

50
00:02:07,840 --> 00:02:09,119
engineering is

51
00:02:09,119 --> 00:02:12,560
social engineering is defined as any act

52
00:02:12,560 --> 00:02:14,480
that influences a person

53
00:02:14,480 --> 00:02:17,520
to speak reveal information or act in a

54
00:02:17,520 --> 00:02:19,520
way that may or may not be in their best

55
00:02:19,520 --> 00:02:23,120
interest in 2017 it was reported that

56
00:02:23,120 --> 00:02:26,400
about 70 of us organizations experienced

57
00:02:26,400 --> 00:02:29,680
some form of a social engineering attack

58
00:02:29,680 --> 00:02:32,160
and it took around 20 days for those

59
00:02:32,160 --> 00:02:34,560
organizations to resolve these incidents

60
00:02:34,560 --> 00:02:37,280
and as we know from the amount of vision

61
00:02:37,280 --> 00:02:38,800
calls we've received about car

62
00:02:38,800 --> 00:02:40,720
warranties and the prevalence of

63
00:02:40,720 --> 00:02:42,640
ransomware attacks we know that these

64
00:02:42,640 --> 00:02:44,160
social engineering attacks are still

65
00:02:44,160 --> 00:02:45,920
happening and the rate that they're

66
00:02:45,920 --> 00:02:48,080
happening has probably increased

67
00:02:48,080 --> 00:02:52,080
um the financial loss from these attacks

68
00:02:52,080 --> 00:02:54,560
has been told between business email

69
00:02:54,560 --> 00:02:57,120
compromise and romance scams and

70
00:02:57,120 --> 00:02:59,200
phishing attacks has totaled

71
00:02:59,200 --> 00:03:01,120
about 2.23

72
00:03:01,120 --> 00:03:03,200
billion dollars

73
00:03:03,200 --> 00:03:05,200
so given the prevalence of these attacks

74
00:03:05,200 --> 00:03:08,000
and how financially costly they are

75
00:03:08,000 --> 00:03:09,360
it's obvious that we need to start

76
00:03:09,360 --> 00:03:11,360
focusing on social engineering as a

77
00:03:11,360 --> 00:03:15,280
means of addressing cyber security

78
00:03:15,280 --> 00:03:18,239
so we know that the human factor is the

79
00:03:18,239 --> 00:03:21,040
most leveraged part of cyber security

80
00:03:21,040 --> 00:03:22,879
attacks especially through social

81
00:03:22,879 --> 00:03:26,080
engineering but the field has neglected

82
00:03:26,080 --> 00:03:27,920
social engineering and is instead

83
00:03:27,920 --> 00:03:30,319
focusing very heavily on bolstering

84
00:03:30,319 --> 00:03:32,959
technical skills as a means of

85
00:03:32,959 --> 00:03:35,280
providing cyber security

86
00:03:35,280 --> 00:03:37,840
and while that's great

87
00:03:37,840 --> 00:03:39,760
it leaves a big hole

88
00:03:39,760 --> 00:03:41,280
and

89
00:03:41,280 --> 00:03:43,280
we know that there is a upcoming

90
00:03:43,280 --> 00:03:45,120
workforce not an upcoming but there is a

91
00:03:45,120 --> 00:03:46,640
workforce shortage

92
00:03:46,640 --> 00:03:49,519
of about 2.7 million cybersecurity

93
00:03:49,519 --> 00:03:51,519
professionals and if the field would

94
00:03:51,519 --> 00:03:54,159
just transition to focusing or putting

95
00:03:54,159 --> 00:03:56,640
some effort into discussing social

96
00:03:56,640 --> 00:03:59,120
engineering and embracing it you could

97
00:03:59,120 --> 00:04:01,040
pull people from different disciplines

98
00:04:01,040 --> 00:04:03,840
into cyber security make the field a bit

99
00:04:03,840 --> 00:04:05,680
more holistic instead of just centered

100
00:04:05,680 --> 00:04:08,080
on technical aspects and then you could

101
00:04:08,080 --> 00:04:10,000
start to fill these gaps

102
00:04:10,000 --> 00:04:12,000
in the workforce so this is where we

103
00:04:12,000 --> 00:04:13,439
come in

104
00:04:13,439 --> 00:04:15,760
one of the things that we do is provide

105
00:04:15,760 --> 00:04:18,238
social engineering education both to

106
00:04:18,238 --> 00:04:21,199
students and educators and we do this

107
00:04:21,199 --> 00:04:23,440
through live capture the flag

108
00:04:23,440 --> 00:04:26,000
social engineering competitions as well

109
00:04:26,000 --> 00:04:29,440
as dr reggae implementing um

110
00:04:29,440 --> 00:04:31,759
course exercises centered around social

111
00:04:31,759 --> 00:04:34,000
engineering in her class and as a part

112
00:04:34,000 --> 00:04:36,639
of that we also have either competition

113
00:04:36,639 --> 00:04:38,720
participants or her students

114
00:04:38,720 --> 00:04:41,600
map their strategies and their tactics

115
00:04:41,600 --> 00:04:43,919
onto the mitre framework

116
00:04:43,919 --> 00:04:46,240
and so my colleague rachel is here to

117
00:04:46,240 --> 00:04:47,440
introduce

118
00:04:47,440 --> 00:04:49,600
one of those uh social engineering class

119
00:04:49,600 --> 00:04:51,199
activities that undergraduate students

120
00:04:51,199 --> 00:04:54,240
participated in all right thanks couture

121
00:04:54,240 --> 00:04:56,800
so one of the ways that we are trying to

122
00:04:56,800 --> 00:04:57,520
get

123
00:04:57,520 --> 00:04:59,680
non-technical students to be awesome to

124
00:04:59,680 --> 00:05:02,560
also be involved in cyber security is

125
00:05:02,560 --> 00:05:04,960
through a course project in an

126
00:05:04,960 --> 00:05:07,120
undergraduate criminal justice cyber

127
00:05:07,120 --> 00:05:09,759
crime class and in this class one of the

128
00:05:09,759 --> 00:05:12,000
projects involves groups of students

129
00:05:12,000 --> 00:05:14,639
reading a social engineering case study

130
00:05:14,639 --> 00:05:17,039
and mapping the adversarial behavior

131
00:05:17,039 --> 00:05:19,039
that they find in that case study onto

132
00:05:19,039 --> 00:05:21,280
the attack framework and for the

133
00:05:21,280 --> 00:05:23,280
purposes of this presentation be going

134
00:05:23,280 --> 00:05:25,440
over two requirements of this course

135
00:05:25,440 --> 00:05:27,120
project and we'll compare some of the

136
00:05:27,120 --> 00:05:29,600
results between groups who read the same

137
00:05:29,600 --> 00:05:31,759
exact case study so one of the

138
00:05:31,759 --> 00:05:33,919
requirements that the groups had to do

139
00:05:33,919 --> 00:05:36,320
for this project was to first identify

140
00:05:36,320 --> 00:05:38,479
the tactics techniques and sub

141
00:05:38,479 --> 00:05:40,880
techniques that they found in the case

142
00:05:40,880 --> 00:05:42,240
study and for each one that they

143
00:05:42,240 --> 00:05:45,360
identified they had to find a quote from

144
00:05:45,360 --> 00:05:47,199
the text as evidence to support their

145
00:05:47,199 --> 00:05:48,720
mapping

146
00:05:48,720 --> 00:05:50,560
in the second part of this project the

147
00:05:50,560 --> 00:05:53,280
students had to calculate the

148
00:05:53,280 --> 00:05:56,240
proportions of each tactic that were

149
00:05:56,240 --> 00:05:59,520
present in the case study

150
00:06:00,880 --> 00:06:02,639
okay so in this picture on the bottom

151
00:06:02,639 --> 00:06:05,120
here is just one example of one of the

152
00:06:05,120 --> 00:06:07,759
group's mappings uh you can see that on

153
00:06:07,759 --> 00:06:10,000
the left reconnaissance had a pretty

154
00:06:10,000 --> 00:06:11,600
strong mapping which makes sense to go

155
00:06:11,600 --> 00:06:13,919
along with social engineering

156
00:06:13,919 --> 00:06:16,400
but there were mappings from techniques

157
00:06:16,400 --> 00:06:18,479
um other than reconnaissance as well and

158
00:06:18,479 --> 00:06:20,400
there are some techniques some tactics

159
00:06:20,400 --> 00:06:22,319
that weren't mapped to at all in this

160
00:06:22,319 --> 00:06:23,840
group at least

161
00:06:23,840 --> 00:06:26,080
i also have an example here of one of

162
00:06:26,080 --> 00:06:28,400
the quotes that the groups pulled out as

163
00:06:28,400 --> 00:06:30,960
evidence to support their mapping to

164
00:06:30,960 --> 00:06:32,880
gather victim identity information

165
00:06:32,880 --> 00:06:35,600
technique which is under reconnaissance

166
00:06:35,600 --> 00:06:37,440
and the technique that or the quote that

167
00:06:37,440 --> 00:06:39,039
they pulled out

168
00:06:39,039 --> 00:06:41,360
was that tim who was the social engineer

169
00:06:41,360 --> 00:06:42,479
they were reading about in their case

170
00:06:42,479 --> 00:06:44,720
study went full for collecting

171
00:06:44,720 --> 00:06:46,479
information such as the email layout

172
00:06:46,479 --> 00:06:48,960
scheme open requests for quotes all

173
00:06:48,960 --> 00:06:51,280
employee names he could find any social

174
00:06:51,280 --> 00:06:53,199
media sites papers they wrote or

175
00:06:53,199 --> 00:06:55,680
published clubs they were part of and

176
00:06:55,680 --> 00:06:57,759
service providers they used so this is

177
00:06:57,759 --> 00:07:00,800
just one example of being able to prove

178
00:07:00,800 --> 00:07:02,960
that the technique was in their case

179
00:07:02,960 --> 00:07:06,880
study and to support their mapping

180
00:07:07,759 --> 00:07:09,599
okay so now this looks at three groups

181
00:07:09,599 --> 00:07:11,360
who are each assigned the same case

182
00:07:11,360 --> 00:07:12,400
study

183
00:07:12,400 --> 00:07:15,360
and we can see here which tactics were

184
00:07:15,360 --> 00:07:17,440
mapped more frequently so

185
00:07:17,440 --> 00:07:19,680
first was reconnaissance all the groups

186
00:07:19,680 --> 00:07:21,440
had a pretty strong mapping for this

187
00:07:21,440 --> 00:07:23,520
tactic but we also saw some pretty

188
00:07:23,520 --> 00:07:27,120
strong mappings for initial access

189
00:07:27,120 --> 00:07:30,240
collection and exfiltration meanwhile

190
00:07:30,240 --> 00:07:32,720
other tactics weren't really mapped too

191
00:07:32,720 --> 00:07:34,560
much at all for example privilege

192
00:07:34,560 --> 00:07:36,960
escalation only had a couple

193
00:07:36,960 --> 00:07:38,560
as well as

194
00:07:38,560 --> 00:07:40,560
impact

195
00:07:40,560 --> 00:07:41,919
and it's also interesting if you look at

196
00:07:41,919 --> 00:07:43,039
the bottom

197
00:07:43,039 --> 00:07:45,759
where the total row is you can see that

198
00:07:45,759 --> 00:07:47,199
even though all of these groups were

199
00:07:47,199 --> 00:07:49,440
reading the same case study some mapped

200
00:07:49,440 --> 00:07:51,199
many more techniques than others for

201
00:07:51,199 --> 00:07:53,759
example group a mapped 44 techniques

202
00:07:53,759 --> 00:07:56,319
while group b only mapped 16. so some

203
00:07:56,319 --> 00:07:58,639
groups were much more restricted with

204
00:07:58,639 --> 00:07:59,919
what they identified and what they

205
00:07:59,919 --> 00:08:01,919
mapped while others were able to kind of

206
00:08:01,919 --> 00:08:04,479
interpret um techniques which we'll get

207
00:08:04,479 --> 00:08:06,080
into um

208
00:08:06,080 --> 00:08:07,759
in this next slide so this is leading

209
00:08:07,759 --> 00:08:09,919
into our lessons learned from

210
00:08:09,919 --> 00:08:12,720
implementing this course project so the

211
00:08:12,720 --> 00:08:14,800
first lesson learned was that there's

212
00:08:14,800 --> 00:08:17,039
not really a wrong way to map onto the

213
00:08:17,039 --> 00:08:19,440
framework

214
00:08:19,440 --> 00:08:21,440
each of these groups read the same case

215
00:08:21,440 --> 00:08:23,199
study but they mapped it very

216
00:08:23,199 --> 00:08:25,440
differently and each group was able to

217
00:08:25,440 --> 00:08:27,520
provide quotes from the text to support

218
00:08:27,520 --> 00:08:29,599
their mapping

219
00:08:29,599 --> 00:08:32,000
and this leads us into our second lesson

220
00:08:32,000 --> 00:08:34,159
learned which was that the tactics and

221
00:08:34,159 --> 00:08:36,559
techniques can be interpreted to fit

222
00:08:36,559 --> 00:08:38,559
more into a social engineering mindset

223
00:08:38,559 --> 00:08:41,200
in social engineering behavior so for

224
00:08:41,200 --> 00:08:43,440
example one group mapped to the

225
00:08:43,440 --> 00:08:45,920
technique of trusted relationship and

226
00:08:45,920 --> 00:08:49,120
while on the attack framework website

227
00:08:49,120 --> 00:08:50,880
the definition is more on the technical

228
00:08:50,880 --> 00:08:52,000
side

229
00:08:52,000 --> 00:08:54,560
the quote that this group pulled out was

230
00:08:54,560 --> 00:08:55,360
that

231
00:08:55,360 --> 00:08:56,800
at this point a little friendly chit

232
00:08:56,800 --> 00:08:58,640
chat ensued and before you know it they

233
00:08:58,640 --> 00:08:59,760
were laughing and exchanging

234
00:08:59,760 --> 00:09:02,160
pleasantries um so this is a way that

235
00:09:02,160 --> 00:09:03,839
they were able to interpret this trusted

236
00:09:03,839 --> 00:09:05,839
relationship to fit into that social

237
00:09:05,839 --> 00:09:08,640
engineering behavior

238
00:09:08,640 --> 00:09:10,800
and the last lesson learned is more of

239
00:09:10,800 --> 00:09:12,240
an affirmation that social engineering

240
00:09:12,240 --> 00:09:14,880
is relevant to both attack and in cyber

241
00:09:14,880 --> 00:09:17,040
security we saw that it was very

242
00:09:17,040 --> 00:09:19,360
relevant in the reconnaissance stage but

243
00:09:19,360 --> 00:09:20,720
these social engineering behaviors were

244
00:09:20,720 --> 00:09:22,800
mapped throughout and it's mapped to

245
00:09:22,800 --> 00:09:25,360
behavior that is also used in technical

246
00:09:25,360 --> 00:09:26,560
attacks

247
00:09:26,560 --> 00:09:29,120
and these technical measures overlap

248
00:09:29,120 --> 00:09:30,880
with the social engineering measures in

249
00:09:30,880 --> 00:09:32,959
any attack as well

250
00:09:32,959 --> 00:09:35,120
i'm now going to transition it back to

251
00:09:35,120 --> 00:09:37,360
katura we'll talk a bit more about the

252
00:09:37,360 --> 00:09:40,240
competition setting now okay so in the

253
00:09:40,240 --> 00:09:42,800
summer of 2021 the care lab

254
00:09:42,800 --> 00:09:45,519
hosted a social engineering ctf

255
00:09:45,519 --> 00:09:48,399
competition where teams were essentially

256
00:09:48,399 --> 00:09:52,000
hired by us to test the lab um

257
00:09:52,000 --> 00:09:54,160
and see how good our

258
00:09:54,160 --> 00:09:58,240
security was i'm in total we had 19 16

259
00:09:58,240 --> 00:10:00,480
teams i'm sorry one high school team

260
00:10:00,480 --> 00:10:03,200
nine undergrad and six grads and two

261
00:10:03,200 --> 00:10:04,720
international two of those teams were

262
00:10:04,720 --> 00:10:05,839
international

263
00:10:05,839 --> 00:10:07,440
so what they needed to do in the midst

264
00:10:07,440 --> 00:10:08,880
of this competition was essentially

265
00:10:08,880 --> 00:10:10,320
capture a series of flags which you can

266
00:10:10,320 --> 00:10:12,720
see on the screen they had to convince

267
00:10:12,720 --> 00:10:14,880
us to retweet a tweet from them

268
00:10:14,880 --> 00:10:16,720
or try and get some information on our

269
00:10:16,720 --> 00:10:19,360
mail client our office location

270
00:10:19,360 --> 00:10:22,160
get us to alter the web page and each of

271
00:10:22,160 --> 00:10:26,880
these flags had different point values

272
00:10:27,440 --> 00:10:29,040
an additional part of the competition

273
00:10:29,040 --> 00:10:30,480
was that they had to put together a

274
00:10:30,480 --> 00:10:32,560
formal pen test report

275
00:10:32,560 --> 00:10:34,399
and in that pentest report they needed

276
00:10:34,399 --> 00:10:36,880
to detail both their pretext and their

277
00:10:36,880 --> 00:10:39,040
strategies but they also needed to

278
00:10:39,040 --> 00:10:41,040
develop a playbook where they needed to

279
00:10:41,040 --> 00:10:43,920
map the entire strategy onto the mitre

280
00:10:43,920 --> 00:10:45,200
framework

281
00:10:45,200 --> 00:10:47,279
and here we have an example playbook

282
00:10:47,279 --> 00:10:49,760
under this example the student was

283
00:10:49,760 --> 00:10:51,600
trying to get information was trying to

284
00:10:51,600 --> 00:10:53,839
get our office phone number and they

285
00:10:53,839 --> 00:10:57,519
impersonated a microsoft employee and

286
00:10:57,519 --> 00:10:59,680
told us that at the end like could they

287
00:10:59,680 --> 00:11:01,440
have our phone number in case we got

288
00:11:01,440 --> 00:11:04,399
disconnected so as you can see they put

289
00:11:04,399 --> 00:11:06,880
up their they mapped their strategy on

290
00:11:06,880 --> 00:11:09,040
here starting with the osam procedure

291
00:11:09,040 --> 00:11:10,800
where they needed to gather information

292
00:11:10,800 --> 00:11:14,399
from us or information on us either

293
00:11:14,399 --> 00:11:15,760
through searching

294
00:11:15,760 --> 00:11:17,920
our twitters and our

295
00:11:17,920 --> 00:11:19,920
emails and our resumes

296
00:11:19,920 --> 00:11:22,079
and then just doing uh ocean on the

297
00:11:22,079 --> 00:11:24,079
university as a whole they then

298
00:11:24,079 --> 00:11:26,560
transition into building their pretext

299
00:11:26,560 --> 00:11:28,959
and their persona establishing a

300
00:11:28,959 --> 00:11:30,399
trusting relationship with us

301
00:11:30,399 --> 00:11:32,079
masquerading as the

302
00:11:32,079 --> 00:11:34,480
microsoft employee establishing an

303
00:11:34,480 --> 00:11:36,399
account as a microsoft employee and then

304
00:11:36,399 --> 00:11:38,320
phishing for the information and then

305
00:11:38,320 --> 00:11:40,640
they ended with asking us for the phone

306
00:11:40,640 --> 00:11:42,880
number in case we got disconnected again

307
00:11:42,880 --> 00:11:44,959
playing off of their trusty relationship

308
00:11:44,959 --> 00:11:46,880
that they had established with us

309
00:11:46,880 --> 00:11:49,120
um and then also that microsoft is a

310
00:11:49,120 --> 00:11:50,800
reputable company so we probably

311
00:11:50,800 --> 00:11:52,320
wouldn't question them wanting our phone

312
00:11:52,320 --> 00:11:54,959
number in general and then fishing for

313
00:11:54,959 --> 00:11:56,480
that information

314
00:11:56,480 --> 00:11:58,000
and now dr reggae is going to talk more

315
00:11:58,000 --> 00:11:59,600
about some of those playbooks that we

316
00:11:59,600 --> 00:12:01,120
found

317
00:12:01,120 --> 00:12:03,680
all right it's a green button yes all

318
00:12:03,680 --> 00:12:05,279
right thanks

319
00:12:05,279 --> 00:12:07,120
so first off uh thanks everyone for

320
00:12:07,120 --> 00:12:09,440
coming out uh super excited to be here

321
00:12:09,440 --> 00:12:12,160
and i'm gonna just pick up on the flag

322
00:12:12,160 --> 00:12:14,399
that katora just talked about

323
00:12:14,399 --> 00:12:16,959
um which was to disclose get us to

324
00:12:16,959 --> 00:12:19,519
reveal our office location um or phone

325
00:12:19,519 --> 00:12:20,560
number so

326
00:12:20,560 --> 00:12:22,480
um what you're seeing here on the table

327
00:12:22,480 --> 00:12:24,399
is the overall

328
00:12:24,399 --> 00:12:26,480
you know across all the playbooks that

329
00:12:26,480 --> 00:12:29,839
we got from all the 16 teams um but

330
00:12:29,839 --> 00:12:31,680
we're focusing on five teams in

331
00:12:31,680 --> 00:12:33,279
particular that we thought did a really

332
00:12:33,279 --> 00:12:34,639
good job with their playbooks because

333
00:12:34,639 --> 00:12:35,600
that's something they had to put in

334
00:12:35,600 --> 00:12:37,040
their reports right

335
00:12:37,040 --> 00:12:39,360
is map out your playbooks what you don't

336
00:12:39,360 --> 00:12:40,639
see in the playbooks are actually the

337
00:12:40,639 --> 00:12:42,959
responses that we in the pushback that

338
00:12:42,959 --> 00:12:44,959
we gave them right so we just kept it

339
00:12:44,959 --> 00:12:46,240
clean and only wanted the student

340
00:12:46,240 --> 00:12:48,959
perspective um to show up

341
00:12:48,959 --> 00:12:51,600
so for this particular flag

342
00:12:51,600 --> 00:12:54,079
if you look at the last five columns

343
00:12:54,079 --> 00:12:56,800
right we have two uh graduate teams

344
00:12:56,800 --> 00:12:58,880
mappings two undergraduate teams

345
00:12:58,880 --> 00:13:00,720
mappings and one high school team

346
00:13:00,720 --> 00:13:02,079
mapping

347
00:13:02,079 --> 00:13:04,399
and if you pay attention to the bottom

348
00:13:04,399 --> 00:13:06,000
half of the table what you're going to

349
00:13:06,000 --> 00:13:08,160
see is predominantly the tactic of

350
00:13:08,160 --> 00:13:11,040
reconnaissance which is not surprising

351
00:13:11,040 --> 00:13:12,720
right they're trying to get information

352
00:13:12,720 --> 00:13:14,320
about it so a lot of the techniques that

353
00:13:14,320 --> 00:13:15,600
you see here

354
00:13:15,600 --> 00:13:17,600
right gathering victim information

355
00:13:17,600 --> 00:13:19,600
victim org information

356
00:13:19,600 --> 00:13:22,639
the 1591.001

357
00:13:22,639 --> 00:13:25,760
which is exactly the flag itself right

358
00:13:25,760 --> 00:13:27,920
determine the physical location

359
00:13:27,920 --> 00:13:30,720
um so that's not surprising right a lot

360
00:13:30,720 --> 00:13:32,079
of this was

361
00:13:32,079 --> 00:13:34,480
built into or the very theme or the

362
00:13:34,480 --> 00:13:38,240
essence of of the competition

363
00:13:38,240 --> 00:13:39,920
uh overall

364
00:13:39,920 --> 00:13:44,240
um this is all 16 mappings right now uh

365
00:13:44,240 --> 00:13:47,519
we found seven really popular tactics

366
00:13:47,519 --> 00:13:50,160
and this gets very very interesting so

367
00:13:50,160 --> 00:13:51,839
what doesn't surprise

368
00:13:51,839 --> 00:13:54,800
me anyways right is we have 43

369
00:13:54,800 --> 00:13:56,320
reconnaissance obviously is a very

370
00:13:56,320 --> 00:13:57,839
popular tactic

371
00:13:57,839 --> 00:14:00,639
we also have resource development which

372
00:14:00,639 --> 00:14:03,760
is sort of setting the stage um

373
00:14:03,760 --> 00:14:06,160
and uh you know creating pretext and

374
00:14:06,160 --> 00:14:08,079
personas with which you know you're

375
00:14:08,079 --> 00:14:11,199
going to come and approach us

376
00:14:11,199 --> 00:14:13,360
what was interesting was

377
00:14:13,360 --> 00:14:15,360
zero zero five right because that's

378
00:14:15,360 --> 00:14:17,600
something that shows up later on in the

379
00:14:17,600 --> 00:14:20,240
intrusion chain as a tactic

380
00:14:20,240 --> 00:14:23,519
but we found it being used heavily

381
00:14:23,519 --> 00:14:25,440
because of one particular technique that

382
00:14:25,440 --> 00:14:27,920
you're going to see in the next slide

383
00:14:27,920 --> 00:14:30,079
but that was the second most popular

384
00:14:30,079 --> 00:14:32,560
tactic that was being used so what was

385
00:14:32,560 --> 00:14:35,279
going on there

386
00:14:35,279 --> 00:14:37,120
so these are the nine most popular

387
00:14:37,120 --> 00:14:40,160
techniques now uh for the competition so

388
00:14:40,160 --> 00:14:42,160
if you look at the first column

389
00:14:42,160 --> 00:14:44,639
uh t103c

390
00:14:44,639 --> 00:14:46,959
which is masquerading

391
00:14:46,959 --> 00:14:48,399
and this is something that really caught

392
00:14:48,399 --> 00:14:51,680
us off guard um i think the the

393
00:14:51,680 --> 00:14:54,800
definition that is provided for this

394
00:14:54,800 --> 00:14:56,320
particular technique in the attack

395
00:14:56,320 --> 00:14:59,199
framework is literally about posing as

396
00:14:59,199 --> 00:15:00,639
somebody else right creating fake

397
00:15:00,639 --> 00:15:02,959
personas blah blah but it's intended to

398
00:15:02,959 --> 00:15:05,360
be a defense evasion

399
00:15:05,360 --> 00:15:08,639
uh tactic uh we found it being used as

400
00:15:08,639 --> 00:15:11,040
pretext persona developments that went

401
00:15:11,040 --> 00:15:12,880
hand in hand with the reconnaissance

402
00:15:12,880 --> 00:15:15,199
phase which is why students were using

403
00:15:15,199 --> 00:15:18,880
it quite a bit uh at the beginning

404
00:15:18,880 --> 00:15:21,760
so that was uh that was interesting uh

405
00:15:21,760 --> 00:15:25,120
1593 1598 all of those

406
00:15:25,120 --> 00:15:27,279
made sense because again they were

407
00:15:27,279 --> 00:15:29,040
part of the

408
00:15:29,040 --> 00:15:31,040
reconnaissance tactic

409
00:15:31,040 --> 00:15:32,720
but we have some tail

410
00:15:32,720 --> 00:15:35,279
end ones uh here

411
00:15:35,279 --> 00:15:37,440
that we thought were very very

412
00:15:37,440 --> 00:15:39,120
interesting as well

413
00:15:39,120 --> 00:15:40,959
so i'm going to talk about that in a

414
00:15:40,959 --> 00:15:43,439
little bit

415
00:15:44,639 --> 00:15:47,839
so some of the lessons that we learned

416
00:15:47,839 --> 00:15:49,680
we found and you know these are after

417
00:15:49,680 --> 00:15:52,639
many chats that i've had with jamie

418
00:15:52,639 --> 00:15:54,880
about this right is what's going on

419
00:15:54,880 --> 00:15:56,079
right because we're trying to interpret

420
00:15:56,079 --> 00:15:57,680
these findings

421
00:15:57,680 --> 00:16:00,399
um and we needed uh expertise to help us

422
00:16:00,399 --> 00:16:01,920
figure this out so one of the things

423
00:16:01,920 --> 00:16:03,680
that we found is students who are

424
00:16:03,680 --> 00:16:05,199
toggling between

425
00:16:05,199 --> 00:16:07,839
using uh 1036

426
00:16:07,839 --> 00:16:10,720
85 and 11 36

427
00:16:10,720 --> 00:16:12,880
right and so what i really like about

428
00:16:12,880 --> 00:16:15,279
this is it's open to interpretation

429
00:16:15,279 --> 00:16:16,880
right so students could they were

430
00:16:16,880 --> 00:16:18,560
essentially doing similar things

431
00:16:18,560 --> 00:16:20,079
everyone was doing a pretext everyone

432
00:16:20,079 --> 00:16:22,079
was creating a persona

433
00:16:22,079 --> 00:16:25,040
but they use these different techniques

434
00:16:25,040 --> 00:16:28,000
to account for that so

435
00:16:28,000 --> 00:16:31,120
and and i should also

436
00:16:31,120 --> 00:16:32,880
age which i should have done a little

437
00:16:32,880 --> 00:16:35,040
earlier but a lot of these students are

438
00:16:35,040 --> 00:16:36,880
not technical

439
00:16:36,880 --> 00:16:38,480
right or they've never used attack

440
00:16:38,480 --> 00:16:39,519
before

441
00:16:39,519 --> 00:16:42,000
so this was for many of them their first

442
00:16:42,000 --> 00:16:44,959
introduction to the framework um so we

443
00:16:44,959 --> 00:16:48,720
didn't really impose any set rules or um

444
00:16:48,720 --> 00:16:50,959
you know give them a detailed

445
00:16:50,959 --> 00:16:52,800
uh

446
00:16:52,800 --> 00:16:54,320
sort of study session if you will and

447
00:16:54,320 --> 00:16:56,000
how to use this framework we left it

448
00:16:56,000 --> 00:16:59,360
open to their creativity and imagination

449
00:16:59,360 --> 00:17:01,360
so we found like i said students could

450
00:17:01,360 --> 00:17:03,360
mix and match and use these techniques

451
00:17:03,360 --> 00:17:05,520
and sometimes it was the same

452
00:17:05,520 --> 00:17:08,160
uh team that would use masquerading in

453
00:17:08,160 --> 00:17:09,760
one sort of uh you know when they were

454
00:17:09,760 --> 00:17:11,599
pursuing one flag but then for another

455
00:17:11,599 --> 00:17:13,039
flag they

456
00:17:13,039 --> 00:17:16,959
said it was 1585 right so

457
00:17:16,959 --> 00:17:18,000
so that was something that we thought

458
00:17:18,000 --> 00:17:19,280
was interesting

459
00:17:19,280 --> 00:17:22,480
um in terms of tactics that were used

460
00:17:22,480 --> 00:17:24,319
right so so we saw this a lot with

461
00:17:24,319 --> 00:17:26,880
persistence as i mentioned when they

462
00:17:26,880 --> 00:17:28,960
started pursuing a flag we didn't just

463
00:17:28,960 --> 00:17:31,600
give it to them there was pushback right

464
00:17:31,600 --> 00:17:32,400
so

465
00:17:32,400 --> 00:17:34,480
um but they persisted so a lot of them

466
00:17:34,480 --> 00:17:36,039
used the

467
00:17:36,039 --> 00:17:38,480
ta003 persistence but they didn't

468
00:17:38,480 --> 00:17:40,960
identify specific techniques within that

469
00:17:40,960 --> 00:17:42,400
that they used

470
00:17:42,400 --> 00:17:44,720
um there were also instances where we

471
00:17:44,720 --> 00:17:46,880
saw in their playbooks

472
00:17:46,880 --> 00:17:48,799
right that they were using tactics and

473
00:17:48,799 --> 00:17:50,720
techniques of persistence or other

474
00:17:50,720 --> 00:17:53,280
things but then they never mapped it on

475
00:17:53,280 --> 00:17:55,520
right so there was that

476
00:17:55,520 --> 00:17:57,440
scenario as well

477
00:17:57,440 --> 00:17:58,400
um

478
00:17:58,400 --> 00:18:01,039
the third point here no major surprise

479
00:18:01,039 --> 00:18:03,120
uh the theme of the competition again

480
00:18:03,120 --> 00:18:05,039
was social engineering a lot of it was

481
00:18:05,039 --> 00:18:07,840
ocean reconnaissance rate um all these

482
00:18:07,840 --> 00:18:10,960
kinds of uh stuff but what's really cool

483
00:18:10,960 --> 00:18:12,640
is a lot of the human and socio

484
00:18:12,640 --> 00:18:14,320
behavioral aspects that we're interested

485
00:18:14,320 --> 00:18:17,360
in were actually captured pretty well

486
00:18:17,360 --> 00:18:19,440
uh there were some tactics and

487
00:18:19,440 --> 00:18:20,960
techniques that were minimally used now

488
00:18:20,960 --> 00:18:22,559
we did have some flags i think there

489
00:18:22,559 --> 00:18:26,000
were two one of them was trying to we

490
00:18:26,000 --> 00:18:26,720
so

491
00:18:26,720 --> 00:18:28,799
adam introduces when and he said that we

492
00:18:28,799 --> 00:18:31,039
were here last year for the power hour

493
00:18:31,039 --> 00:18:33,120
we maintain a ransomware incident data

494
00:18:33,120 --> 00:18:34,799
set a critical infrastructure ransomware

495
00:18:34,799 --> 00:18:36,799
incident data set which is a public

496
00:18:36,799 --> 00:18:38,880
resource by the way but we set it up as

497
00:18:38,880 --> 00:18:40,880
a flag convince us to give it to you

498
00:18:40,880 --> 00:18:42,480
right so that's ip

499
00:18:42,480 --> 00:18:47,120
um and uh so that they actually covered

500
00:18:47,120 --> 00:18:48,080
that

501
00:18:48,080 --> 00:18:49,160
uh with

502
00:18:49,160 --> 00:18:51,679
t1005 they were able to get data from

503
00:18:51,679 --> 00:18:54,160
our system if we agreed to give them the

504
00:18:54,160 --> 00:18:55,600
data set

505
00:18:55,600 --> 00:18:56,640
um

506
00:18:56,640 --> 00:18:58,400
the last one here

507
00:18:58,400 --> 00:19:01,440
40 impact this was data manipulation so

508
00:19:01,440 --> 00:19:03,600
one of the flags was convince us to

509
00:19:03,600 --> 00:19:06,400
change content on our actual website

510
00:19:06,400 --> 00:19:08,000
right and so what we're essentially

511
00:19:08,000 --> 00:19:10,080
doing is we have disinformation that's

512
00:19:10,080 --> 00:19:12,480
going on on our website

513
00:19:12,480 --> 00:19:14,480
or misinformation depending on how you

514
00:19:14,480 --> 00:19:16,640
look at it so there were some teams that

515
00:19:16,640 --> 00:19:19,520
were able to successfully get there

516
00:19:19,520 --> 00:19:21,679
using pure social engineering and that's

517
00:19:21,679 --> 00:19:25,640
what they then used

518
00:19:26,000 --> 00:19:29,600
uh so carrying on with this idea of

519
00:19:29,600 --> 00:19:31,520
creativity one of the things that we

520
00:19:31,520 --> 00:19:33,039
wanted to do

521
00:19:33,039 --> 00:19:35,600
was in the report ask students well what

522
00:19:35,600 --> 00:19:36,720
recommendations do you have for

523
00:19:36,720 --> 00:19:39,200
mitigations and for a lot of social

524
00:19:39,200 --> 00:19:41,760
engineering related mitigations the

525
00:19:41,760 --> 00:19:43,679
attack framework doesn't offer a lot of

526
00:19:43,679 --> 00:19:45,679
detail right because that falls kind of

527
00:19:45,679 --> 00:19:47,200
outside the scope

528
00:19:47,200 --> 00:19:49,039
a little bit but what we really liked

529
00:19:49,039 --> 00:19:52,640
was that students used techniques to

530
00:19:52,640 --> 00:19:55,440
guide mitigation right so i'm not going

531
00:19:55,440 --> 00:19:57,120
to read through all of them but you can

532
00:19:57,120 --> 00:19:58,720
get a feel for

533
00:19:58,720 --> 00:20:00,160
you know like if you look at the spear

534
00:20:00,160 --> 00:20:02,320
fishing one right so that was a

535
00:20:02,320 --> 00:20:04,880
technique that they said they used uh in

536
00:20:04,880 --> 00:20:06,960
the competition so they came up with

537
00:20:06,960 --> 00:20:08,799
their own sets of recommendations for

538
00:20:08,799 --> 00:20:11,120
that uh so anti-spoofing email

539
00:20:11,120 --> 00:20:13,440
authentication and so on and so forth so

540
00:20:13,440 --> 00:20:17,039
again we gave them that creativity

541
00:20:18,480 --> 00:20:20,799
so one of the uh

542
00:20:20,799 --> 00:20:23,039
last things that we like to say right

543
00:20:23,039 --> 00:20:25,919
that we are finding very useful

544
00:20:25,919 --> 00:20:28,159
um is that students can actually use

545
00:20:28,159 --> 00:20:30,320
attack as an aide rachel mentioned that

546
00:20:30,320 --> 00:20:33,280
there is no right or wrong way to map

547
00:20:33,280 --> 00:20:35,919
um and

548
00:20:35,919 --> 00:20:37,679
i think i think we agree with that we

549
00:20:37,679 --> 00:20:39,679
want them to get a feel for the

550
00:20:39,679 --> 00:20:41,039
framework

551
00:20:41,039 --> 00:20:42,720
and i think this helps them understand

552
00:20:42,720 --> 00:20:44,640
the adversarial mindset right because

553
00:20:44,640 --> 00:20:46,000
they understand where they are in the

554
00:20:46,000 --> 00:20:49,120
intrusion chain they can also figure out

555
00:20:49,120 --> 00:20:51,360
um which techniques can help them

556
00:20:51,360 --> 00:20:54,000
successfully move from one tactic to the

557
00:20:54,000 --> 00:20:55,919
next or not right like what works what

558
00:20:55,919 --> 00:20:58,080
doesn't work and how might adversaries

559
00:20:58,080 --> 00:21:00,840
be doing that themselves

560
00:21:00,840 --> 00:21:02,400
um

561
00:21:02,400 --> 00:21:05,120
another interesting point that we found

562
00:21:05,120 --> 00:21:07,200
obviously not all risks and threats are

563
00:21:07,200 --> 00:21:08,720
captured in attack

564
00:21:08,720 --> 00:21:10,720
and i think this is partially because of

565
00:21:10,720 --> 00:21:12,240
the reason that some of the harms that

566
00:21:12,240 --> 00:21:14,000
i'm thinking of as a social scientist

567
00:21:14,000 --> 00:21:16,080
are not necessarily technical or

568
00:21:16,080 --> 00:21:18,240
tangible harms per se

569
00:21:18,240 --> 00:21:21,200
but things like reputation loss right or

570
00:21:21,200 --> 00:21:23,200
again we had to talk earlier wonderful

571
00:21:23,200 --> 00:21:25,600
one on insider threats right

572
00:21:25,600 --> 00:21:27,039
um

573
00:21:27,039 --> 00:21:30,559
so you know how can students use the

574
00:21:30,559 --> 00:21:32,640
insider threat ttp knowledge base for

575
00:21:32,640 --> 00:21:35,520
instance in this particular case

576
00:21:35,520 --> 00:21:38,159
and the last point here is you know we

577
00:21:38,159 --> 00:21:39,760
hope that this is something that's

578
00:21:39,760 --> 00:21:42,240
useful to other educators

579
00:21:42,240 --> 00:21:44,720
like i said we're social scientists and

580
00:21:44,720 --> 00:21:46,240
one of the things that we're trying to

581
00:21:46,240 --> 00:21:47,120
do

582
00:21:47,120 --> 00:21:49,039
is to use well-established frameworks

583
00:21:49,039 --> 00:21:51,440
like the attack framework to show that

584
00:21:51,440 --> 00:21:53,039
the social science side of it the

585
00:21:53,039 --> 00:21:55,760
socio-behavioral psychological aspects

586
00:21:55,760 --> 00:21:58,480
are relevant and they can be mapped onto

587
00:21:58,480 --> 00:21:59,440
uh

588
00:21:59,440 --> 00:22:01,440
really well respected frameworks like

589
00:22:01,440 --> 00:22:04,960
the attack framework um so that's uh

590
00:22:04,960 --> 00:22:07,679
everything that we have for you

591
00:22:07,679 --> 00:22:10,320
and we can open it up to questions or

592
00:22:10,320 --> 00:22:12,559
comments and thank you again

593
00:22:12,559 --> 00:22:14,559
attack khan you know for bringing us

594
00:22:14,559 --> 00:22:16,080
here that's really cool and thank you

595
00:22:16,080 --> 00:22:18,799
all for coming out

596
00:22:22,400 --> 00:22:24,799
and really truly honored um thank you

597
00:22:24,799 --> 00:22:26,640
not just for the great presentation but

598
00:22:26,640 --> 00:22:28,320
what you do to exactly as you

599
00:22:28,320 --> 00:22:30,320
highlighted you know very humbly but i'm

600
00:22:30,320 --> 00:22:32,240
gonna you know sing the praises here you

601
00:22:32,240 --> 00:22:33,760
know extending these great ideas and

602
00:22:33,760 --> 00:22:35,440
really asking questions that resonate

603
00:22:35,440 --> 00:22:37,360
with all of us but most importantly

604
00:22:37,360 --> 00:22:38,960
extending that knowledge to everyone

605
00:22:38,960 --> 00:22:40,880
making sure you know anyone you know

606
00:22:40,880 --> 00:22:42,640
underrepresented people just bring that

607
00:22:42,640 --> 00:22:44,320
accessibility you know to different

608
00:22:44,320 --> 00:22:45,520
groups because you know looking at those

609
00:22:45,520 --> 00:22:47,520
mappings i had a blast going through

610
00:22:47,520 --> 00:22:50,159
their data set um because it's just such

611
00:22:50,159 --> 00:22:52,640
a different unique perspective

612
00:22:52,640 --> 00:22:54,240
on you know something that i thought i

613
00:22:54,240 --> 00:22:56,080
really knew but exactly as you said the

614
00:22:56,080 --> 00:22:57,679
big lessons learned were

615
00:22:57,679 --> 00:22:59,600
there really is no right way to use

616
00:22:59,600 --> 00:23:01,840
attack it's really what works for you

617
00:23:01,840 --> 00:23:03,679
like tactics techniques and procedures

618
00:23:03,679 --> 00:23:06,240
could be almost anything so really uh

619
00:23:06,240 --> 00:23:08,159
truly a pleasure and honor so thank you

620
00:23:08,159 --> 00:23:09,679
thank you i think we have a little bit

621
00:23:09,679 --> 00:23:13,720
of time for questions um

622
00:23:34,960 --> 00:23:36,640
uh just to repeat for the live audience

623
00:23:36,640 --> 00:23:38,080
the two-part question are very

624
00:23:38,080 --> 00:23:39,679
interesting uh excited to see the

625
00:23:39,679 --> 00:23:41,360
response here but part one was you know

626
00:23:41,360 --> 00:23:43,919
we're bringing in uh students who might

627
00:23:43,919 --> 00:23:45,360
not have heard of attack you know you

628
00:23:45,360 --> 00:23:47,200
did a quick introduction so they kind of

629
00:23:47,200 --> 00:23:48,880
knew where the website was and such but

630
00:23:48,880 --> 00:23:50,799
did you have any kind of impressions or

631
00:23:50,799 --> 00:23:52,559
artifacts or any kind of lessons learned

632
00:23:52,559 --> 00:23:54,640
from their learning curve kind of stop

633
00:23:54,640 --> 00:23:56,240
adopting and working with attack and you

634
00:23:56,240 --> 00:23:59,120
know from first start to end what that

635
00:23:59,120 --> 00:24:00,799
looked like and then part two what about

636
00:24:00,799 --> 00:24:02,880
the the physical social engineering side

637
00:24:02,880 --> 00:24:04,320
were there any like big lessons learned

638
00:24:04,320 --> 00:24:06,320
there regarding like you know lock

639
00:24:06,320 --> 00:24:08,720
picking opening doors you know putting a

640
00:24:08,720 --> 00:24:11,600
mask on a really interesting space

641
00:24:11,600 --> 00:24:13,679
so yeah sure i'm jamie i'm going to

642
00:24:13,679 --> 00:24:16,640
weave you into my response so heads up

643
00:24:16,640 --> 00:24:18,000
so that's a great question i'll start

644
00:24:18,000 --> 00:24:21,039
with part two uh no to physical because

645
00:24:21,039 --> 00:24:23,679
this was during the pandemic uh one of

646
00:24:23,679 --> 00:24:25,840
the things that we found is it's not so

647
00:24:25,840 --> 00:24:27,840
much necessarily about pandemic anymore

648
00:24:27,840 --> 00:24:29,840
a lot of universities colleges its high

649
00:24:29,840 --> 00:24:32,559
schools have been hit hard budget-wise

650
00:24:32,559 --> 00:24:34,720
so even this year we're keeping our

651
00:24:34,720 --> 00:24:36,799
competition virtual so we can't really

652
00:24:36,799 --> 00:24:39,360
get at the physical aspect just yet now

653
00:24:39,360 --> 00:24:41,520
um with regards to part one a lot of

654
00:24:41,520 --> 00:24:43,520
them didn't have learned about attack

655
00:24:43,520 --> 00:24:45,279
before we actually had jaime come in and

656
00:24:45,279 --> 00:24:49,520
do an hour's worth of an orientation um

657
00:24:49,520 --> 00:24:52,240
so that we could all you know uh

658
00:24:52,240 --> 00:24:53,919
become used to it and and

659
00:24:53,919 --> 00:24:55,760
uh the competition was about social

660
00:24:55,760 --> 00:24:57,279
engineering right

661
00:24:57,279 --> 00:24:59,039
and we want to see their playbooks the

662
00:24:59,039 --> 00:25:00,480
attack component was something that we

663
00:25:00,480 --> 00:25:03,039
were looking for in terms of consistency

664
00:25:03,039 --> 00:25:05,200
you know to guide students along so one

665
00:25:05,200 --> 00:25:07,200
of the things that we do have

666
00:25:07,200 --> 00:25:09,919
um is we have the playbooks from all the

667
00:25:09,919 --> 00:25:11,360
students

668
00:25:11,360 --> 00:25:12,880
in their reports

669
00:25:12,880 --> 00:25:15,039
right so we're actually going through

670
00:25:15,039 --> 00:25:18,320
those right now what i i know jamie was

671
00:25:18,320 --> 00:25:19,840
saying is like how cool would it have

672
00:25:19,840 --> 00:25:21,440
been if we could have done a focus group

673
00:25:21,440 --> 00:25:22,400
with them

674
00:25:22,400 --> 00:25:25,200
right after and just gone inside their

675
00:25:25,200 --> 00:25:27,919
brains and see what was going on so

676
00:25:27,919 --> 00:25:29,840
that's something that we're trying to

677
00:25:29,840 --> 00:25:31,679
get at uh because for us we're just

678
00:25:31,679 --> 00:25:33,679
trying to do a proof of concept can we

679
00:25:33,679 --> 00:25:36,159
even do this competition virtually

680
00:25:36,159 --> 00:25:37,760
um so now that we've gone through that

681
00:25:37,760 --> 00:25:38,960
you know that's part of the lessons

682
00:25:38,960 --> 00:25:40,720
learned is how do we now get into the

683
00:25:40,720 --> 00:25:42,880
next issue of metrics and measurement

684
00:25:42,880 --> 00:25:45,039
but what we do have at least are the

685
00:25:45,039 --> 00:25:48,240
playbooks um which we're mapped onto and

686
00:25:48,240 --> 00:25:49,600
i thought what was really cool is some

687
00:25:49,600 --> 00:25:52,720
of the teams even mapped our responses

688
00:25:52,720 --> 00:25:54,320
to the attack framework which i thought

689
00:25:54,320 --> 00:25:58,000
was very clever as well yeah

690
00:25:58,000 --> 00:25:59,600
only thing i'd add to that was my

691
00:25:59,600 --> 00:26:02,080
biggest lesson learn i had was

692
00:26:02,080 --> 00:26:04,080
um that best practice of checking each

693
00:26:04,080 --> 00:26:05,760
other mapping because you know i mapped

694
00:26:05,760 --> 00:26:07,679
before we did all this i mapped their

695
00:26:07,679 --> 00:26:09,760
case study to attack and i was like oh i

696
00:26:09,760 --> 00:26:11,039
think this makes sense to me i'm okay

697
00:26:11,039 --> 00:26:12,480
with this and after reviewing the

698
00:26:12,480 --> 00:26:14,080
students work i was like i had some

699
00:26:14,080 --> 00:26:15,360
really good ideas like some things i

700
00:26:15,360 --> 00:26:17,440
didn't really think about it that way so

701
00:26:17,440 --> 00:26:18,720
you know really making sure even

702
00:26:18,720 --> 00:26:20,720
internally we do that we spend weeks

703
00:26:20,720 --> 00:26:22,400
doing those checks so you know it all

704
00:26:22,400 --> 00:26:24,240
comes down to like you said that you

705
00:26:24,240 --> 00:26:25,760
know opening your aperture getting a

706
00:26:25,760 --> 00:26:27,520
little you know a bit of diversity on

707
00:26:27,520 --> 00:26:29,600
perspectives and then really making sure

708
00:26:29,600 --> 00:26:31,600
like you know what are we the mappings

709
00:26:31,600 --> 00:26:32,720
aren't going to be something we're just

710
00:26:32,720 --> 00:26:33,919
going to throw at the problem to be a

711
00:26:33,919 --> 00:26:35,760
solution it's really you know that

712
00:26:35,760 --> 00:26:38,000
connective glue towards you know what

713
00:26:38,000 --> 00:26:39,520
the best mapping is the one that works

714
00:26:39,520 --> 00:26:41,600
best for us yeah and what was really

715
00:26:41,600 --> 00:26:43,760
cool i'll just add with this one thing

716
00:26:43,760 --> 00:26:45,520
is like i said we had high school teams

717
00:26:45,520 --> 00:26:46,880
undergrad we had one high school team

718
00:26:46,880 --> 00:26:48,880
and all girls team from the u.s virgin

719
00:26:48,880 --> 00:26:51,039
islands and they were amazing

720
00:26:51,039 --> 00:26:52,960
they had some of the best playbook

721
00:26:52,960 --> 00:26:54,240
mappings

722
00:26:54,240 --> 00:26:56,720
compared to even undergrads and grads

723
00:26:56,720 --> 00:26:59,440
so in terms of sort of skill levels or

724
00:26:59,440 --> 00:27:00,960
education level or things that's

725
00:27:00,960 --> 00:27:02,240
something else that we're interested in

726
00:27:02,240 --> 00:27:04,240
looking at right is does that have an

727
00:27:04,240 --> 00:27:06,960
impact on students understandings so i

728
00:27:06,960 --> 00:27:08,960
don't think there's a right age to even

729
00:27:08,960 --> 00:27:11,919
start learning about attack i think high

730
00:27:11,919 --> 00:27:13,520
schools can certainly sort of get into

731
00:27:13,520 --> 00:27:14,640
that space and this is part of the

732
00:27:14,640 --> 00:27:17,120
workforce training right because if we

733
00:27:17,120 --> 00:27:18,880
start talking about it by the time they

734
00:27:18,880 --> 00:27:20,559
enter the workforce

735
00:27:20,559 --> 00:27:21,840
they're going to be already at least

736
00:27:21,840 --> 00:27:24,159
exposed to it maybe try their hand at it

737
00:27:24,159 --> 00:27:26,000
and they can hit the ground running

738
00:27:26,000 --> 00:27:26,960
so

739
00:27:26,960 --> 00:27:27,919
yeah

740
00:27:27,919 --> 00:27:29,200
so i think we're running on time here

741
00:27:29,200 --> 00:27:31,520
but one final comment thought is you

742
00:27:31,520 --> 00:27:33,520
mentioned you know this work the

743
00:27:33,520 --> 00:27:34,880
penetration testing everything you're

744
00:27:34,880 --> 00:27:36,799
doing in the in the care lab including

745
00:27:36,799 --> 00:27:38,559
the ransomware set so thank you yes

746
00:27:38,559 --> 00:27:41,840
what's next well you know what's next

747
00:27:41,840 --> 00:27:43,760
so we're doing our competition again

748
00:27:43,760 --> 00:27:46,640
this year the theme is the care lab has

749
00:27:46,640 --> 00:27:48,559
been hit with ransomware which i think

750
00:27:48,559 --> 00:27:50,720
is super ironic because we maintain a

751
00:27:50,720 --> 00:27:53,279
ransomware data set that is very very

752
00:27:53,279 --> 00:27:56,480
popular um so uh there's gonna be a lot

753
00:27:56,480 --> 00:27:58,720
of that can i say

754
00:27:58,720 --> 00:28:00,320
yeah so he's

755
00:28:00,320 --> 00:28:02,080
he's actually to be behind the scenes

756
00:28:02,080 --> 00:28:05,279
with us um just like he was last year so

757
00:28:05,279 --> 00:28:08,399
he is actually a very very solid social

758
00:28:08,399 --> 00:28:09,520
engineer

759
00:28:09,520 --> 00:28:12,159
watch out for him so he's really good

760
00:28:12,159 --> 00:28:13,760
but what i really like about the attack

761
00:28:13,760 --> 00:28:16,640
team is that they were so welcoming

762
00:28:16,640 --> 00:28:19,200
to this idea of education and they were

763
00:28:19,200 --> 00:28:20,320
patient and they were understanding

764
00:28:20,320 --> 00:28:22,799
that's what we like to see as educators

765
00:28:22,799 --> 00:28:25,840
is more folks at mitre right or in

766
00:28:25,840 --> 00:28:27,520
industry come and engage with us and

767
00:28:27,520 --> 00:28:30,159
also not just with technical folks but

768
00:28:30,159 --> 00:28:32,640
also with social scientists

769
00:28:32,640 --> 00:28:37,720
so thank you so much it's a pleasure

