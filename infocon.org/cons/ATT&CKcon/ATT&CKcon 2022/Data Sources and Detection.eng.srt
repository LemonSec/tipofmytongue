1
00:00:12,230 --> 00:00:13,230
- Ladies and gentlemen,

2
00:00:13,230 --> 00:00:17,610
please welcome back to the
stage, Mr. Adam Pennington.

3
00:00:17,610 --> 00:00:20,850
- [Adam] Hey.

4
00:00:20,850 --> 00:00:22,480
(applause)

5
00:00:22,480 --> 00:00:23,480
Welcome back from lunch.

6
00:00:23,480 --> 00:00:24,689
You know, if it was provided

7
00:00:24,689 --> 00:00:28,360
by us or provided at your own home

8
00:00:28,360 --> 00:00:30,480
hopefully as you went
outside, if you're here

9
00:00:30,480 --> 00:00:32,710
you got a chance to see
the sponsor tables we

10
00:00:32,710 --> 00:00:35,830
have downstairs, encourage
you to visit them.

11
00:00:35,830 --> 00:00:37,850
Say hi, most of them have swag.

12
00:00:37,850 --> 00:00:39,190
We promise.

13
00:00:39,190 --> 00:00:42,329
So go check it out.

14
00:00:42,329 --> 00:00:43,510
Our first talk after lunch

15
00:00:43,510 --> 00:00:46,500
we have the first of our attack updates.

16
00:00:46,500 --> 00:00:48,270
So this is gonna be talking

17
00:00:48,270 --> 00:00:51,109
about defensive attack by Lex Croton.

18
00:00:51,109 --> 00:00:52,179
(applause)

19
00:00:52,179 --> 00:00:57,550
- [Lex] Is it this button?

20
00:00:57,550 --> 00:00:59,669
- [Adam] It's big green one.

21
00:00:59,670 --> 00:01:00,670
- [Lex] Okay.

22
00:01:00,670 --> 00:01:02,399
It's the green gun.

23
00:01:02,399 --> 00:01:03,399
Goodbye guys.

24
00:01:03,399 --> 00:01:04,519
Okay, awesome, yeah.

25
00:01:04,519 --> 00:01:06,720
My name's Lex, I'm here to give you guys

26
00:01:06,720 --> 00:01:09,220
the Defensive Attack updates, finally.

27
00:01:09,220 --> 00:01:14,929
See if this works, come on, there we go.

28
00:01:14,930 --> 00:01:17,729
That was a good hair day.

29
00:01:17,729 --> 00:01:19,990
So I'm the Lead Cybersecurity
Engineer for Mitre

30
00:01:19,990 --> 00:01:21,530
I just got there last June

31
00:01:21,530 --> 00:01:25,030
before that I was former
exploitation developer turn blue

32
00:01:25,030 --> 00:01:26,030
and I never looked back.

33
00:01:26,030 --> 00:01:28,250
Okay, that's a very important thing.

34
00:01:28,250 --> 00:01:30,060
I like quite a few teams

35
00:01:30,060 --> 00:01:32,610
digital forensics or hunting detection.

36
00:01:32,610 --> 00:01:35,149
My canine child, he's like this big

37
00:01:35,149 --> 00:01:37,390
and he jumps on me all the time.

38
00:01:37,390 --> 00:01:39,842
And then this last one is a joke

39
00:01:39,842 --> 00:01:41,450
because all you see is work stuff

40
00:01:41,450 --> 00:01:44,539
but I actually do some fun stuff too.

41
00:01:44,539 --> 00:01:46,090
I like playing video games.

42
00:01:46,090 --> 00:01:47,460
PS4, look me up.

43
00:01:47,460 --> 00:01:49,990
I like doing street photography.

44
00:01:49,990 --> 00:01:52,520
You see me out there
actually taking pictures

45
00:01:52,520 --> 00:01:55,988
of crazy people, doing crazy things.

46
00:01:55,989 --> 00:01:57,140
And I actually grow vegetables

47
00:01:57,140 --> 00:01:59,270
and herbs to like heal people's bodies

48
00:01:59,270 --> 00:02:03,369
like creams, ointments,
teas, all those things.

49
00:02:03,369 --> 00:02:06,729
So, welcome to the other
side of MITRE ATT&CK.

50
00:02:06,729 --> 00:02:09,030
Again, finally, I finally worked Jamie

51
00:02:09,030 --> 00:02:11,990
down enough where he gave me this talk.

52
00:02:11,990 --> 00:02:15,090
This is going to incorporate
mitigation's, data sources

53
00:02:15,090 --> 00:02:17,250
and data components, detections,

54
00:02:17,250 --> 00:02:19,950
and of course CAR,
specifically for this talk

55
00:02:19,950 --> 00:02:22,798
we're gonna be looking
into detections and CAR

56
00:02:22,799 --> 00:02:26,819
but just know my area
encompasses all of these areas.

57
00:02:26,819 --> 00:02:27,819
We started this update

58
00:02:27,819 --> 00:02:30,660
in V5 mitigation's and then subsequently

59
00:02:30,660 --> 00:02:34,180
in V10 with data sources
and data components.

60
00:02:34,180 --> 00:02:36,959
And between those twos,
we have the mapping to

61
00:02:36,959 --> 00:02:39,909
risk control frameworks,
which is a really good thing.

62
00:02:39,909 --> 00:02:44,649
And then also letting defenders
know what data to collect.

63
00:02:44,650 --> 00:02:48,790
So, where are we?

64
00:02:48,790 --> 00:02:50,790
This is what happened after V10.

65
00:02:50,790 --> 00:02:53,640
This bottom portion right
here gives me so much anxiety.

66
00:02:53,640 --> 00:02:56,328
Okay, I don't know what it's saying.

67
00:02:56,329 --> 00:02:57,329
And a lot of other people

68
00:02:57,329 --> 00:02:58,400
don't know what it's saying either.

69
00:02:58,400 --> 00:03:03,739
So the changes that we're
gonna do in V11 is this,

70
00:03:03,739 --> 00:03:04,739
we're gonna be breaking

71
00:03:04,739 --> 00:03:07,810
out that detection paragraph
into their data components so

72
00:03:07,810 --> 00:03:10,499
that you have a better
understanding of what the detection

73
00:03:10,499 --> 00:03:12,900
and what defenders need to collect overall

74
00:03:12,900 --> 00:03:14,209
which is a very good thing, right?

75
00:03:14,209 --> 00:03:15,780
This gives me less anxiety.

76
00:03:15,780 --> 00:03:19,360
There's some order here you guys, okay.

77
00:03:19,360 --> 00:03:21,099
Next up you'll see that we are gonna try

78
00:03:21,099 --> 00:03:26,819
and make a cohesive kind of
detection statement overall

79
00:03:26,819 --> 00:03:29,858
monitor executed commands and arguments,

80
00:03:29,859 --> 00:03:34,280
analyze creative processes,
files, registry keys,

81
00:03:34,280 --> 00:03:38,069
look for IP addresses or
port numbers or protocols

82
00:03:38,069 --> 00:03:42,010
that you should be looking
for defenders overall.

83
00:03:42,010 --> 00:03:44,298
And then next we're gonna try
and give you that little bit

84
00:03:44,299 --> 00:03:46,650
of in depth that you're
gonna need that says,

85
00:03:46,650 --> 00:03:48,060
what exactly you're looking for.

86
00:03:48,060 --> 00:03:51,319
Process names, registry key paths,

87
00:03:51,319 --> 00:03:53,409
command lines and arguments
that are gonna tell you exactly

88
00:03:53,409 --> 00:03:57,319
what you need to know as
a defender in this space.

89
00:03:57,319 --> 00:03:59,899
So, where do we go from here?

90
00:03:59,900 --> 00:04:01,550
How can I improve this work?

91
00:04:01,550 --> 00:04:06,770
Cause this took a lot of work you guys.

92
00:04:06,770 --> 00:04:09,889
Coming soon, of course,
we're gonna have data sources

93
00:04:09,889 --> 00:04:11,909
into all the other domains.

94
00:04:11,909 --> 00:04:15,918
So ICS, Cloud, Mobile, macOS, Linux.

95
00:04:15,919 --> 00:04:17,000
We're gonna try and get us all

96
00:04:17,000 --> 00:04:20,279
on one page cause I like to work together,

97
00:04:20,279 --> 00:04:22,638
and so that we can all have
things that tell defenders

98
00:04:22,639 --> 00:04:25,360
as a community, what we need to look for.

99
00:04:25,360 --> 00:04:28,830
Again, please note the coming soon, okay.

100
00:04:28,830 --> 00:04:31,909
Next, we have the Cyber
Analytic Repository.

101
00:04:31,910 --> 00:04:35,250
This started in 2013, 2016

102
00:04:35,250 --> 00:04:41,320
but we fully intend to
give it a 2.0 upgrade.

103
00:04:41,320 --> 00:04:44,040
This is the place where
we could build analytics

104
00:04:44,040 --> 00:04:45,910
to give a more in-depth view of

105
00:04:45,910 --> 00:04:47,630
what is going on for defenders.

106
00:04:47,630 --> 00:04:49,920
And we fully intend to align this

107
00:04:49,920 --> 00:04:52,190
to the MITRE ATT&CK detections.

108
00:04:52,190 --> 00:04:53,190
So that means data models

109
00:04:53,190 --> 00:04:54,910
are going to be more
synced across the board.

110
00:04:54,910 --> 00:04:59,130
That means anything that
is not in MITRE detections

111
00:04:59,130 --> 00:05:02,370
is going to be in the
Cyber Analytic Repository

112
00:05:02,370 --> 00:05:07,840
and a more in depth of what
exactly you need to know.

113
00:05:07,840 --> 00:05:10,750
So just to recap, cause
I said a lot of things,

114
00:05:10,750 --> 00:05:12,290
what we're looking
forward towards the future

115
00:05:12,290 --> 00:05:13,580
we're gonna have cross domains

116
00:05:13,580 --> 00:05:17,340
against ICS, Cloud, Mobile, macOS, Linux.

117
00:05:17,340 --> 00:05:20,190
We're gonna align
detections with data sources

118
00:05:20,190 --> 00:05:22,190
and data components so that
we get a better understanding

119
00:05:22,190 --> 00:05:23,450
of what you're looking for.

120
00:05:23,450 --> 00:05:26,580
We're gonna incorporate the
Cyber Analytic Repository

121
00:05:26,580 --> 00:05:30,729
and try to give that a full
upgrade in what's coming soon.

122
00:05:30,730 --> 00:05:33,200
And then of course, things
that are not on this slide,

123
00:05:33,200 --> 00:05:35,760
mitigation's and anything updates to,

124
00:05:35,760 --> 00:05:38,070
you know, the famous debate

125
00:05:38,070 --> 00:05:41,659
of command execution
compared to process creation.

126
00:05:41,660 --> 00:05:43,770
I've heard the emails, okay.

127
00:05:43,770 --> 00:05:46,280
It is going to change I promise you that.

128
00:05:46,280 --> 00:05:49,190
And then of course we can't
leave out mitigation's,

129
00:05:49,190 --> 00:05:51,910
you know, we did get that
risk control framework update

130
00:05:51,910 --> 00:05:53,530
but how can we push that further

131
00:05:53,530 --> 00:05:56,359
into mapping it to the new techniques?

132
00:05:56,360 --> 00:05:58,050
How can we push that
further to incorporate,

133
00:05:58,050 --> 00:06:01,420
you know, the protect,
defend and detect scenarios

134
00:06:01,420 --> 00:06:04,050
across the board and how can we improve

135
00:06:04,050 --> 00:06:08,310
our defensive posture
overall for MITRE ATT&CK.

136
00:06:08,310 --> 00:06:14,090
Short, sweet and to this
point, my name is Lex.

137
00:06:14,090 --> 00:06:18,719
You can find me on Twitter and
I'm open for any questions.

138
00:06:18,720 --> 00:06:20,300
(applause)

139
00:06:20,300 --> 00:06:24,390
- [Jamie] And this is really a topic

140
00:06:24,390 --> 00:06:27,390
that we're really excited
about, as you can tell.

141
00:06:27,390 --> 00:06:28,979
Something that we recognize from

142
00:06:28,980 --> 00:06:30,870
the very first ATT&CKCON we didn't

143
00:06:30,870 --> 00:06:32,850
obviously we saw the CFPs

144
00:06:32,850 --> 00:06:35,410
but the presentations really
highlighted the, you know,

145
00:06:35,410 --> 00:06:38,250
how much power, how much
attention, how much kind

146
00:06:38,250 --> 00:06:41,190
of potential we have with
the defensive side of ATT&CK.

147
00:06:41,190 --> 00:06:42,600
So It's been honor working

148
00:06:42,600 --> 00:06:44,360
with you and we're really
excited for the future.

149
00:06:44,360 --> 00:06:46,240
And regarding the question earlier

150
00:06:46,240 --> 00:06:48,830
it is something where as most things

151
00:06:48,830 --> 00:06:50,020
in ATT&CK we're leaning towards you.

152
00:06:50,021 --> 00:06:52,900
You know, we built it,
we were open to feedback.

153
00:06:52,900 --> 00:06:53,900
We want to grow this.

154
00:06:53,900 --> 00:06:57,049
We want new use cases,
more depth, more, you know,

155
00:06:57,050 --> 00:06:58,450
breadth into different platforms.

156
00:06:58,450 --> 00:07:00,860
All of that is on the table.

157
00:07:00,860 --> 00:07:03,600
So, Lex, unfortunately is
not gonna be on the couch

158
00:07:03,600 --> 00:07:06,030
but great news is we have
plenty of time right now.

159
00:07:06,030 --> 00:07:07,369
So let's go around the room.

160
00:07:07,370 --> 00:07:09,541
You know, any questions already got one?

161
00:07:09,541 --> 00:07:10,541
- [Participant] Alright.

162
00:07:10,541 --> 00:07:11,541
So one

163
00:07:11,541 --> 00:07:13,100
of my favorite things is
relationships correlations

164
00:07:13,100 --> 00:07:15,440
and I'm excited about this CAR upgrade.

165
00:07:15,440 --> 00:07:18,460
So what I wanna know is could you just

166
00:07:18,460 --> 00:07:21,960
give me a little sneak
peek, if you were mentioning

167
00:07:21,960 --> 00:07:24,520
that you'd be able to better correlate

168
00:07:24,520 --> 00:07:28,330
with the data sources, data
components, are you saying

169
00:07:28,330 --> 00:07:31,940
that perhaps we would be able
to have the relationships

170
00:07:31,940 --> 00:07:34,500
between them and the CAR analytics?

171
00:07:34,500 --> 00:07:36,050
Is that what you're saying?

172
00:07:36,050 --> 00:07:38,460
- [Jamie] So just for a
repeat for the live audience

173
00:07:38,460 --> 00:07:40,659
the question was, you
know, getting into those

174
00:07:40,660 --> 00:07:41,660
the future of CAR

175
00:07:41,660 --> 00:07:44,430
and the really integration
of data sources, components

176
00:07:44,430 --> 00:07:46,600
and analytics and all that
logic, you know, what is it

177
00:07:46,600 --> 00:07:47,740
what is the future of, you know,

178
00:07:47,740 --> 00:07:50,410
CAR and the correlation between, you know,

179
00:07:50,410 --> 00:07:52,490
analytics and logic and you know,

180
00:07:52,490 --> 00:07:54,450
these objects that we're
creating regarding data sources

181
00:07:54,450 --> 00:07:55,450
and data components.

182
00:07:55,450 --> 00:07:57,630
- [Lex] Yeah, so really good question

183
00:07:57,630 --> 00:08:00,050
and I'm still trying
to figure that out now.

184
00:08:00,050 --> 00:08:04,210
I think the one aspect of CAR is that

185
00:08:04,210 --> 00:08:06,570
it can give us the platform
to go really in depth.

186
00:08:06,570 --> 00:08:08,490
And, so, as you look at their data models

187
00:08:08,490 --> 00:08:10,490
they have the process,
they have the networking

188
00:08:10,490 --> 00:08:12,770
and then they have two levels below that,

189
00:08:12,770 --> 00:08:16,940
and they have, I believe
the nitty gritty details

190
00:08:16,940 --> 00:08:20,570
of each data source or in their case

191
00:08:20,570 --> 00:08:22,990
their umbrella platform.

192
00:08:22,990 --> 00:08:27,120
And so being able to take like
we saw for command execution

193
00:08:27,120 --> 00:08:30,750
or the command scripting interpreter

194
00:08:30,750 --> 00:08:33,149
what exactly are you
looking for in regards

195
00:08:33,149 --> 00:08:34,679
to the log files that you need to look

196
00:08:34,679 --> 00:08:37,241
at, taking the digital
forensics, the threatening

197
00:08:37,241 --> 00:08:40,140
and the detections perspective and saying

198
00:08:40,140 --> 00:08:42,110
what am I supposed to see?

199
00:08:42,110 --> 00:08:43,740
What do I see in the prefetch files?

200
00:08:43,740 --> 00:08:45,519
What do I see in the SHM cash?

201
00:08:45,519 --> 00:08:48,740
What do I see in any
other type of log files

202
00:08:48,740 --> 00:08:52,029
that can help defenders
build better analytics?

203
00:08:52,029 --> 00:08:54,310
And so we can't really
take up the platform

204
00:08:54,310 --> 00:08:56,768
cause we know we Sigma
and Elastic and all those

205
00:08:56,769 --> 00:08:59,949
other analytic repositories,
so how can we be different?

206
00:08:59,949 --> 00:09:01,250
And so that's a key thing

207
00:09:01,250 --> 00:09:02,420
that we're trying to figure out right now

208
00:09:02,420 --> 00:09:05,620
- [Jamie] Exactly as Lex implied,

209
00:09:05,620 --> 00:09:07,040
it starts with that common language.

210
00:09:07,040 --> 00:09:08,661
So now that we have a
common language, you know,

211
00:09:08,661 --> 00:09:10,410
we can build around,
you know, data sources,

212
00:09:10,410 --> 00:09:11,990
components extend that to CAR

213
00:09:11,990 --> 00:09:14,309
and really connect those
dots where, you know,

214
00:09:14,309 --> 00:09:15,889
ideas that we're kind
of, you know, prototyping

215
00:09:15,889 --> 00:09:17,999
experimenting when the CAR domain,

216
00:09:17,999 --> 00:09:19,300
maybe over time that matures is something

217
00:09:19,300 --> 00:09:21,109
we can actually apply into
Attack and say, you know,

218
00:09:21,110 --> 00:09:22,880
this actually makes sense
in a broad perspective.

219
00:09:22,880 --> 00:09:24,550
So it really is, you know,

220
00:09:24,550 --> 00:09:26,719
I'm really excited to see
what you do, really balancing

221
00:09:26,720 --> 00:09:29,480
and kind of making those very interesting

222
00:09:29,480 --> 00:09:33,430
and very unique projects
play off each other.

223
00:09:33,430 --> 00:09:35,149
Question.

224
00:09:35,149 --> 00:09:40,319
- [Participant 2] (indistinct)

225
00:09:40,319 --> 00:09:45,290
- [Jamie] So the question
for the live audience is,

226
00:09:45,290 --> 00:09:47,620
you know, MITRE is known
for making frameworks,

227
00:09:47,620 --> 00:09:50,420
we love a good PowerPoint,
we love a good white paper,

228
00:09:50,420 --> 00:09:52,529
but what's kind of the future

229
00:09:52,529 --> 00:09:55,519
of tying together multiple
projects like, you know,

230
00:09:55,519 --> 00:09:58,970
defend and we have engage and
we have MITRE ATT&CK in short

231
00:09:58,970 --> 00:10:01,610
we internally recognize and respect

232
00:10:01,610 --> 00:10:03,019
that these are very different projects

233
00:10:03,019 --> 00:10:05,269
but they're very different philosophies.

234
00:10:05,269 --> 00:10:08,970
So we are, you know, interested
in, you know, learning

235
00:10:08,970 --> 00:10:10,980
from each other rather,
you know, if one framework

236
00:10:10,980 --> 00:10:13,899
has an interesting idea
that is applicable consuming

237
00:10:13,899 --> 00:10:17,240
that, that said really
building those static kind

238
00:10:17,240 --> 00:10:19,589
of brittle connections, you know,

239
00:10:19,589 --> 00:10:21,809
in the past we've, you know,
struggled, you know, you know,

240
00:10:21,809 --> 00:10:23,430
every project has its own cadence,

241
00:10:23,430 --> 00:10:26,920
every project has its own
philosophy, really putting those,

242
00:10:26,920 --> 00:10:29,000
you know, neck and neck
sometimes is problematic.

243
00:10:29,000 --> 00:10:31,800
So I think more, you know,
Adam can probably allude

244
00:10:31,800 --> 00:10:34,199
to this later in a following comment

245
00:10:34,200 --> 00:10:36,800
but keeping it more
informal where, you know,

246
00:10:36,800 --> 00:10:38,050
the knowledge is being transferred

247
00:10:38,050 --> 00:10:39,709
but not necessarily framework to framework

248
00:10:39,709 --> 00:10:41,699
connections is probably the sweet spot.

249
00:10:41,700 --> 00:10:43,749
Great question though.

250
00:10:43,749 --> 00:10:45,629
I think I saw a couple more hands.

251
00:10:45,629 --> 00:10:47,879
We have about four minutes.

252
00:10:47,879 --> 00:10:51,699
Don't be shy, but one
thing, I guess while we wait

253
00:10:51,699 --> 00:10:53,920
for people to kind of
stew on potential ideas

254
00:10:53,920 --> 00:10:56,969
a question I had for you was, you know,

255
00:10:56,970 --> 00:10:59,899
I was obviously there
watching you kind of come

256
00:10:59,899 --> 00:11:02,509
from a very practitioner
focused, like, you know,

257
00:11:02,509 --> 00:11:05,819
doing day to day digital
forensics doing blue teaming

258
00:11:05,819 --> 00:11:07,878
and then kind of growing into what good

259
00:11:07,879 --> 00:11:10,300
framework kind of high level approach.

260
00:11:10,300 --> 00:11:12,819
What advice would you give
for someone, you know,

261
00:11:12,819 --> 00:11:14,378
kind of in that same
experience, like, you know,

262
00:11:14,379 --> 00:11:17,399
maybe a hands on detect
engineer or threat hunter.

263
00:11:17,399 --> 00:11:18,399
- [Lex] Yeah.

264
00:11:18,399 --> 00:11:19,730
- [Jamie] And, you know, you
see this like data sources

265
00:11:19,730 --> 00:11:20,730
and data components

266
00:11:20,730 --> 00:11:22,610
and you're like maybe, maybe
some of that jargon, you know,

267
00:11:22,610 --> 00:11:24,939
vibe, some of it's a little bit new

268
00:11:24,939 --> 00:11:26,629
what advice would you give
someone kind of, you know,

269
00:11:26,629 --> 00:11:28,041
making that first step into, Hey

270
00:11:28,041 --> 00:11:30,290
I really want to start to see how I fit

271
00:11:30,290 --> 00:11:31,740
and see myself within this framework.

272
00:11:31,740 --> 00:11:33,809
- [Lex] Ooh, that's a good question.

273
00:11:33,809 --> 00:11:35,620
So like Jamie said, I came

274
00:11:35,620 --> 00:11:39,930
from a digital forensic
background as well as a developer.

275
00:11:39,930 --> 00:11:41,888
So if you don't know about
developers, they're always

276
00:11:41,889 --> 00:11:45,459
in the weeds, literally
in the kernel building

277
00:11:45,459 --> 00:11:48,219
with API calls and getting down to the

278
00:11:48,220 --> 00:11:50,360
the bits and bites, the
ones and zeros, whatever.

279
00:11:50,360 --> 00:11:53,939
So I'm very focused on the details.

280
00:11:53,939 --> 00:11:56,099
And so getting into MITRE ATT&CK

281
00:11:56,100 --> 00:11:59,809
it was a very hard lesson
from Jamie to pull back

282
00:11:59,809 --> 00:12:03,259
and think abstract, think very abstract.

283
00:12:03,259 --> 00:12:06,380
They, I would say that every portion

284
00:12:06,380 --> 00:12:09,990
of MITRE ATT&CK has the
base level of knowledge.

285
00:12:09,990 --> 00:12:10,990
And so things

286
00:12:10,990 --> 00:12:14,100
like command execution and
process creation, right.

287
00:12:14,100 --> 00:12:18,329
I mentioned this, what exactly
is command execution doing?

288
00:12:18,329 --> 00:12:19,529
Is it using a process?

289
00:12:19,529 --> 00:12:22,069
Are you looking at the the CLI?

290
00:12:22,069 --> 00:12:24,649
Are you looking at, you
know, the bash history

291
00:12:24,649 --> 00:12:26,610
And it's just a log file?

292
00:12:26,610 --> 00:12:28,910
You have to understand
what the base level is

293
00:12:28,910 --> 00:12:31,250
and apply that to MITRE ATT&CK,

294
00:12:31,250 --> 00:12:33,809
you can't just go through with it and say

295
00:12:33,809 --> 00:12:36,480
let's get to the details
because I know what it is.

296
00:12:36,480 --> 00:12:37,779
You have to take your knowledge out

297
00:12:37,779 --> 00:12:41,640
of it and look at the base
level and the abstract level.

298
00:12:41,640 --> 00:12:44,610
- [Jamie] I wish we could
pull up another street name.

299
00:12:44,610 --> 00:12:47,899
I think there's a, I have a gif for it,

300
00:12:47,899 --> 00:12:50,550
as Adam would say
directly related to that.

301
00:12:50,550 --> 00:12:51,839
But I think we're coming on times.

302
00:12:51,839 --> 00:12:52,851
We maybe have time for one more question

303
00:12:52,851 --> 00:12:55,139
from the audience.

304
00:12:55,139 --> 00:12:59,550
Over here?

305
00:12:59,550 --> 00:13:06,160
- [Participant 3] (indistinct)

306
00:13:06,160 --> 00:13:10,569
- [Lex] Yes.

307
00:13:10,569 --> 00:13:12,160
So did you wanna
repeat the question first?

308
00:13:12,160 --> 00:13:14,290
- [Jamie] Oh, yes, I forgot my job.

309
00:13:14,290 --> 00:13:15,290
Thank you.

310
00:13:15,290 --> 00:13:17,579
Yes, so the question is right now we have

311
00:13:17,579 --> 00:13:20,019
within the attack model,
it's data sources,

312
00:13:20,019 --> 00:13:22,199
the data components, the techniques.

313
00:13:22,199 --> 00:13:23,699
In the future is there any thought

314
00:13:23,699 --> 00:13:25,899
towards making the mapping
down to the procedure level?

315
00:13:25,899 --> 00:13:28,199
Cause we know within a
technique or a sub technique

316
00:13:28,199 --> 00:13:30,099
there's so much variance
regarding, you know,

317
00:13:30,100 --> 00:13:32,410
the procedures and kind of, you know,

318
00:13:32,410 --> 00:13:34,250
the implementation of
a technique may differ

319
00:13:34,250 --> 00:13:36,160
between adversaries between over time.

320
00:13:36,160 --> 00:13:39,050
There's so much opportunity
for creativity there.

321
00:13:39,050 --> 00:13:40,689
- [Lex] Yeah, and my answer to

322
00:13:40,689 --> 00:13:43,959
that is CAR that's where
that's going to lie

323
00:13:43,959 --> 00:13:47,709
keeping MITRE detections, very abstract.

324
00:13:47,709 --> 00:13:51,050
Like what exactly you're
looking for the verb, the noun

325
00:13:51,050 --> 00:13:52,959
and then the action and then going

326
00:13:52,959 --> 00:13:55,209
into CAR and saying, okay,
there's different levels.

327
00:13:55,209 --> 00:13:56,430
Like I mentioned, you
have your threat hunters,

328
00:13:56,430 --> 00:13:58,670
you have your digital forensics,

329
00:13:58,670 --> 00:14:00,339
you have your detection engineers.

330
00:14:00,339 --> 00:14:02,560
What exactly are they looking
for on those different levels

331
00:14:02,560 --> 00:14:06,849
and how can we apply
detections for those defenders?

332
00:14:06,850 --> 00:14:09,999
- [Jamie] Very selfish,
final question here is

333
00:14:09,999 --> 00:14:13,589
if this intrigued anyone here or anyone

334
00:14:13,589 --> 00:14:16,459
in their live stream or, you
know, watching this six months

335
00:14:16,459 --> 00:14:19,618
two weeks, you know,
whatever amount of time later

336
00:14:19,619 --> 00:14:22,439
how do people contribute ideas
and what are you looking for?

337
00:14:22,439 --> 00:14:25,368
- [Lex] Ooh, this is my favorite question.

338
00:14:25,369 --> 00:14:28,259
So, I, in the public
MITRE ATT&CK Slack Channel

339
00:14:28,259 --> 00:14:30,740
we started the Defensive ATT&CK Channel,

340
00:14:30,740 --> 00:14:32,339
so please come visit me there.

341
00:14:32,339 --> 00:14:36,000
I'm normally like looking
on people on Monday's.

342
00:14:36,000 --> 00:14:38,899
So if you ever have anything
on Monday's, I'm always there.

343
00:14:38,899 --> 00:14:40,740
Of course you can always
hit me up on social media

344
00:14:40,740 --> 00:14:45,370
Twitter, Flex, on the hunt, a pun there.

345
00:14:45,370 --> 00:14:48,179
And then also the email
that Jamie gets bombarded

346
00:14:48,179 --> 00:14:49,179
with all the time.

347
00:14:49,179 --> 00:14:50,399
- [Jamie] They always keep coming.

348
00:14:50,399 --> 00:14:52,589
- [Lex] Yeah, they always
get to me somehow, yeah.

349
00:14:52,589 --> 00:14:53,670
- [Jamie] Thank you so much.

350
00:14:53,670 --> 00:14:54,670
- [Lex] Yeah.

351
00:14:54,670 --> 00:14:54,670
(applause)

