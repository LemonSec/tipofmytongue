1
00:00:11,280 --> 00:00:13,679
hey welcome back to the attack on couch

2
00:00:13,679 --> 00:00:15,599
thank you so much jamie for giving me

3
00:00:15,599 --> 00:00:18,080
time to run back here um we really

4
00:00:18,080 --> 00:00:19,760
wanted to make sure that we prioritize

5
00:00:19,760 --> 00:00:21,840
giving you time with the speakers so for

6
00:00:21,840 --> 00:00:23,680
our online audience thank you again for

7
00:00:23,680 --> 00:00:25,359
joining us i know

8
00:00:25,359 --> 00:00:27,439
looking at the screen is a lot

9
00:00:27,439 --> 00:00:29,519
especially two days in a row but we

10
00:00:29,519 --> 00:00:30,960
really appreciate you being here because

11
00:00:30,960 --> 00:00:32,399
it makes all of the work that all of our

12
00:00:32,399 --> 00:00:35,120
speakers have done so much more worth it

13
00:00:35,120 --> 00:00:37,920
also shameless plug meme contest we're

14
00:00:37,920 --> 00:00:39,360
gonna be announcing it at the closing

15
00:00:39,360 --> 00:00:42,879
ceremony ceremony i have your flag

16
00:00:42,879 --> 00:00:44,640
whoever you will be

17
00:00:44,640 --> 00:00:45,840
um

18
00:00:45,840 --> 00:00:48,079
in my bag so we will be gifting that to

19
00:00:48,079 --> 00:00:48,960
you

20
00:00:48,960 --> 00:00:51,680
at the end of uh closing ceremony so

21
00:00:51,680 --> 00:00:53,520
we'll announce that there and then we'll

22
00:00:53,520 --> 00:00:55,199
be sending it out to you

23
00:00:55,199 --> 00:00:57,360
um that's just for online viewers

24
00:00:57,360 --> 00:00:59,120
again we really appreciate you guys

25
00:00:59,120 --> 00:01:01,680
being here so

26
00:01:01,680 --> 00:01:02,480
now

27
00:01:02,480 --> 00:01:05,119
not on like a resetting um

28
00:01:05,119 --> 00:01:07,040
you all gave a fantastic presentation

29
00:01:07,040 --> 00:01:08,640
would you all like introduce yourselves

30
00:01:08,640 --> 00:01:10,479
really quick just

31
00:01:10,479 --> 00:01:12,880
sure yeah i'll go first um i'm dr ancho

32
00:01:12,880 --> 00:01:14,400
reggae and i'm an associate professor

33
00:01:14,400 --> 00:01:15,920
with the department of criminal justice

34
00:01:15,920 --> 00:01:20,240
at temple and i also direct the care lab

35
00:01:20,240 --> 00:01:22,640
and i am rachel blyman i am a criminal

36
00:01:22,640 --> 00:01:25,520
justice phd student with the care lab at

37
00:01:25,520 --> 00:01:28,080
temple university

38
00:01:28,080 --> 00:01:31,040
and i'm katora williams i'm a doctoral

39
00:01:31,040 --> 00:01:32,560
student in the department of criminal

40
00:01:32,560 --> 00:01:34,720
justice at temple university and also a

41
00:01:34,720 --> 00:01:36,240
graduate research assistant in the care

42
00:01:36,240 --> 00:01:37,200
lab

43
00:01:37,200 --> 00:01:39,360
okay that's really impressive like

44
00:01:39,360 --> 00:01:40,880
doctor doctor doctor

45
00:01:40,880 --> 00:01:43,119
like well in training all right and

46
00:01:43,119 --> 00:01:44,479
training i mean

47
00:01:44,479 --> 00:01:46,159
really impressive because i know there's

48
00:01:46,159 --> 00:01:48,799
so many publications and

49
00:01:48,799 --> 00:01:51,920
thesis and papers and research that

50
00:01:51,920 --> 00:01:53,759
years upon years that go with this and

51
00:01:53,759 --> 00:01:55,360
then money spent right

52
00:01:55,360 --> 00:01:57,759
all of that all of that so thank you so

53
00:01:57,759 --> 00:01:59,520
much because i know that like we

54
00:01:59,520 --> 00:02:00,880
definitely really need our people in

55
00:02:00,880 --> 00:02:03,520
academia to be able to like have

56
00:02:03,520 --> 00:02:05,520
that priority of time of like making the

57
00:02:05,520 --> 00:02:08,080
world like even better right so i really

58
00:02:08,080 --> 00:02:09,440
appreciate that

59
00:02:09,440 --> 00:02:10,959
um it's nice when industries can come

60
00:02:10,959 --> 00:02:12,959
together and like you know companies

61
00:02:12,959 --> 00:02:14,959
that have those research but i feel like

62
00:02:14,959 --> 00:02:16,720
academia is it's a very special

63
00:02:16,720 --> 00:02:18,640
protected place

64
00:02:18,640 --> 00:02:20,800
so i appreciate that um i loved your

65
00:02:20,800 --> 00:02:23,680
discussion today um all about the all of

66
00:02:23,680 --> 00:02:24,879
the points that you made about

67
00:02:24,879 --> 00:02:26,959
non-technical students like reaching out

68
00:02:26,959 --> 00:02:28,720
to them and then the social engineering

69
00:02:28,720 --> 00:02:31,120
was fantastic i am a fan i have an

70
00:02:31,120 --> 00:02:33,360
offensive background so i'm super

71
00:02:33,360 --> 00:02:35,120
and jamie is really good at social

72
00:02:35,120 --> 00:02:37,280
engineering it's like scary it's scary

73
00:02:37,280 --> 00:02:39,680
good yes yeah yeah there's some yeah

74
00:02:39,680 --> 00:02:42,480
yeah and we were lucky we roped him in

75
00:02:42,480 --> 00:02:44,239
last year and he's like what are you all

76
00:02:44,239 --> 00:02:45,760
gonna do and we're like well this and

77
00:02:45,760 --> 00:02:47,280
then we brought him behind the scenes so

78
00:02:47,280 --> 00:02:49,920
you got to see what we were doing and he

79
00:02:49,920 --> 00:02:51,680
actually and this is what i love about

80
00:02:51,680 --> 00:02:53,120
the mitre group right like the attack

81
00:02:53,120 --> 00:02:54,400
group

82
00:02:54,400 --> 00:02:57,040
they gave like jamie actually took time

83
00:02:57,040 --> 00:02:59,760
out of his busy schedule right to engage

84
00:02:59,760 --> 00:03:00,959
with the students to give them an

85
00:03:00,959 --> 00:03:03,120
orientation to help us figure out how

86
00:03:03,120 --> 00:03:05,120
should we do the mappings and we can't

87
00:03:05,120 --> 00:03:06,959
do this alone as educators like we just

88
00:03:06,959 --> 00:03:09,040
can't do this right so when you have

89
00:03:09,040 --> 00:03:11,440
expertise that bring their a game to the

90
00:03:11,440 --> 00:03:12,959
table and i'm not even talking about the

91
00:03:12,959 --> 00:03:14,879
live engagement right just behind the

92
00:03:14,879 --> 00:03:16,640
scenes stuff just helping us understand

93
00:03:16,640 --> 00:03:18,959
the matrix helping us how you know can

94
00:03:18,959 --> 00:03:21,599
students use this um and then of course

95
00:03:21,599 --> 00:03:24,560
he did engage live with the students and

96
00:03:24,560 --> 00:03:27,360
he really wowed us with his social

97
00:03:27,360 --> 00:03:28,959
engineering prowess

98
00:03:28,959 --> 00:03:31,040
he's really good you're right it's scary

99
00:03:31,040 --> 00:03:32,799
good yeah it's scary like i feel like

100
00:03:32,799 --> 00:03:34,879
anyone with that much natural charisma

101
00:03:34,879 --> 00:03:37,040
is just dangerous

102
00:03:37,040 --> 00:03:38,959
yeah i feel like yeah i feel like we

103
00:03:38,959 --> 00:03:42,400
need to rope you in now no no

104
00:03:42,400 --> 00:03:45,200
so um

105
00:03:45,200 --> 00:03:46,879
unsure is that right that is correct so

106
00:03:46,879 --> 00:03:49,599
yeah and sure um so how can attack like

107
00:03:49,599 --> 00:03:51,200
you had mentioned in your talk about

108
00:03:51,200 --> 00:03:52,879
attacking an education tool right can

109
00:03:52,879 --> 00:03:54,720
you kind of expand more on that like how

110
00:03:54,720 --> 00:03:55,519
how

111
00:03:55,519 --> 00:03:57,360
right and one of one of the things that

112
00:03:57,360 --> 00:03:59,120
i think i've struggled with as an

113
00:03:59,120 --> 00:04:01,680
educator is how do i get students to

114
00:04:01,680 --> 00:04:04,080
understand

115
00:04:04,080 --> 00:04:06,080
the adversarial mindset

116
00:04:06,080 --> 00:04:08,480
right and how they think and how they

117
00:04:08,480 --> 00:04:10,720
move through attack chains

118
00:04:10,720 --> 00:04:13,599
um so the attack framework's really been

119
00:04:13,599 --> 00:04:15,840
super useful for that and really helps

120
00:04:15,840 --> 00:04:17,759
students who are not from a technical

121
00:04:17,759 --> 00:04:19,120
background

122
00:04:19,120 --> 00:04:20,798
feel like they can contribute because

123
00:04:20,798 --> 00:04:22,160
that's one of the biggest hurdles that

124
00:04:22,160 --> 00:04:23,840
i've had as an educator is have

125
00:04:23,840 --> 00:04:25,520
non-technical students so we can't do

126
00:04:25,520 --> 00:04:27,280
cyber because we don't know how to code

127
00:04:27,280 --> 00:04:28,400
or we don't know

128
00:04:28,400 --> 00:04:30,160
you know digital forensics i can't but

129
00:04:30,160 --> 00:04:32,000
i'm like you know how people think right

130
00:04:32,000 --> 00:04:33,840
and you know how people work in groups

131
00:04:33,840 --> 00:04:35,440
so how

132
00:04:35,440 --> 00:04:37,199
uh how is this any really different

133
00:04:37,199 --> 00:04:38,639
right in that regards yes it's in a

134
00:04:38,639 --> 00:04:40,320
different context and

135
00:04:40,320 --> 00:04:42,160
um i think that's what the attack

136
00:04:42,160 --> 00:04:44,400
framework has really helped me do as an

137
00:04:44,400 --> 00:04:45,600
educator

138
00:04:45,600 --> 00:04:47,600
is figure out how do we how do we help

139
00:04:47,600 --> 00:04:49,759
students understand these types of

140
00:04:49,759 --> 00:04:53,600
activities that adversaries engage in

141
00:04:53,600 --> 00:04:55,520
awesome yeah

142
00:04:55,520 --> 00:04:57,600
so rachel really so we had talked a

143
00:04:57,600 --> 00:05:00,240
little bit beforehand so fair warning to

144
00:05:00,240 --> 00:05:01,840
the audience um there was a couple

145
00:05:01,840 --> 00:05:03,199
questions that we had talked about that

146
00:05:03,199 --> 00:05:04,479
we felt were really

147
00:05:04,479 --> 00:05:07,280
relevant to ask um so i'm gonna ask

148
00:05:07,280 --> 00:05:08,720
these questions and then i'm gonna sneak

149
00:05:08,720 --> 00:05:11,280
over to your channel um and then we'll

150
00:05:11,280 --> 00:05:12,880
see if there's any in the that channel

151
00:05:12,880 --> 00:05:14,400
really quick so just haven't forgotten

152
00:05:14,400 --> 00:05:17,759
about slack um but rachel how can

153
00:05:17,759 --> 00:05:19,680
non-technical students specifically

154
00:05:19,680 --> 00:05:20,720
right like which is another thing that

155
00:05:20,720 --> 00:05:22,639
you all mentioned um how can they

156
00:05:22,639 --> 00:05:24,400
benefit from attack and what does that

157
00:05:24,400 --> 00:05:27,280
look like right well when i first

158
00:05:27,280 --> 00:05:28,479
started

159
00:05:28,479 --> 00:05:30,880
getting into you know what the care lab

160
00:05:30,880 --> 00:05:32,400
is doing social engineering the cyber

161
00:05:32,400 --> 00:05:35,759
stuff i was a criminal justice student

162
00:05:35,759 --> 00:05:39,120
um i was i actually met anshul um

163
00:05:39,120 --> 00:05:41,199
because i was a student in her class

164
00:05:41,199 --> 00:05:44,080
in undergrad um and it was a cyber crime

165
00:05:44,080 --> 00:05:45,039
class

166
00:05:45,039 --> 00:05:48,400
and i i had a cyber security uh not a

167
00:05:48,400 --> 00:05:50,240
cyber security a computer science minor

168
00:05:50,240 --> 00:05:51,600
so i was doing a little bit of coding

169
00:05:51,600 --> 00:05:53,759
stuff but i wasn't super into it and i

170
00:05:53,759 --> 00:05:55,360
took this class and i

171
00:05:55,360 --> 00:05:56,800
learned that

172
00:05:56,800 --> 00:05:59,360
so much cyber security really does rely

173
00:05:59,360 --> 00:06:01,520
on understanding the human side which is

174
00:06:01,520 --> 00:06:03,440
where you know the liberal arts social

175
00:06:03,440 --> 00:06:05,680
sciences can come in

176
00:06:05,680 --> 00:06:10,319
and when we implemented in class this

177
00:06:10,319 --> 00:06:12,960
attack matrix mapping project it really

178
00:06:12,960 --> 00:06:14,560
shows that

179
00:06:14,560 --> 00:06:17,680
you know in these scenarios these are

180
00:06:17,680 --> 00:06:20,000
cyber security threats and you're able

181
00:06:20,000 --> 00:06:22,319
to understand them without any technical

182
00:06:22,319 --> 00:06:24,880
expertise at all just by looking at the

183
00:06:24,880 --> 00:06:26,240
behavior and understanding the human and

184
00:06:26,240 --> 00:06:28,479
what they're doing

185
00:06:28,479 --> 00:06:31,199
i so love that you said that so like my

186
00:06:31,199 --> 00:06:32,800
former background is actually human

187
00:06:32,800 --> 00:06:35,840
intelligence and it has been amazing to

188
00:06:35,840 --> 00:06:38,160
watch the parallels between

189
00:06:38,160 --> 00:06:38,960
like

190
00:06:38,960 --> 00:06:41,680
humans and the silly things that we do

191
00:06:41,680 --> 00:06:43,759
and then like how i'm just as stupid of

192
00:06:43,759 --> 00:06:46,319
a user as the next one right and then

193
00:06:46,319 --> 00:06:49,120
also understanding like how

194
00:06:49,120 --> 00:06:51,759
it's by understanding ourselves

195
00:06:51,759 --> 00:06:53,280
that we really understand also what the

196
00:06:53,280 --> 00:06:55,039
adversary is doing because the reality

197
00:06:55,039 --> 00:06:56,000
is they're just

198
00:06:56,000 --> 00:06:57,280
they're just another messy human on the

199
00:06:57,280 --> 00:06:59,680
other end right exactly so there's

200
00:06:59,680 --> 00:07:01,599
actually a talk that they had talked

201
00:07:01,599 --> 00:07:03,199
like that had gone to

202
00:07:03,199 --> 00:07:04,639
and i was talking about all of the other

203
00:07:04,639 --> 00:07:06,880
operators on the dark net right like for

204
00:07:06,880 --> 00:07:08,800
trickbots specifically and how it was

205
00:07:08,800 --> 00:07:10,160
actually people that were just trying to

206
00:07:10,160 --> 00:07:11,440
feed their families and they couldn't

207
00:07:11,440 --> 00:07:13,360
get a software development job

208
00:07:13,360 --> 00:07:16,720
so they got a job with trick bot because

209
00:07:16,720 --> 00:07:18,800
it paid yeah and they didn't really care

210
00:07:18,800 --> 00:07:19,840
what they were doing so long as they

211
00:07:19,840 --> 00:07:21,599
were doing development work

212
00:07:21,599 --> 00:07:22,960
and it's it's insane but you're right

213
00:07:22,960 --> 00:07:24,560
it's just humans and understanding

214
00:07:24,560 --> 00:07:26,400
humans there's a human behind every

215
00:07:26,400 --> 00:07:27,360
attack

216
00:07:27,360 --> 00:07:29,039
yes 100

217
00:07:29,039 --> 00:07:30,960
um

218
00:07:30,960 --> 00:07:33,440
couture yes i love that name thank you

219
00:07:33,440 --> 00:07:35,840
you guys have to i love it um

220
00:07:35,840 --> 00:07:37,199
so

221
00:07:37,199 --> 00:07:39,680
as we kind of like you all have

222
00:07:39,680 --> 00:07:43,440
such a great diverse experience

223
00:07:43,440 --> 00:07:45,840
um

224
00:07:45,919 --> 00:07:47,599
as you've been in this field

225
00:07:47,599 --> 00:07:49,199
like what are some obstacles that you've

226
00:07:49,199 --> 00:07:50,800
kind of had to navigate throughout your

227
00:07:50,800 --> 00:07:52,240
career

228
00:07:52,240 --> 00:07:53,039
um

229
00:07:53,039 --> 00:07:55,440
so there's a couple um

230
00:07:55,440 --> 00:07:57,280
first i have like

231
00:07:57,280 --> 00:07:59,199
probably the most diverse background

232
00:07:59,199 --> 00:08:02,080
like i'm the meat like for undergraduate

233
00:08:02,080 --> 00:08:04,240
major hops all over the place so like i

234
00:08:04,240 --> 00:08:06,720
have a psych background i was pre-med

235
00:08:06,720 --> 00:08:07,919
like

236
00:08:07,919 --> 00:08:10,080
i have a neuroscience degree like

237
00:08:10,080 --> 00:08:12,479
he's really yeah really really really

238
00:08:12,479 --> 00:08:14,080
super smart that i can

239
00:08:14,080 --> 00:08:16,160
work like these really random things

240
00:08:16,160 --> 00:08:18,080
that i can do right

241
00:08:18,080 --> 00:08:20,400
so it was trying to figure out like well

242
00:08:20,400 --> 00:08:22,800
where do i fit in like i have all these

243
00:08:22,800 --> 00:08:24,639
like i'm a jack of some trees not all of

244
00:08:24,639 --> 00:08:25,919
some of them so like how do i pull all

245
00:08:25,919 --> 00:08:28,080
these things together to figure out

246
00:08:28,080 --> 00:08:30,479
where i fit in and then i met ancho and

247
00:08:30,479 --> 00:08:32,640
he was like oh it's you have other psych

248
00:08:32,640 --> 00:08:34,320
background you should be talking about

249
00:08:34,320 --> 00:08:36,159
fraud and lying and manipulation i was

250
00:08:36,159 --> 00:08:37,760
like oh yeah when i was a psychologist

251
00:08:37,760 --> 00:08:39,120
that's what i was doing so like we

252
00:08:39,120 --> 00:08:42,320
should and so uh then the social

253
00:08:42,320 --> 00:08:44,000
engineering came in and now i'm starting

254
00:08:44,000 --> 00:08:45,440
to transition into privacy and

255
00:08:45,440 --> 00:08:46,880
surveillance and like all this

256
00:08:46,880 --> 00:08:48,800
psychology and thought behind that so

257
00:08:48,800 --> 00:08:50,399
it's just me trying to figure out like

258
00:08:50,399 --> 00:08:52,959
where i fit in and like how my skill set

259
00:08:52,959 --> 00:08:54,720
works and then there's always like you

260
00:08:54,720 --> 00:08:57,040
got to jump over the boys club and like

261
00:08:57,040 --> 00:08:59,200
tech and everything and then like being

262
00:08:59,200 --> 00:09:00,800
a minority and trying to figure out

263
00:09:00,800 --> 00:09:03,040
where you fit in and and everything so

264
00:09:03,040 --> 00:09:05,440
there's all those like little things

265
00:09:05,440 --> 00:09:08,640
um but for me it's probably like well

266
00:09:08,640 --> 00:09:10,240
what do i do with everything that i know

267
00:09:10,240 --> 00:09:11,920
how to do yeah and like how do i make

268
00:09:11,920 --> 00:09:14,080
money off of it

269
00:09:14,080 --> 00:09:15,760
fair cause that's actually a thing right

270
00:09:15,760 --> 00:09:18,080
we gotta get the student loans back

271
00:09:18,080 --> 00:09:20,640
fingers crossed we won't but you know

272
00:09:20,640 --> 00:09:22,399
so that insider talk must have been

273
00:09:22,399 --> 00:09:24,480
really great then oh yes that's that's

274
00:09:24,480 --> 00:09:26,959
like me i'm like oh i love i love

275
00:09:26,959 --> 00:09:29,279
manipulators like this is all like oh my

276
00:09:29,279 --> 00:09:31,279
god i love it this kind of thing is like

277
00:09:31,279 --> 00:09:33,519
uh that's my jizz like

278
00:09:33,519 --> 00:09:36,000
so oh my god you i love that word right

279
00:09:36,000 --> 00:09:37,760
that is like one of my favorite friend

280
00:09:37,760 --> 00:09:39,360
news that we're like what's your zhu

281
00:09:39,360 --> 00:09:41,600
like is there any judge doing i was like

282
00:09:41,600 --> 00:09:42,880
yeah i don't really feel that yeah

283
00:09:42,880 --> 00:09:44,880
that's not a good sign like i need to

284
00:09:44,880 --> 00:09:46,880
find some of this yeah it's such a great

285
00:09:46,880 --> 00:09:49,040
word for such a not like you can't

286
00:09:49,040 --> 00:09:50,320
really describe you don't know what it

287
00:09:50,320 --> 00:09:51,760
is but you know what it is you know what

288
00:09:51,760 --> 00:09:54,640
it is exactly oh i love it all right so

289
00:09:54,640 --> 00:09:56,560
what let me find your slack room really

290
00:09:56,560 --> 00:09:59,519
quick what is the name of your sacrum um

291
00:09:59,519 --> 00:10:00,480
i think that's it right here yeah

292
00:10:00,480 --> 00:10:02,000
williams it starts with williams bloom's

293
00:10:02,000 --> 00:10:05,200
very game blimey gotcha and i

294
00:10:05,200 --> 00:10:09,360
conveniently have no internet connection

295
00:10:09,519 --> 00:10:13,120
okay so look at big tech letting us down

296
00:10:13,120 --> 00:10:16,720
you know awkward no one look at this um

297
00:10:16,720 --> 00:10:19,440
no worries uh so as that comes back up

298
00:10:19,440 --> 00:10:20,399
um

299
00:10:20,399 --> 00:10:21,839
because it's figuring itself out right

300
00:10:21,839 --> 00:10:23,120
now

301
00:10:23,120 --> 00:10:24,160
uh

302
00:10:24,160 --> 00:10:26,560
well actually uh

303
00:10:26,560 --> 00:10:28,800
it's gonna take it's it's i love live

304
00:10:28,800 --> 00:10:30,399
this is this is why live is awesome

305
00:10:30,399 --> 00:10:32,399
everybody just so we're clear this is

306
00:10:32,399 --> 00:10:34,079
this is the benefit you get from it all

307
00:10:34,079 --> 00:10:35,680
right so you've had lots of people

308
00:10:35,680 --> 00:10:37,360
respond with like excellent projects and

309
00:10:37,360 --> 00:10:38,560
they love the awareness that you're

310
00:10:38,560 --> 00:10:40,959
giving to everyone um for the upcoming

311
00:10:40,959 --> 00:10:43,760
generation i love that comment um so it

312
00:10:43,760 --> 00:10:45,920
looks like not a lot of questions wait

313
00:10:45,920 --> 00:10:48,000
wait

314
00:10:48,000 --> 00:10:49,839
influence in the house

315
00:10:49,839 --> 00:10:52,240
kellogini's influence in the house

316
00:10:52,240 --> 00:10:54,880
oh do we social engineer at home

317
00:10:54,880 --> 00:10:56,959
is that what that means uh i guess yeah

318
00:10:56,959 --> 00:10:58,079
don't we all

319
00:10:58,079 --> 00:11:00,560
yeah

320
00:11:00,560 --> 00:11:02,640
manipulate my husband in some way

321
00:11:02,640 --> 00:11:04,320
god i love it but i also have a child

322
00:11:04,320 --> 00:11:06,160
who's the master of social engineer at

323
00:11:06,160 --> 00:11:08,320
the house so there's that

324
00:11:08,320 --> 00:11:10,079
well it sounds like you guys already hit

325
00:11:10,079 --> 00:11:12,320
up all the questions so seriously thank

326
00:11:12,320 --> 00:11:13,760
you so much that was a fantastic talk

327
00:11:13,760 --> 00:11:15,680
and thanks for having us yes i really

328
00:11:15,680 --> 00:11:16,560
appreciate you guys bringing your

329
00:11:16,560 --> 00:11:17,760
perspective

330
00:11:17,760 --> 00:11:19,279
all right all right well you guys have a

331
00:11:19,279 --> 00:11:20,880
great rest of the conference enjoy the

332
00:11:20,880 --> 00:11:23,200
closing ceremony thank you sorry and

333
00:11:23,200 --> 00:11:25,040
we'll see you soon all right

334
00:11:25,040 --> 00:11:25,920
all right

335
00:11:25,920 --> 00:11:28,000
so thank you guys so much for joining us

336
00:11:28,000 --> 00:11:29,600
um make sure to post your questions in

337
00:11:29,600 --> 00:11:31,600
the slack channel i am checking them i

338
00:11:31,600 --> 00:11:33,040
promise um

339
00:11:33,040 --> 00:11:34,560
uh just not at the beginning of the

340
00:11:34,560 --> 00:11:37,120
talks so uh we're gonna bring up our

341
00:11:37,120 --> 00:11:38,720
next speakers

342
00:11:38,720 --> 00:11:40,560
come on

343
00:11:40,560 --> 00:11:43,760
snap attack hey how's it going good

344
00:11:43,760 --> 00:11:46,079
um so thank you so much for your

345
00:11:46,079 --> 00:11:48,640
presentation today that i alright so the

346
00:11:48,640 --> 00:11:51,120
fact that you're a physicist i i love

347
00:11:51,120 --> 00:11:54,000
that i've heard so many things

348
00:11:54,000 --> 00:11:55,120
so when i was going through my computer

349
00:11:55,120 --> 00:11:56,639
science degree we were in the same

350
00:11:56,639 --> 00:11:58,560
building as our physics department

351
00:11:58,560 --> 00:11:59,680
and

352
00:11:59,680 --> 00:12:01,920
they were the best problem solvers

353
00:12:01,920 --> 00:12:04,000
uh they are because everything has to be

354
00:12:04,000 --> 00:12:06,399
applied right so as an experimental

355
00:12:06,399 --> 00:12:08,639
physicist i can't just solve a problem

356
00:12:08,639 --> 00:12:10,399
publish a paper i have to solve a

357
00:12:10,399 --> 00:12:12,399
problem and then run an experiment and

358
00:12:12,399 --> 00:12:14,000
if it doesn't work your funding is

359
00:12:14,000 --> 00:12:15,600
pulled so like you have a lot of

360
00:12:15,600 --> 00:12:17,279
incentive to get it right yeah super

361
00:12:17,279 --> 00:12:19,040
high stakes

362
00:12:19,040 --> 00:12:20,480
um could you guys introduce yourselves

363
00:12:20,480 --> 00:12:21,839
really quick for the audience right so

364
00:12:21,839 --> 00:12:23,200
i'm jonathan mulholland so i'm the

365
00:12:23,200 --> 00:12:25,440
director of ai at snap attack

366
00:12:25,440 --> 00:12:27,040
and i'm fred frey i'm the cto and

367
00:12:27,040 --> 00:12:29,440
co-founder of snap attack nice so we got

368
00:12:29,440 --> 00:12:31,279
two high title positions up here

369
00:12:31,279 --> 00:12:32,480
presented well when you're in a small

370
00:12:32,480 --> 00:12:34,639
company uh five months old

371
00:12:34,639 --> 00:12:36,240
all the titles are pretty pretty snazzy

372
00:12:36,240 --> 00:12:37,920
sound yeah everybody gets a nice title

373
00:12:37,920 --> 00:12:39,519
when you got this many people awesome it

374
00:12:39,519 --> 00:12:41,360
sounds like so in the military that i

375
00:12:41,360 --> 00:12:42,959
was in um one of the things they did

376
00:12:42,959 --> 00:12:45,040
they would give you really sexy titles

377
00:12:45,040 --> 00:12:46,880
and like and we'd always like reframe

378
00:12:46,880 --> 00:12:48,720
them to be like and i'm a lawn escaping

379
00:12:48,720 --> 00:12:49,760
architect

380
00:12:49,760 --> 00:12:51,839
like i might be a human intelligence

381
00:12:51,839 --> 00:12:54,320
collector but really i am a landscape

382
00:12:54,320 --> 00:12:55,279
master

383
00:12:55,279 --> 00:12:57,600
like because the reality was the work as

384
00:12:57,600 --> 00:12:59,279
well do it all yeah you've got to do it

385
00:12:59,279 --> 00:13:01,519
all work is work you know like it's like

386
00:13:01,519 --> 00:13:04,079
10 percent cool and sexy and then like

387
00:13:04,079 --> 00:13:05,519
90

388
00:13:05,519 --> 00:13:08,000
oh like all of this to do the cool and

389
00:13:08,000 --> 00:13:11,120
sexy right totally so um what really

390
00:13:11,120 --> 00:13:12,240
like so

391
00:13:12,240 --> 00:13:13,600
i really liked how you guys kind of

392
00:13:13,600 --> 00:13:15,040
broke things down between the red and

393
00:13:15,040 --> 00:13:17,760
the blue um what were some lessons that

394
00:13:17,760 --> 00:13:20,480
you didn't expect to find that you found

395
00:13:20,480 --> 00:13:22,880
that's a good question um so i mean it's

396
00:13:22,880 --> 00:13:24,160
always been a challenge like getting the

397
00:13:24,160 --> 00:13:26,320
red and blue teams together so um in our

398
00:13:26,320 --> 00:13:28,240
previous life we stood up threat hunt

399
00:13:28,240 --> 00:13:30,399
teams for large organizations and one of

400
00:13:30,399 --> 00:13:32,320
the one of the challenges was how do we

401
00:13:32,320 --> 00:13:34,000
collaborate between red teams and blue

402
00:13:34,000 --> 00:13:36,160
teams and you know one way is through

403
00:13:36,160 --> 00:13:38,959
blog posting and texting and you know um

404
00:13:38,959 --> 00:13:41,600
kind of like this like you know surprise

405
00:13:41,600 --> 00:13:44,160
like communication uh we stood up esx

406
00:13:44,160 --> 00:13:46,639
servers and vms and stuff like that um

407
00:13:46,639 --> 00:13:48,480
and that really helped out a lot of like

408
00:13:48,480 --> 00:13:49,440
trying to

409
00:13:49,440 --> 00:13:52,160
get collaboration going but then we

410
00:13:52,160 --> 00:13:54,160
really realized that red teamers when

411
00:13:54,160 --> 00:13:55,760
they do an attack the attack never

412
00:13:55,760 --> 00:13:58,240
changes so so one thing that's important

413
00:13:58,240 --> 00:14:00,240
is let's memorialize that right they go

414
00:14:00,240 --> 00:14:02,320
through a lot of effort to to perform an

415
00:14:02,320 --> 00:14:04,160
attack whether it be a lateral movement

416
00:14:04,160 --> 00:14:05,760
or set up infrastructure of a domain

417
00:14:05,760 --> 00:14:08,720
controller and do kerberos all of these

418
00:14:08,720 --> 00:14:10,320
attacks take a lot of time energy and

419
00:14:10,320 --> 00:14:12,079
effort but we don't have to redo them

420
00:14:12,079 --> 00:14:13,360
over and over again so why don't we

421
00:14:13,360 --> 00:14:15,519
create a platform that memorializes that

422
00:14:15,519 --> 00:14:18,160
attack um one time and then we put it up

423
00:14:18,160 --> 00:14:20,079
on a shelf and then the question is like

424
00:14:20,079 --> 00:14:21,839
well how do you communicate that right i

425
00:14:21,839 --> 00:14:24,160
mean a bunch of logs is the obvious way

426
00:14:24,160 --> 00:14:26,399
but if you can synchronize the video of

427
00:14:26,399 --> 00:14:28,480
what the attacker did at the exact same

428
00:14:28,480 --> 00:14:30,320
time

429
00:14:30,320 --> 00:14:31,760
if you can synchronize the video of what

430
00:14:31,760 --> 00:14:33,760
the hacker typed the keystrokes of what

431
00:14:33,760 --> 00:14:34,880
they typed

432
00:14:34,880 --> 00:14:36,800
the logs of what the forensic evidence

433
00:14:36,800 --> 00:14:38,320
put off and you can capture that one

434
00:14:38,320 --> 00:14:40,240
time and then share that out to a wide

435
00:14:40,240 --> 00:14:41,839
audience then we don't have to recreate

436
00:14:41,839 --> 00:14:43,519
the wheel every time somebody can

437
00:14:43,519 --> 00:14:45,600
reference that as almost a wikipedia of

438
00:14:45,600 --> 00:14:47,440
threats so that was kind of our goal

439
00:14:47,440 --> 00:14:48,880
setting out

440
00:14:48,880 --> 00:14:51,440
i love that because there's so much work

441
00:14:51,440 --> 00:14:53,199
when it comes to a lot of these things

442
00:14:53,199 --> 00:14:54,639
so like cutting out that like i feel

443
00:14:54,639 --> 00:14:56,160
like one thing that has been very

444
00:14:56,160 --> 00:14:57,199
consistent through this entire

445
00:14:57,199 --> 00:14:59,600
conference is like that mental energy

446
00:14:59,600 --> 00:15:01,519
like what do you only have so much of it

447
00:15:01,519 --> 00:15:03,279
that's right so what do you spend it on

448
00:15:03,279 --> 00:15:04,880
yeah and i mean like the solar winds

449
00:15:04,880 --> 00:15:06,880
like i mean everybody was so burnt out

450
00:15:06,880 --> 00:15:09,040
because we were all recreating the wheel

451
00:15:09,040 --> 00:15:10,800
right um and if

452
00:15:10,800 --> 00:15:12,399
we what we really need is i think

453
00:15:12,399 --> 00:15:14,000
infosec is a team sport right i didn't

454
00:15:14,000 --> 00:15:15,120
coin that somebody else said but it's

455
00:15:15,120 --> 00:15:16,480
it's something that we really believe in

456
00:15:16,480 --> 00:15:18,639
it's a team sport um you know we all

457
00:15:18,639 --> 00:15:20,800
have our roles so

458
00:15:20,800 --> 00:15:22,079
you know one of the challenging things

459
00:15:22,079 --> 00:15:23,199
is how do you know when you have to

460
00:15:23,199 --> 00:15:24,959
recreate the reel or when you don't have

461
00:15:24,959 --> 00:15:26,240
to recreate the reel and you can use

462
00:15:26,240 --> 00:15:28,639
something off the shelf versus uh when

463
00:15:28,639 --> 00:15:30,160
you are the first person and then when

464
00:15:30,160 --> 00:15:31,440
you're the first person how do you share

465
00:15:31,440 --> 00:15:33,199
that to a large audience right so they

466
00:15:33,199 --> 00:15:34,880
don't have to recreate the reel

467
00:15:34,880 --> 00:15:37,120
that's that's a real challenge right

468
00:15:37,120 --> 00:15:38,480
yeah it's tricky too and you're the

469
00:15:38,480 --> 00:15:39,600
first person because then you're also

470
00:15:39,600 --> 00:15:40,959
the steward

471
00:15:40,959 --> 00:15:42,480
so then you have to go through that like

472
00:15:42,480 --> 00:15:44,560
what should i release and if i release

473
00:15:44,560 --> 00:15:46,240
this and what other ways would it be

474
00:15:46,240 --> 00:15:48,720
used for good or evil yeah definitely a

475
00:15:48,720 --> 00:15:50,639
dual age sword absolutely i mean any red

476
00:15:50,639 --> 00:15:52,880
team technique tool everything it brings

477
00:15:52,880 --> 00:15:54,639
awareness but it also brings risk in

478
00:15:54,639 --> 00:15:56,240
danger right yeah

479
00:15:56,240 --> 00:15:59,440
so um what is one question that you guys

480
00:15:59,440 --> 00:16:02,399
wish i would ask you

481
00:16:02,639 --> 00:16:06,000
um i'd well so i mean at being in charge

482
00:16:06,000 --> 00:16:09,279
of ai and data science uh one thing that

483
00:16:09,279 --> 00:16:11,199
i'm always coming back to is you know

484
00:16:11,199 --> 00:16:14,240
why is data science and ml in um cyber

485
00:16:14,240 --> 00:16:16,800
so hard yeah right so that's a great

486
00:16:16,800 --> 00:16:18,480
question because it's so successful in

487
00:16:18,480 --> 00:16:20,160
other fields right you have this image

488
00:16:20,160 --> 00:16:22,480
recognitions amazingly successful right

489
00:16:22,480 --> 00:16:24,880
like language processing is becoming

490
00:16:24,880 --> 00:16:27,360
almost as successful and so why haven't

491
00:16:27,360 --> 00:16:30,240
we figured this out cyber and the

492
00:16:30,240 --> 00:16:33,440
issue really is that cyber data is so

493
00:16:33,440 --> 00:16:35,519
complex and nuanced right if you have

494
00:16:35,519 --> 00:16:38,320
one data type with image imagery right

495
00:16:38,320 --> 00:16:40,000
it's just an image if you figure out how

496
00:16:40,000 --> 00:16:42,000
to process that image you're done with

497
00:16:42,000 --> 00:16:43,839
cyber right you have many different log

498
00:16:43,839 --> 00:16:46,160
types right you have different os's and

499
00:16:46,160 --> 00:16:49,120
even within a certain log like paradigm

500
00:16:49,120 --> 00:16:51,040
right if you have sysmon data

501
00:16:51,040 --> 00:16:52,800
um you have a whole bunch of bunch of

502
00:16:52,800 --> 00:16:54,320
different type of event types and each

503
00:16:54,320 --> 00:16:55,680
of those you have to treat differently

504
00:16:55,680 --> 00:16:57,040
and they might have to cross-reference

505
00:16:57,040 --> 00:16:59,440
to even make sense of one you know log

506
00:16:59,440 --> 00:17:01,600
entry over here and that's kind of

507
00:17:01,600 --> 00:17:03,440
unique in data science data scientists

508
00:17:03,440 --> 00:17:05,199
are often used to being able to grab one

509
00:17:05,199 --> 00:17:06,880
or two pieces of information and just

510
00:17:06,880 --> 00:17:08,240
using them they don't have to correlate

511
00:17:08,240 --> 00:17:10,000
across you know a dozen different

512
00:17:10,000 --> 00:17:11,520
domains and add like three different

513
00:17:11,520 --> 00:17:13,039
types of context to make sense of

514
00:17:13,039 --> 00:17:14,559
something so that's something we're

515
00:17:14,559 --> 00:17:15,919
trying to collect on the platform is

516
00:17:15,919 --> 00:17:17,359
let's get everything in one place and

517
00:17:17,359 --> 00:17:19,439
make sense of it within this idea of

518
00:17:19,439 --> 00:17:22,319
this red blue paradigm so

519
00:17:22,319 --> 00:17:23,760
that makes sense and i remember so when

520
00:17:23,760 --> 00:17:25,119
i was doing a lot of thread hunting i

521
00:17:25,119 --> 00:17:26,400
remember one of the biggest problems i

522
00:17:26,400 --> 00:17:28,079
would have is finding the clean data

523
00:17:28,079 --> 00:17:30,240
like identifying what's actually needed

524
00:17:30,240 --> 00:17:32,400
in those data sets so that's so messy so

525
00:17:32,400 --> 00:17:34,320
the more complex the system is

526
00:17:34,320 --> 00:17:36,799
those data sets and those

527
00:17:36,799 --> 00:17:38,400
right that's one of the one of the keys

528
00:17:38,400 --> 00:17:40,080
for these red sessions so these attack

529
00:17:40,080 --> 00:17:42,240
sessions we create the attacker gets to

530
00:17:42,240 --> 00:17:44,640
add a red marker right where the exploit

531
00:17:44,640 --> 00:17:46,799
is and it can go right down to it's it's

532
00:17:46,799 --> 00:17:48,960
an interface where you just label either

533
00:17:48,960 --> 00:17:51,520
process or you know a log line

534
00:17:51,520 --> 00:17:52,960
and it's very easy for a blue team

535
00:17:52,960 --> 00:17:54,720
member to go in and say okay well okay i

536
00:17:54,720 --> 00:17:56,799
can see you know a video of how this

537
00:17:56,799 --> 00:17:58,720
attack executed and i can see exactly

538
00:17:58,720 --> 00:18:00,720
the log they tagged say this is where

539
00:18:00,720 --> 00:18:02,480
the bad stuff happened so it's very easy

540
00:18:02,480 --> 00:18:04,320
to clean up data very easy to pull in

541
00:18:04,320 --> 00:18:06,320
like a window of logs around that time

542
00:18:06,320 --> 00:18:07,919
and say this is what i need to look at

543
00:18:07,919 --> 00:18:09,360
yeah so

544
00:18:09,360 --> 00:18:11,120
yeah actually just add to that like

545
00:18:11,120 --> 00:18:13,120
that's that's also one of our long-term

546
00:18:13,120 --> 00:18:15,280
goals is to label data right so we think

547
00:18:15,280 --> 00:18:16,880
that mitre attack is the way that we

548
00:18:16,880 --> 00:18:19,039
should label um you know as you classify

549
00:18:19,039 --> 00:18:20,480
oh yeah not just saying it because here

550
00:18:20,480 --> 00:18:21,679
it's built into the platform we've been

551
00:18:21,679 --> 00:18:23,919
working on for a while um but labels in

552
00:18:23,919 --> 00:18:25,679
our platform are miter attack labels and

553
00:18:25,679 --> 00:18:27,440
we think that's really powerful because

554
00:18:27,440 --> 00:18:30,160
um you know if you look at like t1003 uh

555
00:18:30,160 --> 00:18:32,559
lsas dumping um then we can all get on

556
00:18:32,559 --> 00:18:34,400
the same page right as a red teamer

557
00:18:34,400 --> 00:18:36,080
there's a metasploit module that does

558
00:18:36,080 --> 00:18:38,559
t1003 there's an atomic red there's

559
00:18:38,559 --> 00:18:40,320
there's um you know humans that do it

560
00:18:40,320 --> 00:18:42,320
you can inject it right into a dll into

561
00:18:42,320 --> 00:18:43,760
memory there's lots of different ways

562
00:18:43,760 --> 00:18:45,840
you can do t1003

563
00:18:45,840 --> 00:18:48,000
um and so what are all those data so

564
00:18:48,000 --> 00:18:50,240
when we train data sets for for ai in

565
00:18:50,240 --> 00:18:51,760
the future right we're nowhere near that

566
00:18:51,760 --> 00:18:54,240
but what we need is a lot of data

567
00:18:54,240 --> 00:18:56,480
cleanly labeled and we need robust uh

568
00:18:56,480 --> 00:18:58,240
cases right um there's a great talk

569
00:18:58,240 --> 00:19:00,880
talking about um you know process access

570
00:19:00,880 --> 00:19:03,360
that um that was done by the team um

571
00:19:03,360 --> 00:19:05,200
yesterday and uh

572
00:19:05,200 --> 00:19:06,720
you know there's so many variations if

573
00:19:06,720 --> 00:19:08,720
you only detect on one ff you're going

574
00:19:08,720 --> 00:19:10,400
to be missing a lot of process

575
00:19:10,400 --> 00:19:13,360
injections so i think the idea is to you

576
00:19:13,360 --> 00:19:14,400
know bring up

577
00:19:14,400 --> 00:19:15,919
many variations to figure out what

578
00:19:15,919 --> 00:19:17,760
variables the hackers have control over

579
00:19:17,760 --> 00:19:19,840
and they can vary and then which can

580
00:19:19,840 --> 00:19:20,640
which

581
00:19:20,640 --> 00:19:22,559
are our kind of checkmate

582
00:19:22,559 --> 00:19:25,039
that they have to do because you cannot

583
00:19:25,039 --> 00:19:27,840
add a service to the you know the

584
00:19:27,840 --> 00:19:28,880
windows operating system without

585
00:19:28,880 --> 00:19:30,640
touching this registry key right you

586
00:19:30,640 --> 00:19:33,039
don't have to use sc.exe or you know

587
00:19:33,039 --> 00:19:34,880
service create but you do have to add

588
00:19:34,880 --> 00:19:37,360
this registry key so finding the the

589
00:19:37,360 --> 00:19:40,320
bottlenecks of attackers um that they

590
00:19:40,320 --> 00:19:41,679
have to do otherwise the operating

591
00:19:41,679 --> 00:19:42,880
system won't

592
00:19:42,880 --> 00:19:44,320
won't actually add a service that's

593
00:19:44,320 --> 00:19:45,600
really critical it's really hard

594
00:19:45,600 --> 00:19:47,919
research but the more variations of that

595
00:19:47,919 --> 00:19:50,720
data we get um the better at chances of

596
00:19:50,720 --> 00:19:52,799
finding that right and having everything

597
00:19:52,799 --> 00:19:55,280
uh unified under a common language so we

598
00:19:55,280 --> 00:19:57,200
can say if you're trying to find these

599
00:19:57,200 --> 00:19:59,200
commonalities okay i'm looking at this

600
00:19:59,200 --> 00:20:00,880
particular sub technique and then having

601
00:20:00,880 --> 00:20:03,280
things the data already grouped at in

602
00:20:03,280 --> 00:20:05,360
those sub techniques allows you to find

603
00:20:05,360 --> 00:20:07,840
those commonalities and and you know you

604
00:20:07,840 --> 00:20:09,440
don't have to do all this pre-filtering

605
00:20:09,440 --> 00:20:11,280
and research into what's actually in the

606
00:20:11,280 --> 00:20:12,799
data right it's already it's already

607
00:20:12,799 --> 00:20:14,880
labeled yeah i can actually see and then

608
00:20:14,880 --> 00:20:17,039
having experts like red teamers come in

609
00:20:17,039 --> 00:20:18,640
i can also see that generating really

610
00:20:18,640 --> 00:20:20,320
good conversation with the community

611
00:20:20,320 --> 00:20:21,679
being like is this really where this

612
00:20:21,679 --> 00:20:24,080
happens or is it actually here

613
00:20:24,080 --> 00:20:25,760
but we do need to wrap up and this is an

614
00:20:25,760 --> 00:20:27,600
amazing discussion and i really want to

615
00:20:27,600 --> 00:20:29,600
continue it so we're clear so i would

616
00:20:29,600 --> 00:20:31,919
definitely recommend um

617
00:20:31,919 --> 00:20:33,840
be sure to for those of you that are

618
00:20:33,840 --> 00:20:35,440
online uh

619
00:20:35,440 --> 00:20:37,440
i know you guys are down to continue to

620
00:20:37,440 --> 00:20:38,880
talk about this um there's a slack room

621
00:20:38,880 --> 00:20:40,400
keep asking questions all of our

622
00:20:40,400 --> 00:20:42,640
speakers are on it um so we can

623
00:20:42,640 --> 00:20:43,840
definitely continue that conversation

624
00:20:43,840 --> 00:20:45,600
here but thank you guys so much sign up

625
00:20:45,600 --> 00:20:47,520
today we uh we dropped the release today

626
00:20:47,520 --> 00:20:50,559
so sign up uh snap attack.com community

627
00:20:50,559 --> 00:20:52,960
thank you i really appreciate that yeah

628
00:20:52,960 --> 00:20:53,919
so

629
00:20:53,919 --> 00:20:55,679
we're gonna bring on what we're gonna

630
00:20:55,679 --> 00:20:57,600
kind of do now is because i'm gonna be

631
00:20:57,600 --> 00:20:59,120
part of the closing remarks ceremony so

632
00:20:59,120 --> 00:21:00,880
you all are tracking we're gonna be

633
00:21:00,880 --> 00:21:02,720
announcing the

634
00:21:02,720 --> 00:21:06,159
name winner so you have like until now

635
00:21:06,159 --> 00:21:07,039
until

636
00:21:07,039 --> 00:21:08,640
honestly i would do it before closing

637
00:21:08,640 --> 00:21:09,840
ceremony because at some point we got to

638
00:21:09,840 --> 00:21:12,400
stop looking at the computer right so um

639
00:21:12,400 --> 00:21:13,760
so before closing ceremony so we can

640
00:21:13,760 --> 00:21:15,840
decide who is going to be our

641
00:21:15,840 --> 00:21:18,559
meme winner and you'll get the attack

642
00:21:18,559 --> 00:21:20,960
flag so um we're going to go ahead and

643
00:21:20,960 --> 00:21:22,480
hit up our speakers that are going to

644
00:21:22,480 --> 00:21:24,320
come in the future so we're going to try

645
00:21:24,320 --> 00:21:26,159
not to hit too much of their talk and

646
00:21:26,159 --> 00:21:27,520
what they're going to be going over but

647
00:21:27,520 --> 00:21:28,799
we do want to give you a little bit of

648
00:21:28,799 --> 00:21:30,960
insight so i'll let you go ahead and

649
00:21:30,960 --> 00:21:33,360
introduce yourself hi i'm brian donahue

650
00:21:33,360 --> 00:21:35,280
i'm a principal security specialist at

651
00:21:35,280 --> 00:21:37,440
red canary and i'm going to be talking

652
00:21:37,440 --> 00:21:39,280
primarily today about atomic red team

653
00:21:39,280 --> 00:21:41,520
which is a open source adversary

654
00:21:41,520 --> 00:21:44,159
emulation library of tests really that

655
00:21:44,159 --> 00:21:46,960
emulate abstract behaviors i am a huge

656
00:21:46,960 --> 00:21:50,080
fan of atomic red team great i know that

657
00:21:50,080 --> 00:21:51,760
you guys presented atomic red team

658
00:21:51,760 --> 00:21:53,600
initially at the first attack on right

659
00:21:53,600 --> 00:21:54,640
yeah i was thinking about that i was

660
00:21:54,640 --> 00:21:56,240
here at that attack count i was like who

661
00:21:56,240 --> 00:21:58,240
presented and i think it was brian bio

662
00:21:58,240 --> 00:22:00,720
our ceo i hope it was

663
00:22:00,720 --> 00:22:02,640
embarrassing myself if it wasn't

664
00:22:02,640 --> 00:22:04,559
no it's such a really cool evolution to

665
00:22:04,559 --> 00:22:06,480
be like at the first attack con and then

666
00:22:06,480 --> 00:22:08,240
to be here and be able to speak on it

667
00:22:08,240 --> 00:22:10,480
again and it's been such a successful

668
00:22:10,480 --> 00:22:12,240
project that you're able to talk about

669
00:22:12,240 --> 00:22:14,080
it yeah and for the first time really

670
00:22:14,080 --> 00:22:16,080
like ever we have a proper team built

671
00:22:16,080 --> 00:22:19,120
around it so my co-presenter who's uh

672
00:22:19,120 --> 00:22:20,400
not here because he lives all the way

673
00:22:20,400 --> 00:22:21,760
across the country and it was kind of

674
00:22:21,760 --> 00:22:23,679
insane to fly across the country for a

675
00:22:23,679 --> 00:22:26,159
15-minute talk um so he's sort of like a

676
00:22:26,159 --> 00:22:29,679
the pride product manager for atomic red

677
00:22:29,679 --> 00:22:31,919
team so we like really now we've gotten

678
00:22:31,919 --> 00:22:34,159
very very like

679
00:22:34,159 --> 00:22:36,559
uh like professional about how we're

680
00:22:36,559 --> 00:22:38,320
working on it and developing it so like

681
00:22:38,320 --> 00:22:39,679
what i'm basically going to be talking

682
00:22:39,679 --> 00:22:42,000
about today is how we've taken an

683
00:22:42,000 --> 00:22:43,919
approach to like figure out

684
00:22:43,919 --> 00:22:46,720
what our coverage actually looks like um

685
00:22:46,720 --> 00:22:48,880
kind of starting with like defining what

686
00:22:48,880 --> 00:22:50,799
is coverage in the context of atomic red

687
00:22:50,799 --> 00:22:52,720
team against mitre attack so like for

688
00:22:52,720 --> 00:22:54,720
everyone out there who may or may not be

689
00:22:54,720 --> 00:22:56,880
familiar with atomic red team it's

690
00:22:56,880 --> 00:22:58,640
mapped to minor attack like mito attack

691
00:22:58,640 --> 00:23:00,080
is the classification system we used to

692
00:23:00,080 --> 00:23:01,760
organize it so

693
00:23:01,760 --> 00:23:03,280
um for the first time ever we're saying

694
00:23:03,280 --> 00:23:04,720
like okay well here's how we define

695
00:23:04,720 --> 00:23:06,480
coverage and there's intuitive and

696
00:23:06,480 --> 00:23:07,840
non-intuitive ways that we're thinking

697
00:23:07,840 --> 00:23:10,640
about that um and then also like here's

698
00:23:10,640 --> 00:23:11,919
how we go about actually determining

699
00:23:11,919 --> 00:23:13,760
what that what that coverage looks like

700
00:23:13,760 --> 00:23:16,960
so that we can perform gap analysis and

701
00:23:16,960 --> 00:23:19,840
uh improve the product like not only to

702
00:23:19,840 --> 00:23:21,760
tell people like hey go contribute over

703
00:23:21,760 --> 00:23:22,559
there

704
00:23:22,559 --> 00:23:23,440
um

705
00:23:23,440 --> 00:23:25,679
or like contribute for this tactic but

706
00:23:25,679 --> 00:23:28,159
also so that like users of the platform

707
00:23:28,159 --> 00:23:30,400
who may never have any intention to

708
00:23:30,400 --> 00:23:32,799
contribute to it understand like what

709
00:23:32,799 --> 00:23:34,799
they're getting out of atomic red team

710
00:23:34,799 --> 00:23:37,600
as a product that's awesome that you

711
00:23:37,600 --> 00:23:38,720
guys are offering that support i

712
00:23:38,720 --> 00:23:40,080
actually know a lot of people that what

713
00:23:40,080 --> 00:23:41,679
they've done is they literally sit down

714
00:23:41,679 --> 00:23:43,440
with their blue teams and they're a red

715
00:23:43,440 --> 00:23:45,600
teamer and they have atomic red team

716
00:23:45,600 --> 00:23:47,279
pulled up and they're running each test

717
00:23:47,279 --> 00:23:49,520
one by one and they're talking with

718
00:23:49,520 --> 00:23:50,640
their blue team like okay now what do

719
00:23:50,640 --> 00:23:52,159
you see and then they're coaching them

720
00:23:52,159 --> 00:23:53,760
through it and so i've seen it such a

721
00:23:53,760 --> 00:23:55,919
useful tool that is available and open

722
00:23:55,919 --> 00:23:59,120
for people and in shameless plugs so one

723
00:23:59,120 --> 00:24:01,120
of the things i work on at canary is our

724
00:24:01,120 --> 00:24:02,480
annual threat detection report which we

725
00:24:02,480 --> 00:24:03,760
just dropped last week so if you're one

726
00:24:03,760 --> 00:24:05,919
of those people out there who's like

727
00:24:05,919 --> 00:24:08,000
going through the attack matrix just

728
00:24:08,000 --> 00:24:10,400
going like from top left to bottom right

729
00:24:10,400 --> 00:24:12,559
running atomic red team tests like

730
00:24:12,559 --> 00:24:14,320
maybe don't do it that way like a better

731
00:24:14,320 --> 00:24:15,760
way to do it maybe is to look at like

732
00:24:15,760 --> 00:24:17,279
the threat detection report and look at

733
00:24:17,279 --> 00:24:19,200
the rankings for mito attack techniques

734
00:24:19,200 --> 00:24:20,880
in there uh because they're ranked by

735
00:24:20,880 --> 00:24:22,799
prevalence right so like your testing

736
00:24:22,799 --> 00:24:24,720
should probably go by prevalence as well

737
00:24:24,720 --> 00:24:27,120
so right start with those things that uh

738
00:24:27,120 --> 00:24:29,279
are most likely to occur and then move

739
00:24:29,279 --> 00:24:30,799
down the list of those things that are

740
00:24:30,799 --> 00:24:32,960
less likely to occur so that is an

741
00:24:32,960 --> 00:24:34,559
excellent point and like and perfect

742
00:24:34,559 --> 00:24:36,159
being with the entire conference right

743
00:24:36,159 --> 00:24:37,520
like so many different talks have been

744
00:24:37,520 --> 00:24:39,520
about like how can we integrate like

745
00:24:39,520 --> 00:24:40,880
prioritizing with cyber threat

746
00:24:40,880 --> 00:24:43,039
intelligence first versus just like

747
00:24:43,039 --> 00:24:44,559
hitting the gambit

748
00:24:44,559 --> 00:24:46,400
so it's a super valid point is there

749
00:24:46,400 --> 00:24:48,480
anything that you want to say so

750
00:24:48,480 --> 00:24:49,919
our online viewers are kind of like

751
00:24:49,919 --> 00:24:51,600
exclusively getting this content during

752
00:24:51,600 --> 00:24:53,760
the conference um so

753
00:24:53,760 --> 00:24:55,840
it sounds fancy but really what it is

754
00:24:55,840 --> 00:24:57,039
it's really just a time for you to be

755
00:24:57,039 --> 00:24:58,799
able to share with them like being the

756
00:24:58,799 --> 00:25:01,039
human behind the speaker right um is

757
00:25:01,039 --> 00:25:01,919
there anything that you kind of want to

758
00:25:01,919 --> 00:25:04,240
share with them um as far as your

759
00:25:04,240 --> 00:25:06,559
journey in cyber security or your the

760
00:25:06,559 --> 00:25:07,440
presentation that you're gonna be

761
00:25:07,440 --> 00:25:10,320
getting yeah so um

762
00:25:10,320 --> 00:25:12,400
the so the the funny thing about the way

763
00:25:12,400 --> 00:25:15,039
we kind of created this talk was like

764
00:25:15,039 --> 00:25:17,279
adam was initially going to give it and

765
00:25:17,279 --> 00:25:19,039
then we talked and we were like i live

766
00:25:19,039 --> 00:25:21,120
you know 30 minutes from tyson's i'll

767
00:25:21,120 --> 00:25:22,880
give it you stay home so we did this

768
00:25:22,880 --> 00:25:24,799
like cross-country creation of the slide

769
00:25:24,799 --> 00:25:26,960
deck and as we were creating it one of

770
00:25:26,960 --> 00:25:28,320
the questions that immediately occurred

771
00:25:28,320 --> 00:25:29,600
to me was like

772
00:25:29,600 --> 00:25:33,279
why are we including test difficulty in

773
00:25:33,279 --> 00:25:35,679
the like idea of coverage right so one

774
00:25:35,679 --> 00:25:37,440
of the elements that we factored into

775
00:25:37,440 --> 00:25:39,840
like defining coverage of mitre attack

776
00:25:39,840 --> 00:25:41,679
is difficulty how hard is it to run this

777
00:25:41,679 --> 00:25:42,480
test

778
00:25:42,480 --> 00:25:44,799
um and the reason for that in my opinion

779
00:25:44,799 --> 00:25:45,679
is like

780
00:25:45,679 --> 00:25:47,919
we need to make them as easy to run as

781
00:25:47,919 --> 00:25:50,480
possible right um i hate the term like

782
00:25:50,480 --> 00:25:52,159
oh that person's technical or not

783
00:25:52,159 --> 00:25:54,240
because i often find it used as like an

784
00:25:54,240 --> 00:25:56,799
insult and plus it's very loosey-goosey

785
00:25:56,799 --> 00:25:58,320
it's like you know

786
00:25:58,320 --> 00:26:00,320
seo is is technical swimming is

787
00:26:00,320 --> 00:26:01,919
technical what are we talking about here

788
00:26:01,919 --> 00:26:02,880
so

789
00:26:02,880 --> 00:26:05,200
i use the no less insulting term but

790
00:26:05,200 --> 00:26:08,159
funnier term of referring to muggles and

791
00:26:08,159 --> 00:26:10,559
wizards uh so we want to make it as

792
00:26:10,559 --> 00:26:12,720
muggle friendly as possible because

793
00:26:12,720 --> 00:26:14,240
ultimately like if we want to solve the

794
00:26:14,240 --> 00:26:16,320
broader security problem we have to

795
00:26:16,320 --> 00:26:18,880
bring more muggles and to understand

796
00:26:18,880 --> 00:26:20,640
like how we're doing security so like in

797
00:26:20,640 --> 00:26:23,200
order to keep growing atomic red team we

798
00:26:23,200 --> 00:26:24,720
want to have tests available to folks

799
00:26:24,720 --> 00:26:27,600
who are new to security less experienced

800
00:26:27,600 --> 00:26:29,279
in addition to tests that are involved

801
00:26:29,279 --> 00:26:31,520
and more difficult to run um so that's

802
00:26:31,520 --> 00:26:34,000
kind of the most like counter-intuitive

803
00:26:34,000 --> 00:26:35,520
thing i thought about the way we went

804
00:26:35,520 --> 00:26:37,679
about um sort of

805
00:26:37,679 --> 00:26:39,440
defining coverage and figuring out how

806
00:26:39,440 --> 00:26:41,840
well we cover mito attack it's actually

807
00:26:41,840 --> 00:26:43,200
really smart i'm actually very

808
00:26:43,200 --> 00:26:44,960
insightful so thank you i really

809
00:26:44,960 --> 00:26:46,480
appreciate it i really appreciate you

810
00:26:46,480 --> 00:26:48,640
coming out here for a 15-minute talk and

811
00:26:48,640 --> 00:26:49,840
we know how much goes into these

812
00:26:49,840 --> 00:26:51,840
presentations so coming out here thank

813
00:26:51,840 --> 00:26:53,360
you glad to do it it's my fourth time at

814
00:26:53,360 --> 00:26:55,039
attack con so i'm going to attack on

815
00:26:55,039 --> 00:26:56,960
lifer so i love it okay if you do it

816
00:26:56,960 --> 00:26:58,720
again great all right we'll see you next

817
00:26:58,720 --> 00:27:00,960
year thank you so much thanks so next

818
00:27:00,960 --> 00:27:03,200
we're going to be able to talk to tim uh

819
00:27:03,200 --> 00:27:04,720
tim was actually who i gave a shout out

820
00:27:04,720 --> 00:27:07,760
to earlier um he's been super helpful in

821
00:27:07,760 --> 00:27:11,120
working with our team on linux um so

822
00:27:11,120 --> 00:27:12,559
we're super excited to have you here

823
00:27:12,559 --> 00:27:15,520
today hello so i guess this is the um

824
00:27:15,520 --> 00:27:17,840
the morning after the night before yeah

825
00:27:17,840 --> 00:27:20,399
with birthday cake yeah so for all of

826
00:27:20,399 --> 00:27:22,960
you it was his birthday yesterday should

827
00:27:22,960 --> 00:27:24,720
we ask how old you are yeah that was

828
00:27:24,720 --> 00:27:26,799
good fun

829
00:27:26,799 --> 00:27:28,960
with the question

830
00:27:28,960 --> 00:27:29,679
so

831
00:27:29,679 --> 00:27:31,200
what do we want to talk about yeah where

832
00:27:31,200 --> 00:27:32,799
do we where do we start where do we

833
00:27:32,799 --> 00:27:36,880
start okay so how about um

834
00:27:36,880 --> 00:27:37,919
tell us the story behind your

835
00:27:37,919 --> 00:27:39,200
presentation how did you come up with

836
00:27:39,200 --> 00:27:41,760
the topic okay so background because

837
00:27:41,760 --> 00:27:44,159
it's something fairly relevant i've gone

838
00:27:44,159 --> 00:27:46,640
blue red blue uh in terms of my career

839
00:27:46,640 --> 00:27:48,799
history so i started off working in a

840
00:27:48,799 --> 00:27:51,279
sock about 20 years ago at a bank spent

841
00:27:51,279 --> 00:27:52,880
a lot of time understanding financial

842
00:27:52,880 --> 00:27:55,440
services moved through into cisco spent

843
00:27:55,440 --> 00:27:57,600
a lot of time looking at networks and

844
00:27:57,600 --> 00:28:00,000
kind of realized that um

845
00:28:00,000 --> 00:28:01,760
when it comes to the vertical specific

846
00:28:01,760 --> 00:28:03,279
stuff that's the technology that

847
00:28:03,279 --> 00:28:05,360
actually generates your money um a lot

848
00:28:05,360 --> 00:28:07,039
of stocks don't necessarily have the

849
00:28:07,039 --> 00:28:08,880
visibility they would like of that yeah

850
00:28:08,880 --> 00:28:10,720
it's one thing to understand exchange to

851
00:28:10,720 --> 00:28:12,799
understand active direction windows but

852
00:28:12,799 --> 00:28:14,960
yeah the message bus inside a service

853
00:28:14,960 --> 00:28:16,720
provider what does that even look like

854
00:28:16,720 --> 00:28:18,799
as an attack service do you think that

855
00:28:18,799 --> 00:28:20,159
that's because they're like oh well if i

856
00:28:20,159 --> 00:28:22,480
can't see it then no one else can too

857
00:28:22,480 --> 00:28:24,080
and there's a degree of truth to that

858
00:28:24,080 --> 00:28:25,279
and there are certainly not enough

859
00:28:25,279 --> 00:28:26,960
visibility of these kinds of systems in

860
00:28:26,960 --> 00:28:29,600
the wild um but i think it's also simply

861
00:28:29,600 --> 00:28:30,880
the fact that

862
00:28:30,880 --> 00:28:32,880
we're fighting and ever um increasing

863
00:28:32,880 --> 00:28:35,039
deluge of attacks all over the place and

864
00:28:35,039 --> 00:28:36,240
people start with the stuff that's

865
00:28:36,240 --> 00:28:37,919
easiest to find

866
00:28:37,919 --> 00:28:40,960
that's fair that is fair but

867
00:28:40,960 --> 00:28:42,559
and the reason for the talk is we have

868
00:28:42,559 --> 00:28:44,080
customers that want to understand those

869
00:28:44,080 --> 00:28:45,679
things better i've got customers that

870
00:28:45,679 --> 00:28:47,440
want to understand what their telco

871
00:28:47,440 --> 00:28:48,559
environment looks like and what i

872
00:28:48,559 --> 00:28:50,080
understand what a payment platform

873
00:28:50,080 --> 00:28:52,480
attack could look like and so their

874
00:28:52,480 --> 00:28:54,000
threat modeling is that that

875
00:28:54,000 --> 00:28:56,640
hypothesizing um of what what could

876
00:28:56,640 --> 00:28:58,799
happen um and then yeah we take it from

877
00:28:58,799 --> 00:29:01,360
there i love that so i feel like there's

878
00:29:01,360 --> 00:29:02,880
a certain degree of bravery that a

879
00:29:02,880 --> 00:29:05,520
company has to have to be like okay

880
00:29:05,520 --> 00:29:07,360
let's rip off the band-aid what does

881
00:29:07,360 --> 00:29:09,039
this actually look like if we open up

882
00:29:09,039 --> 00:29:10,720
the system and we really look at what an

883
00:29:10,720 --> 00:29:13,120
attack looks like yeah and

884
00:29:13,120 --> 00:29:15,039
it's a bravery that you don't get forced

885
00:29:15,039 --> 00:29:16,799
into um

886
00:29:16,799 --> 00:29:19,120
nobody ever reports um publicly on what

887
00:29:19,120 --> 00:29:20,480
happens inside the network once the

888
00:29:20,480 --> 00:29:21,760
bridge is happening they talk about the

889
00:29:21,760 --> 00:29:23,440
outside they talk about the website

890
00:29:23,440 --> 00:29:24,960
getting interface they've ran somewhere

891
00:29:24,960 --> 00:29:27,120
because you can't avoid that but like

892
00:29:27,120 --> 00:29:29,520
the the database done um how did that

893
00:29:29,520 --> 00:29:31,360
happen how did the adversary get access

894
00:29:31,360 --> 00:29:32,480
well you don't find that in the

895
00:29:32,480 --> 00:29:35,440
traditional um response report so

896
00:29:35,440 --> 00:29:36,960
that's where i come in is to kind of

897
00:29:36,960 --> 00:29:39,279
guess how that might have happened

898
00:29:39,279 --> 00:29:41,440
so it's still guesswork in the end it's

899
00:29:41,440 --> 00:29:43,360
absolutely hypothesis

900
00:29:43,360 --> 00:29:46,240
based on experience intuition uh yeah

901
00:29:46,240 --> 00:29:49,039
an understanding of the applications um

902
00:29:49,039 --> 00:29:50,799
that that blue red blue means that i've

903
00:29:50,799 --> 00:29:52,799
sat both sides of the fence i've tried

904
00:29:52,799 --> 00:29:54,159
to secure things i've tried to break

905
00:29:54,159 --> 00:29:56,000
into things and now i'm coming back and

906
00:29:56,000 --> 00:29:57,679
saying well actually this is this is

907
00:29:57,679 --> 00:30:00,399
what it looked like

908
00:30:00,399 --> 00:30:02,480
so then like all right so for those of

909
00:30:02,480 --> 00:30:03,600
us that are

910
00:30:03,600 --> 00:30:05,440
not a seasoned experience you have so

911
00:30:05,440 --> 00:30:07,279
many years in the industry like what are

912
00:30:07,279 --> 00:30:10,000
some key um

913
00:30:10,000 --> 00:30:12,320
i guess like what are some like

914
00:30:12,320 --> 00:30:14,159
methods of thought or questions to ask

915
00:30:14,159 --> 00:30:15,600
ourselves to be able to piece that

916
00:30:15,600 --> 00:30:17,440
together

917
00:30:17,440 --> 00:30:19,200
the simple ones the simple ones are

918
00:30:19,200 --> 00:30:21,279
still the best how's it authenticated do

919
00:30:21,279 --> 00:30:23,039
we have logs um

920
00:30:23,039 --> 00:30:24,960
who has access where do they have access

921
00:30:24,960 --> 00:30:28,159
from uh you yeah you can take

922
00:30:28,159 --> 00:30:29,840
two ends of the spectrum if you look at

923
00:30:29,840 --> 00:30:31,520
microsoft stride methodology it's a

924
00:30:31,520 --> 00:30:32,720
really good way of looking at threat

925
00:30:32,720 --> 00:30:34,399
modeling in a general sense but it tends

926
00:30:34,399 --> 00:30:35,919
to be quite developer-centric and it

927
00:30:35,919 --> 00:30:37,840
doesn't necessarily always cover the

928
00:30:37,840 --> 00:30:39,600
operational aspects of a platform but

929
00:30:39,600 --> 00:30:41,039
it's still a good place to start because

930
00:30:41,039 --> 00:30:43,200
it starts to get you to think about yeah

931
00:30:43,200 --> 00:30:45,200
what does an attack look like what data

932
00:30:45,200 --> 00:30:47,120
might they be wishing to steal um how

933
00:30:47,120 --> 00:30:49,279
would they get out of the system

934
00:30:49,279 --> 00:30:51,120
so that's a good one for development but

935
00:30:51,120 --> 00:30:52,880
not necessarily operational exactly and

936
00:30:52,880 --> 00:30:54,320
that's where attack comes in it gives me

937
00:30:54,320 --> 00:30:55,520
that language

938
00:30:55,520 --> 00:30:57,039
everybody said it over the course of the

939
00:30:57,039 --> 00:30:58,399
last day and a half

940
00:30:58,399 --> 00:31:00,320
that language that shared language that

941
00:31:00,320 --> 00:31:02,000
means i can go to a sock and i just i

942
00:31:02,000 --> 00:31:05,039
could describe an attack on oracle db2

943
00:31:05,039 --> 00:31:06,880
mq or whatever else it happens to be in

944
00:31:06,880 --> 00:31:08,399
a way that they're going to be familiar

945
00:31:08,399 --> 00:31:10,080
with they're going to understand your

946
00:31:10,080 --> 00:31:11,279
account compromise they're going to

947
00:31:11,279 --> 00:31:13,279
understand password if i if i talk to

948
00:31:13,279 --> 00:31:14,960
them about the database table inside a

949
00:31:14,960 --> 00:31:16,960
in inside a database that holds these

950
00:31:16,960 --> 00:31:18,080
and then possibly they're probably not

951
00:31:18,080 --> 00:31:19,519
going to get that at least not

952
00:31:19,519 --> 00:31:21,120
immediately but if we can start to

953
00:31:21,120 --> 00:31:22,320
expand

954
00:31:22,320 --> 00:31:24,000
their field of vision

955
00:31:24,000 --> 00:31:25,039
um

956
00:31:25,039 --> 00:31:27,279
then we have a chance

957
00:31:27,279 --> 00:31:29,760
i like that so um you're about to go up

958
00:31:29,760 --> 00:31:31,440
and speak which we're so grateful that

959
00:31:31,440 --> 00:31:33,200
you're here because you came

960
00:31:33,200 --> 00:31:35,840
all the way from the uk

961
00:31:35,840 --> 00:31:37,840
yeah

962
00:31:37,840 --> 00:31:39,679
second time speaking outside the uk as

963
00:31:39,679 --> 00:31:41,120
well which is really insane like i've

964
00:31:41,120 --> 00:31:43,200
done 20 years worth of speaking in the

965
00:31:43,200 --> 00:31:46,640
uk spoken to attack and spoken to the

966
00:31:46,640 --> 00:31:48,799
german government so you're you're the

967
00:31:48,799 --> 00:31:50,159
they're the two people who've got me out

968
00:31:50,159 --> 00:31:51,200
of the uk

969
00:31:51,200 --> 00:31:53,120
i so appreciate the fact yeah because

970
00:31:53,120 --> 00:31:54,799
the only place is germany right like

971
00:31:54,799 --> 00:31:56,720
where it's like american which are two

972
00:31:56,720 --> 00:31:58,559
big very differences oh absolutely yeah

973
00:31:58,559 --> 00:31:59,679
very different cultures of very

974
00:31:59,679 --> 00:32:01,600
different languages as well yes and you

975
00:32:01,600 --> 00:32:03,840
speak german as well right enough that i

976
00:32:03,840 --> 00:32:05,919
got by i wouldn't claim that the germans

977
00:32:05,919 --> 00:32:07,279
understood every word i was saying but

978
00:32:07,279 --> 00:32:09,120
we didn't we didn't have too many

979
00:32:09,120 --> 00:32:10,159
problems

980
00:32:10,159 --> 00:32:12,320
that is really really impressive we're

981
00:32:12,320 --> 00:32:14,159
really grateful to have you here and for

982
00:32:14,159 --> 00:32:17,039
this for you to come on your birthday

983
00:32:17,039 --> 00:32:18,399
it means a lot

984
00:32:18,399 --> 00:32:20,399
it's nice to be here it's three years of

985
00:32:20,399 --> 00:32:22,000
being locked down you've got to escape

986
00:32:22,000 --> 00:32:24,240
somehow what better place to do it

987
00:32:24,240 --> 00:32:26,159
you know what that's a fair point right

988
00:32:26,159 --> 00:32:29,039
the escape from being locked down yeah

989
00:32:29,039 --> 00:32:30,640
and what better way other than like to

990
00:32:30,640 --> 00:32:32,880
find a way to not like when you do break

991
00:32:32,880 --> 00:32:35,440
out and to give back to the community in

992
00:32:35,440 --> 00:32:36,480
another way

993
00:32:36,480 --> 00:32:38,399
cool yeah i mean

994
00:32:38,399 --> 00:32:40,960
the three years of of thinking about all

995
00:32:40,960 --> 00:32:43,919
of this so 15 minutes from three years

996
00:32:43,919 --> 00:32:47,279
worth of work um it's necessarily short

997
00:32:47,279 --> 00:32:48,799
and brief but you can always come and

998
00:32:48,799 --> 00:32:50,480
talk to me afterwards and we can discuss

999
00:32:50,480 --> 00:32:52,559
things in more detail i really really

1000
00:32:52,559 --> 00:32:54,240
appreciate that yeah so for our online

1001
00:32:54,240 --> 00:32:55,279
viewers is there anything they want to

1002
00:32:55,279 --> 00:32:57,360
say to our online viewers

1003
00:32:57,360 --> 00:32:58,320
uh

1004
00:32:58,320 --> 00:33:01,279
don't discount linux osx and all of the

1005
00:33:01,279 --> 00:33:03,039
weird stuff you have in your environment

1006
00:33:03,039 --> 00:33:05,360
because when that happens and breaches

1007
00:33:05,360 --> 00:33:06,720
do occur

1008
00:33:06,720 --> 00:33:08,320
it's typically somebody like me that

1009
00:33:08,320 --> 00:33:10,080
turns up and gets very frustrated that

1010
00:33:10,080 --> 00:33:11,600
there aren't any lugs

1011
00:33:11,600 --> 00:33:13,039
and there isn't any evidence and we

1012
00:33:13,039 --> 00:33:14,240
can't really

1013
00:33:14,240 --> 00:33:15,840
figure out what's happened

1014
00:33:15,840 --> 00:33:18,399
i'm in advance

1015
00:33:18,399 --> 00:33:19,919
no that is so valid thank you so much

1016
00:33:19,919 --> 00:33:21,600
because that's a really really good

1017
00:33:21,600 --> 00:33:22,720
point

1018
00:33:22,720 --> 00:33:24,399
so all right we're super looking forward

1019
00:33:24,399 --> 00:33:26,480
to talking can't wait and i believe we

1020
00:33:26,480 --> 00:33:28,960
have one more speaker coming up right

1021
00:33:28,960 --> 00:33:31,360
cool no yeah one more right yeah all

1022
00:33:31,360 --> 00:33:33,360
right

1023
00:33:33,360 --> 00:33:34,799
all right so our last speaker is about

1024
00:33:34,799 --> 00:33:36,720
to come up um i'll let them introduce

1025
00:33:36,720 --> 00:33:38,640
themselves but again really i look

1026
00:33:38,640 --> 00:33:40,720
forward to that talk um tim has been

1027
00:33:40,720 --> 00:33:43,760
really great and a great partner um so

1028
00:33:43,760 --> 00:33:45,760
how are you hey how you doing i'm good

1029
00:33:45,760 --> 00:33:46,960
all right so i'll let you introduce

1030
00:33:46,960 --> 00:33:48,880
yourself to our viewers all right hey

1031
00:33:48,880 --> 00:33:50,399
everybody my name is jared stroud and

1032
00:33:50,399 --> 00:33:52,480
i'm with lacework cloud security company

1033
00:33:52,480 --> 00:33:55,120
i'm super excited to be here we are very

1034
00:33:55,120 --> 00:33:56,960
grateful for you to be here thanks for

1035
00:33:56,960 --> 00:33:58,880
having me so tell us about like what

1036
00:33:58,880 --> 00:34:00,000
inspired your talk that you're going to

1037
00:34:00,000 --> 00:34:02,240
be giving later today sure so my talk is

1038
00:34:02,240 --> 00:34:04,320
specifically on attacking containers and

1039
00:34:04,320 --> 00:34:06,559
i think collectively similar to your

1040
00:34:06,559 --> 00:34:08,320
talk on linux and mac stuff you know

1041
00:34:08,320 --> 00:34:10,320
windows gets a lot of attention uh for

1042
00:34:10,320 --> 00:34:12,879
obvious reasons and uh recently there's

1043
00:34:12,879 --> 00:34:14,480
been kind of an uptick in container

1044
00:34:14,480 --> 00:34:16,320
focused attacks and over the past year

1045
00:34:16,320 --> 00:34:17,760
we've actually been running some honey

1046
00:34:17,760 --> 00:34:19,599
pots to collect data on those attacks

1047
00:34:19,599 --> 00:34:21,199
and we're super excited to share the

1048
00:34:21,199 --> 00:34:23,280
results of those for defenders today so

1049
00:34:23,280 --> 00:34:25,440
they can kind of get out there and

1050
00:34:25,440 --> 00:34:26,800
look at different ways to improve their

1051
00:34:26,800 --> 00:34:28,879
security posture around containers ah

1052
00:34:28,879 --> 00:34:30,239
like information sharing is my love

1053
00:34:30,239 --> 00:34:32,320
language so thank you so much like on

1054
00:34:32,320 --> 00:34:34,079
behalf of the community thank you for

1055
00:34:34,079 --> 00:34:36,000
sharing that because that's a huge deal

1056
00:34:36,000 --> 00:34:37,199
right like you can't defend what you

1057
00:34:37,199 --> 00:34:40,000
don't know about exactly and kind of

1058
00:34:40,000 --> 00:34:41,679
to add to that we're also releasing the

1059
00:34:41,679 --> 00:34:43,599
honeypot that we purposely built to

1060
00:34:43,599 --> 00:34:45,280
collect that data so

1061
00:34:45,280 --> 00:34:47,119
other researchers can go forth deploy

1062
00:34:47,119 --> 00:34:48,639
that collect data see what you're seeing

1063
00:34:48,639 --> 00:34:50,480
in your environment to kind of have an

1064
00:34:50,480 --> 00:34:51,918
iterative process to improve the

1065
00:34:51,918 --> 00:34:53,918
detections of actual attacks that you're

1066
00:34:53,918 --> 00:34:54,800
facing

1067
00:34:54,800 --> 00:34:57,359
enterprise nice so all right i love that

1068
00:34:57,359 --> 00:34:58,880
you're releasing that so thank you

1069
00:34:58,880 --> 00:35:00,720
because i know how much work goes into

1070
00:35:00,720 --> 00:35:02,720
creating these tools right and it's so

1071
00:35:02,720 --> 00:35:04,240
easy to just like okay i created this

1072
00:35:04,240 --> 00:35:07,119
tool like now how do i get my return on

1073
00:35:07,119 --> 00:35:09,119
investment for all of the time that i

1074
00:35:09,119 --> 00:35:10,480
spent on this and you guys are just like

1075
00:35:10,480 --> 00:35:12,480
releasing it to the community absolutely

1076
00:35:12,480 --> 00:35:14,079
i mean when you look at the open source

1077
00:35:14,079 --> 00:35:15,440
community as a whole and specifically

1078
00:35:15,440 --> 00:35:17,920
all the things that attack does for the

1079
00:35:17,920 --> 00:35:20,240
community uh we look at it just paying

1080
00:35:20,240 --> 00:35:22,160
it forward right because uh obviously

1081
00:35:22,160 --> 00:35:24,400
attack has shaped the community uh in a

1082
00:35:24,400 --> 00:35:26,240
lot of awesome ways and uh we're just

1083
00:35:26,240 --> 00:35:28,000
trying to contribute back i really

1084
00:35:28,000 --> 00:35:30,640
appreciate that absolutely um so with

1085
00:35:30,640 --> 00:35:32,160
that said when we release things open

1086
00:35:32,160 --> 00:35:34,320
source right like honeypot sure um do

1087
00:35:34,320 --> 00:35:35,680
you have any suggestions for people that

1088
00:35:35,680 --> 00:35:37,119
are going to be using it specifically

1089
00:35:37,119 --> 00:35:38,640
like for like if

1090
00:35:38,640 --> 00:35:40,640
attackers are like oh

1091
00:35:40,640 --> 00:35:42,079
these are the newest honey pots that are

1092
00:35:42,079 --> 00:35:43,440
released that i need to be aware of

1093
00:35:43,440 --> 00:35:44,720
because they have these signatures like

1094
00:35:44,720 --> 00:35:46,240
do you have any suggestions for those

1095
00:35:46,240 --> 00:35:48,640
people to be able to counter i guess you

1096
00:35:48,640 --> 00:35:51,119
could say opsec sure so just like

1097
00:35:51,119 --> 00:35:52,880
deploying anything in your enterprise

1098
00:35:52,880 --> 00:35:54,240
there's always an associated risk with

1099
00:35:54,240 --> 00:35:55,520
it so understanding what you're

1100
00:35:55,520 --> 00:35:57,200
deploying and the associated risk that

1101
00:35:57,200 --> 00:35:58,800
comes with those utilities is super

1102
00:35:58,800 --> 00:36:00,640
important so just grabbing stuff off the

1103
00:36:00,640 --> 00:36:01,920
internet and deploying it's never a

1104
00:36:01,920 --> 00:36:03,839
great idea we kept our honeypot pretty

1105
00:36:03,839 --> 00:36:05,520
simple to audit so that way you can kind

1106
00:36:05,520 --> 00:36:07,440
of quickly iterate okay it's a pretty

1107
00:36:07,440 --> 00:36:09,200
straightforward python flask app let's

1108
00:36:09,200 --> 00:36:10,560
get it out there public facing to

1109
00:36:10,560 --> 00:36:12,560
collect the data but uh never deploy

1110
00:36:12,560 --> 00:36:13,680
something that you're not fully

1111
00:36:13,680 --> 00:36:14,880
comfortable with especially when it's

1112
00:36:14,880 --> 00:36:16,800
going to be collecting attacker data

1113
00:36:16,800 --> 00:36:17,760
yeah

1114
00:36:17,760 --> 00:36:18,880
i could definitely see that and also

1115
00:36:18,880 --> 00:36:20,240
knowing how to actually take that data

1116
00:36:20,240 --> 00:36:21,920
back and analyze it and make sure it's

1117
00:36:21,920 --> 00:36:24,079
not gonna absolutely bleed into anything

1118
00:36:24,079 --> 00:36:27,079
else

1119
00:36:27,280 --> 00:36:28,640
like i have definitely been that guy

1120
00:36:28,640 --> 00:36:30,480
that's like oh wait did that go to

1121
00:36:30,480 --> 00:36:33,440
master did that go like absolutely so

1122
00:36:33,440 --> 00:36:36,079
yeah um is there anything that um

1123
00:36:36,079 --> 00:36:37,520
so i know we didn't get a chance to talk

1124
00:36:37,520 --> 00:36:39,680
prior to this but um but i really want

1125
00:36:39,680 --> 00:36:40,800
to give you like is there anything you

1126
00:36:40,800 --> 00:36:42,560
want to share with the community um i

1127
00:36:42,560 --> 00:36:45,119
know that a lot of us have in this field

1128
00:36:45,119 --> 00:36:46,880
um this is really a great time to kind

1129
00:36:46,880 --> 00:36:48,240
of speak to anything that you've kind of

1130
00:36:48,240 --> 00:36:50,079
gone through in your own career journey

1131
00:36:50,079 --> 00:36:52,160
sure uh so speaking from personal

1132
00:36:52,160 --> 00:36:54,320
experience one thing that uh you know uh

1133
00:36:54,320 --> 00:36:55,520
sometimes people ask me is like how do i

1134
00:36:55,520 --> 00:36:57,920
get started or how do i dive into let's

1135
00:36:57,920 --> 00:36:59,680
say your uh assist admin you're like in

1136
00:36:59,680 --> 00:37:01,839
the right team stuff or something of

1137
00:37:01,839 --> 00:37:03,599
that kind of situation uh never

1138
00:37:03,599 --> 00:37:05,280
underestimate the power of the home lab

1139
00:37:05,280 --> 00:37:07,119
and just kind of tinkering in your off

1140
00:37:07,119 --> 00:37:09,680
hours and uh what what that can do for

1141
00:37:09,680 --> 00:37:11,040
you uh you know i started off with like

1142
00:37:11,040 --> 00:37:12,480
kind of like a simple blog and it's it's

1143
00:37:12,480 --> 00:37:14,560
done wonders for my career

1144
00:37:14,560 --> 00:37:17,440
huh so i will ask this because you're

1145
00:37:17,440 --> 00:37:19,200
releasing a honeypot so it's like for

1146
00:37:19,200 --> 00:37:21,520
the home labs like

1147
00:37:21,520 --> 00:37:23,200
like so would that be kind of like the

1148
00:37:23,200 --> 00:37:25,280
beginning of a home lab of releasing

1149
00:37:25,280 --> 00:37:26,720
that honeypot and doing it very well

1150
00:37:26,720 --> 00:37:28,560
sure so if you're interested in uh kind

1151
00:37:28,560 --> 00:37:30,320
of on the attack defense side of that

1152
00:37:30,320 --> 00:37:31,680
you know set it up in your own home lab

1153
00:37:31,680 --> 00:37:34,240
and a vm and see what uh the requests to

1154
00:37:34,240 --> 00:37:35,760
it look like and then play the defender

1155
00:37:35,760 --> 00:37:37,359
role and look at what data you can pull

1156
00:37:37,359 --> 00:37:39,520
from that and build iocs from it that's

1157
00:37:39,520 --> 00:37:41,200
a really really smart way to like go

1158
00:37:41,200 --> 00:37:43,119
about it because

1159
00:37:43,119 --> 00:37:45,200
it's a really tough like there's just so

1160
00:37:45,200 --> 00:37:47,680
much data absolutely and it's a lot you

1161
00:37:47,680 --> 00:37:48,800
have to know so much especially when

1162
00:37:48,800 --> 00:37:50,240
you're playing blue yep you have to

1163
00:37:50,240 --> 00:37:51,280
understand the red and then when you're

1164
00:37:51,280 --> 00:37:52,960
playing infrastructure and then it's

1165
00:37:52,960 --> 00:37:54,400
even more complicated like well did i

1166
00:37:54,400 --> 00:37:55,920
misconfigure it so

1167
00:37:55,920 --> 00:37:57,760
yes it's good to like i'm really glad

1168
00:37:57,760 --> 00:37:58,800
you're releasing something that's like

1169
00:37:58,800 --> 00:38:00,400
bite-sized yep

1170
00:38:00,400 --> 00:38:01,920
so that's really cool well we're really

1171
00:38:01,920 --> 00:38:03,280
looking forward to your talk oh thank

1172
00:38:03,280 --> 00:38:04,800
you for having me thank you we really

1173
00:38:04,800 --> 00:38:06,000
appreciate you coming here and spending

1174
00:38:06,000 --> 00:38:07,359
the time so absolutely we'll see you

1175
00:38:07,359 --> 00:38:09,119
later see you later all right

1176
00:38:09,119 --> 00:38:11,520
so i believe that concludes all of our

1177
00:38:11,520 --> 00:38:13,680
speakers for this segment

1178
00:38:13,680 --> 00:38:15,680
do we have other speakers coming up nope

1179
00:38:15,680 --> 00:38:17,680
that's it so that'll be all the speakers

1180
00:38:17,680 --> 00:38:20,160
um i believe next time you will see me

1181
00:38:20,160 --> 00:38:22,320
for the closing remarks

1182
00:38:22,320 --> 00:38:23,760
and we will be

1183
00:38:23,760 --> 00:38:26,800
uh announcing the meme winner so you

1184
00:38:26,800 --> 00:38:28,880
have from now

1185
00:38:28,880 --> 00:38:30,000
until

1186
00:38:30,000 --> 00:38:32,720
not very long from now to be able to get

1187
00:38:32,720 --> 00:38:34,720
that meme up we'll announce when we have

1188
00:38:34,720 --> 00:38:36,880
the cutoff how about that um but we're

1189
00:38:36,880 --> 00:38:38,000
really looking forward to seeing what

1190
00:38:38,000 --> 00:38:39,760
you guys got so

1191
00:38:39,760 --> 00:38:43,800
we will see you next time

1192
00:38:47,680 --> 00:38:49,759
you

