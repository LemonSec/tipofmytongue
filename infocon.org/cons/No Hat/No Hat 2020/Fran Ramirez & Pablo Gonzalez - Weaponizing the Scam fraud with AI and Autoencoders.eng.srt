1
00:00:56,079 --> 00:00:59,039
now it's time to abandon the magic world

2
00:00:59,039 --> 00:01:01,680
of software exploitation in order to

3
00:01:01,680 --> 00:01:04,080
move to another exciting field

4
00:01:04,080 --> 00:01:06,479
fran ramirez and pablo gonzalez are two

5
00:01:06,479 --> 00:01:08,560
great security researchers

6
00:01:08,560 --> 00:01:11,840
working for telefonica 11 pat and

7
00:01:11,840 --> 00:01:13,920
well-known speakers

8
00:01:13,920 --> 00:01:16,560
they are here today to show house the

9
00:01:16,560 --> 00:01:17,360
powerful

10
00:01:17,360 --> 00:01:20,799
of ai to enhance malicious activities

11
00:01:20,799 --> 00:01:21,759
such as fishing

12
00:01:21,759 --> 00:01:25,439
fruits and fake news spreading

13
00:01:25,439 --> 00:01:28,159
fran pablo with cancer roses the stage

14
00:01:28,159 --> 00:01:30,400
is yours

15
00:01:30,400 --> 00:01:33,520
hello everyone it is satellite for us to

16
00:01:33,520 --> 00:01:36,240
be here in this no hat edition

17
00:01:36,240 --> 00:01:38,320
we really would have loved to be in

18
00:01:38,320 --> 00:01:39,360
person with you

19
00:01:39,360 --> 00:01:41,600
but do it to the worst situation because

20
00:01:41,600 --> 00:01:42,560
the pandemic

21
00:01:42,560 --> 00:01:45,680
it has not been possible well

22
00:01:45,680 --> 00:01:48,320
in this talk we are going to address a

23
00:01:48,320 --> 00:01:48,880
topic

24
00:01:48,880 --> 00:01:51,600
that is becoming a real problem in our

25
00:01:51,600 --> 00:01:52,320
society

26
00:01:52,320 --> 00:01:54,799
every day the fake news and more

27
00:01:54,799 --> 00:01:55,840
specifically

28
00:01:55,840 --> 00:01:59,439
the dick fakes and these same techniques

29
00:01:59,439 --> 00:02:02,079
can be used to for example bring

30
00:02:02,079 --> 00:02:02,640
phishing

31
00:02:02,640 --> 00:02:05,840
attacks to another level

32
00:02:05,840 --> 00:02:10,560
but first let's introduce ourselves

33
00:02:12,480 --> 00:02:14,800
pablo gonzalez is a well-known cyber

34
00:02:14,800 --> 00:02:16,319
security researcher

35
00:02:16,319 --> 00:02:18,720
within this field who has great

36
00:02:18,720 --> 00:02:20,560
experience as a speaker

37
00:02:20,560 --> 00:02:23,599
in many events both in spain and in the

38
00:02:23,599 --> 00:02:26,080
rest of the world

39
00:02:26,080 --> 00:02:28,959
he has also written a wide number of

40
00:02:28,959 --> 00:02:33,200
books related to computer security

41
00:02:34,800 --> 00:02:37,519
i am also a computer security researcher

42
00:02:37,519 --> 00:02:38,800
and my main goal

43
00:02:38,800 --> 00:02:41,360
is to find the connection between

44
00:02:41,360 --> 00:02:44,560
computer security and machine learning

45
00:02:44,560 --> 00:02:46,959
this is exactly where pablo and i are

46
00:02:46,959 --> 00:02:47,840
working in

47
00:02:47,840 --> 00:02:50,879
our eds locus team or crazy ideas team

48
00:02:50,879 --> 00:02:53,840
at telefonica

49
00:02:55,440 --> 00:02:57,760
okay then what are we going to talk

50
00:02:57,760 --> 00:03:00,080
about here today

51
00:03:00,080 --> 00:03:02,640
we are going to talk about news fake

52
00:03:02,640 --> 00:03:03,120
news

53
00:03:03,120 --> 00:03:07,519
and dig fakes attack based on material

54
00:03:07,519 --> 00:03:11,040
ceo is come fro this will be our first

55
00:03:11,040 --> 00:03:12,480
demo

56
00:03:12,480 --> 00:03:15,599
defend based on machine learning and

57
00:03:15,599 --> 00:03:18,800
for the first time our new detecting

58
00:03:18,800 --> 00:03:21,760
dig fakes as a service this will be our

59
00:03:21,760 --> 00:03:24,399
second demo

60
00:03:27,120 --> 00:03:30,159
in 2017 we started to see different

61
00:03:30,159 --> 00:03:33,200
techniques to impersonated people

62
00:03:33,200 --> 00:03:35,920
in this video where the image of obama

63
00:03:35,920 --> 00:03:36,879
is used

64
00:03:36,879 --> 00:03:39,440
they used a supplanting of the leaves

65
00:03:39,440 --> 00:03:40,799
only synchronize it

66
00:03:40,799 --> 00:03:43,840
with the sound the deep fakes

67
00:03:43,840 --> 00:03:47,840
era had begun

68
00:03:48,799 --> 00:03:50,640
the fake news started to have

69
00:03:50,640 --> 00:03:52,799
consequences in the real world

70
00:03:52,799 --> 00:03:55,040
like in the stock market and in the

71
00:03:55,040 --> 00:03:57,760
false news about terrorist attacks

72
00:03:57,760 --> 00:04:00,319
like this one that you can see about a

73
00:04:00,319 --> 00:04:02,239
fake attack in the white house

74
00:04:02,239 --> 00:04:06,560
that had consequences in the market

75
00:04:08,159 --> 00:04:10,799
okay now i will give way to my friend

76
00:04:10,799 --> 00:04:12,480
and colleague paolo gonzalez

77
00:04:12,480 --> 00:04:15,040
to tell us about the different attacks

78
00:04:15,040 --> 00:04:15,680
using

79
00:04:15,680 --> 00:04:18,320
deep learning

80
00:04:19,440 --> 00:04:22,479
thank you fran hello everyone

81
00:04:22,479 --> 00:04:25,840
in this section we'll talk about

82
00:04:25,840 --> 00:04:29,440
same aspects that we have found

83
00:04:29,440 --> 00:04:32,720
while simulating an attack attack based

84
00:04:32,720 --> 00:04:33,360
of the

85
00:04:33,360 --> 00:04:36,479
on the use of artificial intelligence

86
00:04:36,479 --> 00:04:39,680
and the goal is to look at different

87
00:04:39,680 --> 00:04:42,479
methods or antennas for performing

88
00:04:42,479 --> 00:04:42,960
attack

89
00:04:42,960 --> 00:04:46,479
attack we will see a real demo

90
00:04:46,479 --> 00:04:49,520
of what what can be a

91
00:04:49,520 --> 00:04:53,199
archive and we will also present a new

92
00:04:53,199 --> 00:04:54,080
tool

93
00:04:54,080 --> 00:04:57,360
that we are working on to detect

94
00:04:57,360 --> 00:05:01,600
the fakes today we are exposed to

95
00:05:01,600 --> 00:05:04,960
important um

96
00:05:04,960 --> 00:05:07,919
important risks that can go under and

97
00:05:07,919 --> 00:05:08,720
notice

98
00:05:08,720 --> 00:05:12,400
we by the human eye we must

99
00:05:12,400 --> 00:05:15,440
also understand that these types of the

100
00:05:15,440 --> 00:05:17,840
attacks become our political scenes

101
00:05:17,840 --> 00:05:21,600
during the pandemic we have

102
00:05:21,600 --> 00:05:24,479
we have increased it the use of the

103
00:05:24,479 --> 00:05:26,160
software such as

104
00:05:26,160 --> 00:05:29,520
teams zoom skype we must

105
00:05:29,520 --> 00:05:32,800
be able to detect whether what we

106
00:05:32,800 --> 00:05:38,960
see or here is here is real or not

107
00:05:38,960 --> 00:05:42,240
in general a discriminative model is the

108
00:05:42,240 --> 00:05:44,479
decision boundary between the

109
00:05:44,479 --> 00:05:47,680
classes a generative model explicitly

110
00:05:47,680 --> 00:05:50,240
models the actual distribution of its

111
00:05:50,240 --> 00:05:51,360
class

112
00:05:51,360 --> 00:05:54,479
in the final both of them

113
00:05:54,479 --> 00:05:55,919
is predicting the conditional

114
00:05:55,919 --> 00:05:58,319
probability name p

115
00:05:58,319 --> 00:06:01,759
but both models learn different

116
00:06:01,759 --> 00:06:04,479
probabilities

117
00:06:04,800 --> 00:06:07,919
generative model learns the joint

118
00:06:07,919 --> 00:06:09,520
probability distribution

119
00:06:09,520 --> 00:06:11,520
it predicts the conditional priority

120
00:06:11,520 --> 00:06:14,319
with the help of the bias theorem

121
00:06:14,319 --> 00:06:17,600
a discriminative model model learns

122
00:06:17,600 --> 00:06:20,160
the conditional probability distribution

123
00:06:20,160 --> 00:06:20,880
both of

124
00:06:20,880 --> 00:06:23,919
these models were were

125
00:06:23,919 --> 00:06:27,600
generally used in unsupervised

126
00:06:27,600 --> 00:06:30,479
learning problems in our case the

127
00:06:30,479 --> 00:06:31,440
decision

128
00:06:31,440 --> 00:06:36,719
was to proceed with the generative model

129
00:06:37,680 --> 00:06:40,800
in the branch of generative models based

130
00:06:40,800 --> 00:06:44,880
on unsupervised learning we find

131
00:06:44,880 --> 00:06:48,720
an objective to generate examples of

132
00:06:48,720 --> 00:06:50,160
false images

133
00:06:50,160 --> 00:06:52,960
that are as close as possible to a real

134
00:06:52,960 --> 00:06:54,240
one

135
00:06:54,240 --> 00:06:57,120
in both variational encoders and

136
00:06:57,120 --> 00:06:57,840
generate

137
00:06:57,840 --> 00:07:00,240
generate adversarial networks we will

138
00:07:00,240 --> 00:07:03,840
use generative models

139
00:07:04,800 --> 00:07:07,680
barry only variation and encoders learn

140
00:07:07,680 --> 00:07:09,039
the parameter of a probability

141
00:07:09,039 --> 00:07:10,560
distribution representing

142
00:07:10,560 --> 00:07:13,680
the data baa is a generative model

143
00:07:13,680 --> 00:07:16,400
it estimates the probability density

144
00:07:16,400 --> 00:07:17,199
function

145
00:07:17,199 --> 00:07:20,720
pdf of the training data suppose such

146
00:07:20,720 --> 00:07:24,000
a model is training strain a natural

147
00:07:24,000 --> 00:07:24,960
looking

148
00:07:24,960 --> 00:07:28,720
phases match in that case

149
00:07:28,720 --> 00:07:31,280
it should assign a high probability

150
00:07:31,280 --> 00:07:31,919
value

151
00:07:31,919 --> 00:07:34,960
to a phase picture but low priority if

152
00:07:34,960 --> 00:07:35,520
it is

153
00:07:35,520 --> 00:07:39,520
a car image for example an image

154
00:07:39,520 --> 00:07:43,840
of random giveaways on the other hand so

155
00:07:43,840 --> 00:07:47,520
we assign a low probability value

156
00:07:47,520 --> 00:07:50,639
the bae model can also sample

157
00:07:50,639 --> 00:07:53,840
samples from the learning pdf

158
00:07:53,840 --> 00:07:57,199
which is the coolest part since it

159
00:07:57,199 --> 00:08:00,240
will generate new samples that look

160
00:08:00,240 --> 00:08:04,080
similar to the original data set

161
00:08:05,440 --> 00:08:08,879
um creation this is the fantastic

162
00:08:08,879 --> 00:08:11,520
feature of the games for example we

163
00:08:11,520 --> 00:08:14,160
could create new faces from people

164
00:08:14,160 --> 00:08:17,440
that don't exist the the significant

165
00:08:17,440 --> 00:08:20,879
insight that defines a gun

166
00:08:20,879 --> 00:08:24,800
is to set up these modeling problems uh

167
00:08:24,800 --> 00:08:29,120
some kind of context this is where the

168
00:08:29,120 --> 00:08:33,599
adversarial part of the names comes from

169
00:08:33,599 --> 00:08:37,039
the key idea is to build not

170
00:08:37,039 --> 00:08:40,080
one but two competing networks

171
00:08:40,080 --> 00:08:42,559
a generic and generator and

172
00:08:42,559 --> 00:08:43,679
discriminator

173
00:08:43,679 --> 00:08:48,240
this generator tries to create random

174
00:08:48,240 --> 00:08:52,000
synthetic synthetic outputs for instance

175
00:08:52,000 --> 00:08:55,600
images or faces while the discriminator

176
00:08:55,600 --> 00:08:58,720
tries to tell this this part

177
00:08:58,720 --> 00:09:02,399
apart from real outcomes

178
00:09:02,399 --> 00:09:06,240
say at the base of the liberties

179
00:09:06,240 --> 00:09:09,040
the hope is that as the two networks

180
00:09:09,040 --> 00:09:10,000
face off

181
00:09:10,000 --> 00:09:13,279
they will both get better

182
00:09:13,279 --> 00:09:17,360
and better with the end result

183
00:09:17,360 --> 00:09:20,000
being a generator network that proves

184
00:09:20,000 --> 00:09:21,200
possesses

185
00:09:21,200 --> 00:09:25,040
realistic outputs two players

186
00:09:25,040 --> 00:09:28,880
generator g and discriminator d

187
00:09:28,880 --> 00:09:33,600
fight with between each other

188
00:09:34,959 --> 00:09:38,320
um a gun may have

189
00:09:38,320 --> 00:09:40,720
some problems during during their

190
00:09:40,720 --> 00:09:41,440
training

191
00:09:41,440 --> 00:09:43,440
description for example the

192
00:09:43,440 --> 00:09:44,560
discriminator

193
00:09:44,560 --> 00:09:47,200
discriminator can become very good and

194
00:09:47,200 --> 00:09:47,760
always

195
00:09:47,760 --> 00:09:50,000
detect the output of the generator as a

196
00:09:50,000 --> 00:09:51,680
fake this is a problem

197
00:09:51,680 --> 00:09:56,000
since we will have condemned the inmate

198
00:09:56,000 --> 00:09:59,440
the generator may not improve and do not

199
00:09:59,440 --> 00:10:02,959
generate or generate different examples

200
00:10:02,959 --> 00:10:06,079
so it will not advance

201
00:10:06,079 --> 00:10:10,240
its learning and it establishes

202
00:10:10,240 --> 00:10:14,079
the model does not come back

203
00:10:14,079 --> 00:10:17,519
anyway if we manage the optimis

204
00:10:17,519 --> 00:10:20,240
desk parameters the final result is

205
00:10:20,240 --> 00:10:21,120
really

206
00:10:21,120 --> 00:10:23,680
excellent

207
00:10:25,680 --> 00:10:29,120
it's not necessary to be an expert on

208
00:10:29,120 --> 00:10:31,040
math or machine learning

209
00:10:31,040 --> 00:10:33,839
for using this kind of technology

210
00:10:33,839 --> 00:10:34,720
everything

211
00:10:34,720 --> 00:10:38,160
is ready to use on the internet you have

212
00:10:38,160 --> 00:10:38,959
the lab

213
00:10:38,959 --> 00:10:42,079
packet you can find almost anything

214
00:10:42,079 --> 00:10:45,600
anything online for example

215
00:10:45,600 --> 00:10:48,880
of free shopping with guns we have used

216
00:10:48,880 --> 00:10:49,440
some

217
00:10:49,440 --> 00:10:52,160
libraries that are accessible to

218
00:10:52,160 --> 00:10:54,240
everyone and on the internet

219
00:10:54,240 --> 00:10:58,399
also we want to do a loft cost

220
00:10:58,399 --> 00:11:01,839
exercise and use our own hardware

221
00:11:01,839 --> 00:11:06,720
as you can see on the on the slide

222
00:11:07,120 --> 00:11:10,560
to perform the tests we'll use

223
00:11:10,560 --> 00:11:14,480
it's an example of our boss

224
00:11:14,480 --> 00:11:17,760
zamaronso ctco from telefonica

225
00:11:17,760 --> 00:11:21,200
we are going to carry out an attack that

226
00:11:21,200 --> 00:11:25,360
involves the use of different techniques

227
00:11:25,360 --> 00:11:29,200
ba is variational encoders and

228
00:11:29,200 --> 00:11:31,760
general generative adversarial network

229
00:11:31,760 --> 00:11:32,800
guns

230
00:11:32,800 --> 00:11:35,519
and first we will use a neural network

231
00:11:35,519 --> 00:11:37,279
to have a generator

232
00:11:37,279 --> 00:11:40,399
that allows to produce false

233
00:11:40,399 --> 00:11:43,920
chemo the idea is that

234
00:11:43,920 --> 00:11:47,839
using a vae we talk the features of a

235
00:11:47,839 --> 00:11:48,720
person

236
00:11:48,720 --> 00:11:51,680
and the generator returns the images of

237
00:11:51,680 --> 00:11:52,399
chema

238
00:11:52,399 --> 00:11:54,720
with the feature of the person who is

239
00:11:54,720 --> 00:11:55,680
impersonating

240
00:11:55,680 --> 00:11:59,279
him the generator will then

241
00:11:59,279 --> 00:12:02,560
provide an output by certain images

242
00:12:02,560 --> 00:12:05,360
with the functions or movements of

243
00:12:05,360 --> 00:12:06,800
another person

244
00:12:06,800 --> 00:12:10,320
that generator will train it to beat

245
00:12:10,320 --> 00:12:12,880
a discriminator who is trained with the

246
00:12:12,880 --> 00:12:14,399
real pictures

247
00:12:14,399 --> 00:12:18,079
of terror the idea is to get a person to

248
00:12:18,079 --> 00:12:19,680
move from an ass

249
00:12:19,680 --> 00:12:22,839
manics and the output is an

250
00:12:22,839 --> 00:12:26,079
image image of sema

251
00:12:26,079 --> 00:12:29,360
if we take many frames per second

252
00:12:29,360 --> 00:12:32,720
we will get a video

253
00:12:33,920 --> 00:12:39,040
first we will train the phase generation

254
00:12:39,040 --> 00:12:41,920
to perform this operation we must detect

255
00:12:41,920 --> 00:12:44,320
the key points or landmarks

256
00:12:44,320 --> 00:12:48,120
of the person's face in this case

257
00:12:48,120 --> 00:12:52,959
68 landmarks okay

258
00:12:52,959 --> 00:12:56,160
to implement these steps to extract the

259
00:12:56,160 --> 00:12:57,760
landmarks from the face

260
00:12:57,760 --> 00:13:01,440
we use fix to peaks tensorflow

261
00:13:01,440 --> 00:13:04,800
in our setup this operation took

262
00:13:04,800 --> 00:13:07,519
three days to complete this liver

263
00:13:07,519 --> 00:13:08,079
library

264
00:13:08,079 --> 00:13:12,079
allows us to reduce the training model

265
00:13:12,079 --> 00:13:15,680
or unify the model in a single

266
00:13:15,680 --> 00:13:18,800
file and finally the best part will

267
00:13:18,800 --> 00:13:22,399
enable us to to text it using

268
00:13:22,399 --> 00:13:26,320
the webcam directly to

269
00:13:26,320 --> 00:13:30,079
to bring uh to bring it to life

270
00:13:30,079 --> 00:13:33,120
we want to teach an ay to talk

271
00:13:33,120 --> 00:13:36,320
like a chema this type of attack

272
00:13:36,320 --> 00:13:39,360
shows a va of the person accompanied

273
00:13:39,360 --> 00:13:40,560
with audio

274
00:13:40,560 --> 00:13:44,320
where the person is here this can be

275
00:13:44,320 --> 00:13:46,639
very confusing to the person who is

276
00:13:46,639 --> 00:13:48,079
consuming the information

277
00:13:48,079 --> 00:13:52,079
since he sees hers with what

278
00:13:52,079 --> 00:13:55,279
believes to be the same person in this

279
00:13:55,279 --> 00:13:55,839
real

280
00:13:55,839 --> 00:13:58,880
video of chema we can listen to his

281
00:13:58,880 --> 00:14:00,079
voice

282
00:14:00,079 --> 00:14:03,760
and see his face in action and the

283
00:14:03,760 --> 00:14:06,320
air quality data that you have from the

284
00:14:06,320 --> 00:14:08,160
iot sensor in the city and you can

285
00:14:08,160 --> 00:14:10,000
predict what is going to be the air

286
00:14:10,000 --> 00:14:11,120
quality you can

287
00:14:11,120 --> 00:14:12,880
predict for instance what is going to be

288
00:14:12,880 --> 00:14:14,240
the

289
00:14:14,240 --> 00:14:17,360
the first step was to generate

290
00:14:17,360 --> 00:14:20,959
the audio with the voice closest to

291
00:14:20,959 --> 00:14:22,079
chemist

292
00:14:22,079 --> 00:14:25,360
like the one we can hear

293
00:14:25,360 --> 00:14:28,839
in the following audio hi

294
00:14:28,839 --> 00:14:31,920
louise are you available to handle an

295
00:14:31,920 --> 00:14:34,959
international payment of 15 000 this

296
00:14:34,959 --> 00:14:36,320
morning

297
00:14:36,320 --> 00:14:39,279
please find a way around it i'm

298
00:14:39,279 --> 00:14:43,920
currently in las vegas and i'm very busy

299
00:14:43,920 --> 00:14:45,279
um

300
00:14:45,279 --> 00:14:47,839
to teach and a why to speak like a

301
00:14:47,839 --> 00:14:48,720
person

302
00:14:48,720 --> 00:14:52,240
we can use microsoft custom voice it's

303
00:14:52,240 --> 00:14:55,279
or was only available for

304
00:14:55,279 --> 00:14:58,560
english and chinese audios you need

305
00:14:58,560 --> 00:15:01,760
to upload a serious series of

306
00:15:01,760 --> 00:15:04,240
audio samples of the person speaking in

307
00:15:04,240 --> 00:15:05,440
english

308
00:15:05,440 --> 00:15:08,800
but it must have the right quality

309
00:15:08,800 --> 00:15:12,480
label to get good results

310
00:15:12,480 --> 00:15:16,160
at this point we obtain information from

311
00:15:16,160 --> 00:15:17,440
a person

312
00:15:17,440 --> 00:15:20,959
on youtube for example we collect

313
00:15:20,959 --> 00:15:27,760
about 314 samples

314
00:15:27,760 --> 00:15:31,839
yeah really of the thread 30

315
00:15:31,839 --> 00:15:35,040
seconds each the idea

316
00:15:35,040 --> 00:15:38,639
would be to have samples worth

317
00:15:38,639 --> 00:15:41,839
8 hours

318
00:15:43,279 --> 00:15:46,399
once this is done we must

319
00:15:46,399 --> 00:15:50,079
then tell the microsoft api

320
00:15:50,079 --> 00:15:54,240
and just about those audios are saying

321
00:15:54,240 --> 00:15:57,680
to do with this we use

322
00:15:57,680 --> 00:16:00,880
the google speech drugs apa

323
00:16:00,880 --> 00:16:03,519
we get the transcription of audios to

324
00:16:03,519 --> 00:16:04,000
text

325
00:16:04,000 --> 00:16:07,440
and upload them as well once this is

326
00:16:07,440 --> 00:16:08,079
done

327
00:16:08,079 --> 00:16:11,120
we resize the model and we can pass it

328
00:16:11,120 --> 00:16:14,079
the text to create the speech

329
00:16:14,079 --> 00:16:17,440
logic lag logically

330
00:16:17,440 --> 00:16:20,839
in our our basic basic and low cost

331
00:16:20,839 --> 00:16:24,160
example there are many points

332
00:16:24,160 --> 00:16:27,839
of improvement since we did not

333
00:16:27,839 --> 00:16:31,600
use all the recommended audio hours

334
00:16:31,600 --> 00:16:37,040
nor were the audios of the best quality

335
00:16:37,040 --> 00:16:40,560
finally we put all the different parts

336
00:16:40,560 --> 00:16:43,440
together to create an unified

337
00:16:43,440 --> 00:16:46,880
demonstration in a simulation on a chat

338
00:16:46,880 --> 00:16:50,639
application um well

339
00:16:50,639 --> 00:16:54,720
let's see the final result

340
00:16:55,420 --> 00:16:59,179
[Music]

341
00:17:00,959 --> 00:17:04,079
hi and luigi

342
00:17:04,079 --> 00:17:05,919
handle an international payment of

343
00:17:05,919 --> 00:17:08,640
fifteen thousand dollars this morning

344
00:17:08,640 --> 00:17:10,880
please find the way around it and i'm

345
00:17:10,880 --> 00:17:13,359
currently in las vegas and i'm very busy

346
00:17:13,359 --> 00:17:15,599
use this ipa number for the account

347
00:17:15,599 --> 00:17:19,439
where the money has to be sent

348
00:17:19,439 --> 00:17:22,160
okay thank you pablo until now we have

349
00:17:22,160 --> 00:17:22,799
seen

350
00:17:22,799 --> 00:17:24,880
many different attack methods and

351
00:17:24,880 --> 00:17:26,160
techniques

352
00:17:26,160 --> 00:17:28,799
now let's look at some techniques

353
00:17:28,799 --> 00:17:29,440
focused

354
00:17:29,440 --> 00:17:33,840
this time at the defense

355
00:17:35,600 --> 00:17:37,760
let's talk about a new application that

356
00:17:37,760 --> 00:17:40,240
we have developed in the grace ideas in

357
00:17:40,240 --> 00:17:41,360
their locus team

358
00:17:41,360 --> 00:17:44,559
at telefonica this time focused to try

359
00:17:44,559 --> 00:17:45,520
to detect

360
00:17:45,520 --> 00:17:50,480
and defend ourselves from defects

361
00:17:50,559 --> 00:17:53,360
this application is designed to create a

362
00:17:53,360 --> 00:17:55,360
defects detection service

363
00:17:55,360 --> 00:17:58,640
where the user only has to enter the url

364
00:17:58,640 --> 00:18:01,679
of a video or directly upload it

365
00:18:01,679 --> 00:18:04,240
and the service will detect whether it's

366
00:18:04,240 --> 00:18:07,039
true or false

367
00:18:07,200 --> 00:18:10,080
it will also create a complete report

368
00:18:10,080 --> 00:18:11,120
that details

369
00:18:11,120 --> 00:18:14,080
all the parameters that have been used

370
00:18:14,080 --> 00:18:15,280
in the application

371
00:18:15,280 --> 00:18:19,200
to reach that final result

372
00:18:20,240 --> 00:18:22,240
this project's primary detection and

373
00:18:22,240 --> 00:18:23,520
genes are based

374
00:18:23,520 --> 00:18:26,320
on the following investigations that you

375
00:18:26,320 --> 00:18:26,960
can see

376
00:18:26,960 --> 00:18:29,840
in the slideshow

377
00:18:32,960 --> 00:18:35,600
what we can see here is the scheme of

378
00:18:35,600 --> 00:18:37,760
this architecture

379
00:18:37,760 --> 00:18:40,799
the four engines are documented and

380
00:18:40,799 --> 00:18:44,240
we also have developed an api to make it

381
00:18:44,240 --> 00:18:45,760
easy to integrate it

382
00:18:45,760 --> 00:18:48,960
with any kind of software the

383
00:18:48,960 --> 00:18:52,400
operation workflow works as follows

384
00:18:52,400 --> 00:18:55,280
through the api or ddlp the file or the

385
00:18:55,280 --> 00:18:56,080
url

386
00:18:56,080 --> 00:18:59,679
it checks that its hash does not exist

387
00:18:59,679 --> 00:19:03,039
in the database if it exists now it will

388
00:19:03,039 --> 00:19:06,240
offer the stored historical result if

389
00:19:06,240 --> 00:19:06,880
not

390
00:19:06,880 --> 00:19:10,080
it will be sent for analysis through the

391
00:19:10,080 --> 00:19:13,520
four engines finally the hash

392
00:19:13,520 --> 00:19:15,600
will be held in the database and the

393
00:19:15,600 --> 00:19:16,720
final report

394
00:19:16,720 --> 00:19:19,600
will be returned

395
00:19:20,640 --> 00:19:23,520
now let's see a small demonstration of

396
00:19:23,520 --> 00:19:39,110
how it works

397
00:19:39,110 --> 00:20:13,589
[Music]

398
00:20:18,240 --> 00:20:20,480
going back to the fake news to detect if

399
00:20:20,480 --> 00:20:22,080
they are true or false

400
00:20:22,080 --> 00:20:25,280
we have to use extensions or apis

401
00:20:25,280 --> 00:20:27,679
there are many but they are mainly based

402
00:20:27,679 --> 00:20:28,320
on

403
00:20:28,320 --> 00:20:31,039
verifying origin domains as a true

404
00:20:31,039 --> 00:20:31,919
source

405
00:20:31,919 --> 00:20:35,360
analysis of patterns in news content

406
00:20:35,360 --> 00:20:38,080
or keyword search to improve the search

407
00:20:38,080 --> 00:20:40,080
categorization and management

408
00:20:40,080 --> 00:20:43,200
of the information the most used machine

409
00:20:43,200 --> 00:20:44,480
learning techniques

410
00:20:44,480 --> 00:20:48,000
are nlp natural language processing

411
00:20:48,000 --> 00:20:52,880
and the lstm neural networks

412
00:20:56,320 --> 00:20:59,360
on the defects besides the engines

413
00:20:59,360 --> 00:21:02,080
that we have used in our demo of this

414
00:21:02,080 --> 00:21:03,760
phase as a service

415
00:21:03,760 --> 00:21:07,039
there is an exciting method based on the

416
00:21:07,039 --> 00:21:09,039
blinking of the eyes

417
00:21:09,039 --> 00:21:12,080
using a gaussian classified were the

418
00:21:12,080 --> 00:21:14,240
measure of the number of blinks

419
00:21:14,240 --> 00:21:17,440
and their duration we can have a first

420
00:21:17,440 --> 00:21:20,159
approximation that will allow us to

421
00:21:20,159 --> 00:21:24,320
guess if the video is false or true

422
00:21:25,600 --> 00:21:29,679
okay well to conclude let's recap

423
00:21:29,679 --> 00:21:32,480
one fooling people it's easy very cheap

424
00:21:32,480 --> 00:21:33,280
if you use

425
00:21:33,280 --> 00:21:36,320
image instead test

426
00:21:36,320 --> 00:21:39,440
two ai and cyber security go hand in

427
00:21:39,440 --> 00:21:41,200
hand

428
00:21:41,200 --> 00:21:44,159
and three knowledge and awareness are

429
00:21:44,159 --> 00:21:44,559
the

430
00:21:44,559 --> 00:21:46,960
pillars of which we will learn to

431
00:21:46,960 --> 00:21:47,679
protect

432
00:21:47,679 --> 00:21:50,320
ourselves

433
00:21:53,039 --> 00:21:56,240
and that's it gracias thanks

434
00:21:56,240 --> 00:21:59,840
and gretchen

435
00:22:00,400 --> 00:22:02,320
thank you guys for the very interesting

436
00:22:02,320 --> 00:22:03,600
presentation

437
00:22:03,600 --> 00:22:07,039
even if not totally ready yet the evil

438
00:22:07,039 --> 00:22:08,000
potential

439
00:22:08,000 --> 00:22:10,240
of the deep fakes is quite scary

440
00:22:10,240 --> 00:22:11,440
actually

441
00:22:11,440 --> 00:22:14,080
especially in terms of the spreading of

442
00:22:14,080 --> 00:22:15,200
fake news for

443
00:22:15,200 --> 00:22:18,480
information warfare campaign uh

444
00:22:18,480 --> 00:22:20,559
there are some questions coming from

445
00:22:20,559 --> 00:22:23,360
from the audience for you

446
00:22:23,360 --> 00:22:26,400
the first one ask it if

447
00:22:26,400 --> 00:22:29,919
in your opinion it's possible to create

448
00:22:29,919 --> 00:22:32,880
some deep fake surrealistic that can be

449
00:22:32,880 --> 00:22:35,280
used to fool and bypass biometric

450
00:22:35,280 --> 00:22:37,520
authentication

451
00:22:37,520 --> 00:22:39,760
okay first of all let me say that we are

452
00:22:39,760 --> 00:22:42,080
really really happy to be here with you

453
00:22:42,080 --> 00:22:45,360
in the no hat conference and uh second

454
00:22:45,360 --> 00:22:46,000
about the

455
00:22:46,000 --> 00:22:49,200
question um it depends on the technology

456
00:22:49,200 --> 00:22:52,000
of the tech biometric technology because

457
00:22:52,000 --> 00:22:54,000
for example a face id is not

458
00:22:54,000 --> 00:22:56,720
only based on image it use infrared

459
00:22:56,720 --> 00:22:57,679
light too

460
00:22:57,679 --> 00:23:00,880
so if the biometric um way

461
00:23:00,880 --> 00:23:04,720
to detect the person it's based only on

462
00:23:04,720 --> 00:23:08,000
image totally yes for sure it can be it

463
00:23:08,000 --> 00:23:09,280
can be cheated

464
00:23:09,280 --> 00:23:12,880
totally but um some biometric scenarios

465
00:23:12,880 --> 00:23:15,919
use another things and another method to

466
00:23:15,919 --> 00:23:18,799
to detect life for example or uh warm

467
00:23:18,799 --> 00:23:19,280
them

468
00:23:19,280 --> 00:23:21,679
the the warmer skin for for example the

469
00:23:21,679 --> 00:23:22,480
heat of the

470
00:23:22,480 --> 00:23:26,240
of the of the body or etc

471
00:23:26,240 --> 00:23:28,559
okay so a sort of multi-factor

472
00:23:28,559 --> 00:23:30,320
authentication for biomedical

473
00:23:30,320 --> 00:23:33,360
parameters made it really difficult for

474
00:23:33,360 --> 00:23:36,799
uh even for deep fakes to bypass this

475
00:23:36,799 --> 00:23:37,520
kind of

476
00:23:37,520 --> 00:23:40,880
system right okay thank you so

477
00:23:40,880 --> 00:23:44,320
uh we can pass the second one so um

478
00:23:44,320 --> 00:23:46,480
do you think it would be possible to

479
00:23:46,480 --> 00:23:48,159
integrate a sort of

480
00:23:48,159 --> 00:23:50,640
deep fake recognizer algorithm inside

481
00:23:50,640 --> 00:23:52,240
video call software

482
00:23:52,240 --> 00:23:56,159
in order to spot in real time dig fakes

483
00:23:56,159 --> 00:23:59,760
it could be really useful for uh spot

484
00:23:59,760 --> 00:24:02,480
uh advanced fishing activities probably

485
00:24:02,480 --> 00:24:03,120
right

486
00:24:03,120 --> 00:24:06,480
exactly um totally yes for sure because

487
00:24:06,480 --> 00:24:07,360
if you can see

488
00:24:07,360 --> 00:24:10,080
the demo that we use uh to impersonate

489
00:24:10,080 --> 00:24:10,640
our

490
00:24:10,640 --> 00:24:13,840
boss was uh what was made in a very

491
00:24:13,840 --> 00:24:14,960
simple computer it

492
00:24:14,960 --> 00:24:18,080
it wasn't uh a big cloud architecture

493
00:24:18,080 --> 00:24:21,760
was a small laptop with a big uh gpu

494
00:24:21,760 --> 00:24:24,799
and we we got a very very

495
00:24:24,799 --> 00:24:27,440
very good result so if you have money

496
00:24:27,440 --> 00:24:28,720
you have resources

497
00:24:28,720 --> 00:24:32,159
and you have a a big amount of of

498
00:24:32,159 --> 00:24:35,039
computing of computational power

499
00:24:35,039 --> 00:24:39,120
for sure you can create in real time um

500
00:24:39,120 --> 00:24:41,919
voice and image both at the same time

501
00:24:41,919 --> 00:24:43,919
for sure

502
00:24:43,919 --> 00:24:48,000
okay nice to know yeah we can

503
00:24:48,000 --> 00:24:50,640
it's not it it's not easy it's it's

504
00:24:50,640 --> 00:24:52,159
really expensive to do it

505
00:24:52,159 --> 00:24:54,640
but you can do it be because we made it

506
00:24:54,640 --> 00:24:56,799
with only a few resources

507
00:24:56,799 --> 00:24:59,279
and only in two weeks training that

508
00:24:59,279 --> 00:25:00,880
neural network so

509
00:25:00,880 --> 00:25:04,159
in only two weeks in that computer we

510
00:25:04,159 --> 00:25:07,200
we will be able to to get a very good

511
00:25:07,200 --> 00:25:09,360
results not at the end

512
00:25:09,360 --> 00:25:14,400
so we have hope right

513
00:25:14,400 --> 00:25:16,799
let me know so let's move to the last

514
00:25:16,799 --> 00:25:17,520
one

515
00:25:17,520 --> 00:25:21,039
uh someone is asking if uh did you have

516
00:25:21,039 --> 00:25:24,720
a experience in real world cases of deep

517
00:25:24,720 --> 00:25:28,159
fakes and what extent

518
00:25:28,159 --> 00:25:31,279
sorry say again please uh if there are

519
00:25:31,279 --> 00:25:33,840
there was some kind of deep fakes

520
00:25:33,840 --> 00:25:37,279
in the real world uh i think

521
00:25:37,279 --> 00:25:39,520
i think this is the question yeah right

522
00:25:39,520 --> 00:25:40,320
right yeah

523
00:25:40,320 --> 00:25:42,559
you can find lots of examples like for

524
00:25:42,559 --> 00:25:44,559
example the the obama one that you

525
00:25:44,559 --> 00:25:47,760
that you can see on in our presentation

526
00:25:47,760 --> 00:25:49,840
but these phases are getting better and

527
00:25:49,840 --> 00:25:50,880
better every day

528
00:25:50,880 --> 00:25:54,000
so for sure in a in a in a short time we

529
00:25:54,000 --> 00:25:55,039
are going to

530
00:25:55,039 --> 00:25:59,360
be um no it's going to be impossible to

531
00:25:59,360 --> 00:26:02,480
to know if some video is real 100

532
00:26:02,480 --> 00:26:04,720
so we are we are right now trying to

533
00:26:04,720 --> 00:26:06,320
find different techniques

534
00:26:06,320 --> 00:26:09,760
to detect that uh if a video is a defect

535
00:26:09,760 --> 00:26:10,159
or

536
00:26:10,159 --> 00:26:13,360
not basing other things more than the

537
00:26:13,360 --> 00:26:15,919
the ai you know like for example the the

538
00:26:15,919 --> 00:26:17,039
one that we

539
00:26:17,039 --> 00:26:20,240
we said on the on the slide right for

540
00:26:20,240 --> 00:26:22,000
example the blinking of the eyes

541
00:26:22,000 --> 00:26:24,240
the position of the body so that that

542
00:26:24,240 --> 00:26:25,520
kind of thing that are

543
00:26:25,520 --> 00:26:28,880
outside the area are um i think they are

544
00:26:28,880 --> 00:26:30,559
the main factors to try to

545
00:26:30,559 --> 00:26:33,840
the defend us against the new generation

546
00:26:33,840 --> 00:26:36,559
of deep fakes

547
00:26:36,559 --> 00:26:39,440
okay good luck for your work because i

548
00:26:39,440 --> 00:26:40,320
really

549
00:26:40,320 --> 00:26:42,559
thank you it would be really important

550
00:26:42,559 --> 00:26:43,760
if the next year

551
00:26:43,760 --> 00:26:47,279
in order to thought the new uh coming of

552
00:26:47,279 --> 00:26:48,799
advanced fake news

553
00:26:48,799 --> 00:26:50,799
that it was already a problem until now

554
00:26:50,799 --> 00:26:53,039
in the last years and with deep fakes i

555
00:26:53,039 --> 00:26:53,760
think that they

556
00:26:53,760 --> 00:26:56,320
become a huge huge problem for all

557
00:26:56,320 --> 00:26:58,960
around the world

558
00:26:59,679 --> 00:27:02,960
thanks for your work thanks for sharing

559
00:27:02,960 --> 00:27:06,000
it with us and thank you again and see

560
00:27:06,000 --> 00:27:06,960
you soon

561
00:27:06,960 --> 00:27:16,080
thank you very much thank you very much

