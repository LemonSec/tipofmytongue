1
00:00:02,100 --> 00:00:05,640
our next speaker is Andrew Krug who is

2
00:00:05,640 --> 00:00:07,700
going to talk to us about

3
00:00:07,700 --> 00:00:10,860
politics in the cloud in specifically

4
00:00:10,860 --> 00:00:13,500
one form of government democracy

5
00:00:13,500 --> 00:00:16,500
democratization

6
00:00:16,980 --> 00:00:18,480
and he tells me that's not the one

7
00:00:18,480 --> 00:00:20,880
that's under attack now so

8
00:00:20,880 --> 00:00:22,680
relax

9
00:00:22,680 --> 00:00:24,960
I was actually uh making jokes with the

10
00:00:24,960 --> 00:00:27,539
keynote speaker earlier who literally

11
00:00:27,539 --> 00:00:29,699
stood on stage here and just said be

12
00:00:29,699 --> 00:00:31,980
nice to each other because my thing is

13
00:00:31,980 --> 00:00:34,980
mostly a thinly veiled attempt at also

14
00:00:34,980 --> 00:00:36,960
tricking you into being nice to each

15
00:00:36,960 --> 00:00:39,000
other and that feels like a lot of the

16
00:00:39,000 --> 00:00:40,680
work that we're doing these days is

17
00:00:40,680 --> 00:00:42,600
we're just coming up with more and more

18
00:00:42,600 --> 00:00:45,059
reasons to work together and then you

19
00:00:45,059 --> 00:00:47,160
know slapping an architecture diagram on

20
00:00:47,160 --> 00:00:48,480
top of that and then it becomes a

21
00:00:48,480 --> 00:00:50,700
framework or something

22
00:00:50,700 --> 00:00:52,620
I don't know if anybody was here for uh

23
00:00:52,620 --> 00:00:55,559
Adam's presentation just before this but

24
00:00:55,559 --> 00:00:57,840
Adam kind of alluded to the fact that

25
00:00:57,840 --> 00:00:59,340
that people work in this place that's

26
00:00:59,340 --> 00:01:01,260
called the cloud

27
00:01:01,260 --> 00:01:03,300
um you know so like a hundred billion

28
00:01:03,300 --> 00:01:06,060
dollar business or something and uh

29
00:01:06,060 --> 00:01:08,460
Adam's the only person I know that

30
00:01:08,460 --> 00:01:12,979
refers to the cloud as a sub-platform

31
00:01:13,200 --> 00:01:15,479
so this is the democratizing security

32
00:01:15,479 --> 00:01:17,939
talk uh welcome to democratizing

33
00:01:17,939 --> 00:01:20,520
Security in the cloud we're of course

34
00:01:20,520 --> 00:01:22,080
here back in person at Wild West

35
00:01:22,080 --> 00:01:23,700
hackenfest

36
00:01:23,700 --> 00:01:25,799
um if I sound a little funky I swear I

37
00:01:25,799 --> 00:01:28,380
don't have covid this time but I have

38
00:01:28,380 --> 00:01:30,119
been conferencing for about three weeks

39
00:01:30,119 --> 00:01:33,060
now and my voice is a little tired

40
00:01:33,060 --> 00:01:35,100
but I'm not hating the weather

41
00:01:35,100 --> 00:01:36,979
today we are going to talk about

42
00:01:36,979 --> 00:01:39,000
democratizing security and what I mean

43
00:01:39,000 --> 00:01:41,100
by that especially as it relates to the

44
00:01:41,100 --> 00:01:43,320
cloud we'll look at kind of the attack

45
00:01:43,320 --> 00:01:45,720
surface of a few interesting things that

46
00:01:45,720 --> 00:01:47,759
have been going on in the cloud and

47
00:01:47,759 --> 00:01:49,799
we'll learn about how attackers are

48
00:01:49,799 --> 00:01:52,320
democratizing security faster than

49
00:01:52,320 --> 00:01:54,360
Defenders

50
00:01:54,360 --> 00:01:56,280
there are a lot of different ways that

51
00:01:56,280 --> 00:01:58,920
we can all kind of get to democratized

52
00:01:58,920 --> 00:02:01,979
security right the paths are mini and

53
00:02:01,979 --> 00:02:03,540
today we'll just look at some of the

54
00:02:03,540 --> 00:02:05,280
things that you could potentially do in

55
00:02:05,280 --> 00:02:07,259
your software development life cycle to

56
00:02:07,259 --> 00:02:08,699
kind of do this thing that we're we're

57
00:02:08,699 --> 00:02:10,739
called democratizing or some people some

58
00:02:10,739 --> 00:02:12,360
people refer to this as accessible

59
00:02:12,360 --> 00:02:13,739
security

60
00:02:13,739 --> 00:02:16,140
in case we haven't met I'm Andrew Krug I

61
00:02:16,140 --> 00:02:17,879
lead the security evangelism team at

62
00:02:17,879 --> 00:02:18,959
datadog

63
00:02:18,959 --> 00:02:21,180
I'm also hiring if anybody's looking for

64
00:02:21,180 --> 00:02:23,459
work I also teach the cloud security

65
00:02:23,459 --> 00:02:26,640
class for anti-siphon training which we

66
00:02:26,640 --> 00:02:28,140
did the last two days I think some of

67
00:02:28,140 --> 00:02:30,360
the folks in the room were at that class

68
00:02:30,360 --> 00:02:33,900
we had a great time most of my work in

69
00:02:33,900 --> 00:02:35,459
the cloud space though is on incident

70
00:02:35,459 --> 00:02:38,280
response forensics and automation sort

71
00:02:38,280 --> 00:02:40,200
of did a bunch of work a few years back

72
00:02:40,200 --> 00:02:42,840
on automating memory forensics and

73
00:02:42,840 --> 00:02:45,599
things at scale and if you go and Google

74
00:02:45,599 --> 00:02:47,580
for that you'll find that my socials are

75
00:02:47,580 --> 00:02:48,900
on the slide if you want to follow me on

76
00:02:48,900 --> 00:02:50,400
Twitter I'm actually dangerously close

77
00:02:50,400 --> 00:02:52,319
to a thousand followers and I don't know

78
00:02:52,319 --> 00:02:53,640
you know if I'm going to get coveted

79
00:02:53,640 --> 00:02:55,019
again before I hit a thousand or else

80
00:02:55,019 --> 00:02:56,940
I'll hit a thousand first you know you

81
00:02:56,940 --> 00:02:58,800
be the judge

82
00:02:58,800 --> 00:03:01,200
besides uh the professional if you have

83
00:03:01,200 --> 00:03:02,819
no interest at all in Cloud security I

84
00:03:02,819 --> 00:03:05,640
also like saxophones old tractors horses

85
00:03:05,640 --> 00:03:09,180
and Legend of Zelda not any specific one

86
00:03:09,180 --> 00:03:11,159
um but you know there's uh seems to be

87
00:03:11,159 --> 00:03:13,319
making a bit of a Resurgence so when you

88
00:03:13,319 --> 00:03:15,840
think about democratizing security you

89
00:03:15,840 --> 00:03:17,159
might think that this is kind of like a

90
00:03:17,159 --> 00:03:18,540
management level non-technical

91
00:03:18,540 --> 00:03:21,300
presentation and the topic sounds a lot

92
00:03:21,300 --> 00:03:23,879
like buzzwords right well some of it is

93
00:03:23,879 --> 00:03:26,099
and some of it's actually uh very

94
00:03:26,099 --> 00:03:27,780
tactical and you can apply to your

95
00:03:27,780 --> 00:03:30,120
organization if you prefer the Clint

96
00:03:30,120 --> 00:03:31,920
Gibbler version of this meme he throws

97
00:03:31,920 --> 00:03:33,780
this in a lot of his slide decks so if

98
00:03:33,780 --> 00:03:36,000
anybody wants to boo and say the topic

99
00:03:36,000 --> 00:03:37,799
is bad you know you wouldn't be wrong

100
00:03:37,799 --> 00:03:39,959
all the links and slides for the talk

101
00:03:39,959 --> 00:03:42,840
are available here if I can trick you

102
00:03:42,840 --> 00:03:44,940
into scanning a QR code

103
00:03:44,940 --> 00:03:47,580
you're welcome to visit the GitHub gist

104
00:03:47,580 --> 00:03:50,280
and and download the slides

105
00:03:50,280 --> 00:03:52,860
so let's take a minute to Define what I

106
00:03:52,860 --> 00:03:55,560
what I mean when I say democratizing uh

107
00:03:55,560 --> 00:03:58,080
my first contact with this idea was

108
00:03:58,080 --> 00:04:00,180
actually in 2020 and I was watching this

109
00:04:00,180 --> 00:04:02,280
talk from one of the RSA Keynotes on big

110
00:04:02,280 --> 00:04:05,040
stage and I saw Wendy nather from Cisco

111
00:04:05,040 --> 00:04:09,060
formerly of Duo talking about the rise

112
00:04:09,060 --> 00:04:10,920
of the citizen contributor and I think

113
00:04:10,920 --> 00:04:13,080
this is the first time that this idea

114
00:04:13,080 --> 00:04:15,599
really clicked for me and it didn't seem

115
00:04:15,599 --> 00:04:18,060
like anything besides uh marketing

116
00:04:18,060 --> 00:04:20,100
jargon I'll reference this presentation

117
00:04:20,100 --> 00:04:22,440
a few times during the talk but this is

118
00:04:22,440 --> 00:04:24,120
really was really my inspiration for

119
00:04:24,120 --> 00:04:25,979
sitting down and kind of thinking

120
00:04:25,979 --> 00:04:28,080
through how we could apply this idea to

121
00:04:28,080 --> 00:04:30,000
cloud computing and our use of it as an

122
00:04:30,000 --> 00:04:32,460
industry this wasn't new though like we

123
00:04:32,460 --> 00:04:34,800
had been sort of kicking around this

124
00:04:34,800 --> 00:04:36,900
idea of democratized Technology since

125
00:04:36,900 --> 00:04:41,220
about 2013 or so so the first Wikipedia

126
00:04:41,220 --> 00:04:43,259
page goes all the way back there it's

127
00:04:43,259 --> 00:04:45,720
not a new idea but it's taken us a while

128
00:04:45,720 --> 00:04:47,820
as a security culture to kind of arrive

129
00:04:47,820 --> 00:04:49,620
at this as a solution to some of the

130
00:04:49,620 --> 00:04:51,840
social problems we're for having in our

131
00:04:51,840 --> 00:04:53,520
our businesses right and I think we can

132
00:04:53,520 --> 00:04:56,040
all agree that we have a lot of social

133
00:04:56,040 --> 00:04:58,620
problems when it comes to security teams

134
00:04:58,620 --> 00:05:00,600
working well with software development

135
00:05:00,600 --> 00:05:02,460
teams or operations teams we're getting

136
00:05:02,460 --> 00:05:04,500
there we're learning to be nicer to each

137
00:05:04,500 --> 00:05:07,440
other but uh we just don't have all the

138
00:05:07,440 --> 00:05:09,360
tools that we need if we want to just

139
00:05:09,360 --> 00:05:11,820
Define it kind of further I think that

140
00:05:11,820 --> 00:05:13,039
we could define

141
00:05:13,039 --> 00:05:15,600
democracy as making technology

142
00:05:15,600 --> 00:05:19,199
accessible to folks besides the primary

143
00:05:19,199 --> 00:05:20,940
audience right so when I think of this

144
00:05:20,940 --> 00:05:23,160
it's security tools and security things

145
00:05:23,160 --> 00:05:25,860
that anybody can interact with even if

146
00:05:25,860 --> 00:05:28,500
they don't know anything about security

147
00:05:28,500 --> 00:05:31,020
and somehow they can still end up doing

148
00:05:31,020 --> 00:05:33,060
the right thing and if we break that

149
00:05:33,060 --> 00:05:35,520
down into three primary areas to focus

150
00:05:35,520 --> 00:05:37,680
on where both where we're looking for

151
00:05:37,680 --> 00:05:40,020
means of improvement or we're looking

152
00:05:40,020 --> 00:05:43,259
for friction I think that we can we can

153
00:05:43,259 --> 00:05:45,900
define those as control design and

154
00:05:45,900 --> 00:05:48,180
culture right security gets a bad rap

155
00:05:48,180 --> 00:05:52,259
sometimes for being overly controlling

156
00:05:52,259 --> 00:05:54,180
especially when it comes to this design

157
00:05:54,180 --> 00:05:56,940
process and that results in some kind of

158
00:05:56,940 --> 00:05:59,220
cultural friction

159
00:05:59,220 --> 00:06:00,780
so what we need to do is we need to move

160
00:06:00,780 --> 00:06:02,759
towards a model where we are using

161
00:06:02,759 --> 00:06:05,100
collaborative control simplified design

162
00:06:05,100 --> 00:06:08,100
and an open and transparent culture and

163
00:06:08,100 --> 00:06:10,259
that might sound easy to do but it's

164
00:06:10,259 --> 00:06:12,120
actually really hard in practice to do

165
00:06:12,120 --> 00:06:14,400
this 100 of the time and if you really

166
00:06:14,400 --> 00:06:16,380
think about it I bet each of you can

167
00:06:16,380 --> 00:06:17,880
think about a project that you're

168
00:06:17,880 --> 00:06:20,160
working on in your security team right

169
00:06:20,160 --> 00:06:23,340
now where you're experiencing friction

170
00:06:23,340 --> 00:06:25,919
due to one a failure in one of these

171
00:06:25,919 --> 00:06:27,240
areas

172
00:06:27,240 --> 00:06:29,940
and in the meantime we've all been going

173
00:06:29,940 --> 00:06:32,280
through this massive change in the way

174
00:06:32,280 --> 00:06:34,259
that we're showing up to work for the

175
00:06:34,259 --> 00:06:36,660
last three years or so right like things

176
00:06:36,660 --> 00:06:39,360
are fundamentally different in our

177
00:06:39,360 --> 00:06:42,539
professional and personal lives

178
00:06:42,539 --> 00:06:45,000
our work-life balance is a lot different

179
00:06:45,000 --> 00:06:47,100
than it was and a lot of us that weren't

180
00:06:47,100 --> 00:06:49,139
used to working at home have started

181
00:06:49,139 --> 00:06:50,340
working at home

182
00:06:50,340 --> 00:06:51,900
and the way that this kind of relates to

183
00:06:51,900 --> 00:06:54,599
cloud is that as we have moved things

184
00:06:54,599 --> 00:06:56,880
out of the Enterprise and out of data

185
00:06:56,880 --> 00:06:58,740
centers and into places where it's

186
00:06:58,740 --> 00:07:00,840
easier to get at from home we've

187
00:07:00,840 --> 00:07:02,940
actually increased the risk and we've

188
00:07:02,940 --> 00:07:06,300
also increased people's expectation of

189
00:07:06,300 --> 00:07:08,639
what that work experience is going to be

190
00:07:08,639 --> 00:07:10,259
like at home

191
00:07:10,259 --> 00:07:12,900
our users have really come to expect a

192
00:07:12,900 --> 00:07:14,819
consumer level experience and a hundred

193
00:07:14,819 --> 00:07:16,319
percent of the systems that they used to

194
00:07:16,319 --> 00:07:18,539
do their job right they want that same

195
00:07:18,539 --> 00:07:21,780
level of polish on things as their

196
00:07:21,780 --> 00:07:24,539
interaction with their like Roku TV or

197
00:07:24,539 --> 00:07:26,340
Netflix interface

198
00:07:26,340 --> 00:07:28,080
I remember when I started in security

199
00:07:28,080 --> 00:07:30,060
before security alerting was really

200
00:07:30,060 --> 00:07:31,620
accessible to everybody we used to just

201
00:07:31,620 --> 00:07:33,900
throw Consolidated syslog up on screen

202
00:07:33,900 --> 00:07:36,419
maybe we would pipe it to a colorizer if

203
00:07:36,419 --> 00:07:38,460
we're feeling fancy and we would look

204
00:07:38,460 --> 00:07:41,160
for things that that we should be aware

205
00:07:41,160 --> 00:07:45,300
of right so uh that's a kind of the

206
00:07:45,300 --> 00:07:47,580
original Sim and if you were feeling

207
00:07:47,580 --> 00:07:49,800
fancy maybe you wrote a Perl script to

208
00:07:49,800 --> 00:07:51,240
parse some of this and you get like an

209
00:07:51,240 --> 00:07:53,639
email roll up at the end of the day this

210
00:07:53,639 --> 00:07:56,460
is a quote uh right out of that ER RSA

211
00:07:56,460 --> 00:07:58,560
presentation nobody wants to go home

212
00:07:58,560 --> 00:08:00,840
after work and use their Erp software

213
00:08:00,840 --> 00:08:02,099
for fun

214
00:08:02,099 --> 00:08:04,560
I'd go ahead and uh just kind of

215
00:08:04,560 --> 00:08:06,300
paraphrase that and say nobody wants to

216
00:08:06,300 --> 00:08:07,620
go home at the end of the day and use

217
00:08:07,620 --> 00:08:10,259
their their Sim software for fun and if

218
00:08:10,259 --> 00:08:12,120
you do maybe we should stage an

219
00:08:12,120 --> 00:08:14,400
intervention

220
00:08:14,400 --> 00:08:15,840
and I think we could apply this

221
00:08:15,840 --> 00:08:17,759
statement to to most of the tools we're

222
00:08:17,759 --> 00:08:21,660
actually forcing our user base to use as

223
00:08:21,660 --> 00:08:24,780
part of their day-to-day right if if

224
00:08:24,780 --> 00:08:25,860
they don't

225
00:08:25,860 --> 00:08:28,440
if they don't derive Joy from it they're

226
00:08:28,440 --> 00:08:30,539
not going to continue to want to use

227
00:08:30,539 --> 00:08:32,039
that especially if they're not security

228
00:08:32,039 --> 00:08:34,740
personas there was one statement from

229
00:08:34,740 --> 00:08:36,240
the talk that really kind of made me

230
00:08:36,240 --> 00:08:39,479
wonder though and that was when they she

231
00:08:39,479 --> 00:08:42,120
said that we are already democratizing

232
00:08:42,120 --> 00:08:43,620
security for the cloud and I said to

233
00:08:43,620 --> 00:08:46,380
myself I actually really don't think we

234
00:08:46,380 --> 00:08:48,360
are democratizing security for the cloud

235
00:08:48,360 --> 00:08:51,779
maybe we are for SAS apis and SAS

236
00:08:51,779 --> 00:08:54,899
services in the sense that we we as

237
00:08:54,899 --> 00:08:57,240
users control our use of that software

238
00:08:57,240 --> 00:09:00,180
but when it comes to infrastructure as a

239
00:09:00,180 --> 00:09:01,800
service or the platforms that we're

240
00:09:01,800 --> 00:09:04,380
running code on we're really not

241
00:09:04,380 --> 00:09:06,779
democratizing and we can do a much

242
00:09:06,779 --> 00:09:09,660
better job sorry we're having some audio

243
00:09:09,660 --> 00:09:11,399
trouble it would seem

244
00:09:11,399 --> 00:09:13,080
we can do a much better job making

245
00:09:13,080 --> 00:09:15,000
systems accessible and usable by

246
00:09:15,000 --> 00:09:17,279
everyone and when I say everyone I mean

247
00:09:17,279 --> 00:09:19,320
people who aren't security people or at

248
00:09:19,320 --> 00:09:20,880
least people who don't identify

249
00:09:20,880 --> 00:09:23,700
primarily as security people we need to

250
00:09:23,700 --> 00:09:25,980
be thinking about designing for those

251
00:09:25,980 --> 00:09:28,200
folks first so remember when you're

252
00:09:28,200 --> 00:09:30,360
asking yourself if they process or

253
00:09:30,360 --> 00:09:32,399
technology as Democratic it has to meet

254
00:09:32,399 --> 00:09:35,160
these pieces of criteria it has to be

255
00:09:35,160 --> 00:09:37,620
accessible to non-technical users or at

256
00:09:37,620 --> 00:09:39,120
least users outside of the subject

257
00:09:39,120 --> 00:09:42,000
matter expertise area in such a way that

258
00:09:42,000 --> 00:09:44,399
they can actually use that technology so

259
00:09:44,399 --> 00:09:45,420
for us

260
00:09:45,420 --> 00:09:47,760
designing for Security Plus developers

261
00:09:47,760 --> 00:09:49,680
seems like a really reasonable place to

262
00:09:49,680 --> 00:09:51,839
start and maybe as a bonus we'd like to

263
00:09:51,839 --> 00:09:53,880
create tools and tactics that scale

264
00:09:53,880 --> 00:09:55,500
Beyond just Security Plus developers

265
00:09:55,500 --> 00:09:57,779
maybe we want to empower somebody in a

266
00:09:57,779 --> 00:09:59,640
leadership role to take an action at a

267
00:09:59,640 --> 00:10:02,279
certain phase So based on that test I

268
00:10:02,279 --> 00:10:04,440
don't really think as an industry that

269
00:10:04,440 --> 00:10:05,940
we're as good as we could be at

270
00:10:05,940 --> 00:10:07,560
democratizing the usage of cloud

271
00:10:07,560 --> 00:10:10,320
providers and I think there's a you know

272
00:10:10,320 --> 00:10:12,480
we all have different levels of comfort

273
00:10:12,480 --> 00:10:14,760
with cloud in the room I mean I would

274
00:10:14,760 --> 00:10:16,260
say just like raise your hand if you

275
00:10:16,260 --> 00:10:17,820
feel really comfortable with your cloud

276
00:10:17,820 --> 00:10:19,860
provider

277
00:10:19,860 --> 00:10:22,200
yet we are all security people and not a

278
00:10:22,200 --> 00:10:24,660
single hand went up that said I'm really

279
00:10:24,660 --> 00:10:26,880
comfortable with my cloud provider

280
00:10:26,880 --> 00:10:28,800
is anybody willing to identify as just

281
00:10:28,800 --> 00:10:31,260
not in the cloud at all still like you

282
00:10:31,260 --> 00:10:33,000
have zero things

283
00:10:33,000 --> 00:10:34,860
so every person has at least one thing

284
00:10:34,860 --> 00:10:36,480
in the cloud and no one is comfortable

285
00:10:36,480 --> 00:10:38,399
with the technology stack that they're

286
00:10:38,399 --> 00:10:41,160
responsible for securing so in that

287
00:10:41,160 --> 00:10:43,920
sense we all really really need to do

288
00:10:43,920 --> 00:10:45,540
better to make these things more

289
00:10:45,540 --> 00:10:47,820
accessible to everybody and one thing I

290
00:10:47,820 --> 00:10:50,399
do know though is that attackers are

291
00:10:50,399 --> 00:10:52,500
democratizing their tools tactics and

292
00:10:52,500 --> 00:10:55,019
techniques way faster than Defenders

293
00:10:55,019 --> 00:10:56,579
and usually what this looks a lot like

294
00:10:56,579 --> 00:11:00,360
is automation but also due to the

295
00:11:00,360 --> 00:11:03,540
distributed nature anonymity and dogged

296
00:11:03,540 --> 00:11:05,880
pursuit of a single goal attackers are

297
00:11:05,880 --> 00:11:07,500
sharing sharing knowledge a lot more

298
00:11:07,500 --> 00:11:09,360
freely than Defenders they automate

299
00:11:09,360 --> 00:11:11,579
repetitive tasks they developed

300
00:11:11,579 --> 00:11:14,579
technology to make uh the application of

301
00:11:14,579 --> 00:11:16,440
their methods more accessible and they

302
00:11:16,440 --> 00:11:17,940
spend a fair bit of time actually

303
00:11:17,940 --> 00:11:20,519
thinking about user experience just

304
00:11:20,519 --> 00:11:22,140
think about the amount of hours that

305
00:11:22,140 --> 00:11:24,240
goes into running a decent fishing

306
00:11:24,240 --> 00:11:25,560
campaign

307
00:11:25,560 --> 00:11:28,140
and taking a user happy path to clicking

308
00:11:28,140 --> 00:11:30,420
on that piece of ransomware and we see

309
00:11:30,420 --> 00:11:32,579
this all the time right the biggest

310
00:11:32,579 --> 00:11:34,620
difference is that and we've all heard

311
00:11:34,620 --> 00:11:36,839
this before attackers only have to be

312
00:11:36,839 --> 00:11:38,820
successful one time

313
00:11:38,820 --> 00:11:41,459
and Defenders have to be successful a

314
00:11:41,459 --> 00:11:43,200
hundred percent of the time

315
00:11:43,200 --> 00:11:44,880
so I borrowed a couple of bits from this

316
00:11:44,880 --> 00:11:48,180
presentation from a blog post that

317
00:11:48,180 --> 00:11:49,740
somebody works on my team at datadog

318
00:11:49,740 --> 00:11:53,639
wrote and gave a readout on at Sans new

319
00:11:53,639 --> 00:11:56,100
to cyber it was called fantastic hacks

320
00:11:56,100 --> 00:11:58,019
and where to find them it's kind of a a

321
00:11:58,019 --> 00:12:00,480
look back year in review at Cloud

322
00:12:00,480 --> 00:12:02,519
breaches

323
00:12:02,519 --> 00:12:04,260
for this talk I thought it would be fun

324
00:12:04,260 --> 00:12:06,000
to do a little bit of analysis and

325
00:12:06,000 --> 00:12:07,920
categorization on the types of attacks

326
00:12:07,920 --> 00:12:09,839
that we're seeing if you want to go

327
00:12:09,839 --> 00:12:11,820
check out fantastic hacks and where to

328
00:12:11,820 --> 00:12:13,800
find them I threw the link in the slide

329
00:12:13,800 --> 00:12:15,839
deck here and it's also on that GitHub

330
00:12:15,839 --> 00:12:18,060
gist that the QR code was attached to

331
00:12:18,060 --> 00:12:20,399
seriously the QR code really is only

332
00:12:20,399 --> 00:12:22,260
attached to a GitHub just it's safe to

333
00:12:22,260 --> 00:12:23,399
scan

334
00:12:23,399 --> 00:12:26,040
you can trust me I swear so how are we

335
00:12:26,040 --> 00:12:28,620
doing uh the question I always ask is

336
00:12:28,620 --> 00:12:30,600
are we getting better at preventing the

337
00:12:30,600 --> 00:12:32,940
top three types of attacks and the

338
00:12:32,940 --> 00:12:35,579
answer really seems to be that we aren't

339
00:12:35,579 --> 00:12:37,740
the majority of these are the same root

340
00:12:37,740 --> 00:12:39,720
cause that I started uh talking about

341
00:12:39,720 --> 00:12:42,540
when I began speaking on cloud security

342
00:12:42,540 --> 00:12:44,880
back in 2015.

343
00:12:44,880 --> 00:12:45,959
so

344
00:12:45,959 --> 00:12:48,839
these are uh Pro the the top problems

345
00:12:48,839 --> 00:12:51,120
are the result of credential leaks right

346
00:12:51,120 --> 00:12:53,339
that's a bit unsurprising

347
00:12:53,339 --> 00:12:55,139
but this still isn't really a problem

348
00:12:55,139 --> 00:12:56,940
that we've adopted solutions for as an

349
00:12:56,940 --> 00:12:58,860
industry we're leaking credentials all

350
00:12:58,860 --> 00:13:00,060
the time they're very impractical

351
00:13:00,060 --> 00:13:02,040
impactful they result in data breaches

352
00:13:02,040 --> 00:13:03,779
they result in crypto mining but we're

353
00:13:03,779 --> 00:13:05,579
really kind of treating the symptom and

354
00:13:05,579 --> 00:13:06,720
not the problem

355
00:13:06,720 --> 00:13:08,339
there's plenty of solutions out there

356
00:13:08,339 --> 00:13:10,320
but we're just not seeing the adoption

357
00:13:10,320 --> 00:13:12,540
curve really move at all

358
00:13:12,540 --> 00:13:14,399
I might say it's not moving fast enough

359
00:13:14,399 --> 00:13:15,899
but it's really not moving at all in

360
00:13:15,899 --> 00:13:18,000
fact if we look at the metrics we're

361
00:13:18,000 --> 00:13:20,639
just as bad as we were in 2015.

362
00:13:20,639 --> 00:13:22,980
Insider threats here actually really

363
00:13:22,980 --> 00:13:25,800
surprised me uh how uh how prevalent

364
00:13:25,800 --> 00:13:28,740
they were in the um last year's worth of

365
00:13:28,740 --> 00:13:30,360
cloud breaches they made up over eight

366
00:13:30,360 --> 00:13:31,500
percent

367
00:13:31,500 --> 00:13:33,600
this is also kind of a credential

368
00:13:33,600 --> 00:13:35,220
management problem as well in the sense

369
00:13:35,220 --> 00:13:37,440
that these were the result of a

370
00:13:37,440 --> 00:13:39,480
termination of access issue in many

371
00:13:39,480 --> 00:13:41,339
cases where you had an employee depart

372
00:13:41,339 --> 00:13:42,959
or sever their employment relationship

373
00:13:42,959 --> 00:13:44,760
and they came back months and months

374
00:13:44,760 --> 00:13:47,399
later and actually exfil traded data or

375
00:13:47,399 --> 00:13:50,100
to face an environment or committed some

376
00:13:50,100 --> 00:13:53,100
other Act of corporate Espionage so long

377
00:13:53,100 --> 00:13:55,019
after somebody had left they maintain

378
00:13:55,019 --> 00:13:57,600
maintain privilege access and then

379
00:13:57,600 --> 00:13:58,880
there's misconfiguration

380
00:13:58,880 --> 00:14:01,260
misconfiguration tends to be these S3

381
00:14:01,260 --> 00:14:03,000
buckets open to the world types of

382
00:14:03,000 --> 00:14:05,760
breaches these are highly impactful due

383
00:14:05,760 --> 00:14:07,560
to the amount of public data that's

384
00:14:07,560 --> 00:14:09,300
exposed in every single one of these and

385
00:14:09,300 --> 00:14:11,279
I don't think that we go a quarter

386
00:14:11,279 --> 00:14:13,560
without seeing a headline that says

387
00:14:13,560 --> 00:14:16,680
Amazon server exposes data or something

388
00:14:16,680 --> 00:14:18,180
like that usually they're talking about

389
00:14:18,180 --> 00:14:21,180
S3 they're not actually talking about a

390
00:14:21,180 --> 00:14:24,480
server running in AWS and if we Loop in

391
00:14:24,480 --> 00:14:27,300
server-side request forgeries which I

392
00:14:27,300 --> 00:14:29,040
also put in that credential category

393
00:14:29,040 --> 00:14:32,160
it's about 60 makes up about 62 percent

394
00:14:32,160 --> 00:14:34,620
of cloud incidents so that's really

395
00:14:34,620 --> 00:14:36,899
really significant right and I do that

396
00:14:36,899 --> 00:14:38,820
because generally the goal of an

397
00:14:38,820 --> 00:14:42,360
attacker using an ssrf to gain access is

398
00:14:42,360 --> 00:14:43,980
to exfiltrate some kind of machine level

399
00:14:43,980 --> 00:14:46,260
credential to another place and then

400
00:14:46,260 --> 00:14:48,779
leverage that gain access to more data

401
00:14:48,779 --> 00:14:52,019
or exfiltrate data so if we look at the

402
00:14:52,019 --> 00:14:54,120
top three there that means that roughly

403
00:14:54,120 --> 00:14:57,120
82 percent of incidents are not related

404
00:14:57,120 --> 00:14:59,160
to vulnerabilities in the environment at

405
00:14:59,160 --> 00:15:01,199
all they're actually mistakes that are

406
00:15:01,199 --> 00:15:03,000
made by the folks who work for your

407
00:15:03,000 --> 00:15:04,380
companies

408
00:15:04,380 --> 00:15:06,720
so your biggest threat is actually the

409
00:15:06,720 --> 00:15:09,420
people who have access and are using

410
00:15:09,420 --> 00:15:11,399
your cloud services

411
00:15:11,399 --> 00:15:13,139
Gartner also predicts that

412
00:15:13,139 --> 00:15:14,639
misconfigurations are going to increase

413
00:15:14,639 --> 00:15:17,880
over the next two years this quote uh is

414
00:15:17,880 --> 00:15:19,860
straight out of a Gartner report it says

415
00:15:19,860 --> 00:15:22,220
that they believe it will increase to 99

416
00:15:22,220 --> 00:15:24,720
of the cause of breaches due to the

417
00:15:24,720 --> 00:15:26,839
increasing complexity of environments

418
00:15:26,839 --> 00:15:28,800
what's actually that hard to believe

419
00:15:28,800 --> 00:15:30,480
because things are getting more and more

420
00:15:30,480 --> 00:15:33,240
complex but at the same time it's like

421
00:15:33,240 --> 00:15:36,300
thanks for the vote of confidence

422
00:15:36,300 --> 00:15:37,980
you know I really think that we actually

423
00:15:37,980 --> 00:15:40,500
can do better at detecting these things

424
00:15:40,500 --> 00:15:43,740
early and preventing misconfiguration

425
00:15:43,740 --> 00:15:45,779
so what we really need is we need

426
00:15:45,779 --> 00:15:47,880
security process and Technology that's

427
00:15:47,880 --> 00:15:50,100
for the people and by the people and

428
00:15:50,100 --> 00:15:51,660
what that really means is it's something

429
00:15:51,660 --> 00:15:54,060
that development teams and security

430
00:15:54,060 --> 00:15:57,300
teams enjoy using and they're going to

431
00:15:57,300 --> 00:15:59,399
adopt consistently

432
00:15:59,399 --> 00:16:01,500
especially in the cloud

433
00:16:01,500 --> 00:16:03,779
security for the people and by the

434
00:16:03,779 --> 00:16:05,459
people can solve many of our problems

435
00:16:05,459 --> 00:16:07,560
because Beyond those top three attacks

436
00:16:07,560 --> 00:16:10,259
if you examine the rest of the actual

437
00:16:10,259 --> 00:16:12,240
path of the attacker Beyond initial

438
00:16:12,240 --> 00:16:13,500
access

439
00:16:13,500 --> 00:16:15,959
the rest is pretty unsensational and

440
00:16:15,959 --> 00:16:18,120
we're pretty detecting and remediating

441
00:16:18,120 --> 00:16:18,899
it

442
00:16:18,899 --> 00:16:21,360
sure maybe the root cause in a small

443
00:16:21,360 --> 00:16:23,220
percentage of cases is something as

444
00:16:23,220 --> 00:16:26,160
awesome as log for J or spring for shell

445
00:16:26,160 --> 00:16:28,139
but the really cool new zero day isn't

446
00:16:28,139 --> 00:16:30,120
the thing we need to pay attention to we

447
00:16:30,120 --> 00:16:31,800
need to pay attention to the techniques

448
00:16:31,800 --> 00:16:34,199
tactics and procedures that are highly

449
00:16:34,199 --> 00:16:36,240
predictable we're seeing tons and tons

450
00:16:36,240 --> 00:16:39,600
of the same attacker run books right

451
00:16:39,600 --> 00:16:41,759
this is great for democratizing security

452
00:16:41,759 --> 00:16:44,100
because we can make prevention detection

453
00:16:44,100 --> 00:16:46,579
and response more accessible to everyone

454
00:16:46,579 --> 00:16:49,860
by using things like plain English to

455
00:16:49,860 --> 00:16:51,600
describe these attacks and also

456
00:16:51,600 --> 00:16:53,880
automation the headlines don't help us

457
00:16:53,880 --> 00:16:55,740
with this though when it comes to making

458
00:16:55,740 --> 00:16:58,019
the business believe sometimes that we

459
00:16:58,019 --> 00:17:00,000
can solve their problems

460
00:17:00,000 --> 00:17:01,980
if you're really starting to dig into

461
00:17:01,980 --> 00:17:04,500
these things they've got great headlines

462
00:17:04,500 --> 00:17:06,959
but instead of the focusing on the

463
00:17:06,959 --> 00:17:09,480
indicators of compromise journalists are

464
00:17:09,480 --> 00:17:12,359
focused on words like devious and highly

465
00:17:12,359 --> 00:17:15,480
sophisticated to fool you I recently uh

466
00:17:15,480 --> 00:17:16,799
was asked to take a look at this

467
00:17:16,799 --> 00:17:18,780
ransomware write-up from the dfir report

468
00:17:18,780 --> 00:17:20,579
I don't know if anybody ran across it as

469
00:17:20,579 --> 00:17:23,400
well it was called uh the quantum

470
00:17:23,400 --> 00:17:24,720
ransomware

471
00:17:24,720 --> 00:17:27,359
did anybody see that it was really just

472
00:17:27,359 --> 00:17:30,000
a really speedy ransomware and it

473
00:17:30,000 --> 00:17:32,760
started with a shortcut inside of an ISO

474
00:17:32,760 --> 00:17:34,679
but then if you look at the rest of the

475
00:17:34,679 --> 00:17:37,140
path it's pretty unsensational it loads

476
00:17:37,140 --> 00:17:39,960
a dll it dumps credentials from lsas

477
00:17:39,960 --> 00:17:42,900
it's even got plain old Cobalt strike in

478
00:17:42,900 --> 00:17:43,679
there

479
00:17:43,679 --> 00:17:45,780
what's incredibly sophisticated about

480
00:17:45,780 --> 00:17:47,580
that the only thing that's really

481
00:17:47,580 --> 00:17:50,460
impressive is that the democratization

482
00:17:50,460 --> 00:17:52,799
of this attack has made it so the

483
00:17:52,799 --> 00:17:54,780
automation has moved faster and faster

484
00:17:54,780 --> 00:17:56,160
than ever before inside of an

485
00:17:56,160 --> 00:17:57,419
environment

486
00:17:57,419 --> 00:17:59,340
I think we're all really tired of

487
00:17:59,340 --> 00:18:01,380
hearing that Automation and these

488
00:18:01,380 --> 00:18:03,419
predictable types of attacks is

489
00:18:03,419 --> 00:18:04,679
sophisticated

490
00:18:04,679 --> 00:18:06,900
and in many ways these are just taking

491
00:18:06,900 --> 00:18:08,880
advantage of the fact that when we put

492
00:18:08,880 --> 00:18:10,320
traditional on-prem Enterprise

493
00:18:10,320 --> 00:18:12,840
technology in the cloud it still

494
00:18:12,840 --> 00:18:14,760
requires the same security that we

495
00:18:14,760 --> 00:18:17,700
required on-prem in addition to the

496
00:18:17,700 --> 00:18:19,559
cloud concerns so really if you take an

497
00:18:19,559 --> 00:18:21,600
Enterprise and put in the cloud lift and

498
00:18:21,600 --> 00:18:25,140
shift it's just your Enterprise on cloud

499
00:18:25,140 --> 00:18:27,240
in some ways running Enterprise services

500
00:18:27,240 --> 00:18:29,340
on cloud becomes more challenging

501
00:18:29,340 --> 00:18:31,559
because the perimeter changed

502
00:18:31,559 --> 00:18:33,419
formerly things that used Network

503
00:18:33,419 --> 00:18:37,559
identity as a form of total identity are

504
00:18:37,559 --> 00:18:40,080
are no longer really okay that's because

505
00:18:40,080 --> 00:18:42,360
the cloud has these always on always

506
00:18:42,360 --> 00:18:45,000
accessible endpoints and in a an

507
00:18:45,000 --> 00:18:46,500
attacker gains access to your Cloud

508
00:18:46,500 --> 00:18:48,419
provider's control plane via a leaked

509
00:18:48,419 --> 00:18:51,240
credential it's pretty much game over so

510
00:18:51,240 --> 00:18:53,340
related to those problems but slightly

511
00:18:53,340 --> 00:18:55,620
different than those problems of just

512
00:18:55,620 --> 00:18:57,120
kind of like taking your Enterprise and

513
00:18:57,120 --> 00:18:59,360
lifting and shifting it into the cloud

514
00:18:59,360 --> 00:19:02,580
we have things that we call Cloud native

515
00:19:02,580 --> 00:19:05,700
technology now and arguably these need

516
00:19:05,700 --> 00:19:07,559
even more democratizing than our

517
00:19:07,559 --> 00:19:09,480
traditional Enterprise infrastructure

518
00:19:09,480 --> 00:19:11,480
these are things like kubernetes

519
00:19:11,480 --> 00:19:14,400
serverless technology like AWS Lambda

520
00:19:14,400 --> 00:19:16,860
and platform as a service like AWS

521
00:19:16,860 --> 00:19:19,440
fargate and Google Cloud run these

522
00:19:19,440 --> 00:19:21,179
environments support building things at

523
00:19:21,179 --> 00:19:23,160
a really different scale in a

524
00:19:23,160 --> 00:19:25,320
fundamentally different way so they

525
00:19:25,320 --> 00:19:27,840
inherently have more complexity and like

526
00:19:27,840 --> 00:19:30,419
everything else there are trade-offs and

527
00:19:30,419 --> 00:19:32,280
choosing to build on top of those

528
00:19:32,280 --> 00:19:35,700
platforms when we think about what

529
00:19:35,700 --> 00:19:37,799
technology to build on and when it comes

530
00:19:37,799 --> 00:19:40,020
to Cloud providers we always need to

531
00:19:40,020 --> 00:19:41,580
consider the trade-offs from a threat

532
00:19:41,580 --> 00:19:44,160
model perspective and also when it comes

533
00:19:44,160 --> 00:19:45,960
to the accessibility of that technology

534
00:19:45,960 --> 00:19:48,140
to our engineering teams especially

535
00:19:48,140 --> 00:19:50,340
non-security teams

536
00:19:50,340 --> 00:19:52,740
as you go up and down this pyramid I've

537
00:19:52,740 --> 00:19:55,679
sort of built here you have more control

538
00:19:55,679 --> 00:19:58,260
over the things that you have to work on

539
00:19:58,260 --> 00:20:00,480
more so at the top of the pyramid you

540
00:20:00,480 --> 00:20:03,480
might notice things like fat VMS like

541
00:20:03,480 --> 00:20:06,539
regular AWS ec2 instances

542
00:20:06,539 --> 00:20:09,480
and when we go down the pyramid

543
00:20:09,480 --> 00:20:12,900
of more control to less control you'll

544
00:20:12,900 --> 00:20:14,820
see that with ease of use we often have

545
00:20:14,820 --> 00:20:17,039
increased visibility concerns because

546
00:20:17,039 --> 00:20:19,140
those are the trade-offs we're not Opera

547
00:20:19,140 --> 00:20:21,000
operating the underlying infrastructure

548
00:20:21,000 --> 00:20:23,299
so we actually need more instrumentation

549
00:20:23,299 --> 00:20:25,620
not less

550
00:20:25,620 --> 00:20:28,200
I always like to ask folks in the cloud

551
00:20:28,200 --> 00:20:30,360
security class what do you think is the

552
00:20:30,360 --> 00:20:32,580
most expensive thing in your Cloud

553
00:20:32,580 --> 00:20:34,679
environment

554
00:20:34,679 --> 00:20:37,740
most people will guess compute

555
00:20:37,740 --> 00:20:40,260
and the that's generally wrong in a

556
00:20:40,260 --> 00:20:41,940
mature environment the thing that costs

557
00:20:41,940 --> 00:20:44,400
the most tends to be observability like

558
00:20:44,400 --> 00:20:47,520
actually monitoring logging and alerting

559
00:20:47,520 --> 00:20:50,539
on the things that you're running

560
00:20:50,580 --> 00:20:53,100
so this diagram isn't to say that you

561
00:20:53,100 --> 00:20:54,659
shouldn't build your application on top

562
00:20:54,659 --> 00:20:57,299
of something like AWS Lambda or ECS

563
00:20:57,299 --> 00:20:58,919
Freight

564
00:20:58,919 --> 00:21:00,720
it's just an acknowledgment that if you

565
00:21:00,720 --> 00:21:02,460
do you need to consider adding

566
00:21:02,460 --> 00:21:04,260
visibility into the way you build that

567
00:21:04,260 --> 00:21:06,419
surface or application having a plan at

568
00:21:06,419 --> 00:21:08,940
the outset socializing that plan and

569
00:21:08,940 --> 00:21:10,799
having clear indicators of compromise

570
00:21:10,799 --> 00:21:12,840
that you can make visible for security

571
00:21:12,840 --> 00:21:15,600
teams and not for that application it's

572
00:21:15,600 --> 00:21:18,600
really key to democratizing the security

573
00:21:18,600 --> 00:21:20,640
and if technology wasn't making things

574
00:21:20,640 --> 00:21:23,159
challenging enough we have this shift in

575
00:21:23,159 --> 00:21:24,720
the industry and the way that we're

576
00:21:24,720 --> 00:21:27,120
building things our industry doesn't

577
00:21:27,120 --> 00:21:29,880
build monolithic applications anymore on

578
00:21:29,880 --> 00:21:32,640
top of model view controller Frameworks

579
00:21:32,640 --> 00:21:35,580
we're shifting to microservices and on

580
00:21:35,580 --> 00:21:37,740
the slide here is actually a network

581
00:21:37,740 --> 00:21:40,559
flow diagram from a demo application we

582
00:21:40,559 --> 00:21:42,960
build at datadog to kind of demonstrate

583
00:21:42,960 --> 00:21:45,000
the way the tooling works and it's

584
00:21:45,000 --> 00:21:47,760
modeled after an e-commerce store like a

585
00:21:47,760 --> 00:21:50,460
regular e-commerce store I know it's a

586
00:21:50,460 --> 00:21:52,679
little small but you might note all the

587
00:21:52,679 --> 00:21:53,940
little services that we're all

588
00:21:53,940 --> 00:21:55,500
responsible for securing and running

589
00:21:55,500 --> 00:21:57,299
these days things that you normally

590
00:21:57,299 --> 00:21:59,159
wouldn't think of as part of a shopping

591
00:21:59,159 --> 00:22:01,679
cart experience like fraud detection

592
00:22:01,679 --> 00:22:04,520
product recommendations ad Services

593
00:22:04,520 --> 00:22:07,679
these are all places to hide

594
00:22:07,679 --> 00:22:10,559
this idea of microservices and 12-factor

595
00:22:10,559 --> 00:22:12,600
applications has made our lives as

596
00:22:12,600 --> 00:22:15,539
Defenders a lot more challenging and

597
00:22:15,539 --> 00:22:17,640
that's why simplification and democracy

598
00:22:17,640 --> 00:22:20,159
are becoming increasingly important

599
00:22:20,159 --> 00:22:22,200
right we actually have to empower the

600
00:22:22,200 --> 00:22:24,419
software development teams to take care

601
00:22:24,419 --> 00:22:26,400
of these things and think about the

602
00:22:26,400 --> 00:22:29,220
threat model on their own

603
00:22:29,220 --> 00:22:31,320
so how do we do that in the cloud you

604
00:22:31,320 --> 00:22:33,120
might be saying okay Andrew I believe

605
00:22:33,120 --> 00:22:35,400
you building for the cloud is hard it's

606
00:22:35,400 --> 00:22:37,679
easy to get breached in the cloud these

607
00:22:37,679 --> 00:22:38,580
applications are really really

608
00:22:38,580 --> 00:22:40,919
complicated what do we do about it

609
00:22:40,919 --> 00:22:42,720
this is where a lot of folks will throw

610
00:22:42,720 --> 00:22:45,240
up this diagram and say that devsec Ops

611
00:22:45,240 --> 00:22:47,820
is the ultimate answer to this problem

612
00:22:47,820 --> 00:22:49,860
sounds easy right just bake a little

613
00:22:49,860 --> 00:22:52,020
security into every step and we've

614
00:22:52,020 --> 00:22:54,240
totally democratized security

615
00:22:54,240 --> 00:22:55,980
well I'm actually not going to tell you

616
00:22:55,980 --> 00:22:57,780
that today because I don't think that

617
00:22:57,780 --> 00:23:00,780
devsec Ops alone is the answer

618
00:23:00,780 --> 00:23:02,700
the problem with these Continuous Flow

619
00:23:02,700 --> 00:23:05,520
diagrams is that they become different

620
00:23:05,520 --> 00:23:07,679
things to different people based on your

621
00:23:07,679 --> 00:23:10,260
persona and just because we say that

622
00:23:10,260 --> 00:23:12,360
we're putting Security in at every stage

623
00:23:12,360 --> 00:23:14,520
doesn't mean that we've truly made

624
00:23:14,520 --> 00:23:16,919
security accessible to everyone

625
00:23:16,919 --> 00:23:18,539
the tools are still hard to understand

626
00:23:18,539 --> 00:23:20,700
for a lot of engineering teams and

627
00:23:20,700 --> 00:23:22,799
devsecops workflows become full of

628
00:23:22,799 --> 00:23:24,659
manual approvals if you show this

629
00:23:24,659 --> 00:23:26,159
diagram to a boots on the ground

630
00:23:26,159 --> 00:23:28,620
security person they usually see a gate

631
00:23:28,620 --> 00:23:30,000
at every step

632
00:23:30,000 --> 00:23:32,340
when really we should be applying

633
00:23:32,340 --> 00:23:35,280
guidance for these engineering teams and

634
00:23:35,280 --> 00:23:38,460
continuously measuring

635
00:23:38,460 --> 00:23:40,080
so

636
00:23:40,080 --> 00:23:42,299
in order to really build a culture

637
00:23:42,299 --> 00:23:44,520
around devsecops that's collaborative

638
00:23:44,520 --> 00:23:47,640
and provides more guidance and not Gates

639
00:23:47,640 --> 00:23:49,620
we have to build this Democratic

640
00:23:49,620 --> 00:23:51,000
foundation in the way that we're

641
00:23:51,000 --> 00:23:53,340
designing these processes and that

642
00:23:53,340 --> 00:23:54,840
Foundation is going to create a common

643
00:23:54,840 --> 00:23:56,820
language that we can use

644
00:23:56,820 --> 00:23:59,880
that's really owned by engineering and

645
00:23:59,880 --> 00:24:02,159
security sits then in more of a guidance

646
00:24:02,159 --> 00:24:04,440
and tooling role if we're doing that we

647
00:24:04,440 --> 00:24:06,120
can really scale the impact of our

648
00:24:06,120 --> 00:24:07,740
security team or security Engineers

649
00:24:07,740 --> 00:24:09,720
because we then put the capabilities in

650
00:24:09,720 --> 00:24:11,640
everybody's hands and the security team

651
00:24:11,640 --> 00:24:14,100
is just sitting back and measuring let's

652
00:24:14,100 --> 00:24:16,380
look at an example here I can't think of

653
00:24:16,380 --> 00:24:17,880
a better example of something that's

654
00:24:17,880 --> 00:24:19,320
harder to make accessible and

655
00:24:19,320 --> 00:24:22,020
democratize than identity and access in

656
00:24:22,020 --> 00:24:24,659
most clouds does anybody use the IAM

657
00:24:24,659 --> 00:24:27,480
system in their cloud provider would

658
00:24:27,480 --> 00:24:30,120
anybody say that it was straightforward

659
00:24:30,120 --> 00:24:32,460
these systems are challenging to

660
00:24:32,460 --> 00:24:35,159
understand right I I worked as a kind of

661
00:24:35,159 --> 00:24:36,960
an identity specialist for three years

662
00:24:36,960 --> 00:24:39,120
or so and I have a really hard time

663
00:24:39,120 --> 00:24:41,100
using these things the difference

664
00:24:41,100 --> 00:24:43,500
between you and an identity engineer is

665
00:24:43,500 --> 00:24:45,840
that the identity identity engineer has

666
00:24:45,840 --> 00:24:47,700
accepted that it's going to take them a

667
00:24:47,700 --> 00:24:49,200
long time to carry out their task

668
00:24:49,200 --> 00:24:51,179
engineering teams when they use this

669
00:24:51,179 --> 00:24:52,799
they make mistakes or they give up

670
00:24:52,799 --> 00:24:54,720
completely when they're using them and

671
00:24:54,720 --> 00:24:56,880
when an engineer gives up they usually

672
00:24:56,880 --> 00:25:00,260
blow permissions wide open

673
00:25:00,720 --> 00:25:03,659
certainly not ideal and if credentials

674
00:25:03,659 --> 00:25:05,820
are the root cause of all of these

675
00:25:05,820 --> 00:25:07,980
security incidents on our pie chart the

676
00:25:07,980 --> 00:25:09,840
answer is really to democratize more

677
00:25:09,840 --> 00:25:11,940
identity and access management because

678
00:25:11,940 --> 00:25:13,679
the blast radius of any security

679
00:25:13,679 --> 00:25:16,500
incident that involves credentials is

680
00:25:16,500 --> 00:25:19,260
dictated by how permissive a specific

681
00:25:19,260 --> 00:25:21,059
set of permissions is

682
00:25:21,059 --> 00:25:23,520
we can also protect resources given

683
00:25:23,520 --> 00:25:26,279
things like condition Keys which are new

684
00:25:26,279 --> 00:25:29,880
to the AWS cloud in the last several

685
00:25:29,880 --> 00:25:32,159
years or so and they are ways to

686
00:25:32,159 --> 00:25:34,919
describe when a credential is allowed to

687
00:25:34,919 --> 00:25:37,740
be used on what conditions is that is

688
00:25:37,740 --> 00:25:41,400
that IAM policy statement always true

689
00:25:41,400 --> 00:25:43,980
so there's at least two areas here that

690
00:25:43,980 --> 00:25:45,659
we can primarily work on if we're just

691
00:25:45,659 --> 00:25:47,340
thinking about identity and access we

692
00:25:47,340 --> 00:25:48,779
can work on the developer credentials

693
00:25:48,779 --> 00:25:51,120
themselves or we can work on minimizing

694
00:25:51,120 --> 00:25:53,220
the blast radius of an incident by

695
00:25:53,220 --> 00:25:55,740
making IAM more accessible the first

696
00:25:55,740 --> 00:25:57,360
part of that problem we've kind of

697
00:25:57,360 --> 00:25:59,220
solved from a technical perspective the

698
00:25:59,220 --> 00:26:00,539
technology for this is really better

699
00:26:00,539 --> 00:26:02,460
than ever and that's the Long Live

700
00:26:02,460 --> 00:26:04,020
credentials that live on developer

701
00:26:04,020 --> 00:26:05,700
systems that we're constantly putting in

702
00:26:05,700 --> 00:26:07,260
places that we shouldn't

703
00:26:07,260 --> 00:26:10,740
there's a bit more socialization that we

704
00:26:10,740 --> 00:26:12,659
need to do there and we kind of have an

705
00:26:12,659 --> 00:26:14,520
adoption problem with this because when

706
00:26:14,520 --> 00:26:16,440
Cloud providers First launch support for

707
00:26:16,440 --> 00:26:18,659
single sign-on it was a really really

708
00:26:18,659 --> 00:26:20,340
complicated setup and the user

709
00:26:20,340 --> 00:26:22,260
experience was terrible the user

710
00:26:22,260 --> 00:26:24,179
experience on the command line was even

711
00:26:24,179 --> 00:26:26,039
worse than the user experience in

712
00:26:26,039 --> 00:26:27,299
browser

713
00:26:27,299 --> 00:26:31,140
so this of course isn't true in 2022 but

714
00:26:31,140 --> 00:26:33,480
the technology was so bad prior to now

715
00:26:33,480 --> 00:26:35,700
that it left this lingering perception

716
00:26:35,700 --> 00:26:38,220
that it's impossible to provide good ux

717
00:26:38,220 --> 00:26:40,679
and single sign-on for the cloud

718
00:26:40,679 --> 00:26:42,419
back to our leaked access key problem

719
00:26:42,419 --> 00:26:44,520
though that was the uh single sign-on

720
00:26:44,520 --> 00:26:46,200
might help you solve your problem slide

721
00:26:46,200 --> 00:26:47,940
if you're not familiar with cloud

722
00:26:47,940 --> 00:26:49,559
provider authentication there's two

723
00:26:49,559 --> 00:26:51,600
primary types right there's developer

724
00:26:51,600 --> 00:26:53,840
authentication or human authentication

725
00:26:53,840 --> 00:26:56,820
and there's machine Authentication

726
00:26:56,820 --> 00:26:58,860
and human usable credentials are these

727
00:26:58,860 --> 00:27:01,080
things like access key Pairs and machine

728
00:27:01,080 --> 00:27:02,940
credentials are the short-lived tokens

729
00:27:02,940 --> 00:27:05,340
that are vended by The Machine's

730
00:27:05,340 --> 00:27:06,840
metadata service that are good for about

731
00:27:06,840 --> 00:27:09,480
15 minutes if our goal is to prevent

732
00:27:09,480 --> 00:27:11,760
leak developer Keys first we should

733
00:27:11,760 --> 00:27:14,100
start off by identifying the problem and

734
00:27:14,100 --> 00:27:15,779
I would assert that the problem is part

735
00:27:15,779 --> 00:27:18,960
education and part insecure examples I

736
00:27:18,960 --> 00:27:21,000
run across tons of examples still on the

737
00:27:21,000 --> 00:27:22,980
web in code and if you want great

738
00:27:22,980 --> 00:27:25,080
first-time open source contributions

739
00:27:25,080 --> 00:27:27,840
just go to docs repositories and start

740
00:27:27,840 --> 00:27:30,299
getting rid of insecure examples of how

741
00:27:30,299 --> 00:27:33,480
to how to play with Cloud credentials

742
00:27:33,480 --> 00:27:36,120
this uh snapshot up on screen here is

743
00:27:36,120 --> 00:27:38,399
actually from the boto 3 reference which

744
00:27:38,399 --> 00:27:42,480
is the AWS uh python library for for

745
00:27:42,480 --> 00:27:45,240
interacting and it actually stubs out

746
00:27:45,240 --> 00:27:47,820
the AWS access key and the AWS secret

747
00:27:47,820 --> 00:27:51,659
access key in the uh object there and

748
00:27:51,659 --> 00:27:53,520
those are actually optional but a lot of

749
00:27:53,520 --> 00:27:55,440
people don't read this and think that

750
00:27:55,440 --> 00:27:57,179
those arguments are optional so they

751
00:27:57,179 --> 00:27:58,980
immediately copy paste and they start

752
00:27:58,980 --> 00:28:01,140
hard coding credentials in something and

753
00:28:01,140 --> 00:28:02,820
the next thing you know they've leaked

754
00:28:02,820 --> 00:28:04,020
their credentials

755
00:28:04,020 --> 00:28:06,120
I actually made this mistake when I

756
00:28:06,120 --> 00:28:09,000
first started writing code for AWS

757
00:28:09,000 --> 00:28:11,279
because I didn't know how the default

758
00:28:11,279 --> 00:28:13,200
credential provider chain even worked

759
00:28:13,200 --> 00:28:15,299
and what the other ways were to get

760
00:28:15,299 --> 00:28:18,419
credentials to the AWS SDK then we need

761
00:28:18,419 --> 00:28:20,220
to figure out after we've kind of

762
00:28:20,220 --> 00:28:22,320
addressed that education problem how do

763
00:28:22,320 --> 00:28:24,000
we measure and visualize the scale of

764
00:28:24,000 --> 00:28:24,960
the problem

765
00:28:24,960 --> 00:28:26,760
in this case the easiest way to do that

766
00:28:26,760 --> 00:28:28,679
is with something like truffle hog I

767
00:28:28,679 --> 00:28:30,000
don't know if anybody here is a fan of

768
00:28:30,000 --> 00:28:31,980
truffle hog we don't even really need

769
00:28:31,980 --> 00:28:34,380
something as fancy as truffle hog to

770
00:28:34,380 --> 00:28:36,539
detect these things it's been around for

771
00:28:36,539 --> 00:28:38,159
a bit they just released version three

772
00:28:38,159 --> 00:28:40,200
it handles all the big cloud providers

773
00:28:40,200 --> 00:28:42,360
credentials with regard to scanning

774
00:28:42,360 --> 00:28:45,240
commits but AWS credentials are

775
00:28:45,240 --> 00:28:47,760
regexable they're totally easy to detect

776
00:28:47,760 --> 00:28:50,700
in code so you can get these with all

777
00:28:50,700 --> 00:28:52,679
kinds of different static analysis and

778
00:28:52,679 --> 00:28:54,299
you can create dashboards and things of

779
00:28:54,299 --> 00:28:56,100
how often folks are leaking credentials

780
00:28:56,100 --> 00:28:58,200
and you can drive towards a different

781
00:28:58,200 --> 00:29:00,419
kind of solution if just doing single

782
00:29:00,419 --> 00:29:02,460
sign-on isn't really working for your

783
00:29:02,460 --> 00:29:04,740
business the machine credentials are a

784
00:29:04,740 --> 00:29:06,419
bit more complicated

785
00:29:06,419 --> 00:29:08,760
since uh sessions are short-lived on the

786
00:29:08,760 --> 00:29:10,620
machines the best thing that we can do

787
00:29:10,620 --> 00:29:13,020
here is really try to prevent theft of

788
00:29:13,020 --> 00:29:15,299
credentials in the first place the best

789
00:29:15,299 --> 00:29:17,580
way to do this is actually to change an

790
00:29:17,580 --> 00:29:19,799
insecure default and move to a version

791
00:29:19,799 --> 00:29:21,720
of the credential vending service on the

792
00:29:21,720 --> 00:29:26,399
instances called imdsv2 AWS introduced

793
00:29:26,399 --> 00:29:28,620
this in response to the Capital One data

794
00:29:28,620 --> 00:29:30,840
breach and I bet you know if I ask for

795
00:29:30,840 --> 00:29:32,399
show of hands there are people in this

796
00:29:32,399 --> 00:29:34,080
room who are probably impacted by the

797
00:29:34,080 --> 00:29:37,200
Capital One data breach imds V2 is the

798
00:29:37,200 --> 00:29:38,580
best mitigation that we have for

799
00:29:38,580 --> 00:29:41,580
actually shutting down ssrfs it's really

800
00:29:41,580 --> 00:29:43,500
just a socialization issue that we need

801
00:29:43,500 --> 00:29:45,440
teams to think about turning this on

802
00:29:45,440 --> 00:29:48,539
anytime we're talking about a machine in

803
00:29:48,539 --> 00:29:50,760
the cloud having some kind of privileged

804
00:29:50,760 --> 00:29:51,980
access

805
00:29:51,980 --> 00:29:54,659
imdsv2 introduces this token granting

806
00:29:54,659 --> 00:29:57,000
token not dissimilar to a ticket

807
00:29:57,000 --> 00:29:58,860
granting ticket by the way there are no

808
00:29:58,860 --> 00:30:00,840
new ideas they're just ideas that we

809
00:30:00,840 --> 00:30:03,179
continue to recycle

810
00:30:03,179 --> 00:30:05,880
it uh it Gates those credentials behind

811
00:30:05,880 --> 00:30:08,279
a a service that requires that token

812
00:30:08,279 --> 00:30:10,559
granting token and the token granting

813
00:30:10,559 --> 00:30:13,799
token has to have a TTL of one or less

814
00:30:13,799 --> 00:30:16,620
in order to call that service so

815
00:30:16,620 --> 00:30:19,020
effectively it shuts down ssrfs this

816
00:30:19,020 --> 00:30:20,159
still doesn't really help with remote

817
00:30:20,159 --> 00:30:22,500
code execution or things like log for

818
00:30:22,500 --> 00:30:23,940
shell and spring for Shell where you

819
00:30:23,940 --> 00:30:26,100
have privileged access on the box but

820
00:30:26,100 --> 00:30:27,360
this is a great step in the right

821
00:30:27,360 --> 00:30:28,860
direction for shutting these types of

822
00:30:28,860 --> 00:30:31,860
attacks down the socialized portion of I

823
00:30:31,860 --> 00:30:33,960
is a bit harder

824
00:30:33,960 --> 00:30:37,080
but it's still possible to do like we

825
00:30:37,080 --> 00:30:38,640
can still teach people to reason about

826
00:30:38,640 --> 00:30:41,100
how these things work by simplifying

827
00:30:41,100 --> 00:30:43,679
some of the concepts on this slide as an

828
00:30:43,679 --> 00:30:45,960
example diagram I use frequently to

829
00:30:45,960 --> 00:30:47,640
introduce folks to the identity and

830
00:30:47,640 --> 00:30:50,100
access Mana identity and access decision

831
00:30:50,100 --> 00:30:53,340
making model in the AWS cloud

832
00:30:53,340 --> 00:30:56,820
is this complicated kind of but it's not

833
00:30:56,820 --> 00:30:59,399
as complicated as the giant diagram that

834
00:30:59,399 --> 00:31:01,679
actually represents the access decision

835
00:31:01,679 --> 00:31:04,140
facility in AWS

836
00:31:04,140 --> 00:31:06,120
so just taking somebody and walking them

837
00:31:06,120 --> 00:31:08,519
through the idea that there is a thing

838
00:31:08,519 --> 00:31:10,500
that has to make a decision about any

839
00:31:10,500 --> 00:31:13,740
decision any any access decision for any

840
00:31:13,740 --> 00:31:15,779
API call you make in the cloud is a

841
00:31:15,779 --> 00:31:17,820
great step in the right direction

842
00:31:17,820 --> 00:31:19,679
one of the ways that we can also

843
00:31:19,679 --> 00:31:21,600
socialize this and get more people

844
00:31:21,600 --> 00:31:23,820
involved in identity is to make the

845
00:31:23,820 --> 00:31:25,919
interaction itself easier on-screen is

846
00:31:25,919 --> 00:31:27,659
an example from an open source tool

847
00:31:27,659 --> 00:31:30,539
called pmapper and I think pmapper is a

848
00:31:30,539 --> 00:31:32,460
great uh a great reference for

849
00:31:32,460 --> 00:31:35,159
democratizing I am has anybody heard of

850
00:31:35,159 --> 00:31:36,779
pmapper before

851
00:31:36,779 --> 00:31:39,960
one one hand pmapper is an open source

852
00:31:39,960 --> 00:31:42,779
project that allows anyone to ask it who

853
00:31:42,779 --> 00:31:45,960
can do what using plain English and see

854
00:31:45,960 --> 00:31:47,880
if uh if that person can carry out that

855
00:31:47,880 --> 00:31:50,460
specific task and this is the way we

856
00:31:50,460 --> 00:31:52,260
should be thinking about these systems

857
00:31:52,260 --> 00:31:55,019
some sometimes we call this low code or

858
00:31:55,019 --> 00:31:57,299
no code but really this is just English

859
00:31:57,299 --> 00:31:58,980
human language

860
00:31:58,980 --> 00:32:01,380
acronym free human language easy to

861
00:32:01,380 --> 00:32:03,960
understand usable by many folks not just

862
00:32:03,960 --> 00:32:06,360
security people and we can of course

863
00:32:06,360 --> 00:32:09,059
detect and visualize after we do all

864
00:32:09,059 --> 00:32:11,519
that stuff by creating dashboards and do

865
00:32:11,519 --> 00:32:13,799
doing things like continuous auditing of

866
00:32:13,799 --> 00:32:16,200
the environment for undesired settings

867
00:32:16,200 --> 00:32:19,919
like imdsv2 it's not about measuring is

868
00:32:19,919 --> 00:32:22,200
it done or is it not done it doesn't

869
00:32:22,200 --> 00:32:24,480
become binary right it's about measuring

870
00:32:24,480 --> 00:32:26,760
the adoption curve for something that

871
00:32:26,760 --> 00:32:28,740
you're trying to get development teams

872
00:32:28,740 --> 00:32:31,679
to onboard the most successful teams

873
00:32:31,679 --> 00:32:34,019
tend to set goals and drive towards them

874
00:32:34,019 --> 00:32:37,260
not just say here's a hard Line in the

875
00:32:37,260 --> 00:32:40,140
Sand we're not going to use imdsv1 after

876
00:32:40,140 --> 00:32:41,519
this state

877
00:32:41,519 --> 00:32:44,399
again education socialization are going

878
00:32:44,399 --> 00:32:45,960
to be your friend for ensuring that

879
00:32:45,960 --> 00:32:47,760
things that you don't want in your

880
00:32:47,760 --> 00:32:50,159
environment don't end up in your

881
00:32:50,159 --> 00:32:51,179
environment

882
00:32:51,179 --> 00:32:52,980
so if you think these sound a lot like

883
00:32:52,980 --> 00:32:55,740
user stories too you'd be right and

884
00:32:55,740 --> 00:32:57,240
there's a great talk that was uh

885
00:32:57,240 --> 00:32:58,740
inspirational to me while I was building

886
00:32:58,740 --> 00:33:01,260
this talk by Alyssa Miller

887
00:33:01,260 --> 00:33:03,659
on writing great security user stories

888
00:33:03,659 --> 00:33:05,279
and how that relates to threat models

889
00:33:05,279 --> 00:33:06,840
I'd encourage you all to go and watch

890
00:33:06,840 --> 00:33:08,940
this presentation and then sit down with

891
00:33:08,940 --> 00:33:10,740
an engineering team and have them

892
00:33:10,740 --> 00:33:12,600
participate in creating some security

893
00:33:12,600 --> 00:33:15,659
user stories with you not particularly

894
00:33:15,659 --> 00:33:17,580
Cloud focused but just generally good

895
00:33:17,580 --> 00:33:19,320
advice there's also Community

896
00:33:19,320 --> 00:33:21,840
involvement in socializing sometimes as

897
00:33:21,840 --> 00:33:24,000
well we can all be advocates for changes

898
00:33:24,000 --> 00:33:26,039
in some of these products

899
00:33:26,039 --> 00:33:29,220
AWS is a very very large business and

900
00:33:29,220 --> 00:33:31,980
the ecosystems of companies around AWS

901
00:33:31,980 --> 00:33:33,779
sometimes don't move as fast with the

902
00:33:33,779 --> 00:33:35,580
security controls as we would like them

903
00:33:35,580 --> 00:33:38,419
to so this is a great example uh the

904
00:33:38,419 --> 00:33:41,760
imdsv2 Wall of Shame is a git repository

905
00:33:41,760 --> 00:33:43,799
that's just a list of vendors that don't

906
00:33:43,799 --> 00:33:45,480
support the secure version of that

907
00:33:45,480 --> 00:33:46,440
service

908
00:33:46,440 --> 00:33:48,299
it's a great way to get them motivated

909
00:33:48,299 --> 00:33:50,820
to go and support the more secure

910
00:33:50,820 --> 00:33:53,399
version of the metadata service ideally

911
00:33:53,399 --> 00:33:55,340
things like this wouldn't have to happen

912
00:33:55,340 --> 00:33:57,659
imdsv2 has been out for three years

913
00:33:57,659 --> 00:34:00,899
which is why in this case I'm only a

914
00:34:00,899 --> 00:34:01,980
little okay with the fact that we're

915
00:34:01,980 --> 00:34:04,200
shaming them but it does seem necessary

916
00:34:04,200 --> 00:34:06,299
because companies are popping off this

917
00:34:06,299 --> 00:34:08,339
list since Scott Piper started the skit

918
00:34:08,339 --> 00:34:09,839
Repository

919
00:34:09,839 --> 00:34:12,000
so let's look at a final example here of

920
00:34:12,000 --> 00:34:14,579
democratizing sometimes our detections

921
00:34:14,579 --> 00:34:17,339
break we're all good at detection but

922
00:34:17,339 --> 00:34:18,899
we're not necessarily always good at

923
00:34:18,899 --> 00:34:21,000
testing detections and we don't know

924
00:34:21,000 --> 00:34:22,918
that they're broken until we actually

925
00:34:22,918 --> 00:34:25,918
miss a really important event

926
00:34:25,918 --> 00:34:28,320
so why do detections break in the cloud

927
00:34:28,320 --> 00:34:30,599
if you've ever parsed cloudtrail data

928
00:34:30,599 --> 00:34:33,480
many of the same reasons that they break

929
00:34:33,480 --> 00:34:35,879
on-prem except that we also have

930
00:34:35,879 --> 00:34:38,040
components outside of our control to

931
00:34:38,040 --> 00:34:40,199
deal with I'm sure if you worked on a

932
00:34:40,199 --> 00:34:41,940
Sim in-house you know the pain of

933
00:34:41,940 --> 00:34:43,918
something like a dictionary becoming a

934
00:34:43,918 --> 00:34:46,918
list or a dictionary becoming a list of

935
00:34:46,918 --> 00:34:48,899
dictionaries and all of a sudden that

936
00:34:48,899 --> 00:34:50,280
breaks through detection or it breaks

937
00:34:50,280 --> 00:34:52,139
your indexing and then all of a sudden

938
00:34:52,139 --> 00:34:54,119
you can't build alerts that actually

939
00:34:54,119 --> 00:34:57,060
work against that log source

940
00:34:57,060 --> 00:34:58,800
so the way that we're measuring and

941
00:34:58,800 --> 00:35:00,960
visualizing in this case is by using a

942
00:35:00,960 --> 00:35:03,119
tool that we recently open source at

943
00:35:03,119 --> 00:35:05,700
datadog during q1 it's called Stratus

944
00:35:05,700 --> 00:35:07,800
red team Stratus red team is a cloud

945
00:35:07,800 --> 00:35:10,800
native adversary emulation tool for AWS

946
00:35:10,800 --> 00:35:12,480
and kubernetes

947
00:35:12,480 --> 00:35:14,520
and by the way

948
00:35:14,520 --> 00:35:16,740
we're democratizing this by making a tax

949
00:35:16,740 --> 00:35:19,380
understandable to everyone by using the

950
00:35:19,380 --> 00:35:21,480
miter attack framework to describe the

951
00:35:21,480 --> 00:35:23,700
techniques tactics and procedures or

952
00:35:23,700 --> 00:35:27,119
ttps and also giving the developers the

953
00:35:27,119 --> 00:35:29,040
One-Shot ability to detonate these

954
00:35:29,040 --> 00:35:31,079
things inside of an of a cloud

955
00:35:31,079 --> 00:35:34,320
environment and see if they're detected

956
00:35:34,320 --> 00:35:36,780
so here's a quick demo of how that works

957
00:35:36,780 --> 00:35:39,359
end to end in a detection testing

958
00:35:39,359 --> 00:35:41,400
scenario when the video is actually

959
00:35:41,400 --> 00:35:43,020
working I don't see it in the speaker

960
00:35:43,020 --> 00:35:44,400
notes so I'm just going to have to watch

961
00:35:44,400 --> 00:35:46,320
on screen

962
00:35:46,320 --> 00:35:48,300
so this is stratus spinning up and

963
00:35:48,300 --> 00:35:51,839
describing all of its capabilities

964
00:35:51,839 --> 00:35:54,300
has a lot of them we're also spinning up

965
00:35:54,300 --> 00:35:56,760
a kubernetes cluster and then we got

966
00:35:56,760 --> 00:35:58,980
some detections there on screen the

967
00:35:58,980 --> 00:36:00,420
things that we want to see if we can

968
00:36:00,420 --> 00:36:03,599
continuously detect that's step one make

969
00:36:03,599 --> 00:36:06,300
some detections

970
00:36:06,300 --> 00:36:08,280
in this case we're using a standard

971
00:36:08,280 --> 00:36:11,940
datadog Quarry syntax in our example

972
00:36:11,940 --> 00:36:13,859
looking at kubernetes audit logs we're

973
00:36:13,859 --> 00:36:16,320
also looking at persistence by creating

974
00:36:16,320 --> 00:36:19,140
additional IAM users in the cloud

975
00:36:19,140 --> 00:36:20,820
then we're going to install Stratus red

976
00:36:20,820 --> 00:36:23,880
team as an API because fun fact when we

977
00:36:23,880 --> 00:36:25,619
built Stratus red team we built it so

978
00:36:25,619 --> 00:36:27,720
you can bind to it and go Lang to create

979
00:36:27,720 --> 00:36:30,060
other tools so that's what we've done

980
00:36:30,060 --> 00:36:31,920
here to create kind of an end-to-end

981
00:36:31,920 --> 00:36:35,780
test pipeline example

982
00:36:37,200 --> 00:36:38,760
so we got a little script that's going

983
00:36:38,760 --> 00:36:41,280
to show on screen that just describes

984
00:36:41,280 --> 00:36:44,160
which alerts and which ttps we're going

985
00:36:44,160 --> 00:36:46,460
to test

986
00:36:48,780 --> 00:36:51,420
someday we'll open source this too

987
00:36:51,420 --> 00:36:53,099
then we're going to detonate the ttps

988
00:36:53,099 --> 00:36:55,020
and we're going to monitor how much time

989
00:36:55,020 --> 00:36:58,920
it took the SIM to detect those attacks

990
00:36:58,920 --> 00:37:01,260
so you can see it detonating

991
00:37:01,260 --> 00:37:02,640
and you can actually see that the

992
00:37:02,640 --> 00:37:04,380
attacks are detected quite quickly I

993
00:37:04,380 --> 00:37:05,880
think one of those is like six seconds

994
00:37:05,880 --> 00:37:08,460
to detection nine seconds to detection

995
00:37:08,460 --> 00:37:10,980
and at the end of that the little

996
00:37:10,980 --> 00:37:12,780
wrapper that we wrote around Stratus is

997
00:37:12,780 --> 00:37:14,940
actually going to emit a metric back to

998
00:37:14,940 --> 00:37:17,520
the monitoring platform to say how long

999
00:37:17,520 --> 00:37:21,180
it took end to end for each platform for

1000
00:37:21,180 --> 00:37:23,880
that specific TTP to be detected then

1001
00:37:23,880 --> 00:37:25,440
we're going to go back to the platform

1002
00:37:25,440 --> 00:37:27,720
we're going to confirm the detections so

1003
00:37:27,720 --> 00:37:29,640
it should generate alerts it looks like

1004
00:37:29,640 --> 00:37:32,060
it did

1005
00:37:33,420 --> 00:37:35,400
of course those alerts have all of the

1006
00:37:35,400 --> 00:37:36,660
information that we would need to go and

1007
00:37:36,660 --> 00:37:39,420
remediate that and then we also have a

1008
00:37:39,420 --> 00:37:41,160
sample dashboard that we've created that

1009
00:37:41,160 --> 00:37:43,020
shows the number of ttps that we've

1010
00:37:43,020 --> 00:37:45,900
detected and also the change in time to

1011
00:37:45,900 --> 00:37:48,180
detect over multiple deployments of the

1012
00:37:48,180 --> 00:37:51,119
same piece of software

1013
00:37:51,119 --> 00:37:54,599
so not only can we Empower developers to

1014
00:37:54,599 --> 00:37:56,760
use this tool to just run these ttps

1015
00:37:56,760 --> 00:37:58,500
inside of the environment we could

1016
00:37:58,500 --> 00:38:00,660
create a service level objective around

1017
00:38:00,660 --> 00:38:02,579
how quickly certain types of behaviors

1018
00:38:02,579 --> 00:38:04,500
need to be detected

1019
00:38:04,500 --> 00:38:06,720
in the cloud security class we we talk a

1020
00:38:06,720 --> 00:38:09,000
lot about how fast do you need to detect

1021
00:38:09,000 --> 00:38:10,560
something in order to be effective at

1022
00:38:10,560 --> 00:38:13,920
preventing a breach completely and when

1023
00:38:13,920 --> 00:38:16,380
does an SLA prevent you from doing that

1024
00:38:16,380 --> 00:38:18,599
fast enough that the attacker is going

1025
00:38:18,599 --> 00:38:20,160
to get away with some data and you're

1026
00:38:20,160 --> 00:38:21,660
going to shut it down let's say 15

1027
00:38:21,660 --> 00:38:23,579
minutes after they've actually come and

1028
00:38:23,579 --> 00:38:25,260
gone so if you're more of an

1029
00:38:25,260 --> 00:38:27,660
architecture diagram individual this is

1030
00:38:27,660 --> 00:38:29,520
what the workflow for that looks like

1031
00:38:29,520 --> 00:38:32,460
you have a a git commit of some kind

1032
00:38:32,460 --> 00:38:34,920
inside of your CI CD thing which in this

1033
00:38:34,920 --> 00:38:37,320
demo was AWS code build we're running

1034
00:38:37,320 --> 00:38:39,839
Stratus red team Stratus red team is

1035
00:38:39,839 --> 00:38:41,460
executing inside of a clean room

1036
00:38:41,460 --> 00:38:44,040
environment it's very very hard to run

1037
00:38:44,040 --> 00:38:46,140
tools like this in a production

1038
00:38:46,140 --> 00:38:48,119
environment because the attribution of

1039
00:38:48,119 --> 00:38:50,160
events back to the original actor is

1040
00:38:50,160 --> 00:38:52,320
really really challenging and you can

1041
00:38:52,320 --> 00:38:54,060
ask me about that stuff you can also ask

1042
00:38:54,060 --> 00:38:55,920
Adam machinchi about that stuff we both

1043
00:38:55,920 --> 00:38:58,079
have spent a ton of time thinking about

1044
00:38:58,079 --> 00:38:59,760
problems like this

1045
00:38:59,760 --> 00:39:02,640
when that runs of course we're going to

1046
00:39:02,640 --> 00:39:04,440
get logs back from the cloud provider's

1047
00:39:04,440 --> 00:39:06,720
control plane via cloudtrail we're going

1048
00:39:06,720 --> 00:39:08,700
to run that through our Sim in this case

1049
00:39:08,700 --> 00:39:10,800
we're using datadog for the example then

1050
00:39:10,800 --> 00:39:12,780
we're going to use our little script to

1051
00:39:12,780 --> 00:39:15,119
pull the Sim and see when the event was

1052
00:39:15,119 --> 00:39:18,180
detected and then if we fall below our

1053
00:39:18,180 --> 00:39:19,740
service level objective for detection

1054
00:39:19,740 --> 00:39:21,599
we're going to emit a message to a

1055
00:39:21,599 --> 00:39:23,940
messaging platform of our choice in this

1056
00:39:23,940 --> 00:39:26,099
case on the diagram it says Amazon chime

1057
00:39:26,099 --> 00:39:27,720
but it could be anything text message

1058
00:39:27,720 --> 00:39:30,420
pagerduty slack message whatever

1059
00:39:30,420 --> 00:39:33,420
so we all know in this room that ttps

1060
00:39:33,420 --> 00:39:35,579
are great right and this is just kind of

1061
00:39:35,579 --> 00:39:38,940
building on that idea that uh describing

1062
00:39:38,940 --> 00:39:40,859
attacks as techniques tactics and

1063
00:39:40,859 --> 00:39:44,099
procedures is way better than describing

1064
00:39:44,099 --> 00:39:47,040
things as cves and the move to miter

1065
00:39:47,040 --> 00:39:48,960
attack has really really helped us there

1066
00:39:48,960 --> 00:39:51,780
because we have we're throwing around

1067
00:39:51,780 --> 00:39:54,420
less acronyms we're making things really

1068
00:39:54,420 --> 00:39:56,760
really understandable and communicable

1069
00:39:56,760 --> 00:39:59,160
for the rest of our organization

1070
00:39:59,160 --> 00:40:01,200
so if you like that tool that you saw on

1071
00:40:01,200 --> 00:40:02,940
screen and you want to pull it down it

1072
00:40:02,940 --> 00:40:06,540
does ship with 23 ttps for the AWS cloud

1073
00:40:06,540 --> 00:40:08,760
and six for kubernetes all of those

1074
00:40:08,760 --> 00:40:11,579
attacks can be simulated by anyone with

1075
00:40:11,579 --> 00:40:13,619
access to an account or an expert red

1076
00:40:13,619 --> 00:40:15,960
teamer and I consider that a win I'd

1077
00:40:15,960 --> 00:40:18,060
even call it democratizing

1078
00:40:18,060 --> 00:40:19,980
so if you think that demo I just showed

1079
00:40:19,980 --> 00:40:22,680
you is actually cool we have not built

1080
00:40:22,680 --> 00:40:24,599
out the complete feature for Stratus red

1081
00:40:24,599 --> 00:40:27,000
team that does the end to end part and I

1082
00:40:27,000 --> 00:40:29,099
have a GitHub issue here if you think

1083
00:40:29,099 --> 00:40:31,079
it's neat if you could just go and give

1084
00:40:31,079 --> 00:40:34,800
it a thumbs up a plus one if I I didn't

1085
00:40:34,800 --> 00:40:36,480
show a feature that you think the tool

1086
00:40:36,480 --> 00:40:38,520
should have go ahead and throw a comment

1087
00:40:38,520 --> 00:40:40,980
on there and I'd like to do a little bit

1088
00:40:40,980 --> 00:40:42,660
of product management before we actually

1089
00:40:42,660 --> 00:40:45,660
decide to to mature that prototype the

1090
00:40:45,660 --> 00:40:48,060
stratus tool is available just not the

1091
00:40:48,060 --> 00:40:51,180
the uh end-to-end detection that emits

1092
00:40:51,180 --> 00:40:52,440
those metrics

1093
00:40:52,440 --> 00:40:54,660
so with that I'll ask you the question

1094
00:40:54,660 --> 00:40:56,520
you know maybe we can chat after this

1095
00:40:56,520 --> 00:40:58,740
what pieces of security are you

1096
00:40:58,740 --> 00:41:00,900
democratizing now that you can identify

1097
00:41:00,900 --> 00:41:03,720
what that means inside of your business

1098
00:41:03,720 --> 00:41:06,000
would love to talk to you at lunch again

1099
00:41:06,000 --> 00:41:08,760
all of the links from this talk are

1100
00:41:08,760 --> 00:41:09,839
available

1101
00:41:09,839 --> 00:41:12,240
in this GitHub gist you can scan the

1102
00:41:12,240 --> 00:41:13,920
barcode if you're not a barcode scanner

1103
00:41:13,920 --> 00:41:16,560
the bitly URL is down there at the lower

1104
00:41:16,560 --> 00:41:20,400
left once again I'm Andrew Krug I'm a

1105
00:41:20,400 --> 00:41:22,380
lead security evangelist at datadog

1106
00:41:22,380 --> 00:41:24,060
that's how you can get a hold of me

1107
00:41:24,060 --> 00:41:25,859
please do get a hold of me if you have

1108
00:41:25,859 --> 00:41:28,440
any questions thanks

1109
00:41:28,440 --> 00:41:32,819
[Applause]

1110
00:41:32,819 --> 00:41:33,740
foreign

1111
00:41:33,740 --> 00:41:37,200
thanks for coming and telling us about

1112
00:41:37,200 --> 00:41:39,599
how to apply democracy in the cloud

1113
00:41:39,599 --> 00:41:42,780
anybody got any questions I don't think

1114
00:41:42,780 --> 00:41:44,940
I had any from the Discord

1115
00:41:44,940 --> 00:41:47,339
and if somebody posts one it'll pop up

1116
00:41:47,339 --> 00:41:49,380
and I'll see it so we'll take the one in

1117
00:41:49,380 --> 00:41:52,160
in the house here

1118
00:41:56,280 --> 00:41:58,800
oh yeah sorry the question was where is

1119
00:41:58,800 --> 00:42:01,380
the data from the the pie chart that I

1120
00:42:01,380 --> 00:42:04,260
showed it's actually from the security

1121
00:42:04,260 --> 00:42:05,720
researcher

1122
00:42:05,720 --> 00:42:07,920
raminac I think is the way that you

1123
00:42:07,920 --> 00:42:09,180
would pronounce the name and it is

1124
00:42:09,180 --> 00:42:11,040
linked in the slides and it's linked in

1125
00:42:11,040 --> 00:42:12,780
the GitHub gist

1126
00:42:12,780 --> 00:42:13,500
um

1127
00:42:13,500 --> 00:42:15,780
it's it's basically just a it's a public

1128
00:42:15,780 --> 00:42:18,300
repository that he does where he tracks

1129
00:42:18,300 --> 00:42:21,060
all of the uh breaches that are in the

1130
00:42:21,060 --> 00:42:22,560
news through the year it's not based on

1131
00:42:22,560 --> 00:42:25,440
some um report like vdbir that's right

1132
00:42:25,440 --> 00:42:30,260
uh right here in the slide so up there

1133
00:42:32,339 --> 00:42:34,560
and I he doesn't categorize those I

1134
00:42:34,560 --> 00:42:35,760
actually think that that would be a

1135
00:42:35,760 --> 00:42:37,140
significant Improvement to this

1136
00:42:37,140 --> 00:42:38,880
repository if somebody wanted to make a

1137
00:42:38,880 --> 00:42:40,800
community contribution just to

1138
00:42:40,800 --> 00:42:42,960
categorize them uh at a at a broad level

1139
00:42:42,960 --> 00:42:46,079
based on what initial access was what

1140
00:42:46,079 --> 00:42:48,660
blast radius was what the techniques uh

1141
00:42:48,660 --> 00:42:50,220
were that were used inside the

1142
00:42:50,220 --> 00:42:51,240
environment because then we could

1143
00:42:51,240 --> 00:42:54,500
generate much better metrics

1144
00:42:55,619 --> 00:42:59,420
any other questions over here

1145
00:42:59,480 --> 00:43:03,260
[Music]

1146
00:43:05,819 --> 00:43:08,460
the question was for the TTP from the

1147
00:43:08,460 --> 00:43:10,380
automated tooling what's the format for

1148
00:43:10,380 --> 00:43:11,460
those

1149
00:43:11,460 --> 00:43:14,099
um if you go there so one Shameless plug

1150
00:43:14,099 --> 00:43:16,740
on my Twitter page there's a deep dive

1151
00:43:16,740 --> 00:43:19,020
talk on Stratus red team from last week

1152
00:43:19,020 --> 00:43:21,140
that I did at AWS Summit North America

1153
00:43:21,140 --> 00:43:24,060
but for the actual tool itself if you

1154
00:43:24,060 --> 00:43:26,040
wanted to contribute a TTP the format is

1155
00:43:26,040 --> 00:43:27,780
just terraform

1156
00:43:27,780 --> 00:43:30,000
so Stratus red team is a cloud native

1157
00:43:30,000 --> 00:43:32,640
rapper around terraform executing those

1158
00:43:32,640 --> 00:43:34,859
ttps and if it's not something that we

1159
00:43:34,859 --> 00:43:36,420
can do natively in the cloud control

1160
00:43:36,420 --> 00:43:38,760
plane we actually spin up an ec2

1161
00:43:38,760 --> 00:43:40,980
instance or a container and then we use

1162
00:43:40,980 --> 00:43:42,960
the systems manager agent to execute

1163
00:43:42,960 --> 00:43:45,720
commands inside of that ec2 agent or

1164
00:43:45,720 --> 00:43:47,640
container so you could even do something

1165
00:43:47,640 --> 00:43:51,119
fancy like chain Atomic red team to

1166
00:43:51,119 --> 00:43:54,020
Stratus red team

1167
00:43:55,079 --> 00:43:56,819
that'd be really cool if you do that

1168
00:43:56,819 --> 00:43:59,819
please let me know so we can recognize

1169
00:43:59,819 --> 00:44:01,260
you in the project we don't send

1170
00:44:01,260 --> 00:44:05,660
t-shirts yet but I have stickers

1171
00:44:08,579 --> 00:44:12,500
all right any other questions required

1172
00:44:12,900 --> 00:44:15,780
all right thanks everybody and I could

1173
00:44:15,780 --> 00:44:16,920
tell you all the other things that

1174
00:44:16,920 --> 00:44:18,180
you've been doing but it's lunch time

1175
00:44:18,180 --> 00:44:20,640
and I know you won't listen so go eat

1176
00:44:20,640 --> 00:44:23,220
lunch we'll see you back in an hour

1177
00:44:23,220 --> 00:44:24,720
and then I'll tell you what the other

1178
00:44:24,720 --> 00:44:26,460
stuff you could be doing

1179
00:44:26,460 --> 00:44:29,100
thanks everybody great to see you

1180
00:44:29,100 --> 00:44:34,009
[Applause]

