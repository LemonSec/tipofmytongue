1
00:00:00,000 --> 00:00:03,720
I'm here's Ren talking about

2
00:00:01,680 --> 00:00:05,490
demystifying machine learning so please

3
00:00:03,720 --> 00:00:13,230
give her a warm warm applause thank you

4
00:00:05,490 --> 00:00:15,030
hi everybody alright so yeah I wanted to

5
00:00:13,230 --> 00:00:18,050
talk about machine learning since it's

6
00:00:15,030 --> 00:00:20,490
such a hot topic these days everywhere

7
00:00:18,050 --> 00:00:23,279
this is a small thing about me I've done

8
00:00:20,490 --> 00:00:25,019
a lot of undergrad research I only

9
00:00:23,279 --> 00:00:26,730
grabbed a couple years ago but I did a

10
00:00:25,019 --> 00:00:27,959
lot of Gundagai research in machine

11
00:00:26,730 --> 00:00:29,789
learning especially an image

12
00:00:27,960 --> 00:00:31,669
classification

13
00:00:29,789 --> 00:00:34,559
so my background kinda comes from that

14
00:00:31,669 --> 00:00:35,820
and I use machine learning techniques

15
00:00:34,559 --> 00:00:37,769
definitely my work right now but I'm

16
00:00:35,820 --> 00:00:39,059
infrastructure engineer and you can

17
00:00:37,770 --> 00:00:41,730
pretty much apply machine learning to

18
00:00:39,059 --> 00:00:45,030
anything that you're doing it's really a

19
00:00:41,730 --> 00:00:47,550
tool so anyway we're gonna start so I

20
00:00:45,030 --> 00:00:50,190
was inspired to make this talk because I

21
00:00:47,550 --> 00:00:54,000
was in this lift line in the Bay Area

22
00:00:50,190 --> 00:00:56,640
one day and there was a machine learning

23
00:00:54,000 --> 00:00:59,399
engineer from I guess they were working

24
00:00:56,640 --> 00:01:00,750
on like Android platform and they kind

25
00:00:59,399 --> 00:01:02,699
of like went off on this really long

26
00:01:00,750 --> 00:01:04,890
rant about oh machine learning he's

27
00:01:02,699 --> 00:01:07,470
really stupid that's kind of like

28
00:01:04,890 --> 00:01:09,720
literally what this person said and then

29
00:01:07,470 --> 00:01:11,700
kind of went off on a rant do what we

30
00:01:09,720 --> 00:01:15,539
want it to do and yet you know and then

31
00:01:11,700 --> 00:01:17,880
I guess I was just sitting there and I

32
00:01:15,540 --> 00:01:19,770
was like for people that don't quite

33
00:01:17,880 --> 00:01:23,009
know a lot about machine learning yet I

34
00:01:19,770 --> 00:01:25,140
feel like that could be not such a great

35
00:01:23,009 --> 00:01:26,909
summary for what machine learning can

36
00:01:25,140 --> 00:01:30,119
and can't do and what it should be used

37
00:01:26,909 --> 00:01:32,130
for so I don't think anybody here is

38
00:01:30,119 --> 00:01:35,460
gonna start screaming around machine

39
00:01:32,130 --> 00:01:37,710
learning stupid but I figured it can't

40
00:01:35,460 --> 00:01:39,419
hurt to know a little bit more and get a

41
00:01:37,710 --> 00:01:42,059
little bit educated about what machine

42
00:01:39,420 --> 00:01:44,460
learning is I'm not talking about AI so

43
00:01:42,060 --> 00:01:45,990
like machine learning and AI they're

44
00:01:44,460 --> 00:01:48,149
they're kind of like sonatas so they

45
00:01:45,990 --> 00:01:50,640
used in like you know colloquial terms

46
00:01:48,149 --> 00:01:53,180
but I'm only talking about machine

47
00:01:50,640 --> 00:01:55,500
learning and some of the techniques and

48
00:01:53,180 --> 00:02:00,799
hopefully you guys can learn one one

49
00:01:55,500 --> 00:02:03,030
thing or two from it and yeah cool so

50
00:02:00,799 --> 00:02:05,219
yeah like I said this talk is for

51
00:02:03,030 --> 00:02:07,530
anybody else I also think that machine

52
00:02:05,219 --> 00:02:10,500
learning is a little frustrating doesn't

53
00:02:07,530 --> 00:02:13,560
quite do what we wanted to do yet and I

54
00:02:10,500 --> 00:02:15,900
wanted to mystify that I yeah so

55
00:02:13,560 --> 00:02:18,030
to get right to it so when I heard that

56
00:02:15,900 --> 00:02:19,260
statement in the car from the Android

57
00:02:18,030 --> 00:02:22,080
engineer saying machine learning is

58
00:02:19,260 --> 00:02:24,450
stupid right and I get that he was kind

59
00:02:22,080 --> 00:02:27,180
of like really I think frustrated about

60
00:02:24,450 --> 00:02:29,790
it but the way I deconstructed the

61
00:02:27,180 --> 00:02:31,739
statement is basically why don't

62
00:02:29,790 --> 00:02:34,140
machines or like machine learning have

63
00:02:31,739 --> 00:02:36,510
same kind of understanding you know

64
00:02:34,140 --> 00:02:38,190
recognition intuition kind of automated

65
00:02:36,510 --> 00:02:41,340
learning like all these things that kind

66
00:02:38,190 --> 00:02:43,349
of I guess we expect from machine

67
00:02:41,340 --> 00:02:46,319
learning because of all these you know

68
00:02:43,349 --> 00:02:47,940
sci-fi examples like Jarvis and Hall and

69
00:02:46,319 --> 00:02:50,790
you know all that stuff to kind of like

70
00:02:47,940 --> 00:02:54,540
you know do everything on their own and

71
00:02:50,790 --> 00:02:56,190
it's kind of magical right and so that's

72
00:02:54,540 --> 00:02:58,500
kind of how I understood it and I was

73
00:02:56,190 --> 00:03:00,930
just also like thinking I think the

74
00:02:58,500 --> 00:03:03,750
frustration is that like why domains

75
00:03:00,930 --> 00:03:06,660
also have like learning and execution

76
00:03:03,750 --> 00:03:10,500
skills like humans have right now if not

77
00:03:06,660 --> 00:03:12,329
any better and I guess kind of like

78
00:03:10,500 --> 00:03:13,739
expecting machine learning to be some

79
00:03:12,330 --> 00:03:18,750
sort of like an accelerated learning

80
00:03:13,739 --> 00:03:20,130
version than what humans can do so kind

81
00:03:18,750 --> 00:03:22,140
let's kind of demystify that I kind of

82
00:03:20,130 --> 00:03:26,010
see where we're at in terms of reality

83
00:03:22,140 --> 00:03:28,078
with machine learning so yeah who here

84
00:03:26,010 --> 00:03:30,750
actually in those machine learning

85
00:03:28,079 --> 00:03:34,410
techniques work with it before a little

86
00:03:30,750 --> 00:03:37,260
bit a lot experts here okay whatever it

87
00:03:34,410 --> 00:03:41,220
doesn't matter so this talk I'm kind of

88
00:03:37,260 --> 00:03:43,769
assuming I wrote this this talk for more

89
00:03:41,220 --> 00:03:45,720
of a generalized audience so I didn't

90
00:03:43,769 --> 00:03:47,069
really want to get heavy into jargons I

91
00:03:45,720 --> 00:03:48,780
didn't want to like get into like

92
00:03:47,069 --> 00:03:50,488
statistical modeling it's it's it's a KO

93
00:03:48,780 --> 00:03:51,840
algorithms and that things that people

94
00:03:50,489 --> 00:03:54,780
are just gonna sleep on all right

95
00:03:51,840 --> 00:03:58,319
um so but I do want to go over like

96
00:03:54,780 --> 00:04:01,019
really really simple examples of how you

97
00:03:58,319 --> 00:04:04,170
can build a simple neural network and

98
00:04:01,019 --> 00:04:05,670
use that example to kind of build on top

99
00:04:04,170 --> 00:04:07,078
of that and kind of go into comparisons

100
00:04:05,670 --> 00:04:09,268
of how machine learning will tackle some

101
00:04:07,079 --> 00:04:11,430
problems versus how a human would anyway

102
00:04:09,269 --> 00:04:15,239
yeah so I'm not gonna get into like

103
00:04:11,430 --> 00:04:16,798
super jargony stuff yeah so machine

104
00:04:15,239 --> 00:04:19,289
learning is heavily rooted in

105
00:04:16,798 --> 00:04:23,099
statistical analysis mathematical models

106
00:04:19,289 --> 00:04:24,539
concepts but they're also deeply rooted

107
00:04:23,099 --> 00:04:26,909
especially in your own network so deeply

108
00:04:24,539 --> 00:04:27,389
rooted and biological evidence for

109
00:04:26,909 --> 00:04:30,659
learning

110
00:04:27,389 --> 00:04:34,889
how the brain the biological I guess the

111
00:04:30,659 --> 00:04:38,509
the structure of how the brain works and

112
00:04:34,889 --> 00:04:40,590
in case you feel like this about math

113
00:04:38,509 --> 00:04:44,840
I'm gonna just kind of leave that part

114
00:04:40,590 --> 00:04:47,698
out yeah and then so machine learning

115
00:04:44,840 --> 00:04:50,008
it's it has a name like learning in it

116
00:04:47,699 --> 00:04:52,919
but it really has to do with how do we

117
00:04:50,009 --> 00:04:57,870
build models that can't answer questions

118
00:04:52,919 --> 00:04:59,729
so let's say yeah not actually yeah

119
00:04:57,870 --> 00:05:01,259
so let's say you have certain question

120
00:04:59,729 --> 00:05:04,289
you want to answer that could be like

121
00:05:01,259 --> 00:05:06,210
classify an image or figure out what is

122
00:05:04,289 --> 00:05:07,469
the best next move to make in a game

123
00:05:06,210 --> 00:05:09,719
right those are kind of questions that

124
00:05:07,469 --> 00:05:11,219
you want to ask and you build the model

125
00:05:09,719 --> 00:05:14,789
supposed to give you the answer to that

126
00:05:11,219 --> 00:05:18,180
in a preferably really fast faster than

127
00:05:14,789 --> 00:05:19,979
how humans can and generally when you're

128
00:05:18,180 --> 00:05:22,680
building models you kind of go through

129
00:05:19,979 --> 00:05:24,419
this this is a pipeline that you would

130
00:05:22,680 --> 00:05:27,449
go through normally in a very high

131
00:05:24,419 --> 00:05:30,180
high-level format so you first start

132
00:05:27,449 --> 00:05:31,919
with some training data of what the what

133
00:05:30,180 --> 00:05:33,539
the question is and what the answers

134
00:05:31,919 --> 00:05:36,330
might look like so for example if I had

135
00:05:33,539 --> 00:05:39,300
a bunch of images of cats that would be

136
00:05:36,330 --> 00:05:41,250
you know the image itself is my question

137
00:05:39,300 --> 00:05:43,649
and then the answer might be it's a cat

138
00:05:41,250 --> 00:05:45,330
image right so you have a bunch of kind

139
00:05:43,649 --> 00:05:47,189
of like what we call the labeled data

140
00:05:45,330 --> 00:05:50,008
like that and that's usually used as

141
00:05:47,189 --> 00:05:51,509
training data so that you can start

142
00:05:50,009 --> 00:05:54,169
building the model that you're looking

143
00:05:51,509 --> 00:05:59,069
for right and the models are usually

144
00:05:54,169 --> 00:06:01,169
statistical algorithms um and you test

145
00:05:59,069 --> 00:06:03,089
the model by basically seeing given this

146
00:06:01,169 --> 00:06:04,620
training data does it actually give me

147
00:06:03,089 --> 00:06:05,939
the answer does the algorithm give me

148
00:06:04,620 --> 00:06:07,259
the answer that I'm looking for so if

149
00:06:05,939 --> 00:06:09,899
you give it a bunch of cat images does

150
00:06:07,259 --> 00:06:12,449
it say does it label each image as cat

151
00:06:09,899 --> 00:06:13,949
right for example and if it doesn't then

152
00:06:12,449 --> 00:06:14,849
you know you correct it and you tuned

153
00:06:13,949 --> 00:06:17,159
and you kind of go through this

154
00:06:14,849 --> 00:06:19,020
iterative process a feedback loop of

155
00:06:17,159 --> 00:06:22,199
sorts and you kind of do that over and

156
00:06:19,020 --> 00:06:24,508
over and over and over again until you

157
00:06:22,199 --> 00:06:26,759
know your accuracy general accuracy kind

158
00:06:24,509 --> 00:06:30,149
of goes up right and so that's like the

159
00:06:26,759 --> 00:06:32,069
very high level of how any like research

160
00:06:30,149 --> 00:06:36,569
or anybody using machine learning would

161
00:06:32,069 --> 00:06:39,300
go about training a model and I kind of

162
00:06:36,569 --> 00:06:41,220
want to go over what are like the two

163
00:06:39,300 --> 00:06:43,950
big types

164
00:06:41,220 --> 00:06:45,480
models that out there out there these

165
00:06:43,950 --> 00:06:49,200
are not the only ones but these are the

166
00:06:45,480 --> 00:06:51,360
main two types so there's a machine

167
00:06:49,200 --> 00:06:53,610
learning models can be split into either

168
00:06:51,360 --> 00:06:55,790
it's supervised learning or unsupervised

169
00:06:53,610 --> 00:06:58,830
learning so what that would mean is

170
00:06:55,790 --> 00:07:01,260
supervised learning you basically give

171
00:06:58,830 --> 00:07:03,659
it some data knowing what the answer

172
00:07:01,260 --> 00:07:05,789
idea is so the cat example that I kept

173
00:07:03,660 --> 00:07:08,250
talking about is a classic example of

174
00:07:05,790 --> 00:07:10,050
that where you know exactly the image

175
00:07:08,250 --> 00:07:12,300
that you just given it's supposed to be

176
00:07:10,050 --> 00:07:14,820
a cat and you want the algorithm or the

177
00:07:12,300 --> 00:07:18,990
model to give you that same answer and

178
00:07:14,820 --> 00:07:20,790
these are vastly I guess easier to test

179
00:07:18,990 --> 00:07:22,710
because you already know what the answer

180
00:07:20,790 --> 00:07:25,860
is supposed to be then the unsupervised

181
00:07:22,710 --> 00:07:27,840
learning model which you use these

182
00:07:25,860 --> 00:07:30,750
models or build these models to discover

183
00:07:27,840 --> 00:07:33,869
patterns that you yourself humans can't

184
00:07:30,750 --> 00:07:35,790
see right so there are algorithms called

185
00:07:33,870 --> 00:07:37,530
like k-means clustering which is

186
00:07:35,790 --> 00:07:40,050
supposed to basic it fine given the plop

187
00:07:37,530 --> 00:07:42,539
of data give me what are the clusters of

188
00:07:40,050 --> 00:07:44,880
data that I can't see as a human by

189
00:07:42,540 --> 00:07:46,710
myself right but you don't really know

190
00:07:44,880 --> 00:07:49,169
when you just have that data what it

191
00:07:46,710 --> 00:07:50,760
might look like until you have run

192
00:07:49,169 --> 00:07:53,070
something like he means a clustering

193
00:07:50,760 --> 00:07:54,419
algorithm of it so it's a little bit

194
00:07:53,070 --> 00:07:56,790
harder to test it because you don't

195
00:07:54,419 --> 00:07:58,890
really know exactly what the answers

196
00:07:56,790 --> 00:08:01,260
you're looking for but you're hoping the

197
00:07:58,890 --> 00:08:02,430
model of the model or the algorithm to

198
00:08:01,260 --> 00:08:04,740
basically chuck through a lot of data

199
00:08:02,430 --> 00:08:07,950
fast and give me give you some sort of

200
00:08:04,740 --> 00:08:11,460
answer right so in terms of example

201
00:08:07,950 --> 00:08:13,530
purposes I wanted to kind of hone in on

202
00:08:11,460 --> 00:08:14,849
one example that uses supervised

203
00:08:13,530 --> 00:08:18,330
learning model just because it's a

204
00:08:14,850 --> 00:08:20,640
little bit easier to relate to but yeah

205
00:08:18,330 --> 00:08:22,710
and there's reinforcement learning

206
00:08:20,640 --> 00:08:24,630
models there's a bunch of other stuff

207
00:08:22,710 --> 00:08:27,810
that you know if you're curious you're

208
00:08:24,630 --> 00:08:29,159
welcome to go browse so yeah there's a

209
00:08:27,810 --> 00:08:31,500
lot of algorithms

210
00:08:29,160 --> 00:08:33,210
don't try to rethink is my whole purpose

211
00:08:31,500 --> 00:08:35,309
of this it's like I wanna just find an

212
00:08:33,210 --> 00:08:37,110
image online that has like a lot of

213
00:08:35,309 --> 00:08:38,520
these really famous known algorithms

214
00:08:37,110 --> 00:08:40,050
that are typically used in machine

215
00:08:38,520 --> 00:08:42,510
learning and kinda I don't want to say

216
00:08:40,049 --> 00:08:45,089
there's a lot of them right and there's

217
00:08:42,510 --> 00:08:47,310
no five no means am I gonna go into even

218
00:08:45,089 --> 00:08:50,400
like some of them but I want to just

219
00:08:47,310 --> 00:08:52,319
focus on you can't read that it's fine

220
00:08:50,400 --> 00:08:53,640
so this says here neural networks we're

221
00:08:52,320 --> 00:08:56,660
gonna go into kind of

222
00:08:53,640 --> 00:08:59,910
what what uh what perceptrons are and

223
00:08:56,660 --> 00:09:01,380
kind of how they they are the building

224
00:08:59,910 --> 00:09:02,910
blocks of building a simple neural

225
00:09:01,380 --> 00:09:04,560
network so there's simple neural network

226
00:09:02,910 --> 00:09:05,790
there's a deep learning neural network

227
00:09:04,560 --> 00:09:07,680
there's bunch of types of neural network

228
00:09:05,790 --> 00:09:09,829
but the simpler one is easier to relate

229
00:09:07,680 --> 00:09:11,040
to and easier to understand right now

230
00:09:09,830 --> 00:09:14,280
cool

231
00:09:11,040 --> 00:09:15,959
so perceptrons there's a simplest

232
00:09:14,280 --> 00:09:19,620
building block in a simple neural

233
00:09:15,960 --> 00:09:21,870
network it's a linear binary classifier

234
00:09:19,620 --> 00:09:24,030
that really gives what 0 or 1 at the end

235
00:09:21,870 --> 00:09:26,280
so I promise this is really the only

236
00:09:24,030 --> 00:09:30,270
equation I'm gonna put up on my slides

237
00:09:26,280 --> 00:09:32,970
today so this is what we would call like

238
00:09:30,270 --> 00:09:35,130
an activation function dragon here

239
00:09:32,970 --> 00:09:39,300
activation function it really just means

240
00:09:35,130 --> 00:09:40,530
like you have certain inputs so actually

241
00:09:39,300 --> 00:09:42,390
let me just go over this quickly right

242
00:09:40,530 --> 00:09:44,610
now so this is saying that the

243
00:09:42,390 --> 00:09:47,400
activation function is say I want the

244
00:09:44,610 --> 00:09:50,310
output to be 1 if some weighted value

245
00:09:47,400 --> 00:09:54,689
dot product of their variable X are you

246
00:09:50,310 --> 00:09:56,430
looking for plus B is a bias if that is

247
00:09:54,690 --> 00:09:58,830
greater than 0 then I want the output to

248
00:09:56,430 --> 00:10:01,849
be 1 so that really just is saying like

249
00:09:58,830 --> 00:10:04,080
given some variable looking for and

250
00:10:01,850 --> 00:10:05,760
given some sort of weight which weight

251
00:10:04,080 --> 00:10:08,700
just basically means how important this

252
00:10:05,760 --> 00:10:09,750
variable is and the weight will come you

253
00:10:08,700 --> 00:10:12,390
guys will understand a little bit more

254
00:10:09,750 --> 00:10:14,790
when I get to the next slide but so it

255
00:10:12,390 --> 00:10:18,750
gives it basically how important a

256
00:10:14,790 --> 00:10:22,410
variable is plus bias and if you just

257
00:10:18,750 --> 00:10:25,040
ignore all this equation right here if

258
00:10:22,410 --> 00:10:27,900
you see this diagram right here this

259
00:10:25,040 --> 00:10:31,079
this activation function literally is

260
00:10:27,900 --> 00:10:34,290
trying to split a problem space into two

261
00:10:31,080 --> 00:10:36,120
different quadrants right and this is

262
00:10:34,290 --> 00:10:39,689
very simple one so really only the zero

263
00:10:36,120 --> 00:10:42,720
one of given one feature right and the

264
00:10:39,690 --> 00:10:44,160
IQ palling this variable in ml language

265
00:10:42,720 --> 00:10:46,110
we call it the features features

266
00:10:44,160 --> 00:10:48,050
basically means the things that we care

267
00:10:46,110 --> 00:10:51,090
about that help us determine an answer

268
00:10:48,050 --> 00:10:53,609
so in this case this might be like the X

269
00:10:51,090 --> 00:10:56,310
might be hey the question is basically

270
00:10:53,610 --> 00:10:59,700
like uh is the color blue red on the dot

271
00:10:56,310 --> 00:11:02,280
right and then the model in this

272
00:10:59,700 --> 00:11:05,240
question would be a this line which is

273
00:11:02,280 --> 00:11:07,439
you know represented PI it's not it but

274
00:11:05,240 --> 00:11:09,600
an activation function that

275
00:11:07,440 --> 00:11:11,790
sickly say it's okay is it colored blue

276
00:11:09,600 --> 00:11:13,410
red I mean that's pretty simple this is

277
00:11:11,790 --> 00:11:18,599
basically a linear line that cuts the

278
00:11:13,410 --> 00:11:21,030
problem space right and so given that so

279
00:11:18,600 --> 00:11:22,410
that's this is a great example where we

280
00:11:21,030 --> 00:11:23,790
have only have like one feature we're

281
00:11:22,410 --> 00:11:27,060
looking at which is in this case like

282
00:11:23,790 --> 00:11:29,579
for example a color you can expand a

283
00:11:27,060 --> 00:11:31,890
perceptron to have more than one feature

284
00:11:29,580 --> 00:11:33,960
that it looks at and it has a lot more

285
00:11:31,890 --> 00:11:36,210
weights this looks a little bit

286
00:11:33,960 --> 00:11:37,530
complicated but all it is is like there

287
00:11:36,210 --> 00:11:39,600
is an activation function you have a

288
00:11:37,530 --> 00:11:42,390
bunch of inputs so it's a vector right

289
00:11:39,600 --> 00:11:45,330
it's a vector of features and where each

290
00:11:42,390 --> 00:11:47,490
feature is represented with you know a

291
00:11:45,330 --> 00:11:49,440
weight of how important is so to

292
00:11:47,490 --> 00:11:51,390
translate like a mathematical equation

293
00:11:49,440 --> 00:11:54,720
like this I would think of it as let's

294
00:11:51,390 --> 00:11:58,530
say if my question was would I buy some

295
00:11:54,720 --> 00:12:02,520
model of a car right and my inputs might

296
00:11:58,530 --> 00:12:03,839
be like price and color and size and yet

297
00:12:02,520 --> 00:12:05,910
oh right

298
00:12:03,840 --> 00:12:08,910
and then those would be literally my

299
00:12:05,910 --> 00:12:10,949
inputs right and then my weight would be

300
00:12:08,910 --> 00:12:13,650
for me I care a lot about price of the

301
00:12:10,950 --> 00:12:15,960
car so I would give a lot more weight to

302
00:12:13,650 --> 00:12:17,250
the price feature than any other things

303
00:12:15,960 --> 00:12:18,600
like color or whatever else they're

304
00:12:17,250 --> 00:12:20,250
looking at right and then that way you

305
00:12:18,600 --> 00:12:21,540
eat that would at the end give me zero

306
00:12:20,250 --> 00:12:26,910
one that's the whole point of

307
00:12:21,540 --> 00:12:29,160
perceptrons it gives you zero one so I

308
00:12:26,910 --> 00:12:32,069
put this slide because um you know how I

309
00:12:29,160 --> 00:12:34,020
was saying a lot of machine machine

310
00:12:32,070 --> 00:12:35,670
learning is based on biological evidence

311
00:12:34,020 --> 00:12:38,460
for learning or like biological

312
00:12:35,670 --> 00:12:41,839
structures perceptrons are literally

313
00:12:38,460 --> 00:12:45,390
meant to represent how neurons will work

314
00:12:41,840 --> 00:12:45,840
so you have a picture of a neuron right

315
00:12:45,390 --> 00:12:47,790
here

316
00:12:45,840 --> 00:12:50,070
there's dendrites which receive

317
00:12:47,790 --> 00:12:52,439
information from other neurons which is

318
00:12:50,070 --> 00:12:54,360
literally synonymous to bunch of inputs

319
00:12:52,440 --> 00:12:55,710
in the perceptron and I mean this the

320
00:12:54,360 --> 00:12:58,050
image even looks really really similar

321
00:12:55,710 --> 00:12:59,940
to one another and then you got some

322
00:12:58,050 --> 00:13:01,229
output that comes out and these axon

323
00:12:59,940 --> 00:13:03,720
terminals right here connect to other

324
00:13:01,230 --> 00:13:05,760
neurons right and then that's literally

325
00:13:03,720 --> 00:13:08,490
well as a perceptron does it taste and

326
00:13:05,760 --> 00:13:10,080
bunch of input calculates it and then

327
00:13:08,490 --> 00:13:13,950
gives us zero one and that gets

328
00:13:10,080 --> 00:13:16,680
transmitted to other neurons or in this

329
00:13:13,950 --> 00:13:18,420
case other perceptrons so yeah one

330
00:13:16,680 --> 00:13:21,390
perceptron can be really synonymous to

331
00:13:18,420 --> 00:13:23,790
what Howard and your own work

332
00:13:21,390 --> 00:13:27,060
so if you put a lot of these neurons

333
00:13:23,790 --> 00:13:28,170
together that's actually if you just

334
00:13:27,060 --> 00:13:29,449
like have a lot of these neurons

335
00:13:28,170 --> 00:13:32,189
together and many different layers

336
00:13:29,450 --> 00:13:33,420
that's like the simplest version when

337
00:13:32,190 --> 00:13:35,760
you're on that where you got so like

338
00:13:33,420 --> 00:13:39,839
here all by the way the all these

339
00:13:35,760 --> 00:13:42,120
circles are perceptrons so you got bunch

340
00:13:39,839 --> 00:13:43,980
of perceptrons at the first layer that's

341
00:13:42,120 --> 00:13:45,959
considered like the input layer which

342
00:13:43,980 --> 00:13:48,240
usually that only means that like these

343
00:13:45,959 --> 00:13:50,310
are the perceptrons that take the raw

344
00:13:48,240 --> 00:13:52,350
data you give it that might be color a

345
00:13:50,310 --> 00:13:53,880
bunch of numbers like the car example I

346
00:13:52,350 --> 00:13:57,060
was using like might be prices of things

347
00:13:53,880 --> 00:13:58,980
it might be size of things and then

348
00:13:57,060 --> 00:14:00,810
usually neural networks are defined by

349
00:13:58,980 --> 00:14:02,430
the fact that you have a lot of

350
00:14:00,810 --> 00:14:06,300
different abstract layers in between

351
00:14:02,430 --> 00:14:08,250
that might compute on the output of the

352
00:14:06,300 --> 00:14:10,260
first input layer and all the actual

353
00:14:08,250 --> 00:14:11,820
airs in between until you get to the

354
00:14:10,260 --> 00:14:14,790
output layer that finally ultimately

355
00:14:11,820 --> 00:14:16,589
gives you a bunch of variables that you

356
00:14:14,790 --> 00:14:19,170
know you can use as an answer to your

357
00:14:16,589 --> 00:14:22,079
questions so but the important most

358
00:14:19,170 --> 00:14:24,120
important thing here is that neural

359
00:14:22,079 --> 00:14:26,160
network the simple neural network you

360
00:14:24,120 --> 00:14:27,930
just put a lot of perceptrons together

361
00:14:26,160 --> 00:14:30,019
in main different abstract layers and

362
00:14:27,930 --> 00:14:32,519
that's how you get a neural network and

363
00:14:30,019 --> 00:14:35,250
going back to the whole biological

364
00:14:32,519 --> 00:14:38,269
example of things does it look any kind

365
00:14:35,250 --> 00:14:42,240
of like similar because the way we have

366
00:14:38,269 --> 00:14:43,920
abstract layers of perceptrons to create

367
00:14:42,240 --> 00:14:46,199
a neural net simple neural network is

368
00:14:43,920 --> 00:14:49,319
exactly almost like how brains work also

369
00:14:46,199 --> 00:14:51,599
brains have they have neurons that

370
00:14:49,320 --> 00:14:53,310
process the raw input that a bunch of

371
00:14:51,600 --> 00:14:54,959
other neurons that keep on processing

372
00:14:53,310 --> 00:14:56,969
after that after them so that until we

373
00:14:54,959 --> 00:14:58,890
you know I might see a Apple and think

374
00:14:56,970 --> 00:15:01,380
it's tasty right but there's a bunch of

375
00:14:58,890 --> 00:15:03,060
neurons the Hat that are abstracting the

376
00:15:01,380 --> 00:15:06,180
information that I've seen an apple

377
00:15:03,060 --> 00:15:11,760
until I get to that point right so um

378
00:15:06,180 --> 00:15:15,120
right alright so uh I was talking about

379
00:15:11,760 --> 00:15:18,060
apples right um so given that kind of

380
00:15:15,120 --> 00:15:19,769
like super fast overview of how like a

381
00:15:18,060 --> 00:15:21,599
neural network simple neural network

382
00:15:19,769 --> 00:15:24,839
might work and what like perceptions

383
00:15:21,600 --> 00:15:27,390
might be so I kind of wanted to apply

384
00:15:24,839 --> 00:15:29,819
that to our original problem was how our

385
00:15:27,390 --> 00:15:32,010
machine machine learning different than

386
00:15:29,819 --> 00:15:33,459
how like humans learn or what like the

387
00:15:32,010 --> 00:15:36,740
challenges

388
00:15:33,460 --> 00:15:40,940
that I guess impacted in a way that it's

389
00:15:36,740 --> 00:15:43,910
not as I guess as robust of a learning

390
00:15:40,940 --> 00:15:49,820
as humans do yet yet is the key order

391
00:15:43,910 --> 00:15:51,560
because we're getting there um so I want

392
00:15:49,820 --> 00:15:53,570
to take this simple example let's say

393
00:15:51,560 --> 00:15:55,939
you want to classify an image of an

394
00:15:53,570 --> 00:15:58,250
apple how would a machine-learning

395
00:15:55,940 --> 00:15:59,000
approach it versus how any one of you

396
00:15:58,250 --> 00:16:01,670
might approach it

397
00:15:59,000 --> 00:16:03,350
so if heard from machine were to look at

398
00:16:01,670 --> 00:16:04,430
this so let's say if you were to try to

399
00:16:03,350 --> 00:16:06,350
classify this image

400
00:16:04,430 --> 00:16:08,329
some of the features oh I guess it's

401
00:16:06,350 --> 00:16:11,450
that's really hard to see huh I'll read

402
00:16:08,330 --> 00:16:14,180
it off so some of the features that

403
00:16:11,450 --> 00:16:17,090
might be used to identify this object

404
00:16:14,180 --> 00:16:21,530
which is an apple in the image is for

405
00:16:17,090 --> 00:16:23,720
example size of the object the color

406
00:16:21,530 --> 00:16:25,939
gradients so there's a lot of Reds here

407
00:16:23,720 --> 00:16:29,780
some greens there that's not really part

408
00:16:25,940 --> 00:16:31,580
of an apple position so where the where

409
00:16:29,780 --> 00:16:35,480
the apple is in the in context of

410
00:16:31,580 --> 00:16:37,010
everything else and it might also look

411
00:16:35,480 --> 00:16:38,600
at stuff like as it's looking at the

412
00:16:37,010 --> 00:16:40,730
color gradients on the image like

413
00:16:38,600 --> 00:16:42,230
anomalies like white spots where there's

414
00:16:40,730 --> 00:16:44,390
like a shine on the surface right here

415
00:16:42,230 --> 00:16:46,400
that all shows up on your calculating

416
00:16:44,390 --> 00:16:49,370
the color gradients across the object

417
00:16:46,400 --> 00:16:50,840
you're looking at and I also put up here

418
00:16:49,370 --> 00:16:52,310
like so those might be the feature

419
00:16:50,840 --> 00:16:54,200
you're looking at and there might be

420
00:16:52,310 --> 00:16:56,300
some other anomalies that might throw

421
00:16:54,200 --> 00:17:01,300
off they auger them from thinking this

422
00:16:56,300 --> 00:17:03,439
an apple which is like the leaf and so

423
00:17:01,300 --> 00:17:06,200
these are kind of like the features that

424
00:17:03,440 --> 00:17:08,300
machine learning might use to create the

425
00:17:06,200 --> 00:17:12,290
model that it wants to use to identify

426
00:17:08,300 --> 00:17:15,980
this object as an apple a lot of the

427
00:17:12,290 --> 00:17:18,530
times when you're building models like

428
00:17:15,980 --> 00:17:20,750
this you run into many different

429
00:17:18,530 --> 00:17:22,790
problems so like for example if you have

430
00:17:20,750 --> 00:17:25,160
so I only listed very few features here

431
00:17:22,790 --> 00:17:26,780
but once you expand out your feature set

432
00:17:25,160 --> 00:17:29,060
which you normally usually we're like

433
00:17:26,780 --> 00:17:32,660
always have - - and you really want

434
00:17:29,060 --> 00:17:34,940
accurate results in classifications you

435
00:17:32,660 --> 00:17:36,530
might end up with too many features and

436
00:17:34,940 --> 00:17:38,060
you might end up with features that

437
00:17:36,530 --> 00:17:41,149
really don't really matter and the

438
00:17:38,060 --> 00:17:43,190
answer at the end for example if I was

439
00:17:41,150 --> 00:17:45,470
already looking at color gradients here

440
00:17:43,190 --> 00:17:46,880
I might not really care about the fact

441
00:17:45,470 --> 00:17:48,170
the feature that only one

442
00:17:46,880 --> 00:17:49,160
feature that looks at like whether the

443
00:17:48,170 --> 00:17:51,320
pixels red or something like that

444
00:17:49,160 --> 00:17:54,440
something very specific right so there

445
00:17:51,320 --> 00:17:57,169
are a lot of features that can bias or

446
00:17:54,440 --> 00:18:01,190
hinder or be completely redundant to the

447
00:17:57,170 --> 00:18:03,380
models that you're creating and then and

448
00:18:01,190 --> 00:18:05,840
if you as and if you keep on adding more

449
00:18:03,380 --> 00:18:07,640
features to your model that's yet

450
00:18:05,840 --> 00:18:08,959
another permutation of the feature that

451
00:18:07,640 --> 00:18:10,640
you need to calculate which just

452
00:18:08,960 --> 00:18:13,550
basically expands out your computation

453
00:18:10,640 --> 00:18:15,440
space so unless you have a lot in lots

454
00:18:13,550 --> 00:18:18,139
and lots of computers to just check out

455
00:18:15,440 --> 00:18:20,420
check out check out numbers right you

456
00:18:18,140 --> 00:18:22,640
might end up with a model that has like

457
00:18:20,420 --> 00:18:24,650
100 different features it takes like two

458
00:18:22,640 --> 00:18:25,700
hours to calculate for one image just

459
00:18:24,650 --> 00:18:28,100
because there's just so many features

460
00:18:25,700 --> 00:18:30,290
right so there's like a fine balance

461
00:18:28,100 --> 00:18:32,600
between water the right features to use

462
00:18:30,290 --> 00:18:34,850
and Mike you might end up put too many

463
00:18:32,600 --> 00:18:37,000
features to calculate you might end up

464
00:18:34,850 --> 00:18:40,100
with features that you don't really need

465
00:18:37,000 --> 00:18:44,210
and you know how to do this how to

466
00:18:40,100 --> 00:18:46,250
calculate fast right versus so I don't

467
00:18:44,210 --> 00:18:50,570
want to compare that to like if I was

468
00:18:46,250 --> 00:18:51,830
looking at this Apple feet picture these

469
00:18:50,570 --> 00:18:53,960
are some of the things I might think of

470
00:18:51,830 --> 00:18:55,970
and one of the things I really want you

471
00:18:53,960 --> 00:18:59,600
guys to notice is in this previous image

472
00:18:55,970 --> 00:19:01,460
it was had to do a lot with like you

473
00:18:59,600 --> 00:19:04,790
look at the Apple the machines look at

474
00:19:01,460 --> 00:19:06,380
the Apple these features are related to

475
00:19:04,790 --> 00:19:09,580
this physical properties right like the

476
00:19:06,380 --> 00:19:12,680
color or the size of this position etc

477
00:19:09,580 --> 00:19:15,649
and then the real distinction I really

478
00:19:12,680 --> 00:19:18,260
want to make here was if a human were to

479
00:19:15,650 --> 00:19:20,030
look at the Apple picture they also look

480
00:19:18,260 --> 00:19:21,800
at the physical properties of it right

481
00:19:20,030 --> 00:19:23,510
like the color size and everything that

482
00:19:21,800 --> 00:19:25,879
the machine the machine learning model

483
00:19:23,510 --> 00:19:27,950
might look at but you also have all

484
00:19:25,880 --> 00:19:29,480
these other contextual data because for

485
00:19:27,950 --> 00:19:31,850
example if I'm looking at Apple I might

486
00:19:29,480 --> 00:19:33,680
think oh that last time I ate an apple

487
00:19:31,850 --> 00:19:35,330
was really juicy or like I might think

488
00:19:33,680 --> 00:19:37,280
oh yeah this is a red apple I've seen

489
00:19:35,330 --> 00:19:39,710
green apples before or like I might

490
00:19:37,280 --> 00:19:42,620
think somebody else that I know really

491
00:19:39,710 --> 00:19:44,240
likes apples so like it's not just the

492
00:19:42,620 --> 00:19:45,919
physical qualities that you're looking

493
00:19:44,240 --> 00:19:48,050
at right but you also think of many

494
00:19:45,920 --> 00:19:50,810
other like you you draw from memories

495
00:19:48,050 --> 00:19:53,450
you draw from other examples of apples

496
00:19:50,810 --> 00:19:54,830
that you've seen so if you kind of if

497
00:19:53,450 --> 00:19:56,510
you can kind of think of this as like

498
00:19:54,830 --> 00:19:59,060
you have all this physical features you

499
00:19:56,510 --> 00:20:00,830
look at but you have as a human all this

500
00:19:59,060 --> 00:20:03,320
other contextual data

501
00:20:00,830 --> 00:20:06,049
that you can draw information from right

502
00:20:03,320 --> 00:20:07,158
which machine learning doesn't have

503
00:20:06,049 --> 00:20:10,789
right now like the machine learning

504
00:20:07,159 --> 00:20:12,140
right now as I shown you it only really

505
00:20:10,789 --> 00:20:13,549
looked at the physical features and they

506
00:20:12,140 --> 00:20:17,659
try to figure out what it was in that

507
00:20:13,549 --> 00:20:20,360
image right and then as a human you have

508
00:20:17,659 --> 00:20:21,769
so much other content of data that

509
00:20:20,360 --> 00:20:22,789
altogether that comes together that you

510
00:20:21,769 --> 00:20:25,010
don't even notice it's like all

511
00:20:22,789 --> 00:20:27,679
subconsciously process right that all

512
00:20:25,010 --> 00:20:33,710
together helps you to learn something is

513
00:20:27,679 --> 00:20:36,769
an Apple so to kind of hone in that a

514
00:20:33,710 --> 00:20:39,110
little bit this comparison I want to

515
00:20:36,769 --> 00:20:41,210
make was basically the difference in

516
00:20:39,110 --> 00:20:42,860
machine learning and a human in the

517
00:20:41,210 --> 00:20:44,990
power of basically the feature

518
00:20:42,860 --> 00:20:49,580
dimensionality and contextual data that

519
00:20:44,990 --> 00:20:53,059
you have so one other really big

520
00:20:49,580 --> 00:20:55,370
comparison I really want to make was if

521
00:20:53,059 --> 00:20:57,350
you remember in a couple slides ago

522
00:20:55,370 --> 00:20:59,479
where I showed you guys how you would

523
00:20:57,350 --> 00:21:03,889
use a training data set to start

524
00:20:59,480 --> 00:21:05,450
building a model a lot of the problems

525
00:21:03,889 --> 00:21:06,860
and I've definitely know this personally

526
00:21:05,450 --> 00:21:09,740
because I've worked on image

527
00:21:06,860 --> 00:21:13,939
classification is it's difficult to get

528
00:21:09,740 --> 00:21:18,350
a very large as well as varied training

529
00:21:13,940 --> 00:21:21,950
set data so for example let's say in the

530
00:21:18,350 --> 00:21:24,110
context of an apple you might be lucky

531
00:21:21,950 --> 00:21:26,450
if you get something like ten thousand

532
00:21:24,110 --> 00:21:29,629
or a hundred thousand labelled images

533
00:21:26,450 --> 00:21:32,809
and examples of apples that you can use

534
00:21:29,630 --> 00:21:35,179
to train your model right and I like

535
00:21:32,809 --> 00:21:37,940
literally ten thousand is like a lot if

536
00:21:35,179 --> 00:21:39,500
you're looking at images or objects or I

537
00:21:37,940 --> 00:21:40,730
can only really speak from image

538
00:21:39,500 --> 00:21:44,120
classification because that's the work

539
00:21:40,730 --> 00:21:46,149
that done and if you're thinking about

540
00:21:44,120 --> 00:21:49,879
it's like ten thousand is not that many

541
00:21:46,149 --> 00:21:51,500
examples to look at something something

542
00:21:49,880 --> 00:21:52,820
as simple as apples sure that might work

543
00:21:51,500 --> 00:21:55,279
but if you get into more complex

544
00:21:52,820 --> 00:21:57,049
problems right like for example how do

545
00:21:55,279 --> 00:21:59,000
you solve like I'm gonna go into the

546
00:21:57,049 --> 00:22:00,470
alphago example in a bit but like hi if

547
00:21:59,000 --> 00:22:02,600
you could if you're trying to compute

548
00:22:00,470 --> 00:22:04,730
for like a very complex game right

549
00:22:02,600 --> 00:22:07,158
there's probably there's you're gonna

550
00:22:04,730 --> 00:22:09,200
need a lot of data and examples to make

551
00:22:07,159 --> 00:22:13,220
sure your model actually is accurate

552
00:22:09,200 --> 00:22:14,390
right so this is one of the biggest

553
00:22:13,220 --> 00:22:16,790
tasks in one building

554
00:22:14,390 --> 00:22:18,290
model like you can't get enough for the

555
00:22:16,790 --> 00:22:21,350
training model a training set to

556
00:22:18,290 --> 00:22:24,139
actually make your model accurate and

557
00:22:21,350 --> 00:22:27,649
then if you think about it if you

558
00:22:24,140 --> 00:22:29,390
compare it to a human being like how

559
00:22:27,650 --> 00:22:31,160
many apples do you think you've seen

560
00:22:29,390 --> 00:22:33,050
ever since you were born right like

561
00:22:31,160 --> 00:22:35,860
probably a lot and you don't even have

562
00:22:33,050 --> 00:22:38,330
to eat an apple or CNF with yourself to

563
00:22:35,860 --> 00:22:40,040
count it as an example right people talk

564
00:22:38,330 --> 00:22:41,689
about apples people other people might

565
00:22:40,040 --> 00:22:44,810
eat apples and you have all this like

566
00:22:41,690 --> 00:22:46,820
even indirect examples of apples that

567
00:22:44,810 --> 00:22:49,190
you might be exposed to that it's not

568
00:22:46,820 --> 00:22:50,720
like just like looking at apples and oh

569
00:22:49,190 --> 00:22:52,010
that's an apple right you might see it

570
00:22:50,720 --> 00:22:54,530
done bunch of different colors at apples

571
00:22:52,010 --> 00:22:56,000
so there's a lot of data that you're

572
00:22:54,530 --> 00:23:00,770
just always subconsciously kind of

573
00:22:56,000 --> 00:23:03,770
absorbing in that far surpasses the

574
00:23:00,770 --> 00:23:08,570
label data you can give to a model to

575
00:23:03,770 --> 00:23:12,560
train it so there's actually MIT paper

576
00:23:08,570 --> 00:23:14,750
on this about why I linked it here why

577
00:23:12,560 --> 00:23:18,260
humans right now are far ahead and

578
00:23:14,750 --> 00:23:19,430
learning in terms of a far head and

579
00:23:18,260 --> 00:23:21,530
learning that machine's right now it's

580
00:23:19,430 --> 00:23:23,390
because we seriously just have so much

581
00:23:21,530 --> 00:23:25,100
contextual data that we get all the time

582
00:23:23,390 --> 00:23:27,350
right about everything you don't even

583
00:23:25,100 --> 00:23:29,780
notice it but you are always absorbing

584
00:23:27,350 --> 00:23:31,820
some sort of example about any of the

585
00:23:29,780 --> 00:23:33,230
objects or people or the language or

586
00:23:31,820 --> 00:23:35,300
whatever that you're interacting with

587
00:23:33,230 --> 00:23:37,190
that you that the machine learning just

588
00:23:35,300 --> 00:23:38,600
can't right now at this moment can't

589
00:23:37,190 --> 00:23:40,670
keep up with because you're artificially

590
00:23:38,600 --> 00:23:43,879
creating datasets to feed into a model

591
00:23:40,670 --> 00:23:48,830
to train it right so there is that kind

592
00:23:43,880 --> 00:23:50,570
of sorry am i running out time oh okay

593
00:23:48,830 --> 00:23:52,760
yeah I know it so there's that I'll go

594
00:23:50,570 --> 00:23:54,950
through really fast so I put some

595
00:23:52,760 --> 00:23:56,480
summary of comparison here you guys can

596
00:23:54,950 --> 00:24:00,800
take a look I was gonna go into detail

597
00:23:56,480 --> 00:24:02,390
but that's fine um so yeah uh I've given

598
00:24:00,800 --> 00:24:05,149
couple examples how a machine learning

599
00:24:02,390 --> 00:24:07,010
is you know in some ways have a lot more

600
00:24:05,150 --> 00:24:09,050
challenges that humans do a lot of them

601
00:24:07,010 --> 00:24:10,790
is like you know obviously access to a

602
00:24:09,050 --> 00:24:14,750
ton of data subconscious data that we

603
00:24:10,790 --> 00:24:16,010
always process feature sets one of the

604
00:24:14,750 --> 00:24:17,630
things what are the features that you

605
00:24:16,010 --> 00:24:21,370
can reasonably calculate for example

606
00:24:17,630 --> 00:24:23,810
like google has about 1 million servers

607
00:24:21,370 --> 00:24:26,090
they're able to use all that computation

608
00:24:23,810 --> 00:24:27,879
power to power all the AI provider

609
00:24:26,090 --> 00:24:30,249
services versus how many

610
00:24:27,879 --> 00:24:31,359
us here have 1 million servers and you

611
00:24:30,249 --> 00:24:34,479
know you can do stuff stuff with that

612
00:24:31,359 --> 00:24:36,789
right and if you compare that to a human

613
00:24:34,479 --> 00:24:38,529
brain you got 1 billion neurons it's

614
00:24:36,789 --> 00:24:40,829
like all provided infrastructure to

615
00:24:38,529 --> 00:24:43,179
compute whatever you're looking at right

616
00:24:40,829 --> 00:24:46,389
sorry I'm severely running out of time

617
00:24:43,179 --> 00:24:50,409
but let's see if I can speed this

618
00:24:46,389 --> 00:24:53,139
through yeah so if you have one thing to

619
00:24:50,409 --> 00:24:55,119
take away from this talk machines

620
00:24:53,139 --> 00:24:57,248
machine learning learns very differently

621
00:24:55,119 --> 00:24:59,319
it has a lot of different challenges and

622
00:24:57,249 --> 00:25:00,909
especially doesn't have access to all

623
00:24:59,319 --> 00:25:04,059
the data and then the learning capably

624
00:25:00,909 --> 00:25:05,979
that we already have so once until we

625
00:25:04,059 --> 00:25:07,678
get to that you might not be able to

626
00:25:05,979 --> 00:25:09,999
compare it directly to a human learning

627
00:25:07,679 --> 00:25:12,789
I'll put the slides up if you guys want

628
00:25:09,999 --> 00:25:14,229
to take a look oh this slide please

629
00:25:12,789 --> 00:25:16,599
you might want to take a look at this

630
00:25:14,229 --> 00:25:18,759
paper really quick because you'll learn

631
00:25:16,599 --> 00:25:20,439
some really cool stuff about how neural

632
00:25:18,759 --> 00:25:21,999
networks see the world that might be

633
00:25:20,440 --> 00:25:23,100
different from what you think all right

634
00:25:21,999 --> 00:25:29,280
thank you

635
00:25:23,100 --> 00:25:29,280
[Applause]

