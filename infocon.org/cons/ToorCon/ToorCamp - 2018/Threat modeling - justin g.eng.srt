1
00:00:01,219 --> 00:00:06,770
and I guess without further ado let's

2
00:00:04,279 --> 00:00:14,030
welcome Justin here to talk about threat

3
00:00:06,770 --> 00:00:16,460
modeling thank you very much my name is

4
00:00:14,030 --> 00:00:18,470
Justin Goodheart I'm from Olympia

5
00:00:16,460 --> 00:00:22,280
Washington part of the only mega group

6
00:00:18,470 --> 00:00:25,160
here hanging out helping out and I'm

7
00:00:22,280 --> 00:00:28,130
here to talk about threat modeling and

8
00:00:25,160 --> 00:00:31,730
try not to do feedback so if I lean

9
00:00:28,130 --> 00:00:33,980
forward I started out with doing

10
00:00:31,730 --> 00:00:36,079
development work for about 13 years and

11
00:00:33,980 --> 00:00:37,640
then at one point they shifted and

12
00:00:36,079 --> 00:00:40,159
pulled me over into the security team

13
00:00:37,640 --> 00:00:42,640
and so I got a chance to start trying to

14
00:00:40,159 --> 00:00:45,469
help developers write more secure code

15
00:00:42,640 --> 00:00:46,670
better quality code and over the years

16
00:00:45,469 --> 00:00:49,280
I've been able to help out with threat

17
00:00:46,670 --> 00:00:52,010
modeling able to help out with scare

18
00:00:49,280 --> 00:00:54,889
code static code analysis different

19
00:00:52,010 --> 00:01:00,709
talks and pretty much just trying to be

20
00:00:54,889 --> 00:01:02,210
a good member of the community how many

21
00:01:00,710 --> 00:01:06,200
folks have done threat modeling before

22
00:01:02,210 --> 00:01:06,980
show hands nice those who didn't raise

23
00:01:06,200 --> 00:01:08,540
their hand

24
00:01:06,980 --> 00:01:11,060
I could probably guarantee that you have

25
00:01:08,540 --> 00:01:14,830
done some former threat modeling a good

26
00:01:11,060 --> 00:01:18,110
example is with traffic driving around

27
00:01:14,830 --> 00:01:21,050
obeying the speed limit signs doing

28
00:01:18,110 --> 00:01:23,060
maintenance on your car being able to

29
00:01:21,050 --> 00:01:24,380
keep an eye out for the drivers around

30
00:01:23,060 --> 00:01:26,540
you especially those who are driving

31
00:01:24,380 --> 00:01:30,020
erratically or who are on their phone

32
00:01:26,540 --> 00:01:32,030
while shaving and putting on makeup so

33
00:01:30,020 --> 00:01:34,160
what you're doing is you're putting in

34
00:01:32,030 --> 00:01:35,450
different controls to try to reduce the

35
00:01:34,160 --> 00:01:37,369
threats that could go against you

36
00:01:35,450 --> 00:01:38,510
so obeying the speed limit science

37
00:01:37,370 --> 00:01:40,700
keeping your distance from the car in

38
00:01:38,510 --> 00:01:42,800
front of you making sure your vehicle

39
00:01:40,700 --> 00:01:44,150
has been properly maintained so it

40
00:01:42,800 --> 00:01:47,420
doesn't break down on the side of the

41
00:01:44,150 --> 00:01:49,340
road those kind of things is what we are

42
00:01:47,420 --> 00:01:50,780
trying to encourage the developers in

43
00:01:49,340 --> 00:01:52,640
doing when they're building applications

44
00:01:50,780 --> 00:01:55,990
and when they're taking a look at

45
00:01:52,640 --> 00:01:58,640
implementing new systems we want them to

46
00:01:55,990 --> 00:02:00,470
see what kind of threats are there see

47
00:01:58,640 --> 00:02:01,520
what kind of things to avoid see what

48
00:02:00,470 --> 00:02:05,260
they can put in place in order to try to

49
00:02:01,520 --> 00:02:05,259
reduce the risk to the application

50
00:02:06,240 --> 00:02:14,070
I missed the slide there it is so

51
00:02:12,210 --> 00:02:15,930
certain out I was going to talk about

52
00:02:14,070 --> 00:02:17,609
application threat modeling and then I

53
00:02:15,930 --> 00:02:19,800
have a couple slides on network threat

54
00:02:17,610 --> 00:02:22,500
modeling as well kind of a new area I'm

55
00:02:19,800 --> 00:02:25,320
diving into threat modeling is where

56
00:02:22,500 --> 00:02:27,209
have most my experience though so

57
00:02:25,320 --> 00:02:29,130
application threat modeling is approach

58
00:02:27,209 --> 00:02:30,990
for analyzing the security of

59
00:02:29,130 --> 00:02:32,160
application or system so a good

60
00:02:30,990 --> 00:02:35,790
opportunity in order to be able to take

61
00:02:32,160 --> 00:02:38,549
a look at how it's documented how it's

62
00:02:35,790 --> 00:02:41,910
built how you have put in the different

63
00:02:38,550 --> 00:02:44,010
uh negations in place and it also helps

64
00:02:41,910 --> 00:02:46,890
with the developers to get a chance to

65
00:02:44,010 --> 00:02:48,750
work with the security team in order to

66
00:02:46,890 --> 00:02:50,609
learn more and do cross collaboration

67
00:02:48,750 --> 00:02:52,739
because there's things developers have

68
00:02:50,610 --> 00:02:54,300
figured out to make things better they

69
00:02:52,739 --> 00:02:56,070
could help security and then there's

70
00:02:54,300 --> 00:02:57,480
areas where security gets a chance to

71
00:02:56,070 --> 00:02:59,430
collaborate with developers to help

72
00:02:57,480 --> 00:03:03,959
their code and their systems be more

73
00:02:59,430 --> 00:03:05,520
secure so the process threat modeling

74
00:03:03,959 --> 00:03:07,860
process is pretty much breaking down the

75
00:03:05,520 --> 00:03:10,200
system then we do is you determine what

76
00:03:07,860 --> 00:03:11,790
the threats are and then you go through

77
00:03:10,200 --> 00:03:13,260
and you identify the countermeasures so

78
00:03:11,790 --> 00:03:16,079
mitigations or controls you can put in

79
00:03:13,260 --> 00:03:18,750
place to reduce the risk potentially

80
00:03:16,080 --> 00:03:23,730
also eliminating risk usually that means

81
00:03:18,750 --> 00:03:24,959
get rid of the feature but most what we

82
00:03:23,730 --> 00:03:26,488
do with application threat modeling is

83
00:03:24,959 --> 00:03:28,500
we start with the data flow diagram a

84
00:03:26,489 --> 00:03:33,150
good conceptual diagram of the system

85
00:03:28,500 --> 00:03:35,070
using some simple shapes the different

86
00:03:33,150 --> 00:03:37,950
shapes are external entity so a

87
00:03:35,070 --> 00:03:39,720
different system or potentially like

88
00:03:37,950 --> 00:03:41,190
some one another company systems or

89
00:03:39,720 --> 00:03:43,799
another internal system that you're

90
00:03:41,190 --> 00:03:47,060
using or interfacing with maybe even a

91
00:03:43,799 --> 00:03:50,340
third-party service you have a process

92
00:03:47,060 --> 00:03:53,070
this is where the work is actually done

93
00:03:50,340 --> 00:03:55,739
in the system so a function could be a

94
00:03:53,070 --> 00:03:58,519
web service you can look at like the

95
00:03:55,739 --> 00:04:01,230
application itself as its own process

96
00:03:58,519 --> 00:04:03,000
the data flow so where the data is going

97
00:04:01,230 --> 00:04:05,880
back and forth and that's what you're

98
00:04:03,000 --> 00:04:08,220
trying to focus on and then data store

99
00:04:05,880 --> 00:04:10,410
where the data it lands where the file

100
00:04:08,220 --> 00:04:13,079
shares are or your data stores like your

101
00:04:10,410 --> 00:04:15,150
database may be a flat file that you're

102
00:04:13,079 --> 00:04:16,530
storing somewhere or some data and then

103
00:04:15,150 --> 00:04:17,899
trust boundaries is something a little

104
00:04:16,529 --> 00:04:20,358
bit different from

105
00:04:17,899 --> 00:04:24,198
traditional data flow diagrams that

106
00:04:20,358 --> 00:04:27,380
threat models use and that shows going

107
00:04:24,199 --> 00:04:31,070
from one security context to another so

108
00:04:27,380 --> 00:04:32,780
like a good example on a web server you

109
00:04:31,070 --> 00:04:34,669
have different rights that you're

110
00:04:32,780 --> 00:04:37,820
running as than you would if you're

111
00:04:34,669 --> 00:04:39,680
connecting from a browser or the

112
00:04:37,820 --> 00:04:41,090
settings that you have on a database is

113
00:04:39,680 --> 00:04:43,100
going to be different than your web

114
00:04:41,090 --> 00:04:45,229
server so you have different contexts

115
00:04:43,100 --> 00:04:47,300
that you're transferring from and so we

116
00:04:45,229 --> 00:04:49,070
want to show those lines in order to

117
00:04:47,300 --> 00:04:53,389
show when you're going from one context

118
00:04:49,070 --> 00:04:55,659
to another a good example of a dad one

119
00:04:53,389 --> 00:04:57,740
of the diagrams for a threat model is

120
00:04:55,660 --> 00:05:00,919
just one of the canned ones I found

121
00:04:57,740 --> 00:05:03,560
online from Microsoft and this one shows

122
00:05:00,919 --> 00:05:05,990
a user browser the users coming in

123
00:05:03,560 --> 00:05:07,729
through a user interface service goes

124
00:05:05,990 --> 00:05:09,889
over to user profile service that has

125
00:05:07,729 --> 00:05:12,110
its own data store and it also

126
00:05:09,889 --> 00:05:14,060
incorporates in a newsfeed service that

127
00:05:12,110 --> 00:05:17,210
it also has its own back-end data store

128
00:05:14,060 --> 00:05:20,030
but also can push out RSS feeds to the

129
00:05:17,210 --> 00:05:22,580
Internet what we do is we start out with

130
00:05:20,030 --> 00:05:24,919
the diagram here and we sit down and we

131
00:05:22,580 --> 00:05:28,669
label each and every interaction going

132
00:05:24,919 --> 00:05:30,409
from one process to the data flow or

133
00:05:28,669 --> 00:05:32,450
from the data flow across the trust

134
00:05:30,410 --> 00:05:36,110
boundary or going into another data

135
00:05:32,450 --> 00:05:37,669
store and we want to make sure stuff

136
00:05:36,110 --> 00:05:40,310
that we could actually reference that

137
00:05:37,669 --> 00:05:42,979
one pinpoint and this was kind of a

138
00:05:40,310 --> 00:05:46,099
sloppy normally the numbers are much

139
00:05:42,979 --> 00:05:49,669
better and you break it down more detail

140
00:05:46,099 --> 00:05:51,500
but this is kind of overlaying then once

141
00:05:49,669 --> 00:05:53,659
you have your interactions on the

142
00:05:51,500 --> 00:05:56,030
diagram you go ahead and you sit down

143
00:05:53,660 --> 00:05:58,700
any show at each one of those steps

144
00:05:56,030 --> 00:06:00,169
where it crosses over from across trust

145
00:05:58,700 --> 00:06:03,139
boundaries across processes and you

146
00:06:00,169 --> 00:06:06,560
should identify the stride stride is a

147
00:06:03,139 --> 00:06:08,599
different threat categories but each one

148
00:06:06,560 --> 00:06:11,120
has each of the different processes

149
00:06:08,599 --> 00:06:14,469
external interactors data stores etc

150
00:06:11,120 --> 00:06:17,900
have a different potential threat area

151
00:06:14,470 --> 00:06:21,639
let me go into that a little bit so

152
00:06:17,900 --> 00:06:23,810
stride is spoofing tampering repudiation

153
00:06:21,639 --> 00:06:29,210
information disclosure denial service

154
00:06:23,810 --> 00:06:30,500
and elevation privilege and we see if we

155
00:06:29,210 --> 00:06:32,310
go back one

156
00:06:30,500 --> 00:06:34,139
probably should shift these slides

157
00:06:32,310 --> 00:06:38,060
around so that I go through stride

158
00:06:34,139 --> 00:06:40,469
before talking about the matrix so

159
00:06:38,060 --> 00:06:43,139
old-school what we do is we sit down

160
00:06:40,469 --> 00:06:44,280
with this matrix and we break down after

161
00:06:43,139 --> 00:06:47,189
you've identified all the different

162
00:06:44,280 --> 00:06:49,169
elements on the diagram and we figure

163
00:06:47,189 --> 00:06:51,090
out what threats were there and so we

164
00:06:49,169 --> 00:06:52,590
sit down and we go okay we're going from

165
00:06:51,090 --> 00:06:54,000
this point to that point and we'd sit

166
00:06:52,590 --> 00:06:57,150
down and go okay they're spoofing and

167
00:06:54,000 --> 00:06:57,870
there is repudiation and then we move on

168
00:06:57,150 --> 00:06:59,698
to the next one

169
00:06:57,870 --> 00:07:02,370
and so it's kind of a manual process

170
00:06:59,699 --> 00:07:04,710
using this matrix later on I'll show you

171
00:07:02,370 --> 00:07:06,930
a tool that Microsoft provides for free

172
00:07:04,710 --> 00:07:08,250
that helps determine the threats

173
00:07:06,930 --> 00:07:13,560
automatically make it a little bit

174
00:07:08,250 --> 00:07:16,139
easier so spoofing is trying to pretend

175
00:07:13,560 --> 00:07:18,240
that you're someone or that you're

176
00:07:16,139 --> 00:07:19,830
something that you're not so a good

177
00:07:18,240 --> 00:07:21,469
example is if I was to go up and say

178
00:07:19,830 --> 00:07:23,969
that I'm Bill Gates

179
00:07:21,469 --> 00:07:25,590
I'd have to prove it and usually we do

180
00:07:23,969 --> 00:07:28,439
that through some sort of factor

181
00:07:25,590 --> 00:07:30,239
authentication sometimes multi factors

182
00:07:28,439 --> 00:07:32,430
sometimes single factor and you're

183
00:07:30,240 --> 00:07:34,349
trying to prove that entity well

184
00:07:32,430 --> 00:07:37,259
sometimes you're interfacing with

185
00:07:34,349 --> 00:07:39,000
another service some third party that

186
00:07:37,259 --> 00:07:40,500
third party you want to be able to prove

187
00:07:39,000 --> 00:07:42,930
that that really is who you're talking

188
00:07:40,500 --> 00:07:47,580
to and so you're trying to reduce the

189
00:07:42,930 --> 00:07:49,830
potential of an attacker or someone or

190
00:07:47,580 --> 00:07:50,818
maybe in a mistake configuration and

191
00:07:49,830 --> 00:07:53,250
talking to someone that you're not

192
00:07:50,819 --> 00:07:57,750
supposed to be talking to or gonna be

193
00:07:53,250 --> 00:07:58,889
someone that they're not tampering this

194
00:07:57,750 --> 00:08:01,349
is where you've changed in the data

195
00:07:58,889 --> 00:08:02,909
either across the wire or at rest

196
00:08:01,349 --> 00:08:06,830
or you're editing it when you're not

197
00:08:02,909 --> 00:08:09,240
authorized to do so so being able to

198
00:08:06,830 --> 00:08:12,930
capture it across the wire inject

199
00:08:09,240 --> 00:08:15,120
something also potentially compromised

200
00:08:12,930 --> 00:08:19,770
into files on the network share some

201
00:08:15,120 --> 00:08:21,990
like that repudiation is basically a

202
00:08:19,770 --> 00:08:25,529
legal term for being able to prove that

203
00:08:21,990 --> 00:08:27,300
something happened usually we do this

204
00:08:25,529 --> 00:08:30,089
through a lot mitigated through logs and

205
00:08:27,300 --> 00:08:33,029
our to prove usually also the third

206
00:08:30,089 --> 00:08:35,549
party good example what you're buying

207
00:08:33,029 --> 00:08:37,588
stock and you go in there and you say

208
00:08:35,549 --> 00:08:39,750
okay the stocks coming down it's about

209
00:08:37,589 --> 00:08:41,550
fifteen dollars a share and you go ahead

210
00:08:39,750 --> 00:08:43,360
and you buy a hundred shares but then

211
00:08:41,549 --> 00:08:45,368
you see it drop another five dollars

212
00:08:43,360 --> 00:08:47,350
so you call up the company you say hey I

213
00:08:45,369 --> 00:08:49,809
didn't buy it at $15 I really bought it

214
00:08:47,350 --> 00:08:51,819
at 10 well in order to be able to reduce

215
00:08:49,809 --> 00:08:53,799
the someone trying to pull scam or

216
00:08:51,819 --> 00:08:56,979
something over they have a trusted third

217
00:08:53,799 --> 00:08:59,829
party that timestamps the interaction

218
00:08:56,980 --> 00:09:01,809
how much it cost the time and you could

219
00:08:59,829 --> 00:09:05,049
prove that when you bought it you really

220
00:09:01,809 --> 00:09:08,769
bought it at $15 a share that's a good

221
00:09:05,049 --> 00:09:11,920
example - also the checks in the mail so

222
00:09:08,769 --> 00:09:13,480
you call it the collectors call you and

223
00:09:11,920 --> 00:09:15,040
you're talking to on the phone you say

224
00:09:13,480 --> 00:09:16,660
well the checks in the mail

225
00:09:15,040 --> 00:09:17,799
well way for them to prove that the

226
00:09:16,660 --> 00:09:19,868
check was in the mail on that particular

227
00:09:17,799 --> 00:09:21,699
day the post office will stamp the

228
00:09:19,869 --> 00:09:23,920
envelopes are going through the post

229
00:09:21,699 --> 00:09:25,988
office with their own time stamp and

230
00:09:23,920 --> 00:09:27,488
they're a third party that doesn't care

231
00:09:25,989 --> 00:09:31,660
if you pay your bill on time or not and

232
00:09:27,489 --> 00:09:35,199
so that works for non-repudiation not

233
00:09:31,660 --> 00:09:37,839
the good kind of fun example information

234
00:09:35,199 --> 00:09:40,089
disclosure is very similar to tampering

235
00:09:37,839 --> 00:09:42,489
except this time is unauthorized viewing

236
00:09:40,089 --> 00:09:44,949
of the data so you've been able to gain

237
00:09:42,489 --> 00:09:46,209
access to a file you've been able to see

238
00:09:44,949 --> 00:09:49,179
what's going across the wire than when

239
00:09:46,209 --> 00:09:49,988
you're a supposed to now this has also a

240
00:09:49,179 --> 00:09:52,360
lot when you're getting into

241
00:09:49,989 --> 00:09:55,720
confidential data that a lot of folks

242
00:09:52,360 --> 00:09:59,019
are not authorized to see denial service

243
00:09:55,720 --> 00:10:01,299
is always fun this is where be able to

244
00:09:59,019 --> 00:10:02,470
prevent something from running beyond to

245
00:10:01,299 --> 00:10:03,669
prevent someone from getting to your

246
00:10:02,470 --> 00:10:05,350
service be able to prevent it from

247
00:10:03,669 --> 00:10:07,989
sowing into your website

248
00:10:05,350 --> 00:10:11,290
denial service also has fun stuff with

249
00:10:07,989 --> 00:10:12,399
the distributed DDoS attacks or what

250
00:10:11,290 --> 00:10:14,769
happened last night I guess with the

251
00:10:12,399 --> 00:10:16,769
wireless were conveniently went down for

252
00:10:14,769 --> 00:10:18,999
a little while

253
00:10:16,769 --> 00:10:21,339
elevation privilege and this is where

254
00:10:18,999 --> 00:10:23,679
you can inject something in in order to

255
00:10:21,339 --> 00:10:27,220
be able to get more rights than you were

256
00:10:23,679 --> 00:10:30,399
authorized in half so some folks do this

257
00:10:27,220 --> 00:10:32,980
through probably sequel injection

258
00:10:30,399 --> 00:10:34,779
cross-site scripting to be able to gain

259
00:10:32,980 --> 00:10:35,860
access to different areas or be able to

260
00:10:34,779 --> 00:10:37,899
change something they're supposed to be

261
00:10:35,860 --> 00:10:39,459
able to change or to try to change the

262
00:10:37,899 --> 00:10:40,829
context that they're running ass in

263
00:10:39,459 --> 00:10:48,089
order to be able to have more rights

264
00:10:40,829 --> 00:10:50,199
admin rights other rights back about

265
00:10:48,089 --> 00:10:52,089
2003 I think it was the trustworthy

266
00:10:50,199 --> 00:10:54,549
computing initiative that Bill Gates put

267
00:10:52,089 --> 00:10:56,889
out with a simple memo they started

268
00:10:54,549 --> 00:10:59,379
working on being able to show

269
00:10:56,889 --> 00:11:02,439
different ways of identifying a scale

270
00:10:59,379 --> 00:11:05,170
for the risk of the system and they use

271
00:11:02,439 --> 00:11:08,998
an acronym called dread and it stands

272
00:11:05,170 --> 00:11:11,979
for damaged repudiate read

273
00:11:08,999 --> 00:11:14,350
reproducibility I could say it exploit

274
00:11:11,980 --> 00:11:15,999
ability affected users and

275
00:11:14,350 --> 00:11:18,100
discoverability and the whole goal was

276
00:11:15,999 --> 00:11:19,720
as you sit there with the big room of

277
00:11:18,100 --> 00:11:22,419
folks and you go down each one of these

278
00:11:19,720 --> 00:11:23,499
giving it to a scale of 1 to 5 and so

279
00:11:22,419 --> 00:11:26,259
you could sit there and you could debate

280
00:11:23,499 --> 00:11:30,639
over is it really a three is it a four

281
00:11:26,259 --> 00:11:32,709
who wins and what ends up happening is

282
00:11:30,639 --> 00:11:35,019
you end up going through and identifying

283
00:11:32,709 --> 00:11:39,368
what the risk score is for that

284
00:11:35,019 --> 00:11:40,959
particular threat and lessons learned

285
00:11:39,369 --> 00:11:42,189
they ended up shift in it because there

286
00:11:40,959 --> 00:11:44,829
was too many folks fighting over the

287
00:11:42,189 --> 00:11:47,079
different scales to be able to go for a

288
00:11:44,829 --> 00:11:49,238
high medium low so if you sit down in

289
00:11:47,079 --> 00:11:50,799
the group and someone goes well I think

290
00:11:49,239 --> 00:11:53,589
this is gonna be really bad because it

291
00:11:50,799 --> 00:11:56,139
will impact us it will affect 10,000

292
00:11:53,589 --> 00:11:58,149
users we're gonna set it as high and

293
00:11:56,139 --> 00:11:59,889
it's a lot easier to sell a high medium

294
00:11:58,149 --> 00:12:04,899
low than it is to go through each of

295
00:11:59,889 --> 00:12:08,110
these and have a D of five and a R of

296
00:12:04,899 --> 00:12:11,499
one an eighth a of three and what does

297
00:12:08,110 --> 00:12:12,819
that mean kind of thing so high medium

298
00:12:11,499 --> 00:12:16,779
low works much better when you're going

299
00:12:12,819 --> 00:12:19,269
through threat models then you go in and

300
00:12:16,779 --> 00:12:21,790
you start addressing each as well kind

301
00:12:19,269 --> 00:12:22,959
of bring it back make sure that what's

302
00:12:21,790 --> 00:12:26,709
going on my head you guys are actually

303
00:12:22,959 --> 00:12:28,929
understanding too so you've gone through

304
00:12:26,709 --> 00:12:31,628
you've documented a system you created a

305
00:12:28,929 --> 00:12:33,549
conceptual diagram you've now marked

306
00:12:31,629 --> 00:12:34,989
each of the interactions you've gone

307
00:12:33,549 --> 00:12:37,059
through and you determine what kind of

308
00:12:34,989 --> 00:12:38,949
threats are happening in each of those

309
00:12:37,059 --> 00:12:40,299
interactions and you've gone through and

310
00:12:38,949 --> 00:12:42,969
you've identified the risk of that

311
00:12:40,299 --> 00:12:47,019
particular threat now it's time to

312
00:12:42,970 --> 00:12:49,539
mitigate it so there's four main ways of

313
00:12:47,019 --> 00:12:51,759
mitigating threats and it kind of it's

314
00:12:49,539 --> 00:12:54,009
very similar to dealing with risk and

315
00:12:51,759 --> 00:12:55,839
you can mitigate the threat by adding in

316
00:12:54,009 --> 00:12:57,220
a control some way of you know to reduce

317
00:12:55,839 --> 00:12:59,350
the potential of that threat being

318
00:12:57,220 --> 00:13:01,329
exploited you can eliminate the threat

319
00:12:59,350 --> 00:13:02,739
which usually means you're getting rid

320
00:13:01,329 --> 00:13:05,799
of that feature you getting rid of that

321
00:13:02,739 --> 00:13:07,600
system sometimes program folks will come

322
00:13:05,799 --> 00:13:09,180
up to you and say we really need to have

323
00:13:07,600 --> 00:13:11,560
this system in order to track this

324
00:13:09,180 --> 00:13:14,290
and then they just want to be able to

325
00:13:11,560 --> 00:13:15,819
put it into a Microsoft Access file put

326
00:13:14,290 --> 00:13:17,819
it on the network share and think that

327
00:13:15,820 --> 00:13:20,770
it's gonna be safe or even better

328
00:13:17,820 --> 00:13:23,680
someone in the office admin assistant

329
00:13:20,770 --> 00:13:25,660
knows how to build access forms and they

330
00:13:23,680 --> 00:13:27,069
lock it down with a password but they

331
00:13:25,660 --> 00:13:29,170
keep forgetting that you just hold on

332
00:13:27,070 --> 00:13:32,170
the shift key open up the Access file

333
00:13:29,170 --> 00:13:36,430
and bypass everything so a little the

334
00:13:32,170 --> 00:13:37,900
risk is there so sometimes the better

335
00:13:36,430 --> 00:13:40,089
bet is to either get rid of that

336
00:13:37,900 --> 00:13:42,310
particular data store and say maybe

337
00:13:40,090 --> 00:13:44,620
there's a better way or be able to

338
00:13:42,310 --> 00:13:46,319
transfer it over like the next one where

339
00:13:44,620 --> 00:13:48,760
you shift it over to another system or

340
00:13:46,320 --> 00:13:51,520
you had extra insurance in order to be

341
00:13:48,760 --> 00:13:53,710
able to deal with the risk or you deal

342
00:13:51,520 --> 00:13:55,120
with a third party tool trying to

343
00:13:53,710 --> 00:13:56,950
transfer that particular threat over

344
00:13:55,120 --> 00:13:59,260
somewhere else and then there's always

345
00:13:56,950 --> 00:14:01,110
accepting the risk and accepting the

346
00:13:59,260 --> 00:14:05,560
risk could be very dangerous

347
00:14:01,110 --> 00:14:08,440
folks are usually quicker to accept the

348
00:14:05,560 --> 00:14:10,270
risk of assist a threat or of a bad

349
00:14:08,440 --> 00:14:11,620
system than they are to actually address

350
00:14:10,270 --> 00:14:13,720
it because I think it's going to take

351
00:14:11,620 --> 00:14:16,320
more time more energy a lot more

352
00:14:13,720 --> 00:14:20,200
fighting just to do it right and so

353
00:14:16,320 --> 00:14:23,110
managers usually will just blindly

354
00:14:20,200 --> 00:14:24,820
accept the trick there is to make sure

355
00:14:23,110 --> 00:14:26,560
you document it make sure they

356
00:14:24,820 --> 00:14:27,970
understand what the risk is and make

357
00:14:26,560 --> 00:14:30,339
sure that they understand what could

358
00:14:27,970 --> 00:14:31,480
happen if it goes wrong and even better

359
00:14:30,340 --> 00:14:34,090
is when you could get the development

360
00:14:31,480 --> 00:14:35,740
team to come back later and note out how

361
00:14:34,090 --> 00:14:38,440
they would fix it if they were told to

362
00:14:35,740 --> 00:14:41,980
go fix it in event of a breach or some

363
00:14:38,440 --> 00:14:44,400
sort of incident but another kind of

364
00:14:41,980 --> 00:14:46,690
thing I picked up in one of my studies

365
00:14:44,400 --> 00:14:49,000
sometimes worry is a sign that the risk

366
00:14:46,690 --> 00:14:51,910
hasn't been fully accepted or that risk

367
00:14:49,000 --> 00:14:53,950
acceptance was inappropriate so you

368
00:14:51,910 --> 00:14:55,089
start going down the path they've

369
00:14:53,950 --> 00:14:57,700
already said we're going to accept the

370
00:14:55,090 --> 00:14:59,710
risk and then now the manager is a

371
00:14:57,700 --> 00:15:02,200
little worried about it or the dev team

372
00:14:59,710 --> 00:15:03,940
manager or someone else release manager

373
00:15:02,200 --> 00:15:07,630
and they start to question whether or

374
00:15:03,940 --> 00:15:09,430
not that risk is worth it you should

375
00:15:07,630 --> 00:15:11,200
probably try to circle back around and

376
00:15:09,430 --> 00:15:13,060
reevaluate to see if there should be

377
00:15:11,200 --> 00:15:14,320
some other control in place or what you

378
00:15:13,060 --> 00:15:18,640
could do in order to bill to reduce that

379
00:15:14,320 --> 00:15:21,310
risk so if you decide to go ahead and

380
00:15:18,640 --> 00:15:22,130
mitigate there's two main ways and stuff

381
00:15:21,310 --> 00:15:25,729
that

382
00:15:22,130 --> 00:15:27,320
you can mitigate a threat design the

383
00:15:25,730 --> 00:15:30,020
security control that will protect it

384
00:15:27,320 --> 00:15:32,990
and that's where you go through the

385
00:15:30,020 --> 00:15:35,240
different common mitigations like sequel

386
00:15:32,990 --> 00:15:38,090
injection threats sequel injection

387
00:15:35,240 --> 00:15:41,440
threat you use parameters queries your

388
00:15:38,090 --> 00:15:44,030
threats gone you make sure you could use

389
00:15:41,440 --> 00:15:45,710
third-party tools like candy the NAD

390
00:15:44,030 --> 00:15:49,010
framework which does parameterize

391
00:15:45,710 --> 00:15:51,350
queries behind the scenes you can in

392
00:15:49,010 --> 00:15:53,750
some cases when you're doing more

393
00:15:51,350 --> 00:15:57,230
dynamic script incorporates something

394
00:15:53,750 --> 00:15:59,540
like sanitization and also input

395
00:15:57,230 --> 00:16:00,860
validation but the best bet is to use

396
00:15:59,540 --> 00:16:02,390
like parameters queries and you put it

397
00:16:00,860 --> 00:16:07,120
in that control of using parameters

398
00:16:02,390 --> 00:16:09,680
queries that threat goes away identify

399
00:16:07,120 --> 00:16:11,840
that we are then accepting the risk and

400
00:16:09,680 --> 00:16:14,180
this is the second option and this one I

401
00:16:11,840 --> 00:16:16,400
also kind of note it's really good to

402
00:16:14,180 --> 00:16:19,790
document it and also what you would do

403
00:16:16,400 --> 00:16:22,010
if it was exploited because that having

404
00:16:19,790 --> 00:16:23,360
that list there it helps you reduce the

405
00:16:22,010 --> 00:16:25,460
time after you've identified that

406
00:16:23,360 --> 00:16:27,140
there's been an incident before you

407
00:16:25,460 --> 00:16:32,390
could have a fix in place or a hotfix in

408
00:16:27,140 --> 00:16:33,319
place another good thing when you're

409
00:16:32,390 --> 00:16:36,140
going through a threat modeling with a

410
00:16:33,320 --> 00:16:37,550
team is to sit down with them and say

411
00:16:36,140 --> 00:16:39,260
what are some of the common ones that we

412
00:16:37,550 --> 00:16:41,510
have and as you start going through the

413
00:16:39,260 --> 00:16:44,390
threat models start making a list of the

414
00:16:41,510 --> 00:16:46,090
different threats and how you would how

415
00:16:44,390 --> 00:16:48,890
you mitigated in that particular project

416
00:16:46,090 --> 00:16:50,300
this list eventually builds up into a

417
00:16:48,890 --> 00:16:52,790
nice library a reference library you

418
00:16:50,300 --> 00:16:54,469
could refer back to how do we fix it in

419
00:16:52,790 --> 00:16:56,750
the other project what do we do last

420
00:16:54,470 --> 00:16:59,240
project or last year and you can start

421
00:16:56,750 --> 00:17:01,220
seeing okay we saw this again how do we

422
00:16:59,240 --> 00:17:03,380
fix it before this is a real quick easy

423
00:17:01,220 --> 00:17:05,150
way or how can we make it better and

424
00:17:03,380 --> 00:17:07,609
circle back and fix the application from

425
00:17:05,150 --> 00:17:09,890
last year and so you get a chance to nor

426
00:17:07,609 --> 00:17:11,659
to uses reference library but it also

427
00:17:09,890 --> 00:17:13,550
builds up the team because as you go

428
00:17:11,660 --> 00:17:15,829
through it more often they have a point

429
00:17:13,550 --> 00:17:18,619
of reference they can study up on it we

430
00:17:15,829 --> 00:17:20,688
have lessons learned and then another

431
00:17:18,619 --> 00:17:23,000
good thing to do is look out at the

432
00:17:20,689 --> 00:17:25,040
different articles and blogs and

433
00:17:23,000 --> 00:17:27,199
different feeds that come in talk about

434
00:17:25,040 --> 00:17:28,940
security related issues because that

435
00:17:27,199 --> 00:17:31,790
Brent builds an awareness with your dev

436
00:17:28,940 --> 00:17:33,350
team a security team as well being able

437
00:17:31,790 --> 00:17:34,610
to know what's out there what kind of

438
00:17:33,350 --> 00:17:35,719
events are happening

439
00:17:34,610 --> 00:17:37,549
what kind of threats are on the horizon

440
00:17:35,720 --> 00:17:40,490
what are folks finding what the new

441
00:17:37,549 --> 00:17:43,429
technology is coming out and when it

442
00:17:40,490 --> 00:17:45,290
does is it helps build that team up with

443
00:17:43,429 --> 00:17:47,030
their understanding and the better the

444
00:17:45,290 --> 00:17:48,500
understanding the more they collaborate

445
00:17:47,030 --> 00:17:49,549
when they come across a particular

446
00:17:48,500 --> 00:17:54,200
threat in the system that they have

447
00:17:49,549 --> 00:17:56,330
dealt with before so an iterative

448
00:17:54,200 --> 00:17:59,150
approach so just when you think it's

449
00:17:56,330 --> 00:18:03,260
over you get to go through it again and

450
00:17:59,150 --> 00:18:05,540
my organization a lot of the developers

451
00:18:03,260 --> 00:18:07,490
they'll build the threat model and then

452
00:18:05,540 --> 00:18:08,960
they walk away from it and they go build

453
00:18:07,490 --> 00:18:11,059
something else that doesn't exactly

454
00:18:08,960 --> 00:18:13,309
follow the threat model that's a very

455
00:18:11,059 --> 00:18:15,200
bad approach so I'm constantly trying to

456
00:18:13,309 --> 00:18:17,899
get them back in the room when things

457
00:18:15,200 --> 00:18:19,910
are changing to reevaluate how they have

458
00:18:17,900 --> 00:18:21,830
addressed that threat what the system

459
00:18:19,910 --> 00:18:23,929
looks like maybe you even recreate the

460
00:18:21,830 --> 00:18:25,580
threat model after the fact in order to

461
00:18:23,929 --> 00:18:27,919
make sure it's more accurate and then

462
00:18:25,580 --> 00:18:29,780
help identify if there any of there any

463
00:18:27,919 --> 00:18:33,470
threats that we did not mitigate or we

464
00:18:29,780 --> 00:18:34,250
didn't know we're there and so practice

465
00:18:33,470 --> 00:18:37,010
makes perfect

466
00:18:34,250 --> 00:18:38,240
and it really pays off and so as you get

467
00:18:37,010 --> 00:18:40,280
a chance to go through a few it also

468
00:18:38,240 --> 00:18:42,020
builds up more confidence with your dev

469
00:18:40,280 --> 00:18:43,820
team because they've gone through it a

470
00:18:42,020 --> 00:18:45,440
few times they're more familiar with it

471
00:18:43,820 --> 00:18:49,879
they get faster going through the

472
00:18:45,440 --> 00:18:53,210
threats and this is a diagram I pulled

473
00:18:49,880 --> 00:18:54,770
for more of an agile process but the

474
00:18:53,210 --> 00:18:56,809
idea is that you have that requirement

475
00:18:54,770 --> 00:18:58,820
that vision that you want to build comes

476
00:18:56,809 --> 00:19:00,980
in you model it create the conceptual

477
00:18:58,820 --> 00:19:02,870
diagram you go ahead and you figure I

478
00:19:00,980 --> 00:19:04,370
didn't identify the threats you figure

479
00:19:02,870 --> 00:19:06,080
out the controls you're going to put in

480
00:19:04,370 --> 00:19:08,629
and that's where you enumerate through

481
00:19:06,080 --> 00:19:11,418
the threats and then you go ahead and

482
00:19:08,630 --> 00:19:13,490
you build out your mitigations and then

483
00:19:11,419 --> 00:19:14,690
you do a validation step and you could

484
00:19:13,490 --> 00:19:17,450
use different tools for the validation

485
00:19:14,690 --> 00:19:20,510
step like static code analysis peer

486
00:19:17,450 --> 00:19:21,830
review so really good you also have the

487
00:19:20,510 --> 00:19:24,140
Chancellor to pull the security team if

488
00:19:21,830 --> 00:19:26,570
you have one in order to take a look at

489
00:19:24,140 --> 00:19:29,390
the code at the system helping them with

490
00:19:26,570 --> 00:19:32,090
the validation Quality Assurance testers

491
00:19:29,390 --> 00:19:33,500
are really good allies to have when

492
00:19:32,090 --> 00:19:35,510
you're dealing with the validation step

493
00:19:33,500 --> 00:19:37,340
two because they could find functional

494
00:19:35,510 --> 00:19:39,200
bugs that would also resolve in a

495
00:19:37,340 --> 00:19:44,120
security bug because if it's not working

496
00:19:39,200 --> 00:19:45,950
right maybe it could be exploited and so

497
00:19:44,120 --> 00:19:48,290
some essential questions that we want to

498
00:19:45,950 --> 00:19:48,540
ask while we're going through the threat

499
00:19:48,290 --> 00:19:51,750
mam

500
00:19:48,540 --> 00:19:52,260
process what are you building what does

501
00:19:51,750 --> 00:19:55,520
it look like

502
00:19:52,260 --> 00:19:57,870
what is it using what kind of platforms

503
00:19:55,520 --> 00:19:59,730
what could go wrong with it once it's

504
00:19:57,870 --> 00:20:01,469
built how are we going to deploy it out

505
00:19:59,730 --> 00:20:04,170
to the wallet and just let it go or do

506
00:20:01,470 --> 00:20:06,450
we have a plan to maintain it what do

507
00:20:04,170 --> 00:20:09,780
you do about those things that can go

508
00:20:06,450 --> 00:20:13,080
wrong so if you know that there's gonna

509
00:20:09,780 --> 00:20:14,790
be the potential that your internal

510
00:20:13,080 --> 00:20:16,649
server that's underneath someone's desk

511
00:20:14,790 --> 00:20:18,420
could go down maybe you should move it

512
00:20:16,650 --> 00:20:20,730
to one of the servers in the data center

513
00:20:18,420 --> 00:20:24,930
or go to the cloud which is a fun

514
00:20:20,730 --> 00:20:26,640
buzzword and then you go ahead and ask

515
00:20:24,930 --> 00:20:28,800
the question of did we do a decent job

516
00:20:26,640 --> 00:20:29,970
of the analysis when we're going through

517
00:20:28,800 --> 00:20:34,070
this threat modeling process have that

518
00:20:29,970 --> 00:20:37,740
retro Frank retrospection of how it went

519
00:20:34,070 --> 00:20:39,360
how do we communicate as a team how did

520
00:20:37,740 --> 00:20:41,940
we address the issues where the want

521
00:20:39,360 --> 00:20:44,129
areas that we need to improve in do we

522
00:20:41,940 --> 00:20:45,990
need better models do we need to do a

523
00:20:44,130 --> 00:20:48,210
better job of working together across

524
00:20:45,990 --> 00:20:49,710
the different teams I can get a chance

525
00:20:48,210 --> 00:20:54,690
to figure out how to make it smoother

526
00:20:49,710 --> 00:20:56,760
quicker and easier when we're going

527
00:20:54,690 --> 00:20:58,800
through that I kind of explained the

528
00:20:56,760 --> 00:21:01,290
more of a manual process of doing the

529
00:20:58,800 --> 00:21:02,909
diagramming Microsoft I mentioned

530
00:21:01,290 --> 00:21:05,280
earlier and a few other companies have

531
00:21:02,910 --> 00:21:06,840
some tools that make it a lot easier so

532
00:21:05,280 --> 00:21:08,490
that you could just do the diagramming

533
00:21:06,840 --> 00:21:10,199
and then it helps you with identifying

534
00:21:08,490 --> 00:21:12,750
the threats and then also documenting

535
00:21:10,200 --> 00:21:15,240
how you're mitigating the Microsoft

536
00:21:12,750 --> 00:21:18,900
threat modeling tool 2016 which they

537
00:21:15,240 --> 00:21:20,910
also now have a prototype a preview for

538
00:21:18,900 --> 00:21:22,830
their Azure version of a threat modeling

539
00:21:20,910 --> 00:21:27,210
tool to help out when you're doing Azure

540
00:21:22,830 --> 00:21:29,159
type systems this one is free and it it

541
00:21:27,210 --> 00:21:31,650
works a lot like a Visio stencils you

542
00:21:29,160 --> 00:21:33,540
just do the drawing of the year system

543
00:21:31,650 --> 00:21:35,370
and then it determines the threats for

544
00:21:33,540 --> 00:21:37,340
you and you just go down and you show

545
00:21:35,370 --> 00:21:39,300
how you're going to address those

546
00:21:37,340 --> 00:21:42,209
there's another one called threat

547
00:21:39,300 --> 00:21:44,510
modeler threat modeler has a cost to it

548
00:21:42,210 --> 00:21:46,920
but they have three different editions

549
00:21:44,510 --> 00:21:48,150
to use you have standard Edition where

550
00:21:46,920 --> 00:21:50,490
you get a chance to draw everything out

551
00:21:48,150 --> 00:21:53,280
more of a single use on a single machine

552
00:21:50,490 --> 00:21:55,950
license you have a dev ops Edition which

553
00:21:53,280 --> 00:21:57,389
is supposed to help with the devs get a

554
00:21:55,950 --> 00:21:59,160
chance to connect they do their role

555
00:21:57,390 --> 00:22:00,570
security folks connect and do their role

556
00:21:59,160 --> 00:22:01,540
and you get a chance to kind of track it

557
00:22:00,570 --> 00:22:04,419
through your lifecycle

558
00:22:01,540 --> 00:22:07,240
and then the Enterprise Edition is for

559
00:22:04,420 --> 00:22:09,400
more of the distributed keeping track of

560
00:22:07,240 --> 00:22:12,790
multiple systems multiple different

561
00:22:09,400 --> 00:22:14,530
projects and then some other possible

562
00:22:12,790 --> 00:22:19,720
threat modeling tools that you can look

563
00:22:14,530 --> 00:22:21,910
up the secure CAD iris risk which some

564
00:22:19,720 --> 00:22:23,080
folks say is really I haven't got a

565
00:22:21,910 --> 00:22:26,560
chance to dive into but I've heard good

566
00:22:23,080 --> 00:22:33,659
things about SD elements biosecurity

567
00:22:26,560 --> 00:22:38,409
compass so that was the application side

568
00:22:33,660 --> 00:22:39,490
I also want to note on the website for

569
00:22:38,410 --> 00:22:42,490
tour camp I also have two other

570
00:22:39,490 --> 00:22:44,470
resources a guide that talks about the

571
00:22:42,490 --> 00:22:45,940
different types of threats for the

572
00:22:44,470 --> 00:22:48,130
stride threats and then a list of their

573
00:22:45,940 --> 00:22:49,210
mitigations the common ones she uses a

574
00:22:48,130 --> 00:22:51,670
guide in order to help with the

575
00:22:49,210 --> 00:22:53,590
conversation and then also I have a

576
00:22:51,670 --> 00:22:54,820
networking resource guide in order to

577
00:22:53,590 --> 00:22:57,189
help with some of the questions that you

578
00:22:54,820 --> 00:22:58,570
want to ask to that so it kind of shift

579
00:22:57,190 --> 00:23:01,180
gears a little bit from the application

580
00:22:58,570 --> 00:23:03,189
side and you're going to see my novice

581
00:23:01,180 --> 00:23:08,550
work on the network threat modeling side

582
00:23:03,190 --> 00:23:11,860
so a lot of research into trying to find

583
00:23:08,550 --> 00:23:16,780
someone else's work because plagiarism

584
00:23:11,860 --> 00:23:18,270
is cool and so I found a really good

585
00:23:16,780 --> 00:23:20,770
presentation that talked about

586
00:23:18,270 --> 00:23:23,050
documenting segmenting and then

587
00:23:20,770 --> 00:23:24,550
restricting is the kind of the road map

588
00:23:23,050 --> 00:23:27,730
for how do you address network threat

589
00:23:24,550 --> 00:23:29,560
modeling the concept is keeping your

590
00:23:27,730 --> 00:23:31,690
documentation up-to-date on your network

591
00:23:29,560 --> 00:23:33,310
map how the systems are configured so

592
00:23:31,690 --> 00:23:34,840
you can use it as a reference guide in

593
00:23:33,310 --> 00:23:36,520
order to make sure that things are right

594
00:23:34,840 --> 00:23:39,959
because that helps with the validation

595
00:23:36,520 --> 00:23:42,129
step when you can circle back later a

596
00:23:39,960 --> 00:23:44,590
segmentation in order to be able to make

597
00:23:42,130 --> 00:23:46,480
it so that it's not one big flat network

598
00:23:44,590 --> 00:23:48,699
that everyone can't talk to everyone

599
00:23:46,480 --> 00:23:51,340
unless you have other controls in place

600
00:23:48,700 --> 00:23:52,630
like the certificates and there's some

601
00:23:51,340 --> 00:23:53,919
new stuff that's going on now where you

602
00:23:52,630 --> 00:23:56,080
don't even have to worry about firewalls

603
00:23:53,920 --> 00:23:58,330
and I don't know I saw some stuff at the

604
00:23:56,080 --> 00:24:01,210
RSA conference that was pretty out there

605
00:23:58,330 --> 00:24:02,500
but with the segmentation you don't want

606
00:24:01,210 --> 00:24:04,540
to be able to have something that has

607
00:24:02,500 --> 00:24:06,760
like confidential systems or if you have

608
00:24:04,540 --> 00:24:08,590
secret or top secret type stuff being

609
00:24:06,760 --> 00:24:11,230
able to be on the same network with all

610
00:24:08,590 --> 00:24:12,699
the public information you want to be

611
00:24:11,230 --> 00:24:14,440
able to separate those out so that

612
00:24:12,700 --> 00:24:16,330
someone who gains access to the public

613
00:24:14,440 --> 00:24:19,539
systems can necessarily gain access to

614
00:24:16,330 --> 00:24:21,460
your more sensitive networks and then

615
00:24:19,539 --> 00:24:22,750
restrict and said I've gone with the

616
00:24:21,460 --> 00:24:24,159
defaults for your routers and switches

617
00:24:22,750 --> 00:24:25,960
and so I've gone with the defaults for

618
00:24:24,159 --> 00:24:27,700
your servers be able to configure and

619
00:24:25,960 --> 00:24:29,559
lock them down so that folks only have

620
00:24:27,700 --> 00:24:31,779
access to what theirs they D to to get

621
00:24:29,559 --> 00:24:32,559
the job done and only to the areas and

622
00:24:31,779 --> 00:24:36,009
stuff that they're supposed to be able

623
00:24:32,559 --> 00:24:38,408
to get access to some additional

624
00:24:36,009 --> 00:24:39,850
considerations so how many different

625
00:24:38,409 --> 00:24:41,409
devices are you talking about a home

626
00:24:39,850 --> 00:24:43,928
network or you're talking about an

627
00:24:41,409 --> 00:24:46,570
enterprise with 19,000 plus employees

628
00:24:43,929 --> 00:24:48,549
with different servers and devices

629
00:24:46,570 --> 00:24:50,168
across the whole how many different

630
00:24:48,549 --> 00:24:52,330
versions the firmware you havin to deal

631
00:24:50,169 --> 00:24:53,620
with if you have five different router

632
00:24:52,330 --> 00:24:56,740
types but they're all dispersed across

633
00:24:53,620 --> 00:24:58,209
and they all have different firmware is

634
00:24:56,740 --> 00:25:01,450
there maybe a chance there in order to

635
00:24:58,210 --> 00:25:03,639
get them all on the same firmware are

636
00:25:01,450 --> 00:25:07,799
using the recommended versions in some

637
00:25:03,639 --> 00:25:11,799
cases folks in different organizations

638
00:25:07,799 --> 00:25:13,600
personal experience forgot to get the

639
00:25:11,799 --> 00:25:16,120
routers up to date on the latest

640
00:25:13,600 --> 00:25:18,250
firmware and so a couple years goes by

641
00:25:16,120 --> 00:25:19,508
and you find this and it's a firestorm

642
00:25:18,250 --> 00:25:21,639
in or to go through and try to get

643
00:25:19,509 --> 00:25:23,980
everyone up to speed get it all the

644
00:25:21,639 --> 00:25:25,508
phone we're at the right level and then

645
00:25:23,980 --> 00:25:27,549
do you have a good change management

646
00:25:25,509 --> 00:25:29,159
process in place you know to keep track

647
00:25:27,549 --> 00:25:32,200
of the different versions the changes

648
00:25:29,159 --> 00:25:35,019
where they're at and then also you don't

649
00:25:32,200 --> 00:25:36,190
want any hidden surprises so one day all

650
00:25:35,019 --> 00:25:38,200
of a sudden everything is available

651
00:25:36,190 --> 00:25:40,240
through showdown and you're scrambling

652
00:25:38,200 --> 00:25:41,830
to figure out why and there's been no

653
00:25:40,240 --> 00:25:44,649
changes at least nothing in your logs

654
00:25:41,830 --> 00:25:46,750
and then all of a sudden you call the

655
00:25:44,649 --> 00:25:48,070
one the group that works on it and we're

656
00:25:46,750 --> 00:25:50,019
actually there now off the internet

657
00:25:48,070 --> 00:25:53,320
again so it's kind of weird when that

658
00:25:50,019 --> 00:25:56,049
happens magically without any logs or

659
00:25:53,320 --> 00:25:57,610
any change or any record that they made

660
00:25:56,049 --> 00:26:00,668
any changes in the network or firewalls

661
00:25:57,610 --> 00:26:02,019
and so it's kind of scary because you

662
00:26:00,669 --> 00:26:07,720
never know when something might just pop

663
00:26:02,019 --> 00:26:09,940
up another option I've seen some

664
00:26:07,720 --> 00:26:13,539
examples where the folks have taken a

665
00:26:09,940 --> 00:26:15,340
network diagram for their network threat

666
00:26:13,539 --> 00:26:16,779
modeling and they just converted it over

667
00:26:15,340 --> 00:26:18,820
to a data flow diagram and then you use

668
00:26:16,779 --> 00:26:20,409
the existing tools of that in place but

669
00:26:18,820 --> 00:26:21,110
they use it more with the strides in the

670
00:26:20,409 --> 00:26:23,510
dread

671
00:26:21,110 --> 00:26:25,850
and some folks say that that is

672
00:26:23,510 --> 00:26:28,610
challenging because application

673
00:26:25,850 --> 00:26:48,740
processes aren't exactly the same is the

674
00:26:28,610 --> 00:26:50,179
network so so questions good please very

675
00:26:48,740 --> 00:26:52,640
good question the question was how long

676
00:26:50,180 --> 00:26:54,830
how much time do a developer spend when

677
00:26:52,640 --> 00:26:57,500
they're on threat modeling when they're

678
00:26:54,830 --> 00:27:01,879
building to a feature and depends on how

679
00:26:57,500 --> 00:27:03,470
hostile they are some groups haven't

680
00:27:01,880 --> 00:27:05,300
done or haven't been forced to do a lot

681
00:27:03,470 --> 00:27:07,430
of threat modeling before and so they'll

682
00:27:05,300 --> 00:27:09,010
drag their feet and they'll make it seem

683
00:27:07,430 --> 00:27:11,030
like it's the worst idea in the world

684
00:27:09,010 --> 00:27:12,110
just to convince management that they

685
00:27:11,030 --> 00:27:16,450
shouldn't do threat modeling in the

686
00:27:12,110 --> 00:27:18,500
first place it does happen but I've have

687
00:27:16,450 --> 00:27:20,060
worked with multiple teams now stuff

688
00:27:18,500 --> 00:27:21,380
where we could get a new threat model

689
00:27:20,060 --> 00:27:23,600
knocked out in about an hour

690
00:27:21,380 --> 00:27:26,300
and sitting down and just get a room

691
00:27:23,600 --> 00:27:27,860
together make it a team sport pull in

692
00:27:26,300 --> 00:27:29,600
the folks that are working like the BA

693
00:27:27,860 --> 00:27:31,399
so they can answer some questions

694
00:27:29,600 --> 00:27:33,379
pull in if you're dealing with like

695
00:27:31,400 --> 00:27:35,510
databases operations stuff the servers

696
00:27:33,380 --> 00:27:37,790
configurations pull the operations folks

697
00:27:35,510 --> 00:27:39,650
into the room sit down and you just

698
00:27:37,790 --> 00:27:40,340
spend that hour going through and knock

699
00:27:39,650 --> 00:27:42,290
out the threats

700
00:27:40,340 --> 00:27:45,550
make sure it's diagrammed accurately and

701
00:27:42,290 --> 00:27:45,550
then run with it

702
00:27:50,520 --> 00:27:57,600
and he'll make him own that very good

703
00:28:04,590 --> 00:28:09,939
there are the question was between

704
00:28:08,260 --> 00:28:12,790
application diagrams and network

705
00:28:09,940 --> 00:28:15,430
diagrams the difference is is that right

706
00:28:12,790 --> 00:28:16,960
yeah so with the application diagram

707
00:28:15,430 --> 00:28:18,610
you're permanently are focusing on the

708
00:28:16,960 --> 00:28:22,840
data where is it going in the system

709
00:28:18,610 --> 00:28:24,550
with the network you're looking at the

710
00:28:22,840 --> 00:28:27,010
different IP ranges your different

711
00:28:24,550 --> 00:28:28,389
firewall rules where things get diverse

712
00:28:27,010 --> 00:28:30,520
back and forth what kind of traffic

713
00:28:28,390 --> 00:28:34,240
you're looking at do you have quality of

714
00:28:30,520 --> 00:28:37,480
service configured so maybe streaming a

715
00:28:34,240 --> 00:28:40,630
video goes different than someone trying

716
00:28:37,480 --> 00:28:43,180
to send an email but usually what you

717
00:28:40,630 --> 00:28:46,390
end up with is there's the logical

718
00:28:43,180 --> 00:28:48,070
network diagrams or you could show the

719
00:28:46,390 --> 00:28:50,020
IP address has gone from one router to a

720
00:28:48,070 --> 00:28:52,780
switch or traversing the whole network

721
00:28:50,020 --> 00:28:54,940
and then you also have some folks that

722
00:28:52,780 --> 00:28:57,430
will do their whiteboard network

723
00:28:54,940 --> 00:29:00,310
diagrams which look like clouds with

724
00:28:57,430 --> 00:29:02,950
lines and some little brick walls and so

725
00:29:00,310 --> 00:29:04,929
it kind of varies there on the network

726
00:29:02,950 --> 00:29:05,860
side but usually what you want to do is

727
00:29:04,930 --> 00:29:08,080
you want to have something that's

728
00:29:05,860 --> 00:29:09,459
accurate so make sure that they validate

729
00:29:08,080 --> 00:29:10,810
the diagram and then you just sit down

730
00:29:09,460 --> 00:29:13,390
and say okay do we have the right

731
00:29:10,810 --> 00:29:14,740
versions of the firmware do we have a

732
00:29:13,390 --> 00:29:16,540
lock down properly do we have the right

733
00:29:14,740 --> 00:29:17,770
firewall rules in place have we worked

734
00:29:16,540 --> 00:29:19,000
with the firewall team and our to make

735
00:29:17,770 --> 00:29:22,810
sure that the configurations are there

736
00:29:19,000 --> 00:29:28,980
or is it set to any any which some folks

737
00:29:22,810 --> 00:29:28,980
still do but yeah you remember

738
00:29:34,090 --> 00:29:39,649
the question was about how we see the

739
00:29:38,180 --> 00:29:43,010
threat modeling impacting the cyber

740
00:29:39,650 --> 00:29:44,510
insurance world and the cyber insurance

741
00:29:43,010 --> 00:29:46,250
world is dealing more with the risk

742
00:29:44,510 --> 00:29:48,110
management than the threat management of

743
00:29:46,250 --> 00:29:51,050
the applications but it still comes into

744
00:29:48,110 --> 00:29:52,850
play because some folks will say that

745
00:29:51,050 --> 00:29:54,190
they'll just go ahead and pay a little

746
00:29:52,850 --> 00:29:58,280
bit more for the insurance or

747
00:29:54,190 --> 00:30:02,540
third-party through an SLA will insist

748
00:29:58,280 --> 00:30:04,070
that they have their insurance a high

749
00:30:02,540 --> 00:30:06,320
enough not bill to cover the expenses of

750
00:30:04,070 --> 00:30:07,580
the system or potential damages or how

751
00:30:06,320 --> 00:30:13,909
it would take nor to get it up in them

752
00:30:07,580 --> 00:30:19,210
in a natural natural emergency or some

753
00:30:13,910 --> 00:30:19,210
sort of attack yeah please

754
00:30:41,160 --> 00:30:47,429
the first part again real quick Auto

755
00:30:45,120 --> 00:30:49,110
compliance of so kind of breaking that

756
00:30:47,429 --> 00:31:03,559
so the difference I think the question

757
00:30:49,110 --> 00:31:03,559
was right

758
00:31:14,970 --> 00:31:19,220
so kind of the different what I

759
00:31:16,950 --> 00:31:23,759
understand and correct me if I'm wrong

760
00:31:19,220 --> 00:31:25,529
yeah so when you're dealing with how

761
00:31:23,759 --> 00:31:27,210
much time do you put towards auditing

762
00:31:25,529 --> 00:31:28,950
and compliance how much time did you put

763
00:31:27,210 --> 00:31:30,330
towards training and best practices how

764
00:31:28,950 --> 00:31:32,340
much time do you put towards doing a

765
00:31:30,330 --> 00:31:43,228
threat modeling is that kind of a

766
00:31:32,340 --> 00:31:44,189
summary good so when you're dealing

767
00:31:43,229 --> 00:31:45,599
having those learning opportunities

768
00:31:44,190 --> 00:31:47,249
where you're saying that we're just not

769
00:31:45,599 --> 00:31:48,899
making you do this because we hate you

770
00:31:47,249 --> 00:31:52,229
we're doing this because we love you and

771
00:31:48,899 --> 00:31:56,668
we want you to grow which threat

772
00:31:52,229 --> 00:31:58,009
modeling sometimes gets that way so most

773
00:31:56,669 --> 00:32:00,239
of the time making sure to reiterate

774
00:31:58,009 --> 00:32:02,700
making sure to be open when they are

775
00:32:00,239 --> 00:32:04,859
hostile so you go into a dev team and

776
00:32:02,700 --> 00:32:06,330
their first thing you want to let them

777
00:32:04,859 --> 00:32:08,369
know when you're the first time they

778
00:32:06,330 --> 00:32:10,379
have to go through a threat model is say

779
00:32:08,369 --> 00:32:12,658
that you're here to help you here in

780
00:32:10,379 --> 00:32:16,439
order to make it easier that is gonna be

781
00:32:12,659 --> 00:32:19,559
a team sport but then you want to make

782
00:32:16,440 --> 00:32:21,809
sure and stuff that kind of try to carry

783
00:32:19,559 --> 00:32:24,149
them at the beginning go to extra mile

784
00:32:21,809 --> 00:32:26,369
be there for questions be there for

785
00:32:24,149 --> 00:32:27,599
walking them through it but then also be

786
00:32:26,369 --> 00:32:29,249
able to point them to some good

787
00:32:27,599 --> 00:32:31,099
resources they can find on their own so

788
00:32:29,249 --> 00:32:34,409
the best practice is in training site

789
00:32:31,099 --> 00:32:37,379
and then at the same time being able to

790
00:32:34,409 --> 00:32:39,059
just actually tell them you're gonna be

791
00:32:37,379 --> 00:32:41,248
audited later at some point you're going

792
00:32:39,059 --> 00:32:42,749
to be audited and this will help make it

793
00:32:41,249 --> 00:32:45,149
so those are easier so you don't have to

794
00:32:42,749 --> 00:32:46,559
worry about that as much that helps with

795
00:32:45,149 --> 00:32:47,849
the app dev managers too because

796
00:32:46,559 --> 00:32:51,629
epitaphs managers don't like dealing

797
00:32:47,849 --> 00:32:52,710
with audits the downside though when

798
00:32:51,629 --> 00:32:54,959
you're talking about threat modeling

799
00:32:52,710 --> 00:32:57,599
sometimes they don't see the importance

800
00:32:54,960 --> 00:32:59,369
of it sometimes they're hostile towards

801
00:32:57,599 --> 00:33:00,869
it or they're resistant and so again a

802
00:32:59,369 --> 00:33:03,209
chance in order to try to make sure that

803
00:33:00,869 --> 00:33:05,249
their managers are involved and that

804
00:33:03,210 --> 00:33:07,320
they understand that there's a value

805
00:33:05,249 --> 00:33:09,169
added to the team and that's where it

806
00:33:07,320 --> 00:33:11,580
also helps with documenting the systems

807
00:33:09,169 --> 00:33:13,320
because if they create a threat model in

808
00:33:11,580 --> 00:33:15,269
the data flow diagram and you say that

809
00:33:13,320 --> 00:33:18,178
that's good enough for their application

810
00:33:15,269 --> 00:33:19,979
diagram it helps them go wait I don't

811
00:33:18,179 --> 00:33:21,539
have to create more documents I could

812
00:33:19,979 --> 00:33:24,830
just create that and then check it in

813
00:33:21,539 --> 00:33:24,830
with the code and I'm done

814
00:33:38,990 --> 00:33:45,510
that's a very good point so sooner the

815
00:33:42,299 --> 00:33:48,120
development lifecycle to better a good

816
00:33:45,510 --> 00:33:49,860
example we had a privacy office come

817
00:33:48,120 --> 00:33:51,178
down with their own system and so the

818
00:33:49,860 --> 00:33:53,120
developers were scurrying and our to

819
00:33:51,179 --> 00:33:55,799
look good to the privacy officer and

820
00:33:53,120 --> 00:33:57,539
they sat down and they finally listened

821
00:33:55,799 --> 00:33:59,490
to me I'm like do it at the very

822
00:33:57,539 --> 00:34:01,049
beginning before you write up the system

823
00:33:59,490 --> 00:34:03,419
because that far too often they start

824
00:34:01,049 --> 00:34:05,220
coding they'd have something in in QA

825
00:34:03,419 --> 00:34:07,110
they possibly have something in

826
00:34:05,220 --> 00:34:07,950
production and then they go wait a

827
00:34:07,110 --> 00:34:11,190
minute we're supposed to do the threat

828
00:34:07,950 --> 00:34:14,100
model on this weren't we it happens and

829
00:34:11,190 --> 00:34:15,418
so as soon as they know what their kind

830
00:34:14,100 --> 00:34:17,730
of a concept of what they want to build

831
00:34:15,418 --> 00:34:19,830
do the threat model right there at the

832
00:34:17,730 --> 00:34:21,480
very beginning and it's gonna be much

833
00:34:19,830 --> 00:34:23,850
easier on them it's gonna be much easier

834
00:34:21,480 --> 00:34:25,590
on everyone because it's no longer now a

835
00:34:23,850 --> 00:34:27,299
stopgap it's no longer a hurdle that

836
00:34:25,590 --> 00:34:30,060
they have to jump through it's now just

837
00:34:27,300 --> 00:34:31,470
part of its like a guide it helps them

838
00:34:30,060 --> 00:34:32,850
get a better picture of what they're

839
00:34:31,469 --> 00:34:34,918
going to be building how they're gonna

840
00:34:32,850 --> 00:34:36,389
be coding it and so usually they

841
00:34:34,918 --> 00:34:39,179
actually like the threat model at that

842
00:34:36,389 --> 00:34:41,720
stage opposed to being resistant to it

843
00:34:39,179 --> 00:34:41,720
so yeah

844
00:34:55,199 --> 00:35:00,569
the way I explained didn't work you have

845
00:34:58,900 --> 00:35:02,950
your conceptual diagram of your system

846
00:35:00,570 --> 00:35:04,420
and then different features can be added

847
00:35:02,950 --> 00:35:06,730
on without actually changing the

848
00:35:04,420 --> 00:35:08,830
exceptional diagram but if there is a

849
00:35:06,730 --> 00:35:10,240
feature change that does change that's

850
00:35:08,830 --> 00:35:13,060
when you want to circle back and revisit

851
00:35:10,240 --> 00:35:14,589
the threat model during the third model

852
00:35:13,060 --> 00:35:16,570
conversation we don't usually go all the

853
00:35:14,590 --> 00:35:18,790
way down into the weeds usually we're

854
00:35:16,570 --> 00:35:20,290
talking more conceptual a high-level but

855
00:35:18,790 --> 00:35:21,700
by having the data flow diagram they

856
00:35:20,290 --> 00:35:23,800
actually know a little bit better what

857
00:35:21,700 --> 00:35:25,779
their process is going to be like and so

858
00:35:23,800 --> 00:35:28,000
we could talk about them when we're

859
00:35:25,780 --> 00:35:30,550
addressing the high-level stuff so it's

860
00:35:28,000 --> 00:35:32,110
a chance to be more familiar with like

861
00:35:30,550 --> 00:35:33,670
how is that function going to happen how

862
00:35:32,110 --> 00:35:35,410
are we going to authenticate how are we

863
00:35:33,670 --> 00:35:37,210
going to log what events are we going to

864
00:35:35,410 --> 00:35:38,740
log so those things that already been

865
00:35:37,210 --> 00:35:42,040
talked about in the meeting and

866
00:35:38,740 --> 00:35:43,839
alongside in there the developers always

867
00:35:42,040 --> 00:35:47,970
have my phone number so they usually

868
00:35:43,840 --> 00:35:47,970
reach out but that's a good point yeah

869
00:35:49,660 --> 00:35:52,790
[Music]

870
00:35:57,390 --> 00:36:01,509
if you're dealing with an external and I

871
00:35:59,710 --> 00:36:03,160
started the the question was this for

872
00:36:01,510 --> 00:36:04,540
every process do you have to necessarily

873
00:36:03,160 --> 00:36:08,140
have done a thermal or you can go higher

874
00:36:04,540 --> 00:36:09,279
lab if there's an external interactor so

875
00:36:08,140 --> 00:36:10,960
you're dealing with it someone else's

876
00:36:09,280 --> 00:36:12,940
API you want to make sure that's

877
00:36:10,960 --> 00:36:14,800
captured because every time your system

878
00:36:12,940 --> 00:36:17,710
talks to someone else's if you want to

879
00:36:14,800 --> 00:36:20,860
make sure it's on the diagram is a

880
00:36:17,710 --> 00:36:22,840
external entity but when you're dealing

881
00:36:20,860 --> 00:36:25,000
with the system itself you should wait

882
00:36:22,840 --> 00:36:27,580
to tell folks is to aim the beneful

883
00:36:25,000 --> 00:36:29,860
diagram world somewhere between a level

884
00:36:27,580 --> 00:36:33,910
0 and level 1 I keep a high enough level

885
00:36:29,860 --> 00:36:35,800
to where it's not 5,000 threats it's

886
00:36:33,910 --> 00:36:38,470
usually more like a hundred threats that

887
00:36:35,800 --> 00:36:40,420
you have to go through what ends up

888
00:36:38,470 --> 00:36:41,740
happening is you could go all the way

889
00:36:40,420 --> 00:36:43,750
down into the weeds and talk about each

890
00:36:41,740 --> 00:36:45,520
and every function and you could diagram

891
00:36:43,750 --> 00:36:46,690
it and you can put it into like the

892
00:36:45,520 --> 00:36:48,850
third modeling tools or you can sit down

893
00:36:46,690 --> 00:36:52,270
with the matrix and identify all of them

894
00:36:48,850 --> 00:36:54,520
and it becomes bigger than the project

895
00:36:52,270 --> 00:36:57,030
itself and so you end up having to go

896
00:36:54,520 --> 00:36:59,050
through a lot more paperwork lot more

897
00:36:57,030 --> 00:37:00,970
medications and you have to document so

898
00:36:59,050 --> 00:37:02,830
much that the whole team kind of gets

899
00:37:00,970 --> 00:37:05,649
bogged down but by bringing it back up

900
00:37:02,830 --> 00:37:06,420
to like a level zero level one right in

901
00:37:05,650 --> 00:37:08,190
there and enough

902
00:37:06,420 --> 00:37:11,520
no kind of the main functional areas

903
00:37:08,190 --> 00:37:13,559
like this is our web front-end our web

904
00:37:11,520 --> 00:37:14,970
server area we're going to have our web

905
00:37:13,559 --> 00:37:17,790
services here and then we're going to

906
00:37:14,970 --> 00:37:20,129
have our data store in the back and so

907
00:37:17,790 --> 00:37:21,630
you understand how the system flows and

908
00:37:20,130 --> 00:37:23,160
you can talk about how you're going to

909
00:37:21,630 --> 00:37:26,970
deal with authentication with your

910
00:37:23,160 --> 00:37:33,930
authorization with something like you're

911
00:37:26,970 --> 00:37:36,959
logging with also redundancy resilient

912
00:37:33,930 --> 00:37:39,240
systems like load balancing different

913
00:37:36,960 --> 00:37:41,670
ways of handling the potential of denial

914
00:37:39,240 --> 00:37:44,029
service attacks how those configurations

915
00:37:41,670 --> 00:37:44,030
are going to be

916
00:38:09,769 --> 00:38:16,950
yes it's very good point so I'm not as

917
00:38:13,589 --> 00:38:19,078
familiar with the ratings as much but by

918
00:38:16,950 --> 00:38:20,489
having it done you could actually check

919
00:38:19,079 --> 00:38:23,460
that off you could document it you could

920
00:38:20,489 --> 00:38:25,460
show it in an audit or a review and so

921
00:38:23,460 --> 00:38:28,079
that helps when you're dealing with

922
00:38:25,460 --> 00:38:30,599
trying to show like auditors or trying

923
00:38:28,079 --> 00:38:33,420
to get ratings on how secure the systems

924
00:38:30,599 --> 00:38:34,559
are yeah because going through the steps

925
00:38:33,420 --> 00:38:37,619
you know show that you've gone through

926
00:38:34,559 --> 00:38:39,749
those steps and especially when it comes

927
00:38:37,619 --> 00:38:40,829
to an audit but most importantly being

928
00:38:39,749 --> 00:38:42,629
able to talk through that with the

929
00:38:40,829 --> 00:38:44,489
development team be able to work with

930
00:38:42,630 --> 00:38:46,680
them and on how they need to improve

931
00:38:44,489 --> 00:38:50,880
their controls to make the systems more

932
00:38:46,680 --> 00:38:52,558
secure yeah it's a team sport you learn

933
00:38:50,880 --> 00:38:54,150
from the developers just as much as they

934
00:38:52,559 --> 00:38:56,099
learn from you and you get a chance to

935
00:38:54,150 --> 00:39:01,890
figure out how they approach to the

936
00:38:56,099 --> 00:39:04,589
different issues any more questions

937
00:39:01,890 --> 00:39:06,720
so I have some additional resources

938
00:39:04,589 --> 00:39:10,109
again the slide deck is already posted

939
00:39:06,720 --> 00:39:12,480
on the Tor site I have some threat

940
00:39:10,109 --> 00:39:15,210
modeling tool download Microsoft's

941
00:39:12,480 --> 00:39:19,109
secure development lifecycle resources

942
00:39:15,210 --> 00:39:21,210
and then also a book reference this is a

943
00:39:19,109 --> 00:39:23,788
pretty good book on threat modeling that

944
00:39:21,210 --> 00:39:26,240
I found before so thank you very much

945
00:39:23,789 --> 00:39:35,050
for your time and have a good tour can

946
00:39:26,240 --> 00:39:35,049
[Applause]

