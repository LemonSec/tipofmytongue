1
00:00:01,310 --> 00:00:06,359
alright so next up we have both Dave and

2
00:00:04,890 --> 00:00:08,280
Catherine here speaking on avoiding

3
00:00:06,359 --> 00:00:09,990
default passwords and secret breaches

4
00:00:08,280 --> 00:00:18,479
using open source so please welcome

5
00:00:09,990 --> 00:00:21,270
welcome them to the torque on stage all

6
00:00:18,480 --> 00:00:22,529
right thanks so Dave Dietrich the

7
00:00:21,270 --> 00:00:23,038
University of Washington for quite a

8
00:00:22,529 --> 00:00:25,439
while

9
00:00:23,039 --> 00:00:27,689
programmer sis administrator security

10
00:00:25,439 --> 00:00:30,060
operations when simple Nomad was talking

11
00:00:27,689 --> 00:00:31,948
about history in DDoS I was involved in

12
00:00:30,060 --> 00:00:34,649
writing the first five analyses of those

13
00:00:31,949 --> 00:00:36,239
tools and in trying to get thousands of

14
00:00:34,649 --> 00:00:38,850
people on the campus to figure out how

15
00:00:36,239 --> 00:00:40,559
to secure their machines became a big

16
00:00:38,850 --> 00:00:42,180
proponent of Newton's third law of ulnar

17
00:00:40,559 --> 00:00:43,489
ability disclosure which is for every

18
00:00:42,180 --> 00:00:45,360
vulnerability that you disclose

19
00:00:43,489 --> 00:00:48,120
identifying disclose there should be an

20
00:00:45,360 --> 00:00:52,610
equal and opposite mitigation so that's

21
00:00:48,120 --> 00:00:52,610
part of the motivation for the talk here

22
00:00:53,000 --> 00:00:57,210
and I'm Katherine carpenter I'm a

23
00:00:55,469 --> 00:00:58,530
business consultant in information

24
00:00:57,210 --> 00:01:00,809
security and privacy with a background

25
00:00:58,530 --> 00:01:02,640
in healthcare and ethics I'm also the

26
00:01:00,809 --> 00:01:04,679
founder of szura advisors and a licensed

27
00:01:02,640 --> 00:01:06,780
attorney so i have to warn you none of

28
00:01:04,680 --> 00:01:09,689
this is legal advice but your future

29
00:01:06,780 --> 00:01:12,659
lawyers may thank you if you listen to

30
00:01:09,689 --> 00:01:15,600
our ideas Dave and I post first wrote

31
00:01:12,659 --> 00:01:18,479
about the default admin password problem

32
00:01:15,600 --> 00:01:20,520
in 2014 when we discussed the ethics of

33
00:01:18,479 --> 00:01:22,500
the karna botnet and using the data it

34
00:01:20,520 --> 00:01:24,149
produced and we've been working in this

35
00:01:22,500 --> 00:01:25,920
field since then educating and

36
00:01:24,150 --> 00:01:27,990
advocating about ethical information

37
00:01:25,920 --> 00:01:30,329
security research and working to find

38
00:01:27,990 --> 00:01:32,520
ways to better protect information data

39
00:01:30,329 --> 00:01:34,380
and privacy some of the work that went

40
00:01:32,520 --> 00:01:38,329
into this presentation was funded by a

41
00:01:34,380 --> 00:01:38,329
Comcast open source innovation grant

42
00:01:39,140 --> 00:01:46,409
okay the beginning of our presentation

43
00:01:41,880 --> 00:01:51,740
covers topics you're familiar with it's

44
00:01:46,409 --> 00:01:56,000
not oh the slides aren't connected I

45
00:01:51,740 --> 00:01:56,000
thought that would go over automatically

46
00:02:01,280 --> 00:02:06,070
[Music]

47
00:02:03,330 --> 00:02:07,390
the beginning of our of our presentation

48
00:02:06,070 --> 00:02:10,359
covers topics you're already familiar

49
00:02:07,390 --> 00:02:12,460
with and our goal is to get developers

50
00:02:10,360 --> 00:02:16,930
to think differently and and behave

51
00:02:12,460 --> 00:02:18,400
differently when managing to begin our

52
00:02:16,930 --> 00:02:20,080
presentation at the discussion of

53
00:02:18,400 --> 00:02:52,890
secrets and a very fundamental question

54
00:02:20,080 --> 00:02:52,890
what is switchover let me do it directly

55
00:03:05,820 --> 00:03:09,269
is there a switch

56
00:03:11,530 --> 00:03:42,069
I thought it was automatic alright so

57
00:03:40,690 --> 00:03:44,380
we're gonna use Jeff Mitchell's

58
00:03:42,069 --> 00:03:46,089
definition of a secret and that is

59
00:03:44,380 --> 00:03:49,750
something that will elevate your risk if

60
00:03:46,090 --> 00:03:52,120
exposed to unauthorized entities this

61
00:03:49,750 --> 00:03:53,560
kind of information use with networked

62
00:03:52,120 --> 00:03:56,019
computers and applications generally

63
00:03:53,560 --> 00:03:57,760
controls access or identifies a user to

64
00:03:56,019 --> 00:04:00,130
a service and for that reason and

65
00:03:57,760 --> 00:04:03,069
exposed secret is a threat to the user

66
00:04:00,130 --> 00:04:07,390
or the system an identifier czar related

67
00:04:03,069 --> 00:04:09,339
to secrets but they have different

68
00:04:07,390 --> 00:04:13,059
levels of sensitivity and identifiers

69
00:04:09,340 --> 00:04:15,519
like a user name may be exposed without

70
00:04:13,060 --> 00:04:17,228
causing harm in some cases an identifier

71
00:04:15,519 --> 00:04:19,660
must be shared for technology to work

72
00:04:17,228 --> 00:04:21,459
for example DNS text record used by

73
00:04:19,660 --> 00:04:24,610
Deacon protocols to prevent email

74
00:04:21,459 --> 00:04:27,039
spoofing and in all cases a secret that

75
00:04:24,610 --> 00:04:29,380
is exposed causes harm to the user or

76
00:04:27,039 --> 00:04:31,450
the system in open-source software

77
00:04:29,380 --> 00:04:33,039
projects you'll generally need to deal

78
00:04:31,450 --> 00:04:35,500
with the following types of Secrets

79
00:04:33,039 --> 00:04:38,469
passwords either as clear text salted

80
00:04:35,500 --> 00:04:39,970
and hash strings stored on a system that

81
00:04:38,470 --> 00:04:42,720
does the hashing and compares the hashes

82
00:04:39,970 --> 00:04:44,950
bearer tokens long strings of characters

83
00:04:42,720 --> 00:04:47,530
representing large numbers including

84
00:04:44,950 --> 00:04:49,000
cookies API tokens of JSON web tokens

85
00:04:47,530 --> 00:04:51,549
that represent an authenticated user

86
00:04:49,000 --> 00:04:53,620
when presented to the server these are

87
00:04:51,550 --> 00:04:54,910
more complex than passwords and so

88
00:04:53,620 --> 00:04:57,039
they're not usually entered manually

89
00:04:54,910 --> 00:04:58,690
they're stored in computer memory but

90
00:04:57,039 --> 00:05:01,120
just like passwords they require a

91
00:04:58,690 --> 00:05:03,640
secured transport mechanism to stay

92
00:05:01,120 --> 00:05:05,620
secret and private keys are the private

93
00:05:03,640 --> 00:05:08,919
component of public private keys all

94
00:05:05,620 --> 00:05:11,110
used for encryption and for any public

95
00:05:08,919 --> 00:05:13,599
private key pair the private key must

96
00:05:11,110 --> 00:05:15,789
remain secret so where do secrets come

97
00:05:13,600 --> 00:05:17,979
from you can create them yourself if

98
00:05:15,789 --> 00:05:19,810
it's a password you make it up you can

99
00:05:17,979 --> 00:05:21,400
generate it automatically using a system

100
00:05:19,810 --> 00:05:22,599
and sometimes you need to get them from

101
00:05:21,400 --> 00:05:24,820
somewhere else like a service you're

102
00:05:22,599 --> 00:05:25,120
using if the service generates it and

103
00:05:24,820 --> 00:05:27,190
you

104
00:05:25,120 --> 00:05:28,479
have to retrieve it from them like if

105
00:05:27,190 --> 00:05:30,460
Amazon generates the service you

106
00:05:28,479 --> 00:05:33,940
retrieve it from the AWS panel or you

107
00:05:30,460 --> 00:05:39,219
got a key access to a product key for a

108
00:05:33,940 --> 00:05:41,430
licensed product so there's there's a

109
00:05:39,220 --> 00:05:43,960
secret distribution to distribution

110
00:05:41,430 --> 00:05:46,180
problem whenever you're trying to share

111
00:05:43,960 --> 00:05:47,799
secrets with someone if all of you need

112
00:05:46,180 --> 00:05:48,910
access to the same service and one

113
00:05:47,800 --> 00:05:50,860
problem we address with this

114
00:05:48,910 --> 00:05:52,840
presentation is how you might share or

115
00:05:50,860 --> 00:05:55,290
distribute secrets to others who need

116
00:05:52,840 --> 00:05:57,669
them differently than you may now

117
00:05:55,290 --> 00:06:00,070
looking at complexities about dealing

118
00:05:57,669 --> 00:06:03,070
with harms and ensuring information is

119
00:06:00,070 --> 00:06:05,289
how you want it to be information

120
00:06:03,070 --> 00:06:07,060
resides in and goes between information

121
00:06:05,289 --> 00:06:09,159
systems sometimes it floats around on

122
00:06:07,060 --> 00:06:11,070
hard drives - there are three main

123
00:06:09,160 --> 00:06:12,850
attributes to information assurance

124
00:06:11,070 --> 00:06:15,159
availability integrity and

125
00:06:12,850 --> 00:06:16,720
confidentiality an authentication is

126
00:06:15,160 --> 00:06:18,900
important because we're talking about

127
00:06:16,720 --> 00:06:21,360
passwords we're also discussing

128
00:06:18,900 --> 00:06:23,530
protection and reaction capabilities

129
00:06:21,360 --> 00:06:25,360
mostly we'll talk about that later but

130
00:06:23,530 --> 00:06:27,210
it's important to consider reaction

131
00:06:25,360 --> 00:06:29,650
capabilities as a way to mitigate

132
00:06:27,210 --> 00:06:31,419
problematic situations for example an

133
00:06:29,650 --> 00:06:34,900
intrusion of your system or a breach or

134
00:06:31,419 --> 00:06:37,659
leak of data will discuss availability

135
00:06:34,900 --> 00:06:41,409
integrity and confidentiality in the

136
00:06:37,660 --> 00:06:43,780
next few slides information compromise

137
00:06:41,410 --> 00:06:46,090
can cause harm if the information is

138
00:06:43,780 --> 00:06:47,859
changed or altered and that change

139
00:06:46,090 --> 00:06:49,450
compromises the integrity of the

140
00:06:47,860 --> 00:06:51,160
information because it changes the

141
00:06:49,450 --> 00:06:52,810
meaning of the information for example

142
00:06:51,160 --> 00:06:54,760
change a buy order to a sell order

143
00:06:52,810 --> 00:06:56,470
change a paycheck from two thousand

144
00:06:54,760 --> 00:06:57,780
dollars to two hundred dollars that

145
00:06:56,470 --> 00:07:00,250
changes the integrity of the information

146
00:06:57,780 --> 00:07:02,229
when information is deleted or encrypted

147
00:07:00,250 --> 00:07:04,360
there's harm because the availability of

148
00:07:02,229 --> 00:07:06,219
the information is compromised and it is

149
00:07:04,360 --> 00:07:08,320
no longer available unless you have the

150
00:07:06,220 --> 00:07:09,699
key to decrypt it if deleted while

151
00:07:08,320 --> 00:07:11,770
there's the potential for recovery

152
00:07:09,699 --> 00:07:14,770
there's at least a temporary harm to the

153
00:07:11,770 --> 00:07:16,299
availability of the data if the

154
00:07:14,770 --> 00:07:17,979
information that's intended to be

155
00:07:16,300 --> 00:07:19,720
private is leaked to the public the

156
00:07:17,979 --> 00:07:22,990
confidentiality of the information is

157
00:07:19,720 --> 00:07:27,820
compromised because that information is

158
00:07:22,990 --> 00:07:30,520
no longer private so looking at second

159
00:07:27,820 --> 00:07:34,150
downstream harms secondary effects leaks

160
00:07:30,520 --> 00:07:36,729
of credentials allow systems allow an

161
00:07:34,150 --> 00:07:38,560
unauthorized user access to a system and

162
00:07:36,729 --> 00:07:40,690
that compromises the integrity

163
00:07:38,560 --> 00:07:43,060
of the system because an unauthorized

164
00:07:40,690 --> 00:07:45,910
person has access to the system and can

165
00:07:43,060 --> 00:07:47,830
now modify files or accesses or access

166
00:07:45,910 --> 00:07:50,200
to the system since an unauthorized

167
00:07:47,830 --> 00:07:52,300
person is able to view the files their

168
00:07:50,200 --> 00:07:55,330
confidentiality is also likely

169
00:07:52,300 --> 00:07:57,850
compromised encrypting a file alters the

170
00:07:55,330 --> 00:07:59,500
integrity of the file because it changes

171
00:07:57,850 --> 00:08:01,990
the file it's no longer in its original

172
00:07:59,500 --> 00:08:04,150
form and ransomware compromises the

173
00:08:01,990 --> 00:08:06,250
availability of data or information

174
00:08:04,150 --> 00:08:09,489
because it becomes unreadable without

175
00:08:06,250 --> 00:08:11,830
the key if ransomware happens to encrypt

176
00:08:09,490 --> 00:08:13,330
critical system files the files are no

177
00:08:11,830 --> 00:08:16,210
longer available and the system could

178
00:08:13,330 --> 00:08:17,740
crash or refuse to boot up our goal is

179
00:08:16,210 --> 00:08:20,169
to minimize harm and speed up the

180
00:08:17,740 --> 00:08:22,120
mitigation process so we're going to

181
00:08:20,169 --> 00:08:24,789
talk about what goes on in the real

182
00:08:22,120 --> 00:08:26,650
world we'll begin by looking at the

183
00:08:24,790 --> 00:08:28,570
complexity of the group that will use

184
00:08:26,650 --> 00:08:30,729
some secrets so you're just one person

185
00:08:28,570 --> 00:08:32,710
there is no sharing or distribution

186
00:08:30,729 --> 00:08:34,900
problem but there still is a default

187
00:08:32,710 --> 00:08:36,969
password problem there's a small

188
00:08:34,900 --> 00:08:39,338
federated group say a trusted group the

189
00:08:36,969 --> 00:08:43,270
same community or slack channel then

190
00:08:39,339 --> 00:08:45,460
there's a distribution problem but in

191
00:08:43,270 --> 00:08:47,110
this context you might set up a central

192
00:08:45,460 --> 00:08:49,089
protected server to share secrets and

193
00:08:47,110 --> 00:08:52,930
the turnover of the group may be limited

194
00:08:49,089 --> 00:08:55,750
that is an assumption take a set of

195
00:08:52,930 --> 00:08:57,930
federated organizational units say a

196
00:08:55,750 --> 00:09:00,760
commercial group its product developers

197
00:08:57,930 --> 00:09:02,439
the open-source developers within the

198
00:09:00,760 --> 00:09:04,300
same organization and the group

199
00:09:02,440 --> 00:09:06,670
responsible for identity management all

200
00:09:04,300 --> 00:09:08,680
at the same organization say there's a

201
00:09:06,670 --> 00:09:15,099
vault server and only employees have

202
00:09:08,680 --> 00:09:18,579
access authorization of services with

203
00:09:15,100 --> 00:09:20,080
developers outside the company if open

204
00:09:18,580 --> 00:09:21,339
source developers from outside the

205
00:09:20,080 --> 00:09:23,770
federated group are aiming to

206
00:09:21,339 --> 00:09:27,160
participate in a project secrets must be

207
00:09:23,770 --> 00:09:30,699
shared outside the identity management

208
00:09:27,160 --> 00:09:32,459
group and that leads to a Confederated

209
00:09:30,700 --> 00:09:35,020
set of preexisting groups or individuals

210
00:09:32,459 --> 00:09:38,040
Confederated here means there's a common

211
00:09:35,020 --> 00:09:40,900
goal but less trust because the outside

212
00:09:38,040 --> 00:09:42,699
participants are non employees there's

213
00:09:40,900 --> 00:09:46,990
still possibly some degree of personal

214
00:09:42,700 --> 00:09:50,680
trust what is limited although although

215
00:09:46,990 --> 00:09:52,010
Trust is limited here there are no

216
00:09:50,680 --> 00:09:55,400
credentials going from that

217
00:09:52,010 --> 00:09:56,990
Identity Management Group to the outside

218
00:09:55,400 --> 00:09:59,270
individuals but you need a way to

219
00:09:56,990 --> 00:10:01,820
transmit secrets facilitate sharing new

220
00:09:59,270 --> 00:10:05,350
secrets and generate or revoke secrets

221
00:10:01,820 --> 00:10:05,350
from people who are no longer trusted

222
00:10:05,770 --> 00:10:09,350
went too fast

223
00:10:07,430 --> 00:10:11,900
the secret distribution problem can be

224
00:10:09,350 --> 00:10:14,330
summed up this way you need a method for

225
00:10:11,900 --> 00:10:17,329
creating and sharing secrets also for

226
00:10:14,330 --> 00:10:19,130
generating and revoking secrets as the

227
00:10:17,330 --> 00:10:22,760
size of the group grows the sharing of

228
00:10:19,130 --> 00:10:26,050
Secrets become more complex and another

229
00:10:22,760 --> 00:10:28,370
thing that impacts the distribution or

230
00:10:26,050 --> 00:10:31,479
replication of Secrets is how frequently

231
00:10:28,370 --> 00:10:37,270
the membership of the group changes so I

232
00:10:31,480 --> 00:10:39,860
want to I want to get a Raspberry Pi and

233
00:10:37,270 --> 00:10:41,780
this is the first the first of the

234
00:10:39,860 --> 00:10:44,270
problems is the default admin password

235
00:10:41,780 --> 00:10:46,459
problem if you got a Raspberry Pi you

236
00:10:44,270 --> 00:10:49,579
can log in as the default user PI and

237
00:10:46,460 --> 00:10:51,560
the password is raspberry pi has pseudo

238
00:10:49,580 --> 00:10:54,110
access changing the password is best

239
00:10:51,560 --> 00:10:56,089
practice but it's only discretionary and

240
00:10:54,110 --> 00:10:58,340
that's just raspberry pi any open source

241
00:10:56,090 --> 00:11:04,040
technology potentially has a default

242
00:10:58,340 --> 00:11:07,550
password so this problem was actually

243
00:11:04,040 --> 00:11:11,660
predated the internet Morris worm in the

244
00:11:07,550 --> 00:11:14,510
ARPANET two modules that had 432 common

245
00:11:11,660 --> 00:11:16,219
english words or names as well as a

246
00:11:14,510 --> 00:11:17,180
module that would take the account we

247
00:11:16,220 --> 00:11:19,730
would look through the password file

248
00:11:17,180 --> 00:11:22,479
find the account name try that as the

249
00:11:19,730 --> 00:11:25,400
password try no password as the password

250
00:11:22,480 --> 00:11:26,930
quite effective and there have been

251
00:11:25,400 --> 00:11:28,670
researchers over the years who have

252
00:11:26,930 --> 00:11:32,239
found vulnerabilities and things like

253
00:11:28,670 --> 00:11:35,689
commodity or consumer wireless access

254
00:11:32,240 --> 00:11:37,430
points routers things like that there's

255
00:11:35,690 --> 00:11:39,170
a big list of all these default common

256
00:11:37,430 --> 00:11:41,209
defaults that's available it's used by a

257
00:11:39,170 --> 00:11:43,939
whole bunch of tools and that's been

258
00:11:41,210 --> 00:11:46,460
exploited despite people like David

259
00:11:43,940 --> 00:11:48,110
Fifield at blackhat showing nmap

260
00:11:46,460 --> 00:11:50,960
scripting engine being used to go out

261
00:11:48,110 --> 00:11:53,450
and scan for in this case his camera at

262
00:11:50,960 --> 00:11:57,050
home finding it trying a default

263
00:11:53,450 --> 00:11:59,090
password getting in and simple Nomad was

264
00:11:57,050 --> 00:12:00,849
mentioning the DDoS attacks that have

265
00:11:59,090 --> 00:12:04,820
been happening lately from IOT devices

266
00:12:00,850 --> 00:12:05,540
so I look back after the Mara botnet

267
00:12:04,820 --> 00:12:07,339
came out

268
00:12:05,540 --> 00:12:09,349
this is a Venn diagram I went through

269
00:12:07,339 --> 00:12:10,910
the passwords that were used by these

270
00:12:09,350 --> 00:12:13,910
tools to gain access to these systems

271
00:12:10,910 --> 00:12:16,790
and you'll see that there's a massive

272
00:12:13,910 --> 00:12:18,980
overlap the big gigantic bubble there is

273
00:12:16,790 --> 00:12:21,259
a program called BARC that was floating

274
00:12:18,980 --> 00:12:26,060
around in like the late 1990s or early

275
00:12:21,259 --> 00:12:29,149
2000s brute force on ssh embedded lists

276
00:12:26,060 --> 00:12:32,329
of over 50,000 passwords some of those

277
00:12:29,149 --> 00:12:34,670
passwords indicated that there were some

278
00:12:32,329 --> 00:12:37,219
military sites that had common passwords

279
00:12:34,670 --> 00:12:39,949
then make the reason being the passwords

280
00:12:37,220 --> 00:12:43,959
and the account names indicated the

281
00:12:39,949 --> 00:12:45,889
basis where these accounts existed so

282
00:12:43,959 --> 00:12:47,779
that's one of the main things we've got

283
00:12:45,889 --> 00:12:49,519
to get rid of for those of you that saw

284
00:12:47,779 --> 00:12:52,279
the truffle hog talk a moment ago the

285
00:12:49,519 --> 00:12:55,009
embedded secrets in source code problem

286
00:12:52,279 --> 00:12:57,410
and one of the main things that he was

287
00:12:55,009 --> 00:12:59,360
saying start to put the search for these

288
00:12:57,410 --> 00:13:02,329
things as an audit mechanism into the

289
00:12:59,360 --> 00:13:04,699
DevOps chain that gives you the ability

290
00:13:02,329 --> 00:13:08,300
to keep the secrets from being breached

291
00:13:04,699 --> 00:13:12,889
in the first place all right so this

292
00:13:08,300 --> 00:13:15,229
might be duplicative I think you

293
00:13:12,889 --> 00:13:17,750
mentioned over but to hackers found

294
00:13:15,230 --> 00:13:21,199
credentials in a private github repo and

295
00:13:17,750 --> 00:13:25,480
used them to access over data stored on

296
00:13:21,199 --> 00:13:28,849
AWS around October 2016 and it was only

297
00:13:25,480 --> 00:13:32,000
publicized about a year later the

298
00:13:28,850 --> 00:13:34,819
attackers found personal information 457

299
00:13:32,000 --> 00:13:36,440
million customers and drivers they also

300
00:13:34,819 --> 00:13:39,790
found six hundred thousand drivers

301
00:13:36,440 --> 00:13:44,810
licenses which that alone triggers

302
00:13:39,790 --> 00:13:47,029
reporting requirement and uber claims

303
00:13:44,810 --> 00:13:48,349
that no credit card numbers or social

304
00:13:47,029 --> 00:13:52,040
security numbers our trip data was

305
00:13:48,350 --> 00:13:54,589
recovered but they also paid a hundred

306
00:13:52,040 --> 00:13:59,480
thousand dollars to keep these intruders

307
00:13:54,589 --> 00:14:03,110
quiet and Adobe Visual Studio 2015 had a

308
00:13:59,480 --> 00:14:06,319
bug in it that someone learned about

309
00:14:03,110 --> 00:14:09,410
because they published a private repo

310
00:14:06,319 --> 00:14:13,310
and it ended up being public on github

311
00:14:09,410 --> 00:14:15,228
and it had AWS access keys in it and all

312
00:14:13,310 --> 00:14:19,289
of a sudden he

313
00:14:15,229 --> 00:14:21,959
$6,500 in usage fees after doing really

314
00:14:19,289 --> 00:14:24,869
nothing so his lesson learned from that

315
00:14:21,959 --> 00:14:27,179
experience was put your access keys in a

316
00:14:24,869 --> 00:14:30,929
separate config file and use get ignore

317
00:14:27,179 --> 00:14:32,519
to exclude them in reality also people

318
00:14:30,929 --> 00:14:34,470
are searching for credentials in get lab

319
00:14:32,519 --> 00:14:36,509
and using the ones they find to steal

320
00:14:34,470 --> 00:14:38,699
intellectual property even though this

321
00:14:36,509 --> 00:14:44,910
mischief is not generally publicized in

322
00:14:38,699 --> 00:14:46,410
the media okay so if you start trying to

323
00:14:44,910 --> 00:14:50,129
solve this problem you're gonna run into

324
00:14:46,410 --> 00:14:52,439
two people anybody here not seen David

325
00:14:50,129 --> 00:14:55,019
if I fail or David's Daniel

326
00:14:52,439 --> 00:14:58,199
Summerfield's talking it's a very good

327
00:14:55,019 --> 00:15:00,600
one he goes into a quite a bit of depth

328
00:14:58,199 --> 00:15:02,779
on pros and cons of various tools so I'm

329
00:15:00,600 --> 00:15:05,789
not gonna be repeating what he said but

330
00:15:02,779 --> 00:15:09,779
look for that there's another person max

331
00:15:05,789 --> 00:15:13,350
VT who had put together a Google Doc

332
00:15:09,779 --> 00:15:15,509
that lists a set of tools with some

333
00:15:13,350 --> 00:15:17,459
details about those and I'll also throw

334
00:15:15,509 --> 00:15:20,129
in that the software development section

335
00:15:17,459 --> 00:15:22,559
of my home page has significant number

336
00:15:20,129 --> 00:15:23,939
of resources as well so most of what I'm

337
00:15:22,559 --> 00:15:26,249
gonna be talking about here is going to

338
00:15:23,939 --> 00:15:27,539
come from these guys as well as some of

339
00:15:26,249 --> 00:15:30,839
the research that I had done on a

340
00:15:27,539 --> 00:15:33,409
previous project so if you're going to

341
00:15:30,839 --> 00:15:35,429
start looking at tactics and procedures

342
00:15:33,409 --> 00:15:37,529
we've got to deal with this default

343
00:15:35,429 --> 00:15:40,108
password problem like it's existed too

344
00:15:37,529 --> 00:15:45,919
long there needs to be a better way for

345
00:15:40,109 --> 00:15:48,629
people to do the coding if you look at

346
00:15:45,919 --> 00:15:51,449
these are like the really high level

347
00:15:48,629 --> 00:15:52,769
recommendations from Sommerfeld you're

348
00:15:51,449 --> 00:15:54,508
always going to have this bootstrapping

349
00:15:52,769 --> 00:15:57,389
problem if you decide the solution is

350
00:15:54,509 --> 00:15:59,189
encryption of the secrets then the key

351
00:15:57,389 --> 00:16:02,100
has to exist somewhere you're gonna put

352
00:15:59,189 --> 00:16:03,899
it into a CI CD chain then now the key

353
00:16:02,100 --> 00:16:05,249
has to be somewhere where Jenkins or

354
00:16:03,899 --> 00:16:07,289
whatever is going to be trying to access

355
00:16:05,249 --> 00:16:09,149
them so you can never get rid of this

356
00:16:07,289 --> 00:16:13,409
bootstrapping problem there's always

357
00:16:09,149 --> 00:16:14,939
going to be some starting point so his

358
00:16:13,409 --> 00:16:17,209
idea or his suggestion is

359
00:16:14,939 --> 00:16:19,978
compartmentalised as much as you can and

360
00:16:17,209 --> 00:16:21,988
use tactical human intervention where

361
00:16:19,979 --> 00:16:25,319
necessary try to minimize it try to

362
00:16:21,989 --> 00:16:28,620
structure it by policy and focus on

363
00:16:25,319 --> 00:16:31,199
audit so again truffle hog

364
00:16:28,620 --> 00:16:33,270
in the CI CD pipeline that's one way of

365
00:16:31,200 --> 00:16:35,040
making sure that you're looking at these

366
00:16:33,270 --> 00:16:40,110
things before they get to the point of

367
00:16:35,040 --> 00:16:42,420
hitting github and automation of all of

368
00:16:40,110 --> 00:16:44,400
the tedious things especially if you're

369
00:16:42,420 --> 00:16:46,319
trying to compose a large system from

370
00:16:44,400 --> 00:16:48,240
open source components each one of them

371
00:16:46,320 --> 00:16:51,050
needing passwords the ability to

372
00:16:48,240 --> 00:16:53,130
simplify rolling all those passwords

373
00:16:51,050 --> 00:16:55,890
revoking credentials when someone's

374
00:16:53,130 --> 00:16:58,830
laptop is compromised those all require

375
00:16:55,890 --> 00:17:01,319
automation and whatever you do don't try

376
00:16:58,830 --> 00:17:03,870
to like let's just go change everything

377
00:17:01,320 --> 00:17:05,069
that we have to deal with or every

378
00:17:03,870 --> 00:17:07,349
policy that we have about dealing with

379
00:17:05,069 --> 00:17:09,780
secrets try to do it in an incremental

380
00:17:07,349 --> 00:17:12,530
way bring people aboard there's gonna be

381
00:17:09,780 --> 00:17:15,599
some training time so take small steps

382
00:17:12,530 --> 00:17:19,319
if you just think about let's keep it

383
00:17:15,599 --> 00:17:20,849
out of a repo pushing is the problem as

384
00:17:19,319 --> 00:17:23,369
was mentioned in a truffle hog talk

385
00:17:20,849 --> 00:17:26,010
every single commit that has ever been

386
00:17:23,369 --> 00:17:27,599
made contains something if the secrets

387
00:17:26,010 --> 00:17:30,090
are in there you just keep layering

388
00:17:27,599 --> 00:17:33,149
commits on top of it whoever has cloned

389
00:17:30,090 --> 00:17:35,189
or pulled that repo has them so if

390
00:17:33,150 --> 00:17:37,920
you're using it and you explicitly add

391
00:17:35,190 --> 00:17:39,450
files rather than using wildcards you

392
00:17:37,920 --> 00:17:42,660
reduce the chance that some temporary

393
00:17:39,450 --> 00:17:44,880
file is gonna be included get status

394
00:17:42,660 --> 00:17:46,679
after doing get add so that you just

395
00:17:44,880 --> 00:17:48,870
have some feedback these are the things

396
00:17:46,679 --> 00:17:52,080
that are now in the staging area or

397
00:17:48,870 --> 00:17:55,800
using git commit specific file names

398
00:17:52,080 --> 00:17:58,230
rather than get commit - a again try to

399
00:17:55,800 --> 00:18:01,980
avoid accidentally doing something that

400
00:17:58,230 --> 00:18:02,670
you're not really aware of get diff - -

401
00:18:01,980 --> 00:18:04,920
cached

402
00:18:02,670 --> 00:18:07,610
a lot of people don't think of that that

403
00:18:04,920 --> 00:18:09,990
will show you the changes in the files

404
00:18:07,610 --> 00:18:11,310
look through it methodically to see if

405
00:18:09,990 --> 00:18:13,770
there happens to be a comment that was

406
00:18:11,310 --> 00:18:17,550
left or if there was a file it shows up

407
00:18:13,770 --> 00:18:19,980
as being added if you just do get commit

408
00:18:17,550 --> 00:18:21,540
without a message a lot of people start

409
00:18:19,980 --> 00:18:23,700
doing you know I'm gonna give a message

410
00:18:21,540 --> 00:18:24,780
I want to be in a hurry that's when

411
00:18:23,700 --> 00:18:27,780
things will happen that you don't

412
00:18:24,780 --> 00:18:31,830
realize how many people here know about

413
00:18:27,780 --> 00:18:34,920
get what changed it's a handy way of

414
00:18:31,830 --> 00:18:36,540
seeing okay could at least somebody it's

415
00:18:34,920 --> 00:18:39,210
a good way of seeing what files were

416
00:18:36,540 --> 00:18:41,050
staged what files were changed in each

417
00:18:39,210 --> 00:18:43,059
of the commits

418
00:18:41,050 --> 00:18:45,100
the thing is these are all discretionary

419
00:18:43,059 --> 00:18:46,600
policies you've got to train your

420
00:18:45,100 --> 00:18:48,719
developers and make sure that they

421
00:18:46,600 --> 00:18:52,059
understand this is your responsibility

422
00:18:48,720 --> 00:18:53,410
take that responsibility so you're only

423
00:18:52,059 --> 00:18:55,809
gonna have problems if there are humans

424
00:18:53,410 --> 00:19:01,360
involved in coding so that's a simple

425
00:18:55,809 --> 00:19:03,850
thing to fix no it's not excluding files

426
00:19:01,360 --> 00:19:06,010
with get ignore as has been recommended

427
00:19:03,850 --> 00:19:08,800
the people that Katherine was talking

428
00:19:06,010 --> 00:19:11,890
about also mention and get robbed it's

429
00:19:08,800 --> 00:19:13,809
not perfect you can have wildcards but

430
00:19:11,890 --> 00:19:16,630
can you predict that I'm gonna make a

431
00:19:13,809 --> 00:19:19,420
copy temporarily with my initials as the

432
00:19:16,630 --> 00:19:22,030
extension and then forget about it and

433
00:19:19,420 --> 00:19:24,400
accidentally commit it that you're not

434
00:19:22,030 --> 00:19:27,370
gonna find or you're not gonna prevent

435
00:19:24,400 --> 00:19:28,690
by a policy so a number of people are

436
00:19:27,370 --> 00:19:31,110
now starting to say just move the

437
00:19:28,690 --> 00:19:33,610
secret's out of the code repo don't

438
00:19:31,110 --> 00:19:36,129
commit code that has a hard-coded

439
00:19:33,610 --> 00:19:38,949
password in it someone wanting to change

440
00:19:36,130 --> 00:19:41,440
that must then edit that file now it's

441
00:19:38,950 --> 00:19:44,830
in conflict with the original file it's

442
00:19:41,440 --> 00:19:48,570
still in the repo just make them access

443
00:19:44,830 --> 00:19:50,919
secrets indirectly rather than hard code

444
00:19:48,570 --> 00:19:53,080
another way to deal with this is to just

445
00:19:50,920 --> 00:19:54,850
get used to minimizing the life cycle

446
00:19:53,080 --> 00:19:57,159
get used to burning the creds and

447
00:19:54,850 --> 00:19:58,870
restoring them each time you're going to

448
00:19:57,160 --> 00:20:01,690
deploy a new system if you're in

449
00:19:58,870 --> 00:20:05,790
development mode so that you don't

450
00:20:01,690 --> 00:20:08,350
accidentally have a long-lived secret f5

451
00:20:05,790 --> 00:20:11,710
has an open source project that requires

452
00:20:08,350 --> 00:20:13,780
product key that key that they were

453
00:20:11,710 --> 00:20:17,590
trying to protect in the repo with PGP

454
00:20:13,780 --> 00:20:20,230
so if somebody who had previously been

455
00:20:17,590 --> 00:20:22,419
trusted is revoked they still have their

456
00:20:20,230 --> 00:20:24,429
private key it was encrypted with their

457
00:20:22,420 --> 00:20:26,230
public key you can't stop them from

458
00:20:24,429 --> 00:20:27,790
reading that file so the lifetime of the

459
00:20:26,230 --> 00:20:30,100
secret must be less than the

460
00:20:27,790 --> 00:20:33,970
rolling-over of the the untrusted people

461
00:20:30,100 --> 00:20:36,610
and that also helps when it becomes an

462
00:20:33,970 --> 00:20:39,730
emergency and you must now go out and

463
00:20:36,610 --> 00:20:41,740
rekey a lot of things when you're

464
00:20:39,730 --> 00:20:45,190
choosing your tools you have to pay

465
00:20:41,740 --> 00:20:47,830
really close attention to lock in are

466
00:20:45,190 --> 00:20:50,860
you now choosing a tool that only works

467
00:20:47,830 --> 00:20:53,889
on AWS are you choosing a tool that

468
00:20:50,860 --> 00:20:54,939
requires that you use chef so these

469
00:20:53,890 --> 00:20:57,310
kinds of things will

470
00:20:54,940 --> 00:21:00,340
a problem if you're planning on growing

471
00:20:57,310 --> 00:21:02,350
a small group into a larger project and

472
00:21:00,340 --> 00:21:04,689
you want to look for tools that are easy

473
00:21:02,350 --> 00:21:07,199
to integrate so things that may access

474
00:21:04,690 --> 00:21:09,610
things from the file system or by using

475
00:21:07,200 --> 00:21:11,530
command lines you can do in line command

476
00:21:09,610 --> 00:21:16,209
substitution you can now more easily

477
00:21:11,530 --> 00:21:20,110
integrate with with other tools in terms

478
00:21:16,210 --> 00:21:22,660
of rolling your secrets think about the

479
00:21:20,110 --> 00:21:25,060
general period of whatever the project

480
00:21:22,660 --> 00:21:28,030
is that you're working on so campaigns

481
00:21:25,060 --> 00:21:29,590
there is a there is an election that

482
00:21:28,030 --> 00:21:32,080
happens as soon as the election is done

483
00:21:29,590 --> 00:21:34,659
that's the time to go burn all the creds

484
00:21:32,080 --> 00:21:37,419
start over again because you're going to

485
00:21:34,660 --> 00:21:39,130
have turnover and staff with academic

486
00:21:37,420 --> 00:21:41,680
research projects the main thing is

487
00:21:39,130 --> 00:21:43,440
intellectual property theft so at least

488
00:21:41,680 --> 00:21:46,270
your period of performance of your grant

489
00:21:43,440 --> 00:21:47,680
but probably more frequently if you have

490
00:21:46,270 --> 00:21:49,990
graduate students who are coming and

491
00:21:47,680 --> 00:21:52,230
going overtime anybody who is left

492
00:21:49,990 --> 00:21:55,890
should be considered not trusted anymore

493
00:21:52,230 --> 00:21:58,570
you can't rely on the employee system

494
00:21:55,890 --> 00:22:02,020
making someone who's no longer staff and

495
00:21:58,570 --> 00:22:04,090
no longer have access and then the

496
00:22:02,020 --> 00:22:06,400
bigger problem is really consumer

497
00:22:04,090 --> 00:22:09,970
devices you've got a supply chain of

498
00:22:06,400 --> 00:22:13,570
tools that you're using you may rely on

499
00:22:09,970 --> 00:22:15,790
upstream services and each of those may

500
00:22:13,570 --> 00:22:20,710
have their own cycle for how they they

501
00:22:15,790 --> 00:22:21,909
deal with with secrets so when I talk

502
00:22:20,710 --> 00:22:24,640
about emergencies and break class

503
00:22:21,910 --> 00:22:26,590
procedures this is not a good break

504
00:22:24,640 --> 00:22:28,630
class procedure this is not the kind of

505
00:22:26,590 --> 00:22:31,179
we're talking about how many people here

506
00:22:28,630 --> 00:22:35,230
know that I can is rolling the DNS SEC

507
00:22:31,180 --> 00:22:38,320
key signing key in a little bit okay

508
00:22:35,230 --> 00:22:41,160
it's at least one person this is the key

509
00:22:38,320 --> 00:22:44,950
that signs the keys that sign the keys

510
00:22:41,160 --> 00:22:48,370
that allow you to have a device validate

511
00:22:44,950 --> 00:22:50,680
DNS SEC they've been mentioning us for a

512
00:22:48,370 --> 00:22:52,689
while they've done a survey to

513
00:22:50,680 --> 00:22:55,740
understand what the impact is the impact

514
00:22:52,690 --> 00:22:58,600
will be minimal but there are devices

515
00:22:55,740 --> 00:23:00,970
probably guaranteed that are out there

516
00:22:58,600 --> 00:23:03,459
that use DNS SEC that cannot be patched

517
00:23:00,970 --> 00:23:06,280
or updated that will no longer be able

518
00:23:03,460 --> 00:23:11,440
to validate DNS zone information

519
00:23:06,280 --> 00:23:12,760
so there will be some pain from this so

520
00:23:11,440 --> 00:23:16,060
let's look a little bit at some of these

521
00:23:12,760 --> 00:23:18,820
tools and again I'm kind of falling back

522
00:23:16,060 --> 00:23:21,429
on Daniel Summerfield's way of

523
00:23:18,820 --> 00:23:23,200
categorizing them his first set was the

524
00:23:21,430 --> 00:23:26,230
source code management integrated tools

525
00:23:23,200 --> 00:23:27,730
and most of you here if you've heard of

526
00:23:26,230 --> 00:23:31,530
any of these you've heard of black box

527
00:23:27,730 --> 00:23:34,870
or get crypt and basically they're

528
00:23:31,530 --> 00:23:37,060
public private key used GPG encrypt the

529
00:23:34,870 --> 00:23:40,090
secrets in the repo whoever's keys were

530
00:23:37,060 --> 00:23:42,159
used for signing has access to them so

531
00:23:40,090 --> 00:23:44,679
again they're leaving the secrets in

532
00:23:42,160 --> 00:23:48,210
some obfuscated form in the code repo

533
00:23:44,680 --> 00:23:51,760
which is one of the downsides

534
00:23:48,210 --> 00:23:53,830
then there's the orchestration tools so

535
00:23:51,760 --> 00:23:58,030
if you're doing some build automation if

536
00:23:53,830 --> 00:24:01,360
you're using chef puppet ansible there

537
00:23:58,030 --> 00:24:03,100
are solutions for each of these haven't

538
00:24:01,360 --> 00:24:06,610
really looked at Barbican from OpenStack

539
00:24:03,100 --> 00:24:10,060
but here you see that there's at least

540
00:24:06,610 --> 00:24:11,679
one big lock in if you're using chef and

541
00:24:10,060 --> 00:24:15,460
you want to use sit at all set it all

542
00:24:11,680 --> 00:24:19,150
requires AWS I am so you're totally

543
00:24:15,460 --> 00:24:21,640
locked in on that one then there's

544
00:24:19,150 --> 00:24:22,990
secrets as a service how many people

545
00:24:21,640 --> 00:24:25,980
here are familiar with hashey core vault

546
00:24:22,990 --> 00:24:28,990
or have ever used it there's a few more

547
00:24:25,980 --> 00:24:30,070
it's probably the well it is the leader

548
00:24:28,990 --> 00:24:32,980
it's the one that's the most popular

549
00:24:30,070 --> 00:24:34,929
right now it scales really well but it

550
00:24:32,980 --> 00:24:37,030
is kind of complicated to set up the

551
00:24:34,930 --> 00:24:39,100
recommended deployment which is a

552
00:24:37,030 --> 00:24:42,750
cluster Eyes environment for high

553
00:24:39,100 --> 00:24:46,000
availability it uses consensus for the

554
00:24:42,750 --> 00:24:49,030
unsealing of the vault so 3 out of 5

555
00:24:46,000 --> 00:24:51,280
keys are required which means if the

556
00:24:49,030 --> 00:24:53,440
system goes down you've got to get three

557
00:24:51,280 --> 00:24:55,389
people on the phone ASAP to get that

558
00:24:53,440 --> 00:25:00,820
thing unsealed otherwise your user base

559
00:24:55,390 --> 00:25:02,770
is down and also note that interest Knox

560
00:25:00,820 --> 00:25:06,370
here is kind of interesting and it uses

561
00:25:02,770 --> 00:25:10,600
the files the file system and files in

562
00:25:06,370 --> 00:25:13,360
userspace fuse to expose the secrets

563
00:25:10,600 --> 00:25:15,820
from a remote system in the file system

564
00:25:13,360 --> 00:25:18,570
so it solves a distribution problem and

565
00:25:15,820 --> 00:25:21,780
simplifies the access of the secrets

566
00:25:18,570 --> 00:25:24,159
and then there's kind of this

567
00:25:21,780 --> 00:25:30,639
miscellaneous set here I noticed that

568
00:25:24,160 --> 00:25:34,690
Amazon now has secrets manager again

569
00:25:30,640 --> 00:25:36,970
it's Amazon only crypt this kind of

570
00:25:34,690 --> 00:25:38,950
interesting year because they're trying

571
00:25:36,970 --> 00:25:41,200
to do something similar to vault its

572
00:25:38,950 --> 00:25:45,900
relying on a CD and console as a cluster

573
00:25:41,200 --> 00:25:52,750
eyes key value store for simplicity and

574
00:25:45,900 --> 00:25:56,200
high availability and backup and Shopify

575
00:25:52,750 --> 00:25:58,059
uses this encrypted JSON mechanism so

576
00:25:56,200 --> 00:26:00,130
they're using JSON encrypting the data

577
00:25:58,059 --> 00:26:03,010
in it then there's this thing called

578
00:26:00,130 --> 00:26:05,530
Python Secrets which is one of the main

579
00:26:03,010 --> 00:26:08,620
reasons we're here so what is Python

580
00:26:05,530 --> 00:26:11,920
secrets it's available right now on pi

581
00:26:08,620 --> 00:26:15,219
PI I'll be making another release pretty

582
00:26:11,920 --> 00:26:17,110
soon with a few little changes probably

583
00:26:15,220 --> 00:26:21,610
switching to calendar versioning instead

584
00:26:17,110 --> 00:26:23,559
of the kind of semantic versioning the

585
00:26:21,610 --> 00:26:27,790
core features for the purposes of this

586
00:26:23,559 --> 00:26:29,860
talk is it allows you to remove the need

587
00:26:27,790 --> 00:26:31,899
for default passwords you can have a

588
00:26:29,860 --> 00:26:34,199
product open-source product where the

589
00:26:31,900 --> 00:26:37,870
first thing you do is Keys get generated

590
00:26:34,200 --> 00:26:41,309
passwords get generated there is no

591
00:26:37,870 --> 00:26:44,050
default or it doesn't need to be it also

592
00:26:41,309 --> 00:26:45,639
kind of helps with moving the secrets

593
00:26:44,050 --> 00:26:49,149
out of the source code base and then

594
00:26:45,640 --> 00:26:51,190
managing them in a way that you can

595
00:26:49,150 --> 00:26:53,500
accommodate multiple open source

596
00:26:51,190 --> 00:26:59,020
components so if you have like RabbitMQ

597
00:26:53,500 --> 00:27:02,280
and console and a couple other things

598
00:26:59,020 --> 00:27:04,840
they all require some secret that

599
00:27:02,280 --> 00:27:06,790
mechanism to have them all be the same

600
00:27:04,840 --> 00:27:10,500
password is the same on all these things

601
00:27:06,790 --> 00:27:13,210
a sort of cheap single sign-on is

602
00:27:10,500 --> 00:27:16,330
facilitated you can make them unique if

603
00:27:13,210 --> 00:27:19,179
you need to and it uses a drop-in model

604
00:27:16,330 --> 00:27:22,419
if you're familiar with like our syslog

605
00:27:19,179 --> 00:27:24,640
d and cron dot d a directory where you

606
00:27:22,420 --> 00:27:28,179
drop things into it and then in a

607
00:27:24,640 --> 00:27:30,309
modular way the larger file update dot d

608
00:27:28,179 --> 00:27:31,590
is a how many people here have not heard

609
00:27:30,309 --> 00:27:34,200
of update d

610
00:27:31,590 --> 00:27:36,928
it really makes your life easier in

611
00:27:34,200 --> 00:27:41,100
being able to have your bash RC file or

612
00:27:36,929 --> 00:27:43,559
your ssh configuration file be handled

613
00:27:41,100 --> 00:27:46,740
by breaking it up into small parts

614
00:27:43,559 --> 00:27:47,940
they're all put into one file it

615
00:27:46,740 --> 00:27:49,409
supports multiple simultaneous

616
00:27:47,940 --> 00:27:53,580
environments

617
00:27:49,409 --> 00:27:55,140
hashey Korps terraform implemented

618
00:27:53,580 --> 00:27:56,879
something about a year ago that they

619
00:27:55,140 --> 00:27:59,010
called initially environments they now

620
00:27:56,880 --> 00:28:01,620
call it workspaces allows you to have

621
00:27:59,010 --> 00:28:04,020
development production staging and has

622
00:28:01,620 --> 00:28:06,149
the secrets and configuration for each

623
00:28:04,020 --> 00:28:10,320
one of them separated and to move

624
00:28:06,149 --> 00:28:12,750
between them easily there's a program

625
00:28:10,320 --> 00:28:15,149
called mantle that came out of Cisco

626
00:28:12,750 --> 00:28:17,070
which was an automated deployment of a

627
00:28:15,149 --> 00:28:20,879
whole bunch of matured machine learning

628
00:28:17,070 --> 00:28:24,840
tools and they have a single program

629
00:28:20,880 --> 00:28:27,120
pipe secret-spy that has built into it

630
00:28:24,840 --> 00:28:29,010
hard-coded prompts for each of the

631
00:28:27,120 --> 00:28:30,600
secrets so if you're now going to try

632
00:28:29,010 --> 00:28:33,240
and integrate some new tool into that

633
00:28:30,600 --> 00:28:35,879
you've got to go edit that program to

634
00:28:33,240 --> 00:28:38,190
add the prompts to then create the

635
00:28:35,880 --> 00:28:41,419
secrets yml file the big global file

636
00:28:38,190 --> 00:28:44,190
that's used for the configuration so

637
00:28:41,419 --> 00:28:47,240
what Python Secrets does is make it

638
00:28:44,190 --> 00:28:51,330
easier to then add new components

639
00:28:47,240 --> 00:28:54,750
without impacting anything and hopefully

640
00:28:51,330 --> 00:28:56,879
then if promoted it becomes a lot easier

641
00:28:54,750 --> 00:29:02,010
for all of the source tools to to

642
00:28:56,880 --> 00:29:05,029
integrate tools like terraform will take

643
00:29:02,010 --> 00:29:08,820
secrets from environment variables and

644
00:29:05,029 --> 00:29:11,820
instantiate variables for the terraform

645
00:29:08,820 --> 00:29:13,470
run so python secrets will make it

646
00:29:11,820 --> 00:29:16,789
easier for you to have all these secrets

647
00:29:13,470 --> 00:29:19,320
defined export them run a sub program

648
00:29:16,789 --> 00:29:21,179
you're now not even needing to put them

649
00:29:19,320 --> 00:29:24,928
anywhere near the code repository they

650
00:29:21,179 --> 00:29:29,370
just come from the environment so how

651
00:29:24,929 --> 00:29:31,950
does it work the proof of concept for

652
00:29:29,370 --> 00:29:34,110
using this tool how many people here

653
00:29:31,950 --> 00:29:37,250
know the NSA has a github page with a

654
00:29:34,110 --> 00:29:39,240
whole bunch of tools on it very few

655
00:29:37,250 --> 00:29:41,549
there are some interesting things on

656
00:29:39,240 --> 00:29:44,280
there one of them is this thing called

657
00:29:41,549 --> 00:29:45,450
go secure which is potentially raspberry

658
00:29:44,280 --> 00:29:49,320
pi client and server

659
00:29:45,450 --> 00:29:52,410
for a VPN and their instructions of

660
00:29:49,320 --> 00:29:55,020
course this thing is a Raspberry Pi uses

661
00:29:52,410 --> 00:29:58,320
raspbian log into it with PI password

662
00:29:55,020 --> 00:30:00,629
raspberry so I've demonstrated with

663
00:29:58,320 --> 00:30:08,760
Python secrets how to to get around that

664
00:30:00,630 --> 00:30:15,530
problem so there's probably time to go

665
00:30:08,760 --> 00:30:19,920
through them all so one of the biggest

666
00:30:15,530 --> 00:30:22,710
limitations I would say is currently

667
00:30:19,920 --> 00:30:26,040
this program runs with the Python

668
00:30:22,710 --> 00:30:27,780
secrets module which I probably should

669
00:30:26,040 --> 00:30:29,610
rename my program because I thought

670
00:30:27,780 --> 00:30:32,399
underscore secrets is kind of confusing

671
00:30:29,610 --> 00:30:37,770
in comparison with Python secrets the

672
00:30:32,400 --> 00:30:41,130
module that came into Python at 3.6 so

673
00:30:37,770 --> 00:30:42,450
you have to be using 3.6 or greater I'd

674
00:30:41,130 --> 00:30:44,970
recommend doing it in a virtual

675
00:30:42,450 --> 00:30:48,540
environment in this example it's in

676
00:30:44,970 --> 00:30:51,090
default installed Python I have 3 6

677
00:30:48,540 --> 00:30:59,730
installed separate from the Mac Python

678
00:30:51,090 --> 00:31:02,939
to avoid breaking it help is available

679
00:30:59,730 --> 00:31:05,910
at a high level I'm using the OpenStack

680
00:31:02,940 --> 00:31:08,640
cliff framework for command line err

681
00:31:05,910 --> 00:31:18,530
faces which is really handy it allows

682
00:31:08,640 --> 00:31:18,530
you to define yep let's get past already

683
00:31:19,980 --> 00:31:26,200
there you can change which environment

684
00:31:24,280 --> 00:31:27,610
you can change where the secrets are

685
00:31:26,200 --> 00:31:29,530
kept so if you need to move them to a

686
00:31:27,610 --> 00:31:32,080
shared file system or something like

687
00:31:29,530 --> 00:31:35,080
that it facilitates that and then it

688
00:31:32,080 --> 00:31:36,970
uses sub commands which are pretty easy

689
00:31:35,080 --> 00:31:39,820
to implement they're just Python objects

690
00:31:36,970 --> 00:31:45,460
so adding to this tool is once you get

691
00:31:39,820 --> 00:31:47,740
used to cliff it's pretty easy each

692
00:31:45,460 --> 00:31:51,640
command can have its own help for the

693
00:31:47,740 --> 00:31:53,050
unique options so I'll be showing the

694
00:31:51,640 --> 00:31:58,630
templating command in a minute in a

695
00:31:53,050 --> 00:32:00,370
minute uses Jinja templating and there

696
00:31:58,630 --> 00:32:04,510
are some utilities built-in like with

697
00:32:00,370 --> 00:32:06,699
Amazon security groups you want to allow

698
00:32:04,510 --> 00:32:08,379
access for only the IP address of the

699
00:32:06,700 --> 00:32:11,290
system you're using there's a way to go

700
00:32:08,380 --> 00:32:20,080
get your IP add that as a variable to

701
00:32:11,290 --> 00:32:21,970
make direct access somebody tried

702
00:32:20,080 --> 00:32:32,320
changing my Apple password a couple days

703
00:32:21,970 --> 00:32:36,430
ago so the concept of environments this

704
00:32:32,320 --> 00:32:38,889
was done as something to facilitate the

705
00:32:36,430 --> 00:32:40,690
ansible jim's playbook so I'll mention

706
00:32:38,890 --> 00:32:42,730
it a little bit where you're

707
00:32:40,690 --> 00:32:44,080
instantiating a system like going out

708
00:32:42,730 --> 00:32:46,120
getting let's encrypt certificates

709
00:32:44,080 --> 00:32:48,010
setting up a database that has the

710
00:32:46,120 --> 00:32:49,600
database secrets in it and it's used by

711
00:32:48,010 --> 00:32:51,550
somebody on a regular basis so there's

712
00:32:49,600 --> 00:32:54,189
state that needs to be kept all the

713
00:32:51,550 --> 00:32:55,899
backups get kept in the secret directory

714
00:32:54,190 --> 00:32:59,110
now you've got one place where all the

715
00:32:55,900 --> 00:33:00,970
files are located when you first use it

716
00:32:59,110 --> 00:33:02,639
you don't have a directory by default

717
00:33:00,970 --> 00:33:05,620
it's dot secrets in your home directory

718
00:33:02,640 --> 00:33:08,800
it gets created on first use so it makes

719
00:33:05,620 --> 00:33:13,179
it pretty easy to get running we're

720
00:33:08,800 --> 00:33:16,360
gonna clone the go secure repo the go

721
00:33:13,180 --> 00:33:19,290
secure repo has within it a description

722
00:33:16,360 --> 00:33:23,860
of the variables that are required to

723
00:33:19,290 --> 00:33:27,610
burn a SD card or flash an SD card so

724
00:33:23,860 --> 00:33:30,250
going to the directory the secrets look

725
00:33:27,610 --> 00:33:33,750
like a standard drop-d style

726
00:33:30,250 --> 00:33:36,880
directory structure with yml files in it

727
00:33:33,750 --> 00:33:41,500
secrets are simple data structures in

728
00:33:36,880 --> 00:33:44,650
yamo name of a variable the prompt that

729
00:33:41,500 --> 00:33:48,220
you're going to give to the user the

730
00:33:44,650 --> 00:33:50,680
type of the variable not shown here is

731
00:33:48,220 --> 00:33:53,230
there's a export option where you can

732
00:33:50,680 --> 00:33:55,600
say I want this specific environment

733
00:33:53,230 --> 00:33:57,940
variable to be exported so if you need

734
00:33:55,600 --> 00:34:02,740
to change the name of the variable to

735
00:33:57,940 --> 00:34:06,160
accommodate that can be easily done when

736
00:34:02,740 --> 00:34:07,510
you clone the secrets by default the

737
00:34:06,160 --> 00:34:09,580
environment is going to be created with

738
00:34:07,510 --> 00:34:12,100
the base name of the directory that

739
00:34:09,580 --> 00:34:13,299
you're in so as long as the projects

740
00:34:12,100 --> 00:34:16,710
that you're working on are unique you

741
00:34:13,300 --> 00:34:16,710
don't need to manually set that

742
00:34:25,540 --> 00:34:31,360
so say clone from give a directory name

743
00:34:28,590 --> 00:34:33,720
by default it tells you whenever there

744
00:34:31,360 --> 00:34:36,190
are variables that have not been set yet

745
00:34:33,719 --> 00:34:38,500
you can then key on that to make sure

746
00:34:36,190 --> 00:34:46,600
that you don't try to run something and

747
00:34:38,500 --> 00:34:50,250
have passwords not be set look at the

748
00:34:46,600 --> 00:34:50,250
time I that's not going soon

749
00:35:07,750 --> 00:35:20,349
okay so each open-source tool that

750
00:35:18,220 --> 00:35:25,419
you're gonna add to an environment has

751
00:35:20,349 --> 00:35:27,400
its secrets in its own group you can

752
00:35:25,420 --> 00:35:33,430
list the groups see how many secrets are

753
00:35:27,400 --> 00:35:36,790
in each one and by default when you show

754
00:35:33,430 --> 00:35:40,390
variables you get the descriptions of

755
00:35:36,790 --> 00:35:42,690
the variables the values are redacted so

756
00:35:40,390 --> 00:35:45,910
if you're at a conference and you forget

757
00:35:42,690 --> 00:35:48,640
you don't want your AWS secret key to be

758
00:35:45,910 --> 00:35:49,839
copied by somebody and get thirty seven

759
00:35:48,640 --> 00:35:54,368
hundred or thirty six hundred dollar

760
00:35:49,840 --> 00:36:00,130
bill so you have to use the - - no -

761
00:35:54,369 --> 00:36:03,609
redact option you'll see that there are

762
00:36:00,130 --> 00:36:05,859
types password and token underscore hex

763
00:36:03,609 --> 00:36:07,840
and string string is something that a

764
00:36:05,859 --> 00:36:10,000
user provides the other ones or types

765
00:36:07,840 --> 00:36:12,730
that are general so you start out by

766
00:36:10,000 --> 00:36:16,780
saying I have this set of defined

767
00:36:12,730 --> 00:36:20,950
secrets generate me some secrets now you

768
00:36:16,780 --> 00:36:23,140
get your password I'm using the xkcd

769
00:36:20,950 --> 00:36:25,419
style password which if you're not

770
00:36:23,140 --> 00:36:28,118
familiar with it get people to use it it

771
00:36:25,420 --> 00:36:32,230
actually is really really easy in this

772
00:36:28,119 --> 00:36:34,359
case forwards the initial letter of each

773
00:36:32,230 --> 00:36:37,960
of those words spells a four-letter word

774
00:36:34,359 --> 00:36:42,880
in this case hut so if I put a golf ball

775
00:36:37,960 --> 00:36:45,970
on my screen that will remind me Puu PU

776
00:36:42,880 --> 00:36:50,320
TT better than having a post-it note

777
00:36:45,970 --> 00:36:52,919
with the real password you can set the

778
00:36:50,320 --> 00:36:59,820
variables manually on the command line

779
00:36:52,920 --> 00:36:59,820
with a variable equals value you can

780
00:37:04,640 --> 00:37:08,400
set it from a file

781
00:37:06,870 --> 00:37:10,080
put an ad sign in front of it you're

782
00:37:08,400 --> 00:37:11,940
gonna read from the file to set the

783
00:37:10,080 --> 00:37:15,000
variable so this is a way to import

784
00:37:11,940 --> 00:37:22,020
secrets from other places created a

785
00:37:15,000 --> 00:37:24,720
torque on SSH key so add that one for

786
00:37:22,020 --> 00:37:28,230
very long things cliff requires that you

787
00:37:24,720 --> 00:37:30,060
do - - fit - width to make everything

788
00:37:28,230 --> 00:37:32,700
nicely formatted on the screen otherwise

789
00:37:30,060 --> 00:37:37,020
it goes as long as the last column goes

790
00:37:32,700 --> 00:37:38,549
as long as whatever the value is cliff

791
00:37:37,020 --> 00:37:42,270
is really cool if you're a Python coder

792
00:37:38,550 --> 00:37:46,560
and you're right api's or CL is learned

793
00:37:42,270 --> 00:37:49,140
cliff and here's the solution for the

794
00:37:46,560 --> 00:37:56,180
mantle problem to find the secrets say

795
00:37:49,140 --> 00:37:56,180
prompt me for them supervised it okay

796
00:37:57,740 --> 00:38:10,939
and I'll cut it off here so how do we

797
00:38:08,040 --> 00:38:13,860
solve this problem of go secure requires

798
00:38:10,940 --> 00:38:17,430
passwords and pre-shared keys and things

799
00:38:13,860 --> 00:38:20,190
like that to make SD cards for the

800
00:38:17,430 --> 00:38:23,279
Raspberry Pi client server we do it by

801
00:38:20,190 --> 00:38:26,580
using Jinja templating so in a ginger

802
00:38:23,280 --> 00:38:29,370
template plain text password is a

803
00:38:26,580 --> 00:38:31,880
reference to a variable the variable is

804
00:38:29,370 --> 00:38:34,020
in the environment switch environments

805
00:38:31,880 --> 00:38:36,780
regenerate you have a different value

806
00:38:34,020 --> 00:38:38,850
it's the output of the templating that

807
00:38:36,780 --> 00:38:47,190
has a secret in it so what we're gonna

808
00:38:38,850 --> 00:38:50,100
do is we have the cloud - config client

809
00:38:47,190 --> 00:38:53,760
J - and server J - they're slightly

810
00:38:50,100 --> 00:38:57,150
different you can get fancy and put them

811
00:38:53,760 --> 00:39:02,520
all in one with logic but not doing that

812
00:38:57,150 --> 00:39:04,890
oops and go secure has the helper make

813
00:39:02,520 --> 00:39:06,630
file so it's a little bit easier to

814
00:39:04,890 --> 00:39:08,460
remember what the commands are or

815
00:39:06,630 --> 00:39:10,470
someone who's doing this for the first

816
00:39:08,460 --> 00:39:15,040
time it's simplified we're gonna create

817
00:39:10,470 --> 00:39:16,779
the client and the server templates to

818
00:39:15,040 --> 00:39:18,850
prove that the files are created outside

819
00:39:16,780 --> 00:39:21,190
the repo create a marker and the temp

820
00:39:18,850 --> 00:39:23,009
directory run the find command looking

821
00:39:21,190 --> 00:39:25,660
for files in the dot secrets

822
00:39:23,010 --> 00:39:27,850
subdirectory and the current working

823
00:39:25,660 --> 00:39:29,310
directory and there's nothing that's

824
00:39:27,850 --> 00:39:32,560
newer because we just created the marker

825
00:39:29,310 --> 00:39:36,070
create the cloud config say make cloud -

826
00:39:32,560 --> 00:39:37,779
config use the templates there is a

827
00:39:36,070 --> 00:39:40,000
mechanism to get a temp directory

828
00:39:37,780 --> 00:39:42,250
created in the environment so that you

829
00:39:40,000 --> 00:39:46,810
can store the file with the secrets

830
00:39:42,250 --> 00:39:48,670
temporarily templating puts the secrets

831
00:39:46,810 --> 00:39:50,020
in the file so this is the kind of thing

832
00:39:48,670 --> 00:39:58,140
that would accidentally get committed to

833
00:39:50,020 --> 00:40:07,890
github and prove it's not there and

834
00:39:58,140 --> 00:40:07,890
we're good so yes

835
00:40:10,270 --> 00:40:18,710
you say environments path gives you the

836
00:40:15,859 --> 00:40:21,470
path of the environment add the tempter

837
00:40:18,710 --> 00:40:31,820
option creates the drifter directory if

838
00:40:21,470 --> 00:40:34,368
it doesn't exist returns a path so sum

839
00:40:31,820 --> 00:40:37,040
of everything up you can protect with

840
00:40:34,369 --> 00:40:38,720
policy you can run truffle hog to detect

841
00:40:37,040 --> 00:40:41,390
but you're still gonna have some

842
00:40:38,720 --> 00:40:43,759
problems so being prepared to respond

843
00:40:41,390 --> 00:40:46,730
and having tools to make that easy is

844
00:40:43,760 --> 00:40:49,190
super important all these different

845
00:40:46,730 --> 00:40:50,660
tools exist Python secrets now exists

846
00:40:49,190 --> 00:40:53,119
getting people to use them is really

847
00:40:50,660 --> 00:40:55,759
hard so I'm encouraging everybody here

848
00:40:53,119 --> 00:40:58,000
to reach out to anyone you know who

849
00:40:55,760 --> 00:41:00,349
works in some open source project and

850
00:40:58,000 --> 00:41:02,270
try to convince them to think about

851
00:41:00,349 --> 00:41:04,070
changing the way they're doing things to

852
00:41:02,270 --> 00:41:08,000
avoid the default password problem at

853
00:41:04,070 --> 00:41:11,960
least and it's going to take some time

854
00:41:08,000 --> 00:41:13,880
some documentation will be necessary so

855
00:41:11,960 --> 00:41:16,250
I'm just we're encouraging everybody

856
00:41:13,880 --> 00:41:18,410
here to get involved the slides will be

857
00:41:16,250 --> 00:41:20,390
published in a little bit links to all

858
00:41:18,410 --> 00:41:23,180
these resources including I was talking

859
00:41:20,390 --> 00:41:26,060
about the ansible dims playbooks for

860
00:41:23,180 --> 00:41:28,220
setting up small scale distributed open

861
00:41:26,060 --> 00:41:32,810
source system I'm still in the process

862
00:41:28,220 --> 00:41:34,759
of integrating p-set into that so get

863
00:41:32,810 --> 00:41:39,369
involved help out a little request

864
00:41:34,760 --> 00:41:39,369
encouraged so any questions

865
00:41:44,400 --> 00:41:48,170
all right I guess everybody's hungry

866
00:41:57,320 --> 00:42:01,369
[Applause]

