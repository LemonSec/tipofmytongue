1
00:00:00,000 --> 00:00:13,349
so yeah these are

2
00:00:15,600 --> 00:00:22,470
Christian we are both from emory
university we are PhD researchers and we

3
00:00:22,470 --> 00:00:23,849
work with sound

4
00:00:23,850 --> 00:00:30,090
my background is in architecture and his
background music and sound design so I

5
00:00:30,090 --> 00:00:34,980
am interested in space and how space is
used and how sound actually is part of

6
00:00:34,980 --> 00:00:39,629
this kind of use of the space and so
we'd like to present you some of the

7
00:00:39,629 --> 00:00:45,180
project we are working on and some we
are working on previously and some

8
00:00:45,180 --> 00:00:53,040
future directions as well so there's a
an important component that is the

9
00:00:53,040 --> 00:01:00,510
design methodology for this kind of
objects which are very physical and

10
00:01:00,510 --> 00:01:05,339
their the way to be played it really
depends by how they are design and how

11
00:01:05,339 --> 00:01:08,339
the sound is designed as well so we're
going to talk about

12
00:01:09,090 --> 00:01:18,000
the technology we use for for these
objects so the first creation is a is a

13
00:01:18,000 --> 00:01:18,750
broom

14
00:01:18,750 --> 00:01:24,090
so there's an arduino which is
controlling all the input from the

15
00:01:24,090 --> 00:01:25,580
sensors a

16
00:01:25,580 --> 00:01:31,580
on this room including an accelerometer
and an embedded speaker and the idea was

17
00:01:31,580 --> 00:01:37,220
to create a sensitive object which could
interact with the space and was an

18
00:01:37,220 --> 00:01:42,350
everyday object which every person could
use but I was mostly interested in how

19
00:01:42,350 --> 00:01:47,990
the interaction with the floor and the
space could come out of the explicity of

20
00:01:47,990 --> 00:01:53,270
the instruments so I tested this model
library for your time audio on arduino

21
00:01:53,270 --> 00:01:54,610
and

22
00:01:54,610 --> 00:02:00,940
and later I changed a bit the design of
the interaction including a distance

23
00:02:00,940 --> 00:02:04,240
sensor to control the peach and

24
00:02:04,240 --> 00:02:10,179
some kind of gesture sensing as well and
you can see some examples from the video

25
00:02:10,179 --> 00:02:21,430
in a minute

26
00:02:21,430 --> 00:02:24,430
so there was an error in the data

27
00:02:25,090 --> 00:02:28,750
and so we're going to do an imitation of
those people look for one

28
00:02:36,310 --> 00:02:43,030
and after these experiments I went into
like trying different time from for this

29
00:02:43,030 --> 00:02:46,930
instrument but I was really interested
in what people could think if you

30
00:02:46,930 --> 00:02:51,220
actually play an instrument like this in
a normal house and what can happen so I

31
00:02:51,220 --> 00:02:56,769
have many interesting opinions from my
musicians friends which thought i was a

32
00:02:56,769 --> 00:02:57,849
bit crazy

33
00:02:57,849 --> 00:03:06,190
so I'm just her well go back to write on

34
00:03:13,670 --> 00:03:14,569
ok

35
00:03:14,569 --> 00:03:22,939
so yeah I already said that the second
experiment was all that with lead auto

36
00:03:22,939 --> 00:03:28,430
and in this case we wanted to experiment
with a kind of skeleton track him from

37
00:03:28,430 --> 00:03:36,560
connect and we wanted to create an alter
ego me during a movement or a user and

38
00:03:36,560 --> 00:03:40,849
in this case the user had to become part
of this kind of dialogue this a

39
00:03:40,849 --> 00:03:46,548
performative interaction in front of
this image so the participant in this

40
00:03:46,549 --> 00:03:49,010
case was becoming

41
00:03:49,010 --> 00:03:52,939
the puppet master in a sense and a day

42
00:03:53,959 --> 00:03:59,239
the shadow created by the object and the
lights and also the sound was part of

43
00:03:59,239 --> 00:04:02,810
the performance so when people could
come and see this scene they were

44
00:04:02,810 --> 00:04:06,319
thinking about what's going on and they
wanted to be part of this kind of

45
00:04:06,319 --> 00:04:13,010
dialogue and the interesting thing is
that the object was kind of fascinating

46
00:04:13,010 --> 00:04:18,649
in a sense but also made by a very
common materials as bubble wrap it was

47
00:04:18,649 --> 00:04:24,080
clearly are closed anger with an arduino
and some servo motors which also produce

48
00:04:24,080 --> 00:04:27,150
sound which was very creepy and

49
00:04:27,150 --> 00:04:33,960
the sound i decided to program in super
collider I used already existing flute

50
00:04:33,960 --> 00:04:39,508
patch but was creating kind of different
picture sound so when you were waving

51
00:04:39,509 --> 00:04:46,199
your your arms in the air then you were
creating like spooky sounds kind of 80

52
00:04:46,199 --> 00:04:51,930
and you also have a video to show next

53
00:04:59,250 --> 00:05:06,000
so I really seem like a ghost everyone's
fine

54
00:05:06,000 --> 00:05:13,500
haha and it was really at in terms of
understanding i was working

55
00:05:13,500 --> 00:05:18,090
it was very clear to to see all the
connection which was also part of the of

56
00:05:18,090 --> 00:05:21,960
the design of the of the peace in this
case the like the

57
00:05:22,610 --> 00:05:36,560
in this case the kinect was in a black
box below the the wings so we used to

58
00:05:36,560 --> 00:05:40,610
call them kinetic wings at the beginning
so we were experimenting with kind of

59
00:05:40,610 --> 00:05:46,069
response of structures and and then we
decided to like play a bit on this kind

60
00:05:46,069 --> 00:05:50,030
of person implication of the character
playing in front of you you were also

61
00:05:50,030 --> 00:05:56,239
animating and we use open and I for the
kinect libraries and processing so

62
00:05:56,240 --> 00:06:03,439
processing was sending video messages to
arduino and and from these i will leave

63
00:06:03,439 --> 00:06:09,319
like that it

64
00:06:09,319 --> 00:06:12,830
okay so I'm gonna talk about this one
briefly now

65
00:06:12,830 --> 00:06:17,688
so this instrument is called the air
harp and so the idea behind the Earhart

66
00:06:17,689 --> 00:06:21,770
was that the desert the trees and he
started out as a mystery box project

67
00:06:22,460 --> 00:06:26,299
so the idea is that you had a box on the
table and I was all up to the person

68
00:06:26,300 --> 00:06:30,440
interacting with the box to figure out
how to play this instrument and and I

69
00:06:30,440 --> 00:06:34,339
really wanted to design something that
allows the person to make music

70
00:06:35,060 --> 00:06:41,120
pick it up and make music with in less
than 10 seconds basically so this is the

71
00:06:41,120 --> 00:06:44,210
way that you interact with the
instrument and I like to try and give

72
00:06:44,210 --> 00:06:47,210
you a live demo first

73
00:06:52,710 --> 00:06:55,710
yeah

74
00:06:58,630 --> 00:06:59,370
yeah

75
00:06:59,370 --> 00:07:02,370
yeah

76
00:07:03,729 --> 00:07:09,400
so basically it's completely embedded so
battery speakers and all this are in the

77
00:07:09,400 --> 00:07:16,719
box or nine physically model strings
going across the length of the box and

78
00:07:16,719 --> 00:07:21,490
under some physics simulation which
changes the position of the string of

79
00:07:21,490 --> 00:07:24,909
the object which in turn plucks the
strings based on the orientation of the

80
00:07:24,909 --> 00:07:27,909
device

81
00:07:33,569 --> 00:07:36,340
yeah

82
00:07:36,340 --> 00:07:38,780
yeah

83
00:07:38,780 --> 00:07:41,030
yeah

84
00:07:41,030 --> 00:07:42,750
yeah

85
00:07:42,750 --> 00:07:49,650
ok so the idea is that the interaction
should be very very natural and very

86
00:07:49,650 --> 00:07:53,700
easy to understand this is also the
second generation of the air Harper eat

87
00:07:53,700 --> 00:07:58,560
laser cut this nice front panel reason
we did this actually was to let the

88
00:07:58,560 --> 00:08:02,310
sound come out of the box because
initially we just had one single f-hole

89
00:08:02,310 --> 00:08:06,060
on the front and that was nowhere near
loud enough to amplify the instrument

90
00:08:06,060 --> 00:08:09,660
and so he was just quickly how it works

91
00:08:09,660 --> 00:08:16,860
we've got a virtual mass on two Springs
and and as you tilt the box we can

92
00:08:16,860 --> 00:08:22,470
derive the resulting gravity forces that
would need to push this mass across the

93
00:08:22,470 --> 00:08:28,380
strings and this is all there is to it
basically and use this picture of the

94
00:08:28,380 --> 00:08:32,849
inside we've got a single accelerometer
belabor it but i'll come back to later

95
00:08:32,849 --> 00:08:39,000
battery and two speakers and a line out
and the potentiometer that does nothing

96
00:08:41,099 --> 00:08:45,780
ok and i think i just went through all
of this

97
00:08:46,350 --> 00:08:53,610
ok so physical physical modeling of
sound is really useful for this kind of

98
00:08:53,610 --> 00:08:57,870
thing because it does a lot of the work
for you just tell it and I'm gonna put

99
00:08:57,870 --> 00:09:02,490
in this much for us and it's going to
behave exactly how I expected to within

100
00:09:02,490 --> 00:09:07,650
the constraints of this physical
simulation but i found especially coming

101
00:09:07,650 --> 00:09:11,400
from a sound design background that this
is often not enough and I wanted to be

102
00:09:11,400 --> 00:09:16,110
able to perform environmental sounds as
if i was performing an instrument and so

103
00:09:16,110 --> 00:09:21,000
here's a picture of some of the spraying
wd-40 on a door hinge and I say no don't

104
00:09:21,000 --> 00:09:25,740
do that because i can use it for making
synthesizers

105
00:09:25,740 --> 00:09:28,140
so the idea with this project was too

106
00:09:28,140 --> 00:09:34,680
use the trackpad to a very simple input
mechanism to produce squeaky door sounds

107
00:09:34,680 --> 00:09:39,660
and so there are two approaches you can
take you can use either physically model

108
00:09:39,660 --> 00:09:44,640
the entire system and here are some
papers that use equations straight from

109
00:09:44,640 --> 00:09:49,680
tectonic seismic research to produce the
sound of friction

110
00:09:49,680 --> 00:09:55,349
I took a different approach to this
which is too kind of approach the sound

111
00:09:55,350 --> 00:10:01,170
of a door like a synthesizer kind of
like a modular synthesizer and where

112
00:10:01,170 --> 00:10:04,650
instead of thinking about physical
processes you're thinking about

113
00:10:04,650 --> 00:10:09,930
oscillators and filters any name your
parameters according to what you think

114
00:10:09,930 --> 00:10:14,069
it sounds like that's a bit of a stretch
of design process

115
00:10:14,070 --> 00:10:17,220
so this is the block diagram for a
squeaky door model

116
00:10:17,220 --> 00:10:21,810
I've got an impulse train generators
amplitude modulation bunch of band pass

117
00:10:21,810 --> 00:10:28,890
filters and resonators and i should say
this model was developed based on Andy

118
00:10:28,890 --> 00:10:31,140
Fornells prototype

119
00:10:31,140 --> 00:10:39,480
so just play a video of this so over
here you can see the trackpad position

120
00:10:39,480 --> 00:10:43,230
the position of my fingers I played it
and here you can see the parameters

121
00:10:43,230 --> 00:10:46,230
moving and how they are mapped to the
parameters

122
00:10:56,670 --> 00:11:02,430
yeah

123
00:11:07,450 --> 00:11:16,030
yeah

124
00:11:17,690 --> 00:11:21,500
yeah

125
00:11:21,500 --> 00:11:24,400
one

126
00:11:24,400 --> 00:11:27,400
yeah

127
00:11:28,750 --> 00:11:32,380
okay i won't play the whole video but
you can look it up later

128
00:11:32,380 --> 00:11:44,680
watch yourself and okay that's wrong
title basically and so the model was

129
00:11:44,680 --> 00:11:49,630
designed in pure data and we use touch
size from a surface to control the model

130
00:11:49,630 --> 00:11:55,660
and and the main thing here is that if
you want to perform environmental sound

131
00:11:55,660 --> 00:12:00,430
don't necessarily go for physics
simulation in think about it more like a

132
00:12:00,430 --> 00:12:09,339
synthesizer notice and over back to last
year after those experiments you so

133
00:12:09,340 --> 00:12:15,670
before i decided to start being a
serious person and do some that kind of

134
00:12:15,670 --> 00:12:18,620
sounds kept research in

135
00:12:18,620 --> 00:12:23,900
related to architecture and so I decided
in London to look at the other advantage

136
00:12:23,900 --> 00:12:27,140
because of the architecture there

137
00:12:28,400 --> 00:12:34,819
the river and a lot of green and so I
was interested in how a location which

138
00:12:34,820 --> 00:12:40,340
is quite known and use that are
restorative place by many people

139
00:12:40,340 --> 00:12:44,180
including to this could be understood in
a different way

140
00:12:44,780 --> 00:12:49,160
just because of its sound and so I
organized the sound work which is part

141
00:12:49,160 --> 00:12:52,459
of my PhD research whose updates you can
see at this link

142
00:12:54,339 --> 00:12:59,769
and I decided to embed the recordings in
an interactive objects and i decided to

143
00:12:59,769 --> 00:13:02,769
use fabric for days

144
00:13:03,840 --> 00:13:10,770
the the idea behind the fabric is that
you can immerse yourself in this

145
00:13:10,770 --> 00:13:17,970
situation recorded by someone else just
catching the correspondent buildings and

146
00:13:17,970 --> 00:13:22,140
this is possible because i used
conductive thread and an embroidery

147
00:13:22,140 --> 00:13:26,760
machine we have but it can be possible
so just doing my hand and so for every

148
00:13:26,760 --> 00:13:33,300
one of these places i associated one of
the recordings i made so this can be

149
00:13:33,300 --> 00:13:40,770
done with that because that allows you
to to detect the the touch and also to

150
00:13:40,770 --> 00:13:45,329
do some nice fading which is very
natural and it's why I wanted for this

151
00:13:45,330 --> 00:13:51,540
object because after the strange sounds
coming out of the first two pieces i

152
00:13:51,540 --> 00:13:57,750
want to something a bit more relaxing to
be my part of my research and so in this

153
00:13:57,750 --> 00:14:03,630
case you have the surface of the fabric
which is kind of the conductive part you

154
00:14:03,630 --> 00:14:08,760
can touch and then there's a layer of
insulating fat fabric with some holes

155
00:14:08,760 --> 00:14:11,750
and then the same capacity of part

156
00:14:11,750 --> 00:14:17,330
which is sensing the touch goes to
traces which go to this red ball

157
00:14:17,330 --> 00:14:20,030
mpr 121

158
00:14:20,030 --> 00:14:24,290
and so I had to stitch all these wires
and put them in place that and

159
00:14:24,290 --> 00:14:30,829
everything is going through I square C -
Bella and this had me like program in

160
00:14:30,830 --> 00:14:35,630
the code to to read these things in real
time but it was amazing that everything

161
00:14:35,630 --> 00:14:40,700
could work just by plugging the cables
because the fabric is actually really

162
00:14:40,700 --> 00:14:47,000
resistant compared to some other
electronics and so in this case there's

163
00:14:47,000 --> 00:14:53,780
a strong meaning because I'm trying to
look for interfaces that i can bring to

164
00:14:53,780 --> 00:15:00,199
other people which are not so familiar
with what I'm researching which is sound

165
00:15:00,200 --> 00:15:05,060
and acoustics related to architecture
and try to to bring something intuitive

166
00:15:05,060 --> 00:15:11,119
to them and this is also what i like the
methodology of use for another project

167
00:15:12,790 --> 00:15:14,750
so I went a

168
00:15:14,750 --> 00:15:20,960
- China recently and we were supposed to
be music boxes in a local village

169
00:15:21,590 --> 00:15:23,990
so I was really interested in

170
00:15:23,990 --> 00:15:29,750
like the sound environmental sound there
because it was very relaxing with

171
00:15:29,750 --> 00:15:33,589
mountains and river but also i was
interested in the local music so i

172
00:15:33,589 --> 00:15:36,920
decided to record this sounds from local
people and

173
00:15:37,550 --> 00:15:44,329
My partner in in this project is Shannon
she wanted to have this music box is

174
00:15:44,330 --> 00:15:48,529
very tiny objects projecting shadows and
the shadows was supposed to be the

175
00:15:48,529 --> 00:15:54,769
lookout decoration patterns that they
also use in weaving and so after some

176
00:15:54,769 --> 00:15:59,870
research the project had to be delivered
in 7 days basically and so I try to find

177
00:15:59,870 --> 00:16:05,089
the the easiest way to to to be able to
have local people interacting with these

178
00:16:05,089 --> 00:16:10,670
objects and and see the reactions and so
I using this case arduino and other

179
00:16:10,670 --> 00:16:13,649
fruit soundboard

180
00:16:13,649 --> 00:16:19,559
and an accelerometer and so everything
had to be embedded in this box but the

181
00:16:19,559 --> 00:16:25,800
interaction should be like really
straightforward and it work well because

182
00:16:25,800 --> 00:16:29,309
even kids could get it easily

183
00:16:30,509 --> 00:16:34,529
I have no sound

184
00:16:39,860 --> 00:16:41,840
yeah

185
00:16:41,840 --> 00:16:44,870
yeah

186
00:16:44,870 --> 00:16:47,430
yeah

187
00:16:47,430 --> 00:16:50,670
so then the city media to me

188
00:16:50,670 --> 00:16:54,329
there was this other feature you could
connect your boxes and play another song

189
00:16:54,330 --> 00:17:01,740
just by sensing a magnet and it was
really interesting for various boxes in

190
00:17:01,740 --> 00:17:04,150
the spaces in there

191
00:17:04,150 --> 00:17:09,880
like social ax space is just used for
gathering and talk about local affairs

192
00:17:09,880 --> 00:17:15,400
of village and just sleep there were
checking relax and they were really

193
00:17:15,400 --> 00:17:19,510
interested in hearing of course their
music and they said the object is too

194
00:17:19,510 --> 00:17:24,010
simple for us we want our declaration
you have to cut something on the sides

195
00:17:24,010 --> 00:17:28,420
because we we don't really recognize
this cube at something which is ours and

196
00:17:28,420 --> 00:17:34,840
so I needed to to be helped by a girl
another design student explaining what

197
00:17:34,840 --> 00:17:40,720
they were seeing and was interesting to
see how different people also we're

198
00:17:40,720 --> 00:17:45,370
giving different advice on the box so
they were saying but all that is going

199
00:17:45,370 --> 00:17:46,840
to be really expensive

200
00:17:46,840 --> 00:17:54,550
you know you don't have too much money
for the hands of time and yeah so let's

201
00:17:54,550 --> 00:17:55,450
see

202
00:17:55,450 --> 00:17:59,440
so you just rotate the side entry into
the song and then put it back to its

203
00:17:59,440 --> 00:18:01,710
original position then

204
00:18:01,710 --> 00:18:08,010
it stops working so it's really simple
thing but I thought that for my case

205
00:18:08,010 --> 00:18:12,240
it's important like to do more in the
research part by gathering the right

206
00:18:12,240 --> 00:18:15,929
sounds and then giving the design to the
minimal

207
00:18:15,929 --> 00:18:21,690
ok then I will go back to the
presentation which is still

208
00:18:23,010 --> 00:18:26,669
yeah okay

209
00:18:32,360 --> 00:18:36,139
well I'll talk about the lightsaber in
the second but basically well let's see

210
00:18:36,140 --> 00:18:41,570
i was doing all this amazing soundscape
research and I was in my research group

211
00:18:41,570 --> 00:18:46,428
developing the sports called Bella which
is a audio platform that works with the

212
00:18:46,429 --> 00:18:52,460
BeagleBone audio framework reading and
and this is what we've been using

213
00:18:52,460 --> 00:18:56,720
philosophies projects have been talking
about basically and so the nice thing

214
00:18:56,720 --> 00:19:02,179
about this board is that you've got
extremely low latency audio outputs that

215
00:19:02,179 --> 00:19:07,190
means if you press a button it will take
you less than some two milliseconds or

216
00:19:07,190 --> 00:19:11,390
less in milliseconds sometimes for the
sounds to come out of it which is very

217
00:19:11,390 --> 00:19:16,940
fast and also the sensor band with the
resolution is very high and the sensor

218
00:19:16,940 --> 00:19:22,070
unlock sensor sampling rate is very high
as well which is a moderate so this

219
00:19:22,070 --> 00:19:28,549
allows us to make some very very the
objects with a very very high level of

220
00:19:28,549 --> 00:19:32,418
expressivity in the interaction so to
demonstrate this

221
00:19:32,419 --> 00:19:37,070
we built a lightsaber so you might
notice that this light saver

222
00:19:37,640 --> 00:19:41,840
doesn't look like lightsaber is just a
card for two and this because we want to

223
00:19:41,840 --> 00:19:48,649
focus only on the sound we were
interested in the lights and so on and

224
00:19:48,650 --> 00:19:53,929
so the way this works is we've got bail
on side one end of the tube and the

225
00:19:53,929 --> 00:20:00,530
battery and and these are all the
components that were using so we've got

226
00:20:00,530 --> 00:20:02,690
the next parameter over here

227
00:20:02,690 --> 00:20:10,390
a piezo desk over here speaker our
billboards and the battery and

228
00:20:10,390 --> 00:20:15,610
so we use the PSO disk to detect hits on
the sword so when you're swinging the

229
00:20:15,610 --> 00:20:18,550
sword around then he hit against the
surface will go

230
00:20:18,550 --> 00:20:24,010
you know and and as you move around with
the accelerometer we use that to be

231
00:20:24,010 --> 00:20:28,270
integrated the experimental value to get
a velocity reading and we use that to

232
00:20:28,270 --> 00:20:35,860
produce the iconic lightsaber sounds and
i'll just play a quick video which i may

233
00:20:35,860 --> 00:20:37,090
skip through a little bit

234
00:20:37,090 --> 00:20:40,090
which explains how this works

235
00:20:52,940 --> 00:20:57,680
so the lightsabres on the most iconic
sound effects everybody knows

236
00:20:57,680 --> 00:21:01,850
lightsaber from their childhoods and
that's going to sports now these delay

237
00:21:01,850 --> 00:21:10,459
lines are variable delay so okay so
basically what we did was we just got

238
00:21:10,460 --> 00:21:13,190
back here

239
00:21:13,190 --> 00:21:17,690
ok so one ben burtt designed lightsabers
what he did was he played the sound of a

240
00:21:17,690 --> 00:21:22,160
TV hum coming through a speaker and then
used a very long microphone like a

241
00:21:22,160 --> 00:21:27,410
shotgun microphone and recorded the
output of the imitators of the swings of

242
00:21:27,410 --> 00:21:34,640
the of the jetta is with their
lightsabers in the film and and we

243
00:21:34,640 --> 00:21:41,540
replicated this process inside . data
and are you familiar with pure data for

244
00:21:41,540 --> 00:21:45,800
those who are in that's basically a
digital processing language of visual

245
00:21:45,800 --> 00:21:50,330
language reconnect lot of components to
each other with cables and and we can

246
00:21:50,330 --> 00:21:54,379
use the Sun bill basically so we were
produced this idea of Doppler effect

247
00:21:54,380 --> 00:22:03,740
delay lines and and movements using the
pea patch and and then assembled at all

248
00:22:03,740 --> 00:22:10,100
inside light saver cardboard tube and
unfortunately we don't have that one

249
00:22:10,100 --> 00:22:21,020
with us to demo today I'm just going to
move straight on here which is i'll just

250
00:22:21,020 --> 00:22:24,350
quickly wrap up this actually so
basically and what we're interested in

251
00:22:24,350 --> 00:22:28,730
is how does it feel to interact with the
lightsaber when you have this low

252
00:22:28,730 --> 00:22:29,450
latency

253
00:22:29,450 --> 00:22:32,720
what would feel like if you actually had
a lightsaber it was sound like and so on

254
00:22:32,720 --> 00:22:38,630
and and this is something that was
really made possible through the low

255
00:22:38,630 --> 00:22:42,110
latency and through the high bandwidth
resolution sensor data

256
00:22:42,650 --> 00:22:47,510
ok so this is the final instrument will
show you today which is called we call

257
00:22:47,510 --> 00:22:50,200
it the van Gogh laser and

258
00:22:50,200 --> 00:22:57,040
also known as the shaker and and the
reason we called it the angular sizer

259
00:22:57,040 --> 00:23:02,170
was because we wanted to make an
instrument that contains literally just

260
00:23:02,170 --> 00:23:06,760
next door ometer a bale aboard the
speaker and the battery so something is

261
00:23:06,760 --> 00:23:18,070
holed up something that you just
requires the most minimal kind of

262
00:23:18,070 --> 00:23:21,070
interaction basically so

263
00:23:34,620 --> 00:23:40,770
and so a couple of stories for it
basically we started by making a

264
00:23:40,770 --> 00:23:45,690
synthesizer that emulated vanghele
soundtrack to Blade Runner and the

265
00:23:45,690 --> 00:23:49,800
synthesizer settings he had and then
what we did then was we had a very I

266
00:23:49,800 --> 00:23:54,960
derivative rapid process of switching
between the patch designing the sound

267
00:23:54,960 --> 00:24:02,550
and designing the sensor mappings to the
sound and and because sound and sensor

268
00:24:02,550 --> 00:24:05,940
you don't we distinguish between them
when you're programming for a platform

269
00:24:05,940 --> 00:24:13,020
like this and that made it very easy to
prototype stuff very fast and so

270
00:24:13,020 --> 00:24:18,210
basically what i'm trying to say with
this one is that if you have very very

271
00:24:18,210 --> 00:24:22,230
rapid very i trace of design then you
may end up with some strange results but

272
00:24:22,230 --> 00:24:25,110
it will be very very carefully designed
because you've had a very very short

273
00:24:25,110 --> 00:24:26,610
durations

274
00:24:26,610 --> 00:24:35,100
ok so just wrap it up here are some
little nuggets of wisdom we thought we'd

275
00:24:35,100 --> 00:24:40,590
collected by am working on these
instruments so it keep it simple and

276
00:24:40,590 --> 00:24:46,439
there's an enormous amount you can do
with just one single sensor almost all

277
00:24:46,440 --> 00:24:50,760
of these instruments show today work
with one single sensor or two sensors

278
00:24:50,760 --> 00:24:56,790
and we find that constraints are often
extremely useful and making an engaging

279
00:24:56,790 --> 00:25:02,520
experience also have this desire to
experience in your mind when you design

280
00:25:02,520 --> 00:25:07,950
the instruments and obviously people
will misuse it or use it and I expected

281
00:25:07,950 --> 00:25:12,720
ways but you've got one design principle
in mind then you'll come up with

282
00:25:12,720 --> 00:25:18,660
something very strong and don't buy us
to focus just on the sensors are just in

283
00:25:18,660 --> 00:25:19,620
the synthesizer

284
00:25:19,620 --> 00:25:24,389
but think of the whole instrument as a
whole and and it will help

285
00:25:24,390 --> 00:25:26,940
otherwise it's very easy to forget about

286
00:25:26,940 --> 00:25:31,590
and you know how am I going to map the
sensor range to this parameter and oh

287
00:25:31,590 --> 00:25:36,419
actually doesn't actually sound the way
I expected it to and so forth and and

288
00:25:36,420 --> 00:25:37,740
finally as i said before

289
00:25:37,740 --> 00:25:40,440
make sure you're comfortable with your
design and development environment and

290
00:25:40,440 --> 00:25:42,780
make sure you have a fast

291
00:25:42,780 --> 00:25:47,520
the ability to fast I durations so the
more quickly you can see the results of

292
00:25:47,520 --> 00:25:51,750
what your prototype think the better
your results will be and I think that is

293
00:25:51,750 --> 00:25:52,920
all of it from us

294
00:25:52,920 --> 00:25:59,520
thank you

295
00:26:01,200 --> 00:26:06,480
when how much can i just ask is the next
speaker in the room like okay if you

296
00:26:06,480 --> 00:26:11,850
want to come up and you could ask if
anybody's got one question that they

297
00:26:11,850 --> 00:26:13,139
want to ask

298
00:26:13,139 --> 00:26:18,360
ok this person here hi

299
00:26:18,360 --> 00:26:21,360
when you think about a musical
instrument

300
00:26:21,360 --> 00:26:24,779
one of the things about an instrument is
predictability I mean I know if I do

301
00:26:24,779 --> 00:26:28,649
this thing i will get this response each
and every time and that would enable me

302
00:26:28,649 --> 00:26:32,729
to perform and have the same thing
happened several times most of the

303
00:26:32,730 --> 00:26:36,570
things you show me seem to be much more
like I don't know what's going to happen

304
00:26:36,570 --> 00:26:40,918
I mean could just be an instrument that
someone could perform and consistently

305
00:26:40,919 --> 00:26:43,289
produce a repeated outcome

306
00:26:43,289 --> 00:26:50,700
you know ok ok so and yeah the
instruments showed there was an element

307
00:26:50,700 --> 00:26:54,450
of unpredictability and they are
actually designed some of them on the

308
00:26:54,450 --> 00:26:59,730
principle of I am I don't know what this
thing is but i want to be able to find

309
00:26:59,730 --> 00:27:05,309
out very quickly what it is and because
they're unpredictable in the first in

310
00:27:05,309 --> 00:27:10,470
this discovery face doesn't mean that
they're in controllable it that still

311
00:27:10,470 --> 00:27:13,260
means they can learn how to use these
instruments so for example of Angola

312
00:27:13,260 --> 00:27:19,200
sizer with the shaker and a few days
after we design that we realized all we

313
00:27:19,200 --> 00:27:22,529
can do this twisty thing and it sounds
like a pity Otto string orchestra

314
00:27:22,529 --> 00:27:28,620
basically and and this and that is
completely repeatable and the same

315
00:27:28,620 --> 00:27:31,350
applies to lots of the other instruments
as well

316
00:27:31,350 --> 00:27:32,080
and

317
00:27:32,080 --> 00:27:38,740
so I don't know the answer the question
but basically if you design it carefully

318
00:27:38,740 --> 00:27:43,299
it will be controlled and repeatable it
may be strange but it's repeatable and

319
00:27:43,299 --> 00:27:44,679
you can become good at it

320
00:27:44,679 --> 00:27:50,529
and so we're going to have these two
instruments around if you want to play

321
00:27:50,529 --> 00:27:53,529
with them and it's thank you very much

322
00:27:57,130 --> 00:27:57,880
yeah

