1
00:00:08,380 --> 00:00:10,750
I just liked and the word

2
00:00:10,750 --> 00:00:13,960
hi everybody

3
00:00:13,960 --> 00:00:15,820
I want to say thank you to

4
00:00:15,820 --> 00:00:21,939
July four give you a really good
architectural review Android I've

5
00:00:21,939 --> 00:00:25,720
actually been through our two hour long
presentations are pretty much every

6
00:00:25,720 --> 00:00:31,270
topic that he covered so to cover that
much material that quickly is really

7
00:00:31,270 --> 00:00:40,989
impressive a way for someone introduced
myself my online here pretty picture I

8
00:00:40,989 --> 00:00:46,120
mean items next role of each I remember
I was one of the founding members of the

9
00:00:46,120 --> 00:00:51,390
Android security team and andrea was
really small win it was first really

10
00:00:51,390 --> 00:00:57,039
starting off I've been working on
laundry now for six almost seven years

11
00:00:57,039 --> 00:01:04,430
focus full-time on security efforts
under scary team is really diverse we

12
00:01:04,430 --> 00:01:06,660
cover a lot of different things

13
00:01:06,660 --> 00:01:11,990
malware analysis reverse engineering
stats analysis looking for bad behavior

14
00:01:11,990 --> 00:01:16,490
patching the device trying to break into
the device my job is tightened security

15
00:01:16,490 --> 00:01:23,199
lady so what does that mean that means
basically I am responsible for all the

16
00:01:23,200 --> 00:01:27,290
security properties of all the code that
runs the device the security model

17
00:01:27,290 --> 00:01:31,340
understanding how that interacts with
other parts of the system

18
00:01:31,340 --> 00:01:36,070
understand how that impacts of malware
overall trying to keep our users safe

19
00:01:36,070 --> 00:01:40,990
and also setting standards for the
industry to try to figure out what are

20
00:01:40,990 --> 00:01:44,689
the desirable security characteristics
and what is DNA and return some of the

21
00:01:44,689 --> 00:01:52,059
undesirable character character security
characteristics you'll see an Android in

22
00:01:52,060 --> 00:01:57,119
my role I actually have the opportunity
to touch millions of people I remember

23
00:01:57,119 --> 00:02:01,280
when I realized the change I had
committed to the entry code bases are

24
00:02:01,280 --> 00:02:07,740
running on Over $1,000,000,000 ice is a
really good feeling that I'm just one of

25
00:02:07,740 --> 00:02:11,820
many people that actually work on
Android on a day-to-day basis

26
00:02:11,820 --> 00:02:18,430
Andrew itself is a huge projects
certainly more than even just the

27
00:02:18,430 --> 00:02:20,819
numerical goal

28
00:02:20,819 --> 00:02:25,488
millions of lines of the open source
having truett andrade from developers

29
00:02:25,489 --> 00:02:29,010
who may or may not care about security
security may not be the first thing on

30
00:02:29,010 --> 00:02:33,060
their mind the people in this room or
security experts by the keyboard GPO

31
00:02:33,060 --> 00:02:38,450
experts compiler experts and this is all
code that we've made available one of

32
00:02:38,450 --> 00:02:43,540
the beauties of Android is the fact that
everything is open source people in this

33
00:02:43,540 --> 00:02:46,780
room can go into a hundred and get a
really solid understanding of why

34
00:02:46,780 --> 00:02:48,400
Android works the way it is

35
00:02:48,400 --> 00:02:51,900
look at the history look at how we've
changed things and I think that's one of

36
00:02:51,900 --> 00:02:55,169
the strengths of the Android ecosystem
that people want to they can understand

37
00:02:55,169 --> 00:02:57,840
what's going on they can understand and
modify it

38
00:02:57,840 --> 00:03:04,549
Andrew during and his presentation today
it was impressive to me just how he took

39
00:03:04,549 --> 00:03:09,199
a android data logging at the
instrumentation to it as able to drive a

40
00:03:09,199 --> 00:03:13,230
lot of characteristics and applications
is the kinds of innovations that we want

41
00:03:13,230 --> 00:03:19,819
to see thousands of devices have chosen
to use Android and something I'm really

42
00:03:19,819 --> 00:03:23,219
proud of and there are literally
hundreds of companies out there that are

43
00:03:23,219 --> 00:03:28,930
focused on security efforts for Android
and everybody in this room is in one way

44
00:03:28,930 --> 00:03:33,569
or another involving Andrew security and
so it's something that is really

45
00:03:33,569 --> 00:03:42,189
impressive to to see you a little bit
and talk about what is security what

46
00:03:42,189 --> 00:03:45,728
does it mean to be secure everybody in
this room has a different idea of what

47
00:03:45,729 --> 00:03:48,109
it means to be secure

48
00:03:48,109 --> 00:03:52,750
there's a popular joke in the computer
effort computer security practitioners

49
00:03:52,750 --> 00:04:00,129
that the only safe computer is one
that's unplug delia's life-and-death my

50
00:04:00,129 --> 00:04:04,078
co-workers look at the signing go
picking up that's not true for and

51
00:04:04,079 --> 00:04:09,259
remove batteries on the device and chat
on plugging hundred another security

52
00:04:09,259 --> 00:04:10,239
hole

53
00:04:10,240 --> 00:04:20,269
anyway the first lesson 11 goals I have
today it's to try to to distill lessons

54
00:04:20,269 --> 00:04:23,200
things that we've learned from adverse
security they think are applicable to

55
00:04:23,200 --> 00:04:28,950
the wider community but the first lesson
that want to convey today it's really

56
00:04:28,950 --> 00:04:34,200
fundamental everything that we doing
security is to some degree a compromise

57
00:04:34,200 --> 00:04:39,550
between security and functionality when
we enable something when we let people

58
00:04:39,550 --> 00:04:44,940
use their devices were implicitly
getting out some control over them

59
00:04:44,940 --> 00:04:50,960
we've been fortunate in that and it has
had years to try to figure out the right

60
00:04:50,960 --> 00:04:56,539
compromise between security and
functionality it's not something we

61
00:04:56,540 --> 00:05:00,420
always thought it's not something that
we always get right it's a continued to

62
00:05:00,420 --> 00:05:06,380
work in progress and trying to find the
right balance is hard and it actually

63
00:05:06,380 --> 00:05:15,969
there is an upper individual basis and I
wanted to find some of the the court

64
00:05:15,970 --> 00:05:22,240
things that drive our thinking and what
were you hoping to accomplish a lot of

65
00:05:22,240 --> 00:05:25,450
times when you think of security
solutions

66
00:05:25,450 --> 00:05:29,539
this is the picture that comes to mind
you have the security guard he's there

67
00:05:29,540 --> 00:05:33,890
the big signs something bad has happened
the classic example I think of his

68
00:05:33,890 --> 00:05:39,440
firewall software that is installed on
PCs they probably all my goodness your

69
00:05:39,440 --> 00:05:44,980
application is trying to connect to port
8080 parts of the allure to try to tell

70
00:05:44,980 --> 00:05:49,110
users hey something might be wrong it
right into some degree it tries to

71
00:05:49,110 --> 00:05:57,060
doesn't try to but has the effect of
instilling fear within the user times

72
00:05:57,060 --> 00:06:01,140
this year is an essay well-founded it
may not be the right kind of

73
00:06:01,140 --> 00:06:05,430
decision-making lodgings is also
minimally effective thing they catch

74
00:06:05,430 --> 00:06:10,090
things which are benign behavior don't
catch things which are which are things

75
00:06:10,090 --> 00:06:14,820
that people really should be concerned
about andrea has a different philosophy

76
00:06:14,820 --> 00:06:17,370
when it comes to security

77
00:06:17,370 --> 00:06:19,680
the most effective security and

78
00:06:19,680 --> 00:06:25,470
is invisible and just by running an
Android device you should feel a sense

79
00:06:25,470 --> 00:06:30,400
of calm that even if you take whatever
actions you take your data your

80
00:06:30,400 --> 00:06:34,380
confidential information is going to be
secure and since then the guiding

81
00:06:34,380 --> 00:06:39,120
philosophy behind Android we try to try
to make sure that the properties and

82
00:06:39,120 --> 00:06:44,440
read how are secured by default that we
protect uses right off the bat and we

83
00:06:44,440 --> 00:06:52,000
don't force users to make the necessary
decisions where they don't have till so

84
00:06:52,000 --> 00:06:58,550
how do we how do we actually do this how
do we actually bridge the gap and try to

85
00:06:58,550 --> 00:07:02,710
make it so we designed a system where
security is for front doors active

86
00:07:02,710 --> 00:07:07,280
involvement security people feel
protected but people aren't consciously

87
00:07:07,280 --> 00:07:11,609
involved when my mom runs Android she
shouldn't have to make decisions is

88
00:07:11,610 --> 00:07:16,470
accessing death and all say well I
somebody else's made that decision for

89
00:07:16,470 --> 00:07:24,659
her and hopefully it's a right on Sir
Richard gala I'm primarily gonna focus

90
00:07:24,659 --> 00:07:30,539
on the lower right hand corner talking
about one time security and talking

91
00:07:30,539 --> 00:07:36,250
about our sandbox information model how
do we implement security device basis

92
00:07:36,250 --> 00:07:40,360
but there's actually a lot about Android

93
00:07:40,360 --> 00:07:45,530
happens even before called gets to the
device

94
00:07:45,530 --> 00:07:50,380
take the classic example of malware and
Rory will talk a little bit about

95
00:07:50,380 --> 00:07:54,479
malware and whether Mauer's an actual
problem or not but you actually get

96
00:07:54,479 --> 00:07:57,789
malware onto the device you actually
have to go through a lot of different

97
00:07:57,789 --> 00:08:04,680
layers before you even get execution
Google Play is one of the is the first

98
00:08:04,680 --> 00:08:08,130
line of defense for users were
constantly reviewing apps were

99
00:08:08,130 --> 00:08:12,820
constantly making sure that aren't
exploiting security vulnerabilities are

100
00:08:12,820 --> 00:08:16,270
doing something bad were watching out
for the users best interests through

101
00:08:16,270 --> 00:08:19,789
Google Play and make sure that the
absolute system with our policy but of

102
00:08:19,789 --> 00:08:23,599
course and raise an open system we want
to make sure that people have choices

103
00:08:23,599 --> 00:08:26,979
about where to get out locations so we
allow side loading

104
00:08:26,980 --> 00:08:32,090
will even get to side loading you have
to go through dialogue would allow

105
00:08:32,090 --> 00:08:38,720
sideloading users aware of the potential
consequences but even then we rely on

106
00:08:38,720 --> 00:08:43,229
multiple layers of defeats so if you go
silent application which we know to be

107
00:08:43,229 --> 00:08:44,110
dangerous

108
00:08:44,110 --> 00:08:48,740
will inform you about what's going on we
allow you to make a choice and so one of

109
00:08:48,740 --> 00:08:51,590
the important security characteristics
and sure everybody in this room is

110
00:08:51,590 --> 00:08:56,050
familiar with is the the principle of
defense in depth we don't rely on anyone

111
00:08:56,050 --> 00:09:02,569
security control to to implement the
security features of Android users safe

112
00:09:02,570 --> 00:09:07,990
my presentation today is gonna be on the
lower right hand corner of the security

113
00:09:07,990 --> 00:09:10,960
runtime chats and the sandbox and
permission

114
00:09:10,960 --> 00:09:19,520
model in my mind Android there are four
pillars of security

115
00:09:19,520 --> 00:09:23,949
whenever we look at a security problem
whenever you look at security bug we try

116
00:09:23,950 --> 00:09:30,020
to answer four questions four goals how
can we prevent the bug from happening in

117
00:09:30,020 --> 00:09:34,140
the first place the best security bug is
someone that can never happen

118
00:09:34,140 --> 00:09:39,210
can we pull the battery from the device
that's not practical solution but other

119
00:09:39,210 --> 00:09:45,790
other changes we can make that
prevention is going to fail some quite

120
00:09:45,790 --> 00:09:52,099
so we thought that layers of its layers
of defense detection detection of the

121
00:09:52,100 --> 00:09:55,820
valuable tool that we have a choice that
are there things that we can do to

122
00:09:55,820 --> 00:10:00,500
increase our knowledge about security
bugs to make sure that we're aware of

123
00:10:00,500 --> 00:10:05,950
what's happening on device minimization
we know there's gonna be security bugs

124
00:10:05,950 --> 00:10:12,170
what can we do to make the security bugs
so they don't compromise the entire

125
00:10:12,170 --> 00:10:16,839
system so that the process is contained
so that we understand the

126
00:10:16,840 --> 00:10:22,140
characteristics when something bad goes
out when something bad happens and the

127
00:10:22,140 --> 00:10:24,630
reaction

128
00:10:24,630 --> 00:10:29,020
what do we do when something that goes
when something bad happens how do we

129
00:10:29,020 --> 00:10:33,660
address I really think any security
organization needs to have answers for

130
00:10:33,660 --> 00:10:37,930
these four questions are safer these
four strategies I want to go through

131
00:10:37,930 --> 00:10:47,650
what and reads answer for these four
strategies are the very first pillar of

132
00:10:47,650 --> 00:10:53,410
Android security is prevention we want
to make sure that we prevent it from

133
00:10:53,410 --> 00:10:57,860
happening before the user either has to
think about you just have to think about

134
00:10:57,860 --> 00:11:06,310
the people in this room here thinking
about it and read it does all the

135
00:11:06,310 --> 00:11:09,579
traditional approaches to security
prevention

136
00:11:09,580 --> 00:11:16,800
you'd expect from any matures charity
organization code reviews all of Android

137
00:11:16,800 --> 00:11:21,270
code is peer reviewed by another
engineer with an Android we make sure

138
00:11:21,270 --> 00:11:25,180
that that's been checked in

139
00:11:25,180 --> 00:11:30,469
regardless of the source has a second
set of eyes on it for code that special

140
00:11:30,470 --> 00:11:33,130
security sensitive will have engineering

141
00:11:33,130 --> 00:11:38,400
security teams which take a look at it
make sure that there's no problem with

142
00:11:38,400 --> 00:11:42,510
the total at least no problems that we
can find make sure that is consistent

143
00:11:42,510 --> 00:11:50,740
with what the security best practices in
addition to code arts design reuse does

144
00:11:50,740 --> 00:11:56,390
the future makes sense is a future going
to going to cause security issues on the

145
00:11:56,390 --> 00:12:03,209
device is security is is that code going
to

146
00:12:03,209 --> 00:12:07,979
violated users privacy in some way

147
00:12:07,980 --> 00:12:12,279
big focus of our scary team is on
outreach and education

148
00:12:12,279 --> 00:12:16,980
a lot of times we act as an internal
consulting organization for other people

149
00:12:16,980 --> 00:12:21,110
who are implementing security features
and so we want to make sure that they

150
00:12:21,110 --> 00:12:26,869
have the tools that they need in order
to make good security decisions when

151
00:12:26,869 --> 00:12:31,269
things I'm very proud about with Android
is we talked a safe by default

152
00:12:31,269 --> 00:12:37,129
design philosophy applications are most
talk a little bit about I don't talk a

153
00:12:37,129 --> 00:12:41,429
lot about our sandbox model but
applications have to go out of their way

154
00:12:41,429 --> 00:12:48,050
to introduce security holes if you use
an application developer a you just

155
00:12:48,050 --> 00:12:53,079
writing and reapplication your
application should be safe by default

156
00:12:53,079 --> 00:12:59,099
there's also read him so we look at me
look at and reform the attackers point

157
00:12:59,100 --> 00:13:01,709
you how can we break and enter it
ourselves

158
00:13:01,709 --> 00:13:07,179
assume you have full access to the towed
into the engineering staff so these are

159
00:13:07,179 --> 00:13:11,980
all really good traditional aspects of
what you find any security organization

160
00:13:11,980 --> 00:13:19,889
adolescent chill and this is why I
really wanna spend a lot of time on

161
00:13:19,889 --> 00:13:24,490
because I think it's confusing and maybe
people in this room may be familiar with

162
00:13:24,490 --> 00:13:30,990
it by one issue that work apartment with
it always start with the sandbox if

163
00:13:30,990 --> 00:13:34,279
you're doing security engineering and
you haven't used the terms down box

164
00:13:34,279 --> 00:13:36,829
you've made a mistake

165
00:13:36,829 --> 00:13:40,609
the best Android

166
00:13:40,610 --> 00:13:46,440
from its very early days was designed
with the concept that we are going to

167
00:13:46,440 --> 00:13:53,149
stand box applications we are not going
to allow an application to have full

168
00:13:53,149 --> 00:13:58,089
administrator access full root access
we're going to have a discrete list of

169
00:13:58,089 --> 00:14:02,529
things and application can do it so this
was a very important security partner

170
00:14:02,529 --> 00:14:08,010
and that was pretty much in and rates
from day one I like a credit for it I

171
00:14:08,010 --> 00:14:15,010
can't really take credit for words but
when we talk about the security of

172
00:14:15,010 --> 00:14:19,939
Android a big chunk of the security
license and box itself

173
00:14:19,940 --> 00:14:24,070
nikolai talk a little bit about the
sandbox

174
00:14:24,070 --> 00:14:28,200
wanna give a different view of the
sandbox from the point of view of an

175
00:14:28,200 --> 00:14:35,000
early Android system after itself has
always been divided engine parts we have

176
00:14:35,000 --> 00:14:40,700
this concept of the system which is
responsible for mediating communication

177
00:14:40,700 --> 00:14:46,480
between different processes we had this
concept of route which a lot of a lot of

178
00:14:46,480 --> 00:14:49,670
tools and resources to be right there
with you find our traditional Linux

179
00:14:49,670 --> 00:14:57,140
system and we also invented this concept
using UID separation to of multiple

180
00:14:57,140 --> 00:15:00,630
difference and boxes each application
has run home directory their own

181
00:15:00,630 --> 00:15:05,480
isolated sandbox where they can run
their codes safely so this was a very

182
00:15:05,480 --> 00:15:13,510
traditional Android security model for
you know for older devices 2003 and so

183
00:15:13,510 --> 00:15:18,670
over time we watched the attacks are
going on out there we know what's what's

184
00:15:18,670 --> 00:15:22,380
happening in the ecosystem and we're
continuing to evolve the platform to

185
00:15:22,380 --> 00:15:31,850
make it more and more secure in Andhra
421 we did a really decent a significant

186
00:15:31,850 --> 00:15:36,910
change to our security model this
concept of multiple users and

187
00:15:36,910 --> 00:15:40,319
enterprises face if you want to go where

188
00:15:40,320 --> 00:15:45,190
not only worry dividing code up based on
the application itself had this concept

189
00:15:45,190 --> 00:15:49,980
that multiple different uses could use
the device and that one uses data would

190
00:15:49,980 --> 00:15:56,550
be protected from another uses data so
again i refinance the sandbox model we

191
00:15:56,550 --> 00:16:03,219
also started introducing hardware roots
of trust trust them and trying to move

192
00:16:03,220 --> 00:16:09,920
things move especially security critical
code into a place that would be

193
00:16:09,920 --> 00:16:14,709
unaffected by Colonel vulnerabilities
that would be unaffected by other

194
00:16:14,710 --> 00:16:18,420
attacks against the system as this is
good

195
00:16:18,420 --> 00:16:24,719
continue to evolve this is the status
wasn't for one but we continue to look

196
00:16:24,720 --> 00:16:29,760
at a tax and I was having lunch today
and they were talking about you know

197
00:16:29,760 --> 00:16:37,110
when it was my job to be done there's
always things we can learn from those me

198
00:16:37,110 --> 00:16:45,470
new attacks so the next lesson I wanted
to convey yes we need we need to

199
00:16:45,470 --> 00:16:49,530
continue to improve things over time as
we understand new threats and as we were

200
00:16:49,530 --> 00:16:57,010
able to react any threats and revived
otto was what I consider to be a very

201
00:16:57,010 --> 00:17:03,230
revolutionary change within Android from
security perspective Andrew 50 was a

202
00:17:03,230 --> 00:17:10,620
very first release where we had SELinux
enforcing mode and so a lot of the

203
00:17:10,619 --> 00:17:15,188
components that were big model of the
conference before became a much smaller

204
00:17:15,189 --> 00:17:22,339
model of the components we are able to
take each process and identify a set of

205
00:17:22,339 --> 00:17:26,990
rules I said as he looked to call CSS
sandbox that we want to surround those

206
00:17:26,990 --> 00:17:35,930
processes with green boxes boxes has
exercised different resources it was one

207
00:17:35,930 --> 00:17:40,910
of the green boxes and red boxes have
access to different bits of data another

208
00:17:40,910 --> 00:17:45,040
fairly revolutionary change that we made
was

209
00:17:45,040 --> 00:17:53,270
in 50 we basically got rid of the root
user with estimates policies there is no

210
00:17:53,270 --> 00:17:59,690
all-powerful God root user you have a
bunch of UID 0 processes which have

211
00:17:59,690 --> 00:18:06,390
access to certain resources they could
have the typical conditions that might

212
00:18:06,390 --> 00:18:15,620
see it but the concept of route in an
Android 50 device and so we have a lot

213
00:18:15,620 --> 00:18:23,719
of a lot of Sept segmentation and each
one of these UN has the minimum

214
00:18:23,720 --> 00:18:28,910
capabilities and needs performance job
and no other and that's all the way down

215
00:18:28,910 --> 00:18:35,830
to almost everything that's gone from
the inservice shell scripts and things

216
00:18:35,830 --> 00:18:49,189
like that so around 250 time frame
actually was involved with very

217
00:18:49,190 --> 00:18:55,450
conversation there was a reddit AMA by
John Sawyer just in case you might know

218
00:18:55,450 --> 00:18:58,380
him from the and rereading community
where somebody asked him a question

219
00:18:58,380 --> 00:19:05,680
which Android devices do you find to be
the most secure devices and he said

220
00:19:05,680 --> 00:19:12,770
something that was me feel really happy
and Andrew 520 the devices are actually

221
00:19:12,770 --> 00:19:17,120
very hard to root because of the
estimates of policy because of the title

222
00:19:17,120 --> 00:19:21,080
changes and we had there may still be
bugs but we're able to make reasoned

223
00:19:21,080 --> 00:19:25,639
arguments about whether contain the
model is how that was a security

224
00:19:25,640 --> 00:19:30,740
partners of the device are so a lot of
times you be aware of people to turn

225
00:19:30,740 --> 00:19:35,010
them into sexual exploits which is no I
talked about two different strategies

226
00:19:35,010 --> 00:19:39,570
for Android is really want two things I
want to see you so

227
00:19:39,570 --> 00:19:44,760
as we continue to move forward you
should expect these boxes to get smaller

228
00:19:44,760 --> 00:19:48,580
and smaller as we further refine things
as we further make sure that were

229
00:19:48,580 --> 00:19:53,070
falling good design principles of design
practices following the principle of

230
00:19:53,070 --> 00:19:56,460
least privilege make sure that we have
really solid our picture these boxes

231
00:19:56,460 --> 00:20:01,330
against smaller and the future what
we're looking for is more credit

232
00:20:01,330 --> 00:20:06,320
protection features we like to the
kernel is a lot of security controls we

233
00:20:06,320 --> 00:20:07,570
have in place

234
00:20:07,570 --> 00:20:12,100
self-protection features for the kernel
are important research topic similarly

235
00:20:12,100 --> 00:20:17,959
what are the things that we can do to
reduce our reliance on road which is the

236
00:20:17,960 --> 00:20:21,260
code which is very large which could
have a lot of bugs in it are the things

237
00:20:21,260 --> 00:20:26,800
we can do more to her level so these are
things that we're looking at for the

238
00:20:26,800 --> 00:20:32,280
future of Android similarly there's been
some research on supply chain because

239
00:20:32,280 --> 00:20:36,020
we're starting to see some supply chain
vulnerabilities occurring where the

240
00:20:36,020 --> 00:20:45,280
devices are modified before the action
which stands users strong security

241
00:20:45,280 --> 00:20:52,760
standards so in 1 p.m. porn
characteristics that we as security

242
00:20:52,760 --> 00:20:56,330
professionals need to do is make sure
that we're providing guidance to the

243
00:20:56,330 --> 00:21:05,169
ecosystem Bell what is good security and
what's not good security

244
00:21:05,170 --> 00:21:14,610
there's a there's a compile-time
statement com never allow rules never

245
00:21:14,610 --> 00:21:19,219
allow rules are great because if you try
as much as a mandatory access control

246
00:21:19,220 --> 00:21:21,750
system if a rule doesn't exist

247
00:21:21,750 --> 00:21:27,050
you just can't perform the operation
never levels are compiled versions of

248
00:21:27,050 --> 00:21:30,649
certain behaviors are not present so
what are some of the things that we

249
00:21:30,650 --> 00:21:39,530
don't allow Andhra compatible devices no
detriment access no death came out says

250
00:21:39,530 --> 00:21:43,270
no key traits of a net no mapping had a
process

251
00:21:43,270 --> 00:21:51,050
00 address for personal protection no
writing to the system file system we

252
00:21:51,050 --> 00:21:56,200
talked a little about their fight cooper
also enforce this at at the SELinux

253
00:21:56,200 --> 00:22:04,260
level today we have about two hundred
and fifty year SELinux never allow rules

254
00:22:04,260 --> 00:22:09,490
which not only are tested at compile
time they're also a contractual

255
00:22:09,490 --> 00:22:14,100
requirement that we have with our
partners that is not permit modify the

256
00:22:14,100 --> 00:22:18,679
CTS tested CTS for those of you who are
familiar with this dance for a

257
00:22:18,680 --> 00:22:22,170
compatibility test suite it's the
definition what it means to be

258
00:22:22,170 --> 00:22:28,680
compatible so as we discover as we
discover undesirable behaviors in the

259
00:22:28,680 --> 00:22:34,980
ecosystem we make changes to Android to
address those undesirable behaviors and

260
00:22:34,980 --> 00:22:39,680
to make sure that we have consistent
security policies across our tariffs

261
00:22:39,680 --> 00:22:48,720
elites are are are part of Isis Isis

262
00:22:48,720 --> 00:22:59,179
Miller said talk about the first pillar
it's very important to make sure that

263
00:22:59,179 --> 00:23:06,150
we're preventing bugs make sure that
bugs can be introduced also want to talk

264
00:23:06,150 --> 00:23:12,440
about the second pillar of Android
security minimization

265
00:23:12,440 --> 00:23:18,940
before going to minimization the sandbox
model that we have for Android actually

266
00:23:18,940 --> 00:23:23,400
addresses both prevention of bugs by
making certain things and accessible and

267
00:23:23,400 --> 00:23:27,679
it also provides a mitigation we know
security bugs gonna happen everybody in

268
00:23:27,679 --> 00:23:31,400
this room knows that tomorrow or the
next day or the next day there's going

269
00:23:31,400 --> 00:23:37,220
to be another security bug and so the
sandbox allows us to understand the

270
00:23:37,220 --> 00:23:38,929
scope of what happens

271
00:23:38,929 --> 00:23:43,840
win a bug occurs we know it's impossible
to fix everybody who is impossible to

272
00:23:43,840 --> 00:23:48,740
fix every bug I don't think anybody
would be in this room and your knowledge

273
00:23:48,740 --> 00:23:52,990
is impossible to fix every bug it's
impossible to find every bug as I

274
00:23:52,990 --> 00:23:56,450
mentioned earlier there are thousands of
people who are contributing to the

275
00:23:56,450 --> 00:24:01,510
Android Open Source project there are
thousands of unique device out there

276
00:24:01,510 --> 00:24:07,580
hundreds of manufacturers all of which
may not have security at the top of

277
00:24:07,580 --> 00:24:11,289
their mind unlike the people in this
room is actually preaching to the choir

278
00:24:11,289 --> 00:24:17,210
I really appreciate this one thing I
don't think we do really well as an

279
00:24:17,210 --> 00:24:23,929
industry is to have robustness and tell
you if you build a bridge we're having

280
00:24:23,929 --> 00:24:27,590
this conversation at dinner last night
if you build a bridge in a car gets into

281
00:24:27,590 --> 00:24:32,530
an accident on the bridge the entire
bridge doesn't fall down and so why are

282
00:24:32,530 --> 00:24:37,990
we had a state in software where 11
vulnerability and caused the entire

283
00:24:37,990 --> 00:24:43,929
system collapse I think it's a very
interesting academic question and very

284
00:24:43,929 --> 00:24:48,210
interesting from industry perspective
why we haven't been doing more to help

285
00:24:48,210 --> 00:24:52,940
robustness and failure to treat computer
science like

286
00:24:52,940 --> 00:24:59,300
to treat computer science as an
engineering profession also minimization

287
00:24:59,300 --> 00:25:02,990
and maintains integrity of the system
won't be able to make reasoned arguments

288
00:25:02,990 --> 00:25:13,090
about the state of the system even in
the presence of battery bunny coda to my

289
00:25:13,090 --> 00:25:15,129
next lesson today

290
00:25:15,130 --> 00:25:21,330
account for human error everybody in
this room makes mistakes I've made

291
00:25:21,330 --> 00:25:26,710
mistakes have had security consequences
everybody in this room amazing states we

292
00:25:26,710 --> 00:25:36,980
have to design systems that are robust
against human error this is my pet peeve

293
00:25:36,980 --> 00:25:41,230
right now someone on chat a little bit
about it because this is the pain point

294
00:25:41,230 --> 00:25:46,400
of my last two-three months a
mathematicians in this room eBay got a

295
00:25:46,400 --> 00:25:56,020
degree in math really oh yeah that one
person so mathematically is this

296
00:25:56,020 --> 00:26:04,290
statement true X plus one greater than X
for all values of x should be in

297
00:26:04,290 --> 00:26:10,230
ok I'm not I'm not that major cell
function as a good answer I believe the

298
00:26:10,230 --> 00:26:15,350
statement to be true for all values of
acts where experts want greater than X

299
00:26:15,350 --> 00:26:25,870
having said that is that true in the
computer programming world no 4 years

300
00:26:25,870 --> 00:26:31,669
ago we as an industry decided that we
only had to fix face to put numbers in

301
00:26:31,670 --> 00:26:36,770
and so what's gonna happen if we take
our maximum number that we can fit and

302
00:26:36,770 --> 00:26:43,030
add 12 it is going to turn negative this
has been the bane of my existence this

303
00:26:43,030 --> 00:26:46,210
decision that was made forty years ago
has been the bane of my existence for

304
00:26:46,210 --> 00:26:52,660
the last like two or three months it's
important that programming languages

305
00:26:52,660 --> 00:26:59,400
reflecting two diff behavior and don't
have really weird error conditions and I

306
00:26:59,400 --> 00:27:03,320
hope as an industry we can move away
from this concept where numbers will

307
00:27:03,320 --> 00:27:07,850
over anyway

308
00:27:07,850 --> 00:27:14,350
programming languages have bugs people
introduced by this is known for

309
00:27:14,350 --> 00:27:19,370
encouraging bugs what are the

310
00:27:19,370 --> 00:27:25,979
what is the entry does to help protect
against bugs me a crime system we have

311
00:27:25,980 --> 00:27:30,920
big protections like a SLR SLR is on a
lot of press because of the recent stage

312
00:27:30,920 --> 00:27:35,960
fright vulnerability is is a very
important exploit medication to also a

313
00:27:35,960 --> 00:27:40,290
medication because these aren't
solutions to problems these are ways to

314
00:27:40,290 --> 00:27:47,350
make it more difficult for shutdown
known known vacuous actress was very

315
00:27:47,350 --> 00:27:52,600
early days had no excuse memory our
staff is not excusable he was not

316
00:27:52,600 --> 00:27:56,428
excusable we've had it for a very long
time will enforce that on all Android

317
00:27:56,429 --> 00:28:00,570
devices we have additional compiler
protections to fortify source which ad

318
00:28:00,570 --> 00:28:05,280
buffer overflow protection too common
Lipsy functions readonly relocation step

319
00:28:05,280 --> 00:28:11,580
in areas we try to to detect corruption
of the state of the program and make

320
00:28:11,580 --> 00:28:14,590
sure that we fail clearly because again
you know if people wanna have fun for

321
00:28:14,590 --> 00:28:15,230
all of us

322
00:28:15,230 --> 00:28:20,120
the last one is actually something i
wanna talk about we are doing

323
00:28:20,120 --> 00:28:24,500
innovation in security space and raise
the first Linux distribution to

324
00:28:24,500 --> 00:28:29,920
completely ban on non pipe I and Ares if
you are dynamically binary you will be

325
00:28:29,920 --> 00:28:35,530
randomized and we guarantee that a
platform level i'm waiting for other

326
00:28:35,530 --> 00:28:39,160
Linux distributions to catch up to its
to catch up to our sandbox and model and

327
00:28:39,160 --> 00:28:44,570
catch up you are native code harding and
that kind of thing I still wonder why it

328
00:28:44,570 --> 00:28:51,010
link systems get access to the browser
get access to all the data but we're

329
00:28:51,010 --> 00:28:54,220
going to future like i said im never
gonna be out of a job we have to do

330
00:28:54,220 --> 00:28:55,770
other things

331
00:28:55,770 --> 00:29:01,370
ensure full protections I actually think
we need to move away from a system to

332
00:29:01,370 --> 00:29:04,669
have unknown injury behaviour a big
chunk of the stage fright

333
00:29:04,670 --> 00:29:13,040
vulnerabilities where because of this
exact numeric property CFI control-flow

334
00:29:13,040 --> 00:29:16,730
integrity their implementations at work
today they have reasonable for

335
00:29:16,730 --> 00:29:21,070
performance tradeoffs we need to figure
out if these work and make sure that

336
00:29:21,070 --> 00:29:25,200
were info enforcing the integrity of the

337
00:29:25,200 --> 00:29:28,130
make sure that we have compiled
enforcing that you call function you

338
00:29:28,130 --> 00:29:33,389
actually will get that function not to a
different function step protections

339
00:29:33,389 --> 00:29:38,039
Stack Overflow these are all areas that
were contained to invest entertaining to

340
00:29:38,039 --> 00:29:46,379
do research in order to make exploits in
order to lessen the recess encourage

341
00:29:46,380 --> 00:29:48,529
safe languages

342
00:29:48,529 --> 00:29:52,350
if you leave this room with one thing I
want you leave this room with the idea

343
00:29:52,350 --> 00:29:56,549
that if you write a line and see any
time in the future

344
00:29:56,549 --> 00:30:02,429
you're making me sad because we need to
as an industry we need to move away from

345
00:30:02,429 --> 00:30:09,840
languages which have known problems and
traditionally did this Andrew's primary

346
00:30:09,840 --> 00:30:14,168
development language the one that we
only support for a very long period of

347
00:30:14,169 --> 00:30:24,630
time is memory say you cannot perform a
buffer overflow against against Joba and

348
00:30:24,630 --> 00:30:30,740
it wasn't for a long time that we even
in we've allowed native code as an API I

349
00:30:30,740 --> 00:30:33,549
mean writing a platform-independent
language actually has a lot of other

350
00:30:33,549 --> 00:30:39,600
benefits besides just security it also
mixed portability better and makes it

351
00:30:39,600 --> 00:30:44,490
easier but even today we specifically
say that if you're developing a native

352
00:30:44,490 --> 00:30:50,889
code you are a second class citizen we
do not want to see any difficulty and

353
00:30:50,889 --> 00:30:56,289
ran it so I think a lot of a chunk of
the big chunk of the changes that we a

354
00:30:56,289 --> 00:31:01,919
big chunk of the reason why a very
important aspects why there's not more

355
00:31:01,919 --> 00:31:08,360
security vulnerability is because we've
chosen as a language java is a very

356
00:31:08,360 --> 00:31:16,709
important decision that I'm really happy
with I mentioned earlier our industry

357
00:31:16,710 --> 00:31:21,899
needs to move away from unsafe languages
too risky to air problem we need to

358
00:31:21,899 --> 00:31:27,709
figure out how we can get out of this
situation that we're in today we're

359
00:31:27,710 --> 00:31:31,100
doing research within our organization
to try to figure out

360
00:31:31,100 --> 00:31:37,049
or their tools and resources that we can
make available to developers which are

361
00:31:37,049 --> 00:31:42,020
drop-in replacement for C or which can
act in terms of see they have the same

362
00:31:42,020 --> 00:31:46,299
performance characteristics have
predictable memory allocation the

363
00:31:46,299 --> 00:31:53,010
allocation so I don't consider myself a
language experts and certainly if people

364
00:31:53,010 --> 00:31:59,379
have recommendations or suggestions on
how we can be ourselves out we as an

365
00:31:59,380 --> 00:32:03,169
industry can dig ourselves out I think
it's very important conversation have

366
00:32:03,169 --> 00:32:14,640
created to reach out to dinner thing
which I think Andrew does well is this

367
00:32:14,640 --> 00:32:18,659
concept of principle of least privilege
especially with the SELinux

368
00:32:18,659 --> 00:32:24,190
implementation and Andrew 50 we've
identified for almost every process on

369
00:32:24,190 --> 00:32:29,299
Android what are the minimum
requirements that takes for that for

370
00:32:29,299 --> 00:32:34,820
that process to execute I think if
you're doing security engineering

371
00:32:34,820 --> 00:32:39,840
security organization if your security
professional this news via talking of

372
00:32:39,840 --> 00:32:45,830
mine and actually have actually uses
cloaking 401 at things that really

373
00:32:45,830 --> 00:32:53,110
strikes me about this quotes Jesus
quotes from 1975 I was 12 years old the

374
00:32:53,110 --> 00:33:00,969
time i've a bunch of people in this room
were even born at the time and so if you

375
00:33:00,970 --> 00:33:05,490
design a system that doesn't have the
principle of least privilege in mind

376
00:33:05,490 --> 00:33:12,060
then you need to know you need to
reconsider

377
00:33:12,060 --> 00:33:17,730
so I talked about what certain sort of
the bane of my existence the last two or

378
00:33:17,730 --> 00:33:21,890
three months there are some recent press
about availability called late-stage

379
00:33:21,890 --> 00:33:34,080
rights and so there is reasonably early
stage fright and we actually designed

380
00:33:34,080 --> 00:33:37,899
the media server with containment mine
and we also found that are explanations

381
00:33:37,900 --> 00:33:48,510
were really effective important parts
the other principle I want to talk about

382
00:33:48,510 --> 00:33:56,210
is the principle of detection is not yet
known as an honest tax reform is not

383
00:33:56,210 --> 00:34:01,180
enough to actually get medications you
need to know that the bugs are there so

384
00:34:01,180 --> 00:34:05,630
the next lessons basically keep used to
the route you need to know what's going

385
00:34:05,630 --> 00:34:06,260
on

386
00:34:06,260 --> 00:34:11,540
facing you know what the users going and
how do we do this in Android bunch

387
00:34:11,540 --> 00:34:17,500
different ways we actually published one
very early days or even so anybody in

388
00:34:17,500 --> 00:34:20,239
this room with anybody in the world
wants to reach out and talk some and the

389
00:34:20,239 --> 00:34:29,339
scheme just email us we have a bug
database we are we are consumers readers

390
00:34:29,340 --> 00:34:32,850
academic journals and you learn a lot of
things from reading with the communities

391
00:34:32,850 --> 00:34:35,290
doing

392
00:34:35,290 --> 00:34:40,199
we have we have automated detection of
discussions in forums about security

393
00:34:40,199 --> 00:34:45,889
issues it raises rates our attention and
we're aware of what's going on there are

394
00:34:45,889 --> 00:34:49,310
really interesting thing they think we
do as well call failed exploited action

395
00:34:49,310 --> 00:34:55,009
when we sticks about not only is well
off times were also instrument the bug

396
00:34:55,010 --> 00:34:58,870
and will say it is cold out was taken

397
00:34:58,870 --> 00:35:04,509
let's all get let's make sure happens so
the devices that are fixed can act as

398
00:35:04,510 --> 00:35:09,790
protectors of the devices they're still
vulnerable so we can know what's

399
00:35:09,790 --> 00:35:15,340
actually happening in the ecosystem is a
technique that people seem to be doing

400
00:35:15,340 --> 00:35:24,030
today and we also have the added
security rewards program where we are

401
00:35:24,030 --> 00:35:29,980
willing to pay money depending on the
kind of bug you bring us and the kind of

402
00:35:29,980 --> 00:35:38,390
help that you provide us in the
resulting up depending on how it's

403
00:35:38,390 --> 00:35:45,009
actually explains it could result up to
$30,000 and in rewards and I have a

404
00:35:45,010 --> 00:35:48,900
feeling that this number is actually
have to go up over time I've seen this

405
00:35:48,900 --> 00:36:02,830
number is actually 2004 reaction it's
important for any a manufacturer any

406
00:36:02,830 --> 00:36:06,470
operating system and presenting suffered
government to figure out how they're

407
00:36:06,470 --> 00:36:12,270
going up neither software for Nexus
devices we've committed to a monthly

408
00:36:12,270 --> 00:36:16,140
security upgrade cycle we make sure that
we have public both times to know what

409
00:36:16,140 --> 00:36:20,740
the people are aware of what the
security issues are facing and we've

410
00:36:20,740 --> 00:36:28,149
committed to doing this for three years
from device manufacturer and only do we

411
00:36:28,150 --> 00:36:33,190
do update ourselves we also support 1.6
million apps in our place store and when

412
00:36:33,190 --> 00:36:37,100
it was absurd security issues we have
provide a mechanism for them to update

413
00:36:37,100 --> 00:36:43,640
and we enforce at the system level that
if there's a security bug-eyed

414
00:36:43,640 --> 00:36:46,759
we just don't allow those after played
those apps will get fixed one way or

415
00:36:46,760 --> 00:36:52,660
another and so we've identified a number
of critical bugs in half and we are in

416
00:36:52,660 --> 00:36:58,990
the process of make sure those apps get
fixed no such thing as perfect security

417
00:36:58,990 --> 00:37:05,149
a lot of times when the industry talks
about security about this they're like

418
00:37:05,150 --> 00:37:10,410
oh a hundred percent of devices
available this I think that does a

419
00:37:10,410 --> 00:37:15,560
disservice to our store community I
think it's really important to talk

420
00:37:15,560 --> 00:37:20,380
about after its risk assessments if
you're in the medical industry you

421
00:37:20,380 --> 00:37:25,100
wouldn't say a hundred percent of humans
are vulnerable to you pull up a headline

422
00:37:25,100 --> 00:37:30,170
like that and so they're helping new
phone lines 99 percent of devices are

423
00:37:30,170 --> 00:37:37,420
vulnerable and these are actually
numbers where we can actually measure

424
00:37:37,420 --> 00:37:41,040
them or more effectively actually have
this ability that way kids are being

425
00:37:41,040 --> 00:37:45,980
installed and so we actually start
looking into this month ahead big

426
00:37:45,980 --> 00:37:52,580
headlines but they're only like 1200
this is this particular bug where there

427
00:37:52,580 --> 00:37:59,130
was a mismatch in the signature checking
for AP case and it turns out that the

428
00:37:59,130 --> 00:38:02,750
vast majority people who are excellent
we're looking for game cheats and there

429
00:38:02,750 --> 00:38:08,740
was no explanation the wild I do think
it's an industry and we need to have

430
00:38:08,740 --> 00:38:12,609
real information about risk make sure
that they have permissions available

431
00:38:12,610 --> 00:38:18,570
Google is doing our part by publishing
our security reports we're actually

432
00:38:18,570 --> 00:38:21,480
going to lots of details about what
we're seeing in the industry the

433
00:38:21,480 --> 00:38:25,920
exploitation or seeing in the industry
to make sure that people have accurate

434
00:38:25,920 --> 00:38:31,920
information to which to make security
decisions

435
00:38:31,920 --> 00:38:39,350
have run over time and resell has group
grew up in the air and at age we benefit

436
00:38:39,350 --> 00:38:43,960
from forty years of experience we
actually have what I consider to be a

437
00:38:43,960 --> 00:38:51,560
sophisticated robust security model and
we're going to continue to thank you

438
00:38:51,560 --> 00:39:17,779
what's your opinion on using native
court for security related tasks or

439
00:39:17,780 --> 00:39:23,510
singing about sleazy real possibilities
of drama cauldrons natives native code

440
00:39:23,510 --> 00:39:29,890
of its so I don't think native code
should be used for a lot of different

441
00:39:29,890 --> 00:39:36,259
house I would I would think that there
has to be other languages to support

442
00:39:36,260 --> 00:39:40,060
that but certainly if it's a choice
between code is already grin and has

443
00:39:40,060 --> 00:39:44,980
been tested and you can see an argument
for codes are you interested where you

444
00:39:44,980 --> 00:39:48,620
already have an understanding of the
security properties of the code and you

445
00:39:48,620 --> 00:39:53,549
might introduce more risk by moving to a
different language I don't know that I

446
00:39:53,550 --> 00:40:08,059
think it also depends on my case basis

447
00:40:08,059 --> 00:40:13,859
examples and RAID device vendors that
has introduced careless security

448
00:40:13,859 --> 00:40:21,469
mistakes in into their devices with the
vendor-specific customizations I did

449
00:40:21,469 --> 00:40:25,660
talk about what we're doing on the
SELinux i'd never allow rules which

450
00:40:25,660 --> 00:40:28,819
enforce certain consistencies in the
ecosystem I think you're familiar with

451
00:40:28,819 --> 00:40:35,390
never allow rules we also make sure that
we have lecture published best practices

452
00:40:35,390 --> 00:40:38,969
and guidance to our partners about what
to do and what not to do

453
00:40:38,969 --> 00:40:45,739
purposes education process for them and
for us and making sure that the enough

454
00:40:45,739 --> 00:40:49,259
information is available enough testing
is available to to encourage correct

455
00:40:49,259 --> 00:41:02,150
behaviour and to encourage now
introducing tough one

456
00:41:02,150 --> 00:41:09,640
do you see any way forwards to patching
the updating problem with all those

457
00:41:09,640 --> 00:41:16,440
thousands of different devices with MCI
minnows between the updates coming to

458
00:41:16,440 --> 00:41:20,220
the global source tree and actually
hitting users what do you think what

459
00:41:20,220 --> 00:41:27,180
kind of improvements would be the best
way forward there it's a really tough

460
00:41:27,180 --> 00:41:34,990
problem certainly make sure that we have
information available about which

461
00:41:34,990 --> 00:41:38,779
devices are updating which devices
aren't updating make sure people have

462
00:41:38,779 --> 00:41:43,160
intelligence information in order to
make intelligent decisions I think it's

463
00:41:43,160 --> 00:41:47,759
a really key aspects of trying to make
sure that we drive updates and we as an

464
00:41:47,760 --> 00:41:55,369
industry we encourage updates the
removal of cold air making sure that we

465
00:41:55,369 --> 00:41:59,589
have mechanisms outside of an OTA to do
security updates also think if we tend

466
00:41:59,589 --> 00:42:03,349
to split more often the core operating
system Android applications are really

467
00:42:03,349 --> 00:42:08,000
great example of that where the
applications aren't Titans system update

468
00:42:08,000 --> 00:42:13,279
independently through placed or anything
just make sure we have more awareness is

469
00:42:13,279 --> 00:42:23,670
a really great step and I don't know if
there's any easy solutions I fear that

470
00:42:23,670 --> 00:42:25,280
last one

471
00:42:25,280 --> 00:42:33,300
and I would like to TV viewers 431
question concerning privacy because the

472
00:42:33,300 --> 00:42:38,040
first presentation today we heard that
there are many EPS who are requesting

473
00:42:38,040 --> 00:42:45,800
too many permissions and this is a main
a major privacy issue development

474
00:42:45,800 --> 00:42:50,090
heading in this direction so we've been
primarily focusing development not the

475
00:42:50,090 --> 00:42:56,580
platform level but at the at the Google
Play level so every out that's hosted on

476
00:42:56,580 --> 00:43:02,620
Google Play is required to meet our our
standards and applications which are

477
00:43:02,620 --> 00:43:06,830
extracting information from advice
without the appropriate notification to

478
00:43:06,830 --> 00:43:08,009
the user

479
00:43:08,010 --> 00:43:13,180
found similar they may have to follow
our terms of service and they have to

480
00:43:13,180 --> 00:43:17,710
follow to be to be hosted on Google Play
so the problem is that this is more of

481
00:43:17,710 --> 00:43:24,910
those mixed cases where there's
legitimate need for some of these API

482
00:43:24,910 --> 00:43:29,649
some of these data you can't universally
say this particular bit of data is bad

483
00:43:29,650 --> 00:43:36,100
and so all of the apps on Google Play Me
Terms of Service if they don't read the

484
00:43:36,100 --> 00:43:39,610
Terms of Service you make sure that they
removed from Google Play until such time

485
00:43:39,610 --> 00:43:45,240
as they do meet the terms of service I
find it interesting because security

486
00:43:45,240 --> 00:43:50,879
whereas I'm because it said one of the
design goals should be that the user

487
00:43:50,880 --> 00:43:58,980
feels there's some color on the other
hand in terms of privacy users should be

488
00:43:58,980 --> 00:44:05,150
more aware of what's going on there so
maybe there's some description it's a

489
00:44:05,150 --> 00:44:10,100
tough challenge I and III allude to this
on my very early sites that there's a

490
00:44:10,100 --> 00:44:16,930
balancing act between functionality and
security things that we did for Android

491
00:44:16,930 --> 00:44:21,839
Emma was to introduce user probable
permissions or permission model we

492
00:44:21,840 --> 00:44:25,890
actually disclosed uses at the time of
use that particular operations being

493
00:44:25,890 --> 00:44:31,379
loud I think will give users more
control over how the one share

494
00:44:31,380 --> 00:44:34,660
information a lot of people are
perfectly happy to share information

495
00:44:34,660 --> 00:44:45,569
man and we need to make sure that
there's visibility into thats thanks

496
00:44:45,570 --> 00:44:45,810
again

