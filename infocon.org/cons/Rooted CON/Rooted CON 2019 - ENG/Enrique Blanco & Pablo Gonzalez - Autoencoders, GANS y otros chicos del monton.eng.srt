1
00:00:00,060 --> 00:00:07,949
Pablo Enrique van hablar de última learn

2
00:00:03,689 --> 00:00:13,650
and recur will tell you about it issues

3
00:00:07,950 --> 00:00:19,619
topic which I feel fascinating our

4
00:00:13,650 --> 00:00:22,880
workers cyber security experts is very

5
00:00:19,619 --> 00:00:26,340
much about it actually

6
00:00:22,880 --> 00:00:29,840
this is extremely useful and his

7
00:00:26,340 --> 00:00:41,940
presentation will be of awesome

8
00:00:29,840 --> 00:00:45,410
so you have to well first of all we'll

9
00:00:41,940 --> 00:00:50,129
tell you about the applicability of

10
00:00:45,410 --> 00:00:53,250
artificial intelligence and its

11
00:00:50,129 --> 00:00:54,930
relationship with cyber security we will

12
00:00:53,250 --> 00:01:00,719
tell you about defensive and offensive

13
00:00:54,930 --> 00:01:03,300
techniques but that's kind of a didactic

14
00:01:00,719 --> 00:01:05,040
part of this presentation and then we

15
00:01:03,300 --> 00:01:08,759
will share with you some real cases that

16
00:01:05,040 --> 00:01:10,830
we have developed for you to see how far

17
00:01:08,760 --> 00:01:14,360
we can get in terms of artificial

18
00:01:10,830 --> 00:01:19,048
intelligence applied to some security so

19
00:01:14,360 --> 00:01:20,670
well sometimes we are kind of afraid and

20
00:01:19,049 --> 00:01:23,250
I said well perhaps if artificial

21
00:01:20,670 --> 00:01:27,810
intelligence arrives is introduced

22
00:01:23,250 --> 00:01:35,430
perhaps we will be not be demanded as

23
00:01:27,810 --> 00:01:37,259
much if we join if we bring together two

24
00:01:35,430 --> 00:01:39,180
profiles people who specializing in

25
00:01:37,259 --> 00:01:42,570
artificial intelligence and people

26
00:01:39,180 --> 00:01:46,200
specializing in cyber security surely we

27
00:01:42,570 --> 00:01:48,658
come partner up very well and make up a

28
00:01:46,200 --> 00:01:51,030
very good team so my name is Pablo

29
00:01:48,659 --> 00:02:00,659
gonzález I've been working in telefónica

30
00:01:51,030 --> 00:02:04,680
for six years now few books that are

31
00:02:00,659 --> 00:02:08,099
displayed outside feel free to buy them

32
00:02:04,680 --> 00:02:12,420
if you so wish I also set up hackers

33
00:02:08,098 --> 00:02:13,609
Club was an entrepreneur project then we

34
00:02:12,420 --> 00:02:16,450
also have

35
00:02:13,610 --> 00:02:20,450
Enrique Enrique is a specialized team

36
00:02:16,450 --> 00:02:22,850
artificial intelligence he's got a

37
00:02:20,450 --> 00:02:25,100
degree in physics master schools in

38
00:02:22,850 --> 00:02:28,190
astrophysics and notice he's here with

39
00:02:25,100 --> 00:02:32,269
us discussing cyber security as well as

40
00:02:28,190 --> 00:02:35,030
AI he worked in India for some time then

41
00:02:32,270 --> 00:02:42,650
he went to Germany and now he's back

42
00:02:35,030 --> 00:02:45,800
with us we in telefónica dose of our

43
00:02:42,650 --> 00:02:48,260
scene Telefonica we work at the

44
00:02:45,800 --> 00:02:50,690
triceraton's apartments meaning that

45
00:02:48,260 --> 00:02:52,700
department where we are allowed to play

46
00:02:50,690 --> 00:02:55,400
around with technology to experiment

47
00:02:52,700 --> 00:02:57,440
with technology as well as with cyber

48
00:02:55,400 --> 00:02:59,360
security artificial intelligence and

49
00:02:57,440 --> 00:03:02,090
they give us free room for us to

50
00:02:59,360 --> 00:03:05,060
investigate and research so we are a new

51
00:03:02,090 --> 00:03:07,340
national stage for instance we tried of

52
00:03:05,060 --> 00:03:09,470
something and while we may write an

53
00:03:07,340 --> 00:03:12,380
article about it and that will be it

54
00:03:09,470 --> 00:03:14,900
that will be the entry but if we test

55
00:03:12,380 --> 00:03:17,299
something and we see that can be applied

56
00:03:14,900 --> 00:03:20,959
and can be improved product or service

57
00:03:17,300 --> 00:03:23,570
we go ahead with it and then we also

58
00:03:20,959 --> 00:03:27,110
work with patents which is also good fun

59
00:03:23,570 --> 00:03:27,440
because our work is not monotonous at

60
00:03:27,110 --> 00:03:29,690
all

61
00:03:27,440 --> 00:03:32,420
we all the time two different things and

62
00:03:29,690 --> 00:03:35,329
now I will tell you more about it well

63
00:03:32,420 --> 00:03:37,220
first of all which cells use please stay

64
00:03:35,330 --> 00:03:41,209
in the room do not leave the room I will

65
00:03:37,220 --> 00:03:43,459
be brief here second we will be talking

66
00:03:41,209 --> 00:03:50,870
about artificial intelligence applied to

67
00:03:43,459 --> 00:03:53,090
cyber security marriage do to understand

68
00:03:50,870 --> 00:03:57,170
each other or not let us see what

69
00:03:53,090 --> 00:03:59,540
happens there then let us also to come

70
00:03:57,170 --> 00:04:04,160
out techniques to develop attacks and

71
00:03:59,540 --> 00:04:06,829
defense also based always based on ia

72
00:04:04,160 --> 00:04:08,750
algorithms then also will see what we

73
00:04:06,830 --> 00:04:11,890
have done with that up until now and

74
00:04:08,750 --> 00:04:15,049
then applicability there having other

75
00:04:11,890 --> 00:04:17,630
presentations about phishing and like

76
00:04:15,049 --> 00:04:21,200
and then today we will be talking about

77
00:04:17,630 --> 00:04:23,510
fraud to CEO but to all of you do that

78
00:04:21,200 --> 00:04:27,340
yes nearly all of you to that

79
00:04:23,510 --> 00:04:31,159
so someone come and say well if I sent a

80
00:04:27,340 --> 00:04:34,340
get out of email I will be in big

81
00:04:31,160 --> 00:04:39,010
trouble so let us see how we can evolve

82
00:04:34,340 --> 00:04:42,729
that how far we can get so that you

83
00:04:39,010 --> 00:04:45,830
change your mindset all right

84
00:04:42,730 --> 00:04:51,140
we are starting now to false in this

85
00:04:45,830 --> 00:04:56,930
video I'm sure it looks real but it is

86
00:04:51,140 --> 00:05:02,810
not the model was made with neural

87
00:04:56,930 --> 00:05:06,020
networks but suppose an artificial

88
00:05:02,810 --> 00:05:14,200
intelligence I have learnt to move the

89
00:05:06,020 --> 00:05:18,020
mouse and Obama and then they just gave

90
00:05:14,200 --> 00:05:21,500
Moses pitch to hit the system the model

91
00:05:18,020 --> 00:05:23,330
was trained and then we have Jennifer

92
00:05:21,500 --> 00:05:26,690
Lawrence video can you hear that

93
00:05:23,330 --> 00:05:30,830
have you seen that before it's quite

94
00:05:26,690 --> 00:05:32,150
good funny thing is but this is for you

95
00:05:30,830 --> 00:05:39,070
to understand what happens with those

96
00:05:32,150 --> 00:05:41,750
type of attacks if you don't know that

97
00:05:39,070 --> 00:05:58,760
he's Steve Buscemi

98
00:05:41,750 --> 00:06:01,970
well Jubran tell the problem is that

99
00:05:58,760 --> 00:06:05,590
this face hopping techniques have also

100
00:06:01,970 --> 00:06:07,910
been taking over to the porn industry

101
00:06:05,590 --> 00:06:13,780
come on man go and say well these

102
00:06:07,910 --> 00:06:19,190
actress is in erotic video ok we will

103
00:06:13,780 --> 00:06:23,020
stop that video ok you can guess what

104
00:06:19,190 --> 00:06:26,719
comes after and then we ask ourselves

105
00:06:23,020 --> 00:06:28,789
how important is have fake news well

106
00:06:26,720 --> 00:06:30,290
factors are very much related to the

107
00:06:28,790 --> 00:06:34,280
topic of our presentation because the

108
00:06:30,290 --> 00:06:36,950
moment machines will start to generate

109
00:06:34,280 --> 00:06:40,940
this type of tech news we will

110
00:06:36,950 --> 00:06:44,320
in trouble we will be in trouble because

111
00:06:40,940 --> 00:06:48,920
we tend to believe what we read but we

112
00:06:44,320 --> 00:06:51,140
see notice these piece of news not at

113
00:06:48,920 --> 00:06:53,300
all related so artificial intelligence

114
00:06:51,140 --> 00:06:58,430
because it is quite an old piece of news

115
00:06:53,300 --> 00:07:02,330
were the Twitter account of us news

116
00:06:58,430 --> 00:07:10,430
agencies was hacked he said that there

117
00:07:02,330 --> 00:07:14,300
was that one house had been hacked

118
00:07:10,430 --> 00:07:20,780
and it was actually fake body had an

119
00:07:14,300 --> 00:07:24,860
impact on society someone will give a

120
00:07:20,780 --> 00:07:28,419
second thought to it and I say we will

121
00:07:24,860 --> 00:07:33,230
we end up understanding each other

122
00:07:28,420 --> 00:07:37,600
imagine a corporate network imagine that

123
00:07:33,230 --> 00:07:40,130
they have solutions in place using

124
00:07:37,600 --> 00:07:44,270
artificial intelligence imagine that we

125
00:07:40,130 --> 00:07:49,190
have network traffic and we can train

126
00:07:44,270 --> 00:07:52,729
our AI to detect malicious and not

127
00:07:49,190 --> 00:07:56,000
malicious traffic based on supervisor

128
00:07:52,730 --> 00:07:59,680
algorithms this is a real case with some

129
00:07:56,000 --> 00:08:03,830
of my colleagues did a proof of concept

130
00:07:59,680 --> 00:08:06,410
so the landing who taught the AI to

131
00:08:03,830 --> 00:08:08,330
classify the traffic then they moved on

132
00:08:06,410 --> 00:08:12,590
to the testing phase and they say oh

133
00:08:08,330 --> 00:08:15,159
there is an anomaly in the traffic so

134
00:08:12,590 --> 00:08:17,599
it's a high likelihood for you to be

135
00:08:15,160 --> 00:08:20,840
anomalous and then there is another

136
00:08:17,600 --> 00:08:26,690
element which is we can also find on the

137
00:08:20,840 --> 00:08:30,260
Internet which is fish I fish also based

138
00:08:26,690 --> 00:08:33,979
on an algorithm phishing sites and non

139
00:08:30,260 --> 00:08:41,330
phishing sites are classified

140
00:08:33,979 --> 00:08:45,970
artificial intelligence detects phishing

141
00:08:41,330 --> 00:08:48,920
or or not alright so let us start now

142
00:08:45,970 --> 00:08:50,209
I'd like to show you some basic concepts

143
00:08:48,920 --> 00:08:54,110
about machine learning

144
00:08:50,209 --> 00:08:56,089
well there may be may not be basics to

145
00:08:54,110 --> 00:08:59,300
some of you because I know that many of

146
00:08:56,089 --> 00:09:01,519
you are actual experts in artificial

147
00:08:59,300 --> 00:09:03,079
intelligence and machine learning and

148
00:09:01,519 --> 00:09:05,089
we'd like to take this opportunity to

149
00:09:03,079 --> 00:09:07,819
share with you the techniques that we

150
00:09:05,089 --> 00:09:10,850
have used to generate the modeling and

151
00:09:07,820 --> 00:09:14,000
the attacks but let us give you some

152
00:09:10,850 --> 00:09:16,519
background now so first of all what is

153
00:09:14,000 --> 00:09:21,470
machine learning about it is a branch of

154
00:09:16,519 --> 00:09:24,620
artificial intelligence that we can in

155
00:09:21,470 --> 00:09:29,390
fact patterns within data once these

156
00:09:24,620 --> 00:09:32,660
data are fed so it is started off back

157
00:09:29,390 --> 00:09:37,640
in the 80s and then here evolved into

158
00:09:32,660 --> 00:09:39,439
another branch which is deep learning so

159
00:09:37,640 --> 00:09:41,209
the good thing about machine learning is

160
00:09:39,440 --> 00:09:44,060
that it helps us generate models and

161
00:09:41,209 --> 00:09:46,760
models just mathematical representations

162
00:09:44,060 --> 00:09:48,920
of the processes that are taking place

163
00:09:46,760 --> 00:09:53,200
in the real world what is actually

164
00:09:48,920 --> 00:09:56,630
valuable here is that we are able to

165
00:09:53,200 --> 00:09:59,360
make predictions based on the data that

166
00:09:56,630 --> 00:10:01,360
have been input so with this paradigm is

167
00:09:59,360 --> 00:10:03,680
both supervised and unsupervised

168
00:10:01,360 --> 00:10:08,209
actually generating a machine learning

169
00:10:03,680 --> 00:10:10,969
model requires giving training data to

170
00:10:08,209 --> 00:10:13,459
an algorithm and here we would like to

171
00:10:10,970 --> 00:10:15,950
talk about another element another

172
00:10:13,459 --> 00:10:18,319
concept what we mean by machine learning

173
00:10:15,950 --> 00:10:22,130
algorithm well all of you present here

174
00:10:18,320 --> 00:10:24,589
know what algorithm is about because of

175
00:10:22,130 --> 00:10:27,500
the training that you have it's the

176
00:10:24,589 --> 00:10:30,470
number of steps in a specific order

177
00:10:27,500 --> 00:10:34,519
which is for specific purpose we will be

178
00:10:30,470 --> 00:10:37,100
defining the it as the set of steps that

179
00:10:34,519 --> 00:10:39,769
are given to a model so that the model

180
00:10:37,100 --> 00:10:44,029
can make the calculations and execute

181
00:10:39,769 --> 00:10:47,300
the function that we wanted to make once

182
00:10:44,029 --> 00:10:50,660
then within machine learning we are

183
00:10:47,300 --> 00:10:54,290
moving about some different paradigms so

184
00:10:50,660 --> 00:10:58,579
learning paradigms here the inductive

185
00:10:54,290 --> 00:11:00,349
world and the enhancement here we have

186
00:10:58,579 --> 00:11:02,989
the supervised and unsupervised learning

187
00:11:00,350 --> 00:11:06,860
and then the semi-supervised which is a

188
00:11:02,990 --> 00:11:08,720
combination of the other two we will be

189
00:11:06,860 --> 00:11:10,790
focusing on supervised and unsupervised

190
00:11:08,720 --> 00:11:13,160
and generative models that have interest

191
00:11:10,790 --> 00:11:15,860
to generate attacks are based on the non

192
00:11:13,160 --> 00:11:18,800
supervised learning and now I'd like to

193
00:11:15,860 --> 00:11:22,279
mention the enhanced learning these

194
00:11:18,800 --> 00:11:25,479
dilemmas were people work in an

195
00:11:22,279 --> 00:11:28,220
environment and they get every word in

196
00:11:25,480 --> 00:11:31,160
exchange and then through trial and

197
00:11:28,220 --> 00:11:35,029
error they find the necessary sequence

198
00:11:31,160 --> 00:11:37,779
of steps to maximize that learning to

199
00:11:35,029 --> 00:11:41,089
enhance that learning now going into

200
00:11:37,779 --> 00:11:45,770
supervised learning this is quite

201
00:11:41,089 --> 00:11:49,699
self-explanatory graph will have input

202
00:11:45,770 --> 00:11:51,860
and data for the algorithm then will

203
00:11:49,699 --> 00:11:54,529
have a number of labels because you have

204
00:11:51,860 --> 00:11:57,500
taken some time to label these samples

205
00:11:54,529 --> 00:11:59,300
you just fit the algorithm with it the

206
00:11:57,500 --> 00:12:01,310
algorithm units for me to generate a

207
00:11:59,300 --> 00:12:03,649
predictive model and once you have

208
00:12:01,310 --> 00:12:07,670
tested samples that your algorithm has

209
00:12:03,649 --> 00:12:13,149
never ever seen then you get a label

210
00:12:07,670 --> 00:12:16,939
label may be either classifications who

211
00:12:13,149 --> 00:12:20,060
other type of data infinite area and

212
00:12:16,940 --> 00:12:22,220
marek data and then here now in non

213
00:12:20,060 --> 00:12:24,800
supervised learning the approach is

214
00:12:22,220 --> 00:12:29,870
quite similar yet this time we do not

215
00:12:24,800 --> 00:12:32,359
have any labels please from the one hand

216
00:12:29,870 --> 00:12:34,370
makes things easier because we may get

217
00:12:32,360 --> 00:12:36,740
quite a lot of terah

218
00:12:34,370 --> 00:12:39,199
maybe we may have got a lot of data but

219
00:12:36,740 --> 00:12:41,089
we don't have to label them often this

220
00:12:39,199 --> 00:12:44,060
type of not supervised learning it

221
00:12:41,089 --> 00:12:46,130
focuses on clustering and grouping and

222
00:12:44,060 --> 00:12:48,920
the ease of an exploratory in nature

223
00:12:46,130 --> 00:12:52,189
aimed at discovering characteristics in

224
00:12:48,920 --> 00:12:53,630
the data that we couldn't do

225
00:12:52,190 --> 00:12:55,310
otherwise for instance we are talking

226
00:12:53,630 --> 00:12:57,939
about classification of images

227
00:12:55,310 --> 00:13:03,560
processing of natural language etc

228
00:12:57,940 --> 00:13:08,650
another basic example or concept that we

229
00:13:03,560 --> 00:13:11,930
should understand should not understand

230
00:13:08,650 --> 00:13:15,260
effect nutracheck neuronal networks

231
00:13:11,930 --> 00:13:17,780
using a mathematical model mimicking a

232
00:13:15,260 --> 00:13:20,990
set of neurons that are stucked in

233
00:13:17,780 --> 00:13:26,120
different layers and this allows us to

234
00:13:20,990 --> 00:13:33,740
infer data these human neural networks

235
00:13:26,120 --> 00:13:35,960
the most basic ones one network with an

236
00:13:33,740 --> 00:13:38,570
entry layer and output layer

237
00:13:35,960 --> 00:13:40,940
or input layer and output layer in this

238
00:13:38,570 --> 00:13:43,010
case there are two layers but number of

239
00:13:40,940 --> 00:13:46,220
nodes is variable and each of these

240
00:13:43,010 --> 00:13:51,200
nodes is representation mathematical

241
00:13:46,220 --> 00:13:55,090
representation of what it is considered

242
00:13:51,200 --> 00:14:00,020
to be a neuron so each of the inputs

243
00:13:55,090 --> 00:14:06,320
escalated and then the activation

244
00:14:00,020 --> 00:14:11,540
function is implemented and then there

245
00:14:06,320 --> 00:14:14,240
is an output resulting output so the

246
00:14:11,540 --> 00:14:16,819
behavior of a neural network is defined

247
00:14:14,240 --> 00:14:18,920
by the architecture architecture is

248
00:14:16,820 --> 00:14:22,220
characterized by the number of neurons

249
00:14:18,920 --> 00:14:24,770
making up that network the depth as well

250
00:14:22,220 --> 00:14:29,290
as the number of layers and the nature

251
00:14:24,770 --> 00:14:29,290
of the connections between these neurons

252
00:14:29,380 --> 00:14:37,370
so the main architectures that are

253
00:14:34,970 --> 00:14:40,370
produced in deep learning in this case

254
00:14:37,370 --> 00:14:43,480
is a set of algorithms that can model

255
00:14:40,370 --> 00:14:46,460
the attraction of theta based on these

256
00:14:43,480 --> 00:14:49,970
architectures architectures of deep

257
00:14:46,460 --> 00:14:52,310
networks often talk about deep neural

258
00:14:49,970 --> 00:14:55,070
networks conventional neural networks

259
00:14:52,310 --> 00:14:59,530
recurrent neural networks that perform

260
00:14:55,070 --> 00:15:01,850
better was in some fields often the

261
00:14:59,530 --> 00:15:02,660
convolutional czar better for artificial

262
00:15:01,850 --> 00:15:04,670
vision

263
00:15:02,660 --> 00:15:10,990
whereas the common ones are used for

264
00:15:04,670 --> 00:15:14,150
language processing so here we see a

265
00:15:10,990 --> 00:15:16,340
convolutional neural network this is the

266
00:15:14,150 --> 00:15:21,740
typical example which is often used to

267
00:15:16,340 --> 00:15:24,740
share a deep network for supervision so

268
00:15:21,740 --> 00:15:28,160
if we get to have a set of images with

269
00:15:24,740 --> 00:15:30,350
cars and trucks aircrafts if they are

270
00:15:28,160 --> 00:15:32,719
labeled we just give that to a

271
00:15:30,350 --> 00:15:35,840
convolutional network after training it

272
00:15:32,720 --> 00:15:38,500
we can infer whether the image that has

273
00:15:35,840 --> 00:15:41,630
been input is that of a car truck and

274
00:15:38,500 --> 00:15:44,890
aircraft this is supervised learning and

275
00:15:41,630 --> 00:15:47,330
these type of architectures are also

276
00:15:44,890 --> 00:15:50,390
useful for an unsupervised learning

277
00:15:47,330 --> 00:15:52,970
based on older and while we've been

278
00:15:50,390 --> 00:15:55,100
trying to summarize machine learning and

279
00:15:52,970 --> 00:15:58,430
deep learning in five minutes which is a

280
00:15:55,100 --> 00:16:05,870
bit mushy so to speak we move on into a

281
00:15:58,430 --> 00:16:10,489
generative models models are for between

282
00:16:05,870 --> 00:16:12,980
the non supervised learning paradigm and

283
00:16:10,490 --> 00:16:15,470
the main purpose of it is finding

284
00:16:12,980 --> 00:16:20,590
patterns in the data that will enable us

285
00:16:15,470 --> 00:16:26,270
to generate new samples from a known

286
00:16:20,590 --> 00:16:28,820
probability distribution so here we have

287
00:16:26,270 --> 00:16:31,760
the variation allowed encoders and

288
00:16:28,820 --> 00:16:33,890
generative adversarial networks and I'm

289
00:16:31,760 --> 00:16:37,310
sure that you are aware of these two

290
00:16:33,890 --> 00:16:40,870
approaches first of all out encoder what

291
00:16:37,310 --> 00:16:45,229
are they about well this is very simple

292
00:16:40,870 --> 00:16:50,030
we have but there is one limitation here

293
00:16:45,230 --> 00:16:52,670
there is a layer lower size of the input

294
00:16:50,030 --> 00:16:57,260
and output layer and the mission of this

295
00:16:52,670 --> 00:16:59,599
architecture is reproducing input data

296
00:16:57,260 --> 00:17:01,580
in the best possible manner and this is

297
00:16:59,600 --> 00:17:04,040
the way the algorithm is being trained

298
00:17:01,580 --> 00:17:07,040
to come up with named model model that

299
00:17:04,040 --> 00:17:09,379
first allow you to compress the images

300
00:17:07,040 --> 00:17:12,199
and then to decompress them so we have

301
00:17:09,380 --> 00:17:14,600
images of Pablo one of the videos that

302
00:17:12,199 --> 00:17:17,870
we made for face swapping and

303
00:17:14,599 --> 00:17:21,079
we have the reconstructed image so well

304
00:17:17,869 --> 00:17:24,260
these but this there is a bit of a

305
00:17:21,079 --> 00:17:28,299
distortion here so here we'll have these

306
00:17:24,260 --> 00:17:28,299
first parts where information is coded

307
00:17:29,140 --> 00:17:35,559
and often this type of systems when we

308
00:17:32,720 --> 00:17:41,120
work with images we need convolutional

309
00:17:35,559 --> 00:17:43,730
networks to have a latent space to the C

310
00:17:41,120 --> 00:17:45,830
layer that is a various factor that

311
00:17:43,730 --> 00:17:47,990
would allow you allow us to narrow down

312
00:17:45,830 --> 00:17:50,289
the characteristics of the image and why

313
00:17:47,990 --> 00:17:53,179
do we want to narrow down these

314
00:17:50,289 --> 00:17:57,650
characteristics well to captures

315
00:17:53,179 --> 00:18:01,309
meaningful variation in the changes in

316
00:17:57,650 --> 00:18:04,190
the input data then we have the decoder

317
00:18:01,309 --> 00:18:07,010
which is the top part when we have that

318
00:18:04,190 --> 00:18:09,799
Laden vector we just want to reconstruct

319
00:18:07,010 --> 00:18:12,350
our image our input data the

320
00:18:09,799 --> 00:18:14,710
characteristics here very simple often

321
00:18:12,350 --> 00:18:21,320
they have the same architecture but

322
00:18:14,710 --> 00:18:23,210
invented that dad of the encoder so let

323
00:18:21,320 --> 00:18:26,360
us assume that our model is already

324
00:18:23,210 --> 00:18:28,809
trained the outer core architecture is

325
00:18:26,360 --> 00:18:33,439
already there that allow us to

326
00:18:28,809 --> 00:18:38,270
reconstruct images if we wanted to

327
00:18:33,440 --> 00:18:41,809
generate new images from our Z space

328
00:18:38,270 --> 00:18:44,809
from our Ladin sector we will have to

329
00:18:41,809 --> 00:18:48,678
make something using normal distribution

330
00:18:44,809 --> 00:18:54,320
and then we will obtain faces of Harlow

331
00:18:48,679 --> 00:18:56,960
and seen faces of Pablo this is known as

332
00:18:54,320 --> 00:19:00,129
variational outlawed encoder

333
00:18:56,960 --> 00:19:02,630
now I'll also try to summarize

334
00:19:00,130 --> 00:19:07,880
generative adversarial network is about

335
00:19:02,630 --> 00:19:10,580
this is a set of two neural networks

336
00:19:07,880 --> 00:19:13,390
that are competing we have two gamers a

337
00:19:10,580 --> 00:19:16,970
discriminator and a generator that is

338
00:19:13,390 --> 00:19:21,049
generator can be assimilated to the

339
00:19:16,970 --> 00:19:25,430
coder and out encoder from random noise

340
00:19:21,049 --> 00:19:28,520
a fake image is generated discriminator

341
00:19:25,430 --> 00:19:32,480
it's a classifier mainly gives you

342
00:19:28,520 --> 00:19:36,730
either a 0 or a 1 0 will be real Pablo

343
00:19:32,480 --> 00:19:39,980
and takes real images of Pablo

344
00:19:36,730 --> 00:19:45,080
combustion against the image that has

345
00:19:39,980 --> 00:19:49,880
been given by the generator and it tells

346
00:19:45,080 --> 00:19:53,679
you the level of match and then tries to

347
00:19:49,880 --> 00:19:58,610
deceive the generator how did you train

348
00:19:53,680 --> 00:20:00,980
J and what you generate samples that you

349
00:19:58,610 --> 00:20:05,990
give to the discriminator the

350
00:20:00,980 --> 00:20:09,980
discriminator see the likeliness for

351
00:20:05,990 --> 00:20:12,890
that image to be true or false and often

352
00:20:09,980 --> 00:20:18,950
this type of architectures are trained

353
00:20:12,890 --> 00:20:23,390
to these masks the generator maximizing

354
00:20:18,950 --> 00:20:31,880
the likeliness for the discriminator to

355
00:20:23,390 --> 00:20:41,420
be drawn so we also see how close G has

356
00:20:31,880 --> 00:20:43,460
been how close it was to D seed so it

357
00:20:41,420 --> 00:20:46,280
takes some time to train these type of

358
00:20:43,460 --> 00:20:50,090
algorithms with just with standard

359
00:20:46,280 --> 00:20:53,020
models so the model may not converge it

360
00:20:50,090 --> 00:20:54,860
is difficult to choose the right

361
00:20:53,020 --> 00:20:57,440
architecture as well as the right

362
00:20:54,860 --> 00:21:02,030
parameters so therefore you have to

363
00:20:57,440 --> 00:21:04,490
choose wisely sometimes playing with

364
00:21:02,030 --> 00:21:06,410
these parameters or working with these

365
00:21:04,490 --> 00:21:09,230
parameters could be a bit tedious the

366
00:21:06,410 --> 00:21:11,990
generator may also become stagnant or

367
00:21:09,230 --> 00:21:14,720
blocked and then these samples may not

368
00:21:11,990 --> 00:21:16,490
be favourite well that can be corrected

369
00:21:14,720 --> 00:21:19,580
through mathematical techniques as you

370
00:21:16,490 --> 00:21:22,880
can also try it through the technique

371
00:21:19,580 --> 00:21:25,189
making the discriminator able to tell

372
00:21:22,880 --> 00:21:28,850
the generator how close it was from

373
00:21:25,190 --> 00:21:31,400
deceiving age Oh perhaps the generator

374
00:21:28,850 --> 00:21:32,600
becomes like really smart very good over

375
00:21:31,400 --> 00:21:34,590
a short period of time

376
00:21:32,600 --> 00:21:38,969
Anton also have an impact of the

377
00:21:34,590 --> 00:21:44,100
learning and now let us play a bit after

378
00:21:38,970 --> 00:21:47,460
theory let us see what we did and I'm

379
00:21:44,100 --> 00:21:51,600
thinking about fraud - CEO applicability

380
00:21:47,460 --> 00:21:53,190
in the offensive side then well not

381
00:21:51,600 --> 00:22:01,908
later on we'll also tell you how to

382
00:21:53,190 --> 00:22:04,620
detect this type of it so this is

383
00:22:01,909 --> 00:22:08,130
something that we can all use we can

384
00:22:04,620 --> 00:22:11,760
also use cloud and at the end of the day

385
00:22:08,130 --> 00:22:15,380
we resources are available at an

386
00:22:11,760 --> 00:22:18,929
affordable price so Pablo has became a

387
00:22:15,380 --> 00:22:22,710
comedian so we did a face swapping

388
00:22:18,929 --> 00:22:24,630
without encoder on the screen you see

389
00:22:22,710 --> 00:22:27,210
the code of the library where you can

390
00:22:24,630 --> 00:22:34,169
get it ok

391
00:22:27,210 --> 00:22:39,029
let's show it to you do you know him

392
00:22:34,169 --> 00:22:42,690
I'm here to talk about about the limits

393
00:22:39,029 --> 00:22:44,789
of humor I was born in 1981 at the end

394
00:22:42,690 --> 00:22:48,210
of the 80s early 90s there were not

395
00:22:44,789 --> 00:22:51,620
limiting humor you could tell jokes

396
00:22:48,210 --> 00:22:54,840
about Prime Minister terrorist group

397
00:22:51,620 --> 00:22:57,449
about the royal family you could also

398
00:22:54,840 --> 00:23:05,580
tell joke about the whole royal family

399
00:22:57,450 --> 00:23:12,080
at that time we're told about the mother

400
00:23:05,580 --> 00:23:12,080
of the king at that time all right

401
00:23:13,399 --> 00:23:24,570
ok what we have just seen it's me I mean

402
00:23:19,020 --> 00:23:29,580
the comedian so the face is fits in well

403
00:23:24,570 --> 00:23:35,178
same as the color of his skin and now we

404
00:23:29,580 --> 00:23:35,178
have Enrique say couch ok

405
00:23:36,100 --> 00:23:41,168
so the attack is not me becoming a

406
00:23:38,110 --> 00:23:44,350
comedian which could be it as well but

407
00:23:41,169 --> 00:23:52,539
us getting it I don't know a politician

408
00:23:44,350 --> 00:23:55,178
or person of influence and showing the

409
00:23:52,539 --> 00:23:58,330
real face of the person by changing the

410
00:23:55,179 --> 00:23:59,980
gestures of this person okay if we show

411
00:23:58,330 --> 00:24:02,470
you that later that would be the actual

412
00:23:59,980 --> 00:24:05,830
attack and let us see what happens how

413
00:24:02,470 --> 00:24:08,320
our own colors work step by step let us

414
00:24:05,830 --> 00:24:12,158
take a look at this case and bring us a

415
00:24:08,320 --> 00:24:20,678
couch but this one did not come out as

416
00:24:12,159 --> 00:24:22,919
well that well probably he is with his

417
00:24:20,679 --> 00:24:22,919
eye

418
00:24:25,610 --> 00:24:33,889
was fourth in the last seven years

419
00:24:30,890 --> 00:24:36,890
Manchester City was champion twice and

420
00:24:33,890 --> 00:24:38,530
if you want to say three times because

421
00:24:36,890 --> 00:24:41,190
they will be

422
00:24:38,530 --> 00:24:48,879
in one more week two three or four and

423
00:24:41,190 --> 00:24:56,920
they were second twice okay so you can

424
00:24:48,880 --> 00:25:01,990
see the eye that's looking good so we

425
00:24:56,920 --> 00:25:04,390
have target video so we want to show and

426
00:25:01,990 --> 00:25:08,310
recurse her face then we take out the

427
00:25:04,390 --> 00:25:15,430
frames and then we detect the facial

428
00:25:08,310 --> 00:25:18,010
framework and then we kind of feed in

429
00:25:15,430 --> 00:25:23,500
the face of Mourinho with in each of the

430
00:25:18,010 --> 00:25:32,770
frames then we have we record some of

431
00:25:23,500 --> 00:25:34,960
the movements often trigger you would

432
00:25:32,770 --> 00:25:46,330
like to have the same conditions in the

433
00:25:34,960 --> 00:25:50,050
video the lighting and face so in two

434
00:25:46,330 --> 00:25:51,850
minutes we extracted nearly 30,000

435
00:25:50,050 --> 00:25:54,550
different faces for Enrique then we

436
00:25:51,850 --> 00:25:57,310
train the algorithm we have the series

437
00:25:54,550 --> 00:26:02,230
that I just told you the encoder when we

438
00:25:57,310 --> 00:26:05,500
input real images then we reduce the

439
00:26:02,230 --> 00:26:08,740
sizing we capture the characteristics of

440
00:26:05,500 --> 00:26:11,680
the real image and then decoder help us

441
00:26:08,740 --> 00:26:15,010
reconstruct the image from the elements

442
00:26:11,680 --> 00:26:16,840
here on the vector base so here we have

443
00:26:15,010 --> 00:26:19,270
D characteristics that help us

444
00:26:16,840 --> 00:26:22,840
reconstruct the image the more trained

445
00:26:19,270 --> 00:26:28,120
the algorithm is the better will be the

446
00:26:22,840 --> 00:26:31,990
output so we have Enrico side mourinho

447
00:26:28,120 --> 00:26:36,479
side and decoder encoder is essential is

448
00:26:31,990 --> 00:26:40,030
key because if the encoder couldn't use

449
00:26:36,480 --> 00:26:43,390
both sides of both faces we couldn't

450
00:26:40,030 --> 00:26:47,110
really cross the two faces

451
00:26:43,390 --> 00:26:50,740
but if we do it in this fashion this is

452
00:26:47,110 --> 00:26:53,590
one we will catch so we have an triggers

453
00:26:50,740 --> 00:26:56,590
original images Dantas and the

454
00:26:53,590 --> 00:26:58,780
reconstructed images then original image

455
00:26:56,590 --> 00:27:03,120
of Modena reconstructed images of

456
00:26:58,780 --> 00:27:09,940
Mourinho and now here in orange we have

457
00:27:03,120 --> 00:27:15,389
Modi new facial traits mixed with and

458
00:27:09,940 --> 00:27:15,390
liquor size okay and this is the mix

459
00:27:16,110 --> 00:27:21,820
okay

460
00:27:17,380 --> 00:27:25,809
these is a time lapse of one day okay

461
00:27:21,820 --> 00:27:41,110
becomes sharper and sharper the more you

462
00:27:25,809 --> 00:27:43,960
train it this is the the way it works we

463
00:27:41,110 --> 00:27:47,740
have the original mes and trend vector

464
00:27:43,960 --> 00:27:54,309
face then the color of Mourinho and then

465
00:27:47,740 --> 00:27:58,870
these will return the traits of Mourinho

466
00:27:54,309 --> 00:28:02,260
with and exercise here we can make a

467
00:27:58,870 --> 00:28:07,389
marine you behave as a pre-k was like

468
00:28:02,260 --> 00:28:12,190
him to behave and then change change it

469
00:28:07,390 --> 00:28:14,340
completely well but we will not be doing

470
00:28:12,190 --> 00:28:14,340
that

471
00:28:18,920 --> 00:28:24,080
someone recommend record the video of

472
00:28:21,440 --> 00:28:27,400
yourself and then apply louver

473
00:28:24,080 --> 00:28:31,460
marinos video so what the problem the

474
00:28:27,400 --> 00:28:33,410
big problem here would be me recording

475
00:28:31,460 --> 00:28:37,940
myself doing something which is really

476
00:28:33,410 --> 00:28:40,850
crazy and then I will just slope my face

477
00:28:37,940 --> 00:28:42,470
and put instead the face of a person

478
00:28:40,850 --> 00:28:45,020
that I really want to attack so we

479
00:28:42,470 --> 00:28:48,950
really wanted to see to investigate how

480
00:28:45,020 --> 00:28:54,740
we could work with JNC and these also

481
00:28:48,950 --> 00:28:57,380
allowed us to see how the co a fraud

482
00:28:54,740 --> 00:29:00,380
works we wanted to use this generative

483
00:28:57,380 --> 00:29:02,690
model and then before a web cam we could

484
00:29:00,380 --> 00:29:05,390
generate the face of a person that we

485
00:29:02,690 --> 00:29:06,679
want to impersonate her to swap so that

486
00:29:05,390 --> 00:29:09,110
the person would end up doing whatever

487
00:29:06,679 --> 00:29:12,490
they would like to do he that person to

488
00:29:09,110 --> 00:29:15,620
do for you so we use the face to face

489
00:29:12,490 --> 00:29:17,870
demo and we also use this library which

490
00:29:15,620 --> 00:29:19,010
is quite interesting depicts two peaks

491
00:29:17,870 --> 00:29:21,530
tensorflow

492
00:29:19,010 --> 00:29:22,940
so do you get an original video of a

493
00:29:21,530 --> 00:29:25,668
person the person you want to

494
00:29:22,940 --> 00:29:28,580
impersonate you have all the frames then

495
00:29:25,669 --> 00:29:34,150
to train the gun and once you can is

496
00:29:28,580 --> 00:29:34,149
trained then you generate fake images

497
00:29:35,440 --> 00:29:42,470
now we go to our CD which to youtube

498
00:29:40,280 --> 00:29:45,020
video with a white background because we

499
00:29:42,470 --> 00:29:53,960
also saw that with color background we

500
00:29:45,020 --> 00:29:58,790
had many problems the same plane the

501
00:29:53,960 --> 00:30:05,270
face hardly moves and it is easy to draw

502
00:29:58,790 --> 00:30:07,700
the facial landmarks puntos in conocido

503
00:30:05,270 --> 00:30:11,000
snake adele Rostova personas de este

504
00:30:07,700 --> 00:30:15,470
video a Chema a extra most asientos bent

505
00:30:11,000 --> 00:30:20,260
here we draw 208 714 frames to train our

506
00:30:15,470 --> 00:30:24,230
general model so then we proceeded to

507
00:30:20,260 --> 00:30:27,290
train the model it's a very simple it's

508
00:30:24,230 --> 00:30:30,520
very well explained so we were training

509
00:30:27,290 --> 00:30:30,520
our model

510
00:30:31,139 --> 00:30:36,689
once we had it trained and we saw that

511
00:30:34,480 --> 00:30:40,389
the generation of images did not improve

512
00:30:36,690 --> 00:30:44,409
we decided to test a model the first

513
00:30:40,389 --> 00:30:47,620
thing was to diminish the train model it

514
00:30:44,409 --> 00:30:53,309
was one gigabyte profiled so we had to

515
00:30:47,620 --> 00:30:56,289
reduce a train model so that the webcam

516
00:30:53,309 --> 00:30:59,950
could capture the image take the facial

517
00:30:56,289 --> 00:31:04,360
landmark so we could use the image as an

518
00:30:59,950 --> 00:31:08,019
input we reduced the models because we

519
00:31:04,360 --> 00:31:12,100
don't want multiple files and we don't

520
00:31:08,019 --> 00:31:14,730
need the metadata all the tensorflow we

521
00:31:12,100 --> 00:31:18,279
just want the weight of our architecture

522
00:31:14,730 --> 00:31:20,950
that's how we started testing now here

523
00:31:18,279 --> 00:31:25,950
we will give you a quick demo so you can

524
00:31:20,950 --> 00:31:25,950
see how it works

525
00:31:40,260 --> 00:31:45,519
vamos hacer es Nacimiento no creo que

526
00:31:43,450 --> 00:31:48,490
tenemos Kevin Python take this player to

527
00:31:45,519 --> 00:31:50,399
Pablo she was hugging input okay go get

528
00:31:48,490 --> 00:31:53,950
it okay

529
00:31:50,399 --> 00:31:56,428
anyone wants to make this engine okay

530
00:31:53,950 --> 00:31:56,429
I'll do it

531
00:31:57,450 --> 00:32:05,880
[Applause]

532
00:32:03,410 --> 00:32:09,780
[Laughter]

533
00:32:05,880 --> 00:32:12,990
nobody nobody not this time 100 years

534
00:32:09,780 --> 00:32:22,370
first we tests so that people can see I

535
00:32:12,990 --> 00:32:25,530
don't I

536
00:32:22,370 --> 00:32:28,830
muy importante Colo Carson ah it's very

537
00:32:25,530 --> 00:32:30,720
important to place yourself at similar

538
00:32:28,830 --> 00:32:37,350
distance to the end of Chima in the

539
00:32:30,720 --> 00:32:42,650
original video the good thing they

540
00:32:37,350 --> 00:32:51,719
copied facial features

541
00:32:42,650 --> 00:32:55,350
it's not perfect but there's no tricks

542
00:32:51,720 --> 00:33:05,130
here this is valid for anyone who would

543
00:32:55,350 --> 00:33:07,560
get in front of this webcam teeth

544
00:33:05,130 --> 00:33:16,880
missing because chairman never shows his

545
00:33:07,560 --> 00:33:16,879
teeth in the video ask for a raise

546
00:33:24,559 --> 00:33:37,960
okay thank you very much this is a model

547
00:33:34,190 --> 00:33:46,820
train for only three days and in fact we

548
00:33:37,960 --> 00:33:48,830
we had a hundred 1,024 we would have

549
00:33:46,820 --> 00:33:51,580
liked to increase it more but we

550
00:33:48,830 --> 00:33:54,710
couldn't because we needed eight

551
00:33:51,580 --> 00:34:36,310
gigabyte memory and this computer only

552
00:33:54,710 --> 00:34:39,199
has four what money where's the fedora

553
00:34:36,310 --> 00:34:41,980
corner mr. husai e-commerce decent Chima

554
00:34:39,199 --> 00:34:43,908
when we were so this guy becoming Chima

555
00:34:41,980 --> 00:34:46,490
there was a problem with the eyes

556
00:34:43,909 --> 00:34:50,679
apparently oh and the voice actually

557
00:34:46,489 --> 00:34:55,489
which is different so we have to see

558
00:34:50,679 --> 00:34:58,690
what AR can we use to generate audio do

559
00:34:55,489 --> 00:34:58,689
you recognize this voice now

560
00:35:03,910 --> 00:35:07,259
nor do apparently

561
00:35:09,510 --> 00:35:17,070
and I'm very busy are you available to

562
00:35:14,770 --> 00:35:20,710
handle an international payment of

563
00:35:17,070 --> 00:35:24,130
$15,000 this morning please find a way

564
00:35:20,710 --> 00:35:27,430
around it I am currently in Las Vegas

565
00:35:24,130 --> 00:35:29,890
and I'm very busy use this Iban number

566
00:35:27,430 --> 00:35:33,848
for the account where the money has to

567
00:35:29,890 --> 00:35:36,549
be sent take note of it yes nine one two

568
00:35:33,849 --> 00:35:39,400
one zero zero zero four one eight four

569
00:35:36,550 --> 00:35:41,560
five zero two zero zero zero five one

570
00:35:39,400 --> 00:35:43,270
three three two insert to send me the

571
00:35:41,560 --> 00:35:49,980
slip once it's done and don't tell

572
00:35:43,270 --> 00:35:49,980
anyone this transaction has to be but

573
00:35:50,640 --> 00:35:55,089
that's not funny erosion of computing a

574
00:35:52,839 --> 00:35:59,170
staff I'll say so this is this becomes a

575
00:35:55,089 --> 00:36:01,810
CDO swindled be encouraged both the

576
00:35:59,170 --> 00:36:04,589
image and the audio we wanted to match

577
00:36:01,810 --> 00:36:09,480
[Music]

578
00:36:04,589 --> 00:36:09,480
able to generate this image of Chema

579
00:36:10,320 --> 00:36:18,670
what real image is Enrique was saying

580
00:36:14,650 --> 00:36:21,010
with more time and more computing power

581
00:36:18,670 --> 00:36:23,980
it would have been better then we were

582
00:36:21,010 --> 00:36:25,569
concerned about the audio we were trying

583
00:36:23,980 --> 00:36:31,119
to see what we couldn't do with it so

584
00:36:25,569 --> 00:36:35,200
Microsoft has an API that we can use a

585
00:36:31,119 --> 00:36:38,050
neural network where we can train with

586
00:36:35,200 --> 00:36:40,720
the audio of an individual we can

587
00:36:38,050 --> 00:36:46,270
download videos from the internet when

588
00:36:40,720 --> 00:36:49,419
people are in speak they improve the way

589
00:36:46,270 --> 00:36:51,940
of speaking in Spanish this is not yet

590
00:36:49,420 --> 00:36:54,579
available if you put this advise voice

591
00:36:51,940 --> 00:36:56,079
in Spanish we would have someone it

592
00:36:54,579 --> 00:37:00,670
would be kind of weird it would be a

593
00:36:56,079 --> 00:37:04,599
Spanglish sort of thing so what we did

594
00:37:00,670 --> 00:37:08,560
was this we used this service to train

595
00:37:04,599 --> 00:37:12,369
the network downloading audios from

596
00:37:08,560 --> 00:37:14,578
YouTube in which Chema ends up speaking

597
00:37:12,369 --> 00:37:14,579
English

598
00:37:14,980 --> 00:37:23,750
then we divided it in 30 second

599
00:37:20,980 --> 00:37:29,140
recommendation was a bit more because

600
00:37:23,750 --> 00:37:29,140
the tone was a bit kind of a can with

601
00:37:29,260 --> 00:37:33,650
audio with the better audio source if

602
00:37:31,520 --> 00:37:36,320
would have looked more natural

603
00:37:33,650 --> 00:37:39,609
also we had to transcribe what Tim was

604
00:37:36,320 --> 00:37:44,839
saying in the video just rather to text

605
00:37:39,609 --> 00:37:48,920
for that we use a speech-to-text Google

606
00:37:44,839 --> 00:37:50,839
Cloud an API and then we uploaded orders

607
00:37:48,920 --> 00:37:53,680
and transcriptions to this service we

608
00:37:50,839 --> 00:38:01,660
started to train and eight hours later

609
00:37:53,680 --> 00:38:01,660
the result was okay then we said it is

610
00:38:04,599 --> 00:38:11,750
this tax so then where's Lucas please

611
00:38:09,800 --> 00:38:15,140
raise your hand Lucas Lucas

612
00:38:11,750 --> 00:38:18,440
how does he was working but he had just

613
00:38:15,140 --> 00:38:22,060
with the audio he said let's make this

614
00:38:18,440 --> 00:38:25,750
bit more real because it is important

615
00:38:22,060 --> 00:38:29,029
apart from the voice and the vibration

616
00:38:25,750 --> 00:38:38,140
he had some noise so you'll see there

617
00:38:29,030 --> 00:38:46,040
are some of the results here we have

618
00:38:38,140 --> 00:38:48,710
recent someone's faking Gemma and he

619
00:38:46,040 --> 00:38:52,579
says I can't right now

620
00:38:48,710 --> 00:38:56,869
I won't give you a call this text

621
00:38:52,579 --> 00:38:59,920
message says so are you available with

622
00:38:56,869 --> 00:38:59,920
his answers

623
00:39:01,310 --> 00:39:06,580
and it says yes so here's a call

624
00:39:09,170 --> 00:39:13,800
[Music]

625
00:39:40,810 --> 00:39:46,400
so to send me the slip once it's done

626
00:39:43,520 --> 00:39:50,109
and don't tell anyone this transaction

627
00:39:46,400 --> 00:39:54,490
has to be supervised only by you

628
00:39:50,109 --> 00:40:04,190
well if you're not by the boys okay

629
00:39:54,490 --> 00:40:07,669
that's the results I told them regular

630
00:40:04,190 --> 00:40:11,780
we had to test this with someone to see

631
00:40:07,670 --> 00:40:14,240
how credible the audio can be under

632
00:40:11,780 --> 00:40:19,700
under image so then we started making

633
00:40:14,240 --> 00:40:27,109
tests we wanted to diminish the metallic

634
00:40:19,700 --> 00:40:31,189
that can sound so we started to see that

635
00:40:27,109 --> 00:40:35,630
people could actually go for it could

636
00:40:31,190 --> 00:40:38,450
actually buy so then we were talking

637
00:40:35,630 --> 00:40:43,270
about email and here we have a video

638
00:40:38,450 --> 00:40:45,169
which is very real audio someone is

639
00:40:43,270 --> 00:40:51,380
substituting the identity of someone

640
00:40:45,170 --> 00:40:56,140
else as well we have seen it's quite

641
00:40:51,380 --> 00:40:56,140
easy to generate these fake

642
00:40:57,040 --> 00:41:03,790
personalities you don't need to have a

643
00:40:58,910 --> 00:41:07,910
physical test you can use cloud services

644
00:41:03,790 --> 00:41:10,970
which can cost between 300 and 1000

645
00:41:07,910 --> 00:41:12,799
euros depends on the gigabytes it could

646
00:41:10,970 --> 00:41:15,250
we could go up to three point two

647
00:41:12,800 --> 00:41:19,690
thousand euros and in the cloud bottom

648
00:41:15,250 --> 00:41:24,980
it's very simple to generate this

649
00:41:19,690 --> 00:41:27,860
contents to deceive people three people

650
00:41:24,980 --> 00:41:29,990
working for a few days we were able to

651
00:41:27,860 --> 00:41:37,970
do this imagine what you can do with a

652
00:41:29,990 --> 00:41:45,859
dedicated team with substantial

653
00:41:37,970 --> 00:41:50,540
resources source of fake news one of the

654
00:41:45,860 --> 00:41:54,650
first to appear was text fake news to

655
00:41:50,540 --> 00:41:56,960
confuse people we have an overexposure

656
00:41:54,650 --> 00:42:02,060
to information and we know social media

657
00:41:56,960 --> 00:42:05,150
and all sorts of digital media and we

658
00:42:02,060 --> 00:42:08,140
tend to believe absolutely everything

659
00:42:05,150 --> 00:42:11,840
that is written because we read

660
00:42:08,140 --> 00:42:15,049
information from sites in which we trust

661
00:42:11,840 --> 00:42:21,850
and we with we're identifiable so this

662
00:42:15,050 --> 00:42:29,630
makes it easier to disseminate fake news

663
00:42:21,850 --> 00:42:31,850
so 5 percent may believe it so that you

664
00:42:29,630 --> 00:42:33,890
can see it as a success there are a

665
00:42:31,850 --> 00:42:36,620
number of resources nowadays that allow

666
00:42:33,890 --> 00:42:41,830
you to determine whatever news is a fake

667
00:42:36,620 --> 00:42:41,830
or not talking about supervised learning

668
00:42:43,300 --> 00:42:50,830
so you have to take news to determine

669
00:42:47,200 --> 00:42:53,169
whether a false or true one and zero

670
00:42:50,830 --> 00:42:57,220
with deep learning and machine learning

671
00:42:53,170 --> 00:43:02,700
algorithms for natural language

672
00:42:57,220 --> 00:43:02,700
processing so you can obtain a model

673
00:43:03,690 --> 00:43:09,700
submitted to these procedures it look of

674
00:43:06,310 --> 00:43:15,490
you a result fake or true this is a

675
00:43:09,700 --> 00:43:19,750
well-known procedures and services to

676
00:43:15,490 --> 00:43:23,500
analyze the truthfulness of the news

677
00:43:19,750 --> 00:43:27,090
that you read so if you want to protect

678
00:43:23,500 --> 00:43:31,869
yourself from that content you can use

679
00:43:27,090 --> 00:43:40,140
many services we found a couple which

680
00:43:31,869 --> 00:43:43,720
are highly intuitive so you could see

681
00:43:40,140 --> 00:43:48,220
whether the fake whether the news was

682
00:43:43,720 --> 00:43:49,299
fake or legit if it was a satirical or

683
00:43:48,220 --> 00:43:52,419
cynical

684
00:43:49,300 --> 00:43:53,910
so then we have a fake news detector

685
00:43:52,420 --> 00:43:57,240
which is called

686
00:43:53,910 --> 00:43:59,049
Robinho but if he said and then we had a

687
00:43:57,240 --> 00:44:02,709
service

688
00:43:59,050 --> 00:44:06,010
there's called fake box you just send it

689
00:44:02,710 --> 00:44:11,760
the URL of the news and making a quick

690
00:44:06,010 --> 00:44:11,760
analysis and return you a probability of

691
00:44:12,570 --> 00:44:18,310
being fake it's someone that you want to

692
00:44:15,790 --> 00:44:25,119
take a look we'll have a small demo

693
00:44:18,310 --> 00:44:27,970
later on about how you can use ia to to

694
00:44:25,119 --> 00:44:30,760
the service of the of genuine news and

695
00:44:27,970 --> 00:44:34,839
biometric patterns and videos however

696
00:44:30,760 --> 00:44:37,410
very few that are not supported by

697
00:44:34,840 --> 00:44:40,690
individual material that are purely text

698
00:44:37,410 --> 00:44:45,250
so here we come back to fake news and

699
00:44:40,690 --> 00:44:47,770
fake videos which are becoming more

700
00:44:45,250 --> 00:44:49,240
sophisticated and it's very difficult to

701
00:44:47,770 --> 00:44:51,320
see whether the content that you're

702
00:44:49,240 --> 00:44:52,939
viewing is legitimate

703
00:44:51,320 --> 00:44:55,610
number of group and there's a group from

704
00:44:52,940 --> 00:44:59,090
the MIT that is looking for my matron of

705
00:44:55,610 --> 00:45:00,610
a pattern in these videos allows you to

706
00:44:59,090 --> 00:45:05,890
determine where the videos false or not

707
00:45:00,610 --> 00:45:08,510
we found an interest in publication

708
00:45:05,890 --> 00:45:11,089
based of the video by Jennifer Lawrence

709
00:45:08,510 --> 00:45:15,020
in which the analyzed with a lack of all

710
00:45:11,090 --> 00:45:17,000
the excess of blinking as a sample that

711
00:45:15,020 --> 00:45:20,000
you are in the print that you're

712
00:45:17,000 --> 00:45:21,950
watching a fake video in addition to the

713
00:45:20,000 --> 00:45:24,650
color histograms in the contour of the

714
00:45:21,950 --> 00:45:29,960
face to determine whether the face has

715
00:45:24,650 --> 00:45:33,380
been overlapped was automated this

716
00:45:29,960 --> 00:45:37,120
person make here we made a face swapping

717
00:45:33,380 --> 00:45:40,280
with Nicolas Cage and in frame of 75

718
00:45:37,120 --> 00:45:42,790
Nicolas Cage doesn't blink but in the

719
00:45:40,280 --> 00:45:47,480
original he does so we make use of

720
00:45:42,790 --> 00:45:49,970
recurring convoluted networks to detect

721
00:45:47,480 --> 00:45:51,890
false videos and this includes a

722
00:45:49,970 --> 00:45:56,480
probability of the eye being closed

723
00:45:51,890 --> 00:45:58,129
announced so this now just to determine

724
00:45:56,480 --> 00:46:03,100
with high precision when the video was

725
00:45:58,130 --> 00:46:07,010
false or not we couldn't reproduce this

726
00:46:03,100 --> 00:46:08,089
he'll see that was quite interesting we

727
00:46:07,010 --> 00:46:11,120
said okay

728
00:46:08,090 --> 00:46:14,320
as we have small knowledge of machine

729
00:46:11,120 --> 00:46:17,509
learning let us build a classifier

730
00:46:14,320 --> 00:46:21,890
making use of typical features that we

731
00:46:17,510 --> 00:46:32,270
can draw from a video in this case is

732
00:46:21,890 --> 00:46:37,120
the duration of the blinking blink all

733
00:46:32,270 --> 00:46:41,410
those biometric parameters are tabled

734
00:46:37,120 --> 00:46:41,410
many publications on this

735
00:46:42,700 --> 00:46:46,629
people from different sects on for

736
00:46:44,840 --> 00:46:49,910
different condition and different

737
00:46:46,630 --> 00:46:53,330
characteristics blink at various rates

738
00:46:49,910 --> 00:46:57,920
so on that basis they say you can say

739
00:46:53,330 --> 00:47:01,009
whether you are watching a thankful

740
00:46:57,920 --> 00:47:05,150
video or not if you're reading during a

741
00:47:01,010 --> 00:47:07,340
blink maybe it wants a result second but

742
00:47:05,150 --> 00:47:15,310
if you talking to someone you blink much

743
00:47:07,340 --> 00:47:22,090
more frequently so we try to find these

744
00:47:15,310 --> 00:47:25,880
exceptions duration and number and

745
00:47:22,090 --> 00:47:27,980
minimum separation between blinking so

746
00:47:25,880 --> 00:47:32,150
here we have one of the papers

747
00:47:27,980 --> 00:47:35,780
connecting all these data on blinking

748
00:47:32,150 --> 00:47:40,370
rates so what we did was create gaussian

749
00:47:35,780 --> 00:47:43,610
classifier on the basis of blinking

750
00:47:40,370 --> 00:47:50,600
speed so we established a normal

751
00:47:43,610 --> 00:47:52,970
distribution we tested our videos

752
00:47:50,600 --> 00:47:56,600
against that model so it works very much

753
00:47:52,970 --> 00:48:00,169
the idea is simple it's improvable of

754
00:47:56,600 --> 00:48:05,960
course many more characteristics can be

755
00:48:00,170 --> 00:48:10,940
included but the basic test is that we

756
00:48:05,960 --> 00:48:16,070
have for instance that video in the case

757
00:48:10,940 --> 00:48:20,200
of showing Pablo's face actual videos

758
00:48:16,070 --> 00:48:24,590
only Yale and Pablo were labeled as true

759
00:48:20,200 --> 00:48:28,220
videos whereas the face swapping wizard

760
00:48:24,590 --> 00:48:32,170
went upward and was rated as false and

761
00:48:28,220 --> 00:48:35,709
the same as the one of Jennifer Lawrence

762
00:48:32,170 --> 00:48:35,710
and Jennifer

763
00:48:35,989 --> 00:48:45,150
locus all these videos were tested and

764
00:48:42,499 --> 00:48:48,868
one was catalog that's true but then the

765
00:48:45,150 --> 00:48:54,299
face swapping changed the thing

766
00:48:48,869 --> 00:48:57,719
completely so both and videos had an

767
00:48:54,299 --> 00:49:04,499
excess of blinking these are either

768
00:48:57,719 --> 00:49:06,150
original video this is just a simple

769
00:49:04,499 --> 00:49:10,468
example of how to protect ourselves

770
00:49:06,150 --> 00:49:14,900
against this type of attacks but as the

771
00:49:10,469 --> 00:49:14,900
passage of time these models improve and

772
00:49:17,119 --> 00:49:23,159
at an exponential rate so it will be

773
00:49:21,119 --> 00:49:23,969
complicated to differentiate one from

774
00:49:23,159 --> 00:49:28,559
another

775
00:49:23,969 --> 00:49:31,049
so regards conclusions well to finish we

776
00:49:28,559 --> 00:49:31,499
have just one minute I think one minute

777
00:49:31,049 --> 00:49:36,239
left

778
00:49:31,499 --> 00:49:38,038
the first conclusion is that it becomes

779
00:49:36,239 --> 00:49:42,329
difficult to differentiate what is real

780
00:49:38,039 --> 00:49:44,939
and what is not the first thing we have

781
00:49:42,329 --> 00:49:46,679
to think about is how we can protect

782
00:49:44,939 --> 00:49:48,989
ourselves from what is real and what is

783
00:49:46,679 --> 00:49:51,569
not real because all the individual

784
00:49:48,989 --> 00:49:53,849
freedoms and we owe that we have

785
00:49:51,569 --> 00:49:58,380
constructed throughout our history will

786
00:49:53,849 --> 00:50:03,329
be worthless second clusion is that

787
00:49:58,380 --> 00:50:09,749
cheating people is cheap it's not

788
00:50:03,329 --> 00:50:13,979
expensive in this domain because just we

789
00:50:09,749 --> 00:50:15,959
use a device that anyone can buy very

790
00:50:13,979 --> 00:50:21,269
low training our learning curve to

791
00:50:15,959 --> 00:50:24,448
three.js custom voice devices and this

792
00:50:21,269 --> 00:50:30,390
is available 21 and it can be used for

793
00:50:24,449 --> 00:50:32,369
good things or bad things for us one

794
00:50:30,390 --> 00:50:35,368
conclusion is there

795
00:50:32,369 --> 00:50:40,079
the AAA and some security will go hand

796
00:50:35,369 --> 00:50:43,619
in hand towards the future and limits of

797
00:50:40,079 --> 00:50:46,229
ia have not been set

798
00:50:43,619 --> 00:50:50,819
some security will be strengthened as

799
00:50:46,229 --> 00:50:52,379
well as attacked by artificial

800
00:50:50,819 --> 00:50:55,589
intelligence so we have to be aware of

801
00:50:52,380 --> 00:50:57,809
this and take it into account knowledge

802
00:50:55,589 --> 00:51:00,119
and awareness are the pillars on which

803
00:50:57,809 --> 00:51:04,170
we have we will again support ourselves

804
00:51:00,119 --> 00:51:09,690
to protect ourselves so awareness and

805
00:51:04,170 --> 00:51:15,259
knowledge of all the whole society is

806
00:51:09,690 --> 00:51:28,079
essential so any questions or comments

807
00:51:15,259 --> 00:51:31,049
we'll be working very low-cost very few

808
00:51:28,079 --> 00:51:34,920
days oh my god I was sending this to my

809
00:51:31,049 --> 00:51:40,499
work colleagues this is the CEOs a

810
00:51:34,920 --> 00:51:43,829
swindle questions you have to go where

811
00:51:40,499 --> 00:51:46,558
the mics are I have one actually just as

812
00:51:43,829 --> 00:51:48,839
you made a training model on to land the

813
00:51:46,559 --> 00:51:51,329
final interest points of the face and

814
00:51:48,839 --> 00:51:53,849
all that you make a second

815
00:51:51,329 --> 00:51:56,039
post-production stage to clean all the

816
00:51:53,849 --> 00:51:59,039
details that make the videos different

817
00:51:56,039 --> 00:52:01,859
and you can do that professional in the

818
00:51:59,039 --> 00:52:05,910
video and the perfect there's nobody who

819
00:52:01,859 --> 00:52:08,848
can differentiate anything that is the

820
00:52:05,910 --> 00:52:11,460
first example shown by Pablo of Obama

821
00:52:08,849 --> 00:52:14,579
that is very intelligent approach they

822
00:52:11,460 --> 00:52:18,710
take his original video and they

823
00:52:14,579 --> 00:52:22,410
reproduced the speech with generative

824
00:52:18,710 --> 00:52:23,880
movement of his lips so he ends up

825
00:52:22,410 --> 00:52:26,368
saying something else than what he

826
00:52:23,880 --> 00:52:29,160
originally said so any other any

827
00:52:26,369 --> 00:52:33,329
question any microphone that wants to

828
00:52:29,160 --> 00:52:36,210
speak up this is a good for hybrid war

829
00:52:33,329 --> 00:52:41,010
attacks I invent us and Mary

830
00:52:36,210 --> 00:52:43,710
if I can get in to a electric generator

831
00:52:41,010 --> 00:52:47,130
and cause glitches in one area I

832
00:52:43,710 --> 00:52:51,150
recorded I get a president of the CEO of

833
00:52:47,130 --> 00:52:53,160
our utility i hack a news I invented and

834
00:52:51,150 --> 00:52:55,619
say that is we have a suspected nuclear

835
00:52:53,160 --> 00:52:58,259
attack in this area and you cause

836
00:52:55,619 --> 00:53:02,780
glitches in the city and you release

837
00:52:58,260 --> 00:53:06,420
these news when information is power and

838
00:53:02,780 --> 00:53:09,089
what we see is what we believe so we

839
00:53:06,420 --> 00:53:11,790
need to have a critical thought and put

840
00:53:09,089 --> 00:53:14,160
into doubt into question whether what

841
00:53:11,790 --> 00:53:18,390
we've seen is real we have to invent a

842
00:53:14,160 --> 00:53:23,250
foam atom not to differentiate what is

843
00:53:18,390 --> 00:53:27,618
real and what is bogus yeah impressive I

844
00:53:23,250 --> 00:53:27,619
have a question where are you at the top

845
00:53:30,800 --> 00:53:37,320
intelligence and planning for

846
00:53:34,349 --> 00:53:39,599
classifying events I have a system that

847
00:53:37,320 --> 00:53:43,859
collect these events from many servers

848
00:53:39,599 --> 00:53:46,230
and I would like to be told through

849
00:53:43,859 --> 00:53:48,690
these techniques when the an event

850
00:53:46,230 --> 00:53:54,260
response to malicious event and I have

851
00:53:48,690 --> 00:53:57,780
training I have the usual the routine

852
00:53:54,260 --> 00:54:01,500
which is not malicious so when we talk

853
00:53:57,780 --> 00:54:07,650
about anomalies we had a similar case it

854
00:54:01,500 --> 00:54:11,070
was supervised which are normal events

855
00:54:07,650 --> 00:54:13,080
in a system and which are non usually

856
00:54:11,070 --> 00:54:15,119
that's enabled a massage so then the

857
00:54:13,080 --> 00:54:16,770
system learns so when you are in

858
00:54:15,119 --> 00:54:19,470
production you will have this

859
00:54:16,770 --> 00:54:25,910
classification of events this has been

860
00:54:19,470 --> 00:54:29,549
classified in which this is a case all

861
00:54:25,910 --> 00:54:32,098
normal events I only have abnormal

862
00:54:29,550 --> 00:54:33,980
events when I'm attacked well it had to

863
00:54:32,099 --> 00:54:39,059
generate

864
00:54:33,980 --> 00:54:42,630
mimic attacks well it's a very case with

865
00:54:39,059 --> 00:54:44,880
the anomalies thank you very much thank

866
00:54:42,630 --> 00:54:45,610
you that was great great presentation

867
00:54:44,880 --> 00:54:48,849
thinking

868
00:54:45,610 --> 00:54:48,849
[Applause]

