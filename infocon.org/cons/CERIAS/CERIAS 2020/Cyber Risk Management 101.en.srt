1
00:00:00,000 --> 00:00:05,370
so let's get us started so this is our

2
00:00:02,490 --> 00:00:05,910
first time using WebEx we'll see how it

3
00:00:05,370 --> 00:00:10,969
goes

4
00:00:05,910 --> 00:00:13,500
and during the speak please mute your

5
00:00:10,969 --> 00:00:17,789
speaker because you know this could

6
00:00:13,500 --> 00:00:19,590
cause some trouble for WebEx so it's my

7
00:00:17,789 --> 00:00:22,920
honor and a pleasure to introduce our

8
00:00:19,590 --> 00:00:25,740
speaker Nick sturgeon currently serves

9
00:00:22,920 --> 00:00:28,410
as a director of information security

10
00:00:25,740 --> 00:00:31,650
for IU Health and IU School of Medicine

11
00:00:28,410 --> 00:00:33,719
his responsibilities include supporting

12
00:00:31,650 --> 00:00:36,690
the IU School of Medicine cyber risk

13
00:00:33,719 --> 00:00:40,020
management program and leading IU Health

14
00:00:36,690 --> 00:00:42,000
security research and read team has

15
00:00:40,020 --> 00:00:44,340
worked in information technology for

16
00:00:42,000 --> 00:00:46,739
over 15 years with 10 years in

17
00:00:44,340 --> 00:00:49,230
cybersecurity nine years in law

18
00:00:46,739 --> 00:00:52,078
enforcement and 10 years in state

19
00:00:49,230 --> 00:00:53,398
government he earned his Bachelor of

20
00:00:52,079 --> 00:00:58,020
Science in management information

21
00:00:53,399 --> 00:01:00,149
systems from Indiana State in 2003 and a

22
00:00:58,020 --> 00:01:04,290
Master of Science in cyber forensics

23
00:01:00,149 --> 00:01:07,439
from Purdue 2015 he has extensive

24
00:01:04,290 --> 00:01:09,930
experience in Incident Response digital

25
00:01:07,439 --> 00:01:13,500
investigations Criminal Investigations

26
00:01:09,930 --> 00:01:16,650
digital media recovery criminal law data

27
00:01:13,500 --> 00:01:18,900
governance endpoint protection Network

28
00:01:16,650 --> 00:01:21,900
and log analysis vulnerability

29
00:01:18,900 --> 00:01:24,360
management security operations incident

30
00:01:21,900 --> 00:01:27,270
management protocol amendment project

31
00:01:24,360 --> 00:01:29,689
management as an instructor and a

32
00:01:27,270 --> 00:01:32,789
service implementation of management

33
00:01:29,689 --> 00:01:35,880
security services throughout his career

34
00:01:32,790 --> 00:01:39,180
he has supported multiple industries and

35
00:01:35,880 --> 00:01:42,810
sectors including academia state local

36
00:01:39,180 --> 00:01:45,570
tribal territorial governments

37
00:01:42,810 --> 00:01:48,600
healthcare information technology and

38
00:01:45,570 --> 00:01:51,479
manufacturing addition to his current

39
00:01:48,600 --> 00:01:53,579
duties nique is a host on to podcasts

40
00:01:51,479 --> 00:01:56,820
he's a part-time information security

41
00:01:53,579 --> 00:01:59,669
instructor at UTSA and adjunct professor

42
00:01:56,820 --> 00:02:02,339
at the University of Southern Indiana he

43
00:01:59,670 --> 00:02:05,579
also serves as a board member for the

44
00:02:02,340 --> 00:02:08,039
cyber resilience Institute Ohio River

45
00:02:05,579 --> 00:02:10,679
Valley Chapter of the cloud security

46
00:02:08,038 --> 00:02:13,890
Alliance and the National Council of

47
00:02:10,679 --> 00:02:16,860
registered IAEA OS

48
00:02:13,890 --> 00:02:19,880
with FERPA adieu let's welcome Nica hey

49
00:02:16,860 --> 00:02:23,910
thank you guys for having me on and I

50
00:02:19,880 --> 00:02:27,420
will say I'm glad I'm against the guinea

51
00:02:23,910 --> 00:02:32,180
pig for this new setup given our current

52
00:02:27,420 --> 00:02:35,839
circumstances with Kovan 19 and actually

53
00:02:32,180 --> 00:02:40,770
we talked about what's going on now with

54
00:02:35,840 --> 00:02:44,670
Ovid 19 in risk management is perfect

55
00:02:40,770 --> 00:02:49,459
this is a really good introduction into

56
00:02:44,670 --> 00:02:53,929
why cyber risk management is needed and

57
00:02:49,459 --> 00:02:53,930
with all the additional

58
00:02:54,210 --> 00:03:01,120
constraints on resources and new

59
00:02:57,430 --> 00:03:05,310
potential vectors or cybercriminals to

60
00:03:01,120 --> 00:03:12,460
utilize the work from home situation or

61
00:03:05,310 --> 00:03:16,390
the crisis so you benefit themselves

62
00:03:12,460 --> 00:03:18,850
it's really perfect for the discussion

63
00:03:16,390 --> 00:03:20,769
on cyber risk management so I want to

64
00:03:18,850 --> 00:03:24,430
thank you guys for allowing me to come

65
00:03:20,770 --> 00:03:28,410
in to talk about cyber risk management

66
00:03:24,430 --> 00:03:33,340
and and why it's important or an overall

67
00:03:28,410 --> 00:03:36,700
cybersecurity program I am going to

68
00:03:33,340 --> 00:03:39,750
share my screen here get the

69
00:03:36,700 --> 00:03:39,750
presentation up

70
00:03:39,970 --> 00:03:42,030
you

71
00:03:42,380 --> 00:03:44,650
sure

72
00:03:46,640 --> 00:03:49,869
[Music]

73
00:03:50,329 --> 00:03:54,650
so can you guys see my screen

74
00:03:55,760 --> 00:04:06,709
yep okay so I developed this

75
00:04:03,530 --> 00:04:08,930
presentation more for kind of an

76
00:04:06,709 --> 00:04:11,709
introductory into what cyber risk

77
00:04:08,930 --> 00:04:11,709
management is

78
00:04:12,080 --> 00:04:19,239
a little bit technical going to cover

79
00:04:14,720 --> 00:04:19,238
some of the frameworks and

80
00:04:19,410 --> 00:04:25,020
in just the background and standards and

81
00:04:22,740 --> 00:04:28,380
regulations so this is really a

82
00:04:25,020 --> 00:04:30,979
high-level overview of cyber risk

83
00:04:28,380 --> 00:04:30,980
management

84
00:04:32,810 --> 00:04:38,300
so but why does this matter I mean

85
00:04:35,240 --> 00:04:41,780
bottom line up front why do

86
00:04:38,300 --> 00:04:45,680
organizations why with all the the

87
00:04:41,780 --> 00:04:49,309
technologies and everything that's going

88
00:04:45,680 --> 00:04:52,850
on in cybersecurity why does why do we

89
00:04:49,310 --> 00:04:56,090
need a risk management program in really

90
00:04:52,850 --> 00:05:01,600
bottom line is it's to help prevent

91
00:04:56,090 --> 00:05:04,520
businesses shutting their doors exposing

92
00:05:01,600 --> 00:05:08,440
information whether it's customer data

93
00:05:04,520 --> 00:05:13,690
its health information

94
00:05:08,440 --> 00:05:13,690
PII Eph I all of that stuff

95
00:05:14,960 --> 00:05:25,570
risk management goes into helping

96
00:05:21,460 --> 00:05:25,570
keeping this stuff from happening

97
00:05:26,280 --> 00:05:34,159
and since I'm talking to you know an

98
00:05:28,680 --> 00:05:40,290
academic group I mean it's not just the

99
00:05:34,160 --> 00:05:43,380
high-end P I you know or IP sorry the

100
00:05:40,290 --> 00:05:47,270
intellectual property that companies

101
00:05:43,380 --> 00:05:49,889
have it's research data that is being

102
00:05:47,270 --> 00:05:55,909
sought after just as much as anything

103
00:05:49,889 --> 00:06:01,950
else the the potentials beyond just the

104
00:05:55,910 --> 00:06:06,030
public relations impact or the loss of

105
00:06:01,950 --> 00:06:10,050
data or some of the other things that we

106
00:06:06,030 --> 00:06:13,429
think about when we think of loss from a

107
00:06:10,050 --> 00:06:16,440
cyber incident but it's also the

108
00:06:13,430 --> 00:06:18,750
government regulation and regulators

109
00:06:16,440 --> 00:06:23,840
that are coming out with their fines and

110
00:06:18,750 --> 00:06:27,870
their penalties for failing to implement

111
00:06:23,840 --> 00:06:31,469
cybersecurity within your organization I

112
00:06:27,870 --> 00:06:36,960
mean all of that are the negative

113
00:06:31,470 --> 00:06:42,320
outcomes of failed cyber risk management

114
00:06:36,960 --> 00:06:42,320
or a lack of cyber risk management

115
00:06:43,029 --> 00:06:52,029
some case study now this particular case

116
00:06:46,899 --> 00:06:54,309
I'm leaving out the particular city / to

117
00:06:52,029 --> 00:07:00,339
protect the innocent as well as the

118
00:06:54,309 --> 00:07:04,929
guilty probably won't take a detective

119
00:07:00,339 --> 00:07:08,549
to figure out which city were talking

120
00:07:04,929 --> 00:07:12,669
about but a very large major u.s. city

121
00:07:08,549 --> 00:07:15,529
was hit with samsam ransomware variant

122
00:07:12,669 --> 00:07:18,378
back in 2018

123
00:07:15,529 --> 00:07:21,979
what we have here is just kind of the

124
00:07:18,379 --> 00:07:25,149
the very high level of facts of what

125
00:07:21,979 --> 00:07:28,449
happened thousands of city employees

126
00:07:25,149 --> 00:07:31,909
could not get access to their computers

127
00:07:28,449 --> 00:07:36,589
agencies law enforcement courts could

128
00:07:31,909 --> 00:07:38,808
not do their civic duties there the

129
00:07:36,589 --> 00:07:41,689
things that they are set up to do to

130
00:07:38,809 --> 00:07:45,229
provide services to citizens people

131
00:07:41,689 --> 00:07:48,699
couldn't pay their water bill traffic

132
00:07:45,229 --> 00:07:53,340
tickets again could not be processed

133
00:07:48,699 --> 00:07:58,990
in several years worth of body cam data

134
00:07:53,340 --> 00:08:01,919
from the police department was gone just

135
00:07:58,990 --> 00:08:08,189
think of the on that from a criminal

136
00:08:01,919 --> 00:08:12,900
aspect in Criminal Justice the evidence

137
00:08:08,189 --> 00:08:17,590
that could have put somebody in jail

138
00:08:12,900 --> 00:08:20,159
that had committed anywhere for minor

139
00:08:17,590 --> 00:08:23,619
traffic infractions all the way up to

140
00:08:20,159 --> 00:08:28,139
very serious crimes that evidence is

141
00:08:23,620 --> 00:08:32,240
gone it cannot be used because of this

142
00:08:28,139 --> 00:08:36,460
particular cyber incident

143
00:08:32,240 --> 00:08:39,580
and I depending on which

144
00:08:36,460 --> 00:08:41,800
number you read and which article that

145
00:08:39,580 --> 00:08:45,610
she read on this it's anywhere from 17

146
00:08:41,799 --> 00:08:50,020
and 218 million dollars worth of damage

147
00:08:45,610 --> 00:08:52,090
to this city that's a lot of money state

148
00:08:50,020 --> 00:08:55,780
government city governments whether

149
00:08:52,090 --> 00:08:59,120
large or small that amount of money does

150
00:08:55,780 --> 00:09:02,930
a lot of

151
00:08:59,120 --> 00:09:07,410
damage and that's a big part of a budget

152
00:09:02,930 --> 00:09:08,969
in all of the citizens that aren't able

153
00:09:07,410 --> 00:09:11,750
to take care of the things that they

154
00:09:08,970 --> 00:09:14,940
need to take care of because the city

155
00:09:11,750 --> 00:09:21,480
didn't have access to a good portion of

156
00:09:14,940 --> 00:09:23,190
its IT systems huge impact and this is

157
00:09:21,480 --> 00:09:25,949
something that's this city is probably

158
00:09:23,190 --> 00:09:26,790
still dealing with today even the

159
00:09:25,949 --> 00:09:31,319
positives

160
00:09:26,790 --> 00:09:33,319
out of this incident will be felt for

161
00:09:31,320 --> 00:09:36,120
years to come now I had an opportunity

162
00:09:33,320 --> 00:09:39,089
last summer to meet one of the

163
00:09:36,120 --> 00:09:44,490
individuals and listen to her talk and

164
00:09:39,089 --> 00:09:47,510
she was I I can't remember her exact

165
00:09:44,490 --> 00:09:51,480
position then it was it may have been a

166
00:09:47,510 --> 00:09:52,760
CIS Oh row or or someone very high

167
00:09:51,480 --> 00:09:56,250
within their security department

168
00:09:52,760 --> 00:10:00,389
listening to their response and and what

169
00:09:56,250 --> 00:10:04,019
they had to do as a result of this it

170
00:10:00,389 --> 00:10:08,160
was fascinating from an incident

171
00:10:04,019 --> 00:10:11,459
response perspective the impact is going

172
00:10:08,160 --> 00:10:13,769
to be felt for years to come and here's

173
00:10:11,459 --> 00:10:18,719
the thing

174
00:10:13,769 --> 00:10:25,949
it could have most likely been avoided

175
00:10:18,720 --> 00:10:28,439
and in their after-action report what

176
00:10:25,949 --> 00:10:30,660
was found in one of the big things here

177
00:10:28,439 --> 00:10:34,439
as you can see in bold is there were

178
00:10:30,660 --> 00:10:38,579
gaps in their formal risk assessment had

179
00:10:34,439 --> 00:10:42,329
they taken it seriously had they put the

180
00:10:38,579 --> 00:10:45,079
proper amount of resources and time and

181
00:10:42,329 --> 00:10:51,420
attention into doing a risk assessment

182
00:10:45,079 --> 00:10:53,519
and doing one right in my opinion that

183
00:10:51,420 --> 00:10:57,118
incident probably would not have

184
00:10:53,519 --> 00:11:00,660
happened and if it did it probably would

185
00:10:57,119 --> 00:11:03,319
have been minimized in its scale and

186
00:11:00,660 --> 00:11:03,319
impact

187
00:11:05,960 --> 00:11:13,190
so I've covered a little bit of the

188
00:11:09,140 --> 00:11:18,280
topics of what we're going to get

189
00:11:13,190 --> 00:11:18,280
through so I won't read this verbatim

190
00:11:18,370 --> 00:11:24,100
but as we get into it you know let's

191
00:11:22,629 --> 00:11:27,209
let's start from the beginning I'm going

192
00:11:24,100 --> 00:11:30,089
to assume that

193
00:11:27,209 --> 00:11:32,339
you guys don't know what cyber risk

194
00:11:30,089 --> 00:11:33,990
management is it's not a insult on

195
00:11:32,339 --> 00:11:36,839
anybody's intelligence but I want to

196
00:11:33,990 --> 00:11:39,389
make sure we get on a solid base and

197
00:11:36,839 --> 00:11:45,059
that we're all going from this point

198
00:11:39,389 --> 00:11:47,369
forward from the same same point so I'm

199
00:11:45,059 --> 00:11:49,079
sure most everybody here has heard of

200
00:11:47,369 --> 00:11:52,529
NIST the National Institute for

201
00:11:49,079 --> 00:12:08,368
Standards and Technology and their

202
00:11:52,529 --> 00:12:11,429
special publication 800-53 and the

203
00:12:08,369 --> 00:12:18,729
impact of the occurrence now there's

204
00:12:11,429 --> 00:12:22,069
some really key points in this and

205
00:12:18,729 --> 00:12:27,969
probability and impact so what is the

206
00:12:22,069 --> 00:12:31,039
chance or the likelihood of a bad thing

207
00:12:27,969 --> 00:12:35,299
happening and then what is the impact

208
00:12:31,039 --> 00:12:39,109
and I know being at from Purdue when we

209
00:12:35,299 --> 00:12:42,249
talk about quantification and in wanting

210
00:12:39,109 --> 00:12:45,859
hard data to make good decisions

211
00:12:42,249 --> 00:12:49,249
probability is quantifiable the same

212
00:12:45,859 --> 00:12:54,499
thing with impact that can be dollars it

213
00:12:49,249 --> 00:12:56,869
could be days out of service or whatever

214
00:12:54,499 --> 00:12:59,239
it may be but we can use those two

215
00:12:56,869 --> 00:13:01,449
points to help quantify our decision

216
00:12:59,239 --> 00:13:01,449
making

217
00:13:02,910 --> 00:13:08,219
so some of the elements of risk we have

218
00:13:05,640 --> 00:13:11,520
our threats these are the could be the

219
00:13:08,220 --> 00:13:14,640
bad guys that are out there that want to

220
00:13:11,520 --> 00:13:18,150
attack our individual organizations

221
00:13:14,640 --> 00:13:21,140
these could be you know individual

222
00:13:18,150 --> 00:13:24,660
points of malware or anything like that

223
00:13:21,140 --> 00:13:27,569
again likelihood what are the chances of

224
00:13:24,660 --> 00:13:30,530
this happening very very important

225
00:13:27,570 --> 00:13:34,010
especially when we talk about priority

226
00:13:30,530 --> 00:13:34,010
prioritization and

227
00:13:35,110 --> 00:13:43,220
getting resources for different things

228
00:13:38,839 --> 00:13:45,980
and lining those up so I mean why do we

229
00:13:43,220 --> 00:13:49,790
want to put a whole lot of it expensive

230
00:13:45,980 --> 00:13:53,510
resources to something that is very very

231
00:13:49,790 --> 00:13:57,529
unlikely to happen it just doesn't make

232
00:13:53,510 --> 00:14:02,920
sense the vulnerabilities again looking

233
00:13:57,529 --> 00:14:07,060
internally to IT systems or our physical

234
00:14:02,920 --> 00:14:10,910
layouts what where are our weaknesses

235
00:14:07,060 --> 00:14:15,529
where are those you know were weak links

236
00:14:10,910 --> 00:14:20,390
in our chain the asset value maybe this

237
00:14:15,529 --> 00:14:24,430
kind of goes into impact again why would

238
00:14:20,390 --> 00:14:27,110
we put a whole lot of expensive

239
00:14:24,430 --> 00:14:32,120
protections around assets that aren't

240
00:14:27,110 --> 00:14:34,930
that valuable begin or if we have our

241
00:14:32,120 --> 00:14:34,930
crown jewels

242
00:14:35,740 --> 00:14:40,990
good mean us staying in business or not

243
00:14:38,470 --> 00:14:43,839
and we're not providing the right amount

244
00:14:40,990 --> 00:14:47,680
of resources around those assets we're

245
00:14:43,839 --> 00:14:49,930
just opening ourselves up or a lot of

246
00:14:47,680 --> 00:14:51,579
bad stuff to happen and then the

247
00:14:49,930 --> 00:14:55,839
compensating controls these are the

248
00:14:51,579 --> 00:14:58,569
things that you know we've got we know

249
00:14:55,839 --> 00:15:00,610
bad things are going to happen but when

250
00:14:58,569 --> 00:15:05,498
they do we have these things to give us

251
00:15:00,610 --> 00:15:10,329
buffers and they're also the way we act

252
00:15:05,499 --> 00:15:12,360
and the way we handle when bad things do

253
00:15:10,329 --> 00:15:12,359
happen

254
00:15:12,680 --> 00:15:20,029
now how do we have respond to risk and

255
00:15:16,790 --> 00:15:23,019
it's just not all hair on fire it's just

256
00:15:20,029 --> 00:15:26,240
not panicking I mean when we talk about

257
00:15:23,019 --> 00:15:30,379
the current situations with the the Cova

258
00:15:26,240 --> 00:15:33,619
19 issue and we see these panic buys now

259
00:15:30,379 --> 00:15:36,550
that's not really how we want to respond

260
00:15:33,619 --> 00:15:36,550
to risk

261
00:15:37,130 --> 00:15:42,550
we want to do it smartly we want to make

262
00:15:39,500 --> 00:15:47,570
sure that we have these things in place

263
00:15:42,550 --> 00:15:52,969
and how we handle risk now we'll mention

264
00:15:47,570 --> 00:15:55,730
two that individually we are constantly

265
00:15:52,970 --> 00:15:59,660
evaluating risk whether you realize it

266
00:15:55,730 --> 00:16:03,280
or not whether we decide to speed or

267
00:15:59,660 --> 00:16:06,680
cross the street when the light is

268
00:16:03,280 --> 00:16:10,310
showing us the red hand those little

269
00:16:06,680 --> 00:16:13,160
decisions are us responding to risk well

270
00:16:10,310 --> 00:16:14,750
we can avoid it we can say you know what

271
00:16:13,160 --> 00:16:16,850
I'm just not going to leave the house

272
00:16:14,750 --> 00:16:19,360
and that's pretty much you know keeping

273
00:16:16,850 --> 00:16:23,990
it contextual to what's going on today

274
00:16:19,360 --> 00:16:26,110
by us quarantine or selves at home we

275
00:16:23,990 --> 00:16:29,900
are trying to avoid the risk all

276
00:16:26,110 --> 00:16:34,010
together stopping those behaviors or

277
00:16:29,900 --> 00:16:36,790
processes that introduce that risk into

278
00:16:34,010 --> 00:16:41,230
our lives or our businesses or whatever

279
00:16:36,790 --> 00:16:45,469
we can try to reduce we're going to take

280
00:16:41,230 --> 00:16:50,390
steps and measures that will reduce the

281
00:16:45,470 --> 00:16:53,300
opportunity or that risk to happen or

282
00:16:50,390 --> 00:16:55,699
you can be like some people and be like

283
00:16:53,300 --> 00:16:58,310
out you know what I think it's a hoax or

284
00:16:55,700 --> 00:17:03,680
I don't think it's going to affect me

285
00:16:58,310 --> 00:17:07,399
and just accept whatever happens we in

286
00:17:03,680 --> 00:17:08,899
business you know for years as I was

287
00:17:07,400 --> 00:17:11,380
getting out into the professional world

288
00:17:08,900 --> 00:17:13,819
and even going through grad school as

289
00:17:11,380 --> 00:17:17,120
cybers are really ramping up and the

290
00:17:13,819 --> 00:17:19,040
data breaches are more and more most

291
00:17:17,119 --> 00:17:23,649
companies were saying you know what

292
00:17:19,040 --> 00:17:26,209
bottom line the cost to implement these

293
00:17:23,650 --> 00:17:30,230
security controls or these security

294
00:17:26,209 --> 00:17:33,550
applications is so much more than the

295
00:17:30,230 --> 00:17:36,470
damage I'm just going to accept it

296
00:17:33,550 --> 00:17:39,169
lastly we can say you know what we're

297
00:17:36,470 --> 00:17:41,360
going to transfer the risk and typically

298
00:17:39,170 --> 00:17:43,820
that's done through insurance or through

299
00:17:41,360 --> 00:17:46,340
our contracts we're going to say

300
00:17:43,820 --> 00:17:48,679
insurance company I'm gonna pay this

301
00:17:46,340 --> 00:17:51,370
premium and when something bad happens

302
00:17:48,680 --> 00:17:55,640
I'm going

303
00:17:51,370 --> 00:18:00,199
rely on you to cover anything you know

304
00:17:55,640 --> 00:18:03,020
any of the cost that I incur as a result

305
00:18:00,200 --> 00:18:06,620
of that risk happening now we'll see if

306
00:18:03,020 --> 00:18:10,490
anybody has any questions you know if

307
00:18:06,620 --> 00:18:15,040
you want to chime in please do I know

308
00:18:10,490 --> 00:18:18,580
it's a little bit harder over the WebEx

309
00:18:15,040 --> 00:18:23,360
but if you do have a question you know

310
00:18:18,580 --> 00:18:26,899
please feel free to chime in or if you

311
00:18:23,360 --> 00:18:30,168
want to wait until after I get there

312
00:18:26,900 --> 00:18:34,879
here that's fine as as well

313
00:18:30,169 --> 00:18:37,549
so and I love nest I mean this has been

314
00:18:34,879 --> 00:18:41,029
around for years and and the work that

315
00:18:37,549 --> 00:18:45,499
they do on cybersecurity related stuff

316
00:18:41,029 --> 00:18:48,529
risk management is great one downside is

317
00:18:45,499 --> 00:18:53,259
they're very verbose when with their

318
00:18:48,529 --> 00:18:59,539
definitions and and their documents and

319
00:18:53,259 --> 00:19:02,299
I really I hate having this particular

320
00:18:59,539 --> 00:19:08,749
slide in this presentation just because

321
00:19:02,299 --> 00:19:12,580
it's it's very wordy but you know being

322
00:19:08,749 --> 00:19:15,019
the good academic that I am you know

323
00:19:12,580 --> 00:19:17,359
want to have that in there but let's

324
00:19:15,019 --> 00:19:22,759
let's break that down a little bit more

325
00:19:17,359 --> 00:19:26,168
into really what risk management is the

326
00:19:22,759 --> 00:19:30,190
first step is it's we have to understand

327
00:19:26,169 --> 00:19:35,210
what our business is who what when where

328
00:19:30,190 --> 00:19:38,149
you we have to know who we are from

329
00:19:35,210 --> 00:19:42,409
there we then can start identifying the

330
00:19:38,149 --> 00:19:46,809
particular things that are unique to my

331
00:19:42,409 --> 00:19:46,809
organization or your organization

332
00:19:46,980 --> 00:19:52,820
and what those particular things that

333
00:19:50,220 --> 00:19:57,450
could cause us harm

334
00:19:52,820 --> 00:20:02,909
from there we do our analyzation or

335
00:19:57,450 --> 00:20:06,000
analysis and analyze what those negative

336
00:20:02,910 --> 00:20:10,049
outcomes would be for those given

337
00:20:06,000 --> 00:20:13,740
situations we look at the threats we

338
00:20:10,049 --> 00:20:15,600
look at our potential responses the

339
00:20:13,740 --> 00:20:18,230
actions and decisions that we are going

340
00:20:15,600 --> 00:20:20,649
to take based on those particular

341
00:20:18,230 --> 00:20:23,440
situations

342
00:20:20,650 --> 00:20:27,910
then once we have done all of that the

343
00:20:23,440 --> 00:20:29,380
second part is more of our action these

344
00:20:27,910 --> 00:20:35,440
are the things that we're doing to

345
00:20:29,380 --> 00:20:40,960
minimize either the likelihood of that

346
00:20:35,440 --> 00:20:44,590
bad thing happening or we try to

347
00:20:40,960 --> 00:20:47,610
minimize the impact of those bad things

348
00:20:44,590 --> 00:20:47,610
happening and

349
00:20:48,270 --> 00:20:54,810
either in the de minimizing the

350
00:20:51,180 --> 00:20:56,520
likelihood or impact we are doing

351
00:20:54,810 --> 00:20:59,010
compensating controls where you're

352
00:20:56,520 --> 00:21:02,400
changing our processes we're putting in

353
00:20:59,010 --> 00:21:06,230
safeguards but all of that together is

354
00:21:02,400 --> 00:21:11,360
really the action piece of managing risk

355
00:21:06,230 --> 00:21:11,360
at least again it from my point of view

356
00:21:11,780 --> 00:21:18,139
now we're cyber risk management comes in

357
00:21:15,590 --> 00:21:22,699
all we're really doing is we're

358
00:21:18,140 --> 00:21:25,010
overlaying our IT infrastructure our

359
00:21:22,700 --> 00:21:27,830
digital infrastructure onto that so

360
00:21:25,010 --> 00:21:31,460
everything I just said now just apply it

361
00:21:27,830 --> 00:21:35,780
to our technology or data our networks

362
00:21:31,460 --> 00:21:40,090
supply chain all of that stuff the added

363
00:21:35,780 --> 00:21:43,330
thing is is we are doing this on a

364
00:21:40,090 --> 00:21:46,669
constant basis it's not a one-and-done

365
00:21:43,330 --> 00:21:48,429
and I'll get into more of that here in a

366
00:21:46,670 --> 00:21:52,800
little bit

367
00:21:48,430 --> 00:21:57,300
but we're

368
00:21:52,800 --> 00:22:02,129
we're cyber is not necessarily a unicorn

369
00:21:57,300 --> 00:22:05,159
is that this process can be applied to

370
00:22:02,130 --> 00:22:08,970
other things it could be financial risk

371
00:22:05,160 --> 00:22:11,790
it could be all hazards you know coming

372
00:22:08,970 --> 00:22:16,020
from a public safety background this is

373
00:22:11,790 --> 00:22:18,980
something that police agencies fire

374
00:22:16,020 --> 00:22:23,790
agencies we look at All Hazards approach

375
00:22:18,980 --> 00:22:28,830
so in that aspect and it and I hate to

376
00:22:23,790 --> 00:22:30,960
and I kind of get some cyber folks a

377
00:22:28,830 --> 00:22:32,610
little angry at me at times for saying

378
00:22:30,960 --> 00:22:35,400
hey we're not a unicorn

379
00:22:32,610 --> 00:22:40,350
we're not that special in the grand

380
00:22:35,400 --> 00:22:42,990
scheme of things is to be taken

381
00:22:40,350 --> 00:22:47,580
seriously to really get that buy-in at

382
00:22:42,990 --> 00:22:50,340
the executive level we need to realize

383
00:22:47,580 --> 00:22:51,899
that we're just one piece within the

384
00:22:50,340 --> 00:22:55,439
business one piece within the

385
00:22:51,900 --> 00:22:59,940
organization on the other hand there it

386
00:22:55,440 --> 00:23:03,150
does take folks that have the experience

387
00:22:59,940 --> 00:23:06,060
that know the technologies that know the

388
00:23:03,150 --> 00:23:08,850
threats to be able to run it but in the

389
00:23:06,060 --> 00:23:15,570
context of the business we need to be

390
00:23:08,850 --> 00:23:18,500
able to in with the entire organization

391
00:23:15,570 --> 00:23:18,500
the entire enterprise

392
00:23:19,340 --> 00:23:26,300
so why take a risk-based approach

393
00:23:23,530 --> 00:23:32,360
well I've mentioned some of this already

394
00:23:26,300 --> 00:23:36,050
is when we quantify when we do the

395
00:23:32,360 --> 00:23:41,740
research and the analysis and we start

396
00:23:36,050 --> 00:23:44,810
looking at this thing through a rigor

397
00:23:41,740 --> 00:23:49,670
analytical approach and we have the data

398
00:23:44,810 --> 00:23:54,740
then we can really say what the true

399
00:23:49,670 --> 00:23:58,220
risk are and thus be able to apply and

400
00:23:54,740 --> 00:24:00,710
prioritize what resources and it's

401
00:23:58,220 --> 00:24:06,610
limited every organization has a finite

402
00:24:00,710 --> 00:24:10,990
amount of resources available do you use

403
00:24:06,610 --> 00:24:13,240
and I've seen it I've been in you know

404
00:24:10,990 --> 00:24:15,970
number of different agencies and

405
00:24:13,240 --> 00:24:17,650
everybody's project is their baby and

406
00:24:15,970 --> 00:24:21,280
they wanted to get it through and they

407
00:24:17,650 --> 00:24:25,720
want it to be funded and all that stuff

408
00:24:21,280 --> 00:24:30,190
but when you are competing against every

409
00:24:25,720 --> 00:24:32,740
other part of the organization resources

410
00:24:30,190 --> 00:24:38,320
are finite and so you have to be able to

411
00:24:32,740 --> 00:24:40,750
apply those resources do those things

412
00:24:38,320 --> 00:24:45,090
that are going to have the highest

413
00:24:40,750 --> 00:24:45,090
impact of reducing risk

414
00:24:46,260 --> 00:24:51,300
but even then going through this risk

415
00:24:49,230 --> 00:24:54,210
management process like I've mentioned

416
00:24:51,300 --> 00:24:56,970
already is that we're using proven

417
00:24:54,210 --> 00:24:59,520
methods and techniques we're not just

418
00:24:56,970 --> 00:25:02,670
guessing it isn't a gut fill it isn't

419
00:24:59,520 --> 00:25:04,500
Nick just saying well I think yeah I

420
00:25:02,670 --> 00:25:05,970
want to you know go with the wind here

421
00:25:04,500 --> 00:25:09,150
put my finger out and say well I think

422
00:25:05,970 --> 00:25:15,690
this is what we need to be doing we have

423
00:25:09,150 --> 00:25:20,960
data behind our decisions and that data

424
00:25:15,690 --> 00:25:25,200
and the facts are powerful when it comes

425
00:25:20,960 --> 00:25:28,660
to you talking with executives and in

426
00:25:25,200 --> 00:25:32,890
those within the c-suite

427
00:25:28,660 --> 00:25:37,570
but - it's a I used the broken glass

428
00:25:32,890 --> 00:25:43,360
kind of methodology once you start

429
00:25:37,570 --> 00:25:46,830
looking through a risk lens it really

430
00:25:43,360 --> 00:25:50,050
does change the way you think about

431
00:25:46,830 --> 00:25:52,840
everything that you do

432
00:25:50,050 --> 00:25:57,760
and once that glass is broken you can't

433
00:25:52,840 --> 00:26:00,570
ever go back I apologize I've background

434
00:25:57,760 --> 00:26:04,020
noise it's the the downside of being

435
00:26:00,570 --> 00:26:04,020
work from home

436
00:26:06,480 --> 00:26:10,880
but when you are

437
00:26:11,490 --> 00:26:16,770
going through this analytical process

438
00:26:13,980 --> 00:26:20,760
and you're using the data you're now

439
00:26:16,770 --> 00:26:26,610
giving the c-suite you're giving

440
00:26:20,760 --> 00:26:30,860
management really a power in being able

441
00:26:26,610 --> 00:26:35,070
to decide which of those controls are

442
00:26:30,860 --> 00:26:40,070
going to be implemented and that is huge

443
00:26:35,070 --> 00:26:42,600
we're not wasting a bunch of you know

444
00:26:40,070 --> 00:26:48,629
resources needlessly on things that

445
00:26:42,600 --> 00:26:51,090
aren't going to work again to to find'

446
00:26:48,630 --> 00:26:53,340
I guess the the cybersecurity crowd here

447
00:26:51,090 --> 00:26:58,260
more of the vendors and again not really

448
00:26:53,340 --> 00:27:02,370
meaning to offend but when you've got 50

449
00:26:58,260 --> 00:27:08,010
vendors that are coming at you selling

450
00:27:02,370 --> 00:27:11,669
blinky lights and all sorts of cool toys

451
00:27:08,010 --> 00:27:14,220
in these things how do you know it's

452
00:27:11,670 --> 00:27:18,360
going to solve the problems that you

453
00:27:14,220 --> 00:27:20,330
have and risk management and going

454
00:27:18,360 --> 00:27:26,250
through this process and this program

455
00:27:20,330 --> 00:27:28,740
will help you know what to implement

456
00:27:26,250 --> 00:27:32,570
a lot better than just let oh this has

457
00:27:28,740 --> 00:27:32,570
got some cool blinky light

458
00:27:34,890 --> 00:27:42,540
and this is so I work with a lot of

459
00:27:39,140 --> 00:27:45,060
privacy and compliance driven folks and

460
00:27:42,540 --> 00:27:52,159
this is where I upset them so I'm an

461
00:27:45,060 --> 00:27:55,860
equal-opportunity and who I upset but

462
00:27:52,160 --> 00:27:56,370
compliance management you know in health

463
00:27:55,860 --> 00:27:59,909
care

464
00:27:56,370 --> 00:28:01,590
we're heavily regulated the Office of

465
00:27:59,910 --> 00:28:08,880
Civil Rights under the Health and Human

466
00:28:01,590 --> 00:28:14,610
Services Agency is our primary regulator

467
00:28:08,880 --> 00:28:17,670
and HIPAA is mmm no joke I mean it is

468
00:28:14,610 --> 00:28:21,479
hefty it there's it's very prescriptive

469
00:28:17,670 --> 00:28:23,940
in some aspects government will come

470
00:28:21,480 --> 00:28:27,630
down with the heavy hand if you are

471
00:28:23,940 --> 00:28:30,420
found to be in violation of HIPAA and so

472
00:28:27,630 --> 00:28:33,030
what happens in these really heavy

473
00:28:30,420 --> 00:28:38,910
regulated industries like health care

474
00:28:33,030 --> 00:28:42,300
and Finance there there is a mentality

475
00:28:38,910 --> 00:28:45,450
that tends to happen on checking the box

476
00:28:42,300 --> 00:28:48,480
well are we you know the regulation says

477
00:28:45,450 --> 00:28:51,750
we have to do XY and Z or A through Z

478
00:28:48,480 --> 00:28:55,190
and you just go through this process of

479
00:28:51,750 --> 00:28:55,190
checking the box

480
00:28:57,600 --> 00:29:02,580
sure this will make a lot of security

481
00:28:59,010 --> 00:29:06,559
folks happy compliance does not equate

482
00:29:02,580 --> 00:29:09,320
to being secure

483
00:29:06,559 --> 00:29:12,860
I am sure that a lot of these companies

484
00:29:09,320 --> 00:29:16,490
that have been breached thought they

485
00:29:12,860 --> 00:29:19,248
were compliant and I thought that that

486
00:29:16,490 --> 00:29:22,899
they thought they were doing security

487
00:29:19,249 --> 00:29:24,799
the right way and I'm sorry to say

488
00:29:22,899 --> 00:29:26,989
that's not the case

489
00:29:24,799 --> 00:29:29,749
checking the box does not make you

490
00:29:26,990 --> 00:29:35,269
secure on the other hand you do have to

491
00:29:29,749 --> 00:29:40,369
be cognizant of what regulations that

492
00:29:35,269 --> 00:29:43,580
you are mandated under and have to

493
00:29:40,369 --> 00:29:46,159
follow it is a risk so you can't just

494
00:29:43,580 --> 00:29:50,449
completely ignore

495
00:29:46,160 --> 00:29:52,880
those regulatory obligations because if

496
00:29:50,450 --> 00:29:55,820
you don't follow them then you're

497
00:29:52,880 --> 00:30:01,330
putting your organization at risk of

498
00:29:55,820 --> 00:30:01,330
being in violation of one or more walls

499
00:30:01,810 --> 00:30:09,280
it is one of my philosophies that if you

500
00:30:06,070 --> 00:30:11,830
do security right the compliance will

501
00:30:09,280 --> 00:30:15,720
come the compliance piece will follow

502
00:30:11,830 --> 00:30:18,699
and in this process you do have to to

503
00:30:15,720 --> 00:30:22,630
understand what those regulatory burdens

504
00:30:18,700 --> 00:30:26,980
are and map them what you're doing to

505
00:30:22,630 --> 00:30:30,070
those regulations but the compliance

506
00:30:26,980 --> 00:30:32,320
piece will come that's something you'll

507
00:30:30,070 --> 00:30:34,270
hear me say at least two or three more

508
00:30:32,320 --> 00:30:37,240
times through the remainder of this

509
00:30:34,270 --> 00:30:41,129
program is when you do security right

510
00:30:37,240 --> 00:30:41,130
the compliance piece will come

511
00:30:41,700 --> 00:30:48,899
so why take this risk-based approach

512
00:30:46,440 --> 00:30:51,740
well the biggest thing is again you

513
00:30:48,899 --> 00:30:56,370
probably start you're able to prioritize

514
00:30:51,740 --> 00:30:59,570
the the biggest things the that will

515
00:30:56,370 --> 00:30:59,570
cause you the most harm

516
00:31:00,870 --> 00:31:06,178
whether that's regulation whether that's

517
00:31:03,480 --> 00:31:09,809
a technology risk whether it's people

518
00:31:06,179 --> 00:31:16,710
risk you're able to prioritize those

519
00:31:09,809 --> 00:31:21,928
things and call it the 80/20 rule when

520
00:31:16,710 --> 00:31:25,080
you do that you're probably on it you

521
00:31:21,929 --> 00:31:30,350
know some statistical average taking

522
00:31:25,080 --> 00:31:34,460
care of 80% of those things that will

523
00:31:30,350 --> 00:31:34,459
cause you the most damage

524
00:31:34,700 --> 00:31:43,370
but it also I think one of the another

525
00:31:39,050 --> 00:31:47,320
huge important aspect is you become more

526
00:31:43,370 --> 00:31:50,239
proactive I've been in a number of IT

527
00:31:47,320 --> 00:31:52,490
organizations where you're basically

528
00:31:50,240 --> 00:31:56,000
just a firefighter you're moving from

529
00:31:52,490 --> 00:31:59,480
one fire to the next fire to the next

530
00:31:56,000 --> 00:31:59,990
fire and it's like a dog chasing its

531
00:31:59,480 --> 00:32:04,020
tail

532
00:31:59,990 --> 00:32:10,220
you're never getting caught up

533
00:32:04,020 --> 00:32:14,190
and when you start having these

534
00:32:10,220 --> 00:32:16,590
prioritized list of things to do and

535
00:32:14,190 --> 00:32:20,370
knowing in applying those things

536
00:32:16,590 --> 00:32:24,629
strategically you're able to become

537
00:32:20,370 --> 00:32:27,209
proactive and then you instead of being

538
00:32:24,630 --> 00:32:28,910
a firefighter you're actually making

539
00:32:27,210 --> 00:32:32,340
headway and I've been there I've

540
00:32:28,910 --> 00:32:35,520
multiple organizations where even when I

541
00:32:32,340 --> 00:32:39,419
was a cop doing IT stuff I felt more

542
00:32:35,520 --> 00:32:42,480
like a firefighter than I did a cop and

543
00:32:39,420 --> 00:32:47,840
it's frustrating because you don't feel

544
00:32:42,480 --> 00:32:47,840
like you're ever making any headway

545
00:32:49,600 --> 00:32:57,760
so and I talked about this a little bit

546
00:32:54,400 --> 00:33:01,720
a couple of slides ago but under that

547
00:32:57,760 --> 00:33:04,470
risk-based approach you just you're only

548
00:33:01,720 --> 00:33:07,419
worried about checking the box and

549
00:33:04,470 --> 00:33:12,100
focused on the requirements and focused

550
00:33:07,419 --> 00:33:15,130
on you know well are we doing this and

551
00:33:12,100 --> 00:33:18,928
it really isn't how well are you doing

552
00:33:15,130 --> 00:33:23,039
those things it's well we're doing them

553
00:33:18,929 --> 00:33:23,039
we're compliant with the law

554
00:33:23,200 --> 00:33:30,890
and that

555
00:33:26,450 --> 00:33:34,820
checkbox' mentality it's

556
00:33:30,890 --> 00:33:37,550
and grained into the organization and

557
00:33:34,820 --> 00:33:41,990
the other thing and the thing I I think

558
00:33:37,550 --> 00:33:49,629
is most troublesome in my opinion when

559
00:33:41,990 --> 00:33:53,840
we are focused on compliance is those

560
00:33:49,630 --> 00:33:57,470
regulations end up being the sealing of

561
00:33:53,840 --> 00:34:02,209
what organizations think they should be

562
00:33:57,470 --> 00:34:05,560
doing not the not the floor not the

563
00:34:02,210 --> 00:34:10,510
minimum but this ceiling

564
00:34:05,560 --> 00:34:13,120
and so the mindset of organizations are

565
00:34:10,510 --> 00:34:18,190
well the government says I need to be

566
00:34:13,120 --> 00:34:23,080
doing these things and any more than

567
00:34:18,190 --> 00:34:25,409
that what am I getting out of it so at

568
00:34:23,080 --> 00:34:28,870
that point it's a financial decision

569
00:34:25,409 --> 00:34:31,270
even maybe whether or not they think

570
00:34:28,870 --> 00:34:37,029
they're taking a risk based decision or

571
00:34:31,270 --> 00:34:38,830
not they don't see the value in going

572
00:34:37,030 --> 00:34:41,110
above those standards because the

573
00:34:38,830 --> 00:34:42,489
government has now this is what I've got

574
00:34:41,110 --> 00:34:43,260
to do and I don't want to do anything

575
00:34:42,489 --> 00:34:48,250
else

576
00:34:43,260 --> 00:34:52,450
it happens organization in and out so

577
00:34:48,250 --> 00:34:55,300
it's another kind of foot stomp moment

578
00:34:52,449 --> 00:34:58,589
on why I think taking a compliance base

579
00:34:55,300 --> 00:34:58,590
approach is the wrong approach

580
00:35:00,910 --> 00:35:08,558
so the another important note here and I

581
00:35:04,680 --> 00:35:11,368
hit on it a little bit earlier is that

582
00:35:08,559 --> 00:35:15,970
this cyber risk management program

583
00:35:11,369 --> 00:35:18,839
should be incorporated into the

584
00:35:15,970 --> 00:35:23,680
enterprise risk management program

585
00:35:18,839 --> 00:35:26,529
because there are other risk to a

586
00:35:23,680 --> 00:35:29,348
business outside the cyber risk and that

587
00:35:26,530 --> 00:35:32,470
being a cyber security professional I

588
00:35:29,349 --> 00:35:35,500
want to think that the cyber risk will

589
00:35:32,470 --> 00:35:37,750
cripple and are you know absolutely the

590
00:35:35,500 --> 00:35:41,260
most important risk that the

591
00:35:37,750 --> 00:35:44,950
organization should be addressing but in

592
00:35:41,260 --> 00:35:48,670
real life there are other risk that are

593
00:35:44,950 --> 00:35:54,419
just as damaging to an organization

594
00:35:48,670 --> 00:35:57,819
other than cyber risk but one year also

595
00:35:54,420 --> 00:36:00,130
incorporated into the risk management at

596
00:35:57,819 --> 00:36:02,470
the enterprise level you start talking

597
00:36:00,130 --> 00:36:06,490
the same language one of the downsides

598
00:36:02,470 --> 00:36:08,799
and and another kind of points I like to

599
00:36:06,490 --> 00:36:11,859
pick on folks in in the cyber security

600
00:36:08,799 --> 00:36:16,569
world is we tend to want to use our own

601
00:36:11,859 --> 00:36:20,140
jargon and talk our own language and I

602
00:36:16,569 --> 00:36:26,349
think that does more detrimental our

603
00:36:20,140 --> 00:36:31,180
does more to detriment our standpoint or

604
00:36:26,349 --> 00:36:35,440
our conversations with the c-suite when

605
00:36:31,180 --> 00:36:39,578
we just talk the bits and bytes we need

606
00:36:35,440 --> 00:36:43,000
to be able to speak in a language that

607
00:36:39,579 --> 00:36:46,140
or you have senior leadership or

608
00:36:43,000 --> 00:36:49,000
executive leadership folks understand I

609
00:36:46,140 --> 00:36:50,879
like talking bits and bytes more you

610
00:36:49,000 --> 00:36:54,210
know just as much as every other cyber

611
00:36:50,880 --> 00:36:56,849
geek out there

612
00:36:54,210 --> 00:37:00,390
you know and that's fine to do when

613
00:36:56,849 --> 00:37:04,670
you're in that company of other cyber

614
00:37:00,390 --> 00:37:07,560
folks but when you're talking to

615
00:37:04,670 --> 00:37:11,730
executives they speak a whole other

616
00:37:07,560 --> 00:37:16,820
language and when we use and we can use

617
00:37:11,730 --> 00:37:19,740
risk as that kind of rosetta stone and

618
00:37:16,820 --> 00:37:23,550
to be able to translate that that geek

619
00:37:19,740 --> 00:37:25,799
speak into corporate speak now we're

620
00:37:23,550 --> 00:37:27,930
talking again probabilities where

621
00:37:25,800 --> 00:37:30,830
impacts we're talking dollars and cents

622
00:37:27,930 --> 00:37:34,660
those are the type of things that

623
00:37:30,830 --> 00:37:37,569
executives understand

624
00:37:34,660 --> 00:37:41,288
as much as we want to you know talk

625
00:37:37,569 --> 00:37:45,839
about the the technical details of Sam

626
00:37:41,289 --> 00:37:49,480
Sam or other vulnerabilities or you know

627
00:37:45,839 --> 00:37:53,109
he just the they don't understand it

628
00:37:49,480 --> 00:37:57,490
they're not ever going to be through

629
00:37:53,109 --> 00:37:59,828
cyber folks and they don't need to be

630
00:37:57,490 --> 00:38:03,160
that's why they have us there but it's

631
00:37:59,829 --> 00:38:05,230
our responsibility as cyber

632
00:38:03,160 --> 00:38:08,879
professionals to adapt to the

633
00:38:05,230 --> 00:38:13,000
organization and be able to talk in

634
00:38:08,880 --> 00:38:17,529
their language it may not seem fair but

635
00:38:13,000 --> 00:38:20,160
that's just the reality of of the world

636
00:38:17,529 --> 00:38:20,160
that we live in

637
00:38:20,600 --> 00:38:28,069
now I've mentioned regulations and

638
00:38:24,650 --> 00:38:31,300
standards a little bit more on the

639
00:38:28,070 --> 00:38:34,430
regulations but just to define it

640
00:38:31,300 --> 00:38:37,700
regulations are those things that the

641
00:38:34,430 --> 00:38:41,540
government says that you have to do and

642
00:38:37,700 --> 00:38:45,439
if you don't do it you can be put in

643
00:38:41,540 --> 00:38:50,020
jail or you could be levy to fines or

644
00:38:45,440 --> 00:38:50,020
other types of job judgments

645
00:38:51,680 --> 00:39:01,270
now standards they're voluntary NIST is

646
00:38:54,320 --> 00:39:04,250
not a regulation and when we and I hear

647
00:39:01,270 --> 00:39:06,500
quite a bit well I'm compliant with NIST

648
00:39:04,250 --> 00:39:08,720
no no no you're not compliant with in

649
00:39:06,500 --> 00:39:10,820
this this is not a regulation is a

650
00:39:08,720 --> 00:39:14,029
voluntary standard it's a group of

651
00:39:10,820 --> 00:39:16,250
individuals coming together to say we

652
00:39:14,030 --> 00:39:19,320
think these are the best things that the

653
00:39:16,250 --> 00:39:23,870
industry should do

654
00:39:19,320 --> 00:39:27,690
now the one kind of caveat in that is

655
00:39:23,870 --> 00:39:31,490
standards can become mandatory through

656
00:39:27,690 --> 00:39:34,670
contracts PCI the payment card industry

657
00:39:31,490 --> 00:39:34,669
standard is

658
00:39:35,210 --> 00:39:41,240
in force through contracts so the credit

659
00:39:38,839 --> 00:39:44,230
card company say you will do these

660
00:39:41,240 --> 00:39:48,890
things to be able to do business with us

661
00:39:44,230 --> 00:39:51,530
now this is a tool that organizations

662
00:39:48,890 --> 00:39:54,348
can use when they are working with

663
00:39:51,530 --> 00:39:59,270
third-party vendors to ensure security

664
00:39:54,349 --> 00:40:02,359
say I want you to do implement these

665
00:39:59,270 --> 00:40:05,180
standards and that's it third the legal

666
00:40:02,359 --> 00:40:07,650
contract process and they become

667
00:40:05,180 --> 00:40:13,219
enforceable

668
00:40:07,650 --> 00:40:17,999
this is just a small sampling of the

669
00:40:13,219 --> 00:40:22,979
regulations that are out there from the

670
00:40:17,999 --> 00:40:26,368
US standpoint as well as more with the

671
00:40:22,979 --> 00:40:29,999
GDP are from a Europe standpoint but yet

672
00:40:26,369 --> 00:40:32,400
each country has their own set of

673
00:40:29,999 --> 00:40:34,140
regulations that companies have to

674
00:40:32,400 --> 00:40:35,930
follow from a cyber security standpoint

675
00:40:34,140 --> 00:40:38,700
and if you're doing business

676
00:40:35,930 --> 00:40:42,390
internationally you have to be cognizant

677
00:40:38,700 --> 00:40:46,968
of those regulations and I also have

678
00:40:42,390 --> 00:40:52,170
some individual state regulations here

679
00:40:46,969 --> 00:40:59,479
CCPA and Ohio Data Protection Act more

680
00:40:52,170 --> 00:41:03,150
states are passing GDP are like type of

681
00:40:59,479 --> 00:41:06,808
regulations not seeing a whole lot of

682
00:41:03,150 --> 00:41:09,839
necessarily cybersecurity regulations a

683
00:41:06,809 --> 00:41:12,239
lot of its focus on privacy which i

684
00:41:09,839 --> 00:41:15,808
think is missing a little bit of the

685
00:41:12,239 --> 00:41:18,539
boat the privacy and security or two

686
00:41:15,809 --> 00:41:21,640
different sides of the same coin but

687
00:41:18,539 --> 00:41:25,840
that's a topic for another day

688
00:41:21,640 --> 00:41:30,910
now standards pci-dss the NIST has a

689
00:41:25,840 --> 00:41:37,420
bunch of them out there dis sans top 20

690
00:41:30,910 --> 00:41:39,759
I Triple E these are all the either

691
00:41:37,420 --> 00:41:41,230
nonprofit organizations or in this

692
00:41:39,760 --> 00:41:44,760
standpoint there are organizations

693
00:41:41,230 --> 00:41:49,690
within the government or inside as well

694
00:41:44,760 --> 00:41:53,350
but usually these groups of people are

695
00:41:49,690 --> 00:41:57,450
from academia industry government coming

696
00:41:53,350 --> 00:42:01,460
together and saying what do we want

697
00:41:57,450 --> 00:42:04,549
to say these you know the are the the

698
00:42:01,460 --> 00:42:07,770
way we want industry to our

699
00:42:04,550 --> 00:42:12,800
organizations within our industry to to

700
00:42:07,770 --> 00:42:16,740
do and again completely voluntary but

701
00:42:12,800 --> 00:42:20,000
they do provide some good baseline

702
00:42:16,740 --> 00:42:25,759
activities and things that organizations

703
00:42:20,000 --> 00:42:25,760
you know should be doing to be secure

704
00:42:25,980 --> 00:42:30,830
part of me one second want to take a

705
00:42:28,200 --> 00:42:30,830
quick drink

706
00:42:34,520 --> 00:42:42,520
so now that we've covered quite a bit of

707
00:42:38,600 --> 00:42:42,520
material already with

708
00:42:42,609 --> 00:42:48,609
why it's important down to the things

709
00:42:45,099 --> 00:42:51,880
that organizations are mandated to do

710
00:42:48,609 --> 00:42:53,828
through regulation or even the things

711
00:42:51,880 --> 00:42:56,950
that they can do voluntarily through

712
00:42:53,829 --> 00:43:01,809
standards let's get into a little bit

713
00:42:56,950 --> 00:43:04,089
more of the risk management frameworks

714
00:43:01,809 --> 00:43:05,920
and some of these are voluntary as well

715
00:43:04,089 --> 00:43:12,489
that none of the ones that I have in

716
00:43:05,920 --> 00:43:16,900
here are reinforced by any organization

717
00:43:12,489 --> 00:43:19,109
at least that I'm aware of and just as

718
00:43:16,900 --> 00:43:22,150
there are standards on cybersecurity

719
00:43:19,109 --> 00:43:26,440
frameworks there are a number of risk

720
00:43:22,150 --> 00:43:28,119
management frameworks fare is one of the

721
00:43:26,440 --> 00:43:32,789
ones and I will talk about it a little

722
00:43:28,119 --> 00:43:36,220
bit more here in a couple slides NIST

723
00:43:32,789 --> 00:43:42,640
853 rav4 and I believe we're at five is

724
00:43:36,220 --> 00:43:45,029
in draft mode i iso COBIT i mean these

725
00:43:42,640 --> 00:43:50,970
are just some that are out there now I

726
00:43:45,029 --> 00:43:55,210
will mention on like ISO and COBIT

727
00:43:50,970 --> 00:44:03,249
generally cost a lot of money I just to

728
00:43:55,210 --> 00:44:06,099
even bring in ISO to do like the 2727

729
00:44:03,249 --> 00:44:08,200
zero zero one it's like fifty thousand I

730
00:44:06,099 --> 00:44:11,109
mean it error or more I mean they're

731
00:44:08,200 --> 00:44:16,480
they do cost to be certified

732
00:44:11,109 --> 00:44:19,119
whereas NIST is you know it there's no

733
00:44:16,480 --> 00:44:21,849
cost to it it's just or whatever the

734
00:44:19,119 --> 00:44:24,309
cost to be to implement those things so

735
00:44:21,849 --> 00:44:29,499
I did want to point that out

736
00:44:24,309 --> 00:44:33,819
same thing Koba with ISACA so just an

737
00:44:29,499 --> 00:44:38,348
example here of what the fair risk

738
00:44:33,819 --> 00:44:41,999
framework is and kind of that that cycle

739
00:44:38,349 --> 00:44:46,170
of of activities and different

740
00:44:41,999 --> 00:44:49,569
attributes within the framework and what

741
00:44:46,170 --> 00:44:52,829
organizations can do to help build up

742
00:44:49,569 --> 00:44:52,829
and quantify

743
00:44:53,270 --> 00:44:58,070
skin and the things and their approach

744
00:44:54,980 --> 00:45:01,820
that they want to do a little bit of a

745
00:44:58,070 --> 00:45:06,920
newer framework and I want to say less

746
00:45:01,820 --> 00:45:08,960
than five or so years I may may be off a

747
00:45:06,920 --> 00:45:11,960
little bit by a couple years but it's a

748
00:45:08,960 --> 00:45:16,190
relatively new framework I was first

749
00:45:11,960 --> 00:45:20,350
introduced into this framework when I

750
00:45:16,190 --> 00:45:24,110
was at Ernst & Young as a consultant to

751
00:45:20,350 --> 00:45:30,589
me a little bit more actionable it's

752
00:45:24,110 --> 00:45:32,780
less heavy of a lift and say NIST 853

753
00:45:30,590 --> 00:45:35,990
again I love this they do a lot of good

754
00:45:32,780 --> 00:45:37,880
work one of the complaints and it's just

755
00:45:35,990 --> 00:45:41,660
not a complaint for me it's others out

756
00:45:37,880 --> 00:45:45,830
there is they're very detailed very

757
00:45:41,660 --> 00:45:48,290
heavy and again the wording even going

758
00:45:45,830 --> 00:45:52,490
through a lot of this the special

759
00:45:48,290 --> 00:45:56,960
publications are are very verbose and if

760
00:45:52,490 --> 00:45:59,060
you want to get a good night's sleep you

761
00:45:56,960 --> 00:46:02,390
know it never hurts to pick up one of

762
00:45:59,060 --> 00:46:06,710
their special publications and I love it

763
00:46:02,390 --> 00:46:08,900
I've read a number of them but it it

764
00:46:06,710 --> 00:46:13,400
does take a little at a time to get

765
00:46:08,900 --> 00:46:17,510
through so when we talk about nest this

766
00:46:13,400 --> 00:46:19,450
is just kind of a graphic that I put

767
00:46:17,510 --> 00:46:23,270
together based on their framework

768
00:46:19,450 --> 00:46:25,569
they're black-and-white image just

769
00:46:23,270 --> 00:46:28,160
wasn't cutting it for me for

770
00:46:25,570 --> 00:46:30,920
presentation purposes but this is

771
00:46:28,160 --> 00:46:34,609
basically kind of the the process that

772
00:46:30,920 --> 00:46:38,510
you go through and the thing to note

773
00:46:34,610 --> 00:46:43,120
even with the the fair process and I

774
00:46:38,510 --> 00:46:45,920
think what makes both the NIST and fair

775
00:46:43,120 --> 00:46:48,980
some of the better ones in my opinion is

776
00:46:45,920 --> 00:46:53,140
that it is a continual process it you're

777
00:46:48,980 --> 00:46:57,200
not just one and done it's an ongoing

778
00:46:53,140 --> 00:46:59,560
effort throughout the year or over the

779
00:46:57,200 --> 00:46:59,560
years

780
00:46:59,710 --> 00:47:05,749
just a little bit of a breakdown of what

781
00:47:02,989 --> 00:47:08,930
each of those steps are I'm not going to

782
00:47:05,749 --> 00:47:13,160
to read the these things for Batum I

783
00:47:08,930 --> 00:47:19,399
will make the slides available if you do

784
00:47:13,160 --> 00:47:22,299
want them again just the last few bits

785
00:47:19,400 --> 00:47:22,299
of the framework

786
00:47:23,040 --> 00:47:31,650
so now and this is I think one of the

787
00:47:27,450 --> 00:47:33,990
the things I kind of debated about

788
00:47:31,650 --> 00:47:36,390
whether to include in this particular

789
00:47:33,990 --> 00:47:40,439
presentation or not because again when I

790
00:47:36,390 --> 00:47:44,580
initially developed the this slide it

791
00:47:40,440 --> 00:47:47,040
was more for those within industry that

792
00:47:44,580 --> 00:47:48,960
aren't currently doing cyber risk

793
00:47:47,040 --> 00:47:52,670
management but I think there's still

794
00:47:48,960 --> 00:47:55,490
some some things here to take away

795
00:47:52,670 --> 00:47:59,250
depending on what you were wanting to do

796
00:47:55,490 --> 00:48:00,149
once you graduate and you finish your

797
00:47:59,250 --> 00:48:03,290
program

798
00:48:00,150 --> 00:48:07,700
I think there

799
00:48:03,290 --> 00:48:09,830
keeping these in mind no matter what you

800
00:48:07,700 --> 00:48:12,589
are going to do I think they're still

801
00:48:09,830 --> 00:48:14,900
very important aspects to you know to

802
00:48:12,590 --> 00:48:17,690
have and think about and as you're

803
00:48:14,900 --> 00:48:20,680
conversing with other folks within the

804
00:48:17,690 --> 00:48:25,340
cyber organization that you may work for

805
00:48:20,680 --> 00:48:27,649
just helpful to have first and foremost

806
00:48:25,340 --> 00:48:31,870
in any program or project that's your

807
00:48:27,650 --> 00:48:37,610
building having executive buy-in is

808
00:48:31,870 --> 00:48:42,140
important if they do not feel that the

809
00:48:37,610 --> 00:48:47,770
effort the time and resources are worthy

810
00:48:42,140 --> 00:48:50,540
and going to improve the organization or

811
00:48:47,770 --> 00:48:53,050
going to advance the mission of the

812
00:48:50,540 --> 00:48:56,120
organization it's not going to happen

813
00:48:53,050 --> 00:49:01,660
plain and simple now some of this

814
00:48:56,120 --> 00:49:04,700
conversation will be had by a CSO or

815
00:49:01,660 --> 00:49:09,049
other senior management with the

816
00:49:04,700 --> 00:49:12,410
executive leadership folks but it's

817
00:49:09,050 --> 00:49:14,300
still important you know if you're as if

818
00:49:12,410 --> 00:49:17,359
you're coming into maybe entry-level

819
00:49:14,300 --> 00:49:21,830
positions or maybe not so entry-level

820
00:49:17,360 --> 00:49:24,800
positions that you're thinking the way

821
00:49:21,830 --> 00:49:27,830
that the CISOs thinking so they can take

822
00:49:24,800 --> 00:49:29,480
that and arm themselves with the

823
00:49:27,830 --> 00:49:32,750
conversation that they're going to have

824
00:49:29,480 --> 00:49:36,480
with the leadership team

825
00:49:32,750 --> 00:49:40,040
strategically everything that the

826
00:49:36,480 --> 00:49:43,260
security team or cybersecurity

827
00:49:40,040 --> 00:49:46,020
department within an organization needs

828
00:49:43,260 --> 00:49:47,980
to line up with the enterprise business

829
00:49:46,020 --> 00:49:52,119
strategy

830
00:49:47,980 --> 00:49:55,210
and I want to stress this again is that

831
00:49:52,119 --> 00:49:58,150
as cybersecurity professionals within an

832
00:49:55,210 --> 00:50:02,320
organization we are there to support the

833
00:49:58,150 --> 00:50:05,320
organization that business we need to

834
00:50:02,320 --> 00:50:08,350
align our activities with what the

835
00:50:05,320 --> 00:50:12,040
business is doing if we are going

836
00:50:08,350 --> 00:50:15,819
against what the organization is doing

837
00:50:12,040 --> 00:50:20,320
we're not going to be successful it is

838
00:50:15,820 --> 00:50:24,070
imperative no matter what if you're

839
00:50:20,320 --> 00:50:28,359
doing blue team red team doesn't matter

840
00:50:24,070 --> 00:50:30,670
what part of cybersecurity going into we

841
00:50:28,359 --> 00:50:33,330
need to align and be advancing the

842
00:50:30,670 --> 00:50:33,330
mission of the organization

843
00:50:34,380 --> 00:50:39,390
and we also need to be good stewards and

844
00:50:38,070 --> 00:50:43,830
then we need to be good partners with

845
00:50:39,390 --> 00:50:48,089
the other folks within our company with

846
00:50:43,830 --> 00:50:53,069
the other verticals having these siloed

847
00:50:48,090 --> 00:50:56,100
approaches does no good we need to be

848
00:50:53,070 --> 00:51:02,210
good partners within these organizations

849
00:50:56,100 --> 00:51:02,210
a little bit of my soapbox moment there

850
00:51:04,410 --> 00:51:09,029
when you get buy-in from the other parts

851
00:51:06,780 --> 00:51:12,590
of the organization and we're helping

852
00:51:09,030 --> 00:51:12,590
them solve their problems

853
00:51:12,750 --> 00:51:20,090
it's amazing what can get done when

854
00:51:17,190 --> 00:51:22,200
we're not bickering and infighting and

855
00:51:20,090 --> 00:51:27,710
actually working together within the

856
00:51:22,200 --> 00:51:27,710
organization things get done quickly

857
00:51:28,910 --> 00:51:34,370
when we're solving these problems we as

858
00:51:31,850 --> 00:51:37,730
cybersecurity professionals we need to

859
00:51:34,370 --> 00:51:41,660
understand the organization's maturity

860
00:51:37,730 --> 00:51:46,670
the culture financial health I also need

861
00:51:41,660 --> 00:51:48,980
to understand the external factors like

862
00:51:46,670 --> 00:51:53,390
market conditions and again the laws and

863
00:51:48,980 --> 00:51:56,030
regulations all of that

864
00:51:53,390 --> 00:51:59,359
we may not be the best to understand but

865
00:51:56,030 --> 00:52:01,400
if we work with others within the

866
00:51:59,360 --> 00:52:04,070
business that can help us understand

867
00:52:01,400 --> 00:52:06,520
better and make us better and the

868
00:52:04,070 --> 00:52:11,840
solutions that were we're providing

869
00:52:06,520 --> 00:52:15,340
again goes a long long way to making the

870
00:52:11,840 --> 00:52:15,340
business more secure

871
00:52:17,100 --> 00:52:22,480
other considerations when you're talking

872
00:52:20,650 --> 00:52:25,110
about building a risk management program

873
00:52:22,480 --> 00:52:28,060
or other program it doesn't matter

874
00:52:25,110 --> 00:52:30,190
communication is important if you're not

875
00:52:28,060 --> 00:52:32,250
talking with other people if you're not

876
00:52:30,190 --> 00:52:36,930
letting them know what's going on

877
00:52:32,250 --> 00:52:36,930
successes failures everything in between

878
00:52:38,190 --> 00:52:43,080
and that in itself is a risk but we have

879
00:52:41,520 --> 00:52:46,110
to be able to communicate these things

880
00:52:43,080 --> 00:52:49,049
you know if you're working in a security

881
00:52:46,110 --> 00:52:53,480
awareness type of capacity being able to

882
00:52:49,050 --> 00:52:56,700
work with HR and crafting education or

883
00:52:53,480 --> 00:53:01,440
trainings based on the real risk that

884
00:52:56,700 --> 00:53:04,109
you were seeing in your your jobs is

885
00:53:01,440 --> 00:53:07,020
important you know yeah we get fishing

886
00:53:04,110 --> 00:53:09,390
you know we all understand social

887
00:53:07,020 --> 00:53:12,900
engineering but wouldn't it be more

888
00:53:09,390 --> 00:53:15,629
impactful if you can take actual use

889
00:53:12,900 --> 00:53:21,360
cases that you're seeing and communicate

890
00:53:15,630 --> 00:53:24,120
that to the throughout the organization

891
00:53:21,360 --> 00:53:27,560
I think that's a lot more powerful and I

892
00:53:24,120 --> 00:53:30,330
think at least in my opinion I feel that

893
00:53:27,560 --> 00:53:33,299
through this risk management process we

894
00:53:30,330 --> 00:53:36,869
can help

895
00:53:33,300 --> 00:53:36,869
identify those things

896
00:53:37,020 --> 00:53:43,230
again roles and responsibilities the

897
00:53:39,740 --> 00:53:45,959
understanding different parts of the

898
00:53:43,230 --> 00:53:48,330
organization can you can help that can

899
00:53:45,960 --> 00:53:51,540
help you craft how you talk to somebody

900
00:53:48,330 --> 00:53:55,410
and how you communicate it to them so

901
00:53:51,540 --> 00:53:58,050
they understand it better the governance

902
00:53:55,410 --> 00:54:02,330
risk compliance software I think is it's

903
00:53:58,050 --> 00:54:06,020
another thing a lot of these there's

904
00:54:02,330 --> 00:54:10,110
Archer by RSA there's a number of other

905
00:54:06,020 --> 00:54:13,530
GRC platforms that can help kind of be

906
00:54:10,110 --> 00:54:16,290
the central point for managing these

907
00:54:13,530 --> 00:54:19,590
risk and and all the things that go

908
00:54:16,290 --> 00:54:22,200
along with risk management supply chain

909
00:54:19,590 --> 00:54:23,880
risk management is important dealing

910
00:54:22,200 --> 00:54:26,640
with your logistics folks and

911
00:54:23,880 --> 00:54:29,060
understanding or whoever's owning the

912
00:54:26,640 --> 00:54:32,009
relationships with the vendors and and

913
00:54:29,060 --> 00:54:34,380
very very important you look at target

914
00:54:32,010 --> 00:54:37,530
and some other breaches were it came in

915
00:54:34,380 --> 00:54:40,950
through a third party other things like

916
00:54:37,530 --> 00:54:42,420
that or something that are important to

917
00:54:40,950 --> 00:54:47,419
consider when building this type of

918
00:54:42,420 --> 00:54:53,370
program so I and I cannot stress enough

919
00:54:47,420 --> 00:54:56,430
this process is not linear it's not

920
00:54:53,370 --> 00:55:00,240
point A to point B and once you get to B

921
00:54:56,430 --> 00:55:04,319
you're done it is cyclical it's always

922
00:55:00,240 --> 00:55:06,450
going as you're in this process you may

923
00:55:04,320 --> 00:55:12,780
iterate through multiple times within a

924
00:55:06,450 --> 00:55:16,890
year or a month or even a day again as

925
00:55:12,780 --> 00:55:18,950
you look at to me whatever risk

926
00:55:16,890 --> 00:55:22,560
management framework if it's not

927
00:55:18,950 --> 00:55:26,580
cyclical it's not a good program at

928
00:55:22,560 --> 00:55:27,720
least in my opinion but again at the

929
00:55:26,580 --> 00:55:29,069
heart of that as I mentioned in

930
00:55:27,720 --> 00:55:33,569
communicating the things that you're

931
00:55:29,070 --> 00:55:38,070
seeing throughout each step of the that

932
00:55:33,570 --> 00:55:41,100
phase our program is is important now

933
00:55:38,070 --> 00:55:44,400
this may not be necessarily something

934
00:55:41,100 --> 00:55:46,500
that would relate to the purposes of

935
00:55:44,400 --> 00:55:48,630
this class but I mean when you're

936
00:55:46,500 --> 00:55:51,810
talking about you know even working with

937
00:55:48,630 --> 00:55:54,570
the red team understanding when do I

938
00:55:51,810 --> 00:55:58,080
need to start coordinating my pen test

939
00:55:54,570 --> 00:56:02,130
or my vulnerability scans when do I need

940
00:55:58,080 --> 00:56:05,160
to start based on the findings start

941
00:56:02,130 --> 00:56:08,700
patch management or mitigating those

942
00:56:05,160 --> 00:56:11,430
things that we find so no not

943
00:56:08,700 --> 00:56:13,680
necessarily something that you all may

944
00:56:11,430 --> 00:56:16,589
find particularly important but as

945
00:56:13,680 --> 00:56:18,359
you're working through when should I be

946
00:56:16,590 --> 00:56:21,540
doing some of these activities whether

947
00:56:18,360 --> 00:56:25,380
it's you know again pentest

948
00:56:21,540 --> 00:56:29,759
vulnerability scan implementing into

949
00:56:25,380 --> 00:56:31,170
projects all that good stuff so this is

950
00:56:29,760 --> 00:56:34,530
just kind of a breakdown of things that

951
00:56:31,170 --> 00:56:36,750
an organization could do throughout the

952
00:56:34,530 --> 00:56:39,150
quarter again as they're doing this

953
00:56:36,750 --> 00:56:41,460
spreading that work out so it's

954
00:56:39,150 --> 00:56:44,280
happening throughout the year and not

955
00:56:41,460 --> 00:56:46,890
just ramping up you know that one point

956
00:56:44,280 --> 00:56:49,380
in time in the year when a risk

957
00:56:46,890 --> 00:56:52,259
assessments do because of whatever

958
00:56:49,380 --> 00:56:54,950
reason there's a lot of work that

959
00:56:52,260 --> 00:56:57,359
happens to ramp up real quick and then

960
00:56:54,950 --> 00:57:02,220
one of the things that happens

961
00:56:57,359 --> 00:57:05,848
is there's a huge drop-off and things

962
00:57:02,220 --> 00:57:09,538
don't and to get done now in the the

963
00:57:05,849 --> 00:57:13,349
mitigation and the follow-up and not to

964
00:57:09,539 --> 00:57:17,519
happen and looking at OCR and what they

965
00:57:13,349 --> 00:57:20,130
find for it's not typically the fact

966
00:57:17,519 --> 00:57:25,738
that an organization got breached it's

967
00:57:20,130 --> 00:57:27,509
the fact that they didn't follow through

968
00:57:25,739 --> 00:57:29,579
they didn't create what this called a

969
00:57:27,509 --> 00:57:32,430
risk management plan which is just

970
00:57:29,579 --> 00:57:35,430
basically a project plan to how they're

971
00:57:32,430 --> 00:57:36,930
going to remediate or mitigate the

972
00:57:35,430 --> 00:57:39,239
threats that they found or the risks

973
00:57:36,930 --> 00:57:43,589
that they found and then following up

974
00:57:39,239 --> 00:57:47,509
that's what they hammer organizations

975
00:57:43,589 --> 00:57:51,808
for is not the is not doing the follow

976
00:57:47,509 --> 00:57:54,950
through and that's probably one of the

977
00:57:51,809 --> 00:58:00,239
reasons I think if in a framework is it

978
00:57:54,950 --> 00:58:02,999
that cyclical process is part of my

979
00:58:00,239 --> 00:58:05,130
reasoning why I don't think it's a good

980
00:58:02,999 --> 00:58:08,488
framework if it's just that one here

981
00:58:05,130 --> 00:58:12,029
versus the cyclical it anyway a framing

982
00:58:08,489 --> 00:58:15,329
scope just some and again other

983
00:58:12,029 --> 00:58:19,019
activities that could be doing the risk

984
00:58:15,329 --> 00:58:22,799
assessment and again it could happen at

985
00:58:19,019 --> 00:58:25,140
any point during the year then just

986
00:58:22,799 --> 00:58:28,829
starting the planning process all over

987
00:58:25,140 --> 00:58:29,970
towards the end of the year some other

988
00:58:28,829 --> 00:58:31,799
things to think about

989
00:58:29,970 --> 00:58:35,129
you know strategic alignment mentioned

990
00:58:31,799 --> 00:58:37,140
already any and this goes for any

991
00:58:35,130 --> 00:58:38,999
project again you want to have smart

992
00:58:37,140 --> 00:58:41,549
goals specific measurable attainable

993
00:58:38,999 --> 00:58:47,129
relevant and timely you want to be able

994
00:58:41,549 --> 00:58:53,519
to understand what are indicators of

995
00:58:47,130 --> 00:58:56,599
success those KPIs and those metrics you

996
00:58:53,519 --> 00:58:59,930
know and there's some for some of you

997
00:58:56,599 --> 00:59:02,309
data geeks out there which I am one of

998
00:58:59,930 --> 00:59:03,899
some of the things that you can consider

999
00:59:02,309 --> 00:59:07,859
you know reduction in the number of

1000
00:59:03,900 --> 00:59:10,050
security incidents number of new

1001
00:59:07,859 --> 00:59:12,960
unmitigated risk

1002
00:59:10,050 --> 00:59:16,730
time to remediate or mean time to

1003
00:59:12,960 --> 00:59:20,610
remediate there's a number of different

1004
00:59:16,730 --> 00:59:23,940
metrics that are out there that could be

1005
00:59:20,610 --> 00:59:28,740
an indicator of success and that's going

1006
00:59:23,940 --> 00:59:33,570
to depend on a case-by-case basis

1007
00:59:28,740 --> 00:59:36,180
whatever the organization really deems

1008
00:59:33,570 --> 00:59:37,920
of what that indicated indications are

1009
00:59:36,180 --> 00:59:41,700
but you want to know what success looks

1010
00:59:37,920 --> 00:59:46,230
like and be able to measure as you're

1011
00:59:41,700 --> 00:59:48,480
doing these things so I think I have a

1012
00:59:46,230 --> 00:59:52,170
couple more minutes left so case study

1013
00:59:48,480 --> 00:59:56,370
number two very interesting this goes

1014
00:59:52,170 --> 01:00:02,730
back to I think 2011 this security guard

1015
00:59:56,370 --> 01:00:06,299
at a Texas hospital sets up a botnet on

1016
01:00:02,730 --> 01:00:10,640
this hospitals network if you attack a

1017
01:00:06,300 --> 01:00:12,540
rival hacker gang when I first talked

1018
01:00:10,640 --> 01:00:18,240
saw this I'm like really

1019
01:00:12,540 --> 01:00:21,480
why is a security guard in a hacker

1020
01:00:18,240 --> 01:00:26,939
collective or a hacker gang there's some

1021
01:00:21,480 --> 01:00:30,360
failures there but then there's some

1022
01:00:26,940 --> 01:00:32,910
other failures along the way that I I do

1023
01:00:30,360 --> 01:00:37,830
believe if we were talking risk

1024
01:00:32,910 --> 01:00:41,879
management separation of duties lease

1025
01:00:37,830 --> 01:00:44,009
privileges some basic things probably

1026
01:00:41,880 --> 01:00:46,080
would have kept this from happening and

1027
01:00:44,010 --> 01:00:48,690
then because it's Texas it was the

1028
01:00:46,080 --> 01:00:52,400
summertime it's a hospital a lot of

1029
01:00:48,690 --> 01:00:57,330
things could have gone wrong with this

1030
01:00:52,400 --> 01:01:01,650
the guy ended up pleading guilty mainly

1031
01:00:57,330 --> 01:01:04,590
because of the video that he posted and

1032
01:01:01,650 --> 01:01:06,480
and took care of himself or took of

1033
01:01:04,590 --> 01:01:09,240
himself as he's doing these things I'm

1034
01:01:06,480 --> 01:01:17,100
going to try to jump out here real quick

1035
01:01:09,240 --> 01:01:19,109
and play this video but I want you to

1036
01:01:17,100 --> 01:01:22,950
look at some of the things from a risk

1037
01:01:19,110 --> 01:01:23,849
management standpoint of had a risk

1038
01:01:22,950 --> 01:01:29,098
management program

1039
01:01:23,849 --> 01:01:31,950
been in place yeah what would you have

1040
01:01:29,099 --> 01:01:35,509
caught either through technical controls

1041
01:01:31,950 --> 01:01:35,509
or through policies or procedures

1042
01:01:41,170 --> 01:01:43,230
you

1043
01:01:57,310 --> 01:02:00,279
so of course he's a hacker he's got to

1044
01:01:59,560 --> 01:02:03,529
be in hoodie

1045
01:02:00,280 --> 01:02:03,530
[Laughter]

1046
01:02:06,470 --> 01:02:12,770
so I don't know if you guys can hear

1047
01:02:08,810 --> 01:02:15,130
that but he's talking about his what

1048
01:02:12,770 --> 01:02:19,240
he's doing he's dropping a botnet on a

1049
01:02:15,130 --> 01:02:19,240
computer he's got it on a thumb drive

1050
01:02:23,180 --> 01:02:34,100
so at that point so you could see that

1051
01:02:29,990 --> 01:02:37,189
he had his security badge he swipes up

1052
01:02:34,100 --> 01:02:41,200
to some random for within the hospital

1053
01:02:37,190 --> 01:02:45,140
and you see that he's at a computer I

1054
01:02:41,200 --> 01:02:51,109
mean why is the security guard able to

1055
01:02:45,140 --> 01:02:54,620
log in on a computer and install a this

1056
01:02:51,110 --> 01:02:57,580
program or whatever you know he used to

1057
01:02:54,620 --> 01:02:57,580
install the botnet

1058
01:02:58,740 --> 01:03:04,439
again I mentioned lease privileges I

1059
01:03:01,230 --> 01:03:07,730
mean he's a security guard yeah he's

1060
01:03:04,440 --> 01:03:10,410
going to have access the force I mean

1061
01:03:07,730 --> 01:03:14,450
just give him the benefit of the doubt

1062
01:03:10,410 --> 01:03:19,649
there but the fact that he he's got

1063
01:03:14,450 --> 01:03:22,080
login credentials that most likely have

1064
01:03:19,650 --> 01:03:24,810
some sort of advanced privileges it may

1065
01:03:22,080 --> 01:03:28,770
not be full admin privileges but enough

1066
01:03:24,810 --> 01:03:35,690
you know super user probably at minimum

1067
01:03:28,770 --> 01:03:35,690
to install this type of application l

1068
01:03:36,069 --> 01:03:44,739
you know making some assumptions here

1069
01:03:39,489 --> 01:03:45,880
you know do they have antivirus or at

1070
01:03:44,739 --> 01:03:48,130
that point

1071
01:03:45,880 --> 01:03:51,050
edie are really endpoint detection and

1072
01:03:48,130 --> 01:03:55,520
response really wasn't

1073
01:03:51,050 --> 01:04:00,740
Oh a thing yet but you know we did they

1074
01:03:55,520 --> 01:04:03,800
have antivirus what other controls in

1075
01:04:00,740 --> 01:04:08,120
place did they not have because I mean

1076
01:04:03,800 --> 01:04:09,800
obviously he was able to install it I

1077
01:04:08,120 --> 01:04:12,440
don't know if anybody wants to chime in

1078
01:04:09,800 --> 01:04:16,510
on some other things that they think a

1079
01:04:12,440 --> 01:04:21,010
risk management program would have

1080
01:04:16,510 --> 01:04:21,010
caught to keep this from happening

1081
01:04:26,500 --> 01:04:34,960
I personally think if the hospital set

1082
01:04:32,140 --> 01:04:37,598
up a reasonable multi-level security or

1083
01:04:34,960 --> 01:04:42,220
have a reasonable hour back I think this

1084
01:04:37,599 --> 01:04:44,680
would not not happen at all and I'm not

1085
01:04:42,220 --> 01:04:47,410
sure if this is a part of the the risk

1086
01:04:44,680 --> 01:04:50,140
management as well but I assume like as

1087
01:04:47,410 --> 01:04:52,629
an organisation you if you you for

1088
01:04:50,140 --> 01:04:53,980
certain like a security policy you

1089
01:04:52,630 --> 01:04:57,130
definitely should have a clear

1090
01:04:53,980 --> 01:04:59,440
definition of what or who can do what

1091
01:04:57,130 --> 01:05:03,340
right so I think there's definitely

1092
01:04:59,440 --> 01:05:06,869
something messed up no I mean in you're

1093
01:05:03,340 --> 01:05:06,869
absolutely right I mean the

1094
01:05:07,000 --> 01:05:13,070
going through and even from an HR

1095
01:05:10,040 --> 01:05:17,020
standpoint you know did they do a

1096
01:05:13,070 --> 01:05:19,640
security or background check on this guy

1097
01:05:17,020 --> 01:05:23,030
to see who his friends are reference

1098
01:05:19,640 --> 01:05:28,009
checks in being in and a hacker

1099
01:05:23,030 --> 01:05:31,010
collective you know typically you know

1100
01:05:28,010 --> 01:05:32,720
there's some good people on it that you

1101
01:05:31,010 --> 01:05:35,840
know and some white hat hacker

1102
01:05:32,720 --> 01:05:40,129
collectives but it I mean there's some

1103
01:05:35,840 --> 01:05:44,120
things there red flags to me even just

1104
01:05:40,130 --> 01:05:46,420
doing some non technical controls would

1105
01:05:44,120 --> 01:05:46,420
have

1106
01:05:46,520 --> 01:05:51,920
probably save this company or this

1107
01:05:48,950 --> 01:05:56,330
hospital from being able to be victim of

1108
01:05:51,920 --> 01:05:59,069
this type of attack and this is a pure

1109
01:05:56,330 --> 01:06:02,540
example of an insider threat

1110
01:05:59,069 --> 01:06:04,940
so yeah that's

1111
01:06:02,540 --> 01:06:07,700
one of the things I'm a technical guy

1112
01:06:04,940 --> 01:06:11,060
but some of these controls don't have to

1113
01:06:07,700 --> 01:06:15,520
be super technical but when the the

1114
01:06:11,060 --> 01:06:20,630
policies fell those technical controls

1115
01:06:15,520 --> 01:06:22,970
like an EDR or lease privilege you know

1116
01:06:20,630 --> 01:06:25,640
on an ad or accident you know identity

1117
01:06:22,970 --> 01:06:28,730
access management say okay this guy is a

1118
01:06:25,640 --> 01:06:31,480
security guard here's where he can log

1119
01:06:28,730 --> 01:06:33,560
on to maybe one machine or a couple

1120
01:06:31,480 --> 01:06:36,050
machines based on you know

1121
01:06:33,560 --> 01:06:38,210
classification but not some random

1122
01:06:36,050 --> 01:06:44,080
person's computer somewhere in the

1123
01:06:38,210 --> 01:06:44,080
hospital so yeah it just it's

1124
01:06:44,280 --> 01:06:53,370
again I mentioned that broken glass type

1125
01:06:47,820 --> 01:06:59,880
of mentality once you start looking

1126
01:06:53,370 --> 01:07:05,910
through this with a risk management or

1127
01:06:59,880 --> 01:07:08,510
risk based lens the world does change

1128
01:07:05,910 --> 01:07:13,170
quite a bit

1129
01:07:08,510 --> 01:07:16,110
so get back here I've got the link to

1130
01:07:13,170 --> 01:07:19,620
the video if you want to watch it all

1131
01:07:16,110 --> 01:07:25,110
the way through but just kind of a recap

1132
01:07:19,620 --> 01:07:30,589
of what happened as far as what the

1133
01:07:25,110 --> 01:07:35,570
impact and outcome was again HVAC unit

1134
01:07:30,590 --> 01:07:39,210
hey that just think of the the potential

1135
01:07:35,570 --> 01:07:44,750
impact to human life had something gone

1136
01:07:39,210 --> 01:07:49,200
wrong somebody else exploited the

1137
01:07:44,750 --> 01:07:52,160
vulnerability that he set up not only

1138
01:07:49,200 --> 01:07:55,410
you know patient lives were at risk

1139
01:07:52,160 --> 01:07:58,109
medication that's needed to be

1140
01:07:55,410 --> 01:07:59,549
temperature controlled the specimens and

1141
01:07:58,110 --> 01:08:02,810
there's still a lot of bad stuff that

1142
01:07:59,550 --> 01:08:06,200
could have happened as a result of this

1143
01:08:02,810 --> 01:08:06,200
insider threat

1144
01:08:06,920 --> 01:08:13,299
so yeah I think that puts me right at

1145
01:08:11,029 --> 01:08:13,299
the hour

1146
01:08:14,109 --> 01:08:18,028
I have any questions any comments

1147
01:08:22,620 --> 01:08:30,689
you would mention that there was a new

1148
01:08:26,220 --> 01:08:32,960
possible vision for NIST what is the new

1149
01:08:30,689 --> 01:08:35,969
direction they're taking in that new

1150
01:08:32,960 --> 01:08:39,330
revision five it's in production

1151
01:08:35,970 --> 01:08:46,100
yeah it's incorporating the new privacy

1152
01:08:39,330 --> 01:08:50,609
framework so the this privacy framework

1153
01:08:46,100 --> 01:08:55,190
1.0 I believe came out towards the end

1154
01:08:50,609 --> 01:08:59,700
of last year and with it it aligns to

1155
01:08:55,189 --> 01:09:03,689
the NIST cybersecurity framework as far

1156
01:08:59,700 --> 01:09:07,608
as some of the verbage and even how its

1157
01:09:03,689 --> 01:09:11,759
how CSF has the five different functions

1158
01:09:07,609 --> 01:09:19,109
there are five similar functions within

1159
01:09:11,760 --> 01:09:22,230
the the privacy framework and it's been

1160
01:09:19,109 --> 01:09:28,950
a minute since I've looked at the draft

1161
01:09:22,229 --> 01:09:35,250
version but I do believe that revision 5

1162
01:09:28,950 --> 01:09:39,229
incorporates the privacy piece into 1.0

1163
01:09:35,250 --> 01:09:39,229
or Rev 4 I'm sorry

1164
01:09:41,339 --> 01:09:48,889
okay good question any other questions

1165
01:09:50,910 --> 01:09:57,250
Hynek awesome talk and you mentioned a

1166
01:09:55,300 --> 01:09:59,500
couple different frameworks from

1167
01:09:57,250 --> 01:10:05,070
different organizations like one of them

1168
01:09:59,500 --> 01:10:09,610
is needs so I wonder as a organization

1169
01:10:05,070 --> 01:10:12,280
which framework should I choose or maybe

1170
01:10:09,610 --> 01:10:17,849
another way to ask this question is you

1171
01:10:12,280 --> 01:10:20,639
know as a company we probably have some

1172
01:10:17,850 --> 01:10:24,210
compliance

1173
01:10:20,640 --> 01:10:26,430
thing to do one way to do that is I look

1174
01:10:24,210 --> 01:10:28,200
at whatever compliance I need to fulfill

1175
01:10:26,430 --> 01:10:31,080
and I pick up a wire framework

1176
01:10:28,200 --> 01:10:33,660
the other way would be you know I pick

1177
01:10:31,080 --> 01:10:37,140
up some framework which might not

1178
01:10:33,660 --> 01:10:39,870
satisfy some compliance at all so you

1179
01:10:37,140 --> 01:10:43,920
see like there is a there's a conflict

1180
01:10:39,870 --> 01:10:49,580
between ideal framework and some

1181
01:10:43,920 --> 01:10:54,720
complies you want to achieve yeah so it

1182
01:10:49,580 --> 01:10:57,150
and again I'm not necessarily advocating

1183
01:10:54,720 --> 01:11:00,330
or recommending one I think it is an

1184
01:10:57,150 --> 01:11:04,230
organizational decision what they they

1185
01:11:00,330 --> 01:11:08,250
do choose NIST one of the good things

1186
01:11:04,230 --> 01:11:13,860
about NIST is they have mapped a lot of

1187
01:11:08,250 --> 01:11:19,460
that the risk management framework to

1188
01:11:13,860 --> 01:11:22,170
the CSF to the different regulatory

1189
01:11:19,460 --> 01:11:27,150
requirements HIPPA being probably the

1190
01:11:22,170 --> 01:11:30,210
biggest one there there's also a tool

1191
01:11:27,150 --> 01:11:33,000
that I did not mention in here called

1192
01:11:30,210 --> 01:11:38,790
the secure control framework it's an

1193
01:11:33,000 --> 01:11:45,210
open source organization that actually

1194
01:11:38,790 --> 01:11:48,269
maps out almost all of the regulatory

1195
01:11:45,210 --> 01:11:52,350
and other frameworks I mean they have

1196
01:11:48,270 --> 01:11:54,300
done a lot of good work they also from a

1197
01:11:52,350 --> 01:11:56,580
like a risk assessment standpoint ask

1198
01:11:54,300 --> 01:11:59,340
some questions risk baits questions or

1199
01:11:56,580 --> 01:12:03,450
assessment based questions then aligned

1200
01:11:59,340 --> 01:12:06,450
to the different frameworks the only one

1201
01:12:03,450 --> 01:12:09,440
that isn't there is high trust because

1202
01:12:06,450 --> 01:12:09,440
its proprietary

1203
01:12:11,160 --> 01:12:17,490
a so that's another tool organizations

1204
01:12:14,250 --> 01:12:19,470
could could potentially use again it's

1205
01:12:17,490 --> 01:12:25,469
open sourced it's a collaborative

1206
01:12:19,470 --> 01:12:29,280
process there are a lot of folks from

1207
01:12:25,470 --> 01:12:32,910
industry involved in that but it really

1208
01:12:29,280 --> 01:12:36,030
yeah go back to the other part of your

1209
01:12:32,910 --> 01:12:37,830
question the compliance piece is

1210
01:12:36,030 --> 01:12:43,500
definitely something they have to think

1211
01:12:37,830 --> 01:12:47,100
about and in choosing a framework again

1212
01:12:43,500 --> 01:12:48,720
not to reinvent the wheel but if there

1213
01:12:47,100 --> 01:12:51,120
is something that's already out there

1214
01:12:48,720 --> 01:12:57,390
that's mapped to that whether it's socks

1215
01:12:51,120 --> 01:12:59,580
or GLBA or HIPAA if there's something

1216
01:12:57,390 --> 01:13:04,080
that's already out there they may want

1217
01:12:59,580 --> 01:13:07,350
to look at that first and then decide do

1218
01:13:04,080 --> 01:13:11,160
we want to start from scratch or utilize

1219
01:13:07,350 --> 01:13:14,060
what somebody else has done now the

1220
01:13:11,160 --> 01:13:17,820
thing I will say is not doing anything

1221
01:13:14,060 --> 01:13:21,270
it's not an excuse you at some point you

1222
01:13:17,820 --> 01:13:26,160
have to make a decision and go down a

1223
01:13:21,270 --> 01:13:28,440
path and and through the good thing is

1224
01:13:26,160 --> 01:13:31,710
if you're there doing that

1225
01:13:28,440 --> 01:13:35,049
iterative process and continual cycle

1226
01:13:31,710 --> 01:13:38,289
then they can say are we

1227
01:13:35,050 --> 01:13:40,809
have we gone down the right path if not

1228
01:13:38,289 --> 01:13:43,239
okay where can we adjust and make sure

1229
01:13:40,809 --> 01:13:47,600
we're going down the path that we need

1230
01:13:43,239 --> 01:13:49,910
to be going down but not doing anything

1231
01:13:47,600 --> 01:13:52,100
in my opinion isn't acceptable and

1232
01:13:49,910 --> 01:13:59,330
according in if they're under a

1233
01:13:52,100 --> 01:14:01,340
regulatory scrutiny like HIPAA not doing

1234
01:13:59,330 --> 01:14:03,750
anything will get them in trouble with

1235
01:14:01,340 --> 01:14:09,720
OCR

1236
01:14:03,750 --> 01:14:12,750
it the one thing within hip it's they

1237
01:14:09,720 --> 01:14:16,020
you don't have to go full you know throw

1238
01:14:12,750 --> 01:14:21,360
every single available resource or

1239
01:14:16,020 --> 01:14:24,750
dollar at a cybersecurity program it's

1240
01:14:21,360 --> 01:14:31,110
reasonable to what that organization is

1241
01:14:24,750 --> 01:14:34,440
from sighs do you they take all that

1242
01:14:31,110 --> 01:14:38,730
into consideration so you know a single

1243
01:14:34,440 --> 01:14:42,740
practice office doesn't have to throw

1244
01:14:38,730 --> 01:14:47,940
the same controls that an IU health or a

1245
01:14:42,740 --> 01:14:50,010
large healthcare system would need to

1246
01:14:47,940 --> 01:14:53,820
put in so they do allow some leeway

1247
01:14:50,010 --> 01:14:55,380
based on size of the organization so but

1248
01:14:53,820 --> 01:14:58,980
the one thing is you've got to do

1249
01:14:55,380 --> 01:15:02,580
something you just cannot do it there's

1250
01:14:58,980 --> 01:15:04,259
actually a single practice provider just

1251
01:15:02,580 --> 01:15:09,330
a couple weeks ago that came out that

1252
01:15:04,260 --> 01:15:11,940
was hit with substantial fine from OCR

1253
01:15:09,330 --> 01:15:14,159
because they weren't doing risk

1254
01:15:11,940 --> 01:15:19,790
management

1255
01:15:14,159 --> 01:15:19,790
thank you any other questions

1256
01:15:22,719 --> 01:15:28,800
all right well that's antique again

1257
01:15:26,160 --> 01:15:34,540
thank you very much for having me

1258
01:15:28,800 --> 01:15:36,820
awesome I think WebEx is working well it

1259
01:15:34,540 --> 01:15:39,699
was a good experience apologize for the

1260
01:15:36,820 --> 01:15:41,620
background that that is the the time we

1261
01:15:39,699 --> 01:15:43,980
live in I guess with all of this work

1262
01:15:41,620 --> 01:15:43,980
from home

1263
01:15:44,310 --> 01:15:52,540
alright thanks Nick thanks Jerry I

1264
01:15:50,860 --> 01:15:57,449
appreciate it I appreciate you doing

1265
01:15:52,540 --> 01:15:57,449
this yeah bye-bye yeah

1266
01:16:02,980 --> 01:16:05,040
you

