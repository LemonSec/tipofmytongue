1
00:00:08,470 --> 00:00:12,200
okay great so we'll get going with the

2
00:00:11,360 --> 00:00:14,149
south

3
00:00:12,200 --> 00:00:14,739
it's my pleasure to introduce captain

4
00:00:14,150 --> 00:00:19,270
core

5
00:00:14,740 --> 00:00:20,830
who's currently PhD student pasty Canada

6
00:00:19,270 --> 00:00:22,779
of computer and information technology

7
00:00:20,830 --> 00:00:24,070
at Purdue University he's earned a

8
00:00:22,779 --> 00:00:25,779
bachelor's and master's degree in

9
00:00:24,070 --> 00:00:27,759
government and politics from st. John's

10
00:00:25,779 --> 00:00:29,590
University masters and networking

11
00:00:27,759 --> 00:00:31,810
communication management and an MBA from

12
00:00:29,590 --> 00:00:33,790
Keller Graduate School he currently

13
00:00:31,810 --> 00:00:35,199
serves as a captain a United States Army

14
00:00:33,790 --> 00:00:37,809
and has worked in the information

15
00:00:35,199 --> 00:00:39,190
technology field for over 24 years his

16
00:00:37,809 --> 00:00:42,099
research interests include information

17
00:00:39,190 --> 00:00:43,989
security cyber security forensics risk

18
00:00:42,100 --> 00:00:46,269
analysis cyber resiliency and

19
00:00:43,989 --> 00:00:47,830
information assurance ethics he'll be

20
00:00:46,269 --> 00:00:49,629
talking to a city about the application

21
00:00:47,830 --> 00:00:52,059
of natural language processing in

22
00:00:49,629 --> 00:00:53,799
advanced persistent threat domain so

23
00:00:52,059 --> 00:00:59,919
captain holser it's all yours thank you

24
00:00:53,799 --> 00:01:03,640
very much yes so it's a long title I got

25
00:00:59,920 --> 00:01:05,770
it but being in the military used to

26
00:01:03,640 --> 00:01:07,659
acronyms and the one thing we're always

27
00:01:05,770 --> 00:01:10,030
told to spell out the acronyms the first

28
00:01:07,659 --> 00:01:12,070
time you use them so this what this is

29
00:01:10,030 --> 00:01:13,810
this is my dissertation work and i'm

30
00:01:12,070 --> 00:01:17,439
looking at natural language processing

31
00:01:13,810 --> 00:01:19,149
of open source documents out in the

32
00:01:17,439 --> 00:01:20,710
internet so there's nothing in here and

33
00:01:19,149 --> 00:01:22,840
obviously it's classified or sensitive

34
00:01:20,710 --> 00:01:26,829
but what it also means is it's also

35
00:01:22,840 --> 00:01:29,140
nothing that's proprietary and that's so

36
00:01:26,829 --> 00:01:32,919
so what I've done is I started actually

37
00:01:29,140 --> 00:01:36,999
and I'll actually plug although none of

38
00:01:32,920 --> 00:01:38,979
none of her students here but the dr.

39
00:01:36,999 --> 00:01:41,048
darks information security problem

40
00:01:38,979 --> 00:01:44,170
challenges class and this actually

41
00:01:41,049 --> 00:01:46,210
started out in her course I did a

42
00:01:44,170 --> 00:01:47,829
project on cyber resiliency and looking

43
00:01:46,210 --> 00:01:50,829
at the advanced persistent threat and

44
00:01:47,829 --> 00:01:52,990
that kind of spring boarded me into

45
00:01:50,829 --> 00:01:54,460
doing some of the some of this work

46
00:01:52,990 --> 00:01:57,929
about the advanced persistent threat

47
00:01:54,460 --> 00:02:00,579
domain which is a relatively new domain

48
00:01:57,929 --> 00:02:03,299
and just to define advanced persistent

49
00:02:00,579 --> 00:02:06,758
threat if you haven't heard of it before

50
00:02:03,299 --> 00:02:08,440
advanced obviously being adversaries

51
00:02:06,759 --> 00:02:12,010
that are employing tactics that cover a

52
00:02:08,440 --> 00:02:14,470
full spectrum this isn't a drive-by

53
00:02:12,010 --> 00:02:18,250
attack on a website this isn't just

54
00:02:14,470 --> 00:02:20,650
installing some malware and and doing

55
00:02:18,250 --> 00:02:22,510
something that's pretty innocuous this

56
00:02:20,650 --> 00:02:24,130
is actually a very strategically

57
00:02:22,510 --> 00:02:27,010
designed attack from beginning to end

58
00:02:24,130 --> 00:02:28,120
when it's which you'll see later on I'm

59
00:02:27,010 --> 00:02:28,810
going to actually go through the cyber

60
00:02:28,120 --> 00:02:31,200
kill chain

61
00:02:28,810 --> 00:02:34,450
but it's it's all the way from planning

62
00:02:31,200 --> 00:02:35,980
execution staying within the system

63
00:02:34,450 --> 00:02:40,149
which is where your persistence comes

64
00:02:35,980 --> 00:02:45,220
from and then ultimately a extra waiting

65
00:02:40,150 --> 00:02:47,380
in a in a lowkey fashion until you find

66
00:02:45,220 --> 00:02:49,290
the data or the system that you're

67
00:02:47,380 --> 00:02:54,579
looking for and then exfiltrating and

68
00:02:49,290 --> 00:02:58,709
executing your final attack so as we

69
00:02:54,580 --> 00:03:01,900
continue with this there's actually

70
00:02:58,709 --> 00:03:04,810
excuse me I apologize i'm a bit of a dry

71
00:03:01,900 --> 00:03:06,940
mouth there's the term apt was actually

72
00:03:04,810 --> 00:03:09,549
coined by the air force about ten years

73
00:03:06,940 --> 00:03:12,040
ago when they wanted to describe this

74
00:03:09,549 --> 00:03:13,900
kind of low and slow attack that they

75
00:03:12,040 --> 00:03:16,929
were seeing across the networks and

76
00:03:13,900 --> 00:03:18,700
across government networks but they

77
00:03:16,930 --> 00:03:21,700
wanted to be able to discuss this with

78
00:03:18,700 --> 00:03:23,429
with organisations with academia that

79
00:03:21,700 --> 00:03:27,268
didn't necessarily have the the

80
00:03:23,430 --> 00:03:32,260
classification or the authority to see a

81
00:03:27,269 --> 00:03:33,940
classified information so they came up

82
00:03:32,260 --> 00:03:36,700
with the term advanced persistent threat

83
00:03:33,940 --> 00:03:37,870
because as I showed them the less

84
00:03:36,700 --> 00:03:40,119
sliding as i'm going to show in the next

85
00:03:37,870 --> 00:03:42,120
this in the next slide this really

86
00:03:40,120 --> 00:03:44,079
defines not only the actor that's

87
00:03:42,120 --> 00:03:48,579
executing this kind of attack but it

88
00:03:44,079 --> 00:03:50,200
also describes the attack itself now as

89
00:03:48,579 --> 00:03:52,840
an actor these are adversaries that will

90
00:03:50,200 --> 00:03:56,170
employ or what right easy for me to say

91
00:03:52,840 --> 00:03:59,079
wide range of tactics from the use of

92
00:03:56,170 --> 00:04:01,000
fishing to the use of malware to how

93
00:03:59,079 --> 00:04:03,900
they're going to actually sell the data

94
00:04:01,000 --> 00:04:08,920
and make make a profit on it or turn

95
00:04:03,900 --> 00:04:10,840
data into money into goods and then back

96
00:04:08,920 --> 00:04:14,920
into money again so that they basically

97
00:04:10,840 --> 00:04:17,410
do like the old organized crime and

98
00:04:14,920 --> 00:04:19,659
clean their money they're well-funded

99
00:04:17,410 --> 00:04:21,729
and well-organized and they're patient

100
00:04:19,660 --> 00:04:23,950
they can stay in a system from six

101
00:04:21,728 --> 00:04:26,289
months to 18 months there's actually

102
00:04:23,950 --> 00:04:28,740
been some reports on the extreme side

103
00:04:26,289 --> 00:04:31,750
that some of these apt attacks have been

104
00:04:28,740 --> 00:04:33,130
extended over two years so it's not

105
00:04:31,750 --> 00:04:35,080
something that they're just trying to

106
00:04:33,130 --> 00:04:37,360
deface a website and get out of there as

107
00:04:35,080 --> 00:04:40,630
I said before they can infiltrate a

108
00:04:37,360 --> 00:04:42,520
network and remain hidden as I said and

109
00:04:40,630 --> 00:04:43,900
their goal is stealthy execution they

110
00:04:42,520 --> 00:04:45,460
don't want you to know they're there

111
00:04:43,900 --> 00:04:46,840
because the longer they can stay there

112
00:04:45,460 --> 00:04:49,299
the more information and the more

113
00:04:46,840 --> 00:04:52,840
valuable information they can obtain and

114
00:04:49,300 --> 00:04:55,690
it's the challenge here is that as the

115
00:04:52,840 --> 00:04:57,849
as the actor he only has to find one

116
00:04:55,690 --> 00:04:59,259
flaw in the system whereas the defender

117
00:04:57,849 --> 00:05:01,530
has to defend every floor we've heard

118
00:04:59,259 --> 00:05:06,009
this before and other talks previously

119
00:05:01,530 --> 00:05:08,590
and and their priority is this attack

120
00:05:06,009 --> 00:05:10,419
whereas the defender also has to worry

121
00:05:08,590 --> 00:05:12,280
about business processes and and other

122
00:05:10,419 --> 00:05:13,690
things that they have to what risks

123
00:05:12,280 --> 00:05:15,698
they're going to accept so it's a bit

124
00:05:13,690 --> 00:05:18,340
it's a bit more challenging for the

125
00:05:15,699 --> 00:05:19,960
defender as an attack it involves

126
00:05:18,340 --> 00:05:22,469
multiple methods tools and techniques

127
00:05:19,960 --> 00:05:27,130
using a sophisticated and complex manner

128
00:05:22,470 --> 00:05:28,659
a single apt can include social

129
00:05:27,130 --> 00:05:31,180
engineering like i said before fishing

130
00:05:28,659 --> 00:05:33,430
campaign as well as malware and maybe

131
00:05:31,180 --> 00:05:35,020
even what's really interesting is once

132
00:05:33,430 --> 00:05:36,880
they get past the initial phase of the

133
00:05:35,020 --> 00:05:38,620
apt attack they can start using

134
00:05:36,880 --> 00:05:42,069
traditional packages that you and I

135
00:05:38,620 --> 00:05:46,509
might use SSH SFTP other things like

136
00:05:42,069 --> 00:05:48,789
that that would actually get go through

137
00:05:46,509 --> 00:05:51,520
a firewall or security measures and

138
00:05:48,789 --> 00:05:53,349
would probably be considered just normal

139
00:05:51,520 --> 00:05:57,159
traffic and probably ignored for that

140
00:05:53,349 --> 00:05:58,360
reason so here-here's and I apologize

141
00:05:57,159 --> 00:06:01,360
that this looks like a bit of an eye

142
00:05:58,360 --> 00:06:03,130
chart but this is the cyber kill chain

143
00:06:01,360 --> 00:06:06,940
that you're seeing here and includes

144
00:06:03,130 --> 00:06:10,000
reconnaissance weaponization which are

145
00:06:06,940 --> 00:06:12,909
the first two phases excuse me then you

146
00:06:10,000 --> 00:06:16,199
have delivery exploitation installation

147
00:06:12,909 --> 00:06:18,219
command and control which is maintaining

148
00:06:16,199 --> 00:06:20,259
communications with those systems and

149
00:06:18,219 --> 00:06:21,639
then actions on the objective I know it

150
00:06:20,259 --> 00:06:25,740
sounds very military and probably that's

151
00:06:21,639 --> 00:06:28,150
my fault but actually it's the term that

152
00:06:25,740 --> 00:06:29,919
Lockheed Martin uses and defined this

153
00:06:28,150 --> 00:06:31,599
kill chain because this is when they

154
00:06:29,919 --> 00:06:34,120
find the data they want how do they get

155
00:06:31,599 --> 00:06:36,699
it out of there so going back to

156
00:06:34,120 --> 00:06:38,229
reconnaissance this is if you've ever

157
00:06:36,699 --> 00:06:39,639
heard of the term footprinting that's

158
00:06:38,229 --> 00:06:42,008
what this is this is finding out

159
00:06:39,639 --> 00:06:45,120
information finding your flaws finding

160
00:06:42,009 --> 00:06:47,469
the flaws in the system finding the the

161
00:06:45,120 --> 00:06:49,419
internal person that you might be able

162
00:06:47,469 --> 00:06:52,419
to take advantage of whether it's a

163
00:06:49,419 --> 00:06:54,039
spearfishing a well in campaign or just

164
00:06:52,419 --> 00:06:56,260
the person who might have some interest

165
00:06:54,039 --> 00:06:58,090
that you could send them that email

166
00:06:56,260 --> 00:07:00,460
and just get them through a phishing

167
00:06:58,090 --> 00:07:02,500
attack you have weaponization and here

168
00:07:00,460 --> 00:07:05,049
the actor puts together codes used to

169
00:07:02,500 --> 00:07:06,790
compromise the target system it involves

170
00:07:05,050 --> 00:07:08,710
the use of existing improving code that

171
00:07:06,790 --> 00:07:11,650
they've adapted that they will adapt to

172
00:07:08,710 --> 00:07:13,270
their need so again this excuse me goes

173
00:07:11,650 --> 00:07:17,260
back to the complexity thing they can go

174
00:07:13,270 --> 00:07:18,820
out there and actually I apologize they

175
00:07:17,260 --> 00:07:21,849
can go out there and they can actually

176
00:07:18,820 --> 00:07:23,740
hire someone to write a piece of code or

177
00:07:21,850 --> 00:07:26,160
take another piece of code that might be

178
00:07:23,740 --> 00:07:29,170
out there on the internet and then

179
00:07:26,160 --> 00:07:33,910
weaponize it for some kind of for their

180
00:07:29,170 --> 00:07:35,260
attack there's delivery and this is the

181
00:07:33,910 --> 00:07:37,600
most common of course are going to be

182
00:07:35,260 --> 00:07:39,820
email attachments website malicious

183
00:07:37,600 --> 00:07:41,020
websites removable media all the same

184
00:07:39,820 --> 00:07:44,230
things that we hear about in general

185
00:07:41,020 --> 00:07:47,109
cyber security but this doesn't have to

186
00:07:44,230 --> 00:07:49,510
be that's a sufficient doesn't need to

187
00:07:47,110 --> 00:07:52,030
be that specific excuse me sophisticated

188
00:07:49,510 --> 00:07:53,800
it is the overall complexity of the

189
00:07:52,030 --> 00:07:59,590
attack that makes it a sophisticated

190
00:07:53,800 --> 00:08:01,270
attack exploitation is it doesn't work

191
00:07:59,590 --> 00:08:04,419
unless the person clicks on it so how do

192
00:08:01,270 --> 00:08:09,580
you exploit the user and and get him to

193
00:08:04,420 --> 00:08:11,830
actually trigger the next step which is

194
00:08:09,580 --> 00:08:14,349
installation installation we often

195
00:08:11,830 --> 00:08:17,050
include a remote administration tool or

196
00:08:14,350 --> 00:08:19,480
a rat which or some kind of backdoor

197
00:08:17,050 --> 00:08:21,700
that the apt can use to gain control the

198
00:08:19,480 --> 00:08:23,350
target system once triggered the

199
00:08:21,700 --> 00:08:25,360
malicious code reaches back to its

200
00:08:23,350 --> 00:08:28,720
commanding control servers which I'll

201
00:08:25,360 --> 00:08:32,409
get back which and they provides the apt

202
00:08:28,720 --> 00:08:34,450
actor with useful information and usable

203
00:08:32,409 --> 00:08:37,390
information that they can use in later

204
00:08:34,450 --> 00:08:41,140
ap stages of the attack whether it's

205
00:08:37,390 --> 00:08:43,900
usernames passwords IP addresses IP

206
00:08:41,140 --> 00:08:47,050
address ranges and the like once

207
00:08:43,900 --> 00:08:48,910
installed the rat can also lay dormant

208
00:08:47,050 --> 00:08:51,189
and can be turned off now normally what

209
00:08:48,910 --> 00:08:53,650
will happen in a much more simple attack

210
00:08:51,190 --> 00:08:55,180
is remote access tool will be used get

211
00:08:53,650 --> 00:08:58,600
the information they want delete it off

212
00:08:55,180 --> 00:09:01,750
the system and get and basically clear

213
00:08:58,600 --> 00:09:03,070
the wipe away their tracks but here what

214
00:09:01,750 --> 00:09:04,630
they do is they let the right lie

215
00:09:03,070 --> 00:09:06,760
dormant in the system and again this

216
00:09:04,630 --> 00:09:08,830
goes back to that persistence aspect so

217
00:09:06,760 --> 00:09:09,610
they get bits of information at a time

218
00:09:08,830 --> 00:09:11,140
then

219
00:09:09,610 --> 00:09:13,240
I only get a username the first time

220
00:09:11,140 --> 00:09:14,709
they connect to this computer then maybe

221
00:09:13,240 --> 00:09:16,570
they'll try to figure out how elevated

222
00:09:14,709 --> 00:09:18,489
permissions work and that might be three

223
00:09:16,570 --> 00:09:22,240
months later again that low and slow

224
00:09:18,490 --> 00:09:24,070
approach because the more activity they

225
00:09:22,240 --> 00:09:26,290
show between the rat and the command and

226
00:09:24,070 --> 00:09:28,480
control servers the more likely it is

227
00:09:26,290 --> 00:09:31,649
that that it will trip some sort of

228
00:09:28,480 --> 00:09:34,269
sensor whether it's an IDs or an IPS

229
00:09:31,649 --> 00:09:36,760
system that runs on the network so by

230
00:09:34,269 --> 00:09:39,130
doing it in small doses it's a lot

231
00:09:36,760 --> 00:09:40,779
harder for the defenders to the tech and

232
00:09:39,130 --> 00:09:43,839
the defending systems to detect

233
00:09:40,779 --> 00:09:47,649
malicious activity command and control

234
00:09:43,839 --> 00:09:50,410
phase starts when that when that rat

235
00:09:47,649 --> 00:09:51,970
starts beaconing back to to the command

236
00:09:50,410 --> 00:09:54,670
and control servers or it could be a

237
00:09:51,970 --> 00:09:58,300
botnet I mean it they'll use a variety

238
00:09:54,670 --> 00:10:02,189
of different things so that that it so

239
00:09:58,300 --> 00:10:05,050
that no two apts are exactly alike

240
00:10:02,190 --> 00:10:06,610
they'll also install additional software

241
00:10:05,050 --> 00:10:09,579
they might roll their own encryption

242
00:10:06,610 --> 00:10:11,560
they might again like I said earlier use

243
00:10:09,579 --> 00:10:14,829
what would be generally accepted

244
00:10:11,560 --> 00:10:19,239
programs like FileZilla or or SFTP or

245
00:10:14,829 --> 00:10:21,699
ssh to to actually get themselves in

246
00:10:19,240 --> 00:10:23,350
transition system and then allow them to

247
00:10:21,699 --> 00:10:25,420
extract the data because of course over

248
00:10:23,350 --> 00:10:27,579
an encrypted pipe it's a lot harder to

249
00:10:25,420 --> 00:10:30,069
detect what actual information is going

250
00:10:27,579 --> 00:10:32,199
out and then the active actions on

251
00:10:30,070 --> 00:10:33,850
objective we're talking about actively

252
00:10:32,199 --> 00:10:35,589
going after the data they're looking for

253
00:10:33,850 --> 00:10:37,240
actively going after and possibly

254
00:10:35,589 --> 00:10:39,459
damaging systems that they want to do

255
00:10:37,240 --> 00:10:42,640
because apts aren't just about getting

256
00:10:39,459 --> 00:10:45,518
data out Stuxnet is actually classified

257
00:10:42,640 --> 00:10:48,579
as an apt and that the goal of Stuxnet

258
00:10:45,519 --> 00:10:51,310
was actually to define to identify SCADA

259
00:10:48,579 --> 00:10:53,290
systems and and and close issues and

260
00:10:51,310 --> 00:10:55,899
nuclear reactors so we can see how the

261
00:10:53,290 --> 00:11:00,180
apt can not only be about data theft but

262
00:10:55,899 --> 00:11:03,850
it can also be have a malicious intent

263
00:11:00,180 --> 00:11:05,380
cost of apt attacks of just quickly I

264
00:11:03,850 --> 00:11:07,390
mean a study by the pond amount

265
00:11:05,380 --> 00:11:10,540
Institute the researchers estimated they

266
00:11:07,390 --> 00:11:16,260
closed up to 161 dollars for each record

267
00:11:10,540 --> 00:11:19,810
lost and in in an event think about it I

268
00:11:16,260 --> 00:11:22,029
RSA here they estimated was 66 million

269
00:11:19,810 --> 00:11:23,300
dollars us to undo the damage caused by

270
00:11:22,029 --> 00:11:25,189
the apt attack now there's

271
00:11:23,300 --> 00:11:27,199
isn't just in the data they lost but

272
00:11:25,190 --> 00:11:29,480
this was also providing services to the

273
00:11:27,200 --> 00:11:31,640
compromised individuals and compromised

274
00:11:29,480 --> 00:11:38,390
organizations and having to basically

275
00:11:31,640 --> 00:11:40,459
fix the damage now so that that's this

276
00:11:38,390 --> 00:11:43,399
is the that's the area that I was doing

277
00:11:40,459 --> 00:11:46,060
my research about but what I'm trying to

278
00:11:43,399 --> 00:11:50,180
do now is actually use open source

279
00:11:46,060 --> 00:11:52,819
documentation using natural language

280
00:11:50,180 --> 00:11:55,489
processing to learn key terms within

281
00:11:52,820 --> 00:11:57,709
this domain that I can build tube in

282
00:11:55,490 --> 00:12:01,550
order to build an ontology that can be

283
00:11:57,709 --> 00:12:05,959
used by anyone who's working with apts

284
00:12:01,550 --> 00:12:08,390
and understand as dr. Ruston was talking

285
00:12:05,959 --> 00:12:12,949
about last week it's it's partial partek

286
00:12:08,390 --> 00:12:16,040
taxonomy and also understanding more

287
00:12:12,950 --> 00:12:21,079
details about and standardizing the way

288
00:12:16,040 --> 00:12:23,180
terminology is used so open source

289
00:12:21,079 --> 00:12:26,029
technology has been used for years used

290
00:12:23,180 --> 00:12:28,880
by law enforcement intelligence as a way

291
00:12:26,029 --> 00:12:30,800
to gain information that's actually

292
00:12:28,880 --> 00:12:32,689
publicly available Facebook would be

293
00:12:30,800 --> 00:12:35,779
considered open source obviously not

294
00:12:32,690 --> 00:12:38,660
applicable for my work here but but

295
00:12:35,779 --> 00:12:41,720
definitely is considered open source and

296
00:12:38,660 --> 00:12:44,540
skip that why is this significant well

297
00:12:41,720 --> 00:12:48,649
part of the yes part of this comes from

298
00:12:44,540 --> 00:12:50,899
my proposal companies are facing this

299
00:12:48,649 --> 00:12:56,510
challenge all the time a pt's late as I

300
00:12:50,899 --> 00:12:58,940
said are they take this approach that it

301
00:12:56,510 --> 00:13:06,290
keeps them obscure and hidden imagine if

302
00:12:58,940 --> 00:13:09,020
if well the imagine a company like

303
00:13:06,290 --> 00:13:11,209
Target if an apt infected their system

304
00:13:09,020 --> 00:13:13,100
and was slowly siphoning off credit

305
00:13:11,209 --> 00:13:18,859
cards over years and years of time

306
00:13:13,100 --> 00:13:21,640
that's that that damage and the impact

307
00:13:18,860 --> 00:13:25,220
of that company could be significant

308
00:13:21,640 --> 00:13:26,779
okay I'm going to skip this so here's

309
00:13:25,220 --> 00:13:28,670
here's the methodology and the approach

310
00:13:26,779 --> 00:13:31,579
that i've been using or i've been using

311
00:13:28,670 --> 00:13:36,209
in my research I started out and I disc

312
00:13:31,579 --> 00:13:38,550
I found excuse me

313
00:13:36,209 --> 00:13:40,800
I found to open-source knowledge bases

314
00:13:38,550 --> 00:13:44,389
about the advanced persistent threat I

315
00:13:40,800 --> 00:13:46,439
took them I call a to them I

316
00:13:44,389 --> 00:13:49,829
deduplicated because there was a lot of

317
00:13:46,439 --> 00:13:51,480
repeat documents in there and I ended up

318
00:13:49,829 --> 00:13:53,189
actually the numbers a little high I

319
00:13:51,480 --> 00:13:55,860
actually ended up with a few few more

320
00:13:53,189 --> 00:13:59,009
doc inside and removed but 425 documents

321
00:13:55,860 --> 00:14:00,929
which I felt was a significant enough

322
00:13:59,009 --> 00:14:04,350
base to start with developing an

323
00:14:00,929 --> 00:14:06,300
ontology i selected 22 of those

324
00:14:04,350 --> 00:14:08,429
documents for manual processing and i'll

325
00:14:06,300 --> 00:14:11,399
get i'll get into that a little bit all

326
00:14:08,429 --> 00:14:12,809
that was was actually me going through

327
00:14:11,399 --> 00:14:18,029
these documents and reading them

328
00:14:12,809 --> 00:14:21,480
identifying key terms and and and key

329
00:14:18,029 --> 00:14:24,600
definitions because i had to be able to

330
00:14:21,480 --> 00:14:27,540
use that the what i found in those

331
00:14:24,600 --> 00:14:31,139
documents to actually build not only my

332
00:14:27,540 --> 00:14:33,360
draft ontology but but also a co

333
00:14:31,139 --> 00:14:34,709
reference library that the language the

334
00:14:33,360 --> 00:14:38,939
natural language processing software

335
00:14:34,709 --> 00:14:42,899
will will use to ideally filter out and

336
00:14:38,939 --> 00:14:45,959
understand ambiguous references within a

337
00:14:42,899 --> 00:14:51,209
document i then took that I'm then

338
00:14:45,959 --> 00:14:56,420
taking that draft ontology and the the

339
00:14:51,209 --> 00:14:58,709
actual same pool of 425 documents using

340
00:14:56,420 --> 00:15:00,269
using natural language processing to

341
00:14:58,709 --> 00:15:02,699
identify key terms within those

342
00:15:00,269 --> 00:15:05,579
documents and then going to and

343
00:15:02,699 --> 00:15:08,160
developing a protege an ontology excuse

344
00:15:05,579 --> 00:15:10,649
me using protege which is an which is a

345
00:15:08,160 --> 00:15:13,559
recognized piece of software and then

346
00:15:10,649 --> 00:15:15,990
ultimately the final product is an owl

347
00:15:13,559 --> 00:15:18,269
too compliant which is an industry

348
00:15:15,990 --> 00:15:23,189
standard developed by the World Wide Web

349
00:15:18,269 --> 00:15:24,749
Consortium for an ontology so it is

350
00:15:23,189 --> 00:15:27,209
natural language processing natural

351
00:15:24,749 --> 00:15:32,069
language processing is just that it

352
00:15:27,209 --> 00:15:34,229
takes naturally found a text in

353
00:15:32,069 --> 00:15:37,199
documents like these slides like an

354
00:15:34,230 --> 00:15:39,569
article like a blog and will actually

355
00:15:37,199 --> 00:15:41,939
read through it and analyze it and and

356
00:15:39,569 --> 00:15:44,099
break it down into the tokens and the

357
00:15:41,939 --> 00:15:47,429
words and the terms and identify and

358
00:15:44,100 --> 00:15:50,170
categorize those terms it looks at

359
00:15:47,429 --> 00:15:52,730
things syntactically and semantically

360
00:15:50,170 --> 00:15:56,630
natural language processing can actually

361
00:15:52,730 --> 00:16:00,020
deal with multiple languages I had to

362
00:15:56,630 --> 00:16:02,290
exclude foreign languages from my

363
00:16:00,020 --> 00:16:04,699
research only because of my own

364
00:16:02,290 --> 00:16:08,120
inability to work with those languages

365
00:16:04,700 --> 00:16:10,459
so I had to actually that's why actually

366
00:16:08,120 --> 00:16:12,410
part of my document size dropped a bit

367
00:16:10,459 --> 00:16:13,819
was because not only were there

368
00:16:12,410 --> 00:16:16,430
duplicates but there were also ones that

369
00:16:13,820 --> 00:16:18,260
were in Chinese and Cyrillic and Arabic

370
00:16:16,430 --> 00:16:20,630
that I just couldn't process so I had to

371
00:16:18,260 --> 00:16:24,770
accept at least for the for this work

372
00:16:20,630 --> 00:16:25,850
that I couldn't use that so some basic

373
00:16:24,770 --> 00:16:27,410
terms that you'll hear when you hear

374
00:16:25,850 --> 00:16:29,000
about natural language processing you

375
00:16:27,410 --> 00:16:32,149
have a domain which is just the area

376
00:16:29,000 --> 00:16:34,640
we're discussing apt in this case you

377
00:16:32,149 --> 00:16:36,920
have the corpus or the corpora which is

378
00:16:34,640 --> 00:16:40,339
the all the documents you're using so my

379
00:16:36,920 --> 00:16:43,490
corpus currently consists of 425

380
00:16:40,339 --> 00:16:45,890
documents you have a lemma which if you

381
00:16:43,490 --> 00:16:48,140
remember ACTU Basic English classes in

382
00:16:45,890 --> 00:16:50,779
high school and grammar school it's your

383
00:16:48,140 --> 00:16:53,360
root word so as the example was here I

384
00:16:50,779 --> 00:16:57,380
have the word capture and you variations

385
00:16:53,360 --> 00:16:59,450
captured captures capturing and then all

386
00:16:57,380 --> 00:17:00,589
documents are broken down into tokens

387
00:16:59,450 --> 00:17:03,110
and I'll talk a little bit more about

388
00:17:00,589 --> 00:17:05,059
them later but primarily anything

389
00:17:03,110 --> 00:17:07,309
between white spaces are considered

390
00:17:05,059 --> 00:17:08,990
tokens so they can be words they can

391
00:17:07,309 --> 00:17:11,809
also be punctuation or lat which

392
00:17:08,990 --> 00:17:14,449
actually became a bit of a challenge for

393
00:17:11,809 --> 00:17:19,189
me as I was trying to to sort through

394
00:17:14,449 --> 00:17:21,260
this NLP s will identify parts of speech

395
00:17:19,189 --> 00:17:24,140
tagging they'll identify things as verbs

396
00:17:21,260 --> 00:17:28,429
verb phrases nouns adjectives and the

397
00:17:24,140 --> 00:17:30,710
like they'll also use named entity

398
00:17:28,429 --> 00:17:33,559
recognition or any are and what that is

399
00:17:30,710 --> 00:17:36,140
is it sees the word microsoft and

400
00:17:33,559 --> 00:17:40,820
recognizes it as an organization it sees

401
00:17:36,140 --> 00:17:42,860
the term States or a country like India

402
00:17:40,820 --> 00:17:46,340
and they'll recognize that as a location

403
00:17:42,860 --> 00:17:48,800
or Baghdad as a city which is also a

404
00:17:46,340 --> 00:17:52,189
location and there's actually about 13

405
00:17:48,800 --> 00:17:54,889
common any ours that are used and part

406
00:17:52,190 --> 00:17:56,630
of my work was to actually try to

407
00:17:54,890 --> 00:17:59,390
improve that a little bit or refine it

408
00:17:56,630 --> 00:18:01,700
because for example United could be an

409
00:17:59,390 --> 00:18:02,600
organization as in United Nations or it

410
00:18:01,700 --> 00:18:06,080
can be a

411
00:18:02,600 --> 00:18:07,730
location is in the United States the

412
00:18:06,080 --> 00:18:09,830
role of an ontology I've already spoken

413
00:18:07,730 --> 00:18:11,299
about so I'm actually escaped here here

414
00:18:09,830 --> 00:18:13,418
and I hope you can see this a little bit

415
00:18:11,299 --> 00:18:16,879
clearer than I can on my small screen

416
00:18:13,419 --> 00:18:20,299
ontology associate terms vertically and

417
00:18:16,880 --> 00:18:22,130
horizontally vertically as in if you

418
00:18:20,299 --> 00:18:23,510
think as I have in the example here we

419
00:18:22,130 --> 00:18:25,490
have communications underneath

420
00:18:23,510 --> 00:18:28,879
communications we have encrypted and

421
00:18:25,490 --> 00:18:31,070
unencrypted and then below encrypted for

422
00:18:28,880 --> 00:18:35,110
example you have things like unencrypted

423
00:18:31,070 --> 00:18:39,559
you'll have file transfer protocol HTTP

424
00:18:35,110 --> 00:18:44,059
you'll have telnet under encrypted you

425
00:18:39,559 --> 00:18:46,668
have ssh SFTP secure HTTP and as you can

426
00:18:44,059 --> 00:18:50,000
see there as I've kind of done it in the

427
00:18:46,669 --> 00:18:52,730
tree diagram here the the horizontal

428
00:18:50,000 --> 00:18:54,919
would be your the items at the same

429
00:18:52,730 --> 00:18:56,600
level so encrypted or unencrypted would

430
00:18:54,919 --> 00:18:58,760
be at the same level because of the

431
00:18:56,600 --> 00:19:01,039
broadness of the two topics and the more

432
00:18:58,760 --> 00:19:07,879
specific examples or the identities are

433
00:19:01,039 --> 00:19:10,190
actually at that lowest level now when I

434
00:19:07,880 --> 00:19:11,809
when I took these documents actually one

435
00:19:10,190 --> 00:19:13,490
of the interesting things as I said I

436
00:19:11,809 --> 00:19:15,889
started with about twenty two documents

437
00:19:13,490 --> 00:19:19,730
and try to actually do it myself I think

438
00:19:15,890 --> 00:19:22,130
of from that experience if I had tried

439
00:19:19,730 --> 00:19:24,110
to go all through all 425 and then I

440
00:19:22,130 --> 00:19:28,340
probably would it would have taken me

441
00:19:24,110 --> 00:19:29,719
years so and to see that to see this

442
00:19:28,340 --> 00:19:32,720
natural language processing software

443
00:19:29,720 --> 00:19:34,940
only take maybe four days on on my

444
00:19:32,720 --> 00:19:37,070
personal computer to process through

445
00:19:34,940 --> 00:19:39,919
four hundred documents actually is very

446
00:19:37,070 --> 00:19:42,500
helpful the only challenge is it doesn't

447
00:19:39,919 --> 00:19:45,770
go all the way it it doesn't just spit

448
00:19:42,500 --> 00:19:47,690
out a list of useful terms it gives you

449
00:19:45,770 --> 00:19:51,230
everything back that's in the document

450
00:19:47,690 --> 00:19:56,390
so the 425 documents broke down into a

451
00:19:51,230 --> 00:19:59,299
four almost 4.5 million tokens to be to

452
00:19:56,390 --> 00:20:01,280
be used now a lot of those and I don't I

453
00:19:59,299 --> 00:20:02,389
don't I don't want to trivialize it some

454
00:20:01,280 --> 00:20:06,590
of them were meaningless some of them

455
00:20:02,390 --> 00:20:08,840
were actually parentheses other symbols

456
00:20:06,590 --> 00:20:10,850
that were just useless wouldn't wouldn't

457
00:20:08,840 --> 00:20:12,830
provide anything useful for the ontology

458
00:20:10,850 --> 00:20:16,419
development but then you also have

459
00:20:12,830 --> 00:20:20,419
common words and this is actually where

460
00:20:16,420 --> 00:20:22,280
what I actually did I had this wasn't in

461
00:20:20,420 --> 00:20:25,250
my original plan but I adapted on the

462
00:20:22,280 --> 00:20:26,870
fly I actually went out and used the

463
00:20:25,250 --> 00:20:29,930
America the contemporary American

464
00:20:26,870 --> 00:20:31,610
English 5,000 most common words and i

465
00:20:29,930 --> 00:20:34,070
actually just filtered those out of the

466
00:20:31,610 --> 00:20:36,740
documents now I only did that in terms

467
00:20:34,070 --> 00:20:39,980
of identifying important terms for the

468
00:20:36,740 --> 00:20:42,260
ontology I did not I I couldn't just

469
00:20:39,980 --> 00:20:44,420
delete them because obviously that would

470
00:20:42,260 --> 00:20:45,800
potentially destroy context of what I

471
00:20:44,420 --> 00:20:48,650
was trying to work on in finding

472
00:20:45,800 --> 00:20:52,220
definitions but almost half of the the

473
00:20:48,650 --> 00:20:56,090
tokens were or half of the words that we

474
00:20:52,220 --> 00:20:59,300
found 1.25 million was actually those

475
00:20:56,090 --> 00:21:01,270
common words you can see how much I mean

476
00:20:59,300 --> 00:21:04,550
how quickly we were getting down now

477
00:21:01,270 --> 00:21:07,100
another 450 another half a million were

478
00:21:04,550 --> 00:21:09,919
punctuation some kinds of punctuation so

479
00:21:07,100 --> 00:21:12,050
I could get rid of those at least as far

480
00:21:09,920 --> 00:21:15,800
as identifying terms for terminology and

481
00:21:12,050 --> 00:21:18,200
then another 85,000 were just numbers

482
00:21:15,800 --> 00:21:20,870
and by that you know whether it's 1024

483
00:21:18,200 --> 00:21:22,880
64 whatever is which weren't going to

484
00:21:20,870 --> 00:21:25,729
meaningful term stream fine ontology and

485
00:21:22,880 --> 00:21:29,320
I ultimately came down to about 600,000

486
00:21:25,730 --> 00:21:32,630
meet tokens that I could actually say

487
00:21:29,320 --> 00:21:35,780
some ontological terms could come from

488
00:21:32,630 --> 00:21:38,270
these now one thing I discovered and

489
00:21:35,780 --> 00:21:40,070
this is actually getting back to I'll

490
00:21:38,270 --> 00:21:42,230
get to this like these are the district

491
00:21:40,070 --> 00:21:44,270
the chart on the Left shows the

492
00:21:42,230 --> 00:21:46,550
distribution of how many tokens per

493
00:21:44,270 --> 00:21:49,370
document and you can see that actually

494
00:21:46,550 --> 00:21:52,550
most of them fell in the 0 to 30,000

495
00:21:49,370 --> 00:21:54,229
range with that one little outlier or

496
00:21:52,550 --> 00:21:56,120
too little outliers that were between

497
00:21:54,230 --> 00:22:00,380
eighty and ninety thousand and those

498
00:21:56,120 --> 00:22:03,709
were actually full blown books that I

499
00:22:00,380 --> 00:22:05,420
had or most several chapter books I

500
00:22:03,710 --> 00:22:08,030
think they're more like dissertations

501
00:22:05,420 --> 00:22:09,740
but most of these documents as you can

502
00:22:08,030 --> 00:22:12,170
see really falling that really the one

503
00:22:09,740 --> 00:22:14,210
the 0 to 10 thousand range because a lot

504
00:22:12,170 --> 00:22:18,230
of these or articles are on websites

505
00:22:14,210 --> 00:22:20,990
short papers that are done by things

506
00:22:18,230 --> 00:22:23,270
like kaspersky papers done by kaspersky

507
00:22:20,990 --> 00:22:25,100
or mcafee or things like that so they're

508
00:22:23,270 --> 00:22:28,160
actually designed to be to be a lot

509
00:22:25,100 --> 00:22:29,600
shorter now one of the things I quickly

510
00:22:28,160 --> 00:22:31,130
again

511
00:22:29,600 --> 00:22:34,159
you won't you only realize as you're

512
00:22:31,130 --> 00:22:36,410
going through your research is that I

513
00:22:34,160 --> 00:22:38,660
was finding many very like I showed you

514
00:22:36,410 --> 00:22:42,320
the example of captured before the word

515
00:22:38,660 --> 00:22:44,150
capture before a lot of my I've seen

516
00:22:42,320 --> 00:22:46,159
variations of the same word I'm like

517
00:22:44,150 --> 00:22:48,200
well how many times I had to ask it made

518
00:22:46,160 --> 00:22:49,820
me ask myself how many times should this

519
00:22:48,200 --> 00:22:52,250
word actually appear in the ontology

520
00:22:49,820 --> 00:22:54,049
well theoretically only once it should

521
00:22:52,250 --> 00:22:55,700
appear in the ontology so I started

522
00:22:54,049 --> 00:22:58,039
looking at the unique lemons which is

523
00:22:55,700 --> 00:23:02,150
why I show that here and the average

524
00:22:58,039 --> 00:23:05,000
document had only between zero and five

525
00:23:02,150 --> 00:23:07,100
hundred unique lemma that makes that out

526
00:23:05,000 --> 00:23:09,650
starts to make my identification of

527
00:23:07,100 --> 00:23:11,449
ontological terms a lot a lot easier

528
00:23:09,650 --> 00:23:16,340
than then it might have been when I was

529
00:23:11,450 --> 00:23:22,010
looking at 2.5 million tokens then this

530
00:23:16,340 --> 00:23:25,730
is just student this is just a quick

531
00:23:22,010 --> 00:23:27,230
breakdown of the distribution now the

532
00:23:25,730 --> 00:23:33,049
one thing this doesn't show is the total

533
00:23:27,230 --> 00:23:34,700
tokens but the the first the first two

534
00:23:33,049 --> 00:23:37,100
are just punctuation xin digits which

535
00:23:34,700 --> 00:23:38,480
usually fell out now you can the third

536
00:23:37,100 --> 00:23:39,678
one is the actually the interesting one

537
00:23:38,480 --> 00:23:41,360
there that's that's where the unique

538
00:23:39,679 --> 00:23:43,280
lemma falls and you can see how tight of

539
00:23:41,360 --> 00:23:45,229
a distribution that is in that box plot

540
00:23:43,280 --> 00:23:49,789
and that's basically what I knew I

541
00:23:45,230 --> 00:23:51,559
needed to focus on excuse me that's what

542
00:23:49,789 --> 00:23:54,950
I need to focus on in order to find my

543
00:23:51,559 --> 00:23:56,480
ontological terms and this the one the

544
00:23:54,950 --> 00:23:59,780
second from the right is actually those

545
00:23:56,480 --> 00:24:02,030
common words as 1.2 million tokens that

546
00:23:59,780 --> 00:24:07,850
I was talking about 25 tokens I was

547
00:24:02,030 --> 00:24:10,280
talking about earlier so this is this is

548
00:24:07,850 --> 00:24:14,510
actually some statistical analysis that

549
00:24:10,280 --> 00:24:16,039
I did of some terms now you can see the

550
00:24:14,510 --> 00:24:18,320
third one there is the apostrophe s

551
00:24:16,039 --> 00:24:19,970
possessive that's not an ontological

552
00:24:18,320 --> 00:24:23,389
term but you can see how many times it

553
00:24:19,970 --> 00:24:26,240
appears over 6,000 times in 338 of the

554
00:24:23,390 --> 00:24:27,980
documents it in and of itself as a token

555
00:24:26,240 --> 00:24:29,419
is not useful now the possessive the

556
00:24:27,980 --> 00:24:31,370
word that's before is of course

557
00:24:29,419 --> 00:24:34,880
important but you can see where that's

558
00:24:31,370 --> 00:24:36,830
where again this shows where even though

559
00:24:34,880 --> 00:24:39,740
the the natural language processing does

560
00:24:36,830 --> 00:24:42,080
a lot to choose me help me break down

561
00:24:39,740 --> 00:24:43,220
these documents there's still a lot of

562
00:24:42,080 --> 00:24:44,899
manual

563
00:24:43,220 --> 00:24:48,380
lifting that has to be done in my part

564
00:24:44,900 --> 00:24:51,049
and where I first had thought I said

565
00:24:48,380 --> 00:24:53,419
well the words that I'm going to want to

566
00:24:51,049 --> 00:24:56,418
use are going to be those terms if they

567
00:24:53,419 --> 00:24:59,929
appear a lot in throughout the whole

568
00:24:56,419 --> 00:25:02,000
corpus but if you look at CID which yes

569
00:24:59,929 --> 00:25:03,950
has 20,000 appearances but it actually

570
00:25:02,000 --> 00:25:07,070
only appears in 28 documents and

571
00:25:03,950 --> 00:25:08,929
actually of the of the whole it's only

572
00:25:07,070 --> 00:25:11,539
three point six percent so that we I

573
00:25:08,929 --> 00:25:14,990
quickly realized well where's my where's

574
00:25:11,539 --> 00:25:16,429
the sweet spot where do I need to if i'm

575
00:25:14,990 --> 00:25:18,830
going to use statistics to try to

576
00:25:16,429 --> 00:25:21,320
identify some of my terminology and it

577
00:25:18,830 --> 00:25:24,168
came down to appearances poor corpus now

578
00:25:21,320 --> 00:25:27,439
that appearances / corpus is the number

579
00:25:24,169 --> 00:25:30,260
of appearances averaged out over the 425

580
00:25:27,440 --> 00:25:31,940
documents though the column to its to

581
00:25:30,260 --> 00:25:33,860
the left of that the appearances per

582
00:25:31,940 --> 00:25:36,380
document is actually documents it

583
00:25:33,860 --> 00:25:40,309
appears in so that's what explains the

584
00:25:36,380 --> 00:25:43,220
difference in those numbers now it's our

585
00:25:40,309 --> 00:25:45,260
if these are only the top 15 terms

586
00:25:43,220 --> 00:25:49,520
there's actually about the table ends up

587
00:25:45,260 --> 00:25:52,070
for lemma ends up being about 70,000 so

588
00:25:49,520 --> 00:25:54,440
I'm not going to there's not going to be

589
00:25:52,070 --> 00:25:56,178
slides for everything obviously but it's

590
00:25:54,440 --> 00:26:00,020
actually ironic here that if you look

591
00:25:56,179 --> 00:26:02,510
the term apt actually isn't but by this

592
00:26:00,020 --> 00:26:05,650
by the designation that I've use

593
00:26:02,510 --> 00:26:08,270
actually comes up as number 36 so

594
00:26:05,650 --> 00:26:11,150
there's a lot of terms in here that you

595
00:26:08,270 --> 00:26:12,650
wouldn't necessarily think of or I did

596
00:26:11,150 --> 00:26:15,140
that I wouldn't have thought of right

597
00:26:12,650 --> 00:26:18,820
away as being corpus terms but hear

598
00:26:15,140 --> 00:26:22,820
things like server attackers C 2 and C

599
00:26:18,820 --> 00:26:25,070
and C are actually both shorthand for

600
00:26:22,820 --> 00:26:27,830
command and control so that's the one

601
00:26:25,070 --> 00:26:30,230
thing that I will say that would take

602
00:26:27,830 --> 00:26:32,510
probably a lot more time to work on is

603
00:26:30,230 --> 00:26:34,220
actually going through because again

604
00:26:32,510 --> 00:26:36,740
this goes back to why we're looking for

605
00:26:34,220 --> 00:26:39,860
an ontology in the first place C 2 and C

606
00:26:36,740 --> 00:26:42,080
and C or I if I said c2 to somebody and

607
00:26:39,860 --> 00:26:43,100
they only knew it is C&C they wouldn't

608
00:26:42,080 --> 00:26:44,899
necessarily know what I'm talking about

609
00:26:43,100 --> 00:26:51,260
and that's the value of the two ontology

610
00:26:44,900 --> 00:26:53,750
now here's the here's a a simplified

611
00:26:51,260 --> 00:26:56,059
overview of basically the the ontology

612
00:26:53,750 --> 00:26:57,020
as I'm developing it you can see I have

613
00:26:56,059 --> 00:26:59,990
the

614
00:26:57,020 --> 00:27:02,690
the tables or the portions that include

615
00:26:59,990 --> 00:27:04,820
focus on the organization and then the

616
00:27:02,690 --> 00:27:08,810
the parts that focus on the attack so as

617
00:27:04,820 --> 00:27:10,340
I go to the organization we have as an

618
00:27:08,810 --> 00:27:12,919
apt organization it's going to have a

619
00:27:10,340 --> 00:27:16,220
name most of them right now or just apt

620
00:27:12,920 --> 00:27:19,010
one apt to apt 30 is a common one if you

621
00:27:16,220 --> 00:27:21,770
actually google it some but not all will

622
00:27:19,010 --> 00:27:23,360
have state sponsorship sponsorships by

623
00:27:21,770 --> 00:27:27,700
motivation i was looking at things like

624
00:27:23,360 --> 00:27:30,139
mice deep some some are looking to close

625
00:27:27,700 --> 00:27:32,600
some most or criminal activities

626
00:27:30,140 --> 00:27:35,210
stealing information others are looking

627
00:27:32,600 --> 00:27:39,770
to do malicious things along lines of

628
00:27:35,210 --> 00:27:40,940
Stuxnet then we go to the organization

629
00:27:39,770 --> 00:27:42,620
and how its structured remember I said

630
00:27:40,940 --> 00:27:44,900
this is a complex thing you have things

631
00:27:42,620 --> 00:27:46,550
like code writers virus writers web

632
00:27:44,900 --> 00:27:49,400
designers system administrators and

633
00:27:46,550 --> 00:27:51,560
these are terms we probably all could

634
00:27:49,400 --> 00:27:53,960
come up with a definition pretty quickly

635
00:27:51,560 --> 00:27:55,700
but finding this kind of information and

636
00:27:53,960 --> 00:27:57,710
seeing how complex these organizations

637
00:27:55,700 --> 00:28:01,580
are shows how important it is to have

638
00:27:57,710 --> 00:28:05,150
these come this ontology development

639
00:28:01,580 --> 00:28:07,070
nation now as I move down to the attack

640
00:28:05,150 --> 00:28:08,990
obviously this is a lot more detailed

641
00:28:07,070 --> 00:28:11,260
you have things like the name of an

642
00:28:08,990 --> 00:28:15,890
attack and you'll hear things like

643
00:28:11,260 --> 00:28:17,600
Stuxnet ice fog trying to think the are

644
00:28:15,890 --> 00:28:19,340
the RSA attack I'm drawing a blank on

645
00:28:17,600 --> 00:28:21,469
the name but I mean you have a lot of

646
00:28:19,340 --> 00:28:22,909
and they'll get reused and they might

647
00:28:21,470 --> 00:28:25,550
get renamed but there could be a

648
00:28:22,910 --> 00:28:28,160
relationship attributed organizations

649
00:28:25,550 --> 00:28:30,350
the attribution is one of our toughest

650
00:28:28,160 --> 00:28:32,480
things to do but sometimes there are

651
00:28:30,350 --> 00:28:34,040
patterns and there there's information

652
00:28:32,480 --> 00:28:37,130
embedded within the code that actually

653
00:28:34,040 --> 00:28:40,399
tells us the organization not too bright

654
00:28:37,130 --> 00:28:42,740
but it's what it is and then when it

655
00:28:40,400 --> 00:28:44,900
first appeared and again some apt

656
00:28:42,740 --> 00:28:46,550
attacks may get reused by other

657
00:28:44,900 --> 00:28:49,150
organizations or by the same

658
00:28:46,550 --> 00:28:54,080
organization later on with a different

659
00:28:49,150 --> 00:28:55,960
different set of targets now again like

660
00:28:54,080 --> 00:28:59,179
I said apt name here's some examples

661
00:28:55,960 --> 00:29:01,700
shady right night dragon ice fog

662
00:28:59,180 --> 00:29:03,200
arachnophobia and that's actually one

663
00:29:01,700 --> 00:29:06,260
thing i don't i'm not sure if you can

664
00:29:03,200 --> 00:29:08,390
see clearly but the there's a link here

665
00:29:06,260 --> 00:29:09,158
between an apt attack and the malware

666
00:29:08,390 --> 00:29:11,950
that it uses

667
00:29:09,159 --> 00:29:15,309
and bitter bug which I've used here is

668
00:29:11,950 --> 00:29:18,429
actually a sub component of the

669
00:29:15,309 --> 00:29:22,928
arachnophobia apt I guess that makes

670
00:29:18,429 --> 00:29:25,690
sense using with the similar names and

671
00:29:22,929 --> 00:29:26,979
here we have the types of communications

672
00:29:25,690 --> 00:29:31,809
that are used which again you I've

673
00:29:26,979 --> 00:29:36,179
mentioned earlier and that actually

674
00:29:31,809 --> 00:29:38,678
pretty much covers this this the

675
00:29:36,179 --> 00:29:40,090
ontology is still in work in progress

676
00:29:38,679 --> 00:29:42,279
and I've got to get it done pretty quick

677
00:29:40,090 --> 00:29:45,399
because I'm graduating here and in

678
00:29:42,279 --> 00:29:48,369
December I'm about to end i'm scheduled

679
00:29:45,399 --> 00:29:51,279
to defend here but the first 22

680
00:29:48,369 --> 00:29:54,119
documents produced almost a thousand

681
00:29:51,279 --> 00:29:56,799
terms that I personally could identify

682
00:29:54,119 --> 00:29:59,439
using some of the statistical analysis

683
00:29:56,799 --> 00:30:02,080
and the larger set of documents I'm

684
00:29:59,440 --> 00:30:05,080
already seeing that list growing to well

685
00:30:02,080 --> 00:30:07,599
over 3,000 if I would turn that ontology

686
00:30:05,080 --> 00:30:10,359
and now start to use it as a search tool

687
00:30:07,599 --> 00:30:12,939
to search the web because I now have

688
00:30:10,359 --> 00:30:14,769
terms that I can use I would expect that

689
00:30:12,940 --> 00:30:16,690
we continue to expand and that's

690
00:30:14,769 --> 00:30:19,389
actually one of the future aspects of

691
00:30:16,690 --> 00:30:21,869
research and using a potentially link

692
00:30:19,389 --> 00:30:26,738
analysis as a means of understanding if

693
00:30:21,869 --> 00:30:28,658
if two if two different apts for example

694
00:30:26,739 --> 00:30:30,940
use the same kind of same means of

695
00:30:28,659 --> 00:30:32,499
communication other other attributes

696
00:30:30,940 --> 00:30:34,450
that are similar are there are there

697
00:30:32,499 --> 00:30:36,940
ways that we can apply detection methods

698
00:30:34,450 --> 00:30:39,009
from one to the other because of the

699
00:30:36,940 --> 00:30:40,570
similarities that they share and that's

700
00:30:39,009 --> 00:30:43,629
that's where the application comes in

701
00:30:40,570 --> 00:30:45,639
here too for cyber security and for us

702
00:30:43,629 --> 00:30:47,379
as the defenders not only having the

703
00:30:45,639 --> 00:30:51,570
common terminology but potentially

704
00:30:47,379 --> 00:30:54,178
starting to mine data big data and find

705
00:30:51,570 --> 00:30:56,859
improving our detection defense method

706
00:30:54,179 --> 00:30:59,070
methodology so I'll open up the floor to

707
00:30:56,859 --> 00:30:59,070
questions

708
00:31:00,930 --> 00:31:12,410
I was interested in what software you

709
00:31:10,500 --> 00:31:15,960
used for a natural language processing

710
00:31:12,410 --> 00:31:17,970
i'm using oh that's good i'm sorry i

711
00:31:15,960 --> 00:31:19,320
didn't mention that there's actually a

712
00:31:17,970 --> 00:31:21,210
few out there there's a couple of open

713
00:31:19,320 --> 00:31:23,330
source ones i actually looked at the

714
00:31:21,210 --> 00:31:27,410
natural language toolkit which is python

715
00:31:23,330 --> 00:31:30,389
but i ended up on Stanford's core NLP

716
00:31:27,410 --> 00:31:32,790
and there's actually an extension that

717
00:31:30,390 --> 00:31:34,920
somebody developed and I'm drawing a

718
00:31:32,790 --> 00:31:36,899
blank in his name so i apologize i want

719
00:31:34,920 --> 00:31:39,240
to give him credit he created an app

720
00:31:36,900 --> 00:31:42,180
called book NLP which is just an

721
00:31:39,240 --> 00:31:45,020
extension of Stanford's product which

722
00:31:42,180 --> 00:31:47,940
was meant to deal with large documents

723
00:31:45,020 --> 00:31:51,210
entire books versus just sentences or

724
00:31:47,940 --> 00:31:54,660
paragraphs or short blogs it's called

725
00:31:51,210 --> 00:31:55,950
book NLP okay look is the extension now

726
00:31:54,660 --> 00:31:57,930
the one the one thing I will say if

727
00:31:55,950 --> 00:32:00,750
anybody looking into natural language

728
00:31:57,930 --> 00:32:03,740
processing Lisa's far there Coronel

729
00:32:00,750 --> 00:32:06,000
Coronel P product actually they have

730
00:32:03,740 --> 00:32:07,470
there have been a lot of extensions that

731
00:32:06,000 --> 00:32:09,300
have been developed by people doing

732
00:32:07,470 --> 00:32:11,400
their own research I didn't personally

733
00:32:09,300 --> 00:32:14,760
have the time because of my timeline

734
00:32:11,400 --> 00:32:16,650
here to develop my own the only thing

735
00:32:14,760 --> 00:32:19,410
the only challenge that I've seen and

736
00:32:16,650 --> 00:32:22,410
also with protege as an ontology tools

737
00:32:19,410 --> 00:32:24,630
people use it they develop it for as

738
00:32:22,410 --> 00:32:26,550
much as they need and then it doesn't

739
00:32:24,630 --> 00:32:28,500
quite either get continue to be

740
00:32:26,550 --> 00:32:30,030
developed because they've run out of

741
00:32:28,500 --> 00:32:32,790
funding or just they finish their

742
00:32:30,030 --> 00:32:35,399
project or it doesn't quite hit the mark

743
00:32:32,790 --> 00:32:37,610
that you might need but there are a lot

744
00:32:35,400 --> 00:32:40,440
of there was a lot of tools and a lot of

745
00:32:37,610 --> 00:32:43,520
resources out there as even as dr.

746
00:32:40,440 --> 00:32:49,230
Raskin was talking about two weeks ago

747
00:32:43,520 --> 00:32:51,930
sure the software that you used what

748
00:32:49,230 --> 00:32:53,970
format was your corpus in and did you

749
00:32:51,930 --> 00:32:57,960
get your corpus off the internet or oh

750
00:32:53,970 --> 00:33:00,210
I'm sorry I thought I okay yes I found

751
00:32:57,960 --> 00:33:03,270
two knowledge bases online they were

752
00:33:00,210 --> 00:33:07,380
actually both on github and they were in

753
00:33:03,270 --> 00:33:11,010
PDF format what I ended up having to do

754
00:33:07,380 --> 00:33:13,260
though was using a Python tool to

755
00:33:11,010 --> 00:33:14,908
actually extract the text from those

756
00:33:13,260 --> 00:33:18,869
documents so that they could be

757
00:33:14,909 --> 00:33:21,989
SS by the NLP software now some some

758
00:33:18,869 --> 00:33:24,238
some pdfs can be processed natively

759
00:33:21,989 --> 00:33:27,570
through the NLP but i was getting too

760
00:33:24,239 --> 00:33:29,970
many errors and I because it was kind of

761
00:33:27,570 --> 00:33:33,080
strolling my progress I made the

762
00:33:29,970 --> 00:33:36,359
sacrifice of losing images and and maybe

763
00:33:33,080 --> 00:33:39,570
graphically design PDFs accepting that I

764
00:33:36,359 --> 00:33:41,309
would lose those uh and I just extracted

765
00:33:39,570 --> 00:33:53,249
whatever text I could get from them and

766
00:33:41,309 --> 00:33:55,168
process that any other questions I have

767
00:33:53,249 --> 00:33:58,470
a question yum you mentioned text

768
00:33:55,169 --> 00:34:01,879
categorization do you use any machine

769
00:33:58,470 --> 00:34:07,799
learning algorithm to categorize text uh

770
00:34:01,879 --> 00:34:09,239
their core NOP well the natural as a

771
00:34:07,799 --> 00:34:11,069
natural language processing tool some of

772
00:34:09,239 --> 00:34:14,848
them have some algorithms I didn't I

773
00:34:11,069 --> 00:34:18,179
used what came out of the box I I used

774
00:34:14,849 --> 00:34:20,609
it as it came I again this is that that

775
00:34:18,179 --> 00:34:22,260
ability to extend these packages that's

776
00:34:20,609 --> 00:34:24,659
where you could add algorithms like that

777
00:34:22,260 --> 00:34:26,579
I did I did and it was part of the

778
00:34:24,659 --> 00:34:31,139
reason for using the 22 documents was to

779
00:34:26,579 --> 00:34:34,109
try to train their algorithm it didn't

780
00:34:31,139 --> 00:34:35,669
prove and I'll honestly say it could be

781
00:34:34,109 --> 00:34:40,379
it could be on me because I was actually

782
00:34:35,668 --> 00:34:42,538
trying to learn this as I was going my

783
00:34:40,379 --> 00:34:45,029
training of the tool didn't seem to

784
00:34:42,539 --> 00:34:47,849
change my results very much but you can

785
00:34:45,029 --> 00:34:53,369
actually train these NLP software to

786
00:34:47,849 --> 00:34:55,049
recognize regular expressions that they

787
00:34:53,369 --> 00:34:57,000
might be coming you can use regular

788
00:34:55,049 --> 00:35:02,309
expressions to train it in algorithms to

789
00:34:57,000 --> 00:35:04,819
train its a yes they are possible any

790
00:35:02,309 --> 00:35:04,819
other question

791
00:35:06,240 --> 00:35:14,009
well thank you very much that does it

792
00:35:11,900 --> 00:35:16,490
it's weird being on this side of the

793
00:35:14,010 --> 00:35:16,490
screen off

794
00:35:28,060 --> 00:35:30,120
you

