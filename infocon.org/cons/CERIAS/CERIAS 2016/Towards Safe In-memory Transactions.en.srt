1
00:00:09,840 --> 00:00:19,390
so welcome everyone it's my pleasure to

2
00:00:15,580 --> 00:00:21,640
introduce srivatsan ravi today he is a

3
00:00:19,390 --> 00:00:23,529
postdoctoral researcher in the

4
00:00:21,640 --> 00:00:25,150
department of computer science and is

5
00:00:23,529 --> 00:00:29,439
interested in the theory and practice of

6
00:00:25,150 --> 00:00:32,320
distributed computing today he will talk

7
00:00:29,439 --> 00:00:38,650
about how to make in-memory transactions

8
00:00:32,320 --> 00:00:41,620
safe Thank You Himanta so this talk is

9
00:00:38,650 --> 00:00:43,600
going to be about building and the

10
00:00:41,620 --> 00:00:47,320
inherent complexity is associated with

11
00:00:43,600 --> 00:00:49,360
implementing in-memory transactions so

12
00:00:47,320 --> 00:00:51,309
transactions is of course the concept

13
00:00:49,360 --> 00:00:52,750
that everyone and the computer science

14
00:00:51,309 --> 00:00:55,110
is familiar with but there are some

15
00:00:52,750 --> 00:00:57,970
inherent issues in implementing them

16
00:00:55,110 --> 00:01:00,010
inside the memory and what I will be

17
00:00:57,970 --> 00:01:02,470
talking about is the motivation for this

18
00:01:00,010 --> 00:01:04,839
programming model the inherent

19
00:01:02,470 --> 00:01:07,539
complexities with associated with it and

20
00:01:04,839 --> 00:01:11,350
hopefully several questions for all of

21
00:01:07,540 --> 00:01:14,200
us to ponder over so the background here

22
00:01:11,350 --> 00:01:15,729
is so for those of you who familiar with

23
00:01:14,200 --> 00:01:19,659
sort of the recent trend in the

24
00:01:15,729 --> 00:01:21,729
computing industry we've seen this idea

25
00:01:19,659 --> 00:01:23,920
that the number of codes put on a single

26
00:01:21,729 --> 00:01:26,710
computing chip has increased since the

27
00:01:23,920 --> 00:01:29,109
early 2000s the so called the Moore's

28
00:01:26,710 --> 00:01:30,609
Law is no longer valid for us in the

29
00:01:29,109 --> 00:01:32,740
sense that you can't keep writing

30
00:01:30,609 --> 00:01:34,990
sequential programs and expect it to

31
00:01:32,740 --> 00:01:36,490
give better performance just because you

32
00:01:34,990 --> 00:01:38,380
have a faster processor so you've

33
00:01:36,490 --> 00:01:40,479
reached that thermal and you know

34
00:01:38,380 --> 00:01:42,070
physical limit of the number of

35
00:01:40,479 --> 00:01:44,350
transistors that you can fit into a

36
00:01:42,070 --> 00:01:46,059
single die and so people CPU

37
00:01:44,350 --> 00:01:49,719
manufacturers have moved towards putting

38
00:01:46,060 --> 00:01:51,609
multiple cores within a single chip so

39
00:01:49,719 --> 00:01:53,919
you've seen this increase of in a

40
00:01:51,609 --> 00:01:55,839
stabilization of cpu frequency but the

41
00:01:53,920 --> 00:01:58,749
increase in the number of coves which

42
00:01:55,840 --> 00:02:00,549
have put into a single die so the bottom

43
00:01:58,749 --> 00:02:02,530
line for us from the pub from the

44
00:02:00,549 --> 00:02:04,689
perspective of an algorithm designer is

45
00:02:02,530 --> 00:02:06,549
that the programs have to be written for

46
00:02:04,689 --> 00:02:08,739
concurrency so the thread level

47
00:02:06,549 --> 00:02:12,100
parallelism in the program will have to

48
00:02:08,740 --> 00:02:14,440
be exploited but of course what this

49
00:02:12,100 --> 00:02:16,239
means is that these processes and

50
00:02:14,440 --> 00:02:18,489
threads they have to synchronize amongst

51
00:02:16,239 --> 00:02:20,500
each other right but at some point when

52
00:02:18,489 --> 00:02:22,840
all these multiple threads try to ax

53
00:02:20,500 --> 00:02:25,420
a single piece of data they reach the

54
00:02:22,840 --> 00:02:26,830
sequential memory bottleneck and now the

55
00:02:25,420 --> 00:02:29,290
question for us is how do you resolve

56
00:02:26,830 --> 00:02:30,700
that and this is a very deep question at

57
00:02:29,290 --> 00:02:33,970
the heart of designing concurrent

58
00:02:30,700 --> 00:02:35,589
programs so most of us are aware of

59
00:02:33,970 --> 00:02:37,810
these traditional synchronization

60
00:02:35,590 --> 00:02:39,610
techniques you have this cause green

61
00:02:37,810 --> 00:02:41,200
locking technique where you just if

62
00:02:39,610 --> 00:02:43,420
you're implementing a list you just take

63
00:02:41,200 --> 00:02:45,579
the lock on the head and it's very

64
00:02:43,420 --> 00:02:47,170
simple and easy to use but of course

65
00:02:45,580 --> 00:02:48,910
there's a contention and a sequential

66
00:02:47,170 --> 00:02:50,559
bottleneck associated with it right

67
00:02:48,910 --> 00:02:54,250
that's the single log and you really

68
00:02:50,560 --> 00:02:56,290
prevent any concurrency happening oh you

69
00:02:54,250 --> 00:02:58,540
can do more fine-grain locking right you

70
00:02:56,290 --> 00:02:59,890
can take logs depending on the semantics

71
00:02:58,540 --> 00:03:02,500
of the application that you're building

72
00:02:59,890 --> 00:03:04,510
and that is a fine granularity there's

73
00:03:02,500 --> 00:03:06,820
great performance but it's so much

74
00:03:04,510 --> 00:03:09,100
harder to verify and more importantly

75
00:03:06,820 --> 00:03:10,870
it's not easily composable so you can't

76
00:03:09,100 --> 00:03:12,160
take different log based programs and

77
00:03:10,870 --> 00:03:14,980
sort of get them working in one

78
00:03:12,160 --> 00:03:19,180
contiguous piece of program which

79
00:03:14,980 --> 00:03:20,950
appears correct or you can do this log 3

80
00:03:19,180 --> 00:03:22,739
synchronization where you exploit the

81
00:03:20,950 --> 00:03:25,060
hardware primitives that are provided

82
00:03:22,739 --> 00:03:26,830
you know that provides this sort of

83
00:03:25,060 --> 00:03:28,390
fine-grained granularity and great

84
00:03:26,830 --> 00:03:30,670
performance but again it has the same

85
00:03:28,390 --> 00:03:32,859
problem associated with fine grain

86
00:03:30,670 --> 00:03:34,630
locking it's just so hard to verify the

87
00:03:32,860 --> 00:03:36,610
correctness of the content program

88
00:03:34,630 --> 00:03:39,870
unique you can't ensure the safety of

89
00:03:36,610 --> 00:03:42,670
the concurrent program more specifically

90
00:03:39,870 --> 00:03:45,790
so just to sort of give you a background

91
00:03:42,670 --> 00:03:47,859
you know if you were designing a list

92
00:03:45,790 --> 00:03:49,420
based queue right a very simple data

93
00:03:47,860 --> 00:03:51,310
structure that we are all aware of a

94
00:03:49,420 --> 00:03:53,828
first-in-first-out data structure right

95
00:03:51,310 --> 00:03:56,950
what goes in first comes out and Q and

96
00:03:53,829 --> 00:03:58,510
DQ operations so if you had to do this

97
00:03:56,950 --> 00:04:00,880
via cause green locking if you

98
00:03:58,510 --> 00:04:02,470
implemented it as a linked list you will

99
00:04:00,880 --> 00:04:05,980
simply take the lock on the head of the

100
00:04:02,470 --> 00:04:08,140
list and you're good so what is the

101
00:04:05,980 --> 00:04:10,359
problem so the log becomes this

102
00:04:08,140 --> 00:04:13,059
bottleneck and if this process holding

103
00:04:10,360 --> 00:04:15,040
this log fails and without releasing

104
00:04:13,060 --> 00:04:18,130
this lock then no other process can

105
00:04:15,040 --> 00:04:23,560
acquire any operations on this data

106
00:04:18,130 --> 00:04:25,150
structure the sequential bottleneck and

107
00:04:23,560 --> 00:04:27,160
this is a blocking abstraction the

108
00:04:25,150 --> 00:04:28,719
single lock or you can do fine green

109
00:04:27,160 --> 00:04:30,190
locking right so in this case you know

110
00:04:28,720 --> 00:04:32,080
it's a queue when you're working on

111
00:04:30,190 --> 00:04:33,790
different parts of the queue you can use

112
00:04:32,080 --> 00:04:35,349
different locks but then

113
00:04:33,790 --> 00:04:37,240
the programmer needs to implement these

114
00:04:35,350 --> 00:04:38,980
logs in a safe manner he needs to be

115
00:04:37,240 --> 00:04:41,140
careful that he doesn't violate the

116
00:04:38,980 --> 00:04:42,780
semantics of what he is trying to

117
00:04:41,140 --> 00:04:45,550
implement in the concurrent code and

118
00:04:42,780 --> 00:04:47,380
this is a age-old problem for us and

119
00:04:45,550 --> 00:04:49,720
this turns out to be a verification

120
00:04:47,380 --> 00:04:51,820
nightmare most of the times it's okay

121
00:04:49,720 --> 00:04:53,860
for a simple q or a stack data

122
00:04:51,820 --> 00:04:55,690
structures that we know but what about

123
00:04:53,860 --> 00:04:58,060
more complex data structures for which

124
00:04:55,690 --> 00:05:01,930
the sequential behavior is fairly

125
00:04:58,060 --> 00:05:03,640
rigorous and hard to specify or you can

126
00:05:01,930 --> 00:05:05,770
do this log free programming where you

127
00:05:03,640 --> 00:05:07,810
use these non blocking primitives like

128
00:05:05,770 --> 00:05:09,190
compare and swap and test and set which

129
00:05:07,810 --> 00:05:11,080
are available on modern hardware

130
00:05:09,190 --> 00:05:13,510
architectures instruction set

131
00:05:11,080 --> 00:05:16,780
architectures and you have the same

132
00:05:13,510 --> 00:05:18,969
problem with these two where you really

133
00:05:16,780 --> 00:05:20,440
need the programmer to understand the

134
00:05:18,970 --> 00:05:22,900
semantics of what he is trying to

135
00:05:20,440 --> 00:05:28,750
implement so that he only generates safe

136
00:05:22,900 --> 00:05:30,789
code verification nightmare but here's a

137
00:05:28,750 --> 00:05:33,220
more real-world problem that all of us

138
00:05:30,790 --> 00:05:35,500
I'm sure as designers of concurrent

139
00:05:33,220 --> 00:05:37,810
programs are faced with so you have two

140
00:05:35,500 --> 00:05:41,170
different queues right to independent

141
00:05:37,810 --> 00:05:43,660
queues now imagine you want to move one

142
00:05:41,170 --> 00:05:46,330
piece of element from one to the other

143
00:05:43,660 --> 00:05:50,200
and you want this entire action to

144
00:05:46,330 --> 00:05:52,479
appear atomic so what does this mean so

145
00:05:50,200 --> 00:05:55,030
you want to atomically DQ from the first

146
00:05:52,480 --> 00:05:57,040
queue and whatever you get from that DQ

147
00:05:55,030 --> 00:06:00,520
you want to Inc you it into the second

148
00:05:57,040 --> 00:06:03,490
one now you want this entire action to

149
00:06:00,520 --> 00:06:06,940
appear atomic in the sense that no other

150
00:06:03,490 --> 00:06:09,940
concurrent process sees that it was dq'd

151
00:06:06,940 --> 00:06:12,520
and it wasn't included either sees that

152
00:06:09,940 --> 00:06:14,920
nothing happened or both happened how do

153
00:06:12,520 --> 00:06:16,690
you ensure this now you could take logs

154
00:06:14,920 --> 00:06:18,340
on each of the individual queues and you

155
00:06:16,690 --> 00:06:21,400
know design it explicitly the way you

156
00:06:18,340 --> 00:06:24,310
would but this is not really a universal

157
00:06:21,400 --> 00:06:25,960
solution right what you really want is

158
00:06:24,310 --> 00:06:27,460
something right in the middle right with

159
00:06:25,960 --> 00:06:29,560
coarse grained locking you know you take

160
00:06:27,460 --> 00:06:31,930
that single lock it's going to be safe

161
00:06:29,560 --> 00:06:34,090
but it's not really going to perform

162
00:06:31,930 --> 00:06:35,740
well it's going to be blocking but then

163
00:06:34,090 --> 00:06:37,210
you have this other extreme with this

164
00:06:35,740 --> 00:06:39,670
lock free programming and fine-grained

165
00:06:37,210 --> 00:06:41,469
locking which in which case you're

166
00:06:39,670 --> 00:06:43,570
really going to exploit the concurrency

167
00:06:41,470 --> 00:06:46,270
you're probably going to get highly

168
00:06:43,570 --> 00:06:47,320
efficient code but it's much harder to

169
00:06:46,270 --> 00:06:49,900
verify the safety

170
00:06:47,320 --> 00:06:51,250
the code so you want something which is

171
00:06:49,900 --> 00:06:54,840
right in the middle just right

172
00:06:51,250 --> 00:06:56,920
Goldilocks right and this is where

173
00:06:54,840 --> 00:06:58,900
transactional memory as a programming

174
00:06:56,920 --> 00:07:01,690
model has really come into the picture

175
00:06:58,900 --> 00:07:03,640
for us so the idea is now that

176
00:07:01,690 --> 00:07:05,320
programming concurrent programming is

177
00:07:03,640 --> 00:07:07,210
made very simple as long as the

178
00:07:05,320 --> 00:07:10,270
underlying sequential code and the

179
00:07:07,210 --> 00:07:12,219
sequential specification is correct so

180
00:07:10,270 --> 00:07:14,380
you the programmer himself does not need

181
00:07:12,220 --> 00:07:16,600
to explicitly worry about dealing with

182
00:07:14,380 --> 00:07:18,730
correctness and deadlox easy

183
00:07:16,600 --> 00:07:20,830
composability and verification whatever

184
00:07:18,730 --> 00:07:22,780
the composable problem that you have you

185
00:07:20,830 --> 00:07:24,400
get this in sort of a blackbox

186
00:07:22,780 --> 00:07:27,669
abstraction a universal piece of

187
00:07:24,400 --> 00:07:30,130
programming model and the concurrent

188
00:07:27,670 --> 00:07:32,290
operations are basically now executed as

189
00:07:30,130 --> 00:07:34,690
optimistic transactions with this

190
00:07:32,290 --> 00:07:37,390
all-or-nothing semantics so either the

191
00:07:34,690 --> 00:07:40,900
entire piece of code takes effect or it

192
00:07:37,390 --> 00:07:44,469
does not so imagine how good an

193
00:07:40,900 --> 00:07:47,020
abstraction that is so you get the best

194
00:07:44,470 --> 00:07:48,520
of Bowl balls both worlds now so you

195
00:07:47,020 --> 00:07:50,200
have the coarse grain locking which is

196
00:07:48,520 --> 00:07:52,359
very simple and easy to verify the

197
00:07:50,200 --> 00:07:56,289
safety of the code and hopefully

198
00:07:52,360 --> 00:07:58,120
hopefully we can get these transactions

199
00:07:56,290 --> 00:08:01,300
to execute concurrently and resolve

200
00:07:58,120 --> 00:08:03,340
these conflicts at runtime now the

201
00:08:01,300 --> 00:08:04,990
purpose of this talk is to talk about

202
00:08:03,340 --> 00:08:07,750
what it takes to implement such

203
00:08:04,990 --> 00:08:09,970
transactions most specifically in this

204
00:08:07,750 --> 00:08:12,250
talk I will only concentrate on the

205
00:08:09,970 --> 00:08:14,980
inherent complexities associated with

206
00:08:12,250 --> 00:08:18,730
implementing them and where the

207
00:08:14,980 --> 00:08:20,260
bottleneck lies so if you look at it in

208
00:08:18,730 --> 00:08:22,300
terms of an implementation you have

209
00:08:20,260 --> 00:08:24,159
these transactions which are accessing

210
00:08:22,300 --> 00:08:26,260
these data items like the nodes of a

211
00:08:24,160 --> 00:08:28,270
list which in turn are working on these

212
00:08:26,260 --> 00:08:30,310
underlying memory locations with the

213
00:08:28,270 --> 00:08:34,299
abstractions provided by the underlying

214
00:08:30,310 --> 00:08:36,159
hardware instruction set architecture so

215
00:08:34,299 --> 00:08:38,409
these transactions now just do reads and

216
00:08:36,159 --> 00:08:40,209
writes on data items now our goal as

217
00:08:38,409 --> 00:08:42,039
algorithm design this is to just provide

218
00:08:40,210 --> 00:08:44,200
the algorithms for designing these reads

219
00:08:42,039 --> 00:08:46,780
and writes and once you do this it

220
00:08:44,200 --> 00:08:48,730
serves as a universal abstraction so you

221
00:08:46,780 --> 00:08:50,500
can work on any well-defined piece of

222
00:08:48,730 --> 00:08:52,510
sequential code instead of explicitly

223
00:08:50,500 --> 00:08:53,980
writing code each time specific to

224
00:08:52,510 --> 00:08:57,280
whatever you are trying to implement in

225
00:08:53,980 --> 00:08:59,170
a concurrent way so you can do this

226
00:08:57,280 --> 00:09:00,600
purely in software just like designing

227
00:08:59,170 --> 00:09:02,399
any other data structure you

228
00:09:00,600 --> 00:09:04,319
can like implement these transactions by

229
00:09:02,399 --> 00:09:07,949
applying these primitives on these based

230
00:09:04,319 --> 00:09:10,319
objects but what is really cool for us

231
00:09:07,949 --> 00:09:12,359
right now is that there is support for

232
00:09:10,319 --> 00:09:14,459
executing these transactions as part of

233
00:09:12,360 --> 00:09:16,769
the instruction set architecture which

234
00:09:14,459 --> 00:09:19,739
basically extends the classic messy

235
00:09:16,769 --> 00:09:21,660
cache coherence protocol and in this

236
00:09:19,740 --> 00:09:24,120
talk I will be explicitly concentrating

237
00:09:21,660 --> 00:09:26,189
on this but then there is a problem

238
00:09:24,120 --> 00:09:28,649
right even hardware transactions can

239
00:09:26,190 --> 00:09:30,750
arbitrary fail so what now people tend

240
00:09:28,649 --> 00:09:33,240
to do is move towards this hybrid model

241
00:09:30,750 --> 00:09:34,980
of transactions in memory where you

242
00:09:33,240 --> 00:09:36,540
first try to execute something in

243
00:09:34,980 --> 00:09:37,980
Hardware because the hardware is going

244
00:09:36,540 --> 00:09:40,349
to be very fast it's going to give all

245
00:09:37,980 --> 00:09:41,880
these safety semantics to you and if the

246
00:09:40,350 --> 00:09:43,829
hardware transaction phase of which

247
00:09:41,880 --> 00:09:45,660
there is a very high probability simply

248
00:09:43,829 --> 00:09:48,719
because of spurious aborts the size of

249
00:09:45,660 --> 00:09:50,399
the cache line is limited you know the

250
00:09:48,720 --> 00:09:52,350
process executing the transaction may be

251
00:09:50,399 --> 00:09:54,600
arbitrarily d scheduled at any point of

252
00:09:52,350 --> 00:09:56,550
time due to context switching so you

253
00:09:54,600 --> 00:09:58,500
need a backup the back up being you try

254
00:09:56,550 --> 00:10:01,560
to re-execute that same piece of code in

255
00:09:58,500 --> 00:10:04,079
software this is what we call the hybrid

256
00:10:01,560 --> 00:10:05,790
model and this is pretty much the next

257
00:10:04,079 --> 00:10:09,769
generation programming model I would

258
00:10:05,790 --> 00:10:12,420
argue for writing safes concurrent code

259
00:10:09,769 --> 00:10:14,189
when I mean safe I'll elaborate on this

260
00:10:12,420 --> 00:10:16,589
it must be that these transactions are

261
00:10:14,189 --> 00:10:18,480
consistent so they opaque to the outside

262
00:10:16,589 --> 00:10:22,139
world in the sense that everything

263
00:10:18,480 --> 00:10:23,699
happens without any concurrency bugs

264
00:10:22,139 --> 00:10:27,089
that are explicitly introduced as part

265
00:10:23,699 --> 00:10:28,979
of executing these transactions so just

266
00:10:27,089 --> 00:10:30,269
in terms of using transaction memory for

267
00:10:28,980 --> 00:10:31,920
those of you who are trying to envision

268
00:10:30,269 --> 00:10:34,980
what this programming model looks like

269
00:10:31,920 --> 00:10:36,719
it's quite simple so you write your

270
00:10:34,980 --> 00:10:38,399
piece of sequential code so in this case

271
00:10:36,720 --> 00:10:42,060
imagine you're just doing your thang you

272
00:10:38,399 --> 00:10:43,649
into a queue abstraction so you said you

273
00:10:42,060 --> 00:10:45,180
know implemented as a list you change

274
00:10:43,649 --> 00:10:46,800
the pointers the next to point to the

275
00:10:45,180 --> 00:10:48,300
new node and the new node to point to

276
00:10:46,800 --> 00:10:50,219
the new element that you are inserting

277
00:10:48,300 --> 00:10:52,050
this is just a simple piece of

278
00:10:50,220 --> 00:10:54,750
sequential code that all of us know how

279
00:10:52,050 --> 00:10:57,449
to write now your goal when you try and

280
00:10:54,750 --> 00:10:59,339
turn it into concurrent code all that

281
00:10:57,449 --> 00:11:01,649
the programming model requires is to

282
00:10:59,339 --> 00:11:04,949
explicitly mark the piece of code that

283
00:11:01,649 --> 00:11:08,220
you expect to run atomically with an

284
00:11:04,949 --> 00:11:10,889
atomic delimiter so this is exactly the

285
00:11:08,220 --> 00:11:13,430
delimiter which is provided by today by

286
00:11:10,889 --> 00:11:15,200
today's software transaction memory

287
00:11:13,430 --> 00:11:17,859
tations in fact for those of you who

288
00:11:15,200 --> 00:11:20,390
familiar with it the current GCC

289
00:11:17,860 --> 00:11:23,450
implementation has support for running

290
00:11:20,390 --> 00:11:25,550
in memory transactions so the delimiter

291
00:11:23,450 --> 00:11:27,020
is this transaction atomic which lets

292
00:11:25,550 --> 00:11:28,430
you write your sequential code just

293
00:11:27,020 --> 00:11:30,890
place this and the underline compiler

294
00:11:28,430 --> 00:11:32,180
why is about resolving conflicts while

295
00:11:30,890 --> 00:11:37,040
ensuring that the underlying

296
00:11:32,180 --> 00:11:38,899
implementation is safe so the concurrent

297
00:11:37,040 --> 00:11:45,589
operation in the atomic block is

298
00:11:38,899 --> 00:11:47,330
executed as a transaction so what it

299
00:11:45,589 --> 00:11:49,130
would mean is that in this case you're

300
00:11:47,330 --> 00:11:51,110
performing a DQ operation and you're

301
00:11:49,130 --> 00:11:52,520
performing in an incubation normally you

302
00:11:51,110 --> 00:11:54,399
would take fine-grained locks if you

303
00:11:52,520 --> 00:11:57,199
wanted a real efficient implementation

304
00:11:54,399 --> 00:11:59,120
in this case you don't worry you write

305
00:11:57,200 --> 00:12:01,550
your sequential code and you just wrap

306
00:11:59,120 --> 00:12:03,470
the DQ and in queue operations within

307
00:12:01,550 --> 00:12:05,479
two separate transactions and the

308
00:12:03,470 --> 00:12:07,070
underlying GCC implementation of

309
00:12:05,480 --> 00:12:09,290
whichever compiler that are using in

310
00:12:07,070 --> 00:12:10,720
diverse to execute these transactions

311
00:12:09,290 --> 00:12:17,510
concurrently with this all-or-nothing

312
00:12:10,720 --> 00:12:19,010
semantics so far so good so the

313
00:12:17,510 --> 00:12:22,490
programmer does not need to worry about

314
00:12:19,010 --> 00:12:24,470
correctness and deadlox or is it how do

315
00:12:22,490 --> 00:12:25,730
we ensure that the programmer does not

316
00:12:24,470 --> 00:12:28,190
have to worry about correctness and

317
00:12:25,730 --> 00:12:29,930
deadlox and that's pretty much the goal

318
00:12:28,190 --> 00:12:32,089
of this talk where I am trying to help

319
00:12:29,930 --> 00:12:33,979
you understand what are the inherent

320
00:12:32,089 --> 00:12:36,170
challenges associated with implementing

321
00:12:33,980 --> 00:12:38,900
these transactions today because I would

322
00:12:36,170 --> 00:12:40,459
argue that this is the real zeitgeist

323
00:12:38,900 --> 00:12:45,770
programming model for concurrent code

324
00:12:40,459 --> 00:12:47,479
right now so in this case imagine you're

325
00:12:45,770 --> 00:12:49,880
inserting and removing into a list a

326
00:12:47,480 --> 00:12:51,230
classic banking transaction however you

327
00:12:49,880 --> 00:12:52,970
want to think of it you're inserting an

328
00:12:51,230 --> 00:12:55,400
element into a set and you're removing

329
00:12:52,970 --> 00:12:58,520
an element into a set so in this case

330
00:12:55,400 --> 00:13:01,970
the head points to a node 1 node 1

331
00:12:58,520 --> 00:13:04,819
points to a node 2 2 2 3 3 to 4 and then

332
00:13:01,970 --> 00:13:07,430
today so this is the initial invariant

333
00:13:04,820 --> 00:13:09,260
that is present so now imagine that is a

334
00:13:07,430 --> 00:13:10,399
transaction two transactions happening

335
00:13:09,260 --> 00:13:12,890
they are trying to happen concurrently

336
00:13:10,399 --> 00:13:15,980
this is simply like you know someone

337
00:13:12,890 --> 00:13:18,140
inserting and removing some money into

338
00:13:15,980 --> 00:13:20,660
your banking account or you know however

339
00:13:18,140 --> 00:13:22,910
you want to envision it so in this case

340
00:13:20,660 --> 00:13:25,730
what you need to do when you insert a

341
00:13:22,910 --> 00:13:26,819
new element one is that the head needs

342
00:13:25,730 --> 00:13:28,679
to you need to

343
00:13:26,819 --> 00:13:31,049
get the new element and the head pointer

344
00:13:28,679 --> 00:13:33,689
needs to be updated to point to this new

345
00:13:31,049 --> 00:13:36,059
element let us say one which is created

346
00:13:33,689 --> 00:13:38,039
and the new point the new element

347
00:13:36,059 --> 00:13:40,069
created its next pointer must be changed

348
00:13:38,039 --> 00:13:42,509
to this existing element which is too

349
00:13:40,069 --> 00:13:44,669
but concurrently there is another

350
00:13:42,509 --> 00:13:46,829
transaction of which the first

351
00:13:44,669 --> 00:13:49,410
transaction is oblivious to which is

352
00:13:46,829 --> 00:13:50,728
trying to remove the element to right

353
00:13:49,410 --> 00:13:53,069
now you must make sure that there are no

354
00:13:50,729 --> 00:13:54,869
dangling pointers at this time how do

355
00:13:53,069 --> 00:13:57,059
you do this this is what we mean by

356
00:13:54,869 --> 00:13:58,739
safety right it's something which is

357
00:13:57,059 --> 00:14:00,809
obvious to us you know these subtle

358
00:13:58,739 --> 00:14:02,879
concurrency bugs that arise and the

359
00:14:00,809 --> 00:14:05,339
question is what does it formally mean

360
00:14:02,879 --> 00:14:08,279
to say a piece of concurrent code is

361
00:14:05,339 --> 00:14:09,749
safe in the sense that nothing happens

362
00:14:08,279 --> 00:14:14,910
that could not have happened in a

363
00:14:09,749 --> 00:14:17,160
sequential run of this program here's

364
00:14:14,910 --> 00:14:19,410
another example so initially we begin

365
00:14:17,160 --> 00:14:22,399
with this invariant you know to data

366
00:14:19,410 --> 00:14:24,660
items x equal to 1 and y equal to 2 and

367
00:14:22,399 --> 00:14:27,389
you have two transactions which are

368
00:14:24,660 --> 00:14:29,549
running concurrently so transaction t1

369
00:14:27,389 --> 00:14:31,169
which is reading this element X and it

370
00:14:29,549 --> 00:14:33,209
is trying to atomically increment it and

371
00:14:31,169 --> 00:14:35,879
its trying to atomically increment the

372
00:14:33,209 --> 00:14:38,459
element Y and that is a concurrent

373
00:14:35,879 --> 00:14:40,499
transaction which is basically trying to

374
00:14:38,459 --> 00:14:42,929
you know do one x y over x for some

375
00:14:40,499 --> 00:14:44,639
reason so what is the most important

376
00:14:42,929 --> 00:14:46,649
thing that what is the worst thing that

377
00:14:44,639 --> 00:14:50,669
can go wrong here from the design of a

378
00:14:46,649 --> 00:14:52,679
concurrent programmer so the worst thing

379
00:14:50,669 --> 00:14:54,989
that can go wrong is that the concurrent

380
00:14:52,679 --> 00:14:57,269
transaction only sees a partial update

381
00:14:54,989 --> 00:15:00,149
it sees that X has been updated but why

382
00:14:57,269 --> 00:15:01,979
has not yet been updated if that is

383
00:15:00,149 --> 00:15:05,039
indeed the scenario what can happen you

384
00:15:01,979 --> 00:15:07,439
can basically envision that this

385
00:15:05,039 --> 00:15:10,229
transaction t2 it reads X equal to 2 and

386
00:15:07,439 --> 00:15:14,219
y equal to in which case you end up

387
00:15:10,229 --> 00:15:16,499
going into a division by 0 so what is

388
00:15:14,220 --> 00:15:19,379
happening is that these two transactions

389
00:15:16,499 --> 00:15:21,929
simply by virtue of a bad implementation

390
00:15:19,379 --> 00:15:23,850
are seeing a state of the system

391
00:15:21,929 --> 00:15:25,679
configuration which they could not have

392
00:15:23,850 --> 00:15:29,489
observed in a sequential run of these

393
00:15:25,679 --> 00:15:32,389
two transactions and these sort of

394
00:15:29,489 --> 00:15:35,069
errors are errors which are typically

395
00:15:32,389 --> 00:15:37,769
irrecoverable from and this is really a

396
00:15:35,069 --> 00:15:40,199
problem for us and how do we deal with

397
00:15:37,769 --> 00:15:41,880
these sort of errors is basically

398
00:15:40,200 --> 00:15:44,400
the challenge of designing safe

399
00:15:41,880 --> 00:15:48,090
transactions or safe transactions in

400
00:15:44,400 --> 00:15:50,939
memory so what is safety for in-memory

401
00:15:48,090 --> 00:15:52,800
transactions the safe code must

402
00:15:50,940 --> 00:15:54,930
basically protect against these runtime

403
00:15:52,800 --> 00:15:57,150
errors like division by zero or running

404
00:15:54,930 --> 00:15:59,189
into infinite loops simply because the

405
00:15:57,150 --> 00:16:01,970
transaction witnesses an inconsistent

406
00:15:59,190 --> 00:16:04,860
state of the system configuration and

407
00:16:01,970 --> 00:16:08,520
from our point of view safety basically

408
00:16:04,860 --> 00:16:10,950
means in very informal terms that no

409
00:16:08,520 --> 00:16:12,840
transaction must witness state that

410
00:16:10,950 --> 00:16:15,270
cannot be observed in a sequential

411
00:16:12,840 --> 00:16:17,550
execution even if the processes

412
00:16:15,270 --> 00:16:22,439
executing the transaction may fail by

413
00:16:17,550 --> 00:16:24,689
crashing so is that clear so what it

414
00:16:22,440 --> 00:16:26,130
means is that nothing can happen during

415
00:16:24,690 --> 00:16:30,180
the execution of a concurrent

416
00:16:26,130 --> 00:16:32,310
transaction which could not have

417
00:16:30,180 --> 00:16:34,670
happened when the same transaction ran

418
00:16:32,310 --> 00:16:37,579
sequentially without any concurrency

419
00:16:34,670 --> 00:16:40,770
this is seemingly a very obvious

420
00:16:37,580 --> 00:16:43,560
definition of what is safe right the

421
00:16:40,770 --> 00:16:44,880
mind tends to envision what is running

422
00:16:43,560 --> 00:16:46,979
sequentially it's much harder to

423
00:16:44,880 --> 00:16:48,600
envision the possible interleaving when

424
00:16:46,980 --> 00:16:50,430
n different processes try to

425
00:16:48,600 --> 00:16:53,850
concurrently access the same piece of

426
00:16:50,430 --> 00:16:56,099
memory so formally what this would mean

427
00:16:53,850 --> 00:16:59,760
for us is that the execution appears

428
00:16:56,100 --> 00:17:01,980
opaque by opaque I mean I can take these

429
00:16:59,760 --> 00:17:03,660
I can take an execution a concurrent

430
00:17:01,980 --> 00:17:05,699
execution in which these transactions

431
00:17:03,660 --> 00:17:07,670
and these processes are interleaving and

432
00:17:05,699 --> 00:17:10,470
accessing different memory locations and

433
00:17:07,670 --> 00:17:12,209
I can reduce it to a sequential

434
00:17:10,470 --> 00:17:14,400
execution of these same set of

435
00:17:12,209 --> 00:17:16,380
transactions so every transaction

436
00:17:14,400 --> 00:17:19,860
including the ones that are aborted and

437
00:17:16,380 --> 00:17:22,770
are incomplete must be be placed in a

438
00:17:19,859 --> 00:17:24,689
total order and this total order must

439
00:17:22,770 --> 00:17:28,170
appear like a sequential run of the same

440
00:17:24,690 --> 00:17:29,880
set of transactions so if you don't

441
00:17:28,170 --> 00:17:31,380
worry about aborted transactions it's

442
00:17:29,880 --> 00:17:32,790
this famous definition that I am sure

443
00:17:31,380 --> 00:17:34,290
all of you are familiar with from the

444
00:17:32,790 --> 00:17:36,060
database world which is strict

445
00:17:34,290 --> 00:17:37,710
serializability you can see realize all

446
00:17:36,060 --> 00:17:39,629
these transactions at least the

447
00:17:37,710 --> 00:17:41,460
committed ones without worrying about

448
00:17:39,630 --> 00:17:45,120
the state seen by the incomplete

449
00:17:41,460 --> 00:17:46,650
transactions so let's try and understand

450
00:17:45,120 --> 00:17:49,800
what this definition means because it's

451
00:17:46,650 --> 00:17:52,320
not immediate to follow so here you have

452
00:17:49,800 --> 00:17:53,250
a transaction t1 which is reading a data

453
00:17:52,320 --> 00:17:54,990
item X

454
00:17:53,250 --> 00:17:56,970
it's returning the initial value of this

455
00:17:54,990 --> 00:17:58,860
item let us say zero let us assume all

456
00:17:56,970 --> 00:18:01,710
data items have initial value zero and

457
00:17:58,860 --> 00:18:06,290
it's subsequently going to go ahead and

458
00:18:01,710 --> 00:18:09,030
read a data item why but imagine that

459
00:18:06,290 --> 00:18:12,060
before just after it reads the data item

460
00:18:09,030 --> 00:18:14,250
X there is a concurrent transaction t2

461
00:18:12,060 --> 00:18:17,700
which writes a value new value to this

462
00:18:14,250 --> 00:18:19,380
data item X and it commits so what this

463
00:18:17,700 --> 00:18:21,090
transaction has previously seen has been

464
00:18:19,380 --> 00:18:23,670
overwritten by a concurrent transaction

465
00:18:21,090 --> 00:18:26,070
and now I will schedule another

466
00:18:23,670 --> 00:18:30,330
transaction T 3 which is writing the

467
00:18:26,070 --> 00:18:33,000
data new value to this data item why now

468
00:18:30,330 --> 00:18:34,919
this transaction t1 is actually reading

469
00:18:33,000 --> 00:18:37,740
the state of the memory and it will see

470
00:18:34,920 --> 00:18:40,680
that the value of data item y is 1 and

471
00:18:37,740 --> 00:18:46,530
it is going to return this value what is

472
00:18:40,680 --> 00:18:49,350
the problem with this execution so the

473
00:18:46,530 --> 00:18:53,760
problem here is that the transactions t2

474
00:18:49,350 --> 00:18:56,820
and t3 happen one after the other so if

475
00:18:53,760 --> 00:19:00,000
i take transactions t1 t2 and t3 and

476
00:18:56,820 --> 00:19:01,919
place them in a total order this total

477
00:19:00,000 --> 00:19:03,930
order there must be a total order in

478
00:19:01,920 --> 00:19:07,050
which I can justify the response of

479
00:19:03,930 --> 00:19:09,870
transaction t1 which returns 0 from X

480
00:19:07,050 --> 00:19:13,409
and returns the new value for the data

481
00:19:09,870 --> 00:19:16,800
item y which is one so what can I do I

482
00:19:13,410 --> 00:19:20,430
can put transaction t2 and t3 before t1

483
00:19:16,800 --> 00:19:23,940
so if i put t2 and t3 before t1 i have a

484
00:19:20,430 --> 00:19:26,550
problem right so t2 happens before t1

485
00:19:23,940 --> 00:19:29,310
but then t1 never sees that new value of

486
00:19:26,550 --> 00:19:31,020
x has been updated in the membrane so i

487
00:19:29,310 --> 00:19:33,030
can never sort of totally order these

488
00:19:31,020 --> 00:19:37,680
transactions i always get a cycle in

489
00:19:33,030 --> 00:19:39,450
this piece of code so and this is the

490
00:19:37,680 --> 00:19:41,130
scenario even if this transaction t1

491
00:19:39,450 --> 00:19:43,020
aborts i don't care whether the bots are

492
00:19:41,130 --> 00:19:44,700
commits it still sees an inconsistent

493
00:19:43,020 --> 00:19:46,530
state a state that could not have been

494
00:19:44,700 --> 00:19:52,260
observed in a sequential run of

495
00:19:46,530 --> 00:19:54,660
transactions t1 t2 one t3 and as I said

496
00:19:52,260 --> 00:19:56,400
the equivalent sequential execution is

497
00:19:54,660 --> 00:19:59,700
to take these three transactions and

498
00:19:56,400 --> 00:20:01,950
place them in some total order so the if

499
00:19:59,700 --> 00:20:03,179
you try all possible ways all possible

500
00:20:01,950 --> 00:20:05,370
permutations are placing these

501
00:20:03,179 --> 00:20:07,110
transactions in this total order you see

502
00:20:05,370 --> 00:20:10,379
that all these permutations

503
00:20:07,110 --> 00:20:12,899
in a cycle a cycle which cannot justify

504
00:20:10,380 --> 00:20:15,360
the response is written by transaction

505
00:20:12,900 --> 00:20:18,030
t1 in any sequential run of this piece

506
00:20:15,360 --> 00:20:21,419
of code this is what we call a cycle in

507
00:20:18,030 --> 00:20:26,790
the serialization so this is an example

508
00:20:21,420 --> 00:20:31,440
of an execution which is not opaque so

509
00:20:26,790 --> 00:20:32,879
if you think about a a just

510
00:20:31,440 --> 00:20:35,190
serializability where you know

511
00:20:32,880 --> 00:20:36,780
transaction t1 is aborted it's not

512
00:20:35,190 --> 00:20:38,429
committed so in this case you're

513
00:20:36,780 --> 00:20:40,260
perfectly fine because you don't worry

514
00:20:38,429 --> 00:20:41,640
about the state seen by transaction t1

515
00:20:40,260 --> 00:20:44,790
which is actually aborted in this

516
00:20:41,640 --> 00:20:46,799
execution so now you can you just worry

517
00:20:44,790 --> 00:20:48,510
about transactions t2 and t3 no one is

518
00:20:46,799 --> 00:20:50,400
reading any state no committed

519
00:20:48,510 --> 00:20:52,830
transactions reading state so you just

520
00:20:50,400 --> 00:20:55,380
say it's utilizable but for all of us

521
00:20:52,830 --> 00:20:57,178
who write in memory transactions we look

522
00:20:55,380 --> 00:20:58,890
for these strong safety property which

523
00:20:57,179 --> 00:21:01,140
is opacity so you want the entire piece

524
00:20:58,890 --> 00:21:04,169
of code to be opaque in the sense that

525
00:21:01,140 --> 00:21:06,450
its privatisation safe so no transaction

526
00:21:04,169 --> 00:21:07,980
even the aborted ones can see a state

527
00:21:06,450 --> 00:21:09,540
which cannot be witnessed in a sequin

528
00:21:07,980 --> 00:21:11,820
children and if you think about it this

529
00:21:09,540 --> 00:21:14,129
is sort of obvious because once a

530
00:21:11,820 --> 00:21:16,649
transaction even if it may in the future

531
00:21:14,130 --> 00:21:18,030
eventually abort if it sees an

532
00:21:16,650 --> 00:21:19,679
inconsistent state as part of the

533
00:21:18,030 --> 00:21:22,230
program for instance the previous

534
00:21:19,679 --> 00:21:24,179
example it could end up doing a division

535
00:21:22,230 --> 00:21:26,429
by zero or running into an infinite loop

536
00:21:24,179 --> 00:21:28,380
and then you're stuck in this Eirik ooh

537
00:21:26,429 --> 00:21:35,040
this error from which you can't recover

538
00:21:28,380 --> 00:21:37,169
from so in this case you have

539
00:21:35,040 --> 00:21:40,200
transaction t1 which actually goes ahead

540
00:21:37,169 --> 00:21:42,270
and commit so in this case you would say

541
00:21:40,200 --> 00:21:44,760
that this execution is not when strictly

542
00:21:42,270 --> 00:21:46,260
serializable because now I even worry

543
00:21:44,760 --> 00:21:48,270
about the state seen by this committed

544
00:21:46,260 --> 00:21:54,330
transaction t1 and I still get that

545
00:21:48,270 --> 00:21:56,429
cycle in the serialization but of course

546
00:21:54,330 --> 00:21:57,720
safety alone is not enough right if

547
00:21:56,429 --> 00:21:59,669
you're in a distributed system a

548
00:21:57,720 --> 00:22:02,490
distributed system in which nothing ever

549
00:21:59,669 --> 00:22:04,679
works is trivially safe right we don't

550
00:22:02,490 --> 00:22:06,150
care about this so what you really want

551
00:22:04,679 --> 00:22:07,830
to ensure that that is progress in the

552
00:22:06,150 --> 00:22:09,390
system which is why we don't resort to

553
00:22:07,830 --> 00:22:11,820
the single log based solution right

554
00:22:09,390 --> 00:22:13,020
because it's trivially safe but it's

555
00:22:11,820 --> 00:22:16,020
never actually going to give you

556
00:22:13,020 --> 00:22:17,550
progress in the system so if every

557
00:22:16,020 --> 00:22:19,590
transaction are BOTS then it you are

558
00:22:17,550 --> 00:22:21,899
trivially safe you know who cares but

559
00:22:19,590 --> 00:22:24,299
you know that's really not good so you

560
00:22:21,900 --> 00:22:28,440
want to allow for as much concurrency as

561
00:22:24,299 --> 00:22:31,679
possible and ideally you want every

562
00:22:28,440 --> 00:22:32,909
transaction to eventually commit so they

563
00:22:31,679 --> 00:22:35,400
must be able to make progress in

564
00:22:32,909 --> 00:22:37,740
parallel and the goal of this talk is to

565
00:22:35,400 --> 00:22:39,720
basically understand what is this cost

566
00:22:37,740 --> 00:22:42,210
of concurrency are that these inherent

567
00:22:39,720 --> 00:22:46,740
limitations to building safe in memory

568
00:22:42,210 --> 00:22:48,330
transactions so if you just sort of take

569
00:22:46,740 --> 00:22:50,220
a step back in I want to give you a

570
00:22:48,330 --> 00:22:52,168
brief overview of the history of you

571
00:22:50,220 --> 00:22:54,480
know this programming model so it first

572
00:22:52,169 --> 00:22:56,850
came as a hardware abstraction in 1993

573
00:22:54,480 --> 00:23:01,020
as the modification to the instruction

574
00:22:56,850 --> 00:23:02,760
set architecture and this was by Herlihy

575
00:23:01,020 --> 00:23:05,279
in Moss where they essentially exploited

576
00:23:02,760 --> 00:23:07,350
the cache coherence protocol and gave a

577
00:23:05,279 --> 00:23:09,690
proposal for executing hardware

578
00:23:07,350 --> 00:23:12,360
transactions in memory but then this

579
00:23:09,690 --> 00:23:13,950
proposal died you know people made some

580
00:23:12,360 --> 00:23:15,840
proposals for a software transaction

581
00:23:13,950 --> 00:23:18,210
memory implementation which was static

582
00:23:15,840 --> 00:23:19,620
where you could specify the data items

583
00:23:18,210 --> 00:23:22,260
that you are trying to access atomically

584
00:23:19,620 --> 00:23:23,969
a priori and eventually you move to a

585
00:23:22,260 --> 00:23:26,220
more dynamic model which is what is

586
00:23:23,970 --> 00:23:27,570
prevalent today we're even if at the

587
00:23:26,220 --> 00:23:28,890
start of the transaction you don't know

588
00:23:27,570 --> 00:23:30,360
all the data items you are eventually

589
00:23:28,890 --> 00:23:33,630
going to access you can resolve these

590
00:23:30,360 --> 00:23:35,520
conflicts at runtime and now as I said

591
00:23:33,630 --> 00:23:37,760
we've moved towards this hybrid model

592
00:23:35,520 --> 00:23:40,950
and the main reason for that is that

593
00:23:37,760 --> 00:23:43,169
today's Intel chipsets if you buy the

594
00:23:40,950 --> 00:23:45,000
latest chipset today the Haswell chipset

595
00:23:43,169 --> 00:23:47,669
has support for in-memory hardware

596
00:23:45,000 --> 00:23:49,230
transactions and once Intel or one of

597
00:23:47,669 --> 00:23:51,210
these hardware manufacturers put these

598
00:23:49,230 --> 00:23:52,380
instructions in their instruction set

599
00:23:51,210 --> 00:23:54,990
architecture they don't take it out

600
00:23:52,380 --> 00:23:57,240
simply for backward compatibility so

601
00:23:54,990 --> 00:24:00,570
this model is here to say and what is

602
00:23:57,240 --> 00:24:02,039
important and what is even more good for

603
00:24:00,570 --> 00:24:04,950
people like me is that we don't yet know

604
00:24:02,039 --> 00:24:06,870
how to develop efficient use of this

605
00:24:04,950 --> 00:24:09,690
instruction set which is now given to us

606
00:24:06,870 --> 00:24:11,399
and as we as we will discover in this

607
00:24:09,690 --> 00:24:13,230
talk there are some inherent limitations

608
00:24:11,399 --> 00:24:14,428
we just can't overcome so we have to

609
00:24:13,230 --> 00:24:18,330
find ways to circumvent those

610
00:24:14,429 --> 00:24:20,250
limitations so the stock as i said is

611
00:24:18,330 --> 00:24:24,689
about this inherent limitations of these

612
00:24:20,250 --> 00:24:27,750
hybrid transactions so when I say

613
00:24:24,690 --> 00:24:30,090
hardware transaction memory all you have

614
00:24:27,750 --> 00:24:32,039
to imagine is a modification to the

615
00:24:30,090 --> 00:24:32,939
existing cache coherence protocol which

616
00:24:32,039 --> 00:24:35,250
has support for

617
00:24:32,940 --> 00:24:37,650
caching transactional state so you keep

618
00:24:35,250 --> 00:24:39,300
this additional state which is added as

619
00:24:37,650 --> 00:24:41,760
part of a transaction in some tracking

620
00:24:39,300 --> 00:24:43,350
set and when this tracking set gets

621
00:24:41,760 --> 00:24:44,910
invalidated you know that the hybrid

622
00:24:43,350 --> 00:24:46,770
transaction has incurred a conflict

623
00:24:44,910 --> 00:24:50,790
which means the transaction is going to

624
00:24:46,770 --> 00:24:52,860
abort so you get this consistency and

625
00:24:50,790 --> 00:24:54,540
safety and conflict detection for free

626
00:24:52,860 --> 00:24:56,520
as part of the hardware transaction and

627
00:24:54,540 --> 00:25:00,870
it appears to execute atomically in

628
00:24:56,520 --> 00:25:02,250
hardware so basically an extension to

629
00:25:00,870 --> 00:25:04,020
the cache Curren protocol and this is

630
00:25:02,250 --> 00:25:06,120
true of both the intel haswell chipset

631
00:25:04,020 --> 00:25:09,620
and the IBM blue jean q processors which

632
00:25:06,120 --> 00:25:12,300
also have hardware transactional support

633
00:25:09,620 --> 00:25:13,919
so you have this fast part transactions

634
00:25:12,300 --> 00:25:15,540
which are executed and ty lee in

635
00:25:13,920 --> 00:25:18,150
hardware which are exploiting cash

636
00:25:15,540 --> 00:25:20,670
currents but then as you can imagine

637
00:25:18,150 --> 00:25:22,020
anything which is executed purely in

638
00:25:20,670 --> 00:25:23,730
hardware comes with fundamental

639
00:25:22,020 --> 00:25:25,560
limitations and in this case because

640
00:25:23,730 --> 00:25:26,880
you're exploiting cash Goering's you're

641
00:25:25,560 --> 00:25:30,600
limited by the size of your cache

642
00:25:26,880 --> 00:25:33,060
hierarchy your cache line there is a you

643
00:25:30,600 --> 00:25:34,860
know anything executed in cash

644
00:25:33,060 --> 00:25:36,480
potentially has a very short lifetime

645
00:25:34,860 --> 00:25:38,729
you can't execute these very long

646
00:25:36,480 --> 00:25:40,170
running transactions because the process

647
00:25:38,730 --> 00:25:43,460
executing the transaction will be d

648
00:25:40,170 --> 00:25:45,900
schedule and you may simply get a boss

649
00:25:43,460 --> 00:25:47,550
due to these spurious reasons because

650
00:25:45,900 --> 00:25:48,960
there is some other piece of data in

651
00:25:47,550 --> 00:25:51,450
your cache line with whom you don't have

652
00:25:48,960 --> 00:25:52,980
any actual conflict but that's just

653
00:25:51,450 --> 00:25:54,450
going to be aborted because of another

654
00:25:52,980 --> 00:25:57,090
transitive transaction running

655
00:25:54,450 --> 00:25:59,580
concurrently and so you have all these

656
00:25:57,090 --> 00:26:01,379
problems with running transactions in

657
00:25:59,580 --> 00:26:03,510
hardware you can't just expect to run

658
00:26:01,380 --> 00:26:06,750
everything in hardware and have

659
00:26:03,510 --> 00:26:09,780
everything running safely and fast which

660
00:26:06,750 --> 00:26:11,520
is why we exploit the need for a slow

661
00:26:09,780 --> 00:26:13,950
path in which we execute the same

662
00:26:11,520 --> 00:26:16,639
transaction purely in software as as a

663
00:26:13,950 --> 00:26:19,200
piece as just a piece of data structure

664
00:26:16,640 --> 00:26:21,450
this is typically for these long running

665
00:26:19,200 --> 00:26:23,760
hardware transactions in the cloud you

666
00:26:21,450 --> 00:26:26,280
know as you can imagine which is fairly

667
00:26:23,760 --> 00:26:28,050
more reliable but then it's much slower

668
00:26:26,280 --> 00:26:30,180
in execution time obviously right

669
00:26:28,050 --> 00:26:32,580
because you're not executing it in

670
00:26:30,180 --> 00:26:34,200
hardware and the interleaving of these

671
00:26:32,580 --> 00:26:37,110
two hardware and software transactions

672
00:26:34,200 --> 00:26:38,490
make it very hard for us to verify so

673
00:26:37,110 --> 00:26:40,229
for the purpose of the stock I will call

674
00:26:38,490 --> 00:26:42,390
the hardware transaction the fastback

675
00:26:40,230 --> 00:26:44,400
and the software transactions are slow

676
00:26:42,390 --> 00:26:48,070
path

677
00:26:44,400 --> 00:26:50,290
so as part of this model you have these

678
00:26:48,070 --> 00:26:52,360
direct accesses and cached accesses in

679
00:26:50,290 --> 00:26:54,639
which the slope a transaction directly

680
00:26:52,360 --> 00:26:56,469
modifies the memory and the hardware

681
00:26:54,640 --> 00:26:59,290
transaction basically caches everything

682
00:26:56,470 --> 00:27:01,450
and puts it into his tracking set of

683
00:26:59,290 --> 00:27:02,980
cash currents in order to be able to

684
00:27:01,450 --> 00:27:05,290
invalidate whether a memory location

685
00:27:02,980 --> 00:27:07,299
previously accessed or written was

686
00:27:05,290 --> 00:27:09,610
concurrently updated or read by a

687
00:27:07,299 --> 00:27:14,470
concurrent transaction in which case you

688
00:27:09,610 --> 00:27:16,750
get automatic conflict detection as I

689
00:27:14,470 --> 00:27:18,250
say for slope at Apple or transactions

690
00:27:16,750 --> 00:27:20,200
they operate directly on the memory

691
00:27:18,250 --> 00:27:22,419
state so it's what we call direct access

692
00:27:20,200 --> 00:27:24,040
and these fast pad transactions

693
00:27:22,419 --> 00:27:26,080
basically put everything in this

694
00:27:24,040 --> 00:27:27,580
tracking set and like in any cache

695
00:27:26,080 --> 00:27:29,949
coherence protocol there's a shared and

696
00:27:27,580 --> 00:27:31,540
exclusive state so if you just want to

697
00:27:29,950 --> 00:27:33,970
read something you just put it in Schad

698
00:27:31,540 --> 00:27:36,190
mode in which only if it's concurrently

699
00:27:33,970 --> 00:27:37,540
updated the hardware transaction fails

700
00:27:36,190 --> 00:27:39,250
but if you're writing something

701
00:27:37,540 --> 00:27:41,139
obviously even if concurrently someone

702
00:27:39,250 --> 00:27:46,390
reads it the hardware transaction is

703
00:27:41,140 --> 00:27:48,700
about it yes so the slow path is

704
00:27:46,390 --> 00:27:51,669
essentially a transaction which is

705
00:27:48,700 --> 00:27:53,860
implemented purely in software so the

706
00:27:51,669 --> 00:27:55,330
fast path is one which in which you

707
00:27:53,860 --> 00:27:57,010
directly use the instruction set

708
00:27:55,330 --> 00:28:09,250
extension which is provided by the

709
00:27:57,010 --> 00:28:11,950
chipset sorry please use your phone okay

710
00:28:09,250 --> 00:28:14,410
so my question is with the cache

711
00:28:11,950 --> 00:28:17,380
coherence protocols in place in the

712
00:28:14,410 --> 00:28:18,760
hardware light to my solos in place I'm

713
00:28:17,380 --> 00:28:20,980
not understanding with the differences

714
00:28:18,760 --> 00:28:23,200
between these so you have a card

715
00:28:20,980 --> 00:28:25,299
transaction which in which you execute

716
00:28:23,200 --> 00:28:27,880
everything using cash codons that's what

717
00:28:25,299 --> 00:28:29,710
I call fast path all right and slow path

718
00:28:27,880 --> 00:28:30,970
is one when you don't use cash codons

719
00:28:29,710 --> 00:28:33,370
and you write the piece of code

720
00:28:30,970 --> 00:28:35,049
explicitly like any other algorithm so

721
00:28:33,370 --> 00:28:36,520
you're writing directly to my exam okay

722
00:28:35,049 --> 00:28:41,679
so that's what i call it the red state

723
00:28:36,520 --> 00:28:43,450
and cashed it thank so you have these

724
00:28:41,679 --> 00:28:44,830
tracking set of bots in fast part

725
00:28:43,450 --> 00:28:46,600
transactions because you're working

726
00:28:44,830 --> 00:28:48,939
directly with cash coincide you get this

727
00:28:46,600 --> 00:28:50,949
automatic contention detection if

728
00:28:48,940 --> 00:28:54,070
someone concurrently accesses the cash

729
00:28:50,950 --> 00:28:56,440
state so in this case you have a fast

730
00:28:54,070 --> 00:28:57,770
per transaction t2 which is writing to a

731
00:28:56,440 --> 00:28:59,990
base object B which

732
00:28:57,770 --> 00:29:03,260
this object can be cashed in exclusive

733
00:28:59,990 --> 00:29:05,510
mode and now if you have a concurrent

734
00:29:03,260 --> 00:29:07,760
any transaction which is even accessing

735
00:29:05,510 --> 00:29:09,379
this memory location then automatically

736
00:29:07,760 --> 00:29:12,290
you know that the fast part transaction

737
00:29:09,380 --> 00:29:13,850
t2 will be aborted as opposed to

738
00:29:12,290 --> 00:29:16,460
designing it in slope at that you have

739
00:29:13,850 --> 00:29:17,870
to explicitly validate this so this is

740
00:29:16,460 --> 00:29:21,710
the advantage when you are exploiting

741
00:29:17,870 --> 00:29:23,419
the high-back cash codons explicitly so

742
00:29:21,710 --> 00:29:25,070
the tracking set is invalidated and you

743
00:29:23,420 --> 00:29:29,980
know that this fast part transaction t2

744
00:29:25,070 --> 00:29:32,179
will abort without violating safety and

745
00:29:29,980 --> 00:29:33,830
similarly if you have a Fastback

746
00:29:32,180 --> 00:29:36,110
transaction t2 which is simply reading

747
00:29:33,830 --> 00:29:38,030
this memory location it's accessed in

748
00:29:36,110 --> 00:29:40,370
shad mode and if a concurrent

749
00:29:38,030 --> 00:29:42,260
transaction simply rights to it only

750
00:29:40,370 --> 00:29:45,020
then is the fast part transaction t2

751
00:29:42,260 --> 00:29:48,770
invalidated and in this case it is going

752
00:29:45,020 --> 00:29:51,170
to abort so if you if you envision it

753
00:29:48,770 --> 00:29:53,540
the hardware gives you all this safety

754
00:29:51,170 --> 00:29:55,280
properties for free in essence the

755
00:29:53,540 --> 00:29:57,260
software doesn't in software you

756
00:29:55,280 --> 00:30:00,230
explicitly have to write code to detect

757
00:29:57,260 --> 00:30:02,360
this but the trade-off here is that the

758
00:30:00,230 --> 00:30:04,520
heart the fasts per transaction is going

759
00:30:02,360 --> 00:30:06,649
to fail most of the times and you can't

760
00:30:04,520 --> 00:30:08,389
actually give any provable guarantees on

761
00:30:06,650 --> 00:30:09,500
when this hardware transaction or the

762
00:30:08,390 --> 00:30:11,030
fast part transaction is going to

763
00:30:09,500 --> 00:30:13,040
succeed which is why you try to

764
00:30:11,030 --> 00:30:14,660
re-execute that same piece of code in

765
00:30:13,040 --> 00:30:16,760
the failed hardware transaction in

766
00:30:14,660 --> 00:30:20,110
software which is what we call the

767
00:30:16,760 --> 00:30:20,110
hybrid model now yes

768
00:30:31,350 --> 00:30:36,039
well this is down to how you implement

769
00:30:33,880 --> 00:30:37,750
this hybrid implementation so there are

770
00:30:36,039 --> 00:30:40,570
different implementation strategies but

771
00:30:37,750 --> 00:30:42,250
the most basic strategy is you try the

772
00:30:40,570 --> 00:30:43,899
piece of code as a hardware transaction

773
00:30:42,250 --> 00:30:46,019
for X number of times typically a

774
00:30:43,899 --> 00:30:50,080
threshold which people have estimated

775
00:30:46,019 --> 00:30:51,460
purely by experiments and if you fail

776
00:30:50,080 --> 00:30:53,320
after these subsequent number of

777
00:30:51,460 --> 00:30:55,720
thresholds you execute that same piece

778
00:30:53,320 --> 00:30:57,189
of code as a software transaction but

779
00:30:55,720 --> 00:31:00,039
what is important from the point of view

780
00:30:57,190 --> 00:31:02,679
is of safety is that you can imagine at

781
00:31:00,039 --> 00:31:04,480
any step in the execution that there are

782
00:31:02,679 --> 00:31:06,519
hardware and software transactions

783
00:31:04,480 --> 00:31:07,990
running concurrently which for some

784
00:31:06,519 --> 00:31:09,909
reason are trying to access the same

785
00:31:07,990 --> 00:31:11,889
memory location and both of them have

786
00:31:09,909 --> 00:31:14,769
different mechanisms for detecting

787
00:31:11,889 --> 00:31:16,539
safety violations the inherent challenge

788
00:31:14,769 --> 00:31:18,130
for us in the hybrid model is how do you

789
00:31:16,539 --> 00:31:24,929
detect it and what is that cost of

790
00:31:18,130 --> 00:31:27,399
detecting the safety violations yes I

791
00:31:24,929 --> 00:31:30,730
have a question in the previous slide we

792
00:31:27,399 --> 00:31:34,449
say that if t2 cannot be concurrently

793
00:31:30,730 --> 00:31:36,519
executed with t1 then as you said t2

794
00:31:34,450 --> 00:31:39,940
will try a couple of times and then

795
00:31:36,519 --> 00:31:42,250
we'll will switch to the software mode

796
00:31:39,940 --> 00:31:44,980
yes but it's not guaranteed that in

797
00:31:42,250 --> 00:31:47,980
software mod t2 and t1 won't have a

798
00:31:44,980 --> 00:31:49,840
conflict it's not guaranteed yes I'm not

799
00:31:47,980 --> 00:31:52,630
we're not guaranteeing eventual commit

800
00:31:49,840 --> 00:31:54,850
we are only guaranteeing some sort of

801
00:31:52,630 --> 00:31:57,370
progress progress which basically says

802
00:31:54,850 --> 00:31:58,840
if eventually there is no conflict maybe

803
00:31:57,370 --> 00:32:00,250
you will come it but I haven't yet gone

804
00:31:58,840 --> 00:32:03,840
into the details of this process we are

805
00:32:00,250 --> 00:32:03,840
still concentrating on safety right now

806
00:32:04,019 --> 00:32:09,190
so in this case you know what is

807
00:32:07,690 --> 00:32:11,500
important for us to take away is that

808
00:32:09,190 --> 00:32:13,720
the fast part transactions they appear

809
00:32:11,500 --> 00:32:15,639
to execute atomic so they just happen in

810
00:32:13,720 --> 00:32:18,039
this one single indivisible point in

811
00:32:15,639 --> 00:32:20,439
time and it's up to the software

812
00:32:18,039 --> 00:32:21,970
transactions to detect this so in this

813
00:32:20,440 --> 00:32:23,830
case you have this fast per transaction

814
00:32:21,970 --> 00:32:25,960
t2 it's you know either aborted or

815
00:32:23,830 --> 00:32:28,510
incomplete in which case the concurrent

816
00:32:25,960 --> 00:32:30,309
slope a transaction will assume that

817
00:32:28,510 --> 00:32:32,230
it's actually running alone because it

818
00:32:30,309 --> 00:32:34,600
just does not see this concurrent fast

819
00:32:32,230 --> 00:32:36,370
path transaction it only sees it when

820
00:32:34,600 --> 00:32:41,340
the fast part transaction actually

821
00:32:36,370 --> 00:32:41,340
succeeds and

822
00:32:41,440 --> 00:32:44,799
similarly the case when you know the

823
00:32:43,360 --> 00:32:46,299
other transaction is a fast by

824
00:32:44,799 --> 00:32:47,830
transaction right it's only when the

825
00:32:46,299 --> 00:32:50,200
fast part transaction actually commits

826
00:32:47,830 --> 00:32:52,299
is that state actually reflected in the

827
00:32:50,200 --> 00:32:54,519
system configuration if it's incomplete

828
00:32:52,299 --> 00:32:56,049
or if it is aborted the state never is

829
00:32:54,519 --> 00:32:57,580
reflected in the system configuration

830
00:32:56,049 --> 00:32:59,559
it's like that transaction never took

831
00:32:57,580 --> 00:33:00,908
place which is the most important thing

832
00:32:59,559 --> 00:33:02,918
for us for safety right you need this

833
00:33:00,909 --> 00:33:07,110
all-or-nothing semantics either

834
00:33:02,919 --> 00:33:07,110
everything happened or nothing happened

835
00:33:07,169 --> 00:33:12,159
but what is it what is the problem here

836
00:33:09,789 --> 00:33:14,799
so the problem here is that you can't

837
00:33:12,159 --> 00:33:17,710
just use the fast part transaction the

838
00:33:14,799 --> 00:33:19,299
hardware transaction just explicit loads

839
00:33:17,710 --> 00:33:21,399
and stores and the memory locations that

840
00:33:19,299 --> 00:33:23,710
you are trying to do right so you need

841
00:33:21,399 --> 00:33:26,500
to explicitly instrument the hardware

842
00:33:23,710 --> 00:33:29,830
transaction code to detect additional

843
00:33:26,500 --> 00:33:31,750
metadata what do I mean by this you need

844
00:33:29,830 --> 00:33:33,340
to be able to know that there is a

845
00:33:31,750 --> 00:33:35,590
concurrent slope our transaction which

846
00:33:33,340 --> 00:33:36,759
for some reason is very slow right but

847
00:33:35,590 --> 00:33:38,709
you need to be able to detect this

848
00:33:36,759 --> 00:33:41,110
because if a slow part transaction

849
00:33:38,710 --> 00:33:43,120
starts but not yet finishes and then a

850
00:33:41,110 --> 00:33:44,649
Fastback transaction comes and like in

851
00:33:43,120 --> 00:33:46,830
the example that we saw it reads a

852
00:33:44,649 --> 00:33:49,479
partial state then you have a problem

853
00:33:46,830 --> 00:33:51,490
now the question for us is how much do

854
00:33:49,480 --> 00:33:53,350
we have to instrument the hardware

855
00:33:51,490 --> 00:33:55,210
transaction because more instrumentation

856
00:33:53,350 --> 00:33:57,189
means that you're adding more into your

857
00:33:55,210 --> 00:33:59,110
cache line you add more into your cache

858
00:33:57,190 --> 00:34:01,299
line that is the more chance of a boat's

859
00:33:59,110 --> 00:34:07,600
the more chance of a boat's lesser

860
00:34:01,299 --> 00:34:10,119
performance so here's a simple example

861
00:34:07,600 --> 00:34:11,889
which I was alluding to so you have a

862
00:34:10,119 --> 00:34:13,990
slope our transaction now remember this

863
00:34:11,889 --> 00:34:16,389
is not atomic right so this is trying to

864
00:34:13,989 --> 00:34:18,578
write to memory locations x and y but

865
00:34:16,389 --> 00:34:19,780
it's in a partial commit state it's just

866
00:34:18,579 --> 00:34:22,030
that the process executing the

867
00:34:19,780 --> 00:34:23,679
transaction is very slow because we are

868
00:34:22,030 --> 00:34:25,990
in an asynchronous world right they are

869
00:34:23,679 --> 00:34:27,819
inside a multi-core machine there is no

870
00:34:25,989 --> 00:34:30,489
bound on when these processes are going

871
00:34:27,819 --> 00:34:32,560
to take steps in fact by asynchrony here

872
00:34:30,489 --> 00:34:34,839
I mean there is no concept of time there

873
00:34:32,560 --> 00:34:35,918
is only causality so you know something

874
00:34:34,839 --> 00:34:38,619
is change only when the system

875
00:34:35,918 --> 00:34:40,089
configuration changes so in this case

876
00:34:38,619 --> 00:34:42,399
you have the slow part transaction which

877
00:34:40,089 --> 00:34:44,980
is in this partial come at stage and it

878
00:34:42,399 --> 00:34:47,828
just sleeps right it's got d scheduled

879
00:34:44,980 --> 00:34:49,949
or whatever and now I bring this fast by

880
00:34:47,829 --> 00:34:52,119
transaction which is trying to read X

881
00:34:49,949 --> 00:34:54,219
now at this point this fast by

882
00:34:52,119 --> 00:34:54,580
transaction which is just doing a load

883
00:34:54,219 --> 00:34:56,980
to the

884
00:34:54,580 --> 00:34:59,410
memory has to make a decision on whether

885
00:34:56,980 --> 00:35:01,090
it is going to read this partial state

886
00:34:59,410 --> 00:35:02,410
in the hope that the slope our

887
00:35:01,090 --> 00:35:04,210
transaction will eventually commit

888
00:35:02,410 --> 00:35:06,970
because if it does not commit it it

889
00:35:04,210 --> 00:35:10,810
could not have read this state and if it

890
00:35:06,970 --> 00:35:13,209
did commit there is no guarantee i mean

891
00:35:10,810 --> 00:35:14,650
there is no guarantee for this first

892
00:35:13,210 --> 00:35:16,330
part transaction t1 that is actually

893
00:35:14,650 --> 00:35:18,400
going to commit at that point so the

894
00:35:16,330 --> 00:35:20,110
best thing it must it can do is to be

895
00:35:18,400 --> 00:35:21,760
able to instrument you know you can

896
00:35:20,110 --> 00:35:23,890
instrument these loads with an

897
00:35:21,760 --> 00:35:25,720
additional metadata which you can force

898
00:35:23,890 --> 00:35:28,210
the slow part transactions to also write

899
00:35:25,720 --> 00:35:29,500
to indicate that look I'm in a partial

900
00:35:28,210 --> 00:35:31,480
commit state I haven't yet fully

901
00:35:29,500 --> 00:35:33,820
completed my transaction which allows

902
00:35:31,480 --> 00:35:35,200
the fast part transaction to detect the

903
00:35:33,820 --> 00:35:38,350
presence of this concurrent slope a

904
00:35:35,200 --> 00:35:40,120
transaction and in fact what you can

905
00:35:38,350 --> 00:35:43,060
show is that even if you need some very

906
00:35:40,120 --> 00:35:45,790
basic progress right you commit only if

907
00:35:43,060 --> 00:35:47,529
there is no concurrency even if you want

908
00:35:45,790 --> 00:35:50,110
some property like this you need

909
00:35:47,530 --> 00:35:51,520
instrumentation and i will quickly go

910
00:35:50,110 --> 00:35:53,470
through this example in fact what it

911
00:35:51,520 --> 00:35:55,690
says is that you need some amount of

912
00:35:53,470 --> 00:35:59,230
instrumentation in your hardware

913
00:35:55,690 --> 00:36:02,230
transactions so with the same example

914
00:35:59,230 --> 00:36:04,690
now imagine you first read a data item Z

915
00:36:02,230 --> 00:36:06,130
you return the initial value and then

916
00:36:04,690 --> 00:36:08,470
you write you are trying to write to x

917
00:36:06,130 --> 00:36:10,450
and y right you bring it to this partial

918
00:36:08,470 --> 00:36:15,819
commit when x and y x is committed but

919
00:36:10,450 --> 00:36:18,009
not yet why and now you can force a new

920
00:36:15,820 --> 00:36:19,840
fast part transaction which comes later

921
00:36:18,010 --> 00:36:21,550
this the time line goes from left to

922
00:36:19,840 --> 00:36:23,230
right here okay you need to envision it

923
00:36:21,550 --> 00:36:25,150
from left to right time flowing that way

924
00:36:23,230 --> 00:36:28,480
so the slope our transaction is just

925
00:36:25,150 --> 00:36:30,070
slow literally it stops after a partial

926
00:36:28,480 --> 00:36:33,310
commit and then it takes one more step

927
00:36:30,070 --> 00:36:34,900
and then if the phosphor transaction

928
00:36:33,310 --> 00:36:38,529
comes and reads why it returns the new

929
00:36:34,900 --> 00:36:40,330
value so far so good but then what can

930
00:36:38,530 --> 00:36:42,400
happen is that if the code is uninst

931
00:36:40,330 --> 00:36:44,860
romentic from the fast path side I can

932
00:36:42,400 --> 00:36:47,260
insert another fast part transaction T 3

933
00:36:44,860 --> 00:36:49,180
here which is reading X but at this

934
00:36:47,260 --> 00:36:50,920
point x is not yet been reflected in the

935
00:36:49,180 --> 00:36:54,910
system state so it just returns the

936
00:36:50,920 --> 00:36:56,590
initial value and now I can insert

937
00:36:54,910 --> 00:36:58,960
another fast part transaction which is

938
00:36:56,590 --> 00:37:00,750
writing one to Z and this all this

939
00:36:58,960 --> 00:37:03,880
transaction also goes ahead and commits

940
00:37:00,750 --> 00:37:06,370
so you see that i have transaction T 0

941
00:37:03,880 --> 00:37:08,170
which is reading an old value of Z it's

942
00:37:06,370 --> 00:37:10,058
partially committed to x and y

943
00:37:08,170 --> 00:37:11,859
and then i have three phase power

944
00:37:10,059 --> 00:37:13,390
transactions which are uninst romentic

945
00:37:11,859 --> 00:37:16,240
they do not see the presence of this

946
00:37:13,390 --> 00:37:19,390
concurrent slow part transaction they

947
00:37:16,240 --> 00:37:21,129
just see the system state and the one of

948
00:37:19,390 --> 00:37:23,950
them returns the old value and the other

949
00:37:21,130 --> 00:37:26,290
returns the new value what is the

950
00:37:23,950 --> 00:37:31,419
problem is this a safe execution of this

951
00:37:26,290 --> 00:37:33,430
concurrent program and the answer is no

952
00:37:31,420 --> 00:37:35,650
because I know that the slope a

953
00:37:33,430 --> 00:37:37,480
transaction must commit right I must

954
00:37:35,650 --> 00:37:38,770
treated as committed because there is a

955
00:37:37,480 --> 00:37:44,109
fast per transaction which actually

956
00:37:38,770 --> 00:37:45,750
return this value but in this case there

957
00:37:44,109 --> 00:37:48,339
will be a cycle in the serialization

958
00:37:45,750 --> 00:37:51,599
because the only way I can justify this

959
00:37:48,339 --> 00:37:54,578
in any sequential run is that I place

960
00:37:51,599 --> 00:37:59,680
transactions t1 and t3 before

961
00:37:54,579 --> 00:38:02,440
transaction T 0 why because transaction

962
00:37:59,680 --> 00:38:03,819
t3 returns the old value of x so it must

963
00:38:02,440 --> 00:38:07,359
appear to have happened before

964
00:38:03,819 --> 00:38:08,650
transaction T 0 but if transaction t3

965
00:38:07,359 --> 00:38:11,859
appear to have happened before

966
00:38:08,650 --> 00:38:13,030
transaction t0 even transaction t1 must

967
00:38:11,859 --> 00:38:16,150
appear to have happened before

968
00:38:13,030 --> 00:38:18,849
transaction T 3 but if transaction t1

969
00:38:16,150 --> 00:38:22,359
which writes a new value to Z and

970
00:38:18,849 --> 00:38:26,650
commits this value must be seen when

971
00:38:22,359 --> 00:38:28,660
transaction t0 actually try to read Z so

972
00:38:26,650 --> 00:38:31,089
you see there is no way I can place

973
00:38:28,660 --> 00:38:33,910
these four transactions in one total

974
00:38:31,089 --> 00:38:41,470
order which will justify the response of

975
00:38:33,910 --> 00:38:43,029
x y and z was that clear and what this

976
00:38:41,470 --> 00:38:44,740
really tells us is that you must

977
00:38:43,030 --> 00:38:46,780
instrument the hardware transaction and

978
00:38:44,740 --> 00:38:49,058
this is where a lot of our overhead

979
00:38:46,780 --> 00:38:50,650
comes in and in fact this is even for

980
00:38:49,059 --> 00:38:52,990
some very weak progress like sequential

981
00:38:50,650 --> 00:38:55,569
so ideally what you want to say is that

982
00:38:52,990 --> 00:38:57,879
only if let's say you're inserting and

983
00:38:55,569 --> 00:39:00,970
removing into a list right so if you are

984
00:38:57,880 --> 00:39:02,290
inserting one and removing five right

985
00:39:00,970 --> 00:39:04,359
there are these two three and four in

986
00:39:02,290 --> 00:39:06,250
the middle there's no real conflict in

987
00:39:04,359 --> 00:39:07,839
this scenario right so ideally you

988
00:39:06,250 --> 00:39:09,520
expect the two transactions which are

989
00:39:07,839 --> 00:39:11,500
inserting one and removing fight to run

990
00:39:09,520 --> 00:39:13,690
concurrently without any conflict on the

991
00:39:11,500 --> 00:39:15,609
membrane this would be the ideal

992
00:39:13,690 --> 00:39:17,500
progress guarantee for us or something

993
00:39:15,609 --> 00:39:20,230
realistic this is what we would call

994
00:39:17,500 --> 00:39:21,119
progressive so sequential here being you

995
00:39:20,230 --> 00:39:22,710
know you just

996
00:39:21,119 --> 00:39:24,240
due to a concurrent transaction and even

997
00:39:22,710 --> 00:39:26,789
in this case you need instrumentation

998
00:39:24,240 --> 00:39:29,220
and progressive would be only there is a

999
00:39:26,789 --> 00:39:32,039
real read/write conflict on the data

1000
00:39:29,220 --> 00:39:34,439
items that you're accessing and in fact

1001
00:39:32,039 --> 00:39:37,380
what we can show is that even in this

1002
00:39:34,440 --> 00:39:38,609
progressive case I mean of course even

1003
00:39:37,380 --> 00:39:40,710
in the sequential case you have this

1004
00:39:38,609 --> 00:39:41,848
instrumentation that you must incur but

1005
00:39:40,710 --> 00:39:43,440
in the progressive case you actually

1006
00:39:41,849 --> 00:39:45,839
have a linear amount of instrumentation

1007
00:39:43,440 --> 00:39:48,089
that you need to incur so for each

1008
00:39:45,839 --> 00:39:49,288
memory location that you access you need

1009
00:39:48,089 --> 00:39:51,089
to access an additional piece of

1010
00:39:49,289 --> 00:39:53,819
metadata that you must plays into your

1011
00:39:51,089 --> 00:39:56,369
tracking set and cache line and this is

1012
00:39:53,819 --> 00:39:58,589
a huge overhead and a huge step back for

1013
00:39:56,369 --> 00:40:00,869
us when really designing hybrid

1014
00:39:58,589 --> 00:40:02,700
transactions because you just aren't

1015
00:40:00,869 --> 00:40:05,039
going to get sufficiently good enough

1016
00:40:02,700 --> 00:40:06,839
performance to justify the application

1017
00:40:05,039 --> 00:40:09,509
developer to migrate from legacy log

1018
00:40:06,839 --> 00:40:13,970
based code which has been working for 20

1019
00:40:09,509 --> 00:40:13,970
30 years to this new programming model

1020
00:40:14,539 --> 00:40:20,029
so the real cost now is that these fast

1021
00:40:17,609 --> 00:40:22,410
part transactions may be aborted even by

1022
00:40:20,029 --> 00:40:24,960
slope our transactions which are not

1023
00:40:22,410 --> 00:40:28,499
conflicting at all with you and you

1024
00:40:24,960 --> 00:40:31,019
still suffer because of this because

1025
00:40:28,499 --> 00:40:33,029
there is no real progress now but if you

1026
00:40:31,019 --> 00:40:35,069
do need some progress then you have to

1027
00:40:33,029 --> 00:40:37,109
incur this linear instrumentation cost

1028
00:40:35,069 --> 00:40:39,269
of placing more stuff into your cache

1029
00:40:37,109 --> 00:40:41,910
line now whether this experimentally

1030
00:40:39,269 --> 00:40:44,488
translates in terms of real performance

1031
00:40:41,910 --> 00:40:46,890
in terms of overhead to your concurrent

1032
00:40:44,489 --> 00:40:49,259
code this is up for debate this depends

1033
00:40:46,890 --> 00:40:50,879
entirely on the cache hierarchy the size

1034
00:40:49,259 --> 00:40:54,779
of the cache line so many other

1035
00:40:50,880 --> 00:40:58,950
parameters but what about the cost in

1036
00:40:54,779 --> 00:41:00,569
the slow path and what we can show is

1037
00:40:58,950 --> 00:41:04,499
that even the slow part incurs a

1038
00:41:00,569 --> 00:41:06,210
significant cost so what will happen is

1039
00:41:04,499 --> 00:41:09,749
that the fast car transaction may be

1040
00:41:06,210 --> 00:41:11,039
aborted by non-conflicting once or the

1041
00:41:09,749 --> 00:41:13,649
fast part incurs this linear

1042
00:41:11,039 --> 00:41:15,779
instrumentation cost but even the slow

1043
00:41:13,650 --> 00:41:19,349
path will have to continuously validate

1044
00:41:15,779 --> 00:41:22,529
itself whatever it reads let's try and

1045
00:41:19,349 --> 00:41:24,239
look at an example for this so what you

1046
00:41:22,529 --> 00:41:25,619
actually have even for the slow part is

1047
00:41:24,239 --> 00:41:29,249
that if you want this you know

1048
00:41:25,619 --> 00:41:31,170
progressive property you know you're

1049
00:41:29,249 --> 00:41:33,058
going to incur this validation cost you

1050
00:41:31,170 --> 00:41:34,740
know each time you read something you

1051
00:41:33,059 --> 00:41:36,960
must go back and check

1052
00:41:34,740 --> 00:41:41,759
if whatever you read before has not been

1053
00:41:36,960 --> 00:41:43,650
changed since which is intuitive so

1054
00:41:41,760 --> 00:41:45,720
imagine here that you have this

1055
00:41:43,650 --> 00:41:47,700
transaction p.m. which is writing a

1056
00:41:45,720 --> 00:41:49,740
value 1 2 X this is a fast part

1057
00:41:47,700 --> 00:41:52,649
transaction this transaction will go

1058
00:41:49,740 --> 00:41:54,390
ahead and commit and now imagine you

1059
00:41:52,650 --> 00:41:56,369
have a long-running transaction right

1060
00:41:54,390 --> 00:41:57,750
imagine you searching through an Amazon

1061
00:41:56,369 --> 00:42:00,150
database or anything one of these

1062
00:41:57,750 --> 00:42:03,360
transactions you're reading you know em

1063
00:42:00,150 --> 00:42:06,210
distinct data items so you want to get

1064
00:42:03,360 --> 00:42:07,920
the value of them so you read x1 to xn

1065
00:42:06,210 --> 00:42:11,310
minus 1 and you get the initial value

1066
00:42:07,920 --> 00:42:13,650
and then you read XM and you see that

1067
00:42:11,310 --> 00:42:15,270
the state the memory was is no longer

1068
00:42:13,650 --> 00:42:17,070
the initial state and you return the

1069
00:42:15,270 --> 00:42:19,080
value 1 so this is a slow part

1070
00:42:17,070 --> 00:42:25,440
transaction it doesn't exploit cash

1071
00:42:19,080 --> 00:42:27,240
codons so you have these weeds which are

1072
00:42:25,440 --> 00:42:29,940
pretty much invisible right leads don't

1073
00:42:27,240 --> 00:42:32,009
modify the memory at least ideally we

1074
00:42:29,940 --> 00:42:36,180
wouldn't expect the read implementation

1075
00:42:32,010 --> 00:42:38,160
to modify the state of the memory and as

1076
00:42:36,180 --> 00:42:39,629
you can imagine this read of XM must

1077
00:42:38,160 --> 00:42:42,029
actually written one this cannot return

1078
00:42:39,630 --> 00:42:45,980
0 right because a previous transaction

1079
00:42:42,030 --> 00:42:49,619
change the state of this memory of XM

1080
00:42:45,980 --> 00:42:52,080
now if you move that fast by transaction

1081
00:42:49,619 --> 00:42:54,840
to run after the read of XM minus 1 and

1082
00:42:52,080 --> 00:42:59,160
concurrently with XM this read of XM

1083
00:42:54,840 --> 00:43:03,720
will still return 1 right because it

1084
00:42:59,160 --> 00:43:06,839
can't distinguish the two scenarios so

1085
00:43:03,720 --> 00:43:09,330
first n minus 1 data items returned the

1086
00:43:06,840 --> 00:43:15,900
initial value the nth data item returns

1087
00:43:09,330 --> 00:43:18,330
this new value but what if there is a

1088
00:43:15,900 --> 00:43:21,000
concurrent transaction which is writing

1089
00:43:18,330 --> 00:43:28,170
to x1 after x1 has been read by

1090
00:43:21,000 --> 00:43:30,090
transaction T 0 now this read of XM as

1091
00:43:28,170 --> 00:43:34,230
part of the transactional implementation

1092
00:43:30,090 --> 00:43:37,080
has to make a choice so it has three

1093
00:43:34,230 --> 00:43:39,450
options one is that this transaction

1094
00:43:37,080 --> 00:43:40,710
aborts the reader bots it just does not

1095
00:43:39,450 --> 00:43:43,439
return a value and say is that this

1096
00:43:40,710 --> 00:43:46,890
transaction field the other is that it

1097
00:43:43,440 --> 00:43:48,120
runs 0 the initial value of x 1 XM or it

1098
00:43:46,890 --> 00:43:49,680
returns 1 which is the

1099
00:43:48,120 --> 00:43:55,200
new value written by a concurrent fast

1100
00:43:49,680 --> 00:43:59,190
part front section so what must it do to

1101
00:43:55,200 --> 00:44:01,230
detect this scenario so in this case

1102
00:43:59,190 --> 00:44:04,140
this slope a transaction espera ser

1103
00:44:01,230 --> 00:44:06,270
implementation must go back and read the

1104
00:44:04,140 --> 00:44:07,620
state of the memory of the previous

1105
00:44:06,270 --> 00:44:09,120
transactions that have been read to

1106
00:44:07,620 --> 00:44:12,930
check if they haven't been invalidated

1107
00:44:09,120 --> 00:44:15,120
so in this case transaction T 0 when it

1108
00:44:12,930 --> 00:44:17,940
performs the read of X M must actually

1109
00:44:15,120 --> 00:44:19,080
go back keep local state of all the

1110
00:44:17,940 --> 00:44:21,570
memory locations that have previously

1111
00:44:19,080 --> 00:44:23,819
been read and check if any of these

1112
00:44:21,570 --> 00:44:25,890
memory locations have been changed since

1113
00:44:23,820 --> 00:44:28,530
it last read them in essence it must get

1114
00:44:25,890 --> 00:44:30,450
an entire snapshot of the memory during

1115
00:44:28,530 --> 00:44:35,120
the execution of this long-running

1116
00:44:30,450 --> 00:44:40,049
transaction but now we have a problem

1117
00:44:35,120 --> 00:44:43,799
the problem here being that if it does

1118
00:44:40,050 --> 00:44:44,970
return one there is a cycle now it can't

1119
00:44:43,800 --> 00:44:47,910
hurt on one that's out of the question

1120
00:44:44,970 --> 00:44:51,000
because if it returns one then I have TM

1121
00:44:47,910 --> 00:44:52,950
and t1 which must appear in any total

1122
00:44:51,000 --> 00:44:55,200
order like a sequential execution to

1123
00:44:52,950 --> 00:44:57,120
have happen before t0 and I can't

1124
00:44:55,200 --> 00:45:00,689
justify the response of x1 returning

1125
00:44:57,120 --> 00:45:02,700
zero and XM returning one it can never

1126
00:45:00,690 --> 00:45:07,020
happen in sequential execution this is

1127
00:45:02,700 --> 00:45:10,080
not a safe piece of code but in the

1128
00:45:07,020 --> 00:45:14,100
worst case what can go wrong is that I

1129
00:45:10,080 --> 00:45:17,220
can stuff n minus 1 n minus 1 different

1130
00:45:14,100 --> 00:45:22,890
transactions each of which are writing

1131
00:45:17,220 --> 00:45:24,720
from x1 to xn minus 1 concurrently right

1132
00:45:22,890 --> 00:45:26,220
this can perfectly well happen these are

1133
00:45:24,720 --> 00:45:28,259
writing to different memory locations

1134
00:45:26,220 --> 00:45:29,520
and they are all expected to succeed the

1135
00:45:28,260 --> 00:45:34,200
cache Goering's won't detect any

1136
00:45:29,520 --> 00:45:37,170
conflict and now what must this read of

1137
00:45:34,200 --> 00:45:39,509
X and implementation have to do as I

1138
00:45:37,170 --> 00:45:42,240
said it must go back and verify not just

1139
00:45:39,510 --> 00:45:44,760
whether x1 has changed it must verify if

1140
00:45:42,240 --> 00:45:47,549
anything from x1 to xn minus 1 has

1141
00:45:44,760 --> 00:45:50,630
indeed been changed so in the worst case

1142
00:45:47,550 --> 00:45:52,770
I force this read operation to access

1143
00:45:50,630 --> 00:45:54,830
every memory location that was

1144
00:45:52,770 --> 00:45:58,560
previously read by this transaction and

1145
00:45:54,830 --> 00:46:00,029
this is an extreme overhead for long

1146
00:45:58,560 --> 00:46:02,089
running transactions which are of course

1147
00:46:00,030 --> 00:46:07,740
extremely prevalent in through dates

1148
00:46:02,089 --> 00:46:09,630
cloud applications and the problem here

1149
00:46:07,740 --> 00:46:11,970
is that this read of XM is going to

1150
00:46:09,630 --> 00:46:14,010
access m minus 1 visting memory location

1151
00:46:11,970 --> 00:46:16,319
so this is this huge complexity that I

1152
00:46:14,010 --> 00:46:20,250
incur for the slow part transactional

1153
00:46:16,320 --> 00:46:23,339
implementation and if I don't incur this

1154
00:46:20,250 --> 00:46:24,990
I violate safety and I end up causing

1155
00:46:23,339 --> 00:46:27,259
all these runtime errors potentially

1156
00:46:24,990 --> 00:46:33,029
depending on the underlying program code

1157
00:46:27,260 --> 00:46:35,490
and if you sort of proceed by induct

1158
00:46:33,030 --> 00:46:37,320
induction here you can basically see

1159
00:46:35,490 --> 00:46:39,509
that there is a quadratic complexity

1160
00:46:37,320 --> 00:46:41,640
here right because each read has to go

1161
00:46:39,510 --> 00:46:44,910
back and check if the previous reads

1162
00:46:41,640 --> 00:46:48,839
have been changed and iteratively this

1163
00:46:44,910 --> 00:46:51,420
sums up to be quadratic in the size of

1164
00:46:48,839 --> 00:46:53,400
all the memory locations that I'm

1165
00:46:51,420 --> 00:46:57,510
accessing as part of this long-running

1166
00:46:53,400 --> 00:47:00,900
transaction and the big challenge for us

1167
00:46:57,510 --> 00:47:03,089
as algorithm designers is how do we

1168
00:47:00,900 --> 00:47:06,150
overcome these fundamental limitations

1169
00:47:03,089 --> 00:47:08,849
how do we move to this programming model

1170
00:47:06,150 --> 00:47:11,880
which is so simple and easy to use which

1171
00:47:08,849 --> 00:47:17,430
is here to stay but circumvent these

1172
00:47:11,880 --> 00:47:19,859
fundamental limitations so just to take

1173
00:47:17,430 --> 00:47:21,029
a step back as i said you know even in

1174
00:47:19,859 --> 00:47:24,839
the sequential case you have this

1175
00:47:21,030 --> 00:47:26,940
overhead and in even with the slightly

1176
00:47:24,839 --> 00:47:29,040
more concurrency scenario you have this

1177
00:47:26,940 --> 00:47:31,319
linear cost that must be incurred on

1178
00:47:29,040 --> 00:47:36,150
both the fastpass side and the slow path

1179
00:47:31,319 --> 00:47:38,930
side else you don't get any concurrency

1180
00:47:36,150 --> 00:47:42,690
so this is the price that we must pray

1181
00:47:38,930 --> 00:47:45,060
for writing safe concurrent code

1182
00:47:42,690 --> 00:47:47,550
concurrent code which can work in any

1183
00:47:45,060 --> 00:47:49,170
sequential application but in a safe

1184
00:47:47,550 --> 00:47:56,310
manner without introducing runtime

1185
00:47:49,170 --> 00:47:59,839
errors so with that I'll move to my what

1186
00:47:56,310 --> 00:48:02,609
I have to say as my concluding remarks

1187
00:47:59,839 --> 00:48:05,069
what I'm going to argue is that the

1188
00:48:02,609 --> 00:48:08,098
hybrid model is fundamental so it is

1189
00:48:05,069 --> 00:48:10,529
here to stay the days I would argue of

1190
00:48:08,099 --> 00:48:12,900
programming essentially using these

1191
00:48:10,530 --> 00:48:15,569
other programming models like mapreduce

1192
00:48:12,900 --> 00:48:17,459
or any of these other programming models

1193
00:48:15,569 --> 00:48:19,440
eventually you know we are going to move

1194
00:48:17,459 --> 00:48:22,440
to a this especially for these in memory

1195
00:48:19,440 --> 00:48:23,880
high performance applications and the

1196
00:48:22,440 --> 00:48:25,799
main reason here is that there is

1197
00:48:23,880 --> 00:48:27,479
hardware support that is hardware

1198
00:48:25,799 --> 00:48:29,489
support in today's Intel chipsets

1199
00:48:27,479 --> 00:48:34,319
there's hardwell support in today's IBM

1200
00:48:29,489 --> 00:48:35,699
chipsets and of course we know that we

1201
00:48:34,319 --> 00:48:37,650
are always going to be limited by the

1202
00:48:35,699 --> 00:48:40,259
size of your cache line which means that

1203
00:48:37,650 --> 00:48:42,869
you are always going to expect the code

1204
00:48:40,259 --> 00:48:45,420
to be executed in software so the hybrid

1205
00:48:42,869 --> 00:48:47,819
model is fundamental but of course

1206
00:48:45,420 --> 00:48:49,829
writing safe transactions in the hybrid

1207
00:48:47,819 --> 00:48:53,038
model comes with these huge inherent

1208
00:48:49,829 --> 00:48:57,650
limitations the big question for us is

1209
00:48:53,039 --> 00:48:57,650
how to circumvent these inherent costs

1210
00:48:58,009 --> 00:49:03,420
open challenges for all of us who are

1211
00:49:01,079 --> 00:49:04,799
designing these so if you for those of

1212
00:49:03,420 --> 00:49:07,489
you want to play around with the current

1213
00:49:04,799 --> 00:49:09,869
GCC implementation you will see take a

1214
00:49:07,489 --> 00:49:13,589
writer sequential implementation of a

1215
00:49:09,869 --> 00:49:15,769
queue or a stack or a list set and take

1216
00:49:13,589 --> 00:49:17,400
the most efficient fine-grained

1217
00:49:15,769 --> 00:49:20,698
implementation of the same data

1218
00:49:17,400 --> 00:49:22,170
structure and implement the same data

1219
00:49:20,699 --> 00:49:23,670
structure the sequential code wrap it

1220
00:49:22,170 --> 00:49:26,609
around the transactional delimiter on

1221
00:49:23,670 --> 00:49:30,269
GCC and you will see a noticeable gap in

1222
00:49:26,609 --> 00:49:32,339
performance the question for us is how

1223
00:49:30,269 --> 00:49:33,779
to bridge this gap the hybrid model is

1224
00:49:32,339 --> 00:49:36,930
one step towards bridging that gap

1225
00:49:33,779 --> 00:49:39,239
because you expect in majority at least

1226
00:49:36,930 --> 00:49:40,799
when there is not heavy contention in

1227
00:49:39,239 --> 00:49:42,420
the cache line that most of the

1228
00:49:40,799 --> 00:49:44,549
transactions are going to execute in

1229
00:49:42,420 --> 00:49:47,459
hardware which is going to be noticeably

1230
00:49:44,549 --> 00:49:49,440
faster but this isn't always the case

1231
00:49:47,459 --> 00:49:52,410
especially for applications which have

1232
00:49:49,440 --> 00:49:54,599
huge sequential bottlenecks and there

1233
00:49:52,410 --> 00:49:57,690
are lots of fundamental open questions

1234
00:49:54,599 --> 00:50:00,329
in terms of you know choosing I mean the

1235
00:49:57,690 --> 00:50:02,069
workloads I presented in this talk there

1236
00:50:00,329 --> 00:50:05,069
are pathological workloads worst case

1237
00:50:02,069 --> 00:50:07,170
scenarios maybe this isn't always the

1238
00:50:05,069 --> 00:50:09,239
case so we want to dynamically derive

1239
00:50:07,170 --> 00:50:12,150
implementations depending on the

1240
00:50:09,239 --> 00:50:15,299
workload we need efficient formal

1241
00:50:12,150 --> 00:50:17,640
methods and verification techniques and

1242
00:50:15,299 --> 00:50:20,579
more importantly understand the impact

1243
00:50:17,640 --> 00:50:22,469
of cache hierarchy and the memory model

1244
00:50:20,579 --> 00:50:23,910
you know different instruction set

1245
00:50:22,469 --> 00:50:27,420
architectures have their own different

1246
00:50:23,910 --> 00:50:29,069
memory models which specify what values

1247
00:50:27,420 --> 00:50:34,740
loads and stores

1248
00:50:29,070 --> 00:50:37,590
actually return so the big takeaway more

1249
00:50:34,740 --> 00:50:39,180
than anything here is that you cannot

1250
00:50:37,590 --> 00:50:42,930
violate the safety of concurrent code

1251
00:50:39,180 --> 00:50:45,870
this is a given for us right if you do

1252
00:50:42,930 --> 00:50:48,330
do this if you do sort of dis don't

1253
00:50:45,870 --> 00:50:49,890
design implementations which which are

1254
00:50:48,330 --> 00:50:51,600
sort of have these strong safety

1255
00:50:49,890 --> 00:50:53,759
properties then you have to explicitly

1256
00:50:51,600 --> 00:50:55,850
patch them using sandboxing or these

1257
00:50:53,760 --> 00:50:59,670
other techniques which are very ad hoc

1258
00:50:55,850 --> 00:51:01,440
so you cannot compromise on safety but

1259
00:50:59,670 --> 00:51:06,450
what use is safety if there is no

1260
00:51:01,440 --> 00:51:08,130
performance but the hardware model does

1261
00:51:06,450 --> 00:51:10,649
come with some inherent limitations the

1262
00:51:08,130 --> 00:51:12,110
hybrid model specifically the question

1263
00:51:10,650 --> 00:51:14,280
for us is how to circumvent these

1264
00:51:12,110 --> 00:51:15,720
limitations there are tons of ideas

1265
00:51:14,280 --> 00:51:18,270
which have been which are currently

1266
00:51:15,720 --> 00:51:21,330
being explode for this but my purpose in

1267
00:51:18,270 --> 00:51:23,310
this talk is not to do solution this

1268
00:51:21,330 --> 00:51:24,540
programming model but to for us to

1269
00:51:23,310 --> 00:51:26,430
understand what are the inherent

1270
00:51:24,540 --> 00:51:29,640
limitations that we can efficiently

1271
00:51:26,430 --> 00:51:31,200
overcome these limitations and there are

1272
00:51:29,640 --> 00:51:33,270
tons of ways to overcome these

1273
00:51:31,200 --> 00:51:37,859
limitations which I'm happy to talk

1274
00:51:33,270 --> 00:51:39,750
about offline but as I said I will

1275
00:51:37,860 --> 00:51:42,090
reiterate the significance of this

1276
00:51:39,750 --> 00:51:44,240
programming model which I'm which I

1277
00:51:42,090 --> 00:51:46,530
would like to claim is here to stay and

1278
00:51:44,240 --> 00:51:49,830
it has support from hardware

1279
00:51:46,530 --> 00:51:52,320
manufacturers and fits about in

1280
00:51:49,830 --> 00:51:53,670
developing just about any application

1281
00:51:52,320 --> 00:51:56,130
with a well-defined sequential

1282
00:51:53,670 --> 00:51:58,880
specification and that's all I have to

1283
00:51:56,130 --> 00:51:58,880
say today thank you

1284
00:52:05,480 --> 00:52:13,310
I have a basic question about

1285
00:52:10,810 --> 00:52:15,470
performance increase so what is the

1286
00:52:13,310 --> 00:52:20,170
performance improvement if we use this

1287
00:52:15,470 --> 00:52:27,230
model so depends on the application

1288
00:52:20,170 --> 00:52:30,140
right so for let's say there is a data

1289
00:52:27,230 --> 00:52:32,260
structure for which we don't know any

1290
00:52:30,140 --> 00:52:35,210
efficient concurrent implementation

1291
00:52:32,260 --> 00:52:37,280
right we haven't developed a

1292
00:52:35,210 --> 00:52:38,660
fine-grained concurrent implementation

1293
00:52:37,280 --> 00:52:40,520
for this in which case I would argue

1294
00:52:38,660 --> 00:52:42,830
that go towards this because you're

1295
00:52:40,520 --> 00:52:44,990
definitely going to get some performance

1296
00:52:42,830 --> 00:52:47,590
improvement but for data structures for

1297
00:52:44,990 --> 00:52:49,759
which we have you know 10 20 years of

1298
00:52:47,590 --> 00:52:51,770
research into how to make them

1299
00:52:49,760 --> 00:52:53,900
efficiently concurrent those

1300
00:52:51,770 --> 00:52:56,900
implementations especially like use and

1301
00:52:53,900 --> 00:52:58,880
stacks we know to outperform the hybrid

1302
00:52:56,900 --> 00:53:02,060
model the hardware transactional memory

1303
00:52:58,880 --> 00:53:03,560
model but I should we should also take

1304
00:53:02,060 --> 00:53:05,540
this with a grain of salt because we

1305
00:53:03,560 --> 00:53:06,980
just got this instruction set

1306
00:53:05,540 --> 00:53:10,160
architecture hardware transactions just

1307
00:53:06,980 --> 00:53:11,810
came a little over a year ago and you

1308
00:53:10,160 --> 00:53:13,368
know the research community hasn't spent

1309
00:53:11,810 --> 00:53:15,830
sufficient time and really getting the

1310
00:53:13,369 --> 00:53:18,530
best out of it we have some fundamental

1311
00:53:15,830 --> 00:53:21,710
limitations for some applications it

1312
00:53:18,530 --> 00:53:24,320
looks good for lots of applications not

1313
00:53:21,710 --> 00:53:27,170
yet but that's because we still haven't

1314
00:53:24,320 --> 00:53:31,700
moved we haven't gotten the best most

1315
00:53:27,170 --> 00:53:33,650
efficient implementation right now but

1316
00:53:31,700 --> 00:53:36,609
if you look at the stamp benchmarks the

1317
00:53:33,650 --> 00:53:38,960
Stanford bench back Stanford benchmarks

1318
00:53:36,609 --> 00:53:43,640
you will see that for some applications

1319
00:53:38,960 --> 00:53:45,680
like k-means it's slightly okay but also

1320
00:53:43,640 --> 00:53:47,990
it depends entirely on Haswell versus

1321
00:53:45,680 --> 00:53:49,490
IBM chipsets you know they have

1322
00:53:47,990 --> 00:53:51,410
different cache hierarchy is different

1323
00:53:49,490 --> 00:53:53,000
memory models and we are yet to

1324
00:53:51,410 --> 00:53:58,700
understand the interplay of all of these

1325
00:53:53,000 --> 00:54:01,990
parameters do to get a deterministic

1326
00:53:58,700 --> 00:54:01,990
answer on real performance

1327
00:54:02,890 --> 00:54:04,950
you

