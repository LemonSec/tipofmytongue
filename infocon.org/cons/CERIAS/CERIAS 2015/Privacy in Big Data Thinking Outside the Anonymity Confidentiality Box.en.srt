1
00:00:07,910 --> 00:00:17,880
okay welcome to the january twentieth

2
00:00:12,179 --> 00:00:19,350
serious seminar I Chris Chris Clifton in

3
00:00:17,880 --> 00:00:20,790
addition to being the instructor of

4
00:00:19,350 --> 00:00:24,450
record for the course will be your

5
00:00:20,790 --> 00:00:25,890
speaker today I coming back here to

6
00:00:24,450 --> 00:00:28,860
Purdue where I've been on the faculty

7
00:00:25,890 --> 00:00:33,989
since the beginning of Lent beginning of

8
00:00:28,860 --> 00:00:35,249
the millennium I've back here after two

9
00:00:33,989 --> 00:00:38,248
and a half years at the National Science

10
00:00:35,249 --> 00:00:43,079
Foundation and what I'd like to talk

11
00:00:38,249 --> 00:00:48,030
about today is data privacy and privacy

12
00:00:43,079 --> 00:00:49,739
and security go hand in hand it's very

13
00:00:48,030 --> 00:00:53,280
tough to protect privacy if you don't

14
00:00:49,739 --> 00:00:56,099
have data security as those of us who

15
00:00:53,280 --> 00:00:59,370
have spent some time working for the

16
00:00:56,100 --> 00:01:04,379
federal government know first hand if

17
00:00:59,370 --> 00:01:05,908
any of you have ever done security work

18
00:01:04,379 --> 00:01:08,189
where you had to get a clearance you

19
00:01:05,909 --> 00:01:11,070
know just how much information you have

20
00:01:08,189 --> 00:01:14,070
to give and because of poor secure

21
00:01:11,070 --> 00:01:18,710
computer security much of that

22
00:01:14,070 --> 00:01:22,469
information is now who knows where so

23
00:01:18,710 --> 00:01:27,329
yeah with however privacy really

24
00:01:22,469 --> 00:01:28,860
introduces some new challenges and a lot

25
00:01:27,329 --> 00:01:32,279
of the way we've thought about privacy

26
00:01:28,860 --> 00:01:33,600
in the past is very limiting and what

27
00:01:32,280 --> 00:01:36,630
we're beginning to see is it really

28
00:01:33,600 --> 00:01:39,630
doesn't cover all of the concerns and

29
00:01:36,630 --> 00:01:41,399
challenges so I'm going to go into a

30
00:01:39,630 --> 00:01:44,729
couple of examples of some work we've

31
00:01:41,399 --> 00:01:46,020
done here at Purdue and then kind of

32
00:01:44,729 --> 00:01:51,240
open this up for hopefully some

33
00:01:46,020 --> 00:01:52,740
brainstorming on what some challenges

34
00:01:51,240 --> 00:01:59,070
and issues are and what we might do in

35
00:01:52,740 --> 00:02:03,630
the future so what is privacy well first

36
00:01:59,070 --> 00:02:07,199
example might be complete secrecy but

37
00:02:03,630 --> 00:02:08,399
that's not really possible if nothing

38
00:02:07,200 --> 00:02:11,459
else you learned that I want something

39
00:02:08,399 --> 00:02:13,319
otherwise I wouldn't have asked so the

40
00:02:11,459 --> 00:02:14,220
real problem with privacy is what can we

41
00:02:13,319 --> 00:02:18,690
achieve in

42
00:02:14,220 --> 00:02:25,079
terms of I keep my information from

43
00:02:18,690 --> 00:02:27,840
being used seen in places I don't want

44
00:02:25,080 --> 00:02:34,620
it seen and yet it still gets to be used

45
00:02:27,840 --> 00:02:38,900
in ways that I do want and this is this

46
00:02:34,620 --> 00:02:43,890
is where it gets to be challenging so

47
00:02:38,900 --> 00:02:46,830
one of the kind of traditional measures

48
00:02:43,890 --> 00:02:48,450
of privacy that's written in fact very

49
00:02:46,830 --> 00:02:53,730
explicitly into a lot of laws

50
00:02:48,450 --> 00:02:56,040
particularly US law is anonymity you may

51
00:02:53,730 --> 00:02:59,100
have all the data about me but you don't

52
00:02:56,040 --> 00:03:08,670
know who it's about you can't link the

53
00:02:59,100 --> 00:03:12,030
data to me so the idea is that protects

54
00:03:08,670 --> 00:03:14,458
privacy you can't you know it's you

55
00:03:12,030 --> 00:03:20,280
don't know it's my data so you're you're

56
00:03:14,459 --> 00:03:22,260
not violating my privacy interesting

57
00:03:20,280 --> 00:03:24,810
counterpart you know how many people

58
00:03:22,260 --> 00:03:29,250
feel that this is really an adequate

59
00:03:24,810 --> 00:03:31,560
view of privacy if you have complete

60
00:03:29,250 --> 00:03:36,769
anonymity your private data is out there

61
00:03:31,560 --> 00:03:36,769
but nobody knows it's you is that enough

62
00:03:37,250 --> 00:03:42,989
people who would disagree with that and

63
00:03:39,830 --> 00:03:45,690
as an interesting counterpart suppose

64
00:03:42,989 --> 00:03:47,190
we're talking instead of personal data

65
00:03:45,690 --> 00:03:52,290
we're talking about intellectual

66
00:03:47,190 --> 00:03:54,299
property if you were a company and your

67
00:03:52,290 --> 00:03:56,130
intellectual property were out there for

68
00:03:54,299 --> 00:04:00,420
all to see but they didn't know whose it

69
00:03:56,130 --> 00:04:03,060
was would you feel good about that now

70
00:04:00,420 --> 00:04:04,708
that completely misses the point well to

71
00:04:03,060 --> 00:04:08,549
some extent people feel that way about

72
00:04:04,709 --> 00:04:12,600
their private personal data as well so

73
00:04:08,549 --> 00:04:17,040
anonymity you know it's not only is it

74
00:04:12,600 --> 00:04:23,400
not enough but worse yet it's really

75
00:04:17,040 --> 00:04:27,690
hard to get back in 2006 a decade ago we

76
00:04:23,400 --> 00:04:31,919
had an example where AOL

77
00:04:27,690 --> 00:04:34,920
released its customer web searches for

78
00:04:31,920 --> 00:04:39,660
research studies 20 million queries

79
00:04:34,920 --> 00:04:41,970
among 650,000 unique users they replace

80
00:04:39,660 --> 00:04:46,980
the user ID with a random number so this

81
00:04:41,970 --> 00:04:49,230
is anonymous data well most of you are

82
00:04:46,980 --> 00:04:53,730
probably old enough to remember what

83
00:04:49,230 --> 00:04:58,340
happened a new york times reporter track

84
00:04:53,730 --> 00:05:03,180
down a person and said oh are you user

85
00:04:58,340 --> 00:05:08,030
one for 587 now is this you are these

86
00:05:03,180 --> 00:05:08,030
your queries and the answer was yes

87
00:05:09,740 --> 00:05:15,750
including some things that someone might

88
00:05:12,630 --> 00:05:21,180
find embarrassing but also some queries

89
00:05:15,750 --> 00:05:25,560
that were specific to location specific

90
00:05:21,180 --> 00:05:32,880
to name that quickly allowed them to

91
00:05:25,560 --> 00:05:34,830
track down who wrote those queries you

92
00:05:32,880 --> 00:05:38,900
know you don't want to be the person who

93
00:05:34,830 --> 00:05:38,900
is responsible for something like this

94
00:05:39,620 --> 00:05:48,030
and it just keeps going Netflix an

95
00:05:43,650 --> 00:05:50,849
example where it was shown how to read n

96
00:05:48,030 --> 00:05:55,580
tify where it wasn't actually reporters

97
00:05:50,850 --> 00:05:58,919
doing it very recently new york city

98
00:05:55,580 --> 00:06:01,469
released taxi cab data and it was

99
00:05:58,919 --> 00:06:04,530
quickly shown how it would be very easy

100
00:06:01,470 --> 00:06:09,950
to identify individuals both the taxi

101
00:06:04,530 --> 00:06:09,950
drivers and the passengers in this data

102
00:06:10,220 --> 00:06:15,840
interesting uber responded when New York

103
00:06:14,250 --> 00:06:18,660
City said we want that same information

104
00:06:15,840 --> 00:06:23,549
from you uber said well we'll release it

105
00:06:18,660 --> 00:06:25,080
in an anonymous manner and actually had

106
00:06:23,550 --> 00:06:28,650
some very good ideas about how they

107
00:06:25,080 --> 00:06:30,450
could do this New York City said no

108
00:06:28,650 --> 00:06:33,840
we're going to release it in the same

109
00:06:30,450 --> 00:06:36,770
way we did for the taxi data even though

110
00:06:33,840 --> 00:06:38,369
that's a violation of people's privacy

111
00:06:36,770 --> 00:06:42,919
it's

112
00:06:38,370 --> 00:06:47,419
interesting interesting situation there

113
00:06:42,919 --> 00:06:50,510
so you know how do we provide anonymity

114
00:06:47,419 --> 00:06:58,229
how do we avoid some of those things

115
00:06:50,510 --> 00:07:01,229
well there's some notions of the kind of

116
00:06:58,229 --> 00:07:08,460
two classes one is syntactic anonymity

117
00:07:01,229 --> 00:07:11,180
and the other is noisy information so if

118
00:07:08,460 --> 00:07:16,138
i can add noise to the data in a way

119
00:07:11,180 --> 00:07:19,889
that hides who an individual is this

120
00:07:16,139 --> 00:07:22,800
provides sufficient anonymity or if I

121
00:07:19,889 --> 00:07:27,090
can come up with some specific approach

122
00:07:22,800 --> 00:07:29,729
so for example k anonymity says I'm

123
00:07:27,090 --> 00:07:33,479
going to release the data but I'm going

124
00:07:29,729 --> 00:07:36,080
to generalize rather than giving a birth

125
00:07:33,479 --> 00:07:39,030
date I may just give a year of birth

126
00:07:36,080 --> 00:07:42,630
rather than giving an address i'll just

127
00:07:39,030 --> 00:07:45,929
give the zip code and inkay anonymous

128
00:07:42,630 --> 00:07:48,440
data that means that in that identifying

129
00:07:45,930 --> 00:07:51,030
information you give about people

130
00:07:48,440 --> 00:07:59,360
there's at least K people who look

131
00:07:51,030 --> 00:08:04,289
identical you know unfortunately if you

132
00:07:59,360 --> 00:08:07,440
give a list of K people and you know

133
00:08:04,289 --> 00:08:12,449
under classes you say they're all in the

134
00:08:07,440 --> 00:08:14,010
security seminar even though that

135
00:08:12,449 --> 00:08:16,110
metadata about them that you could

136
00:08:14,010 --> 00:08:17,430
identify is the same you still know

137
00:08:16,110 --> 00:08:19,199
they're all in this room and if you're a

138
00:08:17,430 --> 00:08:22,590
stalker you're going to be able to find

139
00:08:19,199 --> 00:08:25,470
them l diversity said not only do we

140
00:08:22,590 --> 00:08:30,270
have to have that cannon uma t but there

141
00:08:25,470 --> 00:08:34,550
has to be diversity among the sensitive

142
00:08:30,270 --> 00:08:40,740
information of course this is

143
00:08:34,549 --> 00:08:43,319
challenging you have to first year your

144
00:08:40,740 --> 00:08:45,120
data is doesn't look like the original

145
00:08:43,320 --> 00:08:48,620
data you don't have addresses you just

146
00:08:45,120 --> 00:08:51,750
have zip codes for example and second

147
00:08:48,620 --> 00:08:54,990
you have to define what is

148
00:08:51,750 --> 00:08:56,850
identifying information how do you know

149
00:08:54,990 --> 00:09:00,750
what might be identifying and what might

150
00:08:56,850 --> 00:09:03,480
not it may be that being in this course

151
00:09:00,750 --> 00:09:05,280
in some sentence census could be

152
00:09:03,480 --> 00:09:10,650
sensitive than others it could be what

153
00:09:05,280 --> 00:09:15,000
identifies you so there's challenge here

154
00:09:10,650 --> 00:09:17,610
of some of these noisy information

155
00:09:15,000 --> 00:09:19,950
methods can get around that and actually

156
00:09:17,610 --> 00:09:22,890
when you talk about public use microdata

157
00:09:19,950 --> 00:09:26,880
sets they put out for example by the US

158
00:09:22,890 --> 00:09:29,430
Census they one of the ways they will

159
00:09:26,880 --> 00:09:32,910
protect them is adding some noise to the

160
00:09:29,430 --> 00:09:38,579
data while still preserving certain

161
00:09:32,910 --> 00:09:39,719
statistical properties yeah so you go

162
00:09:38,580 --> 00:09:41,460
out and try to find someone there's

163
00:09:39,720 --> 00:09:45,420
there is nobody that exactly matches

164
00:09:41,460 --> 00:09:48,330
that data item because it's not quite

165
00:09:45,420 --> 00:09:51,719
real but it's close enough to use for

166
00:09:48,330 --> 00:09:58,470
statistical analysis differential

167
00:09:51,720 --> 00:10:02,610
privacy is a more kind of formally

168
00:09:58,470 --> 00:10:04,140
defined way of doing this so you know

169
00:10:02,610 --> 00:10:07,800
what are the problems well can we really

170
00:10:04,140 --> 00:10:10,860
prevent RIA denta fication experience

171
00:10:07,800 --> 00:10:13,050
you know our experiences no we keep

172
00:10:10,860 --> 00:10:20,250
trying to anonymize data and people keep

173
00:10:13,050 --> 00:10:26,040
breaking it variety in the data just

174
00:10:20,250 --> 00:10:28,170
makes this worse assume we can is the

175
00:10:26,040 --> 00:10:30,750
data still useful we've actually got a

176
00:10:28,170 --> 00:10:34,189
study underway where we're shadowing a

177
00:10:30,750 --> 00:10:37,200
study and repeating the same analyses on

178
00:10:34,190 --> 00:10:42,810
anonymization zuv the data to see what

179
00:10:37,200 --> 00:10:45,360
happens we're currently having some

180
00:10:42,810 --> 00:10:49,819
serious issues with an autumn izing a

181
00:10:45,360 --> 00:10:49,820
city-sized health information data set

182
00:10:50,000 --> 00:11:00,240
it's even with that many people even

183
00:10:54,570 --> 00:11:02,550
with hundreds of thousands of people you

184
00:11:00,240 --> 00:11:03,620
end up losing a lot of information and

185
00:11:02,550 --> 00:11:06,300
it

186
00:11:03,620 --> 00:11:13,910
tough to do any sort of interesting

187
00:11:06,300 --> 00:11:21,329
studies so as far as noise addition

188
00:11:13,910 --> 00:11:24,749
epsilon differential privacy is a is a

189
00:11:21,329 --> 00:11:30,870
way of dealing with this that has it

190
00:11:24,749 --> 00:11:33,360
really hit the can hit the research

191
00:11:30,870 --> 00:11:35,370
community about a decade ago and we've

192
00:11:33,360 --> 00:11:38,309
still been figuring out the details

193
00:11:35,370 --> 00:11:42,149
figuring out how to make this work in

194
00:11:38,309 --> 00:11:44,339
practice and how to use it the idea

195
00:11:42,149 --> 00:11:49,879
behind epsilon differential privacy is

196
00:11:44,339 --> 00:11:52,499
let's assume that we have a data set and

197
00:11:49,879 --> 00:11:55,649
what we're going to do is we're going to

198
00:11:52,499 --> 00:11:58,980
say we're going to calculate some

199
00:11:55,649 --> 00:12:02,430
function on that data we're going to do

200
00:11:58,980 --> 00:12:06,749
some analysis and the results of that

201
00:12:02,430 --> 00:12:10,138
analysis are going to be very close to

202
00:12:06,749 --> 00:12:15,980
the same even if we remove a person from

203
00:12:10,139 --> 00:12:22,709
the data set so you know we have our

204
00:12:15,980 --> 00:12:25,230
normal way of doing this but by adding

205
00:12:22,709 --> 00:12:32,248
some noise to this well maybe we can

206
00:12:25,230 --> 00:12:37,559
hide that individual impact and the key

207
00:12:32,249 --> 00:12:41,459
idea here is that we want to be able to

208
00:12:37,559 --> 00:12:43,170
remove an individual and essentially the

209
00:12:41,459 --> 00:12:47,189
answer is probably going to come out the

210
00:12:43,170 --> 00:12:50,309
same the impact of one individual on the

211
00:12:47,189 --> 00:12:51,748
answer is less than there's small

212
00:12:50,309 --> 00:12:57,800
relative the amount of noise we're

213
00:12:51,749 --> 00:13:00,240
adding and yet the answer as a whole is

214
00:12:57,800 --> 00:13:03,120
you know the noise is small relative to

215
00:13:00,240 --> 00:13:09,689
the answer as a whole so for example if

216
00:13:03,120 --> 00:13:12,569
you were to compute the sum of the ages

217
00:13:09,689 --> 00:13:16,560
or the average age of everyone in this

218
00:13:12,569 --> 00:13:19,650
room you know I could

219
00:13:16,560 --> 00:13:25,739
at a hundred to the sum is not going to

220
00:13:19,650 --> 00:13:27,689
change the average much and but any

221
00:13:25,740 --> 00:13:35,700
individual is going to make a less of a

222
00:13:27,690 --> 00:13:37,529
change than that the key is it has to

223
00:13:35,700 --> 00:13:41,720
work for any individual it doesn't

224
00:13:37,529 --> 00:13:47,250
matter which individual we remove and

225
00:13:41,720 --> 00:13:49,140
what's more it needs to for the

226
00:13:47,250 --> 00:13:51,150
differential privacy mechanism to work

227
00:13:49,140 --> 00:13:56,880
in general this needs to work for any

228
00:13:51,150 --> 00:13:58,680
pair of databases otherwise from

229
00:13:56,880 --> 00:14:00,480
figuring out how much noise might have

230
00:13:58,680 --> 00:14:02,760
been added you can figure out which

231
00:14:00,480 --> 00:14:04,950
database you know what the original

232
00:14:02,760 --> 00:14:07,529
database was to figure out how much

233
00:14:04,950 --> 00:14:08,970
noise you might need so it turns out

234
00:14:07,529 --> 00:14:10,710
that there are some problems which are

235
00:14:08,970 --> 00:14:16,650
very difficult to provide differential

236
00:14:10,710 --> 00:14:18,480
privacy some problems that are easy the

237
00:14:16,650 --> 00:14:21,240
idea is what you're really getting out

238
00:14:18,480 --> 00:14:22,950
of this is you're getting one answer but

239
00:14:21,240 --> 00:14:27,360
you know what you're really getting is a

240
00:14:22,950 --> 00:14:34,080
point in a distribution and you know

241
00:14:27,360 --> 00:14:37,260
that the point in the distribution is a

242
00:14:34,080 --> 00:14:40,800
little bit you know if you think about

243
00:14:37,260 --> 00:14:42,569
one point the actual answer you get well

244
00:14:40,800 --> 00:14:45,630
it could be from either the red or the

245
00:14:42,570 --> 00:14:47,570
blue distribution there's just not that

246
00:14:45,630 --> 00:14:53,760
much difference between the two of them

247
00:14:47,570 --> 00:14:56,130
and it's going to be the mean of this is

248
00:14:53,760 --> 00:14:57,720
going to be very close in fact most of

249
00:14:56,130 --> 00:15:02,820
the time it's pretty close to the true

250
00:14:57,720 --> 00:15:05,070
answer sometimes it's off but that

251
00:15:02,820 --> 00:15:07,500
potential for being off some time can

252
00:15:05,070 --> 00:15:11,339
really completely hides the impact of

253
00:15:07,500 --> 00:15:15,000
any one person the nice thing about this

254
00:15:11,339 --> 00:15:16,950
is we don't need to worry about what's

255
00:15:15,000 --> 00:15:19,500
sensitive what's identifying in an

256
00:15:16,950 --> 00:15:21,930
individual this no matter what that

257
00:15:19,500 --> 00:15:23,610
function is this analysis you don't

258
00:15:21,930 --> 00:15:26,160
release the data you release the

259
00:15:23,610 --> 00:15:30,139
analysis now there are ways we can do

260
00:15:26,160 --> 00:15:32,490
this where the analysis is give me a

261
00:15:30,139 --> 00:15:36,600
data set that looks like the real one

262
00:15:32,490 --> 00:15:39,750
and you actually can release things that

263
00:15:36,600 --> 00:15:42,240
look very similar to the real data but

264
00:15:39,750 --> 00:15:44,819
in practice it works best where you say

265
00:15:42,240 --> 00:15:54,509
I'm going to use this to compute some

266
00:15:44,819 --> 00:15:57,449
value so if you want to know more about

267
00:15:54,509 --> 00:15:59,430
differential privacy you should have

268
00:15:57,449 --> 00:16:02,250
been here a couple of years ago when we

269
00:15:59,430 --> 00:16:04,709
had Christine tasks gave a tutorial on

270
00:16:02,250 --> 00:16:07,370
differential privacy but since this is

271
00:16:04,709 --> 00:16:12,388
the serious seminar you can go back and

272
00:16:07,370 --> 00:16:14,399
look at that tutorial two or three years

273
00:16:12,389 --> 00:16:16,649
ago well three years now is at least

274
00:16:14,399 --> 00:16:20,370
three years ago and it was Christine

275
00:16:16,649 --> 00:16:26,720
task gave a tutorial on differential

276
00:16:20,370 --> 00:16:32,279
privacy but you know what is privacy

277
00:16:26,720 --> 00:16:37,879
well if you look at you the u.s. a lot

278
00:16:32,279 --> 00:16:40,589
of this goes back to a paper by Brandeis

279
00:16:37,879 --> 00:16:42,569
where he talks about the right to be let

280
00:16:40,589 --> 00:16:44,279
alone actually you Warren and Brandeis

281
00:16:42,569 --> 00:16:51,839
they talk about the right to be let

282
00:16:44,279 --> 00:16:54,600
alone this is supreme court justice from

283
00:16:51,839 --> 00:16:56,519
a information privacy point of view my

284
00:16:54,600 --> 00:16:59,100
information is protected in a way that

285
00:16:56,519 --> 00:17:03,480
it doesn't adversely affect me sometime

286
00:16:59,100 --> 00:17:08,459
in the future so it's really it's not

287
00:17:03,480 --> 00:17:10,470
about it's not so much that you care

288
00:17:08,459 --> 00:17:12,419
that the information is known as the

289
00:17:10,470 --> 00:17:18,150
fact that that information is known by

290
00:17:12,419 --> 00:17:22,039
someone else affects you now in some

291
00:17:18,150 --> 00:17:26,449
cases that may be a direct effect they

292
00:17:22,039 --> 00:17:29,070
don't give you a job because of it or

293
00:17:26,449 --> 00:17:33,960
you know in other cases it Mitch maybe

294
00:17:29,070 --> 00:17:36,000
much more indirect because someone knows

295
00:17:33,960 --> 00:17:38,010
something about you or may know

296
00:17:36,000 --> 00:17:40,520
something about you you find it hard to

297
00:17:38,010 --> 00:17:40,520
look them in the eye

298
00:17:41,840 --> 00:17:46,980
you know these are all things it's you

299
00:17:45,480 --> 00:17:50,130
know often these things are very

300
00:17:46,980 --> 00:17:51,720
difficult to measure so a lot of it is

301
00:17:50,130 --> 00:17:53,460
about control over the data the data

302
00:17:51,720 --> 00:17:57,090
should only be used in ways that you

303
00:17:53,460 --> 00:18:00,299
approve of sometimes you may not approve

304
00:17:57,090 --> 00:18:03,510
of the use of the data that has nothing

305
00:18:00,299 --> 00:18:05,340
to do with a direct effect on you but it

306
00:18:03,510 --> 00:18:08,429
has an effect on society that you may

307
00:18:05,340 --> 00:18:13,520
not be happy with I don't want my data

308
00:18:08,429 --> 00:18:16,260
used in ways that control advertising so

309
00:18:13,520 --> 00:18:22,460
some of you see certain ads others see

310
00:18:16,260 --> 00:18:22,460
different ads that stratify society

311
00:18:23,270 --> 00:18:31,918
interesting example is men and women see

312
00:18:27,480 --> 00:18:34,500
different ads this was looked at and

313
00:18:31,919 --> 00:18:39,600
actually there was a study of job ads

314
00:18:34,500 --> 00:18:45,419
and found that women tended to see ads

315
00:18:39,600 --> 00:18:47,250
for lower paying jobs well you know they

316
00:18:45,419 --> 00:18:49,280
started doing some further study what

317
00:18:47,250 --> 00:18:52,710
I've heard of the reason behind this

318
00:18:49,280 --> 00:18:57,690
it's not that they weren't showing the

319
00:18:52,710 --> 00:19:00,540
job ads to the high paid job ads to the

320
00:18:57,690 --> 00:19:05,700
women who were appropriate for them it's

321
00:19:00,540 --> 00:19:08,250
that other places many cosmetic

322
00:19:05,700 --> 00:19:11,790
manufacturers we're saying okay here's a

323
00:19:08,250 --> 00:19:13,260
high-income woman I want to I want to

324
00:19:11,790 --> 00:19:14,790
show them an ad and I'm going to pay

325
00:19:13,260 --> 00:19:19,350
more for that ad than the person who's

326
00:19:14,790 --> 00:19:22,730
offering them the good job but the end

327
00:19:19,350 --> 00:19:26,250
result is you know the end result is

328
00:19:22,730 --> 00:19:28,559
this could lead to people not getting

329
00:19:26,250 --> 00:19:30,179
jobs that would be very appropriate for

330
00:19:28,559 --> 00:19:32,370
them because they don't know about them

331
00:19:30,179 --> 00:19:35,220
I don't want my data to be used for

332
00:19:32,370 --> 00:19:39,110
something like that so how can I control

333
00:19:35,220 --> 00:19:41,790
that it's not affecting me directly

334
00:19:39,110 --> 00:19:48,418
certainly not hurting me but it's

335
00:19:41,790 --> 00:19:49,730
hurting thing is hurting society so you

336
00:19:48,419 --> 00:19:53,159
know a lot of issues that come up

337
00:19:49,730 --> 00:19:54,540
disclosure of information disclosure

338
00:19:53,159 --> 00:19:56,670
sharing

339
00:19:54,540 --> 00:19:59,430
I want the data to be used for things

340
00:19:56,670 --> 00:20:03,090
that I want I don't want it to be

341
00:19:59,430 --> 00:20:05,000
disclosed for things I don't want you

342
00:20:03,090 --> 00:20:09,990
know what's the probe use and recourse

343
00:20:05,000 --> 00:20:11,850
what do i do if my date is misused how

344
00:20:09,990 --> 00:20:16,140
do I even know that it's being used in

345
00:20:11,850 --> 00:20:24,689
ways I don't approve of so these are all

346
00:20:16,140 --> 00:20:27,030
yeah sorry this raises an interesting

347
00:20:24,690 --> 00:20:31,200
question because with the potential mic

348
00:20:27,030 --> 00:20:32,700
on yeah it is it is now this raises an

349
00:20:31,200 --> 00:20:37,110
interesting question because with the

350
00:20:32,700 --> 00:20:39,510
potential for big data in the spirit of

351
00:20:37,110 --> 00:20:41,969
trying to squeeze more accurate answers

352
00:20:39,510 --> 00:20:44,520
with less air or due to differential

353
00:20:41,970 --> 00:20:50,730
privacy and accumulative tolerance that

354
00:20:44,520 --> 00:20:53,060
can result there from are we saying the

355
00:20:50,730 --> 00:20:56,820
individual should basically withhold or

356
00:20:53,060 --> 00:20:59,940
as individuals we should withhold from

357
00:20:56,820 --> 00:21:03,929
society information because we fear it

358
00:20:59,940 --> 00:21:09,300
might be used against us and and does

359
00:21:03,930 --> 00:21:13,370
that individual desire override

360
00:21:09,300 --> 00:21:17,310
society's greater good okay so you know

361
00:21:13,370 --> 00:21:19,889
part of the issue is a policy cultural

362
00:21:17,310 --> 00:21:21,360
thing is making that call but let's

363
00:21:19,890 --> 00:21:23,130
assume we get to the point where

364
00:21:21,360 --> 00:21:27,419
everyone says well if my information

365
00:21:23,130 --> 00:21:28,470
would be used to the greater good even

366
00:21:27,420 --> 00:21:30,990
though I may not be delighted with it

367
00:21:28,470 --> 00:21:33,990
every single time how do we then

368
00:21:30,990 --> 00:21:35,310
maintain that privacy so i just had had

369
00:21:33,990 --> 00:21:36,720
to point that out because we can obsess

370
00:21:35,310 --> 00:21:38,790
on whatever individual wants and never

371
00:21:36,720 --> 00:21:40,560
get anywhere yeah i mean it is an

372
00:21:38,790 --> 00:21:44,000
interesting it is an interesting and as

373
00:21:40,560 --> 00:21:47,550
an individual most people are very happy

374
00:21:44,000 --> 00:21:53,250
to give up their personal information

375
00:21:47,550 --> 00:21:55,800
for some purposes in fact someone offers

376
00:21:53,250 --> 00:21:57,600
you a very limp small benefit you'll

377
00:21:55,800 --> 00:22:03,899
probably give up all kinds of personal

378
00:21:57,600 --> 00:22:05,639
information the and actually societal

379
00:22:03,900 --> 00:22:07,580
benefit people are willing to give up

380
00:22:05,640 --> 00:22:11,150
data a

381
00:22:07,580 --> 00:22:14,689
for cancer research or for all kinds of

382
00:22:11,150 --> 00:22:21,740
other things very willing to do it it's

383
00:22:14,690 --> 00:22:26,120
you know the difficult thing is is how

384
00:22:21,740 --> 00:22:28,370
do you make sure that you still have

385
00:22:26,120 --> 00:22:32,750
that control but that it's used in ways

386
00:22:28,370 --> 00:22:36,439
that you're happy with and if the only

387
00:22:32,750 --> 00:22:39,680
answer is to withhold data to become a

388
00:22:36,440 --> 00:22:43,970
hermit well yeah that's not good for

389
00:22:39,680 --> 00:22:49,490
society or individuals if on the other

390
00:22:43,970 --> 00:22:52,750
hand you had some obviously very complex

391
00:22:49,490 --> 00:22:55,580
way of doing things where you could

392
00:22:52,750 --> 00:22:58,520
specify oh yeah it's okay to use my data

393
00:22:55,580 --> 00:23:01,129
for that no it's okay to not not okay to

394
00:22:58,520 --> 00:23:05,420
use it for that what would the end

395
00:23:01,130 --> 00:23:06,920
result be you know the problem is how

396
00:23:05,420 --> 00:23:08,930
often does your data get used could you

397
00:23:06,920 --> 00:23:11,360
really get asked every time would you

398
00:23:08,930 --> 00:23:13,400
want that so I don't think that's a

399
00:23:11,360 --> 00:23:15,830
practical but it might be an interesting

400
00:23:13,400 --> 00:23:18,260
thought experiment what would happen if

401
00:23:15,830 --> 00:23:21,020
every time your data was used for

402
00:23:18,260 --> 00:23:22,970
anything you were given the opportunity

403
00:23:21,020 --> 00:23:25,820
to make a decision as to whether you

404
00:23:22,970 --> 00:23:27,590
wanted that to happen or not and you

405
00:23:25,820 --> 00:23:33,919
were actually told what the impact would

406
00:23:27,590 --> 00:23:35,870
be of your making that decision that's

407
00:23:33,920 --> 00:23:37,340
an interesting interesting thought as to

408
00:23:35,870 --> 00:23:40,370
what would happen often would you say

409
00:23:37,340 --> 00:23:43,929
yes how would you say no obviously

410
00:23:40,370 --> 00:23:45,830
that's not the way things would work but

411
00:23:43,930 --> 00:23:49,430
that's that's one of the key challenges

412
00:23:45,830 --> 00:23:53,620
here in privacy is we don't there are so

413
00:23:49,430 --> 00:23:53,620
many different issues that come up

414
00:23:55,240 --> 00:24:02,150
there's some interesting outcomes though

415
00:23:58,100 --> 00:24:04,600
for example polling political polls

416
00:24:02,150 --> 00:24:08,120
people are known to give information

417
00:24:04,600 --> 00:24:10,939
that it's known that poll results and

418
00:24:08,120 --> 00:24:16,550
the actual election results are going to

419
00:24:10,940 --> 00:24:19,430
have differences and you know and in

420
00:24:16,550 --> 00:24:20,990
particular candidates with extreme views

421
00:24:19,430 --> 00:24:25,970
often do better than

422
00:24:20,990 --> 00:24:30,290
polls say they will and there are some

423
00:24:25,970 --> 00:24:33,140
clear reasons why this happens the same

424
00:24:30,290 --> 00:24:35,149
is true how many of you have ever given

425
00:24:33,140 --> 00:24:40,429
incorrect information when asked to

426
00:24:35,150 --> 00:24:45,410
register at a website yeah half the

427
00:24:40,429 --> 00:24:47,000
class so you know when you're getting

428
00:24:45,410 --> 00:24:49,390
this in this big data coming in at a

429
00:24:47,000 --> 00:24:51,740
website where you're asked to register

430
00:24:49,390 --> 00:24:56,000
you really trust that data do your

431
00:24:51,740 --> 00:25:01,580
analyses if half the people are giving

432
00:24:56,000 --> 00:25:05,710
bad data you know you have to to start

433
00:25:01,580 --> 00:25:09,050
thinking about what if you can provide

434
00:25:05,710 --> 00:25:11,200
promises of privacy does that mean you

435
00:25:09,050 --> 00:25:13,730
get better data and better answers

436
00:25:11,200 --> 00:25:18,110
there's some interesting questions that

437
00:25:13,730 --> 00:25:20,000
come up and another is can can we come

438
00:25:18,110 --> 00:25:23,949
up with weaker views of privacy often

439
00:25:20,000 --> 00:25:27,320
this anonymity differential privacy just

440
00:25:23,950 --> 00:25:30,100
make it very hard to get good data but

441
00:25:27,320 --> 00:25:32,379
if you just say okay it's a free-for-all

442
00:25:30,100 --> 00:25:35,020
that also makes it very hard because

443
00:25:32,380 --> 00:25:37,700
people won't want to give you good data

444
00:25:35,020 --> 00:25:41,510
so here's a couple of examples of some

445
00:25:37,700 --> 00:25:44,780
work we've done with somewhat weaker

446
00:25:41,510 --> 00:25:47,540
views of privacy so either you know you

447
00:25:44,780 --> 00:25:49,220
aren't sure what I want you may know who

448
00:25:47,540 --> 00:25:53,300
i am but you don't quite know what i

449
00:25:49,220 --> 00:25:58,490
want or you aren't sure who I am you may

450
00:25:53,300 --> 00:26:03,550
have some idea so this idea of plausible

451
00:25:58,490 --> 00:26:03,550
deniability you can

452
00:26:04,450 --> 00:26:12,340
so we've looked at this in the concept

453
00:26:07,450 --> 00:26:13,750
of text because for example with even

454
00:26:12,340 --> 00:26:15,480
with something like search queries but

455
00:26:13,750 --> 00:26:19,890
much more with something you've written

456
00:26:15,480 --> 00:26:23,230
notion like anonymity makes no sense

457
00:26:19,890 --> 00:26:27,340
okay I'm only going to release the

458
00:26:23,230 --> 00:26:28,930
letter you've written if there's several

459
00:26:27,340 --> 00:26:33,639
other people who've written exactly the

460
00:26:28,930 --> 00:26:38,800
same letter and this isn't this isn't

461
00:26:33,640 --> 00:26:45,850
likely so here's one example was a

462
00:26:38,800 --> 00:26:48,340
location uncertainty example and me I

463
00:26:45,850 --> 00:26:50,639
think I have to click to get that too so

464
00:26:48,340 --> 00:26:53,080
this is that was actually at a

465
00:26:50,640 --> 00:26:57,130
conference where gave a talk on this

466
00:26:53,080 --> 00:27:03,720
where that was showing what was being

467
00:26:57,130 --> 00:27:08,260
reported by the GPS in a tablet and

468
00:27:03,720 --> 00:27:10,630
you'll notice there is a point that it

469
00:27:08,260 --> 00:27:13,510
says is the point but there's also a

470
00:27:10,630 --> 00:27:16,930
circle where it says there's some

471
00:27:13,510 --> 00:27:21,690
uncertainty with this and so the idea is

472
00:27:16,930 --> 00:27:27,960
could we use that to say we're going to

473
00:27:21,690 --> 00:27:31,510
give some uncertainty we're going to

474
00:27:27,960 --> 00:27:37,780
give an incorrect location but we're

475
00:27:31,510 --> 00:27:42,390
going to give a a level of uncertainty

476
00:27:37,780 --> 00:27:44,770
that you're somewhere in that space but

477
00:27:42,390 --> 00:27:48,580
not at this not necessarily at the

478
00:27:44,770 --> 00:27:51,970
center of it and what would that do to

479
00:27:48,580 --> 00:27:58,210
existing location based services so we

480
00:27:51,970 --> 00:28:02,950
did some analysis of this and said let's

481
00:27:58,210 --> 00:28:07,360
look and see whether this case android

482
00:28:02,950 --> 00:28:13,690
apps are using this and there is a very

483
00:28:07,360 --> 00:28:15,689
simple get accuracy call and so we look

484
00:28:13,690 --> 00:28:17,850
through a bunch of android apps

485
00:28:15,690 --> 00:28:19,980
to see if they use this get accuracy at

486
00:28:17,850 --> 00:28:26,820
all or if they just assume the point

487
00:28:19,980 --> 00:28:28,440
they were given was correct and some of

488
00:28:26,820 --> 00:28:34,470
these actually did there are several

489
00:28:28,440 --> 00:28:36,000
that actually made use of this you can

490
00:28:34,470 --> 00:28:37,649
certainly see it would be obvious how

491
00:28:36,000 --> 00:28:41,309
you might make use of it in something

492
00:28:37,649 --> 00:28:43,018
like taxi magic well yeah if you've got

493
00:28:41,309 --> 00:28:45,000
a very uncertain location you probably

494
00:28:43,019 --> 00:28:48,240
don't want the taxi to just go there

495
00:28:45,000 --> 00:28:53,190
when you might be half a block away or

496
00:28:48,240 --> 00:28:54,509
on the other side of a alley I talked to

497
00:28:53,190 --> 00:28:58,409
an uber driver was run into that problem

498
00:28:54,509 --> 00:29:00,840
of pulling in of being directed to pull

499
00:28:58,409 --> 00:29:03,059
into an alley to pick someone up because

500
00:29:00,840 --> 00:29:08,879
well they were really on the street on

501
00:29:03,059 --> 00:29:11,250
the other side so these are ones that

502
00:29:08,879 --> 00:29:13,469
actually did look front we're e for

503
00:29:11,250 --> 00:29:17,820
uncertainty they actually had code to

504
00:29:13,470 --> 00:29:19,879
call that get accuracy how many of these

505
00:29:17,820 --> 00:29:26,480
actually sent that back to the server

506
00:29:19,879 --> 00:29:28,860
did something with it well very few and

507
00:29:26,480 --> 00:29:30,659
there were only two that we were

508
00:29:28,860 --> 00:29:34,110
actually able to detect an impact on the

509
00:29:30,659 --> 00:29:43,620
outcome of all these location apps we

510
00:29:34,110 --> 00:29:47,399
looked at so you open Foursquare

511
00:29:43,620 --> 00:29:48,899
basically both doing check-in and they

512
00:29:47,399 --> 00:29:52,379
were using it to say are you really at

513
00:29:48,899 --> 00:29:54,389
that location in the case of foursquare

514
00:29:52,379 --> 00:29:57,809
they said if the reported uncertainty

515
00:29:54,389 --> 00:30:01,529
was high they look at other aspects

516
00:29:57,809 --> 00:30:05,250
before they allow you to check-in in

517
00:30:01,529 --> 00:30:07,980
yelp they say if what you say is your

518
00:30:05,250 --> 00:30:09,120
location is within that reported

519
00:30:07,980 --> 00:30:11,429
uncertainty then they're going to

520
00:30:09,120 --> 00:30:12,840
believe you in other words they're

521
00:30:11,429 --> 00:30:18,090
saying it's the GPS that's not

522
00:30:12,840 --> 00:30:21,389
trustworthy you know that ladder okay

523
00:30:18,090 --> 00:30:24,600
that would work you could wait until you

524
00:30:21,389 --> 00:30:26,100
left an air place and report your check

525
00:30:24,600 --> 00:30:27,629
in with high uncertainty and your

526
00:30:26,100 --> 00:30:29,090
stalkers not going to find you because

527
00:30:27,629 --> 00:30:33,540
you've already left

528
00:30:29,090 --> 00:30:39,590
before you check in so this is actually

529
00:30:33,540 --> 00:30:44,070
a several people did this and that

530
00:30:39,590 --> 00:30:46,830
picture is this is done at a dex duel

531
00:30:44,070 --> 00:30:49,590
seminar that is shallow stag stool in

532
00:30:46,830 --> 00:30:51,830
the picture in the corner and guess

533
00:30:49,590 --> 00:30:55,590
where what we weren't out in the field

534
00:30:51,830 --> 00:31:00,260
when this the iPad that this picture is

535
00:30:55,590 --> 00:31:06,290
from was reporting the location it was

536
00:31:00,260 --> 00:31:14,940
barely within the uncertainty space that

537
00:31:06,290 --> 00:31:17,330
of that circle okay so another idea

538
00:31:14,940 --> 00:31:22,920
where we're using this uncertainty is

539
00:31:17,330 --> 00:31:25,110
text general generalization so here

540
00:31:22,920 --> 00:31:29,070
we're looking at the concept of

541
00:31:25,110 --> 00:31:31,709
de-identification things like protecting

542
00:31:29,070 --> 00:31:33,629
against author identification protecting

543
00:31:31,710 --> 00:31:35,970
against releasing things that have very

544
00:31:33,630 --> 00:31:42,900
specific information that identifies you

545
00:31:35,970 --> 00:31:44,550
and but at the same type you know d

546
00:31:42,900 --> 00:31:46,320
edification tools get rid of obvious

547
00:31:44,550 --> 00:31:48,960
identifying information but often

548
00:31:46,320 --> 00:31:55,770
there's things in the text itself that

549
00:31:48,960 --> 00:31:59,370
make it unique so for example how many

550
00:31:55,770 --> 00:32:02,760
of you know what phantom pain is few of

551
00:31:59,370 --> 00:32:04,620
you do phantom pain is what you feel

552
00:32:02,760 --> 00:32:11,040
when you've lost a limb and it still

553
00:32:04,620 --> 00:32:13,739
hurts if you put in a medical record

554
00:32:11,040 --> 00:32:16,830
someone has phantom pain well there are

555
00:32:13,740 --> 00:32:18,660
some cases where it's not loss of a limb

556
00:32:16,830 --> 00:32:23,189
but generally that means they've lost a

557
00:32:18,660 --> 00:32:24,960
limb well that's kind of identifying but

558
00:32:23,190 --> 00:32:27,450
it certainly doesn't match any of the

559
00:32:24,960 --> 00:32:30,960
identifiers zwi would list as

560
00:32:27,450 --> 00:32:33,620
identifying information an alternative

561
00:32:30,960 --> 00:32:36,000
we can suppress sensitive information

562
00:32:33,620 --> 00:32:40,409
you know instead of say uses marijuana

563
00:32:36,000 --> 00:32:42,659
for pain we could say uses well we

564
00:32:40,410 --> 00:32:47,099
suppress it entirely that doesn't

565
00:32:42,659 --> 00:32:49,739
very useful does it so our idea was to

566
00:32:47,099 --> 00:32:52,249
generalize that you know instead of

567
00:32:49,739 --> 00:32:54,869
saying uses marijuana for phantom pain

568
00:32:52,249 --> 00:32:58,529
which is certainly not something you

569
00:32:54,869 --> 00:33:01,949
would want known if you were the person

570
00:32:58,529 --> 00:33:04,859
responsible because hey it's both

571
00:33:01,950 --> 00:33:11,809
sensitive and identify least in this

572
00:33:04,859 --> 00:33:14,220
state information generalization well

573
00:33:11,809 --> 00:33:17,489
we'll get rid of some of the identifying

574
00:33:14,220 --> 00:33:19,679
but also some of the sensitivity by

575
00:33:17,489 --> 00:33:27,539
generalizing information and yet will

576
00:33:19,679 --> 00:33:31,259
retain some of the useful analysis so

577
00:33:27,539 --> 00:33:38,700
yeah this was this was an attempt to do

578
00:33:31,259 --> 00:33:42,419
this to generalize and basically we

579
00:33:38,700 --> 00:33:43,859
could use a hierarchy of words we

580
00:33:42,419 --> 00:33:46,919
actually can get that from various

581
00:33:43,859 --> 00:33:51,989
ontology such as as wordnet is a simple

582
00:33:46,919 --> 00:33:55,320
example but there are much more complex

583
00:33:51,989 --> 00:34:00,200
and semantically valuable hierarchies

584
00:33:55,320 --> 00:34:04,019
and rather than just sanitizing by

585
00:34:00,200 --> 00:34:13,440
scrubbing out or redacting the bad

586
00:34:04,019 --> 00:34:15,418
information we generalize it so that's

587
00:34:13,440 --> 00:34:18,299
an example of making information less

588
00:34:15,418 --> 00:34:23,308
sensitive less identifiable but not

589
00:34:18,299 --> 00:34:26,730
perfect another approach to doing this

590
00:34:23,309 --> 00:34:30,179
is kind of hiding the real information

591
00:34:26,730 --> 00:34:32,690
in noisy information this was an idea

592
00:34:30,179 --> 00:34:35,039
that we came up with to protect queries

593
00:34:32,690 --> 00:34:39,899
the idea would be that the browser

594
00:34:35,039 --> 00:34:46,789
submits more than one query which one's

595
00:34:39,899 --> 00:34:51,469
the real one so deniability the key is

596
00:34:46,789 --> 00:34:55,529
regardless of which was the real query

597
00:34:51,469 --> 00:34:56,168
you get the same set so any one of those

598
00:34:55,529 --> 00:34:57,940
could have been

599
00:34:56,168 --> 00:35:01,839
original query there's no way to prove

600
00:34:57,940 --> 00:35:06,700
which was the real one in addition you

601
00:35:01,839 --> 00:35:10,839
want those cover queries to be diverse

602
00:35:06,700 --> 00:35:14,078
topics you know you don't want to give a

603
00:35:10,839 --> 00:35:17,349
whole bunch of queries about the Super

604
00:35:14,079 --> 00:35:24,130
Bowl because that's going to give the

605
00:35:17,349 --> 00:35:29,579
information away anyway finally and this

606
00:35:24,130 --> 00:35:33,880
is the hard part plausibility you want

607
00:35:29,579 --> 00:35:36,549
the queries to make sense so you know

608
00:35:33,880 --> 00:35:37,869
java compiler newton apple for those of

609
00:35:36,549 --> 00:35:40,559
you old enough to remember the newton

610
00:35:37,869 --> 00:35:43,630
these are both things that make sense

611
00:35:40,559 --> 00:35:45,880
java compiler and motorola table you

612
00:35:43,630 --> 00:35:52,690
know it's motorola and table how those

613
00:35:45,880 --> 00:35:58,540
go why would those go together so this

614
00:35:52,690 --> 00:36:02,130
is an example of a you know implausible

615
00:35:58,540 --> 00:36:08,349
query so you wouldn't want to give those

616
00:36:02,130 --> 00:36:12,359
so the theory behind this is that user

617
00:36:08,349 --> 00:36:12,359
queries follow some distribution and

618
00:36:12,990 --> 00:36:19,509
cover queries are generated through some

619
00:36:15,670 --> 00:36:26,920
distribution and we want to be able to

620
00:36:19,510 --> 00:36:29,890
say that the probability of the these

621
00:36:26,920 --> 00:36:32,500
two events where q1 is the user in q2 is

622
00:36:29,890 --> 00:36:38,290
the cover query and q1 is the cover in

623
00:36:32,500 --> 00:36:41,010
q2 is the user are the same and this

624
00:36:38,290 --> 00:36:43,660
essentially gives us a formula that

625
00:36:41,010 --> 00:36:47,109
based on the distributions that we have

626
00:36:43,660 --> 00:36:49,779
to meet so then we have to come up with

627
00:36:47,109 --> 00:36:52,299
some way of doing it and we tried a

628
00:36:49,780 --> 00:36:57,390
couple of ways I'm not because of the

629
00:36:52,299 --> 00:36:57,390
time I'm not going to go into a lot of

630
00:36:57,480 --> 00:37:06,549
detail but one approach we used was

631
00:37:02,980 --> 00:37:08,049
based on Latin semantic indexing which

632
00:37:06,549 --> 00:37:09,580
is a technique used in information

633
00:37:08,049 --> 00:37:12,540
retrieval

634
00:37:09,580 --> 00:37:16,029
where we essentially generated queries

635
00:37:12,540 --> 00:37:21,160
from the things that would be good

636
00:37:16,030 --> 00:37:23,140
queries for the data that you had so if

637
00:37:21,160 --> 00:37:25,180
I have a query that's going to return

638
00:37:23,140 --> 00:37:29,140
100 documents I should be able to

639
00:37:25,180 --> 00:37:36,700
generate queries that also return 100

640
00:37:29,140 --> 00:37:40,270
documents this is turned out to be very

641
00:37:36,700 --> 00:37:44,770
difficult did some work here a second

642
00:37:40,270 --> 00:37:48,820
similar approach was to use a query log

643
00:37:44,770 --> 00:37:51,100
and generate queries that were similar

644
00:37:48,820 --> 00:37:56,380
to the terms in the query log in with

645
00:37:51,100 --> 00:37:59,730
similar frequencies so you know here's

646
00:37:56,380 --> 00:38:02,350
an example of some sample queries that

647
00:37:59,730 --> 00:38:03,370
we came up with this is actually

648
00:38:02,350 --> 00:38:04,990
interesting because one of the things

649
00:38:03,370 --> 00:38:07,839
that makes the problem hard as queries

650
00:38:04,990 --> 00:38:09,459
tend to be in a sequence you give a

651
00:38:07,840 --> 00:38:12,160
query it's not quite what you wanted you

652
00:38:09,460 --> 00:38:13,630
give another similar query and then at

653
00:38:12,160 --> 00:38:16,779
some point you give something completely

654
00:38:13,630 --> 00:38:22,930
different and we need our sequence of

655
00:38:16,780 --> 00:38:25,570
cover queries to match that as well so

656
00:38:22,930 --> 00:38:27,870
any idea which of these is the real

657
00:38:25,570 --> 00:38:27,870
query

658
00:38:34,090 --> 00:38:46,930
who would guess first none second a

659
00:38:38,530 --> 00:38:48,910
couple of you third none maybe one well

660
00:38:46,930 --> 00:38:52,509
you know some of these things are pretty

661
00:38:48,910 --> 00:38:56,890
obviously real things once you you do

662
00:38:52,510 --> 00:39:01,620
this stemming some of them actually seem

663
00:38:56,890 --> 00:39:05,500
to you know be related terms unrelated

664
00:39:01,620 --> 00:39:08,080
turns out that the in that one the third

665
00:39:05,500 --> 00:39:14,230
example was the correct one but it it

666
00:39:08,080 --> 00:39:15,910
worked out pretty well so I'm not going

667
00:39:14,230 --> 00:39:18,750
to go through the details because I want

668
00:39:15,910 --> 00:39:20,379
to get on to some other things but

669
00:39:18,750 --> 00:39:24,240
essentially the same sort of

670
00:39:20,380 --> 00:39:28,600
probabilistic argument works for

671
00:39:24,240 --> 00:39:30,250
sequences that works for the regular

672
00:39:28,600 --> 00:39:32,410
queries that we showed before where you

673
00:39:30,250 --> 00:39:34,840
eventually have this event being a

674
00:39:32,410 --> 00:39:37,620
sequence and it needs to be equally

675
00:39:34,840 --> 00:39:41,050
probable for the cover and the non cover

676
00:39:37,620 --> 00:39:47,220
so here's another example of some

677
00:39:41,050 --> 00:39:47,220
queries these taken without the stemming

678
00:39:49,730 --> 00:40:05,549
again guesses actually the third is the

679
00:39:59,749 --> 00:40:14,098
real query the others are are generated

680
00:40:05,549 --> 00:40:16,319
sequences so you know there's just a

681
00:40:14,099 --> 00:40:18,720
couple of examples of things you can do

682
00:40:16,319 --> 00:40:27,058
when you start thinking beyond simple

683
00:40:18,720 --> 00:40:31,249
views of anonymity secrecy one of the

684
00:40:27,059 --> 00:40:35,519
things about all of these you basically

685
00:40:31,249 --> 00:40:37,879
weakened knowledge about the user either

686
00:40:35,519 --> 00:40:41,930
through not knowing who the user is or

687
00:40:37,880 --> 00:40:44,130
not knowing what's true about that user

688
00:40:41,930 --> 00:40:46,950
which weakens what you can learn about

689
00:40:44,130 --> 00:40:49,440
the data and this is something we've

690
00:40:46,950 --> 00:40:55,499
been working on how do we better learn

691
00:40:49,440 --> 00:40:59,339
from anonymized data you know so this

692
00:40:55,499 --> 00:41:05,700
could reduce the utility this leads to

693
00:40:59,339 --> 00:41:09,480
resistance heard someone once basically

694
00:41:05,700 --> 00:41:11,419
say to differential privacy you know how

695
00:41:09,480 --> 00:41:14,160
how many babies are we going to kill

696
00:41:11,420 --> 00:41:16,440
with differential privacy you know is

697
00:41:14,160 --> 00:41:22,558
that the measure of epsilon the the

698
00:41:16,440 --> 00:41:25,499
privacy measure what people making these

699
00:41:22,559 --> 00:41:27,150
statements often forget about is the

700
00:41:25,499 --> 00:41:34,819
fact that there's already noise in the

701
00:41:27,150 --> 00:41:34,819
data your your data is not perfect and

702
00:41:35,180 --> 00:41:41,970
adding a little more noise often it's a

703
00:41:40,259 --> 00:41:47,099
very small amount relative to what's

704
00:41:41,970 --> 00:41:49,339
already there in the data so you know

705
00:41:47,099 --> 00:41:52,200
when we start talking about these things

706
00:41:49,339 --> 00:41:55,140
people can go off the deep end in then

707
00:41:52,200 --> 00:41:57,259
and not think about what's really going

708
00:41:55,140 --> 00:41:57,259
on

709
00:41:58,739 --> 00:42:02,890
but you know are there other ways to

710
00:42:01,690 --> 00:42:09,190
provide privacy are there the other

711
00:42:02,890 --> 00:42:11,828
things we should think about and this is

712
00:42:09,190 --> 00:42:13,450
something to to think about this and

713
00:42:11,829 --> 00:42:16,779
what we should be doing in terms of

714
00:42:13,450 --> 00:42:20,410
protecting privacy like to go back to

715
00:42:16,779 --> 00:42:23,920
some of the laws guidelines and rules

716
00:42:20,410 --> 00:42:27,609
and understanding some of these can help

717
00:42:23,920 --> 00:42:29,710
I think give us some ideas so some of

718
00:42:27,609 --> 00:42:33,779
the things that the EU data protection

719
00:42:29,710 --> 00:42:37,989
directive which is 20 years old now

720
00:42:33,779 --> 00:42:42,009
provides the right to know where data

721
00:42:37,989 --> 00:42:43,539
originated in other words if they've got

722
00:42:42,009 --> 00:42:47,289
data about me I have the right to know

723
00:42:43,539 --> 00:42:52,450
where it came from I have the right to

724
00:42:47,289 --> 00:42:54,190
fix inaccurate data in the event you do

725
00:42:52,450 --> 00:42:59,710
something illegal with it I have a right

726
00:42:54,190 --> 00:43:00,849
of recourse in some circumstances I

727
00:42:59,710 --> 00:43:03,549
should have the right to withhold

728
00:43:00,849 --> 00:43:06,569
permission to use that data not

729
00:43:03,549 --> 00:43:09,788
necessarily in all circumstances and

730
00:43:06,569 --> 00:43:13,630
these circumstances are defined as part

731
00:43:09,789 --> 00:43:19,569
of the rules one of the things they do

732
00:43:13,630 --> 00:43:22,420
say is anonymity if the data personal

733
00:43:19,569 --> 00:43:25,259
data is information that can be traced

734
00:43:22,420 --> 00:43:31,119
directly or indirectly to a specific

735
00:43:25,259 --> 00:43:34,269
individual and if it's not personal data

736
00:43:31,119 --> 00:43:37,319
in other words if I can't trace it to an

737
00:43:34,269 --> 00:43:40,529
individual it's not covered by the law

738
00:43:37,319 --> 00:43:45,130
unfortunately as we've been discovering

739
00:43:40,529 --> 00:43:47,829
data is traceable to individuals in fact

740
00:43:45,130 --> 00:43:50,410
the the number of things that the EU

741
00:43:47,829 --> 00:43:55,869
considers personal I personally

742
00:43:50,410 --> 00:43:58,239
identifiable data keeps growing number

743
00:43:55,869 --> 00:44:01,559
of years ago IP address was added to the

744
00:43:58,239 --> 00:44:03,910
list and all of a sudden all of your

745
00:44:01,559 --> 00:44:05,650
firewall logs become personally

746
00:44:03,910 --> 00:44:08,519
identifiable data and covered by this

747
00:44:05,650 --> 00:44:08,519
law law

748
00:44:09,430 --> 00:44:19,069
but think about it IP address

749
00:44:12,230 --> 00:44:21,410
individually identifiable I mean I don't

750
00:44:19,069 --> 00:44:25,009
think any of you would take that long to

751
00:44:21,410 --> 00:44:31,759
find the IP address of the desktop

752
00:44:25,010 --> 00:44:33,890
machine in my office in fact probably

753
00:44:31,760 --> 00:44:35,599
several of you can trace through your

754
00:44:33,890 --> 00:44:41,420
email logs and figure it out while we

755
00:44:35,599 --> 00:44:44,450
speak they then say use is allowed in

756
00:44:41,420 --> 00:44:49,099
certain circumstances if unambiguous

757
00:44:44,450 --> 00:44:50,990
consent is given if in order to perform

758
00:44:49,099 --> 00:44:54,319
a contract with the subject of the data

759
00:44:50,990 --> 00:44:59,000
it's required to have that data in other

760
00:44:54,319 --> 00:45:00,859
words if I want to buy something from

761
00:44:59,000 --> 00:45:03,980
you using your credit card I don't need

762
00:45:00,859 --> 00:45:08,390
your consent to have the credit card in

763
00:45:03,980 --> 00:45:11,900
data you've given it to me to perform

764
00:45:08,390 --> 00:45:14,150
that contract if it's legally required

765
00:45:11,900 --> 00:45:16,700
to have that data you can have it if

766
00:45:14,150 --> 00:45:19,490
it's necessary to protect the vital

767
00:45:16,700 --> 00:45:23,990
interests of the subject if it's in the

768
00:45:19,490 --> 00:45:27,848
public interest and interesting

769
00:45:23,990 --> 00:45:29,930
difference here you know in the US

770
00:45:27,849 --> 00:45:31,460
Google will say everything we do is in

771
00:45:29,930 --> 00:45:39,710
the public interest it's all for the

772
00:45:31,460 --> 00:45:44,260
good now in the EU public interest tends

773
00:45:39,710 --> 00:45:46,849
to mean if the government is doing it or

774
00:45:44,260 --> 00:45:48,530
if it's necessary for legitimate

775
00:45:46,849 --> 00:45:53,980
interests of the processor and doesn't

776
00:45:48,530 --> 00:45:56,630
violate privacy that's pretty open-ended

777
00:45:53,980 --> 00:45:58,670
doesn't violate privacy what does that

778
00:45:56,630 --> 00:46:04,220
mean the definition of privacy is it

779
00:45:58,670 --> 00:46:06,819
doesn't violate privacy there are some

780
00:46:04,220 --> 00:46:09,970
uses that they specifically prescribe

781
00:46:06,819 --> 00:46:11,990
there are certain things that that

782
00:46:09,970 --> 00:46:15,348
information you're not supposed to be

783
00:46:11,990 --> 00:46:16,819
using or revealing they say that you

784
00:46:15,349 --> 00:46:20,809
have to make data available to the

785
00:46:16,819 --> 00:46:22,788
subject in particular in some cases you

786
00:46:20,809 --> 00:46:26,390
have to give advance notice and right

787
00:46:22,789 --> 00:46:29,179
useful and they limit the use for

788
00:46:26,390 --> 00:46:33,739
automated decisions you can opt out of

789
00:46:29,179 --> 00:46:35,769
automated decision makings that things

790
00:46:33,739 --> 00:46:37,729
like the use is legitimate and

791
00:46:35,769 --> 00:46:40,178
safeguards are in place to protect a

792
00:46:37,729 --> 00:46:44,629
person's interest it's up to the

793
00:46:40,179 --> 00:46:46,369
processor of the data to show that not

794
00:46:44,630 --> 00:46:50,119
you as an individual having to prove

795
00:46:46,369 --> 00:46:52,009
that they misused it and logic involved

796
00:46:50,119 --> 00:46:55,459
in decisions must be available to the

797
00:46:52,009 --> 00:46:59,959
affected person always wanted to go to

798
00:46:55,459 --> 00:47:02,209
Europe and and go to fair isaac

799
00:46:59,959 --> 00:47:06,769
corporation and say hey I want your

800
00:47:02,209 --> 00:47:08,448
algorithm under EU law you have to tell

801
00:47:06,769 --> 00:47:10,308
me the logic to involved in decisions I

802
00:47:08,449 --> 00:47:13,789
want to know exactly how that credit

803
00:47:10,309 --> 00:47:16,669
score is computed might make an

804
00:47:13,789 --> 00:47:21,489
interesting case not a good computer

805
00:47:16,669 --> 00:47:23,989
science project though and I suspect a

806
00:47:21,489 --> 00:47:30,019
legal project that would not win in the

807
00:47:23,989 --> 00:47:31,219
long run several examples the u.s. is a

808
00:47:30,019 --> 00:47:33,468
little bit different we don't have an

809
00:47:31,219 --> 00:47:38,359
overarching privacy law we have sector

810
00:47:33,469 --> 00:47:40,880
specific laws HIPAA is one of them more

811
00:47:38,359 --> 00:47:46,549
well-known Health Insurance Portability

812
00:47:40,880 --> 00:47:48,919
and Accountability Act and part of it is

813
00:47:46,549 --> 00:47:51,589
these safe harbor rules which are

814
00:47:48,919 --> 00:47:54,529
somewhat unique in law they specifically

815
00:47:51,589 --> 00:47:59,299
say there are 19 identifiers if you

816
00:47:54,529 --> 00:48:04,669
remove those then the data is presumed

817
00:47:59,299 --> 00:48:07,429
to not be identifiable and some of these

818
00:48:04,669 --> 00:48:09,169
are generalizations like location you're

819
00:48:07,429 --> 00:48:12,049
allowed to use the first three digits of

820
00:48:09,169 --> 00:48:15,819
a postal code if that first three digits

821
00:48:12,049 --> 00:48:20,599
includes at least 10,000 people dates

822
00:48:15,819 --> 00:48:22,400
nothing finer than a year there's also a

823
00:48:20,599 --> 00:48:24,619
clause in there that scares people a bit

824
00:48:22,400 --> 00:48:29,019
which is you have no other reason to

825
00:48:24,619 --> 00:48:29,019
believe that the data is identifiable

826
00:48:31,220 --> 00:48:39,868
yeah I you know it's written in law it's

827
00:48:35,610 --> 00:48:42,600
okay to plead ignorance I don't think

828
00:48:39,869 --> 00:48:44,400
people are so you don't find a huge

829
00:48:42,600 --> 00:48:47,490
number of data sets that are released

830
00:48:44,400 --> 00:48:49,200
under safe harbor what people do is they

831
00:48:47,490 --> 00:48:50,790
tend to release data under a data use

832
00:48:49,200 --> 00:48:52,799
agreement it's not made publicly

833
00:48:50,790 --> 00:49:01,650
available it's made available just two

834
00:48:52,800 --> 00:49:05,190
people who sign the agreement but you

835
00:49:01,650 --> 00:49:07,380
know these are very specific and just

836
00:49:05,190 --> 00:49:10,770
talked about very narrow interpretations

837
00:49:07,380 --> 00:49:14,250
of privacy going back actually quite a

838
00:49:10,770 --> 00:49:19,410
bit farther in the past we have the u.s.

839
00:49:14,250 --> 00:49:27,540
Fair Information practices these aren't

840
00:49:19,410 --> 00:49:32,640
rules they are guidelines or aspirations

841
00:49:27,540 --> 00:49:34,890
and looking at these I think gives us

842
00:49:32,640 --> 00:49:39,859
more ideas for where privacy research

843
00:49:34,890 --> 00:49:41,520
should be going so transparency

844
00:49:39,859 --> 00:49:44,040
organizations should be transparent

845
00:49:41,520 --> 00:49:48,390
should notify individuals about what's

846
00:49:44,040 --> 00:49:50,160
going on with the data the individual

847
00:49:48,390 --> 00:49:51,480
should be involved in that process of

848
00:49:50,160 --> 00:49:58,680
using personally identifiable

849
00:49:51,480 --> 00:50:02,310
information you should talk about the

850
00:49:58,680 --> 00:50:06,000
purpose and articulate why it's okay to

851
00:50:02,310 --> 00:50:08,340
use for that purpose you should only

852
00:50:06,000 --> 00:50:11,940
collect data that's directly relevant

853
00:50:08,340 --> 00:50:14,280
necessary which all the people talking

854
00:50:11,940 --> 00:50:15,900
about big data it's like no no I want to

855
00:50:14,280 --> 00:50:17,580
collect everything because I don't know

856
00:50:15,900 --> 00:50:21,570
what it might be useful for but it might

857
00:50:17,580 --> 00:50:25,920
be some day and that flies right in the

858
00:50:21,570 --> 00:50:27,690
face of the phipps you should only use

859
00:50:25,920 --> 00:50:32,520
it for the purpose specified in the

860
00:50:27,690 --> 00:50:36,570
notice you should ensure that it's

861
00:50:32,520 --> 00:50:39,150
accurate relevant timely complete you

862
00:50:36,570 --> 00:50:41,670
should protect it and you should be

863
00:50:39,150 --> 00:50:45,470
accountable and auditable make sure that

864
00:50:41,670 --> 00:50:49,470
you follow these principles

865
00:50:45,470 --> 00:50:52,529
a lot of very good ideas and when we

866
00:50:49,470 --> 00:50:57,118
look at it find there's a lot of things

867
00:50:52,529 --> 00:51:00,769
that are important in here that existing

868
00:50:57,119 --> 00:51:03,150
privacy research doesn't even touch I

869
00:51:00,769 --> 00:51:05,549
think this opens up a lot of ways that

870
00:51:03,150 --> 00:51:09,990
we should think about what just like

871
00:51:05,549 --> 00:51:12,299
going back to the 70s and thinking about

872
00:51:09,990 --> 00:51:14,669
what people talked about then that open

873
00:51:12,299 --> 00:51:20,940
up new ideas for what we can be doing

874
00:51:14,670 --> 00:51:27,089
today in terms of providing privacy 40

875
00:51:20,940 --> 00:51:30,900
years some of other examples in Canada

876
00:51:27,089 --> 00:51:34,890
they have pop ADA which is a general

877
00:51:30,900 --> 00:51:37,079
overview law and they have some

878
00:51:34,890 --> 00:51:39,269
interesting statements may collect user

879
00:51:37,079 --> 00:51:41,220
disclose personal information only for

880
00:51:39,269 --> 00:51:43,078
purposes that a reasonable person would

881
00:51:41,220 --> 00:51:47,910
consider are appropriate in the

882
00:51:43,079 --> 00:51:50,849
circumstances again very hard to say

883
00:51:47,910 --> 00:51:59,250
what that is it's it's one of these well

884
00:51:50,849 --> 00:52:01,109
I know what when I see it you know may

885
00:51:59,250 --> 00:52:05,910
have several more specific principles

886
00:52:01,109 --> 00:52:08,308
very detailed another one that I think

887
00:52:05,910 --> 00:52:12,000
is very good is the Australian privacy

888
00:52:08,309 --> 00:52:16,140
principles if you're interested in going

889
00:52:12,000 --> 00:52:20,009
into research into privacy or looking at

890
00:52:16,140 --> 00:52:21,509
new ways of thinking about privacy they

891
00:52:20,009 --> 00:52:23,339
give one of the nice things about the

892
00:52:21,509 --> 00:52:27,809
Australian privacy principles is they

893
00:52:23,339 --> 00:52:34,049
actually give examples and how the law

894
00:52:27,809 --> 00:52:35,160
ought to apply to those examples and so

895
00:52:34,049 --> 00:52:38,190
there's some very interesting

896
00:52:35,160 --> 00:52:42,629
information in here and again they talk

897
00:52:38,190 --> 00:52:47,609
about many of the same things that we

898
00:52:42,630 --> 00:52:50,519
see in these other principles but also

899
00:52:47,609 --> 00:52:52,970
in some of it very specific some of it

900
00:52:50,519 --> 00:52:52,970
less specific

901
00:52:53,800 --> 00:53:02,950
and okay but I think we can even find

902
00:53:00,730 --> 00:53:07,290
some things going beyond this so we did

903
00:53:02,950 --> 00:53:12,180
a study of privacy preferences in

904
00:53:07,290 --> 00:53:14,800
collaborative search so the idea was

905
00:53:12,180 --> 00:53:17,549
you're searching you have several people

906
00:53:14,800 --> 00:53:21,010
who are collaborating on a task and

907
00:53:17,550 --> 00:53:27,160
you're using one person search results

908
00:53:21,010 --> 00:53:30,370
to help another and this was a search

909
00:53:27,160 --> 00:53:31,779
engine they were building and they

910
00:53:30,370 --> 00:53:33,190
started looking and saying you know what

911
00:53:31,780 --> 00:53:35,020
about sharing how is this information

912
00:53:33,190 --> 00:53:37,240
shared what are the privacy how does

913
00:53:35,020 --> 00:53:42,420
privacy affect this so what they did

914
00:53:37,240 --> 00:53:45,339
with a set of prior expectations in this

915
00:53:42,420 --> 00:53:47,980
they're using it in a variety of real

916
00:53:45,340 --> 00:53:50,500
scenarios to help in getting feedback on

917
00:53:47,980 --> 00:53:52,030
that tool but at the same time let's say

918
00:53:50,500 --> 00:53:54,400
let's try to find out what they really

919
00:53:52,030 --> 00:53:57,760
want in terms of privacy so they just

920
00:53:54,400 --> 00:54:00,160
said tell us what you want not here's a

921
00:53:57,760 --> 00:54:02,920
language specify them in this language

922
00:54:00,160 --> 00:54:08,350
not which boxes do you check just tell

923
00:54:02,920 --> 00:54:10,660
us what you want and the policies were

924
00:54:08,350 --> 00:54:12,850
then analyzed manually to figure out

925
00:54:10,660 --> 00:54:16,359
what this meant some interesting things

926
00:54:12,850 --> 00:54:18,190
came up that don't show up at all in any

927
00:54:16,360 --> 00:54:20,470
of that previous discussion so for

928
00:54:18,190 --> 00:54:24,970
example one that came up consistently

929
00:54:20,470 --> 00:54:27,220
was reciprocity i will share information

930
00:54:24,970 --> 00:54:30,399
with people who will share the same kind

931
00:54:27,220 --> 00:54:32,500
of information with me you see that

932
00:54:30,400 --> 00:54:34,450
nowhere in any of these regulations and

933
00:54:32,500 --> 00:54:36,610
yet that was one of the things that

934
00:54:34,450 --> 00:54:42,549
showed up most commonly in people's

935
00:54:36,610 --> 00:54:44,470
preferences so I think there may be

936
00:54:42,550 --> 00:54:46,660
things people want in terms of privacy

937
00:54:44,470 --> 00:54:49,680
that go well beyond what we're talking

938
00:54:46,660 --> 00:54:52,450
you know what we even think of today in

939
00:54:49,680 --> 00:54:54,580
any of these law much less what we do in

940
00:54:52,450 --> 00:54:59,290
research and so I think it's a wide-open

941
00:54:54,580 --> 00:55:03,270
area some other common things context

942
00:54:59,290 --> 00:55:06,370
location-based restrictions query term

943
00:55:03,270 --> 00:55:07,480
time-based restrictions I only want to

944
00:55:06,370 --> 00:55:09,580
share

945
00:55:07,480 --> 00:55:16,359
with my work group the things i actually

946
00:55:09,580 --> 00:55:18,009
do during work hours I can give later if

947
00:55:16,359 --> 00:55:19,680
you want to talk to me about it I can

948
00:55:18,010 --> 00:55:25,180
give a very specific example of

949
00:55:19,680 --> 00:55:27,160
something going very wrong there anyway

950
00:55:25,180 --> 00:55:31,899
any questions on this I think we're

951
00:55:27,160 --> 00:55:34,930
pretty much out of time but he questions

952
00:55:31,900 --> 00:55:38,290
comments they say if you have thoughts

953
00:55:34,930 --> 00:55:41,410
ideas discussion feel free to come talk

954
00:55:38,290 --> 00:55:44,619
to me at some point and then this is an

955
00:55:41,410 --> 00:55:51,000
open and I think a burgeoning area to be

956
00:55:44,619 --> 00:55:51,000
working in thank you

