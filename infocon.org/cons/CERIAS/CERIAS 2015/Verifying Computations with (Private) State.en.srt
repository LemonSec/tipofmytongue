1
00:00:37,590 --> 00:00:44,470
said that I need to wake so good

2
00:00:42,100 --> 00:00:47,860
afternoon welcome to the serious

3
00:00:44,470 --> 00:00:50,710
security seminar series so today is my

4
00:00:47,860 --> 00:00:53,559
great pleasure to introduce dr. ariel of

5
00:00:50,710 --> 00:00:56,050
freeman from my university of chicago re

6
00:00:53,559 --> 00:00:58,870
is a assistant professor of computer

7
00:00:56,050 --> 00:01:01,569
science at the chicago he's a research

8
00:00:58,870 --> 00:01:04,119
lies at the intersection of computer

9
00:01:01,570 --> 00:01:07,030
security and distributed systems he is

10
00:01:04,119 --> 00:01:08,920
presently focused on finding new ways to

11
00:01:07,030 --> 00:01:11,890
protect the security and privacy of

12
00:01:08,920 --> 00:01:13,630
users of cloud hosted services his

13
00:01:11,890 --> 00:01:16,630
interests also includes software and

14
00:01:13,630 --> 00:01:19,240
network security data privacy anonymity

15
00:01:16,630 --> 00:01:21,460
and electronic voting as well as the

16
00:01:19,240 --> 00:01:24,610
interaction between computer security

17
00:01:21,460 --> 00:01:26,919
law and public policy previously he was

18
00:01:24,610 --> 00:01:28,300
a postdoc researcher at the CIS

19
00:01:26,920 --> 00:01:31,119
department at the University of

20
00:01:28,300 --> 00:01:32,500
Pennsylvania and he received his PhD in

21
00:01:31,119 --> 00:01:36,630
computer science from Princeton

22
00:01:32,500 --> 00:01:39,580
University in 2012 re yes thanks so much

23
00:01:36,630 --> 00:01:40,949
so good afternoon as he said I marty

24
00:01:39,580 --> 00:01:44,170
Feldman and i'll be talking about

25
00:01:40,950 --> 00:01:46,479
verifying computations with and without

26
00:01:44,170 --> 00:01:49,030
private state and i'll get to what that

27
00:01:46,479 --> 00:01:52,200
is later on and the material in this

28
00:01:49,030 --> 00:01:55,509
talk is based on joint work with

29
00:01:52,200 --> 00:01:58,329
professors and students at the

30
00:01:55,509 --> 00:02:03,070
university of texas at austin as well as

31
00:01:58,329 --> 00:02:06,520
the university of pennsylvania so as

32
00:02:03,070 --> 00:02:08,859
computing permeates ever more aspects of

33
00:02:06,520 --> 00:02:11,620
society we increasingly participate in

34
00:02:08,860 --> 00:02:14,920
complex systems where we rely on

35
00:02:11,620 --> 00:02:18,700
computation performed by others so this

36
00:02:14,920 --> 00:02:20,649
includes cloud services that are pretty

37
00:02:18,700 --> 00:02:24,160
familiar like Amazon Web Services

38
00:02:20,650 --> 00:02:27,220
Microsoft Azure the various Google

39
00:02:24,160 --> 00:02:30,130
services and so on it also it also

40
00:02:27,220 --> 00:02:31,810
includes Internet of Things devices the

41
00:02:30,130 --> 00:02:34,930
so-called Internet of Things devices

42
00:02:31,810 --> 00:02:39,820
which include the thing on the left is a

43
00:02:34,930 --> 00:02:42,070
smart meter these devices that track how

44
00:02:39,820 --> 00:02:45,459
we drive to decide how much we should be

45
00:02:42,070 --> 00:02:49,780
billed for auto insurance navigation

46
00:02:45,459 --> 00:02:52,740
devices like GPS navigation devices

47
00:02:49,780 --> 00:02:55,150
and another perhaps less recognized

48
00:02:52,740 --> 00:02:58,209
example of relying on the computation

49
00:02:55,150 --> 00:03:01,900
done by others is research studies often

50
00:02:58,209 --> 00:03:05,560
based on common data sets such as those

51
00:03:01,900 --> 00:03:07,870
from the US Census Bureau or those from

52
00:03:05,560 --> 00:03:10,840
from other data repositories like I dash

53
00:03:07,870 --> 00:03:14,830
which is a repository of biomedical data

54
00:03:10,840 --> 00:03:16,900
at UCSD so we rely on computation by a

55
00:03:14,830 --> 00:03:19,060
lot of different parties and these

56
00:03:16,900 --> 00:03:21,550
parties may not have the same interests

57
00:03:19,060 --> 00:03:26,110
that we do sometimes their interests are

58
00:03:21,550 --> 00:03:29,320
even at odds with us and so this leads

59
00:03:26,110 --> 00:03:31,269
to a number of problems so it's well

60
00:03:29,320 --> 00:03:33,280
known that this leads to privacy

61
00:03:31,269 --> 00:03:34,930
problems a lot of people have have

62
00:03:33,280 --> 00:03:38,920
talked about this this has gotten a lot

63
00:03:34,930 --> 00:03:42,459
of attention you know there have been

64
00:03:38,920 --> 00:03:44,649
breaches by external attackers to cloud

65
00:03:42,459 --> 00:03:46,930
services there have been changes in

66
00:03:44,650 --> 00:03:49,660
privacy policies of the various entities

67
00:03:46,930 --> 00:03:51,940
that we interact with and who hold our

68
00:03:49,660 --> 00:03:54,370
data you know potentially using our data

69
00:03:51,940 --> 00:03:56,230
in ways that we didn't expect there's

70
00:03:54,370 --> 00:03:59,440
the possibility of government pressure

71
00:03:56,230 --> 00:04:03,730
and surveillance even there's also the

72
00:03:59,440 --> 00:04:06,100
risk of accidental leaks due to bugs or

73
00:04:03,730 --> 00:04:09,070
even d anonymization of the results of

74
00:04:06,100 --> 00:04:12,730
release data so I'm not going to talk

75
00:04:09,070 --> 00:04:15,940
that much about the most of these

76
00:04:12,730 --> 00:04:18,608
threats to privacy except for accidental

77
00:04:15,940 --> 00:04:20,798
leaks however I have worked on them in

78
00:04:18,608 --> 00:04:23,770
the past what I will be talking about

79
00:04:20,798 --> 00:04:26,320
mainly today are sort of another class

80
00:04:23,770 --> 00:04:28,599
of problems that arise when we rely on

81
00:04:26,320 --> 00:04:31,330
computation done by others and that is

82
00:04:28,600 --> 00:04:33,640
threats to the integrity of our data and

83
00:04:31,330 --> 00:04:36,310
the computations that are performed on

84
00:04:33,640 --> 00:04:39,250
it by these other parties who rely on

85
00:04:36,310 --> 00:04:42,100
and the reality is that these

86
00:04:39,250 --> 00:04:44,919
computations can fail in Byzantine ways

87
00:04:42,100 --> 00:04:46,570
leading to arbitrarily corrupt results

88
00:04:44,919 --> 00:04:49,060
and these faults could be malicious

89
00:04:46,570 --> 00:04:52,229
these third parties might have the

90
00:04:49,060 --> 00:04:55,180
incentive to simply behave incorrectly

91
00:04:52,229 --> 00:04:57,219
deviate from correct execution but of

92
00:04:55,180 --> 00:04:59,310
course these faults could also be

93
00:04:57,220 --> 00:05:01,780
non-malicious they could be a result of

94
00:04:59,310 --> 00:05:03,370
corrupt inputs they could be a result of

95
00:05:01,780 --> 00:05:07,239
miss configuration

96
00:05:03,370 --> 00:05:14,440
of software bugs or heart or hardware

97
00:05:07,240 --> 00:05:16,630
faults and right now I argue that the

98
00:05:14,440 --> 00:05:19,139
main tools that we that we use to

99
00:05:16,630 --> 00:05:21,669
mitigate these are mostly sort of

100
00:05:19,139 --> 00:05:24,520
non-technical they're legal or

101
00:05:21,669 --> 00:05:26,530
market-based so we have laws we have

102
00:05:24,520 --> 00:05:28,690
government regulations on the handling

103
00:05:26,530 --> 00:05:30,760
of data we have court decisions and then

104
00:05:28,690 --> 00:05:33,699
we have promises made by these various

105
00:05:30,760 --> 00:05:35,740
entities privacy policies service level

106
00:05:33,699 --> 00:05:37,720
agreements and so forth but I'd argue

107
00:05:35,740 --> 00:05:40,870
that these non technical methods aren't

108
00:05:37,720 --> 00:05:42,789
enough and in particular they aren't

109
00:05:40,870 --> 00:05:47,530
enough for dealing with problems of

110
00:05:42,789 --> 00:05:50,380
integrity and the reason is because in

111
00:05:47,530 --> 00:05:53,469
many cases miss behavior by these

112
00:05:50,380 --> 00:05:56,380
parties is very hard to detect and if

113
00:05:53,470 --> 00:05:59,100
you don't even know that the parties are

114
00:05:56,380 --> 00:06:02,169
misbehaving either intentionally or not

115
00:05:59,100 --> 00:06:04,720
these non technical methods can't work

116
00:06:02,169 --> 00:06:06,460
well you can't really sort of have an

117
00:06:04,720 --> 00:06:08,349
enforcement mechanism if you don't even

118
00:06:06,460 --> 00:06:10,750
know that things are going wrong so for

119
00:06:08,349 --> 00:06:13,240
example if you outsource a computation

120
00:06:10,750 --> 00:06:15,550
on a large amount of data you know that

121
00:06:13,240 --> 00:06:18,970
may take hours this computation and then

122
00:06:15,550 --> 00:06:21,039
get back a result how do you know that

123
00:06:18,970 --> 00:06:24,070
you know this was act the result was

124
00:06:21,039 --> 00:06:26,200
actually computed correctly you know so

125
00:06:24,070 --> 00:06:29,169
that you would be able to enforce some

126
00:06:26,200 --> 00:06:31,240
kind of you know legal mechanism or some

127
00:06:29,169 --> 00:06:35,169
kind of contract or something like that

128
00:06:31,240 --> 00:06:37,330
and so as an alternative that one of the

129
00:06:35,169 --> 00:06:40,030
main things that I work on is the idea

130
00:06:37,330 --> 00:06:42,460
of designing systems for verifiability

131
00:06:40,030 --> 00:06:44,979
that is assuming that system

132
00:06:42,460 --> 00:06:46,840
participants are untrusted and providing

133
00:06:44,979 --> 00:06:50,800
the participants with enough information

134
00:06:46,840 --> 00:06:52,989
to check that others are executing

135
00:06:50,800 --> 00:06:55,870
correctly rather than simply relying on

136
00:06:52,990 --> 00:06:59,349
their promises and one of the other

137
00:06:55,870 --> 00:07:02,110
things that I'll be talking about today

138
00:06:59,349 --> 00:07:04,419
that is nice about designing systems for

139
00:07:02,110 --> 00:07:07,840
verifiability is that it opens the door

140
00:07:04,419 --> 00:07:10,120
for new applications such as that this

141
00:07:07,840 --> 00:07:11,859
verification can be done in zero

142
00:07:10,120 --> 00:07:14,860
knowledge something that wasn't possible

143
00:07:11,860 --> 00:07:16,270
before which is which means that you

144
00:07:14,860 --> 00:07:18,610
could verify some

145
00:07:16,270 --> 00:07:20,440
else's behavior even if you didn't

146
00:07:18,610 --> 00:07:25,180
necessarily know the inputs to the

147
00:07:20,440 --> 00:07:29,380
computation that they performed and I

148
00:07:25,180 --> 00:07:30,610
also want to note that this this what

149
00:07:29,380 --> 00:07:33,310
I'm going to be talking about this

150
00:07:30,610 --> 00:07:36,010
method of verifying computations is

151
00:07:33,310 --> 00:07:38,490
different from program verification so

152
00:07:36,010 --> 00:07:43,030
program verification is concerned with

153
00:07:38,490 --> 00:07:45,940
determining whether a particular program

154
00:07:43,030 --> 00:07:50,559
matches a specification whereas what

155
00:07:45,940 --> 00:07:54,820
I'll be talking about today is given

156
00:07:50,560 --> 00:07:58,120
that you given that you have some code

157
00:07:54,820 --> 00:08:00,490
and given that assuming that you know

158
00:07:58,120 --> 00:08:03,190
what it does if you give it to someone

159
00:08:00,490 --> 00:08:07,000
else can you verify that they have

160
00:08:03,190 --> 00:08:09,610
executed that code correctly and so i'll

161
00:08:07,000 --> 00:08:12,100
be talking about two systems in this

162
00:08:09,610 --> 00:08:14,800
vein that that i've been part of that

163
00:08:12,100 --> 00:08:19,570
I've worked on with my collaborators the

164
00:08:14,800 --> 00:08:22,080
first is called pantry which is a system

165
00:08:19,570 --> 00:08:24,730
for outsourcing computations and

166
00:08:22,080 --> 00:08:26,859
verifying the results verifying that

167
00:08:24,730 --> 00:08:29,170
some other party who you outsource the

168
00:08:26,860 --> 00:08:32,050
computation to executed it correctly

169
00:08:29,170 --> 00:08:34,330
that is sometimes practical and I'll get

170
00:08:32,049 --> 00:08:35,890
to what what I mean by that and the

171
00:08:34,330 --> 00:08:38,620
other system i'll be talking about is

172
00:08:35,890 --> 00:08:41,640
called verde p which was at your assist

173
00:08:38,620 --> 00:08:44,500
this year which is about how you do

174
00:08:41,640 --> 00:08:47,439
verifiable and privacy preserving data

175
00:08:44,500 --> 00:08:48,880
analysis such as in the case of a

176
00:08:47,440 --> 00:08:50,680
research study you want to convince

177
00:08:48,880 --> 00:08:55,750
others that your the results of your

178
00:08:50,680 --> 00:08:59,079
research study are correct so while

179
00:08:55,750 --> 00:09:02,770
still preserving privacy so let's start

180
00:08:59,080 --> 00:09:05,140
with pantry so the goal of pantry is to

181
00:09:02,770 --> 00:09:07,750
be able to outsource computation to an

182
00:09:05,140 --> 00:09:10,360
untrusted provider running a set of

183
00:09:07,750 --> 00:09:16,840
untrusted servers so this is you know

184
00:09:10,360 --> 00:09:18,700
like the Amazon ec2 style case and there

185
00:09:16,840 --> 00:09:20,590
are a couple of goals that we had for

186
00:09:18,700 --> 00:09:25,060
pantry the first is that we wanted it to

187
00:09:20,590 --> 00:09:28,899
be practical at least you know for some

188
00:09:25,060 --> 00:09:30,430
uses and so one of the most basic

189
00:09:28,899 --> 00:09:32,709
terms of practicality for outsourced

190
00:09:30,430 --> 00:09:35,319
computation is that it's worthwhile for

191
00:09:32,709 --> 00:09:38,290
the client that is that it's actually

192
00:09:35,319 --> 00:09:40,029
cheaper for the client to ask someone

193
00:09:38,290 --> 00:09:41,769
else to do the work than to do it

194
00:09:40,029 --> 00:09:45,040
themselves because obviously if you

195
00:09:41,769 --> 00:09:46,899
don't even meet that bar then unless

196
00:09:45,040 --> 00:09:48,939
you're you're adding some other feature

197
00:09:46,899 --> 00:09:52,179
like zero knowledge there really isn't

198
00:09:48,939 --> 00:09:53,920
any reason to do it the other thing is

199
00:09:52,179 --> 00:09:56,079
we wanted to support realistic

200
00:09:53,920 --> 00:09:58,779
applications such as MapReduce

201
00:09:56,079 --> 00:10:02,378
computations and database computations

202
00:09:58,779 --> 00:10:04,600
and finally we one of the system to be

203
00:10:02,379 --> 00:10:07,420
designed for verifiability we wanted it

204
00:10:04,600 --> 00:10:09,699
to be efficient for users of these

205
00:10:07,420 --> 00:10:14,579
services to be able to efficiently

206
00:10:09,699 --> 00:10:16,839
verify computation results so given this

207
00:10:14,579 --> 00:10:19,479
problem domain there are a number of

208
00:10:16,839 --> 00:10:22,629
possible approaches that might come to

209
00:10:19,480 --> 00:10:26,110
mind the first is to sort of audit

210
00:10:22,629 --> 00:10:28,089
random samples of the computation

211
00:10:26,110 --> 00:10:30,910
results maybe you sort of re execute the

212
00:10:28,089 --> 00:10:32,860
computation on on sort of portions of

213
00:10:30,910 --> 00:10:35,620
the input or parts of the computation

214
00:10:32,860 --> 00:10:38,679
but it's hard to catch small errors

215
00:10:35,620 --> 00:10:40,779
without doing a lot of auditing if you

216
00:10:38,679 --> 00:10:42,879
just audit random samples it's kind of a

217
00:10:40,779 --> 00:10:45,670
needle in the haystack problem another

218
00:10:42,879 --> 00:10:48,370
alternative is to kind of you know do a

219
00:10:45,670 --> 00:10:51,370
bft style design and run multiple

220
00:10:48,370 --> 00:10:55,319
replicas of the computation but this

221
00:10:51,370 --> 00:10:58,569
assumes that the faults are uncorrelated

222
00:10:55,319 --> 00:11:00,819
another approach would be to take

223
00:10:58,569 --> 00:11:03,459
advantage of trusted hardware and use

224
00:11:00,819 --> 00:11:05,740
remote attestation to have the trusted

225
00:11:03,459 --> 00:11:07,989
Hardware attest to the fact that some

226
00:11:05,740 --> 00:11:11,559
particular code is running on the remote

227
00:11:07,990 --> 00:11:14,079
system but of course that requires an

228
00:11:11,559 --> 00:11:15,819
additional assumption and you know you

229
00:11:14,079 --> 00:11:18,878
can also create special purpose

230
00:11:15,819 --> 00:11:20,829
protocols which may be efficient they

231
00:11:18,879 --> 00:11:23,019
may even be more efficient than general

232
00:11:20,829 --> 00:11:25,628
purpose verifiable computation but

233
00:11:23,019 --> 00:11:28,990
they're difficult to create and to prove

234
00:11:25,629 --> 00:11:31,179
correct and so what we want is something

235
00:11:28,990 --> 00:11:33,910
that sort of covers the broadest

236
00:11:31,179 --> 00:11:36,959
possible set of programs that we can

237
00:11:33,910 --> 00:11:39,429
that we can conceivably outsource and so

238
00:11:36,959 --> 00:11:41,160
we want something that's general purpose

239
00:11:39,429 --> 00:11:42,640
and we want something that has

240
00:11:41,160 --> 00:11:44,740
unconditional

241
00:11:42,640 --> 00:11:46,330
guarantees in the sense that we only

242
00:11:44,740 --> 00:11:48,970
rely on let's say cryptographic

243
00:11:46,330 --> 00:11:51,400
assumptions rather than assumptions that

244
00:11:48,970 --> 00:11:56,080
for example the remote party runs some

245
00:11:51,400 --> 00:11:58,510
piece of trusted hardware so in theory

246
00:11:56,080 --> 00:12:01,840
we know how to do this we can just use

247
00:11:58,510 --> 00:12:04,810
probabilistically checkable proofs and

248
00:12:01,840 --> 00:12:08,620
there are pcp based argument systems

249
00:12:04,810 --> 00:12:10,479
where a client has some input X and some

250
00:12:08,620 --> 00:12:12,670
function f that they want to outsource

251
00:12:10,480 --> 00:12:16,180
and they send those things to a server

252
00:12:12,670 --> 00:12:20,349
and the server responds with a result y

253
00:12:16,180 --> 00:12:24,339
which is purportedly equal to f of X as

254
00:12:20,350 --> 00:12:28,240
well as a proof pi that that is indeed

255
00:12:24,340 --> 00:12:30,700
the case so in principle we could do

256
00:12:28,240 --> 00:12:33,940
this and in fact the PC piece theorem

257
00:12:30,700 --> 00:12:35,950
states that the client only needs to

258
00:12:33,940 --> 00:12:38,710
inspect this proof in a constant number

259
00:12:35,950 --> 00:12:41,650
of locations regardless of the

260
00:12:38,710 --> 00:12:43,720
computation unfortunately just simply

261
00:12:41,650 --> 00:12:46,569
applying this to the problem doesn't

262
00:12:43,720 --> 00:12:49,630
work so well in practice this sort of

263
00:12:46,570 --> 00:12:52,600
traditional as in you know maybe prior

264
00:12:49,630 --> 00:12:54,910
to the past five years PCP based systems

265
00:12:52,600 --> 00:12:58,030
are really slow and I mean really slow

266
00:12:54,910 --> 00:13:01,329
so for example verifying the result of a

267
00:12:58,030 --> 00:13:03,689
500 x 500 matrix multiply would take

268
00:13:01,330 --> 00:13:07,390
more than something like 500 trillion

269
00:13:03,690 --> 00:13:09,150
CPU years fortunately within the past

270
00:13:07,390 --> 00:13:12,120
five years there have been a number of

271
00:13:09,150 --> 00:13:15,189
advances in this area of verifiable

272
00:13:12,120 --> 00:13:18,010
computation that have led to many orders

273
00:13:15,190 --> 00:13:20,950
of magnitude of cost reduction and have

274
00:13:18,010 --> 00:13:23,290
yield have yielded built systems that

275
00:13:20,950 --> 00:13:27,390
for example have compilers that compile

276
00:13:23,290 --> 00:13:27,390
high-level languages like C into

277
00:13:27,540 --> 00:13:33,219
representations that are amenable to

278
00:13:30,270 --> 00:13:35,650
doing this kind of proof based

279
00:13:33,220 --> 00:13:37,540
verifiable computation and a number of

280
00:13:35,650 --> 00:13:41,140
different groups have worked on this

281
00:13:37,540 --> 00:13:46,020
problem and the system that I'm going to

282
00:13:41,140 --> 00:13:52,930
discuss pantry is based on two of them

283
00:13:46,020 --> 00:13:54,699
zatar and Pinocchio so what does what

284
00:13:52,930 --> 00:13:55,989
does pantry do well there's another

285
00:13:54,700 --> 00:14:00,399
problem

286
00:13:55,990 --> 00:14:02,290
with pcp based systems with prior pcp

287
00:14:00,399 --> 00:14:06,070
based systems and that is that they were

288
00:14:02,290 --> 00:14:08,290
stateless that is that whenever you

289
00:14:06,070 --> 00:14:10,420
wanted to outsource a computation you

290
00:14:08,290 --> 00:14:12,699
had to send all of the input from the

291
00:14:10,420 --> 00:14:16,329
client to the server along with your

292
00:14:12,700 --> 00:14:19,420
function and the output had to be sent

293
00:14:16,330 --> 00:14:22,029
all of the output had to be sent back to

294
00:14:19,420 --> 00:14:24,430
the client which is obviously sort of

295
00:14:22,029 --> 00:14:28,630
not a practical situation for the sort

296
00:14:24,430 --> 00:14:30,880
of outsourced computations on sort of

297
00:14:28,630 --> 00:14:35,040
large data sets that we're hoping to be

298
00:14:30,880 --> 00:14:37,570
able to do such as you know MapReduce

299
00:14:35,040 --> 00:14:40,029
processes as well as you know database

300
00:14:37,570 --> 00:14:42,250
queries and that sort of thing it's

301
00:14:40,029 --> 00:14:46,630
really impractical to you know pay that

302
00:14:42,250 --> 00:14:49,300
kind of network cost so you know as a

303
00:14:46,630 --> 00:14:52,500
result you know we need to do something

304
00:14:49,300 --> 00:14:55,120
more and so what pantry does is combined

305
00:14:52,500 --> 00:14:58,089
recent advances in verifiable

306
00:14:55,120 --> 00:15:01,480
computation with untrusted server

307
00:14:58,089 --> 00:15:05,170
storage so what it does is that it gives

308
00:15:01,480 --> 00:15:07,570
the server access to some untrusted

309
00:15:05,170 --> 00:15:11,349
storage some some storage that the

310
00:15:07,570 --> 00:15:14,649
client does not need to trust and then

311
00:15:11,350 --> 00:15:17,260
the proof of correct computation that

312
00:15:14,649 --> 00:15:19,209
the server returns to the client not

313
00:15:17,260 --> 00:15:21,910
only states that the function was

314
00:15:19,209 --> 00:15:24,729
evaluated correctly but that all reads

315
00:15:21,910 --> 00:15:27,730
and writes to this untrusted storage

316
00:15:24,730 --> 00:15:30,100
were done correctly so all of the reeds

317
00:15:27,730 --> 00:15:32,589
actually fetch data that was really

318
00:15:30,100 --> 00:15:35,850
there in the untrusted storage and all

319
00:15:32,589 --> 00:15:38,920
rights actually wrote the correct values

320
00:15:35,850 --> 00:15:41,200
correctly computed by F back to the

321
00:15:38,920 --> 00:15:44,649
storage so that for example if a

322
00:15:41,200 --> 00:15:47,440
subsequent computation accessed it you

323
00:15:44,649 --> 00:15:49,930
could actually say something as the

324
00:15:47,440 --> 00:15:53,170
client about what that what that storage

325
00:15:49,930 --> 00:15:54,479
contained so to explain how this works I

326
00:15:53,170 --> 00:15:58,750
just want to provide some background

327
00:15:54,480 --> 00:16:01,720
about the about verifying a computation

328
00:15:58,750 --> 00:16:06,339
and in particular the way that zatar and

329
00:16:01,720 --> 00:16:08,079
pinocchio work so this process of

330
00:16:06,339 --> 00:16:09,580
verifying a computation basically

331
00:16:08,079 --> 00:16:13,599
proceeds in three steps

332
00:16:09,580 --> 00:16:16,930
first the client compiles the program to

333
00:16:13,600 --> 00:16:19,210
a circuit representation which

334
00:16:16,930 --> 00:16:21,430
implements a series of algebraic

335
00:16:19,210 --> 00:16:23,710
constraints there's basically sort of

336
00:16:21,430 --> 00:16:25,260
you can think about it as a system of

337
00:16:23,710 --> 00:16:28,620
equations where each equation

338
00:16:25,260 --> 00:16:32,890
corresponds to one gate in the circuit

339
00:16:28,620 --> 00:16:34,870
then that sort of sir that compiled

340
00:16:32,890 --> 00:16:37,780
representation is sent to the server and

341
00:16:34,870 --> 00:16:40,540
the server finds a satisfying assignment

342
00:16:37,780 --> 00:16:43,930
to these constraints that is finds an

343
00:16:40,540 --> 00:16:47,020
assignment to all of the variables all

344
00:16:43,930 --> 00:16:49,150
of the variables in those equations to

345
00:16:47,020 --> 00:16:52,120
make them all hold simultaneously and

346
00:16:49,150 --> 00:16:54,310
then finally the server proves that it

347
00:16:52,120 --> 00:16:58,480
knows this satisfying assignment to the

348
00:16:54,310 --> 00:17:01,479
client so let me explain how these three

349
00:16:58,480 --> 00:17:04,569
steps work in more detail so the first

350
00:17:01,480 --> 00:17:08,530
is actually making and satisfying these

351
00:17:04,569 --> 00:17:10,919
constraints so for any for any program

352
00:17:08,530 --> 00:17:13,780
written in a high-level language

353
00:17:10,920 --> 00:17:16,870
basically each program construct is

354
00:17:13,780 --> 00:17:18,639
converted into a series of constraints

355
00:17:16,869 --> 00:17:22,899
so suppose we had this simple program

356
00:17:18,640 --> 00:17:26,830
add 5 which simply takes an input X as a

357
00:17:22,900 --> 00:17:30,160
parameter adds 5 to it and returns the

358
00:17:26,829 --> 00:17:34,419
value so you can compile these into

359
00:17:30,160 --> 00:17:37,150
these two constraints on the right over

360
00:17:34,420 --> 00:17:40,260
there and these constraints are chosen

361
00:17:37,150 --> 00:17:43,420
by the compiler so that they are

362
00:17:40,260 --> 00:17:47,890
satisfiable if and only if the output is

363
00:17:43,420 --> 00:17:49,660
correct given the input X and so

364
00:17:47,890 --> 00:17:54,040
basically the compiler for each

365
00:17:49,660 --> 00:17:56,200
potential program construct creates an

366
00:17:54,040 --> 00:18:00,340
equivalent set of constraints so suppose

367
00:17:56,200 --> 00:18:03,460
you had an input X well then if the

368
00:18:00,340 --> 00:18:06,820
server computes correctly and outputs y

369
00:18:03,460 --> 00:18:09,250
equals 9 it's possible to satisfy both

370
00:18:06,820 --> 00:18:11,409
of these constraints simultaneously but

371
00:18:09,250 --> 00:18:14,980
suppose that the server claims that the

372
00:18:11,410 --> 00:18:17,440
output Y is 10 then it's not possible to

373
00:18:14,980 --> 00:18:21,420
satisfy these constraints and so

374
00:18:17,440 --> 00:18:23,140
therefore finding an assignment is

375
00:18:21,420 --> 00:18:26,320
tantamount

376
00:18:23,140 --> 00:18:28,720
correct execution it's only possible to

377
00:18:26,320 --> 00:18:31,659
find a satisfying assignment if and only

378
00:18:28,720 --> 00:18:35,290
if the program was executed correctly

379
00:18:31,660 --> 00:18:38,470
and this can be done for more complex

380
00:18:35,290 --> 00:18:41,200
program constructions so you know you

381
00:18:38,470 --> 00:18:44,830
can do this for branches and four

382
00:18:41,200 --> 00:18:47,880
inequalities and for loops and so on so

383
00:18:44,830 --> 00:18:50,590
for example if you had this not equal

384
00:18:47,880 --> 00:18:52,840
condition you can represent it as the

385
00:18:50,590 --> 00:18:56,169
two constraints on the bottom left and

386
00:18:52,840 --> 00:19:01,270
basically you can see that if x1 equals

387
00:18:56,170 --> 00:19:03,190
x2 then you have to set y equal zero in

388
00:19:01,270 --> 00:19:06,790
order to satisfy the first constraint

389
00:19:03,190 --> 00:19:10,690
whereas if X 1 is not equal to x2 then

390
00:19:06,790 --> 00:19:13,270
you have to set y equal to 1 in order to

391
00:19:10,690 --> 00:19:14,920
satisfy the second constraint and so

392
00:19:13,270 --> 00:19:18,310
these two constraints when taken

393
00:19:14,920 --> 00:19:21,340
together make sure that the result of

394
00:19:18,310 --> 00:19:25,899
the not equal operation is actually

395
00:19:21,340 --> 00:19:28,629
correct so once this satisfying

396
00:19:25,900 --> 00:19:30,630
assignment is found the server needs to

397
00:19:28,630 --> 00:19:34,480
prove to the client that it's actually

398
00:19:30,630 --> 00:19:36,040
that's actually really dumb this so the

399
00:19:34,480 --> 00:19:40,360
simplest thing you could imagine it

400
00:19:36,040 --> 00:19:44,350
doing is simply sending over as the

401
00:19:40,360 --> 00:19:46,030
proof the list of assignments values

402
00:19:44,350 --> 00:19:48,159
assigned to all of the sort of

403
00:19:46,030 --> 00:19:50,680
intermediate variables of all of these

404
00:19:48,160 --> 00:19:52,960
constraints but this is that but

405
00:19:50,680 --> 00:19:55,570
verifying this is actually as expensive

406
00:19:52,960 --> 00:19:58,540
as doing the computation over again

407
00:19:55,570 --> 00:20:01,510
because you essentially have a number of

408
00:19:58,540 --> 00:20:03,790
constraints that's linear in the size of

409
00:20:01,510 --> 00:20:05,340
the computation and you have to plug in

410
00:20:03,790 --> 00:20:07,840
all these values and basically

411
00:20:05,340 --> 00:20:11,139
reevaluate it so that isn't going to

412
00:20:07,840 --> 00:20:13,720
work so instead what these protocols do

413
00:20:11,140 --> 00:20:18,870
is they convert the satisfying

414
00:20:13,720 --> 00:20:21,580
assignment into at least many of these

415
00:20:18,870 --> 00:20:25,000
including us zatar and pinocchio they

416
00:20:21,580 --> 00:20:28,470
convert this the assignment the

417
00:20:25,000 --> 00:20:31,330
satisfying assignment into aqap a

418
00:20:28,470 --> 00:20:33,700
quadratic arithmetic program which is

419
00:20:31,330 --> 00:20:36,639
basically a polynomial with an error

420
00:20:33,700 --> 00:20:37,330
detection property and then the client

421
00:20:36,640 --> 00:20:41,950
can kind

422
00:20:37,330 --> 00:20:44,560
to query this polynomial evaluative al

423
00:20:41,950 --> 00:20:48,370
you ate this polynomial at at a random

424
00:20:44,560 --> 00:20:52,720
location and the response is is

425
00:20:48,370 --> 00:20:56,169
sufficient to prove that the server does

426
00:20:52,720 --> 00:20:58,210
in fact know a satisfying assignment to

427
00:20:56,170 --> 00:21:04,000
all of the constraints without actually

428
00:20:58,210 --> 00:21:05,290
having to return them all so these

429
00:21:04,000 --> 00:21:08,640
systems have the property that

430
00:21:05,290 --> 00:21:12,129
constructing this query is expensive

431
00:21:08,640 --> 00:21:14,110
there is some setup phase depending on

432
00:21:12,130 --> 00:21:15,700
the system for example zatar and

433
00:21:14,110 --> 00:21:17,320
pinocchio are somewhat different but

434
00:21:15,700 --> 00:21:19,240
they both have a setup phase that's

435
00:21:17,320 --> 00:21:22,960
roughly linear in the size of the

436
00:21:19,240 --> 00:21:27,520
computation fortunately this cost of

437
00:21:22,960 --> 00:21:30,390
setting up can be sort of amortized over

438
00:21:27,520 --> 00:21:33,879
multiple invitations of the same

439
00:21:30,390 --> 00:21:35,890
computation over multiple inputs the

440
00:21:33,880 --> 00:21:38,470
client can provide multiple inputs and

441
00:21:35,890 --> 00:21:41,350
get back multiple outputs along with

442
00:21:38,470 --> 00:21:43,450
multiple proofs and indeed these can be

443
00:21:41,350 --> 00:21:46,230
run in parallel which will be very good

444
00:21:43,450 --> 00:21:50,950
for certain applications like mapreduce

445
00:21:46,230 --> 00:21:54,340
so what about the issue of verifying

446
00:21:50,950 --> 00:21:57,310
reads and writes to untrusted storage so

447
00:21:54,340 --> 00:21:59,470
in pantry the sort of naive way of doing

448
00:21:57,310 --> 00:22:01,690
this would be to treat the untrusted

449
00:21:59,470 --> 00:22:04,260
storage as kind of a big switch

450
00:22:01,690 --> 00:22:06,760
statement where there is a variable

451
00:22:04,260 --> 00:22:09,490
associated with each position in the

452
00:22:06,760 --> 00:22:12,220
storage and let's say a load from

453
00:22:09,490 --> 00:22:15,100
storage would just be sort of a switch

454
00:22:12,220 --> 00:22:16,780
statement over all of the storage but

455
00:22:15,100 --> 00:22:19,240
this really isn't any good it's it's

456
00:22:16,780 --> 00:22:20,980
linear each each load operation for

457
00:22:19,240 --> 00:22:22,990
example would be would require a linear

458
00:22:20,980 --> 00:22:26,770
amount of work in the in the entirety of

459
00:22:22,990 --> 00:22:31,510
the storage so instead what pantry does

460
00:22:26,770 --> 00:22:34,510
is structures the untrusted storage as a

461
00:22:31,510 --> 00:22:36,879
block store where essentially blocks of

462
00:22:34,510 --> 00:22:39,010
data of arbitrary size are named by the

463
00:22:36,880 --> 00:22:42,460
hashes of their contents and then it

464
00:22:39,010 --> 00:22:46,690
ought ments see with two new operations

465
00:22:42,460 --> 00:22:50,350
the first get block works by giving an

466
00:22:46,690 --> 00:22:53,590
input digester hache dee returns a

467
00:22:50,350 --> 00:22:57,250
data block B which has the invariant the

468
00:22:53,590 --> 00:23:02,889
hash of that block B has to equal the

469
00:22:57,250 --> 00:23:06,850
input hash it also augments see with put

470
00:23:02,890 --> 00:23:10,570
block operation which takes a block B at

471
00:23:06,850 --> 00:23:12,820
input and returns a digest a hash D

472
00:23:10,570 --> 00:23:14,918
prime that has that preserves the

473
00:23:12,820 --> 00:23:18,189
invariant that that digests that's

474
00:23:14,919 --> 00:23:20,470
returned has to be equal to the hash of

475
00:23:18,190 --> 00:23:22,990
the supply data which is then stored in

476
00:23:20,470 --> 00:23:27,789
the untrusted block store so how do you

477
00:23:22,990 --> 00:23:32,049
verify these operations well suppose you

478
00:23:27,789 --> 00:23:35,740
had this example where there's an input

479
00:23:32,049 --> 00:23:38,200
hache dee and then the program performs

480
00:23:35,740 --> 00:23:41,770
the get block operation to get the block

481
00:23:38,200 --> 00:23:44,169
corresponding to that digest treats that

482
00:23:41,770 --> 00:23:46,179
block as an integer increments it by one

483
00:23:44,169 --> 00:23:49,690
and then stores it and why and returns

484
00:23:46,179 --> 00:23:52,750
the result so this is compiled to a set

485
00:23:49,690 --> 00:23:55,840
of constraints which roughly have this

486
00:23:52,750 --> 00:23:57,549
structure so the last constraint is one

487
00:23:55,840 --> 00:23:59,168
that you'd recognize that just make sure

488
00:23:57,549 --> 00:24:01,270
that the increment was done correctly

489
00:23:59,169 --> 00:24:03,820
but what of the rest of the constraints

490
00:24:01,270 --> 00:24:07,059
the rest of the constraints essentially

491
00:24:03,820 --> 00:24:09,970
implement the hash function in in in the

492
00:24:07,059 --> 00:24:12,250
form of constraints and then compare the

493
00:24:09,970 --> 00:24:15,580
result of the hash function with the

494
00:24:12,250 --> 00:24:18,850
input digest D so the only way to

495
00:24:15,580 --> 00:24:21,399
satisfy those constraints is for the

496
00:24:18,850 --> 00:24:23,620
hash to be computed correctly and if the

497
00:24:21,400 --> 00:24:25,539
hash is a good hash function is a

498
00:24:23,620 --> 00:24:30,699
collision resistant hash function then

499
00:24:25,539 --> 00:24:33,820
this also can convince the the client

500
00:24:30,700 --> 00:24:37,000
that the correct value was fetched so

501
00:24:33,820 --> 00:24:40,600
you're essentially outsourcing the check

502
00:24:37,000 --> 00:24:42,909
that the correct value was retrieved in

503
00:24:40,600 --> 00:24:45,340
this one instance to the untrusted

504
00:24:42,909 --> 00:24:47,980
server and rely on the fact that the

505
00:24:45,340 --> 00:24:49,299
check has to be computed correctly

506
00:24:47,980 --> 00:24:53,409
because it's part of a verifiable

507
00:24:49,299 --> 00:24:56,049
computation so given these tools what

508
00:24:53,409 --> 00:24:58,600
can you do it turns out that with just

509
00:24:56,049 --> 00:25:01,000
see and get block and put block you can

510
00:24:58,600 --> 00:25:04,100
implement verifiable MapReduce and so

511
00:25:01,000 --> 00:25:07,460
the way that works is the

512
00:25:04,100 --> 00:25:10,730
client outsources a particular map

513
00:25:07,460 --> 00:25:14,380
function to a set of mappers run by the

514
00:25:10,730 --> 00:25:17,270
untrusted provider and it also provides

515
00:25:14,380 --> 00:25:19,220
some input hashes of the particular

516
00:25:17,270 --> 00:25:22,879
blocks of data that the various mappers

517
00:25:19,220 --> 00:25:24,650
are going to work on along with a query

518
00:25:22,880 --> 00:25:28,240
which is going to be used as part of the

519
00:25:24,650 --> 00:25:32,480
the proof it's going to be used by the

520
00:25:28,240 --> 00:25:35,120
the server to generate proofs so what is

521
00:25:32,480 --> 00:25:38,480
this what does the mapper actually do

522
00:25:35,120 --> 00:25:41,870
well it calls get each mapper basically

523
00:25:38,480 --> 00:25:44,630
calls get block on the input hash to get

524
00:25:41,870 --> 00:25:48,320
the block of data verifiably then the

525
00:25:44,630 --> 00:25:51,470
map function is runs on it and it

526
00:25:48,320 --> 00:25:56,210
produces some output and then for each

527
00:25:51,470 --> 00:25:59,270
of the reducers a new block is plate is

528
00:25:56,210 --> 00:26:03,549
written to untrusted storage and the

529
00:25:59,270 --> 00:26:08,150
digest of that block is actually is

530
00:26:03,549 --> 00:26:10,190
actually returned to the client along

531
00:26:08,150 --> 00:26:13,760
with the proof of the correct execution

532
00:26:10,190 --> 00:26:16,700
of each of the of each of the mappers

533
00:26:13,760 --> 00:26:19,640
then in the reduce phase the client

534
00:26:16,700 --> 00:26:21,559
turns around and sends those interim

535
00:26:19,640 --> 00:26:24,380
hashes of the results of the map phase

536
00:26:21,559 --> 00:26:29,090
to the reducer nodes along with a

537
00:26:24,380 --> 00:26:32,570
reduced function and a query and the

538
00:26:29,090 --> 00:26:36,620
reducers get the necessary blocks run

539
00:26:32,570 --> 00:26:39,830
the reducer run the reduce function and

540
00:26:36,620 --> 00:26:42,739
then outputs the result as another block

541
00:26:39,830 --> 00:26:45,260
and returns the digest of those blocks

542
00:26:42,740 --> 00:26:48,110
along with a correct along with a proof

543
00:26:45,260 --> 00:26:50,600
of correctness of the reduced phase and

544
00:26:48,110 --> 00:26:53,120
so what you basically have here is that

545
00:26:50,600 --> 00:26:55,610
all of the data never needed to be

546
00:26:53,120 --> 00:26:59,928
stored with the client the client only

547
00:26:55,610 --> 00:27:02,780
ever saw small proofs and hashes and yet

548
00:26:59,929 --> 00:27:05,390
can be convinced that this data parallel

549
00:27:02,780 --> 00:27:09,350
computation was actually done correctly

550
00:27:05,390 --> 00:27:12,530
over this remote database with just see

551
00:27:09,350 --> 00:27:14,389
and get block and put block pantry can

552
00:27:12,530 --> 00:27:16,668
also do other things you can build

553
00:27:14,390 --> 00:27:17,600
verifiable data structures you can

554
00:27:16,669 --> 00:27:20,390
imagine

555
00:27:17,600 --> 00:27:22,730
that verifiable blocks contain the

556
00:27:20,390 --> 00:27:24,730
hashes of other verifiable blocks which

557
00:27:22,730 --> 00:27:27,260
allows you to build things like

558
00:27:24,730 --> 00:27:30,169
verifiable tree based data structures

559
00:27:27,260 --> 00:27:33,530
and indices and that sort of thing you

560
00:27:30,169 --> 00:27:37,880
can out sit you can represent queries

561
00:27:33,530 --> 00:27:40,428
like for example in one example of

562
00:27:37,880 --> 00:27:42,860
something we did is we used a subset of

563
00:27:40,429 --> 00:27:44,929
sequel and we compiled that into a

564
00:27:42,860 --> 00:27:47,120
verifiable program and so you could

565
00:27:44,929 --> 00:27:51,470
potentially have a relational database

566
00:27:47,120 --> 00:27:53,689
with indices and query processing all

567
00:27:51,470 --> 00:27:57,820
implemented with C and get block input

568
00:27:53,690 --> 00:28:00,799
block and be able to verify the results

569
00:27:57,820 --> 00:28:03,320
however beyond that you can also do

570
00:28:00,799 --> 00:28:06,530
something that you can't normally do and

571
00:28:03,320 --> 00:28:10,639
that is zero knowledge verification so

572
00:28:06,530 --> 00:28:12,559
in that case not only is the storage not

573
00:28:10,640 --> 00:28:14,990
in the possession of the client but the

574
00:28:12,559 --> 00:28:16,760
client is not actually allowed to see it

575
00:28:14,990 --> 00:28:19,940
the only thing that the client has

576
00:28:16,760 --> 00:28:21,860
access to is a commitment to the

577
00:28:19,940 --> 00:28:23,929
contents of the storage and that

578
00:28:21,860 --> 00:28:26,870
commitment that cryptographic commitment

579
00:28:23,929 --> 00:28:29,210
binds the server to specific values in

580
00:28:26,870 --> 00:28:32,418
the storage while still hiding its

581
00:28:29,210 --> 00:28:34,610
contents from the client so and this

582
00:28:32,419 --> 00:28:36,710
will be useful in the next system that

583
00:28:34,610 --> 00:28:38,539
I'll that I'll discuss but what's really

584
00:28:36,710 --> 00:28:42,260
interesting about that is that the

585
00:28:38,539 --> 00:28:45,140
client can be convinced that the that

586
00:28:42,260 --> 00:28:46,640
this potentially complex computation was

587
00:28:45,140 --> 00:28:49,460
done correctly without actually needing

588
00:28:46,640 --> 00:28:51,620
to know what the data is so how

589
00:28:49,460 --> 00:28:54,679
practical is all of this well there's

590
00:28:51,620 --> 00:28:57,260
good news and bad news the bad news is

591
00:28:54,679 --> 00:29:01,850
that the server overhead as compared to

592
00:28:57,260 --> 00:29:03,950
unverified execution is pretty high even

593
00:29:01,850 --> 00:29:05,870
though it's been improved by you know

594
00:29:03,950 --> 00:29:07,789
let's say 20 orders of magnitude it's

595
00:29:05,870 --> 00:29:10,219
still several orders of magnitude more

596
00:29:07,789 --> 00:29:13,190
expensive you also have this client

597
00:29:10,220 --> 00:29:16,610
setup costs which can be amortized in

598
00:29:13,190 --> 00:29:20,600
certain cases but it's also an obstacle

599
00:29:16,610 --> 00:29:22,219
and finally in pantry at least the

600
00:29:20,600 --> 00:29:24,260
programming model is limited because

601
00:29:22,220 --> 00:29:27,049
essentially the entire computation has

602
00:29:24,260 --> 00:29:29,629
to be static loop bounds array sizes

603
00:29:27,049 --> 00:29:30,539
pointers and so forth although recent

604
00:29:29,630 --> 00:29:33,039
work has

605
00:29:30,539 --> 00:29:36,009
started to lift this restriction

606
00:29:33,039 --> 00:29:38,408
basically by having the compiled circuit

607
00:29:36,009 --> 00:29:40,690
represent more of the machine you know

608
00:29:38,409 --> 00:29:43,440
the program counter and so forth however

609
00:29:40,690 --> 00:29:46,059
there is good news some MapReduce

610
00:29:43,440 --> 00:29:47,740
applications are practical today in the

611
00:29:46,059 --> 00:29:51,009
sense that outsourcing is worthwhile for

612
00:29:47,740 --> 00:29:53,470
the client see and get block and put

613
00:29:51,009 --> 00:29:56,590
block are pretty expressive and you also

614
00:29:53,470 --> 00:29:59,019
get zero knowledge verification so you

615
00:29:56,590 --> 00:30:04,959
get capabilities that weren't previously

616
00:29:59,019 --> 00:30:06,999
possible so in summary pantry provides

617
00:30:04,960 --> 00:30:09,820
sometimes practical verifiable

618
00:30:06,999 --> 00:30:12,009
outsourced computation by combining

619
00:30:09,820 --> 00:30:15,009
untrusted server storage with verifiable

620
00:30:12,009 --> 00:30:17,679
computation yielding realistic

621
00:30:15,009 --> 00:30:19,769
applications and it's also nice that

622
00:30:17,679 --> 00:30:22,269
it's unconditional and general purpose

623
00:30:19,769 --> 00:30:26,019
in the sense that it only relies on

624
00:30:22,269 --> 00:30:28,149
cryptographic assumptions so now I'm

625
00:30:26,019 --> 00:30:31,720
going to move on to talking about the

626
00:30:28,149 --> 00:30:37,658
second system that that that's in this

627
00:30:31,720 --> 00:30:41,950
area and that's a ver DP so the setting

628
00:30:37,659 --> 00:30:44,440
of verdi p is that of verifying research

629
00:30:41,950 --> 00:30:47,799
results so in many cases you have some

630
00:30:44,440 --> 00:30:49,600
data curator will call it like the US

631
00:30:47,799 --> 00:30:53,408
Census Bureau which has some standard

632
00:30:49,600 --> 00:30:56,320
data set let's say it's about dog

633
00:30:53,409 --> 00:30:57,909
ownership and then researchers come

634
00:30:56,320 --> 00:31:00,100
along and want to perform a query over

635
00:30:57,909 --> 00:31:05,259
this data set and they want to publish

636
00:31:00,100 --> 00:31:06,908
the results to some readers so you know

637
00:31:05,259 --> 00:31:08,649
suppose the researchers do their study

638
00:31:06,909 --> 00:31:12,429
and they say the average number of dogs

639
00:31:08,649 --> 00:31:17,350
that people own is 10 per person so this

640
00:31:12,429 --> 00:31:19,869
seems a bit off and indeed mistakes and

641
00:31:17,350 --> 00:31:22,299
even fraud do happen in the results of

642
00:31:19,869 --> 00:31:24,449
research studies so what do we do about

643
00:31:22,299 --> 00:31:28,779
this well the traditional approach is

644
00:31:24,450 --> 00:31:31,960
reproducibility somebody else let's say

645
00:31:28,779 --> 00:31:33,789
takes the data set they perform the same

646
00:31:31,960 --> 00:31:35,440
query over it they perform the same kind

647
00:31:33,789 --> 00:31:37,899
of data analysis they try to repeat it

648
00:31:35,440 --> 00:31:41,129
and they see whether the results match

649
00:31:37,899 --> 00:31:43,479
the published results unfortunately

650
00:31:41,129 --> 00:31:43,840
sensitive data poses a problem so

651
00:31:43,480 --> 00:31:46,360
suppose

652
00:31:43,840 --> 00:31:47,500
that the database is not about dog

653
00:31:46,360 --> 00:31:49,990
ownership but is actually about

654
00:31:47,500 --> 00:31:52,960
something more sensitive like you know

655
00:31:49,990 --> 00:31:55,960
medical data then this raises two

656
00:31:52,960 --> 00:31:58,120
challenges the first is that the result

657
00:31:55,960 --> 00:32:00,330
itself of the computation we know this

658
00:31:58,120 --> 00:32:03,219
the result itself can leak information

659
00:32:00,330 --> 00:32:06,309
such as you know the the famous Netflix

660
00:32:03,220 --> 00:32:10,020
prize database stand on D anonymization

661
00:32:06,309 --> 00:32:12,730
the second problem is that the fact that

662
00:32:10,020 --> 00:32:16,840
the distribution of this database is

663
00:32:12,730 --> 00:32:18,580
limited limits reproducibility so

664
00:32:16,840 --> 00:32:23,549
there's this kind of conflict between

665
00:32:18,580 --> 00:32:26,110
privacy and verifiability in the sort of

666
00:32:23,549 --> 00:32:29,559
verification of the results of research

667
00:32:26,110 --> 00:32:32,529
studies conducted over sensitive data so

668
00:32:29,559 --> 00:32:36,220
what about using differential privacy so

669
00:32:32,529 --> 00:32:38,620
to deal with this first challenge often

670
00:32:36,220 --> 00:32:40,450
what what what what is an approach that

671
00:32:38,620 --> 00:32:44,199
has been proposed is to use differential

672
00:32:40,450 --> 00:32:48,429
privacy which basically which basically

673
00:32:44,200 --> 00:32:52,330
involves adding some noise to the result

674
00:32:48,429 --> 00:32:54,299
that is published so that the privacy of

675
00:32:52,330 --> 00:32:56,830
no individual in the database is

676
00:32:54,299 --> 00:33:00,908
compromised and this is good because it

677
00:32:56,830 --> 00:33:02,918
provides mathematical privacy guarantees

678
00:33:00,909 --> 00:33:05,169
it provides a methodology for figuring

679
00:33:02,919 --> 00:33:07,710
out how much noise you have to add to

680
00:33:05,169 --> 00:33:10,919
preserve the privacy of database

681
00:33:07,710 --> 00:33:15,179
participants however it actually makes

682
00:33:10,919 --> 00:33:18,760
reproducibility even harder because

683
00:33:15,179 --> 00:33:20,919
suppose that the researcher wanted to

684
00:33:18,760 --> 00:33:24,100
make the result some some particular

685
00:33:20,919 --> 00:33:28,779
value like 2.5 she could publish this

686
00:33:24,100 --> 00:33:31,389
result and then even if you had access

687
00:33:28,779 --> 00:33:35,799
to this sensitive database you couldn't

688
00:33:31,390 --> 00:33:38,860
actually be sure whether or not the

689
00:33:35,799 --> 00:33:41,889
researcher was lying because the

690
00:33:38,860 --> 00:33:44,469
researcher could always claim sort of

691
00:33:41,890 --> 00:33:48,100
basically plausible denial deniability

692
00:33:44,470 --> 00:33:50,590
and claim that effectively you know the

693
00:33:48,100 --> 00:33:53,500
the sort of unexpected result is simply

694
00:33:50,590 --> 00:33:55,449
a result of of the particular Chort the

695
00:33:53,500 --> 00:33:57,320
particular choice of random noise that

696
00:33:55,450 --> 00:33:59,360
was drawn from some

697
00:33:57,320 --> 00:34:01,009
tribution they could blame it on the

698
00:33:59,360 --> 00:34:07,100
noise that they had it that they had to

699
00:34:01,009 --> 00:34:10,940
add so to overcome the problem with this

700
00:34:07,100 --> 00:34:13,549
approach we propose combining

701
00:34:10,940 --> 00:34:15,740
differential privacy with zero knowledge

702
00:34:13,550 --> 00:34:18,950
verifiable computation of the kind that

703
00:34:15,739 --> 00:34:20,928
I talked about earlier and so for

704
00:34:18,949 --> 00:34:22,969
example you the researcher does not

705
00:34:20,929 --> 00:34:25,460
choose the noise so they can't lie about

706
00:34:22,969 --> 00:34:28,368
the noise and then in addition to

707
00:34:25,460 --> 00:34:32,060
publishing a paper they also proved the

708
00:34:28,369 --> 00:34:34,310
result using pantry they published their

709
00:34:32,060 --> 00:34:36,980
their query constraints along with a

710
00:34:34,310 --> 00:34:39,739
proof of correct execution of that

711
00:34:36,980 --> 00:34:43,699
particular query over the data and then

712
00:34:39,739 --> 00:34:46,759
anybody who then reads this paper can

713
00:34:43,699 --> 00:34:48,888
get the proof and check that the query

714
00:34:46,760 --> 00:34:52,119
was executed correctly even though they

715
00:34:48,889 --> 00:34:54,980
don't have access to the underlying data

716
00:34:52,119 --> 00:34:56,990
so there are a couple of problems with

717
00:34:54,980 --> 00:35:00,619
this the first is that if these

718
00:34:56,989 --> 00:35:02,899
constraints represent a circuit you

719
00:35:00,619 --> 00:35:05,230
can't just sort of naively take sort of

720
00:35:02,900 --> 00:35:07,819
trace the execution of the query that

721
00:35:05,230 --> 00:35:09,290
the researcher wanted to do convert it

722
00:35:07,819 --> 00:35:11,270
to a circuit and then generate a proof

723
00:35:09,290 --> 00:35:14,270
because the very structure of the

724
00:35:11,270 --> 00:35:16,790
circuit could leak information about the

725
00:35:14,270 --> 00:35:19,750
database if it if it depends on on the

726
00:35:16,790 --> 00:35:22,910
database the second problem is that

727
00:35:19,750 --> 00:35:25,460
pantry is really only efficient can

728
00:35:22,910 --> 00:35:27,649
really only break even in data parallel

729
00:35:25,460 --> 00:35:29,420
computations like the MapReduce example

730
00:35:27,650 --> 00:35:32,960
I talked about earlier when you can

731
00:35:29,420 --> 00:35:36,319
amortize the cost of that set up you

732
00:35:32,960 --> 00:35:41,200
know over over sort of multiple

733
00:35:36,319 --> 00:35:44,599
invitations of the same program and so

734
00:35:41,200 --> 00:35:46,970
basically that's that's what verdi p our

735
00:35:44,599 --> 00:35:49,130
system does it combines privacy and

736
00:35:46,970 --> 00:35:51,379
verifiability by combining differential

737
00:35:49,130 --> 00:35:56,599
privacy and zero knowledge verifiable

738
00:35:51,380 --> 00:35:58,490
computation and but you know there's

739
00:35:56,599 --> 00:36:02,359
some challenges and actually making this

740
00:35:58,490 --> 00:36:05,569
work correctly so the first challenge is

741
00:36:02,359 --> 00:36:07,848
that you have to ensure that the results

742
00:36:05,569 --> 00:36:10,040
of computations performed in the system

743
00:36:07,849 --> 00:36:11,099
are differentially private and as we'll

744
00:36:10,040 --> 00:36:13,200
see we use a

745
00:36:11,099 --> 00:36:15,749
domain specific query language for

746
00:36:13,200 --> 00:36:17,279
expressing queries the second problem is

747
00:36:15,749 --> 00:36:20,700
that we need to achieve structural

748
00:36:17,279 --> 00:36:23,069
privacy that is we need the generation

749
00:36:20,700 --> 00:36:26,129
of circuits or equivalently constraints

750
00:36:23,069 --> 00:36:27,808
to be data independent to not depend on

751
00:36:26,130 --> 00:36:29,849
the database so that it doesn't you know

752
00:36:27,809 --> 00:36:31,529
the structure of the computation doesn't

753
00:36:29,849 --> 00:36:34,140
it doesn't in any way leak information

754
00:36:31,529 --> 00:36:36,479
about individuals and the third is that

755
00:36:34,140 --> 00:36:39,379
we need efficient execution which means

756
00:36:36,479 --> 00:36:41,899
we need a highly parallelizable runtime

757
00:36:39,380 --> 00:36:46,319
so what about the first question

758
00:36:41,900 --> 00:36:48,509
ensuring differential privacy well so

759
00:36:46,319 --> 00:36:52,489
there's this existing language called

760
00:36:48,509 --> 00:36:57,119
fuzz and it is a language for expressing

761
00:36:52,489 --> 00:37:00,450
queries and it has a type system such

762
00:36:57,119 --> 00:37:04,140
that if the program type checks then the

763
00:37:00,450 --> 00:37:06,629
result of the query can be known to be

764
00:37:04,140 --> 00:37:09,839
differentially private so suppose that

765
00:37:06,630 --> 00:37:11,489
you had you suppose you had a database

766
00:37:09,839 --> 00:37:14,339
you wanted to know how many people are

767
00:37:11,489 --> 00:37:19,739
over 40 so you could express it in fuzz

768
00:37:14,339 --> 00:37:22,170
with this code we are basically will you

769
00:37:19,739 --> 00:37:24,660
basically so apply a particular

770
00:37:22,170 --> 00:37:26,359
predicate to each row of the database in

771
00:37:24,660 --> 00:37:30,118
this case this sort of over 40

772
00:37:26,359 --> 00:37:33,719
predicates on the right then you split

773
00:37:30,119 --> 00:37:35,569
the database based on whether or not

774
00:37:33,719 --> 00:37:39,660
that predicate is true or false and

775
00:37:35,569 --> 00:37:41,369
finally you count one of the two halves

776
00:37:39,660 --> 00:37:43,920
of the database or one of the two

777
00:37:41,369 --> 00:37:47,279
portions of the database and that's how

778
00:37:43,920 --> 00:37:49,559
you get your result and then you add

779
00:37:47,279 --> 00:37:51,989
some noise to ensure that it's

780
00:37:49,559 --> 00:37:55,049
differentially private and basically the

781
00:37:51,989 --> 00:37:58,200
sort of type system and runtime sort of

782
00:37:55,049 --> 00:38:01,049
keep track of the sensitivity of the

783
00:37:58,200 --> 00:38:04,249
computation so that you know how much

784
00:38:01,049 --> 00:38:07,349
noise needs to be added at the end so

785
00:38:04,249 --> 00:38:09,379
this is all well and good the problem of

786
00:38:07,349 --> 00:38:12,479
course is that if you convert this

787
00:38:09,380 --> 00:38:15,569
particular sort of pipeline to a circuit

788
00:38:12,479 --> 00:38:17,819
it could leak information about the

789
00:38:15,569 --> 00:38:20,999
particular underlying data because as

790
00:38:17,819 --> 00:38:24,460
you can see you know the sizes of the

791
00:38:20,999 --> 00:38:26,410
sort of two portions after the split

792
00:38:24,460 --> 00:38:27,970
you know are different and so if you had

793
00:38:26,410 --> 00:38:30,879
sort of the number of gates in your

794
00:38:27,970 --> 00:38:34,779
circuit depend on that that would leak

795
00:38:30,880 --> 00:38:37,359
information about about the database so

796
00:38:34,780 --> 00:38:39,670
and there are other examples of this you

797
00:38:37,359 --> 00:38:41,740
know if you had data dependent loops or

798
00:38:39,670 --> 00:38:45,720
recursion this could also leaked

799
00:38:41,740 --> 00:38:48,729
information about about the database so

800
00:38:45,720 --> 00:38:49,868
to achieve structural privacy to prevent

801
00:38:48,730 --> 00:38:53,220
the structure of the circuit from

802
00:38:49,869 --> 00:38:56,440
leaking stuff we use fixed size

803
00:38:53,220 --> 00:38:58,450
intermediate results static loop bounds

804
00:38:56,440 --> 00:39:01,210
and recursion depth and statically

805
00:38:58,450 --> 00:39:03,460
compiled predicates and if you design

806
00:39:01,210 --> 00:39:06,880
the if you modify the language in the

807
00:39:03,460 --> 00:39:10,780
way that we described then you can

808
00:39:06,880 --> 00:39:14,950
actually prove that indeed structural

809
00:39:10,780 --> 00:39:20,109
privacy is preserved the next question

810
00:39:14,950 --> 00:39:24,879
is efficiency and so you know as we

811
00:39:20,109 --> 00:39:27,339
talked about with pantry the expensive

812
00:39:24,880 --> 00:39:32,640
part is the proof set up which has to be

813
00:39:27,339 --> 00:39:37,140
done once for example by the curator and

814
00:39:32,640 --> 00:39:40,118
proof generation which has to be done by

815
00:39:37,140 --> 00:39:42,310
the researcher and has to be done

816
00:39:40,119 --> 00:39:45,400
basically once per execution of a

817
00:39:42,310 --> 00:39:48,279
particular circuit and is several orders

818
00:39:45,400 --> 00:39:51,190
of magnitude more expensive than

819
00:39:48,280 --> 00:39:53,440
unverified execution whereas what is

820
00:39:51,190 --> 00:39:56,680
cheap and independent of the circuit

821
00:39:53,440 --> 00:40:00,040
size is the verification of the proofs

822
00:39:56,680 --> 00:40:01,839
of correctness so that can be done in in

823
00:40:00,040 --> 00:40:04,240
milliseconds and so we have to manage

824
00:40:01,839 --> 00:40:08,290
the cost of the sort of expensive part

825
00:40:04,240 --> 00:40:09,910
of pantry so just simply taking the

826
00:40:08,290 --> 00:40:11,770
query we want to do over the database

827
00:40:09,910 --> 00:40:14,080
and converting it into a single giant

828
00:40:11,770 --> 00:40:16,450
circuit is really far too expensive it

829
00:40:14,080 --> 00:40:19,720
will overwhelm the resources of of an

830
00:40:16,450 --> 00:40:22,299
individual server so we have to exploit

831
00:40:19,720 --> 00:40:26,220
data parallelism in some way and so

832
00:40:22,300 --> 00:40:29,500
what's nice about this particular

833
00:40:26,220 --> 00:40:32,589
language of V fuzz is it has the

834
00:40:29,500 --> 00:40:34,890
property that the predicate is applied

835
00:40:32,589 --> 00:40:37,630
essentially to each row of the database

836
00:40:34,890 --> 00:40:40,210
individually and so what you

837
00:40:37,630 --> 00:40:44,440
do is you can essentially divide each

838
00:40:40,210 --> 00:40:47,920
phase of this computation each phase of

839
00:40:44,440 --> 00:40:52,960
this pipeline into multiple tiles that

840
00:40:47,920 --> 00:40:56,799
are then sharded over multiple machines

841
00:40:52,960 --> 00:40:58,900
so all computations in this language

842
00:40:56,799 --> 00:41:02,019
basically have three phases they have a

843
00:40:58,900 --> 00:41:04,089
sort of they have the application of the

844
00:41:02,019 --> 00:41:07,359
of the predicate to each row of the

845
00:41:04,089 --> 00:41:12,490
database and you can sort of apply it to

846
00:41:07,359 --> 00:41:15,130
chunks of the database then the results

847
00:41:12,490 --> 00:41:18,279
of these predicates are aggregated in

848
00:41:15,130 --> 00:41:21,640
account phase and finally noise is added

849
00:41:18,279 --> 00:41:24,549
at the end and so each of these shards

850
00:41:21,640 --> 00:41:26,920
can be placed on a different machine

851
00:41:24,549 --> 00:41:29,529
it's basically an embarrassingly

852
00:41:26,920 --> 00:41:34,210
parallel problem which is really good

853
00:41:29,529 --> 00:41:37,480
because the complexity of pantry really

854
00:41:34,210 --> 00:41:40,299
depends on the circuit size and so as a

855
00:41:37,480 --> 00:41:43,359
result you only need to generate a

856
00:41:40,299 --> 00:41:46,299
circuit that is sort of linear in the

857
00:41:43,359 --> 00:41:49,390
size of one of these chunks of the

858
00:41:46,299 --> 00:41:52,630
database rather than the entire database

859
00:41:49,390 --> 00:41:56,140
itself it also allows the cost of sort

860
00:41:52,630 --> 00:41:59,529
of setting up the prove the setting up

861
00:41:56,140 --> 00:42:01,839
the proof to be amortized over all of

862
00:41:59,529 --> 00:42:05,470
the tiles all of the execute all of the

863
00:42:01,839 --> 00:42:07,808
parallel execution of the smaller

864
00:42:05,470 --> 00:42:13,288
circuit that lets say applies to

865
00:42:07,809 --> 00:42:13,289
different tiles of the computation now

866
00:42:13,619 --> 00:42:20,500
what about passing values between phases

867
00:42:16,900 --> 00:42:23,349
so now that now that we're actually

868
00:42:20,500 --> 00:42:28,059
dealing with multiple computations some

869
00:42:23,349 --> 00:42:29,769
executed as phases some some executed in

870
00:42:28,059 --> 00:42:32,319
parallel we need a way to sort of

871
00:42:29,769 --> 00:42:35,140
connect the data between them and so

872
00:42:32,319 --> 00:42:37,569
effectively they're a series of

873
00:42:35,140 --> 00:42:40,808
cryptographic commitments each phase

874
00:42:37,569 --> 00:42:43,869
generates a set of commitments to the

875
00:42:40,809 --> 00:42:45,880
remotely stored data which the the

876
00:42:43,869 --> 00:42:50,259
readers of the paper never get to see

877
00:42:45,880 --> 00:42:51,260
and then these commitments are used to

878
00:42:50,259 --> 00:42:56,120
sort of

879
00:42:51,260 --> 00:42:58,250
find the the researchers to the 22

880
00:42:56,120 --> 00:43:01,339
particular data as the input to the next

881
00:42:58,250 --> 00:43:04,640
phase so the last thing I want to talk

882
00:43:01,340 --> 00:43:06,620
about is how well this works in terms of

883
00:43:04,640 --> 00:43:08,359
its efficiency and there are a number of

884
00:43:06,620 --> 00:43:10,040
questions that you can ask the

885
00:43:08,360 --> 00:43:13,130
efficiency of proof generation the

886
00:43:10,040 --> 00:43:14,900
efficiency of proof verification the

887
00:43:13,130 --> 00:43:17,420
scalability of the system to sort of

888
00:43:14,900 --> 00:43:18,440
larger databases and so these are the

889
00:43:17,420 --> 00:43:21,260
things that I'm going to be talking

890
00:43:18,440 --> 00:43:23,000
about now in the paper we also talked

891
00:43:21,260 --> 00:43:26,480
about the efficiency of proof set up as

892
00:43:23,000 --> 00:43:28,010
well as some micro benchmarks and so in

893
00:43:26,480 --> 00:43:30,110
order to figure out how well this

894
00:43:28,010 --> 00:43:32,150
actually works we did a couple of

895
00:43:30,110 --> 00:43:33,890
different queries which are which are

896
00:43:32,150 --> 00:43:36,640
sort of common in the differentially in

897
00:43:33,890 --> 00:43:40,549
the differential privacy literature and

898
00:43:36,640 --> 00:43:44,150
we outsource these computations to a

899
00:43:40,550 --> 00:43:47,240
bunch of ec2 instances we use 32 you see

900
00:43:44,150 --> 00:43:49,670
two instances with a lot of RAM and in

901
00:43:47,240 --> 00:43:52,069
particular they they had some fancy

902
00:43:49,670 --> 00:43:54,910
NVIDIA GPUs which can be used to

903
00:43:52,070 --> 00:43:58,910
accelerate the cryptography of the

904
00:43:54,910 --> 00:44:00,680
verifiable computation system one thing

905
00:43:58,910 --> 00:44:02,450
that's notable though is despite the

906
00:44:00,680 --> 00:44:04,669
sort of hefty specs of these machines

907
00:44:02,450 --> 00:44:10,089
they only cost about two dollars per

908
00:44:04,670 --> 00:44:16,190
instance per hour so to evaluate this

909
00:44:10,090 --> 00:44:18,680
for proof generation we estimated the

910
00:44:16,190 --> 00:44:21,560
time that it would take for the prover

911
00:44:18,680 --> 00:44:27,319
to run on various queries and various

912
00:44:21,560 --> 00:44:31,759
sizes of input databases and as you can

913
00:44:27,320 --> 00:44:34,430
see you know even with you know this

914
00:44:31,760 --> 00:44:37,160
given level of parallelism you know it

915
00:44:34,430 --> 00:44:39,410
takes a few hours and only needs to be

916
00:44:37,160 --> 00:44:40,970
done basically once before publication

917
00:44:39,410 --> 00:44:42,379
like it's not like when you're sort of

918
00:44:40,970 --> 00:44:44,209
playing with the data figuring out

919
00:44:42,380 --> 00:44:46,370
exactly what query you you have to do

920
00:44:44,210 --> 00:44:47,510
you need to actually do this you really

921
00:44:46,370 --> 00:44:52,609
only need to do it once before

922
00:44:47,510 --> 00:44:54,470
publication and experiments like we sort

923
00:44:52,610 --> 00:44:56,570
of actually did some experiments to

924
00:44:54,470 --> 00:44:59,240
verify our cost model these are

925
00:44:56,570 --> 00:45:01,670
represented by those dots which and our

926
00:44:59,240 --> 00:45:04,160
program our actual results were within

927
00:45:01,670 --> 00:45:07,480
three-point-three percent of our

928
00:45:04,160 --> 00:45:12,259
projections and these experiments cost

929
00:45:07,480 --> 00:45:14,119
64 and 128 dollars respectively now what

930
00:45:12,260 --> 00:45:18,020
about proof verification so proof

931
00:45:14,119 --> 00:45:19,819
verification is very fast each proof and

932
00:45:18,020 --> 00:45:22,130
so now there are multiple proofs because

933
00:45:19,819 --> 00:45:23,750
there's different tiles but each proof

934
00:45:22,130 --> 00:45:28,010
is only two hundred eighty eight bytes

935
00:45:23,750 --> 00:45:31,220
and takes milliseconds to verify so in

936
00:45:28,010 --> 00:45:34,490
all of our examples basically it only

937
00:45:31,220 --> 00:45:37,160
took you know about you know even for

938
00:45:34,490 --> 00:45:39,549
our sort of most intensive example only

939
00:45:37,160 --> 00:45:44,960
took less than three and a half seconds

940
00:45:39,549 --> 00:45:48,380
to verify to verify the results so

941
00:45:44,960 --> 00:45:51,829
finally we were interested in the

942
00:45:48,380 --> 00:45:54,140
scalability of proof generation so you

943
00:45:51,829 --> 00:45:56,750
know if you wanted to pay more for let's

944
00:45:54,140 --> 00:45:59,750
say more instances could you do better

945
00:45:56,750 --> 00:46:01,520
and the answer is that proof generation

946
00:45:59,750 --> 00:46:03,619
is actually highly scalable the work

947
00:46:01,520 --> 00:46:05,869
that you actually need to do to sort of

948
00:46:03,619 --> 00:46:08,869
prove that you've done a research study

949
00:46:05,869 --> 00:46:13,220
correctly scales very well with the

950
00:46:08,869 --> 00:46:16,119
number of with the number of rows so for

951
00:46:13,220 --> 00:46:19,399
example if you had a thousand machines

952
00:46:16,119 --> 00:46:21,859
and a 2 million Road database it would

953
00:46:19,400 --> 00:46:28,069
take about a hundred minutes to generate

954
00:46:21,859 --> 00:46:30,230
to generate a proof so that you know at

955
00:46:28,069 --> 00:46:32,270
a cost of sort of two dollars per

956
00:46:30,230 --> 00:46:35,000
instance per hour and considering that

957
00:46:32,270 --> 00:46:36,890
it only has to be done once it's

958
00:46:35,000 --> 00:46:38,690
probably a small part of the research

959
00:46:36,890 --> 00:46:41,900
budget you know this sort of last step

960
00:46:38,690 --> 00:46:43,910
of publishing the proof and so we

961
00:46:41,900 --> 00:46:49,880
believe that you know you could actually

962
00:46:43,910 --> 00:46:54,319
do this in a lot of cases and so to sum

963
00:46:49,880 --> 00:46:57,170
things up you know verdi p enables the

964
00:46:54,319 --> 00:46:59,900
interesting combination of privacy and

965
00:46:57,170 --> 00:47:02,660
verifiability by combining differential

966
00:46:59,900 --> 00:47:05,420
privacy with the verifiable computation

967
00:47:02,660 --> 00:47:09,710
machinery that i talked about in the

968
00:47:05,420 --> 00:47:11,930
first half of the talk and v fuzz

969
00:47:09,710 --> 00:47:14,799
queries that type check it provides this

970
00:47:11,930 --> 00:47:17,080
nice query language that are provably

971
00:47:14,799 --> 00:47:20,770
differentially private and pre

972
00:47:17,080 --> 00:47:24,759
probably structurally private and the

973
00:47:20,770 --> 00:47:27,310
system is in fact you know scalable and

974
00:47:24,760 --> 00:47:28,780
you know relatively affordable you know

975
00:47:27,310 --> 00:47:31,450
it's it's a relatively small percentage

976
00:47:28,780 --> 00:47:33,340
of the sort of research budget that you

977
00:47:31,450 --> 00:47:34,799
would have and we believe that you could

978
00:47:33,340 --> 00:47:38,830
do similar things in other applications

979
00:47:34,800 --> 00:47:41,440
like for example suppose that you had

980
00:47:38,830 --> 00:47:43,810
one of these devices attached to your

981
00:47:41,440 --> 00:47:46,270
car that that sort of tracked your

982
00:47:43,810 --> 00:47:48,040
driving habits but you didn't want to

983
00:47:46,270 --> 00:47:50,200
reveal you know that sort of detailed

984
00:47:48,040 --> 00:47:52,360
sensitive data about how you drive or

985
00:47:50,200 --> 00:47:54,939
where you drive to the insurance company

986
00:47:52,360 --> 00:47:58,440
so what you could imagine happening is

987
00:47:54,940 --> 00:48:01,570
that your car would sort of provide

988
00:47:58,440 --> 00:48:03,730
sensitive driving data to this to this

989
00:48:01,570 --> 00:48:07,570
device and the insurance company would

990
00:48:03,730 --> 00:48:09,940
provide its billing formula and then the

991
00:48:07,570 --> 00:48:12,100
device would return differentially

992
00:48:09,940 --> 00:48:15,310
private statistics about about your

993
00:48:12,100 --> 00:48:17,350
driving along with the proof that the

994
00:48:15,310 --> 00:48:20,290
billing formula was actually correctly

995
00:48:17,350 --> 00:48:22,630
applied so the final answer you get

996
00:48:20,290 --> 00:48:26,440
about let's say you know how much you

997
00:48:22,630 --> 00:48:30,640
should pay is actually correct so to

998
00:48:26,440 --> 00:48:32,890
conclude I'd argue that it's possible to

999
00:48:30,640 --> 00:48:35,170
build general-purpose systems designed

1000
00:48:32,890 --> 00:48:37,540
for verifiability and I think it's

1001
00:48:35,170 --> 00:48:40,480
necessary that we do this because we are

1002
00:48:37,540 --> 00:48:44,470
increasingly relying on computation done

1003
00:48:40,480 --> 00:48:47,740
by others and legal and market-based

1004
00:48:44,470 --> 00:48:50,589
enforcement I'd argue are not enough on

1005
00:48:47,740 --> 00:48:53,140
their own and indeed these sorts of

1006
00:48:50,590 --> 00:48:55,270
mechanisms can complement them because

1007
00:48:53,140 --> 00:48:57,790
essentially they provide evidence

1008
00:48:55,270 --> 00:49:01,270
whether or not these third parties are

1009
00:48:57,790 --> 00:49:03,310
actually doing what they say they do it

1010
00:49:01,270 --> 00:49:06,700
also enables the possibility of new

1011
00:49:03,310 --> 00:49:10,090
applications that might not have been

1012
00:49:06,700 --> 00:49:11,890
previously possible due to the risks the

1013
00:49:10,090 --> 00:49:15,130
ability to for example prove things

1014
00:49:11,890 --> 00:49:18,310
about prove things about databases that

1015
00:49:15,130 --> 00:49:20,880
you're not allowed to see is sort of a

1016
00:49:18,310 --> 00:49:25,090
very sort of a very interesting

1017
00:49:20,880 --> 00:49:26,290
capability and so that's all and I hope

1018
00:49:25,090 --> 00:49:28,300
we have a little bit of time for

1019
00:49:26,290 --> 00:49:30,990
questions and thanks for listening and

1020
00:49:28,300 --> 00:49:30,990
thanks for inviting me

1021
00:49:41,230 --> 00:49:49,370
so my question is open have you thought

1022
00:49:46,130 --> 00:49:51,110
about the further optimizing the deity

1023
00:49:49,370 --> 00:49:53,390
execution performance of these

1024
00:49:51,110 --> 00:49:55,490
verification task for example by

1025
00:49:53,390 --> 00:49:58,850
exploiting some of the parallelism that

1026
00:49:55,490 --> 00:50:01,729
is intrinsic in the in the verification

1027
00:49:58,850 --> 00:50:04,810
to make it even more efficient so to

1028
00:50:01,730 --> 00:50:07,220
speed up proof verifications right yeah

1029
00:50:04,810 --> 00:50:09,500
so we I haven't looked at that I mean it

1030
00:50:07,220 --> 00:50:11,330
might it might be possible to do it I

1031
00:50:09,500 --> 00:50:14,480
mean so you know one of the issues is

1032
00:50:11,330 --> 00:50:15,440
that like each of the you know even

1033
00:50:14,480 --> 00:50:20,030
though the circuit is the same the

1034
00:50:15,440 --> 00:50:21,860
inputs are different and so you know so

1035
00:50:20,030 --> 00:50:23,600
certain aspects of the proof are going

1036
00:50:21,860 --> 00:50:25,850
to be different I mean one of the things

1037
00:50:23,600 --> 00:50:28,130
about the proof is that it's already so

1038
00:50:25,850 --> 00:50:31,160
small because it's already kind of

1039
00:50:28,130 --> 00:50:32,660
independent of of a lot of the it's

1040
00:50:31,160 --> 00:50:35,750
already independent of a lot of the

1041
00:50:32,660 --> 00:50:37,759
computation you know there's already so

1042
00:50:35,750 --> 00:50:40,580
much that the client doesn't doesn't

1043
00:50:37,760 --> 00:50:42,110
already know so I'm not I'm not sure you

1044
00:50:40,580 --> 00:50:43,910
know what approach you would take but

1045
00:50:42,110 --> 00:50:45,800
there might be something you can do

1046
00:50:43,910 --> 00:50:47,870
certainly on the server end of things

1047
00:50:45,800 --> 00:50:50,240
there are already been improvements

1048
00:50:47,870 --> 00:50:52,120
since we since we built the system for

1049
00:50:50,240 --> 00:50:56,990
example one of the most expensive

1050
00:50:52,120 --> 00:51:00,380
aspects of verdi p is that each phase

1051
00:50:56,990 --> 00:51:03,770
has to commit to the results of the

1052
00:51:00,380 --> 00:51:05,360
phase and then the next phase each sort

1053
00:51:03,770 --> 00:51:08,390
of tile of the next phase has to

1054
00:51:05,360 --> 00:51:11,330
decommit so as to prove that you know

1055
00:51:08,390 --> 00:51:15,290
that phase is using the same data as the

1056
00:51:11,330 --> 00:51:19,100
preceding phase and so what we did in

1057
00:51:15,290 --> 00:51:21,230
inver DP is we actually we actually

1058
00:51:19,100 --> 00:51:25,190
implemented the cryptographic commitment

1059
00:51:21,230 --> 00:51:28,460
in C and compiled that to a verifiable

1060
00:51:25,190 --> 00:51:30,590
computation but if you specialize the

1061
00:51:28,460 --> 00:51:32,690
the proof machinery as a recent paper

1062
00:51:30,590 --> 00:51:35,990
from earlier this year did sort of

1063
00:51:32,690 --> 00:51:37,850
building commitments into the proof

1064
00:51:35,990 --> 00:51:39,859
machinery you can actually do the

1065
00:51:37,850 --> 00:51:42,020
process of kind of chaining multiple

1066
00:51:39,860 --> 00:51:43,580
verifiable computations together much

1067
00:51:42,020 --> 00:51:46,680
more efficiently so

1068
00:51:43,580 --> 00:51:49,770
that would actually lop off a big a big

1069
00:51:46,680 --> 00:51:54,960
chunk of the cost of the system that I

1070
00:51:49,770 --> 00:51:57,560
just talked about so very interesting

1071
00:51:54,960 --> 00:52:00,750
talk I had two clarification questions

1072
00:51:57,560 --> 00:52:03,690
in pantry I did not condition whatever

1073
00:52:00,750 --> 00:52:05,730
this and server we don't trust him for

1074
00:52:03,690 --> 00:52:08,340
doing correct computation and then you

1075
00:52:05,730 --> 00:52:09,690
talked about untrusted storage and so I

1076
00:52:08,340 --> 00:52:10,859
didn't understand the difference in

1077
00:52:09,690 --> 00:52:13,020
terms of the assumption that you're

1078
00:52:10,859 --> 00:52:16,259
making on the server are compared to the

1079
00:52:13,020 --> 00:52:18,119
storage from the client perspective so

1080
00:52:16,260 --> 00:52:21,300
from the from the clients perspective it

1081
00:52:18,119 --> 00:52:23,070
actually doesn't matter you know whose

1082
00:52:21,300 --> 00:52:25,230
storage this is like whether it's

1083
00:52:23,070 --> 00:52:27,960
actually the same store you know whether

1084
00:52:25,230 --> 00:52:29,400
whether it's the same party who holds

1085
00:52:27,960 --> 00:52:33,510
the storage maybe it's just the same

1086
00:52:29,400 --> 00:52:36,119
server who also has the storage you know

1087
00:52:33,510 --> 00:52:38,190
because effectively all the all the

1088
00:52:36,119 --> 00:52:40,530
client cares about is that there's some

1089
00:52:38,190 --> 00:52:42,810
continuity between let's say some

1090
00:52:40,530 --> 00:52:45,540
initial commitment to what the initial

1091
00:52:42,810 --> 00:52:47,880
state of the storage was and sort of all

1092
00:52:45,540 --> 00:52:50,430
of the subsequent computation so for

1093
00:52:47,880 --> 00:52:51,930
example you know that every value that

1094
00:52:50,430 --> 00:52:54,210
was read from that database and

1095
00:52:51,930 --> 00:52:56,690
subsequently used in the computation can

1096
00:52:54,210 --> 00:52:59,220
actually be tied back to that initial

1097
00:52:56,690 --> 00:53:02,190
initial commitment and similarly any

1098
00:52:59,220 --> 00:53:04,319
rights that happened really did update

1099
00:53:02,190 --> 00:53:07,619
the the appropriate portions of that

1100
00:53:04,320 --> 00:53:10,800
storage you can even have as Verde p

1101
00:53:07,619 --> 00:53:12,690
does the system output a new updated

1102
00:53:10,800 --> 00:53:14,340
commitment that the client can actually

1103
00:53:12,690 --> 00:53:17,910
trust so the client actually doesn't

1104
00:53:14,340 --> 00:53:21,690
need to care you know who holds the

1105
00:53:17,910 --> 00:53:23,879
storage they just know that you know all

1106
00:53:21,690 --> 00:53:26,910
sorts of sort of corruption might have

1107
00:53:23,880 --> 00:53:30,359
happened in the storage but the the

1108
00:53:26,910 --> 00:53:33,029
program verifies the the contents of any

1109
00:53:30,359 --> 00:53:36,779
of any reads that that arts that are

1110
00:53:33,030 --> 00:53:38,730
then used in in the computation but from

1111
00:53:36,780 --> 00:53:41,670
the server's perspective this store this

1112
00:53:38,730 --> 00:53:44,280
storage could actually not even be you

1113
00:53:41,670 --> 00:53:45,600
know be run by even somebody else you

1114
00:53:44,280 --> 00:53:48,960
know you could imagine some you know

1115
00:53:45,600 --> 00:53:51,240
block store sort storage run by some

1116
00:53:48,960 --> 00:53:53,080
other party and all the server does is

1117
00:53:51,240 --> 00:53:56,049
sort of do regular

1118
00:53:53,080 --> 00:54:00,279
get input operations on that block store

1119
00:53:56,050 --> 00:54:03,880
and as long as as long as that block

1120
00:54:00,280 --> 00:54:09,100
store you know continues to service

1121
00:54:03,880 --> 00:54:10,990
requests you know it will work and the

1122
00:54:09,100 --> 00:54:14,319
client will be able to actually take

1123
00:54:10,990 --> 00:54:16,509
care of making sure that the contents is

1124
00:54:14,320 --> 00:54:18,340
correct because essentially all of the

1125
00:54:16,510 --> 00:54:22,210
checks are built into the verifiable

1126
00:54:18,340 --> 00:54:24,100
program okay and the second thing was

1127
00:54:22,210 --> 00:54:26,560
it's a fish art but that's regarding

1128
00:54:24,100 --> 00:54:29,500
Verde be so here's the model is there

1129
00:54:26,560 --> 00:54:31,480
are all these there is a database I as a

1130
00:54:29,500 --> 00:54:33,370
reader or somebody who's looking at the

1131
00:54:31,480 --> 00:54:37,090
answer has no idea about what is the

1132
00:54:33,370 --> 00:54:39,220
database so how can I be sure that you

1133
00:54:37,090 --> 00:54:41,200
are taking care of all the value 18

1134
00:54:39,220 --> 00:54:43,240
integrity that all the records are used

1135
00:54:41,200 --> 00:54:45,460
by computation stuff like that well so

1136
00:54:43,240 --> 00:54:48,009
that's why i think that the sort of most

1137
00:54:45,460 --> 00:54:51,010
realistic setting for using something

1138
00:54:48,010 --> 00:54:53,890
like this is where there is a data

1139
00:54:51,010 --> 00:54:56,350
curator with some standard data set like

1140
00:54:53,890 --> 00:54:59,850
the Census Bureau or one of these

1141
00:54:56,350 --> 00:55:04,750
biomedical data repositories where

1142
00:54:59,850 --> 00:55:06,730
essentially the data was collected let's

1143
00:55:04,750 --> 00:55:08,140
say by someone other than the

1144
00:55:06,730 --> 00:55:10,480
researchers so they can't let's say

1145
00:55:08,140 --> 00:55:13,500
cherry-pick the data set in order to get

1146
00:55:10,480 --> 00:55:16,540
the results that they want and so then

1147
00:55:13,500 --> 00:55:18,550
you could imagine that this data set was

1148
00:55:16,540 --> 00:55:21,070
collected in advance of the researchers

1149
00:55:18,550 --> 00:55:22,990
asking to do the study a public

1150
00:55:21,070 --> 00:55:27,520
commitment was published to it you know

1151
00:55:22,990 --> 00:55:31,830
long beforehand you know the the sort of

1152
00:55:27,520 --> 00:55:34,509
data set was not chosen was not chosen

1153
00:55:31,830 --> 00:55:38,350
with with that particular query in mind

1154
00:55:34,510 --> 00:55:40,690
and you know multiple studies could be

1155
00:55:38,350 --> 00:55:42,160
done on it so I think that that's a way

1156
00:55:40,690 --> 00:55:43,870
to that that's a that's a potential way

1157
00:55:42,160 --> 00:55:46,960
to deal with that problem and then the

1158
00:55:43,870 --> 00:55:49,870
program itself you know could you know

1159
00:55:46,960 --> 00:55:51,940
be structured so that it's clear that it

1160
00:55:49,870 --> 00:55:54,069
actually sort of touches every record

1161
00:55:51,940 --> 00:55:57,980
and those are tied back to that bad

1162
00:55:54,070 --> 00:56:01,820
commitment all right

1163
00:55:57,980 --> 00:56:05,140
the time let's uh the other questions

1164
00:56:01,820 --> 00:56:05,140
all fine and let's thank our t1

