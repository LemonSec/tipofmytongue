1
00:00:06,680 --> 00:00:13,730
after a short delay with fun setup of

2
00:00:11,350 --> 00:00:17,210
video displays after it is my pleasure

3
00:00:13,730 --> 00:00:19,369
to introduce Lotfi bend owed money I

4
00:00:17,210 --> 00:00:22,460
hope I didn't butcher your name he's a

5
00:00:19,369 --> 00:00:24,948
lecturer at Iowa State working in

6
00:00:22,460 --> 00:00:28,609
different areas of secure software

7
00:00:24,949 --> 00:00:30,470
development and he has traveled quite a

8
00:00:28,609 --> 00:00:31,880
bit and come through a whole bunch of

9
00:00:30,470 --> 00:00:34,430
different countries which was

10
00:00:31,880 --> 00:00:37,190
interesting to read including the

11
00:00:34,430 --> 00:00:39,500
Fraunhofer Institute for secure

12
00:00:37,190 --> 00:00:41,660
information technology in Germany which

13
00:00:39,500 --> 00:00:45,110
was very nice trade his research focuses

14
00:00:41,660 --> 00:00:47,029
on empirical research in secure software

15
00:00:45,110 --> 00:00:49,250
development development of secure

16
00:00:47,030 --> 00:00:51,590
systems using an agile approach and

17
00:00:49,250 --> 00:00:52,910
cyber easily connected vehicles and I'm

18
00:00:51,590 --> 00:00:55,010
very interested to hear what he has to

19
00:00:52,910 --> 00:00:58,339
say about what do you think so please

20
00:00:55,010 --> 00:00:59,000
take it away thank you it is so what I

21
00:00:58,340 --> 00:01:01,960
said

22
00:00:59,000 --> 00:01:05,869
my name is Latvia Bennett man I'm with

23
00:01:01,960 --> 00:01:08,990
Iowa State University I travelled quite

24
00:01:05,869 --> 00:01:14,150
the word I think I went through three

25
00:01:08,990 --> 00:01:16,580
continents so far and I am here so I I

26
00:01:14,150 --> 00:01:20,540
came here to share with you my passion

27
00:01:16,580 --> 00:01:24,080
for empirical research and hopefully

28
00:01:20,540 --> 00:01:28,670
some probably of you will be I would

29
00:01:24,080 --> 00:01:33,560
appreciate that so in this talk I'm

30
00:01:28,670 --> 00:01:37,070
going to give examples from my research

31
00:01:33,560 --> 00:01:43,250
on four roles that empirical research

32
00:01:37,070 --> 00:01:46,130
can play in software security so the

33
00:01:43,250 --> 00:01:49,850
first thing probably who actually did

34
00:01:46,130 --> 00:01:53,240
not take course on soft on security so

35
00:01:49,850 --> 00:01:56,089
far so all of you took course on

36
00:01:53,240 --> 00:01:59,080
software security and one question that

37
00:01:56,090 --> 00:02:03,770
you had it probably when it comes to

38
00:01:59,080 --> 00:02:06,200
threat modeling is that we have I think

39
00:02:03,770 --> 00:02:08,929
probably so far 60 method for threat

40
00:02:06,200 --> 00:02:11,450
modeling you could see by this kind of

41
00:02:08,929 --> 00:02:15,170
study by colleagues they did it at the

42
00:02:11,450 --> 00:02:18,369
time and we got it from there slide when

43
00:02:15,170 --> 00:02:20,510
I was at foreign however said so the

44
00:02:18,370 --> 00:02:23,540
number of citations

45
00:02:20,510 --> 00:02:25,609
or uses of this threat modeling approach

46
00:02:23,540 --> 00:02:29,120
you have fault tree analysis you have

47
00:02:25,610 --> 00:02:32,360
attack tree you have the MSS Dale Mike

48
00:02:29,120 --> 00:02:34,760
refers tried misuse cases and for

49
00:02:32,360 --> 00:02:38,019
default tree analysis you see for the

50
00:02:34,760 --> 00:02:41,870
citation this is 2014 more than 1000

51
00:02:38,019 --> 00:02:44,150
paper actually either they work it with

52
00:02:41,870 --> 00:02:46,790
the approach extended and so on or

53
00:02:44,150 --> 00:02:50,360
actually they apply it or probably they

54
00:02:46,790 --> 00:02:53,569
cited somehow so we have a big number

55
00:02:50,360 --> 00:02:56,180
and the question when you go to to work

56
00:02:53,569 --> 00:02:58,790
with this in real context with this

57
00:02:56,180 --> 00:03:02,060
method your first question which one I

58
00:02:58,790 --> 00:03:06,679
am going to use obviously this simple

59
00:03:02,060 --> 00:03:08,930
answer is it depends but that's good

60
00:03:06,680 --> 00:03:11,690
that we have many methods that probably

61
00:03:08,930 --> 00:03:16,640
also would help us to identify all the

62
00:03:11,690 --> 00:03:19,670
potential threats might be however we

63
00:03:16,640 --> 00:03:22,488
hear all the time about new threats that

64
00:03:19,670 --> 00:03:25,668
comes to follow to the world I'll give

65
00:03:22,489 --> 00:03:28,790
him an example this is one attack that

66
00:03:25,669 --> 00:03:30,919
we got it about two years ago and this

67
00:03:28,790 --> 00:03:34,179
is what we named it use of malicious

68
00:03:30,919 --> 00:03:37,819
dependency in this kind of attack that

69
00:03:34,180 --> 00:03:39,590
we identified you deploy your

70
00:03:37,819 --> 00:03:41,030
application let's say to the cloud

71
00:03:39,590 --> 00:03:46,609
specially to Nadia's

72
00:03:41,030 --> 00:03:49,220
you use specific dependency but it's

73
00:03:46,609 --> 00:03:51,590
possible that in one of the dependency

74
00:03:49,220 --> 00:03:53,959
that you used it she changes the

75
00:03:51,590 --> 00:03:57,139
behavior of another dependency that you

76
00:03:53,959 --> 00:04:02,569
are using and that's potentially you did

77
00:03:57,139 --> 00:04:05,000
not you do not realize that so that's a

78
00:04:02,569 --> 00:04:08,388
new at least we were not aware about it

79
00:04:05,000 --> 00:04:10,940
so simply how this is works

80
00:04:08,389 --> 00:04:14,660
so you call for example for not years

81
00:04:10,940 --> 00:04:17,660
you have the async library in your code

82
00:04:14,660 --> 00:04:19,880
and the code the dependency that you are

83
00:04:17,660 --> 00:04:22,760
using it's probably going only to give

84
00:04:19,880 --> 00:04:26,389
you to change the colors for your

85
00:04:22,760 --> 00:04:31,430
formatting for your HTML but in this

86
00:04:26,389 --> 00:04:31,969
code there is few lines extra requires a

87
00:04:31,430 --> 00:04:34,889
sink

88
00:04:31,969 --> 00:04:36,780
it saves the method map in

89
00:04:34,889 --> 00:04:39,930
variable this is JavaScript so you could

90
00:04:36,780 --> 00:04:42,840
do it then there is a definition of the

91
00:04:39,930 --> 00:04:45,840
map function and in this redefinition

92
00:04:42,840 --> 00:04:48,628
there is a leak of the events so you

93
00:04:45,840 --> 00:04:52,409
have the events that sink get which you

94
00:04:48,629 --> 00:04:54,689
are using they will be leapt because you

95
00:04:52,409 --> 00:04:57,599
have this leak method and then the

96
00:04:54,689 --> 00:05:01,139
behavior continue because you call again

97
00:04:57,599 --> 00:05:04,050
to apply the previous method so with

98
00:05:01,139 --> 00:05:06,240
this redefinition of function now the

99
00:05:04,050 --> 00:05:08,849
map that you are using is not the map of

100
00:05:06,240 --> 00:05:12,479
the sink but actually in the new map

101
00:05:08,849 --> 00:05:16,438
from the other dependency that you are

102
00:05:12,479 --> 00:05:18,960
using if you did a review of the code

103
00:05:16,439 --> 00:05:21,270
your sink is great it's not change it

104
00:05:18,960 --> 00:05:24,628
you are fine but because the other

105
00:05:21,270 --> 00:05:28,620
dependency changed the behavior so you

106
00:05:24,629 --> 00:05:30,270
have this attack so my bottom line the

107
00:05:28,620 --> 00:05:32,279
bottom line here is we have different

108
00:05:30,270 --> 00:05:34,139
method let's say one of the cases for

109
00:05:32,279 --> 00:05:36,240
software security we have different

110
00:05:34,139 --> 00:05:39,539
method for threat modeling but we are

111
00:05:36,240 --> 00:05:44,460
still discovering attacks more more and

112
00:05:39,539 --> 00:05:47,818
more and more we discover attacks the

113
00:05:44,460 --> 00:05:49,979
classic way for cyber security you have

114
00:05:47,819 --> 00:05:51,930
problems we come with a set of solutions

115
00:05:49,979 --> 00:05:54,270
we prove that these are solution our

116
00:05:51,930 --> 00:05:56,659
grades --great and probably we develop

117
00:05:54,270 --> 00:05:59,609
software and so on this is method one

118
00:05:56,659 --> 00:06:01,469
there is another method so we've seen

119
00:05:59,610 --> 00:06:04,889
with that for threat models with direct

120
00:06:01,469 --> 00:06:08,270
60 times and we are still not did not

121
00:06:04,889 --> 00:06:12,120
reach probably satisfactory situation a

122
00:06:08,270 --> 00:06:15,270
second approach that would be collect

123
00:06:12,120 --> 00:06:17,159
practical wisdom from expert you will be

124
00:06:15,270 --> 00:06:19,979
graduating like the previous one like

125
00:06:17,159 --> 00:06:21,750
myself and do you want you go to the

126
00:06:19,979 --> 00:06:25,649
industry and you have real problems

127
00:06:21,750 --> 00:06:28,620
there you gain experience what if we go

128
00:06:25,649 --> 00:06:30,930
for all these kind of things that we

129
00:06:28,620 --> 00:06:34,439
have we go to one of the things we go to

130
00:06:30,930 --> 00:06:37,919
this experts we go to the facts experts

131
00:06:34,439 --> 00:06:42,389
data and try to learn from there from

132
00:06:37,919 --> 00:06:44,310
this wisdom so empirical research method

133
00:06:42,389 --> 00:06:46,379
they are not in you they have been there

134
00:06:44,310 --> 00:06:48,689
for social science they have been there

135
00:06:46,379 --> 00:06:50,909
for education for medicine

136
00:06:48,689 --> 00:06:53,610
so we have the qualitative study

137
00:06:50,909 --> 00:06:56,819
probably you are aware about this so for

138
00:06:53,610 --> 00:06:59,689
example the interviews the case study

139
00:06:56,819 --> 00:07:02,009
this is for medical for example

140
00:06:59,689 --> 00:07:04,019
observation so people they work you

141
00:07:02,009 --> 00:07:08,069
observe how they do and you try to

142
00:07:04,019 --> 00:07:10,829
derive rules there or common patterns

143
00:07:08,069 --> 00:07:12,659
you have the mapping study mapping study

144
00:07:10,829 --> 00:07:14,819
implies that there are study the top

145
00:07:12,659 --> 00:07:17,129
talk about topic like now for example

146
00:07:14,819 --> 00:07:20,159
let's say blockage chain and you want to

147
00:07:17,129 --> 00:07:22,639
check what is this stage what are the

148
00:07:20,159 --> 00:07:25,139
aspect that are studied in block chain

149
00:07:22,639 --> 00:07:28,229
the other category for empirical

150
00:07:25,139 --> 00:07:31,800
research is the quantitative study where

151
00:07:28,229 --> 00:07:33,360
you have a quantification here like data

152
00:07:31,800 --> 00:07:35,699
analytics you have probably

153
00:07:33,360 --> 00:07:37,829
questionnaires and surveys you might

154
00:07:35,699 --> 00:07:40,979
have experiment so you run things on

155
00:07:37,829 --> 00:07:43,860
code and you bring data comment pattern

156
00:07:40,979 --> 00:07:45,808
there are also four papers you do

157
00:07:43,860 --> 00:07:48,509
systematic literature review you have a

158
00:07:45,809 --> 00:07:51,389
criterion you wanna see how for example

159
00:07:48,509 --> 00:07:56,489
mature specific field based on specific

160
00:07:51,389 --> 00:07:58,979
criteria that you come up with so we

161
00:07:56,489 --> 00:08:01,498
have a set of empirical research methods

162
00:07:58,979 --> 00:08:05,550
those here set of this common one that

163
00:08:01,499 --> 00:08:08,519
we use in software security and this

164
00:08:05,550 --> 00:08:10,499
they have been used for other Sciences

165
00:08:08,519 --> 00:08:14,339
we could use them also for software

166
00:08:10,499 --> 00:08:18,809
security so I said I'm gonna share with

167
00:08:14,339 --> 00:08:21,329
you four rows and the first role that

168
00:08:18,809 --> 00:08:24,509
empirical research could play with

169
00:08:21,329 --> 00:08:27,059
software security it could help us with

170
00:08:24,509 --> 00:08:29,579
improve the maturity of the models the

171
00:08:27,059 --> 00:08:33,808
techniques and processes that we use to

172
00:08:29,579 --> 00:08:38,519
engineer secure software let's take the

173
00:08:33,808 --> 00:08:41,338
case of risk estimation so for risk

174
00:08:38,519 --> 00:08:43,409
estimation the common formula that we

175
00:08:41,339 --> 00:08:46,199
use is the risk exposure equal to

176
00:08:43,409 --> 00:08:47,579
impacts multiplied by likelihood so you

177
00:08:46,199 --> 00:08:50,279
get the impact then you get the

178
00:08:47,579 --> 00:08:53,729
likelihood thus will define your risk

179
00:08:50,279 --> 00:08:55,889
exposure so the likelihood it's kind of

180
00:08:53,730 --> 00:08:58,769
the attack potential how likely the

181
00:08:55,889 --> 00:09:00,929
attack could happen multiplied by the

182
00:08:58,769 --> 00:09:02,580
frequency how often is going to happen

183
00:09:00,929 --> 00:09:05,160
let's say you could use this

184
00:09:02,580 --> 00:09:08,520
you might come with different way but

185
00:09:05,160 --> 00:09:11,250
this is kind of common so I would take

186
00:09:08,520 --> 00:09:12,960
here for the connected car we have now

187
00:09:11,250 --> 00:09:14,340
most of the cars they are connected

188
00:09:12,960 --> 00:09:16,380
somehow you have Bluetooth you have

189
00:09:14,340 --> 00:09:18,900
different devices and I'm going to say

190
00:09:16,380 --> 00:09:22,340
what are the different threats that I

191
00:09:18,900 --> 00:09:24,840
have and how likely how likely the

192
00:09:22,340 --> 00:09:27,660
threats can happen and what is the

193
00:09:24,840 --> 00:09:29,430
unpacked so you come and someone is

194
00:09:27,660 --> 00:09:33,000
going the attack is going to flash the

195
00:09:29,430 --> 00:09:35,760
firmware or here I would say this is the

196
00:09:33,000 --> 00:09:37,680
likelihood the unpacked is low probably

197
00:09:35,760 --> 00:09:41,069
probably not you might not agree with me

198
00:09:37,680 --> 00:09:43,410
and the likelihood is no is low let's

199
00:09:41,070 --> 00:09:45,210
say inject brake message the likelihood

200
00:09:43,410 --> 00:09:49,110
this is probably is going to be possible

201
00:09:45,210 --> 00:09:51,450
the impact is still probably I would say

202
00:09:49,110 --> 00:09:53,850
probably low but there is another one

203
00:09:51,450 --> 00:09:58,340
take control the likelihood is going to

204
00:09:53,850 --> 00:10:00,960
be likely low and the unpacked is high

205
00:09:58,340 --> 00:10:03,390
this is my perception you might agree

206
00:10:00,960 --> 00:10:05,520
with it you might not I could give you

207
00:10:03,390 --> 00:10:08,189
an argument ation that's my

208
00:10:05,520 --> 00:10:12,240
argumentation for why I would say this

209
00:10:08,190 --> 00:10:15,450
is low or high or I would show you why I

210
00:10:12,240 --> 00:10:21,240
came to this conclusion so we bring this

211
00:10:15,450 --> 00:10:22,890
this is Robert so he was here years ago

212
00:10:21,240 --> 00:10:26,130
he's graduated from here and you work it

213
00:10:22,890 --> 00:10:29,010
on this paper together so and we ask

214
00:10:26,130 --> 00:10:32,520
what is the risks exposure of a threat

215
00:10:29,010 --> 00:10:35,430
take control of a car so let's assume

216
00:10:32,520 --> 00:10:39,089
that Raj says this is high risk I can't

217
00:10:35,430 --> 00:10:42,150
say no this is low risk how did we come

218
00:10:39,089 --> 00:10:44,490
up to this conclusion low or high and

219
00:10:42,150 --> 00:10:46,620
the first question if two peoples they

220
00:10:44,490 --> 00:10:50,240
come especially to experts they come to

221
00:10:46,620 --> 00:10:53,490
you and you are working on let's say for

222
00:10:50,240 --> 00:10:56,010
to develop something and one says this

223
00:10:53,490 --> 00:11:00,930
is high one thing one says this is low

224
00:10:56,010 --> 00:11:02,640
who should you believe so question who

225
00:11:00,930 --> 00:11:03,930
should you believe this is actually the

226
00:11:02,640 --> 00:11:08,180
one who is going to make the decision

227
00:11:03,930 --> 00:11:13,050
this is that's what this comes to him so

228
00:11:08,180 --> 00:11:15,949
and I heard a jump I would say if one

229
00:11:13,050 --> 00:11:17,510
says it was high and one says low

230
00:11:15,950 --> 00:11:19,730
go talk to each other and come with me

231
00:11:17,510 --> 00:11:23,139
with the response something that makes

232
00:11:19,730 --> 00:11:27,320
us so far it doesn't make sense

233
00:11:23,139 --> 00:11:29,000
so let's we have as risks as I talked it

234
00:11:27,320 --> 00:11:31,040
before for threat modeling we have many

235
00:11:29,000 --> 00:11:32,810
methods and that's great because we have

236
00:11:31,040 --> 00:11:34,730
different perspective on things

237
00:11:32,810 --> 00:11:36,800
we have also for risk estimation

238
00:11:34,730 --> 00:11:40,010
different methods so the OS they came

239
00:11:36,800 --> 00:11:44,990
with their own factors for estimation

240
00:11:40,010 --> 00:11:47,240
rescue estimation ISO 1840 1845 they

241
00:11:44,990 --> 00:11:50,019
have also their own factors there among

242
00:11:47,240 --> 00:11:52,930
other things in that standard the nest

243
00:11:50,019 --> 00:11:56,360
830 they have also their own estimation

244
00:11:52,930 --> 00:11:58,969
risk and the octave too they have their

245
00:11:56,360 --> 00:12:02,389
own estimation method let's assume are

246
00:11:58,970 --> 00:12:06,800
used for example the octave and karate

247
00:12:02,389 --> 00:12:09,800
used a nist SP 830 everyone used his own

248
00:12:06,800 --> 00:12:13,160
factors the factor that are defined in

249
00:12:09,800 --> 00:12:16,160
this document for the estimation of risk

250
00:12:13,160 --> 00:12:19,459
so now we know that we have already two

251
00:12:16,160 --> 00:12:22,730
different ways to do estimation so we

252
00:12:19,459 --> 00:12:24,469
have them here so I use the motifs the

253
00:12:22,730 --> 00:12:26,480
means the opportunity what is the

254
00:12:24,470 --> 00:12:29,180
motivation what are the means and what

255
00:12:26,480 --> 00:12:31,850
are what is the opportunity to to do

256
00:12:29,180 --> 00:12:33,260
that from the other side we've seen the

257
00:12:31,850 --> 00:12:35,690
capability what are the resources

258
00:12:33,260 --> 00:12:37,939
available from hardware from the scripts

259
00:12:35,690 --> 00:12:41,600
and so on that you could use to perform

260
00:12:37,940 --> 00:12:44,570
specific attacks and also the entrance

261
00:12:41,600 --> 00:12:48,380
for doing that or not and the question

262
00:12:44,570 --> 00:12:51,050
comes now whether you believe right or

263
00:12:48,380 --> 00:12:53,420
you believe Lotfi now here you are going

264
00:12:51,050 --> 00:12:54,979
to come to the point which factor should

265
00:12:53,420 --> 00:12:57,079
I use we know that we are using

266
00:12:54,980 --> 00:12:58,819
different methods and the question which

267
00:12:57,079 --> 00:13:01,189
factor should I use we need to use the

268
00:12:58,819 --> 00:13:07,610
same factor probably so we can get to an

269
00:13:01,190 --> 00:13:09,769
agreement right so whom should you

270
00:13:07,610 --> 00:13:14,990
believe comes to which estimate should

271
00:13:09,769 --> 00:13:17,300
you use right so let's have now two two

272
00:13:14,990 --> 00:13:19,370
estimation two threats

273
00:13:17,300 --> 00:13:21,380
we're not going to use only one the

274
00:13:19,370 --> 00:13:24,350
first one is remote update of ECU

275
00:13:21,380 --> 00:13:26,029
firmware and here we have the likelihood

276
00:13:24,350 --> 00:13:28,760
we have the impact the likelihood rod

277
00:13:26,029 --> 00:13:29,710
says 13 I would say 30 how did we come

278
00:13:28,760 --> 00:13:32,830
up with Vietnam

279
00:13:29,710 --> 00:13:36,970
so we said low high and very high then

280
00:13:32,830 --> 00:13:38,950
we we make scale if it's lower than zero

281
00:13:36,970 --> 00:13:41,050
if it's higher than four then because

282
00:13:38,950 --> 00:13:42,730
you have a set of factors you compute

283
00:13:41,050 --> 00:13:45,969
these numbers so you do summation we're

284
00:13:42,730 --> 00:13:47,410
gonna see that so we come with different

285
00:13:45,970 --> 00:13:50,440
numbers we come with different

286
00:13:47,410 --> 00:13:52,270
estimation low and high likelihood for

287
00:13:50,440 --> 00:13:55,660
the falsification of speedometer reading

288
00:13:52,270 --> 00:13:59,980
we come also for two different number 50

289
00:13:55,660 --> 00:14:02,199
at 23:59 23 right he says this is really

290
00:13:59,980 --> 00:14:07,440
very high and I will say this is medium

291
00:14:02,200 --> 00:14:07,440
now the question is who to believe right

292
00:14:08,040 --> 00:14:14,980
so we have an error in this estimation

293
00:14:11,440 --> 00:14:16,810
and the common thing here I brought this

294
00:14:14,980 --> 00:14:21,130
kind of from physics from physics the

295
00:14:16,810 --> 00:14:24,520
document old document you have two ways

296
00:14:21,130 --> 00:14:27,520
for to analyze your error you have one

297
00:14:24,520 --> 00:14:29,470
is you use historical data you have

298
00:14:27,520 --> 00:14:32,770
historical data and you gonna use that

299
00:14:29,470 --> 00:14:34,870
to analyze what is your error and you

300
00:14:32,770 --> 00:14:36,730
have the uncertainty approach where are

301
00:14:34,870 --> 00:14:40,720
you going to measure the bound where the

302
00:14:36,730 --> 00:14:43,300
true value lie and this it implies that

303
00:14:40,720 --> 00:14:45,040
if you have an agreement then this is

304
00:14:43,300 --> 00:14:48,120
most likely the true value if the

305
00:14:45,040 --> 00:14:51,579
experts they agree for this case on

306
00:14:48,120 --> 00:14:53,650
something on specific value for the risk

307
00:14:51,580 --> 00:14:56,110
I would say that this is actually the

308
00:14:53,650 --> 00:14:58,180
risk if they disagree then there is

309
00:14:56,110 --> 00:15:00,250
something that is wrong the first

310
00:14:58,180 --> 00:15:02,279
approach actually we do not we cannot

311
00:15:00,250 --> 00:15:04,900
apply it because we do not have

312
00:15:02,279 --> 00:15:07,150
historical data the day that we have

313
00:15:04,900 --> 00:15:09,130
historical data that's probably the best

314
00:15:07,150 --> 00:15:13,630
way to go because you have better

315
00:15:09,130 --> 00:15:17,290
probably better foundation so we come to

316
00:15:13,630 --> 00:15:19,870
the estimation and the uncertainty in

317
00:15:17,290 --> 00:15:21,730
general its measured using the standard

318
00:15:19,870 --> 00:15:24,160
deviation the regular mathematical

319
00:15:21,730 --> 00:15:26,230
standard deviation thing we have here

320
00:15:24,160 --> 00:15:28,449
for the simple case this is the simple

321
00:15:26,230 --> 00:15:32,250
one where you have Z this is the

322
00:15:28,450 --> 00:15:36,459
summation for factor X I then the the

323
00:15:32,250 --> 00:15:38,560
the standard deviation for Z so you have

324
00:15:36,459 --> 00:15:43,459
the square root of the summation for the

325
00:15:38,560 --> 00:15:45,739
for the Delta X I square so if we get to

326
00:15:43,459 --> 00:15:47,779
Delta Z that is a small small

327
00:15:45,740 --> 00:15:51,499
uncertainty then there is an agreement

328
00:15:47,779 --> 00:15:54,139
right since we said if this variation is

329
00:15:51,499 --> 00:15:56,240
a small then people they agree if there

330
00:15:54,139 --> 00:15:59,569
is a big variation then people they

331
00:15:56,240 --> 00:16:02,179
disagree so a big uncertainty applied

332
00:15:59,569 --> 00:16:04,459
disagreement it's a common thing that we

333
00:16:02,179 --> 00:16:10,459
use it for other aspect for the

334
00:16:04,459 --> 00:16:14,118
estimation of uncertainty so we got that

335
00:16:10,459 --> 00:16:16,998
that's the approach now we jump which

336
00:16:14,119 --> 00:16:19,009
factor we are going to use and let's say

337
00:16:16,999 --> 00:16:21,499
here we had at some point a debate and

338
00:16:19,009 --> 00:16:24,319
we said attacker capability is the

339
00:16:21,499 --> 00:16:26,689
ability to access system resources to

340
00:16:24,319 --> 00:16:29,839
exercise of threats this is actually

341
00:16:26,689 --> 00:16:32,629
it's a good factor that has really it

342
00:16:29,839 --> 00:16:35,480
impacts the risk estimation and we

343
00:16:32,629 --> 00:16:37,579
should use it so we say you cannot use

344
00:16:35,480 --> 00:16:39,860
the scripts you cannot use specific

345
00:16:37,579 --> 00:16:42,410
hardware's you cannot use the

346
00:16:39,860 --> 00:16:47,240
opportunity that you have unless you

347
00:16:42,410 --> 00:16:49,160
have specific capability so and you have

348
00:16:47,240 --> 00:16:50,809
a specific capability now we have to

349
00:16:49,160 --> 00:16:53,629
come up with the likelihood for this

350
00:16:50,809 --> 00:16:55,459
capability so you have now the

351
00:16:53,629 --> 00:16:57,559
likelihood of the capability is how

352
00:16:55,459 --> 00:17:00,109
likely potential attacker can have this

353
00:16:57,559 --> 00:17:03,410
capability and you could have specific

354
00:17:00,110 --> 00:17:06,339
factors for the estimation of likelihood

355
00:17:03,410 --> 00:17:10,099
for capabilities such as how many

356
00:17:06,339 --> 00:17:13,220
persons they have they are around to

357
00:17:10,099 --> 00:17:18,198
estimate in that in that moment for

358
00:17:13,220 --> 00:17:20,890
example to check the opportunity so we

359
00:17:18,199 --> 00:17:23,959
identify for these attacks two simple

360
00:17:20,890 --> 00:17:26,360
attacker capability one is local access

361
00:17:23,959 --> 00:17:28,399
and one is remote access you might say

362
00:17:26,359 --> 00:17:33,139
well remote access he can access my

363
00:17:28,398 --> 00:17:37,610
Bluetooth or he can access we can access

364
00:17:33,140 --> 00:17:40,309
it remotely using v2v or whatever so you

365
00:17:37,610 --> 00:17:43,039
can go in details so we specify two

366
00:17:40,309 --> 00:17:45,950
access capability one local access when

367
00:17:43,039 --> 00:17:48,860
remote access and we give again the same

368
00:17:45,950 --> 00:17:52,250
threats so this is not V this is right

369
00:17:48,860 --> 00:17:56,149
so how likely is it to have remote

370
00:17:52,250 --> 00:17:57,830
update office you a firmware so we say

371
00:17:56,150 --> 00:18:00,620
for the local access if I have local

372
00:17:57,830 --> 00:18:04,550
access to the car and I can plug it plug

373
00:18:00,620 --> 00:18:07,250
my code in the obd2 probably I have

374
00:18:04,550 --> 00:18:09,680
waste scripts and this is 27 percent is

375
00:18:07,250 --> 00:18:12,110
likely and they would say 30 percent is

376
00:18:09,680 --> 00:18:14,390
likely we come to the second thing that

377
00:18:12,110 --> 00:18:16,820
we say falsification falsification of

378
00:18:14,390 --> 00:18:19,790
speedometer reading but say if I have

379
00:18:16,820 --> 00:18:23,570
local access it is very high I could do

380
00:18:19,790 --> 00:18:24,740
it so and I would say yeah it's high but

381
00:18:23,570 --> 00:18:28,010
still it's 30

382
00:18:24,740 --> 00:18:31,400
but for remote access if I have remote

383
00:18:28,010 --> 00:18:33,500
access it's gonna be more difficult so

384
00:18:31,400 --> 00:18:35,540
it's 10 and they would say yes it's

385
00:18:33,500 --> 00:18:38,690
going to be more difficult and risk is

386
00:18:35,540 --> 00:18:41,629
low it's 15 so you have much work to do

387
00:18:38,690 --> 00:18:45,680
and probably more hurdles to to do that

388
00:18:41,630 --> 00:18:49,640
tag we see here that 27 and 30 they are

389
00:18:45,680 --> 00:18:52,160
not far 50 and 30 they are not far if we

390
00:18:49,640 --> 00:18:55,100
compare them to the previous value where

391
00:18:52,160 --> 00:18:57,400
we have let's say 50 and we have 10 so

392
00:18:55,100 --> 00:18:59,830
for the previous one we have different

393
00:18:57,400 --> 00:19:02,540
exposure risk estimation exposure

394
00:18:59,830 --> 00:19:07,550
estimation of the risk exposure and here

395
00:19:02,540 --> 00:19:10,280
we have close one so we came and we

396
00:19:07,550 --> 00:19:13,159
formulated this so a sense attacker

397
00:19:10,280 --> 00:19:16,310
capability this is a condition to use

398
00:19:13,160 --> 00:19:18,200
specific means and opportunity then you

399
00:19:16,310 --> 00:19:20,450
have the set of factors that you have

400
00:19:18,200 --> 00:19:22,610
for each a threat you identify the

401
00:19:20,450 --> 00:19:27,710
capability that you have capability K

402
00:19:22,610 --> 00:19:32,840
here and you want to identify the the P

403
00:19:27,710 --> 00:19:36,110
so this is the potential of attack so

404
00:19:32,840 --> 00:19:38,360
you have the factors but multiplied by

405
00:19:36,110 --> 00:19:41,889
your likelihood for having that

406
00:19:38,360 --> 00:19:45,020
capability then you come for your

407
00:19:41,890 --> 00:19:48,770
potential attack it's going to be the

408
00:19:45,020 --> 00:19:51,830
maximum of the potential of attacks

409
00:19:48,770 --> 00:19:53,570
given the different capability so you're

410
00:19:51,830 --> 00:19:55,520
going to get the maximum for all of them

411
00:19:53,570 --> 00:19:58,429
for all the potential capability that

412
00:19:55,520 --> 00:20:01,900
you have and the risk is going to be the

413
00:19:58,430 --> 00:20:04,220
impact for that threat multiplied by the

414
00:20:01,900 --> 00:20:07,010
attack potential multiplied by the

415
00:20:04,220 --> 00:20:09,070
occurrence so this is kind of how we

416
00:20:07,010 --> 00:20:16,570
compute

417
00:20:09,070 --> 00:20:20,590
we compute the the attack so we came now

418
00:20:16,570 --> 00:20:23,559
we had the idea on how to measure how to

419
00:20:20,590 --> 00:20:25,600
identify this uncertainty we came with

420
00:20:23,559 --> 00:20:28,210
one factor that we believe this is

421
00:20:25,600 --> 00:20:31,539
should have an impact and actually it

422
00:20:28,210 --> 00:20:34,029
had an impact in our opinion but still

423
00:20:31,539 --> 00:20:35,980
we are too and whether the numbers that

424
00:20:34,029 --> 00:20:38,679
we got they are arbitrary numbers

425
00:20:35,980 --> 00:20:40,059
because we are excited about it or that

426
00:20:38,679 --> 00:20:42,490
was kind of truth

427
00:20:40,059 --> 00:20:45,580
so we can with hypothesis the

428
00:20:42,490 --> 00:20:48,039
uncertainty in the attack potential when

429
00:20:45,580 --> 00:20:51,070
considering attacker capability one is

430
00:20:48,039 --> 00:20:52,809
equal to the uncertainty in the attack

431
00:20:51,070 --> 00:20:55,029
potential when not considering the

432
00:20:52,809 --> 00:20:58,509
attacker capability we said let's

433
00:20:55,029 --> 00:21:00,879
consider now we have hypothesis and this

434
00:20:58,509 --> 00:21:03,129
hypothesis says that the uncertainty

435
00:21:00,879 --> 00:21:06,759
when we do not use the attacker

436
00:21:03,129 --> 00:21:10,600
capability is the same as the put attack

437
00:21:06,759 --> 00:21:13,360
potential when we consider when when we

438
00:21:10,600 --> 00:21:15,668
consider the attack capability is equal

439
00:21:13,360 --> 00:21:19,719
to the one when we do not consider the

440
00:21:15,669 --> 00:21:22,210
attack ability so and the goal is to

441
00:21:19,720 --> 00:21:25,299
prove that this is false whether we can

442
00:21:22,210 --> 00:21:27,429
prove that this is false or not so if we

443
00:21:25,299 --> 00:21:29,830
prove that this is false it implies that

444
00:21:27,429 --> 00:21:32,049
attacker capability it has a value in

445
00:21:29,830 --> 00:21:35,649
the risk estimation and we should

446
00:21:32,049 --> 00:21:39,549
consider it as one of the factors so if

447
00:21:35,649 --> 00:21:41,889
we cannot prove the opposite then we

448
00:21:39,549 --> 00:21:47,259
cannot conclude based on this statement

449
00:21:41,889 --> 00:21:51,250
right so we took the example of seven

450
00:21:47,259 --> 00:21:53,740
threats for connected vehicles and we

451
00:21:51,250 --> 00:21:55,570
send the information to expert that we

452
00:21:53,740 --> 00:22:00,490
know they work on cyber security or they

453
00:21:55,570 --> 00:22:04,029
have exposure to knowledge about attacks

454
00:22:00,490 --> 00:22:08,590
to two cars connected cars we did that

455
00:22:04,029 --> 00:22:12,340
in November 2013 so we did this example

456
00:22:08,590 --> 00:22:15,029
so seven threats we got response from

457
00:22:12,340 --> 00:22:19,090
nine expert the data it was complete and

458
00:22:15,029 --> 00:22:20,850
at the date it was in 2013 so what we

459
00:22:19,090 --> 00:22:22,620
found here is that the average

460
00:22:20,850 --> 00:22:25,439
considering the attacker kept

461
00:22:22,620 --> 00:22:29,459
of the uncertainty for the seventh rats

462
00:22:25,440 --> 00:22:32,700
was 2.23 and the average were not

463
00:22:29,460 --> 00:22:37,170
considering attacker capability was 5.20

464
00:22:32,700 --> 00:22:41,640
so the 5.20 that uncertainty is as you

465
00:22:37,170 --> 00:22:43,740
can see is higher than 2.23 but we can

466
00:22:41,640 --> 00:22:46,770
see the value are different but whether

467
00:22:43,740 --> 00:22:48,720
this difference is meaningful or not we

468
00:22:46,770 --> 00:22:51,780
have to go to the inference with from

469
00:22:48,720 --> 00:22:54,630
statistics and based on the t-test this

470
00:22:51,780 --> 00:22:56,879
is 99 percent they are different and the

471
00:22:54,630 --> 00:22:59,160
effect size another metric that we use

472
00:22:56,880 --> 00:23:02,070
for statistics the effect size is 2

473
00:22:59,160 --> 00:23:05,780
which is more than threshold we use 33

474
00:23:02,070 --> 00:23:11,360
so this difference is of practical value

475
00:23:05,780 --> 00:23:15,780
so since so we did it with two cases to

476
00:23:11,360 --> 00:23:17,729
two studies like this so this is one we

477
00:23:15,780 --> 00:23:19,710
had another one in the paper so

478
00:23:17,730 --> 00:23:23,370
considering that occur capability with

479
00:23:19,710 --> 00:23:28,050
this evidence is reduces the uncertainty

480
00:23:23,370 --> 00:23:30,479
in the risk estimation so my suggestion

481
00:23:28,050 --> 00:23:32,399
if you are going to do risk estimation

482
00:23:30,480 --> 00:23:36,240
one of the things that you start looking

483
00:23:32,400 --> 00:23:38,370
for is to see the attackers what are the

484
00:23:36,240 --> 00:23:41,040
capability of the attackers from there

485
00:23:38,370 --> 00:23:44,580
you start you should consider that as

486
00:23:41,040 --> 00:23:46,440
one of the items that you use obviously

487
00:23:44,580 --> 00:23:48,470
whether the hardware is available

488
00:23:46,440 --> 00:23:52,170
whether the scripts are available

489
00:23:48,470 --> 00:23:54,450
although we did not prove whether that

490
00:23:52,170 --> 00:23:55,920
that's correct or not so you could might

491
00:23:54,450 --> 00:23:59,010
consider them but the tagger community

492
00:23:55,920 --> 00:24:01,110
should be the one is there others

493
00:23:59,010 --> 00:24:07,770
probably that needs probably more

494
00:24:01,110 --> 00:24:09,479
studies to do so that's one roll so one

495
00:24:07,770 --> 00:24:11,190
roll is that we have a set of methods

496
00:24:09,480 --> 00:24:14,250
and a set of techniques and software

497
00:24:11,190 --> 00:24:17,540
security and a Pyrrhic research it helps

498
00:24:14,250 --> 00:24:21,150
to mature these methods and these models

499
00:24:17,540 --> 00:24:24,330
strugle going to the expert and bringing

500
00:24:21,150 --> 00:24:31,560
some data there that would help to

501
00:24:24,330 --> 00:24:34,320
improve them so that's good for what we

502
00:24:31,560 --> 00:24:36,060
learn about method what we did for for

503
00:24:34,320 --> 00:24:38,399
research but campus

504
00:24:36,060 --> 00:24:40,110
helped me to address my everyday problem

505
00:24:38,400 --> 00:24:42,060
I am in the company and they work on

506
00:24:40,110 --> 00:24:44,219
software security can this empirical

507
00:24:42,060 --> 00:24:47,190
research help me to work on my own

508
00:24:44,220 --> 00:24:49,980
problems and they're all here the second

509
00:24:47,190 --> 00:24:52,410
role which is also very classic is that

510
00:24:49,980 --> 00:24:55,880
it allows to identify recommendation for

511
00:24:52,410 --> 00:25:00,420
solving problems we take your example of

512
00:24:55,880 --> 00:25:05,790
a study that we did it at IBM and this

513
00:25:00,420 --> 00:25:09,090
is related to DevOps so at IBM they have

514
00:25:05,790 --> 00:25:12,480
a system for business analytics

515
00:25:09,090 --> 00:25:15,330
application and they develop projects

516
00:25:12,480 --> 00:25:17,100
that for the business analytics so you

517
00:25:15,330 --> 00:25:20,040
could see how things complicated

518
00:25:17,100 --> 00:25:22,500
different infrastructure they have for

519
00:25:20,040 --> 00:25:25,440
the analytics they have two tools here

520
00:25:22,500 --> 00:25:28,620
software prediction Watson analytics or

521
00:25:25,440 --> 00:25:32,310
SPSS they have their IBM information

522
00:25:28,620 --> 00:25:34,830
server and a lot of things that they

523
00:25:32,310 --> 00:25:36,810
could use to develop a new application

524
00:25:34,830 --> 00:25:41,159
for business analytics based on the

525
00:25:36,810 --> 00:25:44,159
demands the classic approach for

526
00:25:41,160 --> 00:25:49,080
developing application is that you do

527
00:25:44,160 --> 00:25:52,890
development you packages you make a

528
00:25:49,080 --> 00:25:56,340
package then you get kind of a release

529
00:25:52,890 --> 00:26:00,690
letters and that everything is in that

530
00:25:56,340 --> 00:26:02,580
package and it's worth pushing to the

531
00:26:00,690 --> 00:26:04,710
production and you get a set of

532
00:26:02,580 --> 00:26:08,580
signature so you could push it to the

533
00:26:04,710 --> 00:26:11,100
operation and the goal here is that if

534
00:26:08,580 --> 00:26:16,050
we're gonna have a problems it's already

535
00:26:11,100 --> 00:26:18,209
so we have we did a good analysis of

536
00:26:16,050 --> 00:26:20,820
when before to push it to the production

537
00:26:18,210 --> 00:26:22,890
and it's worth to push it and probably

538
00:26:20,820 --> 00:26:25,230
they will be risk but we studied them in

539
00:26:22,890 --> 00:26:30,210
advance so this happens in the release

540
00:26:25,230 --> 00:26:33,720
letter so this is good have development

541
00:26:30,210 --> 00:26:35,580
we have operation but very security a

542
00:26:33,720 --> 00:26:38,370
tendency we have been working on agile

543
00:26:35,580 --> 00:26:40,260
and this is kind of great but we finish

544
00:26:38,370 --> 00:26:42,000
our zile on the end of the development

545
00:26:40,260 --> 00:26:44,879
now we need to push it there are two

546
00:26:42,000 --> 00:26:47,490
different processes if we combine the

547
00:26:44,880 --> 00:26:49,180
development and the operation not Kjar

548
00:26:47,490 --> 00:26:52,540
or not to combine them but

549
00:26:49,180 --> 00:26:55,180
surely to connect them then we're going

550
00:26:52,540 --> 00:26:56,800
to have an added value so from developed

551
00:26:55,180 --> 00:27:00,940
from operation you could have feedback

552
00:26:56,800 --> 00:27:04,360
and from development you could have you

553
00:27:00,940 --> 00:27:06,220
could have collaboration one thing easy

554
00:27:04,360 --> 00:27:09,219
thing is when you develop an application

555
00:27:06,220 --> 00:27:11,200
and for security perspective you

556
00:27:09,220 --> 00:27:12,520
probably gonna study it or prepare it

557
00:27:11,200 --> 00:27:14,140
based on your development environment

558
00:27:12,520 --> 00:27:16,629
but you know what you need it you need

559
00:27:14,140 --> 00:27:19,150
it for the operation environment if you

560
00:27:16,630 --> 00:27:21,640
have a problems you want them to go fast

561
00:27:19,150 --> 00:27:24,670
to the development and come back to the

562
00:27:21,640 --> 00:27:28,180
operations so we need that feedback loop

563
00:27:24,670 --> 00:27:32,920
that would improve the way that how we

564
00:27:28,180 --> 00:27:38,740
manage software based on a study and see

565
00:27:32,920 --> 00:27:43,690
a technology so they did what are the

566
00:27:38,740 --> 00:27:47,860
obstacle that are stopping company from

567
00:27:43,690 --> 00:27:50,020
adopting this paradigm of having the

568
00:27:47,860 --> 00:27:52,659
development and operation strong

569
00:27:50,020 --> 00:27:55,600
communication there and at the top one

570
00:27:52,660 --> 00:27:59,020
was security or compliance concerns and

571
00:27:55,600 --> 00:28:03,219
this is with 28% difficult to justify

572
00:27:59,020 --> 00:28:05,889
from an ROI standpoint 27% organization

573
00:28:03,220 --> 00:28:10,090
complexity 27 so you have different

574
00:28:05,890 --> 00:28:13,150
factors but the top is actually the

575
00:28:10,090 --> 00:28:17,340
security and compliance concern if they

576
00:28:13,150 --> 00:28:20,680
solve that then that helps to to do it

577
00:28:17,340 --> 00:28:24,159
but actually what was the case for also

578
00:28:20,680 --> 00:28:27,780
for this kind of application at IBM they

579
00:28:24,160 --> 00:28:30,700
have a problem for security concerns and

580
00:28:27,780 --> 00:28:32,560
the question that we have here is what

581
00:28:30,700 --> 00:28:34,750
are the security aspect that should be

582
00:28:32,560 --> 00:28:36,760
considered when automating the

583
00:28:34,750 --> 00:28:38,620
development process the development and

584
00:28:36,760 --> 00:28:40,629
deployment process remember we have a

585
00:28:38,620 --> 00:28:42,790
development process you can hear you can

586
00:28:40,630 --> 00:28:45,010
have continuous integration but when it

587
00:28:42,790 --> 00:28:47,440
comes to the deployment those are

588
00:28:45,010 --> 00:28:50,110
separate you have release notice there

589
00:28:47,440 --> 00:28:52,360
so and the goal is that you can push

590
00:28:50,110 --> 00:28:56,199
things from the development that can go

591
00:28:52,360 --> 00:28:58,870
to the deployment in smooth way and the

592
00:28:56,200 --> 00:29:01,090
question for that we post here is what

593
00:28:58,870 --> 00:29:02,209
are the security aspect that we have and

594
00:29:01,090 --> 00:29:04,699
we have that

595
00:29:02,210 --> 00:29:12,110
there and we need to consider when

596
00:29:04,700 --> 00:29:15,710
thinking about the Java process so we

597
00:29:12,110 --> 00:29:18,709
studied their five projects one it was

598
00:29:15,710 --> 00:29:22,550
automated already and for that our

599
00:29:18,710 --> 00:29:25,040
manual processes and we interviewed nine

600
00:29:22,550 --> 00:29:27,800
participants they were from the testing

601
00:29:25,040 --> 00:29:32,540
developers on security project

602
00:29:27,800 --> 00:29:36,050
management we had variation of roles so

603
00:29:32,540 --> 00:29:39,379
we didn't we interviewed this this

604
00:29:36,050 --> 00:29:42,050
participant so we have an interview then

605
00:29:39,380 --> 00:29:44,540
the classic way for interviewing so you

606
00:29:42,050 --> 00:29:47,870
have the interview you prepare you

607
00:29:44,540 --> 00:29:50,629
select your participant you execute

608
00:29:47,870 --> 00:29:54,020
semi-structured you have the interviews

609
00:29:50,630 --> 00:29:57,170
you transcribe your interviews then out

610
00:29:54,020 --> 00:30:00,050
of this transcription you quote them to

611
00:29:57,170 --> 00:30:04,400
get meaningful information useful to

612
00:30:00,050 --> 00:30:06,800
answer the question so once you have

613
00:30:04,400 --> 00:30:09,740
those codes you have data extraction

614
00:30:06,800 --> 00:30:12,379
then you classify them so to get the

615
00:30:09,740 --> 00:30:18,220
aspect that you need and obviously you

616
00:30:12,380 --> 00:30:22,670
will analyze the results so that you got

617
00:30:18,220 --> 00:30:25,130
so one with when we did this analysis we

618
00:30:22,670 --> 00:30:27,140
notified first item probably is not

619
00:30:25,130 --> 00:30:30,770
related to security but it's related to

620
00:30:27,140 --> 00:30:35,450
the manual process why they would go to

621
00:30:30,770 --> 00:30:38,570
the to the DevOps so one of the criteria

622
00:30:35,450 --> 00:30:40,820
is the lack of qualified personnel so

623
00:30:38,570 --> 00:30:43,610
you might have you want to push to the

624
00:30:40,820 --> 00:30:46,399
operation but the guy who is going to do

625
00:30:43,610 --> 00:30:48,889
specific tests he is already on vacation

626
00:30:46,400 --> 00:30:51,410
and you have probably to wait so if you

627
00:30:48,890 --> 00:30:53,510
have manual then you might have lack of

628
00:30:51,410 --> 00:30:55,160
qualified personnel at the time that you

629
00:30:53,510 --> 00:30:57,620
need it and for example someone is

630
00:30:55,160 --> 00:31:00,380
qualified and but he is on vacation you

631
00:30:57,620 --> 00:31:03,739
have to wait there is the problem of

632
00:31:00,380 --> 00:31:06,410
difficult collaboration so this is

633
00:31:03,740 --> 00:31:09,080
mentioned 5 times in these interviews or

634
00:31:06,410 --> 00:31:11,450
5 items that are related to difficult

635
00:31:09,080 --> 00:31:14,990
collaboration there is the lack of good

636
00:31:11,450 --> 00:31:16,000
documentation so we had also three items

637
00:31:14,990 --> 00:31:18,280
that were mentioned

638
00:31:16,000 --> 00:31:21,760
for the lack of documentation frequent a

639
00:31:18,280 --> 00:31:23,940
human errors there is a lot of a lot of

640
00:31:21,760 --> 00:31:26,770
errors when you have manual process and

641
00:31:23,940 --> 00:31:28,920
obviously if you have error and you have

642
00:31:26,770 --> 00:31:33,700
a process then if you expect your

643
00:31:28,920 --> 00:31:36,850
application to be up it's not up on time

644
00:31:33,700 --> 00:31:40,120
there is a lot of manual tests five

645
00:31:36,850 --> 00:31:42,760
items related to manual tests this is

646
00:31:40,120 --> 00:31:45,129
also problem for manual process there is

647
00:31:42,760 --> 00:31:48,190
a lengthy deployment at some point they

648
00:31:45,130 --> 00:31:50,770
wait one week until the first day of

649
00:31:48,190 --> 00:31:53,290
full process is suited to have the

650
00:31:50,770 --> 00:31:55,120
application up which is very long

651
00:31:53,290 --> 00:31:56,860
especially if you want tomorrow to use

652
00:31:55,120 --> 00:31:58,090
the application the customer what's the

653
00:31:56,860 --> 00:31:59,800
more you use the application the

654
00:31:58,090 --> 00:32:01,990
application is ready come on guys can I

655
00:31:59,800 --> 00:32:05,290
use it now we are still working on the

656
00:32:01,990 --> 00:32:09,160
deployment so lantee deployment three

657
00:32:05,290 --> 00:32:11,170
times it was raised so you have a

658
00:32:09,160 --> 00:32:14,170
problem now you probably cannot go and

659
00:32:11,170 --> 00:32:16,060
justify your return on investment but

660
00:32:14,170 --> 00:32:17,680
from security perspective this is our

661
00:32:16,060 --> 00:32:20,530
main question what are the aspects that

662
00:32:17,680 --> 00:32:22,810
we need to consider the first major

663
00:32:20,530 --> 00:32:24,760
thing here is separation of duty we did

664
00:32:22,810 --> 00:32:26,649
before study for the literature and

665
00:32:24,760 --> 00:32:29,410
separation is use it was mentioned but

666
00:32:26,650 --> 00:32:30,100
it was not really dominant for this

667
00:32:29,410 --> 00:32:33,130
application

668
00:32:30,100 --> 00:32:34,959
it was dominant that the interviewers

669
00:32:33,130 --> 00:32:39,400
one of the main concern that they have

670
00:32:34,960 --> 00:32:41,380
is separation of duty so the developer

671
00:32:39,400 --> 00:32:44,050
should not be the one actually that

672
00:32:41,380 --> 00:32:46,180
takes care of the operation or should

673
00:32:44,050 --> 00:32:49,570
not be the one that takes care of the

674
00:32:46,180 --> 00:32:53,290
security review the enforcement of

675
00:32:49,570 --> 00:32:55,419
access control policy so if I am I am a

676
00:32:53,290 --> 00:32:57,990
developers I might have access to the

677
00:32:55,420 --> 00:33:00,940
database so I could fix my codes

678
00:32:57,990 --> 00:33:03,910
depending on everything there but I

679
00:33:00,940 --> 00:33:06,880
should not have access to those records

680
00:33:03,910 --> 00:33:10,480
in operation right I shouldn't be

681
00:33:06,880 --> 00:33:13,480
allowed so I can write with some data

682
00:33:10,480 --> 00:33:15,040
specific ones to fix my code to write

683
00:33:13,480 --> 00:33:17,740
the code but the operation one I

684
00:33:15,040 --> 00:33:20,530
shouldn't so if there is a connection

685
00:33:17,740 --> 00:33:23,350
between development and operation that

686
00:33:20,530 --> 00:33:25,780
aspect of enforcement of access policy

687
00:33:23,350 --> 00:33:28,810
should be there especially for this case

688
00:33:25,780 --> 00:33:31,870
access through to data

689
00:33:28,810 --> 00:33:34,300
the second the third aspect was the

690
00:33:31,870 --> 00:33:36,280
manual security tests so we do lot of

691
00:33:34,300 --> 00:33:39,580
pennies they do lot of penetration

692
00:33:36,280 --> 00:33:41,889
testing things are manual if you want to

693
00:33:39,580 --> 00:33:44,350
go for the automation you have problems

694
00:33:41,890 --> 00:33:47,470
you have many manual tests that are not

695
00:33:44,350 --> 00:33:49,360
automated they have also then made one

696
00:33:47,470 --> 00:33:51,160
of the main concern is the audit when

697
00:33:49,360 --> 00:33:53,560
they have applications before they push

698
00:33:51,160 --> 00:33:57,400
them the production they go through the

699
00:33:53,560 --> 00:34:02,110
audit and now they should consider the

700
00:33:57,400 --> 00:34:03,310
audit - they have security guidelines so

701
00:34:02,110 --> 00:34:06,969
they want to consider that these

702
00:34:03,310 --> 00:34:10,060
security guidelines how they are applied

703
00:34:06,970 --> 00:34:13,300
they should be in the automation process

704
00:34:10,060 --> 00:34:16,810
automated process - how to manage

705
00:34:13,300 --> 00:34:18,550
security issues and mitigation when

706
00:34:16,810 --> 00:34:21,190
vulnerability they discover Berner

707
00:34:18,550 --> 00:34:22,270
ability now how the process when you

708
00:34:21,190 --> 00:34:25,870
have the development and operation

709
00:34:22,270 --> 00:34:28,120
connected how things will work there is

710
00:34:25,870 --> 00:34:30,429
also the security team they are

711
00:34:28,120 --> 00:34:32,679
participating in the manual process and

712
00:34:30,429 --> 00:34:36,418
there was a concern if you have an

713
00:34:32,679 --> 00:34:38,770
automation for the four devil process

714
00:34:36,418 --> 00:34:40,839
someone probably is going to push things

715
00:34:38,770 --> 00:34:44,230
from development straight forward to put

716
00:34:40,840 --> 00:34:46,570
to the operation and the security team

717
00:34:44,230 --> 00:34:50,860
they will not be aware about that and

718
00:34:46,570 --> 00:34:55,870
there was concern about about that so

719
00:34:50,860 --> 00:34:57,760
those are several seven concerns that we

720
00:34:55,870 --> 00:35:01,690
identified we're going to have a look

721
00:34:57,760 --> 00:35:03,550
here for their separation of duty so you

722
00:35:01,690 --> 00:35:06,040
could see here we have development team

723
00:35:03,550 --> 00:35:09,430
we have basically the integration and

724
00:35:06,040 --> 00:35:11,230
testing team a central team and we have

725
00:35:09,430 --> 00:35:13,029
production team so you have the

726
00:35:11,230 --> 00:35:16,300
application development of the

727
00:35:13,030 --> 00:35:18,550
application they do lab tests and from

728
00:35:16,300 --> 00:35:20,740
lab tests they go and they prepare their

729
00:35:18,550 --> 00:35:24,340
packages once they prepare their

730
00:35:20,740 --> 00:35:29,529
packages they give it to the integration

731
00:35:24,340 --> 00:35:33,100
testing central team the IT ITC they

732
00:35:29,530 --> 00:35:35,590
perform the tests then if they have so

733
00:35:33,100 --> 00:35:37,390
they confirm the environment everything

734
00:35:35,590 --> 00:35:40,150
is going to run on the product on their

735
00:35:37,390 --> 00:35:42,279
environment and they push it to the

736
00:35:40,150 --> 00:35:44,920
development again so

737
00:35:42,280 --> 00:35:46,900
this is now it's ready so you could do

738
00:35:44,920 --> 00:35:49,690
your testing user testing for the

739
00:35:46,900 --> 00:35:52,900
development they do the tests they could

740
00:35:49,690 --> 00:35:56,140
fix bugs if there are any issues so they

741
00:35:52,900 --> 00:35:58,180
look there if everything there then they

742
00:35:56,140 --> 00:36:01,480
provide the release sign-off so they

743
00:35:58,180 --> 00:36:04,359
could push it to the production once

744
00:36:01,480 --> 00:36:07,150
they have that release sign-off the I

745
00:36:04,360 --> 00:36:09,580
t's the ITC they got the package they

746
00:36:07,150 --> 00:36:11,950
got the release so they could push it to

747
00:36:09,580 --> 00:36:14,920
the production they give it to the next

748
00:36:11,950 --> 00:36:17,799
third team so the third team they could

749
00:36:14,920 --> 00:36:20,110
work with the pushing things to the

750
00:36:17,800 --> 00:36:23,080
production but they have also to get

751
00:36:20,110 --> 00:36:26,500
that change management change management

752
00:36:23,080 --> 00:36:29,980
request signed off so we see to the

753
00:36:26,500 --> 00:36:32,560
minimum here big three three teams that

754
00:36:29,980 --> 00:36:34,870
they work and separation of duty they

755
00:36:32,560 --> 00:36:40,810
don't want someone who does development

756
00:36:34,870 --> 00:36:43,509
to probably participate in the code that

757
00:36:40,810 --> 00:36:46,420
is in the test environment if he is

758
00:36:43,510 --> 00:36:50,770
going to do anything there then that

759
00:36:46,420 --> 00:36:56,290
might compromise the numeric compromise

760
00:36:50,770 --> 00:36:59,830
the other package so obviously we can

761
00:36:56,290 --> 00:37:02,230
talk a lot about this separation of duty

762
00:36:59,830 --> 00:37:07,330
and how things can go wrong but

763
00:37:02,230 --> 00:37:10,840
basically this is this is the idea they

764
00:37:07,330 --> 00:37:13,870
also identified for best practices for

765
00:37:10,840 --> 00:37:15,580
the transformation to DevOps that based

766
00:37:13,870 --> 00:37:18,700
on their experience from the first

767
00:37:15,580 --> 00:37:21,850
project you need good documentation and

768
00:37:18,700 --> 00:37:24,279
you need the logging so from development

769
00:37:21,850 --> 00:37:26,049
activity you do good logging from

770
00:37:24,280 --> 00:37:28,300
pushing to the test you have a good

771
00:37:26,050 --> 00:37:30,310
blogging to push into production you

772
00:37:28,300 --> 00:37:33,040
have a good logging in case of a

773
00:37:30,310 --> 00:37:35,220
problems you can go back to identify if

774
00:37:33,040 --> 00:37:37,690
you have anything that you need to do

775
00:37:35,220 --> 00:37:39,640
you need strong collaboration and

776
00:37:37,690 --> 00:37:42,220
communications so they have it all ready

777
00:37:39,640 --> 00:37:44,379
for manual process they have hard time

778
00:37:42,220 --> 00:37:46,779
for collaboration but if you want to

779
00:37:44,380 --> 00:37:49,440
work on the verbs secure DevOps you need

780
00:37:46,780 --> 00:37:52,510
strong collaboration and communication

781
00:37:49,440 --> 00:37:56,170
the third obvious is the automation of

782
00:37:52,510 --> 00:37:59,410
process and the fourth item

783
00:37:56,170 --> 00:38:01,960
is the enforcement of separation of duty

784
00:37:59,410 --> 00:38:08,470
so it's best practice to have an

785
00:38:01,960 --> 00:38:12,010
enforcement of separation of duty so we

786
00:38:08,470 --> 00:38:14,589
have now two roles we've seen from the

787
00:38:12,010 --> 00:38:16,780
empirical research the first role is it

788
00:38:14,589 --> 00:38:18,880
helps to mature the methods and the

789
00:38:16,780 --> 00:38:21,790
techniques that we have for software

790
00:38:18,880 --> 00:38:24,460
security the second role we could have

791
00:38:21,790 --> 00:38:25,990
from practical point of view to study

792
00:38:24,460 --> 00:38:28,329
problems and come up with the

793
00:38:25,990 --> 00:38:31,328
recommendation from the expert so you go

794
00:38:28,329 --> 00:38:34,869
to more people you bring that wisdom and

795
00:38:31,329 --> 00:38:36,160
that wisdom you could use it so IBM the

796
00:38:34,869 --> 00:38:37,839
last communication I have I think

797
00:38:36,160 --> 00:38:39,460
probably two weeks ago they said that

798
00:38:37,839 --> 00:38:41,078
they got those recommendation and they

799
00:38:39,460 --> 00:38:46,260
implemented them for the other project

800
00:38:41,079 --> 00:38:49,930
which is it was good useful for them so

801
00:38:46,260 --> 00:38:52,630
the third rule this is a talk when I be

802
00:38:49,930 --> 00:38:58,180
M this is IBM Germany so this is where I

803
00:38:52,630 --> 00:39:00,599
was before so the role 3 is that we have

804
00:38:58,180 --> 00:39:03,220
a lot of accepted truth and our

805
00:39:00,599 --> 00:39:05,410
self-evident statement when we started

806
00:39:03,220 --> 00:39:08,890
security there's a lot of several

807
00:39:05,410 --> 00:39:11,348
professors that they have weight and

808
00:39:08,890 --> 00:39:13,690
they come up with a statement and as a

809
00:39:11,349 --> 00:39:16,720
student we got those statement and we

810
00:39:13,690 --> 00:39:18,579
believe that those are truths and some

811
00:39:16,720 --> 00:39:20,230
people they come later on with something

812
00:39:18,579 --> 00:39:23,500
that we like it probably it's well

813
00:39:20,230 --> 00:39:26,619
written and we use those are accepted

814
00:39:23,500 --> 00:39:29,260
truth empirical research would allow

815
00:39:26,619 --> 00:39:32,140
also to verify these accepted truth well

816
00:39:29,260 --> 00:39:35,440
this is what we believe this correct and

817
00:39:32,140 --> 00:39:38,910
we accept it as it is can we prove it

818
00:39:35,440 --> 00:39:43,150
whether it's a true or actually it's not

819
00:39:38,910 --> 00:39:45,069
so I give here example so our the first

820
00:39:43,150 --> 00:39:47,290
role I give more detailed application

821
00:39:45,069 --> 00:39:52,049
the second one also more detailed

822
00:39:47,290 --> 00:39:52,049
example here for example there is one

823
00:39:52,610 --> 00:39:56,900
one through with that probably when we

824
00:39:55,130 --> 00:39:58,520
talk about the time to fix security

825
00:39:56,900 --> 00:40:01,630
vulnerability whether this is a

826
00:39:58,520 --> 00:40:04,730
cross-site scripting sequel injection or

827
00:40:01,630 --> 00:40:07,070
authentication or whatever we would jump

828
00:40:04,730 --> 00:40:09,200
and we say code complexity this is the

829
00:40:07,070 --> 00:40:12,080
factor that is the most important that

830
00:40:09,200 --> 00:40:14,060
what we should consider when we do the

831
00:40:12,080 --> 00:40:16,819
estimation of the time to fix security

832
00:40:14,060 --> 00:40:18,830
availability the answer actually is not

833
00:40:16,820 --> 00:40:22,250
so we did a study in this study

834
00:40:18,830 --> 00:40:26,509
it's on 2004 at SAT and we found I think

835
00:40:22,250 --> 00:40:28,430
more than 50 factor and the one probably

836
00:40:26,510 --> 00:40:31,400
one of the most important is the skills

837
00:40:28,430 --> 00:40:34,339
of the developer how how good have they

838
00:40:31,400 --> 00:40:37,730
have skills their skills to identify

839
00:40:34,340 --> 00:40:41,570
these these vulnerability so that's also

840
00:40:37,730 --> 00:40:45,500
very important so not only that you have

841
00:40:41,570 --> 00:40:48,140
the the code complexity but but also the

842
00:40:45,500 --> 00:40:50,780
skills and the experience of these of

843
00:40:48,140 --> 00:40:55,400
the developers the type of vulnerability

844
00:40:50,780 --> 00:40:57,470
and so on so this through that code

845
00:40:55,400 --> 00:40:59,930
complexity this is the main factor that

846
00:40:57,470 --> 00:41:03,020
you should consider for when saying that

847
00:40:59,930 --> 00:41:05,330
you are going to fix this value fix this

848
00:41:03,020 --> 00:41:05,900
variability in three days or in two

849
00:41:05,330 --> 00:41:08,870
hours

850
00:41:05,900 --> 00:41:11,470
you should also consider who actually is

851
00:41:08,870 --> 00:41:16,370
going to do that how much experience

852
00:41:11,470 --> 00:41:18,890
does he have or she has so the second

853
00:41:16,370 --> 00:41:21,799
one is when we talk about agile

854
00:41:18,890 --> 00:41:23,720
development we talk often that there is

855
00:41:21,800 --> 00:41:26,180
a mismatch with software security and

856
00:41:23,720 --> 00:41:28,160
this is kind of something people they

857
00:41:26,180 --> 00:41:30,200
have it there is a mismatch we have

858
00:41:28,160 --> 00:41:32,299
software security you need threat

859
00:41:30,200 --> 00:41:35,089
modeling you need risk in InDesign and

860
00:41:32,300 --> 00:41:37,040
you need implementation if you have a

861
00:41:35,090 --> 00:41:39,470
change then your design is not correct

862
00:41:37,040 --> 00:41:43,460
then you have to do things again from

863
00:41:39,470 --> 00:41:46,100
scratch because for agile you are going

864
00:41:43,460 --> 00:41:48,710
to iterate often so we might go with

865
00:41:46,100 --> 00:41:51,650
this simplistic idea and jump there so

866
00:41:48,710 --> 00:41:53,990
we did kind an analysis of the

867
00:41:51,650 --> 00:41:56,030
literature what are the literature that

868
00:41:53,990 --> 00:41:59,089
they are talking about how to apply

869
00:41:56,030 --> 00:42:00,950
agile and software security and we come

870
00:41:59,090 --> 00:42:02,540
that there are items that there are

871
00:42:00,950 --> 00:42:05,490
problems that needs to be solved and

872
00:42:02,540 --> 00:42:07,259
there are items that actually it's okay

873
00:42:05,490 --> 00:42:09,149
the practices companies the users

874
00:42:07,260 --> 00:42:11,550
already so because they avoid these

875
00:42:09,150 --> 00:42:15,780
these problems or they have solved these

876
00:42:11,550 --> 00:42:17,790
problems the third item is code

877
00:42:15,780 --> 00:42:19,440
vulnerability vulnerability at the code

878
00:42:17,790 --> 00:42:23,670
level they are the main software

879
00:42:19,440 --> 00:42:26,400
security flaws so this is here we have

880
00:42:23,670 --> 00:42:29,430
study four-for-one software's and card

881
00:42:26,400 --> 00:42:32,880
but I refer here to the I Triple E cyber

882
00:42:29,430 --> 00:42:34,740
security report top ten flaws and in

883
00:42:32,880 --> 00:42:36,990
this report they would say the same

884
00:42:34,740 --> 00:42:39,890
based on study that they got code from

885
00:42:36,990 --> 00:42:41,669
big company there are as many

886
00:42:39,890 --> 00:42:44,279
vulnerability at the design level

887
00:42:41,670 --> 00:42:46,590
authentication authorization as you

888
00:42:44,280 --> 00:42:49,080
would have also encode so it's not that

889
00:42:46,590 --> 00:42:52,770
the code vulnerability that are most

890
00:42:49,080 --> 00:42:54,690
frequent they are actually probably from

891
00:42:52,770 --> 00:42:57,990
academia and so on people they report

892
00:42:54,690 --> 00:43:03,990
this but the the design flaws they are

893
00:42:57,990 --> 00:43:06,240
also very important from a publication

894
00:43:03,990 --> 00:43:08,490
or from when we talk to colleagues on

895
00:43:06,240 --> 00:43:10,618
dev ops or sector fobs

896
00:43:08,490 --> 00:43:12,540
we report that the collaboration problem

897
00:43:10,619 --> 00:43:14,940
between the developers and the operation

898
00:43:12,540 --> 00:43:16,770
and actually the automation of the

899
00:43:14,940 --> 00:43:19,590
process those are the main concerns

900
00:43:16,770 --> 00:43:21,480
we've seen now for the study that I

901
00:43:19,590 --> 00:43:24,510
showed that probably for the case of

902
00:43:21,480 --> 00:43:26,430
ambient separation of duty is one of the

903
00:43:24,510 --> 00:43:30,240
main concern it notified more than these

904
00:43:26,430 --> 00:43:31,950
so this are kind of truth that we jump

905
00:43:30,240 --> 00:43:33,509
we have on the talk that we say

906
00:43:31,950 --> 00:43:35,189
collaboration automation this is really

907
00:43:33,510 --> 00:43:39,900
what you need to solve and you could

908
00:43:35,190 --> 00:43:42,000
have Dex that's a sec DevOps know for

909
00:43:39,900 --> 00:43:43,650
the case of IBM it was the main thing is

910
00:43:42,000 --> 00:43:46,350
the access control and separation of

911
00:43:43,650 --> 00:43:49,710
duty those are the two items among the

912
00:43:46,350 --> 00:43:51,180
top that they need to solve going if we

913
00:43:49,710 --> 00:43:53,130
consider malware whether this is

914
00:43:51,180 --> 00:43:56,700
software security or not we had also

915
00:43:53,130 --> 00:43:59,820
studied in 2016 we got 1000 recent

916
00:43:56,700 --> 00:44:01,439
malware and we try to see whether they

917
00:43:59,820 --> 00:44:03,600
access the files they access the

918
00:44:01,440 --> 00:44:05,670
registry they change the file system

919
00:44:03,600 --> 00:44:06,900
they change the registry are they access

920
00:44:05,670 --> 00:44:09,900
the network or not

921
00:44:06,900 --> 00:44:13,020
so for each we give it about two minutes

922
00:44:09,900 --> 00:44:14,850
to check whether this true or not this

923
00:44:13,020 --> 00:44:16,470
is kind of also it's believed that when

924
00:44:14,850 --> 00:44:18,990
you have malware they are going to

925
00:44:16,470 --> 00:44:19,330
change the file system they are going to

926
00:44:18,990 --> 00:44:21,459
change

927
00:44:19,330 --> 00:44:25,090
the registry and they are going to use

928
00:44:21,460 --> 00:44:27,250
the network and we found for most in

929
00:44:25,090 --> 00:44:29,050
general so they did not exhibit this

930
00:44:27,250 --> 00:44:31,030
behavior at least the recent one they

931
00:44:29,050 --> 00:44:35,010
are not exhibiting this behavior they

932
00:44:31,030 --> 00:44:38,410
are slow column they do not give you

933
00:44:35,010 --> 00:44:44,890
much opportunity as it was before to

934
00:44:38,410 --> 00:44:49,000
identify that they are behaving so we

935
00:44:44,890 --> 00:44:53,080
have three now roles and the four role

936
00:44:49,000 --> 00:44:55,420
is actually now what about if I have new

937
00:44:53,080 --> 00:44:58,330
problems if I have new problems I could

938
00:44:55,420 --> 00:45:00,160
jump myself and I could solve it but

939
00:44:58,330 --> 00:45:02,110
empirical research they could help you

940
00:45:00,160 --> 00:45:05,529
to explore techniques for solving the

941
00:45:02,110 --> 00:45:07,900
problem so we take the case of

942
00:45:05,530 --> 00:45:10,240
incremental development on software

943
00:45:07,900 --> 00:45:11,800
security for the case of software's and

944
00:45:10,240 --> 00:45:15,700
card this is an open source for

945
00:45:11,800 --> 00:45:19,390
e-commerce so it's one of the main one

946
00:45:15,700 --> 00:45:23,680
main open source for e-commerce used and

947
00:45:19,390 --> 00:45:25,060
we took that the software and we studied

948
00:45:23,680 --> 00:45:27,940
the vulnerability was that different

949
00:45:25,060 --> 00:45:29,680
aspect from security perspective one of

950
00:45:27,940 --> 00:45:32,440
the things that we did we did the

951
00:45:29,680 --> 00:45:36,339
interview for the security lead so we

952
00:45:32,440 --> 00:45:40,360
want to learn from him security aspect

953
00:45:36,340 --> 00:45:43,120
that he has with a fourth and card so

954
00:45:40,360 --> 00:45:46,140
that would help because this is

955
00:45:43,120 --> 00:45:49,210
incremental incremental development - so

956
00:45:46,140 --> 00:45:50,589
we got few first few remarks here that

957
00:45:49,210 --> 00:45:53,620
needs to be considered when we talk

958
00:45:50,590 --> 00:45:56,500
about incremental development the

959
00:45:53,620 --> 00:46:00,960
changes of the security requirement of

960
00:45:56,500 --> 00:46:03,730
the payment the payment current district

961
00:46:00,960 --> 00:46:07,000
implies for their case complete

962
00:46:03,730 --> 00:46:12,880
assessment for every two years there are

963
00:46:07,000 --> 00:46:15,610
new version for the PA DSS this is for

964
00:46:12,880 --> 00:46:16,990
the banking and the the payment for

965
00:46:15,610 --> 00:46:19,090
every two years there is a new version

966
00:46:16,990 --> 00:46:21,009
for every two years they stop the

967
00:46:19,090 --> 00:46:23,950
development they spend about two months

968
00:46:21,010 --> 00:46:27,210
to do the evaluation so that two months

969
00:46:23,950 --> 00:46:30,759
is kind of 10% which is timely time lost

970
00:46:27,210 --> 00:46:32,710
code the changes may imply security and

971
00:46:30,760 --> 00:46:34,960
party security mechanism if you do

972
00:46:32,710 --> 00:46:37,359
go change you might have your

973
00:46:34,960 --> 00:46:40,000
authentication authorization broken and

974
00:46:37,359 --> 00:46:42,130
that happens from time to time so you

975
00:46:40,000 --> 00:46:46,510
have to be careful when you do code code

976
00:46:42,130 --> 00:46:49,060
code changes if they change even the

977
00:46:46,510 --> 00:46:53,200
framework that they use for the

978
00:46:49,060 --> 00:46:56,410
application for example because the u.s.

979
00:46:53,200 --> 00:46:58,509
PHP if they use a new version of the

980
00:46:56,410 --> 00:47:02,379
framework or other label that they could

981
00:46:58,510 --> 00:47:04,570
use this might imply that their security

982
00:47:02,380 --> 00:47:06,550
mechanism they are not valid anymore and

983
00:47:04,570 --> 00:47:09,670
they have several cases so they change

984
00:47:06,550 --> 00:47:11,650
the framework not their own code and

985
00:47:09,670 --> 00:47:17,140
some security mechanisms they don't work

986
00:47:11,650 --> 00:47:19,990
the way that they need to based on so

987
00:47:17,140 --> 00:47:23,710
his hunt over the code and for 50

988
00:47:19,990 --> 00:47:25,390
comment change change that they

989
00:47:23,710 --> 00:47:27,790
commented on because whenever they got

990
00:47:25,390 --> 00:47:29,770
to change first thing is the main

991
00:47:27,790 --> 00:47:32,080
developers they discussed the impact on

992
00:47:29,770 --> 00:47:35,859
security or the impact of the change on

993
00:47:32,080 --> 00:47:37,990
security they found that for every 50

994
00:47:35,859 --> 00:47:39,759
comments one of them it concerns

995
00:47:37,990 --> 00:47:44,290
security they have to be careful about

996
00:47:39,760 --> 00:47:47,050
it if they do not its security broken so

997
00:47:44,290 --> 00:47:49,960
those comments that we have we can see

998
00:47:47,050 --> 00:47:52,000
that the change code changes they

999
00:47:49,960 --> 00:47:53,890
potentially have impact on the security

1000
00:47:52,000 --> 00:47:57,609
of the software and they have to be

1001
00:47:53,890 --> 00:48:00,430
careful about it so we have a case now

1002
00:47:57,609 --> 00:48:03,130
what is the solution to give to work

1003
00:48:00,430 --> 00:48:05,919
with that problem so one simple solution

1004
00:48:03,130 --> 00:48:07,810
like the PA DSS is to do full

1005
00:48:05,920 --> 00:48:10,119
reassessment every two years you need to

1006
00:48:07,810 --> 00:48:12,670
do full reassessment you go to the code

1007
00:48:10,119 --> 00:48:14,530
review especially the money on manual

1008
00:48:12,670 --> 00:48:17,800
one penetration testing you have to do

1009
00:48:14,530 --> 00:48:21,460
them fool again there are solution

1010
00:48:17,800 --> 00:48:24,310
actually practical one practical one for

1011
00:48:21,460 --> 00:48:26,680
the for their case the first thing is

1012
00:48:24,310 --> 00:48:28,720
when they have a change they discuss the

1013
00:48:26,680 --> 00:48:31,210
impact of the change on the software

1014
00:48:28,720 --> 00:48:36,129
security so they have an evaluation

1015
00:48:31,210 --> 00:48:39,760
there in another company that we studied

1016
00:48:36,130 --> 00:48:41,890
so they do peer review of the changes

1017
00:48:39,760 --> 00:48:42,550
they have before at the end of each

1018
00:48:41,890 --> 00:48:46,069
sprint

1019
00:48:42,550 --> 00:48:48,200
everyone gets his code they sit together

1020
00:48:46,070 --> 00:48:50,660
and everyone gives through another

1021
00:48:48,200 --> 00:48:53,240
developers that they trust to go and

1022
00:48:50,660 --> 00:48:54,740
they to check what is the impact of the

1023
00:48:53,240 --> 00:48:56,689
code changes that they did on their

1024
00:48:54,740 --> 00:48:58,509
security and whether they have the near

1025
00:48:56,690 --> 00:49:03,290
ability there or not

1026
00:48:58,510 --> 00:49:07,310
that case was in Germany so hearing us

1027
00:49:03,290 --> 00:49:09,080
had one so far one company and we went

1028
00:49:07,310 --> 00:49:12,170
through them and what they do for

1029
00:49:09,080 --> 00:49:15,610
example they scan the code for keywords

1030
00:49:12,170 --> 00:49:18,560
so if you are using specific libraries

1031
00:49:15,610 --> 00:49:21,440
for cryptography and so on they would

1032
00:49:18,560 --> 00:49:23,299
scan this the code for those keywords

1033
00:49:21,440 --> 00:49:25,580
for the method that you have for the

1034
00:49:23,300 --> 00:49:28,370
label that you have if you touch these

1035
00:49:25,580 --> 00:49:31,819
things then you have security aspect

1036
00:49:28,370 --> 00:49:34,640
someone needs to verify so keywords this

1037
00:49:31,820 --> 00:49:36,770
is another approach another one is that

1038
00:49:34,640 --> 00:49:38,299
the developers they are the comment when

1039
00:49:36,770 --> 00:49:40,340
they do change

1040
00:49:38,300 --> 00:49:42,620
they are the comment there and they say

1041
00:49:40,340 --> 00:49:45,680
there is a potential impact of security

1042
00:49:42,620 --> 00:49:47,930
of this portion of code that implies the

1043
00:49:45,680 --> 00:49:52,430
code needs to be reviewed by security

1044
00:49:47,930 --> 00:49:54,379
expert so or actually they potentially

1045
00:49:52,430 --> 00:49:58,310
that is one of the solution is to add

1046
00:49:54,380 --> 00:50:00,560
the notation to the software so to say

1047
00:49:58,310 --> 00:50:04,190
that this related to authentication this

1048
00:50:00,560 --> 00:50:05,870
related to authorization once you have

1049
00:50:04,190 --> 00:50:08,540
this anotation

1050
00:50:05,870 --> 00:50:10,130
you could scan it and you know this is

1051
00:50:08,540 --> 00:50:14,990
authentication you have to be careful

1052
00:50:10,130 --> 00:50:18,130
about these methods so this kind of

1053
00:50:14,990 --> 00:50:20,540
existing now solution but this is from

1054
00:50:18,130 --> 00:50:23,000
people who deal with the problems how

1055
00:50:20,540 --> 00:50:25,810
actually they deal with it and the goal

1056
00:50:23,000 --> 00:50:28,880
at some point is to come up with a way

1057
00:50:25,810 --> 00:50:31,430
that should work practical way that

1058
00:50:28,880 --> 00:50:34,370
should work the default ways you do

1059
00:50:31,430 --> 00:50:37,040
reassessment for reassessment right so

1060
00:50:34,370 --> 00:50:44,630
this is one aspect that we are working

1061
00:50:37,040 --> 00:50:49,160
on before going further so it's nice we

1062
00:50:44,630 --> 00:50:52,600
have one almost now on time so we have

1063
00:50:49,160 --> 00:50:56,120
empirical research we could use them for

1064
00:50:52,600 --> 00:50:59,339
we have four roles we specified for

1065
00:50:56,120 --> 00:51:02,220
software security but there are

1066
00:50:59,340 --> 00:51:06,150
imitation for that and the limitation

1067
00:51:02,220 --> 00:51:08,669
for empirical study we call them threats

1068
00:51:06,150 --> 00:51:11,460
to validity threats to validity specific

1069
00:51:08,670 --> 00:51:14,040
way in which the study might be wrong so

1070
00:51:11,460 --> 00:51:16,650
things might go might be what we are

1071
00:51:14,040 --> 00:51:19,740
reporting is wrong if you refer on the

1072
00:51:16,650 --> 00:51:22,440
first study that I showed we talked

1073
00:51:19,740 --> 00:51:25,290
about the t-test but we also give the

1074
00:51:22,440 --> 00:51:27,240
effect size that's implies that this is

1075
00:51:25,290 --> 00:51:29,730
practical value from statistics this is

1076
00:51:27,240 --> 00:51:32,759
correct it's so possible that the study

1077
00:51:29,730 --> 00:51:35,250
you forget to do that or that probably

1078
00:51:32,760 --> 00:51:38,700
that value is not it's not good so you

1079
00:51:35,250 --> 00:51:41,400
cannot have conclusive results if you

1080
00:51:38,700 --> 00:51:43,589
choose also you have study then you did

1081
00:51:41,400 --> 00:51:47,010
not go through the participant that

1082
00:51:43,590 --> 00:51:49,080
represents the domain then you do not

1083
00:51:47,010 --> 00:51:51,090
have a good picture you if you say that

1084
00:51:49,080 --> 00:51:53,430
you have a good picture that's not true

1085
00:51:51,090 --> 00:51:55,920
but if you say that you have perspective

1086
00:51:53,430 --> 00:51:59,190
or specific people for specific case

1087
00:51:55,920 --> 00:52:01,890
then that would applies my questioning

1088
00:51:59,190 --> 00:52:05,160
here is how to assess the validity of an

1089
00:52:01,890 --> 00:52:08,879
empirical study I was gonna answer it

1090
00:52:05,160 --> 00:52:12,680
he's gonna get this book how to assess

1091
00:52:08,880 --> 00:52:12,680
the validity of empirical study

1092
00:52:15,630 --> 00:52:21,099
try you you benchmark it you bench those

1093
00:52:19,119 --> 00:52:22,839
different empirical studies about the

1094
00:52:21,099 --> 00:52:26,140
results of what happened from doing them

1095
00:52:22,839 --> 00:52:28,808
against real world situations you do

1096
00:52:26,140 --> 00:52:30,790
benchmarking against so this is the

1097
00:52:28,809 --> 00:52:32,950
first one and this is you identify your

1098
00:52:30,790 --> 00:52:35,710
question right how did how to find out

1099
00:52:32,950 --> 00:52:38,049
the theory and the practice you you have

1100
00:52:35,710 --> 00:52:41,859
to go back to reality and say okay the

1101
00:52:38,050 --> 00:52:45,369
empirical study really achieved a

1102
00:52:41,859 --> 00:52:47,109
success we were looking at go it has it

1103
00:52:45,369 --> 00:52:49,480
depends upon how you define success when

1104
00:52:47,109 --> 00:52:53,799
the empirical studies versus the normal

1105
00:52:49,480 --> 00:52:56,770
processes you used before I'm gonna give

1106
00:52:53,800 --> 00:52:59,109
here it's a good question so if you hear

1107
00:52:56,770 --> 00:53:01,720
I'm saying assess the validity if you

1108
00:52:59,109 --> 00:53:03,190
say success then implies that you apply

1109
00:53:01,720 --> 00:53:04,540
your own particular research again and

1110
00:53:03,190 --> 00:53:09,130
you check whether it's valid or not

1111
00:53:04,540 --> 00:53:11,950
that's the replication so if you have an

1112
00:53:09,130 --> 00:53:15,520
empirical study now how you assess what

1113
00:53:11,950 --> 00:53:17,140
are the limitation of this study if I

1114
00:53:15,520 --> 00:53:21,069
reform it how you assess that this

1115
00:53:17,140 --> 00:53:31,029
studied has a limitation specific

1116
00:53:21,069 --> 00:53:33,130
limitation in the study did you qualify

1117
00:53:31,030 --> 00:53:35,770
what you're looking at before you

1118
00:53:33,130 --> 00:53:39,849
started how did you say we're looking

1119
00:53:35,770 --> 00:53:42,240
we're focusing on these things which one

1120
00:53:39,849 --> 00:53:42,240
probably

1121
00:53:53,700 --> 00:53:58,980
I'm gonna make this question sir but

1122
00:53:56,310 --> 00:54:00,840
it's just a reflection on it we would

1123
00:53:58,980 --> 00:54:04,050
know that mathematical perspective is

1124
00:54:00,840 --> 00:54:05,910
something and when it comes to empirical

1125
00:54:04,050 --> 00:54:06,750
research you could prove that but here

1126
00:54:05,910 --> 00:54:09,810
it's different

1127
00:54:06,750 --> 00:54:12,180
would it be okay here if I did not say

1128
00:54:09,810 --> 00:54:15,120
that the effect size is though if I said

1129
00:54:12,180 --> 00:54:18,419
that the effect size was let's say is

1130
00:54:15,120 --> 00:54:23,400
0-2 would that be okay can I have a

1131
00:54:18,420 --> 00:54:31,070
conclusive result here can I claim this

1132
00:54:23,400 --> 00:54:33,570
result I cannot

1133
00:54:31,070 --> 00:54:36,030
that's from statistical perspective I

1134
00:54:33,570 --> 00:54:40,740
cannot conclude that so that's an

1135
00:54:36,030 --> 00:54:46,470
example so empirical research they are

1136
00:54:40,740 --> 00:54:48,299
not so one get it so we have a study

1137
00:54:46,470 --> 00:54:50,759
here about threat to validity when

1138
00:54:48,300 --> 00:54:53,910
chapter in the book so whoever wants to

1139
00:54:50,760 --> 00:54:59,130
get good answer can get this as a gift

1140
00:54:53,910 --> 00:55:03,210
for today so you have a lot of criteria

1141
00:54:59,130 --> 00:55:05,580
that you go to analyze your work and

1142
00:55:03,210 --> 00:55:07,440
your result and how you did things to

1143
00:55:05,580 --> 00:55:10,049
know what are the limitation of your

1144
00:55:07,440 --> 00:55:13,320
study empirical research all the time

1145
00:55:10,050 --> 00:55:16,230
they have limitation so far so whenever

1146
00:55:13,320 --> 00:55:18,720
we say things it's not as complete as if

1147
00:55:16,230 --> 00:55:28,680
you write to prove all the proofs also

1148
00:55:18,720 --> 00:55:30,839
you have Assumption right so with this I

1149
00:55:28,680 --> 00:55:34,230
would say that when we talk about

1150
00:55:30,840 --> 00:55:36,120
science or at least our hard science we

1151
00:55:34,230 --> 00:55:38,880
talk that we have causality and we have

1152
00:55:36,120 --> 00:55:41,370
repeatability we can repeat things but

1153
00:55:38,880 --> 00:55:44,070
when we talk about empirical research we

1154
00:55:41,370 --> 00:55:48,779
talk about observation on general of

1155
00:55:44,070 --> 00:55:50,850
patterns this is what we get and but we

1156
00:55:48,780 --> 00:55:52,380
have observation we have patterns it's

1157
00:55:50,850 --> 00:55:55,049
better than we do not have anything

1158
00:55:52,380 --> 00:55:59,820
right if better than we have only

1159
00:55:55,050 --> 00:56:01,590
opinions that that we use so but

1160
00:55:59,820 --> 00:56:03,900
observation should have to identify

1161
00:56:01,590 --> 00:56:06,450
causality and repeatability so if we

1162
00:56:03,900 --> 00:56:07,320
have a lot of patterns then we increase

1163
00:56:06,450 --> 00:56:10,049
our knowledge

1164
00:56:07,320 --> 00:56:14,490
potentially we can come to two causality

1165
00:56:10,050 --> 00:56:17,190
and we can come to to science so this is

1166
00:56:14,490 --> 00:56:19,259
the last slide for my presentation I

1167
00:56:17,190 --> 00:56:20,880
hope I convinced you about the value of

1168
00:56:19,260 --> 00:56:24,000
empirical research for software security

1169
00:56:20,880 --> 00:56:26,340
so I showed four rules here that we

1170
00:56:24,000 --> 00:56:28,860
worked on there are probably other roles

1171
00:56:26,340 --> 00:56:33,000
that empirical research could help with

1172
00:56:28,860 --> 00:56:37,760
and we could have better way for to

1173
00:56:33,000 --> 00:56:42,569
develop secure software so thank you

1174
00:56:37,760 --> 00:56:42,569
[Applause]

1175
00:56:47,880 --> 00:56:49,940
you

