1
00:00:00,000 --> 00:00:01,920
good afternoon and welcome to this

2
00:00:01,920 --> 00:00:03,659
week's serious security Symposium from

3
00:00:03,659 --> 00:00:05,880
Purdue University before we start I want

4
00:00:05,880 --> 00:00:08,160
to ask you to please mark your calendars

5
00:00:08,160 --> 00:00:10,320
for the 24th annual serious cyber

6
00:00:10,320 --> 00:00:12,660
security Symposium our signature event

7
00:00:12,660 --> 00:00:15,480
this year will be an in-person event at

8
00:00:15,480 --> 00:00:18,600
Purdue University on March 28th 29th it

9
00:00:18,600 --> 00:00:21,300
is open to the general public uh the

10
00:00:21,300 --> 00:00:23,699
agenda has not yet been posted but will

11
00:00:23,699 --> 00:00:26,279
here within the month and we're looking

12
00:00:26,279 --> 00:00:28,439
forward to to the event it'll also

13
00:00:28,439 --> 00:00:30,960
coincide with the 25th anniversary of

14
00:00:30,960 --> 00:00:32,759
Sirius

15
00:00:32,759 --> 00:00:35,940
so with that I am pleased to kick off

16
00:00:35,940 --> 00:00:38,880
this session Gideon Rasmussen has a long

17
00:00:38,880 --> 00:00:40,620
history in the cyber security industry

18
00:00:40,620 --> 00:00:42,360
dating back to his military career

19
00:00:42,360 --> 00:00:44,820
before we called anything cyber his

20
00:00:44,820 --> 00:00:46,320
experience includes a number of security

21
00:00:46,320 --> 00:00:48,360
positions in several Industries within

22
00:00:48,360 --> 00:00:49,379
the commercial within commercial

23
00:00:49,379 --> 00:00:52,200
companies he's a prolific LinkedIn

24
00:00:52,200 --> 00:00:54,180
poster where he and I first became

25
00:00:54,180 --> 00:00:56,100
friends as I started following his many

26
00:00:56,100 --> 00:00:58,140
thoughts and realized that I saw my

27
00:00:58,140 --> 00:01:00,239
found myself nodding my head to many of

28
00:01:00,239 --> 00:01:02,039
the things that he was sharing so he

29
00:01:02,039 --> 00:01:03,780
shares his thoughts and insights often

30
00:01:03,780 --> 00:01:05,580
on the evolving field of cyber security

31
00:01:05,580 --> 00:01:07,140
I encourage you to take a look at him

32
00:01:07,140 --> 00:01:10,740
he's known online as the virtual CSO

33
00:01:10,740 --> 00:01:12,900
which is also the name of his consulting

34
00:01:12,900 --> 00:01:15,960
company he spoke at the serious security

35
00:01:15,960 --> 00:01:18,420
seminar a bit over a year ago and we're

36
00:01:18,420 --> 00:01:20,040
delighted to have him back today to get

37
00:01:20,040 --> 00:01:21,720
in welcome

38
00:01:21,720 --> 00:01:25,080
terrific thanks so much Joel so we're

39
00:01:25,080 --> 00:01:26,820
gathered here today to speak about

40
00:01:26,820 --> 00:01:29,580
program maturity and

41
00:01:29,580 --> 00:01:31,979
within the cyber security and also

42
00:01:31,979 --> 00:01:37,259
operational risk context so a little bit

43
00:01:37,259 --> 00:01:40,259
of a different flavor there

44
00:01:40,259 --> 00:01:43,020
we're going to move quickly through the

45
00:01:43,020 --> 00:01:45,600
agenda and cover a great deal of

46
00:01:45,600 --> 00:01:47,880
information we're going to start with

47
00:01:47,880 --> 00:01:51,299
minimal compliance and pivot into common

48
00:01:51,299 --> 00:01:54,960
controls and then risk management and

49
00:01:54,960 --> 00:01:57,720
finally strong risk management which is

50
00:01:57,720 --> 00:02:01,200
for companies that have very very low

51
00:02:01,200 --> 00:02:02,880
risk tolerance

52
00:02:02,880 --> 00:02:05,820
we will take some time to talk about

53
00:02:05,820 --> 00:02:10,199
influencing funding so that's part of

54
00:02:10,199 --> 00:02:14,280
really the strategy beyond having a

55
00:02:14,280 --> 00:02:16,800
maturity model is you have to get the

56
00:02:16,800 --> 00:02:19,500
funding and support to move through

57
00:02:19,500 --> 00:02:22,260
those different tiers I am speaking

58
00:02:22,260 --> 00:02:25,800
today to cyber security students as an

59
00:02:25,800 --> 00:02:26,760
audience

60
00:02:26,760 --> 00:02:30,420
and I will be using U.S Air Force crash

61
00:02:30,420 --> 00:02:32,280
course format so we're going to move

62
00:02:32,280 --> 00:02:35,459
very very quickly the good thing is that

63
00:02:35,459 --> 00:02:38,459
this session is being recorded and if

64
00:02:38,459 --> 00:02:40,560
you'd like to send me an email or a

65
00:02:40,560 --> 00:02:43,319
LinkedIn message at the end I can also

66
00:02:43,319 --> 00:02:46,319
get you a copy of the slides so just let

67
00:02:46,319 --> 00:02:49,140
the information wash over you and you're

68
00:02:49,140 --> 00:02:52,620
going to have access to the deck and to

69
00:02:52,620 --> 00:02:55,440
Links within the deck after the session

70
00:02:55,440 --> 00:02:58,680
has concluded I will ask you to hold

71
00:02:58,680 --> 00:03:02,040
your questions until the end but you can

72
00:03:02,040 --> 00:03:05,060
use the the zoom feature

73
00:03:05,060 --> 00:03:06,840
to

74
00:03:06,840 --> 00:03:10,440
um create a question within that queue

75
00:03:10,440 --> 00:03:13,260
and we'll get to it as we start to

76
00:03:13,260 --> 00:03:16,280
conclude this session

77
00:03:16,500 --> 00:03:19,200
so let's talk a little bit more about

78
00:03:19,200 --> 00:03:22,500
program maturity within cyber security

79
00:03:22,500 --> 00:03:26,159
and and operational risk management so

80
00:03:26,159 --> 00:03:29,459
level one will be minimal compliance and

81
00:03:29,459 --> 00:03:32,280
some organizations start there

82
00:03:32,280 --> 00:03:35,280
um you might have a startup company

83
00:03:35,280 --> 00:03:37,860
um or you may just have an organization

84
00:03:37,860 --> 00:03:41,400
that is at a lower level of maturity and

85
00:03:41,400 --> 00:03:44,159
typically minimal compliance will be

86
00:03:44,159 --> 00:03:46,980
with some sort of control framework like

87
00:03:46,980 --> 00:03:50,180
then this cyber security framework

88
00:03:50,180 --> 00:03:53,659
or there may be some minimal compliance

89
00:03:53,659 --> 00:03:57,060
to laws or regulations

90
00:03:57,060 --> 00:04:00,180
next level two we have common controls

91
00:04:00,180 --> 00:04:03,959
so the control Frameworks are not meant

92
00:04:03,959 --> 00:04:08,159
to be very very specific or prescriptive

93
00:04:08,159 --> 00:04:11,159
so there are controls that were all

94
00:04:11,159 --> 00:04:15,180
accustomed to within cyber security such

95
00:04:15,180 --> 00:04:17,760
as a web application firewall

96
00:04:17,760 --> 00:04:21,238
which will fall into this second level

97
00:04:21,238 --> 00:04:23,360
of maturity it may not be called out

98
00:04:23,360 --> 00:04:27,000
explicitly in the control framework but

99
00:04:27,000 --> 00:04:30,000
these are controls that as cyber

100
00:04:30,000 --> 00:04:33,540
Security Professionals we expect to see

101
00:04:33,540 --> 00:04:37,080
in place and we view them as necessary

102
00:04:37,080 --> 00:04:40,620
level three is risk management which is

103
00:04:40,620 --> 00:04:43,440
called for and and most of the control

104
00:04:43,440 --> 00:04:46,320
Frameworks and laws and regulations but

105
00:04:46,320 --> 00:04:49,139
may sometimes be skipped over in

106
00:04:49,139 --> 00:04:52,500
practice so we'll get down a little

107
00:04:52,500 --> 00:04:55,880
deeper into what types of

108
00:04:55,880 --> 00:04:58,680
analysis assessment and mitigation

109
00:04:58,680 --> 00:05:01,680
should be in place and then finally

110
00:05:01,680 --> 00:05:04,979
we'll get to level four strong risk

111
00:05:04,979 --> 00:05:07,860
management and again this is typically

112
00:05:07,860 --> 00:05:10,500
for organizations that have a very low

113
00:05:10,500 --> 00:05:13,040
risk tolerance think financial

114
00:05:13,040 --> 00:05:14,660
institutions

115
00:05:14,660 --> 00:05:18,680
federal government and then also

116
00:05:18,680 --> 00:05:22,340
pharmaceutical companies

117
00:05:22,380 --> 00:05:24,780
so starting with minimal compliance

118
00:05:24,780 --> 00:05:28,380
maturity level one most organizations

119
00:05:28,380 --> 00:05:31,620
will use either than this cyber security

120
00:05:31,620 --> 00:05:34,680
framework or internationally it's more

121
00:05:34,680 --> 00:05:39,120
likely that they'll use ISO 27001

122
00:05:39,120 --> 00:05:41,520
I'm a proponent of the cyber security

123
00:05:41,520 --> 00:05:45,840
framework it's 108 controls which

124
00:05:45,840 --> 00:05:49,199
provide a foundation so we'll have a

125
00:05:49,199 --> 00:05:51,660
requirement for example for encrypting

126
00:05:51,660 --> 00:05:54,419
data at rest but I also like the

127
00:05:54,419 --> 00:05:57,780
presentation layer that it provides for

128
00:05:57,780 --> 00:06:01,680
executives so if we were walking over to

129
00:06:01,680 --> 00:06:03,600
an elevator and we were to get into the

130
00:06:03,600 --> 00:06:05,460
elevator with an exec and they were to

131
00:06:05,460 --> 00:06:08,220
ask tell me about our cyber security

132
00:06:08,220 --> 00:06:10,139
program

133
00:06:10,139 --> 00:06:12,180
you could say something like

134
00:06:12,180 --> 00:06:15,900
first we look to identify risk to the

135
00:06:15,900 --> 00:06:18,600
organization and then we deploy

136
00:06:18,600 --> 00:06:21,539
protective controls to prevent

137
00:06:21,539 --> 00:06:24,660
cyber security issues we detect

138
00:06:24,660 --> 00:06:29,000
suspicious activity and then we respond

139
00:06:29,000 --> 00:06:31,919
uh either with an incident response plan

140
00:06:31,919 --> 00:06:34,220
disaster recovery

141
00:06:34,220 --> 00:06:37,919
and or crisis Communications and finally

142
00:06:37,919 --> 00:06:41,100
when we recover we look for things like

143
00:06:41,100 --> 00:06:44,400
root cause analysis to reap to prevent

144
00:06:44,400 --> 00:06:47,639
reoccurrence so if you notice there I

145
00:06:47,639 --> 00:06:50,639
didn't really get deep into technical

146
00:06:50,639 --> 00:06:52,800
controls or some of the traditional

147
00:06:52,800 --> 00:06:56,880
domains of information security such as

148
00:06:56,880 --> 00:07:01,400
access control or physical security and

149
00:07:01,400 --> 00:07:04,919
it's for good reason if we're talking to

150
00:07:04,919 --> 00:07:07,440
a business leader who spent most of

151
00:07:07,440 --> 00:07:10,380
their their life in accounting as an

152
00:07:10,380 --> 00:07:13,860
example be before becoming a CEO we

153
00:07:13,860 --> 00:07:17,340
start to leave them behind if we get too

154
00:07:17,340 --> 00:07:20,280
far in the weeds of cyber security

155
00:07:20,280 --> 00:07:24,440
also at this minimal level of compliance

156
00:07:24,440 --> 00:07:27,740
it's necessary to include

157
00:07:27,740 --> 00:07:31,680
requirements from laws regulations and

158
00:07:31,680 --> 00:07:34,680
contractual obligations such as the PCI

159
00:07:34,680 --> 00:07:38,220
Data security standard if your

160
00:07:38,220 --> 00:07:41,099
organization stores processes or

161
00:07:41,099 --> 00:07:42,419
transmits

162
00:07:42,419 --> 00:07:44,699
payment card or credit or debit card

163
00:07:44,699 --> 00:07:46,199
numbers

164
00:07:46,199 --> 00:07:49,560
be mindful though when you think in

165
00:07:49,560 --> 00:07:51,539
terms of laws

166
00:07:51,539 --> 00:07:55,560
Etc from regulatory bodies that they're

167
00:07:55,560 --> 00:07:58,680
biased towards their interests so as an

168
00:07:58,680 --> 00:08:03,199
example the payment card brands that

169
00:08:03,199 --> 00:08:06,599
require adherence to the PCI Data

170
00:08:06,599 --> 00:08:09,300
security standard only care about the

171
00:08:09,300 --> 00:08:11,539
security of their payment card numbers

172
00:08:11,539 --> 00:08:14,639
and and if your organization has some

173
00:08:14,639 --> 00:08:17,220
sort of disaster and cannot recover

174
00:08:17,220 --> 00:08:20,400
that's not really a concern to them so

175
00:08:20,400 --> 00:08:24,180
it's important to really focus on your

176
00:08:24,180 --> 00:08:26,220
organization rather than minimal

177
00:08:26,220 --> 00:08:29,099
compliance

178
00:08:29,099 --> 00:08:32,279
so still at this first tier of minimal

179
00:08:32,279 --> 00:08:34,559
compliance I did want to take a little

180
00:08:34,559 --> 00:08:37,200
bit of time to talk about data

181
00:08:37,200 --> 00:08:40,339
management because oft times it's

182
00:08:40,339 --> 00:08:43,620
overlooked or may not be done well and

183
00:08:43,620 --> 00:08:47,339
obviously we need to know where our data

184
00:08:47,339 --> 00:08:50,640
is as a first step if we're going to try

185
00:08:50,640 --> 00:08:54,060
to secure it so oftentimes when I first

186
00:08:54,060 --> 00:08:56,880
get involved with an organization I'll

187
00:08:56,880 --> 00:09:00,600
ask for a very very high level view of

188
00:09:00,600 --> 00:09:04,200
what types of data we have and where

189
00:09:04,200 --> 00:09:06,120
it's stored so you see the data

190
00:09:06,120 --> 00:09:08,040
repository field

191
00:09:08,040 --> 00:09:10,380
it's also good to understand not only

192
00:09:10,380 --> 00:09:13,380
the types of data that we have

193
00:09:13,380 --> 00:09:17,640
but the volume of it so if we have a

194
00:09:17,640 --> 00:09:20,519
very small volume of data and a data

195
00:09:20,519 --> 00:09:23,399
repository we may

196
00:09:23,399 --> 00:09:26,459
place a higher priority on on a

197
00:09:26,459 --> 00:09:29,100
different area that has similar

198
00:09:29,100 --> 00:09:31,620
sensitive information and significantly

199
00:09:31,620 --> 00:09:33,360
more records

200
00:09:33,360 --> 00:09:36,420
and then we we get a little deeper into

201
00:09:36,420 --> 00:09:39,300
data management with the data owner who

202
00:09:39,300 --> 00:09:42,000
would be the person or the role that

203
00:09:42,000 --> 00:09:44,580
would give permission for data to be

204
00:09:44,580 --> 00:09:47,100
stored in a certain area for example

205
00:09:47,100 --> 00:09:49,800
they would give permission before moving

206
00:09:49,800 --> 00:09:54,180
it outside of our on-premises I.T

207
00:09:54,180 --> 00:09:57,660
environment to a vendor environment and

208
00:09:57,660 --> 00:09:59,640
then also you have the data custodian so

209
00:09:59,640 --> 00:10:02,820
that's the role that's responsible for

210
00:10:02,820 --> 00:10:05,160
protecting that information

211
00:10:05,160 --> 00:10:06,250
thank you

212
00:10:06,250 --> 00:10:07,440
[Music]

213
00:10:07,440 --> 00:10:10,860
so to get a little deeper Beyond just

214
00:10:10,860 --> 00:10:13,500
having a system or application inventory

215
00:10:13,500 --> 00:10:16,339
we'll talk about having a configuration

216
00:10:16,339 --> 00:10:20,160
management database and

217
00:10:20,160 --> 00:10:24,000
some fields that I recommend so first

218
00:10:24,000 --> 00:10:26,540
off it's good to have an understanding

219
00:10:26,540 --> 00:10:31,260
of the system contacts in the event that

220
00:10:31,260 --> 00:10:34,260
we need to take the system down to patch

221
00:10:34,260 --> 00:10:36,120
it or

222
00:10:36,120 --> 00:10:36,899
um

223
00:10:36,899 --> 00:10:39,240
we're responding to some sort of an

224
00:10:39,240 --> 00:10:41,760
incident it's also good to have

225
00:10:41,760 --> 00:10:45,300
management and Tech exec contacts in the

226
00:10:45,300 --> 00:10:47,519
events that we need to escalate so if

227
00:10:47,519 --> 00:10:51,779
we're having difficulty either getting a

228
00:10:51,779 --> 00:10:53,339
patch installed getting the maintenance

229
00:10:53,339 --> 00:10:56,459
window for that or we have a custom

230
00:10:56,459 --> 00:10:59,399
application running uh in this

231
00:10:59,399 --> 00:11:02,040
environment and we're trying to get a

232
00:11:02,040 --> 00:11:06,959
code fix uh created and tested

233
00:11:06,959 --> 00:11:10,200
in a critical situation then it's

234
00:11:10,200 --> 00:11:12,420
important to be able to reach out

235
00:11:12,420 --> 00:11:14,399
potentially to the management and Tech

236
00:11:14,399 --> 00:11:17,940
exec contact to get that priority and to

237
00:11:17,940 --> 00:11:21,000
get that response to them we can also

238
00:11:21,000 --> 00:11:22,620
obviously

239
00:11:22,620 --> 00:11:26,760
have specific metrics and reporting that

240
00:11:26,760 --> 00:11:29,279
then goes to the right people associated

241
00:11:29,279 --> 00:11:32,760
with the systems and applications you

242
00:11:32,760 --> 00:11:36,300
can see on the left side towards the

243
00:11:36,300 --> 00:11:38,220
bottom there the application record

244
00:11:38,220 --> 00:11:41,339
that's meant to be a link So within a

245
00:11:41,339 --> 00:11:44,399
configuration management database you

246
00:11:44,399 --> 00:11:47,160
can come in on an infrastructure record

247
00:11:47,160 --> 00:11:50,820
maybe a server or a virtual machine and

248
00:11:50,820 --> 00:11:52,320
then click over to the application

249
00:11:52,320 --> 00:11:54,000
record or you could come into the

250
00:11:54,000 --> 00:11:58,380
application record and connect to the

251
00:11:58,380 --> 00:12:00,839
information about the underlying

252
00:12:00,839 --> 00:12:03,779
infrastructure production status is this

253
00:12:03,779 --> 00:12:07,680
a production system is it Dev and then

254
00:12:07,680 --> 00:12:09,959
you can see some more risk-based

255
00:12:09,959 --> 00:12:13,920
information in the right Fields so uh

256
00:12:13,920 --> 00:12:17,700
business criticality uh does this system

257
00:12:17,700 --> 00:12:20,820
need to be up on five nines

258
00:12:20,820 --> 00:12:23,880
is it internet facing is it vendor

259
00:12:23,880 --> 00:12:27,300
hosted what types of data is on it and

260
00:12:27,300 --> 00:12:29,519
then you can see that the CI data

261
00:12:29,519 --> 00:12:32,940
certified by and certified date CI is

262
00:12:32,940 --> 00:12:36,120
configuration item so we're going to

263
00:12:36,120 --> 00:12:39,060
want someone at least once a year

264
00:12:39,060 --> 00:12:41,760
typically the system owner to look at

265
00:12:41,760 --> 00:12:44,639
this record and see if it still currents

266
00:12:44,639 --> 00:12:47,820
and if it needs to be updated oftentimes

267
00:12:47,820 --> 00:12:51,480
you might have someone move uh into a

268
00:12:51,480 --> 00:12:53,279
different role so maybe the alternate

269
00:12:53,279 --> 00:12:56,519
system owner or one of the data owners

270
00:12:56,519 --> 00:13:00,120
has changed that during this process the

271
00:13:00,120 --> 00:13:02,639
system owner would update that and that

272
00:13:02,639 --> 00:13:05,459
would be the new certified date

273
00:13:05,459 --> 00:13:08,820
it's also important to use some sort of

274
00:13:08,820 --> 00:13:12,720
Discovery tool to detect new systems as

275
00:13:12,720 --> 00:13:15,660
they come up online especially with VMS

276
00:13:15,660 --> 00:13:18,899
and in in Cloud environments and also to

277
00:13:18,899 --> 00:13:22,380
use some sort of Discovery tool to

278
00:13:22,380 --> 00:13:25,500
detect unstructured data in areas where

279
00:13:25,500 --> 00:13:28,380
we don't expect it so that in the

280
00:13:28,380 --> 00:13:31,260
Privacy career field they talk that talk

281
00:13:31,260 --> 00:13:33,480
about that as data linkage so if we

282
00:13:33,480 --> 00:13:34,399
expect

283
00:13:34,399 --> 00:13:36,839
primarily our sensitive data to be in

284
00:13:36,839 --> 00:13:39,240
our production environments and maybe we

285
00:13:39,240 --> 00:13:41,839
might have some sensitive data on

286
00:13:41,839 --> 00:13:45,600
laptops and we have we're finding it all

287
00:13:45,600 --> 00:13:47,459
over the place then

288
00:13:47,459 --> 00:13:49,800
we want to make sure that we get it to

289
00:13:49,800 --> 00:13:52,380
the areas where we expect it where we

290
00:13:52,380 --> 00:13:56,040
have enhanced security controls so so

291
00:13:56,040 --> 00:13:57,720
some additional thoughts around

292
00:13:57,720 --> 00:14:00,740
inventory there

293
00:14:01,260 --> 00:14:03,180
so level two we're going to talk about

294
00:14:03,180 --> 00:14:06,899
common controls quickly so again control

295
00:14:06,899 --> 00:14:09,540
Frameworks such as then this cyber

296
00:14:09,540 --> 00:14:13,980
security framework or ISO 27001 are not

297
00:14:13,980 --> 00:14:17,639
meant to be prescriptive or very very

298
00:14:17,639 --> 00:14:21,180
specific so that leaves what I would

299
00:14:21,180 --> 00:14:25,500
refer to as gaps that we need to fill

300
00:14:25,500 --> 00:14:27,720
um and and typically we start to fill

301
00:14:27,720 --> 00:14:31,560
the gaps with common controls so some

302
00:14:31,560 --> 00:14:34,200
examples of controls that you will not

303
00:14:34,200 --> 00:14:37,560
see explicitly called out and then this

304
00:14:37,560 --> 00:14:39,779
cyber security framework or patching

305
00:14:39,779 --> 00:14:42,660
penetration testing having a phishing

306
00:14:42,660 --> 00:14:45,060
test program having a security

307
00:14:45,060 --> 00:14:48,600
operations center and or active

308
00:14:48,600 --> 00:14:50,660
monitoring by cyber Security

309
00:14:50,660 --> 00:14:54,959
Professionals 24 7 365. so as I

310
00:14:54,959 --> 00:14:57,000
mentioned those controls to you

311
00:14:57,000 --> 00:14:59,339
they're not Arcane They're Not Unusual

312
00:14:59,339 --> 00:15:01,560
we would by and large expect them to be

313
00:15:01,560 --> 00:15:04,260
in place in an environment that hosts

314
00:15:04,260 --> 00:15:05,699
sensitive data

315
00:15:05,699 --> 00:15:08,519
so those are some examples and some

316
00:15:08,519 --> 00:15:12,180
easier ways to identify gaps rather than

317
00:15:12,180 --> 00:15:15,660
just by our experience or knowledge is

318
00:15:15,660 --> 00:15:18,480
to look at something like the center for

319
00:15:18,480 --> 00:15:21,079
internet Securities critical security

320
00:15:21,079 --> 00:15:25,820
controls listing and we may decide okay

321
00:15:25,820 --> 00:15:28,320
one we're going to call out some of

322
00:15:28,320 --> 00:15:30,060
these controls because they're already

323
00:15:30,060 --> 00:15:32,279
in place but also

324
00:15:32,279 --> 00:15:34,740
maybe something like a web content

325
00:15:34,740 --> 00:15:37,860
filter isn't in place today and that

326
00:15:37,860 --> 00:15:40,860
kind of reminds us that we think we want

327
00:15:40,860 --> 00:15:42,779
to get to that maybe next year or the

328
00:15:42,779 --> 00:15:44,760
year after that

329
00:15:44,760 --> 00:15:47,040
I did want to talk about risk-based

330
00:15:47,040 --> 00:15:49,980
deployment of controls so we're not just

331
00:15:49,980 --> 00:15:52,680
going to have a cyber security control

332
00:15:52,680 --> 00:15:56,339
and deploy it everywhere ideally what we

333
00:15:56,339 --> 00:15:59,160
do is if we're adding controls to the

334
00:15:59,160 --> 00:16:02,760
environment we're adding them based on

335
00:16:02,760 --> 00:16:05,519
risk severity so I'll get into an

336
00:16:05,519 --> 00:16:09,360
example for web applications so

337
00:16:09,360 --> 00:16:12,779
in in this model we're saying

338
00:16:12,779 --> 00:16:14,579
we're going to conduct source code

339
00:16:14,579 --> 00:16:17,279
scanning of all web applications

340
00:16:17,279 --> 00:16:20,220
throughout the organization

341
00:16:20,220 --> 00:16:22,560
and for those applications that store

342
00:16:22,560 --> 00:16:26,100
process or transmit sensitive data

343
00:16:26,100 --> 00:16:28,139
we're going to have source code scanning

344
00:16:28,139 --> 00:16:30,959
and we're going to add as a second layer

345
00:16:30,959 --> 00:16:33,959
of dynamic application scanning of those

346
00:16:33,959 --> 00:16:36,779
web apps with sensitive data

347
00:16:36,779 --> 00:16:39,959
and for internet exposed web

348
00:16:39,959 --> 00:16:42,899
applications that host sensitive data

349
00:16:42,899 --> 00:16:45,000
we're going to have all three of those

350
00:16:45,000 --> 00:16:47,339
bullets so source code scanning Dynamic

351
00:16:47,339 --> 00:16:49,860
application scanning and penetration

352
00:16:49,860 --> 00:16:52,860
testing so you can see as

353
00:16:52,860 --> 00:16:56,399
the perceived risk grows we're going to

354
00:16:56,399 --> 00:16:59,880
deploy controls in that manner and as I

355
00:16:59,880 --> 00:17:03,360
go through this common controls

356
00:17:03,360 --> 00:17:05,579
maturity level two

357
00:17:05,579 --> 00:17:08,040
I'm quite certain that those of you on

358
00:17:08,040 --> 00:17:11,099
the line are are seeing these as

359
00:17:11,099 --> 00:17:14,160
necessary controls the really common

360
00:17:14,160 --> 00:17:16,140
sense if you're familiar with cyber

361
00:17:16,140 --> 00:17:19,980
security and really all we're doing is

362
00:17:19,980 --> 00:17:22,559
filling holes in the control framework

363
00:17:22,559 --> 00:17:24,780
and this is basic due diligence so

364
00:17:24,780 --> 00:17:27,359
nothing to be proud of but we do need to

365
00:17:27,359 --> 00:17:30,299
go that second layer Beyond The Bare

366
00:17:30,299 --> 00:17:32,940
Bones foundational controls in a control

367
00:17:32,940 --> 00:17:35,600
framework

368
00:17:36,059 --> 00:17:39,480
so let's step into maturity level three

369
00:17:39,480 --> 00:17:43,440
risk management and I did want to call

370
00:17:43,440 --> 00:17:47,280
out examples of how control Frameworks

371
00:17:47,280 --> 00:17:50,280
actually call for risk management there

372
00:17:50,280 --> 00:17:51,960
are times in the industry where people

373
00:17:51,960 --> 00:17:54,660
will say that control framework is

374
00:17:54,660 --> 00:17:56,880
compliance and it really doesn't

375
00:17:56,880 --> 00:18:01,080
address risk and I I don't agree with

376
00:18:01,080 --> 00:18:03,780
that and we're looking at uh I guess six

377
00:18:03,780 --> 00:18:06,299
controls on the screen from the cyber

378
00:18:06,299 --> 00:18:08,820
security framework requiring risk

379
00:18:08,820 --> 00:18:10,740
management processes

380
00:18:10,740 --> 00:18:13,799
organizational risk tolerance and we're

381
00:18:13,799 --> 00:18:16,080
gonna have a slide on that next

382
00:18:16,080 --> 00:18:20,100
uh but also really to have some sort of

383
00:18:20,100 --> 00:18:25,280
risk analysis risk assessment and then

384
00:18:25,280 --> 00:18:28,679
prioritized risk mitigation

385
00:18:28,679 --> 00:18:32,220
so from a risk management perspective we

386
00:18:32,220 --> 00:18:36,000
really have four options we can accept

387
00:18:36,000 --> 00:18:39,299
risk and typically that's done with a

388
00:18:39,299 --> 00:18:42,539
risk registry entry or plan of action

389
00:18:42,539 --> 00:18:45,000
and Milestones which is more on the

390
00:18:45,000 --> 00:18:47,460
federal government but if we have a risk

391
00:18:47,460 --> 00:18:50,220
register entry or a poem

392
00:18:50,220 --> 00:18:51,780
we're going to make sure that we have a

393
00:18:51,780 --> 00:18:54,480
thermal process around that and the

394
00:18:54,480 --> 00:18:57,539
right levels of management are signing

395
00:18:57,539 --> 00:19:00,900
off based on the risk severity

396
00:19:00,900 --> 00:19:04,020
we can also avoid risk so there are

397
00:19:04,020 --> 00:19:06,000
times where a line of business or a

398
00:19:06,000 --> 00:19:08,280
business unit will say I'm not doing

399
00:19:08,280 --> 00:19:12,419
business in that country their decision

400
00:19:12,419 --> 00:19:15,179
risk mitigation is something that we're

401
00:19:15,179 --> 00:19:17,340
much more accustomed to in cyber

402
00:19:17,340 --> 00:19:20,039
security so as an example we'll run a

403
00:19:20,039 --> 00:19:23,100
vulnerability scan and we need to

404
00:19:23,100 --> 00:19:25,679
remediate that within standards and

405
00:19:25,679 --> 00:19:29,280
oftentimes we'll patch or will apply a

406
00:19:29,280 --> 00:19:32,940
configuration within infrastructure

407
00:19:32,940 --> 00:19:37,020
and risk transference with as fast as we

408
00:19:37,020 --> 00:19:39,120
need to go during this presentation the

409
00:19:39,120 --> 00:19:41,640
easiest example I could give you is

410
00:19:41,640 --> 00:19:44,900
cyber security insurance

411
00:19:45,539 --> 00:19:48,539
so let's talk about a risk tolerance

412
00:19:48,539 --> 00:19:51,480
statement which is alluded to in one of

413
00:19:51,480 --> 00:19:53,240
the cyber security framework

414
00:19:53,240 --> 00:19:55,880
requirements and this is really

415
00:19:55,880 --> 00:19:58,820
management or senior Executives

416
00:19:58,820 --> 00:20:01,380
conveying tone from the top when it

417
00:20:01,380 --> 00:20:03,419
comes to cyber security

418
00:20:03,419 --> 00:20:06,179
so in this example management is saying

419
00:20:06,179 --> 00:20:08,940
they have a low tolerance for external

420
00:20:08,940 --> 00:20:12,360
intrusions and operational risk

421
00:20:12,360 --> 00:20:15,299
a moderate tolerance for compliance risk

422
00:20:15,299 --> 00:20:17,820
so we're not just going to adhere to

423
00:20:17,820 --> 00:20:21,720
every compliance requirement uh that

424
00:20:21,720 --> 00:20:23,940
were subjected to we may take some risk

425
00:20:23,940 --> 00:20:24,919
there

426
00:20:24,919 --> 00:20:28,200
trying to keep that balance between what

427
00:20:28,200 --> 00:20:30,080
controls are required and what

428
00:20:30,080 --> 00:20:33,179
additional controls are we going to

429
00:20:33,179 --> 00:20:35,460
deploy on our own and that sometimes

430
00:20:35,460 --> 00:20:38,400
leaves compliance requirements that

431
00:20:38,400 --> 00:20:40,380
we've addressed a different way would be

432
00:20:40,380 --> 00:20:42,299
an example

433
00:20:42,299 --> 00:20:46,020
also legal risk so in this case

434
00:20:46,020 --> 00:20:48,780
management is saying in in some rare

435
00:20:48,780 --> 00:20:52,919
cases we may need to go to court uh over

436
00:20:52,919 --> 00:20:55,940
something like an unenforceable contract

437
00:20:55,940 --> 00:20:59,900
and we'll accept that risk but again

438
00:20:59,900 --> 00:21:02,400
management pivots back and says

439
00:21:02,400 --> 00:21:05,039
reputational risk we only have a low

440
00:21:05,039 --> 00:21:08,160
tolerance for that so what's great about

441
00:21:08,160 --> 00:21:11,400
a risk tolerance statement is if it's

442
00:21:11,400 --> 00:21:13,919
not in place and as cyber Security

443
00:21:13,919 --> 00:21:16,860
Professionals or leaders we can convince

444
00:21:16,860 --> 00:21:18,840
executive management to publish

445
00:21:18,840 --> 00:21:21,299
something like this when we come back

446
00:21:21,299 --> 00:21:23,580
for funding or we need to implement a

447
00:21:23,580 --> 00:21:26,160
new control we can tie it back to this

448
00:21:26,160 --> 00:21:29,120
tone from the top

449
00:21:29,159 --> 00:21:32,280
I do want to talk about threat landscape

450
00:21:32,280 --> 00:21:34,679
and controls analysis which is a very

451
00:21:34,679 --> 00:21:37,980
simple methodology that I I've created

452
00:21:37,980 --> 00:21:42,360
and you're welcome to use and really

453
00:21:42,360 --> 00:21:46,260
the idea behind it is we start from

454
00:21:46,260 --> 00:21:50,220
business and I.T Executives side of the

455
00:21:50,220 --> 00:21:52,679
table and we spend a good deal of time

456
00:21:52,679 --> 00:21:55,760
in their space before we gradually

457
00:21:55,760 --> 00:21:59,940
transition to cyber security so if you

458
00:21:59,940 --> 00:22:01,260
think about many of the assessment

459
00:22:01,260 --> 00:22:03,960
reports that are out there there's one

460
00:22:03,960 --> 00:22:06,659
page which is an executive summary and

461
00:22:06,659 --> 00:22:08,520
and sometimes that can leave a foul

462
00:22:08,520 --> 00:22:11,039
taste in the mouth of Executives so

463
00:22:11,039 --> 00:22:13,260
let's jump into it

464
00:22:13,260 --> 00:22:16,020
so we start with inherent risk of the

465
00:22:16,020 --> 00:22:18,179
organization so what is the company

466
00:22:18,179 --> 00:22:20,820
profile what industry is the

467
00:22:20,820 --> 00:22:24,720
organization in what types of digital

468
00:22:24,720 --> 00:22:27,600
physical assets does does the

469
00:22:27,600 --> 00:22:31,679
organization have and logically what

470
00:22:31,679 --> 00:22:34,020
types of potential adversaries do we

471
00:22:34,020 --> 00:22:36,299
have that want to take

472
00:22:36,299 --> 00:22:39,059
control of those assets

473
00:22:39,059 --> 00:22:41,820
then also we start to think about the

474
00:22:41,820 --> 00:22:44,280
adversary right so what are their

475
00:22:44,280 --> 00:22:46,980
techniques for compromising data what

476
00:22:46,980 --> 00:22:48,720
are their capabilities

477
00:22:48,720 --> 00:22:51,659
oftentimes they will leverage the cyber

478
00:22:51,659 --> 00:22:54,600
crime ecosystem so if they reach an

479
00:22:54,600 --> 00:22:56,400
impasse where they can't get by a

480
00:22:56,400 --> 00:22:59,340
certain control they may leverage or

481
00:22:59,340 --> 00:23:00,960
contract with another criminal

482
00:23:00,960 --> 00:23:03,120
organization to get in

483
00:23:03,120 --> 00:23:05,580
let's talk a little bit about potential

484
00:23:05,580 --> 00:23:08,580
impact and we can leverage reputable

485
00:23:08,580 --> 00:23:11,520
sources like the Verizon data breach

486
00:23:11,520 --> 00:23:15,440
investigations report or acfes

487
00:23:15,440 --> 00:23:18,179
occupational fraud report which also

488
00:23:18,179 --> 00:23:20,760
comes down annually

489
00:23:20,760 --> 00:23:22,919
and then we'll talk about risk tolerance

490
00:23:22,919 --> 00:23:25,919
now hopefully you've convinced the

491
00:23:25,919 --> 00:23:28,380
executives to put out a risk tolerance

492
00:23:28,380 --> 00:23:30,600
statement and that's a copy paste right

493
00:23:30,600 --> 00:23:33,000
so we could take that last slide and put

494
00:23:33,000 --> 00:23:35,940
it right into this section of the report

495
00:23:35,940 --> 00:23:38,220
and now finally we're starting to Pivot

496
00:23:38,220 --> 00:23:39,620
into

497
00:23:39,620 --> 00:23:42,480
risk mitigation so we want to be fair

498
00:23:42,480 --> 00:23:45,539
and balanced in this analysis so we're

499
00:23:45,539 --> 00:23:47,880
going to start by saying here are the

500
00:23:47,880 --> 00:23:50,659
the preventive and detective controls

501
00:23:50,659 --> 00:23:53,880
that are in place that mitigate or

502
00:23:53,880 --> 00:23:55,740
reduce the risk that we've been talking

503
00:23:55,740 --> 00:23:58,020
about so far so we're going to talk

504
00:23:58,020 --> 00:24:00,720
about protection boundaries and that's

505
00:24:00,720 --> 00:24:03,120
really the data repositories where most

506
00:24:03,120 --> 00:24:05,580
of our sensitive data resides

507
00:24:05,580 --> 00:24:08,280
what type of control framework are we

508
00:24:08,280 --> 00:24:13,200
using so we mentioned this CSF ISO 27001

509
00:24:13,200 --> 00:24:15,419
and then at a very high level what are

510
00:24:15,419 --> 00:24:17,400
the risk assessments so

511
00:24:17,400 --> 00:24:20,820
annual audits assessments uh

512
00:24:20,820 --> 00:24:22,980
vulnerability scanning pen testing so

513
00:24:22,980 --> 00:24:24,960
it's not all just in that assessment

514
00:24:24,960 --> 00:24:28,320
risk assessment space but by and large

515
00:24:28,320 --> 00:24:31,799
what kind of uh controls do we have in

516
00:24:31,799 --> 00:24:36,600
place to identify risk and obviously we

517
00:24:36,600 --> 00:24:39,360
start to address that then so finally

518
00:24:39,360 --> 00:24:42,780
towards the end the final section we

519
00:24:42,780 --> 00:24:45,179
talk about the residual risk so we went

520
00:24:45,179 --> 00:24:48,240
all the ways from what type of company

521
00:24:48,240 --> 00:24:51,780
do we have what type of adversaries what

522
00:24:51,780 --> 00:24:54,659
are their capabilities uh how do we

523
00:24:54,659 --> 00:24:57,600
mitigate risk in a good way right and

524
00:24:57,600 --> 00:25:00,419
the residual risk or recommended

525
00:25:00,419 --> 00:25:03,059
controls where do we have room for

526
00:25:03,059 --> 00:25:05,400
improvement so I've used this really

527
00:25:05,400 --> 00:25:07,860
simple way it's more like a presentation

528
00:25:07,860 --> 00:25:12,419
layer of an assessment and it really

529
00:25:12,419 --> 00:25:16,260
resonates uh with Executives so I

530
00:25:16,260 --> 00:25:18,600
welcome you to try that As you move

531
00:25:18,600 --> 00:25:21,600
forward with your careers as well

532
00:25:21,600 --> 00:25:24,179
so let's talk about

533
00:25:24,179 --> 00:25:27,240
attack Centric controls and and kind of

534
00:25:27,240 --> 00:25:29,640
that Focus right in in Risk Management

535
00:25:29,640 --> 00:25:32,820
so we're going to talk briefly as we go

536
00:25:32,820 --> 00:25:34,980
from top to bottom about how an

537
00:25:34,980 --> 00:25:38,640
adversary May gain access to an I.T

538
00:25:38,640 --> 00:25:40,020
environment

539
00:25:40,020 --> 00:25:42,539
find sensitive data and try a few

540
00:25:42,539 --> 00:25:46,020
exfiltrate it or export it from the

541
00:25:46,020 --> 00:25:47,880
organization and we want to have

542
00:25:47,880 --> 00:25:50,400
controls in place that make that

543
00:25:50,400 --> 00:25:52,980
difficult or at the very least detect

544
00:25:52,980 --> 00:25:55,679
that suspicious activity

545
00:25:55,679 --> 00:25:58,500
so first off an adversary is going to

546
00:25:58,500 --> 00:26:01,740
want to deliver malware and I think most

547
00:26:01,740 --> 00:26:04,799
of you on the line know that that's

548
00:26:04,799 --> 00:26:07,919
oftentimes by a phishing message a

549
00:26:07,919 --> 00:26:12,900
social engineering email uh with a

550
00:26:12,900 --> 00:26:17,279
malicious link or a file attachment that

551
00:26:17,279 --> 00:26:21,659
helps that adversary get a foothold and

552
00:26:21,659 --> 00:26:24,960
gain access to a system within the it

553
00:26:24,960 --> 00:26:26,279
environment

554
00:26:26,279 --> 00:26:30,000
so that the next row the adversary has

555
00:26:30,000 --> 00:26:33,179
gained system access so

556
00:26:33,179 --> 00:26:35,700
how can we make that difficult right so

557
00:26:35,700 --> 00:26:38,700
one we want to make sure that end users

558
00:26:38,700 --> 00:26:40,380
do not have

559
00:26:40,380 --> 00:26:42,600
administrative access to their

560
00:26:42,600 --> 00:26:45,960
workstations to their company owned PCS

561
00:26:45,960 --> 00:26:50,400
or laptops because if malware gains a

562
00:26:50,400 --> 00:26:52,320
foothold and someone's logged in as

563
00:26:52,320 --> 00:26:53,700
admin

564
00:26:53,700 --> 00:26:56,220
it's going to be more effective that way

565
00:26:56,220 --> 00:26:58,200
then we need to make sure that there's

566
00:26:58,200 --> 00:27:00,539
some sort of advanced endpoint

567
00:27:00,539 --> 00:27:03,480
protection in place commonly referred to

568
00:27:03,480 --> 00:27:07,080
as EDR and xdr now but really good

569
00:27:07,080 --> 00:27:09,659
endpoint protection to protect against

570
00:27:09,659 --> 00:27:13,020
malware and then also integrated with

571
00:27:13,020 --> 00:27:16,020
log monitoring and event correlation or

572
00:27:16,020 --> 00:27:18,379
a Sim

573
00:27:19,620 --> 00:27:21,440
foreign

574
00:27:21,440 --> 00:27:24,480
of allow listing which is software that

575
00:27:24,480 --> 00:27:28,919
only allows known software and

576
00:27:28,919 --> 00:27:31,440
executables binaries to run on the

577
00:27:31,440 --> 00:27:35,580
system so if malware and or ransomware

578
00:27:35,580 --> 00:27:38,640
gets introduced to the system

579
00:27:38,640 --> 00:27:41,220
the allow listing software won't let it

580
00:27:41,220 --> 00:27:44,820
run so a terrific way to bolster your

581
00:27:44,820 --> 00:27:47,159
security there and then having

582
00:27:47,159 --> 00:27:48,779
two-factor or multi-factor

583
00:27:48,779 --> 00:27:50,880
authentication for servers is another

584
00:27:50,880 --> 00:27:52,140
good approach

585
00:27:52,140 --> 00:27:55,559
so next with the adversary having gained

586
00:27:55,559 --> 00:27:58,380
access to one system thankfully they

587
00:27:58,380 --> 00:28:00,360
probably don't have access to the

588
00:28:00,360 --> 00:28:03,000
sensitive data that they need yet

589
00:28:03,000 --> 00:28:04,980
so they're going to try to Pivot and

590
00:28:04,980 --> 00:28:08,100
move laterally east to west across the

591
00:28:08,100 --> 00:28:10,320
network so how can we make that

592
00:28:10,320 --> 00:28:13,020
difficult Well Network segmentation

593
00:28:13,020 --> 00:28:15,179
right so let's say we have

594
00:28:15,179 --> 00:28:17,640
payment card data or research and

595
00:28:17,640 --> 00:28:20,820
development data if we have that

596
00:28:20,820 --> 00:28:22,919
sensitive information on its own

597
00:28:22,919 --> 00:28:26,880
networks and we require a second level

598
00:28:26,880 --> 00:28:29,880
of authentication that's going to make

599
00:28:29,880 --> 00:28:32,159
it difficult for adversaries to get to

600
00:28:32,159 --> 00:28:35,460
that data so to give you an example if

601
00:28:35,460 --> 00:28:37,740
if I've met if I'm meant to have access

602
00:28:37,740 --> 00:28:40,380
to that research and development data in

603
00:28:40,380 --> 00:28:42,900
the morning I log into the network on I

604
00:28:42,900 --> 00:28:44,580
really just have access to the common

605
00:28:44,580 --> 00:28:47,340
use Network and how to get to that

606
00:28:47,340 --> 00:28:49,980
research and development data I have to

607
00:28:49,980 --> 00:28:52,860
authenticate to a jump box or a Bastion

608
00:28:52,860 --> 00:28:55,380
host hopefully we've got multi-factor

609
00:28:55,380 --> 00:28:58,440
authentication for that too and now once

610
00:28:58,440 --> 00:29:01,140
I've got that second layer of

611
00:29:01,140 --> 00:29:04,679
authentication completed I can get in to

612
00:29:04,679 --> 00:29:07,380
the that secondary Network that

613
00:29:07,380 --> 00:29:10,919
segmented and I can access the research

614
00:29:10,919 --> 00:29:13,380
and development data

615
00:29:13,380 --> 00:29:17,700
so next row down data exfiltration so at

616
00:29:17,700 --> 00:29:21,000
this point the adversary has access to

617
00:29:21,000 --> 00:29:24,299
sensitive data uh or a bad day is

618
00:29:24,299 --> 00:29:27,480
getting worse right so this could also

619
00:29:27,480 --> 00:29:30,120
be Insider threat right so we may have

620
00:29:30,120 --> 00:29:32,880
an authorized user that has access to

621
00:29:32,880 --> 00:29:34,919
sensitive data and they want to export

622
00:29:34,919 --> 00:29:37,860
it or exfiltrate it so how could we make

623
00:29:37,860 --> 00:29:40,740
that more difficult well granular source

624
00:29:40,740 --> 00:29:43,440
and destination firewall rules and I've

625
00:29:43,440 --> 00:29:45,720
got to step away from this a little bit

626
00:29:45,720 --> 00:29:48,120
because we could really get dragged down

627
00:29:48,120 --> 00:29:49,559
into

628
00:29:49,559 --> 00:29:52,860
a a full morning long presentation a

629
00:29:52,860 --> 00:29:55,679
day-long presentation where we just

630
00:29:55,679 --> 00:29:57,000
talked about

631
00:29:57,000 --> 00:30:00,419
how to adversaries exfiltrate data from

632
00:30:00,419 --> 00:30:03,659
an I.T environment and how might we

633
00:30:03,659 --> 00:30:06,720
prevent that right so obviously we want

634
00:30:06,720 --> 00:30:08,399
to make sure that people can't plug a

635
00:30:08,399 --> 00:30:12,480
USB drive in we want to prevent uh

636
00:30:12,480 --> 00:30:15,720
access to personal email like Gmail or

637
00:30:15,720 --> 00:30:18,720
going out to things like Dropbox but

638
00:30:18,720 --> 00:30:21,240
unfortunately I don't have time to cover

639
00:30:21,240 --> 00:30:24,360
more than that but it's important to

640
00:30:24,360 --> 00:30:27,779
research how adversaries conduct data

641
00:30:27,779 --> 00:30:30,799
exfiltration and how to prevent that

642
00:30:30,799 --> 00:30:34,679
so next we we do have an adversary in

643
00:30:34,679 --> 00:30:36,480
the environment we want to detect them

644
00:30:36,480 --> 00:30:39,299
so some ways to do that are threat

645
00:30:39,299 --> 00:30:41,460
hunting right so

646
00:30:41,460 --> 00:30:43,559
um this is where we have qualified

647
00:30:43,559 --> 00:30:47,659
Security Professionals that uh access

648
00:30:47,659 --> 00:30:50,580
the SIM and we're you know we're

649
00:30:50,580 --> 00:30:53,279
searching through blogs and events and

650
00:30:53,279 --> 00:30:56,340
we're trying to find signs of the

651
00:30:56,340 --> 00:30:58,320
adversary so rather than passively

652
00:30:58,320 --> 00:30:59,700
saying

653
00:30:59,700 --> 00:31:02,820
we've got endpoint protection and we've

654
00:31:02,820 --> 00:31:05,640
got the Sim logging and event

655
00:31:05,640 --> 00:31:08,279
correlation it's just automatically

656
00:31:08,279 --> 00:31:11,340
going to notify us if there's an

657
00:31:11,340 --> 00:31:13,980
adversary we really need to look and we

658
00:31:13,980 --> 00:31:16,799
can do that leveraging um cyber threat

659
00:31:16,799 --> 00:31:19,620
intelligence data from organizations

660
00:31:19,620 --> 00:31:21,720
like sisa

661
00:31:21,720 --> 00:31:23,640
it's also good to take a look at the

662
00:31:23,640 --> 00:31:25,559
miter attack framework if you haven't

663
00:31:25,559 --> 00:31:27,240
already

664
00:31:27,240 --> 00:31:30,140
um it speaks about adversarial

665
00:31:30,140 --> 00:31:34,559
techniques uh tactics and procedures

666
00:31:34,559 --> 00:31:37,559
um so next we've at we've

667
00:31:37,559 --> 00:31:39,720
identified an adversary in the

668
00:31:39,720 --> 00:31:41,880
environment and thankfully we have our

669
00:31:41,880 --> 00:31:44,700
incident response plan hopefully it has

670
00:31:44,700 --> 00:31:47,399
scenarios it's not just generic right

671
00:31:47,399 --> 00:31:50,580
and we leverage our incident response

672
00:31:50,580 --> 00:31:53,760
plan to find

673
00:31:53,760 --> 00:31:57,480
what access is the the adversary has and

674
00:31:57,480 --> 00:31:59,399
eradicate them from the environment and

675
00:31:59,399 --> 00:32:01,980
prevent them from getting back in it's

676
00:32:01,980 --> 00:32:03,779
important to have incident response

677
00:32:03,779 --> 00:32:06,419
exercises so we're not doing this for

678
00:32:06,419 --> 00:32:10,200
the first time when we find an adversary

679
00:32:10,200 --> 00:32:13,080
did want to discuss emerging threats and

680
00:32:13,080 --> 00:32:15,179
countermeasures right we absolutely need

681
00:32:15,179 --> 00:32:18,659
that in Risk Management so each time I

682
00:32:18,659 --> 00:32:21,000
do this presentation I update it so

683
00:32:21,000 --> 00:32:24,840
here's a couple of recent alerts from

684
00:32:24,840 --> 00:32:27,860
sisa so one is around weak security

685
00:32:27,860 --> 00:32:31,200
controls that are exploited for initial

686
00:32:31,200 --> 00:32:34,559
access uh so it's great to get these

687
00:32:34,559 --> 00:32:37,559
alerts and advisories from sisa and to

688
00:32:37,559 --> 00:32:40,140
go in and see what our threat actors

689
00:32:40,140 --> 00:32:44,100
doing today and what are recommendations

690
00:32:44,100 --> 00:32:46,740
for controls to either prevent that

691
00:32:46,740 --> 00:32:49,679
access or at least identify it and

692
00:32:49,679 --> 00:32:51,240
respond

693
00:32:51,240 --> 00:32:55,020
we also have another alert where there's

694
00:32:55,020 --> 00:32:58,200
an exfiltration tool that was used to

695
00:32:58,200 --> 00:33:00,539
steal sensitive information from a

696
00:33:00,539 --> 00:33:03,360
defense contractor so I don't care

697
00:33:03,360 --> 00:33:06,299
that I I'm not in a defense contract or

698
00:33:06,299 --> 00:33:08,220
organization I want to know what are the

699
00:33:08,220 --> 00:33:10,200
adversaries doing

700
00:33:10,200 --> 00:33:12,659
um they use those tools and pass them

701
00:33:12,659 --> 00:33:14,940
around so it's good to know what's going

702
00:33:14,940 --> 00:33:17,220
on now with these threat actors what

703
00:33:17,220 --> 00:33:19,799
techniques tactics and procedures they

704
00:33:19,799 --> 00:33:22,919
have and then to take action internally

705
00:33:22,919 --> 00:33:25,620
I I have some bullets there at the

706
00:33:25,620 --> 00:33:27,480
bottom because there's a fair amount of

707
00:33:27,480 --> 00:33:30,480
times where I'll work with security

708
00:33:30,480 --> 00:33:32,419
teams and sure enough everybody's

709
00:33:32,419 --> 00:33:36,179
subscribed to the sisa advisories and

710
00:33:36,179 --> 00:33:39,059
alerts but the question is you know if

711
00:33:39,059 --> 00:33:42,000
you've got five or seven people that are

712
00:33:42,000 --> 00:33:43,860
all thinking the other person's doing

713
00:33:43,860 --> 00:33:46,679
something do we have a process where

714
00:33:46,679 --> 00:33:49,440
when each advisory comes in each alert

715
00:33:49,440 --> 00:33:51,840
comes in we look through it and we

716
00:33:51,840 --> 00:33:55,019
decide at a high level what if this

717
00:33:55,019 --> 00:33:57,840
applies to us what actions should we

718
00:33:57,840 --> 00:34:00,779
take and then to make plans to do that

719
00:34:00,779 --> 00:34:02,760
you may have one or two things that

720
00:34:02,760 --> 00:34:04,080
you're going you're saying I'm gonna do

721
00:34:04,080 --> 00:34:07,140
right now and maybe have a to-do list or

722
00:34:07,140 --> 00:34:10,199
a list of things that you may do this

723
00:34:10,199 --> 00:34:12,418
year or next year it's great to hang on

724
00:34:12,418 --> 00:34:15,239
to the things that we can't do today and

725
00:34:15,239 --> 00:34:18,239
these advisories but to use the moving

726
00:34:18,239 --> 00:34:19,440
forward

727
00:34:19,440 --> 00:34:22,020
and I do have a link there to more

728
00:34:22,020 --> 00:34:24,480
information and advice on how to set up

729
00:34:24,480 --> 00:34:27,300
a cyber threat intelligence program

730
00:34:27,300 --> 00:34:29,699
I did speak to you about risk register

731
00:34:29,699 --> 00:34:33,859
entries and this helps to influence

732
00:34:33,859 --> 00:34:37,520
mitigation of cyber security risk issues

733
00:34:37,520 --> 00:34:40,619
it prevents skeletons in the closet so

734
00:34:40,619 --> 00:34:43,679
if we become aware of a risk and perhaps

735
00:34:43,679 --> 00:34:45,719
we have maybe

736
00:34:45,719 --> 00:34:48,418
um an I.T executive you know an app

737
00:34:48,418 --> 00:34:51,060
executive whomever that says that's fine

738
00:34:51,060 --> 00:34:52,800
you know we're not going to deal with

739
00:34:52,800 --> 00:34:54,659
this right now we'll do deal with it

740
00:34:54,659 --> 00:34:57,839
next year terrific let's fill out a risk

741
00:34:57,839 --> 00:35:00,300
register entry and we'll get that into

742
00:35:00,300 --> 00:35:02,940
the risk governance process and we can

743
00:35:02,940 --> 00:35:05,220
talk about it and sometimes just that

744
00:35:05,220 --> 00:35:07,020
hey we're going to fill out a risk

745
00:35:07,020 --> 00:35:09,240
registry entry and it's going to be seen

746
00:35:09,240 --> 00:35:12,240
by other layers of Executives sometimes

747
00:35:12,240 --> 00:35:15,720
that will spur on remediation and if not

748
00:35:15,720 --> 00:35:18,619
these risk register entries either

749
00:35:18,619 --> 00:35:21,300
document risk acceptance that's

750
00:35:21,300 --> 00:35:24,480
typically something that's low risk high

751
00:35:24,480 --> 00:35:26,339
cost

752
00:35:26,339 --> 00:35:29,880
um or it can be used similar to a plan

753
00:35:29,880 --> 00:35:32,640
of action and Milestone to say we are

754
00:35:32,640 --> 00:35:35,599
going to mitigate this risk here's

755
00:35:35,599 --> 00:35:38,339
Milestones here's the five steps which

756
00:35:38,339 --> 00:35:42,900
bring us to this target remediation date

757
00:35:42,900 --> 00:35:45,960
quickly here is a risk register process

758
00:35:45,960 --> 00:35:49,800
diagram typically risk is identified in

759
00:35:49,800 --> 00:35:52,859
the cyber security Realm by the infosec

760
00:35:52,859 --> 00:35:55,260
teams though sometimes the process owner

761
00:35:55,260 --> 00:35:57,240
and really what we're going to do is

762
00:35:57,240 --> 00:36:00,660
work with that process owner to create a

763
00:36:00,660 --> 00:36:03,540
risk registry entry this is outside of

764
00:36:03,540 --> 00:36:07,140
vulnerability scans it's something else

765
00:36:07,140 --> 00:36:09,960
um and when it comes to step six they're

766
00:36:09,960 --> 00:36:12,660
in the risk governance swim Lane

767
00:36:12,660 --> 00:36:16,020
executive leadership May rarely say look

768
00:36:16,020 --> 00:36:18,180
we want you to do some more research we

769
00:36:18,180 --> 00:36:20,700
want you to revise this and come back

770
00:36:20,700 --> 00:36:24,599
or they may say risk accept low risk

771
00:36:24,599 --> 00:36:27,300
issue high cost we'll review it in a

772
00:36:27,300 --> 00:36:30,780
year or they may say we agree with your

773
00:36:30,780 --> 00:36:34,020
risk mitigation plans here we we may by

774
00:36:34,020 --> 00:36:36,720
the way be asking for some funding or

775
00:36:36,720 --> 00:36:39,180
Staffing priority in this process but we

776
00:36:39,180 --> 00:36:42,119
agree with your plan to risk mitigate we

777
00:36:42,119 --> 00:36:44,820
agree with your three to five uh

778
00:36:44,820 --> 00:36:47,520
Milestones or steps to get to that

779
00:36:47,520 --> 00:36:50,280
Target date and then you can see when

780
00:36:50,280 --> 00:36:53,540
remediation is said to be done we have

781
00:36:53,540 --> 00:36:56,400
infosec confirming that that the

782
00:36:56,400 --> 00:36:59,280
notification goes out that that issue

783
00:36:59,280 --> 00:37:01,560
has been closed

784
00:37:01,560 --> 00:37:03,480
heading down the home stretch of this

785
00:37:03,480 --> 00:37:05,599
presentation so strong risk management

786
00:37:05,599 --> 00:37:07,740
typically this is for financial

787
00:37:07,740 --> 00:37:10,200
institutions government entities

788
00:37:10,200 --> 00:37:13,500
pharmaceutical companies very low risk

789
00:37:13,500 --> 00:37:14,940
tolerance

790
00:37:14,940 --> 00:37:16,859
um one I would suggest that you should

791
00:37:16,859 --> 00:37:19,800
not have the Cyber Security executive or

792
00:37:19,800 --> 00:37:21,300
leader

793
00:37:21,300 --> 00:37:24,960
um reporting into a CIO or a CTO because

794
00:37:24,960 --> 00:37:28,260
it's a conflict of interest uh the the

795
00:37:28,260 --> 00:37:30,060
cyber security leader should report into

796
00:37:30,060 --> 00:37:33,119
someone like the CEO the chief risk

797
00:37:33,119 --> 00:37:35,880
officer or the board of directors it is

798
00:37:35,880 --> 00:37:38,700
important to have cyber security metrics

799
00:37:38,700 --> 00:37:41,220
key performance indicators key risk

800
00:37:41,220 --> 00:37:44,640
indicators and really that provides risk

801
00:37:44,640 --> 00:37:48,060
transparency to the executives but it

802
00:37:48,060 --> 00:37:51,300
also helps us influence risk mitigation

803
00:37:51,300 --> 00:37:54,599
and sometimes funding for our program

804
00:37:54,599 --> 00:37:57,060
I do think it's important for the cyber

805
00:37:57,060 --> 00:38:00,420
security leader to provide updates

806
00:38:00,420 --> 00:38:02,579
um to the board of directors or similar

807
00:38:02,579 --> 00:38:04,619
executive group like a cyber security

808
00:38:04,619 --> 00:38:07,220
committee

809
00:38:07,220 --> 00:38:09,000
also

810
00:38:09,000 --> 00:38:11,160
I think it's important for the the cyber

811
00:38:11,160 --> 00:38:13,740
security program to not just stay at the

812
00:38:13,740 --> 00:38:16,260
Enterprise level where we're comfortable

813
00:38:16,260 --> 00:38:18,839
as cyber Security Professionals right or

814
00:38:18,839 --> 00:38:21,480
we're talking about systems and and

815
00:38:21,480 --> 00:38:24,119
networks and applications but we get

816
00:38:24,119 --> 00:38:27,180
down into understanding what are the

817
00:38:27,180 --> 00:38:29,579
business processes

818
00:38:29,579 --> 00:38:31,440
um what are the services that the

819
00:38:31,440 --> 00:38:33,300
business units the lines of business

820
00:38:33,300 --> 00:38:35,579
have and

821
00:38:35,579 --> 00:38:39,000
do we have the right types of cyber

822
00:38:39,000 --> 00:38:42,300
Security fraud prevention controls in

823
00:38:42,300 --> 00:38:45,720
place so to get to that next level and

824
00:38:45,720 --> 00:38:47,520
and prevent something negative from

825
00:38:47,520 --> 00:38:49,040
happening

826
00:38:49,040 --> 00:38:52,619
also to be involved in things like fraud

827
00:38:52,619 --> 00:38:55,020
prevention and privacy which are a

828
00:38:55,020 --> 00:38:58,320
little bit peripheral to cyber um we

829
00:38:58,320 --> 00:39:01,079
definitely have a role to play there

830
00:39:01,079 --> 00:39:05,520
and I'm a fan of iia's three lines of

831
00:39:05,520 --> 00:39:08,400
Defense model which says that the first

832
00:39:08,400 --> 00:39:10,320
line of defense is operational

833
00:39:10,320 --> 00:39:13,020
management right so that might just be

834
00:39:13,020 --> 00:39:16,320
I.T or the average employee they are the

835
00:39:16,320 --> 00:39:18,660
first line of defense developers of the

836
00:39:18,660 --> 00:39:21,180
first line of defense second line is

837
00:39:21,180 --> 00:39:24,060
risk management functions like cyber

838
00:39:24,060 --> 00:39:26,160
security like privacy like the fraud

839
00:39:26,160 --> 00:39:28,619
prevention team also compliance

840
00:39:28,619 --> 00:39:31,200
functions and then the third line of

841
00:39:31,200 --> 00:39:34,320
defense is internal audit

842
00:39:34,320 --> 00:39:37,920
I also think it's important to have

843
00:39:37,920 --> 00:39:41,099
self-identified audit issues as a

844
00:39:41,099 --> 00:39:43,500
requirement uh perhaps we're saying

845
00:39:43,500 --> 00:39:45,599
operational functions in line of

846
00:39:45,599 --> 00:39:48,060
business have to declare self-identified

847
00:39:48,060 --> 00:39:50,460
audit issues

848
00:39:50,460 --> 00:39:53,839
two or four times a year and it just

849
00:39:53,839 --> 00:39:56,220
reinforces that it's not just the

850
00:39:56,220 --> 00:39:58,640
Securities team or internal audits team

851
00:39:58,640 --> 00:40:02,280
job to identify risk

852
00:40:02,280 --> 00:40:05,099
everyone has that responsibility in that

853
00:40:05,099 --> 00:40:08,040
first line of defense operational

854
00:40:08,040 --> 00:40:10,579
management

855
00:40:12,000 --> 00:40:15,240
you've all heard about zero trust uh and

856
00:40:15,240 --> 00:40:18,540
it's an architectural security model

857
00:40:18,540 --> 00:40:21,420
um so that's an important place to get

858
00:40:21,420 --> 00:40:24,359
into uh people have challenges with it

859
00:40:24,359 --> 00:40:27,180
because as an architectural model it's a

860
00:40:27,180 --> 00:40:29,640
little bit high level right and then

861
00:40:29,640 --> 00:40:31,200
also that gets complicated because

862
00:40:31,200 --> 00:40:34,380
vendors will say hey we've solved for

863
00:40:34,380 --> 00:40:37,980
zero trust they haven't so on my website

864
00:40:37,980 --> 00:40:42,900
I have a listing of 134 controls and

865
00:40:42,900 --> 00:40:45,000
it's not meant to be a control based one

866
00:40:45,000 --> 00:40:47,940
for zero trust it's more I've had people

867
00:40:47,940 --> 00:40:49,260
say to me

868
00:40:49,260 --> 00:40:51,300
I'm really struggling with the

869
00:40:51,300 --> 00:40:54,480
architectural piece what's what am I

870
00:40:54,480 --> 00:40:56,280
selecting from like

871
00:40:56,280 --> 00:40:58,980
how do you make this real so I've had

872
00:40:58,980 --> 00:41:01,380
some ideas of here are some controls

873
00:41:01,380 --> 00:41:04,500
that you could select again not meaning

874
00:41:04,500 --> 00:41:08,180
to solve for zero trust

875
00:41:08,760 --> 00:41:11,160
Carnegie Mellon has

876
00:41:11,160 --> 00:41:14,760
um 21 practices to establish and

877
00:41:14,760 --> 00:41:16,680
maintain an Insider threat program

878
00:41:16,680 --> 00:41:18,839
really

879
00:41:18,839 --> 00:41:22,260
strongly encourage you coming out of

880
00:41:22,260 --> 00:41:24,960
this to take a look at that as cyber

881
00:41:24,960 --> 00:41:28,079
Security Professionals uh it's an online

882
00:41:28,079 --> 00:41:31,859
book in PDF format it's about 200 pages

883
00:41:31,859 --> 00:41:34,380
but carry this with you throughout your

884
00:41:34,380 --> 00:41:37,140
career because we do need to be mindful

885
00:41:37,140 --> 00:41:40,859
that there are authorized Personnel

886
00:41:40,859 --> 00:41:43,320
employees and contractors within our

887
00:41:43,320 --> 00:41:46,500
organization that may either seek to do

888
00:41:46,500 --> 00:41:48,180
harm to the organization or to

889
00:41:48,180 --> 00:41:50,820
exfiltrate data

890
00:41:50,820 --> 00:41:52,980
a little bit more this is from miter

891
00:41:52,980 --> 00:41:55,680
talking about Insider threat monitoring

892
00:41:55,680 --> 00:41:58,260
uh I do want to hit on some of the

893
00:41:58,260 --> 00:42:00,540
themes that they talk about so in

894
00:42:00,540 --> 00:42:03,020
Insider threats routinely used

895
00:42:03,020 --> 00:42:06,660
unsophisticated techniques tactics and

896
00:42:06,660 --> 00:42:10,760
procedures to access and exfiltrate data

897
00:42:10,760 --> 00:42:13,859
specifically they're using removable

898
00:42:13,859 --> 00:42:17,099
media so we need to make sure in our

899
00:42:17,099 --> 00:42:19,079
companies and corporations don't allow

900
00:42:19,079 --> 00:42:22,200
people to plug in a USB drive and just

901
00:42:22,200 --> 00:42:24,960
take a gig of data out on it uh on a

902
00:42:24,960 --> 00:42:26,400
drive like that

903
00:42:26,400 --> 00:42:29,579
also email is a common exfiltration

904
00:42:29,579 --> 00:42:32,940
channel so I would recommend blocking

905
00:42:32,940 --> 00:42:35,760
access to things like Gmail and then we

906
00:42:35,760 --> 00:42:38,640
need to monitor outbound email from the

907
00:42:38,640 --> 00:42:40,980
corporate authorized accounts that all

908
00:42:40,980 --> 00:42:43,440
employees and contractors have

909
00:42:43,440 --> 00:42:46,560
also cloud storage is used for

910
00:42:46,560 --> 00:42:49,440
exfiltration so blocking things like

911
00:42:49,440 --> 00:42:51,660
Dropbox and then maybe we have

912
00:42:51,660 --> 00:42:54,839
exceptions based on business need but we

913
00:42:54,839 --> 00:42:57,660
mitigate a lot of that risk I mentioned

914
00:42:57,660 --> 00:43:00,119
threat hunting before again we could

915
00:43:00,119 --> 00:43:02,819
have a morning or a whole day on threat

916
00:43:02,819 --> 00:43:04,140
hunting but

917
00:43:04,140 --> 00:43:06,780
actively searching for adversaries in

918
00:43:06,780 --> 00:43:09,960
your environment we can start by looking

919
00:43:09,960 --> 00:43:13,400
um for suspicious events in our logging

920
00:43:13,400 --> 00:43:15,960
indicators of compromise so you'll get

921
00:43:15,960 --> 00:43:19,980
an advisory from cisa that says here are

922
00:43:19,980 --> 00:43:23,040
some of the malicious IP addresses

923
00:43:23,040 --> 00:43:26,220
also tactics techniques and procedures

924
00:43:26,220 --> 00:43:29,460
so we talked about seesa alerts and

925
00:43:29,460 --> 00:43:32,579
advisories there's also the miter attack

926
00:43:32,579 --> 00:43:36,319
framework and then hunting based on

927
00:43:36,319 --> 00:43:40,380
hypothesis so an example is we know that

928
00:43:40,380 --> 00:43:41,520
sooner or later we're gonna have an

929
00:43:41,520 --> 00:43:44,460
employee that's seeking to export data

930
00:43:44,460 --> 00:43:47,040
and take it to their next employer

931
00:43:47,040 --> 00:43:49,200
what would they do

932
00:43:49,200 --> 00:43:51,599
what would that look like what

933
00:43:51,599 --> 00:43:53,460
preventive controls could we put in

934
00:43:53,460 --> 00:43:55,920
place and then one of the things I love

935
00:43:55,920 --> 00:43:59,160
about hunting is it feeds security

936
00:43:59,160 --> 00:44:01,319
monitoring so you have ideas coming out

937
00:44:01,319 --> 00:44:03,180
of that and you say you know what

938
00:44:03,180 --> 00:44:05,460
we need to put some extra alerts into

939
00:44:05,460 --> 00:44:07,940
the SIM

940
00:44:12,180 --> 00:44:13,920
I think this is one of the final slides

941
00:44:13,920 --> 00:44:17,760
in in the DAC so very important for you

942
00:44:17,760 --> 00:44:20,579
as cyber Security Professionals and

943
00:44:20,579 --> 00:44:23,040
students to learn how to influence

944
00:44:23,040 --> 00:44:24,800
funding and it's going to be different

945
00:44:24,800 --> 00:44:28,380
uh for different organizations

946
00:44:28,380 --> 00:44:30,660
um depending what industry you're in and

947
00:44:30,660 --> 00:44:31,859
then also

948
00:44:31,859 --> 00:44:34,619
who are your Executives what what are

949
00:44:34,619 --> 00:44:37,079
their drivers what motivates them

950
00:44:37,079 --> 00:44:40,740
so some examples of ways to influence

951
00:44:40,740 --> 00:44:43,980
funding for your security program for

952
00:44:43,980 --> 00:44:47,220
new security controls and or Staffing

953
00:44:47,220 --> 00:44:50,579
if you're in uh a financial institution

954
00:44:50,579 --> 00:44:52,440
federal government Pharmaceuticals

955
00:44:52,440 --> 00:44:55,200
sometimes it's just compliance and if

956
00:44:55,200 --> 00:44:58,859
you can tie a cyber security issue or

957
00:44:58,859 --> 00:45:01,020
vulnerability

958
00:45:01,020 --> 00:45:03,720
um to one of the many regulatory

959
00:45:03,720 --> 00:45:05,280
requirements you may be able to get

960
00:45:05,280 --> 00:45:09,000
funding to get that resolved uh

961
00:45:09,000 --> 00:45:12,540
operational risk so

962
00:45:12,540 --> 00:45:14,940
those types of organizations also care

963
00:45:14,940 --> 00:45:17,520
about that operational risk may be more

964
00:45:17,520 --> 00:45:19,680
meaningful to a privately owned company

965
00:45:19,680 --> 00:45:21,900
but we talked about risk tolerance

966
00:45:21,900 --> 00:45:25,460
statement metrics kpis Kris having

967
00:45:25,460 --> 00:45:29,700
assessments done by an external firm uh

968
00:45:29,700 --> 00:45:32,280
an assessment report is a

969
00:45:32,280 --> 00:45:35,099
non-repudiation vehicle right so an exec

970
00:45:35,099 --> 00:45:36,780
can say I don't remember that

971
00:45:36,780 --> 00:45:38,819
conversation I don't remember that email

972
00:45:38,819 --> 00:45:40,619
it's hard to say I don't remember the

973
00:45:40,619 --> 00:45:42,119
assessment report

974
00:45:42,119 --> 00:45:45,000
also things like table top exercisers or

975
00:45:45,000 --> 00:45:48,060
wargamings or uh War gaming or you

976
00:45:48,060 --> 00:45:51,180
involve your senior leadership team they

977
00:45:51,180 --> 00:45:53,940
get put under stress right when we're

978
00:45:53,940 --> 00:45:55,560
simulating that there's an incident

979
00:45:55,560 --> 00:45:58,079
going on they don't want to experience

980
00:45:58,079 --> 00:46:00,599
that stress in real life may get you

981
00:46:00,599 --> 00:46:04,380
some funding be careful with asking for

982
00:46:04,380 --> 00:46:05,940
additional Staffing and saying you don't

983
00:46:05,940 --> 00:46:07,920
have capacity

984
00:46:07,920 --> 00:46:10,200
um if you ask any manager they're going

985
00:46:10,200 --> 00:46:12,480
to say that they're they're understaffed

986
00:46:12,480 --> 00:46:15,380
right so some ways to go down that path

987
00:46:15,380 --> 00:46:19,560
if every one of your employees has 10

988
00:46:19,560 --> 00:46:21,920
primary and Alternate duties

989
00:46:21,920 --> 00:46:25,319
and those all look important you might

990
00:46:25,319 --> 00:46:27,180
be able to convince an executive you

991
00:46:27,180 --> 00:46:30,060
don't have enough staff also if a lot of

992
00:46:30,060 --> 00:46:33,000
the work is documented in tickets you

993
00:46:33,000 --> 00:46:34,740
may be able to use that ticket data

994
00:46:34,740 --> 00:46:37,079
based on the volume and hours to get

995
00:46:37,079 --> 00:46:39,599
some staffing here's some more subtle

996
00:46:39,599 --> 00:46:42,900
things if continually you you as an

997
00:46:42,900 --> 00:46:45,420
individual contributor in cyber security

998
00:46:45,420 --> 00:46:49,079
or a leader uh are planning and

999
00:46:49,079 --> 00:46:50,940
executing on your goals and delivering

1000
00:46:50,940 --> 00:46:53,339
you may get funding in part because of

1001
00:46:53,339 --> 00:46:56,280
that the execs know you know what if I

1002
00:46:56,280 --> 00:46:58,500
give money to this person or this

1003
00:46:58,500 --> 00:47:01,200
manager I know I'm going to get return

1004
00:47:01,200 --> 00:47:04,440
out of it Communications routines don't

1005
00:47:04,440 --> 00:47:06,540
just ask at the end of the year for your

1006
00:47:06,540 --> 00:47:09,960
funding you want to participate in

1007
00:47:09,960 --> 00:47:13,020
program updates meeting routines and you

1008
00:47:13,020 --> 00:47:14,460
know give an update every month of

1009
00:47:14,460 --> 00:47:16,500
what's going on and what the risk is and

1010
00:47:16,500 --> 00:47:19,560
what type of support you need have some

1011
00:47:19,560 --> 00:47:21,960
one-on-one meeting strategically with

1012
00:47:21,960 --> 00:47:24,839
Executives and then Financial Acumen

1013
00:47:24,839 --> 00:47:27,300
realize that right around at this time

1014
00:47:27,300 --> 00:47:30,359
of the year Executives have use or lose

1015
00:47:30,359 --> 00:47:33,780
money so if they don't spend it they'll

1016
00:47:33,780 --> 00:47:35,640
lose it at the end of the year and also

1017
00:47:35,640 --> 00:47:37,800
it will hurt them because next year if

1018
00:47:37,800 --> 00:47:39,420
they're asking for money and they didn't

1019
00:47:39,420 --> 00:47:42,180
spend all of it this year they're going

1020
00:47:42,180 --> 00:47:45,599
to take a haircut or get less funding in

1021
00:47:45,599 --> 00:47:50,040
their new budget so I used to years back

1022
00:47:50,040 --> 00:47:52,140
I had an executive and I used to kind of

1023
00:47:52,140 --> 00:47:54,720
stick my head in his door frame and say

1024
00:47:54,720 --> 00:47:58,680
got any money I've got you know three uh

1025
00:47:58,680 --> 00:48:01,200
invoices from vendors and and I'm ready

1026
00:48:01,200 --> 00:48:03,240
I'm ready to execute and spend that

1027
00:48:03,240 --> 00:48:06,780
money and sometimes I was successful

1028
00:48:06,780 --> 00:48:10,460
so with that Joel we've reached the end

1029
00:48:10,460 --> 00:48:14,280
of the presentation and I think we can

1030
00:48:14,280 --> 00:48:17,579
open it up and see what questions and

1031
00:48:17,579 --> 00:48:20,420
comments we have

1032
00:48:21,000 --> 00:48:22,740
we can thank you getting there one

1033
00:48:22,740 --> 00:48:24,480
question did come in on the Q a feature

1034
00:48:24,480 --> 00:48:27,119
uh from one of our PhD students so how

1035
00:48:27,119 --> 00:48:28,500
do you get by

1036
00:48:28,500 --> 00:48:31,500
sorry how do you get buy-in from

1037
00:48:31,500 --> 00:48:34,380
security teams that may see these

1038
00:48:34,380 --> 00:48:37,079
compliance efforts as box ticking

1039
00:48:37,079 --> 00:48:39,859
exercises

1040
00:48:40,020 --> 00:48:42,480
well I think it's important to be able

1041
00:48:42,480 --> 00:48:44,339
to articulate

1042
00:48:44,339 --> 00:48:46,980
compliance requirements from a risk

1043
00:48:46,980 --> 00:48:50,160
perspective and in general

1044
00:48:50,160 --> 00:48:54,480
most of them have some value in in terms

1045
00:48:54,480 --> 00:48:58,440
of how we're going to prevent

1046
00:48:58,440 --> 00:49:01,500
um a security issue from happening or to

1047
00:49:01,500 --> 00:49:03,480
to detect it

1048
00:49:03,480 --> 00:49:05,819
um there may be some cases where what

1049
00:49:05,819 --> 00:49:08,280
they're saying is legitimate though

1050
00:49:08,280 --> 00:49:12,060
um so if one of the things about PCI

1051
00:49:12,060 --> 00:49:13,500
compliance the way that payment card

1052
00:49:13,500 --> 00:49:16,079
security is done is there can be

1053
00:49:16,079 --> 00:49:18,180
compensating controls but we've got to

1054
00:49:18,180 --> 00:49:20,760
make sure that if we're saying we're not

1055
00:49:20,760 --> 00:49:24,839
going to cover One requirement we're not

1056
00:49:24,839 --> 00:49:26,940
citing another requirement that really

1057
00:49:26,940 --> 00:49:29,640
doesn't address that issue but in answer

1058
00:49:29,640 --> 00:49:32,099
to that question I think it's a fair

1059
00:49:32,099 --> 00:49:34,740
thing for the security team to say pay

1060
00:49:34,740 --> 00:49:37,319
your box ticking on

1061
00:49:37,319 --> 00:49:40,579
um final Integrity monitoring we've got

1062
00:49:40,579 --> 00:49:43,619
vulnerability scanning running we've got

1063
00:49:43,619 --> 00:49:46,500
many other ways of determining some sort

1064
00:49:46,500 --> 00:49:49,200
of issue file Integrity monitoring is

1065
00:49:49,200 --> 00:49:51,300
this Antiquated control and you know

1066
00:49:51,300 --> 00:49:53,280
what I might tend to agree with them so

1067
00:49:53,280 --> 00:49:56,099
be always be ready to see the other side

1068
00:49:56,099 --> 00:49:58,920
of the table will be part of my advice

1069
00:49:58,920 --> 00:50:01,859
yeah great answer um my take on this

1070
00:50:01,859 --> 00:50:04,020
because the idea of box ticking you know

1071
00:50:04,020 --> 00:50:05,460
oh you're not really making yourself

1072
00:50:05,460 --> 00:50:08,300
more secure your ticks and boxes

1073
00:50:08,300 --> 00:50:12,300
granted right I I also do usually try to

1074
00:50:12,300 --> 00:50:14,060
share is that well the reason that those

1075
00:50:14,060 --> 00:50:17,220
boxes are there is to make you think

1076
00:50:17,220 --> 00:50:19,200
about these things that sometimes you

1077
00:50:19,200 --> 00:50:21,780
may skip over so yes there is a

1078
00:50:21,780 --> 00:50:22,980
difference in just trying to do box

1079
00:50:22,980 --> 00:50:25,319
checking but but the reason those boxes

1080
00:50:25,319 --> 00:50:27,359
are there hopefully lead you towards

1081
00:50:27,359 --> 00:50:28,859
actually making sure you make some smart

1082
00:50:28,859 --> 00:50:30,300
decisions so I agree with your answer

1083
00:50:30,300 --> 00:50:32,040
there very much

1084
00:50:32,040 --> 00:50:35,160
um we are right at 5 20 which is the

1085
00:50:35,160 --> 00:50:39,240
official end time of the class uh if a

1086
00:50:39,240 --> 00:50:40,980
question comes in before I'm done

1087
00:50:40,980 --> 00:50:43,020
rambling here we'll be glad to get it in

1088
00:50:43,020 --> 00:50:45,060
here uh because we know a lot of people

1089
00:50:45,060 --> 00:50:48,380
typically will budget until 5 30 on this

1090
00:50:48,380 --> 00:50:52,260
anyways but as as we do wrap up I do

1091
00:50:52,260 --> 00:50:54,359
want to again uh say Gideon thank you

1092
00:50:54,359 --> 00:50:56,359
very much it's always great to have you

1093
00:50:56,359 --> 00:50:59,940
uh while this is a four credit class a

1094
00:50:59,940 --> 00:51:01,800
gradual level lecture class at Purdue

1095
00:51:01,800 --> 00:51:05,040
University uh the public is encouraged

1096
00:51:05,040 --> 00:51:07,800
to tune in uh and those who do so can

1097
00:51:07,800 --> 00:51:10,079
actually get continuing education nation

1098
00:51:10,079 --> 00:51:12,540
and I know that's a concern of yours as

1099
00:51:12,540 --> 00:51:15,839
well with as many letters as you have uh

1100
00:51:15,839 --> 00:51:17,520
designating the certs that you have on

1101
00:51:17,520 --> 00:51:19,619
this so we're pleased that the the

1102
00:51:19,619 --> 00:51:22,440
general public can tune into this

1103
00:51:22,440 --> 00:51:26,099
um and uh we uh again appreciate you

1104
00:51:26,099 --> 00:51:28,319
taking the time and I know that in

1105
00:51:28,319 --> 00:51:30,359
seeing you speak elsewhere and from our

1106
00:51:30,359 --> 00:51:33,000
conversations that I do hope that we are

1107
00:51:33,000 --> 00:51:34,680
able to get you back here in another

1108
00:51:34,680 --> 00:51:37,319
year or so to cover another one of these

1109
00:51:37,319 --> 00:51:39,660
topics that are not only uh great uh

1110
00:51:39,660 --> 00:51:41,819
things for our students to learn but

1111
00:51:41,819 --> 00:51:44,520
also for those in general in the cyber

1112
00:51:44,520 --> 00:51:46,260
security industry to take take interest

1113
00:51:46,260 --> 00:51:49,260
and take note of as I started with your

1114
00:51:49,260 --> 00:51:50,819
introduction I encourage all of our

1115
00:51:50,819 --> 00:51:53,880
attendees and participants to seek you

1116
00:51:53,880 --> 00:51:56,940
out on social media especially you're a

1117
00:51:56,940 --> 00:51:59,640
heavy um a posting that goes on on

1118
00:51:59,640 --> 00:52:01,460
LinkedIn where I follow you very closely

1119
00:52:01,460 --> 00:52:03,240
and I want to encourage everybody

1120
00:52:03,240 --> 00:52:05,400
getting included please show up again

1121
00:52:05,400 --> 00:52:07,980
next week live as Christine task a very

1122
00:52:07,980 --> 00:52:10,800
proud graduate of the serious program at

1123
00:52:10,800 --> 00:52:13,500
Purdue University uh we'll return home

1124
00:52:13,500 --> 00:52:16,500
air quotes will return home to to give

1125
00:52:16,500 --> 00:52:19,440
our our seminar again next week so with

1126
00:52:19,440 --> 00:52:21,960
that thanks very much and we'll see you

1127
00:52:21,960 --> 00:52:24,180
next week bye-bye

1128
00:52:24,180 --> 00:52:27,379
thanks so much Joel

