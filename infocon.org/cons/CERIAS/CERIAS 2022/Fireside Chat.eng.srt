1
00:00:00,719 --> 00:00:02,960
before i start the panel i'd like to uh

2
00:00:02,960 --> 00:00:05,200
recognize that i when i did the

3
00:00:05,200 --> 00:00:08,000
introduction for uh

4
00:00:08,000 --> 00:00:10,160
dr mcgrew i had mentioned this the start

5
00:00:10,160 --> 00:00:11,759
of the coast lab and

6
00:00:11,759 --> 00:00:13,280
and my colleague

7
00:00:13,280 --> 00:00:15,040
sam wagstaff who helped with that and i

8
00:00:15,040 --> 00:00:17,760
now see sam is here so sam

9
00:00:17,760 --> 00:00:19,920
identify yourself

10
00:00:19,920 --> 00:00:22,080
right there okay so

11
00:00:22,080 --> 00:00:23,439
sam is er

12
00:00:23,439 --> 00:00:25,920
was here on the faculty before i arrived

13
00:00:25,920 --> 00:00:29,279
and was one of my co-conspirators in the

14
00:00:29,279 --> 00:00:32,399
early days of coast and security so

15
00:00:32,399 --> 00:00:34,320
thank you for

16
00:00:34,320 --> 00:00:37,440
finding your way here today sam

17
00:00:37,440 --> 00:00:40,480
okay we have a panel session

18
00:00:40,480 --> 00:00:43,360
a fireside chat

19
00:00:43,360 --> 00:00:45,200
with three distinguished individuals

20
00:00:45,200 --> 00:00:46,719
here

21
00:00:46,719 --> 00:00:49,360
and i'm not going to go spend time

22
00:00:49,360 --> 00:00:52,399
introducing them they have bios in the

23
00:00:52,399 --> 00:00:54,800
uh program that you can look at

24
00:00:54,800 --> 00:00:56,320
we'll

25
00:00:56,320 --> 00:00:58,480
go through a moment let them

26
00:00:58,480 --> 00:01:00,160
state who they are so you can match them

27
00:01:00,160 --> 00:01:01,760
up with the bios

28
00:01:01,760 --> 00:01:03,440
but then we're going to launch into some

29
00:01:03,440 --> 00:01:04,720
questions

30
00:01:04,720 --> 00:01:07,519
and if

31
00:01:08,400 --> 00:01:10,560
after the first question or two if any

32
00:01:10,560 --> 00:01:12,240
of you have some you'd like to pose to

33
00:01:12,240 --> 00:01:13,360
the panel

34
00:01:13,360 --> 00:01:15,920
please queue up at the microphone and

35
00:01:15,920 --> 00:01:18,720
we'll take your questions as jumping off

36
00:01:18,720 --> 00:01:21,040
points for some of our discussion

37
00:01:21,040 --> 00:01:23,280
so gentlemen if you would

38
00:01:23,280 --> 00:01:24,479
zach we'll start with you if you just

39
00:01:24,479 --> 00:01:26,080
say a couple words about who you are

40
00:01:26,080 --> 00:01:28,560
sure i'm zac tudor i'm the associate lab

41
00:01:28,560 --> 00:01:30,079
director for national and homeland

42
00:01:30,079 --> 00:01:32,159
security science and technology uh at

43
00:01:32,159 --> 00:01:34,560
the idaho national lab i only add the uh

44
00:01:34,560 --> 00:01:36,320
the science technology when i'm in

45
00:01:36,320 --> 00:01:38,799
academic settings normally they just say

46
00:01:38,799 --> 00:01:40,960
national homeland security because uh we

47
00:01:40,960 --> 00:01:43,680
are at inl the uh the nation's nuclear

48
00:01:43,680 --> 00:01:46,240
energy lab uh we are an engineering lab

49
00:01:46,240 --> 00:01:48,000
um you know primarily but of course you

50
00:01:48,000 --> 00:01:49,520
know we we take all phases of the

51
00:01:49,520 --> 00:01:51,920
science and there we've primarily known

52
00:01:51,920 --> 00:01:53,759
at least in my group for being the

53
00:01:53,759 --> 00:01:55,280
industrial control security kind of

54
00:01:55,280 --> 00:01:56,640
center of excellence

55
00:01:56,640 --> 00:01:59,360
both here and in the us and and kind of

56
00:01:59,360 --> 00:02:01,600
abroad as well so um some of the things

57
00:02:01,600 --> 00:02:03,119
that david was talking about earlier i'm

58
00:02:03,119 --> 00:02:05,119
thinking okay how can i apply that to uh

59
00:02:05,119 --> 00:02:07,759
to the physics on the shop floor or or

60
00:02:07,759 --> 00:02:11,920
for for energy systems etc um so i'm a

61
00:02:11,920 --> 00:02:14,400
prior submariner as will uh we have a 50

62
00:02:14,400 --> 00:02:17,040
submarine panel up here as well um you

63
00:02:17,040 --> 00:02:18,720
know officer enlisted so he can talk

64
00:02:18,720 --> 00:02:19,680
about all of

65
00:02:19,680 --> 00:02:21,520
the fine wonderful times and great food

66
00:02:21,520 --> 00:02:22,959
he had and i can talk about the hard

67
00:02:22,959 --> 00:02:25,200
work

68
00:02:25,440 --> 00:02:26,160
so

69
00:02:26,160 --> 00:02:28,640
with that i think that's almost enough

70
00:02:28,640 --> 00:02:31,360
and you look familiar

71
00:02:31,360 --> 00:02:33,920
yeah i'm david mcgrew and i think you

72
00:02:33,920 --> 00:02:36,800
heard enough already about me

73
00:02:36,800 --> 00:02:39,120
tommy gardner first i'd like to thank

74
00:02:39,120 --> 00:02:41,599
david for your talk that was very well

75
00:02:41,599 --> 00:02:43,120
uh presented

76
00:02:43,120 --> 00:02:44,640
much more organized than i'm going to be

77
00:02:44,640 --> 00:02:47,760
tomorrow so you set a standard that

78
00:02:47,760 --> 00:02:49,360
and and zach thanks for your work in the

79
00:02:49,360 --> 00:02:51,120
submarine force because you're right the

80
00:02:51,120 --> 00:02:52,480
officers are told to keep your hands in

81
00:02:52,480 --> 00:02:53,920
your pocket you don't know what you're

82
00:02:53,920 --> 00:02:55,920
doing leave it to the people who know

83
00:02:55,920 --> 00:02:58,159
what they're doing to make the ship work

84
00:02:58,159 --> 00:02:59,200
but uh

85
00:02:59,200 --> 00:03:02,560
it's nice to have a fellow bubble head

86
00:03:02,560 --> 00:03:04,000
on the panel

87
00:03:04,000 --> 00:03:05,200
my job in

88
00:03:05,200 --> 00:03:07,040
daytime is

89
00:03:07,040 --> 00:03:10,480
is the cto for hp federal and that's the

90
00:03:10,480 --> 00:03:12,879
federal division of hp incorporated so

91
00:03:12,879 --> 00:03:16,400
we do the print the pcs the laptops

92
00:03:16,400 --> 00:03:19,120
workstations and the 3d print for

93
00:03:19,120 --> 00:03:21,200
industrial security we're very

94
00:03:21,200 --> 00:03:22,959
concerned about the security of our 3d

95
00:03:22,959 --> 00:03:23,920
printers

96
00:03:23,920 --> 00:03:26,799
we're into microfluidics and some of the

97
00:03:26,799 --> 00:03:29,760
testing of medical devices is new

98
00:03:29,760 --> 00:03:32,239
i'm focused primarily my research area

99
00:03:32,239 --> 00:03:34,480
is the quantum internet and a new

100
00:03:34,480 --> 00:03:36,480
generation internet that's just now

101
00:03:36,480 --> 00:03:38,319
available from new techniques coming out

102
00:03:38,319 --> 00:03:40,480
of the quantum world

103
00:03:40,480 --> 00:03:41,440
my

104
00:03:41,440 --> 00:03:43,280
nighttime job i teach at catholic

105
00:03:43,280 --> 00:03:44,959
university so i've got a

106
00:03:44,959 --> 00:03:47,040
foot in the door in academia as an

107
00:03:47,040 --> 00:03:49,280
adjunct teaching

108
00:03:49,280 --> 00:03:52,080
cyber security software programming and

109
00:03:52,080 --> 00:03:54,480
this semester the digital supply chain

110
00:03:54,480 --> 00:03:57,040
so interesting subject i'm learning more

111
00:03:57,040 --> 00:03:58,799
than the students are but that's part of

112
00:03:58,799 --> 00:04:01,680
being a professional that's right

113
00:04:01,680 --> 00:04:03,760
uh and for those of you who didn't guess

114
00:04:03,760 --> 00:04:07,519
i'm gene spafford and i do many things

115
00:04:07,519 --> 00:04:09,360
uh including

116
00:04:09,360 --> 00:04:11,519
moderating this wonderful

117
00:04:11,519 --> 00:04:12,959
group here

118
00:04:12,959 --> 00:04:15,519
and i'm going to start off with

119
00:04:15,519 --> 00:04:17,358
a question

120
00:04:17,358 --> 00:04:19,600
to hear your responses because you come

121
00:04:19,600 --> 00:04:23,120
from a variety of different perspectives

122
00:04:23,120 --> 00:04:26,639
what's really been in the news a lot

123
00:04:26,639 --> 00:04:28,880
deservedly so over the the last four or

124
00:04:28,880 --> 00:04:31,759
five weeks has been the um the russian

125
00:04:31,759 --> 00:04:34,160
incursion into ukraine

126
00:04:34,160 --> 00:04:35,680
and

127
00:04:35,680 --> 00:04:38,000
many many stories there and many

128
00:04:38,000 --> 00:04:39,919
unfortunate stories

129
00:04:39,919 --> 00:04:42,639
but uh one that sort of hits to our

130
00:04:42,639 --> 00:04:45,199
domain is in the area of of sort of

131
00:04:45,199 --> 00:04:47,360
cyber war

132
00:04:47,360 --> 00:04:48,240
that

133
00:04:48,240 --> 00:04:50,560
many were proclaiming was going to be an

134
00:04:50,560 --> 00:04:51,440
issue

135
00:04:51,440 --> 00:04:52,960
that the russians

136
00:04:52,960 --> 00:04:55,199
have been preparing this for some period

137
00:04:55,199 --> 00:04:57,280
of time they have a lot of expertise

138
00:04:57,280 --> 00:04:58,560
both within

139
00:04:58,560 --> 00:05:03,120
their uh the gru and the svr

140
00:05:03,120 --> 00:05:05,440
and fsb and the criminal groups that

141
00:05:05,440 --> 00:05:07,199
they control

142
00:05:07,199 --> 00:05:09,199
but we've been sort of surprised not to

143
00:05:09,199 --> 00:05:11,199
have seen much happen

144
00:05:11,199 --> 00:05:12,160
although

145
00:05:12,160 --> 00:05:14,560
sissa and others have been warning us

146
00:05:14,560 --> 00:05:18,479
that it's imminent it's coming it's big

147
00:05:18,479 --> 00:05:20,720
so i'm i'm interested in hearing from

148
00:05:20,720 --> 00:05:22,960
your perspectives why haven't we seen

149
00:05:22,960 --> 00:05:25,360
something and are we going to see

150
00:05:25,360 --> 00:05:26,320
something

151
00:05:26,320 --> 00:05:27,199
so

152
00:05:27,199 --> 00:05:29,199
i'll start with this and zach probably

153
00:05:29,199 --> 00:05:31,120
knows a lot more about the details i'm

154
00:05:31,120 --> 00:05:32,400
i'm guessing

155
00:05:32,400 --> 00:05:33,680
i don't have any of the inside

156
00:05:33,680 --> 00:05:36,160
intelligence uh when you go to hp they

157
00:05:36,160 --> 00:05:39,440
take away your clearances

158
00:05:39,440 --> 00:05:41,120
but when i was a young lieutenant

159
00:05:41,120 --> 00:05:43,520
commander in the pentagon i was assigned

160
00:05:43,520 --> 00:05:45,199
to go through all the

161
00:05:45,199 --> 00:05:48,080
top secret special category special

162
00:05:48,080 --> 00:05:49,280
programs

163
00:05:49,280 --> 00:05:51,039
and determine which ones we needed to

164
00:05:51,039 --> 00:05:52,639
keep special which ones we didn't and

165
00:05:52,639 --> 00:05:54,639
there's about a 20 percent

166
00:05:54,639 --> 00:05:56,479
up charge for any program if you're

167
00:05:56,479 --> 00:05:58,319
going to keep it under wraps

168
00:05:58,319 --> 00:05:59,919
and it's not that the russians don't

169
00:05:59,919 --> 00:06:01,600
have capability we know they have

170
00:06:01,600 --> 00:06:04,800
capability there's no doubt about that

171
00:06:04,800 --> 00:06:06,160
you have to choose when are you going to

172
00:06:06,160 --> 00:06:07,440
use it

173
00:06:07,440 --> 00:06:09,680
and uh we used a lot of our special

174
00:06:09,680 --> 00:06:12,240
capability and desert storm you know

175
00:06:12,240 --> 00:06:13,840
things that have been in wraps in

176
00:06:13,840 --> 00:06:15,120
holdback

177
00:06:15,120 --> 00:06:17,199
because once you use it and people know

178
00:06:17,199 --> 00:06:19,120
what you've got and they're able to make

179
00:06:19,120 --> 00:06:20,800
counters against it

180
00:06:20,800 --> 00:06:22,639
i think that's what's happening now i

181
00:06:22,639 --> 00:06:24,560
think the russians think we've got

182
00:06:24,560 --> 00:06:26,560
control of the situation whether they do

183
00:06:26,560 --> 00:06:27,680
or not

184
00:06:27,680 --> 00:06:28,560
and

185
00:06:28,560 --> 00:06:30,400
i think they're saying we don't want to

186
00:06:30,400 --> 00:06:32,000
let the world know

187
00:06:32,000 --> 00:06:34,800
what tricks we have up our sleeves

188
00:06:34,800 --> 00:06:36,720
and so they're holding back

189
00:06:36,720 --> 00:06:39,600
uh if they get to a desperate position

190
00:06:39,600 --> 00:06:42,000
where all of a sudden the tide's turning

191
00:06:42,000 --> 00:06:44,319
and there's 100 scenarios that could

192
00:06:44,319 --> 00:06:46,560
create that

193
00:06:46,560 --> 00:06:49,360
that's when you likely see them pull the

194
00:06:49,360 --> 00:06:50,880
you know pulled open the bag and

195
00:06:50,880 --> 00:06:54,400
pandora's box begin to open

196
00:06:54,479 --> 00:06:56,479
yeah i'll i'll go and unfortunately i'm

197
00:06:56,479 --> 00:06:57,840
on the road so much i don't get to you

198
00:06:57,840 --> 00:07:00,160
know read most of the intel so uh so i'm

199
00:07:00,160 --> 00:07:02,000
kind of in the same boat as you are but

200
00:07:02,000 --> 00:07:03,599
you know on one level i'm thinking that

201
00:07:03,599 --> 00:07:05,520
perhaps russia doesn't want to open up a

202
00:07:05,520 --> 00:07:07,680
second front yeah um and that's what

203
00:07:07,680 --> 00:07:09,599
cyber would be now if we uh talk about

204
00:07:09,599 --> 00:07:11,520
that so i think that we were all

205
00:07:11,520 --> 00:07:13,919
expecting as spot said

206
00:07:13,919 --> 00:07:15,440
lots of different

207
00:07:15,440 --> 00:07:17,280
things whether it would be

208
00:07:17,280 --> 00:07:19,360
some some different kind of uh attacks

209
00:07:19,360 --> 00:07:21,199
and not even you know novel attacks

210
00:07:21,199 --> 00:07:23,199
against the us to keep us busy you know

211
00:07:23,199 --> 00:07:25,360
while they're doing things in ukraine or

212
00:07:25,360 --> 00:07:26,960
i mean we've seen some minor things

213
00:07:26,960 --> 00:07:29,120
happen in ukraine and without a lot of

214
00:07:29,120 --> 00:07:31,039
attribution yet but but i think that um

215
00:07:31,039 --> 00:07:33,199
that would be seen by the us and and the

216
00:07:33,199 --> 00:07:35,120
nato allies and and

217
00:07:35,120 --> 00:07:37,120
and the european union as an escalation

218
00:07:37,120 --> 00:07:39,280
of a different kind and it would you

219
00:07:39,280 --> 00:07:40,880
know give them you know some different

220
00:07:40,880 --> 00:07:42,160
things to have to worry about i think

221
00:07:42,160 --> 00:07:43,840
they're trying to save that for uh for a

222
00:07:43,840 --> 00:07:45,919
rainy day i have no doubt that cybercom

223
00:07:45,919 --> 00:07:47,440
is ready to respond

224
00:07:47,440 --> 00:07:49,280
it's just they're waiting for the right

225
00:07:49,280 --> 00:07:51,919
indicator of compromise or the the right

226
00:07:51,919 --> 00:07:54,720
uh uh trigger that says you've crossed

227
00:07:54,720 --> 00:07:57,039
the line yeah i know when i first got

228
00:07:57,039 --> 00:08:00,560
into this job uh in about 2016 um a lot

229
00:08:00,560 --> 00:08:02,240
of my folks had just been getting back

230
00:08:02,240 --> 00:08:04,879
from ukraine after the 2015 attack and

231
00:08:04,879 --> 00:08:07,120
then the uh the 2016 attack and i was

232
00:08:07,120 --> 00:08:08,400
saying you know gee i didn't have to do

233
00:08:08,400 --> 00:08:10,000
a lot of my own business development you

234
00:08:10,000 --> 00:08:11,520
know because you know back at that time

235
00:08:11,520 --> 00:08:12,879
you know there was an adversary that

236
00:08:12,879 --> 00:08:14,160
wasn't named was doing it i said i'm

237
00:08:14,160 --> 00:08:15,840
gonna send him a fruit basket or

238
00:08:15,840 --> 00:08:19,520
something um so uh um but um you know

239
00:08:19,520 --> 00:08:21,039
for for many years you know all of us

240
00:08:21,039 --> 00:08:22,560
here had to convince you know people

241
00:08:22,560 --> 00:08:24,000
either in government or industry or

242
00:08:24,000 --> 00:08:26,319
others um that cyber threat was real

243
00:08:26,319 --> 00:08:27,919
right and that it was worth investing in

244
00:08:27,919 --> 00:08:29,680
you know that discussion is finally over

245
00:08:29,680 --> 00:08:31,759
i think so that's that's the only good

246
00:08:31,759 --> 00:08:32,958
news

247
00:08:32,958 --> 00:08:34,000
um

248
00:08:34,000 --> 00:08:35,360
do you have anything to add to this

249
00:08:35,360 --> 00:08:36,640
david

250
00:08:36,640 --> 00:08:38,880
um you know i i agree with what's been

251
00:08:38,880 --> 00:08:41,360
said right um

252
00:08:41,360 --> 00:08:43,440
there we might find out that something

253
00:08:43,440 --> 00:08:45,519
is we might find out about russian cyber

254
00:08:45,519 --> 00:08:47,040
activity after

255
00:08:47,040 --> 00:08:49,519
you know in due time right the the thing

256
00:08:49,519 --> 00:08:52,160
that stands out in my mind is the uh

257
00:08:52,160 --> 00:08:55,600
you know during crimea there were

258
00:08:55,600 --> 00:08:56,959
there was uh

259
00:08:56,959 --> 00:09:00,080
malware that had infected um

260
00:09:00,080 --> 00:09:02,959
smartphones of uh ukrainian

261
00:09:02,959 --> 00:09:04,959
um artillerymen

262
00:09:04,959 --> 00:09:06,320
and they had they were all using a

263
00:09:06,320 --> 00:09:09,120
particular app because if i forget what

264
00:09:09,120 --> 00:09:10,399
it did right but there was some app they

265
00:09:10,399 --> 00:09:12,080
were all using and somebody figured that

266
00:09:12,080 --> 00:09:14,399
out and was able to target them that way

267
00:09:14,399 --> 00:09:16,320
and and that didn't come out for a month

268
00:09:16,320 --> 00:09:18,399
or at least after it came out after the

269
00:09:18,399 --> 00:09:20,640
fact right so they're they're

270
00:09:20,640 --> 00:09:23,680
i think the main point is that you know

271
00:09:23,680 --> 00:09:25,279
you know not all the cards are on the

272
00:09:25,279 --> 00:09:26,720
table yet

273
00:09:26,720 --> 00:09:28,560
but we we might find out something in

274
00:09:28,560 --> 00:09:29,360
time

275
00:09:29,360 --> 00:09:32,160
well i think uh one of the interesting

276
00:09:32,160 --> 00:09:34,080
uh possible outcomes of this you were

277
00:09:34,080 --> 00:09:36,560
saying finally everybody's aware well

278
00:09:36,560 --> 00:09:40,480
it seems to me very similar to

279
00:09:40,480 --> 00:09:44,000
well going back certainly to the y2k

280
00:09:44,000 --> 00:09:47,120
is you have a lot of warnings disaster

281
00:09:47,120 --> 00:09:48,160
is coming

282
00:09:48,160 --> 00:09:50,399
and then nothing happens and everybody

283
00:09:50,399 --> 00:09:52,480
goes well why do we get excited about

284
00:09:52,480 --> 00:09:54,480
that why should we be investing when

285
00:09:54,480 --> 00:09:57,519
nothing happens and we're warned

286
00:09:57,519 --> 00:09:59,440
that's a natural consequence certainly

287
00:09:59,440 --> 00:10:00,320
for

288
00:10:00,320 --> 00:10:02,800
those who control the budgets

289
00:10:02,800 --> 00:10:04,560
it's not a good consequence but it's a

290
00:10:04,560 --> 00:10:06,000
natural one

291
00:10:06,000 --> 00:10:08,079
so if nothing does happen

292
00:10:08,079 --> 00:10:10,399
because they're holding back

293
00:10:10,399 --> 00:10:12,160
how do we keep

294
00:10:12,160 --> 00:10:13,920
the pressure up

295
00:10:13,920 --> 00:10:16,160
in government and industry for people to

296
00:10:16,160 --> 00:10:18,000
be aware and actually put the controls

297
00:10:18,000 --> 00:10:19,680
in place

298
00:10:19,680 --> 00:10:21,120
this administration is doing a really

299
00:10:21,120 --> 00:10:23,760
good job of putting cyber security up in

300
00:10:23,760 --> 00:10:24,959
the forefront

301
00:10:24,959 --> 00:10:28,000
and the may 12th executive order i

302
00:10:28,000 --> 00:10:29,760
never can't remember the number but it's

303
00:10:29,760 --> 00:10:34,160
a 47012 or something like that uh really

304
00:10:34,160 --> 00:10:37,839
spun a lot of action and you know with

305
00:10:37,839 --> 00:10:39,839
agencies responsible for the action and

306
00:10:39,839 --> 00:10:42,160
deadlines there's a 90-day deadline

307
00:10:42,160 --> 00:10:44,800
100-day deadline a six-month a one-year

308
00:10:44,800 --> 00:10:46,640
and and we're coming up on you know

309
00:10:46,640 --> 00:10:47,440
these

310
00:10:47,440 --> 00:10:49,040
six month period

311
00:10:49,040 --> 00:10:51,839
uh it's a uh

312
00:10:51,839 --> 00:10:53,839
it's it's kind of interesting how that

313
00:10:53,839 --> 00:10:55,920
uh a lot of the work that's gone on

314
00:10:55,920 --> 00:10:58,240
realized that hey we we've talked about

315
00:10:58,240 --> 00:11:01,200
this now is the time to take action and

316
00:11:01,200 --> 00:11:02,720
do something about it

317
00:11:02,720 --> 00:11:04,880
i don't think we're going to see any

318
00:11:04,880 --> 00:11:08,160
lessening of cyber importance

319
00:11:08,160 --> 00:11:10,320
primarily because of ransomware

320
00:11:10,320 --> 00:11:12,640
those attacks have been primarily at

321
00:11:12,640 --> 00:11:14,800
vulnerable locations hospitals schools

322
00:11:14,800 --> 00:11:17,200
municipalities

323
00:11:17,200 --> 00:11:18,959
i think you're going to see a broadening

324
00:11:18,959 --> 00:11:20,560
of those attacks

325
00:11:20,560 --> 00:11:23,120
if we don't work on collective defense

326
00:11:23,120 --> 00:11:25,120
and identification

327
00:11:25,120 --> 00:11:27,600
of who's doing what to who

328
00:11:27,600 --> 00:11:30,959
better and there's ways to do that

329
00:11:30,959 --> 00:11:32,480
but if that's

330
00:11:32,480 --> 00:11:34,560
not stopped then everybody's going to

331
00:11:34,560 --> 00:11:36,160
feel threatened and it's what you don't

332
00:11:36,160 --> 00:11:36,880
know

333
00:11:36,880 --> 00:11:38,640
that creates action it's all the things

334
00:11:38,640 --> 00:11:41,040
that you you fear but don't have any

335
00:11:41,040 --> 00:11:43,680
idea how to analyze this puts that risk

336
00:11:43,680 --> 00:11:46,720
equation in an imbalance well that ties

337
00:11:46,720 --> 00:11:48,079
right in with what david was talking

338
00:11:48,079 --> 00:11:50,480
about in in his remarks earlier

339
00:11:50,480 --> 00:11:53,279
uh is having that visibility

340
00:11:53,279 --> 00:11:55,439
well

341
00:11:57,360 --> 00:11:59,279
um you know both the ransomware and

342
00:11:59,279 --> 00:12:00,880
others but um you know so russia's not

343
00:12:00,880 --> 00:12:03,200
the only adversary in the digital domain

344
00:12:03,200 --> 00:12:04,720
um and i think that a lot of things that

345
00:12:04,720 --> 00:12:06,160
are happening around the world um you

346
00:12:06,160 --> 00:12:07,760
know you know increased competition with

347
00:12:07,760 --> 00:12:10,000
china um you know there's still you know

348
00:12:10,000 --> 00:12:11,920
terrorist threats in various places that

349
00:12:11,920 --> 00:12:14,240
are manifesting themselves in cyber as

350
00:12:14,240 --> 00:12:16,240
well um you know once again i think that

351
00:12:16,240 --> 00:12:18,320
at least the the guys that hold the

352
00:12:18,320 --> 00:12:20,720
purse strings um you know are aware of

353
00:12:20,720 --> 00:12:23,440
what's going on and as we are changing

354
00:12:23,440 --> 00:12:25,680
um whether we want to onshore or front

355
00:12:25,680 --> 00:12:28,079
shore manufacturing looking at supply

356
00:12:28,079 --> 00:12:29,760
chains there are a lot of things in our

357
00:12:29,760 --> 00:12:31,279
domain that are that are not going to go

358
00:12:31,279 --> 00:12:33,600
away you know if there's no you know big

359
00:12:33,600 --> 00:12:35,680
cyber event as a result of this and

360
00:12:35,680 --> 00:12:37,040
which i'm really kind of hoping for it

361
00:12:37,040 --> 00:12:39,440
right zach you mentioned purse strings

362
00:12:39,440 --> 00:12:41,839
uh i think that's really the key you

363
00:12:41,839 --> 00:12:43,519
know there there's intelligence

364
00:12:43,519 --> 00:12:45,040
community that are

365
00:12:45,040 --> 00:12:47,360
looking into things because that's what

366
00:12:47,360 --> 00:12:48,880
they get paid to do

367
00:12:48,880 --> 00:12:51,120
find find out things know things that

368
00:12:51,120 --> 00:12:53,360
other people don't know or things that

369
00:12:53,360 --> 00:12:55,360
other countries think are unknowable or

370
00:12:55,360 --> 00:12:57,200
we've protected that's what they get

371
00:12:57,200 --> 00:12:59,040
paid to do but there's a criminal

372
00:12:59,040 --> 00:13:01,600
activity and that gets to the ransomware

373
00:13:01,600 --> 00:13:03,440
they're in it for the money

374
00:13:03,440 --> 00:13:05,600
most of them yeah most of them some are

375
00:13:05,600 --> 00:13:07,680
paid by state actors and so that gets in

376
00:13:07,680 --> 00:13:10,160
the intelligence world or uh and the

377
00:13:10,160 --> 00:13:12,240
economic issues of intellectual property

378
00:13:12,240 --> 00:13:14,959
theft is always out there uh when i was

379
00:13:14,959 --> 00:13:17,600
a senior at the naval academy we have

380
00:13:17,600 --> 00:13:19,760
what's called a forestall lecture where

381
00:13:19,760 --> 00:13:22,079
they bring in luminaries to kind of

382
00:13:22,079 --> 00:13:24,480
teach us what the world's about and you

383
00:13:24,480 --> 00:13:27,040
know make us think a little bit and i

384
00:13:27,040 --> 00:13:28,800
remember my senior year they brought in

385
00:13:28,800 --> 00:13:30,880
a science fiction writer

386
00:13:30,880 --> 00:13:32,639
named robert heinlein

387
00:13:32,639 --> 00:13:33,519
now

388
00:13:33,519 --> 00:13:34,800
some of you may have actually read

389
00:13:34,800 --> 00:13:38,399
jaime's books uh a famous writer i read

390
00:13:38,399 --> 00:13:39,920
every book he'd had when i was a

391
00:13:39,920 --> 00:13:43,279
teenager and so to see him 22 years old

392
00:13:43,279 --> 00:13:44,959
at the naval academy was like you know

393
00:13:44,959 --> 00:13:47,279
just i was excited to go usually you

394
00:13:47,279 --> 00:13:49,360
sleep through these lectures i'm excited

395
00:13:49,360 --> 00:13:50,720
to be there

396
00:13:50,720 --> 00:13:53,920
and uh the last book heinlein wrote in

397
00:13:53,920 --> 00:13:54,959
highland was there because he was a

398
00:13:54,959 --> 00:13:56,639
naval academy graduate you know where

399
00:13:56,639 --> 00:13:58,320
else would you expected him to go to

400
00:13:58,320 --> 00:13:59,440
school but

401
00:13:59,440 --> 00:14:00,880
you know he's dreaming these far out

402
00:14:00,880 --> 00:14:02,320
things because that's what you do with

403
00:14:02,320 --> 00:14:03,760
the academy you just

404
00:14:03,760 --> 00:14:06,800
you just try to think of the future

405
00:14:06,800 --> 00:14:08,639
he wrote the book the moon is a strange

406
00:14:08,639 --> 00:14:09,760
mistress

407
00:14:09,760 --> 00:14:11,199
last book he wrote

408
00:14:11,199 --> 00:14:12,959
and in that book he talked about a

409
00:14:12,959 --> 00:14:15,040
dialogue between a mother and a

410
00:14:15,040 --> 00:14:16,639
five-year-old son

411
00:14:16,639 --> 00:14:19,120
now if any of you have had five-year-old

412
00:14:19,120 --> 00:14:21,279
children you know how they

413
00:14:21,279 --> 00:14:23,120
they tend to be inquisitive

414
00:14:23,120 --> 00:14:23,920
and

415
00:14:23,920 --> 00:14:26,160
the the boy was asking his mom

416
00:14:26,160 --> 00:14:28,399
every time she asked gave an answer he

417
00:14:28,399 --> 00:14:30,959
would say well why he said well this is

418
00:14:30,959 --> 00:14:32,880
why it happened and this is why we're

419
00:14:32,880 --> 00:14:33,600
doing

420
00:14:33,600 --> 00:14:36,160
well why is that and and you know the

421
00:14:36,160 --> 00:14:38,480
routine after 15 wides you get tired of

422
00:14:38,480 --> 00:14:40,959
answering and the the response is just

423
00:14:40,959 --> 00:14:42,240
because

424
00:14:42,240 --> 00:14:44,800
and so she's going like that and uh the

425
00:14:44,800 --> 00:14:46,720
way heinlein describes this dialogue

426
00:14:46,720 --> 00:14:48,160
which is common to most people with

427
00:14:48,160 --> 00:14:50,800
children is that finally the mother got

428
00:14:50,800 --> 00:14:52,880
exasperated and said johnny

429
00:14:52,880 --> 00:14:55,199
if you want to know the answer why to

430
00:14:55,199 --> 00:14:56,560
any question

431
00:14:56,560 --> 00:14:59,040
the answer is always money

432
00:14:59,040 --> 00:15:00,639
and you start to think about it and

433
00:15:00,639 --> 00:15:02,959
somehow you can go down enough questions

434
00:15:02,959 --> 00:15:04,240
and you'll get to where the purse

435
00:15:04,240 --> 00:15:06,720
strings matter

436
00:15:06,720 --> 00:15:10,480
i thank zach no problem yeah

437
00:15:10,480 --> 00:15:12,320
well i think it's interesting that there

438
00:15:12,320 --> 00:15:13,839
have been

439
00:15:13,839 --> 00:15:16,800
some major operations that have leaked

440
00:15:16,800 --> 00:15:19,279
over into the private sphere so just

441
00:15:19,279 --> 00:15:20,560
prior to the invasion there was an

442
00:15:20,560 --> 00:15:22,800
attack against satellite communications

443
00:15:22,800 --> 00:15:25,839
that leaked out into europe and

444
00:15:25,839 --> 00:15:28,160
partly to north america that permanently

445
00:15:28,160 --> 00:15:30,560
apparently bricked satellite receivers

446
00:15:30,560 --> 00:15:33,519
that are in use in things like

447
00:15:33,519 --> 00:15:36,160
windmills for solar generation and some

448
00:15:36,160 --> 00:15:38,720
positioning and a few years earlier

449
00:15:38,720 --> 00:15:42,079
attack against ukraine the not petcha

450
00:15:42,079 --> 00:15:43,519
malware that

451
00:15:43,519 --> 00:15:46,079
uh again went out in damaged systems in

452
00:15:46,079 --> 00:15:47,920
a number of places

453
00:15:47,920 --> 00:15:49,279
so it's

454
00:15:49,279 --> 00:15:50,880
non-combatants definitely have to worry

455
00:15:50,880 --> 00:15:52,560
about this it's a question of how do we

456
00:15:52,560 --> 00:15:53,600
how do we

457
00:15:53,600 --> 00:15:55,920
get them to realize this

458
00:15:55,920 --> 00:15:57,600
and you mentioned the executive order

459
00:15:57,600 --> 00:15:58,800
are there other things that we can be

460
00:15:58,800 --> 00:16:02,000
doing to get the community at large to

461
00:16:02,000 --> 00:16:03,920
understand that even if they're not

462
00:16:03,920 --> 00:16:05,920
directly in the crosshairs

463
00:16:05,920 --> 00:16:07,920
they have the potential for significant

464
00:16:07,920 --> 00:16:10,880
losses well you mentioned the uh not

465
00:16:10,880 --> 00:16:13,120
petcha and and it gets to the law of

466
00:16:13,120 --> 00:16:15,360
unintended consequences that was never

467
00:16:15,360 --> 00:16:17,279
intended to get out and damage all the

468
00:16:17,279 --> 00:16:19,360
companies that it was that wasn't why it

469
00:16:19,360 --> 00:16:21,279
was written but nobody thought to that

470
00:16:21,279 --> 00:16:23,680
second and third order effects or what

471
00:16:23,680 --> 00:16:25,519
uh you could call in a military sense

472
00:16:25,519 --> 00:16:27,120
collateral damage

473
00:16:27,120 --> 00:16:29,519
and and i think that's where you have to

474
00:16:29,519 --> 00:16:30,720
look through

475
00:16:30,720 --> 00:16:33,120
if we're going to use offensive cyber

476
00:16:33,120 --> 00:16:36,160
and we have capability uh ash carter was

477
00:16:36,160 --> 00:16:38,000
a secretary of defense and first brought

478
00:16:38,000 --> 00:16:39,680
that out in the open

479
00:16:39,680 --> 00:16:42,079
we have capability and i suspect it's

480
00:16:42,079 --> 00:16:43,920
better than anywhere else in the world

481
00:16:43,920 --> 00:16:46,160
have we chosen to use it in limited

482
00:16:46,160 --> 00:16:48,639
cases limited ability but we've got to

483
00:16:48,639 --> 00:16:51,440
know what's the unintended consequences

484
00:16:51,440 --> 00:16:53,519
what's what is going to happen if it's

485
00:16:53,519 --> 00:16:54,560
released

486
00:16:54,560 --> 00:16:56,000
what else is it going to do and that's

487
00:16:56,000 --> 00:16:57,920
what i'm concerned about is have we

488
00:16:57,920 --> 00:17:00,399
really thought through this or have we

489
00:17:00,399 --> 00:17:02,079
taken tests

490
00:17:02,079 --> 00:17:03,279
of

491
00:17:03,279 --> 00:17:05,199
tools we're going to use if the right

492
00:17:05,199 --> 00:17:07,839
circumstances exist and make sure they

493
00:17:07,839 --> 00:17:09,760
don't get out of control

494
00:17:09,760 --> 00:17:11,919
well we had that leak of the cia toolkit

495
00:17:11,919 --> 00:17:15,520
that's been widely mr blue

496
00:17:15,520 --> 00:17:17,599
mr snowden did a good job of handing

497
00:17:17,599 --> 00:17:19,439
over the keys to the kingdom yeah that

498
00:17:19,439 --> 00:17:23,520
one was not clearly him but nonetheless

499
00:17:23,520 --> 00:17:25,439
so but one thing is though when you talk

500
00:17:25,439 --> 00:17:27,760
about unintended uh consequence or or

501
00:17:27,760 --> 00:17:29,840
just the unexpected success you know

502
00:17:29,840 --> 00:17:31,919
take the colonial pipeline attack it was

503
00:17:31,919 --> 00:17:34,480
an attack against i.t systems

504
00:17:34,480 --> 00:17:35,919
that ended up

505
00:17:35,919 --> 00:17:37,679
bleeding over into the operations of a

506
00:17:37,679 --> 00:17:40,240
pipeline because of the reliance no one

507
00:17:40,240 --> 00:17:42,240
really knew that they were that reliant

508
00:17:42,240 --> 00:17:43,280
on i.t

509
00:17:43,280 --> 00:17:45,280
um and the thing was it's like well

510
00:17:45,280 --> 00:17:46,480
there's nothing wrong with the eot

511
00:17:46,480 --> 00:17:48,880
system um but we're not sure so let's

512
00:17:48,880 --> 00:17:50,799
shut it down just to make sure nothing's

513
00:17:50,799 --> 00:17:52,799
bad right and so now we provide a denial

514
00:17:52,799 --> 00:17:54,240
of service attack as a preventive

515
00:17:54,240 --> 00:17:57,039
measure um based on an attack on you

516
00:17:57,039 --> 00:17:59,440
know you know i.t systems for billing

517
00:17:59,440 --> 00:18:01,039
and once you get back to the money you

518
00:18:01,039 --> 00:18:02,160
know they you know they they could have

519
00:18:02,160 --> 00:18:03,760
kept the the products flowing but they

520
00:18:03,760 --> 00:18:05,440
they wouldn't know who to charge so they

521
00:18:05,440 --> 00:18:06,799
stopped yeah well they charged me an

522
00:18:06,799 --> 00:18:08,240
hour and a half to fill up my tank of

523
00:18:08,240 --> 00:18:11,360
gas up to the northeast

524
00:18:11,360 --> 00:18:12,320
so

525
00:18:12,320 --> 00:18:13,520
you know

526
00:18:13,520 --> 00:18:15,360
you asked you know

527
00:18:15,360 --> 00:18:16,640
what should we be doing to raise

528
00:18:16,640 --> 00:18:18,559
awareness and it would be really nice if

529
00:18:18,559 --> 00:18:21,440
we could speak to successful defense

530
00:18:21,440 --> 00:18:22,480
and

531
00:18:22,480 --> 00:18:25,039
you know you i like the example of uh

532
00:18:25,039 --> 00:18:27,520
y2k right because you know i was one of

533
00:18:27,520 --> 00:18:29,520
the people involved in preparing for y2k

534
00:18:29,520 --> 00:18:33,600
probably a lot of us were right and um

535
00:18:34,000 --> 00:18:35,200
you know i it

536
00:18:35,200 --> 00:18:36,559
when people said oh there was no nothing

537
00:18:36,559 --> 00:18:38,400
burger right you know you know after

538
00:18:38,400 --> 00:18:39,919
that you know nothing really terrible

539
00:18:39,919 --> 00:18:41,760
happened right i felt you know it's

540
00:18:41,760 --> 00:18:43,360
election i was like wait a minute we saw

541
00:18:43,360 --> 00:18:45,039
the bridge might crumble and we shorted

542
00:18:45,039 --> 00:18:46,480
up and then it didn't fall down right

543
00:18:46,480 --> 00:18:48,080
that was a success

544
00:18:48,080 --> 00:18:49,919
and and being able to speak to shoring

545
00:18:49,919 --> 00:18:50,960
up right

546
00:18:50,960 --> 00:18:52,799
showing people the success story right

547
00:18:52,799 --> 00:18:55,280
this is a success story and i think

548
00:18:55,280 --> 00:18:56,559
we're seeing the same thing in the cyber

549
00:18:56,559 --> 00:18:58,240
domain right where it's like okay we're

550
00:18:58,240 --> 00:18:59,440
actually paying attention now we're

551
00:18:59,440 --> 00:19:01,520
doing a better job of defending things

552
00:19:01,520 --> 00:19:03,440
we weren't attacked or no attacks were

553
00:19:03,440 --> 00:19:05,760
successful that's that that should be

554
00:19:05,760 --> 00:19:07,760
described as a success and interpreted

555
00:19:07,760 --> 00:19:09,360
that way it's the same way you know say

556
00:19:09,360 --> 00:19:10,559
the secret service i mean the president

557
00:19:10,559 --> 00:19:12,080
hasn't been shot in 30 years so why are

558
00:19:12,080 --> 00:19:15,199
we spending all that money yeah

559
00:19:15,919 --> 00:19:18,400
well this is this is actually a very big

560
00:19:18,400 --> 00:19:20,400
problem uh to quantify

561
00:19:20,400 --> 00:19:22,640
so for instance spending premiums on

562
00:19:22,640 --> 00:19:25,520
insurance well we haven't had a fire in

563
00:19:25,520 --> 00:19:27,360
30 years so why are we spending so much

564
00:19:27,360 --> 00:19:28,559
for insurance when we're not going to

565
00:19:28,559 --> 00:19:29,840
have a fire

566
00:19:29,840 --> 00:19:30,960
is

567
00:19:30,960 --> 00:19:33,039
really a failure in

568
00:19:33,039 --> 00:19:34,160
thinking

569
00:19:34,160 --> 00:19:36,080
and we haven't really brought that into

570
00:19:36,080 --> 00:19:39,440
the cyber realm yet

571
00:19:39,440 --> 00:19:40,960
that's going to be an important aspect i

572
00:19:40,960 --> 00:19:43,840
think one of the things david brought up

573
00:19:43,840 --> 00:19:45,919
is is one that is beginning to drive

574
00:19:45,919 --> 00:19:48,160
more awareness which is privacy we want

575
00:19:48,160 --> 00:19:52,000
to have good security for better privacy

576
00:19:52,000 --> 00:19:53,360
but

577
00:19:53,360 --> 00:19:55,440
integrating that into an environment

578
00:19:55,440 --> 00:19:56,400
where

579
00:19:56,400 --> 00:19:59,280
violating privacy generates income for

580
00:19:59,280 --> 00:20:01,679
advertising

581
00:20:01,679 --> 00:20:03,360
is going to be a challenge at least in

582
00:20:03,360 --> 00:20:05,679
the us well you know it's it's uh you

583
00:20:05,679 --> 00:20:07,360
know we talk about you know once again

584
00:20:07,360 --> 00:20:09,760
30 40 years these systems have not been

585
00:20:09,760 --> 00:20:11,360
designed with security in mind so now

586
00:20:11,360 --> 00:20:12,960
we're designing it with security in mind

587
00:20:12,960 --> 00:20:14,960
and we're noticing the privacy impacts

588
00:20:14,960 --> 00:20:17,520
of the the systems that weren't designed

589
00:20:17,520 --> 00:20:19,679
for security or privacy now we have to

590
00:20:19,679 --> 00:20:21,760
start making some trade-offs um so you

591
00:20:21,760 --> 00:20:23,039
know some one of those it's uh you know

592
00:20:23,039 --> 00:20:25,520
if you are um unintentionally collecting

593
00:20:25,520 --> 00:20:26,799
you know personal identifiable

594
00:20:26,799 --> 00:20:29,440
information and then throwing it away um

595
00:20:29,440 --> 00:20:30,720
if you can really throw it away and

596
00:20:30,720 --> 00:20:32,320
that's that's the part right so so he

597
00:20:32,320 --> 00:20:33,440
said well i don't i don't trust that

598
00:20:33,440 --> 00:20:35,200
you're that you're not using it so now

599
00:20:35,200 --> 00:20:36,799
we can't collect it okay well if you

600
00:20:36,799 --> 00:20:38,559
don't collect it then we lose a lot of

601
00:20:38,559 --> 00:20:40,720
very exquisite security type data and

602
00:20:40,720 --> 00:20:42,080
you know so which would you you know

603
00:20:42,080 --> 00:20:44,000
rather be

604
00:20:44,000 --> 00:20:46,640
you know your privacy but uh

605
00:20:46,640 --> 00:20:48,400
insecure transactions that will lead

606
00:20:48,400 --> 00:20:51,039
back to your privacy again uh anyway so

607
00:20:51,039 --> 00:20:53,120
um once again it's an education not how

608
00:20:53,120 --> 00:20:55,919
do we um you know make sure that we can

609
00:20:55,919 --> 00:20:58,640
make those decisions um you know with

610
00:20:58,640 --> 00:21:01,600
the entire society you know

611
00:21:01,600 --> 00:21:03,280
adding some value to it as opposed to

612
00:21:03,280 --> 00:21:04,799
just you know technocrats like us

613
00:21:04,799 --> 00:21:06,400
deciding what's good for the rest of the

614
00:21:06,400 --> 00:21:08,640
community

615
00:21:08,640 --> 00:21:10,480
yeah i have a i have a goal i want to

616
00:21:10,480 --> 00:21:12,480
learn more about the tim berners-lee

617
00:21:12,480 --> 00:21:15,280
solid interrupt proposal

618
00:21:15,280 --> 00:21:18,320
as uh are you familiar with this

619
00:21:18,320 --> 00:21:19,840
you know tim berners-lee the guy that

620
00:21:19,840 --> 00:21:21,520
did you know the

621
00:21:21,520 --> 00:21:24,640
web standards a long time ago uh

622
00:21:24,640 --> 00:21:26,640
you know has a is working on like a next

623
00:21:26,640 --> 00:21:29,520
generation internet to

624
00:21:29,520 --> 00:21:32,000
the idea that your people own their own

625
00:21:32,000 --> 00:21:33,200
data and

626
00:21:33,200 --> 00:21:35,440
basically can provide access control to

627
00:21:35,440 --> 00:21:37,760
third parties on on their own data

628
00:21:37,760 --> 00:21:39,360
so that like uh

629
00:21:39,360 --> 00:21:40,640
you could have a government registered

630
00:21:40,640 --> 00:21:42,720
identity and then you populate your

631
00:21:42,720 --> 00:21:45,679
your your data and and then you allow

632
00:21:45,679 --> 00:21:47,679
third parties access to this data so you

633
00:21:47,679 --> 00:21:48,799
manage it

634
00:21:48,799 --> 00:21:50,960
and you control access to it and then

635
00:21:50,960 --> 00:21:52,559
i'm not sure how copying is dealt with

636
00:21:52,559 --> 00:21:54,080
right because it seems like you can make

637
00:21:54,080 --> 00:21:56,720
a copy of the data but at least yeah i i

638
00:21:56,720 --> 00:21:59,120
don't know i i mean they're pr i think

639
00:21:59,120 --> 00:22:01,120
that privacy issues are way deeper than

640
00:22:01,120 --> 00:22:03,679
anything i talked about right and

641
00:22:03,679 --> 00:22:05,679
something like uh real next generation

642
00:22:05,679 --> 00:22:07,200
technologies like

643
00:22:07,200 --> 00:22:09,360
uh this uh solid i think is the name of

644
00:22:09,360 --> 00:22:10,720
the the

645
00:22:10,720 --> 00:22:12,799
tim berners-lee proposal

646
00:22:12,799 --> 00:22:14,159
and

647
00:22:14,159 --> 00:22:15,760
you know i i think you know like it

648
00:22:15,760 --> 00:22:16,880
needs to be

649
00:22:16,880 --> 00:22:18,480
it's more than the transport protocol we

650
00:22:18,480 --> 00:22:20,720
need to be concerned about is like the

651
00:22:20,720 --> 00:22:22,480
the whole architecture around the data

652
00:22:22,480 --> 00:22:24,320
we we have some people that are actually

653
00:22:24,320 --> 00:22:26,480
looking at privacy in the metaverse

654
00:22:26,480 --> 00:22:29,039
and trying to think of that and uh we we

655
00:22:29,039 --> 00:22:31,760
make these uh ar vr headsets

656
00:22:31,760 --> 00:22:34,080
uh and they're they're really designed

657
00:22:34,080 --> 00:22:36,080
for our gaming division but we found out

658
00:22:36,080 --> 00:22:37,360
they could be used for a lot more than

659
00:22:37,360 --> 00:22:39,039
gaming like like in

660
00:22:39,039 --> 00:22:41,280
uh if you if you take the algorithms

661
00:22:41,280 --> 00:22:42,320
that have been developed that are

662
00:22:42,320 --> 00:22:44,480
tracking eye movements they can also

663
00:22:44,480 --> 00:22:46,000
track your pulse rate they can track

664
00:22:46,000 --> 00:22:48,400
your blood pressure they can sense if

665
00:22:48,400 --> 00:22:49,919
you're in a gaming environment how

666
00:22:49,919 --> 00:22:52,159
you're reacting to the game and based on

667
00:22:52,159 --> 00:22:54,880
your reactions you can shift to another

668
00:22:54,880 --> 00:22:58,320
part of the software to enhance or to

669
00:22:58,320 --> 00:23:00,880
take the stress off depending on

670
00:23:00,880 --> 00:23:02,720
how the player wants to play

671
00:23:02,720 --> 00:23:04,240
but but you can do this on classroom

672
00:23:04,240 --> 00:23:06,799
situation where you can monitor in a

673
00:23:06,799 --> 00:23:08,880
virtual classroom on the computer

674
00:23:08,880 --> 00:23:10,799
monitor you can monitor pulse rate and

675
00:23:10,799 --> 00:23:13,039
blood pressure you can monitor whether

676
00:23:13,039 --> 00:23:15,280
somebody's paying attention there are 53

677
00:23:15,280 --> 00:23:16,960
muscles in the face you can track the

678
00:23:16,960 --> 00:23:19,280
muscle movement and you can actually

679
00:23:19,280 --> 00:23:21,440
accurately predict over 90 percent in

680
00:23:21,440 --> 00:23:24,320
the lab says 98 so i think you got to

681
00:23:24,320 --> 00:23:26,240
cut that back by about 10 percent to get

682
00:23:26,240 --> 00:23:27,440
a real number

683
00:23:27,440 --> 00:23:30,480
uh but the uh what the emotional state

684
00:23:30,480 --> 00:23:31,919
of the student is

685
00:23:31,919 --> 00:23:33,200
are they paying attention did they

686
00:23:33,200 --> 00:23:34,840
understand the concept that you just

687
00:23:34,840 --> 00:23:37,440
presented and talk about privacy i mean

688
00:23:37,440 --> 00:23:38,960
you're you're looking inside somebody's

689
00:23:38,960 --> 00:23:40,640
head when you do that

690
00:23:40,640 --> 00:23:42,480
and so we have emerged you're finding

691
00:23:42,480 --> 00:23:43,679
out things they don't know themselves

692
00:23:43,679 --> 00:23:46,000
they don't have united thought it's

693
00:23:46,000 --> 00:23:48,159
still subconscious and hadn't moved up

694
00:23:48,159 --> 00:23:51,360
yet uh but we have merged our cyber

695
00:23:51,360 --> 00:23:53,679
security affinity group which is a

696
00:23:53,679 --> 00:23:55,520
collection of

697
00:23:55,520 --> 00:23:58,400
about 300 maybe 400 people that are

698
00:23:58,400 --> 00:24:00,559
focused in cyber security in our company

699
00:24:00,559 --> 00:24:01,840
and they get together every couple of

700
00:24:01,840 --> 00:24:03,919
weeks and they trade stories here's what

701
00:24:03,919 --> 00:24:05,600
i'm working on here's what i'm doing

702
00:24:05,600 --> 00:24:06,640
just so

703
00:24:06,640 --> 00:24:09,200
in a matrix organization you're not cut

704
00:24:09,200 --> 00:24:11,360
out or left out on the wings you're in

705
00:24:11,360 --> 00:24:13,760
touch with what the company's doing we

706
00:24:13,760 --> 00:24:15,760
merged the cyber group with our privacy

707
00:24:15,760 --> 00:24:18,400
group and and privacy group much smaller

708
00:24:18,400 --> 00:24:20,080
20 to 50 people

709
00:24:20,080 --> 00:24:21,120
but

710
00:24:21,120 --> 00:24:23,600
you realize that the issues are very

711
00:24:23,600 --> 00:24:24,720
common

712
00:24:24,720 --> 00:24:26,799
just from different perspectives and the

713
00:24:26,799 --> 00:24:28,640
thing the cyber people are talking about

714
00:24:28,640 --> 00:24:30,400
the privacy people are interested and

715
00:24:30,400 --> 00:24:32,640
vice versa and i think that was you know

716
00:24:32,640 --> 00:24:34,000
somebody brought it up and we said we'll

717
00:24:34,000 --> 00:24:35,919
give it a try that's probably the best

718
00:24:35,919 --> 00:24:36,799
thing we could have done for the

719
00:24:36,799 --> 00:24:40,159
collaboration well i i don't need vr to

720
00:24:40,159 --> 00:24:42,240
increase the stress level of my class oh

721
00:24:42,240 --> 00:24:43,600
yeah so

722
00:24:43,600 --> 00:24:44,840
you're a good

723
00:24:44,840 --> 00:24:48,959
professor experience gives me that

724
00:24:49,760 --> 00:24:51,840
again if any of you uh have a question

725
00:24:51,840 --> 00:24:53,919
you'd like us to consider please queue

726
00:24:53,919 --> 00:24:55,360
up there at the microphone i'll i'll

727
00:24:55,360 --> 00:24:57,840
call on you

728
00:24:57,840 --> 00:25:00,880
another aspect here that ties in with

729
00:25:00,880 --> 00:25:03,679
some of the security and privacy

730
00:25:03,679 --> 00:25:05,520
that we're beginning to see

731
00:25:05,520 --> 00:25:08,480
is we've had this issue of global supply

732
00:25:08,480 --> 00:25:10,799
chains and standards

733
00:25:10,799 --> 00:25:12,000
but

734
00:25:12,000 --> 00:25:13,840
what's happening uh

735
00:25:13,840 --> 00:25:16,320
there's hardware certainly that over 50

736
00:25:16,320 --> 00:25:17,760
percent of our chips are produced in

737
00:25:17,760 --> 00:25:18,880
taiwan

738
00:25:18,880 --> 00:25:21,520
so if the prc decides this week is the

739
00:25:21,520 --> 00:25:23,360
one they want to take taiwan back we

740
00:25:23,360 --> 00:25:24,720
have a problem

741
00:25:24,720 --> 00:25:27,039
uh but from a software perspective and

742
00:25:27,039 --> 00:25:29,440
and certainly cisco hp

743
00:25:29,440 --> 00:25:32,320
produce a lot of software that we use

744
00:25:32,320 --> 00:25:34,400
we're seeing with

745
00:25:34,400 --> 00:25:37,279
both economic uh sanctions against

746
00:25:37,279 --> 00:25:39,360
russia

747
00:25:39,360 --> 00:25:40,720
iran

748
00:25:40,720 --> 00:25:43,600
there's a lot being developed locally

749
00:25:43,600 --> 00:25:46,480
prc's developing their own network their

750
00:25:46,480 --> 00:25:49,200
own protocols we're balkanizing

751
00:25:49,200 --> 00:25:50,480
the network

752
00:25:50,480 --> 00:25:52,240
and we're losing a lot of that

753
00:25:52,240 --> 00:25:53,840
interoperability

754
00:25:53,840 --> 00:25:56,799
uh as a result of political pressure and

755
00:25:56,799 --> 00:25:58,799
some economic pressure

756
00:25:58,799 --> 00:25:59,760
um

757
00:25:59,760 --> 00:26:01,840
what does this portend

758
00:26:01,840 --> 00:26:04,480
for our overall

759
00:26:04,480 --> 00:26:06,240
security and privacy posture going

760
00:26:06,240 --> 00:26:08,480
forward and let's go just down the line

761
00:26:08,480 --> 00:26:10,000
with well you know it's kind of

762
00:26:10,000 --> 00:26:11,679
interesting you know on one level so

763
00:26:11,679 --> 00:26:13,440
about um you know 10 or 15 years ago we

764
00:26:13,440 --> 00:26:16,000
were doing a um a project for a

765
00:26:16,000 --> 00:26:18,000
consortium called logic an oil and gas

766
00:26:18,000 --> 00:26:19,919
consortium and we're looking at the

767
00:26:19,919 --> 00:26:21,760
integration of safety and control and

768
00:26:21,760 --> 00:26:23,600
one of the other vendors

769
00:26:23,600 --> 00:26:25,039
because they were all smart engineers

770
00:26:25,039 --> 00:26:26,799
had decided to write their own tcpip

771
00:26:26,799 --> 00:26:29,039
stack instead of using one that had been

772
00:26:29,039 --> 00:26:30,960
used and vetted and let me tell you new

773
00:26:30,960 --> 00:26:33,679
software is full of bugs

774
00:26:33,679 --> 00:26:34,720
and so

775
00:26:34,720 --> 00:26:37,039
is there going to be a a

776
00:26:37,039 --> 00:26:38,880
chinese equivalent of swift and a

777
00:26:38,880 --> 00:26:40,720
chinese equivalent of other things it's

778
00:26:40,720 --> 00:26:42,320
going to take them a long time to get it

779
00:26:42,320 --> 00:26:44,320
right where they can trust that it is as

780
00:26:44,320 --> 00:26:46,080
good as what they were using before so

781
00:26:46,080 --> 00:26:48,320
so that's one interesting aspect i also

782
00:26:48,320 --> 00:26:49,760
but from our own perspective a lot of

783
00:26:49,760 --> 00:26:51,840
the offshoring that had been done

784
00:26:51,840 --> 00:26:53,200
both with manufacturing and with

785
00:26:53,200 --> 00:26:55,440
software you know coming back in

786
00:26:55,440 --> 00:26:56,880
is going to be coupled with things like

787
00:26:56,880 --> 00:26:59,919
our new software bills and materials

788
00:26:59,919 --> 00:27:01,760
digital or hardware builds materials and

789
00:27:01,760 --> 00:27:02,799
okay

790
00:27:02,799 --> 00:27:04,320
and because of all these different

791
00:27:04,320 --> 00:27:06,080
things i have developed something called

792
00:27:06,080 --> 00:27:08,240
the federated uh bill of materials and

793
00:27:08,240 --> 00:27:09,760
i'll leave it to you to work on the

794
00:27:09,760 --> 00:27:13,200
acronym but it gives you a chance to you

795
00:27:13,200 --> 00:27:15,440
know put these things together in in

796
00:27:15,440 --> 00:27:17,919
ways that combined with new you know

797
00:27:17,919 --> 00:27:20,720
training education on secure development

798
00:27:20,720 --> 00:27:21,600
on

799
00:27:21,600 --> 00:27:23,200
cyber informed engineering that i hope

800
00:27:23,200 --> 00:27:24,720
the the secretary of energy will be

801
00:27:24,720 --> 00:27:27,120
signing out soon that can bring us to a

802
00:27:27,120 --> 00:27:28,960
lot better systems you know when we when

803
00:27:28,960 --> 00:27:30,720
we get to talking about workforce you

804
00:27:30,720 --> 00:27:32,480
know you know like oh a million jobs

805
00:27:32,480 --> 00:27:34,159
half of whatever the number is we're

806
00:27:34,159 --> 00:27:36,159
never going to hire and train our way

807
00:27:36,159 --> 00:27:37,679
out of uh the problem with cyber

808
00:27:37,679 --> 00:27:39,440
security we just have to make um you

809
00:27:39,440 --> 00:27:41,840
know more secure systems um that are

810
00:27:41,840 --> 00:27:44,320
easily monitored that protect privacy

811
00:27:44,320 --> 00:27:46,000
you know from the beginning and and

812
00:27:46,000 --> 00:27:47,600
it'll take us 50 years to replace all

813
00:27:47,600 --> 00:27:51,039
the legacy but at least we'll see a path

814
00:27:51,600 --> 00:27:52,640
so

815
00:27:52,640 --> 00:27:55,039
i like software bill of materials and i

816
00:27:55,039 --> 00:27:56,480
like testing

817
00:27:56,480 --> 00:27:57,200
and

818
00:27:57,200 --> 00:28:00,360
i think testing is underrated right that

819
00:28:00,360 --> 00:28:02,640
underappreciated like so nist is doing

820
00:28:02,640 --> 00:28:04,080
something new automated crypto

821
00:28:04,080 --> 00:28:06,000
validation protocol to add like

822
00:28:06,000 --> 00:28:08,000
automated testing so you can take a

823
00:28:08,000 --> 00:28:10,000
crypto module and have it run through

824
00:28:10,000 --> 00:28:12,399
all the battery of tests and and then

825
00:28:12,399 --> 00:28:13,919
when you realize oh wait there's a bug i

826
00:28:13,919 --> 00:28:15,440
have to fix it and then you fix the bug

827
00:28:15,440 --> 00:28:18,480
you can revalidate use using uh like

828
00:28:18,480 --> 00:28:20,799
basically a cloud service right so this

829
00:28:20,799 --> 00:28:21,840
like

830
00:28:21,840 --> 00:28:23,760
automation around testing

831
00:28:23,760 --> 00:28:26,240
is that's that's the way to go because i

832
00:28:26,240 --> 00:28:27,600
i don't trust the people who implemented

833
00:28:27,600 --> 00:28:30,080
it until it's tested

834
00:28:30,080 --> 00:28:32,799
i'll speak on the hardware side and your

835
00:28:32,799 --> 00:28:34,960
expertise in software

836
00:28:34,960 --> 00:28:36,320
makes sense

837
00:28:36,320 --> 00:28:38,559
the hardware side

838
00:28:38,559 --> 00:28:41,120
i serve on the i'm one of the voting

839
00:28:41,120 --> 00:28:42,399
members for the department of homeland

840
00:28:42,399 --> 00:28:44,640
security supply chain risk management

841
00:28:44,640 --> 00:28:45,840
task force

842
00:28:45,840 --> 00:28:47,840
and i chaired the threat evaluation

843
00:28:47,840 --> 00:28:48,799
group

844
00:28:48,799 --> 00:28:51,200
which we started three years ago

845
00:28:51,200 --> 00:28:52,799
and that report's out and they've asked

846
00:28:52,799 --> 00:28:54,480
me to chair the hardware bill of

847
00:28:54,480 --> 00:28:57,600
material which once again you can use

848
00:28:57,600 --> 00:28:59,679
your own name h-bomb in the middle of a

849
00:28:59,679 --> 00:29:02,799
war sounds ominous

850
00:29:03,919 --> 00:29:04,799
but

851
00:29:04,799 --> 00:29:06,799
you've got to think of hardware and

852
00:29:06,799 --> 00:29:08,720
software bill of materials at the same

853
00:29:08,720 --> 00:29:11,360
time so i attend all the s-bomb

854
00:29:11,360 --> 00:29:12,399
meetings

855
00:29:12,399 --> 00:29:14,640
and their uh chairs attend all my

856
00:29:14,640 --> 00:29:16,880
meetings and and because of that at

857
00:29:16,880 --> 00:29:19,360
least we're in the same wavelength

858
00:29:19,360 --> 00:29:20,880
but they're different problems yeah the

859
00:29:20,880 --> 00:29:22,320
different problems that i think the hard

860
00:29:22,320 --> 00:29:24,640
work is much easier

861
00:29:24,640 --> 00:29:26,960
but uh but but it's still just as

862
00:29:26,960 --> 00:29:28,000
incredible

863
00:29:28,000 --> 00:29:30,159
back to the chip manufacturing and you

864
00:29:30,159 --> 00:29:32,799
mentioned taiwan and tsmc and i was

865
00:29:32,799 --> 00:29:34,880
supposed to go over there next week

866
00:29:34,880 --> 00:29:36,960
uh with the national defense university

867
00:29:36,960 --> 00:29:38,720
and they canceled the trip so they're

868
00:29:38,720 --> 00:29:40,559
coming out to palo alto we're going to

869
00:29:40,559 --> 00:29:42,880
tour them around silicon valley but the

870
00:29:42,880 --> 00:29:45,120
follow-on trip to taiwan just thought

871
00:29:45,120 --> 00:29:46,480
you never know when the shoe is going to

872
00:29:46,480 --> 00:29:48,159
drop i think they would have dropped it

873
00:29:48,159 --> 00:29:49,919
a month ago the same day the russians

874
00:29:49,919 --> 00:29:52,159
invaded ukraine if they were going to do

875
00:29:52,159 --> 00:29:53,600
it anytime soon

876
00:29:53,600 --> 00:29:54,880
but

877
00:29:54,880 --> 00:29:57,120
china values its economic security more

878
00:29:57,120 --> 00:29:58,240
than

879
00:29:58,240 --> 00:29:59,760
they value their relationship with

880
00:29:59,760 --> 00:30:02,480
taiwan as my conclusion and if you look

881
00:30:02,480 --> 00:30:04,399
at where they're made

882
00:30:04,399 --> 00:30:06,000
i'm not as worried about where the chips

883
00:30:06,000 --> 00:30:08,480
are stamped out as to where they're

884
00:30:08,480 --> 00:30:09,679
designed

885
00:30:09,679 --> 00:30:11,520
because it's the design of the ship is

886
00:30:11,520 --> 00:30:14,480
where the risk factors are it's where

887
00:30:14,480 --> 00:30:16,559
you put the back doors in it's how you

888
00:30:16,559 --> 00:30:18,559
can attack the chip itself

889
00:30:18,559 --> 00:30:20,399
because the manufacturing of the chips

890
00:30:20,399 --> 00:30:21,840
pretty straightforward i mean it's a

891
00:30:21,840 --> 00:30:24,720
complex very delicate very hard thing to

892
00:30:24,720 --> 00:30:26,799
do but it's a straightforward too and

893
00:30:26,799 --> 00:30:28,720
where's the threats in the manufacturing

894
00:30:28,720 --> 00:30:30,640
versus threat and design well well you

895
00:30:30,640 --> 00:30:32,240
know but you know on one level you know

896
00:30:32,240 --> 00:30:34,640
there though when i know purdue is a

897
00:30:34,640 --> 00:30:36,320
member of this new cyber manufacturing

898
00:30:36,320 --> 00:30:38,559
innovation institute um trying to you

899
00:30:38,559 --> 00:30:40,399
know validate that yeah that design

900
00:30:40,399 --> 00:30:42,480
actually you know did get to the chip

901
00:30:42,480 --> 00:30:44,240
manufacturer uh with this level of

902
00:30:44,240 --> 00:30:46,399
integrity you know and and the way they

903
00:30:46,399 --> 00:30:48,559
designed it so so i think that um you

904
00:30:48,559 --> 00:30:51,279
know it may be designed in in seattle

905
00:30:51,279 --> 00:30:52,960
but by the time it gets across a wire

906
00:30:52,960 --> 00:30:54,880
and into that machine if it's

907
00:30:54,880 --> 00:30:57,600
interdicted and uh and a change a subtle

908
00:30:57,600 --> 00:30:59,200
change made so there's there's both

909
00:30:59,200 --> 00:31:01,200
sides of it and if you hash it at the

910
00:31:01,200 --> 00:31:03,600
design point then you validate the hash

911
00:31:03,600 --> 00:31:05,279
before you go in production you have

912
00:31:05,279 --> 00:31:06,799
some certainty yeah you got to get more

913
00:31:06,799 --> 00:31:08,559
complex than that that was you know you

914
00:31:08,559 --> 00:31:09,760
know guys like david had figured out the

915
00:31:09,760 --> 00:31:12,080
hash thing

916
00:31:12,080 --> 00:31:14,240
i i sort of want to follow up a little

917
00:31:14,240 --> 00:31:15,760
bit on what you started whether you're

918
00:31:15,760 --> 00:31:18,080
talking software bill of materials and

919
00:31:18,080 --> 00:31:19,519
and just i'm going to push back on that

920
00:31:19,519 --> 00:31:21,440
and say that's not really a solution for

921
00:31:21,440 --> 00:31:22,960
some of the problem

922
00:31:22,960 --> 00:31:24,159
uh

923
00:31:24,159 --> 00:31:27,919
last week i i did a poll on infosec

924
00:31:27,919 --> 00:31:31,039
twitter right and and

925
00:31:31,039 --> 00:31:33,519
what i said is you're on a plane and the

926
00:31:33,519 --> 00:31:35,039
pilot announces

927
00:31:35,039 --> 00:31:37,919
we have our new software uh agile design

928
00:31:37,919 --> 00:31:40,080
and we can download from a repository

929
00:31:40,080 --> 00:31:42,880
and update if anything happens

930
00:31:42,880 --> 00:31:44,399
and you're a passenger on this plane

931
00:31:44,399 --> 00:31:45,679
what do you do

932
00:31:45,679 --> 00:31:48,720
well the number one choice by

933
00:31:48,720 --> 00:31:50,960
i gave a limited set of choices but the

934
00:31:50,960 --> 00:31:53,039
number one choice by far was make sure

935
00:31:53,039 --> 00:31:54,960
my will is up to date

936
00:31:54,960 --> 00:31:56,159
um

937
00:31:56,159 --> 00:31:59,519
so we have we may know

938
00:31:59,519 --> 00:32:00,799
of a

939
00:32:00,799 --> 00:32:03,440
thing that's in the software but how

940
00:32:03,440 --> 00:32:05,200
it's developed

941
00:32:05,200 --> 00:32:09,039
is a real problem our overall software

942
00:32:09,039 --> 00:32:11,840
development process moved away

943
00:32:11,840 --> 00:32:12,799
from

944
00:32:12,799 --> 00:32:15,200
design into more

945
00:32:15,200 --> 00:32:17,200
you know let's do things and and then

946
00:32:17,200 --> 00:32:19,120
patch it afterwards

947
00:32:19,120 --> 00:32:21,600
and one of my favorite quotes is is

948
00:32:21,600 --> 00:32:23,840
software that that hasn't been specified

949
00:32:23,840 --> 00:32:25,120
can never be wrong it can only be

950
00:32:25,120 --> 00:32:26,320
surprising

951
00:32:26,320 --> 00:32:29,360
so we have a lot of surprises

952
00:32:29,360 --> 00:32:32,960
um how do we also get back into

953
00:32:32,960 --> 00:32:36,320
better software design that meets our

954
00:32:36,320 --> 00:32:38,480
security and privacy goals i mean that

955
00:32:38,480 --> 00:32:40,480
that's also a supply chain issue where

956
00:32:40,480 --> 00:32:43,120
do we go yeah well you know i talk about

957
00:32:43,120 --> 00:32:44,559
that you know cyber informed engineering

958
00:32:44,559 --> 00:32:47,360
again um that should be linking to

959
00:32:47,360 --> 00:32:49,440
secure software development you know

960
00:32:49,440 --> 00:32:51,679
they're they're i hate standards on one

961
00:32:51,679 --> 00:32:53,519
level because you know the nice thing

962
00:32:53,519 --> 00:32:54,799
about standards is everyone can have

963
00:32:54,799 --> 00:32:57,200
their own um and so with software it's

964
00:32:57,200 --> 00:32:58,799
kind of the same way and i want to make

965
00:32:58,799 --> 00:33:00,480
sure that that all the software

966
00:33:00,480 --> 00:33:03,200
developers for for my different hardware

967
00:33:03,200 --> 00:33:04,960
are using the same standard not not

968
00:33:04,960 --> 00:33:06,720
their own and coming to a level but i

969
00:33:06,720 --> 00:33:07,919
think that's that's something that we

970
00:33:07,919 --> 00:33:08,880
have to learn i think some of the

971
00:33:08,880 --> 00:33:10,720
metadata that s bombs will be able to

972
00:33:10,720 --> 00:33:11,840
collect

973
00:33:11,840 --> 00:33:14,640
we'll talk about the level of rigor

974
00:33:14,640 --> 00:33:17,279
in the software development application

975
00:33:17,279 --> 00:33:19,200
framework that those folks are using and

976
00:33:19,200 --> 00:33:21,600
i think that as we start developing some

977
00:33:21,600 --> 00:33:23,600
of those standards

978
00:33:23,600 --> 00:33:24,799
we'll be able to pick and choose

979
00:33:24,799 --> 00:33:27,200
suppliers that are more apt to uh to

980
00:33:27,200 --> 00:33:28,880
produce you know good code yeah

981
00:33:28,880 --> 00:33:30,399
mandatory standards are called

982
00:33:30,399 --> 00:33:31,600
regulations

983
00:33:31,600 --> 00:33:33,919
so that's uh you get into the regulation

984
00:33:33,919 --> 00:33:35,440
field and boy there goes innovation

985
00:33:35,440 --> 00:33:38,720
right out the door with it so

986
00:33:38,720 --> 00:33:40,080
well this is certainly

987
00:33:40,080 --> 00:33:42,399
in in cryptography it's certainly

988
00:33:42,399 --> 00:33:44,399
recognized that people who are rolling

989
00:33:44,399 --> 00:33:46,799
their own or trying to do their own

990
00:33:46,799 --> 00:33:48,799
uh without a proper guidance uh

991
00:33:48,799 --> 00:33:51,039
generally are making a huge mistake

992
00:33:51,039 --> 00:33:53,120
um

993
00:33:53,120 --> 00:33:54,960
rolling their own has some connotations

994
00:33:54,960 --> 00:33:56,880
too yeah

995
00:33:56,880 --> 00:34:00,480
those are the ones who very often try

996
00:34:01,519 --> 00:34:03,519
you know

997
00:34:03,519 --> 00:34:06,559
i think you're right that coding

998
00:34:06,559 --> 00:34:09,199
practices are aren't deliberate enough

999
00:34:09,199 --> 00:34:11,040
don't involve enough design

1000
00:34:11,040 --> 00:34:13,199
and you know probably the industry is is

1001
00:34:13,199 --> 00:34:14,960
partly to blame there's mostly to blame

1002
00:34:14,960 --> 00:34:17,359
here right i think that

1003
00:34:17,359 --> 00:34:19,599
i'd really like to see more attention

1004
00:34:19,599 --> 00:34:20,960
paid on design

1005
00:34:20,960 --> 00:34:23,520
and methodologies around design and

1006
00:34:23,520 --> 00:34:25,359
um you know one of the things i always

1007
00:34:25,359 --> 00:34:26,719
tell people that i that i work with

1008
00:34:26,719 --> 00:34:29,040
around software and i write i write and

1009
00:34:29,040 --> 00:34:32,159
i work with a lot of software

1010
00:34:32,159 --> 00:34:33,760
you know what's valuable is code that's

1011
00:34:33,760 --> 00:34:35,679
been reviewed right so you can have

1012
00:34:35,679 --> 00:34:37,760
somebody really smart you know writes a

1013
00:34:37,760 --> 00:34:39,679
thousand lines of code but until like

1014
00:34:39,679 --> 00:34:41,359
somebody else has actually sanity

1015
00:34:41,359 --> 00:34:43,839
checked it right i mean it shouldn't be

1016
00:34:43,839 --> 00:34:45,520
trusted right so

1017
00:34:45,520 --> 00:34:47,440
and then when you take like you you

1018
00:34:47,440 --> 00:34:48,960
build up like

1019
00:34:48,960 --> 00:34:51,119
you know 200 000 lines of code that was

1020
00:34:51,119 --> 00:34:53,199
been well written and well vetted and

1021
00:34:53,199 --> 00:34:55,359
then you slap you know 5000 lines of

1022
00:34:55,359 --> 00:34:57,359
patches in it because oh well we wanted

1023
00:34:57,359 --> 00:34:59,040
to do this other thing right well you

1024
00:34:59,040 --> 00:35:01,119
just invalidated you need to have a

1025
00:35:01,119 --> 00:35:03,119
process and a review around adding that

1026
00:35:03,119 --> 00:35:06,960
patch in you know so validation is is

1027
00:35:06,960 --> 00:35:09,520
the code review is is

1028
00:35:09,520 --> 00:35:11,040
of primary importance we should be

1029
00:35:11,040 --> 00:35:13,040
tracking it we should be valuing it and

1030
00:35:13,040 --> 00:35:14,480
and if you look at the tools and the

1031
00:35:14,480 --> 00:35:16,079
methodology and practices at least the

1032
00:35:16,079 --> 00:35:18,079
ones that that that i've seen right i

1033
00:35:18,079 --> 00:35:22,800
don't see enough uh recognition of this

1034
00:35:23,839 --> 00:35:25,200
i was going to say i i blame gordon

1035
00:35:25,200 --> 00:35:27,760
moore for the state of sloppy software

1036
00:35:27,760 --> 00:35:29,520
because back in the 70s when when

1037
00:35:29,520 --> 00:35:31,920
hardware cycles were expensive you spent

1038
00:35:31,920 --> 00:35:34,480
a lot of time designing your code you

1039
00:35:34,480 --> 00:35:36,400
know writing it carefully bench checking

1040
00:35:36,400 --> 00:35:38,000
it because it was going to take you you

1041
00:35:38,000 --> 00:35:40,560
know a half day or a day or more to get

1042
00:35:40,560 --> 00:35:42,800
one run back right you know and if you

1043
00:35:42,800 --> 00:35:43,920
needed to have something you know

1044
00:35:43,920 --> 00:35:46,000
developed either commercially or or for

1045
00:35:46,000 --> 00:35:48,400
school and it was due on friday and you

1046
00:35:48,400 --> 00:35:49,920
only you know and it was tuesday you

1047
00:35:49,920 --> 00:35:51,760
figure i have four chances to get this

1048
00:35:51,760 --> 00:35:54,400
right so i better make sure that i have

1049
00:35:54,400 --> 00:35:56,960
designed my specification i understand

1050
00:35:56,960 --> 00:35:58,960
what the requirement is you know i write

1051
00:35:58,960 --> 00:36:00,880
it in the language that i can do well

1052
00:36:00,880 --> 00:36:03,760
now i'm gonna i can sit at right my desk

1053
00:36:03,760 --> 00:36:05,680
and just just try a thousand things in

1054
00:36:05,680 --> 00:36:08,079
an hour just about um and then when i

1055
00:36:08,079 --> 00:36:09,359
finally get the answer i can give it to

1056
00:36:09,359 --> 00:36:11,119
my professor and you know you know say

1057
00:36:11,119 --> 00:36:12,880
it's all done and it works the same way

1058
00:36:12,880 --> 00:36:14,400
i believe in in some software

1059
00:36:14,400 --> 00:36:15,839
development houses well it's certainly

1060
00:36:15,839 --> 00:36:18,000
the case that if you're first to market

1061
00:36:18,000 --> 00:36:20,480
you have an advantage and that's driven

1062
00:36:20,480 --> 00:36:22,560
a lot of these methods the the just in

1063
00:36:22,560 --> 00:36:25,119
time the devops the agile programming

1064
00:36:25,119 --> 00:36:27,200
is to turn things around quickly for

1065
00:36:27,200 --> 00:36:28,800
features

1066
00:36:28,800 --> 00:36:30,640
but we don't really have any penalties

1067
00:36:30,640 --> 00:36:32,560
in the system what's your poor quality

1068
00:36:32,560 --> 00:36:34,240
let your customers fix your software

1069
00:36:34,240 --> 00:36:36,320
problems oh yeah yeah that's the yeah i

1070
00:36:36,320 --> 00:36:37,680
worked for a company that that must have

1071
00:36:37,680 --> 00:36:39,359
been their motto that's that's the

1072
00:36:39,359 --> 00:36:41,440
shortest block on my resume after i

1073
00:36:41,440 --> 00:36:42,960
realized what i was looking for and you

1074
00:36:42,960 --> 00:36:44,800
know and actually and don't look me up

1075
00:36:44,800 --> 00:36:46,160
on linkedin i don't think i even

1076
00:36:46,160 --> 00:36:48,640
mentioned the name of the company

1077
00:36:48,640 --> 00:36:52,799
um i don't remem when do we uh

1078
00:36:52,839 --> 00:36:55,599
15 so we've got time

1079
00:36:55,599 --> 00:36:57,680
i'm not seeing anybody

1080
00:36:57,680 --> 00:36:59,680
jumping up here to ask questions oh

1081
00:36:59,680 --> 00:37:02,480
maybe that's a cue

1082
00:37:04,000 --> 00:37:05,520
so i used to say that you know if there

1083
00:37:05,520 --> 00:37:06,880
are students out there that didn't have

1084
00:37:06,880 --> 00:37:08,560
questions they obviously aren't um you

1085
00:37:08,560 --> 00:37:10,400
know

1086
00:37:10,400 --> 00:37:12,880
i can't do it

1087
00:37:12,880 --> 00:37:15,280
and i can prove it with the software

1088
00:37:15,280 --> 00:37:16,079
so

1089
00:37:16,079 --> 00:37:19,800
in theory the next release of nist

1090
00:37:19,800 --> 00:37:21,599
800-161

1091
00:37:21,599 --> 00:37:22,880
is

1092
00:37:22,880 --> 00:37:24,480
immediately

1093
00:37:24,480 --> 00:37:27,040
in in queue to be released

1094
00:37:27,040 --> 00:37:28,000
so

1095
00:37:28,000 --> 00:37:28,880
close

1096
00:37:28,880 --> 00:37:30,320
how much

1097
00:37:30,320 --> 00:37:33,440
of the issues are you going to address

1098
00:37:33,440 --> 00:37:35,200
because

1099
00:37:35,200 --> 00:37:37,760
the second release

1100
00:37:37,760 --> 00:37:40,160
was almost a total rewrite from the

1101
00:37:40,160 --> 00:37:41,760
initial yes

1102
00:37:41,760 --> 00:37:42,800
uh

1103
00:37:42,800 --> 00:37:45,040
release so

1104
00:37:45,040 --> 00:37:47,119
could you comment on where you think

1105
00:37:47,119 --> 00:37:49,119
you're going what you've solved and

1106
00:37:49,119 --> 00:37:51,599
what's left to be solved yeah i let me

1107
00:37:51,599 --> 00:37:53,359
say something about nisk and i know a

1108
00:37:53,359 --> 00:37:54,960
lot of you out there have interface and

1109
00:37:54,960 --> 00:37:57,119
work with them but i i think they're one

1110
00:37:57,119 --> 00:37:59,119
of the best run agencies in government

1111
00:37:59,119 --> 00:38:01,520
today now i was very close with walt

1112
00:38:01,520 --> 00:38:03,520
koppen who was the last director in this

1113
00:38:03,520 --> 00:38:06,160
previous administration walt and i serve

1114
00:38:06,160 --> 00:38:08,720
on the u.s council on competitiveness

1115
00:38:08,720 --> 00:38:10,240
and for some reason they always put us

1116
00:38:10,240 --> 00:38:12,320
next to each other at all the meetings

1117
00:38:12,320 --> 00:38:13,440
and

1118
00:38:13,440 --> 00:38:17,040
he does a great job of getting industry

1119
00:38:17,040 --> 00:38:19,440
government and academia together

1120
00:38:19,440 --> 00:38:21,920
at nist to discuss issues

1121
00:38:21,920 --> 00:38:24,880
and they do not publish anything until

1122
00:38:24,880 --> 00:38:27,920
all issues or complaints are resolved

1123
00:38:27,920 --> 00:38:30,079
they have an answer so they come to a

1124
00:38:30,079 --> 00:38:32,400
collaborative understanding and that's

1125
00:38:32,400 --> 00:38:34,720
why you know i was fussing at walt last

1126
00:38:34,720 --> 00:38:36,800
uh two years ago

1127
00:38:36,800 --> 00:38:38,480
you know you've got to get some of these

1128
00:38:38,480 --> 00:38:40,720
new crypto modules out the quantum

1129
00:38:40,720 --> 00:38:42,400
resistant encryption

1130
00:38:42,400 --> 00:38:43,839
we've got to be prepared we need to be

1131
00:38:43,839 --> 00:38:46,480
prepared now and we're losing time

1132
00:38:46,480 --> 00:38:49,440
and he says we don't do it that way we

1133
00:38:49,440 --> 00:38:51,280
make sure

1134
00:38:51,280 --> 00:38:54,240
careful step deliberate process

1135
00:38:54,240 --> 00:38:56,320
to adjudicate all this and when you look

1136
00:38:56,320 --> 00:38:59,119
at example of public-private partnership

1137
00:38:59,119 --> 00:39:01,119
i think nist does it right

1138
00:39:01,119 --> 00:39:04,079
and so 161 is coming on don't know

1139
00:39:04,079 --> 00:39:05,440
exactly when

1140
00:39:05,440 --> 00:39:06,880
i think they're ready

1141
00:39:06,880 --> 00:39:10,000
98 to release it today but they're

1142
00:39:10,000 --> 00:39:12,160
crossing the eyes and dotting the tees

1143
00:39:12,160 --> 00:39:12,880
or

1144
00:39:12,880 --> 00:39:15,839
that

1145
00:39:24,880 --> 00:39:28,440
i don't know i'm the same

1146
00:39:39,599 --> 00:39:43,400
in theory a final

1147
00:39:43,520 --> 00:39:45,599
so so i just want to say you know it's

1148
00:39:45,599 --> 00:39:47,280
almost like an acronym like you know we

1149
00:39:47,280 --> 00:39:48,640
lost our cheat sheet and which one is

1150
00:39:48,640 --> 00:39:51,680
161 oh yeah no no it's a supply what

1151
00:39:51,680 --> 00:39:54,079
what is it

1152
00:39:54,079 --> 00:39:55,760
i guess i should know that okay yeah i

1153
00:39:55,760 --> 00:39:58,880
do that 161 172 go close together

1154
00:39:58,880 --> 00:40:01,119
qe or the controlled unclassified

1155
00:40:01,119 --> 00:40:03,839
information is really the focus 172

1156
00:40:03,839 --> 00:40:06,560
which gets you into the cmmc discussion

1157
00:40:06,560 --> 00:40:09,520
of the cyber security uh maturity model

1158
00:40:09,520 --> 00:40:11,520
certification yeah i was just saying i

1159
00:40:11,520 --> 00:40:13,680
had a meeting last week with paul

1160
00:40:13,680 --> 00:40:16,000
nielsen who's the ceo of carnegie

1161
00:40:16,000 --> 00:40:18,560
mellon's software engineering institute

1162
00:40:18,560 --> 00:40:20,319
and paul and i go way back to when he

1163
00:40:20,319 --> 00:40:22,800
was a two-star in the air force running

1164
00:40:22,800 --> 00:40:25,520
the air force research lab i was office

1165
00:40:25,520 --> 00:40:27,200
at the office of naval research and we

1166
00:40:27,200 --> 00:40:29,359
had some collaborations together and so

1167
00:40:29,359 --> 00:40:31,680
we were just telling c stories rehashing

1168
00:40:31,680 --> 00:40:34,400
old times but he reminded me when i was

1169
00:40:34,400 --> 00:40:36,240
running a major program to build a

1170
00:40:36,240 --> 00:40:38,480
sealed delivery system

1171
00:40:38,480 --> 00:40:39,920
that had carried

1172
00:40:39,920 --> 00:40:41,440
10 seals

1173
00:40:41,440 --> 00:40:43,520
up a river for a week-long and a

1174
00:40:43,520 --> 00:40:46,240
lithium-ion polymer battery

1175
00:40:46,240 --> 00:40:48,000
we had some real software problems in

1176
00:40:48,000 --> 00:40:50,400
that program and somebody told me i'll

1177
00:40:50,400 --> 00:40:51,839
go up to carnegie mellon and see if they

1178
00:40:51,839 --> 00:40:54,000
could help and since office naval

1179
00:40:54,000 --> 00:40:55,760
research was sending about 12 million a

1180
00:40:55,760 --> 00:40:57,440
year to carnegie mellon

1181
00:40:57,440 --> 00:40:59,520
i got a lot of help you know that'll

1182
00:40:59,520 --> 00:41:01,680
that'll wake up some professors over

1183
00:41:01,680 --> 00:41:04,640
there and they uh

1184
00:41:04,880 --> 00:41:06,240
and the one thing they were telling me

1185
00:41:06,240 --> 00:41:09,119
about was mccabe complexity matrix full

1186
00:41:09,119 --> 00:41:11,520
path integration testing every node and

1187
00:41:11,520 --> 00:41:13,200
every path that you've validated the

1188
00:41:13,200 --> 00:41:15,040
software has been through this

1189
00:41:15,040 --> 00:41:17,520
and uh and when you're looking at mccabe

1190
00:41:17,520 --> 00:41:19,040
we don't call it mccabe anymore we do

1191
00:41:19,040 --> 00:41:20,720
have complexity testing

1192
00:41:20,720 --> 00:41:23,599
uh somehow mccabe must get discredited

1193
00:41:23,599 --> 00:41:25,680
but his name's dropped off

1194
00:41:25,680 --> 00:41:28,240
cyclomatic complexity

1195
00:41:28,240 --> 00:41:30,400
but uh but paul brought that up do you

1196
00:41:30,400 --> 00:41:31,760
remember when

1197
00:41:31,760 --> 00:41:33,839
and and you know you think that this was

1198
00:41:33,839 --> 00:41:34,800
back

1199
00:41:34,800 --> 00:41:35,680
in

1200
00:41:35,680 --> 00:41:38,720
20 years ago and and we're same issues

1201
00:41:38,720 --> 00:41:41,200
are still an appliance i i think

1202
00:41:41,200 --> 00:41:43,760
nist is going to get this out and

1203
00:41:43,760 --> 00:41:46,240
they're going to be uh

1204
00:41:46,240 --> 00:41:47,599
people that even when it comes out

1205
00:41:47,599 --> 00:41:49,440
they're going to start complaining and

1206
00:41:49,440 --> 00:41:50,880
the beautiful thing is they're going to

1207
00:41:50,880 --> 00:41:52,720
listen to those complaints they're going

1208
00:41:52,720 --> 00:41:54,000
to evaluate it they're going to put it

1209
00:41:54,000 --> 00:41:55,760
out with industry and you may see a

1210
00:41:55,760 --> 00:41:57,680
whole other version come out in three

1211
00:41:57,680 --> 00:41:58,800
years from now

1212
00:41:58,800 --> 00:42:00,800
it's because they're listening and

1213
00:42:00,800 --> 00:42:02,880
they're not just ignoring or saying this

1214
00:42:02,880 --> 00:42:04,480
is the way we do it

1215
00:42:04,480 --> 00:42:07,440
they really are facilitating input so if

1216
00:42:07,440 --> 00:42:09,760
you take the time to make a comment on a

1217
00:42:09,760 --> 00:42:13,119
nist document it will be heard i i was

1218
00:42:13,119 --> 00:42:15,280
pushing for 193 to get out and that's

1219
00:42:15,280 --> 00:42:16,800
one on hardware

1220
00:42:16,800 --> 00:42:17,920
uh

1221
00:42:17,920 --> 00:42:19,280
resiliency

1222
00:42:19,280 --> 00:42:21,680
you know what is resiliency well the

1223
00:42:21,680 --> 00:42:23,520
first thing this does is they spend

1224
00:42:23,520 --> 00:42:26,000
months just defining the terms

1225
00:42:26,000 --> 00:42:29,200
and so in our uh our our scrim task

1226
00:42:29,200 --> 00:42:31,520
force whenever there's what do you mean

1227
00:42:31,520 --> 00:42:33,599
when you say artificial intelligence

1228
00:42:33,599 --> 00:42:35,440
what do you mean yeah you know we

1229
00:42:35,440 --> 00:42:37,359
default to the nist definitions because

1230
00:42:37,359 --> 00:42:39,599
they've done a whole lot of work already

1231
00:42:39,599 --> 00:42:41,359
just to define the term so we're all on

1232
00:42:41,359 --> 00:42:43,359
the same sheet of music i think

1233
00:42:43,359 --> 00:42:45,119
something that that should be born in

1234
00:42:45,119 --> 00:42:47,119
mind and and often we forget it because

1235
00:42:47,119 --> 00:42:49,839
we are so focused on near-term issues

1236
00:42:49,839 --> 00:42:52,000
is how rapidly

1237
00:42:52,000 --> 00:42:54,960
our field continues to evolve

1238
00:42:54,960 --> 00:42:56,160
so

1239
00:42:56,160 --> 00:42:57,680
uh this is one of the things talking

1240
00:42:57,680 --> 00:43:00,240
with david about when we had our our uh

1241
00:43:00,240 --> 00:43:02,640
visionary workshop 20 years ago

1242
00:43:02,640 --> 00:43:04,880
uh we said some very provocative things

1243
00:43:04,880 --> 00:43:07,040
that now in hindsight look well of

1244
00:43:07,040 --> 00:43:08,079
course

1245
00:43:08,079 --> 00:43:08,800
like

1246
00:43:08,800 --> 00:43:10,480
always on

1247
00:43:10,480 --> 00:43:13,359
uh technology and that was not the case

1248
00:43:13,359 --> 00:43:14,960
20 years ago

1249
00:43:14,960 --> 00:43:16,960
even a few years ago if you had talked

1250
00:43:16,960 --> 00:43:18,079
about

1251
00:43:18,079 --> 00:43:21,119
public repositories of code

1252
00:43:21,119 --> 00:43:23,200
people would not have understood what

1253
00:43:23,200 --> 00:43:25,200
that meant

1254
00:43:25,200 --> 00:43:28,560
the advent of things like git uh and and

1255
00:43:28,560 --> 00:43:29,599
similar

1256
00:43:29,599 --> 00:43:32,880
packages um talking about uh

1257
00:43:32,880 --> 00:43:36,480
containers and and uh similar control

1258
00:43:36,480 --> 00:43:39,119
ten years ago those were

1259
00:43:39,119 --> 00:43:40,720
theoretical or

1260
00:43:40,720 --> 00:43:42,960
in the lab they weren't out in regular

1261
00:43:42,960 --> 00:43:44,640
use

1262
00:43:44,640 --> 00:43:47,040
so these standards and this is also by

1263
00:43:47,040 --> 00:43:48,160
the way what draw

1264
00:43:48,160 --> 00:43:49,839
drives the agile development kind of

1265
00:43:49,839 --> 00:43:51,680
approach is because these things are

1266
00:43:51,680 --> 00:43:54,160
evolving so quickly but those are really

1267
00:43:54,160 --> 00:43:55,680
kind of difficult for us to get our

1268
00:43:55,680 --> 00:43:57,839
hands around because it takes time to

1269
00:43:57,839 --> 00:43:58,880
understand those and what the

1270
00:43:58,880 --> 00:44:00,640
implications are sure

1271
00:44:00,640 --> 00:44:02,560
absolutely

1272
00:44:02,560 --> 00:44:03,599
okay

1273
00:44:03,599 --> 00:44:05,839
um mark probasco with periton

1274
00:44:05,839 --> 00:44:09,119
corporation my hp

1275
00:44:09,119 --> 00:44:11,280
mom

1276
00:44:11,280 --> 00:44:13,760
two two questions one is one i've been

1277
00:44:13,760 --> 00:44:15,520
on the navy account for

1278
00:44:15,520 --> 00:44:17,599
a number of years

1279
00:44:17,599 --> 00:44:19,359
one of the issues is when we get the

1280
00:44:19,359 --> 00:44:21,040
hardware in

1281
00:44:21,040 --> 00:44:23,520
uh it has all the down to the chip level

1282
00:44:23,520 --> 00:44:25,280
we have to have the software the chip

1283
00:44:25,280 --> 00:44:27,359
levels all of that

1284
00:44:27,359 --> 00:44:28,319
but

1285
00:44:28,319 --> 00:44:29,839
it's when you get into replacement

1286
00:44:29,839 --> 00:44:30,720
boards

1287
00:44:30,720 --> 00:44:32,240
we have to have

1288
00:44:32,240 --> 00:44:34,319
who's got the replacement board who

1289
00:44:34,319 --> 00:44:35,920
installed you know what and i know you

1290
00:44:35,920 --> 00:44:36,880
know yeah

1291
00:44:36,880 --> 00:44:38,880
every day um i guess i was kind of

1292
00:44:38,880 --> 00:44:42,000
curious to see where you see that

1293
00:44:42,000 --> 00:44:44,480
going because that's you know we

1294
00:44:44,480 --> 00:44:47,440
that that plays a huge role in the ship

1295
00:44:47,440 --> 00:44:49,520
absolutely all that and then the last

1296
00:44:49,520 --> 00:44:51,680
question is

1297
00:44:51,680 --> 00:44:52,960
dodaf

1298
00:44:52,960 --> 00:44:55,280
once in a while we'll get

1299
00:44:55,280 --> 00:44:57,359
requests in from the department of

1300
00:44:57,359 --> 00:44:59,119
defense to follow

1301
00:44:59,119 --> 00:45:01,920
dodaf processes

1302
00:45:01,920 --> 00:45:03,119
i

1303
00:45:03,119 --> 00:45:05,359
not sure where dodaf is going and how

1304
00:45:05,359 --> 00:45:06,319
well

1305
00:45:06,319 --> 00:45:08,480
cyber is built into that process and i

1306
00:45:08,480 --> 00:45:09,440
just wonder

1307
00:45:09,440 --> 00:45:11,200
anybody on the board i have any

1308
00:45:11,200 --> 00:45:12,319
influence

1309
00:45:12,319 --> 00:45:14,240
i'm going to refuse any knowledge or do

1310
00:45:14,240 --> 00:45:16,160
that yeah i thought after gone away

1311
00:45:16,160 --> 00:45:18,079
years ago okay no i thought it had

1312
00:45:18,079 --> 00:45:20,720
disappeared completely back okay right

1313
00:45:20,720 --> 00:45:22,079
it's there to slow things down not

1314
00:45:22,079 --> 00:45:24,720
necessarily but the end cost is doing

1315
00:45:24,720 --> 00:45:26,720
some really good work in hardware

1316
00:45:26,720 --> 00:45:30,640
manufacturing and if you look at the um

1317
00:45:30,640 --> 00:45:33,040
end the national cyber center of

1318
00:45:33,040 --> 00:45:35,440
excellence that this supports as a

1319
00:45:35,440 --> 00:45:37,680
public-private partnership and what

1320
00:45:37,680 --> 00:45:40,079
they've done is looking at all the logic

1321
00:45:40,079 --> 00:45:41,680
bearing components in your hardware

1322
00:45:41,680 --> 00:45:43,920
products and this is not just hp working

1323
00:45:43,920 --> 00:45:45,839
on the project but dell and lenovo and i

1324
00:45:45,839 --> 00:45:47,920
think some others

1325
00:45:47,920 --> 00:45:50,240
that you're you're looking at

1326
00:45:50,240 --> 00:45:51,920
putting a crypto signature on each

1327
00:45:51,920 --> 00:45:53,119
component

1328
00:45:53,119 --> 00:45:55,280
and then hashing those signatures

1329
00:45:55,280 --> 00:45:57,359
together with all the components on

1330
00:45:57,359 --> 00:45:58,240
there

1331
00:45:58,240 --> 00:46:00,880
and if the hash doesn't add up at boot

1332
00:46:00,880 --> 00:46:03,040
somebody's manipulated one of the

1333
00:46:03,040 --> 00:46:05,119
components or added a component

1334
00:46:05,119 --> 00:46:08,960
and uh and that's problematic from a uh

1335
00:46:08,960 --> 00:46:10,720
tampering point of view

1336
00:46:10,720 --> 00:46:12,160
and i think that's going to give you

1337
00:46:12,160 --> 00:46:14,880
more security that the the hardware that

1338
00:46:14,880 --> 00:46:16,160
was built in

1339
00:46:16,160 --> 00:46:19,040
at manufacturing and shipped it's the

1340
00:46:19,040 --> 00:46:21,359
same one that was delivered on receipt

1341
00:46:21,359 --> 00:46:23,280
to the customer and it's the same one

1342
00:46:23,280 --> 00:46:26,160
being used five years later

1343
00:46:26,160 --> 00:46:28,000
and all the way we used to call it

1344
00:46:28,000 --> 00:46:29,680
cradle to

1345
00:46:29,680 --> 00:46:32,560
cradle the grave and and now our

1346
00:46:32,560 --> 00:46:34,160
sustainability people say you've got to

1347
00:46:34,160 --> 00:46:35,760
say cradle to cradle because you're

1348
00:46:35,760 --> 00:46:37,119
going to take all the things we're going

1349
00:46:37,119 --> 00:46:38,240
to put in the grave and going to reuse

1350
00:46:38,240 --> 00:46:41,040
them all okay so

1351
00:46:41,040 --> 00:46:43,599
i'm sure oh hi uh going back slightly to

1352
00:46:43,599 --> 00:46:45,839
the ukraine conflict i was wondering if

1353
00:46:45,839 --> 00:46:47,680
you could uh speculate a little on what

1354
00:46:47,680 --> 00:46:50,160
a hot cyber warfare hot war cyber

1355
00:46:50,160 --> 00:46:52,319
warfare would look like and uh

1356
00:46:52,319 --> 00:46:53,680
address the question i sort of have

1357
00:46:53,680 --> 00:46:55,760
which is is ukraine better prepared for

1358
00:46:55,760 --> 00:46:56,960
it having fought it for at least eight

1359
00:46:56,960 --> 00:46:58,400
years than we are

1360
00:46:58,400 --> 00:47:01,200
well considering that we help train some

1361
00:47:01,200 --> 00:47:02,880
of the people there yes they're better

1362
00:47:02,880 --> 00:47:06,560
prepared than than what they were before

1363
00:47:06,560 --> 00:47:07,680
i think she asked if they're better

1364
00:47:07,680 --> 00:47:10,560
prepared than we are

1365
00:47:13,200 --> 00:47:16,079
[Laughter]

1366
00:47:16,079 --> 00:47:17,760
i don't think so because at least what

1367
00:47:17,760 --> 00:47:19,440
we found in training them

1368
00:47:19,440 --> 00:47:21,200
uh there were there were a number of

1369
00:47:21,200 --> 00:47:22,160
gaps

1370
00:47:22,160 --> 00:47:24,000
well and it's always back to money how

1371
00:47:24,000 --> 00:47:25,599
much can they afford to spend it's a

1372
00:47:25,599 --> 00:47:28,400
risk reduction if you want zero risk

1373
00:47:28,400 --> 00:47:30,319
you're going to spend infinite dollars

1374
00:47:30,319 --> 00:47:33,440
it's a correlation and and so ukraine

1375
00:47:33,440 --> 00:47:35,680
had limited resources and we were trying

1376
00:47:35,680 --> 00:47:37,200
to train them from an intellectual point

1377
00:47:37,200 --> 00:47:39,200
of view but they still have people and

1378
00:47:39,200 --> 00:47:41,599
people are money and they had limits of

1379
00:47:41,599 --> 00:47:43,839
what they could do and and we have

1380
00:47:43,839 --> 00:47:46,640
limits ourselves not as many limits

1381
00:47:46,640 --> 00:47:48,559
but the if you want to read a good book

1382
00:47:48,559 --> 00:47:50,640
on the cyber war the future

1383
00:47:50,640 --> 00:47:52,480
my classmate at the naval academy jim

1384
00:47:52,480 --> 00:47:55,200
stavridis 2034 became a yeah i became an

1385
00:47:55,200 --> 00:47:57,520
admiral and served at southern command i

1386
00:47:57,520 --> 00:47:58,800
worked with him there and then he went

1387
00:47:58,800 --> 00:48:00,319
on to european command i was on an

1388
00:48:00,319 --> 00:48:02,240
advisory board with him i've stayed

1389
00:48:02,240 --> 00:48:04,319
close to this guy i had no clue he could

1390
00:48:04,319 --> 00:48:06,000
write a novel like this

1391
00:48:06,000 --> 00:48:07,920
but it's it doesn't go into the details

1392
00:48:07,920 --> 00:48:10,319
of how the cybers operated but it is a

1393
00:48:10,319 --> 00:48:12,079
scary story that if we don't do

1394
00:48:12,079 --> 00:48:13,760
something now

1395
00:48:13,760 --> 00:48:16,720
about protecting cyber security and uh

1396
00:48:16,720 --> 00:48:18,720
military warfare we're going to be in

1397
00:48:18,720 --> 00:48:21,119
big trouble by 2034. and it's called

1398
00:48:21,119 --> 00:48:23,920
2034 a novel of the next uh world war in

1399
00:48:23,920 --> 00:48:26,640
the next cyber world war yeah and and

1400
00:48:26,640 --> 00:48:29,280
actually tomorrow's a closing keynote

1401
00:48:29,280 --> 00:48:31,520
dick clark has written several books on

1402
00:48:31,520 --> 00:48:33,119
this

1403
00:48:33,119 --> 00:48:34,640
he's really absolutely too that that

1404
00:48:34,640 --> 00:48:36,000
would be uh

1405
00:48:36,000 --> 00:48:37,920
i think his talk he will talk about that

1406
00:48:37,920 --> 00:48:40,079
about how we're in a hybrid war

1407
00:48:40,079 --> 00:48:42,880
right now yeah

1408
00:48:44,160 --> 00:48:45,200
so

1409
00:48:45,200 --> 00:48:47,520
i'll i'll ask another question here as

1410
00:48:47,520 --> 00:48:48,880
as we've

1411
00:48:48,880 --> 00:48:51,839
sort of cleared the queue

1412
00:48:52,480 --> 00:48:56,480
we're seeing increased interest

1413
00:48:56,480 --> 00:48:58,960
i would say a lot of

1414
00:48:58,960 --> 00:49:00,960
i would say a lot of it is hype

1415
00:49:00,960 --> 00:49:05,920
um as well as interest in ai writ large

1416
00:49:05,920 --> 00:49:07,440
i i don't believe there is artificial

1417
00:49:07,440 --> 00:49:08,559
intelligence

1418
00:49:08,559 --> 00:49:10,480
but there is certainly a lot in machine

1419
00:49:10,480 --> 00:49:12,480
learning and and

1420
00:49:12,480 --> 00:49:15,200
machine recognition

1421
00:49:15,200 --> 00:49:17,920
we're getting to a point

1422
00:49:17,920 --> 00:49:19,599
probably past it where some decisions

1423
00:49:19,599 --> 00:49:21,599
are being made and we don't know why

1424
00:49:21,599 --> 00:49:23,119
we have systems that we're designing

1425
00:49:23,119 --> 00:49:25,760
that are doing things and we're not sure

1426
00:49:25,760 --> 00:49:27,440
why and people are talking about using

1427
00:49:27,440 --> 00:49:29,520
those for security

1428
00:49:29,520 --> 00:49:32,160
what does that portend for us as a field

1429
00:49:32,160 --> 00:49:34,319
on the trajectory we're on yeah i was

1430
00:49:34,319 --> 00:49:35,440
going to make the joke about there might

1431
00:49:35,440 --> 00:49:37,119
not be as much natural intelligence as

1432
00:49:37,119 --> 00:49:39,599
there was 50 years ago but um

1433
00:49:39,599 --> 00:49:41,119
and so so yeah so people need to

1434
00:49:41,119 --> 00:49:43,119
understand kind of the progression from

1435
00:49:43,119 --> 00:49:46,800
you know autonomous systems to you know

1436
00:49:46,800 --> 00:49:49,119
automated systems etc um

1437
00:49:49,119 --> 00:49:51,280
you know i think that um

1438
00:49:51,280 --> 00:49:54,000
we need to get ahead of what um ai will

1439
00:49:54,000 --> 00:49:56,240
do for us those uh those highly

1440
00:49:56,240 --> 00:49:58,079
autonomous systems

1441
00:49:58,079 --> 00:50:00,480
we worked on a task with

1442
00:50:00,480 --> 00:50:02,400
california the california energy

1443
00:50:02,400 --> 00:50:05,119
security for the 21st century and we

1444
00:50:05,119 --> 00:50:06,960
developed a machine to machine automated

1445
00:50:06,960 --> 00:50:08,400
threat reduction system you know you

1446
00:50:08,400 --> 00:50:10,240
know fast faster than you know than

1447
00:50:10,240 --> 00:50:12,319
human speed etc and uh and when briefing

1448
00:50:12,319 --> 00:50:13,839
into the c-suite you know one of the

1449
00:50:13,839 --> 00:50:15,520
officers in there was like you know i

1450
00:50:15,520 --> 00:50:17,599
don't feel comfortable and with an ai

1451
00:50:17,599 --> 00:50:20,640
i'm running the grid and the ceo said

1452
00:50:20,640 --> 00:50:22,880
neither am i but it's coming and so we

1453
00:50:22,880 --> 00:50:24,960
need to start now understanding what

1454
00:50:24,960 --> 00:50:26,960
that means and i think that's what uh

1455
00:50:26,960 --> 00:50:28,960
you know is really the problem now so um

1456
00:50:28,960 --> 00:50:30,319
you know you know military guys we used

1457
00:50:30,319 --> 00:50:31,760
to always talk about the ooda loop or

1458
00:50:31,760 --> 00:50:33,520
humans in the loop i think we're at the

1459
00:50:33,520 --> 00:50:35,520
point now where we have to just uh have

1460
00:50:35,520 --> 00:50:38,000
humans on the loop um those autonomous

1461
00:50:38,000 --> 00:50:40,160
systems need to have boundaries um you

1462
00:50:40,160 --> 00:50:42,079
know i liken it to you know teenagers

1463
00:50:42,079 --> 00:50:44,000
okay you know you come home by ten if

1464
00:50:44,000 --> 00:50:45,839
you're not going to come home by 10 give

1465
00:50:45,839 --> 00:50:47,599
me a call and i'll give you a new set of

1466
00:50:47,599 --> 00:50:49,440
uh you know guidelines so you know as

1467
00:50:49,440 --> 00:50:51,119
these autonomous systems are approaching

1468
00:50:51,119 --> 00:50:53,119
their limits they should be able to talk

1469
00:50:53,119 --> 00:50:55,119
to that that human you know absolute

1470
00:50:55,119 --> 00:50:56,960
decide and say hey i'm seeing something

1471
00:50:56,960 --> 00:50:59,359
that's outside of my purview do i turn

1472
00:50:59,359 --> 00:51:00,559
it over to you are you going to give me

1473
00:51:00,559 --> 00:51:03,200
some extra instructions um but until we

1474
00:51:03,200 --> 00:51:05,520
understand exactly you know what the

1475
00:51:05,520 --> 00:51:06,880
um

1476
00:51:06,880 --> 00:51:09,760
our capability to make uh an artificial

1477
00:51:09,760 --> 00:51:11,520
intelligence or an autonomous system you

1478
00:51:11,520 --> 00:51:13,680
know that's uh that's trustworthy um

1479
00:51:13,680 --> 00:51:15,839
then i'll i'll be the last one to have a

1480
00:51:15,839 --> 00:51:18,000
car like that i'll argue that humans are

1481
00:51:18,000 --> 00:51:19,920
in the loop it's where they're in the

1482
00:51:19,920 --> 00:51:22,079
loop the loop may be at the beginning

1483
00:51:22,079 --> 00:51:23,440
when they're writing the code for the

1484
00:51:23,440 --> 00:51:25,119
automatic system

1485
00:51:25,119 --> 00:51:27,599
and and yet they're making decisions on

1486
00:51:27,599 --> 00:51:30,000
those limits on those constraints and

1487
00:51:30,000 --> 00:51:31,520
combining that in the software that may

1488
00:51:31,520 --> 00:51:33,359
be imperfect it may have flaws it may

1489
00:51:33,359 --> 00:51:35,280
have problematic and that's why you do

1490
00:51:35,280 --> 00:51:36,480
the testing

1491
00:51:36,480 --> 00:51:38,640
before you go live before you put it on

1492
00:51:38,640 --> 00:51:40,079
automatic system but

1493
00:51:40,079 --> 00:51:43,200
it's not that the aei isn't understood

1494
00:51:43,200 --> 00:51:44,559
uh

1495
00:51:44,559 --> 00:51:46,559
you know bayesian belief network they're

1496
00:51:46,559 --> 00:51:48,960
well understood easily explain the

1497
00:51:48,960 --> 00:51:50,880
process and the math

1498
00:51:50,880 --> 00:51:53,520
but you go into some of the

1499
00:51:53,520 --> 00:51:55,440
deep learning techniques

1500
00:51:55,440 --> 00:51:57,680
well you may not be able to say how the

1501
00:51:57,680 --> 00:51:59,920
math got to that answer but you know the

1502
00:51:59,920 --> 00:52:02,480
process it could get there so is that

1503
00:52:02,480 --> 00:52:05,599
well enough understood to say i trust it

1504
00:52:05,599 --> 00:52:07,760
the answers are not going to be perfect

1505
00:52:07,760 --> 00:52:09,200
but are they better than what you have

1506
00:52:09,200 --> 00:52:10,640
today

1507
00:52:10,640 --> 00:52:12,640
the speed you brought up zach is

1508
00:52:12,640 --> 00:52:14,240
critical

1509
00:52:14,240 --> 00:52:16,319
you know if you want the superman

1510
00:52:16,319 --> 00:52:18,480
approach you know faster than a speeding

1511
00:52:18,480 --> 00:52:20,800
bullet well you know

1512
00:52:20,800 --> 00:52:23,040
our response time has got to be faster

1513
00:52:23,040 --> 00:52:24,160
than the speeding bullet it's going to

1514
00:52:24,160 --> 00:52:27,119
be faster than superman and to do that

1515
00:52:27,119 --> 00:52:28,559
the human has to be in the loop at the

1516
00:52:28,559 --> 00:52:29,520
beginning

1517
00:52:29,520 --> 00:52:31,040
not in the middle of the process or

1518
00:52:31,040 --> 00:52:32,720
you've lost already

1519
00:52:32,720 --> 00:52:34,079
david you were talking about using

1520
00:52:34,079 --> 00:52:35,920
machine learning for some of the

1521
00:52:35,920 --> 00:52:37,839
observation and detection

1522
00:52:37,839 --> 00:52:39,839
yeah what are you

1523
00:52:39,839 --> 00:52:42,000
seeing there so

1524
00:52:42,000 --> 00:52:43,440
um i think

1525
00:52:43,440 --> 00:52:45,520
our artificial intelligence and machine

1526
00:52:45,520 --> 00:52:48,480
learning you know in in recent

1527
00:52:48,480 --> 00:52:51,440
memory have really been oversold

1528
00:52:51,440 --> 00:52:54,400
and and in particular

1529
00:52:54,400 --> 00:52:55,440
you know when you look at machine

1530
00:52:55,440 --> 00:52:57,119
learning or ai you can there's

1531
00:52:57,119 --> 00:52:58,319
interpretable

1532
00:52:58,319 --> 00:53:00,880
which is like there's a model that is

1533
00:53:00,880 --> 00:53:02,079
simple enough that a person can

1534
00:53:02,079 --> 00:53:04,319
understand it and then there's like the

1535
00:53:04,319 --> 00:53:06,800
non-interpretable which is like

1536
00:53:06,800 --> 00:53:09,200
you know there's a neural network which

1537
00:53:09,200 --> 00:53:10,720
you know when i train it on this data it

1538
00:53:10,720 --> 00:53:12,480
gets really good results when i test it

1539
00:53:12,480 --> 00:53:14,960
on that data which is no guarantee in

1540
00:53:14,960 --> 00:53:16,480
the real world right

1541
00:53:16,480 --> 00:53:17,599
um

1542
00:53:17,599 --> 00:53:19,520
and i i think you know during the i

1543
00:53:19,520 --> 00:53:21,599
don't know the last uh

1544
00:53:21,599 --> 00:53:23,520
10 years right like if if you pay

1545
00:53:23,520 --> 00:53:24,960
attention to the gartner hype cycle

1546
00:53:24,960 --> 00:53:26,720
right i think that's

1547
00:53:26,720 --> 00:53:28,319
there's some good insight in that right

1548
00:53:28,319 --> 00:53:30,240
so what the i don't know machine

1549
00:53:30,240 --> 00:53:32,640
learning is somewhere on the uh

1550
00:53:32,640 --> 00:53:34,000
the the

1551
00:53:34,000 --> 00:53:35,760
i i forgot all the jargon in the in the

1552
00:53:35,760 --> 00:53:37,760
hype cycle it's like the

1553
00:53:37,760 --> 00:53:39,119
we're headed into the trough of

1554
00:53:39,119 --> 00:53:41,040
disillusionment or something like that

1555
00:53:41,040 --> 00:53:42,400
according to them

1556
00:53:42,400 --> 00:53:44,880
but there's an intuitive understanding

1557
00:53:44,880 --> 00:53:47,040
that's hard to get with math

1558
00:53:47,040 --> 00:53:49,599
when it's very complex math i mean

1559
00:53:49,599 --> 00:53:51,119
you're you're talking about nonlinear

1560
00:53:51,119 --> 00:53:53,040
dynamics in one of most of these

1561
00:53:53,040 --> 00:53:54,880
equations and chaos theory starts to

1562
00:53:54,880 --> 00:53:57,280
play again but when you're when you've

1563
00:53:57,280 --> 00:53:59,599
got an intuition for it you feel

1564
00:53:59,599 --> 00:54:01,440
comfortable with it because you

1565
00:54:01,440 --> 00:54:03,440
understand how it got to the decision it

1566
00:54:03,440 --> 00:54:04,880
made

1567
00:54:04,880 --> 00:54:06,800
when it's a process you either got to

1568
00:54:06,800 --> 00:54:08,960
believe in the process or you don't and

1569
00:54:08,960 --> 00:54:10,960
that's done through repetition it's it's

1570
00:54:10,960 --> 00:54:13,359
proven time and time again almost like a

1571
00:54:13,359 --> 00:54:15,599
monte carlo simulation you run it with

1572
00:54:15,599 --> 00:54:17,040
every possible variable in every

1573
00:54:17,040 --> 00:54:20,240
possible way and here's the statistics

1574
00:54:20,240 --> 00:54:21,760
but the state explosion there it's hard

1575
00:54:21,760 --> 00:54:24,319
so um you know a friend at the office of

1576
00:54:24,319 --> 00:54:26,000
science at doe talks about the fact that

1577
00:54:26,000 --> 00:54:27,520
you know he doesn't believe in

1578
00:54:27,520 --> 00:54:29,760
explainable ai you know you can take a a

1579
00:54:29,760 --> 00:54:32,480
photo and uh and and give it to to an ai

1580
00:54:32,480 --> 00:54:33,920
and it'll tell you you know it's a dog

1581
00:54:33,920 --> 00:54:35,839
and you change three pixels yeah you

1582
00:54:35,839 --> 00:54:38,000
know and it's a person right and it can

1583
00:54:38,000 --> 00:54:40,240
explain both sides yeah right so you

1584
00:54:40,240 --> 00:54:41,920
know and it may not have been either one

1585
00:54:41,920 --> 00:54:44,720
but there's your bias in data and so the

1586
00:54:44,720 --> 00:54:47,040
data collection decision

1587
00:54:47,040 --> 00:54:48,799
may be where you insert a bias that

1588
00:54:48,799 --> 00:54:51,040
gives you an answer that's

1589
00:54:51,040 --> 00:54:52,480
obviously wrong or once again your

1590
00:54:52,480 --> 00:54:54,079
sensor just you know been a different

1591
00:54:54,079 --> 00:54:56,000
light you know the same same object

1592
00:54:56,000 --> 00:54:58,400
right well the whole adversarial machine

1593
00:54:58,400 --> 00:55:00,640
learning and that i was thinking about

1594
00:55:00,640 --> 00:55:03,200
this during your talk as well is that

1595
00:55:03,200 --> 00:55:04,640
um if you have something that's

1596
00:55:04,640 --> 00:55:06,160
continuing to learn while it's in

1597
00:55:06,160 --> 00:55:07,359
operation

1598
00:55:07,359 --> 00:55:10,000
it can be trained to ignore things that

1599
00:55:10,000 --> 00:55:11,920
you wanted to ignore this is a common

1600
00:55:11,920 --> 00:55:12,960
problem that's been around with

1601
00:55:12,960 --> 00:55:14,720
intrusion detection for a while

1602
00:55:14,720 --> 00:55:15,839
but really the whole notion of

1603
00:55:15,839 --> 00:55:18,319
adversarial machine learning is is only

1604
00:55:18,319 --> 00:55:19,920
i've only heard that term over the last

1605
00:55:19,920 --> 00:55:21,280
few years

1606
00:55:21,280 --> 00:55:23,599
maybe it's been around longer but

1607
00:55:23,599 --> 00:55:27,680
we're getting to that point there's um

1608
00:55:28,240 --> 00:55:30,079
i want to make sure to to be clear on

1609
00:55:30,079 --> 00:55:32,880
the ai and ml right i'm a big fan of ai

1610
00:55:32,880 --> 00:55:35,359
and ml as long as it's like simple and

1611
00:55:35,359 --> 00:55:38,000
interpretable and we can feel you know

1612
00:55:38,000 --> 00:55:39,359
the the people who designed it

1613
00:55:39,359 --> 00:55:40,720
understands like if it gives you this

1614
00:55:40,720 --> 00:55:42,079
answer i can tell you why it gave you

1615
00:55:42,079 --> 00:55:43,280
that answer

1616
00:55:43,280 --> 00:55:45,280
and that's really it's the best way to

1617
00:55:45,280 --> 00:55:47,119
handle large volumes of data right so we

1618
00:55:47,119 --> 00:55:48,880
totally should be invested in that but

1619
00:55:48,880 --> 00:55:50,720
then there's like other categories of ai

1620
00:55:50,720 --> 00:55:53,359
and ml which are like too complex and we

1621
00:55:53,359 --> 00:55:56,400
should reject people who propose like

1622
00:55:56,400 --> 00:55:58,160
uh

1623
00:55:58,160 --> 00:56:00,480
you know using something that isn't

1624
00:56:00,480 --> 00:56:02,799
interpretable there is a professor whose

1625
00:56:02,799 --> 00:56:04,559
name i cannot recall

1626
00:56:04,559 --> 00:56:05,680
but

1627
00:56:05,680 --> 00:56:09,119
she publishes in the natural sciences

1628
00:56:09,119 --> 00:56:12,319
and she is on a campaign of

1629
00:56:12,319 --> 00:56:13,359
uh

1630
00:56:13,359 --> 00:56:17,280
reject explainable ai and embrace

1631
00:56:17,280 --> 00:56:19,200
interpretable machine learning

1632
00:56:19,200 --> 00:56:21,119
and so i don't want to like misstate her

1633
00:56:21,119 --> 00:56:22,400
but this

1634
00:56:22,400 --> 00:56:23,520
what

1635
00:56:23,520 --> 00:56:25,280
there's a lot of really valid points

1636
00:56:25,280 --> 00:56:27,200
around this ex there's this

1637
00:56:27,200 --> 00:56:28,559
explainability

1638
00:56:28,559 --> 00:56:30,640
paradigm that's been introduced which is

1639
00:56:30,640 --> 00:56:32,400
something like this right i have this

1640
00:56:32,400 --> 00:56:34,240
data i'm going to analyze it with some

1641
00:56:34,240 --> 00:56:36,640
ml thing and it's really complex and i

1642
00:56:36,640 --> 00:56:38,240
don't understand why it works so i'll

1643
00:56:38,240 --> 00:56:39,760
build like a simpler version of the

1644
00:56:39,760 --> 00:56:41,920
complex thing to explain

1645
00:56:41,920 --> 00:56:43,760
what the complex thing is thinking when

1646
00:56:43,760 --> 00:56:45,359
it tells you something right so instead

1647
00:56:45,359 --> 00:56:47,040
of like taking

1648
00:56:47,040 --> 00:56:48,400
the approach of saying no no we're going

1649
00:56:48,400 --> 00:56:50,000
to go with an interpretable model

1650
00:56:50,000 --> 00:56:51,280
instead it's like no i'm going to build

1651
00:56:51,280 --> 00:56:52,640
a second thing

1652
00:56:52,640 --> 00:56:54,000
second complex thing to explain the

1653
00:56:54,000 --> 00:56:56,480
first complex thing and and then

1654
00:56:56,480 --> 00:56:57,440
so

1655
00:56:57,440 --> 00:56:59,359
i think she builds a good case in the

1656
00:56:59,359 --> 00:57:01,440
natural sciences and i i think we should

1657
00:57:01,440 --> 00:57:02,799
be paying attention to it in cyber

1658
00:57:02,799 --> 00:57:04,480
security well i mean i think part of the

1659
00:57:04,480 --> 00:57:05,839
other you know thing we have is you know

1660
00:57:05,839 --> 00:57:08,240
continuous learning um which we all talk

1661
00:57:08,240 --> 00:57:10,319
about if uh um you know you have a

1662
00:57:10,319 --> 00:57:11,760
self-driving you know vehicle an

1663
00:57:11,760 --> 00:57:13,760
autonomous vehicle and it comes across a

1664
00:57:13,760 --> 00:57:15,359
situation that it doesn't understand and

1665
00:57:15,359 --> 00:57:17,760
the human takes over and now learns and

1666
00:57:17,760 --> 00:57:19,680
so once again i go back to you know you

1667
00:57:19,680 --> 00:57:21,280
know anyone here who has uh you know

1668
00:57:21,280 --> 00:57:23,200
raised children or you know watched uh

1669
00:57:23,200 --> 00:57:24,960
somehow someone else raised children and

1670
00:57:24,960 --> 00:57:26,480
you you know put all this input and

1671
00:57:26,480 --> 00:57:28,160
training and everything and all of a

1672
00:57:28,160 --> 00:57:29,839
sudden they come out with some random

1673
00:57:29,839 --> 00:57:31,280
output and said you know where did you

1674
00:57:31,280 --> 00:57:32,799
learn that i'm like i don't know and it

1675
00:57:32,799 --> 00:57:34,480
was at school or in the playground or

1676
00:57:34,480 --> 00:57:36,160
something else so if you allow a system

1677
00:57:36,160 --> 00:57:37,520
to continuously learn you better be

1678
00:57:37,520 --> 00:57:40,079
watching all of those inputs um as you

1679
00:57:40,079 --> 00:57:41,760
said before you know ai tainting and

1680
00:57:41,760 --> 00:57:43,440
others because you're going to get

1681
00:57:43,440 --> 00:57:46,319
unexpected results because the learning

1682
00:57:46,319 --> 00:57:49,599
continues i saw a really good example uh

1683
00:57:49,599 --> 00:57:52,559
two days ago online from someone about

1684
00:57:52,559 --> 00:57:54,880
training up a system to recognize with

1685
00:57:54,880 --> 00:57:56,880
it was semantic it wasn't

1686
00:57:56,880 --> 00:57:59,440
particular data but that uh defining a

1687
00:57:59,440 --> 00:58:00,400
chair

1688
00:58:00,400 --> 00:58:02,799
as uh something people sit on that has a

1689
00:58:02,799 --> 00:58:05,119
back and four legs

1690
00:58:05,119 --> 00:58:06,000
um

1691
00:58:06,000 --> 00:58:09,400
that's a horse

1692
00:58:09,440 --> 00:58:11,040
and and so

1693
00:58:11,040 --> 00:58:13,280
thinking about somewhat outside the box

1694
00:58:13,280 --> 00:58:15,760
of the definitions and and

1695
00:58:15,760 --> 00:58:17,280
that leads us into some interesting

1696
00:58:17,280 --> 00:58:18,480
directions

1697
00:58:18,480 --> 00:58:20,960
which we don't have time to explore

1698
00:58:20,960 --> 00:58:23,200
because we've sort of hit the end of our

1699
00:58:23,200 --> 00:58:24,640
time i think we could probably go on in

1700
00:58:24,640 --> 00:58:25,760
this for

1701
00:58:25,760 --> 00:58:27,599
for uh quite a bit longer

1702
00:58:27,599 --> 00:58:29,119
but um

1703
00:58:29,119 --> 00:58:30,640
zach you said you have to leave a little

1704
00:58:30,640 --> 00:58:31,760
bit early

1705
00:58:31,760 --> 00:58:33,280
but you're around tomorrow to give a

1706
00:58:33,280 --> 00:58:36,319
talk so uh i would encourage all of you

1707
00:58:36,319 --> 00:58:38,880
uh if you have a chance maybe at lunch

1708
00:58:38,880 --> 00:58:40,720
to uh

1709
00:58:40,720 --> 00:58:42,880
follow up with any of the panel here

1710
00:58:42,880 --> 00:58:44,720
that you're interested in talking to

1711
00:58:44,720 --> 00:58:46,960
thank you so much for your attention and

1712
00:58:46,960 --> 00:58:50,680
now we go to a break

1713
00:59:02,559 --> 00:59:04,640
you

