1
00:00:00,480 --> 00:00:03,120
so welcome again to the wednesday

2
00:00:03,120 --> 00:00:04,640
security seminar

3
00:00:04,640 --> 00:00:06,480
um

4
00:00:06,480 --> 00:00:09,280
as a reminder to everyone who is

5
00:00:09,280 --> 00:00:12,160
uh joining us

6
00:00:12,160 --> 00:00:14,400
if you have a question for our speaker

7
00:00:14,400 --> 00:00:16,560
please post it in the q a

8
00:00:16,560 --> 00:00:19,039
and not the chat

9
00:00:19,039 --> 00:00:20,720
because we'll be taking the questions

10
00:00:20,720 --> 00:00:23,359
from the q a afterwards

11
00:00:23,359 --> 00:00:25,519
and as to our speaker

12
00:00:25,519 --> 00:00:28,160
we're really pleased today to have

13
00:00:28,160 --> 00:00:32,238
alyssa miller and alyssa's bio is on the

14
00:00:32,238 --> 00:00:34,239
website and she

15
00:00:34,239 --> 00:00:36,239
indicates she's the business information

16
00:00:36,239 --> 00:00:39,440
security officer for s p global

17
00:00:39,440 --> 00:00:42,399
which is a role where she

18
00:00:42,399 --> 00:00:45,440
brings connectivity between the business

19
00:00:45,440 --> 00:00:47,520
side and the security side

20
00:00:47,520 --> 00:00:50,239
of business to get

21
00:00:50,239 --> 00:00:52,160
people on both sides to work together

22
00:00:52,160 --> 00:00:53,440
which is

23
00:00:53,440 --> 00:00:56,239
much to be desired in most organizations

24
00:00:56,239 --> 00:00:58,399
but interestingly her career has taken

25
00:00:58,399 --> 00:01:00,399
her from a

26
00:01:00,399 --> 00:01:01,840
junior hacker

27
00:01:01,840 --> 00:01:05,040
to programmer to penetration tester to

28
00:01:05,040 --> 00:01:07,360
an industry leader where she has been

29
00:01:07,360 --> 00:01:08,880
involved in

30
00:01:08,880 --> 00:01:12,240
uh many initiatives and she's a an

31
00:01:12,240 --> 00:01:14,640
established speaker on the circuit and

32
00:01:14,640 --> 00:01:16,640
has a book coming out soon that's not

33
00:01:16,640 --> 00:01:18,799
listed in the bio online she's the

34
00:01:18,799 --> 00:01:20,720
author of the cyber defenders career

35
00:01:20,720 --> 00:01:23,759
guide which will be coming out uh soon

36
00:01:23,759 --> 00:01:25,520
do you have a publication date on that

37
00:01:25,520 --> 00:01:27,680
alyssa yeah so they changed the title

38
00:01:27,680 --> 00:01:30,240
it's cyber security career guide now

39
00:01:30,240 --> 00:01:32,960
okay publishers are fun to work with uh

40
00:01:32,960 --> 00:01:35,040
but yeah it should be um i actually just

41
00:01:35,040 --> 00:01:36,400
got an email a little before this

42
00:01:36,400 --> 00:01:38,159
meeting because it is officially going

43
00:01:38,159 --> 00:01:39,840
to production now so they're expecting

44
00:01:39,840 --> 00:01:42,320
about three months before it will be

45
00:01:42,320 --> 00:01:44,079
available in print

46
00:01:44,079 --> 00:01:46,880
it's already available for pre-purchase

47
00:01:46,880 --> 00:01:48,399
where you can actually

48
00:01:48,399 --> 00:01:50,880
re start reading the draft copy of the

49
00:01:50,880 --> 00:01:52,720
book so that's good

50
00:01:52,720 --> 00:01:54,880
yeah well well this is from somebody

51
00:01:54,880 --> 00:01:57,520
with a long career in cyber security so

52
00:01:57,520 --> 00:01:58,960
those of you who are interested may want

53
00:01:58,960 --> 00:02:01,439
to look that up and uh actually we've

54
00:02:01,439 --> 00:02:03,280
had several speakers here recently

55
00:02:03,280 --> 00:02:04,240
who've

56
00:02:04,240 --> 00:02:05,840
been uh

57
00:02:05,840 --> 00:02:07,520
writing about cyber security helen

58
00:02:07,520 --> 00:02:10,720
patton spoke a couple weeks ago and so

59
00:02:10,720 --> 00:02:12,560
i would encourage

60
00:02:12,560 --> 00:02:14,640
the students in particular to think

61
00:02:14,640 --> 00:02:16,080
about looking at these if you're

62
00:02:16,080 --> 00:02:18,080
considering your career but rather than

63
00:02:18,080 --> 00:02:20,000
take any further time let me turn it

64
00:02:20,000 --> 00:02:22,480
over to alyssa and uh

65
00:02:22,480 --> 00:02:24,239
alyssa thank you so much you'll be

66
00:02:24,239 --> 00:02:26,000
telling us about threat modeling in the

67
00:02:26,000 --> 00:02:27,840
world of devops

68
00:02:27,840 --> 00:02:30,239
yeah so thank you first of all and what

69
00:02:30,239 --> 00:02:32,480
an awesome introduction

70
00:02:32,480 --> 00:02:33,440
um

71
00:02:33,440 --> 00:02:35,840
so uh stop me if you're not seeing the

72
00:02:35,840 --> 00:02:37,760
right slides um but i think we should be

73
00:02:37,760 --> 00:02:39,599
good to go here so

74
00:02:39,599 --> 00:02:40,480
um

75
00:02:40,480 --> 00:02:43,280
yeah i i appreciate you know the

76
00:02:43,280 --> 00:02:44,560
opportunity to be here talking to all of

77
00:02:44,560 --> 00:02:45,920
you this evening

78
00:02:45,920 --> 00:02:46,800
and

79
00:02:46,800 --> 00:02:48,319
you know i want to start off actually

80
00:02:48,319 --> 00:02:50,720
with a little story um

81
00:02:50,720 --> 00:02:51,760
so

82
00:02:51,760 --> 00:02:53,760
i travel a lot to speak at different

83
00:02:53,760 --> 00:02:55,760
conferences um

84
00:02:55,760 --> 00:02:58,080
and i also travel a lot for work and

85
00:02:58,080 --> 00:02:59,440
you know so kova has been kind of

86
00:02:59,440 --> 00:03:01,360
interesting because there hasn't been a

87
00:03:01,360 --> 00:03:02,840
lot of travel

88
00:03:02,840 --> 00:03:04,560
but

89
00:03:04,560 --> 00:03:06,879
getting back to traveling

90
00:03:06,879 --> 00:03:08,959
uh sort of middle of last year was the

91
00:03:08,959 --> 00:03:11,120
first time i got to fly since the start

92
00:03:11,120 --> 00:03:13,040
of the pandemic

93
00:03:13,040 --> 00:03:14,080
and

94
00:03:14,080 --> 00:03:16,800
you know so i went on i i was flying out

95
00:03:16,800 --> 00:03:19,200
to reno nevada and for a conference and

96
00:03:19,200 --> 00:03:22,080
i needed to book flights and so

97
00:03:22,080 --> 00:03:23,760
yeah i started looking at different

98
00:03:23,760 --> 00:03:25,760
flights as i always do and one thing

99
00:03:25,760 --> 00:03:28,239
that always has stuck with me that i

100
00:03:28,239 --> 00:03:30,080
learned early on as a traveling

101
00:03:30,080 --> 00:03:33,519
consultant was plan your layovers

102
00:03:33,519 --> 00:03:35,519
appropriately

103
00:03:35,519 --> 00:03:37,959
and so you know you go on to like

104
00:03:37,959 --> 00:03:40,640
delta.com and and you look at you know

105
00:03:40,640 --> 00:03:42,080
you're gonna book a flight and you'll

106
00:03:42,080 --> 00:03:43,680
see they show you the layovers a lot of

107
00:03:43,680 --> 00:03:46,640
them are like 45 minutes or maybe an

108
00:03:46,640 --> 00:03:47,760
hour

109
00:03:47,760 --> 00:03:49,760
and you know i'm like

110
00:03:49,760 --> 00:03:51,840
all right i i really i can't afford to

111
00:03:51,840 --> 00:03:53,280
be delayed

112
00:03:53,280 --> 00:03:55,519
um you know i'll end up missing

113
00:03:55,519 --> 00:03:58,400
my speaking slot at this conference

114
00:03:58,400 --> 00:04:01,200
um so i'm looking at you know the the

115
00:04:01,200 --> 00:04:03,360
various options available

116
00:04:03,360 --> 00:04:05,040
and all the flights that i was seeing

117
00:04:05,040 --> 00:04:07,519
were flying that had the right arrival

118
00:04:07,519 --> 00:04:10,159
times were flying through salt lake city

119
00:04:10,159 --> 00:04:11,680
now i'd never been to salt lake city

120
00:04:11,680 --> 00:04:12,720
before i'd never been through that

121
00:04:12,720 --> 00:04:15,280
airport before and so that already makes

122
00:04:15,280 --> 00:04:16,959
me nervous right when i'm i'm talking

123
00:04:16,959 --> 00:04:19,199
about an airport that i don't really

124
00:04:19,199 --> 00:04:20,079
know

125
00:04:20,079 --> 00:04:21,040
and

126
00:04:21,040 --> 00:04:21,839
so

127
00:04:21,839 --> 00:04:23,440
i'm the type of person i'd rather spend

128
00:04:23,440 --> 00:04:25,280
hours sitting in an airport than rushing

129
00:04:25,280 --> 00:04:29,440
for a flight so i booked a set of

130
00:04:29,440 --> 00:04:31,600
flights that had a two and a half hour

131
00:04:31,600 --> 00:04:33,199
layover

132
00:04:33,199 --> 00:04:35,280
instead of the one that was available

133
00:04:35,280 --> 00:04:37,759
that had a 40 minute layover would have

134
00:04:37,759 --> 00:04:39,759
gotten me out to reno obviously a few

135
00:04:39,759 --> 00:04:41,199
hours sooner

136
00:04:41,199 --> 00:04:44,400
but i i wanted a longer layover just in

137
00:04:44,400 --> 00:04:45,840
case

138
00:04:45,840 --> 00:04:47,759
well it turned out when i landed it was

139
00:04:47,759 --> 00:04:49,919
a really good thing because this

140
00:04:49,919 --> 00:04:52,160
was taken after we landed

141
00:04:52,160 --> 00:04:55,840
and this is our plane parked on the

142
00:04:55,840 --> 00:04:57,199
tarmac

143
00:04:57,199 --> 00:05:00,479
a mile from the terminal

144
00:05:00,479 --> 00:05:01,680
because

145
00:05:01,680 --> 00:05:03,919
unknown to me the terminal is under

146
00:05:03,919 --> 00:05:05,680
massive construction because they

147
00:05:05,680 --> 00:05:07,360
actually just built a whole brand new

148
00:05:07,360 --> 00:05:09,520
airport in salt lake city i did not know

149
00:05:09,520 --> 00:05:10,720
this

150
00:05:10,720 --> 00:05:11,919
so

151
00:05:11,919 --> 00:05:14,400
how you get from there a mile away from

152
00:05:14,400 --> 00:05:16,720
the terminal over to the terminal is you

153
00:05:16,720 --> 00:05:18,880
have to get on buses and the buses take

154
00:05:18,880 --> 00:05:19,919
you over

155
00:05:19,919 --> 00:05:21,600
and there's multiple shuttle buses and

156
00:05:21,600 --> 00:05:22,639
of course they're not sitting there

157
00:05:22,639 --> 00:05:24,720
waiting for you when the plane lands so

158
00:05:24,720 --> 00:05:26,000
you get off the plane and now you gotta

159
00:05:26,000 --> 00:05:27,280
wait for the bus to show up and the bus

160
00:05:27,280 --> 00:05:28,560
shows up you get on the bus you go over

161
00:05:28,560 --> 00:05:29,759
to the terminal

162
00:05:29,759 --> 00:05:32,080
took a long time

163
00:05:32,080 --> 00:05:34,560
had i had that 40 minute layover

164
00:05:34,560 --> 00:05:36,479
there is no way

165
00:05:36,479 --> 00:05:38,160
that i would have made that connecting

166
00:05:38,160 --> 00:05:39,360
flight

167
00:05:39,360 --> 00:05:40,720
and then it would have been scrambling

168
00:05:40,720 --> 00:05:42,240
hoping that it could find another flight

169
00:05:42,240 --> 00:05:44,240
to get on

170
00:05:44,240 --> 00:05:45,120
so

171
00:05:45,120 --> 00:05:47,680
what happened here

172
00:05:47,680 --> 00:05:50,880
i i looked at a situation i asked myself

173
00:05:50,880 --> 00:05:52,479
okay

174
00:05:52,479 --> 00:05:54,320
you know what what could happen here

175
00:05:54,320 --> 00:05:55,840
what could go wrong

176
00:05:55,840 --> 00:05:58,000
and then kind of thinking about that i i

177
00:05:58,000 --> 00:05:59,840
took some action

178
00:05:59,840 --> 00:06:02,080
so

179
00:06:02,560 --> 00:06:04,960
that's threat modeling

180
00:06:04,960 --> 00:06:06,800
this is what threat modeling is all

181
00:06:06,800 --> 00:06:09,120
about it's something that inherently we

182
00:06:09,120 --> 00:06:11,120
all understand

183
00:06:11,120 --> 00:06:13,360
just as human beings we do it all the

184
00:06:13,360 --> 00:06:15,680
time

185
00:06:16,240 --> 00:06:18,160
so that's what we're talking about but

186
00:06:18,160 --> 00:06:19,360
we're going to apply this to cyber

187
00:06:19,360 --> 00:06:21,039
security but before i get started just a

188
00:06:21,039 --> 00:06:23,039
really quick intro

189
00:06:23,039 --> 00:06:24,800
gene ra did most of it for me so i don't

190
00:06:24,800 --> 00:06:26,639
really have to uh give you a whole lot

191
00:06:26,639 --> 00:06:28,960
but yeah i am a hacker and a researcher

192
00:06:28,960 --> 00:06:31,120
um i've been a hacker all my life

193
00:06:31,120 --> 00:06:32,720
uh gee and i were talking before we got

194
00:06:32,720 --> 00:06:34,400
started about the fact that at 12 years

195
00:06:34,400 --> 00:06:37,039
old i was breaking into a service called

196
00:06:37,039 --> 00:06:40,080
prodigy um which probably most of you

197
00:06:40,080 --> 00:06:41,440
i don't even know if any of you remember

198
00:06:41,440 --> 00:06:43,600
that hey if you do great you're you're

199
00:06:43,600 --> 00:06:46,240
older like me if not don't feel bad

200
00:06:46,240 --> 00:06:48,319
basically it was a online community that

201
00:06:48,319 --> 00:06:49,840
you dialed up to directly this was

202
00:06:49,840 --> 00:06:52,479
before we had the internet

203
00:06:52,479 --> 00:06:54,880
i am also as was mentioned business

204
00:06:54,880 --> 00:06:56,639
information security officer from s p

205
00:06:56,639 --> 00:06:57,919
global ratings if you want more

206
00:06:57,919 --> 00:06:59,759
information about what exactly it is i

207
00:06:59,759 --> 00:07:02,240
do i did actually blog on this about a

208
00:07:02,240 --> 00:07:04,160
year ago just because people kept asking

209
00:07:04,160 --> 00:07:06,319
me what the heck is abiso

210
00:07:06,319 --> 00:07:09,120
um author and blogger as we talked about

211
00:07:09,120 --> 00:07:11,919
and also a former software developer

212
00:07:11,919 --> 00:07:13,840
so my

213
00:07:13,840 --> 00:07:16,000
you know path into tech actually started

214
00:07:16,000 --> 00:07:17,440
with

215
00:07:17,440 --> 00:07:20,479
developing software

216
00:07:20,800 --> 00:07:22,639
now let's get back to that threat

217
00:07:22,639 --> 00:07:24,000
modeling thing

218
00:07:24,000 --> 00:07:26,319
so when i talk about threat modeling

219
00:07:26,319 --> 00:07:27,840
unfortunately the picture that a lot of

220
00:07:27,840 --> 00:07:30,160
people have in their minds is of these

221
00:07:30,160 --> 00:07:32,800
really complex ideas

222
00:07:32,800 --> 00:07:36,000
um you know the typical process is that

223
00:07:36,000 --> 00:07:39,440
people know threat modeling for in the

224
00:07:39,440 --> 00:07:41,599
software and cyber security senses we

225
00:07:41,599 --> 00:07:43,440
start by creating all these diagrams

226
00:07:43,440 --> 00:07:46,000
they talk about where the data flows in

227
00:07:46,000 --> 00:07:47,759
our application where it gets stored

228
00:07:47,759 --> 00:07:49,919
where it crosses trust boundaries all

229
00:07:49,919 --> 00:07:52,639
these things so you drop all of this

230
00:07:52,639 --> 00:07:54,879
stuff and then you get a bunch of people

231
00:07:54,879 --> 00:07:57,360
you talked about the the threats

232
00:07:57,360 --> 00:07:58,879
what are the threats that it faces and

233
00:07:58,879 --> 00:07:59,919
you

234
00:07:59,919 --> 00:08:01,599
well you categorize those threats

235
00:08:01,599 --> 00:08:02,960
according to

236
00:08:02,960 --> 00:08:06,160
stride this this framework that we have

237
00:08:06,160 --> 00:08:08,160
for how we classify

238
00:08:08,160 --> 00:08:10,560
our our threats and understand the

239
00:08:10,560 --> 00:08:12,080
different types of threats that we might

240
00:08:12,080 --> 00:08:13,280
face

241
00:08:13,280 --> 00:08:14,560
well and then we have this pasta

242
00:08:14,560 --> 00:08:16,560
methodology that well we could leverage

243
00:08:16,560 --> 00:08:18,639
that and that helps build us out that

244
00:08:18,639 --> 00:08:20,080
talks about how we actually do the

245
00:08:20,080 --> 00:08:22,560
threat modeling and you can see you know

246
00:08:22,560 --> 00:08:25,120
define your objectives and a scope and

247
00:08:25,120 --> 00:08:28,800
then you have application decomposition

248
00:08:28,800 --> 00:08:30,879
and then well now you've got a threat

249
00:08:30,879 --> 00:08:32,799
analysis then vulnerability and weakness

250
00:08:32,799 --> 00:08:35,519
analysis and attack model i mean okay

251
00:08:35,519 --> 00:08:37,519
this is a lot of work

252
00:08:37,519 --> 00:08:39,200
but then after we've identified all

253
00:08:39,200 --> 00:08:41,039
those threats well now we have to rate

254
00:08:41,039 --> 00:08:43,200
them and prioritize them so we're going

255
00:08:43,200 --> 00:08:45,440
to use this model called dread and

256
00:08:45,440 --> 00:08:47,519
that's going to tell us okay well you

257
00:08:47,519 --> 00:08:49,519
know how bad would the attack be

258
00:08:49,519 --> 00:08:52,320
how easy is it to recreate it how easily

259
00:08:52,320 --> 00:08:54,000
could someone launch an attack yada yada

260
00:08:54,000 --> 00:08:55,839
yada yada all right so we get that so

261
00:08:55,839 --> 00:08:57,680
we've got that framework but then we're

262
00:08:57,680 --> 00:08:59,279
going to throw this octave process on

263
00:08:59,279 --> 00:09:01,600
top of this because that really tells us

264
00:09:01,600 --> 00:09:03,360
hey we can we can look at this from a

265
00:09:03,360 --> 00:09:05,360
couple different viewpoints and here's

266
00:09:05,360 --> 00:09:06,959
how we can take all of what we're doing

267
00:09:06,959 --> 00:09:08,800
and make sure that we understand it from

268
00:09:08,800 --> 00:09:11,120
the business side and the technical side

269
00:09:11,120 --> 00:09:13,120
and well that all seems really complex

270
00:09:13,120 --> 00:09:14,240
so then we came up with this thing

271
00:09:14,240 --> 00:09:17,200
called the catback taxonomy which logs

272
00:09:17,200 --> 00:09:19,440
all sorts of common threats and whatnot

273
00:09:19,440 --> 00:09:21,760
and kind of like if you're used to cbe

274
00:09:21,760 --> 00:09:23,360
and how we use that for vulnerabilities

275
00:09:23,360 --> 00:09:26,480
this is it for threats and

276
00:09:26,480 --> 00:09:28,800
that's a lot of stuff

277
00:09:28,800 --> 00:09:30,480
that's a lot

278
00:09:30,480 --> 00:09:32,959
and the reality is this approach these

279
00:09:32,959 --> 00:09:34,640
approaches to threat modeling it is

280
00:09:34,640 --> 00:09:37,040
really heavyweight

281
00:09:37,040 --> 00:09:40,000
and it relies on

282
00:09:40,000 --> 00:09:43,120
a lot of technical security knowledge

283
00:09:43,120 --> 00:09:45,440
it doesn't necessarily connect us really

284
00:09:45,440 --> 00:09:47,680
well with the business even if we've got

285
00:09:47,680 --> 00:09:50,000
like that organizational view that you

286
00:09:50,000 --> 00:09:52,240
have in the active process it still kind

287
00:09:52,240 --> 00:09:53,920
of misses

288
00:09:53,920 --> 00:09:54,800
and

289
00:09:54,800 --> 00:09:56,880
it's very much point in time because

290
00:09:56,880 --> 00:09:58,959
you're gonna do this process

291
00:09:58,959 --> 00:10:00,480
and

292
00:10:00,480 --> 00:10:02,959
you know okay great i got this picture

293
00:10:02,959 --> 00:10:04,640
but how often can you do that process

294
00:10:04,640 --> 00:10:07,120
when it involves all of that

295
00:10:07,120 --> 00:10:08,880
so this is what we've been doing with

296
00:10:08,880 --> 00:10:10,160
threat model we've been doing it for

297
00:10:10,160 --> 00:10:12,079
over a decade but the problem is this

298
00:10:12,079 --> 00:10:16,519
kind of thinking is so 2008.

299
00:10:16,880 --> 00:10:20,560
hmm why is alyssa say 2008 what's so

300
00:10:20,560 --> 00:10:22,959
special about 2008

301
00:10:22,959 --> 00:10:25,040
well 2008

302
00:10:25,040 --> 00:10:27,360
this thing showed up

303
00:10:27,360 --> 00:10:29,760
devops

304
00:10:29,760 --> 00:10:31,440
patrick dubois and andrew schaefer got

305
00:10:31,440 --> 00:10:32,720
together at a conference they talked

306
00:10:32,720 --> 00:10:35,120
about the idea of how can we make

307
00:10:35,120 --> 00:10:37,440
software deployment development and

308
00:10:37,440 --> 00:10:38,640
deployment

309
00:10:38,640 --> 00:10:40,560
faster and easier how can we get

310
00:10:40,560 --> 00:10:42,880
developers working with our operations

311
00:10:42,880 --> 00:10:44,959
teams and get them working toward a

312
00:10:44,959 --> 00:10:46,800
shared responsibility

313
00:10:46,800 --> 00:10:49,440
and how can we deploy faster and easier

314
00:10:49,440 --> 00:10:51,200
and so they came up with this concept

315
00:10:51,200 --> 00:10:53,279
that we know today is devops

316
00:10:53,279 --> 00:10:54,959
problem is security kind of got left on

317
00:10:54,959 --> 00:10:56,560
the outside

318
00:10:56,560 --> 00:10:58,079
right i mean

319
00:10:58,079 --> 00:10:59,440
okay great so you guys start moving

320
00:10:59,440 --> 00:11:01,600
faster and faster and faster how do we

321
00:11:01,600 --> 00:11:03,760
insecurity keep up with this

322
00:11:03,760 --> 00:11:06,320
well that that's not good

323
00:11:06,320 --> 00:11:08,480
and so you know it wasn't until a number

324
00:11:08,480 --> 00:11:09,920
of years later that we started to hear

325
00:11:09,920 --> 00:11:12,079
this term devsecops where we talked

326
00:11:12,079 --> 00:11:13,440
about the

327
00:11:13,440 --> 00:11:15,600
bringing security into devops but we're

328
00:11:15,600 --> 00:11:17,760
still not really good at it

329
00:11:17,760 --> 00:11:20,160
but threat modeling is one of those ways

330
00:11:20,160 --> 00:11:22,000
that we really can

331
00:11:22,000 --> 00:11:24,160
get involved in it and quite honestly

332
00:11:24,160 --> 00:11:25,839
threat modeling is probably one of the

333
00:11:25,839 --> 00:11:28,079
single most important things we can do

334
00:11:28,079 --> 00:11:30,480
from a security perspective

335
00:11:30,480 --> 00:11:31,440
and

336
00:11:31,440 --> 00:11:33,920
because as i said it's kind of inherent

337
00:11:33,920 --> 00:11:37,360
to what we do just in our daily lives

338
00:11:37,360 --> 00:11:39,279
and when it comes to trying to secure

339
00:11:39,279 --> 00:11:41,519
systems if i don't understand what's

340
00:11:41,519 --> 00:11:43,600
critical to me

341
00:11:43,600 --> 00:11:46,000
and i don't understand the things the

342
00:11:46,000 --> 00:11:48,000
threats that it faces

343
00:11:48,000 --> 00:11:50,639
how am i supposed to secure it

344
00:11:50,639 --> 00:11:53,920
threat modeling gives us that ability

345
00:11:53,920 --> 00:11:55,839
but it's not just me that thinks this

346
00:11:55,839 --> 00:11:59,279
okay so in 2019 oh my god that's three

347
00:11:59,279 --> 00:12:01,279
almost three years ago now

348
00:12:01,279 --> 00:12:04,000
um towards the end of 2019 at least so

349
00:12:04,000 --> 00:12:05,519
it's not that old

350
00:12:05,519 --> 00:12:07,519
puppet and circle ci got together and

351
00:12:07,519 --> 00:12:10,079
they did this state of devops report one

352
00:12:10,079 --> 00:12:12,639
of the things they looked at

353
00:12:12,639 --> 00:12:15,040
was the relative effectiveness of

354
00:12:15,040 --> 00:12:17,440
different security practices

355
00:12:17,440 --> 00:12:20,560
versus how frequently we conduct those

356
00:12:20,560 --> 00:12:22,880
security practices and they laid them on

357
00:12:22,880 --> 00:12:24,399
they came up with this little bit of a

358
00:12:24,399 --> 00:12:26,320
matrix so you see

359
00:12:26,320 --> 00:12:28,639
on the the y-axis there you've got how

360
00:12:28,639 --> 00:12:31,680
frequently we conduct them and on the

361
00:12:31,680 --> 00:12:33,120
x-axis

362
00:12:33,120 --> 00:12:34,240
how

363
00:12:34,240 --> 00:12:36,560
impactful they are to security posture

364
00:12:36,560 --> 00:12:38,639
within the organization

365
00:12:38,639 --> 00:12:40,320
so i know this is kind of tough to read

366
00:12:40,320 --> 00:12:41,920
but let me just walk you through it

367
00:12:41,920 --> 00:12:44,160
verbally really fast upper left corner

368
00:12:44,160 --> 00:12:45,440
there the things we do a lot that don't

369
00:12:45,440 --> 00:12:47,600
have a lot of impact on our security

370
00:12:47,600 --> 00:12:48,959
posture are the things we're used to

371
00:12:48,959 --> 00:12:52,160
hearing about static code analysis uh

372
00:12:52,160 --> 00:12:54,399
dependency checkers penetration testing

373
00:12:54,399 --> 00:12:56,000
that's all up there is this if we do a

374
00:12:56,000 --> 00:12:57,519
lot of it

375
00:12:57,519 --> 00:12:59,519
but doesn't translate into a strong

376
00:12:59,519 --> 00:13:01,600
security posture

377
00:13:01,600 --> 00:13:04,399
but if we go down to the lower right the

378
00:13:04,399 --> 00:13:07,040
things that we do the least

379
00:13:07,040 --> 00:13:09,360
but have the biggest impact

380
00:13:09,360 --> 00:13:11,600
this one right here

381
00:13:11,600 --> 00:13:13,440
security and development teams

382
00:13:13,440 --> 00:13:15,760
collaborating on threat

383
00:13:15,760 --> 00:13:18,160
models

384
00:13:18,480 --> 00:13:20,880
this is it this is they see the same

385
00:13:20,880 --> 00:13:23,279
thing like we can have so much impact

386
00:13:23,279 --> 00:13:24,800
with our threat models but we don't do

387
00:13:24,800 --> 00:13:26,399
it very often

388
00:13:26,399 --> 00:13:28,399
why don't we do it very often well

389
00:13:28,399 --> 00:13:30,079
especially now in the world of devops

390
00:13:30,079 --> 00:13:32,000
our devs look at this and they say i

391
00:13:32,000 --> 00:13:33,519
can't do that in devops i don't have

392
00:13:33,519 --> 00:13:35,279
these long design cycles where i can

393
00:13:35,279 --> 00:13:37,519
create these big diagrams and talk about

394
00:13:37,519 --> 00:13:38,639
this

395
00:13:38,639 --> 00:13:41,279
so i got to thinking all right

396
00:13:41,279 --> 00:13:43,199
how do we go about this i know threat

397
00:13:43,199 --> 00:13:45,360
modeling is important

398
00:13:45,360 --> 00:13:46,320
but

399
00:13:46,320 --> 00:13:48,240
it doesn't fit the way we're doing it

400
00:13:48,240 --> 00:13:49,760
does not fit

401
00:13:49,760 --> 00:13:52,320
so it was time to get back to basics and

402
00:13:52,320 --> 00:13:53,600
if i want to get back to basics about

403
00:13:53,600 --> 00:13:55,040
threat modeling there's two questions i

404
00:13:55,040 --> 00:13:56,160
need to ask

405
00:13:56,160 --> 00:13:57,680
what is it

406
00:13:57,680 --> 00:13:59,199
and why do we do it

407
00:13:59,199 --> 00:14:00,639
i mean i kind of already answered the

408
00:14:00,639 --> 00:14:02,800
why right like oh my gosh look at the

409
00:14:02,800 --> 00:14:04,800
impact it has on our security posture

410
00:14:04,800 --> 00:14:06,160
but let's dig into this a little more in

411
00:14:06,160 --> 00:14:07,519
detail

412
00:14:07,519 --> 00:14:10,079
so i started looking for

413
00:14:10,079 --> 00:14:11,680
definitions of just what is threat

414
00:14:11,680 --> 00:14:14,560
modeling well this was oasp's definition

415
00:14:14,560 --> 00:14:17,680
so open web application security project

416
00:14:17,680 --> 00:14:20,079
they're everything appsack right they

417
00:14:20,079 --> 00:14:21,680
know all of application security it's

418
00:14:21,680 --> 00:14:23,360
their sole focus like they'll know what

419
00:14:23,360 --> 00:14:25,680
it is

420
00:14:25,920 --> 00:14:26,800
wow

421
00:14:26,800 --> 00:14:27,839
look at that

422
00:14:27,839 --> 00:14:30,320
that is one hell of a definition this is

423
00:14:30,320 --> 00:14:32,959
not getting back to basics a lot of you

424
00:14:32,959 --> 00:14:35,120
know technical jargon in here a lot of

425
00:14:35,120 --> 00:14:36,880
security specific jargon in here this

426
00:14:36,880 --> 00:14:38,959
isn't helping anybody so what about

427
00:14:38,959 --> 00:14:40,880
wikipedia if it's on wikipedia it's got

428
00:14:40,880 --> 00:14:42,399
to be true and they've got all the great

429
00:14:42,399 --> 00:14:43,760
stuff you know it's crowdsourced

430
00:14:43,760 --> 00:14:46,160
knowledge it's wonderful

431
00:14:46,160 --> 00:14:49,199
not really doing much better

432
00:14:49,199 --> 00:14:51,360
still really complex really technically

433
00:14:51,360 --> 00:14:53,120
focused we see things like attack

434
00:14:53,120 --> 00:14:56,160
vectors and and you know

435
00:14:56,160 --> 00:14:58,000
vulnerable to attack and relevant

436
00:14:58,000 --> 00:14:59,680
threats and what do these things even

437
00:14:59,680 --> 00:15:00,639
mean

438
00:15:00,639 --> 00:15:03,279
all right well

439
00:15:03,279 --> 00:15:04,560
they're not helpful so what about

440
00:15:04,560 --> 00:15:07,360
microsoft you know adam shostak kind of

441
00:15:07,360 --> 00:15:08,560
like the

442
00:15:08,560 --> 00:15:11,360
one of the key images of you know in the

443
00:15:11,360 --> 00:15:13,279
threat modeling world if there is such a

444
00:15:13,279 --> 00:15:14,480
thing

445
00:15:14,480 --> 00:15:17,040
what did microsoft have to say well they

446
00:15:17,040 --> 00:15:18,560
got better

447
00:15:18,560 --> 00:15:20,720
still pretty lengthy and still not

448
00:15:20,720 --> 00:15:22,399
really getting me back to the basics

449
00:15:22,399 --> 00:15:25,519
like what at its core is threat modeling

450
00:15:25,519 --> 00:15:28,160
and that's when it hit like all right

451
00:15:28,160 --> 00:15:29,519
let's really just think about this

452
00:15:29,519 --> 00:15:32,240
simply what is threat modeling

453
00:15:32,240 --> 00:15:33,680
this is asking the question what could

454
00:15:33,680 --> 00:15:35,440
possibly go wrong

455
00:15:35,440 --> 00:15:37,279
so if i'm booking a flight and i'm

456
00:15:37,279 --> 00:15:38,639
flying through an airport that i've

457
00:15:38,639 --> 00:15:40,399
never been in before

458
00:15:40,399 --> 00:15:42,240
what could possibly go wrong in that

459
00:15:42,240 --> 00:15:44,800
scenario

460
00:15:45,839 --> 00:15:47,759
so

461
00:15:47,759 --> 00:15:49,199
this is the

462
00:15:49,199 --> 00:15:52,959
simplistic definition i came up with

463
00:15:52,959 --> 00:15:54,560
you're just identifying the likely

464
00:15:54,560 --> 00:15:56,160
threats to a system

465
00:15:56,160 --> 00:15:57,920
to inform the design of security

466
00:15:57,920 --> 00:16:00,639
countermeasures

467
00:16:00,880 --> 00:16:03,040
cool all right so i can work with this

468
00:16:03,040 --> 00:16:04,480
well it turns out i wasn't the only one

469
00:16:04,480 --> 00:16:07,279
asking this question

470
00:16:07,279 --> 00:16:09,040
and in 2020

471
00:16:09,040 --> 00:16:11,120
14 15 of us

472
00:16:11,120 --> 00:16:13,279
in the security industry including

473
00:16:13,279 --> 00:16:15,360
myself including adam shostak including

474
00:16:15,360 --> 00:16:16,959
a whole bunch of other really awesome

475
00:16:16,959 --> 00:16:20,160
and super smart people

476
00:16:20,240 --> 00:16:22,560
we got together and decided we were

477
00:16:22,560 --> 00:16:24,240
going to create the threat modeling

478
00:16:24,240 --> 00:16:25,680
manifesto

479
00:16:25,680 --> 00:16:27,360
because we all had a passion for threat

480
00:16:27,360 --> 00:16:29,279
modeling we all recognized the

481
00:16:29,279 --> 00:16:30,880
challenges and the fact that threat

482
00:16:30,880 --> 00:16:32,079
modeling

483
00:16:32,079 --> 00:16:33,759
isn't getting adopted the way we think

484
00:16:33,759 --> 00:16:36,079
it should be and we're not making use of

485
00:16:36,079 --> 00:16:38,399
the value that it brings so we wanted to

486
00:16:38,399 --> 00:16:40,079
start to fix that by telling people

487
00:16:40,079 --> 00:16:41,600
about threat modeling and just helping

488
00:16:41,600 --> 00:16:44,079
them understand what it should be

489
00:16:44,079 --> 00:16:46,880
and so within the manifesto this is

490
00:16:46,880 --> 00:16:48,000
the

491
00:16:48,000 --> 00:16:51,600
the uh definition that we came up with

492
00:16:51,600 --> 00:16:53,920
and you notice it's not that dissimilar

493
00:16:53,920 --> 00:16:56,240
from my definition well i mean it's

494
00:16:56,240 --> 00:16:57,839
probably because you know i was i was

495
00:16:57,839 --> 00:16:59,519
there and i had some influence on the

496
00:16:59,519 --> 00:17:02,160
definition as it got written

497
00:17:02,160 --> 00:17:04,400
but we agreed to this threat modeling is

498
00:17:04,400 --> 00:17:07,280
analyzing representations of a system

499
00:17:07,280 --> 00:17:08,959
to highlight concerns about security and

500
00:17:08,959 --> 00:17:11,119
privacy characteristics now that's a

501
00:17:11,119 --> 00:17:13,280
little more specific than my

502
00:17:13,280 --> 00:17:16,000
my particular definition because this is

503
00:17:16,000 --> 00:17:17,760
definitely more security and technology

504
00:17:17,760 --> 00:17:18,959
focused

505
00:17:18,959 --> 00:17:20,559
but this is where we headed and we

506
00:17:20,559 --> 00:17:22,160
wanted to keep it focused on security

507
00:17:22,160 --> 00:17:23,439
and technology because that was our

508
00:17:23,439 --> 00:17:24,799
audience

509
00:17:24,799 --> 00:17:26,640
okay great

510
00:17:26,640 --> 00:17:28,480
so we're highlighting

511
00:17:28,480 --> 00:17:29,840
these concerns about security and

512
00:17:29,840 --> 00:17:30,880
privacy

513
00:17:30,880 --> 00:17:32,559
but why

514
00:17:32,559 --> 00:17:35,039
why do we care why is threat modeling

515
00:17:35,039 --> 00:17:36,320
why do we do it

516
00:17:36,320 --> 00:17:38,559
what is the purpose what is our desired

517
00:17:38,559 --> 00:17:40,080
outcome

518
00:17:40,080 --> 00:17:42,400
and this borrows from the second half

519
00:17:42,400 --> 00:17:44,400
of my definition and that is the output

520
00:17:44,400 --> 00:17:47,120
of threat modeling informs decisions

521
00:17:47,120 --> 00:17:48,480
that you're going to make in subsequent

522
00:17:48,480 --> 00:17:50,000
design development testing and

523
00:17:50,000 --> 00:17:51,919
deployment

524
00:17:51,919 --> 00:17:54,240
of your systems of your applications of

525
00:17:54,240 --> 00:17:56,240
your products

526
00:17:56,240 --> 00:17:58,480
this is why we threaten model because

527
00:17:58,480 --> 00:18:00,640
when we understand the critical assets

528
00:18:00,640 --> 00:18:05,039
and we understand the potential threats

529
00:18:05,039 --> 00:18:07,360
now we can account for them when i know

530
00:18:07,360 --> 00:18:08,640
that there's a possibility that

531
00:18:08,640 --> 00:18:10,880
something could go wrong on my layover

532
00:18:10,880 --> 00:18:14,320
in salt lake city i can take a

533
00:18:14,320 --> 00:18:16,559
appropriate step to make sure that i

534
00:18:16,559 --> 00:18:19,280
account for that

535
00:18:20,799 --> 00:18:23,200
i made an informed decision

536
00:18:23,200 --> 00:18:24,880
i didn't miss my flight on the

537
00:18:24,880 --> 00:18:26,000
connection

538
00:18:26,000 --> 00:18:27,760
i got there on time

539
00:18:27,760 --> 00:18:30,480
because i threaten modeled

540
00:18:30,480 --> 00:18:33,039
so all right this is all great

541
00:18:33,039 --> 00:18:34,320
it's wonderful

542
00:18:34,320 --> 00:18:36,640
but now i got to put this into reality

543
00:18:36,640 --> 00:18:38,240
how do i make threat modeling a thing if

544
00:18:38,240 --> 00:18:40,240
i'm a software developer

545
00:18:40,240 --> 00:18:41,520
or

546
00:18:41,520 --> 00:18:43,520
i'm a member of a software development

547
00:18:43,520 --> 00:18:45,919
organization

548
00:18:45,919 --> 00:18:49,840
i got to build a methodology to do this

549
00:18:49,840 --> 00:18:52,000
and this is where the threat modeling

550
00:18:52,000 --> 00:18:54,320
manifesto

551
00:18:54,320 --> 00:18:56,960
made sure that we focused not

552
00:18:56,960 --> 00:18:59,760
on writing a methodology

553
00:18:59,760 --> 00:19:02,240
because we want the methodology

554
00:19:02,240 --> 00:19:04,480
to be something that's meaningful

555
00:19:04,480 --> 00:19:06,880
to each organization

556
00:19:06,880 --> 00:19:09,120
or to each person

557
00:19:09,120 --> 00:19:11,440
who adopts that methodology

558
00:19:11,440 --> 00:19:13,320
and if we tried to define a

559
00:19:13,320 --> 00:19:15,679
one-size-fits-all methodology

560
00:19:15,679 --> 00:19:17,360
that's what created all of those

561
00:19:17,360 --> 00:19:18,960
frameworks and things you saw out there

562
00:19:18,960 --> 00:19:21,360
when i talked about octave and pasta and

563
00:19:21,360 --> 00:19:23,520
stride and dread

564
00:19:23,520 --> 00:19:27,280
and the capac taxonomy

565
00:19:27,280 --> 00:19:29,600
all of those were frameworks

566
00:19:29,600 --> 00:19:31,520
that were derived from the objective to

567
00:19:31,520 --> 00:19:34,160
create a single one-size-fits-all

568
00:19:34,160 --> 00:19:37,520
guide or whatever have you for how to do

569
00:19:37,520 --> 00:19:40,320
threat modeling

570
00:19:40,720 --> 00:19:42,880
and that's just not the approach threat

571
00:19:42,880 --> 00:19:45,360
modeling needs to be meaningful so

572
00:19:45,360 --> 00:19:48,639
within the manifesto

573
00:19:48,799 --> 00:19:52,080
we define values five values of threat

574
00:19:52,080 --> 00:19:54,480
modeling what a value is

575
00:19:54,480 --> 00:19:56,240
it's just something that has relative

576
00:19:56,240 --> 00:19:59,280
worth merit or importance it's it speaks

577
00:19:59,280 --> 00:20:00,720
again to

578
00:20:00,720 --> 00:20:03,039
why are we doing this and what's the

579
00:20:03,039 --> 00:20:07,039
most important aspect

580
00:20:07,039 --> 00:20:10,640
so when i when we discuss the values

581
00:20:10,640 --> 00:20:12,559
in threat modeling

582
00:20:12,559 --> 00:20:14,080
what you'll see is we talk about them in

583
00:20:14,080 --> 00:20:15,919
terms of

584
00:20:15,919 --> 00:20:18,480
one characteristic as opposed to a

585
00:20:18,480 --> 00:20:19,520
different

586
00:20:19,520 --> 00:20:21,520
characteristic

587
00:20:21,520 --> 00:20:22,240
so

588
00:20:22,240 --> 00:20:24,799
while there's still value to that latter

589
00:20:24,799 --> 00:20:26,559
half

590
00:20:26,559 --> 00:20:28,880
it's the former part the side the one on

591
00:20:28,880 --> 00:20:31,520
the left that you'll see in a minute

592
00:20:31,520 --> 00:20:35,120
that means the most to us so as we start

593
00:20:35,120 --> 00:20:37,200
thinking about all right how am i going

594
00:20:37,200 --> 00:20:39,679
to make threat modeling a reality how am

595
00:20:39,679 --> 00:20:41,440
i going to fit this

596
00:20:41,440 --> 00:20:43,840
into my world into my

597
00:20:43,840 --> 00:20:46,840
software design and development into my

598
00:20:46,840 --> 00:20:48,799
sdlc

599
00:20:48,799 --> 00:20:52,320
my devops and ci cd pipelines

600
00:20:52,320 --> 00:20:54,640
these values are the things that help

601
00:20:54,640 --> 00:20:57,600
you shape that methodology

602
00:20:57,600 --> 00:20:59,039
they're the things that make sure that

603
00:20:59,039 --> 00:21:00,880
you're on the right track that you're

604
00:21:00,880 --> 00:21:03,200
focused on the most important things

605
00:21:03,200 --> 00:21:05,679
and that whatever methodology you design

606
00:21:05,679 --> 00:21:07,600
is going to accomplish the goals that

607
00:21:07,600 --> 00:21:10,880
make threat modeling so effective in

608
00:21:10,880 --> 00:21:13,600
addressing security posture

609
00:21:13,600 --> 00:21:18,320
so let's dig in the first value

610
00:21:18,320 --> 00:21:21,120
is that we value a culture of finding

611
00:21:21,120 --> 00:21:23,440
and fixing design issues

612
00:21:23,440 --> 00:21:26,799
over checkbox compliance

613
00:21:26,799 --> 00:21:28,240
now what do i mean by checkbox

614
00:21:28,240 --> 00:21:29,679
compliance

615
00:21:29,679 --> 00:21:32,720
here's a good example

616
00:21:33,039 --> 00:21:36,320
hey the ada says we need to have a uh

617
00:21:36,320 --> 00:21:39,840
a handicap space

618
00:21:41,280 --> 00:21:43,280
this ain't doing it

619
00:21:43,280 --> 00:21:45,200
maybe it checks the box i would hope not

620
00:21:45,200 --> 00:21:47,280
i would hope that uh you know

621
00:21:47,280 --> 00:21:49,679
anyone auditing this for accessibility

622
00:21:49,679 --> 00:21:52,559
needs would say this is not okay

623
00:21:52,559 --> 00:21:53,840
but this is what happens in

624
00:21:53,840 --> 00:21:56,080
organizations a lot of times when they

625
00:21:56,080 --> 00:21:58,720
do implement threat modeling

626
00:21:58,720 --> 00:22:01,440
it's to check a box

627
00:22:01,440 --> 00:22:03,679
it's to say simply yeah we did it we did

628
00:22:03,679 --> 00:22:05,120
the thing

629
00:22:05,120 --> 00:22:06,559
we got a bunch of people together in a

630
00:22:06,559 --> 00:22:07,600
room

631
00:22:07,600 --> 00:22:09,280
we got them all talking about the design

632
00:22:09,280 --> 00:22:12,559
we created a bunch of documents

633
00:22:12,559 --> 00:22:15,918
we did the thing and it's done

634
00:22:16,720 --> 00:22:18,320
obviously that's not what we want to be

635
00:22:18,320 --> 00:22:19,440
threat modeling for you don't get any

636
00:22:19,440 --> 00:22:21,280
value out of that you don't get value

637
00:22:21,280 --> 00:22:24,000
out of simply checking a box

638
00:22:24,000 --> 00:22:25,520
so when we're talking about threat

639
00:22:25,520 --> 00:22:27,360
modeling we're really looking to build

640
00:22:27,360 --> 00:22:28,880
that culture

641
00:22:28,880 --> 00:22:31,919
where people are collaborating to find

642
00:22:31,919 --> 00:22:34,880
and fix design issues there's a clear

643
00:22:34,880 --> 00:22:36,960
design issue here

644
00:22:36,960 --> 00:22:39,760
no one can park in this space

645
00:22:39,760 --> 00:22:42,159
so we haven't accomplished our goal at

646
00:22:42,159 --> 00:22:43,280
all

647
00:22:43,280 --> 00:22:45,200
maybe we checked the box because we have

648
00:22:45,200 --> 00:22:46,480
a space

649
00:22:46,480 --> 00:22:49,600
with the right symbol painted on it

650
00:22:49,600 --> 00:22:51,840
but no one can park there

651
00:22:51,840 --> 00:22:55,840
that doesn't increase accessibility

652
00:22:57,360 --> 00:22:58,960
so when we think about threat modeling

653
00:22:58,960 --> 00:23:00,480
it's the same

654
00:23:00,480 --> 00:23:02,799
we want our threat modeling to actually

655
00:23:02,799 --> 00:23:04,880
be something that we leverage to find

656
00:23:04,880 --> 00:23:07,520
and fix issues in the design we want to

657
00:23:07,520 --> 00:23:10,000
catch it early we want to be able to

658
00:23:10,000 --> 00:23:11,120
apply

659
00:23:11,120 --> 00:23:14,320
informed decisions to the design of the

660
00:23:14,320 --> 00:23:17,360
system the software whatever it is that

661
00:23:17,360 --> 00:23:19,840
we're creating

662
00:23:19,840 --> 00:23:22,080
so as you think about building out your

663
00:23:22,080 --> 00:23:24,159
methodology that's a value you have to

664
00:23:24,159 --> 00:23:25,440
keep in mind

665
00:23:25,440 --> 00:23:26,240
is

666
00:23:26,240 --> 00:23:28,000
how am i doing this in a way that it's

667
00:23:28,000 --> 00:23:30,559
going to create a culture

668
00:23:30,559 --> 00:23:32,400
that's focused on finding and fixing

669
00:23:32,400 --> 00:23:34,320
design issues not create a methodology

670
00:23:34,320 --> 00:23:35,440
that people are just going to want to

671
00:23:35,440 --> 00:23:36,480
rush through

672
00:23:36,480 --> 00:23:39,039
get it done check off the box and say we

673
00:23:39,039 --> 00:23:41,520
did it hands down we're going into the

674
00:23:41,520 --> 00:23:44,320
development now

675
00:23:44,559 --> 00:23:47,200
so that's our first value you see left

676
00:23:47,200 --> 00:23:49,360
side right side

677
00:23:49,360 --> 00:23:50,960
maybe there's some value in checkbox

678
00:23:50,960 --> 00:23:53,279
compliance

679
00:23:53,279 --> 00:23:54,880
we know that we're making sure people

680
00:23:54,880 --> 00:23:56,080
did it

681
00:23:56,080 --> 00:23:58,320
i guess there's some value in that

682
00:23:58,320 --> 00:24:00,320
but the real value comes in finding and

683
00:24:00,320 --> 00:24:03,520
fixing those issues

684
00:24:03,679 --> 00:24:04,400
okay

685
00:24:04,400 --> 00:24:07,200
our next value

686
00:24:07,279 --> 00:24:08,480
and this stems from what i was just

687
00:24:08,480 --> 00:24:11,279
talking about people and collaboration

688
00:24:11,279 --> 00:24:15,360
over processes methodologies and tools

689
00:24:15,360 --> 00:24:18,559
unfortunately what we see too often

690
00:24:18,559 --> 00:24:20,559
is when we want to bring threat modeling

691
00:24:20,559 --> 00:24:22,720
into devops in particular

692
00:24:22,720 --> 00:24:25,440
we get really focused on the processes

693
00:24:25,440 --> 00:24:27,919
and the methodologies and and using

694
00:24:27,919 --> 00:24:30,880
tools to do this

695
00:24:30,880 --> 00:24:32,640
and we forget that the

696
00:24:32,640 --> 00:24:34,720
large portion of this value think back

697
00:24:34,720 --> 00:24:36,640
to what i showed you on that that report

698
00:24:36,640 --> 00:24:38,720
from puppet and circle ci

699
00:24:38,720 --> 00:24:40,799
and what i said you know what it said in

700
00:24:40,799 --> 00:24:41,840
that little box that you probably

701
00:24:41,840 --> 00:24:44,240
couldn't read but i read it to you

702
00:24:44,240 --> 00:24:46,799
it was security and developers

703
00:24:46,799 --> 00:24:48,559
collaborating

704
00:24:48,559 --> 00:24:50,720
on threat models

705
00:24:50,720 --> 00:24:53,200
that created that value that impacted

706
00:24:53,200 --> 00:24:56,080
the security posture

707
00:24:56,080 --> 00:24:57,200
and so

708
00:24:57,200 --> 00:24:59,120
while it's great

709
00:24:59,120 --> 00:25:01,200
that we have things like octave and

710
00:25:01,200 --> 00:25:06,000
pasta and stride and all these things

711
00:25:06,240 --> 00:25:10,880
if our focus is to accomplish those

712
00:25:10,880 --> 00:25:14,000
to the degree that we forget about or

713
00:25:14,000 --> 00:25:16,320
lose sight of or actually don't even

714
00:25:16,320 --> 00:25:18,880
implement the collaboration between the

715
00:25:18,880 --> 00:25:20,640
people

716
00:25:20,640 --> 00:25:21,919
we're not getting the value out of

717
00:25:21,919 --> 00:25:24,159
threat modeling that we're looking for

718
00:25:24,159 --> 00:25:25,840
you think i think back to what we used

719
00:25:25,840 --> 00:25:28,400
to do with threat modeling in waterfall

720
00:25:28,400 --> 00:25:29,520
approaches where we had these really

721
00:25:29,520 --> 00:25:31,039
long design cycles and we did create the

722
00:25:31,039 --> 00:25:33,520
diagrams we did all that stuff

723
00:25:33,520 --> 00:25:35,760
one of the most valuable parts of it was

724
00:25:35,760 --> 00:25:38,000
getting everybody in a room the

725
00:25:38,000 --> 00:25:40,720
developers the operations people the

726
00:25:40,720 --> 00:25:43,200
project managers the security

727
00:25:43,200 --> 00:25:44,480
engineers

728
00:25:44,480 --> 00:25:47,360
getting them in a room together

729
00:25:47,360 --> 00:25:49,679
talking through those data flow diagrams

730
00:25:49,679 --> 00:25:52,559
so everybody understood

731
00:25:52,559 --> 00:25:56,480
how this system was going to work

732
00:25:56,480 --> 00:25:58,400
that collaboration

733
00:25:58,400 --> 00:26:00,240
where everybody's able to gain

734
00:26:00,240 --> 00:26:02,400
visibility into what the design is going

735
00:26:02,400 --> 00:26:03,919
to be

736
00:26:03,919 --> 00:26:05,440
and they're able to provide their

737
00:26:05,440 --> 00:26:08,000
feedback

738
00:26:08,080 --> 00:26:10,080
that's what we want to be focused on

739
00:26:10,080 --> 00:26:12,720
when we're designing a methodology for

740
00:26:12,720 --> 00:26:14,799
threat modeling

741
00:26:14,799 --> 00:26:17,520
what the processes are that we implement

742
00:26:17,520 --> 00:26:19,919
what methodologies we leverage

743
00:26:19,919 --> 00:26:21,840
what tools

744
00:26:21,840 --> 00:26:24,480
those can have some value

745
00:26:24,480 --> 00:26:26,960
but we need to focus on the people and

746
00:26:26,960 --> 00:26:28,480
that collaboration to make sure we're

747
00:26:28,480 --> 00:26:31,760
getting the true value out of it

748
00:26:33,600 --> 00:26:35,120
so our next

749
00:26:35,120 --> 00:26:37,120
our next value

750
00:26:37,120 --> 00:26:40,720
is that threat modeling values a journey

751
00:26:40,720 --> 00:26:43,039
of understanding

752
00:26:43,039 --> 00:26:46,159
over a security or privacy snapshot

753
00:26:46,159 --> 00:26:47,840
so i mentioned that before one of the

754
00:26:47,840 --> 00:26:49,520
big struggles

755
00:26:49,520 --> 00:26:53,120
with threat modeling

756
00:26:53,120 --> 00:26:55,840
in that old style where we had all these

757
00:26:55,840 --> 00:26:57,840
big frameworks and things that we

758
00:26:57,840 --> 00:27:00,000
leveraged

759
00:27:00,000 --> 00:27:03,360
was that we ultimately ended up with

760
00:27:03,360 --> 00:27:05,760
a point in time snapshot

761
00:27:05,760 --> 00:27:08,320
it was so heavy lifting that we could do

762
00:27:08,320 --> 00:27:09,520
it once

763
00:27:09,520 --> 00:27:10,960
and that was it

764
00:27:10,960 --> 00:27:12,559
like we just did it we checked the box

765
00:27:12,559 --> 00:27:14,159
we said we're done

766
00:27:14,159 --> 00:27:17,440
we had our one snapshot that told us

767
00:27:17,440 --> 00:27:19,039
but as we know software is far more

768
00:27:19,039 --> 00:27:21,039
dynamic than that

769
00:27:21,039 --> 00:27:23,360
product development is far more dynamic

770
00:27:23,360 --> 00:27:25,360
than that

771
00:27:25,360 --> 00:27:28,799
and so as things change

772
00:27:28,799 --> 00:27:31,279
as our understanding

773
00:27:31,279 --> 00:27:32,480
changes

774
00:27:32,480 --> 00:27:35,679
even if the technology is the same

775
00:27:35,679 --> 00:27:38,320
we want threat modeling to be a journey

776
00:27:38,320 --> 00:27:40,720
to understand those things we don't want

777
00:27:40,720 --> 00:27:43,760
it to be that one point in time snapshot

778
00:27:43,760 --> 00:27:46,159
that hey we did it we saw a bunch of

779
00:27:46,159 --> 00:27:48,720
threats we responded to them we designed

780
00:27:48,720 --> 00:27:51,679
around them and that was it we were done

781
00:27:51,679 --> 00:27:54,320
that doesn't bring value the value is

782
00:27:54,320 --> 00:27:56,000
constantly learning and growing and

783
00:27:56,000 --> 00:27:57,760
understanding the system

784
00:27:57,760 --> 00:27:59,360
and gaining new

785
00:27:59,360 --> 00:28:02,880
abilities and new visibility into what

786
00:28:02,880 --> 00:28:05,679
those threats are

787
00:28:06,640 --> 00:28:08,320
so when i talk about building out a

788
00:28:08,320 --> 00:28:11,120
threat modeling methodology whether it's

789
00:28:11,120 --> 00:28:13,600
in an organization whether i'm just a

790
00:28:13,600 --> 00:28:15,600
single developer maintaining an open

791
00:28:15,600 --> 00:28:17,200
source

792
00:28:17,200 --> 00:28:20,399
library or package

793
00:28:20,799 --> 00:28:22,399
i want to be constantly evolving my

794
00:28:22,399 --> 00:28:24,799
understanding of the threats

795
00:28:24,799 --> 00:28:27,120
because inevitably

796
00:28:27,120 --> 00:28:29,200
the idea that we're going to somehow

797
00:28:29,200 --> 00:28:30,720
identify every possible threat that

798
00:28:30,720 --> 00:28:32,880
could ever exist

799
00:28:32,880 --> 00:28:35,200
that's just not likely

800
00:28:35,200 --> 00:28:37,360
it's not going to happen

801
00:28:37,360 --> 00:28:39,440
new threats pop up all the time new

802
00:28:39,440 --> 00:28:41,279
attack vectors are discovered all the

803
00:28:41,279 --> 00:28:42,399
time

804
00:28:42,399 --> 00:28:44,480
so i want my threat modeling to be that

805
00:28:44,480 --> 00:28:45,440
journey

806
00:28:45,440 --> 00:28:47,679
continuously returning

807
00:28:47,679 --> 00:28:50,320
and understanding in new ways

808
00:28:50,320 --> 00:28:52,880
the threats that my system faces

809
00:28:52,880 --> 00:28:55,440
and looking for ways to design to

810
00:28:55,440 --> 00:28:57,279
accommodate and account for those

811
00:28:57,279 --> 00:28:59,840
threats

812
00:29:00,399 --> 00:29:02,320
having a snapshot is good

813
00:29:02,320 --> 00:29:04,480
it gives us some stuff to work with

814
00:29:04,480 --> 00:29:06,640
and again if i'm in a waterfall

815
00:29:06,640 --> 00:29:08,480
methodology where

816
00:29:08,480 --> 00:29:10,240
each time i'm going to do some design

817
00:29:10,240 --> 00:29:12,720
work i do a threat model and i have that

818
00:29:12,720 --> 00:29:15,840
luxury of all that time great

819
00:29:15,840 --> 00:29:18,159
but that isn't modern day devops that's

820
00:29:18,159 --> 00:29:21,760
not the way we develop these days

821
00:29:23,360 --> 00:29:27,039
now this one seems obvious

822
00:29:27,039 --> 00:29:28,960
the next value is

823
00:29:28,960 --> 00:29:32,159
valuing actually doing threat modeling

824
00:29:32,159 --> 00:29:35,279
over talking about it

825
00:29:36,320 --> 00:29:40,240
why did we feel the need to include this

826
00:29:40,240 --> 00:29:41,520
melissa what

827
00:29:41,520 --> 00:29:45,120
of course of course you got to do it

828
00:29:45,120 --> 00:29:47,279
and yet what we find in a lot of

829
00:29:47,279 --> 00:29:49,039
organizations is they talk about the

830
00:29:49,039 --> 00:29:51,600
idea of threat modeling

831
00:29:51,600 --> 00:29:54,799
but nobody really understands it nobody

832
00:29:54,799 --> 00:29:56,080
really

833
00:29:56,080 --> 00:29:57,600
is doing it

834
00:29:57,600 --> 00:29:59,919
and a lot of times it's because

835
00:29:59,919 --> 00:30:01,919
everybody's thinking about how to come

836
00:30:01,919 --> 00:30:03,520
up with the perfect way to do threat

837
00:30:03,520 --> 00:30:05,760
modeling that they never really actually

838
00:30:05,760 --> 00:30:09,039
get started on it

839
00:30:09,039 --> 00:30:10,320
it's kind of like that person gets all

840
00:30:10,320 --> 00:30:11,600
excited

841
00:30:11,600 --> 00:30:13,760
to go jump out of an airplane

842
00:30:13,760 --> 00:30:16,159
gets right up to the door but just won't

843
00:30:16,159 --> 00:30:17,520
jump

844
00:30:17,520 --> 00:30:20,320
their fear kicks in or whatever else

845
00:30:20,320 --> 00:30:21,760
they want to make sure they do just the

846
00:30:21,760 --> 00:30:23,039
perfect jump they want to have the

847
00:30:23,039 --> 00:30:26,799
perfect form as they leave the door

848
00:30:27,840 --> 00:30:29,440
stop talking about it get up in the

849
00:30:29,440 --> 00:30:32,559
plane jump

850
00:30:32,799 --> 00:30:34,559
if it's not perfect the first time it's

851
00:30:34,559 --> 00:30:35,679
okay

852
00:30:35,679 --> 00:30:38,080
you're not gonna die you will survive i

853
00:30:38,080 --> 00:30:41,679
promise it's threat modeling

854
00:30:41,679 --> 00:30:43,600
it's far less high risk than jumping out

855
00:30:43,600 --> 00:30:44,799
of an airplane

856
00:30:44,799 --> 00:30:48,399
but people do that all the time and live

857
00:30:48,640 --> 00:30:50,799
so the idea here is

858
00:30:50,799 --> 00:30:52,480
when i say doing threat modeling over

859
00:30:52,480 --> 00:30:53,919
talking about it it's actually putting

860
00:30:53,919 --> 00:30:55,919
something into action don't get into

861
00:30:55,919 --> 00:30:58,559
that whole what's the uh the cliche

862
00:30:58,559 --> 00:31:02,000
around that paralysis by analysis

863
00:31:02,000 --> 00:31:03,600
we don't need to have a perfect threat

864
00:31:03,600 --> 00:31:04,880
model

865
00:31:04,880 --> 00:31:06,720
we don't need to identify every

866
00:31:06,720 --> 00:31:09,600
vulnerability every thread every design

867
00:31:09,600 --> 00:31:11,679
feature that's off we just need to start

868
00:31:11,679 --> 00:31:13,519
doing something and get incrementally

869
00:31:13,519 --> 00:31:14,960
better

870
00:31:14,960 --> 00:31:17,200
we have that opportunity

871
00:31:17,200 --> 00:31:19,200
and speaking of getting

872
00:31:19,200 --> 00:31:21,679
continually better that's our last value

873
00:31:21,679 --> 00:31:25,039
continuous refinement

874
00:31:25,039 --> 00:31:26,720
the idea that these threat models will

875
00:31:26,720 --> 00:31:29,760
not be perfect our security program will

876
00:31:29,760 --> 00:31:31,679
not be perfect

877
00:31:31,679 --> 00:31:33,600
but it doesn't need to be because it

878
00:31:33,600 --> 00:31:34,880
never will be

879
00:31:34,880 --> 00:31:37,760
so stop trying to be perfect and value

880
00:31:37,760 --> 00:31:39,360
continuous refinement over a single

881
00:31:39,360 --> 00:31:41,200
delivery instead of trying to create

882
00:31:41,200 --> 00:31:43,679
that one perfect

883
00:31:43,679 --> 00:31:46,679
statue

884
00:31:47,360 --> 00:31:47,560
and

885
00:31:47,560 --> 00:31:48,880
[Music]

886
00:31:48,880 --> 00:31:49,760
just

887
00:31:49,760 --> 00:31:50,799
you know

888
00:31:50,799 --> 00:31:52,320
thinking that hey i'm going to be

889
00:31:52,320 --> 00:31:54,080
totally happy with it i'm going to sit

890
00:31:54,080 --> 00:31:55,519
down tonight i'm going to carve out this

891
00:31:55,519 --> 00:31:57,360
the statue and be done

892
00:31:57,360 --> 00:31:59,360
no artists sit there and they

893
00:31:59,360 --> 00:32:02,879
continually revise their work

894
00:32:03,200 --> 00:32:04,399
whether it's a statue whether it's a

895
00:32:04,399 --> 00:32:05,760
painting whatever they're constantly

896
00:32:05,760 --> 00:32:06,960
going back

897
00:32:06,960 --> 00:32:08,559
watch bob ross for crying out loud

898
00:32:08,559 --> 00:32:10,000
number times he goes back and makes

899
00:32:10,000 --> 00:32:11,519
changes to little parts because it's

900
00:32:11,519 --> 00:32:13,440
just not quite right he keeps refining

901
00:32:13,440 --> 00:32:16,240
it over and over again

902
00:32:16,240 --> 00:32:17,840
did i just date myself talking about bob

903
00:32:17,840 --> 00:32:19,120
ross do any of you know who i'm talking

904
00:32:19,120 --> 00:32:20,960
about anymore

905
00:32:20,960 --> 00:32:23,440
i don't know i'm old what can i say

906
00:32:23,440 --> 00:32:24,880
but this is the reality when we talk

907
00:32:24,880 --> 00:32:26,320
about our threat models we want them to

908
00:32:26,320 --> 00:32:30,320
be continuously refined

909
00:32:30,799 --> 00:32:32,960
we want to be always improving as we're

910
00:32:32,960 --> 00:32:35,279
on that journey each step of that

911
00:32:35,279 --> 00:32:37,760
journey should be refinement of our

912
00:32:37,760 --> 00:32:41,640
understanding of that threat

913
00:32:42,080 --> 00:32:43,519
rather than sitting down and saying one

914
00:32:43,519 --> 00:32:45,120
time hey this is it this is what we

915
00:32:45,120 --> 00:32:47,760
understand we're done

916
00:32:47,760 --> 00:32:49,200
kind of back to that whole point in time

917
00:32:49,200 --> 00:32:51,360
conversation

918
00:32:51,360 --> 00:32:56,000
no it's all about continuous refinement

919
00:32:56,000 --> 00:32:57,760
if all i'm doing with my threat modeling

920
00:32:57,760 --> 00:32:59,600
is producing one report and i hand that

921
00:32:59,600 --> 00:33:01,760
out the door and i say hey this is your

922
00:33:01,760 --> 00:33:03,519
your delivery

923
00:33:03,519 --> 00:33:05,760
no

924
00:33:05,919 --> 00:33:07,679
how am i ensuring that that's a living

925
00:33:07,679 --> 00:33:09,360
document how is that something that's

926
00:33:09,360 --> 00:33:11,279
going to continue to grow how can we

927
00:33:11,279 --> 00:33:14,159
continuously refine that

928
00:33:14,159 --> 00:33:16,000
so instead of seeing the deliverable

929
00:33:16,000 --> 00:33:17,679
from a threat model being hey i create

930
00:33:17,679 --> 00:33:19,440
you this threat model report now you go

931
00:33:19,440 --> 00:33:21,600
act how do i make this something more

932
00:33:21,600 --> 00:33:24,960
dynamic we're talking about devops here

933
00:33:24,960 --> 00:33:27,679
devops at infinity how do we do the same

934
00:33:27,679 --> 00:33:29,519
with threat modeling and make threat

935
00:33:29,519 --> 00:33:31,840
modeling follow that same idea of

936
00:33:31,840 --> 00:33:34,000
a never-ending cycle

937
00:33:34,000 --> 00:33:36,960
that's the idea of continuous refinement

938
00:33:36,960 --> 00:33:40,399
so if i've got cicd do i now have cr

939
00:33:40,399 --> 00:33:41,360
maybe

940
00:33:41,360 --> 00:33:42,960
we don't really need to do that though

941
00:33:42,960 --> 00:33:44,240
we don't need to talk about it in those

942
00:33:44,240 --> 00:33:46,720
terms just know that continuously

943
00:33:46,720 --> 00:33:49,120
refining our methodology

944
00:33:49,120 --> 00:33:52,720
continuously refining the results

945
00:33:52,720 --> 00:33:55,039
making sure that what we produce is not

946
00:33:55,039 --> 00:33:58,080
just the end state of something

947
00:33:58,080 --> 00:33:59,760
but is merely

948
00:33:59,760 --> 00:34:02,000
one view that we're going to continue to

949
00:34:02,000 --> 00:34:03,840
refine over time

950
00:34:03,840 --> 00:34:05,279
this is what we're looking to value in

951
00:34:05,279 --> 00:34:06,720
threat modeling

952
00:34:06,720 --> 00:34:08,480
so

953
00:34:08,480 --> 00:34:10,879
those are the values

954
00:34:10,879 --> 00:34:12,480
now beyond values we also talked about

955
00:34:12,480 --> 00:34:14,239
principles and principles are really

956
00:34:14,239 --> 00:34:15,599
just those fundamental truths about

957
00:34:15,599 --> 00:34:17,520
threat modeling

958
00:34:17,520 --> 00:34:18,239
so

959
00:34:18,239 --> 00:34:20,079
understanding where the value comes from

960
00:34:20,079 --> 00:34:21,839
great well now what does that mean how

961
00:34:21,839 --> 00:34:23,280
does when i start to put this into

962
00:34:23,280 --> 00:34:24,879
action what are some fundamental things

963
00:34:24,879 --> 00:34:28,960
i need to know about threat modeling

964
00:34:29,599 --> 00:34:32,720
and so there's four of them

965
00:34:33,199 --> 00:34:34,480
and i'm not going to put a bunch of

966
00:34:34,480 --> 00:34:37,359
words on the screen but

967
00:34:37,359 --> 00:34:38,639
first and foremost the best use of

968
00:34:38,639 --> 00:34:40,000
threat modeling

969
00:34:40,000 --> 00:34:41,760
is to improve the security and privacy

970
00:34:41,760 --> 00:34:44,560
of a system through early and frequent

971
00:34:44,560 --> 00:34:47,560
analysis

972
00:34:48,079 --> 00:34:50,639
doing it early doing it often

973
00:34:50,639 --> 00:34:53,359
this is how we accomplish those ideas of

974
00:34:53,359 --> 00:34:55,839
it being a journey this is how we make

975
00:34:55,839 --> 00:34:58,320
sure that it has impact and we'll talk

976
00:34:58,320 --> 00:35:00,400
in just a few minutes about how that

977
00:35:00,400 --> 00:35:03,839
helps our pipelines

978
00:35:05,599 --> 00:35:06,960
through modeling must align with an

979
00:35:06,960 --> 00:35:08,880
organization's development practices and

980
00:35:08,880 --> 00:35:10,960
follow design changes in iterations that

981
00:35:10,960 --> 00:35:13,680
are scoped to manageable portions of the

982
00:35:13,680 --> 00:35:14,640
system

983
00:35:14,640 --> 00:35:17,280
i know that was a lot of words

984
00:35:17,280 --> 00:35:19,200
just focus on it being an iterative

985
00:35:19,200 --> 00:35:21,200
process and manageable portions so

986
00:35:21,200 --> 00:35:23,040
instead of trying to tackle an entire

987
00:35:23,040 --> 00:35:23,920
system

988
00:35:23,920 --> 00:35:25,760
map it out in all these big

989
00:35:25,760 --> 00:35:28,480
diagrams and things let's focus on

990
00:35:28,480 --> 00:35:30,400
manageable pieces how can we keep that

991
00:35:30,400 --> 00:35:31,920
scope simple

992
00:35:31,920 --> 00:35:34,720
and just do it in an iterative fashion

993
00:35:34,720 --> 00:35:37,520
short iterations manageable scope that's

994
00:35:37,520 --> 00:35:39,440
how we do threat modeling

995
00:35:39,440 --> 00:35:40,960
now the outcomes of threat modeling are

996
00:35:40,960 --> 00:35:43,520
most meaningful when they are of value

997
00:35:43,520 --> 00:35:45,040
to the stakeholders

998
00:35:45,040 --> 00:35:47,280
this is kind of one of those duh moments

999
00:35:47,280 --> 00:35:49,760
right if what i'm creating

1000
00:35:49,760 --> 00:35:52,720
from my threat modeling

1001
00:35:52,720 --> 00:35:54,720
is not of value to my stakeholders then

1002
00:35:54,720 --> 00:35:56,079
that whole process wasn't very

1003
00:35:56,079 --> 00:35:57,359
meaningful

1004
00:35:57,359 --> 00:35:59,359
if they're not able to take

1005
00:35:59,359 --> 00:36:00,800
that threat model and look at it and say

1006
00:36:00,800 --> 00:36:02,800
okay we're able to make design decisions

1007
00:36:02,800 --> 00:36:05,280
we're able to change how we test

1008
00:36:05,280 --> 00:36:06,960
whatever from that threat model we've

1009
00:36:06,960 --> 00:36:09,280
not really done anything meaningful

1010
00:36:09,280 --> 00:36:12,320
and finally dialogue is the key to

1011
00:36:12,320 --> 00:36:14,280
establishing that common understanding

1012
00:36:14,280 --> 00:36:15,680
[Music]

1013
00:36:15,680 --> 00:36:17,440
documents just record those

1014
00:36:17,440 --> 00:36:20,000
understandings and enable measurement

1015
00:36:20,000 --> 00:36:22,720
so here again that idea of collaboration

1016
00:36:22,720 --> 00:36:25,359
that's where our understanding is formed

1017
00:36:25,359 --> 00:36:27,680
any documentation that we do of it

1018
00:36:27,680 --> 00:36:29,839
that's there so that we can record the

1019
00:36:29,839 --> 00:36:32,160
understanding and measure later our

1020
00:36:32,160 --> 00:36:33,839
successes

1021
00:36:33,839 --> 00:36:37,680
but the value is in the dialogue

1022
00:36:37,680 --> 00:36:39,599
so

1023
00:36:39,599 --> 00:36:42,800
we need to move away from

1024
00:36:42,800 --> 00:36:45,280
devops we want to move into devsecops

1025
00:36:45,280 --> 00:36:47,280
how do we do real

1026
00:36:47,280 --> 00:36:50,240
devsecops

1027
00:36:50,240 --> 00:36:51,760
you see

1028
00:36:51,760 --> 00:36:53,599
the the typical security approach any

1029
00:36:53,599 --> 00:36:56,880
time that we want to bring security into

1030
00:36:56,880 --> 00:36:59,119
the sdlc has always been to create the

1031
00:36:59,119 --> 00:37:00,720
idea of

1032
00:37:00,720 --> 00:37:02,480
quality gates

1033
00:37:02,480 --> 00:37:04,320
this point where you get to each of the

1034
00:37:04,320 --> 00:37:05,760
at the end of each of these phases hey

1035
00:37:05,760 --> 00:37:07,200
we have a quality gate you can't go to

1036
00:37:07,200 --> 00:37:09,119
the next phase unless you pass this this

1037
00:37:09,119 --> 00:37:12,079
security test

1038
00:37:12,160 --> 00:37:14,000
we need to get away from that insecurity

1039
00:37:14,000 --> 00:37:15,760
we need to start thinking about security

1040
00:37:15,760 --> 00:37:18,880
being integrated into every phase it's

1041
00:37:18,880 --> 00:37:19,920
not

1042
00:37:19,920 --> 00:37:21,520
something that we do outside of the

1043
00:37:21,520 --> 00:37:23,680
phases it's something that is just

1044
00:37:23,680 --> 00:37:26,240
inherent to each phase doing that

1045
00:37:26,240 --> 00:37:27,760
security thing and this is where threat

1046
00:37:27,760 --> 00:37:30,480
modeling really starts to bring security

1047
00:37:30,480 --> 00:37:33,200
to life in the devops space

1048
00:37:33,200 --> 00:37:35,440
now we hear about pushing left all the

1049
00:37:35,440 --> 00:37:38,079
time so i talked about yo do early and

1050
00:37:38,079 --> 00:37:41,760
often with our iterations

1051
00:37:42,640 --> 00:37:45,119
well if i want to bring security

1052
00:37:45,119 --> 00:37:47,119
as far left as i can go in the

1053
00:37:47,119 --> 00:37:48,800
development pipeline what is that

1054
00:37:48,800 --> 00:37:50,880
farthest left point

1055
00:37:50,880 --> 00:37:53,440
it's the user story

1056
00:37:53,440 --> 00:37:54,480
right

1057
00:37:54,480 --> 00:37:57,040
if i'm looking at my pipeline

1058
00:37:57,040 --> 00:37:59,280
i can't move any farther left in those

1059
00:37:59,280 --> 00:38:01,520
phases than where this all starts and

1060
00:38:01,520 --> 00:38:03,680
that's the user story someone has an

1061
00:38:03,680 --> 00:38:04,560
idea

1062
00:38:04,560 --> 00:38:06,720
for a new functionality

1063
00:38:06,720 --> 00:38:09,200
or for you know some other concept that

1064
00:38:09,200 --> 00:38:10,720
they're going to ask for a new feature

1065
00:38:10,720 --> 00:38:14,240
request whatever it becomes a user story

1066
00:38:14,240 --> 00:38:17,598
that's where it all begins

1067
00:38:17,680 --> 00:38:20,320
so if i want to push left with security

1068
00:38:20,320 --> 00:38:22,720
how can i build threat modeling

1069
00:38:22,720 --> 00:38:24,640
into the user story

1070
00:38:24,640 --> 00:38:26,160
now let's think about this now if i

1071
00:38:26,160 --> 00:38:28,960
build threat modeling into a user story

1072
00:38:28,960 --> 00:38:31,760
that means i've already limited it to a

1073
00:38:31,760 --> 00:38:34,079
very small scope because now i only have

1074
00:38:34,079 --> 00:38:37,839
to threat model that user story

1075
00:38:38,560 --> 00:38:40,560
and oh by the way

1076
00:38:40,560 --> 00:38:43,119
user stories that's kind of

1077
00:38:43,119 --> 00:38:44,960
by definition i'm going to be iterative

1078
00:38:44,960 --> 00:38:46,640
because we're constantly doing new user

1079
00:38:46,640 --> 00:38:48,320
stories so i'm starting to accomplish

1080
00:38:48,320 --> 00:38:50,240
those values and those those principles

1081
00:38:50,240 --> 00:38:53,280
of threat modeling just by focusing on

1082
00:38:53,280 --> 00:38:54,960
bringing threat modeling into the user

1083
00:38:54,960 --> 00:38:57,040
story

1084
00:38:57,040 --> 00:38:59,440
now what does that look like

1085
00:38:59,440 --> 00:39:00,400
well

1086
00:39:00,400 --> 00:39:01,680
if you're familiar with software

1087
00:39:01,680 --> 00:39:03,760
development you might recognize the

1088
00:39:03,760 --> 00:39:05,599
typical user story this is the most

1089
00:39:05,599 --> 00:39:10,000
basic style user story as a some persona

1090
00:39:10,000 --> 00:39:11,520
i want to

1091
00:39:11,520 --> 00:39:13,040
do something

1092
00:39:13,040 --> 00:39:14,400
so that

1093
00:39:14,400 --> 00:39:16,560
i can accomplish some goal

1094
00:39:16,560 --> 00:39:19,040
right that that is the typical simplest

1095
00:39:19,040 --> 00:39:22,400
structure for a user story

1096
00:39:22,960 --> 00:39:25,119
so what i'm proposing

1097
00:39:25,119 --> 00:39:26,640
is if i want to bring threat modeling

1098
00:39:26,640 --> 00:39:27,839
into this i need to add a couple

1099
00:39:27,839 --> 00:39:30,320
questions

1100
00:39:30,400 --> 00:39:33,040
as a persona i want to do this thing so

1101
00:39:33,040 --> 00:39:34,800
that i can accomplish this and i want

1102
00:39:34,800 --> 00:39:36,320
you to protect

1103
00:39:36,320 --> 00:39:39,200
something from some threat

1104
00:39:39,200 --> 00:39:41,920
so as a car driver i want to be able to

1105
00:39:41,920 --> 00:39:44,720
enter a destination name into my mapping

1106
00:39:44,720 --> 00:39:47,280
software so that i can navigate without

1107
00:39:47,280 --> 00:39:48,880
an address

1108
00:39:48,880 --> 00:39:50,400
okay cool

1109
00:39:50,400 --> 00:39:52,079
so now what are the threats that i face

1110
00:39:52,079 --> 00:39:53,200
there well

1111
00:39:53,200 --> 00:39:55,280
let's think about one one critical asset

1112
00:39:55,280 --> 00:39:56,960
that's a part of that is my search

1113
00:39:56,960 --> 00:39:58,640
history i don't want people being able

1114
00:39:58,640 --> 00:40:00,800
to look at where i you know what my

1115
00:40:00,800 --> 00:40:02,720
search history was so i want you to

1116
00:40:02,720 --> 00:40:04,240
protect that from being accessed by

1117
00:40:04,240 --> 00:40:06,160
attackers

1118
00:40:06,160 --> 00:40:08,640
this is plain language this gets rid of

1119
00:40:08,640 --> 00:40:11,359
all of those technical jargon and all

1120
00:40:11,359 --> 00:40:13,440
that stuff that we needed

1121
00:40:13,440 --> 00:40:15,440
this gets me focused on just simple

1122
00:40:15,440 --> 00:40:18,240
language that those business people or

1123
00:40:18,240 --> 00:40:20,000
whoever is writing my user's story could

1124
00:40:20,000 --> 00:40:21,280
be anyone

1125
00:40:21,280 --> 00:40:23,200
right if i'm thinking i'm an open source

1126
00:40:23,200 --> 00:40:24,960
developer i'm receiving

1127
00:40:24,960 --> 00:40:27,040
you know user stories from the general

1128
00:40:27,040 --> 00:40:30,000
public essentially

1129
00:40:30,000 --> 00:40:31,200
these are things that can be written i

1130
00:40:31,200 --> 00:40:32,480
don't have to have

1131
00:40:32,480 --> 00:40:34,480
specific security knowledge to write

1132
00:40:34,480 --> 00:40:36,800
this threat model i can look at and say

1133
00:40:36,800 --> 00:40:38,880
all right i recognize this is a critical

1134
00:40:38,880 --> 00:40:39,839
piece

1135
00:40:39,839 --> 00:40:41,680
this is a critical asset search history

1136
00:40:41,680 --> 00:40:44,079
is going to be a critical asset in this

1137
00:40:44,079 --> 00:40:45,680
user story

1138
00:40:45,680 --> 00:40:47,200
and so i need to protect it from being

1139
00:40:47,200 --> 00:40:49,920
accessed by attackers

1140
00:40:49,920 --> 00:40:52,319
so let's look at now how does threat

1141
00:40:52,319 --> 00:40:53,680
modeling

1142
00:40:53,680 --> 00:40:55,839
when i bring it to the user story

1143
00:40:55,839 --> 00:40:58,400
actually speed up my entire development

1144
00:40:58,400 --> 00:40:59,680
pipeline

1145
00:40:59,680 --> 00:41:01,119
so i've got this thread information in

1146
00:41:01,119 --> 00:41:03,200
the user story it's in simple plain

1147
00:41:03,200 --> 00:41:05,040
language anybody can read that and

1148
00:41:05,040 --> 00:41:06,640
understand it

1149
00:41:06,640 --> 00:41:08,800
that means when my developer takes that

1150
00:41:08,800 --> 00:41:11,920
or i if i am the developer take that off

1151
00:41:11,920 --> 00:41:13,359
the backlog and i look at that user

1152
00:41:13,359 --> 00:41:15,440
story and i start to think in my mind

1153
00:41:15,440 --> 00:41:16,800
that might be the only planning and

1154
00:41:16,800 --> 00:41:19,520
design i do is in my own head

1155
00:41:19,520 --> 00:41:21,520
i can already start to think of what the

1156
00:41:21,520 --> 00:41:23,599
security requirements are based on that

1157
00:41:23,599 --> 00:41:25,440
information

1158
00:41:25,440 --> 00:41:27,440
now because i have that information for

1159
00:41:27,440 --> 00:41:30,319
those security requirements well those

1160
00:41:30,319 --> 00:41:32,000
feed the security controls i'm going to

1161
00:41:32,000 --> 00:41:34,160
build i've now made an informed design

1162
00:41:34,160 --> 00:41:36,400
decision

1163
00:41:36,400 --> 00:41:39,520
that's the goal threat modeling

1164
00:41:39,520 --> 00:41:41,760
but it gets better and this is where

1165
00:41:41,760 --> 00:41:43,760
things really start to hit and this is

1166
00:41:43,760 --> 00:41:45,760
where things get more efficient

1167
00:41:45,760 --> 00:41:47,839
so first and foremost i mean if i'm

1168
00:41:47,839 --> 00:41:49,760
really good just having that information

1169
00:41:49,760 --> 00:41:51,119
where my developers don't have to sit

1170
00:41:51,119 --> 00:41:53,119
down and really dig into trying to

1171
00:41:53,119 --> 00:41:54,400
figure out what the threats are and what

1172
00:41:54,400 --> 00:41:56,480
the critical assets are that's wonderful

1173
00:41:56,480 --> 00:41:58,000
right i've already made their jobs

1174
00:41:58,000 --> 00:41:59,680
easier but now when i have that

1175
00:41:59,680 --> 00:42:01,520
information and i know what security

1176
00:42:01,520 --> 00:42:03,040
controls i built based on these

1177
00:42:03,040 --> 00:42:04,319
requirements which are based on the

1178
00:42:04,319 --> 00:42:06,480
threat information now i can feed that

1179
00:42:06,480 --> 00:42:08,560
to my test cases

1180
00:42:08,560 --> 00:42:10,640
i know what security test cases are most

1181
00:42:10,640 --> 00:42:12,160
important to me because they were in my

1182
00:42:12,160 --> 00:42:13,760
threat model

1183
00:42:13,760 --> 00:42:16,400
so instead of trying to test the world i

1184
00:42:16,400 --> 00:42:18,640
can test those very specific controls

1185
00:42:18,640 --> 00:42:20,160
that i've implemented

1186
00:42:20,160 --> 00:42:21,920
and now because i know that

1187
00:42:21,920 --> 00:42:24,240
i can leverage that after i deploy to

1188
00:42:24,240 --> 00:42:26,000
implement monitoring

1189
00:42:26,000 --> 00:42:27,920
so i know the types of attacks i need to

1190
00:42:27,920 --> 00:42:29,359
be looking for i know what i need to be

1191
00:42:29,359 --> 00:42:31,359
watching for

1192
00:42:31,359 --> 00:42:33,839
now this is great but okay how do i

1193
00:42:33,839 --> 00:42:36,400
actually make this happen in practice

1194
00:42:36,400 --> 00:42:37,920
let's think about where developers live

1195
00:42:37,920 --> 00:42:41,119
and now admittedly this is probably more

1196
00:42:41,119 --> 00:42:42,800
in like a development organization as

1197
00:42:42,800 --> 00:42:44,560
opposed to a single developer doing your

1198
00:42:44,560 --> 00:42:49,200
work you know maintaining a library but

1199
00:42:49,200 --> 00:42:51,359
how do i make this work

1200
00:42:51,359 --> 00:42:53,040
this is some of the worst yaml you're

1201
00:42:53,040 --> 00:42:55,040
ever going to see it's valid it's valid

1202
00:42:55,040 --> 00:42:56,720
yaml but it's over simplistic but it's

1203
00:42:56,720 --> 00:42:59,280
just to describe this so

1204
00:42:59,280 --> 00:43:00,720
thinking about where how do we meet

1205
00:43:00,720 --> 00:43:02,079
developers where they live and create

1206
00:43:02,079 --> 00:43:04,319
things that are less friction

1207
00:43:04,319 --> 00:43:06,079
developers are all up and you know

1208
00:43:06,079 --> 00:43:08,160
dealing with yaml on a daily basis now

1209
00:43:08,160 --> 00:43:10,480
it's what drives our pipelines it's what

1210
00:43:10,480 --> 00:43:12,400
helps you know build our cloud formation

1211
00:43:12,400 --> 00:43:14,079
it's everything

1212
00:43:14,079 --> 00:43:16,400
so as i'm building out what if i was to

1213
00:43:16,400 --> 00:43:18,400
simply build out some yaml that actually

1214
00:43:18,400 --> 00:43:21,119
described the threat model

1215
00:43:21,119 --> 00:43:23,920
the countermeasures that i put in place

1216
00:43:23,920 --> 00:43:27,839
and the the assets

1217
00:43:28,560 --> 00:43:30,240
if i've got that documented in the ammo

1218
00:43:30,240 --> 00:43:32,720
that i can be leveraged now to automate

1219
00:43:32,720 --> 00:43:33,920
the building of my

1220
00:43:33,920 --> 00:43:36,160
security test cases that provides that

1221
00:43:36,160 --> 00:43:37,599
information all the way through to my

1222
00:43:37,599 --> 00:43:40,160
ops team when they go to launch their

1223
00:43:40,160 --> 00:43:41,839
monitoring

1224
00:43:41,839 --> 00:43:44,000
this is collaborative

1225
00:43:44,000 --> 00:43:46,160
now collaboration doesn't necessarily

1226
00:43:46,160 --> 00:43:48,079
mean 40 people in a room talking about

1227
00:43:48,079 --> 00:43:50,800
the same thing at the same time

1228
00:43:50,800 --> 00:43:52,800
if we're bringing this together so i

1229
00:43:52,800 --> 00:43:55,680
have my user story feeds my now my

1230
00:43:55,680 --> 00:43:56,960
threat yaml

1231
00:43:56,960 --> 00:43:59,280
and my design and yaml and whatnot i've

1232
00:43:59,280 --> 00:44:02,079
got all this information there

1233
00:44:02,079 --> 00:44:03,760
i'm still collaborating i still have

1234
00:44:03,760 --> 00:44:06,839
everybody kind of coming to a general

1235
00:44:06,839 --> 00:44:08,400
understanding

1236
00:44:08,400 --> 00:44:11,040
of the system its assets and the threats

1237
00:44:11,040 --> 00:44:12,880
it faces and the counter measures that

1238
00:44:12,880 --> 00:44:15,520
we're implementing

1239
00:44:15,520 --> 00:44:17,440
so here's a simple example

1240
00:44:17,440 --> 00:44:18,720
from before

1241
00:44:18,720 --> 00:44:20,960
those search terms that's our asset

1242
00:44:20,960 --> 00:44:23,119
little description of what they are

1243
00:44:23,119 --> 00:44:25,440
a couple threats just plain language

1244
00:44:25,440 --> 00:44:26,960
threats

1245
00:44:26,960 --> 00:44:29,200
so if i assume it's maybe a rest service

1246
00:44:29,200 --> 00:44:31,200
that sits behind there all right so i

1247
00:44:31,200 --> 00:44:32,800
could have thrust

1248
00:44:32,800 --> 00:44:36,880
the threat of theft via that service

1249
00:44:36,880 --> 00:44:38,480
so some countermeasures i might

1250
00:44:38,480 --> 00:44:40,400
implement a client certificate i might

1251
00:44:40,400 --> 00:44:42,160
implement session tokens i might do some

1252
00:44:42,160 --> 00:44:43,839
other things but those are counter

1253
00:44:43,839 --> 00:44:45,280
measures that are meant to protect

1254
00:44:45,280 --> 00:44:46,720
against that

1255
00:44:46,720 --> 00:44:47,920
i might have

1256
00:44:47,920 --> 00:44:51,040
theft via the database

1257
00:44:51,040 --> 00:44:53,200
if someone gains access to my database

1258
00:44:53,200 --> 00:44:54,960
through sql injection attacks or other

1259
00:44:54,960 --> 00:44:56,560
things

1260
00:44:56,560 --> 00:44:58,000
well if i

1261
00:44:58,000 --> 00:44:59,920
encrypt the field where

1262
00:44:59,920 --> 00:45:02,560
that information is being stored

1263
00:45:02,560 --> 00:45:04,319
now that's a counter measure to that

1264
00:45:04,319 --> 00:45:05,440
threat

1265
00:45:05,440 --> 00:45:07,200
so these are things now that i can use

1266
00:45:07,200 --> 00:45:09,440
to manage and by doing so i've made

1267
00:45:09,440 --> 00:45:12,880
those other tasks the qa tasks the the

1268
00:45:12,880 --> 00:45:15,119
deployment tasks become

1269
00:45:15,119 --> 00:45:16,240
far

1270
00:45:16,240 --> 00:45:17,280
more

1271
00:45:17,280 --> 00:45:18,560
efficient

1272
00:45:18,560 --> 00:45:19,839
because i have all this information

1273
00:45:19,839 --> 00:45:21,680
there and it all started by getting that

1274
00:45:21,680 --> 00:45:24,560
into the user story in small

1275
00:45:24,560 --> 00:45:27,040
manageable iterations

1276
00:45:27,040 --> 00:45:28,720
this is where threat modeling can take

1277
00:45:28,720 --> 00:45:30,240
us

1278
00:45:30,240 --> 00:45:31,680
it's just simply asking what can go

1279
00:45:31,680 --> 00:45:32,880
wrong

1280
00:45:32,880 --> 00:45:34,800
planning for it implementing

1281
00:45:34,800 --> 00:45:37,119
countermeasures and then using that

1282
00:45:37,119 --> 00:45:38,319
information

1283
00:45:38,319 --> 00:45:39,920
we can make that whole pipeline more

1284
00:45:39,920 --> 00:45:42,000
efficient

1285
00:45:42,000 --> 00:45:44,079
so i'm going to wrap up here but i want

1286
00:45:44,079 --> 00:45:46,640
to leave you with a quote love albert

1287
00:45:46,640 --> 00:45:48,560
einstein i love this quote genius is

1288
00:45:48,560 --> 00:45:51,520
making complex ideas simple

1289
00:45:51,520 --> 00:45:55,359
not making simple ideas complex

1290
00:45:55,359 --> 00:45:57,119
i want to understand threat modeling

1291
00:45:57,119 --> 00:45:59,599
it's this complex idea

1292
00:45:59,599 --> 00:46:01,200
i want to take it and break it down into

1293
00:46:01,200 --> 00:46:02,880
the simple question of what could

1294
00:46:02,880 --> 00:46:05,839
possibly go wrong

1295
00:46:06,079 --> 00:46:07,920
and if i want to implement that modeling

1296
00:46:07,920 --> 00:46:09,839
i don't want to take that simple what

1297
00:46:09,839 --> 00:46:11,839
could possibly go wrong and make it

1298
00:46:11,839 --> 00:46:14,960
complex with a whole bunch of jargon and

1299
00:46:14,960 --> 00:46:16,400
complex

1300
00:46:16,400 --> 00:46:18,960
frameworks and other things

1301
00:46:18,960 --> 00:46:22,240
keep it simple

1302
00:46:22,319 --> 00:46:24,960
so as i wrap up um i always invite you

1303
00:46:24,960 --> 00:46:27,040
guys to reach out please by all means

1304
00:46:27,040 --> 00:46:28,560
follow me on twitter

1305
00:46:28,560 --> 00:46:30,640
i always love to connect with people

1306
00:46:30,640 --> 00:46:33,200
talk more about these concepts

1307
00:46:33,200 --> 00:46:34,720
my linkedin is up there as well if you

1308
00:46:34,720 --> 00:46:36,560
prefer linkedin

1309
00:46:36,560 --> 00:46:39,440
uh you also have my website there i'm

1310
00:46:39,440 --> 00:46:41,440
happy to to connect with you and we can

1311
00:46:41,440 --> 00:46:42,800
talk further about threat modeling we

1312
00:46:42,800 --> 00:46:45,040
can talk about you know hacking modems

1313
00:46:45,040 --> 00:46:46,720
at 12 whatever you want to chat about

1314
00:46:46,720 --> 00:46:49,119
i'm always happy to talk

1315
00:46:49,119 --> 00:46:50,800
and then finally great big thank you

1316
00:46:50,800 --> 00:46:52,240
thank you to my organization for

1317
00:46:52,240 --> 00:46:53,839
everything they do for me

1318
00:46:53,839 --> 00:46:56,960
thank you to all of you for being here

1319
00:46:56,960 --> 00:46:58,800
today and gene i appreciate the

1320
00:46:58,800 --> 00:47:00,720
invitation having me today it's been

1321
00:47:00,720 --> 00:47:01,920
wonderful

1322
00:47:01,920 --> 00:47:05,920
and i will open it back up to you

1323
00:47:05,920 --> 00:47:08,960
thank you so much alyssa uh

1324
00:47:08,960 --> 00:47:11,760
that's really interesting um we

1325
00:47:11,760 --> 00:47:13,520
talk a little bit about threat modeling

1326
00:47:13,520 --> 00:47:15,280
in some of our classes but it's not a

1327
00:47:15,280 --> 00:47:17,119
primary aspect

1328
00:47:17,119 --> 00:47:19,599
in in some of our curricula

1329
00:47:19,599 --> 00:47:22,839
uh so it's it's great to hear that

1330
00:47:22,839 --> 00:47:26,160
um we have a question in the q a and i

1331
00:47:26,160 --> 00:47:27,599
would encourage other members of the

1332
00:47:27,599 --> 00:47:28,640
audience

1333
00:47:28,640 --> 00:47:30,960
to post their questions to the q a as

1334
00:47:30,960 --> 00:47:32,559
well uh do you want to read those

1335
00:47:32,559 --> 00:47:34,800
directly or would you like to yeah

1336
00:47:34,800 --> 00:47:37,040
so i got one from here from alex and

1337
00:47:37,040 --> 00:47:39,599
he's asking uh can i speak to how

1338
00:47:39,599 --> 00:47:42,000
privacy has worked into

1339
00:47:42,000 --> 00:47:44,000
the cyber security space models such as

1340
00:47:44,000 --> 00:47:45,599
stride have always been focused on

1341
00:47:45,599 --> 00:47:48,240
security aspects and you know the cia

1342
00:47:48,240 --> 00:47:49,440
triad

1343
00:47:49,440 --> 00:47:50,480
um

1344
00:47:50,480 --> 00:47:53,280
but you know organizations are called on

1345
00:47:53,280 --> 00:47:55,599
more and more to to confront privacy

1346
00:47:55,599 --> 00:47:56,960
implications

1347
00:47:56,960 --> 00:47:58,880
and that's exactly i mean you saw a

1348
00:47:58,880 --> 00:48:00,880
perfect example of that right so with

1349
00:48:00,880 --> 00:48:03,280
this idea of that mapping application

1350
00:48:03,280 --> 00:48:05,119
and search history

1351
00:48:05,119 --> 00:48:06,559
you know maybe that's not even so much

1352
00:48:06,559 --> 00:48:08,079
of a cyber security concern but that's a

1353
00:48:08,079 --> 00:48:10,160
definite privacy concern and that's

1354
00:48:10,160 --> 00:48:13,040
exactly why i stress getting away from

1355
00:48:13,040 --> 00:48:14,640
those frameworks where they're really

1356
00:48:14,640 --> 00:48:17,040
focused on security jargon

1357
00:48:17,040 --> 00:48:18,480
and when we think about instead of just

1358
00:48:18,480 --> 00:48:20,720
okay what is what's most important what

1359
00:48:20,720 --> 00:48:22,480
is that most important asset or what are

1360
00:48:22,480 --> 00:48:24,960
a couple really important assets that

1361
00:48:24,960 --> 00:48:27,200
are involved in a user story

1362
00:48:27,200 --> 00:48:29,440
and then i break that down and i think

1363
00:48:29,440 --> 00:48:31,599
about it in terms of okay you know what

1364
00:48:31,599 --> 00:48:33,440
could possibly go wrong here

1365
00:48:33,440 --> 00:48:35,599
it's not always a security answer

1366
00:48:35,599 --> 00:48:38,000
sometimes it is a privacy answer

1367
00:48:38,000 --> 00:48:39,680
and so that's we're getting away from

1368
00:48:39,680 --> 00:48:41,200
that yeah we can leverage threat

1369
00:48:41,200 --> 00:48:44,000
modeling much broader and it does help

1370
00:48:44,000 --> 00:48:45,280
us then

1371
00:48:45,280 --> 00:48:47,680
to address that a little bit easier than

1372
00:48:47,680 --> 00:48:49,599
you know where some of the other privacy

1373
00:48:49,599 --> 00:48:51,599
frameworks get really technically

1374
00:48:51,599 --> 00:48:53,440
focused and we kind of lose sight of

1375
00:48:53,440 --> 00:48:56,559
what we're really trying to do

1376
00:48:57,119 --> 00:48:59,280
so douglas asks thank you for speaking

1377
00:48:59,280 --> 00:49:01,760
today if you had only three months to

1378
00:49:01,760 --> 00:49:03,440
train someone

1379
00:49:03,440 --> 00:49:05,280
to be an entry-level security

1380
00:49:05,280 --> 00:49:07,119
professional what areas would i

1381
00:49:07,119 --> 00:49:10,240
concentrate on

1382
00:49:10,880 --> 00:49:12,480
boy that's a tough question because

1383
00:49:12,480 --> 00:49:14,839
security professionals even a broad

1384
00:49:14,839 --> 00:49:18,160
broad space um

1385
00:49:18,160 --> 00:49:20,319
you know honestly i

1386
00:49:20,319 --> 00:49:21,520
this is going to sound like a cop-out

1387
00:49:21,520 --> 00:49:22,720
answer but

1388
00:49:22,720 --> 00:49:23,599
you know i

1389
00:49:23,599 --> 00:49:25,839
everybody already has something they

1390
00:49:25,839 --> 00:49:27,200
bring to the table that fits in the

1391
00:49:27,200 --> 00:49:29,119
security space right cyber security is

1392
00:49:29,119 --> 00:49:32,079
inherent to our just our way of life

1393
00:49:32,079 --> 00:49:33,520
and so

1394
00:49:33,520 --> 00:49:34,400
you know

1395
00:49:34,400 --> 00:49:36,640
understanding

1396
00:49:36,640 --> 00:49:38,559
you know just

1397
00:49:38,559 --> 00:49:39,839
where we've come from we bring an

1398
00:49:39,839 --> 00:49:41,440
important perspective to cyber security

1399
00:49:41,440 --> 00:49:42,720
but if you really want to dig into

1400
00:49:42,720 --> 00:49:44,960
something to try to you know prepare

1401
00:49:44,960 --> 00:49:47,760
yourself i would say really understand

1402
00:49:47,760 --> 00:49:50,720
the idea of risk and when i say risk i

1403
00:49:50,720 --> 00:49:52,559
don't just mean cyber security risk i

1404
00:49:52,559 --> 00:49:54,960
mean risk as it pertains to an

1405
00:49:54,960 --> 00:49:57,680
organization so that you understand when

1406
00:49:57,680 --> 00:49:59,280
i'm a ceo

1407
00:49:59,280 --> 00:50:01,440
and i'm looking at business risk it's

1408
00:50:01,440 --> 00:50:03,839
not just cyber security it's not just

1409
00:50:03,839 --> 00:50:05,760
privacy it's not just regulatory it's

1410
00:50:05,760 --> 00:50:08,800
financial it's market risk

1411
00:50:08,800 --> 00:50:10,160
all of these things and if you can

1412
00:50:10,160 --> 00:50:12,559
figure that out and understand how cyber

1413
00:50:12,559 --> 00:50:14,400
security fits in it

1414
00:50:14,400 --> 00:50:16,640
in those terms

1415
00:50:16,640 --> 00:50:18,880
and then tie in the technical aspects i

1416
00:50:18,880 --> 00:50:20,400
mean i could tell you i could throw out

1417
00:50:20,400 --> 00:50:22,319
here for you yeah you know go learn this

1418
00:50:22,319 --> 00:50:24,079
technical thing or that technical thing

1419
00:50:24,079 --> 00:50:25,599
but it's all going to vary based on the

1420
00:50:25,599 --> 00:50:27,760
role you're looking for

1421
00:50:27,760 --> 00:50:29,760
the one thing that never changes

1422
00:50:29,760 --> 00:50:31,119
is the need for us to be able to

1423
00:50:31,119 --> 00:50:33,920
understand risk

1424
00:50:35,760 --> 00:50:39,520
which of those guitars is my favorite

1425
00:50:39,520 --> 00:50:41,760
uh let's see can you see it from here

1426
00:50:41,760 --> 00:50:44,079
it's kind of hidden behind

1427
00:50:44,079 --> 00:50:45,440
um

1428
00:50:45,440 --> 00:50:47,280
so i'm rather and go get it i'll just

1429
00:50:47,280 --> 00:50:48,960
tell you there's a

1430
00:50:48,960 --> 00:50:50,319
one of the guitars i have over there is

1431
00:50:50,319 --> 00:50:52,559
a grech baritone

1432
00:50:52,559 --> 00:50:54,480
um so

1433
00:50:54,480 --> 00:50:56,480
regular it's a six string guitar but

1434
00:50:56,480 --> 00:50:58,559
with a longer scale

1435
00:50:58,559 --> 00:50:59,520
and

1436
00:50:59,520 --> 00:51:01,839
it's instead of being you know a low e

1437
00:51:01,839 --> 00:51:05,599
to a high e it's a low b to high b which

1438
00:51:05,599 --> 00:51:08,240
means it's a fourth step it's you know a

1439
00:51:08,240 --> 00:51:10,480
fourth down from the standard tuning of

1440
00:51:10,480 --> 00:51:13,760
a guitar um it's just it's got a really

1441
00:51:13,760 --> 00:51:16,160
really haunting tone and it's actually

1442
00:51:16,160 --> 00:51:17,839
really cool

1443
00:51:17,839 --> 00:51:19,040
um

1444
00:51:19,040 --> 00:51:20,880
can you compare and contrast including

1445
00:51:20,880 --> 00:51:23,680
threat modeling and user stories versus

1446
00:51:23,680 --> 00:51:26,160
defining abuser stories

1447
00:51:26,160 --> 00:51:28,319
so my issue with abuser stories or abuse

1448
00:51:28,319 --> 00:51:30,079
cases is that

1449
00:51:30,079 --> 00:51:33,119
unfortunately two things happen there

1450
00:51:33,119 --> 00:51:34,800
the way they've traditionally been

1451
00:51:34,800 --> 00:51:36,480
talked about requires that deep like

1452
00:51:36,480 --> 00:51:38,559
cyber security

1453
00:51:38,559 --> 00:51:41,200
knowledge and you know if you have to

1454
00:51:41,200 --> 00:51:42,960
have sort of that base knowledge to do

1455
00:51:42,960 --> 00:51:43,599
it

1456
00:51:43,599 --> 00:51:46,240
and then second it's

1457
00:51:46,240 --> 00:51:47,920
it's trying to get into the mind of the

1458
00:51:47,920 --> 00:51:49,200
attacker

1459
00:51:49,200 --> 00:51:51,920
which honestly there's so many attackers

1460
00:51:51,920 --> 00:51:53,839
out there with their own mindsets that's

1461
00:51:53,839 --> 00:51:55,359
not what we want to be thinking about we

1462
00:51:55,359 --> 00:51:56,480
don't want to be trying to predict what

1463
00:51:56,480 --> 00:51:59,119
the attacker is going to do necessarily

1464
00:51:59,119 --> 00:52:00,640
we want to be thinking about what

1465
00:52:00,640 --> 00:52:03,520
matters the most to me and how you know

1466
00:52:03,520 --> 00:52:06,640
and what are the types of um

1467
00:52:06,640 --> 00:52:07,839
you know counter measures and things

1468
00:52:07,839 --> 00:52:10,720
that i need to bring as a result so

1469
00:52:10,720 --> 00:52:13,359
abuser stories are

1470
00:52:13,359 --> 00:52:15,839
are good in a sense i mean i like what

1471
00:52:15,839 --> 00:52:17,920
the attempt there is to do it's to

1472
00:52:17,920 --> 00:52:21,119
really understand okay what is the full

1473
00:52:21,119 --> 00:52:23,599
i guess use case but now an abuse case

1474
00:52:23,599 --> 00:52:25,280
for how somebody might go about

1475
00:52:25,280 --> 00:52:27,359
exploiting but that becomes so

1476
00:52:27,359 --> 00:52:29,200
predictive and so granular that if

1477
00:52:29,200 --> 00:52:30,960
you're focused on that rather than just

1478
00:52:30,960 --> 00:52:32,800
focused on how do i defend these assets

1479
00:52:32,800 --> 00:52:34,640
from specific threats

1480
00:52:34,640 --> 00:52:36,480
you get a little too

1481
00:52:36,480 --> 00:52:38,319
granular in your focus and you you'll

1482
00:52:38,319 --> 00:52:40,880
miss things and so that's why i don't

1483
00:52:40,880 --> 00:52:43,040
like to see it be that specific and then

1484
00:52:43,040 --> 00:52:45,440
again i don't i want more people

1485
00:52:45,440 --> 00:52:46,400
involved

1486
00:52:46,400 --> 00:52:47,520
not less

1487
00:52:47,520 --> 00:52:49,040
so if someone's got to do a bunch of

1488
00:52:49,040 --> 00:52:50,400
training just to be able to do threat

1489
00:52:50,400 --> 00:52:51,520
modeling

1490
00:52:51,520 --> 00:52:53,359
that already makes it a very exclusive

1491
00:52:53,359 --> 00:52:57,200
environment and i that makes me nervous

1492
00:52:57,200 --> 00:52:59,280
does he be so have to necessarily be

1493
00:52:59,280 --> 00:53:01,760
somebody with a business background no

1494
00:53:01,760 --> 00:53:04,079
i have absolutely no business background

1495
00:53:04,079 --> 00:53:05,359
what you need to be is you need to be

1496
00:53:05,359 --> 00:53:07,599
somebody who has

1497
00:53:07,599 --> 00:53:09,520
a certain level of empathy

1498
00:53:09,520 --> 00:53:12,079
who you know can kind of

1499
00:53:12,079 --> 00:53:13,280
uh who's

1500
00:53:13,280 --> 00:53:14,480
able to understand

1501
00:53:14,480 --> 00:53:16,960
those varying audiences and understand

1502
00:53:16,960 --> 00:53:19,200
different people's motivations

1503
00:53:19,200 --> 00:53:21,280
um and then it's really just have the

1504
00:53:21,280 --> 00:53:22,880
desire to

1505
00:53:22,880 --> 00:53:24,720
get in and learn the business

1506
00:53:24,720 --> 00:53:27,599
so i work for s p global ratings

1507
00:53:27,599 --> 00:53:29,440
we are a credit rating agency we do

1508
00:53:29,440 --> 00:53:30,880
ratings for

1509
00:53:30,880 --> 00:53:33,119
large enterprise organizations nation

1510
00:53:33,119 --> 00:53:34,880
states things like that

1511
00:53:34,880 --> 00:53:38,000
i coming in the door knew absolutely

1512
00:53:38,000 --> 00:53:39,040
nothing

1513
00:53:39,040 --> 00:53:40,880
about that business i didn't know

1514
00:53:40,880 --> 00:53:42,800
anything about ratings whatsoever i

1515
00:53:42,800 --> 00:53:45,440
don't have an mba i so you know on that

1516
00:53:45,440 --> 00:53:47,359
side i've that's all stuff i've kind of

1517
00:53:47,359 --> 00:53:49,280
picked up along the way but the thing

1518
00:53:49,280 --> 00:53:50,800
that i do have

1519
00:53:50,800 --> 00:53:51,760
is

1520
00:53:51,760 --> 00:53:53,680
i've always been very good at

1521
00:53:53,680 --> 00:53:56,400
understanding other people's motivations

1522
00:53:56,400 --> 00:53:58,720
and presenting cyber security concepts

1523
00:53:58,720 --> 00:54:00,240
in a way to them that's meaningful to

1524
00:54:00,240 --> 00:54:01,359
them something that they could

1525
00:54:01,359 --> 00:54:03,760
understand easily that spoke to their

1526
00:54:03,760 --> 00:54:06,800
motivations and made them want to help

1527
00:54:06,800 --> 00:54:09,040
me right because if i explain to you in

1528
00:54:09,040 --> 00:54:10,480
the right way that you understand it and

1529
00:54:10,480 --> 00:54:12,000
you understand how it impacts you and

1530
00:54:12,000 --> 00:54:13,760
can make your life better

1531
00:54:13,760 --> 00:54:15,359
then you want to help me

1532
00:54:15,359 --> 00:54:17,599
accomplish that which is

1533
00:54:17,599 --> 00:54:18,720
perfect

1534
00:54:18,720 --> 00:54:21,119
so that's where i see especially in my

1535
00:54:21,119 --> 00:54:22,880
role i think it's a lot more about that

1536
00:54:22,880 --> 00:54:25,839
being able to to weigh the business

1537
00:54:25,839 --> 00:54:27,839
needs against the cyber security needs

1538
00:54:27,839 --> 00:54:31,040
and find that common ground

1539
00:54:31,520 --> 00:54:34,000
how do you convince the management to

1540
00:54:34,000 --> 00:54:35,839
threat model

1541
00:54:35,839 --> 00:54:38,400
in the develop in the devops cycles it

1542
00:54:38,400 --> 00:54:41,359
adds to the user story tasks cost

1543
00:54:41,359 --> 00:54:44,079
perspective and most of internal threats

1544
00:54:44,079 --> 00:54:46,640
would be not accessible or very

1545
00:54:46,640 --> 00:54:48,640
difficult to a remote attacker

1546
00:54:48,640 --> 00:54:50,480
so here again

1547
00:54:50,480 --> 00:54:51,839
um

1548
00:54:51,839 --> 00:54:53,280
so the user story thing i mean you saw

1549
00:54:53,280 --> 00:54:54,799
how simple that is it's like three extra

1550
00:54:54,799 --> 00:54:56,400
questions right

1551
00:54:56,400 --> 00:54:59,200
and again with it that spirit of we're

1552
00:54:59,200 --> 00:55:00,720
never gonna be perfect we're never gonna

1553
00:55:00,720 --> 00:55:02,240
find all the things

1554
00:55:02,240 --> 00:55:03,839
it's really just asking that person

1555
00:55:03,839 --> 00:55:06,079
who's come up with that idea just to say

1556
00:55:06,079 --> 00:55:07,440
all right

1557
00:55:07,440 --> 00:55:10,160
you've got this idea what what is that

1558
00:55:10,160 --> 00:55:12,720
most critical asset or assets

1559
00:55:12,720 --> 00:55:14,559
and you can get as granular or as light

1560
00:55:14,559 --> 00:55:16,799
as you want here but the fact is by

1561
00:55:16,799 --> 00:55:18,559
doing it in that manageable scope where

1562
00:55:18,559 --> 00:55:21,920
it's just one user story at a time

1563
00:55:21,920 --> 00:55:23,599
the the cost implications of that are

1564
00:55:23,599 --> 00:55:25,520
pretty minor quite honestly and it's

1565
00:55:25,520 --> 00:55:27,280
just you know you're in there creating a

1566
00:55:27,280 --> 00:55:29,040
user story anyway a couple extra

1567
00:55:29,040 --> 00:55:30,559
keystrokes a little bit of thought

1568
00:55:30,559 --> 00:55:31,599
process

1569
00:55:31,599 --> 00:55:33,280
isn't the thing that's that's really

1570
00:55:33,280 --> 00:55:35,599
going to suck up a lot of time

1571
00:55:35,599 --> 00:55:36,640
um

1572
00:55:36,640 --> 00:55:38,720
you know as far as internal versus

1573
00:55:38,720 --> 00:55:40,079
external

1574
00:55:40,079 --> 00:55:41,520
what you're looking at here is okay how

1575
00:55:41,520 --> 00:55:43,119
do i prioritize

1576
00:55:43,119 --> 00:55:45,119
right so i'm looking at what is that

1577
00:55:45,119 --> 00:55:46,720
critical asset

1578
00:55:46,720 --> 00:55:48,319
now the threat to that critical asset

1579
00:55:48,319 --> 00:55:49,839
might be an internal that might be the

1580
00:55:49,839 --> 00:55:52,640
biggest threat um

1581
00:55:52,640 --> 00:55:54,960
an easy example for you is okay what if

1582
00:55:54,960 --> 00:55:58,160
availability i've got an internal system

1583
00:55:58,160 --> 00:55:59,920
it's not available to the external world

1584
00:55:59,920 --> 00:56:01,359
at all

1585
00:56:01,359 --> 00:56:03,920
but availability might be my critical

1586
00:56:03,920 --> 00:56:05,440
asset right

1587
00:56:05,440 --> 00:56:07,040
asset doesn't have to be a tangible

1588
00:56:07,040 --> 00:56:10,000
thing my critical asset could simply be

1589
00:56:10,000 --> 00:56:12,640
the availability of that system and so

1590
00:56:12,640 --> 00:56:14,640
something about or maybe it's a critical

1591
00:56:14,640 --> 00:56:16,640
function because you know this user

1592
00:56:16,640 --> 00:56:18,720
story defines some new critical function

1593
00:56:18,720 --> 00:56:21,040
and so the availability that function is

1594
00:56:21,040 --> 00:56:23,520
is that key thing

1595
00:56:23,520 --> 00:56:25,760
so there again

1596
00:56:25,760 --> 00:56:27,440
i'm finding the things that are most

1597
00:56:27,440 --> 00:56:29,200
important to me because that's what i

1598
00:56:29,200 --> 00:56:30,480
need to be defending

1599
00:56:30,480 --> 00:56:31,839
that's how i start to build cyber

1600
00:56:31,839 --> 00:56:33,280
resiliency

1601
00:56:33,280 --> 00:56:35,480
and that's how i make sure that i'm

1602
00:56:35,480 --> 00:56:38,000
prioritizing and doing things in a

1603
00:56:38,000 --> 00:56:40,240
manner that's that's scalable

1604
00:56:40,240 --> 00:56:43,799
in the long term

1605
00:56:44,960 --> 00:56:46,880
what changes would you want to see in

1606
00:56:46,880 --> 00:56:49,280
education to make security

1607
00:56:49,280 --> 00:56:52,000
more of a focus in development

1608
00:56:52,000 --> 00:56:54,079
boy that's a that's a challenge right

1609
00:56:54,079 --> 00:56:56,559
because developers inherently

1610
00:56:56,559 --> 00:56:59,760
are there to create code or to create

1611
00:56:59,760 --> 00:57:02,160
products or to create things

1612
00:57:02,160 --> 00:57:04,000
and so you know

1613
00:57:04,000 --> 00:57:04,799
where

1614
00:57:04,799 --> 00:57:06,880
i look at the education space and how

1615
00:57:06,880 --> 00:57:10,000
security plays a part i think it's

1616
00:57:10,000 --> 00:57:12,480
broader than what a lot of people might

1617
00:57:12,480 --> 00:57:14,160
think of when we talk about how to

1618
00:57:14,160 --> 00:57:16,799
educate developers like i don't

1619
00:57:16,799 --> 00:57:17,440
i

1620
00:57:17,440 --> 00:57:19,040
i know there's been a lot of talk and a

1621
00:57:19,040 --> 00:57:21,520
lot of work done in bringing you know

1622
00:57:21,520 --> 00:57:23,119
secure coding

1623
00:57:23,119 --> 00:57:26,000
tasks into this into you know as we're

1624
00:57:26,000 --> 00:57:27,280
teaching computer science and we're

1625
00:57:27,280 --> 00:57:29,440
teaching development and i think there's

1626
00:57:29,440 --> 00:57:31,359
value to that but i think

1627
00:57:31,359 --> 00:57:33,920
the greater understanding of how

1628
00:57:33,920 --> 00:57:35,359
inherent

1629
00:57:35,359 --> 00:57:37,440
the systems that we're creating are to

1630
00:57:37,440 --> 00:57:39,280
our digital life

1631
00:57:39,280 --> 00:57:42,400
and understanding you know where that

1632
00:57:42,400 --> 00:57:45,680
begins and how each piece of a

1633
00:57:45,680 --> 00:57:48,319
development life cycle adds to or

1634
00:57:48,319 --> 00:57:50,079
detracts from the security posture of

1635
00:57:50,079 --> 00:57:52,319
what ultimately gets created and helping

1636
00:57:52,319 --> 00:57:55,040
the developers see their part in that i

1637
00:57:55,040 --> 00:57:56,400
think is probably one of the most

1638
00:57:56,400 --> 00:57:58,640
important pieces because

1639
00:57:58,640 --> 00:58:00,880
what happens in most organizations it's

1640
00:58:00,880 --> 00:58:03,040
not that developers don't want to be

1641
00:58:03,040 --> 00:58:04,960
secure it's not they're lazy it's

1642
00:58:04,960 --> 00:58:07,839
nothing like that it's that

1643
00:58:07,839 --> 00:58:10,319
their motivations are different

1644
00:58:10,319 --> 00:58:12,880
you know in an organization my dev's

1645
00:58:12,880 --> 00:58:15,200
first motivation is not to create the

1646
00:58:15,200 --> 00:58:18,160
most secure impenetrable thing ever it

1647
00:58:18,160 --> 00:58:19,599
it's to get through the user stories

1648
00:58:19,599 --> 00:58:21,680
they got pressure on them to to produce

1649
00:58:21,680 --> 00:58:24,240
code get it deployed on time get it you

1650
00:58:24,240 --> 00:58:25,040
know

1651
00:58:25,040 --> 00:58:27,680
first of all write it so it builds

1652
00:58:27,680 --> 00:58:29,119
it doesn't build they haven't done their

1653
00:58:29,119 --> 00:58:30,880
job right so

1654
00:58:30,880 --> 00:58:32,640
that's their motivation so i think what

1655
00:58:32,640 --> 00:58:34,960
we just want to do is bring

1656
00:58:34,960 --> 00:58:37,359
the idea into that that security is a

1657
00:58:37,359 --> 00:58:40,000
part of that too and create that shared

1658
00:58:40,000 --> 00:58:42,799
responsibility but also help them see

1659
00:58:42,799 --> 00:58:45,040
that security and this is on us the

1660
00:58:45,040 --> 00:58:47,119
security practitioners that we're a part

1661
00:58:47,119 --> 00:58:49,280
of that shared responsibility too and

1662
00:58:49,280 --> 00:58:51,200
that the things that we do

1663
00:58:51,200 --> 00:58:53,119
from security practices can actually

1664
00:58:53,119 --> 00:58:55,599
make development easier like you saw

1665
00:58:55,599 --> 00:58:57,359
when i laid out that that progression of

1666
00:58:57,359 --> 00:59:00,799
threat modeling information

1667
00:59:01,359 --> 00:59:03,040
and then how did i go from a software

1668
00:59:03,040 --> 00:59:06,400
developer to a hacker and then a b-cell

1669
00:59:06,400 --> 00:59:07,440
so

1670
00:59:07,440 --> 00:59:09,040
professionally that would be the

1671
00:59:09,040 --> 00:59:10,400
progression

1672
00:59:10,400 --> 00:59:13,839
but the reality is i was i guess i still

1673
00:59:13,839 --> 00:59:15,280
even even

1674
00:59:15,280 --> 00:59:18,160
in just life um so i mean i was that kid

1675
00:59:18,160 --> 00:59:19,599
first of all

1676
00:59:19,599 --> 00:59:22,160
four years old i liked taking apart

1677
00:59:22,160 --> 00:59:24,640
things to figure out how they worked um

1678
00:59:24,640 --> 00:59:25,920
you know my parents weren't always happy

1679
00:59:25,920 --> 00:59:27,040
when they do that when i would take

1680
00:59:27,040 --> 00:59:29,359
apart things like tvs and other

1681
00:59:29,359 --> 00:59:31,280
electronics around the house

1682
00:59:31,280 --> 00:59:32,640
um

1683
00:59:32,640 --> 00:59:34,079
but you know in general they worked when

1684
00:59:34,079 --> 00:59:35,680
i put them back together so hey no harm

1685
00:59:35,680 --> 00:59:36,960
no foul

1686
00:59:36,960 --> 00:59:38,160
but so i always had that kind of

1687
00:59:38,160 --> 00:59:40,240
curiosity to take things out apart and

1688
00:59:40,240 --> 00:59:41,440
figure out how they work i mean that

1689
00:59:41,440 --> 00:59:44,160
that was the the hacker in me but at

1690
00:59:44,160 --> 00:59:46,640
that same time i mean i touched uh gina

1691
00:59:46,640 --> 00:59:48,559
we're talking about this before we got

1692
00:59:48,559 --> 00:59:50,960
started

1693
00:59:51,200 --> 00:59:53,680
you know i i touched my first computer i

1694
00:59:53,680 --> 00:59:55,200
got to play for the first time on a

1695
00:59:55,200 --> 00:59:57,200
computer when i was four years old which

1696
00:59:57,200 --> 01:00:00,160
nowadays isn't a big deal like that

1697
01:00:00,160 --> 01:00:01,440
people are probably starting earlier

1698
01:00:01,440 --> 01:00:03,359
than that but you know this was early

1699
01:00:03,359 --> 01:00:07,200
80s yeah not old um you know

1700
01:00:07,200 --> 01:00:08,799
so that was

1701
01:00:08,799 --> 01:00:10,079
you know that kind of sparked that

1702
01:00:10,079 --> 01:00:11,359
curiosity

1703
01:00:11,359 --> 01:00:12,799
that got me when it was available in

1704
01:00:12,799 --> 01:00:14,400
school i started to learn programming

1705
01:00:14,400 --> 01:00:16,880
taught myself basic programming

1706
01:00:16,880 --> 01:00:17,760
and

1707
01:00:17,760 --> 01:00:20,400
then bought my first computer was 12.

1708
01:00:20,400 --> 01:00:21,440
um

1709
01:00:21,440 --> 01:00:23,359
honestly i got into development by

1710
01:00:23,359 --> 01:00:24,880
accident because i actually went to

1711
01:00:24,880 --> 01:00:27,680
school for at marquette university for

1712
01:00:27,680 --> 01:00:28,960
pre-med

1713
01:00:28,960 --> 01:00:30,720
and after three semesters of college

1714
01:00:30,720 --> 01:00:32,480
chemistry was like yeah peace out i'm

1715
01:00:32,480 --> 01:00:33,920
not doing that

1716
01:00:33,920 --> 01:00:35,599
um and how to change majors and they

1717
01:00:35,599 --> 01:00:37,520
happen to have computer science well at

1718
01:00:37,520 --> 01:00:39,280
that point i already knew programming

1719
01:00:39,280 --> 01:00:42,079
and seemed like it could be an easy path

1720
01:00:42,079 --> 01:00:43,520
to go

1721
01:00:43,520 --> 01:00:46,960
and then it wasn't until

1722
01:00:47,119 --> 01:00:48,160
so you know i mean that was the first

1723
01:00:48,160 --> 01:00:50,079
time i even saw programming being a

1724
01:00:50,079 --> 01:00:52,000
career i still didn't see

1725
01:00:52,000 --> 01:00:52,960
uh

1726
01:00:52,960 --> 01:00:55,520
pen testing being a career until

1727
01:00:55,520 --> 01:00:56,960
i had worked for an organization for

1728
01:00:56,960 --> 01:00:59,040
nine years as a programmer

1729
01:00:59,040 --> 01:01:01,680
and one of the uh security managers who

1730
01:01:01,680 --> 01:01:02,720
i had worked with on a number of

1731
01:01:02,720 --> 01:01:04,720
projects asked me to join her security

1732
01:01:04,720 --> 01:01:06,480
test team

1733
01:01:06,480 --> 01:01:08,640
which was the pen testing team and so

1734
01:01:08,640 --> 01:01:10,319
she just kind of took a flyer on me i

1735
01:01:10,319 --> 01:01:12,559
sort of fell into that role didn't know

1736
01:01:12,559 --> 01:01:15,119
anything about it but it worked out

1737
01:01:15,119 --> 01:01:16,079
um

1738
01:01:16,079 --> 01:01:17,520
and then be so it's just a long

1739
01:01:17,520 --> 01:01:20,559
progression um i've been in a lot of

1740
01:01:20,559 --> 01:01:22,480
different spaces

1741
01:01:22,480 --> 01:01:23,440
um

1742
01:01:23,440 --> 01:01:26,160
in leadership roles for the last you

1743
01:01:26,160 --> 01:01:29,200
know 12 years 13 years

1744
01:01:29,200 --> 01:01:31,440
14 years holy cow

1745
01:01:31,440 --> 01:01:33,760
um

1746
01:01:34,160 --> 01:01:35,280
but it was seeing a lot of different

1747
01:01:35,280 --> 01:01:36,720
things so i worked at that financial

1748
01:01:36,720 --> 01:01:38,160
services company where i started as a

1749
01:01:38,160 --> 01:01:39,920
program i worked there for 15 years but

1750
01:01:39,920 --> 01:01:41,520
then i got into consulting and i was in

1751
01:01:41,520 --> 01:01:43,599
consulting for eight years so i got to

1752
01:01:43,599 --> 01:01:45,520
see a lot of different industries i got

1753
01:01:45,520 --> 01:01:47,040
to

1754
01:01:47,040 --> 01:01:49,680
the p the le the um you know

1755
01:01:49,680 --> 01:01:51,760
organizational level of the people i was

1756
01:01:51,760 --> 01:01:53,599
talking to started to increase instead

1757
01:01:53,599 --> 01:01:55,599
of talking to devs or engineering

1758
01:01:55,599 --> 01:01:59,119
managers i started talking to vps and

1759
01:01:59,119 --> 01:02:02,799
csos and and doing board presentations

1760
01:02:02,799 --> 01:02:03,760
and

1761
01:02:03,760 --> 01:02:05,680
and then i spent some time working for

1762
01:02:05,680 --> 01:02:06,640
vendor

1763
01:02:06,640 --> 01:02:09,440
i spent some time working at a reseller

1764
01:02:09,440 --> 01:02:11,280
all of that it just gave me a lot of

1765
01:02:11,280 --> 01:02:12,720
different background and i think that

1766
01:02:12,720 --> 01:02:15,359
kind of culminated in the role that i'm

1767
01:02:15,359 --> 01:02:18,160
in now so it's it's one of those things

1768
01:02:18,160 --> 01:02:20,640
um you know for me it was a long trek i

1769
01:02:20,640 --> 01:02:22,480
think we're getting better in security

1770
01:02:22,480 --> 01:02:24,640
though at creating kind of that job

1771
01:02:24,640 --> 01:02:27,039
mapping and you know sort of that career

1772
01:02:27,039 --> 01:02:28,160
progression

1773
01:02:28,160 --> 01:02:29,760
but i think the big thing you know with

1774
01:02:29,760 --> 01:02:31,920
the be so is you do have to have

1775
01:02:31,920 --> 01:02:33,200
sort of that you do have to have some

1776
01:02:33,200 --> 01:02:35,200
business understanding like i'm not an

1777
01:02:35,200 --> 01:02:37,280
mba i said that you know i

1778
01:02:37,280 --> 01:02:39,200
but i i've been exposed to enough of the

1779
01:02:39,200 --> 01:02:41,200
concepts i've done my own you know

1780
01:02:41,200 --> 01:02:43,760
studying and what not to understand

1781
01:02:43,760 --> 01:02:45,200
what some of the things are you learning

1782
01:02:45,200 --> 01:02:47,440
an mba program to understand you know

1783
01:02:47,440 --> 01:02:49,119
what is the cfo looking at what is the

1784
01:02:49,119 --> 01:02:52,720
ceo looking at what is the ceo thinking

1785
01:02:52,720 --> 01:02:54,400
so that when i have those conversations

1786
01:02:54,400 --> 01:02:56,640
i can speak to them effectively i think

1787
01:02:56,640 --> 01:02:59,039
all of that's been really valuable to me

1788
01:02:59,039 --> 01:03:02,920
in getting into that role

1789
01:03:03,839 --> 01:03:06,160
that's great this generated a lot of

1790
01:03:06,160 --> 01:03:08,400
questions thank you for answering them

1791
01:03:08,400 --> 01:03:11,760
yeah i know people appreciate that and

1792
01:03:11,760 --> 01:03:13,359
also for being very generous with

1793
01:03:13,359 --> 01:03:16,079
sharing contact information so if there

1794
01:03:16,079 --> 01:03:17,680
are other questions that occur to people

1795
01:03:17,680 --> 01:03:20,000
they can address them to you

1796
01:03:20,000 --> 01:03:21,119
uh

1797
01:03:21,119 --> 01:03:23,599
thank you very much for the talk i think

1798
01:03:23,599 --> 01:03:26,559
really if i if i were to summarize this

1799
01:03:26,559 --> 01:03:28,319
something that we've stressed here is

1800
01:03:28,319 --> 01:03:30,558
that

1801
01:03:30,880 --> 01:03:33,839
security is better when it's integrated

1802
01:03:33,839 --> 01:03:36,240
into the processes rather than as

1803
01:03:36,240 --> 01:03:38,160
something separate that you try and

1804
01:03:38,160 --> 01:03:40,079
layer on top afterwards

1805
01:03:40,079 --> 01:03:42,160
and and you certainly have underscored

1806
01:03:42,160 --> 01:03:44,000
that here

1807
01:03:44,000 --> 01:03:46,160
um

1808
01:03:46,160 --> 01:03:48,160
i would like to

1809
01:03:48,160 --> 01:03:49,760
remind the audience

1810
01:03:49,760 --> 01:03:51,920
that we have uh

1811
01:03:51,920 --> 01:03:53,839
next week

1812
01:03:53,839 --> 01:03:57,119
dr chris demchik who is the

1813
01:03:57,119 --> 01:03:59,039
grace murray hopper chair at the u.s

1814
01:03:59,039 --> 01:04:01,359
naval war college and she'll be talking

1815
01:04:01,359 --> 01:04:03,680
about operational resilience work she's

1816
01:04:03,680 --> 01:04:05,520
been doing there so a very different

1817
01:04:05,520 --> 01:04:07,599
perspective in some respects

1818
01:04:07,599 --> 01:04:10,799
but another great talk coming up

1819
01:04:10,799 --> 01:04:13,760
those of you who are in indiana uh drive

1820
01:04:13,760 --> 01:04:15,920
safely walk safely

1821
01:04:15,920 --> 01:04:17,839
and uh thank you very much for attending

1822
01:04:17,839 --> 01:04:19,039
everyone

1823
01:04:19,039 --> 01:04:22,200
good night

1824
01:04:38,720 --> 01:04:40,799
you

