1
00:00:05,770 --> 00:00:14,030
welcome to the next stock in the series

2
00:00:08,870 --> 00:00:17,479
of CBS seminar for sprint 2017 so today

3
00:00:14,030 --> 00:00:20,330
we have our own squad car Scott recently

4
00:00:17,480 --> 00:00:23,060
defended his PhD successfully in capital

5
00:00:20,330 --> 00:00:26,000
science department where he worked with

6
00:00:23,060 --> 00:00:29,269
professor Matthew spire and then I guess

7
00:00:26,000 --> 00:00:31,789
he is going to join NGC soon after

8
00:00:29,269 --> 00:00:35,030
finishing his PhD over here Scott's

9
00:00:31,789 --> 00:00:37,370
works on typical say program analysis

10
00:00:35,030 --> 00:00:39,350
did dynamic analysis static analysis in

11
00:00:37,370 --> 00:00:40,989
that field and today he is going to

12
00:00:39,350 --> 00:00:43,579
share what are some of his recent work

13
00:00:40,989 --> 00:00:46,370
that he is going to present next week at

14
00:00:43,579 --> 00:00:49,370
HS e seus and today is going to talk

15
00:00:46,370 --> 00:00:50,899
more about what he is going to talk

16
00:00:49,370 --> 00:00:54,828
about their but obviously a bit more

17
00:00:50,899 --> 00:00:57,620
detail so Scott you Thanks yeah so

18
00:00:54,829 --> 00:01:00,379
professor prescott i mentioned i'm scott

19
00:00:57,620 --> 00:01:02,510
caramel a PhD student here at Purdue and

20
00:01:00,379 --> 00:01:03,919
I recently defended he mentioned that i

21
00:01:02,510 --> 00:01:05,630
work with matthias pay our groups called

22
00:01:03,920 --> 00:01:06,980
the hex hive group so if you want to

23
00:01:05,630 --> 00:01:08,449
google that to find out any more

24
00:01:06,980 --> 00:01:11,360
information about the group you should

25
00:01:08,450 --> 00:01:14,330
be able to find that online so I'm going

26
00:01:11,360 --> 00:01:16,759
to be presenting this paper is this talk

27
00:01:14,330 --> 00:01:18,798
is on the main research paper for my

28
00:01:16,759 --> 00:01:23,150
thesis that I've been working on for

29
00:01:18,799 --> 00:01:25,700
three years now so the first thing I'm

30
00:01:23,150 --> 00:01:26,990
going to do is talk to you about the

31
00:01:25,700 --> 00:01:29,259
problem that I want to solve in my

32
00:01:26,990 --> 00:01:32,089
research and what motivates the problem

33
00:01:29,259 --> 00:01:34,280
why is it important and then i'll give

34
00:01:32,090 --> 00:01:36,140
you the introduction to the my talk in

35
00:01:34,280 --> 00:01:38,030
background that will make the rest of

36
00:01:36,140 --> 00:01:39,290
the talk more understandable if we have

37
00:01:38,030 --> 00:01:41,960
this back from information already

38
00:01:39,290 --> 00:01:44,329
covered then i'll talk about the design

39
00:01:41,960 --> 00:01:47,089
and implementation of data

40
00:01:44,329 --> 00:01:48,529
confidentiality and integrity which is

41
00:01:47,090 --> 00:01:50,509
the name of the project and then i'll

42
00:01:48,530 --> 00:01:51,799
give some highlights of the evaluation

43
00:01:50,509 --> 00:01:53,450
there's a lot more in the paper

44
00:01:51,799 --> 00:01:55,009
basically for each of these bold points

45
00:01:53,450 --> 00:01:58,070
there's more on the paper if you can

46
00:01:55,009 --> 00:02:01,340
look into if you're interested and then

47
00:01:58,070 --> 00:02:04,429
i'll wrap it up in the conclusion so

48
00:02:01,340 --> 00:02:06,469
first our motivation so we're interested

49
00:02:04,430 --> 00:02:10,520
I'm interested in we taught language

50
00:02:06,469 --> 00:02:13,100
based security which is using looking at

51
00:02:10,520 --> 00:02:14,860
why the C and C++ programming languages

52
00:02:13,100 --> 00:02:18,260
are insecure and why do they lead to

53
00:02:14,860 --> 00:02:19,380
security problems and in particular I'm

54
00:02:18,260 --> 00:02:22,130
just going to call out one

55
00:02:19,380 --> 00:02:24,480
we found vulnerability if you follow the

56
00:02:22,130 --> 00:02:25,980
security blogs right you see that new

57
00:02:24,480 --> 00:02:27,269
vulnerabilities were being fault found

58
00:02:25,980 --> 00:02:29,459
all the time but we'll just talk about

59
00:02:27,270 --> 00:02:31,650
this one a little bit so it's called

60
00:02:29,460 --> 00:02:33,600
heartbleed and the root cause is a

61
00:02:31,650 --> 00:02:35,760
missing bounced check and it's in the

62
00:02:33,600 --> 00:02:39,359
library called openssl which is a crypto

63
00:02:35,760 --> 00:02:41,790
library implemented in C and it allowed

64
00:02:39,360 --> 00:02:43,980
a clever attacker to send a message to

65
00:02:41,790 --> 00:02:45,720
the server and then it would the server

66
00:02:43,980 --> 00:02:47,100
would send back its private encryption

67
00:02:45,720 --> 00:02:50,760
key which could allow the attacker to

68
00:02:47,100 --> 00:02:53,880
impersonate the server and this affects

69
00:02:50,760 --> 00:02:58,890
um any server that uses openssl which

70
00:02:53,880 --> 00:03:01,920
apache engine X the commonly used linux

71
00:02:58,890 --> 00:03:03,239
web servers all use open SSL and it

72
00:03:01,920 --> 00:03:04,890
could have effect potentially up to

73
00:03:03,240 --> 00:03:06,530
sixty six percent of websites on the

74
00:03:04,890 --> 00:03:08,790
internet according to some metrics so

75
00:03:06,530 --> 00:03:13,440
it's a really big vulnerability that has

76
00:03:08,790 --> 00:03:18,000
a high impact in terms of how widely it

77
00:03:13,440 --> 00:03:19,320
could be exploited in the wild so a lot

78
00:03:18,000 --> 00:03:20,970
of security researchers are interested

79
00:03:19,320 --> 00:03:22,260
in saying why didn't we already detect

80
00:03:20,970 --> 00:03:24,150
heart play there's a lot of security

81
00:03:22,260 --> 00:03:27,209
work in static analysis and bug finding

82
00:03:24,150 --> 00:03:30,030
these different approaches but currently

83
00:03:27,210 --> 00:03:32,330
none of those fountain tire played in

84
00:03:30,030 --> 00:03:35,580
particular we're going to I'm going to

85
00:03:32,330 --> 00:03:38,310
talk about cfi which is control flow

86
00:03:35,580 --> 00:03:40,050
integrity and it basically says that I

87
00:03:38,310 --> 00:03:41,820
determine what the control flow of this

88
00:03:40,050 --> 00:03:44,340
program should be statically and then at

89
00:03:41,820 --> 00:03:47,070
runtime IC did my program deviate from

90
00:03:44,340 --> 00:03:49,200
this static control flow graph but the

91
00:03:47,070 --> 00:03:50,760
heartbleed blood bug does not change the

92
00:03:49,200 --> 00:03:53,280
control flow of the program it just

93
00:03:50,760 --> 00:03:55,649
simply leaked a sensitive data so that

94
00:03:53,280 --> 00:03:58,080
motivates our work which is looking at a

95
00:03:55,650 --> 00:04:00,840
text that leak sensitive data or corrupt

96
00:03:58,080 --> 00:04:03,150
data on a remote server for example

97
00:04:00,840 --> 00:04:05,190
similar to the heart please logon the

98
00:04:03,150 --> 00:04:06,990
exploit I described and so we need new

99
00:04:05,190 --> 00:04:08,910
tools to protect sensitive data like

100
00:04:06,990 --> 00:04:11,700
encryption keys or password lists or

101
00:04:08,910 --> 00:04:13,650
authentication tokens and that's what

102
00:04:11,700 --> 00:04:19,200
data shield and data confidentiality and

103
00:04:13,650 --> 00:04:20,880
integrity is targeted at so um the key

104
00:04:19,200 --> 00:04:22,560
inside of my worker the key idea is that

105
00:04:20,880 --> 00:04:24,210
some data are more sensitive than others

106
00:04:22,560 --> 00:04:27,600
and they're worth paying overhead to

107
00:04:24,210 --> 00:04:29,640
protect because the my mechanisms in

108
00:04:27,600 --> 00:04:31,320
language based security usually work by

109
00:04:29,640 --> 00:04:32,240
inserting additional security checks

110
00:04:31,320 --> 00:04:35,960
into the probe

111
00:04:32,240 --> 00:04:37,819
graham to check for for example missing

112
00:04:35,960 --> 00:04:40,159
bounced checks for for ray out of bounds

113
00:04:37,819 --> 00:04:43,430
and each of these new additional checks

114
00:04:40,160 --> 00:04:45,410
costs overhead so we are proposing that

115
00:04:43,430 --> 00:04:48,020
you want to protect key data with these

116
00:04:45,410 --> 00:04:50,120
additional checks examples of approaches

117
00:04:48,020 --> 00:04:52,789
along these lines that that identify a

118
00:04:50,120 --> 00:04:55,069
specific subset of data to protect our

119
00:04:52,789 --> 00:04:57,050
stack Canaries which are special values

120
00:04:55,069 --> 00:04:59,360
that are on the stack that indicate that

121
00:04:57,050 --> 00:05:00,919
if the secondary value changes that

122
00:04:59,360 --> 00:05:02,539
indicates the attacker overwrote the

123
00:05:00,919 --> 00:05:05,870
stack and try to corrupt the return

124
00:05:02,539 --> 00:05:09,050
address or a similar another approaches

125
00:05:05,870 --> 00:05:12,470
depth which says that any code that's in

126
00:05:09,050 --> 00:05:15,319
memory can cannot be writable it could

127
00:05:12,470 --> 00:05:17,599
only be executable so attackers would

128
00:05:15,319 --> 00:05:19,430
target the code to overrate the code in

129
00:05:17,599 --> 00:05:21,469
memory with their own code and hijack

130
00:05:19,430 --> 00:05:23,960
the program and the final example I'll

131
00:05:21,470 --> 00:05:26,270
give you a CPI which is a basically a

132
00:05:23,960 --> 00:05:28,729
specialized cfi CPI stands for code

133
00:05:26,270 --> 00:05:30,500
pointer integrity and it keeps its own

134
00:05:28,729 --> 00:05:32,330
protected copy of all the function

135
00:05:30,500 --> 00:05:34,849
pointers and virtual function pointers

136
00:05:32,330 --> 00:05:36,889
in the program and stops the attacker

137
00:05:34,849 --> 00:05:39,110
from tampering with them so all these

138
00:05:36,889 --> 00:05:43,009
mechanisms identify a subset of

139
00:05:39,110 --> 00:05:45,229
sensitive data and protect it in our key

140
00:05:43,009 --> 00:05:46,969
difference is that we're enabling the

141
00:05:45,229 --> 00:05:48,680
programmer to choose which data is

142
00:05:46,969 --> 00:05:51,110
protected so the policies as I mentioned

143
00:05:48,680 --> 00:05:53,000
before all have the data that is going

144
00:05:51,110 --> 00:05:54,349
to be protected chosen by the designer

145
00:05:53,000 --> 00:05:57,680
of the mechanism and the programmer

146
00:05:54,349 --> 00:05:59,180
khaya cannot change it and the reason

147
00:05:57,680 --> 00:06:01,699
that we do partial protection rather

148
00:05:59,180 --> 00:06:03,319
than protecting the entire program for

149
00:06:01,699 --> 00:06:05,030
example of bonds checking every single

150
00:06:03,319 --> 00:06:07,240
pointer in the program is that Bond's

151
00:06:05,030 --> 00:06:10,039
checking every pointer is very expensive

152
00:06:07,240 --> 00:06:11,780
in at a very very high level the way our

153
00:06:10,039 --> 00:06:13,610
mechanism works as I briefly mentioned

154
00:06:11,780 --> 00:06:15,770
is that we take the program source code

155
00:06:13,610 --> 00:06:17,479
we compile it with our compiler and then

156
00:06:15,770 --> 00:06:18,889
the resulting Viner has additional

157
00:06:17,479 --> 00:06:23,449
security checks that are missing from

158
00:06:18,889 --> 00:06:26,719
the original program so this is going to

159
00:06:23,449 --> 00:06:28,849
further frame the problem and how our

160
00:06:26,719 --> 00:06:31,190
solutions to that problem are going to

161
00:06:28,849 --> 00:06:32,509
be based on these assumptions so we

162
00:06:31,190 --> 00:06:35,750
assume that only low overhead is

163
00:06:32,509 --> 00:06:37,310
acceptable so when we say low overhead

164
00:06:35,750 --> 00:06:39,530
ideally we're getting down to five or

165
00:06:37,310 --> 00:06:41,419
ten percent because so this paper

166
00:06:39,530 --> 00:06:43,580
theorizes that if it's down the over it

167
00:06:41,419 --> 00:06:46,839
is only between five and ten percent the

168
00:06:43,580 --> 00:06:49,188
end user might not even perceive it

169
00:06:46,839 --> 00:06:50,779
we assume that we have the program

170
00:06:49,189 --> 00:06:52,789
source code because as I mentioned were

171
00:06:50,779 --> 00:06:54,979
compiler based mechanism weary compile

172
00:06:52,789 --> 00:06:57,919
the program and we assume that the

173
00:06:54,979 --> 00:07:00,800
original program contains bugs so the

174
00:06:57,919 --> 00:07:02,659
original program should properly process

175
00:07:00,800 --> 00:07:05,119
expected input but the attacker can

176
00:07:02,659 --> 00:07:07,039
potentially create malicious input that

177
00:07:05,119 --> 00:07:12,499
causes the program to leak sensitive

178
00:07:07,039 --> 00:07:15,529
data or to corrupt sensitive data so the

179
00:07:12,499 --> 00:07:18,259
key concept that we're going to talk

180
00:07:15,529 --> 00:07:20,960
about is memory safety so memory safety

181
00:07:18,259 --> 00:07:23,149
means that whenever you read and write

182
00:07:20,960 --> 00:07:26,210
through a pointer and a C or C++ program

183
00:07:23,149 --> 00:07:27,800
you read or write the object to which

184
00:07:26,210 --> 00:07:30,109
the pointer was most recently assigned

185
00:07:27,800 --> 00:07:31,460
and I'm going to go into detail about

186
00:07:30,110 --> 00:07:35,449
the different ways that this could be

187
00:07:31,460 --> 00:07:36,979
violated on the next few slides and I'm

188
00:07:35,449 --> 00:07:39,889
going to note that confidentiality means

189
00:07:36,979 --> 00:07:41,688
memory safety for reading and integrity

190
00:07:39,889 --> 00:07:45,589
means confidential or memory safety for

191
00:07:41,689 --> 00:07:48,110
writing so one way that you can break

192
00:07:45,589 --> 00:07:50,330
memory safety is a spatial memory safety

193
00:07:48,110 --> 00:07:52,729
violation so say we have the code

194
00:07:50,330 --> 00:07:55,698
snippet over on that side of the slide

195
00:07:52,729 --> 00:07:58,818
and then a buffer in memory somewhere so

196
00:07:55,699 --> 00:08:00,529
we loop over the initialize I 20 and we

197
00:07:58,819 --> 00:08:02,360
loop over the cut the elements of the

198
00:08:00,529 --> 00:08:05,300
buffer setting them all to some value

199
00:08:02,360 --> 00:08:06,949
and this is fine as long as the buffer

200
00:08:05,300 --> 00:08:09,349
of I is still within the bounds of the

201
00:08:06,949 --> 00:08:11,870
array but when we go past the end of the

202
00:08:09,349 --> 00:08:13,819
array we write whatever memory happens

203
00:08:11,870 --> 00:08:15,649
to be there and this is an out-of-bounds

204
00:08:13,819 --> 00:08:16,939
right and it's a violation of spatial

205
00:08:15,649 --> 00:08:18,800
memory safety so we would like to

206
00:08:16,939 --> 00:08:21,860
ideally prevent these out of bound

207
00:08:18,800 --> 00:08:23,379
rights from happening another way that

208
00:08:21,860 --> 00:08:26,240
you can violate memory safety is

209
00:08:23,379 --> 00:08:29,680
temporally so in this example we

210
00:08:26,240 --> 00:08:32,329
allocate a rayon the heap using malloc

211
00:08:29,680 --> 00:08:34,430
right to one of its Ella elements and

212
00:08:32,328 --> 00:08:36,948
then free it free the buffer so now it's

213
00:08:34,429 --> 00:08:39,760
gone but we can still use the pointer to

214
00:08:36,948 --> 00:08:42,559
write to the element an element of buff

215
00:08:39,760 --> 00:08:44,930
that is pointing to now d allocated

216
00:08:42,559 --> 00:08:47,300
memory and now this in this way we're

217
00:08:44,930 --> 00:08:48,888
writing to an unintended memory location

218
00:08:47,300 --> 00:08:50,510
that doesn't contain the most recently

219
00:08:48,889 --> 00:08:54,529
assigned object so this is another way

220
00:08:50,510 --> 00:08:56,740
of violating memory safety so as I

221
00:08:54,529 --> 00:08:59,420
briefly talked about in the beginning

222
00:08:56,740 --> 00:09:01,690
why don't we insert checks before

223
00:08:59,420 --> 00:09:03,979
a pointer dereference to see if the

224
00:09:01,690 --> 00:09:05,900
pointed to object is the most recently

225
00:09:03,980 --> 00:09:08,770
assigned object and the reason is that's

226
00:09:05,900 --> 00:09:11,870
over costly in terms of overhead so

227
00:09:08,770 --> 00:09:14,060
state-of-the-art complete memory safety

228
00:09:11,870 --> 00:09:15,680
mechanisms have about a hundred percent

229
00:09:14,060 --> 00:09:18,079
overhead or more depending on the

230
00:09:15,680 --> 00:09:21,050
program itself and how often it I uses

231
00:09:18,080 --> 00:09:23,060
pointers and the over overhead is a

232
00:09:21,050 --> 00:09:27,829
function of how many of these new checks

233
00:09:23,060 --> 00:09:29,030
we insert into the program so the way

234
00:09:27,830 --> 00:09:31,430
we're going to tackle this problem is

235
00:09:29,030 --> 00:09:33,709
we're going to define a new policy that

236
00:09:31,430 --> 00:09:36,260
allows for protecting only a subset of

237
00:09:33,710 --> 00:09:40,550
sensitive data with lower overhead and

238
00:09:36,260 --> 00:09:43,490
we're going to give several ways of

239
00:09:40,550 --> 00:09:45,589
implementing this new policy and finally

240
00:09:43,490 --> 00:09:47,420
we'll evaluate the security of our

241
00:09:45,590 --> 00:09:50,300
implementation by seeing if it can

242
00:09:47,420 --> 00:09:54,560
detect publicly found are publicly

243
00:09:50,300 --> 00:09:57,199
available exploits so now we'll describe

244
00:09:54,560 --> 00:09:59,869
the design of data confidentiality and

245
00:09:57,200 --> 00:10:02,900
integrity the the design is that

246
00:09:59,870 --> 00:10:04,370
sensitive pointers can access only the

247
00:10:02,900 --> 00:10:06,370
intended sensitive objects so we have

248
00:10:04,370 --> 00:10:10,070
memory safety for sensitive pointers

249
00:10:06,370 --> 00:10:11,750
non-sensitive pointers are isolated from

250
00:10:10,070 --> 00:10:14,630
sensitive data but they can point

251
00:10:11,750 --> 00:10:17,960
anywhere except sensitive data and then

252
00:10:14,630 --> 00:10:20,210
explicit data flow between sensitive and

253
00:10:17,960 --> 00:10:22,100
non-sensitive variables is forbidden so

254
00:10:20,210 --> 00:10:25,130
the compiler is going to apply this

255
00:10:22,100 --> 00:10:29,210
policy to the compiled program that it's

256
00:10:25,130 --> 00:10:31,280
given and at a high level the way this

257
00:10:29,210 --> 00:10:33,470
works is that we divide memory into two

258
00:10:31,280 --> 00:10:35,839
regions one contains sensitive data and

259
00:10:33,470 --> 00:10:38,390
one contains not sensitive data and in

260
00:10:35,840 --> 00:10:40,490
the sensitive region it contains all all

261
00:10:38,390 --> 00:10:42,560
the sensitive data as well as metadata

262
00:10:40,490 --> 00:10:44,570
about those objects which has allows us

263
00:10:42,560 --> 00:10:47,810
to insert our bonds checks and track the

264
00:10:44,570 --> 00:10:49,490
size of the objects in the non sensitive

265
00:10:47,810 --> 00:10:51,380
region we simply have all the non

266
00:10:49,490 --> 00:10:56,480
sensitive data separated from all the

267
00:10:51,380 --> 00:10:58,189
sensitive data and the way the the

268
00:10:56,480 --> 00:11:01,210
programmer identifies the sensitive data

269
00:10:58,190 --> 00:11:05,020
is by using annotations and

270
00:11:01,210 --> 00:11:05,020
organizations are tight based

271
00:11:06,110 --> 00:11:12,540
so if you add an annotation is shown at

272
00:11:08,610 --> 00:11:14,850
the bottom this makes the entire object

273
00:11:12,540 --> 00:11:16,500
sender sorry fee if you annotate a

274
00:11:14,850 --> 00:11:20,910
struck that makes all the struct and all

275
00:11:16,500 --> 00:11:22,980
its members sensitive sure so you're

276
00:11:20,910 --> 00:11:25,199
making this perfect segregation between

277
00:11:22,980 --> 00:11:27,450
census you in on sensitive but there can

278
00:11:25,200 --> 00:11:29,040
be situation where indeed at least the

279
00:11:27,450 --> 00:11:31,290
sensitive part want to read something

280
00:11:29,040 --> 00:11:34,620
from the non sensitive case yeah so

281
00:11:31,290 --> 00:11:36,209
currently there's no support for

282
00:11:34,620 --> 00:11:38,460
information any information for between

283
00:11:36,210 --> 00:11:39,990
sensitive and non-sensitive so our

284
00:11:38,460 --> 00:11:41,280
subject is that the code that's doing

285
00:11:39,990 --> 00:11:43,530
the sensitive stuff is going to do with

286
00:11:41,280 --> 00:11:45,900
sold thing deal with it sensitive data

287
00:11:43,530 --> 00:11:49,860
and the non sensitive stuff will be

288
00:11:45,900 --> 00:11:51,510
totally separate in future work we plan

289
00:11:49,860 --> 00:11:53,370
to investigate ways of making this safe

290
00:11:51,510 --> 00:11:55,380
so maybe you could have a sanitizer that

291
00:11:53,370 --> 00:11:58,380
allows you to write from sensitive stuff

292
00:11:55,380 --> 00:11:59,280
down just to nonsense of stuff but that

293
00:11:58,380 --> 00:12:05,400
would be something that we're going to

294
00:11:59,280 --> 00:12:07,020
investigate in the future so along the

295
00:12:05,400 --> 00:12:09,000
same lines if you if you annotate a

296
00:12:07,020 --> 00:12:13,560
struct all of its members are the are

297
00:12:09,000 --> 00:12:18,150
now sensitive so this annotation is

298
00:12:13,560 --> 00:12:20,069
recursive one of the key metrics are the

299
00:12:18,150 --> 00:12:21,480
key benefits of our approach is that you

300
00:12:20,070 --> 00:12:22,620
don't have to make many annotations

301
00:12:21,480 --> 00:12:24,330
because we don't want the programmer to

302
00:12:22,620 --> 00:12:26,160
have to do a lot of work and change a

303
00:12:24,330 --> 00:12:27,810
lot of their code so when you annotate a

304
00:12:26,160 --> 00:12:30,120
struct all the members of the structure

305
00:12:27,810 --> 00:12:31,739
sensitive and then recursively if the

306
00:12:30,120 --> 00:12:34,170
struct itself contains pointers to other

307
00:12:31,740 --> 00:12:37,980
strikes those types become sensitive as

308
00:12:34,170 --> 00:12:39,870
well and pointers to a type and the type

309
00:12:37,980 --> 00:12:41,550
itself have the same sensitivity the

310
00:12:39,870 --> 00:12:43,500
only case where we don't have this

311
00:12:41,550 --> 00:12:47,189
recursive rule is for primitives so

312
00:12:43,500 --> 00:12:51,660
integers char's floats they're not ever

313
00:12:47,190 --> 00:12:52,500
explicitly sensitive types and now I'm

314
00:12:51,660 --> 00:12:55,829
going to talk about the implementation

315
00:12:52,500 --> 00:12:57,930
of our mechanism which is as I mentioned

316
00:12:55,830 --> 00:13:01,470
implemented a compiler that we use the

317
00:12:57,930 --> 00:13:03,930
LLVM compiler infrastructure so the

318
00:13:01,470 --> 00:13:06,080
annotations look exactly like this so

319
00:13:03,930 --> 00:13:08,280
say we have a struct foo and we put the

320
00:13:06,080 --> 00:13:10,230
annotation before some instance of foo

321
00:13:08,280 --> 00:13:12,569
now all foods in the program are going

322
00:13:10,230 --> 00:13:16,130
to be sensitive so let's say we allocate

323
00:13:12,570 --> 00:13:18,750
a struct foo on the heap using malloc

324
00:13:16,130 --> 00:13:19,830
the first thing we do is replace the

325
00:13:18,750 --> 00:13:21,960
normal malik call with

326
00:13:19,830 --> 00:13:23,340
call to our region based alligator which

327
00:13:21,960 --> 00:13:25,620
I showed the diagram before with the

328
00:13:23,340 --> 00:13:27,570
sensitive stuff on top so that our

329
00:13:25,620 --> 00:13:30,780
alligator ensures that this allocation

330
00:13:27,570 --> 00:13:31,980
will be in the correct region the second

331
00:13:30,780 --> 00:13:34,020
thing we do is that we want to be able

332
00:13:31,980 --> 00:13:36,600
to bounce checks all these objects right

333
00:13:34,020 --> 00:13:38,130
so we have to record this first address

334
00:13:36,600 --> 00:13:39,660
of the object and the last address and

335
00:13:38,130 --> 00:13:41,640
we put that in a metadata table which

336
00:13:39,660 --> 00:13:43,829
again talk to the beginning it's above

337
00:13:41,640 --> 00:13:46,199
the sensitive mountains of region

338
00:13:43,830 --> 00:13:50,250
boundary and the memory overview diagram

339
00:13:46,200 --> 00:13:52,140
so we record the base address as the

340
00:13:50,250 --> 00:13:53,880
pointer returned by Malik and the last

341
00:13:52,140 --> 00:13:59,010
address is the pointer times the size of

342
00:13:53,880 --> 00:14:01,170
the struct then let's say now we

343
00:13:59,010 --> 00:14:02,400
dereference the pointer to foo now is

344
00:14:01,170 --> 00:14:04,380
the time that we want to do the balance

345
00:14:02,400 --> 00:14:07,560
checking so in this example we have

346
00:14:04,380 --> 00:14:08,670
pointer arrow X before we can

347
00:14:07,560 --> 00:14:10,709
dereference the pointer to determine if

348
00:14:08,670 --> 00:14:12,990
it's safe we look up the bounds of this

349
00:14:10,710 --> 00:14:15,150
this pointer using the address of the

350
00:14:12,990 --> 00:14:17,160
pointer and then we check that the

351
00:14:15,150 --> 00:14:21,750
pointers between of course the first and

352
00:14:17,160 --> 00:14:23,579
last address of the object now for an

353
00:14:21,750 --> 00:14:26,460
non-sensitive objects so anything that

354
00:14:23,580 --> 00:14:28,770
hasn't been of the annotated type we

355
00:14:26,460 --> 00:14:30,510
again replace the Mallik but this time

356
00:14:28,770 --> 00:14:32,640
we put in the nonsense of Mallik which

357
00:14:30,510 --> 00:14:35,970
ensures that the abbot already allocated

358
00:14:32,640 --> 00:14:37,980
below the boundary and then when we

359
00:14:35,970 --> 00:14:40,350
dereference the pointer that's not

360
00:14:37,980 --> 00:14:41,940
sensitive we have to have to ensure that

361
00:14:40,350 --> 00:14:43,950
doesn't point up into the sensitive

362
00:14:41,940 --> 00:14:46,170
region and one way of implanting that is

363
00:14:43,950 --> 00:14:48,210
using a mask is shown here where we

364
00:14:46,170 --> 00:14:49,560
clear the upper bits so the maximum

365
00:14:48,210 --> 00:14:52,050
value of the pointer is below the

366
00:14:49,560 --> 00:14:53,880
boundary after it's been masks and then

367
00:14:52,050 --> 00:14:57,420
we allow the pointer dereference to

368
00:14:53,880 --> 00:14:59,189
happen so I mentioned that it's

369
00:14:57,420 --> 00:15:01,979
implemented in a compiler the compiler

370
00:14:59,190 --> 00:15:04,200
past has two different parts it is a

371
00:15:01,980 --> 00:15:06,030
module analysis where it finds all the

372
00:15:04,200 --> 00:15:08,910
sensitive types all the annotations that

373
00:15:06,030 --> 00:15:10,260
I mentioned before and then I mentioned

374
00:15:08,910 --> 00:15:12,199
the other pieces of the dataflow piece

375
00:15:10,260 --> 00:15:15,480
so the data it does an inner procedural

376
00:15:12,200 --> 00:15:17,370
conducts context-sensitive analysis to

377
00:15:15,480 --> 00:15:19,740
find all the variables that have data

378
00:15:17,370 --> 00:15:23,940
flow with the variables of the annotated

379
00:15:19,740 --> 00:15:28,130
types and it makes them all sensitive at

380
00:15:23,940 --> 00:15:30,750
runtime there is a library for actually

381
00:15:28,130 --> 00:15:32,840
creating separating the sensitive

382
00:15:30,750 --> 00:15:34,880
announces of variables it has

383
00:15:32,840 --> 00:15:38,600
different allocators for the heat

384
00:15:34,880 --> 00:15:40,640
variables it Maps it separates the stack

385
00:15:38,600 --> 00:15:42,680
variables it creates a stack dedicated

386
00:15:40,640 --> 00:15:44,600
to this non-sensitive region and then

387
00:15:42,680 --> 00:15:48,010
Global's are mapped into their regions

388
00:15:44,600 --> 00:15:50,330
by a linker script that I will map the

389
00:15:48,010 --> 00:15:52,580
nonsense of Global's to the nonsense of

390
00:15:50,330 --> 00:15:58,670
region appropriately and the same thing

391
00:15:52,580 --> 00:16:01,210
for the sensitive Global's so now I'll

392
00:15:58,670 --> 00:16:04,490
talk about the evaluation of our

393
00:16:01,210 --> 00:16:07,850
mechanism so this is going to be the

394
00:16:04,490 --> 00:16:09,500
highlights of the evaluation from the

395
00:16:07,850 --> 00:16:10,700
actual paper so if you're interested

396
00:16:09,500 --> 00:16:21,440
there's a few more case studies in there

397
00:16:10,700 --> 00:16:24,590
that you can check out so a key question

398
00:16:21,440 --> 00:16:27,080
that we want to answer is does our idea

399
00:16:24,590 --> 00:16:29,900
of protecting a subset of the data do we

400
00:16:27,080 --> 00:16:33,260
actually observe lower overhead when we

401
00:16:29,900 --> 00:16:36,170
have this condition so this graph shows

402
00:16:33,260 --> 00:16:39,050
two experiments for two micro benchmarks

403
00:16:36,170 --> 00:16:41,449
that I wrote that we're designed to

404
00:16:39,050 --> 00:16:43,160
allow me to control what percent is not

405
00:16:41,450 --> 00:16:46,610
sensitive and what percent is sensitive

406
00:16:43,160 --> 00:16:48,500
so the first one is insertion sort so it

407
00:16:46,610 --> 00:16:50,870
creates to erase one is an answered

408
00:16:48,500 --> 00:16:53,510
array and one is a sensitive ray and it

409
00:16:50,870 --> 00:16:56,900
puts random data in them and sorts them

410
00:16:53,510 --> 00:16:58,400
using insertion sort and I can the input

411
00:16:56,900 --> 00:16:59,990
to the program is the size of the two

412
00:16:58,400 --> 00:17:02,270
arrays how much sensitive data to I want

413
00:16:59,990 --> 00:17:03,440
the number of elements is the mansa's of

414
00:17:02,270 --> 00:17:06,170
red number of elements of a sensitive

415
00:17:03,440 --> 00:17:09,320
right and going on the bottom axis from

416
00:17:06,170 --> 00:17:11,600
left to right that's having a higher

417
00:17:09,319 --> 00:17:14,179
percentage of sensitive data so as we

418
00:17:11,599 --> 00:17:16,219
would expect or as our hypothesis was

419
00:17:14,180 --> 00:17:18,380
that as we increase the amount of

420
00:17:16,220 --> 00:17:20,329
sensitive data we're putting in more and

421
00:17:18,380 --> 00:17:22,930
more checks or executing more and more

422
00:17:20,329 --> 00:17:26,149
checks and our overhead is increasing so

423
00:17:22,930 --> 00:17:30,200
for point of comparison we have soft

424
00:17:26,150 --> 00:17:33,260
bound and softbound CTS those are two

425
00:17:30,200 --> 00:17:38,380
mechanisms that give complete memory

426
00:17:33,260 --> 00:17:38,379
safety so soft bound is complete

427
00:17:58,800 --> 00:18:11,379
okay that's interesting how we have the

428
00:18:09,130 --> 00:18:14,350
ton of time left yes we have still have

429
00:18:11,380 --> 00:18:24,910
and we have 20 minutes 25 minutes okay

430
00:18:14,350 --> 00:18:27,790
go okay so did you say something okay so

431
00:18:24,910 --> 00:18:29,890
as we can see I was as I was describing

432
00:18:27,790 --> 00:18:33,460
southbound south on sets their total

433
00:18:29,890 --> 00:18:36,010
memory safety so as we move there their

434
00:18:33,460 --> 00:18:37,120
overhead is totally independent of about

435
00:18:36,010 --> 00:18:39,160
a sensitive data because it treats

436
00:18:37,120 --> 00:18:41,110
everything the same in fact softbound

437
00:18:39,160 --> 00:18:42,940
and self on sets don't even read the

438
00:18:41,110 --> 00:18:44,860
annotation so they don't have any idea

439
00:18:42,940 --> 00:18:47,500
how much data is sensitive according to

440
00:18:44,860 --> 00:18:50,110
our annotations so question sure my

441
00:18:47,500 --> 00:18:52,300
question is what do you buy sweet say

442
00:18:50,110 --> 00:18:54,760
insertion sort right sister they seen

443
00:18:52,300 --> 00:18:56,530
such I'm sorting an airy yeah run house

444
00:18:54,760 --> 00:18:59,170
of the elements are insensitive and a

445
00:18:56,530 --> 00:19:00,940
half our non-sensitive but it but then

446
00:18:59,170 --> 00:19:04,150
how can we compare because they there is

447
00:19:00,940 --> 00:19:06,100
a clear separation so it's not always

448
00:19:04,150 --> 00:19:07,450
half it's ten percent or sensitive ten

449
00:19:06,100 --> 00:19:09,429
percent and answered sort of up to

450
00:19:07,450 --> 00:19:10,780
ninety percent but then how are you

451
00:19:09,430 --> 00:19:13,210
going to compare them because you are

452
00:19:10,780 --> 00:19:15,940
not going to take anything from the

453
00:19:13,210 --> 00:19:17,380
sensitive area and make it applicable so

454
00:19:15,940 --> 00:19:19,690
let's say you want to compare one

455
00:19:17,380 --> 00:19:21,940
element insensitive render the Reno

456
00:19:19,690 --> 00:19:23,830
density sorry they're totally separate

457
00:19:21,940 --> 00:19:26,050
so it sorts the sensitive array and then

458
00:19:23,830 --> 00:19:28,510
it sorts the lancet said of array so it

459
00:19:26,050 --> 00:19:30,159
does it starts two totally separate

460
00:19:28,510 --> 00:19:31,870
arrays it's basically like imagine you

461
00:19:30,160 --> 00:19:34,000
have a program that deals with sensitive

462
00:19:31,870 --> 00:19:35,199
data does a bunch of stuff does deal

463
00:19:34,000 --> 00:19:36,880
with Dan sets of data does bunch of

464
00:19:35,200 --> 00:19:38,890
stuff and they're totally separate but

465
00:19:36,880 --> 00:19:40,570
it's still sorting the amount of

466
00:19:38,890 --> 00:19:42,610
elements that it's sorting is the same

467
00:19:40,570 --> 00:19:43,810
it's just how much is sensitive and how

468
00:19:42,610 --> 00:19:45,459
much is dance isn't but they're two

469
00:19:43,810 --> 00:19:47,260
totally different arrays they can't be

470
00:19:45,460 --> 00:19:51,280
you can't have an array that makes us

471
00:19:47,260 --> 00:19:52,510
sensitivity does that X yeah okay

472
00:19:51,280 --> 00:19:54,639
because I was just doing trying to

473
00:19:52,510 --> 00:19:57,010
understand the experiment oh because

474
00:19:54,640 --> 00:19:59,590
specially in your second example maybe

475
00:19:57,010 --> 00:20:02,590
as I increase let's say you have 10,000

476
00:19:59,590 --> 00:20:04,689
elements no in your area maybe the Green

477
00:20:02,590 --> 00:20:06,939
Line is catching up and making it almost

478
00:20:04,690 --> 00:20:10,870
equal to the blue line of singers so

479
00:20:06,940 --> 00:20:12,370
because your data set here it's

480
00:20:10,870 --> 00:20:15,159
I think it's hundreds of thousands

481
00:20:12,370 --> 00:20:17,290
armies alike yes so I need to run it for

482
00:20:15,160 --> 00:20:18,970
a long time in order to make you know

483
00:20:17,290 --> 00:20:22,120
account for measurement noise and get

484
00:20:18,970 --> 00:20:23,980
good results in terms of being run long

485
00:20:22,120 --> 00:20:26,139
enough to measure the time accurately so

486
00:20:23,980 --> 00:20:31,830
it's a really big array it runs for like

487
00:20:26,140 --> 00:20:35,440
i don't know i made it or something so

488
00:20:31,830 --> 00:20:36,879
the other benchmark is find max which is

489
00:20:35,440 --> 00:20:39,340
just a linear scan of the two arrays

490
00:20:36,880 --> 00:20:42,790
yeah and is he pointed out the the

491
00:20:39,340 --> 00:20:45,189
overhead of softbound decreases in this

492
00:20:42,790 --> 00:20:47,850
I i attribute that to measurement noise

493
00:20:45,190 --> 00:20:50,950
or perhaps some optimization that

494
00:20:47,850 --> 00:20:52,870
softbound implemented in there compiler

495
00:20:50,950 --> 00:20:54,460
that's kicking in on this benchmark I

496
00:20:52,870 --> 00:20:56,350
don't know the details of the

497
00:20:54,460 --> 00:20:58,270
implementation of soft bombs so I i can

498
00:20:56,350 --> 00:21:02,980
really always speak to what's what I've

499
00:20:58,270 --> 00:21:06,730
done good so thank you yeah how come the

500
00:21:02,980 --> 00:21:08,290
word hadees below zero so it's there's

501
00:21:06,730 --> 00:21:11,980
there's a couple different sources of

502
00:21:08,290 --> 00:21:13,960
speed up in the program one is that when

503
00:21:11,980 --> 00:21:16,570
we do the sensitive regions were

504
00:21:13,960 --> 00:21:18,910
changing the locality in cash effects so

505
00:21:16,570 --> 00:21:21,189
we actually observed in doing our

506
00:21:18,910 --> 00:21:23,470
benchmarks that we would tend to speed

507
00:21:21,190 --> 00:21:25,770
up programs by do using our partitioning

508
00:21:23,470 --> 00:21:30,250
and changing the way the allocator works

509
00:21:25,770 --> 00:21:33,760
for the other benchmarks we actually use

510
00:21:30,250 --> 00:21:35,679
the region based allocator when we

511
00:21:33,760 --> 00:21:36,610
evaluate the baseline because we it so

512
00:21:35,679 --> 00:21:37,960
we have a run that has no

513
00:21:36,610 --> 00:21:39,520
instrumentation then we have a run with

514
00:21:37,960 --> 00:21:41,470
our expectation and we compare them to

515
00:21:39,520 --> 00:21:43,600
figure out what our overhead is we found

516
00:21:41,470 --> 00:21:44,830
that the regions were giving us a little

517
00:21:43,600 --> 00:21:46,689
bit of unfair advantage because we were

518
00:21:44,830 --> 00:21:49,120
increasing a locality and having a lot

519
00:21:46,690 --> 00:21:51,790
fewer page faults so we ran everything

520
00:21:49,120 --> 00:21:53,139
in the next the remaining slides that

521
00:21:51,790 --> 00:21:54,970
I'll show you with the region based

522
00:21:53,140 --> 00:21:58,240
allocator which separated the two

523
00:21:54,970 --> 00:22:02,790
regions it's a interesting question

524
00:21:58,240 --> 00:22:02,790
though any other questions at this point

525
00:22:03,570 --> 00:22:09,669
yes I think I've talked about that what

526
00:22:06,610 --> 00:22:11,860
ah so then the other question that we'd

527
00:22:09,670 --> 00:22:13,960
be interested in knowing is let's say

528
00:22:11,860 --> 00:22:15,459
that our hypothesis that we have a

529
00:22:13,960 --> 00:22:17,830
really small amount of sensitive data

530
00:22:15,460 --> 00:22:21,010
holds and we're mostly working on that

531
00:22:17,830 --> 00:22:22,659
sort of not sensitive data but we still

532
00:22:21,010 --> 00:22:24,600
have to stop the sensitive pointers from

533
00:22:22,660 --> 00:22:28,210
ever pointing into the sensitive read

534
00:22:24,600 --> 00:22:30,939
so we evaluated the spec benchmarks in

535
00:22:28,210 --> 00:22:32,590
this configuration the spec CPU 2006

536
00:22:30,940 --> 00:22:34,660
benchmarks are pretty much the standard

537
00:22:32,590 --> 00:22:36,790
and my fields for benchmarking

538
00:22:34,660 --> 00:22:39,250
performance however they're not really

539
00:22:36,790 --> 00:22:42,610
security critical programs they're like

540
00:22:39,250 --> 00:22:45,280
one is a chess simulator one is a go

541
00:22:42,610 --> 00:22:47,350
board game simulator one is a you know a

542
00:22:45,280 --> 00:22:49,000
pathfinding algorithm so there isn't

543
00:22:47,350 --> 00:22:51,639
necessarily sensitive data but these are

544
00:22:49,000 --> 00:22:53,200
simply measuring used to figure out what

545
00:22:51,640 --> 00:22:58,660
the overhead is for a variety of

546
00:22:53,200 --> 00:23:01,000
programs so they're the along the bottom

547
00:22:58,660 --> 00:23:02,980
of this axis are the individual package

548
00:23:01,000 --> 00:23:05,380
marks and then the different colored

549
00:23:02,980 --> 00:23:08,080
bars are three different ways of

550
00:23:05,380 --> 00:23:10,090
enforcing the isolation of non sensitive

551
00:23:08,080 --> 00:23:11,980
stuff from sensitive stuff so in my

552
00:23:10,090 --> 00:23:14,860
example in the beginning I showed we

553
00:23:11,980 --> 00:23:16,210
used a mask to clear the upper bits so

554
00:23:14,860 --> 00:23:18,040
that the pointer can't point up into the

555
00:23:16,210 --> 00:23:22,090
sensitive region but there's two other

556
00:23:18,040 --> 00:23:25,210
ways of enforcing that one of the first

557
00:23:22,090 --> 00:23:29,020
of the two is MPX which is a harbor

558
00:23:25,210 --> 00:23:31,630
feature by Intel it actually introduces

559
00:23:29,020 --> 00:23:33,850
for new bounds registers and explicit

560
00:23:31,630 --> 00:23:36,970
bounds check instructions that you can

561
00:23:33,850 --> 00:23:39,280
use to do bounds checking so the way we

562
00:23:36,970 --> 00:23:41,530
use this is we put the bounds of the non

563
00:23:39,280 --> 00:23:43,450
sensitive region in the first bounds

564
00:23:41,530 --> 00:23:45,220
register and then every time before we

565
00:23:43,450 --> 00:23:47,200
dereference a non sensitive pointer we

566
00:23:45,220 --> 00:23:49,450
execute the bar insert the bounced check

567
00:23:47,200 --> 00:23:50,890
instruction so effectively it's a

568
00:23:49,450 --> 00:23:52,780
bounced check implemented at hardware

569
00:23:50,890 --> 00:23:56,200
that we can use for the nonce instead of

570
00:23:52,780 --> 00:24:00,670
region the last one the the yellow one

571
00:23:56,200 --> 00:24:03,670
bar is a feature of the x86 64

572
00:24:00,670 --> 00:24:07,330
instruction set called address override

573
00:24:03,670 --> 00:24:10,090
prefix and what it does is it tells the

574
00:24:07,330 --> 00:24:12,040
processor to interpret the memory

575
00:24:10,090 --> 00:24:14,199
operands of this instruction as 32-bit

576
00:24:12,040 --> 00:24:15,670
values so you put this magic number for

577
00:24:14,200 --> 00:24:18,070
the instruction and then it will assume

578
00:24:15,670 --> 00:24:20,550
that all your pointers are 32 bits so

579
00:24:18,070 --> 00:24:22,899
instructions with this prefix can never

580
00:24:20,550 --> 00:24:24,550
reference the sensitive region that's

581
00:24:22,900 --> 00:24:27,700
the third way we can enforce the

582
00:24:24,550 --> 00:24:29,320
isolation so if you compare the heights

583
00:24:27,700 --> 00:24:31,300
of the heights of the bars maybe for now

584
00:24:29,320 --> 00:24:34,540
focus on the last one which is the mean

585
00:24:31,300 --> 00:24:36,440
because there's a lot of benchmarks we

586
00:24:34,540 --> 00:24:38,930
can see that masking is

587
00:24:36,440 --> 00:24:40,490
the highest overhead because we're

588
00:24:38,930 --> 00:24:43,220
loading this value into where to

589
00:24:40,490 --> 00:24:46,340
register doing the hand and then using

590
00:24:43,220 --> 00:24:48,170
the mouse pointer whereas MPX we have we

591
00:24:46,340 --> 00:24:50,600
can use the bounds registers for free

592
00:24:48,170 --> 00:24:51,770
essentially we might actually have lower

593
00:24:50,600 --> 00:24:53,360
register pressure because we're not

594
00:24:51,770 --> 00:24:56,150
using a register to store the mask

595
00:24:53,360 --> 00:24:58,879
itself and then finally the yellow bar

596
00:24:56,150 --> 00:25:00,800
which is essentially invisible is the

597
00:24:58,880 --> 00:25:02,510
address override prefix and it's all in

598
00:25:00,800 --> 00:25:05,870
hardware so it's very very fast that it

599
00:25:02,510 --> 00:25:08,200
has essentially no overhead any negative

600
00:25:05,870 --> 00:25:12,020
over at is essentially measurement noise

601
00:25:08,200 --> 00:25:13,730
so the question that arises from this

602
00:25:12,020 --> 00:25:16,670
observation is why would we use the

603
00:25:13,730 --> 00:25:19,730
different options so one reason would be

604
00:25:16,670 --> 00:25:22,310
almost every processor has and

605
00:25:19,730 --> 00:25:24,830
instruction but not every processor

606
00:25:22,310 --> 00:25:27,350
sports MPX and edges override prefix and

607
00:25:24,830 --> 00:25:30,020
the other good thing potentially about

608
00:25:27,350 --> 00:25:31,969
MPX is we could have multiple sensitive

609
00:25:30,020 --> 00:25:34,879
regions because the we could change the

610
00:25:31,970 --> 00:25:36,200
values in the bounds registers and have

611
00:25:34,880 --> 00:25:37,430
there are four of them so we could

612
00:25:36,200 --> 00:25:39,440
eventually have four different regions

613
00:25:37,430 --> 00:25:41,210
as well that's not currently implemented

614
00:25:39,440 --> 00:25:44,420
but that's sort of an idea that could be

615
00:25:41,210 --> 00:25:50,180
interesting to pursue in the future any

616
00:25:44,420 --> 00:25:52,430
questions about this now the question we

617
00:25:50,180 --> 00:25:53,990
want to ask answer is how much of we

618
00:25:52,430 --> 00:25:55,360
improved security have we done something

619
00:25:53,990 --> 00:25:58,340
that's actually going to detect

620
00:25:55,360 --> 00:26:04,760
vulnerabilities and attacks in the wild

621
00:25:58,340 --> 00:26:08,209
so we found a crypto library called

622
00:26:04,760 --> 00:26:10,370
embed TLS which is now owned by arm it's

623
00:26:08,210 --> 00:26:14,410
used in embedded devices to do crypto

624
00:26:10,370 --> 00:26:17,659
and there is luckily for us there's a CV

625
00:26:14,410 --> 00:26:21,500
found in mpls which is common

626
00:26:17,660 --> 00:26:22,970
vulnerabilities and exposures so the guy

627
00:26:21,500 --> 00:26:25,580
that found it wrote a nice blog posts

628
00:26:22,970 --> 00:26:27,430
showing how the vulnerability worked and

629
00:26:25,580 --> 00:26:30,230
he also had a proof of concept exploit

630
00:26:27,430 --> 00:26:33,560
so we checked out this version of a med

631
00:26:30,230 --> 00:26:36,200
TLS compiled it with our protection our

632
00:26:33,560 --> 00:26:38,360
compiler and then checked if the exploit

633
00:26:36,200 --> 00:26:41,920
would still work but no we in fact we

634
00:26:38,360 --> 00:26:45,979
found that we detected the out of bounds

635
00:26:41,920 --> 00:26:47,270
read and we were able to abort the

636
00:26:45,980 --> 00:26:49,940
program rather than leaking

637
00:26:47,270 --> 00:26:51,800
the server's contents so we were able to

638
00:26:49,940 --> 00:26:56,000
detect that the attack was taking place

639
00:26:51,800 --> 00:26:57,830
in a in a software that's actually used

640
00:26:56,000 --> 00:27:02,050
by people out in production and there in

641
00:26:57,830 --> 00:27:05,510
the real world any questions about that

642
00:27:02,050 --> 00:27:08,440
so now I'm going to wrap up the talking

643
00:27:05,510 --> 00:27:12,230
and summarize the points the key points

644
00:27:08,440 --> 00:27:14,690
we in DC I we have stronger production /

645
00:27:12,230 --> 00:27:17,090
sensitive data and relax production for

646
00:27:14,690 --> 00:27:18,380
non sensitive data and the reason we

647
00:27:17,090 --> 00:27:20,149
have this relax production is it allows

648
00:27:18,380 --> 00:27:22,340
us to have lower overhead overall and

649
00:27:20,150 --> 00:27:24,890
that's a key metric for getting people

650
00:27:22,340 --> 00:27:26,810
to actually use our mechanism is that

651
00:27:24,890 --> 00:27:29,000
people want fairly low performance are

652
00:27:26,810 --> 00:27:31,429
really high performance in practice and

653
00:27:29,000 --> 00:27:34,370
we have lower overhead than complete

654
00:27:31,430 --> 00:27:36,110
memory safety and we suggest that one of

655
00:27:34,370 --> 00:27:37,550
the reasons that memory safety complete

656
00:27:36,110 --> 00:27:40,760
memory safety is not being adapted is

657
00:27:37,550 --> 00:27:43,220
that is the prohibitive overhead and our

658
00:27:40,760 --> 00:27:46,760
security evaluation with M bed TLS shows

659
00:27:43,220 --> 00:27:48,830
that if our technique is used and we

660
00:27:46,760 --> 00:27:50,720
compile embed TLS with our compiler

661
00:27:48,830 --> 00:27:51,919
we're able to detect a real

662
00:27:50,720 --> 00:27:56,840
vulnerability that was found in the

663
00:27:51,920 --> 00:27:59,990
software and lastly the compiler is now

664
00:27:56,840 --> 00:28:02,600
open source you can go to this URL and

665
00:27:59,990 --> 00:28:05,120
check out the software user yourself

666
00:28:02,600 --> 00:28:06,679
compile your own programs and I would be

667
00:28:05,120 --> 00:28:23,479
glad to answer any questions about it

668
00:28:06,680 --> 00:28:26,000
our questions about the talk to so my

669
00:28:23,480 --> 00:28:29,750
question is that did you already talking

670
00:28:26,000 --> 00:28:33,080
with some people about some companies

671
00:28:29,750 --> 00:28:37,010
who are interested in using this or what

672
00:28:33,080 --> 00:28:39,949
kind of what kind of or if not then what

673
00:28:37,010 --> 00:28:41,390
kind of industry can you focus on for

674
00:28:39,950 --> 00:28:43,580
this kind of yes so the interesting

675
00:28:41,390 --> 00:28:45,380
thing about my research area is that

676
00:28:43,580 --> 00:28:47,449
there is a little bit of a lag between

677
00:28:45,380 --> 00:28:50,210
what is the cutting edge research and

678
00:28:47,450 --> 00:28:53,150
what is being done in industry so I

679
00:28:50,210 --> 00:28:54,590
mentioned the beginning cfi that see if

680
00:28:53,150 --> 00:28:56,390
I doesn't protect hardly but it can

681
00:28:54,590 --> 00:28:58,760
protect against it different rotax

682
00:28:56,390 --> 00:29:00,210
attacks that target control fall and it

683
00:28:58,760 --> 00:29:03,050
is actually being adapted an industry

684
00:29:00,210 --> 00:29:05,460
the combined Chris the new microsoft

685
00:29:03,050 --> 00:29:08,280
latest microsoft compiler has a form of

686
00:29:05,460 --> 00:29:10,530
control flow integrity GCC as a form of

687
00:29:08,280 --> 00:29:14,940
control flow integrity and so does llvm

688
00:29:10,530 --> 00:29:16,530
clang so the interesting approach for me

689
00:29:14,940 --> 00:29:19,260
that i think would be more adaptable to

690
00:29:16,530 --> 00:29:22,290
industry is trying to potentially not

691
00:29:19,260 --> 00:29:23,670
rely on annotations is one drink

692
00:29:22,290 --> 00:29:26,610
important direction for future work

693
00:29:23,670 --> 00:29:28,530
because it we assume that the primer

694
00:29:26,610 --> 00:29:30,179
knows what's important but in practice

695
00:29:28,530 --> 00:29:31,410
an industry you would like to have a

696
00:29:30,180 --> 00:29:33,090
tool that works automatically and

697
00:29:31,410 --> 00:29:34,800
doesn't require you to go back and say

698
00:29:33,090 --> 00:29:35,970
what are the really important things

699
00:29:34,800 --> 00:29:42,930
here you would just like to have it all

700
00:29:35,970 --> 00:29:46,710
work out of the box interesting so any

701
00:29:42,930 --> 00:29:48,900
other patient okay so then maybe just

702
00:29:46,710 --> 00:29:50,580
one final thing are you immediately

703
00:29:48,900 --> 00:29:52,860
jumpered both confidentiality integrity

704
00:29:50,580 --> 00:29:54,990
but let's see if I want integrity only

705
00:29:52,860 --> 00:29:57,449
yes is dead already something easily

706
00:29:54,990 --> 00:29:58,950
solid a value yes so the interesting

707
00:29:57,450 --> 00:30:03,450
thing about confidentiality and

708
00:29:58,950 --> 00:30:05,550
integrity is the rights are more rare in

709
00:30:03,450 --> 00:30:07,260
programs than brees so usually you read

710
00:30:05,550 --> 00:30:08,730
a bunch of things you complete some

711
00:30:07,260 --> 00:30:11,010
results when you write it back to memory

712
00:30:08,730 --> 00:30:13,290
so there's actually a mode in the

713
00:30:11,010 --> 00:30:15,330
compiler that only protects rights

714
00:30:13,290 --> 00:30:18,270
that's confidentiality our integrity

715
00:30:15,330 --> 00:30:20,429
only and it has much lower overhead

716
00:30:18,270 --> 00:30:21,600
because the rights are rare we have few

717
00:30:20,430 --> 00:30:25,710
we have to check fewer things than we

718
00:30:21,600 --> 00:30:28,050
only check rights if you want integrity

719
00:30:25,710 --> 00:30:29,790
of data then no pretty much my approach

720
00:30:28,050 --> 00:30:33,060
is the is the only way if you want

721
00:30:29,790 --> 00:30:34,680
partial into prediction softbound does

722
00:30:33,060 --> 00:30:37,590
have a mode that's right only that they

723
00:30:34,680 --> 00:30:40,820
call out and they pay for two but i

724
00:30:37,590 --> 00:30:43,949
think that integrity is actually a more

725
00:30:40,820 --> 00:30:46,620
maybe widely applicable approach to

726
00:30:43,950 --> 00:30:49,170
industry and end users because it will

727
00:30:46,620 --> 00:30:51,389
be low overhead as i mentioned it a lot

728
00:30:49,170 --> 00:30:54,210
of mechanisms focus on stopping the

729
00:30:51,390 --> 00:30:55,560
attacker from corrupting the data rather

730
00:30:54,210 --> 00:31:00,600
than stopping the attacker from reading

731
00:30:55,560 --> 00:31:02,159
the data partly because it's lower

732
00:31:00,600 --> 00:31:03,719
overhead to protect integrity but

733
00:31:02,160 --> 00:31:05,100
confidentiality on its own obviously

734
00:31:03,720 --> 00:31:07,770
doesn't make sense because he can just

735
00:31:05,100 --> 00:31:09,419
overwrite the tiger can just overwrite

736
00:31:07,770 --> 00:31:11,790
your protection mechanism we like turn

737
00:31:09,420 --> 00:31:15,350
it off so you need integrity so

738
00:31:11,790 --> 00:31:15,350
mechanisms do focus on integrity

739
00:31:36,940 --> 00:31:39,000
you

