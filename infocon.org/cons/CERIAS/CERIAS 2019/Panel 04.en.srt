1
00:00:05,270 --> 00:00:16,139
okay well thank you all for coming back

2
00:00:13,139 --> 00:00:18,270
and staying for the best part of the

3
00:00:16,139 --> 00:00:20,310
symposium as you know to keep people

4
00:00:18,270 --> 00:00:22,410
around we always pack the best to last

5
00:00:20,310 --> 00:00:24,390
unless you were to speaker earlier in

6
00:00:22,410 --> 00:00:25,859
the day and we have to make sure we keep

7
00:00:24,390 --> 00:00:28,560
everyone here throughout the entire

8
00:00:25,859 --> 00:00:31,320
thing but no I think this is a really

9
00:00:28,560 --> 00:00:33,120
interesting and exciting topic that

10
00:00:31,320 --> 00:00:37,170
we're going to be talking about today

11
00:00:33,120 --> 00:00:39,870
again dealing with one of Purdue giant

12
00:00:37,170 --> 00:00:41,790
leaps of securing the giant Leafs and

13
00:00:39,870 --> 00:00:45,328
health longevity and quality of life

14
00:00:41,790 --> 00:00:48,360
we've got for hopefully interest for

15
00:00:45,329 --> 00:00:51,300
hopefully differing perspectives to

16
00:00:48,360 --> 00:00:53,460
point out issues and we I've asked the

17
00:00:51,300 --> 00:00:55,620
panelists to give some brief statements

18
00:00:53,460 --> 00:00:57,660
for five to ten minutes so there's

19
00:00:55,620 --> 00:01:00,419
plenty of time for lively discussion

20
00:00:57,660 --> 00:01:02,339
because I know myself I prefer either

21
00:01:00,420 --> 00:01:04,799
when I'm on a panel or listening to want

22
00:01:02,340 --> 00:01:07,229
the discussions always generate the most

23
00:01:04,799 --> 00:01:11,220
interesting things and people prepared

24
00:01:07,229 --> 00:01:12,689
slides but everyone seems to have a good

25
00:01:11,220 --> 00:01:15,229
perspective on what we're going to talk

26
00:01:12,689 --> 00:01:18,630
about and so we'll just start by having

27
00:01:15,229 --> 00:01:21,390
Jim Ralph like so yeah yeah I was gonna

28
00:01:18,630 --> 00:01:23,580
say I want to make sure I was getting it

29
00:01:21,390 --> 00:01:26,220
in the right order Jim rouse talk who's

30
00:01:23,580 --> 00:01:28,560
the chief security officer for CVS

31
00:01:26,220 --> 00:01:32,250
health thank you very much

32
00:01:28,560 --> 00:01:34,110
so I share our actually just stepped

33
00:01:32,250 --> 00:01:37,920
down from the chair of the health

34
00:01:34,110 --> 00:01:41,250
information sharing analysis center to I

35
00:01:37,920 --> 00:01:42,990
sac and as such I've had a broad

36
00:01:41,250 --> 00:01:45,299
perspective on health care now I'm a

37
00:01:42,990 --> 00:01:47,630
reformed banker I have to admit that so

38
00:01:45,299 --> 00:01:50,220
joined healthcare about six years ago

39
00:01:47,630 --> 00:01:52,520
and I'm still kind of learning the

40
00:01:50,220 --> 00:01:55,770
nuances I guess of applying

41
00:01:52,520 --> 00:01:59,039
cybersecurity practices to healthcare

42
00:01:55,770 --> 00:02:02,780
the biggest challenge that healthcare as

43
00:01:59,040 --> 00:02:07,140
an industry face is that HIPAA has a

44
00:02:02,780 --> 00:02:08,459
dominant presence throughout all of

45
00:02:07,140 --> 00:02:09,360
healthcare and that's generally a good

46
00:02:08,459 --> 00:02:11,910
thing

47
00:02:09,360 --> 00:02:12,849
Hiep is pretty light from a security

48
00:02:11,910 --> 00:02:16,420
standpoint

49
00:02:12,849 --> 00:02:19,298
it's primarily about privacy so when I

50
00:02:16,420 --> 00:02:21,730
compare it to financial services which

51
00:02:19,299 --> 00:02:24,249
is a little heavier on the cyber side

52
00:02:21,730 --> 00:02:27,578
the biggest challenge that we as an

53
00:02:24,249 --> 00:02:30,969
industry face in healthcare specifically

54
00:02:27,579 --> 00:02:34,480
healthcare providers is that security is

55
00:02:30,969 --> 00:02:38,319
thought of as a compliance thing meaning

56
00:02:34,480 --> 00:02:42,099
that if you comply with the regulatory

57
00:02:38,319 --> 00:02:44,439
requirements all is good and that there

58
00:02:42,099 --> 00:02:47,939
was a time where that was absolutely

59
00:02:44,439 --> 00:02:50,319
true that time was several decades ago

60
00:02:47,939 --> 00:02:53,739
it's not true at all today

61
00:02:50,319 --> 00:02:57,969
and so being compliant with regulatory

62
00:02:53,739 --> 00:03:02,430
requirement is a critical path but it's

63
00:02:57,969 --> 00:03:05,948
not the end game and it's not sufficient

64
00:03:02,430 --> 00:03:07,599
and what that means is if you think of

65
00:03:05,949 --> 00:03:10,870
the alternative what's the alternative

66
00:03:07,599 --> 00:03:13,209
to a compliance based security program

67
00:03:10,870 --> 00:03:15,040
it's a risk driven security program well

68
00:03:13,209 --> 00:03:17,979
what is that well that's studying and

69
00:03:15,040 --> 00:03:19,810
understanding intelligence about threat

70
00:03:17,979 --> 00:03:22,389
actor tactics and then changing and

71
00:03:19,810 --> 00:03:25,060
adjusting your controls based on that so

72
00:03:22,389 --> 00:03:27,479
I work for a large enterprise today we

73
00:03:25,060 --> 00:03:31,290
change our controls in terms of our

74
00:03:27,479 --> 00:03:35,079
control procedures 1.5 times a day

75
00:03:31,290 --> 00:03:37,239
that's an indication of resiliency for

76
00:03:35,079 --> 00:03:40,419
an enterprise today there was a time

77
00:03:37,239 --> 00:03:43,449
where never changing your controls was

78
00:03:40,419 --> 00:03:46,419
thought of as resilient so I'll tell a

79
00:03:43,449 --> 00:03:47,560
story my first day in cyber security you

80
00:03:46,419 --> 00:03:50,259
know it was a long time ago

81
00:03:47,560 --> 00:03:52,359
please don't rub it in my first day in

82
00:03:50,259 --> 00:03:54,089
cyber security I actually was a C so now

83
00:03:52,359 --> 00:03:56,949
I was an IT professional for a long time

84
00:03:54,090 --> 00:03:58,629
but that was back when that I worked for

85
00:03:56,949 --> 00:04:01,919
American Express they didn't have a C so

86
00:03:58,629 --> 00:04:05,560
so they said oh we need a C so you know

87
00:04:01,919 --> 00:04:07,060
you do it you know and so my first day

88
00:04:05,560 --> 00:04:09,819
on the job I'm looking at my calendar on

89
00:04:07,060 --> 00:04:12,759
the second day there's this meeting with

90
00:04:09,819 --> 00:04:15,129
the OCC now I knew enough to know that

91
00:04:12,759 --> 00:04:16,630
OCC is officer of the control office of

92
00:04:15,129 --> 00:04:19,149
the controller of the currency right

93
00:04:16,630 --> 00:04:21,279
these are this is a heavy-duty regulator

94
00:04:19,149 --> 00:04:23,349
right the title of the meeting was a

95
00:04:21,279 --> 00:04:26,139
presentation of the information security

96
00:04:23,349 --> 00:04:27,998
strategy for American Express

97
00:04:26,139 --> 00:04:30,340
it's when it dawned on me that's why I

98
00:04:27,999 --> 00:04:32,710
was selected as the see so for that

99
00:04:30,340 --> 00:04:34,960
point of time because my boss the CIO

100
00:04:32,710 --> 00:04:37,830
didn't want to give that presentation so

101
00:04:34,960 --> 00:04:40,029
I had 24 hours to prepare a presentation

102
00:04:37,830 --> 00:04:40,930
without being cybersecurity

103
00:04:40,029 --> 00:04:43,900
professionals

104
00:04:40,930 --> 00:04:46,990
now fortunately I had bumped into a guy

105
00:04:43,900 --> 00:04:49,688
who's a heavy cybersecurity guy wrote a

106
00:04:46,990 --> 00:04:51,849
bunch of books named Mark Mirko I and he

107
00:04:49,689 --> 00:04:55,150
gave me a piece of paper he said when

108
00:04:51,849 --> 00:04:57,759
you get well over your head call this

109
00:04:55,150 --> 00:04:59,049
number now I was pretty cocky I looked

110
00:04:57,759 --> 00:05:00,669
there that's like I I'm not gonna need

111
00:04:59,050 --> 00:05:03,430
that I just stuck it in my pocket never

112
00:05:00,669 --> 00:05:06,789
thought another thing about it until I

113
00:05:03,430 --> 00:05:08,889
saw that calendar entry for the OCC I

114
00:05:06,789 --> 00:05:11,169
realized I was well over my head so I

115
00:05:08,889 --> 00:05:14,319
immediately pulled out the number and

116
00:05:11,169 --> 00:05:19,359
called Steve Katz Steve Katz with the

117
00:05:14,319 --> 00:05:22,180
first C so ever in in ever like ever for

118
00:05:19,360 --> 00:05:24,099
a Citibank and he was consulting at the

119
00:05:22,180 --> 00:05:25,930
time and this 20 years ago and I called

120
00:05:24,099 --> 00:05:28,449
him up I said Steve I got this meeting I

121
00:05:25,930 --> 00:05:30,669
got a present to the OCC I'm you know

122
00:05:28,449 --> 00:05:31,860
the new CEO for American Express he said

123
00:05:30,669 --> 00:05:33,909
don't worry I'll be right over

124
00:05:31,860 --> 00:05:36,849
so I said well let me give you the

125
00:05:33,909 --> 00:05:38,259
directions click well sure enough 45

126
00:05:36,849 --> 00:05:40,990
minutes he comes over he comes over with

127
00:05:38,259 --> 00:05:43,089
two other people he introduces me to him

128
00:05:40,990 --> 00:05:44,770
there are two other C cells from other

129
00:05:43,089 --> 00:05:47,050
financial service firms that compete

130
00:05:44,770 --> 00:05:48,878
with American Express they dropped

131
00:05:47,050 --> 00:05:50,830
everything that they had to do that

132
00:05:48,879 --> 00:05:53,860
afternoon and they were gonna help Steve

133
00:05:50,830 --> 00:05:55,210
help me prepare for this presentation so

134
00:05:53,860 --> 00:05:57,279
they walk in my office one of them goes

135
00:05:55,210 --> 00:05:58,719
right to my workstation didn't have

136
00:05:57,279 --> 00:06:00,330
laptops back then so it goes my

137
00:05:58,719 --> 00:06:03,099
workstation says what's your password

138
00:06:00,330 --> 00:06:05,080
I'm thinking this is an initiation right

139
00:06:03,099 --> 00:06:07,539
they're testing movie that security guy

140
00:06:05,080 --> 00:06:09,008
right they said no you idiot I'm doing

141
00:06:07,539 --> 00:06:10,599
your presentation for you I got to get

142
00:06:09,009 --> 00:06:13,360
into PowerPoint so I can put it together

143
00:06:10,599 --> 00:06:15,310
right so literally they spend an hour

144
00:06:13,360 --> 00:06:18,189
and a half going through all the papers

145
00:06:15,310 --> 00:06:19,750
on my desk in my office you know I had

146
00:06:18,189 --> 00:06:21,939
four different security functions I was

147
00:06:19,750 --> 00:06:25,539
all bringing together into one and they

148
00:06:21,939 --> 00:06:27,669
prepared the entire presentation I did

149
00:06:25,539 --> 00:06:29,550
nothing when when I'd start to offer

150
00:06:27,669 --> 00:06:32,080
well I think that they said shut up

151
00:06:29,550 --> 00:06:34,779
they read the whole thing and then they

152
00:06:32,080 --> 00:06:37,508
said okay now you give the presentation

153
00:06:34,779 --> 00:06:39,100
to us we will roleplay that we're the

154
00:06:37,509 --> 00:06:41,710
OCC will pretend with the OSI

155
00:06:39,100 --> 00:06:42,880
and you give the presentation to us so I

156
00:06:41,710 --> 00:06:45,340
went through and I gave the presentation

157
00:06:42,880 --> 00:06:47,950
and they'd sit there and say no you

158
00:06:45,340 --> 00:06:51,659
idiot you can't say that you have to say

159
00:06:47,950 --> 00:06:53,950
this and they're very very prescriptive

160
00:06:51,660 --> 00:06:55,390
so this went on for like two or three

161
00:06:53,950 --> 00:06:58,330
hours and finally they said okay you're

162
00:06:55,390 --> 00:06:59,890
ready boy and I was like battered by

163
00:06:58,330 --> 00:07:01,180
that time I'm like I really don't feel

164
00:06:59,890 --> 00:07:03,159
all that confident there's no know

165
00:07:01,180 --> 00:07:05,020
you're ready just stick to the script

166
00:07:03,160 --> 00:07:07,600
the next day I came in I gave the

167
00:07:05,020 --> 00:07:10,120
presentation the occ the end of the

168
00:07:07,600 --> 00:07:12,760
presentation the occ said I think you

169
00:07:10,120 --> 00:07:14,470
have a good strategy looks solid we're

170
00:07:12,760 --> 00:07:17,440
all set we won't see it for another year

171
00:07:14,470 --> 00:07:18,580
now just to translate that's as good at

172
00:07:17,440 --> 00:07:20,440
it as it ever gets

173
00:07:18,580 --> 00:07:23,680
like that that is like a high bar if you

174
00:07:20,440 --> 00:07:26,200
meet that right and the reason that I

175
00:07:23,680 --> 00:07:28,600
survived that was because they use the

176
00:07:26,200 --> 00:07:32,229
formula and they used a formula that

177
00:07:28,600 --> 00:07:35,290
back then was the formula you choose a

178
00:07:32,230 --> 00:07:36,910
risk framework you identify control

179
00:07:35,290 --> 00:07:38,950
objectives in that risk framework

180
00:07:36,910 --> 00:07:41,350
you are lying your business and IT

181
00:07:38,950 --> 00:07:43,719
management practices with the control

182
00:07:41,350 --> 00:07:46,390
objectives that are clearly in the risk

183
00:07:43,720 --> 00:07:48,910
framework you get a third party to do an

184
00:07:46,390 --> 00:07:51,099
attestation of the efficacy of your

185
00:07:48,910 --> 00:07:52,140
controls against that risk framework and

186
00:07:51,100 --> 00:07:56,020
you declare victory

187
00:07:52,140 --> 00:07:59,260
that's what cybersecurity was 20 years

188
00:07:56,020 --> 00:08:04,289
ago and it was it worked like it was

189
00:07:59,260 --> 00:08:06,219
okay today the boundary with

190
00:08:04,290 --> 00:08:09,660
conventional controls and a risk

191
00:08:06,220 --> 00:08:12,880
framework and what you actually need for

192
00:08:09,660 --> 00:08:16,900
resiliency is getting farther and

193
00:08:12,880 --> 00:08:19,630
farther apart and it's why compliance to

194
00:08:16,900 --> 00:08:23,169
so-called industry standards is totally

195
00:08:19,630 --> 00:08:27,370
insufficient if you want to avoid major

196
00:08:23,170 --> 00:08:28,930
business impact of security incidents so

197
00:08:27,370 --> 00:08:31,900
my challenge in healthcare as our

198
00:08:28,930 --> 00:08:35,590
challenges in healthcare it's to move

199
00:08:31,900 --> 00:08:39,179
from compliance driven security to risk

200
00:08:35,590 --> 00:08:39,180
driven security

201
00:08:39,630 --> 00:08:45,160
thank you very much and so now we'll

202
00:08:43,450 --> 00:08:48,220
turn it over to Chris Reid who's a

203
00:08:45,160 --> 00:08:51,400
director of product cybersecurity at Eli

204
00:08:48,220 --> 00:08:58,090
Lilly yeah so I can't agree with Jim

205
00:08:51,400 --> 00:08:59,650
more and and I think so just to give you

206
00:08:58,090 --> 00:09:02,350
know I think what I'd like to bring to

207
00:08:59,650 --> 00:09:04,329
this it's a little different is just the

208
00:09:02,350 --> 00:09:07,930
kind of highlight how fast healthcare

209
00:09:04,330 --> 00:09:10,060
starting to change it's an industry that

210
00:09:07,930 --> 00:09:12,370
I think's been hasn't really been

211
00:09:10,060 --> 00:09:14,890
affected as much as many other

212
00:09:12,370 --> 00:09:16,960
industries by the digital innovations

213
00:09:14,890 --> 00:09:18,250
that have happened out there but all

214
00:09:16,960 --> 00:09:20,950
that's coming and I think if you need

215
00:09:18,250 --> 00:09:22,360
any further evidence it's that I sit you

216
00:09:20,950 --> 00:09:25,360
know I work for Eli Lilly a drug company

217
00:09:22,360 --> 00:09:26,680
and I'm sitting here building a product

218
00:09:25,360 --> 00:09:28,450
cybersecurity team because we're gonna

219
00:09:26,680 --> 00:09:30,939
have a lot of digital products that sit

220
00:09:28,450 --> 00:09:34,840
in patients hands and on their bodies

221
00:09:30,940 --> 00:09:37,450
very soon and it's to me it's a really

222
00:09:34,840 --> 00:09:39,610
exciting time the way I try to relate

223
00:09:37,450 --> 00:09:41,440
this is you know I think about the

224
00:09:39,610 --> 00:09:43,270
healthcare I've been through and a lot

225
00:09:41,440 --> 00:09:44,890
of times it's you know when you're

226
00:09:43,270 --> 00:09:47,500
healthy you might go in the doctor and

227
00:09:44,890 --> 00:09:50,770
get a test every few months or once a

228
00:09:47,500 --> 00:09:53,140
year so the medical record is literally

229
00:09:50,770 --> 00:09:54,699
this little spot checks of how you're

230
00:09:53,140 --> 00:09:58,449
doing but there's a lot of things that

231
00:09:54,700 --> 00:10:00,310
happen between in those gaps and with

232
00:09:58,450 --> 00:10:03,790
all the all the technology all the

233
00:10:00,310 --> 00:10:05,650
wearables and sensors and honestly the

234
00:10:03,790 --> 00:10:06,880
cost of coming to a facility to even

235
00:10:05,650 --> 00:10:08,680
manage that

236
00:10:06,880 --> 00:10:10,439
you're gonna start seeing a lot of that

237
00:10:08,680 --> 00:10:12,790
pushed out to the patient to the edge

238
00:10:10,440 --> 00:10:16,000
and the cool part about that is we'll

239
00:10:12,790 --> 00:10:17,760
have a lot more data points but the bad

240
00:10:16,000 --> 00:10:20,620
part about that is a holler duration

241
00:10:17,760 --> 00:10:22,330
which so for all that the risk

242
00:10:20,620 --> 00:10:24,190
management perspective you know it does

243
00:10:22,330 --> 00:10:25,570
get really difficult and simple

244
00:10:24,190 --> 00:10:28,390
compliance is not going to keep all that

245
00:10:25,570 --> 00:10:29,710
data safe and and make it have a lot of

246
00:10:28,390 --> 00:10:33,870
integrity that's going to be used to

247
00:10:29,710 --> 00:10:35,890
treat people and make serious decisions

248
00:10:33,870 --> 00:10:38,140
you know one of the things I think is

249
00:10:35,890 --> 00:10:40,060
interesting as well as you know as a

250
00:10:38,140 --> 00:10:43,540
pharmaceutical company we're starting to

251
00:10:40,060 --> 00:10:45,219
use what we call digital biomarkers to

252
00:10:43,540 --> 00:10:47,740
look at whether or not our medicines

253
00:10:45,220 --> 00:10:50,830
work so this is if you think about even

254
00:10:47,740 --> 00:10:52,960
example of a Parkinson's patient with

255
00:10:50,830 --> 00:10:55,930
some type of gyroscope device

256
00:10:52,960 --> 00:10:58,060
on them you could actually see it is the

257
00:10:55,930 --> 00:11:00,069
medicine that they're taking effectively

258
00:10:58,060 --> 00:11:03,160
reducing the amount of tremor that they

259
00:11:00,070 --> 00:11:06,490
have over time and so you're gonna see

260
00:11:03,160 --> 00:11:07,810
actual digital data not just biologic

261
00:11:06,490 --> 00:11:08,980
data I mean it's it's it's

262
00:11:07,810 --> 00:11:10,750
representative of something that's

263
00:11:08,980 --> 00:11:12,520
happening but a lot of that's going to

264
00:11:10,750 --> 00:11:15,279
be used in the space in the future and

265
00:11:12,520 --> 00:11:18,550
of course all the AI applied to all this

266
00:11:15,279 --> 00:11:20,649
and the big data work in the back you

267
00:11:18,550 --> 00:11:22,839
know Lily specifically and I can share

268
00:11:20,649 --> 00:11:24,940
this you know we're working on the

269
00:11:22,839 --> 00:11:28,540
concept of artificial pancreas this

270
00:11:24,940 --> 00:11:32,110
insulin de pump that will by itself

271
00:11:28,540 --> 00:11:34,630
watch your glucose and give you lot

272
00:11:32,110 --> 00:11:36,310
smaller doses of insulin when you need

273
00:11:34,630 --> 00:11:39,370
it and act more like your actual

274
00:11:36,310 --> 00:11:41,079
pancreas would operate so you're gonna

275
00:11:39,370 --> 00:11:43,810
start seeing technology really get into

276
00:11:41,080 --> 00:11:47,560
a lot of sensors and data analytics to

277
00:11:43,810 --> 00:11:49,719
help patients you know live healthier

278
00:11:47,560 --> 00:11:51,130
lives and hopefully increase the value

279
00:11:49,720 --> 00:11:54,160
that we're getting out of our healthcare

280
00:11:51,130 --> 00:11:58,089
I guess to make a point about the

281
00:11:54,160 --> 00:12:00,250
regulatory and the risk management you

282
00:11:58,089 --> 00:12:01,990
know the FDA is actually in my opinion

283
00:12:00,250 --> 00:12:04,990
they're doing a pretty good job in this

284
00:12:01,990 --> 00:12:06,760
space in the medical device world they

285
00:12:04,990 --> 00:12:08,050
haven't come across with a list of

286
00:12:06,760 --> 00:12:10,270
here's everything you need to implement

287
00:12:08,050 --> 00:12:13,390
to be compliant and get your product

288
00:12:10,270 --> 00:12:15,550
approve but one of the things that we

289
00:12:13,390 --> 00:12:16,810
struggle with is how to integrate you

290
00:12:15,550 --> 00:12:18,130
know medical device companies typically

291
00:12:16,810 --> 00:12:21,069
are pretty good about safety risk

292
00:12:18,130 --> 00:12:22,990
management they're not good about risk

293
00:12:21,070 --> 00:12:25,839
management on cybersecurity and so we're

294
00:12:22,990 --> 00:12:27,760
working hard on how do these two systems

295
00:12:25,839 --> 00:12:30,610
live next to each other and have an

296
00:12:27,760 --> 00:12:32,140
interplay but you can't just throw

297
00:12:30,610 --> 00:12:33,970
cybersecurity into your normal risk

298
00:12:32,140 --> 00:12:36,339
management process because safety will

299
00:12:33,970 --> 00:12:37,660
always win and security is a lot more

300
00:12:36,339 --> 00:12:41,110
than just safety we need to make sure

301
00:12:37,660 --> 00:12:41,980
the data has integrity and obviously you

302
00:12:41,110 --> 00:12:43,810
want to keep your personal information

303
00:12:41,980 --> 00:12:48,520
safe because there's a lot of personal

304
00:12:43,810 --> 00:12:50,260
data flowing through the system you know

305
00:12:48,520 --> 00:12:51,430
I think as I think further in the future

306
00:12:50,260 --> 00:12:54,640
too we're gonna have a lot of

307
00:12:51,430 --> 00:12:56,410
interesting privacy issues around who

308
00:12:54,640 --> 00:12:57,850
pays for things so if you think about

309
00:12:56,410 --> 00:13:00,010
the commercial models of how all these

310
00:12:57,850 --> 00:13:01,630
services we use how they work today a

311
00:13:00,010 --> 00:13:03,040
lot of its advertising and driven and

312
00:13:01,630 --> 00:13:05,230
you get to use your Gmail account for

313
00:13:03,040 --> 00:13:06,730
free it's going to be interesting to see

314
00:13:05,230 --> 00:13:08,980
what privacy we have to

315
00:13:06,730 --> 00:13:11,620
up in order to fund the development of

316
00:13:08,980 --> 00:13:13,449
all these tools going forward

317
00:13:11,620 --> 00:13:16,440
and then I think lastly and it'll

318
00:13:13,449 --> 00:13:19,779
probably help especially to Georgetown

319
00:13:16,440 --> 00:13:21,430
at the end here talking later one of the

320
00:13:19,779 --> 00:13:24,430
biggest concerns I have is we have a big

321
00:13:21,430 --> 00:13:27,010
legacy device problem and I'm worried

322
00:13:24,430 --> 00:13:29,649
about that problem impacting the trust

323
00:13:27,010 --> 00:13:31,870
and all these future technologies and we

324
00:13:29,649 --> 00:13:34,209
have a really almost an intractable

325
00:13:31,870 --> 00:13:36,730
problem in the legacy space there's just

326
00:13:34,209 --> 00:13:39,670
a lot of old devices in a lot of

327
00:13:36,730 --> 00:13:41,110
organizations that are understaffed and

328
00:13:39,670 --> 00:13:43,269
under trained and we're trying to do the

329
00:13:41,110 --> 00:13:44,800
best through things like H I SEC to tool

330
00:13:43,269 --> 00:13:47,769
everyone up and help them get the

331
00:13:44,800 --> 00:13:49,599
funding they need but you know you can

332
00:13:47,769 --> 00:13:51,160
walk into any healthcare environment and

333
00:13:49,600 --> 00:13:53,079
just see devices all over the place and

334
00:13:51,160 --> 00:13:54,880
if you know anything about those devices

335
00:13:53,079 --> 00:13:57,489
you start thinking like oh when's the

336
00:13:54,880 --> 00:13:59,199
last time that they got patched and what

337
00:13:57,490 --> 00:14:00,430
networks is it connected to and you

338
00:13:59,199 --> 00:14:03,339
probably don't ask too many of those

339
00:14:00,430 --> 00:14:05,339
questions right now so but yeah it's

340
00:14:03,339 --> 00:14:09,420
it's a it's an exciting space right now

341
00:14:05,339 --> 00:14:12,730
but it is it is very fun and complicated

342
00:14:09,420 --> 00:14:15,069
okay well and when you're talking about

343
00:14:12,730 --> 00:14:18,339
all those digital sensors it's a great

344
00:14:15,069 --> 00:14:19,899
transition to VJ raghunathan who's a

345
00:14:18,339 --> 00:14:22,149
professor of Electrical and Computer

346
00:14:19,899 --> 00:14:28,230
Engineering here at Purdue and works on

347
00:14:22,149 --> 00:14:28,230
embedded systems in IOT thank you David

348
00:14:28,389 --> 00:14:34,630
so I sort of bring the academic

349
00:14:31,180 --> 00:14:37,599
perspective - I guess this panel and one

350
00:14:34,630 --> 00:14:39,399
of the benefits of being an academic is

351
00:14:37,600 --> 00:14:40,930
that I have the luxury of being able to

352
00:14:39,399 --> 00:14:43,630
dream up cleanslate solutions right

353
00:14:40,930 --> 00:14:45,880
without being hampered by a lot of the

354
00:14:43,630 --> 00:14:52,449
you know legacy baggage if I may pull it

355
00:14:45,880 --> 00:14:53,980
up and so we my I lead a team of very

356
00:14:52,449 --> 00:14:56,859
bright students and researchers some of

357
00:14:53,980 --> 00:14:58,930
whom are in the room here who over the

358
00:14:56,860 --> 00:15:00,519
past 10 years or so I've been looking at

359
00:14:58,930 --> 00:15:03,930
essentially cleanslate

360
00:15:00,519 --> 00:15:06,279
approaches for hardware and software

361
00:15:03,930 --> 00:15:09,819
architectures for next-generation

362
00:15:06,279 --> 00:15:12,069
embedded systems and the medical device

363
00:15:09,819 --> 00:15:15,370
area right we're talking about variable

364
00:15:12,069 --> 00:15:16,810
medical devices and more a plate of even

365
00:15:15,370 --> 00:15:19,089
more interest implantable medical

366
00:15:16,810 --> 00:15:20,300
devices things that actually go inside

367
00:15:19,089 --> 00:15:23,930
your body

368
00:15:20,300 --> 00:15:27,170
and ways in ways to design these systems

369
00:15:23,930 --> 00:15:31,819
to make them more energy efficient and

370
00:15:27,170 --> 00:15:33,860
secure and there's a number of specific

371
00:15:31,820 --> 00:15:35,600
systems that we've that people looked at

372
00:15:33,860 --> 00:15:38,990
and worked on including sort of the

373
00:15:35,600 --> 00:15:43,690
artificial pancreas sort of system where

374
00:15:38,990 --> 00:15:48,080
we try to design a bunch of what we call

375
00:15:43,690 --> 00:15:50,140
last lines of defense into the endpoint

376
00:15:48,080 --> 00:15:53,960
or the medical device itself such that

377
00:15:50,140 --> 00:15:55,580
you know if even if there is some kind

378
00:15:53,960 --> 00:15:58,250
of a security attack or there's some

379
00:15:55,580 --> 00:16:00,250
kind of a malfunction in the device you

380
00:15:58,250 --> 00:16:04,850
know can be put in sufficient safeguards

381
00:16:00,250 --> 00:16:08,360
and make those safeguards you know well

382
00:16:04,850 --> 00:16:10,580
locked down and small enough that they

383
00:16:08,360 --> 00:16:12,050
could be verified statically it could be

384
00:16:10,580 --> 00:16:13,670
you know sort of verified using formal

385
00:16:12,050 --> 00:16:15,859
methods for example where we can

386
00:16:13,670 --> 00:16:17,599
actually prove that look you know under

387
00:16:15,860 --> 00:16:19,550
these set of assumptions these these

388
00:16:17,600 --> 00:16:20,750
devices will actually do you know

389
00:16:19,550 --> 00:16:22,819
perform the way they're expected to

390
00:16:20,750 --> 00:16:24,650
perform or if there is a security attack

391
00:16:22,820 --> 00:16:27,440
of particular time that you can actually

392
00:16:24,650 --> 00:16:28,970
say something intelligent about you know

393
00:16:27,440 --> 00:16:30,650
what the device is basically going to be

394
00:16:28,970 --> 00:16:34,250
doing and if you can lock down the

395
00:16:30,650 --> 00:16:37,880
device to prevent any any any damage and

396
00:16:34,250 --> 00:16:42,710
so my take on sort of based on that line

397
00:16:37,880 --> 00:16:44,810
of work is I think implantables you know

398
00:16:42,710 --> 00:16:46,940
looking forward you're 15 or 20 years

399
00:16:44,810 --> 00:16:49,400
I think implantables are going to play a

400
00:16:46,940 --> 00:16:52,310
very very key role in this whole space

401
00:16:49,400 --> 00:16:55,130
of medical devices I think it's sort of

402
00:16:52,310 --> 00:16:57,349
continuing that trend of pushing sort of

403
00:16:55,130 --> 00:16:59,480
healthcare down to the patient and down

404
00:16:57,350 --> 00:17:01,700
in fact into the patient in the case of

405
00:16:59,480 --> 00:17:05,050
an implantable and I think that lets us

406
00:17:01,700 --> 00:17:10,130
do two things right one is it lets you

407
00:17:05,050 --> 00:17:11,899
get a you know at least in most cases a

408
00:17:10,130 --> 00:17:13,280
lot of real-time feedback right so

409
00:17:11,900 --> 00:17:15,380
you're sort of closing that loop in

410
00:17:13,280 --> 00:17:16,609
real-time as something happens to a

411
00:17:15,380 --> 00:17:20,420
patient you know if the patient you know

412
00:17:16,609 --> 00:17:22,280
has in epic seizure patient has a heart

413
00:17:20,420 --> 00:17:24,620
attack or something right you know the

414
00:17:22,280 --> 00:17:28,639
the the loop gets closed much faster and

415
00:17:24,619 --> 00:17:32,239
second is it allows us to move towards a

416
00:17:28,640 --> 00:17:33,290
realm of personalized medicine and again

417
00:17:32,240 --> 00:17:36,020
as

418
00:17:33,290 --> 00:17:37,550
mentioned you know that aspect of

419
00:17:36,020 --> 00:17:39,139
personalization right you know you want

420
00:17:37,550 --> 00:17:42,409
to be able to figure out if a particular

421
00:17:39,140 --> 00:17:44,990
drug is working well for a specific

422
00:17:42,410 --> 00:17:47,000
patient or not and sort of that aspect

423
00:17:44,990 --> 00:17:49,100
of personalization really comes to the

424
00:17:47,000 --> 00:17:50,210
forefront if you now start thinking of

425
00:17:49,100 --> 00:17:51,379
all of these variable and implantable

426
00:17:50,210 --> 00:17:53,210
medical devices you're not sort of

427
00:17:51,380 --> 00:17:56,870
providing you personalized real-time

428
00:17:53,210 --> 00:17:58,940
feedback the challenge with a lot of

429
00:17:56,870 --> 00:18:02,360
these devices in terms of security as

430
00:17:58,940 --> 00:18:06,830
I'm sure my co-panelists will do as well

431
00:18:02,360 --> 00:18:11,060
is the fact that you know it's one thing

432
00:18:06,830 --> 00:18:13,129
trying to design a large cyber cyber

433
00:18:11,060 --> 00:18:16,399
system and trying to secure that right

434
00:18:13,130 --> 00:18:18,470
as complex and as difficult as it is but

435
00:18:16,400 --> 00:18:20,360
you also these systems also have the

436
00:18:18,470 --> 00:18:24,080
computer resources the sort of

437
00:18:20,360 --> 00:18:26,330
architectural safeguards in place that

438
00:18:24,080 --> 00:18:27,470
as a security engineer or a person who's

439
00:18:26,330 --> 00:18:29,449
worried about the security of these

440
00:18:27,470 --> 00:18:32,420
systems you at least have the tools that

441
00:18:29,450 --> 00:18:34,820
you can use in order to enforce security

442
00:18:32,420 --> 00:18:36,890
policies and stuff the issue with a lot

443
00:18:34,820 --> 00:18:40,040
of these implantable medical devices is

444
00:18:36,890 --> 00:18:42,430
that they're you know clearly for mostly

445
00:18:40,040 --> 00:18:48,320
for energy consumption reasons or for

446
00:18:42,430 --> 00:18:49,910
form-factor reasons they lack a lot at

447
00:18:48,320 --> 00:18:51,560
least hardware components in their lack

448
00:18:49,910 --> 00:18:53,150
lot of the architectural safety

449
00:18:51,560 --> 00:18:54,580
mechanisms that we are typically used to

450
00:18:53,150 --> 00:18:56,420
when we think about security and

451
00:18:54,580 --> 00:18:58,460
conventional car types of computing

452
00:18:56,420 --> 00:19:01,610
systems right and that makes it a real

453
00:18:58,460 --> 00:19:03,770
challenge in terms of actually trying to

454
00:19:01,610 --> 00:19:05,899
secure these devices right and can often

455
00:19:03,770 --> 00:19:07,160
even something as simple as you know you

456
00:19:05,900 --> 00:19:10,100
put something into a patient you put a

457
00:19:07,160 --> 00:19:11,960
pacemaker into a patient and you somehow

458
00:19:10,100 --> 00:19:12,980
want to securely communicate with it

459
00:19:11,960 --> 00:19:16,220
right this thing is going to be

460
00:19:12,980 --> 00:19:18,170
wirelessly enabled how do you exchange

461
00:19:16,220 --> 00:19:20,120
keys with an implanted device in a

462
00:19:18,170 --> 00:19:22,610
secure manner right it's in a scalable

463
00:19:20,120 --> 00:19:24,830
way right and not do something crazy is

464
00:19:22,610 --> 00:19:26,389
having sort of a preset key that you're

465
00:19:24,830 --> 00:19:27,620
going to use for the same key for all

466
00:19:26,390 --> 00:19:31,700
the other devices in stuff right so

467
00:19:27,620 --> 00:19:34,189
that's one aspect the last challenge

468
00:19:31,700 --> 00:19:37,040
that I'll that I'll mention in my

469
00:19:34,190 --> 00:19:40,360
opening remarks here is security in

470
00:19:37,040 --> 00:19:42,590
these implantable devices also sort of a

471
00:19:40,360 --> 00:19:44,870
it's it's a double-edged sword

472
00:19:42,590 --> 00:19:46,040
because under normal conditions imagine

473
00:19:44,870 --> 00:19:46,370
again a patient for example who has a

474
00:19:46,040 --> 00:19:47,960
pain

475
00:19:46,370 --> 00:19:49,459
under normal conditions you want to lock

476
00:19:47,960 --> 00:19:51,860
down this patient pacemaker as much as

477
00:19:49,460 --> 00:19:53,750
he can I don't want anybody talking to

478
00:19:51,860 --> 00:19:56,270
it except perhaps you know in a very

479
00:19:53,750 --> 00:19:57,650
secure way a device that a user owns or

480
00:19:56,270 --> 00:19:58,789
of course we enter a secure environment

481
00:19:57,650 --> 00:20:00,590
like a doctor's office like a

482
00:19:58,789 --> 00:20:02,620
cardiologists office and they we have

483
00:20:00,590 --> 00:20:05,750
that magic wand over here for your heart

484
00:20:02,620 --> 00:20:07,189
but the instant something goes wrong

485
00:20:05,750 --> 00:20:08,960
with you the instant you have a heart

486
00:20:07,190 --> 00:20:11,210
attack and you know you call 9-1-1 and

487
00:20:08,960 --> 00:20:12,590
that emergency responder shows up you

488
00:20:11,210 --> 00:20:14,720
want all your safeguards to basically

489
00:20:12,590 --> 00:20:17,629
just vanish because you don't want to

490
00:20:14,720 --> 00:20:20,029
impede access you know access to your

491
00:20:17,630 --> 00:20:21,289
device and access to care right in any

492
00:20:20,029 --> 00:20:23,630
kind of way and you don't want to have

493
00:20:21,289 --> 00:20:24,919
that emergency responder even delay by a

494
00:20:23,630 --> 00:20:26,299
few minutes or a couple of minutes

495
00:20:24,919 --> 00:20:28,309
trying to actually get into your device

496
00:20:26,299 --> 00:20:30,649
right so it is really strange thing and

497
00:20:28,309 --> 00:20:32,658
by the way that emergency responder will

498
00:20:30,649 --> 00:20:34,908
probably use some kind of a special

499
00:20:32,659 --> 00:20:36,140
device to top ear to your implantable

500
00:20:34,909 --> 00:20:37,490
medical device which and these two

501
00:20:36,140 --> 00:20:39,110
devices have never seen each other level

502
00:20:37,490 --> 00:20:41,539
never had a chance to sort of exchange

503
00:20:39,110 --> 00:20:43,219
keys before or sort of collaborate with

504
00:20:41,539 --> 00:20:45,230
each other right so it's a really

505
00:20:43,220 --> 00:20:47,149
strange problem where you really want

506
00:20:45,230 --> 00:20:49,580
your device locked down except when you

507
00:20:47,149 --> 00:20:51,918
don't in which case you need to just

508
00:20:49,580 --> 00:20:53,629
throw it open completely and sort of

509
00:20:51,919 --> 00:20:56,179
solving that dichotomy I think is one of

510
00:20:53,630 --> 00:21:00,529
the most interesting sort of challenges

511
00:20:56,179 --> 00:21:04,669
in power you know things that I'll stop

512
00:21:00,529 --> 00:21:07,250
with that and our last speaker is Church

513
00:21:04,669 --> 00:21:09,590
Bailey who's a senior advisor for health

514
00:21:07,250 --> 00:21:11,870
IT security with Purdue health care

515
00:21:09,590 --> 00:21:13,490
advisors Thank You professor Ebert so I

516
00:21:11,870 --> 00:21:15,590
come from a different perspective I'm a

517
00:21:13,490 --> 00:21:18,070
security practitioner who has the

518
00:21:15,590 --> 00:21:21,230
benefit of actually working with

519
00:21:18,070 --> 00:21:24,230
delivery health systems doctors nurses I

520
00:21:21,230 --> 00:21:27,080
keep practitioners in health systems of

521
00:21:24,230 --> 00:21:29,539
all sizes down to your one doc three

522
00:21:27,080 --> 00:21:32,178
employee clinic all the way to multi

523
00:21:29,539 --> 00:21:34,789
Hospital health systems and I get to see

524
00:21:32,179 --> 00:21:36,620
the whole gamut of good practice bad

525
00:21:34,789 --> 00:21:39,140
practice and anywhere in between and

526
00:21:36,620 --> 00:21:42,860
I'll concur with these three gentlemen

527
00:21:39,140 --> 00:21:46,279
right HIPAA I think is is very

528
00:21:42,860 --> 00:21:48,469
misunderstood right so as an industry

529
00:21:46,279 --> 00:21:50,149
we're being promoted for

530
00:21:48,470 --> 00:21:52,549
interoperability we want data sharing

531
00:21:50,149 --> 00:21:54,350
because we want to get data in the

532
00:21:52,549 --> 00:21:56,030
patient's hands so that as they bounce

533
00:21:54,350 --> 00:21:58,310
around to the various care providers

534
00:21:56,030 --> 00:22:01,340
they have the data that they need to get

535
00:21:58,310 --> 00:22:04,940
optimal care however providers who are

536
00:22:01,340 --> 00:22:06,830
under this regulatory constraint of well

537
00:22:04,940 --> 00:22:09,770
can I share with that other care

538
00:22:06,830 --> 00:22:13,699
provider can i how do I do so securely

539
00:22:09,770 --> 00:22:16,220
right so HIPAA allows it because it's so

540
00:22:13,700 --> 00:22:20,540
misunderstood people error on the side

541
00:22:16,220 --> 00:22:22,520
of caution and inhibits care there are

542
00:22:20,540 --> 00:22:25,040
things we can do securely to to enable

543
00:22:22,520 --> 00:22:27,500
the patient for sure so I think HIPPA

544
00:22:25,040 --> 00:22:30,050
needs some significant rewrites right

545
00:22:27,500 --> 00:22:33,800
think about when HIPAA was established

546
00:22:30,050 --> 00:22:36,950
right it was enforceable early 2000 was

547
00:22:33,800 --> 00:22:41,210
written in 1996 as part of a health

548
00:22:36,950 --> 00:22:44,360
insurance modernization right so

549
00:22:41,210 --> 00:22:46,610
security was a byproduct of HIPAA but

550
00:22:44,360 --> 00:22:49,520
because of it we have now had two

551
00:22:46,610 --> 00:22:51,469
decades of facilities and healthcare

552
00:22:49,520 --> 00:22:55,220
delivery systems just not understanding

553
00:22:51,470 --> 00:22:57,290
how it implemented and you know the way

554
00:22:55,220 --> 00:22:59,720
that I describe it is health care today

555
00:22:57,290 --> 00:23:02,930
is in there dot-com boom where most of

556
00:22:59,720 --> 00:23:06,350
us back in the early 90s late 90s

557
00:23:02,930 --> 00:23:08,270
adopting public facing systems right

558
00:23:06,350 --> 00:23:09,740
those first DMC's you rolled out because

559
00:23:08,270 --> 00:23:12,020
you had services you want to get to the

560
00:23:09,740 --> 00:23:14,510
public healthcare is just now in that

561
00:23:12,020 --> 00:23:16,940
space and we wouldn't be in that space

562
00:23:14,510 --> 00:23:19,460
if it wasn't for some incentives at

563
00:23:16,940 --> 00:23:22,250
least us-based health care facilities

564
00:23:19,460 --> 00:23:23,990
right since 2011 health care facilities

565
00:23:22,250 --> 00:23:26,420
have been incentivized to adopt

566
00:23:23,990 --> 00:23:29,150
electronic health records and to deploy

567
00:23:26,420 --> 00:23:33,200
patient portals and to get information

568
00:23:29,150 --> 00:23:34,730
in the hands of the patient right so we

569
00:23:33,200 --> 00:23:38,680
we've had these organizations that were

570
00:23:34,730 --> 00:23:41,630
purely paper-based pen-and-paper

571
00:23:38,680 --> 00:23:44,060
very next week oh my goodness we have

572
00:23:41,630 --> 00:23:46,160
electronical system we're you know we

573
00:23:44,060 --> 00:23:49,220
have computers everywhere and we don't

574
00:23:46,160 --> 00:23:52,070
have a formal risk management strategy

575
00:23:49,220 --> 00:23:53,480
to deal with IT issues you know we do

576
00:23:52,070 --> 00:23:55,610
you handle compliance the OSHA

577
00:23:53,480 --> 00:23:57,490
infectious disease those kinds of the

578
00:23:55,610 --> 00:23:59,389
shoes fairly well in healthcare but

579
00:23:57,490 --> 00:24:02,540
managing the security of data and

580
00:23:59,390 --> 00:24:04,550
systems those processes although other

581
00:24:02,540 --> 00:24:06,590
industries have have gotten very good at

582
00:24:04,550 --> 00:24:09,530
it we don't have the personnel in

583
00:24:06,590 --> 00:24:11,779
healthcare to address that most security

584
00:24:09,530 --> 00:24:14,509
officers in that medium

585
00:24:11,779 --> 00:24:16,580
Health System and smaller there security

586
00:24:14,509 --> 00:24:18,049
officer is probably their h-i-m their

587
00:24:16,580 --> 00:24:19,820
health information management person

588
00:24:18,049 --> 00:24:21,710
right they were the person who managed

589
00:24:19,820 --> 00:24:24,468
the chart room right they they were

590
00:24:21,710 --> 00:24:26,659
charged with keeping patient privacy and

591
00:24:24,469 --> 00:24:29,059
now oh well you dealt with data you

592
00:24:26,659 --> 00:24:31,639
dealt with information where this other

593
00:24:29,059 --> 00:24:32,840
hat in the reality is they're only

594
00:24:31,639 --> 00:24:35,539
wearing that hat

595
00:24:32,840 --> 00:24:38,269
whenever Health and Human Services pays

596
00:24:35,539 --> 00:24:40,489
them a call or their payor wants to know

597
00:24:38,269 --> 00:24:42,619
how their securing data right they don't

598
00:24:40,489 --> 00:24:46,129
have the luxury of wearing the security

599
00:24:42,619 --> 00:24:48,109
hat every day every hour that they're in

600
00:24:46,129 --> 00:24:49,699
the facility and then worrying about it

601
00:24:48,109 --> 00:24:51,499
right you ask an hie in person what

602
00:24:49,700 --> 00:24:53,929
keeps them up at night it's not data

603
00:24:51,499 --> 00:24:56,239
security because they're they're just

604
00:24:53,929 --> 00:24:59,119
not informed enough to know that so

605
00:24:56,239 --> 00:25:01,759
these poor risk management strategies

606
00:24:59,119 --> 00:25:04,428
which is required by HIPAA but it's not

607
00:25:01,759 --> 00:25:08,570
prescriptive HIPAA will say look to NIST

608
00:25:04,429 --> 00:25:10,099
use the NIST 853 for controls and how

609
00:25:08,570 --> 00:25:13,158
you would protect your systems look at

610
00:25:10,099 --> 00:25:15,379
834 how you would assess your IT

611
00:25:13,159 --> 00:25:17,389
environment you give that type of

612
00:25:15,379 --> 00:25:20,509
framework to a person who's used to

613
00:25:17,389 --> 00:25:22,728
managing paper files and and it's it

614
00:25:20,509 --> 00:25:24,109
doesn't get implemented then not to

615
00:25:22,729 --> 00:25:25,909
their fault they just don't understand

616
00:25:24,109 --> 00:25:27,918
it they don't have the resources to go

617
00:25:25,909 --> 00:25:30,589
and get it figure it out

618
00:25:27,919 --> 00:25:34,339
so these risk management practices leads

619
00:25:30,589 --> 00:25:36,859
to poor technology life cycles so as

620
00:25:34,339 --> 00:25:39,320
Chris mentioned right the FDA is

621
00:25:36,859 --> 00:25:41,449
providing decent guidance and medical

622
00:25:39,320 --> 00:25:42,710
device manufacturers are implementing

623
00:25:41,450 --> 00:25:44,779
right they understand they've heard the

624
00:25:42,710 --> 00:25:46,119
consumers people were afraid when Dick

625
00:25:44,779 --> 00:25:49,519
Cheney turned off his his pacemaker

626
00:25:46,119 --> 00:25:50,678
right that that was world news and was

627
00:25:49,519 --> 00:25:52,789
he paranoid

628
00:25:50,679 --> 00:25:54,830
probably not he's a high profile person

629
00:25:52,789 --> 00:25:56,389
he travels internationally right if he

630
00:25:54,830 --> 00:25:59,570
was a target and someone got close

631
00:25:56,389 --> 00:26:00,918
enough to him their potential

632
00:25:59,570 --> 00:26:02,899
vulnerability there certainly is a

633
00:26:00,919 --> 00:26:06,169
threat there right someone like myself

634
00:26:02,899 --> 00:26:08,238
low risk but it's the it's the legacy

635
00:26:06,169 --> 00:26:11,779
devices that really we have the issue

636
00:26:08,239 --> 00:26:13,190
because in most care facilities if it's

637
00:26:11,779 --> 00:26:15,529
not a revenue-generating

638
00:26:13,190 --> 00:26:18,320
right so you hear the commercials on a

639
00:26:15,529 --> 00:26:20,659
radio get yard scan $49.99 right that's

640
00:26:18,320 --> 00:26:23,418
a revenue-generating service yeah at the

641
00:26:20,659 --> 00:26:25,350
end of the day your doctor is running a

642
00:26:23,419 --> 00:26:28,200
business right so you keep his door

643
00:26:25,350 --> 00:26:30,178
open they need to have revenue so if

644
00:26:28,200 --> 00:26:32,549
they have an $8,000 EKG machine that

645
00:26:30,179 --> 00:26:34,140
they're about 20 years ago and the

646
00:26:32,549 --> 00:26:36,240
function of it hasn't changed it's a

647
00:26:34,140 --> 00:26:38,070
diagnostic device it doesn't really make

648
00:26:36,240 --> 00:26:41,900
them any money they're not going to

649
00:26:38,070 --> 00:26:45,090
upgrade it but this networked it is

650
00:26:41,900 --> 00:26:47,429
networks aren't segmented so if you are

651
00:26:45,090 --> 00:26:49,350
in the clinic and and you have access to

652
00:26:47,429 --> 00:26:51,090
the network that device is vulnerable to

653
00:26:49,350 --> 00:26:53,159
you know anything else that may be

654
00:26:51,090 --> 00:26:55,760
vulnerable from that state that age of a

655
00:26:53,160 --> 00:26:57,990
device so it's a big thing and

656
00:26:55,760 --> 00:27:00,570
eventually that will organically solve

657
00:26:57,990 --> 00:27:03,870
itself these devices break down as they

658
00:27:00,570 --> 00:27:09,178
do turn over but it's gonna be a long

659
00:27:03,870 --> 00:27:10,770
time so a couple other things just the

660
00:27:09,179 --> 00:27:12,320
the situation of awareness of the

661
00:27:10,770 --> 00:27:14,700
vulnerability threat landscape

662
00:27:12,320 --> 00:27:16,740
healthcare providers are in the business

663
00:27:14,700 --> 00:27:22,159
to provide care right they they're not

664
00:27:16,740 --> 00:27:22,159
in the business to be up on the latest

665
00:27:22,400 --> 00:27:26,280
whatever the latest one it really might

666
00:27:24,419 --> 00:27:27,809
be right so a couple years ago when we

667
00:27:26,280 --> 00:27:32,490
were dealing with heartbleed and poodle

668
00:27:27,809 --> 00:27:35,158
these SSL issues SSL is one of those

669
00:27:32,490 --> 00:27:38,549
things that we should have solved a long

670
00:27:35,159 --> 00:27:40,440
time ago right we shouldn't be using SSL

671
00:27:38,549 --> 00:27:42,059
version any SSL versions right we should

672
00:27:40,440 --> 00:27:46,710
be on TLS version 1.2

673
00:27:42,059 --> 00:27:50,520
I see SSL version 2 everywhere right

674
00:27:46,710 --> 00:27:53,220
because our health care folks their IT

675
00:27:50,520 --> 00:27:55,110
consumers we've we've programmed them to

676
00:27:53,220 --> 00:27:56,549
look for the padlock all right so in

677
00:27:55,110 --> 00:27:59,100
their EHR system and their patient

678
00:27:56,549 --> 00:28:00,600
portals they see a pedal oh it's secure

679
00:27:59,100 --> 00:28:03,090
they don't understand that there's

680
00:28:00,600 --> 00:28:04,500
there's levels of security there and

681
00:28:03,090 --> 00:28:06,959
they don't know that they should be

682
00:28:04,500 --> 00:28:09,630
reaching out for the most modern right

683
00:28:06,960 --> 00:28:14,789
and that that goes through all layers of

684
00:28:09,630 --> 00:28:16,530
the system other talking points security

685
00:28:14,789 --> 00:28:20,129
awareness of all levels right so you've

686
00:28:16,530 --> 00:28:21,658
got folks that are your senior

687
00:28:20,130 --> 00:28:23,370
executives of the healthcare system all

688
00:28:21,659 --> 00:28:24,900
the way down to that medical assistant

689
00:28:23,370 --> 00:28:27,600
right and the medical assistants

690
00:28:24,900 --> 00:28:29,880
touching the patient they're interfacing

691
00:28:27,600 --> 00:28:32,639
with infusion pumps they're they're

692
00:28:29,880 --> 00:28:34,380
they're interfacing with the Pyxis in

693
00:28:32,640 --> 00:28:36,750
order to dispense meds for the for the

694
00:28:34,380 --> 00:28:38,130
RN there's there's all kinds of things

695
00:28:36,750 --> 00:28:38,410
that they're interacting with and they

696
00:28:38,130 --> 00:28:41,500
have

697
00:28:38,410 --> 00:28:43,330
no awareness of anomalies right so if

698
00:28:41,500 --> 00:28:45,850
they see a message on the screen they

699
00:28:43,330 --> 00:28:48,610
click through it if there's well it's

700
00:28:45,850 --> 00:28:51,550
time to reboot right so things like

701
00:28:48,610 --> 00:28:52,780
ransomware is why health care is it's so

702
00:28:51,550 --> 00:28:55,480
vulnerable to those things because

703
00:28:52,780 --> 00:28:58,210
people in the industry just they don't

704
00:28:55,480 --> 00:29:01,240
know to stop and they you know we were

705
00:28:58,210 --> 00:29:07,330
telling folks to have a zero trust but

706
00:29:01,240 --> 00:29:09,310
they don't know not to trust physical

707
00:29:07,330 --> 00:29:12,669
security it's it's not necessary a cyber

708
00:29:09,310 --> 00:29:15,070
issue but because we have legacy devices

709
00:29:12,670 --> 00:29:16,480
Windows XP is still very prevalent at

710
00:29:15,070 --> 00:29:18,310
least here in the Midwest in health care

711
00:29:16,480 --> 00:29:21,430
delivery systems I would imagine it's

712
00:29:18,310 --> 00:29:25,720
it's prevalent everywhere and why is

713
00:29:21,430 --> 00:29:27,430
that because there's a there's a mobile

714
00:29:25,720 --> 00:29:29,500
ultrasound machine that plugs into it

715
00:29:27,430 --> 00:29:32,530
and it and it's purely because the

716
00:29:29,500 --> 00:29:34,600
driver only works on XP and in order to

717
00:29:32,530 --> 00:29:35,950
retool that it's a turnkey solution and

718
00:29:34,600 --> 00:29:37,480
I got to spend another hundred thousand

719
00:29:35,950 --> 00:29:38,920
dollars for whatever the latest and

720
00:29:37,480 --> 00:29:41,230
greatest and the latest and greatest

721
00:29:38,920 --> 00:29:44,110
doesn't give you any more diagnostic

722
00:29:41,230 --> 00:29:47,320
capability within that whatever the test

723
00:29:44,110 --> 00:29:49,330
that device is for so they live with it

724
00:29:47,320 --> 00:29:53,129
but it's on the network they access the

725
00:29:49,330 --> 00:29:57,010
EHR they print they do other things so

726
00:29:53,130 --> 00:29:58,060
and the the physical aspect of that you

727
00:29:57,010 --> 00:29:59,410
could walk up you could touch these

728
00:29:58,060 --> 00:30:00,550
things as a patient you could walk them

729
00:29:59,410 --> 00:30:03,160
touch these things as a as a

730
00:30:00,550 --> 00:30:06,190
representative of a patient and there's

731
00:30:03,160 --> 00:30:07,210
not a lot of scrutiny when you're

732
00:30:06,190 --> 00:30:10,950
walking through a healthcare facility

733
00:30:07,210 --> 00:30:13,300
right you if you want to do harm a

734
00:30:10,950 --> 00:30:14,770
hospital is where you need to go because

735
00:30:13,300 --> 00:30:16,600
most people aren't going to question you

736
00:30:14,770 --> 00:30:19,120
all right they're busy they're

737
00:30:16,600 --> 00:30:21,219
overloaded and you can you can touch you

738
00:30:19,120 --> 00:30:24,010
can touch a PC you can touch a Pyxis

739
00:30:21,220 --> 00:30:26,410
machine amid dispensing you can touch

740
00:30:24,010 --> 00:30:28,420
medical devices and you know something

741
00:30:26,410 --> 00:30:31,090
as simple as a rubber ducky right a key

742
00:30:28,420 --> 00:30:33,150
keystroke injector device you can you

743
00:30:31,090 --> 00:30:39,370
can have a cause a lot of damage

744
00:30:33,150 --> 00:30:39,730
other talking points I think I'll leave

745
00:30:39,370 --> 00:30:43,780
it that

746
00:30:39,730 --> 00:30:46,240
leave that for questions okay well I you

747
00:30:43,780 --> 00:30:48,879
know I was thinking of this in my terms

748
00:30:46,240 --> 00:30:51,970
of where we're going with the change in

749
00:30:48,880 --> 00:30:52,260
medicine and the change in new implanted

750
00:30:51,970 --> 00:30:54,450
of

751
00:30:52,260 --> 00:30:57,120
Isis and personalized medicine and all

752
00:30:54,450 --> 00:30:59,070
the new security concerns in that and

753
00:30:57,120 --> 00:31:01,409
not thinking as much about the legacy

754
00:30:59,070 --> 00:31:03,780
systems and the integrated patient

755
00:31:01,410 --> 00:31:07,080
health exchanges of information in the

756
00:31:03,780 --> 00:31:10,200
privacy of all of that and so personally

757
00:31:07,080 --> 00:31:11,669
I things that I just consider normal

758
00:31:10,200 --> 00:31:13,830
cyber problems their information

759
00:31:11,670 --> 00:31:16,500
security or information privacy seeing

760
00:31:13,830 --> 00:31:19,260
the way that they're getting transformed

761
00:31:16,500 --> 00:31:22,080
today from that individual small device

762
00:31:19,260 --> 00:31:26,390
up through you know citywide statewide

763
00:31:22,080 --> 00:31:29,070
health information exchanges is a little

764
00:31:26,390 --> 00:31:32,160
illuminating and a little disconcerting

765
00:31:29,070 --> 00:31:34,200
as well it's one of those things where

766
00:31:32,160 --> 00:31:37,890
when you're talking about what people

767
00:31:34,200 --> 00:31:40,800
are pulling up on their systems twice

768
00:31:37,890 --> 00:31:43,910
now recently seeing a physician he

769
00:31:40,800 --> 00:31:47,100
googled a term and then pulled up pages

770
00:31:43,910 --> 00:31:48,990
off of Wikipedia to explain what was

771
00:31:47,100 --> 00:31:51,270
going on on this terminal with my

772
00:31:48,990 --> 00:31:53,100
medical records and you know my entire

773
00:31:51,270 --> 00:31:54,870
personal health record they're on the

774
00:31:53,100 --> 00:31:57,030
same device that I have no idea how

775
00:31:54,870 --> 00:31:59,310
secure that is but you're just thinking

776
00:31:57,030 --> 00:32:00,870
of you know he thought nothing of it and

777
00:31:59,310 --> 00:32:02,940
he said you know did your rash look

778
00:32:00,870 --> 00:32:07,500
exactly like this and it was like well

779
00:32:02,940 --> 00:32:09,390
yes it did you know these things where I

780
00:32:07,500 --> 00:32:11,340
think you're right you bring that human

781
00:32:09,390 --> 00:32:13,470
in I think there's also you know these

782
00:32:11,340 --> 00:32:17,669
emerging challenges as you talked about

783
00:32:13,470 --> 00:32:20,490
in terms of the individual implantable

784
00:32:17,670 --> 00:32:21,840
devices and in terms of their some

785
00:32:20,490 --> 00:32:24,240
interesting work colleagues are doing

786
00:32:21,840 --> 00:32:26,570
here at Purdue and actually using the

787
00:32:24,240 --> 00:32:29,130
bioelectric field of the human as

788
00:32:26,570 --> 00:32:31,379
identifiers of who can access that

789
00:32:29,130 --> 00:32:33,570
device to control that device so you're

790
00:32:31,380 --> 00:32:35,160
using your personalized electrical field

791
00:32:33,570 --> 00:32:37,169
to make sure that you don't have someone

792
00:32:35,160 --> 00:32:39,390
spoofing it so there's really creative

793
00:32:37,170 --> 00:32:41,220
solutions to some of that but then when

794
00:32:39,390 --> 00:32:44,910
you get into the sharing of information

795
00:32:41,220 --> 00:32:47,970
that no CVS being an example that is

796
00:32:44,910 --> 00:32:49,920
also now providing prescription plans as

797
00:32:47,970 --> 00:32:52,290
well as being the person who's selling

798
00:32:49,920 --> 00:32:55,500
the drugs so now you've got more

799
00:32:52,290 --> 00:32:58,170
information collected uniformly and sort

800
00:32:55,500 --> 00:33:00,360
of I guess for privacy side the good or

801
00:32:58,170 --> 00:33:03,150
bad of our healthcare system now as most

802
00:33:00,360 --> 00:33:05,010
of your health care data is fragmented

803
00:33:03,150 --> 00:33:06,179
and so it's very hard for anyone to

804
00:33:05,010 --> 00:33:08,399
really get your life

805
00:33:06,179 --> 00:33:09,690
history of your medical history because

806
00:33:08,399 --> 00:33:11,549
some of it are with the drug companies

807
00:33:09,690 --> 00:33:14,669
over what's the different providers

808
00:33:11,549 --> 00:33:16,350
you've seen over the years etc and you

809
00:33:14,669 --> 00:33:18,419
know if you have more of a system like

810
00:33:16,350 --> 00:33:19,980
in Canada provincially you've got all of

811
00:33:18,419 --> 00:33:22,799
the data sitting in one place which

812
00:33:19,980 --> 00:33:24,659
opens up potential for more accurate

813
00:33:22,799 --> 00:33:27,149
health care which is one trade off

814
00:33:24,659 --> 00:33:28,350
versus the vulnerabilities attack yet so

815
00:33:27,149 --> 00:33:31,049
I think there's a whole range of

816
00:33:28,350 --> 00:33:33,779
questions for that we can talk about

817
00:33:31,049 --> 00:33:38,009
here and so please step up to the mic

818
00:33:33,779 --> 00:33:39,720
and address those as well as we're

819
00:33:38,009 --> 00:33:41,970
waiting for someone to come up I guess

820
00:33:39,720 --> 00:33:43,769
you know the one question I pose to the

821
00:33:41,970 --> 00:33:47,519
panel is what are you most concerned

822
00:33:43,769 --> 00:33:52,080
about in looking at security of the

823
00:33:47,519 --> 00:33:54,119
future of your personal health care so

824
00:33:52,080 --> 00:33:57,539
I'll give it a shot so there's a trend

825
00:33:54,119 --> 00:33:59,490
that has some toxic ating attributes to

826
00:33:57,539 --> 00:34:02,070
it which is cloud computing and the

827
00:33:59,490 --> 00:34:04,590
intoxicating attributes is that you can

828
00:34:02,070 --> 00:34:07,139
store data in one place use it for

829
00:34:04,590 --> 00:34:09,270
hundreds of different purposes with

830
00:34:07,139 --> 00:34:12,029
different entities using that data now

831
00:34:09,270 --> 00:34:14,489
that's the promise and the economics to

832
00:34:12,030 --> 00:34:16,589
that equation or what's intoxicating

833
00:34:14,489 --> 00:34:18,569
because instead of storing data a

834
00:34:16,589 --> 00:34:21,239
hundred times you're storing data once

835
00:34:18,569 --> 00:34:23,308
and you're using and sharing it with all

836
00:34:21,239 --> 00:34:25,049
sorts of different entities that could

837
00:34:23,309 --> 00:34:28,079
be competing with each other in certain

838
00:34:25,049 --> 00:34:30,780
cases but have very different needs but

839
00:34:28,079 --> 00:34:35,879
need access to that data right so

840
00:34:30,780 --> 00:34:39,389
there's two approaches that give us some

841
00:34:35,879 --> 00:34:41,339
hope for being able to realize that and

842
00:34:39,389 --> 00:34:43,409
protect the data effectively in all

843
00:34:41,339 --> 00:34:47,668
scenarios one is called differential

844
00:34:43,409 --> 00:34:49,290
privacy which is it's an obfuscation I'm

845
00:34:47,668 --> 00:34:51,449
gonna butcher this in the interest of

846
00:34:49,290 --> 00:34:54,329
time an obfuscation technique that

847
00:34:51,449 --> 00:34:57,750
basically allows you to get multiple

848
00:34:54,329 --> 00:34:59,760
people to access the same data without

849
00:34:57,750 --> 00:35:02,520
sharing data from a compliance

850
00:34:59,760 --> 00:35:05,059
standpoint so that's one dimension the

851
00:35:02,520 --> 00:35:09,000
other is homomorphic encryption which

852
00:35:05,059 --> 00:35:12,180
allows you to offer an encryption

853
00:35:09,000 --> 00:35:13,760
capability on the data that served up as

854
00:35:12,180 --> 00:35:15,480
well as the queries that go in

855
00:35:13,760 --> 00:35:17,520
simultaneously so if different

856
00:35:15,480 --> 00:35:19,650
competitors are using the same database

857
00:35:17,520 --> 00:35:21,480
neither one knows what the others

858
00:35:19,650 --> 00:35:24,450
and they're only seeing the data that

859
00:35:21,480 --> 00:35:29,999
they're entitled to see so you combine

860
00:35:24,450 --> 00:35:33,480
those two trains of Technology

861
00:35:29,999 --> 00:35:35,519
deployment development evolution and now

862
00:35:33,480 --> 00:35:37,769
you have the promise potentially of

863
00:35:35,519 --> 00:35:40,019
storing data once in the cloud and using

864
00:35:37,769 --> 00:35:43,470
it for multiple purposes including

865
00:35:40,019 --> 00:35:47,819
consumer purposes with lots of different

866
00:35:43,470 --> 00:35:50,910
entities it's still relatively new but

867
00:35:47,819 --> 00:35:54,990
this is a perfect example of where HIPAA

868
00:35:50,910 --> 00:35:57,118
gives us guidance today that says if you

869
00:35:54,990 --> 00:35:59,939
D identify the data you can share it

870
00:35:57,119 --> 00:36:02,009
with multiple entities all right let's

871
00:35:59,940 --> 00:36:05,279
just assume that one of those entities

872
00:36:02,009 --> 00:36:08,430
that you share it with has a wealth of

873
00:36:05,279 --> 00:36:11,309
consumer data at their disposal and a

874
00:36:08,430 --> 00:36:14,549
number of data scientists with pretty

875
00:36:11,309 --> 00:36:17,849
decent tools at their disposal what that

876
00:36:14,549 --> 00:36:19,710
means is you share de-identified data it

877
00:36:17,849 --> 00:36:22,890
doesn't know that part of the data

878
00:36:19,710 --> 00:36:25,650
element says Jim you know in that and

879
00:36:22,890 --> 00:36:28,589
you share that with the the entity and

880
00:36:25,650 --> 00:36:31,200
they can identify it very easily using

881
00:36:28,589 --> 00:36:34,259
the data science techniques and the data

882
00:36:31,200 --> 00:36:36,989
that they already have the from a HIPAA

883
00:36:34,259 --> 00:36:39,989
perspective this is cool this is okay

884
00:36:36,989 --> 00:36:43,079
this is this is compliant from a risk

885
00:36:39,989 --> 00:36:45,239
standpoint not so much right and by the

886
00:36:43,079 --> 00:36:48,749
way there is no answer for this from a

887
00:36:45,239 --> 00:36:50,700
compliance standpoint and I think you

888
00:36:48,749 --> 00:36:55,109
pointed out what was it George you

889
00:36:50,700 --> 00:36:58,379
pointed out HIPAA started in 1996 right

890
00:36:55,109 --> 00:37:00,210
took a long time right to iterate so the

891
00:36:58,380 --> 00:37:02,670
legislative process around healthcare is

892
00:37:00,210 --> 00:37:04,380
that an efficient process don't answer

893
00:37:02,670 --> 00:37:06,559
that that's a rhetorical question right

894
00:37:04,380 --> 00:37:09,720
so it's gonna be a long time before

895
00:37:06,559 --> 00:37:13,079
regulations solve for this so we as

896
00:37:09,720 --> 00:37:15,450
practitioners have to use risk and our

897
00:37:13,079 --> 00:37:17,940
concepts of risk to solve for this and

898
00:37:15,450 --> 00:37:20,879
that means designing controls that don't

899
00:37:17,940 --> 00:37:23,029
necessarily exist today to be able to

900
00:37:20,880 --> 00:37:26,539
solve this problem because technology

901
00:37:23,029 --> 00:37:26,539
marches ahead

902
00:37:27,439 --> 00:37:31,499
anyone else want to say something or

903
00:37:29,880 --> 00:37:34,160
should we take in another question I

904
00:37:31,499 --> 00:37:41,519
think we should go ahead

905
00:37:34,160 --> 00:37:44,399
so as working for a DoD contractor I see

906
00:37:41,519 --> 00:37:47,069
a lot of similarities between you know

907
00:37:44,400 --> 00:37:51,150
what I'm hearing here and what what we

908
00:37:47,069 --> 00:37:53,579
face as well I mean you know there's no

909
00:37:51,150 --> 00:37:55,199
profit in cybersecurity right it's

910
00:37:53,579 --> 00:37:58,319
you're protecting against something

911
00:37:55,199 --> 00:38:04,529
you're hoping to limit a future event

912
00:37:58,319 --> 00:38:07,199
that may happen so it's difficult to

913
00:38:04,529 --> 00:38:09,709
sell right and we're all up against the

914
00:38:07,199 --> 00:38:12,509
same problems that that George described

915
00:38:09,709 --> 00:38:15,419
limited you know limited resources to a

916
00:38:12,509 --> 00:38:17,400
task the tsunami that's hitting us right

917
00:38:15,420 --> 00:38:20,519
so but and Jim

918
00:38:17,400 --> 00:38:23,130
so you described essentially what is

919
00:38:20,519 --> 00:38:26,129
what we use in DoD the risk management

920
00:38:23,130 --> 00:38:28,249
framework is what you used right but and

921
00:38:26,130 --> 00:38:32,999
and we're getting further away from

922
00:38:28,249 --> 00:38:37,169
being able to usefully apply that to get

923
00:38:32,999 --> 00:38:39,029
resilience right so but what what and I

924
00:38:37,170 --> 00:38:41,910
think you just started to describe what

925
00:38:39,029 --> 00:38:43,739
my question is what what's the next

926
00:38:41,910 --> 00:38:49,979
steps what are the next steps to narrow

927
00:38:43,739 --> 00:38:52,739
that gap or to start to you know reduce

928
00:38:49,979 --> 00:38:54,598
the risk yeah so the genie is out of the

929
00:38:52,739 --> 00:38:57,329
bottle we're not gonna narrow it that's

930
00:38:54,599 --> 00:38:59,789
not in the cards but there is hope

931
00:38:57,329 --> 00:39:03,809
because there actually is profit in

932
00:38:59,789 --> 00:39:05,789
cybersecurity there unique examples but

933
00:39:03,809 --> 00:39:10,979
but it is there so for example I

934
00:39:05,789 --> 00:39:12,809
implemented something called D Kim and

935
00:39:10,979 --> 00:39:16,169
SPF you're probably all familiar with

936
00:39:12,809 --> 00:39:17,819
and D mark is the standard does anybody

937
00:39:16,170 --> 00:39:20,819
from a day so we're talking about email

938
00:39:17,819 --> 00:39:24,359
so basically trusted email D mark

939
00:39:20,819 --> 00:39:26,819
basically prevents any entity from

940
00:39:24,359 --> 00:39:28,890
spoofing a domain which used to be a

941
00:39:26,819 --> 00:39:32,819
common technique for phishing attacks

942
00:39:28,890 --> 00:39:35,969
and in my case I implemented it about

943
00:39:32,819 --> 00:39:37,210
40% of our e mail volume dropped most of

944
00:39:35,969 --> 00:39:40,359
it coming from

945
00:39:37,210 --> 00:39:41,789
Russia and Eastern Europe and the volume

946
00:39:40,359 --> 00:39:44,460
that dropped was basically

947
00:39:41,789 --> 00:39:49,089
pharmaceutical spammers that were

948
00:39:44,460 --> 00:39:51,730
selling you know products to our members

949
00:39:49,089 --> 00:39:55,569
through email and so when we dropped all

950
00:39:51,730 --> 00:39:57,970
that traffic the click-through rate on

951
00:39:55,569 --> 00:40:02,349
our email campaigns and about two

952
00:39:57,970 --> 00:40:04,480
billion emails a year went up 10% every

953
00:40:02,349 --> 00:40:07,240
year and this has been going on for last

954
00:40:04,480 --> 00:40:10,390
four years so what that means is our

955
00:40:07,240 --> 00:40:12,160
email campaigns are driving people to

956
00:40:10,390 --> 00:40:15,038
have healthier behaviors and that drives

957
00:40:12,160 --> 00:40:17,589
profit to the company so we put a

958
00:40:15,039 --> 00:40:19,329
security control in place and it

959
00:40:17,589 --> 00:40:21,730
increased profit for their company so

960
00:40:19,329 --> 00:40:23,890
that's one example of profit can drive

961
00:40:21,730 --> 00:40:27,339
there are other examples for if any

962
00:40:23,890 --> 00:40:29,230
large enterprise build software and

963
00:40:27,339 --> 00:40:32,170
spend a lot of money to build software

964
00:40:29,230 --> 00:40:34,329
if you build software and get somewhere

965
00:40:32,170 --> 00:40:36,250
between 20 and 30 percent improvement in

966
00:40:34,329 --> 00:40:38,319
productivity in the development hours

967
00:40:36,250 --> 00:40:40,809
and building the software well then you

968
00:40:38,319 --> 00:40:43,000
build software at a lower cost so that

969
00:40:40,809 --> 00:40:44,920
also will drive profit you can also take

970
00:40:43,000 --> 00:40:46,779
the productivity gain and invested a new

971
00:40:44,920 --> 00:40:48,880
functionality or capability that also

972
00:40:46,779 --> 00:40:51,910
drives profit so from an economic

973
00:40:48,880 --> 00:40:53,770
standpoint never try to sell software

974
00:40:51,910 --> 00:40:55,149
security because it's lower risk

975
00:40:53,770 --> 00:40:57,190
that's that you'll never win that

976
00:40:55,150 --> 00:41:00,130
argument because it's there's no way to

977
00:40:57,190 --> 00:41:02,770
attribute defects and software security

978
00:41:00,130 --> 00:41:04,869
to an enterprise because the consumers

979
00:41:02,770 --> 00:41:07,630
that get hosed when they browse a

980
00:41:04,869 --> 00:41:11,380
website and get infected with malware

981
00:41:07,630 --> 00:41:13,630
that's on the software you know in terms

982
00:41:11,380 --> 00:41:15,490
of the vulnerability they never know

983
00:41:13,630 --> 00:41:17,260
that it's your website that it does they

984
00:41:15,490 --> 00:41:18,910
find out six months later when the fraud

985
00:41:17,260 --> 00:41:20,829
hits if no I there's no attribution

986
00:41:18,910 --> 00:41:23,618
whatsoever so there's no incentive for

987
00:41:20,829 --> 00:41:26,980
an enterprise to have quality software

988
00:41:23,619 --> 00:41:29,770
but there is economic incentive in terms

989
00:41:26,980 --> 00:41:31,869
of improving your productivity for

990
00:41:29,770 --> 00:41:34,140
building a software and harvesting that

991
00:41:31,869 --> 00:41:36,940
benefit any way you wish but that's

992
00:41:34,140 --> 00:41:42,279
economic dollars and cents so in most

993
00:41:36,940 --> 00:41:44,799
security cases it actually there's an

994
00:41:42,279 --> 00:41:47,650
economic argument to implementing

995
00:41:44,799 --> 00:41:49,870
security controls the variable is you

996
00:41:47,650 --> 00:41:52,620
have to look at the total cost of IT Oh

997
00:41:49,870 --> 00:41:55,089
and total cost includes the patching and

998
00:41:52,620 --> 00:41:56,890
vulnerability management which is often

999
00:41:55,090 --> 00:41:58,960
not captured anywhere on a balance sheet

1000
00:41:56,890 --> 00:42:02,440
for any enterprise but that's actually

1001
00:41:58,960 --> 00:42:05,460
where the value is so if you look at the

1002
00:42:02,440 --> 00:42:08,650
total cost of IT ownership I can

1003
00:42:05,460 --> 00:42:10,570
influence and I and I've said this

1004
00:42:08,650 --> 00:42:12,520
publicly I'll say it again I have no

1005
00:42:10,570 --> 00:42:15,460
problem getting money for cybersecurity

1006
00:42:12,520 --> 00:42:17,470
I never have I get as much money as I

1007
00:42:15,460 --> 00:42:19,480
want for whatever programs and projects

1008
00:42:17,470 --> 00:42:21,669
that I want I know that sounds like

1009
00:42:19,480 --> 00:42:23,650
that's counter to conventional wisdom

1010
00:42:21,670 --> 00:42:26,320
I'm telling I've worked for big

1011
00:42:23,650 --> 00:42:29,410
companies I never have problem because I

1012
00:42:26,320 --> 00:42:31,450
used the economic benefits now there are

1013
00:42:29,410 --> 00:42:34,149
some security things that it's difficult

1014
00:42:31,450 --> 00:42:36,939
to do that I grant you that but the

1015
00:42:34,150 --> 00:42:41,200
majority 70% of information security

1016
00:42:36,940 --> 00:42:43,210
controls are in the delivery of IT so if

1017
00:42:41,200 --> 00:42:45,819
you change and alter the delivery of IT

1018
00:42:43,210 --> 00:42:48,160
to be more effective and most

1019
00:42:45,820 --> 00:42:50,890
enterprises that are large spend a lot

1020
00:42:48,160 --> 00:42:53,680
of money on IT and that's cost savings

1021
00:42:50,890 --> 00:42:55,810
that you can use to invest so the

1022
00:42:53,680 --> 00:42:58,089
economics and the profit motive actually

1023
00:42:55,810 --> 00:42:59,980
is alive and well you have to be a

1024
00:42:58,090 --> 00:43:02,350
little bit more creative on how you do

1025
00:42:59,980 --> 00:43:05,800
it but that's what I do and I encourage

1026
00:43:02,350 --> 00:43:07,990
everyone to do that does that help yeah

1027
00:43:05,800 --> 00:43:09,550
I can't agree more I mean I think you

1028
00:43:07,990 --> 00:43:13,270
have to have that a little bit of

1029
00:43:09,550 --> 00:43:15,670
business acumen to help deliver help the

1030
00:43:13,270 --> 00:43:19,090
biz the business understand what that

1031
00:43:15,670 --> 00:43:21,100
risk is but how taking an approach is

1032
00:43:19,090 --> 00:43:24,400
going to help bring some money back to

1033
00:43:21,100 --> 00:43:26,049
the table for them and I'd say what I

1034
00:43:24,400 --> 00:43:28,030
try to do a lot of times I'm looking for

1035
00:43:26,050 --> 00:43:29,500
opportunities the reality is we have and

1036
00:43:28,030 --> 00:43:32,200
this or I think it comes in to risk

1037
00:43:29,500 --> 00:43:34,930
management we have more problems than we

1038
00:43:32,200 --> 00:43:36,609
can solve on any given day but I try to

1039
00:43:34,930 --> 00:43:39,250
match like what are our biggest risks

1040
00:43:36,610 --> 00:43:41,050
with where do I see where we can move a

1041
00:43:39,250 --> 00:43:43,630
business process forward so your example

1042
00:43:41,050 --> 00:43:45,490
making things more efficient a lot of

1043
00:43:43,630 --> 00:43:46,870
the big terms that you'll hear today in

1044
00:43:45,490 --> 00:43:49,839
agile but met with continuous

1045
00:43:46,870 --> 00:43:51,580
integration hey you should implement to

1046
00:43:49,840 --> 00:43:53,020
compute continuous integration in your

1047
00:43:51,580 --> 00:43:54,910
software dolmen process and by the way

1048
00:43:53,020 --> 00:43:56,470
when you do that I'm gonna plug in all

1049
00:43:54,910 --> 00:43:57,879
these security tools and the developers

1050
00:43:56,470 --> 00:44:01,770
can't move to the next phase until they

1051
00:43:57,880 --> 00:44:03,640
close things out you start to show them

1052
00:44:01,770 --> 00:44:05,050
advantages in

1053
00:44:03,640 --> 00:44:07,080
but at the same time you're getting

1054
00:44:05,050 --> 00:44:09,250
controls built in there and everyone is

1055
00:44:07,080 --> 00:44:11,890
coming out better on the other side so

1056
00:44:09,250 --> 00:44:14,530
there is a savviness I think to get

1057
00:44:11,890 --> 00:44:16,240
security done well so I think it is

1058
00:44:14,530 --> 00:44:18,849
getting hard because you can't just say

1059
00:44:16,240 --> 00:44:21,549
hey this is an awful problem we have to

1060
00:44:18,849 --> 00:44:23,710
solve it that's not gonna ever get you

1061
00:44:21,550 --> 00:44:26,470
funding or very rarely unless it's just

1062
00:44:23,710 --> 00:44:30,880
obvious so I would just emphasize that I

1063
00:44:26,470 --> 00:44:32,290
think that's really important the one

1064
00:44:30,880 --> 00:44:34,170
thing that I would add to that again

1065
00:44:32,290 --> 00:44:38,230
sort of from the perspective somebody's

1066
00:44:34,170 --> 00:44:40,680
building technology is I think even

1067
00:44:38,230 --> 00:44:45,880
those that security can often be an

1068
00:44:40,680 --> 00:44:48,910
enabler for you know new usage models or

1069
00:44:45,880 --> 00:44:50,830
new use cases right for example if one

1070
00:44:48,910 --> 00:44:52,960
were to solve the security problem of

1071
00:44:50,830 --> 00:44:54,400
you know how do I securely you know sort

1072
00:44:52,960 --> 00:44:56,590
of bootstrap and medical the implantable

1073
00:44:54,400 --> 00:44:59,020
medical device from my own smartphone it

1074
00:44:56,590 --> 00:45:00,940
that could and you know I think that

1075
00:44:59,020 --> 00:45:03,400
potentially drives a very powerful

1076
00:45:00,940 --> 00:45:05,260
message that it now enables users

1077
00:45:03,400 --> 00:45:07,300
potential users to keep track of their

1078
00:45:05,260 --> 00:45:09,280
own implantable medical devices and

1079
00:45:07,300 --> 00:45:11,650
their status and their operation of

1080
00:45:09,280 --> 00:45:13,720
those in real time and that could

1081
00:45:11,650 --> 00:45:14,830
potentially drive up adoption rates

1082
00:45:13,720 --> 00:45:16,209
right or people are using these

1083
00:45:14,830 --> 00:45:18,819
technologies so security I think could

1084
00:45:16,210 --> 00:45:20,680
also play the role of an enabler sort of

1085
00:45:18,820 --> 00:45:21,970
indirectly driving the economic side but

1086
00:45:20,680 --> 00:45:28,149
I do agree with them that it is the

1087
00:45:21,970 --> 00:45:30,098
economics which which which now can you

1088
00:45:28,150 --> 00:45:31,800
continue that discussion yeah cyber

1089
00:45:30,099 --> 00:45:34,690
security can be a competitive advantage

1090
00:45:31,800 --> 00:45:37,839
but it has to be linked to reimbursement

1091
00:45:34,690 --> 00:45:40,750
I tell medicine we can do a lot

1092
00:45:37,839 --> 00:45:43,119
serving disparate populations of sick

1093
00:45:40,750 --> 00:45:45,820
people with telemedicine but if

1094
00:45:43,119 --> 00:45:48,310
providers can't be reimbursed for that

1095
00:45:45,820 --> 00:45:50,380
encounter they're not going to invest in

1096
00:45:48,310 --> 00:45:52,509
new proper cybersecurity to protect that

1097
00:45:50,380 --> 00:45:55,750
telemedicine session all right so it

1098
00:45:52,510 --> 00:45:58,980
goes back to again if it can't generate

1099
00:45:55,750 --> 00:46:01,570
revenue the the smaller medium-sized

1100
00:45:58,980 --> 00:46:04,050
delivery system is not gonna be able to

1101
00:46:01,570 --> 00:46:04,050
invest in it

1102
00:46:06,330 --> 00:46:10,840
hey thanks follow y'all for coming I had

1103
00:46:09,340 --> 00:46:12,460
a kind of a broad question in a more

1104
00:46:10,840 --> 00:46:14,020
context was it a question the broader

1105
00:46:12,460 --> 00:46:16,120
one being I've worked in health care a

1106
00:46:14,020 --> 00:46:17,170
number of years myself and seeing a lot

1107
00:46:16,120 --> 00:46:19,420
of the problems that a lot of you

1108
00:46:17,170 --> 00:46:21,250
discussed like even in some of the

1109
00:46:19,420 --> 00:46:23,230
bigger hospitals that implement more

1110
00:46:21,250 --> 00:46:25,390
security protocols like a doctor has to

1111
00:46:23,230 --> 00:46:26,620
have their token on them they usually

1112
00:46:25,390 --> 00:46:28,600
leave it on their badge but then they

1113
00:46:26,620 --> 00:46:31,420
say hey nurse I need this file go get

1114
00:46:28,600 --> 00:46:33,759
that for me and then or a nurse may

1115
00:46:31,420 --> 00:46:35,560
leave their their token i they leave on

1116
00:46:33,760 --> 00:46:37,000
their badge at the nursing station which

1117
00:46:35,560 --> 00:46:38,170
is open and you could just reach over

1118
00:46:37,000 --> 00:46:40,630
the counter and grab it if you really

1119
00:46:38,170 --> 00:46:41,920
wanted to a number of other ones being

1120
00:46:40,630 --> 00:46:43,660
like the monitor and a doctor's office

1121
00:46:41,920 --> 00:46:44,890
face in the window you could very easily

1122
00:46:43,660 --> 00:46:47,350
look at personal health care information

1123
00:46:44,890 --> 00:46:50,920
it's like with all of these types of

1124
00:46:47,350 --> 00:46:52,600
little examples one of the panel's

1125
00:46:50,920 --> 00:46:56,050
thoughts on solutions potentially being

1126
00:46:52,600 --> 00:46:57,970
do we want to focus on training our

1127
00:46:56,050 --> 00:47:01,680
current healthcare personnel giving them

1128
00:46:57,970 --> 00:47:04,569
another workload of learn a new you know

1129
00:47:01,680 --> 00:47:05,890
privacy protocol trying to implement it

1130
00:47:04,570 --> 00:47:08,800
into what you already known you've done

1131
00:47:05,890 --> 00:47:11,589
for 30 years or do we want to focus more

1132
00:47:08,800 --> 00:47:13,720
on having the new blood and

1133
00:47:11,590 --> 00:47:16,270
cybersecurity have a more focused

1134
00:47:13,720 --> 00:47:17,500
context-specific view of healthcare or

1135
00:47:16,270 --> 00:47:20,880
whatever vertical they're gonna work in

1136
00:47:17,500 --> 00:47:23,290
like oil manufacturing or something yes

1137
00:47:20,880 --> 00:47:25,930
it's either/or is what you're suggesting

1138
00:47:23,290 --> 00:47:27,850
there's our possible solutions but

1139
00:47:25,930 --> 00:47:30,490
together those sound couple things first

1140
00:47:27,850 --> 00:47:32,200
of all if we could just get rid of all

1141
00:47:30,490 --> 00:47:37,299
the people in healthcare security be

1142
00:47:32,200 --> 00:47:41,350
fine no problem flawless okay that's not

1143
00:47:37,300 --> 00:47:44,380
likely so maybe we ought to be training

1144
00:47:41,350 --> 00:47:45,520
or teaching people a little bit more

1145
00:47:44,380 --> 00:47:49,120
effectively in terms of security

1146
00:47:45,520 --> 00:47:51,220
awareness but what we've done

1147
00:47:49,120 --> 00:47:53,799
historically for less a couple of

1148
00:47:51,220 --> 00:47:57,490
decades is we teach people of the risks

1149
00:47:53,800 --> 00:48:00,130
of cybersecurity it's it's totally

1150
00:47:57,490 --> 00:48:02,200
insufficient first of all today most

1151
00:48:00,130 --> 00:48:05,950
media outlets do a better job of it than

1152
00:48:02,200 --> 00:48:07,750
any enterprise or provider would do just

1153
00:48:05,950 --> 00:48:09,370
read the paper I mean there's always

1154
00:48:07,750 --> 00:48:11,200
that you can't pick up a paper today

1155
00:48:09,370 --> 00:48:13,359
without reading about cybersecurity it's

1156
00:48:11,200 --> 00:48:13,779
in mainstream today it's made it if you

1157
00:48:13,360 --> 00:48:16,780
will

1158
00:48:13,780 --> 00:48:17,580
what's not in there is focus on the

1159
00:48:16,780 --> 00:48:19,380
technique

1160
00:48:17,580 --> 00:48:23,130
that you as a consumer need to

1161
00:48:19,380 --> 00:48:25,380
understand that as a professional and as

1162
00:48:23,130 --> 00:48:27,900
a individual as a you know in terms of

1163
00:48:25,380 --> 00:48:29,910
your personal needs and there's kind of

1164
00:48:27,900 --> 00:48:32,420
a blending in terms of you know

1165
00:48:29,910 --> 00:48:34,859
smartphones that cross the gamut there

1166
00:48:32,420 --> 00:48:38,340
but we have to teach people how to be

1167
00:48:34,860 --> 00:48:39,510
better consumers and here's and and what

1168
00:48:38,340 --> 00:48:44,120
does that mean here here's a couple

1169
00:48:39,510 --> 00:48:49,500
examples if you use a digital platform

1170
00:48:44,120 --> 00:48:53,400
that you don't pay for it means someone

1171
00:48:49,500 --> 00:48:56,520
else is paying for it so you're not the

1172
00:48:53,400 --> 00:48:59,040
consumer even though you are made to

1173
00:48:56,520 --> 00:49:00,630
feel like you're the consumer for Gmail

1174
00:48:59,040 --> 00:49:04,460
as an example

1175
00:49:00,630 --> 00:49:07,920
who's the consumer or who's the buyer

1176
00:49:04,460 --> 00:49:09,990
the buyer who's funding that is funding

1177
00:49:07,920 --> 00:49:13,530
that because of the information you

1178
00:49:09,990 --> 00:49:16,649
provide into the system you're not the

1179
00:49:13,530 --> 00:49:20,070
consumer the digital consumer you're the

1180
00:49:16,650 --> 00:49:23,070
product or more specifically information

1181
00:49:20,070 --> 00:49:26,670
about you is the product and therefore

1182
00:49:23,070 --> 00:49:30,000
you're the product manager so if you

1183
00:49:26,670 --> 00:49:32,580
think about being the product manager

1184
00:49:30,000 --> 00:49:35,340
you've got a fighting chance for making

1185
00:49:32,580 --> 00:49:38,069
decisions on which platforms to use if

1186
00:49:35,340 --> 00:49:40,740
you're paying a lot of money for a

1187
00:49:38,070 --> 00:49:44,010
platform I'm just using an Apple iPhone

1188
00:49:40,740 --> 00:49:46,799
as an icon here because I think it's a

1189
00:49:44,010 --> 00:49:48,720
lot of money and if I use iCloud to back

1190
00:49:46,800 --> 00:49:51,390
that up there's a lot of money that I'm

1191
00:49:48,720 --> 00:49:54,089
spending for that but your information

1192
00:49:51,390 --> 00:49:56,490
is much better protected because you're

1193
00:49:54,090 --> 00:49:58,320
the actual consumer but when you use a

1194
00:49:56,490 --> 00:50:01,529
digital platform that somebody else is

1195
00:49:58,320 --> 00:50:03,330
paying for and you're the product and so

1196
00:50:01,530 --> 00:50:05,580
you've got to act like a product manager

1197
00:50:03,330 --> 00:50:08,310
which is deciding what the trade-off

1198
00:50:05,580 --> 00:50:10,860
value to use an individual is to give up

1199
00:50:08,310 --> 00:50:12,210
your information and and if you think

1200
00:50:10,860 --> 00:50:16,500
about giving up your information in that

1201
00:50:12,210 --> 00:50:18,360
context you've got a fighting chance how

1202
00:50:16,500 --> 00:50:21,510
to be a digital consumer and have some

1203
00:50:18,360 --> 00:50:23,790
level of protection in what you do but

1204
00:50:21,510 --> 00:50:27,950
that is anybody hear that message I mean

1205
00:50:23,790 --> 00:50:27,950
you know unfortunately because

1206
00:50:28,829 --> 00:50:32,759
platform owners aren't telling us this

1207
00:50:30,509 --> 00:50:35,999
because yeah a pretty good game going

1208
00:50:32,759 --> 00:50:38,009
right now right so it's up to us to

1209
00:50:35,999 --> 00:50:40,200
figure this out yeah the way the way we

1210
00:50:38,009 --> 00:50:41,729
think about it a lot is in the way I've

1211
00:50:40,200 --> 00:50:44,549
I've thought about it for a number of

1212
00:50:41,729 --> 00:50:46,259
years is you've got to teach users how

1213
00:50:44,549 --> 00:50:50,160
to know when they're walking down a dark

1214
00:50:46,259 --> 00:50:52,619
alley because no amount of controls are

1215
00:50:50,160 --> 00:50:54,839
ever gonna stop that intuitive sense of

1216
00:50:52,619 --> 00:50:57,029
something's not right here I need to

1217
00:50:54,839 --> 00:50:59,160
slow down and pay attention and have my

1218
00:50:57,029 --> 00:51:01,859
guard up right telling a user that there

1219
00:50:59,160 --> 00:51:04,709
are dark alleys insufficient yeah

1220
00:51:01,859 --> 00:51:06,900
telling a user how to walk down a dark

1221
00:51:04,709 --> 00:51:08,940
say how to choose at which one yeah

1222
00:51:06,900 --> 00:51:11,729
right so so that's where we focus a lot

1223
00:51:08,940 --> 00:51:13,319
of our efforts but I agree totally you

1224
00:51:11,729 --> 00:51:16,200
you've got also make these things easier

1225
00:51:13,319 --> 00:51:18,569
for them make it easier to see the dark

1226
00:51:16,200 --> 00:51:20,129
alley you know even things like tagging

1227
00:51:18,569 --> 00:51:22,440
email in a certain way when we think

1228
00:51:20,130 --> 00:51:23,969
it's suspicious just a you know and

1229
00:51:22,440 --> 00:51:26,069
obviously getting a lot of that out with

1230
00:51:23,969 --> 00:51:27,539
you mark and things like that is you've

1231
00:51:26,069 --> 00:51:29,249
got to take the workload off the user

1232
00:51:27,539 --> 00:51:33,209
because there everyone's trying to get

1233
00:51:29,249 --> 00:51:40,468
their jobs done and yeah it's got to be

1234
00:51:33,209 --> 00:51:42,029
both unfortunately sure more consequence

1235
00:51:40,469 --> 00:51:43,650
if aquestion with the advent of like

1236
00:51:42,029 --> 00:51:45,719
wearable health technologies like the

1237
00:51:43,650 --> 00:51:48,619
artificial pancreas like even more

1238
00:51:45,719 --> 00:51:52,199
simple insulin pumps that have a lot of

1239
00:51:48,619 --> 00:51:55,109
sensitive personal healthcare data the

1240
00:51:52,199 --> 00:51:57,779
move and from a security view will that

1241
00:51:55,109 --> 00:51:59,578
may be a solution to securing that data

1242
00:51:57,779 --> 00:52:02,190
would be maybe encryption in the device

1243
00:51:59,579 --> 00:52:04,469
or having some secure means of storing

1244
00:52:02,190 --> 00:52:06,150
it at a hospital but then that could

1245
00:52:04,469 --> 00:52:07,829
potentially get into the area of do we

1246
00:52:06,150 --> 00:52:09,150
want to open data centers and hospitals

1247
00:52:07,829 --> 00:52:11,339
huge data centers where they're already

1248
00:52:09,150 --> 00:52:13,109
having a lot of funding issues the way

1249
00:52:11,339 --> 00:52:15,538
with the way it is and then we need to

1250
00:52:13,109 --> 00:52:17,160
potentially hire more personnel to with

1251
00:52:15,539 --> 00:52:19,140
the cybersecurity focus to manage those

1252
00:52:17,160 --> 00:52:22,259
data centers like well what kind of

1253
00:52:19,140 --> 00:52:23,368
ideas yeah I'll start first of all I

1254
00:52:22,259 --> 00:52:25,559
think this is where I was saying I think

1255
00:52:23,369 --> 00:52:26,940
the FDA is doing a pretty good job they

1256
00:52:25,559 --> 00:52:29,729
have a draft guidance out there they got

1257
00:52:26,940 --> 00:52:30,809
released in October and if there was any

1258
00:52:29,729 --> 00:52:34,279
doubt of whether or not you're supposed

1259
00:52:30,809 --> 00:52:37,109
to encrypt data at rest it's it's gone

1260
00:52:34,279 --> 00:52:38,699
they you know not only do they say that

1261
00:52:37,109 --> 00:52:41,799
do that kind of thing I mean they talk

1262
00:52:38,699 --> 00:52:45,010
about cryptographically verify

1263
00:52:41,800 --> 00:52:46,360
the software that's running you know on

1264
00:52:45,010 --> 00:52:49,480
the device and things like that

1265
00:52:46,360 --> 00:52:51,490
so I really applauded them for it's not

1266
00:52:49,480 --> 00:52:52,990
a checklist and there's some there's

1267
00:52:51,490 --> 00:52:54,669
some work to do as a draft guidance

1268
00:52:52,990 --> 00:52:58,859
that's gonna that's getting reworked

1269
00:52:54,670 --> 00:53:00,970
right now but I feel like you know

1270
00:52:58,860 --> 00:53:03,190
there's no doubt all these devices are

1271
00:53:00,970 --> 00:53:06,189
gonna have to solve these problems but

1272
00:53:03,190 --> 00:53:07,720
just like vijay mentioned it is

1273
00:53:06,190 --> 00:53:09,670
difficult though because if some of the

1274
00:53:07,720 --> 00:53:11,020
you know we want a device that's gonna

1275
00:53:09,670 --> 00:53:12,880
operate for a week without recharging

1276
00:53:11,020 --> 00:53:15,280
how many people's phones operate for a

1277
00:53:12,880 --> 00:53:17,260
week without recharging right but you

1278
00:53:15,280 --> 00:53:19,390
don't want to have to recharge your you

1279
00:53:17,260 --> 00:53:21,000
know hey I'm I'm going away for three

1280
00:53:19,390 --> 00:53:23,710
days I gotta remember to charge my

1281
00:53:21,000 --> 00:53:27,520
insulin pump I mean you know we've got

1282
00:53:23,710 --> 00:53:30,880
to come up with ways to manage the cost

1283
00:53:27,520 --> 00:53:33,430
not just money but computation and

1284
00:53:30,880 --> 00:53:36,610
things like that on these and then as

1285
00:53:33,430 --> 00:53:37,839
far as that you know the integration of

1286
00:53:36,610 --> 00:53:39,790
all these environments is definitely

1287
00:53:37,840 --> 00:53:41,140
gonna main interesting area like as it

1288
00:53:39,790 --> 00:53:42,910
comes up I definitely don't think

1289
00:53:41,140 --> 00:53:45,759
anyone's gonna expect a hospital

1290
00:53:42,910 --> 00:53:48,850
provider to fill data centers that's

1291
00:53:45,760 --> 00:53:50,620
that's not going to happen but I think

1292
00:53:48,850 --> 00:53:52,779
you're gonna see data start to get

1293
00:53:50,620 --> 00:53:55,630
layered like where there's like the

1294
00:53:52,780 --> 00:53:56,920
primary EHR system but then there's hey

1295
00:53:55,630 --> 00:53:58,270
there you use this type of device and so

1296
00:53:56,920 --> 00:54:00,550
I can go get all the details of that and

1297
00:53:58,270 --> 00:54:05,230
it's stored somewhere else and and it'll

1298
00:54:00,550 --> 00:54:08,320
get abstracted from the physician but we

1299
00:54:05,230 --> 00:54:10,480
can't expect like if we're generating it

1300
00:54:08,320 --> 00:54:13,000
can't get by at a data per hour per user

1301
00:54:10,480 --> 00:54:15,940
that a hospital's gonna be able to you

1302
00:54:13,000 --> 00:54:17,080
know take in all that data like so

1303
00:54:15,940 --> 00:54:19,390
there's gonna have to be really strong

1304
00:54:17,080 --> 00:54:22,090
integration and strategy on how to do

1305
00:54:19,390 --> 00:54:24,310
that to go back to Jim's comment I think

1306
00:54:22,090 --> 00:54:25,810
in a scenario like that will be the

1307
00:54:24,310 --> 00:54:28,060
product the patient would be the product

1308
00:54:25,810 --> 00:54:31,299
the device manufacturers will be

1309
00:54:28,060 --> 00:54:34,540
identify the data and write it so if my

1310
00:54:31,300 --> 00:54:37,690
device gave me a boost of insulin right

1311
00:54:34,540 --> 00:54:40,990
it knows it knows what my body was doing

1312
00:54:37,690 --> 00:54:42,910
prior during and after treatment right

1313
00:54:40,990 --> 00:54:46,149
that data can inform researchers make

1314
00:54:42,910 --> 00:54:48,970
the device better all policy issues a

1315
00:54:46,150 --> 00:54:51,190
privacy issues aside right so I don't

1316
00:54:48,970 --> 00:54:52,750
think it'll be the delivery system the

1317
00:54:51,190 --> 00:54:54,960
healthcare provider have any manage that

1318
00:54:52,750 --> 00:54:54,960
data

1319
00:54:55,030 --> 00:54:59,470
someone will if I could tell you or

1320
00:54:58,120 --> 00:55:02,770
trend that's driving a lot of us right

1321
00:54:59,470 --> 00:55:07,870
now that I think is really good is it's

1322
00:55:02,770 --> 00:55:09,970
the outcome based payment so a lot of

1323
00:55:07,870 --> 00:55:12,940
you know you hear even in the media or

1324
00:55:09,970 --> 00:55:14,680
big insulin manufacturer price of

1325
00:55:12,940 --> 00:55:18,760
insulin is a big topic even in Congress

1326
00:55:14,680 --> 00:55:22,240
right now and all that there is a drive

1327
00:55:18,760 --> 00:55:25,360
to a model where outcome will be what

1328
00:55:22,240 --> 00:55:27,430
pays so if someone's glue if someone's

1329
00:55:25,360 --> 00:55:31,870
blood trader is managed in range you get

1330
00:55:27,430 --> 00:55:33,790
paid this this amount if it's not you

1331
00:55:31,870 --> 00:55:36,810
basically maybe get covered just for the

1332
00:55:33,790 --> 00:55:40,060
cost of the product but no profit right

1333
00:55:36,810 --> 00:55:41,380
that that that's starting to shift in

1334
00:55:40,060 --> 00:55:43,480
the background but we need a lot of

1335
00:55:41,380 --> 00:55:46,330
these data systems in order to actually

1336
00:55:43,480 --> 00:55:47,890
show that so to me that's a really

1337
00:55:46,330 --> 00:55:49,950
exciting trend but we still have a lot

1338
00:55:47,890 --> 00:55:52,210
of work to do but I'm hoping that that

1339
00:55:49,950 --> 00:55:55,390
so hopefully it's just a little bit from

1340
00:55:52,210 --> 00:55:57,070
the product but it just it does the

1341
00:55:55,390 --> 00:55:58,960
motivations become still like hey we're

1342
00:55:57,070 --> 00:56:00,370
getting good outcomes and we have the

1343
00:55:58,960 --> 00:56:02,260
data we need to do that and that's

1344
00:56:00,370 --> 00:56:05,700
actually what's funding a lot of the the

1345
00:56:02,260 --> 00:56:05,700
research and keeping things up to speed

1346
00:56:06,060 --> 00:56:11,110
my 15 second ending to that will just be

1347
00:56:09,160 --> 00:56:12,990
that when you're talking about a lot of

1348
00:56:11,110 --> 00:56:17,410
these devices you know variable device I

1349
00:56:12,990 --> 00:56:19,330
think security ends up being a whole lot

1350
00:56:17,410 --> 00:56:22,060
more than just cryptography and the data

1351
00:56:19,330 --> 00:56:24,670
because the security the attack model or

1352
00:56:22,060 --> 00:56:26,920
the attack surface is just so broad and

1353
00:56:24,670 --> 00:56:28,870
so diverse right I don't have to do I

1354
00:56:26,920 --> 00:56:30,670
don't even need need your data right i

1355
00:56:28,870 --> 00:56:34,259
but all I need to do is to just drain

1356
00:56:30,670 --> 00:56:37,540
the battery on your system that does not

1357
00:56:34,260 --> 00:56:39,190
need me to actually even read a single

1358
00:56:37,540 --> 00:56:40,450
piece of information from you I can just

1359
00:56:39,190 --> 00:56:42,670
keep transmitting the error to you and

1360
00:56:40,450 --> 00:56:45,609
just keep keep your radio on and let you

1361
00:56:42,670 --> 00:56:47,920
burn your battery out right so a lot of

1362
00:56:45,610 --> 00:56:49,570
the security attacks can be you know

1363
00:56:47,920 --> 00:56:51,130
sort of non cryptographic and stuff and

1364
00:56:49,570 --> 00:56:53,680
so the solutions also will have to be I

1365
00:56:51,130 --> 00:56:54,910
think so uniquely tailored and

1366
00:56:53,680 --> 00:56:58,839
out-of-the-box to address some of these

1367
00:56:54,910 --> 00:57:01,830
unconventional non cyber security

1368
00:56:58,840 --> 00:57:04,330
attacks perhaps okay thanks

1369
00:57:01,830 --> 00:57:06,100
let's take one more question so we have

1370
00:57:04,330 --> 00:57:08,170
time for a short break before the final

1371
00:57:06,100 --> 00:57:08,828
session okay so going back to this

1372
00:57:08,170 --> 00:57:11,079
problem

1373
00:57:08,829 --> 00:57:12,789
like the wearable devices so what do you

1374
00:57:11,079 --> 00:57:14,529
think about the issue of you send these

1375
00:57:12,789 --> 00:57:16,239
devices out and there's of like a

1376
00:57:14,529 --> 00:57:18,219
vulnerability found in these and some of

1377
00:57:16,239 --> 00:57:19,569
these systems may be very hard to pass

1378
00:57:18,219 --> 00:57:21,039
like the user might not know what

1379
00:57:19,569 --> 00:57:22,450
they're doing or like pretty much

1380
00:57:21,039 --> 00:57:23,829
impossible with like an artificial

1381
00:57:22,450 --> 00:57:26,169
pancreas where it's literally in your

1382
00:57:23,829 --> 00:57:27,249
body so it's really hard to like pageant

1383
00:57:26,170 --> 00:57:28,390
so what do you what do you think about

1384
00:57:27,249 --> 00:57:31,899
that issue how do you think we're gonna

1385
00:57:28,390 --> 00:57:33,700
solve that issue going forward well you

1386
00:57:31,900 --> 00:57:37,119
say it's hard it doesn't mean we have

1387
00:57:33,700 --> 00:57:38,499
the option not to do it I've I was gonna

1388
00:57:37,119 --> 00:57:40,089
give the example earlier about how you

1389
00:57:38,499 --> 00:57:41,828
get security controls worked in and

1390
00:57:40,089 --> 00:57:44,499
every time I brought up how are we gonna

1391
00:57:41,829 --> 00:57:46,930
update this out in the field everyone

1392
00:57:44,499 --> 00:57:48,788
looked at me like we can't do that but I

1393
00:57:46,930 --> 00:57:52,029
managed to tie it to other priorities

1394
00:57:48,789 --> 00:57:53,680
that we had for the program like

1395
00:57:52,029 --> 00:57:58,599
updating our algorithms that run on it

1396
00:57:53,680 --> 00:58:00,399
safely and things like that and all of a

1397
00:57:58,599 --> 00:58:03,759
sudden it became they saw that was the

1398
00:58:00,400 --> 00:58:07,119
solution and it totally got funded and

1399
00:58:03,759 --> 00:58:09,039
supported and taken through I do think

1400
00:58:07,119 --> 00:58:10,900
there will be devices it's going to

1401
00:58:09,039 --> 00:58:15,400
depend on the safety impact some devices

1402
00:58:10,900 --> 00:58:16,930
won't be updated and that there's still

1403
00:58:15,400 --> 00:58:19,059
gonna be an interesting problem in that

1404
00:58:16,930 --> 00:58:20,589
space but we're gonna have to I mean if

1405
00:58:19,059 --> 00:58:22,239
you look at the FDA guidance and their

1406
00:58:20,589 --> 00:58:24,279
expectations you have to be able to

1407
00:58:22,239 --> 00:58:25,809
update these devices in the field that

1408
00:58:24,279 --> 00:58:28,420
isn't it's not going to get through FDA

1409
00:58:25,809 --> 00:58:30,160
approval coming into the future without

1410
00:58:28,420 --> 00:58:31,809
that capability

1411
00:58:30,160 --> 00:58:35,140
and that you've done it well which kind

1412
00:58:31,809 --> 00:58:36,969
of makes sense cuz it's software we

1413
00:58:35,140 --> 00:58:40,180
foolin software it's never perfect

1414
00:58:36,969 --> 00:58:42,789
they're never I software always has to

1415
00:58:40,180 --> 00:58:45,038
be patched so if we're putting software

1416
00:58:42,789 --> 00:58:47,589
in devices hey you got a patch it that's

1417
00:58:45,039 --> 00:58:49,660
you know because some vulnerabilities we

1418
00:58:47,589 --> 00:58:51,880
discovered years after the software's

1419
00:58:49,660 --> 00:58:53,828
release absolutely you got to be able to

1420
00:58:51,880 --> 00:58:56,319
patch it I mean that's the way software

1421
00:58:53,829 --> 00:58:58,599
works I think it works that way with

1422
00:58:56,319 --> 00:59:00,099
planes now I think that the West Coast

1423
00:58:58,599 --> 00:59:03,369
companies wrestling with that set right

1424
00:59:00,099 --> 00:59:04,509
now software update right I think

1425
00:59:03,369 --> 00:59:06,489
there's no question that we'll have to

1426
00:59:04,509 --> 00:59:08,799
update these devices what scares me is

1427
00:59:06,489 --> 00:59:11,229
how right so these devices are gonna be

1428
00:59:08,799 --> 00:59:13,779
in you or on you so how are they gonna

1429
00:59:11,229 --> 00:59:15,669
be updated Bluetooth personal device

1430
00:59:13,779 --> 00:59:17,949
will it be a dedicated device that comes

1431
00:59:15,670 --> 00:59:19,420
coupled with the device not likely right

1432
00:59:17,949 --> 00:59:20,709
because that increases the expense

1433
00:59:19,420 --> 00:59:21,200
they're going to use a device that you

1434
00:59:20,709 --> 00:59:23,808
already

1435
00:59:21,200 --> 00:59:27,140
in your possession right so you're going

1436
00:59:23,809 --> 00:59:28,970
to make a very sensitive very trusted

1437
00:59:27,140 --> 00:59:31,549
transaction to update your pacemaker on

1438
00:59:28,970 --> 00:59:35,000
an Android device that's five years old

1439
00:59:31,549 --> 00:59:36,920
way behind on its updates and patches do

1440
00:59:35,000 --> 00:59:38,420
you trust that device you trust your

1441
00:59:36,920 --> 00:59:40,940
pacemaker because maybe it's been

1442
00:59:38,420 --> 00:59:42,890
verified cryptographically and and with

1443
00:59:40,940 --> 00:59:44,660
formal methods but you trust the Android

1444
00:59:42,890 --> 00:59:47,270
device that you're using to communicate

1445
00:59:44,660 --> 00:59:49,190
with your pacemaker right so consumers

1446
00:59:47,270 --> 00:59:50,599
probably gonna know but but certainly

1447
00:59:49,190 --> 00:59:52,760
device manufacturers will have to take

1448
00:59:50,599 --> 00:59:57,140
those ecosystems and mine when they're

1449
00:59:52,760 --> 01:00:00,740
developing these patch routines for a

1450
00:59:57,140 --> 01:00:02,480
recall yeah and I think again from my

1451
01:00:00,740 --> 01:00:03,799
vantage point this is a really

1452
01:00:02,480 --> 01:00:05,869
interesting space from a research

1453
01:00:03,799 --> 01:00:07,759
perspective right and you know so for

1454
01:00:05,869 --> 01:00:09,799
example some of my students are looking

1455
01:00:07,760 --> 01:00:12,170
at specifically something that George

1456
01:00:09,799 --> 01:00:14,180
you just mentioned which is you know how

1457
01:00:12,170 --> 01:00:15,740
do I interact with an implantable device

1458
01:00:14,180 --> 01:00:18,020
from an external device that I don't

1459
01:00:15,740 --> 01:00:21,140
trust you know perhaps there's a health

1460
01:00:18,020 --> 01:00:22,220
server that I trust but if in order to

1461
01:00:21,140 --> 01:00:23,569
get to that health server I need to go

1462
01:00:22,220 --> 01:00:25,879
through this Android device which is

1463
01:00:23,569 --> 01:00:27,079
five years old and unpatch and is there

1464
01:00:25,880 --> 01:00:29,329
some way that I can actually talk

1465
01:00:27,079 --> 01:00:32,900
without trusting this intermediate party

1466
01:00:29,329 --> 01:00:35,049
right that's a really interesting you

1467
01:00:32,900 --> 01:00:36,950
know sort of research question and

1468
01:00:35,049 --> 01:00:41,059
hopefully something that we can get a

1469
01:00:36,950 --> 01:00:44,799
handle on very soon hey do you have a

1470
01:00:41,059 --> 01:00:47,380
short question or a short answer

1471
01:00:44,799 --> 01:00:51,859
so it's interesting what you said about

1472
01:00:47,380 --> 01:00:53,480
how to sell security how about selling

1473
01:00:51,859 --> 01:00:56,390
it from the standpoint of resilience

1474
01:00:53,480 --> 01:01:00,170
some availability so we know that every

1475
01:00:56,390 --> 01:01:02,210
system will be hacked you know you can't

1476
01:01:00,170 --> 01:01:04,960
prevent it eventually it will be hacked

1477
01:01:02,210 --> 01:01:07,790
but how about building in some

1478
01:01:04,960 --> 01:01:09,380
redundancy so that the system hack

1479
01:01:07,790 --> 01:01:14,599
system will continue to operate and

1480
01:01:09,380 --> 01:01:18,410
deliver it that may be another angle may

1481
01:01:14,599 --> 01:01:20,240
be easier to get itself well yeah all

1482
01:01:18,410 --> 01:01:22,848
those all those failure modes will have

1483
01:01:20,240 --> 01:01:25,790
to be looked at yeah sometimes it's

1484
01:01:22,849 --> 01:01:30,140
redundancy sometimes it's failing to a

1485
01:01:25,790 --> 01:01:32,569
safe state a lot of that is is

1486
01:01:30,140 --> 01:01:34,520
definitely considered a movie expected

1487
01:01:32,569 --> 01:01:36,140
there's not really this is

1488
01:01:34,520 --> 01:01:38,360
where the risk management gets really

1489
01:01:36,140 --> 01:01:39,859
important is there's no there's no list

1490
01:01:38,360 --> 01:01:41,300
that's gonna make it right for the

1491
01:01:39,860 --> 01:01:43,460
device that you're working on like this

1492
01:01:41,300 --> 01:01:45,140
you have to really do a lot of and the

1493
01:01:43,460 --> 01:01:47,630
FDA is again push this a lot of threat

1494
01:01:45,140 --> 01:01:49,549
modeling to understand what your attack

1495
01:01:47,630 --> 01:01:53,210
surfaces are and how you respond to

1496
01:01:49,550 --> 01:01:55,580
those and how you fail safely there's

1497
01:01:53,210 --> 01:01:57,950
not a really simple answer that we need

1498
01:01:55,580 --> 01:01:59,540
more research in this face for sure I do

1499
01:01:57,950 --> 01:02:01,160
agree I think the availability angle is

1500
01:01:59,540 --> 01:02:02,720
sort of could potentially be a

1501
01:02:01,160 --> 01:02:05,390
differentiator right you know you're

1502
01:02:02,720 --> 01:02:07,040
gonna be offering a better you know sort

1503
01:02:05,390 --> 01:02:08,299
of SLA or service level agreement or

1504
01:02:07,040 --> 01:02:10,759
somebody saying that your systems gonna

1505
01:02:08,300 --> 01:02:13,870
be up so with a higher percentage of

1506
01:02:10,760 --> 01:02:16,760
time that could potentially be a yeah

1507
01:02:13,870 --> 01:02:23,630
I've made a pair of pacemakers in you

1508
01:02:16,760 --> 01:02:23,900
know heart I mean yes something like

1509
01:02:23,630 --> 01:02:25,400
that

1510
01:02:23,900 --> 01:02:28,550
I'll take a slightly pessimistic

1511
01:02:25,400 --> 01:02:32,540
approach resiliency and redundancy is

1512
01:02:28,550 --> 01:02:35,510
absolutely key but in your lower

1513
01:02:32,540 --> 01:02:37,790
maturity organizations right when a

1514
01:02:35,510 --> 01:02:40,460
system fails open or fails over to a

1515
01:02:37,790 --> 01:02:42,259
redundant node they don't have the

1516
01:02:40,460 --> 01:02:44,990
monitoring place to know that it

1517
01:02:42,260 --> 01:02:46,700
switched over so from a incident or a

1518
01:02:44,990 --> 01:02:49,100
compromised detection mode sometimes

1519
01:02:46,700 --> 01:02:51,290
that hard failure although it's it's

1520
01:02:49,100 --> 01:02:54,200
hard to deal with is is there indicator

1521
01:02:51,290 --> 01:02:55,970
that something bad has happened let's

1522
01:02:54,200 --> 01:02:58,720
call someone who can fix this

1523
01:02:55,970 --> 01:03:01,100
so certainly an implantable devices

1524
01:02:58,720 --> 01:03:04,220
resiliency and redundancy is absolutely

1525
01:03:01,100 --> 01:03:05,569
key because you failure is not an option

1526
01:03:04,220 --> 01:03:09,910
right great

1527
01:03:05,570 --> 01:03:12,530
but with traditional networked systems I

1528
01:03:09,910 --> 01:03:16,670
for anything smaller than like a six

1529
01:03:12,530 --> 01:03:22,070
hundred employee health system it would

1530
01:03:16,670 --> 01:03:26,620
be problematic okay thanks well let's

1531
01:03:22,070 --> 01:03:26,620
thank our panel for a lively discussion

1532
01:03:27,040 --> 01:03:29,100
you

1533
01:03:35,350 --> 01:03:37,410
you

