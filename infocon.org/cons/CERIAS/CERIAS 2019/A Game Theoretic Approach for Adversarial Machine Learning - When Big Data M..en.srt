1
00:00:03,980 --> 00:00:08,570
this afternoon it's my pleasure to

2
00:00:06,290 --> 00:00:11,000
introduce our speaker today professor

3
00:00:08,570 --> 00:00:12,710
Bowie she is an associate professor of

4
00:00:11,000 --> 00:00:14,900
statistics here at Purdue University

5
00:00:12,710 --> 00:00:17,600
she's been on campus since 2004 I

6
00:00:14,900 --> 00:00:19,070
believe and even though she did receive

7
00:00:17,600 --> 00:00:21,470
her degrees from the University of

8
00:00:19,070 --> 00:00:24,440
Michigan we still we still enjoy having

9
00:00:21,470 --> 00:00:28,450
her here on campus at Purdue so I think

10
00:00:24,440 --> 00:00:31,100
that it's kind of unusual to think about

11
00:00:28,450 --> 00:00:33,589
statistics when you talk about cyber

12
00:00:31,100 --> 00:00:35,690
security although math is at the heart

13
00:00:33,590 --> 00:00:37,160
of it and and what I really like about

14
00:00:35,690 --> 00:00:39,440
her topic it's something that we're

15
00:00:37,160 --> 00:00:41,660
gonna hear more and more of is is it's

16
00:00:39,440 --> 00:00:44,420
she's taken a game theory approach to

17
00:00:41,660 --> 00:00:46,099
looking at and machine learning so she's

18
00:00:44,420 --> 00:00:48,200
combining two very hot topics into her

19
00:00:46,100 --> 00:00:50,560
security presentation today so with that

20
00:00:48,200 --> 00:00:53,120
I'll turn it over to Professor she

21
00:00:50,560 --> 00:00:55,250
actually thank you for a very nice

22
00:00:53,120 --> 00:00:58,849
introduction and documentation for the

23
00:00:55,250 --> 00:01:02,390
talk so the work I presented here is a

24
00:00:58,850 --> 00:01:04,909
summary of several papers I wrote with

25
00:01:02,390 --> 00:01:09,499
my students and collaborators from

26
00:01:04,909 --> 00:01:11,770
Dallas so we all know there were

27
00:01:09,499 --> 00:01:15,079
malicious attacks in cyber security

28
00:01:11,770 --> 00:01:18,499
while there in our network intruders and

29
00:01:15,079 --> 00:01:21,199
spam emails is another example spammers

30
00:01:18,499 --> 00:01:23,749
constantly rewrite of spam email and

31
00:01:21,200 --> 00:01:26,389
spam filter which serves as classifier

32
00:01:23,749 --> 00:01:28,939
cannot label them quietly and very

33
00:01:26,389 --> 00:01:30,380
recently this received were lots of

34
00:01:28,939 --> 00:01:33,380
miscibility rather because of

35
00:01:30,380 --> 00:01:36,109
differently so deep learning pace system

36
00:01:33,380 --> 00:01:39,408
are very sensitive to manually input

37
00:01:36,109 --> 00:01:41,719
perturbations so one famous example is

38
00:01:39,409 --> 00:01:43,819
the stocks an example ray they try to

39
00:01:41,719 --> 00:01:46,068
put her of your Snickers on a stop sign

40
00:01:43,819 --> 00:01:49,340
and then stop Sam will be Miss Casswell

41
00:01:46,069 --> 00:01:50,869
speed limit isn't well that even has a

42
00:01:49,340 --> 00:01:53,719
different background color

43
00:01:50,869 --> 00:01:56,869
another example is rather physical you

44
00:01:53,719 --> 00:02:00,020
attack or attacking physical layers so

45
00:01:56,869 --> 00:02:02,659
it's called offing attack well Nick is

46
00:02:00,020 --> 00:02:05,929
an ultrasonic commands which is

47
00:02:02,659 --> 00:02:07,880
inaudible to human but these auto Sonia

48
00:02:05,929 --> 00:02:10,399
commands can control almost all the

49
00:02:07,880 --> 00:02:13,250
speech recognition system by targeting

50
00:02:10,399 --> 00:02:16,810
on the hardware and it can even control

51
00:02:13,250 --> 00:02:16,810
the navigation system of a card

52
00:02:19,620 --> 00:02:25,930
well there were several mission Minh

53
00:02:22,120 --> 00:02:28,180
Minh is talking about handling data

54
00:02:25,930 --> 00:02:31,180
points that has unusual properties

55
00:02:28,180 --> 00:02:33,519
so from cybersecurity and from computer

56
00:02:31,180 --> 00:02:36,099
vision we actually see two classes

57
00:02:33,519 --> 00:02:38,560
offered or service samples why certain

58
00:02:36,099 --> 00:02:41,200
samples that's very similar to the

59
00:02:38,560 --> 00:02:43,840
standard normal samples but cannot

60
00:02:41,200 --> 00:02:45,339
recognize another classes are those so

61
00:02:43,840 --> 00:02:47,760
examples I mean I have very different

62
00:02:45,340 --> 00:02:50,349
properties they follow different

63
00:02:47,760 --> 00:02:53,920
distributions compared with the Thai

64
00:02:50,349 --> 00:02:55,780
sample then while standard machine

65
00:02:53,920 --> 00:02:59,260
learning techniques cannot handle this

66
00:02:55,780 --> 00:03:01,599
daughter with other service ampuls well

67
00:02:59,260 --> 00:03:05,560
we need a whole new class of machining

68
00:03:01,599 --> 00:03:19,120
techniques that can well do is go solar

69
00:03:05,560 --> 00:03:21,750
tax properly or somehow okay so there's

70
00:03:19,120 --> 00:03:24,250
another topic is artificial intelligence

71
00:03:21,750 --> 00:03:26,590
artificial intelligences you are the

72
00:03:24,250 --> 00:03:29,109
Browder it is not more limited with

73
00:03:26,590 --> 00:03:32,829
machining but direct knowledge official

74
00:03:29,109 --> 00:03:36,000
intelligence also it's forward-thinking

75
00:03:32,829 --> 00:03:39,370
just try to improve the capacity

76
00:03:36,000 --> 00:03:42,040
increased accuracy and it needs a do a

77
00:03:39,370 --> 00:03:44,200
thorough machining capacity so it needs

78
00:03:42,040 --> 00:03:48,370
to be able to handle well malicious

79
00:03:44,200 --> 00:03:51,310
instances and still act properly and Kim

80
00:03:48,370 --> 00:03:53,609
theory actually offers a very useful to

81
00:03:51,310 --> 00:03:56,949
to model the interaction between

82
00:03:53,609 --> 00:04:01,180
attackers and defenders and here we

83
00:03:56,949 --> 00:04:03,660
assume a defender is a menu system and

84
00:04:01,180 --> 00:04:08,709
we could have multiple workers

85
00:04:03,660 --> 00:04:10,599
well my past work actually address while

86
00:04:08,709 --> 00:04:14,530
supervising an inner door cero

87
00:04:10,599 --> 00:04:17,320
environment unsurprisingly and active

88
00:04:14,530 --> 00:04:20,760
learning algorithms facing activated

89
00:04:17,320 --> 00:04:24,010
verses and as for deep learning we shall

90
00:04:20,760 --> 00:04:26,560
use randomized decision boundary for

91
00:04:24,010 --> 00:04:29,539
tyranny models that will be able to

92
00:04:26,560 --> 00:04:39,650
break transferability of dorsal samples

93
00:04:29,540 --> 00:04:43,340
and classified instances properly so the

94
00:04:39,650 --> 00:04:46,580
first work reuses crucial game to acero

95
00:04:43,340 --> 00:04:49,369
stackable came to model interaction so

96
00:04:46,580 --> 00:04:51,530
you know the Asaro stackable game what

97
00:04:49,370 --> 00:04:54,170
one player will make the first move and

98
00:04:51,530 --> 00:04:56,840
after observing the first players action

99
00:04:54,170 --> 00:05:00,230
the second player will choose his

100
00:04:56,840 --> 00:05:02,060
strategy and in this crucial game every

101
00:05:00,230 --> 00:05:04,760
player can have their own utility

102
00:05:02,060 --> 00:05:07,370
function and they try to maximize their

103
00:05:04,760 --> 00:05:09,409
own payoff so it's different from the

104
00:05:07,370 --> 00:05:12,140
zero-sum game in through some game while

105
00:05:09,410 --> 00:05:15,560
one player skin is another players loss

106
00:05:12,140 --> 00:05:17,900
but in the sequential game I often

107
00:05:15,560 --> 00:05:19,610
receive questions about well who should

108
00:05:17,900 --> 00:05:23,150
be the leader in the game we have

109
00:05:19,610 --> 00:05:27,050
defender we have multiple vs. well in

110
00:05:23,150 --> 00:05:29,539
the well one business school their

111
00:05:27,050 --> 00:05:31,820
status your staff who came the

112
00:05:29,540 --> 00:05:34,100
conclusion is the leader hazard voltage

113
00:05:31,820 --> 00:05:36,050
in the game say the largest company

114
00:05:34,100 --> 00:05:38,930
being the meeting the game beside the

115
00:05:36,050 --> 00:05:43,520
price for product then they'd received

116
00:05:38,930 --> 00:05:46,070
the largest profit here well in the

117
00:05:43,520 --> 00:05:47,690
Asaro game while we'll compare two

118
00:05:46,070 --> 00:05:50,420
differents narrows two different games

119
00:05:47,690 --> 00:05:54,550
why is relighted defender to be the

120
00:05:50,420 --> 00:05:57,140
meeting the game and other the worst

121
00:05:54,550 --> 00:05:58,490
adversary's become the follower then

122
00:05:57,140 --> 00:06:01,640
this is a one liter

123
00:05:58,490 --> 00:06:03,320
I'm follower game another scenario is we

124
00:06:01,640 --> 00:06:05,810
like to defend their be the follower in

125
00:06:03,320 --> 00:06:09,280
the game and they're the worst fears are

126
00:06:05,810 --> 00:06:12,110
the leaders so out of the workers there

127
00:06:09,280 --> 00:06:14,510
well move then defender will choose a

128
00:06:12,110 --> 00:06:17,120
defensive strategy then this is I'm

129
00:06:14,510 --> 00:06:19,099
needed well follower game well the Kim

130
00:06:17,120 --> 00:06:21,740
said hub actually is a complex

131
00:06:19,100 --> 00:06:24,680
optimization problem so we are searching

132
00:06:21,740 --> 00:06:28,280
for the you crib room solutions in two

133
00:06:24,680 --> 00:06:32,770
different scenarios the details are in a

134
00:06:28,280 --> 00:06:32,770
preprint papers countdown the review

135
00:06:40,510 --> 00:06:46,370
well in the game setup but we also may

136
00:06:43,880 --> 00:06:50,600
first need to define the strategies for

137
00:06:46,370 --> 00:06:53,240
each player and defender strategy is to

138
00:06:50,600 --> 00:06:55,850
draw defensive walk along the center of

139
00:06:53,240 --> 00:06:57,320
the normal population so the size of the

140
00:06:55,850 --> 00:06:59,000
defensive wall is controlled by a

141
00:06:57,320 --> 00:07:01,610
parameter between 0 & 1

142
00:06:59,000 --> 00:07:04,460
well we can imagine this defensive voice

143
00:07:01,610 --> 00:07:06,680
comparable to a confidence region we

144
00:07:04,460 --> 00:07:09,620
used to draw in the multivariate normal

145
00:07:06,680 --> 00:07:12,350
population so the parameter / is

146
00:07:09,620 --> 00:07:13,250
comparable to a confidence level in the

147
00:07:12,350 --> 00:07:17,960
normal population

148
00:07:13,250 --> 00:07:20,420
an attacker strategy well attacker

149
00:07:17,960 --> 00:07:22,549
strategy is to move the objects under

150
00:07:20,420 --> 00:07:25,790
their control toward the center of the

151
00:07:22,550 --> 00:07:27,650
normal population and attacker strategy

152
00:07:25,790 --> 00:07:31,400
is also controlled by a parameter

153
00:07:27,650 --> 00:07:33,859
between 7 1 0 means were no more stay at

154
00:07:31,400 --> 00:07:37,340
the original opposition then 1 means

155
00:07:33,860 --> 00:07:41,120
more you know I the center of the normal

156
00:07:37,340 --> 00:07:43,700
the strategy space for both players are

157
00:07:41,120 --> 00:07:46,730
other players abounded between 0 & 1

158
00:07:43,700 --> 00:07:50,360
and next in the game we need to define

159
00:07:46,730 --> 00:07:53,500
each players payoff attackers payoff at

160
00:07:50,360 --> 00:07:56,180
the expected value of the utilities

161
00:07:53,500 --> 00:07:58,900
generated by other samples that

162
00:07:56,180 --> 00:08:01,960
successfully evade detection and

163
00:07:58,900 --> 00:08:08,900
defenders payoff is negative 1 times

164
00:08:01,960 --> 00:08:11,930
misclassification cost so to solve for

165
00:08:08,900 --> 00:08:14,270
the equilibrium while in a multiple

166
00:08:11,930 --> 00:08:17,870
folder multiple leader game is a very

167
00:08:14,270 --> 00:08:21,320
complex optimization problem solving for

168
00:08:17,870 --> 00:08:24,200
the setup point and you are set up

169
00:08:21,320 --> 00:08:27,469
because well the strategy space is

170
00:08:24,200 --> 00:08:31,610
bounded so we actually do an exhaustive

171
00:08:27,470 --> 00:08:34,670
search and well here are the two

172
00:08:31,610 --> 00:08:36,740
equivalent strategies on the left this

173
00:08:34,669 --> 00:08:40,459
world defender is the me during the game

174
00:08:36,740 --> 00:08:43,010
and defenders equilibrium strategy it's

175
00:08:40,460 --> 00:08:47,600
a small right circle around the blue

176
00:08:43,010 --> 00:08:49,130
points and attackers new equilibrium

177
00:08:47,600 --> 00:08:52,670
strategy or the black

178
00:08:49,130 --> 00:08:55,250
once that's on the boundary of the

179
00:08:52,670 --> 00:08:57,979
normal population so honest proud

180
00:08:55,250 --> 00:09:01,340
grievance green points are the original

181
00:08:57,980 --> 00:09:04,700
attack objects black points are the new

182
00:09:01,340 --> 00:09:05,750
attack objects and blue points are the

183
00:09:04,700 --> 00:09:08,240
normal points

184
00:09:05,750 --> 00:09:11,600
no more population position we assume

185
00:09:08,240 --> 00:09:13,640
that doesn't change and the right panel

186
00:09:11,600 --> 00:09:15,550
shows the equilibrium strategy when

187
00:09:13,640 --> 00:09:18,860
defender is the follower in the game

188
00:09:15,550 --> 00:09:20,870
well the red circle is larger it's a

189
00:09:18,860 --> 00:09:23,450
more relaxed strategy and we can see

190
00:09:20,870 --> 00:09:26,900
more blue points monomer points are

191
00:09:23,450 --> 00:09:28,820
properly classified and well one

192
00:09:26,900 --> 00:09:30,860
defender is the following the game we

193
00:09:28,820 --> 00:09:34,520
see the black points but not very

194
00:09:30,860 --> 00:09:35,840
aggressive so they're away from even the

195
00:09:34,520 --> 00:09:38,990
boundary points are for the normal

196
00:09:35,840 --> 00:09:41,750
population so comparing this to game

197
00:09:38,990 --> 00:09:44,540
setup we basically see one defender is

198
00:09:41,750 --> 00:09:46,250
the following in the game well defender

199
00:09:44,540 --> 00:09:49,490
has advantage in the reserved

200
00:09:46,250 --> 00:09:51,410
environment so when defenders the

201
00:09:49,490 --> 00:09:54,310
follower defender has an advantage to

202
00:09:51,410 --> 00:09:57,050
observe all the adversary's moves and

203
00:09:54,310 --> 00:09:59,540
well it were sure is not aware of the

204
00:09:57,050 --> 00:10:02,229
existence of the defensive strategy they

205
00:09:59,540 --> 00:10:05,449
make nice aggressive attacks and

206
00:10:02,230 --> 00:10:07,670
defender is able to draw a more relaxed

207
00:10:05,450 --> 00:10:10,220
the same boundary to have more new more

208
00:10:07,670 --> 00:10:10,849
points properly classified and on the

209
00:10:10,220 --> 00:10:12,680
other hand

210
00:10:10,850 --> 00:10:15,040
well if defenders the media defend the

211
00:10:12,680 --> 00:10:18,109
first needs to decide on that assembly

212
00:10:15,040 --> 00:10:21,349
deceptive ensive strategy say the spam

213
00:10:18,110 --> 00:10:22,100
filter needs to say more conservative

214
00:10:21,350 --> 00:10:25,100
strategy

215
00:10:22,100 --> 00:10:28,250
block out you know many no more points

216
00:10:25,100 --> 00:10:30,440
and observing the existence of such a

217
00:10:28,250 --> 00:10:31,520
defensive strategy or the worthless

218
00:10:30,440 --> 00:10:34,300
while

219
00:10:31,520 --> 00:10:37,280
tends to launch more aggressive attacks

220
00:10:34,300 --> 00:10:42,939
so these conclusions very different from

221
00:10:37,280 --> 00:10:42,939
the business studies well

222
00:10:44,860 --> 00:10:53,000
and next whoa we'll just do a server

223
00:10:48,980 --> 00:10:55,280
landing I'm surprised environment so we

224
00:10:53,000 --> 00:10:57,170
observe order cell samples mostly from

225
00:10:55,280 --> 00:10:59,540
to develop occasional men while

226
00:10:57,170 --> 00:11:02,300
cybersecurity another is computer vision

227
00:10:59,540 --> 00:11:04,280
and but we serve samples in these two

228
00:11:02,300 --> 00:11:07,359
different in cyber security and computer

229
00:11:04,280 --> 00:11:11,329
variants have very different properties

230
00:11:07,360 --> 00:11:14,360
well in cybersecurity well first of all

231
00:11:11,330 --> 00:11:17,090
we may not have many labeled data points

232
00:11:14,360 --> 00:11:20,030
when there's a new attack say a new

233
00:11:17,090 --> 00:11:21,980
malware or a new in the completely new

234
00:11:20,030 --> 00:11:25,550
attack we may not have the luxury to

235
00:11:21,980 --> 00:11:28,190
label the new attack objects or women

236
00:11:25,550 --> 00:11:31,370
you know have completely unlabeled

237
00:11:28,190 --> 00:11:35,060
either search say for anomaly detection

238
00:11:31,370 --> 00:11:39,380
technique then we still need to be able

239
00:11:35,060 --> 00:11:42,079
to have robust many algorithms that can

240
00:11:39,380 --> 00:11:45,350
endure the worst behavior from large

241
00:11:42,080 --> 00:11:47,330
amount of unlabeled samples and we

242
00:11:45,350 --> 00:11:49,490
noticed also samples in cybersecurity

243
00:11:47,330 --> 00:11:51,440
they can certain have very different

244
00:11:49,490 --> 00:11:55,420
distribution are very different property

245
00:11:51,440 --> 00:11:57,680
from the standard training samples and

246
00:11:55,420 --> 00:12:00,800
to attack our supervised learning

247
00:11:57,680 --> 00:12:03,709
technique or anomaly detection technique

248
00:12:00,800 --> 00:12:06,490
while adversary's just needs to fill in

249
00:12:03,710 --> 00:12:10,220
the gap place a few objects between

250
00:12:06,490 --> 00:12:14,060
previously well separated clusters the

251
00:12:10,220 --> 00:12:18,220
multiple separate cluster can be connect

252
00:12:14,060 --> 00:12:21,709
together into a large mix cluster and

253
00:12:18,220 --> 00:12:25,970
currently while the work hung or saralyn

254
00:12:21,710 --> 00:12:27,680
mostly focus on a classification task so

255
00:12:25,970 --> 00:12:30,080
they assume there's a large member of

256
00:12:27,680 --> 00:12:31,459
labeled data points in computer vision

257
00:12:30,080 --> 00:12:34,460
this is easy

258
00:12:31,460 --> 00:12:38,020
images afraid but in cybersecurity it

259
00:12:34,460 --> 00:12:38,020
may not be a realistic assumption

260
00:12:41,480 --> 00:12:53,210
okay like me so our algorithm color to

261
00:12:48,050 --> 00:12:56,839
multiple well objectives so we first

262
00:12:53,210 --> 00:12:59,390
will try to identify the sub-clusters no

263
00:12:56,840 --> 00:13:03,530
more subclass or abnormal subclass sir

264
00:12:59,390 --> 00:13:06,110
instead large mixed clusters and next

265
00:13:03,530 --> 00:13:08,540
our algorithm will not label all the

266
00:13:06,110 --> 00:13:11,240
unlabeled data points so this is

267
00:13:08,540 --> 00:13:13,160
different from semi surprisingly well in

268
00:13:11,240 --> 00:13:15,260
semi surprising ending it assumes

269
00:13:13,160 --> 00:13:18,230
there's a hundreds of labeled points and

270
00:13:15,260 --> 00:13:20,510
a large number of unlabeled point now it

271
00:13:18,230 --> 00:13:23,000
gradually try to identify the most

272
00:13:20,510 --> 00:13:25,130
accurate classification boundary which

273
00:13:23,000 --> 00:13:28,220
you know achieve the highest accuracy on

274
00:13:25,130 --> 00:13:33,220
all the unlabeled data points and for

275
00:13:28,220 --> 00:13:37,430
our algorithm well we we will well

276
00:13:33,220 --> 00:13:40,880
preserve unlabeled regions between

277
00:13:37,430 --> 00:13:43,370
normal and abnormal subclasses those

278
00:13:40,880 --> 00:13:47,150
only would regions it's comparable to

279
00:13:43,370 --> 00:13:49,010
confidence regions and compared with the

280
00:13:47,150 --> 00:13:50,449
classification boundary classification

281
00:13:49,010 --> 00:13:53,510
boundary chemicals idea as a point

282
00:13:50,450 --> 00:13:55,640
estimate so given very small number of

283
00:13:53,510 --> 00:13:57,740
label data point well this point

284
00:13:55,640 --> 00:14:01,310
estimate is not accurate even through a

285
00:13:57,740 --> 00:14:04,850
semi surprise enemy and using well save

286
00:14:01,310 --> 00:14:06,680
the unlabeled confidence region and try

287
00:14:04,850 --> 00:14:09,440
to identify high confidence

288
00:14:06,680 --> 00:14:12,859
no more regions will be a mall while

289
00:14:09,440 --> 00:14:16,310
appropriate approach and at the same

290
00:14:12,860 --> 00:14:19,850
time we also identify outliers outliers

291
00:14:16,310 --> 00:14:22,130
as potential nominees and our idea to

292
00:14:19,850 --> 00:14:25,910
identify the high confidence regions is

293
00:14:22,130 --> 00:14:29,030
that large mix Craster well we can

294
00:14:25,910 --> 00:14:31,819
imagine is comparable to airports kruky

295
00:14:29,030 --> 00:14:34,760
so in airport secrete here only a small

296
00:14:31,820 --> 00:14:36,470
name of passengers will go through while

297
00:14:34,760 --> 00:14:38,660
the fast protected

298
00:14:36,470 --> 00:14:41,300
most of the passengers will go through

299
00:14:38,660 --> 00:14:43,520
the time consuming security check but so

300
00:14:41,300 --> 00:14:48,790
far for the passenger name of use all

301
00:14:43,520 --> 00:14:50,960
the passengers are no more passengers so

302
00:14:48,790 --> 00:14:53,660
basically you know doors are learning

303
00:14:50,960 --> 00:14:55,650
hanging objects outside of the high

304
00:14:53,660 --> 00:14:58,439
confidence region needs to go to

305
00:14:55,650 --> 00:15:01,319
well second day of screening this will

306
00:14:58,440 --> 00:15:10,830
pre one well order were so samples to

307
00:15:01,320 --> 00:15:13,830
enter the high confidence region so our

308
00:15:10,830 --> 00:15:18,180
algorithm actually have to well we need

309
00:15:13,830 --> 00:15:20,339
to take two parts of the data well on

310
00:15:18,180 --> 00:15:22,770
the Proud on the left panel while the

311
00:15:20,339 --> 00:15:24,900
orange points are the urban no more data

312
00:15:22,770 --> 00:15:28,589
points blue points at the no more data

313
00:15:24,900 --> 00:15:31,470
points so we see three clusters together

314
00:15:28,589 --> 00:15:34,490
in your former large one large mix

315
00:15:31,470 --> 00:15:37,200
cluster if we don't you know have any

316
00:15:34,490 --> 00:15:39,839
additional information just use a

317
00:15:37,200 --> 00:15:41,820
standard clustering algorithm let's what

318
00:15:39,839 --> 00:15:45,140
across your algorithm will retain a

319
00:15:41,820 --> 00:15:48,500
large you know mix cluster unable

320
00:15:45,140 --> 00:15:52,140
newscaster and for our out reason well

321
00:15:48,500 --> 00:15:54,900
we assume there's a handful of labeled

322
00:15:52,140 --> 00:16:00,779
seeds could be just half a percent of

323
00:15:54,900 --> 00:16:03,600
the well dataset then using the labeled

324
00:16:00,779 --> 00:16:06,089
seeds we first compute the probability

325
00:16:03,600 --> 00:16:08,670
densities of the data point so it's a

326
00:16:06,089 --> 00:16:12,209
grid based algorithm in QuickBase

327
00:16:08,670 --> 00:16:15,120
algorithm while future space are divided

328
00:16:12,209 --> 00:16:17,969
into special cells then it compute the

329
00:16:15,120 --> 00:16:20,310
density in the special cells will use

330
00:16:17,970 --> 00:16:23,400
the maple seeds to first compute the

331
00:16:20,310 --> 00:16:27,060
probability density in each special

332
00:16:23,400 --> 00:16:28,920
cells then the nibble special cells with

333
00:16:27,060 --> 00:16:31,319
high density high probability density

334
00:16:28,920 --> 00:16:34,469
will be grouped together in the first

335
00:16:31,320 --> 00:16:37,080
pass will form three type of small

336
00:16:34,470 --> 00:16:40,380
clusters will have labeled no more

337
00:16:37,080 --> 00:16:44,670
subclasses labeled up no more subclasses

338
00:16:40,380 --> 00:16:47,300
and unlabeled small clusters then in the

339
00:16:44,670 --> 00:16:50,969
second pass will ignore the maple seeds

340
00:16:47,300 --> 00:16:53,459
just wrong the grid based algorithm

341
00:16:50,970 --> 00:16:56,190
again it will read n large clusters

342
00:16:53,459 --> 00:16:58,050
larger unlabeled classes then we'll

343
00:16:56,190 --> 00:17:00,290
merge the results from the first pass

344
00:16:58,050 --> 00:17:03,510
with the results from the second pass

345
00:17:00,290 --> 00:17:07,109
will identify the position of the small

346
00:17:03,510 --> 00:17:08,890
clusters from the first pass well from

347
00:17:07,109 --> 00:17:11,319
you know my

348
00:17:08,890 --> 00:17:15,610
them into the large unmade classroom

349
00:17:11,319 --> 00:17:18,208
then the Penuel wall in the middle the

350
00:17:15,609 --> 00:17:22,359
middle panel showed the results from our

351
00:17:18,209 --> 00:17:25,839
80 class algorithm so we I think if I

352
00:17:22,359 --> 00:17:28,419
were orange points blue points three

353
00:17:25,839 --> 00:17:31,210
subclasses into this large class and

354
00:17:28,420 --> 00:17:33,750
those purple points between orange and

355
00:17:31,210 --> 00:17:38,440
blue points those are the unlabeled

356
00:17:33,750 --> 00:17:41,550
points so they identify only what region

357
00:17:38,440 --> 00:17:44,680
like a confidence region between

358
00:17:41,550 --> 00:17:46,720
subclasses and the position of the

359
00:17:44,680 --> 00:17:50,410
subclasses can be arbitrary in the large

360
00:17:46,720 --> 00:17:52,840
class in the large mixed class and over

361
00:17:50,410 --> 00:17:55,330
the ship of this unlabeled confidence

362
00:17:52,840 --> 00:17:58,080
region can be quite flexible then we

363
00:17:55,330 --> 00:18:00,939
also have black points black points are

364
00:17:58,080 --> 00:18:05,470
identified as outliers potential

365
00:18:00,940 --> 00:18:08,080
anomalies no attack objects the right

366
00:18:05,470 --> 00:18:10,360
panel is the results from a set semi

367
00:18:08,080 --> 00:18:12,129
surprise in any algorithm basically

368
00:18:10,360 --> 00:18:14,649
every wrong different semi surprise that

369
00:18:12,130 --> 00:18:17,440
many algorithm named Morris give very

370
00:18:14,650 --> 00:18:19,600
similar results so semi surprised many

371
00:18:17,440 --> 00:18:21,850
algorithm uses the same labeled seats

372
00:18:19,600 --> 00:18:24,730
try to identify a classification

373
00:18:21,850 --> 00:18:27,490
boundary in the center so around the

374
00:18:24,730 --> 00:18:30,010
center of the original points then we

375
00:18:27,490 --> 00:18:33,010
can see a completely miss class fair

376
00:18:30,010 --> 00:18:35,440
well no more sub procedure and also

377
00:18:33,010 --> 00:18:38,490
didn't get the structure of the three no

378
00:18:35,440 --> 00:18:38,490
APA structure

379
00:18:42,809 --> 00:18:49,899
well the results here is from when

380
00:18:47,230 --> 00:18:54,400
realtor said it's a neutral networking

381
00:18:49,900 --> 00:18:57,340
trend data collected in 1999 and in his

382
00:18:54,400 --> 00:19:00,549
critique up data said 40 percent

383
00:18:57,340 --> 00:19:03,970
nitrogen tree instances around 60

384
00:19:00,549 --> 00:19:08,280
percent are no more instances and here

385
00:19:03,970 --> 00:19:11,679
while in Bern wrong we keep 100 randomly

386
00:19:08,280 --> 00:19:15,340
sample instances keep their labels then

387
00:19:11,679 --> 00:19:21,340
basically 99.6% will be unlabeled data

388
00:19:15,340 --> 00:19:24,459
points then the data points in our high

389
00:19:21,340 --> 00:19:27,699
confidence regions 90% of them are no

390
00:19:24,460 --> 00:19:30,610
more data points so we compare with our

391
00:19:27,700 --> 00:19:33,790
average 60% where we do identify high

392
00:19:30,610 --> 00:19:36,610
confidence regions and nitrogen trend

393
00:19:33,790 --> 00:19:39,040
data is highly mixed so it's very

394
00:19:36,610 --> 00:19:42,549
difficult to I think if I were intrinsic

395
00:19:39,040 --> 00:19:46,840
intrinsic went from no more instances we

396
00:19:42,549 --> 00:19:50,220
achieve a good results in here we are

397
00:19:46,840 --> 00:19:53,409
currently running another larger well

398
00:19:50,220 --> 00:19:56,410
well cybersecurity data set with a

399
00:19:53,410 --> 00:20:00,010
hundred and ten dimensions and we still

400
00:19:56,410 --> 00:20:01,780
have good with us so our algorithm skill

401
00:20:00,010 --> 00:20:05,620
up to high dimensional results as well

402
00:20:01,780 --> 00:20:07,360
and as for the size of the defensive

403
00:20:05,620 --> 00:20:12,149
wall well the sense of the destroyed

404
00:20:07,360 --> 00:20:16,570
defensive wall that red circle actually

405
00:20:12,150 --> 00:20:19,480
we in the middle panel there's small

406
00:20:16,570 --> 00:20:21,820
blue circles so blue circles are the

407
00:20:19,480 --> 00:20:24,309
difference it was they identify the high

408
00:20:21,820 --> 00:20:27,370
confidence Newman regions the sense of

409
00:20:24,309 --> 00:20:29,350
the difference award is determined

410
00:20:27,370 --> 00:20:31,750
through that previous committee retic

411
00:20:29,350 --> 00:20:33,969
study so one defender is the following

412
00:20:31,750 --> 00:20:36,790
in general the equilibrant strategy will

413
00:20:33,970 --> 00:20:40,299
recommend defensive war sites around 60%

414
00:20:36,790 --> 00:20:44,080
between 60% to 80% now to conserve him

415
00:20:40,299 --> 00:20:46,299
now to the next and in the kdd cap data

416
00:20:44,080 --> 00:20:50,740
we also recommend the same range between

417
00:20:46,299 --> 00:20:54,280
60 to 80% to draw a further defensive in

418
00:20:50,740 --> 00:20:58,330
height high confidence region

419
00:20:54,280 --> 00:21:00,820
then another approach utilizing a small

420
00:20:58,330 --> 00:21:04,060
name of labelled seeds is active

421
00:21:00,820 --> 00:21:06,100
learning so academia algorithm you start

422
00:21:04,060 --> 00:21:10,149
from a very small number of training

423
00:21:06,100 --> 00:21:12,820
data points then it will sample the most

424
00:21:10,150 --> 00:21:15,100
influential data point Ulrika will

425
00:21:12,820 --> 00:21:18,370
provide a label for this inferential

426
00:21:15,100 --> 00:21:20,290
data point then by gradually increase in

427
00:21:18,370 --> 00:21:23,199
the size of the training data while

428
00:21:20,290 --> 00:21:26,020
active linear algorithm will achieve the

429
00:21:23,200 --> 00:21:28,300
same accuracy are sustained classifiers

430
00:21:26,020 --> 00:21:31,930
a support vector machine are a lot of

431
00:21:28,300 --> 00:21:33,879
equation but active learning by simple

432
00:21:31,930 --> 00:21:35,800
in the more influenced data point you

433
00:21:33,880 --> 00:21:38,050
know to be labeled and including the

434
00:21:35,800 --> 00:21:41,230
training data it uses a much smaller

435
00:21:38,050 --> 00:21:45,460
Trinity data set compared visa standard

436
00:21:41,230 --> 00:21:48,670
or classifier but here you do so citing

437
00:21:45,460 --> 00:21:52,780
or we imagine the Oracle that provide

438
00:21:48,670 --> 00:21:57,550
labels for the sample data point can be

439
00:21:52,780 --> 00:21:59,920
controlled by adversary's so here we

440
00:21:57,550 --> 00:22:02,740
assume that could be three type of outer

441
00:21:59,920 --> 00:22:06,010
coasts why is the genuine Oracle it just

442
00:22:02,740 --> 00:22:08,590
always provide cracked labels another

443
00:22:06,010 --> 00:22:11,530
type is noisy Oracle so if you are not

444
00:22:08,590 --> 00:22:13,870
purposely produce wrong labels it just

445
00:22:11,530 --> 00:22:16,240
you know by probability will not get out

446
00:22:13,870 --> 00:22:18,610
the labels cracked for example in

447
00:22:16,240 --> 00:22:20,860
crowdsourcing while people just label

448
00:22:18,610 --> 00:22:22,750
instances well quickly then there's a

449
00:22:20,860 --> 00:22:24,820
road rage but it doesn't you know

450
00:22:22,750 --> 00:22:28,030
purposely try to hurt the performance of

451
00:22:24,820 --> 00:22:30,790
the many algorithm the third type of the

452
00:22:28,030 --> 00:22:32,500
Oracle is Monisha so local militias are

453
00:22:30,790 --> 00:22:35,440
Okoye controlled by the reverse rate

454
00:22:32,500 --> 00:22:40,510
adhere targeted reproduce wrong labels

455
00:22:35,440 --> 00:22:42,400
and hopefully while try to reduce the

456
00:22:40,510 --> 00:22:45,990
accuracy cell for the acumen algorithm

457
00:22:42,400 --> 00:22:45,990
as a as much as possible

458
00:22:49,619 --> 00:22:59,129
I also skip the actual algorithm this

459
00:22:56,369 --> 00:23:01,678
paper is a pure it's going to appear in

460
00:22:59,129 --> 00:23:05,639
that workshop in pH EDD while a

461
00:23:01,679 --> 00:23:07,139
conference well in April so the

462
00:23:05,639 --> 00:23:10,439
algorithm is iterative

463
00:23:07,139 --> 00:23:12,508
so we try to estimate which Oracle is

464
00:23:10,440 --> 00:23:15,809
genuine Oracle reaches Manisha's are

465
00:23:12,509 --> 00:23:17,970
local well we first cluster data based

466
00:23:15,809 --> 00:23:20,220
on the data clustering results compared

467
00:23:17,970 --> 00:23:22,409
with the labels produced by the locusts

468
00:23:20,220 --> 00:23:25,019
we asked Mary to answer at the genuine

469
00:23:22,409 --> 00:23:27,840
articles that we will use only the ice

470
00:23:25,019 --> 00:23:30,419
to make genuine Oracle to label the

471
00:23:27,840 --> 00:23:31,408
sample data point increase the training

472
00:23:30,419 --> 00:23:34,619
dataset by one

473
00:23:31,409 --> 00:23:39,479
so in this iterative process we write on

474
00:23:34,619 --> 00:23:42,478
the webspam data and here were 60% of

475
00:23:39,479 --> 00:23:45,899
the instances spam in your instances and

476
00:23:42,479 --> 00:23:47,609
we compile while our while or do a

477
00:23:45,899 --> 00:23:50,008
thorough active learning happening with

478
00:23:47,609 --> 00:23:52,649
a simple majority rule with

479
00:23:50,009 --> 00:23:54,899
crowdsourcing technique and also with

480
00:23:52,649 --> 00:23:57,869
the standard acronym technique without

481
00:23:54,899 --> 00:24:01,918
monisha Sandra Caracas underlying

482
00:23:57,869 --> 00:24:04,199
philosopher is support vector machine so

483
00:24:01,919 --> 00:24:06,690
this is the typical results for active

484
00:24:04,200 --> 00:24:09,720
learning as streaming sites gradually

485
00:24:06,690 --> 00:24:12,090
increase so we start from 20 labeled

486
00:24:09,720 --> 00:24:16,710
training data points gradually increased

487
00:24:12,090 --> 00:24:18,209
to more than 100 so the table we are

488
00:24:16,710 --> 00:24:20,519
plotting the accuracy of the act

489
00:24:18,210 --> 00:24:22,889
learning algorithm on both right and

490
00:24:20,519 --> 00:24:26,279
left panel the top line the most

491
00:24:22,889 --> 00:24:28,379
accurate accurate technique is the

492
00:24:26,279 --> 00:24:30,599
standard active learning technique where

493
00:24:28,379 --> 00:24:33,899
Oracle's always produce the wrong or

494
00:24:30,599 --> 00:24:36,450
correct labels but they both Blackland

495
00:24:33,899 --> 00:24:40,080
let's the accuracy of our auto cell

496
00:24:36,450 --> 00:24:42,960
actually algorithm so on the right panel

497
00:24:40,080 --> 00:24:44,789
we assume there are 3000 costs 1000

498
00:24:42,960 --> 00:24:45,570
genuine Oracle's teller malicious

499
00:24:44,789 --> 00:24:48,929
Oracle's

500
00:24:45,570 --> 00:24:50,039
10-week Holocaust now after about a key

501
00:24:48,929 --> 00:24:52,830
training samples

502
00:24:50,039 --> 00:24:55,499
labor training samples will be able to

503
00:24:52,830 --> 00:24:58,408
estimate our general costs and our

504
00:24:55,499 --> 00:25:01,109
accuracy know quickly matched the

505
00:24:58,409 --> 00:25:01,860
accuracy of the standard active learning

506
00:25:01,109 --> 00:25:03,629
techniques

507
00:25:01,860 --> 00:25:07,760
but the difference between four

508
00:25:03,630 --> 00:25:11,160
algorithm even in your between or our

509
00:25:07,760 --> 00:25:13,770
technique and majority water not very

510
00:25:11,160 --> 00:25:15,750
significant on the right hand side so on

511
00:25:13,770 --> 00:25:19,679
the left hand side we look at a more

512
00:25:15,750 --> 00:25:23,640
extreme example out of three our coasts

513
00:25:19,679 --> 00:25:25,710
we assume only favor journal articles 13

514
00:25:23,640 --> 00:25:29,309
mm initials are low cost to our noise

515
00:25:25,710 --> 00:25:33,150
articles so we here we see among you

516
00:25:29,309 --> 00:25:37,678
know better comparison for technics well

517
00:25:33,150 --> 00:25:40,530
our technique will we will be lesser

518
00:25:37,679 --> 00:25:43,770
crew men the standard acumen technique

519
00:25:40,530 --> 00:25:46,320
but majority world is just like flipping

520
00:25:43,770 --> 00:25:53,010
or flipping a coin and call sourcing

521
00:25:46,320 --> 00:25:56,850
technique is a nice accurate so that's

522
00:25:53,010 --> 00:25:59,510
the results in well mostly I'm

523
00:25:56,850 --> 00:26:03,830
surprising in our weekly surprising

524
00:25:59,510 --> 00:26:07,650
scenario when we basically vacations

525
00:26:03,830 --> 00:26:09,809
targeted on cybersecurity datasets next

526
00:26:07,650 --> 00:26:12,000
well we'll look had surprisingly mean

527
00:26:09,809 --> 00:26:15,540
scenario surprising a new scenario

528
00:26:12,000 --> 00:26:17,940
assume large name of labeling data point

529
00:26:15,540 --> 00:26:20,610
but this is were often a case in

530
00:26:17,940 --> 00:26:25,050
computer vision domain and here we

531
00:26:20,610 --> 00:26:27,709
consider two techniques rather two

532
00:26:25,050 --> 00:26:29,520
strategies to make machine meaning

533
00:26:27,710 --> 00:26:33,540
technical classifiers

534
00:26:29,520 --> 00:26:36,179
Moldova's against dosha perturbation why

535
00:26:33,540 --> 00:26:38,580
is to draw a conservative strategy so

536
00:26:36,179 --> 00:26:40,650
both strategy is inspired by game theory

537
00:26:38,580 --> 00:26:42,960
well in game theory the you Calibri

538
00:26:40,650 --> 00:26:45,300
solution is a more conservative solution

539
00:26:42,960 --> 00:26:46,980
basically we withdraw the decision

540
00:26:45,300 --> 00:26:49,678
boundary toward the center for the

541
00:26:46,980 --> 00:26:52,290
normal population then as more difficult

542
00:26:49,679 --> 00:26:55,650
for the worse way to reach the boundary

543
00:26:52,290 --> 00:26:58,470
of the neoconservatives in the same

544
00:26:55,650 --> 00:27:01,320
function now another strategy is to have

545
00:26:58,470 --> 00:27:03,510
randomized the same boundary so if we

546
00:27:01,320 --> 00:27:06,149
randomized the same boundary then it's

547
00:27:03,510 --> 00:27:07,890
multi-record for the real adversary's to

548
00:27:06,150 --> 00:27:10,919
discover why it's the same boundary and

549
00:27:07,890 --> 00:27:14,550
to create new dorsal samples so the

550
00:27:10,919 --> 00:27:15,360
first technique here is the word cero

551
00:27:14,550 --> 00:27:17,730
spot back

552
00:27:15,360 --> 00:27:21,389
here we draw a more well we take the

553
00:27:17,730 --> 00:27:23,250
conservative strategy support vector

554
00:27:21,390 --> 00:27:25,470
machine Jen yourselves a convex

555
00:27:23,250 --> 00:27:28,650
optimization problem so we differ hinge

556
00:27:25,470 --> 00:27:33,980
laws you know well then try to solve for

557
00:27:28,650 --> 00:27:36,510
the decision boundary here if we well

558
00:27:33,980 --> 00:27:39,210
somehow incorporate support vector

559
00:27:36,510 --> 00:27:40,980
machine with game theory model support

560
00:27:39,210 --> 00:27:43,290
vector machine is already up with

561
00:27:40,980 --> 00:27:46,260
optimization problem game theory is

562
00:27:43,290 --> 00:27:48,780
another optimization in your problem

563
00:27:46,260 --> 00:27:52,890
then we are going to have a double loop

564
00:27:48,780 --> 00:27:55,710
of optimizations so for the service part

565
00:27:52,890 --> 00:27:57,660
vector machine we simplify well the

566
00:27:55,710 --> 00:27:59,970
algorithm we don't directly your scheme

567
00:27:57,660 --> 00:28:02,880
giveaway but instead we try to model

568
00:27:59,970 --> 00:28:06,020
that hack and incorporate anticipated

569
00:28:02,880 --> 00:28:10,260
attack inside the risk minimization

570
00:28:06,020 --> 00:28:12,629
formulation inside the last function the

571
00:28:10,260 --> 00:28:14,490
actual setup of the new loss function

572
00:28:12,630 --> 00:28:17,580
and the attack model and in the paper is

573
00:28:14,490 --> 00:28:19,800
a security paper so basically we

574
00:28:17,580 --> 00:28:22,050
consider two possible attacks once the

575
00:28:19,800 --> 00:28:24,149
free range attack new freer injured have

576
00:28:22,050 --> 00:28:26,610
objects can be moved anywhere in the in

577
00:28:24,150 --> 00:28:29,750
the feature space another scenario is

578
00:28:26,610 --> 00:28:33,389
targeted attack in targeted attack wall

579
00:28:29,750 --> 00:28:35,220
but the result objects must move toward

580
00:28:33,390 --> 00:28:37,470
a normal value

581
00:28:35,220 --> 00:28:40,410
a normal object randomly selected from

582
00:28:37,470 --> 00:28:43,500
normal population then based on attack

583
00:28:40,410 --> 00:28:45,200
model we will rewrite a loss function in

584
00:28:43,500 --> 00:28:47,790
the risk minimization problem and

585
00:28:45,200 --> 00:28:49,860
recompute compute a different work

586
00:28:47,790 --> 00:28:56,970
conservative work support vector machine

587
00:28:49,860 --> 00:28:58,800
design boundary so this is this is a

588
00:28:56,970 --> 00:29:02,070
comparison of the standard support

589
00:28:58,800 --> 00:29:04,379
vector machine decision boundary and the

590
00:29:02,070 --> 00:29:06,510
more conservative decision boundary so

591
00:29:04,380 --> 00:29:08,460
here red points are the urban normal

592
00:29:06,510 --> 00:29:09,540
data points green points are the normal

593
00:29:08,460 --> 00:29:12,030
populations

594
00:29:09,540 --> 00:29:13,770
well the daishan is the standard design

595
00:29:12,030 --> 00:29:17,010
bhangra basically choose the best

596
00:29:13,770 --> 00:29:19,680
separation between two classes and using

597
00:29:17,010 --> 00:29:22,470
kernel function could be or a non linear

598
00:29:19,680 --> 00:29:25,650
decision boundary but the black points

599
00:29:22,470 --> 00:29:27,830
are the well actually tack data points

600
00:29:25,650 --> 00:29:30,330
well if we

601
00:29:27,830 --> 00:29:35,699
well you've in the risk minimization

602
00:29:30,330 --> 00:29:39,059
problem well we put in the crack well we

603
00:29:35,700 --> 00:29:42,450
put in the properly estimated attack

604
00:29:39,059 --> 00:29:44,999
model then the blue line is the revised

605
00:29:42,450 --> 00:29:46,529
more conservatism boundary it managed to

606
00:29:44,999 --> 00:29:49,169
prolong caught most of the happy

607
00:29:46,529 --> 00:29:52,080
instances but you've seen the risk

608
00:29:49,169 --> 00:29:55,529
minimization formulation well that has

609
00:29:52,080 --> 00:29:59,369
the anticipated attack strength doesn't

610
00:29:55,529 --> 00:30:02,429
match the actual attack then well we all

611
00:29:59,369 --> 00:30:05,249
seem more well wrongly labeled no more

612
00:30:02,429 --> 00:30:08,070
objects and more attack objects come you

613
00:30:05,249 --> 00:30:09,570
know approach the boundary of the reduce

614
00:30:08,070 --> 00:30:11,999
arrows fought back to measuring the same

615
00:30:09,570 --> 00:30:14,849
boundary so we're on our set of

616
00:30:11,999 --> 00:30:19,349
simulation basically if we do not really

617
00:30:14,849 --> 00:30:22,499
observe the attack objects well the risk

618
00:30:19,349 --> 00:30:25,979
minimization problem better to predict

619
00:30:22,499 --> 00:30:32,279
the medium strength attack and Jordison

620
00:30:25,979 --> 00:30:34,349
boundary but not too conservative so the

621
00:30:32,279 --> 00:30:36,839
next randomized the same boundary

622
00:30:34,349 --> 00:30:40,830
strategy we apply to keep new night work

623
00:30:36,839 --> 00:30:42,869
so for Tiffany night work this is why in

624
00:30:40,830 --> 00:30:44,759
the past couple of years those arrow

625
00:30:42,869 --> 00:30:50,549
machining in the sudden becomes a very

626
00:30:44,759 --> 00:30:53,129
popular topic so images well with very

627
00:30:50,549 --> 00:30:55,649
minor perturbation can easily be

628
00:30:53,129 --> 00:30:59,699
misclassified by deep neural network

629
00:30:55,649 --> 00:31:01,830
model so the left is a hundred into it

630
00:30:59,700 --> 00:31:03,779
there's quickly label and on the right

631
00:31:01,830 --> 00:31:06,449
hand side there's a misclassified tree

632
00:31:03,779 --> 00:31:08,460
we see just a few you know pixels on

633
00:31:06,450 --> 00:31:11,519
three is missing then it cannot be

634
00:31:08,460 --> 00:31:15,559
labeled correctly so deep neural network

635
00:31:11,519 --> 00:31:18,960
become very popular classifier and

636
00:31:15,559 --> 00:31:21,570
eventually outperform support vector

637
00:31:18,960 --> 00:31:25,549
machine is an image classification tasks

638
00:31:21,570 --> 00:31:27,960
in 2012 while limiting that competition

639
00:31:25,549 --> 00:31:29,908
given your network clearly out

640
00:31:27,960 --> 00:31:32,359
performance of a dropped machine this

641
00:31:29,909 --> 00:31:36,479
wire you know deep neural network is

642
00:31:32,359 --> 00:31:40,799
well used widely in computer reading and

643
00:31:36,479 --> 00:31:42,390
audio you know classification tasks but

644
00:31:40,799 --> 00:31:44,730
it's also very one

645
00:31:42,390 --> 00:31:47,190
it's less robust in the support vector

646
00:31:44,730 --> 00:31:52,320
machine that's the current conclusion

647
00:31:47,190 --> 00:31:55,470
and our our results is try to improve

648
00:31:52,320 --> 00:32:06,240
the performance of new network facing or

649
00:31:55,470 --> 00:32:08,880
sell images so there are many different

650
00:32:06,240 --> 00:32:12,990
attack algorithms designed to generate

651
00:32:08,880 --> 00:32:15,870
the perturbations well and then a new or

652
00:32:12,990 --> 00:32:18,179
several image so famous example is

653
00:32:15,870 --> 00:32:20,580
collinear Wagoner's iterative outward

654
00:32:18,179 --> 00:32:23,820
hack there's also in a moment based

655
00:32:20,580 --> 00:32:26,280
attack well also a text you know well

656
00:32:23,820 --> 00:32:29,158
somehow try to estimate the

657
00:32:26,280 --> 00:32:32,220
randomization technique and recomputed

658
00:32:29,159 --> 00:32:36,390
greetings but these are all grading base

659
00:32:32,220 --> 00:32:38,370
basically the use objective function try

660
00:32:36,390 --> 00:32:41,210
to define the minimal amount of

661
00:32:38,370 --> 00:32:46,199
perturbation I did to an image and

662
00:32:41,210 --> 00:32:49,440
compute the greetings to you know change

663
00:32:46,200 --> 00:32:53,340
the pixel virus unoriginal in your test

664
00:32:49,440 --> 00:32:55,770
image and generate new several images so

665
00:32:53,340 --> 00:33:00,049
more or less other tack algorithm follow

666
00:32:55,770 --> 00:33:03,780
the same green based approach and here

667
00:33:00,049 --> 00:33:06,658
well we did reserve samples there's one

668
00:33:03,780 --> 00:33:08,700
interesting phenomenon is observed it's

669
00:33:06,659 --> 00:33:12,150
called transferability of those zero

670
00:33:08,700 --> 00:33:15,600
samples so people discovered well you've

671
00:33:12,150 --> 00:33:18,240
wondered also image is generated well to

672
00:33:15,600 --> 00:33:20,189
break one dip neural network model then

673
00:33:18,240 --> 00:33:22,260
the simulator so image will be

674
00:33:20,190 --> 00:33:24,780
misclassified by other neural network

675
00:33:22,260 --> 00:33:27,299
models with very different structure or

676
00:33:24,780 --> 00:33:30,270
it akka hi EEMA - you know across

677
00:33:27,299 --> 00:33:32,490
different model classes it can even be

678
00:33:30,270 --> 00:33:34,559
misclassified by support vector machine

679
00:33:32,490 --> 00:33:38,220
or just regression tests in which

680
00:33:34,559 --> 00:33:40,110
classifier and here we see well if we

681
00:33:38,220 --> 00:33:42,780
randomized the same boundary of deep

682
00:33:40,110 --> 00:33:45,658
neural network we can successfully stop

683
00:33:42,780 --> 00:33:47,730
transferability of all those examples so

684
00:33:45,659 --> 00:33:50,539
innocence make new network model bars

685
00:33:47,730 --> 00:33:50,539
against attacks

686
00:33:54,789 --> 00:34:01,070
so we actually considered to attack

687
00:33:58,429 --> 00:34:04,549
scenario in the weak attack scenario

688
00:34:01,070 --> 00:34:08,480
well we assume attackers adversary's no

689
00:34:04,549 --> 00:34:10,759
only one new network but werster is know

690
00:34:08,480 --> 00:34:14,210
the structure the parameter of one new

691
00:34:10,760 --> 00:34:17,480
network but we will trim a number of new

692
00:34:14,210 --> 00:34:20,270
networks but just using different random

693
00:34:17,480 --> 00:34:24,199
initial points in the training procedure

694
00:34:20,270 --> 00:34:26,889
so neural network is very vulnerable

695
00:34:24,199 --> 00:34:31,219
even starting from the training process

696
00:34:26,889 --> 00:34:34,369
if we change while the initial wires we

697
00:34:31,219 --> 00:34:37,879
end up with what different enough new

698
00:34:34,369 --> 00:34:42,220
networks different enough models so here

699
00:34:37,879 --> 00:34:44,960
we train ten neural network models well

700
00:34:42,219 --> 00:34:47,270
basically if you have a pool of ten or

701
00:34:44,960 --> 00:34:48,889
twenty neural network models then that's

702
00:34:47,270 --> 00:34:51,710
sufficient to randomize the same

703
00:34:48,889 --> 00:34:53,210
boundary and the basin entrepreneur

704
00:34:51,710 --> 00:34:57,139
network is a neural network that

705
00:34:53,210 --> 00:34:59,000
actually known to the worship so it was

706
00:34:57,139 --> 00:35:02,450
you notice structure not permit virus

707
00:34:59,000 --> 00:35:05,240
then but were several images will be

708
00:35:02,450 --> 00:35:07,939
generated or told that based on tip new

709
00:35:05,240 --> 00:35:10,939
network now it has performance you know

710
00:35:07,940 --> 00:35:14,240
accuracy zero percent on the generators

711
00:35:10,940 --> 00:35:16,880
are images and here we also compare with

712
00:35:14,240 --> 00:35:17,750
a different strategy is called in SEM

713
00:35:16,880 --> 00:35:21,920
board or cero

714
00:35:17,750 --> 00:35:25,310
trin or modo

715
00:35:21,920 --> 00:35:28,010
so one major class of different strategy

716
00:35:25,310 --> 00:35:30,410
is to do in neural network using

717
00:35:28,010 --> 00:35:32,720
undersell images so it's called

718
00:35:30,410 --> 00:35:35,450
adversarial a drink neural network and

719
00:35:32,720 --> 00:35:38,660
we can trim one we can truly assemble

720
00:35:35,450 --> 00:35:40,970
well it has also proper also some

721
00:35:38,660 --> 00:35:43,430
problems why is what the adversary

722
00:35:40,970 --> 00:35:47,390
images involved in the great training

723
00:35:43,430 --> 00:35:49,879
procedure is overfitting and once you'll

724
00:35:47,390 --> 00:35:52,790
return the model it's a new is a new

725
00:35:49,880 --> 00:35:55,160
model then newer those are images can be

726
00:35:52,790 --> 00:35:58,580
generated toward a new model the between

727
00:35:55,160 --> 00:36:01,899
model and still while new model will

728
00:35:58,580 --> 00:36:01,900
have zero percent accuracy

729
00:36:06,480 --> 00:36:13,450
so for the meek attack scenario well we

730
00:36:11,230 --> 00:36:16,720
can have multiple defense strategy out

731
00:36:13,450 --> 00:36:19,930
at she good performance so first one

732
00:36:16,720 --> 00:36:23,290
well for every new tight sample we

733
00:36:19,930 --> 00:36:26,770
randomly choose one trend model from a

734
00:36:23,290 --> 00:36:30,400
pro se tell our 2020 models to classify

735
00:36:26,770 --> 00:36:33,220
that has English Irish accuracy it's 86

736
00:36:30,400 --> 00:36:36,520
percent this is average over 50 or 20

737
00:36:33,220 --> 00:36:39,819
wrongs another one is simply use the

738
00:36:36,520 --> 00:36:42,340
majority rule of all the trim models 10

739
00:36:39,820 --> 00:36:44,620
or 20 of them and because your adversary

740
00:36:42,340 --> 00:36:46,600
knows only one model the majority world

741
00:36:44,620 --> 00:36:50,230
also achieves a good accuracy ninety one

742
00:36:46,600 --> 00:36:54,420
ninety nine percent and third one we

743
00:36:50,230 --> 00:36:57,220
randomized well among the retreat models

744
00:36:54,420 --> 00:37:01,450
so for Erica's image you rejoin them

745
00:36:57,220 --> 00:37:04,810
they pick one retreat model accuracy

746
00:37:01,450 --> 00:37:07,720
increased to 87 percent well the last

747
00:37:04,810 --> 00:37:10,120
strategy in the meek attack scenario

748
00:37:07,720 --> 00:37:12,160
while basically I returned four new ties

749
00:37:10,120 --> 00:37:14,920
image we ruined them in a truther model

750
00:37:12,160 --> 00:37:17,410
and inject random noises to the

751
00:37:14,920 --> 00:37:20,290
parameter value to the parameters in new

752
00:37:17,410 --> 00:37:22,180
night-work so we not only randomly

753
00:37:20,290 --> 00:37:24,880
select one model we also drain demise

754
00:37:22,180 --> 00:37:27,940
parameter but under this stronger

755
00:37:24,880 --> 00:37:31,390
randomizations strategy the count

756
00:37:27,940 --> 00:37:35,140
accuracy is 77.9%

757
00:37:31,390 --> 00:37:39,370
but later we consider a second stronger

758
00:37:35,140 --> 00:37:41,859
attack scenario well we assume the

759
00:37:39,370 --> 00:37:44,500
diversities know all the trend models of

760
00:37:41,860 --> 00:37:47,440
the tantrum new network other words with

761
00:37:44,500 --> 00:37:50,460
no tomorrow's structure permit riders

762
00:37:47,440 --> 00:37:54,490
now it can generate order cell images

763
00:37:50,460 --> 00:37:57,640
attacking other models and with that

764
00:37:54,490 --> 00:38:00,819
strong attack basically only the last

765
00:37:57,640 --> 00:38:03,609
while strategies your works so when we

766
00:38:00,820 --> 00:38:06,340
inject random noises to the trend model

767
00:38:03,610 --> 00:38:10,270
we basically formed random example and

768
00:38:06,340 --> 00:38:12,640
we still maintain accuracy about 80% so

769
00:38:10,270 --> 00:38:15,070
what we observe here is well basically

770
00:38:12,640 --> 00:38:16,200
there's a there's a trade-off between

771
00:38:15,070 --> 00:38:19,500
occurrence

772
00:38:16,200 --> 00:38:23,970
and robustness the simple majority award

773
00:38:19,500 --> 00:38:27,000
is well has the smallest occurs 0% in

774
00:38:23,970 --> 00:38:28,379
the strong attack scenario but for the

775
00:38:27,000 --> 00:38:31,650
weak attack scenario has highest

776
00:38:28,380 --> 00:38:34,740
accuracy and well for the random

777
00:38:31,650 --> 00:38:36,420
assemble accuracy on the weak attack

778
00:38:34,740 --> 00:38:38,939
scenario is the lowest but if you

779
00:38:36,420 --> 00:38:42,140
maintain this level of accuracy on the

780
00:38:38,940 --> 00:38:45,329
strong attacks so this is another

781
00:38:42,140 --> 00:38:47,848
phenomena observed recently you know in

782
00:38:45,329 --> 00:38:50,010
robust machine naming we probably needs

783
00:38:47,849 --> 00:38:52,380
to have a systematic way to try to

784
00:38:50,010 --> 00:38:59,040
quantify the treat of between robustness

785
00:38:52,380 --> 00:39:01,799
and accuracy and for future results well

786
00:38:59,040 --> 00:39:04,109
how to build robust aplenty models or in

787
00:39:01,799 --> 00:39:06,630
general how to evaluate machining

788
00:39:04,109 --> 00:39:09,359
techniques robustness against virtual

789
00:39:06,630 --> 00:39:12,299
samples it's still open research area

790
00:39:09,359 --> 00:39:15,210
and another thing is you are given your

791
00:39:12,299 --> 00:39:17,430
network is almost a black box and we

792
00:39:15,210 --> 00:39:20,040
need to understand how to be known at

793
00:39:17,430 --> 00:39:23,368
who reaches conclusion so you make the

794
00:39:20,040 --> 00:39:25,680
distilled mo explainable then well in

795
00:39:23,369 --> 00:39:27,630
time will we should be able to further

796
00:39:25,680 --> 00:39:33,240
improve you know the generalization

797
00:39:27,630 --> 00:39:35,910
error of deep neural network so my

798
00:39:33,240 --> 00:39:41,540
related publications are my website yeah

799
00:39:35,910 --> 00:39:41,540
thank you are there any questions

800
00:39:45,330 --> 00:39:51,870
okay if no questions thank you very much

801
00:39:48,920 --> 00:39:53,580
this topic I really swell funding you

802
00:39:51,870 --> 00:39:56,970
know by different agencies so I'm

803
00:39:53,580 --> 00:39:59,279
actively looking for well students who

804
00:39:56,970 --> 00:40:02,720
want to work on this topic so you feel

805
00:39:59,280 --> 00:40:02,720
interested please talk to me

806
00:40:13,740 --> 00:40:15,799
you

