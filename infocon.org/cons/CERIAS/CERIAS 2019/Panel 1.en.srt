1
00:00:00,030 --> 00:00:03,629
thank you for enduring our extended

2
00:00:01,680 --> 00:00:05,970
break I promise you'll not have to cool

3
00:00:03,629 --> 00:00:08,700
your jets that long the rest of the

4
00:00:05,970 --> 00:00:10,710
afternoon rest of the day so we're gonna

5
00:00:08,700 --> 00:00:12,329
start our first panel discussion of the

6
00:00:10,710 --> 00:00:15,049
session you haven't been paying

7
00:00:12,330 --> 00:00:17,730
attention to the Purdue University 150

8
00:00:15,049 --> 00:00:20,670
celebration they have four major themes

9
00:00:17,730 --> 00:00:23,010
of research for the next 150 years and

10
00:00:20,670 --> 00:00:25,680
we've structure our panel discussions

11
00:00:23,010 --> 00:00:26,849
around those four themes so the first of

12
00:00:25,680 --> 00:00:28,920
the four we're going to talk about is

13
00:00:26,849 --> 00:00:31,289
artificial intelligence and I'm

14
00:00:28,920 --> 00:00:33,360
delighted that our moderator today is

15
00:00:31,289 --> 00:00:35,100
Professor Jennifer Nevel she's a

16
00:00:33,360 --> 00:00:37,250
professor of computer science and

17
00:00:35,100 --> 00:00:40,440
statistics here at Purdue University and

18
00:00:37,250 --> 00:00:42,420
she has been involved with over a

19
00:00:40,440 --> 00:00:45,120
hundred peer-reviewed publications five

20
00:00:42,420 --> 00:00:48,809
thousand citations focused on developing

21
00:00:45,120 --> 00:00:51,718
data mining machine learning techniques

22
00:00:48,809 --> 00:00:53,399
and complex network domain social

23
00:00:51,719 --> 00:00:55,410
information and physical networks

24
00:00:53,399 --> 00:00:57,390
there's not much she hasn't touched and

25
00:00:55,410 --> 00:00:59,550
she was clearly our first choice to

26
00:00:57,390 --> 00:01:01,379
moderate the AI panel so with that I'll

27
00:00:59,550 --> 00:01:04,018
introduce Jen and let her introduce her

28
00:01:01,379 --> 00:01:05,780
panel okay thank you is this gonna be a

29
00:01:04,019 --> 00:01:08,729
problem with two mics like should I -

30
00:01:05,780 --> 00:01:12,330
it's fine okay well thanks everybody for

31
00:01:08,729 --> 00:01:15,960
coming I would like to introduce our

32
00:01:12,330 --> 00:01:18,119
panelists here for our discussion on AI

33
00:01:15,960 --> 00:01:21,570
and security

34
00:01:18,119 --> 00:01:25,229
let me see if I'll go from the farthest

35
00:01:21,570 --> 00:01:28,369
with dr. Chris Clifton is a professor of

36
00:01:25,229 --> 00:01:31,289
computer science at Purdue he works on

37
00:01:28,369 --> 00:01:32,579
issues related to data privacy I'm sure

38
00:01:31,290 --> 00:01:36,869
you all know him because he's always

39
00:01:32,579 --> 00:01:39,839
here at every serious symposium he's he

40
00:01:36,869 --> 00:01:42,000
has been a sort of stalwart member of

41
00:01:39,840 --> 00:01:45,509
both the security group and the data

42
00:01:42,000 --> 00:01:48,210
mining groups here at Purdue in computer

43
00:01:45,509 --> 00:01:51,210
science he left for a little while and

44
00:01:48,210 --> 00:01:52,500
from 2013 to 2015 to serve as program

45
00:01:51,210 --> 00:01:54,960
director at the National Science

46
00:01:52,500 --> 00:01:57,930
Foundation and prior to joining Purdue

47
00:01:54,960 --> 00:02:00,030
in 2001 he was a principal scientist in

48
00:01:57,930 --> 00:02:02,460
the information technology division at

49
00:02:00,030 --> 00:02:05,549
mitre and before mitre he was a

50
00:02:02,460 --> 00:02:06,809
professor at Northwestern University so

51
00:02:05,549 --> 00:02:09,149
who's next

52
00:02:06,810 --> 00:02:12,069
we have Ashish Kundu dr. Kundu is a

53
00:02:09,149 --> 00:02:14,019
master inventor and research scientist

54
00:02:12,069 --> 00:02:17,048
at the in the security research

55
00:02:14,019 --> 00:02:20,109
department at the TJ Watson Research

56
00:02:17,049 --> 00:02:22,629
Center at IBM in New York he received

57
00:02:20,109 --> 00:02:25,329
his PhD in computer science from Purdue

58
00:02:22,629 --> 00:02:27,189
in 2010 and his main research interests

59
00:02:25,329 --> 00:02:29,620
are broadly in the area of cyber

60
00:02:27,189 --> 00:02:33,939
security privacy compliance and AI

61
00:02:29,620 --> 00:02:36,819
ethics he has led the security and

62
00:02:33,939 --> 00:02:39,310
compliance group at IBM Watson health as

63
00:02:36,819 --> 00:02:42,069
well as well as IBM Watson education and

64
00:02:39,310 --> 00:02:44,680
his work has led to more than a hundred

65
00:02:42,069 --> 00:02:46,750
patents filed with more than 80 patents

66
00:02:44,680 --> 00:02:48,389
granted and he has more than 30

67
00:02:46,750 --> 00:02:51,069
peer-reviewed to academic research

68
00:02:48,389 --> 00:02:53,319
publications he has been recognized with

69
00:02:51,069 --> 00:02:55,510
the honor of Master inventor by IBM

70
00:02:53,319 --> 00:02:57,790
Research and while he was here at Purdue

71
00:02:55,510 --> 00:03:01,030
he received the serious Diamond Award

72
00:02:57,790 --> 00:03:03,189
for his outstanding contribution to PhD

73
00:03:01,030 --> 00:03:06,700
research in cyber security and he also

74
00:03:03,189 --> 00:03:09,790
got the best graduate teaching assistant

75
00:03:06,700 --> 00:03:13,238
award so next okay now I'm in the right

76
00:03:09,790 --> 00:03:15,429
orders so is mr. Paul Carnivale who is

77
00:03:13,239 --> 00:03:18,040
director of technology for Northrop

78
00:03:15,430 --> 00:03:19,989
Grumman mission system sector and he's a

79
00:03:18,040 --> 00:03:23,019
member of Northrop Grumman's corporate

80
00:03:19,989 --> 00:03:25,299
technology counsel in this role he leads

81
00:03:23,019 --> 00:03:27,519
a wide range of advanced technology

82
00:03:25,299 --> 00:03:29,859
initiatives including integration of the

83
00:03:27,519 --> 00:03:32,409
sector's R&D program university research

84
00:03:29,859 --> 00:03:34,299
intellectual property innovation and

85
00:03:32,409 --> 00:03:37,149
development of emerging technologies

86
00:03:34,299 --> 00:03:39,310
applied to intelligence in DoD his prior

87
00:03:37,150 --> 00:03:41,229
work includes development of national

88
00:03:39,310 --> 00:03:43,239
scale intelligence SIGINT and

89
00:03:41,229 --> 00:03:45,519
communication systems with an emphasis

90
00:03:43,239 --> 00:03:47,169
on information theory digital signal

91
00:03:45,519 --> 00:03:52,150
processing and electronics hardware

92
00:03:47,169 --> 00:03:53,590
design mr. Khan convo holds a BS II from

93
00:03:52,150 --> 00:03:56,829
the Cooper Union School of Engineering

94
00:03:53,590 --> 00:03:59,260
and an MSE from Rutgers University and

95
00:03:56,829 --> 00:04:02,560
then finally last but not least we have

96
00:03:59,260 --> 00:04:04,120
dr. Sanjay and Aaron who is a fellow and

97
00:04:02,560 --> 00:04:06,479
chief scientist and information

98
00:04:04,120 --> 00:04:09,370
assurance and security department at

99
00:04:06,479 --> 00:04:14,439
perspective labs which was earlier

100
00:04:09,370 --> 00:04:16,659
called vancour labs and and then he also

101
00:04:14,439 --> 00:04:18,668
has been at telcordia and Belcore

102
00:04:16,659 --> 00:04:20,978
currently has a principal investigator

103
00:04:18,668 --> 00:04:22,840
of two DARPA projects one is on

104
00:04:20,978 --> 00:04:23,530
configuration security and the other one

105
00:04:22,840 --> 00:04:25,270
is on

106
00:04:23,530 --> 00:04:28,119
space exploration for cyber-physical

107
00:04:25,270 --> 00:04:30,099
systems such as underwater robots he

108
00:04:28,120 --> 00:04:32,500
also leads a science of configuration

109
00:04:30,100 --> 00:04:34,960
progress project to synthesize error

110
00:04:32,500 --> 00:04:36,910
free network and cloud configurations

111
00:04:34,960 --> 00:04:38,830
and minutes rather than months all of

112
00:04:36,910 --> 00:04:40,570
these projects leverage two branches of

113
00:04:38,830 --> 00:04:44,109
AI machine learning and deductive

114
00:04:40,570 --> 00:04:48,520
reasoning and he has his PhD in computer

115
00:04:44,110 --> 00:04:50,410
science from UCLA in 1988 okay great so

116
00:04:48,520 --> 00:04:53,049
now that I have introduced everybody on

117
00:04:50,410 --> 00:04:55,240
the panel I'll tell you a little bit

118
00:04:53,050 --> 00:04:57,970
about the format that we'll have here so

119
00:04:55,240 --> 00:05:00,430
I'm going to open it up for each of the

120
00:04:57,970 --> 00:05:03,760
panelists to give four or five minutes

121
00:05:00,430 --> 00:05:06,430
statement on their views of what are the

122
00:05:03,760 --> 00:05:08,950
main opportunities and challenges as

123
00:05:06,430 --> 00:05:11,770
that we face with respect to

124
00:05:08,950 --> 00:05:13,000
cybersecurity as we move into this new

125
00:05:11,770 --> 00:05:18,159
age of AI

126
00:05:13,000 --> 00:05:20,890
so really the advances in cyber physical

127
00:05:18,160 --> 00:05:22,720
systems and AI have led to what people

128
00:05:20,890 --> 00:05:25,450
refer to as the fourth wave of the

129
00:05:22,720 --> 00:05:27,340
Industrial Revolution obviously these

130
00:05:25,450 --> 00:05:29,349
kind of systems are being embedded

131
00:05:27,340 --> 00:05:31,869
throughout the fabric of our lives and

132
00:05:29,350 --> 00:05:34,050
thinking about how security sort of

133
00:05:31,870 --> 00:05:37,390
intersects with AI is a very important

134
00:05:34,050 --> 00:05:40,300
topic to topic at talk about not only

135
00:05:37,390 --> 00:05:43,900
from the viewpoint of how we can use AI

136
00:05:40,300 --> 00:05:46,390
to improve security but also how do a AI

137
00:05:43,900 --> 00:05:48,190
systems offer new challenges and

138
00:05:46,390 --> 00:05:51,190
security risks that we have to deal with

139
00:05:48,190 --> 00:05:52,870
and so once the each panelists gives

140
00:05:51,190 --> 00:05:54,640
their opening statements then we'll open

141
00:05:52,870 --> 00:05:57,840
it up to questions for the audience so

142
00:05:54,640 --> 00:06:01,960
we can have a good discussion okay so

143
00:05:57,840 --> 00:06:04,419
maybe we should start with dr. Sanjay

144
00:06:01,960 --> 00:06:07,299
nur in because he has a couple of slides

145
00:06:04,419 --> 00:06:12,390
that he wanted to show to set the set

146
00:06:07,300 --> 00:06:12,390
the context here are they showing no

147
00:06:16,310 --> 00:06:19,310
okay

148
00:06:20,120 --> 00:06:26,370
you can hear me right okay right thanks

149
00:06:24,870 --> 00:06:29,879
a lot professor Nevel for the

150
00:06:26,370 --> 00:06:32,099
introductions I will be talking about

151
00:06:29,879 --> 00:06:35,370
the application of AI to security there

152
00:06:32,099 --> 00:06:37,949
is a lot of work on securing AI but I'll

153
00:06:35,370 --> 00:06:42,770
be talking about the other other side of

154
00:06:37,949 --> 00:06:45,900
things so I am the PI of a new DARPA

155
00:06:42,770 --> 00:06:48,389
project in the new program called

156
00:06:45,900 --> 00:06:50,609
configuration security and there the

157
00:06:48,389 --> 00:06:53,270
problem is that you know these IOT

158
00:06:50,610 --> 00:06:55,889
infrastructure is being is being built

159
00:06:53,270 --> 00:06:58,799
with you know much larger number of

160
00:06:55,889 --> 00:07:02,330
devices than the 40,000 routers that was

161
00:06:58,800 --> 00:07:05,130
mentioned earlier GRA Rothrock stock

162
00:07:02,330 --> 00:07:06,930
configuration errors it's well well

163
00:07:05,130 --> 00:07:08,460
known and well documented that they

164
00:07:06,930 --> 00:07:12,060
account for about 80 percent of your

165
00:07:08,460 --> 00:07:13,229
downtime and vulnerabilities and that's

166
00:07:12,060 --> 00:07:15,719
going to be even worse

167
00:07:13,229 --> 00:07:17,878
problems for IOT so the configuration

168
00:07:15,719 --> 00:07:18,539
security program is to figure out what

169
00:07:17,879 --> 00:07:20,099
to do about it

170
00:07:18,539 --> 00:07:26,400
I know how to eliminate configuration

171
00:07:20,099 --> 00:07:29,669
errors ideally but they are posing a

172
00:07:26,400 --> 00:07:31,529
somewhat well this is my opinion that

173
00:07:29,669 --> 00:07:33,900
somewhat easier problem then because

174
00:07:31,529 --> 00:07:37,800
eliminating configuration errors is an

175
00:07:33,900 --> 00:07:39,479
open-ended problem is so to minimize the

176
00:07:37,800 --> 00:07:42,060
attack surface the configuration attack

177
00:07:39,479 --> 00:07:44,520
surface that is can we give just enough

178
00:07:42,060 --> 00:07:46,440
permissions to the devices so that their

179
00:07:44,520 --> 00:07:48,270
job is done and they can do their job so

180
00:07:46,440 --> 00:07:50,130
that's why they want to minimize the iit

181
00:07:48,270 --> 00:07:51,539
configuration attack surface but while

182
00:07:50,130 --> 00:07:52,889
preserving functionality right

183
00:07:51,539 --> 00:07:54,389
preserving functionality is important

184
00:07:52,889 --> 00:07:56,069
because functionality is not important

185
00:07:54,389 --> 00:08:03,240
then to switch off all the devices and

186
00:07:56,069 --> 00:08:06,240
no cyber attack is possible so so my

187
00:08:03,240 --> 00:08:09,539
project is on applying AI techniques to

188
00:08:06,240 --> 00:08:12,569
solve that problem and there are a

189
00:08:09,539 --> 00:08:14,250
couple of interesting and

190
00:08:12,569 --> 00:08:18,229
thought-provoking reads in this area

191
00:08:14,250 --> 00:08:21,300
before we try to apply AI one one one

192
00:08:18,229 --> 00:08:23,399
essay is by Kesha Pinkney ITT Austin

193
00:08:21,300 --> 00:08:25,860
it says the unreasonable effectiveness

194
00:08:23,399 --> 00:08:28,199
of machine learning in computer systems

195
00:08:25,860 --> 00:08:28,530
research so he is underwhelmed by all

196
00:08:28,199 --> 00:08:32,070
the

197
00:08:28,530 --> 00:08:34,968
of AI two computer systems research

198
00:08:32,070 --> 00:08:40,409
which would I think is his area is

199
00:08:34,969 --> 00:08:41,599
programming languages and so what he's

200
00:08:40,409 --> 00:08:44,610
saying is that while there have been

201
00:08:41,599 --> 00:08:46,650
some some interesting applications but

202
00:08:44,610 --> 00:08:48,840
there is nothing mind-boggling like

203
00:08:46,650 --> 00:08:50,370
self-driving cars and in urban

204
00:08:48,840 --> 00:08:51,780
environments so he wants have the

205
00:08:50,370 --> 00:08:53,970
equivalent of that he hasn't seen that

206
00:08:51,780 --> 00:08:58,130
and Betty yes does give some ideas as to

207
00:08:53,970 --> 00:09:02,490
what what that would mean and the second

208
00:08:58,130 --> 00:09:05,939
sobering somewhat sobering article is by

209
00:09:02,490 --> 00:09:07,620
Robin summer and one PacSun called

210
00:09:05,940 --> 00:09:09,390
outside the closed world on using

211
00:09:07,620 --> 00:09:12,680
machine learning for network intrusion

212
00:09:09,390 --> 00:09:16,980
detection and there the idea is that

213
00:09:12,680 --> 00:09:19,699
this whole whole concept of making a

214
00:09:16,980 --> 00:09:23,210
machine learn normal behavior and then

215
00:09:19,700 --> 00:09:26,820
you know using that to detect

216
00:09:23,210 --> 00:09:29,040
abnormality and therefore detection of a

217
00:09:26,820 --> 00:09:30,690
zero-day attack they are skeptical about

218
00:09:29,040 --> 00:09:32,250
that whole thing because machine

219
00:09:30,690 --> 00:09:35,370
learning requires both positive and

220
00:09:32,250 --> 00:09:36,990
negative examples to be effective so if

221
00:09:35,370 --> 00:09:42,930
you just give it positive examples then

222
00:09:36,990 --> 00:09:44,970
it may not may not work so science

223
00:09:42,930 --> 00:09:48,650
advances by producing counter examples

224
00:09:44,970 --> 00:09:52,610
to conventional wisdom and so we are

225
00:09:48,650 --> 00:09:55,740
trying to apply AI in the following way

226
00:09:52,610 --> 00:09:56,880
when you say minimize IOT configuration

227
00:09:55,740 --> 00:09:58,830
rock surface while preserving

228
00:09:56,880 --> 00:10:00,480
functionality this seems like an

229
00:09:58,830 --> 00:10:02,040
optimization problem right or the

230
00:10:00,480 --> 00:10:05,400
optimization engines they solve exactly

231
00:10:02,040 --> 00:10:06,630
this problem of minimize or maximize an

232
00:10:05,400 --> 00:10:08,910
objective function subject to

233
00:10:06,630 --> 00:10:10,860
constraints so if you can cost this

234
00:10:08,910 --> 00:10:12,900
problem as an optimization problem then

235
00:10:10,860 --> 00:10:16,740
we can use very off the shelf very

236
00:10:12,900 --> 00:10:24,180
powerful optimization engines like you

237
00:10:16,740 --> 00:10:26,430
heard of simplex and so let me sketch to

238
00:10:24,180 --> 00:10:30,109
you how we are trying to do that what

239
00:10:26,430 --> 00:10:33,390
are approaches the next like this okay

240
00:10:30,110 --> 00:10:36,089
so one of the central ideas is that of a

241
00:10:33,390 --> 00:10:38,100
scoring function and this is related to

242
00:10:36,089 --> 00:10:40,050
the resilience core that Rothrock was

243
00:10:38,100 --> 00:10:40,950
mentioning so given a configuration of a

244
00:10:40,050 --> 00:10:43,530
system can

245
00:10:40,950 --> 00:10:46,470
I give a score to it as to how

246
00:10:43,530 --> 00:10:48,089
vulnerable it is and then whether it can

247
00:10:46,470 --> 00:10:49,980
deliver the functionality or not this is

248
00:10:48,090 --> 00:10:52,590
like a building code so you build up

249
00:10:49,980 --> 00:10:55,260
build a building according to code and

250
00:10:52,590 --> 00:10:57,750
then no matter how these well the

251
00:10:55,260 --> 00:10:59,160
subject subject of constraints that

252
00:10:57,750 --> 00:11:00,210
regardless of how the stresses are

253
00:10:59,160 --> 00:11:02,880
placed on the building is going to

254
00:11:00,210 --> 00:11:04,980
deliver some functionality or some

255
00:11:02,880 --> 00:11:07,950
assurance measure ins properties it's a

256
00:11:04,980 --> 00:11:09,270
similar idea and so the critical ID

257
00:11:07,950 --> 00:11:12,330
critical thing is that we are not

258
00:11:09,270 --> 00:11:14,220
modeling adversary behavior we are only

259
00:11:12,330 --> 00:11:15,920
looking at a configuration and scoring

260
00:11:14,220 --> 00:11:19,200
it according to functionality and

261
00:11:15,920 --> 00:11:21,390
vulnerability and then we model the

262
00:11:19,200 --> 00:11:26,610
attack surface as an objective function

263
00:11:21,390 --> 00:11:28,350
on these course so and then and then the

264
00:11:26,610 --> 00:11:30,720
functionality requirement is just a

265
00:11:28,350 --> 00:11:36,110
predicate on on these scores and now we

266
00:11:30,720 --> 00:11:38,670
can use the the existing the DMI

267
00:11:36,110 --> 00:11:41,070
optimization engines now the critical

268
00:11:38,670 --> 00:11:42,930
question is how do you figure out what

269
00:11:41,070 --> 00:11:44,790
the scoring function is so there's

270
00:11:42,930 --> 00:11:47,819
that's where AI comes in we can learn

271
00:11:44,790 --> 00:11:50,310
this function through simulation so we

272
00:11:47,820 --> 00:11:54,660
have a system B and simulators are

273
00:11:50,310 --> 00:11:58,050
available so we drive it with lots of

274
00:11:54,660 --> 00:12:01,740
different configurations and we you know

275
00:11:58,050 --> 00:12:03,900
evaluate this course and then we collect

276
00:12:01,740 --> 00:12:07,140
the training data and we pass that to a

277
00:12:03,900 --> 00:12:10,160
neural network learning engine and

278
00:12:07,140 --> 00:12:12,840
produce a neural network and then a

279
00:12:10,160 --> 00:12:15,689
neural network can be converted into a

280
00:12:12,840 --> 00:12:19,200
mixed integer linear program how many of

281
00:12:15,690 --> 00:12:24,270
you are familiar with that idea okay

282
00:12:19,200 --> 00:12:27,870
right so one so this is not commonly

283
00:12:24,270 --> 00:12:28,949
known but but it's actually quite well

284
00:12:27,870 --> 00:12:31,650
understood for people who do

285
00:12:28,950 --> 00:12:33,270
verification of neural networks so

286
00:12:31,650 --> 00:12:35,390
neural networks of course with the

287
00:12:33,270 --> 00:12:37,949
activation function will call r lu

288
00:12:35,390 --> 00:12:40,980
rectified linear unit which is quite

289
00:12:37,950 --> 00:12:44,540
quite powerful so you can convert any

290
00:12:40,980 --> 00:12:47,130
neural network with r lu into an ILP and

291
00:12:44,540 --> 00:12:48,599
now you can use the

292
00:12:47,130 --> 00:12:51,960
you know you learned the scoring

293
00:12:48,600 --> 00:12:54,240
function with as an as an neural network

294
00:12:51,960 --> 00:12:56,220
enhance nm ILP and then you formulate

295
00:12:54,240 --> 00:13:01,050
your objective function and then you can

296
00:12:56,220 --> 00:13:04,590
use an mi LP solver to resolve to

297
00:13:01,050 --> 00:13:07,380
produce a configuration that minimizes

298
00:13:04,590 --> 00:13:10,260
the attack surface and preserves the

299
00:13:07,380 --> 00:13:17,310
functionality so we are not modeling the

300
00:13:10,260 --> 00:13:19,230
adversary behavior and and yet we are

301
00:13:17,310 --> 00:13:21,119
able to solve the inverse problem that

302
00:13:19,230 --> 00:13:23,760
if you're given a so now you can say I

303
00:13:21,120 --> 00:13:26,700
given this III want a configuration

304
00:13:23,760 --> 00:13:28,260
given this score so the mi LP solver

305
00:13:26,700 --> 00:13:29,700
will produce that for you because it

306
00:13:28,260 --> 00:13:31,620
does not make any distinctions between

307
00:13:29,700 --> 00:13:33,180
input and output variables they're only

308
00:13:31,620 --> 00:13:37,950
constraints so it just solves that

309
00:13:33,180 --> 00:13:40,589
constraints so you can solve the the the

310
00:13:37,950 --> 00:13:43,260
inverse problem you know you have a

311
00:13:40,590 --> 00:13:45,450
resilience core for example you want to

312
00:13:43,260 --> 00:13:47,700
say okay how should I I know what my

313
00:13:45,450 --> 00:13:49,350
system has a bad resilience core now how

314
00:13:47,700 --> 00:13:52,770
should I reconfigure my system so this

315
00:13:49,350 --> 00:14:10,290
approach could attack that problem so

316
00:13:52,770 --> 00:14:13,170
that's what I have to say thank you okay

317
00:14:10,290 --> 00:14:16,040
so anyway from a different perspective

318
00:14:13,170 --> 00:14:18,990
so North Grumman there's a large-scale

319
00:14:16,040 --> 00:14:22,079
systems integrator and the biggest

320
00:14:18,990 --> 00:14:26,100
problems that I perceived in this whole

321
00:14:22,080 --> 00:14:29,010
domain is the the convergence of

322
00:14:26,100 --> 00:14:31,890
cybersecurity artificial intelligence

323
00:14:29,010 --> 00:14:34,380
advanced analytics is really changing

324
00:14:31,890 --> 00:14:37,710
and creating a whole new paradigm on how

325
00:14:34,380 --> 00:14:40,470
we conduct cyber operations and adding

326
00:14:37,710 --> 00:14:43,470
to that the ability to build autonomous

327
00:14:40,470 --> 00:14:47,100
systems that require near real-time

328
00:14:43,470 --> 00:14:48,780
dynamic decision-making in an

329
00:14:47,100 --> 00:14:50,940
environment that we don't really

330
00:14:48,780 --> 00:14:54,150
understand what all the attack surface

331
00:14:50,940 --> 00:14:56,460
and all the possible defects are and we

332
00:14:54,150 --> 00:15:00,750
have to create mission critical systems

333
00:14:56,460 --> 00:15:03,270
and so one of the things I do I work

334
00:15:00,750 --> 00:15:07,800
with a joint collaborative industry

335
00:15:03,270 --> 00:15:09,780
government technical group sponsored by

336
00:15:07,800 --> 00:15:11,760
the Atia Association that's the advanced

337
00:15:09,780 --> 00:15:13,230
technical intelligence Association and

338
00:15:11,760 --> 00:15:16,050
with the office of director national

339
00:15:13,230 --> 00:15:17,730
intelligence odni and some of you might

340
00:15:16,050 --> 00:15:20,010
might have heard of the instep program

341
00:15:17,730 --> 00:15:22,560
but that's the intelligence Science and

342
00:15:20,010 --> 00:15:24,930
Technology partnership so when we get

343
00:15:22,560 --> 00:15:27,449
together if we ask questions like this

344
00:15:24,930 --> 00:15:29,520
you know across the industry what are

345
00:15:27,450 --> 00:15:31,470
our biggest problems and when you deal

346
00:15:29,520 --> 00:15:35,030
with large systems so our biggest

347
00:15:31,470 --> 00:15:37,530
problems I believe are very large-scale

348
00:15:35,030 --> 00:15:40,620
heterogeneous systems that cross

349
00:15:37,530 --> 00:15:42,650
multiple domains that have to operate in

350
00:15:40,620 --> 00:15:45,780
chaotic environments whether it's a

351
00:15:42,650 --> 00:15:49,410
wartime environment for military systems

352
00:15:45,780 --> 00:15:52,199
or if it's a human human you manatorian

353
00:15:49,410 --> 00:15:55,260
relief operation and so forth and you're

354
00:15:52,200 --> 00:15:57,360
operating across boundaries of you know

355
00:15:55,260 --> 00:15:59,819
thousands of different nodes of

356
00:15:57,360 --> 00:16:02,310
different modalities of extremely high

357
00:15:59,820 --> 00:16:05,700
volumes of data that has to be decided

358
00:16:02,310 --> 00:16:09,060
on very quickly now part of the problem

359
00:16:05,700 --> 00:16:10,920
is that decision-making in a very

360
00:16:09,060 --> 00:16:13,760
sensitive operation can't be done

361
00:16:10,920 --> 00:16:16,740
autonomously you have to do it with the

362
00:16:13,760 --> 00:16:19,620
final approval of a commander or a human

363
00:16:16,740 --> 00:16:21,839
decision maker so if you think about the

364
00:16:19,620 --> 00:16:25,110
ability to how humans would interact

365
00:16:21,839 --> 00:16:28,830
with machines in the context of being

366
00:16:25,110 --> 00:16:31,320
secure in a cyber security sense that

367
00:16:28,830 --> 00:16:33,270
changes how we operate so one of the

368
00:16:31,320 --> 00:16:35,839
things that we're sort of working on

369
00:16:33,270 --> 00:16:38,189
with this collective community is

370
00:16:35,839 --> 00:16:40,920
understanding what the right level of

371
00:16:38,190 --> 00:16:43,440
cyber security is to accomplish the

372
00:16:40,920 --> 00:16:46,650
mission objectives and the right level

373
00:16:43,440 --> 00:16:48,750
of AI so going into any new forum I

374
00:16:46,650 --> 00:16:50,760
think one of the biggest issues from the

375
00:16:48,750 --> 00:16:53,220
first five seconds is defining a

376
00:16:50,760 --> 00:16:55,950
taxonomy that we all got agree on across

377
00:16:53,220 --> 00:16:57,780
the board so no object just as a case in

378
00:16:55,950 --> 00:17:00,440
point Northrop Grumman is a large

379
00:16:57,780 --> 00:17:03,000
company so one of our sectors builds you

380
00:17:00,440 --> 00:17:04,290
unmanned vehicle platforms a Global Hawk

381
00:17:03,000 --> 00:17:05,699
this afternoon and I'm actually on the

382
00:17:04,290 --> 00:17:08,760
agenda that presents they'll have some

383
00:17:05,699 --> 00:17:10,770
videos and and some graphics of it the

384
00:17:08,760 --> 00:17:12,839
Information Systems sector which became

385
00:17:10,770 --> 00:17:15,180
mission system sector is building

386
00:17:12,839 --> 00:17:16,770
large-scale enterprise systems so now

387
00:17:15,180 --> 00:17:20,040
when you go in and say what do you mean

388
00:17:16,770 --> 00:17:21,510
by autonomy the aerospace systems sector

389
00:17:20,040 --> 00:17:24,810
is going to talk about you know unmanned

390
00:17:21,510 --> 00:17:26,160
airborne autonomous vehicles when you

391
00:17:24,810 --> 00:17:29,419
ask somebody from the information

392
00:17:26,160 --> 00:17:32,040
technology domain they're going to say

393
00:17:29,420 --> 00:17:33,870
large-scale network enterprises with

394
00:17:32,040 --> 00:17:36,450
software-defined networking that could

395
00:17:33,870 --> 00:17:38,820
resilient resilient leary constitute

396
00:17:36,450 --> 00:17:41,310
communications against cyber threats so

397
00:17:38,820 --> 00:17:42,990
the very same question and the very same

398
00:17:41,310 --> 00:17:45,560
nomenclature autonomy means whole

399
00:17:42,990 --> 00:17:49,380
different things so so the idea of

400
00:17:45,560 --> 00:17:51,600
effective mission operations also

401
00:17:49,380 --> 00:17:54,560
implies what we really need to do for

402
00:17:51,600 --> 00:17:57,990
mission objectives and cybersecurity

403
00:17:54,560 --> 00:18:00,030
could mean something very different if

404
00:17:57,990 --> 00:18:02,580
you put a mission context around it so

405
00:18:00,030 --> 00:18:04,320
in other words if you say we have some

406
00:18:02,580 --> 00:18:06,689
sort of military campaign that's going

407
00:18:04,320 --> 00:18:09,600
to last a half an hour until we you know

408
00:18:06,690 --> 00:18:11,310
take out some threat then security only

409
00:18:09,600 --> 00:18:13,409
needs to last a half an hour it doesn't

410
00:18:11,310 --> 00:18:15,659
have to last for all archival storage

411
00:18:13,410 --> 00:18:17,820
time so then that changes the

412
00:18:15,660 --> 00:18:19,530
methodology you changes the mathematics

413
00:18:17,820 --> 00:18:21,899
it changes the algorithm it changes the

414
00:18:19,530 --> 00:18:24,389
concept of operation so without the

415
00:18:21,900 --> 00:18:27,840
context of what we're trying to do with

416
00:18:24,390 --> 00:18:30,180
our operations and and a large-scale

417
00:18:27,840 --> 00:18:32,550
systems it's very hard to talk about

418
00:18:30,180 --> 00:18:33,810
what the right cybersecurity solution is

419
00:18:32,550 --> 00:18:35,870
and what the right to artificial

420
00:18:33,810 --> 00:18:38,220
intelligence I mean machine learning

421
00:18:35,870 --> 00:18:40,110
enabler would be to help achieve those

422
00:18:38,220 --> 00:18:43,200
goals so anyway so that's the whole

423
00:18:40,110 --> 00:18:45,740
thing the operationalization the the

424
00:18:43,200 --> 00:18:49,410
whole conceptualization of how you

425
00:18:45,740 --> 00:18:52,380
incorporate AI cyber security advanced

426
00:18:49,410 --> 00:18:56,010
machine learning within a mission

427
00:18:52,380 --> 00:18:57,780
context and in the whole ecosystem that

428
00:18:56,010 --> 00:19:00,000
goes along with it in terms of how one

429
00:18:57,780 --> 00:19:03,000
does designs how one's does validation

430
00:19:00,000 --> 00:19:05,690
how orders they should do post auditing

431
00:19:03,000 --> 00:19:08,430
of results and it's a continuously

432
00:19:05,690 --> 00:19:11,010
regenerative cycle and it's not one

433
00:19:08,430 --> 00:19:12,420
solution and on a chaotic campaign where

434
00:19:11,010 --> 00:19:15,120
something is happening in near real-time

435
00:19:12,420 --> 00:19:16,920
and a chaotic environment the dynamics

436
00:19:15,120 --> 00:19:21,479
are really in terms of seconds and

437
00:19:16,920 --> 00:19:26,090
minutes and not years and decades so so

438
00:19:21,480 --> 00:19:26,090
I pass pass off somebody's refer to you

439
00:19:29,040 --> 00:19:32,770
[Applause]

440
00:19:41,009 --> 00:19:49,480
good morning everyone can you hear me

441
00:19:43,889 --> 00:19:52,330
right so if we look at the trend of our

442
00:19:49,480 --> 00:19:53,710
last several decades in computing to

443
00:19:52,330 --> 00:19:55,840
today what is happening there on one

444
00:19:53,710 --> 00:19:58,389
side we have data and knowledge the

445
00:19:55,840 --> 00:20:01,209
other side we have computing but now

446
00:19:58,389 --> 00:20:03,340
there is a tipping point that has come

447
00:20:01,210 --> 00:20:05,080
up about intelligence you know so you

448
00:20:03,340 --> 00:20:07,330
look at the whole triangulation about it

449
00:20:05,080 --> 00:20:09,519
we are moving in the direction of really

450
00:20:07,330 --> 00:20:12,039
excited about intelligence right what

451
00:20:09,519 --> 00:20:14,470
can we do with intelligence which is

452
00:20:12,039 --> 00:20:16,690
artificial intelligence I remember when

453
00:20:14,470 --> 00:20:19,750
I was an undergrad in a top school in

454
00:20:16,690 --> 00:20:22,629
India one of my professors art why do we

455
00:20:19,750 --> 00:20:25,059
need AI artificial intelligence you know

456
00:20:22,629 --> 00:20:27,428
and it was a tough question to ask their

457
00:20:25,059 --> 00:20:30,100
time there are several answers part of

458
00:20:27,429 --> 00:20:33,730
answers there are several answers to it

459
00:20:30,100 --> 00:20:35,529
but now the answers come very very

460
00:20:33,730 --> 00:20:38,200
easily when you look at another

461
00:20:35,529 --> 00:20:41,139
dimension of what we produce out of

462
00:20:38,200 --> 00:20:44,350
these three triangulated attributes

463
00:20:41,139 --> 00:20:46,059
right we are we have data centers huge

464
00:20:44,350 --> 00:20:48,699
data centers on one one side of the

465
00:20:46,059 --> 00:20:52,870
spectrum we have IOT devices very

466
00:20:48,700 --> 00:20:57,100
miniaturized IOT devices on another side

467
00:20:52,870 --> 00:20:58,989
and what we are also building cyber

468
00:20:57,100 --> 00:21:01,928
physical systems which are mobile like

469
00:20:58,990 --> 00:21:04,750
autonomous self-driving cars right if we

470
00:21:01,929 --> 00:21:07,090
look at all these two different trends

471
00:21:04,750 --> 00:21:11,279
happening in in the whole area

472
00:21:07,090 --> 00:21:15,428
it is really leading us to think that

473
00:21:11,279 --> 00:21:17,500
that there is a real need for moving in

474
00:21:15,429 --> 00:21:20,769
this direction of Intel artificial

475
00:21:17,500 --> 00:21:24,700
intelligence and machine learning but

476
00:21:20,769 --> 00:21:29,289
its security still needed you know and I

477
00:21:24,700 --> 00:21:32,230
remember when I graduated from computer

478
00:21:29,289 --> 00:21:33,730
science and serious and joined IBM TJ

479
00:21:32,230 --> 00:21:36,879
Watson Research Center one of the

480
00:21:33,730 --> 00:21:39,740
tagline I pour there in my door is that

481
00:21:36,879 --> 00:21:43,189
security is a new functionality

482
00:21:39,740 --> 00:21:45,140
and I think at some point where we are

483
00:21:43,190 --> 00:21:48,440
already thinking security is the new

484
00:21:45,140 --> 00:21:50,300
functionality intelligence will totally

485
00:21:48,440 --> 00:21:51,710
be today as a human being right we

486
00:21:50,300 --> 00:21:54,530
always think about our safety and

487
00:21:51,710 --> 00:21:57,140
security right most of our intelligence

488
00:21:54,530 --> 00:21:59,510
goes about protecting that protecting

489
00:21:57,140 --> 00:22:02,630
the data knowledge and the materials we

490
00:21:59,510 --> 00:22:04,040
have acquired so security is the new

491
00:22:02,630 --> 00:22:06,320
functionality will continue to be

492
00:22:04,040 --> 00:22:09,830
whether it is AI quantum computing

493
00:22:06,320 --> 00:22:11,659
whatever not it is so therefore it is it

494
00:22:09,830 --> 00:22:13,790
is a great pleasure and honor for me to

495
00:22:11,660 --> 00:22:16,310
come back here as an alumnus and talk

496
00:22:13,790 --> 00:22:20,840
about it now if we look at what are the

497
00:22:16,310 --> 00:22:22,909
threats right the threats are the threat

498
00:22:20,840 --> 00:22:24,590
landscape is changing a lot from

499
00:22:22,910 --> 00:22:26,570
academic scenario the different threat

500
00:22:24,590 --> 00:22:28,429
landscape is basically highly

501
00:22:26,570 --> 00:22:30,830
sophisticated and complicated in terms

502
00:22:28,430 --> 00:22:34,390
of coming up with new cryptanalysis

503
00:22:30,830 --> 00:22:38,320
attacks adversarial machine learning

504
00:22:34,390 --> 00:22:40,520
agile is for example membership attacks

505
00:22:38,320 --> 00:22:42,830
breaching privacy of machine learning

506
00:22:40,520 --> 00:22:46,129
models and training data but if you look

507
00:22:42,830 --> 00:22:48,830
at real-world scenarios right it is that

508
00:22:46,130 --> 00:22:52,250
it is that weak it is a weakest link in

509
00:22:48,830 --> 00:22:54,110
the system still is the problem we

510
00:22:52,250 --> 00:22:56,630
questioning you look at configuration

511
00:22:54,110 --> 00:22:59,330
problems right the databases you look at

512
00:22:56,630 --> 00:23:02,360
Experian they talked about that the

513
00:22:59,330 --> 00:23:05,810
database password was default there are

514
00:23:02,360 --> 00:23:08,510
so many recently there was hard drives

515
00:23:05,810 --> 00:23:10,879
iris and Jordan is a IOT search engine

516
00:23:08,510 --> 00:23:14,570
okay and you go there you can search for

517
00:23:10,880 --> 00:23:16,940
hard drives scuzzy hard drives which are

518
00:23:14,570 --> 00:23:18,260
available on the internet with no

519
00:23:16,940 --> 00:23:21,590
authentication require or default

520
00:23:18,260 --> 00:23:24,230
authentication required right so the

521
00:23:21,590 --> 00:23:26,629
weakest link is is not essentially the

522
00:23:24,230 --> 00:23:30,310
highly evolved threat landscape it is

523
00:23:26,630 --> 00:23:32,360
now it can be the configuration the the

524
00:23:30,310 --> 00:23:34,580
programming language artifacts that we

525
00:23:32,360 --> 00:23:36,709
are not giving out time to I will give

526
00:23:34,580 --> 00:23:38,860
one example here that I did enough since

527
00:23:36,710 --> 00:23:41,560
there are many students here to

528
00:23:38,860 --> 00:23:43,669
encourage you not to just think about

529
00:23:41,560 --> 00:23:46,399
complicated attack scenarios but also

530
00:23:43,670 --> 00:23:47,420
think about how do you break into a

531
00:23:46,400 --> 00:23:48,890
system okay

532
00:23:47,420 --> 00:23:51,380
and then think about building a

533
00:23:48,890 --> 00:23:52,890
technology from that side and that will

534
00:23:51,380 --> 00:23:57,390
help you a lot

535
00:23:52,890 --> 00:24:01,530
in 2010 I after my internship I learned

536
00:23:57,390 --> 00:24:04,820
that C++ has a vulnerability called has

537
00:24:01,530 --> 00:24:07,800
a construct called placement knew and

538
00:24:04,820 --> 00:24:09,990
placement knew can be used to carry out

539
00:24:07,800 --> 00:24:11,909
whole lot of buffer overflow attacks I

540
00:24:09,990 --> 00:24:13,860
thought people might have discovered it

541
00:24:11,910 --> 00:24:15,660
already it has been two decades or more

542
00:24:13,860 --> 00:24:17,399
the buffer overflow has been talked

543
00:24:15,660 --> 00:24:19,230
about interestingly there was not a

544
00:24:17,400 --> 00:24:21,570
single paper talking about placement new

545
00:24:19,230 --> 00:24:23,610
attacks I wrote a paper we went into top

546
00:24:21,570 --> 00:24:26,370
confirm and then GCC released a patch on

547
00:24:23,610 --> 00:24:27,719
that right still there are many more

548
00:24:26,370 --> 00:24:30,689
things to be done so I would encourage

549
00:24:27,720 --> 00:24:33,300
all of you to while taking taking a look

550
00:24:30,690 --> 00:24:35,010
at a really complex attack scenarios and

551
00:24:33,300 --> 00:24:37,350
technologies to develop around cyber

552
00:24:35,010 --> 00:24:40,230
security look at in real systems what

553
00:24:37,350 --> 00:24:40,469
are the issues and build around it as

554
00:24:40,230 --> 00:24:45,450
well

555
00:24:40,470 --> 00:24:49,430
I think I'll pause there thank you

556
00:24:45,450 --> 00:24:54,020
[Applause]

557
00:24:49,430 --> 00:24:57,360
okay I'll take care of it let me drive

558
00:24:54,020 --> 00:25:00,180
I'm gonna be the Chimera mudgin I come

559
00:24:57,360 --> 00:25:02,550
to this out of the data mining machine

560
00:25:00,180 --> 00:25:04,290
learning community database you know

561
00:25:02,550 --> 00:25:07,110
dealing dealing with the information

562
00:25:04,290 --> 00:25:11,820
first and then moving towards security

563
00:25:07,110 --> 00:25:17,879
and point out the difficulties of using

564
00:25:11,820 --> 00:25:23,879
AI in security AI machine learning

565
00:25:17,880 --> 00:25:26,810
techniques are very good at discovering

566
00:25:23,880 --> 00:25:33,770
discovering general truths discovering

567
00:25:26,810 --> 00:25:37,020
things that apply most of the time in

568
00:25:33,770 --> 00:25:40,290
security often what we're fighting

569
00:25:37,020 --> 00:25:47,040
against is an adversary who's finding

570
00:25:40,290 --> 00:25:49,440
that one little weak spot that you know

571
00:25:47,040 --> 00:25:53,340
that little niche where you can get

572
00:25:49,440 --> 00:25:57,930
things through most of our system is

573
00:25:53,340 --> 00:26:00,270
secure you know can't break in and if

574
00:25:57,930 --> 00:26:04,470
we're not careful and we try to apply

575
00:26:00,270 --> 00:26:06,420
machine learning that's what we get most

576
00:26:04,470 --> 00:26:09,810
of our system is secure

577
00:26:06,420 --> 00:26:13,380
just like it is today but there's gonna

578
00:26:09,810 --> 00:26:17,000
be those few little holes there is an

579
00:26:13,380 --> 00:26:20,160
area of machine learning known as

580
00:26:17,000 --> 00:26:22,020
adversarial machine learning a lot of

581
00:26:20,160 --> 00:26:24,600
that work has been how do we develop

582
00:26:22,020 --> 00:26:28,620
techniques to break machine learning and

583
00:26:24,600 --> 00:26:30,570
they're becoming very effective also

584
00:26:28,620 --> 00:26:33,060
techniques to protect against that and

585
00:26:30,570 --> 00:26:34,669
then I got to thank Paul and Northrop

586
00:26:33,060 --> 00:26:38,090
Grumman there are several of us working

587
00:26:34,670 --> 00:26:40,130
on this area

588
00:26:38,090 --> 00:26:42,830
collaborating with Northrop Grumman

589
00:26:40,130 --> 00:26:47,100
specifically and how do we defend

590
00:26:42,830 --> 00:26:50,159
against these attacks the I'm sure many

591
00:26:47,100 --> 00:26:53,730
of you seen a very visible one which is

592
00:26:50,160 --> 00:26:55,770
a stop sign that people put some

593
00:26:53,730 --> 00:26:59,010
stickers on the stop sign and all of a

594
00:26:55,770 --> 00:27:03,450
sudden these image recognition systems

595
00:26:59,010 --> 00:27:06,629
see a speed limit sign we as humans

596
00:27:03,450 --> 00:27:10,800
don't but that AI they've found a little

597
00:27:06,630 --> 00:27:18,330
weak spot in there where you know it's

598
00:27:10,800 --> 00:27:22,110
completely off that said there are ways

599
00:27:18,330 --> 00:27:26,010
where we can use AI machine learning

600
00:27:22,110 --> 00:27:28,530
techniques we have to just be very

601
00:27:26,010 --> 00:27:31,350
careful about thinking about what they

602
00:27:28,530 --> 00:27:34,830
do for us and I will say this is

603
00:27:31,350 --> 00:27:39,030
something that serious has been very

604
00:27:34,830 --> 00:27:44,540
active and very involved in and just to

605
00:27:39,030 --> 00:27:46,879
give an idea this was a serious seminar

606
00:27:44,540 --> 00:27:52,940
developing custom intrusion detection

607
00:27:46,880 --> 00:27:56,130
filters using data mining this is a

608
00:27:52,940 --> 00:27:59,280
seminar talking about using machine

609
00:27:56,130 --> 00:28:05,280
learning techniques but what we did in

610
00:27:59,280 --> 00:28:07,950
this was looked not at developing

611
00:28:05,280 --> 00:28:09,870
completely autonomous systems some

612
00:28:07,950 --> 00:28:11,580
system that's gonna find things for us

613
00:28:09,870 --> 00:28:15,629
automatically and we don't have to worry

614
00:28:11,580 --> 00:28:18,649
about how it works it was to help us as

615
00:28:15,630 --> 00:28:21,650
humans to sift through

616
00:28:18,650 --> 00:28:23,600
to go through and say here's the things

617
00:28:21,650 --> 00:28:26,120
that you should you know that it looks

618
00:28:23,600 --> 00:28:32,779
like you can safely ignore let's develop

619
00:28:26,120 --> 00:28:38,029
some human vetted rules to quickly build

620
00:28:32,779 --> 00:28:40,570
intrusion detection systems for those of

621
00:28:38,029 --> 00:28:43,730
you haven't figured out from the picture

622
00:28:40,570 --> 00:28:46,820
notice the date when Sirius was looking

623
00:28:43,730 --> 00:28:49,850
at things like this almost twenty years

624
00:28:46,820 --> 00:28:53,720
ago so you're in the right place for

625
00:28:49,850 --> 00:28:57,860
this and in fact do we have any serious

626
00:28:53,720 --> 00:29:02,659
alumni from around that time this was a

627
00:28:57,860 --> 00:29:06,158
course offered in 2001 looking at using

628
00:29:02,659 --> 00:29:10,760
machine learning techniques in security

629
00:29:06,159 --> 00:29:13,669
so this is this is nothing new for

630
00:29:10,760 --> 00:29:15,350
serious I want to you know point out

631
00:29:13,669 --> 00:29:19,279
we've been thinking about this for a

632
00:29:15,350 --> 00:29:22,399
long time making a lot of progress but

633
00:29:19,279 --> 00:29:24,409
we have to be very careful many people

634
00:29:22,399 --> 00:29:28,489
who get into machine learning today look

635
00:29:24,409 --> 00:29:32,330
at this wonderful technology that just

636
00:29:28,490 --> 00:29:36,980
seems to solve all these problems people

637
00:29:32,330 --> 00:29:41,389
think of this as as you know was pointed

638
00:29:36,980 --> 00:29:44,659
out a lot of people the you know Sanjay

639
00:29:41,390 --> 00:29:46,850
pointed out some papers who looked at

640
00:29:44,659 --> 00:29:49,130
this as well you just get training data

641
00:29:46,850 --> 00:29:51,168
you go through your training data first

642
00:29:49,130 --> 00:29:52,580
thing he points out is you know we don't

643
00:29:51,169 --> 00:29:54,950
have good negative examples in the

644
00:29:52,580 --> 00:29:57,439
training data you know we don't have a

645
00:29:54,950 --> 00:29:59,779
we've got kind of one class for most of

646
00:29:57,440 --> 00:30:01,570
our examples yes there's machine

647
00:29:59,779 --> 00:30:04,370
learning techniques the deal with that

648
00:30:01,570 --> 00:30:07,250
we need to understand what they do and

649
00:30:04,370 --> 00:30:08,959
not just blindly assume that this new

650
00:30:07,250 --> 00:30:14,210
technology is going to solve all our

651
00:30:08,960 --> 00:30:19,039
problems so anyway on that note of being

652
00:30:14,210 --> 00:30:22,429
a bit of a curmudgeon there I'll I'll

653
00:30:19,039 --> 00:30:23,990
finish off and turn it over and we can

654
00:30:22,429 --> 00:30:33,560
get some questions going so

655
00:30:23,990 --> 00:30:36,050
I guess maybe I don't know if people

656
00:30:33,560 --> 00:30:39,710
have questions already teed up to ask

657
00:30:36,050 --> 00:30:41,780
people okay come on up I was gonna throw

658
00:30:39,710 --> 00:30:44,020
in the first question but I will hold

659
00:30:41,780 --> 00:30:44,020
off

660
00:31:02,910 --> 00:31:09,580
hello yeah we got you all right so my

661
00:31:07,660 --> 00:31:11,200
question when I talk about when I ask

662
00:31:09,580 --> 00:31:13,389
this question about security I'm

663
00:31:11,200 --> 00:31:16,150
thinking about public safety not

664
00:31:13,390 --> 00:31:19,270
necessarily about cyber security so so

665
00:31:16,150 --> 00:31:22,270
my question is on on AI thinking about

666
00:31:19,270 --> 00:31:25,300
it seems like we might not have a handle

667
00:31:22,270 --> 00:31:29,560
on the right applications for AI so my

668
00:31:25,300 --> 00:31:33,129
question as a scene setter what do you

669
00:31:29,560 --> 00:31:36,300
think about AI projects like project

670
00:31:33,130 --> 00:31:38,020
maven where Google was using AI

671
00:31:36,300 --> 00:31:40,030
potentially to help the Defense

672
00:31:38,020 --> 00:31:43,990
Department with potentially lethal

673
00:31:40,030 --> 00:31:46,899
actions what what is your opinion about

674
00:31:43,990 --> 00:31:52,470
the ethics of AI if you could comment on

675
00:31:46,900 --> 00:31:52,470
that okay

676
00:31:53,800 --> 00:32:03,639
so we are actually there's a great

677
00:31:59,180 --> 00:32:07,340
question you know so if we look at AI

678
00:32:03,640 --> 00:32:09,890
security privacy compliance they lie on

679
00:32:07,340 --> 00:32:12,320
one side and then you have safety and

680
00:32:09,890 --> 00:32:15,490
ethics they lie on the other side right

681
00:32:12,320 --> 00:32:18,050
and and they are not independent sets

682
00:32:15,490 --> 00:32:20,030
they're essentially there's a lot of

683
00:32:18,050 --> 00:32:21,830
intersection between them playing in the

684
00:32:20,030 --> 00:32:24,080
they're completely intersecting the

685
00:32:21,830 --> 00:32:27,800
sweet spot is always what everybody

686
00:32:24,080 --> 00:32:30,530
would like to work on I'm sure you must

687
00:32:27,800 --> 00:32:32,899
have seen that there has been a lot of

688
00:32:30,530 --> 00:32:35,300
discussion about AI thick's for example

689
00:32:32,900 --> 00:32:38,120
from IBM Research a couple of years back

690
00:32:35,300 --> 00:32:40,669
there was an AI ethics white paper that

691
00:32:38,120 --> 00:32:43,699
came out in fact I was contributing to

692
00:32:40,670 --> 00:32:45,830
that as part of the board recently

693
00:32:43,700 --> 00:32:48,050
Google started an ethics board and that

694
00:32:45,830 --> 00:32:51,710
dissolve it but the challenge is that

695
00:32:48,050 --> 00:32:54,399
ethics is highly context oriented right

696
00:32:51,710 --> 00:32:59,050
and when you dis solve a problem with AI

697
00:32:54,400 --> 00:33:01,430
right then the the challenge is about

698
00:32:59,050 --> 00:33:04,430
how do you protect it right and

699
00:33:01,430 --> 00:33:06,560
protection is something not that it in

700
00:33:04,430 --> 00:33:09,050
context oriented but the but it may not

701
00:33:06,560 --> 00:33:10,639
be aware of what the cultural

702
00:33:09,050 --> 00:33:13,760
requirement are things can be culturally

703
00:33:10,640 --> 00:33:15,320
driven ethics can be driven by the who

704
00:33:13,760 --> 00:33:17,870
is the adversary and who is not an

705
00:33:15,320 --> 00:33:21,110
adversary in a in a military area right

706
00:33:17,870 --> 00:33:24,649
so I guess there is a there's a role of

707
00:33:21,110 --> 00:33:27,889
game theory there you know to learn and

708
00:33:24,650 --> 00:33:30,470
and preserve the ethical model models of

709
00:33:27,890 --> 00:33:34,040
ethics and safety in terms of utility

710
00:33:30,470 --> 00:33:36,520
functions and and apply that value

711
00:33:34,040 --> 00:33:42,500
highly provide a game theoretic model of

712
00:33:36,520 --> 00:33:44,900
cybersecurity for ethics of that so yeah

713
00:33:42,500 --> 00:33:46,520
I'm familiar with maven and now sorry

714
00:33:44,900 --> 00:33:49,100
it's not considered dichotomy right when

715
00:33:46,520 --> 00:33:51,590
we talked about AI so I'd like to think

716
00:33:49,100 --> 00:33:54,199
of one side of it it's physics based AI

717
00:33:51,590 --> 00:33:57,260
and the other is human AI and what I

718
00:33:54,200 --> 00:34:00,170
mean by that is as I said before I got

719
00:33:57,260 --> 00:34:02,390
pretty good visibility over a wide swath

720
00:34:00,170 --> 00:34:04,850
of technology so now technology so all

721
00:34:02,390 --> 00:34:06,710
the way up to big systems and we're

722
00:34:04,850 --> 00:34:09,199
using machine learning and AI

723
00:34:06,710 --> 00:34:11,900
to compute optimum coefficients of

724
00:34:09,199 --> 00:34:13,759
waveforms for more effective radio

725
00:34:11,900 --> 00:34:16,310
communications for improving bandwidth

726
00:34:13,760 --> 00:34:17,540
efficiency okay so there's no human

727
00:34:16,310 --> 00:34:18,830
factor there you have noise in the

728
00:34:17,540 --> 00:34:22,130
environment and you have to make sure

729
00:34:18,830 --> 00:34:23,960
you handle the very abilities of of you

730
00:34:22,130 --> 00:34:25,250
know signal noise you know will the

731
00:34:23,960 --> 00:34:27,740
impairments that you might experience

732
00:34:25,250 --> 00:34:29,060
but then when you get to the human side

733
00:34:27,739 --> 00:34:32,540
that's when you have the non-linearity

734
00:34:29,060 --> 00:34:35,810
so you have like intentional activities

735
00:34:32,540 --> 00:34:37,279
to you know circumvent your algorithms

736
00:34:35,810 --> 00:34:39,620
or come up with something that will

737
00:34:37,280 --> 00:34:42,470
compromise the ability to to be secure

738
00:34:39,620 --> 00:34:44,389
so so when we deal with so what we

739
00:34:42,469 --> 00:34:46,069
generally speak about is AI epical or

740
00:34:44,389 --> 00:34:48,859
not I think it depends on how it's used

741
00:34:46,070 --> 00:34:50,750
and we do spend a lot of time needing to

742
00:34:48,860 --> 00:34:52,790
understand the policies the governance

743
00:34:50,750 --> 00:34:55,159
the legal aspect the privacy concerns

744
00:34:52,790 --> 00:34:56,509
and only apply the AI that meets all

745
00:34:55,159 --> 00:34:58,730
those conditions and that's one of those

746
00:34:56,510 --> 00:35:01,880
constraints of actually making AI

747
00:34:58,730 --> 00:35:04,880
practical in government military systems

748
00:35:01,880 --> 00:35:07,250
so so how we would use it is say

749
00:35:04,880 --> 00:35:08,990
decision support so decision support is

750
00:35:07,250 --> 00:35:10,610
sort of an offline activity that you

751
00:35:08,990 --> 00:35:13,430
could do anything you could do gaming

752
00:35:10,610 --> 00:35:16,820
you could do you know concept of

753
00:35:13,430 --> 00:35:18,859
operations you could do campaign task

754
00:35:16,820 --> 00:35:20,840
planning and and whatever you want to do

755
00:35:18,860 --> 00:35:22,880
and then you use that to take the

756
00:35:20,840 --> 00:35:25,490
results and ultimately either you and

757
00:35:22,880 --> 00:35:27,860
it's going to factor in what pieces are

758
00:35:25,490 --> 00:35:30,049
aiding the human and which pieces that

759
00:35:27,860 --> 00:35:32,570
the human AXA has to take over to make

760
00:35:30,050 --> 00:35:34,460
those final decisions so now our

761
00:35:32,570 --> 00:35:36,260
adversaries on the other hand might not

762
00:35:34,460 --> 00:35:37,970
follow the same you know list of

763
00:35:36,260 --> 00:35:39,860
governance ethics compliance and so

764
00:35:37,970 --> 00:35:42,230
forth and that sort of puts us at a

765
00:35:39,860 --> 00:35:44,690
disadvantage in terms of speed and which

766
00:35:42,230 --> 00:35:46,910
an attack occurs until the time we could

767
00:35:44,690 --> 00:35:48,470
recover from the attack especially if

768
00:35:46,910 --> 00:35:50,210
what we're using machine learning for

769
00:35:48,470 --> 00:35:52,279
divulges privacy information of

770
00:35:50,210 --> 00:35:53,780
individuals so you have to anybody we do

771
00:35:52,280 --> 00:35:55,780
have research in the area privacy

772
00:35:53,780 --> 00:35:58,430
preserving information sharing and

773
00:35:55,780 --> 00:36:00,620
attribution has to take into account all

774
00:35:58,430 --> 00:36:02,779
the policy and ethics so it's not a

775
00:36:00,620 --> 00:36:05,960
simple answer but we are fully aware of

776
00:36:02,780 --> 00:36:07,280
it and the constraints forces us to work

777
00:36:05,960 --> 00:36:08,750
around some of these things that we

778
00:36:07,280 --> 00:36:11,920
could be more efficient with AI we have

779
00:36:08,750 --> 00:36:11,920
to find other means of doing it

780
00:36:13,059 --> 00:36:40,900
go ahead and look at my notes and by the

781
00:36:38,949 --> 00:36:43,569
talks are there online right I'll be

782
00:36:40,900 --> 00:36:45,579
able to give you the link

783
00:36:43,569 --> 00:36:50,079
but couple of points they raised was

784
00:36:45,579 --> 00:36:55,689
that AI could be used in in you know in

785
00:36:50,079 --> 00:36:58,599
the legal system judges they're there

786
00:36:55,689 --> 00:37:00,219
you know Sentencing Guidelines or just

787
00:36:58,599 --> 00:37:02,409
mention all can sometimes be clouded and

788
00:37:00,219 --> 00:37:06,809
then AI could help to eliminate some of

789
00:37:02,409 --> 00:37:08,979
that bias that people feel and then

790
00:37:06,809 --> 00:37:11,799
there were other questions raised like

791
00:37:08,979 --> 00:37:16,689
you know suppose that the autonomous

792
00:37:11,799 --> 00:37:19,029
cars are quite robust you know the

793
00:37:16,689 --> 00:37:20,649
amount of errors they make are you know

794
00:37:19,029 --> 00:37:22,989
far lesser than humans but then would

795
00:37:20,650 --> 00:37:25,359
you be rather killed by an autonomous

796
00:37:22,989 --> 00:37:27,359
car or by a you know a human human

797
00:37:25,359 --> 00:37:31,989
driver these are the some of the

798
00:37:27,359 --> 00:37:34,749
questions that they were raising yeah

799
00:37:31,989 --> 00:37:36,969
I'll point out one of the things this is

800
00:37:34,749 --> 00:37:40,118
a great question but one of the

801
00:37:36,969 --> 00:37:43,989
difficulties here is we are using these

802
00:37:40,119 --> 00:37:45,999
AI systems to solve problems that we

803
00:37:43,989 --> 00:37:51,039
have a hard time solving as individuals

804
00:37:45,999 --> 00:37:54,129
as humans which means often the way

805
00:37:51,039 --> 00:37:59,169
they're solved we don't fully understand

806
00:37:54,130 --> 00:38:03,729
and many of the AI techniques are rather

807
00:37:59,169 --> 00:38:08,499
opaque explaining actually what they do

808
00:38:03,729 --> 00:38:10,839
is very difficult justifying what they

809
00:38:08,499 --> 00:38:12,939
do may be a little easier come saying

810
00:38:10,839 --> 00:38:16,269
well here is a possible explanation it

811
00:38:12,939 --> 00:38:18,489
may not actually be what really happened

812
00:38:16,269 --> 00:38:20,709
but it's a reasonable explanation of

813
00:38:18,489 --> 00:38:23,349
what could have happened we tend to

814
00:38:20,709 --> 00:38:24,960
accept that for humans for explaining

815
00:38:23,349 --> 00:38:27,190
our decisions

816
00:38:24,960 --> 00:38:32,170
but another thing that comes into the

817
00:38:27,190 --> 00:38:33,549
ethics is and just touched on bias we

818
00:38:32,170 --> 00:38:37,859
think okay well these will help reduce

819
00:38:33,549 --> 00:38:41,020
bias but it turns out these systems can

820
00:38:37,859 --> 00:38:44,950
introduce bias even where there was no

821
00:38:41,020 --> 00:38:48,339
bias to begin with and you know you

822
00:38:44,950 --> 00:38:51,790
mentioned an autonomous weapon system

823
00:38:48,339 --> 00:38:56,920
well what if we train that and teach

824
00:38:51,790 --> 00:39:02,500
that system to avoid civilian avoid

825
00:38:56,920 --> 00:39:04,240
killing civilians and you know we we

826
00:39:02,500 --> 00:39:06,910
look around and basically we gather all

827
00:39:04,240 --> 00:39:09,399
kinds of pictures of civilians and

828
00:39:06,910 --> 00:39:12,098
military in the midst of civilians and

829
00:39:09,400 --> 00:39:13,510
such here and then we deploy that

830
00:39:12,099 --> 00:39:16,720
someplace else

831
00:39:13,510 --> 00:39:17,920
where the the dress you know somebody

832
00:39:16,720 --> 00:39:19,808
care you know the likelihood that

833
00:39:17,920 --> 00:39:22,720
somebody's carrying a walking stick that

834
00:39:19,809 --> 00:39:27,609
might look like a weapon may be higher

835
00:39:22,720 --> 00:39:30,160
and all of a sudden it's making really

836
00:39:27,609 --> 00:39:32,828
strange determinations of what is a

837
00:39:30,160 --> 00:39:35,890
civilian and what is not so we've kind

838
00:39:32,829 --> 00:39:38,290
of tried to put ethic and ethical

839
00:39:35,890 --> 00:39:43,118
behavior into the system but it turns

840
00:39:38,290 --> 00:39:45,520
out not to work the way we expected this

841
00:39:43,119 --> 00:39:50,079
I think is a big problem with ethics and

842
00:39:45,520 --> 00:39:54,460
AI is that how these systems are going

843
00:39:50,079 --> 00:39:58,270
to behave in practice is is very

844
00:39:54,460 --> 00:40:03,069
challenging and this is particularly and

845
00:39:58,270 --> 00:40:06,940
challenging in in these public security

846
00:40:03,069 --> 00:40:08,890
type of systems where we don't have a

847
00:40:06,940 --> 00:40:11,710
lot of chance to try them out and see

848
00:40:08,890 --> 00:40:16,118
how they work and and don't work in

849
00:40:11,710 --> 00:40:19,900
practice before you know we're using

850
00:40:16,119 --> 00:40:23,470
them for real and then they may make

851
00:40:19,900 --> 00:40:26,339
mistakes so that's I think I think a big

852
00:40:23,470 --> 00:40:26,339
concern yeah

853
00:40:27,640 --> 00:40:41,080
I can can introduce you know drastically

854
00:40:38,050 --> 00:40:44,500
reduce that error sure still you know

855
00:40:41,080 --> 00:40:46,090
get the wrong guy but that not be

856
00:40:44,500 --> 00:40:51,010
preferable to the current state of

857
00:40:46,090 --> 00:40:53,260
affairs so I think we could discuss this

858
00:40:51,010 --> 00:40:55,960
question for the entire hour so maybe

859
00:40:53,260 --> 00:41:03,280
let's move on to let someone else come

860
00:40:55,960 --> 00:41:05,700
in with a question actually ends up

861
00:41:03,280 --> 00:41:10,420
being a follow-up to mr. Clifton's

862
00:41:05,700 --> 00:41:13,509
comment it's I find it very very

863
00:41:10,420 --> 00:41:15,640
disturbing that when you put the

864
00:41:13,510 --> 00:41:18,370
stickers on the stop sign what failure

865
00:41:15,640 --> 00:41:21,339
mode you get you would think if it

866
00:41:18,370 --> 00:41:24,100
looked a bass if an IE I looked at a

867
00:41:21,340 --> 00:41:26,380
sign the way human or other animals do

868
00:41:24,100 --> 00:41:28,720
you might say oh well it thinks it's a

869
00:41:26,380 --> 00:41:31,870
hospital sign or it thinks you know that

870
00:41:28,720 --> 00:41:34,270
that's a no u-turn sign but instead say

871
00:41:31,870 --> 00:41:36,549
it finds a kitten or there was another

872
00:41:34,270 --> 00:41:38,410
one that came out recently about the had

873
00:41:36,550 --> 00:41:41,020
a picture of a room you put an elephant

874
00:41:38,410 --> 00:41:42,580
in the room and then the AI started

875
00:41:41,020 --> 00:41:45,280
thinking like the couch was the end

876
00:41:42,580 --> 00:41:47,890
table and the end table was a floor lamp

877
00:41:45,280 --> 00:41:51,550
and all that it's not picking things up

878
00:41:47,890 --> 00:41:54,850
the way that we would pick it up and

879
00:41:51,550 --> 00:41:58,150
what I'm wondering is do we need to

880
00:41:54,850 --> 00:42:00,940
develop especially the neural networks

881
00:41:58,150 --> 00:42:05,230
once that actually can explain

882
00:42:00,940 --> 00:42:07,420
themselves I'd it's you know coming from

883
00:42:05,230 --> 00:42:10,570
doing some expert systems in the past

884
00:42:07,420 --> 00:42:13,150
it's very disturbing to me to think that

885
00:42:10,570 --> 00:42:15,670
okay we're just gonna throw a bunch it's

886
00:42:13,150 --> 00:42:18,340
like the old Sydney Harris cartoon where

887
00:42:15,670 --> 00:42:20,590
you see big equation then a miracle

888
00:42:18,340 --> 00:42:22,450
occurs then the rest of the equation and

889
00:42:20,590 --> 00:42:23,920
when one side is saying to another I

890
00:42:22,450 --> 00:42:27,189
think you need to be a little more

891
00:42:23,920 --> 00:42:31,300
explicit here in step two and I kind of

892
00:42:27,190 --> 00:42:33,700
feel like the what we're concentrating

893
00:42:31,300 --> 00:42:34,210
on in AI right now with the neural

894
00:42:33,700 --> 00:42:36,310
networks

895
00:42:34,210 --> 00:42:37,430
we're just what we feed a bunch of

896
00:42:36,310 --> 00:42:39,109
training data in and

897
00:42:37,430 --> 00:42:41,049
hoping a miracle occurs that it will

898
00:42:39,109 --> 00:42:45,290
recognize the things we want to

899
00:42:41,050 --> 00:42:48,140
recognize good night can I respond sure

900
00:42:45,290 --> 00:42:50,089
yeah so from a practical point of view

901
00:42:48,140 --> 00:42:52,160
yeah so I agree with all that we've all

902
00:42:50,089 --> 00:42:54,230
seen the you know the the extreme of a

903
00:42:52,160 --> 00:42:58,578
stop sign looking like you know whatever

904
00:42:54,230 --> 00:42:59,990
real sign or the the ability if we can

905
00:42:58,579 --> 00:43:01,579
understand something so that that's the

906
00:42:59,990 --> 00:43:02,868
whole issue explain ability which is one

907
00:43:01,579 --> 00:43:05,180
of the key problems you know getting

908
00:43:02,869 --> 00:43:07,970
confidence in the the autonomous

909
00:43:05,180 --> 00:43:09,589
decision-making by a nonhuman gaining

910
00:43:07,970 --> 00:43:12,078
that confidence and then the explained

911
00:43:09,589 --> 00:43:13,520
ability is important so often what will

912
00:43:12,079 --> 00:43:15,920
happen you could end up with an optimal

913
00:43:13,520 --> 00:43:18,349
solution based on unexplainable events

914
00:43:15,920 --> 00:43:20,569
and then we won't accept that well back

915
00:43:18,349 --> 00:43:23,059
off the optimal solution to be sub

916
00:43:20,569 --> 00:43:24,770
optimum until we get to a point of

917
00:43:23,059 --> 00:43:26,930
comfort that we could explain it at

918
00:43:24,770 --> 00:43:28,550
least to the degree of confidence enough

919
00:43:26,930 --> 00:43:30,799
to carry on but whatever we're trying to

920
00:43:28,550 --> 00:43:33,770
do so what that would mean is that this

921
00:43:30,800 --> 00:43:35,839
whole scale of of confidence explain

922
00:43:33,770 --> 00:43:38,480
ability and how much explain ability

923
00:43:35,839 --> 00:43:40,880
versus the impact and the unexpected

924
00:43:38,480 --> 00:43:43,490
behaviors or emergent behavior might

925
00:43:40,880 --> 00:43:45,710
occur so we as a practical you know an

926
00:43:43,490 --> 00:43:49,040
analyst that's doing Intel analysis

927
00:43:45,710 --> 00:43:52,970
example will use AI to reduce the

928
00:43:49,040 --> 00:43:54,680
workload for the analyst such that you

929
00:43:52,970 --> 00:43:57,078
will see the stop sign and they'll see

930
00:43:54,680 --> 00:43:58,549
all the other symbols and other signs

931
00:43:57,079 --> 00:43:59,869
that he's supposed to do so human

932
00:43:58,549 --> 00:44:02,990
analysts could weed those out very

933
00:43:59,869 --> 00:44:06,530
quickly if we rely a hunt percent on an

934
00:44:02,990 --> 00:44:09,020
AI then you're gonna be subject to a lot

935
00:44:06,530 --> 00:44:11,750
of false hits and a lot of adverse

936
00:44:09,020 --> 00:44:13,549
impacts so the ability of an analyst so

937
00:44:11,750 --> 00:44:16,670
that's a practical side of it so you do

938
00:44:13,549 --> 00:44:18,500
enough AI just enough so the analyst has

939
00:44:16,670 --> 00:44:21,740
workload could be reduced so they're

940
00:44:18,500 --> 00:44:23,059
effective with the less work force you

941
00:44:21,740 --> 00:44:25,848
have to correct targets that you

942
00:44:23,059 --> 00:44:27,920
identify whether it's Intel analysis

943
00:44:25,849 --> 00:44:30,260
based on documents or its imagery or

944
00:44:27,920 --> 00:44:32,089
whatever so you'll keep scaling that

945
00:44:30,260 --> 00:44:34,670
back and also you take into account the

946
00:44:32,089 --> 00:44:36,170
fatigue of an analyst and where an

947
00:44:34,670 --> 00:44:38,450
analyst starts a human analyst starts

948
00:44:36,170 --> 00:44:41,030
becoming overloaded then the whole scale

949
00:44:38,450 --> 00:44:42,500
of where you can apply AI changes so

950
00:44:41,030 --> 00:44:45,410
that whole realm of the human machine

951
00:44:42,500 --> 00:44:47,990
interaction and the physiological of

952
00:44:45,410 --> 00:44:48,899
interaction with the data is very

953
00:44:47,990 --> 00:44:51,118
tightly

954
00:44:48,900 --> 00:44:53,970
Bulls and that's why a set of my opening

955
00:44:51,119 --> 00:44:56,609
remarks in a large-scale system all

956
00:44:53,970 --> 00:44:58,740
these interactions are not very well

957
00:44:56,609 --> 00:45:00,869
understood but you have to look at the

958
00:44:58,740 --> 00:45:03,839
whole system to be practical to use any

959
00:45:00,869 --> 00:45:05,480
of these approaches yeah and just Faulk

960
00:45:03,839 --> 00:45:10,288
a little more getting back to

961
00:45:05,480 --> 00:45:13,289
cybersecurity you know if we think of

962
00:45:10,289 --> 00:45:16,980
this what we want this AI to do is not

963
00:45:13,289 --> 00:45:19,619
do tasks we do as humans you know we we

964
00:45:16,980 --> 00:45:22,049
don't why is it that we're trying to get

965
00:45:19,619 --> 00:45:23,910
this thing to recognize images our

966
00:45:22,049 --> 00:45:26,609
vision systems work pretty well we can

967
00:45:23,910 --> 00:45:29,180
recognize things we wanted to get to do

968
00:45:26,609 --> 00:45:32,098
to do the things we don't do well and

969
00:45:29,180 --> 00:45:37,589
concentrate on those and in those cases

970
00:45:32,099 --> 00:45:39,720
an explanation it may not even make

971
00:45:37,589 --> 00:45:43,710
sense to us we don't know how to solve

972
00:45:39,720 --> 00:45:45,450
the problem maybe there isn't an

973
00:45:43,710 --> 00:45:47,220
explanation that will help us to

974
00:45:45,450 --> 00:45:49,169
understand how the machine is solving

975
00:45:47,220 --> 00:45:53,430
the problem because somehow this is just

976
00:45:49,170 --> 00:45:57,799
beyond the way we think but if we're

977
00:45:53,430 --> 00:46:01,649
careful to use these in ways that you

978
00:45:57,799 --> 00:46:04,319
know we understand what the outcome is

979
00:46:01,650 --> 00:46:06,269
we we may not understand how it got

980
00:46:04,319 --> 00:46:08,339
there but we understand what the outcome

981
00:46:06,269 --> 00:46:12,508
is how this applies what it's telling us

982
00:46:08,339 --> 00:46:16,170
and what it's not telling us not how it

983
00:46:12,509 --> 00:46:18,089
fails but when it might fail I think for

984
00:46:16,170 --> 00:46:21,059
many cases this is is going to be

985
00:46:18,089 --> 00:46:23,009
sufficient but that does that's

986
00:46:21,059 --> 00:46:25,200
something that's also something we don't

987
00:46:23,009 --> 00:46:28,710
get out of to date today's systems is a

988
00:46:25,200 --> 00:46:31,558
good understanding of when they're going

989
00:46:28,710 --> 00:46:33,630
to fail and and that I think is

990
00:46:31,559 --> 00:46:35,549
something it's not quite the same as

991
00:46:33,630 --> 00:46:43,650
explanation but I think that's something

992
00:46:35,549 --> 00:46:47,329
we need to concentrate on explain

993
00:46:43,650 --> 00:46:50,299
ability is an important area of AI but

994
00:46:47,329 --> 00:46:54,089
what it boils down to essentially is

995
00:46:50,299 --> 00:46:56,970
explaining why a certain function or a

996
00:46:54,089 --> 00:47:00,269
certain set of equations solved by an AI

997
00:46:56,970 --> 00:47:02,609
system is behaving or giving such output

998
00:47:00,269 --> 00:47:04,890
right so so the

999
00:47:02,610 --> 00:47:07,350
they range the amount of data that is

1000
00:47:04,890 --> 00:47:09,330
together we gather and mannered and then

1001
00:47:07,350 --> 00:47:12,089
used for external explain ability of the

1002
00:47:09,330 --> 00:47:14,850
system is going to be humongous and we

1003
00:47:12,090 --> 00:47:16,740
need to as Paul pointed out that you

1004
00:47:14,850 --> 00:47:20,190
know we need to be careful about how we

1005
00:47:16,740 --> 00:47:23,160
select those data points to explain them

1006
00:47:20,190 --> 00:47:25,080
and then for example GDP are as a

1007
00:47:23,160 --> 00:47:27,600
compliance requirement as has explained

1008
00:47:25,080 --> 00:47:29,220
ability as one of the requirements how

1009
00:47:27,600 --> 00:47:30,799
are you going to implement that that's a

1010
00:47:29,220 --> 00:47:36,140
big question

1011
00:47:30,800 --> 00:47:36,140
Sanjay did you have any response to this

1012
00:48:02,750 --> 00:48:11,040
before you actually implement it so if

1013
00:48:08,940 --> 00:48:12,930
there is then a few things can be done

1014
00:48:11,040 --> 00:48:16,430
there's one of the other stuff that we

1015
00:48:12,930 --> 00:48:18,899
are exploring in our projects but I

1016
00:48:16,430 --> 00:48:20,430
think validation against some ground

1017
00:48:18,900 --> 00:48:23,790
truth engine would we would be a

1018
00:48:20,430 --> 00:48:26,640
critical part of you know deploying

1019
00:48:23,790 --> 00:48:30,270
deployment of an AI system for real word

1020
00:48:26,640 --> 00:48:31,740
decision-making so maybe before we go

1021
00:48:30,270 --> 00:48:35,040
into the next question let me just point

1022
00:48:31,740 --> 00:48:37,410
out that in the research field of AI we

1023
00:48:35,040 --> 00:48:40,050
have two types of goals that people

1024
00:48:37,410 --> 00:48:42,210
focus on one is to develop agents that

1025
00:48:40,050 --> 00:48:44,070
behave rationally and the other is to

1026
00:48:42,210 --> 00:48:47,550
develop agents that behave like humans

1027
00:48:44,070 --> 00:48:49,500
right so this stuff that Chris and Paul

1028
00:48:47,550 --> 00:48:51,720
are referring to as the methods are

1029
00:48:49,500 --> 00:48:53,400
augmenting people's abilities and

1030
00:48:51,720 --> 00:48:55,589
hopefully helping them make better

1031
00:48:53,400 --> 00:48:58,080
decisions more efficiently those are not

1032
00:48:55,590 --> 00:48:59,940
always the systems are not always built

1033
00:48:58,080 --> 00:49:01,950
to try to replicate exactly what

1034
00:48:59,940 --> 00:49:03,450
decisions humans would make because

1035
00:49:01,950 --> 00:49:04,980
that's much harder to put into the

1036
00:49:03,450 --> 00:49:06,810
objective functions so it's it's worth

1037
00:49:04,980 --> 00:49:09,060
thinking about as we start expecting

1038
00:49:06,810 --> 00:49:11,220
certain kinds of behavior from our AI

1039
00:49:09,060 --> 00:49:12,299
system so let's go on to the next

1040
00:49:11,220 --> 00:49:14,879
question

1041
00:49:12,300 --> 00:49:16,920
so it's a follow up on actually cheating

1042
00:49:14,880 --> 00:49:23,070
AI to behave like humans or explainable

1043
00:49:16,920 --> 00:49:25,050
AI I'm sure you're aware of that I'm

1044
00:49:23,070 --> 00:49:29,010
sure you're aware of the dispute between

1045
00:49:25,050 --> 00:49:30,780
statisticians and AI fans so I'm just

1046
00:49:29,010 --> 00:49:32,400
curious what do you think are the

1047
00:49:30,780 --> 00:49:34,700
transformational attributes that we

1048
00:49:32,400 --> 00:49:37,950
still need to you know call AI

1049
00:49:34,700 --> 00:49:39,359
intelligent because to a human it's very

1050
00:49:37,950 --> 00:49:41,430
difficult to also define what an

1051
00:49:39,360 --> 00:49:43,500
intelligence is expecially when you it

1052
00:49:41,430 --> 00:49:44,850
takes like 10,000 pictures of a panda to

1053
00:49:43,500 --> 00:49:46,470
know that it's a panda but for a human

1054
00:49:44,850 --> 00:49:48,900
it's only one picture you can tell

1055
00:49:46,470 --> 00:49:50,220
difference between a panda and a cat so

1056
00:49:48,900 --> 00:49:52,050
in your idea what are the other

1057
00:49:50,220 --> 00:49:54,629
transformational things that we need or

1058
00:49:52,050 --> 00:49:56,430
the big leaps that we need for AI to to

1059
00:49:54,630 --> 00:50:01,890
confidently say it's intelligent it's

1060
00:49:56,430 --> 00:50:07,980
behaving like a human I'll start with

1061
00:50:01,890 --> 00:50:10,890
that I claim that we humans have too big

1062
00:50:07,980 --> 00:50:13,260
an ego to ever accept that these

1063
00:50:10,890 --> 00:50:15,540
artificial things are intelligent so we

1064
00:50:13,260 --> 00:50:20,190
will define intelligence in a way that

1065
00:50:15,540 --> 00:50:24,210
these machines are not intelligent and I

1066
00:50:20,190 --> 00:50:26,790
don't think that is is a bad thing we've

1067
00:50:24,210 --> 00:50:29,250
got lots of people let people do what

1068
00:50:26,790 --> 00:50:31,580
they're good at which is what we refer

1069
00:50:29,250 --> 00:50:34,860
to as human intelligence

1070
00:50:31,580 --> 00:50:38,120
let's get these machines solving

1071
00:50:34,860 --> 00:50:40,470
problems that humans aren't good at and

1072
00:50:38,120 --> 00:50:42,450
let's look at this in the computer

1073
00:50:40,470 --> 00:50:46,980
security domain what are the things that

1074
00:50:42,450 --> 00:50:49,339
we don't do well and how can we use the

1075
00:50:46,980 --> 00:50:51,630
machines to address those problems

1076
00:50:49,340 --> 00:50:54,390
rather than trying to come up with

1077
00:50:51,630 --> 00:50:59,190
machines that do a good job of doing

1078
00:50:54,390 --> 00:51:04,500
what we already do well sort of making a

1079
00:50:59,190 --> 00:51:06,210
assertion here so AI as I said before

1080
00:51:04,500 --> 00:51:07,380
the taxonomy could meet a lot of

1081
00:51:06,210 --> 00:51:11,180
different things but if you say AI

1082
00:51:07,380 --> 00:51:14,040
covers a lot of ground everything from a

1083
00:51:11,180 --> 00:51:16,500
simple single parameter rulesets like a

1084
00:51:14,040 --> 00:51:18,900
thermostat not a nest thermostat then

1085
00:51:16,500 --> 00:51:21,420
you have more complex rule sets you have

1086
00:51:18,900 --> 00:51:24,270
some automation you have semantic

1087
00:51:21,420 --> 00:51:25,600
processing and eventually at the far

1088
00:51:24,270 --> 00:51:28,990
right of the spectrum you'll have

1089
00:51:25,600 --> 00:51:31,330
narrow AI and generally I write so then

1090
00:51:28,990 --> 00:51:33,250
where does cognition actually kick in we

1091
00:51:31,330 --> 00:51:35,560
have a Watson man sitting right here so

1092
00:51:33,250 --> 00:51:38,860
what find the aquaria Watson system that

1093
00:51:35,560 --> 00:51:41,110
it becomes cognitive so I assert that

1094
00:51:38,860 --> 00:51:42,490
you could do a lot of things that one

1095
00:51:41,110 --> 00:51:44,170
gets fooled into thinking you'd say I

1096
00:51:42,490 --> 00:51:46,149
but it's nothing more than building a

1097
00:51:44,170 --> 00:51:48,910
good ontology with a knowledge base and

1098
00:51:46,150 --> 00:51:50,890
doing semantic queries and then a system

1099
00:51:48,910 --> 00:51:52,990
could very much look like an AI system

1100
00:51:50,890 --> 00:51:54,730
because it looks P hat it gives you the

1101
00:51:52,990 --> 00:51:58,359
right answers but it's based on a

1102
00:51:54,730 --> 00:52:00,340
knowledge base of well understood you

1103
00:51:58,360 --> 00:52:02,320
know activities and performance of what

1104
00:52:00,340 --> 00:52:05,080
you call the system but it's when you

1105
00:52:02,320 --> 00:52:08,230
get outside of it those constraints into

1106
00:52:05,080 --> 00:52:10,000
the unknown that's when you run into you

1107
00:52:08,230 --> 00:52:13,420
need some more cognitive processing but

1108
00:52:10,000 --> 00:52:16,210
I think I'd say that maybe 90% of what

1109
00:52:13,420 --> 00:52:18,820
we do don't quite fall into the

1110
00:52:16,210 --> 00:52:21,370
cognitive area but then become

1111
00:52:18,820 --> 00:52:23,020
sophisticated rulesets and you know and

1112
00:52:21,370 --> 00:52:25,089
I say that from my perspective not some

1113
00:52:23,020 --> 00:52:27,640
other domains especially with these UAVs

1114
00:52:25,090 --> 00:52:29,920
that Tamas vehicles they very much look

1115
00:52:27,640 --> 00:52:31,480
like AI systems and the full cognitive

1116
00:52:29,920 --> 00:52:32,830
and they do things that you know you

1117
00:52:31,480 --> 00:52:35,410
wonder how they could react in the

1118
00:52:32,830 --> 00:52:37,600
environment as they do but the very

1119
00:52:35,410 --> 00:52:40,870
sophisticated rule sets so semantic

1120
00:52:37,600 --> 00:52:43,420
computing is one element of AI and that

1121
00:52:40,870 --> 00:52:44,500
answers a lot of the mail but then to go

1122
00:52:43,420 --> 00:52:46,120
all the way to the right side of the

1123
00:52:44,500 --> 00:52:47,740
spectrum and then expect to do things

1124
00:52:46,120 --> 00:52:48,910
like you know weed out cats and dogs and

1125
00:52:47,740 --> 00:52:51,129
elephants and do with you know

1126
00:52:48,910 --> 00:52:53,170
seamlessly that requires a different

1127
00:52:51,130 --> 00:52:57,700
technology that we don't quite have

1128
00:52:53,170 --> 00:52:59,680
right now so I just had one more thing

1129
00:52:57,700 --> 00:53:02,770
here is Adam in turn so Watson by the

1130
00:52:59,680 --> 00:53:08,620
way no I think

1131
00:53:02,770 --> 00:53:13,570
person was a good stepping point for AI

1132
00:53:08,620 --> 00:53:17,920
in 2011 taking from psychology

1133
00:53:13,570 --> 00:53:20,650
intelligence is about learning from past

1134
00:53:17,920 --> 00:53:23,260
Bosch behavioral learning and generating

1135
00:53:20,650 --> 00:53:26,140
more knowledge that can be useful to you

1136
00:53:23,260 --> 00:53:27,850
or ritual to others it's essentially

1137
00:53:26,140 --> 00:53:30,279
about intelligence is all about learning

1138
00:53:27,850 --> 00:53:31,390
and whether you learn in a supervised

1139
00:53:30,280 --> 00:53:32,950
manner whether you learn in an

1140
00:53:31,390 --> 00:53:35,799
unsupervised minor or semi-supervised

1141
00:53:32,950 --> 00:53:38,049
manner is what we are looking at a new

1142
00:53:35,800 --> 00:53:40,630
image do that but as

1143
00:53:38,050 --> 00:53:43,450
as perhaps a Clifton and Paul have

1144
00:53:40,630 --> 00:53:45,490
pointed out and flopster navel also

1145
00:53:43,450 --> 00:53:48,490
pointed out that you know human-centered

1146
00:53:45,490 --> 00:53:50,049
a I like Kenny I help human beings to to

1147
00:53:48,490 --> 00:53:52,660
carry out tasks that human beings are

1148
00:53:50,050 --> 00:53:55,050
not good at right and from that point of

1149
00:53:52,660 --> 00:53:57,640
view can we develop intelligence or AI

1150
00:53:55,050 --> 00:54:01,090
belt algorithms and techniques that

1151
00:53:57,640 --> 00:54:05,220
could help us become better in whatever

1152
00:54:01,090 --> 00:54:07,510
we do or achieve as a society so the

1153
00:54:05,220 --> 00:54:13,240
does a lot of work going on in the

1154
00:54:07,510 --> 00:54:16,720
industry about societal or AI for good

1155
00:54:13,240 --> 00:54:19,120
right as societal good and that is also

1156
00:54:16,720 --> 00:54:21,490
who are going on in the army side right

1157
00:54:19,120 --> 00:54:23,710
essentially a military side and the

1158
00:54:21,490 --> 00:54:25,299
question is how do you differentiate

1159
00:54:23,710 --> 00:54:26,830
between what kind of algorithms you are

1160
00:54:25,300 --> 00:54:29,530
using there right or what kind of

1161
00:54:26,830 --> 00:54:33,580
intelligence that is your comes re are

1162
00:54:29,530 --> 00:54:35,560
you using supervised learning versus

1163
00:54:33,580 --> 00:54:39,160
unsupervised learning because if you

1164
00:54:35,560 --> 00:54:42,270
start applying unsupervised learning in

1165
00:54:39,160 --> 00:54:45,279
in military side it might become slowly

1166
00:54:42,270 --> 00:54:46,870
get highly biased and caused harm and

1167
00:54:45,280 --> 00:54:50,170
that is where you need a human

1168
00:54:46,870 --> 00:54:53,770
supervision so so intelligence might be

1169
00:54:50,170 --> 00:54:55,510
might need to be administered and

1170
00:54:53,770 --> 00:54:57,870
monitored by human being since at some

1171
00:54:55,510 --> 00:54:57,870
level

1172
00:55:05,270 --> 00:55:11,130
is can all be settled by the Turing test

1173
00:55:07,890 --> 00:55:12,720
right so I mean to be really happy to

1174
00:55:11,130 --> 00:55:16,350
find what is human intelligence and what

1175
00:55:12,720 --> 00:55:18,330
is the AI but there was an interesting

1176
00:55:16,350 --> 00:55:21,390
article we are very very very far away

1177
00:55:18,330 --> 00:55:23,370
from human intelligence Creary creating

1178
00:55:21,390 --> 00:55:24,779
human intelligence artificially there

1179
00:55:23,370 --> 00:55:27,779
was an interesting article on natural

1180
00:55:24,780 --> 00:55:30,150
language understanding by Douglas

1181
00:55:27,780 --> 00:55:31,440
Hofstadter's heard the name that was

1182
00:55:30,150 --> 00:55:34,350
Hofstadter he wrote this book called

1183
00:55:31,440 --> 00:55:39,180
gorilla Shabak he's actually at Indiana

1184
00:55:34,350 --> 00:55:40,980
University you know close by girdle

1185
00:55:39,180 --> 00:55:49,259
assured buck anybody who read that book

1186
00:55:40,980 --> 00:55:51,780
yeah okay yeah so he wrote an article I

1187
00:55:49,260 --> 00:55:54,750
believe in the Atlantic magazine that

1188
00:55:51,780 --> 00:55:57,750
you know despite all the advances in

1189
00:55:54,750 --> 00:56:00,300
Google Translate and all we are very far

1190
00:55:57,750 --> 00:56:01,950
away from translating you know things

1191
00:56:00,300 --> 00:56:06,410
accurately you know we can read novels

1192
00:56:01,950 --> 00:56:08,819
and extract he gave lots of examples of

1193
00:56:06,410 --> 00:56:11,700
you know phrases and sentences that we

1194
00:56:08,820 --> 00:56:13,460
can understand but machines know we're

1195
00:56:11,700 --> 00:56:19,879
close to understanding those things so

1196
00:56:13,460 --> 00:56:19,880
so a lot of good problems to solve still

1197
00:56:20,300 --> 00:56:29,940
so I'm gonna use nonlinear

1198
00:56:24,600 --> 00:56:32,120
discontinuities as my stripper name to

1199
00:56:29,940 --> 00:56:35,550
go back to the original comment about

1200
00:56:32,120 --> 00:56:39,839
healthcare and AI it occurs to me that

1201
00:56:35,550 --> 00:56:43,020
we've got a vast body of proved ground

1202
00:56:39,840 --> 00:56:45,480
truth that AI could help explain to us

1203
00:56:43,020 --> 00:56:48,570
and I'm wondering if any of the

1204
00:56:45,480 --> 00:56:51,350
panelists or a few professor would have

1205
00:56:48,570 --> 00:56:54,450
any thoughts on using AI to explain

1206
00:56:51,350 --> 00:56:57,600
protein folding if I put together a

1207
00:56:54,450 --> 00:56:59,430
string of amino acids in a millisecond

1208
00:56:57,600 --> 00:57:03,750
it's gonna snap into exactly the right

1209
00:56:59,430 --> 00:57:06,180
shape we don't know how I'm wondering if

1210
00:57:03,750 --> 00:57:09,690
there's a way to perhaps Watson model

1211
00:57:06,180 --> 00:57:10,250
that process so we could understand and

1212
00:57:09,690 --> 00:57:11,990
have

1213
00:57:10,250 --> 00:57:14,420
I explained it something that apparently

1214
00:57:11,990 --> 00:57:16,939
is not accessible to normal human

1215
00:57:14,420 --> 00:57:19,849
consciousness even though we're doing it

1216
00:57:16,940 --> 00:57:21,859
billions of times a second I was gonna

1217
00:57:19,849 --> 00:57:24,349
say is Daisuke Kehaar out here we have

1218
00:57:21,859 --> 00:57:28,490
people who are who are trying to do

1219
00:57:24,349 --> 00:57:32,510
these things trying to study it very

1220
00:57:28,490 --> 00:57:36,770
hard problems and you know an

1221
00:57:32,510 --> 00:57:40,849
interesting thing is I think that's a

1222
00:57:36,770 --> 00:57:47,050
very nice idea can we get the machines

1223
00:57:40,849 --> 00:57:49,790
to explain to us how these things work I

1224
00:57:47,050 --> 00:57:53,349
think the first step and we're not even

1225
00:57:49,790 --> 00:57:57,080
there yet is can the machines actually

1226
00:57:53,349 --> 00:57:59,150
say this is what is happening or this is

1227
00:57:57,080 --> 00:58:00,920
what happens without necessarily being

1228
00:57:59,150 --> 00:58:04,430
able to explain to us that would be a

1229
00:58:00,920 --> 00:58:09,050
first step can they essentially predict

1230
00:58:04,430 --> 00:58:11,470
what happens in these situations that at

1231
00:58:09,050 --> 00:58:14,359
least suggests there is an explanation

1232
00:58:11,470 --> 00:58:17,390
in the space that the machines are

1233
00:58:14,359 --> 00:58:20,210
capable of representing and often we can

1234
00:58:17,390 --> 00:58:22,098
at least describe mathematically what

1235
00:58:20,210 --> 00:58:25,910
that is even if we can't quite get our

1236
00:58:22,099 --> 00:58:28,520
heads around any particular instance and

1237
00:58:25,910 --> 00:58:31,730
so I think there there are ways we can

1238
00:58:28,520 --> 00:58:36,020
use these techniques to better

1239
00:58:31,730 --> 00:58:37,880
understand but getting to the vision you

1240
00:58:36,020 --> 00:58:41,270
have I think is still a long ways down

1241
00:58:37,880 --> 00:58:45,490
the road so let's see it seems like we

1242
00:58:41,270 --> 00:58:48,560
have a pattern like this

1243
00:58:45,490 --> 00:58:50,149
Hanan so in the ending of personalized

1244
00:58:48,560 --> 00:58:51,920
healthcare right I mean you said you

1245
00:58:50,150 --> 00:58:54,560
know a very tough problem and talk about

1246
00:58:51,920 --> 00:58:56,210
a problem that's like really hard but

1247
00:58:54,560 --> 00:58:57,830
you know we're sort of doing it in

1248
00:58:56,210 --> 00:59:01,190
personalized health care when we doing a

1249
00:58:57,830 --> 00:59:03,920
lot to understand using large data big

1250
00:59:01,190 --> 00:59:05,750
data analytics and ml and all the

1251
00:59:03,920 --> 00:59:09,500
different techniques we can to

1252
00:59:05,750 --> 00:59:12,050
understand proteomics and genomics and

1253
00:59:09,500 --> 00:59:15,260
all the different omics to try to

1254
00:59:12,050 --> 00:59:17,330
understand the onset of what the

1255
00:59:15,260 --> 00:59:19,490
biomarkers are that indicate that onset

1256
00:59:17,330 --> 00:59:20,779
of pandemics and endemics so we have you

1257
00:59:19,490 --> 00:59:22,299
know a whole group of people doing that

1258
00:59:20,780 --> 00:59:24,160
applying the same algorithm

1259
00:59:22,299 --> 00:59:25,929
four radar missile defense that are

1260
00:59:24,160 --> 00:59:27,609
applying it to proteomics for

1261
00:59:25,929 --> 00:59:29,679
personalized health care it's a tough

1262
00:59:27,609 --> 00:59:32,469
problem because clinical you know

1263
00:59:29,679 --> 00:59:34,809
techniques now basically look at the

1264
00:59:32,469 --> 00:59:37,660
general populations and look at symptoms

1265
00:59:34,809 --> 00:59:39,249
and doctors prescribe you know some

1266
00:59:37,660 --> 00:59:41,469
medicine based on what they see across

1267
00:59:39,249 --> 00:59:43,269
the large population so the personalized

1268
00:59:41,469 --> 00:59:45,459
healthcare takes an advantage a lot of

1269
00:59:43,269 --> 00:59:48,069
external data it takes an advantage not

1270
00:59:45,459 --> 00:59:49,719
just your your your blood tested the

1271
00:59:48,069 --> 00:59:53,079
blood assays it's also taking in a

1272
00:59:49,719 --> 00:59:54,640
counter your your own genomics your

1273
00:59:53,079 --> 00:59:56,799
history the neighborhood where you grew

1274
00:59:54,640 --> 00:59:58,479
up in and all these external factors to

1275
00:59:56,799 --> 01:00:00,009
see what all comes together and give you

1276
00:59:58,479 --> 01:00:02,078
the best course of action for medical

1277
01:00:00,009 --> 01:00:05,949
care so now if you're getting trying to

1278
01:00:02,079 --> 01:00:07,630
unravel like the the the synthesis of

1279
01:00:05,949 --> 01:00:09,369
how these things actually happen at a

1280
01:00:07,630 --> 01:00:11,679
biochemical level I mean I don't know

1281
01:00:09,369 --> 01:00:13,269
who's actually doing that but we the

1282
01:00:11,679 --> 01:00:14,349
problem is just defining is something

1283
01:00:13,269 --> 01:00:15,729
we're approaching and that's a tough

1284
01:00:14,349 --> 01:00:18,579
problem in itself so I think we're a

1285
01:00:15,729 --> 01:00:28,239
long way off but um interesting question

1286
01:00:18,579 --> 01:00:30,609
though so so - yeah that's that's a

1287
01:00:28,239 --> 01:00:34,660
great question if you look at what's on

1288
01:00:30,609 --> 01:00:37,209
genomic analytics project from IBM

1289
01:00:34,660 --> 01:00:39,609
research that worked on trying to

1290
01:00:37,209 --> 01:00:44,169
provide assistive treatment techniques

1291
01:00:39,609 --> 01:00:45,910
for cancer treatment I was involved in

1292
01:00:44,170 --> 01:00:49,239
that and from security and privacy side

1293
01:00:45,910 --> 01:00:51,279
point of view it essentially what it

1294
01:00:49,239 --> 01:00:55,989
does trying to answer your question is

1295
01:00:51,279 --> 01:00:58,719
that it takes research publications

1296
01:00:55,989 --> 01:01:01,900
about cancer treatment about different

1297
01:00:58,719 --> 01:01:03,749
corner cases of mutations and trying to

1298
01:01:01,900 --> 01:01:08,189
find out what could be a potential

1299
01:01:03,749 --> 01:01:13,348
better treatment for a specific type of

1300
01:01:08,189 --> 01:01:16,749
tumor and that kind of issue is know

1301
01:01:13,349 --> 01:01:18,609
there are a lot of false positives and

1302
01:01:16,749 --> 01:01:20,288
also it also served

1303
01:01:18,609 --> 01:01:22,209
I think it's have some person's life

1304
01:01:20,289 --> 01:01:25,509
perhaps I'm not sure there were to see

1305
01:01:22,209 --> 01:01:29,019
but it it still is a is a product there

1306
01:01:25,509 --> 01:01:30,640
and and it's doing a good job so in the

1307
01:01:29,019 --> 01:01:33,848
same line of work for us when you want

1308
01:01:30,640 --> 01:01:35,980
to explain protein folding why why that

1309
01:01:33,849 --> 01:01:40,890
kind of phenomena works right we need

1310
01:01:35,980 --> 01:01:43,240
look at the underlying principles of the

1311
01:01:40,890 --> 01:01:47,230
chemical formulation biological

1312
01:01:43,240 --> 01:01:50,859
formulation as well as the atomic level

1313
01:01:47,230 --> 01:01:52,930
of models and and the messengered learn

1314
01:01:50,859 --> 01:01:54,720
that and reason about that as it goes

1315
01:01:52,930 --> 01:01:57,460
forward and you can formulate the

1316
01:01:54,720 --> 01:01:59,290
functions and the behavior of that in a

1317
01:01:57,460 --> 01:02:00,430
mathematical manner then it can say you

1318
01:01:59,290 --> 01:02:02,619
know what the protein folding is

1319
01:02:00,430 --> 01:02:05,470
happening because due to these resins

1320
01:02:02,619 --> 01:02:07,750
right it can it can spit out many other

1321
01:02:05,470 --> 01:02:10,330
different many different reasons so so

1322
01:02:07,750 --> 01:02:12,460
bottom line is we need to the system

1323
01:02:10,330 --> 01:02:16,810
should learn about underlying

1324
01:02:12,460 --> 01:02:19,359
mathematical behavior of our develop

1325
01:02:16,810 --> 01:02:24,850
formulation of those systems in a

1326
01:02:19,359 --> 01:02:28,029
mathematically explainable manner you

1327
01:02:24,850 --> 01:02:30,220
know of the atoms molecules and and

1328
01:02:28,030 --> 01:02:31,810
their chemical properties and that is a

1329
01:02:30,220 --> 01:02:33,759
building block then they can come up

1330
01:02:31,810 --> 01:02:35,590
with explain these complex phenomena

1331
01:02:33,760 --> 01:02:39,970
I guess that is how when you talk about

1332
01:02:35,590 --> 01:02:42,670
we have a long way to go there so can I

1333
01:02:39,970 --> 01:02:44,560
cut in and give you a chance to ask the

1334
01:02:42,670 --> 01:02:46,420
answer the next question first

1335
01:02:44,560 --> 01:02:48,490
so we'll get to we're right we've run

1336
01:02:46,420 --> 01:02:50,920
out of time so no pressure but you'll be

1337
01:02:48,490 --> 01:02:52,359
the very last question of the panel I

1338
01:02:50,920 --> 01:02:55,990
hope I'm quick

1339
01:02:52,359 --> 01:02:57,369
in January 2007 or 2019 IBM came out

1340
01:02:55,990 --> 01:02:59,049
with the initiative Q and they're

1341
01:02:57,369 --> 01:03:02,320
talking about the quantum computing how

1342
01:02:59,050 --> 01:03:04,119
does that work with the AI technology I

1343
01:03:02,320 --> 01:03:05,830
know that early theoretical papers from

1344
01:03:04,119 --> 01:03:07,810
the 80s discussed that when quantum

1345
01:03:05,830 --> 01:03:09,279
computing came on AI would take off and

1346
01:03:07,810 --> 01:03:11,830
how do you see that impacting

1347
01:03:09,280 --> 01:03:19,030
cybersecurity with the sheer computing

1348
01:03:11,830 --> 01:03:29,830
power first that was I'm sorry I made

1349
01:03:19,030 --> 01:03:33,180
that deal for you but IBM IBM released

1350
01:03:29,830 --> 01:03:35,440
that quantum computing is out there

1351
01:03:33,180 --> 01:03:37,149
eventually this was obviously a press

1352
01:03:35,440 --> 01:03:39,369
release that it existed they're gonna

1353
01:03:37,150 --> 01:03:41,890
allow a cloud based quantum computing

1354
01:03:39,369 --> 01:03:44,050
but the ability for quantum computing

1355
01:03:41,890 --> 01:03:46,450
speeds up calculations it's such a huge

1356
01:03:44,050 --> 01:03:48,820
angle how does that impact with AI

1357
01:03:46,450 --> 01:03:49,220
because now you already have a system

1358
01:03:48,820 --> 01:03:50,900
that's

1359
01:03:49,220 --> 01:03:52,399
in a huge amount of decisions and it's

1360
01:03:50,900 --> 01:03:54,980
crushing a huge amount of data

1361
01:03:52,400 --> 01:03:56,780
theoretically faster than we can but

1362
01:03:54,980 --> 01:04:07,550
there's also a new style of computing to

1363
01:03:56,780 --> 01:04:09,380
go with it does that have an impact I

1364
01:04:07,550 --> 01:04:13,270
would assume that it will have a huge

1365
01:04:09,380 --> 01:04:25,369
impact yes large computing power but

1366
01:04:13,270 --> 01:04:29,420
maybe other folks no no sorry don't

1367
01:04:25,369 --> 01:04:31,400
happen easily after you so to answer the

1368
01:04:29,420 --> 01:04:34,089
question recently and there's a paper

1369
01:04:31,400 --> 01:04:36,579
that came out from MIT and IBM and other

1370
01:04:34,089 --> 01:04:39,578
academic community members is that

1371
01:04:36,579 --> 01:04:43,010
quantum is going is helping in certain

1372
01:04:39,579 --> 01:04:46,670
type of algorithms we are they're able

1373
01:04:43,010 --> 01:04:48,680
to learn about patterns and essentially

1374
01:04:46,670 --> 01:04:52,670
frequency mining or pattern mining right

1375
01:04:48,680 --> 01:04:55,819
now the advantage there is that if we

1376
01:04:52,670 --> 01:04:58,190
look at quantum computing it is really

1377
01:04:55,819 --> 01:05:01,190
good at modeling the natural behavior

1378
01:04:58,190 --> 01:05:05,480
natural phenomena right essentially I

1379
01:05:01,190 --> 01:05:07,849
would say you know from a classical

1380
01:05:05,480 --> 01:05:10,819
computer is really good at modeling

1381
01:05:07,849 --> 01:05:13,849
discrete behavior in the P and in the P

1382
01:05:10,819 --> 01:05:16,490
NP space okay which are not NP but which

1383
01:05:13,849 --> 01:05:19,099
in the P space but quantum computing

1384
01:05:16,490 --> 01:05:21,560
problems are moving too from discrete to

1385
01:05:19,099 --> 01:05:23,780
some form of continuous domain where you

1386
01:05:21,560 --> 01:05:26,089
can address some of the some of the NP

1387
01:05:23,780 --> 01:05:29,990
problems not np-hard but some of the

1388
01:05:26,089 --> 01:05:32,660
problems right as we move from in the

1389
01:05:29,990 --> 01:05:34,839
complexity theory from from classical

1390
01:05:32,660 --> 01:05:37,569
computers to quantum computers right

1391
01:05:34,839 --> 01:05:40,970
machine learning also has several

1392
01:05:37,569 --> 01:05:43,160
similar type of problems right how do

1393
01:05:40,970 --> 01:05:47,209
you learn about different patterns and I

1394
01:05:43,160 --> 01:05:50,180
believe it's going to help a lot in the

1395
01:05:47,210 --> 01:05:52,819
domain of learning these patterns in

1396
01:05:50,180 --> 01:05:58,720
tip-in from continuous functions okay

1397
01:05:52,819 --> 01:06:01,940
and if you look at secure cyber security

1398
01:05:58,720 --> 01:06:04,939
especially privacy in fact as

1399
01:06:01,940 --> 01:06:09,230
talking to someone about would privacy

1400
01:06:04,940 --> 01:06:14,780
be impacted by quantum computing in fact

1401
01:06:09,230 --> 01:06:17,780
we are working on a on a paper related

1402
01:06:14,780 --> 01:06:20,780
to how quantum computing and can help us

1403
01:06:17,780 --> 01:06:23,800
determine data which are sensitive and

1404
01:06:20,780 --> 01:06:30,319
not and then essentially privacy

1405
01:06:23,800 --> 01:06:34,520
protection better so I would it's not a

1406
01:06:30,319 --> 01:06:36,920
measure just an academic work at this at

1407
01:06:34,520 --> 01:06:39,980
this point there's nothing researcher we

1408
01:06:36,920 --> 01:06:44,619
are just dreaming about it but we'll see

1409
01:06:39,980 --> 01:06:48,349
how it goes so so my response to that is

1410
01:06:44,619 --> 01:06:51,380
in the whole domain of transformational

1411
01:06:48,349 --> 01:06:53,300
computing which quantum is a part of I

1412
01:06:51,380 --> 01:06:54,560
mean you can look at the processors I

1413
01:06:53,300 --> 01:06:56,240
don't think we talk much about the

1414
01:06:54,560 --> 01:06:57,920
actual electronics and processors but

1415
01:06:56,240 --> 01:06:59,000
that's a big part of it I mean we

1416
01:06:57,920 --> 01:07:00,829
couldn't do a lot of what we're doing

1417
01:06:59,000 --> 01:07:03,200
today if it weren't for highly paralyzed

1418
01:07:00,829 --> 01:07:05,930
GPUs or we're talking about neuromorphic

1419
01:07:03,200 --> 01:07:08,598
processors or custom Asics to just do AI

1420
01:07:05,930 --> 01:07:09,770
functions but it depends on what problem

1421
01:07:08,599 --> 01:07:11,210
you're trying to solve now if you're

1422
01:07:09,770 --> 01:07:13,490
dealing with the cybersecurity problem

1423
01:07:11,210 --> 01:07:16,430
distributed over large networks all over

1424
01:07:13,490 --> 01:07:17,959
the world you could design architectures

1425
01:07:16,430 --> 01:07:19,759
so you make sure you place your sensors

1426
01:07:17,960 --> 01:07:21,440
distributed also so you're talking about

1427
01:07:19,760 --> 01:07:23,750
computing at the edge and more the

1428
01:07:21,440 --> 01:07:25,550
Internet of Things and so you don't have

1429
01:07:23,750 --> 01:07:28,040
a centralized processor have you trying

1430
01:07:25,550 --> 01:07:29,750
to do a real-time problem you know

1431
01:07:28,040 --> 01:07:32,000
quantum computer you get a need a data

1432
01:07:29,750 --> 01:07:33,260
set it to be able to host the problem or

1433
01:07:32,000 --> 01:07:34,490
run your problem but if you're trying to

1434
01:07:33,260 --> 01:07:36,950
do something in real time or near

1435
01:07:34,490 --> 01:07:38,569
real-time it's really highly dependent

1436
01:07:36,950 --> 01:07:40,640
on the sensors you have available what

1437
01:07:38,569 --> 01:07:43,550
edge computing you have and try to pack

1438
01:07:40,640 --> 01:07:45,440
as much CPU horsepower hit the edge

1439
01:07:43,550 --> 01:07:47,089
devices as possible to solve a different

1440
01:07:45,440 --> 01:07:48,950
class of problems that could probably be

1441
01:07:47,089 --> 01:07:50,210
solved better that way than quantum in

1442
01:07:48,950 --> 01:07:51,200
quantum certainly depending on the

1443
01:07:50,210 --> 01:07:55,359
problem could do better than a

1444
01:07:51,200 --> 01:07:55,359
distributed cloud computing solution

1445
01:07:55,420 --> 01:08:01,099
I'll claim that fundamental problem in

1446
01:07:59,119 --> 01:08:03,530
AI and the fundamental reason why we're

1447
01:08:01,099 --> 01:08:06,079
seeing these big advances is not that

1448
01:08:03,530 --> 01:08:09,109
we've been committed by our computing

1449
01:08:06,079 --> 01:08:11,060
power it's that we've been limited by

1450
01:08:09,109 --> 01:08:15,049
the amount of data that we have

1451
01:08:11,060 --> 01:08:18,140
to use to to teach these systems for

1452
01:08:15,050 --> 01:08:20,260
these systems to learn from quantum

1453
01:08:18,140 --> 01:08:24,380
computing is not going to change that

1454
01:08:20,260 --> 01:08:26,770
inherently and as pointed out it'll

1455
01:08:24,380 --> 01:08:30,670
speed up certain types of calculations

1456
01:08:26,770 --> 01:08:34,160
but I think the fundamental issues are

1457
01:08:30,670 --> 01:08:37,910
how do we how do we train these systems

1458
01:08:34,160 --> 01:08:41,568
what does it mean and in particular from

1459
01:08:37,910 --> 01:08:48,830
a security point of view how do we use

1460
01:08:41,569 --> 01:08:50,330
these systems in a way that that are

1461
01:08:48,830 --> 01:08:54,080
going to work in the light of a

1462
01:08:50,330 --> 01:08:57,800
determined adversary who is going to try

1463
01:08:54,080 --> 01:09:00,350
to find where the systems aren't working

1464
01:08:57,800 --> 01:09:03,260
what they aren't addressing and I'm not

1465
01:09:00,350 --> 01:09:05,540
certain that that quantum is gonna make

1466
01:09:03,260 --> 01:09:07,910
a fundamental difference in dealing with

1467
01:09:05,540 --> 01:09:09,319
that problem for security it'll make

1468
01:09:07,910 --> 01:09:12,680
some fundamental differences in things

1469
01:09:09,319 --> 01:09:15,290
like cryptography these are going to be

1470
01:09:12,680 --> 01:09:19,819
big issues for us in the security but I

1471
01:09:15,290 --> 01:09:22,640
just I feel that this is not our

1472
01:09:19,819 --> 01:09:25,640
critical issue to think about we've got

1473
01:09:22,640 --> 01:09:27,140
much bigger issues to think about in how

1474
01:09:25,640 --> 01:09:31,089
we want to take advantage of this

1475
01:09:27,140 --> 01:09:31,089
technology to improve computer security

1476
01:09:31,810 --> 01:09:36,230
be up here for follow-up questions but

1477
01:09:34,520 --> 01:09:37,020
let's take this chance to thank them for

1478
01:09:36,229 --> 01:09:41,649
sharing their views

1479
01:09:37,020 --> 01:09:43,710
[Applause]

1480
01:09:41,649 --> 01:09:43,710
you

1481
01:09:50,939 --> 01:09:53,000
you

