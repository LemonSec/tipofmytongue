1
00:00:04,879 --> 00:00:10,440
so I'm at the point in my career can you

2
00:00:08,280 --> 00:00:12,059
hear me as a mic on yeah okay I'm at the

3
00:00:10,440 --> 00:00:15,268
point in my career where I'm better

4
00:00:12,059 --> 00:00:18,299
known for what I used to do which is

5
00:00:15,269 --> 00:00:20,490
kind of an age thing but I tell you

6
00:00:18,300 --> 00:00:24,900
coming here is really helpful for me

7
00:00:20,490 --> 00:00:26,970
because I feel young because Spath was

8
00:00:24,900 --> 00:00:29,159
one of the persons that you know was

9
00:00:26,970 --> 00:00:32,308
instrumental teaching me fundamentals of

10
00:00:29,160 --> 00:00:36,480
cybersecurity a long time ago and you're

11
00:00:32,308 --> 00:00:39,660
still going really strong so and so I'm

12
00:00:36,480 --> 00:00:40,349
impressed and I feel young so so thank

13
00:00:39,660 --> 00:00:43,739
you for that

14
00:00:40,350 --> 00:00:47,039
it was it was it was worth it so I'm

15
00:00:43,739 --> 00:00:49,260
gonna share with you my philosophy and

16
00:00:47,039 --> 00:00:51,180
I'm gonna start with definition of what

17
00:00:49,260 --> 00:00:53,968
resiliency is see resiliency when I

18
00:00:51,180 --> 00:00:57,120
started was very simple no security

19
00:00:53,969 --> 00:00:58,800
breaches and at a point in time you know

20
00:00:57,120 --> 00:01:02,849
a couple of decades ago that was

21
00:00:58,800 --> 00:01:04,500
reasonable it's not reasonable today and

22
00:01:02,850 --> 00:01:08,070
as a matter of fact many say that we're

23
00:01:04,500 --> 00:01:09,420
losing the war in cyber security to the

24
00:01:08,070 --> 00:01:11,100
criminals and to the nation

25
00:01:09,420 --> 00:01:13,200
state-sponsored threat actors and

26
00:01:11,100 --> 00:01:15,330
there's a pretty good argument for that

27
00:01:13,200 --> 00:01:16,740
and some compelling reason for that

28
00:01:15,330 --> 00:01:19,908
which does it it isn't all that

29
00:01:16,740 --> 00:01:22,919
inspiring to be a cyber security

30
00:01:19,909 --> 00:01:24,689
professional right and so at least some

31
00:01:22,920 --> 00:01:26,040
of you of course most of most of the

32
00:01:24,689 --> 00:01:28,559
students are in the back is that they

33
00:01:26,040 --> 00:01:31,290
just know more is that why so most of

34
00:01:28,560 --> 00:01:34,290
you that are students today it's not all

35
00:01:31,290 --> 00:01:36,570
that inspiring you know a motivation to

36
00:01:34,290 --> 00:01:39,259
think about you're gonna join a losing

37
00:01:36,570 --> 00:01:41,908
cause right it's not all that compelling

38
00:01:39,259 --> 00:01:45,479
and so what I'm suggesting to you is

39
00:01:41,909 --> 00:01:47,610
change the definition of resiliency for

40
00:01:45,479 --> 00:01:49,619
an enterprise and resiliency for an

41
00:01:47,610 --> 00:01:52,979
enterprise from my definition is an

42
00:01:49,619 --> 00:01:56,340
enterprise that can recover quickly with

43
00:01:52,979 --> 00:01:58,380
minimal business impact which means that

44
00:01:56,340 --> 00:02:01,290
you're gonna have many security

45
00:01:58,380 --> 00:02:04,949
incidents so the enterprise that I work

46
00:02:01,290 --> 00:02:08,399
for just in the cyber side we have 300 a

47
00:02:04,950 --> 00:02:10,590
year so that's the average of what we

48
00:02:08,399 --> 00:02:12,810
have on an annual basis in terms of

49
00:02:10,590 --> 00:02:13,709
security incidents we also have a lot of

50
00:02:12,810 --> 00:02:15,689
synthetic

51
00:02:13,709 --> 00:02:19,349
security incidents anybody know what a

52
00:02:15,689 --> 00:02:22,049
synthetic security incident is okay I'll

53
00:02:19,349 --> 00:02:25,109
- I'll explain that to you I don't know

54
00:02:22,049 --> 00:02:27,390
how widely used term that is but it's

55
00:02:25,110 --> 00:02:30,599
very simple when you test a control

56
00:02:27,390 --> 00:02:32,760
that's a synthetic incident so if you do

57
00:02:30,599 --> 00:02:36,089
a red team review that's a synthetic

58
00:02:32,760 --> 00:02:38,129
incident so capturing lessons learned

59
00:02:36,090 --> 00:02:40,680
from incidents is kind of a essential

60
00:02:38,129 --> 00:02:42,328
and I mentioned that resilience is where

61
00:02:40,680 --> 00:02:45,180
we change a lot so here's part of my

62
00:02:42,329 --> 00:02:48,659
philosophy which is basically respond

63
00:02:45,180 --> 00:02:52,430
quickly which is essentially building

64
00:02:48,659 --> 00:02:54,388
into an enterprise the same fundamental

65
00:02:52,430 --> 00:02:59,760
mechanisms that are in place in your

66
00:02:54,389 --> 00:03:04,530
body in your immune system so you get

67
00:02:59,760 --> 00:03:07,439
exposed to bacteria and viruses every

68
00:03:04,530 --> 00:03:10,409
day and the way your body responds to

69
00:03:07,439 --> 00:03:12,540
that is your body sends any bodies to

70
00:03:10,409 --> 00:03:16,379
attack the bacteria that enter your

71
00:03:12,540 --> 00:03:19,168
system and your body recovers and

72
00:03:16,379 --> 00:03:21,599
responds sometimes you know without any

73
00:03:19,169 --> 00:03:22,590
side effects whatsoever sometimes you

74
00:03:21,599 --> 00:03:26,488
might catch a cold

75
00:03:22,590 --> 00:03:29,579
as a result but you get better now the

76
00:03:26,489 --> 00:03:33,290
better your immune system is so less you

77
00:03:29,579 --> 00:03:36,269
feel the effects of getting exposed

78
00:03:33,290 --> 00:03:39,780
enterprise's need an immune system that

79
00:03:36,269 --> 00:03:43,019
allows anyone at any level to surface a

80
00:03:39,780 --> 00:03:45,599
problem and anyone at any level to be

81
00:03:43,019 --> 00:03:48,180
able to solve a problem solving a

82
00:03:45,599 --> 00:03:50,220
problem improving processes to make

83
00:03:48,180 --> 00:03:52,949
processes more efficient and effective

84
00:03:50,220 --> 00:03:55,139
well that's resiliency and your

85
00:03:52,949 --> 00:03:57,060
cybersecurity practices can be the best

86
00:03:55,139 --> 00:04:00,329
in the world if you don't have a

87
00:03:57,060 --> 00:04:04,829
foundation of being able to discover big

88
00:04:00,329 --> 00:04:08,430
problems talk about big problems even in

89
00:04:04,829 --> 00:04:10,739
the boardroom and then solve big

90
00:04:08,430 --> 00:04:12,329
problems doesn't matter how good your

91
00:04:10,739 --> 00:04:14,639
security controls are your Nevele

92
00:04:12,329 --> 00:04:21,510
achieve resiliency from enterprise

93
00:04:14,639 --> 00:04:23,969
perspective so I'm an acquired taste for

94
00:04:21,510 --> 00:04:25,830
as a C so I'm just telling you that

95
00:04:23,969 --> 00:04:27,510
because one of the first things I tell

96
00:04:25,830 --> 00:04:30,510
the board and I did this recent

97
00:04:27,510 --> 00:04:31,800
for the CBS board as I said I guarantee

98
00:04:30,510 --> 00:04:34,460
you you will have more security

99
00:04:31,800 --> 00:04:38,040
incidents which typically isn't

100
00:04:34,460 --> 00:04:40,950
compelling you know sales tactic if you

101
00:04:38,040 --> 00:04:44,670
want to get a seaso job but the reason

102
00:04:40,950 --> 00:04:47,640
for that is because we'll put controls

103
00:04:44,670 --> 00:04:52,020
in place that have a better opportunity

104
00:04:47,640 --> 00:04:54,000
to find control breaks control breaks

105
00:04:52,020 --> 00:04:56,099
are where controls aren't working

106
00:04:54,000 --> 00:04:58,590
synthetic controls are part synthetic

107
00:04:56,100 --> 00:05:00,150
incidents are part of that and part of

108
00:04:58,590 --> 00:05:02,549
it is because you have better diagnostic

109
00:05:00,150 --> 00:05:06,359
tools because we'll know what risks

110
00:05:02,550 --> 00:05:12,450
there are so the other thing is I don't

111
00:05:06,360 --> 00:05:15,330
follow what my peers do and I listen to

112
00:05:12,450 --> 00:05:16,110
a lot of smart people spaff being one of

113
00:05:15,330 --> 00:05:17,909
them

114
00:05:16,110 --> 00:05:21,780
that's have you know tremendous impact

115
00:05:17,910 --> 00:05:25,920
on what I do but I pay little attention

116
00:05:21,780 --> 00:05:27,780
to what my peer group does specifically

117
00:05:25,920 --> 00:05:31,220
what controls they're using in their

118
00:05:27,780 --> 00:05:36,419
environment now the reason for that is

119
00:05:31,220 --> 00:05:40,860
largely a threat actor is somebody that

120
00:05:36,420 --> 00:05:42,900
I'm trying to create friction for and so

121
00:05:40,860 --> 00:05:44,790
some of that friction comes from having

122
00:05:42,900 --> 00:05:49,469
controls in my environment that aren't

123
00:05:44,790 --> 00:05:52,680
in other environments and and I also use

124
00:05:49,470 --> 00:05:55,530
early-stage companies to drive

125
00:05:52,680 --> 00:05:57,650
innovation in control design because

126
00:05:55,530 --> 00:06:00,450
that's where the innovation comes from

127
00:05:57,650 --> 00:06:04,200
just largely for economic reasons and

128
00:06:00,450 --> 00:06:06,409
I'll explain that so what I'm going to

129
00:06:04,200 --> 00:06:11,039
share with you in terms of what I do

130
00:06:06,410 --> 00:06:13,770
please shred it challenge it you throw

131
00:06:11,040 --> 00:06:18,030
your best challenge at it I'm fine with

132
00:06:13,770 --> 00:06:22,380
it but I and what I'm doing is not what

133
00:06:18,030 --> 00:06:25,049
my most of my peers do so I mentioned

134
00:06:22,380 --> 00:06:26,880
this in the panel that we had the

135
00:06:25,050 --> 00:06:29,610
difference between compliance based and

136
00:06:26,880 --> 00:06:32,630
risk based I'll give you an example of

137
00:06:29,610 --> 00:06:35,730
this you're familiar I think with these

138
00:06:32,630 --> 00:06:38,550
NIST frameworks here

139
00:06:35,730 --> 00:06:40,290
these standards and from a risk

140
00:06:38,550 --> 00:06:41,280
standpoint if we just look at email I

141
00:06:40,290 --> 00:06:44,070
mentioned the D

142
00:06:41,280 --> 00:06:46,679
mark case I meant in that but these

143
00:06:44,070 --> 00:06:50,040
other examples are unconventional

144
00:06:46,680 --> 00:06:52,919
controls they're not part of a risk

145
00:06:50,040 --> 00:06:54,720
framework in some cases you've never

146
00:06:52,919 --> 00:06:58,830
seen them before but they're highly

147
00:06:54,720 --> 00:07:01,919
effective at driving trust into an email

148
00:06:58,830 --> 00:07:03,539
system that all of us are using today

149
00:07:01,919 --> 00:07:06,630
that doesn't have a whole lot of trust

150
00:07:03,540 --> 00:07:09,600
in it in fact if we look at the

151
00:07:06,630 --> 00:07:11,880
conventional side of the house for email

152
00:07:09,600 --> 00:07:13,620
specifically phishing which is the

153
00:07:11,880 --> 00:07:18,150
number one threat vector of any

154
00:07:13,620 --> 00:07:22,230
enterprise today what the authoritative

155
00:07:18,150 --> 00:07:24,570
sources tell us is teach your employees

156
00:07:22,230 --> 00:07:27,840
in an enterprise to recognize phishing

157
00:07:24,570 --> 00:07:32,550
attacks and kind of the human firewall

158
00:07:27,840 --> 00:07:35,159
construct of you know being smarter so

159
00:07:32,550 --> 00:07:37,370
let's look at that from it in my

160
00:07:35,160 --> 00:07:40,110
organization we have a world-class

161
00:07:37,370 --> 00:07:43,560
capability at teaching people how to

162
00:07:40,110 --> 00:07:46,380
recognize phishing capability when we do

163
00:07:43,560 --> 00:07:49,050
phishing tests simulated tests synthetic

164
00:07:46,380 --> 00:07:51,390
incidents another example when we share

165
00:07:49,050 --> 00:07:54,090
phishing emails with someone and see if

166
00:07:51,390 --> 00:07:57,090
they click on it we're at between five

167
00:07:54,090 --> 00:08:00,719
to seven percent of people responding on

168
00:07:57,090 --> 00:08:04,440
the bait of the phishing email as a

169
00:08:00,720 --> 00:08:07,080
reference point ten percent is

170
00:08:04,440 --> 00:08:10,680
world-class okay so we're in the

171
00:08:07,080 --> 00:08:14,039
world-class level in terms of teaching

172
00:08:10,680 --> 00:08:15,720
people to recognize phishing emails but

173
00:08:14,039 --> 00:08:17,400
if we look at what that actually means

174
00:08:15,720 --> 00:08:19,460
that means five to seven percent of

175
00:08:17,400 --> 00:08:24,120
everybody that clicks on it gets hosed

176
00:08:19,460 --> 00:08:27,780
right they're owned right and that's the

177
00:08:24,120 --> 00:08:30,030
best that we can do so does that sound

178
00:08:27,780 --> 00:08:31,919
like a sustainable model to you because

179
00:08:30,030 --> 00:08:33,270
it doesn't to me emails kind of

180
00:08:31,919 --> 00:08:35,819
important to my enterprise is it

181
00:08:33,270 --> 00:08:39,390
important to yours so why are you

182
00:08:35,820 --> 00:08:41,729
spending money and time to teach people

183
00:08:39,390 --> 00:08:43,380
when the best that you could do is about

184
00:08:41,729 --> 00:08:46,410
ten percent of people are still gonna

185
00:08:43,380 --> 00:08:48,570
click on it and get owned right it's not

186
00:08:46,410 --> 00:08:50,490
a sustainable model it happens to be

187
00:08:48,570 --> 00:08:53,220
what our conventional wisdom and

188
00:08:50,490 --> 00:08:55,519
controls tell us to do every

189
00:08:53,220 --> 00:08:59,160
authoritative source says to do this

190
00:08:55,519 --> 00:09:02,480
there's a better way the better way is

191
00:08:59,160 --> 00:09:05,600
put trust into the email system by

192
00:09:02,480 --> 00:09:07,769
canoeing unconventional controls

193
00:09:05,600 --> 00:09:09,480
unconventional controls don't exist in

194
00:09:07,769 --> 00:09:13,079
the risk framework they're not discussed

195
00:09:09,480 --> 00:09:17,040
by authoritative sources but an example

196
00:09:13,079 --> 00:09:20,459
is if you write a script attached to

197
00:09:17,040 --> 00:09:23,430
your email gateway that takes a feed

198
00:09:20,459 --> 00:09:27,689
from a Intel provider that lists every

199
00:09:23,430 --> 00:09:30,390
domain registered and then you flag any

200
00:09:27,690 --> 00:09:35,570
email coming from a newly registered

201
00:09:30,390 --> 00:09:39,089
domain and don't deliver it for 48 hours

202
00:09:35,570 --> 00:09:41,970
you now have eliminated a large

203
00:09:39,089 --> 00:09:47,390
percentage and source of your phishing

204
00:09:41,970 --> 00:09:51,089
emails and your spam why because any

205
00:09:47,390 --> 00:09:53,189
criminal that sets up a new domain sends

206
00:09:51,089 --> 00:09:54,720
the majority of the email not first 48

207
00:09:53,190 --> 00:09:57,149
hours because after that the spam

208
00:09:54,720 --> 00:10:00,480
filters catch up and figure it out so

209
00:09:57,149 --> 00:10:05,100
they're cycling through new domains so

210
00:10:00,480 --> 00:10:08,670
no legitimate domain sends mass email on

211
00:10:05,100 --> 00:10:10,470
day 1 day 1 you set up the domain you

212
00:10:08,670 --> 00:10:12,000
gotta make sure it works right you send

213
00:10:10,470 --> 00:10:14,850
an email to your buddies or you know to

214
00:10:12,000 --> 00:10:16,649
the administrators that's it you're not

215
00:10:14,850 --> 00:10:18,810
sending massive emails so all you have

216
00:10:16,649 --> 00:10:22,199
to do is drop that email the business

217
00:10:18,810 --> 00:10:25,439
impact is like minimal and it's a simple

218
00:10:22,199 --> 00:10:28,410
script that you write it's not a

219
00:10:25,440 --> 00:10:29,820
conventional control but it works right

220
00:10:28,410 --> 00:10:31,500
it's kind of a bootstrap kind of

221
00:10:29,820 --> 00:10:33,029
approach that's an unconventional

222
00:10:31,500 --> 00:10:34,680
control and that's the difference

223
00:10:33,029 --> 00:10:36,510
between compliance based security and

224
00:10:34,680 --> 00:10:38,670
risk driven security I'm going to show

225
00:10:36,510 --> 00:10:41,399
you a couple other examples of that but

226
00:10:38,670 --> 00:10:43,800
here's the deal there's a big gap

227
00:10:41,399 --> 00:10:46,230
between these two and it's getting

228
00:10:43,800 --> 00:10:48,479
bigger and if you want resilience you

229
00:10:46,230 --> 00:10:51,029
got to be over on this side you got to

230
00:10:48,480 --> 00:10:53,399
use unconventional controls if you want

231
00:10:51,029 --> 00:10:55,380
to avoid major security the business

232
00:10:53,399 --> 00:10:58,829
impact of security breaches now any

233
00:10:55,380 --> 00:11:04,140
policy walks in the room anybody

234
00:10:58,829 --> 00:11:06,540
recognize this one that would be no ok

235
00:11:04,140 --> 00:11:08,490
not any powers that's ok that's that

236
00:11:06,540 --> 00:11:08,949
speaks highly of you is an audience just

237
00:11:08,490 --> 00:11:11,230
so

238
00:11:08,949 --> 00:11:14,019
if you answer that question then I know

239
00:11:11,230 --> 00:11:16,119
you're really true geek so 800 177 is

240
00:11:14,019 --> 00:11:17,769
actually trusted email it's a and it's

241
00:11:16,119 --> 00:11:21,720
actually d mark it's what I mentioned

242
00:11:17,769 --> 00:11:25,899
earlier and this came out with this in

243
00:11:21,720 --> 00:11:27,819
let's see was it three years ago so it's

244
00:11:25,899 --> 00:11:29,499
an example of an unconventional control

245
00:11:27,819 --> 00:11:31,419
that became a conventional control now

246
00:11:29,499 --> 00:11:33,939
and eventually unconventional controls

247
00:11:31,419 --> 00:11:36,910
do become conventional controls it just

248
00:11:33,939 --> 00:11:40,118
takes a cycle of time before the

249
00:11:36,910 --> 00:11:42,069
standards are updated so if you're

250
00:11:40,119 --> 00:11:44,619
investing here eventually they become

251
00:11:42,069 --> 00:11:47,378
conventional controls okay so I'm gonna

252
00:11:44,619 --> 00:11:51,160
give you an example here where this is

253
00:11:47,379 --> 00:11:53,079
the insurance division of CBS we and

254
00:11:51,160 --> 00:11:54,850
this is like four years old or five

255
00:11:53,079 --> 00:11:56,108
years old this data so we had twenty

256
00:11:54,850 --> 00:11:57,850
nine thousand two hundred thirty one

257
00:11:56,109 --> 00:11:59,529
server sending us email every day and we

258
00:11:57,850 --> 00:12:01,779
treated every server the same way that's

259
00:11:59,529 --> 00:12:04,809
why they're all grey dots there right so

260
00:12:01,779 --> 00:12:07,059
and we did some filtering of the servers

261
00:12:04,809 --> 00:12:10,480
based on the domain attributes of the

262
00:12:07,059 --> 00:12:12,999
sending domain not the attachments right

263
00:12:10,480 --> 00:12:16,720
not any campaigns or anything like that

264
00:12:12,999 --> 00:12:19,269
we looked at pure attributes of the

265
00:12:16,720 --> 00:12:21,459
sending domain and what we discovered is

266
00:12:19,269 --> 00:12:24,579
a breakdown where fourteen thousand five

267
00:12:21,459 --> 00:12:26,738
hundred twenty-six senders of email to

268
00:12:24,579 --> 00:12:29,799
us on a daily basis are sending

269
00:12:26,739 --> 00:12:32,709
malicious email so instead of just

270
00:12:29,799 --> 00:12:35,350
letting that email in we decided to

271
00:12:32,709 --> 00:12:37,628
filter that email and not deliver it now

272
00:12:35,350 --> 00:12:41,529
when you don't deliver that email the

273
00:12:37,629 --> 00:12:43,839
user doesn't see that email so if the

274
00:12:41,529 --> 00:12:45,549
users not seeing the fourteen thousand

275
00:12:43,839 --> 00:12:47,649
you know the email from 14,000 plus

276
00:12:45,549 --> 00:12:49,059
servers that sending and that we're

277
00:12:47,649 --> 00:12:50,649
talking about you know millions and

278
00:12:49,059 --> 00:12:52,480
millions of email messages that aren't

279
00:12:50,649 --> 00:12:59,110
being seen what happens to the

280
00:12:52,480 --> 00:13:02,829
experience of the user using email it's

281
00:12:59,110 --> 00:13:06,939
improved there's less clutter there's

282
00:13:02,829 --> 00:13:10,539
more legitimate email you respond and

283
00:13:06,939 --> 00:13:13,498
react to the email you start to trust

284
00:13:10,539 --> 00:13:17,169
the email more so these are

285
00:13:13,499 --> 00:13:20,589
unconventional controls that actually

286
00:13:17,169 --> 00:13:22,300
add trust into your email ecosystem

287
00:13:20,589 --> 00:13:28,080
rather than extracting

288
00:13:22,300 --> 00:13:30,040
trust out at a cost so the second

289
00:13:28,080 --> 00:13:31,900
control that I'm going to cover today is

290
00:13:30,040 --> 00:13:36,610
relatively new it's in production today

291
00:13:31,900 --> 00:13:39,040
and it's basically about 50% of the

292
00:13:36,610 --> 00:13:43,570
phishing emails that get through all of

293
00:13:39,040 --> 00:13:47,410
our other filters are stopped by this

294
00:13:43,570 --> 00:13:49,450
control and we're tuning the algorithm

295
00:13:47,410 --> 00:13:53,589
and over time we think that we're going

296
00:13:49,450 --> 00:13:56,290
to get that up into the 90s so we'll

297
00:13:53,590 --> 00:13:58,180
we'll take phishing emails and in our

298
00:13:56,290 --> 00:14:02,170
enterprise and take them down to a

299
00:13:58,180 --> 00:14:05,560
trickle and the way we're doing it the

300
00:14:02,170 --> 00:14:07,990
there's four types of fishing there's

301
00:14:05,560 --> 00:14:10,300
four tactics that you can use to send a

302
00:14:07,990 --> 00:14:13,450
phishing email spoofing that main was

303
00:14:10,300 --> 00:14:15,219
one display look-alike domain was the

304
00:14:13,450 --> 00:14:16,810
second display name deception is the

305
00:14:15,220 --> 00:14:19,120
third the fourth one is the

306
00:14:16,810 --> 00:14:21,869
fastest-growing one so if you look at in

307
00:14:19,120 --> 00:14:24,610
your enterprises the fastest-growing

308
00:14:21,870 --> 00:14:27,370
phishing emails using this tactic the

309
00:14:24,610 --> 00:14:31,660
tactic is simple I'm gonna take

310
00:14:27,370 --> 00:14:34,120
credentials from my friend and to my

311
00:14:31,660 --> 00:14:36,370
friends email and I'm gonna send you

312
00:14:34,120 --> 00:14:38,140
have any friends in the room here I mean

313
00:14:36,370 --> 00:14:40,210
I know they're friendly but do you know

314
00:14:38,140 --> 00:14:42,160
anybody in the room here yeah this guy

315
00:14:40,210 --> 00:14:45,220
thought so okay so what I'm gonna do is

316
00:14:42,160 --> 00:14:47,199
I'm gonna send an email but I own the

317
00:14:45,220 --> 00:14:49,570
credentials to her email and I'm gonna

318
00:14:47,200 --> 00:14:51,430
send it to you you get email from her

319
00:14:49,570 --> 00:14:53,380
all the time a lot of times it has some

320
00:14:51,430 --> 00:14:55,599
pity humor that's really cute you look

321
00:14:53,380 --> 00:14:57,490
forward to that but this time I'm gonna

322
00:14:55,600 --> 00:14:59,290
be sending the email you're not gonna

323
00:14:57,490 --> 00:15:02,140
know about it and you're gonna think

324
00:14:59,290 --> 00:15:03,610
that it's the email coming from here so

325
00:15:02,140 --> 00:15:06,130
you're gonna trust it a lot more as a

326
00:15:03,610 --> 00:15:08,380
result of that and it's gonna get

327
00:15:06,130 --> 00:15:10,150
through all the spam filters and all of

328
00:15:08,380 --> 00:15:12,760
the inbound filters because it's a

329
00:15:10,150 --> 00:15:14,890
legitimate email account nobody knows

330
00:15:12,760 --> 00:15:17,319
that it's not I just own the credentials

331
00:15:14,890 --> 00:15:19,500
for it so I'm sending email from a

332
00:15:17,320 --> 00:15:22,960
compromised email account

333
00:15:19,500 --> 00:15:26,860
that's the fastest-growing segment and

334
00:15:22,960 --> 00:15:28,950
most commercial fraudsters are using

335
00:15:26,860 --> 00:15:32,410
that technique more and more there is no

336
00:15:28,950 --> 00:15:34,720
control today necessarily that we have

337
00:15:32,410 --> 00:15:35,959
in place we have to design a control to

338
00:15:34,720 --> 00:15:38,810
stop that particular

339
00:15:35,960 --> 00:15:41,360
tactic because the other three tactics

340
00:15:38,810 --> 00:15:43,760
that I shared with you are all stopped

341
00:15:41,360 --> 00:15:45,890
by the unconventional controls that I

342
00:15:43,760 --> 00:15:48,050
shared but this last one is a bit more

343
00:15:45,890 --> 00:15:51,130
challenging so what we're doing is were

344
00:15:48,050 --> 00:15:54,680
basically we created this algorithm

345
00:15:51,130 --> 00:15:57,920
based on 200 billion emails that get

346
00:15:54,680 --> 00:16:02,810
sent a year across all enterprises and

347
00:15:57,920 --> 00:16:05,810
we are now filtering the email based on

348
00:16:02,810 --> 00:16:09,560
attributes of how the email message was

349
00:16:05,810 --> 00:16:13,819
written compared to what is normal by

350
00:16:09,560 --> 00:16:17,780
the email account owner so you're smart

351
00:16:13,820 --> 00:16:20,510
you know concise fit the kinds of emails

352
00:16:17,780 --> 00:16:22,120
that you're accustomed to establishes a

353
00:16:20,510 --> 00:16:26,330
pattern that we can represent

354
00:16:22,120 --> 00:16:30,800
mathematically my blunt lousy English

355
00:16:26,330 --> 00:16:34,400
you know types of emails that I write in

356
00:16:30,800 --> 00:16:37,609
your account don't map to what is the

357
00:16:34,400 --> 00:16:40,370
norm that you typically use and that

358
00:16:37,610 --> 00:16:43,100
Flags a risk score that's a deviation

359
00:16:40,370 --> 00:16:46,670
from what the pattern is and that risk

360
00:16:43,100 --> 00:16:49,850
score is fed into the inbound email

361
00:16:46,670 --> 00:16:52,099
filtering capability and we decide what

362
00:16:49,850 --> 00:16:54,260
to do if the risk score is high we drop

363
00:16:52,100 --> 00:16:56,540
it and don't deliver the email because

364
00:16:54,260 --> 00:16:58,780
it's from a compromised email account if

365
00:16:56,540 --> 00:17:01,939
the risk score is low we send it through

366
00:16:58,780 --> 00:17:03,980
unfettered so what we're doing is we're

367
00:17:01,940 --> 00:17:07,040
mapping a bunch of attributes on the

368
00:17:03,980 --> 00:17:09,980
actual email that's being sent and

369
00:17:07,040 --> 00:17:13,069
whether the email gets distributed to a

370
00:17:09,980 --> 00:17:15,589
large number of people or a small number

371
00:17:13,069 --> 00:17:18,399
of people or the specific people all of

372
00:17:15,589 --> 00:17:23,450
that is being mapped in this algorithm

373
00:17:18,400 --> 00:17:27,709
that allows us to map the tag the email

374
00:17:23,450 --> 00:17:30,890
itself to the account owner and provide

375
00:17:27,709 --> 00:17:32,690
some sort of credibility score that we

376
00:17:30,890 --> 00:17:34,300
can apply on the inbound side so we're

377
00:17:32,690 --> 00:17:39,760
doing that today

378
00:17:34,300 --> 00:17:44,480
and again we're we're at a point where

379
00:17:39,760 --> 00:17:46,850
270,000 employees and I get somewhere

380
00:17:44,480 --> 00:17:49,150
between four and seven phishing emails

381
00:17:46,850 --> 00:17:51,399
that get through all of the control

382
00:17:49,150 --> 00:17:54,430
that we have in place today on that

383
00:17:51,400 --> 00:17:55,960
basis and I think that's pretty good but

384
00:17:54,430 --> 00:17:57,640
I've been measuring that for five years

385
00:17:55,960 --> 00:18:00,070
and it's as good as we've ever gotten it

386
00:17:57,640 --> 00:18:01,810
any of you can do better than that I'm

387
00:18:00,070 --> 00:18:04,960
all ears

388
00:18:01,810 --> 00:18:07,720
so I mentioned security incidents and

389
00:18:04,960 --> 00:18:10,330
they were really where we manufacture

390
00:18:07,720 --> 00:18:12,850
incidents our Incident Response process

391
00:18:10,330 --> 00:18:15,370
has this fifth step here which is

392
00:18:12,850 --> 00:18:17,860
lessons learned there is no better way

393
00:18:15,370 --> 00:18:20,889
to learn about the effectiveness of your

394
00:18:17,860 --> 00:18:21,669
controls than an incident so don't let

395
00:18:20,890 --> 00:18:25,030
it go to waste

396
00:18:21,670 --> 00:18:27,160
celebrate it we get excited when we have

397
00:18:25,030 --> 00:18:29,110
security incidents because we get to

398
00:18:27,160 --> 00:18:31,750
learn something and we get to learn

399
00:18:29,110 --> 00:18:34,810
something that we don't learn every day

400
00:18:31,750 --> 00:18:36,460
and that's positive now a lot of people

401
00:18:34,810 --> 00:18:38,320
think of security incidents like the sky

402
00:18:36,460 --> 00:18:41,290
is falling and you know got to go find a

403
00:18:38,320 --> 00:18:42,939
new job in our case we look forward to

404
00:18:41,290 --> 00:18:44,260
this we celebrate the fact that we have

405
00:18:42,940 --> 00:18:46,240
an incident because we get to harvest

406
00:18:44,260 --> 00:18:49,540
the lessons learned and we turn them

407
00:18:46,240 --> 00:18:53,970
into remediation plans that we track and

408
00:18:49,540 --> 00:18:57,100
measure so an example is we had a

409
00:18:53,970 --> 00:19:00,190
security incident these are examples of

410
00:18:57,100 --> 00:19:02,649
the finding which is kind of lessons

411
00:19:00,190 --> 00:19:06,040
learned the remediation item who owns it

412
00:19:02,650 --> 00:19:08,290
and we track the target dates for all of

413
00:19:06,040 --> 00:19:10,870
those 300 incidents that I mentioned to

414
00:19:08,290 --> 00:19:13,629
you all of this is tracked in terms of

415
00:19:10,870 --> 00:19:15,580
the remediation effort and because we

416
00:19:13,630 --> 00:19:18,520
learned something from the incidents we

417
00:19:15,580 --> 00:19:20,080
change and adjust our priorities on the

418
00:19:18,520 --> 00:19:22,180
allocation of scarce resource to the

419
00:19:20,080 --> 00:19:23,919
highest risk based on what we learn from

420
00:19:22,180 --> 00:19:26,200
the incidents this is the most valuable

421
00:19:23,920 --> 00:19:29,860
source of information we have except for

422
00:19:26,200 --> 00:19:33,760
synthetic incidents synthetic incidents

423
00:19:29,860 --> 00:19:36,490
are red teams that we're doing or other

424
00:19:33,760 --> 00:19:38,740
internal control testing that we do

425
00:19:36,490 --> 00:19:40,750
where we discover that a control is not

426
00:19:38,740 --> 00:19:42,370
work and then we follow the same process

427
00:19:40,750 --> 00:19:44,890
capture the lessons learn and go through

428
00:19:42,370 --> 00:19:48,310
this so the control break is essentially

429
00:19:44,890 --> 00:19:50,920
where you in the cyber security

430
00:19:48,310 --> 00:19:53,310
organization dis determine that a

431
00:19:50,920 --> 00:19:56,260
control is not working effectively and

432
00:19:53,310 --> 00:19:58,000
you treat it like an incident you

433
00:19:56,260 --> 00:20:00,220
harvest the lessons learned and you

434
00:19:58,000 --> 00:20:02,830
implement a remediation plan to fix

435
00:20:00,220 --> 00:20:05,799
whatever you can do to fix that

436
00:20:02,830 --> 00:20:08,230
control now if someone else discovers

437
00:20:05,799 --> 00:20:10,690
that then it's an auditable right an

438
00:20:08,230 --> 00:20:12,820
auditor or regulator discovers that a

439
00:20:10,690 --> 00:20:16,210
little more pain associated with that

440
00:20:12,820 --> 00:20:20,649
but frankly you should be able to have

441
00:20:16,210 --> 00:20:23,049
some rings of control review that are

442
00:20:20,649 --> 00:20:25,360
baked in so what we do is we have we

443
00:20:23,049 --> 00:20:27,820
take the top risks for the enterprise or

444
00:20:25,360 --> 00:20:30,428
in each individual business and then we

445
00:20:27,820 --> 00:20:33,490
identify the key controls the key top

446
00:20:30,429 --> 00:20:35,740
controls or the top key controls that

447
00:20:33,490 --> 00:20:38,740
relate to those risks and we test them

448
00:20:35,740 --> 00:20:40,029
specifically every quarter and we rotate

449
00:20:38,740 --> 00:20:44,289
that every quarter so we're testing

450
00:20:40,029 --> 00:20:46,750
always the top controls that align to

451
00:20:44,289 --> 00:20:49,179
the top risks and we discover control

452
00:20:46,750 --> 00:20:51,639
breaks and they're a lot less painful

453
00:20:49,179 --> 00:20:53,350
when you discover them when auditors

454
00:20:51,639 --> 00:20:55,570
don't discover them you allocate

455
00:20:53,350 --> 00:20:58,779
resources to fix based on that so I'm

456
00:20:55,570 --> 00:21:01,689
gonna change the paradigm a little bit

457
00:20:58,779 --> 00:21:03,279
and I'm gonna talk about two things that

458
00:21:01,690 --> 00:21:07,059
really don't belong together passwords

459
00:21:03,279 --> 00:21:09,610
and people now we have 60 years of

460
00:21:07,059 --> 00:21:12,490
history using passwords to protect the

461
00:21:09,610 --> 00:21:14,678
enterprise and by and large it's done

462
00:21:12,490 --> 00:21:18,190
it's done pretty well passwords have

463
00:21:14,679 --> 00:21:20,820
done pretty well but the unfortunate

464
00:21:18,190 --> 00:21:23,710
thing is that for all six years

465
00:21:20,820 --> 00:21:26,139
passwords are based on a fundamental

466
00:21:23,710 --> 00:21:30,399
principle the fundamental principle is

467
00:21:26,139 --> 00:21:32,049
that you are the only person that has or

468
00:21:30,399 --> 00:21:35,620
knows your secret

469
00:21:32,049 --> 00:21:38,820
that's the principle and for 60 years

470
00:21:35,620 --> 00:21:42,549
that served us well unfortunately that

471
00:21:38,820 --> 00:21:45,939
principle or premise today that he's the

472
00:21:42,549 --> 00:21:50,200
only one that has his password is no

473
00:21:45,940 --> 00:21:53,409
longer valid and in fact every day it

474
00:21:50,200 --> 00:21:56,370
becomes less valid and the reason for

475
00:21:53,409 --> 00:21:59,019
that is that about five years ago

476
00:21:56,370 --> 00:22:03,158
criminal syndicates cyber criminal

477
00:21:59,019 --> 00:22:06,389
syndicates who by definition always look

478
00:22:03,159 --> 00:22:09,220
for the easiest way to get into data

479
00:22:06,389 --> 00:22:11,408
always they always look for the easiest

480
00:22:09,220 --> 00:22:14,740
way what's the easiest way to get access

481
00:22:11,409 --> 00:22:17,880
to data today yeah

482
00:22:14,740 --> 00:22:21,340
yeah that's exactly right using a

483
00:22:17,880 --> 00:22:23,380
password that's a legitimate credential

484
00:22:21,340 --> 00:22:25,720
however you do you're guessing it is

485
00:22:23,380 --> 00:22:28,779
good enough but how are we get access to

486
00:22:25,720 --> 00:22:30,640
it if you do you provide that credential

487
00:22:28,779 --> 00:22:32,830
into the system user ID and password

488
00:22:30,640 --> 00:22:35,039
combination and what does the system do

489
00:22:32,830 --> 00:22:37,510
it trusts you

490
00:22:35,039 --> 00:22:41,908
that's what all our systems are designed

491
00:22:37,510 --> 00:22:45,658
to do and the reason for that is

492
00:22:41,909 --> 00:22:50,799
authentication when we learned

493
00:22:45,659 --> 00:22:53,350
technology a few years ago technology

494
00:22:50,799 --> 00:22:56,500
taught us that authentication was an

495
00:22:53,350 --> 00:22:59,799
event at a beginning and had it end in a

496
00:22:56,500 --> 00:23:03,159
binary outcome and for all of these

497
00:22:59,799 --> 00:23:06,010
years that baked into the way we think

498
00:23:03,159 --> 00:23:08,080
about authentication and it's baked into

499
00:23:06,010 --> 00:23:10,360
the fabric of every authentication

500
00:23:08,080 --> 00:23:16,510
control that we use in the enterprise

501
00:23:10,360 --> 00:23:18,309
today it's obsolete it's obsolete simply

502
00:23:16,510 --> 00:23:21,370
because every binary control can be

503
00:23:18,309 --> 00:23:24,250
defeated so if I'm taking user ID and

504
00:23:21,370 --> 00:23:27,489
password I'm adding on to it a SMS push

505
00:23:24,250 --> 00:23:32,200
of a one-time password to a mobile

506
00:23:27,490 --> 00:23:35,409
device and the user consumer who always

507
00:23:32,200 --> 00:23:38,169
gets inflicted with the security control

508
00:23:35,409 --> 00:23:40,720
the user has to take that password enter

509
00:23:38,169 --> 00:23:43,090
it into the website if they're using a

510
00:23:40,720 --> 00:23:46,360
website and then they they get in right

511
00:23:43,090 --> 00:23:48,039
well what if the criminal the cyber

512
00:23:46,360 --> 00:23:50,260
criminals using the ss7

513
00:23:48,039 --> 00:23:53,169
vulnerability and he's sending that

514
00:23:50,260 --> 00:23:56,620
one-time password to their the criminals

515
00:23:53,169 --> 00:23:59,559
mobile device not the consumers and now

516
00:23:56,620 --> 00:24:02,020
you have binary controls that

517
00:23:59,559 --> 00:24:04,629
automatically trust the bearer of the

518
00:24:02,020 --> 00:24:07,658
credential with the one-time password

519
00:24:04,630 --> 00:24:10,870
every binary control can be defeated so

520
00:24:07,659 --> 00:24:13,299
are you creating friction for the threat

521
00:24:10,870 --> 00:24:15,189
actor yes a little bit you're also

522
00:24:13,299 --> 00:24:17,049
creating friction for the consumer at

523
00:24:15,190 --> 00:24:19,120
the same time or we are and we have a

524
00:24:17,049 --> 00:24:20,500
well-established track record as

525
00:24:19,120 --> 00:24:24,969
security professionals for doing just

526
00:24:20,500 --> 00:24:28,240
that however you've been teaching a long

527
00:24:24,970 --> 00:24:28,610
time staff is it your experience that

528
00:24:28,240 --> 00:24:30,350
pee

529
00:24:28,610 --> 00:24:39,049
we'll have an easier time learning

530
00:24:30,350 --> 00:24:40,939
something or unlearning something so

531
00:24:39,049 --> 00:24:46,220
unlearning is hard isn't it

532
00:24:40,940 --> 00:24:50,900
right unlearning is hard I have to ask

533
00:24:46,220 --> 00:24:54,559
you to unlearn something do not assume

534
00:24:50,900 --> 00:24:55,730
that authentication is a event with the

535
00:24:54,559 --> 00:24:57,860
beginning and end and a binary outcome

536
00:24:55,730 --> 00:25:00,590
assume authentication is a continuous

537
00:24:57,860 --> 00:25:05,090
process it doesn't have a beginning or

538
00:25:00,590 --> 00:25:06,879
an end and it's continuous and the

539
00:25:05,090 --> 00:25:11,149
reason I'm asking you to do that and

540
00:25:06,880 --> 00:25:14,240
unlearn the wisdom that was prevalent

541
00:25:11,150 --> 00:25:17,690
for 60 years is because we'll never

542
00:25:14,240 --> 00:25:19,630
solve authentication unless we think

543
00:25:17,690 --> 00:25:22,010
differently about it

544
00:25:19,630 --> 00:25:24,679
and this is why passwords and people

545
00:25:22,010 --> 00:25:26,360
don't get along very well I mean I am a

546
00:25:24,679 --> 00:25:30,919
security professional I have over a

547
00:25:26,360 --> 00:25:32,928
hundred maybe I don't know 160 passwords

548
00:25:30,919 --> 00:25:35,710
for different sites and mobile

549
00:25:32,929 --> 00:25:38,660
applications I use the same password

550
00:25:35,710 --> 00:25:40,640
along amongst many different sites I

551
00:25:38,660 --> 00:25:43,280
even have a password manager and I still

552
00:25:40,640 --> 00:25:44,900
do it and I know all you are doing it as

553
00:25:43,280 --> 00:25:46,340
well and I know that because the

554
00:25:44,900 --> 00:25:48,740
criminals know that because they started

555
00:25:46,340 --> 00:25:51,830
harvesting credentials five years ago

556
00:25:48,740 --> 00:25:54,980
and now they have billions billions of

557
00:25:51,830 --> 00:25:56,780
credentials available today so they're

558
00:25:54,980 --> 00:25:59,840
doing something called credential

559
00:25:56,780 --> 00:26:02,540
stuffing I hate when that happens

560
00:25:59,840 --> 00:26:04,520
I push the wrong button this was an

561
00:26:02,540 --> 00:26:06,379
operator error by the way this wasn't

562
00:26:04,520 --> 00:26:08,559
because I was actually told not to do

563
00:26:06,380 --> 00:26:08,559
this

564
00:26:12,490 --> 00:26:19,900
a little bit better and so we came up

565
00:26:17,650 --> 00:26:22,570
with a new authentication capability

566
00:26:19,900 --> 00:26:25,990
based on this notion of continuous

567
00:26:22,570 --> 00:26:28,179
authentication and the interesting thing

568
00:26:25,990 --> 00:26:30,730
is it doesn't add friction to the end

569
00:26:28,180 --> 00:26:35,590
user it actually removes friction

570
00:26:30,730 --> 00:26:37,090
because it eliminates passwords and if

571
00:26:35,590 --> 00:26:40,330
you eliminate passwords you also

572
00:26:37,090 --> 00:26:43,389
eliminate costs of password reset so it

573
00:26:40,330 --> 00:26:46,000
actually saves money implementing this

574
00:26:43,390 --> 00:26:48,250
capability so let me get this right it

575
00:26:46,000 --> 00:26:50,830
removes friction from the end user and

576
00:26:48,250 --> 00:26:55,150
it saves money and oh there's better

577
00:26:50,830 --> 00:26:56,889
security what's not to like come on show

578
00:26:55,150 --> 00:26:58,930
me the fine print here there's got to be

579
00:26:56,890 --> 00:27:01,750
something in there that's bad well

580
00:26:58,930 --> 00:27:03,100
here's what it does it takes behavioral

581
00:27:01,750 --> 00:27:04,630
attributes now there's a fundamental

582
00:27:03,100 --> 00:27:06,820
principle that you have to kind of

583
00:27:04,630 --> 00:27:07,620
subscribe to behavior doesn't lie that's

584
00:27:06,820 --> 00:27:11,200
what we believe

585
00:27:07,620 --> 00:27:13,540
behavior doesn't lie and we're applying

586
00:27:11,200 --> 00:27:16,720
that here by saying if you have a mobile

587
00:27:13,540 --> 00:27:19,960
device or a web app what we're gonna do

588
00:27:16,720 --> 00:27:22,480
is we're gonna capture attributes about

589
00:27:19,960 --> 00:27:25,120
your use of the device and how the

590
00:27:22,480 --> 00:27:27,010
device is configured and we're going to

591
00:27:25,120 --> 00:27:30,520
take those attributes and turn them into

592
00:27:27,010 --> 00:27:33,160
a mathematical representation of the

593
00:27:30,520 --> 00:27:36,940
attribute data and we're going to

594
00:27:33,160 --> 00:27:41,350
compare that in real time to an

595
00:27:36,940 --> 00:27:44,350
established pattern so we do that with

596
00:27:41,350 --> 00:27:48,209
30 to 60 of these and then we take the

597
00:27:44,350 --> 00:27:50,679
30 or 60 scores deviation scores

598
00:27:48,210 --> 00:27:54,310
comparing the pattern against real time

599
00:27:50,680 --> 00:27:57,400
we turn that into one risk number and we

600
00:27:54,310 --> 00:28:00,129
feed that risk number to the app and the

601
00:27:57,400 --> 00:28:02,410
app decides how much access to provide

602
00:28:00,130 --> 00:28:05,530
you in real time based on what that

603
00:28:02,410 --> 00:28:09,070
number is and the reason the risk engine

604
00:28:05,530 --> 00:28:10,840
creates just one number is for different

605
00:28:09,070 --> 00:28:13,330
apps they have different thresholds of

606
00:28:10,840 --> 00:28:16,659
what you want in terms of privacy or

607
00:28:13,330 --> 00:28:19,360
security so you can modulate that with

608
00:28:16,660 --> 00:28:21,840
the same risk number and we've

609
00:28:19,360 --> 00:28:26,320
implemented this across all mobile and

610
00:28:21,840 --> 00:28:30,340
web applications that face the consumer

611
00:28:26,320 --> 00:28:33,159
and it's in use today now we did two

612
00:28:30,340 --> 00:28:38,290
things that aren't necessarily relevant

613
00:28:33,160 --> 00:28:41,370
on the slide here using a very important

614
00:28:38,290 --> 00:28:44,980
tool in the design of this capability

615
00:28:41,370 --> 00:28:50,080
the tool that we used here's the

616
00:28:44,980 --> 00:28:53,530
punchline were our values and you see

617
00:28:50,080 --> 00:28:56,699
our values that's not a tool but in this

618
00:28:53,530 --> 00:28:59,740
case it was a vital design tool because

619
00:28:56,700 --> 00:29:02,800
we're taking attributes of your use of

620
00:28:59,740 --> 00:29:07,780
technology we're venturing into the

621
00:29:02,800 --> 00:29:09,580
realm of the creepiness factor right so

622
00:29:07,780 --> 00:29:11,070
if an enterprise is using your

623
00:29:09,580 --> 00:29:14,470
behavioral attributes like maybe

624
00:29:11,070 --> 00:29:17,320
attributes from your watch your eye

625
00:29:14,470 --> 00:29:20,620
watch their feeding biometric

626
00:29:17,320 --> 00:29:22,510
information into an a risk engine

627
00:29:20,620 --> 00:29:25,330
potentially and let's say we're an

628
00:29:22,510 --> 00:29:27,610
insurance company and we could use that

629
00:29:25,330 --> 00:29:30,730
information to price our insurance

630
00:29:27,610 --> 00:29:33,459
policies right now that's clearly in the

631
00:29:30,730 --> 00:29:35,620
realm of creepiness right that's that's

632
00:29:33,460 --> 00:29:39,190
big brother-type sup we don't want that

633
00:29:35,620 --> 00:29:41,169
right so we made two choices the first

634
00:29:39,190 --> 00:29:44,770
choice is we decide only to use benign

635
00:29:41,170 --> 00:29:47,680
attributes and I locked my chief privacy

636
00:29:44,770 --> 00:29:49,060
officer in a room and I said you're not

637
00:29:47,680 --> 00:29:51,400
allowed out of the room she had her

638
00:29:49,060 --> 00:29:53,250
whole team in there until you choose the

639
00:29:51,400 --> 00:29:55,750
attributes that are available on this

640
00:29:53,250 --> 00:29:57,970
spreadsheet there was about 160 of them

641
00:29:55,750 --> 00:30:00,250
I said you have to choose the ones that

642
00:29:57,970 --> 00:30:02,410
are benign that if they ever got exposed

643
00:30:00,250 --> 00:30:04,930
in the internet they would have any

644
00:30:02,410 --> 00:30:06,970
impact on a consumer an individual and

645
00:30:04,930 --> 00:30:08,320
they went through and they was tough -

646
00:30:06,970 --> 00:30:11,320
making trade-offs decision but they came

647
00:30:08,320 --> 00:30:13,510
out with about 60 attributes and those

648
00:30:11,320 --> 00:30:15,760
are the attributes that we use the

649
00:30:13,510 --> 00:30:17,640
second decision we made is we weren't

650
00:30:15,760 --> 00:30:21,220
going to store any attribute information

651
00:30:17,640 --> 00:30:24,520
so if our risk engine got hacked there's

652
00:30:21,220 --> 00:30:28,390
nothing in it that can impact a consumer

653
00:30:24,520 --> 00:30:30,910
from a privacy standpoint we turn every

654
00:30:28,390 --> 00:30:32,830
attribute into a string of numbers and

655
00:30:30,910 --> 00:30:35,110
we just compare two strings of numbers

656
00:30:32,830 --> 00:30:37,689
together to get the risk deviation score

657
00:30:35,110 --> 00:30:38,860
so if our risk engine was hacked

658
00:30:37,690 --> 00:30:43,870
there's nothing in

659
00:30:38,860 --> 00:30:45,428
that impacts now those two decisions had

660
00:30:43,870 --> 00:30:48,729
nothing to do with anything except our

661
00:30:45,429 --> 00:30:52,510
values because our values said we want

662
00:30:48,730 --> 00:30:53,980
the consumer to trust the fact that

663
00:30:52,510 --> 00:30:55,658
they're we're gonna protect their

664
00:30:53,980 --> 00:30:58,630
information so we want to improve

665
00:30:55,659 --> 00:31:01,120
security remove friction and we want

666
00:30:58,630 --> 00:31:02,980
them to trust us so that's why we made

667
00:31:01,120 --> 00:31:05,260
those decisions there is no technical

668
00:31:02,980 --> 00:31:07,769
reason added technology complexity to

669
00:31:05,260 --> 00:31:09,908
the project it added time to the project

670
00:31:07,769 --> 00:31:10,480
but from our standpoint is the right

671
00:31:09,909 --> 00:31:14,049
thing to do

672
00:31:10,480 --> 00:31:16,539
does this sound futuristic no I'm glad

673
00:31:14,049 --> 00:31:18,549
you said that there are four million

674
00:31:16,539 --> 00:31:20,169
people using this today there'll be 40

675
00:31:18,549 --> 00:31:23,379
million by the end of this year there'll

676
00:31:20,169 --> 00:31:27,669
be 150 million in two and a half years

677
00:31:23,380 --> 00:31:31,480
so this is not futuristic it is in

678
00:31:27,669 --> 00:31:33,159
production today and getting back to

679
00:31:31,480 --> 00:31:36,220
what we talked about in the panel in

680
00:31:33,159 --> 00:31:39,220
terms of economics we are ratcheting

681
00:31:36,220 --> 00:31:40,990
down our customer service calls for

682
00:31:39,220 --> 00:31:44,559
password resets because there are no

683
00:31:40,990 --> 00:31:46,860
passwords to reset and in any large

684
00:31:44,559 --> 00:31:49,120
enterprise password resets a pretty high

685
00:31:46,860 --> 00:31:52,000
pretty high call volume and percentage

686
00:31:49,120 --> 00:31:54,729
of call volume so that's dropping so our

687
00:31:52,000 --> 00:31:58,210
costs are going down and our consumer

688
00:31:54,730 --> 00:32:00,610
experience is going way up no passwords

689
00:31:58,210 --> 00:32:04,840
to remember now the other thing we did

690
00:32:00,610 --> 00:32:08,519
is we we used a standard we adopted a

691
00:32:04,840 --> 00:32:12,340
standard that basically says whatever

692
00:32:08,519 --> 00:32:15,250
biometric you use on your phone so

693
00:32:12,340 --> 00:32:17,289
you've chosen this phone this device and

694
00:32:15,250 --> 00:32:19,990
you've chosen a biometric on there right

695
00:32:17,289 --> 00:32:21,879
so whatever your choice is we're gonna

696
00:32:19,990 --> 00:32:24,669
take that as one of the factors that

697
00:32:21,880 --> 00:32:26,710
goes into the risk engine so you make

698
00:32:24,669 --> 00:32:29,500
the choice you can if you're using an

699
00:32:26,710 --> 00:32:31,299
iPhone you can do touch ID or face ID or

700
00:32:29,500 --> 00:32:34,269
you can the combination of both that's

701
00:32:31,299 --> 00:32:38,080
your choice whatever choice you make we

702
00:32:34,269 --> 00:32:40,149
take into our risk engine following a

703
00:32:38,080 --> 00:32:41,559
particular standard that allows us to do

704
00:32:40,149 --> 00:32:43,059
that so you can make whatever choices

705
00:32:41,559 --> 00:32:45,299
you want your carrier can make whatever

706
00:32:43,059 --> 00:32:47,980
choices they want in terms of the

707
00:32:45,299 --> 00:32:49,629
biometric on the device doesn't matter

708
00:32:47,980 --> 00:32:52,360
that becomes part of your users

709
00:32:49,630 --> 00:32:54,040
experience so once you

710
00:32:52,360 --> 00:32:56,409
if you do touch idea once you put your

711
00:32:54,040 --> 00:32:58,299
finger on the device you're into the app

712
00:32:56,410 --> 00:33:00,370
there's nothing else you have to do

713
00:32:58,299 --> 00:33:02,679
everything else that I've shown you is

714
00:33:00,370 --> 00:33:04,510
in the background so that's the

715
00:33:02,679 --> 00:33:07,150
advantage of having a positive user

716
00:33:04,510 --> 00:33:09,910
experience and all of this is simply

717
00:33:07,150 --> 00:33:14,650
because you're not the only one that has

718
00:33:09,910 --> 00:33:17,620
your password so this is the technology

719
00:33:14,650 --> 00:33:20,470
behind it and there's a number of

720
00:33:17,620 --> 00:33:22,169
early-stage companies so if you don't

721
00:33:20,470 --> 00:33:24,970
know the names of some of these

722
00:33:22,170 --> 00:33:26,559
companies don't worry about it

723
00:33:24,970 --> 00:33:28,169
some of the some of them are getting

724
00:33:26,559 --> 00:33:31,360
pretty big but a lot of them are

725
00:33:28,169 --> 00:33:33,120
relatively small and that ties to my

726
00:33:31,360 --> 00:33:37,240
philosophy of using early-stage

727
00:33:33,120 --> 00:33:40,030
companies and I'll tell you why and it

728
00:33:37,240 --> 00:33:42,460
comes down to economics which is what we

729
00:33:40,030 --> 00:33:44,440
were talking about in the panel of how

730
00:33:42,460 --> 00:33:48,540
economics and security are kind of tied

731
00:33:44,440 --> 00:33:51,040
together let's say you're a software

732
00:33:48,540 --> 00:33:54,370
manufacturer software commercial

733
00:33:51,040 --> 00:33:57,399
software producer and your software is

734
00:33:54,370 --> 00:34:01,750
sold to the enterprise to the enterprise

735
00:33:57,400 --> 00:34:05,440
market the economics of the software

736
00:34:01,750 --> 00:34:08,800
industry drive you to allocate your

737
00:34:05,440 --> 00:34:13,389
scarce resource developers and product

738
00:34:08,800 --> 00:34:16,330
managers to achieve the best outcome and

739
00:34:13,389 --> 00:34:19,119
in this case sell to the broadest part

740
00:34:16,330 --> 00:34:21,159
of the enterprise market and if you can

741
00:34:19,119 --> 00:34:23,710
sell to the broadest part of the market

742
00:34:21,159 --> 00:34:26,679
you're gonna be profitable and that's

743
00:34:23,710 --> 00:34:29,740
true for every software manufacturer if

744
00:34:26,679 --> 00:34:32,649
you look at security and the enterprise

745
00:34:29,739 --> 00:34:34,540
security market and you look at the

746
00:34:32,649 --> 00:34:39,850
broadest part of the enterprise security

747
00:34:34,540 --> 00:34:43,840
market it's the dumbest what that means

748
00:34:39,850 --> 00:34:46,929
is it's the least sophisticated and so

749
00:34:43,840 --> 00:34:49,409
large commercial software providers have

750
00:34:46,929 --> 00:34:51,970
to based on the law of economics

751
00:34:49,409 --> 00:34:53,560
allocate their scarce resource to serve

752
00:34:51,969 --> 00:34:59,069
the broadest part of the market which is

753
00:34:53,560 --> 00:35:02,080
the dumbest so if you want innovation in

754
00:34:59,070 --> 00:35:06,070
unconventional controls in a common from

755
00:35:02,080 --> 00:35:07,569
this part of the market it's it can't

756
00:35:06,070 --> 00:35:10,300
it has to come from early-stage

757
00:35:07,570 --> 00:35:13,510
companies which by the way early-stage

758
00:35:10,300 --> 00:35:14,980
companies get bought by who large market

759
00:35:13,510 --> 00:35:17,860
share leaders right because I know the

760
00:35:14,980 --> 00:35:19,600
game right they're smart people it's not

761
00:35:17,860 --> 00:35:22,200
that there are some not smart people I'm

762
00:35:19,600 --> 00:35:24,640
not disparaging any large software

763
00:35:22,200 --> 00:35:27,040
manufacturer I'm purely acknowledging

764
00:35:24,640 --> 00:35:30,430
the economic laws of the jungle and I'm

765
00:35:27,040 --> 00:35:32,800
choosing as a see so to work with

766
00:35:30,430 --> 00:35:36,009
early-stage companies that will design

767
00:35:32,800 --> 00:35:37,780
something based on my use case not a use

768
00:35:36,010 --> 00:35:41,950
case to fit the broadest part of the

769
00:35:37,780 --> 00:35:44,290
market and early-stage companies will

770
00:35:41,950 --> 00:35:46,689
chase any use case because they don't

771
00:35:44,290 --> 00:35:48,160
have any customers and so they're gonna

772
00:35:46,690 --> 00:35:51,910
do what you want them to do and that's

773
00:35:48,160 --> 00:35:54,940
where innovation comes from and look I'm

774
00:35:51,910 --> 00:35:58,359
wrong sometimes like I chose bromium at

775
00:35:54,940 --> 00:36:00,670
one time and you know they'd never paid

776
00:35:58,360 --> 00:36:02,080
off but I'll tell you this I chose a lot

777
00:36:00,670 --> 00:36:04,120
of other companies where I'm spending

778
00:36:02,080 --> 00:36:08,319
nickels and dimes and getting a huge

779
00:36:04,120 --> 00:36:11,470
return like these companies here that

780
00:36:08,320 --> 00:36:13,930
are you know delivering so the reality

781
00:36:11,470 --> 00:36:17,290
is I'm looking for a design partner to

782
00:36:13,930 --> 00:36:19,990
design based on my use case and I don't

783
00:36:17,290 --> 00:36:21,580
really care what happens after that if

784
00:36:19,990 --> 00:36:23,979
they're successful a market god bless

785
00:36:21,580 --> 00:36:25,600
them I'm happy for them but eventually

786
00:36:23,980 --> 00:36:28,000
they're gonna get big and bit bought by

787
00:36:25,600 --> 00:36:31,509
somebody I want to deal with that's just

788
00:36:28,000 --> 00:36:33,070
the nature of the beast so they build a

789
00:36:31,510 --> 00:36:35,410
use case then they build multiple use

790
00:36:33,070 --> 00:36:37,780
cases and multiple use cases satisfies

791
00:36:35,410 --> 00:36:40,540
the funnel again the broadest part of

792
00:36:37,780 --> 00:36:41,890
the market they have to do this and if

793
00:36:40,540 --> 00:36:43,270
they're good at what they do and treat

794
00:36:41,890 --> 00:36:44,920
their shareholders correctly if they're

795
00:36:43,270 --> 00:36:47,860
a public company they will do exactly

796
00:36:44,920 --> 00:36:51,010
this and they have to and so that's not

797
00:36:47,860 --> 00:36:52,960
necessarily what I want what I want is

798
00:36:51,010 --> 00:36:55,890
something that has innovation so I'm

799
00:36:52,960 --> 00:36:57,580
going to give you another example and

800
00:36:55,890 --> 00:37:00,220
unconventional versus commercial

801
00:36:57,580 --> 00:37:02,920
controls privileged user monitoring some

802
00:37:00,220 --> 00:37:04,240
people call that insider threat call it

803
00:37:02,920 --> 00:37:07,860
what you will

804
00:37:04,240 --> 00:37:11,109
the best practice according to

805
00:37:07,860 --> 00:37:14,020
conventional controls and or threat or

806
00:37:11,110 --> 00:37:16,330
Thorat ativ sources are when you grant

807
00:37:14,020 --> 00:37:19,290
access to a system administrator or

808
00:37:16,330 --> 00:37:19,290
domain administrator

809
00:37:19,330 --> 00:37:28,569
and access manager a privileged user of

810
00:37:24,700 --> 00:37:32,529
any kind what you should do is make sure

811
00:37:28,570 --> 00:37:35,200
that an alert or a record goes to the

812
00:37:32,530 --> 00:37:38,230
Sauk alerting them to the fact that

813
00:37:35,200 --> 00:37:41,950
somebody has privilege and is using that

814
00:37:38,230 --> 00:37:43,480
privilege this is conventional you know

815
00:37:41,950 --> 00:37:48,069
conventional controls tell us to do this

816
00:37:43,480 --> 00:37:51,010
okay that is the dumbest thing in the

817
00:37:48,070 --> 00:37:51,610
world and the reason it's the dumbest

818
00:37:51,010 --> 00:37:55,420
thing in the world

819
00:37:51,610 --> 00:38:01,330
does anybody have a sock analyst that

820
00:37:55,420 --> 00:38:03,130
has too little to do anyone anyone know

821
00:38:01,330 --> 00:38:04,900
it's like sake analyst struggled to keep

822
00:38:03,130 --> 00:38:07,150
up with the information that they have

823
00:38:04,900 --> 00:38:09,130
right so you want to add more

824
00:38:07,150 --> 00:38:12,630
information that's absolutely useless to

825
00:38:09,130 --> 00:38:15,790
them so the auditors love this control

826
00:38:12,630 --> 00:38:19,450
it's useless it wastes time and money

827
00:38:15,790 --> 00:38:21,759
don't bother however if you took the

828
00:38:19,450 --> 00:38:24,779
same information and shared it with the

829
00:38:21,760 --> 00:38:26,920
boss of the privileged user who has

830
00:38:24,780 --> 00:38:29,230
context who knows

831
00:38:26,920 --> 00:38:30,810
what should be done how it should be

832
00:38:29,230 --> 00:38:33,430
done and when it should be done

833
00:38:30,810 --> 00:38:37,870
your boss their boss would know right

834
00:38:33,430 --> 00:38:41,430
away if that's an anomaly because they

835
00:38:37,870 --> 00:38:43,900
have the context for that so what we do

836
00:38:41,430 --> 00:38:46,270
what we've done is we planted a large

837
00:38:43,900 --> 00:38:49,090
data Lake and it's like you be a

838
00:38:46,270 --> 00:38:50,110
capability we did a lot of the

839
00:38:49,090 --> 00:38:51,640
development because it was an early

840
00:38:50,110 --> 00:38:53,230
stage company this about three or four

841
00:38:51,640 --> 00:38:55,750
years ago but there a lot of products

842
00:38:53,230 --> 00:38:58,270
today that are a lot more mature so you

843
00:38:55,750 --> 00:38:59,890
don't just say have to build it but we

844
00:38:58,270 --> 00:39:04,630
did we took all this information into

845
00:38:59,890 --> 00:39:07,900
this data Lake and we got identity

846
00:39:04,630 --> 00:39:09,760
account entitlement roles and then log

847
00:39:07,900 --> 00:39:12,970
activity physical access DLP alerts we

848
00:39:09,760 --> 00:39:16,990
took a net by the way every registered

849
00:39:12,970 --> 00:39:18,609
user of our network has a profile that's

850
00:39:16,990 --> 00:39:20,859
a risk profile based on all this

851
00:39:18,610 --> 00:39:23,350
attribute information so we took

852
00:39:20,860 --> 00:39:27,760
physical access we took web browsing we

853
00:39:23,350 --> 00:39:29,770
took email plus the entitlements for

854
00:39:27,760 --> 00:39:33,010
everybody that everything that they're

855
00:39:29,770 --> 00:39:34,540
entitled to and how they use

856
00:39:33,010 --> 00:39:36,370
their behavior is of using the

857
00:39:34,540 --> 00:39:38,440
entitlements all that factors into a

858
00:39:36,370 --> 00:39:40,839
risk score and every single registered

859
00:39:38,440 --> 00:39:43,840
user has a risk score when they become a

860
00:39:40,840 --> 00:39:50,830
privileged user we apply the risk score

861
00:39:43,840 --> 00:39:53,140
and when we see data or an anomaly when

862
00:39:50,830 --> 00:39:57,520
there have privileged we send this email

863
00:39:53,140 --> 00:39:59,740
to their boss and it doesn't take a

864
00:39:57,520 --> 00:40:01,210
rocket science to figure scientists to

865
00:39:59,740 --> 00:40:03,430
figure out that you know Green is good

866
00:40:01,210 --> 00:40:04,420
and red is bad right so you've you click

867
00:40:03,430 --> 00:40:06,370
on one or the other

868
00:40:04,420 --> 00:40:08,710
if what the person is doing is

869
00:40:06,370 --> 00:40:11,560
legitimate you click on green it goes

870
00:40:08,710 --> 00:40:14,200
into updating the model and then that's

871
00:40:11,560 --> 00:40:16,240
not alerted on in the future if it's red

872
00:40:14,200 --> 00:40:18,189
their privileges revoked automatically

873
00:40:16,240 --> 00:40:20,439
there's orchestration to initiate a

874
00:40:18,190 --> 00:40:22,270
security incident and so all they have

875
00:40:20,440 --> 00:40:23,980
to do is read their email and choose one

876
00:40:22,270 --> 00:40:26,560
or the other and they're the subject

877
00:40:23,980 --> 00:40:28,570
matter expert that has the context so

878
00:40:26,560 --> 00:40:30,549
you've got you know privileged user

879
00:40:28,570 --> 00:40:32,650
monitoring based on this now if there's

880
00:40:30,550 --> 00:40:36,910
three it's generally somewhere between

881
00:40:32,650 --> 00:40:40,740
two and three anomalistic events for the

882
00:40:36,910 --> 00:40:44,799
privileged user in real time the model

883
00:40:40,740 --> 00:40:48,580
decides to revoke privilege immediately

884
00:40:44,800 --> 00:40:50,770
and initiate a security incident where

885
00:40:48,580 --> 00:40:54,370
there's orchestration there's no human

886
00:40:50,770 --> 00:40:56,470
involvement at all why is this important

887
00:40:54,370 --> 00:40:58,509
some companies that got hit with not

888
00:40:56,470 --> 00:41:00,939
petia had fifteen thousand servers

889
00:40:58,510 --> 00:41:04,360
knocked over and bricked in ninety

890
00:41:00,940 --> 00:41:06,850
seconds there's no human than on the

891
00:41:04,360 --> 00:41:10,150
planet that can operate that quickly so

892
00:41:06,850 --> 00:41:12,970
the model is actually doing this for us

893
00:41:10,150 --> 00:41:15,090
and the model here is a machine learning

894
00:41:12,970 --> 00:41:18,959
unsupervised machine learning algorithm

895
00:41:15,090 --> 00:41:21,340
that's running today we have over 400

896
00:41:18,960 --> 00:41:24,760
machine learning models running in

897
00:41:21,340 --> 00:41:27,690
production on nine platforms in the

898
00:41:24,760 --> 00:41:32,860
enterprise and what's happening is that

899
00:41:27,690 --> 00:41:35,140
I thought this has shows how much I know

900
00:41:32,860 --> 00:41:38,860
but I thought when I hired four years

901
00:41:35,140 --> 00:41:41,500
ago a chief data scientists to be

902
00:41:38,860 --> 00:41:43,270
dedicated to security I thought he'd be

903
00:41:41,500 --> 00:41:45,040
helping me with all these great tools

904
00:41:43,270 --> 00:41:46,850
that I had and taken all the log data

905
00:41:45,040 --> 00:41:49,190
and making it into something

906
00:41:46,850 --> 00:41:51,819
where I could make actionable like

907
00:41:49,190 --> 00:41:55,030
decide on doing different cyber hunting

908
00:41:51,820 --> 00:41:57,440
campaigns so I can make better decisions

909
00:41:55,030 --> 00:42:00,200
so this is what I thought and what

910
00:41:57,440 --> 00:42:02,960
turned out to be the case over time is

911
00:42:00,200 --> 00:42:06,020
that we put this capability in place and

912
00:42:02,960 --> 00:42:08,900
it ended up driving frontline security

913
00:42:06,020 --> 00:42:11,810
controls to where humans don't have to

914
00:42:08,900 --> 00:42:14,120
make any decision it's making most of

915
00:42:11,810 --> 00:42:16,880
the decisions for us and it's embedded

916
00:42:14,120 --> 00:42:19,640
in the platforms and today you can buy

917
00:42:16,880 --> 00:42:22,130
this or you can build this so you know

918
00:42:19,640 --> 00:42:23,750
it's the whole basis is models where

919
00:42:22,130 --> 00:42:27,920
what a models are just mathematical

920
00:42:23,750 --> 00:42:30,590
representation of an event and it turns

921
00:42:27,920 --> 00:42:33,680
out that figuring out events in a

922
00:42:30,590 --> 00:42:36,590
pattern and determining whether another

923
00:42:33,680 --> 00:42:38,930
event is matching that pattern or not is

924
00:42:36,590 --> 00:42:41,720
pretty straightforward from a data

925
00:42:38,930 --> 00:42:44,180
science perspective so applying a

926
00:42:41,720 --> 00:42:46,580
machine learning algorithm to doing that

927
00:42:44,180 --> 00:42:49,460
routine over and over again actually has

928
00:42:46,580 --> 00:42:54,340
some direct applicability to cyber

929
00:42:49,460 --> 00:42:58,480
security however more sophisticated deep

930
00:42:54,340 --> 00:43:03,260
kind of neural net technology applied to

931
00:42:58,480 --> 00:43:06,860
identifying anomalies and now we're not

932
00:43:03,260 --> 00:43:09,200
so much doesn't work that well and we

933
00:43:06,860 --> 00:43:12,320
struggle with that and it's a part of

934
00:43:09,200 --> 00:43:16,250
cyber security that frankly it's not

935
00:43:12,320 --> 00:43:19,220
practical but in the former it's highly

936
00:43:16,250 --> 00:43:21,920
practical highly scalable and that's

937
00:43:19,220 --> 00:43:23,950
what gives us the 400 machine learning

938
00:43:21,920 --> 00:43:28,340
models that we have in production today

939
00:43:23,950 --> 00:43:31,270
so we've developed we have maybe the 400

940
00:43:28,340 --> 00:43:33,260
maybe there's a 150 of them that we

941
00:43:31,270 --> 00:43:36,770
bespoke models that we developed

942
00:43:33,260 --> 00:43:40,400
ourselves with our data science team we

943
00:43:36,770 --> 00:43:41,870
bought products that have models built

944
00:43:40,400 --> 00:43:44,570
into them we're doing a lot of that in

945
00:43:41,870 --> 00:43:46,430
some cases in the UBA case they the

946
00:43:44,570 --> 00:43:49,430
vendor gives us a model we modify it we

947
00:43:46,430 --> 00:43:51,589
put it into our vironment the email that

948
00:43:49,430 --> 00:43:54,460
I was showing you earlier that's a model

949
00:43:51,590 --> 00:43:57,140
that the vendor produced and we modified

950
00:43:54,460 --> 00:43:59,900
and tuned and adjusted in our

951
00:43:57,140 --> 00:44:00,560
environment so what's really happening

952
00:43:59,900 --> 00:44:05,570
here

953
00:44:00,560 --> 00:44:08,320
is that for students you've got to think

954
00:44:05,570 --> 00:44:12,380
about a by disciplinary approach here

955
00:44:08,320 --> 00:44:15,380
cybersecurity and data science to

956
00:44:12,380 --> 00:44:18,920
whatever degree that you can master

957
00:44:15,380 --> 00:44:20,870
capabilities in those two domains you

958
00:44:18,920 --> 00:44:22,730
will never ever have to worry about

959
00:44:20,870 --> 00:44:24,980
getting a job for the rest of your life

960
00:44:22,730 --> 00:44:27,020
and you'll be able to work wherever you

961
00:44:24,980 --> 00:44:28,730
want to work and you barely can make a

962
00:44:27,020 --> 00:44:30,770
lot of money

963
00:44:28,730 --> 00:44:34,190
so those two things if you can do those

964
00:44:30,770 --> 00:44:36,290
two things you're golden because what's

965
00:44:34,190 --> 00:44:39,520
happening is cybersecurity professionals

966
00:44:36,290 --> 00:44:42,080
and data scientists are coming together

967
00:44:39,520 --> 00:44:45,100
there's always a role for data science

968
00:44:42,080 --> 00:44:47,900
there's always a role for cybersecurity

969
00:44:45,100 --> 00:44:51,319
those two things aren't natural there's

970
00:44:47,900 --> 00:44:53,030
no natural affinity there we find data

971
00:44:51,320 --> 00:44:55,400
scientists and we teach them security

972
00:44:53,030 --> 00:44:57,710
that's a lot easier than finding data

973
00:44:55,400 --> 00:45:00,320
scientists with security expertise we

974
00:44:57,710 --> 00:45:03,520
have a mix of both but this is

975
00:45:00,320 --> 00:45:06,170
absolutely strategic to developing

976
00:45:03,520 --> 00:45:09,530
unconventional controls in a sustainable

977
00:45:06,170 --> 00:45:13,040
way to meet the needs of a resilient

978
00:45:09,530 --> 00:45:16,280
enterprise over time we've got some time

979
00:45:13,040 --> 00:45:17,690
for some questions I'm done with what

980
00:45:16,280 --> 00:45:25,690
I've shared with you I hope this was

981
00:45:17,690 --> 00:45:28,480
helpful and go ahead yeah

982
00:45:25,690 --> 00:45:30,670
okay so the incredibly interesting and

983
00:45:28,480 --> 00:45:34,930
fresh perspectives on security really

984
00:45:30,670 --> 00:45:36,369
appreciated that so I was listening very

985
00:45:34,930 --> 00:45:39,578
carefully to the last part especially

986
00:45:36,369 --> 00:45:41,440
where you said you harvesting all this

987
00:45:39,579 --> 00:45:46,119
data about consumers and milling build

988
00:45:41,440 --> 00:45:50,079
models and but there was a paper that I

989
00:45:46,119 --> 00:45:52,869
had referred to I was I guess the first

990
00:45:50,079 --> 00:45:56,160
speaker yesterday it was and you cannot

991
00:45:52,869 --> 00:45:59,829
use the AI in the traditional way to

992
00:45:56,160 --> 00:46:01,990
learn normal behavior and then you know

993
00:45:59,829 --> 00:46:05,049
detect deviation from normal behavior

994
00:46:01,990 --> 00:46:07,990
because learning algorithms required

995
00:46:05,049 --> 00:46:10,509
both normal and abnormal behavior and so

996
00:46:07,990 --> 00:46:12,008
where do you get the normal behavior the

997
00:46:10,509 --> 00:46:13,660
abnormal behavior from I mean it's just

998
00:46:12,009 --> 00:46:18,609
observing the user well everything is

999
00:46:13,660 --> 00:46:20,379
normal so I think you may have some

1000
00:46:18,609 --> 00:46:22,328
answers to that but I wanted to probe

1001
00:46:20,380 --> 00:46:25,990
that a bit yeah so I don't look for

1002
00:46:22,329 --> 00:46:28,029
normal behavior I look for a pattern so

1003
00:46:25,990 --> 00:46:30,519
the models that we have purely

1004
00:46:28,029 --> 00:46:33,609
determined whether actual behavior

1005
00:46:30,519 --> 00:46:35,169
matches a pattern and to what degree it

1006
00:46:33,609 --> 00:46:37,029
either and actually the way the model

1007
00:46:35,170 --> 00:46:39,279
works it just tells us how much it

1008
00:46:37,029 --> 00:46:41,200
doesn't match and it gives us a

1009
00:46:39,279 --> 00:46:43,509
numerical representation of what it

1010
00:46:41,200 --> 00:46:46,509
doesn't match and I can do a lot with

1011
00:46:43,509 --> 00:46:49,420
that numeric representation so that's

1012
00:46:46,509 --> 00:46:53,589
what we're doing and it actually models

1013
00:46:49,420 --> 00:46:56,109
do that really well and so I've you know

1014
00:46:53,589 --> 00:47:00,038
there are lots of cases where if I

1015
00:46:56,109 --> 00:47:04,750
wanted to scan a database and find the

1016
00:47:00,039 --> 00:47:06,970
color green versus the color fuchsia I'd

1017
00:47:04,750 --> 00:47:09,880
struggle you know for a long time trying

1018
00:47:06,970 --> 00:47:12,640
to do that but just trying to find

1019
00:47:09,880 --> 00:47:16,440
patterns of behavior or behavior that

1020
00:47:12,640 --> 00:47:22,558
match a pattern it's pretty easy to do

1021
00:47:16,440 --> 00:47:25,690
okay thanks when I was a back in

1022
00:47:22,559 --> 00:47:27,069
somewhere around 2005 my wife said to me

1023
00:47:25,690 --> 00:47:30,480
I was living in Minnesota at the time

1024
00:47:27,069 --> 00:47:33,369
anybody lived from Minnesota yeah yeah

1025
00:47:30,480 --> 00:47:38,079
so I was living Minneapolis I was there

1026
00:47:33,369 --> 00:47:39,520
and I loved it there so wonderful but my

1027
00:47:38,079 --> 00:47:41,650
after three and a half winners

1028
00:47:39,520 --> 00:47:43,270
our three winners three and half years

1029
00:47:41,650 --> 00:47:44,410
my wife said to me at dinner look the

1030
00:47:43,270 --> 00:47:47,830
kids and I are moving back east do you

1031
00:47:44,410 --> 00:47:50,379
want to come I said yeah I think I do so

1032
00:47:47,830 --> 00:47:53,950
I moved back east and the job I got was

1033
00:47:50,380 --> 00:47:56,530
actually running data analytics for the

1034
00:47:53,950 --> 00:48:00,189
marketing group of the US domestic card

1035
00:47:56,530 --> 00:48:01,900
business for American Express now those

1036
00:48:00,190 --> 00:48:04,660
models that we built back then they did

1037
00:48:01,900 --> 00:48:07,540
they decayed so then we had 500 people

1038
00:48:04,660 --> 00:48:09,069
just keeping models updated and they

1039
00:48:07,540 --> 00:48:10,869
were conventional traditionals I didn't

1040
00:48:09,070 --> 00:48:14,830
realize at the time but that was the

1041
00:48:10,869 --> 00:48:16,770
foundation for my security career so I

1042
00:48:14,830 --> 00:48:19,900
owe my whole security career to my wife

1043
00:48:16,770 --> 00:48:22,450
in Minnesota for that question

1044
00:48:19,900 --> 00:48:25,330
yeah I just in your comments about

1045
00:48:22,450 --> 00:48:26,770
vendor management when I was at Gartner

1046
00:48:25,330 --> 00:48:29,920
we divided clients into three groups

1047
00:48:26,770 --> 00:48:31,450
type a B and C with the Taipei's being

1048
00:48:29,920 --> 00:48:34,990
folks like you were willing to go out on

1049
00:48:31,450 --> 00:48:36,220
a leading edge what I want to supplement

1050
00:48:34,990 --> 00:48:38,919
your advice by and I'd like your

1051
00:48:36,220 --> 00:48:41,109
thoughts on this is that if you are type

1052
00:48:38,920 --> 00:48:43,450
B or C consumer they're dealing with

1053
00:48:41,110 --> 00:48:45,369
startups can put a lot of stresses in

1054
00:48:43,450 --> 00:48:47,500
unexpected places in your IT

1055
00:48:45,369 --> 00:48:51,100
organization like the company may not be

1056
00:48:47,500 --> 00:48:52,869
around the benefits could be they're

1057
00:48:51,100 --> 00:48:54,310
going to give you a heck of a deal for

1058
00:48:52,869 --> 00:48:55,330
being a reference but that means they're

1059
00:48:54,310 --> 00:48:56,980
gonna be tracking their muddyfeet

1060
00:48:55,330 --> 00:48:59,500
through your data center every couple of

1061
00:48:56,980 --> 00:49:01,270
months when they get a client I'd like

1062
00:48:59,500 --> 00:49:02,710
to see the fuller picture on how you see

1063
00:49:01,270 --> 00:49:04,450
vendor management especially for folks

1064
00:49:02,710 --> 00:49:05,980
who want to make that transition yeah

1065
00:49:04,450 --> 00:49:08,319
William thank you for pointing that out

1066
00:49:05,980 --> 00:49:12,910
you're absolutely right there's a lot of

1067
00:49:08,320 --> 00:49:15,070
engineering overhead that I incur and a

1068
00:49:12,910 --> 00:49:16,720
lot of the resources I use are actually

1069
00:49:15,070 --> 00:49:21,580
embedded in the IT organization they're

1070
00:49:16,720 --> 00:49:24,549
in report to security and I this wasn't

1071
00:49:21,580 --> 00:49:26,380
an easy transition the first thing I did

1072
00:49:24,550 --> 00:49:28,240
six years ago was I convinced

1073
00:49:26,380 --> 00:49:30,250
procurement to change their criteria for

1074
00:49:28,240 --> 00:49:31,779
evaluating vendors because when you

1075
00:49:30,250 --> 00:49:37,030
evaluate a vendor for an enterprise

1076
00:49:31,780 --> 00:49:41,020
software capability you want market size

1077
00:49:37,030 --> 00:49:44,260
you want scalability you want client

1078
00:49:41,020 --> 00:49:46,480
references you want financial resiliency

1079
00:49:44,260 --> 00:49:48,760
you want all of those things which make

1080
00:49:46,480 --> 00:49:50,859
perfect sense for cybersecurity

1081
00:49:48,760 --> 00:49:53,290
early-stage companies none of those

1082
00:49:50,859 --> 00:49:56,100
things apply so what I do

1083
00:49:53,290 --> 00:49:59,140
evaluate the co-founder and the

1084
00:49:56,100 --> 00:50:01,360
co-founders technical ability to attract

1085
00:49:59,140 --> 00:50:03,190
talent and the second thing I look at is

1086
00:50:01,360 --> 00:50:05,590
whether they'll be willing to pivot and

1087
00:50:03,190 --> 00:50:07,780
adjust and change and if those two

1088
00:50:05,590 --> 00:50:11,820
things are in place I'm good to go now

1089
00:50:07,780 --> 00:50:15,310
the reality is I'm spending resource

1090
00:50:11,820 --> 00:50:18,490
engineering resource to make them

1091
00:50:15,310 --> 00:50:20,620
successful so I'm not just letting them

1092
00:50:18,490 --> 00:50:22,750
fail on their own I'm incubating their

1093
00:50:20,620 --> 00:50:25,600
product development process based on my

1094
00:50:22,750 --> 00:50:27,430
use case and I'm creating engineering

1095
00:50:25,600 --> 00:50:30,069
resources that are helping them mature

1096
00:50:27,430 --> 00:50:31,899
their product and that's the commitment

1097
00:50:30,070 --> 00:50:35,980
that's kind of the that you don't see

1098
00:50:31,900 --> 00:50:38,500
that it's hard to get IT to buy into

1099
00:50:35,980 --> 00:50:40,690
that to provide the resource to do that

1100
00:50:38,500 --> 00:50:43,750
because what happens is you know for

1101
00:50:40,690 --> 00:50:46,240
every proof of concept that we do with a

1102
00:50:43,750 --> 00:50:48,070
early-stage company you know it's

1103
00:50:46,240 --> 00:50:50,859
probably a 10 to 1 ratio of what we

1104
00:50:48,070 --> 00:50:53,260
actually put into production 10 of them

1105
00:50:50,860 --> 00:50:53,860
will fail for the one that we put into

1106
00:50:53,260 --> 00:50:56,830
production

1107
00:50:53,860 --> 00:50:59,320
so there's resource that we're putting

1108
00:50:56,830 --> 00:51:00,940
into this that's not that you know it's

1109
00:50:59,320 --> 00:51:02,980
not part of the equation necessarily

1110
00:51:00,940 --> 00:51:04,860
that needs to be and so your point is

1111
00:51:02,980 --> 00:51:08,470
absolutely valid this is not for

1112
00:51:04,860 --> 00:51:11,440
everyone this is an acquired taste yes

1113
00:51:08,470 --> 00:51:13,959
yeah so thank you so much yeah I was

1114
00:51:11,440 --> 00:51:15,790
absolutely struck by the same thing and

1115
00:51:13,960 --> 00:51:18,160
my question actually has to do with IP

1116
00:51:15,790 --> 00:51:21,130
intellectual property if it's your use

1117
00:51:18,160 --> 00:51:23,259
case wait everybody never over is that

1118
00:51:21,130 --> 00:51:25,060
the answer I there's an investment arm

1119
00:51:23,260 --> 00:51:27,730
and they invest in some of the companies

1120
00:51:25,060 --> 00:51:31,990
they've got two investments right now I

1121
00:51:27,730 --> 00:51:35,530
everything that we developed I share

1122
00:51:31,990 --> 00:51:38,950
with everyone because I was taught this

1123
00:51:35,530 --> 00:51:40,780
you know early on the whole industry has

1124
00:51:38,950 --> 00:51:43,270
to be resilient it's not just one

1125
00:51:40,780 --> 00:51:45,520
company to protect all consumers and in

1126
00:51:43,270 --> 00:51:48,250
healthcare we want to protect your

1127
00:51:45,520 --> 00:51:50,650
health information regardless of what

1128
00:51:48,250 --> 00:51:53,830
provider you're using and that means

1129
00:51:50,650 --> 00:51:55,780
changing the entire industry and rising

1130
00:51:53,830 --> 00:51:58,330
you know rising the level of resiliency

1131
00:51:55,780 --> 00:52:00,280
across all companies so I give away

1132
00:51:58,330 --> 00:52:02,440
everything that we do which is why I

1133
00:52:00,280 --> 00:52:04,300
talk things like this so you go to the

1134
00:52:02,440 --> 00:52:05,330
board and you say I don't care about IP

1135
00:52:04,300 --> 00:52:07,610
No

1136
00:52:05,330 --> 00:52:10,069
that I care about IP and developing IP

1137
00:52:07,610 --> 00:52:12,500
for my use case to keep me gainfully

1138
00:52:10,070 --> 00:52:15,200
employed that I really care about okay

1139
00:52:12,500 --> 00:52:17,840
we're commercializing it I we don't we

1140
00:52:15,200 --> 00:52:19,189
give it away okay so your your agreement

1141
00:52:17,840 --> 00:52:21,230
with the companies that you're bringing

1142
00:52:19,190 --> 00:52:24,410
up to really I'll call it bring the

1143
00:52:21,230 --> 00:52:26,510
cutting-edge tech is you own most of it

1144
00:52:24,410 --> 00:52:30,080
and I own some of it we don't know any

1145
00:52:26,510 --> 00:52:32,090
of it okay alright so in most cases the

1146
00:52:30,080 --> 00:52:34,730
vendors own own it and they

1147
00:52:32,090 --> 00:52:37,010
commercialize it we don't we don't I

1148
00:52:34,730 --> 00:52:39,140
used to do patents years ago yeah

1149
00:52:37,010 --> 00:52:41,300
patents are a pain in the butt amen you

1150
00:52:39,140 --> 00:52:43,430
know yes how many times patents are

1151
00:52:41,300 --> 00:52:45,110
defended you got to show up in court be

1152
00:52:43,430 --> 00:52:46,640
a subject matter expert and never get

1153
00:52:45,110 --> 00:52:47,270
your name on a patent it's a dumbest

1154
00:52:46,640 --> 00:52:50,569
thing in the world

1155
00:52:47,270 --> 00:52:51,890
yeah I think yeah thank you so much just

1156
00:52:50,570 --> 00:52:55,610
a couple other little quick ones so how

1157
00:52:51,890 --> 00:52:58,299
many people are you in charge of five

1158
00:52:55,610 --> 00:53:01,640
five hundred and then how many layers

1159
00:52:58,300 --> 00:53:03,230
yeah about six maybe five to six

1160
00:53:01,640 --> 00:53:05,180
depending on some of the operational

1161
00:53:03,230 --> 00:53:07,580
functions have more layers but yeah

1162
00:53:05,180 --> 00:53:09,160
thank you so much thank you how we doing

1163
00:53:07,580 --> 00:53:13,700
on time

1164
00:53:09,160 --> 00:53:16,180
two more can I collect money for these

1165
00:53:13,700 --> 00:53:19,040
[Laughter]

1166
00:53:16,180 --> 00:53:21,890
fascinating idea I'm wondering how long

1167
00:53:19,040 --> 00:53:24,710
does it take to gather the information

1168
00:53:21,890 --> 00:53:27,109
for the behavioral profile thinking you

1169
00:53:24,710 --> 00:53:28,730
hire someone in who's going to have well

1170
00:53:27,110 --> 00:53:30,230
in military terms would be like top

1171
00:53:28,730 --> 00:53:31,010
secret secure compartment and

1172
00:53:30,230 --> 00:53:32,930
information

1173
00:53:31,010 --> 00:53:35,140
I assume you can't wait around for two

1174
00:53:32,930 --> 00:53:36,680
years before they can get to that yeah

1175
00:53:35,140 --> 00:53:38,990
thank you for asking that question

1176
00:53:36,680 --> 00:53:41,120
that's a great question it's about two

1177
00:53:38,990 --> 00:53:42,890
weeks in terms of behavior but it's

1178
00:53:41,120 --> 00:53:45,109
dependent upon the frequency of the

1179
00:53:42,890 --> 00:53:47,299
transactions and unfortunately in

1180
00:53:45,110 --> 00:53:50,240
healthcare you guys don't go to the

1181
00:53:47,300 --> 00:53:52,070
health plan website more than six times

1182
00:53:50,240 --> 00:53:54,350
a year I've noticed you know and it's

1183
00:53:52,070 --> 00:53:55,280
usually an open enrollment that's about

1184
00:53:54,350 --> 00:53:58,190
it

1185
00:53:55,280 --> 00:54:00,710
and so we actually create incentives to

1186
00:53:58,190 --> 00:54:03,830
create more interaction with both mobile

1187
00:54:00,710 --> 00:54:05,600
and web activity for explicitly this

1188
00:54:03,830 --> 00:54:08,270
reason because we need more data to

1189
00:54:05,600 --> 00:54:10,730
build the patterns but generally

1190
00:54:08,270 --> 00:54:12,860
speaking it's about 10 business days

1191
00:54:10,730 --> 00:54:16,190
that it takes us to have a model that

1192
00:54:12,860 --> 00:54:18,150
we're highly confident in so in the mean

1193
00:54:16,190 --> 00:54:21,299
time we actually give a pin

1194
00:54:18,150 --> 00:54:24,359
but you know one time or not one time a

1195
00:54:21,299 --> 00:54:26,819
pin that we give at registration and

1196
00:54:24,359 --> 00:54:29,369
then they use the pin but most of them

1197
00:54:26,819 --> 00:54:32,430
within the first day they use the

1198
00:54:29,369 --> 00:54:36,240
biometric they just use that and so we

1199
00:54:32,430 --> 00:54:39,390
rely on the biometric and a pin if they

1200
00:54:36,240 --> 00:54:41,520
choose that during once they register

1201
00:54:39,390 --> 00:54:43,950
for about the first couple of weeks and

1202
00:54:41,520 --> 00:54:46,020
then the model kicks in after that and

1203
00:54:43,950 --> 00:54:49,078
and does everything in the background so

1204
00:54:46,020 --> 00:54:51,930
it's a good good question the identity

1205
00:54:49,079 --> 00:54:56,010
proofing is the weakest part of this

1206
00:54:51,930 --> 00:54:58,649
model and so we're looking at a couple

1207
00:54:56,010 --> 00:55:00,510
of alternatives right now of taking a

1208
00:54:58,650 --> 00:55:04,819
picture of your driver's license and a

1209
00:55:00,510 --> 00:55:07,349
picture of yourself and mapping both and

1210
00:55:04,819 --> 00:55:09,808
using that as a verification process for

1211
00:55:07,349 --> 00:55:11,460
identity proofing so that's one option

1212
00:55:09,809 --> 00:55:14,970
there's a couple of other options as

1213
00:55:11,460 --> 00:55:17,400
well but trying to solve the identity

1214
00:55:14,970 --> 00:55:19,919
proofing in registration problem is

1215
00:55:17,400 --> 00:55:22,049
actually buying us the time to use the

1216
00:55:19,920 --> 00:55:26,520
model so it's good real good question

1217
00:55:22,049 --> 00:55:27,599
last question Jim okay you've got a

1218
00:55:26,520 --> 00:55:29,849
whole bunch of really good and

1219
00:55:27,599 --> 00:55:31,829
interesting unconventional controls but

1220
00:55:29,849 --> 00:55:33,930
we also live in a world where there are

1221
00:55:31,829 --> 00:55:36,150
a lot of people who are comfortable with

1222
00:55:33,930 --> 00:55:37,740
the conventional yeah so how would you

1223
00:55:36,150 --> 00:55:39,059
convince the auditors not to ding you

1224
00:55:37,740 --> 00:55:40,649
how do you convince the board to allow

1225
00:55:39,059 --> 00:55:42,329
you to go with this kind of approach

1226
00:55:40,650 --> 00:55:44,569
yeah I'm glad you asked that question

1227
00:55:42,329 --> 00:55:50,400
because and both have different answers

1228
00:55:44,569 --> 00:55:52,410
so the auditors I teach it's something I

1229
00:55:50,400 --> 00:55:56,789
learned in financial services if you

1230
00:55:52,410 --> 00:56:00,960
teach regulators new advanced techniques

1231
00:55:56,789 --> 00:56:03,059
they always go to you first and they

1232
00:56:00,960 --> 00:56:05,220
never give you a hard time because

1233
00:56:03,059 --> 00:56:06,779
they're there to learn the people that

1234
00:56:05,220 --> 00:56:10,049
give the enterprises they give a hard

1235
00:56:06,779 --> 00:56:11,730
time on are the ones after you because

1236
00:56:10,049 --> 00:56:13,589
that's when they start to apply what

1237
00:56:11,730 --> 00:56:16,170
you've taught them and that's when it

1238
00:56:13,589 --> 00:56:18,839
gets a little bit more painful for the

1239
00:56:16,170 --> 00:56:21,029
enterprise so I never have a problem now

1240
00:56:18,839 --> 00:56:23,730
in this case we're using a lot of models

1241
00:56:21,029 --> 00:56:26,940
as an example so there's a methodology

1242
00:56:23,730 --> 00:56:29,069
called crisp it's not that you need to

1243
00:56:26,940 --> 00:56:31,870
remember an acronym it's a methodology

1244
00:56:29,069 --> 00:56:36,009
to prove the efficacy of

1245
00:56:31,870 --> 00:56:39,040
a algorithm and it's what auditors have

1246
00:56:36,010 --> 00:56:41,770
to be equipped with to determine whether

1247
00:56:39,040 --> 00:56:44,080
these controls are effective or not you

1248
00:56:41,770 --> 00:56:46,150
can run all a sample tests that you want

1249
00:56:44,080 --> 00:56:48,880
at the end of the day you've got to test

1250
00:56:46,150 --> 00:56:51,270
the efficacy of the model and so I teach

1251
00:56:48,880 --> 00:56:54,130
auditors we have a class that teaches

1252
00:56:51,270 --> 00:56:57,070
audit and our audit professionals I

1253
00:56:54,130 --> 00:56:58,900
treat them like cousins like I some of

1254
00:56:57,070 --> 00:57:01,150
our security people professionals go

1255
00:56:58,900 --> 00:57:03,070
into audit and some come from audit into

1256
00:57:01,150 --> 00:57:06,310
cybersecurity and we teach the same

1257
00:57:03,070 --> 00:57:08,440
curriculum for for both there cuz

1258
00:57:06,310 --> 00:57:10,390
they're kindred spirits if you will but

1259
00:57:08,440 --> 00:57:12,790
you have we for an unconventional

1260
00:57:10,390 --> 00:57:15,940
controls I have to teach now the board

1261
00:57:12,790 --> 00:57:18,520
is a little bit different the board I

1262
00:57:15,940 --> 00:57:24,040
have to teach them how to operate their

1263
00:57:18,520 --> 00:57:26,350
iPhone I know it sounds crazy but you

1264
00:57:24,040 --> 00:57:28,720
talk to them in terms that they can

1265
00:57:26,350 --> 00:57:31,029
understand in their daily life and most

1266
00:57:28,720 --> 00:57:34,149
board members are older than I am which

1267
00:57:31,030 --> 00:57:36,730
means olders dirt right so they're not

1268
00:57:34,150 --> 00:57:38,620
of the you know the generation uses

1269
00:57:36,730 --> 00:57:41,410
technology so you have to do basic

1270
00:57:38,620 --> 00:57:44,859
simple things like that and you have to

1271
00:57:41,410 --> 00:57:47,470
show them that their personal liability

1272
00:57:44,860 --> 00:57:49,540
is not at risk those are the two things

1273
00:57:47,470 --> 00:57:52,480
that they primarily care about and look

1274
00:57:49,540 --> 00:57:54,490
I have experience with some absolutely

1275
00:57:52,480 --> 00:57:56,650
the best most wonderful people in the

1276
00:57:54,490 --> 00:57:59,109
world that I've ever met have been part

1277
00:57:56,650 --> 00:58:02,080
of my board at different times

1278
00:57:59,110 --> 00:58:04,090
tremendous respect for them but I have

1279
00:58:02,080 --> 00:58:05,620
to spoon-feed the information and in a

1280
00:58:04,090 --> 00:58:07,510
way that they can understand it and

1281
00:58:05,620 --> 00:58:09,190
that's fundamentally different than a

1282
00:58:07,510 --> 00:58:11,650
regulator it's fundamentally different

1283
00:58:09,190 --> 00:58:13,360
than an IT professional and it's it's

1284
00:58:11,650 --> 00:58:16,000
different did that answer your question

1285
00:58:13,360 --> 00:58:19,440
yes thank you Jim thank you I hope this

1286
00:58:16,000 --> 00:58:19,440
was helpful god bless you thank you

1287
00:58:22,400 --> 00:58:27,840
okay thank you Jim for helping us close

1288
00:58:25,380 --> 00:58:29,940
begin to close down our session I would

1289
00:58:27,840 --> 00:58:33,660
be remiss if I didn't give a big

1290
00:58:29,940 --> 00:58:36,420
shout-out to our serious team Mike Adam

1291
00:58:33,660 --> 00:58:38,339
Lori they kind of kept this program

1292
00:58:36,420 --> 00:58:40,530
running for not only the last two days

1293
00:58:38,340 --> 00:58:42,750
but for the several months in advance so

1294
00:58:40,530 --> 00:58:45,060
as we as we prepared for this so I want

1295
00:58:42,750 --> 00:58:47,370
to make sure we recognize them if you

1296
00:58:45,060 --> 00:58:49,320
are part of the serious seminar class

1297
00:58:47,370 --> 00:58:50,970
make sure you find us and let us know

1298
00:58:49,320 --> 00:58:53,730
you were here so we can check you off

1299
00:58:50,970 --> 00:58:56,850
the roster list sign-up sheet is in the

1300
00:58:53,730 --> 00:58:59,790
back lori has it the symposium next year

1301
00:58:56,850 --> 00:59:02,940
in 2020 is April 14th and 15th mark your

1302
00:58:59,790 --> 00:59:05,580
calendars and with that unless spaff or

1303
00:59:02,940 --> 00:59:10,140
Dave or Joel has any other comments I'd

1304
00:59:05,580 --> 00:59:11,610
like to make in that case I want to

1305
00:59:10,140 --> 00:59:13,109
thank every one of you for coming I

1306
00:59:11,610 --> 00:59:14,610
really appreciate the time that you

1307
00:59:13,110 --> 00:59:16,050
spent with this his last couple days and

1308
00:59:14,610 --> 00:59:17,150
we look forward to seeing you next year

1309
00:59:16,050 --> 00:59:24,039
thank you

1310
00:59:17,150 --> 00:59:24,039
[Applause]

1311
00:59:29,039 --> 00:59:31,099
you

