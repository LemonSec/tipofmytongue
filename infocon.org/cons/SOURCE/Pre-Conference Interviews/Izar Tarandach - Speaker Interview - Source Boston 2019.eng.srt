1
00:00:05,170 --> 00:00:10,190
[Music]

2
00:00:08,390 --> 00:00:11,690
hi this is rob machine with a source

3
00:00:10,190 --> 00:00:13,670
conference and I'm here with easy art

4
00:00:11,690 --> 00:00:15,559
Aaron - and he is the lead product

5
00:00:13,670 --> 00:00:17,660
security architect at Autodesk

6
00:00:15,559 --> 00:00:19,340
and he's gonna be speaking next week a

7
00:00:17,660 --> 00:00:21,020
source Boston on May 1st through 3rd

8
00:00:19,340 --> 00:00:24,230
he's gonna be speaking on the Wednesday

9
00:00:21,020 --> 00:00:27,500
and his topic is threat model every

10
00:00:24,230 --> 00:00:29,240
story developers or architects - so

11
00:00:27,500 --> 00:00:30,859
these are why don't you tell us a little

12
00:00:29,240 --> 00:00:32,659
bit about your talk and what do you mean

13
00:00:30,859 --> 00:00:36,590
by that when you say that developers are

14
00:00:32,659 --> 00:00:39,290
architects - so this is an evolving talk

15
00:00:36,590 --> 00:00:41,720
it's that the whole thing started

16
00:00:39,290 --> 00:00:46,159
basically when I joined Autodesk about a

17
00:00:41,720 --> 00:00:47,629
year and a half ago and we figured out

18
00:00:46,159 --> 00:00:52,699
that our problem with threat modeling

19
00:00:47,629 --> 00:00:54,619
was scaling was getting threat models

20
00:00:52,699 --> 00:00:56,510
that work had the same speed as

21
00:00:54,619 --> 00:01:01,070
development does and that actually

22
00:00:56,510 --> 00:01:03,229
reflect what what the products are we we

23
00:01:01,070 --> 00:01:05,570
had seen before issues of threat

24
00:01:03,229 --> 00:01:08,000
modeling where it would be either done

25
00:01:05,570 --> 00:01:10,158
at the beginning of the project and then

26
00:01:08,000 --> 00:01:11,900
things would evolve and system would

27
00:01:10,159 --> 00:01:13,190
change and at the end of the day the

28
00:01:11,900 --> 00:01:15,110
tracked model would not match what

29
00:01:13,190 --> 00:01:18,190
actually goes up there and you would

30
00:01:15,110 --> 00:01:19,550
have that scramble just before

31
00:01:18,190 --> 00:01:21,380
deployment

32
00:01:19,550 --> 00:01:25,550
where hey let's figure out what happened

33
00:01:21,380 --> 00:01:27,259
here and with the amount of products

34
00:01:25,550 --> 00:01:28,789
that we have the different teams that we

35
00:01:27,260 --> 00:01:30,800
have different locations different

36
00:01:28,790 --> 00:01:32,690
levels of knowledge of security we we

37
00:01:30,800 --> 00:01:35,060
had to figure out a way to get everybody

38
00:01:32,690 --> 00:01:38,000
being able to do threat modeling that

39
00:01:35,060 --> 00:01:40,940
would respond to those issues and we

40
00:01:38,000 --> 00:01:44,480
came up with this nice methodology

41
00:01:40,940 --> 00:01:45,830
that's been working so far and we wanted

42
00:01:44,480 --> 00:01:48,920
to were to put it out there so that

43
00:01:45,830 --> 00:01:49,970
people could also contribute to it see

44
00:01:48,920 --> 00:01:52,250
if it's something that they can use

45
00:01:49,970 --> 00:01:54,408
themselves and get some discussion going

46
00:01:52,250 --> 00:01:57,830
around and together with that there is a

47
00:01:54,409 --> 00:01:59,930
tool that we've been working on - two

48
00:01:57,830 --> 00:02:04,009
people from Autodesk and two other of

49
00:01:59,930 --> 00:02:06,620
external collaborators that does start

50
00:02:04,010 --> 00:02:08,299
modeling is called and this talk is also

51
00:02:06,620 --> 00:02:10,190
a vehicle to put it out there and show

52
00:02:08,299 --> 00:02:13,239
to people and see if we can get more

53
00:02:10,190 --> 00:02:15,620
people contributing to it and using it

54
00:02:13,239 --> 00:02:19,910
so it's kind of a model for people to

55
00:02:15,620 --> 00:02:21,950
use going forward that's cool yeah one

56
00:02:19,910 --> 00:02:24,049
thing you you pointed out was that

57
00:02:21,950 --> 00:02:25,519
you know the idea that you do the threat

58
00:02:24,050 --> 00:02:28,040
modeling up front and then later it

59
00:02:25,520 --> 00:02:30,020
changes I've definitely seen that myself

60
00:02:28,040 --> 00:02:33,440
a lot I actually teach a threat modeling

61
00:02:30,020 --> 00:02:34,520
class and oftentimes it's funny there

62
00:02:33,440 --> 00:02:35,870
has been a number of times where the

63
00:02:34,520 --> 00:02:38,090
first time they saw an architecture

64
00:02:35,870 --> 00:02:40,160
diagram was when I drew them one and

65
00:02:38,090 --> 00:02:43,610
usually it's not that bad but what

66
00:02:40,160 --> 00:02:44,840
frequently does happen is I'll have

67
00:02:43,610 --> 00:02:45,950
somebody else they all right who's the

68
00:02:44,840 --> 00:02:48,010
best person to draw the picture and

69
00:02:45,950 --> 00:02:50,268
they're up drawing the picture and

70
00:02:48,010 --> 00:02:51,560
somebody in the back goes hey wait no

71
00:02:50,269 --> 00:02:52,880
that's not how it really works and

72
00:02:51,560 --> 00:02:54,110
they're like that's what and then they

73
00:02:52,880 --> 00:02:55,489
argue about it for like 20 minutes

74
00:02:54,110 --> 00:02:57,319
they'll late and I'll just let it happen

75
00:02:55,489 --> 00:02:59,569
I'm like alright just figure it out cuz

76
00:02:57,319 --> 00:03:01,670
we need to know the answer but it's

77
00:02:59,569 --> 00:03:04,488
amazing if they if you don't force them

78
00:03:01,670 --> 00:03:06,890
to have that conversation then it just

79
00:03:04,489 --> 00:03:08,540
doesn't happen sometimes and I noticed

80
00:03:06,890 --> 00:03:11,839
you would point it out in your abstract

81
00:03:08,540 --> 00:03:14,630
that it's kind of gotten worse under

82
00:03:11,840 --> 00:03:16,069
agile in a lot of ways because at least

83
00:03:14,630 --> 00:03:17,989
under the waterfall model you had a

84
00:03:16,069 --> 00:03:19,880
formal structure and time place where

85
00:03:17,989 --> 00:03:21,140
things happen whereas agile you just

86
00:03:19,880 --> 00:03:22,940
have sprints and you're just it's ever

87
00:03:21,140 --> 00:03:25,339
evolving story is like how do you see

88
00:03:22,940 --> 00:03:26,390
that it's that it varies in agile versus

89
00:03:25,340 --> 00:03:28,880
waterfall what are your experiences

90
00:03:26,390 --> 00:03:31,399
there what what you described is what's

91
00:03:28,880 --> 00:03:34,340
usually called the Eureka moment which

92
00:03:31,400 --> 00:03:35,780
is that time when people say yeah we are

93
00:03:34,340 --> 00:03:38,000
secure because we do it this way in that

94
00:03:35,780 --> 00:03:41,720
way and then some developers back of the

95
00:03:38,000 --> 00:03:47,090
room cause it's not exactly like that we

96
00:03:41,720 --> 00:03:50,180
had to take some shortcuts or actually

97
00:03:47,090 --> 00:03:52,130
to to to connect to your point I think

98
00:03:50,180 --> 00:03:54,739
that that discussion when it comes up is

99
00:03:52,130 --> 00:03:56,859
one of the best things ever because one

100
00:03:54,739 --> 00:03:59,720
of the things that I have seen with

101
00:03:56,859 --> 00:04:01,880
threat models is that either you get

102
00:03:59,720 --> 00:04:03,709
that one person that gets designated as

103
00:04:01,880 --> 00:04:07,640
the threat modeler and he's going to

104
00:04:03,709 --> 00:04:09,019
carry the whole thing or you do have

105
00:04:07,640 --> 00:04:10,850
that disconnect between different teams

106
00:04:09,019 --> 00:04:12,769
working on the same system and whatnot

107
00:04:10,850 --> 00:04:15,530
and the systems that we have nowadays

108
00:04:12,769 --> 00:04:17,180
data gets it's a paradox they get more

109
00:04:15,530 --> 00:04:18,649
and more complex even though the pieces

110
00:04:17,180 --> 00:04:22,820
that we use on them get simpler and

111
00:04:18,649 --> 00:04:26,719
simpler so if we can use the threat

112
00:04:22,820 --> 00:04:28,180
model in my opinion to to help the

113
00:04:26,720 --> 00:04:29,990
discussion between the different

114
00:04:28,180 --> 00:04:32,150
developers and different teams and

115
00:04:29,990 --> 00:04:34,010
different parts of the system talking

116
00:04:32,150 --> 00:04:35,270
about and actually having those arica

117
00:04:34,010 --> 00:04:36,680
moments that

118
00:04:35,270 --> 00:04:41,090
a lot of value in the threat model

119
00:04:36,680 --> 00:04:43,280
itself in the process itself so the

120
00:04:41,090 --> 00:04:45,950
whole methodology is built around that

121
00:04:43,280 --> 00:04:48,140
and the tool actually is is in there not

122
00:04:45,950 --> 00:04:52,310
to actually find threats that are of

123
00:04:48,140 --> 00:04:54,440
high value but to enable developers to

124
00:04:52,310 --> 00:04:57,650
have that discussion as the system

125
00:04:54,440 --> 00:04:59,090
develops got it so what are some things

126
00:04:57,650 --> 00:05:01,400
about the methodology that you're

127
00:04:59,090 --> 00:05:03,799
proposing that allows that to happen

128
00:05:01,400 --> 00:05:05,539
like like what in the methodology lets

129
00:05:03,800 --> 00:05:07,390
people kind of get to it early and and

130
00:05:05,540 --> 00:05:12,410
keep it up to date and all that stuff so

131
00:05:07,390 --> 00:05:15,050
I think that if I if I were to order it

132
00:05:12,410 --> 00:05:17,570
I think that one of the big problems

133
00:05:15,050 --> 00:05:19,910
that I have with the way that we've been

134
00:05:17,570 --> 00:05:21,980
doing threat modeling so far is training

135
00:05:19,910 --> 00:05:25,430
we are asking people to figure out

136
00:05:21,980 --> 00:05:27,860
threats basically out of the blue like

137
00:05:25,430 --> 00:05:29,570
think like a hacker come out with what

138
00:05:27,860 --> 00:05:31,940
could possibly go wrong and sometimes

139
00:05:29,570 --> 00:05:35,390
they they lack not only the knowledge of

140
00:05:31,940 --> 00:05:38,450
what is a threat actually but they even

141
00:05:35,390 --> 00:05:40,060
lack the knowledge of the fundamentals

142
00:05:38,450 --> 00:05:42,860
of what is it that there they are

143
00:05:40,060 --> 00:05:45,170
protecting and what could possibly go

144
00:05:42,860 --> 00:05:48,830
wrong so a big part of the the

145
00:05:45,170 --> 00:05:51,800
methodology is focusing on those

146
00:05:48,830 --> 00:05:55,880
specific areas of security interest in a

147
00:05:51,800 --> 00:05:57,140
system pointing out example questions

148
00:05:55,880 --> 00:06:00,460
that you would ask when you were

149
00:05:57,140 --> 00:06:02,900
evaluation evaluating for example

150
00:06:00,460 --> 00:06:05,390
authorization authentication or how do

151
00:06:02,900 --> 00:06:07,729
you defend your secrets or or even how

152
00:06:05,390 --> 00:06:11,570
do you find out what is it in your

153
00:06:07,730 --> 00:06:13,760
system that's that's worth defending so

154
00:06:11,570 --> 00:06:16,520
a big part of it is getting that initial

155
00:06:13,760 --> 00:06:20,150
focus to build the baseline threat model

156
00:06:16,520 --> 00:06:22,400
and then later on it's a checklist based

157
00:06:20,150 --> 00:06:24,770
approach but not really a checklist of

158
00:06:22,400 --> 00:06:27,140
checks that puts the developer in the

159
00:06:24,770 --> 00:06:29,810
mind of okay I have this store in front

160
00:06:27,140 --> 00:06:31,969
of me I'm going to write cold I'm going

161
00:06:29,810 --> 00:06:34,010
to possibly even change the design of

162
00:06:31,970 --> 00:06:36,800
the system what are the things that I

163
00:06:34,010 --> 00:06:38,870
have to have in mind in terms of

164
00:06:36,800 --> 00:06:41,180
security what what could it be that I'm

165
00:06:38,870 --> 00:06:44,360
doing right now without considering the

166
00:06:41,180 --> 00:06:46,700
security point of view that I actually

167
00:06:44,360 --> 00:06:49,010
have to to introduce to a track model or

168
00:06:46,700 --> 00:06:50,810
that I have to route to

169
00:06:49,010 --> 00:06:52,909
other part of the team that somebody has

170
00:06:50,810 --> 00:06:55,790
to pay attention to that or something

171
00:06:52,910 --> 00:06:58,790
for example a developer that has to open

172
00:06:55,790 --> 00:07:01,190
another part for them it's okay I open

173
00:06:58,790 --> 00:07:03,950
the port it's talking David's flowing

174
00:07:01,190 --> 00:07:05,750
fine but perhaps they have to make that

175
00:07:03,950 --> 00:07:07,580
part of the deployment augmentation or

176
00:07:05,750 --> 00:07:09,530
they have to let another part of the

177
00:07:07,580 --> 00:07:13,070
team that deals with the firewalls know

178
00:07:09,530 --> 00:07:15,109
about it so figuring out those security

179
00:07:13,070 --> 00:07:17,120
notable events and making sure that

180
00:07:15,110 --> 00:07:19,280
everybody that has to hear about them

181
00:07:17,120 --> 00:07:21,770
hears about them and addresses them

182
00:07:19,280 --> 00:07:25,700
either as a possible threat or something

183
00:07:21,770 --> 00:07:27,229
that has to be written down somewhere or

184
00:07:25,700 --> 00:07:29,539
part of the tribal knowledge of the

185
00:07:27,230 --> 00:07:33,080
system that's basically we're committed

186
00:07:29,540 --> 00:07:35,150
ology goes right

187
00:07:33,080 --> 00:07:37,789
well that sounds awesome I know a lot of

188
00:07:35,150 --> 00:07:39,200
people struggle with this and you know

189
00:07:37,790 --> 00:07:40,910
there's not nearly enough threat

190
00:07:39,200 --> 00:07:42,770
modeling done up there so the fact that

191
00:07:40,910 --> 00:07:44,060
you guys have a formal methodology that

192
00:07:42,770 --> 00:07:45,289
you're creating that you're using is

193
00:07:44,060 --> 00:07:47,690
great and you're you know it's kind of

194
00:07:45,290 --> 00:07:49,010
battle tested a little bit so definitely

195
00:07:47,690 --> 00:07:51,440
looking forward to seeing the talk and

196
00:07:49,010 --> 00:07:54,020
hearing more about what you guys come up

197
00:07:51,440 --> 00:07:56,300
with looking forward to being there

198
00:07:54,020 --> 00:07:57,590
all right great well if anybody wants to

199
00:07:56,300 --> 00:07:59,870
continue the conversation come on by

200
00:07:57,590 --> 00:08:01,880
source Boston next week these are ours

201
00:07:59,870 --> 00:08:05,630
gonna be speaking on this topic on

202
00:08:01,880 --> 00:08:08,920
Wednesday and we'll see you there thanks

203
00:08:05,630 --> 00:08:08,920
guys there thank you

