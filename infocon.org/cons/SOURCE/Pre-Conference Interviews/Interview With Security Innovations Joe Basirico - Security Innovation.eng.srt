1
00:00:02,280 --> 00:00:05,580
hi I'm Regine I'm the executive director

2
00:00:04,170 --> 00:00:07,830
of the source conference I'm here today

3
00:00:05,580 --> 00:00:10,620
with Joe Becerra Co hey Rob from

4
00:00:07,830 --> 00:00:12,930
security innovation we're gonna have a

5
00:00:10,620 --> 00:00:14,430
chat about some it's pretty dominant so

6
00:00:12,930 --> 00:00:16,259
yeah it sounds great cool

7
00:00:14,430 --> 00:00:19,650
so we click on this box so you're gonna

8
00:00:16,260 --> 00:00:22,289
be doing a talk later today yeah I'll be

9
00:00:19,650 --> 00:00:25,650
talking about some of the social aspects

10
00:00:22,289 --> 00:00:28,019
of kind of integrating communication

11
00:00:25,650 --> 00:00:30,179
around giving hackers and security

12
00:00:28,019 --> 00:00:31,799
researchers to essentially tell you

13
00:00:30,179 --> 00:00:34,019
about the vulnerabilities that they find

14
00:00:31,800 --> 00:00:35,760
so this includes things like have a

15
00:00:34,020 --> 00:00:38,730
message that program how to roll out a

16
00:00:35,760 --> 00:00:41,610
bug bounty program and just kind of how

17
00:00:38,730 --> 00:00:46,980
to do internal and external mess okay so

18
00:00:41,610 --> 00:00:49,110
kind of yeah yeah one of the things that

19
00:00:46,980 --> 00:00:53,040
we see a lot of companies trouble with

20
00:00:49,110 --> 00:00:55,769
is just their ability to communicate

21
00:00:53,040 --> 00:00:57,420
effectively with security researchers so

22
00:00:55,770 --> 00:00:59,820
security researchers are out there

23
00:00:57,420 --> 00:01:02,720
they're finding vulnerabilities new

24
00:00:59,820 --> 00:01:04,949
software whether you like it or not and

25
00:01:02,720 --> 00:01:07,230
under most circumstances they want to

26
00:01:04,949 --> 00:01:09,899
tell you about it and so how can you

27
00:01:07,230 --> 00:01:13,500
make that as easy as possible one of the

28
00:01:09,900 --> 00:01:15,270
ways to do that is bounty programs but

29
00:01:13,500 --> 00:01:17,970
waiting before you get to a bug bounty

30
00:01:15,270 --> 00:01:19,320
program you might want to roll out just

31
00:01:17,970 --> 00:01:22,320
some external messaging like how you

32
00:01:19,320 --> 00:01:25,110
want to be communicated with and how you

33
00:01:22,320 --> 00:01:27,869
get your marketing team and your legal

34
00:01:25,110 --> 00:01:29,550
team involved and things like that and

35
00:01:27,870 --> 00:01:30,780
how you want to know structure that

36
00:01:29,550 --> 00:01:34,320
compensation

37
00:01:30,780 --> 00:01:35,250
so be more proactive yeah so what are

38
00:01:34,320 --> 00:01:36,770
the challenges I think we're actually

39
00:01:35,250 --> 00:01:39,840
chatting about it a little earlier is

40
00:01:36,770 --> 00:01:42,390
when you have companies who've never

41
00:01:39,840 --> 00:01:43,740
dealt with security researchers yeah and

42
00:01:42,390 --> 00:01:49,350
the first time they do it's kind of

43
00:01:43,740 --> 00:01:54,619
terrifying to them yeah what would you

44
00:01:49,350 --> 00:01:57,630
recommend to those kind of yeah yeah so

45
00:01:54,619 --> 00:01:59,610
first up first contact to a security

46
00:01:57,630 --> 00:02:02,490
researcher should probably not be a

47
00:01:59,610 --> 00:02:05,759
lawyer I would start there it's a good

48
00:02:02,490 --> 00:02:08,310
place to start reach out whether that's

49
00:02:05,759 --> 00:02:11,160
with a marketing team or another

50
00:02:08,310 --> 00:02:14,160
engineer or somebody who can start that

51
00:02:11,160 --> 00:02:17,790
ball rolling I think it's important you

52
00:02:14,160 --> 00:02:21,180
know that the security researcher with

53
00:02:17,790 --> 00:02:23,670
respect again they're kind of doing free

54
00:02:21,180 --> 00:02:29,040
testing for you so and they certainly

55
00:02:23,670 --> 00:02:32,880
could have done nothing with it more

56
00:02:29,040 --> 00:02:37,530
nefarious than finding but they came to

57
00:02:32,880 --> 00:02:40,739
you so straight up it's best to start

58
00:02:37,530 --> 00:02:43,290
with kind of that mutual respect again

59
00:02:40,739 --> 00:02:47,060
just making it easy making sure that the

60
00:02:43,290 --> 00:02:51,989
security researcher can easily find your

61
00:02:47,060 --> 00:02:56,790
security page on your website my website

62
00:02:51,989 --> 00:03:00,690
comm slash security should be gives them

63
00:02:56,790 --> 00:03:02,780
information about having a security app

64
00:03:00,690 --> 00:03:07,130
email address this is really important

65
00:03:02,780 --> 00:03:07,130
and having someone who

66
00:03:08,819 --> 00:03:12,720
so really kind of thinking through how

67
00:03:11,159 --> 00:03:16,769
you want them to interact before they

68
00:03:12,720 --> 00:03:19,250
interact yeah yeah and it can be scary

69
00:03:16,769 --> 00:03:21,599
right I remember one of the first times

70
00:03:19,250 --> 00:03:24,659
security innovation follows kind of

71
00:03:21,599 --> 00:03:26,988
strict responsible disclosure which for

72
00:03:24,659 --> 00:03:30,720
us means that we never publicized

73
00:03:26,989 --> 00:03:33,120
vulnerabilities that we find so we'll

74
00:03:30,720 --> 00:03:37,049
work with that company as long as it

75
00:03:33,120 --> 00:03:38,459
takes you know if it takes a month for

76
00:03:37,049 --> 00:03:40,019
them to fix it or six minutes for them

77
00:03:38,459 --> 00:03:44,790
to fix it we're still not gonna go and

78
00:03:40,019 --> 00:03:48,000
publish it on but I remember before this

79
00:03:44,790 --> 00:03:50,150
was a long time ago I made my first

80
00:03:48,000 --> 00:03:53,730
responsible disclosure phone call and

81
00:03:50,150 --> 00:03:56,840
the phone call ended with okay well how

82
00:03:53,730 --> 00:04:00,450
long how long do we have to fix this and

83
00:03:56,840 --> 00:04:02,879
in my naive brain I thought he was

84
00:04:00,450 --> 00:04:07,260
asking how long will it take to fix it

85
00:04:02,879 --> 00:04:09,239
and so my answer was no two weeks and oh

86
00:04:07,260 --> 00:04:11,069
you know that's very generous

87
00:04:09,239 --> 00:04:17,340
how about a month I said sure take a

88
00:04:11,069 --> 00:04:18,719
month take two and and then we hung up

89
00:04:17,339 --> 00:04:21,209
and I was kind of recounting the whole

90
00:04:18,720 --> 00:04:23,099
story to a co-worker of mine because you

91
00:04:21,209 --> 00:04:24,599
know they were probably expecting you to

92
00:04:23,099 --> 00:04:26,430
like go public at the end of that

93
00:04:24,599 --> 00:04:29,490
two-month window

94
00:04:26,430 --> 00:04:32,009
[Music]

95
00:04:29,490 --> 00:04:33,210
we're not we're not going to publish but

96
00:04:32,009 --> 00:04:34,289
that's one of those conversations that

97
00:04:33,210 --> 00:04:36,270
you need to have with the security

98
00:04:34,289 --> 00:04:38,370
researcher you need to know like okay

99
00:04:36,270 --> 00:04:39,960
you're telling us about this but what's

100
00:04:38,370 --> 00:04:42,630
your policy on disclosure are you gonna

101
00:04:39,960 --> 00:04:45,330
go open disclosure and once it sticks do

102
00:04:42,630 --> 00:04:50,090
I have a hard time line is a negotiable

103
00:04:45,330 --> 00:04:50,090
like as long as you see forward progress

104
00:04:50,449 --> 00:05:19,020
you know is it okay if you have other

105
00:05:14,130 --> 00:05:24,210
people there doing it just for we're

106
00:05:19,020 --> 00:05:28,818
what are some of your thoughts on yeah

107
00:05:24,210 --> 00:05:31,289
I I appreciate that

108
00:05:28,819 --> 00:05:35,280
disclosure and the security industry in

109
00:05:31,289 --> 00:05:37,349
general is a giant ecosystem one end of

110
00:05:35,280 --> 00:05:39,570
the spectrum you have folks like us that

111
00:05:37,349 --> 00:05:41,639
are really hard line responsible

112
00:05:39,570 --> 00:05:44,340
disclosure never disclose it out

113
00:05:41,639 --> 00:05:45,810
externally on the other end you have you

114
00:05:44,340 --> 00:05:48,750
know selling bonobos to the highest

115
00:05:45,810 --> 00:05:49,080
bidder and publishing country on a spin

116
00:05:48,750 --> 00:05:53,130
right

117
00:05:49,080 --> 00:05:55,490
and without that whole spectrum I think

118
00:05:53,130 --> 00:05:58,330
people would be maybe less likely to

119
00:05:55,490 --> 00:06:00,760
feel that pressure to

120
00:05:58,330 --> 00:06:04,650
fix and remediating security home I

121
00:06:00,760 --> 00:06:07,419
remember you know just ten years ago

122
00:06:04,650 --> 00:06:09,099
arguing for buffer overflows to get

123
00:06:07,419 --> 00:06:10,750
fixed you know like I'm saying like hey

124
00:06:09,100 --> 00:06:12,520
this is an exploitable buffer overflow

125
00:06:10,750 --> 00:06:14,680
it's gonna be really bad for you if this

126
00:06:12,520 --> 00:06:16,539
you know something else finds this you

127
00:06:14,680 --> 00:06:18,550
need to fix it they go well what's the

128
00:06:16,540 --> 00:06:19,600
likelihood that somebody else is going

129
00:06:18,550 --> 00:06:21,400
to be able to find it there something

130
00:06:19,600 --> 00:06:24,520
else is going to be a blessed way and

131
00:06:21,400 --> 00:06:27,609
then you know Microsoft kind of felt the

132
00:06:24,520 --> 00:06:32,139
pain of that in the Code Red in the era

133
00:06:27,610 --> 00:06:36,250
and I think everybody kind of got their

134
00:06:32,139 --> 00:06:39,760
eyes open in that scenario but it's only

135
00:06:36,250 --> 00:06:41,800
because of this wide spectrum and so my

136
00:06:39,760 --> 00:06:45,150
personal feeling is that it takes that

137
00:06:41,800 --> 00:06:47,940
wide spectrum to make forward progress

138
00:06:45,150 --> 00:06:53,739
but for security innovation we really

139
00:06:47,940 --> 00:06:55,600
focus on what's the best value to the

140
00:06:53,740 --> 00:06:59,220
end-user one of the things that got me

141
00:06:55,600 --> 00:07:02,229
into security in the first place was my

142
00:06:59,220 --> 00:07:04,419
parents like most of our parents aren't

143
00:07:02,229 --> 00:07:06,789
super tech savvy and they're super

144
00:07:04,419 --> 00:07:08,669
afraid of using their credit cards

145
00:07:06,789 --> 00:07:12,300
online or getting their identity stolen

146
00:07:08,669 --> 00:07:16,030
and they have this like this concern

147
00:07:12,300 --> 00:07:17,770
about the software and the devices and

148
00:07:16,030 --> 00:07:19,539
things like that that they're using but

149
00:07:17,770 --> 00:07:22,200
they have no ability to protect

150
00:07:19,539 --> 00:07:24,729
themselves right like they can't make

151
00:07:22,200 --> 00:07:27,580
solid security decisions around what

152
00:07:24,729 --> 00:07:30,639
settings to tweak or how to set up the

153
00:07:27,580 --> 00:07:33,099
firewall at home or whatever and I just

154
00:07:30,639 --> 00:07:36,460
felt like that was unfair right like

155
00:07:33,099 --> 00:07:38,080
it's fine for me I've done this for a

156
00:07:36,460 --> 00:07:40,539
long time and I don't mind tweaking

157
00:07:38,080 --> 00:07:42,280
around with firewall settings but for

158
00:07:40,539 --> 00:07:44,349
your normal end user like they should be

159
00:07:42,280 --> 00:07:48,849
able to take their device out of the box

160
00:07:44,349 --> 00:07:51,180
and just use it without fear and you

161
00:07:48,849 --> 00:07:54,349
know so building and

162
00:07:51,180 --> 00:07:59,100
secure software is a major component

163
00:07:54,350 --> 00:08:00,810
when you have companies are if you have

164
00:07:59,100 --> 00:08:02,210
no owner ability to do this nor the

165
00:08:00,810 --> 00:08:05,070
contentious things I've seen these days

166
00:08:02,210 --> 00:08:07,049
people talk about you know if somebody

167
00:08:05,070 --> 00:08:09,480
acts you and they find a hole you know

168
00:08:07,050 --> 00:08:12,570
should you pack them back or conversely

169
00:08:09,480 --> 00:08:14,880
if you if you are proactively looking

170
00:08:12,570 --> 00:08:17,810
for holes and you find them should you

171
00:08:14,880 --> 00:08:17,810
catch those machines

172
00:08:18,320 --> 00:08:23,610
yeah well that's gotten us into some

173
00:08:20,430 --> 00:08:25,920
pretty interesting scenarios I don't

174
00:08:23,610 --> 00:08:29,730
know if you remember but back in that

175
00:08:25,920 --> 00:08:32,580
code read nimbin era there was a benign

176
00:08:29,730 --> 00:08:34,590
worm that tried to go out and patch all

177
00:08:32,580 --> 00:08:36,780
of those servers and ended up causing

178
00:08:34,590 --> 00:08:38,430
more damage than the original work

179
00:08:36,780 --> 00:08:40,470
because it was downloading all of the

180
00:08:38,429 --> 00:08:44,459
Windows updates too saturated the

181
00:08:40,470 --> 00:08:48,240
network caused a lot of problems so you

182
00:08:44,460 --> 00:08:52,740
know I'm not a huge fan of like

183
00:08:48,240 --> 00:08:56,130
vigilante hacking or you know I for an I

184
00:08:52,740 --> 00:09:00,060
sort of thing just because it it kind of

185
00:08:56,130 --> 00:09:03,990
gets us into this odd scenario where

186
00:09:00,060 --> 00:09:06,900
both sides are malicious and one of the

187
00:09:03,990 --> 00:09:10,080
things that I really like to do is kind

188
00:09:06,900 --> 00:09:11,310
of serve as a partner to the

189
00:09:10,080 --> 00:09:13,740
organization's we work with in the

190
00:09:11,310 --> 00:09:15,900
organizations that that I just interact

191
00:09:13,740 --> 00:09:18,660
with on a day to day basis right so if

192
00:09:15,900 --> 00:09:21,840
I've stumble across the vulnerability in

193
00:09:18,660 --> 00:09:25,800
some app that I use I want them to fix

194
00:09:21,840 --> 00:09:27,990
that I want them to have all the

195
00:09:25,800 --> 00:09:30,630
knowledge and ability to remediate that

196
00:09:27,990 --> 00:09:37,350
ability because I'm a customer right

197
00:09:30,630 --> 00:09:39,600
like if if if I'm if I sit on that or

198
00:09:37,350 --> 00:09:42,360
they try to come back with like legal

199
00:09:39,600 --> 00:09:43,480
attacks like well they're gonna lose out

200
00:09:42,360 --> 00:09:45,730
on

201
00:09:43,480 --> 00:09:48,010
the security knowledge and they're also

202
00:09:45,730 --> 00:09:52,410
going to look at that other customer and

203
00:09:48,010 --> 00:09:52,410
then later on when they do get prettied

204
00:09:52,649 --> 00:10:11,410
it's good to have that what are your

205
00:10:00,670 --> 00:10:13,750
thoughts on yeah I got an email from my

206
00:10:11,410 --> 00:10:19,600
parents hey do I have to lock my credit

207
00:10:13,750 --> 00:10:21,880
or what the Equifax breach sadly I think

208
00:10:19,600 --> 00:10:23,889
is this kind of a textbook case of how

209
00:10:21,880 --> 00:10:27,670
not to do security right so from the

210
00:10:23,889 --> 00:10:30,850
very beginning to the even now with

211
00:10:27,670 --> 00:10:34,329
their noose interim CEO and their CTO

212
00:10:30,850 --> 00:10:39,550
and C so that all stepped down I mean

213
00:10:34,329 --> 00:10:41,319
they original vulnerability could have

214
00:10:39,550 --> 00:10:43,060
been easily attached with good patch

215
00:10:41,320 --> 00:10:45,370
management software it could have been

216
00:10:43,060 --> 00:10:48,099
known about it could have been handled

217
00:10:45,370 --> 00:10:51,310
properly they could have done better

218
00:10:48,100 --> 00:10:55,180
disaster recovery better breach analysis

219
00:10:51,310 --> 00:10:58,839
to know what was happening and kind of

220
00:10:55,180 --> 00:11:01,899
all of those things connected together

221
00:10:58,839 --> 00:11:04,389
to create this perfect storm of so many

222
00:11:01,899 --> 00:11:07,889
people losing data and then they

223
00:11:04,389 --> 00:11:07,889
followed it up with kind of

224
00:11:08,250 --> 00:11:14,400
not exactly well-thought-out plan to to

225
00:11:11,430 --> 00:11:16,229
remediate and fix this is one of the

226
00:11:14,400 --> 00:11:19,829
things that I actually think having a

227
00:11:16,230 --> 00:11:22,260
bug bounty program Social Security

228
00:11:19,830 --> 00:11:25,680
program would help certainly the

229
00:11:22,260 --> 00:11:29,490
attackers that attacked them wouldn't

230
00:11:25,680 --> 00:11:32,479
have turn that over 500 bucks in a

231
00:11:29,490 --> 00:11:34,680
bucket but I imagine somebody else would

232
00:11:32,480 --> 00:11:36,690
you know there are a lot of eyes and

233
00:11:34,680 --> 00:11:39,300
that was unknown vulnerability at the

234
00:11:36,690 --> 00:11:41,520
time and so having that bug bounty

235
00:11:39,300 --> 00:11:44,780
program out there probably would have

236
00:11:41,520 --> 00:11:44,780
meant they would have known about it and

237
00:11:45,260 --> 00:11:49,590
I've been kind of racking my brain about

238
00:11:48,000 --> 00:11:52,340
what do we do about this so you

239
00:11:49,590 --> 00:11:55,470
mentioned one of the obvious one is

240
00:11:52,340 --> 00:11:57,380
essentially every adult with a credit

241
00:11:55,470 --> 00:12:01,290
card or any kind of credit account now

242
00:11:57,380 --> 00:12:08,550
essentially their social address public

243
00:12:01,290 --> 00:12:15,000
information yeah essentially that is all

244
00:12:08,550 --> 00:12:18,449
other companies every company finding

245
00:12:15,000 --> 00:12:19,620
now needs to reissue all yeah things

246
00:12:18,450 --> 00:12:25,770
like what do you think about that I

247
00:12:19,620 --> 00:12:26,760
think that's it it is I mean if if you

248
00:12:25,770 --> 00:12:29,460
want to get into the nitty-gritty about

249
00:12:26,760 --> 00:12:32,340
it like your social security number was

250
00:12:29,460 --> 00:12:36,380
never really intended to be this unique

251
00:12:32,340 --> 00:12:38,970
identifier and it kind of just became

252
00:12:36,380 --> 00:12:42,030
using it in when I was in college my

253
00:12:38,970 --> 00:12:45,450
college ID was my social security and

254
00:12:42,030 --> 00:12:48,150
you know and it was up on public pages

255
00:12:45,450 --> 00:12:53,040
you know stuck to the outside of

256
00:12:48,150 --> 00:12:54,340
classrooms and stuff and and so yeah I

257
00:12:53,040 --> 00:12:57,189
mean it's it's

258
00:12:54,340 --> 00:12:58,900
and that data is is gone I mean like

259
00:12:57,190 --> 00:13:01,090
trying to put toothpaste back in the

260
00:12:58,900 --> 00:13:03,730
tube right like it's not it's not gonna

261
00:13:01,090 --> 00:13:07,270
go back in so it's just a watershed

262
00:13:03,730 --> 00:13:15,220
moment we're gonna stop using of course

263
00:13:07,270 --> 00:13:16,990
not no no I mean it's also not the time

264
00:13:15,220 --> 00:13:19,480
where every company is going to stop

265
00:13:16,990 --> 00:13:21,820
using plaintext passwords or you know

266
00:13:19,480 --> 00:13:23,350
using ORM s for all of their databases

267
00:13:21,820 --> 00:13:28,450
and all the other things that we should

268
00:13:23,350 --> 00:13:31,920
be doing but hopefully hopefully it will

269
00:13:28,450 --> 00:13:35,680
be kind of a beacon of what can go wrong

270
00:13:31,920 --> 00:13:38,020
where you have a company that is whose

271
00:13:35,680 --> 00:13:39,939
job it is to collect all of this

272
00:13:38,020 --> 00:13:43,300
information right like they're a single

273
00:13:39,940 --> 00:13:48,100
hub if you were looking at multiple

274
00:13:43,300 --> 00:13:49,750
companies to target for the biggest bang

275
00:13:48,100 --> 00:13:52,810
for your buck if I was gonna breach one

276
00:13:49,750 --> 00:13:56,230
of these companies and I looked at you

277
00:13:52,810 --> 00:13:59,520
know just thinking about like recent

278
00:13:56,230 --> 00:14:04,390
breaches have LinkedIn and Target and

279
00:13:59,520 --> 00:14:07,210
Equifax well like linkedin usernames and

280
00:14:04,390 --> 00:14:09,490
passwords my business contacts I know

281
00:14:07,210 --> 00:14:11,830
that's not a big deal

282
00:14:09,490 --> 00:14:14,050
target to get my credit card that's a

283
00:14:11,830 --> 00:14:15,790
little bit of a bigger deal with Equifax

284
00:14:14,050 --> 00:14:18,790
oh yeah everything and you get

285
00:14:15,790 --> 00:14:22,300
everything in one stop shop to become

286
00:14:18,790 --> 00:14:24,969
the essential digital everything from

287
00:14:22,300 --> 00:14:28,439
Social Security numbers addresses to you

288
00:14:24,970 --> 00:14:31,140
know all those little little bits of

289
00:14:28,440 --> 00:14:34,170
verification data

290
00:14:31,140 --> 00:14:35,670
that's a pretty impactful thing so so

291
00:14:34,170 --> 00:14:41,729
hopefully people will start to rethink

292
00:14:35,670 --> 00:14:44,459
this if the other two companies take

293
00:14:41,730 --> 00:14:46,019
note and make changes I think that's a

294
00:14:44,459 --> 00:14:53,518
good outcome I don't think it's the end

295
00:14:46,019 --> 00:14:55,680
of that's never gonna go away so I asked

296
00:14:53,519 --> 00:14:57,899
this question the other day in speed

297
00:14:55,680 --> 00:15:03,899
networking section what do you see is

298
00:14:57,899 --> 00:15:06,410
the most challenging problem and it's a

299
00:15:03,899 --> 00:15:06,410
good question

300
00:15:07,970 --> 00:15:16,079
one of the big difficulties I think is

301
00:15:12,180 --> 00:15:17,279
around education of testers and

302
00:15:16,079 --> 00:15:21,689
developers and people building the

303
00:15:17,279 --> 00:15:26,040
software around the impact but education

304
00:15:21,690 --> 00:15:30,660
only happens after you get budget and

305
00:15:26,040 --> 00:15:32,069
buy-in from higher up folks and so you

306
00:15:30,660 --> 00:15:34,579
know there's this this whole kind of

307
00:15:32,070 --> 00:15:34,579
trickle down

308
00:15:35,690 --> 00:15:40,889
path where you start with somebody with

309
00:15:38,759 --> 00:15:42,480
a good idea like we should stop writing

310
00:15:40,889 --> 00:15:44,370
security vulnerabilities how do we do

311
00:15:42,480 --> 00:15:46,230
that well we need education or we need

312
00:15:44,370 --> 00:15:49,410
assessments we need to process

313
00:15:46,230 --> 00:15:51,240
improvements or whatever we need but

314
00:15:49,410 --> 00:15:53,399
then we roll it out and we don't give

315
00:15:51,240 --> 00:15:56,610
the developers time we don't get the

316
00:15:53,399 --> 00:16:01,380
developers and testers access great

317
00:15:56,610 --> 00:16:03,750
education pieces or we kind of say stop

318
00:16:01,380 --> 00:16:05,220
writing security vulnerabilities and

319
00:16:03,750 --> 00:16:07,519
then we're surprised but they continue

320
00:16:05,220 --> 00:16:10,019
so I think that you know giving people

321
00:16:07,519 --> 00:16:14,880
treating security of like another aspect

322
00:16:10,019 --> 00:16:17,279
of software quality and really giving

323
00:16:14,880 --> 00:16:19,350
developers and testers the time to focus

324
00:16:17,279 --> 00:16:23,250
on it stop thinking about it like an

325
00:16:19,350 --> 00:16:25,230
add-on at the end you know there's a lot

326
00:16:23,250 --> 00:16:27,959
of folks we work with that have gone the

327
00:16:25,230 --> 00:16:29,519
entire development lifecycle through

328
00:16:27,959 --> 00:16:32,160
their entire process and they have a

329
00:16:29,519 --> 00:16:36,180
finished product and now they're coming

330
00:16:32,160 --> 00:16:39,209
to us for an assessment and that's great

331
00:16:36,180 --> 00:16:40,649
like I'm happy to you know do that but

332
00:16:39,209 --> 00:16:41,849
starting in the beginning and

333
00:16:40,649 --> 00:16:44,760
anticipating some of these

334
00:16:41,850 --> 00:16:47,130
vulnerabilities and doing the education

335
00:16:44,760 --> 00:16:48,329
necessary to minimize the number of

336
00:16:47,130 --> 00:16:50,100
vulnerabilities that get into the

337
00:16:48,329 --> 00:16:52,319
product in the first place just way more

338
00:16:50,100 --> 00:16:54,690
impact

339
00:16:52,320 --> 00:16:57,240
there's a big benefit though of using

340
00:16:54,690 --> 00:16:59,430
some of these modern frameworks one of

341
00:16:57,240 --> 00:17:03,389
the things that I like recommending is

342
00:16:59,430 --> 00:17:07,040
is leveraging modern frameworks that

343
00:17:03,389 --> 00:17:09,390
that like ORM like some of these

344
00:17:07,040 --> 00:17:10,589
templating engines that that kind of get

345
00:17:09,390 --> 00:17:12,890
rid of sequel injection cross-site

346
00:17:10,589 --> 00:17:14,730
scripting you know you shouldn't

347
00:17:12,890 --> 00:17:17,250
developers shouldn't have to implement

348
00:17:14,730 --> 00:17:17,730
their own Caesar protections and things

349
00:17:17,250 --> 00:17:21,439
like that

350
00:17:17,730 --> 00:17:24,480
instead you can just upload that to a

351
00:17:21,439 --> 00:17:27,089
mature framework and as long as you have

352
00:17:24,480 --> 00:17:28,980
a mature framework you don't have to

353
00:17:27,089 --> 00:17:39,389
think about it you start to solve the

354
00:17:28,980 --> 00:17:45,210
business security I was yes about that

355
00:17:39,390 --> 00:17:48,330
yeah so about seven seven years ago some

356
00:17:45,210 --> 00:17:53,040
friends of mine at a dinner party and we

357
00:17:48,330 --> 00:17:55,799
were all complaining about how we see so

358
00:17:53,040 --> 00:17:59,520
many white guys in insecurity and

359
00:17:55,799 --> 00:18:00,870
Technology in the stem fields and and

360
00:17:59,520 --> 00:18:05,070
how women and underrepresented

361
00:18:00,870 --> 00:18:09,000
minorities just really struggle to get

362
00:18:05,070 --> 00:18:11,580
into the stem industries and then

363
00:18:09,000 --> 00:18:13,860
throughout the evening we kept talking

364
00:18:11,580 --> 00:18:16,500
about it and finally by the end we're

365
00:18:13,860 --> 00:18:19,590
like well let's fix it and so we started

366
00:18:16,500 --> 00:18:20,970
technically learning and the goal of

367
00:18:19,590 --> 00:18:22,770
technically learning is to work with

368
00:18:20,970 --> 00:18:27,380
girls and other represented minorities

369
00:18:22,770 --> 00:18:30,270
in really young in elementary school

370
00:18:27,380 --> 00:18:34,169
because all of our studies and research

371
00:18:30,270 --> 00:18:36,910
looked at that people really start to

372
00:18:34,169 --> 00:18:40,060
opt out of stem programs really early

373
00:18:36,910 --> 00:18:43,090
even second third grade which is really

374
00:18:40,060 --> 00:18:45,850
a bummer and so we developed these

375
00:18:43,090 --> 00:18:49,689
curriculum and we rolled it out to a lot

376
00:18:45,850 --> 00:18:53,350
of the Seattle area schools I'm actually

377
00:18:49,690 --> 00:18:56,050
really happy to say that we emerged with

378
00:18:53,350 --> 00:18:58,240
code.org actually in about three years

379
00:18:56,050 --> 00:19:00,280
and so when code was just starting to

380
00:18:58,240 --> 00:19:03,190
get off the ground

381
00:19:00,280 --> 00:19:05,379
patty Ken desks and said you guys have

382
00:19:03,190 --> 00:19:07,180
methodology and employees and I have

383
00:19:05,380 --> 00:19:09,010
connections money let's get together and

384
00:19:07,180 --> 00:19:10,920
do something amazing and clearly

385
00:19:09,010 --> 00:19:18,879
code.org is just doing a great thing

386
00:19:10,920 --> 00:19:21,400
yeah yeah I think if I would have known

387
00:19:18,880 --> 00:19:24,100
how much work it was gonna be we might

388
00:19:21,400 --> 00:19:31,570
have to second-guess ourselves but we're

389
00:19:24,100 --> 00:19:35,199
just enough to do so security innovation

390
00:19:31,570 --> 00:19:37,540
helps our customers reduce their overall

391
00:19:35,200 --> 00:19:39,490
application risk so through

392
00:19:37,540 --> 00:19:41,649
understanding the risk and mitigating

393
00:19:39,490 --> 00:19:44,230
that risk we do that essentially three

394
00:19:41,650 --> 00:19:45,480
different ways through education so we

395
00:19:44,230 --> 00:19:47,230
have a pretty decent library

396
00:19:45,480 --> 00:19:49,570
computer-based training and

397
00:19:47,230 --> 00:19:52,530
instructor-led training we do it through

398
00:19:49,570 --> 00:19:59,399
assessment so my team does a lot of

399
00:19:52,530 --> 00:20:01,870
penetration testing mitigate

400
00:19:59,400 --> 00:20:03,190
vulnerabilities and discover those with

401
00:20:01,870 --> 00:20:06,010
us and help mitigate them

402
00:20:03,190 --> 00:20:09,220
and then we also help you become more

403
00:20:06,010 --> 00:20:11,680
mature in regards to security maturity

404
00:20:09,220 --> 00:20:14,260
and security process through process

405
00:20:11,680 --> 00:20:16,420
analysis and like sdlc gap analysis and

406
00:20:14,260 --> 00:20:19,300
things like that and so the hope is with

407
00:20:16,420 --> 00:20:22,720
those three things that an organization

408
00:20:19,300 --> 00:20:24,760
can learn what's wrong

409
00:20:22,720 --> 00:20:26,190
educate themselves to mitigate the

410
00:20:24,760 --> 00:20:28,420
vulnerabilities that they have and

411
00:20:26,190 --> 00:20:31,920
implements and process changes so that

412
00:20:28,420 --> 00:20:31,920
those things don't happen in the future

413
00:20:32,550 --> 00:20:47,190
yeah they can contact me by email just

414
00:20:37,060 --> 00:20:47,190
Joe and security yeah thanks

