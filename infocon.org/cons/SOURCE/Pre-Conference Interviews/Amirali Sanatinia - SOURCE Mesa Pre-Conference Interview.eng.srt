1
00:00:06,060 --> 00:00:09,940
hi this is rob machine with a source

2
00:00:08,109 --> 00:00:12,760
conference and I'm here with Alma

3
00:00:09,940 --> 00:00:15,160
Raleigh is sanity Nia who is a computer

4
00:00:12,760 --> 00:00:16,990
science PhD candidate at Northeastern

5
00:00:15,160 --> 00:00:19,210
University and he's going to be speaking

6
00:00:16,990 --> 00:00:22,269
at the source Mesa Phoenix conference on

7
00:00:19,210 --> 00:00:24,490
February 28th of March first and his

8
00:00:22,269 --> 00:00:25,448
talk is called common crypto pitfalls so

9
00:00:24,490 --> 00:00:27,038
we actually have somebody who knows

10
00:00:25,449 --> 00:00:28,570
about cryptography coming to talk to us

11
00:00:27,039 --> 00:00:30,849
about crypto so we're really excited

12
00:00:28,570 --> 00:00:34,210
about that though welcome to the show

13
00:00:30,849 --> 00:00:34,920
I'm rally thank you it's great to be

14
00:00:34,210 --> 00:00:39,160
here

15
00:00:34,920 --> 00:00:40,449
awesome so I was actually really

16
00:00:39,160 --> 00:00:42,849
interested when I saw the abstract

17
00:00:40,449 --> 00:00:44,289
because I've definitely over the years

18
00:00:42,850 --> 00:00:46,420
of dealing with developers and

19
00:00:44,289 --> 00:00:49,390
architects and you know different kinds

20
00:00:46,420 --> 00:00:50,679
of systems seeing all kinds of ways the

21
00:00:49,390 --> 00:00:53,379
laundry list of ways that people can

22
00:00:50,679 --> 00:00:54,969
screw up crypto so why don't you tell us

23
00:00:53,379 --> 00:00:56,890
a little bit about your talk and you

24
00:00:54,969 --> 00:00:59,530
know some of the just high-level some of

25
00:00:56,890 --> 00:01:01,239
the things that you address sure

26
00:00:59,530 --> 00:01:03,969
so in these starts we're going to look

27
00:01:01,239 --> 00:01:06,100
at some of the most common pitfalls and

28
00:01:03,969 --> 00:01:09,520
problems that people usually encounter

29
00:01:06,100 --> 00:01:12,280
then using cryptography teams such as

30
00:01:09,520 --> 00:01:13,929
for example their symmetric cryptography

31
00:01:12,280 --> 00:01:16,930
when they use the wrong mode of

32
00:01:13,930 --> 00:01:19,450
operation to more subtle things in their

33
00:01:16,930 --> 00:01:22,030
implementation and even touch a little

34
00:01:19,450 --> 00:01:24,759
bit on the side channel attacks so that

35
00:01:22,030 --> 00:01:27,070
would be the basic idea would be to look

36
00:01:24,759 --> 00:01:29,110
at the real world examples of programs

37
00:01:27,070 --> 00:01:32,199
that are being widely used by people

38
00:01:29,110 --> 00:01:34,960
around the world how they make mistakes

39
00:01:32,200 --> 00:01:40,329
in cryptography that ultimately tell

40
00:01:34,960 --> 00:01:42,820
them led to compromise right right so

41
00:01:40,329 --> 00:01:44,829
what I'm kind of getting from just what

42
00:01:42,820 --> 00:01:46,658
you said so far and what I've seen in

43
00:01:44,829 --> 00:01:48,579
the real world is it's not just a matter

44
00:01:46,659 --> 00:01:49,960
of people using the wrong algorithms or

45
00:01:48,579 --> 00:01:52,689
making their own stuff up which is

46
00:01:49,960 --> 00:01:54,460
obviously a big problem but even when

47
00:01:52,689 --> 00:01:56,408
they're using quote-unquote the you know

48
00:01:54,460 --> 00:02:00,070
the industry standard solutions they can

49
00:01:56,409 --> 00:02:02,710
still make mistakes right right because

50
00:02:00,070 --> 00:02:05,529
the compiler itself relies on some of

51
00:02:02,710 --> 00:02:07,600
the details of mathematics that there

52
00:02:05,530 --> 00:02:09,490
are certain assumptions that if you

53
00:02:07,600 --> 00:02:11,109
don't abide like that even though if you

54
00:02:09,490 --> 00:02:11,920
if you're out there for example if you

55
00:02:11,110 --> 00:02:15,610
use AES

56
00:02:11,920 --> 00:02:18,299
in a CBC mode and for example you're you

57
00:02:15,610 --> 00:02:20,850
use wrong kind easily you

58
00:02:18,300 --> 00:02:24,060
we use certain keys there it would lead

59
00:02:20,850 --> 00:02:26,579
to attack it's not only using the broken

60
00:02:24,060 --> 00:02:28,620
or broken algorithm such as there's that

61
00:02:26,580 --> 00:02:31,620
can come caused problems even using

62
00:02:28,620 --> 00:02:33,990
something at the cure Isaiah you can

63
00:02:31,620 --> 00:02:35,760
still use the wrong way for example you

64
00:02:33,990 --> 00:02:39,570
can shoot yourself even with the things

65
00:02:35,760 --> 00:02:42,060
that are correct right right so one of

66
00:02:39,570 --> 00:02:43,650
the themes that have that's come up in a

67
00:02:42,060 --> 00:02:47,190
lot of these conversations with some of

68
00:02:43,650 --> 00:02:48,420
the speakers is you know in large

69
00:02:47,190 --> 00:02:50,040
organizations where you have a lot of

70
00:02:48,420 --> 00:02:51,480
resources to throw at the problem you

71
00:02:50,040 --> 00:02:55,350
can just hire more people that you know

72
00:02:51,480 --> 00:02:56,910
go find some PhD in crypto or or hire

73
00:02:55,350 --> 00:02:59,640
some consultants or whatever else but

74
00:02:56,910 --> 00:03:00,960
the challenge seems to really come up

75
00:02:59,640 --> 00:03:02,730
with small and medium sized

76
00:03:00,960 --> 00:03:03,330
organizations that maybe don't have the

77
00:03:02,730 --> 00:03:06,060
resources

78
00:03:03,330 --> 00:03:08,010
what are those folks to us to do to to

79
00:03:06,060 --> 00:03:10,560
be able to implement crypto properly

80
00:03:08,010 --> 00:03:13,140
without having to incur massive expense

81
00:03:10,560 --> 00:03:15,960
is there any way they can do that so I

82
00:03:13,140 --> 00:03:18,329
think these days the certainly most

83
00:03:15,960 --> 00:03:20,730
programming languages they have secure

84
00:03:18,330 --> 00:03:22,830
and cryptography as part of the standard

85
00:03:20,730 --> 00:03:25,709
libraries and there are a lot of dudes

86
00:03:22,830 --> 00:03:27,990
rely versed third-party libraries one of

87
00:03:25,709 --> 00:03:30,600
the basic problems that we have is small

88
00:03:27,990 --> 00:03:33,950
or even medium-sized corporations is

89
00:03:30,600 --> 00:03:36,180
that maybe the lack of that basic

90
00:03:33,950 --> 00:03:38,310
introduction to foundations of

91
00:03:36,180 --> 00:03:40,050
cryptography that people for example

92
00:03:38,310 --> 00:03:42,240
they they know they they need to use AES

93
00:03:40,050 --> 00:03:44,400
but for something no don't know some of

94
00:03:42,240 --> 00:03:46,709
the details that have to get right to

95
00:03:44,400 --> 00:03:48,240
make it work correctly and those are the

96
00:03:46,709 --> 00:03:50,670
things that we can address like some

97
00:03:48,240 --> 00:03:52,260
basic introduction that what are the

98
00:03:50,670 --> 00:03:54,149
things that you can tackle if you

99
00:03:52,260 --> 00:03:56,489
consider or solve the pitfalls that you

100
00:03:54,150 --> 00:03:59,250
should avoid and by following these

101
00:03:56,490 --> 00:04:04,170
simple recipes you would be able to

102
00:03:59,250 --> 00:04:05,760
secure yourself got it so one of the

103
00:04:04,170 --> 00:04:07,589
funny things I've seen over the years is

104
00:04:05,760 --> 00:04:09,120
you know in the course of doing things

105
00:04:07,590 --> 00:04:12,959
like architecture design reviews and

106
00:04:09,120 --> 00:04:15,390
whatnot talking to people and finding

107
00:04:12,959 --> 00:04:17,880
out kind of where the the bodies are

108
00:04:15,390 --> 00:04:19,529
buried so to speak and realizing that oh

109
00:04:17,880 --> 00:04:22,680
they actually implement it you know some

110
00:04:19,529 --> 00:04:25,229
crazy you know rot13 algorithm will be

111
00:04:22,680 --> 00:04:27,960
made up for their ex or against some

112
00:04:25,230 --> 00:04:29,400
large string so they often the mindset

113
00:04:27,960 --> 00:04:31,950
is oh well if nobody else knows what I

114
00:04:29,400 --> 00:04:33,539
did how can anybody figure this out so

115
00:04:31,950 --> 00:04:35,159
what are some of your thoughts on people

116
00:04:33,540 --> 00:04:37,370
rolling their room crypto and you know

117
00:04:35,160 --> 00:04:42,090
some of the repercussions of that I

118
00:04:37,370 --> 00:04:47,070
think that's generally a very bad idea

119
00:04:42,090 --> 00:04:49,650
because you have people who expressed in

120
00:04:47,070 --> 00:04:53,159
the series of therapy they produce the

121
00:04:49,650 --> 00:04:55,979
design system and for many years other

122
00:04:53,160 --> 00:04:57,720
experts have been defended and trying to

123
00:04:55,980 --> 00:04:59,520
fight exploits and problem with that and

124
00:04:57,720 --> 00:05:02,310
at the end for example came up with the

125
00:04:59,520 --> 00:05:05,849
standardized encryption algorithm that

126
00:05:02,310 --> 00:05:08,780
is we have certain amount of trust in it

127
00:05:05,850 --> 00:05:11,610
they secure even 'but many of these

128
00:05:08,780 --> 00:05:13,530
secure cryptography algorithms their

129
00:05:11,610 --> 00:05:17,040
variants as secure at their first design

130
00:05:13,530 --> 00:05:18,630
so even the excerpts got it but it's not

131
00:05:17,040 --> 00:05:20,310
completely right that the first design

132
00:05:18,630 --> 00:05:22,260
then we wouldn't be able to expect

133
00:05:20,310 --> 00:05:23,850
ourselves to get it wrong right at the

134
00:05:22,260 --> 00:05:28,050
first iteration

135
00:05:23,850 --> 00:05:29,880
that's why generally it's not advice to

136
00:05:28,050 --> 00:05:34,500
rope your own crypto even if you have a

137
00:05:29,880 --> 00:05:35,580
PhD for exam in cryptography so you

138
00:05:34,500 --> 00:05:37,040
mentioned something in your abstract

139
00:05:35,580 --> 00:05:39,150
that I found interesting which is

140
00:05:37,040 --> 00:05:41,070
something I actually agree with but I

141
00:05:39,150 --> 00:05:42,840
want to hear your thoughts on it that

142
00:05:41,070 --> 00:05:44,490
bad crypto is actually worse than no

143
00:05:42,840 --> 00:05:47,719
crypto so I want to I'm kind of curious

144
00:05:44,490 --> 00:05:51,480
to hear what your thoughts are on that

145
00:05:47,720 --> 00:05:54,360
certainly so it's been do you think

146
00:05:51,480 --> 00:05:57,630
something is secure you you start to be

147
00:05:54,360 --> 00:05:58,950
more relaxed about it you want to deter

148
00:05:57,630 --> 00:06:01,140
you want to tear it up because they

149
00:05:58,950 --> 00:06:04,289
think ok Security's this cryptography

150
00:06:01,140 --> 00:06:05,729
then your threat model changes a little

151
00:06:04,290 --> 00:06:07,320
bit a lot of things that you wouldn't

152
00:06:05,730 --> 00:06:09,360
consider if you would consider your

153
00:06:07,320 --> 00:06:11,550
crest model because cryptography now

154
00:06:09,360 --> 00:06:14,160
you're not going to consider that so

155
00:06:11,550 --> 00:06:16,410
that's why when you have a wrong notion

156
00:06:14,160 --> 00:06:18,660
of trust can be even worse for example

157
00:06:16,410 --> 00:06:21,330
is if if you don't have a lock on your

158
00:06:18,660 --> 00:06:22,830
door you would be more careful about not

159
00:06:21,330 --> 00:06:25,979
telling people that you're not at home

160
00:06:22,830 --> 00:06:28,650
but if you have lock that opens very

161
00:06:25,980 --> 00:06:30,600
easily but you don't know that you might

162
00:06:28,650 --> 00:06:33,000
be locate my house is secured and if I

163
00:06:30,600 --> 00:06:35,940
tell people that I'm not I'm out of

164
00:06:33,000 --> 00:06:38,040
house no one out of my house

165
00:06:35,940 --> 00:06:40,200
no one can steal me but that's the thing

166
00:06:38,040 --> 00:06:43,530
that we want to avoid having this wrong

167
00:06:40,200 --> 00:06:44,969
feeling of security yeah it's definitely

168
00:06:43,530 --> 00:06:45,750
that's that's my thought you exactly

169
00:06:44,970 --> 00:06:47,460
that you

170
00:06:45,750 --> 00:06:48,900
the false sense of security that you get

171
00:06:47,460 --> 00:06:50,820
from thinking you're secure but you're

172
00:06:48,900 --> 00:06:53,099
really not because I've definitely seen

173
00:06:50,820 --> 00:06:55,440
people they'll just they'll pack a bunch

174
00:06:53,100 --> 00:06:56,820
of data into you know a field and

175
00:06:55,440 --> 00:06:58,410
they'll send it down to a browser and

176
00:06:56,820 --> 00:06:59,700
because they've obfuscated it in some

177
00:06:58,410 --> 00:07:01,830
way they're like up we're good nobody

178
00:06:59,700 --> 00:07:03,450
can see this it's like well just cuz you

179
00:07:01,830 --> 00:07:05,820
can't break it doesn't mean anybody else

180
00:07:03,450 --> 00:07:09,210
can't - so that's always an interesting

181
00:07:05,820 --> 00:07:10,440
guys look at it so cool awesome well I

182
00:07:09,210 --> 00:07:12,120
definitely look forward to continuing

183
00:07:10,440 --> 00:07:15,630
this conversation with you at the source

184
00:07:12,120 --> 00:07:18,450
conference and again that's on February

185
00:07:15,630 --> 00:07:21,330
28th of March first in Mesa in Arizona

186
00:07:18,450 --> 00:07:22,320
and if you're interested in crypto or

187
00:07:21,330 --> 00:07:23,430
want to hear some more about crypto

188
00:07:22,320 --> 00:07:25,440
pitfalls definitely stop by the

189
00:07:23,430 --> 00:07:26,720
conference and have a conversation with

190
00:07:25,440 --> 00:07:29,219
amirali

191
00:07:26,720 --> 00:07:32,070
thanks again for all today and

192
00:07:29,220 --> 00:07:33,690
opportunity to speak admits at source

193
00:07:32,070 --> 00:07:35,460
conference we're really looking forward

194
00:07:33,690 --> 00:07:37,890
to that great awesome

195
00:07:35,460 --> 00:07:39,239
well I'll see you there and this will be

196
00:07:37,890 --> 00:07:40,169
great time so it's gonna be a good event

197
00:07:39,240 --> 00:07:42,120
it's gonna be a lot of people there's

198
00:07:40,169 --> 00:07:43,919
gonna be fun so talk to you today

199
00:07:42,120 --> 00:07:47,120
looking forward to have a great day

200
00:07:43,919 --> 00:07:47,120
thanks you too fine

