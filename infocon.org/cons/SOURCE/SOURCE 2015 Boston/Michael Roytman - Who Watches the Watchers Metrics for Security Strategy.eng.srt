1
00:00:00,000 --> 00:00:02,480
cool

2
00:00:03,500 --> 00:00:07,319
so I don't actually want to talk about

3
00:00:05,490 --> 00:00:08,760
metrics we'll get to metrics and

4
00:00:07,319 --> 00:00:11,599
hopefully everybody will learn something

5
00:00:08,760 --> 00:00:14,460
about metrics but I want to talk about

6
00:00:11,599 --> 00:00:16,710
automation to begin with let's start

7
00:00:14,460 --> 00:00:19,050
with uber for a second

8
00:00:16,710 --> 00:00:21,480
how do Berg get here and why is it so

9
00:00:19,050 --> 00:00:23,130
successful I think that it's entirely

10
00:00:21,480 --> 00:00:25,590
possible for us to have predicted the

11
00:00:23,130 --> 00:00:27,299
rise of uber and my contention here

12
00:00:25,590 --> 00:00:30,359
which might be somewhat contentious is

13
00:00:27,300 --> 00:00:31,650
that that which makes over possible is

14
00:00:30,359 --> 00:00:33,600
the same thing that makes it really

15
00:00:31,650 --> 00:00:35,070
successful what makes uber possible is

16
00:00:33,600 --> 00:00:38,129
that they have location data about their

17
00:00:35,070 --> 00:00:40,290
users so maybe five or six years before

18
00:00:38,129 --> 00:00:41,820
uber came out people started loading

19
00:00:40,290 --> 00:00:43,710
mobile maps into their phones but they

20
00:00:41,820 --> 00:00:46,979
weren't sharing that location data as

21
00:00:43,710 --> 00:00:49,080
soon as the data set of users locations

22
00:00:46,979 --> 00:00:53,070
became available the opportunity for

23
00:00:49,080 --> 00:00:54,390
uber to be possible happened and as soon

24
00:00:53,070 --> 00:00:56,129
as that data set came online is when

25
00:00:54,390 --> 00:00:58,769
uber started to redefine metrics in the

26
00:00:56,129 --> 00:01:00,239
transportation industry so my contention

27
00:00:58,769 --> 00:01:02,610
here is it's not that

28
00:01:00,239 --> 00:01:04,798
Uber's you know customer service are you

29
00:01:02,610 --> 00:01:07,440
being able to request the car or them

30
00:01:04,799 --> 00:01:09,210
hiring drivers is important it's rather

31
00:01:07,440 --> 00:01:11,460
that they redefine what it means to be a

32
00:01:09,210 --> 00:01:14,820
profitable transportation provider so

33
00:01:11,460 --> 00:01:16,979
think about taxis in 2004 a vehicle

34
00:01:14,820 --> 00:01:18,300
routing was a pretty solved problem at

35
00:01:16,980 --> 00:01:20,790
that point you knew a whole bunch of

36
00:01:18,300 --> 00:01:24,120
metrics like average cost per hour of

37
00:01:20,790 --> 00:01:26,820
driver or fuel consumption or number of

38
00:01:24,120 --> 00:01:28,170
trips per day but the problem there was

39
00:01:26,820 --> 00:01:30,119
that those metrics still had an

40
00:01:28,170 --> 00:01:32,340
underlying uncertainty in the data set

41
00:01:30,120 --> 00:01:33,570
or it didn't have a data set about where

42
00:01:32,340 --> 00:01:35,820
the orders happened and where the

43
00:01:33,570 --> 00:01:36,960
destination of those orders was so to be

44
00:01:35,820 --> 00:01:38,580
good at the business one only had to

45
00:01:36,960 --> 00:01:40,649
create those cost per trip metrics and

46
00:01:38,580 --> 00:01:42,870
be pretty okay but whatever came along

47
00:01:40,650 --> 00:01:44,790
those metrics started to become pretty

48
00:01:42,870 --> 00:01:45,810
useless because there wasn't enough data

49
00:01:44,790 --> 00:01:47,520
to make them work and there was an

50
00:01:45,810 --> 00:01:49,500
entirely new data set about where users

51
00:01:47,520 --> 00:01:50,970
were and where they were going so good

52
00:01:49,500 --> 00:01:53,490
metric once you have the user's location

53
00:01:50,970 --> 00:01:55,760
become something like profitability per

54
00:01:53,490 --> 00:01:58,199
hour or profitability per mile or

55
00:01:55,760 --> 00:01:59,850
profitability per city because now all

56
00:01:58,200 --> 00:02:01,470
of a sudden you know how cities differ

57
00:01:59,850 --> 00:02:04,860
between each other which taxi drivers

58
00:02:01,470 --> 00:02:06,840
don't so they're defining a different

59
00:02:04,860 --> 00:02:08,068
metric is what made their entire

60
00:02:06,840 --> 00:02:09,149
business model possible but more

61
00:02:08,068 --> 00:02:10,589
importantly it's what makes them

62
00:02:09,149 --> 00:02:12,270
profitable it's what makes those old

63
00:02:10,590 --> 00:02:14,940
metrics the taxi drivers currently use

64
00:02:12,270 --> 00:02:16,000
completely obsolete so let's think about

65
00:02:14,940 --> 00:02:17,470
a different rubra

66
00:02:16,000 --> 00:02:19,420
trick and we'll also relate that to

67
00:02:17,470 --> 00:02:22,990
security later on what makes a good

68
00:02:19,420 --> 00:02:24,459
driver in the taxi world in the pre uber

69
00:02:22,990 --> 00:02:26,380
world you would think that a good driver

70
00:02:24,460 --> 00:02:27,730
is somebody who makes a lot of money but

71
00:02:26,380 --> 00:02:29,260
that's not true right customers are

72
00:02:27,730 --> 00:02:31,810
looking for safe efficient quick

73
00:02:29,260 --> 00:02:34,720
transportation that's efficient in all

74
00:02:31,810 --> 00:02:37,360
sorts of ways both route and you know do

75
00:02:34,720 --> 00:02:40,209
they give me water are they nice to me

76
00:02:37,360 --> 00:02:41,470
you burn out let's you rate your drivers

77
00:02:40,209 --> 00:02:43,150
and they combined the drivers

78
00:02:41,470 --> 00:02:45,040
profitability with the drivers rating

79
00:02:43,150 --> 00:02:47,530
model this is the same thing there was

80
00:02:45,040 --> 00:02:49,359
no feedback loop to the taxis all then

81
00:02:47,530 --> 00:02:50,950
they becomes a feedback loop to gauge

82
00:02:49,360 --> 00:02:52,360
your original metric that's an entirely

83
00:02:50,950 --> 00:02:54,369
different data set that redefines what

84
00:02:52,360 --> 00:02:56,530
the metric is so a metric like how many

85
00:02:54,370 --> 00:02:57,940
dollars per hours is this driver earn is

86
00:02:56,530 --> 00:02:59,350
great for a taxi company because they

87
00:02:57,940 --> 00:03:01,150
don't know anything about the consumer

88
00:02:59,350 --> 00:03:02,980
they don't collect data about them as

89
00:03:01,150 --> 00:03:04,989
soon as you start both the profitability

90
00:03:02,980 --> 00:03:07,690
for the metric for the driver changes

91
00:03:04,989 --> 00:03:09,220
and the metric for how good a driver is

92
00:03:07,690 --> 00:03:11,920
also changes because you're taking into

93
00:03:09,220 --> 00:03:14,470
account new data so that's what I'm here

94
00:03:11,920 --> 00:03:16,059
to talk about it's not about data it's

95
00:03:14,470 --> 00:03:18,489
not about uber it's not even about

96
00:03:16,060 --> 00:03:19,930
metrics it's actually about automation

97
00:03:18,489 --> 00:03:22,360
of business processes because that's

98
00:03:19,930 --> 00:03:25,540
what uber does it automates the thing

99
00:03:22,360 --> 00:03:27,400
that taxi drivers do most which is fine

100
00:03:25,540 --> 00:03:28,900
resolve the uncertainty in the market

101
00:03:27,400 --> 00:03:30,340
they resolved in certainty of where

102
00:03:28,900 --> 00:03:32,110
driver where customers are and where

103
00:03:30,340 --> 00:03:34,330
customers are going Boober automates

104
00:03:32,110 --> 00:03:35,860
that process that's their value add my

105
00:03:34,330 --> 00:03:37,330
contention is that that value is only

106
00:03:35,860 --> 00:03:38,980
possible if you have defined concrete

107
00:03:37,330 --> 00:03:40,630
metrics that allow you to automate that

108
00:03:38,980 --> 00:03:42,488
process and those metrics are only

109
00:03:40,630 --> 00:03:43,870
possible if you have defined concrete

110
00:03:42,489 --> 00:03:45,910
data that allows you to design that

111
00:03:43,870 --> 00:03:49,090
metric to begin with so let's relate all

112
00:03:45,910 --> 00:03:50,829
that to security attackers are better at

113
00:03:49,090 --> 00:03:52,360
automation than we are they have better

114
00:03:50,829 --> 00:03:55,120
defined metrics and they have better

115
00:03:52,360 --> 00:03:56,650
data about us than we have about them so

116
00:03:55,120 --> 00:03:58,799
the reason why there's a gap people

117
00:03:56,650 --> 00:04:01,209
always talk about the gap between

118
00:03:58,799 --> 00:04:03,489
exploits coming out and us patching

119
00:04:01,209 --> 00:04:05,290
things or the gap between successful

120
00:04:03,489 --> 00:04:07,299
attacks happening and the vulnerability

121
00:04:05,290 --> 00:04:09,010
cycle half-life the reason why that's

122
00:04:07,299 --> 00:04:11,260
true is because attackers are just

123
00:04:09,010 --> 00:04:13,328
better at automating things than us in a

124
00:04:11,260 --> 00:04:15,160
game theoretic sense they don't have to

125
00:04:13,329 --> 00:04:16,540
shift their strategy as often as we have

126
00:04:15,160 --> 00:04:20,290
to shift our strategy because they have

127
00:04:16,540 --> 00:04:21,940
more data about us moreover their costs

128
00:04:20,290 --> 00:04:23,440
are lower so for them to switch

129
00:04:21,940 --> 00:04:25,840
something for them to automate something

130
00:04:23,440 --> 00:04:27,340
is much easier since they can attack the

131
00:04:25,840 --> 00:04:29,500
entirety of the field they can create a

132
00:04:27,340 --> 00:04:31,750
targeted attack they can create a

133
00:04:29,500 --> 00:04:33,220
Kakinada targeted attack and can scan

134
00:04:31,750 --> 00:04:34,960
the entire internet for it to figure out

135
00:04:33,220 --> 00:04:37,000
if it works and then reassess their

136
00:04:34,960 --> 00:04:38,710
situation we can't do that we can't scan

137
00:04:37,000 --> 00:04:40,060
the entire universe of attackers to

138
00:04:38,710 --> 00:04:44,680
figure out what the average strategy is

139
00:04:40,060 --> 00:04:46,540
but we can try to approximate it so one

140
00:04:44,680 --> 00:04:49,480
of the I can make a lot of claims about

141
00:04:46,540 --> 00:04:51,670
attackers but my warrant for this is

142
00:04:49,480 --> 00:04:54,580
that there are more non targeted attacks

143
00:04:51,670 --> 00:04:56,500
being successful this is a 2014 data set

144
00:04:54,580 --> 00:04:58,030
then there are targeted attacks being

145
00:04:56,500 --> 00:05:00,280
successful you hear about the big

146
00:04:58,030 --> 00:05:01,900
breaches but what I see and I monitor

147
00:05:00,280 --> 00:05:04,900
about nine different threat feeds at

148
00:05:01,900 --> 00:05:06,219
this point and I look for successful

149
00:05:04,900 --> 00:05:10,359
exploitation of CVEs

150
00:05:06,220 --> 00:05:11,860
that is AC ve existed a vulnerability

151
00:05:10,360 --> 00:05:14,020
existed on a system there was no

152
00:05:11,860 --> 00:05:15,820
mitigating control and a success an

153
00:05:14,020 --> 00:05:17,020
exploit was launched against that CV at

154
00:05:15,820 --> 00:05:18,880
the same time so that's a successful

155
00:05:17,020 --> 00:05:20,560
technical exploitation maybe no breach

156
00:05:18,880 --> 00:05:22,300
event occurred when you monitor that

157
00:05:20,560 --> 00:05:23,530
over time and when you monitor that

158
00:05:22,300 --> 00:05:25,120
across a couple of threat feeds you

159
00:05:23,530 --> 00:05:27,070
start to notice that there are only a

160
00:05:25,120 --> 00:05:29,440
couple of CVEs throughout all of 2014

161
00:05:27,070 --> 00:05:30,880
that are responsible for a majority of

162
00:05:29,440 --> 00:05:34,540
the traffic it follows a power law

163
00:05:30,880 --> 00:05:36,490
scaling phenomenon and moreover this is

164
00:05:34,540 --> 00:05:37,479
true if you break the data side down any

165
00:05:36,490 --> 00:05:39,430
which way it's scale and very

166
00:05:37,479 --> 00:05:41,800
incompletely so by quarter the same is

167
00:05:39,430 --> 00:05:43,720
true an interesting note here is that a

168
00:05:41,800 --> 00:05:45,220
lot of these are very old CVEs but

169
00:05:43,720 --> 00:05:47,860
that's just an aside my point here is

170
00:05:45,220 --> 00:05:49,960
that if it is true that the matte mass

171
00:05:47,860 --> 00:05:51,460
major volume of breach traffic is

172
00:05:49,960 --> 00:05:52,239
concentrated and only a few of those

173
00:05:51,460 --> 00:05:54,280
CVEs

174
00:05:52,240 --> 00:05:55,930
it must also be true that those attacks

175
00:05:54,280 --> 00:05:58,479
are automated I doubt anybody is

176
00:05:55,930 --> 00:06:00,850
manually firing off two million attacks

177
00:05:58,479 --> 00:06:04,750
against two million different targets or

178
00:06:00,850 --> 00:06:06,820
assets so if that's true and we have to

179
00:06:04,750 --> 00:06:08,919
patch vulnerabilities in some kind of

180
00:06:06,820 --> 00:06:10,440
automated way or patch vulnerabilities

181
00:06:08,919 --> 00:06:12,700
that are being automated by attackers

182
00:06:10,440 --> 00:06:14,169
that means that attackers are already

183
00:06:12,700 --> 00:06:15,760
ahead of us they have already automated

184
00:06:14,169 --> 00:06:17,260
something before we have created a

185
00:06:15,760 --> 00:06:19,810
process for dealing with that sort of

186
00:06:17,260 --> 00:06:22,620
that automation so what we need is we

187
00:06:19,810 --> 00:06:22,620
need better automation

188
00:06:23,040 --> 00:06:28,170
but where do we need the automation is a

189
00:06:26,700 --> 00:06:29,400
good question because there are some

190
00:06:28,170 --> 00:06:31,080
things that can't be automated security

191
00:06:29,400 --> 00:06:33,570
vulnerability assessments can certainly

192
00:06:31,080 --> 00:06:34,740
be automated Incident Response I don't

193
00:06:33,570 --> 00:06:36,090
have a good feel for it I don't work on

194
00:06:34,740 --> 00:06:37,950
that but it seems to me less intuitive

195
00:06:36,090 --> 00:06:38,909
but that can be automated I can talk to

196
00:06:37,950 --> 00:06:41,400
you about vulnerability management

197
00:06:38,910 --> 00:06:42,870
because that's what I'm in her

198
00:06:41,400 --> 00:06:44,520
vulnerability management has pretty

199
00:06:42,870 --> 00:06:47,730
automated vulnerability discovery and

200
00:06:44,520 --> 00:06:50,039
automated I mean we don't have a choice

201
00:06:47,730 --> 00:06:52,920
so we have automated the processes that

202
00:06:50,040 --> 00:06:54,480
exist before nvd and mitre create our

203
00:06:52,920 --> 00:06:56,190
CVS create our vulnerability types

204
00:06:54,480 --> 00:06:58,410
scanners pick those up and that process

205
00:06:56,190 --> 00:07:00,120
is a black box for us we've automated

206
00:06:58,410 --> 00:07:01,770
the process of getting that information

207
00:07:00,120 --> 00:07:03,120
and getting that data you can go out and

208
00:07:01,770 --> 00:07:05,039
you can buy some other data but the

209
00:07:03,120 --> 00:07:06,540
process is much the same that somebody

210
00:07:05,040 --> 00:07:07,950
else creates that data set and at the

211
00:07:06,540 --> 00:07:11,010
point of contact that you have with that

212
00:07:07,950 --> 00:07:12,810
that line is automated scanning however

213
00:07:11,010 --> 00:07:14,099
is not that automatic you might have

214
00:07:12,810 --> 00:07:15,660
scanners that can be fired off

215
00:07:14,100 --> 00:07:17,640
automatically but most enterprises I

216
00:07:15,660 --> 00:07:19,410
work with never actually automate their

217
00:07:17,640 --> 00:07:20,940
scanners or if they do it's for certain

218
00:07:19,410 --> 00:07:22,650
subsets that don't take down business

219
00:07:20,940 --> 00:07:24,960
critical processes so we're getting

220
00:07:22,650 --> 00:07:26,669
there third intelligence is incredibly

221
00:07:24,960 --> 00:07:27,870
manual the providers are working with

222
00:07:26,670 --> 00:07:29,220
for the most part to gather their threat

223
00:07:27,870 --> 00:07:30,900
intelligence by having really smart

224
00:07:29,220 --> 00:07:32,850
people do the kinds of things that

225
00:07:30,900 --> 00:07:34,530
targeted attackers do that is find out

226
00:07:32,850 --> 00:07:36,270
where the attacks are happening how

227
00:07:34,530 --> 00:07:40,409
they're targeted give them aggregating

228
00:07:36,270 --> 00:07:42,359
those datasets there are forms of manual

229
00:07:40,410 --> 00:07:44,490
ish threat intelligence as well in that

230
00:07:42,360 --> 00:07:46,020
we write signatures for specific attacks

231
00:07:44,490 --> 00:07:47,610
or rewrites of interest for exploits let

232
00:07:46,020 --> 00:07:49,500
IDs pick them up look at the breech

233
00:07:47,610 --> 00:07:51,360
traffic of that that's what I do as well

234
00:07:49,500 --> 00:07:53,700
but in reality those data sets are

235
00:07:51,360 --> 00:07:55,050
incredibly biased because to write the

236
00:07:53,700 --> 00:07:57,900
signature means that the exploit has

237
00:07:55,050 --> 00:08:00,380
already occurred our vulnerabilities

238
00:07:57,900 --> 00:08:02,909
scoring is incredibly manual as well and

239
00:08:00,380 --> 00:08:05,070
Steve will know all about that you have

240
00:08:02,910 --> 00:08:06,450
to actually go in and have somebody look

241
00:08:05,070 --> 00:08:08,040
at the vulnerability itself look at the

242
00:08:06,450 --> 00:08:10,440
data about it to create a score and

243
00:08:08,040 --> 00:08:12,510
that's only the score that nvd provides

244
00:08:10,440 --> 00:08:14,730
you with in that they describe some

245
00:08:12,510 --> 00:08:15,599
elements about the vulnerability if you

246
00:08:14,730 --> 00:08:16,950
want to score alone everybody

247
00:08:15,600 --> 00:08:19,530
specifically to your environment that's

248
00:08:16,950 --> 00:08:22,050
an even more manual process and most

249
00:08:19,530 --> 00:08:24,119
importantly remediation itself or

250
00:08:22,050 --> 00:08:25,380
prioritization of actions that is the

251
00:08:24,120 --> 00:08:26,970
decision science which is their whole

252
00:08:25,380 --> 00:08:30,990
reason why we construct metrics is

253
00:08:26,970 --> 00:08:33,990
incredibly manual as well so why is it

254
00:08:30,990 --> 00:08:35,669
so manual it's because we don't have the

255
00:08:33,990 --> 00:08:36,840
data to automate it it's because the

256
00:08:35,669 --> 00:08:39,329
google maps of

257
00:08:36,840 --> 00:08:40,860
uber equivalent doesn't yet exist we

258
00:08:39,330 --> 00:08:42,990
need better base rates for exploitation

259
00:08:40,860 --> 00:08:45,180
of vulnerabilities we need better

260
00:08:42,990 --> 00:08:47,160
exploit availability data currently all

261
00:08:45,180 --> 00:08:48,719
we've got is Metasploit and exploit DB

262
00:08:47,160 --> 00:08:50,640
and whenever I want to look at something

263
00:08:48,720 --> 00:08:52,500
like a blackhat exploit kit I'm crawling

264
00:08:50,640 --> 00:08:54,210
Russian forums to look for CV

265
00:08:52,500 --> 00:08:56,910
enumerators which is not how that should

266
00:08:54,210 --> 00:08:59,400
be done we need better vulnerability

267
00:08:56,910 --> 00:09:01,050
trend data so to say that Microsoft

268
00:08:59,400 --> 00:09:03,360
Patch Tuesday is really important is one

269
00:09:01,050 --> 00:09:05,400
thing but when Microsoft releases those

270
00:09:03,360 --> 00:09:07,260
patches to say this is a target of

271
00:09:05,400 --> 00:09:08,610
opportunity because it affects 92% of

272
00:09:07,260 --> 00:09:10,080
our systems that are currently live and

273
00:09:08,610 --> 00:09:11,790
deployed would be a much more useful

274
00:09:10,080 --> 00:09:14,460
metric for me to prioritize whether or

275
00:09:11,790 --> 00:09:16,500
not I should fix that vulnerability we

276
00:09:14,460 --> 00:09:18,450
need better breach data to know how the

277
00:09:16,500 --> 00:09:20,670
breach occurred not just what the impact

278
00:09:18,450 --> 00:09:22,140
of that breach was so I collect

279
00:09:20,670 --> 00:09:24,569
technical breach data but it's not

280
00:09:22,140 --> 00:09:26,310
impactful breach data somewhere in the

281
00:09:24,570 --> 00:09:27,990
middle exists a world where we have dbi

282
00:09:26,310 --> 00:09:30,209
our data about the impact of those

283
00:09:27,990 --> 00:09:31,350
breaches we have my data about the

284
00:09:30,210 --> 00:09:33,360
successful exploitation of

285
00:09:31,350 --> 00:09:37,710
vulnerabilities and we can tie the two

286
00:09:33,360 --> 00:09:39,150
together to create better metrics so

287
00:09:37,710 --> 00:09:41,670
sometimes we make bad decisions and

288
00:09:39,150 --> 00:09:43,020
sometimes we have bad metrics and I

289
00:09:41,670 --> 00:09:44,939
think that those two are equivalent

290
00:09:43,020 --> 00:09:46,500
statements it's because whether you

291
00:09:44,940 --> 00:09:48,510
explicitly define them in your

292
00:09:46,500 --> 00:09:51,240
organization or not metrics are just

293
00:09:48,510 --> 00:09:52,830
decision support and my whole argument

294
00:09:51,240 --> 00:09:54,570
as to why we need to automate better and

295
00:09:52,830 --> 00:09:56,370
why we need to define stable metrics to

296
00:09:54,570 --> 00:09:58,380
automate better is because good metrics

297
00:09:56,370 --> 00:10:00,210
are nothing but objective functions for

298
00:09:58,380 --> 00:10:01,710
automation think back to any industry

299
00:10:00,210 --> 00:10:05,010
that has automated anything in the past

300
00:10:01,710 --> 00:10:06,900
all the way back to Ford's assembly line

301
00:10:05,010 --> 00:10:08,340
the only reason those things are

302
00:10:06,900 --> 00:10:10,860
possible is because there becomes a

303
00:10:08,340 --> 00:10:13,170
salient field and a salient stable model

304
00:10:10,860 --> 00:10:14,520
of data that then you can mine metrics

305
00:10:13,170 --> 00:10:16,020
about or you can define metrics that

306
00:10:14,520 --> 00:10:18,120
define success in that field based on

307
00:10:16,020 --> 00:10:19,740
the data and once you have that you can

308
00:10:18,120 --> 00:10:21,210
start to define which processes are

309
00:10:19,740 --> 00:10:23,580
automatable and which processes should

310
00:10:21,210 --> 00:10:25,350
be automatable in the Henry Ford example

311
00:10:23,580 --> 00:10:27,060
it's very simple it was assembly time

312
00:10:25,350 --> 00:10:28,950
per car but until he had assembled

313
00:10:27,060 --> 00:10:30,599
enough cars and measured his workers

314
00:10:28,950 --> 00:10:32,010
assembly rates he couldn't even define

315
00:10:30,600 --> 00:10:33,990
the metric of assembly time per car

316
00:10:32,010 --> 00:10:36,860
because a car was a mythical being that

317
00:10:33,990 --> 00:10:39,270
you would create by machining some parts

318
00:10:36,860 --> 00:10:41,220
similarly in security when we want to

319
00:10:39,270 --> 00:10:42,990
make a prioritization decision we need

320
00:10:41,220 --> 00:10:45,990
to be able to understand what data data

321
00:10:42,990 --> 00:10:48,750
sets define priority for us and what

322
00:10:45,990 --> 00:10:50,240
makes a metric good in turn is a

323
00:10:48,750 --> 00:10:52,670
question that we'll explore for

324
00:10:50,240 --> 00:10:54,170
next for the rest of the talk and by no

325
00:10:52,670 --> 00:10:55,849
means am I the authority and what makes

326
00:10:54,170 --> 00:10:57,979
a metric good at the end of this I've

327
00:10:55,850 --> 00:10:59,779
got a really extensive reference list so

328
00:10:57,980 --> 00:11:02,270
that people can dive in further but I

329
00:10:59,779 --> 00:11:03,830
think I have some ideas for necessary if

330
00:11:02,270 --> 00:11:05,630
insufficient criteria for what can make

331
00:11:03,830 --> 00:11:08,779
a metric good let's start with an

332
00:11:05,630 --> 00:11:10,970
example people use CVS s as a metric for

333
00:11:08,779 --> 00:11:12,500
a remediation prioritization but it's

334
00:11:10,970 --> 00:11:14,180
not that it's a description of the

335
00:11:12,500 --> 00:11:15,980
vulnerability itself and the score

336
00:11:14,180 --> 00:11:19,399
shouldn't be taken as such so when you

337
00:11:15,980 --> 00:11:22,070
do so here's what happens a CBS s 10

338
00:11:19,399 --> 00:11:23,690
which is shell-shocked has those

339
00:11:22,070 --> 00:11:25,459
exploitation z' which what you're seeing

340
00:11:23,690 --> 00:11:26,720
on this graph right now the size of the

341
00:11:25,459 --> 00:11:28,550
bubble is the number of number of

342
00:11:26,720 --> 00:11:30,260
successful exploitation zin the hour

343
00:11:28,550 --> 00:11:32,149
when that data point is recorded and

344
00:11:30,260 --> 00:11:34,010
this starts from the release of

345
00:11:32,149 --> 00:11:35,709
heartbleed all the way up to until I see

346
00:11:34,010 --> 00:11:38,689
some shell-shocked expectations and

347
00:11:35,709 --> 00:11:40,250
hardly it is a CVS s5 vulnerability that

348
00:11:38,690 --> 00:11:43,040
is successfully exploited time and time

349
00:11:40,250 --> 00:11:45,290
again and the rate ramps up over time so

350
00:11:43,040 --> 00:11:47,149
what does this tell you this tells you

351
00:11:45,290 --> 00:11:49,010
that the CBS s10 score is not

352
00:11:47,149 --> 00:11:51,520
descriptive of the amount of successful

353
00:11:49,010 --> 00:11:53,810
exploitation zhan that vulnerability but

354
00:11:51,520 --> 00:11:55,790
it's not trying to do that so it's not a

355
00:11:53,810 --> 00:11:57,680
good metric for measuring that moreover

356
00:11:55,790 --> 00:11:59,899
if you zoom out a little bit further

357
00:11:57,680 --> 00:12:01,849
poodle is a CBS s 4.3 which has

358
00:11:59,899 --> 00:12:03,320
substantially more successful

359
00:12:01,850 --> 00:12:06,680
exploitation x' on it than either one of

360
00:12:03,320 --> 00:12:09,279
those so another kind of gut check feel

361
00:12:06,680 --> 00:12:11,599
as to what that metric is describing and

362
00:12:09,279 --> 00:12:13,130
if you zoom out even further and take a

363
00:12:11,600 --> 00:12:15,980
look at some random vulnerabilities that

364
00:12:13,130 --> 00:12:18,980
are all scored CBS s 5 or below we can

365
00:12:15,980 --> 00:12:20,870
see that some see ve for Windows 2000

366
00:12:18,980 --> 00:12:23,839
and I think it effects NT as well from

367
00:12:20,870 --> 00:12:25,430
2001 sees orders of magnitude more

368
00:12:23,839 --> 00:12:28,579
successful exploitations than any of

369
00:12:25,430 --> 00:12:29,719
those but its score is the same 5 so

370
00:12:28,579 --> 00:12:34,000
what are we learning

371
00:12:29,720 --> 00:12:34,000
it's that cbss isn't descriptive yes

372
00:12:35,280 --> 00:12:41,339
so it comes from the alienvault thread

373
00:12:38,140 --> 00:12:45,220
exchange dell counter threat unit i

374
00:12:41,340 --> 00:12:47,350
defender sinai defense sans actually

375
00:12:45,220 --> 00:12:50,260
releases a bunch of on a subpage XML

376
00:12:47,350 --> 00:12:51,940
feed you can get to if you go to risk

377
00:12:50,260 --> 00:12:53,880
that io it lists all of our data sources

378
00:12:51,940 --> 00:12:56,380
but the successful exploitation data is

379
00:12:53,880 --> 00:12:57,880
an indicator of compromise was detected

380
00:12:56,380 --> 00:13:01,390
on a system that is linked to that c ve

381
00:12:57,880 --> 00:13:03,550
or exploit fired off open vulnerability

382
00:13:01,390 --> 00:13:09,640
no mitigating at the same time stamp so

383
00:13:03,550 --> 00:13:11,530
it's both ids logs and ioc logs so this

384
00:13:09,640 --> 00:13:13,780
comes from about fifty thousand

385
00:13:11,530 --> 00:13:16,060
businesses right now fifty thousand

386
00:13:13,780 --> 00:13:21,579
organizations and tracking I think

387
00:13:16,060 --> 00:13:23,709
around 4 million assets so point here

388
00:13:21,580 --> 00:13:25,450
being that it's very clear that the

389
00:13:23,710 --> 00:13:27,460
score is not descriptive of successful

390
00:13:25,450 --> 00:13:28,930
exploitation and if that is a data set

391
00:13:27,460 --> 00:13:30,340
that is important to you guys it's

392
00:13:28,930 --> 00:13:32,349
important to me it's the data set I work

393
00:13:30,340 --> 00:13:34,720
with it's clear that the score is not

394
00:13:32,350 --> 00:13:37,690
descriptive of that but CBS s is not the

395
00:13:34,720 --> 00:13:39,940
problem because CBS s itself has a whole

396
00:13:37,690 --> 00:13:44,830
bunch of sub metrics ie access

397
00:13:39,940 --> 00:13:46,150
complexity or X or local what is that

398
00:13:44,830 --> 00:13:48,970
where is it where it's executed from

399
00:13:46,150 --> 00:13:50,260
local or remote those are good metrics

400
00:13:48,970 --> 00:13:52,270
those are metrics that are descriptive

401
00:13:50,260 --> 00:13:54,250
of the vulnerability and will prove why

402
00:13:52,270 --> 00:13:56,530
they're good also with these criteria

403
00:13:54,250 --> 00:13:58,480
that all enumerate but CB SS for

404
00:13:56,530 --> 00:14:00,910
prioritization is the systemic problem

405
00:13:58,480 --> 00:14:03,970
so if I look at CB SS as a predictor of

406
00:14:00,910 --> 00:14:06,579
breach volume on a particular CBE what I

407
00:14:03,970 --> 00:14:08,080
find and this is a regressive model that

408
00:14:06,580 --> 00:14:10,240
tries to identify a score that is

409
00:14:08,080 --> 00:14:11,740
indicative of a bucket I've defined and

410
00:14:10,240 --> 00:14:15,070
the buckets I've defined are really

411
00:14:11,740 --> 00:14:18,790
crazy they're like 1 to 2 2 to 8 8 to

412
00:14:15,070 --> 00:14:21,100
135 and 135 to a million successful

413
00:14:18,790 --> 00:14:22,689
exploitation zhan that CVE type the

414
00:14:21,100 --> 00:14:24,700
difference in the score the best

415
00:14:22,690 --> 00:14:27,850
predicts that is nothing it's like

416
00:14:24,700 --> 00:14:29,590
points 0 6 with a really high confidence

417
00:14:27,850 --> 00:14:31,900
interval and what that tells you is that

418
00:14:29,590 --> 00:14:34,150
at the far end of the scale in the 8's

419
00:14:31,900 --> 00:14:35,709
9s and 10s CB SS is a pretty good

420
00:14:34,150 --> 00:14:38,770
predictor of breach traffic but

421
00:14:35,710 --> 00:14:40,420
otherwise nothing up not much else is

422
00:14:38,770 --> 00:14:41,829
helping you make a decision moreover

423
00:14:40,420 --> 00:14:43,930
what it tells you is that you can't make

424
00:14:41,830 --> 00:14:46,600
a granular decision granular decision

425
00:14:43,930 --> 00:14:47,109
like the difference between a CB SS 7 &

426
00:14:46,600 --> 00:14:48,519
8

427
00:14:47,110 --> 00:14:50,050
and have that be meaningful in

428
00:14:48,519 --> 00:14:51,459
predicting breach volume and I don't

429
00:14:50,050 --> 00:14:52,959
think it was ever intended to do that as

430
00:14:51,459 --> 00:14:55,359
well I think there's like two possible

431
00:14:52,959 --> 00:14:56,920
scores between seven and eight but

432
00:14:55,360 --> 00:14:58,540
people do this all the time and making

433
00:14:56,920 --> 00:14:59,890
their criticality cut off a seven or

434
00:14:58,540 --> 00:15:01,870
making their criticality cut off an

435
00:14:59,890 --> 00:15:04,079
eight when so the underlying phenomenon

436
00:15:01,870 --> 00:15:08,290
that causes this is that attackers

437
00:15:04,079 --> 00:15:10,300
changes their tactics almost daily what

438
00:15:08,290 --> 00:15:12,430
you're seeing here is that same data

439
00:15:10,300 --> 00:15:13,029
that I showed you before of all those

440
00:15:12,430 --> 00:15:15,040
CVEs

441
00:15:13,029 --> 00:15:17,470
but now it's broken up into week-long

442
00:15:15,040 --> 00:15:19,000
buckets and shifts week over week so on

443
00:15:17,470 --> 00:15:20,740
the right hand side you see attacks that

444
00:15:19,000 --> 00:15:22,269
happen a lot during the week in the

445
00:15:20,740 --> 00:15:24,220
hundreds of thousands on the left hand

446
00:15:22,269 --> 00:15:25,510
side you see attacks that are low volume

447
00:15:24,220 --> 00:15:27,700
and targeted maybe they're happening

448
00:15:25,510 --> 00:15:28,630
once or twice in the week each point is

449
00:15:27,700 --> 00:15:32,230
a different CVE

450
00:15:28,630 --> 00:15:35,860
the yellows are West IDs they're Web

451
00:15:32,230 --> 00:15:37,300
Application Firewall logs and week over

452
00:15:35,860 --> 00:15:38,829
week as a chips you can see whether the

453
00:15:37,300 --> 00:15:40,359
volume is increasing or decreasing it's

454
00:15:38,829 --> 00:15:42,069
logarithmic ly scaled so the stuff at

455
00:15:40,360 --> 00:15:44,230
the top is stuff you haven't seen before

456
00:15:42,070 --> 00:15:45,700
in this week and the stuff at the bottom

457
00:15:44,230 --> 00:15:48,070
of stuff that existed last week but does

458
00:15:45,700 --> 00:15:50,529
it exist this week and so I think this

459
00:15:48,070 --> 00:15:52,990
is doing like 10 or 15 weeks throughout

460
00:15:50,529 --> 00:15:55,329
the end of 2014 and you can clearly see

461
00:15:52,990 --> 00:15:57,519
that no matter what you say the tactics

462
00:15:55,329 --> 00:15:59,800
which attackers take and so regardless

463
00:15:57,519 --> 00:16:01,240
of the biases in my data set what I'm

464
00:15:59,800 --> 00:16:02,680
measuring is stable it would seem that

465
00:16:01,240 --> 00:16:04,000
if those attacks are successful

466
00:16:02,680 --> 00:16:05,800
attackers will continue doing the same

467
00:16:04,000 --> 00:16:06,880
things but that's not true different

468
00:16:05,800 --> 00:16:08,680
attackers are attacking those same

469
00:16:06,880 --> 00:16:10,329
assets they're using different CVS to

470
00:16:08,680 --> 00:16:11,979
target them and the things of high

471
00:16:10,329 --> 00:16:13,660
volume generally stay in the high volume

472
00:16:11,980 --> 00:16:15,519
side in that they are the automation

473
00:16:13,660 --> 00:16:17,199
that I'm talking about the things of a

474
00:16:15,519 --> 00:16:18,220
low volume have crazy variability

475
00:16:17,199 --> 00:16:20,380
between them that are shifting all the

476
00:16:18,220 --> 00:16:21,480
time because target attacks are not all

477
00:16:20,380 --> 00:16:23,890
that predictable

478
00:16:21,480 --> 00:16:26,709
so what defines a good metric that can

479
00:16:23,890 --> 00:16:28,870
capture that kind of behavior it's good

480
00:16:26,709 --> 00:16:31,000
data so let's take a look at that type

481
00:16:28,870 --> 00:16:32,680
of data and how we can define what makes

482
00:16:31,000 --> 00:16:36,070
a good metric for predicting

483
00:16:32,680 --> 00:16:38,680
vulnerability prioritization I give you

484
00:16:36,070 --> 00:16:40,870
two systems call them systems each one

485
00:16:38,680 --> 00:16:42,699
has only one asset in it and each one

486
00:16:40,870 --> 00:16:45,490
has one mitigating control in front of

487
00:16:42,699 --> 00:16:47,589
it call it the same exact firewall one

488
00:16:45,490 --> 00:16:48,940
is protecting a thousand dollars worth

489
00:16:47,589 --> 00:16:51,190
of gremlins the other one is protecting

490
00:16:48,940 --> 00:16:54,070
a million dollars worth of widgets and

491
00:16:51,190 --> 00:16:56,649
so if I tell you consider system a and

492
00:16:54,070 --> 00:16:58,270
system B same mitigating control

493
00:16:56,649 --> 00:17:00,630
protects them which system is more

494
00:16:58,270 --> 00:17:00,630
secure

495
00:17:00,730 --> 00:17:07,919
throw out an answer anyone

496
00:17:04,500 --> 00:17:09,359
right so the system one is more secure

497
00:17:07,919 --> 00:17:10,949
because there's less value at risk here

498
00:17:09,359 --> 00:17:12,059
and there are two ways of looking at

499
00:17:10,949 --> 00:17:13,709
this problem there's two ways of

500
00:17:12,059 --> 00:17:15,510
drafting metrics the first is the way

501
00:17:13,709 --> 00:17:18,059
that anybody in security would do it by

502
00:17:15,510 --> 00:17:19,650
saying there's less at risk here asset

503
00:17:18,059 --> 00:17:21,629
two is a bigger target of opportunity

504
00:17:19,650 --> 00:17:22,890
so asset 2 is more secure the second way

505
00:17:21,630 --> 00:17:24,059
is to say they have the same exact

506
00:17:22,890 --> 00:17:26,880
mitigating control so they must be

507
00:17:24,059 --> 00:17:29,000
equally secure and both I contend are

508
00:17:26,880 --> 00:17:31,799
actually valuable ways of looking at it

509
00:17:29,000 --> 00:17:33,150
the first way of looking at it is one

510
00:17:31,799 --> 00:17:35,190
that takes into account the threat

511
00:17:33,150 --> 00:17:37,470
environment when crafting the metric so

512
00:17:35,190 --> 00:17:38,820
you are saying that what the attackers

513
00:17:37,470 --> 00:17:40,770
are doing should be included in my

514
00:17:38,820 --> 00:17:43,470
metric that's called the type 2 metric

515
00:17:40,770 --> 00:17:45,418
the first metric is a type 1 metric in

516
00:17:43,470 --> 00:17:46,980
that it says it's a controlled

517
00:17:45,419 --> 00:17:48,870
experiment metric it ignores the threat

518
00:17:46,980 --> 00:17:51,299
environment to generate a base rate of

519
00:17:48,870 --> 00:17:54,059
to compare the threat environment metric

520
00:17:51,299 --> 00:17:55,559
to and so my contention here is that you

521
00:17:54,059 --> 00:17:57,750
need both types of metrics when people

522
00:17:55,559 --> 00:17:59,010
create a phishing email and they do a

523
00:17:57,750 --> 00:18:00,990
craft a phishing email and send it out

524
00:17:59,010 --> 00:18:03,059
to their entire enterprise the success

525
00:18:00,990 --> 00:18:04,530
click-through rate of that email is not

526
00:18:03,059 --> 00:18:06,570
indicative of the third environment at

527
00:18:04,530 --> 00:18:08,190
all but it generates a base rate for you

528
00:18:06,570 --> 00:18:09,510
to then later be able to assess how

529
00:18:08,190 --> 00:18:11,070
phishing emails are impacting your

530
00:18:09,510 --> 00:18:12,270
business that's a type 1 metric that's a

531
00:18:11,070 --> 00:18:15,450
controlled experiment that's entirely

532
00:18:12,270 --> 00:18:17,100
useful type 2 metrics or cbss itself is

533
00:18:15,450 --> 00:18:18,600
actually a type 1 metric as well it's

534
00:18:17,100 --> 00:18:20,908
descriptive of the vulnerabilities

535
00:18:18,600 --> 00:18:22,799
themselves it gives you a lot of rich

536
00:18:20,909 --> 00:18:24,390
data about those vulnerabilities but it

537
00:18:22,799 --> 00:18:26,460
doesn't show you how that data interacts

538
00:18:24,390 --> 00:18:31,440
with the threat environment so a type 2

539
00:18:26,460 --> 00:18:32,970
metric would be something like does this

540
00:18:31,440 --> 00:18:34,919
vulnerability have successful

541
00:18:32,970 --> 00:18:39,720
exploitation yes or no binary is a type

542
00:18:34,919 --> 00:18:41,190
2 metric or percentage of infected

543
00:18:39,720 --> 00:18:43,049
machines in your environment does a type

544
00:18:41,190 --> 00:18:44,340
2 metric so you don't know how many of

545
00:18:43,049 --> 00:18:45,570
those machines have what mitigating

546
00:18:44,340 --> 00:18:47,220
control in front of them and that's not

547
00:18:45,570 --> 00:18:48,418
factored into the metric but you are

548
00:18:47,220 --> 00:18:49,740
describing the external threat

549
00:18:48,419 --> 00:18:51,419
environment and combining those two

550
00:18:49,740 --> 00:18:53,820
metrics allows you to understand how

551
00:18:51,419 --> 00:18:55,470
much of your risk is carried by the

552
00:18:53,820 --> 00:18:57,480
threat environment and how much of your

553
00:18:55,470 --> 00:19:00,630
risk is mitigated by your current status

554
00:18:57,480 --> 00:19:05,190
quo controls so use that frame to

555
00:19:00,630 --> 00:19:08,210
evaluate a couple of metrics oh yeah I

556
00:19:05,190 --> 00:19:08,210
actually had a slide about this

557
00:19:15,460 --> 00:19:20,870
good I didn't need the slide so that's

558
00:19:18,080 --> 00:19:22,520
essentially the summary of it you want

559
00:19:20,870 --> 00:19:24,110
to be able to both exclude the real-life

560
00:19:22,520 --> 00:19:25,610
threat environment in some metrics those

561
00:19:24,110 --> 00:19:27,379
metrics are not that useful for guiding

562
00:19:25,610 --> 00:19:29,449
decision-making or policy but they are

563
00:19:27,380 --> 00:19:31,880
useful for being able to generate type 2

564
00:19:29,450 --> 00:19:32,990
metrics with the input or information of

565
00:19:31,880 --> 00:19:34,340
that threat environment that's how you

566
00:19:32,990 --> 00:19:36,770
use threat intelligence right you have a

567
00:19:34,340 --> 00:19:38,510
bunch of type 1 metrics that exclude the

568
00:19:36,770 --> 00:19:39,590
real-life third environment control for

569
00:19:38,510 --> 00:19:41,150
the occurrence rate and tell you about

570
00:19:39,590 --> 00:19:43,040
the behavior rather your users or your

571
00:19:41,150 --> 00:19:44,270
control systems you overlay that with

572
00:19:43,040 --> 00:19:46,280
your threat intelligence and you all of

573
00:19:44,270 --> 00:19:47,600
a sudden are generating type 2 metrics

574
00:19:46,280 --> 00:19:49,730
that talk about the interaction with the

575
00:19:47,600 --> 00:19:52,730
threat environment so what defines a

576
00:19:49,730 --> 00:19:54,910
good metric well all of that up popped

577
00:19:52,730 --> 00:19:57,170
up at once it was supposed to come up

578
00:19:54,910 --> 00:19:59,990
let's talk about them separately these

579
00:19:57,170 --> 00:20:02,840
are essentially I did a litter of you

580
00:19:59,990 --> 00:20:04,670
and I have the citations at the end of

581
00:20:02,840 --> 00:20:06,409
this talk about what people talk about

582
00:20:04,670 --> 00:20:09,580
our good metrics other people did litter

583
00:20:06,410 --> 00:20:12,980
views I had lit reviews of litter views

584
00:20:09,580 --> 00:20:14,870
so let's start with and I have paper to

585
00:20:12,980 --> 00:20:16,970
prove it let's start with how people

586
00:20:14,870 --> 00:20:18,590
define what a security metric is because

587
00:20:16,970 --> 00:20:20,720
this is a hullabaloo in and of itself

588
00:20:18,590 --> 00:20:21,980
there's a bunch of different definitions

589
00:20:20,720 --> 00:20:26,510
and I'm just gonna pick out a couple

590
00:20:21,980 --> 00:20:28,160
point in times so in 1999 core MOS and a

591
00:20:26,510 --> 00:20:30,260
bunch of other people so it's a

592
00:20:28,160 --> 00:20:33,500
measurable measurable attribute of the

593
00:20:30,260 --> 00:20:36,560
result of an SS ECM security engineering

594
00:20:33,500 --> 00:20:37,640
process ISO 2008 for more details that

595
00:20:36,560 --> 00:20:39,320
could serve as evidence of its

596
00:20:37,640 --> 00:20:41,660
effectiveness the security metric may be

597
00:20:39,320 --> 00:20:43,639
objective or subjective quantitative or

598
00:20:41,660 --> 00:20:48,050
qualitative I think we all disagree with

599
00:20:43,640 --> 00:20:50,090
that statement that was 99 in 2003

600
00:20:48,050 --> 00:20:51,649
Lennon says IT security metrics provide

601
00:20:50,090 --> 00:20:53,480
a practical approach to measuring

602
00:20:51,650 --> 00:20:55,460
information security evaluating security

603
00:20:53,480 --> 00:20:56,390
at the system level IT security metrics

604
00:20:55,460 --> 00:20:58,370
are two of the facilitate

605
00:20:56,390 --> 00:21:00,230
decision-making and accountability

606
00:20:58,370 --> 00:21:01,969
through collection of data that's also

607
00:21:00,230 --> 00:21:04,010
really simple of mindset right he's just

608
00:21:01,970 --> 00:21:05,060
describing type 1 metrics of like you

609
00:21:04,010 --> 00:21:08,260
better know what's happening in your

610
00:21:05,060 --> 00:21:10,610
environment let's jump ahead to 2014

611
00:21:08,260 --> 00:21:12,980
security metrics quantitatively describe

612
00:21:10,610 --> 00:21:14,659
the level of security for a system also

613
00:21:12,980 --> 00:21:16,190
a somewhat flawed approach but I think

614
00:21:14,660 --> 00:21:18,500
we're getting somewhere right we've care

615
00:21:16,190 --> 00:21:21,440
about making that data actionable the

616
00:21:18,500 --> 00:21:23,060
quantitative methods and when Johnny and

617
00:21:21,440 --> 00:21:24,050
Bobby I don't know how to say these

618
00:21:23,060 --> 00:21:25,760
people's names in 25

619
00:21:24,050 --> 00:21:28,250
tsa security metric is a quantitative

620
00:21:25,760 --> 00:21:30,080
measure indicating to which extent the

621
00:21:28,250 --> 00:21:31,610
considered entity or process the

622
00:21:30,080 --> 00:21:33,230
attribute has the attribute of being

623
00:21:31,610 --> 00:21:34,580
secure so I think we're getting closer

624
00:21:33,230 --> 00:21:36,950
to a real definition but the best

625
00:21:34,580 --> 00:21:40,790
definition I think is based on these

626
00:21:36,950 --> 00:21:42,710
factors a bunch of people asana and try

627
00:21:40,790 --> 00:21:44,629
and did an assessment of all of these

628
00:21:42,710 --> 00:21:45,680
kind of definitions of security metrics

629
00:21:44,630 --> 00:21:47,690
and they teased out what the

630
00:21:45,680 --> 00:21:48,770
commonalities in them are and to them I

631
00:21:47,690 --> 00:21:50,450
added a couple things

632
00:21:48,770 --> 00:21:51,590
so the first commonality across most

633
00:21:50,450 --> 00:21:53,870
security metrics is they need to be

634
00:21:51,590 --> 00:21:55,550
bounded and unbounded security metric is

635
00:21:53,870 --> 00:21:58,010
not very useful in a decision process if

636
00:21:55,550 --> 00:21:59,270
you tell me that your metric I think

637
00:21:58,010 --> 00:22:01,310
outside in the hall we were just talking

638
00:21:59,270 --> 00:22:04,610
about this somebody was using the metric

639
00:22:01,310 --> 00:22:06,590
of days to patch as a guide for how many

640
00:22:04,610 --> 00:22:08,659
people they should hire so that's an

641
00:22:06,590 --> 00:22:10,129
unbounded metric if it takes infinity

642
00:22:08,660 --> 00:22:11,900
days to patch it does not mean you

643
00:22:10,130 --> 00:22:13,490
should hire infinity people if it takes

644
00:22:11,900 --> 00:22:15,440
a hundred days to patch it does not mean

645
00:22:13,490 --> 00:22:19,130
you should hire you know infinity

646
00:22:15,440 --> 00:22:20,990
divided by whatever people once that

647
00:22:19,130 --> 00:22:22,670
metric has bounds once you place it on a

648
00:22:20,990 --> 00:22:25,070
scale that allows you to define both the

649
00:22:22,670 --> 00:22:27,290
state of no people hired or many people

650
00:22:25,070 --> 00:22:28,939
hired or maybe even the state of I am

651
00:22:27,290 --> 00:22:30,350
patching well and I'm patching poorly

652
00:22:28,940 --> 00:22:31,820
all of a sudden that becomes a better

653
00:22:30,350 --> 00:22:33,800
metric but without the space in which

654
00:22:31,820 --> 00:22:35,179
the metric operates it's useless so it's

655
00:22:33,800 --> 00:22:37,280
a necessary and sufficient condition for

656
00:22:35,180 --> 00:22:39,590
a good metric the second is that it

657
00:22:37,280 --> 00:22:41,420
needs to be scaled metrically and Alex

658
00:22:39,590 --> 00:22:43,790
Hadden Dan Gere all sorts of people talk

659
00:22:41,420 --> 00:22:45,770
about this infinitely to no end you need

660
00:22:43,790 --> 00:22:47,030
to be able to compare two values and to

661
00:22:45,770 --> 00:22:49,190
say that there's a meaningful difference

662
00:22:47,030 --> 00:22:50,540
between these two values that is to say

663
00:22:49,190 --> 00:22:52,520
if you've got a percentage of the metric

664
00:22:50,540 --> 00:22:54,830
great there's you can measurably say the

665
00:22:52,520 --> 00:22:56,540
difference between 70% and 80% if you've

666
00:22:54,830 --> 00:22:58,490
got a percentage on a crazy metric that

667
00:22:56,540 --> 00:23:00,230
makes no sense in advance of itself and

668
00:22:58,490 --> 00:23:02,300
you can't articulate to me what a 10%

669
00:23:00,230 --> 00:23:06,530
increase in that metric is it's not a

670
00:23:02,300 --> 00:23:08,780
good metric three through five come from

671
00:23:06,530 --> 00:23:10,340
epidemiological statistics they're not

672
00:23:08,780 --> 00:23:11,300
you know me saying something should be

673
00:23:10,340 --> 00:23:12,560
objective they're rather really

674
00:23:11,300 --> 00:23:14,480
technical formal mathematical

675
00:23:12,560 --> 00:23:18,020
definitions of objectivity validity and

676
00:23:14,480 --> 00:23:19,970
reliability a metric is objective if the

677
00:23:18,020 --> 00:23:21,860
input data in if it's resistant to

678
00:23:19,970 --> 00:23:25,850
changes in the input data the metric is

679
00:23:21,860 --> 00:23:28,490
valid if it has a measurable output and

680
00:23:25,850 --> 00:23:30,230
it rises to that output that is to say

681
00:23:28,490 --> 00:23:32,750
if you've got you know a metric that

682
00:23:30,230 --> 00:23:34,730
says how many cows have been slaughtered

683
00:23:32,750 --> 00:23:37,070
and you put in two cows versus three

684
00:23:34,730 --> 00:23:37,280
cows three should increase the metric

685
00:23:37,070 --> 00:23:39,980
and

686
00:23:37,280 --> 00:23:41,570
some way towards that objective it's a

687
00:23:39,980 --> 00:23:44,960
really bad example a better example is

688
00:23:41,570 --> 00:23:46,520
to say a better example is to say a

689
00:23:44,960 --> 00:23:48,080
metric that tries to measure exploit

690
00:23:46,520 --> 00:23:49,610
ability if there are more exploits

691
00:23:48,080 --> 00:23:51,020
should give you a higher score if it

692
00:23:49,610 --> 00:23:53,300
doesn't it's not a valid metric metric

693
00:23:51,020 --> 00:23:54,710
and a metric has to be reliable in that

694
00:23:53,300 --> 00:23:56,419
the same inputs generate the same

695
00:23:54,710 --> 00:23:59,990
outputs time and time again so it has to

696
00:23:56,420 --> 00:24:00,800
be mapped in a precise manner those are

697
00:23:59,990 --> 00:24:02,240
just things that allow you to do

698
00:24:00,800 --> 00:24:03,500
mathematical operations of metrics

699
00:24:02,240 --> 00:24:05,320
otherwise you're just comparing apples

700
00:24:03,500 --> 00:24:09,920
to oranges and can't really do much else

701
00:24:05,320 --> 00:24:12,679
the sixth one is a flexible definition

702
00:24:09,920 --> 00:24:14,750
it has to be context specific and by

703
00:24:12,680 --> 00:24:16,310
context specific I mean what I said

704
00:24:14,750 --> 00:24:18,080
earlier that it has to be a type 2

705
00:24:16,310 --> 00:24:19,250
metric or if it's a type 1 metric it has

706
00:24:18,080 --> 00:24:21,320
to be augmented with threat intelligence

707
00:24:19,250 --> 00:24:23,570
because if it's not in cybersecurity

708
00:24:21,320 --> 00:24:25,730
there's an adversary who's changing his

709
00:24:23,570 --> 00:24:28,159
his or her behavior and that change in

710
00:24:25,730 --> 00:24:29,690
behavior is kind of voiding the validity

711
00:24:28,160 --> 00:24:31,850
of your metric if it's not context

712
00:24:29,690 --> 00:24:34,970
specific or doesn't react to changes in

713
00:24:31,850 --> 00:24:36,560
the attackers behavior and seventh is a

714
00:24:34,970 --> 00:24:37,550
requirement that's contentious but I

715
00:24:36,560 --> 00:24:39,139
don't think it is it needs to be

716
00:24:37,550 --> 00:24:40,820
computed automatically that's a

717
00:24:39,140 --> 00:24:42,860
requirement born both out of just the

718
00:24:40,820 --> 00:24:46,730
slew of data that we deal with but also

719
00:24:42,860 --> 00:24:48,919
born out of the fact that you can't use

720
00:24:46,730 --> 00:24:50,450
a metric if it's manually computed

721
00:24:48,920 --> 00:24:52,220
unless you have an army of foot soldiers

722
00:24:50,450 --> 00:24:53,990
and I think for the purposes of this

723
00:24:52,220 --> 00:24:56,990
talk very few of us have an army of foot

724
00:24:53,990 --> 00:24:59,030
soldiers or very few of us are able to

725
00:24:56,990 --> 00:25:02,750
continue to rely on the manual processes

726
00:24:59,030 --> 00:25:04,399
for generating metrics and this is to

727
00:25:02,750 --> 00:25:06,680
say that computer automatically can mean

728
00:25:04,400 --> 00:25:08,180
if I hire a threat intelligence provider

729
00:25:06,680 --> 00:25:09,590
and they have an army of foot soldiers

730
00:25:08,180 --> 00:25:11,870
and they're generating information for

731
00:25:09,590 --> 00:25:13,909
me the input to my metric is automatic

732
00:25:11,870 --> 00:25:15,770
because I'm not doing that work right if

733
00:25:13,910 --> 00:25:18,530
I take that data as ground truth that's

734
00:25:15,770 --> 00:25:19,910
ok so you know manual analysis is

735
00:25:18,530 --> 00:25:21,170
certainly possible but your metrics

736
00:25:19,910 --> 00:25:22,760
shouldn't rely on any kind of manual

737
00:25:21,170 --> 00:25:24,650
analysis because then you can't compute

738
00:25:22,760 --> 00:25:27,650
them in real time and what use are they

739
00:25:24,650 --> 00:25:28,820
with a real-time attacker so let's look

740
00:25:27,650 --> 00:25:31,820
at some metrics and see if they pass the

741
00:25:28,820 --> 00:25:33,649
test mean time to incident discovery is

742
00:25:31,820 --> 00:25:36,980
a really interesting metric so when

743
00:25:33,650 --> 00:25:38,480
people find out when people you know do

744
00:25:36,980 --> 00:25:40,730
post hoc analysis and look at their

745
00:25:38,480 --> 00:25:41,930
incident discovery processes this is a

746
00:25:40,730 --> 00:25:44,930
metric that they use to say like how

747
00:25:41,930 --> 00:25:47,040
good is IRI our team in general and I

748
00:25:44,930 --> 00:25:49,200
think that's a really terrible metric

749
00:25:47,040 --> 00:25:50,490
it's not bounded first of all but that's

750
00:25:49,200 --> 00:25:51,870
okay we can deal with that right we can

751
00:25:50,490 --> 00:25:54,330
say like a hundred days would be really

752
00:25:51,870 --> 00:25:56,580
great if you guys could do that if it is

753
00:25:54,330 --> 00:25:59,480
scaled metrically that is to say 20 days

754
00:25:56,580 --> 00:26:02,730
as two times as bad as ten days maybe

755
00:25:59,480 --> 00:26:04,620
it's its objective in that those two

756
00:26:02,730 --> 00:26:05,970
data points of when the incident

757
00:26:04,620 --> 00:26:08,610
occurred and when you discovered the

758
00:26:05,970 --> 00:26:11,309
incident are stable numbers that don't

759
00:26:08,610 --> 00:26:13,830
can't really argue with those but it's

760
00:26:11,309 --> 00:26:15,870
not valid and it's not valid in that the

761
00:26:13,830 --> 00:26:18,570
number of days the discovery is not

762
00:26:15,870 --> 00:26:19,830
necessarily something that you can count

763
00:26:18,570 --> 00:26:21,840
or articulate because it could be

764
00:26:19,830 --> 00:26:24,299
obviated by a whole bunch of things and

765
00:26:21,840 --> 00:26:25,949
also as that number increases it does

766
00:26:24,299 --> 00:26:27,600
not describe the performance of your

767
00:26:25,950 --> 00:26:29,070
incident response team because there was

768
00:26:27,600 --> 00:26:30,659
a whole bunch of other factors that

769
00:26:29,070 --> 00:26:33,389
could be affecting that and because

770
00:26:30,660 --> 00:26:35,040
teams on different enterprises could be

771
00:26:33,390 --> 00:26:37,590
doing the same things faster or slower

772
00:26:35,040 --> 00:26:38,580
based on the type 1 metrics based on

773
00:26:37,590 --> 00:26:40,290
what's happening in their control

774
00:26:38,580 --> 00:26:43,710
environment what processes were at stake

775
00:26:40,290 --> 00:26:45,059
or what logs they have access to it is a

776
00:26:43,710 --> 00:26:46,559
reliable metric and that if you throw

777
00:26:45,059 --> 00:26:48,809
two numbers in it the same thing pops

778
00:26:46,559 --> 00:26:50,129
out every time it is contact specific

779
00:26:48,809 --> 00:26:51,928
and that it tries to describe incident

780
00:26:50,130 --> 00:26:53,940
response but here's the kicker it's

781
00:26:51,929 --> 00:26:56,490
can't be computed automatically because

782
00:26:53,940 --> 00:26:59,190
if you could compute the time when the

783
00:26:56,490 --> 00:27:01,020
incident happened automatically then you

784
00:26:59,190 --> 00:27:02,160
would have a zero incident response time

785
00:27:01,020 --> 00:27:05,129
you would have already responded to the

786
00:27:02,160 --> 00:27:06,840
incident so that gap or measuring that

787
00:27:05,130 --> 00:27:09,510
data means that you have to manually

788
00:27:06,840 --> 00:27:11,070
post hoc who go find out when that thing

789
00:27:09,510 --> 00:27:13,890
happened based on the new rule such

790
00:27:11,070 --> 00:27:15,899
generated of the incident and if that's

791
00:27:13,890 --> 00:27:17,610
a part of your input into the metric the

792
00:27:15,900 --> 00:27:19,650
metric is not measuring the performance

793
00:27:17,610 --> 00:27:21,959
of your team moreover if that's true

794
00:27:19,650 --> 00:27:23,400
anybody could game the metric right it's

795
00:27:21,960 --> 00:27:25,080
not very useful because you can't really

796
00:27:23,400 --> 00:27:25,559
measure adherence to the metric over

797
00:27:25,080 --> 00:27:26,909
time

798
00:27:25,559 --> 00:27:30,660
because different people could adhere to

799
00:27:26,910 --> 00:27:32,309
it differently vulnerability scanning

800
00:27:30,660 --> 00:27:34,470
coverage however is an awesome metric

801
00:27:32,309 --> 00:27:36,059
passes the test on all of these and that

802
00:27:34,470 --> 00:27:37,860
would just be the percent of assets that

803
00:27:36,059 --> 00:27:40,020
you are scanning with vulnerabilities

804
00:27:37,860 --> 00:27:42,479
it's definitely bounded because it's a

805
00:27:40,020 --> 00:27:44,490
percentage scale metrically its

806
00:27:42,480 --> 00:27:47,160
objective in that it's a binary choice

807
00:27:44,490 --> 00:27:49,770
about every asset its valid and reliable

808
00:27:47,160 --> 00:27:52,049
its contact specific in that it is

809
00:27:49,770 --> 00:27:55,440
trying to describe a particular process

810
00:27:52,049 --> 00:27:56,700
that it is at the root of right there's

811
00:27:55,440 --> 00:27:58,110
nothing else in that process that could

812
00:27:56,700 --> 00:27:59,720
obfuscate your vulnerability Scot

813
00:27:58,110 --> 00:28:02,840
scanning coverage

814
00:27:59,720 --> 00:28:04,460
and it can be gamed either in that why

815
00:28:02,840 --> 00:28:06,889
either you scans it or not the data

816
00:28:04,460 --> 00:28:08,299
backs it up it's computer automatically

817
00:28:06,890 --> 00:28:09,830
because once you've launched a scanner

818
00:28:08,299 --> 00:28:13,330
once you have asset inventory that's

819
00:28:09,830 --> 00:28:15,379
possible the computer automatically

820
00:28:13,330 --> 00:28:17,629
let's take a look at CBS s for

821
00:28:15,380 --> 00:28:19,700
remediation itself it's certainly

822
00:28:17,630 --> 00:28:20,840
bounded it does not scale metrically in

823
00:28:19,700 --> 00:28:23,210
that I don't know the difference between

824
00:28:20,840 --> 00:28:24,320
a nine point seven and a nine point

825
00:28:23,210 --> 00:28:25,220
three moreover I don't know the

826
00:28:24,320 --> 00:28:28,700
difference between a ten and a five

827
00:28:25,220 --> 00:28:30,770
being two times as much it's not

828
00:28:28,700 --> 00:28:33,440
objective because the mapping of the

829
00:28:30,770 --> 00:28:36,020
fairly objective inputs that G VSS gives

830
00:28:33,440 --> 00:28:40,220
us to the score is a pretty subjective

831
00:28:36,020 --> 00:28:42,889
mapping it's not a valid metric in that

832
00:28:40,220 --> 00:28:44,630
note that I say CB SS for remediation in

833
00:28:42,890 --> 00:28:45,919
that it doesn't describe the order in

834
00:28:44,630 --> 00:28:46,940
which you should remediate something is

835
00:28:45,919 --> 00:28:48,679
just describing something about

836
00:28:46,940 --> 00:28:50,210
vulnerability and it's a type one metric

837
00:28:48,679 --> 00:28:52,250
it doesn't take into account the threat

838
00:28:50,210 --> 00:28:53,750
environment it is certainly reliable the

839
00:28:52,250 --> 00:28:56,000
same inputs generate the same outputs

840
00:28:53,750 --> 00:28:58,309
but it's not context specific because

841
00:28:56,000 --> 00:29:00,169
you could also just as easily game CBS s

842
00:28:58,309 --> 00:29:02,270
by saying I don't have information about

843
00:29:00,169 --> 00:29:04,610
this input and so this is scored higher

844
00:29:02,270 --> 00:29:05,900
and people do that fairly frequently in

845
00:29:04,610 --> 00:29:07,520
order to increase the slew of

846
00:29:05,900 --> 00:29:09,260
information they do or don't have to

847
00:29:07,520 --> 00:29:11,840
deal with but it can be computed

848
00:29:09,260 --> 00:29:13,370
automatically so we've taken a look at a

849
00:29:11,840 --> 00:29:14,928
couple metrics and this is my kind of

850
00:29:13,370 --> 00:29:16,549
standard set of rules that you should

851
00:29:14,929 --> 00:29:18,440
gut check yourself does that my metric

852
00:29:16,549 --> 00:29:19,580
make sense for my operation some of

853
00:29:18,440 --> 00:29:20,480
these things are subjective right you

854
00:29:19,580 --> 00:29:21,860
could argue with me about whether

855
00:29:20,480 --> 00:29:23,179
something's objective or valid you could

856
00:29:21,860 --> 00:29:25,879
argue with me about whether something is

857
00:29:23,179 --> 00:29:27,380
context specific or not but as a rule

858
00:29:25,880 --> 00:29:29,570
for checking yourself it's a pretty good

859
00:29:27,380 --> 00:29:31,070
one the other point is that you need

860
00:29:29,570 --> 00:29:33,189
data to make metrics you need data to

861
00:29:31,070 --> 00:29:35,899
make data in the first place and so

862
00:29:33,190 --> 00:29:38,559
let's back up to that same data set it's

863
00:29:35,900 --> 00:29:42,039
actually about at this point

864
00:29:38,559 --> 00:29:44,870
700 million successful breach events if

865
00:29:42,039 --> 00:29:46,220
you look at those two types kind of

866
00:29:44,870 --> 00:29:47,989
emerge just have two types of

867
00:29:46,220 --> 00:29:50,270
vulnerabilities kind of emerged just

868
00:29:47,990 --> 00:29:54,049
happening all the time so there's many

869
00:29:50,270 --> 00:29:55,129
different you know curves of these are

870
00:29:54,049 --> 00:29:55,879
essentially cumulative distribution

871
00:29:55,130 --> 00:29:57,470
functions there's many different

872
00:29:55,880 --> 00:29:59,900
cumulative distribution functions of how

873
00:29:57,470 --> 00:30:02,360
CV is behaved but two types segments

874
00:29:59,900 --> 00:30:03,980
pretty frequently and they are those

875
00:30:02,360 --> 00:30:06,379
that have attacks before the

876
00:30:03,980 --> 00:30:08,630
vulnerability release date and then when

877
00:30:06,380 --> 00:30:10,580
stable weaponized exploits come out the

878
00:30:08,630 --> 00:30:11,809
number of attacks jumps up those are

879
00:30:10,580 --> 00:30:13,159
generally access complexity high

880
00:30:11,809 --> 00:30:14,360
vulnerabilities

881
00:30:13,160 --> 00:30:15,710
if we access complexity low

882
00:30:14,360 --> 00:30:18,678
vulnerabilities as soon as the release

883
00:30:15,710 --> 00:30:20,299
date occurs there's a small ramp up in

884
00:30:18,679 --> 00:30:21,710
attacks once exploits are publicly

885
00:30:20,299 --> 00:30:23,240
available and released the number of

886
00:30:21,710 --> 00:30:25,130
attacks skyrockets and then shoots down

887
00:30:23,240 --> 00:30:26,660
over time and I think the reason for

888
00:30:25,130 --> 00:30:28,309
this is because attackers are not dumb

889
00:30:26,660 --> 00:30:30,620
they look at vulnerabilities and think

890
00:30:28,309 --> 00:30:32,090
oh axis complexity low vulnerability let

891
00:30:30,620 --> 00:30:33,709
us craft an exploit and start firing

892
00:30:32,090 --> 00:30:36,080
this off in an automatic fashion and see

893
00:30:33,710 --> 00:30:37,880
what it catches this isn't descriptive

894
00:30:36,080 --> 00:30:39,889
of all vulnerabilities but what is it is

895
00:30:37,880 --> 00:30:42,410
useful for is that you can see the

896
00:30:39,890 --> 00:30:44,660
effect of exploit publicly available

897
00:30:42,410 --> 00:30:45,710
exploit information on the number of

898
00:30:44,660 --> 00:30:47,809
attacks and those particular

899
00:30:45,710 --> 00:30:49,190
vulnerabilities so I present to you a

900
00:30:47,809 --> 00:30:51,379
completely different metric which is

901
00:30:49,190 --> 00:30:53,510
does the vulnerability have a Metasploit

902
00:30:51,380 --> 00:30:56,270
module or not it is bounded because it

903
00:30:53,510 --> 00:30:59,289
is 0-1 it is scaled metrically because

904
00:30:56,270 --> 00:31:01,940
having it is worse than not having it is

905
00:30:59,289 --> 00:31:04,070
objective in that information is

906
00:31:01,940 --> 00:31:06,620
actually publicly available and pretty

907
00:31:04,070 --> 00:31:07,939
easy to find it's valid reliable it's

908
00:31:06,620 --> 00:31:10,729
context specific because all I'm

909
00:31:07,940 --> 00:31:12,799
describing is the possibility of

910
00:31:10,730 --> 00:31:15,740
exploitation on that metric it's very

911
00:31:12,799 --> 00:31:17,539
hard to game it if by crafting fake not

912
00:31:15,740 --> 00:31:19,970
correct Metasploit module somebody will

913
00:31:17,539 --> 00:31:21,650
check you and its computer automatically

914
00:31:19,970 --> 00:31:25,070
because you can just use showdowns API

915
00:31:21,650 --> 00:31:28,250
or rapid sevens API to get it so why is

916
00:31:25,070 --> 00:31:30,500
this metric better for remediation let's

917
00:31:28,250 --> 00:31:31,940
take a look at two different data sets

918
00:31:30,500 --> 00:31:33,440
now so the first data set that I

919
00:31:31,940 --> 00:31:35,630
described is a data set of successful

920
00:31:33,440 --> 00:31:38,299
exploitations as indicated by indicators

921
00:31:35,630 --> 00:31:40,700
of compromised or IDs events the second

922
00:31:38,299 --> 00:31:42,200
data set that I have is across two

923
00:31:40,700 --> 00:31:43,460
million assets I have all of the

924
00:31:42,200 --> 00:31:45,260
vulnerability scan data from those

925
00:31:43,460 --> 00:31:47,630
assets that is I have all the

926
00:31:45,260 --> 00:31:51,890
occurrences of open live vulnerabilities

927
00:31:47,630 --> 00:31:54,980
on those assets so nvd currently has

928
00:31:51,890 --> 00:31:56,600
like 72 73,000 vulnerabilities in it if

929
00:31:54,980 --> 00:31:58,880
you pick a random vulnerability in the

930
00:31:56,600 --> 00:32:00,590
database and you look at the number of

931
00:31:58,880 --> 00:32:03,980
occurrences of live vulnerabilities in

932
00:32:00,590 --> 00:32:05,840
my data set and conditional on the

933
00:32:03,980 --> 00:32:07,549
probability of that a breach has

934
00:32:05,840 --> 00:32:09,379
occurred or a successful expectation has

935
00:32:07,549 --> 00:32:11,120
occurred on that vulnerability type and

936
00:32:09,380 --> 00:32:12,770
divided by the total number of live

937
00:32:11,120 --> 00:32:14,750
vulnerabilities so what I'm really doing

938
00:32:12,770 --> 00:32:16,730
is I'm saying does this definition have

939
00:32:14,750 --> 00:32:18,380
a successful exploitation event

940
00:32:16,730 --> 00:32:21,350
associated with it and how does that

941
00:32:18,380 --> 00:32:22,760
scale to the live data set of I think

942
00:32:21,350 --> 00:32:24,678
it's a hundred and sixty million

943
00:32:22,760 --> 00:32:26,910
vulnerabilities at this point and if you

944
00:32:24,679 --> 00:32:28,440
do that the

945
00:32:26,910 --> 00:32:31,740
if you pick a random one out of the

946
00:32:28,440 --> 00:32:34,560
72,000 is one that does have a breacher

947
00:32:31,740 --> 00:32:35,850
event associated with it is 6% so you

948
00:32:34,560 --> 00:32:36,960
know some of these vulnerabilities don't

949
00:32:35,850 --> 00:32:38,760
show up some of the vulnerability

950
00:32:36,960 --> 00:32:41,120
definitions don't show up in my data set

951
00:32:38,760 --> 00:32:44,640
at all some are more pervasive because

952
00:32:41,120 --> 00:32:46,860
Adobe Acrobat Reader everybody has some

953
00:32:44,640 --> 00:32:48,720
are less pervasive but I contend that

954
00:32:46,860 --> 00:32:50,219
it's a type 2 metric for generating

955
00:32:48,720 --> 00:32:52,440
remediation because it takes into

956
00:32:50,220 --> 00:32:54,240
account the threat environment and has a

957
00:32:52,440 --> 00:32:56,640
type 1 metric that is controlled which

958
00:32:54,240 --> 00:32:57,870
is has breach occurred or not so if you

959
00:32:56,640 --> 00:32:59,190
do that you have a 6 percent chance of

960
00:32:57,870 --> 00:33:00,120
being successful that means that if

961
00:32:59,190 --> 00:33:02,970
you're just randomly picking

962
00:33:00,120 --> 00:33:04,820
vulnerabilities to fix on average it'll

963
00:33:02,970 --> 00:33:07,920
be about 6 percent successful doing it

964
00:33:04,820 --> 00:33:11,310
let's look at CVS s is the same thing so

965
00:33:07,920 --> 00:33:13,950
these are cutoff scores that is to say

966
00:33:11,310 --> 00:33:15,780
if I pick all vulnerabilities that have

967
00:33:13,950 --> 00:33:18,570
a score of zero or above which is all of

968
00:33:15,780 --> 00:33:20,220
them what's the probability that I am

969
00:33:18,570 --> 00:33:22,080
remediating a vulnerability that has an

970
00:33:20,220 --> 00:33:23,220
Associated breach event with it and of

971
00:33:22,080 --> 00:33:25,320
course that's 6 percent because that's

972
00:33:23,220 --> 00:33:28,080
all vulnerable ''tis as we move up the

973
00:33:25,320 --> 00:33:29,790
chain of cbss and get to about 6 or 7

974
00:33:28,080 --> 00:33:30,870
you can see a significant increase in

975
00:33:29,790 --> 00:33:34,350
the probability of you being successful

976
00:33:30,870 --> 00:33:36,629
so you get about 8 percent success rate

977
00:33:34,350 --> 00:33:38,189
and as you move up even further to just

978
00:33:36,630 --> 00:33:40,710
your mediating pick one vulnerability

979
00:33:38,190 --> 00:33:42,720
that has a cbss score of 10 remediate

980
00:33:40,710 --> 00:33:44,160
that one you have an 11% chance of being

981
00:33:42,720 --> 00:33:45,810
successful you're mediating a successful

982
00:33:44,160 --> 00:33:49,880
agreement that's like almost twice as

983
00:33:45,810 --> 00:33:49,879
good as random that's pretty good

984
00:33:50,090 --> 00:33:54,600
however if you have if you're fixing

985
00:33:52,770 --> 00:33:56,639
just the critical vulnerability is let's

986
00:33:54,600 --> 00:33:58,080
say 8 and above that's not as good of a

987
00:33:56,640 --> 00:34:00,270
strategy as just fixing the tens

988
00:33:58,080 --> 00:34:02,370
moreover let's think about the cost of

989
00:34:00,270 --> 00:34:03,870
undertaking such a strategy if you are

990
00:34:02,370 --> 00:34:05,790
fixing just the CVS s time

991
00:34:03,870 --> 00:34:07,169
vulnerabilities in that data set you are

992
00:34:05,790 --> 00:34:08,879
fixing 23 percent of all the

993
00:34:07,170 --> 00:34:10,830
vulnerabilities which is not a

994
00:34:08,879 --> 00:34:14,549
possibility so we need a test that is

995
00:34:10,830 --> 00:34:15,870
more specific not just sensitive let's

996
00:34:14,550 --> 00:34:17,790
evaluate that other metric which is

997
00:34:15,870 --> 00:34:20,370
Metasploit against the same thing if you

998
00:34:17,790 --> 00:34:21,629
fix the CVS s10 vulnerability random you

999
00:34:20,370 --> 00:34:24,029
have an 11% chance of being successful

1000
00:34:21,629 --> 00:34:27,120
if you fix something that has an entry

1001
00:34:24,030 --> 00:34:29,250
in ex-boy DB then you have a 17 and 1/2

1002
00:34:27,120 --> 00:34:31,199
percent chance of being successful if

1003
00:34:29,250 --> 00:34:33,030
you fix a Metasploit vulnerability one

1004
00:34:31,199 --> 00:34:35,580
that has an entry in Metasploit you're

1005
00:34:33,030 --> 00:34:37,379
down to only about a thousand CVS and

1006
00:34:35,580 --> 00:34:39,210
you have a 27 and a half percent chance

1007
00:34:37,379 --> 00:34:40,560
of fixing it and if you intersect the

1008
00:34:39,210 --> 00:34:42,510
two data sets that is there what

1009
00:34:40,560 --> 00:34:44,100
a proof-of-concept exploit DB Metasploit

1010
00:34:42,510 --> 00:34:46,020
out there and then a Metasploit module

1011
00:34:44,100 --> 00:34:47,819
came out not necessarily in that order

1012
00:34:46,020 --> 00:34:50,130
we're down to only about 600 different

1013
00:34:47,820 --> 00:34:53,460
cv definitions and your probability of

1014
00:34:50,130 --> 00:34:56,730
being successful is 36% so what have I

1015
00:34:53,460 --> 00:35:00,300
done here this is it I'm done with the

1016
00:34:56,730 --> 00:35:02,040
talk but to back it all up what's

1017
00:35:00,300 --> 00:35:05,760
important here is the progression of

1018
00:35:02,040 --> 00:35:07,860
data to well-defined metric to measuring

1019
00:35:05,760 --> 00:35:09,330
that metrics of effectiveness so if you

1020
00:35:07,860 --> 00:35:10,740
want to look more look at more about

1021
00:35:09,330 --> 00:35:12,480
measuring the effectiveness of a metric

1022
00:35:10,740 --> 00:35:14,339
or using things like predictive positive

1023
00:35:12,480 --> 00:35:17,610
value or sensitivity specificity

1024
00:35:14,340 --> 00:35:19,980
cut-offs like that you hear Dan gear has

1025
00:35:17,610 --> 00:35:21,750
an entire workday day-long workshop on

1026
00:35:19,980 --> 00:35:23,970
evaluating metrics that you can take a

1027
00:35:21,750 --> 00:35:27,330
look at it's available online actually

1028
00:35:23,970 --> 00:35:31,470
here there are references and references

1029
00:35:27,330 --> 00:35:33,270
that all obviously post but it's

1030
00:35:31,470 --> 00:35:34,770
important to measure whether your theory

1031
00:35:33,270 --> 00:35:36,600
of what is a good metric is correct so

1032
00:35:34,770 --> 00:35:38,310
I've given you a couple of necessary in

1033
00:35:36,600 --> 00:35:41,160
sufficient conditions for making a

1034
00:35:38,310 --> 00:35:44,610
metric good or making a metric likely to

1035
00:35:41,160 --> 00:35:46,470
be successful those indicate that your

1036
00:35:44,610 --> 00:35:48,210
selection of metric is okay based on a

1037
00:35:46,470 --> 00:35:49,980
data set that you have and obviously

1038
00:35:48,210 --> 00:35:51,420
there are some times when you're like I

1039
00:35:49,980 --> 00:35:53,160
can't answer the question of whether

1040
00:35:51,420 --> 00:35:54,540
this is bounded or not or I can't come

1041
00:35:53,160 --> 00:35:55,830
up with a way to bound this that

1042
00:35:54,540 --> 00:35:57,120
probably means you need to be looking at

1043
00:35:55,830 --> 00:35:58,980
a different data set or generating a

1044
00:35:57,120 --> 00:36:00,630
metric from a different data set and

1045
00:35:58,980 --> 00:36:01,980
that's actually the way that we drive

1046
00:36:00,630 --> 00:36:04,320
new data collection efforts to begin

1047
00:36:01,980 --> 00:36:06,270
with but start with a data set start

1048
00:36:04,320 --> 00:36:07,530
with the richest data sets you can look

1049
00:36:06,270 --> 00:36:09,060
at these necessary and sufficient

1050
00:36:07,530 --> 00:36:11,250
criterion to come up with metrics and

1051
00:36:09,060 --> 00:36:13,020
then over time test their performance on

1052
00:36:11,250 --> 00:36:14,580
live situations test their performance

1053
00:36:13,020 --> 00:36:16,320
as type two metrics are they actually

1054
00:36:14,580 --> 00:36:17,580
descriptive of the threat environment

1055
00:36:16,320 --> 00:36:21,750
and are they actually adding value to

1056
00:36:17,580 --> 00:36:23,759
your organization so as left in an

1057
00:36:21,750 --> 00:36:25,170
exercise left to the reader is to take a

1058
00:36:23,760 --> 00:36:27,420
look at the metrics that we commonly use

1059
00:36:25,170 --> 00:36:29,580
right now walk them through this and I

1060
00:36:27,420 --> 00:36:32,160
think much like we find with mean time

1061
00:36:29,580 --> 00:36:34,170
to incident discovery or average time to

1062
00:36:32,160 --> 00:36:35,730
patch something we'll find that we now

1063
00:36:34,170 --> 00:36:37,200
have rich for better data sets than

1064
00:36:35,730 --> 00:36:41,450
those kinds of metrics and it's time to

1065
00:36:37,200 --> 00:36:41,450
stop using those that's it

1066
00:36:46,820 --> 00:36:54,830
[Applause]

1067
00:36:48,820 --> 00:36:56,210
questions comments concerns questions if

1068
00:36:54,830 --> 00:37:01,069
you're in preparation for that reach

1069
00:36:56,210 --> 00:37:03,470
definitely in rehab and 2535 number

1070
00:37:01,070 --> 00:37:06,560
probably looking back with the dataset

1071
00:37:03,470 --> 00:37:08,689
what can you breathe so it's concern I

1072
00:37:06,560 --> 00:37:09,950
have to stay in organizations have a

1073
00:37:08,690 --> 00:37:13,040
model where they're only going to tax

1074
00:37:09,950 --> 00:37:15,830
things that are in juvie and that's

1075
00:37:13,040 --> 00:37:18,860
employed by the time that they're in and

1076
00:37:15,830 --> 00:37:22,040
then equation compromise

1077
00:37:18,860 --> 00:37:24,560
well so yes you're correct except that

1078
00:37:22,040 --> 00:37:26,390
your question assumes that they have a

1079
00:37:24,560 --> 00:37:28,700
vulnerability that is in Metasploit or

1080
00:37:26,390 --> 00:37:31,430
EDB to compare to one that is not or one

1081
00:37:28,700 --> 00:37:33,500
that might be soon and my answer is if

1082
00:37:31,430 --> 00:37:34,640
you have these things and you know that

1083
00:37:33,500 --> 00:37:37,190
they're being successfully breached or

1084
00:37:34,640 --> 00:37:38,870
are good indicators of past breaches you

1085
00:37:37,190 --> 00:37:40,490
should fix them before you move on to

1086
00:37:38,870 --> 00:37:42,770
the process of calculating what will be

1087
00:37:40,490 --> 00:37:44,750
predictably breached later and I have

1088
00:37:42,770 --> 00:37:45,860
not yet seen a single organization that

1089
00:37:44,750 --> 00:37:49,610
doesn't have at least one Metasploit

1090
00:37:45,860 --> 00:37:50,930
affected vulnerability what I'm saying

1091
00:37:49,610 --> 00:37:53,000
is like you're right we should be doing

1092
00:37:50,930 --> 00:37:54,169
making predictive models as well I think

1093
00:37:53,000 --> 00:37:56,660
we're a bit of ways from being able to

1094
00:37:54,170 --> 00:37:57,980
make those predictions or like a set of

1095
00:37:56,660 --> 00:38:21,830
fresh eyes away from being able to do

1096
00:37:57,980 --> 00:38:25,280
that with the status but the public for

1097
00:38:21,830 --> 00:38:28,790
right away waiting close

1098
00:38:25,280 --> 00:38:30,470
that window of time where you know retro

1099
00:38:28,790 --> 00:38:31,880
actively find out how I passed the one

1100
00:38:30,470 --> 00:38:35,200
that what the current or mobility but

1101
00:38:31,880 --> 00:38:37,580
now you know a week or two later before

1102
00:38:35,200 --> 00:38:38,859
probably or talk no yeah you're right

1103
00:38:37,580 --> 00:38:41,660
there's a lead time I just think that

1104
00:38:38,860 --> 00:38:43,070
this is yeah I'm looking at here what

1105
00:38:41,660 --> 00:38:45,080
are your vulnerabilities let me make

1106
00:38:43,070 --> 00:38:46,430
some strategic decisions for you so

1107
00:38:45,080 --> 00:38:48,470
looking at these vulnerabilities that

1108
00:38:46,430 --> 00:38:51,169
you have right now here's how you decide

1109
00:38:48,470 --> 00:38:52,819
between which ones to fix next the

1110
00:38:51,170 --> 00:38:54,530
question of and you're right this is a

1111
00:38:52,820 --> 00:38:55,940
bad metric for the decision calculus of

1112
00:38:54,530 --> 00:38:57,680
new vulnerability came out should I

1113
00:38:55,940 --> 00:39:00,250
patch it or not I just don't know of any

1114
00:38:57,680 --> 00:39:00,250
organizations

1115
00:39:02,920 --> 00:39:05,890
so we need to be able to predict whether

1116
00:39:04,570 --> 00:39:08,110
something's going to be an exploit or

1117
00:39:05,890 --> 00:39:09,850
not we're just probably coding houses as

1118
00:39:08,110 --> 00:39:13,900
well not just the script of data about

1119
00:39:09,850 --> 00:39:14,980
the vulnerability but that's a

1120
00:39:13,900 --> 00:39:16,660
completely different question right this

1121
00:39:14,980 --> 00:39:17,980
is not a valid metric for new

1122
00:39:16,660 --> 00:39:19,270
vulnerability came out what's the

1123
00:39:17,980 --> 00:39:22,090
probability it'll be exploited in the

1124
00:39:19,270 --> 00:39:23,440
future this is a valid metric for I have

1125
00:39:22,090 --> 00:39:41,730
a set of vulnerabilities which one do I

1126
00:39:23,440 --> 00:39:45,910
fix this is automated this is automated

1127
00:39:41,730 --> 00:39:47,350
so this is a breach that has maybe no

1128
00:39:45,910 --> 00:39:50,470
terminal impact right it's a successful

1129
00:39:47,350 --> 00:39:52,390
exploitation of a vulnerability this is

1130
00:39:50,470 --> 00:39:54,160
automated because I have access to the

1131
00:39:52,390 --> 00:40:11,549
IDS scans of fifty thousand businesses

1132
00:39:54,160 --> 00:40:11,549
in real time which is financially

1133
00:40:11,980 --> 00:40:16,840
pick me pick me

1134
00:40:13,610 --> 00:40:20,320
you just have reached the number of

1135
00:40:16,840 --> 00:40:29,030
reported incidents / creatures

1136
00:40:20,320 --> 00:40:31,130
financially great yeah I think you're

1137
00:40:29,030 --> 00:40:34,610
absolutely right I have no idea how to

1138
00:40:31,130 --> 00:40:38,210
work a c-suite to do that somebody here

1139
00:40:34,610 --> 00:40:40,760
probably knows better yeah I think going

1140
00:40:38,210 --> 00:40:41,990
up a level is exactly my answer the

1141
00:40:40,760 --> 00:40:43,910
vendors that provide the security

1142
00:40:41,990 --> 00:40:45,259
products have aggregated Onam eyes data

1143
00:40:43,910 --> 00:40:46,970
that allows you to find that same level

1144
00:40:45,260 --> 00:40:48,500
of information because I'm not going to

1145
00:40:46,970 --> 00:40:50,270
50,000 businesses and being like hey

1146
00:40:48,500 --> 00:40:51,740
share your data with me I'm going to the

1147
00:40:50,270 --> 00:40:53,630
vendor that provides their technical

1148
00:40:51,740 --> 00:40:55,549
piece of equipment and saying I want an

1149
00:40:53,630 --> 00:40:57,890
itemized live data to be able to make

1150
00:40:55,550 --> 00:40:59,180
these probabilistic decisions the same

1151
00:40:57,890 --> 00:41:01,129
thing needs to happen at all levels

1152
00:40:59,180 --> 00:41:03,799
whatever tools they deploy go to fire I

1153
00:41:01,130 --> 00:41:05,750
and say I want those logs anonymized and

1154
00:41:03,800 --> 00:41:09,110
aggregated and then I can post talk

1155
00:41:05,750 --> 00:41:11,480
detect breaches in that data set so I

1156
00:41:09,110 --> 00:41:14,990
think that the that yeah go ahead

1157
00:41:11,480 --> 00:41:17,630
nothing give a comment about that okay

1158
00:41:14,990 --> 00:41:19,609
yeah it insurers is a good idea right

1159
00:41:17,630 --> 00:41:20,960
like I I don't know what the perverse or

1160
00:41:19,610 --> 00:41:22,280
non perverse incentives are to make

1161
00:41:20,960 --> 00:41:23,630
somebody share data but I think it's

1162
00:41:22,280 --> 00:41:25,930
about time we just grabbed it from them

1163
00:41:23,630 --> 00:41:25,930
anyways

1164
00:41:27,180 --> 00:41:32,500
but I mean how to adjourn that have a

1165
00:41:30,580 --> 00:41:34,600
company secure their style that's right

1166
00:41:32,500 --> 00:41:37,660
which they do now that in a limited

1167
00:41:34,600 --> 00:41:39,940
context way around data loss reach but

1168
00:41:37,660 --> 00:41:42,569
if that were to expand out to you know

1169
00:41:39,940 --> 00:41:42,570
actual property

1170
00:41:43,090 --> 00:41:47,740
at the fact that we the insurers who if

1171
00:41:46,090 --> 00:41:50,680
you tangle

1172
00:41:47,740 --> 00:41:52,368
we need actuarial data on the wrist

1173
00:41:50,680 --> 00:41:53,839
posture of your organization

1174
00:41:52,369 --> 00:41:56,059
and that would be sort of the

1175
00:41:53,839 --> 00:41:58,940
anonymizing that temperatures they will

1176
00:41:56,059 --> 00:42:01,130
appear to be yeah but more like the

1177
00:41:58,940 --> 00:42:04,299
progressive plug into your car and drive

1178
00:42:01,130 --> 00:42:04,299
a certain way thing

1179
00:42:06,940 --> 00:42:11,210
the question I want us to comment about

1180
00:42:09,380 --> 00:42:15,440
you know one of the problems is that we

1181
00:42:11,210 --> 00:42:25,359
don't have disability into tools and

1182
00:42:15,440 --> 00:42:29,140
technology around

1183
00:42:25,359 --> 00:42:32,730
I want to get them to pay that

1184
00:42:29,140 --> 00:42:35,710
thoughts on is there a way to get more

1185
00:42:32,730 --> 00:42:37,779
transparency there well what type of

1186
00:42:35,710 --> 00:42:40,769
value that you extract from better

1187
00:42:37,779 --> 00:42:40,769
knowledge of what

1188
00:42:42,610 --> 00:42:47,630
yeah I mean so I I try to model the

1189
00:42:45,950 --> 00:42:49,879
attackers behavior in doing this right

1190
00:42:47,630 --> 00:42:51,590
that back at my organization what I try

1191
00:42:49,880 --> 00:42:53,120
to do is go further than just Metasploit

1192
00:42:51,590 --> 00:42:55,190
and model out the whole thing the whole

1193
00:42:53,120 --> 00:42:56,600
attack kind of like how useful is this

1194
00:42:55,190 --> 00:43:00,320
vulnerability to an attacker what's the

1195
00:42:56,600 --> 00:43:04,490
probability it'll get exploited having

1196
00:43:00,320 --> 00:43:06,620
both the entries in exploit kits and the

1197
00:43:04,490 --> 00:43:08,649
price of firing one off would make that

1198
00:43:06,620 --> 00:43:11,120
economic decision much easier for me and

1199
00:43:08,650 --> 00:43:12,500
I've been thinking about how there's

1200
00:43:11,120 --> 00:43:16,520
researchers at the University of Trento

1201
00:43:12,500 --> 00:43:18,140
Luka Adi specifically who does this kind

1202
00:43:16,520 --> 00:43:20,150
of crawling and finds all the blackhat

1203
00:43:18,140 --> 00:43:22,339
exploit kits across like 80 different

1204
00:43:20,150 --> 00:43:24,170
forums and he has some scripts that

1205
00:43:22,340 --> 00:43:26,330
screen scrape sometimes he logs in

1206
00:43:24,170 --> 00:43:29,720
manually sometimes it has to be through

1207
00:43:26,330 --> 00:43:31,549
tor this is a service would be a huge

1208
00:43:29,720 --> 00:43:33,140
benefit to the whole community I can't

1209
00:43:31,550 --> 00:43:34,640
think of a great scalable way to do it

1210
00:43:33,140 --> 00:43:35,930
especially because as soon as somebody

1211
00:43:34,640 --> 00:43:37,460
realizes they're being crawled this

1212
00:43:35,930 --> 00:43:38,750
isn't like what I crawled Metasploit

1213
00:43:37,460 --> 00:43:40,910
rapid someone's like great people are

1214
00:43:38,750 --> 00:43:42,230
using my product when you crawl a

1215
00:43:40,910 --> 00:43:48,680
blackhead exploit can't they're like

1216
00:43:42,230 --> 00:43:50,000
great I'm going to switch the IP so if

1217
00:43:48,680 --> 00:43:52,700
anybody can solve that problem I will

1218
00:43:50,000 --> 00:43:54,820
pay you money literally my organization

1219
00:43:52,700 --> 00:43:54,819
will

1220
00:43:55,340 --> 00:43:57,940
yeah

1221
00:44:02,040 --> 00:44:04,850
yes

1222
00:44:06,759 --> 00:44:15,799
white people get back right so what

1223
00:44:10,759 --> 00:44:18,049
you're saying is and there's a traffic

1224
00:44:15,799 --> 00:44:20,269
ESN attack signature that if they

1225
00:44:18,049 --> 00:44:24,700
successfully use that doesn't mean

1226
00:44:20,269 --> 00:44:28,549
necessarily that something of value was

1227
00:44:24,700 --> 00:44:31,450
something right right doesn't even mean

1228
00:44:28,550 --> 00:44:31,450
it was really breached

1229
00:44:31,510 --> 00:44:39,770
if only based on fixing something that

1230
00:44:35,960 --> 00:44:41,840
may expose something now my success

1231
00:44:39,770 --> 00:44:43,520
criteria is code running for an exploit

1232
00:44:41,840 --> 00:44:49,270
right it's like the loosest of success

1233
00:44:43,520 --> 00:44:51,470
criteria is possible tightening it up

1234
00:44:49,270 --> 00:44:53,390
it's a good conversation to have so I

1235
00:44:51,470 --> 00:44:55,790
don't actually do the percolation

1236
00:44:53,390 --> 00:44:56,960
analysis of this I set those rules when

1237
00:44:55,790 --> 00:44:58,670
I make partnerships with the threat

1238
00:44:56,960 --> 00:45:00,350
intelligence companies and say you guys

1239
00:44:58,670 --> 00:45:02,000
get a lot of aggregate data here's what

1240
00:45:00,350 --> 00:45:04,670
I want you to send back to me percolate

1241
00:45:02,000 --> 00:45:05,810
it through this and your suggestion is

1242
00:45:04,670 --> 00:45:07,460
actually pretty awesome what if I only

1243
00:45:05,810 --> 00:45:09,650
take the things that have a confidential

1244
00:45:07,460 --> 00:45:10,670
impact of high and percolate through

1245
00:45:09,650 --> 00:45:12,350
that and then compare it to the other

1246
00:45:10,670 --> 00:45:16,600
one that's actually a really sweet idea

1247
00:45:12,350 --> 00:45:16,600
I would guess that

1248
00:45:17,700 --> 00:45:21,960
what would intuitively happen so you

1249
00:45:20,700 --> 00:45:24,710
would be able to design a much more

1250
00:45:21,960 --> 00:45:27,710
specific test for those vulnerabilities

1251
00:45:24,710 --> 00:45:27,710
yeah

1252
00:45:27,930 --> 00:45:30,859
it's a great idea

1253
00:45:37,480 --> 00:45:41,050
cool thank you

1254
00:45:43,090 --> 00:45:47,679
[Applause]

