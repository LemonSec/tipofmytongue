1
00:00:05,550 --> 00:00:10,590
so TM today is going to talk about zero

2
00:00:08,430 --> 00:00:12,660
trust architecture which is one of those

3
00:00:10,590 --> 00:00:17,670
nice fun buzzwords we keep hearing at

4
00:00:12,660 --> 00:00:20,400
the moment let me scroll down here we go

5
00:00:17,670 --> 00:00:22,920
so TM is the security chief technologist

6
00:00:20,400 --> 00:00:24,479
within DXi technology he's chiefly

7
00:00:22,920 --> 00:00:26,400
responsible for cyber security thought

8
00:00:24,480 --> 00:00:28,109
leadership as well as a research and

9
00:00:26,400 --> 00:00:31,470
development activities for DXE security

10
00:00:28,109 --> 00:00:33,830
worldwide so with out further ado TM

11
00:00:31,470 --> 00:00:36,540
feel free to take it away

12
00:00:33,830 --> 00:00:38,699
thank you can you hear me yes we can

13
00:00:36,540 --> 00:00:41,790
hear you okay I'm going to switch over

14
00:00:38,700 --> 00:00:43,860
to my slide i-i've done everyone I'm so

15
00:00:41,790 --> 00:00:46,010
excited to be addressing a number of

16
00:00:43,860 --> 00:00:49,110
Australian and a number of overseas

17
00:00:46,010 --> 00:00:50,940
viewers I wouldn't go too much into my

18
00:00:49,110 --> 00:00:52,950
introduction Ian has done a great job

19
00:00:50,940 --> 00:00:54,599
introducing me so I'll jump just jump

20
00:00:52,950 --> 00:00:56,370
right into my presentation because this

21
00:00:54,600 --> 00:00:58,559
is going to be a lightning talk I'm only

22
00:00:56,370 --> 00:01:01,140
given 10 minutes and you notice I talk

23
00:00:58,559 --> 00:01:03,239
very very fast so I'll try to squeeze as

24
00:01:01,140 --> 00:01:06,690
many stuff within this 10 minute time

25
00:01:03,239 --> 00:01:08,610
frame so first of all why did I prepare

26
00:01:06,690 --> 00:01:10,679
this talk I prepare this talk because I

27
00:01:08,610 --> 00:01:13,140
was frustrated I was frustrated because

28
00:01:10,680 --> 00:01:15,299
in the last two months when I came back

29
00:01:13,140 --> 00:01:18,270
from RSA Conference I was in RSA

30
00:01:15,299 --> 00:01:20,280
Conference everybody was telling we have

31
00:01:18,270 --> 00:01:22,530
zero trust products and I was like no

32
00:01:20,280 --> 00:01:24,930
your product doesn't there's not a zero

33
00:01:22,530 --> 00:01:26,430
trans product zero product since that

34
00:01:24,930 --> 00:01:28,860
zero trust you know probably is a

35
00:01:26,430 --> 00:01:30,000
buzzword and and and there's a couple of

36
00:01:28,860 --> 00:01:31,049
vendors they were talking about oh you

37
00:01:30,000 --> 00:01:33,150
know we have micro segmentation

38
00:01:31,049 --> 00:01:35,460
therefore you have zero trust I was like

39
00:01:33,150 --> 00:01:38,640
I was like facepalm all right that's not

40
00:01:35,460 --> 00:01:41,399
zero trust and and what became apparent

41
00:01:38,640 --> 00:01:45,090
when I was in RAC conference was that

42
00:01:41,400 --> 00:01:46,920
term I had a privilege to go into some

43
00:01:45,090 --> 00:01:48,420
private conversations with specific

44
00:01:46,920 --> 00:01:49,740
vendors and they were all talking about

45
00:01:48,420 --> 00:01:52,049
what they were doing is zero trust and

46
00:01:49,740 --> 00:01:53,640
and I asked the number of people and in

47
00:01:52,049 --> 00:01:56,130
the room and ask them what is your

48
00:01:53,640 --> 00:01:57,750
definition of zero trust and they all

49
00:01:56,130 --> 00:01:59,970
look at me and it's like yeah that's a

50
00:01:57,750 --> 00:02:01,439
good question um what is a clear zero

51
00:01:59,970 --> 00:02:03,329
trust you know everybody has their own

52
00:02:01,439 --> 00:02:04,648
definitions of zero trust and here's the

53
00:02:03,329 --> 00:02:08,190
problem there's no definition of zero

54
00:02:04,649 --> 00:02:09,750
trust in the industry yet so what I want

55
00:02:08,190 --> 00:02:11,370
to do in the next nine minutes is to

56
00:02:09,750 --> 00:02:14,450
really walk everyone through right what

57
00:02:11,370 --> 00:02:18,120
what zero trust should be all about

58
00:02:14,450 --> 00:02:18,329
likes light now before we start have a

59
00:02:18,120 --> 00:02:30,060
look

60
00:02:18,330 --> 00:02:33,000
this video okay that my friend

61
00:02:30,060 --> 00:02:35,580
everybody that is zero trust that video

62
00:02:33,000 --> 00:02:37,770
was taken in Philippines in a in a more

63
00:02:35,580 --> 00:02:39,660
and and I'm going to make reference to

64
00:02:37,770 --> 00:02:42,420
that video later drop the whole

65
00:02:39,660 --> 00:02:44,340
presentation and and it because it's

66
00:02:42,420 --> 00:02:44,730
important to understand true that video

67
00:02:44,340 --> 00:02:47,430
alone

68
00:02:44,730 --> 00:02:49,049
what zero trust I solve all sorry

69
00:02:47,430 --> 00:02:50,690
they're in charge am I don't think your

70
00:02:49,050 --> 00:02:52,050
slides are showing at the moment oh

71
00:02:50,690 --> 00:02:54,600
sorry sorry

72
00:02:52,050 --> 00:02:59,940
oh gosh I'm so sorry I know why I know

73
00:02:54,600 --> 00:03:02,160
why okay guys sorry I'm I I have I know

74
00:02:59,940 --> 00:03:04,560
what happens I'm so sorry I'm gonna

75
00:03:02,160 --> 00:03:06,680
start over again at the start of the

76
00:03:04,560 --> 00:03:09,140
yeah go for it

77
00:03:06,680 --> 00:03:12,690
okay so so sorry

78
00:03:09,140 --> 00:03:16,559
okay I'm going to I believe you can see

79
00:03:12,690 --> 00:03:19,470
this like no yes we can see the slides

80
00:03:16,560 --> 00:03:21,740
now okay oh no play the video one more

81
00:03:19,470 --> 00:03:21,740
time

82
00:03:34,269 --> 00:03:37,970
okay

83
00:03:35,480 --> 00:03:39,950
so I hope this little 15-second snippets

84
00:03:37,970 --> 00:03:41,780
our video gives you an idea what's your

85
00:03:39,950 --> 00:03:44,060
class is about it was taken in

86
00:03:41,780 --> 00:03:46,879
Philippines more and the link is there

87
00:03:44,060 --> 00:03:49,040
if you want to see a better version of

88
00:03:46,879 --> 00:03:50,390
it and in the rest of my presentation I

89
00:03:49,040 --> 00:03:53,090
will actually make reference to this

90
00:03:50,390 --> 00:03:54,319
like so what is zero trust I won't go

91
00:03:53,090 --> 00:03:56,480
into the definition because the

92
00:03:54,319 --> 00:03:58,819
definition itself right is is this is

93
00:03:56,480 --> 00:04:00,980
there's many interpretations to it but

94
00:03:58,819 --> 00:04:02,510
I'll just give probably four words for

95
00:04:00,980 --> 00:04:04,399
everyone to take away in this

96
00:04:02,510 --> 00:04:09,260
presentation

97
00:04:04,400 --> 00:04:12,950
never trust always verify it is the

98
00:04:09,260 --> 00:04:14,569
opposite of the security way of doing

99
00:04:12,950 --> 00:04:18,108
things in the past where we always use

100
00:04:14,569 --> 00:04:21,199
the word trust but verify now because

101
00:04:18,108 --> 00:04:22,490
the concept is so different it is going

102
00:04:21,199 --> 00:04:24,740
to change the way how we do

103
00:04:22,490 --> 00:04:26,960
cybersecurity management in the coming

104
00:04:24,740 --> 00:04:29,600
years and and and it's actually a better

105
00:04:26,960 --> 00:04:31,880
way of doing things and so why why why

106
00:04:29,600 --> 00:04:35,389
why companies should be doing zero trust

107
00:04:31,880 --> 00:04:37,599
the reason is very simple we in the

108
00:04:35,389 --> 00:04:41,690
security industry has always advocated

109
00:04:37,599 --> 00:04:43,849
deny or you know allow some assess

110
00:04:41,690 --> 00:04:46,219
management it has been a very hard

111
00:04:43,849 --> 00:04:49,280
process in the last 20 years but

112
00:04:46,220 --> 00:04:52,460
progressively as the industry has mature

113
00:04:49,280 --> 00:04:54,260
the a lot of organizations are starting

114
00:04:52,460 --> 00:04:55,760
to think that this is actually within

115
00:04:54,260 --> 00:04:57,860
their reach and is actually known much

116
00:04:55,760 --> 00:04:59,960
possible and technology security

117
00:04:57,860 --> 00:05:02,300
technology has evolved massively in the

118
00:04:59,960 --> 00:05:05,210
last five years such that the concept of

119
00:05:02,300 --> 00:05:08,150
zero trust implementation right will

120
00:05:05,210 --> 00:05:10,219
become easier in time to come so how do

121
00:05:08,150 --> 00:05:11,719
you actually what are the four key

122
00:05:10,220 --> 00:05:14,810
things you need to take note when you

123
00:05:11,720 --> 00:05:17,150
want to do zero trust first you need to

124
00:05:14,810 --> 00:05:19,580
be absolutely you need to have good

125
00:05:17,150 --> 00:05:21,650
situational awareness of what other SS

126
00:05:19,580 --> 00:05:24,260
to assess you have to understand when

127
00:05:21,650 --> 00:05:26,388
you assess any data any network any

128
00:05:24,260 --> 00:05:28,610
piece of information on your environment

129
00:05:26,389 --> 00:05:31,039
you need to actually visualize and think

130
00:05:28,610 --> 00:05:33,050
about who is going to assess the and how

131
00:05:31,039 --> 00:05:35,150
are they going to assay understanding

132
00:05:33,050 --> 00:05:37,970
this this SS is very important because

133
00:05:35,150 --> 00:05:40,039
you cannot lock down if you have no idea

134
00:05:37,970 --> 00:05:42,289
how those assets are going to be SS so

135
00:05:40,039 --> 00:05:44,570
this is the very important thing the

136
00:05:42,289 --> 00:05:45,590
next thing is this for those people who

137
00:05:44,570 --> 00:05:47,390
have actually can come

138
00:05:45,590 --> 00:05:49,669
the concept of zero trust when googas

139
00:05:47,390 --> 00:05:50,960
not being caught in 2014 one of the

140
00:05:49,670 --> 00:05:52,340
first thing that you written in the

141
00:05:50,960 --> 00:05:54,049
stuff that they have shed when they

142
00:05:52,340 --> 00:05:55,700
written a book about it is that they

143
00:05:54,050 --> 00:05:58,190
talk about the importance of a

144
00:05:55,700 --> 00:06:01,039
centralized identity framework and this

145
00:05:58,190 --> 00:06:02,690
is very important you can't do propose

146
00:06:01,040 --> 00:06:06,110
zero trust if you're going to have a

147
00:06:02,690 --> 00:06:08,600
fragmented ident different all the

148
00:06:06,110 --> 00:06:10,100
absence of identity framework so one of

149
00:06:08,600 --> 00:06:12,200
the common problems that I have observed

150
00:06:10,100 --> 00:06:14,570
in in most organizations is that they

151
00:06:12,200 --> 00:06:15,950
haven't I they have an ad environment

152
00:06:14,570 --> 00:06:18,469
they authenticate most of the users and

153
00:06:15,950 --> 00:06:19,729
then in some of the IT systems they

154
00:06:18,470 --> 00:06:22,340
actually create a separate

155
00:06:19,730 --> 00:06:25,370
authentication systems using a series of

156
00:06:22,340 --> 00:06:27,890
SSH SS which which will actually break

157
00:06:25,370 --> 00:06:30,550
on zero trust if you're going to start

158
00:06:27,890 --> 00:06:33,680
authenticating people using disparate

159
00:06:30,550 --> 00:06:36,680
identification framework the third thing

160
00:06:33,680 --> 00:06:40,190
is that this is this is the the hot part

161
00:06:36,680 --> 00:06:42,160
is that once you have memo the SS to the

162
00:06:40,190 --> 00:06:44,719
SS once you have a centralized

163
00:06:42,160 --> 00:06:46,640
identification framework in place you no

164
00:06:44,720 --> 00:06:48,290
need to build a policies and I will tell

165
00:06:46,640 --> 00:06:50,630
right now the biggest thing in the

166
00:06:48,290 --> 00:06:52,730
biggest challenges in in zero trust

167
00:06:50,630 --> 00:06:55,640
implementation is actually building this

168
00:06:52,730 --> 00:06:57,530
policy because zero trust is is only

169
00:06:55,640 --> 00:07:00,400
made possible if you build a robust

170
00:06:57,530 --> 00:07:02,690
policies to say who can assess what

171
00:07:00,400 --> 00:07:04,969
underwent conditions and how they can

172
00:07:02,690 --> 00:07:07,070
assess it and and then the kipling

173
00:07:04,970 --> 00:07:11,540
method right is actually the hole where

174
00:07:07,070 --> 00:07:14,630
the who what where how when and and and

175
00:07:11,540 --> 00:07:16,940
the wine okay so you need to build a

176
00:07:14,630 --> 00:07:18,860
policy framework to actually look at the

177
00:07:16,940 --> 00:07:21,560
SS right and actually answers those six

178
00:07:18,860 --> 00:07:22,160
questions and if you build a framework

179
00:07:21,560 --> 00:07:24,380
around it

180
00:07:22,160 --> 00:07:27,260
you are now starting to put a real

181
00:07:24,380 --> 00:07:31,159
control around who and how the SS are to

182
00:07:27,260 --> 00:07:36,159
be SS in the proper in a proper manner

183
00:07:31,160 --> 00:07:38,840
and one last thing you have to always

184
00:07:36,160 --> 00:07:40,940
monitor your environment the minute to

185
00:07:38,840 --> 00:07:43,159
implement zero trust and let me explain

186
00:07:40,940 --> 00:07:45,980
why the whole concept of zero trust is

187
00:07:43,160 --> 00:07:49,580
this is that you know effectively have

188
00:07:45,980 --> 00:07:54,320
created what we call a large skill what

189
00:07:49,580 --> 00:07:59,530
listing framework and if someone tries

190
00:07:54,320 --> 00:08:02,180
to bypass this whole framework

191
00:07:59,530 --> 00:08:04,729
something will trigger okay it will

192
00:08:02,180 --> 00:08:08,480
probably it it would be probably easier

193
00:08:04,730 --> 00:08:10,790
to monitor anomalous SS anomalous

194
00:08:08,480 --> 00:08:15,200
behavior true as you're transferring and

195
00:08:10,790 --> 00:08:17,570
because it's gonna be is gonna be is

196
00:08:15,200 --> 00:08:20,090
it's gonna be triggered much easier if

197
00:08:17,570 --> 00:08:22,250
it is a bad behavior it means that right

198
00:08:20,090 --> 00:08:25,010
the the fidelity of this this this

199
00:08:22,250 --> 00:08:27,380
anomalous SS is very high in the sense

200
00:08:25,010 --> 00:08:30,440
that it could probably potentially be

201
00:08:27,380 --> 00:08:33,679
something that requires an investigation

202
00:08:30,440 --> 00:08:36,590
why that SS is being made and and was

203
00:08:33,679 --> 00:08:38,510
triggered so if you do not monitor the

204
00:08:36,590 --> 00:08:40,670
whole purpose of implementing zero trust

205
00:08:38,510 --> 00:08:42,169
is going to go down the drain

206
00:08:40,669 --> 00:08:45,500
so you actually have the monitor

207
00:08:42,169 --> 00:08:48,079
continuously on the flip side because

208
00:08:45,500 --> 00:08:50,500
you have already created a very strong

209
00:08:48,080 --> 00:08:53,810
robust framework to allow SS to the SS

210
00:08:50,500 --> 00:08:56,630
always remember company process change

211
00:08:53,810 --> 00:08:59,510
business change the SS to the SS will

212
00:08:56,630 --> 00:09:01,100
also continuously change because people

213
00:08:59,510 --> 00:09:02,660
come and go so you actually have to also

214
00:09:01,100 --> 00:09:05,360
monitor to make sure that even if this

215
00:09:02,660 --> 00:09:08,030
approve SS today it may have to change

216
00:09:05,360 --> 00:09:09,620
tomorrow so so these are the four key

217
00:09:08,030 --> 00:09:12,040
things to take note when you're going to

218
00:09:09,620 --> 00:09:14,480
implement zero trust in your environment

219
00:09:12,040 --> 00:09:16,459
there are actually three enforcement

220
00:09:14,480 --> 00:09:18,830
layers when you increment zero trust

221
00:09:16,460 --> 00:09:21,770
okay infrastructure that's probably the

222
00:09:18,830 --> 00:09:24,410
most common on implementation that every

223
00:09:21,770 --> 00:09:27,560
pipe is aware of through the concept of

224
00:09:24,410 --> 00:09:29,630
micro segmentation but zero trust is

225
00:09:27,560 --> 00:09:33,020
actually goes way more than just micro

226
00:09:29,630 --> 00:09:35,510
segmentation it also talks about at the

227
00:09:33,020 --> 00:09:37,130
container level when they talk to when

228
00:09:35,510 --> 00:09:39,350
you have a continuous spinning of and

229
00:09:37,130 --> 00:09:41,500
talking to another entity such as like a

230
00:09:39,350 --> 00:09:44,210
surveillance function you can have a

231
00:09:41,500 --> 00:09:45,770
container service function talking to

232
00:09:44,210 --> 00:09:47,780
inner service function so all these

233
00:09:45,770 --> 00:09:49,370
forms part of the infrastructure so it's

234
00:09:47,780 --> 00:09:51,589
not necessarily just about micro

235
00:09:49,370 --> 00:09:55,430
segmentation or preventing electro

236
00:09:51,590 --> 00:09:57,680
movement from a PCA to PCB the next

237
00:09:55,430 --> 00:09:59,089
enforcement layer is identity and this

238
00:09:57,680 --> 00:10:01,280
is where it becomes interesting because

239
00:09:59,090 --> 00:10:03,440
zero trust is more than just

240
00:10:01,280 --> 00:10:06,589
infrastructure zero trust can also be

241
00:10:03,440 --> 00:10:08,480
applied to identity okay I'll give one a

242
00:10:06,590 --> 00:10:11,660
one good example of what is zero trust

243
00:10:08,480 --> 00:10:13,010
in the in the identity we'll a lot of

244
00:10:11,660 --> 00:10:14,839
you probably have login

245
00:10:13,010 --> 00:10:16,580
web servers they will ask you to provide

246
00:10:14,840 --> 00:10:18,470
username and password you probably

247
00:10:16,580 --> 00:10:20,060
looking to assess a website they will

248
00:10:18,470 --> 00:10:21,800
provide you a silver certificate and

249
00:10:20,060 --> 00:10:24,650
then you can prove that yes I'm visiting

250
00:10:21,800 --> 00:10:27,469
this website but here's the thing has

251
00:10:24,650 --> 00:10:28,810
the website ever authenticate you as the

252
00:10:27,470 --> 00:10:31,820
user okay

253
00:10:28,810 --> 00:10:33,650
when SSL was invented it was conceived

254
00:10:31,820 --> 00:10:35,990
with the mind that both the server as

255
00:10:33,650 --> 00:10:37,490
well as the end-user they have

256
00:10:35,990 --> 00:10:39,230
certificates that can authentication

257
00:10:37,490 --> 00:10:41,750
other before they can proceed with the

258
00:10:39,230 --> 00:10:43,940
transaction it was very hot dogs yes but

259
00:10:41,750 --> 00:10:46,460
in today um when the whole concept of

260
00:10:43,940 --> 00:10:49,250
PGI and identification has largely been

261
00:10:46,460 --> 00:10:51,650
automated um it is now actually easier

262
00:10:49,250 --> 00:10:53,090
to actually do mutual authentication so

263
00:10:51,650 --> 00:10:55,370
if you seen the video earlier right

264
00:10:53,090 --> 00:10:56,780
where the the security guard was

265
00:10:55,370 --> 00:10:59,000
actually doing a temperature check on

266
00:10:56,780 --> 00:11:00,890
the user coming the user was actually

267
00:10:59,000 --> 00:11:02,540
doing a temperature check back on the

268
00:11:00,890 --> 00:11:05,210
security guard because how do I know

269
00:11:02,540 --> 00:11:07,010
that you know you can also be trusted so

270
00:11:05,210 --> 00:11:09,610
that mutual authentication is very

271
00:11:07,010 --> 00:11:12,800
important so and it fits the example of

272
00:11:09,610 --> 00:11:14,450
never trust always verify not from just

273
00:11:12,800 --> 00:11:16,910
from the server perspective from the

274
00:11:14,450 --> 00:11:19,220
user you also have to protect a practice

275
00:11:16,910 --> 00:11:21,579
zero trust as well back to the asset

276
00:11:19,220 --> 00:11:25,310
that you're you're you're assessing

277
00:11:21,580 --> 00:11:29,390
lastly data you can actually enforce

278
00:11:25,310 --> 00:11:31,849
data zero protection on data access and

279
00:11:29,390 --> 00:11:33,620
there are one key aspect that I I would

280
00:11:31,850 --> 00:11:34,880
like everyone to two key especial

281
00:11:33,620 --> 00:11:36,530
actually like everyone to take note

282
00:11:34,880 --> 00:11:40,820
about how you can enforce your trust on

283
00:11:36,530 --> 00:11:42,560
data um there has some data pseudo

284
00:11:40,820 --> 00:11:45,230
randomization is starting to become very

285
00:11:42,560 --> 00:11:47,359
important from the analytics point of

286
00:11:45,230 --> 00:11:49,850
view um a lot of business analysts right

287
00:11:47,360 --> 00:11:51,950
what tends to dump the data right out

288
00:11:49,850 --> 00:11:54,200
from a date DB right to perform business

289
00:11:51,950 --> 00:11:56,180
analytics actually they don't need to do

290
00:11:54,200 --> 00:11:58,100
that you can actually only share certain

291
00:11:56,180 --> 00:12:00,560
information randomize the information

292
00:11:58,100 --> 00:12:02,270
and pass it to the business analyst

293
00:12:00,560 --> 00:12:03,739
right to do their analytics so that's

294
00:12:02,270 --> 00:12:05,689
one aspect of it the other is probably

295
00:12:03,740 --> 00:12:07,490
which is a very new interesting research

296
00:12:05,690 --> 00:12:09,050
is that you can actually do business

297
00:12:07,490 --> 00:12:10,880
analytics right through an encrypted

298
00:12:09,050 --> 00:12:12,560
Channel okay you never see what the

299
00:12:10,880 --> 00:12:13,730
contents are inside encrypts channel but

300
00:12:12,560 --> 00:12:15,880
there is a way know that they can

301
00:12:13,730 --> 00:12:19,010
actually do some analytics of the

302
00:12:15,880 --> 00:12:23,090
information that's inside a encrypted

303
00:12:19,010 --> 00:12:24,830
and conclave know how to start on the

304
00:12:23,090 --> 00:12:26,870
zero trans journey now this is going to

305
00:12:24,830 --> 00:12:29,180
be a conversation for those people who

306
00:12:26,870 --> 00:12:30,529
who are decision makers and probably

307
00:12:29,180 --> 00:12:32,569
those people who are being cast Oh

308
00:12:30,529 --> 00:12:33,800
actually it's not zero trust and and

309
00:12:32,570 --> 00:12:34,250
they were struggling hard where do we

310
00:12:33,800 --> 00:12:37,339
start

311
00:12:34,250 --> 00:12:39,529
um you can my suggestions is actually a

312
00:12:37,339 --> 00:12:41,570
couple of areas always start from

313
00:12:39,529 --> 00:12:44,600
Greenfield and and the reason is this

314
00:12:41,570 --> 00:12:47,510
when you start from Greenfield you you

315
00:12:44,600 --> 00:12:51,020
can contain the the learning to a

316
00:12:47,510 --> 00:12:52,670
particular a small area and even if it

317
00:12:51,020 --> 00:12:54,860
feels right you know you do not impact

318
00:12:52,670 --> 00:12:56,689
with your the rest of the general

319
00:12:54,860 --> 00:12:58,610
environment and starting from Greenfield

320
00:12:56,690 --> 00:13:01,000
is is important is because this way you

321
00:12:58,610 --> 00:13:03,170
actually start to learn about

322
00:13:01,000 --> 00:13:06,350
inculcating the concepts of zero trust

323
00:13:03,170 --> 00:13:07,939
very slowly into your environment which

324
00:13:06,350 --> 00:13:09,860
then leads me to the next point okay

325
00:13:07,940 --> 00:13:12,350
always implement in phases

326
00:13:09,860 --> 00:13:14,960
do not try to implement zero trust you

327
00:13:12,350 --> 00:13:17,089
know as a as a big bang approach because

328
00:13:14,960 --> 00:13:18,950
we're going back to my point about in

329
00:13:17,089 --> 00:13:20,510
our SD conference people start buying is

330
00:13:18,950 --> 00:13:21,920
your trust products and then they start

331
00:13:20,510 --> 00:13:24,920
trying to implement in the whole company

332
00:13:21,920 --> 00:13:26,569
it is gonna feel very badly but lastly

333
00:13:24,920 --> 00:13:28,790
the most important thing about when you

334
00:13:26,570 --> 00:13:30,080
starts the zero trans journey you have

335
00:13:28,790 --> 00:13:32,120
to change the security management

336
00:13:30,080 --> 00:13:34,430
culture inside your organization because

337
00:13:32,120 --> 00:13:36,350
I can tell you it is really very hard to

338
00:13:34,430 --> 00:13:39,319
tell people that from now on you got to

339
00:13:36,350 --> 00:13:41,330
you got to actually memo and and and and

340
00:13:39,320 --> 00:13:43,400
understand how you assess the essay okay

341
00:13:41,330 --> 00:13:44,750
you have to challenge everybody or

342
00:13:43,400 --> 00:13:46,880
everything that is being you know

343
00:13:44,750 --> 00:13:48,800
there's trying to assess I said it is

344
00:13:46,880 --> 00:13:50,689
going to change and break the way how

345
00:13:48,800 --> 00:13:52,250
people operate so changing the culture

346
00:13:50,690 --> 00:13:53,690
is very important if you want to start

347
00:13:52,250 --> 00:13:55,959
because it is a very different way of

348
00:13:53,690 --> 00:13:57,860
doing six hour security management

349
00:13:55,959 --> 00:14:00,140
there's a couple of applicable

350
00:13:57,860 --> 00:14:02,120
industries on health care they tends to

351
00:14:00,140 --> 00:14:06,740
have a flat network zero trust can

352
00:14:02,120 --> 00:14:08,959
actually help in in securing the medical

353
00:14:06,740 --> 00:14:13,580
devices very quickly through some of

354
00:14:08,959 --> 00:14:16,699
these uh micro segmentation technology

355
00:14:13,580 --> 00:14:20,240
any industry OT environment um is also a

356
00:14:16,700 --> 00:14:22,430
good is also a good use case four four

357
00:14:20,240 --> 00:14:24,230
four zero trust and lastly financial and

358
00:14:22,430 --> 00:14:25,849
riku industry absolutely useful

359
00:14:24,230 --> 00:14:27,650
especially when there's very concerned

360
00:14:25,850 --> 00:14:29,570
about a point-of-sale machine you know

361
00:14:27,650 --> 00:14:32,510
assessing the corporate network and

362
00:14:29,570 --> 00:14:36,020
anything that deals with money away from

363
00:14:32,510 --> 00:14:37,579
the corporate network so to wrap up I

364
00:14:36,020 --> 00:14:39,740
only have one minute left I want

365
00:14:37,579 --> 00:14:40,520
everyone to take away three key message

366
00:14:39,740 --> 00:14:44,780
about what

367
00:14:40,520 --> 00:14:47,180
you're us it is not a product and it is

368
00:14:44,780 --> 00:14:49,819
all about the behavior of how you treat

369
00:14:47,180 --> 00:14:51,620
cybersecurity management this is

370
00:14:49,820 --> 00:14:53,000
important because if anybody tells you

371
00:14:51,620 --> 00:14:55,040
right now in the market that we have a

372
00:14:53,000 --> 00:14:58,100
zero trans product there is a buzzword

373
00:14:55,040 --> 00:15:00,650
okay and I have to set this expectation

374
00:14:58,100 --> 00:15:03,020
it is very hot okay

375
00:15:00,650 --> 00:15:06,110
but if you do it right I can assure you

376
00:15:03,020 --> 00:15:08,390
it is a very future proof of a way of

377
00:15:06,110 --> 00:15:10,250
actually protecting your environment and

378
00:15:08,390 --> 00:15:11,810
with that I'll thank you very much for

379
00:15:10,250 --> 00:15:13,070
your taking your time out you know on a

380
00:15:11,810 --> 00:15:15,199
good Friday to listen to my presentation

381
00:15:13,070 --> 00:15:17,960
I look forward to speak to you guys

382
00:15:15,200 --> 00:15:20,030
again thank you very much thank you very

383
00:15:17,960 --> 00:15:22,220
much Tim and we actually do have a

384
00:15:20,030 --> 00:15:24,020
number of questions in the chat so if

385
00:15:22,220 --> 00:15:25,250
you have some time it would be great if

386
00:15:24,020 --> 00:15:27,020
you could answer those questions as well

387
00:15:25,250 --> 00:15:28,040
yes I will do that okay thank you very

388
00:15:27,020 --> 00:15:30,370
much and thanks everybody

389
00:15:28,040 --> 00:15:30,370
bye-bye

390
00:15:35,800 --> 00:15:37,859
you

