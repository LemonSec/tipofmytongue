1
00:00:00,030 --> 00:00:06,870
right good morning everybody and welcome

2
00:00:02,510 --> 00:00:08,760
to my session on how does a traditional

3
00:00:06,870 --> 00:00:12,540
security team cope with the move to

4
00:00:08,760 --> 00:00:14,428
DevOps give me an introduction about

5
00:00:12,540 --> 00:00:16,560
myself my name's Colin domine I

6
00:00:14,429 --> 00:00:18,990
currently work for a very code we've got

7
00:00:16,560 --> 00:00:21,000
a stand downstairs that's not why I'm

8
00:00:18,990 --> 00:00:23,549
here I'm here to talk to you about my

9
00:00:21,000 --> 00:00:27,439
experience having build secure systems

10
00:00:23,550 --> 00:00:29,310
I've got a background in embedded and

11
00:00:27,439 --> 00:00:32,399
communications technology I've done

12
00:00:29,310 --> 00:00:34,860
medical and secure devices my last four

13
00:00:32,399 --> 00:00:37,140
years I spent building one of the

14
00:00:34,860 --> 00:00:40,980
largest application security programs at

15
00:00:37,140 --> 00:00:45,420
an investment bank here in London my

16
00:00:40,980 --> 00:00:46,919
first foray into that sort of arena and

17
00:00:45,420 --> 00:00:48,390
really this is a story not about the

18
00:00:46,920 --> 00:00:50,700
technology and there's a lot of techy

19
00:00:48,390 --> 00:00:53,129
guys there geeks here it's not about

20
00:00:50,700 --> 00:00:55,140
technology it's it's it's about people

21
00:00:53,129 --> 00:00:56,539
and it's about the lessons that we

22
00:00:55,140 --> 00:00:58,710
learned and it's about some of the

23
00:00:56,539 --> 00:01:01,140
preconceptions and the ideas that I had

24
00:00:58,710 --> 00:01:05,600
coming into that coming into that

25
00:01:01,140 --> 00:01:05,600
program and and the lessons I've learned

26
00:01:07,760 --> 00:01:13,710
so we made reference to Josh Corman only

27
00:01:11,159 --> 00:01:15,540
Elizabeth didn't talk I've built rugged

28
00:01:13,710 --> 00:01:18,000
systems and I think the thing that I've

29
00:01:15,540 --> 00:01:20,009
I've realized is that often the software

30
00:01:18,000 --> 00:01:21,360
that we develop lasts for much longer

31
00:01:20,009 --> 00:01:24,630
than we realize it's going to be in

32
00:01:21,360 --> 00:01:26,430
existence it gets attacked by people far

33
00:01:24,630 --> 00:01:28,170
more skilled than the people that wrote

34
00:01:26,430 --> 00:01:32,909
the software that's certainly the

35
00:01:28,170 --> 00:01:37,250
experience in my in my history in my

36
00:01:32,909 --> 00:01:39,990
time at the my investment paying job now

37
00:01:37,250 --> 00:01:41,909
there's a lot of cinema references in my

38
00:01:39,990 --> 00:01:44,250
talk there's a t-shirt to anybody who

39
00:01:41,909 --> 00:01:46,079
can get all of them the storyboard for

40
00:01:44,250 --> 00:01:47,670
today's discussion is how I build a

41
00:01:46,079 --> 00:01:49,889
security team I came into a role without

42
00:01:47,670 --> 00:01:52,229
any team I was the guy who built the

43
00:01:49,890 --> 00:01:53,970
team I had some preconceived ideas of

44
00:01:52,229 --> 00:01:55,409
what that team would look like what it

45
00:01:53,970 --> 00:01:57,210
ended up looking like was quite a lot

46
00:01:55,409 --> 00:02:00,329
different to to what you might have

47
00:01:57,210 --> 00:02:04,740
expected and there's a good story on how

48
00:02:00,329 --> 00:02:06,240
not to do development operations there's

49
00:02:04,740 --> 00:02:08,310
the difference between the develop and

50
00:02:06,240 --> 00:02:10,258
security that dialogue how they get

51
00:02:08,310 --> 00:02:11,459
things wrong the kind of discussions

52
00:02:10,258 --> 00:02:13,920
that are so happening the kind of

53
00:02:11,459 --> 00:02:15,330
messaging that I was seeing a security

54
00:02:13,920 --> 00:02:18,329
for going to our developers and weird

55
00:02:15,330 --> 00:02:20,819
all broke down we did things a little

56
00:02:18,330 --> 00:02:22,650
bit differently and I was a lot to some

57
00:02:20,819 --> 00:02:26,010
extent God lucky born out of ignorance

58
00:02:22,650 --> 00:02:28,110
we approach things differently I'm just

59
00:02:26,010 --> 00:02:30,329
going to talk about some of the the

60
00:02:28,110 --> 00:02:32,310
differences and and and and what we

61
00:02:30,330 --> 00:02:34,650
found there so when I started the

62
00:02:32,310 --> 00:02:36,900
program I was there the security guy in

63
00:02:34,650 --> 00:02:38,850
the organization and that's what I

64
00:02:36,900 --> 00:02:41,220
thought I needed and I thought I needed

65
00:02:38,850 --> 00:02:43,650
a hacker I thought I needed somebody who

66
00:02:41,220 --> 00:02:45,269
wrote code who could hack that's the

67
00:02:43,650 --> 00:02:47,670
type of person that I wanted to build up

68
00:02:45,269 --> 00:02:49,620
my my security program so I went to the

69
00:02:47,670 --> 00:02:52,530
Human Resources and I said right I need

70
00:02:49,620 --> 00:02:54,120
some some exit sick people and they

71
00:02:52,530 --> 00:02:57,060
brought me cars like this all right

72
00:02:54,120 --> 00:02:58,910
smart suits ties my whole load of

73
00:02:57,060 --> 00:03:00,900
certifications nothing wrong with that

74
00:02:58,910 --> 00:03:03,230
sure we've all got a couple of those but

75
00:03:00,900 --> 00:03:06,299
not really what what I was looking for

76
00:03:03,230 --> 00:03:09,600
in the environment so what I ended up

77
00:03:06,299 --> 00:03:12,480
getting through a through circumstances

78
00:03:09,600 --> 00:03:14,579
was a bunch of these guys so I got a

79
00:03:12,480 --> 00:03:16,950
bunch of kids who knew very little about

80
00:03:14,580 --> 00:03:19,620
AB SEC they had no preconceived ideas

81
00:03:16,950 --> 00:03:21,570
they they were open to learn they were

82
00:03:19,620 --> 00:03:24,209
malleable you could shape their thinking

83
00:03:21,570 --> 00:03:26,940
you could build a you could build a

84
00:03:24,209 --> 00:03:28,590
process around them and that's really

85
00:03:26,940 --> 00:03:31,680
their story that I'm going to share with

86
00:03:28,590 --> 00:03:34,130
you so sticking to that and cinematic

87
00:03:31,680 --> 00:03:37,260
references I'm going to give you a

88
00:03:34,130 --> 00:03:40,109
horror story Ryan Thomas is there this

89
00:03:37,260 --> 00:03:43,649
is a bit of a disaster it's a set here

90
00:03:40,109 --> 00:03:45,930
in London in England it's Friday it's

91
00:03:43,650 --> 00:03:47,760
coming up to six o'clock you're just

92
00:03:45,930 --> 00:03:50,120
getting ready to to go home so let's

93
00:03:47,760 --> 00:03:52,590
meet let's meet the hero of our story

94
00:03:50,120 --> 00:03:55,980
right that's our developer bright-eyed

95
00:03:52,590 --> 00:03:57,269
and enthusiastic they've got their new

96
00:03:55,980 --> 00:03:58,950
business application they're going to

97
00:03:57,269 --> 00:04:00,989
roll out a new trading platform they're

98
00:03:58,950 --> 00:04:02,670
using all the coolest technology they're

99
00:04:00,989 --> 00:04:05,100
rocking the stache - Jas

100
00:04:02,670 --> 00:04:07,290
eyebrow Jas whatever they've got it if

101
00:04:05,100 --> 00:04:09,810
it's brand new they've got the new

102
00:04:07,290 --> 00:04:12,030
technology stacks they're trying to do a

103
00:04:09,810 --> 00:04:13,829
release it's Friday afternoon they're

104
00:04:12,030 --> 00:04:16,019
doing a release let's have a look every

105
00:04:13,829 --> 00:04:18,090
every film has got a needs to have a

106
00:04:16,019 --> 00:04:20,789
sheriff right let's your share of 30

107
00:04:18,089 --> 00:04:23,489
operations guy who's an operations

108
00:04:20,789 --> 00:04:25,020
background here it is be careful all

109
00:04:23,490 --> 00:04:27,620
right they there's more of you there

110
00:04:25,020 --> 00:04:31,580
none of me

111
00:04:27,620 --> 00:04:35,040
our operations in an investment bank

112
00:04:31,580 --> 00:04:36,810
Gavin I know you from an investment bank

113
00:04:35,040 --> 00:04:40,500
how many other guys here from from

114
00:04:36,810 --> 00:04:43,680
banking organizations so operations guys

115
00:04:40,500 --> 00:04:44,670
sheriff is a pretty good character you

116
00:04:43,680 --> 00:04:47,040
know there might be running old

117
00:04:44,670 --> 00:04:49,860
antiquated systems they they rule that

118
00:04:47,040 --> 00:04:52,770
the turf it's their domain that's here

119
00:04:49,860 --> 00:04:54,420
Sheriff now who's the bad guy who's the

120
00:04:52,770 --> 00:04:57,330
villain and thus the monster the

121
00:04:54,420 --> 00:05:00,090
security team right I mean this is an

122
00:04:57,330 --> 00:05:01,940
evil guy it's a horrendous creature it's

123
00:05:00,090 --> 00:05:04,229
like a cross between Freddy Krueger and

124
00:05:01,940 --> 00:05:07,620
Frankenstein's monster let's have a look

125
00:05:04,230 --> 00:05:11,970
at him now of course it's me I was the

126
00:05:07,620 --> 00:05:14,880
security guy right so I was I was the

127
00:05:11,970 --> 00:05:17,340
guy who got to do that right so when our

128
00:05:14,880 --> 00:05:20,040
developer was doing a development stage

129
00:05:17,340 --> 00:05:21,960
he done his UAT and sydney was trying to

130
00:05:20,040 --> 00:05:24,410
deploy into production I was the guy who

131
00:05:21,960 --> 00:05:27,299
got to say stop you're not doing that

132
00:05:24,410 --> 00:05:30,240
you failed some environmental control on

133
00:05:27,300 --> 00:05:33,330
your on your hardware and the developer

134
00:05:30,240 --> 00:05:35,400
it's 20 to 6 on a Friday evening he

135
00:05:33,330 --> 00:05:36,780
doesn't know he doesn't know he's oxide

136
00:05:35,400 --> 00:05:38,609
form he's although he doesn't know what

137
00:05:36,780 --> 00:05:40,200
the operations people are or talking

138
00:05:38,610 --> 00:05:41,850
about he does and he doesn't understand

139
00:05:40,200 --> 00:05:43,770
their language so that was the breakdown

140
00:05:41,850 --> 00:05:46,740
that we used to see so we put a hard

141
00:05:43,770 --> 00:05:48,180
gate in production we thought that would

142
00:05:46,740 --> 00:05:49,770
drive the right behavior we thought

143
00:05:48,180 --> 00:05:51,360
would he stop people doing bad things

144
00:05:49,770 --> 00:05:53,669
and going into production that'll

145
00:05:51,360 --> 00:05:55,290
encourage the right behavior what we

146
00:05:53,670 --> 00:05:57,900
ended up seeing of course is that people

147
00:05:55,290 --> 00:05:59,340
simply stayed on the left as far as they

148
00:05:57,900 --> 00:06:01,349
could they did all their work they did

149
00:05:59,340 --> 00:06:02,969
all their development in development and

150
00:06:01,350 --> 00:06:05,790
only at the final point that they needed

151
00:06:02,970 --> 00:06:08,070
to go to production did they try and

152
00:06:05,790 --> 00:06:10,230
roll out of production that meant that

153
00:06:08,070 --> 00:06:10,680
people were developing on platforms that

154
00:06:10,230 --> 00:06:13,200
weren't

155
00:06:10,680 --> 00:06:15,420
production ready weren't hardened it

156
00:06:13,200 --> 00:06:17,580
drove entirely the wrong sort of

157
00:06:15,420 --> 00:06:20,040
behavior so that's like it takes four

158
00:06:17,580 --> 00:06:21,750
case of of how not to do it and if I

159
00:06:20,040 --> 00:06:23,250
could describe this kind of process

160
00:06:21,750 --> 00:06:24,510
that's the typical thing that you see in

161
00:06:23,250 --> 00:06:26,400
an organization like there's an

162
00:06:24,510 --> 00:06:29,310
organization that is a long way from

163
00:06:26,400 --> 00:06:31,080
being DevOps ready or DevOps capable I'm

164
00:06:29,310 --> 00:06:35,130
happy to chat to people afterwards about

165
00:06:31,080 --> 00:06:37,140
the views on that I think large banks

166
00:06:35,130 --> 00:06:39,300
they've still got a long way to go if I

167
00:06:37,140 --> 00:06:40,620
could sum up that in one word I'd say to

168
00:06:39,300 --> 00:06:42,419
reactive

169
00:06:40,620 --> 00:06:44,610
but the kind of languaging you hear from

170
00:06:42,419 --> 00:06:46,650
a language we heard from people was it's

171
00:06:44,610 --> 00:06:48,600
non-compliant it's not meeting policy

172
00:06:46,650 --> 00:06:50,729
it's been blocked you need an exception

173
00:06:48,600 --> 00:06:53,010
from senior management you need a risk

174
00:06:50,729 --> 00:06:55,050
acceptance there's a deadline we need to

175
00:06:53,010 --> 00:06:56,400
do a risk assessment all good and well

176
00:06:55,050 --> 00:06:59,419
none of these things are actually

177
00:06:56,400 --> 00:07:01,888
helping improve your security position

178
00:06:59,419 --> 00:07:03,270
what we did differently is we try to be

179
00:07:01,889 --> 00:07:06,210
proactive and I'm going to give you some

180
00:07:03,270 --> 00:07:07,650
specific examples that mark has talked

181
00:07:06,210 --> 00:07:09,780
about some of the tooling I'm with the

182
00:07:07,650 --> 00:07:12,000
tool vendor some of the specific

183
00:07:09,780 --> 00:07:13,710
examples of things that we did with the

184
00:07:12,000 --> 00:07:16,500
technology and how we use their

185
00:07:13,710 --> 00:07:18,210
technology so we at proactive you can

186
00:07:16,500 --> 00:07:20,669
see it changing the language right let's

187
00:07:18,210 --> 00:07:23,039
discuss a remediation plan here's a wiki

188
00:07:20,669 --> 00:07:24,780
page on how to deal with that

189
00:07:23,039 --> 00:07:26,099
identifying components getting to people

190
00:07:24,780 --> 00:07:28,650
and saying you using a vulnerable

191
00:07:26,100 --> 00:07:31,590
component he has a code sample that

192
00:07:28,650 --> 00:07:33,840
shows you how to to fix that there's a

193
00:07:31,590 --> 00:07:36,659
new version of that library I do need to

194
00:07:33,840 --> 00:07:39,630
do a new scan or ideally you fixed all

195
00:07:36,660 --> 00:07:41,520
your flaws I could also say that we're

196
00:07:39,630 --> 00:07:43,110
probably pragmatic and how we approach

197
00:07:41,520 --> 00:07:45,570
things Elizabeth made the reference this

198
00:07:43,110 --> 00:07:48,479
morning you don't have to fix everything

199
00:07:45,570 --> 00:07:50,400
it's not green or red around your doing

200
00:07:48,479 --> 00:07:53,340
you're making things safer anything that

201
00:07:50,400 --> 00:07:54,780
you do you're making an improvement when

202
00:07:53,340 --> 00:07:56,190
we started with this I think in the

203
00:07:54,780 --> 00:07:58,440
first couple of years of scanning we

204
00:07:56,190 --> 00:08:01,410
surfaced some way around you know

205
00:07:58,440 --> 00:08:03,150
hundreds of thousands of what you'd call

206
00:08:01,410 --> 00:08:05,220
high severity flaws you know where do

207
00:08:03,150 --> 00:08:07,650
you start with that all right so you

208
00:08:05,220 --> 00:08:09,090
have to start somewhere in my role at

209
00:08:07,650 --> 00:08:12,359
very code I actually deal with a lot of

210
00:08:09,090 --> 00:08:14,340
organizations I'm a evangelist I go up

211
00:08:12,360 --> 00:08:15,720
and talk to two other customers facing

212
00:08:14,340 --> 00:08:17,880
the same kind of problems that we had

213
00:08:15,720 --> 00:08:18,360
and a lot of people don't know where to

214
00:08:17,880 --> 00:08:20,340
start

215
00:08:18,360 --> 00:08:21,750
yeah it doesn't actually matter where

216
00:08:20,340 --> 00:08:23,549
you start as long as you start some way

217
00:08:21,750 --> 00:08:25,680
you'll make up a plan as you go along

218
00:08:23,550 --> 00:08:27,210
and you know people talk to me what was

219
00:08:25,680 --> 00:08:29,669
our five-year strategy what was our

220
00:08:27,210 --> 00:08:32,159
vision sort of didn't have one we made

221
00:08:29,669 --> 00:08:34,409
it up as we went along as long as you're

222
00:08:32,159 --> 00:08:37,229
doing something along the way then then

223
00:08:34,409 --> 00:08:39,450
you you're on the right path checkbox

224
00:08:37,229 --> 00:08:42,270
compliance right so a big bank

225
00:08:39,450 --> 00:08:43,860
compliance driven organization it was

226
00:08:42,270 --> 00:08:46,230
followed that the gate from process that

227
00:08:43,860 --> 00:08:47,820
I talked about you know they were I

228
00:08:46,230 --> 00:08:49,260
don't know how many checkpoints but

229
00:08:47,820 --> 00:08:50,640
somebody had gone through all these

230
00:08:49,260 --> 00:08:52,290
checkpoints and took them all off the

231
00:08:50,640 --> 00:08:53,939
application was no more secure than if

232
00:08:52,290 --> 00:08:54,380
they simply thrown their checkbox and

233
00:08:53,940 --> 00:08:57,860
the

234
00:08:54,380 --> 00:08:59,930
in the bin be pragmatic negotiate with

235
00:08:57,860 --> 00:09:02,870
your development teams if you tell them

236
00:08:59,930 --> 00:09:05,930
they've got to achieve 100% floor

237
00:09:02,870 --> 00:09:07,820
reduction they're not going to start

238
00:09:05,930 --> 00:09:09,170
don't set the bar so high there they

239
00:09:07,820 --> 00:09:11,120
they will simply write that off is

240
00:09:09,170 --> 00:09:13,219
another checkbox exercise that they have

241
00:09:11,120 --> 00:09:17,660
to go through give them realistic goals

242
00:09:13,220 --> 00:09:18,770
right be pragmatic on how you prioritize

243
00:09:17,660 --> 00:09:21,170
your floors you don't need to fix

244
00:09:18,770 --> 00:09:24,319
everything prioritize what you're going

245
00:09:21,170 --> 00:09:27,380
to remediate and yeah in goal is risk

246
00:09:24,320 --> 00:09:29,510
reduction and not compliance it's a

247
00:09:27,380 --> 00:09:30,980
couple of specifics talking maybe going

248
00:09:29,510 --> 00:09:33,740
into a little bit of the technology on

249
00:09:30,980 --> 00:09:36,410
on what we did being able to communicate

250
00:09:33,740 --> 00:09:38,090
with the developers understand their

251
00:09:36,410 --> 00:09:40,069
release cycles their environments their

252
00:09:38,090 --> 00:09:41,780
challenges so a lot of this is cultural

253
00:09:40,070 --> 00:09:44,600
so in a big organization like that

254
00:09:41,780 --> 00:09:46,069
you've got teams you know you have to

255
00:09:44,600 --> 00:09:48,110
understand what pressures those teams

256
00:09:46,070 --> 00:09:50,360
are under there's language and

257
00:09:48,110 --> 00:09:53,330
communication barriers make sure that

258
00:09:50,360 --> 00:09:54,350
you get people at a patient and that are

259
00:09:53,330 --> 00:09:57,050
willing to learn and willing to

260
00:09:54,350 --> 00:09:59,570
understand one of the things that we

261
00:09:57,050 --> 00:10:01,280
identified immediately is on having a

262
00:09:59,570 --> 00:10:03,050
lot of floor review and remediation

263
00:10:01,280 --> 00:10:04,760
calls with people we started to see an T

264
00:10:03,050 --> 00:10:07,189
pattern so we started seeing people

265
00:10:04,760 --> 00:10:11,470
doing the same thing weren't you inherit

266
00:10:07,190 --> 00:10:14,570
that bad the badness um a lot of lots of

267
00:10:11,470 --> 00:10:15,830
reuse of the same bad coding patterns so

268
00:10:14,570 --> 00:10:18,100
what we did is I'd started to identify

269
00:10:15,830 --> 00:10:20,480
that and started to build up a library

270
00:10:18,100 --> 00:10:22,190
and a knowledge base of where we were

271
00:10:20,480 --> 00:10:23,690
seeing these these common NT patterns

272
00:10:22,190 --> 00:10:25,640
the things the systemic things that

273
00:10:23,690 --> 00:10:26,870
people were doing wrong so then built

274
00:10:25,640 --> 00:10:30,370
elearning around that built

275
00:10:26,870 --> 00:10:30,370
instructor-led training around that

276
00:10:30,700 --> 00:10:35,270
remediation guidance and code snippets

277
00:10:32,990 --> 00:10:37,210
so we ran a pretty big remediation

278
00:10:35,270 --> 00:10:39,860
program we actually got consultants

279
00:10:37,210 --> 00:10:42,320
in-house and actually dedicated those

280
00:10:39,860 --> 00:10:44,210
consultants to the application teams so

281
00:10:42,320 --> 00:10:46,700
we we had the assumption that if we

282
00:10:44,210 --> 00:10:48,140
simply highlighted the flaws told people

283
00:10:46,700 --> 00:10:51,260
what to do gave them here learning

284
00:10:48,140 --> 00:10:53,689
resources and incentivize them - forced

285
00:10:51,260 --> 00:10:56,630
them to go in remediate they were just

286
00:10:53,690 --> 00:10:58,640
of their own volition go and do that are

287
00:10:56,630 --> 00:11:00,830
we surprised and quite shocked really

288
00:10:58,640 --> 00:11:02,689
that a lot of the cases that developers

289
00:11:00,830 --> 00:11:05,699
actually don't know what don't know what

290
00:11:02,690 --> 00:11:08,579
to do you can give them a wasp articles

291
00:11:05,699 --> 00:11:10,498
you can give them you have to have that

292
00:11:08,579 --> 00:11:12,269
hands-on you have to have somebody a

293
00:11:10,499 --> 00:11:14,639
security consultant who's actually

294
00:11:12,269 --> 00:11:16,829
dedicated and is sitting with that team

295
00:11:14,639 --> 00:11:18,779
and almost takes ownership with with

296
00:11:16,829 --> 00:11:20,368
their development team that would be one

297
00:11:18,779 --> 00:11:22,290
of my key takeaways as one of the things

298
00:11:20,369 --> 00:11:24,359
that we probably did differently and I

299
00:11:22,290 --> 00:11:26,790
think really would work really well

300
00:11:24,359 --> 00:11:31,709
other things we started seeing was code

301
00:11:26,790 --> 00:11:33,779
reuse right so from copy/paste yeah bad

302
00:11:31,709 --> 00:11:35,128
examples but we saw standard libraries

303
00:11:33,779 --> 00:11:37,819
and the typical discussion that we'd

304
00:11:35,129 --> 00:11:39,989
have with the development team would be

305
00:11:37,819 --> 00:11:42,449
we've seen you've used this piece of

306
00:11:39,989 --> 00:11:44,009
code we went there's a flaw in it and

307
00:11:42,449 --> 00:11:46,649
the team would accept that and then they

308
00:11:44,009 --> 00:11:49,499
would say yeah that's not our code so

309
00:11:46,649 --> 00:11:51,480
then one to mitigate what we did is then

310
00:11:49,499 --> 00:11:53,879
went out and try to identify who owned

311
00:11:51,480 --> 00:11:55,709
that code so to understand where that

312
00:11:53,879 --> 00:11:58,679
ownership lay within our organization

313
00:11:55,709 --> 00:12:00,479
and then shift the problem up the sort

314
00:11:58,679 --> 00:12:03,179
of supply chain as it were and get that

315
00:12:00,480 --> 00:12:05,309
team get that application team to take

316
00:12:03,179 --> 00:12:06,720
ownership of that and then put that back

317
00:12:05,309 --> 00:12:08,759
into the knowledge base and then drive

318
00:12:06,720 --> 00:12:10,350
that down so that the next time we got

319
00:12:08,759 --> 00:12:12,899
on a call and heard that same discussion

320
00:12:10,350 --> 00:12:16,470
we already had a precooked solution and

321
00:12:12,899 --> 00:12:19,199
we knew how to how to deal with that the

322
00:12:16,470 --> 00:12:21,539
the code reuse open source and cots

323
00:12:19,199 --> 00:12:23,819
software libraries I would say typically

324
00:12:21,539 --> 00:12:25,350
our organization we probably two-thirds

325
00:12:23,819 --> 00:12:29,339
of our floors are found in open source

326
00:12:25,350 --> 00:12:31,410
and commercial packages what we did is

327
00:12:29,339 --> 00:12:33,720
we were very proactive I said the word

328
00:12:31,410 --> 00:12:36,299
proactive is one of the bigger programs

329
00:12:33,720 --> 00:12:37,529
that we run using of in this case very

330
00:12:36,299 --> 00:12:40,439
code but this and there's a number of

331
00:12:37,529 --> 00:12:42,119
packaged tools that can go and analyze

332
00:12:40,439 --> 00:12:44,639
what your your software composition

333
00:12:42,119 --> 00:12:45,749
looks like a lot of times organizations

334
00:12:44,639 --> 00:12:47,459
simply don't know what they're using

335
00:12:45,749 --> 00:12:48,989
developers don't know what what they

336
00:12:47,459 --> 00:12:50,399
what they're using certainly the

337
00:12:48,989 --> 00:12:52,019
organization doesn't know what they're

338
00:12:50,399 --> 00:12:54,269
using they're very differently don't

339
00:12:52,019 --> 00:12:56,100
know what licensed what they license

340
00:12:54,269 --> 00:12:57,179
usage looks like and you can be rest

341
00:12:56,100 --> 00:12:58,319
assured they don't know what

342
00:12:57,179 --> 00:13:01,799
vulnerabilities they're exposing

343
00:12:58,319 --> 00:13:04,829
themselves to what we did in that case

344
00:13:01,799 --> 00:13:06,600
was we had a issue with it was a stretch

345
00:13:04,829 --> 00:13:09,329
to remote execution vulnerability a

346
00:13:06,600 --> 00:13:11,129
couple years ago we went and proactively

347
00:13:09,329 --> 00:13:13,229
inless was coming back to that keyword

348
00:13:11,129 --> 00:13:14,909
being proactive about this going and

349
00:13:13,230 --> 00:13:16,769
having with what other applications and

350
00:13:14,909 --> 00:13:18,239
the organization used that same package

351
00:13:16,769 --> 00:13:19,170
and then being able to go to them and

352
00:13:18,239 --> 00:13:20,970
say we

353
00:13:19,170 --> 00:13:23,430
you might have a problem if you think

354
00:13:20,970 --> 00:13:25,470
about that security gate process that we

355
00:13:23,430 --> 00:13:27,000
had earlier that would have flown

356
00:13:25,470 --> 00:13:28,170
through that because it simply wouldn't

357
00:13:27,000 --> 00:13:30,300
have been a gate they would have been

358
00:13:28,170 --> 00:13:32,010
running off-site or whatever it was they

359
00:13:30,300 --> 00:13:33,260
were they were great they would pass

360
00:13:32,010 --> 00:13:36,300
their gate but actually they were

361
00:13:33,260 --> 00:13:39,149
deploying live with the broken struts to

362
00:13:36,300 --> 00:13:42,060
package so that was a good example of

363
00:13:39,149 --> 00:13:44,880
how we were proactive got got ahead of

364
00:13:42,060 --> 00:13:48,540
the game on that pragmatic approach to

365
00:13:44,880 --> 00:13:49,980
remediation yeah people need to fix

366
00:13:48,540 --> 00:13:52,760
their code that as I said they don't

367
00:13:49,980 --> 00:13:56,070
have to fix everything we developed a

368
00:13:52,760 --> 00:13:58,699
systematic way for developers to review

369
00:13:56,070 --> 00:14:02,040
their findings and then to be able to

370
00:13:58,699 --> 00:14:04,800
evidence and document why they felt that

371
00:14:02,040 --> 00:14:07,680
particular flaw or issue false positives

372
00:14:04,800 --> 00:14:12,240
on static analysis how they thought they

373
00:14:07,680 --> 00:14:14,660
were going to mitigate that right so we

374
00:14:12,240 --> 00:14:17,070
we forced them down a route we didn't

375
00:14:14,660 --> 00:14:18,839
allow them to be too creative in how

376
00:14:17,070 --> 00:14:20,639
they wanted to propose mitigations we

377
00:14:18,839 --> 00:14:22,620
made them think that was the key thing

378
00:14:20,639 --> 00:14:24,480
we got them to think about what this

379
00:14:22,620 --> 00:14:27,269
issue was it might be false positive in

380
00:14:24,480 --> 00:14:28,800
the tool it might be something that's

381
00:14:27,269 --> 00:14:30,779
not exploitable in the real world they

382
00:14:28,800 --> 00:14:32,550
might have environmental controls but

383
00:14:30,779 --> 00:14:34,110
the point was we made them think about

384
00:14:32,550 --> 00:14:35,880
what they were going to write down there

385
00:14:34,110 --> 00:14:39,269
we didn't let them just say it's a false

386
00:14:35,880 --> 00:14:40,860
positive the tool is broken we find

387
00:14:39,269 --> 00:14:42,990
didn't matter if the tool had a false

388
00:14:40,860 --> 00:14:46,170
positive but we identified something and

389
00:14:42,990 --> 00:14:48,480
then made them think about that we we

390
00:14:46,170 --> 00:14:50,160
made a we made that systematic we

391
00:14:48,480 --> 00:14:52,230
drummed it into them we taught them so

392
00:14:50,160 --> 00:14:53,790
that the the fact that now developers at

393
00:14:52,230 --> 00:14:55,350
second it's second nature for them to

394
00:14:53,790 --> 00:14:57,779
understand how to propose these

395
00:14:55,350 --> 00:14:59,130
mitigations in this in this format which

396
00:14:57,779 --> 00:15:00,839
then makes it really easy for the

397
00:14:59,130 --> 00:15:04,170
security guard the bad guy to come along

398
00:15:00,839 --> 00:15:06,510
and say yes no that that stands stands

399
00:15:04,170 --> 00:15:08,719
to reason and then use new technology

400
00:15:06,510 --> 00:15:11,279
when relevant we had applications where

401
00:15:08,720 --> 00:15:13,160
we simply had vulnerability counts that

402
00:15:11,279 --> 00:15:15,089
were prohibitive to remediate

403
00:15:13,160 --> 00:15:17,219
applications everyone currently an

404
00:15:15,089 --> 00:15:20,459
investment and it didn't make economic

405
00:15:17,220 --> 00:15:22,410
sense to to invest money in remediating

406
00:15:20,459 --> 00:15:25,920
does that mean there's no risk of course

407
00:15:22,410 --> 00:15:28,170
not so use new technologies and we using

408
00:15:25,920 --> 00:15:30,360
run time protection I think there's a

409
00:15:28,170 --> 00:15:32,550
talk this afternoon by Amenia it's an

410
00:15:30,360 --> 00:15:35,010
it's an interesting place to

411
00:15:32,550 --> 00:15:37,290
you know her to be looking at in terms

412
00:15:35,010 --> 00:15:39,510
of protecting this particular use cases

413
00:15:37,290 --> 00:15:41,130
for it I think in an investment bank in

414
00:15:39,510 --> 00:15:42,930
a big bank where you've got legacy

415
00:15:41,130 --> 00:15:45,120
applications as some really really nice

416
00:15:42,930 --> 00:15:49,500
use cases use the new technology when

417
00:15:45,120 --> 00:15:53,940
it's when it's relevant so look into the

418
00:15:49,500 --> 00:15:56,940
future you know

419
00:15:53,940 --> 00:15:59,279
yeah I'm optimistic about things in what

420
00:15:56,940 --> 00:16:01,620
we've done I'm surprised how long it's

421
00:15:59,279 --> 00:16:04,350
taken to to do what we've we've done I

422
00:16:01,620 --> 00:16:06,420
mean the the stats on the program it was

423
00:16:04,350 --> 00:16:08,360
something like a thousand applications

424
00:16:06,420 --> 00:16:11,490
were brought under govern under

425
00:16:08,360 --> 00:16:13,519
application security we fixed hundreds

426
00:16:11,490 --> 00:16:15,810
of thousands of floors PI's in very high

427
00:16:13,519 --> 00:16:18,839
I'm optimistic about what can be

428
00:16:15,810 --> 00:16:20,579
achieved I think if we carry on doing

429
00:16:18,839 --> 00:16:22,140
things the way we've been doing them

430
00:16:20,579 --> 00:16:23,459
with with the gate with the gating

431
00:16:22,140 --> 00:16:25,230
process like that with the type of

432
00:16:23,459 --> 00:16:28,050
language that we're using their

433
00:16:25,230 --> 00:16:29,430
traditional security people are using I

434
00:16:28,050 --> 00:16:31,439
don't think we're going to get anywhere

435
00:16:29,430 --> 00:16:34,199
I think people need to take a fresh

436
00:16:31,440 --> 00:16:35,399
approach to how your your security

437
00:16:34,200 --> 00:16:39,750
professionals are dealing with your

438
00:16:35,399 --> 00:16:42,029
developers you have change that language

439
00:16:39,750 --> 00:16:43,850
be be proactive come to them with

440
00:16:42,029 --> 00:16:45,930
solutions for the before the problems

441
00:16:43,850 --> 00:16:47,490
ideally you even do that before they

442
00:16:45,930 --> 00:16:50,459
know that they have problems in this

443
00:16:47,490 --> 00:16:52,110
case is now where the consultants are

444
00:16:50,459 --> 00:16:54,050
reaching out to people and saying do you

445
00:16:52,110 --> 00:16:56,970
know that you're using a package that's

446
00:16:54,050 --> 00:16:58,290
internally developed has got issues and

447
00:16:56,970 --> 00:17:01,140
here's and by the way here's a new

448
00:16:58,290 --> 00:17:02,819
version how many times we've been able

449
00:17:01,140 --> 00:17:05,010
to go to developers and say we've seen

450
00:17:02,820 --> 00:17:06,780
you using an open-source component that

451
00:17:05,010 --> 00:17:10,140
one's out-of-date you've got a migration

452
00:17:06,780 --> 00:17:15,629
path to this is the approved library so

453
00:17:10,140 --> 00:17:17,550
I'm not saying it's um I'm not saying is

454
00:17:15,630 --> 00:17:18,780
going to be easy but I think we helped

455
00:17:17,550 --> 00:17:21,510
developers help themselves

456
00:17:18,780 --> 00:17:24,809
empirically if we change change language

457
00:17:21,510 --> 00:17:27,300
I think we're on the way to to to a

458
00:17:24,809 --> 00:17:29,550
happy place I think that's that's all I

459
00:17:27,300 --> 00:17:31,830
have in terms of presentation I'd really

460
00:17:29,550 --> 00:17:33,840
welcome questions either now or if you

461
00:17:31,830 --> 00:17:35,490
want to come downstairs chair to me

462
00:17:33,840 --> 00:17:37,080
understand I haven't talked about any of

463
00:17:35,490 --> 00:17:39,450
the technologies on one of the things

464
00:17:37,080 --> 00:17:41,490
I'm doing it at very code is is new tech

465
00:17:39,450 --> 00:17:43,140
because I'm interested in because I've

466
00:17:41,490 --> 00:17:45,600
seen the problem at first hand I've seen

467
00:17:43,140 --> 00:17:48,690
how the scale of the problem

468
00:17:45,600 --> 00:17:50,250
coming from a from a background where I

469
00:17:48,690 --> 00:17:53,490
was probably working in smaller teams on

470
00:17:50,250 --> 00:17:56,460
embedded or high-grade systems I wasn't

471
00:17:53,490 --> 00:17:58,919
aware of how big the problem application

472
00:17:56,460 --> 00:18:02,340
security is I remember when I went for

473
00:17:58,919 --> 00:18:04,289
the job interview I googled a wasp I

474
00:18:02,340 --> 00:18:08,820
didn't know what I was poised for years

475
00:18:04,289 --> 00:18:11,700
ago and yeah amazed that the the scale

476
00:18:08,820 --> 00:18:13,590
of their problem exists and how our

477
00:18:11,700 --> 00:18:16,440
difficult problem that is for for people

478
00:18:13,590 --> 00:18:18,720
to solve new technologies so where you

479
00:18:16,440 --> 00:18:21,240
can't remediate you don't have the the

480
00:18:18,720 --> 00:18:22,110
money use the tools use the technology

481
00:18:21,240 --> 00:18:24,230
there's some great tools and

482
00:18:22,110 --> 00:18:27,479
technologies out they use them to do

483
00:18:24,230 --> 00:18:28,679
what you can do in the meantime but make

484
00:18:27,480 --> 00:18:30,809
sure that you're actually addressing

485
00:18:28,679 --> 00:18:32,970
that problem at root and going back to

486
00:18:30,809 --> 00:18:34,590
your developers if you've got the kind

487
00:18:32,970 --> 00:18:37,350
of security problems and the kind of

488
00:18:34,590 --> 00:18:39,000
coding issues that I've seen you've

489
00:18:37,350 --> 00:18:41,189
probably got some other serious problems

490
00:18:39,000 --> 00:18:42,629
in your application a state and your

491
00:18:41,190 --> 00:18:45,360
business logic that you really need to

492
00:18:42,629 --> 00:18:48,809
be addressing spend your effort spend

493
00:18:45,360 --> 00:18:51,178
your time they're not on fixing all your

494
00:18:48,809 --> 00:18:53,639
your cross-site scripting and SQL use

495
00:18:51,179 --> 00:18:55,409
the user tool to automate and and and

496
00:18:53,639 --> 00:18:59,549
simply surface those as quickly as

497
00:18:55,409 --> 00:19:03,350
possible so that's all I've got really

498
00:18:59,549 --> 00:19:03,350
hope they are couple of questions

