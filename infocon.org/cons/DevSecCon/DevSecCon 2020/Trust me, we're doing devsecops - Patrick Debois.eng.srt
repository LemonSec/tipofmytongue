1
00:00:00,620 --> 00:00:05,970
here's yes I can

2
00:00:05,970 --> 00:00:09,330
I love Padre how you doing I'm good

3
00:00:09,330 --> 00:00:10,099
Frank

4
00:00:10,099 --> 00:00:13,219
nice to see you now finally face to face

5
00:00:13,219 --> 00:00:18,690
yeah chatting all day on slacks yes just

6
00:00:18,690 --> 00:00:20,970
as a note for everybody so Patrick is

7
00:00:20,970 --> 00:00:24,119
the code behind the machine so it's

8
00:00:24,119 --> 00:00:26,490
being behind the scene putting all this

9
00:00:26,490 --> 00:00:29,880
together and I'm just absolutely amazing

10
00:00:29,880 --> 00:00:33,239
impress about how much work has been

11
00:00:33,239 --> 00:00:37,559
putting together in insole so quickly

12
00:00:37,559 --> 00:00:40,140
and it's been friendly it's been

13
00:00:40,140 --> 00:00:42,149
tactically behind the scenes so if

14
00:00:42,149 --> 00:00:45,180
anything breaks he jumps on it and we

15
00:00:45,180 --> 00:00:49,129
have won a B and C and D that doesn't

16
00:00:49,129 --> 00:00:52,410
that's what helps people do right so yes

17
00:00:52,410 --> 00:00:55,199
and anyone more than that it's like in

18
00:00:55,199 --> 00:00:59,070
this period of you know being on tiptoes

19
00:00:59,070 --> 00:01:02,190
and and you know having a plan B and C

20
00:01:02,190 --> 00:01:04,530
for coronavirus this is a great lesson

21
00:01:04,530 --> 00:01:07,580
of everything went absolutely smooth so

22
00:01:07,580 --> 00:01:10,920
I'll leave the stage to Patrick talking

23
00:01:10,920 --> 00:01:12,930
about - the cops and I'll go into that

24
00:01:12,930 --> 00:01:15,650
don't think we took a little bit in half

25
00:01:15,650 --> 00:01:20,369
so I apologize because I running behind

26
00:01:20,369 --> 00:01:22,170
the scenes I just wanted to say hi

27
00:01:22,170 --> 00:01:24,960
before I reduce actually a recording of

28
00:01:24,960 --> 00:01:27,240
my talk I will be hanging out in on

29
00:01:27,240 --> 00:01:30,420
slack but I want to thank the security

30
00:01:30,420 --> 00:01:33,990
crew you know you Alyssa and Ray running

31
00:01:33,990 --> 00:01:37,229
this like for you know the whole night I

32
00:01:37,229 --> 00:01:42,420
guess yeah and I guess people don't want

33
00:01:42,420 --> 00:01:45,210
to see like everything like behind below

34
00:01:45,210 --> 00:01:47,790
my eyes so I get a better video recorder

35
00:01:47,790 --> 00:01:50,820
so thanks again and yeah you know you

36
00:01:50,820 --> 00:01:52,409
know see you on slack if you have

37
00:01:52,409 --> 00:01:54,570
questions about my talk thank you so

38
00:01:54,570 --> 00:01:57,090
much Patrick great coaching you about

39
00:01:57,090 --> 00:02:06,420
say good morning and thank you for all

40
00:02:06,420 --> 00:02:09,300
being here I'm joining you from remote

41
00:02:09,300 --> 00:02:13,050
because I can't make it to Devan my name

42
00:02:13,050 --> 00:02:13,830
is Patrick

43
00:02:13,830 --> 00:02:15,480
and I'm the director of that watch

44
00:02:15,480 --> 00:02:18,480
relations at snake and today I'm gonna

45
00:02:18,480 --> 00:02:20,610
be talking about Dexter cops in the

46
00:02:20,610 --> 00:02:25,020
context of trust so a little bit about

47
00:02:25,020 --> 00:02:26,100
me

48
00:02:26,100 --> 00:02:29,310
I've been active in DevOps for about 10

49
00:02:29,310 --> 00:02:32,190
years Pam and I've been there from the

50
00:02:32,190 --> 00:02:34,740
very beginning from you know word the

51
00:02:34,740 --> 00:02:37,530
word dub ups to a start up at the first

52
00:02:37,530 --> 00:02:41,370
very first DevOps days and I saw DevOps

53
00:02:41,370 --> 00:02:43,740
expanded into this cultural movement

54
00:02:43,740 --> 00:02:46,590
beyond the tools and with the help of

55
00:02:46,590 --> 00:02:48,210
some friends I even wrote like the

56
00:02:48,210 --> 00:02:50,760
DevOps handbook which but know many of

57
00:02:50,760 --> 00:02:54,660
the stories I've seen or focused on some

58
00:02:54,660 --> 00:02:58,290
where tools but overall most of it on

59
00:02:58,290 --> 00:03:02,970
culture and you know join snake I binge

60
00:03:02,970 --> 00:03:05,220
for many talks about the world as the

61
00:03:05,220 --> 00:03:08,130
cops and it really made me sad watching

62
00:03:08,130 --> 00:03:09,900
that many of the discussions were about

63
00:03:09,900 --> 00:03:14,250
the tools and so do we really need all

64
00:03:14,250 --> 00:03:17,040
these tools to you know to Desa cops or

65
00:03:17,040 --> 00:03:20,430
to understand that Cecrops and believe

66
00:03:20,430 --> 00:03:22,830
me I'm not here as a tool spender but

67
00:03:22,830 --> 00:03:25,920
you do have to believe me that it's not

68
00:03:25,920 --> 00:03:27,360
about the tools

69
00:03:27,360 --> 00:03:30,330
so this slide will be the last tool

70
00:03:30,330 --> 00:03:32,910
slide I'm sorry for those you can still

71
00:03:32,910 --> 00:03:35,160
leave the room I won't even see you so

72
00:03:35,160 --> 00:03:39,570
don't worry about it and I believe you

73
00:03:39,570 --> 00:03:41,520
know beyond the tools that we have a

74
00:03:41,520 --> 00:03:43,590
bigger issue at hand which is about

75
00:03:43,590 --> 00:03:48,720
trust you know 10 years ago security was

76
00:03:48,720 --> 00:03:51,120
already a mine of people during DevOps

77
00:03:51,120 --> 00:03:53,520
but it took us a while as the interstate

78
00:03:53,520 --> 00:03:58,110
to mature and now recently the

79
00:03:58,110 --> 00:03:59,940
bottleneck has moved not between the

80
00:03:59,940 --> 00:04:03,090
knobs but to security and so you know

81
00:04:03,090 --> 00:04:05,940
they're late to the party but there's

82
00:04:05,940 --> 00:04:08,220
still a party going on so we're about it

83
00:04:08,220 --> 00:04:08,959
too much

84
00:04:08,959 --> 00:04:12,060
but we need to get better at learning

85
00:04:12,060 --> 00:04:16,108
distrusting because you know this how I

86
00:04:16,108 --> 00:04:18,209
thought about security and lost that

87
00:04:18,209 --> 00:04:22,019
game it's basically security 101 is

88
00:04:22,019 --> 00:04:24,200
about what trust no one

89
00:04:24,200 --> 00:04:28,220
and what the same thing happened in ops

90
00:04:28,220 --> 00:04:30,710
like nobody was rusting hopes they

91
00:04:30,710 --> 00:04:32,930
couldn't do their job you know if some

92
00:04:32,930 --> 00:04:34,610
people remember the comic master a

93
00:04:34,610 --> 00:04:36,830
breather from hell it was about the

94
00:04:36,830 --> 00:04:40,880
unreliable person not to be trusted you

95
00:04:40,880 --> 00:04:43,040
know that's how shadow I think I born

96
00:04:43,040 --> 00:04:45,230
and people went to the cloud just to

97
00:04:45,230 --> 00:04:47,570
evade their people and you know things

98
00:04:47,570 --> 00:04:49,070
would secure these happening the same

99
00:04:49,070 --> 00:04:51,290
they're looking at creative ways just to

100
00:04:51,290 --> 00:04:55,790
go around like company policies so in

101
00:04:55,790 --> 00:04:58,160
this life I started talking to many with

102
00:04:58,160 --> 00:05:00,470
the security folks and whenever I would

103
00:05:00,470 --> 00:05:02,780
bring up the trust issue they said yeah

104
00:05:02,780 --> 00:05:04,550
it's all this good you know it's all

105
00:05:04,550 --> 00:05:08,900
good but it is trust and verify so we

106
00:05:08,900 --> 00:05:11,540
need to verify it and I don't want to

107
00:05:11,540 --> 00:05:13,730
believe in their good intentions and I'm

108
00:05:13,730 --> 00:05:16,250
not saying this is about policing the

109
00:05:16,250 --> 00:05:18,620
Deaf in the office and I'm hoping there

110
00:05:18,620 --> 00:05:19,910
is a better way of working and

111
00:05:19,910 --> 00:05:22,940
collaborating then we used it before of

112
00:05:22,940 --> 00:05:28,520
saying no while exploring IDs around

113
00:05:28,520 --> 00:05:30,530
DevOps I came across the you know the

114
00:05:30,530 --> 00:05:32,330
research that Mark burkas did around

115
00:05:32,330 --> 00:05:35,840
promise theory and it is an interesting

116
00:05:35,840 --> 00:05:39,140
model to reason about technology about

117
00:05:39,140 --> 00:05:40,910
the system we're working in because you

118
00:05:40,910 --> 00:05:42,800
know a lot of devops about system

119
00:05:42,800 --> 00:05:46,340
thinking and you know the collaboration

120
00:05:46,340 --> 00:05:49,760
is something that is very embedded into

121
00:05:49,760 --> 00:05:52,790
promise theory so everybody in the

122
00:05:52,790 --> 00:05:55,550
system is an agent and you know be my

123
00:05:55,550 --> 00:05:58,460
promises to other people in the agent in

124
00:05:58,460 --> 00:06:01,640
the system sorry and promises should be

125
00:06:01,640 --> 00:06:02,480
verifiable

126
00:06:02,480 --> 00:06:06,050
but you know the guarantee is not there

127
00:06:06,050 --> 00:06:08,570
that it will be that outcome and that's

128
00:06:08,570 --> 00:06:11,090
pretty much like ops learned that it

129
00:06:11,090 --> 00:06:12,800
wasn't about building these perfect

130
00:06:12,800 --> 00:06:16,130
architectures that could never fail but

131
00:06:16,130 --> 00:06:19,460
we learn to live with things that fail

132
00:06:19,460 --> 00:06:22,190
you learn to live about security that's

133
00:06:22,190 --> 00:06:27,050
not perfect and to be more about being

134
00:06:27,050 --> 00:06:29,570
resilient and making sure that we can

135
00:06:29,570 --> 00:06:31,160
deal with the things that we didn't

136
00:06:31,160 --> 00:06:35,810
anticipate so another part that Mark

137
00:06:35,810 --> 00:06:37,320
pointed out

138
00:06:37,320 --> 00:06:39,180
that you know it's easy when you have

139
00:06:39,180 --> 00:06:42,300
evidence that something is not secure

140
00:06:42,300 --> 00:06:44,910
like if we know there's the bug we know

141
00:06:44,910 --> 00:06:47,310
you know there's an ethical factor then

142
00:06:47,310 --> 00:06:50,940
it's easy you know it's not secure or in

143
00:06:50,940 --> 00:06:53,700
which circumstances it's not secure but

144
00:06:53,700 --> 00:06:55,740
you don't always have that evidence and

145
00:06:55,740 --> 00:06:57,720
then it becomes a little bit grey like

146
00:06:57,720 --> 00:07:01,650
if you don't know if it's secure or you

147
00:07:01,650 --> 00:07:05,700
have no evidence is it secure or isn't

148
00:07:05,700 --> 00:07:08,760
it you can't really tell and that's many

149
00:07:08,760 --> 00:07:10,620
of the situations that you're having

150
00:07:10,620 --> 00:07:15,420
Redknapp and we we don't meet to fool

151
00:07:15,420 --> 00:07:18,090
ourselves the fact that the CI PI point

152
00:07:18,090 --> 00:07:20,340
detects a lot of stuff that is a good

153
00:07:20,340 --> 00:07:25,220
thing but it doesn't really make us feel

154
00:07:25,220 --> 00:07:28,710
perfectly secure it it builds upon the

155
00:07:28,710 --> 00:07:30,480
confidence with that we don't find

156
00:07:30,480 --> 00:07:33,360
issues but we're not sure there aren't

157
00:07:33,360 --> 00:07:37,800
any issues so Trust goes beyond that if

158
00:07:37,800 --> 00:07:39,780
we want to trust the system we have to

159
00:07:39,780 --> 00:07:44,250
deal with it in a different way in this

160
00:07:44,250 --> 00:07:47,100
presentation that Jon Moscot their admin

161
00:07:47,100 --> 00:07:47,880
mr. Adama

162
00:07:47,880 --> 00:07:49,650
he did it like an interesting thought

163
00:07:49,650 --> 00:07:52,380
experiment he asked the audience about

164
00:07:52,380 --> 00:07:57,570
what what imagine the systems are not

165
00:07:57,570 --> 00:08:00,300
changing and you don't change any of the

166
00:08:00,300 --> 00:08:05,070
systems how long will it run fine will

167
00:08:05,070 --> 00:08:08,610
it run for a day for two days for five

168
00:08:08,610 --> 00:08:11,580
days if you don't touch them you know

169
00:08:11,580 --> 00:08:13,890
many people started getting uneasy after

170
00:08:13,890 --> 00:08:17,460
a couple of days and it is not unusual

171
00:08:17,460 --> 00:08:19,770
because part of what makes the system

172
00:08:19,770 --> 00:08:23,370
work is the human and the units are part

173
00:08:23,370 --> 00:08:26,400
of the system we work with the tools so

174
00:08:26,400 --> 00:08:28,290
we need to be cautioned about that it's

175
00:08:28,290 --> 00:08:31,650
not only a tool solution but part of the

176
00:08:31,650 --> 00:08:33,900
system is also dealing with the humans

177
00:08:33,900 --> 00:08:38,010
and on the relation lane related note

178
00:08:38,010 --> 00:08:40,110
John Willis showed in this presentation

179
00:08:40,110 --> 00:08:44,370
that you know which environment do you

180
00:08:44,370 --> 00:08:48,279
think can respond the best to unknown is

181
00:08:48,279 --> 00:08:51,100
a system that is perfectly structured or

182
00:08:51,100 --> 00:08:54,129
very deeply structured or is it the one

183
00:08:54,129 --> 00:08:56,499
that has many degrees of freedom where

184
00:08:56,499 --> 00:08:59,170
the use can decide obviously it's

185
00:08:59,170 --> 00:09:00,459
somewhere in the middle

186
00:09:00,459 --> 00:09:02,980
but it doesn't perfect in hard

187
00:09:02,980 --> 00:09:05,199
controlled saying that we want to have

188
00:09:05,199 --> 00:09:08,379
there has to be a way to have these to

189
00:09:08,379 --> 00:09:12,189
make decisions or text that are harder

190
00:09:12,189 --> 00:09:16,749
to decide and another example of how in

191
00:09:16,749 --> 00:09:18,759
a we are dealing all the time with

192
00:09:18,759 --> 00:09:21,610
humans is actually the pipeline or the

193
00:09:21,610 --> 00:09:25,329
flow itself you know a lot of people

194
00:09:25,329 --> 00:09:26,889
think it's about getting the software

195
00:09:26,889 --> 00:09:28,899
moving but it's actually about the

196
00:09:28,899 --> 00:09:31,899
humans talking around the process they

197
00:09:31,899 --> 00:09:34,149
decide things they verify things they

198
00:09:34,149 --> 00:09:37,569
look at text a triage things so in

199
00:09:37,569 --> 00:09:40,990
reality there is a mixture between tools

200
00:09:40,990 --> 00:09:46,470
and having humans at work and you know I

201
00:09:46,470 --> 00:09:49,809
hear somebody at the back you know in a

202
00:09:49,809 --> 00:09:53,980
career I just so hear it trust no one

203
00:09:53,980 --> 00:09:57,129
I will still trust no one this is not

204
00:09:57,129 --> 00:10:00,009
something but will do and you know we

205
00:10:00,009 --> 00:10:03,009
can even have separation of duties now

206
00:10:03,009 --> 00:10:05,500
going at that speed is all about being

207
00:10:05,500 --> 00:10:07,629
more transparent about the things you do

208
00:10:07,629 --> 00:10:11,439
and to utilize the human factor if the

209
00:10:11,439 --> 00:10:15,189
tools caught solve it and no that sounds

210
00:10:15,189 --> 00:10:17,259
scary but you've got to believe that

211
00:10:17,259 --> 00:10:20,620
humans are part of the solution to deal

212
00:10:20,620 --> 00:10:23,949
with issues so what we are basically

213
00:10:23,949 --> 00:10:26,680
doing is building a team we're building

214
00:10:26,680 --> 00:10:29,230
a team across steps economics and part

215
00:10:29,230 --> 00:10:32,399
of a being it good team is having a good

216
00:10:32,399 --> 00:10:36,490
fundamental trust and we're so focused

217
00:10:36,490 --> 00:10:39,759
on gaming results on the upper end you

218
00:10:39,759 --> 00:10:41,769
know the results with tools like can we

219
00:10:41,769 --> 00:10:45,129
fix it but what we are not doing is

220
00:10:45,129 --> 00:10:47,980
building the trust between the teams and

221
00:10:47,980 --> 00:10:54,490
that's what makes it team lost and you

222
00:10:54,490 --> 00:10:55,410
know

223
00:10:55,410 --> 00:10:57,899
not trusting people is really costly you

224
00:10:57,899 --> 00:11:00,779
know we have meeting meeting after

225
00:11:00,779 --> 00:11:03,899
meeting to ask permissions to decide

226
00:11:03,899 --> 00:11:08,300
things together sometimes it is very

227
00:11:08,300 --> 00:11:12,269
costly to do that in fact most of the

228
00:11:12,269 --> 00:11:14,660
time it's actually costly because if you

229
00:11:14,660 --> 00:11:17,579
don't show the trust that people can

230
00:11:17,579 --> 00:11:20,670
decide things you know that might show

231
00:11:20,670 --> 00:11:22,860
that you have a culture that is not

232
00:11:22,860 --> 00:11:27,720
fostering that trust looking around for

233
00:11:27,720 --> 00:11:29,550
a model on trust I came across this book

234
00:11:29,550 --> 00:11:32,160
the same book of trust and it revolves

235
00:11:32,160 --> 00:11:35,160
around three part sincerity do you walk

236
00:11:35,160 --> 00:11:39,540
the walk dude what the talk is it are

237
00:11:39,540 --> 00:11:42,449
you reliable reliability can people

238
00:11:42,449 --> 00:11:43,290
depend on you

239
00:11:43,290 --> 00:11:47,430
are you competent competence are you

240
00:11:47,430 --> 00:11:49,470
competent to do your job and do you

241
00:11:49,470 --> 00:11:52,920
really care you can be sincere reliable

242
00:11:52,920 --> 00:11:56,670
and confident but not care and don't see

243
00:11:56,670 --> 00:11:59,430
that and they might just not trust you

244
00:11:59,430 --> 00:12:01,829
even though you have all the three other

245
00:12:01,829 --> 00:12:06,240
components and what a listening to

246
00:12:06,240 --> 00:12:10,470
security folks it was really interesting

247
00:12:10,470 --> 00:12:12,089
once he got beyond their tools

248
00:12:12,089 --> 00:12:15,060
discussion what they want and basically

249
00:12:15,060 --> 00:12:19,050
it fitted the model perfectly they

250
00:12:19,050 --> 00:12:21,240
wanted to be considered during sprint

251
00:12:21,240 --> 00:12:25,589
planning so just be there on the backlog

252
00:12:25,589 --> 00:12:27,959
as something to do they wanted to make

253
00:12:27,959 --> 00:12:30,750
sure that they were on the mind all the

254
00:12:30,750 --> 00:12:33,959
time every feature so they wanted to

255
00:12:33,959 --> 00:12:36,600
have this reliability of the developer

256
00:12:36,600 --> 00:12:39,630
think about that all the time they

257
00:12:39,630 --> 00:12:41,809
wanted to be the developer more

258
00:12:41,809 --> 00:12:45,059
confident so they developer had to learn

259
00:12:45,059 --> 00:12:48,029
more security practices and the

260
00:12:48,029 --> 00:12:50,880
developer needed to care and that's easy

261
00:12:50,880 --> 00:12:52,589
to say because you know security is

262
00:12:52,589 --> 00:12:55,529
securing this job all the time so why

263
00:12:55,529 --> 00:12:57,839
would the others care and that's what

264
00:12:57,839 --> 00:12:59,790
made it a little bit harder so what a

265
00:12:59,790 --> 00:13:03,899
developer wants from security is they

266
00:13:03,899 --> 00:13:07,800
wanna know that there's Sisir and you

267
00:13:07,800 --> 00:13:09,480
become severe by on

268
00:13:09,480 --> 00:13:12,209
Stanly that there's more things and

269
00:13:12,209 --> 00:13:15,029
priorities than just security and that

270
00:13:15,029 --> 00:13:16,709
there's a balance you have to find out

271
00:13:16,709 --> 00:13:20,699
the bad luck you also want to be there

272
00:13:20,699 --> 00:13:23,699
when they're having issues when this

273
00:13:23,699 --> 00:13:26,250
stories are reviewed and you know part

274
00:13:26,250 --> 00:13:28,589
of not being there doesn't make your

275
00:13:28,589 --> 00:13:30,870
reliable person because you're not there

276
00:13:30,870 --> 00:13:35,220
and they want to become more competent

277
00:13:35,220 --> 00:13:38,160
the developers but they want somebody

278
00:13:38,160 --> 00:13:42,839
else also would teach them and explain

279
00:13:42,839 --> 00:13:45,389
this technical security issue to them

280
00:13:45,389 --> 00:13:49,620
that they didn't know existed and also

281
00:13:49,620 --> 00:13:53,160
they care about the system and you know

282
00:13:53,160 --> 00:13:55,320
more you follow the model you build it

283
00:13:55,320 --> 00:13:58,019
you run it like this owner it builds up

284
00:13:58,019 --> 00:14:01,079
in the Dean and they become also you

285
00:14:01,079 --> 00:14:04,250
know caring about security as well and

286
00:14:04,250 --> 00:14:07,709
what we're aiming at is that security is

287
00:14:07,709 --> 00:14:10,110
a non-blocking thing and it's a self

288
00:14:10,110 --> 00:14:12,420
servicing thing so you can teach the

289
00:14:12,420 --> 00:14:14,790
others to do the things that they need

290
00:14:14,790 --> 00:14:17,329
to be doing during that job

291
00:14:17,329 --> 00:14:20,940
during a talk Zane Lackey gave a good

292
00:14:20,940 --> 00:14:23,130
example how they change the approach at

293
00:14:23,130 --> 00:14:26,480
Etsy so imagine a sensitive conflation

294
00:14:26,480 --> 00:14:27,990
configuration file

295
00:14:27,990 --> 00:14:30,000
nobody is normally allowed to touch it

296
00:14:30,000 --> 00:14:33,209
unless you have approval from five

297
00:14:33,209 --> 00:14:36,510
people but now also imagine it's 2:00

298
00:14:36,510 --> 00:14:39,540
a.m. in the morning and there is like a

299
00:14:39,540 --> 00:14:42,089
deep problem and production and somebody

300
00:14:42,089 --> 00:14:44,790
needs to touch that file will you wait

301
00:14:44,790 --> 00:14:46,170
for five people

302
00:14:46,170 --> 00:14:50,329
to get the approval waiting waiting

303
00:14:50,329 --> 00:14:54,709
so they're changed their model by saying

304
00:14:54,709 --> 00:14:58,829
whenever everybody wanna somebody wanted

305
00:14:58,829 --> 00:15:00,779
to touch the file it would give a

306
00:15:00,779 --> 00:15:04,050
warning are you sure you're you want to

307
00:15:04,050 --> 00:15:06,779
do this this will go out to five people

308
00:15:06,779 --> 00:15:11,010
if it does and people feel like

309
00:15:11,010 --> 00:15:13,380
competent and confident to do the change

310
00:15:13,380 --> 00:15:15,620
and you know that it needs to be done

311
00:15:15,620 --> 00:15:19,500
they can do their jobs for people not

312
00:15:19,500 --> 00:15:22,380
feeling confident it will be enough to

313
00:15:22,380 --> 00:15:22,889
say you know

314
00:15:22,889 --> 00:15:24,989
I'm not going to touch this this is not

315
00:15:24,989 --> 00:15:28,199
something I should be doing so what did

316
00:15:28,199 --> 00:15:30,839
in the end they trusted the operator as

317
00:15:30,839 --> 00:15:31,259
well

318
00:15:31,259 --> 00:15:36,209
not just the process another example is

319
00:15:36,209 --> 00:15:39,779
you know many tools will check

320
00:15:39,779 --> 00:15:42,720
vulnerabilities and you know it's all

321
00:15:42,720 --> 00:15:45,149
good but we're actually also relying

322
00:15:45,149 --> 00:15:47,609
onions and tools to report those ruler

323
00:15:47,609 --> 00:15:49,739
abilities so they are part of our

324
00:15:49,739 --> 00:15:52,829
solution and we want to developers to

325
00:15:52,829 --> 00:15:56,339
become aware of the issues so you know

326
00:15:56,339 --> 00:15:59,609
it notify them during the development

327
00:15:59,609 --> 00:16:02,429
process and we allow them to fix this so

328
00:16:02,429 --> 00:16:04,019
that their problems themselves

329
00:16:04,019 --> 00:16:09,149
now this enablement of security giving

330
00:16:09,149 --> 00:16:11,939
that to developers is something that

331
00:16:11,939 --> 00:16:14,850
really works well but it's more than

332
00:16:14,850 --> 00:16:19,169
just checking the vulnerabilities the

333
00:16:19,169 --> 00:16:21,660
trust of library has actually happened

334
00:16:21,660 --> 00:16:24,149
way before that there are many things

335
00:16:24,149 --> 00:16:26,609
that a developer considers in selecting

336
00:16:26,609 --> 00:16:29,699
a library and it also has to do with the

337
00:16:29,699 --> 00:16:34,649
trust model is this library sincere so

338
00:16:34,649 --> 00:16:37,919
today for their own code of conduct are

339
00:16:37,919 --> 00:16:39,689
they friendly to new people are they

340
00:16:39,689 --> 00:16:43,619
open to new IDs are they reliable what

341
00:16:43,619 --> 00:16:46,350
about issues after releases how often

342
00:16:46,350 --> 00:16:48,480
did their release is there a cadence you

343
00:16:48,480 --> 00:16:51,230
know to other libraries depend on that

344
00:16:51,230 --> 00:16:54,749
are they competent so do they have tests

345
00:16:54,749 --> 00:16:56,459
are there read needs is there a change

346
00:16:56,459 --> 00:16:58,679
log are there like written your least

347
00:16:58,679 --> 00:17:02,519
files has been audited is the code real

348
00:17:02,519 --> 00:17:05,339
Vella written but many things to pick up

349
00:17:05,339 --> 00:17:07,919
and check the reliability or or less I

350
00:17:07,919 --> 00:17:10,439
mean trusting the library and then the

351
00:17:10,439 --> 00:17:12,599
last one is does the library still care

352
00:17:12,599 --> 00:17:15,388
like it's the pluralist to open too long

353
00:17:15,388 --> 00:17:18,269
or the too many Forks and what about the

354
00:17:18,269 --> 00:17:20,699
last commit date you know all these kind

355
00:17:20,699 --> 00:17:23,069
of things like how long did it take to

356
00:17:23,069 --> 00:17:25,409
fix the security all the things that

357
00:17:25,409 --> 00:17:28,439
show that people care about the library

358
00:17:28,439 --> 00:17:33,210
and there's one thing that is in in our

359
00:17:33,210 --> 00:17:36,419
way is that with general

360
00:17:36,419 --> 00:17:38,279
think about ourselves being more

361
00:17:38,279 --> 00:17:42,080
trustworthy than the other things of us

362
00:17:42,080 --> 00:17:44,700
so we need to be aware of that and one

363
00:17:44,700 --> 00:17:47,460
of the reason that is is that we judge

364
00:17:47,460 --> 00:17:49,619
ourselves by our intelligence and

365
00:17:49,619 --> 00:17:51,690
uttered Church ourselves by heart

366
00:17:51,690 --> 00:17:54,179
behavior so we have the hypothetical

367
00:17:54,179 --> 00:17:56,249
ideal case in mind but the others are

368
00:17:56,249 --> 00:17:59,039
seeing the reality and that's a lot more

369
00:17:59,039 --> 00:18:03,509
complicated and this process takes time

370
00:18:03,509 --> 00:18:06,690
so all these feeling for kind of aspects

371
00:18:06,690 --> 00:18:11,159
they take time but in many cases a tool

372
00:18:11,159 --> 00:18:14,249
can get a good discussion going and you

373
00:18:14,249 --> 00:18:15,659
look at the value stream and at the

374
00:18:15,659 --> 00:18:18,059
system and you can discover many things

375
00:18:18,059 --> 00:18:21,749
together so truth ever set cups is when

376
00:18:21,749 --> 00:18:24,509
you get beyond the tools and you know

377
00:18:24,509 --> 00:18:26,730
you start building the deficit cups as a

378
00:18:26,730 --> 00:18:29,429
team or as a group that really works

379
00:18:29,429 --> 00:18:32,220
together together in cases that you

380
00:18:32,220 --> 00:18:34,139
didn't anticipate with the tools or the

381
00:18:34,139 --> 00:18:38,369
things that you can detect with that on

382
00:18:38,369 --> 00:18:40,320
the flip side we need to be aware that

383
00:18:40,320 --> 00:18:42,659
we need to become more Trust learning so

384
00:18:42,659 --> 00:18:44,369
that means we have to do the same things

385
00:18:44,369 --> 00:18:47,970
that other people expect from us and so

386
00:18:47,970 --> 00:18:50,100
we have to learn things we have to be

387
00:18:50,100 --> 00:18:52,559
sincere we have to come to meetings we

388
00:18:52,559 --> 00:18:54,840
have to be you know understanding having

389
00:18:54,840 --> 00:18:57,869
empathy all the same thing of becoming

390
00:18:57,869 --> 00:19:01,739
trustworthy to somebody else and hit

391
00:19:01,739 --> 00:19:05,070
some homework that you can use you know

392
00:19:05,070 --> 00:19:08,129
to explore some of these building of

393
00:19:08,129 --> 00:19:10,889
trusts I want to give a special call-out

394
00:19:10,889 --> 00:19:13,379
to agile conversations which is the

395
00:19:13,379 --> 00:19:16,590
first book I read about digital

396
00:19:16,590 --> 00:19:19,109
transformation in the light of having

397
00:19:19,109 --> 00:19:21,710
like interpersonal communications or

398
00:19:21,710 --> 00:19:25,440
collaborations it's about having the

399
00:19:25,440 --> 00:19:28,470
hard conversations when you don't agree

400
00:19:28,470 --> 00:19:30,779
how can we get better at that how can we

401
00:19:30,779 --> 00:19:33,899
say thanks to improve and encourage

402
00:19:33,899 --> 00:19:36,859
others and it's building upon that trust

403
00:19:36,859 --> 00:19:39,570
it's not yet out but it will be

404
00:19:39,570 --> 00:19:43,739
published soon and as a last note I want

405
00:19:43,739 --> 00:19:46,720
to say that you know all change is hard

406
00:19:46,720 --> 00:19:50,169
you know maybe in 2021 people will say

407
00:19:50,169 --> 00:19:52,510
you know you've tried deficit cops it

408
00:19:52,510 --> 00:19:56,740
just didn't work it's so 2020 but it's

409
00:19:56,740 --> 00:20:00,309
just got a belief and keep going and as

410
00:20:00,309 --> 00:20:02,320
long as we improve our human skills we

411
00:20:02,320 --> 00:20:05,230
have a chance and it will not just be

412
00:20:05,230 --> 00:20:08,500
about the tools with this I want to say

413
00:20:08,500 --> 00:20:10,120
thank you and enjoy the rest of the

414
00:20:10,120 --> 00:20:11,490
conference

415
00:20:11,490 --> 00:20:14,080
you know if you want to reach out to me

416
00:20:14,080 --> 00:20:17,919
Patrick dois Twitter or just send me an

417
00:20:17,919 --> 00:20:20,640
email you know let me know if this

418
00:20:20,640 --> 00:20:24,400
presentation resonated with you or if

419
00:20:24,400 --> 00:20:27,130
you have any questions thank you very

420
00:20:27,130 --> 00:20:28,390
much and arrestor

421
00:20:28,390 --> 00:20:31,590
enjoy the rest of the day

