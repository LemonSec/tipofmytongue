1
00:00:00,000 --> 00:00:02,070
Richard into the stream now Richard

2
00:00:02,070 --> 00:00:06,420
welcome hey how's it going going very

3
00:00:06,420 --> 00:00:09,179
very well thank you and you fantastic

4
00:00:09,179 --> 00:00:13,440
yeah yeah good good and Richard you're a

5
00:00:13,440 --> 00:00:15,150
very humble guy which is why you have a

6
00:00:15,150 --> 00:00:17,130
six-foot picture of yourself in the

7
00:00:17,130 --> 00:00:19,470
background there I can see absolutely if

8
00:00:19,470 --> 00:00:21,420
someone makes a six-foot post-review

9
00:00:21,420 --> 00:00:24,060
you have to you have to keep a hold you

10
00:00:24,060 --> 00:00:25,590
take it and you put it in the bedroom

11
00:00:25,590 --> 00:00:29,039
like any like any reasonable excellent

12
00:00:29,039 --> 00:00:31,980
so Richard we've known each other for a

13
00:00:31,980 --> 00:00:34,530
decade or so now from the London job you

14
00:00:34,530 --> 00:00:36,149
use a group and you did a lot with a

15
00:00:36,149 --> 00:00:37,710
virtual job user group as well you're a

16
00:00:37,710 --> 00:00:40,920
job champion you're the CTO and founder

17
00:00:40,920 --> 00:00:46,050
of option which is a performance tooling

18
00:00:46,050 --> 00:00:47,300
company you're a lead developer

19
00:00:47,300 --> 00:00:50,910
performance RTO fix engine plurals like

20
00:00:50,910 --> 00:00:52,469
trainer and a whole bunch more author

21
00:00:52,469 --> 00:00:54,390
I'm sure as well right

22
00:00:54,390 --> 00:00:56,940
which book did you do is it landers but

23
00:00:56,940 --> 00:01:01,710
our own Jerry Landers I run rowl which

24
00:01:01,710 --> 00:01:04,229
is conveniently located here put that

25
00:01:04,229 --> 00:01:06,270
look like this next to your poster of

26
00:01:06,270 --> 00:01:09,930
your surface amazing great yes well

27
00:01:09,930 --> 00:01:11,760
Richard is our absolute pleasure to have

28
00:01:11,760 --> 00:01:14,670
you on and thank you thank you very much

29
00:01:14,670 --> 00:01:16,259
for being here just so that everyone

30
00:01:16,259 --> 00:01:19,320
online is aware this is a conference

31
00:01:19,320 --> 00:01:21,060
which is a little bit different way of

32
00:01:21,060 --> 00:01:22,890
raising money for an amazing cause the

33
00:01:22,890 --> 00:01:25,259
curve at nineteen pandemic trying to

34
00:01:25,259 --> 00:01:28,259
help victims and and families get back

35
00:01:28,259 --> 00:01:30,570
on their feet there we've raised over

36
00:01:30,570 --> 00:01:32,880
seventy thousand US dollars so far and

37
00:01:32,880 --> 00:01:35,820
we are still going so please do please

38
00:01:35,820 --> 00:01:37,350
do phone this hotline number we'll put

39
00:01:37,350 --> 00:01:39,720
it here but maybe for the recording no

40
00:01:39,720 --> 00:01:41,460
no seriously do you go to all the top

41
00:01:41,460 --> 00:01:43,740
log forward slash tickets and you can go

42
00:01:43,740 --> 00:01:47,250
and donate as much as you can or as much

43
00:01:47,250 --> 00:01:49,799
as as much as it is reasonable so thank

44
00:01:49,799 --> 00:01:51,990
you very much and Richard what I'll do

45
00:01:51,990 --> 00:01:54,390
is I'll add your stream and your screen

46
00:01:54,390 --> 00:01:57,240
in there and I'll let you take it away

47
00:01:57,240 --> 00:01:59,340
thank you Richard thank you very much

48
00:01:59,340 --> 00:02:02,850
silent as I was saying I'm going to talk

49
00:02:02,850 --> 00:02:04,829
about continuous profiling production

50
00:02:04,829 --> 00:02:09,479
what why and how today so in this talk

51
00:02:09,479 --> 00:02:11,310
we're going to cover a few different

52
00:02:11,310 --> 00:02:13,660
things firstly you want

53
00:02:13,660 --> 00:02:15,820
performance tooling and why you want to

54
00:02:15,820 --> 00:02:18,150
look on the kind of problems that

55
00:02:18,150 --> 00:02:20,080
performance tutors can solve and the

56
00:02:20,080 --> 00:02:21,550
insights they can give you I'm going to

57
00:02:21,550 --> 00:02:22,450
talk about the distinction between

58
00:02:22,450 --> 00:02:25,000
measuring problems in a development

59
00:02:25,000 --> 00:02:26,770
versus a production environment because

60
00:02:26,770 --> 00:02:30,300
often people use performance tools like

61
00:02:30,300 --> 00:02:32,500
profiles and things in a development

62
00:02:32,500 --> 00:02:33,910
environment and actually they can often

63
00:02:33,910 --> 00:02:35,140
be more useful in a production

64
00:02:35,140 --> 00:02:36,760
environment then we're going to look at

65
00:02:36,760 --> 00:02:39,280
the different information that you can

66
00:02:39,280 --> 00:02:41,680
get out of a production system so

67
00:02:41,680 --> 00:02:44,470
metrics and profiling and logs and all

68
00:02:44,470 --> 00:02:46,060
sorts of different things and I want to

69
00:02:46,060 --> 00:02:48,550
look at continuous profiling what that

70
00:02:48,550 --> 00:02:50,500
is and how it can help people and draw

71
00:02:50,500 --> 00:02:52,540
some conclusions so firstly what we're

72
00:02:52,540 --> 00:02:54,310
thinking about you know a lot of things

73
00:02:54,310 --> 00:02:55,780
to do with our software system

74
00:02:55,780 --> 00:02:57,790
architecture development with not a

75
00:02:57,790 --> 00:02:59,530
think of three different classes of

76
00:02:59,530 --> 00:03:00,940
problems that we see with the rosen

77
00:03:00,940 --> 00:03:03,100
application firstly there are your known

78
00:03:03,100 --> 00:03:06,910
knowns so these are things that you know

79
00:03:06,910 --> 00:03:09,250
are going to be a problem ahead of time

80
00:03:09,250 --> 00:03:11,650
you can prep for them you can plan for

81
00:03:11,650 --> 00:03:14,470
them you can architect around them you

82
00:03:14,470 --> 00:03:17,230
know for example that main memory is

83
00:03:17,230 --> 00:03:20,470
faster than say disk X at least if

84
00:03:20,470 --> 00:03:22,930
you're on spinning rust and things you

85
00:03:22,930 --> 00:03:25,090
know certain key characteristics about

86
00:03:25,090 --> 00:03:27,130
your your setup like that then there are

87
00:03:27,130 --> 00:03:30,130
your unknown unknowns so these are

88
00:03:30,130 --> 00:03:31,180
things where you don't so know the

89
00:03:31,180 --> 00:03:33,100
details the reversionary know they're

90
00:03:33,100 --> 00:03:34,630
there but they're problems that you

91
00:03:34,630 --> 00:03:37,300
could plan for you could brainstorm you

92
00:03:37,300 --> 00:03:40,540
could think through you don't know what

93
00:03:40,540 --> 00:03:42,430
the exact ratio for example between

94
00:03:42,430 --> 00:03:45,880
memory and disk i/o actually is but you

95
00:03:45,880 --> 00:03:47,770
know that's a ratio that could differ on

96
00:03:47,770 --> 00:03:49,150
different production environments and

97
00:03:49,150 --> 00:03:50,890
you know for example that you might want

98
00:03:50,890 --> 00:03:52,060
to test these kind of characteristics

99
00:03:52,060 --> 00:03:54,550
when say for example moving to a

100
00:03:54,550 --> 00:03:56,530
different data center or moving to a

101
00:03:56,530 --> 00:03:59,320
different cloud instance and they're

102
00:03:59,320 --> 00:04:01,900
your unknown unknowns these are things

103
00:04:01,900 --> 00:04:04,000
which okay maybe if you knew they're a

104
00:04:04,000 --> 00:04:05,860
prop in advance you could plan for but

105
00:04:05,860 --> 00:04:07,209
in practice other things that you don't

106
00:04:07,209 --> 00:04:09,070
think about the things that you don't

107
00:04:09,070 --> 00:04:11,530
necessarily aren't necessarily aware of

108
00:04:11,530 --> 00:04:14,110
beforehand these are things that are

109
00:04:14,110 --> 00:04:16,029
really kick people there for example

110
00:04:16,029 --> 00:04:18,488
you've got some nice fancy parallel

111
00:04:18,488 --> 00:04:20,260
algorithm you've done your big ol

112
00:04:20,260 --> 00:04:22,990
analysis and then you don't realize that

113
00:04:22,990 --> 00:04:26,480
you've got some logging system call

114
00:04:26,480 --> 00:04:27,860
in the middle of this nice parallel

115
00:04:27,860 --> 00:04:29,480
algorithm is a bigger lock in your

116
00:04:29,480 --> 00:04:31,340
logger and it's slowing everything down

117
00:04:31,340 --> 00:04:32,690
these are things that you don't really

118
00:04:32,690 --> 00:04:34,400
know and so you go live with a real

119
00:04:34,400 --> 00:04:36,020
production system and they're things

120
00:04:36,020 --> 00:04:37,880
that you can only really understand from

121
00:04:37,880 --> 00:04:39,580
the real world you can't necessarily

122
00:04:39,580 --> 00:04:42,020
theorize or hypothesize about it no

123
00:04:42,020 --> 00:04:43,180
matter how smart you are

124
00:04:43,180 --> 00:04:46,850
so when people look at solving problems

125
00:04:46,850 --> 00:04:48,950
and working and improving their products

126
00:04:48,950 --> 00:04:50,960
they often think in terms of their

127
00:04:50,960 --> 00:04:54,560
development environments so that can

128
00:04:54,560 --> 00:04:55,880
often be very productive we run

129
00:04:55,880 --> 00:04:59,060
automated tests in our IDE we can get

130
00:04:59,060 --> 00:05:02,000
IDE tooling people can help solve

131
00:05:02,000 --> 00:05:03,500
security problems in a development

132
00:05:03,500 --> 00:05:05,630
environment now lots of fantastic stuff

133
00:05:05,630 --> 00:05:08,560
out there but for performance problems

134
00:05:08,560 --> 00:05:11,060
development and production of very very

135
00:05:11,060 --> 00:05:13,640
different worlds and in practice if you

136
00:05:13,640 --> 00:05:14,930
measure things in your development

137
00:05:14,930 --> 00:05:17,030
environment you will see different

138
00:05:17,030 --> 00:05:19,400
problems to production there's a few

139
00:05:19,400 --> 00:05:21,410
different reasons for this firstly

140
00:05:21,410 --> 00:05:24,500
there's the unrepresentative hardware

141
00:05:24,500 --> 00:05:28,550
problem so in practice machines that

142
00:05:28,550 --> 00:05:31,100
people use for their data sister centers

143
00:05:31,100 --> 00:05:34,010
production systems are often very very

144
00:05:34,010 --> 00:05:35,420
different from the kind of machines that

145
00:05:35,420 --> 00:05:39,740
they develop on so for example you may

146
00:05:39,740 --> 00:05:42,320
be developing code on a laptop you may

147
00:05:42,320 --> 00:05:44,630
have a workstation machine but you're

148
00:05:44,630 --> 00:05:46,370
very unlikely to have more than eight

149
00:05:46,370 --> 00:05:48,650
cores on that machine even if you've got

150
00:05:48,650 --> 00:05:52,130
a pretty beefy desktop machine like the

151
00:05:52,130 --> 00:05:53,840
one I'm using to present this on you're

152
00:05:53,840 --> 00:05:55,790
only gonna have about 16 cores probably

153
00:05:55,790 --> 00:05:59,360
servers these days now 64 128 cores are

154
00:05:59,360 --> 00:06:01,430
a lot and they can be very very

155
00:06:01,430 --> 00:06:06,350
different types of CPU as well often the

156
00:06:06,350 --> 00:06:08,420
exams with bigger caches and sometimes

157
00:06:08,420 --> 00:06:11,000
lower clock speeds in practice just

158
00:06:11,000 --> 00:06:12,710
because things perform well on your

159
00:06:12,710 --> 00:06:14,420
laptop it doesn't mean you're gonna hit

160
00:06:14,420 --> 00:06:16,280
the same performance problems as all

161
00:06:16,280 --> 00:06:18,050
those big workstation machines you can

162
00:06:18,050 --> 00:06:20,030
get lock contention problems which are

163
00:06:20,030 --> 00:06:21,680
visible with many many cores that are

164
00:06:21,680 --> 00:06:23,630
not very visible when you've just got a

165
00:06:23,630 --> 00:06:26,210
few cause you can have different ratios

166
00:06:26,210 --> 00:06:28,670
of CPU and disk i/o rates that shift

167
00:06:28,670 --> 00:06:30,140
your performance differently and if

168
00:06:30,140 --> 00:06:31,940
you're using a modern cloud environment

169
00:06:31,940 --> 00:06:35,240
often those small micro instances and

170
00:06:35,240 --> 00:06:37,130
functions or service platforms can

171
00:06:37,130 --> 00:06:39,140
actually be way way slower than your

172
00:06:39,140 --> 00:06:40,639
development

173
00:06:40,639 --> 00:06:43,800
then there's unrepresentative software

174
00:06:43,800 --> 00:06:47,190
in practice most people deploy their

175
00:06:47,190 --> 00:06:49,440
software stack onto say a Linux

176
00:06:49,440 --> 00:06:52,380
operating system in production they may

177
00:06:52,380 --> 00:06:53,940
well be running on top of virtualization

178
00:06:53,940 --> 00:06:56,190
layer they may well be running on top of

179
00:06:56,190 --> 00:06:59,810
docker within that virtualization layer

180
00:06:59,810 --> 00:07:01,800
for all sorts of things going on there

181
00:07:01,800 --> 00:07:04,200
in development they may well be running

182
00:07:04,200 --> 00:07:06,450
Windows or Mac OS they have completely

183
00:07:06,450 --> 00:07:08,610
different scheduler systems different

184
00:07:08,610 --> 00:07:10,830
bios subsystems different network stacks

185
00:07:10,830 --> 00:07:14,610
Linux and perform very differently and

186
00:07:14,610 --> 00:07:16,740
Linux isn't always faster either and

187
00:07:16,740 --> 00:07:18,630
again as we say different ratios or

188
00:07:18,630 --> 00:07:19,830
different performance characteristics

189
00:07:19,830 --> 00:07:22,620
shift where your bottlenecks are even

190
00:07:22,620 --> 00:07:24,840
running a different version of the same

191
00:07:24,840 --> 00:07:27,960
operating system can cause very very

192
00:07:27,960 --> 00:07:29,970
different performance characteristics

193
00:07:29,970 --> 00:07:32,010
back in May 2015

194
00:07:32,010 --> 00:07:34,860
there was a regular Patch Tuesday update

195
00:07:34,860 --> 00:07:37,850
for Windows that tant UDP throughput by

196
00:07:37,850 --> 00:07:41,070
40% on some benchmarks I was running and

197
00:07:41,070 --> 00:07:43,350
that was just for on those Spectre

198
00:07:43,350 --> 00:07:45,840
meltdown mitigation things I think but

199
00:07:45,840 --> 00:07:48,300
some these performance characteristics

200
00:07:48,300 --> 00:07:54,360
can be very big and finally it's the

201
00:07:54,360 --> 00:07:57,090
workload this is the hardest problem to

202
00:07:57,090 --> 00:07:59,550
solve the biggest differentiating factor

203
00:07:59,550 --> 00:08:01,710
between you trying to replicate and

204
00:08:01,710 --> 00:08:03,990
diagnose a performance problem in your

205
00:08:03,990 --> 00:08:05,669
development environment and a real

206
00:08:05,669 --> 00:08:09,590
production system if you have different

207
00:08:09,590 --> 00:08:12,479
numbers of users hitting your system if

208
00:08:12,479 --> 00:08:15,150
you aren't necessarily running a system

209
00:08:15,150 --> 00:08:16,590
that is dealing with a lot of network

210
00:08:16,590 --> 00:08:18,330
traffic towards other services you know

211
00:08:18,330 --> 00:08:19,560
development environment maybe you're

212
00:08:19,560 --> 00:08:21,180
running them or docker images on the

213
00:08:21,180 --> 00:08:22,740
same box versus running on different

214
00:08:22,740 --> 00:08:25,470
hosts in production if you're using your

215
00:08:25,470 --> 00:08:30,630
different load harness a different type

216
00:08:30,630 --> 00:08:33,089
of load on the system you can get very

217
00:08:33,089 --> 00:08:35,520
very unrepresentative workloads you can

218
00:08:35,520 --> 00:08:38,849
be hitting wrong pages you can be you

219
00:08:38,849 --> 00:08:40,229
can have things that look like they're

220
00:08:40,229 --> 00:08:42,900
in cache a lot in performance tests when

221
00:08:42,900 --> 00:08:44,580
your real production systems they aren't

222
00:08:44,580 --> 00:08:46,110
you can get things where for example

223
00:08:46,110 --> 00:08:48,150
with lots and lots of users you might

224
00:08:48,150 --> 00:08:51,300
not have your user data in cache in a

225
00:08:51,300 --> 00:08:52,650
production system whereas you might were

226
00:08:52,650 --> 00:08:53,520
just testing with

227
00:08:53,520 --> 00:08:56,580
one user it's very very very hard to get

228
00:08:56,580 --> 00:08:58,380
in synthetic performance test or

229
00:08:58,380 --> 00:08:59,640
replicate your production environment

230
00:08:59,640 --> 00:09:02,370
and even if you do get it that's not the

231
00:09:02,370 --> 00:09:03,990
end of the story you have to maintain

232
00:09:03,990 --> 00:09:06,930
that as your users change their behavior

233
00:09:06,930 --> 00:09:09,270
as your system changes its behavior as

234
00:09:09,270 --> 00:09:11,070
you add more features you have to add

235
00:09:11,070 --> 00:09:13,080
performance tests for those in practice

236
00:09:13,080 --> 00:09:15,330
performance testing well and effectively

237
00:09:15,330 --> 00:09:17,490
could often be so hard that many

238
00:09:17,490 --> 00:09:20,480
organizations don't even bother

239
00:09:20,480 --> 00:09:23,430
insurance you need to measure the right

240
00:09:23,430 --> 00:09:26,760
thing okay if you measure the wrong

241
00:09:26,760 --> 00:09:29,100
thing you will fix the wrong problems

242
00:09:29,100 --> 00:09:31,170
and you will not be able to spot and

243
00:09:31,170 --> 00:09:34,020
rectify real performance problems real

244
00:09:34,020 --> 00:09:35,970
performance bottlenecks that cause

245
00:09:35,970 --> 00:09:37,650
actual outages for your production

246
00:09:37,650 --> 00:09:40,500
system and problems there okay

247
00:09:40,500 --> 00:09:42,540
so he said you don't want to look at

248
00:09:42,540 --> 00:09:43,890
your development environment to

249
00:09:43,890 --> 00:09:45,780
understand the causes of your

250
00:09:45,780 --> 00:09:47,580
performance problems where do you want

251
00:09:47,580 --> 00:09:50,070
to look production but what information

252
00:09:50,070 --> 00:09:51,870
can you actually get out of production

253
00:09:51,870 --> 00:09:52,950
production has a different

254
00:09:52,950 --> 00:09:55,170
characteristic extracting information

255
00:09:55,170 --> 00:09:57,210
for production has to be very low

256
00:09:57,210 --> 00:09:59,640
overhead because a higher over and it is

257
00:09:59,640 --> 00:10:02,610
the more it slows your system down the

258
00:10:02,610 --> 00:10:04,080
first type of information that people

259
00:10:04,080 --> 00:10:06,050
get from their production system are

260
00:10:06,050 --> 00:10:09,810
metrics so these are pre-configured

261
00:10:09,810 --> 00:10:11,850
numerical measures these are just like a

262
00:10:11,850 --> 00:10:14,340
series of numbers in a time series that

263
00:10:14,340 --> 00:10:18,030
evolves over time you can get things

264
00:10:18,030 --> 00:10:20,130
like CPU time usage breakdown between

265
00:10:20,130 --> 00:10:23,370
user system disk i/o rates all sorts of

266
00:10:23,370 --> 00:10:25,110
things like that to understand what your

267
00:10:25,110 --> 00:10:27,210
system is doing your page load times

268
00:10:27,210 --> 00:10:30,540
memory consumption metrics can be very

269
00:10:30,540 --> 00:10:32,730
very useful they can be very very cheap

270
00:10:32,730 --> 00:10:34,920
very low overhead to gather that and

271
00:10:34,920 --> 00:10:36,960
pull it out of a production system and

272
00:10:36,960 --> 00:10:39,030
sometimes they can be very effective and

273
00:10:39,030 --> 00:10:41,580
narrowing down where performance

274
00:10:41,580 --> 00:10:44,130
problems are where bottlenecks are in

275
00:10:44,130 --> 00:10:47,190
your system but the problem of metrics

276
00:10:47,190 --> 00:10:50,460
is that you often end up in one of those

277
00:10:50,460 --> 00:10:53,070
murder-mystery weekend investigations

278
00:10:53,070 --> 00:10:56,070
now these things sound very fun and you

279
00:10:56,070 --> 00:11:00,030
know if you've ever seen a qrow show or

280
00:11:00,030 --> 00:11:01,860
read one of the books you'll know that

281
00:11:01,860 --> 00:11:03,810
they can be exciting it goes around and

282
00:11:03,810 --> 00:11:05,520
says were you the murderer were you the

283
00:11:05,520 --> 00:11:07,220
murderer and it's always the last /

284
00:11:07,220 --> 00:11:09,620
you look at who turns out to be the

285
00:11:09,620 --> 00:11:11,780
murderer and you can same kind of

286
00:11:11,780 --> 00:11:14,270
situation with metrics often people try

287
00:11:14,270 --> 00:11:16,160
and measure every single metric Under

288
00:11:16,160 --> 00:11:17,690
the Sun because they want to know

289
00:11:17,690 --> 00:11:19,010
everything but then when they're

290
00:11:19,010 --> 00:11:19,970
actually trying to look for a

291
00:11:19,970 --> 00:11:21,710
performance problem it takes them a long

292
00:11:21,710 --> 00:11:22,970
time to find the resolution cuz they

293
00:11:22,970 --> 00:11:24,740
start scanning through and looking at

294
00:11:24,740 --> 00:11:26,750
these different metrics to see what is

295
00:11:26,750 --> 00:11:29,240
way out of band today what is unusual

296
00:11:29,240 --> 00:11:31,190
and often if you measure a lot of things

297
00:11:31,190 --> 00:11:33,410
you can find correlated failures so it

298
00:11:33,410 --> 00:11:35,600
cannot be necessarily obvious which

299
00:11:35,600 --> 00:11:38,260
metric is is the real problem here

300
00:11:38,260 --> 00:11:40,670
brings us to logging logging can be

301
00:11:40,670 --> 00:11:42,080
incredibly useful for extracting

302
00:11:42,080 --> 00:11:43,510
information reproduction system

303
00:11:43,510 --> 00:11:45,830
arbitrary events emitted by the system

304
00:11:45,830 --> 00:11:48,920
being monitored so less log4j s leverage

305
00:11:48,920 --> 00:11:52,550
a log back log extraction systems log

306
00:11:52,550 --> 00:11:54,590
aggregation systems often very very

307
00:11:54,590 --> 00:11:56,690
useful I don't say these things are

308
00:11:56,690 --> 00:11:58,760
necessarily bad individually the problem

309
00:11:58,760 --> 00:12:00,350
is that if you really want detailed

310
00:12:00,350 --> 00:12:02,660
events being emitted by the system it's

311
00:12:02,660 --> 00:12:05,870
often very manual a lot of work that

312
00:12:05,870 --> 00:12:07,820
your developers have to do sometimes

313
00:12:07,820 --> 00:12:09,650
people have whole teams building

314
00:12:09,650 --> 00:12:11,320
observability platforms around

315
00:12:11,320 --> 00:12:14,030
instrumenting and emitting logging

316
00:12:14,030 --> 00:12:16,520
events can be very detailed can aid

317
00:12:16,520 --> 00:12:18,200
system understanding can give you a

318
00:12:18,200 --> 00:12:20,780
cause that metrics don't necessarily

319
00:12:20,780 --> 00:12:23,600
give but there's a lot of overhead there

320
00:12:23,600 --> 00:12:25,430
and you have to be very careful the old

321
00:12:25,430 --> 00:12:27,230
logging systems don't become the

322
00:12:27,230 --> 00:12:29,120
bottleneck in and of themselves which

323
00:12:29,120 --> 00:12:31,490
I've seen on so many people's production

324
00:12:31,490 --> 00:12:37,130
systems there are also logs for more

325
00:12:37,130 --> 00:12:39,110
specific event so garbage collection

326
00:12:39,110 --> 00:12:41,660
logs for example tell you our events

327
00:12:41,660 --> 00:12:43,850
were in the GC subsystem super useful

328
00:12:43,850 --> 00:12:46,130
quite low overhead actually for GC logs

329
00:12:46,130 --> 00:12:49,550
but very very niche understanding if you

330
00:12:49,550 --> 00:12:51,680
want to do GC tuning very very useful if

331
00:12:51,680 --> 00:12:53,360
you wanna look at other areas maybe not

332
00:12:53,360 --> 00:12:54,070
so useful

333
00:12:54,070 --> 00:12:55,790
then there's course for any

334
00:12:55,790 --> 00:12:57,860
instrumentation this is the kind of

335
00:12:57,860 --> 00:12:59,570
instrumentation that most application

336
00:12:59,570 --> 00:13:01,820
performance monitoring APM tools provide

337
00:13:01,820 --> 00:13:05,089
so they take the start time and end time

338
00:13:05,089 --> 00:13:10,339
of an operation of a method and they

339
00:13:10,339 --> 00:13:11,930
subtract one from the other you take the

340
00:13:11,930 --> 00:13:14,690
time that that operation took Matco the

341
00:13:14,690 --> 00:13:16,470
ER adding is called the instrument

342
00:13:16,470 --> 00:13:19,770
code or instrumentation the key part of

343
00:13:19,770 --> 00:13:21,990
instrumentation is it can be very

344
00:13:21,990 --> 00:13:26,310
detailed it can give you vectors into

345
00:13:26,310 --> 00:13:27,720
your code base that let you understand

346
00:13:27,720 --> 00:13:32,310
where that problem is but it can also be

347
00:13:32,310 --> 00:13:34,680
very overhead it can also be very heavy

348
00:13:34,680 --> 00:13:36,840
in terms of overhead the more detailed

349
00:13:36,840 --> 00:13:39,180
your instrumentation is and they're more

350
00:13:39,180 --> 00:13:41,040
actionable that instrumentation is I

351
00:13:41,040 --> 00:13:43,170
know it tells you more specifically what

352
00:13:43,170 --> 00:13:45,480
the problem is the more overhead there

353
00:13:45,480 --> 00:13:46,950
is to running it but it's perfectly good

354
00:13:46,950 --> 00:13:49,140
for things like how much time you spend

355
00:13:49,140 --> 00:13:50,460
inside the control there of your web app

356
00:13:50,460 --> 00:13:52,650
or how much time do you spend performing

357
00:13:52,650 --> 00:13:57,120
sequel queries production profiling

358
00:13:57,120 --> 00:13:59,460
what's production profile profiling is a

359
00:13:59,460 --> 00:14:02,490
very general method for telling you what

360
00:14:02,490 --> 00:14:04,320
is the dominant consumer of a certain

361
00:14:04,320 --> 00:14:06,090
resource or a certain type of event

362
00:14:06,090 --> 00:14:09,180
within your system so what methods used

363
00:14:09,180 --> 00:14:12,630
up CPU time what lines of code allocated

364
00:14:12,630 --> 00:14:14,870
the most objects things like that

365
00:14:14,870 --> 00:14:18,270
profiling is automatic so you don't need

366
00:14:18,270 --> 00:14:20,100
to tell your profiler

367
00:14:20,100 --> 00:14:22,320
anything about your application or an

368
00:14:22,320 --> 00:14:24,360
instrumentation it can just probe as you

369
00:14:24,360 --> 00:14:27,000
can profile the JVM app you can profile

370
00:14:27,000 --> 00:14:30,930
the JVM app it can be made very very

371
00:14:30,930 --> 00:14:33,660
cheap it can be made to be very very low

372
00:14:33,660 --> 00:14:34,740
overheads

373
00:14:34,740 --> 00:14:37,560
but often a lot of profilers especially

374
00:14:37,560 --> 00:14:38,970
profiles designed for development

375
00:14:38,970 --> 00:14:41,090
environment are not low overhead they

376
00:14:41,090 --> 00:14:45,750
slow down the application under profile

377
00:14:45,750 --> 00:14:48,120
by quite a lot and are thus not usable

378
00:14:48,120 --> 00:14:50,220
in production and we really want profile

379
00:14:50,220 --> 00:14:51,840
in the works in production we'll talk

380
00:14:51,840 --> 00:14:53,250
briefly later on about the kind of

381
00:14:53,250 --> 00:14:55,950
profiles that are low enough overhead

382
00:14:55,950 --> 00:14:57,380
that we can use in production

383
00:14:57,380 --> 00:15:00,170
another problem that instrumentation is

384
00:15:00,170 --> 00:15:02,550
challenging a challenging another

385
00:15:02,550 --> 00:15:03,600
problem is a challenge for

386
00:15:03,600 --> 00:15:06,150
instrumentation is a factor alone

387
00:15:06,150 --> 00:15:07,530
instrumentation needs to be added a

388
00:15:07,530 --> 00:15:10,530
priori before a problem happens and if

389
00:15:10,530 --> 00:15:11,610
the person who designed that

390
00:15:11,610 --> 00:15:14,280
instrumentation system didn't think

391
00:15:14,280 --> 00:15:16,080
about your category of problems you will

392
00:15:16,080 --> 00:15:18,570
be blind to them not only bigger

393
00:15:18,570 --> 00:15:21,240
overhead but it's kind of assumption

394
00:15:21,240 --> 00:15:24,210
driven hypothesis full monitoring

395
00:15:24,210 --> 00:15:25,950
approach so we have a customer for

396
00:15:25,950 --> 00:15:27,570
example at option who

397
00:15:27,570 --> 00:15:30,240
had a problem every five seconds they

398
00:15:30,240 --> 00:15:31,710
had a certain HTTP endpoint that we

399
00:15:31,710 --> 00:15:33,390
rarely slow would respond to any

400
00:15:33,390 --> 00:15:35,790
requests for a couple seconds they had

401
00:15:35,790 --> 00:15:37,650
the APM tool in place it had a sherman

402
00:15:37,650 --> 00:15:39,270
tation and they look to the the

403
00:15:39,270 --> 00:15:40,830
monitoring dashboard for that APM tool

404
00:15:40,830 --> 00:15:43,770
he didn't even show the pause the APM

405
00:15:43,770 --> 00:15:45,510
tool said look everything's fine your

406
00:15:45,510 --> 00:15:47,490
systems going really fast but their

407
00:15:47,490 --> 00:15:50,160
users their users could definitely see

408
00:15:50,160 --> 00:15:52,620
the slowdown were being frustrated by it

409
00:15:52,620 --> 00:15:55,050
now the problem here was that the

410
00:15:55,050 --> 00:15:56,850
instrumentation was on the server that

411
00:15:56,850 --> 00:15:59,340
request so only looked how long it took

412
00:15:59,340 --> 00:16:01,260
to process a sermon the request didn't

413
00:16:01,260 --> 00:16:03,270
look at the bigger picture the system

414
00:16:03,270 --> 00:16:05,790
view the gestalt view the root cause

415
00:16:05,790 --> 00:16:08,340
here was the Tomcat was expiring to

416
00:16:08,340 --> 00:16:10,110
resource cache every five seconds so

417
00:16:10,110 --> 00:16:12,300
every five seconds it would go and talk

418
00:16:12,300 --> 00:16:13,950
towards a resource and say to you know

419
00:16:13,950 --> 00:16:17,040
you know update things here one of those

420
00:16:17,040 --> 00:16:18,750
resources once it's going to scan their

421
00:16:18,750 --> 00:16:21,570
entire class path which was pretty big

422
00:16:21,570 --> 00:16:23,760
it would pause the whole system for a

423
00:16:23,760 --> 00:16:25,590
couple of seconds so that's the kind of

424
00:16:25,590 --> 00:16:27,480
cool thing that can be easily spotted

425
00:16:27,480 --> 00:16:30,690
within seconds of looking at a profiling

426
00:16:30,690 --> 00:16:33,030
view what we're spending all of our time

427
00:16:33,030 --> 00:16:35,310
reloading classes and scanning the class

428
00:16:35,310 --> 00:16:37,230
path we weren't expecting that at all

429
00:16:37,230 --> 00:16:38,880
but it's something that if you don't

430
00:16:38,880 --> 00:16:41,400
think about ahead of time other metrics

431
00:16:41,400 --> 00:16:42,750
and instrumentation wouldn't necessarily

432
00:16:42,750 --> 00:16:46,650
show okay so let's talk about continuous

433
00:16:46,650 --> 00:16:48,990
profiling firstly how do we use

434
00:16:48,990 --> 00:16:50,790
continuous profiles or when I extract a

435
00:16:50,790 --> 00:16:53,100
time period or your applications

436
00:16:53,100 --> 00:16:54,840
machines the performance problem that

437
00:16:54,840 --> 00:16:56,730
you want to look at pick an event to

438
00:16:56,730 --> 00:16:58,590
profile profiles are about measuring

439
00:16:58,590 --> 00:17:00,420
certain events counting certain events

440
00:17:00,420 --> 00:17:03,300
view the results of what the dominant

441
00:17:03,300 --> 00:17:05,189
consumer of that resource of that event

442
00:17:05,189 --> 00:17:06,869
is so what was the thing that was really

443
00:17:06,869 --> 00:17:09,150
the bottle net what was eating the

444
00:17:09,150 --> 00:17:11,000
resource up fix that bottleneck

445
00:17:11,000 --> 00:17:13,680
preferably only one bottleneck if you've

446
00:17:13,680 --> 00:17:15,900
got a nice modern DevOps system can

447
00:17:15,900 --> 00:17:17,819
redeploy rapidly better to fix a

448
00:17:17,819 --> 00:17:20,250
bottleneck redeploy we measure and do it

449
00:17:20,250 --> 00:17:21,720
scientifically change one thing at a

450
00:17:21,720 --> 00:17:22,609
time

451
00:17:22,609 --> 00:17:25,260
profiling can measure all sorts of

452
00:17:25,260 --> 00:17:26,490
different types of events from your

453
00:17:26,490 --> 00:17:28,800
system you can look at CPU time a wall

454
00:17:28,800 --> 00:17:31,050
clock time we'll look at time in a

455
00:17:31,050 --> 00:17:32,580
second you can look at things like

456
00:17:32,580 --> 00:17:35,880
memory allocations what is eating up the

457
00:17:35,880 --> 00:17:37,770
memory on your keyboard is allocating

458
00:17:37,770 --> 00:17:40,080
lots of objects and you can look at

459
00:17:40,080 --> 00:17:40,890
things but more

460
00:17:40,890 --> 00:17:43,380
esoteric or obscure like cache misses

461
00:17:43,380 --> 00:17:45,810
and cache hits all sorts of stuff like

462
00:17:45,810 --> 00:17:46,310
that

463
00:17:46,310 --> 00:17:48,930
so I mentioned these two different types

464
00:17:48,930 --> 00:17:51,240
of time CPU time and wall clock time

465
00:17:51,240 --> 00:17:52,470
because I think it's often very

466
00:17:52,470 --> 00:17:53,910
confusing for people when they look at

467
00:17:53,910 --> 00:18:01,410
profilers CPU time is the actual time do

468
00:18:01,410 --> 00:18:04,560
you spend on CPU executing instructions

469
00:18:04,560 --> 00:18:07,170
on wall clock time is to begin to end

470
00:18:07,170 --> 00:18:11,880
time of your actual operation I as

471
00:18:11,880 --> 00:18:13,950
somebody who's addicted to coffee like

472
00:18:13,950 --> 00:18:15,900
to think of this in terms of a coffee

473
00:18:15,900 --> 00:18:18,360
analogy now if you go to a good coffee

474
00:18:18,360 --> 00:18:20,520
shop or even a Starbucks at lunch you'll

475
00:18:20,520 --> 00:18:22,530
find that there's a big queue outside

476
00:18:22,530 --> 00:18:25,200
the front of that cafe and there are

477
00:18:25,200 --> 00:18:27,270
people waiting that you the time it

478
00:18:27,270 --> 00:18:28,530
takes you to get your coffee from

479
00:18:28,530 --> 00:18:30,000
beginning to end waiting the queue

480
00:18:30,000 --> 00:18:32,460
paying the various taking your order

481
00:18:32,460 --> 00:18:34,350
making the coffee queueing the other

482
00:18:34,350 --> 00:18:36,180
side of your coffee to pop out of that's

483
00:18:36,180 --> 00:18:37,890
your wall clock time that begin to end

484
00:18:37,890 --> 00:18:40,260
time on the operation CPU time is more

485
00:18:40,260 --> 00:18:43,020
like the time that the barista is

486
00:18:43,020 --> 00:18:44,250
spending actually making the coffee

487
00:18:44,250 --> 00:18:46,020
taking people's money the time actually

488
00:18:46,020 --> 00:18:49,950
doing stuff if you want to understand a

489
00:18:49,950 --> 00:18:51,720
wide range of performance problems

490
00:18:51,720 --> 00:18:53,730
within your system you need to look at

491
00:18:53,730 --> 00:18:58,370
both CPU time and walk lock time okay

492
00:18:58,370 --> 00:19:01,550
CPU time can help you diagnose

493
00:19:01,550 --> 00:19:04,620
computationally inefficient bottlenecks

494
00:19:04,620 --> 00:19:06,960
and hotspots it can let you see code

495
00:19:06,960 --> 00:19:08,610
that shouldn't be executing there's

496
00:19:08,610 --> 00:19:10,670
actually take up loads of time like our

497
00:19:10,670 --> 00:19:12,200
aforementioned

498
00:19:12,200 --> 00:19:15,180
example of the Tomcat class path scaling

499
00:19:15,180 --> 00:19:18,480
type stuff it also is scaled by what is

500
00:19:18,480 --> 00:19:23,040
actually running on CPU over time warp

501
00:19:23,040 --> 00:19:26,700
lock time however diagnosis blocking

502
00:19:26,700 --> 00:19:30,330
problems but stop CPU usage of CPU

503
00:19:30,330 --> 00:19:32,730
profiling is related here as well so for

504
00:19:32,730 --> 00:19:34,230
example if you've got a fancy

505
00:19:34,230 --> 00:19:36,450
microservices set up and a lot of your

506
00:19:36,450 --> 00:19:38,370
time you just spend waiting to get data

507
00:19:38,370 --> 00:19:39,660
back from other services

508
00:19:39,660 --> 00:19:41,670
that's what wall clock time can help you

509
00:19:41,670 --> 00:19:44,160
with if you spend a lot of time reading

510
00:19:44,160 --> 00:19:46,410
or writing chrome discs that's that will

511
00:19:46,410 --> 00:19:48,000
show up in wall clock time waiting on

512
00:19:48,000 --> 00:19:50,400
i/o and lock contention systems with

513
00:19:50,400 --> 00:19:52,470
issues within your system where you've

514
00:19:52,470 --> 00:19:55,200
got lots and lots of threads all

515
00:19:55,200 --> 00:19:58,050
get control of a hot lock they will be

516
00:19:58,050 --> 00:19:59,700
visible with wall clock time profile

517
00:19:59,700 --> 00:20:02,550
that is very very useful and not every

518
00:20:02,550 --> 00:20:05,790
system offers wall clock time based

519
00:20:05,790 --> 00:20:10,470
profiling profiling information can be

520
00:20:10,470 --> 00:20:12,600
visualized in a range of different ways

521
00:20:12,600 --> 00:20:15,030
so firstly there is a hotspots view or a

522
00:20:15,030 --> 00:20:17,400
flat profile view so that's just a list

523
00:20:17,400 --> 00:20:19,260
of methods within your application and

524
00:20:19,260 --> 00:20:22,380
they are sorted by what uses up the most

525
00:20:22,380 --> 00:20:25,260
amount of time or at the other resource

526
00:20:25,260 --> 00:20:28,590
that you're measuring good profilers

527
00:20:28,590 --> 00:20:30,450
will also let you see what the line

528
00:20:30,450 --> 00:20:32,880
number is for those profiling hotspots

529
00:20:32,880 --> 00:20:34,650
which parts of the methods are really

530
00:20:34,650 --> 00:20:37,500
hot which can be super useful in big

531
00:20:37,500 --> 00:20:40,310
large methods if your colleagues have

532
00:20:40,310 --> 00:20:42,270
unfortunately left you with those

533
00:20:42,270 --> 00:20:45,480
methods they can also give you a

534
00:20:45,480 --> 00:20:47,940
lifelong stat tracers that tell you what

535
00:20:47,940 --> 00:20:49,800
was calling those methods when they were

536
00:20:49,800 --> 00:20:54,210
hot a more modern more hip more useful

537
00:20:54,210 --> 00:20:56,760
visualization of profiling data can be

538
00:20:56,760 --> 00:21:00,720
found with flame grass okay so frame

539
00:21:00,720 --> 00:21:02,910
graph is a visualization where every

540
00:21:02,910 --> 00:21:05,910
method in your system is a box they can

541
00:21:05,910 --> 00:21:07,800
go top-down like this one is sometimes

542
00:21:07,800 --> 00:21:11,310
called bicycles or bottom-up the more

543
00:21:11,310 --> 00:21:13,950
flamey-o view of flame graphs in this

544
00:21:13,950 --> 00:21:17,760
top-down view every box is calling its

545
00:21:17,760 --> 00:21:20,880
bot it's children below it in the graph

546
00:21:20,880 --> 00:21:23,400
so Java and friend Run which is the top

547
00:21:23,400 --> 00:21:27,390
method in this visualization it's

548
00:21:27,390 --> 00:21:30,270
calling the nioh endpoint dollar

549
00:21:30,270 --> 00:21:32,580
accepted on run method inside tomcat and

550
00:21:32,580 --> 00:21:35,510
that's calling down into a tomcat stack

551
00:21:35,510 --> 00:21:38,340
the width of the boxes within flame

552
00:21:38,340 --> 00:21:41,310
grass visualize how much time roughly

553
00:21:41,310 --> 00:21:44,490
was used by a given method within your

554
00:21:44,490 --> 00:21:48,210
system so why the boxes are saying that

555
00:21:48,210 --> 00:21:49,830
this uses up more time but it's not just

556
00:21:49,830 --> 00:21:52,380
that method it's that method and it's

557
00:21:52,380 --> 00:21:54,720
children that use of time so when you're

558
00:21:54,720 --> 00:21:56,730
interpreting flame graphs you want to

559
00:21:56,730 --> 00:21:57,930
look for the points where the graphs

560
00:21:57,930 --> 00:21:59,970
narrow down where they've got children

561
00:21:59,970 --> 00:22:01,860
the narrower than them

562
00:22:01,860 --> 00:22:04,940
rather than just looking for fat boxes

563
00:22:04,940 --> 00:22:07,340
profane graphs are very good for

564
00:22:07,340 --> 00:22:10,610
visualizing profile data in context

565
00:22:10,610 --> 00:22:13,409
earlier I said many desktop profilers

566
00:22:13,409 --> 00:22:14,940
are not suitable for production

567
00:22:14,940 --> 00:22:17,429
profiling it's completely true hooking

568
00:22:17,429 --> 00:22:19,830
jb --lv maps of production can result in

569
00:22:19,830 --> 00:22:22,019
bad you having a bout of time advanced

570
00:22:22,019 --> 00:22:24,870
statistical profiling is the way forward

571
00:22:24,870 --> 00:22:27,630
in 2020 you can get accurate very very

572
00:22:27,630 --> 00:22:29,970
low overhead profiling data pretty much

573
00:22:29,970 --> 00:22:31,649
all the profilers that work like this

574
00:22:31,649 --> 00:22:34,409
have the following characteristics they

575
00:22:34,409 --> 00:22:38,519
use operating system signals like sig

576
00:22:38,519 --> 00:22:40,409
prof for example SiC alarm to send

577
00:22:40,409 --> 00:22:42,000
signals periodically to different

578
00:22:42,000 --> 00:22:43,769
threads within the system they use that

579
00:22:43,769 --> 00:22:45,210
to interrupt the thread as its operating

580
00:22:45,210 --> 00:22:47,460
and then capture stack traces at that

581
00:22:47,460 --> 00:22:50,309
point in time or they can get allocation

582
00:22:50,309 --> 00:22:52,080
data and capture stack traces on certain

583
00:22:52,080 --> 00:22:54,000
allocations as well traditional

584
00:22:54,000 --> 00:22:55,889
approaches are too slow but this works

585
00:22:55,889 --> 00:22:58,710
very very effectively I don't wanna go

586
00:22:58,710 --> 00:23:00,179
into too much more detail this is quite

587
00:23:00,179 --> 00:23:02,010
a short talk but there's lots of

588
00:23:02,010 --> 00:23:03,389
information online about this kind of

589
00:23:03,389 --> 00:23:05,220
stuff and it's an approach that you see

590
00:23:05,220 --> 00:23:08,370
increasingly effectively adopted in

591
00:23:08,370 --> 00:23:12,720
different ecosystems a job JVM world we

592
00:23:12,720 --> 00:23:14,549
have things like JFR async profiler an

593
00:23:14,549 --> 00:23:18,240
honest profiler ruby our spy Python pice

594
00:23:18,240 --> 00:23:21,299
by the native code ecosystem has perfect

595
00:23:21,299 --> 00:23:23,580
running on Linux and go has P prof these

596
00:23:23,580 --> 00:23:27,149
are low overheads ad hoc profiler so

597
00:23:27,149 --> 00:23:29,309
what I mean by ad hoc well they aren't

598
00:23:29,309 --> 00:23:31,440
profiling all the time necessary they're

599
00:23:31,440 --> 00:23:33,809
still in that desktop mode they're still

600
00:23:33,809 --> 00:23:35,909
in that mode of you've got to connect up

601
00:23:35,909 --> 00:23:38,130
to a production system what we want to

602
00:23:38,130 --> 00:23:40,260
do is think about profiling all the time

603
00:23:40,260 --> 00:23:43,860
so historical beta gives us the ability

604
00:23:43,860 --> 00:23:45,720
to look at things that happened in the

605
00:23:45,720 --> 00:23:48,029
past your outage was last night what was

606
00:23:48,029 --> 00:23:49,830
the profiling data from last night

607
00:23:49,830 --> 00:23:51,899
it lets you correlate with other data

608
00:23:51,899 --> 00:23:53,760
metrics you saw really high load

609
00:23:53,760 --> 00:23:56,010
yesterday afternoon look at the

610
00:23:56,010 --> 00:23:58,049
historical data for that time period it

611
00:23:58,049 --> 00:23:59,909
also lets you do performance regression

612
00:23:59,909 --> 00:24:01,740
analysis you release a new version of

613
00:24:01,740 --> 00:24:03,750
your software just look at the diff in

614
00:24:03,750 --> 00:24:06,210
profiling view in your profiler

615
00:24:06,210 --> 00:24:07,889
between the current version and the

616
00:24:07,889 --> 00:24:10,500
previous version of your software now

617
00:24:10,500 --> 00:24:13,200
it's continuous profiling taking data

618
00:24:13,200 --> 00:24:14,650
from different agents

619
00:24:14,650 --> 00:24:17,200
different systems out there aggregating

620
00:24:17,200 --> 00:24:18,970
them in a common service that lets you

621
00:24:18,970 --> 00:24:20,520
query over that historical data

622
00:24:20,520 --> 00:24:22,750
understand that historical data and

623
00:24:22,750 --> 00:24:25,150
process that historical data and having

624
00:24:25,150 --> 00:24:27,370
a modern web-based report not a

625
00:24:27,370 --> 00:24:29,560
traditional desktop profiler that you

626
00:24:29,560 --> 00:24:31,600
have to connect into the system in

627
00:24:31,600 --> 00:24:34,060
question and manually tweak around with

628
00:24:34,060 --> 00:24:35,650
things in order to see what's going on

629
00:24:35,650 --> 00:24:37,680
that doesn't work when you're running

630
00:24:37,680 --> 00:24:39,790
hundreds or thousands of different

631
00:24:39,790 --> 00:24:41,710
services in production it doesn't scaler

632
00:24:41,710 --> 00:24:44,170
and it also requires you things like

633
00:24:44,170 --> 00:24:46,450
very glass and try and connect into

634
00:24:46,450 --> 00:24:48,040
production systems when you're having a

635
00:24:48,040 --> 00:24:51,070
stressful high-risk outage you want to

636
00:24:51,070 --> 00:24:54,180
have these things set up in advance okay

637
00:24:54,180 --> 00:24:57,610
so two minutes left less time to draw

638
00:24:57,610 --> 00:25:00,370
some conclusions we think an option that

639
00:25:00,370 --> 00:25:01,570
you need to really take a real attitude

640
00:25:01,570 --> 00:25:03,910
shift on profiling your mantra we all

641
00:25:03,910 --> 00:25:08,290
can do so much better on this front we

642
00:25:08,290 --> 00:25:10,180
really we really can so there's three

643
00:25:10,180 --> 00:25:12,520
different parts of that firstly thinking

644
00:25:12,520 --> 00:25:13,870
about performance problems in a

645
00:25:13,870 --> 00:25:17,080
systematic way not an ad hoc way having

646
00:25:17,080 --> 00:25:19,960
a performance diagnostic methodology

647
00:25:19,960 --> 00:25:22,420
knowing what the relationship between

648
00:25:22,420 --> 00:25:24,130
different metrics are that you let you

649
00:25:24,130 --> 00:25:26,740
root down to different causes and having

650
00:25:26,740 --> 00:25:28,660
the right systems in place in order to

651
00:25:28,660 --> 00:25:30,460
be able to understand things being

652
00:25:30,460 --> 00:25:32,170
proactive not reactive

653
00:25:32,170 --> 00:25:34,120
that doesn't mean doing premature

654
00:25:34,120 --> 00:25:36,160
optimization within your software system

655
00:25:36,160 --> 00:25:37,690
what that means is having the right

656
00:25:37,690 --> 00:25:39,820
tooling and systems in place that you

657
00:25:39,820 --> 00:25:43,000
can measure what's going on with your

658
00:25:43,000 --> 00:25:44,680
production system you can perform a

659
00:25:44,680 --> 00:25:47,050
unicameral performance optimize and also

660
00:25:47,050 --> 00:25:49,270
really considering these things as being

661
00:25:49,270 --> 00:25:52,720
a business value win customers genuinely

662
00:25:52,720 --> 00:25:55,780
are often far far happier with a fast

663
00:25:55,780 --> 00:25:57,670
system than a slow system and there's a

664
00:25:57,670 --> 00:25:59,350
bunch of a/b tests out there but like of

665
00:25:59,350 --> 00:26:01,330
google and amazon showing that you get

666
00:26:01,330 --> 00:26:02,860
more business and more customer

667
00:26:02,860 --> 00:26:06,100
attention with a fast system in order to

668
00:26:06,100 --> 00:26:08,560
do that we need to be continuous it's

669
00:26:08,560 --> 00:26:10,540
possibly part of your standard build and

670
00:26:10,540 --> 00:26:13,600
deploy to have monitoring and profiling

671
00:26:13,600 --> 00:26:15,610
data in their stuff that will let you

672
00:26:15,610 --> 00:26:18,520
see what is causing you performance

673
00:26:18,520 --> 00:26:21,310
problems outages and bottlenecks very

674
00:26:21,310 --> 00:26:23,350
very rapidly and just in there as part

675
00:26:23,350 --> 00:26:24,940
of your normal build not something that

676
00:26:24,940 --> 00:26:26,470
you necessarily need to have a one-off

677
00:26:26,470 --> 00:26:27,520
break

678
00:26:27,520 --> 00:26:31,660
and hock measure to understand in short

679
00:26:31,660 --> 00:26:33,220
if there's one takeaway from this talk

680
00:26:33,220 --> 00:26:35,560
please do production profiling all the

681
00:26:35,560 --> 00:26:38,650
time obviously an option we are a

682
00:26:38,650 --> 00:26:41,140
continuous profiling company so you know

683
00:26:41,140 --> 00:26:43,210
our tool will help you achieve those

684
00:26:43,210 --> 00:26:45,310
kind of goals but we really want you to

685
00:26:45,310 --> 00:26:47,820
try and do this continuous profiling

686
00:26:47,820 --> 00:26:49,630
regardless of whether you use our tool

687
00:26:49,630 --> 00:26:51,850
or not it will really be something that

688
00:26:51,850 --> 00:26:53,890
helps you get a more reliable more

689
00:26:53,890 --> 00:26:55,500
performance and more enjoyable

690
00:26:55,500 --> 00:27:00,000
production environment and on that note

691
00:27:00,000 --> 00:27:03,670
we are at the end the talk it's time for

692
00:27:03,670 --> 00:27:05,770
question Simon do we have any questions

693
00:27:05,770 --> 00:27:08,230
Richard yeah I don't have any questions

694
00:27:08,230 --> 00:27:08,950
please do ask

695
00:27:08,950 --> 00:27:11,860
even though within the slack group or of

696
00:27:11,860 --> 00:27:13,330
course you have the what's it called

697
00:27:13,330 --> 00:27:16,270
slider slider in next to the next to

698
00:27:16,270 --> 00:27:19,750
this next video in live to all the talk

699
00:27:19,750 --> 00:27:21,520
talk so please do ask questions there

700
00:27:21,520 --> 00:27:23,950
Richard do you presumably you do Otzi

701
00:27:23,950 --> 00:27:27,910
yeah you do profiling the ops Ian what's

702
00:27:27,910 --> 00:27:30,250
your preferred method do you do you do

703
00:27:30,250 --> 00:27:33,070
any performance testing earlier I get

704
00:27:33,070 --> 00:27:34,930
that it's not like more a tuning kind of

705
00:27:34,930 --> 00:27:36,340
thing but you do any performance testing

706
00:27:36,340 --> 00:27:38,530
in development as well as production and

707
00:27:38,530 --> 00:27:41,590
do you prefer instrumentation sampling

708
00:27:41,590 --> 00:27:45,190
or a bit of a mix so for finding our

709
00:27:45,190 --> 00:27:47,230
production Falls problems we pretty much

710
00:27:47,230 --> 00:27:48,940
found everything through either

711
00:27:48,940 --> 00:27:50,950
profiling or looking at some metrics we

712
00:27:50,950 --> 00:27:52,840
don't run any real instrumentation based

713
00:27:52,840 --> 00:27:57,610
stuff on our own production systems we

714
00:27:57,610 --> 00:27:58,810
the other part my question is

715
00:27:58,810 --> 00:28:00,490
performance testing right we have we do

716
00:28:00,490 --> 00:28:02,680
do certain performance testing for

717
00:28:02,680 --> 00:28:04,390
certain algorithmic bits so we've got a

718
00:28:04,390 --> 00:28:06,070
back-end each storage system where we've

719
00:28:06,070 --> 00:28:08,380
done certain key performance testing

720
00:28:08,380 --> 00:28:10,240
stuff before we roll it out just to see

721
00:28:10,240 --> 00:28:12,610
if it was roughly on ballpark but we

722
00:28:12,610 --> 00:28:14,050
never assumed that that was going to be

723
00:28:14,050 --> 00:28:17,700
like the absolute perfect ahead of time

724
00:28:17,700 --> 00:28:21,160
load test and obviously over time since

725
00:28:21,160 --> 00:28:23,050
we deployed that code into production

726
00:28:23,050 --> 00:28:25,210
we've seen real profiling data back from

727
00:28:25,210 --> 00:28:27,820
it from our own profiling service and we

728
00:28:27,820 --> 00:28:29,890
found things that we would not spotted

729
00:28:29,890 --> 00:28:35,080
ahead of time trying to think of a good

730
00:28:35,080 --> 00:28:37,840
example off the top of my head so one of

731
00:28:37,840 --> 00:28:38,919
the things that we

732
00:28:38,919 --> 00:28:43,239
we spotted was that people were doing

733
00:28:43,239 --> 00:28:45,580
different patterns of querying in our

734
00:28:45,580 --> 00:28:47,529
production system that basically hid

735
00:28:47,529 --> 00:28:49,359
different parts of our systems the way

736
00:28:49,359 --> 00:28:51,429
our load test did so we had to basically

737
00:28:51,429 --> 00:28:53,529
do a little bit more optimization for

738
00:28:53,529 --> 00:28:55,119
certain parts that we didn't think we're

739
00:28:55,119 --> 00:28:56,859
going to be that hot when actually they

740
00:28:56,859 --> 00:29:01,749
were hot cool question from anonymous in

741
00:29:01,749 --> 00:29:04,989
a slide oh really requested how can I

742
00:29:04,989 --> 00:29:07,299
and this is I think this is has a lot of

743
00:29:07,299 --> 00:29:09,429
a lot of weight across a number of

744
00:29:09,429 --> 00:29:12,100
different items but specific performance

745
00:29:12,100 --> 00:29:14,019
for performance as well how can I sell

746
00:29:14,019 --> 00:29:16,840
to my boss the idea of profiling to be

747
00:29:16,840 --> 00:29:20,769
allocated both time and budget yeah

748
00:29:20,769 --> 00:29:25,509
that's a fantastic question so you know

749
00:29:25,509 --> 00:29:26,769
for customers that we've talked to who

750
00:29:26,769 --> 00:29:28,450
found real benefit from this kind of

751
00:29:28,450 --> 00:29:30,820
thing you often find if you're doing any

752
00:29:30,820 --> 00:29:33,159
kind of cloud deployment that you have

753
00:29:33,159 --> 00:29:35,049
low-hanging fruit within your system

754
00:29:35,049 --> 00:29:36,970
that can be easily optimized away they

755
00:29:36,970 --> 00:29:40,840
will often give you a cost win that is

756
00:29:40,840 --> 00:29:43,119
pretty much bigger than a continuous

757
00:29:43,119 --> 00:29:46,059
profiling service will cost so you can

758
00:29:46,059 --> 00:29:50,619
often get easy performance wins in that

759
00:29:50,619 --> 00:29:54,429
way we often find that looking at some

760
00:29:54,429 --> 00:29:56,049
of those a B test that people have used

761
00:29:56,049 --> 00:29:59,220
can be very useful so Google for example

762
00:29:59,220 --> 00:30:01,720
didn't a/b testing showed they had 20%

763
00:30:01,720 --> 00:30:05,080
traffic drop-off on their search page if

764
00:30:05,080 --> 00:30:08,529
they added half a second of low time

765
00:30:08,529 --> 00:30:11,859
latency right so slowing down search

766
00:30:11,859 --> 00:30:16,269
page results drop lost them hot 20% of

767
00:30:16,269 --> 00:30:19,019
their traffic just by half a second

768
00:30:19,019 --> 00:30:21,460
Amazon have published another a/b test

769
00:30:21,460 --> 00:30:23,230
where for example they showed they lost

770
00:30:23,230 --> 00:30:25,570
what they would lose if they generalize

771
00:30:25,570 --> 00:30:27,820
their a/b test 1 billion dollars a year

772
00:30:27,820 --> 00:30:31,210
in revenue from again just adding half a

773
00:30:31,210 --> 00:30:33,269
second to page load times across

774
00:30:33,269 --> 00:30:35,619
amazon.com so if you've got stuff that's

775
00:30:35,619 --> 00:30:38,109
very customer facing customers are often

776
00:30:38,109 --> 00:30:40,330
I don't want to say impatient but we all

777
00:30:40,330 --> 00:30:41,859
want to get stuff done right we're busy

778
00:30:41,859 --> 00:30:43,210
we don't want to be sitting there

779
00:30:43,210 --> 00:30:45,629
waiting it's a frustrating experience

780
00:30:45,629 --> 00:30:48,580
it's a it's a it's a real nightmare so

781
00:30:48,580 --> 00:30:52,949
customer retention is really important

782
00:30:53,139 --> 00:30:54,909
cost reductions very important and the

783
00:30:54,909 --> 00:30:57,039
third aspect of it is really developer

784
00:30:57,039 --> 00:30:59,380
productivity often you can fix

785
00:30:59,380 --> 00:31:01,509
performance problems but those people

786
00:31:01,509 --> 00:31:04,419
who are your colleagues can often be

787
00:31:04,419 --> 00:31:06,700
very very expensive like a lot of

788
00:31:06,700 --> 00:31:08,620
software developers so if you can use

789
00:31:08,620 --> 00:31:10,419
their time more effectively if you can

790
00:31:10,419 --> 00:31:12,759
just say hey click a button here's the

791
00:31:12,759 --> 00:31:14,860
result or not the perfect solution but

792
00:31:14,860 --> 00:31:16,929
so much of the work done for you it's

793
00:31:16,929 --> 00:31:19,210
much more useful for those people rather

794
00:31:19,210 --> 00:31:21,789
than them having to go out there and

795
00:31:21,789 --> 00:31:24,700
spend a lot of their expensive human

796
00:31:24,700 --> 00:31:27,269
capital in solving those problems

797
00:31:27,269 --> 00:31:29,769
awesome rich this is awesome there's

798
00:31:29,769 --> 00:31:31,210
also another question but I'm gonna ask

799
00:31:31,210 --> 00:31:32,919
for that to be taken in slacks because

800
00:31:32,919 --> 00:31:34,690
we are a couple of minutes over okay

801
00:31:34,690 --> 00:31:37,000
next people don't Richard a big thank

802
00:31:37,000 --> 00:31:39,700
you from everyone all the torts thank

803
00:31:39,700 --> 00:31:42,940
you very much Watson session thanks for

804
00:31:42,940 --> 00:31:44,440
organizing everything as well it's great

805
00:31:44,440 --> 00:31:48,990
now our pleasure doesn't

