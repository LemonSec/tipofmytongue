1
00:00:00,000 --> 00:00:02,720
welcome han how are you hen hi good

2
00:00:02,720 --> 00:00:04,000
morning how are you

3
00:00:04,000 --> 00:00:07,200
good night where are you from today

4
00:00:07,200 --> 00:00:09,200
i'm calling from tel aviv from israel

5
00:00:09,200 --> 00:00:11,440
tel aviv so it's it's a more reasonable

6
00:00:11,440 --> 00:00:13,200
time there but still never reasonable

7
00:00:13,200 --> 00:00:13,679
right

8
00:00:13,679 --> 00:00:16,800
it's yeah it's 7 45. yeah yeah

9
00:00:16,800 --> 00:00:20,080
and so and so work at epsilon or also a

10
00:00:20,080 --> 00:00:21,760
sponsor i believe right

11
00:00:21,760 --> 00:00:23,519
yes you're also sponsoring thank you

12
00:00:23,519 --> 00:00:24,960
very much for your support please

13
00:00:24,960 --> 00:00:26,960
everyone uh do check out everything that

14
00:00:26,960 --> 00:00:29,760
uh epsilon epsilon do with their

15
00:00:29,760 --> 00:00:31,039
observability

16
00:00:31,039 --> 00:00:33,200
around microservice environment so

17
00:00:33,200 --> 00:00:34,079
that's that's awesome

18
00:00:34,079 --> 00:00:36,160
and you're a solutions uh solutions

19
00:00:36,160 --> 00:00:37,680
engineering leader

20
00:00:37,680 --> 00:00:39,760
yes i'm running the solution engineering

21
00:00:39,760 --> 00:00:40,879
team in epsilon

22
00:00:40,879 --> 00:00:42,239
that's awesome that's awesome good to

23
00:00:42,239 --> 00:00:43,520
hear and what are you going to be

24
00:00:43,520 --> 00:00:44,960
talking about today then error handling

25
00:00:44,960 --> 00:00:46,559
in stateless environments is the

26
00:00:46,559 --> 00:00:47,760
is the title what are you going to be

27
00:00:47,760 --> 00:00:50,800
talking to us yes

28
00:00:50,800 --> 00:00:52,800
so basically i'll just go over through

29
00:00:52,800 --> 00:00:54,640
all the different types of errors that

30
00:00:54,640 --> 00:00:56,320
are possible in status environments

31
00:00:56,320 --> 00:00:57,600
specifically

32
00:00:57,600 --> 00:01:00,399
in serverless and we'll just touch a

33
00:01:00,399 --> 00:01:01,920
little bit of some of the techniques on

34
00:01:01,920 --> 00:01:04,239
how to actually

35
00:01:04,239 --> 00:01:05,680
improve the way that you're handling

36
00:01:05,680 --> 00:01:08,720
errors in those environments and also

37
00:01:08,720 --> 00:01:13,840
a little bit about distributed tracing

38
00:01:20,000 --> 00:01:23,119
thank you so much so

39
00:01:23,119 --> 00:01:26,799
thank you guys for joining me and

40
00:01:26,799 --> 00:01:28,000
i'm going to talk about something that

41
00:01:28,000 --> 00:01:29,840
is important to all of us

42
00:01:29,840 --> 00:01:31,840
uh which one of us didn't had any

43
00:01:31,840 --> 00:01:33,040
production error this week

44
00:01:33,040 --> 00:01:35,280
i'm guessing uh most of you did so we

45
00:01:35,280 --> 00:01:36,720
will just cover up

46
00:01:36,720 --> 00:01:38,479
the different types of errors in a

47
00:01:38,479 --> 00:01:40,320
stateless environment and also the

48
00:01:40,320 --> 00:01:42,079
techniques on how to

49
00:01:42,079 --> 00:01:44,159
uh how to actually overcome them but let

50
00:01:44,159 --> 00:01:46,880
me just first introduce myself

51
00:01:46,880 --> 00:01:49,040
my name is ken perez uh in the recent

52
00:01:49,040 --> 00:01:51,439
years i've been working close with

53
00:01:51,439 --> 00:01:52,799
probably the most dominant stateless

54
00:01:52,799 --> 00:01:55,439
environments today which is serverless

55
00:01:55,439 --> 00:01:58,560
and i've been running the solution

56
00:01:58,560 --> 00:02:00,799
engineer team in hebsegon

57
00:02:00,799 --> 00:02:04,560
and i'm also a fresh dad i have a

58
00:02:04,560 --> 00:02:06,960
young daughter she's 18 months years old

59
00:02:06,960 --> 00:02:08,318
her name is well

60
00:02:08,318 --> 00:02:09,840
basically the reason that i wake up in

61
00:02:09,840 --> 00:02:12,640
the morning and i'm i'm calling you from

62
00:02:12,640 --> 00:02:13,520
tel aviv

63
00:02:13,520 --> 00:02:17,520
israel so today we're going to discuss

64
00:02:17,520 --> 00:02:19,920
errors in this stateless environment

65
00:02:19,920 --> 00:02:20,840
we're going to focus

66
00:02:20,840 --> 00:02:24,160
on a retry mechanism and try to share

67
00:02:24,160 --> 00:02:24,959
how to

68
00:02:24,959 --> 00:02:27,840
implement distributed tracing the serie

69
00:02:27,840 --> 00:02:29,040
tracing for me is

70
00:02:29,040 --> 00:02:32,879
just the key to gain full observability

71
00:02:32,879 --> 00:02:37,680
into uh distributed systems

72
00:02:37,680 --> 00:02:39,840
so just first thing first let's talk

73
00:02:39,840 --> 00:02:41,519
about errors in in the stateless

74
00:02:41,519 --> 00:02:43,200
environments everybody everybody got

75
00:02:43,200 --> 00:02:43,840
them

76
00:02:43,840 --> 00:02:47,760
uh despite of some

77
00:02:47,760 --> 00:02:49,519
stateful environments like you used to

78
00:02:49,519 --> 00:02:51,200
have status environments are much more

79
00:02:51,200 --> 00:02:52,319
related

80
00:02:52,319 --> 00:02:53,840
or errors are much more related to the

81
00:02:53,840 --> 00:02:55,280
actual environment where the code

82
00:02:55,280 --> 00:02:56,319
actually runs

83
00:02:56,319 --> 00:02:58,239
rather than just a logical error meaning

84
00:02:58,239 --> 00:03:00,560
that a stateless environment

85
00:03:00,560 --> 00:03:03,120
is not affected by the actual state it

86
00:03:03,120 --> 00:03:04,400
doesn't affect it by

87
00:03:04,400 --> 00:03:06,800
customer that is currently creating my

88
00:03:06,800 --> 00:03:08,640
services one by one but it's also it's

89
00:03:08,640 --> 00:03:10,159
just been affected by the entire

90
00:03:10,159 --> 00:03:12,640
environment as a whole the first example

91
00:03:12,640 --> 00:03:14,480
i'm going to use is a simple

92
00:03:14,480 --> 00:03:17,360
application utilizing the most common

93
00:03:17,360 --> 00:03:20,800
stateless resources out there

94
00:03:20,959 --> 00:03:24,640
this application consists of

95
00:03:24,640 --> 00:03:27,760
four different status components we have

96
00:03:27,760 --> 00:03:28,879
uh

97
00:03:28,879 --> 00:03:31,120
basically customers that are streaming

98
00:03:31,120 --> 00:03:33,120
events through api gateway which is the

99
00:03:33,120 --> 00:03:34,480
http endpoint

100
00:03:34,480 --> 00:03:37,920
into a kinesis uh and kinesis is

101
00:03:37,920 --> 00:03:39,440
probably just used to get the fast

102
00:03:39,440 --> 00:03:41,360
response back to the customers but also

103
00:03:41,360 --> 00:03:42,640
used for batching

104
00:03:42,640 --> 00:03:45,040
and this kinesis is triggering lambda

105
00:03:45,040 --> 00:03:46,159
functions

106
00:03:46,159 --> 00:03:48,799
uh in order to perform some sort of data

107
00:03:48,799 --> 00:03:50,560
enrichment and saves it all in in

108
00:03:50,560 --> 00:03:53,120
dynamodb just by looking at this

109
00:03:53,120 --> 00:03:54,239
architecture

110
00:03:54,239 --> 00:03:56,879
i'll probably give it nine or ten at the

111
00:03:56,879 --> 00:03:57,599
rate of

112
00:03:57,599 --> 00:04:00,000
of being fully stateless and fully

113
00:04:00,000 --> 00:04:00,879
serverless

114
00:04:00,879 --> 00:04:03,040
and we might think that customers cannot

115
00:04:03,040 --> 00:04:04,400
really affect each other

116
00:04:04,400 --> 00:04:06,159
because there is no state but a lot of

117
00:04:06,159 --> 00:04:07,519
customers can actually

118
00:04:07,519 --> 00:04:09,040
once they stream a lot of events at the

119
00:04:09,040 --> 00:04:10,799
same time another thing can actually go

120
00:04:10,799 --> 00:04:13,200
wrong in all of those components

121
00:04:13,200 --> 00:04:15,040
i'll just try to touch one of the most

122
00:04:15,040 --> 00:04:16,959
main ones

123
00:04:16,959 --> 00:04:19,358
so akinesis can be overloaded if we

124
00:04:19,358 --> 00:04:21,120
don't have enough charts

125
00:04:21,120 --> 00:04:24,240
and um the the

126
00:04:24,240 --> 00:04:26,160
the main way of actually solving that is

127
00:04:26,160 --> 00:04:28,479
to manually adjust the number of shards

128
00:04:28,479 --> 00:04:30,960
which is not that trivial if you guys

129
00:04:30,960 --> 00:04:32,479
already experienced that because you can

130
00:04:32,479 --> 00:04:32,960
only

131
00:04:32,960 --> 00:04:35,759
uh adjust charge a certain amount of

132
00:04:35,759 --> 00:04:36,400
time

133
00:04:36,400 --> 00:04:38,560
in a day so you need to be very uh

134
00:04:38,560 --> 00:04:40,080
calculated about that

135
00:04:40,080 --> 00:04:43,120
but a much more broad solution with that

136
00:04:43,120 --> 00:04:44,639
will be to spread

137
00:04:44,639 --> 00:04:47,360
the partition keys range rather than

138
00:04:47,360 --> 00:04:48,400
just drawing out

139
00:04:48,400 --> 00:04:50,800
charts and i think the best way will be

140
00:04:50,800 --> 00:04:52,720
to just implement

141
00:04:52,720 --> 00:04:55,440
automatic shard scaling which hopefully

142
00:04:55,440 --> 00:04:55,759
uh

143
00:04:55,759 --> 00:04:57,600
one day lubs will just have that built

144
00:04:57,600 --> 00:04:59,360
in and you don't have to build it on

145
00:04:59,360 --> 00:05:00,240
yourself

146
00:05:00,240 --> 00:05:01,840
and even a lot of the function is not

147
00:05:01,840 --> 00:05:03,440
prone to errors so a lot of the function

148
00:05:03,440 --> 00:05:04,720
can suffer from

149
00:05:04,720 --> 00:05:06,720
exceptions and out of memory and also

150
00:05:06,720 --> 00:05:07,759
timeouts

151
00:05:07,759 --> 00:05:09,919
and unfortunately i can't give you any

152
00:05:09,919 --> 00:05:11,680
tip to actually stop exceptions rather

153
00:05:11,680 --> 00:05:13,759
than just write better code but

154
00:05:13,759 --> 00:05:15,600
you can also manually adjust the

155
00:05:15,600 --> 00:05:17,600
duration to reduce the timeouts and also

156
00:05:17,600 --> 00:05:18,720
adjust the memory

157
00:05:18,720 --> 00:05:21,360
in order to have less out of memories

158
00:05:21,360 --> 00:05:22,560
and even just

159
00:05:22,560 --> 00:05:25,600
catch your known exceptions and and and

160
00:05:25,600 --> 00:05:27,360
and and not actually break when

161
00:05:27,360 --> 00:05:28,800
something happen and the same goes

162
00:05:28,800 --> 00:05:32,800
for dynamodb as for uh dynamodb

163
00:05:32,800 --> 00:05:35,280
the most common uh errors are revolving

164
00:05:35,280 --> 00:05:36,800
the traffic handling

165
00:05:36,800 --> 00:05:38,639
meaning that it can reach its read or

166
00:05:38,639 --> 00:05:40,160
write capacity limits

167
00:05:40,160 --> 00:05:42,720
luckily edwards already offers auto

168
00:05:42,720 --> 00:05:43,919
scaling so we don't have

169
00:05:43,919 --> 00:05:46,800
don't need to deal uh this scaling down

170
00:05:46,800 --> 00:05:48,479
or upscaling

171
00:05:48,479 --> 00:05:49,919
but just taking consideration that

172
00:05:49,919 --> 00:05:51,919
without any hard limit this can get very

173
00:05:51,919 --> 00:05:53,520
pricey

174
00:05:53,520 --> 00:05:56,880
so uh just this is just the tip of the

175
00:05:56,880 --> 00:05:58,720
iceberg when it comes to possible errors

176
00:05:58,720 --> 00:06:00,880
and uh in a stateless environment and

177
00:06:00,880 --> 00:06:02,720
the list just goes on

178
00:06:02,720 --> 00:06:04,840
and there's just other services also to

179
00:06:04,840 --> 00:06:06,479
consider

180
00:06:06,479 --> 00:06:09,680
so uh elasticsearch or

181
00:06:09,680 --> 00:06:12,639
athena or firehose or rds for example

182
00:06:12,639 --> 00:06:14,400
all have their own limitations

183
00:06:14,400 --> 00:06:16,160
and configurations that actually affect

184
00:06:16,160 --> 00:06:17,840
the services behavior

185
00:06:17,840 --> 00:06:20,720
you need to have code that is prone and

186
00:06:20,720 --> 00:06:22,800
aware of all the possible errors

187
00:06:22,800 --> 00:06:25,360
but not even errors you even you just

188
00:06:25,360 --> 00:06:27,199
want to identify issues before they

189
00:06:27,199 --> 00:06:28,560
actually happen

190
00:06:28,560 --> 00:06:31,600
and there's a lot to do when you reach a

191
00:06:31,600 --> 00:06:33,759
connection limit in your database

192
00:06:33,759 --> 00:06:35,520
there's not a lot to do when you reach a

193
00:06:35,520 --> 00:06:37,199
connection in your in your limit in your

194
00:06:37,199 --> 00:06:38,080
database but

195
00:06:38,080 --> 00:06:40,560
it will be extremely useful to identify

196
00:06:40,560 --> 00:06:41,680
a slowdown

197
00:06:41,680 --> 00:06:44,400
in your application so this will

198
00:06:44,400 --> 00:06:45,440
eventually

199
00:06:45,440 --> 00:06:47,199
lead you to actually finding the root

200
00:06:47,199 --> 00:06:48,800
the root cause of the problem

201
00:06:48,800 --> 00:06:51,039
so basically this just lead me to a

202
00:06:51,039 --> 00:06:52,000
technique called

203
00:06:52,000 --> 00:06:55,599
middlewares and

204
00:06:55,599 --> 00:06:58,880
middlewares is basically uh

205
00:06:58,880 --> 00:07:02,160
using midwest it's pretty useful uh

206
00:07:02,160 --> 00:07:05,039
to try to identify and handle errors in

207
00:07:05,039 --> 00:07:06,560
a stateless environment

208
00:07:06,560 --> 00:07:10,080
and the middleware just acts as a layer

209
00:07:10,080 --> 00:07:13,199
before and after the request that is

210
00:07:13,199 --> 00:07:14,720
being handled by the service and it can

211
00:07:14,720 --> 00:07:17,120
be used for virus of operation like

212
00:07:17,120 --> 00:07:20,720
capturing and enriching exceptions data

213
00:07:20,720 --> 00:07:22,560
and also measuring the total duration

214
00:07:22,560 --> 00:07:24,000
and much more

215
00:07:24,000 --> 00:07:27,280
one of my favorite open source library

216
00:07:27,280 --> 00:07:28,720
that actually allows

217
00:07:28,720 --> 00:07:32,400
is a middleware implementation is midi

218
00:07:32,400 --> 00:07:34,800
and uh this is just an example of how to

219
00:07:34,800 --> 00:07:35,680
use midi

220
00:07:35,680 --> 00:07:38,000
uh with edibles lambda and it's also

221
00:07:38,000 --> 00:07:39,280
written in node.js so

222
00:07:39,280 --> 00:07:40,880
midijs is probably the most famous

223
00:07:40,880 --> 00:07:42,880
middleware library in javascript

224
00:07:42,880 --> 00:07:45,919
it's for me what it wins is that what

225
00:07:45,919 --> 00:07:46,479
wins

226
00:07:46,479 --> 00:07:48,319
for me in that library is that the ease

227
00:07:48,319 --> 00:07:50,160
of use so

228
00:07:50,160 --> 00:07:52,400
it's pretty easy to implement

229
00:07:52,400 --> 00:07:54,280
middlewares and also add

230
00:07:54,280 --> 00:07:57,520
a couple of middlewares on top of one

231
00:07:57,520 --> 00:07:58,479
another without

232
00:07:58,479 --> 00:08:00,000
actually having to change your code a

233
00:08:00,000 --> 00:08:02,080
lot in this example we have a process

234
00:08:02,080 --> 00:08:04,479
payment

235
00:08:04,479 --> 00:08:07,199
that is actually just our handle

236
00:08:07,199 --> 00:08:08,960
function and we use midi to add layers

237
00:08:08,960 --> 00:08:09,680
of logic

238
00:08:09,680 --> 00:08:12,000
so the first logic is every time there

239
00:08:12,000 --> 00:08:14,000
is a request from the

240
00:08:14,000 --> 00:08:15,680
from the customer side we can take that

241
00:08:15,680 --> 00:08:18,000
request and add for example an event

242
00:08:18,000 --> 00:08:19,759
logger that will log the event data

243
00:08:19,759 --> 00:08:22,080
or use the timer to tell us how much

244
00:08:22,080 --> 00:08:24,160
time this request actually took

245
00:08:24,160 --> 00:08:26,560
and just by taking this information we

246
00:08:26,560 --> 00:08:27,840
can later on

247
00:08:27,840 --> 00:08:29,759
either we parse it from the logs or pass

248
00:08:29,759 --> 00:08:31,840
it from uh using a dc retracing agent

249
00:08:31,840 --> 00:08:32,559
which i'll

250
00:08:32,559 --> 00:08:35,279
reach out uh uh across the end of the

251
00:08:35,279 --> 00:08:36,399
lecture

252
00:08:36,399 --> 00:08:38,399
you can take all this information to

253
00:08:38,399 --> 00:08:40,880
gain some more logical

254
00:08:40,880 --> 00:08:42,958
data about what's actually going on in

255
00:08:42,958 --> 00:08:44,480
this distributed system

256
00:08:44,480 --> 00:08:47,920
and sometimes our application can just

257
00:08:47,920 --> 00:08:49,279
get malformed data

258
00:08:49,279 --> 00:08:51,279
and we don't want to just recover from

259
00:08:51,279 --> 00:08:53,279
that case but we want also to keep

260
00:08:53,279 --> 00:08:55,680
those mild formed events for later in

261
00:08:55,680 --> 00:08:56,880
the investigation

262
00:08:56,880 --> 00:09:00,320
and and in that case we have uh what is

263
00:09:00,320 --> 00:09:02,800
called a dead letter q

264
00:09:02,800 --> 00:09:06,640
and at that letter q or dlq is basically

265
00:09:06,640 --> 00:09:09,279
as it sounds it's just a queue

266
00:09:09,279 --> 00:09:11,920
and this queue just uses used to store

267
00:09:11,920 --> 00:09:13,920
all the bad and all the well-formed

268
00:09:13,920 --> 00:09:17,279
uh requests of our services that they

269
00:09:17,279 --> 00:09:18,480
may receive

270
00:09:18,480 --> 00:09:20,480
and just to have for us to to later use

271
00:09:20,480 --> 00:09:21,680
that

272
00:09:21,680 --> 00:09:23,680
some stateless services perform a retry

273
00:09:23,680 --> 00:09:25,360
mechanism when the compute parts

274
00:09:25,360 --> 00:09:27,600
was an exception we'll deep dive to that

275
00:09:27,600 --> 00:09:28,399
retries

276
00:09:28,399 --> 00:09:30,560
in a few slides but what's important to

277
00:09:30,560 --> 00:09:32,480
understand is that a recharge mechanism

278
00:09:32,480 --> 00:09:34,000
does not differentiate between a

279
00:09:34,000 --> 00:09:36,080
malformed input or a temporary

280
00:09:36,080 --> 00:09:38,560
error and this just can cause serious

281
00:09:38,560 --> 00:09:39,279
bottlenecks

282
00:09:39,279 --> 00:09:41,279
if our system doesn't have any dead

283
00:09:41,279 --> 00:09:43,200
letter q implemented right

284
00:09:43,200 --> 00:09:45,360
uh also a few stateless environments

285
00:09:45,360 --> 00:09:48,000
already have a built-in dlq capability

286
00:09:48,000 --> 00:09:50,560
and i'll just uh we can just check them

287
00:09:50,560 --> 00:09:51,040
uh

288
00:09:51,040 --> 00:09:53,680
in the next slide so amazon has

289
00:09:53,680 --> 00:09:55,279
announced the simple notification

290
00:09:55,279 --> 00:09:57,360
service as a built-in

291
00:09:57,360 --> 00:10:01,040
uh dlq where i'll under function uh

292
00:10:01,040 --> 00:10:02,959
every time it gets invoked it might fail

293
00:10:02,959 --> 00:10:05,120
so every time it fails a certain

294
00:10:05,120 --> 00:10:07,680
amount of time it can be sort of like

295
00:10:07,680 --> 00:10:08,959
circuit break into

296
00:10:08,959 --> 00:10:12,160
a dlq and think about it that

297
00:10:12,160 --> 00:10:14,480
all the notification that are being sent

298
00:10:14,480 --> 00:10:16,640
to that lambda function if it failed

299
00:10:16,640 --> 00:10:19,040
uh if it recurrently fail and doesn't

300
00:10:19,040 --> 00:10:21,040
succeed even after a few retries we can

301
00:10:21,040 --> 00:10:21,839
just

302
00:10:21,839 --> 00:10:23,920
uh take those events and put them in a

303
00:10:23,920 --> 00:10:26,320
dlq we can store them into s3

304
00:10:26,320 --> 00:10:28,160
and just have our engineers to

305
00:10:28,160 --> 00:10:30,480
investigate that queue on a later time

306
00:10:30,480 --> 00:10:32,399
uh this can help us be build a much more

307
00:10:32,399 --> 00:10:34,160
resilient service that will not go out

308
00:10:34,160 --> 00:10:35,440
out of services

309
00:10:35,440 --> 00:10:38,240
um due to a single customer or performed

310
00:10:38,240 --> 00:10:38,800
input

311
00:10:38,800 --> 00:10:40,560
and if our services will not recover

312
00:10:40,560 --> 00:10:42,079
from malformed input

313
00:10:42,079 --> 00:10:43,680
one is that is not fixable if you

314
00:10:43,680 --> 00:10:45,120
perform a retail mechanism

315
00:10:45,120 --> 00:10:46,720
this service will become our

316
00:10:46,720 --> 00:10:49,440
applications bottlenecks so we can just

317
00:10:49,440 --> 00:10:51,120
use middleware to assist us in

318
00:10:51,120 --> 00:10:53,360
identifying such such issue

319
00:10:53,360 --> 00:10:56,399
uh and we can also see the true effect

320
00:10:56,399 --> 00:10:58,800
of it just by looking at some metrics

321
00:10:58,800 --> 00:11:00,320
and one of the metrics it's called

322
00:11:00,320 --> 00:11:03,680
an iterator age and an iterator rage

323
00:11:03,680 --> 00:11:06,959
is probably the best metric

324
00:11:06,959 --> 00:11:09,200
to look at when you're trying to figure

325
00:11:09,200 --> 00:11:10,480
out whether you have

326
00:11:10,480 --> 00:11:12,160
bottlenecks on your stream based

327
00:11:12,160 --> 00:11:15,120
stateless environment and

328
00:11:15,120 --> 00:11:16,560
i think it's the most used metric to

329
00:11:16,560 --> 00:11:18,240
identify bottlenecks in those stream

330
00:11:18,240 --> 00:11:19,920
based stateless environments

331
00:11:19,920 --> 00:11:22,320
and it actually just shows the age of

332
00:11:22,320 --> 00:11:23,200
the

333
00:11:23,200 --> 00:11:25,120
oldest record being processed by our

334
00:11:25,120 --> 00:11:27,440
service meaning that a large iterator

335
00:11:27,440 --> 00:11:28,240
range can be

336
00:11:28,240 --> 00:11:31,839
due to um a virus of reasons the main

337
00:11:31,839 --> 00:11:32,399
one is

338
00:11:32,399 --> 00:11:35,040
in this case of malformed input that's

339
00:11:35,040 --> 00:11:37,120
causing a recurring error or just a slow

340
00:11:37,120 --> 00:11:38,720
processing time

341
00:11:38,720 --> 00:11:41,680
where we uh handle high scale but our

342
00:11:41,680 --> 00:11:43,760
compute service is slow and can handle

343
00:11:43,760 --> 00:11:44,480
the load

344
00:11:44,480 --> 00:11:46,800
basically the case where our input rate

345
00:11:46,800 --> 00:11:49,760
is much larger than our output rate

346
00:11:49,760 --> 00:11:51,519
there are some ways to actually improve

347
00:11:51,519 --> 00:11:52,800
the slope processing

348
00:11:52,800 --> 00:11:56,240
uh specifically in lambda function and

349
00:11:56,240 --> 00:11:58,399
the first way is just by simple

350
00:11:58,399 --> 00:12:00,000
configuration change

351
00:12:00,000 --> 00:12:02,959
and uh i'll show that uh right in the

352
00:12:02,959 --> 00:12:04,560
next slide but

353
00:12:04,560 --> 00:12:05,920
what's also important to understand

354
00:12:05,920 --> 00:12:07,600
about iterator age is that

355
00:12:07,600 --> 00:12:11,600
um the the longer it is the more that

356
00:12:11,600 --> 00:12:12,160
it's gonna

357
00:12:12,160 --> 00:12:15,120
be delays in the system so taking that

358
00:12:15,120 --> 00:12:15,440
uh

359
00:12:15,440 --> 00:12:17,519
seriously will really significantly

360
00:12:17,519 --> 00:12:18,480
improve the

361
00:12:18,480 --> 00:12:21,120
overall experience of all your uh

362
00:12:21,120 --> 00:12:22,639
customers and also

363
00:12:22,639 --> 00:12:24,880
the the actual time that actually been

364
00:12:24,880 --> 00:12:26,320
in those services

365
00:12:26,320 --> 00:12:28,720
and by improving and and doing those

366
00:12:28,720 --> 00:12:30,079
configuration changes

367
00:12:30,079 --> 00:12:31,760
in the london function you can also

368
00:12:31,760 --> 00:12:33,760
improve the the time they text the

369
00:12:33,760 --> 00:12:34,240
process

370
00:12:34,240 --> 00:12:37,760
even if you are not changing the code

371
00:12:37,760 --> 00:12:40,560
and not a lot of people actually know

372
00:12:40,560 --> 00:12:41,519
this

373
00:12:41,519 --> 00:12:43,360
but setting up the memory size of a

374
00:12:43,360 --> 00:12:44,800
lambda function

375
00:12:44,800 --> 00:12:47,040
directly affects the performance of the

376
00:12:47,040 --> 00:12:47,839
lambda

377
00:12:47,839 --> 00:12:51,120
meaning that memory affects both network

378
00:12:51,120 --> 00:12:54,320
and cputex allocated to the lambda and

379
00:12:54,320 --> 00:12:56,000
what we did is that we built a simple

380
00:12:56,000 --> 00:12:58,240
application it's running a fibonacci

381
00:12:58,240 --> 00:12:59,279
series

382
00:12:59,279 --> 00:13:02,079
and we tried to test the same code over

383
00:13:02,079 --> 00:13:05,120
and again with different configurations

384
00:13:05,120 --> 00:13:07,440
and we just that's exactly what we did

385
00:13:07,440 --> 00:13:09,519
so the charges shows an average duration

386
00:13:09,519 --> 00:13:11,040
of the application

387
00:13:11,040 --> 00:13:12,880
changes where the memory actually

388
00:13:12,880 --> 00:13:14,399
increases and

389
00:13:14,399 --> 00:13:17,200
it also has an effect on the cpu and the

390
00:13:17,200 --> 00:13:18,399
network share so

391
00:13:18,399 --> 00:13:20,560
due to that effect in the network share

392
00:13:20,560 --> 00:13:22,079
when your application and lambda calls

393
00:13:22,079 --> 00:13:23,360
and https

394
00:13:23,360 --> 00:13:25,519
because of the ssl certification and the

395
00:13:25,519 --> 00:13:26,720
ssl handshake

396
00:13:26,720 --> 00:13:28,480
we also detected that it's required to

397
00:13:28,480 --> 00:13:30,399
have at least 500

398
00:13:30,399 --> 00:13:34,079
512 megabytes in order to just get

399
00:13:34,079 --> 00:13:37,279
an improved performance and um

400
00:13:37,279 --> 00:13:39,680
other than then doing all of this

401
00:13:39,680 --> 00:13:41,120
benchmark you can see that

402
00:13:41,120 --> 00:13:43,120
the more memory you're going to use them

403
00:13:43,120 --> 00:13:44,720
the more it's going to be

404
00:13:44,720 --> 00:13:46,480
the performance is going to be improved

405
00:13:46,480 --> 00:13:48,320
and in some cases also in terms of

406
00:13:48,320 --> 00:13:50,399
pricing you can use more memory

407
00:13:50,399 --> 00:13:51,839
but because you improve the the

408
00:13:51,839 --> 00:13:53,760
performance time in on the function

409
00:13:53,760 --> 00:13:54,959
you're going to pay less

410
00:13:54,959 --> 00:13:57,920
so uh you can take we we put this

411
00:13:57,920 --> 00:13:59,199
utility tool

412
00:13:59,199 --> 00:14:02,000
benchmark that we built we also made it

413
00:14:02,000 --> 00:14:03,120
open source

414
00:14:03,120 --> 00:14:05,279
so you can just go to our repository

415
00:14:05,279 --> 00:14:06,800
hexagons repository

416
00:14:06,800 --> 00:14:08,480
and just plug your lambda function and

417
00:14:08,480 --> 00:14:10,320
it will run a benchmark and give you the

418
00:14:10,320 --> 00:14:12,160
best assumptions of the memory

419
00:14:12,160 --> 00:14:13,680
configuration

420
00:14:13,680 --> 00:14:17,360
and um so these are just

421
00:14:17,360 --> 00:14:19,839
one of the some of the ways to overcome

422
00:14:19,839 --> 00:14:20,639
errors

423
00:14:20,639 --> 00:14:23,519
the most common ones to overcome errors

424
00:14:23,519 --> 00:14:24,160
are

425
00:14:24,160 --> 00:14:26,959
actually retries and i want to just take

426
00:14:26,959 --> 00:14:27,760
you back to

427
00:14:27,760 --> 00:14:30,880
the 90s where we get

428
00:14:30,880 --> 00:14:33,760
this screen i'm pretty sure all of us

429
00:14:33,760 --> 00:14:34,160
are

430
00:14:34,160 --> 00:14:36,480
pretty much familiar with that and this

431
00:14:36,480 --> 00:14:38,240
is like back in the days

432
00:14:38,240 --> 00:14:41,360
we got that a lot and it was always

433
00:14:41,360 --> 00:14:44,880
in some important game or we're playing

434
00:14:44,880 --> 00:14:45,440
or

435
00:14:45,440 --> 00:14:46,880
some multiplayer game or maybe just

436
00:14:46,880 --> 00:14:49,199
writing some important document and

437
00:14:49,199 --> 00:14:51,279
uh something just broken in in our

438
00:14:51,279 --> 00:14:53,120
operating system and the only way to

439
00:14:53,120 --> 00:14:54,079
actually solve it was

440
00:14:54,079 --> 00:14:57,120
by simply just keeping calm and and

441
00:14:57,120 --> 00:14:58,320
trying again and actually

442
00:14:58,320 --> 00:15:00,560
resetting the computer and the same goes

443
00:15:00,560 --> 00:15:02,240
for status environments because they are

444
00:15:02,240 --> 00:15:03,199
stateless

445
00:15:03,199 --> 00:15:05,760
retrying makes sense so you can just try

446
00:15:05,760 --> 00:15:07,199
to run it again because maybe it doesn't

447
00:15:07,199 --> 00:15:08,880
have any access to the database

448
00:15:08,880 --> 00:15:11,440
but running again might be affectable

449
00:15:11,440 --> 00:15:13,120
and

450
00:15:13,120 --> 00:15:15,519
a retry mechanism is probably one of the

451
00:15:15,519 --> 00:15:17,199
most useful tool to overcome errors in

452
00:15:17,199 --> 00:15:18,880
the stateless environment and it is

453
00:15:18,880 --> 00:15:21,279
implemented by many services today

454
00:15:21,279 --> 00:15:24,839
um let's first discuss what is a retry

455
00:15:24,839 --> 00:15:26,079
mechanism

456
00:15:26,079 --> 00:15:29,120
a ritual mechanism is can either be

457
00:15:29,120 --> 00:15:32,560
synchronous or asynchronous and uh

458
00:15:32,560 --> 00:15:34,320
a synchronous retry meaning that we have

459
00:15:34,320 --> 00:15:36,000
an application that is failing

460
00:15:36,000 --> 00:15:37,519
but the responsibility of actually

461
00:15:37,519 --> 00:15:40,079
calling it again is under the caller

462
00:15:40,079 --> 00:15:42,639
so think of an hp request i'm setting to

463
00:15:42,639 --> 00:15:43,600
an endpoint

464
00:15:43,600 --> 00:15:45,839
if the endpoint will actually return 400

465
00:15:45,839 --> 00:15:47,920
to 500 i can call it again

466
00:15:47,920 --> 00:15:50,240
with the same parameters but expect

467
00:15:50,240 --> 00:15:51,199
different results so

468
00:15:51,199 --> 00:15:53,519
asynchronous retry is the case where a

469
00:15:53,519 --> 00:15:54,560
vendor or service

470
00:15:54,560 --> 00:15:56,639
has a built-in retry mechanism and it's

471
00:15:56,639 --> 00:15:58,480
not triggered by the user

472
00:15:58,480 --> 00:16:00,480
for example a stream based service that

473
00:16:00,480 --> 00:16:02,160
is failing with a partic particular

474
00:16:02,160 --> 00:16:04,000
input will get retried a few times again

475
00:16:04,000 --> 00:16:05,279
and again with same input

476
00:16:05,279 --> 00:16:07,440
and this time the mechanism controlled

477
00:16:07,440 --> 00:16:08,959
by the service itself

478
00:16:08,959 --> 00:16:11,120
uh it's also fully configurable and you

479
00:16:11,120 --> 00:16:12,720
can set the reach right configuration in

480
00:16:12,720 --> 00:16:14,399
lambda you can also drill down

481
00:16:14,399 --> 00:16:16,079
into specific configurations such as the

482
00:16:16,079 --> 00:16:18,160
minimum delay or maximum delay

483
00:16:18,160 --> 00:16:20,480
or even just decide the type of backup

484
00:16:20,480 --> 00:16:21,920
function

485
00:16:21,920 --> 00:16:24,399
whether it's linear or exponential and

486
00:16:24,399 --> 00:16:26,000
we just touch a little bit about what

487
00:16:26,000 --> 00:16:29,680
exponential is right now so exponential

488
00:16:29,680 --> 00:16:30,320
back off

489
00:16:30,320 --> 00:16:35,120
is a pretty common backup function

490
00:16:35,120 --> 00:16:36,720
every time we have an exception we like

491
00:16:36,720 --> 00:16:38,720
to retry but we if we keep a constant

492
00:16:38,720 --> 00:16:41,040
rate we might require much much and more

493
00:16:41,040 --> 00:16:42,800
which is so just using exponential

494
00:16:42,800 --> 00:16:44,880
backup mean that we gradually trying to

495
00:16:44,880 --> 00:16:46,720
find that sweet spot

496
00:16:46,720 --> 00:16:49,600
and uh the right weight and actually

497
00:16:49,600 --> 00:16:52,160
changing the time exponentially

498
00:16:52,160 --> 00:16:53,680
as it can be seen on the chart it

499
00:16:53,680 --> 00:16:55,519
reduces the average transmissions

500
00:16:55,519 --> 00:16:57,920
needed significantly but does spread

501
00:16:57,920 --> 00:16:59,440
over much more

502
00:16:59,440 --> 00:17:02,320
so sns uses that as default by the way

503
00:17:02,320 --> 00:17:03,440
and

504
00:17:03,440 --> 00:17:05,520
i think the most important thing uh when

505
00:17:05,520 --> 00:17:07,439
it comes to retro is actually being

506
00:17:07,439 --> 00:17:10,799
aware of them so in epsilon we've

507
00:17:10,799 --> 00:17:13,039
implemented a retry detection that will

508
00:17:13,039 --> 00:17:13,839
allow it

509
00:17:13,839 --> 00:17:16,400
allow allow you to see every execution

510
00:17:16,400 --> 00:17:18,000
that was part of the same retry

511
00:17:18,000 --> 00:17:20,000
attempt you can see all the attempts and

512
00:17:20,000 --> 00:17:21,359
access each one of them

513
00:17:21,359 --> 00:17:23,520
each attempt has a different effect on

514
00:17:23,520 --> 00:17:24,559
your system

515
00:17:24,559 --> 00:17:26,640
and it's super critical to be aware when

516
00:17:26,640 --> 00:17:27,760
it happens so you can have

517
00:17:27,760 --> 00:17:30,799
much more clear troubleshooting process

518
00:17:30,799 --> 00:17:32,480
but other than just troubleshooting you

519
00:17:32,480 --> 00:17:33,919
need to build your application to be

520
00:17:33,919 --> 00:17:36,400
rich or aware it needs to be important

521
00:17:36,400 --> 00:17:37,840
so

522
00:17:37,840 --> 00:17:40,880
um ident potency is

523
00:17:40,880 --> 00:17:43,120
basically the practice of identifying

524
00:17:43,120 --> 00:17:44,400
repeated events

525
00:17:44,400 --> 00:17:46,320
meaning that our service is currently in

526
00:17:46,320 --> 00:17:48,000
the second or more which are

527
00:17:48,000 --> 00:17:50,320
attempt but responding accordingly

528
00:17:50,320 --> 00:17:51,200
meaning that

529
00:17:51,200 --> 00:17:53,520
either fail gracefully or making sure we

530
00:17:53,520 --> 00:17:54,880
don't damage our application

531
00:17:54,880 --> 00:17:57,280
so retry can be very destructive to our

532
00:17:57,280 --> 00:17:58,240
application

533
00:17:58,240 --> 00:18:00,320
and this is just an example of an

534
00:18:00,320 --> 00:18:02,160
application where we receive

535
00:18:02,160 --> 00:18:04,240
customer requests to do to perform a

536
00:18:04,240 --> 00:18:06,160
payment and if our service will fail

537
00:18:06,160 --> 00:18:07,679
again and again it will be reinvoked

538
00:18:07,679 --> 00:18:09,280
with the same customer data

539
00:18:09,280 --> 00:18:11,039
we are taking the risk of charging the

540
00:18:11,039 --> 00:18:12,799
customer again so

541
00:18:12,799 --> 00:18:14,640
the first thing we need to be make sure

542
00:18:14,640 --> 00:18:17,200
is that we terminate the code gracefully

543
00:18:17,200 --> 00:18:19,440
so we will not have to uh charge it

544
00:18:19,440 --> 00:18:21,600
again but a much more stronger

545
00:18:21,600 --> 00:18:23,919
method will be to actually introduce a

546
00:18:23,919 --> 00:18:26,000
state to that stateless service

547
00:18:26,000 --> 00:18:28,880
just by storing session data and it just

548
00:18:28,880 --> 00:18:30,160
sounds intimidating

549
00:18:30,160 --> 00:18:31,919
intimidating at first but it's pretty

550
00:18:31,919 --> 00:18:35,360
easy specifically when using dynamodp or

551
00:18:35,360 --> 00:18:36,559
key value database

552
00:18:36,559 --> 00:18:38,559
that everything is fully managed so our

553
00:18:38,559 --> 00:18:40,320
database can store the state of our

554
00:18:40,320 --> 00:18:42,000
request so every request

555
00:18:42,000 --> 00:18:44,000
its state will be initially stored in

556
00:18:44,000 --> 00:18:45,919
that database and our server just need

557
00:18:45,919 --> 00:18:47,039
to fetch this

558
00:18:47,039 --> 00:18:49,760
that state data and update it before and

559
00:18:49,760 --> 00:18:51,200
after the execution

560
00:18:51,200 --> 00:18:53,919
meaning that after every call we we

561
00:18:53,919 --> 00:18:55,760
store the current state and yes

562
00:18:55,760 --> 00:18:58,160
that's the perfect use case for

563
00:18:58,160 --> 00:18:59,520
middleware

564
00:18:59,520 --> 00:19:02,880
and and it can become much more

565
00:19:02,880 --> 00:19:06,000
much much pretty useful to uh to

566
00:19:06,000 --> 00:19:07,760
actually use that so we can just

567
00:19:07,760 --> 00:19:11,039
create each time there's a request

568
00:19:11,039 --> 00:19:12,799
create a new record in the database and

569
00:19:12,799 --> 00:19:14,080
keep fetching that

570
00:19:14,080 --> 00:19:16,960
information so you will not have to

571
00:19:16,960 --> 00:19:18,160
worry about

572
00:19:18,160 --> 00:19:19,679
if there's going to be a retry that you

573
00:19:19,679 --> 00:19:22,840
will also do some more phone to other

574
00:19:22,840 --> 00:19:24,080
services

575
00:19:24,080 --> 00:19:26,960
and yeah so the last topic i would love

576
00:19:26,960 --> 00:19:30,000
to talk about is distributed tracing

577
00:19:30,000 --> 00:19:34,000
and stateless environments

578
00:19:34,000 --> 00:19:35,840
are very much distributed in their

579
00:19:35,840 --> 00:19:37,039
nature

580
00:19:37,039 --> 00:19:40,160
and this has changed the way we monitor

581
00:19:40,160 --> 00:19:41,919
our application there's a whole new

582
00:19:41,919 --> 00:19:43,120
challenges

583
00:19:43,120 --> 00:19:45,120
challenges team are actually facing

584
00:19:45,120 --> 00:19:46,559
today in their microservices

585
00:19:46,559 --> 00:19:47,520
environments

586
00:19:47,520 --> 00:19:50,000
and we can just check them out one by

587
00:19:50,000 --> 00:19:52,559
one now

588
00:19:52,559 --> 00:19:55,200
so the first thing is that stateless

589
00:19:55,200 --> 00:19:56,080
environments

590
00:19:56,080 --> 00:19:58,240
or modern cloud-based apps or

591
00:19:58,240 --> 00:19:59,840
microservices can be very

592
00:19:59,840 --> 00:20:02,559
problematic for engineers and devops in

593
00:20:02,559 --> 00:20:04,480
terms of observability

594
00:20:04,480 --> 00:20:07,679
and um the more things you become much

595
00:20:07,679 --> 00:20:08,960
more distributed the more it's

596
00:20:08,960 --> 00:20:11,120
become very hard to understand what's

597
00:20:11,120 --> 00:20:12,559
actually going on within

598
00:20:12,559 --> 00:20:14,480
uh so unfortunately for engineers and

599
00:20:14,480 --> 00:20:16,000
devops building

600
00:20:16,000 --> 00:20:17,600
monitoring and troubleshooting cloud

601
00:20:17,600 --> 00:20:18,799
market services it's not just

602
00:20:18,799 --> 00:20:19,520
straightforward

603
00:20:19,520 --> 00:20:21,919
saying okay we need to move to the cloud

604
00:20:21,919 --> 00:20:24,480
we can save on costs it requires

605
00:20:24,480 --> 00:20:27,919
much more work to just gain that ability

606
00:20:27,919 --> 00:20:29,919
to troubleshoot and also monitor those

607
00:20:29,919 --> 00:20:31,679
distributed systems

608
00:20:31,679 --> 00:20:33,440
and you need to know whether the

609
00:20:33,440 --> 00:20:35,039
application is working properly how to

610
00:20:35,039 --> 00:20:37,120
enable developer velocity

611
00:20:37,120 --> 00:20:39,280
uh what's currently running in

612
00:20:39,280 --> 00:20:41,120
production to rapidly build new

613
00:20:41,120 --> 00:20:43,360
cloud services and save on development

614
00:20:43,360 --> 00:20:44,240
cost

615
00:20:44,240 --> 00:20:47,919
and um and and yeah and that's basically

616
00:20:47,919 --> 00:20:49,600
what's distributed tracing

617
00:20:49,600 --> 00:20:52,000
is is coming to actually solve so let's

618
00:20:52,000 --> 00:20:54,000
a little bit uh discuss what it is and

619
00:20:54,000 --> 00:20:56,320
why is it actually critical today

620
00:20:56,320 --> 00:20:59,600
so troubleshooting production issues for

621
00:20:59,600 --> 00:21:00,799
microservices and servers

622
00:21:00,799 --> 00:21:03,919
it are requiring much more than just the

623
00:21:03,919 --> 00:21:05,679
basic logs and metrics

624
00:21:05,679 --> 00:21:08,240
which are simply not the right tools for

625
00:21:08,240 --> 00:21:10,720
these highly distributed applications

626
00:21:10,720 --> 00:21:12,559
and each component in our system can

627
00:21:12,559 --> 00:21:15,360
report back every time it runs

628
00:21:15,360 --> 00:21:17,039
with all the operation that it did so

629
00:21:17,039 --> 00:21:19,120
putting that into an engine that is able

630
00:21:19,120 --> 00:21:21,440
to curl it between different events

631
00:21:21,440 --> 00:21:24,480
will eventually allow us to view a full

632
00:21:24,480 --> 00:21:25,600
picture

633
00:21:25,600 --> 00:21:27,840
uh as like an end-to-end request like

634
00:21:27,840 --> 00:21:29,360
you see here

635
00:21:29,360 --> 00:21:31,600
or or simply just see an end to end

636
00:21:31,600 --> 00:21:33,760
trace and a trace

637
00:21:33,760 --> 00:21:36,159
meaning that it's the story of all the

638
00:21:36,159 --> 00:21:38,400
services that were invoked

639
00:21:38,400 --> 00:21:40,799
and how a single request propagated

640
00:21:40,799 --> 00:21:42,400
through that distributed system meaning

641
00:21:42,400 --> 00:21:43,520
i have a customer

642
00:21:43,520 --> 00:21:45,520
and he has sending a request that goes

643
00:21:45,520 --> 00:21:47,520
through four or five different services

644
00:21:47,520 --> 00:21:48,640
so being able to see

645
00:21:48,640 --> 00:21:50,720
all the journey and sometimes it can be

646
00:21:50,720 --> 00:21:52,240
much more complicated than that and also

647
00:21:52,240 --> 00:21:53,600
asking currencies also

648
00:21:53,600 --> 00:21:55,200
be able to capture all those together

649
00:21:55,200 --> 00:21:56,960
and then view them

650
00:21:56,960 --> 00:21:59,520
uh and see exactly what's going on

651
00:21:59,520 --> 00:22:00,480
within them

652
00:22:00,480 --> 00:22:02,240
there's a lot of open source tools to

653
00:22:02,240 --> 00:22:03,840
enable the serie tracing in your code

654
00:22:03,840 --> 00:22:06,320
there's a standard like open tracing

655
00:22:06,320 --> 00:22:09,600
and there's also uh jager which is an

656
00:22:09,600 --> 00:22:11,360
open source distributed tracing which

657
00:22:11,360 --> 00:22:13,360
also has a timeline view that you can

658
00:22:13,360 --> 00:22:16,720
visualize those traces uh but um

659
00:22:16,720 --> 00:22:18,240
how can we actually implement that

660
00:22:18,240 --> 00:22:20,000
ourselves so

661
00:22:20,000 --> 00:22:22,240
first we need to instrument every call

662
00:22:22,240 --> 00:22:23,120
in our service

663
00:22:23,120 --> 00:22:25,520
meaning that whether it's a a call to

664
00:22:25,520 --> 00:22:27,520
the s3 using the adwords sdk

665
00:22:27,520 --> 00:22:30,000
or a record being put to the database or

666
00:22:30,000 --> 00:22:31,679
any other third party api call

667
00:22:31,679 --> 00:22:34,240
for every call we create a spam a span

668
00:22:34,240 --> 00:22:34,720
should

669
00:22:34,720 --> 00:22:36,880
contain all the information needed for

670
00:22:36,880 --> 00:22:39,440
operation the host name the duration

671
00:22:39,440 --> 00:22:42,240
and much more high level metrics and a

672
00:22:42,240 --> 00:22:44,320
distributed tracing engine needs to know

673
00:22:44,320 --> 00:22:46,559
to connect between those asynchronous

674
00:22:46,559 --> 00:22:49,120
spans using correlation identifiers so

675
00:22:49,120 --> 00:22:50,559
we need to

676
00:22:50,559 --> 00:22:52,720
need to ingest and extract those

677
00:22:52,720 --> 00:22:55,200
identifiers it can be the request id

678
00:22:55,200 --> 00:22:57,200
it can be anything that is very unique

679
00:22:57,200 --> 00:22:59,520
to a specific request or response

680
00:22:59,520 --> 00:23:01,760
and as for the context we would like to

681
00:23:01,760 --> 00:23:03,360
add much more

682
00:23:03,360 --> 00:23:05,600
request specific data to assist us with

683
00:23:05,600 --> 00:23:06,960
troubleshooting such

684
00:23:06,960 --> 00:23:09,760
such as this is just an example i have

685
00:23:09,760 --> 00:23:10,480
to

686
00:23:10,480 --> 00:23:12,640
manually implement those dc retracing in

687
00:23:12,640 --> 00:23:14,080
a single request so we have our

688
00:23:14,080 --> 00:23:16,080
handle request function and before the

689
00:23:16,080 --> 00:23:17,200
request we

690
00:23:17,200 --> 00:23:19,679
put it into create a spam for it with

691
00:23:19,679 --> 00:23:21,039
all the contacts so

692
00:23:21,039 --> 00:23:23,120
the example of the context can be the

693
00:23:23,120 --> 00:23:25,440
url or the

694
00:23:25,440 --> 00:23:28,000
remote ip or the color name any data

695
00:23:28,000 --> 00:23:29,679
that will actually allow us

696
00:23:29,679 --> 00:23:31,440
later on looking at the trace and being

697
00:23:31,440 --> 00:23:34,240
able to properly

698
00:23:34,240 --> 00:23:37,440
troubleshoot it so in epsilon we

699
00:23:37,440 --> 00:23:40,640
we we we took all this idea of

700
00:23:40,640 --> 00:23:43,360
implementing automatic tracing libraries

701
00:23:43,360 --> 00:23:44,159
that

702
00:23:44,159 --> 00:23:46,960
uh require you uh almost zero code

703
00:23:46,960 --> 00:23:49,120
changes in a way that you just

704
00:23:49,120 --> 00:23:50,640
plug in the library and it will

705
00:23:50,640 --> 00:23:52,320
automatically detect all the operation

706
00:23:52,320 --> 00:23:53,200
that's going on

707
00:23:53,200 --> 00:23:55,279
just to reduce the the fact that uh a

708
00:23:55,279 --> 00:23:56,559
developer we need to

709
00:23:56,559 --> 00:23:59,039
manually annotate and add spans and and

710
00:23:59,039 --> 00:24:01,039
so this is part of our tracing library

711
00:24:01,039 --> 00:24:04,000
also our uh suffering for the

712
00:24:04,000 --> 00:24:05,760
observability solution

713
00:24:05,760 --> 00:24:07,440
specifically built for cloud

714
00:24:07,440 --> 00:24:09,360
microservices we provide

715
00:24:09,360 --> 00:24:11,360
value to those complex environments

716
00:24:11,360 --> 00:24:13,440
immediately rather than just needing to

717
00:24:13,440 --> 00:24:15,440
manually define spans or run separate

718
00:24:15,440 --> 00:24:16,080
engines

719
00:24:16,080 --> 00:24:17,600
to collect metrics for service

720
00:24:17,600 --> 00:24:20,159
components uh epsilon automatically

721
00:24:20,159 --> 00:24:21,039
traces the

722
00:24:21,039 --> 00:24:23,200
end-to-end state of your services and

723
00:24:23,200 --> 00:24:25,120
provide providing application insights

724
00:24:25,120 --> 00:24:26,000
and metrics

725
00:24:26,000 --> 00:24:28,000
with visibility into the into the

726
00:24:28,000 --> 00:24:30,000
payload um

727
00:24:30,000 --> 00:24:32,159
you can check us out later so just to

728
00:24:32,159 --> 00:24:34,080
summarize

729
00:24:34,080 --> 00:24:36,159
errors in a stateless environment can

730
00:24:36,159 --> 00:24:38,080
and will happen we just need to be able

731
00:24:38,080 --> 00:24:39,200
to identify them

732
00:24:39,200 --> 00:24:41,039
and prepare for them one of the main

733
00:24:41,039 --> 00:24:42,960
technique is retries which is very

734
00:24:42,960 --> 00:24:44,799
powerful method

735
00:24:44,799 --> 00:24:46,720
of just overcoming errors but also

736
00:24:46,720 --> 00:24:48,400
requires to implement it right

737
00:24:48,400 --> 00:24:50,400
and lastly distributed tracing is the

738
00:24:50,400 --> 00:24:52,400
key to gaining full observability

739
00:24:52,400 --> 00:24:54,720
into distributed systems and it's um

740
00:24:54,720 --> 00:24:56,240
it's a crucial component

741
00:24:56,240 --> 00:24:58,640
in status environments uh so thank you

742
00:24:58,640 --> 00:25:00,559
guys i'll also like to share that

743
00:25:00,559 --> 00:25:03,679
uh you can just go to epsilon.com all

744
00:25:03,679 --> 00:25:04,559
the talks

745
00:25:04,559 --> 00:25:08,000
and get a free uh swag and it's our cool

746
00:25:08,000 --> 00:25:09,200
nice t-shirt

747
00:25:09,200 --> 00:25:12,000
um so thank you guys thank you guys so

748
00:25:12,000 --> 00:25:12,640
much

749
00:25:12,640 --> 00:25:14,400
you're awesome thank you very very much

750
00:25:14,400 --> 00:25:16,480
and uh so a couple of questions coming

751
00:25:16,480 --> 00:25:16,720
in

752
00:25:16,720 --> 00:25:19,679
uh one which i will ask directly the

753
00:25:19,679 --> 00:25:21,279
other one i'm going to put in our next

754
00:25:21,279 --> 00:25:22,720
speaker so he can ask

755
00:25:22,720 --> 00:25:26,000
he can ask live on the stream um

756
00:25:26,000 --> 00:25:29,200
so we have mhmxs

757
00:25:29,200 --> 00:25:32,400
uh asking uh regarding about destroying

758
00:25:32,400 --> 00:25:33,039
state

759
00:25:33,039 --> 00:25:34,480
how do you deal with storing state and

760
00:25:34,480 --> 00:25:36,159
business logic that are happening as two

761
00:25:36,159 --> 00:25:37,200
separated

762
00:25:37,200 --> 00:25:39,039
flows two separated steps and the fact

763
00:25:39,039 --> 00:25:41,120
that errors can exist between those two

764
00:25:41,120 --> 00:25:42,960
steps

765
00:25:42,960 --> 00:25:45,679
so i think it's not it's not that easy

766
00:25:45,679 --> 00:25:47,600
task of containing the state you will

767
00:25:47,600 --> 00:25:49,440
need to have some sort

768
00:25:49,440 --> 00:25:52,720
uh that database need to contain uh

769
00:25:52,720 --> 00:25:54,960
access from both services and they both

770
00:25:54,960 --> 00:25:56,159
can have joint

771
00:25:56,159 --> 00:25:58,320
joint states you just need to make sure

772
00:25:58,320 --> 00:25:59,520
that uh

773
00:25:59,520 --> 00:26:01,679
you will handle those atomic operations

774
00:26:01,679 --> 00:26:03,360
so you will not be able to

775
00:26:03,360 --> 00:26:06,480
overrun them but once it comes to

776
00:26:06,480 --> 00:26:08,159
to adding more services that need to

777
00:26:08,159 --> 00:26:10,000
have a shared state meaning that you

778
00:26:10,000 --> 00:26:11,600
might need to to contain them in a

779
00:26:11,600 --> 00:26:12,880
single service or

780
00:26:12,880 --> 00:26:15,200
uh try to figure out a different way to

781
00:26:15,200 --> 00:26:17,520
communicate with one of them

782
00:26:17,520 --> 00:26:20,000
awesome let me pull in romero welcome

783
00:26:20,000 --> 00:26:21,360
romero to uh

784
00:26:21,360 --> 00:26:24,159
to all the talk how are you hi i'm good

785
00:26:24,159 --> 00:26:24,720
how are you

786
00:26:24,720 --> 00:26:27,919
simon hi thanks for watching

787
00:26:27,919 --> 00:26:29,760
i have a question so i'm going to ask it

788
00:26:29,760 --> 00:26:31,120
live which is

789
00:26:31,120 --> 00:26:32,720
something we've been hitting a lot of

790
00:26:32,720 --> 00:26:35,200
lately is we're in the process of

791
00:26:35,200 --> 00:26:36,720
implementing open tracing

792
00:26:36,720 --> 00:26:38,400
and some of the services we're calling

793
00:26:38,400 --> 00:26:40,400
in our in our chain of services

794
00:26:40,400 --> 00:26:42,559
legacy stuff that does not support open

795
00:26:42,559 --> 00:26:44,880
tracing or open telemetry

796
00:26:44,880 --> 00:26:46,720
what should we do in those cases like i

797
00:26:46,720 --> 00:26:49,760
have an api calling login that works

798
00:26:49,760 --> 00:26:52,080
then for instance they call kubernetes

799
00:26:52,080 --> 00:26:53,840
has no support for this and then we call

800
00:26:53,840 --> 00:26:54,480
some other

801
00:26:54,480 --> 00:26:57,039
apis downstream what what are you doing

802
00:26:57,039 --> 00:26:58,159
yeah

803
00:26:58,159 --> 00:27:01,360
so i'm uh i think the the

804
00:27:01,360 --> 00:27:03,120
differentiator between what is supported

805
00:27:03,120 --> 00:27:04,559
and not supported in open tracing is

806
00:27:04,559 --> 00:27:06,400
rather the environment it's more the

807
00:27:06,400 --> 00:27:08,799
actual programming language because you

808
00:27:08,799 --> 00:27:09,840
can manually

809
00:27:09,840 --> 00:27:12,240
i think it uh unless it's like c plus

810
00:27:12,240 --> 00:27:13,120
plus or

811
00:27:13,120 --> 00:27:14,960
anything i think maybe for c plus plus

812
00:27:14,960 --> 00:27:16,880
they also have a support for that

813
00:27:16,880 --> 00:27:19,360
so you just need to figure out a away

814
00:27:19,360 --> 00:27:21,520
and open tracing is just basically the

815
00:27:21,520 --> 00:27:22,399
standard

816
00:27:22,399 --> 00:27:26,159
you can manually uh create those spans

817
00:27:26,159 --> 00:27:27,600
within your code

818
00:27:27,600 --> 00:27:29,840
and uh if you if you if you decide to do

819
00:27:29,840 --> 00:27:31,120
the manual way

820
00:27:31,120 --> 00:27:33,840
and uh you basically need to transmit

821
00:27:33,840 --> 00:27:34,559
that to

822
00:27:34,559 --> 00:27:37,679
the open uh some some tracing engine as

823
00:27:37,679 --> 00:27:38,159
well

824
00:27:38,159 --> 00:27:40,640
so uh i would love just to even hit that

825
00:27:40,640 --> 00:27:41,919
offline with you to see

826
00:27:41,919 --> 00:27:45,520
how we can uh assist with that yeah sure

827
00:27:45,520 --> 00:27:48,880
thanks awesome and i'll i'll give

828
00:27:48,880 --> 00:27:50,799
ramira a full introduction in just a

829
00:27:50,799 --> 00:27:53,200
second but while we while we continue

830
00:27:53,200 --> 00:27:56,799
uh on the questions uh one more question

831
00:27:56,799 --> 00:27:58,799
coming in from uh from slido

832
00:27:58,799 --> 00:28:00,399
from joe is their support for traces

833
00:28:00,399 --> 00:28:02,320
over hybrid architecture so for example

834
00:28:02,320 --> 00:28:04,080
from going from a container to a surface

835
00:28:04,080 --> 00:28:05,840
architecture

836
00:28:05,840 --> 00:28:08,320
yes definitely so uh when it comes to

837
00:28:08,320 --> 00:28:09,840
hexagon our tracing

838
00:28:09,840 --> 00:28:11,679
our automated tracing library is

839
00:28:11,679 --> 00:28:13,679
agnostic to where the code runs

840
00:28:13,679 --> 00:28:15,679
so it can run on containers or

841
00:28:15,679 --> 00:28:17,679
kubernetes on serverless and now that's

842
00:28:17,679 --> 00:28:18,080
who

843
00:28:18,080 --> 00:28:20,480
you can you can also see requests going

844
00:28:20,480 --> 00:28:21,440
from

845
00:28:21,440 --> 00:28:23,520
invoking along the function that puts in

846
00:28:23,520 --> 00:28:25,600
a message on s3 invoking a lot of

847
00:28:25,600 --> 00:28:27,679
non-functioning to calling an endpoint

848
00:28:27,679 --> 00:28:29,520
on the kubernetes itself so you can see

849
00:28:29,520 --> 00:28:30,399
all the

850
00:28:30,399 --> 00:28:33,760
end-to-end trace even in hybrid systems

851
00:28:33,760 --> 00:28:35,440
and and using something like epsilon

852
00:28:35,440 --> 00:28:37,120
would you say there's uh would you say

853
00:28:37,120 --> 00:28:39,360
it's like a always-on kind of solution

854
00:28:39,360 --> 00:28:40,720
or would you say it's like

855
00:28:40,720 --> 00:28:43,120
as and when you feel like you need to do

856
00:28:43,120 --> 00:28:44,159
more investigation

857
00:28:44,159 --> 00:28:46,720
you turn uh

858
00:28:47,520 --> 00:28:51,520
yeah so we have our own

859
00:28:51,520 --> 00:28:54,640
monitoring system that uh you can decide

860
00:28:54,640 --> 00:28:56,320
when you want to actually plug it in

861
00:28:56,320 --> 00:28:58,240
or plug it up but it also brings in

862
00:28:58,240 --> 00:29:00,559
overall infrastructure monitoring so

863
00:29:00,559 --> 00:29:01,440
it's always

864
00:29:01,440 --> 00:29:03,279
on in a way but it's uh it's fully

865
00:29:03,279 --> 00:29:04,480
agentless so you just

866
00:29:04,480 --> 00:29:08,480
collect metrics uh remotely awesome

867
00:29:08,480 --> 00:29:11,520
uh and we're at time now so i will say a

868
00:29:11,520 --> 00:29:12,960
massive thank you very much for the

869
00:29:12,960 --> 00:29:14,559
session thank you very much

870
00:29:14,559 --> 00:29:16,640
thank you so much ed i had fun i've

871
00:29:16,640 --> 00:29:18,320
actually got support as well for the

872
00:29:18,320 --> 00:29:20,799
for all the talks and uh we appreciate

873
00:29:20,799 --> 00:29:21,679
your uh

874
00:29:21,679 --> 00:29:23,120
you're you're coming on so thank you

875
00:29:23,120 --> 00:29:25,679
very much and uh and enjoy the new day i

876
00:29:25,679 --> 00:29:26,240
guess

877
00:29:26,240 --> 00:29:29,520
in tel aviv ramiro is ending up his in

878
00:29:29,520 --> 00:29:31,679
the in in san francisco so

879
00:29:31,679 --> 00:29:33,919
have a great rest of day uh thank you

880
00:29:33,919 --> 00:29:37,840
thanks you too guys

