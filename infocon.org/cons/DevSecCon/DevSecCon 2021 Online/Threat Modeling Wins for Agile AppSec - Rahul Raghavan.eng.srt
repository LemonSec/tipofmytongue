1
00:00:07,530 --> 00:00:10,730
[Music]

2
00:00:12,240 --> 00:00:13,040
hello

3
00:00:13,040 --> 00:00:15,280
welcome everybody to devsecond24 other

4
00:00:15,280 --> 00:00:16,880
talk uh my name is rahul

5
00:00:16,880 --> 00:00:19,439
i'm the co-founder here at v45 and today

6
00:00:19,439 --> 00:00:20,960
i'm excited to be talking about threat

7
00:00:20,960 --> 00:00:22,160
modeling wins

8
00:00:22,160 --> 00:00:25,439
for agile apsec like many others uh

9
00:00:25,439 --> 00:00:27,279
it's my first time at devsecond and i'm

10
00:00:27,279 --> 00:00:29,039
quite excited to be here

11
00:00:29,039 --> 00:00:30,560
speaking with a plethora of other

12
00:00:30,560 --> 00:00:32,159
speakers so an exciting day for me and

13
00:00:32,159 --> 00:00:33,040
hopefully

14
00:00:33,040 --> 00:00:35,200
um all of you guys and girls have a lot

15
00:00:35,200 --> 00:00:37,040
of fun in this talk as well

16
00:00:37,040 --> 00:00:38,719
before we get started with the actual

17
00:00:38,719 --> 00:00:40,960
talk a little bit about myself

18
00:00:40,960 --> 00:00:43,200
my name is rahul like i said i'm one of

19
00:00:43,200 --> 00:00:45,120
the co-founders here at v45 we're

20
00:00:45,120 --> 00:00:46,399
essentially a company

21
00:00:46,399 --> 00:00:49,039
kind of helping a lot of com product

22
00:00:49,039 --> 00:00:50,559
development teams kind of help

23
00:00:50,559 --> 00:00:53,680
helping them measure scale and implement

24
00:00:53,680 --> 00:00:55,840
a lot of application security processes

25
00:00:55,840 --> 00:00:57,680
personally what keeps me up at night

26
00:00:57,680 --> 00:00:59,120
things that you see here on screen

27
00:00:59,120 --> 00:01:01,440
right largely working with clients on

28
00:01:01,440 --> 00:01:03,520
application security automation models

29
00:01:03,520 --> 00:01:06,159
uh trying to make them more familiar and

30
00:01:06,159 --> 00:01:07,920
help them realize their

31
00:01:07,920 --> 00:01:10,560
devsecops value proposition threat

32
00:01:10,560 --> 00:01:11,760
modeling which is one of the things that

33
00:01:11,760 --> 00:01:13,040
we're going to talk about today are the

34
00:01:13,040 --> 00:01:14,000
main thing that we're going to talk

35
00:01:14,000 --> 00:01:14,880
about today

36
00:01:14,880 --> 00:01:16,320
uh that's something that i've been

37
00:01:16,320 --> 00:01:18,240
getting my hands dirty quite

38
00:01:18,240 --> 00:01:21,119
a lot in the last few years um and then

39
00:01:21,119 --> 00:01:21,759
finally

40
00:01:21,759 --> 00:01:24,400
um a lot of movies uh and a lot of

41
00:01:24,400 --> 00:01:25,680
popcorn so that's something

42
00:01:25,680 --> 00:01:27,360
that i'm really kind of looking forward

43
00:01:27,360 --> 00:01:29,200
to every weekend especially ever since

44
00:01:29,200 --> 00:01:30,159
we started

45
00:01:30,159 --> 00:01:32,880
living practically at my basement ever

46
00:01:32,880 --> 00:01:33,439
since the

47
00:01:33,439 --> 00:01:36,560
pandemic started to hit okay with that

48
00:01:36,560 --> 00:01:39,119
let's get started so over the next 45

49
00:01:39,119 --> 00:01:40,159
minutes or so

50
00:01:40,159 --> 00:01:42,159
uh we are largely going to be looking at

51
00:01:42,159 --> 00:01:44,000
this phenomenon

52
00:01:44,000 --> 00:01:45,119
and i'll tell you why i call this a

53
00:01:45,119 --> 00:01:46,799
phenomenon called threat modeling

54
00:01:46,799 --> 00:01:48,320
because we're going to kind of look at

55
00:01:48,320 --> 00:01:50,799
what threat modeling really means more

56
00:01:50,799 --> 00:01:52,320
more as a noun

57
00:01:52,320 --> 00:01:54,320
and as a verb and i have a reason for

58
00:01:54,320 --> 00:01:56,320
that because you've probably heard this

59
00:01:56,320 --> 00:01:57,360
a lot you've probably

60
00:01:57,360 --> 00:01:59,759
seen the word threat modeling being

61
00:01:59,759 --> 00:02:00,719
thrown around

62
00:02:00,719 --> 00:02:02,240
in discussions with product engineering

63
00:02:02,240 --> 00:02:04,560
teams you've seen them uh thrown around

64
00:02:04,560 --> 00:02:06,719
as activities and tasks within

65
00:02:06,719 --> 00:02:09,679
um afghan security programs but really

66
00:02:09,679 --> 00:02:12,319
what we're going to look at is

67
00:02:12,319 --> 00:02:14,959
why do threat models fail and more

68
00:02:14,959 --> 00:02:16,160
importantly

69
00:02:16,160 --> 00:02:18,480
i'm just going to present my version or

70
00:02:18,480 --> 00:02:19,840
my option

71
00:02:19,840 --> 00:02:23,520
to what we think uh would be probably a

72
00:02:23,520 --> 00:02:25,280
decent way to kind of scale this

73
00:02:25,280 --> 00:02:26,080
effective

74
00:02:26,080 --> 00:02:27,599
threat modeling piece within applicant

75
00:02:27,599 --> 00:02:29,760
security automation pieces um and one of

76
00:02:29,760 --> 00:02:30,400
the things that

77
00:02:30,400 --> 00:02:32,959
all bays like to say is if application

78
00:02:32,959 --> 00:02:34,959
security was a website

79
00:02:34,959 --> 00:02:36,879
threat modeling is that page with the

80
00:02:36,879 --> 00:02:38,160
highest bounce rate

81
00:02:38,160 --> 00:02:39,519
because those are the things that people

82
00:02:39,519 --> 00:02:41,200
are always talking about they're really

83
00:02:41,200 --> 00:02:42,800
kind of interested about it but

84
00:02:42,800 --> 00:02:45,440
nobody is really doing it right um so

85
00:02:45,440 --> 00:02:46,720
what we're hoping to achieve at the end

86
00:02:46,720 --> 00:02:47,760
of this 45 minutes

87
00:02:47,760 --> 00:02:49,519
is for us to kind of really understand

88
00:02:49,519 --> 00:02:51,519
some of those building blocks of threat

89
00:02:51,519 --> 00:02:52,239
models

90
00:02:52,239 --> 00:02:53,920
uh application threat models to be more

91
00:02:53,920 --> 00:02:56,000
specific and kind of look at the schools

92
00:02:56,000 --> 00:02:57,760
of thought that would really make sense

93
00:02:57,760 --> 00:02:59,440
for product engineering teams to kind of

94
00:02:59,440 --> 00:03:00,879
implemented scale threat models from

95
00:03:00,879 --> 00:03:02,959
that perspective we're also going to be

96
00:03:02,959 --> 00:03:04,560
looking at threat playbook which is

97
00:03:04,560 --> 00:03:06,959
uh an open source framework that we at

98
00:03:06,959 --> 00:03:08,400
b45 kind of developed

99
00:03:08,400 --> 00:03:10,480
around three and a half years ago um and

100
00:03:10,480 --> 00:03:12,159
we're also kind of looking at how threat

101
00:03:12,159 --> 00:03:13,840
playbook can be one of the means to

102
00:03:13,840 --> 00:03:14,720
implement

103
00:03:14,720 --> 00:03:17,440
um applicant security at scale using

104
00:03:17,440 --> 00:03:18,800
threat modeling

105
00:03:18,800 --> 00:03:20,480
and finally we're also going to be kind

106
00:03:20,480 --> 00:03:23,200
of looking at how the security testing

107
00:03:23,200 --> 00:03:25,200
uh framework would kind of seamlessly

108
00:03:25,200 --> 00:03:26,959
integrate with threat model because

109
00:03:26,959 --> 00:03:28,159
everybody's talking about

110
00:03:28,159 --> 00:03:31,040
the as a code model so we had security

111
00:03:31,040 --> 00:03:32,400
as a code and today we're going to look

112
00:03:32,400 --> 00:03:33,920
at threat modeling as a code

113
00:03:33,920 --> 00:03:35,440
and how is it that we kind of integrate

114
00:03:35,440 --> 00:03:38,159
both these pieces uh into a well-oiled

115
00:03:38,159 --> 00:03:41,280
application or a machinery so

116
00:03:41,280 --> 00:03:43,680
let's start off with something that

117
00:03:43,680 --> 00:03:45,360
everybody's been talking about the whole

118
00:03:45,360 --> 00:03:47,440
state of african security today

119
00:03:47,440 --> 00:03:50,319
uh i know that we've had a lot of talks

120
00:03:50,319 --> 00:03:51,920
today we've had a lot of people talk

121
00:03:51,920 --> 00:03:52,480
about

122
00:03:52,480 --> 00:03:54,400
um uh some of these topics but i just

123
00:03:54,400 --> 00:03:55,840
want to kind of touch uh

124
00:03:55,840 --> 00:03:58,080
upon a few salient features if you will

125
00:03:58,080 --> 00:03:59,120
of what appsec

126
00:03:59,120 --> 00:04:01,920
2.0 or 3.0 really kind of looks at looks

127
00:04:01,920 --> 00:04:02,959
like today

128
00:04:02,959 --> 00:04:04,879
first of all we're seeing a huge

129
00:04:04,879 --> 00:04:06,720
increase in tooling uh and tooling

130
00:04:06,720 --> 00:04:07,439
across

131
00:04:07,439 --> 00:04:08,959
multiple units right we're not just

132
00:04:08,959 --> 00:04:10,480
talking about tooling in terms of

133
00:04:10,480 --> 00:04:12,560
automation we're actually talking about

134
00:04:12,560 --> 00:04:14,400
tooling in terms of developer

135
00:04:14,400 --> 00:04:16,880
um uh platforms you talk about tooling

136
00:04:16,880 --> 00:04:17,600
in terms of

137
00:04:17,600 --> 00:04:19,918
infrastructures code pretty much across

138
00:04:19,918 --> 00:04:20,798
the board tooling

139
00:04:20,798 --> 00:04:24,080
is something that's going on um as we

140
00:04:24,080 --> 00:04:26,080
uh look at product engine's uh teams at

141
00:04:26,080 --> 00:04:28,000
scale uh you're also looking at

142
00:04:28,000 --> 00:04:31,040
deployments uh really kind of scaling

143
00:04:31,040 --> 00:04:32,560
and with those scale deployments you're

144
00:04:32,560 --> 00:04:35,280
actually seeing security test titrations

145
00:04:35,280 --> 00:04:38,800
um increase multi-fold as well

146
00:04:38,800 --> 00:04:41,759
uh the deficit ops wave as we call it i

147
00:04:41,759 --> 00:04:43,120
don't even know if it's a wave anymore

148
00:04:43,120 --> 00:04:44,880
it's been a while since people started

149
00:04:44,880 --> 00:04:46,560
implementing it uh so the whole

150
00:04:46,560 --> 00:04:48,479
devsecops wave has kind of brought with

151
00:04:48,479 --> 00:04:50,080
it this whole feedback

152
00:04:50,080 --> 00:04:52,320
uh looping system which is kind of

153
00:04:52,320 --> 00:04:53,600
really cool because

154
00:04:53,600 --> 00:04:56,800
it's kind of increased our ability to

155
00:04:56,800 --> 00:04:58,639
understand

156
00:04:58,639 --> 00:05:00,479
security vulnerabilities that happen at

157
00:05:00,479 --> 00:05:02,560
the shift right model which essentially

158
00:05:02,560 --> 00:05:04,160
security vulnerabilities that happen at

159
00:05:04,160 --> 00:05:04,960
production

160
00:05:04,960 --> 00:05:07,199
and kind of help them really kind of

161
00:05:07,199 --> 00:05:08,880
bring that back into the forefront

162
00:05:08,880 --> 00:05:11,360
in terms of being more proactive uh in

163
00:05:11,360 --> 00:05:12,320
terms of those

164
00:05:12,320 --> 00:05:14,800
um security vectors or security

165
00:05:14,800 --> 00:05:15,680
vulnerabilities

166
00:05:15,680 --> 00:05:17,759
being able to teams being able to really

167
00:05:17,759 --> 00:05:19,280
kind of understand that before they

168
00:05:19,280 --> 00:05:20,240
actually happen

169
00:05:20,240 --> 00:05:21,360
um and one of the things that we're

170
00:05:21,360 --> 00:05:22,479
going to talk about today which is quite

171
00:05:22,479 --> 00:05:23,280
interesting is

172
00:05:23,280 --> 00:05:26,000
this as a code execution model right we

173
00:05:26,000 --> 00:05:27,199
we started off

174
00:05:27,199 --> 00:05:30,080
with a security as code when the whole

175
00:05:30,080 --> 00:05:31,360
wave started off and today we're going

176
00:05:31,360 --> 00:05:33,039
to kind of look at uh threat modeling is

177
00:05:33,039 --> 00:05:33,840
code but

178
00:05:33,840 --> 00:05:36,160
you had infrastructures code you had

179
00:05:36,160 --> 00:05:38,400
compliances code and today we're going

180
00:05:38,400 --> 00:05:40,400
to kind of see how the azure code model

181
00:05:40,400 --> 00:05:41,120
kind of

182
00:05:41,120 --> 00:05:42,800
really seamlessly integrates in within

183
00:05:42,800 --> 00:05:45,759
the threat modeling process as well

184
00:05:45,759 --> 00:05:48,639
and finally a lot of impetus on not just

185
00:05:48,639 --> 00:05:50,479
the

186
00:05:50,479 --> 00:05:52,880
typical traffic light indicators of high

187
00:05:52,880 --> 00:05:54,960
medium and low security vulnerabilities

188
00:05:54,960 --> 00:05:55,759
but

189
00:05:55,759 --> 00:05:59,280
the the whole model today is in terms of

190
00:05:59,280 --> 00:06:00,560
really understanding those devil and the

191
00:06:00,560 --> 00:06:02,560
details of the metadata

192
00:06:02,560 --> 00:06:04,319
that these security vulnerabilities and

193
00:06:04,319 --> 00:06:06,400
these tools kind of give to product

194
00:06:06,400 --> 00:06:08,240
engineering teams a lot more

195
00:06:08,240 --> 00:06:10,240
analysis in terms of what the story of

196
00:06:10,240 --> 00:06:12,080
each and every vulnerability is so

197
00:06:12,080 --> 00:06:13,919
so all these things are kind of really

198
00:06:13,919 --> 00:06:17,039
interesting from a security perspective

199
00:06:17,039 --> 00:06:18,560
when we kind of talk about threat

200
00:06:18,560 --> 00:06:20,479
modeling uh one of the things that

201
00:06:20,479 --> 00:06:22,800
you know and and we've been in treadmill

202
00:06:22,800 --> 00:06:24,160
we've been in african security for

203
00:06:24,160 --> 00:06:25,520
almost a decade now

204
00:06:25,520 --> 00:06:27,680
and ever since we started off this

205
00:06:27,680 --> 00:06:29,120
there's this casual

206
00:06:29,120 --> 00:06:30,800
that's built about threat modeling in

207
00:06:30,800 --> 00:06:32,160
terms of it being this

208
00:06:32,160 --> 00:06:34,400
penicia of a pill that kind of solves

209
00:06:34,400 --> 00:06:35,759
every problem

210
00:06:35,759 --> 00:06:37,840
in application security and i always

211
00:06:37,840 --> 00:06:39,360
tell this to my sales and marketing

212
00:06:39,360 --> 00:06:40,240
teams

213
00:06:40,240 --> 00:06:42,639
as well in terms of be really be careful

214
00:06:42,639 --> 00:06:44,479
about positioning two things right

215
00:06:44,479 --> 00:06:46,000
be careful about positioning deficit

216
00:06:46,000 --> 00:06:48,319
apps and be careful the way you position

217
00:06:48,319 --> 00:06:49,440
threat model because

218
00:06:49,440 --> 00:06:52,479
both of these things are are

219
00:06:52,479 --> 00:06:56,080
are simply wonderful utopian dreams that

220
00:06:56,080 --> 00:06:57,599
everybody can kind of achieve when you

221
00:06:57,599 --> 00:06:58,639
talk about it

222
00:06:58,639 --> 00:07:00,160
but then when you actually get down to

223
00:07:00,160 --> 00:07:01,680
business you're trying to kind of really

224
00:07:01,680 --> 00:07:02,479
help them

225
00:07:02,479 --> 00:07:05,840
fix this and brass tacks you know

226
00:07:05,840 --> 00:07:08,560
it's really really different and that's

227
00:07:08,560 --> 00:07:10,400
one of the reasons but we really want to

228
00:07:10,400 --> 00:07:11,520
be sure

229
00:07:11,520 --> 00:07:15,039
that why does this happen and why is it

230
00:07:15,039 --> 00:07:16,319
that threat modeling

231
00:07:16,319 --> 00:07:18,400
which seems really really interesting

232
00:07:18,400 --> 00:07:19,520
when you talk about it

233
00:07:19,520 --> 00:07:22,560
seems really uh aspirational yet

234
00:07:22,560 --> 00:07:24,479
achievable when on paper

235
00:07:24,479 --> 00:07:26,080
what is it that really happens when you

236
00:07:26,080 --> 00:07:28,080
kind of take that to ground

237
00:07:28,080 --> 00:07:30,880
to ground zero and and to understand why

238
00:07:30,880 --> 00:07:32,080
threat models fail

239
00:07:32,080 --> 00:07:33,599
it's very important for us to ask

240
00:07:33,599 --> 00:07:35,840
ourselves the initial question

241
00:07:35,840 --> 00:07:37,840
is in terms of what really is the

242
00:07:37,840 --> 00:07:40,080
definition of threat modeling and that's

243
00:07:40,080 --> 00:07:41,039
really where

244
00:07:41,039 --> 00:07:42,639
uh one would like to start off this

245
00:07:42,639 --> 00:07:44,560
journey of understanding threat modeling

246
00:07:44,560 --> 00:07:46,960
in in african security scaling programs

247
00:07:46,960 --> 00:07:49,520
and for us to kind of understand that

248
00:07:49,520 --> 00:07:50,879
it's really important for us to go back

249
00:07:50,879 --> 00:07:52,560
to school and really think of the uh

250
00:07:52,560 --> 00:07:54,000
blind man and the elephant

251
00:07:54,000 --> 00:07:56,160
uh in terms of uh understanding threat

252
00:07:56,160 --> 00:07:57,599
modeling right because

253
00:07:57,599 --> 00:08:00,000
uh threat modeling similar to the fable

254
00:08:00,000 --> 00:08:02,240
there is really kind of dependent

255
00:08:02,240 --> 00:08:05,199
on what you're looking at right um and

256
00:08:05,199 --> 00:08:06,720
and just like the seven men there

257
00:08:06,720 --> 00:08:09,039
you could kind of look at multiple

258
00:08:09,039 --> 00:08:10,240
perspectives

259
00:08:10,240 --> 00:08:11,840
of threat modeling it really depends on

260
00:08:11,840 --> 00:08:13,039
which part of the elephant that you're

261
00:08:13,039 --> 00:08:13,840
really

262
00:08:13,840 --> 00:08:16,160
uh uh you know looking at or trying to

263
00:08:16,160 --> 00:08:17,199
look at right so

264
00:08:17,199 --> 00:08:19,039
you could either it ranges threat

265
00:08:19,039 --> 00:08:20,560
modeling really ranges from things from

266
00:08:20,560 --> 00:08:21,840
finding issues and design and

267
00:08:21,840 --> 00:08:22,960
architecture which probably is the

268
00:08:22,960 --> 00:08:23,919
fundamental

269
00:08:23,919 --> 00:08:27,039
definition of threat model way up to

270
00:08:27,039 --> 00:08:29,520
uh anticipating security incidents which

271
00:08:29,520 --> 00:08:30,800
is one of the most

272
00:08:30,800 --> 00:08:33,919
uh contemporary view if you will of

273
00:08:33,919 --> 00:08:35,440
looking at threat models so it really

274
00:08:35,440 --> 00:08:36,320
kind of depends

275
00:08:36,320 --> 00:08:38,320
on what really is your motivation

276
00:08:38,320 --> 00:08:40,559
because

277
00:08:40,559 --> 00:08:42,559
the motivation to threat model really

278
00:08:42,559 --> 00:08:43,679
kind of

279
00:08:43,679 --> 00:08:46,640
drives home the initial stepping stone

280
00:08:46,640 --> 00:08:47,920
of where you're going to take the threat

281
00:08:47,920 --> 00:08:49,120
model from

282
00:08:49,120 --> 00:08:52,560
and one of the primary reasons that i

283
00:08:52,560 --> 00:08:53,120
feel

284
00:08:53,120 --> 00:08:55,200
uh and we've seen this work uh not work

285
00:08:55,200 --> 00:08:56,640
with multiple uh

286
00:08:56,640 --> 00:08:58,399
engagements as well is the primary

287
00:08:58,399 --> 00:08:59,920
reason for threatment to write largely

288
00:08:59,920 --> 00:09:00,560
fail

289
00:09:00,560 --> 00:09:02,720
is really not understanding the why of

290
00:09:02,720 --> 00:09:04,640
threat modeling right so why is it that

291
00:09:04,640 --> 00:09:05,760
teams would like to do threat modeling

292
00:09:05,760 --> 00:09:08,240
because there is no one-size-fits-all um

293
00:09:08,240 --> 00:09:09,680
it really depends i mean if you if

294
00:09:09,680 --> 00:09:11,200
you're a security architect you might

295
00:09:11,200 --> 00:09:12,640
probably want to do threat model

296
00:09:12,640 --> 00:09:14,959
to identify um securities at an

297
00:09:14,959 --> 00:09:16,959
architectural level at a blueprint level

298
00:09:16,959 --> 00:09:20,240
right if you're a pen tester you can use

299
00:09:20,240 --> 00:09:22,000
threat models as a precursor

300
00:09:22,000 --> 00:09:23,600
for you to do your pen test it's it's a

301
00:09:23,600 --> 00:09:26,160
great way for you to kind of get a lay

302
00:09:26,160 --> 00:09:26,959
of the land

303
00:09:26,959 --> 00:09:28,880
of the application uh for you to kind of

304
00:09:28,880 --> 00:09:30,080
really understand where the attack

305
00:09:30,080 --> 00:09:31,839
vectors are and what kind of strategies

306
00:09:31,839 --> 00:09:32,880
you could implement

307
00:09:32,880 --> 00:09:35,200
from pen testing perspective if you're

308
00:09:35,200 --> 00:09:37,279
an automation engineer

309
00:09:37,279 --> 00:09:39,440
you could use threat models in a way to

310
00:09:39,440 --> 00:09:40,720
kind of really plan

311
00:09:40,720 --> 00:09:42,320
your security regression scripts and

312
00:09:42,320 --> 00:09:44,000
we'll see how that works uh in the next

313
00:09:44,000 --> 00:09:44,800
couple of slides

314
00:09:44,800 --> 00:09:47,200
but long story short i think it's really

315
00:09:47,200 --> 00:09:48,480
important for each

316
00:09:48,480 --> 00:09:51,920
individual team to identify what really

317
00:09:51,920 --> 00:09:53,600
are their motivations to do a threat

318
00:09:53,600 --> 00:09:55,839
model because the monk there

319
00:09:55,839 --> 00:09:58,080
like i said there simply is no

320
00:09:58,080 --> 00:09:59,200
one-size-fits-all

321
00:09:59,200 --> 00:10:00,880
uh you really and just like in anything

322
00:10:00,880 --> 00:10:02,640
else in appsec right you would

323
00:10:02,640 --> 00:10:04,240
no two applications would be the same

324
00:10:04,240 --> 00:10:06,000
and therefore no two applicant security

325
00:10:06,000 --> 00:10:07,360
programs would be the same

326
00:10:07,360 --> 00:10:09,440
uh so i don't think threat model is any

327
00:10:09,440 --> 00:10:10,959
different in that same

328
00:10:10,959 --> 00:10:13,760
uh view of the world and the second

329
00:10:13,760 --> 00:10:14,959
reason we've kind of seen

330
00:10:14,959 --> 00:10:17,200
threat models fail is really an over

331
00:10:17,200 --> 00:10:18,480
emphasis of how

332
00:10:18,480 --> 00:10:20,959
uh because the first the first thing

333
00:10:20,959 --> 00:10:22,240
that people think about in terms of

334
00:10:22,240 --> 00:10:23,120
threat model

335
00:10:23,120 --> 00:10:26,240
is this humongous huge um uh

336
00:10:26,240 --> 00:10:29,519
visual uh documentation that you see uh

337
00:10:29,519 --> 00:10:31,120
where where you kind of feel that

338
00:10:31,120 --> 00:10:33,120
that's just going to be a huge bad mouth

339
00:10:33,120 --> 00:10:34,800
to even get over with right

340
00:10:34,800 --> 00:10:36,240
what is the methodology that i should be

341
00:10:36,240 --> 00:10:38,240
using should i use stride should i use

342
00:10:38,240 --> 00:10:38,880
pasta

343
00:10:38,880 --> 00:10:41,920
should i use uh something else should i

344
00:10:41,920 --> 00:10:43,360
should i find out a methodology for

345
00:10:43,360 --> 00:10:44,079
myself

346
00:10:44,079 --> 00:10:45,600
what tool should i use can i do this

347
00:10:45,600 --> 00:10:47,279
manually should i use

348
00:10:47,279 --> 00:10:49,680
uh a commercial tool a should i use a

349
00:10:49,680 --> 00:10:50,399
commercial

350
00:10:50,399 --> 00:10:52,800
b um and who's going to be doing this

351
00:10:52,800 --> 00:10:54,320
and how do i need to document this do i

352
00:10:54,320 --> 00:10:55,839
need to document this in general do i

353
00:10:55,839 --> 00:10:57,279
need to write documentation for this

354
00:10:57,279 --> 00:10:59,040
there's just so many questions that we

355
00:10:59,040 --> 00:11:00,959
get kind of get entangled

356
00:11:00,959 --> 00:11:03,519
in terms of the operational logistics of

357
00:11:03,519 --> 00:11:04,880
performing a threat model

358
00:11:04,880 --> 00:11:08,800
right and and there's this there's this

359
00:11:08,800 --> 00:11:12,240
really unsaid uh uh complex

360
00:11:12,240 --> 00:11:14,399
uh rule uh in in product engineering

361
00:11:14,399 --> 00:11:16,160
that says the threat models cannot be

362
00:11:16,160 --> 00:11:19,279
simple because set modelings have to be

363
00:11:19,279 --> 00:11:20,160
complex right

364
00:11:20,160 --> 00:11:22,160
and that's and i don't know where that

365
00:11:22,160 --> 00:11:23,839
came out from but again

366
00:11:23,839 --> 00:11:25,440
just something that adds on to

367
00:11:25,440 --> 00:11:28,560
complexities um as well so

368
00:11:28,560 --> 00:11:30,560
simple rule that we follow here uh and

369
00:11:30,560 --> 00:11:33,040
we i also also tell people is document

370
00:11:33,040 --> 00:11:34,079
what you do

371
00:11:34,079 --> 00:11:35,680
not the other way around right and the

372
00:11:35,680 --> 00:11:37,120
same thing works for threat modeling as

373
00:11:37,120 --> 00:11:38,480
well

374
00:11:38,480 --> 00:11:39,920
so talking about threat modeling schools

375
00:11:39,920 --> 00:11:41,279
of thought and this is really where we

376
00:11:41,279 --> 00:11:42,079
start

377
00:11:42,079 --> 00:11:44,240
getting to the beef of today's talk is

378
00:11:44,240 --> 00:11:46,000
really from our perspective there are

379
00:11:46,000 --> 00:11:46,880
two

380
00:11:46,880 --> 00:11:49,920
specific um uh schools of thought in

381
00:11:49,920 --> 00:11:51,040
threat modeling

382
00:11:51,040 --> 00:11:52,800
storytelling threat modeling and

383
00:11:52,800 --> 00:11:54,720
competent driven treatment and

384
00:11:54,720 --> 00:11:57,120
quite self-explanatory uh in terms of in

385
00:11:57,120 --> 00:11:58,480
terms of the verbiage there

386
00:11:58,480 --> 00:12:02,320
um a story-driven threat model is really

387
00:12:02,320 --> 00:12:05,120
uh driven from a perspective of what if

388
00:12:05,120 --> 00:12:07,279
and and you also probably call this an

389
00:12:07,279 --> 00:12:09,440
abuser case driven threat modeling right

390
00:12:09,440 --> 00:12:11,360
uh something that a lot of pen testers

391
00:12:11,360 --> 00:12:13,200
use and we at v45 started using this

392
00:12:13,200 --> 00:12:14,800
from pen testing school of start as well

393
00:12:14,800 --> 00:12:16,160
so you have an application

394
00:12:16,160 --> 00:12:18,079
uh you have a functional walkthrough of

395
00:12:18,079 --> 00:12:19,440
the application then you ask a question

396
00:12:19,440 --> 00:12:20,240
in terms of

397
00:12:20,240 --> 00:12:23,040
what if this attack vector was to

398
00:12:23,040 --> 00:12:24,720
actually be weaponized what would happen

399
00:12:24,720 --> 00:12:25,440
there so that's

400
00:12:25,440 --> 00:12:27,440
a what if scenario uh of a

401
00:12:27,440 --> 00:12:29,120
stoichiometric modeling

402
00:12:29,120 --> 00:12:31,120
a component in threat modeling which is

403
00:12:31,120 --> 00:12:32,639
uh which is what

404
00:12:32,639 --> 00:12:34,880
most organizations would do is more of a

405
00:12:34,880 --> 00:12:36,000
system driven

406
00:12:36,000 --> 00:12:37,279
engagement where you kind of take an

407
00:12:37,279 --> 00:12:38,560
application you look at the various

408
00:12:38,560 --> 00:12:39,760
components that you have in that

409
00:12:39,760 --> 00:12:40,480
application

410
00:12:40,480 --> 00:12:42,000
and you kind of figure out what those

411
00:12:42,000 --> 00:12:43,760
inherent vulnerabilities of uh

412
00:12:43,760 --> 00:12:45,680
or or weaknesses of those components are

413
00:12:45,680 --> 00:12:47,519
so it's more of an inside out driven

414
00:12:47,519 --> 00:12:48,000
approach

415
00:12:48,000 --> 00:12:49,440
whereas the story driven threat model is

416
00:12:49,440 --> 00:12:51,120
more of an outside in

417
00:12:51,120 --> 00:12:53,839
driven approach uh the fundamental

418
00:12:53,839 --> 00:12:55,279
building blocks of an

419
00:12:55,279 --> 00:12:57,120
uh off of the storytelling threat model

420
00:12:57,120 --> 00:12:59,279
um are abuser cases or abuse cases

421
00:12:59,279 --> 00:13:00,800
whereas that incompetent driven threat

422
00:13:00,800 --> 00:13:02,079
models are known issues and let me

423
00:13:02,079 --> 00:13:03,519
explain that a little bit so

424
00:13:03,519 --> 00:13:05,120
in a storytime threat model you have a

425
00:13:05,120 --> 00:13:07,279
user story and that user story kind of

426
00:13:07,279 --> 00:13:09,040
breaks down into what we call an abuser

427
00:13:09,040 --> 00:13:09,519
story

428
00:13:09,519 --> 00:13:11,200
and that abuser story is what you would

429
00:13:11,200 --> 00:13:12,800
kind of use as a starting point

430
00:13:12,800 --> 00:13:15,120
to frame your what-if scenarios um on

431
00:13:15,120 --> 00:13:16,240
the competent driven threat modeling

432
00:13:16,240 --> 00:13:17,600
perspective you already have these

433
00:13:17,600 --> 00:13:19,600
existing confidence and you're relying

434
00:13:19,600 --> 00:13:22,639
on known inherent vulnerabilities or

435
00:13:22,639 --> 00:13:24,720
weaknesses that these components have

436
00:13:24,720 --> 00:13:26,639
so you're kind of using that as your

437
00:13:26,639 --> 00:13:28,639
bedrock if you will to kind of build

438
00:13:28,639 --> 00:13:32,000
onto your uh onto your strategy of of of

439
00:13:32,000 --> 00:13:33,360
drawing these complex

440
00:13:33,360 --> 00:13:36,399
uh or even simple threat models uh a

441
00:13:36,399 --> 00:13:38,480
soil even threat model in usual cases is

442
00:13:38,480 --> 00:13:40,240
usually done post design or development

443
00:13:40,240 --> 00:13:41,440
because you're kind of looking at it at

444
00:13:41,440 --> 00:13:43,839
a water scenario so in most cases

445
00:13:43,839 --> 00:13:45,760
not it's just a rule of thumb is you

446
00:13:45,760 --> 00:13:47,199
probably

447
00:13:47,199 --> 00:13:49,360
use the storytelling threat modeling at

448
00:13:49,360 --> 00:13:51,040
a stage when the application is already

449
00:13:51,040 --> 00:13:52,480
in the posted design

450
00:13:52,480 --> 00:13:54,639
or during the development stage whereas

451
00:13:54,639 --> 00:13:56,079
the advantage of the component driven

452
00:13:56,079 --> 00:13:57,839
threat model is you can actually use it

453
00:13:57,839 --> 00:13:59,920
right before it's developed at a

454
00:13:59,920 --> 00:14:01,920
pre-design phase as well

455
00:14:01,920 --> 00:14:03,199
and and while we're talking this you'll

456
00:14:03,199 --> 00:14:05,040
probably be able to kind of appreciate

457
00:14:05,040 --> 00:14:06,959
what we spoke about in the earlier slide

458
00:14:06,959 --> 00:14:08,320
is in terms of your motivation to the

459
00:14:08,320 --> 00:14:09,680
threat modeling so as and when we keep

460
00:14:09,680 --> 00:14:10,480
going

461
00:14:10,480 --> 00:14:12,720
uh down this chart you'll see that at

462
00:14:12,720 --> 00:14:13,920
every stage here

463
00:14:13,920 --> 00:14:15,360
it kind of changes in terms of who the

464
00:14:15,360 --> 00:14:17,279
persona in product engineering

465
00:14:17,279 --> 00:14:19,120
um is going to be doing the threat model

466
00:14:19,120 --> 00:14:20,399
and what are the outcomes and

467
00:14:20,399 --> 00:14:22,240
motivations of that particular person so

468
00:14:22,240 --> 00:14:23,360
if you're an application security

469
00:14:23,360 --> 00:14:23,920
engineer

470
00:14:23,920 --> 00:14:25,360
your motivations could be different if

471
00:14:25,360 --> 00:14:27,120
you're a security architect your

472
00:14:27,120 --> 00:14:28,399
motivations could be different so it

473
00:14:28,399 --> 00:14:29,519
really depends upon which

474
00:14:29,519 --> 00:14:31,199
two different schools of thought uh kind

475
00:14:31,199 --> 00:14:33,040
of appeal to you from that perspective

476
00:14:33,040 --> 00:14:35,199
um talking about personas storytelling

477
00:14:35,199 --> 00:14:36,079
threat modeling

478
00:14:36,079 --> 00:14:38,399
usually uh a favorite amongst security

479
00:14:38,399 --> 00:14:40,000
professionals security engineers and

480
00:14:40,000 --> 00:14:40,880
developers

481
00:14:40,880 --> 00:14:42,320
and a confidence driven check model is

482
00:14:42,320 --> 00:14:44,399
usually something that both security

483
00:14:44,399 --> 00:14:45,519
professionals

484
00:14:45,519 --> 00:14:47,839
and architects can attend to use because

485
00:14:47,839 --> 00:14:49,440
of its inherent nature of being able to

486
00:14:49,440 --> 00:14:50,160
kind of

487
00:14:50,160 --> 00:14:53,440
um be used at a stage right before the

488
00:14:53,440 --> 00:14:56,000
first line of code is kind of written

489
00:14:56,000 --> 00:14:59,199
interestingly and for anybody uh for all

490
00:14:59,199 --> 00:15:00,160
you uh

491
00:15:00,160 --> 00:15:02,160
automation geeks uh who's listening in

492
00:15:02,160 --> 00:15:03,279
today's program uh

493
00:15:03,279 --> 00:15:06,160
talk um if your focus of threat modeling

494
00:15:06,160 --> 00:15:07,279
is depth

495
00:15:07,279 --> 00:15:08,800
then you probably need to use a story

496
00:15:08,800 --> 00:15:10,880
different threat model but if your focus

497
00:15:10,880 --> 00:15:13,600
is more on scale that's when you use

498
00:15:13,600 --> 00:15:15,600
component of insert model because

499
00:15:15,600 --> 00:15:17,519
as you can as you start drawing your

500
00:15:17,519 --> 00:15:19,120
abuse cases

501
00:15:19,120 --> 00:15:21,680
remember abuse cases are essentially

502
00:15:21,680 --> 00:15:23,120
stemming off

503
00:15:23,120 --> 00:15:25,760
use cases and use cases means

504
00:15:25,760 --> 00:15:27,040
functionalities

505
00:15:27,040 --> 00:15:28,959
functionalities mean edge cases so

506
00:15:28,959 --> 00:15:31,199
therefore if you're focusing on depth

507
00:15:31,199 --> 00:15:32,639
maybe your storytelling threat modeling

508
00:15:32,639 --> 00:15:34,399
is your cup of tea and if you're

509
00:15:34,399 --> 00:15:35,600
focusing on scale

510
00:15:35,600 --> 00:15:36,560
you need to kind of look at more

511
00:15:36,560 --> 00:15:38,079
confident because more competent and

512
00:15:38,079 --> 00:15:39,519
that's the reason we kind of see

513
00:15:39,519 --> 00:15:41,360
a lot of tools on the comprehensible

514
00:15:41,360 --> 00:15:43,519
side of uh of of the fence

515
00:15:43,519 --> 00:15:45,120
um and i'm not going to be promoting any

516
00:15:45,120 --> 00:15:46,320
tools here so if you want to figure out

517
00:15:46,320 --> 00:15:47,440
what those tools are

518
00:15:47,440 --> 00:15:49,440
that's a little bit of a paper exercise

519
00:15:49,440 --> 00:15:50,480
for you

520
00:15:50,480 --> 00:15:55,120
but mostly you see a lot of

521
00:15:55,120 --> 00:15:57,759
commercial tools on the component diving

522
00:15:57,759 --> 00:15:59,199
thread modeling side of the fence and on

523
00:15:59,199 --> 00:16:00,800
the storytime frame you don't have as

524
00:16:00,800 --> 00:16:02,079
many commercial tools

525
00:16:02,079 --> 00:16:02,959
we're going to be looking at thread

526
00:16:02,959 --> 00:16:04,079
playbook which is open source we're

527
00:16:04,079 --> 00:16:05,360
going to be looking at that

528
00:16:05,360 --> 00:16:07,519
in the next few minutes or you can do

529
00:16:07,519 --> 00:16:08,399
this manually

530
00:16:08,399 --> 00:16:10,480
that's where we started off doing so we

531
00:16:10,480 --> 00:16:11,600
pretty much draw

532
00:16:11,600 --> 00:16:13,600
mind maps of sorts as soon as you know

533
00:16:13,600 --> 00:16:15,519
your application uh in terms of what it

534
00:16:15,519 --> 00:16:16,160
does

535
00:16:16,160 --> 00:16:17,920
what it does and you kind of draw these

536
00:16:17,920 --> 00:16:20,320
uh mind maps or or branch off trees if

537
00:16:20,320 --> 00:16:20,880
you will

538
00:16:20,880 --> 00:16:23,680
um that kind of map your threat models

539
00:16:23,680 --> 00:16:24,480
uh and so

540
00:16:24,480 --> 00:16:26,480
today uh we're gonna let's look at this

541
00:16:26,480 --> 00:16:27,600
in a little bit more detail i know you

542
00:16:27,600 --> 00:16:28,800
talked about this but

543
00:16:28,800 --> 00:16:31,120
um in a competent driven threat model

544
00:16:31,120 --> 00:16:32,000
you pretty much start with a

545
00:16:32,000 --> 00:16:32,959
questionnaire

546
00:16:32,959 --> 00:16:34,959
again this this is talking from the view

547
00:16:34,959 --> 00:16:36,320
of the world of you being able to do

548
00:16:36,320 --> 00:16:37,360
this from a tool

549
00:16:37,360 --> 00:16:38,560
uh so therefore you start off with the

550
00:16:38,560 --> 00:16:40,560
questionnaire you pretty much entered

551
00:16:40,560 --> 00:16:42,000
things like what technology stack are

552
00:16:42,000 --> 00:16:42,720
you using

553
00:16:42,720 --> 00:16:44,320
are you are you under some kind of a

554
00:16:44,320 --> 00:16:47,199
compliance a mandate like a pci or a

555
00:16:47,199 --> 00:16:49,440
hipaa or a sock or something like that

556
00:16:49,440 --> 00:16:51,360
and then which domain you're in and then

557
00:16:51,360 --> 00:16:53,120
you think of it like think of it as

558
00:16:53,120 --> 00:16:54,160
actually filling out a questionnaire

559
00:16:54,160 --> 00:16:54,959
that kind of

560
00:16:54,959 --> 00:16:56,639
presents something at the end of the

561
00:16:56,639 --> 00:16:58,079
process for you right so

562
00:16:58,079 --> 00:16:59,600
the questionnaire is where you kind of

563
00:16:59,600 --> 00:17:01,040
really define your application or kind

564
00:17:01,040 --> 00:17:02,480
of define your scope

565
00:17:02,480 --> 00:17:04,799
and then based on those details remember

566
00:17:04,799 --> 00:17:06,160
you have your technology stack

567
00:17:06,160 --> 00:17:07,439
you already have those components for

568
00:17:07,439 --> 00:17:09,119
those stacks so the platform is going to

569
00:17:09,119 --> 00:17:10,079
pretty much kind of

570
00:17:10,079 --> 00:17:13,199
give you this uh buffet of uh

571
00:17:13,199 --> 00:17:15,119
of process flows and data flows that you

572
00:17:15,119 --> 00:17:16,559
kind of kind of use them to

573
00:17:16,559 --> 00:17:17,919
define the way that your application

574
00:17:17,919 --> 00:17:19,760
behaves and then depending on those

575
00:17:19,760 --> 00:17:21,439
components you would have threats

576
00:17:21,439 --> 00:17:23,280
uh and then each of those threats would

577
00:17:23,280 --> 00:17:25,599
have one or more of countermeasures

578
00:17:25,599 --> 00:17:27,280
that you would kind of implement so this

579
00:17:27,280 --> 00:17:29,840
is a very top-level view

580
00:17:29,840 --> 00:17:32,799
of what a workflow of a component driven

581
00:17:32,799 --> 00:17:34,480
trek model looks like but what we're

582
00:17:34,480 --> 00:17:36,160
going to be talking about in more detail

583
00:17:36,160 --> 00:17:36,880
today

584
00:17:36,880 --> 00:17:38,160
which is which is because that's

585
00:17:38,160 --> 00:17:40,160
something that's very close to us and i

586
00:17:40,160 --> 00:17:41,520
personally along with the team i've had

587
00:17:41,520 --> 00:17:43,039
the opportunity to work in this

588
00:17:43,039 --> 00:17:44,160
much more than the comprehensive

589
00:17:44,160 --> 00:17:45,679
instrument model so we're going to talk

590
00:17:45,679 --> 00:17:47,280
about more on the stoichiometric morning

591
00:17:47,280 --> 00:17:47,760
today

592
00:17:47,760 --> 00:17:49,039
so from a storytelling threat modeling

593
00:17:49,039 --> 00:17:51,440
perspective the anatomy is very simple

594
00:17:51,440 --> 00:17:53,280
you have the use case

595
00:17:53,280 --> 00:17:55,679
um which really really tells about what

596
00:17:55,679 --> 00:17:57,200
the functionality of that particular

597
00:17:57,200 --> 00:17:59,679
scope or that application is

598
00:17:59,679 --> 00:18:01,520
a use case would have one or more abuse

599
00:18:01,520 --> 00:18:03,280
cases which means what

600
00:18:03,280 --> 00:18:05,600
can go wrong with that functionality so

601
00:18:05,600 --> 00:18:07,280
that's really the abuse case

602
00:18:07,280 --> 00:18:09,840
and then you have the attack model which

603
00:18:09,840 --> 00:18:12,080
essentially tells you in terms of how

604
00:18:12,080 --> 00:18:14,960
would an abuse case really come to life

605
00:18:14,960 --> 00:18:15,440
so

606
00:18:15,440 --> 00:18:17,520
this is the primary three building

607
00:18:17,520 --> 00:18:19,919
blocks of uh asteroid events technology

608
00:18:19,919 --> 00:18:21,840
what's the use case

609
00:18:21,840 --> 00:18:24,080
what are the various abuse cases for a

610
00:18:24,080 --> 00:18:25,039
use case

611
00:18:25,039 --> 00:18:26,640
and how can those abuse cases really

612
00:18:26,640 --> 00:18:28,080
come to life

613
00:18:28,080 --> 00:18:30,720
let's look at this from an example let's

614
00:18:30,720 --> 00:18:31,919
take an application

615
00:18:31,919 --> 00:18:34,000
where the user story is imagine there's

616
00:18:34,000 --> 00:18:36,160
this you know some kind of a

617
00:18:36,160 --> 00:18:38,799
repository which has notes and then as a

618
00:18:38,799 --> 00:18:40,480
user you want to search

619
00:18:40,480 --> 00:18:42,960
for your notes using the search feature

620
00:18:42,960 --> 00:18:44,080
in that application

621
00:18:44,080 --> 00:18:47,280
a very a very random application a very

622
00:18:47,280 --> 00:18:48,400
random use cases

623
00:18:48,400 --> 00:18:49,600
so just imagine that there's a

624
00:18:49,600 --> 00:18:51,120
repository there's a search bar and

625
00:18:51,120 --> 00:18:52,160
you're searching something within the

626
00:18:52,160 --> 00:18:52,799
search bar

627
00:18:52,799 --> 00:18:54,960
and it happens to be notes right so

628
00:18:54,960 --> 00:18:56,240
that's the user story that's what the

629
00:18:56,240 --> 00:18:58,160
developers are going for

630
00:18:58,160 --> 00:18:59,840
potential abuser stories for the same

631
00:18:59,840 --> 00:19:02,720
user story would be that as an abuser

632
00:19:02,720 --> 00:19:04,559
maybe i want to search for notes that

633
00:19:04,559 --> 00:19:06,559
don't belong to me

634
00:19:06,559 --> 00:19:09,360
breach of confidentiality maybe as an

635
00:19:09,360 --> 00:19:10,160
abuser

636
00:19:10,160 --> 00:19:13,760
i would like to look at notes

637
00:19:13,760 --> 00:19:15,520
that potentially disclose sensitive

638
00:19:15,520 --> 00:19:16,799
information right

639
00:19:16,799 --> 00:19:20,480
a breach of confidentiality again

640
00:19:20,480 --> 00:19:22,799
now as you can see this particular user

641
00:19:22,799 --> 00:19:24,720
story has two abuser stories

642
00:19:24,720 --> 00:19:27,120
now each of these abuser story would

643
00:19:27,120 --> 00:19:29,120
have one or more of attack models so we

644
00:19:29,120 --> 00:19:30,480
just want to take the first

645
00:19:30,480 --> 00:19:33,440
uh abuser story which is that i'd like

646
00:19:33,440 --> 00:19:35,360
to search for user notes that don't

647
00:19:35,360 --> 00:19:37,360
that that do not belong to me and

648
00:19:37,360 --> 00:19:38,559
disclose potentially

649
00:19:38,559 --> 00:19:40,960
uh sensitive information and how would

650
00:19:40,960 --> 00:19:42,640
you but how could you potentially

651
00:19:42,640 --> 00:19:43,840
exploit this you could do man in the

652
00:19:43,840 --> 00:19:45,039
middle attacks you could probably do

653
00:19:45,039 --> 00:19:46,400
injection attacks or os command

654
00:19:46,400 --> 00:19:47,360
injection attacks

655
00:19:47,360 --> 00:19:48,960
you would probably do a url reaction but

656
00:19:48,960 --> 00:19:50,160
you kind of take the user to somewhere

657
00:19:50,160 --> 00:19:50,640
else

658
00:19:50,640 --> 00:19:52,799
and then boom something happens right

659
00:19:52,799 --> 00:19:55,600
again very top-level examples here

660
00:19:55,600 --> 00:19:56,799
so you have the user story you have the

661
00:19:56,799 --> 00:19:58,080
absolute story and then you have the

662
00:19:58,080 --> 00:19:59,919
attack models

663
00:19:59,919 --> 00:20:01,200
i want to take a little bit of a break

664
00:20:01,200 --> 00:20:03,120
here because i want to show you about

665
00:20:03,120 --> 00:20:04,640
threat playbook because

666
00:20:04,640 --> 00:20:06,080
this is the framework that we're going

667
00:20:06,080 --> 00:20:09,520
to kind of use to kind of drive this

668
00:20:09,520 --> 00:20:12,159
uh whole uh storytime threat modeling so

669
00:20:12,159 --> 00:20:12,960
let's look at

670
00:20:12,960 --> 00:20:15,919
how threat playbook kind of works within

671
00:20:15,919 --> 00:20:17,039
the security

672
00:20:17,039 --> 00:20:20,480
driven process okay so this

673
00:20:20,480 --> 00:20:22,480
is the threat playbook interface uh

674
00:20:22,480 --> 00:20:24,320
remember it's an open source platform

675
00:20:24,320 --> 00:20:25,679
i'm gonna pop in the

676
00:20:25,679 --> 00:20:28,799
uh link to this uh github link uh

677
00:20:28,799 --> 00:20:30,159
repo in case you didn't catch it in the

678
00:20:30,159 --> 00:20:32,240
earlier slide um and then

679
00:20:32,240 --> 00:20:34,080
feel free to kind of download it we have

680
00:20:34,080 --> 00:20:34,960
a lot of people who've kind of

681
00:20:34,960 --> 00:20:36,320
downloaded it and you can use you can do

682
00:20:36,320 --> 00:20:37,919
what you want with it there's no

683
00:20:37,919 --> 00:20:39,679
again uh just like we've been saying

684
00:20:39,679 --> 00:20:41,120
there's no one-size-fits-all

685
00:20:41,120 --> 00:20:43,039
with thread playbook as well uh what

686
00:20:43,039 --> 00:20:44,720
you've seen what you're seeing here

687
00:20:44,720 --> 00:20:47,360
is a temporary ui that we've kind of put

688
00:20:47,360 --> 00:20:48,559
together it can be

689
00:20:48,559 --> 00:20:51,120
it can be much more uh better looking

690
00:20:51,120 --> 00:20:52,000
than this

691
00:20:52,000 --> 00:20:53,679
and i just kind of put this for for the

692
00:20:53,679 --> 00:20:55,760
sake of today's uh demonstration

693
00:20:55,760 --> 00:20:57,440
uh but essentially what threat playbook

694
00:20:57,440 --> 00:20:59,440
is is it's an open source framework

695
00:20:59,440 --> 00:21:00,240
which is pretty much

696
00:21:00,240 --> 00:21:03,360
driven by yaml scripts uh

697
00:21:03,360 --> 00:21:05,919
python and a mongodb database right so

698
00:21:05,919 --> 00:21:07,520
essentially what thread playbook does is

699
00:21:07,520 --> 00:21:09,679
it kind of gives you the capability

700
00:21:09,679 --> 00:21:12,960
um to link use cases to abuse cases

701
00:21:12,960 --> 00:21:14,960
and then finally to security testing

702
00:21:14,960 --> 00:21:16,400
scripts as well

703
00:21:16,400 --> 00:21:18,320
uh you could have that you could have

704
00:21:18,320 --> 00:21:20,880
the actual fabric downloaded uh you

705
00:21:20,880 --> 00:21:22,480
could either use it as it is

706
00:21:22,480 --> 00:21:24,559
or you could wrap around a simple ui

707
00:21:24,559 --> 00:21:25,520
like this uh

708
00:21:25,520 --> 00:21:27,600
or or something else for you to kind of

709
00:21:27,600 --> 00:21:28,880
give data board

710
00:21:28,880 --> 00:21:32,159
um interactive uh flavor

711
00:21:32,159 --> 00:21:34,320
so what we're gonna look at today is if

712
00:21:34,320 --> 00:21:35,440
you go to projects

713
00:21:35,440 --> 00:21:37,039
um and this is this is the overall

714
00:21:37,039 --> 00:21:38,400
dashboard you'll see how many projects

715
00:21:38,400 --> 00:21:39,840
are there how many user stories

716
00:21:39,840 --> 00:21:41,280
obviously you would have more than four

717
00:21:41,280 --> 00:21:42,799
user stories i just managed to type in

718
00:21:42,799 --> 00:21:43,520
something

719
00:21:43,520 --> 00:21:46,080
today for this demonstration and then

720
00:21:46,080 --> 00:21:47,039
you would have

721
00:21:47,039 --> 00:21:48,880
uh the various vulnerabilities here by

722
00:21:48,880 --> 00:21:50,240
severity and the threat models by

723
00:21:50,240 --> 00:21:51,760
security so let's kind of

724
00:21:51,760 --> 00:21:53,679
delve into what what goes on with threat

725
00:21:53,679 --> 00:21:54,880
label right

726
00:21:54,880 --> 00:21:56,960
so i have two projects here uh you see

727
00:21:56,960 --> 00:21:58,240
an expensive project

728
00:21:58,240 --> 00:22:00,240
and then you see juice shop which is

729
00:22:00,240 --> 00:22:01,600
obviously the os

730
00:22:01,600 --> 00:22:05,280
juice shop so when you click on the

731
00:22:05,280 --> 00:22:06,880
project you see here

732
00:22:06,880 --> 00:22:08,240
you you give it gives you a

733
00:22:08,240 --> 00:22:09,760
understanding in terms of how many user

734
00:22:09,760 --> 00:22:11,039
stories are there how many abusive

735
00:22:11,039 --> 00:22:11,679
stories

736
00:22:11,679 --> 00:22:13,360
what the threat scenarios are and what

737
00:22:13,360 --> 00:22:15,120
the vulnerabilities here are right

738
00:22:15,120 --> 00:22:17,520
uh so let's look at a simple user story

739
00:22:17,520 --> 00:22:18,559
again uh

740
00:22:18,559 --> 00:22:22,000
please uh uh you know you can you can

741
00:22:22,000 --> 00:22:24,159
oversee these the way this

742
00:22:24,159 --> 00:22:26,159
uh project headers are written like i

743
00:22:26,159 --> 00:22:28,159
said i'm not the best when it comes to

744
00:22:28,159 --> 00:22:29,360
writing a good ui

745
00:22:29,360 --> 00:22:30,880
i'm just here to kind of tell you in

746
00:22:30,880 --> 00:22:32,400
terms of how we could use this

747
00:22:32,400 --> 00:22:34,240
uh i'm sure there are better folks out

748
00:22:34,240 --> 00:22:35,600
there who can kind of make a better ui

749
00:22:35,600 --> 00:22:36,159
of this

750
00:22:36,159 --> 00:22:39,280
but uh moving on uh we've got um we've

751
00:22:39,280 --> 00:22:41,200
got a simple user story called

752
00:22:41,200 --> 00:22:42,880
upload expense right so essentially what

753
00:22:42,880 --> 00:22:44,240
it's intended to do is that

754
00:22:44,240 --> 00:22:46,000
it's an expense management platform

755
00:22:46,000 --> 00:22:47,440
assuming that it's an expense management

756
00:22:47,440 --> 00:22:48,080
platform

757
00:22:48,080 --> 00:22:50,400
somebody's trying to kind of just upload

758
00:22:50,400 --> 00:22:51,200
their uh

759
00:22:51,200 --> 00:22:53,120
expenses to the platform for it to be

760
00:22:53,120 --> 00:22:54,400
kind of processed

761
00:22:54,400 --> 00:22:56,400
so this is a user story uh and you click

762
00:22:56,400 --> 00:22:57,679
here you can actually give

763
00:22:57,679 --> 00:23:00,559
what that user story is from a

764
00:23:00,559 --> 00:23:02,080
functionality perspective

765
00:23:02,080 --> 00:23:04,000
and then you see three abuser stories

766
00:23:04,000 --> 00:23:05,520
linked to it right you have

767
00:23:05,520 --> 00:23:07,919
the first abuser story which is

768
00:23:07,919 --> 00:23:09,760
manipulate expense information

769
00:23:09,760 --> 00:23:12,799
you have tag expense to someone else

770
00:23:12,799 --> 00:23:14,480
or something even more worse which

771
00:23:14,480 --> 00:23:16,159
essentially is bring down the system

772
00:23:16,159 --> 00:23:18,400
using a malware now let's look at this

773
00:23:18,400 --> 00:23:20,080
first up user story you can get a you

774
00:23:20,080 --> 00:23:22,159
can actually give out a description here

775
00:23:22,159 --> 00:23:24,080
in fact actually at the user story level

776
00:23:24,080 --> 00:23:25,600
you can actually kind of tag

777
00:23:25,600 --> 00:23:27,919
uh documents or you can kind of give out

778
00:23:27,919 --> 00:23:29,520
some kind of an image here

779
00:23:29,520 --> 00:23:31,360
so feel free to kind of use it how you

780
00:23:31,360 --> 00:23:32,559
want to

781
00:23:32,559 --> 00:23:33,919
and when you come out when you actually

782
00:23:33,919 --> 00:23:35,679
come to the abuser story here again you

783
00:23:35,679 --> 00:23:37,120
could kind of tag some images or

784
00:23:37,120 --> 00:23:37,840
something like that

785
00:23:37,840 --> 00:23:39,200
there's enough space here for you to do

786
00:23:39,200 --> 00:23:40,880
that um so

787
00:23:40,880 --> 00:23:43,279
here interestingly what's happening here

788
00:23:43,279 --> 00:23:44,240
is here's where

789
00:23:44,240 --> 00:23:46,400
uh what like what we see you saw in the

790
00:23:46,400 --> 00:23:48,080
in the slide previously

791
00:23:48,080 --> 00:23:50,559
each of this abuser stories can be

792
00:23:50,559 --> 00:23:52,159
potentially weaponized using

793
00:23:52,159 --> 00:23:54,960
three or more uh multiple ways so in

794
00:23:54,960 --> 00:23:56,559
this example we're seeing three ways for

795
00:23:56,559 --> 00:23:57,279
example

796
00:23:57,279 --> 00:23:58,960
manipulate expense information you could

797
00:23:58,960 --> 00:24:00,799
do that using a sql injection

798
00:24:00,799 --> 00:24:02,880
uh limit by sparse attack you could do

799
00:24:02,880 --> 00:24:04,960
that using compromising the manager's

800
00:24:04,960 --> 00:24:06,480
password or you could use that using

801
00:24:06,480 --> 00:24:08,320
compromising the auth token

802
00:24:08,320 --> 00:24:11,200
so that is the threat vector here and

803
00:24:11,200 --> 00:24:12,559
when you actually look at the threat

804
00:24:12,559 --> 00:24:13,520
vector

805
00:24:13,520 --> 00:24:14,960
when you click on the thread vector it

806
00:24:14,960 --> 00:24:17,520
will actually tell you uh

807
00:24:17,520 --> 00:24:19,360
what is that attack vector which

808
00:24:19,360 --> 00:24:21,120
essentially is the sql injection

809
00:24:21,120 --> 00:24:23,440
you also have this connected to the cwe

810
00:24:23,440 --> 00:24:24,960
so it will tell you sql injection is an

811
00:24:24,960 --> 00:24:25,840
89

812
00:24:25,840 --> 00:24:27,679
and then from a remediation perspective

813
00:24:27,679 --> 00:24:29,120
you can actually this is mapped to the

814
00:24:29,120 --> 00:24:30,080
asps

815
00:24:30,080 --> 00:24:31,520
which tells you in terms of how you can

816
00:24:31,520 --> 00:24:33,279
go ahead and test uh

817
00:24:33,279 --> 00:24:34,880
this particular vulnerability right

818
00:24:34,880 --> 00:24:37,120
again just just say for the demo

819
00:24:37,120 --> 00:24:39,120
uh not all of this information here

820
00:24:39,120 --> 00:24:41,039
could be practically accurate for this

821
00:24:41,039 --> 00:24:42,080
particular example

822
00:24:42,080 --> 00:24:44,480
but just to give you a a sense of what

823
00:24:44,480 --> 00:24:45,520
the fabric

824
00:24:45,520 --> 00:24:47,440
of thread playbook looks like right so

825
00:24:47,440 --> 00:24:49,120
each of these threat vectors here

826
00:24:49,120 --> 00:24:50,960
link up to one or more potential

827
00:24:50,960 --> 00:24:52,640
vulnerabilities and what's interesting

828
00:24:52,640 --> 00:24:55,440
is you can actually kind of link how you

829
00:24:55,440 --> 00:24:57,200
would test that vulnerability right for

830
00:24:57,200 --> 00:24:57,840
example

831
00:24:57,840 --> 00:24:59,360
to test for sql injection you could

832
00:24:59,360 --> 00:25:01,600
either do an automated vulnerability

833
00:25:01,600 --> 00:25:02,159
scanner

834
00:25:02,159 --> 00:25:03,919
for example i can actually link up tools

835
00:25:03,919 --> 00:25:05,440
like zap or burp suite or

836
00:25:05,440 --> 00:25:07,360
acne or something like that and then as

837
00:25:07,360 --> 00:25:08,720
those tools execute

838
00:25:08,720 --> 00:25:10,240
uh you can actually and if they find

839
00:25:10,240 --> 00:25:11,440
that vulnerability and i'll show you

840
00:25:11,440 --> 00:25:12,320
where it found

841
00:25:12,320 --> 00:25:14,640
uh very very very could see that it'll

842
00:25:14,640 --> 00:25:16,320
actually give you a simple test case

843
00:25:16,320 --> 00:25:17,279
executed here

844
00:25:17,279 --> 00:25:18,880
or you could do this manually you could

845
00:25:18,880 --> 00:25:20,000
you could check for these issues

846
00:25:20,000 --> 00:25:20,640
manually

847
00:25:20,640 --> 00:25:22,880
or if there's an existing exploit uh

848
00:25:22,880 --> 00:25:24,559
that is available for this vulnerability

849
00:25:24,559 --> 00:25:26,000
you could link that up as well

850
00:25:26,000 --> 00:25:27,760
or you could use a source composition

851
00:25:27,760 --> 00:25:29,279
scanning right you could use tools like

852
00:25:29,279 --> 00:25:30,480
snake and other things

853
00:25:30,480 --> 00:25:32,400
for you to kind of uh check for that

854
00:25:32,400 --> 00:25:33,520
same vulnerability

855
00:25:33,520 --> 00:25:35,279
and then finally you could use static

856
00:25:35,279 --> 00:25:36,640
analysis as well which is what we've

857
00:25:36,640 --> 00:25:37,520
used here

858
00:25:37,520 --> 00:25:39,279
so these are the various ways in which

859
00:25:39,279 --> 00:25:40,720
you could potentially

860
00:25:40,720 --> 00:25:42,480
check for this vulnerability so i'm just

861
00:25:42,480 --> 00:25:44,480
going to go back here to the project i'm

862
00:25:44,480 --> 00:25:46,240
going to show you

863
00:25:46,240 --> 00:25:49,679
uh the vulnerabilities here so you see

864
00:25:49,679 --> 00:25:50,799
all these vulnerabilities these are the

865
00:25:50,799 --> 00:25:52,320
various vulnerabilities

866
00:25:52,320 --> 00:25:55,440
that the various tools have found so

867
00:25:55,440 --> 00:25:56,880
depending and because we have the

868
00:25:56,880 --> 00:25:58,799
mapping of the cwe here

869
00:25:58,799 --> 00:26:00,400
as and when the tools find that

870
00:26:00,400 --> 00:26:01,840
particular vulnerability

871
00:26:01,840 --> 00:26:04,640
it will say that this particular

872
00:26:04,640 --> 00:26:06,000
vulnerability has been found

873
00:26:06,000 --> 00:26:07,840
and because of the fact that we've

874
00:26:07,840 --> 00:26:10,080
potentially mapped a vulnerability

875
00:26:10,080 --> 00:26:12,880
to a threat vector so now you have a

876
00:26:12,880 --> 00:26:13,760
link between

877
00:26:13,760 --> 00:26:16,799
a threat a vulnerability the tool that

878
00:26:16,799 --> 00:26:18,400
found that vulnerability so which means

879
00:26:18,400 --> 00:26:18,799
that

880
00:26:18,799 --> 00:26:20,400
tomorrow you can actually look at all of

881
00:26:20,400 --> 00:26:22,159
your threats and say

882
00:26:22,159 --> 00:26:25,279
okay i've got 15 threads

883
00:26:25,279 --> 00:26:27,440
and i've got uh 20 different

884
00:26:27,440 --> 00:26:28,400
vulnerabilities

885
00:26:28,400 --> 00:26:30,159
which are these vulnerabilities map to

886
00:26:30,159 --> 00:26:32,000
which threats so if there's a threat

887
00:26:32,000 --> 00:26:34,480
that does not map to a vulnerability

888
00:26:34,480 --> 00:26:36,880
it means that that particular threat has

889
00:26:36,880 --> 00:26:37,679
not really

890
00:26:37,679 --> 00:26:40,799
has yet been weaponized uh or have has

891
00:26:40,799 --> 00:26:42,159
not been found as yet

892
00:26:42,159 --> 00:26:43,760
now similarly there's a vulnerability

893
00:26:43,760 --> 00:26:45,520
that's not mapped to a threat

894
00:26:45,520 --> 00:26:48,400
that simply means that okay there's some

895
00:26:48,400 --> 00:26:50,000
there's some vulnerability that's come

896
00:26:50,000 --> 00:26:52,320
either by design or by disaster

897
00:26:52,320 --> 00:26:55,279
uh that that has not been envisaged in

898
00:26:55,279 --> 00:26:56,559
your threat modeling process

899
00:26:56,559 --> 00:26:58,480
right which means that's a better way

900
00:26:58,480 --> 00:26:59,520
for you to go back to your threat

901
00:26:59,520 --> 00:27:00,159
modeling

902
00:27:00,159 --> 00:27:01,679
drawing board and say hey how did we

903
00:27:01,679 --> 00:27:03,120
miss this vulnerability what could have

904
00:27:03,120 --> 00:27:04,480
caused this vulnerability and then you

905
00:27:04,480 --> 00:27:05,520
go ahead and refine your thread

906
00:27:05,520 --> 00:27:07,360
modelling from that perspective so which

907
00:27:07,360 --> 00:27:08,000
whichever

908
00:27:08,000 --> 00:27:09,919
you can either do that at a component

909
00:27:09,919 --> 00:27:11,600
level or you want to do that at a

910
00:27:11,600 --> 00:27:14,400
user story or a story level you could do

911
00:27:14,400 --> 00:27:15,200
that as well

912
00:27:15,200 --> 00:27:16,720
so the objective of the thread playbook

913
00:27:16,720 --> 00:27:19,039
really is for us to really kind of drink

914
00:27:19,039 --> 00:27:20,480
about that uh

915
00:27:20,480 --> 00:27:23,600
link between threats vulnerabilities

916
00:27:23,600 --> 00:27:24,960
and then the tools that found those

917
00:27:24,960 --> 00:27:26,960
vulnerabilities and therefore establish

918
00:27:26,960 --> 00:27:27,520
that

919
00:27:27,520 --> 00:27:29,039
end-to-end connectivity between the

920
00:27:29,039 --> 00:27:30,640
threat and the vulnerability but more

921
00:27:30,640 --> 00:27:31,440
importantly

922
00:27:31,440 --> 00:27:33,200
is also the kind of and all of these

923
00:27:33,200 --> 00:27:35,760
things at the back end

924
00:27:35,760 --> 00:27:37,360
all of these user stories and abuser

925
00:27:37,360 --> 00:27:39,440
stories are all simple yaml scripts

926
00:27:39,440 --> 00:27:39,919
right

927
00:27:39,919 --> 00:27:41,440
it's just yaml scripts that we've

928
00:27:41,440 --> 00:27:42,559
written in the background and you kind

929
00:27:42,559 --> 00:27:43,760
of load all of these

930
00:27:43,760 --> 00:27:45,760
uh information on it and because of the

931
00:27:45,760 --> 00:27:47,360
fact that you're trying to kind of

932
00:27:47,360 --> 00:27:49,120
really break that down to its lowest

933
00:27:49,120 --> 00:27:50,399
common denominator being

934
00:27:50,399 --> 00:27:53,279
some kind of a code fabric we're hoping

935
00:27:53,279 --> 00:27:54,960
uh that you know this is something that

936
00:27:54,960 --> 00:27:56,320
a lot of developers

937
00:27:56,320 --> 00:27:59,200
uh can potentially use uh in uh for for

938
00:27:59,200 --> 00:28:00,799
you to kind of just codify that whole

939
00:28:00,799 --> 00:28:02,000
threat modeling process

940
00:28:02,000 --> 00:28:03,440
and as and when you have more of user

941
00:28:03,440 --> 00:28:04,640
stories one of the things that we've

942
00:28:04,640 --> 00:28:05,200
done

943
00:28:05,200 --> 00:28:08,559
is that we've kind of taken um common

944
00:28:08,559 --> 00:28:10,799
uh abuser stories of common threat

945
00:28:10,799 --> 00:28:12,320
scenarios that's applicable for any

946
00:28:12,320 --> 00:28:13,760
application right it doesn't have to be

947
00:28:13,760 --> 00:28:16,000
just application a or application b when

948
00:28:16,000 --> 00:28:17,279
you actually break down your security

949
00:28:17,279 --> 00:28:18,799
test cases there are some gendered

950
00:28:18,799 --> 00:28:20,640
security test cases that's applicable to

951
00:28:20,640 --> 00:28:21,600
any kind of

952
00:28:21,600 --> 00:28:25,039
uh app and then you have specific

953
00:28:25,039 --> 00:28:26,559
test cases that's applicable only to

954
00:28:26,559 --> 00:28:28,159
that particular application

955
00:28:28,159 --> 00:28:30,640
so if there's a way for us to kind of

956
00:28:30,640 --> 00:28:31,279
collate

957
00:28:31,279 --> 00:28:33,600
all of these generic security test cases

958
00:28:33,600 --> 00:28:35,279
and therefore the genetic threats you

959
00:28:35,279 --> 00:28:36,640
can actually look them as as

960
00:28:36,640 --> 00:28:38,720
common abuser cases and that's something

961
00:28:38,720 --> 00:28:40,080
that you're working on right now we're

962
00:28:40,080 --> 00:28:40,640
gonna

963
00:28:40,640 --> 00:28:42,240
soon open source that as well where

964
00:28:42,240 --> 00:28:44,880
we're kind of writing abuser cases that

965
00:28:44,880 --> 00:28:46,399
you could just plug into thread playbook

966
00:28:46,399 --> 00:28:47,840
and then whatever app that you're using

967
00:28:47,840 --> 00:28:48,799
you could just pull in those

968
00:28:48,799 --> 00:28:50,640
music cases without you having to kind

969
00:28:50,640 --> 00:28:53,760
of write them uh from scratch

970
00:28:53,760 --> 00:28:56,960
um and and this is really uh and let's

971
00:28:56,960 --> 00:29:00,159
see if you've got some scans here

972
00:29:00,159 --> 00:29:01,360
no we don't have scans here but

973
00:29:01,360 --> 00:29:02,640
essentially what will happen is you can

974
00:29:02,640 --> 00:29:03,279
actually

975
00:29:03,279 --> 00:29:04,720
run those scans and you can take those

976
00:29:04,720 --> 00:29:06,559
scans and link them back uh

977
00:29:06,559 --> 00:29:10,000
to the uh main abuser cases um

978
00:29:10,000 --> 00:29:11,440
that we see here and therefore the

979
00:29:11,440 --> 00:29:14,080
threat scenarios as well

980
00:29:14,080 --> 00:29:15,840
it also gives you a nice little threat

981
00:29:15,840 --> 00:29:17,360
map here um

982
00:29:17,360 --> 00:29:20,640
which you could kind of use to see what

983
00:29:20,640 --> 00:29:21,679
your

984
00:29:21,679 --> 00:29:24,240
surface vector of your components are so

985
00:29:24,240 --> 00:29:25,919
depending on the number of use cases and

986
00:29:25,919 --> 00:29:27,279
abuse cases that you have

987
00:29:27,279 --> 00:29:28,480
you can actually click on that

988
00:29:28,480 --> 00:29:30,480
particular uh

989
00:29:30,480 --> 00:29:32,399
vulnerability let's see if you find

990
00:29:32,399 --> 00:29:34,559
something here

991
00:29:34,559 --> 00:29:36,399
yeah so let's say that you have a use

992
00:29:36,399 --> 00:29:37,679
case that you want to look at or you

993
00:29:37,679 --> 00:29:39,120
want to have a

994
00:29:39,120 --> 00:29:40,720
you want to kind of just delve into a

995
00:29:40,720 --> 00:29:42,080
particular type of vulnerability you can

996
00:29:42,080 --> 00:29:43,120
actually do that here

997
00:29:43,120 --> 00:29:44,159
and then it will give you the

998
00:29:44,159 --> 00:29:46,399
appropriate mapping between the sql

999
00:29:46,399 --> 00:29:48,480
uh between that particular vulnerability

1000
00:29:48,480 --> 00:29:49,840
and the asps standard that's used to

1001
00:29:49,840 --> 00:29:51,760
validate that

1002
00:29:51,760 --> 00:29:53,919
so that's a little bit about thread

1003
00:29:53,919 --> 00:29:55,440
playbook and now let's

1004
00:29:55,440 --> 00:29:58,320
go back to our slides and see how uh

1005
00:29:58,320 --> 00:29:59,760
threat playbook

1006
00:29:59,760 --> 00:30:01,279
and the storyline threat modeling can

1007
00:30:01,279 --> 00:30:02,799
actually trigger down

1008
00:30:02,799 --> 00:30:06,880
to a security test automation process

1009
00:30:06,880 --> 00:30:09,520
okay um so in this section which is the

1010
00:30:09,520 --> 00:30:10,799
last section of the talk we're gonna

1011
00:30:10,799 --> 00:30:13,600
look at um how threat modeling can be a

1012
00:30:13,600 --> 00:30:14,960
way for us to

1013
00:30:14,960 --> 00:30:17,760
effectively drive uh security testing at

1014
00:30:17,760 --> 00:30:18,880
scale remember we talked about

1015
00:30:18,880 --> 00:30:20,640
motivations of threat modeling

1016
00:30:20,640 --> 00:30:22,559
and one of the bigger motivations that

1017
00:30:22,559 --> 00:30:23,840
teams are having today

1018
00:30:23,840 --> 00:30:25,520
which was one of the motivations that we

1019
00:30:25,520 --> 00:30:27,120
had a couple of years back

1020
00:30:27,120 --> 00:30:28,640
is how can you kind of use threat

1021
00:30:28,640 --> 00:30:30,320
modeling as an effective way

1022
00:30:30,320 --> 00:30:33,200
to drive security testing at scale and

1023
00:30:33,200 --> 00:30:35,200
to do that we're going to go back to our

1024
00:30:35,200 --> 00:30:37,600
initial anatomy slide which is that of

1025
00:30:37,600 --> 00:30:38,960
the use case the abuses

1026
00:30:38,960 --> 00:30:40,720
abuse case and the attack model we're

1027
00:30:40,720 --> 00:30:43,520
going to add some little pieces to this

1028
00:30:43,520 --> 00:30:45,360
existing anatomy and drive home that

1029
00:30:45,360 --> 00:30:47,279
point so you have the use case you have

1030
00:30:47,279 --> 00:30:48,559
the abuser case

1031
00:30:48,559 --> 00:30:50,799
you have the attack model now there's

1032
00:30:50,799 --> 00:30:52,320
one more component that we can add to

1033
00:30:52,320 --> 00:30:54,080
the attack model which is that of test

1034
00:30:54,080 --> 00:30:54,640
cases

1035
00:30:54,640 --> 00:30:57,519
so remember we said attack model tells

1036
00:30:57,519 --> 00:30:58,000
you

1037
00:30:58,000 --> 00:31:00,320
how you would weaponize or how would an

1038
00:31:00,320 --> 00:31:02,080
abuse case come to life

1039
00:31:02,080 --> 00:31:04,320
and the test case really kind of tells

1040
00:31:04,320 --> 00:31:06,080
you how plausible are they

1041
00:31:06,080 --> 00:31:08,240
and that is really what the test cases

1042
00:31:08,240 --> 00:31:09,919
do the test cases as the name such as

1043
00:31:09,919 --> 00:31:11,679
are just a series of test cases that you

1044
00:31:11,679 --> 00:31:14,399
can execute to see or to validate

1045
00:31:14,399 --> 00:31:16,559
whether that scenario that threat

1046
00:31:16,559 --> 00:31:17,679
scenario that you've

1047
00:31:17,679 --> 00:31:20,080
that you've envisaged is actually

1048
00:31:20,080 --> 00:31:22,080
possible in real life or not which

1049
00:31:22,080 --> 00:31:25,279
aka is a security assessment process

1050
00:31:25,279 --> 00:31:27,279
be a pen test or be the vulnerability

1051
00:31:27,279 --> 00:31:28,320
assessment and

1052
00:31:28,320 --> 00:31:29,840
and and we call them separately right

1053
00:31:29,840 --> 00:31:31,360
vulnerability assessment is separate

1054
00:31:31,360 --> 00:31:33,679
and a pen test is not the same so a test

1055
00:31:33,679 --> 00:31:34,799
case is really kind of

1056
00:31:34,799 --> 00:31:37,600
uh that fab that element of the of the

1057
00:31:37,600 --> 00:31:39,039
threat modeling process

1058
00:31:39,039 --> 00:31:41,120
uh that would help you kind of validate

1059
00:31:41,120 --> 00:31:42,480
your threat models that you kind of seen

1060
00:31:42,480 --> 00:31:44,080
in the previous stage

1061
00:31:44,080 --> 00:31:45,600
so let's go back to the previous example

1062
00:31:45,600 --> 00:31:48,320
we stopped the last time around with

1063
00:31:48,320 --> 00:31:49,919
with the third column which essentially

1064
00:31:49,919 --> 00:31:52,799
was uh what are those attack models and

1065
00:31:52,799 --> 00:31:54,640
what are those attack scenarios

1066
00:31:54,640 --> 00:31:55,840
but then when you actually kind of look

1067
00:31:55,840 --> 00:31:58,480
at the security test cases here

1068
00:31:58,480 --> 00:32:01,039
each of those attack models could kind

1069
00:32:01,039 --> 00:32:01,679
of

1070
00:32:01,679 --> 00:32:03,760
open up multiple security test cases so

1071
00:32:03,760 --> 00:32:05,200
let's look at the man the middle attack

1072
00:32:05,200 --> 00:32:06,000
for example

1073
00:32:06,000 --> 00:32:08,240
uh so to to actually test for a man in

1074
00:32:08,240 --> 00:32:09,679
the middle attack you would actually

1075
00:32:09,679 --> 00:32:12,000
a check if the application renders all

1076
00:32:12,000 --> 00:32:13,600
pages in https

1077
00:32:13,600 --> 00:32:15,360
or you would check for known attacks

1078
00:32:15,360 --> 00:32:16,640
within the ssl

1079
00:32:16,640 --> 00:32:19,440
uh tls uh vulnerabilities see if they're

1080
00:32:19,440 --> 00:32:20,559
subjected to poodle

1081
00:32:20,559 --> 00:32:22,240
beast or suite 32 attacks or something

1082
00:32:22,240 --> 00:32:23,919
like that or you could check for

1083
00:32:23,919 --> 00:32:25,679
hsts implementation the application so

1084
00:32:25,679 --> 00:32:27,279
there are multiple ways

1085
00:32:27,279 --> 00:32:29,919
and and as pen testers uh those who are

1086
00:32:29,919 --> 00:32:32,159
in the room virtual room today

1087
00:32:32,159 --> 00:32:34,159
the this is a very day-in day-out

1088
00:32:34,159 --> 00:32:35,279
process for you guys

1089
00:32:35,279 --> 00:32:36,720
uh for you to be able to test for a

1090
00:32:36,720 --> 00:32:38,640
specific kind of

1091
00:32:38,640 --> 00:32:40,080
vulnerability and that's exactly what

1092
00:32:40,080 --> 00:32:41,440
we're doing here we're essentially kind

1093
00:32:41,440 --> 00:32:42,960
of taking that attack model

1094
00:32:42,960 --> 00:32:44,559
and we're kind of breaking them we can

1095
00:32:44,559 --> 00:32:46,159
extending that to what

1096
00:32:46,159 --> 00:32:47,840
various security test cases can

1097
00:32:47,840 --> 00:32:50,080
potentially check for the existence

1098
00:32:50,080 --> 00:32:52,559
or the absence of that particular threat

1099
00:32:52,559 --> 00:32:53,230
scenario

1100
00:32:53,230 --> 00:32:54,840
[Music]

1101
00:32:54,840 --> 00:32:57,840
so the here's the link

1102
00:32:57,840 --> 00:33:00,880
to an effective uh threat modeling

1103
00:33:00,880 --> 00:33:03,200
uh automation scenario right so

1104
00:33:03,200 --> 00:33:04,640
essentially you have to threat you have

1105
00:33:04,640 --> 00:33:06,399
to you have the test case

1106
00:33:06,399 --> 00:33:09,519
um and then a potentially a test case

1107
00:33:09,519 --> 00:33:11,120
from an automation perspective can be

1108
00:33:11,120 --> 00:33:12,720
done in three buckets right

1109
00:33:12,720 --> 00:33:14,960
a you have the tool root which means

1110
00:33:14,960 --> 00:33:16,640
that to execute that test case you're

1111
00:33:16,640 --> 00:33:17,200
using

1112
00:33:17,200 --> 00:33:19,600
some kind of a tool you're using a dash

1113
00:33:19,600 --> 00:33:21,039
tool you're using a

1114
00:33:21,039 --> 00:33:23,200
a a sas tool you're using a source

1115
00:33:23,200 --> 00:33:24,399
composition tool

1116
00:33:24,399 --> 00:33:26,240
so there's this hundred person automator

1117
00:33:26,240 --> 00:33:27,919
so there's a test case and that test

1118
00:33:27,919 --> 00:33:30,480
case can be purely executed using a two

1119
00:33:30,480 --> 00:33:32,720
that's bucket one and then you have

1120
00:33:32,720 --> 00:33:34,399
bucket two which means that these are

1121
00:33:34,399 --> 00:33:35,360
test cases

1122
00:33:35,360 --> 00:33:37,679
that cannot be executed by a tool and

1123
00:33:37,679 --> 00:33:38,399
that is

1124
00:33:38,399 --> 00:33:40,320
needs to be done manually for example

1125
00:33:40,320 --> 00:33:42,159
let's say it's a it's in the trained

1126
00:33:42,159 --> 00:33:43,519
hands of a pen tester that you can

1127
00:33:43,519 --> 00:33:45,679
actually take for a business logic flaw

1128
00:33:45,679 --> 00:33:47,679
no tool can find a business logic flaw

1129
00:33:47,679 --> 00:33:49,120
or an edge case scenario right

1130
00:33:49,120 --> 00:33:51,279
now that's bucket two those are the kind

1131
00:33:51,279 --> 00:33:53,200
of test cases that you want to

1132
00:33:53,200 --> 00:33:56,399
categorize um as a bucket and now

1133
00:33:56,399 --> 00:33:57,760
the thing about bucket 2 is you can

1134
00:33:57,760 --> 00:33:59,919
actually use automation scripts

1135
00:33:59,919 --> 00:34:02,880
to actually simulate those attacks right

1136
00:34:02,880 --> 00:34:03,679
you can use

1137
00:34:03,679 --> 00:34:05,200
automation scripts like selenium

1138
00:34:05,200 --> 00:34:07,279
cucumber robots scripts or whatever that

1139
00:34:07,279 --> 00:34:07,919
you have

1140
00:34:07,919 --> 00:34:11,040
to kind of really uh take that edge case

1141
00:34:11,040 --> 00:34:12,719
or business logic flaw that the pen

1142
00:34:12,719 --> 00:34:13,760
tester has

1143
00:34:13,760 --> 00:34:15,760
has found and then you can actually find

1144
00:34:15,760 --> 00:34:17,359
a way to simulate that particular

1145
00:34:17,359 --> 00:34:18,320
vulnerability so

1146
00:34:18,320 --> 00:34:20,239
those are the vulnerabilities are 100

1147
00:34:20,239 --> 00:34:22,000
manual and then you have the third

1148
00:34:22,000 --> 00:34:23,839
bucket which is the hybrid bucket

1149
00:34:23,839 --> 00:34:25,839
and an example of a hybrid vulnerability

1150
00:34:25,839 --> 00:34:26,960
would be it would be

1151
00:34:26,960 --> 00:34:28,879
a vulnerability where you could go only

1152
00:34:28,879 --> 00:34:30,079
so far with the tool

1153
00:34:30,079 --> 00:34:32,079
and then you need to go manual a perfect

1154
00:34:32,079 --> 00:34:34,480
example is a parameterized task script

1155
00:34:34,480 --> 00:34:36,560
right a dash can potentially scan pages

1156
00:34:36,560 --> 00:34:38,800
and cross crawl pages but then there are

1157
00:34:38,800 --> 00:34:40,879
certain tasks that you need additional

1158
00:34:40,879 --> 00:34:44,239
uh a context like like credential for

1159
00:34:44,239 --> 00:34:45,679
example the simplest context that you

1160
00:34:45,679 --> 00:34:46,399
need to give

1161
00:34:46,399 --> 00:34:47,839
to the tool for the tool to be able to

1162
00:34:47,839 --> 00:34:49,440
kind of move forward and do what it does

1163
00:34:49,440 --> 00:34:49,839
best

1164
00:34:49,839 --> 00:34:52,719
that's a good example of a hybrid based

1165
00:34:52,719 --> 00:34:53,359
uh based

1166
00:34:53,359 --> 00:34:55,599
uh hybrid type of test case so depending

1167
00:34:55,599 --> 00:34:56,879
on your test cases you might have

1168
00:34:56,879 --> 00:34:58,560
hundred test cases for example

1169
00:34:58,560 --> 00:35:00,160
and each of those test cases would fall

1170
00:35:00,160 --> 00:35:02,160
under one of these three buckets either

1171
00:35:02,160 --> 00:35:03,839
a tool driven threat case

1172
00:35:03,839 --> 00:35:07,280
or a script driven test case or a hybrid

1173
00:35:07,280 --> 00:35:08,640
test case right so

1174
00:35:08,640 --> 00:35:11,520
so once you've kind of categorized each

1175
00:35:11,520 --> 00:35:13,040
of your test cases here

1176
00:35:13,040 --> 00:35:15,599
you can actually go ahead and see the

1177
00:35:15,599 --> 00:35:17,280
whole nine yards in terms of how this

1178
00:35:17,280 --> 00:35:17,760
looks

1179
00:35:17,760 --> 00:35:20,400
in terms of a full process of threat

1180
00:35:20,400 --> 00:35:21,359
model

1181
00:35:21,359 --> 00:35:22,960
to a test case so every time there's an

1182
00:35:22,960 --> 00:35:24,560
application that comes in you ask

1183
00:35:24,560 --> 00:35:25,920
yourself the first question is this the

1184
00:35:25,920 --> 00:35:27,520
first time you're doing a threat model

1185
00:35:27,520 --> 00:35:29,440
to that obligation if the answer that

1186
00:35:29,440 --> 00:35:30,800
question is yes

1187
00:35:30,800 --> 00:35:33,760
you would actually do an abu if you

1188
00:35:33,760 --> 00:35:34,240
first

1189
00:35:34,240 --> 00:35:36,320
use the component driven threat model

1190
00:35:36,320 --> 00:35:37,760
like we said though we're talking about

1191
00:35:37,760 --> 00:35:38,880
story-driven threat model there are

1192
00:35:38,880 --> 00:35:40,160
certain advantages

1193
00:35:40,160 --> 00:35:41,760
that the competent demonstrate model

1194
00:35:41,760 --> 00:35:43,440
gives you and the advantage of that

1195
00:35:43,440 --> 00:35:46,240
is scale so in our experience what you

1196
00:35:46,240 --> 00:35:48,320
felt is that it's that marriage

1197
00:35:48,320 --> 00:35:50,240
between competent even threat model and

1198
00:35:50,240 --> 00:35:51,760
the storytelling threat model that gives

1199
00:35:51,760 --> 00:35:52,079
you

1200
00:35:52,079 --> 00:35:55,119
both the efficiencies of depth and skill

1201
00:35:55,119 --> 00:35:56,720
so for us some of our customers in the

1202
00:35:56,720 --> 00:35:58,000
enterprise segment we've actually done

1203
00:35:58,000 --> 00:36:00,000
that is we've actually taken a component

1204
00:36:00,000 --> 00:36:00,880
threat model

1205
00:36:00,880 --> 00:36:04,240
uh modeling tool uh any commercial tool

1206
00:36:04,240 --> 00:36:06,320
we take that we first run that on the

1207
00:36:06,320 --> 00:36:08,320
application we get this entire

1208
00:36:08,320 --> 00:36:09,760
bunch of vulnerabilities right which

1209
00:36:09,760 --> 00:36:11,119
that's going to give you like at least

1210
00:36:11,119 --> 00:36:12,320
60 percent of one

1211
00:36:12,320 --> 00:36:14,960
of potential threats and then you run

1212
00:36:14,960 --> 00:36:15,839
the component

1213
00:36:15,839 --> 00:36:17,839
you've done the abuser given given

1214
00:36:17,839 --> 00:36:19,680
threat models which is more focused on

1215
00:36:19,680 --> 00:36:20,160
depth

1216
00:36:20,160 --> 00:36:21,839
and then you kind of marry both of them

1217
00:36:21,839 --> 00:36:23,599
together to get your 100 threads

1218
00:36:23,599 --> 00:36:25,599
and then you go around with your test uh

1219
00:36:25,599 --> 00:36:27,280
test case methodology so if that's if

1220
00:36:27,280 --> 00:36:28,000
the if

1221
00:36:28,000 --> 00:36:29,040
if that's the first time that you're

1222
00:36:29,040 --> 00:36:31,200
doing the threat modeling you go through

1223
00:36:31,200 --> 00:36:32,320
that flowchart

1224
00:36:32,320 --> 00:36:33,599
if that's not the first time you're

1225
00:36:33,599 --> 00:36:35,280
doing a threat modeling it's it's it's a

1226
00:36:35,280 --> 00:36:36,640
nitrate of threat model

1227
00:36:36,640 --> 00:36:38,720
then you just go ahead and run a story

1228
00:36:38,720 --> 00:36:40,720
driven threat model on that additional

1229
00:36:40,720 --> 00:36:41,520
iteration

1230
00:36:41,520 --> 00:36:43,040
or you run a comprehensive threat model

1231
00:36:43,040 --> 00:36:44,960
in an additional iteration of module

1232
00:36:44,960 --> 00:36:47,040
so so once you've done this you can

1233
00:36:47,040 --> 00:36:48,480
actually kind of

1234
00:36:48,480 --> 00:36:50,000
really kind of collate all of these

1235
00:36:50,000 --> 00:36:52,560
threat models on a singular plane

1236
00:36:52,560 --> 00:36:55,040
and then you can actually start writing

1237
00:36:55,040 --> 00:36:56,400
your automation scripts

1238
00:36:56,400 --> 00:36:58,000
so once you have your threat models you

1239
00:36:58,000 --> 00:36:59,680
have your test cases once you have your

1240
00:36:59,680 --> 00:37:01,200
test cases you can actually start

1241
00:37:01,200 --> 00:37:02,240
automating them

1242
00:37:02,240 --> 00:37:03,839
so once you have once you're done with

1243
00:37:03,839 --> 00:37:05,760
your automation as you saw in the

1244
00:37:05,760 --> 00:37:06,880
previous

1245
00:37:06,880 --> 00:37:09,119
example the demo you can actually use

1246
00:37:09,119 --> 00:37:10,480
frameworks like thread playbook for you

1247
00:37:10,480 --> 00:37:12,320
to say okay i have my test case i have

1248
00:37:12,320 --> 00:37:13,680
my threat models here

1249
00:37:13,680 --> 00:37:15,760
i'm done with my security testing i now

1250
00:37:15,760 --> 00:37:17,440
have my vulnerabilities here

1251
00:37:17,440 --> 00:37:18,960
and then if there's a way for you to map

1252
00:37:18,960 --> 00:37:20,240
your vulnerabilities back to your

1253
00:37:20,240 --> 00:37:20,880
threads

1254
00:37:20,880 --> 00:37:22,640
which threat playbook can do using the

1255
00:37:22,640 --> 00:37:25,040
cwe mapping you're gonna take the cw

1256
00:37:25,040 --> 00:37:26,079
from the vulnerabilities

1257
00:37:26,079 --> 00:37:28,000
take the cwe from the threads kind of

1258
00:37:28,000 --> 00:37:29,599
marry them together and say okay

1259
00:37:29,599 --> 00:37:31,040
these are my threats these are the

1260
00:37:31,040 --> 00:37:32,240
vulnerabilities that are led to those

1261
00:37:32,240 --> 00:37:32,880
threats

1262
00:37:32,880 --> 00:37:36,000
right so this is a very very effective

1263
00:37:36,000 --> 00:37:38,640
way uh and a very practical way for you

1264
00:37:38,640 --> 00:37:39,839
to not just

1265
00:37:39,839 --> 00:37:42,000
look at threat models that can be

1266
00:37:42,000 --> 00:37:43,520
implemented because you can kick off

1267
00:37:43,520 --> 00:37:45,599
with threat models with very little

1268
00:37:45,599 --> 00:37:47,280
red taping from that perspective and

1269
00:37:47,280 --> 00:37:49,280
also kind of look at a way to kind of

1270
00:37:49,280 --> 00:37:50,240
scale

1271
00:37:50,240 --> 00:37:52,160
in terms of being able to kind of use

1272
00:37:52,160 --> 00:37:53,839
this across multiple teams

1273
00:37:53,839 --> 00:37:55,520
across multiple apps and things like

1274
00:37:55,520 --> 00:37:57,839
that so finally this is

1275
00:37:57,839 --> 00:38:01,440
a um this is this is a diagram that i

1276
00:38:01,440 --> 00:38:04,079
i i love because this is my way of

1277
00:38:04,079 --> 00:38:05,359
representing what

1278
00:38:05,359 --> 00:38:07,359
devsecops actually means what you have

1279
00:38:07,359 --> 00:38:09,040
on the top are your typical

1280
00:38:09,040 --> 00:38:10,720
uh building blocks of security

1281
00:38:10,720 --> 00:38:12,480
engineering plan code build test release

1282
00:38:12,480 --> 00:38:13,440
deploy operate

1283
00:38:13,440 --> 00:38:15,200
what do you have on the bottom are the

1284
00:38:15,200 --> 00:38:16,800
are the typical building blocks

1285
00:38:16,800 --> 00:38:19,200
of security engineering which i think is

1286
00:38:19,200 --> 00:38:20,079
threat modeling

1287
00:38:20,079 --> 00:38:22,240
sas test security and infrastructure and

1288
00:38:22,240 --> 00:38:23,119
then security

1289
00:38:23,119 --> 00:38:25,119
monitoring and attack detection and

1290
00:38:25,119 --> 00:38:26,160
really the color

1291
00:38:26,160 --> 00:38:28,480
coding here is really in terms of where

1292
00:38:28,480 --> 00:38:30,400
do those specific security engineering

1293
00:38:30,400 --> 00:38:31,440
building blocks

1294
00:38:31,440 --> 00:38:34,640
fit in their respective

1295
00:38:34,640 --> 00:38:35,920
product engineering building blocks

1296
00:38:35,920 --> 00:38:38,800
threat modeling largely on plan

1297
00:38:38,800 --> 00:38:41,680
now slowly getting into code sashed

1298
00:38:41,680 --> 00:38:42,960
largely on code

1299
00:38:42,960 --> 00:38:45,280
moving its way through build into test

1300
00:38:45,280 --> 00:38:46,960
dust and security iac

1301
00:38:46,960 --> 00:38:48,800
and so on and so forth the good thing

1302
00:38:48,800 --> 00:38:50,480
about agile threat modeling

1303
00:38:50,480 --> 00:38:54,160
is it kind of spreads across the board

1304
00:38:54,160 --> 00:38:56,960
so if you kind of so that modeling today

1305
00:38:56,960 --> 00:38:58,720
can be used at the threat modeling phase

1306
00:38:58,720 --> 00:38:59,520
with the

1307
00:38:59,520 --> 00:39:01,920
the the the conventional threat modeling

1308
00:39:01,920 --> 00:39:03,440
phase you could use that to model

1309
00:39:03,440 --> 00:39:06,240
stories because now you have a link you

1310
00:39:06,240 --> 00:39:08,160
have an ability to codify your threat

1311
00:39:08,160 --> 00:39:09,760
modeling so you can actually use threat

1312
00:39:09,760 --> 00:39:11,599
modeling as a way to derive

1313
00:39:11,599 --> 00:39:14,480
or write security test cases you could

1314
00:39:14,480 --> 00:39:16,160
use the same threat modeling

1315
00:39:16,160 --> 00:39:18,079
and the security test cases to run your

1316
00:39:18,079 --> 00:39:20,480
security test automation

1317
00:39:20,480 --> 00:39:23,359
and then you can also use threat models

1318
00:39:23,359 --> 00:39:25,599
as a building block for you to detect

1319
00:39:25,599 --> 00:39:26,960
whether the vulnerabilities that you

1320
00:39:26,960 --> 00:39:29,280
found actually have a link back to those

1321
00:39:29,280 --> 00:39:30,720
initial threat models there

1322
00:39:30,720 --> 00:39:33,200
so what's beautiful about this process

1323
00:39:33,200 --> 00:39:35,200
is that the threat modeling is actually

1324
00:39:35,200 --> 00:39:37,119
that single starting point

1325
00:39:37,119 --> 00:39:39,280
that you could use to kind of derive

1326
00:39:39,280 --> 00:39:42,160
multiple advantages through your

1327
00:39:42,160 --> 00:39:44,400
security engineering processes and as we

1328
00:39:44,400 --> 00:39:45,839
keep moving forward

1329
00:39:45,839 --> 00:39:48,079
uh with with various other innovations

1330
00:39:48,079 --> 00:39:49,280
that kind of come within the threat

1331
00:39:49,280 --> 00:39:50,079
modding space

1332
00:39:50,079 --> 00:39:51,440
we're kind of hoping that the initial

1333
00:39:51,440 --> 00:39:53,119
orange kind of kind of

1334
00:39:53,119 --> 00:39:56,079
wreaks its way through uh other phases

1335
00:39:56,079 --> 00:39:57,599
of product engineering as well because

1336
00:39:57,599 --> 00:39:59,119
that's really the dream for us to kind

1337
00:39:59,119 --> 00:40:00,640
of look at threat modeling as

1338
00:40:00,640 --> 00:40:02,960
a multiple outcome driven engagement and

1339
00:40:02,960 --> 00:40:04,800
not just a singular outcome

1340
00:40:04,800 --> 00:40:07,359
that maps to a particular persona in

1341
00:40:07,359 --> 00:40:10,160
product engineering and that's really

1342
00:40:10,160 --> 00:40:13,200
very kind of looking to kind of take the

1343
00:40:13,200 --> 00:40:14,640
whole threat modeling experience if you

1344
00:40:14,640 --> 00:40:16,240
will from that perspective

1345
00:40:16,240 --> 00:40:18,800
so in summary uh what we're going to

1346
00:40:18,800 --> 00:40:20,000
look at to what we

1347
00:40:20,000 --> 00:40:22,720
what we hope uh that we're going to that

1348
00:40:22,720 --> 00:40:25,200
you take away today is

1349
00:40:25,200 --> 00:40:28,480
look at what works for you the best

1350
00:40:28,480 --> 00:40:30,160
there is no one-size-fits-all as

1351
00:40:30,160 --> 00:40:31,760
first-rate modeling concern

1352
00:40:31,760 --> 00:40:33,599
understand what your motivations are

1353
00:40:33,599 --> 00:40:35,119
understand why you're doing threat

1354
00:40:35,119 --> 00:40:35,760
modeling

1355
00:40:35,760 --> 00:40:37,280
and then it doesn't have to be complex

1356
00:40:37,280 --> 00:40:39,280
it could be something very very

1357
00:40:39,280 --> 00:40:41,000
native it could be something that

1358
00:40:41,000 --> 00:40:43,040
extremely back of the paper

1359
00:40:43,040 --> 00:40:44,720
as long as that works for you we could

1360
00:40:44,720 --> 00:40:46,560
look at a way to kind of formalize that

1361
00:40:46,560 --> 00:40:48,400
in some shape or form

1362
00:40:48,400 --> 00:40:50,400
it's essential in enterprise segments

1363
00:40:50,400 --> 00:40:51,440
and that's one of the reasons you've

1364
00:40:51,440 --> 00:40:52,640
seen it fails is because

1365
00:40:52,640 --> 00:40:54,400
hey you might say hey rao this looks

1366
00:40:54,400 --> 00:40:56,640
good but i'm not a mom-and-pop uh

1367
00:40:56,640 --> 00:40:58,319
product engineering team i'm actually a

1368
00:40:58,319 --> 00:40:59,520
large enterprise

1369
00:40:59,520 --> 00:41:02,160
uh that runs thousands of applications

1370
00:41:02,160 --> 00:41:03,440
fair enough and that's the reason you

1371
00:41:03,440 --> 00:41:04,240
kind of look at

1372
00:41:04,240 --> 00:41:05,760
how can you do that balance between

1373
00:41:05,760 --> 00:41:07,599
depth and scale and that's what we've

1374
00:41:07,599 --> 00:41:08,160
seen

1375
00:41:08,160 --> 00:41:09,440
is you could use competent different

1376
00:41:09,440 --> 00:41:12,160
threat models for scale

1377
00:41:12,160 --> 00:41:14,240
use abusive driven threat models for

1378
00:41:14,240 --> 00:41:15,359
depth and

1379
00:41:15,359 --> 00:41:17,680
and have that healthy balance between

1380
00:41:17,680 --> 00:41:18,960
depth and scale that gives you the

1381
00:41:18,960 --> 00:41:20,480
efficiencies of both

1382
00:41:20,480 --> 00:41:22,400
um it's it's important for us to make

1383
00:41:22,400 --> 00:41:24,480
threat modeling more accessible

1384
00:41:24,480 --> 00:41:26,640
and by accessible i mean make threat

1385
00:41:26,640 --> 00:41:28,640
modeling that's more adaptable

1386
00:41:28,640 --> 00:41:30,720
across multiple personas in product

1387
00:41:30,720 --> 00:41:32,319
engineering there is something for

1388
00:41:32,319 --> 00:41:33,119
threat modeling

1389
00:41:33,119 --> 00:41:34,319
there is something for developers and

1390
00:41:34,319 --> 00:41:35,839
threat model there's absolutely

1391
00:41:35,839 --> 00:41:37,200
something for security engineering and

1392
00:41:37,200 --> 00:41:38,079
threat models

1393
00:41:38,079 --> 00:41:39,599
there is something for automation

1394
00:41:39,599 --> 00:41:41,359
engineers in threat model so it's all

1395
00:41:41,359 --> 00:41:43,520
about being able to kind of derive that

1396
00:41:43,520 --> 00:41:45,760
specific objective from each of these

1397
00:41:45,760 --> 00:41:47,200
personas so the more that you make

1398
00:41:47,200 --> 00:41:48,640
threat modeling accessible

1399
00:41:48,640 --> 00:41:51,599
it kind of creates that whole uh um just

1400
00:41:51,599 --> 00:41:52,720
like anything else you have a shared

1401
00:41:52,720 --> 00:41:54,480
responsibility model

1402
00:41:54,480 --> 00:41:56,000
within threat modeling as well so it

1403
00:41:56,000 --> 00:41:58,160
kind of just removes that whole front

1404
00:41:58,160 --> 00:41:59,680
ending of threat modeling to be just

1405
00:41:59,680 --> 00:42:01,280
residing with one particular

1406
00:42:01,280 --> 00:42:03,839
team like like security or architects

1407
00:42:03,839 --> 00:42:04,640
and kind of just

1408
00:42:04,640 --> 00:42:07,280
democratizes that within the whole

1409
00:42:07,280 --> 00:42:09,839
applicant security process

1410
00:42:09,839 --> 00:42:12,880
and then frequent threat modeling is not

1411
00:42:12,880 --> 00:42:14,160
something that you would need to start

1412
00:42:14,160 --> 00:42:16,240
off per sprint always you can kind of

1413
00:42:16,240 --> 00:42:17,200
use that in

1414
00:42:17,200 --> 00:42:19,440
in larger iterations uh so you kind of

1415
00:42:19,440 --> 00:42:20,800
start doing threat money you're doing

1416
00:42:20,800 --> 00:42:22,400
trip modeling once a year

1417
00:42:22,400 --> 00:42:23,680
try and see how you can make it just

1418
00:42:23,680 --> 00:42:25,680
twice a year and then we'll break it

1419
00:42:25,680 --> 00:42:27,040
down into more

1420
00:42:27,040 --> 00:42:29,040
granular forms so frequent threat

1421
00:42:29,040 --> 00:42:31,680
modeling can eventually be a per sprint

1422
00:42:31,680 --> 00:42:34,000
activity but doesn't have to start off

1423
00:42:34,000 --> 00:42:36,400
being at a per sprint activity but it's

1424
00:42:36,400 --> 00:42:37,599
it's that dream that you would still

1425
00:42:37,599 --> 00:42:39,520
want to go ahead and chase

1426
00:42:39,520 --> 00:42:42,480
and finally i think the win for threat

1427
00:42:42,480 --> 00:42:43,760
modeling wins in

1428
00:42:43,760 --> 00:42:46,400
appsec agile apsec is a combination of

1429
00:42:46,400 --> 00:42:48,160
it being incremental

1430
00:42:48,160 --> 00:42:50,240
it being consistent and finally also

1431
00:42:50,240 --> 00:42:52,079
being able to have that collaborative

1432
00:42:52,079 --> 00:42:52,880
effort

1433
00:42:52,880 --> 00:42:55,680
of uh of of multiple people joining in

1434
00:42:55,680 --> 00:42:56,319
hands

1435
00:42:56,319 --> 00:42:59,040
uh for this particular activity so with

1436
00:42:59,040 --> 00:42:59,520
that

1437
00:42:59,520 --> 00:43:02,160
um we come to the end of our

1438
00:43:02,160 --> 00:43:03,920
presentation today

1439
00:43:03,920 --> 00:43:08,000
i hope you had a valuable takeaways

1440
00:43:08,000 --> 00:43:09,599
feel free to kind of pop in your

1441
00:43:09,599 --> 00:43:12,240
questions uh um

1442
00:43:12,240 --> 00:43:14,079
on the chat window if you've not done so

1443
00:43:14,079 --> 00:43:16,319
happy to kind of take any questions um i

1444
00:43:16,319 --> 00:43:17,359
know this is

1445
00:43:17,359 --> 00:43:19,599
quite controversial in terms of its

1446
00:43:19,599 --> 00:43:20,880
adaptability and it's kind of

1447
00:43:20,880 --> 00:43:21,920
applicability that's what i'm kind of

1448
00:43:21,920 --> 00:43:23,440
gunning for because it's not something i

1449
00:43:23,440 --> 00:43:24,000
always

1450
00:43:24,000 --> 00:43:26,319
like to kind of throw a cog um in in the

1451
00:43:26,319 --> 00:43:27,920
wheel so i hopefully have done that in

1452
00:43:27,920 --> 00:43:29,119
today's presentation

1453
00:43:29,119 --> 00:43:30,560
um and look forward to kind of answering

1454
00:43:30,560 --> 00:43:32,480
your questions and again

1455
00:43:32,480 --> 00:43:41,839
wonderful to be part of uh desagon24

