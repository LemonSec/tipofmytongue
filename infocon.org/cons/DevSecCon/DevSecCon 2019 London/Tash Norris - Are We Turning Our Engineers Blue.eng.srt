1
00:00:01,830 --> 00:00:02,870
[Applause]

2
00:00:02,870 --> 00:00:05,210
[Music]

3
00:00:05,210 --> 00:00:07,770
all right I'm gonna be talking about

4
00:00:07,770 --> 00:00:09,570
whether we turn our engineer's blue

5
00:00:09,570 --> 00:00:11,670
that's right it's a blue team talk and

6
00:00:11,670 --> 00:00:13,559
but I'm also gonna talk a little bit

7
00:00:13,559 --> 00:00:15,870
about how we make everyone sad all of

8
00:00:15,870 --> 00:00:18,810
the time for those of you that were at

9
00:00:18,810 --> 00:00:21,539
the panel yesterday afternoon you may

10
00:00:21,539 --> 00:00:23,970
hear some snippets that sound familiar

11
00:00:23,970 --> 00:00:26,490
to you I'm hoping not to really repeat

12
00:00:26,490 --> 00:00:27,990
anything but otherwise just give a

13
00:00:27,990 --> 00:00:29,849
little bit more detail and a little bit

14
00:00:29,849 --> 00:00:33,540
more context before I start I'm gonna

15
00:00:33,540 --> 00:00:35,219
talk a lot about our delivery teams and

16
00:00:35,219 --> 00:00:36,870
our engineers but I want to take a

17
00:00:36,870 --> 00:00:38,430
moment to ask you all to have some

18
00:00:38,430 --> 00:00:40,950
empathy for our teams and if you are

19
00:00:40,950 --> 00:00:43,200
here and you're a developer or in your

20
00:00:43,200 --> 00:00:44,520
operations I want to ask you to have

21
00:00:44,520 --> 00:00:46,640
some empathy for our security teams

22
00:00:46,640 --> 00:00:48,870
originally in our careers we were quite

23
00:00:48,870 --> 00:00:50,940
siloed whether you're a developer or a

24
00:00:50,940 --> 00:00:53,489
security person you're a DBA a front-end

25
00:00:53,489 --> 00:00:56,370
engineer you were a security architect

26
00:00:56,370 --> 00:00:58,530
focusing on a specific point and then

27
00:00:58,530 --> 00:01:01,020
all of a sudden we've been expected to

28
00:01:01,020 --> 00:01:03,049
become a mile wide and a mile deep

29
00:01:03,049 --> 00:01:05,188
engineers are configuring docker

30
00:01:05,188 --> 00:01:07,530
containers kubernetes clusters they're

31
00:01:07,530 --> 00:01:09,240
expected to know about network protocols

32
00:01:09,240 --> 00:01:11,640
how to properly configure databases as

33
00:01:11,640 --> 00:01:13,920
security engineers we're expected to

34
00:01:13,920 --> 00:01:16,470
know about a vast range of technologies

35
00:01:16,470 --> 00:01:19,259
and it happened like that and so I'm

36
00:01:19,259 --> 00:01:21,240
gonna talk about things that I've seen

37
00:01:21,240 --> 00:01:24,390
so far whilst working both in big

38
00:01:24,390 --> 00:01:25,979
financial services and small companies

39
00:01:25,979 --> 00:01:28,470
that have helped me along the way to

40
00:01:28,470 --> 00:01:31,079
create blue team's but alongside all of

41
00:01:31,079 --> 00:01:33,150
that is an element of empathy for our

42
00:01:33,150 --> 00:01:37,049
peers so quick intro about me I work for

43
00:01:37,049 --> 00:01:39,600
moon pick and it's about 300 people

44
00:01:39,600 --> 00:01:42,150
total at moon pick and before moon pick

45
00:01:42,150 --> 00:01:43,799
I was at Capital One working for their

46
00:01:43,799 --> 00:01:46,229
US bank function of which I think

47
00:01:46,229 --> 00:01:48,420
there's 40,000 employees it was you know

48
00:01:48,420 --> 00:01:51,720
a big difference for me in between that

49
00:01:51,720 --> 00:01:54,299
moon pig were owned by photo box group

50
00:01:54,299 --> 00:01:55,530
and many of you might have known my

51
00:01:55,530 --> 00:01:57,960
previously so Dennis Cruz who I've

52
00:01:57,960 --> 00:02:00,509
learned an amazing amount from and so I

53
00:02:00,509 --> 00:02:02,070
kind of gradually made this transition

54
00:02:02,070 --> 00:02:05,399
from huge conglomerate enterprise

55
00:02:05,399 --> 00:02:08,239
function with an insane budget to a

56
00:02:08,239 --> 00:02:11,250
moontak security team whereby it what

57
00:02:11,250 --> 00:02:12,780
can you do for free

58
00:02:12,780 --> 00:02:14,010
imagine is something we can all relate

59
00:02:14,010 --> 00:02:16,709
to I'm one of the co-founders for OS

60
00:02:16,709 --> 00:02:19,500
quia London and we call it we are London

61
00:02:19,500 --> 00:02:21,750
but it's a space in which we try and

62
00:02:21,750 --> 00:02:24,750
create an inclusive and welcoming apps

63
00:02:24,750 --> 00:02:26,310
tech area where you can go and you can

64
00:02:26,310 --> 00:02:28,920
learn and you can speak so especially

65
00:02:28,920 --> 00:02:29,790
for those of you that might be

66
00:02:29,790 --> 00:02:31,830
first-time speakers and want to come up

67
00:02:31,830 --> 00:02:33,209
here and talk next year of which I'd

68
00:02:33,209 --> 00:02:35,550
encourage you to do and do you reach out

69
00:02:35,550 --> 00:02:36,840
to me because we're always looking for

70
00:02:36,840 --> 00:02:39,150
speakers that we London and the last

71
00:02:39,150 --> 00:02:40,410
thing I want to mention before I kick

72
00:02:40,410 --> 00:02:43,080
off and I'd be remiss if I didn't

73
00:02:43,080 --> 00:02:44,220
mention it when I have such a great

74
00:02:44,220 --> 00:02:46,650
platform is that there are so many ways

75
00:02:46,650 --> 00:02:48,330
as security folks that we can use our

76
00:02:48,330 --> 00:02:50,570
skills to contribute back to open source

77
00:02:50,570 --> 00:02:53,430
projects and especially for those of you

78
00:02:53,430 --> 00:02:56,910
that are perhaps non developers that

79
00:02:56,910 --> 00:02:58,620
don't consider yourselves as an engineer

80
00:02:58,620 --> 00:03:00,630
you can do some really cool and neat

81
00:03:00,630 --> 00:03:02,640
things with your skills everything from

82
00:03:02,640 --> 00:03:04,769
doing security reviews of open source

83
00:03:04,769 --> 00:03:06,450
projects all the way through to giving

84
00:03:06,450 --> 00:03:09,060
advice and guidance to teams and more

85
00:03:09,060 --> 00:03:10,680
recently I've been applying security

86
00:03:10,680 --> 00:03:13,110
principles outside of tech altogether

87
00:03:13,110 --> 00:03:15,209
and I've been working on a project to

88
00:03:15,209 --> 00:03:18,750
use data around poachers in African game

89
00:03:18,750 --> 00:03:21,930
reserves to try and defer poachers and

90
00:03:21,930 --> 00:03:24,989
try and properly Zone in on where I poke

91
00:03:24,989 --> 00:03:26,880
where our game Rangers should be and

92
00:03:26,880 --> 00:03:28,230
we've been doing that using threat

93
00:03:28,230 --> 00:03:30,420
modeling principles so we've been taking

94
00:03:30,420 --> 00:03:32,610
data about the weather road conditions

95
00:03:32,610 --> 00:03:35,370
animal migration audio from gunshots

96
00:03:35,370 --> 00:03:37,310
using a whole load of low-tech

97
00:03:37,310 --> 00:03:39,540
capabilities to then use our threat

98
00:03:39,540 --> 00:03:41,010
modeling skills what are we doing what

99
00:03:41,010 --> 00:03:42,900
can go wrong what can we do about it to

100
00:03:42,900 --> 00:03:45,000
tell our game keepers where to go so

101
00:03:45,000 --> 00:03:47,190
that we can better utilize the tech that

102
00:03:47,190 --> 00:03:48,959
we have to protect against poachers and

103
00:03:48,959 --> 00:03:51,150
so there's so many great ways you can

104
00:03:51,150 --> 00:03:52,890
use your skills and I'd really encourage

105
00:03:52,890 --> 00:03:55,560
you to do so right onto the blue teen

106
00:03:55,560 --> 00:03:59,459
stuff so I'm gonna cover up a huge range

107
00:03:59,459 --> 00:04:01,890
of things the things I'm gonna cover our

108
00:04:01,890 --> 00:04:05,730
all open source or ideation or or free

109
00:04:05,730 --> 00:04:07,739
things that I do there's a load of great

110
00:04:07,739 --> 00:04:10,440
products and but everything I cover off

111
00:04:10,440 --> 00:04:12,090
is free and so I'm not gonna mention any

112
00:04:12,090 --> 00:04:15,090
vendors if I can help it I'm I'm gonna

113
00:04:15,090 --> 00:04:16,228
cover up a load of things that work for

114
00:04:16,228 --> 00:04:19,560
me I'm also to be true to my own ethics

115
00:04:19,560 --> 00:04:21,238
gonna show you one thing that didn't

116
00:04:21,238 --> 00:04:22,650
work for me because I think it's always

117
00:04:22,650 --> 00:04:24,780
fair to show you where I failed

118
00:04:24,780 --> 00:04:26,520
and but hopefully you'll find it funny

119
00:04:26,520 --> 00:04:29,430
and inspirational at the same time at

120
00:04:29,430 --> 00:04:30,690
least if I need to make me feel a little

121
00:04:30,690 --> 00:04:32,610
bit better so the first thing is

122
00:04:32,610 --> 00:04:33,600
security champions

123
00:04:33,600 --> 00:04:35,820
so Dennis Cruz who I mentioned earlier

124
00:04:35,820 --> 00:04:37,170
has an amazing talk and security

125
00:04:37,170 --> 00:04:39,210
champions and so what I'm gonna really

126
00:04:39,210 --> 00:04:41,130
do is cover off a little bit in

127
00:04:41,130 --> 00:04:43,260
complementary to that and but security

128
00:04:43,260 --> 00:04:44,490
champions are what I like to call my

129
00:04:44,490 --> 00:04:45,900
security pyramid scheme

130
00:04:45,900 --> 00:04:49,350
so all my Ponzi scheme and as I

131
00:04:49,350 --> 00:04:51,300
mentioned I'm in a very small team and

132
00:04:51,300 --> 00:04:54,270
so I can't be everywhere at once and so

133
00:04:54,270 --> 00:04:56,370
the way I utilize security champions are

134
00:04:56,370 --> 00:04:58,850
to be my extended team and so I

135
00:04:58,850 --> 00:05:02,040
purposely put in probably more time than

136
00:05:02,040 --> 00:05:04,320
maybe someone else would into our

137
00:05:04,320 --> 00:05:06,060
security champions so that they can be

138
00:05:06,060 --> 00:05:08,070
our extended team but they don't come

139
00:05:08,070 --> 00:05:11,190
out of our budget which is super and so

140
00:05:11,190 --> 00:05:12,900
that they can help move that along and

141
00:05:12,900 --> 00:05:14,550
the biggest way that we've done that is

142
00:05:14,550 --> 00:05:16,560
we have an engineering operating model

143
00:05:16,560 --> 00:05:19,230
at moon pick a way of working as such of

144
00:05:19,230 --> 00:05:21,240
our engineering teams and security has

145
00:05:21,240 --> 00:05:22,890
been become a huge part of that

146
00:05:22,890 --> 00:05:25,320
operating model and then equally things

147
00:05:25,320 --> 00:05:28,110
like time to resolve vulnerabilities has

148
00:05:28,110 --> 00:05:30,960
become part of those teams KPIs so we've

149
00:05:30,960 --> 00:05:33,990
started to embed it in culture and both

150
00:05:33,990 --> 00:05:35,910
with the support of leadership team and

151
00:05:35,910 --> 00:05:37,890
with the engineers themselves and that's

152
00:05:37,890 --> 00:05:39,780
been a huge benefit in getting security

153
00:05:39,780 --> 00:05:42,570
champions to work we've also done a load

154
00:05:42,570 --> 00:05:44,820
of stuff around specific training for

155
00:05:44,820 --> 00:05:46,680
our security champions we tried to gain

156
00:05:46,680 --> 00:05:50,190
a fire and we've done hackathons and

157
00:05:50,190 --> 00:05:52,620
capture the flags we've done bug bashes

158
00:05:52,620 --> 00:05:55,919
and there was a point in time during the

159
00:05:55,919 --> 00:05:58,410
moon pick and photobooks split where we

160
00:05:58,410 --> 00:05:59,640
got a couple of engineers from both

161
00:05:59,640 --> 00:06:01,620
teams and we got moon pick engineers to

162
00:06:01,620 --> 00:06:03,360
try and hack the photo box website and

163
00:06:03,360 --> 00:06:05,130
photo box engine is try and hack the

164
00:06:05,130 --> 00:06:07,380
moon pic website which is a really good

165
00:06:07,380 --> 00:06:09,810
fun way of gamifying and it's something

166
00:06:09,810 --> 00:06:11,760
I'd encourage you to think about in your

167
00:06:11,760 --> 00:06:13,260
test environments is getting different

168
00:06:13,260 --> 00:06:15,840
services teams to try and get each other

169
00:06:15,840 --> 00:06:17,910
stuff the reason it's so good is because

170
00:06:17,910 --> 00:06:19,200
they'll have their own idea of

171
00:06:19,200 --> 00:06:21,600
vulnerabilities they have and so they'll

172
00:06:21,600 --> 00:06:23,610
try the same exploits against each other

173
00:06:23,610 --> 00:06:25,919
and it's been a really good way for us

174
00:06:25,919 --> 00:06:28,169
to validate validate some of the

175
00:06:28,169 --> 00:06:29,460
assumptions we had about from our

176
00:06:29,460 --> 00:06:31,830
abilities with teams the other way we've

177
00:06:31,830 --> 00:06:33,180
done this is we started to work with

178
00:06:33,180 --> 00:06:34,700
engineers to create pattern

179
00:06:34,700 --> 00:06:37,040
so what we've done is every time someone

180
00:06:37,040 --> 00:06:39,620
asks us a question or they've asked us

181
00:06:39,620 --> 00:06:41,960
for support on a security topic is we've

182
00:06:41,960 --> 00:06:43,730
used that as a chance to create a wiki

183
00:06:43,730 --> 00:06:46,970
or a patent and architecture patent and

184
00:06:46,970 --> 00:06:48,200
we've built that up with them and then

185
00:06:48,200 --> 00:06:50,420
made it consumable the idea is that

186
00:06:50,420 --> 00:06:52,190
answer a question once that answer it

187
00:06:52,190 --> 00:06:54,770
well but then also be open to iterating

188
00:06:54,770 --> 00:06:57,020
over it continuously continuous

189
00:06:57,020 --> 00:07:00,500
improvement okay so the other thing that

190
00:07:00,500 --> 00:07:01,730
we've been building a lot of a

191
00:07:01,730 --> 00:07:05,090
hand-to-mouth resources so again a small

192
00:07:05,090 --> 00:07:07,010
small team not many security people and

193
00:07:07,010 --> 00:07:09,800
the idea of this is we want there to be

194
00:07:09,800 --> 00:07:11,300
a way for engineers to be able to

195
00:07:11,300 --> 00:07:12,980
quickly consume the answers they want

196
00:07:12,980 --> 00:07:15,800
but also for our wider impact team our

197
00:07:15,800 --> 00:07:19,130
marketing team our c-level admins how to

198
00:07:19,130 --> 00:07:21,740
quickly make easily consumable guidance

199
00:07:21,740 --> 00:07:23,660
and so fishing has been a huge thing for

200
00:07:23,660 --> 00:07:25,760
us some of you might have seen the NCSC

201
00:07:25,760 --> 00:07:28,400
guidance recently on the huge increase

202
00:07:28,400 --> 00:07:30,200
in phishing scams both targeted

203
00:07:30,200 --> 00:07:33,110
individuals and businesses and so we did

204
00:07:33,110 --> 00:07:35,990
some really quick simple super simple

205
00:07:35,990 --> 00:07:37,010
because I'm not a designer

206
00:07:37,010 --> 00:07:39,920
I'm infographics for our teams to see

207
00:07:39,920 --> 00:07:41,360
and we just put these in slack channels

208
00:07:41,360 --> 00:07:43,610
and pinned them and we printed them and

209
00:07:43,610 --> 00:07:44,840
put them around the office and again

210
00:07:44,840 --> 00:07:46,750
they were really simple quick ways to

211
00:07:46,750 --> 00:07:49,670
get teams thinking about it the other

212
00:07:49,670 --> 00:07:51,260
thing we've started to do is we start to

213
00:07:51,260 --> 00:07:53,900
create some of these on top tips for

214
00:07:53,900 --> 00:07:56,000
securing your kubernetes cluster and

215
00:07:56,000 --> 00:07:59,930
quick and easy quick and easy consumable

216
00:07:59,930 --> 00:08:02,450
infographics we've also started create

217
00:08:02,450 --> 00:08:03,740
those wikis so I mentioned about

218
00:08:03,740 --> 00:08:05,540
security patterns but every time you

219
00:08:05,540 --> 00:08:07,010
answer a question we're creating a wiki

220
00:08:07,010 --> 00:08:10,190
as well and we are using them a mixture

221
00:08:10,190 --> 00:08:11,450
and we're trying to decide where they

222
00:08:11,450 --> 00:08:13,520
sit if it's confluence or github pages

223
00:08:13,520 --> 00:08:16,340
and I said I would talk about free

224
00:08:16,340 --> 00:08:18,050
tooling so github is a great place to

225
00:08:18,050 --> 00:08:20,270
store them but quick checklists and

226
00:08:20,270 --> 00:08:21,950
wiki's and again it's where teams are

227
00:08:21,950 --> 00:08:23,540
starting to adopt certain technologies

228
00:08:23,540 --> 00:08:25,520
they can go somewhere and quickly go

229
00:08:25,520 --> 00:08:27,080
okay what's the right thing to do about

230
00:08:27,080 --> 00:08:29,810
securing my API or using Postgres

231
00:08:29,810 --> 00:08:31,640
databases or building with lambda

232
00:08:31,640 --> 00:08:34,190
functions whatever it might be and we've

233
00:08:34,190 --> 00:08:37,340
also started doing a mas and I was

234
00:08:37,340 --> 00:08:39,679
definitely inspired by Reddit on this

235
00:08:39,679 --> 00:08:42,039
but the idea was to have

236
00:08:42,039 --> 00:08:43,539
slack channel where people can ask us

237
00:08:43,539 --> 00:08:45,330
anything but also having the ability to

238
00:08:45,330 --> 00:08:48,750
consume anonymous questions using slider

239
00:08:48,750 --> 00:08:50,950
there's always an element of risk so I

240
00:08:50,950 --> 00:08:52,480
recommend not putting it on a screen

241
00:08:52,480 --> 00:08:55,630
behind you I am but the idea was that

242
00:08:55,630 --> 00:08:57,040
teams could ask those questions without

243
00:08:57,040 --> 00:08:59,680
fear of throwing their service under the

244
00:08:59,680 --> 00:09:03,280
bus as it were or really holding the

245
00:09:03,280 --> 00:09:04,990
security team accountable for what they

246
00:09:04,990 --> 00:09:08,260
felt they were or weren't doing well or

247
00:09:08,260 --> 00:09:10,330
at all and so they could get some

248
00:09:10,330 --> 00:09:12,790
feedback to us quickly and so doing a

249
00:09:12,790 --> 00:09:14,260
mas and open door sessions have been

250
00:09:14,260 --> 00:09:17,320
really helpful for us okay under the

251
00:09:17,320 --> 00:09:20,050
good stuff this is Tim and this is my

252
00:09:20,050 --> 00:09:22,600
husband he said I could put a picture on

253
00:09:22,600 --> 00:09:25,810
of him if people couldn't see his face

254
00:09:25,810 --> 00:09:29,020
challenge accepted and I've been doing

255
00:09:29,020 --> 00:09:30,220
threat modeling for a little while now

256
00:09:30,220 --> 00:09:31,450
and those of you that have heard me talk

257
00:09:31,450 --> 00:09:34,120
before or have seen me at meetups

258
00:09:34,120 --> 00:09:36,910
I love threat modeling it's a very

259
00:09:36,910 --> 00:09:39,910
creative way I feel of trying to work

260
00:09:39,910 --> 00:09:40,960
out all the things that can go wrong

261
00:09:40,960 --> 00:09:43,780
with something and so it became very

262
00:09:43,780 --> 00:09:45,790
natural for me to threat model I feel

263
00:09:45,790 --> 00:09:47,110
like I'm always thinking about things

264
00:09:47,110 --> 00:09:49,660
that can go wrong and a great example

265
00:09:49,660 --> 00:09:51,760
for me is that when Tim wanted to

266
00:09:51,760 --> 00:09:54,700
propose we were on our way on holiday we

267
00:09:54,700 --> 00:09:56,230
were going to I'm South Africa and we

268
00:09:56,230 --> 00:09:58,210
were at the airport in London London

269
00:09:58,210 --> 00:10:01,060
Heathrow and he was getting a bit

270
00:10:01,060 --> 00:10:02,800
flustered and a bit sweaty before we got

271
00:10:02,800 --> 00:10:04,960
to security and I couldn't really work

272
00:10:04,960 --> 00:10:06,790
out why and I'm like we're going on a

273
00:10:06,790 --> 00:10:08,830
holiday and he was just like oh my god

274
00:10:08,830 --> 00:10:10,060
we've got go through security and I'm

275
00:10:10,060 --> 00:10:12,910
like relax and he looked at me and said

276
00:10:12,910 --> 00:10:14,860
I'll race ya and I'm very competitive

277
00:10:14,860 --> 00:10:18,310
and so I just left him at airport

278
00:10:18,310 --> 00:10:20,740
security and just kind of ran but also

279
00:10:20,740 --> 00:10:21,820
walked because I didn't want to get

280
00:10:21,820 --> 00:10:23,320
stuck by only one think and I looked a

281
00:10:23,320 --> 00:10:25,180
bit suspicious as far away from him as

282
00:10:25,180 --> 00:10:27,100
possible so that could find the right

283
00:10:27,100 --> 00:10:29,110
cue to get through whether it was known

284
00:10:29,110 --> 00:10:30,790
with pushchairs in front of me no one

285
00:10:30,790 --> 00:10:32,770
with big boots anyone that was going to

286
00:10:32,770 --> 00:10:34,360
slow me down and start thinking about

287
00:10:34,360 --> 00:10:36,670
all the things that could go wrong that

288
00:10:36,670 --> 00:10:38,680
could stop me from winning from beating

289
00:10:38,680 --> 00:10:39,790
my husband and through airport security

290
00:10:39,790 --> 00:10:43,060
and at the same time for Tim he was

291
00:10:43,060 --> 00:10:44,440
thinking about all the things that could

292
00:10:44,440 --> 00:10:46,000
go wrong when he realised he had a ring

293
00:10:46,000 --> 00:10:47,650
box in his backpack and they were

294
00:10:47,650 --> 00:10:49,300
probably gonna ask him to open it so

295
00:10:49,300 --> 00:10:51,550
they could see inside and so he thought

296
00:10:51,550 --> 00:10:52,470
he was going to have to

297
00:10:52,470 --> 00:10:54,120
pose in the middle of Heathrow Terminal

298
00:10:54,120 --> 00:10:57,180
five and so he was thinking about all

299
00:10:57,180 --> 00:10:58,470
the things that could go wrong and we're

300
00:10:58,470 --> 00:10:59,940
both thinking okay what can we do about

301
00:10:59,940 --> 00:11:00,270
it

302
00:11:00,270 --> 00:11:02,430
what can we mitigate in this solution

303
00:11:02,430 --> 00:11:04,410
long story short we both got three

304
00:11:04,410 --> 00:11:06,630
successfully he didn't have to propose

305
00:11:06,630 --> 00:11:08,400
next to an old man put in his trainers

306
00:11:08,400 --> 00:11:10,920
back on and we did get engaged later on

307
00:11:10,920 --> 00:11:12,690
in the holiday but for me it was a way

308
00:11:12,690 --> 00:11:14,790
of kind of reaffirming that in many life

309
00:11:14,790 --> 00:11:16,260
situations are always thinking about

310
00:11:16,260 --> 00:11:18,750
what we're doing what can go wrong what

311
00:11:18,750 --> 00:11:19,800
can we do about it

312
00:11:19,800 --> 00:11:21,390
and how do we make sure we do a good job

313
00:11:21,390 --> 00:11:23,070
and there's a whole load of frameworks

314
00:11:23,070 --> 00:11:25,320
that support this and I'm gonna touch on

315
00:11:25,320 --> 00:11:27,120
this only very lightly because I want to

316
00:11:27,120 --> 00:11:28,560
tell you a better story about how I'm

317
00:11:28,560 --> 00:11:30,000
applying threat modeling and what I'm

318
00:11:30,000 --> 00:11:30,930
doing about it

319
00:11:30,930 --> 00:11:33,270
and but these are just a few resources

320
00:11:33,270 --> 00:11:35,130
and specifically I want to point you

321
00:11:35,130 --> 00:11:36,570
through to some talks and I'll make sure

322
00:11:36,570 --> 00:11:38,730
these slides are available but there are

323
00:11:38,730 --> 00:11:40,440
so many people that do some really great

324
00:11:40,440 --> 00:11:43,200
talks on these and then arias risk out

325
00:11:43,200 --> 00:11:44,720
and the hallway have a free newsletter

326
00:11:44,720 --> 00:11:47,790
they do they always put points you to

327
00:11:47,790 --> 00:11:49,920
the latest talk and that they've seen

328
00:11:49,920 --> 00:11:52,800
and it's very good okay so I think about

329
00:11:52,800 --> 00:11:54,000
threat modeling and I think about all

330
00:11:54,000 --> 00:11:56,580
the ways that I can apply it and one of

331
00:11:56,580 --> 00:11:58,020
the things that I got really excited

332
00:11:58,020 --> 00:12:01,200
about was this idea of we do a threat

333
00:12:01,200 --> 00:12:02,280
model we come up with all these

334
00:12:02,280 --> 00:12:05,040
vulnerabilities relate to a service and

335
00:12:05,040 --> 00:12:06,390
these vulnerabilities are only true

336
00:12:06,390 --> 00:12:07,590
because there's a specific

337
00:12:07,590 --> 00:12:10,170
characteristic in your service and so I

338
00:12:10,170 --> 00:12:12,450
started to think about how if I have

339
00:12:12,450 --> 00:12:15,030
these vulnerabilities then perhaps I can

340
00:12:15,030 --> 00:12:16,680
start to say well they're always there

341
00:12:16,680 --> 00:12:19,080
because of these characteristics and if

342
00:12:19,080 --> 00:12:22,650
I can sanitize ever so slightly use my

343
00:12:22,650 --> 00:12:24,300
mobility so I don't tell everyone all

344
00:12:24,300 --> 00:12:26,040
the ways in which to hack me and pick

345
00:12:26,040 --> 00:12:28,500
then maybe I can create a service where

346
00:12:28,500 --> 00:12:31,320
I can just pull in different services or

347
00:12:31,320 --> 00:12:34,020
different tools or technologies and it

348
00:12:34,020 --> 00:12:36,120
will auto-populate from abilities for me

349
00:12:36,120 --> 00:12:38,370
so I got kind of excited about this and

350
00:12:38,370 --> 00:12:40,290
I thought I'm gonna try and build it and

351
00:12:40,290 --> 00:12:42,900
so I thought this is going to be a great

352
00:12:42,900 --> 00:12:45,570
complementary tool to SAST and DAST of

353
00:12:45,570 --> 00:12:49,080
which i am not a fan and the idea is

354
00:12:49,080 --> 00:12:50,670
that you can do this as early on in your

355
00:12:50,670 --> 00:12:53,490
design process as possible and then use

356
00:12:53,490 --> 00:12:56,310
it to drive decisions on how you build

357
00:12:56,310 --> 00:12:58,620
your tool and how you progress with your

358
00:12:58,620 --> 00:13:00,420
service what design route you go down

359
00:13:00,420 --> 00:13:02,160
when you come up with a new service and

360
00:13:02,160 --> 00:13:03,300
so I started to think about how I would

361
00:13:03,300 --> 00:13:04,180
build it

362
00:13:04,180 --> 00:13:06,610
and I am gonna talk briefly about JIRA

363
00:13:06,610 --> 00:13:08,920
so forgive me but I did work for Dennis

364
00:13:08,920 --> 00:13:11,530
for a long time he loved to do it and so

365
00:13:11,530 --> 00:13:13,300
this is where we store the information

366
00:13:13,300 --> 00:13:15,010
about vulnerabilities and what would

367
00:13:15,010 --> 00:13:17,950
happen is we had specific workflows we

368
00:13:17,950 --> 00:13:20,560
took every vulnerability that we found

369
00:13:20,560 --> 00:13:23,170
and we put it in JIRA and we linked it

370
00:13:23,170 --> 00:13:25,840
IT assets and we linked it to risks and

371
00:13:25,840 --> 00:13:27,280
we had workflows for approvals we had

372
00:13:27,280 --> 00:13:29,260
lots of things but most importantly it

373
00:13:29,260 --> 00:13:32,110
was effectively a database it was a bit

374
00:13:32,110 --> 00:13:34,660
naughty to use it like like a graphical

375
00:13:34,660 --> 00:13:36,850
database but we did and so we put all of

376
00:13:36,850 --> 00:13:39,220
our abilities in there and then there is

377
00:13:39,220 --> 00:13:42,160
a an open source slack bar called OS but

378
00:13:42,160 --> 00:13:45,010
on the a wasp github that you can

379
00:13:45,010 --> 00:13:47,080
utilize and that takes data from JIRA or

380
00:13:47,080 --> 00:13:49,930
wherever your databases ships it off to

381
00:13:49,930 --> 00:13:52,270
elasticsearch and then we had a lambda

382
00:13:52,270 --> 00:13:54,220
function that we could use to query that

383
00:13:54,220 --> 00:13:55,960
data and elasticsearch and then spit it

384
00:13:55,960 --> 00:13:58,360
out back to slack and the idea was I

385
00:13:58,360 --> 00:13:59,860
could say hey slack show me all the

386
00:13:59,860 --> 00:14:03,310
vulnerabilities related to X I might and

387
00:14:03,310 --> 00:14:04,900
the reason that they built this with

388
00:14:04,900 --> 00:14:07,210
just to make risk a lot easier to talk

389
00:14:07,210 --> 00:14:09,070
about at photobooks well so we were

390
00:14:09,070 --> 00:14:11,800
there and so and I'm in pick two and so

391
00:14:11,800 --> 00:14:13,840
I thought maybe I can use this for like

392
00:14:13,840 --> 00:14:17,680
my precognitive Minority Report style

393
00:14:17,680 --> 00:14:19,810
threat modeling where I can just type in

394
00:14:19,810 --> 00:14:21,940
an ICS a or service and I can see all

395
00:14:21,940 --> 00:14:23,740
the vulnerabilities and so I got really

396
00:14:23,740 --> 00:14:26,590
excited about it and as you can see

397
00:14:26,590 --> 00:14:28,630
initially it didn't work super well and

398
00:14:28,630 --> 00:14:32,020
but it gave me an idea and the idea was

399
00:14:32,020 --> 00:14:34,540
well if I can see an IT asset and then I

400
00:14:34,540 --> 00:14:37,330
can see a load of vulnerabilities well I

401
00:14:37,330 --> 00:14:39,790
can also start to see is my mitigation

402
00:14:39,790 --> 00:14:41,920
options and whilst this isn't super

403
00:14:41,920 --> 00:14:44,530
useful like this when it gave me the

404
00:14:44,530 --> 00:14:46,660
idea of is that I could start to think

405
00:14:46,660 --> 00:14:48,880
about how to smartly go after the right

406
00:14:48,880 --> 00:14:50,560
from the right mitigation at the right

407
00:14:50,560 --> 00:14:53,110
time and one of the things that we had a

408
00:14:53,110 --> 00:14:54,550
problem with is we would get a whole

409
00:14:54,550 --> 00:14:56,110
list of vulnerabilities from a threat

410
00:14:56,110 --> 00:14:58,720
model from a pen test and we would give

411
00:14:58,720 --> 00:15:00,970
them a criticality critical high medium

412
00:15:00,970 --> 00:15:03,910
low but what we wouldn't do is say hey

413
00:15:03,910 --> 00:15:06,220
you've got this high and you've got this

414
00:15:06,220 --> 00:15:09,820
high all of these and you've got fixes

415
00:15:09,820 --> 00:15:11,230
and a t-shirt size of fixes but we

416
00:15:11,230 --> 00:15:12,850
wouldn't do is say if you did fix one

417
00:15:12,850 --> 00:15:15,370
that would fix one - but if you did fix

418
00:15:15,370 --> 00:15:16,960
two that would fix

419
00:15:16,960 --> 00:15:19,450
five high vulnerabilities and so we

420
00:15:19,450 --> 00:15:21,610
weren't smartly telling our engineers

421
00:15:21,610 --> 00:15:23,860
what to go after and the hope is always

422
00:15:23,860 --> 00:15:25,840
they'll fix every vulnerability but as

423
00:15:25,840 --> 00:15:27,550
we know they've got a limited amount of

424
00:15:27,550 --> 00:15:30,250
time and product owners love to risk it

425
00:15:30,250 --> 00:15:32,500
except stuff and so I started to think

426
00:15:32,500 --> 00:15:34,240
about how we could use this to drive the

427
00:15:34,240 --> 00:15:36,250
right decisions how to properly allocate

428
00:15:36,250 --> 00:15:38,050
resources and make sure we're fixing the

429
00:15:38,050 --> 00:15:38,890
right things at once

430
00:15:38,890 --> 00:15:41,950
and so I'm sad I think okay I can use

431
00:15:41,950 --> 00:15:45,400
this graphical database JIRA and I can

432
00:15:45,400 --> 00:15:47,320
use our slack but to start to give this

433
00:15:47,320 --> 00:15:49,060
information to engineers I just have to

434
00:15:49,060 --> 00:15:50,440
visualize it in the right way

435
00:15:50,440 --> 00:15:53,440
and so I experimented with it this is a

436
00:15:53,440 --> 00:15:55,330
taxonomy from Cissna it's a great

437
00:15:55,330 --> 00:15:57,670
taxonomy for threats but it's quite

438
00:15:57,670 --> 00:15:59,470
complex and so I thought I'm gonna start

439
00:15:59,470 --> 00:16:01,390
simple because already the graphs looked

440
00:16:01,390 --> 00:16:03,850
a bit confusing and they were a bit mad

441
00:16:03,850 --> 00:16:06,880
but incredibly useful probably one of

442
00:16:06,880 --> 00:16:09,090
the best taxonomy as I've seen for

443
00:16:09,090 --> 00:16:11,320
quantifying threats risk firmer

444
00:16:11,320 --> 00:16:14,200
abilities attack services and defects

445
00:16:14,200 --> 00:16:16,300
bugs flaws or what I pellet owners like

446
00:16:16,300 --> 00:16:19,750
to call features and and what I did is I

447
00:16:19,750 --> 00:16:22,030
created a slightly simpler version and

448
00:16:22,030 --> 00:16:23,260
you'll have to forgive there's a couple

449
00:16:23,260 --> 00:16:24,670
of pictures here from directly in my

450
00:16:24,670 --> 00:16:27,130
notebook because I'm just not a huge fan

451
00:16:27,130 --> 00:16:28,560
of lucidchart at the moment

452
00:16:28,560 --> 00:16:31,150
and what I did is I simplified it a

453
00:16:31,150 --> 00:16:32,590
little bit just to call out the things

454
00:16:32,590 --> 00:16:34,930
that I wanted to represent initially and

455
00:16:34,930 --> 00:16:36,690
I thought okay I'm gonna use this

456
00:16:36,690 --> 00:16:39,220
stacked all that Denis's built and I'm

457
00:16:39,220 --> 00:16:41,880
gonna start to create my Minority Report

458
00:16:41,880 --> 00:16:45,010
threat model and so I thought about what

459
00:16:45,010 --> 00:16:47,470
it could look like and I did a quick POC

460
00:16:47,470 --> 00:16:50,200
and I used plant UML just to demonstrate

461
00:16:50,200 --> 00:16:52,480
what it could be whilst I was kind of

462
00:16:52,480 --> 00:16:54,070
still pitching this idea to the team

463
00:16:54,070 --> 00:16:55,570
about because they still thought it was

464
00:16:55,570 --> 00:16:56,770
a little bit crazy when I started

465
00:16:56,770 --> 00:16:59,260
talking about Tom Cruise every day and I

466
00:16:59,260 --> 00:17:00,610
start to say hey you could pull in data

467
00:17:00,610 --> 00:17:03,520
from CV databases from your your

468
00:17:03,520 --> 00:17:06,099
security tooling from NCSC guidance

469
00:17:06,099 --> 00:17:08,709
whatever it is and from threat models

470
00:17:08,709 --> 00:17:09,819
and then you can start talking about

471
00:17:09,819 --> 00:17:11,680
mitigations and you can talk about how

472
00:17:11,680 --> 00:17:13,900
to go after the right mitigations and so

473
00:17:13,900 --> 00:17:16,990
we run it we use slack but we queried

474
00:17:16,990 --> 00:17:19,270
JIRA of which I put a lot of data into

475
00:17:19,270 --> 00:17:21,099
JIRA and I gave it a go

476
00:17:21,099 --> 00:17:24,940
and the first missile was this

477
00:17:24,940 --> 00:17:27,730
and which isn't totally useful that's

478
00:17:27,730 --> 00:17:29,230
fine this time because there's a whole

479
00:17:29,230 --> 00:17:30,880
load of libraries out there for

480
00:17:30,880 --> 00:17:32,350
visualizing the data that I'm getting so

481
00:17:32,350 --> 00:17:35,080
I'll just use a different library and it

482
00:17:35,080 --> 00:17:37,360
turned out like this I'm like that's

483
00:17:37,360 --> 00:17:39,310
okay because clearly there's too much

484
00:17:39,310 --> 00:17:40,420
data in there and then it's just not

485
00:17:40,420 --> 00:17:42,790
helpful if there's too much data so I

486
00:17:42,790 --> 00:17:44,650
reduce the scope of data and tried a

487
00:17:44,650 --> 00:17:47,350
different way of visualizing and I came

488
00:17:47,350 --> 00:17:49,660
up with this which is probably one of my

489
00:17:49,660 --> 00:17:53,800
more favorite ones and so for me I'm

490
00:17:53,800 --> 00:17:55,420
still on the journey of getting to my

491
00:17:55,420 --> 00:17:57,670
kind of precognitive way of visualizing

492
00:17:57,670 --> 00:18:00,670
threats and ultimately coming back to

493
00:18:00,670 --> 00:18:02,860
the impact I wanted to have that moon

494
00:18:02,860 --> 00:18:05,290
pick an out photo box was really just

495
00:18:05,290 --> 00:18:07,120
around driving the right fix at the

496
00:18:07,120 --> 00:18:10,090
right time and so I took a step back I

497
00:18:10,090 --> 00:18:12,400
went back to plant UML because then I

498
00:18:12,400 --> 00:18:14,440
can still do all of my diagrams as code

499
00:18:14,440 --> 00:18:16,000
and it can still be in get up and

500
00:18:16,000 --> 00:18:17,800
started to go back to the threat models

501
00:18:17,800 --> 00:18:18,940
that we were doing and making sure we

502
00:18:18,940 --> 00:18:20,350
were bringing in the right data at the

503
00:18:20,350 --> 00:18:22,990
right time and so I realized that if I

504
00:18:22,990 --> 00:18:25,600
use basic data I'm getting basic results

505
00:18:25,600 --> 00:18:27,520
and that it just wasn't the right way of

506
00:18:27,520 --> 00:18:29,110
clearing that information and that I

507
00:18:29,110 --> 00:18:31,510
needed to write some some better logic

508
00:18:31,510 --> 00:18:32,950
to make sure that I wasn't pulling in

509
00:18:32,950 --> 00:18:36,640
false positives or relevant data and so

510
00:18:36,640 --> 00:18:39,790
I parked it moved it towards what will

511
00:18:39,790 --> 00:18:41,680
be an open source project and said okay

512
00:18:41,680 --> 00:18:43,690
that's not the right thing for right now

513
00:18:43,690 --> 00:18:46,180
how else can I use threat modeling at me

514
00:18:46,180 --> 00:18:48,490
and picture drive impact as quickly as

515
00:18:48,490 --> 00:18:48,970
possible

516
00:18:48,970 --> 00:18:50,830
and so the thing that I want to talk

517
00:18:50,830 --> 00:18:51,940
about and what some of you might have

518
00:18:51,940 --> 00:18:53,590
seen from the synopsis of this talk is

519
00:18:53,590 --> 00:18:55,930
how I use threat modeling for incidents

520
00:18:55,930 --> 00:18:59,140
instead those who have known me for a

521
00:18:59,140 --> 00:19:00,880
while will know that I'm not a fan of

522
00:19:00,880 --> 00:19:02,860
attack trees I've kind of always thought

523
00:19:02,860 --> 00:19:04,450
they were elegant solutions to a problem

524
00:19:04,450 --> 00:19:07,450
that no one has until I found the

525
00:19:07,450 --> 00:19:10,240
problem at least for me and so I want to

526
00:19:10,240 --> 00:19:11,590
give you a really quick rundown of

527
00:19:11,590 --> 00:19:14,530
attack trees I've got a couple here and

528
00:19:14,530 --> 00:19:16,990
what attack tree is - is they follow the

529
00:19:16,990 --> 00:19:20,200
possible or impossible paths and they

530
00:19:20,200 --> 00:19:22,000
allow you to understand kind of the ways

531
00:19:22,000 --> 00:19:23,590
in which you would you would get into

532
00:19:23,590 --> 00:19:25,930
something and then we've got over here

533
00:19:25,930 --> 00:19:27,730
another way of doing it where you call

534
00:19:27,730 --> 00:19:30,160
out special equipment required or no

535
00:19:30,160 --> 00:19:32,110
special equipment required and the way I

536
00:19:32,110 --> 00:19:34,090
translate that to cyber is no special

537
00:19:34,090 --> 00:19:35,620
knowledge for example knowing how to

538
00:19:35,620 --> 00:19:37,840
craft the packet or the API request

539
00:19:37,840 --> 00:19:40,330
properly or whatever it might be and so

540
00:19:40,330 --> 00:19:42,640
I started to think about how we would

541
00:19:42,640 --> 00:19:44,909
use attack trees and one of the ways I

542
00:19:44,909 --> 00:19:47,500
start to investigate it was in incident

543
00:19:47,500 --> 00:19:49,570
response I mentioned we have a small

544
00:19:49,570 --> 00:19:51,549
team at moon pick the security team is

545
00:19:51,549 --> 00:19:53,740
it's just me at the moment that we are

546
00:19:53,740 --> 00:19:56,020
hiring and we still utilize the photo

547
00:19:56,020 --> 00:19:57,580
box security team of which there is an

548
00:19:57,580 --> 00:19:58,990
incident response team but it's very

549
00:19:58,990 --> 00:20:02,340
very small and so when we see responses

550
00:20:02,340 --> 00:20:05,169
they are required often the security

551
00:20:05,169 --> 00:20:08,049
engineering function support them and so

552
00:20:08,049 --> 00:20:10,240
what we decided to do was utilize that

553
00:20:10,240 --> 00:20:12,130
actress I'm gonna ask you to think of a

554
00:20:12,130 --> 00:20:15,340
an incident that you've had you can spin

555
00:20:15,340 --> 00:20:17,260
the incident wheel and pick many of them

556
00:20:17,260 --> 00:20:19,330
that are out there and some of the

557
00:20:19,330 --> 00:20:20,890
recent reports have shown us that

558
00:20:20,890 --> 00:20:23,049
fishing is still up there but

559
00:20:23,049 --> 00:20:25,450
effectively any incident can utilize

560
00:20:25,450 --> 00:20:26,770
attack trees if you're still trying to

561
00:20:26,770 --> 00:20:29,110
understand what happened and so what we

562
00:20:29,110 --> 00:20:31,360
started to do is we extended our

563
00:20:31,360 --> 00:20:32,740
incident response team for what we

564
00:20:32,740 --> 00:20:34,539
considered several incidents and we

565
00:20:34,539 --> 00:20:37,419
started to bring in as needed because we

566
00:20:37,419 --> 00:20:38,559
still want to be respectful of their

567
00:20:38,559 --> 00:20:40,990
time I rap SEC teams our engineering

568
00:20:40,990 --> 00:20:43,990
teams I stock analyst infrastructure

569
00:20:43,990 --> 00:20:45,220
engineers a whole range of people

570
00:20:45,220 --> 00:20:47,980
effectively everyone when you would use

571
00:20:47,980 --> 00:20:49,690
in a normal threat model when you still

572
00:20:49,690 --> 00:20:52,360
come up with a design for a product and

573
00:20:52,360 --> 00:20:55,210
so what we did during an incident is we

574
00:20:55,210 --> 00:20:56,740
start to think about okay what do we

575
00:20:56,740 --> 00:20:58,570
know about what's happened and sometimes

576
00:20:58,570 --> 00:21:00,940
that's very little information I've just

577
00:21:00,940 --> 00:21:04,120
got a blank diagram up here for some

578
00:21:04,120 --> 00:21:07,240
infrastructure but effectively you have

579
00:21:07,240 --> 00:21:08,320
an incident you're still trying to

580
00:21:08,320 --> 00:21:10,029
understand what happened all you really

581
00:21:10,029 --> 00:21:11,710
know is the bottom of that attack tree

582
00:21:11,710 --> 00:21:14,200
you just know the impact right you you

583
00:21:14,200 --> 00:21:18,070
know and I don't know your CloudFront

584
00:21:18,070 --> 00:21:21,520
subdomain it's been hijacked or you have

585
00:21:21,520 --> 00:21:23,710
had some data exposed to the internet or

586
00:21:23,710 --> 00:21:26,260
all you've had so far is maybe an email

587
00:21:26,260 --> 00:21:28,210
from a journalist saying we found some

588
00:21:28,210 --> 00:21:30,880
of your data online whatever it might be

589
00:21:30,880 --> 00:21:32,289
and so we start to think about what we

590
00:21:32,289 --> 00:21:34,659
know what we then decide to do with the

591
00:21:34,659 --> 00:21:37,779
TAT Ruiz is quantify all of the attack

592
00:21:37,779 --> 00:21:39,610
vectors that could have contributed to

593
00:21:39,610 --> 00:21:42,010
that incident so the idea is that your

594
00:21:42,010 --> 00:21:43,750
incident teams are still going through

595
00:21:43,750 --> 00:21:45,190
their play books they're still going

596
00:21:45,190 --> 00:21:47,289
through their root cause analysis but

597
00:21:47,289 --> 00:21:48,610
what we're doing is we relying on that

598
00:21:48,610 --> 00:21:49,059
extent

599
00:21:49,059 --> 00:21:50,620
knowledge of the app SEC teams the

600
00:21:50,620 --> 00:21:52,149
delivery teams to run through all the

601
00:21:52,149 --> 00:21:53,860
possible and impossible attack vectors

602
00:21:53,860 --> 00:21:56,620
and I'm gonna cover up why we should

603
00:21:56,620 --> 00:21:58,990
capture the impossible but the idea is

604
00:21:58,990 --> 00:22:01,059
that you would also go through your no

605
00:22:01,059 --> 00:22:03,070
special knowledge or no special

606
00:22:03,070 --> 00:22:06,159
equipment attack tree paths as well and

607
00:22:06,159 --> 00:22:08,200
the idea is to quickly or more quickly

608
00:22:08,200 --> 00:22:10,690
direct your stock analysts in to which

609
00:22:10,690 --> 00:22:12,039
route they should go to you when they're

610
00:22:12,039 --> 00:22:13,539
looking through their logs over there

611
00:22:13,539 --> 00:22:15,850
running their play books and so it's

612
00:22:15,850 --> 00:22:17,350
something we've used not in every

613
00:22:17,350 --> 00:22:19,059
incident I'll be honest but it's

614
00:22:19,059 --> 00:22:20,919
certainly an hour cevlar nice to have

615
00:22:20,919 --> 00:22:22,899
two incidents where we're still trying

616
00:22:22,899 --> 00:22:24,549
to understand what happened what caused

617
00:22:24,549 --> 00:22:27,009
this and interestingly I started to see

618
00:22:27,009 --> 00:22:28,720
some of our engineers use these in

619
00:22:28,720 --> 00:22:31,600
normal technical incidents as well so

620
00:22:31,600 --> 00:22:34,389
when they see sites go down or when

621
00:22:34,389 --> 00:22:36,940
they've seen an unusual amount of load

622
00:22:36,940 --> 00:22:38,679
for our kubernetes clusters whatever it

623
00:22:38,679 --> 00:22:40,869
might be we've started to see them run

624
00:22:40,869 --> 00:22:42,340
through all the various things that

625
00:22:42,340 --> 00:22:45,159
could have gone wrong even the what they

626
00:22:45,159 --> 00:22:47,409
might cover off is be impossible start

627
00:22:47,409 --> 00:22:48,759
to rule that out and then go through a

628
00:22:48,759 --> 00:22:50,950
que what's the most likely vector and

629
00:22:50,950 --> 00:22:52,629
then they use that to determine where

630
00:22:52,629 --> 00:22:53,919
they spend the most effort and

631
00:22:53,919 --> 00:22:56,980
investigating first I mentioned that I

632
00:22:56,980 --> 00:22:59,740
captured the impossible on here the

633
00:22:59,740 --> 00:23:02,049
reason I do that is it might be

634
00:23:02,049 --> 00:23:03,669
impossible at point in time because

635
00:23:03,669 --> 00:23:05,350
there's something you've implemented and

636
00:23:05,350 --> 00:23:07,720
but we all know as security Falco

637
00:23:07,720 --> 00:23:10,419
developers that fixes are often and

638
00:23:10,419 --> 00:23:13,499
removed in future releases to production

639
00:23:13,499 --> 00:23:16,629
and so we know that what's impossible

640
00:23:16,629 --> 00:23:18,970
now might not be impossible in the

641
00:23:18,970 --> 00:23:21,429
future and so moving on to some other

642
00:23:21,429 --> 00:23:23,200
tools and tricks that we've been giving

643
00:23:23,200 --> 00:23:24,909
our engineers to help make them a little

644
00:23:24,909 --> 00:23:27,429
bit more blue team is we started to use

645
00:23:27,429 --> 00:23:30,009
security tests and this is a snapshot

646
00:23:30,009 --> 00:23:32,080
from fraser Scott's own cloud security

647
00:23:32,080 --> 00:23:34,059
project which is an open source OS

648
00:23:34,059 --> 00:23:36,549
project but the idea of capturing the

649
00:23:36,549 --> 00:23:38,379
impossible in your attack tree is to

650
00:23:38,379 --> 00:23:40,809
start to quantify how do I know it's

651
00:23:40,809 --> 00:23:42,700
impossible and how do I continuously

652
00:23:42,700 --> 00:23:45,610
validate it's still impossible today to

653
00:23:45,610 --> 00:23:47,289
make sure that we're still protected and

654
00:23:47,289 --> 00:23:49,269
so writing security tests in any form

655
00:23:49,269 --> 00:23:52,330
whether it's BDD tests whether it's

656
00:23:52,330 --> 00:23:54,730
using the same languages and cucumber

657
00:23:54,730 --> 00:23:56,679
I'm down at the front here can talk

658
00:23:56,679 --> 00:23:58,299
about a load more about testing than I

659
00:23:58,299 --> 00:23:59,870
can as kind of list out

660
00:23:59,870 --> 00:24:02,690
yesterday but the idea is that you can

661
00:24:02,690 --> 00:24:04,370
continuously write tests to validate is

662
00:24:04,370 --> 00:24:06,770
that fixed or there and it's something I

663
00:24:06,770 --> 00:24:08,540
would encourage engineer's to do but I

664
00:24:08,540 --> 00:24:11,360
security teams to support them in one of

665
00:24:11,360 --> 00:24:13,010
the other things we've started to do and

666
00:24:13,010 --> 00:24:16,190
I talked about my pyramid scheme of our

667
00:24:16,190 --> 00:24:17,690
engineering deliveries to make that my

668
00:24:17,690 --> 00:24:20,030
extended security team is taking testing

669
00:24:20,030 --> 00:24:22,180
a bit further to upskill our teams and

670
00:24:22,180 --> 00:24:26,030
for more dynamic testing and so I

671
00:24:26,030 --> 00:24:28,400
started to look into test charters or

672
00:24:28,400 --> 00:24:31,250
explorative testing and the idea is that

673
00:24:31,250 --> 00:24:34,400
you take a project or a service use a

674
00:24:34,400 --> 00:24:36,830
tool or a framework and you try and

675
00:24:36,830 --> 00:24:38,570
discover something and often this is

676
00:24:38,570 --> 00:24:41,570
used more for feature testing or

677
00:24:41,570 --> 00:24:43,250
functionality testing where you don't

678
00:24:43,250 --> 00:24:45,320
have a specific thing you're testing for

679
00:24:45,320 --> 00:24:47,570
but we started to do with give our

680
00:24:47,570 --> 00:24:49,429
engineers some training on tools like

681
00:24:49,429 --> 00:24:52,820
SAP and the idea wares or even burps we

682
00:24:52,820 --> 00:24:54,860
load different tools and the idea was

683
00:24:54,860 --> 00:24:55,970
was to get them a little bit more

684
00:24:55,970 --> 00:24:57,830
comfortable with those tools and looking

685
00:24:57,830 --> 00:24:59,780
for vulnerabilities and so they still

686
00:24:59,780 --> 00:25:01,400
had their attack trees they had their

687
00:25:01,400 --> 00:25:03,530
concept of threat modeling what am i

688
00:25:03,530 --> 00:25:05,750
doing what can go wrong what can I do

689
00:25:05,750 --> 00:25:07,400
about it and did I do a good job and

690
00:25:07,400 --> 00:25:09,080
they start to go through that to

691
00:25:09,080 --> 00:25:11,270
discover vulnerabilities and it helped

692
00:25:11,270 --> 00:25:13,429
us to continue to upskill our suffre

693
00:25:13,429 --> 00:25:15,620
engineers and but it also meant that we

694
00:25:15,620 --> 00:25:16,730
were starting to find more and more of

695
00:25:16,730 --> 00:25:18,440
our abilities during the testing phase

696
00:25:18,440 --> 00:25:21,080
of our releases and there's a whole load

697
00:25:21,080 --> 00:25:22,880
of informations and a really great blog

698
00:25:22,880 --> 00:25:25,309
post on medium on test charters which I

699
00:25:25,309 --> 00:25:27,559
would encourage you to look at and if

700
00:25:27,559 --> 00:25:30,170
it's something that interests you the

701
00:25:30,170 --> 00:25:31,160
other thing that's been really

702
00:25:31,160 --> 00:25:33,200
successful for us in getting engineers

703
00:25:33,200 --> 00:25:36,890
to be more Blue Team our POC is and so

704
00:25:36,890 --> 00:25:38,630
what I've started to do is go around to

705
00:25:38,630 --> 00:25:41,600
showcases and Guilds existing meetings

706
00:25:41,600 --> 00:25:43,580
with our engineering teams it's been

707
00:25:43,580 --> 00:25:45,830
really important for me to not add more

708
00:25:45,830 --> 00:25:47,690
meetings to that calendar but to be a

709
00:25:47,690 --> 00:25:50,179
part of their existing process and to

710
00:25:50,179 --> 00:25:50,870
POCs

711
00:25:50,870 --> 00:25:52,520
and the reason i do that is it's very

712
00:25:52,520 --> 00:25:54,320
easy for us to security folk to say

713
00:25:54,320 --> 00:25:56,540
you've got this risk or you've got this

714
00:25:56,540 --> 00:25:58,940
vulnerability and it is high and it is

715
00:25:58,940 --> 00:26:00,710
high because I use this framework to

716
00:26:00,710 --> 00:26:04,280
quantify it using these ten areas and

717
00:26:04,280 --> 00:26:06,410
this number is one to ten and so it very

718
00:26:06,410 --> 00:26:08,179
quickly becomes confusing for both your

719
00:26:08,179 --> 00:26:10,340
teams and your product owners and why

720
00:26:10,340 --> 00:26:11,900
something is high and why they should

721
00:26:11,900 --> 00:26:12,680
care about

722
00:26:12,680 --> 00:26:15,950
and so we've started doing pocs to do a

723
00:26:15,950 --> 00:26:17,480
really quick it's a little bit of a

724
00:26:17,480 --> 00:26:19,820
scare tactic but I like it but really

725
00:26:19,820 --> 00:26:22,190
quick and easy demos to save this is why

726
00:26:22,190 --> 00:26:24,620
you should care this is how easy it is

727
00:26:24,620 --> 00:26:26,960
to exploit and this is virally to fix

728
00:26:26,960 --> 00:26:28,730
and so some of the ones that we've been

729
00:26:28,730 --> 00:26:30,650
showing our pal front subdomain

730
00:26:30,650 --> 00:26:34,760
takeovers or route 53 takeovers badly

731
00:26:34,760 --> 00:26:37,190
configured DNS is a huge cause of

732
00:26:37,190 --> 00:26:40,730
subdomain takeovers and an s3 buckets

733
00:26:40,730 --> 00:26:43,790
there's a great website it's totally

734
00:26:43,790 --> 00:26:46,040
legal and depending on what you do with

735
00:26:46,040 --> 00:26:48,590
it and and then it's called grey hat

736
00:26:48,590 --> 00:26:50,360
warfare and when it allows you to do is

737
00:26:50,360 --> 00:26:52,670
search public s3 bucket so it enumerates

738
00:26:52,670 --> 00:26:55,580
the s3 bucket domain space to look for

739
00:26:55,580 --> 00:26:57,200
buckets that opens the Internet and you

740
00:26:57,200 --> 00:26:59,600
can search on keywords so I searched on

741
00:26:59,600 --> 00:27:02,540
credentials CSV yesterday and just to

742
00:27:02,540 --> 00:27:03,650
check that the numbers were still up

743
00:27:03,650 --> 00:27:06,260
today and I had well over 1100 results

744
00:27:06,260 --> 00:27:09,800
for files in public s3 buckets that were

745
00:27:09,800 --> 00:27:12,980
credentials or CSV for those of you that

746
00:27:12,980 --> 00:27:16,250
use AWS if you download your access key

747
00:27:16,250 --> 00:27:19,250
and secret key and for use with the API

748
00:27:19,250 --> 00:27:21,950
or the CLI and it downloads as a file

749
00:27:21,950 --> 00:27:25,250
called credentials dot CSV and so a lot

750
00:27:25,250 --> 00:27:26,870
of people for whatever reason seems to

751
00:27:26,870 --> 00:27:29,720
be uploading these back to s3 and not

752
00:27:29,720 --> 00:27:31,520
locking down their public buckets and we

753
00:27:31,520 --> 00:27:33,290
talk about public buckets a lot and

754
00:27:33,290 --> 00:27:35,570
people often like yeah I know I need to

755
00:27:35,570 --> 00:27:37,100
lock it down but what's the chance of

756
00:27:37,100 --> 00:27:39,320
them finding my bucket that's weirdly

757
00:27:39,320 --> 00:27:41,330
named or randomly named or doesn't say

758
00:27:41,330 --> 00:27:44,420
my company name whatever and but

759
00:27:44,420 --> 00:27:46,730
actually this tool doesn't care how

760
00:27:46,730 --> 00:27:48,410
complex your bucket name is it just

761
00:27:48,410 --> 00:27:50,510
enumerates through that whole namespace

762
00:27:50,510 --> 00:27:53,540
and so I got a lot of results and I can

763
00:27:53,540 --> 00:27:57,560
tell you that we were able to validate a

764
00:27:57,560 --> 00:27:59,510
lot of these credentials were valid and

765
00:27:59,510 --> 00:28:01,820
where possible we told people but it was

766
00:28:01,820 --> 00:28:03,020
a really interesting way to demonstrate

767
00:28:03,020 --> 00:28:05,240
to our product owners in the room of how

768
00:28:05,240 --> 00:28:07,730
easy it is to find data there's some

769
00:28:07,730 --> 00:28:09,560
other interesting keywords I searched

770
00:28:09,560 --> 00:28:13,850
around customer files around financial

771
00:28:13,850 --> 00:28:17,300
records and there some of these weren't

772
00:28:17,300 --> 00:28:18,830
just public read a lot of them were

773
00:28:18,830 --> 00:28:20,269
public right and so

774
00:28:20,269 --> 00:28:23,649
was able to find static files related to

775
00:28:23,649 --> 00:28:27,289
web design websites I would have been

776
00:28:27,289 --> 00:28:29,599
able to deface a whole load of sites at

777
00:28:29,599 --> 00:28:30,889
the same time and so that was a really

778
00:28:30,889 --> 00:28:33,889
easy demonstration I would encourage you

779
00:28:33,889 --> 00:28:35,299
to spend time POC and the

780
00:28:35,299 --> 00:28:36,859
vulnerabilities that you find and you

781
00:28:36,859 --> 00:28:39,289
talk about with your teams and because

782
00:28:39,289 --> 00:28:41,089
if they don't understand your risk

783
00:28:41,089 --> 00:28:42,499
management framework I would challenge

784
00:28:42,499 --> 00:28:44,479
you about whether you understand the

785
00:28:44,479 --> 00:28:46,729
risk management framework well and so if

786
00:28:46,729 --> 00:28:48,169
you want people to take the things you

787
00:28:48,169 --> 00:28:50,029
find seriously this is really important

788
00:28:50,029 --> 00:28:52,429
but it's also important as a way of

789
00:28:52,429 --> 00:28:54,889
getting your teams on how they would

790
00:28:54,889 --> 00:28:58,429
check for these things as well the other

791
00:28:58,429 --> 00:28:59,809
thing and I mentioned this to a couple

792
00:28:59,809 --> 00:29:00,979
of people yesterday it's been really

793
00:29:00,979 --> 00:29:03,429
valuable for me our working groups now

794
00:29:03,429 --> 00:29:06,529
conferences like this are super but the

795
00:29:06,529 --> 00:29:08,629
networking part sometimes I find really

796
00:29:08,629 --> 00:29:10,700
hard and I'd love to think I'm an

797
00:29:10,700 --> 00:29:12,320
extrovert but I have what my friend

798
00:29:12,320 --> 00:29:15,349
jokes is um people hangovers and which

799
00:29:15,349 --> 00:29:17,299
is if I spend too much time with lots of

800
00:29:17,299 --> 00:29:19,429
other people the next day I kind of just

801
00:29:19,429 --> 00:29:21,589
need to sit and be quiet for a bit and

802
00:29:21,589 --> 00:29:24,759
just kind of not talk to anyone and so

803
00:29:24,759 --> 00:29:27,320
sometimes it's hard in these conferences

804
00:29:27,320 --> 00:29:29,089
to find the right person that has the

805
00:29:29,089 --> 00:29:31,339
same problem as you to have that

806
00:29:31,339 --> 00:29:33,379
conversation and so working groups is

807
00:29:33,379 --> 00:29:34,849
something that Francois and Dennis

808
00:29:34,849 --> 00:29:37,159
introduced me to and it's this idea of

809
00:29:37,159 --> 00:29:38,809
finding people that have a similar issue

810
00:29:38,809 --> 00:29:42,440
to you or a similar interest and but

811
00:29:42,440 --> 00:29:45,109
perhaps a conflicting idea of how they

812
00:29:45,109 --> 00:29:46,879
would approach it or a complementary

813
00:29:46,879 --> 00:29:49,099
mindset whatever it might be and the

814
00:29:49,099 --> 00:29:50,690
idea is you have an informal session

815
00:29:50,690 --> 00:29:52,669
Chatham House Rules but the idea is

816
00:29:52,669 --> 00:29:54,769
whatever you produce at the output of

817
00:29:54,769 --> 00:29:57,769
that is under Creative Commons and so

818
00:29:57,769 --> 00:29:59,509
it's a great way to get together and say

819
00:29:59,509 --> 00:30:02,719
how do we how we fix security culture

820
00:30:02,719 --> 00:30:04,279
which is a big question on how do we

821
00:30:04,279 --> 00:30:06,829
create a risk framework that is

822
00:30:06,829 --> 00:30:09,019
translatable to product odors and so the

823
00:30:09,019 --> 00:30:11,359
idea is you get a few people together

824
00:30:11,359 --> 00:30:14,329
and you you've actively just work on a

825
00:30:14,329 --> 00:30:15,769
project and then you put it out there

826
00:30:15,769 --> 00:30:17,719
for everyone else to contribute to after

827
00:30:17,719 --> 00:30:19,789
and the open security summit that

828
00:30:19,789 --> 00:30:22,159
happened earlier this year and last year

829
00:30:22,159 --> 00:30:24,109
were great ways of doing that but I

830
00:30:24,109 --> 00:30:26,719
would encourage you to reach out to your

831
00:30:26,719 --> 00:30:28,909
network and ask them to spread the word

832
00:30:28,909 --> 00:30:30,499
if there's a problem or a challenge you

833
00:30:30,499 --> 00:30:32,719
have these are a great way to to address

834
00:30:32,719 --> 00:30:33,630
them and to

835
00:30:33,630 --> 00:30:35,730
after them the other thing I would ask

836
00:30:35,730 --> 00:30:37,800
you to do is that when you are in the

837
00:30:37,800 --> 00:30:39,240
networking sessions as many of you may

838
00:30:39,240 --> 00:30:41,400
have only come with one person is trying

839
00:30:41,400 --> 00:30:43,050
to introduce them to someone else but

840
00:30:43,050 --> 00:30:44,760
make them meaningful introductions so

841
00:30:44,760 --> 00:30:47,190
rather than just hey down this is Tony

842
00:30:47,190 --> 00:30:48,210
Tony this is down

843
00:30:48,210 --> 00:30:50,670
I'm trying identify people that you

844
00:30:50,670 --> 00:30:52,350
think have complementary mindset so

845
00:30:52,350 --> 00:30:53,940
Alyssa our keynote yesterday is really

846
00:30:53,940 --> 00:30:55,830
interested in the testing world and I

847
00:30:55,830 --> 00:30:57,000
have a friend here that came from the

848
00:30:57,000 --> 00:30:58,350
testing world that has great contacts

849
00:30:58,350 --> 00:30:59,880
and so we were able to make that

850
00:30:59,880 --> 00:31:02,340
introduction and these introductions are

851
00:31:02,340 --> 00:31:04,170
so powerful for people's journey and for

852
00:31:04,170 --> 00:31:06,060
expanding people's knowledge in this

853
00:31:06,060 --> 00:31:08,190
space and so my very first deficit Khan

854
00:31:08,190 --> 00:31:09,570
someone did the same for me

855
00:31:09,570 --> 00:31:11,790
and it's a great way of expanding your

856
00:31:11,790 --> 00:31:13,620
network finding your working group and

857
00:31:13,620 --> 00:31:15,960
being able to continue to build on those

858
00:31:15,960 --> 00:31:19,740
topics the other thing I've done is

859
00:31:19,740 --> 00:31:21,150
whilst I've been working through all of

860
00:31:21,150 --> 00:31:23,070
these quick kind of ways to make people

861
00:31:23,070 --> 00:31:25,620
blue to you is I constantly sync back to

862
00:31:25,620 --> 00:31:28,290
impact when I'm thinking about security

863
00:31:28,290 --> 00:31:30,210
champions proof of concepts threat

864
00:31:30,210 --> 00:31:32,250
modeling using attack trees working

865
00:31:32,250 --> 00:31:34,440
groups all of these things I've started

866
00:31:34,440 --> 00:31:36,960
to quantify what's the impact and is it

867
00:31:36,960 --> 00:31:38,520
the right thing to be going after right

868
00:31:38,520 --> 00:31:41,310
now so I looked at individual impact

869
00:31:41,310 --> 00:31:43,500
team I've talked about branding group

870
00:31:43,500 --> 00:31:44,940
but effectively that's a line of

871
00:31:44,940 --> 00:31:47,280
business entire business and then

872
00:31:47,280 --> 00:31:48,900
industry and you can kind of phrase it

873
00:31:48,900 --> 00:31:50,460
however you want but the idea was to

874
00:31:50,460 --> 00:31:52,350
continuously reflect and say is this

875
00:31:52,350 --> 00:31:54,450
having the impact that it needs to have

876
00:31:54,450 --> 00:31:56,010
right now is this the right thing to

877
00:31:56,010 --> 00:31:57,630
work on and then I've been getting

878
00:31:57,630 --> 00:31:59,850
feedback from our product teams as to is

879
00:31:59,850 --> 00:32:01,950
the roadmap that I have having the right

880
00:32:01,950 --> 00:32:04,830
impact is it meaningful it's so easy for

881
00:32:04,830 --> 00:32:06,660
us to security folk to drive our own

882
00:32:06,660 --> 00:32:08,310
roadmap for the things that we want to

883
00:32:08,310 --> 00:32:09,660
do with our team's based on our own

884
00:32:09,660 --> 00:32:11,910
perspective without seeking the

885
00:32:11,910 --> 00:32:13,590
perspective of our wider teams and one

886
00:32:13,590 --> 00:32:15,000
of the things that I quite like about

887
00:32:15,000 --> 00:32:16,890
what Amazon do is when they go into

888
00:32:16,890 --> 00:32:18,450
their quarterly planning they post on

889
00:32:18,450 --> 00:32:20,490
Twitter a lot of the teams and they do

890
00:32:20,490 --> 00:32:23,070
feature requests the lambda team do it

891
00:32:23,070 --> 00:32:25,770
well the elasticsearch team maybe not so

892
00:32:25,770 --> 00:32:27,330
well I've got a lot of feature requests

893
00:32:27,330 --> 00:32:29,970
for them but the idea is to constantly

894
00:32:29,970 --> 00:32:31,530
seek that feedback and make sure you

895
00:32:31,530 --> 00:32:34,830
having the right impact and so there's a

896
00:32:34,830 --> 00:32:37,020
whole load of resources that I've kind

897
00:32:37,020 --> 00:32:38,550
of covered up really quickly or things

898
00:32:38,550 --> 00:32:40,080
that have helped me on my journey and

899
00:32:40,080 --> 00:32:42,870
again the idea are quick and easy tools

900
00:32:42,870 --> 00:32:46,529
that are easy to utilize easy to onboard

901
00:32:46,529 --> 00:32:49,559
my only caveat on this list is security

902
00:32:49,559 --> 00:32:52,739
monkey Netflix I love your tools but God

903
00:32:52,739 --> 00:32:57,090
your documentation is awful and so the

904
00:32:57,090 --> 00:32:58,320
idea if you're going to ask your

905
00:32:58,320 --> 00:33:00,239
engineers to utilize any tooling any

906
00:33:00,239 --> 00:33:01,859
open-source tooling is make sure you've

907
00:33:01,859 --> 00:33:04,710
used it yourself make sure that it's

908
00:33:04,710 --> 00:33:06,659
clear that it adds value that it has the

909
00:33:06,659 --> 00:33:09,450
right impact that you want but there are

910
00:33:09,450 --> 00:33:11,519
loads of free races or resources out

911
00:33:11,519 --> 00:33:13,590
there that can just help to make your

912
00:33:13,590 --> 00:33:15,899
delivery teams that a little bit more

913
00:33:15,899 --> 00:33:18,350
blue team and continue to upskill them

914
00:33:18,350 --> 00:33:20,850
there's a lot of stuff there I tend to

915
00:33:20,850 --> 00:33:22,470
tweet a lot of resources and links to

916
00:33:22,470 --> 00:33:24,659
these as well so do feel free to ask me

917
00:33:24,659 --> 00:33:27,029
any questions after if I've mentioned

918
00:33:27,029 --> 00:33:29,489
any that you like and but that's it

919
00:33:29,489 --> 00:33:31,230
thank you guys so much for coming and

920
00:33:31,230 --> 00:33:41,460
for hearing me talk and I am gonna be

921
00:33:41,460 --> 00:33:43,109
around for questions but I am gonna ask

922
00:33:43,109 --> 00:33:45,840
that you come and find me out there and

923
00:33:45,840 --> 00:33:47,549
grab me cuz I don't want to hold you up

924
00:33:47,549 --> 00:33:49,230
or hold the next speaker up but thank

925
00:33:49,230 --> 00:33:51,619
you so much

