1
00:00:01,439 --> 00:00:03,520
hello and welcome to today's

2
00:00:03,520 --> 00:00:05,120
presentation

3
00:00:05,120 --> 00:00:08,480
my name is dennis kengoka and i'm a

4
00:00:08,480 --> 00:00:11,280
principal automotive security strategist

5
00:00:11,280 --> 00:00:13,200
at synopsis

6
00:00:13,200 --> 00:00:16,160
i work with oems and suppliers in the

7
00:00:16,160 --> 00:00:19,279
automotive industry globally

8
00:00:19,279 --> 00:00:22,000
to help them develop more secure

9
00:00:22,000 --> 00:00:24,160
software

10
00:00:24,160 --> 00:00:26,880
in today's presentation i would like to

11
00:00:26,880 --> 00:00:28,080
describe

12
00:00:28,080 --> 00:00:30,320
practical steps for fuzz testing

13
00:00:30,320 --> 00:00:33,440
embedded software in a ci pipeline

14
00:00:33,440 --> 00:00:35,840
a continuous integration pipeline

15
00:00:35,840 --> 00:00:37,840
and also go through an example

16
00:00:37,840 --> 00:00:40,640
implementation

17
00:00:40,640 --> 00:00:44,960
on today's agenda we have three points

18
00:00:44,960 --> 00:00:47,039
the first point is

19
00:00:47,039 --> 00:00:49,200
on challenges with fuzz testing in the

20
00:00:49,200 --> 00:00:50,800
automotive industry

21
00:00:50,800 --> 00:00:53,120
and we'll discuss a little bit about the

22
00:00:53,120 --> 00:00:55,760
common challenges

23
00:00:55,760 --> 00:00:58,480
the second point is on the strategies

24
00:00:58,480 --> 00:00:59,600
for

25
00:00:59,600 --> 00:01:04,400
enabling fuss testing in a ci pipeline

26
00:01:04,400 --> 00:01:06,960
and then the third point is on the

27
00:01:06,960 --> 00:01:09,520
practical steps for integrating fast

28
00:01:09,520 --> 00:01:10,640
testing

29
00:01:10,640 --> 00:01:12,000
and we'll go through an example

30
00:01:12,000 --> 00:01:15,439
implementation at this point as well

31
00:01:15,439 --> 00:01:18,320
so let's start with the first point

32
00:01:18,320 --> 00:01:20,080
and go through some of the challenges

33
00:01:20,080 --> 00:01:22,000
with existing fuzz testing in the

34
00:01:22,000 --> 00:01:25,040
automotive industry

35
00:01:25,520 --> 00:01:27,119
before we begin

36
00:01:27,119 --> 00:01:29,439
i would like to give some background on

37
00:01:29,439 --> 00:01:32,159
the automotive trends

38
00:01:32,159 --> 00:01:34,240
there are four major trends in the

39
00:01:34,240 --> 00:01:36,000
automotive industry

40
00:01:36,000 --> 00:01:39,680
often referred to using the acronym case

41
00:01:39,680 --> 00:01:43,119
which stands for connected autonomous

42
00:01:43,119 --> 00:01:44,799
shared and services

43
00:01:44,799 --> 00:01:47,360
and electrification

44
00:01:47,360 --> 00:01:49,920
regarding connected we see vehicles

45
00:01:49,920 --> 00:01:52,159
today with more connectivity

46
00:01:52,159 --> 00:01:54,000
and more communication interfaces

47
00:01:54,000 --> 00:02:00,159
including wi-fi bluetooth v2x 5g etc

48
00:02:00,159 --> 00:02:02,399
regarding autonomous we see autonomous

49
00:02:02,399 --> 00:02:05,680
vehicles where we have advanced systems

50
00:02:05,680 --> 00:02:08,239
controlling the steering braking and

51
00:02:08,239 --> 00:02:10,318
acceleration of vehicles

52
00:02:10,318 --> 00:02:12,160
as well as a number of different systems

53
00:02:12,160 --> 00:02:15,680
with sensors cameras radar and lighter

54
00:02:15,680 --> 00:02:17,680
that process the input

55
00:02:17,680 --> 00:02:19,200
regarding the surroundings of the

56
00:02:19,200 --> 00:02:21,360
vehicle

57
00:02:21,360 --> 00:02:23,520
in addition we have a number of new

58
00:02:23,520 --> 00:02:25,440
services

59
00:02:25,440 --> 00:02:27,920
including services

60
00:02:27,920 --> 00:02:30,080
provided in the cloud

61
00:02:30,080 --> 00:02:32,080
by oem backends

62
00:02:32,080 --> 00:02:35,360
using web apps or mobile apps

63
00:02:35,360 --> 00:02:36,400
and finally

64
00:02:36,400 --> 00:02:39,280
regarding electrification we see a trend

65
00:02:39,280 --> 00:02:42,080
towards electric vehicles evs

66
00:02:42,080 --> 00:02:44,480
with new technologies such as charging

67
00:02:44,480 --> 00:02:49,720
and battery management systems and v2g

68
00:02:51,599 --> 00:02:53,840
these automotive trends lead to a need

69
00:02:53,840 --> 00:02:55,519
for security

70
00:02:55,519 --> 00:02:57,280
as briefly mentioned on the previous

71
00:02:57,280 --> 00:03:00,800
slide these four major trends connected

72
00:03:00,800 --> 00:03:03,360
autonomous shared and services and

73
00:03:03,360 --> 00:03:05,120
electrification

74
00:03:05,120 --> 00:03:07,519
require more software

75
00:03:07,519 --> 00:03:11,040
and also create more attack surfaces

76
00:03:11,040 --> 00:03:13,920
as well as generate more valuable data

77
00:03:13,920 --> 00:03:15,760
both on the vehicle side

78
00:03:15,760 --> 00:03:19,760
and on the back end side

79
00:03:19,760 --> 00:03:22,640
thus becomes more lucrative targets for

80
00:03:22,640 --> 00:03:24,560
attackers

81
00:03:24,560 --> 00:03:26,319
therefore there is a need for cyber

82
00:03:26,319 --> 00:03:28,159
security

83
00:03:28,159 --> 00:03:30,080
this is already recognized in the

84
00:03:30,080 --> 00:03:31,599
automotive industry

85
00:03:31,599 --> 00:03:35,680
with the upcoming regulation unr 155 on

86
00:03:35,680 --> 00:03:37,440
cyber security

87
00:03:37,440 --> 00:03:40,640
as well as the iso sa2144

88
00:03:40,640 --> 00:03:43,360
cyber security engineering standard

89
00:03:43,360 --> 00:03:46,159
and the recently released automotive

90
00:03:46,159 --> 00:03:49,599
spice for cyber security

91
00:03:49,599 --> 00:03:52,319
and both in the iso sa2 and 434 and

92
00:03:52,319 --> 00:03:54,640
automotive spice for cyber security

93
00:03:54,640 --> 00:03:56,480
fuzz testing is mentioned as a

94
00:03:56,480 --> 00:03:58,840
recommended test

95
00:03:58,840 --> 00:04:01,519
approach one thing to note about fuzz

96
00:04:01,519 --> 00:04:03,840
testing is that to achieve better

97
00:04:03,840 --> 00:04:05,040
results

98
00:04:05,040 --> 00:04:07,439
it is better to execute fuss testing

99
00:04:07,439 --> 00:04:09,439
as much as possible

100
00:04:09,439 --> 00:04:10,879
for example

101
00:04:10,879 --> 00:04:12,959
continuously in a ci continuous

102
00:04:12,959 --> 00:04:15,840
integration pipeline

103
00:04:18,160 --> 00:04:20,959
first let's go through what we mean by

104
00:04:20,959 --> 00:04:22,639
fuzz testing

105
00:04:22,639 --> 00:04:25,360
fast testing is a test technique where

106
00:04:25,360 --> 00:04:27,360
malformed or out of specification

107
00:04:27,360 --> 00:04:30,000
messages are provided to the target

108
00:04:30,000 --> 00:04:33,680
system the sut system under test

109
00:04:33,680 --> 00:04:37,440
and that system is then observed for any

110
00:04:37,440 --> 00:04:40,479
unexpected behavior

111
00:04:40,479 --> 00:04:43,520
if there are any unexpected behavior

112
00:04:43,520 --> 00:04:46,000
it's possible for developers and testers

113
00:04:46,000 --> 00:04:47,680
to further analyze

114
00:04:47,680 --> 00:04:48,880
the issue

115
00:04:48,880 --> 00:04:52,080
and detect unknown vulnerabilities in

116
00:04:52,080 --> 00:04:56,039
their systems and components

117
00:04:57,040 --> 00:04:59,120
and on this slide we see an example

118
00:04:59,120 --> 00:05:01,280
system that's communicating over

119
00:05:01,280 --> 00:05:03,120
bluetooth

120
00:05:03,120 --> 00:05:05,039
there are fuzzed messages sent over

121
00:05:05,039 --> 00:05:06,639
bluetooth here

122
00:05:06,639 --> 00:05:08,639
where typically on the screen you would

123
00:05:08,639 --> 00:05:09,680
see

124
00:05:09,680 --> 00:05:10,560
the

125
00:05:10,560 --> 00:05:13,759
song title the album name and the artist

126
00:05:13,759 --> 00:05:14,720
name

127
00:05:14,720 --> 00:05:17,520
but because of the fuzzed messages

128
00:05:17,520 --> 00:05:19,840
it's only displaying no

129
00:05:19,840 --> 00:05:21,759
you can imagine if it's possible to

130
00:05:21,759 --> 00:05:25,280
craft a malicious message

131
00:05:25,280 --> 00:05:27,840
that would instead of just showing no

132
00:05:27,840 --> 00:05:29,360
could potentially

133
00:05:29,360 --> 00:05:32,000
take over that application

134
00:05:32,000 --> 00:05:33,680
and execute

135
00:05:33,680 --> 00:05:37,240
arbitrary commands

136
00:05:38,720 --> 00:05:39,919
so let's

137
00:05:39,919 --> 00:05:43,039
let's take a practical look at a fuzzed

138
00:05:43,039 --> 00:05:45,520
message

139
00:05:45,680 --> 00:05:48,160
here we use defensive's fuzz testing

140
00:05:48,160 --> 00:05:51,199
tool and the tcp for ipv4

141
00:05:51,199 --> 00:05:52,960
test suite

142
00:05:52,960 --> 00:05:55,039
as you can see in the top portion of the

143
00:05:55,039 --> 00:05:56,240
slide

144
00:05:56,240 --> 00:05:57,680
we have

145
00:05:57,680 --> 00:05:59,759
a set of different test suites

146
00:05:59,759 --> 00:06:02,000
right now we're looking at the tcp test

147
00:06:02,000 --> 00:06:03,039
suite

148
00:06:03,039 --> 00:06:06,160
and within the tcp test suite we have a

149
00:06:06,160 --> 00:06:09,520
number of different fuzzed messages

150
00:06:09,520 --> 00:06:12,000
this example here shows the different

151
00:06:12,000 --> 00:06:15,520
fields in a tcp message

152
00:06:15,520 --> 00:06:17,600
where we can see that the source port

153
00:06:17,600 --> 00:06:20,160
and the act number for example contains

154
00:06:20,160 --> 00:06:22,000
anomalies

155
00:06:22,000 --> 00:06:24,160
we can then send these fuzz messages

156
00:06:24,160 --> 00:06:26,560
with these anomalies to a target system

157
00:06:26,560 --> 00:06:28,960
and observe how that target system would

158
00:06:28,960 --> 00:06:32,239
respond to these

159
00:06:32,840 --> 00:06:35,360
messages let's take a look at a

160
00:06:35,360 --> 00:06:38,800
simplified ci pipeline and

161
00:06:38,800 --> 00:06:41,520
try to understand the problem of trying

162
00:06:41,520 --> 00:06:43,759
to include fuzz testing as part of the

163
00:06:43,759 --> 00:06:45,680
pipeline

164
00:06:45,680 --> 00:06:47,520
as a first step we see here on the left

165
00:06:47,520 --> 00:06:51,360
hand side we have our build step

166
00:06:51,360 --> 00:06:53,360
in this step we can use various

167
00:06:53,360 --> 00:06:55,759
solutions such as static code analysis

168
00:06:55,759 --> 00:06:58,319
and software composition analysis

169
00:06:58,319 --> 00:07:01,199
that can process the source code as it

170
00:07:01,199 --> 00:07:03,840
is

171
00:07:04,000 --> 00:07:06,240
in the next step we have our flashing

172
00:07:06,240 --> 00:07:09,599
where we connect to the hardware device

173
00:07:09,599 --> 00:07:11,039
and this is typically the first

174
00:07:11,039 --> 00:07:12,639
challenge we have that

175
00:07:12,639 --> 00:07:14,720
testing will then be performed on

176
00:07:14,720 --> 00:07:15,759
hardware

177
00:07:15,759 --> 00:07:17,840
we need to flash a binary to a hardware

178
00:07:17,840 --> 00:07:22,080
device a microcontroller or a ecu

179
00:07:22,080 --> 00:07:23,280
and often

180
00:07:23,280 --> 00:07:25,360
that test target

181
00:07:25,360 --> 00:07:27,039
the standalone ecu

182
00:07:27,039 --> 00:07:30,160
is running by itself so we have a

183
00:07:30,160 --> 00:07:32,240
limited test environment which is also a

184
00:07:32,240 --> 00:07:34,240
challenge

185
00:07:34,240 --> 00:07:35,919
and then finally we have to perform our

186
00:07:35,919 --> 00:07:38,960
dynamic testing and this includes the

187
00:07:38,960 --> 00:07:40,319
normal functional testing that we

188
00:07:40,319 --> 00:07:41,520
typically do

189
00:07:41,520 --> 00:07:43,440
but also we want to add fuzz testing

190
00:07:43,440 --> 00:07:46,639
here as part of the pipeline

191
00:07:46,639 --> 00:07:48,639
and this is the second challenge we have

192
00:07:48,639 --> 00:07:51,039
if we include fuzz testing at this stage

193
00:07:51,039 --> 00:07:53,599
of the process it occurs late

194
00:07:53,599 --> 00:07:55,919
it needs to be done dynamically

195
00:07:55,919 --> 00:07:57,599
which means it requires the binary to be

196
00:07:57,599 --> 00:08:00,560
executed and this typically means that

197
00:08:00,560 --> 00:08:04,639
the testing occurs late in the process

198
00:08:07,520 --> 00:08:10,000
so with this understanding of the

199
00:08:10,000 --> 00:08:11,520
challenges

200
00:08:11,520 --> 00:08:12,479
for

201
00:08:12,479 --> 00:08:15,199
integrating fuss testing into the ci

202
00:08:15,199 --> 00:08:16,720
pipeline

203
00:08:16,720 --> 00:08:18,560
let's take a look at some of the

204
00:08:18,560 --> 00:08:20,720
strategies that we can apply

205
00:08:20,720 --> 00:08:22,639
in order to successfully

206
00:08:22,639 --> 00:08:24,800
integrate fast testing into a ci

207
00:08:24,800 --> 00:08:27,599
pipeline

208
00:08:27,599 --> 00:08:29,840
regarding the strategies for fuss

209
00:08:29,840 --> 00:08:32,719
testing in a ci pipeline we have a

210
00:08:32,719 --> 00:08:35,279
number of questions we have to ask

211
00:08:35,279 --> 00:08:37,599
ourselves

212
00:08:37,599 --> 00:08:39,679
we see here on the left hand side a

213
00:08:39,679 --> 00:08:41,679
number of questions

214
00:08:41,679 --> 00:08:43,919
and we'll go through these one by one

215
00:08:43,919 --> 00:08:46,399
and explain a little bit about how these

216
00:08:46,399 --> 00:08:49,120
questions can be addressed

217
00:08:49,120 --> 00:08:53,040
the first question is on when to test

218
00:08:53,040 --> 00:08:55,360
so the important thing here is we want

219
00:08:55,360 --> 00:08:58,399
to test as often as possible as much as

220
00:08:58,399 --> 00:08:59,920
possible

221
00:08:59,920 --> 00:09:02,480
so shift everywhere is really the key

222
00:09:02,480 --> 00:09:04,640
word of making sure the fuss testing

223
00:09:04,640 --> 00:09:05,760
occurs

224
00:09:05,760 --> 00:09:07,600
as often as possible

225
00:09:07,600 --> 00:09:09,440
when it's available

226
00:09:09,440 --> 00:09:11,360
so examples include

227
00:09:11,360 --> 00:09:13,839
for example off-peak hours

228
00:09:13,839 --> 00:09:16,080
you can perform testing during nights

229
00:09:16,080 --> 00:09:18,320
you can perform testing over weekends

230
00:09:18,320 --> 00:09:20,399
so making sure that you use any time

231
00:09:20,399 --> 00:09:24,160
available to perform testing

232
00:09:24,160 --> 00:09:27,360
the second question on how long to test

233
00:09:27,360 --> 00:09:29,440
we want to make sure we can use the full

234
00:09:29,440 --> 00:09:31,760
amount of time available as efficiently

235
00:09:31,760 --> 00:09:33,360
as possible

236
00:09:33,360 --> 00:09:36,320
so if we have time to perform testing

237
00:09:36,320 --> 00:09:38,320
let's use that time

238
00:09:38,320 --> 00:09:40,160
the full time available to perform that

239
00:09:40,160 --> 00:09:42,000
testing

240
00:09:42,000 --> 00:09:44,000
when it comes to what to test it's

241
00:09:44,000 --> 00:09:46,000
important that we perform a terror a

242
00:09:46,000 --> 00:09:48,560
threat analysis and risk assessment

243
00:09:48,560 --> 00:09:50,800
to identify the high risk interfaces and

244
00:09:50,800 --> 00:09:52,959
target applications

245
00:09:52,959 --> 00:09:55,600
so we know what are the high priority

246
00:09:55,600 --> 00:09:58,880
targets that we should test

247
00:10:00,080 --> 00:10:02,640
regarding how to test

248
00:10:02,640 --> 00:10:04,880
we need to understand what is the best

249
00:10:04,880 --> 00:10:07,440
environment we can use for example can

250
00:10:07,440 --> 00:10:10,959
we perform testing on native posix or

251
00:10:10,959 --> 00:10:12,720
can we use virtualized emulated

252
00:10:12,720 --> 00:10:15,120
environments such as cumu

253
00:10:15,120 --> 00:10:18,240
or do we require hardware interfaces for

254
00:10:18,240 --> 00:10:20,000
certain hardware components such as

255
00:10:20,000 --> 00:10:23,760
wi-fi bluetooth and can

256
00:10:24,320 --> 00:10:27,040
next regarding how to detect exceptions

257
00:10:27,040 --> 00:10:28,880
we have to understand how we can monitor

258
00:10:28,880 --> 00:10:30,320
the target system

259
00:10:30,320 --> 00:10:31,839
for example using in-band

260
00:10:31,839 --> 00:10:33,920
instrumentation where we monitor the

261
00:10:33,920 --> 00:10:37,200
same interface that's being fuzz tested

262
00:10:37,200 --> 00:10:39,839
or if we need external instrumentation

263
00:10:39,839 --> 00:10:42,480
where we use some kind of external means

264
00:10:42,480 --> 00:10:46,320
to monitor the target system

265
00:10:46,320 --> 00:10:49,519
and finally how to manage test results

266
00:10:49,519 --> 00:10:51,600
here we have to understand how we can

267
00:10:51,600 --> 00:10:54,160
log failure conditions on the target

268
00:10:54,160 --> 00:10:55,120
system

269
00:10:55,120 --> 00:10:57,920
how we are able to reproduce the issue

270
00:10:57,920 --> 00:11:00,240
as well as have some kind of criteria

271
00:11:00,240 --> 00:11:02,959
where we can decide whether we need to

272
00:11:02,959 --> 00:11:05,760
break the build based on the results of

273
00:11:05,760 --> 00:11:08,399
the testing

274
00:11:10,959 --> 00:11:13,760
so based on this general view of the

275
00:11:13,760 --> 00:11:16,000
strategies for fuss testing in a ci

276
00:11:16,000 --> 00:11:17,279
pipeline

277
00:11:17,279 --> 00:11:19,040
and understanding the type of questions

278
00:11:19,040 --> 00:11:20,800
that we have to answer

279
00:11:20,800 --> 00:11:24,000
let's move on to the third point

280
00:11:24,000 --> 00:11:26,079
and discuss the practical steps for

281
00:11:26,079 --> 00:11:28,320
integrating fuss testing and also go

282
00:11:28,320 --> 00:11:32,160
through this example implementation

283
00:11:33,600 --> 00:11:35,680
the practical steps for integrating fuss

284
00:11:35,680 --> 00:11:38,880
testing into a ci pipeline involves four

285
00:11:38,880 --> 00:11:40,320
steps

286
00:11:40,320 --> 00:11:42,079
the first step is understanding the

287
00:11:42,079 --> 00:11:44,320
existing ci pipeline

288
00:11:44,320 --> 00:11:46,000
here we need to understand what are the

289
00:11:46,000 --> 00:11:48,079
stages of the pipeline

290
00:11:48,079 --> 00:11:50,480
and when is the executable available for

291
00:11:50,480 --> 00:11:52,800
fuzz testing

292
00:11:52,800 --> 00:11:54,560
the second step is understanding the

293
00:11:54,560 --> 00:11:56,639
target system

294
00:11:56,639 --> 00:11:59,760
as i described here we can use a terror

295
00:11:59,760 --> 00:12:02,240
a threat analysis and risk assessment to

296
00:12:02,240 --> 00:12:04,320
identify relevant interfaces and

297
00:12:04,320 --> 00:12:07,040
high-risk targets

298
00:12:07,040 --> 00:12:10,079
the third step is to define fast testing

299
00:12:10,079 --> 00:12:11,760
strategies as i mentioned on the

300
00:12:11,760 --> 00:12:14,000
previous slide

301
00:12:14,000 --> 00:12:16,639
here we need to define when to test how

302
00:12:16,639 --> 00:12:19,680
long to test what to test and how to

303
00:12:19,680 --> 00:12:20,720
test

304
00:12:20,720 --> 00:12:22,880
as well as how to detect exceptions and

305
00:12:22,880 --> 00:12:26,160
manage the test results

306
00:12:26,160 --> 00:12:28,079
and finally the fourth step is

307
00:12:28,079 --> 00:12:31,200
establishing a fuzz testing environment

308
00:12:31,200 --> 00:12:33,120
since testing will occur in a ci

309
00:12:33,120 --> 00:12:35,519
pipeline we have to make sure that test

310
00:12:35,519 --> 00:12:36,639
automation

311
00:12:36,639 --> 00:12:37,440
is

312
00:12:37,440 --> 00:12:39,040
enabled

313
00:12:39,040 --> 00:12:41,040
and that the configuration of the tools

314
00:12:41,040 --> 00:12:42,800
have been made

315
00:12:42,800 --> 00:12:44,720
as well as to

316
00:12:44,720 --> 00:12:47,440
be able to determine the outcome of test

317
00:12:47,440 --> 00:12:50,000
results we need to have the proper logs

318
00:12:50,000 --> 00:12:53,000
generated

319
00:12:53,200 --> 00:12:55,040
on the next few slides

320
00:12:55,040 --> 00:12:58,240
i'll give an explanation of an example

321
00:12:58,240 --> 00:13:00,720
implementation using zephyr

322
00:13:00,720 --> 00:13:03,200
which is a small footprint real-time

323
00:13:03,200 --> 00:13:05,680
operating system an rtos it's an open

324
00:13:05,680 --> 00:13:08,079
source software it has built-in

325
00:13:08,079 --> 00:13:10,000
components and libraries for full

326
00:13:10,000 --> 00:13:11,760
application development

327
00:13:11,760 --> 00:13:13,920
for example device drivers protocol

328
00:13:13,920 --> 00:13:16,959
stacks and file systems

329
00:13:16,959 --> 00:13:18,639
it's also designed for memory

330
00:13:18,639 --> 00:13:21,040
constrained embedded devices which makes

331
00:13:21,040 --> 00:13:23,279
it useful for automotive applications

332
00:13:23,279 --> 00:13:25,600
internet of things smart wearables and

333
00:13:25,600 --> 00:13:28,560
microcontrollers

334
00:13:29,680 --> 00:13:32,720
so using zephyr as an example we'll talk

335
00:13:32,720 --> 00:13:34,800
about these four different steps that i

336
00:13:34,800 --> 00:13:35,760
mentioned

337
00:13:35,760 --> 00:13:37,600
the first is to understand the existing

338
00:13:37,600 --> 00:13:39,360
ci pipeline

339
00:13:39,360 --> 00:13:42,160
here we have daily builds where

340
00:13:42,160 --> 00:13:43,680
functional testing and regression

341
00:13:43,680 --> 00:13:45,519
testing is performed

342
00:13:45,519 --> 00:13:47,199
zephyr is running in an emulated test

343
00:13:47,199 --> 00:13:49,360
environment using qmo

344
00:13:49,360 --> 00:13:51,040
we also have cases where zephyr is

345
00:13:51,040 --> 00:13:52,800
running as a native application on the

346
00:13:52,800 --> 00:13:55,360
host os without emulation using native

347
00:13:55,360 --> 00:13:57,600
post-6 execution

348
00:13:57,600 --> 00:13:59,600
so this is interesting because using

349
00:13:59,600 --> 00:14:02,399
native postx it's possible to execute

350
00:14:02,399 --> 00:14:04,880
zephyr in software only

351
00:14:04,880 --> 00:14:07,120
and that eliminates the need for any

352
00:14:07,120 --> 00:14:09,600
architecture specific target hardware

353
00:14:09,600 --> 00:14:11,360
especially in the earlier phases of

354
00:14:11,360 --> 00:14:12,880
development

355
00:14:12,880 --> 00:14:15,600
there are also already networking tests

356
00:14:15,600 --> 00:14:17,760
conducted in the ci pipeline which

357
00:14:17,760 --> 00:14:23,680
includes tests for tcp dhcp and mqtt

358
00:14:24,880 --> 00:14:27,839
let's take a look at a simplified ci

359
00:14:27,839 --> 00:14:29,680
pipeline example

360
00:14:29,680 --> 00:14:32,079
here we start the process on the left

361
00:14:32,079 --> 00:14:33,279
hand side

362
00:14:33,279 --> 00:14:36,560
we have our prepare build environment

363
00:14:36,560 --> 00:14:39,279
and our build step where we download the

364
00:14:39,279 --> 00:14:41,199
latest sources

365
00:14:41,199 --> 00:14:44,800
and we build the software

366
00:14:44,800 --> 00:14:47,279
in the next step in the test step we

367
00:14:47,279 --> 00:14:49,680
perform our functional tests and our

368
00:14:49,680 --> 00:14:52,160
networking tests

369
00:14:52,160 --> 00:14:54,880
following in the next step we deploy

370
00:14:54,880 --> 00:14:56,800
and this could be to your development

371
00:14:56,800 --> 00:14:59,199
environment or your staging server or

372
00:14:59,199 --> 00:15:01,680
production server

373
00:15:01,680 --> 00:15:04,000
or system and then finally to

374
00:15:04,000 --> 00:15:05,920
we finish this process here in the end

375
00:15:05,920 --> 00:15:08,240
step

376
00:15:08,320 --> 00:15:10,000
what we want to focus on here is just

377
00:15:10,000 --> 00:15:13,040
the middle portion here the test step

378
00:15:13,040 --> 00:15:13,839
where

379
00:15:13,839 --> 00:15:16,560
besides functional tests and networking

380
00:15:16,560 --> 00:15:20,320
tests we want to add fuzz tests

381
00:15:20,320 --> 00:15:23,279
so we can perform this as part of the ci

382
00:15:23,279 --> 00:15:24,800
pipeline

383
00:15:24,800 --> 00:15:27,360
in parallel with other testing but add

384
00:15:27,360 --> 00:15:30,560
as a separate step

385
00:15:31,600 --> 00:15:33,839
so now when we understand the existing

386
00:15:33,839 --> 00:15:36,560
ci pipeline and how we can fit fuzz

387
00:15:36,560 --> 00:15:40,560
testing into that pipeline as a new step

388
00:15:40,560 --> 00:15:41,600
our

389
00:15:41,600 --> 00:15:43,839
next activity is to understand the

390
00:15:43,839 --> 00:15:46,079
target system

391
00:15:46,079 --> 00:15:48,959
again here we use zephyr as an example

392
00:15:48,959 --> 00:15:50,560
and we can see here on the right hand

393
00:15:50,560 --> 00:15:51,680
side

394
00:15:51,680 --> 00:15:54,959
that the networking stack contains a

395
00:15:54,959 --> 00:15:57,680
number of different protocols

396
00:15:57,680 --> 00:15:59,759
so we have from the bottom

397
00:15:59,759 --> 00:16:02,320
are layer 2 network technologies

398
00:16:02,320 --> 00:16:06,320
including ethernet 802 15.4

399
00:16:06,320 --> 00:16:09,199
can and bluetooth we have a number of

400
00:16:09,199 --> 00:16:11,399
different network protocols including

401
00:16:11,399 --> 00:16:16,560
ipv4 ipv6 tcp udp and so on

402
00:16:16,560 --> 00:16:18,240
and then we have our application

403
00:16:18,240 --> 00:16:21,600
protocols on the top such as mqtt and

404
00:16:21,600 --> 00:16:24,399
coap

405
00:16:25,360 --> 00:16:28,959
once we understand the target system

406
00:16:28,959 --> 00:16:31,839
our next step is to prioritize the test

407
00:16:31,839 --> 00:16:33,600
targets

408
00:16:33,600 --> 00:16:36,000
one way to do that is to use a

409
00:16:36,000 --> 00:16:37,759
systematic method

410
00:16:37,759 --> 00:16:39,680
to identify and prioritize these test

411
00:16:39,680 --> 00:16:40,720
targets

412
00:16:40,720 --> 00:16:45,160
using iso sa2m434

413
00:16:45,680 --> 00:16:47,920
in the standard there is a threat

414
00:16:47,920 --> 00:16:51,279
analysis and risk assessment method tera

415
00:16:51,279 --> 00:16:55,040
described that can be followed

416
00:16:55,040 --> 00:16:58,399
also in annex e there are the

417
00:16:58,399 --> 00:17:01,279
cyber security assurance levels cals

418
00:17:01,279 --> 00:17:03,120
described

419
00:17:03,120 --> 00:17:06,400
cals can be used to determine the depth

420
00:17:06,400 --> 00:17:09,599
and the scope of testing

421
00:17:09,599 --> 00:17:11,919
so what we can do here as you can see on

422
00:17:11,919 --> 00:17:14,559
the left hand side in this table

423
00:17:14,559 --> 00:17:17,039
we can use a simplified approach here

424
00:17:17,039 --> 00:17:19,760
using an attack vector based approach to

425
00:17:19,760 --> 00:17:21,599
determine cals

426
00:17:21,599 --> 00:17:24,240
so we see here on the y-axis we have the

427
00:17:24,240 --> 00:17:26,319
impact of an attack

428
00:17:26,319 --> 00:17:28,559
ranging from measurable to bad red to

429
00:17:28,559 --> 00:17:30,400
major to severe

430
00:17:30,400 --> 00:17:32,559
and on the x-axis we have the attack

431
00:17:32,559 --> 00:17:33,919
vector

432
00:17:33,919 --> 00:17:37,679
physical local adjacent and network

433
00:17:37,679 --> 00:17:41,360
so we can see that an attack that occurs

434
00:17:41,360 --> 00:17:42,720
over network

435
00:17:42,720 --> 00:17:45,039
and has a severe impact

436
00:17:45,039 --> 00:17:45,840
has

437
00:17:45,840 --> 00:17:49,039
assigned cal4

438
00:17:49,039 --> 00:17:51,120
whereas an attack that is for example

439
00:17:51,120 --> 00:17:52,320
physical

440
00:17:52,320 --> 00:17:55,600
and has a moderate impact is assigned

441
00:17:55,600 --> 00:17:57,520
cal one

442
00:17:57,520 --> 00:18:00,160
so using this table we can now assign

443
00:18:00,160 --> 00:18:02,480
cals to each of the different interfaces

444
00:18:02,480 --> 00:18:06,400
and sub-interfaces of our target system

445
00:18:06,400 --> 00:18:08,240
we see this here on the right hand side

446
00:18:08,240 --> 00:18:10,799
in this table

447
00:18:10,799 --> 00:18:13,039
we have for example interface ethernet

448
00:18:13,039 --> 00:18:16,080
bluetooth can and the list goes on

449
00:18:16,080 --> 00:18:17,679
and then we have the different sub

450
00:18:17,679 --> 00:18:19,039
interfaces here

451
00:18:19,039 --> 00:18:23,440
layer 2 tcp dhcp mqtt and so on

452
00:18:23,440 --> 00:18:25,919
and then we have the attack vector

453
00:18:25,919 --> 00:18:28,640
as well as the impact it's important to

454
00:18:28,640 --> 00:18:31,679
note that impact would depend on where

455
00:18:31,679 --> 00:18:34,160
this application or where this software

456
00:18:34,160 --> 00:18:36,400
would run in the end

457
00:18:36,400 --> 00:18:38,799
but just as an example we have inputted

458
00:18:38,799 --> 00:18:41,360
different impacts here to get an idea of

459
00:18:41,360 --> 00:18:44,480
what can occur if an attacker is able to

460
00:18:44,480 --> 00:18:46,720
successfully attack that particular

461
00:18:46,720 --> 00:18:48,559
interface

462
00:18:48,559 --> 00:18:50,559
so using the attack vector in that

463
00:18:50,559 --> 00:18:51,840
impact

464
00:18:51,840 --> 00:18:54,640
for example let's take a look at dhcp

465
00:18:54,640 --> 00:18:57,039
we see that the attack vector is network

466
00:18:57,039 --> 00:18:59,840
impact is major we can go to our table

467
00:18:59,840 --> 00:19:02,640
on left hand side we see network

468
00:19:02,640 --> 00:19:04,000
attack vector

469
00:19:04,000 --> 00:19:06,080
and impact is

470
00:19:06,080 --> 00:19:07,200
major

471
00:19:07,200 --> 00:19:09,440
then we have cal 4

472
00:19:09,440 --> 00:19:14,480
so we can assign cal4 to dhcp

473
00:19:14,640 --> 00:19:16,880
on the other hand for example ethernet

474
00:19:16,880 --> 00:19:20,240
l2 is local and moderate we'll look

475
00:19:20,240 --> 00:19:22,960
again on our table on left hand side we

476
00:19:22,960 --> 00:19:24,400
have local

477
00:19:24,400 --> 00:19:25,840
and moderate

478
00:19:25,840 --> 00:19:27,919
we see that this is cal 1

479
00:19:27,919 --> 00:19:30,000
so we can now assign cal 1 to that

480
00:19:30,000 --> 00:19:31,039
interface

481
00:19:31,039 --> 00:19:32,720
so this helps us prioritize all the

482
00:19:32,720 --> 00:19:34,799
different targets in

483
00:19:34,799 --> 00:19:37,280
our software

484
00:19:37,280 --> 00:19:39,280
in our next step now we have to define

485
00:19:39,280 --> 00:19:42,799
the fuzz testing strategies

486
00:19:42,960 --> 00:19:44,799
it's important to note that fuzz testing

487
00:19:44,799 --> 00:19:47,440
is a negative test approach so there's

488
00:19:47,440 --> 00:19:50,320
essentially an infinite input space

489
00:19:50,320 --> 00:19:53,120
and we have to decide how to test when

490
00:19:53,120 --> 00:19:55,280
to test how long to test or what to test

491
00:19:55,280 --> 00:19:57,280
and how to test

492
00:19:57,280 --> 00:19:59,120
and one way to help us

493
00:19:59,120 --> 00:20:01,520
answer those questions is to use the

494
00:20:01,520 --> 00:20:03,360
cals that we just defined on the

495
00:20:03,360 --> 00:20:05,200
previous slide

496
00:20:05,200 --> 00:20:08,000
and with the cows we can then align

497
00:20:08,000 --> 00:20:10,960
the available amount of time for testing

498
00:20:10,960 --> 00:20:13,039
to the different cows

499
00:20:13,039 --> 00:20:15,679
so an example here shows

500
00:20:15,679 --> 00:20:18,320
the cal four levels of cal and we have

501
00:20:18,320 --> 00:20:20,400
our fast testing number of hours or

502
00:20:20,400 --> 00:20:22,480
number of test cases

503
00:20:22,480 --> 00:20:24,640
so we can say that cal one requires

504
00:20:24,640 --> 00:20:26,400
eight hours of testing or one million

505
00:20:26,400 --> 00:20:29,360
test cases and cal 4 requires 80 hours

506
00:20:29,360 --> 00:20:32,240
of testing and 10 million test cases

507
00:20:32,240 --> 00:20:34,080
now these numbers are just an example

508
00:20:34,080 --> 00:20:35,919
and would need to be updated based on

509
00:20:35,919 --> 00:20:38,000
your target system and how much

510
00:20:38,000 --> 00:20:42,240
available time you have in your project

511
00:20:42,400 --> 00:20:43,840
but let's take an example from the

512
00:20:43,840 --> 00:20:46,320
previous slide where we had

513
00:20:46,320 --> 00:20:48,799
for example interface ethernet

514
00:20:48,799 --> 00:20:52,880
sub-interface tcp and dhcp

515
00:20:52,880 --> 00:20:55,919
tcp we had assigned cal 3

516
00:20:55,919 --> 00:20:57,600
which means that we should do 40 hours

517
00:20:57,600 --> 00:21:00,640
of testing or 5 million test cases

518
00:21:00,640 --> 00:21:03,840
and dhcp we had assigned cal4

519
00:21:03,840 --> 00:21:06,000
which means that we should do 80 hours

520
00:21:06,000 --> 00:21:09,600
of testing or 10 million test cases

521
00:21:09,600 --> 00:21:11,919
just to give an idea of how many test

522
00:21:11,919 --> 00:21:13,039
cases

523
00:21:13,039 --> 00:21:15,520
we could run using the defense six fuzz

524
00:21:15,520 --> 00:21:17,360
testing tool

525
00:21:17,360 --> 00:21:20,720
for these respective test suites for tcp

526
00:21:20,720 --> 00:21:23,600
in default full run configuration we

527
00:21:23,600 --> 00:21:26,080
have 9 million test cases with an

528
00:21:26,080 --> 00:21:29,039
average test time of 83 hours

529
00:21:29,039 --> 00:21:31,120
please note that these average test time

530
00:21:31,120 --> 00:21:33,919
depends on the communication

531
00:21:33,919 --> 00:21:37,120
workload the bandwidth

532
00:21:37,120 --> 00:21:38,400
the time it takes to process the

533
00:21:38,400 --> 00:21:40,720
messages on the target system

534
00:21:40,720 --> 00:21:43,280
and the host pc that's running defensive

535
00:21:43,280 --> 00:21:45,440
as well

536
00:21:45,440 --> 00:21:48,400
and then for our dhcp test suite we have

537
00:21:48,400 --> 00:21:50,799
10 million test cases in the full run

538
00:21:50,799 --> 00:21:54,000
with an average test time of 93 hours

539
00:21:54,000 --> 00:21:56,720
so looking at the cal

540
00:21:56,720 --> 00:21:59,200
at the top here we see that for dhcp

541
00:21:59,200 --> 00:22:00,480
cal4

542
00:22:00,480 --> 00:22:02,960
we pretty much do a full test run here

543
00:22:02,960 --> 00:22:05,440
10 million test cases or 90 hours

544
00:22:05,440 --> 00:22:08,320
uh here's 80 hours and 10 mm test cases

545
00:22:08,320 --> 00:22:11,760
and for the tcp we have cal 3

546
00:22:11,760 --> 00:22:13,919
which means we should do 40 hours or 5

547
00:22:13,919 --> 00:22:16,880
million test cases which is about half

548
00:22:16,880 --> 00:22:20,640
of what this test the full test run is

549
00:22:20,640 --> 00:22:24,000
so that helps us define the strategies

550
00:22:24,000 --> 00:22:25,760
and how much testing that should be done

551
00:22:25,760 --> 00:22:29,120
for the different interfaces

552
00:22:39,360 --> 00:22:41,600
let's take a quick look at how we can

553
00:22:41,600 --> 00:22:43,840
detect exceptions as mentioned there are

554
00:22:43,840 --> 00:22:45,280
two approaches

555
00:22:45,280 --> 00:22:47,679
in-band instrumentation and external

556
00:22:47,679 --> 00:22:49,360
instrumentation

557
00:22:49,360 --> 00:22:51,360
embed instrumentation we see here an

558
00:22:51,360 --> 00:22:53,600
example from defense six the fuzz

559
00:22:53,600 --> 00:22:54,880
testing tool

560
00:22:54,880 --> 00:22:56,400
where we can

561
00:22:56,400 --> 00:22:59,280
check this box to enable valid case

562
00:22:59,280 --> 00:23:01,120
instrumentation

563
00:23:01,120 --> 00:23:03,200
for external instrumentation we see that

564
00:23:03,200 --> 00:23:04,240
we can

565
00:23:04,240 --> 00:23:06,480
define a number of scripts that can be

566
00:23:06,480 --> 00:23:09,039
executed before a test case or after a

567
00:23:09,039 --> 00:23:10,559
test case is run

568
00:23:10,559 --> 00:23:11,520
to

569
00:23:11,520 --> 00:23:16,240
check the status of the target system

570
00:23:18,720 --> 00:23:21,120
finally we need to discuss how to manage

571
00:23:21,120 --> 00:23:22,640
the test results

572
00:23:22,640 --> 00:23:25,039
for example if the target application

573
00:23:25,039 --> 00:23:27,840
crashes we need to be able to restart

574
00:23:27,840 --> 00:23:29,919
and resume testing

575
00:23:29,919 --> 00:23:31,919
we need to define how to store the test

576
00:23:31,919 --> 00:23:34,240
results in the log files

577
00:23:34,240 --> 00:23:36,080
as well as at the end of the test run be

578
00:23:36,080 --> 00:23:37,840
able to provide those results back to

579
00:23:37,840 --> 00:23:40,880
the ci pipeline and have some criteria

580
00:23:40,880 --> 00:23:42,480
where we can then determine whether we

581
00:23:42,480 --> 00:23:46,159
should break the build or not

582
00:23:47,919 --> 00:23:50,559
and finally we have our fuzz testing

583
00:23:50,559 --> 00:23:52,799
environment

584
00:23:52,799 --> 00:23:54,960
so here we have jenkins as the

585
00:23:54,960 --> 00:23:56,480
automation server

586
00:23:56,480 --> 00:23:58,960
in a first step it triggers a build and

587
00:23:58,960 --> 00:24:01,760
executes zephyr on native posix as you

588
00:24:01,760 --> 00:24:04,320
can see here on the right hand side this

589
00:24:04,320 --> 00:24:06,880
is running on top of linux

590
00:24:06,880 --> 00:24:09,600
as a second step it triggers to run

591
00:24:09,600 --> 00:24:11,760
defense x which is the fuzz testing tool

592
00:24:11,760 --> 00:24:14,320
with a specific test plan for example

593
00:24:14,320 --> 00:24:17,039
tcp or http

594
00:24:17,039 --> 00:24:19,039
so we have these test plans

595
00:24:19,039 --> 00:24:21,679
prepared in advance

596
00:24:21,679 --> 00:24:23,840
and then defense 6 the fuzz testing tool

597
00:24:23,840 --> 00:24:26,320
as a third step here we'll send these

598
00:24:26,320 --> 00:24:28,400
fuzz messages to zephyr

599
00:24:28,400 --> 00:24:30,320
through the native posix

600
00:24:30,320 --> 00:24:32,640
running on the same linux system so all

601
00:24:32,640 --> 00:24:36,720
the testing is done on software

602
00:24:38,720 --> 00:24:40,799
on the next few slides we'll go through

603
00:24:40,799 --> 00:24:43,279
the practical steps of building the test

604
00:24:43,279 --> 00:24:45,360
environment for zephyr

605
00:24:45,360 --> 00:24:47,279
so first we have to prepare the test

606
00:24:47,279 --> 00:24:48,480
environment

607
00:24:48,480 --> 00:24:51,679
and we use the west tool

608
00:24:51,679 --> 00:24:53,760
to retrieve the latest zephyr project

609
00:24:53,760 --> 00:24:55,840
sources and you can see the commands

610
00:24:55,840 --> 00:24:59,440
here that we use on linux to do that

611
00:24:59,440 --> 00:25:02,000
we also need to install the zephyr sdk

612
00:25:02,000 --> 00:25:05,840
tool chain using these commands

613
00:25:10,640 --> 00:25:13,120
as a next step we have to set up our

614
00:25:13,120 --> 00:25:16,159
native posix networking environment

615
00:25:16,159 --> 00:25:19,120
and the way we do that is we create this

616
00:25:19,120 --> 00:25:21,840
z-a-t-h interface

617
00:25:21,840 --> 00:25:24,320
for the native posix board on zephyr

618
00:25:24,320 --> 00:25:26,720
we use the net tools scripts for the

619
00:25:26,720 --> 00:25:28,880
network setup to configure for example

620
00:25:28,880 --> 00:25:32,799
the ip address for the native posix

621
00:25:32,799 --> 00:25:34,720
and this is running on the same linux

622
00:25:34,720 --> 00:25:36,559
host

623
00:25:36,559 --> 00:25:39,200
as our fuzz testing tool

624
00:25:39,200 --> 00:25:41,440
so we use the net tools here do the

625
00:25:41,440 --> 00:25:42,640
setup

626
00:25:42,640 --> 00:25:43,840
and then

627
00:25:43,840 --> 00:25:46,480
we need to have a target

628
00:25:46,480 --> 00:25:48,799
software an application running that we

629
00:25:48,799 --> 00:25:50,720
will fuzz test against

630
00:25:50,720 --> 00:25:52,400
in this case we use the echo server

631
00:25:52,400 --> 00:25:53,840
application

632
00:25:53,840 --> 00:25:57,840
and this is how we build it and run it

633
00:26:02,080 --> 00:26:03,760
now we have our target application

634
00:26:03,760 --> 00:26:06,880
running we need to configure our

635
00:26:06,880 --> 00:26:10,240
file testing tool defensive

636
00:26:10,240 --> 00:26:15,240
we set the target ip address to 192.022

637
00:26:16,159 --> 00:26:18,799
we also can save our configuration in

638
00:26:18,799 --> 00:26:20,799
the fast testing tool as a test plan

639
00:26:20,799 --> 00:26:22,960
file which can later on be executed via

640
00:26:22,960 --> 00:26:26,240
scripting or called from a ci automation

641
00:26:26,240 --> 00:26:27,520
server

642
00:26:27,520 --> 00:26:28,799
we can also save the suite

643
00:26:28,799 --> 00:26:30,240
configurations

644
00:26:30,240 --> 00:26:32,960
as a settings file

645
00:26:32,960 --> 00:26:35,440
what we do now is we can then execute

646
00:26:35,440 --> 00:26:37,679
fuzz testing using this pre-made test

647
00:26:37,679 --> 00:26:40,320
plan we have the ip address configured

648
00:26:40,320 --> 00:26:42,159
for a target system

649
00:26:42,159 --> 00:26:44,000
and we can also have different ip

650
00:26:44,000 --> 00:26:45,600
addresses configured in different test

651
00:26:45,600 --> 00:26:49,200
plans so we can run testing in parallel

652
00:26:49,200 --> 00:26:51,520
just to show you how the command for

653
00:26:51,520 --> 00:26:54,159
executing defense 6 looks like you see

654
00:26:54,159 --> 00:26:56,720
it here where we then specify

655
00:26:56,720 --> 00:26:58,960
the test plan that we want to use

656
00:26:58,960 --> 00:27:02,720
as well as the target ip address

657
00:27:05,440 --> 00:27:07,840
and finally once we have these previous

658
00:27:07,840 --> 00:27:09,919
steps performed manually to make sure

659
00:27:09,919 --> 00:27:12,080
everything is working we can now add

660
00:27:12,080 --> 00:27:14,960
them to our jenkins pipeline

661
00:27:14,960 --> 00:27:16,960
so we will add these steps

662
00:27:16,960 --> 00:27:18,799
as i showed in that simplified ci

663
00:27:18,799 --> 00:27:21,120
pipeline earlier we would download

664
00:27:21,120 --> 00:27:23,919
latest sources we will build zephyr we

665
00:27:23,919 --> 00:27:25,919
set up our target application the echo

666
00:27:25,919 --> 00:27:26,960
server

667
00:27:26,960 --> 00:27:29,679
we then execute fuzz testing using the

668
00:27:29,679 --> 00:27:32,000
previously configured test plan

669
00:27:32,000 --> 00:27:34,000
or we can use the defense x jenkins

670
00:27:34,000 --> 00:27:35,039
plugin

671
00:27:35,039 --> 00:27:37,440
and load that settings file

672
00:27:37,440 --> 00:27:38,640
and you can see it here on the right

673
00:27:38,640 --> 00:27:40,720
hand side we can add this post build

674
00:27:40,720 --> 00:27:43,200
action step and just configure

675
00:27:43,200 --> 00:27:46,240
defensives as well as the test suite to

676
00:27:46,240 --> 00:27:49,240
use

677
00:27:49,919 --> 00:27:52,640
so by following these steps

678
00:27:52,640 --> 00:27:54,399
and establishing a fast testing

679
00:27:54,399 --> 00:27:57,279
environment we can now perform

680
00:27:57,279 --> 00:27:59,679
fuzz testing in a ci pipeline on

681
00:27:59,679 --> 00:28:00,840
software

682
00:28:00,840 --> 00:28:04,559
only this allows us to also perform

683
00:28:04,559 --> 00:28:06,720
parallel testing

684
00:28:06,720 --> 00:28:09,200
imagine that we can spin up for example

685
00:28:09,200 --> 00:28:12,080
10 instances of zephyr

686
00:28:12,080 --> 00:28:14,399
and then perform fuzz testing on

687
00:28:14,399 --> 00:28:15,919
different interfaces and different

688
00:28:15,919 --> 00:28:18,559
target applications in parallel

689
00:28:18,559 --> 00:28:20,640
this would be much more efficient than

690
00:28:20,640 --> 00:28:23,120
performing testing on hardware we may

691
00:28:23,120 --> 00:28:26,559
have limited availability

692
00:28:26,880 --> 00:28:28,480
the second thing is

693
00:28:28,480 --> 00:28:30,399
we also have to

694
00:28:30,399 --> 00:28:33,279
define how we can detect exceptions and

695
00:28:33,279 --> 00:28:35,840
issues on the target system

696
00:28:35,840 --> 00:28:38,960
as i mentioned if we now have control of

697
00:28:38,960 --> 00:28:42,159
the software only target

698
00:28:42,159 --> 00:28:45,600
we can include various instrumentation

699
00:28:45,600 --> 00:28:48,240
where we can monitor for example the cpu

700
00:28:48,240 --> 00:28:52,080
usage or the memory usage of that target

701
00:28:52,080 --> 00:28:53,279
application

702
00:28:53,279 --> 00:28:55,440
and this can allow us to detect any

703
00:28:55,440 --> 00:28:58,799
abnormal activities

704
00:28:58,799 --> 00:29:01,840
the third thing here also to discuss is

705
00:29:01,840 --> 00:29:02,880
that

706
00:29:02,880 --> 00:29:04,720
while we can perform

707
00:29:04,720 --> 00:29:06,559
a majority of testing

708
00:29:06,559 --> 00:29:08,960
using software only

709
00:29:08,960 --> 00:29:12,000
there are some testing that requires

710
00:29:12,000 --> 00:29:14,000
hardware especially

711
00:29:14,000 --> 00:29:16,480
if we want to test the lower layers of

712
00:29:16,480 --> 00:29:18,640
some of the communication protocols

713
00:29:18,640 --> 00:29:21,760
for example on bluetooth or can

714
00:29:21,760 --> 00:29:23,840
then we would need to have a hardware

715
00:29:23,840 --> 00:29:25,360
dongle

716
00:29:25,360 --> 00:29:27,840
or a hardware component where we perform

717
00:29:27,840 --> 00:29:29,200
testing

718
00:29:29,200 --> 00:29:30,960
but it's important to note that we can

719
00:29:30,960 --> 00:29:34,080
perform most of the testing in software

720
00:29:34,080 --> 00:29:36,080
and then have just a reduced scope of

721
00:29:36,080 --> 00:29:38,320
testing using hardware so that we can be

722
00:29:38,320 --> 00:29:41,279
as efficient as possible

723
00:29:41,279 --> 00:29:43,919
so that brings me to the last slide with

724
00:29:43,919 --> 00:29:45,840
a call to action

725
00:29:45,840 --> 00:29:48,240
i like to ask everyone to investigate

726
00:29:48,240 --> 00:29:50,960
your existing ci pipelines analyze the

727
00:29:50,960 --> 00:29:53,200
target system that you want to fuzz test

728
00:29:53,200 --> 00:29:54,960
define the appropriate first testing

729
00:29:54,960 --> 00:29:56,080
strategies

730
00:29:56,080 --> 00:29:58,880
and finally build a test environment

731
00:29:58,880 --> 00:30:00,480
that allows you to integrate fuzz

732
00:30:00,480 --> 00:30:03,440
testing into your ci pipeline

733
00:30:03,440 --> 00:30:05,440
so with that i would like to thank you

734
00:30:05,440 --> 00:30:07,919
for your attention and i'm happy to take

735
00:30:07,919 --> 00:30:11,240
any questions

