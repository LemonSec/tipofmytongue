1
00:00:00,080 --> 00:00:16,909
[Music]

2
00:00:18,980 --> 00:00:21,130
thank you

3
00:00:21,130 --> 00:00:24,300
[Music]

4
00:00:24,300 --> 00:00:26,340
our next talk will be subjective and

5
00:00:26,340 --> 00:00:28,199
objective code similarity measures by

6
00:00:28,199 --> 00:00:31,080
weiner Schweitzer

7
00:00:31,080 --> 00:00:32,189
thank you

8
00:00:32,189 --> 00:00:33,660
[Applause]

9
00:00:33,660 --> 00:00:37,320
it's it's good to be back in person at

10
00:00:37,320 --> 00:00:39,620
balcon I'm very happy to be here

11
00:00:39,620 --> 00:00:41,940
so subjective and objective called

12
00:00:41,940 --> 00:00:44,660
similarity measure it does sound a bit

13
00:00:44,660 --> 00:00:49,800
vague a bit but we'll see uh basically

14
00:00:49,800 --> 00:00:51,840
two parts of the presentation but before

15
00:00:51,840 --> 00:00:54,780
I kind of just a few words I work for

16
00:00:54,780 --> 00:00:57,360
Cisco Talos I'm based in in Croatia I've

17
00:00:57,360 --> 00:00:59,820
been a sort of antivirus anti-malware

18
00:00:59,820 --> 00:01:05,360
industry for over 20 years

19
00:01:05,360 --> 00:01:09,180
and yeah so my day-to-day work involves

20
00:01:09,180 --> 00:01:11,520
processing quite a large number of

21
00:01:11,520 --> 00:01:13,680
malware samples to do some reverse

22
00:01:13,680 --> 00:01:15,540
engineering doing some research that

23
00:01:15,540 --> 00:01:17,100
then I can maybe share at the

24
00:01:17,100 --> 00:01:19,979
conferences such as such as Balkan

25
00:01:19,979 --> 00:01:23,700
so uh part of this presentation or at

26
00:01:23,700 --> 00:01:25,380
least research for the presentation was

27
00:01:25,380 --> 00:01:27,780
done by some other guys from my team

28
00:01:27,780 --> 00:01:31,080
especially the the bit around the

29
00:01:31,080 --> 00:01:33,840
research of the binary payloads of the

30
00:01:33,840 --> 00:01:36,780
actors we I'm going to talk about so I

31
00:01:36,780 --> 00:01:39,000
want to just give them a credit where

32
00:01:39,000 --> 00:01:40,979
the credit is due so not everything is

33
00:01:40,979 --> 00:01:44,460
done by myself there are other guys in

34
00:01:44,460 --> 00:01:46,799
in the team and I thank them for for

35
00:01:46,799 --> 00:01:50,159
this so agenda

36
00:01:50,159 --> 00:01:52,740
um we're gonna cover a couple of the

37
00:01:52,740 --> 00:01:54,840
threat actors that operated in South

38
00:01:54,840 --> 00:01:57,360
Asia with with the main kind of

39
00:01:57,360 --> 00:02:00,180
intention to okay so you will learn a

40
00:02:00,180 --> 00:02:01,920
little bit about them how they operate

41
00:02:01,920 --> 00:02:04,140
their own ttps

42
00:02:04,140 --> 00:02:07,799
but to talk about the case which I

43
00:02:07,799 --> 00:02:10,199
stumbled upon where I realized that some

44
00:02:10,199 --> 00:02:12,180
of the the code that these two groups

45
00:02:12,180 --> 00:02:15,120
that are basically opposing uh on the

46
00:02:15,120 --> 00:02:17,040
opposing side of the kind of political

47
00:02:17,040 --> 00:02:20,040
Spectrum are using and they're they're

48
00:02:20,040 --> 00:02:23,400
sharing some toolkits and so so from

49
00:02:23,400 --> 00:02:25,680
from that

50
00:02:25,680 --> 00:02:26,720
um

51
00:02:26,720 --> 00:02:30,300
realization I I went forward and I I

52
00:02:30,300 --> 00:02:33,500
wanted to know how would I measure

53
00:02:33,500 --> 00:02:35,940
objectively in you know sort of

54
00:02:35,940 --> 00:02:39,480
automated way similarities uh between

55
00:02:39,480 --> 00:02:42,599
some files I mean it's it's quite a an

56
00:02:42,599 --> 00:02:45,360
all the known project a problem but I

57
00:02:45,360 --> 00:02:47,519
just wanted to to go by myself because

58
00:02:47,519 --> 00:02:49,319
you know you have to reinvent the wheel

59
00:02:49,319 --> 00:02:51,599
or a wheel and keep Reinventing it all

60
00:02:51,599 --> 00:02:54,660
the time so I wanted to do it on this

61
00:02:54,660 --> 00:02:57,840
test set and so the second part of the

62
00:02:57,840 --> 00:02:59,819
presentation is really digging deeper

63
00:02:59,819 --> 00:03:03,780
into the idea of similarity and like how

64
00:03:03,780 --> 00:03:06,540
how it's done and how it can be scaled

65
00:03:06,540 --> 00:03:09,480
on a kind of larger set of malicious

66
00:03:09,480 --> 00:03:10,500
samples

67
00:03:10,500 --> 00:03:12,900
so let's start with the with our

68
00:03:12,900 --> 00:03:16,560
introduction into those two uh apt

69
00:03:16,560 --> 00:03:19,739
groups so one is called transparent

70
00:03:19,739 --> 00:03:22,200
tribe they we call them transparent

71
00:03:22,200 --> 00:03:24,420
tribe but they have many different names

72
00:03:24,420 --> 00:03:27,360
and they are allegedly based in Pakistan

73
00:03:27,360 --> 00:03:29,940
they have a special interest in India

74
00:03:29,940 --> 00:03:32,580
Afghanistan and Pakistan and they they

75
00:03:32,580 --> 00:03:35,040
are targeting various governmental

76
00:03:35,040 --> 00:03:39,000
groups uh military uh groups and and

77
00:03:39,000 --> 00:03:42,480
various uh organizations

78
00:03:42,480 --> 00:03:46,019
they as the final Payless they developed

79
00:03:46,019 --> 00:03:48,959
two main remote access Trojan one is

80
00:03:48,959 --> 00:03:51,900
called crimson red which is uh all

81
00:03:51,900 --> 00:03:53,879
programmed in C sharp it's relatively

82
00:03:53,879 --> 00:03:56,159
simple it does anything but you expect

83
00:03:56,159 --> 00:03:58,860
the remote access Trojan to do so once

84
00:03:58,860 --> 00:04:02,700
it's installed on the target system it

85
00:04:02,700 --> 00:04:04,920
allows the attackers to control it

86
00:04:04,920 --> 00:04:07,260
as any kind of remote Administration

87
00:04:07,260 --> 00:04:10,739
tool and recently to about two years ago

88
00:04:10,739 --> 00:04:13,500
well we discovered that they started

89
00:04:13,500 --> 00:04:17,040
using a c native code and and they they

90
00:04:17,040 --> 00:04:20,459
they use a payload called oblique rat

91
00:04:20,459 --> 00:04:23,400
and the oblique rat is seen in more also

92
00:04:23,400 --> 00:04:26,940
highly targeted attacks in terms of

93
00:04:26,940 --> 00:04:29,699
their own infrastructure they they use

94
00:04:29,699 --> 00:04:33,060
this sort of two-pronged approach one is

95
00:04:33,060 --> 00:04:37,139
they try to find the organizational the

96
00:04:37,139 --> 00:04:39,180
website of the organizations that like

97
00:04:39,180 --> 00:04:41,639
military organization government and

98
00:04:41,639 --> 00:04:45,240
then they copy those websites and

99
00:04:45,240 --> 00:04:48,000
register domain that sound and similar

100
00:04:48,000 --> 00:04:51,240
to the the official ones so that's

101
00:04:51,240 --> 00:04:53,880
that's the one way they're trying to to

102
00:04:53,880 --> 00:04:55,139
do

103
00:04:55,139 --> 00:04:58,940
so it is things such as think tanks

104
00:04:58,940 --> 00:05:02,639
space research organizations and as you

105
00:05:02,639 --> 00:05:04,680
can see on the top World maybe you can't

106
00:05:04,680 --> 00:05:08,759
see but it's just they just use the uh

107
00:05:08,759 --> 00:05:12,840
HD track to copy the the code and to

108
00:05:12,840 --> 00:05:15,720
create that like a clone of the official

109
00:05:15,720 --> 00:05:19,340
site and the second

110
00:05:19,340 --> 00:05:22,880
approach they they are they

111
00:05:22,880 --> 00:05:26,600
register like file sharing like

112
00:05:26,600 --> 00:05:29,360
malicious domains such as

113
00:05:29,360 --> 00:05:32,699
drivetransfer.com mediashare.cc that

114
00:05:32,699 --> 00:05:35,039
look pretty legit in terms of the naming

115
00:05:35,039 --> 00:05:38,400
but they also uh own them and then

116
00:05:38,400 --> 00:05:39,720
that's that's where they host their

117
00:05:39,720 --> 00:05:41,820
their malicious documents and here

118
00:05:41,820 --> 00:05:44,160
here's one of the examples one of the

119
00:05:44,160 --> 00:05:45,900
interesting thing is like at the bottom

120
00:05:45,900 --> 00:05:47,419
it it

121
00:05:47,419 --> 00:05:50,580
instructs you how to use it please copy

122
00:05:50,580 --> 00:05:52,680
link and then paste it on Google search

123
00:05:52,680 --> 00:05:55,740
so don't click from the the mail and

124
00:05:55,740 --> 00:05:57,120
make sure you download it through your

125
00:05:57,120 --> 00:05:59,580
laptop so you know just just give you

126
00:05:59,580 --> 00:06:02,580
some hints on what what sort of uh

127
00:06:02,580 --> 00:06:05,460
Hardware are there are they targeting

128
00:06:05,460 --> 00:06:08,280
here mostly you know likely some sort of

129
00:06:08,280 --> 00:06:09,900
PCS

130
00:06:09,900 --> 00:06:12,240
I kind of already mentioned that they

131
00:06:12,240 --> 00:06:14,340
have defense teams campaign conference

132
00:06:14,340 --> 00:06:18,660
attendees some job adverts and and so on

133
00:06:18,660 --> 00:06:21,600
uh so we'll look at a couple of examples

134
00:06:21,600 --> 00:06:24,300
so here's a here's an email where they

135
00:06:24,300 --> 00:06:27,660
attached a malicious Excel file and this

136
00:06:27,660 --> 00:06:29,580
is a phishing email that was sent to

137
00:06:29,580 --> 00:06:32,280
defense advisors which were stationed in

138
00:06:32,280 --> 00:06:35,100
Indian embassies in Southeast Asia and

139
00:06:35,100 --> 00:06:37,520
eventually if you open this Excel

140
00:06:37,520 --> 00:06:39,479
spreadsheet you will have the Visual

141
00:06:39,479 --> 00:06:41,940
Basic for application macro which will

142
00:06:41,940 --> 00:06:43,759
eventually develop

143
00:06:43,759 --> 00:06:46,860
deliver this Crimson Rock here's a

144
00:06:46,860 --> 00:06:48,139
here's another

145
00:06:48,139 --> 00:06:51,539
theme that seems to come from the

146
00:06:51,539 --> 00:06:53,880
Ministry of Foreign Affairs of Republic

147
00:06:53,880 --> 00:06:56,880
of Iran which which seems to come as

148
00:06:56,880 --> 00:06:58,560
some kind of British High commission

149
00:06:58,560 --> 00:07:03,720
press release which warns whoever is the

150
00:07:03,720 --> 00:07:05,759
recipient I think in this case it was it

151
00:07:05,759 --> 00:07:09,180
was targeted on on Indian government is

152
00:07:09,180 --> 00:07:12,020
that some somebody has described

153
00:07:12,020 --> 00:07:15,180
Iranian organization as a terrorist

154
00:07:15,180 --> 00:07:17,340
organization and this is unprecedented

155
00:07:17,340 --> 00:07:20,220
and so on so the lures seem to be taken

156
00:07:20,220 --> 00:07:23,160
from the original and real documents but

157
00:07:23,160 --> 00:07:25,740
when you open those documents

158
00:07:25,740 --> 00:07:28,139
what you'll have is the Visual Basic for

159
00:07:28,139 --> 00:07:31,199
application code which is the more or

160
00:07:31,199 --> 00:07:33,780
less subject of the the research on

161
00:07:33,780 --> 00:07:36,180
similarity which I started but this

162
00:07:36,180 --> 00:07:39,360
research can be applied to any text

163
00:07:39,360 --> 00:07:41,699
files but it also can be applied to to

164
00:07:41,699 --> 00:07:44,340
Binary binary code and binary files I

165
00:07:44,340 --> 00:07:48,240
think two two major things to notice on

166
00:07:48,240 --> 00:07:50,880
this code I mean we are not going to to

167
00:07:50,880 --> 00:07:53,099
dig too too much deeper but what it does

168
00:07:53,099 --> 00:07:55,560
it sets up some directories and it sets

169
00:07:55,560 --> 00:07:59,900
up some uh variable names eventually uh

170
00:07:59,900 --> 00:08:03,599
the first Arrow points to the user form

171
00:08:03,599 --> 00:08:05,940
you can Define user forms in Visual

172
00:08:05,940 --> 00:08:08,160
Basic for application code where user

173
00:08:08,160 --> 00:08:10,740
can interact with in this case we have a

174
00:08:10,740 --> 00:08:13,979
hidden user form and a user form has a

175
00:08:13,979 --> 00:08:17,099
text box a field and textbook field

176
00:08:17,099 --> 00:08:19,860
contains some text which is which is

177
00:08:19,860 --> 00:08:22,319
separated by a separator character in

178
00:08:22,319 --> 00:08:24,660
this case is zero and and basically

179
00:08:24,660 --> 00:08:27,840
malware because these huge text

180
00:08:27,840 --> 00:08:30,419
characters removes the zeros and then

181
00:08:30,419 --> 00:08:33,120
creates a binary file from it and then

182
00:08:33,120 --> 00:08:34,919
the binary file is saved into a

183
00:08:34,919 --> 00:08:36,839
particular location you just executed

184
00:08:36,839 --> 00:08:39,320
it's kind of a simple thing the two

185
00:08:39,320 --> 00:08:42,240
characteristics here is using this user

186
00:08:42,240 --> 00:08:45,180
form which is a bit unusual the reason

187
00:08:45,180 --> 00:08:47,519
why they might be using the user form is

188
00:08:47,519 --> 00:08:50,459
when you run some macro analysis tools

189
00:08:50,459 --> 00:08:52,980
such as all all a VBA for example which

190
00:08:52,980 --> 00:08:55,080
is like the standard tool you use to

191
00:08:55,080 --> 00:08:56,940
dump the Visual Basic application code

192
00:08:56,940 --> 00:09:00,180
from Doc office documents you won't see

193
00:09:00,180 --> 00:09:03,180
this user user form by default so you

194
00:09:03,180 --> 00:09:05,160
don't know what the what's the what's

195
00:09:05,160 --> 00:09:07,740
contained in it and the second thing is

196
00:09:07,740 --> 00:09:09,320
they are using this

197
00:09:09,320 --> 00:09:12,779
relatively simple uh loop for each Loop

198
00:09:12,779 --> 00:09:16,560
to create from a string they create a

199
00:09:16,560 --> 00:09:19,800
byte array and then they can that binary

200
00:09:19,800 --> 00:09:21,959
byte array can only be saved into a file

201
00:09:21,959 --> 00:09:24,480
so two characteristics that that kind of

202
00:09:24,480 --> 00:09:27,060
stands out so this is the the

203
00:09:27,060 --> 00:09:29,339
transparent tribe group the second group

204
00:09:29,339 --> 00:09:34,680
is the donut group The Donut group is is

205
00:09:34,680 --> 00:09:36,660
like I said they are opposing so they

206
00:09:36,660 --> 00:09:39,120
are most alleged to be from India and

207
00:09:39,120 --> 00:09:41,040
they also have interest in South Asia

208
00:09:41,040 --> 00:09:44,339
Pakistan China Iran West Africa and so

209
00:09:44,339 --> 00:09:46,820
on and they operate slightly different

210
00:09:46,820 --> 00:09:49,320
uh models they they are very much

211
00:09:49,320 --> 00:09:51,720
interested into Mobile and Droid based

212
00:09:51,720 --> 00:09:54,839
base malware and occasionally they they

213
00:09:54,839 --> 00:09:56,279
launch

214
00:09:56,279 --> 00:10:00,620
um they they launch some

215
00:10:01,760 --> 00:10:05,839
office-based macro uh PC based attacks

216
00:10:05,839 --> 00:10:08,580
and they they use some commodity rights

217
00:10:08,580 --> 00:10:11,279
rats remote access Trojans such as

218
00:10:11,279 --> 00:10:13,459
Warzone which is also known as Ave Maria

219
00:10:13,459 --> 00:10:16,740
uh again one one standard rat which

220
00:10:16,740 --> 00:10:19,260
which then if you use if you use those

221
00:10:19,260 --> 00:10:21,360
commodity ones then it's a little bit

222
00:10:21,360 --> 00:10:23,160
more difficult to attribute the attack

223
00:10:23,160 --> 00:10:26,220
to a particular actor if you if you

224
00:10:26,220 --> 00:10:28,740
create your own toolkit then immediately

225
00:10:28,740 --> 00:10:30,600
we can track you because you know you're

226
00:10:30,600 --> 00:10:32,880
the only organization so in in case of

227
00:10:32,880 --> 00:10:34,620
transparent tribe when you see crimson

228
00:10:34,620 --> 00:10:37,500
red anywhere you can you can be almost

229
00:10:37,500 --> 00:10:39,899
certain then this is a transparent tribe

230
00:10:39,899 --> 00:10:42,200
that they do that's doing the work

231
00:10:42,200 --> 00:10:45,180
the donut group

232
00:10:45,180 --> 00:10:45,920
um

233
00:10:45,920 --> 00:10:49,260
often relies on the exploits in Word

234
00:10:49,260 --> 00:10:52,620
documents so they don't always use

235
00:10:52,620 --> 00:10:56,279
Visual Basic for application code but

236
00:10:56,279 --> 00:10:58,620
we realize that in some cases they they

237
00:10:58,620 --> 00:11:02,399
started using it so here's an example of

238
00:11:02,399 --> 00:11:03,600
some

239
00:11:03,600 --> 00:11:05,060
telephone

240
00:11:05,060 --> 00:11:08,220
book from that seems to come from a

241
00:11:08,220 --> 00:11:09,779
Ministry of Foreign Affairs that was

242
00:11:09,779 --> 00:11:13,140
shared in one of one of the attacks so

243
00:11:13,140 --> 00:11:14,880
come back coming back to our Visual

244
00:11:14,880 --> 00:11:18,300
Basic for application code this is uh

245
00:11:18,300 --> 00:11:19,860
the code that was taken from one

246
00:11:19,860 --> 00:11:23,279
transparent tribe example from 2018 and

247
00:11:23,279 --> 00:11:25,140
and here we have the two staple

248
00:11:25,140 --> 00:11:27,899
characteristic the conversion the the

249
00:11:27,899 --> 00:11:31,980
usage of a text field or or some user

250
00:11:31,980 --> 00:11:33,540
form in this case that started with a

251
00:11:33,540 --> 00:11:36,959
text field which is separated by a comma

252
00:11:36,959 --> 00:11:38,480
which is then

253
00:11:38,480 --> 00:11:41,779
converted into binary array using C byte

254
00:11:41,779 --> 00:11:44,700
functions so again we have very similar

255
00:11:44,700 --> 00:11:46,740
to what we've seen before and then the

256
00:11:46,740 --> 00:11:49,560
other group early examples of their code

257
00:11:49,560 --> 00:11:51,480
is as you can see immediately like you

258
00:11:51,480 --> 00:11:53,040
look at two pieces of code and you see

259
00:11:53,040 --> 00:11:54,899
you know that they're not really related

260
00:11:54,899 --> 00:11:58,500
so it's it this one drops a dll and that

261
00:11:58,500 --> 00:12:00,720
dlls is then launched using the Run

262
00:12:00,720 --> 00:12:04,620
dll32 functions so a quite a bit

263
00:12:04,620 --> 00:12:06,540
different

264
00:12:06,540 --> 00:12:08,000
so

265
00:12:08,000 --> 00:12:11,100
again here's an example of a so-called

266
00:12:11,100 --> 00:12:13,200
hangover operation I think this is the

267
00:12:13,200 --> 00:12:18,380
first operation where we we have a donut

268
00:12:18,380 --> 00:12:22,200
using very much similar code so here

269
00:12:22,200 --> 00:12:24,899
again we have a text box separated by

270
00:12:24,899 --> 00:12:27,240
comma and converting with the with the

271
00:12:27,240 --> 00:12:29,040
byte array into an executable then

272
00:12:29,040 --> 00:12:32,399
that's that's then dropped on the disk

273
00:12:32,399 --> 00:12:35,600
um we have a case of donut from June

274
00:12:35,600 --> 00:12:38,399
2021 uh

275
00:12:38,399 --> 00:12:41,339
again they're setting up some variable

276
00:12:41,339 --> 00:12:42,600
names

277
00:12:42,600 --> 00:12:46,680
and saving it with a c byte into a file

278
00:12:46,680 --> 00:12:50,839
so again quite quite similar code

279
00:12:52,139 --> 00:12:54,600
this is the end end of the code and and

280
00:12:54,600 --> 00:12:57,180
we are coming to the so we call this

281
00:12:57,180 --> 00:12:59,399
campaigns as the user campaigns which we

282
00:12:59,399 --> 00:13:01,320
were not sure whether they are

283
00:13:01,320 --> 00:13:04,440
attributed to donut or some other other

284
00:13:04,440 --> 00:13:05,779
group

285
00:13:05,779 --> 00:13:09,600
and so we um

286
00:13:09,600 --> 00:13:11,940
we're trying to find out

287
00:13:11,940 --> 00:13:14,339
all the ttps they're using so they're

288
00:13:14,339 --> 00:13:16,860
using some direct reverse shell

289
00:13:16,860 --> 00:13:19,579
experimentation we found the number of

290
00:13:19,579 --> 00:13:24,120
binary payloads over a period of about

291
00:13:24,120 --> 00:13:27,060
um half a year which which started from

292
00:13:27,060 --> 00:13:30,180
very simple reverse Shell Code to more

293
00:13:30,180 --> 00:13:33,180
complex ones and and eventually created

294
00:13:33,180 --> 00:13:36,779
their own specific rat that uses the

295
00:13:36,779 --> 00:13:38,399
command and control infrastructure that

296
00:13:38,399 --> 00:13:40,680
was previously used by Warzone and NJ

297
00:13:40,680 --> 00:13:44,279
rat so that points out to Donut the VB

298
00:13:44,279 --> 00:13:46,760
code points out to some other

299
00:13:46,760 --> 00:13:50,639
organization so when we discovered these

300
00:13:50,639 --> 00:13:53,940
files there were some Twitter feed or

301
00:13:53,940 --> 00:13:55,560
two groups on Twitter who were like

302
00:13:55,560 --> 00:13:57,980
saying is either a donut or Sidewinder

303
00:13:57,980 --> 00:14:01,920
Sidewinder is again an Indian group that

304
00:14:01,920 --> 00:14:04,380
that's attributed to India by some

305
00:14:04,380 --> 00:14:08,220
vendors and so I wasn't I wasn't sure I

306
00:14:08,220 --> 00:14:10,500
I I started working on it and I'm

307
00:14:10,500 --> 00:14:12,300
thinking okay so this is Sidewinder

308
00:14:12,300 --> 00:14:14,639
whatever this is how do I know and

309
00:14:14,639 --> 00:14:16,800
slowly you you build a slightly

310
00:14:16,800 --> 00:14:19,620
different picture there are some other

311
00:14:19,620 --> 00:14:22,620
kind of cases here and there are some

312
00:14:22,620 --> 00:14:25,380
people such as Peter Cruiser who is who

313
00:14:25,380 --> 00:14:27,779
owns quite a quite a big incident

314
00:14:27,779 --> 00:14:31,980
response company in in Denmark and who

315
00:14:31,980 --> 00:14:34,200
who was like contributed to Donuts so

316
00:14:34,200 --> 00:14:37,019
you know first I was thinking okay maybe

317
00:14:37,019 --> 00:14:41,040
it's it's one vendor and one one actor

318
00:14:41,040 --> 00:14:43,079
and now you know we we went to a

319
00:14:43,079 --> 00:14:46,500
completely different one and uh so it's

320
00:14:46,500 --> 00:14:48,600
very difficult this sort of for the

321
00:14:48,600 --> 00:14:50,760
whole job of attributing certain attacks

322
00:14:50,760 --> 00:14:53,820
to some individual actors because of

323
00:14:53,820 --> 00:14:54,660
course

324
00:14:54,660 --> 00:14:57,959
somebody who's a skilled actor can

325
00:14:57,959 --> 00:15:00,120
really easily emulate somebody else's

326
00:15:00,120 --> 00:15:02,940
tactics and techniques so in this case

327
00:15:02,940 --> 00:15:05,579
we were we were like it's one one or the

328
00:15:05,579 --> 00:15:07,920
other when you look at the

329
00:15:07,920 --> 00:15:11,279
Visual Basic for application code so

330
00:15:11,279 --> 00:15:13,380
which is definitely not contributed to

331
00:15:13,380 --> 00:15:15,300
transparent tribes so remember the first

332
00:15:15,300 --> 00:15:18,000
group is transparent tribe they they are

333
00:15:18,000 --> 00:15:20,279
allegedly linked or are working in

334
00:15:20,279 --> 00:15:22,800
Pakistan and the other guys are not are

335
00:15:22,800 --> 00:15:25,320
like on the other side of the the kind

336
00:15:25,320 --> 00:15:26,519
of playing field

337
00:15:26,519 --> 00:15:29,699
and so here we we have some setting up

338
00:15:29,699 --> 00:15:31,560
the variables at the beginning we had

339
00:15:31,560 --> 00:15:34,560
the user form with the text box which is

340
00:15:34,560 --> 00:15:37,019
separated by some character and we had

341
00:15:37,019 --> 00:15:40,740
the the C byte function so again very

342
00:15:40,740 --> 00:15:44,519
much similar code is is being used and

343
00:15:44,519 --> 00:15:46,620
so we which kind of brought us to the

344
00:15:46,620 --> 00:15:49,560
idea that one group which maybe an

345
00:15:49,560 --> 00:15:51,420
Indian group is emulating this other

346
00:15:51,420 --> 00:15:56,699
group perhaps to hide their own uh ttps

347
00:15:56,699 --> 00:15:59,760
so what I did is like you quickly go on

348
00:15:59,760 --> 00:16:02,579
on virus total which is like de facto

349
00:16:02,579 --> 00:16:05,160
standard for finding new malware samples

350
00:16:05,160 --> 00:16:07,320
and new campaigns and remember there

351
00:16:07,320 --> 00:16:10,139
were two variable names this BTS gohra

352
00:16:10,139 --> 00:16:12,839
and so I created like some rules which

353
00:16:12,839 --> 00:16:15,139
was which as the new files are coming in

354
00:16:15,139 --> 00:16:18,000
the Yara rules which are like this sort

355
00:16:18,000 --> 00:16:21,000
of string matching ability on the binary

356
00:16:21,000 --> 00:16:24,480
files will will give me some results and

357
00:16:24,480 --> 00:16:27,600
so I came up with a number of uh the

358
00:16:27,600 --> 00:16:29,940
very

359
00:16:29,940 --> 00:16:32,880
not similar but very specific files that

360
00:16:32,880 --> 00:16:36,300
will have these variable names and so I

361
00:16:36,300 --> 00:16:37,860
realized that this is basically too

362
00:16:37,860 --> 00:16:39,899
specific if I wanted to catch similar

363
00:16:39,899 --> 00:16:43,019
samples I needed to have some other uh

364
00:16:43,019 --> 00:16:45,060
characteristics so so I came up with

365
00:16:45,060 --> 00:16:50,519
remember this text box says uh C byte s

366
00:16:50,519 --> 00:16:52,980
byte a different text which will which

367
00:16:52,980 --> 00:16:56,220
were common for all of the VBA code that

368
00:16:56,220 --> 00:16:58,639
that we're trying to catch

369
00:16:58,639 --> 00:17:02,459
and in addition to that I also uh if you

370
00:17:02,459 --> 00:17:04,679
remember there is a text field that

371
00:17:04,679 --> 00:17:07,980
contains some binary file uh in in this

372
00:17:07,980 --> 00:17:10,919
case in the case of SD user campaigns

373
00:17:10,919 --> 00:17:13,140
that the binary files wouldn't start

374
00:17:13,140 --> 00:17:15,660
with the MZ which is a like a typical

375
00:17:15,660 --> 00:17:18,179
thing but with it was a it was a zip

376
00:17:18,179 --> 00:17:20,880
file which would be then put on the hard

377
00:17:20,880 --> 00:17:23,339
drive unzipped on the hard drive and

378
00:17:23,339 --> 00:17:25,079
then you have the binary files from

379
00:17:25,079 --> 00:17:28,620
there and that's why we have 8075 at the

380
00:17:28,620 --> 00:17:31,520
beginning which is the PK

381
00:17:31,520 --> 00:17:34,140
and so the condition is okay I was

382
00:17:34,140 --> 00:17:35,940
looking for all the files which are

383
00:17:35,940 --> 00:17:37,980
smaller than 10 megabytes and that

384
00:17:37,980 --> 00:17:40,100
starts with

385
00:17:40,100 --> 00:17:43,620
d0cf11 e0 which which is the beginning

386
00:17:43,620 --> 00:17:47,340
of the OLED 2 file the format of excel

387
00:17:47,340 --> 00:17:50,400
Excel and and Word Documents and so and

388
00:17:50,400 --> 00:17:53,400
I come up with more and more of these

389
00:17:53,400 --> 00:17:54,380
um

390
00:17:54,380 --> 00:17:57,059
these samples and finally when we're

391
00:17:57,059 --> 00:17:59,400
looking for the payloads of SD user

392
00:17:59,400 --> 00:18:01,320
group and why we call these guys as the

393
00:18:01,320 --> 00:18:05,340
users is that they had a a debug string

394
00:18:05,340 --> 00:18:07,799
within the file which pointed to a

395
00:18:07,799 --> 00:18:10,500
particular folder see users as the user

396
00:18:10,500 --> 00:18:13,320
source so for any binary implants they

397
00:18:13,320 --> 00:18:15,299
were creating you will have these

398
00:18:15,299 --> 00:18:17,100
strings in those files and it was very

399
00:18:17,100 --> 00:18:19,679
very easy to discover and that's how we

400
00:18:19,679 --> 00:18:22,140
could go back in time and we realized

401
00:18:22,140 --> 00:18:24,240
how they started uploading these new

402
00:18:24,240 --> 00:18:26,340
implants to to

403
00:18:26,340 --> 00:18:30,179
um to to the the virus total to see how

404
00:18:30,179 --> 00:18:33,360
many anti-malware engines are detecting

405
00:18:33,360 --> 00:18:35,760
these files over time

406
00:18:35,760 --> 00:18:39,360
okay so uh this is this was the really

407
00:18:39,360 --> 00:18:42,539
quick introduction into those two groups

408
00:18:42,539 --> 00:18:45,120
that operate in South Asia and so the

409
00:18:45,120 --> 00:18:47,760
next thing and sort of addition to the

410
00:18:47,760 --> 00:18:50,520
the the the the initial research was

411
00:18:50,520 --> 00:18:53,520
like how do we because when we look at

412
00:18:53,520 --> 00:18:55,080
the two pieces of code we can

413
00:18:55,080 --> 00:18:57,480
immediately see they are similar but how

414
00:18:57,480 --> 00:19:00,900
can the machine uh decide that something

415
00:19:00,900 --> 00:19:04,980
is very similar so my plan was uh that

416
00:19:04,980 --> 00:19:07,140
fight to find some actually not to find

417
00:19:07,140 --> 00:19:10,320
to learn uh which objective code

418
00:19:10,320 --> 00:19:13,260
similarity measures are often used with

419
00:19:13,260 --> 00:19:16,020
the intention to find new samples and to

420
00:19:16,020 --> 00:19:18,720
be able to Cluster malicious files you

421
00:19:18,720 --> 00:19:21,120
know you you always have to keep in mind

422
00:19:21,120 --> 00:19:24,059
that that the number of new malicious

423
00:19:24,059 --> 00:19:25,679
samples that that the anti-malware

424
00:19:25,679 --> 00:19:27,720
companies are discovering every day is

425
00:19:27,720 --> 00:19:30,179
around about 1 million of unique new

426
00:19:30,179 --> 00:19:32,400
samples so so there's a quite a large

427
00:19:32,400 --> 00:19:34,500
number of of files that we need to

428
00:19:34,500 --> 00:19:38,280
process and so so being able to find

429
00:19:38,280 --> 00:19:40,740
similar one quite quickly is very

430
00:19:40,740 --> 00:19:42,900
important when you process large amounts

431
00:19:42,900 --> 00:19:46,380
of data and it turns out that one of the

432
00:19:46,380 --> 00:19:48,480
kind of the the Staples of finding

433
00:19:48,480 --> 00:19:51,840
similarities between any strings and and

434
00:19:51,840 --> 00:19:54,900
files it goes back to well almost like

435
00:19:54,900 --> 00:19:57,179
primary school maybe High School all

436
00:19:57,179 --> 00:19:58,380
right

437
00:19:58,380 --> 00:20:01,740
and so there's this notion of uh

438
00:20:01,740 --> 00:20:05,640
Jacquard index we which which you know

439
00:20:05,640 --> 00:20:07,559
but by chance it was it wasn't

440
00:20:07,559 --> 00:20:10,620
discovered by the French uh Man Called

441
00:20:10,620 --> 00:20:13,080
Paul zakar but it was discovered by some

442
00:20:13,080 --> 00:20:15,240
uh I think it was it was an American

443
00:20:15,240 --> 00:20:18,360
person who wasn't a mathematician or at

444
00:20:18,360 --> 00:20:21,480
all sometimes in the 19th century and it

445
00:20:21,480 --> 00:20:24,120
was also independently discovered by

446
00:20:24,120 --> 00:20:28,380
tanimoto uh in Japan so sometimes

447
00:20:28,380 --> 00:20:30,059
Jacquard similarity is also called

448
00:20:30,059 --> 00:20:34,200
tanimoto index or tanimoto similarity uh

449
00:20:34,200 --> 00:20:37,400
and it's it's basically very simple uh

450
00:20:37,400 --> 00:20:41,220
set math you you will have you have like

451
00:20:41,220 --> 00:20:43,559
two sets and you take the intersection

452
00:20:43,559 --> 00:20:46,080
of the two sets and divide it by divided

453
00:20:46,080 --> 00:20:49,320
by the union of two sets and so the

454
00:20:49,320 --> 00:20:51,360
measure of this is just show you how how

455
00:20:51,360 --> 00:20:53,940
many common elements those two sets they

456
00:20:53,940 --> 00:20:56,820
have right so on a simple example we

457
00:20:56,820 --> 00:21:00,240
have two sets here so going back to the

458
00:21:00,240 --> 00:21:03,299
the primary school math we we have uh

459
00:21:03,299 --> 00:21:05,580
Jacquard coefficient which shows how

460
00:21:05,580 --> 00:21:07,980
many common elements they have so here

461
00:21:07,980 --> 00:21:10,260
we have one set with six elements we

462
00:21:10,260 --> 00:21:12,480
have the second set with five elements

463
00:21:12,480 --> 00:21:15,120
overall there are nine unique elements

464
00:21:15,120 --> 00:21:18,000
here and the common elements are two I

465
00:21:18,000 --> 00:21:20,700
mean five and six in this case so we

466
00:21:20,700 --> 00:21:24,240
have Jakarta coefficient is just like

467
00:21:24,240 --> 00:21:27,419
how similar are those two sets with you

468
00:21:27,419 --> 00:21:30,960
know two two out of nine or or how far

469
00:21:30,960 --> 00:21:33,919
away are those two sets which is seven

470
00:21:33,919 --> 00:21:39,980
of nine seven ninths so one one minus

471
00:21:39,980 --> 00:21:42,299
Jacquard coefficient will give you the

472
00:21:42,299 --> 00:21:44,340
card distance essentially that's the

473
00:21:44,340 --> 00:21:47,520
that's the function uh of course that

474
00:21:47,520 --> 00:21:49,620
sounds super similar super simple and it

475
00:21:49,620 --> 00:21:52,620
is but the the the complicated part is

476
00:21:52,620 --> 00:21:54,960
like how when you've given two binary

477
00:21:54,960 --> 00:21:57,600
files how do you how do you choose those

478
00:21:57,600 --> 00:21:59,039
characteristics how do you choose

479
00:21:59,039 --> 00:22:01,559
elements of the sets and if there are

480
00:22:01,559 --> 00:22:03,539
thousands of elements of each set or

481
00:22:03,539 --> 00:22:05,280
hundreds of thousands of elements of

482
00:22:05,280 --> 00:22:07,919
each set how do you find the something

483
00:22:07,919 --> 00:22:10,380
that's really quickly comes to show you

484
00:22:10,380 --> 00:22:14,460
uh on millions of files uh which which

485
00:22:14,460 --> 00:22:17,100
files are similar for investigations

486
00:22:17,100 --> 00:22:19,740
so and and that's where we come to this

487
00:22:19,740 --> 00:22:23,880
idea of of Como Gore of complexity uh

488
00:22:23,880 --> 00:22:27,120
which is just like a measure of

489
00:22:27,120 --> 00:22:30,179
how how can you describe one program

490
00:22:30,179 --> 00:22:33,480
with another uh and so so this other

491
00:22:33,480 --> 00:22:38,580
program is is is this sort of uh

492
00:22:38,820 --> 00:22:40,799
between those two files between those

493
00:22:40,799 --> 00:22:43,500
two programs and but it also leads to a

494
00:22:43,500 --> 00:22:44,940
measure called normalized information

495
00:22:44,940 --> 00:22:47,820
distance which unfortunately is proved

496
00:22:47,820 --> 00:22:50,179
to be non-computable or semi-computable

497
00:22:50,179 --> 00:22:52,919
uh but it's very similar to something

498
00:22:52,919 --> 00:22:55,260
that we can compute which is called

499
00:22:55,260 --> 00:22:57,960
normalized compression distance and the

500
00:22:57,960 --> 00:22:59,760
normal compression distance really

501
00:22:59,760 --> 00:23:03,299
relies on our ability to compress files

502
00:23:03,299 --> 00:23:05,880
I mean we all compress files we all send

503
00:23:05,880 --> 00:23:08,159
them in a zip format and whatever and it

504
00:23:08,159 --> 00:23:10,740
turns out that to be able to compare two

505
00:23:10,740 --> 00:23:12,480
files you don't have to do much more

506
00:23:12,480 --> 00:23:15,419
than compress be able to compress those

507
00:23:15,419 --> 00:23:17,940
two files and the measure is basically

508
00:23:17,940 --> 00:23:20,760
you concatenate two files and compress

509
00:23:20,760 --> 00:23:23,940
them with some function and then you

510
00:23:23,940 --> 00:23:28,159
this you subtract minimum of the

511
00:23:28,159 --> 00:23:30,840
compress of the lengths of the

512
00:23:30,840 --> 00:23:33,480
compression function on first file and

513
00:23:33,480 --> 00:23:35,220
the compression function of second file

514
00:23:35,220 --> 00:23:38,700
if those two files are very similar the

515
00:23:38,700 --> 00:23:41,880
compressions are very good in nicely

516
00:23:41,880 --> 00:23:44,100
compressing repetitive content so if we

517
00:23:44,100 --> 00:23:45,720
have very two similar files they will

518
00:23:45,720 --> 00:23:49,200
have a lot of similar bits and bytes and

519
00:23:49,200 --> 00:23:51,659
so compressing them two together will be

520
00:23:51,659 --> 00:23:53,340
very similar to compressing a single

521
00:23:53,340 --> 00:23:55,500
file so the length of the two will be

522
00:23:55,500 --> 00:23:58,679
very very near and so divide that by the

523
00:23:58,679 --> 00:24:00,299
maximum of those of those two lengths

524
00:24:00,299 --> 00:24:02,760
and you you get this compression so you

525
00:24:02,760 --> 00:24:05,640
get this measure of similarity and it's

526
00:24:05,640 --> 00:24:06,960
it's it's kind of very good

527
00:24:06,960 --> 00:24:08,940
unfortunately it doesn't scale well

528
00:24:08,940 --> 00:24:11,580
because for every single comparison you

529
00:24:11,580 --> 00:24:13,880
need to comp you need to

530
00:24:13,880 --> 00:24:16,440
compress three times and compression is

531
00:24:16,440 --> 00:24:19,140
not a cheap operation it takes some

532
00:24:19,140 --> 00:24:22,200
times so there are some improvements

533
00:24:22,200 --> 00:24:26,400
which which were proposed and one of

534
00:24:26,400 --> 00:24:28,260
them is called lampos if Jacquard

535
00:24:28,260 --> 00:24:30,780
distance and so and so so to to

536
00:24:30,780 --> 00:24:32,240
understand this

537
00:24:32,240 --> 00:24:35,340
Jacquard distance we have to go back

538
00:24:35,340 --> 00:24:39,299
45 years from now or so in in the

539
00:24:39,299 --> 00:24:40,919
history we are going back to the future

540
00:24:40,919 --> 00:24:44,039
or back to the past to to to learn a

541
00:24:44,039 --> 00:24:47,640
little bit about the lz77 lossless

542
00:24:47,640 --> 00:24:49,740
compression which is kind of the most

543
00:24:49,740 --> 00:24:53,400
simple way of how you compress content

544
00:24:53,400 --> 00:24:56,000
so how how does the

545
00:24:56,000 --> 00:24:59,640
lz77 works well it goes through a file

546
00:24:59,640 --> 00:25:01,380
in a single pass

547
00:25:01,380 --> 00:25:04,559
and it has two buffers one is the search

548
00:25:04,559 --> 00:25:06,900
buffer and the second one is a local

549
00:25:06,900 --> 00:25:11,539
head buffer and it tries to find

550
00:25:11,960 --> 00:25:14,340
data that that appears in a search

551
00:25:14,340 --> 00:25:16,559
buffer that's already that appears in

552
00:25:16,559 --> 00:25:18,480
the look ahead buffer that's already in

553
00:25:18,480 --> 00:25:20,280
the search buffer perhaps it's good to

554
00:25:20,280 --> 00:25:22,740
to show on the original example so we

555
00:25:22,740 --> 00:25:27,419
have a set of we have a a string that we

556
00:25:27,419 --> 00:25:29,580
are trying to compress

557
00:25:29,580 --> 00:25:33,299
that string starts with aaca at the

558
00:25:33,299 --> 00:25:35,460
beginning we only see the look ahead

559
00:25:35,460 --> 00:25:37,200
buffer because the search buffer is

560
00:25:37,200 --> 00:25:38,820
empty we have nothing in the search

561
00:25:38,820 --> 00:25:41,760
buffer and so the look ahead buffer will

562
00:25:41,760 --> 00:25:45,900
contain aaca so the first what we do is

563
00:25:45,900 --> 00:25:50,179
we convert to to encode this file in

564
00:25:50,179 --> 00:25:54,480
lz77 encoding you we create these tuples

565
00:25:54,480 --> 00:25:57,600
of car of characters the Tuple contains

566
00:25:57,600 --> 00:26:01,159
three elements the first element is

567
00:26:01,159 --> 00:26:05,820
the position of the match the second

568
00:26:05,820 --> 00:26:08,340
element is the length of the match and

569
00:26:08,340 --> 00:26:10,320
the third element is the next character

570
00:26:10,320 --> 00:26:12,120
after the match we have seen in the

571
00:26:12,120 --> 00:26:15,419
search buffer so we start with with at

572
00:26:15,419 --> 00:26:17,039
the beginning we have no matches in

573
00:26:17,039 --> 00:26:18,720
search buffer because the search buffer

574
00:26:18,720 --> 00:26:21,600
is empty and so we start with 0 0 and

575
00:26:21,600 --> 00:26:23,700
the next character is a

576
00:26:23,700 --> 00:26:27,919
so we we put on the side we write 0 0 a

577
00:26:27,919 --> 00:26:32,220
uh so now we move one character for

578
00:26:32,220 --> 00:26:35,520
after the A and so our search buffer is

579
00:26:35,520 --> 00:26:37,620
now in green it contains only one

580
00:26:37,620 --> 00:26:39,659
character and our look ahead buffer is

581
00:26:39,659 --> 00:26:42,240
still four for four characters we have

582
00:26:42,240 --> 00:26:44,640
in this case we we created that the the

583
00:26:44,640 --> 00:26:47,279
search buffer is six characters and uh

584
00:26:47,279 --> 00:26:50,520
look ahead is four uh so we now look at

585
00:26:50,520 --> 00:26:52,620
like do we have anything so the next

586
00:26:52,620 --> 00:26:55,320
character is a do I already have a in my

587
00:26:55,320 --> 00:26:58,080
search buffer yes I do how far is it

588
00:26:58,080 --> 00:27:00,120
from my pointer from my search buffer

589
00:27:00,120 --> 00:27:02,460
one character back so it's one character

590
00:27:02,460 --> 00:27:04,559
back how long this is the length I'm

591
00:27:04,559 --> 00:27:06,720
looking at the next character C do I

592
00:27:06,720 --> 00:27:08,400
also have a c in the search buffer I

593
00:27:08,400 --> 00:27:10,620
don't so my length my length of what I

594
00:27:10,620 --> 00:27:12,840
found is one and that's how I go through

595
00:27:12,840 --> 00:27:15,059
the file by matching the look ahead

596
00:27:15,059 --> 00:27:17,880
buffer with the search buffer and the

597
00:27:17,880 --> 00:27:20,400
the more times I have repetitive content

598
00:27:20,400 --> 00:27:22,559
in the file the better I'll be able to

599
00:27:22,559 --> 00:27:25,320
compress this so at the end I end up

600
00:27:25,320 --> 00:27:28,460
with a quite a large number of tuples

601
00:27:28,460 --> 00:27:31,380
and which will be much shorter than the

602
00:27:31,380 --> 00:27:34,200
the whole file and that's how I create I

603
00:27:34,200 --> 00:27:36,600
Can Go reverse the process and I go back

604
00:27:36,600 --> 00:27:39,419
and from those tuples I create the whole

605
00:27:39,419 --> 00:27:41,159
file back and that's how I can get the

606
00:27:41,159 --> 00:27:42,779
file so

607
00:27:42,779 --> 00:27:45,179
so who is this LZ that we are talking

608
00:27:45,179 --> 00:27:47,100
about well there are the two

609
00:27:47,100 --> 00:27:51,000
um Israeli researchers quite young guys

610
00:27:51,000 --> 00:27:53,520
um why they're both alive

611
00:27:53,520 --> 00:27:57,000
um Jacob ziv is 90 years old uh Abraham

612
00:27:57,000 --> 00:28:00,480
lemple is uh uh is the is the letter L

613
00:28:00,480 --> 00:28:03,539
in the in the the algorithm and so about

614
00:28:03,539 --> 00:28:05,700
45 years ago or more they were doing

615
00:28:05,700 --> 00:28:09,360
this fundamental work on you know

616
00:28:09,360 --> 00:28:11,820
creating this idea of of lossless

617
00:28:11,820 --> 00:28:13,740
compression which was not as well known

618
00:28:13,740 --> 00:28:16,440
before and so they created this

619
00:28:16,440 --> 00:28:18,539
algorithm that we use almost on an

620
00:28:18,539 --> 00:28:20,400
everyday basis so like you know in this

621
00:28:20,400 --> 00:28:22,620
case I would I would like to thank

622
00:28:22,620 --> 00:28:24,960
them for you know

623
00:28:24,960 --> 00:28:27,360
doing this really important piece of

624
00:28:27,360 --> 00:28:29,220
research

625
00:28:29,220 --> 00:28:31,620
so going back to the our

626
00:28:31,620 --> 00:28:32,480
um

627
00:28:32,480 --> 00:28:35,760
Jacquard distance that's that was a

628
00:28:35,760 --> 00:28:39,360
recently discovered a technique for

629
00:28:39,360 --> 00:28:43,640
comparing files so the idea is that you

630
00:28:43,640 --> 00:28:45,799
create

631
00:28:45,799 --> 00:28:49,500
these dictionary strings or tuples on on

632
00:28:49,500 --> 00:28:51,900
a file and then then you kind of sort

633
00:28:51,900 --> 00:28:54,900
them and then use some hashing algorithm

634
00:28:54,900 --> 00:28:58,020
to create 32-bit hash values then you

635
00:28:58,020 --> 00:29:01,740
sort those hash values uh by some by

636
00:29:01,740 --> 00:29:04,380
some distance from the smaller to the

637
00:29:04,380 --> 00:29:06,840
biggest and then you choose

638
00:29:06,840 --> 00:29:10,679
an N number of those hashes as index for

639
00:29:10,679 --> 00:29:14,760
hashing in the big database so two files

640
00:29:14,760 --> 00:29:17,820
which are similar will will have

641
00:29:17,820 --> 00:29:22,140
a large overlap between the two uh sets

642
00:29:22,140 --> 00:29:24,659
of hashes so in this case I'm so happy

643
00:29:24,659 --> 00:29:26,700
to meet all my friends at balcon we

644
00:29:26,700 --> 00:29:30,899
create a number of 38 32-bit hashes and

645
00:29:30,899 --> 00:29:32,760
so with some with some other string that

646
00:29:32,760 --> 00:29:35,520
looks maybe I'm so happy to meet all of

647
00:29:35,520 --> 00:29:38,059
my friends but not at Balkan in general

648
00:29:38,059 --> 00:29:41,340
uh we will have a large number of very

649
00:29:41,340 --> 00:29:44,640
similar hashes here and we'll be able to

650
00:29:44,640 --> 00:29:47,399
create to to calculate the card distance

651
00:29:47,399 --> 00:29:50,700
on this on these hashes so so this is

652
00:29:50,700 --> 00:29:52,679
like a kind of like a shortcut so you

653
00:29:52,679 --> 00:29:54,240
don't have to compress the whole file

654
00:29:54,240 --> 00:29:56,159
you do this once you store it in a

655
00:29:56,159 --> 00:29:58,320
database and you have these hashes and

656
00:29:58,320 --> 00:30:00,360
you have to only calculate it once and

657
00:30:00,360 --> 00:30:03,240
then you can do some more clever column

658
00:30:03,240 --> 00:30:07,320
kind of clever matching the other

659
00:30:07,320 --> 00:30:09,379
um

660
00:30:09,779 --> 00:30:12,840
concept that was that's that's often

661
00:30:12,840 --> 00:30:15,720
used in anti-malware world is is this

662
00:30:15,720 --> 00:30:18,360
notion of locality sensitive hashing you

663
00:30:18,360 --> 00:30:20,580
know how when you have man D5 or chavan

664
00:30:20,580 --> 00:30:24,480
or similar cryptographic checksums the

665
00:30:24,480 --> 00:30:26,760
idea is to to have such a good hashing

666
00:30:26,760 --> 00:30:29,100
algorithm that even if the if it's a

667
00:30:29,100 --> 00:30:30,960
small difference between the two files

668
00:30:30,960 --> 00:30:33,600
the hashes will be very different so you

669
00:30:33,600 --> 00:30:35,760
you aim to minimize the collision

670
00:30:35,760 --> 00:30:37,860
between those two hashes but with

671
00:30:37,860 --> 00:30:40,020
locality sensitive hashing the idea is

672
00:30:40,020 --> 00:30:42,299
if you have two similar files you want

673
00:30:42,299 --> 00:30:45,240
to maximize the the collisions in the in

674
00:30:45,240 --> 00:30:47,940
the hash brackets and so so the the

675
00:30:47,940 --> 00:30:50,580
fundamental or the initial

676
00:30:50,580 --> 00:30:51,779
um

677
00:30:51,779 --> 00:30:54,799
algorithm comes from actually

678
00:30:54,799 --> 00:30:58,140
comparing spam emails and something

679
00:30:58,140 --> 00:31:02,220
called spam sum and a Jesse cornbread

680
00:31:02,220 --> 00:31:04,740
from Facebook kind of improved it so it

681
00:31:04,740 --> 00:31:06,960
can be applied to normal text files and

682
00:31:06,960 --> 00:31:09,720
some binary files so what what it does

683
00:31:09,720 --> 00:31:12,419
is it you you just create you have to

684
00:31:12,419 --> 00:31:15,539
calculate the size of the the buffer you

685
00:31:15,539 --> 00:31:17,520
want to calculate the check someone and

686
00:31:17,520 --> 00:31:18,720
once when you have the size of the

687
00:31:18,720 --> 00:31:20,640
buffer depending on the file length and

688
00:31:20,640 --> 00:31:23,279
and so on several characteristic you

689
00:31:23,279 --> 00:31:25,020
travel through the file and for every

690
00:31:25,020 --> 00:31:28,380
buffer you emit a checksum and so so you

691
00:31:28,380 --> 00:31:31,200
get this long string that we see on the

692
00:31:31,200 --> 00:31:33,059
bottom of the screen at the beginning

693
00:31:33,059 --> 00:31:35,340
you have this 24 number which is the

694
00:31:35,340 --> 00:31:38,399
size of the block and then you have uh

695
00:31:38,399 --> 00:31:41,279
using size of the block 24 you get this

696
00:31:41,279 --> 00:31:43,140
checksum that looks very much textual

697
00:31:43,140 --> 00:31:46,559
and then with the double the size of the

698
00:31:46,559 --> 00:31:48,960
block you get smaller checksum but you

699
00:31:48,960 --> 00:31:51,720
can easily compare two files which with

700
00:31:51,720 --> 00:31:54,720
similar content will have very similar

701
00:31:54,720 --> 00:31:56,520
so you just look at the editing distance

702
00:31:56,520 --> 00:31:59,580
between two SSD checksums and you'll be

703
00:31:59,580 --> 00:32:01,980
able to quickly realize so so you have

704
00:32:01,980 --> 00:32:04,500
the measure of similarity goes from zero

705
00:32:04,500 --> 00:32:07,620
here to 100 so 100 is a perfect match

706
00:32:07,620 --> 00:32:11,100
zero is is basically no match the the

707
00:32:11,100 --> 00:32:13,559
what I found in my own kind of looking

708
00:32:13,559 --> 00:32:15,140
at those those those

709
00:32:15,140 --> 00:32:17,760
algorithms is that that doesn't really

710
00:32:17,760 --> 00:32:20,700
work it doesn't work well on binary

711
00:32:20,700 --> 00:32:23,580
files and and so I I quickly kind of

712
00:32:23,580 --> 00:32:26,399
discarded this as deep as as the kind of

713
00:32:26,399 --> 00:32:28,500
gold algorithm

714
00:32:28,500 --> 00:32:32,340
but about 10 years ago of a silly Ruth

715
00:32:32,340 --> 00:32:36,419
developed a hash called SD hash which is

716
00:32:36,419 --> 00:32:39,500
also a kind of a locality sensitive hash

717
00:32:39,500 --> 00:32:42,240
and but it has some better

718
00:32:42,240 --> 00:32:44,520
characteristics it's not really updated

719
00:32:44,520 --> 00:32:48,960
since so so it was I haven't considered

720
00:32:48,960 --> 00:32:50,760
it that much but the one that I

721
00:32:50,760 --> 00:32:53,580
considered and it's really

722
00:32:53,580 --> 00:32:56,940
um well performing on a large sample set

723
00:32:56,940 --> 00:33:01,320
it's called TLS age so Trend Micro

724
00:33:01,320 --> 00:33:03,960
locality sensitive hashing which was

725
00:33:03,960 --> 00:33:06,720
developed by by the some Jonathan Oliver

726
00:33:06,720 --> 00:33:09,840
and a few other guys in Trend Micro and

727
00:33:09,840 --> 00:33:12,000
what this does is

728
00:33:12,000 --> 00:33:14,940
um it's pretty good with code reordering

729
00:33:14,940 --> 00:33:18,000
so sometimes you have malicious actors

730
00:33:18,000 --> 00:33:19,760
who are trying to

731
00:33:19,760 --> 00:33:22,740
randomize the content of the file so you

732
00:33:22,740 --> 00:33:24,659
can't immediately see that some file is

733
00:33:24,659 --> 00:33:28,019
similar to to another by inserting some

734
00:33:28,019 --> 00:33:31,039
junk bytes junk instructions and so on

735
00:33:31,039 --> 00:33:35,580
so tlsh is done so it's quite sensitive

736
00:33:35,580 --> 00:33:39,120
quite resilient to changing those the

737
00:33:39,120 --> 00:33:41,100
byte swapping and things in things like

738
00:33:41,100 --> 00:33:43,380
that and the way it works is you again

739
00:33:43,380 --> 00:33:45,779
you have a small buffer usually five

740
00:33:45,779 --> 00:33:48,299
bytes and out of those five bytes you

741
00:33:48,299 --> 00:33:50,460
take check sum of three so you you kind

742
00:33:50,460 --> 00:33:52,620
of ignore two bytes so you can you know

743
00:33:52,620 --> 00:33:55,380
if if those two rights are the first and

744
00:33:55,380 --> 00:33:57,059
the second byte you ignore them you only

745
00:33:57,059 --> 00:33:59,279
take the last three and then you have

746
00:33:59,279 --> 00:34:01,320
all the permutations of those three

747
00:34:01,320 --> 00:34:04,620
bytes within the five uh engram kind of

748
00:34:04,620 --> 00:34:08,099
buffer and so and you score

749
00:34:08,099 --> 00:34:10,500
um the kind of you you look how often

750
00:34:10,500 --> 00:34:12,899
those engrams are appearing in the file

751
00:34:12,899 --> 00:34:15,960
and you place them in four buckets like

752
00:34:15,960 --> 00:34:19,619
zero percent zero uh lower quarter so

753
00:34:19,619 --> 00:34:21,899
the so and then you the first quartile

754
00:34:21,899 --> 00:34:24,480
uh the second and the third quartile so

755
00:34:24,480 --> 00:34:26,460
for every quartile that they have if

756
00:34:26,460 --> 00:34:28,619
there is a large number of these files

757
00:34:28,619 --> 00:34:30,599
they will be in the highest quartile and

758
00:34:30,599 --> 00:34:33,179
and you you give them a value one one so

759
00:34:33,179 --> 00:34:35,219
it's three so you have the values from

760
00:34:35,219 --> 00:34:37,139
zero to three which you can assign to a

761
00:34:37,139 --> 00:34:39,960
particular byte sequence uh and and

762
00:34:39,960 --> 00:34:42,599
that's how you create a checksum that's

763
00:34:42,599 --> 00:34:47,460
uh 70 or 68 bytes long and so it's very

764
00:34:47,460 --> 00:34:50,580
easy the tlsh gives you a function to

765
00:34:50,580 --> 00:34:52,260
compare that and you get the results

766
00:34:52,260 --> 00:34:55,739
from zero zero to to one

767
00:34:55,739 --> 00:34:58,380
and it works well on a large number of

768
00:34:58,380 --> 00:34:59,640
sets

769
00:34:59,640 --> 00:35:02,700
so now um you know this thing is doesn't

770
00:35:02,700 --> 00:35:05,460
the the comparison of code is not really

771
00:35:05,460 --> 00:35:08,280
just used for like malware analysis it's

772
00:35:08,280 --> 00:35:11,220
also used by many professors around the

773
00:35:11,220 --> 00:35:14,460
world when they try to Mark uh some

774
00:35:14,460 --> 00:35:17,579
student problems to see who copied the

775
00:35:17,579 --> 00:35:20,040
code from one to another and so there's

776
00:35:20,040 --> 00:35:22,619
this idea of called the the algorithm

777
00:35:22,619 --> 00:35:25,040
called measure of software similarity

778
00:35:25,040 --> 00:35:28,380
it said that many professors in the US

779
00:35:28,380 --> 00:35:30,119
are using this measure of software

780
00:35:30,119 --> 00:35:33,119
similarity and so I don't know how they

781
00:35:33,119 --> 00:35:35,040
decide who copied from who but at least

782
00:35:35,040 --> 00:35:38,460
they can see uh whose code is is very

783
00:35:38,460 --> 00:35:39,780
similar and there's a python

784
00:35:39,780 --> 00:35:42,000
implementation called copy detect which

785
00:35:42,000 --> 00:35:43,920
are kind of shamelessly of course used

786
00:35:43,920 --> 00:35:46,980
on on my samples and again the the idea

787
00:35:46,980 --> 00:35:48,480
here is

788
00:35:48,480 --> 00:35:51,900
how do you scale this on a large number

789
00:35:51,900 --> 00:35:53,940
of samples and here's where this

790
00:35:53,940 --> 00:35:55,859
algorithm called we know incoming is

791
00:35:55,859 --> 00:35:57,660
coming in so we have at the beginning

792
00:35:57,660 --> 00:35:59,760
you know how it works we have the

793
00:35:59,760 --> 00:36:02,040
beginning some text in this case a do

794
00:36:02,040 --> 00:36:05,400
run run and do run run we we discard

795
00:36:05,400 --> 00:36:08,960
some useless characters such as space

796
00:36:08,960 --> 00:36:11,520
and you we we maybe do some

797
00:36:11,520 --> 00:36:13,200
transformation of the text and we had

798
00:36:13,200 --> 00:36:15,900
the long string I do run run run run we

799
00:36:15,900 --> 00:36:19,380
take n grams in this case five so a Dura

800
00:36:19,380 --> 00:36:23,040
do run and so on we we create hashes of

801
00:36:23,040 --> 00:36:24,780
those engrams so we have like

802
00:36:24,780 --> 00:36:27,599
hypothetical one byte hashes here and

803
00:36:27,599 --> 00:36:30,240
then and then we go into windowing so we

804
00:36:30,240 --> 00:36:32,460
have an another buffer that we go and

805
00:36:32,460 --> 00:36:34,740
the reason why we do this buffering is

806
00:36:34,740 --> 00:36:38,579
to to come up with the N number smaller

807
00:36:38,579 --> 00:36:41,460
the N smallest values of those hashes

808
00:36:41,460 --> 00:36:44,460
and and for some reason those and

809
00:36:44,460 --> 00:36:46,320
smallest values of the hashings are

810
00:36:46,320 --> 00:36:48,119
really great representations of those

811
00:36:48,119 --> 00:36:51,240
files so instead of comparing hundreds

812
00:36:51,240 --> 00:36:53,040
of hashes we only have to compare five

813
00:36:53,040 --> 00:36:54,839
or six to see that some files are

814
00:36:54,839 --> 00:36:57,240
similar and then for the the fingerprint

815
00:36:57,240 --> 00:36:59,760
in the end you see the fingerprint is 17

816
00:36:59,760 --> 00:37:03,780
17 8 39 17 whatever we also give them

817
00:37:03,780 --> 00:37:05,820
the position where this fingerprint is

818
00:37:05,820 --> 00:37:08,280
so that we can see which parts of the

819
00:37:08,280 --> 00:37:11,220
files are in in fact uh similar of

820
00:37:11,220 --> 00:37:12,720
course you know the students wouldn't be

821
00:37:12,720 --> 00:37:15,560
good students if they wouldn't create

822
00:37:15,560 --> 00:37:18,480
anti-plagiarism engine called Mossad in

823
00:37:18,480 --> 00:37:20,460
this case this is closed source project

824
00:37:20,460 --> 00:37:23,880
at at the moment and the idea of Mozart

825
00:37:23,880 --> 00:37:25,640
is okay so you wanna

826
00:37:25,640 --> 00:37:28,619
each measure of software similarity

827
00:37:28,619 --> 00:37:31,920
creates a score and so you go okay so if

828
00:37:31,920 --> 00:37:33,900
my score is similar that the professor

829
00:37:33,900 --> 00:37:36,599
will think that my I've copied the code

830
00:37:36,599 --> 00:37:39,359
for somebody so what I can do is to to

831
00:37:39,359 --> 00:37:42,240
insert some instructions between my

832
00:37:42,240 --> 00:37:44,400
friend's code which will still keep the

833
00:37:44,400 --> 00:37:46,740
software working but the measure of

834
00:37:46,740 --> 00:37:48,599
software similarity won't raise any

835
00:37:48,599 --> 00:37:51,420
expression so so there are projects like

836
00:37:51,420 --> 00:37:52,980
that and I'm sure it would be really

837
00:37:52,980 --> 00:37:57,000
good for for malware writers as well so

838
00:37:57,000 --> 00:37:58,680
here here are just couple of examples

839
00:37:58,680 --> 00:38:01,020
here we on the left we have a we have a

840
00:38:01,020 --> 00:38:02,760
function which is the original function

841
00:38:02,760 --> 00:38:04,920
and on the right we have functions with

842
00:38:04,920 --> 00:38:09,060
some in inserted uh code like in the

843
00:38:09,060 --> 00:38:12,000
third row you see in and choose K which

844
00:38:12,000 --> 00:38:14,040
is the similar in copied it doesn't do

845
00:38:14,040 --> 00:38:17,940
anything but uh it it breaks the uh

846
00:38:17,940 --> 00:38:20,880
hashing algorithm that's used by measure

847
00:38:20,880 --> 00:38:22,800
of software similarity

848
00:38:22,800 --> 00:38:25,200
and then of course I I decided okay I

849
00:38:25,200 --> 00:38:28,500
need to do something for myself on uh on

850
00:38:28,500 --> 00:38:31,160
on those the the malware set that I have

851
00:38:31,160 --> 00:38:34,920
uh and so I I came up to come up to this

852
00:38:34,920 --> 00:38:37,859
uh python module called pigments or

853
00:38:37,859 --> 00:38:40,440
pigments which is basically a lecture

854
00:38:40,440 --> 00:38:43,020
that allows you to to take a piece of

855
00:38:43,020 --> 00:38:45,240
source code do some transformation of

856
00:38:45,240 --> 00:38:47,520
the source code and then come up with a

857
00:38:47,520 --> 00:38:48,540
different slightly different

858
00:38:48,540 --> 00:38:50,880
representation so in measure of software

859
00:38:50,880 --> 00:38:53,040
similarity there are some things that

860
00:38:53,040 --> 00:38:54,780
needs to be done so it's easier to

861
00:38:54,780 --> 00:38:56,520
compare those files and this is what

862
00:38:56,520 --> 00:38:59,280
I've done so on the VBA code I run those

863
00:38:59,280 --> 00:39:01,859
the pigments and so instead of the code

864
00:39:01,859 --> 00:39:04,440
on the left which has all the all the

865
00:39:04,440 --> 00:39:07,200
spaces and all the capital letters all

866
00:39:07,200 --> 00:39:09,599
the variable names all the strings I

867
00:39:09,599 --> 00:39:11,280
replaced it with the representation on

868
00:39:11,280 --> 00:39:13,980
the right and then I I looked like how

869
00:39:13,980 --> 00:39:15,140
these

870
00:39:15,140 --> 00:39:18,859
algorithms for similarity work on both

871
00:39:18,859 --> 00:39:21,180
non-tokenized non-normalized versions of

872
00:39:21,180 --> 00:39:22,859
the file and normalized versions of the

873
00:39:22,859 --> 00:39:25,800
file and so it turns out that it works

874
00:39:25,800 --> 00:39:27,359
pretty well and this is all the result

875
00:39:27,359 --> 00:39:30,180
of the copy detect in Python that shows

876
00:39:30,180 --> 00:39:32,280
you like which are the similar pieces of

877
00:39:32,280 --> 00:39:35,160
the code and so I I kind of created like

878
00:39:35,160 --> 00:39:38,160
really simple script which used

879
00:39:38,160 --> 00:39:41,099
seven or eight different measures on my

880
00:39:41,099 --> 00:39:43,920
really simple test set so what I had is

881
00:39:43,920 --> 00:39:46,260
like maybe 10 different files they're

882
00:39:46,260 --> 00:39:48,420
all representation of either transparent

883
00:39:48,420 --> 00:39:51,960
tribe or donut and I run my filter of

884
00:39:51,960 --> 00:39:55,140
similarity measures in my script and so

885
00:39:55,140 --> 00:39:58,260
it comes up with some results which kind

886
00:39:58,260 --> 00:40:00,119
of more or less if you look at the the

887
00:40:00,119 --> 00:40:03,180
shape of these these graphs it it it

888
00:40:03,180 --> 00:40:05,700
kind of gives you the idea that that

889
00:40:05,700 --> 00:40:07,380
that it works that most of the

890
00:40:07,380 --> 00:40:10,460
algorithms agree on their

891
00:40:10,460 --> 00:40:12,780
measures or or their distance

892
00:40:12,780 --> 00:40:15,060
calculations

893
00:40:15,060 --> 00:40:18,780
so it turns out that that the the two of

894
00:40:18,780 --> 00:40:21,119
the most similars are from transparent

895
00:40:21,119 --> 00:40:23,460
tribe and as the user so very very

896
00:40:23,460 --> 00:40:25,200
similar to files and they're like from

897
00:40:25,200 --> 00:40:27,359
the opposing Group which confirms that

898
00:40:27,359 --> 00:40:29,099
there's a really good similarity between

899
00:40:29,099 --> 00:40:31,800
them and then there are two other

900
00:40:31,800 --> 00:40:34,079
samples that were like not considered

901
00:40:34,079 --> 00:40:38,339
similar at all and so for me I was quite

902
00:40:38,339 --> 00:40:40,619
happy but I now need to apply This

903
00:40:40,619 --> 00:40:44,160
research on on a much larger scale or

904
00:40:44,160 --> 00:40:46,099
much larger test set

905
00:40:46,099 --> 00:40:49,200
so to conclude we are kind of running

906
00:40:49,200 --> 00:40:51,060
out of time as well

907
00:40:51,060 --> 00:40:52,980
um there are a number of smaller apt

908
00:40:52,980 --> 00:40:55,500
groups in South Asia they share toolkits

909
00:40:55,500 --> 00:40:58,339
or they share the code for some reason

910
00:40:58,339 --> 00:41:01,560
and so which prompted me to do this

911
00:41:01,560 --> 00:41:04,200
Research into similarity or measures of

912
00:41:04,200 --> 00:41:07,500
similarity of code with the intention to

913
00:41:07,500 --> 00:41:11,240
scale it up I need to also

914
00:41:11,240 --> 00:41:13,380
investigate some of the kind of machine

915
00:41:13,380 --> 00:41:15,540
learning things which I kind of don't

916
00:41:15,540 --> 00:41:17,760
understand but we'll see we'll try to

917
00:41:17,760 --> 00:41:19,920
apply it it's a good opportunity to

918
00:41:19,920 --> 00:41:22,380
learn so with that I hope it was

919
00:41:22,380 --> 00:41:25,079
somewhat interesting at my to follow

920
00:41:25,079 --> 00:41:27,240
this journey I'd like to thank you and

921
00:41:27,240 --> 00:41:28,680
if there are any questions I would be

922
00:41:28,680 --> 00:41:32,480
very happy to try to answer

923
00:41:35,040 --> 00:41:38,040
in

924
00:41:38,460 --> 00:41:43,020
oh so in your grab bag of algorithms uh

925
00:41:43,020 --> 00:41:45,240
if I can suggest one more that you might

926
00:41:45,240 --> 00:41:47,760
want to add to your collection

927
00:41:47,760 --> 00:41:50,520
um so there's one called Sim hash

928
00:41:50,520 --> 00:41:54,180
similarity hash which is it's a Google

929
00:41:54,180 --> 00:41:57,420
old Google algorithm from a while ago

930
00:41:57,420 --> 00:41:59,760
when they were using it to compare HTML

931
00:41:59,760 --> 00:42:03,720
web pages it's very similar to SSD and

932
00:42:03,720 --> 00:42:05,480
the second thing

933
00:42:05,480 --> 00:42:08,820
for the tokenization and normalization

934
00:42:08,820 --> 00:42:12,119
instead of pigments take a look at Sly

935
00:42:12,119 --> 00:42:17,940
and ply they are uh so ply is the older

936
00:42:17,940 --> 00:42:21,599
uh they're both uh by David Beasley is

937
00:42:21,599 --> 00:42:24,300
it python python yeah pure Python and

938
00:42:24,300 --> 00:42:26,760
it's a it's a pure python implementation

939
00:42:26,760 --> 00:42:30,000
of Lex and yak and it's really really

940
00:42:30,000 --> 00:42:34,020
nice yeah so it's called Sly and Sly and

941
00:42:34,020 --> 00:42:37,560
ply okay okay cool thanks

942
00:42:37,560 --> 00:42:41,660
any other questions comments

943
00:42:47,339 --> 00:42:50,099
anyone else and then I think we we are

944
00:42:50,099 --> 00:42:51,780
ready for the beer and the next

945
00:42:51,780 --> 00:42:55,680
presentation in about 15 minutes yeah

946
00:42:55,680 --> 00:42:57,480
okay thanks

947
00:42:57,480 --> 00:42:58,810
[Applause]

948
00:42:58,810 --> 00:43:23,560
[Music]

