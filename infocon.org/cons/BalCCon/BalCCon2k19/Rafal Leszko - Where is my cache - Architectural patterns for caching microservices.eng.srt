1
00:00:25,760 --> 00:00:30,450
welcome back everyone

2
00:00:27,360 --> 00:00:32,910
so like all good things everything needs

3
00:00:30,450 --> 00:00:35,489
to come to an end this time this is the

4
00:00:32,910 --> 00:00:37,980
in this year's bulk on our last talk we

5
00:00:35,489 --> 00:00:40,050
definitely not least is titled where is

6
00:00:37,980 --> 00:00:41,819
my cash our architectural patterns for

7
00:00:40,050 --> 00:00:50,519
cashing micro sources by example

8
00:00:41,820 --> 00:00:53,370
please welcome Rafael let's go hello I'm

9
00:00:50,519 --> 00:00:56,760
Rafael I came from Poland

10
00:00:53,370 --> 00:00:58,830
I arrived actually is today and I'll

11
00:00:56,760 --> 00:01:01,710
tell you that this Balkan conference

12
00:00:58,830 --> 00:01:04,739
it's super unique I've never seen before

13
00:01:01,710 --> 00:01:06,540
like self-made TV out of lads it's

14
00:01:04,739 --> 00:01:09,240
really really impressing and all the

15
00:01:06,540 --> 00:01:10,040
other things really very happy to be

16
00:01:09,240 --> 00:01:12,690
here

17
00:01:10,040 --> 00:01:16,350
thanks for coming for the stop so today

18
00:01:12,690 --> 00:01:18,630
I will tell you about cashing especially

19
00:01:16,350 --> 00:01:21,929
cashing and the micro service word the

20
00:01:18,630 --> 00:01:24,990
micro service architecture but first a

21
00:01:21,930 --> 00:01:27,990
few words about myself so I'm a cloud

22
00:01:24,990 --> 00:01:30,270
software engineer at Hazel cast right

23
00:01:27,990 --> 00:01:32,460
before hazel cut I worked at Google and

24
00:01:30,270 --> 00:01:34,200
CERN I'm also an author of the book

25
00:01:32,460 --> 00:01:36,899
continuous delivery with docker and

26
00:01:34,200 --> 00:01:40,130
Jenkins and I from the time the time I

27
00:01:36,899 --> 00:01:42,619
do conference speaking and trainings a

28
00:01:40,130 --> 00:01:47,000
few words about hazel caste

29
00:01:42,619 --> 00:01:50,579
hazel caste is a distributed company is

30
00:01:47,000 --> 00:01:52,609
distributed in two meanings first is

31
00:01:50,579 --> 00:01:55,859
distributed because we produce

32
00:01:52,609 --> 00:01:58,320
distributed software and the second is

33
00:01:55,859 --> 00:02:01,589
distributed because all members work

34
00:01:58,320 --> 00:02:05,818
remotely so we have people from all over

35
00:02:01,590 --> 00:02:07,560
the world our products we produce open

36
00:02:05,819 --> 00:02:10,460
source software so you can use

37
00:02:07,560 --> 00:02:13,440
everything everything is on github our

38
00:02:10,460 --> 00:02:16,080
we have three products the first product

39
00:02:13,440 --> 00:02:18,780
is the most known as hazel caste IMD G

40
00:02:16,080 --> 00:02:20,910
which is kind of a caching solution we

41
00:02:18,780 --> 00:02:22,590
call it caching on steroids

42
00:02:20,910 --> 00:02:26,100
because it's actually has a lot of

43
00:02:22,590 --> 00:02:28,440
features other than caching the second

44
00:02:26,100 --> 00:02:31,500
product is hazel cast yet it is a

45
00:02:28,440 --> 00:02:34,890
library for big data stream processing

46
00:02:31,500 --> 00:02:36,569
and the third one is Kaiser cast cloud

47
00:02:34,890 --> 00:02:40,679
so it is a

48
00:02:36,569 --> 00:02:44,988
a cloud solution for hazel cast so cash

49
00:02:40,680 --> 00:02:47,459
as a service our agenda for today is

50
00:02:44,989 --> 00:02:49,469
pretty simple so there there will be a

51
00:02:47,459 --> 00:02:51,930
very short introduction about cashing in

52
00:02:49,469 --> 00:02:54,120
general and then we walk through all the

53
00:02:51,930 --> 00:02:58,590
patterns that you can use in your system

54
00:02:54,120 --> 00:03:01,250
I would like you to answer two questions

55
00:02:58,590 --> 00:03:06,930
while watching to this presentation

56
00:03:01,250 --> 00:03:10,709
first is what cash do you use in your

57
00:03:06,930 --> 00:03:13,709
company in your in your environment you

58
00:03:10,709 --> 00:03:16,349
definitely use caching so you you must

59
00:03:13,709 --> 00:03:18,959
use one of these patterns because this

60
00:03:16,349 --> 00:03:21,238
list is complete and the second question

61
00:03:18,959 --> 00:03:23,579
is you can I would like you to ask

62
00:03:21,239 --> 00:03:26,280
yourself is can I change to honor any

63
00:03:23,579 --> 00:03:28,200
other patterns if not in my software

64
00:03:26,280 --> 00:03:32,599
architecture doesn't make sense to

65
00:03:28,200 --> 00:03:36,659
change it so let's begin

66
00:03:32,599 --> 00:03:40,138
why caching so everybody does caching

67
00:03:36,659 --> 00:03:41,970
and no matter what software you right no

68
00:03:40,139 --> 00:03:46,169
matter like with programming language

69
00:03:41,970 --> 00:03:49,829
and we do it for two main reasons one is

70
00:03:46,169 --> 00:03:52,680
the most obvious is the performance so

71
00:03:49,829 --> 00:03:55,340
instead of doing some business logic

72
00:03:52,680 --> 00:03:57,750
some long time processing we just cache

73
00:03:55,340 --> 00:04:02,069
some value and then return the cache

74
00:03:57,750 --> 00:04:06,269
response the second one is a little less

75
00:04:02,069 --> 00:04:09,690
obvious is about resilience so it means

76
00:04:06,269 --> 00:04:12,659
that even if our system is down we can

77
00:04:09,690 --> 00:04:14,519
still return sometimes we can still

78
00:04:12,659 --> 00:04:18,478
return the cash value value to the user

79
00:04:14,519 --> 00:04:22,108
and the user may not even realize that

80
00:04:18,478 --> 00:04:25,349
our service is down for example if you

81
00:04:22,108 --> 00:04:28,130
use imagine that you were in Amazon and

82
00:04:25,349 --> 00:04:31,500
you implement the Amazon recommendations

83
00:04:28,130 --> 00:04:34,830
there could be easily cast and even if

84
00:04:31,500 --> 00:04:37,110
the Amazon recommendation service is

85
00:04:34,830 --> 00:04:39,840
down you can return a cached value

86
00:04:37,110 --> 00:04:41,639
because it's not critical to the to the

87
00:04:39,840 --> 00:04:47,250
business

88
00:04:41,639 --> 00:04:53,430
so so you can use caching for improving

89
00:04:47,250 --> 00:04:54,780
your resilience to two failures now what

90
00:04:53,430 --> 00:04:55,620
to do with the micro service

91
00:04:54,780 --> 00:04:59,489
architecture

92
00:04:55,620 --> 00:05:01,860
in the micro Service word that's this

93
00:04:59,490 --> 00:05:05,370
diagram is a sample micro service

94
00:05:01,860 --> 00:05:06,750
architecture you have many services they

95
00:05:05,370 --> 00:05:09,569
can be written in different programming

96
00:05:06,750 --> 00:05:13,439
language they use each other they have

97
00:05:09,569 --> 00:05:17,669
versions so now the question is where is

98
00:05:13,439 --> 00:05:20,159
the right place to put your cache is the

99
00:05:17,669 --> 00:05:24,568
right place to put it inside your

100
00:05:20,159 --> 00:05:28,500
services or maybe as a separate unit as

101
00:05:24,569 --> 00:05:32,340
a cache server on or maybe in front of

102
00:05:28,500 --> 00:05:34,770
each surface and that that is what this

103
00:05:32,340 --> 00:05:38,938
talk is about because there is no one

104
00:05:34,770 --> 00:05:41,219
good solution to these questions so let

105
00:05:38,939 --> 00:05:44,699
let's walk through the possibilities you

106
00:05:41,219 --> 00:05:48,830
have so the first one the simplest

107
00:05:44,699 --> 00:05:48,830
possible cache is embedded cache

108
00:05:50,849 --> 00:05:56,089
it works as follows a request comes to

109
00:05:54,270 --> 00:05:58,919
our system it goes to the load balancer

110
00:05:56,089 --> 00:06:01,259
then the load balancer forwards the

111
00:05:58,919 --> 00:06:05,789
request to one of the application web

112
00:06:01,259 --> 00:06:08,879
services and the application receives

113
00:06:05,789 --> 00:06:13,830
the request it checks in the cache if

114
00:06:08,879 --> 00:06:16,069
the value for some operation and then if

115
00:06:13,830 --> 00:06:19,889
the value if there is no cash value then

116
00:06:16,069 --> 00:06:21,959
perform some business logic if no then

117
00:06:19,889 --> 00:06:24,869
if the value is in the cache then return

118
00:06:21,959 --> 00:06:27,330
the cash value that business logic is

119
00:06:24,869 --> 00:06:31,080
whatever it can be long time calculation

120
00:06:27,330 --> 00:06:33,269
it can be called to external service for

121
00:06:31,080 --> 00:06:38,308
sure it's something that takes a lot of

122
00:06:33,269 --> 00:06:42,300
time so it can be also a call to the

123
00:06:38,309 --> 00:06:46,439
database so something that that is warf

124
00:06:42,300 --> 00:06:47,849
caching that is the site of application

125
00:06:46,439 --> 00:06:50,309
and runs together with our application

126
00:06:47,849 --> 00:06:53,069
so we can if you can even think about

127
00:06:50,309 --> 00:06:55,709
writing called ourself for this if you

128
00:06:53,069 --> 00:06:57,539
happen to use Java like that would be

129
00:06:55,709 --> 00:07:00,659
the very simple code to implement our

130
00:06:57,539 --> 00:07:02,669
cast ourself so we could use concurrent

131
00:07:00,659 --> 00:07:06,029
hash map and that is exactly the

132
00:07:02,669 --> 00:07:08,369
algorithm so the request comes to our

133
00:07:06,029 --> 00:07:09,689
service we check if the cache contains

134
00:07:08,369 --> 00:07:11,669
the request if he has returned the

135
00:07:09,689 --> 00:07:14,639
current value if no do some processing

136
00:07:11,669 --> 00:07:17,909
put it in put the response result into

137
00:07:14,639 --> 00:07:19,529
the cache and then return the result so

138
00:07:17,909 --> 00:07:23,279
you can implement your it yourself

139
00:07:19,529 --> 00:07:25,919
however don't do it because such a

140
00:07:23,279 --> 00:07:29,459
simple implementation based on the on

141
00:07:25,919 --> 00:07:32,159
the standard library is not actually a

142
00:07:29,459 --> 00:07:34,319
cache it's not a cache because it has no

143
00:07:32,159 --> 00:07:35,969
eviction policy knows my size limit no

144
00:07:34,319 --> 00:07:38,099
statistic no billion cash load there's

145
00:07:35,969 --> 00:07:42,829
no expiration time and no notification

146
00:07:38,099 --> 00:07:45,509
mechanism so it is not really a cache

147
00:07:42,829 --> 00:07:48,629
way better solution is to use some

148
00:07:45,509 --> 00:07:51,269
library if you happen to use Java then

149
00:07:48,629 --> 00:07:54,059
you can use guava it has all these

150
00:07:51,269 --> 00:07:57,269
features built-in which you can set up

151
00:07:54,059 --> 00:08:00,980
at the beginning of of the creating of

152
00:07:57,269 --> 00:08:04,540
the cache the resolution is eh guess

153
00:08:00,980 --> 00:08:07,130
which is also a very very good solution

154
00:08:04,540 --> 00:08:09,710
if you don't want to implement it

155
00:08:07,130 --> 00:08:12,409
all this caching logic yourself we can

156
00:08:09,710 --> 00:08:15,560
move the caching one level higher to the

157
00:08:12,410 --> 00:08:18,170
application level for example in case of

158
00:08:15,560 --> 00:08:20,230
spring it's enough to add a few

159
00:08:18,170 --> 00:08:25,250
annotations and the cast is

160
00:08:20,230 --> 00:08:28,580
automatically used so in this example we

161
00:08:25,250 --> 00:08:30,790
just edit the annotation cache shabu and

162
00:08:28,580 --> 00:08:35,740
now every call to the to our method

163
00:08:30,790 --> 00:08:38,360
first checks if the given ISBN is

164
00:08:35,740 --> 00:08:42,140
already in cache if he has returned the

165
00:08:38,360 --> 00:08:46,540
cache value if not perform process with

166
00:08:42,140 --> 00:08:49,819
the method find book and slow source

167
00:08:46,540 --> 00:08:52,880
however be careful because spring by

168
00:08:49,820 --> 00:08:55,820
users by default uses concurrent hash

169
00:08:52,880 --> 00:09:00,439
map I don't know why but they they they

170
00:08:55,820 --> 00:09:02,570
that way so coming back to our the idea

171
00:09:00,440 --> 00:09:04,490
so embedded cache is a library inside

172
00:09:02,570 --> 00:09:06,920
your application which runs together of

173
00:09:04,490 --> 00:09:11,810
your process in case of Java

174
00:09:06,920 --> 00:09:13,430
it runs entire inside the JVM one

175
00:09:11,810 --> 00:09:15,319
problem if you look at this diagram the

176
00:09:13,430 --> 00:09:17,959
one problem is that imagine that the

177
00:09:15,320 --> 00:09:21,920
request comes to our system and it first

178
00:09:17,960 --> 00:09:24,560
goes to the application on the top the

179
00:09:21,920 --> 00:09:27,500
business logic is processed we store the

180
00:09:24,560 --> 00:09:31,099
result in the cache everything is fine

181
00:09:27,500 --> 00:09:33,020
however the next request may go the same

182
00:09:31,100 --> 00:09:36,140
request may go to the to the application

183
00:09:33,020 --> 00:09:38,329
at the bottom and then we have to

184
00:09:36,140 --> 00:09:42,050
execute the business logic again because

185
00:09:38,330 --> 00:09:44,450
this caches are completely separate so

186
00:09:42,050 --> 00:09:48,380
one idea for how to improve the embedded

187
00:09:44,450 --> 00:09:50,560
cache is to use embedded distributed

188
00:09:48,380 --> 00:09:50,560
cache

189
00:09:50,630 --> 00:09:54,380
this is still the same architecture we

190
00:09:52,790 --> 00:09:56,480
don't change the architecture however we

191
00:09:54,380 --> 00:10:00,230
will change the library we use inside

192
00:09:56,480 --> 00:10:04,100
our application so this time we will use

193
00:10:00,230 --> 00:10:05,990
hazel cast as as a library hazel cast is

194
00:10:04,100 --> 00:10:08,090
just a library it's like guava so it's

195
00:10:05,990 --> 00:10:12,410
not a framework or anything it just you

196
00:10:08,090 --> 00:10:16,040
just change library use and this time

197
00:10:12,410 --> 00:10:17,480
each cache will form it in its embedded

198
00:10:16,040 --> 00:10:21,170
cache in your application they will all

199
00:10:17,480 --> 00:10:24,650
form one caching cluster so they they

200
00:10:21,170 --> 00:10:26,839
share the data and it is just the

201
00:10:24,650 --> 00:10:29,030
library so if we stick to this example

202
00:10:26,840 --> 00:10:33,050
in spring all we have to change the

203
00:10:29,030 --> 00:10:35,530
different cache manager and so that is

204
00:10:33,050 --> 00:10:38,449
the whole configuration that you will

205
00:10:35,530 --> 00:10:41,480
use hazel cast instead of the default

206
00:10:38,450 --> 00:10:46,820
Java concurrent hash map inside your

207
00:10:41,480 --> 00:10:52,450
Hall spring application so let's see a

208
00:10:46,820 --> 00:10:55,460
very quick demo on how on how we run

209
00:10:52,450 --> 00:10:57,020
this exactly this configuration in into

210
00:10:55,460 --> 00:11:01,940
application and how the cluster is

211
00:10:57,020 --> 00:11:04,850
formed so in this demo this is exactly

212
00:11:01,940 --> 00:11:07,310
the configuration you exactly the

213
00:11:04,850 --> 00:11:11,060
configuration we've seen on the slide so

214
00:11:07,310 --> 00:11:13,550
we start the to the same to spring good

215
00:11:11,060 --> 00:11:17,089
applications and you will see in a

216
00:11:13,550 --> 00:11:19,849
second that I started them locally on my

217
00:11:17,090 --> 00:11:23,770
laptop so and you will see in a second

218
00:11:19,850 --> 00:11:23,770
that they form one caching cluster

219
00:11:25,550 --> 00:11:31,459
so you see the first the first one

220
00:11:28,760 --> 00:11:35,540
started dismember it means that is the

221
00:11:31,460 --> 00:11:39,250
first cash that started and the second

222
00:11:35,540 --> 00:11:44,329
one joined the first one and they have

223
00:11:39,250 --> 00:11:45,830
one cashing cluster together now you may

224
00:11:44,330 --> 00:11:49,220
ask like how it's possible that they

225
00:11:45,830 --> 00:11:51,290
automatically discover each other I run

226
00:11:49,220 --> 00:11:54,050
it on my laptop so when you run it

227
00:11:51,290 --> 00:11:56,270
locally it will use multicast to find

228
00:11:54,050 --> 00:12:00,530
other members and form one cluster

229
00:11:56,270 --> 00:12:03,620
however we provide different discovery

230
00:12:00,530 --> 00:12:07,100
plug-ins for different environments so

231
00:12:03,620 --> 00:12:09,380
if you happen to use kubernetes then you

232
00:12:07,100 --> 00:12:12,290
just kubernetes plug-in and it will

233
00:12:09,380 --> 00:12:17,660
internally use kubernetes api to find

234
00:12:12,290 --> 00:12:19,699
other cast members what we do we provide

235
00:12:17,660 --> 00:12:23,060
the plugins for most common cloud

236
00:12:19,700 --> 00:12:25,370
solutions but if you if you use

237
00:12:23,060 --> 00:12:28,010
something that we we don't have a plugin

238
00:12:25,370 --> 00:12:31,180
for you can still use eureka which means

239
00:12:28,010 --> 00:12:35,770
that you set up your own or zookeeper or

240
00:12:31,180 --> 00:12:39,979
it means that you will set up your own

241
00:12:35,770 --> 00:12:42,079
service registry like server and then

242
00:12:39,980 --> 00:12:45,740
Hezekiah can use Eureka to discover

243
00:12:42,080 --> 00:12:48,170
themselves we invest a lot in this

244
00:12:45,740 --> 00:12:50,870
discovery plugin so you can read on our

245
00:12:48,170 --> 00:12:53,829
blog how to configure a header cast for

246
00:12:50,870 --> 00:12:53,830
each environment

247
00:12:56,330 --> 00:13:00,890
so that is about embedded cash and

248
00:12:58,280 --> 00:13:05,089
embedded distributed cash let's look at

249
00:13:00,890 --> 00:13:06,949
the pros and cons of of embedded cash so

250
00:13:05,090 --> 00:13:09,050
from the good side is a very simple

251
00:13:06,950 --> 00:13:11,930
configuration deployment because it is

252
00:13:09,050 --> 00:13:15,500
just a library and in your application

253
00:13:11,930 --> 00:13:17,479
we use Java but for any for any

254
00:13:15,500 --> 00:13:21,230
programming language you will find your

255
00:13:17,480 --> 00:13:23,330
library for cashing the good thing is

256
00:13:21,230 --> 00:13:27,590
also that the latency is very low

257
00:13:23,330 --> 00:13:29,810
because it's it's inside your process so

258
00:13:27,590 --> 00:13:33,230
it's super fast we cannot do anything

259
00:13:29,810 --> 00:13:37,489
better and you don't need any ops team

260
00:13:33,230 --> 00:13:38,900
or ops effort needed because the it's

261
00:13:37,490 --> 00:13:42,140
it's managed together with your

262
00:13:38,900 --> 00:13:44,360
application hard from the downsides the

263
00:13:42,140 --> 00:13:46,160
management of such cash is not flexible

264
00:13:44,360 --> 00:13:49,220
because you if you scale if you would

265
00:13:46,160 --> 00:13:51,339
like to scale it up like your cache is

266
00:13:49,220 --> 00:13:54,980
full you would like to have more space

267
00:13:51,340 --> 00:13:59,840
then you have to do it together with

268
00:13:54,980 --> 00:14:04,820
your service it's also limited to JVM or

269
00:13:59,840 --> 00:14:09,410
whatever your your programming languages

270
00:14:04,820 --> 00:14:11,780
meaning that you cannot run one service

271
00:14:09,410 --> 00:14:13,310
written in Ruby the other in Java and

272
00:14:11,780 --> 00:14:16,819
they will not form one cluster because

273
00:14:13,310 --> 00:14:19,130
there is probably no no such library and

274
00:14:16,820 --> 00:14:21,410
the downside is also that data is

275
00:14:19,130 --> 00:14:24,650
co-located of the application which may

276
00:14:21,410 --> 00:14:27,110
not sound like a problem however usually

277
00:14:24,650 --> 00:14:29,750
for big enterprises it is a problem

278
00:14:27,110 --> 00:14:34,070
because data because of the data

279
00:14:29,750 --> 00:14:36,530
security that's why they usually if they

280
00:14:34,070 --> 00:14:39,250
build a lot big system they you don't

281
00:14:36,530 --> 00:14:39,250
use this pattern

282
00:14:39,650 --> 00:14:44,990
stead of the bulk embedded cash the next

283
00:14:41,930 --> 00:14:48,699
pattern is different architectural

284
00:14:44,990 --> 00:14:48,700
pattern and it's called client-server

285
00:14:48,970 --> 00:14:55,640
this may look familiar it's kind of a

286
00:14:51,560 --> 00:14:59,060
database style so you set up a cache

287
00:14:55,640 --> 00:15:01,850
server and then all application connects

288
00:14:59,060 --> 00:15:05,630
to the to the server using up using

289
00:15:01,850 --> 00:15:07,700
cache clients the flow is the same

290
00:15:05,630 --> 00:15:09,320
request comes to the load balancer then

291
00:15:07,700 --> 00:15:11,540
go to the application and application

292
00:15:09,320 --> 00:15:14,330
checks in the cache if the if the

293
00:15:11,540 --> 00:15:21,740
request if such request was already

294
00:15:14,330 --> 00:15:23,390
called so if you convert this to the

295
00:15:21,740 --> 00:15:26,000
embedded mode we've seen before just

296
00:15:23,390 --> 00:15:29,689
just a while ago there are two main

297
00:15:26,000 --> 00:15:33,050
differences so the first is that this

298
00:15:29,690 --> 00:15:36,160
part is separate it's separate it means

299
00:15:33,050 --> 00:15:38,359
that it needs some separate management

300
00:15:36,160 --> 00:15:41,900
usually it will be a separate ops team

301
00:15:38,360 --> 00:15:44,120
or it can be if you follow like the

302
00:15:41,900 --> 00:15:45,949
DevOps it can still be developers who

303
00:15:44,120 --> 00:15:48,290
maintain it but someone has to maintain

304
00:15:45,950 --> 00:15:54,020
it deploy it right configuration and so

305
00:15:48,290 --> 00:15:56,120
on the second difference that between

306
00:15:54,020 --> 00:16:01,420
this and embedded mode is that is this

307
00:15:56,120 --> 00:16:03,950
part this part is it means that now

308
00:16:01,420 --> 00:16:08,839
application uses cache client to connect

309
00:16:03,950 --> 00:16:11,270
to the cache server so if you think

310
00:16:08,839 --> 00:16:14,360
about it like even the cache server can

311
00:16:11,270 --> 00:16:18,710
be written in Java we can use a client

312
00:16:14,360 --> 00:16:21,230
library written in Ruby or in Python and

313
00:16:18,710 --> 00:16:24,200
that is very common strategy in in case

314
00:16:21,230 --> 00:16:26,150
of market micro services that that is

315
00:16:24,200 --> 00:16:28,760
what usually what you do you have one

316
00:16:26,150 --> 00:16:31,579
cache server and a lot of different

317
00:16:28,760 --> 00:16:32,990
micro services with a lot of different

318
00:16:31,580 --> 00:16:36,550
written in different programming

319
00:16:32,990 --> 00:16:39,680
languages they all connect to the server

320
00:16:36,550 --> 00:16:42,199
in this architecture you can you may

321
00:16:39,680 --> 00:16:46,310
also use some other alternatives to

322
00:16:42,200 --> 00:16:47,839
hazel cast like the most probably the

323
00:16:46,310 --> 00:16:50,750
most popular in the web world

324
00:16:47,839 --> 00:16:52,130
Ready's or a little all but still use

325
00:16:50,750 --> 00:16:54,800
memcache

326
00:16:52,130 --> 00:16:57,470
these two solutions that is a man cart

327
00:16:54,800 --> 00:17:00,310
day you cannot use them embed it because

328
00:16:57,470 --> 00:17:03,380
they are written I can see which will

329
00:17:00,310 --> 00:17:05,480
not it will not make possible to embed

330
00:17:03,380 --> 00:17:09,799
it in some java code in whatever

331
00:17:05,480 --> 00:17:11,630
application you write so ready is a

332
00:17:09,799 --> 00:17:16,520
memcache the only possible way is to use

333
00:17:11,630 --> 00:17:19,520
client server how to write use client

334
00:17:16,520 --> 00:17:21,530
server if you if you'd like to start

335
00:17:19,520 --> 00:17:23,418
hazel cast we have not just a simple

336
00:17:21,530 --> 00:17:28,549
script it will start the server for you

337
00:17:23,419 --> 00:17:30,530
for you so you start one service Lucas

338
00:17:28,549 --> 00:17:32,480
note you start another they discover

339
00:17:30,530 --> 00:17:37,070
themselves automatically like like an

340
00:17:32,480 --> 00:17:40,880
embedded mode if you use kubernetes

341
00:17:37,070 --> 00:17:43,100
which is now like hot topic and most

342
00:17:40,880 --> 00:17:45,130
people are moving to kubernetes you can

343
00:17:43,100 --> 00:17:49,580
use our current chart Hampshire is a

344
00:17:45,130 --> 00:17:51,590
package manager for kubernetes with that

345
00:17:49,580 --> 00:17:54,620
simple command it will install a hello

346
00:17:51,590 --> 00:17:57,610
cat server you can specify in parameters

347
00:17:54,620 --> 00:18:01,280
how many nodes you want it will it will

348
00:17:57,610 --> 00:18:07,750
install the Henricus server now how to

349
00:18:01,280 --> 00:18:10,280
use it in the client side so you use a

350
00:18:07,750 --> 00:18:12,140
slightly different configuration but it

351
00:18:10,280 --> 00:18:14,658
still all you have to change is the

352
00:18:12,140 --> 00:18:19,299
cache manager configuration for spring

353
00:18:14,659 --> 00:18:22,250
you specify use kubernetes config and

354
00:18:19,299 --> 00:18:24,049
that's all do automatically using this

355
00:18:22,250 --> 00:18:26,450
discovery plugin kubernetes discovery

356
00:18:24,049 --> 00:18:30,190
plugin to automatically discover cache

357
00:18:26,450 --> 00:18:30,190
server in the kubernetes cluster

358
00:18:31,060 --> 00:18:34,360
so coming back to our diagram from a

359
00:18:33,100 --> 00:18:37,629
moment before

360
00:18:34,360 --> 00:18:41,050
so since cache server part can be

361
00:18:37,630 --> 00:18:43,270
managed by a separate team we can even

362
00:18:41,050 --> 00:18:48,100
move it outside of our organization and

363
00:18:43,270 --> 00:18:50,020
move it into cloud so cloud is still

364
00:18:48,100 --> 00:18:53,500
like client-server the idea is still not

365
00:18:50,020 --> 00:18:55,930
the same however it can be considered as

366
00:18:53,500 --> 00:18:58,990
a separate pattern because it's it has a

367
00:18:55,930 --> 00:19:02,110
lot of differences mainly because the

368
00:18:58,990 --> 00:19:07,180
server part is no longer inside our

369
00:19:02,110 --> 00:19:09,969
organization but the idea is to the same

370
00:19:07,180 --> 00:19:13,540
application connects to one cluster in

371
00:19:09,970 --> 00:19:17,160
the club so we don't have to think about

372
00:19:13,540 --> 00:19:22,980
all this management like backup scaling

373
00:19:17,160 --> 00:19:25,750
security and so on nevertheless like

374
00:19:22,980 --> 00:19:27,580
it's still the same architecture no

375
00:19:25,750 --> 00:19:30,870
problem of distribution if we connect

376
00:19:27,580 --> 00:19:30,870
client-server mode

377
00:19:31,930 --> 00:19:39,850
how to configure this again like in

378
00:19:35,710 --> 00:19:41,440
spring if you use hazel cast plout there

379
00:19:39,850 --> 00:19:43,300
is also further I will speak about

380
00:19:41,440 --> 00:19:45,100
Heather Casper because I'm from hazel

381
00:19:43,300 --> 00:19:46,960
cast but you have another solution like

382
00:19:45,100 --> 00:19:49,030
if you want to use Reddy's you go to

383
00:19:46,960 --> 00:19:52,780
ready slaps the ideas this is exactly

384
00:19:49,030 --> 00:19:55,450
the same so for hazel cast you provide

385
00:19:52,780 --> 00:19:59,440
the all you have to provide a discovery

386
00:19:55,450 --> 00:20:01,930
token and the password for a cluster and

387
00:19:59,440 --> 00:20:06,250
then it will automatically find your

388
00:20:01,930 --> 00:20:08,290
cluster on the web and connect to it so

389
00:20:06,250 --> 00:20:10,860
a quick demo of how to set up the

390
00:20:08,290 --> 00:20:13,840
cluster in the in the hazel gas cloud

391
00:20:10,860 --> 00:20:16,780
you can go to this website and then

392
00:20:13,840 --> 00:20:23,350
create an account and and start your

393
00:20:16,780 --> 00:20:27,940
free capri clusters so the so first we

394
00:20:23,350 --> 00:20:31,300
go to the to this website and and in the

395
00:20:27,940 --> 00:20:34,150
in the UI we select like new new cluster

396
00:20:31,300 --> 00:20:36,970
and then we have to specify the cluster

397
00:20:34,150 --> 00:20:40,300
name and what is very important is the

398
00:20:36,970 --> 00:20:42,100
cloud provider and region what is the

399
00:20:40,300 --> 00:20:43,659
important I will tell you about this in

400
00:20:42,100 --> 00:20:46,000
a second

401
00:20:43,660 --> 00:20:49,570
then you could then you select the

402
00:20:46,000 --> 00:20:51,520
cluster type and click create a few

403
00:20:49,570 --> 00:20:54,280
seconds we should see the matrix and

404
00:20:51,520 --> 00:20:56,820
then information that the cluster is

405
00:20:54,280 --> 00:20:56,820
created

406
00:20:58,060 --> 00:21:01,720
we already have the metrics there is no

407
00:21:00,370 --> 00:21:03,370
in the nothing in the metrics yet

408
00:21:01,720 --> 00:21:06,700
because we didn't add anything to the

409
00:21:03,370 --> 00:21:09,669
cluster if we click on configure client

410
00:21:06,700 --> 00:21:11,860
then you see the setup for the most

411
00:21:09,670 --> 00:21:15,520
common programming languages and you can

412
00:21:11,860 --> 00:21:19,110
grab the discovery token and the

413
00:21:15,520 --> 00:21:23,440
password from there if we go to our our

414
00:21:19,110 --> 00:21:25,540
spring application we have to provide

415
00:21:23,440 --> 00:21:30,790
here the discovery token and the

416
00:21:25,540 --> 00:21:33,430
password and then when we run the

417
00:21:30,790 --> 00:21:36,040
application again is the same

418
00:21:33,430 --> 00:21:37,930
application I didn't change anything the

419
00:21:36,040 --> 00:21:41,740
application actually has nothing is just

420
00:21:37,930 --> 00:21:44,920
configuration and if we run it in a

421
00:21:41,740 --> 00:21:47,410
second it will connect to to this our

422
00:21:44,920 --> 00:21:49,620
phaser capacitor which is located in the

423
00:21:47,410 --> 00:21:49,620
cloud

424
00:21:52,340 --> 00:21:59,209
[Music]

425
00:22:02,870 --> 00:22:10,120
our cluster had just one note one member

426
00:22:06,110 --> 00:22:10,120
this is this is this cluster

427
00:22:11,950 --> 00:22:16,660
so pros and cons of client/server and

428
00:22:14,410 --> 00:22:18,850
cloud solutions so good thing is that

429
00:22:16,660 --> 00:22:20,740
data is separate from the application it

430
00:22:18,850 --> 00:22:24,879
has separate management's which means

431
00:22:20,740 --> 00:22:27,040
that if there is some peak and using car

432
00:22:24,880 --> 00:22:29,500
server we can just scale it up very

433
00:22:27,040 --> 00:22:31,690
easily without touching our application

434
00:22:29,500 --> 00:22:35,020
and it's programming language agnostic

435
00:22:31,690 --> 00:22:37,570
so it's well defined the protocol

436
00:22:35,020 --> 00:22:39,340
between client and server so you use

437
00:22:37,570 --> 00:22:42,879
client library you can use whatever you

438
00:22:39,340 --> 00:22:44,919
want from the downside in case of client

439
00:22:42,880 --> 00:22:50,710
server on-premise you have separate ops

440
00:22:44,920 --> 00:22:53,140
effort and the second downside is

441
00:22:50,710 --> 00:22:55,930
something we didn't mention yet but now

442
00:22:53,140 --> 00:22:59,380
the latency becomes a little more

443
00:22:55,930 --> 00:23:02,500
difficult I mentioned you ended in this

444
00:22:59,380 --> 00:23:04,620
demo that it's important that which

445
00:23:02,500 --> 00:23:07,180
cloud provider choose and which region

446
00:23:04,620 --> 00:23:08,469
so the cloud provider and regional

447
00:23:07,180 --> 00:23:10,660
should be exactly the same as your

448
00:23:08,470 --> 00:23:13,030
application because otherwise you would

449
00:23:10,660 --> 00:23:16,180
imagine that you run your application in

450
00:23:13,030 --> 00:23:21,639
US and have your cloud server in Germany

451
00:23:16,180 --> 00:23:24,000
then it will be slow but it's even more

452
00:23:21,640 --> 00:23:27,610
important even if you have in the same

453
00:23:24,000 --> 00:23:30,100
geographical location then it's

454
00:23:27,610 --> 00:23:33,100
important to have it in the same cloud

455
00:23:30,100 --> 00:23:36,100
provider meaning if your infrastructure

456
00:23:33,100 --> 00:23:38,649
for your application is AWS then create

457
00:23:36,100 --> 00:23:43,300
a club drank create a cache plaster and

458
00:23:38,650 --> 00:23:45,970
AWS but it's even more difficult even

459
00:23:43,300 --> 00:23:47,350
more important because you can still be

460
00:23:45,970 --> 00:23:49,600
this in the same provider in the same

461
00:23:47,350 --> 00:23:52,449
region but you can have multiple like

462
00:23:49,600 --> 00:23:55,750
network hops in between connecting to

463
00:23:52,450 --> 00:23:58,350
your cache server that is why your

464
00:23:55,750 --> 00:24:03,070
client server should be in the same

465
00:23:58,350 --> 00:24:05,980
network than your application in case of

466
00:24:03,070 --> 00:24:09,580
the cloud version it should be in the

467
00:24:05,980 --> 00:24:11,950
same VPC so what we do in a circus cloud

468
00:24:09,580 --> 00:24:14,679
we also provide a way to do a VPC

469
00:24:11,950 --> 00:24:17,680
peering between your the network where

470
00:24:14,680 --> 00:24:21,370
your applications run and the network in

471
00:24:17,680 --> 00:24:22,370
which the server is run because like we

472
00:24:21,370 --> 00:24:25,040
are

473
00:24:22,370 --> 00:24:27,620
we are in very strict requirements in a

474
00:24:25,040 --> 00:24:30,830
terminal for latency is even more than

475
00:24:27,620 --> 00:24:32,600
the database cache is something that

476
00:24:30,830 --> 00:24:36,710
should be really fast this is the space

477
00:24:32,600 --> 00:24:38,270
of in-memory data computation where the

478
00:24:36,710 --> 00:24:44,840
fact that it's in memory it must be

479
00:24:38,270 --> 00:24:48,260
super super fast so that's how we cover

480
00:24:44,840 --> 00:24:50,419
like the basic pattern this - first

481
00:24:48,260 --> 00:24:53,210
architectural patterns may have sounded

482
00:24:50,420 --> 00:24:55,720
obvious to you because embedded the

483
00:24:53,210 --> 00:24:59,540
client-server are quite old

484
00:24:55,720 --> 00:25:04,940
however this third pattern sidecar

485
00:24:59,540 --> 00:25:07,610
pattern is something completely new this

486
00:25:04,940 --> 00:25:09,680
time we will this diagram is kubernetes

487
00:25:07,610 --> 00:25:11,659
specific because sidecar pattern is

488
00:25:09,680 --> 00:25:14,480
mostly seen in kubernetes environment

489
00:25:11,660 --> 00:25:19,100
and actually it's limited to container

490
00:25:14,480 --> 00:25:21,410
based environments so in kubernetes a

491
00:25:19,100 --> 00:25:25,040
deployment unit is called a pod called

492
00:25:21,410 --> 00:25:28,010
a pod and a pod contains one or more

493
00:25:25,040 --> 00:25:30,920
containers which are always deployed on

494
00:25:28,010 --> 00:25:33,770
the same physical machine so usually a

495
00:25:30,920 --> 00:25:36,080
pod contains just one container however

496
00:25:33,770 --> 00:25:39,080
in some scenarios you may have

497
00:25:36,080 --> 00:25:42,350
additional containers responsible for

498
00:25:39,080 --> 00:25:45,020
some additional logic for example such

499
00:25:42,350 --> 00:25:48,080
additional container can be a logging

500
00:25:45,020 --> 00:25:49,520
agent container that will send audio all

501
00:25:48,080 --> 00:25:53,720
the locks from an application to some

502
00:25:49,520 --> 00:25:55,760
external logins logging system this

503
00:25:53,720 --> 00:25:59,450
additional container is in kubernetes

504
00:25:55,760 --> 00:26:03,320
word is called a sidecar container so we

505
00:25:59,450 --> 00:26:05,510
can do the same and put our cash as a

506
00:26:03,320 --> 00:26:10,220
sidecar to our application and deploy it

507
00:26:05,510 --> 00:26:12,980
in one who Burnett is pod so this time

508
00:26:10,220 --> 00:26:14,960
the floor looks as follows request comes

509
00:26:12,980 --> 00:26:16,700
to our system it goes to the kubernetes

510
00:26:14,960 --> 00:26:20,870
service which is kind of a load balancer

511
00:26:16,700 --> 00:26:23,240
in the kubernetes environment then it

512
00:26:20,870 --> 00:26:26,719
goes to one of the kubernetes pod and

513
00:26:23,240 --> 00:26:28,550
the rest is that is exactly the same as

514
00:26:26,720 --> 00:26:32,090
before application gets the request it

515
00:26:28,550 --> 00:26:33,669
connects to the cache server which which

516
00:26:32,090 --> 00:26:36,879
happens to be the

517
00:26:33,670 --> 00:26:38,740
cash container it's always located and

518
00:26:36,880 --> 00:26:40,210
on the local house so do we don't have

519
00:26:38,740 --> 00:26:41,680
because it's the same physical machine

520
00:26:40,210 --> 00:26:45,490
so we don't have any problems with

521
00:26:41,680 --> 00:26:47,500
discovery and all these cash containers

522
00:26:45,490 --> 00:26:51,570
in all pots they all form one cache

523
00:26:47,500 --> 00:26:54,190
cluster so side corn can be see as

524
00:26:51,570 --> 00:26:55,210
something in between embedded mode and a

525
00:26:54,190 --> 00:26:58,900
client-server mode

526
00:26:55,210 --> 00:27:02,560
it's like embedded because it's the same

527
00:26:58,900 --> 00:27:03,760
physical machine it uses the same

528
00:27:02,560 --> 00:27:06,280
resource pool together with the

529
00:27:03,760 --> 00:27:09,550
application and it scales up down

530
00:27:06,280 --> 00:27:10,899
together of the application also we

531
00:27:09,550 --> 00:27:13,080
don't need any discovery because it's

532
00:27:10,900 --> 00:27:14,950
always available on the hot localhost

533
00:27:13,080 --> 00:27:18,340
however it's also similar to

534
00:27:14,950 --> 00:27:21,100
client-server because like we can use

535
00:27:18,340 --> 00:27:24,550
different programming language after all

536
00:27:21,100 --> 00:27:27,760
it just uses client cache client to

537
00:27:24,550 --> 00:27:32,440
connect and there is some isolation

538
00:27:27,760 --> 00:27:34,360
between up and ending and the cache how

539
00:27:32,440 --> 00:27:37,480
would it look like in the code so in the

540
00:27:34,360 --> 00:27:39,070
code we would have like client

541
00:27:37,480 --> 00:27:40,690
configuration with the static

542
00:27:39,070 --> 00:27:44,860
configuration because we know that our

543
00:27:40,690 --> 00:27:48,220
cache server is on localhost how would

544
00:27:44,860 --> 00:27:51,100
we configure this in kubernetes is we

545
00:27:48,220 --> 00:27:54,430
have like deployment configuration with

546
00:27:51,100 --> 00:27:57,100
two containers the the one the first one

547
00:27:54,430 --> 00:28:00,280
is the our application so it's business

548
00:27:57,100 --> 00:28:04,659
logic the second one is it's always the

549
00:28:00,280 --> 00:28:07,320
same it's the cache server pros and cons

550
00:28:04,660 --> 00:28:09,670
of such solution so good thing is that

551
00:28:07,320 --> 00:28:12,970
configurations that are very simple and

552
00:28:09,670 --> 00:28:15,520
we have low latency it's not in the

553
00:28:12,970 --> 00:28:19,060
process but it's the same local network

554
00:28:15,520 --> 00:28:24,040
and there is some isolation of data

555
00:28:19,060 --> 00:28:25,870
applications from the downsides we are

556
00:28:24,040 --> 00:28:28,540
limited to container based environments

557
00:28:25,870 --> 00:28:31,360
you will hear about most in about this

558
00:28:28,540 --> 00:28:34,720
in kubernetes the management is not

559
00:28:31,360 --> 00:28:36,570
flexible again because it scales up and

560
00:28:34,720 --> 00:28:39,010
down together of the application and

561
00:28:36,570 --> 00:28:42,389
technically the data is co-located in

562
00:28:39,010 --> 00:28:44,890
the same application port which can or

563
00:28:42,390 --> 00:28:47,610
can does not have to but can be a

564
00:28:44,890 --> 00:28:47,610
problem

565
00:28:48,220 --> 00:28:55,880
the next pattern and the last one is

566
00:28:51,519 --> 00:28:58,970
something completely different because

567
00:28:55,880 --> 00:29:02,120
so far it was always the application

568
00:28:58,970 --> 00:29:05,769
that decided if a value should be cashed

569
00:29:02,120 --> 00:29:10,129
or not this time it would be different

570
00:29:05,769 --> 00:29:12,440
we will put the cash before the

571
00:29:10,130 --> 00:29:17,600
application so the application does not

572
00:29:12,440 --> 00:29:19,039
even know about cashing again the

573
00:29:17,600 --> 00:29:20,959
request comes to our assistant to the

574
00:29:19,039 --> 00:29:24,590
load balancer but just after the load

575
00:29:20,960 --> 00:29:26,809
balancer you have a cash so the it is

576
00:29:24,590 --> 00:29:30,949
cashed at the HTTP request level and

577
00:29:26,809 --> 00:29:33,320
then in this yellow box it's checked if

578
00:29:30,950 --> 00:29:36,350
the if we have if the request was

579
00:29:33,320 --> 00:29:41,750
already executed and we can reply with

580
00:29:36,350 --> 00:29:43,610
the with the cached response or if there

581
00:29:41,750 --> 00:29:48,679
is no cash value then go to the

582
00:29:43,610 --> 00:29:50,870
application very major solution is from

583
00:29:48,679 --> 00:29:52,730
nginx you can configure it actually

584
00:29:50,870 --> 00:29:54,830
together with your old balancer so if

585
00:29:52,730 --> 00:29:58,820
you use nginx for a load balancer then

586
00:29:54,830 --> 00:30:02,059
you you can configure caching with such

587
00:29:58,820 --> 00:30:04,789
a small part of the code obviously you

588
00:30:02,059 --> 00:30:07,519
can include more properties but the most

589
00:30:04,789 --> 00:30:12,158
important one is the pub where the cal

590
00:30:07,519 --> 00:30:12,159
values are stored and Eric is own

591
00:30:13,070 --> 00:30:17,240
so nginx is a matrix solution you can

592
00:30:15,440 --> 00:30:20,000
use it on production no problem of debt

593
00:30:17,240 --> 00:30:23,420
however it has some problems like first

594
00:30:20,000 --> 00:30:25,310
thing is that it's only HTTP based this

595
00:30:23,420 --> 00:30:30,410
is maybe not such a big deal because we

596
00:30:25,310 --> 00:30:33,260
in micro services usually is its HTTP

597
00:30:30,410 --> 00:30:37,730
based unless you unless you work at

598
00:30:33,260 --> 00:30:40,700
Google and or and use protobuf but or

599
00:30:37,730 --> 00:30:43,100
have some very like streak requirements

600
00:30:40,700 --> 00:30:47,570
then you may use protobuf but otherwise

601
00:30:43,100 --> 00:30:50,120
use HTTP it's not distributed it is not

602
00:30:47,570 --> 00:30:53,450
highly available and the data is stored

603
00:30:50,120 --> 00:30:54,770
on a disk which again might not sound

604
00:30:53,450 --> 00:30:59,060
like a big problem

605
00:30:54,770 --> 00:31:03,650
however like it is a big deal in this in

606
00:30:59,060 --> 00:31:05,899
memory data grid area that you would

607
00:31:03,650 --> 00:31:09,890
like to be guaranteed that your data is

608
00:31:05,900 --> 00:31:14,450
in memory what you could do is use a

609
00:31:09,890 --> 00:31:16,310
plug-in to nginx however the plug-in is

610
00:31:14,450 --> 00:31:19,640
like for Oh hazel caste it does not

611
00:31:16,310 --> 00:31:21,679
exist and for readies it exists but it's

612
00:31:19,640 --> 00:31:23,450
super not much major at all so I would

613
00:31:21,680 --> 00:31:28,220
not recommend it for a production but

614
00:31:23,450 --> 00:31:30,320
this is something you can use we can

615
00:31:28,220 --> 00:31:33,950
think about like the same pattern but

616
00:31:30,320 --> 00:31:37,760
again move it's complicated a little bit

617
00:31:33,950 --> 00:31:41,540
and to merge like sidecar pattern and

618
00:31:37,760 --> 00:31:43,220
reverse proxy pattern it's something

619
00:31:41,540 --> 00:31:47,300
different so it could be again like a

620
00:31:43,220 --> 00:31:49,790
different architectural pattern again

621
00:31:47,300 --> 00:31:55,340
with the sidecar we limit ourselves to

622
00:31:49,790 --> 00:31:58,159
the kubernetes environment now it's the

623
00:31:55,340 --> 00:31:59,899
flows is as follows kubernetes service

624
00:31:58,160 --> 00:32:03,440
receives the request and pass it to one

625
00:31:59,900 --> 00:32:05,150
of the pods however this time is not the

626
00:32:03,440 --> 00:32:09,950
application that receives the request

627
00:32:05,150 --> 00:32:12,140
but the reverse proxy cache container it

628
00:32:09,950 --> 00:32:14,270
checks if the request is cached and if

629
00:32:12,140 --> 00:32:16,970
it's not then it passes it passes it to

630
00:32:14,270 --> 00:32:20,570
the application container so the

631
00:32:16,970 --> 00:32:22,670
application does not know that such

632
00:32:20,570 --> 00:32:24,889
thing as reverse proxy cache container

633
00:32:22,670 --> 00:32:25,910
exists application does not know about

634
00:32:24,890 --> 00:32:28,340
caching

635
00:32:25,910 --> 00:32:32,150
and this fact has some good sides and

636
00:32:28,340 --> 00:32:37,399
bad sides so maybe let's start from what

637
00:32:32,150 --> 00:32:39,370
is good let's come back to this diagram

638
00:32:37,400 --> 00:32:42,460
from the beginning of this presentation

639
00:32:39,370 --> 00:32:44,780
which is a classic micro-service system

640
00:32:42,460 --> 00:32:46,970
so Microsoft is using each other they

641
00:32:44,780 --> 00:32:48,379
have different version and and can be

642
00:32:46,970 --> 00:32:51,559
written in different languages and

643
00:32:48,380 --> 00:32:55,150
framework now if you would like to

644
00:32:51,559 --> 00:32:58,908
introduce caching to this system then

645
00:32:55,150 --> 00:33:03,289
you can actually say in the declarative

646
00:32:58,909 --> 00:33:07,010
manner without touching the code of the

647
00:33:03,289 --> 00:33:11,440
service that these two two services I

648
00:33:07,010 --> 00:33:15,289
would like them to be cached and this is

649
00:33:11,440 --> 00:33:17,780
very good because you don't risk like

650
00:33:15,289 --> 00:33:20,030
breaking some code and a service you

651
00:33:17,780 --> 00:33:25,340
don't have to change anything in the

652
00:33:20,030 --> 00:33:27,020
code it's completely separated this is

653
00:33:25,340 --> 00:33:30,918
how it would look like in the company's

654
00:33:27,020 --> 00:33:32,570
configuration so again like this time we

655
00:33:30,919 --> 00:33:35,840
we have here free actually free

656
00:33:32,570 --> 00:33:38,809
containers the last one is the our

657
00:33:35,840 --> 00:33:40,370
application still the same then we have

658
00:33:38,809 --> 00:33:43,220
caching proxy so this is discussing

659
00:33:40,370 --> 00:33:47,209
proxy you've seen on the diagram we also

660
00:33:43,220 --> 00:33:48,950
need an init container which will do one

661
00:33:47,210 --> 00:33:52,549
thing in it container is something that

662
00:33:48,950 --> 00:33:55,880
run runs before actually pot starts and

663
00:33:52,549 --> 00:34:00,620
this our each container will change how

664
00:33:55,880 --> 00:34:02,299
the networking works in the pot because

665
00:34:00,620 --> 00:34:04,520
normally is the application that would

666
00:34:02,299 --> 00:34:06,740
receive the request however we would

667
00:34:04,520 --> 00:34:12,980
like to change it so this init container

668
00:34:06,740 --> 00:34:15,649
will change change our IP tables so that

669
00:34:12,980 --> 00:34:18,469
the requests any external requests with

670
00:34:15,649 --> 00:34:20,899
the port let's say a tea that goes to

671
00:34:18,469 --> 00:34:22,520
our system will go not to the

672
00:34:20,899 --> 00:34:24,888
application directly but first to the

673
00:34:22,520 --> 00:34:26,418
reverse proxy and then reverse proxy

674
00:34:24,889 --> 00:34:31,350
connect to the application using the

675
00:34:26,418 --> 00:34:33,889
same port but using the loop back so

676
00:34:31,350 --> 00:34:36,719
that this is what this in networking

677
00:34:33,889 --> 00:34:41,850
container in networking script will

678
00:34:36,719 --> 00:34:46,129
change in our IP tables if you look at

679
00:34:41,850 --> 00:34:48,779
this diagram and how we edit the cache

680
00:34:46,130 --> 00:34:51,090
it's kind of a caching injection it

681
00:34:48,780 --> 00:34:53,520
makes you make you think this diagram

682
00:34:51,090 --> 00:34:55,860
about the service match and East your

683
00:34:53,520 --> 00:35:00,900
thing which is like now becoming like

684
00:34:55,860 --> 00:35:04,490
the most popular thing in the world like

685
00:35:00,900 --> 00:35:07,980
two days ago I was on the conference and

686
00:35:04,490 --> 00:35:10,379
the day the conference was it was about

687
00:35:07,980 --> 00:35:12,510
the DevOps conference but the whole

688
00:35:10,380 --> 00:35:14,940
conference like almost all the talks

689
00:35:12,510 --> 00:35:18,330
were about service mesh is your that is

690
00:35:14,940 --> 00:35:19,560
what is going on out of the world and if

691
00:35:18,330 --> 00:35:21,690
you go to the whisky oh page you have a

692
00:35:19,560 --> 00:35:24,630
very similar actually diagram because

693
00:35:21,690 --> 00:35:27,240
the East you ordered us it is the same

694
00:35:24,630 --> 00:35:29,970
idea easier lets you add functionality

695
00:35:27,240 --> 00:35:32,189
to our service in a declarative manner

696
00:35:29,970 --> 00:35:37,459
so you don't change anything in our

697
00:35:32,190 --> 00:35:39,900
system but say I would like to use like

698
00:35:37,460 --> 00:35:42,960
from the service to I would like to

699
00:35:39,900 --> 00:35:45,270
control the traffic and send like 90% of

700
00:35:42,960 --> 00:35:51,360
the requests to the version 1 of service

701
00:35:45,270 --> 00:35:56,130
and the 10% to the version 2 without

702
00:35:51,360 --> 00:35:59,250
changing any any code so east your

703
00:35:56,130 --> 00:36:01,170
actually would could have this casting

704
00:35:59,250 --> 00:36:03,480
functionality but it does not have at

705
00:36:01,170 --> 00:36:07,380
the moment but they plan to support like

706
00:36:03,480 --> 00:36:10,650
caching this way they not only planned

707
00:36:07,380 --> 00:36:13,110
there is if you go to their like github

708
00:36:10,650 --> 00:36:16,820
repo there is an open TR so it will be

709
00:36:13,110 --> 00:36:16,820
come soon soon a big thing

710
00:36:17,270 --> 00:36:22,340
however such a prote with this reverse

711
00:36:19,610 --> 00:36:26,600
proxy caching also had some has some bad

712
00:36:22,340 --> 00:36:28,850
sides so if you detach like the cash

713
00:36:26,600 --> 00:36:31,880
from the application there is one thing

714
00:36:28,850 --> 00:36:35,600
that becomes way more difficult and that

715
00:36:31,880 --> 00:36:37,610
thing is cache invalidation actually if

716
00:36:35,600 --> 00:36:39,080
you look anywhere on the internet what

717
00:36:37,610 --> 00:36:41,240
causes the most of the issues with

718
00:36:39,080 --> 00:36:44,420
caching everyone will tell you the same

719
00:36:41,240 --> 00:36:46,669
it's invalidation meaning when to decide

720
00:36:44,420 --> 00:36:48,890
that the cached value is already stale

721
00:36:46,670 --> 00:36:50,780
that I should not should not use the

722
00:36:48,890 --> 00:36:53,359
value from cache but I should go

723
00:36:50,780 --> 00:36:55,490
directly to the database if you change

724
00:36:53,360 --> 00:36:59,150
thing in the database how do you know

725
00:36:55,490 --> 00:37:01,790
that the value was changed so in case of

726
00:36:59,150 --> 00:37:03,950
the application we can do at least

727
00:37:01,790 --> 00:37:05,930
something in the application code in a

728
00:37:03,950 --> 00:37:09,680
bit in the logic of the of the service

729
00:37:05,930 --> 00:37:11,750
to decide if if I would like to

730
00:37:09,680 --> 00:37:15,200
invalidate some of the some of the cash

731
00:37:11,750 --> 00:37:17,320
values however if the cache is a

732
00:37:15,200 --> 00:37:19,549
separate thing from the application and

733
00:37:17,320 --> 00:37:22,490
application does not know about it then

734
00:37:19,550 --> 00:37:25,790
we are limited to the some HTTP basic

735
00:37:22,490 --> 00:37:29,120
stuff like timeouts attacks generally

736
00:37:25,790 --> 00:37:33,880
like timeouts so this this is actually a

737
00:37:29,120 --> 00:37:33,880
bad ad this kind of difficulty

738
00:37:34,359 --> 00:37:39,819
short summary on the reverse proxy and

739
00:37:36,729 --> 00:37:42,218
reverse proxy cash sidecar caching so

740
00:37:39,819 --> 00:37:44,739
the good thing the main good thing is

741
00:37:42,219 --> 00:37:46,599
that it's configuration based so you

742
00:37:44,739 --> 00:37:48,249
don't need to need to change anything in

743
00:37:46,599 --> 00:37:50,979
your application in order to apply

744
00:37:48,249 --> 00:37:52,359
caching it's also programming language

745
00:37:50,979 --> 00:37:53,859
agnostic it's actually everything

746
00:37:52,359 --> 00:37:56,529
agnostic because it does not even touch

747
00:37:53,859 --> 00:37:58,390
the code River application and it's very

748
00:37:56,529 --> 00:38:01,839
consistent with the containers and micro

749
00:37:58,390 --> 00:38:05,259
service were worked from the downsides

750
00:38:01,839 --> 00:38:08,109
it's difficult it is difficult to do the

751
00:38:05,259 --> 00:38:10,359
cache invalidation and there's no major

752
00:38:08,109 --> 00:38:13,779
solution yet so Easter is implementing

753
00:38:10,359 --> 00:38:16,449
this we in Hydra cast did a prototype a

754
00:38:13,779 --> 00:38:18,969
kind of proof of concept but there is no

755
00:38:16,449 --> 00:38:22,029
nothing that you could use on the

756
00:38:18,969 --> 00:38:23,709
production yet but it will be come in a

757
00:38:22,029 --> 00:38:27,670
year or two you will hear about it more

758
00:38:23,709 --> 00:38:30,129
and more from Delta animation also it's

759
00:38:27,670 --> 00:38:33,069
a protocol based but as I said before I

760
00:38:30,130 --> 00:38:38,499
don't think it's a big deal if you using

761
00:38:33,069 --> 00:38:40,449
micro services you already use HTTP so

762
00:38:38,499 --> 00:38:41,649
like this we came to the end of our

763
00:38:40,449 --> 00:38:45,189
agenda for today

764
00:38:41,650 --> 00:38:48,549
so as a very short summary I know there

765
00:38:45,189 --> 00:38:54,399
are a lot of patterns here so how to

766
00:38:48,549 --> 00:38:56,650
structure this in one's mind I thought

767
00:38:54,400 --> 00:38:59,170
about creating a small decision tree

768
00:38:56,650 --> 00:39:01,869
which can help you decide on which

769
00:38:59,170 --> 00:39:05,319
pattern to use in your system so the

770
00:39:01,869 --> 00:39:08,049
first question I would ask if I were to

771
00:39:05,319 --> 00:39:09,609
design a system is if there is a need

772
00:39:08,049 --> 00:39:13,599
for my application to be aware of

773
00:39:09,609 --> 00:39:18,279
caching if no then if I do I use

774
00:39:13,599 --> 00:39:21,130
container environment or no if no I can

775
00:39:18,279 --> 00:39:25,049
use just major solution from nginx

776
00:39:21,130 --> 00:39:25,049
and reverse proxy

777
00:39:25,260 --> 00:39:32,280
if yes then use reverse proxy sidecar as

778
00:39:29,430 --> 00:39:34,859
soon as there is a my true solution yet

779
00:39:32,280 --> 00:39:38,130
my estimate for this is in one or two

780
00:39:34,859 --> 00:39:39,990
years people will use it now if your

781
00:39:38,130 --> 00:39:43,530
application needs to be aware of the

782
00:39:39,990 --> 00:39:45,540
caching then the next question you can

783
00:39:43,530 --> 00:39:49,020
ask is do I have a lot of data some

784
00:39:45,540 --> 00:39:51,000
security restrictions basically is my

785
00:39:49,020 --> 00:39:55,710
application kind of enterprise big

786
00:39:51,000 --> 00:39:57,390
enterprise thing if no do I need to be

787
00:39:55,710 --> 00:39:59,700
language agnostic or is it containers

788
00:39:57,390 --> 00:40:04,500
based if no then tells you simple

789
00:39:59,700 --> 00:40:06,660
embedded ApS use sidecar however if you

790
00:40:04,500 --> 00:40:09,720
work in a big enterprise big

791
00:40:06,660 --> 00:40:11,640
organization they usually would generate

792
00:40:09,720 --> 00:40:13,879
it with a big system then the last

793
00:40:11,640 --> 00:40:16,710
question you have to ask yourself is my

794
00:40:13,880 --> 00:40:20,580
deployment in my is my infrastructure in

795
00:40:16,710 --> 00:40:24,810
the cloud do I use a wsg CP or Ezra for

796
00:40:20,580 --> 00:40:29,130
four deployments if no use trying server

797
00:40:24,810 --> 00:40:31,140
on premise if yes then use some

798
00:40:29,130 --> 00:40:34,680
cloud-based solution like has Lucas

799
00:40:31,140 --> 00:40:39,180
cloud already slabs or whatever else is

800
00:40:34,680 --> 00:40:40,830
on the market so at the last slide I've

801
00:40:39,180 --> 00:40:44,609
put some resources you can read about

802
00:40:40,830 --> 00:40:48,890
about caching the first one is our proof

803
00:40:44,609 --> 00:40:52,619
of concept of HTTP reverse proxy sidecar

804
00:40:48,890 --> 00:40:54,690
the second one is sorry third one is a

805
00:40:52,619 --> 00:40:56,640
blog post about sidecar hazel caste the

806
00:40:54,690 --> 00:40:59,640
second one is this reverse proxy caching

807
00:40:56,640 --> 00:41:03,270
prototype proof of concept third one is

808
00:40:59,640 --> 00:41:06,839
a very good blog post about caching in

809
00:41:03,270 --> 00:41:09,570
general and some caching best practices

810
00:41:06,840 --> 00:41:12,630
and the last one is a very good video

811
00:41:09,570 --> 00:41:16,890
presentation presentation on how to use

812
00:41:12,630 --> 00:41:18,869
nginx for reverse proxy caching and with

813
00:41:16,890 --> 00:41:22,609
this last slide I would like to thank

814
00:41:18,869 --> 00:41:22,609
you for attending this talk

815
00:41:25,210 --> 00:41:34,980
[Applause]

816
00:41:27,240 --> 00:41:34,979
so sorry do you have any questions

817
00:41:43,820 --> 00:41:51,410
yes hi hello okay okay so uh can you

818
00:41:48,770 --> 00:41:53,690
hear me yes yes okay yes so you guys

819
00:41:51,410 --> 00:41:56,420
made a proof of concept in Heiser cost

820
00:41:53,690 --> 00:41:58,970
for reverse proxy sidecar for Humanity's

821
00:41:56,420 --> 00:42:01,400
yeah and you said that the hardest

822
00:41:58,970 --> 00:42:03,080
problem is to basically invalidate the

823
00:42:01,400 --> 00:42:05,630
cache and if we keep your application

824
00:42:03,080 --> 00:42:08,060
separate you know so completely unaware

825
00:42:05,630 --> 00:42:09,850
of the of the you know caching sidecar

826
00:42:08,060 --> 00:42:16,580
so how did you guys solve this

827
00:42:09,850 --> 00:42:17,930
invalidation problem so thanks this is

828
00:42:16,580 --> 00:42:21,560
like the main problem that you just

829
00:42:17,930 --> 00:42:23,569
cannot solve in a sense that the the

830
00:42:21,560 --> 00:42:25,480
whole idea is that application is not

831
00:42:23,570 --> 00:42:28,460
aware that's why you will not solve it

832
00:42:25,480 --> 00:42:30,740
probably if we were like to create a

833
00:42:28,460 --> 00:42:32,330
production-ready solution there would be

834
00:42:30,740 --> 00:42:34,310
a lot of like engineering problems that

835
00:42:32,330 --> 00:42:36,799
we have just have to tackle but this

836
00:42:34,310 --> 00:42:39,890
what I mentioned is about like that this

837
00:42:36,800 --> 00:42:41,900
will probably never be solved the solve

838
00:42:39,890 --> 00:42:45,980
the best thing you could do is to create

839
00:42:41,900 --> 00:42:47,810
for example an endpoint with the Sun but

840
00:42:45,980 --> 00:42:50,240
that application again becomes aware of

841
00:42:47,810 --> 00:42:52,279
the cache which actually breaks the

842
00:42:50,240 --> 00:42:56,029
whole thing so I would say this pattern

843
00:42:52,280 --> 00:42:59,240
is only for this pattern dedicated to

844
00:42:56,030 --> 00:43:02,890
some use cases where your application

845
00:42:59,240 --> 00:43:02,890
does not need to know about caching

846
00:43:05,040 --> 00:43:10,290
hey thanks for the talk I have a

847
00:43:08,010 --> 00:43:15,800
question about the service you mentioned

848
00:43:10,290 --> 00:43:19,380
the eesti oh I think are there any other

849
00:43:15,800 --> 00:43:21,630
good sides or features or anything since

850
00:43:19,380 --> 00:43:24,150
I haven't heard of that service besides

851
00:43:21,630 --> 00:43:26,430
the one where you can load balance your

852
00:43:24,150 --> 00:43:30,030
requests for example switching to the

853
00:43:26,430 --> 00:43:36,089
new version of API and then doing 10%

854
00:43:30,030 --> 00:43:38,160
90% and increasing yes so yeah it's like

855
00:43:36,090 --> 00:43:39,810
actually very hot topic so really I

856
00:43:38,160 --> 00:43:41,640
recommend it to everyone to play with

857
00:43:39,810 --> 00:43:44,940
this if you don't want to install

858
00:43:41,640 --> 00:43:46,799
yourself you can even go to the Google

859
00:43:44,940 --> 00:43:49,380
cloud and just there's even a tick box

860
00:43:46,800 --> 00:43:52,350
to say creating a kubernetes cluster

861
00:43:49,380 --> 00:43:53,820
who've already installed but to answer a

862
00:43:52,350 --> 00:43:57,868
question like so

863
00:43:53,820 --> 00:43:59,940
easter is basically for as for now it

864
00:43:57,869 --> 00:44:01,350
has like the feature of traffic

865
00:43:59,940 --> 00:44:03,330
management so exactly what I mentioned

866
00:44:01,350 --> 00:44:06,960
it has a feature for security that you

867
00:44:03,330 --> 00:44:11,310
can have a security also declared like

868
00:44:06,960 --> 00:44:13,200
and you could declare in a declarative

869
00:44:11,310 --> 00:44:15,390
way it might make you think about like a

870
00:44:13,200 --> 00:44:16,830
spur oriented programming so will you

871
00:44:15,390 --> 00:44:18,509
think about in a service about the

872
00:44:16,830 --> 00:44:20,609
business logic but you don't want to

873
00:44:18,510 --> 00:44:23,040
think about the same security thing in

874
00:44:20,609 --> 00:44:25,410
each of the service that's why you can

875
00:44:23,040 --> 00:44:27,650
add it to the in a declarative way in

876
00:44:25,410 --> 00:44:33,299
Easter so that every request coming is

877
00:44:27,650 --> 00:44:36,540
is secured so basically as for now is

878
00:44:33,300 --> 00:44:38,910
the Easter is for network control and

879
00:44:36,540 --> 00:44:40,500
address and security but they are adding

880
00:44:38,910 --> 00:44:44,060
feature like caching is one of the

881
00:44:40,500 --> 00:44:44,060
feature they will add definitely

882
00:44:47,310 --> 00:44:50,390
any more questions

883
00:44:55,559 --> 00:45:02,319
more one more question on the cache

884
00:44:58,839 --> 00:45:05,529
invalidation so in a scenario where the

885
00:45:02,319 --> 00:45:09,160
application is unaware of the cache of

886
00:45:05,529 --> 00:45:12,759
course it doesn't make sense to forcibly

887
00:45:09,160 --> 00:45:16,109
make it aware is there a possibility for

888
00:45:12,759 --> 00:45:18,939
the cache itself to become aware that

889
00:45:16,109 --> 00:45:22,630
certain entries need to be invalidated

890
00:45:18,939 --> 00:45:26,828
for instance if you're fronting regular

891
00:45:22,630 --> 00:45:30,429
micro service with REST API making any

892
00:45:26,829 --> 00:45:35,380
kind of put or delete request to us a

893
00:45:30,429 --> 00:45:43,259
certain path would mean that whatever is

894
00:45:35,380 --> 00:45:48,489
caching the entity on that path is no

895
00:45:43,259 --> 00:45:52,839
longer to be used now I'm not aware if

896
00:45:48,489 --> 00:45:57,449
the cache is can do that

897
00:45:52,839 --> 00:46:01,479
do you have an experience there yeah

898
00:45:57,449 --> 00:46:05,679
like to answer a question like yes if

899
00:46:01,479 --> 00:46:07,899
the application is not aware then you

900
00:46:05,679 --> 00:46:09,719
can still cache will invalidate entries

901
00:46:07,900 --> 00:46:12,130
you can and you can inside the cache

902
00:46:09,719 --> 00:46:14,319
that fine define a strategy how it

903
00:46:12,130 --> 00:46:17,199
should be invalidated should be timeout

904
00:46:14,319 --> 00:46:20,019
or some eviction policy like invalidate

905
00:46:17,199 --> 00:46:22,619
for me the last use entries that is

906
00:46:20,019 --> 00:46:24,999
still fine

907
00:46:22,619 --> 00:46:27,099
however like what you mentioned like

908
00:46:24,999 --> 00:46:30,569
after this like that you've got basing

909
00:46:27,099 --> 00:46:32,469
on the HTTP requests do some

910
00:46:30,569 --> 00:46:34,209
invalidation I think it would be

911
00:46:32,469 --> 00:46:36,759
possible I mean there's no solution

912
00:46:34,209 --> 00:46:40,239
implemented yet so this whole theory but

913
00:46:36,759 --> 00:46:42,699
I think so nginx does not do it I just

914
00:46:40,239 --> 00:46:44,169
so any there is no solution yet but in

915
00:46:42,699 --> 00:46:46,959
theory you could think about something

916
00:46:44,169 --> 00:46:50,259
like that however like the problem I see

917
00:46:46,959 --> 00:46:53,890
is that it could work with super

918
00:46:50,259 --> 00:46:56,439
standard rest requests right here but in

919
00:46:53,890 --> 00:46:58,569
any other like when you have some

920
00:46:56,439 --> 00:47:02,169
business logic then it could become more

921
00:46:58,569 --> 00:47:03,939
difficult so I'm not sure if I would

922
00:47:02,169 --> 00:47:06,270
have to think about it if we if I were

923
00:47:03,939 --> 00:47:08,490
to implement it to

924
00:47:06,270 --> 00:47:10,349
because it sounds good like if you fall

925
00:47:08,490 --> 00:47:12,479
like rests in maturity model and you

926
00:47:10,349 --> 00:47:14,400
have everything like then yes let's do

927
00:47:12,480 --> 00:47:16,589
it this way but I had to think if there

928
00:47:14,400 --> 00:47:19,560
are not too many like corner cases and

929
00:47:16,589 --> 00:47:22,009
for things when so yeah I don't have

930
00:47:19,560 --> 00:47:27,950
like the answer like would it make sense

931
00:47:22,010 --> 00:47:27,950
it's a good idea yeah okay thank you

932
00:47:34,460 --> 00:47:37,329
any last questions

933
00:47:41,970 --> 00:47:46,379
there's no questions then thank you

934
00:47:44,110 --> 00:47:46,380
again

935
00:48:12,660 --> 00:48:14,720
you

