1
00:00:27,670 --> 00:00:34,960
next up please welcome gadget who will

2
00:00:31,280 --> 00:00:34,960
tell us something about eyes for robots

3
00:00:36,310 --> 00:00:42,260
good evening everybody how's everybody

4
00:00:38,600 --> 00:00:44,090
doing my name is Tommy Gianni some of

5
00:00:42,260 --> 00:00:48,980
you might not be as nice gadget thank

6
00:00:44,090 --> 00:00:52,450
you so much short introduction Who am I

7
00:00:48,980 --> 00:00:56,269
I'm about assist love building robots

8
00:00:52,450 --> 00:00:58,430
competed in a few competitions

9
00:00:56,269 --> 00:01:00,489
I work as a technology specialist

10
00:00:58,430 --> 00:01:03,199
whatever that means at the Swiss company

11
00:01:00,489 --> 00:01:05,870
and I love to build stuff so you might

12
00:01:03,199 --> 00:01:10,190
have noticed the big-ass video wall that

13
00:01:05,870 --> 00:01:12,130
we have in the makerspace and yeah I'm

14
00:01:10,190 --> 00:01:15,320
today we're going to talk about robots

15
00:01:12,130 --> 00:01:20,390
because robots well they're basically

16
00:01:15,320 --> 00:01:23,690
everywhere they're underwater they're on

17
00:01:20,390 --> 00:01:28,160
the water they they're on the land I

18
00:01:23,690 --> 00:01:31,240
mean we see Tesla's we see robots that

19
00:01:28,160 --> 00:01:35,840
deliver packets that little passengers

20
00:01:31,240 --> 00:01:40,130
we even send some to different planets

21
00:01:35,840 --> 00:01:44,590
and of course drugs so right now

22
00:01:40,130 --> 00:01:47,270
everybody everyone can only drone but

23
00:01:44,590 --> 00:01:50,380
this is really an exciting times we went

24
00:01:47,270 --> 00:01:56,560
from actual science fiction to science

25
00:01:50,380 --> 00:02:02,110
fact so wait here

26
00:01:56,560 --> 00:02:04,570
does it play yeah so what black magic

27
00:02:02,110 --> 00:02:08,800
yes of course black magic and cats and

28
00:02:04,570 --> 00:02:11,230
Roombas so a few decades ago

29
00:02:08,800 --> 00:02:12,940
like the Terminator movie was like at a

30
00:02:11,230 --> 00:02:14,679
science fiction movie and if we look

31
00:02:12,940 --> 00:02:17,500
like at the current technology we're

32
00:02:14,680 --> 00:02:23,230
quite close to to what was depicted

33
00:02:17,500 --> 00:02:26,050
there and building robots is hard so we

34
00:02:23,230 --> 00:02:29,260
didn't get we didn't get there from one

35
00:02:26,050 --> 00:02:31,959
day to another there was a lot of this

36
00:02:29,260 --> 00:02:36,010
in between so this is actually from the

37
00:02:31,959 --> 00:02:38,200
DARPA Robotics Challenge I think the

38
00:02:36,010 --> 00:02:43,390
title of that video is robots might be

39
00:02:38,200 --> 00:02:46,299
just drunk people so Rob building robots

40
00:02:43,390 --> 00:02:48,670
is the easy part actually let the robot

41
00:02:46,300 --> 00:02:52,569
do what you intended to do is actually

42
00:02:48,670 --> 00:02:57,060
the really really tricky part so they

43
00:02:52,569 --> 00:02:57,060
all actually share the same problem

44
00:02:57,600 --> 00:03:03,280
navigation so what is navigation it's

45
00:03:01,360 --> 00:03:05,650
the process or activity of accurately

46
00:03:03,280 --> 00:03:07,390
ascertaining one's position and planning

47
00:03:05,650 --> 00:03:11,200
and following a route according to

48
00:03:07,390 --> 00:03:13,570
Google so we know different ways of

49
00:03:11,200 --> 00:03:18,280
navigation so we used everyday

50
00:03:13,570 --> 00:03:20,290
technologies like GPS we use lidar we

51
00:03:18,280 --> 00:03:22,600
use inertial measurements you have

52
00:03:20,290 --> 00:03:28,090
measurement units so we got that in our

53
00:03:22,600 --> 00:03:32,590
in the hand so in the cell phones we got

54
00:03:28,090 --> 00:03:36,220
sonar we got radar and we got computer

55
00:03:32,590 --> 00:03:37,299
vision so each and every technology has

56
00:03:36,220 --> 00:03:41,620
its ups and downs

57
00:03:37,299 --> 00:03:46,570
so GPS is very very cheap to get these

58
00:03:41,620 --> 00:03:48,459
days it's basically free and you get

59
00:03:46,570 --> 00:03:51,400
global coverage or mostly got global

60
00:03:48,459 --> 00:03:55,450
coverage but for robotics just relying

61
00:03:51,400 --> 00:03:58,540
on GPS consumer-grade receivers they're

62
00:03:55,450 --> 00:04:01,660
not that I'm not accurate enough so and

63
00:03:58,540 --> 00:04:04,420
they need enough size so ever try to

64
00:04:01,660 --> 00:04:05,200
keep it and navigate by phone inside of

65
00:04:04,420 --> 00:04:10,089
a build

66
00:04:05,200 --> 00:04:12,369
kinda sucks so lidar uses lasers this is

67
00:04:10,090 --> 00:04:14,730
pretty awesome technology super fast is

68
00:04:12,370 --> 00:04:20,019
accurate for their range is fantastic

69
00:04:14,730 --> 00:04:22,180
but it's expensive and too the generated

70
00:04:20,019 --> 00:04:24,940
data is massive so you actually need a

71
00:04:22,180 --> 00:04:28,870
lot of processing power to actually make

72
00:04:24,940 --> 00:04:31,150
something useful out of that data and

73
00:04:28,870 --> 00:04:34,360
then we have inertial measurement units

74
00:04:31,150 --> 00:04:38,140
they're pretty cheap the data

75
00:04:34,360 --> 00:04:41,620
acquisition is super fast but they drift

76
00:04:38,140 --> 00:04:45,039
over time and if you want to know more

77
00:04:41,620 --> 00:04:46,960
about IMU navigation you should see this

78
00:04:45,040 --> 00:04:49,540
guys talk from last year's ball count

79
00:04:46,960 --> 00:04:53,770
dancing at the dark where he actually

80
00:04:49,540 --> 00:04:56,530
explains what why I'm use are like they

81
00:04:53,770 --> 00:04:59,109
are and then we have computer vision

82
00:04:56,530 --> 00:05:01,059
it's pretty cheap to start off if you

83
00:04:59,110 --> 00:05:02,530
can you can spend a lot of money in

84
00:05:01,060 --> 00:05:05,440
computer vision if you're regarding

85
00:05:02,530 --> 00:05:07,690
hardware but it's pretty robust works

86
00:05:05,440 --> 00:05:10,870
indoors and outdoors depending under the

87
00:05:07,690 --> 00:05:12,940
camera that you use and again the

88
00:05:10,870 --> 00:05:14,500
accuracy is depending on the on the

89
00:05:12,940 --> 00:05:17,650
amount of hardware and processing power

90
00:05:14,500 --> 00:05:20,140
that you actually have here the same

91
00:05:17,650 --> 00:05:24,489
problem with lidar it can generate a lot

92
00:05:20,140 --> 00:05:26,849
a lot of data so what kind of sensors

93
00:05:24,490 --> 00:05:29,530
are there so I'm going to talk about

94
00:05:26,850 --> 00:05:32,200
three different kinds of sensors so we

95
00:05:29,530 --> 00:05:34,840
got stereoscopic amount of scopic and

96
00:05:32,200 --> 00:05:37,330
structured light so what is a

97
00:05:34,840 --> 00:05:42,310
stereoscopic sensor so it's basically

98
00:05:37,330 --> 00:05:43,990
two cameras like we got in our eyes like

99
00:05:42,310 --> 00:05:47,530
who they are with our eyes and we can

100
00:05:43,990 --> 00:05:52,270
extract three-dimensional information by

101
00:05:47,530 --> 00:05:54,340
comparing two images so well how do we

102
00:05:52,270 --> 00:05:55,659
perceive three-dimensional work so if

103
00:05:54,340 --> 00:05:57,609
you put your finger very close to your

104
00:05:55,660 --> 00:06:00,039
face and you close one eye after the

105
00:05:57,610 --> 00:06:03,250
other you'll you will notice that the

106
00:06:00,039 --> 00:06:05,620
finger will jump a lot between the

107
00:06:03,250 --> 00:06:08,050
between the two eyes and if you focus on

108
00:06:05,620 --> 00:06:11,350
a pit on a point that's far further away

109
00:06:08,050 --> 00:06:13,660
it probably won't jump at all and this

110
00:06:11,350 --> 00:06:14,400
is basically what we're trying to

111
00:06:13,660 --> 00:06:18,210
replicate

112
00:06:14,400 --> 00:06:21,090
Kate with Syrio sensors so yeah we have

113
00:06:18,210 --> 00:06:23,580
serious sensors too and this is how we

114
00:06:21,090 --> 00:06:27,750
do it so we compare different points in

115
00:06:23,580 --> 00:06:31,820
different images to actually try to

116
00:06:27,750 --> 00:06:34,800
calculate how far is that point in space

117
00:06:31,820 --> 00:06:35,940
and it could it looks something like

118
00:06:34,800 --> 00:06:38,490
that

119
00:06:35,940 --> 00:06:40,680
so to explain the overview so we have

120
00:06:38,490 --> 00:06:43,979
what we actually see in the right you

121
00:06:40,680 --> 00:06:46,530
know to the image and the lower part we

122
00:06:43,979 --> 00:06:49,469
see what the depth calculation looks

123
00:06:46,530 --> 00:06:51,690
like and in the right on the right part

124
00:06:49,470 --> 00:06:58,320
we actually see the combination of both

125
00:06:51,690 --> 00:07:00,479
of them all right so this looks this is

126
00:06:58,320 --> 00:07:02,460
good but yeah what can we do with it

127
00:07:00,479 --> 00:07:05,280
look but now all right let's talk about

128
00:07:02,460 --> 00:07:09,599
features how do we know that these

129
00:07:05,280 --> 00:07:11,849
pictures belong together so if you look

130
00:07:09,599 --> 00:07:15,570
at him for us it's pretty obvious they

131
00:07:11,849 --> 00:07:18,750
might be in the same spot so the same

132
00:07:15,570 --> 00:07:22,020
thing goes for robots so we try to find

133
00:07:18,750 --> 00:07:23,880
feature so-called features in pictures

134
00:07:22,020 --> 00:07:29,698
and try to find them in the next image

135
00:07:23,880 --> 00:07:31,889
and this is how we can actually tell or

136
00:07:29,699 --> 00:07:34,039
the grower can tell that yet these

137
00:07:31,889 --> 00:07:37,320
pictures belong together

138
00:07:34,039 --> 00:07:41,010
well something crucial I didn't have to

139
00:07:37,320 --> 00:07:43,199
keep in mind navigation or image

140
00:07:41,010 --> 00:07:47,550
processing is highly reliable on image

141
00:07:43,199 --> 00:07:49,320
quality whoever got up at night and

142
00:07:47,550 --> 00:07:52,289
didn't turn on the lights and actually

143
00:07:49,320 --> 00:07:55,919
knew where he was and bumped his foot

144
00:07:52,289 --> 00:07:59,460
anyways so we're even us we're relying

145
00:07:55,919 --> 00:08:01,889
on it and I mean reoccurring patterns is

146
00:07:59,460 --> 00:08:03,870
pretty confusing if we saw them before I

147
00:08:01,889 --> 00:08:07,820
mean everyone got lost at some point

148
00:08:03,870 --> 00:08:10,380
because everything looked the same so

149
00:08:07,820 --> 00:08:13,289
these are the problems that can can

150
00:08:10,380 --> 00:08:16,530
arise if we don't have context if we

151
00:08:13,289 --> 00:08:21,150
don't have previous information of where

152
00:08:16,530 --> 00:08:22,989
we are right now and the same goes for

153
00:08:21,150 --> 00:08:25,780
how we can

154
00:08:22,990 --> 00:08:27,310
determine those features I mean if we

155
00:08:25,780 --> 00:08:29,590
were just looking at the white wall it's

156
00:08:27,310 --> 00:08:33,190
pretty hard to compare it to the next

157
00:08:29,590 --> 00:08:35,588
white wall and movement again is crucial

158
00:08:33,190 --> 00:08:39,209
if we can't process it fast enough

159
00:08:35,589 --> 00:08:42,099
between images it will just generate

160
00:08:39,208 --> 00:08:46,149
nonsense so we got those features

161
00:08:42,099 --> 00:08:47,740
awesome if we save those features if you

162
00:08:46,149 --> 00:08:53,339
save the information of both features

163
00:08:47,740 --> 00:08:56,140
what do we get exactly a map and

164
00:08:53,339 --> 00:08:58,839
creating a map is crucial for us too so

165
00:08:56,140 --> 00:09:01,209
first time that we go to a place and we

166
00:08:58,839 --> 00:09:03,760
don't know it we have to like notice

167
00:09:01,209 --> 00:09:08,469
okay where is what that's all the first

168
00:09:03,760 --> 00:09:10,839
time so it's computationally intense but

169
00:09:08,470 --> 00:09:14,970
as soon as we got like a hold of the of

170
00:09:10,839 --> 00:09:17,230
your surroundings we're pretty much good

171
00:09:14,970 --> 00:09:18,970
opening a new door we don't have to

172
00:09:17,230 --> 00:09:23,170
rethink how there are the whole venue

173
00:09:18,970 --> 00:09:26,800
looks we just add it to the map so we

174
00:09:23,170 --> 00:09:29,279
can have actually share the map that we

175
00:09:26,800 --> 00:09:32,469
generate as humans with others with I

176
00:09:29,279 --> 00:09:35,200
can explain to you how to get to the bar

177
00:09:32,470 --> 00:09:37,450
next door I don't have to tell you what

178
00:09:35,200 --> 00:09:39,670
color the floor looks like I can tell

179
00:09:37,450 --> 00:09:43,480
you go through that door turn left and

180
00:09:39,670 --> 00:09:45,579
then straight ahead so having a date

181
00:09:43,480 --> 00:09:47,800
that doesn't need necessarily a lot a

182
00:09:45,579 --> 00:09:49,300
lot a lot of data it has to be the right

183
00:09:47,800 --> 00:09:55,120
date and the right data is actually a

184
00:09:49,300 --> 00:09:57,760
pretty complex part when generating in

185
00:09:55,120 --> 00:10:00,640
data we who differentiate between like

186
00:09:57,760 --> 00:10:01,990
two different methods so we talk about

187
00:10:00,640 --> 00:10:03,819
online and offline

188
00:10:01,990 --> 00:10:04,959
what does online offline mean so online

189
00:10:03,820 --> 00:10:05,649
means let's say we have a moving

190
00:10:04,959 --> 00:10:10,479
platform

191
00:10:05,649 --> 00:10:12,760
and we actually generate the data of the

192
00:10:10,480 --> 00:10:15,880
map on the platform itself so you can

193
00:10:12,760 --> 00:10:17,680
imagine that it has its pros and cons

194
00:10:15,880 --> 00:10:19,630
and it can't is we need a lot of

195
00:10:17,680 --> 00:10:22,660
processing power on the moving platform

196
00:10:19,630 --> 00:10:27,459
but we can actually extend and adjust

197
00:10:22,660 --> 00:10:29,439
the map on the fly and offline is you go

198
00:10:27,459 --> 00:10:31,599
through you drive through a venue you

199
00:10:29,440 --> 00:10:32,770
drive through an area you copy that data

200
00:10:31,600 --> 00:10:34,990
to and

201
00:10:32,770 --> 00:10:36,310
powerful machine and there you run it

202
00:10:34,990 --> 00:10:40,209
through in fluent when you get very

203
00:10:36,310 --> 00:10:42,520
accurate data so online to summarize we

204
00:10:40,209 --> 00:10:43,060
need good processing power or good

205
00:10:42,520 --> 00:10:44,740
enough

206
00:10:43,060 --> 00:10:47,410
whatever that means depending on your

207
00:10:44,740 --> 00:10:49,300
own the cameras that you use and mostly

208
00:10:47,410 --> 00:10:52,990
it's a trade-off in quality in map

209
00:10:49,300 --> 00:10:57,310
quality so you can't expect to get the

210
00:10:52,990 --> 00:10:59,080
same exact quality of map than the

211
00:10:57,310 --> 00:11:01,739
offline because we can actually rematch

212
00:10:59,080 --> 00:11:05,890
and rerun it and over all over again

213
00:11:01,740 --> 00:11:09,370
but things like moving people can be

214
00:11:05,890 --> 00:11:11,350
reduced or destroy removed from the

215
00:11:09,370 --> 00:11:16,750
existing map that we do in an online run

216
00:11:11,350 --> 00:11:18,580
and but the online yeah you can do it

217
00:11:16,750 --> 00:11:21,820
you can record the data with a pretty

218
00:11:18,580 --> 00:11:25,029
low-tech device and then copy it to a

219
00:11:21,820 --> 00:11:28,470
machine that actually has the processing

220
00:11:25,029 --> 00:11:31,180
power like a GPU and just refeed that

221
00:11:28,470 --> 00:11:35,830
generated map data to your moving

222
00:11:31,180 --> 00:11:37,920
platform but why not use both of them so

223
00:11:35,830 --> 00:11:41,200
you can actually do a first run with a

224
00:11:37,920 --> 00:11:43,899
lower resolution quality and saving all

225
00:11:41,200 --> 00:11:46,899
that data and then copy it to like

226
00:11:43,899 --> 00:11:49,480
powerful desktop and reuse that all over

227
00:11:46,899 --> 00:11:51,640
again it looks something like this so

228
00:11:49,480 --> 00:11:53,829
I'm gonna use and what I'm using here as

229
00:11:51,640 --> 00:11:55,569
a software called archive app so it's

230
00:11:53,829 --> 00:11:58,989
real time appearance-based

231
00:11:55,570 --> 00:12:05,640
mapping combined with a nifty little

232
00:11:58,990 --> 00:12:05,640
stereo camera and those words

233
00:12:06,390 --> 00:12:09,199
let's see

234
00:12:09,660 --> 00:12:15,569
all right yes we're running all right so

235
00:12:12,960 --> 00:12:17,760
we see the first frame that we saw in

236
00:12:15,570 --> 00:12:20,120
earlier in the earlier video and we

237
00:12:17,760 --> 00:12:23,150
actually attached each and every one

238
00:12:20,120 --> 00:12:25,200
with the previously known position and

239
00:12:23,150 --> 00:12:28,470
like that we can actually generate

240
00:12:25,200 --> 00:12:35,640
pretty pretty good data and we can

241
00:12:28,470 --> 00:12:38,700
relocate ake a look around and receive

242
00:12:35,640 --> 00:12:41,010
with if we recognize things best best

243
00:12:38,700 --> 00:12:43,530
thing is to see actually a sign so oh

244
00:12:41,010 --> 00:12:45,870
you're in the first floor awesome I know

245
00:12:43,530 --> 00:12:50,490
where I am so I know where I want to go

246
00:12:45,870 --> 00:12:53,430
and after we've done like that first

247
00:12:50,490 --> 00:12:57,300
initial run we can copy it to a more

248
00:12:53,430 --> 00:13:00,510
powerful machine and actually have the

249
00:12:57,300 --> 00:13:04,670
whole map generated in a kind of a

250
00:13:00,510 --> 00:13:04,670
better resolution let me see

251
00:13:07,610 --> 00:13:15,480
all right so these are severe senses

252
00:13:10,760 --> 00:13:17,520
pretty awesome all right

253
00:13:15,480 --> 00:13:21,060
what Omanis topic senses well it's

254
00:13:17,520 --> 00:13:23,130
basically one camera that's it

255
00:13:21,060 --> 00:13:26,910
but we reduced like the amount of data

256
00:13:23,130 --> 00:13:29,339
that we generate by half which means we

257
00:13:26,910 --> 00:13:32,219
don't have to have that much processing

258
00:13:29,339 --> 00:13:38,430
power but it's kind of more difficult to

259
00:13:32,220 --> 00:13:41,250
use to map an area and to estimate like

260
00:13:38,430 --> 00:13:45,540
an obstacle like a an object's position

261
00:13:41,250 --> 00:13:48,180
in space not that trivial without a few

262
00:13:45,540 --> 00:13:51,180
tricks all right let's do a little

263
00:13:48,180 --> 00:13:55,140
experiment can someone tell me how big

264
00:13:51,180 --> 00:13:58,109
that zebra is like how big is it this is

265
00:13:55,140 --> 00:14:00,779
like two meters that like that yeah

266
00:13:58,110 --> 00:14:10,620
all right try again how big is that

267
00:14:00,779 --> 00:14:12,210
zebra yeah yeah all right so why can why

268
00:14:10,620 --> 00:14:14,600
is it easier to tell the size of that

269
00:14:12,210 --> 00:14:14,600
zebra

270
00:14:15,380 --> 00:14:20,700
exactly we have we have an object that

271
00:14:18,150 --> 00:14:23,459
we know that we know the exact size of

272
00:14:20,700 --> 00:14:27,080
it that's the same thing that we're

273
00:14:23,460 --> 00:14:32,190
gonna do with that we can do with

274
00:14:27,080 --> 00:14:34,560
computer vision so right yeah if it's a

275
00:14:32,190 --> 00:14:36,900
giant CD something like that happens so

276
00:14:34,560 --> 00:14:41,819
we actually if we don't have a correct

277
00:14:36,900 --> 00:14:45,660
reference like size reference humans can

278
00:14:41,820 --> 00:14:47,760
get screwed - thanks for the question

279
00:14:45,660 --> 00:14:50,130
perfect all right so what we do with

280
00:14:47,760 --> 00:14:54,300
robotics we actually use something

281
00:14:50,130 --> 00:14:56,550
called markers so we pre program or we

282
00:14:54,300 --> 00:15:02,010
tell the robot that we actually this

283
00:14:56,550 --> 00:15:05,300
tagged has a set size so if we see them

284
00:15:02,010 --> 00:15:08,850
in a picture so we can we can actually

285
00:15:05,300 --> 00:15:11,849
calculate the size of that tag according

286
00:15:08,850 --> 00:15:15,420
to the pixels that it takes on on the on

287
00:15:11,850 --> 00:15:17,130
the image and if we see multiple ones we

288
00:15:15,420 --> 00:15:19,500
can actually use that to localize

289
00:15:17,130 --> 00:15:21,800
ourselves which looks something like

290
00:15:19,500 --> 00:15:21,800
this

291
00:15:27,150 --> 00:15:31,500
so you see we can actually get the

292
00:15:29,010 --> 00:15:33,510
orientation of those tags and on the

293
00:15:31,500 --> 00:15:36,360
right on the right side we see like a

294
00:15:33,510 --> 00:15:38,100
map that we generate with the location

295
00:15:36,360 --> 00:15:41,339
of those of those tags and it's not

296
00:15:38,100 --> 00:15:42,420
necessarily just in a tude 2-dimensional

297
00:15:41,339 --> 00:15:44,700
space we can use that in a

298
00:15:42,420 --> 00:15:47,040
three-dimensional space this is kind of

299
00:15:44,700 --> 00:15:50,070
cheating because usually you don't have

300
00:15:47,040 --> 00:15:51,900
the luxury of tags in an area in an area

301
00:15:50,070 --> 00:15:53,610
that you that you operate if you if you

302
00:15:51,900 --> 00:15:58,770
have a chance of course makes it stuff

303
00:15:53,610 --> 00:16:01,620
easier but this helps to get a simple

304
00:15:58,770 --> 00:16:04,829
simple localization method with

305
00:16:01,620 --> 00:16:07,350
relatively low-tech equipment and see

306
00:16:04,830 --> 00:16:12,630
the three-dimensional placement of those

307
00:16:07,350 --> 00:16:14,150
tags but so how do we have a monastic

308
00:16:12,630 --> 00:16:17,490
application

309
00:16:14,150 --> 00:16:19,980
how do we determine like if if a certain

310
00:16:17,490 --> 00:16:24,000
what's distance a certain point so if

311
00:16:19,980 --> 00:16:28,230
you close your eyes and try to to to

312
00:16:24,000 --> 00:16:30,660
estimate point in space with one eye

313
00:16:28,230 --> 00:16:33,000
closed just without moving it's kind of

314
00:16:30,660 --> 00:16:35,520
hard so what what do we do we actually

315
00:16:33,000 --> 00:16:38,810
moves slightly its left and right and

316
00:16:35,520 --> 00:16:42,540
try to actually reach reach or calculate

317
00:16:38,810 --> 00:16:45,000
the position of that so movement helps

318
00:16:42,540 --> 00:16:46,410
us and we have mono vision just fine

319
00:16:45,000 --> 00:16:50,220
there are people that's bench actually

320
00:16:46,410 --> 00:16:53,939
pretty good so 3d with just one eye

321
00:16:50,220 --> 00:16:59,339
awesome yeah yeah well yes but actually

322
00:16:53,940 --> 00:17:02,339
no because our body cheats we as all our

323
00:16:59,339 --> 00:17:04,589
senses to actually combined to actually

324
00:17:02,339 --> 00:17:08,069
get that depth information of a certain

325
00:17:04,589 --> 00:17:10,319
point in space so we use it our hearing

326
00:17:08,069 --> 00:17:12,720
views our eyes we use our touch so again

327
00:17:10,319 --> 00:17:14,790
the example with getting out at night

328
00:17:12,720 --> 00:17:16,709
and pumping your feet your feet are

329
00:17:14,790 --> 00:17:18,889
actually like bumpers on a like on the

330
00:17:16,709 --> 00:17:23,490
Roomba so it tells you to stop

331
00:17:18,890 --> 00:17:26,579
we take our feet and all that gets

332
00:17:23,490 --> 00:17:31,170
combined in that computing thing in our

333
00:17:26,579 --> 00:17:33,600
head which helps us navigate we do the

334
00:17:31,170 --> 00:17:36,870
same with robots so we might replace the

335
00:17:33,600 --> 00:17:39,270
the sense of hearing with sonar to

336
00:17:36,870 --> 00:17:44,530
replace the eyes obviously with camera

337
00:17:39,270 --> 00:17:47,920
bumpers as tactile input and we use

338
00:17:44,530 --> 00:17:50,980
wheels to get a sense how much did we

339
00:17:47,920 --> 00:17:58,140
move in space so we can actually combine

340
00:17:50,980 --> 00:18:00,790
those and get to send get a more robust

341
00:17:58,140 --> 00:18:02,890
localization method because what we're

342
00:18:00,790 --> 00:18:07,420
trying to do is actually eliminate the

343
00:18:02,890 --> 00:18:10,270
errors of all the other sensors and we

344
00:18:07,420 --> 00:18:14,170
can actually do that too with a computer

345
00:18:10,270 --> 00:18:19,530
vision so this is a short video that I

346
00:18:14,170 --> 00:18:24,190
made so I used my smartphone with an AR

347
00:18:19,530 --> 00:18:29,560
framework some Unity game engine so it's

348
00:18:24,190 --> 00:18:31,360
pretty much a copy copy paste method but

349
00:18:29,560 --> 00:18:35,050
we see here the white the the white

350
00:18:31,360 --> 00:18:38,320
surface represents the floor so it texts

351
00:18:35,050 --> 00:18:41,620
the floor and when we move it actually

352
00:18:38,320 --> 00:18:45,550
tries to match those pixels to the

353
00:18:41,620 --> 00:18:49,149
previous frame and in the top it might

354
00:18:45,550 --> 00:18:51,520
be hard to see but we actually see the

355
00:18:49,150 --> 00:18:55,360
distance that we walked and now we see

356
00:18:51,520 --> 00:19:02,740
the difference like steps on that could

357
00:18:55,360 --> 00:19:04,159
get detected as a plane and if we turn

358
00:19:02,740 --> 00:19:08,450
around

359
00:19:04,160 --> 00:19:13,010
at some point here we actually can log

360
00:19:08,450 --> 00:19:15,950
where we went and see our paths that we

361
00:19:13,010 --> 00:19:18,740
did and this was just used this is just

362
00:19:15,950 --> 00:19:20,660
with that smart phone all right well

363
00:19:18,740 --> 00:19:22,280
it's pretty powerful smartphone the

364
00:19:20,660 --> 00:19:26,510
smart phones that you carry today they

365
00:19:22,280 --> 00:19:28,580
pack quite a lot of processing power all

366
00:19:26,510 --> 00:19:30,520
right so let's talk about structures

367
00:19:28,580 --> 00:19:33,409
structured light the structured light

368
00:19:30,520 --> 00:19:38,629
can be used with one camera or two

369
00:19:33,410 --> 00:19:42,620
cameras but it adds projected to it that

370
00:19:38,630 --> 00:19:47,900
mostly it's infrared laser that projects

371
00:19:42,620 --> 00:19:49,790
a known pattern on on a surface and by

372
00:19:47,900 --> 00:19:51,890
the deformation of that pattern we can

373
00:19:49,790 --> 00:19:53,750
actually calculate or estimate the

374
00:19:51,890 --> 00:19:55,220
surface of an object on a

375
00:19:53,750 --> 00:19:57,820
three-dimensional surface so how does

376
00:19:55,220 --> 00:19:57,820
that look

377
00:19:57,830 --> 00:20:03,500
this is like the example video from

378
00:20:00,410 --> 00:20:05,540
Intel so you actually see the different

379
00:20:03,500 --> 00:20:09,110
patterns that are that get projected on

380
00:20:05,540 --> 00:20:11,600
that person and by analyzing the

381
00:20:09,110 --> 00:20:13,939
deformation of the different lines where

382
00:20:11,600 --> 00:20:17,449
you can get pretty good estimate of the

383
00:20:13,940 --> 00:20:22,820
surface of that of that object we can

384
00:20:17,450 --> 00:20:25,640
use points too so in here is you see

385
00:20:22,820 --> 00:20:27,530
like those different IR our points that

386
00:20:25,640 --> 00:20:29,690
we don't see in the RGB image obviously

387
00:20:27,530 --> 00:20:35,000
and this helps us to get a better

388
00:20:29,690 --> 00:20:36,560
feeling for the depth but structured

389
00:20:35,000 --> 00:20:39,250
like they they have their ups and downs

390
00:20:36,560 --> 00:20:43,010
so it's pretty good in getting better

391
00:20:39,250 --> 00:20:45,050
three-dimensional data and usually the

392
00:20:43,010 --> 00:20:46,820
accuracy is much better but they're

393
00:20:45,050 --> 00:20:49,760
pretty susceptible to like external

394
00:20:46,820 --> 00:20:54,649
noise so sunlight is pretty much a

395
00:20:49,760 --> 00:20:56,990
killer for it for it so you can't really

396
00:20:54,650 --> 00:21:00,230
use it for or it's hard to use it in an

397
00:20:56,990 --> 00:21:04,070
outdoor outdoor situation but all those

398
00:21:00,230 --> 00:21:06,530
camera camera technologies can be used

399
00:21:04,070 --> 00:21:08,929
in different ways so we can use them to

400
00:21:06,530 --> 00:21:09,899
give an operator of a remote vehicle

401
00:21:08,930 --> 00:21:12,120
like a sense

402
00:21:09,900 --> 00:21:16,170
of depth in a case of Styria cameras I

403
00:21:12,120 --> 00:21:18,209
mean anybody like didn't has done some

404
00:21:16,170 --> 00:21:20,400
drone flying some first-person wrong

405
00:21:18,210 --> 00:21:22,680
flying it's pretty hard to determine

406
00:21:20,400 --> 00:21:24,660
like the depth or get a feeling for for

407
00:21:22,680 --> 00:21:27,150
the size of objects if you find just

408
00:21:24,660 --> 00:21:29,400
with this with a simple camera needs a

409
00:21:27,150 --> 00:21:31,550
lot of experience and you need to do to

410
00:21:29,400 --> 00:21:34,710
fly around and it probably crash a lot

411
00:21:31,550 --> 00:21:39,090
so that that could be used for for let's

412
00:21:34,710 --> 00:21:41,520
say a person that operates robots that

413
00:21:39,090 --> 00:21:46,860
inspects like a nuclear power plant that

414
00:21:41,520 --> 00:21:49,020
gets used in a in a bomb defusal

415
00:21:46,860 --> 00:21:51,300
situation where it's really hard for the

416
00:21:49,020 --> 00:21:53,820
guys that operate those vehicles who to

417
00:21:51,300 --> 00:21:56,490
get a hold of what it's what is in front

418
00:21:53,820 --> 00:21:58,139
of them so I know from a fraud for the

419
00:21:56,490 --> 00:21:59,970
bomb defusing robots what they do they

420
00:21:58,140 --> 00:22:02,280
sometimes they put like a 10 centimeter

421
00:21:59,970 --> 00:22:04,320
long strip in front of the camera so

422
00:22:02,280 --> 00:22:06,389
they actually can see it and they they

423
00:22:04,320 --> 00:22:09,720
get closer to the object until they see

424
00:22:06,390 --> 00:22:11,190
that the paper actually moves and having

425
00:22:09,720 --> 00:22:14,690
like a stereo camera you can actually

426
00:22:11,190 --> 00:22:17,370
get where let's say a VR headset and

427
00:22:14,690 --> 00:22:19,860
have a sense of depth which is actually

428
00:22:17,370 --> 00:22:21,810
really useful and of course autonomous

429
00:22:19,860 --> 00:22:25,560
cars a lot of autonomous cars these days

430
00:22:21,810 --> 00:22:29,899
they combine different sensors and I

431
00:22:25,560 --> 00:22:35,760
think Tesla is heavily invested in into

432
00:22:29,900 --> 00:22:37,020
vision based navigation so this is

433
00:22:35,760 --> 00:22:39,300
pretty cool

434
00:22:37,020 --> 00:22:43,200
but let's let's let's talk about the

435
00:22:39,300 --> 00:22:44,500
hardware one of our favorite ones as the

436
00:22:43,200 --> 00:22:47,360
Z Mini

437
00:22:44,500 --> 00:22:49,760
[Music]

438
00:22:47,360 --> 00:22:52,850
which is this guy over here it's pretty

439
00:22:49,760 --> 00:22:55,010
tiny it has a built-in IMU so it

440
00:22:52,850 --> 00:22:57,649
actually registers your movement which

441
00:22:55,010 --> 00:23:01,340
can be used in combination with the

442
00:22:57,650 --> 00:23:04,850
images that you get to get a more robust

443
00:23:01,340 --> 00:23:07,250
tracking awesome

444
00:23:04,850 --> 00:23:09,320
we got the realsense camera which is

445
00:23:07,250 --> 00:23:10,970
this this little guy over here this is

446
00:23:09,320 --> 00:23:11,899
actually a structured light sensor that

447
00:23:10,970 --> 00:23:16,040
has an infrared

448
00:23:11,900 --> 00:23:18,230
infrared projector on it stiva camera it

449
00:23:16,040 --> 00:23:24,379
is kind of finicky so not really my

450
00:23:18,230 --> 00:23:26,660
favorite but a newer one is actually one

451
00:23:24,380 --> 00:23:30,770
of intel realsense well i have a lot of

452
00:23:26,660 --> 00:23:33,980
intel products because they have quite a

453
00:23:30,770 --> 00:23:36,350
quite a few of those this sensor is

454
00:23:33,980 --> 00:23:39,290
pretty pretty cool because it does most

455
00:23:36,350 --> 00:23:41,929
of the computation position estimation

456
00:23:39,290 --> 00:23:44,720
on board so you can use that with with a

457
00:23:41,930 --> 00:23:48,590
pretty low powered system and actually

458
00:23:44,720 --> 00:23:51,100
just stream the position data right back

459
00:23:48,590 --> 00:23:53,720
to it to your computer

460
00:23:51,100 --> 00:23:55,939
but those cameras you might have seen

461
00:23:53,720 --> 00:23:58,430
are pretty expensive and for people that

462
00:23:55,940 --> 00:24:04,250
want to start with computer vision this

463
00:23:58,430 --> 00:24:06,590
can be overwhelming so meet the joy of

464
00:24:04,250 --> 00:24:10,130
our cameras au revoir means I see in

465
00:24:06,590 --> 00:24:13,310
French it's this little tiny camera and

466
00:24:10,130 --> 00:24:17,480
if I talk tiny I mean this is the camera

467
00:24:13,310 --> 00:24:18,919
so it does all the computer vision on

468
00:24:17,480 --> 00:24:23,450
board so you actually have a micro SD

469
00:24:18,920 --> 00:24:26,030
card that runs the full Linux attach it

470
00:24:23,450 --> 00:24:29,330
to via USB to your house computer and it

471
00:24:26,030 --> 00:24:33,470
just gets registered as a webcam so no

472
00:24:29,330 --> 00:24:35,179
special drivers needed it's pretty it's

473
00:24:33,470 --> 00:24:38,510
powerful enough to do some amazing

474
00:24:35,180 --> 00:24:42,290
things it's open source and it was

475
00:24:38,510 --> 00:24:44,840
developed by the University of Southern

476
00:24:42,290 --> 00:24:49,550
California actually with an intention to

477
00:24:44,840 --> 00:24:52,909
provide platform for students to start

478
00:24:49,550 --> 00:24:54,809
with computer vision they made a start

479
00:24:52,910 --> 00:24:56,580
campaign out of it and I

480
00:24:54,809 --> 00:24:59,428
it was pretty cool so I was I was one of

481
00:24:56,580 --> 00:25:00,809
those about the backers and the whole

482
00:24:59,429 --> 00:25:02,580
platform is really really well

483
00:25:00,809 --> 00:25:06,720
documented you know that have a lot of

484
00:25:02,580 --> 00:25:10,820
examples from machine learning let's say

485
00:25:06,720 --> 00:25:13,610
object recognition to tracker

486
00:25:10,820 --> 00:25:16,529
recognition facial recognition

487
00:25:13,610 --> 00:25:21,178
iris tracking and depending on what you

488
00:25:16,529 --> 00:25:23,279
want to do it's fast fast enough but you

489
00:25:21,179 --> 00:25:26,999
don't really necessarily need to be

490
00:25:23,279 --> 00:25:30,149
limited to external hardware you can

491
00:25:26,999 --> 00:25:32,220
actually use your laptop's webcam or

492
00:25:30,149 --> 00:25:37,379
actually any USB webcam to get you

493
00:25:32,220 --> 00:25:40,200
started so software that's where usually

494
00:25:37,379 --> 00:25:42,119
where the problem lies you won't you

495
00:25:40,200 --> 00:25:46,080
can't really do a computer vision

496
00:25:42,119 --> 00:25:48,178
without once using OpenCV so it's a the

497
00:25:46,080 --> 00:25:53,070
open source computer vision framework

498
00:25:48,179 --> 00:25:54,809
this is it's cross formed compatible it

499
00:25:53,070 --> 00:25:58,049
brings like a lot of features most of

500
00:25:54,809 --> 00:26:00,330
most of the image processing stuff that

501
00:25:58,049 --> 00:26:02,519
year that you see online is actually at

502
00:26:00,330 --> 00:26:06,749
some at some point related to open CV

503
00:26:02,519 --> 00:26:09,210
and it is well well-documented and you

504
00:26:06,749 --> 00:26:15,749
find a lot of YouTube tutorials online

505
00:26:09,210 --> 00:26:18,240
so kind of a fun project is open posts

506
00:26:15,749 --> 00:26:22,860
so this this project aims to actually

507
00:26:18,240 --> 00:26:26,159
detect humans in a 2d image and actually

508
00:26:22,860 --> 00:26:28,889
assigning skeletons to their through

509
00:26:26,159 --> 00:26:31,519
this different body parts parts which

510
00:26:28,889 --> 00:26:34,918
looks something like this

511
00:26:31,519 --> 00:26:39,809
they used like machine learning to train

512
00:26:34,919 --> 00:26:43,590
to Train framework how humans would look

513
00:26:39,809 --> 00:26:47,158
like in a picture this is quite cool so

514
00:26:43,590 --> 00:26:49,139
Facebook just recently released like the

515
00:26:47,159 --> 00:26:52,259
upgraded version of that which called

516
00:26:49,139 --> 00:26:57,119
dense posts and it can actually

517
00:26:52,259 --> 00:26:58,950
reconstruct like surfaces of humans in a

518
00:26:57,119 --> 00:27:01,668
2d image which looks something like this

519
00:26:58,950 --> 00:27:01,669
is pretty scary

520
00:27:02,190 --> 00:27:11,230
and probably if you're into like machine

521
00:27:08,200 --> 00:27:14,460
learning you won't get around tensorflow

522
00:27:11,230 --> 00:27:17,859
which is the open source library of

523
00:27:14,460 --> 00:27:20,909
Google again this this too is pretty

524
00:27:17,859 --> 00:27:24,789
well documented and you get fantastic

525
00:27:20,909 --> 00:27:29,049
tutorials to start start your journey

526
00:27:24,789 --> 00:27:31,539
into that computer vision so what might

527
00:27:29,049 --> 00:27:33,460
what lies in the future all right I

528
00:27:31,539 --> 00:27:36,580
think robots will will more and more be

529
00:27:33,460 --> 00:27:39,759
used in certain fields like disaster

530
00:27:36,580 --> 00:27:41,678
relief so that you actually send out

531
00:27:39,759 --> 00:27:47,169
swarms that would actually gather data

532
00:27:41,679 --> 00:27:50,409
to detect victims of let's say an

533
00:27:47,169 --> 00:27:52,299
earthquake to 3d map a certain area and

534
00:27:50,409 --> 00:27:54,759
get like a situational awareness of

535
00:27:52,299 --> 00:28:01,570
what's going on to deliver that drones

536
00:27:54,759 --> 00:28:05,230
are already used to deliver blood block

537
00:28:01,570 --> 00:28:06,820
blood bags in remote areas in Africa so

538
00:28:05,230 --> 00:28:09,190
I think that there will be a lot of

539
00:28:06,820 --> 00:28:12,668
change in that in that area and of

540
00:28:09,190 --> 00:28:16,210
course medicine using computer vision

541
00:28:12,669 --> 00:28:17,919
and medicines brings like a lot of

542
00:28:16,210 --> 00:28:19,570
potential because machines are really

543
00:28:17,919 --> 00:28:21,549
good in recognizing patterns you just

544
00:28:19,570 --> 00:28:26,049
have to teach them which patterns are

545
00:28:21,549 --> 00:28:29,200
actually interesting so I think the this

546
00:28:26,049 --> 00:28:31,809
can be used combined machine learning to

547
00:28:29,200 --> 00:28:33,220
actually give doctors an additional

548
00:28:31,809 --> 00:28:35,499
sense for what they're looking at

549
00:28:33,220 --> 00:28:39,340
because not every doctor is equally

550
00:28:35,499 --> 00:28:41,859
trained to interpret data that he's

551
00:28:39,340 --> 00:28:45,238
looking at let's for example say an EKG

552
00:28:41,859 --> 00:28:48,039
like measurement of yura of your heart

553
00:28:45,239 --> 00:28:50,499
they're like subtle differences that not

554
00:28:48,039 --> 00:28:52,119
all all doctors are equally trained for

555
00:28:50,499 --> 00:28:57,970
and not all of them can actually

556
00:28:52,119 --> 00:28:59,470
recognize those patterns patient

557
00:28:57,970 --> 00:29:01,960
monitoring we're talking about we're

558
00:28:59,470 --> 00:29:04,779
talking about robots that actually can

559
00:29:01,960 --> 00:29:06,980
can allow elderly people to stay in

560
00:29:04,779 --> 00:29:10,130
their home instead of having

561
00:29:06,980 --> 00:29:12,289
to put them in an elderly home and for

562
00:29:10,130 --> 00:29:15,830
for experts to have the ability to

563
00:29:12,289 --> 00:29:17,870
actually remotely log in and actually

564
00:29:15,830 --> 00:29:21,379
inspect the patient submit them of

565
00:29:17,870 --> 00:29:26,209
course we have autonomous vehicles those

566
00:29:21,380 --> 00:29:29,149
those will come and they will have a

567
00:29:26,210 --> 00:29:32,480
bunch of sensors in them if you want to

568
00:29:29,149 --> 00:29:34,489
see what can go wrong with with sensors

569
00:29:32,480 --> 00:29:38,029
and autonomous vehicles I'd highly

570
00:29:34,490 --> 00:29:43,010
suggest those talk last year about

571
00:29:38,029 --> 00:29:46,370
hacking autonomous vehicles but this is

572
00:29:43,010 --> 00:29:48,019
not all we're talking surveillance the

573
00:29:46,370 --> 00:29:51,168
computer vision especially machine

574
00:29:48,019 --> 00:29:53,529
learning enables will say state actors

575
00:29:51,169 --> 00:29:55,760
to use that technology to do a

576
00:29:53,529 --> 00:29:57,500
large-scale surveillance without the

577
00:29:55,760 --> 00:30:03,980
need of humans to actually classify it

578
00:29:57,500 --> 00:30:06,620
and of course warfare so it's it has its

579
00:30:03,980 --> 00:30:12,230
ups and downs but I would like to focus

580
00:30:06,620 --> 00:30:16,908
on on the good things so yeah to like do

581
00:30:12,230 --> 00:30:20,120
a short recap we have stereo vision we

582
00:30:16,909 --> 00:30:22,100
have mono vision and vision that uses

583
00:30:20,120 --> 00:30:23,768
structures structured lights to actually

584
00:30:22,100 --> 00:30:27,500
estimate it's three-dimensional

585
00:30:23,769 --> 00:30:29,539
three-dimensional environment and yeah

586
00:30:27,500 --> 00:30:31,970
and I would suggest be nice to your

587
00:30:29,539 --> 00:30:35,960
robots because we might work one day for

588
00:30:31,970 --> 00:30:38,080
them and with that of the open for

589
00:30:35,960 --> 00:30:41,080
questions if you have if you have some

590
00:30:38,080 --> 00:30:41,080
yes

591
00:30:56,770 --> 00:31:05,240
the statement that it must be that we

592
00:30:59,929 --> 00:31:10,220
don't meet yourself a glass I would

593
00:31:05,240 --> 00:31:12,230
partially agree lidar is good in certain

594
00:31:10,220 --> 00:31:17,720
areas but I think if you want to scale

595
00:31:12,230 --> 00:31:21,049
it up machine vision should be used as a

596
00:31:17,720 --> 00:31:23,330
main main sensor but again machine

597
00:31:21,049 --> 00:31:26,929
vision has it has its weaknesses so

598
00:31:23,330 --> 00:31:29,600
let's say fog or if there's dirt on the

599
00:31:26,929 --> 00:31:31,549
cameras so you I would say I was just

600
00:31:29,600 --> 00:31:33,379
not to rely on only one sensor but

601
00:31:31,549 --> 00:31:36,980
actually use maybe a radar as an

602
00:31:33,380 --> 00:31:39,890
additional one and I don't think lidar

603
00:31:36,980 --> 00:31:43,190
is necess ness is a necessity for

604
00:31:39,890 --> 00:31:44,450
autonomous vehicles it certainly helps

605
00:31:43,190 --> 00:31:47,799
and it looks cool to actually generate

606
00:31:44,450 --> 00:31:47,799
that this point cloud

607
00:31:51,460 --> 00:31:54,240
all right

608
00:32:03,370 --> 00:32:09,560
[Music]

609
00:32:05,990 --> 00:32:09,560
you mention it

610
00:32:09,809 --> 00:32:13,460
the medication

611
00:32:21,060 --> 00:32:26,450
yes

612
00:32:24,030 --> 00:32:26,450
this

613
00:32:27,090 --> 00:32:30,500
nation but

614
00:32:33,000 --> 00:32:36,000
better

615
00:32:38,220 --> 00:32:46,000
yeah it depends I had a similar

616
00:32:42,070 --> 00:32:50,139
discussion just a few days ago so moving

617
00:32:46,000 --> 00:32:53,049
from let's say 720p to 8k image

618
00:32:50,140 --> 00:32:56,169
resolution and most of the time you

619
00:32:53,049 --> 00:32:59,440
won't get gained a lot of a lot of more

620
00:32:56,169 --> 00:33:01,570
a lot of information compared to the low

621
00:32:59,440 --> 00:33:03,490
resolution so it's always like the

622
00:33:01,570 --> 00:33:05,740
question what do you want to use it for

623
00:33:03,490 --> 00:33:08,169
and what's good enough because at some

624
00:33:05,740 --> 00:33:10,350
point computational power gets gets more

625
00:33:08,169 --> 00:33:15,820
and more it gets cheaper every day right

626
00:33:10,350 --> 00:33:20,889
so we tend to raise the amount of data

627
00:33:15,820 --> 00:33:23,110
that we feed in but yeah it always

628
00:33:20,890 --> 00:33:25,480
depends what's the given constraint

629
00:33:23,110 --> 00:33:29,199
what's the limiting factor of the

630
00:33:25,480 --> 00:33:31,480
project that you use and usually it's a

631
00:33:29,200 --> 00:33:33,399
good idea to lower the resolution in and

632
00:33:31,480 --> 00:33:38,549
sacrifice lower resolution for higher

633
00:33:33,399 --> 00:33:38,549
framerate if that answers your question

634
00:33:42,760 --> 00:33:46,860
all right thank you very much

635
00:34:12,630 --> 00:34:14,690
you

