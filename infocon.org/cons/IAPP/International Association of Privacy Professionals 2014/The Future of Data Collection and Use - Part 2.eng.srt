1
00:00:04,760 --> 00:00:07,260
one of the early thoughts was the

2
00:00:07,260 --> 00:00:09,780
critique of noticin choice clearly

3
00:00:09,780 --> 00:00:11,880
everybody on every side of the privacy

4
00:00:11,880 --> 00:00:14,099
spectrum has issues with notice and

5
00:00:14,099 --> 00:00:15,330
choice and do they work and are they

6
00:00:15,330 --> 00:00:17,450
ignored and you know do they just

7
00:00:17,450 --> 00:00:21,989
provide a shifting of focus but aren't

8
00:00:21,989 --> 00:00:24,360
really meaningful but other privacy

9
00:00:24,360 --> 00:00:26,460
critics in reacting to the paper or the

10
00:00:26,460 --> 00:00:29,099
concept have said are you proposing to

11
00:00:29,099 --> 00:00:30,930
eliminate individual you know

12
00:00:30,930 --> 00:00:32,460
participation here am I going to

13
00:00:32,460 --> 00:00:35,670
therefore get marketing without being

14
00:00:35,670 --> 00:00:37,920
able to decide I mean where and how are

15
00:00:37,920 --> 00:00:40,890
we minimizing or taking off the table or

16
00:00:40,890 --> 00:00:43,860
are we disrespecting to some degree a

17
00:00:43,860 --> 00:00:46,830
core concept of users having an

18
00:00:46,830 --> 00:00:49,410
important measure of control so would

19
00:00:49,410 --> 00:00:51,690
you give us a reaction to that and yeah

20
00:00:51,690 --> 00:00:54,930
it's one of the themes that that in

21
00:00:54,930 --> 00:00:56,220
thinking about what would be interesting

22
00:00:56,220 --> 00:00:58,470
to advance this is alcohol messaging

23
00:00:58,470 --> 00:01:00,570
which I will touch on that but let me

24
00:01:00,570 --> 00:01:02,730
first give you a little bit more of a

25
00:01:02,730 --> 00:01:04,349
background on how we got to this stage

26
00:01:04,349 --> 00:01:07,530
and then finish with something around

27
00:01:07,530 --> 00:01:09,329
risk although different than perhaps

28
00:01:09,329 --> 00:01:11,460
what Richard talked you yesterday which

29
00:01:11,460 --> 00:01:13,530
i think is relevant to this audience so

30
00:01:13,530 --> 00:01:16,979
Fred talked about 18 months ago of the

31
00:01:16,979 --> 00:01:19,020
seven of us locking ourselves in a very

32
00:01:19,020 --> 00:01:23,490
very very nice hotel to think about what

33
00:01:23,490 --> 00:01:24,840
this new world would look like but the

34
00:01:24,840 --> 00:01:26,639
journey really started two and a half

35
00:01:26,639 --> 00:01:29,929
years prior to that where as part of

36
00:01:29,929 --> 00:01:32,340
kind of our looking at the world are

37
00:01:32,340 --> 00:01:34,020
being Microsoft's view of the world we

38
00:01:34,020 --> 00:01:35,450
said look all the things that Fred

39
00:01:35,450 --> 00:01:38,609
talked about are likely to come in play

40
00:01:38,609 --> 00:01:40,439
and what implications would that have

41
00:01:40,439 --> 00:01:43,229
and that started us on a journey that we

42
00:01:43,229 --> 00:01:46,319
called a global dialogue which involves

43
00:01:46,319 --> 00:01:50,270
over 100 privacy experts ranging from

44
00:01:50,270 --> 00:01:53,310
academics to advocacy organizations to

45
00:01:53,310 --> 00:01:57,270
policy makers to regulations in all five

46
00:01:57,270 --> 00:01:59,880
different parts of the world we chose

47
00:01:59,880 --> 00:02:02,099
not to go to Antarctica as one continent

48
00:02:02,099 --> 00:02:04,439
for perhaps obvious reasons but tech

49
00:02:04,439 --> 00:02:05,999
touched on just about every other part

50
00:02:05,999 --> 00:02:08,940
of the world there were then a global

51
00:02:08,940 --> 00:02:11,250
summit that we hosted on microsoft

52
00:02:11,250 --> 00:02:14,340
campus involving some 70 people and I

53
00:02:14,340 --> 00:02:16,960
always say that the conclusion was

54
00:02:16,960 --> 00:02:20,020
that from those experts that you know

55
00:02:20,020 --> 00:02:22,090
the current model that we have have

56
00:02:22,090 --> 00:02:25,120
grown up with and built with some very

57
00:02:25,120 --> 00:02:28,690
very noble right purposes was not

58
00:02:28,690 --> 00:02:30,130
working today and certainly was not

59
00:02:30,130 --> 00:02:32,920
working tomorrow and I come from kind of

60
00:02:32,920 --> 00:02:34,600
an operational background by extension

61
00:02:34,600 --> 00:02:37,030
if the process is broken one must find a

62
00:02:37,030 --> 00:02:39,610
new process so in other words the

63
00:02:39,610 --> 00:02:43,150
conclusion was almost no one felt that

64
00:02:43,150 --> 00:02:45,160
we didn't need some change the question

65
00:02:45,160 --> 00:02:46,990
was to what change which is where we

66
00:02:46,990 --> 00:02:50,080
started doing much of this work that

67
00:02:50,080 --> 00:02:53,260
Fred talked about this got to a called

68
00:02:53,260 --> 00:02:55,720
the key theme of messaging because

69
00:02:55,720 --> 00:02:58,030
what's interesting about change is that

70
00:02:58,030 --> 00:03:00,760
despite I think people intellectually

71
00:03:00,760 --> 00:03:02,890
perhaps even emotionally recognizing

72
00:03:02,890 --> 00:03:04,510
that we need to evolve to something

73
00:03:04,510 --> 00:03:07,330
better or we could do better to what is

74
00:03:07,330 --> 00:03:10,180
a is a paradigm that is uncomfortable

75
00:03:10,180 --> 00:03:13,240
for many of us in other words we don't

76
00:03:13,240 --> 00:03:15,070
know what the answer is but discovery of

77
00:03:15,070 --> 00:03:17,530
that answer can create some some

78
00:03:17,530 --> 00:03:19,870
emotions about it so what we learnt out

79
00:03:19,870 --> 00:03:21,760
of this is that some messaging

80
00:03:21,760 --> 00:03:24,280
challenges of with Fred suggesting

81
00:03:24,280 --> 00:03:25,960
perhaps a shift more to a use of

82
00:03:25,960 --> 00:03:28,060
information some people interpret it as

83
00:03:28,060 --> 00:03:31,570
well that means consents gone or another

84
00:03:31,570 --> 00:03:34,420
one if we're going to have more

85
00:03:34,420 --> 00:03:36,610
accountability on data stewards that

86
00:03:36,610 --> 00:03:38,680
many of us in this room well that means

87
00:03:38,680 --> 00:03:40,090
all the other fair information

88
00:03:40,090 --> 00:03:41,830
principles are gone well of course none

89
00:03:41,830 --> 00:03:44,800
of that is accurate but it's just this

90
00:03:44,800 --> 00:03:47,350
messaging challenge and this got me

91
00:03:47,350 --> 00:03:50,230
thinking about a called the risk side of

92
00:03:50,230 --> 00:03:52,000
things to for this audience this is

93
00:03:52,000 --> 00:03:55,150
actually the first time that this group

94
00:03:55,150 --> 00:03:57,970
has actually exposed this work to a

95
00:03:57,970 --> 00:04:00,040
group of privacy professionals and so

96
00:04:00,040 --> 00:04:03,040
when I think about risk Fred said

97
00:04:03,040 --> 00:04:06,630
something that is for us as I'll call it

98
00:04:06,630 --> 00:04:09,580
data custodian stewards of organizations

99
00:04:09,580 --> 00:04:11,860
he's really saying this model requires

100
00:04:11,860 --> 00:04:15,210
us to assume more responsibility and

101
00:04:15,210 --> 00:04:17,370
intellectually that sounds good

102
00:04:17,370 --> 00:04:19,358
intellectually I suspect there will be

103
00:04:19,358 --> 00:04:21,279
people in our organizations that would

104
00:04:21,279 --> 00:04:25,060
say hold on a sec consent may not work

105
00:04:25,060 --> 00:04:27,460
but after all that's how we offload most

106
00:04:27,460 --> 00:04:28,960
of our risk on to our unsuspecting

107
00:04:28,960 --> 00:04:30,310
customers

108
00:04:30,310 --> 00:04:32,930
well okay so you can argue about that

109
00:04:32,930 --> 00:04:34,250
since that's just a bad deal for

110
00:04:34,250 --> 00:04:36,080
consumers therefore should be changed

111
00:04:36,080 --> 00:04:37,160
but I'm going to present an alternative

112
00:04:37,160 --> 00:04:39,830
view to you all as I'll call that

113
00:04:39,830 --> 00:04:43,009
custodians the organization's to think

114
00:04:43,009 --> 00:04:44,930
that we can maintain the status quo also

115
00:04:44,930 --> 00:04:47,780
has extreme risk because I think what we

116
00:04:47,780 --> 00:04:49,759
will see is as this model increasingly

117
00:04:49,759 --> 00:04:53,150
comes under stress the natural cycle of

118
00:04:53,150 --> 00:04:54,800
public policy will take place and we

119
00:04:54,800 --> 00:04:56,720
will see reactions to that breakdown of

120
00:04:56,720 --> 00:04:59,150
that and I'm not sure that we'll all be

121
00:04:59,150 --> 00:05:01,699
happy with what those outcomes are so I

122
00:05:01,699 --> 00:05:03,349
think it behooves us to think very

123
00:05:03,349 --> 00:05:05,419
differently pragmatically I think it

124
00:05:05,419 --> 00:05:07,220
behooves us to think differently about

125
00:05:07,220 --> 00:05:09,979
our roles to accept more responsibility

126
00:05:09,979 --> 00:05:13,310
for that to unburden the consumer but to

127
00:05:13,310 --> 00:05:15,770
Jules final question this does not mean

128
00:05:15,770 --> 00:05:18,080
that the individual should not

129
00:05:18,080 --> 00:05:21,110
participate in a strange sort of way if

130
00:05:21,110 --> 00:05:23,569
we find the right solution will in

131
00:05:23,569 --> 00:05:25,810
effect make consent more meaningful

132
00:05:25,810 --> 00:05:28,159
because it will apply to places where

133
00:05:28,159 --> 00:05:30,740
really is important as opposed to the

134
00:05:30,740 --> 00:05:33,949
grad bag as as Christopher said if you

135
00:05:33,949 --> 00:05:36,800
read this treaty longer than Hamlet and

136
00:05:36,800 --> 00:05:39,319
click I agree everything's just fine

137
00:05:39,319 --> 00:05:41,599
that's just probably not sustainable so

138
00:05:41,599 --> 00:05:43,460
we all over responsibility to think

139
00:05:43,460 --> 00:05:47,330
about a different model so the critique

140
00:05:47,330 --> 00:05:48,620
that well I'll be getting all these

141
00:05:48,620 --> 00:05:50,300
marketing messages because someone has

142
00:05:50,300 --> 00:05:52,490
decided that that's low risk and still

143
00:05:52,490 --> 00:05:56,000
likely to have options to absolute

144
00:05:56,000 --> 00:06:01,400
decisions but the more nuanced public

145
00:06:01,400 --> 00:06:06,500
good type decisions or this is a use for

146
00:06:06,500 --> 00:06:09,349
analytics which a user really maybe

147
00:06:09,349 --> 00:06:12,050
isn't in a good position to be seriously

148
00:06:12,050 --> 00:06:14,150
debating and considering we need the

149
00:06:14,150 --> 00:06:17,180
policymakers the thoughtful stewards to

150
00:06:17,180 --> 00:06:19,659
say you know what this isn't a time to

151
00:06:19,659 --> 00:06:22,849
request a consent it won't ever be

152
00:06:22,849 --> 00:06:26,990
meaningful we need responsible thinkers

153
00:06:26,990 --> 00:06:28,580
to say this is something that should

154
00:06:28,580 --> 00:06:30,500
always be happening it's in the benefit

155
00:06:30,500 --> 00:06:31,960
of the individual benefit of society

156
00:06:31,960 --> 00:06:34,159
here this is a discretionary thing

157
00:06:34,159 --> 00:06:36,259
somebody should be asked to take a box

158
00:06:36,259 --> 00:06:38,839
is that affair for all good intentions

159
00:06:38,839 --> 00:06:41,509
we collectively those of us here those

160
00:06:41,509 --> 00:06:43,190
of us there those of us on both sides

161
00:06:43,190 --> 00:06:43,889
Atlantic

162
00:06:43,889 --> 00:06:46,590
have created the hamlet style privacy

163
00:06:46,590 --> 00:06:49,740
notices we've said Wow individual needs

164
00:06:49,740 --> 00:06:51,090
to be in control the way they get

165
00:06:51,090 --> 00:06:53,069
control is to be more transparent that

166
00:06:53,069 --> 00:06:54,870
means that is eighty thousand words and

167
00:06:54,870 --> 00:06:56,789
everything's just fine and we've

168
00:06:56,789 --> 00:07:00,449
sleepwalked a little bit into thinking

169
00:07:00,449 --> 00:07:03,599
that even for example obvious uses of

170
00:07:03,599 --> 00:07:05,550
information I'm going to provide you

171
00:07:05,550 --> 00:07:06,659
with my address because I'd actually

172
00:07:06,659 --> 00:07:08,129
like the package that I ordered from

173
00:07:08,129 --> 00:07:10,319
Amazon to be delivered which is part of

174
00:07:10,319 --> 00:07:12,539
that eighty thousand treaty like notice

175
00:07:12,539 --> 00:07:16,229
it is is part of the whole deal and we

176
00:07:16,229 --> 00:07:17,490
should think about that and say well

177
00:07:17,490 --> 00:07:20,129
yeah that may be should be discoverable

178
00:07:20,129 --> 00:07:21,810
but it shouldn't be part of the click I

179
00:07:21,810 --> 00:07:24,270
agree notion that covers every single

180
00:07:24,270 --> 00:07:27,479
terms of use including parts of

181
00:07:27,479 --> 00:07:29,580
information use that might really apply

182
00:07:29,580 --> 00:07:32,159
to fundamental human rights we've got it

183
00:07:32,159 --> 00:07:33,330
I think just think differently about

184
00:07:33,330 --> 00:07:36,419
I'll call it mixing up the the pieces so

185
00:07:36,419 --> 00:07:38,009
that it provides a more effective model

186
00:07:38,009 --> 00:07:40,379
but it absolutely still means that the

187
00:07:40,379 --> 00:07:42,800
individual has some control some choice

188
00:07:42,800 --> 00:07:45,569
just the model where it's where it

189
00:07:45,569 --> 00:07:48,199
really does apply

