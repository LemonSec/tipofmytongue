1
00:00:09,070 --> 00:00:11,740
anyway it was a great pleasure that I'm

2
00:00:11,740 --> 00:00:13,860
here today to introduce our next session

3
00:00:13,860 --> 00:00:16,420
so for many of you who've worked in

4
00:00:16,420 --> 00:00:18,669
global organizations and had to look at

5
00:00:18,669 --> 00:00:22,660
us and EU privacy issues often there

6
00:00:22,660 --> 00:00:24,820
appears to be a lot of differences

7
00:00:24,820 --> 00:00:27,519
between the two regimes but our next

8
00:00:27,519 --> 00:00:30,369
session will be examining this in a bit

9
00:00:30,369 --> 00:00:32,650
more detail and exploring the

10
00:00:32,650 --> 00:00:35,769
commonalities and differences in the US

11
00:00:35,769 --> 00:00:39,070
and EU approach how much conflict is

12
00:00:39,070 --> 00:00:41,770
there really and we have an expert

13
00:00:41,770 --> 00:00:45,030
keynote panelist for you this morning

14
00:00:45,030 --> 00:00:48,270
first of all representing the u.s.

15
00:00:48,270 --> 00:00:51,160
delighted to introduce Julie Brill who

16
00:00:51,160 --> 00:00:53,320
is a commissioner for the federal trade

17
00:00:53,320 --> 00:00:55,780
commission commissioner burrell has been

18
00:00:55,780 --> 00:01:01,019
with the FTC since 2010 and has

19
00:01:01,019 --> 00:01:03,430
extensive experience on privacy and

20
00:01:03,430 --> 00:01:05,590
particularly on the consumer protection

21
00:01:05,590 --> 00:01:09,009
side prior to her current law she was

22
00:01:09,009 --> 00:01:10,690
with the Senior Deputy Attorney General

23
00:01:10,690 --> 00:01:13,630
chief of consumer protection antitrust

24
00:01:13,630 --> 00:01:16,360
the North Carolina Department of Justice

25
00:01:16,360 --> 00:01:19,600
a lecturer at Columbia University School

26
00:01:19,600 --> 00:01:22,000
of Law assistant attorney general for

27
00:01:22,000 --> 00:01:25,030
consumer protection antitrust the state

28
00:01:25,030 --> 00:01:27,640
of Vermont for over 20 years numerous

29
00:01:27,640 --> 00:01:30,280
awards for protecting consumers written

30
00:01:30,280 --> 00:01:32,290
numerous articles and served on the

31
00:01:32,290 --> 00:01:34,829
number of expert panels so eminently

32
00:01:34,829 --> 00:01:37,659
experienced to represent the u.s. today

33
00:01:37,659 --> 00:01:42,060
our second speaker representing the EU

34
00:01:42,060 --> 00:01:45,520
delighted to present isabelle Felka

35
00:01:45,520 --> 00:01:48,399
perrita with the chairwoman of the canal

36
00:01:48,399 --> 00:01:51,850
and article 29 working party Madame

37
00:01:51,850 --> 00:01:54,610
Falco Parata has been a member of kimmel

38
00:01:54,610 --> 00:01:59,670
since 2004 came chair in 2011 re-elected

39
00:01:59,670 --> 00:02:02,469
2014 and was elected the chair of the

40
00:02:02,469 --> 00:02:05,590
article 29 working party dobri of this

41
00:02:05,590 --> 00:02:08,590
year again has numerous experience in

42
00:02:08,590 --> 00:02:11,470
privacy technology expert advisors for

43
00:02:11,470 --> 00:02:14,260
the OECD chair the advisory board and

44
00:02:14,260 --> 00:02:16,660
general delegate of the French internet

45
00:02:16,660 --> 00:02:19,359
right forum so again eminently suitable

46
00:02:19,359 --> 00:02:21,560
to represent the EU in our

47
00:02:21,560 --> 00:02:24,110
debate this morning and finally our

48
00:02:24,110 --> 00:02:27,230
referee or should I say moderator for

49
00:02:27,230 --> 00:02:30,980
this I'm sure very candid debate is Yeti

50
00:02:30,980 --> 00:02:33,470
Telamon who is a partner at Covington

51
00:02:33,470 --> 00:02:36,830
and Burling LLP in Brussels yet his

52
00:02:36,830 --> 00:02:39,110
co-chair of the firm's privacy practice

53
00:02:39,110 --> 00:02:41,569
and she's been selected to join the

54
00:02:41,569 --> 00:02:43,250
European Commission or the expert team

55
00:02:43,250 --> 00:02:46,880
on privacy she advises all aspects of EU

56
00:02:46,880 --> 00:02:50,300
DP and security regular speaker on

57
00:02:50,300 --> 00:02:52,489
privacy and she has law degrees from

58
00:02:52,489 --> 00:02:55,100
both Belgium and the US so linking our

59
00:02:55,100 --> 00:02:58,370
two speakers so once again I'd like to

60
00:02:58,370 --> 00:03:00,890
welcome our keynote panel what I'm

61
00:03:00,890 --> 00:03:03,489
assured is going to be a candid and

62
00:03:03,489 --> 00:03:06,680
interesting debate on the commonalities

63
00:03:06,680 --> 00:03:09,489
and differences between the US and EU

64
00:03:09,489 --> 00:03:13,750
welcome our panelists thank you

65
00:03:18,909 --> 00:03:22,450
thank you sooo good morning everybody

66
00:03:22,450 --> 00:03:25,730
this is a well packed room I even see

67
00:03:25,730 --> 00:03:27,440
some people sitting on the steps there

68
00:03:27,440 --> 00:03:30,440
so we hope this will be a good panel and

69
00:03:30,440 --> 00:03:31,819
that is worth while sitting on those

70
00:03:31,819 --> 00:03:35,660
steps commonalities and differences

71
00:03:35,660 --> 00:03:38,870
between the u.s. and the EU approach to

72
00:03:38,870 --> 00:03:42,650
data protection what are we are we just

73
00:03:42,650 --> 00:03:46,310
in the US and the EU are we just very

74
00:03:46,310 --> 00:03:48,319
far cousins who see each other once or

75
00:03:48,319 --> 00:03:52,190
twice a year or are we brothers and

76
00:03:52,190 --> 00:03:53,870
sisters but we haven't quite realized it

77
00:03:53,870 --> 00:03:57,620
yet well the purpose of this panel is to

78
00:03:57,620 --> 00:03:59,569
find the question the answer to that

79
00:03:59,569 --> 00:04:01,940
question but we're not going to find the

80
00:04:01,940 --> 00:04:03,260
answer for you you're going to have to

81
00:04:03,260 --> 00:04:06,019
find the answer yourself and those two

82
00:04:06,019 --> 00:04:08,209
distinguished ladies sitting here with

83
00:04:08,209 --> 00:04:10,310
me on the on the stage here they're

84
00:04:10,310 --> 00:04:11,599
going to help you find the answers

85
00:04:11,599 --> 00:04:15,709
Commissioner brill the FTC madam file

86
00:04:15,709 --> 00:04:20,089
capital of the hill and the chairwoman

87
00:04:20,089 --> 00:04:22,130
of the article 29 working party I can't

88
00:04:22,130 --> 00:04:24,590
think of two more distinguished and more

89
00:04:24,590 --> 00:04:26,180
appropriate people to be sitting here

90
00:04:26,180 --> 00:04:28,520
and to help you answer that question and

91
00:04:28,520 --> 00:04:31,130
the way we we thought we would be doing

92
00:04:31,130 --> 00:04:33,620
this is we would take a number of topics

93
00:04:33,620 --> 00:04:36,050
topics that are very much alive on both

94
00:04:36,050 --> 00:04:38,479
sides of the ocean and see how they're

95
00:04:38,479 --> 00:04:40,789
being dealt with on both sides of the

96
00:04:40,789 --> 00:04:42,590
ocean and see whether there are miles

97
00:04:42,590 --> 00:04:44,810
apart the east and the Western into

98
00:04:44,810 --> 00:04:46,520
shall never meet or whether they're

99
00:04:46,520 --> 00:04:49,450
actually a lot closer than we all think

100
00:04:49,450 --> 00:04:52,460
right now we have only 40 minutes and

101
00:04:52,460 --> 00:04:54,710
some of them are already gone so let's

102
00:04:54,710 --> 00:04:58,669
dive straight into it first topic that

103
00:04:58,669 --> 00:05:00,680
we would use as an example is big data

104
00:05:00,680 --> 00:05:03,410
very much alive on both sides of the

105
00:05:03,410 --> 00:05:05,240
ocean and if I can start with You

106
00:05:05,240 --> 00:05:07,520
Commissioner brill there's been a lot of

107
00:05:07,520 --> 00:05:09,800
activity in the United States on big

108
00:05:09,800 --> 00:05:11,960
data recently you have the White House

109
00:05:11,960 --> 00:05:15,470
who recently released the report you

110
00:05:15,470 --> 00:05:17,630
have the FTC who organized a very

111
00:05:17,630 --> 00:05:20,990
interesting workshop and my question to

112
00:05:20,990 --> 00:05:23,030
you is can you give us a flavor of what

113
00:05:23,030 --> 00:05:25,700
went on there what the latest thinking

114
00:05:25,700 --> 00:05:28,280
is and I would be especially interested

115
00:05:28,280 --> 00:05:29,630
and I imagine the audience would be

116
00:05:29,630 --> 00:05:31,190
especially interested

117
00:05:31,190 --> 00:05:33,380
to see whether we're moving away in the

118
00:05:33,380 --> 00:05:34,810
United States from the traditional

119
00:05:34,810 --> 00:05:38,570
notice and consent form whether we go to

120
00:05:38,570 --> 00:05:41,300
a control of views that's being made of

121
00:05:41,300 --> 00:05:43,130
data rather than a control at the point

122
00:05:43,130 --> 00:05:45,230
of collection is there some is there

123
00:05:45,230 --> 00:05:46,940
some movement that where is this heading

124
00:05:46,940 --> 00:05:50,330
so Thank You Yeti and let me just say

125
00:05:50,330 --> 00:05:53,870
thank you so much to the eye appt us to

126
00:05:53,870 --> 00:05:57,740
come speak the eye appt important

127
00:05:57,740 --> 00:05:59,960
organization and I think that what they

128
00:05:59,960 --> 00:06:02,510
do what's evidenced here is they bring

129
00:06:02,510 --> 00:06:05,660
together people who really care about

130
00:06:05,660 --> 00:06:11,090
privacy we may not always agree on you

131
00:06:11,090 --> 00:06:12,950
know what it is that regulators are

132
00:06:12,950 --> 00:06:15,950
doing but the conversation is so deeply

133
00:06:15,950 --> 00:06:17,780
important and so thank you to Trevor

134
00:06:17,780 --> 00:06:19,880
thank you to Omer thank you to Mindy and

135
00:06:19,880 --> 00:06:22,040
everyone else at the ia PP who does such

136
00:06:22,040 --> 00:06:24,140
a fabulous job organizing these

137
00:06:24,140 --> 00:06:27,710
conferences ok big data well actually

138
00:06:27,710 --> 00:06:30,110
let me give a cheat sheet answer to your

139
00:06:30,110 --> 00:06:31,730
big question in the question that's soo

140
00:06:31,730 --> 00:06:35,000
posed cheat sheet answer you know I

141
00:06:35,000 --> 00:06:36,590
actually think that our commonalities

142
00:06:36,590 --> 00:06:38,540
are much much greater than our

143
00:06:38,540 --> 00:06:39,770
differences I do think there are

144
00:06:39,770 --> 00:06:41,180
differences because we have different

145
00:06:41,180 --> 00:06:42,890
systems and different laws but I think

146
00:06:42,890 --> 00:06:44,810
there's a tremendous amount that is

147
00:06:44,810 --> 00:06:46,460
shared between the United States and

148
00:06:46,460 --> 00:06:49,570
Europe so diving into those issues on

149
00:06:49,570 --> 00:06:54,130
big data so the White House began its

150
00:06:54,130 --> 00:06:59,990
effort almost a year ago but it came out

151
00:06:59,990 --> 00:07:02,330
of the Snowden revelations and the

152
00:07:02,330 --> 00:07:04,630
president announced that he wanted to

153
00:07:04,630 --> 00:07:07,580
re-examine the ways in which information

154
00:07:07,580 --> 00:07:09,200
was being used not only on the

155
00:07:09,200 --> 00:07:11,630
government side but also on the

156
00:07:11,630 --> 00:07:14,840
commercial side and began a big data a

157
00:07:14,840 --> 00:07:16,700
series of workshops and came out with a

158
00:07:16,700 --> 00:07:19,970
report independently because we are an

159
00:07:19,970 --> 00:07:22,940
independent agency the FTC began looking

160
00:07:22,940 --> 00:07:25,160
at big data issues and that grew out

161
00:07:25,160 --> 00:07:26,930
separately not so much out of the

162
00:07:26,930 --> 00:07:29,780
Snowden revelations but out of our 2012

163
00:07:29,780 --> 00:07:31,430
privacy report where we did a big

164
00:07:31,430 --> 00:07:33,680
rethink about the way in which privacy

165
00:07:33,680 --> 00:07:36,200
ought to be thought of in the United

166
00:07:36,200 --> 00:07:38,570
States and it also grew out of a data

167
00:07:38,570 --> 00:07:40,760
broker workshop of data broker workshop

168
00:07:40,760 --> 00:07:43,430
and report that we did I OT

169
00:07:43,430 --> 00:07:45,650
um Internet of Things workshop we've

170
00:07:45,650 --> 00:07:48,290
been doing a lot of thinking and having

171
00:07:48,290 --> 00:07:49,700
a lot of workshops and doing a lot of

172
00:07:49,700 --> 00:07:53,660
reports around big data issues so some

173
00:07:53,660 --> 00:07:55,250
of the things that we have been thinking

174
00:07:55,250 --> 00:07:58,820
about big data does have huge potential

175
00:07:58,820 --> 00:08:01,580
benefits for society you know and this

176
00:08:01,580 --> 00:08:03,380
is reflected in the White House report

177
00:08:03,380 --> 00:08:05,990
but also in our data broker report

178
00:08:05,990 --> 00:08:08,540
whether it's health care whether it's

179
00:08:08,540 --> 00:08:10,550
transportation whether its use of

180
00:08:10,550 --> 00:08:13,730
resources energy resources or education

181
00:08:13,730 --> 00:08:16,700
there are huge potential benefits but we

182
00:08:16,700 --> 00:08:19,580
also see some risks with respect to Big

183
00:08:19,580 --> 00:08:22,100
Data data security we just heard from

184
00:08:22,100 --> 00:08:24,290
Miko a tremendous amount about data data

185
00:08:24,290 --> 00:08:27,440
security Internet of Things and big data

186
00:08:27,440 --> 00:08:31,490
also present data security issues when

187
00:08:31,490 --> 00:08:34,429
we have a collect at all now and maybe

188
00:08:34,429 --> 00:08:37,340
think about potential uses later to me

189
00:08:37,340 --> 00:08:39,679
first and foremost that raises data

190
00:08:39,679 --> 00:08:42,650
security issues collection of health and

191
00:08:42,650 --> 00:08:45,130
other sensitive information or the

192
00:08:45,130 --> 00:08:47,540
creation of health or other sensitive

193
00:08:47,540 --> 00:08:50,180
information these are also of concerns

194
00:08:50,180 --> 00:08:52,160
and we need to be thinking about what

195
00:08:52,160 --> 00:08:54,950
are the appropriate mechanisms for

196
00:08:54,950 --> 00:08:56,870
informing consumers and being

197
00:08:56,870 --> 00:08:58,850
transparent around collection and

198
00:08:58,850 --> 00:09:01,730
creation of health information and one

199
00:09:01,730 --> 00:09:03,110
of the things that we are beginning to

200
00:09:03,110 --> 00:09:04,880
speak about in the United States and one

201
00:09:04,880 --> 00:09:06,560
of the things that our workshop on Big

202
00:09:06,560 --> 00:09:08,810
Data whether it's a tool for inclusion

203
00:09:08,810 --> 00:09:10,940
or exclusion one of the things we're

204
00:09:10,940 --> 00:09:12,590
thinking about is the potential for

205
00:09:12,590 --> 00:09:16,610
discriminatory and unfair use of big

206
00:09:16,610 --> 00:09:19,730
data so the challenges are real I mean

207
00:09:19,730 --> 00:09:21,710
when it comes to big data the challenges

208
00:09:21,710 --> 00:09:23,780
around transparency and choice

209
00:09:23,780 --> 00:09:25,190
mechanisms and providing appropriate

210
00:09:25,190 --> 00:09:27,560
knows notice to consumers it is a

211
00:09:27,560 --> 00:09:29,180
challenge I mean especially in the

212
00:09:29,180 --> 00:09:30,380
internet of things where you have

213
00:09:30,380 --> 00:09:32,120
devices that may not have a user

214
00:09:32,120 --> 00:09:34,760
interface but this doesn't mean that

215
00:09:34,760 --> 00:09:37,520
notice and choice goes away from my

216
00:09:37,520 --> 00:09:38,810
perspective and I think from the

217
00:09:38,810 --> 00:09:40,550
perspective of the Commission as a whole

218
00:09:40,550 --> 00:09:44,540
we need to be thinking about how notice

219
00:09:44,540 --> 00:09:49,340
choice transparency ought to be um I cut

220
00:09:49,340 --> 00:09:51,620
it ought to come to fruition in the

221
00:09:51,620 --> 00:09:53,420
world of big data and in the world of

222
00:09:53,420 --> 00:09:55,610
internet of things not whether they

223
00:09:55,610 --> 00:09:56,780
apply but

224
00:09:56,780 --> 00:09:59,300
how they apply so trans and the other

225
00:09:59,300 --> 00:10:00,830
thing I would say is transparency is an

226
00:10:00,830 --> 00:10:02,570
incredibly important issue with respect

227
00:10:02,570 --> 00:10:05,750
to consumer trust to the extent that we

228
00:10:05,750 --> 00:10:07,970
really do want a big data world in to

229
00:10:07,970 --> 00:10:10,160
the extent that we really do want to see

230
00:10:10,160 --> 00:10:12,380
these potential benefits come to

231
00:10:12,380 --> 00:10:14,660
fruition we need to ensure the consumers

232
00:10:14,660 --> 00:10:16,910
trust the system and the way that that's

233
00:10:16,910 --> 00:10:20,480
going to happen is by transparency and a

234
00:10:20,480 --> 00:10:22,370
providing appropriate notice and choice

235
00:10:22,370 --> 00:10:25,700
in in the right circumstances so the

236
00:10:25,700 --> 00:10:28,340
analogy that I like to use is an

237
00:10:28,340 --> 00:10:31,040
automobile analogy we need to give tools

238
00:10:31,040 --> 00:10:33,170
to consumers on the dashboard we need to

239
00:10:33,170 --> 00:10:34,790
give them notice and choice when

240
00:10:34,790 --> 00:10:37,160
appropriate we talk about the context of

241
00:10:37,160 --> 00:10:39,080
the transaction if we're within a

242
00:10:39,080 --> 00:10:40,940
context of the transaction maybe notice

243
00:10:40,940 --> 00:10:43,880
and choice needs can be a little bit

244
00:10:43,880 --> 00:10:45,830
lesser because it's part of the overall

245
00:10:45,830 --> 00:10:47,540
transaction but when you're talking

246
00:10:47,540 --> 00:10:49,460
about collection and use that's

247
00:10:49,460 --> 00:10:51,620
completely outside of the context of the

248
00:10:51,620 --> 00:10:53,480
transaction that's when we talk about

249
00:10:53,480 --> 00:10:55,610
needing to provide more notice in

250
00:10:55,610 --> 00:10:57,350
information and transparency to

251
00:10:57,350 --> 00:11:00,140
consumers um so I think about this in

252
00:11:00,140 --> 00:11:03,560
the automobile term terms providing

253
00:11:03,560 --> 00:11:05,300
information on a dashboard when

254
00:11:05,300 --> 00:11:08,090
appropriate but also companies need to

255
00:11:08,090 --> 00:11:10,100
be looking under the hood that is

256
00:11:10,100 --> 00:11:12,590
engaging in privacy by design really

257
00:11:12,590 --> 00:11:14,990
examining what they're doing as well as

258
00:11:14,990 --> 00:11:17,870
providing information to consumers on

259
00:11:17,870 --> 00:11:19,910
the dashboard one of the things that

260
00:11:19,910 --> 00:11:21,230
people are talking about a lot in the

261
00:11:21,230 --> 00:11:23,630
United States and I think here are use

262
00:11:23,630 --> 00:11:26,450
frameworks risk-based frameworks when it

263
00:11:26,450 --> 00:11:30,530
comes to big data very important

264
00:11:30,530 --> 00:11:32,560
discussion I think there is a very

265
00:11:32,560 --> 00:11:34,850
important role for youth based

266
00:11:34,850 --> 00:11:37,100
frameworks and risk-based frameworks but

267
00:11:37,100 --> 00:11:38,800
it can't be the end of the conversation

268
00:11:38,800 --> 00:11:42,230
it's part of what of an overall approach

269
00:11:42,230 --> 00:11:45,080
to privacy in this new world but I don't

270
00:11:45,080 --> 00:11:46,550
think that it can be the end of the

271
00:11:46,550 --> 00:11:49,250
conversation again security issues come

272
00:11:49,250 --> 00:11:52,250
into play and also when you talk about

273
00:11:52,250 --> 00:11:54,650
what's inappropriate use I think that

274
00:11:54,650 --> 00:11:56,150
you need to bring the public into that

275
00:11:56,150 --> 00:11:58,280
conversation in other words if it's just

276
00:11:58,280 --> 00:11:59,540
the company's deciding what

277
00:11:59,540 --> 00:12:02,020
inappropriate uses or what risk is I

278
00:12:02,020 --> 00:12:04,520
don't know that the choices will

279
00:12:04,520 --> 00:12:07,100
necessarily always be the best sunshine

280
00:12:07,100 --> 00:12:08,700
is a very important element

281
00:12:08,700 --> 00:12:11,850
so I think that one of the big questions

282
00:12:11,850 --> 00:12:14,130
is who is going to decide what an

283
00:12:14,130 --> 00:12:15,990
appropriate uses who's going to decide

284
00:12:15,990 --> 00:12:18,360
what appropriate risk is in those kinds

285
00:12:18,360 --> 00:12:20,640
of frameworks again being a part of an

286
00:12:20,640 --> 00:12:22,740
overall framework there again I think

287
00:12:22,740 --> 00:12:24,690
the public really needs to be a part of

288
00:12:24,690 --> 00:12:27,390
it and very very briefly an important

289
00:12:27,390 --> 00:12:29,850
role for anonymization the

290
00:12:29,850 --> 00:12:34,080
identification we talked in the at the

291
00:12:34,080 --> 00:12:37,170
FTC about using the root most robust

292
00:12:37,170 --> 00:12:39,720
tools possible for technical d

293
00:12:39,720 --> 00:12:41,970
identification but we all know that it

294
00:12:41,970 --> 00:12:43,530
won't be a silver bullet there will

295
00:12:43,530 --> 00:12:44,940
always be the potential for re

296
00:12:44,940 --> 00:12:48,000
identification so we want a couple d

297
00:12:48,000 --> 00:12:50,400
identification and anonymous ation with

298
00:12:50,400 --> 00:12:53,370
social contracts that is the company

299
00:12:53,370 --> 00:12:54,810
that says we're going to de-identify

300
00:12:54,810 --> 00:12:57,510
we're going to anonymize will also make

301
00:12:57,510 --> 00:13:00,180
a promise that it won't re identify the

302
00:13:00,180 --> 00:13:02,250
data and anyone that it provides the

303
00:13:02,250 --> 00:13:04,590
information to they will ensure that

304
00:13:04,590 --> 00:13:07,740
that company does not seek to

305
00:13:07,740 --> 00:13:09,900
re-identify the data and in that

306
00:13:09,900 --> 00:13:11,430
circumstance again the amount of

307
00:13:11,430 --> 00:13:13,380
consumer trust that will be engendered

308
00:13:13,380 --> 00:13:17,010
by any Big Data project from information

309
00:13:17,010 --> 00:13:18,990
that is d identified in that way I think

310
00:13:18,990 --> 00:13:21,420
will be enormous so those are the kinds

311
00:13:21,420 --> 00:13:22,650
of things that we're thinking about in

312
00:13:22,650 --> 00:13:26,070
order to bring to fruition the benefits

313
00:13:26,070 --> 00:13:28,260
of big data and yet have appropriate

314
00:13:28,260 --> 00:13:31,140
tools in place to protect privacy and

315
00:13:31,140 --> 00:13:34,950
security madam poca beulah does this

316
00:13:34,950 --> 00:13:36,450
sound like this comes from another

317
00:13:36,450 --> 00:13:39,120
planet or does it sound very familiar to

318
00:13:39,120 --> 00:13:42,360
you well it doesn't come from another

319
00:13:42,360 --> 00:13:45,090
planet and I'm glad to be here today to

320
00:13:45,090 --> 00:13:48,750
have I don't know if it's a candid

321
00:13:48,750 --> 00:13:52,410
conversation or pragmatic conversation

322
00:13:52,410 --> 00:13:54,960
that's I'm happy to be here and share

323
00:13:54,960 --> 00:13:59,340
ideas today um a few reactions towards

324
00:13:59,340 --> 00:14:04,320
what Judy just said um first I think we

325
00:14:04,320 --> 00:14:06,690
share the idea in Europe and at the

326
00:14:06,690 --> 00:14:10,650
Working Party 29 levels specifically we

327
00:14:10,650 --> 00:14:15,090
share the idea that big data is just not

328
00:14:15,090 --> 00:14:18,710
only a new way to process that

329
00:14:18,710 --> 00:14:23,400
this is a real i would say historical

330
00:14:23,400 --> 00:14:27,780
breakthrough in other words it's a new

331
00:14:27,780 --> 00:14:31,170
step in the digital age and i would call

332
00:14:31,170 --> 00:14:34,200
it a stay a step in which the data

333
00:14:34,200 --> 00:14:38,100
becomes a little bit ambient you see the

334
00:14:38,100 --> 00:14:41,460
data is everywhere carried by any types

335
00:14:41,460 --> 00:14:46,500
of device the telephone the sensors the

336
00:14:46,500 --> 00:14:49,640
body sensors the electrical sensors the

337
00:14:49,640 --> 00:14:52,740
CCTV everything is big data so I think

338
00:14:52,740 --> 00:14:56,040
we share the conviction with the Podesta

339
00:14:56,040 --> 00:14:59,430
report that we are facing something that

340
00:14:59,430 --> 00:15:04,770
is really different second thing I think

341
00:15:04,770 --> 00:15:09,140
we're sharing is that it brings a huge

342
00:15:09,140 --> 00:15:13,950
amount of benefit and Julie mentioned

343
00:15:13,950 --> 00:15:16,380
some of these new services brought

344
00:15:16,380 --> 00:15:18,810
through big data so there is no

345
00:15:18,810 --> 00:15:22,920
difference between us Third Point of

346
00:15:22,920 --> 00:15:26,610
course we share also the concerns if not

347
00:15:26,610 --> 00:15:29,090
the risks but the concerns

348
00:15:29,090 --> 00:15:33,180
discrimination obviously another concern

349
00:15:33,180 --> 00:15:37,160
maybe is about the role of the algorithm

350
00:15:37,160 --> 00:15:40,620
because big data is based on algorithm

351
00:15:40,620 --> 00:15:43,860
how does it work these algorithm are

352
00:15:43,860 --> 00:15:46,170
they transparent do they know what's

353
00:15:46,170 --> 00:15:49,200
behind what logics are behind the tree

354
00:15:49,200 --> 00:15:52,530
the algorithm this is probably one of

355
00:15:52,530 --> 00:15:56,250
the subject but generally speaking what

356
00:15:56,250 --> 00:15:59,820
we fear about big data is that the

357
00:15:59,820 --> 00:16:04,100
person the individual won't be in

358
00:16:04,100 --> 00:16:07,500
control of this big data so in the

359
00:16:07,500 --> 00:16:10,590
statement the Working Party 29 issued we

360
00:16:10,590 --> 00:16:13,290
said the individual they have to stay in

361
00:16:13,290 --> 00:16:16,040
control they have to be able to make

362
00:16:16,040 --> 00:16:19,650
information toys towards big data

363
00:16:19,650 --> 00:16:24,060
applications so does it mean we have to

364
00:16:24,060 --> 00:16:27,390
review our principles that was your

365
00:16:27,390 --> 00:16:30,930
question to what we have as an

366
00:16:30,930 --> 00:16:31,800
experience

367
00:16:31,800 --> 00:16:34,740
in Europe the answer from the g20 9

368
00:16:34,740 --> 00:16:38,149
would be from the Working Party 29 is no

369
00:16:38,149 --> 00:16:42,649
no because we don't have proof evidence

370
00:16:42,649 --> 00:16:46,560
that our principles are no longer valid

371
00:16:46,560 --> 00:16:49,410
on the contrary in each of our countries

372
00:16:49,410 --> 00:16:52,680
we are already working on big data

373
00:16:52,680 --> 00:16:56,550
applications using our principles so

374
00:16:56,550 --> 00:17:01,649
they are definitely efficient and I

375
00:17:01,649 --> 00:17:04,410
would say that on the contrary if we

376
00:17:04,410 --> 00:17:07,290
were to change our principal and there

377
00:17:07,290 --> 00:17:11,579
are ideas around this direction for

378
00:17:11,579 --> 00:17:13,530
instance and Julie mentioned it the

379
00:17:13,530 --> 00:17:17,400
risk-based approach we would be maybe a

380
00:17:17,400 --> 00:17:21,030
little bit afraid because we believe

381
00:17:21,030 --> 00:17:24,030
that the risk-based approach is a very

382
00:17:24,030 --> 00:17:27,150
interesting approach to measure the

383
00:17:27,150 --> 00:17:31,980
allocation of resources of DPA of data

384
00:17:31,980 --> 00:17:35,510
controllers to proportionate

385
00:17:35,510 --> 00:17:39,380
accountability obligations all of that

386
00:17:39,380 --> 00:17:42,120
can be linked to the risk-based

387
00:17:42,120 --> 00:17:44,970
approached but the rights of the data

388
00:17:44,970 --> 00:17:47,460
subjects how can they be linked to the

389
00:17:47,460 --> 00:17:51,090
risk-based approach and specifically if

390
00:17:51,090 --> 00:17:53,550
the risk is assessed by the data

391
00:17:53,550 --> 00:17:56,820
controller you have the right or you

392
00:17:56,820 --> 00:18:00,059
don't have the right it's not related to

393
00:18:00,059 --> 00:18:05,010
the risk so as a conclusion to you

394
00:18:05,010 --> 00:18:09,530
question we believe that big data is a

395
00:18:09,530 --> 00:18:13,910
dramatic new step for the digital age

396
00:18:13,910 --> 00:18:19,230
that it doesn't pushes every all of us

397
00:18:19,230 --> 00:18:23,040
to review our principles of course we

398
00:18:23,040 --> 00:18:26,400
have to develop innovative thinking for

399
00:18:26,400 --> 00:18:30,150
anonymization for market marketing

400
00:18:30,150 --> 00:18:33,330
efforts for transparencies of course we

401
00:18:33,330 --> 00:18:36,090
have to work on that but the principles

402
00:18:36,090 --> 00:18:39,690
of our EU legal framework are still

403
00:18:39,690 --> 00:18:43,890
valid we believe it thank you I hope

404
00:18:43,890 --> 00:18:45,290
you're keeping score

405
00:18:45,290 --> 00:18:49,700
common different I'm keeping my scores

406
00:18:49,700 --> 00:18:52,820
right second one bridge incidents

407
00:18:52,820 --> 00:18:55,110
unfortunately most of you in the room

408
00:18:55,110 --> 00:18:57,240
during your professional life you're

409
00:18:57,240 --> 00:18:58,620
gonna have one you're gonna have a

410
00:18:58,620 --> 00:19:00,360
breach incident and you're gonna have to

411
00:19:00,360 --> 00:19:04,890
go to your regulator now madam Alka p

412
00:19:04,890 --> 00:19:07,440
about that in Europe contrary to the

413
00:19:07,440 --> 00:19:09,150
United States we don't have a uniform

414
00:19:09,150 --> 00:19:10,890
breach role you we have some Member

415
00:19:10,890 --> 00:19:12,330
States very few actually who have a

416
00:19:12,330 --> 00:19:15,570
breach notification law but of but

417
00:19:15,570 --> 00:19:17,190
obviously we all know that in the draft

418
00:19:17,190 --> 00:19:19,470
regulation it's very much in there and

419
00:19:19,470 --> 00:19:21,630
it's very brought a very low threshold

420
00:19:21,630 --> 00:19:25,560
very short period to to come to the

421
00:19:25,560 --> 00:19:28,610
regulator and I would be interested I

422
00:19:28,610 --> 00:19:30,540
would be interested in two things

423
00:19:30,540 --> 00:19:33,930
actually one is it strikes me that this

424
00:19:33,930 --> 00:19:36,320
is an area where the United States is

425
00:19:36,320 --> 00:19:39,330
actually far ahead of Europe you have

426
00:19:39,330 --> 00:19:43,650
had bridge laws for decades so is Europe

427
00:19:43,650 --> 00:19:45,240
looking to the States sort of saying

428
00:19:45,240 --> 00:19:46,890
those are mistakes that were made over

429
00:19:46,890 --> 00:19:48,060
there we're not gonna make the same

430
00:19:48,060 --> 00:19:49,800
mistakes will make our own mistakes but

431
00:19:49,800 --> 00:19:52,200
not at least not those and I'm losing my

432
00:19:52,200 --> 00:19:56,520
papers here that's my first question are

433
00:19:56,520 --> 00:19:58,890
we looking at at the states here in

434
00:19:58,890 --> 00:20:02,190
Europe and second is how are the dpa is

435
00:20:02,190 --> 00:20:03,840
preparing for this this is going to be

436
00:20:03,840 --> 00:20:09,420
an avalanche of notifications very

437
00:20:09,420 --> 00:20:10,920
complicated could be cyber security

438
00:20:10,920 --> 00:20:13,440
could be malware could be simple human

439
00:20:13,440 --> 00:20:17,940
error could be forensics is the main

440
00:20:17,940 --> 00:20:19,830
power within dps to do this is their

441
00:20:19,830 --> 00:20:21,960
knowledge technical knowledge within dps

442
00:20:21,960 --> 00:20:23,730
I'd be interested in your views yeah

443
00:20:23,730 --> 00:20:27,810
this is a also a very key question

444
00:20:27,810 --> 00:20:29,850
because for instance at the clean level

445
00:20:29,850 --> 00:20:33,330
in most of our investigation we noticed

446
00:20:33,330 --> 00:20:36,720
that there is a data security issue and

447
00:20:36,720 --> 00:20:39,840
that there is I would say a sort of lack

448
00:20:39,840 --> 00:20:43,200
of security culture within the data

449
00:20:43,200 --> 00:20:45,120
controllers so of course we're very much

450
00:20:45,120 --> 00:20:47,280
interested by the American example that

451
00:20:47,280 --> 00:20:50,820
is a little bit ahead and compared to us

452
00:20:50,820 --> 00:20:55,260
in the means to cope these data security

453
00:20:55,260 --> 00:20:58,770
issue it's not entirely true

454
00:20:58,770 --> 00:21:02,100
she said we have the uniform legislation

455
00:21:02,100 --> 00:21:05,340
that was passed in 2009 and that has

456
00:21:05,340 --> 00:21:07,530
started to be implemented in the

457
00:21:07,530 --> 00:21:09,090
European countries in France for

458
00:21:09,090 --> 00:21:12,510
instance it's in 2011 that we have

459
00:21:12,510 --> 00:21:15,210
introduced the data notification in our

460
00:21:15,210 --> 00:21:19,950
low so it's probably a bit too early to

461
00:21:19,950 --> 00:21:23,850
have I would say in general conclusion

462
00:21:23,850 --> 00:21:26,670
on the efficiency of this notification

463
00:21:26,670 --> 00:21:29,910
within Europe but what we could say is

464
00:21:29,910 --> 00:21:32,580
that from the at least the French

465
00:21:32,580 --> 00:21:37,200
example and some others in interesting

466
00:21:37,200 --> 00:21:40,040
comments first we haven't been floated

467
00:21:40,040 --> 00:21:45,150
by notification and it's not exactly

468
00:21:45,150 --> 00:21:49,590
what we expected second and generally

469
00:21:49,590 --> 00:21:53,160
the notification a bit late compared to

470
00:21:53,160 --> 00:21:58,490
the obligation of the law third these

471
00:21:58,490 --> 00:22:01,680
notification they help the data

472
00:22:01,680 --> 00:22:05,190
controller and I'm sure Julie will agree

473
00:22:05,190 --> 00:22:08,820
to structure the internal internal

474
00:22:08,820 --> 00:22:13,130
procedure for the security issue so

475
00:22:13,130 --> 00:22:16,380
pedagogically it's very helpful for the

476
00:22:16,380 --> 00:22:19,970
data controller but it's true that this

477
00:22:19,970 --> 00:22:23,550
legislation yet is not really well

478
00:22:23,550 --> 00:22:25,230
understood by the Europe and data

479
00:22:25,230 --> 00:22:27,450
controller and in France for instance

480
00:22:27,450 --> 00:22:31,130
we've had to make meeting with them to

481
00:22:31,130 --> 00:22:34,650
re-explain the legislation in order for

482
00:22:34,650 --> 00:22:38,640
them to understand it so for the g20 9

483
00:22:38,640 --> 00:22:43,260
we have issued recently an advice and

484
00:22:43,260 --> 00:22:46,800
opinion giving to the data controllers

485
00:22:46,800 --> 00:22:49,590
some examples of good practices good

486
00:22:49,590 --> 00:22:52,530
practice for instance to be examined for

487
00:22:52,530 --> 00:22:55,620
notification to the data subjects so

488
00:22:55,620 --> 00:23:00,810
there is a huge debate and reflection

489
00:23:00,810 --> 00:23:02,970
about this legislation I think it's a

490
00:23:02,970 --> 00:23:05,670
good legislation and I would say it's

491
00:23:05,670 --> 00:23:09,440
not a good legislation which aims at

492
00:23:09,440 --> 00:23:12,299
pointing out the data controllers that

493
00:23:12,299 --> 00:23:18,059
has committed a mistake for us the main

494
00:23:18,059 --> 00:23:21,690
interest of this legislation is to

495
00:23:21,690 --> 00:23:27,480
structure the information flows and the

496
00:23:27,480 --> 00:23:30,600
security culture within the data

497
00:23:30,600 --> 00:23:33,570
controllers and to help I would say the

498
00:23:33,570 --> 00:23:37,409
maturity of the issue to raise and it

499
00:23:37,409 --> 00:23:40,860
takes time it was not in our habits but

500
00:23:40,860 --> 00:23:43,409
I'm sure by the end it's going to be

501
00:23:43,409 --> 00:23:47,010
very efficient Commissioner Burrell does

502
00:23:47,010 --> 00:23:48,840
this sound familiar to you or you say oh

503
00:23:48,840 --> 00:23:50,789
no we do it completely differently it

504
00:23:50,789 --> 00:23:55,260
will um we we do it in a way that many

505
00:23:55,260 --> 00:23:56,490
people in the United States don't

506
00:23:56,490 --> 00:24:00,960
understand even but but actually the

507
00:24:00,960 --> 00:24:04,860
principle behind it is precisely as

508
00:24:04,860 --> 00:24:09,929
Isabel articulated which is that the

509
00:24:09,929 --> 00:24:12,539
idea behind breach notification it is to

510
00:24:12,539 --> 00:24:15,059
inform consumers so especially if it

511
00:24:15,059 --> 00:24:16,620
involves their credit card or whatever

512
00:24:16,620 --> 00:24:18,659
that they can take steps to try to

513
00:24:18,659 --> 00:24:20,070
protect themselves against identity

514
00:24:20,070 --> 00:24:22,770
theft however another very important

515
00:24:22,770 --> 00:24:24,179
principle behind the breach notification

516
00:24:24,179 --> 00:24:27,630
laws is to instill a culture of data

517
00:24:27,630 --> 00:24:31,200
security and to basically tie the

518
00:24:31,200 --> 00:24:33,899
company's reputation to data security

519
00:24:33,899 --> 00:24:37,049
and this has been going on now for over

520
00:24:37,049 --> 00:24:38,750
ten years in the united states

521
00:24:38,750 --> 00:24:41,909
california was the first state to adopt

522
00:24:41,909 --> 00:24:44,820
a breach notification law and the reason

523
00:24:44,820 --> 00:24:46,500
i said it was complicated how it's done

524
00:24:46,500 --> 00:24:48,779
is the breach notification laws are

525
00:24:48,779 --> 00:24:52,110
actually at the state level there are 47

526
00:24:52,110 --> 00:24:53,250
states that now have a breach

527
00:24:53,250 --> 00:24:55,049
notification law so essentially it is

528
00:24:55,049 --> 00:24:57,120
more or less universal in the united

529
00:24:57,120 --> 00:24:59,340
states but at the state level with

530
00:24:59,340 --> 00:25:02,130
respect to the underlying data security

531
00:25:02,130 --> 00:25:04,890
that is what was happening with respect

532
00:25:04,890 --> 00:25:06,480
to the breach and whether or not a

533
00:25:06,480 --> 00:25:09,419
company had engaged in as we term it at

534
00:25:09,419 --> 00:25:10,820
the Federal Trade Commission

535
00:25:10,820 --> 00:25:14,100
unreasonable security practices that is

536
00:25:14,100 --> 00:25:16,049
something that we examine at the federal

537
00:25:16,049 --> 00:25:19,230
level at the FTC but it is the principle

538
00:25:19,230 --> 00:25:21,090
behind it is precisely as Isabel

539
00:25:21,090 --> 00:25:22,060
articulated

540
00:25:22,060 --> 00:25:26,500
is to tie the company's reputation to

541
00:25:26,500 --> 00:25:28,660
data security how are we doing in the

542
00:25:28,660 --> 00:25:31,540
United States we still have a ways to go

543
00:25:31,540 --> 00:25:34,090
as well in terms of instilling a

544
00:25:34,090 --> 00:25:36,730
security culture I can't say whether

545
00:25:36,730 --> 00:25:39,880
we're ahead or behind European companies

546
00:25:39,880 --> 00:25:42,340
but i do think for instance most of the

547
00:25:42,340 --> 00:25:44,260
people in this audience get it they

548
00:25:44,260 --> 00:25:47,170
completely get it where we're working to

549
00:25:47,170 --> 00:25:51,760
reach are the the long tail of say for

550
00:25:51,760 --> 00:25:54,160
instance the app community or the long

551
00:25:54,160 --> 00:25:57,070
tail of other service providers that is

552
00:25:57,070 --> 00:25:59,890
entities that may not be able to send

553
00:25:59,890 --> 00:26:02,530
representatives to a conference like

554
00:26:02,530 --> 00:26:04,120
this or may not be represented by

555
00:26:04,120 --> 00:26:05,800
attorneys who can come to a conference

556
00:26:05,800 --> 00:26:08,020
like this but you know the traditional

557
00:26:08,020 --> 00:26:09,460
sort of two guys are two gals in a

558
00:26:09,460 --> 00:26:11,860
garage we've got to instill in them the

559
00:26:11,860 --> 00:26:15,760
same security culture because size of a

560
00:26:15,760 --> 00:26:17,620
company does not correlate to

561
00:26:17,620 --> 00:26:20,110
sensitivity and importance of the data

562
00:26:20,110 --> 00:26:22,360
so it's very important for from our

563
00:26:22,360 --> 00:26:23,920
perspective to try to instill the

564
00:26:23,920 --> 00:26:25,960
security culture everywhere but I

565
00:26:25,960 --> 00:26:26,980
thought it might be interesting for

566
00:26:26,980 --> 00:26:30,310
folks to hear a little bit too you know

567
00:26:30,310 --> 00:26:32,320
about how we do it at the FTC so there's

568
00:26:32,320 --> 00:26:34,030
breach notification and then there's

569
00:26:34,030 --> 00:26:36,100
examining the underlying security the

570
00:26:36,100 --> 00:26:37,720
Federal Trade Commission looks at that

571
00:26:37,720 --> 00:26:41,860
through our FTC act we have brought to

572
00:26:41,860 --> 00:26:46,660
date over like 40 50 cases if you suffer

573
00:26:46,660 --> 00:26:49,180
a breach it doesn't necessarily mean

574
00:26:49,180 --> 00:26:51,700
that we're going to bring an enforcement

575
00:26:51,700 --> 00:26:55,210
action and conversely even if you don't

576
00:26:55,210 --> 00:26:57,130
suffer a breach we still might bring an

577
00:26:57,130 --> 00:26:59,130
enforcement action if we find that you

578
00:26:59,130 --> 00:27:01,210
did not have reasonable security

579
00:27:01,210 --> 00:27:03,970
practices that could lead to a clear

580
00:27:03,970 --> 00:27:06,760
vulnerability and the clear potential

581
00:27:06,760 --> 00:27:09,730
for a data security problem so you'll

582
00:27:09,730 --> 00:27:12,180
see cases that fall into both categories

583
00:27:12,180 --> 00:27:16,960
will we have federal legislation you

584
00:27:16,960 --> 00:27:18,340
know again on the civilian normal

585
00:27:18,340 --> 00:27:22,450
question the Federal Trade Commission

586
00:27:22,450 --> 00:27:24,550
which is a bipartisan independent

587
00:27:24,550 --> 00:27:27,670
commission has unanimously called for

588
00:27:27,670 --> 00:27:31,360
federal legislation I as one of the five

589
00:27:31,360 --> 00:27:33,580
members of the Commission do believe

590
00:27:33,580 --> 00:27:34,380
there should

591
00:27:34,380 --> 00:27:38,130
be a strong federal legislation and if

592
00:27:38,130 --> 00:27:40,560
there's strong legislation for breach

593
00:27:40,560 --> 00:27:42,870
notification then I'd be okay with

594
00:27:42,870 --> 00:27:44,730
preemption but I don't think there

595
00:27:44,730 --> 00:27:46,170
should be preemption of all the state

596
00:27:46,170 --> 00:27:47,960
laws unless the breach notification

597
00:27:47,960 --> 00:27:51,890
portion of this law is strong that is

598
00:27:51,890 --> 00:27:55,230
robust notification to consumers on the

599
00:27:55,230 --> 00:27:58,080
issue of data security as opposed to the

600
00:27:58,080 --> 00:28:00,450
breach notification I think they're the

601
00:28:00,450 --> 00:28:03,980
argument for preemption is more

602
00:28:03,980 --> 00:28:06,630
significant and and ought to be paid

603
00:28:06,630 --> 00:28:08,670
more attention to I don't see how

604
00:28:08,670 --> 00:28:11,610
companies could have different security

605
00:28:11,610 --> 00:28:14,460
systems one for California one for North

606
00:28:14,460 --> 00:28:17,340
Carolina 14 months it I just don't know

607
00:28:17,340 --> 00:28:19,890
how that works so again I think that the

608
00:28:19,890 --> 00:28:22,110
law should be a strong one and I'm very

609
00:28:22,110 --> 00:28:23,640
hopeful that it will pass because I do

610
00:28:23,640 --> 00:28:26,100
look we're doing a good job at the FTC

611
00:28:26,100 --> 00:28:28,500
on data security but we could use a few

612
00:28:28,500 --> 00:28:32,310
more tools in our toolbox in order to

613
00:28:32,310 --> 00:28:35,190
improve and further instill the culture

614
00:28:35,190 --> 00:28:37,110
that Isabelle was talking about whether

615
00:28:37,110 --> 00:28:38,730
it's through rulemaking Authority or

616
00:28:38,730 --> 00:28:41,660
civil civil money penalty authority or

617
00:28:41,660 --> 00:28:43,770
additional tools i think that that would

618
00:28:43,770 --> 00:28:47,190
be helpful in this area thank you let's

619
00:28:47,190 --> 00:28:48,450
make this a little bit more difficult

620
00:28:48,450 --> 00:28:50,970
for our ladies here I've been thinking

621
00:28:50,970 --> 00:28:55,890
loud and heart and find something that I

622
00:28:55,890 --> 00:28:58,170
think is typical European and I think I

623
00:28:58,170 --> 00:29:00,450
found it the right to be forgotten so

624
00:29:00,450 --> 00:29:02,100
let's not forget the right to be

625
00:29:02,100 --> 00:29:04,530
forgotten manifold could be others then

626
00:29:04,530 --> 00:29:06,060
where are we on the right to be

627
00:29:06,060 --> 00:29:08,700
forgotten so you can have your drink

628
00:29:08,700 --> 00:29:14,300
first if you want better for my voice

629
00:29:14,930 --> 00:29:19,920
sorry um where are we exactly hmm good

630
00:29:19,920 --> 00:29:24,060
start um we have a decision of the

631
00:29:24,060 --> 00:29:26,970
European Court of Justice there is a

632
00:29:26,970 --> 00:29:30,450
very crucial decision and I think this

633
00:29:30,450 --> 00:29:33,470
decision it's not only dedicated and

634
00:29:33,470 --> 00:29:37,740
directed to Europe it's a decision that

635
00:29:37,740 --> 00:29:41,310
is addressed I would say not to the

636
00:29:41,310 --> 00:29:43,590
entire world but at least to the privacy

637
00:29:43,590 --> 00:29:45,530
community as a whole

638
00:29:45,530 --> 00:29:48,950
and it says first and this is very

639
00:29:48,950 --> 00:29:51,860
important that privacy is a fundamental

640
00:29:51,860 --> 00:29:55,220
right and I think it's important that

641
00:29:55,220 --> 00:29:57,950
the highest judiciary level in Europe

642
00:29:57,950 --> 00:30:02,630
has said repeatedly and again privacy is

643
00:30:02,630 --> 00:30:08,030
a fundamental right second technically

644
00:30:08,030 --> 00:30:14,920
the decision is not so new because I

645
00:30:14,920 --> 00:30:18,800
mean the right to erase the right to

646
00:30:18,800 --> 00:30:21,770
oppose we knew this right in the

647
00:30:21,770 --> 00:30:26,480
directive and the editors the bloggers I

648
00:30:26,480 --> 00:30:28,880
mean it was already applied by the DPA

649
00:30:28,880 --> 00:30:32,150
within Europe what is new is that the

650
00:30:32,150 --> 00:30:35,450
search engine are now considered by the

651
00:30:35,450 --> 00:30:38,720
court and so by the regulators as data

652
00:30:38,720 --> 00:30:41,840
controllers so they have to apply these

653
00:30:41,840 --> 00:30:47,960
rights having said that it's true that

654
00:30:47,960 --> 00:30:51,880
the decision of the court has risen

655
00:30:51,880 --> 00:30:55,400
enormous social expectations within

656
00:30:55,400 --> 00:30:59,450
Europe and you probably have the figures

657
00:30:59,450 --> 00:31:03,260
from google but it's more than 100,000

658
00:31:03,260 --> 00:31:09,140
demands towards Google to delist content

659
00:31:09,140 --> 00:31:12,920
what does it mean to us privacy

660
00:31:12,920 --> 00:31:16,640
community it means that people they

661
00:31:16,640 --> 00:31:19,100
won't somehow to control their digital

662
00:31:19,100 --> 00:31:21,200
life and it's a new way that is offered

663
00:31:21,200 --> 00:31:24,860
to them complimentary to go directly to

664
00:31:24,860 --> 00:31:28,640
the editor primary editor of website for

665
00:31:28,640 --> 00:31:31,850
instance to control this digital life so

666
00:31:31,850 --> 00:31:37,420
it's we have to listen to that so what

667
00:31:37,420 --> 00:31:41,900
the g29 has done since then of course

668
00:31:41,900 --> 00:31:44,200
what we want is to have a kind of

669
00:31:44,200 --> 00:31:47,870
harmonized application of this decision

670
00:31:47,870 --> 00:31:51,500
within Europe why do we want that not to

671
00:31:51,500 --> 00:31:54,860
exist but because we want the data

672
00:31:54,860 --> 00:31:57,910
subjects wherever they are in Europe

673
00:31:57,910 --> 00:32:02,440
to benefit from the same protection so

674
00:32:02,440 --> 00:32:07,360
we constituted very quickly after the

675
00:32:07,360 --> 00:32:11,500
decision of the court a working group in

676
00:32:11,500 --> 00:32:13,810
order first to cope with the first

677
00:32:13,810 --> 00:32:16,960
complaints we had and they had been

678
00:32:16,960 --> 00:32:19,630
complaints all over Europe from the disc

679
00:32:19,630 --> 00:32:22,210
on the decision the first decision of

680
00:32:22,210 --> 00:32:26,680
Google because we know that roughly half

681
00:32:26,680 --> 00:32:29,830
of the demands have been accepted and so

682
00:32:29,830 --> 00:32:32,350
they listed by Google and so the

683
00:32:32,350 --> 00:32:34,630
decision of Google are under the control

684
00:32:34,630 --> 00:32:37,150
of the regulators the Privacy Protection

685
00:32:37,150 --> 00:32:40,300
Authority or the judge so in all of

686
00:32:40,300 --> 00:32:42,580
European countries we have had we have

687
00:32:42,580 --> 00:32:45,130
received complaints so we have

688
00:32:45,130 --> 00:32:48,150
constituted this working group to

689
00:32:48,150 --> 00:32:52,060
coordinate ourselves to deal to assess

690
00:32:52,060 --> 00:32:55,420
the complaints we have elaborated a kind

691
00:32:55,420 --> 00:32:59,520
of dashboard in order to segment and to

692
00:32:59,520 --> 00:33:03,280
to map the different complaints we were

693
00:33:03,280 --> 00:33:06,700
receiving and what we are trying to do

694
00:33:06,700 --> 00:33:11,740
now is from these ingredients practical

695
00:33:11,740 --> 00:33:15,490
ingredients to be able and I hope next

696
00:33:15,490 --> 00:33:18,360
week we will be able to do it to issue

697
00:33:18,360 --> 00:33:21,580
guidelines common guidelines which means

698
00:33:21,580 --> 00:33:25,900
first common criteria throughout Europe

699
00:33:25,900 --> 00:33:28,750
on what criteria do we decide that

700
00:33:28,750 --> 00:33:31,090
Google has made the right or the wrong

701
00:33:31,090 --> 00:33:35,170
decision is it a public figure is it a

702
00:33:35,170 --> 00:33:39,160
minor is it an accurate information I

703
00:33:39,160 --> 00:33:42,100
mean we can figure out what kind of

704
00:33:42,100 --> 00:33:44,530
criteria criteria could be on the list

705
00:33:44,530 --> 00:33:48,790
it's already the practice of the DPA

706
00:33:48,790 --> 00:33:51,540
it's also probably related to the

707
00:33:51,540 --> 00:33:56,020
decision of the courts so common

708
00:33:56,020 --> 00:34:00,070
criteria and second document that we try

709
00:34:00,070 --> 00:34:03,880
to elaborate is a document that would be

710
00:34:03,880 --> 00:34:07,270
that would explain how this right will

711
00:34:07,270 --> 00:34:10,330
be de-listed is going to work which data

712
00:34:10,330 --> 00:34:11,210
subjects

713
00:34:11,210 --> 00:34:16,030
benefit from this right for instance

714
00:34:16,030 --> 00:34:19,849
Chinese in Hong Kong is allowed to ask

715
00:34:19,849 --> 00:34:24,409
for the listing and what is the what

716
00:34:24,409 --> 00:34:28,760
will be the territorial effect of the

717
00:34:28,760 --> 00:34:32,440
delisting decision is it only limited to

718
00:34:32,440 --> 00:34:35,409
Europe is it a worldwide decision

719
00:34:35,409 --> 00:34:37,639
depending on how the treatment is

720
00:34:37,639 --> 00:34:40,760
organized you see they are a lot of

721
00:34:40,760 --> 00:34:45,050
different technical aspects that we have

722
00:34:45,050 --> 00:34:49,760
to deal with and the idea is to have at

723
00:34:49,760 --> 00:34:53,330
the European level the common approach

724
00:34:53,330 --> 00:34:56,629
and I think it's a very important

725
00:34:56,629 --> 00:34:59,570
because again we believe that it's not a

726
00:34:59,570 --> 00:35:03,950
technical subject for technicians it's a

727
00:35:03,950 --> 00:35:07,520
subject for the life of every day every

728
00:35:07,520 --> 00:35:10,310
everyday life of everyone so we

729
00:35:10,310 --> 00:35:16,210
definitely as DPA need to bring a simple

730
00:35:16,210 --> 00:35:19,210
understandable and come an answer within

731
00:35:19,210 --> 00:35:22,940
Europe so next week we're going to have

732
00:35:22,940 --> 00:35:25,220
our plenary session at the Working Party

733
00:35:25,220 --> 00:35:28,849
29 and I hope we'll be able to provide

734
00:35:28,849 --> 00:35:31,910
you with these common guidelines are

735
00:35:31,910 --> 00:35:33,920
looking forward to them commissionable

736
00:35:33,920 --> 00:35:35,780
are you gonna prove me wrong that this

737
00:35:35,780 --> 00:35:37,490
is a typical European thing is there

738
00:35:37,490 --> 00:35:39,770
such a thing in the United States well

739
00:35:39,770 --> 00:35:42,650
uh needless to say as everybody knows

740
00:35:42,650 --> 00:35:48,800
the ECJ decision was quite controversial

741
00:35:48,800 --> 00:35:51,940
in the United States there were a lot of

742
00:35:51,940 --> 00:35:55,790
First Amendment advocates who read this

743
00:35:55,790 --> 00:35:57,740
as a slap in the face to the First

744
00:35:57,740 --> 00:36:01,010
Amendment generally I don't want to take

745
00:36:01,010 --> 00:36:03,010
a lot of time because this is a very

746
00:36:03,010 --> 00:36:05,869
subtle and complicated issue with

747
00:36:05,869 --> 00:36:07,760
respect to the United States in my view

748
00:36:07,760 --> 00:36:10,150
I did give a speech about this in Vienna

749
00:36:10,150 --> 00:36:14,330
a couple of months ago so the short

750
00:36:14,330 --> 00:36:17,960
answer is I think that there are

751
00:36:17,960 --> 00:36:21,920
elements in US law and in u.s. tradition

752
00:36:21,920 --> 00:36:23,579
as well as in what the ft

753
00:36:23,579 --> 00:36:26,339
she has called for to be implemented in

754
00:36:26,339 --> 00:36:29,489
the united states that reflect a right

755
00:36:29,489 --> 00:36:32,609
of deletion and or the the concerns

756
00:36:32,609 --> 00:36:34,200
around a right of deletion or right of

757
00:36:34,200 --> 00:36:36,630
erasure i don't think we would use the

758
00:36:36,630 --> 00:36:39,089
terminology right to be forgotten I

759
00:36:39,089 --> 00:36:41,969
worry that that's actually somewhat of a

760
00:36:41,969 --> 00:36:44,039
misnomer or potentially misleading

761
00:36:44,039 --> 00:36:46,319
because I don't think it really is a

762
00:36:46,319 --> 00:36:48,180
right to be forgotten it but I think

763
00:36:48,180 --> 00:36:51,180
Isabel mentioned you know these concepts

764
00:36:51,180 --> 00:36:52,739
of right of deletion and right of

765
00:36:52,739 --> 00:36:55,499
erasure have been around for a while in

766
00:36:55,499 --> 00:36:58,289
the United States it's more targeted you

767
00:36:58,289 --> 00:36:59,519
know it exists in the Fair Credit

768
00:36:59,519 --> 00:37:01,619
Reporting Act consumers have the right

769
00:37:01,619 --> 00:37:03,869
to have information removed from their

770
00:37:03,869 --> 00:37:05,910
credit report if it's old or if it's

771
00:37:05,910 --> 00:37:07,529
inaccurate and they have the right to

772
00:37:07,529 --> 00:37:10,380
review their credit reports for accuracy

773
00:37:10,380 --> 00:37:13,589
we have called for people search firms

774
00:37:13,589 --> 00:37:16,410
that is entities that perform a similar

775
00:37:16,410 --> 00:37:18,959
function to what was going on in the ECJ

776
00:37:18,959 --> 00:37:21,630
decision the underlying facts similar

777
00:37:21,630 --> 00:37:24,479
but not identical we've called for those

778
00:37:24,479 --> 00:37:26,729
firms to give consumers the ability to

779
00:37:26,729 --> 00:37:30,839
opt out or to erase their information so

780
00:37:30,839 --> 00:37:32,819
there are elements of this that either

781
00:37:32,819 --> 00:37:35,999
exists in US law now or that exists in

782
00:37:35,999 --> 00:37:38,279
our thinking oh and the the face our

783
00:37:38,279 --> 00:37:41,609
facebook consent order requires this

784
00:37:41,609 --> 00:37:43,829
that social network to provide a right

785
00:37:43,829 --> 00:37:47,069
of deletion for consumers in certain

786
00:37:47,069 --> 00:37:48,839
circumstances so we do have these

787
00:37:48,839 --> 00:37:51,209
concepts one of the things that I have

788
00:37:51,209 --> 00:37:54,779
called for in my speech and and

789
00:37:54,779 --> 00:37:58,019
elsewhere is clearly Europe is working

790
00:37:58,019 --> 00:37:59,549
through these issues I mean is Isabel

791
00:37:59,549 --> 00:38:01,499
just said and they are complicated

792
00:38:01,499 --> 00:38:04,170
issues you know the ECJ just like the

793
00:38:04,170 --> 00:38:05,880
Supreme Court decisions under the Fourth

794
00:38:05,880 --> 00:38:08,099
Amendment they've got a set of facts in

795
00:38:08,099 --> 00:38:09,650
front of them and they render a decision

796
00:38:09,650 --> 00:38:13,079
how those set of facts now play out in

797
00:38:13,079 --> 00:38:16,769
other circumstances is something that

798
00:38:16,769 --> 00:38:19,440
needs to be determined over time I do

799
00:38:19,440 --> 00:38:21,089
think one of the big questions will be

800
00:38:21,089 --> 00:38:23,579
the territorial reach and I think that

801
00:38:23,579 --> 00:38:26,249
there are some serious things to think

802
00:38:26,249 --> 00:38:28,499
about in terms of whether the European

803
00:38:28,499 --> 00:38:30,719
decision should have worldwide effect or

804
00:38:30,719 --> 00:38:34,309
not I think that could raise some

805
00:38:34,309 --> 00:38:37,280
potential concerns real real concerns

806
00:38:37,280 --> 00:38:39,080
the United States but in the meantime I

807
00:38:39,080 --> 00:38:41,360
think we need to play out we need to see

808
00:38:41,360 --> 00:38:43,990
how this plays out just as we would any

809
00:38:43,990 --> 00:38:46,250
Supreme Court decision under the Fourth

810
00:38:46,250 --> 00:38:48,890
Amendment I was afraid the Commission

811
00:38:48,890 --> 00:38:50,600
was gonna prove me wrong and she didn't

812
00:38:50,600 --> 00:38:52,510
disappoint me she did prove me wrong sir

813
00:38:52,510 --> 00:38:55,880
well not entirely not entirely um we

814
00:38:55,880 --> 00:38:57,950
have exactly four and a half minutes

815
00:38:57,950 --> 00:39:00,200
left to tackle an enormous subject

816
00:39:00,200 --> 00:39:02,000
called to international data transfers

817
00:39:02,000 --> 00:39:05,690
it's so I'll start to speak very very

818
00:39:05,690 --> 00:39:10,250
fast it's it's the subject where I think

819
00:39:10,250 --> 00:39:14,110
in a most visible way there is an honest

820
00:39:14,110 --> 00:39:17,780
attempt by various countries various

821
00:39:17,780 --> 00:39:20,000
continents to try to come to global

822
00:39:20,000 --> 00:39:26,120
solutions vcrs CVP ours the apac regime

823
00:39:26,120 --> 00:39:29,450
the referential magnificent step forward

824
00:39:29,450 --> 00:39:32,810
if you ask me a matter fact is where are

825
00:39:32,810 --> 00:39:35,390
we on this no I think I agree it's a

826
00:39:35,390 --> 00:39:38,420
magnificent step two great two different

827
00:39:38,420 --> 00:39:41,750
legal systems in a very operational way

828
00:39:41,750 --> 00:39:45,860
and so the idea is to now once we have

829
00:39:45,860 --> 00:39:50,000
elaborated the referential is to test if

830
00:39:50,000 --> 00:39:55,360
it works so a working group has been

831
00:39:55,360 --> 00:40:00,260
created and we have champions three

832
00:40:00,260 --> 00:40:04,220
companies that have accepted to test the

833
00:40:04,220 --> 00:40:08,150
referential two of them are already bc

834
00:40:08,150 --> 00:40:11,210
your compliance and one is not to our

835
00:40:11,210 --> 00:40:13,610
CBP are compliant and one is bc are

836
00:40:13,610 --> 00:40:16,970
compliant and they are going to commit

837
00:40:16,970 --> 00:40:21,980
to the other certification so we're

838
00:40:21,980 --> 00:40:24,950
going to see how it works we're going to

839
00:40:24,950 --> 00:40:30,140
have case studies i guess and we will

840
00:40:30,140 --> 00:40:35,060
see what we can do beyond and what we

841
00:40:35,060 --> 00:40:37,910
can do beyond is to provide the

842
00:40:37,910 --> 00:40:41,810
companies with a comment certification

843
00:40:41,810 --> 00:40:46,240
and how do you how do you call that

844
00:40:46,240 --> 00:40:50,299
leaflet or you with practical tools it's

845
00:40:50,299 --> 00:40:53,180
a bit probably too early now to see if

846
00:40:53,180 --> 00:40:55,880
it's possible really to from the referee

847
00:40:55,880 --> 00:40:58,700
referential to provide the international

848
00:40:58,700 --> 00:41:00,950
companies with practical tools but it's

849
00:41:00,950 --> 00:41:03,740
exactly what we are aiming at doing with

850
00:41:03,740 --> 00:41:06,890
our champions were three champions

851
00:41:06,890 --> 00:41:09,740
wonderful this will be of great interest

852
00:41:09,740 --> 00:41:12,440
to the company's Commissioner Brill the

853
00:41:12,440 --> 00:41:14,000
safe harbor I couldn't close this

854
00:41:14,000 --> 00:41:16,730
without mentioning a safe harbor are we

855
00:41:16,730 --> 00:41:19,069
on the same line or is this the east in

856
00:41:19,069 --> 00:41:20,530
the West End additional never meet to me

857
00:41:20,530 --> 00:41:23,690
you have the last word on this I am

858
00:41:23,690 --> 00:41:28,190
deeply hopeful that we will come to an

859
00:41:28,190 --> 00:41:31,940
appropriate conclusion to the safe

860
00:41:31,940 --> 00:41:36,950
harbor discussions look I understand

861
00:41:36,950 --> 00:41:39,200
that in Europe the safe harbor has been

862
00:41:39,200 --> 00:41:41,000
of deep concern since the Snowden

863
00:41:41,000 --> 00:41:44,180
revelations and since many people are

864
00:41:44,180 --> 00:41:47,150
thinking about not only how government

865
00:41:47,150 --> 00:41:48,589
is using data but also the role of

866
00:41:48,589 --> 00:41:51,680
commercial entities in terms of the

867
00:41:51,680 --> 00:41:54,349
transfer of data and I have said very

868
00:41:54,349 --> 00:41:57,829
clearly in here in Brussels and

869
00:41:57,829 --> 00:41:59,930
elsewhere that I think safe harbor is a

870
00:41:59,930 --> 00:42:03,470
deeply important tool for consumer

871
00:42:03,470 --> 00:42:06,200
protection and privacy it is the hook

872
00:42:06,200 --> 00:42:09,740
that people like me and other folks who

873
00:42:09,740 --> 00:42:14,540
are focused on protecting US citizens

874
00:42:14,540 --> 00:42:17,599
privacy as well as Europeans privacy it

875
00:42:17,599 --> 00:42:20,599
is the hook that we have to to offer

876
00:42:20,599 --> 00:42:23,900
greater protection so I have said please

877
00:42:23,900 --> 00:42:25,460
don't take it away from me as a law

878
00:42:25,460 --> 00:42:27,230
enforcement official I do not want any

879
00:42:27,230 --> 00:42:30,020
tools taken away now having said that

880
00:42:30,020 --> 00:42:34,190
safe harbor is 15 years old and like any

881
00:42:34,190 --> 00:42:38,799
tool it can be re-examined and

882
00:42:38,799 --> 00:42:42,500
inappropriate ways improved and so we

883
00:42:42,500 --> 00:42:44,480
have been working with our colleagues at

884
00:42:44,480 --> 00:42:46,339
the Commerce Department which is the

885
00:42:46,339 --> 00:42:48,530
entity that administers the program we

886
00:42:48,530 --> 00:42:51,319
are the backstop enforcement entity but

887
00:42:51,319 --> 00:42:53,510
the Commerce Department administers it

888
00:42:53,510 --> 00:42:55,309
the Commerce Department is leading the

889
00:42:55,309 --> 00:42:57,960
discussions with a DG justice

890
00:42:57,960 --> 00:42:59,790
to others in the Commission over how

891
00:42:59,790 --> 00:43:02,040
safe harbor can be improved and we've

892
00:43:02,040 --> 00:43:04,109
been working very closely with everyone

893
00:43:04,109 --> 00:43:06,690
to give our views in terms of how safe

894
00:43:06,690 --> 00:43:09,060
harbor can be improved look the

895
00:43:09,060 --> 00:43:10,830
alternative dispute resolution fees i

896
00:43:10,830 --> 00:43:12,450
think is something that clearly needs to

897
00:43:12,450 --> 00:43:14,480
be addressed increased transparency

898
00:43:14,480 --> 00:43:17,670
around who's in safe harbor who's out of

899
00:43:17,670 --> 00:43:21,089
safe harbor who's it clearly can be

900
00:43:21,089 --> 00:43:24,420
improved increased accountability on the

901
00:43:24,420 --> 00:43:27,300
part of ensuring that those who are part

902
00:43:27,300 --> 00:43:29,880
of safe harbor are complying with its

903
00:43:29,880 --> 00:43:32,339
principles absolutely can be improved

904
00:43:32,339 --> 00:43:34,859
but please don't take it away because I

905
00:43:34,859 --> 00:43:38,580
will and my agency will enforce it and I

906
00:43:38,580 --> 00:43:40,140
think we've put our money where our

907
00:43:40,140 --> 00:43:43,170
mouth is just this week we announced a

908
00:43:43,170 --> 00:43:46,859
very important settlement involving an

909
00:43:46,859 --> 00:43:50,720
entity trustee that is it did not

910
00:43:50,720 --> 00:43:55,710
involve it's safe harbor compliance but

911
00:43:55,710 --> 00:43:58,170
rather trustee is a very important part

912
00:43:58,170 --> 00:44:01,200
of the entire self regulatory program

913
00:44:01,200 --> 00:44:03,869
with a bit concerned safe harbor trustee

914
00:44:03,869 --> 00:44:05,400
also has an incredibly important role

915
00:44:05,400 --> 00:44:08,640
with respect to children's privacy they

916
00:44:08,640 --> 00:44:11,310
also provide a seal and safe harbor

917
00:44:11,310 --> 00:44:14,339
program with respect to kapa children's

918
00:44:14,339 --> 00:44:16,880
online privacy protection act so we just

919
00:44:16,880 --> 00:44:19,410
announced a settlement involving trustee

920
00:44:19,410 --> 00:44:22,380
because we found that in a minority of

921
00:44:22,380 --> 00:44:27,150
large minority of cases that is a small

922
00:44:27,150 --> 00:44:28,940
I should say a small minority of cases

923
00:44:28,940 --> 00:44:32,880
they were not actually appropriately

924
00:44:32,880 --> 00:44:35,160
recertifying the company the entities

925
00:44:35,160 --> 00:44:36,960
that's what we alleged there was a

926
00:44:36,960 --> 00:44:39,180
settlement we now have trustee under a

927
00:44:39,180 --> 00:44:41,820
20-year order that's going to require

928
00:44:41,820 --> 00:44:44,250
additional reporting requirements if

929
00:44:44,250 --> 00:44:47,220
that order is violated their rule and we

930
00:44:47,220 --> 00:44:49,650
and we prove a violation there could be

931
00:44:49,650 --> 00:44:51,839
very significant penalties that that

932
00:44:51,839 --> 00:44:55,770
will inure to or in your against trustee

933
00:44:55,770 --> 00:44:58,020
but it isn't just the trustee case we

934
00:44:58,020 --> 00:44:59,970
have brought now about 25 cases

935
00:44:59,970 --> 00:45:02,520
involving safe harbor violations

936
00:45:02,520 --> 00:45:05,250
including elements of the Google and

937
00:45:05,250 --> 00:45:08,390
Facebook settlement so now any

938
00:45:08,390 --> 00:45:11,059
case that we examine in the United

939
00:45:11,059 --> 00:45:13,670
States with respect to privacy or data

940
00:45:13,670 --> 00:45:16,339
security we look at whether or not there

941
00:45:16,339 --> 00:45:18,740
is a potential safe harbor violation so

942
00:45:18,740 --> 00:45:21,349
it's something that we at the FTC FTC

943
00:45:21,349 --> 00:45:25,069
take tremendously seriously what is the

944
00:45:25,069 --> 00:45:28,579
trustee settlement mean I really hope

945
00:45:28,579 --> 00:45:30,680
that everyone here and everyone in

946
00:45:30,680 --> 00:45:33,890
Europe will take away the message not

947
00:45:33,890 --> 00:45:36,920
that safe harbor is broken therefore we

948
00:45:36,920 --> 00:45:39,109
had to bring the trustee case but rather

949
00:45:39,109 --> 00:45:42,640
that safe harbor works and backstop

950
00:45:42,640 --> 00:45:46,970
enforcement by the FTC works because

951
00:45:46,970 --> 00:45:48,740
what we will do look it doesn't happen

952
00:45:48,740 --> 00:45:50,809
immediately there are all sorts of due

953
00:45:50,809 --> 00:45:52,760
process rights in our justice system in

954
00:45:52,760 --> 00:45:54,470
the United States so sometimes these

955
00:45:54,470 --> 00:45:56,839
cases are slower than people would like

956
00:45:56,839 --> 00:45:59,720
but we will take these cases seriously

957
00:45:59,720 --> 00:46:02,089
and in appropriate circumstances we will

958
00:46:02,089 --> 00:46:04,849
bring an enforcement action even against

959
00:46:04,849 --> 00:46:07,730
entities whether it's Facebook or Google

960
00:46:07,730 --> 00:46:09,740
or whether it's in a key player like

961
00:46:09,740 --> 00:46:11,750
trustee we will in appropriate

962
00:46:11,750 --> 00:46:13,700
circumstances bring enforcement actions

963
00:46:13,700 --> 00:46:16,190
and I think that shows that the system

964
00:46:16,190 --> 00:46:19,160
works thank you very much ladies you

965
00:46:19,160 --> 00:46:21,670
were wonderful

966
00:46:29,250 --> 00:46:33,930
one post applause remark I just wanted

967
00:46:33,930 --> 00:46:36,990
to see a few comments on the safe harbor

968
00:46:36,990 --> 00:46:39,330
because you imagine of course you I get

969
00:46:39,330 --> 00:46:42,510
rebuttal time the last question was the

970
00:46:42,510 --> 00:46:46,980
most delicate firm now we don't only

971
00:46:46,980 --> 00:46:51,390
want improvement of the safe harbor we

972
00:46:51,390 --> 00:46:55,770
want clear answers to the situation that

973
00:46:55,770 --> 00:46:57,930
has been created by the Snowden

974
00:46:57,930 --> 00:47:02,070
revelation so the Commission has made 13

975
00:47:02,070 --> 00:47:04,920
proposition on these Thirteen's

976
00:47:04,920 --> 00:47:07,920
proposition and specifically the 13th

977
00:47:07,920 --> 00:47:11,940
one the DPA the European authorities

978
00:47:11,940 --> 00:47:17,580
they are expecting real answers so it's

979
00:47:17,580 --> 00:47:19,560
not a technical issue you know that has

980
00:47:19,560 --> 00:47:23,760
to be improved year by year it's there

981
00:47:23,760 --> 00:47:26,430
has been a kind of confident crisis

982
00:47:26,430 --> 00:47:29,280
within Europe after the Snowden

983
00:47:29,280 --> 00:47:33,510
revelation the safe harbor is one of the

984
00:47:33,510 --> 00:47:36,540
most important compliance to between the

985
00:47:36,540 --> 00:47:39,990
two continents so we need now to adopt

986
00:47:39,990 --> 00:47:45,180
these tools who the new situation so we

987
00:47:45,180 --> 00:47:50,360
will be very vigilant on the output and

988
00:47:50,360 --> 00:47:56,580
so I get a tiny rebuttal but I there

989
00:47:56,580 --> 00:47:58,910
were the Commission for forward 13

990
00:47:58,910 --> 00:48:03,540
demands requests suggestions 11 of them

991
00:48:03,540 --> 00:48:07,680
dealt with were in in my sphere and in

992
00:48:07,680 --> 00:48:09,300
within the sphere of the Commerce

993
00:48:09,300 --> 00:48:12,180
Department dealt with safe harbor as a

994
00:48:12,180 --> 00:48:14,280
sort of an administrative tool and in

995
00:48:14,280 --> 00:48:16,980
the enforcement tool and I was you know

996
00:48:16,980 --> 00:48:19,580
we are deeply involved in in those 11

997
00:48:19,580 --> 00:48:21,630
Isabelle's absolutely right there are

998
00:48:21,630 --> 00:48:23,970
two recommendations that are outside of

999
00:48:23,970 --> 00:48:27,060
my Riemann and frankly I think actually

1000
00:48:27,060 --> 00:48:29,040
outside of your remit and frankly

1001
00:48:29,040 --> 00:48:32,490
outside of DG justices remit rip as it

1002
00:48:32,490 --> 00:48:35,760
you know it in a box but I understand

1003
00:48:35,760 --> 00:48:37,170
there's deep concern about these issues

1004
00:48:37,170 --> 00:48:39,510
I think that there has been a tremendous

1005
00:48:39,510 --> 00:48:41,920
effort on the part of

1006
00:48:41,920 --> 00:48:44,020
the national security folks in the

1007
00:48:44,020 --> 00:48:45,730
United States to figure out how to

1008
00:48:45,730 --> 00:48:48,910
appropriately respond but it's not what

1009
00:48:48,910 --> 00:48:53,200
I do um but I do think that what you see

1010
00:48:53,200 --> 00:48:55,599
in the United States through breathing

1011
00:48:55,599 --> 00:48:59,410
great life into the pee Club the privacy

1012
00:48:59,410 --> 00:49:00,900
and civil liberties oversight board

1013
00:49:00,900 --> 00:49:03,730
through the chief privacy officers that

1014
00:49:03,730 --> 00:49:07,260
we have throughout the national security

1015
00:49:07,260 --> 00:49:09,700
system and through all sorts of

1016
00:49:09,700 --> 00:49:11,619
mechanisms that we are starting to

1017
00:49:11,619 --> 00:49:13,930
reexamine whether it's the FISA Court

1018
00:49:13,930 --> 00:49:15,910
and various bills that are being

1019
00:49:15,910 --> 00:49:18,160
examined and whatnot I think there is a

1020
00:49:18,160 --> 00:49:20,589
deep discussion in the United States not

1021
00:49:20,589 --> 00:49:22,329
only about how to deal with Europeans

1022
00:49:22,329 --> 00:49:23,530
concerns but frankly how to deal with

1023
00:49:23,530 --> 00:49:26,530
concerns of US citizens this is a

1024
00:49:26,530 --> 00:49:28,420
discussion that's deeply important and

1025
00:49:28,420 --> 00:49:31,720
will continue so I understand what

1026
00:49:31,720 --> 00:49:34,150
Isabelle saying I understand the linkage

1027
00:49:34,150 --> 00:49:35,890
that has been made but that is a

1028
00:49:35,890 --> 00:49:41,170
conversation that I can watch but I I'm

1029
00:49:41,170 --> 00:49:44,319
not competent to engage and I think the

1030
00:49:44,319 --> 00:49:47,500
competent folks the security folks need

1031
00:49:47,500 --> 00:49:49,799
to be a deep part of that conversation

1032
00:49:49,799 --> 00:49:53,160
thank you very much

