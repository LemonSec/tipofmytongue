1
00:00:06,440 --> 00:00:09,330
okay thanks very much Simon I had less

2
00:00:09,330 --> 00:00:13,590
gray hair in that photo to be honest I'm

3
00:00:13,590 --> 00:00:14,730
going to be loved I'm going to level

4
00:00:14,730 --> 00:00:17,460
with you I had actually planned to do a

5
00:00:17,460 --> 00:00:20,190
standard presentation on personal data

6
00:00:20,190 --> 00:00:23,369
privacy but actually the next 30 minutes

7
00:00:23,369 --> 00:00:26,070
is going to be more of a rant and

8
00:00:26,070 --> 00:00:27,359
actually it's going to be a rant for a

9
00:00:27,359 --> 00:00:29,189
number of reasons first of all because I

10
00:00:29,189 --> 00:00:31,769
just got back from San Francisco for the

11
00:00:31,769 --> 00:00:34,650
RSA conference and this was a conference

12
00:00:34,650 --> 00:00:36,480
of security and privacy professionals

13
00:00:36,480 --> 00:00:40,170
this was I think they called it the the

14
00:00:40,170 --> 00:00:41,910
super bowl of the security and privacy

15
00:00:41,910 --> 00:00:45,000
industry I actually saw a number of

16
00:00:45,000 --> 00:00:46,290
things about the way that our

17
00:00:46,290 --> 00:00:47,640
professionals are managing their data

18
00:00:47,640 --> 00:00:51,440
which actually worried me considerably

19
00:00:51,440 --> 00:00:53,460
but equally we're going to talk about

20
00:00:53,460 --> 00:00:56,370
the advent of IOT as well because I

21
00:00:56,370 --> 00:00:57,750
think you know one of the things that

22
00:00:57,750 --> 00:00:59,340
people don't realize is that all of

23
00:00:59,340 --> 00:01:01,200
these wonderful devices that we have in

24
00:01:01,200 --> 00:01:03,690
our home our tracking everything that we

25
00:01:03,690 --> 00:01:08,900
do and selling that data on to who knows

26
00:01:08,900 --> 00:01:12,510
so when we get started it always makes

27
00:01:12,510 --> 00:01:14,700
me laugh whenever I put this quote up

28
00:01:14,700 --> 00:01:16,410
because everybody here knows this quote

29
00:01:16,410 --> 00:01:19,920
in fact we know that personal data has

30
00:01:19,920 --> 00:01:22,260
economic value we've known about it for

31
00:01:22,260 --> 00:01:25,320
about 15 years I think and yet when you

32
00:01:25,320 --> 00:01:27,180
go and talk to people outside they have

33
00:01:27,180 --> 00:01:29,640
absolutely no idea that data has

34
00:01:29,640 --> 00:01:32,940
economic value I always ask this

35
00:01:32,940 --> 00:01:34,950
question and I say was anybody surprised

36
00:01:34,950 --> 00:01:36,690
at the price that whatsapp were required

37
00:01:36,690 --> 00:01:38,760
by Facebook only remembers how much they

38
00:01:38,760 --> 00:01:42,450
were bought for 19 billion dollars only

39
00:01:42,450 --> 00:01:46,350
by the way anybody surprised at that

40
00:01:46,350 --> 00:01:51,870
number one or two so I actually actually

41
00:01:51,870 --> 00:01:55,409
soon after they've got acquired i did a

42
00:01:55,409 --> 00:01:57,510
news program with CNBC and you know they

43
00:01:57,510 --> 00:01:59,190
asked me and they said well that's a lot

44
00:01:59,190 --> 00:02:00,540
of money for a company that really

45
00:02:00,540 --> 00:02:02,909
hasn't made a profit and i said well do

46
00:02:02,909 --> 00:02:04,619
you really think it's worth that much

47
00:02:04,619 --> 00:02:05,880
money and i said well i think it is

48
00:02:05,880 --> 00:02:08,699
because if you consider it whatsapp were

49
00:02:08,699 --> 00:02:10,619
required for the equivalent of 42

50
00:02:10,619 --> 00:02:15,029
dollars per record now if you reverse

51
00:02:15,029 --> 00:02:16,799
Instagram were required for thirty

52
00:02:16,799 --> 00:02:18,330
dollars per user

53
00:02:18,330 --> 00:02:20,040
and youtuber required for approximately

54
00:02:20,040 --> 00:02:22,440
twenty dollars per user in other words

55
00:02:22,440 --> 00:02:24,780
what that means is the actual value of

56
00:02:24,780 --> 00:02:29,460
personal data is increasing so our

57
00:02:29,460 --> 00:02:31,680
digital footprint is an incredibly

58
00:02:31,680 --> 00:02:34,170
valuable commodity and organizations

59
00:02:34,170 --> 00:02:35,790
across the world recognize that

60
00:02:35,790 --> 00:02:38,340
commodity now that second point that

61
00:02:38,340 --> 00:02:40,140
consumers and governments are looking

62
00:02:40,140 --> 00:02:41,970
for change it's slightly tongue-in-cheek

63
00:02:41,970 --> 00:02:46,350
I have absolutely no idea consumers are

64
00:02:46,350 --> 00:02:49,110
completely blind and entirely oblivious

65
00:02:49,110 --> 00:02:52,050
to this market economy in which there

66
00:02:52,050 --> 00:02:54,630
personally identifiable data is making

67
00:02:54,630 --> 00:02:57,060
billionaires of people all across the

68
00:02:57,060 --> 00:03:01,320
world they have absolutely no idea but I

69
00:03:01,320 --> 00:03:03,300
think there is a huge opportunity and

70
00:03:03,300 --> 00:03:05,700
that really is i guess the purpose of

71
00:03:05,700 --> 00:03:09,750
this talk is for us as an industry to be

72
00:03:09,750 --> 00:03:12,180
able to introduce ethical practices now

73
00:03:12,180 --> 00:03:13,920
i'm not talking about regulatory

74
00:03:13,920 --> 00:03:16,320
compliance this is not about regulatory

75
00:03:16,320 --> 00:03:18,660
compliance this is about the ethical use

76
00:03:18,660 --> 00:03:21,300
of data giving users the ability to be

77
00:03:21,300 --> 00:03:23,130
able to control and have transparency

78
00:03:23,130 --> 00:03:25,350
over their data and actually get real

79
00:03:25,350 --> 00:03:27,570
market return for their personally

80
00:03:27,570 --> 00:03:30,330
identifiable information that i think is

81
00:03:30,330 --> 00:03:33,450
the opportunity that we face so I was

82
00:03:33,450 --> 00:03:34,739
going to stand up and I was going to

83
00:03:34,739 --> 00:03:37,260
talk to you about a couple of blogs and

84
00:03:37,260 --> 00:03:39,090
a couple of stories that I've actually

85
00:03:39,090 --> 00:03:41,760
witnessed around this concept of the

86
00:03:41,760 --> 00:03:45,300
perceived value of personal data in

87
00:03:45,300 --> 00:03:48,030
order to do that I was going to share

88
00:03:48,030 --> 00:03:51,450
with you a recent story that I wrote in

89
00:03:51,450 --> 00:03:54,360
The Telegraph so of course i went to the

90
00:03:54,360 --> 00:03:57,930
Telegraph website and i found the story

91
00:03:57,930 --> 00:04:00,630
and of course as you can tell i'm

92
00:04:00,630 --> 00:04:06,750
looking to buy a car I didn't ask for

93
00:04:06,750 --> 00:04:09,060
that I didn't tell the Telegraph I

94
00:04:09,060 --> 00:04:11,850
didn't tell anybody that it's okay for

95
00:04:11,850 --> 00:04:14,730
you to keep trying to sell me stuff that

96
00:04:14,730 --> 00:04:20,070
I don't need but there it is and I think

97
00:04:20,070 --> 00:04:23,010
that's a really good example because I

98
00:04:23,010 --> 00:04:26,040
actually provided consent for somebody

99
00:04:26,040 --> 00:04:29,780
to be able to track my web history in

100
00:04:29,780 --> 00:04:33,200
fact all of you provide

101
00:04:33,200 --> 00:04:36,390
you provide explicit consent I mean if

102
00:04:36,390 --> 00:04:38,040
you remember years ago everybody got

103
00:04:38,040 --> 00:04:40,590
upset because the NHS was using the

104
00:04:40,590 --> 00:04:42,870
concept of implicit consent we know

105
00:04:42,870 --> 00:04:44,700
what's best for you and everyone said

106
00:04:44,700 --> 00:04:46,620
well how dare a doctor even consider

107
00:04:46,620 --> 00:04:47,850
they they know what's best for my

108
00:04:47,850 --> 00:04:51,090
medical history now I want explicit

109
00:04:51,090 --> 00:04:52,620
consent so now you've got it

110
00:04:52,620 --> 00:04:57,120
congratulations it's on about page 27 of

111
00:04:57,120 --> 00:04:59,310
the terms of service every time that you

112
00:04:59,310 --> 00:05:04,050
sign up for any digital service at some

113
00:05:04,050 --> 00:05:05,430
conferences I talked about a south park

114
00:05:05,430 --> 00:05:07,170
episode for those of you that have seen

115
00:05:07,170 --> 00:05:11,730
it will know what I'm talking about we

116
00:05:11,730 --> 00:05:13,590
need to move away from this concept that

117
00:05:13,590 --> 00:05:15,330
we are actually providing people consent

118
00:05:15,330 --> 00:05:17,370
because we simply aren't as an industry

119
00:05:17,370 --> 00:05:19,560
as a society we aren't providing people

120
00:05:19,560 --> 00:05:23,010
consent putting it on page 27 28 / Terms

121
00:05:23,010 --> 00:05:24,930
of Service and expecting people to read

122
00:05:24,930 --> 00:05:27,120
it and understand it is just

123
00:05:27,120 --> 00:05:30,090
preposterous does everybody remember the

124
00:05:30,090 --> 00:05:32,010
company vtech that were recently

125
00:05:32,010 --> 00:05:33,900
compromised remember everybody remember

126
00:05:33,900 --> 00:05:37,280
this now here was a company who provide

127
00:05:37,280 --> 00:05:41,220
electronic toys for children now sadly

128
00:05:41,220 --> 00:05:43,980
they actually got compromised and all of

129
00:05:43,980 --> 00:05:45,540
the information that children had and

130
00:05:45,540 --> 00:05:48,300
provided all of their content was made

131
00:05:48,300 --> 00:05:50,970
accessible to criminals that's pretty

132
00:05:50,970 --> 00:05:54,630
bad right so what do you think vtec did

133
00:05:54,630 --> 00:05:57,510
I mean of course they did the

134
00:05:57,510 --> 00:05:58,800
investigation they work with law

135
00:05:58,800 --> 00:06:00,600
enforcement but what do you think their

136
00:06:00,600 --> 00:06:04,470
response was anybody that has a chance

137
00:06:04,470 --> 00:06:06,030
and actually I tweeted this not so long

138
00:06:06,030 --> 00:06:09,600
ago they edited their privacy policy and

139
00:06:09,600 --> 00:06:13,620
in the privacy policy they stated by

140
00:06:13,620 --> 00:06:16,500
accepting these terms of service you

141
00:06:16,500 --> 00:06:18,660
accept that your information may be

142
00:06:18,660 --> 00:06:22,910
accessed by unauthorized third parties

143
00:06:23,300 --> 00:06:27,750
that's hilarious right they wanted to

144
00:06:27,750 --> 00:06:29,640
absolve themselves of the liability of a

145
00:06:29,640 --> 00:06:33,240
protecting your information and so we

146
00:06:33,240 --> 00:06:34,800
had a really long debate and I would

147
00:06:34,800 --> 00:06:36,030
encourage all of you to have this

148
00:06:36,030 --> 00:06:37,860
discussion afterwards because the

149
00:06:37,860 --> 00:06:40,290
question becomes well under principle

150
00:06:40,290 --> 00:06:41,610
seven of the Data Protection Act they

151
00:06:41,610 --> 00:06:44,490
can't do that but they're a global

152
00:06:44,490 --> 00:06:47,010
company so how is that enforceable if

153
00:06:47,010 --> 00:06:49,440
they don't have any assets in the UK how

154
00:06:49,440 --> 00:06:50,760
is that going to be enforceable in fact

155
00:06:50,760 --> 00:06:53,250
the ICO came out and said you can't do

156
00:06:53,250 --> 00:06:58,410
that that's unacceptable but regardless

157
00:06:58,410 --> 00:07:01,230
of the fact whether it's legal or

158
00:07:01,230 --> 00:07:04,320
compliant or not I went and gave a talk

159
00:07:04,320 --> 00:07:05,760
at a local school and there were parents

160
00:07:05,760 --> 00:07:07,290
there and I was talking to them at that

161
00:07:07,290 --> 00:07:10,860
about the vtec case I asked him the

162
00:07:10,860 --> 00:07:12,450
question said does anybody know or

163
00:07:12,450 --> 00:07:14,160
didn't anybody by v tech toys in the

164
00:07:14,160 --> 00:07:16,290
last three months and hands went up and

165
00:07:16,290 --> 00:07:18,240
I asked him the question and I said well

166
00:07:18,240 --> 00:07:20,550
are you aware of this particular policy

167
00:07:20,550 --> 00:07:22,290
change are you aware that this is a

168
00:07:22,290 --> 00:07:24,720
company that is actually given away

169
00:07:24,720 --> 00:07:28,590
information to criminals information

170
00:07:28,590 --> 00:07:31,260
about your children and not one hand

171
00:07:31,260 --> 00:07:33,680
went up they were completely unaware

172
00:07:33,680 --> 00:07:36,540
entirely oblivious that this is the

173
00:07:36,540 --> 00:07:38,010
world that we live in that they've

174
00:07:38,010 --> 00:07:39,840
actually bought equipment in which

175
00:07:39,840 --> 00:07:43,050
they've authorized or allowed potential

176
00:07:43,050 --> 00:07:44,520
hackers to basically steal information

177
00:07:44,520 --> 00:07:47,910
and they are then held responsible and

178
00:07:47,910 --> 00:07:54,180
they had no idea of this so if we move

179
00:07:54,180 --> 00:07:57,060
forward you know I think this concept of

180
00:07:57,060 --> 00:08:00,630
oil in the in a row what is it personal

181
00:08:00,630 --> 00:08:03,750
data being in the new oil I think we in

182
00:08:03,750 --> 00:08:05,040
reality what we're seeing is we're

183
00:08:05,040 --> 00:08:07,650
seeing two types of business models you

184
00:08:07,650 --> 00:08:09,480
know and and I've actually seen some of

185
00:08:09,480 --> 00:08:11,010
that with regard to targeted marketing

186
00:08:11,010 --> 00:08:13,310
but service personalization as well and

187
00:08:13,310 --> 00:08:15,480
generally speaking I think this market

188
00:08:15,480 --> 00:08:17,460
somewhere in the region of between 50 to

189
00:08:17,460 --> 00:08:19,860
70 billion dollars per annum I mean

190
00:08:19,860 --> 00:08:21,990
that's roughly what it's worth which is

191
00:08:21,990 --> 00:08:26,700
pretty impressive but we actually did a

192
00:08:26,700 --> 00:08:28,800
study and we asked consumers we said

193
00:08:28,800 --> 00:08:30,780
well what what is your perception of

194
00:08:30,780 --> 00:08:32,429
personal data what do you actually want

195
00:08:32,429 --> 00:08:34,710
and they came back with a number of

196
00:08:34,710 --> 00:08:35,830
things first of all they were

197
00:08:35,830 --> 00:08:39,070
control they want to have a say over who

198
00:08:39,070 --> 00:08:41,260
has access to their data and for me this

199
00:08:41,260 --> 00:08:42,820
kind of comes back down to this concept

200
00:08:42,820 --> 00:08:44,920
of consent again it's not about implicit

201
00:08:44,920 --> 00:08:46,960
or explicit consent to me it's about

202
00:08:46,960 --> 00:08:49,330
informed consent it's about actually

203
00:08:49,330 --> 00:08:50,560
telling me what you're going to do with

204
00:08:50,560 --> 00:08:51,880
this and saying are you okay with this

205
00:08:51,880 --> 00:08:54,490
and me saying yeah okay I am or actually

206
00:08:54,490 --> 00:09:01,300
no I'm not it reminds me that when I

207
00:09:01,300 --> 00:09:03,370
went actually we went to go and see

208
00:09:03,370 --> 00:09:05,470
despicable me 2 at a local cinema it's a

209
00:09:05,470 --> 00:09:08,740
dreadful film by the way but my

210
00:09:08,740 --> 00:09:11,500
four-year-old loved it and we were there

211
00:09:11,500 --> 00:09:16,120
and i think i spent about 30 pounds to

212
00:09:16,120 --> 00:09:18,280
go i think was a rock five tickets was

213
00:09:18,280 --> 00:09:20,170
two adults and three children which is

214
00:09:20,170 --> 00:09:22,120
extortionate now by the way I have just

215
00:09:22,120 --> 00:09:23,560
had to say cinema tickets are just

216
00:09:23,560 --> 00:09:26,170
expensive as anything but at the time we

217
00:09:26,170 --> 00:09:28,060
bought these tickets of about 30 pounds

218
00:09:28,060 --> 00:09:30,700
and you know the patellar behind her you

219
00:09:30,700 --> 00:09:31,990
know the cash register she said to me

220
00:09:31,990 --> 00:09:34,390
well do you want to join our loyalty

221
00:09:34,390 --> 00:09:37,840
card program and I went you know what

222
00:09:37,840 --> 00:09:40,000
what do i get if i spend 30 pounds above

223
00:09:40,000 --> 00:09:41,290
all you'll get a free you'll get a free

224
00:09:41,290 --> 00:09:42,640
cinema ticket next time you're here and

225
00:09:42,640 --> 00:09:43,810
I said well actually that's probably

226
00:09:43,810 --> 00:09:46,660
worth it I'm happy to trade my personal

227
00:09:46,660 --> 00:09:50,020
data for this and so I said okay fine

228
00:09:50,020 --> 00:09:52,000
I'll join join your loyalty program and

229
00:09:52,000 --> 00:09:53,680
she said oh that's going to be another

230
00:09:53,680 --> 00:09:58,450
15 pounds please I was like sorry you

231
00:09:58,450 --> 00:10:01,180
want me to pay you twice now at this

232
00:10:01,180 --> 00:10:02,860
point my wife gets embarrassed because I

233
00:10:02,860 --> 00:10:04,990
do this a lot I'm sure all of you do

234
00:10:04,990 --> 00:10:07,540
that as well you always ask questions or

235
00:10:07,540 --> 00:10:09,280
actually when you're at a restaurant and

236
00:10:09,280 --> 00:10:10,600
someone takes away your credit card

237
00:10:10,600 --> 00:10:12,280
you're like no no come back come back

238
00:10:12,280 --> 00:10:14,560
and bring the machine here that I'm that

239
00:10:14,560 --> 00:10:16,120
kind of guy I'm the kind of guy that

240
00:10:16,120 --> 00:10:17,950
watches like movies about cybersecurity

241
00:10:17,950 --> 00:10:19,690
and says perhaps nonsense that will

242
00:10:19,690 --> 00:10:23,620
never happen and I started to let's just

243
00:10:23,620 --> 00:10:25,750
say have a a debate with this young girl

244
00:10:25,750 --> 00:10:27,880
and I felt really bad for her because I

245
00:10:27,880 --> 00:10:29,740
said well you want me to be you want me

246
00:10:29,740 --> 00:10:31,750
to pay twice I said well this is

247
00:10:31,750 --> 00:10:33,010
ridiculous is that I'm paying you with

248
00:10:33,010 --> 00:10:34,360
my personal data and she didn't

249
00:10:34,360 --> 00:10:37,000
understand the concept and I said well

250
00:10:37,000 --> 00:10:39,840
am I the only person that's ever

251
00:10:39,840 --> 00:10:42,520
discussed this with you I hope that

252
00:10:42,520 --> 00:10:44,440
wasn't the word I use and she said yeah

253
00:10:44,440 --> 00:10:46,120
she said we've got about 200,000

254
00:10:46,120 --> 00:10:48,210
customers

255
00:10:48,339 --> 00:10:49,959
and I asked her I said well what are you

256
00:10:49,959 --> 00:10:50,949
going to do with this and she had no

257
00:10:50,949 --> 00:10:53,769
idea and it reminds me of my chocolate

258
00:10:53,769 --> 00:10:56,019
story you know we were at westfield and

259
00:10:56,019 --> 00:10:57,879
Cadbury's of giving away free creamed

260
00:10:57,879 --> 00:11:00,249
eggs and the queue for people handing

261
00:11:00,249 --> 00:11:01,930
over their personal data for chocolate

262
00:11:01,930 --> 00:11:04,899
was about 50 to 60 people deep and when

263
00:11:04,899 --> 00:11:05,949
I asked them what they're going to do

264
00:11:05,949 --> 00:11:07,389
with the data I walked around the back

265
00:11:07,389 --> 00:11:09,249
there was a privacy policy it was like

266
00:11:09,249 --> 00:11:12,699
tumbleweed in cobwebs so we're not

267
00:11:12,699 --> 00:11:14,290
having this discussion we're not

268
00:11:14,290 --> 00:11:15,610
explaining to people what they're going

269
00:11:15,610 --> 00:11:17,319
to do with their data and I think in

270
00:11:17,319 --> 00:11:18,610
part because people aren't asking the

271
00:11:18,610 --> 00:11:21,100
question but that's what we need to

272
00:11:21,100 --> 00:11:22,839
start to do is get people to start

273
00:11:22,839 --> 00:11:24,999
asking the question and then we need

274
00:11:24,999 --> 00:11:26,709
transparency on the information that

275
00:11:26,709 --> 00:11:29,649
we've provided show of hands how many of

276
00:11:29,649 --> 00:11:32,559
you have a smartphone how many of you

277
00:11:32,559 --> 00:11:34,749
have apps on that smartphone every one

278
00:11:34,749 --> 00:11:38,769
of us can you tell me just one app what

279
00:11:38,769 --> 00:11:40,540
data it collects where it sends that

280
00:11:40,540 --> 00:11:42,220
data who it shows that data with who

281
00:11:42,220 --> 00:11:43,660
they sell that data with and how it

282
00:11:43,660 --> 00:11:48,610
communicates just one app can you tell

283
00:11:48,610 --> 00:11:52,149
me about all of the apps you have no and

284
00:11:52,149 --> 00:11:55,720
I'm the same by the way you are this is

285
00:11:55,720 --> 00:11:58,779
the privacy industry and yet you're

286
00:11:58,779 --> 00:12:00,759
giving away your information to app

287
00:12:00,759 --> 00:12:03,040
providers you're giving away your

288
00:12:03,040 --> 00:12:04,689
information and they're selling it on

289
00:12:04,689 --> 00:12:06,670
and you have no idea who they're selling

290
00:12:06,670 --> 00:12:10,959
it on to doesn't that worry you we have

291
00:12:10,959 --> 00:12:12,999
no transparency today and do you think

292
00:12:12,999 --> 00:12:17,439
it's going to get any better we need to

293
00:12:17,439 --> 00:12:19,300
start demanding transparency and not

294
00:12:19,300 --> 00:12:20,589
only transparency about what you're

295
00:12:20,589 --> 00:12:22,600
doing on my device but actually what

296
00:12:22,600 --> 00:12:23,889
you're going to do with my information

297
00:12:23,889 --> 00:12:26,170
if you get the opportunity and I'm sure

298
00:12:26,170 --> 00:12:28,720
many of you have seen this have a read

299
00:12:28,720 --> 00:12:30,790
up of the whatsapp investigation by the

300
00:12:30,790 --> 00:12:32,709
Canadian Data Protection Authority and

301
00:12:32,709 --> 00:12:34,120
they got on a Dutch Data Protection

302
00:12:34,120 --> 00:12:36,670
Authority have a look at what they said

303
00:12:36,670 --> 00:12:38,079
and actually have a look at what they

304
00:12:38,079 --> 00:12:41,139
did and that's just one application done

305
00:12:41,139 --> 00:12:45,220
years and years ago this to me is key

306
00:12:45,220 --> 00:12:50,019
fair value this to me is how this

307
00:12:50,019 --> 00:12:52,600
industry actually becomes a line item in

308
00:12:52,600 --> 00:12:56,410
business because I genuinely believe

309
00:12:56,410 --> 00:12:59,019
that there is real economic value in

310
00:12:59,019 --> 00:13:01,779
personally identifiable data

311
00:13:01,779 --> 00:13:03,069
and if you remember the World Economic

312
00:13:03,069 --> 00:13:05,439
Forum cited this economy to be worth a

313
00:13:05,439 --> 00:13:08,610
trillion euros by 2020 in Europe alone

314
00:13:08,610 --> 00:13:11,470
here's the really cool part two-thirds

315
00:13:11,470 --> 00:13:13,920
of that will be realized by the consumer

316
00:13:13,920 --> 00:13:17,290
so we have the ability to be able to

317
00:13:17,290 --> 00:13:19,120
allow consumers to be able to get

318
00:13:19,120 --> 00:13:20,860
monetary gain from personally

319
00:13:20,860 --> 00:13:23,920
identifiable data or their data I think

320
00:13:23,920 --> 00:13:25,930
when they can see the value in that then

321
00:13:25,930 --> 00:13:27,160
they will start to take protective

322
00:13:27,160 --> 00:13:30,910
mechanisms in place trying to use fear

323
00:13:30,910 --> 00:13:33,069
uncertainty and doubt to get people to

324
00:13:33,069 --> 00:13:38,740
change their behavior doesn't work trust

325
00:13:38,740 --> 00:13:41,470
and I like this piece they said don't be

326
00:13:41,470 --> 00:13:44,889
creepy and the concept of don't be

327
00:13:44,889 --> 00:13:46,410
creepy we're seeing this all of the time

328
00:13:46,410 --> 00:13:48,519
you know every time you do a web

329
00:13:48,519 --> 00:13:50,199
transaction every time you're out and

330
00:13:50,199 --> 00:13:53,410
about you get targeted messages you get

331
00:13:53,410 --> 00:13:55,209
people trying to sell you stuff and I

332
00:13:55,209 --> 00:13:58,180
didn't ask for this I didn't ask for

333
00:13:58,180 --> 00:13:59,559
someone trying to sell me in this an

334
00:13:59,559 --> 00:14:02,649
when I was doing research that to me is

335
00:14:02,649 --> 00:14:04,600
creepy and I remember I gave a

336
00:14:04,600 --> 00:14:07,709
presentation and I was on a panel of

337
00:14:07,709 --> 00:14:10,809
digital marketing companies right you

338
00:14:10,809 --> 00:14:13,420
know what that means and I said you're

339
00:14:13,420 --> 00:14:15,850
creepy as an industry the whole industry

340
00:14:15,850 --> 00:14:18,240
so thus far has been relatively creepy

341
00:14:18,240 --> 00:14:20,559
but i think you know we can begin to

342
00:14:20,559 --> 00:14:26,009
change the dialogue i love this quote

343
00:14:26,009 --> 00:14:29,439
everybody remembers Tim Cook from Apple

344
00:14:29,439 --> 00:14:30,850
when he changed the privacy policy was

345
00:14:30,850 --> 00:14:32,589
about last year and he said you are not

346
00:14:32,589 --> 00:14:34,559
the product I thought that was fantastic

347
00:14:34,559 --> 00:14:38,129
and I'm really hopeful that

348
00:14:38,129 --> 00:14:40,540
organizations will begin to see that

349
00:14:40,540 --> 00:14:42,959
personally identifiable data or privacy

350
00:14:42,959 --> 00:14:45,870
actually can be a bottom line and

351
00:14:45,870 --> 00:14:49,480
actually add value to the business but

352
00:14:49,480 --> 00:14:50,740
if you're getting it for free and as I

353
00:14:50,740 --> 00:14:52,689
tell my kids they said dad the app is

354
00:14:52,689 --> 00:14:55,410
free and I keep reminding him of this

355
00:14:55,410 --> 00:14:58,420
I'm one of those dads as well

356
00:14:58,420 --> 00:15:02,260
I am I took when my dog was four years

357
00:15:02,260 --> 00:15:04,690
old I started to teach you how to use

358
00:15:04,690 --> 00:15:07,300
metasploit which was a hacking tool kit

359
00:15:07,300 --> 00:15:09,639
and now actually teaching them how to

360
00:15:09,639 --> 00:15:15,100
use tor but I think it's important they

361
00:15:15,100 --> 00:15:16,930
need to understand what information is

362
00:15:16,930 --> 00:15:21,760
being collected about them because that

363
00:15:21,760 --> 00:15:24,220
is the world we're moving towards now

364
00:15:24,220 --> 00:15:26,800
this actually is a diagram taken from

365
00:15:26,800 --> 00:15:30,370
NIST I are 76 28 which is the volume 2

366
00:15:30,370 --> 00:15:33,010
smart grid mandate on privacy on privacy

367
00:15:33,010 --> 00:15:38,019
as we move forward every single device

368
00:15:38,019 --> 00:15:39,730
that we have in our home is going to be

369
00:15:39,730 --> 00:15:43,240
collecting information about us how many

370
00:15:43,240 --> 00:15:45,639
of you have more than 10 IP connected

371
00:15:45,639 --> 00:15:48,490
devices in your home today keep your

372
00:15:48,490 --> 00:15:54,339
hand up if you have 20 30 all right you

373
00:15:54,339 --> 00:15:58,120
might be me 40 no all right so I'm still

374
00:15:58,120 --> 00:15:59,350
the most saddest guy in the room

375
00:15:59,350 --> 00:16:01,360
actually funny story is whenever I do

376
00:16:01,360 --> 00:16:03,459
that I ask people in the audience once

377
00:16:03,459 --> 00:16:05,980
and somebody somebody said they had 75

378
00:16:05,980 --> 00:16:07,870
devices and I think the thing that

379
00:16:07,870 --> 00:16:09,130
surprised me was he was still married

380
00:16:09,130 --> 00:16:14,310
and I use the word he by the way as well

381
00:16:14,310 --> 00:16:16,660
but the you know these types of devices

382
00:16:16,660 --> 00:16:18,339
are going to be collecting for vast

383
00:16:18,339 --> 00:16:20,440
amounts of data in our home now this is

384
00:16:20,440 --> 00:16:23,410
just one by the way this is taken from a

385
00:16:23,410 --> 00:16:26,230
smart meter and this is what we called

386
00:16:26,230 --> 00:16:28,570
and I don't like to use acronyms but

387
00:16:28,570 --> 00:16:30,310
this is what we call nyame which is

388
00:16:30,310 --> 00:16:32,610
non-intrusive activity load monitoring

389
00:16:32,610 --> 00:16:35,470
now every smart meter will be collecting

390
00:16:35,470 --> 00:16:37,329
transactional data about what you do in

391
00:16:37,329 --> 00:16:40,019
your house you know the fact that you've

392
00:16:40,019 --> 00:16:42,100
going to switch the washing machine on

393
00:16:42,100 --> 00:16:44,019
use the toaster and made a cup of tea

394
00:16:44,019 --> 00:16:46,569
six times in a day that's probably in an

395
00:16:46,569 --> 00:16:50,500
English house by the way does that worry

396
00:16:50,500 --> 00:16:52,329
anyone are you happy with this type of

397
00:16:52,329 --> 00:16:54,760
data being collected about your home are

398
00:16:54,760 --> 00:16:56,110
you happy with the fact that the utility

399
00:16:56,110 --> 00:16:57,850
knows that you had the hot tub and hot

400
00:16:57,850 --> 00:17:02,230
tub on at eleven o'clock at night they

401
00:17:02,230 --> 00:17:05,829
are you happy with this anyone now this

402
00:17:05,829 --> 00:17:07,659
is interesting because not only can I

403
00:17:07,659 --> 00:17:09,579
tell the fact that you're running a

404
00:17:09,579 --> 00:17:11,169
washing machine I can also tell what

405
00:17:11,169 --> 00:17:12,069
model number that wash

406
00:17:12,069 --> 00:17:16,540
machine now that's based on what we call

407
00:17:16,540 --> 00:17:18,099
a polling interval so we will ask the

408
00:17:18,099 --> 00:17:20,680
meter every 15 minutes if we decrease

409
00:17:20,680 --> 00:17:22,210
that polling interval down to two

410
00:17:22,210 --> 00:17:25,300
seconds what do you think we find out

411
00:17:25,300 --> 00:17:30,730
then this might worry you by the way you

412
00:17:30,730 --> 00:17:33,730
may not want to hear this what what's

413
00:17:33,730 --> 00:17:35,680
the saying because viewers of a nervous

414
00:17:35,680 --> 00:17:38,140
and dismissive in disposition may want

415
00:17:38,140 --> 00:17:40,450
to look away now or is it match of the

416
00:17:40,450 --> 00:17:41,440
day they go if you don't want to know

417
00:17:41,440 --> 00:17:44,830
the scores just go on mute now actually

418
00:17:44,830 --> 00:17:46,150
if we decrease the polling interval down

419
00:17:46,150 --> 00:17:48,700
to two seconds we can also tell what TV

420
00:17:48,700 --> 00:17:52,270
shows you're watching absolutely true by

421
00:17:52,270 --> 00:17:54,700
the way and which country so there was a

422
00:17:54,700 --> 00:17:58,480
country in Europe that had there was a

423
00:17:58,480 --> 00:18:02,140
DSO who had sold smart meters and there

424
00:18:02,140 --> 00:18:03,940
was a vulnerability found and all of

425
00:18:03,940 --> 00:18:05,710
their customers had this particular

426
00:18:05,710 --> 00:18:09,010
issue whereby the utility knew what TV

427
00:18:09,010 --> 00:18:10,330
shows every single one of their

428
00:18:10,330 --> 00:18:13,390
customers were watching which country do

429
00:18:13,390 --> 00:18:16,210
you think that was from I hear Germany

430
00:18:16,210 --> 00:18:17,680
right because at it absolutely was

431
00:18:17,680 --> 00:18:20,290
Germany you know the fastian of privacy

432
00:18:20,290 --> 00:18:23,080
is what I keep getting told but the

433
00:18:23,080 --> 00:18:25,570
people didn't know people had no idea of

434
00:18:25,570 --> 00:18:27,850
these implications but I want to kind of

435
00:18:27,850 --> 00:18:30,070
turn this on its head I you know this is

436
00:18:30,070 --> 00:18:32,080
worrying but this is reality right we

437
00:18:32,080 --> 00:18:34,800
have to accept that IOT is going to be

438
00:18:34,800 --> 00:18:37,390
providing more insights into our home

439
00:18:37,390 --> 00:18:39,490
and if you get the opportunity have a

440
00:18:39,490 --> 00:18:41,650
look at this project called hat the hub

441
00:18:41,650 --> 00:18:44,110
of all things and this is a university

442
00:18:44,110 --> 00:18:46,030
project which is looking to provide that

443
00:18:46,030 --> 00:18:48,160
level of insight into every smart home

444
00:18:48,160 --> 00:18:50,860
as we move forward but I believe what we

445
00:18:50,860 --> 00:18:53,980
can begin to do is provide informed

446
00:18:53,980 --> 00:18:56,770
consent transparency and value to

447
00:18:56,770 --> 00:18:59,110
consumers now why can't I turn around to

448
00:18:59,110 --> 00:19:00,730
the consumer and say well listen you're

449
00:19:00,730 --> 00:19:02,050
running that washing machine at seven

450
00:19:02,050 --> 00:19:03,790
o'clock at night that washing machine

451
00:19:03,790 --> 00:19:07,750
isn't particularly efficient so what we

452
00:19:07,750 --> 00:19:09,610
can do is we can provide you with a new

453
00:19:09,610 --> 00:19:11,110
washing machine which is more efficient

454
00:19:11,110 --> 00:19:13,270
but in doing so we can give you a

455
00:19:13,270 --> 00:19:14,950
discount of thirty to forty percent and

456
00:19:14,950 --> 00:19:16,510
by the way the return on investment to

457
00:19:16,510 --> 00:19:18,940
you is three months we can save energy

458
00:19:18,940 --> 00:19:23,020
you can get economic value and I believe

459
00:19:23,020 --> 00:19:25,610
that a more ethical way to do things

460
00:19:25,610 --> 00:19:27,650
this I think is a move towards this

461
00:19:27,650 --> 00:19:29,660
concept of personally of the personal

462
00:19:29,660 --> 00:19:31,250
data economy and you're already

463
00:19:31,250 --> 00:19:32,570
beginning to see this right the

464
00:19:32,570 --> 00:19:34,730
insurance industry putting black boxes

465
00:19:34,730 --> 00:19:37,700
in your car that's an example of this

466
00:19:37,700 --> 00:19:42,230
and that in a sense was what the

467
00:19:42,230 --> 00:19:43,670
Department of Business through the my

468
00:19:43,670 --> 00:19:45,740
data project tries to do it tries to

469
00:19:45,740 --> 00:19:48,020
provide transparency over what

470
00:19:48,020 --> 00:19:51,520
information organizations have about you

471
00:19:51,520 --> 00:19:53,780
so I do think that there is a way

472
00:19:53,780 --> 00:19:56,990
forward it is pragmatic it is quite

473
00:19:56,990 --> 00:19:59,660
worrying it is quite scary but if we can

474
00:19:59,660 --> 00:20:01,730
provide value to consumers give them

475
00:20:01,730 --> 00:20:03,710
transparency and informed consent I can

476
00:20:03,710 --> 00:20:05,929
say no I can say no actually I don't

477
00:20:05,929 --> 00:20:07,190
want you to know this information I

478
00:20:07,190 --> 00:20:08,570
don't want you to be able to sell this

479
00:20:08,570 --> 00:20:12,110
data on it's all about value you know

480
00:20:12,110 --> 00:20:14,330
people will always argue and say well I

481
00:20:14,330 --> 00:20:16,250
don't use facebook or I do use Facebook

482
00:20:16,250 --> 00:20:18,320
but to be fair they provide you with

483
00:20:18,320 --> 00:20:20,450
value they give you a service and it's

484
00:20:20,450 --> 00:20:21,590
your choice whether you want to use it

485
00:20:21,590 --> 00:20:27,799
or not now that of course is the great

486
00:20:27,799 --> 00:20:30,190
business world that that of course is

487
00:20:30,190 --> 00:20:32,480
the way that the commercial industry is

488
00:20:32,480 --> 00:20:34,970
moving forward there is an alternate and

489
00:20:34,970 --> 00:20:36,860
flip side to this and I think vtec was

490
00:20:36,860 --> 00:20:38,690
an example of that Ashley Madison was an

491
00:20:38,690 --> 00:20:40,490
example of that and we actually

492
00:20:40,490 --> 00:20:44,650
conducted research to say well okay we

493
00:20:44,650 --> 00:20:46,309
organizations are collecting vast

494
00:20:46,309 --> 00:20:48,590
amounts of data about all of us and it

495
00:20:48,590 --> 00:20:50,030
seems like every single day there's and

496
00:20:50,030 --> 00:20:52,429
other organization compromised so what I

497
00:20:52,429 --> 00:20:53,570
wanted to do is just give you a

498
00:20:53,570 --> 00:20:56,330
alternate view as well which is as we're

499
00:20:56,330 --> 00:20:58,070
collecting all of this information about

500
00:20:58,070 --> 00:21:02,600
you me our children and our family what

501
00:21:02,600 --> 00:21:05,090
happens as a result of that well what

502
00:21:05,090 --> 00:21:06,950
happens as a result of that is this

503
00:21:06,950 --> 00:21:09,830
information is being targeted by who

504
00:21:09,830 --> 00:21:12,440
knows nefarious individuals out there

505
00:21:12,440 --> 00:21:14,660
and what they're beginning to do now is

506
00:21:14,660 --> 00:21:15,799
they're beginning to sell this

507
00:21:15,799 --> 00:21:20,000
information on so the need to be able to

508
00:21:20,000 --> 00:21:22,190
have better degrees of protection that

509
00:21:22,190 --> 00:21:24,049
the need to be able to actually

510
00:21:24,049 --> 00:21:26,059
understand what's being sold as is key

511
00:21:26,059 --> 00:21:28,760
now this is taken from a research paper

512
00:21:28,760 --> 00:21:30,620
we did call the hidden data economy and

513
00:21:30,620 --> 00:21:32,990
the intent of that was to show people

514
00:21:32,990 --> 00:21:36,260
what happens after a data breach so this

515
00:21:36,260 --> 00:21:38,990
one actually this one scared me the most

516
00:21:38,990 --> 00:21:40,490
and it's not particularly insightful

517
00:21:40,490 --> 00:21:42,320
because we all know personal data is

518
00:21:42,320 --> 00:21:44,870
available for sale but we found this

519
00:21:44,870 --> 00:21:47,840
young man he was 19 years old based in

520
00:21:47,840 --> 00:21:49,760
the east of england and i remember

521
00:21:49,760 --> 00:21:51,440
having this conversation so we sent it

522
00:21:51,440 --> 00:21:52,670
to the police and we said look can you

523
00:21:52,670 --> 00:21:55,220
let this particular individual know that

524
00:21:55,220 --> 00:21:57,230
his personal data is being sold by

525
00:21:57,230 --> 00:22:00,020
primitives so there's a knock at the

526
00:22:00,020 --> 00:22:01,640
door and he answers the door and he says

527
00:22:01,640 --> 00:22:03,020
you know we explained to him what we

528
00:22:03,020 --> 00:22:05,210
found you know the fact that we've got

529
00:22:05,210 --> 00:22:08,240
is you his demographics we've got every

530
00:22:08,240 --> 00:22:09,950
single one of his digital accounts his

531
00:22:09,950 --> 00:22:12,350
password his email accounts even his mum

532
00:22:12,350 --> 00:22:14,120
and dad's details by the way this mum

533
00:22:14,120 --> 00:22:15,260
and dad's facebook accounts email

534
00:22:15,260 --> 00:22:18,740
accounts the whole nine yards and he

535
00:22:18,740 --> 00:22:19,730
asked me a question he said well what

536
00:22:19,730 --> 00:22:22,610
can I do and I said well change your

537
00:22:22,610 --> 00:22:26,120
passwords first of all and don't be so

538
00:22:26,120 --> 00:22:27,470
promiscuous when you're on the internet

539
00:22:27,470 --> 00:22:29,750
you know don't dump all your data out

540
00:22:29,750 --> 00:22:32,720
there and then of course the

541
00:22:32,720 --> 00:22:34,580
conversation changed because we had

542
00:22:34,580 --> 00:22:36,590
other examples where we had medical data

543
00:22:36,590 --> 00:22:38,270
which was being sold and sold those

544
00:22:38,270 --> 00:22:40,720
which have been stolen and sold online

545
00:22:40,720 --> 00:22:42,830
and then they asked me that question

546
00:22:42,830 --> 00:22:44,750
said well what do I do about my medical

547
00:22:44,750 --> 00:22:53,090
data any ideas because I don't know the

548
00:22:53,090 --> 00:22:56,750
answer and that's the reality of the

549
00:22:56,750 --> 00:22:59,330
world that we live in is that you know

550
00:22:59,330 --> 00:23:01,850
what I call digital information like a

551
00:23:01,850 --> 00:23:03,350
digital tattoo and I'm sure many of you

552
00:23:03,350 --> 00:23:05,630
have heard the concept you can't tell

553
00:23:05,630 --> 00:23:07,490
but I love tattoos and completely

554
00:23:07,490 --> 00:23:12,830
covered head to toe and I gave away too

555
00:23:12,830 --> 00:23:14,230
much

556
00:23:14,230 --> 00:23:18,790
damn it oh but it's like a tattoo you

557
00:23:18,790 --> 00:23:20,110
know and I always tell people about this

558
00:23:20,110 --> 00:23:22,630
concept that whereby you know you try

559
00:23:22,630 --> 00:23:24,070
removing your information from the

560
00:23:24,070 --> 00:23:25,330
internets like trying to remove a tattoo

561
00:23:25,330 --> 00:23:27,940
you know it's expensive it painful it's

562
00:23:27,940 --> 00:23:30,280
painful it leaves scars and that's

563
00:23:30,280 --> 00:23:31,720
exactly the world that I was trying to

564
00:23:31,720 --> 00:23:33,040
explain to this particular individual

565
00:23:33,040 --> 00:23:35,080
and what we're beginning to witness and

566
00:23:35,080 --> 00:23:36,910
what we're beginning to see is you know

567
00:23:36,910 --> 00:23:39,100
I talked about personal data as being

568
00:23:39,100 --> 00:23:41,350
the new oil of the digital world these

569
00:23:41,350 --> 00:23:43,000
guys have known it for years and they've

570
00:23:43,000 --> 00:23:44,919
been targeting large databases and large

571
00:23:44,919 --> 00:23:47,620
systems to exfiltrate data to be able to

572
00:23:47,620 --> 00:23:50,470
go out and sell that on and it doesn't

573
00:23:50,470 --> 00:23:52,690
just end there you know personal data is

574
00:23:52,690 --> 00:23:55,960
being stocks sold we've got identities

575
00:23:55,960 --> 00:23:58,360
being sold and even to the point of if

576
00:23:58,360 --> 00:24:00,190
you wanted to be really granular and

577
00:24:00,190 --> 00:24:02,530
target people based upon specific

578
00:24:02,530 --> 00:24:05,049
profession you can do that on the left

579
00:24:05,049 --> 00:24:06,490
hand side you have a particular seller

580
00:24:06,490 --> 00:24:09,549
who's known to us on Alpha Bay and he's

581
00:24:09,549 --> 00:24:11,440
actually selling information about

582
00:24:11,440 --> 00:24:12,820
physicians based in the United States

583
00:24:12,820 --> 00:24:14,980
based on a hospital that he compromised

584
00:24:14,980 --> 00:24:18,340
and that's the world that we live in and

585
00:24:18,340 --> 00:24:21,429
to be honest it this marketplace is

586
00:24:21,429 --> 00:24:24,549
getting broader and richer and even more

587
00:24:24,549 --> 00:24:27,570
data is coming online all of the time

588
00:24:27,570 --> 00:24:29,530
everybody remembers when target were

589
00:24:29,530 --> 00:24:32,049
breached we saw the information based

590
00:24:32,049 --> 00:24:34,270
upon the target breach was just 140

591
00:24:34,270 --> 00:24:37,780
million credit card details online for

592
00:24:37,780 --> 00:24:41,610
sale within two weeks it was

593
00:24:41,610 --> 00:24:46,270
instantaneous almost and of course it

594
00:24:46,270 --> 00:24:49,000
doesn't end there because this was taken

595
00:24:49,000 --> 00:24:50,919
naturally from a hematology lab based in

596
00:24:50,919 --> 00:24:52,870
France and there was a group of hackers

597
00:24:52,870 --> 00:24:54,340
who were trying to blackmail this

598
00:24:54,340 --> 00:24:57,250
laboratory to say unless you pay us a

599
00:24:57,250 --> 00:24:59,950
certain amount of ransom we will dump

600
00:24:59,950 --> 00:25:02,890
all of your patient data online and so

601
00:25:02,890 --> 00:25:04,360
the blood results of every single one of

602
00:25:04,360 --> 00:25:06,870
their patients was then dumped online

603
00:25:06,870 --> 00:25:10,860
I'm come about done naturally

604
00:25:12,300 --> 00:25:14,910
I do this not to spread fear uncertainty

605
00:25:14,910 --> 00:25:17,400
and doubt and I did warn you that this

606
00:25:17,400 --> 00:25:19,290
was pretty much a rant which it kind of

607
00:25:19,290 --> 00:25:23,100
is but I think there are two key points

608
00:25:23,100 --> 00:25:24,690
that we should recognize here so first

609
00:25:24,690 --> 00:25:29,010
of all we have to recognize that we call

610
00:25:29,010 --> 00:25:30,390
it a threat landscape with in cyber

611
00:25:30,390 --> 00:25:33,780
security but the number of groups out

612
00:25:33,780 --> 00:25:35,400
there going out and targeting

613
00:25:35,400 --> 00:25:37,860
organizations across the world stealing

614
00:25:37,860 --> 00:25:39,630
information and dumping that data and

615
00:25:39,630 --> 00:25:41,610
selling it on is growing at an

616
00:25:41,610 --> 00:25:45,200
exponential rate I wrote a paper called

617
00:25:45,200 --> 00:25:47,550
33 years ago actually called cyber crime

618
00:25:47,550 --> 00:25:49,590
exposed in which I said today

619
00:25:49,590 --> 00:25:51,570
cybercriminals require no technical

620
00:25:51,570 --> 00:25:54,330
knowledge to become cyber criminals and

621
00:25:54,330 --> 00:25:57,240
that's absolutely true and if I get the

622
00:25:57,240 --> 00:25:59,070
opportunity I can I can send you the

623
00:25:59,070 --> 00:26:01,170
paper when I talk about this particular

624
00:26:01,170 --> 00:26:04,560
research the talk is entitled my dad

625
00:26:04,560 --> 00:26:07,410
could be a cybercriminal and the

626
00:26:07,410 --> 00:26:08,580
funniest thing was when I spoke at

627
00:26:08,580 --> 00:26:10,920
Oxford Oxford University my dad was

628
00:26:10,920 --> 00:26:12,480
actually in the front row and he didn't

629
00:26:12,480 --> 00:26:16,740
appreciate that too late it's out you

630
00:26:16,740 --> 00:26:18,330
can't do anything about it what are you

631
00:26:18,330 --> 00:26:20,730
going to do right so the first thing we

632
00:26:20,730 --> 00:26:22,710
have to recognize is that there is

633
00:26:22,710 --> 00:26:24,870
enormous economic value in the data that

634
00:26:24,870 --> 00:26:29,190
we have the actual value of that data is

635
00:26:29,190 --> 00:26:31,380
increasing exponentially pretty much

636
00:26:31,380 --> 00:26:34,020
increasing exponentially although there

637
00:26:34,020 --> 00:26:36,530
are some nuances here you know the the

638
00:26:36,530 --> 00:26:39,120
market cost of some of these assets is

639
00:26:39,120 --> 00:26:41,490
quite low but the demand is still high

640
00:26:41,490 --> 00:26:43,650
what I mean by that is five years ago

641
00:26:43,650 --> 00:26:45,150
credit cards were being sold at one

642
00:26:45,150 --> 00:26:46,500
hundred and fifty dollars two hundred

643
00:26:46,500 --> 00:26:47,760
and thirty two hundred fifty dollars

644
00:26:47,760 --> 00:26:49,260
today they're about three dollars a

645
00:26:49,260 --> 00:26:52,110
piece but the demand is there it's just

646
00:26:52,110 --> 00:26:54,570
suppliers just completely come in you

647
00:26:54,570 --> 00:26:57,840
know it's it's been incredible but the

648
00:26:57,840 --> 00:26:59,310
actual value of personal data is

649
00:26:59,310 --> 00:27:02,280
increasing exponentially the perceived

650
00:27:02,280 --> 00:27:03,810
value of personal data in other words

651
00:27:03,810 --> 00:27:08,520
how consumers value their data is less

652
00:27:08,520 --> 00:27:12,060
than zero two years ago it was worth a

653
00:27:12,060 --> 00:27:14,550
cream egg now if you want to go and

654
00:27:14,550 --> 00:27:16,410
watch despicable me 2 you've got to pay

655
00:27:16,410 --> 00:27:18,360
for the privilege of somebody capturing

656
00:27:18,360 --> 00:27:22,080
your personal data actually decreasing

657
00:27:22,080 --> 00:27:24,990
in value and that model can't work and I

658
00:27:24,990 --> 00:27:26,100
think that's an issue

659
00:27:26,100 --> 00:27:28,919
but I do think we as an industry have

660
00:27:28,919 --> 00:27:30,720
the opportunity to be able to look at

661
00:27:30,720 --> 00:27:33,750
things like I OT and allow people the

662
00:27:33,750 --> 00:27:35,850
market opportunities to get fair value

663
00:27:35,850 --> 00:27:37,890
the ability to be able to get real

664
00:27:37,890 --> 00:27:40,220
transparency and informed consent and

665
00:27:40,220 --> 00:27:42,870
that to me goes beyond the concept of

666
00:27:42,870 --> 00:27:46,320
using compliance as a driver towards

667
00:27:46,320 --> 00:27:48,360
privacy because that to me just creates

668
00:27:48,360 --> 00:27:50,429
a baseline and you know what I want more

669
00:27:50,429 --> 00:27:53,669
than a baseline I actually wouldn't mind

670
00:27:53,669 --> 00:27:56,730
a trillion euros by 2020 personally by

671
00:27:56,730 --> 00:28:02,370
the way I need more tattoos right so you

672
00:28:02,370 --> 00:28:04,700
know my my asp of all of you today is

673
00:28:04,700 --> 00:28:08,220
you know have a look at the research and

674
00:28:08,220 --> 00:28:11,100
if you are interested in some of these

675
00:28:11,100 --> 00:28:13,530
new concepts and these new business

676
00:28:13,530 --> 00:28:16,230
models start having this discussion with

677
00:28:16,230 --> 00:28:20,340
the business that you're in you know in

678
00:28:20,340 --> 00:28:22,470
the past and you know I worked in

679
00:28:22,470 --> 00:28:24,030
security information governance and

680
00:28:24,030 --> 00:28:26,100
privacy I've always been the guy that's

681
00:28:26,100 --> 00:28:29,130
been told about projects like a day

682
00:28:29,130 --> 00:28:32,610
before it goes live I remember getting a

683
00:28:32,610 --> 00:28:34,140
phone call at four thirty on a Friday

684
00:28:34,140 --> 00:28:36,270
saying we're rolling out a program for

685
00:28:36,270 --> 00:28:39,240
20 million consumers across the water

686
00:28:39,240 --> 00:28:41,130
across the country can you please

687
00:28:41,130 --> 00:28:43,740
approve it I was on Friday afternoon and

688
00:28:43,740 --> 00:28:46,020
now by the way if you try to phone me I

689
00:28:46,020 --> 00:28:48,210
never answer the phone after 4 30 just a

690
00:28:48,210 --> 00:28:52,530
tip what I'd like to be able to do is

691
00:28:52,530 --> 00:28:54,750
move to a world and HR was with one of

692
00:28:54,750 --> 00:28:56,429
the largest car manufacturers this just

693
00:28:56,429 --> 00:28:59,340
on monday is where we can look to

694
00:28:59,340 --> 00:29:01,140
actually provide real value to the

695
00:29:01,140 --> 00:29:03,510
business but do so by providing

696
00:29:03,510 --> 00:29:05,940
solutions which I think are ethical and

697
00:29:05,940 --> 00:29:09,419
go beyond compliance with that thank you

698
00:29:09,419 --> 00:29:11,630
very much

699
00:29:17,980 --> 00:29:20,119
yeah we've got some quite some time for

700
00:29:20,119 --> 00:29:28,970
questions I think I'm not okay I'm not

701
00:29:28,970 --> 00:29:30,440
answering questions about my tattoos by

702
00:29:30,440 --> 00:29:37,879
the way hi my name's Kate may feel some

703
00:29:37,879 --> 00:29:40,580
mistake um I'm just interested in your

704
00:29:40,580 --> 00:29:42,379
views on what the consumers feel about

705
00:29:42,379 --> 00:29:44,179
this because whenever I talk to friends

706
00:29:44,179 --> 00:29:46,039
outside the privacy industry they don't

707
00:29:46,039 --> 00:29:48,080
care normal people right normal people

708
00:29:48,080 --> 00:29:50,359
don't care and I understand how a lab

709
00:29:50,359 --> 00:29:52,639
would be blackmailed and that's bad for

710
00:29:52,639 --> 00:29:54,169
that business and indeed for that I

711
00:29:54,169 --> 00:29:56,600
suppose but I think in turn in inside

712
00:29:56,600 --> 00:29:58,730
the privacy sector and we worry about it

713
00:29:58,730 --> 00:30:01,039
more than our consumer market do I think

714
00:30:01,039 --> 00:30:02,389
you're right and and to be honest I

715
00:30:02,389 --> 00:30:04,309
think we have the same friends because

716
00:30:04,309 --> 00:30:07,759
they you know whenever I talk to people

717
00:30:07,759 --> 00:30:09,529
like what I do they're like well I don't

718
00:30:09,529 --> 00:30:10,759
really care because the bank will just

719
00:30:10,759 --> 00:30:12,470
you know if my credit card gets

720
00:30:12,470 --> 00:30:14,450
compromised they'll just give me my

721
00:30:14,450 --> 00:30:16,340
money back but I think there are some

722
00:30:16,340 --> 00:30:17,570
things that are going to be changing so

723
00:30:17,570 --> 00:30:20,239
first of all banks and no longer going

724
00:30:20,239 --> 00:30:22,690
to be blanket providing you a refund and

725
00:30:22,690 --> 00:30:25,330
I know if a number of cases in which

726
00:30:25,330 --> 00:30:27,559
people have made the same mistake once

727
00:30:27,559 --> 00:30:30,649
or twice and they go back to the bank

728
00:30:30,649 --> 00:30:31,730
and the bank said well I'm not going to

729
00:30:31,730 --> 00:30:33,590
i'm not going to pay for and so i think

730
00:30:33,590 --> 00:30:35,659
this a this comes down to the concept of

731
00:30:35,659 --> 00:30:37,159
accountability and I think

732
00:30:37,159 --> 00:30:38,749
accountability is now beginning to be

733
00:30:38,749 --> 00:30:41,809
placed upon consumers which is slowly

734
00:30:41,809 --> 00:30:44,739
but surely changing changing the shift

735
00:30:44,739 --> 00:30:47,419
but we've always tried to educate users

736
00:30:47,419 --> 00:30:49,249
by saying do this because if you don't

737
00:30:49,249 --> 00:30:51,049
the world is going to fall in and you

738
00:30:51,049 --> 00:30:52,399
know the Four Horsemen of the Apocalypse

739
00:30:52,399 --> 00:30:53,899
will come and you know the worst thing

740
00:30:53,899 --> 00:30:57,440
is going to happen but I protect things

741
00:30:57,440 --> 00:31:00,679
that I attribute that has a value so for

742
00:31:00,679 --> 00:31:02,480
example i lock my car because my car has

743
00:31:02,480 --> 00:31:04,970
value I don't necessarily care about my

744
00:31:04,970 --> 00:31:06,230
data because I don't perceive that to

745
00:31:06,230 --> 00:31:08,299
have value and I think if we can begin

746
00:31:08,299 --> 00:31:10,489
to have this discussion about economic

747
00:31:10,489 --> 00:31:12,769
value that our data has and actually

748
00:31:12,769 --> 00:31:16,549
show examples whereby they can make

749
00:31:16,549 --> 00:31:17,629
money through their personally

750
00:31:17,629 --> 00:31:19,789
identifiable data then perhaps we'll

751
00:31:19,789 --> 00:31:21,230
start to take it more seriously then

752
00:31:21,230 --> 00:31:22,849
perhaps we'll begin to try to protect it

753
00:31:22,849 --> 00:31:25,549
but right now how many people I mean if

754
00:31:25,549 --> 00:31:26,869
you go and talk to your normal friends

755
00:31:26,869 --> 00:31:27,920
and say what's the

756
00:31:27,920 --> 00:31:31,520
any of your personal data probably

757
00:31:31,520 --> 00:31:34,670
nothing right it's like what's the value

758
00:31:34,670 --> 00:31:39,550
of intellectual property I don't know

759
00:31:40,990 --> 00:31:44,470
this question too

760
00:31:51,160 --> 00:31:54,310
hi stefan from City I want the question

761
00:31:54,310 --> 00:31:56,950
on the idea of informed consent I mean

762
00:31:56,950 --> 00:31:59,110
how do you see the panel bit with all

763
00:31:59,110 --> 00:32:01,480
the devices the Internet of Things how

764
00:32:01,480 --> 00:32:03,820
even if people care how will they be

765
00:32:03,820 --> 00:32:05,740
able to manage that just in terms of

766
00:32:05,740 --> 00:32:07,780
times and capacity yeah it's going to be

767
00:32:07,780 --> 00:32:11,010
hard it's going to be really difficult

768
00:32:11,010 --> 00:32:14,770
but we've got a couple of pilot projects

769
00:32:14,770 --> 00:32:16,690
underway one particular in smart grids

770
00:32:16,690 --> 00:32:19,540
and the intent of that is to try to

771
00:32:19,540 --> 00:32:23,350
introduce informed consent by actually

772
00:32:23,350 --> 00:32:24,910
talking by doing focus groups and

773
00:32:24,910 --> 00:32:27,670
explain to people what we're doing but I

774
00:32:27,670 --> 00:32:28,930
think its scale it's going to be very

775
00:32:28,930 --> 00:32:32,110
very difficult but you know you can lead

776
00:32:32,110 --> 00:32:33,580
a horse to water but you can't force it

777
00:32:33,580 --> 00:32:36,340
to drink so I think you know what will

778
00:32:36,340 --> 00:32:37,570
provide the tools will provide

779
00:32:37,570 --> 00:32:39,310
communications mechanisms will explain

780
00:32:39,310 --> 00:32:40,960
to people what we're trying to do there

781
00:32:40,960 --> 00:32:42,490
will be normal people that will just say

782
00:32:42,490 --> 00:32:45,370
well I don't care but at least we can

783
00:32:45,370 --> 00:32:47,650
try to provide that information to make

784
00:32:47,650 --> 00:32:50,230
it available for people it reminds me

785
00:32:50,230 --> 00:32:51,700
actually my brother got an

786
00:32:51,700 --> 00:32:55,600
internet-connected doorbell and and he

787
00:32:55,600 --> 00:32:57,070
was sick leave is crowing about this he

788
00:32:57,070 --> 00:32:57,610
said I've just got this

789
00:32:57,610 --> 00:32:59,440
internet-connected doorbell and you know

790
00:32:59,440 --> 00:33:01,450
what it will text my phone every time

791
00:33:01,450 --> 00:33:02,920
somebody's at my house and I can see

792
00:33:02,920 --> 00:33:05,650
pictures of who's at my house and I went

793
00:33:05,650 --> 00:33:07,510
well are you aware that this is

794
00:33:07,510 --> 00:33:09,220
collecting data about you I use are you

795
00:33:09,220 --> 00:33:10,870
concerned about the security and privacy

796
00:33:10,870 --> 00:33:15,310
issues anywhere I don't really care now

797
00:33:15,310 --> 00:33:16,960
his doorbell rings at four o'clock every

798
00:33:16,960 --> 00:33:18,520
morning and now he takes security

799
00:33:18,520 --> 00:33:22,330
seriously but those are examples of you

800
00:33:22,330 --> 00:33:24,970
know people being feature driven and not

801
00:33:24,970 --> 00:33:26,590
really considering the implications so

802
00:33:26,590 --> 00:33:28,510
what we can do is we can provide the

803
00:33:28,510 --> 00:33:30,430
information you can be ethical but we

804
00:33:30,430 --> 00:33:33,310
can't force people to value their

805
00:33:33,310 --> 00:33:34,750
information there has to be up to them

806
00:33:34,750 --> 00:33:41,110
oh it's equipped another Lilith okay so

807
00:33:41,110 --> 00:33:43,150
we got time for no problems thanks very

808
00:33:43,150 --> 00:33:45,210
much

