1
00:00:10,849 --> 00:00:13,679
thank you Chris and thank you for having

2
00:00:13,679 --> 00:00:18,449
pointed out that I'm quite old I'm glad

3
00:00:18,449 --> 00:00:21,150
to be here in Toronto today of course

4
00:00:21,150 --> 00:00:24,680
glad to be here at the IPP symposium

5
00:00:24,680 --> 00:00:27,090
it's an important day for us we're

6
00:00:27,090 --> 00:00:30,660
launching an important exercise with

7
00:00:30,660 --> 00:00:32,969
respect to the consent model so here it

8
00:00:32,969 --> 00:00:38,520
is the suspense is over a widely cited

9
00:00:38,520 --> 00:00:42,270
study dating back to 2008 suggests that

10
00:00:42,270 --> 00:00:45,500
Internet users would need to spend 244

11
00:00:45,500 --> 00:00:49,770
hours per year that's nearly 33 workdays

12
00:00:49,770 --> 00:00:52,920
to read much less understand the privacy

13
00:00:52,920 --> 00:00:54,930
policies of the websites that they

14
00:00:54,930 --> 00:00:59,100
visited fast forward eight years add

15
00:00:59,100 --> 00:01:02,399
mobile applications smart devices and

16
00:01:02,399 --> 00:01:05,760
wearables to the mix it seems clear in

17
00:01:05,760 --> 00:01:07,710
our current context that reading privacy

18
00:01:07,710 --> 00:01:09,659
policies could be a full-time pursuit

19
00:01:09,659 --> 00:01:14,729
with untold time hours of overtime this

20
00:01:14,729 --> 00:01:16,680
situation serves to highlight one of the

21
00:01:16,680 --> 00:01:18,630
many challenges that new technologies

22
00:01:18,630 --> 00:01:20,369
have brought to bear on the current

23
00:01:20,369 --> 00:01:24,420
consent model the fact is Peppa da

24
00:01:24,420 --> 00:01:27,710
predates smartphones cloud computing and

25
00:01:27,710 --> 00:01:32,009
business models predicated on thank you

26
00:01:32,009 --> 00:01:35,549
on unlimited access to personal

27
00:01:35,549 --> 00:01:38,579
information and automated processes that

28
00:01:38,579 --> 00:01:41,460
use complex algorithms to extrapolate

29
00:01:41,460 --> 00:01:43,829
new information from very large data

30
00:01:43,829 --> 00:01:46,189
sets

31
00:01:48,909 --> 00:01:52,880
gone are the days of routine predictable

32
00:01:52,880 --> 00:01:55,460
and transparent one-on-one interactions

33
00:01:55,460 --> 00:01:58,490
with companies it is no longer entirely

34
00:01:58,490 --> 00:02:01,220
clear who's processing our data and for

35
00:02:01,220 --> 00:02:04,310
what purposes while some would argue

36
00:02:04,310 --> 00:02:06,560
that privacy policies have become more

37
00:02:06,560 --> 00:02:08,929
about shielding organizations from legal

38
00:02:08,929 --> 00:02:11,930
liability their intent is also to armed

39
00:02:11,930 --> 00:02:13,940
individuals with the information they

40
00:02:13,940 --> 00:02:16,220
need to decide whether to give or

41
00:02:16,220 --> 00:02:19,970
withhold consent is it fair then to

42
00:02:19,970 --> 00:02:22,580
saddle consumers with the responsibility

43
00:02:22,580 --> 00:02:25,220
of having to make sense of these complex

44
00:02:25,220 --> 00:02:27,650
data flows in order to make an informed

45
00:02:27,650 --> 00:02:30,110
choice about whether or not to provide

46
00:02:30,110 --> 00:02:34,130
consent suffice to say that technology

47
00:02:34,130 --> 00:02:36,709
and business models have changed so

48
00:02:36,709 --> 00:02:38,959
significantly since bifida was drafted

49
00:02:38,959 --> 00:02:41,930
that many now describe the consent model

50
00:02:41,930 --> 00:02:46,010
as not up to the task we heard this time

51
00:02:46,010 --> 00:02:47,900
and time again last year during our

52
00:02:47,900 --> 00:02:50,690
consultations on our strategic privacy

53
00:02:50,690 --> 00:02:53,239
priorities when I spoke at this

54
00:02:53,239 --> 00:02:55,880
conference a year ago I indicated that

55
00:02:55,880 --> 00:02:57,320
the economics of personal information

56
00:02:57,320 --> 00:03:00,320
would be a key focus for my office over

57
00:03:00,320 --> 00:03:02,690
the next five years and that under this

58
00:03:02,690 --> 00:03:04,519
priority we would examine the current

59
00:03:04,519 --> 00:03:07,070
consent model with a view to improving

60
00:03:07,070 --> 00:03:11,690
it so I am pleased today to announce the

61
00:03:11,690 --> 00:03:14,540
launch of a discussion paper examining

62
00:03:14,540 --> 00:03:16,820
potential changes to the consent model

63
00:03:16,820 --> 00:03:19,489
we want to start a conversation across

64
00:03:19,489 --> 00:03:21,799
the country and we will be consulting

65
00:03:21,799 --> 00:03:24,709
widely with yourselves with others on

66
00:03:24,709 --> 00:03:29,090
how to address this issue in my remarks

67
00:03:29,090 --> 00:03:30,859
this morning I will touch on some of the

68
00:03:30,859 --> 00:03:34,519
proposed solutions but more importantly

69
00:03:34,519 --> 00:03:36,650
I would like to focus on the roles and

70
00:03:36,650 --> 00:03:38,900
responsibilities of the various players

71
00:03:38,900 --> 00:03:41,959
in this world in which privacy often

72
00:03:41,959 --> 00:03:45,590
seems elusive it will be important I

73
00:03:45,590 --> 00:03:48,049
think to clarify the expectations of

74
00:03:48,049 --> 00:03:51,859
individuals organizations regulators and

75
00:03:51,859 --> 00:03:55,670
legislators I will conclude with a few

76
00:03:55,670 --> 00:03:59,160
thoughts on Privacy Act the public

77
00:03:59,160 --> 00:04:04,390
public-sector legislation in terms of

78
00:04:04,390 --> 00:04:06,610
pippa da it is unlikely that any one

79
00:04:06,610 --> 00:04:08,550
solution could serve as the proverbial

80
00:04:08,550 --> 00:04:11,110
silver bullet but we believe a

81
00:04:11,110 --> 00:04:12,910
combination of solutions could help

82
00:04:12,910 --> 00:04:15,280
individuals achieve greater privacy

83
00:04:15,280 --> 00:04:21,310
protection which is our ultimate goal so

84
00:04:21,310 --> 00:04:23,590
let's talk about the roles of various

85
00:04:23,590 --> 00:04:26,460
players now when it comes to consent

86
00:04:26,460 --> 00:04:28,900
individuals play an important role as

87
00:04:28,900 --> 00:04:32,220
privacy is linked to individual autonomy

88
00:04:32,220 --> 00:04:34,930
but is it fair to assume that average

89
00:04:34,930 --> 00:04:37,900
Canadians will be able to demystify the

90
00:04:37,900 --> 00:04:39,880
complex business relationships and

91
00:04:39,880 --> 00:04:42,610
algorithms what's essentially under the

92
00:04:42,610 --> 00:04:45,100
hood in terms of the processing of

93
00:04:45,100 --> 00:04:48,940
personal information is the solution to

94
00:04:48,940 --> 00:04:50,800
provide individuals with better

95
00:04:50,800 --> 00:04:53,710
information on these complexities so

96
00:04:53,710 --> 00:04:56,400
that they may make informed choices or

97
00:04:56,400 --> 00:04:59,440
must must we find other ways to protect

98
00:04:59,440 --> 00:05:02,020
their interests leaving them to decide

99
00:05:02,020 --> 00:05:04,090
matters for which they can reasonably

100
00:05:04,090 --> 00:05:06,580
and practically indicate their

101
00:05:06,580 --> 00:05:11,920
preferences organizations on the other

102
00:05:11,920 --> 00:05:14,050
hand have a legitimate interest in

103
00:05:14,050 --> 00:05:15,910
processing information for business

104
00:05:15,910 --> 00:05:18,850
purposes they must however be held

105
00:05:18,850 --> 00:05:21,180
accountable in a very meaningful way

106
00:05:21,180 --> 00:05:23,920
what incentives should exist for

107
00:05:23,920 --> 00:05:26,560
organizations to implement greater

108
00:05:26,560 --> 00:05:28,660
transparency and privacy preference

109
00:05:28,660 --> 00:05:31,390
mechanisms to enhance individuals

110
00:05:31,390 --> 00:05:34,840
ability to provide consent to what

111
00:05:34,840 --> 00:05:36,820
extent can businesses be expected to

112
00:05:36,820 --> 00:05:38,710
self-regulate in a matter that protects

113
00:05:38,710 --> 00:05:43,320
individual privacy in the digital age

114
00:05:43,320 --> 00:05:46,090
while organizations have a role in

115
00:05:46,090 --> 00:05:47,200
ensuring the protection of their

116
00:05:47,200 --> 00:05:49,630
customers they are not impartial and

117
00:05:49,630 --> 00:05:51,310
will ultimately act in their own

118
00:05:51,310 --> 00:05:54,610
interest consumer trust and effective

119
00:05:54,610 --> 00:05:56,320
privacy protection demand the

120
00:05:56,320 --> 00:05:58,060
intervention of independent and

121
00:05:58,060 --> 00:06:01,510
impartial actors that are capable of

122
00:06:01,510 --> 00:06:03,610
holding organizations to account and

123
00:06:03,610 --> 00:06:06,060
protecting the interests of individuals

124
00:06:06,060 --> 00:06:08,969
courts have a role to play here

125
00:06:08,969 --> 00:06:12,979
but in most countries including Canada

126
00:06:12,979 --> 00:06:16,589
the EPA's privacy commissioners have an

127
00:06:16,589 --> 00:06:21,569
important role to play to this end what

128
00:06:21,569 --> 00:06:23,519
are the necessary attributes and

129
00:06:23,519 --> 00:06:25,999
authorities of an effective regulator

130
00:06:25,999 --> 00:06:28,999
how best can data protection authorities

131
00:06:28,999 --> 00:06:32,099
ensure that the interests of individuals

132
00:06:32,099 --> 00:06:34,589
are protected and that organizations are

133
00:06:34,589 --> 00:06:37,489
held accountable for their actions

134
00:06:37,489 --> 00:06:39,599
currently my office plays a more

135
00:06:39,599 --> 00:06:42,269
reactive role where generally we

136
00:06:42,269 --> 00:06:44,669
generally investigate complaints after a

137
00:06:44,669 --> 00:06:47,519
violation has occurred would it be

138
00:06:47,519 --> 00:06:49,559
reasonable to give my office the

139
00:06:49,559 --> 00:06:51,449
authority to oversee compliance with

140
00:06:51,449 --> 00:06:54,059
privacy legislation more proactively

141
00:06:54,059 --> 00:06:57,539
before problems arise and in most

142
00:06:57,539 --> 00:06:59,399
countries as you know regulators have

143
00:06:59,399 --> 00:07:01,349
the authority to issue binding orders

144
00:07:01,349 --> 00:07:03,319
and to impose financial sanctions

145
00:07:03,319 --> 00:07:08,869
against organizations why not Canada

146
00:07:09,079 --> 00:07:11,819
while many proposed solutions may be

147
00:07:11,819 --> 00:07:13,979
implemented within the current legal

148
00:07:13,979 --> 00:07:16,199
framework others may require legislative

149
00:07:16,199 --> 00:07:19,079
change is it time to call upon

150
00:07:19,079 --> 00:07:20,969
Parliament to expand the powers of the

151
00:07:20,969 --> 00:07:22,819
office of the Privacy Commissioner

152
00:07:22,819 --> 00:07:25,649
should privacy by design become a

153
00:07:25,649 --> 00:07:28,469
legislated requirement as it will soon

154
00:07:28,469 --> 00:07:32,309
be in Europe should pipita be amended to

155
00:07:32,309 --> 00:07:34,949
provide for no-go zones or conversely

156
00:07:34,949 --> 00:07:37,709
for new legal grounds for processing

157
00:07:37,709 --> 00:07:40,219
where consent may not be practicable

158
00:07:40,219 --> 00:07:42,659
these are the sorts of questions we're

159
00:07:42,659 --> 00:07:45,389
hoping to answer during our consultation

160
00:07:45,389 --> 00:07:50,009
process let's move now to potential

161
00:07:50,009 --> 00:07:54,539
solutions one school of thought suggests

162
00:07:54,539 --> 00:07:56,279
the existing consent model may be

163
00:07:56,279 --> 00:07:58,979
enhanced through mechanisms that improve

164
00:07:58,979 --> 00:08:01,409
the ability of individuals to exercise

165
00:08:01,409 --> 00:08:05,189
meaningful consent proposed solutions

166
00:08:05,189 --> 00:08:07,679
involve providing consumers with better

167
00:08:07,679 --> 00:08:10,349
information giving them the ability to

168
00:08:10,349 --> 00:08:12,119
manage preferences across different

169
00:08:12,119 --> 00:08:14,999
services and ensuring privacy is no

170
00:08:14,999 --> 00:08:16,619
longer an afterthought but is rather

171
00:08:16,619 --> 00:08:19,860
bait or design into products and

172
00:08:19,860 --> 00:08:21,670
services

173
00:08:21,670 --> 00:08:23,960
with respect to the Internet of Things

174
00:08:23,960 --> 00:08:26,270
the US Federal Trade Commission has

175
00:08:26,270 --> 00:08:28,280
proposed a number of promising solutions

176
00:08:28,280 --> 00:08:31,100
to improve the effectiveness of privacy

177
00:08:31,100 --> 00:08:34,250
messaging in the IOT environment these

178
00:08:34,250 --> 00:08:37,219
include QR codes that lead consumers to

179
00:08:37,219 --> 00:08:40,159
more in-depth information set up wizards

180
00:08:40,159 --> 00:08:42,289
to help users select privacy settings

181
00:08:42,289 --> 00:08:46,940
and privacy dashboards the ability to

182
00:08:46,940 --> 00:08:48,770
manage privacy preferences across

183
00:08:48,770 --> 00:08:50,810
different services means individuals

184
00:08:50,810 --> 00:08:53,150
will no longer have to inform themselves

185
00:08:53,150 --> 00:08:55,340
of an organization's privacy practices

186
00:08:55,340 --> 00:08:58,220
and decide whether to provide consent

187
00:08:58,220 --> 00:09:01,000
each time they use a new digital service

188
00:09:01,000 --> 00:09:05,180
this could also help for consent when

189
00:09:05,180 --> 00:09:07,430
new uses of previously collected data

190
00:09:07,430 --> 00:09:14,540
are proposed another school of thought

191
00:09:14,540 --> 00:09:16,820
contends that information flows have

192
00:09:16,820 --> 00:09:18,440
become too complex for the average

193
00:09:18,440 --> 00:09:21,590
person and have called for relaxing of

194
00:09:21,590 --> 00:09:25,160
requirements for consent advocates up

195
00:09:25,160 --> 00:09:26,810
for this approach focus on

196
00:09:26,810 --> 00:09:29,510
accountability and ethical use of

197
00:09:29,510 --> 00:09:31,730
personal information placing the

198
00:09:31,730 --> 00:09:33,740
responsibility for oversight on

199
00:09:33,740 --> 00:09:37,610
regulators alternatives to the consent

200
00:09:37,610 --> 00:09:39,350
model raised questions about whether

201
00:09:39,350 --> 00:09:42,140
certain types of data users may be

202
00:09:42,140 --> 00:09:45,140
permissible without consent so long as

203
00:09:45,140 --> 00:09:48,220
the right privacy framework is in place

204
00:09:48,220 --> 00:09:51,920
such models however begged a question do

205
00:09:51,920 --> 00:09:53,900
we have the right oversight structure to

206
00:09:53,900 --> 00:09:56,390
provide public assurance that their

207
00:09:56,390 --> 00:09:57,830
information is being used for

208
00:09:57,830 --> 00:10:00,440
appropriate purposes and that it is

209
00:10:00,440 --> 00:10:03,910
adequately protected

210
00:10:06,850 --> 00:10:09,380
Europe has a law that allows that of

211
00:10:09,380 --> 00:10:12,380
processing without consent so long as it

212
00:10:12,380 --> 00:10:14,540
is done for legitimate business purposes

213
00:10:14,540 --> 00:10:17,960
and does not intrude on the rights of

214
00:10:17,960 --> 00:10:21,410
the individual to proceed organizations

215
00:10:21,410 --> 00:10:24,440
must conduct a balancing test to waive

216
00:10:24,440 --> 00:10:26,600
the interest of the organization against

217
00:10:26,600 --> 00:10:29,870
those of the individual a solution for

218
00:10:29,870 --> 00:10:31,520
Canada might be to broaden the

219
00:10:31,520 --> 00:10:33,740
permissible grounds for processing under

220
00:10:33,740 --> 00:10:36,590
pipita to include legitimate business

221
00:10:36,590 --> 00:10:41,570
interests subject to a balancing test we

222
00:10:41,570 --> 00:10:43,790
might also consider legislating no-go

223
00:10:43,790 --> 00:10:46,760
zones which prohibit the collection use

224
00:10:46,760 --> 00:10:49,460
or disclosure of personal information in

225
00:10:49,460 --> 00:10:52,880
certain circumstances no-go zones could

226
00:10:52,880 --> 00:10:55,670
be based on a variety of criteria such

227
00:10:55,670 --> 00:10:58,460
as the sensitivity of the data the

228
00:10:58,460 --> 00:11:00,470
nature of the proposed use or disclosure

229
00:11:00,470 --> 00:11:03,740
or vulnerabilities associated with the

230
00:11:03,740 --> 00:11:06,310
group whose data is being processed in

231
00:11:06,310 --> 00:11:09,620
our policy position on online behavioral

232
00:11:09,620 --> 00:11:11,960
advertising for instance we've

233
00:11:11,960 --> 00:11:13,640
identified the funeral go zones

234
00:11:13,640 --> 00:11:15,680
including the tracking of children and

235
00:11:15,680 --> 00:11:18,590
the use of tracking methods users can't

236
00:11:18,590 --> 00:11:26,870
control now what should be the role of

237
00:11:26,870 --> 00:11:31,850
organizations under pipita organizations

238
00:11:31,850 --> 00:11:33,590
are already accountable for meeting

239
00:11:33,590 --> 00:11:35,180
their obligations to protect their

240
00:11:35,180 --> 00:11:38,000
customers personal information but

241
00:11:38,000 --> 00:11:39,620
certain governance solutions could

242
00:11:39,620 --> 00:11:41,600
further strengthen accountability

243
00:11:41,600 --> 00:11:45,710
mechanisms codes of practice and privacy

244
00:11:45,710 --> 00:11:48,590
trust marks for example can provide an

245
00:11:48,590 --> 00:11:50,300
added measure of predictability and

246
00:11:50,300 --> 00:11:52,480
consistency for companies in

247
00:11:52,480 --> 00:11:54,740
understanding their obligations around

248
00:11:54,740 --> 00:11:56,990
meaningful consent and appropriate

249
00:11:56,990 --> 00:12:00,410
limits on data processing they may also

250
00:12:00,410 --> 00:12:02,870
offer greater clarity for individuals

251
00:12:02,870 --> 00:12:04,820
that their information is being

252
00:12:04,820 --> 00:12:06,710
processed in a transparent and fair

253
00:12:06,710 --> 00:12:08,870
manner that is in line with their

254
00:12:08,870 --> 00:12:12,980
expectations these codes of practice and

255
00:12:12,980 --> 00:12:15,260
privacy trust marks may be voluntary

256
00:12:15,260 --> 00:12:18,410
best practices promoted by industry

257
00:12:18,410 --> 00:12:21,199
or they could be developed by regulators

258
00:12:21,199 --> 00:12:26,089
to serve as an enforcement tool under

259
00:12:26,089 --> 00:12:27,829
Cappetta my office has a mandate to

260
00:12:27,829 --> 00:12:29,930
encourage organizations to adopt

261
00:12:29,930 --> 00:12:32,810
instruments such as policies policies

262
00:12:32,810 --> 00:12:35,329
and codes of practice that are in line

263
00:12:35,329 --> 00:12:38,540
with legislative requirements up to now

264
00:12:38,540 --> 00:12:40,519
however this is not a provision we have

265
00:12:40,519 --> 00:12:45,589
fully explored some commentators suggest

266
00:12:45,589 --> 00:12:48,110
that in the age of big data where future

267
00:12:48,110 --> 00:12:49,970
uses of personal information are

268
00:12:49,970 --> 00:12:52,279
difficult to predict at the time it is

269
00:12:52,279 --> 00:12:55,220
collected organizations should be able

270
00:12:55,220 --> 00:12:58,100
to determine for themselves based on the

271
00:12:58,100 --> 00:12:59,689
advice of boards of ethics and

272
00:12:59,689 --> 00:13:02,569
accountability principles how data may

273
00:13:02,569 --> 00:13:04,100
be used without the consent of

274
00:13:04,100 --> 00:13:07,879
individuals should the private sector be

275
00:13:07,879 --> 00:13:10,569
allowed to self-regulate in that manner

276
00:13:10,569 --> 00:13:13,069
should legislation be amended to

277
00:13:13,069 --> 00:13:15,589
authorize any use found appropriate by

278
00:13:15,589 --> 00:13:17,899
an Ethics Board or should limits be

279
00:13:17,899 --> 00:13:21,220
outlined in law in cases where

280
00:13:21,220 --> 00:13:23,509
organizations have the ability to decide

281
00:13:23,509 --> 00:13:25,839
whether data users are fair and ethical

282
00:13:25,839 --> 00:13:30,759
what role should regulators play

283
00:13:33,880 --> 00:13:36,649
accountability based solutions rely on

284
00:13:36,649 --> 00:13:38,480
organizations to develop and implement

285
00:13:38,480 --> 00:13:40,149
measures that respect their privacy

286
00:13:40,149 --> 00:13:43,040
obligations including their obligation

287
00:13:43,040 --> 00:13:46,250
to maintain meaningful consent while

288
00:13:46,250 --> 00:13:47,959
there are positive aspects to the

289
00:13:47,959 --> 00:13:49,939
ethical framework proposals discussed

290
00:13:49,939 --> 00:13:52,850
earlier the process is internal to the

291
00:13:52,850 --> 00:13:55,639
organization which inevitably places its

292
00:13:55,639 --> 00:13:59,660
interests ahead of others independent

293
00:13:59,660 --> 00:14:01,699
oversight bodies are needed to ensure

294
00:14:01,699 --> 00:14:04,130
balance between the privacy rights of

295
00:14:04,130 --> 00:14:06,829
individuals and the legitimate need of

296
00:14:06,829 --> 00:14:08,689
organisations to collect views and

297
00:14:08,689 --> 00:14:12,170
disclose personal information where

298
00:14:12,170 --> 00:14:15,069
consent is impracticable and

299
00:14:15,069 --> 00:14:17,300
organizations have a greater role in

300
00:14:17,300 --> 00:14:19,459
deciding appropriate uses for personal

301
00:14:19,459 --> 00:14:21,949
information the need for regulatory

302
00:14:21,949 --> 00:14:24,010
bodies becomes even more

303
00:14:24,010 --> 00:14:29,080
compelling so what attributes and

304
00:14:29,080 --> 00:14:31,750
authorities should a regulator have in

305
00:14:31,750 --> 00:14:33,430
order to be truly effective in

306
00:14:33,430 --> 00:14:34,930
protecting the privacy rights of

307
00:14:34,930 --> 00:14:38,470
individuals order making powers and

308
00:14:38,470 --> 00:14:41,710
fines are some examples of enforcement

309
00:14:41,710 --> 00:14:43,680
measures that could influence

310
00:14:43,680 --> 00:14:46,300
organizations practices and strengthen

311
00:14:46,300 --> 00:14:49,240
privacy protections for individuals in a

312
00:14:49,240 --> 00:14:50,950
world where the traditional consent

313
00:14:50,950 --> 00:14:55,030
model is under significant stress the

314
00:14:55,030 --> 00:14:57,490
ability to levy fines currently exists

315
00:14:57,490 --> 00:14:59,440
in the data protection laws of some

316
00:14:59,440 --> 00:15:02,260
European countries as well as in the

317
00:15:02,260 --> 00:15:04,120
European Union's new general data

318
00:15:04,120 --> 00:15:07,540
protection regulation while EU and US

319
00:15:07,540 --> 00:15:11,020
regulators have order making powers my

320
00:15:11,020 --> 00:15:12,760
office on the other hand can only make

321
00:15:12,760 --> 00:15:15,760
non-binding recommendations and has no

322
00:15:15,760 --> 00:15:17,680
power to order a company to comply or

323
00:15:17,680 --> 00:15:21,730
levy fines it's also worth noting that

324
00:15:21,730 --> 00:15:23,890
our current enforcement regime operates

325
00:15:23,890 --> 00:15:26,920
on a complaint based model a privacy

326
00:15:26,920 --> 00:15:29,350
incident occurs somebody complains to my

327
00:15:29,350 --> 00:15:31,870
office and we determine whether the

328
00:15:31,870 --> 00:15:35,040
there are grounds to investigate a

329
00:15:35,040 --> 00:15:38,080
proactive enforcement model would

330
00:15:38,080 --> 00:15:40,180
involve intervening at an earlier stage

331
00:15:40,180 --> 00:15:42,490
to ensure an organization is complying

332
00:15:42,490 --> 00:15:45,250
with measures such as no-go zones or

333
00:15:45,250 --> 00:15:48,010
legitimate purposes legitimate business

334
00:15:48,010 --> 00:15:50,500
interest provisions this could be done

335
00:15:50,500 --> 00:15:52,600
for it for example through spot checks

336
00:15:52,600 --> 00:15:57,340
or compliance reviews these potential

337
00:15:57,340 --> 00:15:59,500
solutions raise an important question

338
00:15:59,500 --> 00:16:02,440
for my office as the federal regulator

339
00:16:02,440 --> 00:16:04,390
should we be given additional powers to

340
00:16:04,390 --> 00:16:07,090
oversee compliance and enforce knee or

341
00:16:07,090 --> 00:16:10,270
enhance consent rules certainly this

342
00:16:10,270 --> 00:16:11,620
would bring us more in line with our

343
00:16:11,620 --> 00:16:14,590
counterparts and provinces with private

344
00:16:14,590 --> 00:16:16,540
sector privacy legislation that is

345
00:16:16,540 --> 00:16:19,660
substantially similar to pipita as well

346
00:16:19,660 --> 00:16:22,960
as regulators in the US and the EU which

347
00:16:22,960 --> 00:16:25,900
have order making powers but of course

348
00:16:25,900 --> 00:16:28,390
regulators are only part of the puzzle

349
00:16:28,390 --> 00:16:31,210
as I've said before individuals

350
00:16:31,210 --> 00:16:33,939
organizations and legislators

351
00:16:33,939 --> 00:16:38,949
to have a role to play in any case these

352
00:16:38,949 --> 00:16:40,329
are the questions I hope to answer

353
00:16:40,329 --> 00:16:42,669
during this important consultation

354
00:16:42,669 --> 00:16:46,239
process and we look forward to hearing

355
00:16:46,239 --> 00:16:49,899
your views you've seen I think on the

356
00:16:49,899 --> 00:16:52,359
screen the timetable that we have in

357
00:16:52,359 --> 00:16:56,259
mind so today we're in mid-may making

358
00:16:56,259 --> 00:16:59,649
public our consultation paper we would

359
00:16:59,649 --> 00:17:03,009
hope to receive views from those who are

360
00:17:03,009 --> 00:17:06,459
interested by mid-july and in the fall

361
00:17:06,459 --> 00:17:10,779
we will proceed with meetings and other

362
00:17:10,779 --> 00:17:13,959
ways to consult much along the way as we

363
00:17:13,959 --> 00:17:17,949
used to define the private the strategic

364
00:17:17,949 --> 00:17:24,669
priorities of the office last year a few

365
00:17:24,669 --> 00:17:27,250
words sorry a few words now on Privacy

366
00:17:27,250 --> 00:17:29,819
Act reform

367
00:17:34,760 --> 00:17:37,679
as you may know I've recently testified

368
00:17:37,679 --> 00:17:39,870
and submitted recommendations on private

369
00:17:39,870 --> 00:17:41,490
Privacy Act reform to a parliamentary

370
00:17:41,490 --> 00:17:44,880
committee I'm hopeful this issue will be

371
00:17:44,880 --> 00:17:46,559
a priority for the government as the

372
00:17:46,559 --> 00:17:49,170
basic protections and rights guaranteed

373
00:17:49,170 --> 00:17:51,150
by the legislation had not been updated

374
00:17:51,150 --> 00:17:56,880
since 1983 it goes without saying that

375
00:17:56,880 --> 00:17:58,950
the law governing how federal

376
00:17:58,950 --> 00:18:01,559
institutions collect use this close and

377
00:18:01,559 --> 00:18:05,309
protect personal information is archaic

378
00:18:05,309 --> 00:18:07,800
it's archaic on a technological from a

379
00:18:07,800 --> 00:18:10,170
technological perspective from a

380
00:18:10,170 --> 00:18:12,000
legislative perspective and from a

381
00:18:12,000 --> 00:18:14,220
transparency perspective in terms of

382
00:18:14,220 --> 00:18:17,670
expectations of citizens so the act is

383
00:18:17,670 --> 00:18:21,600
in dire need of modernization to that

384
00:18:21,600 --> 00:18:23,250
end I've made a number of

385
00:18:23,250 --> 00:18:26,100
recommendations to Parliament 16

386
00:18:26,100 --> 00:18:28,830
altogether I won't name them here but

387
00:18:28,830 --> 00:18:31,440
for example it's important to reduce the

388
00:18:31,440 --> 00:18:33,600
over collection of data by creating an

389
00:18:33,600 --> 00:18:36,030
explicit requirement in law that

390
00:18:36,030 --> 00:18:37,830
institutions only collect information

391
00:18:37,830 --> 00:18:40,830
that is necessary for the operation of a

392
00:18:40,830 --> 00:18:43,770
program or activity we also want

393
00:18:43,770 --> 00:18:45,900
institutions to consult with my office

394
00:18:45,900 --> 00:18:47,790
on draft legislation that may impact

395
00:18:47,790 --> 00:18:52,770
privacy it's also critical given that

396
00:18:52,770 --> 00:18:55,320
technology makes information collection

397
00:18:55,320 --> 00:18:58,230
and sharing much easier that all

398
00:18:58,230 --> 00:19:00,030
information sharing between departments

399
00:19:00,030 --> 00:19:01,950
and agencies be governed by written

400
00:19:01,950 --> 00:19:04,200
agreements that should be submitted to

401
00:19:04,200 --> 00:19:07,590
my office we're also calling on

402
00:19:07,590 --> 00:19:09,030
Parliament to finally enshrine in

403
00:19:09,030 --> 00:19:10,890
statute a number of provisions that are

404
00:19:10,890 --> 00:19:12,840
not currently afforded the weight of the

405
00:19:12,840 --> 00:19:15,390
law for instance it should be a legal

406
00:19:15,390 --> 00:19:17,790
requirement that institutions employ

407
00:19:17,790 --> 00:19:20,070
appropriate safeguards to protect

408
00:19:20,070 --> 00:19:22,559
personal information an obligation that

409
00:19:22,559 --> 00:19:24,390
as you know was imposed on private

410
00:19:24,390 --> 00:19:27,559
organizations through bill s form

411
00:19:27,559 --> 00:19:30,090
government institutions ought to be

412
00:19:30,090 --> 00:19:32,429
bound by law to notify my office of

413
00:19:32,429 --> 00:19:35,100
serious privacy breaches another

414
00:19:35,100 --> 00:19:39,240
obligation imposed on companies privacy

415
00:19:39,240 --> 00:19:41,130
impact assessments for new or

416
00:19:41,130 --> 00:19:42,940
substantially redesigned program

417
00:19:42,940 --> 00:19:45,010
and services should be illegal

418
00:19:45,010 --> 00:19:48,610
imperative we're further calling for an

419
00:19:48,610 --> 00:19:50,590
explicit public education and research

420
00:19:50,590 --> 00:19:54,130
mandate as I have in pipita the

421
00:19:54,130 --> 00:19:56,080
flexibility to publicly report on

422
00:19:56,080 --> 00:19:57,850
government privacy issues that are in

423
00:19:57,850 --> 00:19:59,170
the public interest in a more timely

424
00:19:59,170 --> 00:20:02,380
fashion not just through annual or

425
00:20:02,380 --> 00:20:06,190
special reports to Parliament and we

426
00:20:06,190 --> 00:20:08,230
also are calling for the extension of

427
00:20:08,230 --> 00:20:10,900
the Act two ministers offices and the

428
00:20:10,900 --> 00:20:14,530
Prime Minister's office without renewal

429
00:20:14,530 --> 00:20:16,360
the protections of the Privacy Act are

430
00:20:16,360 --> 00:20:18,790
proving to be increasingly out of touch

431
00:20:18,790 --> 00:20:20,710
with Canadians in terms of how they

432
00:20:20,710 --> 00:20:25,200
engage with the digital world in

433
00:20:25,200 --> 00:20:29,020
conclusion the fast-paced evolution of

434
00:20:29,020 --> 00:20:31,020
the digital economy due to constant

435
00:20:31,020 --> 00:20:33,520
technological innovation has

436
00:20:33,520 --> 00:20:35,170
fundamentally changed the privacy

437
00:20:35,170 --> 00:20:38,800
landscape we are at a critical point in

438
00:20:38,800 --> 00:20:42,450
which action is needed on a few fronts

439
00:20:42,450 --> 00:20:45,370
Privacy Act reform as I've just said is

440
00:20:45,370 --> 00:20:48,880
long overdue and the time has also come

441
00:20:48,880 --> 00:20:52,180
to seriously seriously think about the

442
00:20:52,180 --> 00:20:54,520
practicability of the current consent

443
00:20:54,520 --> 00:20:57,460
model under pipita and how it might be

444
00:20:57,460 --> 00:21:01,240
better supported or enhanced I would

445
00:21:01,240 --> 00:21:03,190
encourage you then to read our

446
00:21:03,190 --> 00:21:05,740
discussion paper and provide your

447
00:21:05,740 --> 00:21:08,920
feedback as privacy professionals your

448
00:21:08,920 --> 00:21:12,820
input will be extremely important beyond

449
00:21:12,820 --> 00:21:14,470
that I would ask that you share this

450
00:21:14,470 --> 00:21:15,910
discussion paper with your colleagues

451
00:21:15,910 --> 00:21:18,640
and friends it's critical that we hear

452
00:21:18,640 --> 00:21:21,610
not only from privacy experts but also

453
00:21:21,610 --> 00:21:25,180
from advocacy groups academics educators

454
00:21:25,180 --> 00:21:29,460
IT specialists and everyday Canadians

455
00:21:29,460 --> 00:21:33,400
with that very important discussion

456
00:21:33,400 --> 00:21:36,400
we're about to launch on the viability

457
00:21:36,400 --> 00:21:39,060
and practicability of the consent model

458
00:21:39,060 --> 00:21:42,250
that will be an important very important

459
00:21:42,250 --> 00:21:46,300
initiative in my mandate and I hope that

460
00:21:46,300 --> 00:21:49,420
through that process we find the right

461
00:21:49,420 --> 00:21:50,640
balance between

462
00:21:50,640 --> 00:21:53,430
relation and Privacy Protection with the

463
00:21:53,430 --> 00:21:56,610
goal i have set out for myself when I

464
00:21:56,610 --> 00:21:59,820
was appointed to improve the privacy

465
00:21:59,820 --> 00:22:04,189
protection of Canadians thank

466
00:22:09,870 --> 00:22:11,790
I think there's there's time for

467
00:22:11,790 --> 00:22:14,610
questions so if people do want to ask

468
00:22:14,610 --> 00:22:17,809
questions there are mics

469
00:22:34,429 --> 00:22:36,200
if there are no questions I'll just

470
00:22:36,200 --> 00:22:38,480
leave you with this thought so the you

471
00:22:38,480 --> 00:22:41,899
will see in a discussion paper a fairly

472
00:22:41,899 --> 00:22:44,899
complete not completely not completely

473
00:22:44,899 --> 00:22:48,019
exhausted but a fairly long menu of

474
00:22:48,019 --> 00:22:50,360
solutions and improvements possible to

475
00:22:50,360 --> 00:22:54,379
the consent model obviously we need your

476
00:22:54,379 --> 00:22:57,200
your comments on those that you find

477
00:22:57,200 --> 00:23:01,820
most appropriate and effective but do

478
00:23:01,820 --> 00:23:04,700
give some thought to the issue of what

479
00:23:04,700 --> 00:23:07,340
is the appropriate role of individuals

480
00:23:07,340 --> 00:23:10,759
it is their privacy that we are trying

481
00:23:10,759 --> 00:23:13,610
to protect through rules and the

482
00:23:13,610 --> 00:23:16,179
application of rules but the

483
00:23:16,179 --> 00:23:18,230
consultation cell and you know as

484
00:23:18,230 --> 00:23:22,129
experts that the consent model may have

485
00:23:22,129 --> 00:23:25,249
limits in the in the current age so

486
00:23:25,249 --> 00:23:28,779
absolutely I think we need to improve

487
00:23:28,779 --> 00:23:32,929
the information that individuals have to

488
00:23:32,929 --> 00:23:37,129
exercise meaningfully their their power

489
00:23:37,129 --> 00:23:40,190
to consent or not to consent to the

490
00:23:40,190 --> 00:23:43,190
usual information but we we also need to

491
00:23:43,190 --> 00:23:45,399
think about the role of other players

492
00:23:45,399 --> 00:23:50,990
particularly organizations and the role

493
00:23:50,990 --> 00:23:53,210
of regulators which then suggests

494
00:23:53,210 --> 00:23:56,029
perhaps certain roles for legislators

495
00:23:56,029 --> 00:23:59,269
I'm I true I'm absolutely convinced that

496
00:23:59,269 --> 00:24:02,869
many solutions can be found within the

497
00:24:02,869 --> 00:24:06,679
current pavada for instance greater use

498
00:24:06,679 --> 00:24:09,110
of cause of practice would not require

499
00:24:09,110 --> 00:24:12,950
any letters of change but it may be that

500
00:24:12,950 --> 00:24:14,990
certain solutions would require a list

501
00:24:14,990 --> 00:24:17,600
of change and I will not be signed from

502
00:24:17,600 --> 00:24:20,360
recommending changes if that is the case

503
00:24:20,360 --> 00:24:24,619
so look at the solutions that we we

504
00:24:24,619 --> 00:24:27,019
propose give you give us our comments on

505
00:24:27,019 --> 00:24:31,580
that but also give serious thought to in

506
00:24:31,580 --> 00:24:34,399
this day and age what can we ask and

507
00:24:34,399 --> 00:24:37,460
what is realistic to ask of individuals

508
00:24:37,460 --> 00:24:40,070
and if there are certain situations

509
00:24:40,070 --> 00:24:45,109
where consent is impracticable what kind

510
00:24:45,109 --> 00:24:46,140
of system do we need

511
00:24:46,140 --> 00:24:51,720
so that innovation can occur so that

512
00:24:51,720 --> 00:24:54,900
business interests can be fulfilled but

513
00:24:54,900 --> 00:24:58,110
in a way that truly respects the privacy

514
00:24:58,110 --> 00:25:01,050
of ions and individuals I'll leave you

515
00:25:01,050 --> 00:25:04,010
with that thought thank you

