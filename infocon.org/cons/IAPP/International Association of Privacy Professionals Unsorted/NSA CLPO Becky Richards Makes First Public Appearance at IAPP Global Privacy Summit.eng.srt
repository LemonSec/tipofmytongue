1
00:00:04,120 --> 00:00:05,920
my name is sam pfeifle I'm our

2
00:00:05,920 --> 00:00:08,950
publications director at the IPP thank

3
00:00:08,950 --> 00:00:13,150
you all for being here our next panel

4
00:00:13,150 --> 00:00:15,779
something that we're very excited about

5
00:00:15,779 --> 00:00:18,940
Rebecca Richards

6
00:00:18,940 --> 00:00:22,939
at NSA organization may be heard about

7
00:00:22,939 --> 00:00:25,970
this a little bit lately and she's been

8
00:00:25,970 --> 00:00:29,150
a long long time member and supporter of

9
00:00:29,150 --> 00:00:31,700
the IEP and we're really thrilled that

10
00:00:31,700 --> 00:00:35,090
she chose to come and her first speaking

11
00:00:35,090 --> 00:00:37,180
parents with us here at the Senate and

12
00:00:37,180 --> 00:00:40,489
hey guys all for coming to see that I

13
00:00:40,489 --> 00:00:44,540
wanna thank Dan moistener he is the most

14
00:00:44,540 --> 00:00:48,980
recent leadership has worked in a White

15
00:00:48,980 --> 00:00:52,519
House is now at MIT and really one of

16
00:00:52,519 --> 00:00:56,720
the first people that to set this

17
00:00:56,720 --> 00:01:03,739
conversation up so being here let them

18
00:01:03,739 --> 00:01:06,530
take a come here and you said welcome

19
00:01:06,530 --> 00:01:08,650
back

20
00:01:12,610 --> 00:01:16,039
so this is a great opportunity for me

21
00:01:16,039 --> 00:01:19,850
because that case a really old friend we

22
00:01:19,850 --> 00:01:22,729
realized that we met in two thousand on

23
00:01:22,729 --> 00:01:24,979
the platform for privacy preferences

24
00:01:24,979 --> 00:01:27,500
working group that he just informed me

25
00:01:27,500 --> 00:01:31,210
that she wrote health policy for trustee

26
00:01:31,210 --> 00:01:35,240
she she went on to be one of the first

27
00:01:35,240 --> 00:01:40,039
hires at the new DHS privacy office she

28
00:01:40,039 --> 00:01:43,369
had an extraordinary run there she's

29
00:01:43,369 --> 00:01:46,250
really well known to all of you she's

30
00:01:46,250 --> 00:01:47,929
part of the leadership of the I it he'd

31
00:01:47,929 --> 00:01:53,390
be helping with the government cipd

32
00:01:53,390 --> 00:01:57,830
certification development I you know she

33
00:01:57,830 --> 00:02:00,560
got tremendous accolades when when she

34
00:02:00,560 --> 00:02:02,090
was announced for this position that

35
00:02:02,090 --> 00:02:07,099
he's been just such a expert and a

36
00:02:07,099 --> 00:02:09,979
serious focus worker I'm very excited

37
00:02:09,979 --> 00:02:12,890
that she's now in a leadership position

38
00:02:12,890 --> 00:02:16,250
a principle as we would say in the

39
00:02:16,250 --> 00:02:22,220
government and Adam I'm very lucky to be

40
00:02:22,220 --> 00:02:24,260
here because I haven't actually had a

41
00:02:24,260 --> 00:02:26,090
chance to talk with Becky about what new

42
00:02:26,090 --> 00:02:27,920
jobs like and what it's bad so that's

43
00:02:27,920 --> 00:02:29,260
what we're going to do here

44
00:02:29,260 --> 00:02:32,409
a few of our friends so what are you

45
00:02:32,409 --> 00:02:40,569
doing so some of you may know back in

46
00:02:40,569 --> 00:02:42,489
August the president announced that it

47
00:02:42,489 --> 00:02:44,379
was time to create a new leadership

48
00:02:44,379 --> 00:02:46,569
position at NSA the Civil of recent

49
00:02:46,569 --> 00:02:49,450
privacy on the server decision and after

50
00:02:49,450 --> 00:02:51,909
quite a bit of thought I threw my hat in

51
00:02:51,909 --> 00:02:55,780
and was honored to be chosen and i

52
00:02:55,780 --> 00:03:00,909
started this is week five so it's been

53
00:03:00,909 --> 00:03:03,210
drinking from a fire

54
00:03:03,210 --> 00:03:05,610
and a lot of people have had a lot of

55
00:03:05,610 --> 00:03:07,290
thoughts of what is it you're doing and

56
00:03:07,290 --> 00:03:09,780
why are you that's a crazy job for you

57
00:03:09,780 --> 00:03:12,690
to take but it's actually really excited

58
00:03:12,690 --> 00:03:16,650
it's a real opportunity NSA is in a

59
00:03:16,650 --> 00:03:19,860
place where it's time to think about

60
00:03:19,860 --> 00:03:21,810
what we can do to make some shifts and

61
00:03:21,810 --> 00:03:23,820
what they're doing but also to help them

62
00:03:23,820 --> 00:03:25,740
learn to speak and tell their own story

63
00:03:25,740 --> 00:03:27,750
this is an agency that's known as no

64
00:03:27,750 --> 00:03:30,780
such agency they haven't had to speak

65
00:03:30,780 --> 00:03:33,960
their your intelligence folks you don't

66
00:03:33,960 --> 00:03:37,830
want them to talk and so this is them

67
00:03:37,830 --> 00:03:40,140
learning you know how to talk about all

68
00:03:40,140 --> 00:03:42,600
the things that they do as it relates to

69
00:03:42,600 --> 00:03:45,150
compliance in a way that people

70
00:03:45,150 --> 00:03:48,960
understand outside of that building so

71
00:03:48,960 --> 00:03:53,100
so you've been a privacy officer in

72
00:03:53,100 --> 00:03:54,720
government practically since the

73
00:03:54,720 --> 00:03:57,630
beginning of that being a think that

74
00:03:57,630 --> 00:04:00,150
anyone can do I just curious question

75
00:04:00,150 --> 00:04:03,870
what do you think is going to be special

76
00:04:03,870 --> 00:04:05,580
especially interesting especially

77
00:04:05,580 --> 00:04:09,060
challenging different about being an

78
00:04:09,060 --> 00:04:10,620
intelligence agency of course you had

79
00:04:10,620 --> 00:04:13,530
Intelligence functions in DHS but as you

80
00:04:13,530 --> 00:04:15,540
say you're now really in developing

81
00:04:15,540 --> 00:04:16,860
these what do you think is going to be

82
00:04:16,860 --> 00:04:18,149
different

83
00:04:18,149 --> 00:04:21,370
well so transparency is definitely going

84
00:04:21,370 --> 00:04:25,960
to be different you don't want your

85
00:04:25,960 --> 00:04:27,730
adversaries to know what you're doing

86
00:04:27,730 --> 00:04:29,710
and that intelligence when you're doing

87
00:04:29,710 --> 00:04:31,810
national security work there are real

88
00:04:31,810 --> 00:04:33,430
threats people have talked about those

89
00:04:33,430 --> 00:04:35,230
real threats so we need to protect what

90
00:04:35,230 --> 00:04:37,600
we're doing but we also need to be more

91
00:04:37,600 --> 00:04:40,419
transparent so I think a lot of my job

92
00:04:40,419 --> 00:04:44,520
will be translating from NSA speak to

93
00:04:44,520 --> 00:04:47,830
public speak and beginning to explain in

94
00:04:47,830 --> 00:04:50,110
a little bit clearer way what are the

95
00:04:50,110 --> 00:04:51,910
protections are in place what are we

96
00:04:51,910 --> 00:04:55,000
doing why are we doing that and you know

97
00:04:55,000 --> 00:04:57,100
it's been interesting I've got a lot of

98
00:04:57,100 --> 00:04:59,110
power point presentations so far and

99
00:04:59,110 --> 00:05:01,440
I've gotten a lot of legal court orders

100
00:05:01,440 --> 00:05:04,030
there's not a lot of planning some of us

101
00:05:04,030 --> 00:05:05,760
have some of their presentations

102
00:05:05,760 --> 00:05:11,590
actually have you got what you need to

103
00:05:11,590 --> 00:05:13,120
actually be able to talk about things so

104
00:05:13,120 --> 00:05:15,100
one of the things we really did at DHS

105
00:05:15,100 --> 00:05:18,040
was what I have turned the grandmother

106
00:05:18,040 --> 00:05:20,470
test can you write a privacy impact

107
00:05:20,470 --> 00:05:21,610
assessment that your grandmother

108
00:05:21,610 --> 00:05:24,400
understands I'm not sure our pjs always

109
00:05:24,400 --> 00:05:25,840
meant that standard but it was

110
00:05:25,840 --> 00:05:28,390
definitely the gold and people began to

111
00:05:28,390 --> 00:05:29,710
understand like what is it you're doing

112
00:05:29,710 --> 00:05:31,450
and I think that's a lot of what we want

113
00:05:31,450 --> 00:05:34,870
to think about for NSA and they're all

114
00:05:34,870 --> 00:05:37,300
learning to speak and you know they have

115
00:05:37,300 --> 00:05:40,900
spent their entire career not going home

116
00:05:40,900 --> 00:05:43,150
not talking to people about what they do

117
00:05:43,150 --> 00:05:46,570
not know but also really internalizing I

118
00:05:46,570 --> 00:05:48,220
was really surprised I've never

119
00:05:48,220 --> 00:05:49,870
surprised but all of their literature

120
00:05:49,870 --> 00:05:52,360
free media leaks still talks about

121
00:05:52,360 --> 00:05:55,700
privacy these people have in their vain

122
00:05:55,700 --> 00:05:57,350
they are protecting privacy that they

123
00:05:57,350 --> 00:05:59,840
are protecting us persons but they have

124
00:05:59,840 --> 00:06:02,210
never had to talk about it and so that's

125
00:06:02,210 --> 00:06:05,990
a relief so I'm curious you've been

126
00:06:05,990 --> 00:06:08,330
there obviously not such a long time but

127
00:06:08,330 --> 00:06:09,530
you've probably talked to a lot of

128
00:06:09,530 --> 00:06:12,680
people what could you tell us about what

129
00:06:12,680 --> 00:06:17,000
the move is since the Snowden

130
00:06:17,000 --> 00:06:20,810
revelations or people are they pissed

131
00:06:20,810 --> 00:06:22,940
off are they depressed do they feel

132
00:06:22,940 --> 00:06:25,220
misunderstood do they feel angry we're

133
00:06:25,220 --> 00:06:28,130
weird if you could I don't expect you to

134
00:06:28,130 --> 00:06:29,600
generalize but really interesting to

135
00:06:29,600 --> 00:06:31,460
have some sense of a large number of

136
00:06:31,460 --> 00:06:33,670
people they've got obviously a strong

137
00:06:33,670 --> 00:06:39,740
mission-driven ethos we're we're are

138
00:06:39,740 --> 00:06:43,370
they now now that the spotlight is on

139
00:06:43,370 --> 00:06:46,790
them fairly or otherwise probably all of

140
00:06:46,790 --> 00:06:49,510
those emotions in some way shape or form

141
00:06:49,510 --> 00:06:52,310
but what I have been struck by is this

142
00:06:52,310 --> 00:06:54,920
is an organization that is very

143
00:06:54,920 --> 00:06:57,860
compliant so they have a set of rules

144
00:06:57,860 --> 00:06:59,840
and they have a very strong culture of

145
00:06:59,840 --> 00:07:02,600
compliance and so they look at what is

146
00:07:02,600 --> 00:07:04,250
it said these are the rules that were

147
00:07:04,250 --> 00:07:07,850
set forward by the court by the AG and

148
00:07:07,850 --> 00:07:10,520
we have followed those and so to have

149
00:07:10,520 --> 00:07:13,610
people come in and say this is you know

150
00:07:13,610 --> 00:07:15,200
what you're doing is horrible I think

151
00:07:15,200 --> 00:07:16,490
it's hard for them to hear because they

152
00:07:16,490 --> 00:07:18,200
don't need people you know they're doing

153
00:07:18,200 --> 00:07:20,390
this every day day in and day out and in

154
00:07:20,390 --> 00:07:22,370
their blood is protection of your

155
00:07:22,370 --> 00:07:24,650
privacy they talk about it every single

156
00:07:24,650 --> 00:07:27,080
person from you know the people down you

157
00:07:27,080 --> 00:07:29,510
know all up and down the scale talk

158
00:07:29,510 --> 00:07:32,780
about them protecting privacy my goal is

159
00:07:32,780 --> 00:07:35,510
is to help translate that so that the

160
00:07:35,510 --> 00:07:37,370
public can understand that but then also

161
00:07:37,370 --> 00:07:38,240
to look at

162
00:07:38,240 --> 00:07:41,419
understand the technology has changed so

163
00:07:41,419 --> 00:07:44,380
let's think about technology in the 80s

164
00:07:44,380 --> 00:07:46,970
we were probably on a closed network

165
00:07:46,970 --> 00:07:48,440
looking at what the Russians are doing

166
00:07:48,440 --> 00:07:49,880
and listening to what the Russians are

167
00:07:49,880 --> 00:07:52,970
doing and there's not a lot of us person

168
00:07:52,970 --> 00:07:55,280
if Eddie it's a closed Network you're

169
00:07:55,280 --> 00:07:58,220
directing it today Osama bin Laden's

170
00:07:58,220 --> 00:07:59,960
emails were passing at the same one that

171
00:07:59,960 --> 00:08:02,900
you my mother all of our email is going

172
00:08:02,900 --> 00:08:04,400
through so those are changes and

173
00:08:04,400 --> 00:08:06,169
technology that mean that the privacy

174
00:08:06,169 --> 00:08:08,419
and civil liberties concerns are

175
00:08:08,419 --> 00:08:13,159
different so I'm curious on that Fred

176
00:08:13,159 --> 00:08:15,289
you know one of the other ways that

177
00:08:15,289 --> 00:08:17,630
Becky and I have worked together is when

178
00:08:17,630 --> 00:08:20,240
when I was helping to put together the

179
00:08:20,240 --> 00:08:23,479
consumer privacy Bill of Rights updated

180
00:08:23,479 --> 00:08:27,949
his principles the frankly the best

181
00:08:27,949 --> 00:08:30,500
source of expertise that I had to draw

182
00:08:30,500 --> 00:08:32,929
and was that with the sheet privacy

183
00:08:32,929 --> 00:08:34,700
officers in the privacy of in the

184
00:08:34,700 --> 00:08:38,750
government and and including very

185
00:08:38,750 --> 00:08:42,740
significantly Becky it do you think that

186
00:08:42,740 --> 00:08:45,560
the is is the NSA staff going to get

187
00:08:45,560 --> 00:08:49,130
into the act do you think God or what do

188
00:08:49,130 --> 00:08:50,779
you think you're going to learn from the

189
00:08:50,779 --> 00:08:54,079
essay staff about about how to address

190
00:08:54,079 --> 00:08:57,800
these questions I think there's a lot

191
00:08:57,800 --> 00:09:00,260
that I have to learn about what NSA does

192
00:09:00,260 --> 00:09:02,420
and there's a lot for NSA to learn about

193
00:09:02,420 --> 00:09:05,060
what it means to build privacy and civil

194
00:09:05,060 --> 00:09:06,660
liberties into the

195
00:09:06,660 --> 00:09:08,819
and so what I want to think what I'm

196
00:09:08,819 --> 00:09:10,709
working with and a lot of what I'm doing

197
00:09:10,709 --> 00:09:12,389
right now is listening internally and

198
00:09:12,389 --> 00:09:13,740
learning what they do and then

199
00:09:13,740 --> 00:09:16,319
understanding how we can put assessments

200
00:09:16,319 --> 00:09:17,690
in how we can do a better job

201
00:09:17,690 --> 00:09:20,069
demonstrating that we have thought about

202
00:09:20,069 --> 00:09:22,980
privacy and begin to have some of those

203
00:09:22,980 --> 00:09:26,819
conversations externally I am starting

204
00:09:26,819 --> 00:09:29,910
to reach out to advocates people in this

205
00:09:29,910 --> 00:09:32,009
room I want to hear what some of your

206
00:09:32,009 --> 00:09:33,870
concerns are about what NSA is doing

207
00:09:33,870 --> 00:09:36,720
help understand whether there is a

208
00:09:36,720 --> 00:09:39,180
disagreement on the facts of what we're

209
00:09:39,180 --> 00:09:41,339
doing or if it's a misunderstanding and

210
00:09:41,339 --> 00:09:43,470
begin to build some of that bridge so

211
00:09:43,470 --> 00:09:45,269
I'm reaching I've started reaching out

212
00:09:45,269 --> 00:09:47,370
to the advocacy community to do a

213
00:09:47,370 --> 00:09:49,649
listening tour I was up in Congress this

214
00:09:49,649 --> 00:09:51,600
week and last week and again sort of

215
00:09:51,600 --> 00:09:53,699
understanding where is the disconnect is

216
00:09:53,699 --> 00:09:55,980
the disconnect on substance where's the

217
00:09:55,980 --> 00:09:59,579
disconnect on you know the way we've

218
00:09:59,579 --> 00:10:01,379
described or not described because

219
00:10:01,379 --> 00:10:05,279
transparency is not what NSA has done as

220
00:10:05,279 --> 00:10:08,279
well here too so now you you manage the

221
00:10:08,279 --> 00:10:10,199
fire hose and your first couple weeks

222
00:10:10,199 --> 00:10:12,569
what's the wedding because you're kind

223
00:10:12,569 --> 00:10:14,310
of media trip like the next couple of

224
00:10:14,310 --> 00:10:15,689
months what are you going to come back

225
00:10:15,689 --> 00:10:18,509
and tell it or whatever to me diep has

226
00:10:18,509 --> 00:10:22,860
there's kind of duties so what we're

227
00:10:22,860 --> 00:10:26,430
doing is going through and understanding

228
00:10:26,430 --> 00:10:28,529
what NSA does and we're taking a couple

229
00:10:28,529 --> 00:10:31,500
of different approaches to identify sort

230
00:10:31,500 --> 00:10:33,540
of what are the existing protections we

231
00:10:33,540 --> 00:10:37,170
have employees so NSA as I have come to

232
00:10:37,170 --> 00:10:38,370
learn has a number of different

233
00:10:38,370 --> 00:10:40,939
authorities by which we collect and I've

234
00:10:40,939 --> 00:10:42,720
because of the privacy and civil

235
00:10:42,720 --> 00:10:45,060
liberties oversight board and just start

236
00:10:45,060 --> 00:10:47,550
walking right in I'm beginning to learn

237
00:10:47,550 --> 00:10:49,589
what those are and so what we started to

238
00:10:49,589 --> 00:10:50,570
do is serve what I

239
00:10:50,570 --> 00:10:53,270
a baseline activity report that says

240
00:10:53,270 --> 00:10:55,430
here are all the protections we have in

241
00:10:55,430 --> 00:10:57,320
place if we've collect you under FISA

242
00:10:57,320 --> 00:10:59,690
here's the protection we have if we did

243
00:10:59,690 --> 00:11:03,140
it under you know 215 which is the

244
00:11:03,140 --> 00:11:04,850
business records program or here's the

245
00:11:04,850 --> 00:11:06,200
others a number of different numbers are

246
00:11:06,200 --> 00:11:08,480
under 12 executive order 12 triple cream

247
00:11:08,480 --> 00:11:10,280
so we're going to look at it that way

248
00:11:10,280 --> 00:11:12,710
but then at a separate ways to look at

249
00:11:12,710 --> 00:11:14,840
it and understand how do we do

250
00:11:14,840 --> 00:11:17,930
collections so here 24 it's been a lot

251
00:11:17,930 --> 00:11:20,660
of how do I look at I'm a u.s. person i

252
00:11:20,660 --> 00:11:24,410
am in us when kinetis i collect on you i

253
00:11:24,410 --> 00:11:28,550
am a person in germany who is a german

254
00:11:28,550 --> 00:11:30,560
when connect lectin begin to look at it

255
00:11:30,560 --> 00:11:32,360
from the individuals perspective to

256
00:11:32,360 --> 00:11:34,070
understand where and how we're doing

257
00:11:34,070 --> 00:11:37,040
some of those collections and and it's a

258
00:11:37,040 --> 00:11:39,980
portrait of taking a look at it a couple

259
00:11:39,980 --> 00:11:42,470
of different approaches and then using

260
00:11:42,470 --> 00:11:44,270
the fair information practice principles

261
00:11:44,270 --> 00:11:47,480
to begin to analyze and identify what

262
00:11:47,480 --> 00:11:51,050
the best way is and what about the long

263
00:11:51,050 --> 00:11:52,880
run what are you what are you when will

264
00:11:52,880 --> 00:11:56,860
you decide you accomplish

265
00:11:57,800 --> 00:11:59,580
everybody will think we have the best

266
00:11:59,580 --> 00:12:03,510
privacy program in the world I think the

267
00:12:03,510 --> 00:12:06,240
long term is to really build privacy

268
00:12:06,240 --> 00:12:08,880
into the cold build the concept of the

269
00:12:08,880 --> 00:12:11,370
assessments into the core of what NSA

270
00:12:11,370 --> 00:12:15,089
does and understand that when a new

271
00:12:15,089 --> 00:12:17,100
technology comes along that there is a

272
00:12:17,100 --> 00:12:19,020
conversation that's head that says I can

273
00:12:19,020 --> 00:12:21,300
do with a or I can do it be well a is

274
00:12:21,300 --> 00:12:23,970
very privacy and space of B is not I

275
00:12:23,970 --> 00:12:26,190
still get the mission we should go with

276
00:12:26,190 --> 00:12:28,560
B and have that be part of that

277
00:12:28,560 --> 00:12:31,260
conversation I think that we've done a

278
00:12:31,260 --> 00:12:32,850
pretty good job with that at Homeland

279
00:12:32,850 --> 00:12:35,040
Security over time so that people have

280
00:12:35,040 --> 00:12:36,540
that assessment in place and that would

281
00:12:36,540 --> 00:12:38,310
be that it becomes just part of what

282
00:12:38,310 --> 00:12:43,110
they do so what would be tempted to ask

283
00:12:43,110 --> 00:12:45,390
based on you know the headlines

284
00:12:45,390 --> 00:12:49,230
announcing your arrival NSA gets privacy

285
00:12:49,230 --> 00:12:52,110
civil liberties officer it's as if there

286
00:12:52,110 --> 00:12:54,420
was no one or nothing or no

287
00:12:54,420 --> 00:12:58,760
consideration about this set of issues

288
00:12:58,760 --> 00:13:01,170
before you got there is that did you

289
00:13:01,170 --> 00:13:04,740
arrive and find a wasteland what did you

290
00:13:04,740 --> 00:13:09,720
find I now see no no actually I was

291
00:13:09,720 --> 00:13:11,100
really impressed they had they actually

292
00:13:11,100 --> 00:13:14,010
did pias and so though there is privacy

293
00:13:14,010 --> 00:13:16,080
program that is happening down in the

294
00:13:16,080 --> 00:13:18,209
poly shoe shop and then ogc actually

295
00:13:18,209 --> 00:13:20,279
kind of still delivery shop and they

296
00:13:20,279 --> 00:13:21,839
were doing a really quite impressive

297
00:13:21,839 --> 00:13:23,820
data mining report that nobody would

298
00:13:23,820 --> 00:13:27,990
ever see cuz it's classified but no they

299
00:13:27,990 --> 00:13:29,580
did have both of those functions and

300
00:13:29,580 --> 00:13:31,529
they were happening they when you think

301
00:13:31,529 --> 00:13:34,770
about NSA privacy there for them was

302
00:13:34,770 --> 00:13:37,220
privacy about their employees about

303
00:13:37,220 --> 00:13:39,420
contractors about the average person

304
00:13:39,420 --> 00:13:41,580
walking down the street it was not as

305
00:13:41,580 --> 00:13:42,430
concentrated

306
00:13:42,430 --> 00:13:44,440
this is the big collection that we're

307
00:13:44,440 --> 00:13:47,860
getting through these needs and so what

308
00:13:47,860 --> 00:13:50,080
this job does is it brings it up I'm a

309
00:13:50,080 --> 00:13:52,649
direct report to the director of NSA and

310
00:13:52,649 --> 00:13:57,160
I and it just as a focal point to bring

311
00:13:57,160 --> 00:13:58,839
all of those and I walked in the

312
00:13:58,839 --> 00:14:00,430
building and people were already asking

313
00:14:00,430 --> 00:14:02,860
questions so they were sort of waiting

314
00:14:02,860 --> 00:14:04,720
for me and we're like here can you

315
00:14:04,720 --> 00:14:06,250
respond to this and what do you think of

316
00:14:06,250 --> 00:14:08,920
this and you know week to the clog

317
00:14:08,920 --> 00:14:11,470
showed up so there's been no lack of

318
00:14:11,470 --> 00:14:14,980
work and and and i know i actually had

319
00:14:14,980 --> 00:14:17,110
the chance over the last six months to

320
00:14:17,110 --> 00:14:19,089
get to know your colleague John DeLong

321
00:14:19,089 --> 00:14:22,959
who's the director of compliance he's

322
00:14:22,959 --> 00:14:26,620
actually been part of the NSA outreach

323
00:14:26,620 --> 00:14:29,470
effort as far as I can see it has been

324
00:14:29,470 --> 00:14:31,270
up at a couple of workshops that we've

325
00:14:31,270 --> 00:14:33,760
held it in my team great detectives

326
00:14:33,760 --> 00:14:36,070
perspective like the first time you came

327
00:14:36,070 --> 00:14:37,570
actually I think the second time it came

328
00:14:37,570 --> 00:14:39,670
I asked my said well I'm really glad

329
00:14:39,670 --> 00:14:41,140
you're coming can i list you on the

330
00:14:41,140 --> 00:14:43,300
agenda he said yeah i said can i list

331
00:14:43,300 --> 00:14:45,580
your agents indiana and this was a

332
00:14:45,580 --> 00:14:47,709
little surprising to be so so you see

333
00:14:47,709 --> 00:14:49,839
you some groundwork has been laid if you

334
00:14:49,839 --> 00:14:51,190
get the parents the initiative so how

335
00:14:51,190 --> 00:14:52,990
are you going to relate to the

336
00:14:52,990 --> 00:14:55,480
compliance organization so John and I

337
00:14:55,480 --> 00:14:57,580
are in each other's office every day we

338
00:14:57,580 --> 00:14:59,440
r co equals both of us report directly

339
00:14:59,440 --> 00:15:06,180
to the director he is d4 and I md5 but

340
00:15:06,180 --> 00:15:09,339
really when we think about this I think

341
00:15:09,339 --> 00:15:11,500
of module is being on the front end so

342
00:15:11,500 --> 00:15:13,750
we have it legal asking can you do this

343
00:15:13,750 --> 00:15:15,370
and I think that the privacy and civil

344
00:15:15,370 --> 00:15:17,500
liberties job will be to ask should we

345
00:15:17,500 --> 00:15:17,889
do

346
00:15:17,889 --> 00:15:20,589
and if we should how should we do it to

347
00:15:20,589 --> 00:15:22,269
reduce the amount of privacy and civil

348
00:15:22,269 --> 00:15:25,660
liberties impact John and his team's

349
00:15:25,660 --> 00:15:27,549
role is them to say okay we have these

350
00:15:27,549 --> 00:15:28,959
rules in place let's make sure that

351
00:15:28,959 --> 00:15:30,489
we're compliant with those rules and

352
00:15:30,489 --> 00:15:32,799
he's done an absolutely fantastic job so

353
00:15:32,799 --> 00:15:33,970
there's no question they're complying

354
00:15:33,970 --> 00:15:36,369
with those rules part of my job is to

355
00:15:36,369 --> 00:15:39,359
help influence what those rules are and

356
00:15:39,359 --> 00:15:41,949
identify places that we can reduce the

357
00:15:41,949 --> 00:15:43,839
risks privacy and civil liberties and

358
00:15:43,839 --> 00:15:45,549
identify different ways to mitigate

359
00:15:45,549 --> 00:15:47,589
those so what should I have asked you

360
00:15:47,589 --> 00:15:49,799
that I

361
00:15:53,910 --> 00:15:56,220
I got it all you've got it all all right

362
00:15:56,220 --> 00:15:58,640
hi thank you so much okay goodbye

363
00:15:58,640 --> 00:16:00,210
congratulations but what's forward to

364
00:16:00,210 --> 00:16:03,470
having you back thank you all

