1
00:00:08,400 --> 00:00:11,360
every day the world wakes up to news of

2
00:00:11,360 --> 00:00:13,120
privacy

3
00:00:13,120 --> 00:00:16,759
demanding attention

4
00:00:18,960 --> 00:00:20,640
we are in the midst of a digital

5
00:00:20,640 --> 00:00:22,240
revolution

6
00:00:22,240 --> 00:00:25,840
the questions the laws the consequences

7
00:00:25,840 --> 00:00:28,080
keep coming

8
00:00:28,080 --> 00:00:30,800
but our mission remains the same

9
00:00:30,800 --> 00:00:33,760
we must adapt and change as our work is

10
00:00:33,760 --> 00:00:36,559
tested and retested on an almost daily

11
00:00:36,559 --> 00:00:38,399
basis

12
00:00:38,399 --> 00:00:41,360
we believe in the power of sharing ideas

13
00:00:41,360 --> 00:00:42,840
experience and

14
00:00:42,840 --> 00:00:45,600
knowledge which calls us together to

15
00:00:45,600 --> 00:00:47,920
learn from our diverse community

16
00:00:47,920 --> 00:00:51,840
to explore the full spectrum of privacy

17
00:00:51,840 --> 00:00:57,000
we gather to answer the call

18
00:00:59,380 --> 00:01:17,040
[Music]

19
00:01:17,040 --> 00:01:20,960
hello everyone and welcome to the iapp

20
00:01:20,960 --> 00:01:23,439
global privacy summit

21
00:01:23,439 --> 00:01:26,000
my name is vivian arts and i have the

22
00:01:26,000 --> 00:01:30,079
honor of serving as the 2022 chair of

23
00:01:30,079 --> 00:01:33,840
the iapp board of directors

24
00:01:33,840 --> 00:01:37,200
and hello i am patrice ettinger i am the

25
00:01:37,200 --> 00:01:39,520
chief privacy officer at pfizer

26
00:01:39,520 --> 00:01:41,360
and i had the pleasure of serving as the

27
00:01:41,360 --> 00:01:45,280
ipp board chair in 2021

28
00:01:45,280 --> 00:01:48,079
and hello everyone i'm justin weiss i am

29
00:01:48,079 --> 00:01:49,920
the global head of data privacy at

30
00:01:49,920 --> 00:01:52,720
naspers and process i was privileged to

31
00:01:52,720 --> 00:01:56,320
serve as chair in 2020

32
00:01:56,320 --> 00:01:57,920
it has been three

33
00:01:57,920 --> 00:01:59,439
long years

34
00:01:59,439 --> 00:02:02,399
since we last gathered for an iapp

35
00:02:02,399 --> 00:02:06,560
global privacy summit here in washington

36
00:02:06,560 --> 00:02:09,280
the pandemic has affected our lives in

37
00:02:09,280 --> 00:02:10,878
countless ways

38
00:02:10,878 --> 00:02:13,680
we have lost too many family members

39
00:02:13,680 --> 00:02:16,080
friends and colleagues

40
00:02:16,080 --> 00:02:19,120
to this horrible coronavirus

41
00:02:19,120 --> 00:02:20,319
our work

42
00:02:20,319 --> 00:02:23,440
our schools our travel

43
00:02:23,440 --> 00:02:25,520
our ability to gather

44
00:02:25,520 --> 00:02:28,560
has been changed forever

45
00:02:28,560 --> 00:02:30,879
and we cannot fail to mention the

46
00:02:30,879 --> 00:02:33,280
ongoing challenges that our world faces

47
00:02:33,280 --> 00:02:36,080
yes the pandemic continues at the same

48
00:02:36,080 --> 00:02:38,560
time we bear witness to the human

49
00:02:38,560 --> 00:02:40,239
suffering that is occurring in the

50
00:02:40,239 --> 00:02:41,920
ukraine

51
00:02:41,920 --> 00:02:44,640
trevor hughes our president and ceo of

52
00:02:44,640 --> 00:02:45,760
iapp

53
00:02:45,760 --> 00:02:47,760
will be sharing some important updates

54
00:02:47,760 --> 00:02:49,840
from this stage tomorrow about the

55
00:02:49,840 --> 00:02:52,080
iappb's efforts to support those in

56
00:02:52,080 --> 00:02:54,239
crisis due to this heartbreaking

57
00:02:54,239 --> 00:02:56,800
conflict

58
00:02:56,879 --> 00:02:59,040
through all of this the iapp has

59
00:02:59,040 --> 00:03:01,599
continued to pursue its mission to serve

60
00:03:01,599 --> 00:03:03,760
all of you members of the privacy

61
00:03:03,760 --> 00:03:05,200
community

62
00:03:05,200 --> 00:03:07,040
we're very grateful to be able to come

63
00:03:07,040 --> 00:03:10,879
together after three long years

64
00:03:10,879 --> 00:03:12,879
so let's get to work

65
00:03:12,879 --> 00:03:15,840
we have a tremendous conference planned

66
00:03:15,840 --> 00:03:17,360
for all of you

67
00:03:17,360 --> 00:03:20,400
and it is my pleasure to now introduce

68
00:03:20,400 --> 00:03:22,879
our first keynote speaker

69
00:03:22,879 --> 00:03:26,159
professor amy geider

70
00:03:26,159 --> 00:03:27,599
professor geider

71
00:03:27,599 --> 00:03:30,080
teaches at tulane law school in new

72
00:03:30,080 --> 00:03:32,560
orleans and is a journalist turned

73
00:03:32,560 --> 00:03:33,680
lawyer

74
00:03:33,680 --> 00:03:36,000
she is recognized internationally for

75
00:03:36,000 --> 00:03:38,400
her expertise in privacy

76
00:03:38,400 --> 00:03:39,840
media law

77
00:03:39,840 --> 00:03:43,360
totes and the law of higher education

78
00:03:43,360 --> 00:03:45,599
her scholarship explores the tensions

79
00:03:45,599 --> 00:03:48,000
between social regulation

80
00:03:48,000 --> 00:03:50,640
and first amendment values

81
00:03:50,640 --> 00:03:53,200
particularly the shifting boundaries of

82
00:03:53,200 --> 00:03:54,879
press freedoms

83
00:03:54,879 --> 00:03:57,760
and rising public anxieties

84
00:03:57,760 --> 00:04:01,280
about the erosion of privacy

85
00:04:01,280 --> 00:04:03,680
professor guida's latest book seek and

86
00:04:03,680 --> 00:04:06,000
hide the tangled history of the right to

87
00:04:06,000 --> 00:04:09,519
privacy is being released today

88
00:04:09,519 --> 00:04:11,519
there are limited copies available to

89
00:04:11,519 --> 00:04:13,519
you at our bookstore just after the

90
00:04:13,519 --> 00:04:14,879
session

91
00:04:14,879 --> 00:04:17,120
please join us in welcoming professor

92
00:04:17,120 --> 00:04:19,490
guida to the stage

93
00:04:19,490 --> 00:04:45,429
[Music]

94
00:04:46,080 --> 00:04:49,120
hi everyone i'm i'm absolutely uh

95
00:04:49,120 --> 00:04:52,000
delighted to be here

96
00:04:52,000 --> 00:04:53,759
and i'm here because i wanted to

97
00:04:53,759 --> 00:04:57,759
introduce you to re-introduce you really

98
00:04:57,759 --> 00:05:00,000
to a man you surely

99
00:05:00,000 --> 00:05:01,680
already know

100
00:05:01,680 --> 00:05:03,680
it's louis brandeis

101
00:05:03,680 --> 00:05:05,440
this man

102
00:05:05,440 --> 00:05:07,680
louis brandeis is famous in privacy

103
00:05:07,680 --> 00:05:10,880
circles for a lot of reasons he co-wrote

104
00:05:10,880 --> 00:05:13,280
with sam warren the right to privacy the

105
00:05:13,280 --> 00:05:16,560
harvard law review article from 1890

106
00:05:16,560 --> 00:05:18,479
that laid the groundwork for much of our

107
00:05:18,479 --> 00:05:20,800
privacy law today

108
00:05:20,800 --> 00:05:23,639
he had offered a powerful stinging and

109
00:05:23,639 --> 00:05:26,320
nation-changing descent in the olmstead

110
00:05:26,320 --> 00:05:28,800
wiretapping case that today gives us

111
00:05:28,800 --> 00:05:30,800
privacy protections against police

112
00:05:30,800 --> 00:05:33,919
investigations and so much more

113
00:05:33,919 --> 00:05:36,320
we know a lot about brandeis and the way

114
00:05:36,320 --> 00:05:39,520
he influenced our privacy interests but

115
00:05:39,520 --> 00:05:42,080
what isn't as well known is the way that

116
00:05:42,080 --> 00:05:45,919
certain privacy interests influenced him

117
00:05:45,919 --> 00:05:47,440
and that's what i want to share with you

118
00:05:47,440 --> 00:05:48,400
today

119
00:05:48,400 --> 00:05:50,800
three examples of the sorts of things

120
00:05:50,800 --> 00:05:53,440
that stirred privacy concerns in this

121
00:05:53,440 --> 00:05:56,639
father of sorts of american privacy

122
00:05:56,639 --> 00:05:58,560
three stories that you may not have

123
00:05:58,560 --> 00:06:00,319
heard before

124
00:06:00,319 --> 00:06:02,240
and i'll do this in pictures for two

125
00:06:02,240 --> 00:06:03,919
reasons

126
00:06:03,919 --> 00:06:06,880
first because visual images motivated

127
00:06:06,880 --> 00:06:09,680
brandeis and his co-author worn in a big

128
00:06:09,680 --> 00:06:10,880
way

129
00:06:10,880 --> 00:06:13,440
visuals show the technology in play at

130
00:06:13,440 --> 00:06:15,680
the time they wrote the right to privacy

131
00:06:15,680 --> 00:06:17,919
and beyond and these images will help

132
00:06:17,919 --> 00:06:20,319
explain precisely why people were so

133
00:06:20,319 --> 00:06:23,120
worried about privacy back then

134
00:06:23,120 --> 00:06:25,840
second because if you're like me some of

135
00:06:25,840 --> 00:06:27,759
these images some of the stories that go

136
00:06:27,759 --> 00:06:29,840
with the images might surprise you

137
00:06:29,840 --> 00:06:33,440
because of the power of the invasions

138
00:06:33,440 --> 00:06:34,639
first

139
00:06:34,639 --> 00:06:36,319
this

140
00:06:36,319 --> 00:06:39,199
this is an image from a book titled cape

141
00:06:39,199 --> 00:06:43,280
cod folks published in 1881

142
00:06:43,280 --> 00:06:46,080
it's a sketch of grandpa fisher

143
00:06:46,080 --> 00:06:49,039
a character who is hopelessly weak

144
00:06:49,039 --> 00:06:51,840
confused and defenseless

145
00:06:51,840 --> 00:06:55,599
here he's dying his scraggly gray hair

146
00:06:55,599 --> 00:06:58,240
black so that he might look like a man

147
00:06:58,240 --> 00:07:01,280
of thirty only to end up in the author's

148
00:07:01,280 --> 00:07:04,800
assessment neither old nor young human

149
00:07:04,800 --> 00:07:06,960
nor inhuman

150
00:07:06,960 --> 00:07:08,880
trouble was the grandpa fisher was a

151
00:07:08,880 --> 00:07:12,160
real person he really looked like this

152
00:07:12,160 --> 00:07:15,280
this hair dying thing really happened

153
00:07:15,280 --> 00:07:17,440
and the author who wrote cape cod folks

154
00:07:17,440 --> 00:07:20,080
had lived in this very real small town

155
00:07:20,080 --> 00:07:21,440
on cape cod

156
00:07:21,440 --> 00:07:23,599
had worked as a teacher there and had

157
00:07:23,599 --> 00:07:25,759
taken fastidious notes about her

158
00:07:25,759 --> 00:07:29,039
interactions with residents there

159
00:07:29,039 --> 00:07:31,599
cape cod folks was a true expose of

160
00:07:31,599 --> 00:07:33,280
small town life

161
00:07:33,280 --> 00:07:36,479
the day's reality television so to speak

162
00:07:36,479 --> 00:07:39,039
but there were no stars here

163
00:07:39,039 --> 00:07:40,960
one woman died

164
00:07:40,960 --> 00:07:42,840
the official cause of her death was

165
00:07:42,840 --> 00:07:45,280
consumption but everybody knew what had

166
00:07:45,280 --> 00:07:46,879
really killed her

167
00:07:46,879 --> 00:07:49,840
the unpleasant notoriety forced upon her

168
00:07:49,840 --> 00:07:53,280
by that book as her doctor put it

169
00:07:53,280 --> 00:07:55,759
lewis brandeis relatively brand new

170
00:07:55,759 --> 00:07:58,160
attorney handled the case not on her

171
00:07:58,160 --> 00:08:00,560
behalf or her family's behalf

172
00:08:00,560 --> 00:08:04,080
but on behalf of the publisher

173
00:08:04,080 --> 00:08:05,599
what's important here though is that

174
00:08:05,599 --> 00:08:07,440
brandeis argued in effect that this was

175
00:08:07,440 --> 00:08:10,319
indeed an invasion of grandpa fisher's

176
00:08:10,319 --> 00:08:13,440
privacy along with all of the others

177
00:08:13,440 --> 00:08:15,520
it's just that this sort of privacy

178
00:08:15,520 --> 00:08:18,400
invasion didn't yet exist in law he

179
00:08:18,400 --> 00:08:19,680
argued

180
00:08:19,680 --> 00:08:21,919
therefore instead the cape cod folks

181
00:08:21,919 --> 00:08:24,960
book was only a breach of the canons of

182
00:08:24,960 --> 00:08:28,080
propriety and good manners not a legal

183
00:08:28,080 --> 00:08:29,599
violation

184
00:08:29,599 --> 00:08:31,360
the civil law didn't yet address

185
00:08:31,360 --> 00:08:33,120
eavesdropping or looking into one's

186
00:08:33,120 --> 00:08:35,440
windows either brandeis noted so it

187
00:08:35,440 --> 00:08:37,360
certainly didn't recognize this

188
00:08:37,360 --> 00:08:40,320
publication related invasion of the

189
00:08:40,320 --> 00:08:43,599
plaintiff's domestic privacy

190
00:08:43,599 --> 00:08:46,320
later probably not coincidentally just

191
00:08:46,320 --> 00:08:48,720
after brandeis's cousin went missing in

192
00:08:48,720 --> 00:08:51,680
new york city with resulting sensational

193
00:08:51,680 --> 00:08:53,440
press coverage about what may have

194
00:08:53,440 --> 00:08:54,399
happened

195
00:08:54,399 --> 00:08:57,440
brandeis settled the cape cod folks case

196
00:08:57,440 --> 00:08:59,760
that meant that grandpa fisher and all

197
00:08:59,760 --> 00:09:02,399
the outed others got money for their

198
00:09:02,399 --> 00:09:04,720
emotional pain because of what even

199
00:09:04,720 --> 00:09:07,200
brandeis the attorney for the publisher

200
00:09:07,200 --> 00:09:11,279
believed was a privacy invasion

201
00:09:11,279 --> 00:09:13,920
second this

202
00:09:13,920 --> 00:09:16,800
nine years after cape cod folks

203
00:09:16,800 --> 00:09:19,200
this copy of new york illustrated news

204
00:09:19,200 --> 00:09:20,480
came out

205
00:09:20,480 --> 00:09:23,519
it was september of 1890 and that was

206
00:09:23,519 --> 00:09:25,279
three months before brandeis would

207
00:09:25,279 --> 00:09:27,680
publish the right to privacy complaining

208
00:09:27,680 --> 00:09:30,720
about precisely this sort of thing

209
00:09:30,720 --> 00:09:33,680
the headline reads caught by a camera

210
00:09:33,680 --> 00:09:35,040
fiend

211
00:09:35,040 --> 00:09:38,240
the caption a society young lady of red

212
00:09:38,240 --> 00:09:40,800
bank new jersey while sunning herself

213
00:09:40,800 --> 00:09:43,440
after her morning bath is photog

214
00:09:43,440 --> 00:09:46,160
photographed in her gay and limited

215
00:09:46,160 --> 00:09:49,360
attire by a snapshot from a stranger's

216
00:09:49,360 --> 00:09:51,040
camera

217
00:09:51,040 --> 00:09:54,200
and indeed there off to the right of the

218
00:09:54,200 --> 00:09:57,200
tantalizingly busty young woman with the

219
00:09:57,200 --> 00:09:59,760
blouse falling down just so

220
00:09:59,760 --> 00:10:01,200
is a man

221
00:10:01,200 --> 00:10:03,600
camera in hand hiding in the bushes

222
00:10:03,600 --> 00:10:05,440
photographing her

223
00:10:05,440 --> 00:10:07,680
the newspaper would pay anyone who'd

224
00:10:07,680 --> 00:10:10,240
send in such images so this was surely

225
00:10:10,240 --> 00:10:13,519
sketched from that man's real photo

226
00:10:13,519 --> 00:10:15,920
this was precisely the sort of chilling

227
00:10:15,920 --> 00:10:18,000
technological advancement that helped

228
00:10:18,000 --> 00:10:20,079
spark the right to privacy

229
00:10:20,079 --> 00:10:21,680
brandeis and warren were worried

230
00:10:21,680 --> 00:10:23,680
especially about two things that this

231
00:10:23,680 --> 00:10:26,079
newspaper symbolizes

232
00:10:26,079 --> 00:10:29,279
first these nasty so-called detective

233
00:10:29,279 --> 00:10:31,680
cameras that suddenly gave photographers

234
00:10:31,680 --> 00:10:33,519
the ability to surreptitiously

235
00:10:33,519 --> 00:10:35,200
photograph people

236
00:10:35,200 --> 00:10:37,360
women like this one

237
00:10:37,360 --> 00:10:40,000
such cameras were even marketed in ads

238
00:10:40,000 --> 00:10:41,920
that way

239
00:10:41,920 --> 00:10:43,760
second that the scandalous media of the

240
00:10:43,760 --> 00:10:47,200
day pulitzer included could and would

241
00:10:47,200 --> 00:10:49,360
publish such pictures

242
00:10:49,360 --> 00:10:51,360
very clearly something needed to be done

243
00:10:51,360 --> 00:10:52,959
to stop what even the new york times

244
00:10:52,959 --> 00:10:55,279
worried was the growing invasion of

245
00:10:55,279 --> 00:10:57,519
individuals privacy

246
00:10:57,519 --> 00:11:00,000
and so weeks later brandeis and his

247
00:11:00,000 --> 00:11:02,320
co-author warren published the right to

248
00:11:02,320 --> 00:11:04,800
privacy the law review article that

249
00:11:04,800 --> 00:11:06,720
argued that we all have the right to be

250
00:11:06,720 --> 00:11:07,920
let alone

251
00:11:07,920 --> 00:11:10,320
some say it's the most famous law review

252
00:11:10,320 --> 00:11:13,040
of all time the basis for our right to

253
00:11:13,040 --> 00:11:14,959
privacy today

254
00:11:14,959 --> 00:11:17,279
and it worries very much about the

255
00:11:17,279 --> 00:11:19,600
people like those in cape cod folks

256
00:11:19,600 --> 00:11:21,440
whose stories are told against their

257
00:11:21,440 --> 00:11:22,800
wishes

258
00:11:22,800 --> 00:11:25,600
it condemns the technology of the day

259
00:11:25,600 --> 00:11:28,160
that help facilitate such telling the

260
00:11:28,160 --> 00:11:30,399
cameras and the newspapers that to

261
00:11:30,399 --> 00:11:32,560
paraphrase the new york illustrated news

262
00:11:32,560 --> 00:11:37,600
itself allowed graphic illustrations

263
00:11:37,600 --> 00:11:38,480
third

264
00:11:38,480 --> 00:11:40,000
this image

265
00:11:40,000 --> 00:11:42,079
many years later louis brandeis had

266
00:11:42,079 --> 00:11:44,000
become a justice on the united states

267
00:11:44,000 --> 00:11:46,000
supreme court and had learned about a

268
00:11:46,000 --> 00:11:47,760
police practice he found deeply

269
00:11:47,760 --> 00:11:49,760
deserving disturbing

270
00:11:49,760 --> 00:11:52,000
police were eavesdropping on people's

271
00:11:52,000 --> 00:11:54,560
phone conversations by tapping into

272
00:11:54,560 --> 00:11:57,120
phone lines without a warrant

273
00:11:57,120 --> 00:11:59,519
by this time brandeis had come to trust

274
00:11:59,519 --> 00:12:01,920
media more and so he encouraged the

275
00:12:01,920 --> 00:12:04,639
newspaper editors who were his friends

276
00:12:04,639 --> 00:12:06,959
to report on the tactic

277
00:12:06,959 --> 00:12:08,800
he hoped that his fellow justices might

278
00:12:08,800 --> 00:12:11,519
be similarly outraged and would vote to

279
00:12:11,519 --> 00:12:14,079
hear a wiretapping case

280
00:12:14,079 --> 00:12:15,920
the justices thereafter granted

281
00:12:15,920 --> 00:12:18,160
certiorari and agreed to hear the

282
00:12:18,160 --> 00:12:21,200
olmstead case and this is the original

283
00:12:21,200 --> 00:12:23,360
olmstead phone that's here in the

284
00:12:23,360 --> 00:12:24,959
building

285
00:12:24,959 --> 00:12:27,120
anyway in bad news for brandeis and for

286
00:12:27,120 --> 00:12:29,519
all of society at the time the justices

287
00:12:29,519 --> 00:12:32,399
decided that such police activity was

288
00:12:32,399 --> 00:12:33,519
proper

289
00:12:33,519 --> 00:12:35,680
that the phone lines were outside the

290
00:12:35,680 --> 00:12:39,519
home so a warrant wasn't necessary

291
00:12:39,519 --> 00:12:42,160
but brandeis disagreed and wrote

292
00:12:42,160 --> 00:12:44,320
what became a powerfully persuasive

293
00:12:44,320 --> 00:12:46,720
dissent that has now become the law in

294
00:12:46,720 --> 00:12:48,639
the united states

295
00:12:48,639 --> 00:12:51,200
he wrote that in modern times subtler

296
00:12:51,200 --> 00:12:53,680
and more far-reaching devices had been

297
00:12:53,680 --> 00:12:56,320
created to invade privacy making it

298
00:12:56,320 --> 00:12:58,320
possible for others to reveal what was

299
00:12:58,320 --> 00:13:00,480
whispered in the closet

300
00:13:00,480 --> 00:13:03,360
he was especially worried he said about

301
00:13:03,360 --> 00:13:06,320
newer technology including the evil

302
00:13:06,320 --> 00:13:08,560
incident to invasion of privacy of the

303
00:13:08,560 --> 00:13:10,880
telephone that made it possible to

304
00:13:10,880 --> 00:13:13,200
listen in on even the most confidential

305
00:13:13,200 --> 00:13:15,440
of conversations

306
00:13:15,440 --> 00:13:18,639
the brandeis descent in olmstead is a

307
00:13:18,639 --> 00:13:21,120
second reason that brandeis is hugely

308
00:13:21,120 --> 00:13:23,680
famous in privacy circles of course

309
00:13:23,680 --> 00:13:25,519
and the principles in his olmstead

310
00:13:25,519 --> 00:13:27,839
descent are now the foundation for

311
00:13:27,839 --> 00:13:30,720
privacy and police investigations today

312
00:13:30,720 --> 00:13:33,760
in short police need a warrant

313
00:13:33,760 --> 00:13:35,839
but as he worked on his dissenting

314
00:13:35,839 --> 00:13:37,920
opinion in the olmstead case about

315
00:13:37,920 --> 00:13:39,360
wiretaps

316
00:13:39,360 --> 00:13:41,920
brandeis had an even broader sense of

317
00:13:41,920 --> 00:13:44,240
what privacy related things might come

318
00:13:44,240 --> 00:13:45,279
one day

319
00:13:45,279 --> 00:13:47,040
things that may sound troublingly

320
00:13:47,040 --> 00:13:48,800
familiar

321
00:13:48,800 --> 00:13:51,279
he foresaw cloud-based storage and

322
00:13:51,279 --> 00:13:53,199
hacking to some extent

323
00:13:53,199 --> 00:13:55,920
he predicted that the day would come

324
00:13:55,920 --> 00:13:58,480
when people without removing papers from

325
00:13:58,480 --> 00:14:00,720
secret drawers would be able to

326
00:14:00,720 --> 00:14:02,560
reproduce them in court

327
00:14:02,560 --> 00:14:04,560
and thereafter revealed to a jury the

328
00:14:04,560 --> 00:14:07,680
most intimate occurrences of the home

329
00:14:07,680 --> 00:14:09,600
and he'd been just as worried about

330
00:14:09,600 --> 00:14:11,920
radium and photography and the

331
00:14:11,920 --> 00:14:14,880
developing power of television to peer

332
00:14:14,880 --> 00:14:18,560
back into a house to learn its secrets

333
00:14:18,560 --> 00:14:20,880
and maybe even advances in the psychic

334
00:14:20,880 --> 00:14:23,199
and related sciences that could allow

335
00:14:23,199 --> 00:14:26,240
others to explore a man's unexpressed

336
00:14:26,240 --> 00:14:27,279
beliefs

337
00:14:27,279 --> 00:14:28,839
thoughts and

338
00:14:28,839 --> 00:14:31,519
emotions but his in the present law

339
00:14:31,519 --> 00:14:33,760
clerk urged him to scratch all that from

340
00:14:33,760 --> 00:14:37,040
his dissenting opinion as very obviously

341
00:14:37,040 --> 00:14:39,199
impossible

342
00:14:39,199 --> 00:14:40,880
now we know that brandeis wasn't wrong

343
00:14:40,880 --> 00:14:43,760
at all when he saw an effect nanny cams

344
00:14:43,760 --> 00:14:46,240
and doorbell cameras and internet data

345
00:14:46,240 --> 00:14:49,199
tracking that can indeed reveal our very

346
00:14:49,199 --> 00:14:50,959
thoughts

347
00:14:50,959 --> 00:14:54,160
so let's return again to this picture

348
00:14:54,160 --> 00:14:57,040
this is how brandeis wanted you to see

349
00:14:57,040 --> 00:15:00,160
him we're lucky to have it

350
00:15:00,160 --> 00:15:03,120
by 1910 this was the only photograph of

351
00:15:03,120 --> 00:15:06,240
brandeis that brandeis had kept or so he

352
00:15:06,240 --> 00:15:07,680
told a reporter

353
00:15:07,680 --> 00:15:10,079
he'd taken care to destroy all of the

354
00:15:10,079 --> 00:15:12,639
others he said

355
00:15:12,639 --> 00:15:14,639
and those are three stories

356
00:15:14,639 --> 00:15:16,720
really four if you consider the brandeis

357
00:15:16,720 --> 00:15:18,800
photo about what helped in part to

358
00:15:18,800 --> 00:15:20,800
motivate brandeis and his calls for

359
00:15:20,800 --> 00:15:22,079
privacy

360
00:15:22,079 --> 00:15:24,000
he was a man who cared deeply about

361
00:15:24,000 --> 00:15:25,199
privacy

362
00:15:25,199 --> 00:15:27,279
he was worried about the technology that

363
00:15:27,279 --> 00:15:29,759
could invade people's privacy he was

364
00:15:29,759 --> 00:15:33,199
worried about the people who would too

365
00:15:33,199 --> 00:15:34,720
so maybe it's best to leave you with

366
00:15:34,720 --> 00:15:36,320
what brandeis wrote in the right to

367
00:15:36,320 --> 00:15:39,120
privacy and in the olmstead descent

368
00:15:39,120 --> 00:15:40,880
that these sorts of things were the

369
00:15:40,880 --> 00:15:42,800
privacies of life

370
00:15:42,800 --> 00:15:45,040
that they were of far greater importance

371
00:15:45,040 --> 00:15:47,440
than unwarranted governmental quests for

372
00:15:47,440 --> 00:15:49,199
truthful information

373
00:15:49,199 --> 00:15:51,440
that they were of far greater importance

374
00:15:51,440 --> 00:15:54,560
to the individual and the sense of self

375
00:15:54,560 --> 00:15:57,199
than the public's right to know certain

376
00:15:57,199 --> 00:15:59,600
truthful information

377
00:15:59,600 --> 00:16:02,720
that as you know largely remains the law

378
00:16:02,720 --> 00:16:05,199
in the united states today with regard

379
00:16:05,199 --> 00:16:07,440
to this type of privacy

380
00:16:07,440 --> 00:16:09,839
even in an internet age in which much is

381
00:16:09,839 --> 00:16:12,480
recorded and much is published

382
00:16:12,480 --> 00:16:14,399
and even as we grapple with the day's

383
00:16:14,399 --> 00:16:17,279
privacy concerns we have louis brandeis

384
00:16:17,279 --> 00:16:19,440
to thank in large part for that

385
00:16:19,440 --> 00:16:20,720
foundation

386
00:16:20,720 --> 00:16:22,180
thank you

387
00:16:22,180 --> 00:16:25,550
[Applause]

388
00:44:09,670 --> 00:44:27,650
[Music]

389
00:44:28,480 --> 00:44:30,640
well thank you malcolm that was great

390
00:44:30,640 --> 00:44:32,720
and some great takeaways from that that

391
00:44:32,720 --> 00:44:34,560
that talk there my name's steven

392
00:44:34,560 --> 00:44:36,720
reynolds i'm a partner at baker mckenzie

393
00:44:36,720 --> 00:44:38,480
and a member of the iapp board of

394
00:44:38,480 --> 00:44:39,680
directors

395
00:44:39,680 --> 00:44:42,079
our next speaker and final speaker this

396
00:44:42,079 --> 00:44:43,760
evening was sworn in as the chair of the

397
00:44:43,760 --> 00:44:46,119
federal trade commission on june 15

398
00:44:46,119 --> 00:44:47,839
2021.

399
00:44:47,839 --> 00:44:49,839
prior to becoming head of the ftc she

400
00:44:49,839 --> 00:44:51,520
was an associate professor of law at

401
00:44:51,520 --> 00:44:53,520
columbia law school and she also

402
00:44:53,520 --> 00:44:55,440
previously served as counsel to the u.s

403
00:44:55,440 --> 00:44:56,640
health judiciary committee's

404
00:44:56,640 --> 00:44:59,520
subcommittee on antitrust commercial and

405
00:44:59,520 --> 00:45:01,040
administrative law

406
00:45:01,040 --> 00:45:03,440
legal advisor to ftc commissioner rohit

407
00:45:03,440 --> 00:45:05,680
chopra and legal director at the open

408
00:45:05,680 --> 00:45:07,280
markets institute

409
00:45:07,280 --> 00:45:09,359
joining us for her first public address

410
00:45:09,359 --> 00:45:12,240
focused on privacy issues is ftc chair

411
00:45:12,240 --> 00:45:17,240
please welcome to the stage lena kahn

412
00:45:19,280 --> 00:45:35,200
[Music]

413
00:45:35,200 --> 00:45:37,200
hello everybody it's great to see you

414
00:45:37,200 --> 00:45:37,920
all

415
00:45:37,920 --> 00:45:41,200
uh thanks so much to trevor and iapp for

416
00:45:41,200 --> 00:45:43,040
the invitation to speak with you all

417
00:45:43,040 --> 00:45:47,200
today it's a tremendous honor to be here

418
00:45:47,200 --> 00:45:48,800
so it's a striking moment to be

419
00:45:48,800 --> 00:45:51,440
discussing the state of data privacy and

420
00:45:51,440 --> 00:45:54,079
security today with the landscape having

421
00:45:54,079 --> 00:45:56,480
shifted so significantly even over the

422
00:45:56,480 --> 00:45:58,240
last few years

423
00:45:58,240 --> 00:46:00,480
the pandemic hastened the digitization

424
00:46:00,480 --> 00:46:02,800
of our economy and society

425
00:46:02,800 --> 00:46:05,119
further embedding digital technologies

426
00:46:05,119 --> 00:46:08,160
deeper into our lives with schools

427
00:46:08,160 --> 00:46:10,880
workplaces and all manner of life

428
00:46:10,880 --> 00:46:13,200
switching over to virtual formats

429
00:46:13,200 --> 00:46:15,599
effectively overnight

430
00:46:15,599 --> 00:46:18,560
we also saw that this digital transition

431
00:46:18,560 --> 00:46:20,800
was not experienced equally by all

432
00:46:20,800 --> 00:46:23,760
americans since many still lack access

433
00:46:23,760 --> 00:46:26,079
to reliable internet and affordable

434
00:46:26,079 --> 00:46:28,319
personal technologies

435
00:46:28,319 --> 00:46:30,000
the experience of the last couple of

436
00:46:30,000 --> 00:46:32,160
years has both illustrated the

437
00:46:32,160 --> 00:46:34,800
tremendous benefits of these tools as

438
00:46:34,800 --> 00:46:37,200
well as the challenges and risks posed

439
00:46:37,200 --> 00:46:39,680
by this growing dependence

440
00:46:39,680 --> 00:46:41,920
we've seen how security vulnerabilities

441
00:46:41,920 --> 00:46:44,319
can have sweeping effects disrupting

442
00:46:44,319 --> 00:46:46,560
fuel supply for an entire segment of the

443
00:46:46,560 --> 00:46:48,960
country and halting meat processing

444
00:46:48,960 --> 00:46:52,000
operations nationwide

445
00:46:52,000 --> 00:46:54,400
we've also seen how privacy breaches can

446
00:46:54,400 --> 00:46:56,640
be materially consequential with

447
00:46:56,640 --> 00:46:59,119
violations exposing millions of children

448
00:46:59,119 --> 00:47:00,880
during the course of doing their school

449
00:47:00,880 --> 00:47:01,839
work

450
00:47:01,839 --> 00:47:04,319
or resulting in the purchase and sale of

451
00:47:04,319 --> 00:47:07,520
individuals sensitive health data

452
00:47:07,520 --> 00:47:09,920
meanwhile greater adoption of workplace

453
00:47:09,920 --> 00:47:12,160
technology surveillance technologies and

454
00:47:12,160 --> 00:47:14,640
facial recognition tools is expanding

455
00:47:14,640 --> 00:47:17,200
data collection in newly invasive and

456
00:47:17,200 --> 00:47:20,640
potentially discriminatory ways

457
00:47:20,640 --> 00:47:22,880
americans are aware of the stakes and

458
00:47:22,880 --> 00:47:24,960
the potential hazards

459
00:47:24,960 --> 00:47:26,800
one survey showed that close to

460
00:47:26,800 --> 00:47:28,960
two-thirds of americans believe that it

461
00:47:28,960 --> 00:47:31,280
is no longer possible to go through

462
00:47:31,280 --> 00:47:33,760
daily life without companies collecting

463
00:47:33,760 --> 00:47:35,359
data about them

464
00:47:35,359 --> 00:47:37,520
while over 80 percent feel that they

465
00:47:37,520 --> 00:47:39,920
have meager control over the data

466
00:47:39,920 --> 00:47:42,000
collected on them and believe that the

467
00:47:42,000 --> 00:47:44,400
risks of data collection by commercial

468
00:47:44,400 --> 00:47:48,240
entities outweigh the benefits

469
00:47:48,480 --> 00:47:50,720
against this backdrop the federal trade

470
00:47:50,720 --> 00:47:53,119
commission is charged with ensuring that

471
00:47:53,119 --> 00:47:55,839
our legal tools and our approach to law

472
00:47:55,839 --> 00:47:58,160
enforcement keep pace with market

473
00:47:58,160 --> 00:48:01,200
developments and business practices

474
00:48:01,200 --> 00:48:03,680
with its long-standing expertise in how

475
00:48:03,680 --> 00:48:06,240
companies collect and deploy americans

476
00:48:06,240 --> 00:48:07,200
data

477
00:48:07,200 --> 00:48:09,520
along with its unique combination of

478
00:48:09,520 --> 00:48:12,559
enforcement policy and research tools

479
00:48:12,559 --> 00:48:15,200
the ftc is especially well suited to

480
00:48:15,200 --> 00:48:17,680
this task

481
00:48:17,680 --> 00:48:20,000
in my remarks today i will offer a few

482
00:48:20,000 --> 00:48:22,240
observations about the new political

483
00:48:22,240 --> 00:48:25,839
economy of how americans data is tracked

484
00:48:25,839 --> 00:48:27,839
gathered and used

485
00:48:27,839 --> 00:48:30,000
identify a few ways that the federal

486
00:48:30,000 --> 00:48:32,079
trade commission is refining its

487
00:48:32,079 --> 00:48:34,079
approach in light of these new market

488
00:48:34,079 --> 00:48:35,359
realities

489
00:48:35,359 --> 00:48:37,760
and lastly share some broader questions

490
00:48:37,760 --> 00:48:40,079
that i believe these realities raise for

491
00:48:40,079 --> 00:48:41,920
the current frameworks we use for

492
00:48:41,920 --> 00:48:43,920
policing the use and abuse of

493
00:48:43,920 --> 00:48:46,880
individuals data

494
00:48:47,200 --> 00:48:49,599
concerns about americans privacy has

495
00:48:49,599 --> 00:48:52,000
long preceded the digital age

496
00:48:52,000 --> 00:48:55,440
lewis brandeis and samuel warren in 1890

497
00:48:55,440 --> 00:48:58,240
famously sought to define anew the exact

498
00:48:58,240 --> 00:49:01,520
nature and extent of privacy protections

499
00:49:01,520 --> 00:49:04,480
guaranteed by law in the face of quote

500
00:49:04,480 --> 00:49:08,319
recent inventions and business methods

501
00:49:08,319 --> 00:49:10,240
at bottom they explained the law

502
00:49:10,240 --> 00:49:12,960
protects people from the unwanted prying

503
00:49:12,960 --> 00:49:15,440
eyes of private actors almost in the

504
00:49:15,440 --> 00:49:17,200
same way that it protects against

505
00:49:17,200 --> 00:49:19,599
physical injury

506
00:49:19,599 --> 00:49:23,200
similarly lawmakers in 1970 passed the

507
00:49:23,200 --> 00:49:25,680
fair credit reporting act the first

508
00:49:25,680 --> 00:49:27,760
federal law to govern how private

509
00:49:27,760 --> 00:49:30,400
businesses could use americans personal

510
00:49:30,400 --> 00:49:32,319
information

511
00:49:32,319 --> 00:49:34,160
the law prescribed the types of

512
00:49:34,160 --> 00:49:35,839
information the credit reporting

513
00:49:35,839 --> 00:49:38,559
agencies could use and guaranteed a

514
00:49:38,559 --> 00:49:40,559
person's right to see what was in their

515
00:49:40,559 --> 00:49:43,359
file a recognition of the unique harms

516
00:49:43,359 --> 00:49:45,359
that can result when firms have

517
00:49:45,359 --> 00:49:48,000
unchecked power to create dossiers on

518
00:49:48,000 --> 00:49:50,400
people that can be used to then grant or

519
00:49:50,400 --> 00:49:53,520
deny them opportunities

520
00:49:53,520 --> 00:49:55,440
though these basic principles governing

521
00:49:55,440 --> 00:49:57,359
what types of personal information

522
00:49:57,359 --> 00:49:59,599
businesses can and cannot collect and

523
00:49:59,599 --> 00:50:02,319
use extend back decades

524
00:50:02,319 --> 00:50:04,400
the context in which we must now apply

525
00:50:04,400 --> 00:50:08,079
them today looks dramatically different

526
00:50:08,079 --> 00:50:10,319
digital technologies have enabled firms

527
00:50:10,319 --> 00:50:12,559
to collect data on individuals at a

528
00:50:12,559 --> 00:50:14,480
hyper granular level

529
00:50:14,480 --> 00:50:16,640
tracking not just what a purchase of

530
00:50:16,640 --> 00:50:19,200
what a person purchased for example

531
00:50:19,200 --> 00:50:22,319
but also their keystroke usage how long

532
00:50:22,319 --> 00:50:24,400
their mouse hovered over any particular

533
00:50:24,400 --> 00:50:25,280
item

534
00:50:25,280 --> 00:50:27,040
and the full set of items that they

535
00:50:27,040 --> 00:50:29,760
viewed but did not buy

536
00:50:29,760 --> 00:50:32,319
as people rely on digital tools to carry

537
00:50:32,319 --> 00:50:35,359
out a greater portion of daily tasks the

538
00:50:35,359 --> 00:50:37,680
scope of information collected

539
00:50:37,680 --> 00:50:40,640
also becomes increasingly vast ranging

540
00:50:40,640 --> 00:50:43,680
from one's precise location and full web

541
00:50:43,680 --> 00:50:46,400
browsing history to one's health records

542
00:50:46,400 --> 00:50:48,319
and complete network of family and

543
00:50:48,319 --> 00:50:49,839
friends

544
00:50:49,839 --> 00:50:52,160
the availability of powerful cloud

545
00:50:52,160 --> 00:50:54,720
storage services and automated decision

546
00:50:54,720 --> 00:50:57,200
making systems meanwhile have allowed

547
00:50:57,200 --> 00:51:00,480
companies to combine data across domains

548
00:51:00,480 --> 00:51:03,200
and retain and analyze it in aggregated

549
00:51:03,200 --> 00:51:06,079
form at an unprecedented scale

550
00:51:06,079 --> 00:51:08,079
yielding stunningly detailed and

551
00:51:08,079 --> 00:51:10,640
comprehensive user profiles that can be

552
00:51:10,640 --> 00:51:12,960
used to target individuals with striking

553
00:51:12,960 --> 00:51:15,119
precision

554
00:51:15,119 --> 00:51:17,680
some firms like weather forecasting or

555
00:51:17,680 --> 00:51:20,079
mapping apps for example may primarily

556
00:51:20,079 --> 00:51:22,480
use this personal data to customize

557
00:51:22,480 --> 00:51:25,040
service for individual users

558
00:51:25,040 --> 00:51:27,680
others can also market or sell this data

559
00:51:27,680 --> 00:51:29,520
to third-party brokers and other

560
00:51:29,520 --> 00:51:32,079
businesses in ancillary or secondary

561
00:51:32,079 --> 00:51:34,319
markets that most users may not even

562
00:51:34,319 --> 00:51:36,800
know exists

563
00:51:36,800 --> 00:51:39,520
indeed the general lack of legal limits

564
00:51:39,520 --> 00:51:41,280
on what types of information can be

565
00:51:41,280 --> 00:51:44,160
monetized has yielded a booming economy

566
00:51:44,160 --> 00:51:46,079
built around the buying and selling of

567
00:51:46,079 --> 00:51:48,160
this data

568
00:51:48,160 --> 00:51:50,559
this has let firms provide services for

569
00:51:50,559 --> 00:51:53,359
zero dollars while monetizing personal

570
00:51:53,359 --> 00:51:55,839
information a business model that seems

571
00:51:55,839 --> 00:51:58,079
to incentivize endless tracking and

572
00:51:58,079 --> 00:52:01,040
vacuuming up of users data

573
00:52:01,040 --> 00:52:03,359
indeed the value that data brokers

574
00:52:03,359 --> 00:52:05,599
advertisers and others extract from this

575
00:52:05,599 --> 00:52:07,839
data has led firms to create an

576
00:52:07,839 --> 00:52:10,559
elaborate web of tools to surveil users

577
00:52:10,559 --> 00:52:14,079
across apps websites and devices

578
00:52:14,079 --> 00:52:16,720
as one scholar has noted today's digital

579
00:52:16,720 --> 00:52:18,960
economy represents probably the most

580
00:52:18,960 --> 00:52:21,040
highly surveilled environment in the

581
00:52:21,040 --> 00:52:24,000
history of humanity

582
00:52:24,000 --> 00:52:25,839
while these data practices can enable

583
00:52:25,839 --> 00:52:28,319
services in forms of personalization

584
00:52:28,319 --> 00:52:29,760
that could in some instances be

585
00:52:29,760 --> 00:52:32,400
benefiting users they can also enable

586
00:52:32,400 --> 00:52:34,880
business practices that harm americans

587
00:52:34,880 --> 00:52:36,880
in a host of ways

588
00:52:36,880 --> 00:52:39,119
for example we've seen that firms can

589
00:52:39,119 --> 00:52:41,599
target scams and deceptive ads to

590
00:52:41,599 --> 00:52:43,760
consumers who are most susceptible to

591
00:52:43,760 --> 00:52:45,760
being lured by them

592
00:52:45,760 --> 00:52:48,319
they can direct ads in key sectors like

593
00:52:48,319 --> 00:52:51,920
health credit housing in the workplace

594
00:52:51,920 --> 00:52:55,119
based on consumers race gender age

595
00:52:55,119 --> 00:52:58,640
engaging in unlawful discrimination

596
00:52:58,640 --> 00:53:00,880
collecting and sharing data on people's

597
00:53:00,880 --> 00:53:03,680
physical movements and online activity

598
00:53:03,680 --> 00:53:06,720
meanwhile can endanger them enabling

599
00:53:06,720 --> 00:53:10,000
stalkers to track them in real time

600
00:53:10,000 --> 00:53:11,920
and failing to keep sensitive personal

601
00:53:11,920 --> 00:53:14,800
information secure can also expose users

602
00:53:14,800 --> 00:53:17,280
to hackers identity thieves and cyber

603
00:53:17,280 --> 00:53:19,599
threats

604
00:53:19,599 --> 00:53:21,680
the incentive to maximally collect and

605
00:53:21,680 --> 00:53:24,559
retain user data can also concentrate

606
00:53:24,559 --> 00:53:26,400
valuable data in ways that create

607
00:53:26,400 --> 00:53:27,839
systemic risk

608
00:53:27,839 --> 00:53:30,079
increasing the hazards and costs of

609
00:53:30,079 --> 00:53:32,319
hacks and cyber attacks

610
00:53:32,319 --> 00:53:34,480
some moreover have also questioned

611
00:53:34,480 --> 00:53:37,119
whether the opacity and complexity of

612
00:53:37,119 --> 00:53:39,440
digital ad markets could be enabling

613
00:53:39,440 --> 00:53:41,920
widespread fraud and masking a major

614
00:53:41,920 --> 00:53:43,920
bubble

615
00:53:43,920 --> 00:53:45,920
beyond these specific harms the data

616
00:53:45,920 --> 00:53:47,520
practices of today's surveillance

617
00:53:47,520 --> 00:53:50,400
economy can create and exacerbate deep

618
00:53:50,400 --> 00:53:53,440
asymmetries of information exacerbating

619
00:53:53,440 --> 00:53:56,720
in turn imbalances of power as numerous

620
00:53:56,720 --> 00:53:59,680
scholars have noted businesses access to

621
00:53:59,680 --> 00:54:02,160
and control over vast troves of granular

622
00:54:02,160 --> 00:54:04,880
data on individuals can give these firms

623
00:54:04,880 --> 00:54:07,040
enormous power to predict

624
00:54:07,040 --> 00:54:10,160
influence and control human behavior

625
00:54:10,160 --> 00:54:11,920
in other words what's at stake with

626
00:54:11,920 --> 00:54:14,000
these business practices is not just

627
00:54:14,000 --> 00:54:16,640
one's subjective preference for privacy

628
00:54:16,640 --> 00:54:19,119
over the long term but one's freedom

629
00:54:19,119 --> 00:54:21,520
dignity and equal participation in our

630
00:54:21,520 --> 00:54:25,400
economy in our society

631
00:54:25,599 --> 00:54:28,160
our talented ftc teams are focused on

632
00:54:28,160 --> 00:54:29,920
adapting the commission's existing

633
00:54:29,920 --> 00:54:32,240
authority to address and rectify

634
00:54:32,240 --> 00:54:34,480
unlawful data practices

635
00:54:34,480 --> 00:54:36,799
a few key aspects of this approach are

636
00:54:36,799 --> 00:54:39,680
particularly worth noting

637
00:54:39,680 --> 00:54:41,839
first we're seeking to harness our

638
00:54:41,839 --> 00:54:44,799
scarce resources to maximize impact

639
00:54:44,799 --> 00:54:47,440
particularly by focus on focusing on

640
00:54:47,440 --> 00:54:49,680
firms whose business practices cause

641
00:54:49,680 --> 00:54:52,160
widespread harm

642
00:54:52,160 --> 00:54:54,559
this means tackling conduct by dominant

643
00:54:54,559 --> 00:54:57,119
firms as well as intermediaries that may

644
00:54:57,119 --> 00:54:59,760
facilitate unlawful conduct on a massive

645
00:54:59,760 --> 00:55:01,280
scale

646
00:55:01,280 --> 00:55:03,599
for example last year the commission

647
00:55:03,599 --> 00:55:06,559
took action against openx an ad exchange

648
00:55:06,559 --> 00:55:08,559
that handles billions of advertising

649
00:55:08,559 --> 00:55:11,359
requests involving consumer data and the

650
00:55:11,359 --> 00:55:13,280
company was alleged to have unlawfully

651
00:55:13,280 --> 00:55:15,440
collected information from services

652
00:55:15,440 --> 00:55:17,760
directed at children

653
00:55:17,760 --> 00:55:19,839
we intend to hold accountable dominant

654
00:55:19,839 --> 00:55:21,760
middlemen for consumer harms that they

655
00:55:21,760 --> 00:55:23,520
facilitate through unlawful data

656
00:55:23,520 --> 00:55:25,920
practices

657
00:55:25,920 --> 00:55:27,280
second we are taking an

658
00:55:27,280 --> 00:55:29,680
interdisciplinary approach assessing

659
00:55:29,680 --> 00:55:31,839
data practices through both the consumer

660
00:55:31,839 --> 00:55:35,040
protection and competition lens

661
00:55:35,040 --> 00:55:37,119
given the intersecting ways in which

662
00:55:37,119 --> 00:55:38,000
wide

663
00:55:38,000 --> 00:55:39,760
wide scale data collection and

664
00:55:39,760 --> 00:55:42,000
commercial surveillance practices can

665
00:55:42,000 --> 00:55:44,400
facilitate violations of both consumer

666
00:55:44,400 --> 00:55:47,280
protection and antitrust laws we are

667
00:55:47,280 --> 00:55:49,599
keen to marshal our expertise in both

668
00:55:49,599 --> 00:55:52,240
areas to ensure that we are grasping the

669
00:55:52,240 --> 00:55:54,880
full implications of particular business

670
00:55:54,880 --> 00:55:57,760
conduct and strategies

671
00:55:57,760 --> 00:55:59,599
also key to our interdisciplinary

672
00:55:59,599 --> 00:56:02,160
approach is our growing reliance on

673
00:56:02,160 --> 00:56:04,799
technologists alongside the skilled

674
00:56:04,799 --> 00:56:07,200
lawyers economists and investigators who

675
00:56:07,200 --> 00:56:09,440
lead our enforcement work

676
00:56:09,440 --> 00:56:11,119
we have already increased the number of

677
00:56:11,119 --> 00:56:13,680
technologists on our staff drawing from

678
00:56:13,680 --> 00:56:16,640
a diverse set of skill sets including

679
00:56:16,640 --> 00:56:19,119
data scientists and engineers user

680
00:56:19,119 --> 00:56:22,079
design experts and ai researchers and we

681
00:56:22,079 --> 00:56:25,680
plan to continue building up this team

682
00:56:25,680 --> 00:56:28,160
third when we encounter law violations

683
00:56:28,160 --> 00:56:30,160
we are focused on designing effective

684
00:56:30,160 --> 00:56:32,559
remedies that are directly informed by

685
00:56:32,559 --> 00:56:34,400
the business incentives that various

686
00:56:34,400 --> 00:56:36,960
markets favor and reward

687
00:56:36,960 --> 00:56:39,040
this includes pursuing remedies that

688
00:56:39,040 --> 00:56:42,079
fully cure the underlying harm and where

689
00:56:42,079 --> 00:56:44,480
necessary deprive law breakers of the

690
00:56:44,480 --> 00:56:47,200
fruits of their misconduct

691
00:56:47,200 --> 00:56:49,599
for example the commission recently took

692
00:56:49,599 --> 00:56:51,280
action against weight watchers

693
00:56:51,280 --> 00:56:53,760
subsidiary kerbo alleging that the

694
00:56:53,760 --> 00:56:56,640
company had illegally harvested

695
00:56:56,640 --> 00:56:58,319
children's sensitive personal

696
00:56:58,319 --> 00:57:01,280
information including their names eating

697
00:57:01,280 --> 00:57:03,760
habits daily activities

698
00:57:03,760 --> 00:57:06,960
birth date and persistent identifiers

699
00:57:06,960 --> 00:57:08,960
our settlement required not only that

700
00:57:08,960 --> 00:57:11,200
the business pay a penalty for its law

701
00:57:11,200 --> 00:57:13,680
breaking but also also that it delete

702
00:57:13,680 --> 00:57:15,359
its ill-gotten gain

703
00:57:15,359 --> 00:57:17,440
and destroy any algorithms derived from

704
00:57:17,440 --> 00:57:19,359
that data

705
00:57:19,359 --> 00:57:21,520
where appropriate our remedies will also

706
00:57:21,520 --> 00:57:23,280
seek to foreground executive

707
00:57:23,280 --> 00:57:24,640
accountability

708
00:57:24,640 --> 00:57:26,319
through prophylactic limits on

709
00:57:26,319 --> 00:57:29,359
executives conduct

710
00:57:29,359 --> 00:57:31,280
in our action against spy phone for

711
00:57:31,280 --> 00:57:34,559
example the ftc banned both the company

712
00:57:34,559 --> 00:57:36,720
and its ceo from the surveillance

713
00:57:36,720 --> 00:57:39,119
business resolving allegations that they

714
00:57:39,119 --> 00:57:41,440
had been secretly harvesting and selling

715
00:57:41,440 --> 00:57:44,079
real-time access to data on a range of

716
00:57:44,079 --> 00:57:46,640
sensitive activity

717
00:57:46,640 --> 00:57:48,720
lastly we are focused on ensuring that

718
00:57:48,720 --> 00:57:50,720
our remedies evolve to reflect the

719
00:57:50,720 --> 00:57:53,119
latest best practices in security and

720
00:57:53,119 --> 00:57:54,480
privacy

721
00:57:54,480 --> 00:57:56,720
in our recent action against cafe press

722
00:57:56,720 --> 00:57:59,040
for example our settlement remedied an

723
00:57:59,040 --> 00:58:01,280
alleged breach by requiring the use of

724
00:58:01,280 --> 00:58:04,400
multi-factor multi-factor authentication

725
00:58:04,400 --> 00:58:06,799
reflecting the latest thinking in secure

726
00:58:06,799 --> 00:58:09,359
credentialing

727
00:58:09,359 --> 00:58:11,359
even without a federal privacy or

728
00:58:11,359 --> 00:58:12,880
security law

729
00:58:12,880 --> 00:58:15,599
the ftc has for decades served as a de

730
00:58:15,599 --> 00:58:18,160
facto enforcer in this domain using

731
00:58:18,160 --> 00:58:20,640
section 5 of the ftc act and other

732
00:58:20,640 --> 00:58:23,280
statutory authorities to crack down on

733
00:58:23,280 --> 00:58:25,200
unlawful practices

734
00:58:25,200 --> 00:58:27,280
no doubt we will continue using our

735
00:58:27,280 --> 00:58:29,839
current enforcement tools to take swift

736
00:58:29,839 --> 00:58:32,640
and bold action

737
00:58:35,040 --> 00:58:37,359
the realities of how firms surveil

738
00:58:37,359 --> 00:58:39,839
categorize and monetize user data in the

739
00:58:39,839 --> 00:58:42,400
modern economy however invites us to

740
00:58:42,400 --> 00:58:44,480
consider how we might need to update our

741
00:58:44,480 --> 00:58:46,799
approach further yet

742
00:58:46,799 --> 00:58:48,640
first the commission is considering

743
00:58:48,640 --> 00:58:50,799
initiating a rulemaking to address

744
00:58:50,799 --> 00:58:52,880
commercial surveillance and lacks data

745
00:58:52,880 --> 00:58:54,880
security practices

746
00:58:54,880 --> 00:58:56,559
given that our economy will only

747
00:58:56,559 --> 00:58:59,440
continue to further digitize market-wide

748
00:58:59,440 --> 00:59:01,839
rules could help provide clear notice

749
00:59:01,839 --> 00:59:04,079
and render enforcement more impactful

750
00:59:04,079 --> 00:59:06,640
and efficient

751
00:59:06,640 --> 00:59:08,960
second i believe we need to reassess the

752
00:59:08,960 --> 00:59:11,359
frameworks we presently use to assess

753
00:59:11,359 --> 00:59:13,359
unlawful conduct

754
00:59:13,359 --> 00:59:15,280
specifically i am concerned that the

755
00:59:15,280 --> 00:59:17,839
present market realities may render the

756
00:59:17,839 --> 00:59:20,480
notice and consent paradigm outdated and

757
00:59:20,480 --> 00:59:22,160
insufficient

758
00:59:22,160 --> 00:59:23,760
many have noted the ways that this

759
00:59:23,760 --> 00:59:26,240
framework seems to fall short given both

760
00:59:26,240 --> 00:59:28,079
the overwhelming nature of privacy

761
00:59:28,079 --> 00:59:30,400
policies and the fact that they may very

762
00:59:30,400 --> 00:59:32,480
well be beside the point

763
00:59:32,480 --> 00:59:34,160
when faced with technologies that are

764
00:59:34,160 --> 00:59:36,319
increasingly critical for navigating

765
00:59:36,319 --> 00:59:39,280
modern life users often lack a real set

766
00:59:39,280 --> 00:59:41,440
of alternatives and cannot reasonably

767
00:59:41,440 --> 00:59:44,720
forego using these tools

768
00:59:44,720 --> 00:59:46,319
going forward i believe we should

769
00:59:46,319 --> 00:59:48,240
approach data privacy and security

770
00:59:48,240 --> 00:59:50,640
protections by considering substantive

771
00:59:50,640 --> 00:59:52,960
limits rather than just procedural

772
00:59:52,960 --> 00:59:55,599
protections which tend to create process

773
00:59:55,599 --> 00:59:57,680
requirements while sidestepping more

774
00:59:57,680 --> 00:59:59,599
fundamental questions about whether

775
00:59:59,599 --> 01:00:01,440
certain types of data collection and

776
01:00:01,440 --> 01:00:03,119
processing should be permitted in the

777
01:00:03,119 --> 01:00:04,720
first place

778
01:00:04,720 --> 01:00:06,640
the central role the digital tools will

779
01:00:06,640 --> 01:00:08,960
only continue to play invites us to

780
01:00:08,960 --> 01:00:10,799
consider whether we want to live in a

781
01:00:10,799 --> 01:00:13,359
society where firms can condition access

782
01:00:13,359 --> 01:00:15,680
to critical critical technologies and

783
01:00:15,680 --> 01:00:17,839
opportunities on users having to

784
01:00:17,839 --> 01:00:20,559
surrender to commercial surveillance

785
01:00:20,559 --> 01:00:22,799
privacy legislation from congress could

786
01:00:22,799 --> 01:00:24,799
also help assure in this type of new

787
01:00:24,799 --> 01:00:26,480
paradigm

788
01:00:26,480 --> 01:00:28,400
thank you again for inviting me to speak

789
01:00:28,400 --> 01:00:30,880
with you all today this is an incredibly

790
01:00:30,880 --> 01:00:32,640
exciting and momentous time for these

791
01:00:32,640 --> 01:00:35,119
issues with a lot at stake and a

792
01:00:35,119 --> 01:00:37,200
tremendous amount of work to be done and

793
01:00:37,200 --> 01:00:38,559
i'm looking forward to working with you

794
01:00:38,559 --> 01:00:40,720
all as we chart forward the path ahead

795
01:00:40,720 --> 01:00:41,890
thank you

796
01:00:41,890 --> 01:00:43,120
[Applause]

797
01:00:43,120 --> 01:00:46,750
[Music]

