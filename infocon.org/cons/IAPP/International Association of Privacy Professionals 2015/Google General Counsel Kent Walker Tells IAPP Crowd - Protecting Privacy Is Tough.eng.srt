1
00:00:11,809 --> 00:00:15,719
privacy in particular protecting privacy

2
00:00:15,719 --> 00:00:19,650
is tough as you all well know it's tough

3
00:00:19,650 --> 00:00:22,590
technologically it's tough socially and

4
00:00:22,590 --> 00:00:25,680
it's tough legally and it won't come as

5
00:00:25,680 --> 00:00:28,289
a surprise to anybody in the audience to

6
00:00:28,289 --> 00:00:30,029
hear the we at Google have had our

7
00:00:30,029 --> 00:00:33,000
challenges over the years we've we've

8
00:00:33,000 --> 00:00:35,280
made our mistakes we launched Google

9
00:00:35,280 --> 00:00:37,950
Buzz without designing as well as we

10
00:00:37,950 --> 00:00:41,340
could have we launched Street View in

11
00:00:41,340 --> 00:00:44,010
some countries which we've got a mixed

12
00:00:44,010 --> 00:00:47,010
reception and we collected Wi-Fi data by

13
00:00:47,010 --> 00:00:50,910
mistake that said we live in Silicon

14
00:00:50,910 --> 00:00:53,370
Valley we pride ourselves on the ability

15
00:00:53,370 --> 00:00:55,379
to learn from mistakes to launch and

16
00:00:55,379 --> 00:00:57,239
iterate and to get things right

17
00:00:57,239 --> 00:01:00,989
eventually I'm happy to be here at ia

18
00:01:00,989 --> 00:01:03,930
PEEPi to discuss some of the things

19
00:01:03,930 --> 00:01:06,119
we've learned over the years to talk

20
00:01:06,119 --> 00:01:08,700
about the intersection between the

21
00:01:08,700 --> 00:01:10,939
information revolution and privacy and

22
00:01:10,939 --> 00:01:14,250
to share some perspectives on how

23
00:01:14,250 --> 00:01:16,590
government policy can help us get it

24
00:01:16,590 --> 00:01:20,670
right we at Google have had to evolve

25
00:01:20,670 --> 00:01:23,549
our attitude and our approach on privacy

26
00:01:23,549 --> 00:01:27,000
issues particularly in Europe we've

27
00:01:27,000 --> 00:01:28,500
needed to do a better job of listening

28
00:01:28,500 --> 00:01:31,229
to and understanding concerns raised by

29
00:01:31,229 --> 00:01:33,920
data protection authorities and others

30
00:01:33,920 --> 00:01:36,630
we're now engaging with European

31
00:01:36,630 --> 00:01:38,579
regulators to improve our compliance

32
00:01:38,579 --> 00:01:41,670
with European data protection laws and I

33
00:01:41,670 --> 00:01:43,409
think it's fair to say that we have put

34
00:01:43,409 --> 00:01:45,450
in more work than any other company out

35
00:01:45,450 --> 00:01:48,180
there in meeting these sometimes

36
00:01:48,180 --> 00:01:51,659
challenging legal requirements I hope

37
00:01:51,659 --> 00:01:53,790
that our our implementation of the

38
00:01:53,790 --> 00:01:55,560
recently decided right to be forgotten

39
00:01:55,560 --> 00:01:58,170
decision in Europe shows that we are

40
00:01:58,170 --> 00:02:00,600
willing to adjust our course when it

41
00:02:00,600 --> 00:02:03,899
comes to privacy the Castella ruling

42
00:02:03,899 --> 00:02:06,000
established that search is subject to

43
00:02:06,000 --> 00:02:09,389
European data protection law and broadly

44
00:02:09,389 --> 00:02:12,000
outline various obligations regarding

45
00:02:12,000 --> 00:02:12,670
the removal

46
00:02:12,670 --> 00:02:15,340
and search we've been working hard to

47
00:02:15,340 --> 00:02:17,800
implement the decision some of the

48
00:02:17,800 --> 00:02:20,560
decisions are easy some of them are very

49
00:02:20,560 --> 00:02:22,810
difficult as we weigh the balance

50
00:02:22,810 --> 00:02:25,660
between privacy rights and the public's

51
00:02:25,660 --> 00:02:28,540
right to know our approach has largely

52
00:02:28,540 --> 00:02:30,459
been consistent with the recommendations

53
00:02:30,459 --> 00:02:33,790
of European experts and regulators but

54
00:02:33,790 --> 00:02:35,500
they're still disagreement around the

55
00:02:35,500 --> 00:02:37,450
scope of issues like whether the scope

56
00:02:37,450 --> 00:02:40,330
of removals should be global or focused

57
00:02:40,330 --> 00:02:43,420
on Europe conflicts of law and

58
00:02:43,420 --> 00:02:44,709
jurisdiction are never easy

59
00:02:44,709 --> 00:02:46,540
since the fundamental rights at stake

60
00:02:46,540 --> 00:02:48,760
are sometimes weighed differently in

61
00:02:48,760 --> 00:02:49,959
different countries and different parts

62
00:02:49,959 --> 00:02:53,140
of the world but despite these

63
00:02:53,140 --> 00:02:56,230
differences we have some big reasons to

64
00:02:56,230 --> 00:03:00,040
get this to get privacy right there's no

65
00:03:00,040 --> 00:03:02,650
way around the fact the data analysis

66
00:03:02,650 --> 00:03:05,830
what we call smart data is a key driver

67
00:03:05,830 --> 00:03:09,690
of today's economy and tomorrow's growth

68
00:03:09,690 --> 00:03:13,810
like light data is a renewable and a non

69
00:03:13,810 --> 00:03:17,650
rival risk resource using it well fuels

70
00:03:17,650 --> 00:03:21,120
innovation than all parts of the economy

71
00:03:21,120 --> 00:03:23,910
of course data comes from many sources

72
00:03:23,910 --> 00:03:26,980
some data is pre-existing what's in our

73
00:03:26,980 --> 00:03:29,799
genes our bodies our environment the

74
00:03:29,799 --> 00:03:31,840
world has always been full of such facts

75
00:03:31,840 --> 00:03:35,070
and some data we create ourselves

76
00:03:35,070 --> 00:03:37,150
through a whole new world of

77
00:03:37,150 --> 00:03:39,459
computerized transactions and the

78
00:03:39,459 --> 00:03:42,180
growing world of the Internet of Things

79
00:03:42,180 --> 00:03:45,010
it's important to step back and remember

80
00:03:45,010 --> 00:03:48,370
that until the year 2000 mankind had

81
00:03:48,370 --> 00:03:51,760
created and stored roughly 12 exabytes

82
00:03:51,760 --> 00:03:54,790
of data in total an exabyte is a lot

83
00:03:54,790 --> 00:03:56,590
it's roughly the amount of information

84
00:03:56,590 --> 00:03:59,560
in the US Library of Congress so twelve

85
00:03:59,560 --> 00:04:01,329
exabytes in human history up to twelve

86
00:04:01,329 --> 00:04:04,660
thousand 2000 today the world creates

87
00:04:04,660 --> 00:04:07,180
and stores roughly two exabytes of data

88
00:04:07,180 --> 00:04:11,799
every single day 90% of the data in the

89
00:04:11,799 --> 00:04:13,720
world has been created in the last two

90
00:04:13,720 --> 00:04:18,880
years alone that's 2.5 quintillion bytes

91
00:04:18,880 --> 00:04:22,750
of data every day a way to think about

92
00:04:22,750 --> 00:04:25,480
that is creating a new Google every

93
00:04:25,480 --> 00:04:29,440
for days and the rate is increasing in

94
00:04:29,440 --> 00:04:32,110
just one example YouTube users upload

95
00:04:32,110 --> 00:04:35,290
hundreds of hours of video every minute

96
00:04:35,290 --> 00:04:38,290
in total that's more than all cinema all

97
00:04:38,290 --> 00:04:42,700
TV all home movies ever made believe it

98
00:04:42,700 --> 00:04:46,720
or not the data the facts alone aren't

99
00:04:46,720 --> 00:04:48,480
really the interesting part

100
00:04:48,480 --> 00:04:50,890
they've always been lots of facts in the

101
00:04:50,890 --> 00:04:54,910
world raw data is to knowledge what's

102
00:04:54,910 --> 00:04:58,540
and is to silicon chips data without

103
00:04:58,540 --> 00:05:03,520
insight is pretty worthless it's data

104
00:05:03,520 --> 00:05:07,720
used well smart data that lets you build

105
00:05:07,720 --> 00:05:10,630
a bigger picture a kind of integrated

106
00:05:10,630 --> 00:05:14,140
knowledge we are just starting to unlock

107
00:05:14,140 --> 00:05:16,330
new troves of understanding with huge

108
00:05:16,330 --> 00:05:19,150
social value and it's not just online

109
00:05:19,150 --> 00:05:21,430
companies reaping the benefits it's

110
00:05:21,430 --> 00:05:23,140
small businesses selling more and

111
00:05:23,140 --> 00:05:26,530
wasting less consumers getting more of

112
00:05:26,530 --> 00:05:29,650
what they want faster universities and

113
00:05:29,650 --> 00:05:31,690
research hospitals revolutionising

114
00:05:31,690 --> 00:05:34,660
health care through genetics Diagnostics

115
00:05:34,660 --> 00:05:38,200
personalized medicine and maybe most

116
00:05:38,200 --> 00:05:41,260
importantly poor people around the world

117
00:05:41,260 --> 00:05:44,140
being included in a global trading and

118
00:05:44,140 --> 00:05:46,030
information economy with an

119
00:05:46,030 --> 00:05:48,270
unprecedented billion human beings

120
00:05:48,270 --> 00:05:50,740
coming out of extreme poverty in the

121
00:05:50,740 --> 00:05:54,310
last 30 years that is unprecedented in

122
00:05:54,310 --> 00:05:58,120
the history of mankind we are also

123
00:05:58,120 --> 00:06:00,340
seeing data-driven innovation in our

124
00:06:00,340 --> 00:06:03,490
daily lives personalized learning gives

125
00:06:03,490 --> 00:06:06,160
real-time feedback and assessments to

126
00:06:06,160 --> 00:06:08,580
help with student proficiency

127
00:06:08,580 --> 00:06:11,080
de-identified data sets from hospitals

128
00:06:11,080 --> 00:06:12,220
are helping improve healthcare

129
00:06:12,220 --> 00:06:15,430
efficiency and outcomes data about the

130
00:06:15,430 --> 00:06:18,010
location of assaults is facilitating

131
00:06:18,010 --> 00:06:20,620
targeted interventions to reduce violent

132
00:06:20,620 --> 00:06:24,730
crime so let me stress our deep belief

133
00:06:24,730 --> 00:06:28,390
the data driven innovation is compatible

134
00:06:28,390 --> 00:06:31,900
with privacy in fact the two must go

135
00:06:31,900 --> 00:06:34,960
together there's a path to data security

136
00:06:34,960 --> 00:06:38,230
and access control reasonable user

137
00:06:38,230 --> 00:06:39,050
awareness

138
00:06:39,050 --> 00:06:42,379
Powerman data portability that will let

139
00:06:42,379 --> 00:06:45,190
us achieve both privacy and innovation

140
00:06:45,190 --> 00:06:48,319
of course overly rigid restrictions on

141
00:06:48,319 --> 00:06:50,990
combining and repurposing data strict

142
00:06:50,990 --> 00:06:53,720
prohibitions on data transfer or overly

143
00:06:53,720 --> 00:06:55,310
detailed consent requirements could

144
00:06:55,310 --> 00:06:57,229
create challenges for the growth of

145
00:06:57,229 --> 00:06:59,690
data-driven innovation blanket

146
00:06:59,690 --> 00:07:01,220
prohibitions on data collection and

147
00:07:01,220 --> 00:07:03,699
transfer necessarily limit innovation

148
00:07:03,699 --> 00:07:06,860
it's the misuse of data not its

149
00:07:06,860 --> 00:07:09,020
collection per se that should concern us

150
00:07:09,020 --> 00:07:12,770
most of course in arguing for an

151
00:07:12,770 --> 00:07:15,770
approach focused on avoiding harms we

152
00:07:15,770 --> 00:07:17,810
are required to also face up to the need

153
00:07:17,810 --> 00:07:20,210
to keep collected data safe and secure

154
00:07:20,210 --> 00:07:23,240
so as to avoid the harms that can flow

155
00:07:23,240 --> 00:07:26,379
from data breaches and unlawful access

156
00:07:26,379 --> 00:07:28,759
so how do we see those challenges at

157
00:07:28,759 --> 00:07:31,129
Google how do we meet privacy and

158
00:07:31,129 --> 00:07:33,229
security expectations of users around

159
00:07:33,229 --> 00:07:36,319
the world complying with law is

160
00:07:36,319 --> 00:07:38,509
obviously a baseline requirement and

161
00:07:38,509 --> 00:07:40,430
we're working hard to make sure we get

162
00:07:40,430 --> 00:07:43,639
it right beyond that however we also

163
00:07:43,639 --> 00:07:45,259
have to contend with a simple fact that

164
00:07:45,259 --> 00:07:47,569
privacy means different things to

165
00:07:47,569 --> 00:07:49,190
different people in different situations

166
00:07:49,190 --> 00:07:51,860
and in different cultures there's simply

167
00:07:51,860 --> 00:07:55,069
no one-size-fits-all solution or easy

168
00:07:55,069 --> 00:07:58,310
answer here that's why we work hard to

169
00:07:58,310 --> 00:08:01,639
put the user in control people want to

170
00:08:01,639 --> 00:08:03,409
be in control the information they share

171
00:08:03,409 --> 00:08:05,870
and want to have choices about the

172
00:08:05,870 --> 00:08:08,960
services they use that takes a lot of

173
00:08:08,960 --> 00:08:11,779
engineering work privacy by design not

174
00:08:11,779 --> 00:08:14,360
just in the creation of new products but

175
00:08:14,360 --> 00:08:16,310
in the operation of your daily business

176
00:08:16,310 --> 00:08:21,860
a few examples first user controls our

177
00:08:21,860 --> 00:08:23,360
user dashboard lets you see the

178
00:08:23,360 --> 00:08:25,879
information stored by Google and access

179
00:08:25,879 --> 00:08:27,759
all your privacy settings from one place

180
00:08:27,759 --> 00:08:29,900
you can see the people you've shared

181
00:08:29,900 --> 00:08:31,909
documents with the apps you've

182
00:08:31,909 --> 00:08:34,570
downloaded to your phone much more

183
00:08:34,570 --> 00:08:36,979
people are using these tools and

184
00:08:36,979 --> 00:08:39,219
understanding the choices they're making

185
00:08:39,219 --> 00:08:41,779
10 million people check out their

186
00:08:41,779 --> 00:08:43,940
account history settings each week and

187
00:08:43,940 --> 00:08:46,100
they make roughly two and a half million

188
00:08:46,100 --> 00:08:48,860
changes to those settings roughly evenly

189
00:08:48,860 --> 00:08:50,930
split between people turning on settings

190
00:08:50,930 --> 00:08:53,040
and turning off settings

191
00:08:53,040 --> 00:08:55,330
keeping a record of what you search for

192
00:08:55,330 --> 00:08:57,480
can improve the quality of some results

193
00:08:57,480 --> 00:08:59,740
but if you want to search without your

194
00:08:59,740 --> 00:09:01,810
queries being stored turn off search

195
00:09:01,810 --> 00:09:05,080
history it's just that easy knowing your

196
00:09:05,080 --> 00:09:06,880
location helps us give directions

197
00:09:06,880 --> 00:09:09,370
without having you having to type in

198
00:09:09,370 --> 00:09:12,010
your current location that's great for

199
00:09:12,010 --> 00:09:13,480
people like me who have a hard time

200
00:09:13,480 --> 00:09:16,060
typing on small screens but you can

201
00:09:16,060 --> 00:09:19,870
always turn off location as well we take

202
00:09:19,870 --> 00:09:21,790
pride in letting people leave Google

203
00:09:21,790 --> 00:09:23,380
easily it's a little counterintuitive

204
00:09:23,380 --> 00:09:25,839
but we think it's the right thing to do

205
00:09:25,839 --> 00:09:28,510
and in the long term builds trust and

206
00:09:28,510 --> 00:09:31,690
quality of our services data portability

207
00:09:31,690 --> 00:09:35,290
matters so we built data take out a tool

208
00:09:35,290 --> 00:09:37,360
that lets you export and remove data

209
00:09:37,360 --> 00:09:40,210
stored by Google and import it to

210
00:09:40,210 --> 00:09:42,970
another service we want people using our

211
00:09:42,970 --> 00:09:44,830
services because they love them not

212
00:09:44,830 --> 00:09:46,540
because we somehow hold their data

213
00:09:46,540 --> 00:09:49,810
hostage now I also want to stress the

214
00:09:49,810 --> 00:09:52,089
importance of security I noticed a

215
00:09:52,089 --> 00:09:54,339
privacy conference but I also know that

216
00:09:54,339 --> 00:09:56,020
this audience understands better than

217
00:09:56,020 --> 00:09:58,990
perhaps anyone that data privacy and

218
00:09:58,990 --> 00:10:01,029
data security are not at odds with each

219
00:10:01,029 --> 00:10:02,890
other there are two sides of the same

220
00:10:02,890 --> 00:10:05,650
coin you can't have privacy without

221
00:10:05,650 --> 00:10:08,380
security your data just isn't private if

222
00:10:08,380 --> 00:10:11,440
it isn't secure we can see too easily

223
00:10:11,440 --> 00:10:13,450
what happens to privacy when security

224
00:10:13,450 --> 00:10:16,000
fails the celebrity hacks of late last

225
00:10:16,000 --> 00:10:18,300
year are a clear example of the risks

226
00:10:18,300 --> 00:10:20,770
people using the iCloud service were

227
00:10:20,770 --> 00:10:22,180
victimized likely through a

228
00:10:22,180 --> 00:10:24,490
sophisticated phishing or malware attack

229
00:10:24,490 --> 00:10:27,400
and consumers are clearly worried about

230
00:10:27,400 --> 00:10:29,770
breaches a recent poll in the u.s.

231
00:10:29,770 --> 00:10:31,360
showed that more people are concerned

232
00:10:31,360 --> 00:10:33,339
about being hacked than about having

233
00:10:33,339 --> 00:10:36,520
their house robbed the FTC once again

234
00:10:36,520 --> 00:10:38,560
found last year that identity theft a

235
00:10:38,560 --> 00:10:40,839
typical outcome when data security goes

236
00:10:40,839 --> 00:10:43,180
wrong was the leading consumer complaint

237
00:10:43,180 --> 00:10:47,190
in 2014 for the 15th consecutive year

238
00:10:47,190 --> 00:10:49,870
that's why we invest so heavily in

239
00:10:49,870 --> 00:10:52,029
strong account protections and encourage

240
00:10:52,029 --> 00:10:55,000
others to focus more on this area anti

241
00:10:55,000 --> 00:10:56,740
hijacking systems have reduced the

242
00:10:56,740 --> 00:10:58,930
number of compromised Google accounts by

243
00:10:58,930 --> 00:11:02,170
more than 99 percent since we introduced

244
00:11:02,170 --> 00:11:05,220
them in 2011 by blocking sufficient

245
00:11:05,220 --> 00:11:07,889
suspicious login attempts if you've ever

246
00:11:07,889 --> 00:11:10,350
traveled to a new place and got a gmail

247
00:11:10,350 --> 00:11:12,779
about a recent login that's our system

248
00:11:12,779 --> 00:11:14,790
at work we were one of the first

249
00:11:14,790 --> 00:11:16,139
companies to offer the additional

250
00:11:16,139 --> 00:11:17,699
protection of two-factor authentication

251
00:11:17,699 --> 00:11:20,939
across our accounts even if a hacker has

252
00:11:20,939 --> 00:11:23,009
your password he or she likely doesn't

253
00:11:23,009 --> 00:11:25,500
have your phone or security key so

254
00:11:25,500 --> 00:11:26,970
getting into your account becomes much

255
00:11:26,970 --> 00:11:30,180
harder our Safe Browsing technology

256
00:11:30,180 --> 00:11:32,129
scours the web for sites that try to

257
00:11:32,129 --> 00:11:35,790
steal passwords or contain malware you

258
00:11:35,790 --> 00:11:36,839
may have seen one of the very visible

259
00:11:36,839 --> 00:11:38,720
warnings we show when someone tries to

260
00:11:38,720 --> 00:11:41,040
navigate to a malware that malicious

261
00:11:41,040 --> 00:11:42,990
page and you're not alone we're

262
00:11:42,990 --> 00:11:45,449
currently showing 20 million warnings

263
00:11:45,449 --> 00:11:48,029
per week we make this data freely

264
00:11:48,029 --> 00:11:49,439
available to the public and other

265
00:11:49,439 --> 00:11:51,509
companies and since both Apple Safari

266
00:11:51,509 --> 00:11:53,850
and Mozilla's Firefox browsers use it

267
00:11:53,850 --> 00:11:57,000
taken together we help protect 1.1

268
00:11:57,000 --> 00:11:58,709
billion people around the world from

269
00:11:58,709 --> 00:12:02,759
attacks we also stopped all ads pointing

270
00:12:02,759 --> 00:12:05,040
to sites where we find malware last year

271
00:12:05,040 --> 00:12:07,860
alone we remove more than 250,000 sites

272
00:12:07,860 --> 00:12:10,319
from our ad network for hiding different

273
00:12:10,319 --> 00:12:13,319
kinds of Mellor but the internet

274
00:12:13,319 --> 00:12:15,899
interconnected nature of the web means

275
00:12:15,899 --> 00:12:17,670
that security is not just something one

276
00:12:17,670 --> 00:12:20,550
company can do by itself vulnerabilities

277
00:12:20,550 --> 00:12:22,500
of one system can create a launching pad

278
00:12:22,500 --> 00:12:25,170
for attacks on others that's why we're

279
00:12:25,170 --> 00:12:26,639
working to improve the state of the web

280
00:12:26,639 --> 00:12:29,639
ecosystem we're at large for example in

281
00:12:29,639 --> 00:12:31,170
an effort to engage other sites to use

282
00:12:31,170 --> 00:12:33,540
encryption we now rank the encrypted

283
00:12:33,540 --> 00:12:35,639
websites slightly higher in our search

284
00:12:35,639 --> 00:12:38,339
results also I know you've been hearing

285
00:12:38,339 --> 00:12:40,170
a lot about encryption at Google we've

286
00:12:40,170 --> 00:12:42,720
significantly in critics panda dauer use

287
00:12:42,720 --> 00:12:44,490
of encryption which helps safeguard

288
00:12:44,490 --> 00:12:46,319
fundamental human rights like privacy

289
00:12:46,319 --> 00:12:49,620
and free expression encryption requires

290
00:12:49,620 --> 00:12:51,809
governments including the US government

291
00:12:51,809 --> 00:12:54,480
to go through proper legal channels to

292
00:12:54,480 --> 00:12:56,309
request the data they need for an

293
00:12:56,309 --> 00:12:58,019
investigation rather than relying on

294
00:12:58,019 --> 00:13:00,899
mass surveillance Google was the first

295
00:13:00,899 --> 00:13:02,490
email service to be encrypted by default

296
00:13:02,490 --> 00:13:06,269
and Google search drive and maps are all

297
00:13:06,269 --> 00:13:06,750
encrypted

298
00:13:06,750 --> 00:13:09,449
we've encrypted dated moving internally

299
00:13:09,449 --> 00:13:11,670
between our servers a project we

300
00:13:11,670 --> 00:13:13,380
accelerated in the wake of the Snowden

301
00:13:13,380 --> 00:13:15,569
revelations and we're working to extend

302
00:13:15,569 --> 00:13:17,459
the encryption to more of our services

303
00:13:17,459 --> 00:13:18,170
every day

304
00:13:18,170 --> 00:13:21,690
of course the private sector can't do it

305
00:13:21,690 --> 00:13:23,820
alone governments have a responsibility

306
00:13:23,820 --> 00:13:25,950
to protect their citizens and an often

307
00:13:25,950 --> 00:13:28,080
pressing need to review private

308
00:13:28,080 --> 00:13:29,520
communications in the course of

309
00:13:29,520 --> 00:13:32,160
investigating crimes make no mistake we

310
00:13:32,160 --> 00:13:34,340
recognize that we have a legal and moral

311
00:13:34,340 --> 00:13:36,720
responsibility to protect the privacy

312
00:13:36,720 --> 00:13:39,540
and security of our users data at the

313
00:13:39,540 --> 00:13:42,090
same time we want to be responsible in

314
00:13:42,090 --> 00:13:43,940
helping government's keeping people safe

315
00:13:43,940 --> 00:13:47,220
we're committed to both goals so we work

316
00:13:47,220 --> 00:13:48,420
with governments in ways that are

317
00:13:48,420 --> 00:13:51,840
countable and transparent governments on

318
00:13:51,840 --> 00:13:53,400
both sides of the Atlantic are

319
00:13:53,400 --> 00:13:55,080
suggesting that they need access to

320
00:13:55,080 --> 00:13:57,210
encryption keys or other forms of

321
00:13:57,210 --> 00:14:00,030
backdoor access to user information in

322
00:14:00,030 --> 00:14:02,100
our view encryption doesn't just protect

323
00:14:02,100 --> 00:14:04,680
against bad guys it directs governments

324
00:14:04,680 --> 00:14:07,500
toward the front door using established

325
00:14:07,500 --> 00:14:10,950
legal process so we need to make the

326
00:14:10,950 --> 00:14:12,990
front door work better not build

327
00:14:12,990 --> 00:14:15,630
backdoors it's always been true that

328
00:14:15,630 --> 00:14:17,880
technology can be used used for good or

329
00:14:17,880 --> 00:14:20,610
for bad ever since people discovered

330
00:14:20,610 --> 00:14:23,760
fire there's been arson but since most

331
00:14:23,760 --> 00:14:25,440
people the overwhelming majority of

332
00:14:25,440 --> 00:14:27,510
people use the internet for good and

333
00:14:27,510 --> 00:14:29,640
legitimate ways we shouldn't weaken

334
00:14:29,640 --> 00:14:31,500
security and privacy protections for the

335
00:14:31,500 --> 00:14:33,480
majority to deal with the minority who

336
00:14:33,480 --> 00:14:36,210
dump that's why in both emergency and

337
00:14:36,210 --> 00:14:39,330
non-emergency situations we review every

338
00:14:39,330 --> 00:14:41,040
single data request that comes to our

339
00:14:41,040 --> 00:14:43,140
door to ensure that they comply with the

340
00:14:43,140 --> 00:14:45,390
law and are not over broad our

341
00:14:45,390 --> 00:14:47,910
transparency report that we were the

342
00:14:47,910 --> 00:14:50,310
first to publish shows that we are often

343
00:14:50,310 --> 00:14:52,430
pushing back on requests that we receive

344
00:14:52,430 --> 00:14:55,020
that's also why in non-emergency

345
00:14:55,020 --> 00:14:57,330
situations data requests especially for

346
00:14:57,330 --> 00:15:00,090
private communications like Gmail must

347
00:15:00,090 --> 00:15:02,040
always come through appropriate channels

348
00:15:02,040 --> 00:15:04,200
like mutual legal assistance treaties

349
00:15:04,200 --> 00:15:07,410
and what's which create processes for

350
00:15:07,410 --> 00:15:10,170
one government to request data stored by

351
00:15:10,170 --> 00:15:13,620
a company from another country still the

352
00:15:13,620 --> 00:15:15,900
EM lap process is too slow too

353
00:15:15,900 --> 00:15:19,230
complicated and in need of reform for

354
00:15:19,230 --> 00:15:20,940
example it would save everyone time if

355
00:15:20,940 --> 00:15:23,070
we move beyond fax machines and

356
00:15:23,070 --> 00:15:26,610
diplomatic pouches red wax and sealing

357
00:15:26,610 --> 00:15:29,280
ribbons to web forms that are quick and

358
00:15:29,280 --> 00:15:31,220
easy to process

359
00:15:31,220 --> 00:15:33,839
Europe is leading the way here and we

360
00:15:33,839 --> 00:15:35,250
now need the US government to follow

361
00:15:35,250 --> 00:15:38,370
suit and it's time for governments to

362
00:15:38,370 --> 00:15:40,380
step to consider changes to

363
00:15:40,380 --> 00:15:41,850
international agreements that would make

364
00:15:41,850 --> 00:15:44,550
data access contingent on the physical

365
00:15:44,550 --> 00:15:46,650
location of the person rather than the

366
00:15:46,650 --> 00:15:50,160
location of the data improving illegal

367
00:15:50,160 --> 00:15:52,620
channels for governments to obtain data

368
00:15:52,620 --> 00:15:54,810
is very different than permitting mass

369
00:15:54,810 --> 00:15:57,240
surveillance prism and other programs

370
00:15:57,240 --> 00:15:58,380
that were recently revealed

371
00:15:58,380 --> 00:16:00,690
we're damaging for the entire internet

372
00:16:00,690 --> 00:16:03,870
ecosystem and for the US government's

373
00:16:03,870 --> 00:16:05,370
relationship with Europe and other

374
00:16:05,370 --> 00:16:06,330
regions of the world

375
00:16:06,330 --> 00:16:08,490
we don't want technology companies

376
00:16:08,490 --> 00:16:11,310
mistakenly viewing viewed as doing mass

377
00:16:11,310 --> 00:16:13,730
surveillance that is just not the case

378
00:16:13,730 --> 00:16:16,260
but the revelation sparked a very

379
00:16:16,260 --> 00:16:18,029
important debate about privacy and

380
00:16:18,029 --> 00:16:19,650
security in the context of government

381
00:16:19,650 --> 00:16:21,870
surveillance we need to find a

382
00:16:21,870 --> 00:16:23,820
reasonable middle ground as we progress

383
00:16:23,820 --> 00:16:26,010
that debate one that restricts

384
00:16:26,010 --> 00:16:28,080
indiscriminate surveillance and aides

385
00:16:28,080 --> 00:16:30,450
valid law enforcement efforts while also

386
00:16:30,450 --> 00:16:32,520
protecting people's privacy and keeping

387
00:16:32,520 --> 00:16:34,950
their data secure we need surveillance

388
00:16:34,950 --> 00:16:36,959
reform including ecto reform in the

389
00:16:36,959 --> 00:16:39,690
United States we need encryption and we

390
00:16:39,690 --> 00:16:41,339
need better mechanisms for sharing data

391
00:16:41,339 --> 00:16:43,920
between governments for legitimate law

392
00:16:43,920 --> 00:16:46,830
enforcement purposes and as we continue

393
00:16:46,830 --> 00:16:49,589
to press for surveillance reform it's

394
00:16:49,589 --> 00:16:52,080
also crucial crucial that we continue to

395
00:16:52,080 --> 00:16:54,300
support the successful revision of the

396
00:16:54,300 --> 00:16:56,970
us-eu safe harbor agreement and other

397
00:16:56,970 --> 00:16:58,800
international agreements that facilitate

398
00:16:58,800 --> 00:17:01,610
data flows the safe harbor agreement and

399
00:17:01,610 --> 00:17:04,949
apex cross border privacy rules provides

400
00:17:04,949 --> 00:17:06,480
that a legitimate transfer of data in

401
00:17:06,480 --> 00:17:09,510
the cloud these programs help not just

402
00:17:09,510 --> 00:17:12,089
for big upstarts but for small upstarts

403
00:17:12,089 --> 00:17:14,510
as well they facilitate interoperability

404
00:17:14,510 --> 00:17:17,790
solve applicable law conflicts and give

405
00:17:17,790 --> 00:17:20,640
countries sorry companies an operating

406
00:17:20,640 --> 00:17:22,740
baseline by setting the standards for

407
00:17:22,740 --> 00:17:25,230
the transfer and protection of personal

408
00:17:25,230 --> 00:17:29,280
data these kinds of sustainable transfer

409
00:17:29,280 --> 00:17:31,050
models are critical to cross-border data

410
00:17:31,050 --> 00:17:33,630
flows and of the worldwide increasingly

411
00:17:33,630 --> 00:17:37,020
data-driven economy finally I'd like to

412
00:17:37,020 --> 00:17:38,490
say a few words about the recent White

413
00:17:38,490 --> 00:17:41,280
House draft privacy bill the US has

414
00:17:41,280 --> 00:17:42,840
demonstrated in this past week that it

415
00:17:42,840 --> 00:17:44,070
continues to work in developing

416
00:17:44,070 --> 00:17:44,670
legislation

417
00:17:44,670 --> 00:17:46,410
that strikes the right balance between

418
00:17:46,410 --> 00:17:48,060
protecting the rights of consumers and

419
00:17:48,060 --> 00:17:50,730
allowing for data innovation we applaud

420
00:17:50,730 --> 00:17:52,650
the efforts of the administration for

421
00:17:52,650 --> 00:17:54,930
kicking this off and for making it clear

422
00:17:54,930 --> 00:17:58,110
that this is a discussion draft figuring

423
00:17:58,110 --> 00:18:01,260
out the details will be difficult it's

424
00:18:01,260 --> 00:18:02,760
encouraging that the administration is

425
00:18:02,760 --> 00:18:04,620
welcoming an active discussion to

426
00:18:04,620 --> 00:18:06,840
improve on what they've put forth it's

427
00:18:06,840 --> 00:18:08,580
time for people to start considering how

428
00:18:08,580 --> 00:18:10,620
the details of this bill or any bill

429
00:18:10,620 --> 00:18:14,430
would work in practical terms do they

430
00:18:14,430 --> 00:18:16,650
effectively address privacy risks and

431
00:18:16,650 --> 00:18:19,860
real horns do they promote the kinds of

432
00:18:19,860 --> 00:18:21,810
transformative data-driven innovation

433
00:18:21,810 --> 00:18:24,930
that we've been discussing today as I

434
00:18:24,930 --> 00:18:27,510
noted at the outset privacy protection

435
00:18:27,510 --> 00:18:29,040
is one of the most difficult and

436
00:18:29,040 --> 00:18:31,980
important social technological and legal

437
00:18:31,980 --> 00:18:34,860
challenges we face today we've learned

438
00:18:34,860 --> 00:18:36,450
from experience it can be hard to apply

439
00:18:36,450 --> 00:18:38,640
privacy protections when privacy can

440
00:18:38,640 --> 00:18:40,500
mean so many different things to

441
00:18:40,500 --> 00:18:42,260
different people in different contexts

442
00:18:42,260 --> 00:18:44,640
that's why we put users in the driver's

443
00:18:44,640 --> 00:18:46,370
seat through settings and controls

444
00:18:46,370 --> 00:18:49,440
Portability and security we're working

445
00:18:49,440 --> 00:18:51,600
hard to apply sometimes challenging

446
00:18:51,600 --> 00:18:53,790
legal requirements working hard to make

447
00:18:53,790 --> 00:18:55,710
the web a safer place for everyone not

448
00:18:55,710 --> 00:18:57,870
just our users and working hard for

449
00:18:57,870 --> 00:19:00,150
surveillance reform and progress on data

450
00:19:00,150 --> 00:19:03,210
transfer rules the bottom line is that

451
00:19:03,210 --> 00:19:04,710
people around the world are benefitting

452
00:19:04,710 --> 00:19:06,450
from smarter uses of data to solve

453
00:19:06,450 --> 00:19:09,090
problems big and small it has never been

454
00:19:09,090 --> 00:19:11,940
more critical than all of us individuals

455
00:19:11,940 --> 00:19:14,310
companies and governments remain

456
00:19:14,310 --> 00:19:16,140
committed to solving these problems and

457
00:19:16,140 --> 00:19:19,590
to getting privacy and security right we

458
00:19:19,590 --> 00:19:21,300
work look forward to working with all of

459
00:19:21,300 --> 00:19:25,490
you toward that goal thank you very much

460
00:19:29,340 --> 00:19:33,300
were you really wise

