1
00:00:00,000 --> 00:00:10,760
alright thanks only wonder but I've been
told not use the LAV mic because there's

2
00:00:10,760 --> 00:00:16,590
feedbacks honest and right here at the
podium which is really weird I conduct

3
00:00:16,590 --> 00:00:22,250
alright I started a little history
lesson from 1970 to stay close to this

4
00:00:22,250 --> 00:00:28,769
man named James Anderson without was
hired by the USAir force to lead a

5
00:00:28,769 --> 00:00:34,300
computer security study by Anderson was
a former USNavy gunnery officer he later

6
00:00:34,300 --> 00:00:39,239
became a radio officer and by the time
he had been in this by the time he was

7
00:00:39,239 --> 00:00:43,750
hired by the Air Force had been a
private sector for about ten fifteen

8
00:00:43,750 --> 00:00:47,629
years he was established expert in
computer security among other things a

9
00:00:47,629 --> 00:00:52,550
number of patents the goal the Air Force
study was to determine whether it was

10
00:00:52,550 --> 00:00:56,149
possible to create a computing system
that would meet the classified security

11
00:00:56,149 --> 00:01:01,500
needs of the military airlift command
without having to invent a brand new

12
00:01:01,500 --> 00:01:05,170
operating system so that was the goal of
this study we pull together the

13
00:01:05,170 --> 00:01:09,140
technical team that was a mix of
government and academia and industry and

14
00:01:09,140 --> 00:01:13,439
they got together in about six months of
work later they produce a hundred and

15
00:01:13,439 --> 00:01:18,529
forty page report called the computer
security technology you planning study

16
00:01:18,530 --> 00:01:23,560
and the spielberg you could actually
argue define the direction of computer

17
00:01:23,560 --> 00:01:28,060
security research for the next decade
maybe longer

18
00:01:28,060 --> 00:01:33,780
it in numerate a number of topics for
future exploration and it predicted a

19
00:01:33,780 --> 00:01:38,829
lot of software security attack vectors
accurately got a lot of things wrong in

20
00:01:38,829 --> 00:01:42,990
terms of how competing with play out but
it predicted a lot of attack vectors

21
00:01:42,990 --> 00:01:46,429
really successfully and one of the
reasons I particularly like this paper

22
00:01:46,430 --> 00:01:50,180
and I'm sure it today is because it
contains to my knowledge one of the very

23
00:01:50,180 --> 00:01:55,259
first technical descriptions of a buffer
overflow vulnerability in the historical

24
00:01:55,259 --> 00:02:02,740
literature

25
00:02:02,740 --> 00:02:06,250
performing this function does not check
the source and destination addresses

26
00:02:06,250 --> 00:02:12,010
properly this can be used to inject code
into the modern that will prevent permit

27
00:02:12,010 --> 00:02:15,290
the user to seize control the machine
and my monitor here doesn't mean the

28
00:02:15,290 --> 00:02:18,940
thing that you're looking at the display
it's this other constantly he raises

29
00:02:18,940 --> 00:02:25,579
which is not important here but there is
a black and white 1972 and software

30
00:02:25,580 --> 00:02:31,840
security been terrible ever since but
that aside you can also say this is the

31
00:02:31,840 --> 00:02:35,650
first of many pieces of computer
security research that led us to where

32
00:02:35,650 --> 00:02:39,430
we are today in cybersecurity and so
that's what we gonna talk about the

33
00:02:39,430 --> 00:02:45,760
state of cybersecurity in 2016 very
briefly this means you have occasion

34
00:02:45,760 --> 00:02:52,950
security my whole career for some it's
not leadership that's enough about me

35
00:02:52,950 --> 00:03:00,579
ok so the stuff and share with you today
is a subset of what my company has

36
00:03:00,580 --> 00:03:04,849
published in something called the state
of software security report we do this

37
00:03:04,849 --> 00:03:08,619
periodically we have a lot of data at
all about that men and thus are six

38
00:03:08,620 --> 00:03:14,140
volume is designed for C so's
application security experts developers

39
00:03:14,140 --> 00:03:17,619
anybody who's doing software and once a
broad view of how software security is

40
00:03:17,620 --> 00:03:22,329
going the way I described this report
when people were like well there's a

41
00:03:22,329 --> 00:03:26,630
million reports out there what is the
difference with this one we report on

42
00:03:26,630 --> 00:03:31,350
software vulnerabilities hopefully
before breaches happen a lot of the

43
00:03:31,350 --> 00:03:35,709
other ones out there that are amazing
the dbl our other reports are reporting

44
00:03:35,709 --> 00:03:39,920
on Regis after they happen as we're
trying to talk about what phone bills

45
00:03:39,920 --> 00:03:45,298
are showing up and software across the
board at scale that may lead to bridges

46
00:03:45,299 --> 00:03:51,850
why would you listen to me talk about
this is opposed to the other hundreds of

47
00:03:51,850 --> 00:03:58,440
people that the notes are for security
reason as nobody else has application

48
00:03:58,440 --> 00:04:04,340
security did it at this scale so this
report includes data from over 200,000

49
00:04:04,340 --> 00:04:09,410
application assessments that were done
by my company

50
00:04:09,410 --> 00:04:15,720
over an eighteen-month period between
the end of 2013 and mid 2015 with a lot

51
00:04:15,720 --> 00:04:18,649
of customers we ask a lot of
applications most of this comes through

52
00:04:18,649 --> 00:04:22,799
static analysis but there's some other
analysis methods in there as well

53
00:04:22,800 --> 00:04:27,750
the vast majority of it is through
automated means one thing I should

54
00:04:27,750 --> 00:04:31,000
mention as I go through this I'm gonna
assume that you have a basic passing

55
00:04:31,000 --> 00:04:34,540
knowledge of application security
vulnerabilities are not explain what you

56
00:04:34,540 --> 00:04:34,820
know

57
00:04:34,820 --> 00:04:38,960
across the scripting is recommended
action and I'm not expect that you'll

58
00:04:38,960 --> 00:04:50,680
just be there no later

59
00:04:50,680 --> 00:04:55,830
some might say that this is just an
accurate just as accurate description of

60
00:04:55,830 --> 00:05:01,330
the state of software security today as
the very long report to be published but

61
00:05:01,330 --> 00:05:06,380
then that would be a really short
presentation so I enjoy this chief

62
00:05:06,380 --> 00:05:13,310
scientist tweeted itself that would show
that ok for you get into it with any

63
00:05:13,310 --> 00:05:17,539
study I think it's important to know the
source of the data the methodology

64
00:05:17,539 --> 00:05:21,900
so you can frame your interpretation of
the data I don't see this sort of thing

65
00:05:21,900 --> 00:05:27,030
covered very often when people
presenting reports so I'm gonna do it

66
00:05:27,030 --> 00:05:31,320
someone start by telling you a few of
the biases in our approach and the

67
00:05:31,320 --> 00:05:39,150
reason is just enhance our understanding
of what it means to here are some biases

68
00:05:39,150 --> 00:05:44,770
that are true of any study security
vulnerabilities regardless of you know

69
00:05:44,770 --> 00:05:53,758
the vendor whatever we have selection
bias this is our customers there are

70
00:05:53,759 --> 00:05:58,870
people producing software that are not
our customers they have a lot of

71
00:05:58,870 --> 00:06:03,840
applications they made shoes 500 of
those analyzed and leave out another

72
00:06:03,840 --> 00:06:13,119
thousand so the data is what we have you
can think of it as also a best-case

73
00:06:13,120 --> 00:06:16,590
scenario because we're also looking at
data from companies that care enough

74
00:06:16,590 --> 00:06:20,380
about application to actually do
something about it as a lot of them out

75
00:06:20,380 --> 00:06:27,740
there that are not doing anything so we
can kind of a best-case scenario type 1

76
00:06:27,740 --> 00:06:31,610
and type 2 experimental errors so and
automated software vulnerability

77
00:06:31,610 --> 00:06:35,289
scanning the other thing called boss
positive thing called false negatives

78
00:06:35,289 --> 00:06:39,560
and false positives when you detect
something and it's not real a false

79
00:06:39,560 --> 00:06:43,770
negative is when you fail to detect
something that is actually there so

80
00:06:43,770 --> 00:06:48,659
that's of course going to happen whether
it's a manual and test by UN whether its

81
00:06:48,659 --> 00:06:52,930
automated analysis being done by
computer you're going to have false

82
00:06:52,930 --> 00:06:58,009
positives and false negatives that
expected that's pegged into the data

83
00:06:58,009 --> 00:07:04,520
call this but capabilities by US I mean
we've built a technology we decide what

84
00:07:04,520 --> 00:07:08,729
the scan for we decide where to go deep
and shallow and certain areas which of

85
00:07:08,729 --> 00:07:12,330
course go as deep as we can in all areas
but there's gonna be some by as to the

86
00:07:12,330 --> 00:07:19,568
nature of the technology itself so
that's also a really really bad at a

87
00:07:19,569 --> 00:07:23,050
particular language as we just released
said we haven't gotten his mature on

88
00:07:23,050 --> 00:07:27,039
that as we are as we have for an older
language that's gonna be baked into the

89
00:07:27,039 --> 00:07:35,580
day as well as in kind of how you might
interpret the data so many NATO mission

90
00:07:35,580 --> 00:07:41,580
I call it or not knowing the majority of
a particular application may cause you

91
00:07:41,580 --> 00:07:46,729
to make some assumptions about your kind
of grouping it all together so you're

92
00:07:46,729 --> 00:07:50,469
saying like with this group of here
which is a really modern urban this one

93
00:07:50,469 --> 00:07:52,149
over here with his legacy

94
00:07:52,149 --> 00:07:55,339
you know we don't we don't capture that
we don't know how old the application is

95
00:07:55,339 --> 00:08:00,089
necessarily something all the data
together in terms of what we find an

96
00:08:00,089 --> 00:08:06,330
attribution bias you see some data man
this is really really bad like why is

97
00:08:06,330 --> 00:08:10,419
classic ASP so terrible that developers
must suck and like maybe that's true

98
00:08:10,419 --> 00:08:16,318
maybe it's not like that's not in the
dataset so we have an inclination do

99
00:08:16,319 --> 00:08:21,439
that based on our own experiences and
just try and get yourself out of that

100
00:08:21,439 --> 00:08:24,930
and not make those assumptions as we
don't actually have anything that says

101
00:08:24,930 --> 00:08:31,479
that we can make our best educated guess
again lasting from the biases just

102
00:08:31,479 --> 00:08:38,439
remember correlation is not causation is
ever get this ok so there was a spike in

103
00:08:38,440 --> 00:08:39,459
case you don't get it

104
00:08:39,458 --> 00:08:42,549
despite what this chart may suggest
you're not going to reduce the number of

105
00:08:42,549 --> 00:08:48,410
Nicolas Cage movies by erecting fences
around your swimming pools

106
00:08:48,410 --> 00:08:53,420
if you enjoy this and you haven't seen
this website that has the scrapping and

107
00:08:53,420 --> 00:08:58,110
many others you can google spurious
correlations is also a little went to

108
00:08:58,110 --> 00:09:01,540
the website the corner there but anyway
so just remember I say a few times

109
00:09:01,540 --> 00:09:05,389
remember correlation causation

110
00:09:05,389 --> 00:09:09,910
I will say a few times because you gonna
be really tempted to draw some

111
00:09:09,910 --> 00:09:16,579
conclusions that are not actually backed
by the data right now that we're 10

112
00:09:16,579 --> 00:09:20,689
minutes so we start by looking at how
different industry verticals compared to

113
00:09:20,689 --> 00:09:23,209
one another so we use industry
definition from the Bureau of Labor

114
00:09:23,209 --> 00:09:27,939
Statistics there's a lot of industries
they are defined so we don't necessarily

115
00:09:27,939 --> 00:09:32,969
want every chart to have like 50 bars on
it so we consolidate similar industries

116
00:09:32,970 --> 00:09:37,269
together so for example technology
includes technology telecom software

117
00:09:37,269 --> 00:09:45,899
electronics in a few others so when I
show you this they are based on industry

118
00:09:45,899 --> 00:09:49,389
groupings that we didn't make up that we
did make up the groupings to make it

119
00:09:49,389 --> 00:09:54,779
simple for today just have your say a
financial company a lot that a lot of

120
00:09:54,779 --> 00:09:59,689
times what you'll be asking us like my
peers but we thought it'd be interesting

121
00:09:59,689 --> 00:10:04,180
to see how different industries relate
how they rank relative to one another so

122
00:10:04,180 --> 00:10:09,469
sorry little bit

123
00:10:09,470 --> 00:10:15,400
so that shows you which industry does
best against standards on this is

124
00:10:15,400 --> 00:10:20,720
showing what percentage of applications
fail and they lost top 10 policy

125
00:10:20,720 --> 00:10:25,110
the first time it submitted so first of
all what does it mean to build policy in

126
00:10:25,110 --> 00:10:29,300
our parlance that means that you had at
least one instance of a vulnerability in

127
00:10:29,300 --> 00:10:35,520
that taxonomy so one single injection
would be a fail one crisis gripping

128
00:10:35,520 --> 00:10:40,130
would be a fail at a hundred or 1.2
accounting you know whether you like it

129
00:10:40,130 --> 00:10:43,970
or not we don't I don't like it I don't
know that you're THAT much worse off if

130
00:10:43,970 --> 00:10:47,860
you have a thousand people injections
were some hundred so we talk about

131
00:10:47,860 --> 00:10:52,830
failing or passing a policy based on if
you had anything in that taxonomy and

132
00:10:52,830 --> 00:10:56,520
taxonomy that's what a lot of customers
due to injuries of enforcing policies

133
00:10:56,520 --> 00:11:01,770
and compliance they do have passed
Failsworth thing and the other thing

134
00:11:01,770 --> 00:11:04,579
which I already said I want to point out
again is that this is based on the

135
00:11:04,580 --> 00:11:08,910
initial submission only the first time
in application is submitted and will

136
00:11:08,910 --> 00:11:18,219
talk about remediation StatsCan later so
not a lot of variance their financial

137
00:11:18,220 --> 00:11:28,130
services doing the best 58% 58% fail 76%
government during the worst that's not a

138
00:11:28,130 --> 00:11:32,740
huge variance and remember it only takes
one vulnerability in the US top ten to

139
00:11:32,740 --> 00:11:38,540
feel there's a lot of categories there
this is a slightly different view of the

140
00:11:38,540 --> 00:11:43,670
same data so the field applications are
shown in pink and you can sense the

141
00:11:43,670 --> 00:11:47,670
overwhelming majority of enterprise
applications are web-based that's the

142
00:11:47,670 --> 00:11:51,699
reason that we're using the OWASP top 10
in this case as a standard measure

143
00:11:51,700 --> 00:11:56,080
against so again we had a clear best and
worst got the Financial Services the

144
00:11:56,080 --> 00:11:59,900
best government is the worst and the
remaining sectors accounting group

145
00:11:59,900 --> 00:12:05,010
pretty close to remember this is not
just like you know five or 10

146
00:12:05,010 --> 00:12:11,569
applications in each industry there's a
total of 200,000 applications here in

147
00:12:11,570 --> 00:12:12,710
case you didn't notice

148
00:12:12,710 --> 00:12:17,040
and you probably did even the best
performing sector is failing for three

149
00:12:17,040 --> 00:12:23,750
out of five applications though this is
really awful ok show against who thinks

150
00:12:23,750 --> 00:12:30,190
law density and if you don't know that
terms for mega vibe flaws per thousand

151
00:12:30,190 --> 00:12:34,380
lines of code something like flaws per
unit we think that is a valuable thing

152
00:12:34,380 --> 00:12:38,310
to measure not a trick question

153
00:12:38,310 --> 00:12:47,430
alright so like 10 percent maybe fifteen
percent of the room so both answer

154
00:12:47,430 --> 00:12:51,959
disorder correct but there's a lot of
honesty about this and our customers ask

155
00:12:51,960 --> 00:12:56,260
but analysts ass about this i really
wanna know foster megabyte which is in

156
00:12:56,260 --> 00:13:01,150
fact something you can measure but it's
a very misleading metric because the

157
00:13:01,150 --> 00:13:06,050
programming language itself has a really
significant impact on that number

158
00:13:06,050 --> 00:13:13,170
someone would you can accomplish a lot
of stuff in very little code some of you

159
00:13:13,170 --> 00:13:16,640
may have seen this comic and it was
training to be an xkcd hitter so if

160
00:13:16,640 --> 00:13:24,480
you're one of those questioned grumbles
yourselves what else reads it requires

161
00:13:24,480 --> 00:13:25,520
guys flying

162
00:13:25,520 --> 00:13:30,860
Python how did you do that important I
gravity and it would probably take at

163
00:13:30,860 --> 00:13:35,550
least like 1000 or 5000 want to go to
implement anti gravity and Joba so

164
00:13:35,550 --> 00:13:42,589
there's a variance in the density of
what you can what you can do in a

165
00:13:42,590 --> 00:13:48,470
particular language that's why I bought
density is kind of a bogus number would

166
00:13:48,470 --> 00:13:53,760
use it in certain situations but here it
is anyway some languages particularly C

167
00:13:53,760 --> 00:13:57,860
and C++ produce compiled code this much
higher density than others like Jabba

168
00:13:57,860 --> 00:14:02,410
which means that industry one
organization that has a higher

169
00:14:02,410 --> 00:14:08,569
prevalence of of those denser languages
is gonna have to see this higher as well

170
00:14:08,570 --> 00:14:13,800
just math right I'm giving you these
industry comparison charts and

171
00:14:13,800 --> 00:14:17,660
immediately telling you not to read too
much into them like manufacturing which

172
00:14:17,660 --> 00:14:22,270
is on the very left they're very very
highest 352

173
00:14:22,270 --> 00:14:29,319
and healthcare is really low does that
mean that manufacturing companies right

174
00:14:29,320 --> 00:14:33,670
really really bad cone I mean maybe they
do but probably not

175
00:14:33,670 --> 00:14:41,469
23 times worse than health care it's
probably a sign up table is probably

176
00:14:41,470 --> 00:14:46,510
more about what's what's making up those
numbers what's making up that

177
00:14:46,510 --> 00:14:54,400
application portfolio so where flood
density can be a useful metric is a

178
00:14:54,400 --> 00:15:01,370
track internally within organization or
for an application overtime so where you

179
00:15:01,370 --> 00:15:07,940
have one thing and you're seeing is it
getting better or worse not comparing

180
00:15:07,940 --> 00:15:12,820
completely different populations so it's
it is useful for benchmarking that

181
00:15:12,820 --> 00:15:18,990
progress as a company as the dev team
you know as a business unit so come back

182
00:15:18,990 --> 00:15:22,030
to this metric again later we talk about
remediation rates and look at it with

183
00:15:22,030 --> 00:15:27,870
then that frame

184
00:15:27,870 --> 00:15:32,160
this is about as small as the bars get
this one's a little bit for the screen

185
00:15:32,160 --> 00:15:35,279
size but for showing us the prevalence
of a few different vulnerability

186
00:15:35,279 --> 00:15:40,650
counters categories that we've chosen a
different industry verticals the sequel

187
00:15:40,650 --> 00:15:43,970
injection and cross-site scripting have
consistently been at the top of the list

188
00:15:43,970 --> 00:15:48,640
for application security flaws
cryptographic flaws are in there because

189
00:15:48,640 --> 00:15:52,560
they've been highlighted in recent years
as a result of major phone bill is like

190
00:15:52,560 --> 00:15:55,859
heart bleed four distinct world consider
all concerned about security and privacy

191
00:15:55,860 --> 00:15:59,920
now so prepare stuff is pretty hot we
look at the prevalence of single

192
00:15:59,920 --> 00:16:03,740
injection and cross-site scripting
across the different new trees we see a

193
00:16:03,740 --> 00:16:07,390
fairly similar level you do see some
bars gonna stretching out to the right

194
00:16:07,390 --> 00:16:12,670
so government stands out as being
significantly worse than other

195
00:16:12,670 --> 00:16:18,569
industries in that regard those numbers
are anything to go on you know the the

196
00:16:18,570 --> 00:16:23,279
recent not so recently more disclosure
OPM may not be the last significant

197
00:16:23,279 --> 00:16:30,650
event in government security

198
00:16:30,650 --> 00:16:37,490
a slightly more confusing picture you've
got this cluster of prevalence around

199
00:16:37,490 --> 00:16:42,580
60% and again that 60% of applications
having at least one cryptographic issues

200
00:16:42,580 --> 00:16:44,630
or problems again

201
00:16:44,630 --> 00:16:48,170
healthcare stands out there's having
extremely high prevalence in that

202
00:16:48,170 --> 00:16:49,170
category

203
00:16:49,170 --> 00:16:55,849
manufacturing and the color their
government a little lower in that

204
00:16:55,850 --> 00:17:01,900
category so we have a lot more of this
in the report itself I'm not gonna do

205
00:17:01,900 --> 00:17:06,520
what the percentages reach one but it's
interesting to see that that variation

206
00:17:06,520 --> 00:17:10,650
where different issues are doing very
well in some areas in very early and

207
00:17:10,650 --> 00:17:17,490
others should say very well they're
doing better

208
00:17:17,490 --> 00:17:23,959
another slice of the state even cited a
number of different ways and we try to

209
00:17:23,959 --> 00:17:24,350
do it

210
00:17:24,349 --> 00:17:28,990
not entirely differently each time we do
report but we try to do a few things are

211
00:17:28,990 --> 00:17:32,920
different people cuba few things the
same for consistency is one thing you

212
00:17:32,920 --> 00:17:36,710
can do is you can slice the data by
language so we'll compare different

213
00:17:36,710 --> 00:17:39,970
programming languages now looking at the
relative security of applications

214
00:17:39,970 --> 00:17:44,100
written in those languages and how
prevalent certain categories are so

215
00:17:44,100 --> 00:17:48,449
remember what I said about the beginning
at the beginning about missing data we

216
00:17:48,450 --> 00:17:52,650
have to be careful not to draw too many
conclusions based on this so first of

217
00:17:52,650 --> 00:17:56,360
all the population that shows the
language distribution across the entire

218
00:17:56,360 --> 00:18:01,820
dataset for our past three reports and
remember the selection by staff actor

219
00:18:01,820 --> 00:18:05,220
but there's still a pretty sizable
increase in dotnet usage which is that

220
00:18:05,220 --> 00:18:09,809
kind of dark pink color even when you
account for the fact that over time

221
00:18:09,809 --> 00:18:14,350
we've had a broader set of supported
languages that we take in dotnet is

222
00:18:14,350 --> 00:18:19,990
actually increasing that's really the
only thing you should take a charter is

223
00:18:19,990 --> 00:18:22,960
that done that appears to be on the rise
relative to Java Enterprise IT

224
00:18:22,960 --> 00:18:28,630
enterprise environments because most of
all we do is enter price if you go back

225
00:18:28,630 --> 00:18:33,360
about 10 slides your number we talked
about comparing industries on top 10 so

226
00:18:33,360 --> 00:18:38,469
we're doing that again here except slice
by programming language instead of by

227
00:18:38,470 --> 00:18:43,620
industry so unsurprisingly compiled
application languages like C++ check to

228
00:18:43,620 --> 00:18:49,050
see that are not typically used for
creating web apps have a higher pass

229
00:18:49,050 --> 00:18:50,340
rate that makes sense right

230
00:18:50,340 --> 00:18:56,139
your web vulnerability is a number of
apps ok general-purpose bytecode

231
00:18:56,140 --> 00:19:00,059
languages like Java and.net which is the
highest value medications are a little

232
00:19:00,059 --> 00:19:05,899
lower than in scripting languages a
classic ASP PHP ColdFusion are coming in

233
00:19:05,900 --> 00:19:10,480
at the bottom there are far lower pass
rate though

234
00:19:10,480 --> 00:19:18,720
what conclusions can you draw from this
common denominator close enough that I

235
00:19:18,720 --> 00:19:23,809
would consider them in Queensland
scripting languages clearly need help

236
00:19:23,809 --> 00:19:30,410
there's something going on there we have
some guests about that

237
00:19:30,410 --> 00:19:34,610
prevalence again

238
00:19:34,610 --> 00:19:37,330
of certain types of vulnerabilities
except sliced my language is that

239
00:19:37,330 --> 00:19:42,418
industry so again as you would expect
single injection cross-site scripting

240
00:19:42,419 --> 00:19:48,140
are far more prevalent and web scripting
language is classic ASP ColdFusion PHP

241
00:19:48,140 --> 00:19:53,830
compared to dot net and Java and you
know I guess about this and you can make

242
00:19:53,830 --> 00:19:59,460
your own guess my guess is that it's
related to feature sets within the

243
00:19:59,460 --> 00:20:04,679
language so dot net and Java have a lot
of defenses built in I mean think about

244
00:20:04,679 --> 00:20:08,410
the evolution of crisis gripping
defenses in the dotnet framework over

245
00:20:08,410 --> 00:20:14,460
the years it's gotten pretty good you
compare that to PHP where I think it

246
00:20:14,460 --> 00:20:19,059
wasn't even at help PHP five maybe for
of it I think PHP 5 or you could even

247
00:20:19,059 --> 00:20:24,720
like like down parameters and Davis
group was actually part of the the the

248
00:20:24,720 --> 00:20:32,740
Corps classic classic ASP what sort of
security API is to have any right so

249
00:20:32,740 --> 00:20:37,510
developers are working within this
within this framework that doesn't give

250
00:20:37,510 --> 00:20:41,590
them many opportunities to protect the
code again that's just a guess

251
00:20:41,590 --> 00:20:44,899
computer has actually gotten better over
the years we take a lot of flak every

252
00:20:44,900 --> 00:20:48,419
time we put publish results that show
called fusion has a high prevalence rate

253
00:20:48,419 --> 00:20:53,490
I mean we're just going based on the
data we see it actually is high but will

254
00:20:53,490 --> 00:20:57,490
get feedback from developers and welcome
to think like it's getting a lot better

255
00:20:57,490 --> 00:21:02,179
and to some degree that's true to
improve for example they incorporate

256
00:21:02,179 --> 00:21:10,320
these sappy library from a loss into
distribution now that being said you're

257
00:21:10,320 --> 00:21:14,418
the best library for defense from office
that was jumping quarter and they

258
00:21:14,419 --> 00:21:15,200
haven't caught up in

259
00:21:15,200 --> 00:21:19,830
and and Pakistan instead so it is a
little bit behind it is getting better

260
00:21:19,830 --> 00:21:23,039
other languages that are sort of you
debtor legacy are not getting better or

261
00:21:23,039 --> 00:21:33,539
you're not getting new classic ASP
defense libraries anytime soon I also

262
00:21:33,539 --> 00:21:38,250
want to call out the high rate of
command injection in PHP so that's the

263
00:21:38,250 --> 00:21:42,130
little green bar where to the right and
Command injection and colin is out

264
00:21:42,130 --> 00:21:47,740
because we got challenged by a few
people on Twitter about about this and

265
00:21:47,740 --> 00:21:51,360
the general comment was like well a
peacoat all the time and i never see

266
00:21:51,360 --> 00:21:58,158
that nobody ever shells out and as a
command a direct command in PHP I never

267
00:21:58,159 --> 00:22:03,980
see this there's no possible way could
be a 35% or whatever that barr says and

268
00:22:03,980 --> 00:22:08,649
the first thing is it's not just a US
command injection that kind of an

269
00:22:08,649 --> 00:22:15,629
ejection its argument injection Oct 78
and 80 80 included in there and also we

270
00:22:15,630 --> 00:22:21,740
actually do see PHP up shelling out
using user input they do that this is

271
00:22:21,740 --> 00:22:25,820
where they can have your experience
comes into play if you're a pen tester

272
00:22:25,820 --> 00:22:29,990
and you're only you doing code reviews
or pen testing of PHP applications

273
00:22:29,990 --> 00:22:33,000
you know once a week you know one hour
per week or what happened a couple weeks

274
00:22:33,000 --> 00:22:38,480
you're probably getting the most
critical most scrutinized applications

275
00:22:38,480 --> 00:22:42,620
the company has the most important ones
of course they're probably gonna be over

276
00:22:42,620 --> 00:22:47,739
all a bit better than the ones that are
further down the priority level we're

277
00:22:47,740 --> 00:22:52,169
looking at all the times will begin with
companies that have a hundred thousand

278
00:22:52,169 --> 00:22:55,389
applications so we're getting the really
good stuff and they really legacy stuff

279
00:22:55,389 --> 00:23:03,209
and that's going to bring those averages
up terms of what types of refining the

280
00:23:03,210 --> 00:23:07,330
data is actually stand up when you look
at it with that scrutiny and the

281
00:23:07,330 --> 00:23:10,178
person's the person who made that
comment

282
00:23:10,179 --> 00:23:16,210
his experience is also correct so I
never see that like well we could show

283
00:23:16,210 --> 00:23:18,900
you

284
00:23:18,900 --> 00:23:26,150
we always get asked which languages most
secure in such a loaded question and

285
00:23:26,150 --> 00:23:32,790
this slide shows a little busy but the
side slip slide shows there's no simple

286
00:23:32,790 --> 00:23:37,760
answer to that question so let's look at
manufacturing the right there in the

287
00:23:37,760 --> 00:23:44,910
mill so they're a little different in
terms of language makeup so they're

288
00:23:44,910 --> 00:23:49,320
gonna bucking the trend this whole
java.net dominance thing I love more

289
00:23:49,320 --> 00:23:55,870
native code C++ and yet they're also
highly ranked in terms of security so

290
00:23:55,870 --> 00:24:00,379
the numbers over on the right or the
rankings if you go way back to the

291
00:24:00,380 --> 00:24:03,490
beginning we said which industry was
doing the best I remember financial

292
00:24:03,490 --> 00:24:06,580
services on top and government was at
the bottom so that's on the right is

293
00:24:06,580 --> 00:24:12,899
their rankings so even though
manufacturing has more native languages

294
00:24:12,900 --> 00:24:17,600
than than other industries they're
actually still doing better from policy

295
00:24:17,600 --> 00:24:21,679
compliance so you know I think I have a
lot to do with how seriously the

296
00:24:21,680 --> 00:24:27,910
industry take security in the dead life
cycle but again this is just a guess

297
00:24:27,910 --> 00:24:33,260
it's not surprising that financial
services at the top having brought this

298
00:24:33,260 --> 00:24:37,770
financial service companies my whole
career there always a little bit further

299
00:24:37,770 --> 00:24:41,000
ahead in terms of their thinking their
adoption of tools or adoption process

300
00:24:41,000 --> 00:24:47,980
not all of them but you know what I see
here is that if there are if there are

301
00:24:47,980 --> 00:24:52,250
any inherent security different
differences in language choice I think a

302
00:24:52,250 --> 00:24:57,580
lot of it can be overcome by process and
programs and someone taking it seriously

303
00:24:57,580 --> 00:25:02,668
building workflow around it

304
00:25:02,669 --> 00:25:09,399
this is my conclusion program majority
probably has a greater impact on

305
00:25:09,399 --> 00:25:15,059
security which choice and again you
think about manufacturing they've been

306
00:25:15,059 --> 00:25:20,899
dealing with things like process and
supply chain and thinking about where

307
00:25:20,899 --> 00:25:27,299
parts come from if you apply the same
disciplines to software which they do

308
00:25:27,299 --> 00:25:32,809
and we see that like what you guys think
about this much more you know much more

309
00:25:32,809 --> 00:25:36,820
forward-thinking than other companies
they're not thinking of supply chain and

310
00:25:36,820 --> 00:25:37,970
things of that nature

311
00:25:37,970 --> 00:25:41,190
you guys have a really rigorous workflow
around how you deal with partner how you

312
00:25:41,190 --> 00:25:47,649
deal with you know I don't know
manufacturing process and so it's maybe

313
00:25:47,649 --> 00:25:54,559
use a mindset issue I don't know this is
about as deep into the DL go and I call

314
00:25:54,559 --> 00:25:55,678
this out

315
00:25:55,679 --> 00:26:01,940
cryptographic flaws in global out and
that's just because against increased

316
00:26:01,940 --> 00:26:06,940
scrutiny recently on privacy and
security especially around mobile I want

317
00:26:06,940 --> 00:26:12,840
to conspecific CWE categories that we
found in Android and iOS applications so

318
00:26:12,840 --> 00:26:16,928
I'm less concerned about top 13 31
insufficient interview that gets flag

319
00:26:16,929 --> 00:26:21,019
flag when you use a random number
generator that's not sufficiently random

320
00:26:21,019 --> 00:26:25,549
and that's fine I mean not all the time
but most the time you use those random

321
00:26:25,549 --> 00:26:32,408
security critical anyway so not as big
of a deal in most cases but they're like

322
00:26:32,409 --> 00:26:36,379
the next one down to ninety seven is
like a huge concern because improper

323
00:26:36,379 --> 00:26:41,869
validation of significance and all the
time you look at you know mobile

324
00:26:41,869 --> 00:26:46,100
applications and they've disabled that
check so what does that mean we've got

325
00:26:46,100 --> 00:26:50,418
mad and middle right you getting
certificate the math works out you have

326
00:26:50,419 --> 00:26:55,009
encryption but you're not validating
identity and for some reason mobile apps

327
00:26:55,009 --> 00:26:56,749
are doing this all the time

328
00:26:56,749 --> 00:27:02,789
not been able to get to the bottom of
why I think anecdotally you talk to

329
00:27:02,789 --> 00:27:09,779
developers about it and perhaps I turned
off because QA and then

330
00:27:09,779 --> 00:27:12,889
they didn't want to cut a certificate
just to make it work and do as we turn

331
00:27:12,889 --> 00:27:18,369
it off over to actually write code to
overwrite to override that Checketts not

332
00:27:18,369 --> 00:27:23,340
is usually just get true false true
thing you actually an Android after

333
00:27:23,340 --> 00:27:27,099
right like a class that overrides should
be a validation and you know you have to

334
00:27:27,099 --> 00:27:32,989
do so in a number of cases anecdotally
they turn it off for QA purposes and

335
00:27:32,989 --> 00:27:35,639
then they just forget to turn it back on

336
00:27:35,639 --> 00:27:42,299
anyway we see that a lot and that's
really troubling and the reason for it

337
00:27:42,299 --> 00:27:47,309
you know the root cause not just the
fact that I think it causes its

338
00:27:47,309 --> 00:27:51,999
developer majority but obviously I don't
know for sure that you have a lot of

339
00:27:51,999 --> 00:27:56,769
mobile apps being developed by people
that have not had as much experience

340
00:27:56,769 --> 00:28:00,509
coding and that's not to say that people
fresh out of college

341
00:28:00,509 --> 00:28:05,009
can do a good job but I know it's
baffling that is that high and it's

342
00:28:05,009 --> 00:28:15,369
consistently that high over numerous
reports pretty crazy for doing well we

343
00:28:15,369 --> 00:28:22,459
got a lot of pretty dense material is
the first is a first for me I'm reward

344
00:28:22,460 --> 00:28:25,239
you with a few pictures of cash from the
internet in various stages of

345
00:28:25,239 --> 00:28:30,899
development so feel free to voice your
approval or disapproval and then we'll

346
00:28:30,899 --> 00:28:37,359
do a few more charges this appears to be
working on some sort of fluid dynamics

347
00:28:37,359 --> 00:28:39,030
simulation

348
00:28:39,030 --> 00:28:48,160
complex as God is contemplating a change
his out with him maybe as codes

349
00:28:48,160 --> 00:28:52,860
compiling this data just getting started

350
00:28:52,860 --> 00:28:57,189
encoding but he's hardly relating the
C++ may not be the best option these

351
00:28:57,190 --> 00:29:06,730
days that's on the back to a more charge
more charts we've talked a lot about

352
00:29:06,730 --> 00:29:09,640
languages and vulnerabilities in
industries and how different

353
00:29:09,640 --> 00:29:12,480
organizations compared with one another
but that's really only have two picture

354
00:29:12,480 --> 00:29:18,040
because I love this quote came from a
way you can't scare yourself to cure can

355
00:29:18,040 --> 00:29:22,540
scan all you want but if you don't fix
stuff like what's the point if you got

356
00:29:22,540 --> 00:29:26,020
the fewest flaws of the game and like
the other you know the other companies

357
00:29:26,020 --> 00:29:30,220
actually fixing their stuff so you
actually have to look at remediation how

358
00:29:30,220 --> 00:29:34,080
companies organizations industry is
doing at fixing the stuff that they

359
00:29:34,080 --> 00:29:41,389
actually find something really proud of
just as a person does more for this

360
00:29:41,390 --> 00:29:46,920
coming along time across all of our
customers in 2015 we detected nearly 10

361
00:29:46,920 --> 00:29:51,440
million flaws and customers are
remediated nearly seven million of those

362
00:29:51,440 --> 00:29:54,010
and then just last year which is pretty
cool

363
00:29:54,010 --> 00:30:00,879
ok so who which by industry which
industry fixes the most vulnerabilities

364
00:30:00,880 --> 00:30:09,400
are you surprised so much bigger
variants manufacturing and I was

365
00:30:09,400 --> 00:30:13,250
surprised the first time I saw it too
baby it's not as shocking as I think so

366
00:30:13,250 --> 00:30:19,490
we get to this clear view of the same
data but you can see there's this huge

367
00:30:19,490 --> 00:30:23,530
disparity when we went back to the house
industries did in terms of initial

368
00:30:23,530 --> 00:30:28,410
submission there was a very narrow
spread right there are between like 60%

369
00:30:28,410 --> 00:30:36,210
and 80% but he only got government only
fixing 27 percent of what sound and

370
00:30:36,210 --> 00:30:41,430
manufacturing is way up there 81% so
again a lot of factors may be at work

371
00:30:41,430 --> 00:30:46,040
then maybe regulatory drivers
contributing to that fixed rate there

372
00:30:46,040 --> 00:30:50,750
may be again I said about manufacturing
that process improvement methodologies

373
00:30:50,750 --> 00:30:55,310
kinda have a big to their culture they
may also be better at rolling out

374
00:30:55,310 --> 00:30:59,070
policies that are achieved through the
developers view is achievable so mad he

375
00:30:59,070 --> 00:31:02,669
has an area where like you're planning
application you find thousands of laws

376
00:31:02,670 --> 00:31:05,220
and you say your developers like you
have to fix all these within the next

377
00:31:05,220 --> 00:31:06,200
month

378
00:31:06,200 --> 00:31:09,480
like they're gonna come back and laugh
at you there's gonna not do it because

379
00:31:09,480 --> 00:31:15,220
it doesn't seem achievable and we found
in dealing with lots of enterprise

380
00:31:15,220 --> 00:31:18,160
they're trying to roll out policies on a
wide scale like that is that you have to

381
00:31:18,160 --> 00:31:21,580
make things achievable and so maybe the
first time around you say well you have

382
00:31:21,580 --> 00:31:25,720
to fix all the very highest highs within
90 days and there seems ludicrous to

383
00:31:25,720 --> 00:31:29,930
people that are done pen testing with it
you don't understand how quickly these

384
00:31:29,930 --> 00:31:33,970
things can actually be fixed but we have
seen a lot of companies have success

385
00:31:33,970 --> 00:31:39,330
doing that and then they make that that
step and then they tighten the policies

386
00:31:39,330 --> 00:31:45,220
but if you know relegate you like we had
to fix everything immediately then

387
00:31:45,220 --> 00:31:48,980
you've actually create the situation
where nothing gets done because it just

388
00:31:48,980 --> 00:31:54,600
seems insurmountable again I do know
there are cases where companies have had

389
00:31:54,600 --> 00:31:58,060
success because they do that I don't
know if that's the reason that 81

390
00:31:58,060 --> 00:32:03,730
percent and 20 or 27 percent are you
know just bury their but I think there's

391
00:32:03,730 --> 00:32:10,980
probably some contribution of things
like that

392
00:32:10,980 --> 00:32:17,070
density so that power density changes
from the first assessment to the last

393
00:32:17,070 --> 00:32:22,720
assessment of a particular application
that's useful so in lieu of all flaws in

394
00:32:22,720 --> 00:32:29,710
green looking at only very high and high
security flaws and applications that are

395
00:32:29,710 --> 00:32:33,320
only assess one time which is not
represented in this trial but have not

396
00:32:33,320 --> 00:32:37,500
had any remediation in the time frame
the window the study you see you about a

397
00:32:37,500 --> 00:32:40,420
hundred and fifty three flights per
megabyte so there was actually are

398
00:32:40,420 --> 00:32:49,680
getting remediated are all lower over
time you see that customers reduce flood

399
00:32:49,680 --> 00:32:53,340
density for all flaws by you know going
from

400
00:32:53,340 --> 00:33:02,350
um 58 250 but for the laws are ranked
severity high and very high are going

401
00:33:02,350 --> 00:33:06,530
down much more drastically and what the
suggests to us is that customers this

402
00:33:06,530 --> 00:33:10,070
this should be a shocker customers
prioritize remediation of the high and

403
00:33:10,070 --> 00:33:15,080
very high salary plus over fixing other
ones and it almost suggests that their

404
00:33:15,080 --> 00:33:19,030
security policies may focus exclusively
on those flaws in other words they may

405
00:33:19,030 --> 00:33:23,940
be intentionally ignoring remediation of
those things that they view as as less

406
00:33:23,940 --> 00:33:29,680
severe than that probably makes sense
logically but I have the data to back it

407
00:33:29,680 --> 00:33:38,390
up now to get you in here so remember
correlation is not causation so one of

408
00:33:38,390 --> 00:33:41,060
the things we make available to
customers is like a readout call and you

409
00:33:41,060 --> 00:33:45,020
get on the phone with somebody who knows
securing development and they walk you

410
00:33:45,020 --> 00:33:48,410
through what we found a kind of how to
fix stuff and you can ask questions and

411
00:33:48,410 --> 00:33:52,040
not required but we got a lot of good
feedback on the experience and so we do

412
00:33:52,040 --> 00:33:56,750
that for a lot of organizations
especially the first time through his me

413
00:33:56,750 --> 00:34:03,230
so you'd expect that that would have a
positive impact on remediation rates but

414
00:34:03,230 --> 00:34:07,270
you never know until you measure so what
we did was we looked at applications

415
00:34:07,270 --> 00:34:10,080
where there was a readout force
application where there wasn't a readout

416
00:34:10,080 --> 00:34:13,290
and we looked at the percent decrease in
flow density for that particular

417
00:34:13,290 --> 00:34:17,550
application so again comparing point A
to point B timeline wise for a

418
00:34:17,550 --> 00:34:22,100
particular application to flood into
your spine there and we saw a

419
00:34:22,100 --> 00:34:27,520
significant difference applications that
did have remediation done but without a

420
00:34:27,520 --> 00:34:34,449
readout reduced by 17% and applications
that can fix some stuff with a readout

421
00:34:34,449 --> 00:34:40,649
was 42% reduction so that that's two and
a half times better when there was read

422
00:34:40,650 --> 00:34:44,050
out was because of the readout I don't
know if they do the readout because

423
00:34:44,050 --> 00:34:47,800
they're just really much more attuned to
application security in somebody's kind

424
00:34:47,800 --> 00:34:52,990
of like crack in the web maybe I like to
think it's because the readout but I can

425
00:34:52,989 --> 00:34:58,120
tell you that for sure but there's
definite correlation and the numbers are

426
00:34:58,120 --> 00:34:58,920
pretty stunning

427
00:34:58,920 --> 00:35:06,349
another thing that we tell people is
gonna CBT based e-learning around

428
00:35:06,349 --> 00:35:10,109
applications curies ago coding and
various things of that nature so it

429
00:35:10,109 --> 00:35:14,180
ought to be interesting to try to
measure the impact of you learning and

430
00:35:14,180 --> 00:35:17,710
remediation rates but that's even harder
to connect the dots because a lot of

431
00:35:17,710 --> 00:35:22,640
other factors and you would think that
the more likely outcome of e-learning if

432
00:35:22,640 --> 00:35:28,720
there was a positive impact would be the
first place when you look at the overall

433
00:35:28,720 --> 00:35:36,149
fixed-rate customers have established an
e-learning program we noticed that the

434
00:35:36,150 --> 00:35:42,730
fixed rate is considerably higher 75%
658 so it's a three percent difference

435
00:35:42,730 --> 00:35:47,960
does suggest there some correlation with
having that type of program around

436
00:35:47,960 --> 00:35:52,290
compared to your fixed rate but to all
these other things that are in play

437
00:35:52,290 --> 00:35:56,240
having a program doesn't mean that the
particular developer for that

438
00:35:56,240 --> 00:35:59,649
application took that course we're not
winning and how well they didn't of

439
00:35:59,650 --> 00:36:03,849
course not factory knapsack program
which ready or not factoring in

440
00:36:03,849 --> 00:36:07,250
regulatory compliance drivers are not
factoring in the remediation coaching

441
00:36:07,250 --> 00:36:11,299
that we factored in on the last slide so
it's really hard to take one single

442
00:36:11,299 --> 00:36:19,180
factor in drug inclusion about it and
that's why but this is a really

443
00:36:19,180 --> 00:36:22,819
contentious topic and some people really
scream at you when you say that security

444
00:36:22,819 --> 00:36:26,349
training could possibly result in more
secure software so I think I held

445
00:36:26,349 --> 00:36:30,420
personally I think it helps I'm a little
bit correlation there between companies

446
00:36:30,420 --> 00:36:34,089
have a program and those who don't and
they have program have a higher tax rate

447
00:36:34,089 --> 00:36:40,170
but I don't have any way of proving that
so I did not make that claim and the

448
00:36:40,170 --> 00:36:43,940
last one during every last bit of the
day that said we decided if there was

449
00:36:43,940 --> 00:36:48,910
any variation in fix rate based on the
type of analysis of performs a static

450
00:36:48,910 --> 00:36:54,920
analysis dynamic analysis male
penetration testing and we saw that on

451
00:36:54,920 --> 00:36:59,829
average companies tend to 60 abilities
at a higher rate when the static

452
00:36:59,829 --> 00:37:00,990
analysis

453
00:37:00,990 --> 00:37:06,390
number of reasons for that I think that
it provides a little bit higher fidelity

454
00:37:06,390 --> 00:37:08,730
results around root cause so

455
00:37:08,730 --> 00:37:14,110
you can narrow down a finding to a
particular file and line of code points

456
00:37:14,110 --> 00:37:18,740
the developer exactly where they need to
make effects whereas if you doing local

457
00:37:18,740 --> 00:37:22,910
web scanner dynamics can you gonna get a
URL and you're gonna get there here's

458
00:37:22,910 --> 00:37:25,970
what happened when we sent a request and
response and just we saw that you're not

459
00:37:25,970 --> 00:37:29,500
going to necessarily give the developer
the exact line of code a lot of people

460
00:37:29,500 --> 00:37:32,240
to figure out obviously as their
application that kinda know how it works

461
00:37:32,240 --> 00:37:36,479
but when you give somebody very
prescriptive guidance about where to go

462
00:37:36,480 --> 00:37:38,630
and what to do

463
00:37:38,630 --> 00:37:44,080
it's even easier that's my best guess
about why you say that variation between

464
00:37:44,080 --> 00:37:48,750
static and the other two types of you
think about a manual pen tester getting

465
00:37:48,750 --> 00:37:52,180
kind of the same level of information
that you are dynamics can write you

466
00:37:52,180 --> 00:37:56,370
getting a URL getting a request for
sponsors getting maybe when we inject

467
00:37:56,370 --> 00:38:00,170
something into this particular parameter
but again they have to go and figure out

468
00:38:00,170 --> 00:38:03,940
where does that map in the framework on
using where would I actually put

469
00:38:03,940 --> 00:38:12,370
validation and so on this last section
isn't directly related to our study but

470
00:38:12,370 --> 00:38:14,930
it's something I wanted to include
anyway because I always feel we're doing

471
00:38:14,930 --> 00:38:18,230
presentations without putting some sort
of actionable thing at the end to kind

472
00:38:18,230 --> 00:38:24,030
of take the way we can all go read the
report but we run programs for a lot of

473
00:38:24,030 --> 00:38:29,730
companies and you look at kind of what
makes them successful there's some

474
00:38:29,730 --> 00:38:36,240
pretty basic things you can do to raise
your chance of success so I wanna give a

475
00:38:36,240 --> 00:38:40,250
few tips when you're one of the people
responsible for something scary your

476
00:38:40,250 --> 00:38:49,370
company going back so one more quick
story around the time of World War one

477
00:38:49,370 --> 00:38:54,700
only seven percent of American
households owned toothpaste the army had

478
00:38:54,700 --> 00:38:58,580
enacted the draft around this time and
they were finding that so many recruits

479
00:38:58,580 --> 00:39:02,830
were coming in and join the army and
they're showing up the rotten teeth that

480
00:39:02,830 --> 00:39:06,779
government officials actually declared
poor dental hygiene and national

481
00:39:06,780 --> 00:39:08,750
security risk is true

482
00:39:08,750 --> 00:39:15,600
around the same time a man named Claude
Hopkins was hired by the toothpaste

483
00:39:15,600 --> 00:39:19,610
toothpaste company to design a national
ad campaign in Hopkins was this

484
00:39:19,610 --> 00:39:24,880
marketing genius who had done these rays
campaigns in the past with great success

485
00:39:24,880 --> 00:39:25,700
he done

486
00:39:25,700 --> 00:39:33,680
campaign which God huge uptick in palm
oil sales and he had claimed that like

487
00:39:33,680 --> 00:39:37,730
Cleopatra you had used just completely
false obviously but he was like this

488
00:39:37,730 --> 00:39:40,990
marketing genius he needed to find
something that would make people want to

489
00:39:40,990 --> 00:39:45,790
brush their teeth more often so that you
could sell more Pepsi and so he went he

490
00:39:45,790 --> 00:39:50,640
started reading dental literature Dental
Studies and dental text books and he

491
00:39:50,640 --> 00:39:53,730
seized upon the sting called newson
plaques and it's just something that

492
00:39:53,730 --> 00:40:00,310
accumulates on the teeth overtime
naturally and it's so easy he renamed

493
00:40:00,310 --> 00:40:06,740
that to the film The Dirty film the
yellow film and what he did is he kind

494
00:40:06,740 --> 00:40:13,399
of appeal to the public's narcissism or
desire for beauty and he reframed

495
00:40:13,400 --> 00:40:19,790
president is not a health care thing but
it beauty aid as brilliant as well this

496
00:40:19,790 --> 00:40:29,450
did was to give people think about
different way three weeks after the ads

497
00:40:29,450 --> 00:40:34,460
in national pepsin couldn't handle the
demand three years later it was an

498
00:40:34,460 --> 00:40:36,960
international product ten years later

499
00:40:36,960 --> 00:40:43,170
sixty-five percent of American
households 0222 to this number if you

500
00:40:43,170 --> 00:40:48,090
think about it today but sixty-five from
seven is pretty good and so what he did

501
00:40:48,090 --> 00:40:52,840
is he defined and he was doing this just
think about it in this way but he

502
00:40:52,840 --> 00:40:57,970
defined simple Q the film them develop
on your teeth every morning and that

503
00:40:57,970 --> 00:41:00,970
would trigger a particular behavior
which the brushing and there was a clear

504
00:41:00,970 --> 00:41:07,830
reward associated with that which was
being prettier and that cycle created

505
00:41:07,830 --> 00:41:13,840
this this habit and the end of ww2
military downgraded for dental hygiene

506
00:41:13,840 --> 00:41:16,049
where it was no longer

507
00:41:16,049 --> 00:41:20,299
a national security risk that's a great
marking system success story but was

508
00:41:20,299 --> 00:41:26,170
happy with abstract we have to I think
we have to think like that happens in

509
00:41:26,170 --> 00:41:29,640
terms of motivating developers to build
habits around security activities

510
00:41:29,640 --> 00:41:34,819
whether that's you know scanning the
code base after every build or whether

511
00:41:34,819 --> 00:41:37,729
it's remembering to follow a security
checklist every time they build a new

512
00:41:37,729 --> 00:41:43,899
feature whatever reading habit can be
extremely useful you can imagine how

513
00:41:43,900 --> 00:41:47,339
daily task that they'd have to do every
day or with every feature might be more

514
00:41:47,339 --> 00:41:52,679
useful than a quote-unquote habitats
likes to append test every year because

515
00:41:52,679 --> 00:41:56,559
you do it then you forget about it
doesn't really change behavior so

516
00:41:56,559 --> 00:41:59,660
they're not really a one size fits all
approach here it depends a lot on how

517
00:41:59,660 --> 00:42:04,699
development stunning your company what
type of culture you have but if you can

518
00:42:04,699 --> 00:42:07,589
find a corresponding trigger and drive
the particular behavior that you're

519
00:42:07,589 --> 00:42:10,078
trying to drive and hopefully this
summer wardrobe that your most of the

520
00:42:10,079 --> 00:42:14,309
way of creating a habit you want to read
more about the person thing and other

521
00:42:14,309 --> 00:42:17,539
you know sort of the psychology of
habits there's a really good book called

522
00:42:17,539 --> 00:42:21,999
the power of habit that gets a lot more
detail would recommend that so number

523
00:42:21,999 --> 00:42:27,979
one find ways to create habits number
two i talked about this earlier but the

524
00:42:27,979 --> 00:42:33,769
fact that when developers receive
remediation guidance they did better

525
00:42:33,769 --> 00:42:38,390
remediation the point is that they did
remediation so again if you're only

526
00:42:38,390 --> 00:42:42,140
focus on how much you can scan as
opposed to how much for fixing then

527
00:42:42,140 --> 00:42:46,308
you're kind of focusing on the only half
the problem how do you make that push

528
00:42:46,309 --> 00:42:50,650
toward remediation focus program any
number of ways you couldn't mandatory

529
00:42:50,650 --> 00:42:54,089
doubt you could do something simple like
make sure you import all your findings

530
00:42:54,089 --> 00:42:57,259
of the bug tracking system because what
developers to go to the bug tracking

531
00:42:57,259 --> 00:43:01,939
system and they fix the faulty bugs that
came up and there's definitely have it

532
00:43:01,939 --> 00:43:05,359
there right so they've got you think
about you know cue behaviour orders got

533
00:43:05,359 --> 00:43:10,299
the queue it's just like checking juror
Bugzilla the paper was just fixing bugs

534
00:43:10,299 --> 00:43:13,469
and then the reward is like being able
to mark tickets as close which you may

535
00:43:13,469 --> 00:43:18,239
not think its reward but like trust me
developers love to markets closed

536
00:43:18,239 --> 00:43:21,789
number two is the thing about steps that
you can take to encourage and facilitate

537
00:43:21,789 --> 00:43:22,910
remediation

538
00:43:22,910 --> 00:43:29,700
and again that seems very obvious but if
you go back to the data we show that how

539
00:43:29,700 --> 00:43:35,129
much does not getting remediated it's
obviously not a solved problem

540
00:43:35,130 --> 00:43:38,319
third thing he drugged her she don't
know is kind of nice given credit for

541
00:43:38,319 --> 00:43:42,240
modern management philosophy anyway said
what gets measured gets managed the idea

542
00:43:42,240 --> 00:43:44,750
is pretty simple hear something that
you're paying attention to actually

543
00:43:44,750 --> 00:43:48,289
managing will cause you to improve in
those cases unless you actively

544
00:43:48,289 --> 00:43:52,980
sabotaging the process you will probably
get better and sometimes hard when

545
00:43:52,980 --> 00:43:57,049
you're really close to a situation to
see progress subjectively just like you

546
00:43:57,049 --> 00:44:03,369
know you have some really tall like you
know when the next twelve you don't you

547
00:44:03,369 --> 00:44:10,280
don't see minor progress subjectively
unless you're measuring and so if you

548
00:44:10,280 --> 00:44:13,569
measure stuff whatever those remediation
raids flood density whatever it is

549
00:44:13,569 --> 00:44:18,049
you're able to kind of give yourself
credit for what you've done and you're

550
00:44:18,049 --> 00:44:22,750
able to track and manage progress over
longer periods of time so number three's

551
00:44:22,750 --> 00:44:28,819
measure early and often against seems so
obvious but many programs do not do this

552
00:44:28,819 --> 00:44:34,630
very well so do those three things form
habits focus on remediation

553
00:44:34,630 --> 00:44:40,440
metrics so there's my takeaway that's
all I have for you today I have five

554
00:44:40,440 --> 00:45:01,040
minutes I think I'll be having sexual
questions there

555
00:45:01,040 --> 00:45:07,660
yeah

556
00:45:07,660 --> 00:45:11,270
ya know how we look at products raids in
comparing different types of

557
00:45:11,270 --> 00:45:14,740
applications that handle different sorts
of data like financial data versus

558
00:45:14,740 --> 00:45:20,220
healthcare dinner theater is beyond
looking at those industry slices no

559
00:45:20,220 --> 00:45:23,879
because most the time we're doing an
analysis of an application they're

560
00:45:23,880 --> 00:45:27,170
letting us compiled binaries we don't
really have the context of the

561
00:45:27,170 --> 00:45:31,160
application we know that comes from a
healthcare company but maybe it's like

562
00:45:31,160 --> 00:45:38,660
maybe it's not actually dealing with PII
right maybe the financial one has to do

563
00:45:38,660 --> 00:45:43,240
with you know something that's the
didn't have a sword in it but its

564
00:45:43,240 --> 00:45:47,140
related trading something like that so
we don't have enough metadata around

565
00:45:47,140 --> 00:45:50,078
what the applications being used for in
this context to really make this place

566
00:45:50,079 --> 00:46:14,779
we go as grand as we can but but with
industry and the back

567
00:46:14,779 --> 00:46:19,589
the question is so with mobile apps in
the whole certificate issue certificates

568
00:46:19,589 --> 00:46:23,489
are actually cheap and why would people
do that i mean yeah I agree with you

569
00:46:23,489 --> 00:46:29,309
when I said expensive if I actually use
that word I think I was using expensive

570
00:46:29,309 --> 00:46:34,169
in the dollar amount but more just in
the the hassle amount that they have to

571
00:46:34,169 --> 00:46:37,449
cut the certain put it in the QA and
then let him suck you a service have

572
00:46:37,449 --> 00:46:41,439
different names and then also it's more
of a hassle thing but you know your

573
00:46:41,439 --> 00:46:47,009
rights are increasingly now our low cost
or free and I totally agree with you i

574
00:46:47,009 --> 00:46:56,010
don't i don't get it there

575
00:46:56,010 --> 00:46:59,890
so to what extent do I think the
remediation number for government are

576
00:46:59,890 --> 00:47:07,089
skewed by the amount of time that the
tapes from the dream well so this was

577
00:47:07,090 --> 00:47:15,060
the study was an eighteen month window
so if they scan at the beginning of that

578
00:47:15,060 --> 00:47:19,020
window and had fix it by the end of the
window it was included in remediation

579
00:47:19,020 --> 00:47:25,790
now you do have cases where the scanned
for the first time near the end of that

580
00:47:25,790 --> 00:47:29,750
window it wouldn't be and maybe they
fixed it like a day after we closed you

581
00:47:29,750 --> 00:47:33,850
know that when they would get credit for
fixing that because both the beginning

582
00:47:33,850 --> 00:47:38,270
and the end in volunteer that so I think
with any industry there's there's some

583
00:47:38,270 --> 00:47:44,740
of those cases where you stand that that
border of when we started ran to the

584
00:47:44,740 --> 00:47:53,299
window but eighty-one percent versus 27%
is pretty wide so yes it's probably and

585
00:47:53,300 --> 00:47:57,530
probably a factor but it probably only
explains like a really small amount of

586
00:47:57,530 --> 00:48:06,090
it is just a guess you're right in front

587
00:48:06,090 --> 00:48:08,630
yep

588
00:48:08,630 --> 00:48:17,620
so question was about languages that
were not included on the list of

589
00:48:17,620 --> 00:48:23,220
language comparisons such as Python and
other languages

590
00:48:23,220 --> 00:48:30,759
member we talked about selection bias so
it's things that we support so we do so

591
00:48:30,760 --> 00:48:34,020
for example we just for Ruby on Rails
but we just don't get a lot of it from

592
00:48:34,020 --> 00:48:38,610
customers it's not as prevalent in
enterprise environments so we just don't

593
00:48:38,610 --> 00:48:40,060
have as much data on it

594
00:48:40,060 --> 00:48:47,970
python Python coming out soon but of
course the 2013 have any date on it so

595
00:48:47,970 --> 00:48:51,529
yeah just that's why gonna call out like
remember the selection biases are you

596
00:48:51,530 --> 00:48:54,480
know what features we build what things
we support and you know what our

597
00:48:54,480 --> 00:49:14,470
customers chooses to give us

598
00:49:14,470 --> 00:49:25,129
what percentage of those are actually
exploitable flaws to paraphrase the

599
00:49:25,130 --> 00:49:29,250
terminology used warnings to me in the
output of static analysis that's fine

600
00:49:29,250 --> 00:49:35,050
some tools may use that what I mean is
the direct output of what we provide the

601
00:49:35,050 --> 00:49:38,000
customers some of those will become
exploitable some will not become

602
00:49:38,000 --> 00:49:42,460
exploitable that's true across the board
that's part of the deal that's part of

603
00:49:42,460 --> 00:50:16,290
what i'm talking bout with experimental
air they're very high density reducing

604
00:50:16,290 --> 00:50:23,220
from 97 or 98 whatever does that mean
there's an increase in the lower medium

605
00:50:23,220 --> 00:50:29,450
security flaws I would say not a
statistically important increase I mean

606
00:50:29,450 --> 00:50:32,399
there's always fluctuation right you
write new code you scan again you

607
00:50:32,400 --> 00:50:37,460
introduce some new flaws but what is
just really telling us is that people

608
00:50:37,460 --> 00:50:42,160
focus on the higher severity flaws first
which is what you would expect them to

609
00:50:42,160 --> 00:50:46,399
do but they did it kind of place that
out we're not seeing like significant

610
00:50:46,400 --> 00:50:50,630
increases in medium security because
they're focusing on on very high tonight

611
00:50:50,630 --> 00:50:55,980
we're seeing them fix those on average
slower and you know what with less I

612
00:50:55,980 --> 00:51:01,099
guess intensity that they fix the
Verizon highest I have a stop sign so

613
00:51:01,099 --> 00:51:05,589
I'll be around thanks for coming and
enjoy the best conference

