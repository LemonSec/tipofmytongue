1
00:00:00,030 --> 00:00:05,009
so this is don't work with<font color="#E5E5E5"> my</font><font color="#CCCCCC"> advisor</font>

2
00:00:02,610 --> 00:00:13,290
Patrick McDonald<font color="#E5E5E5"> and collaborators from</font>

3
00:00:05,009 --> 00:00:16,139
<font color="#E5E5E5">University of Wisconsin and ARL here we</font>

4
00:00:13,290 --> 00:00:19,310
go<font color="#E5E5E5"> so just</font><font color="#CCCCCC"> to get you started</font>

5
00:00:16,139 --> 00:00:23,820
consider an adversary who's trying to

6
00:00:19,310 --> 00:00:31,259
crash a driverless car<font color="#CCCCCC"> the driverless</font>

7
00:00:23,820 --> 00:00:33,660
car today<font color="#E5E5E5"> uses a camera to identify and</font>

8
00:00:31,260 --> 00:00:37,790
<font color="#E5E5E5">locate signs on the side</font><font color="#CCCCCC"> of</font><font color="#E5E5E5"> the road and</font>

9
00:00:33,660 --> 00:00:41,160
then it's going<font color="#CCCCCC"> to use a classifier to</font>

10
00:00:37,790 --> 00:00:43,920
process this raw image and output the

11
00:00:41,160 --> 00:00:46,038
type of<font color="#E5E5E5"> the sign and in this work we're</font>

12
00:00:43,920 --> 00:00:48,450
considering adversary's who are able to

13
00:00:46,039 --> 00:00:50,910
<font color="#E5E5E5">manipulate the input of the neural</font>

14
00:00:48,450 --> 00:00:53,760
<font color="#CCCCCC">network classifier</font><font color="#E5E5E5"> and who are</font>

15
00:00:50,910 --> 00:00:54,660
<font color="#E5E5E5">interested in making it forcing it to</font>

16
00:00:53,760 --> 00:00:58,108
<font color="#CCCCCC">make</font><font color="#E5E5E5"> mistakes</font>

17
00:00:54,660 --> 00:01:00,718
<font color="#E5E5E5">for instance here</font><font color="#CCCCCC"> you have an</font><font color="#E5E5E5"> image of a</font>

18
00:00:58,109 --> 00:01:03,719
stop sign which<font color="#CCCCCC"> is correctly processed</font>

19
00:01:00,719 --> 00:01:05,700
<font color="#E5E5E5">by the model and now if I consider an</font>

20
00:01:03,719 --> 00:01:11,280
adversary capable of<font color="#E5E5E5"> introducing this</font>

21
00:01:05,700 --> 00:01:14,130
perturbation<font color="#E5E5E5"> to</font><font color="#CCCCCC"> the image the adversary</font>

22
00:01:11,280 --> 00:01:16,860
is able to force<font color="#E5E5E5"> the model to produce</font>

23
00:01:14,130 --> 00:01:20,270
the wrong class and previous<font color="#CCCCCC"> work has</font>

24
00:01:16,860 --> 00:01:23,670
shown that this<font color="#E5E5E5"> is possible with</font>

25
00:01:20,270 --> 00:01:28,100
indistinguishable perturbations<font color="#CCCCCC"> and very</font>

26
00:01:23,670 --> 00:01:31,590
reliably<font color="#E5E5E5"> so this is not a problem</font>

27
00:01:28,100 --> 00:01:34,399
<font color="#E5E5E5">specific to driverless cars companies in</font>

28
00:01:31,590 --> 00:01:37,710
the industry use neural<font color="#E5E5E5"> networks</font><font color="#CCCCCC"> to</font>

29
00:01:34,400 --> 00:01:41,100
<font color="#E5E5E5">detect financial fraud malware and</font>

30
00:01:37,710 --> 00:01:44,820
advanced<font color="#E5E5E5"> persistent threats</font><font color="#CCCCCC"> they also</font>

31
00:01:41,100 --> 00:01:50,119
process medical data and genetic<font color="#E5E5E5"> data</font>

32
00:01:44,820 --> 00:01:53,070
<font color="#E5E5E5">with neural networks also some companies</font>

33
00:01:50,119 --> 00:01:54,810
<font color="#E5E5E5">provide deep learning</font><font color="#CCCCCC"> as a service for</font>

34
00:01:53,070 --> 00:01:59,219
other developers<font color="#E5E5E5"> to</font><font color="#CCCCCC"> include in their</font>

35
00:01:54,810 --> 00:02:01,110
products so before I get<font color="#CCCCCC"> started</font><font color="#E5E5E5"> let</font><font color="#CCCCCC"> me</font>

36
00:01:59,219 --> 00:02:02,880
introduce briefly<font color="#E5E5E5"> some basics about</font>

37
00:02:01,110 --> 00:02:05,219
neural networks<font color="#CCCCCC"> so I can lay out the</font>

38
00:02:02,880 --> 00:02:08,519
rest of the presentation<font color="#CCCCCC"> so this is an</font>

39
00:02:05,219 --> 00:02:11,760
<font color="#CCCCCC">example of a neural network</font><font color="#E5E5E5"> which is</font>

40
00:02:08,520 --> 00:02:12,660
<font color="#E5E5E5">solving a classification test that is</font>

41
00:02:11,760 --> 00:02:15,890
that you are trying

42
00:02:12,660 --> 00:02:19,260
<font color="#E5E5E5">to map an input domain into predefined</font>

43
00:02:15,890 --> 00:02:21,390
<font color="#E5E5E5">finite set of classes for instance here</font>

44
00:02:19,260 --> 00:02:25,649
the neural network is trained<font color="#CCCCCC"> to</font>

45
00:02:21,390 --> 00:02:27,089
recognize digits<font color="#E5E5E5"> in images so the first</font>

46
00:02:25,650 --> 00:02:30,450
layer of the<font color="#E5E5E5"> neural</font><font color="#CCCCCC"> network is simply</font>

47
00:02:27,090 --> 00:02:33,690
<font color="#CCCCCC">reading the</font><font color="#E5E5E5"> image and encoding it as a</font>

48
00:02:30,450 --> 00:02:36,329
<font color="#CCCCCC">vector of real values then the second</font>

49
00:02:33,690 --> 00:02:39,500
the first<font color="#E5E5E5"> hidden layer sorry</font><font color="#CCCCCC"> is applying</font>

50
00:02:36,330 --> 00:02:43,050
a weighted sum to this input<font color="#E5E5E5"> layer and</font>

51
00:02:39,500 --> 00:02:45,690
<font color="#E5E5E5">then</font><font color="#CCCCCC"> nonlinear functions to produce the</font>

52
00:02:43,050 --> 00:02:47,880
first representation of the input<font color="#CCCCCC"> the</font>

53
00:02:45,690 --> 00:02:50,450
second hidden layer<font color="#E5E5E5"> repeats the same</font>

54
00:02:47,880 --> 00:02:53,100
process<font color="#E5E5E5"> with</font><font color="#CCCCCC"> different parameters in</font><font color="#E5E5E5"> the</font>

55
00:02:50,450 --> 00:02:56,420
weighted sum to produce a second

56
00:02:53,100 --> 00:02:59,880
representation of the input<font color="#CCCCCC"> and so on</font>

57
00:02:56,420 --> 00:03:02,760
until you<font color="#CCCCCC"> reach</font><font color="#E5E5E5"> the last</font><font color="#CCCCCC"> hidden</font><font color="#E5E5E5"> layer</font>

58
00:02:59,880 --> 00:03:04,950
which has<font color="#CCCCCC"> as many</font><font color="#E5E5E5"> neurons as there are</font>

59
00:03:02,760 --> 00:03:09,359
classes in the prom<font color="#E5E5E5"> and each neuron</font>

60
00:03:04,950 --> 00:03:11,250
produces a score value<font color="#E5E5E5"> which indicates</font>

61
00:03:09,360 --> 00:03:14,220
the likeliness<font color="#E5E5E5"> of the sample of being in</font>

62
00:03:11,250 --> 00:03:16,530
<font color="#E5E5E5">this class and finally this is processed</font>

63
00:03:14,220 --> 00:03:20,190
<font color="#E5E5E5">by a</font><font color="#CCCCCC"> softmax</font><font color="#E5E5E5"> layer which is simply</font>

64
00:03:16,530 --> 00:03:23,550
taking<font color="#CCCCCC"> the class values</font><font color="#E5E5E5"> into</font>

65
00:03:20,190 --> 00:03:26,550
probabilities so normalizing and summing

66
00:03:23,550 --> 00:03:30,800
up to<font color="#CCCCCC"> one and so this whole model</font><font color="#E5E5E5"> is</font>

67
00:03:26,550 --> 00:03:33,840
trained by<font color="#E5E5E5"> showing it a bunch of</font>

68
00:03:30,800 --> 00:03:35,820
<font color="#E5E5E5">input-output pairs and back propagating</font>

69
00:03:33,840 --> 00:03:37,650
error gradients through the<font color="#E5E5E5"> model and it</font>

70
00:03:35,820 --> 00:03:40,519
turns out<font color="#E5E5E5"> that neural networks have been</font>

71
00:03:37,650 --> 00:03:42,870
shown to<font color="#E5E5E5"> produce state-of-the-art</font>

72
00:03:40,520 --> 00:03:45,989
<font color="#E5E5E5">accuracies in many mission learning</font>

73
00:03:42,870 --> 00:03:49,050
tasks in the past<font color="#E5E5E5"> ten years</font><font color="#CCCCCC"> another</font>

74
00:03:45,989 --> 00:03:52,860
<font color="#CCCCCC">example is this architecture used in the</font>

75
00:03:49,050 --> 00:03:56,810
<font color="#E5E5E5">industry to extract meaning from raw</font>

76
00:03:52,860 --> 00:04:00,030
audio<font color="#E5E5E5"> and it shows the success of DNN</font>

77
00:03:56,810 --> 00:04:04,590
<font color="#CCCCCC">because it is able</font><font color="#E5E5E5"> to replace a chain of</font>

78
00:04:00,030 --> 00:04:07,709
<font color="#E5E5E5">tools that</font><font color="#CCCCCC"> require hand feature feature</font>

79
00:04:04,590 --> 00:04:11,209
<font color="#CCCCCC">engineering</font><font color="#E5E5E5"> and here the neural network</font>

80
00:04:07,709 --> 00:04:13,890
is<font color="#CCCCCC"> able</font><font color="#E5E5E5"> to extract</font><font color="#CCCCCC"> our our</font><font color="#E5E5E5"> key of</font>

81
00:04:11,209 --> 00:04:19,829
increasingly<font color="#E5E5E5"> abstract representations</font>

82
00:04:13,890 --> 00:04:23,099
automatically so however even though

83
00:04:19,829 --> 00:04:26,020
<font color="#E5E5E5">neural networks perform very well on the</font>

84
00:04:23,100 --> 00:04:29,400
<font color="#E5E5E5">JIT innate inputs previous work has done</font>

85
00:04:26,020 --> 00:04:34,240
traded that<font color="#E5E5E5"> it is extremely easy for</font>

86
00:04:29,400 --> 00:04:36,729
adversary's<font color="#CCCCCC"> with knowledge of the neural</font>

87
00:04:34,240 --> 00:04:39,659
<font color="#E5E5E5">network to find indistinguishable</font>

88
00:04:36,729 --> 00:04:44,800
perturbations<font color="#CCCCCC"> that will force the model</font>

89
00:04:39,659 --> 00:04:48,879
<font color="#E5E5E5">to it put a wrong class so for instance</font>

90
00:04:44,800 --> 00:04:51,430
here on the left<font color="#E5E5E5"> you have our digit data</font>

91
00:04:48,879 --> 00:04:53,789
set on the diagonal<font color="#E5E5E5"> all the samples are</font>

92
00:04:51,430 --> 00:04:58,150
<font color="#E5E5E5">correctly</font><font color="#CCCCCC"> classified by the model</font><font color="#E5E5E5"> and</font>

93
00:04:53,789 --> 00:05:00,039
off the<font color="#E5E5E5"> diagonal is you will find at</font>

94
00:04:58,150 --> 00:05:02,859
virtual samples that are<font color="#E5E5E5"> all miss</font>

95
00:05:00,039 --> 00:05:06,849
<font color="#E5E5E5">classified by the model so you to read</font>

96
00:05:02,860 --> 00:05:08,409
the matrix<font color="#CCCCCC"> the rows are</font><font color="#E5E5E5"> input classes so</font>

97
00:05:06,849 --> 00:05:10,659
<font color="#CCCCCC">they're the legitimate class of the</font>

98
00:05:08,409 --> 00:05:14,469
sample<font color="#E5E5E5"> that</font><font color="#CCCCCC"> a human being would assign</font>

99
00:05:10,659 --> 00:05:17,849
and the columns are<font color="#E5E5E5"> the output of the</font>

100
00:05:14,470 --> 00:05:21,130
<font color="#CCCCCC">model and as you can</font><font color="#E5E5E5"> see</font><font color="#CCCCCC"> we can craft</font>

101
00:05:17,849 --> 00:05:24,849
<font color="#E5E5E5">perturbations that take any sample from</font>

102
00:05:21,130 --> 00:05:27,190
any class<font color="#E5E5E5"> to any target class chosen by</font>

103
00:05:24,849 --> 00:05:29,889
the<font color="#CCCCCC"> adversary for instance the</font><font color="#E5E5E5"> first row</font>

104
00:05:27,190 --> 00:05:32,590
is a<font color="#E5E5E5"> zero classified by the model as a</font>

105
00:05:29,889 --> 00:05:35,440
zero one<font color="#E5E5E5"> two three</font><font color="#CCCCCC"> through nine this</font>

106
00:05:32,590 --> 00:05:37,960
works with many data<font color="#CCCCCC"> sets</font><font color="#E5E5E5"> on the right</font>

107
00:05:35,440 --> 00:05:41,020
you<font color="#E5E5E5"> will see</font><font color="#CCCCCC"> the Sifford data set where</font>

108
00:05:37,960 --> 00:05:45,638
you<font color="#E5E5E5"> can classify dogs as birds planes as</font>

109
00:05:41,020 --> 00:05:48,279
trucks<font color="#CCCCCC"> and below it is a traffic sign</font>

110
00:05:45,639 --> 00:05:50,949
data set where you<font color="#CCCCCC"> can for instance</font>

111
00:05:48,279 --> 00:05:56,279
classify or<font color="#E5E5E5"> no truck sign into a yield</font>

112
00:05:50,949 --> 00:05:59,620
sign<font color="#E5E5E5"> and how this is done is by</font>

113
00:05:56,279 --> 00:06:03,250
computing the Jacobian of<font color="#E5E5E5"> the model</font><font color="#CCCCCC"> with</font>

114
00:05:59,620 --> 00:06:05,259
<font color="#CCCCCC">respect</font><font color="#E5E5E5"> to the current</font><font color="#CCCCCC"> input which gives</font>

115
00:06:03,250 --> 00:06:07,779
you an estimation of the<font color="#E5E5E5"> sensitivity</font><font color="#CCCCCC"> of</font>

116
00:06:05,259 --> 00:06:10,330
the model and then you<font color="#CCCCCC"> combine these</font>

117
00:06:07,779 --> 00:06:12,940
values<font color="#CCCCCC"> into add virtual sailin c maps</font>

118
00:06:10,330 --> 00:06:16,029
which will indicate for each input

119
00:06:12,940 --> 00:06:18,969
<font color="#E5E5E5">feature how likely it is to</font><font color="#CCCCCC"> contribute</font>

120
00:06:16,029 --> 00:06:23,099
to your<font color="#CCCCCC"> Mis classification goal and you</font>

121
00:06:18,969 --> 00:06:27,659
do this iteratively<font color="#E5E5E5"> perturbing the</font>

122
00:06:23,099 --> 00:06:30,520
highest-selling<font color="#E5E5E5"> c features until you are</font>

123
00:06:27,659 --> 00:06:34,029
<font color="#E5E5E5">able to force the model to</font><font color="#CCCCCC"> misclassify</font>

124
00:06:30,520 --> 00:06:37,359
the sample in a class<font color="#E5E5E5"> that you chose</font><font color="#CCCCCC"> so</font>

125
00:06:34,029 --> 00:06:38,649
now<font color="#E5E5E5"> I'm going</font><font color="#CCCCCC"> to go to the</font><font color="#E5E5E5"> topic of</font>

126
00:06:37,360 --> 00:06:39,840
<font color="#E5E5E5">interest for this talk which is</font>

127
00:06:38,649 --> 00:06:44,510
defending again

128
00:06:39,840 --> 00:06:48,299
these attacks<font color="#CCCCCC"> so what are</font><font color="#E5E5E5"> we trying to</font>

129
00:06:44,510 --> 00:06:53,190
<font color="#E5E5E5">achieve</font><font color="#CCCCCC"> so if you consider a simplified</font>

130
00:06:48,300 --> 00:06:56,310
picture<font color="#E5E5E5"> of the models</font><font color="#CCCCCC"> output surface</font><font color="#E5E5E5"> X</font>

131
00:06:53,190 --> 00:07:00,570
is a legitimate<font color="#E5E5E5"> sample and the adversary</font>

132
00:06:56,310 --> 00:07:03,449
is trying to find the<font color="#E5E5E5"> add virtual sample</font>

133
00:07:00,570 --> 00:07:05,669
<font color="#E5E5E5">X star that</font><font color="#CCCCCC"> is closest to</font><font color="#E5E5E5"> the legitimate</font>

134
00:07:03,449 --> 00:07:08,010
sample so<font color="#E5E5E5"> basically the one that's on</font>

135
00:07:05,669 --> 00:07:10,710
the<font color="#E5E5E5"> other side of the decision boundary</font>

136
00:07:08,010 --> 00:07:13,349
<font color="#E5E5E5">and what we are trying to do as</font>

137
00:07:10,710 --> 00:07:17,030
defenders is push this decision boundary

138
00:07:13,350 --> 00:07:19,860
<font color="#E5E5E5">further away from the legitimate sample</font>

139
00:07:17,030 --> 00:07:21,929
we want to do<font color="#E5E5E5"> this with a low impact on</font>

140
00:07:19,860 --> 00:07:24,660
<font color="#E5E5E5">the architecture so</font><font color="#CCCCCC"> that the solution</font>

141
00:07:21,930 --> 00:07:27,860
<font color="#CCCCCC">can be easily deployed</font><font color="#E5E5E5"> in existing</font>

142
00:07:24,660 --> 00:07:30,600
systems<font color="#E5E5E5"> we need to maintain</font><font color="#CCCCCC"> accuracy</font>

143
00:07:27,860 --> 00:07:34,110
<font color="#E5E5E5">because otherwise the model becomes</font>

144
00:07:30,600 --> 00:07:37,770
useless<font color="#CCCCCC"> related to this we have</font><font color="#E5E5E5"> to</font>

145
00:07:34,110 --> 00:07:39,810
achieve robustness<font color="#E5E5E5"> in something that is</font>

146
00:07:37,770 --> 00:07:41,820
close to<font color="#E5E5E5"> the legitimate expected</font>

147
00:07:39,810 --> 00:07:44,280
distribution<font color="#CCCCCC"> or else you</font><font color="#E5E5E5"> could imagine</font>

148
00:07:41,820 --> 00:07:47,070
<font color="#E5E5E5">this constant classifier where the</font>

149
00:07:44,280 --> 00:07:50,520
decision boundaries to infinity which

150
00:07:47,070 --> 00:07:52,130
would be perfectly robust<font color="#E5E5E5"> and finally we</font>

151
00:07:50,520 --> 00:07:55,650
have<font color="#E5E5E5"> to maintain the speed of networks</font>

152
00:07:52,130 --> 00:07:57,450
because neural networks are widely used

153
00:07:55,650 --> 00:07:59,840
<font color="#E5E5E5">in</font><font color="#CCCCCC"> the</font><font color="#E5E5E5"> industry</font><font color="#CCCCCC"> because they're able</font><font color="#E5E5E5"> to</font>

154
00:07:57,450 --> 00:08:05,159
<font color="#E5E5E5">make predictions a test and very quickly</font>

155
00:07:59,840 --> 00:08:07,049
<font color="#E5E5E5">so we</font><font color="#CCCCCC"> don't want</font><font color="#E5E5E5"> to degrade that so if</font>

156
00:08:05,160 --> 00:08:11,849
you remember<font color="#E5E5E5"> the model that I</font><font color="#CCCCCC"> showed you</font>

157
00:08:07,050 --> 00:08:13,919
<font color="#E5E5E5">earlier the last layer is the softmax</font>

158
00:08:11,849 --> 00:08:16,830
layer and this<font color="#E5E5E5"> is</font><font color="#CCCCCC"> what we leverage to</font>

159
00:08:13,919 --> 00:08:19,560
<font color="#E5E5E5">create our defense the softmax layer</font>

160
00:08:16,830 --> 00:08:21,900
works by applying an exponential

161
00:08:19,560 --> 00:08:24,150
function<font color="#CCCCCC"> to the class scores and</font>

162
00:08:21,900 --> 00:08:27,989
dividing by the sum of the<font color="#E5E5E5"> exponential</font>

163
00:08:24,150 --> 00:08:30,530
values and there is a<font color="#E5E5E5"> parameter in that</font>

164
00:08:27,990 --> 00:08:34,680
<font color="#E5E5E5">function which is the temperature</font><font color="#CCCCCC"> T</font>

165
00:08:30,530 --> 00:08:36,919
which divides<font color="#E5E5E5"> the class scores before</font>

166
00:08:34,679 --> 00:08:39,689
the exponential function<font color="#CCCCCC"> is applied</font><font color="#E5E5E5"> and</font>

167
00:08:36,919 --> 00:08:42,000
what this parameter does is that<font color="#E5E5E5"> when</font>

168
00:08:39,690 --> 00:08:44,310
you set a low temperature<font color="#CCCCCC"> the</font>

169
00:08:42,000 --> 00:08:47,100
probabilities will be extremely<font color="#E5E5E5"> discreet</font>

170
00:08:44,310 --> 00:08:50,719
so you will make<font color="#E5E5E5"> confident predictions</font>

171
00:08:47,100 --> 00:08:53,880
<font color="#E5E5E5">however if you increase the temperature</font>

172
00:08:50,720 --> 00:08:56,640
<font color="#E5E5E5">the probability vector will smooth</font>

173
00:08:53,880 --> 00:08:59,010
and converge towards one over the number

174
00:08:56,640 --> 00:09:00,810
of<font color="#E5E5E5"> classes so typically</font><font color="#CCCCCC"> people will set</font>

175
00:08:59,010 --> 00:09:03,450
the temperature<font color="#E5E5E5"> to</font><font color="#CCCCCC"> one because they want</font>

176
00:09:00,810 --> 00:09:06,030
to<font color="#CCCCCC"> make</font><font color="#E5E5E5"> confident predictions what we</font>

177
00:09:03,450 --> 00:09:07,620
saw is we can instead increase the

178
00:09:06,030 --> 00:09:10,860
temperature<font color="#E5E5E5"> to increase the robustness</font>

179
00:09:07,620 --> 00:09:14,220
of<font color="#E5E5E5"> the model</font><font color="#CCCCCC"> and I will show</font><font color="#E5E5E5"> you how if</font>

180
00:09:10,860 --> 00:09:16,620
you have<font color="#CCCCCC"> your training</font><font color="#E5E5E5"> data which is a</font>

181
00:09:14,220 --> 00:09:19,050
set of input points<font color="#CCCCCC"> and labels that you</font>

182
00:09:16,620 --> 00:09:22,610
show to<font color="#CCCCCC"> the network</font><font color="#E5E5E5"> you can train a</font>

183
00:09:19,050 --> 00:09:25,109
first<font color="#CCCCCC"> Network as you would typically do</font>

184
00:09:22,610 --> 00:09:29,400
<font color="#E5E5E5">to the exception</font><font color="#CCCCCC"> that you raise the</font>

185
00:09:25,110 --> 00:09:33,900
temperature<font color="#CCCCCC"> to a large value typically</font>

186
00:09:29,400 --> 00:09:36,329
around<font color="#E5E5E5"> 40 to 50 and you will</font><font color="#CCCCCC"> produce</font>

187
00:09:33,900 --> 00:09:39,630
this<font color="#E5E5E5"> way probability vectors that</font><font color="#CCCCCC"> are</font>

188
00:09:36,330 --> 00:09:42,960
very smooth<font color="#CCCCCC"> you are going to then use</font>

189
00:09:39,630 --> 00:09:45,480
these probability vectors<font color="#E5E5E5"> to label your</font>

190
00:09:42,960 --> 00:09:48,270
<font color="#E5E5E5">data that is you replace the labels that</font>

191
00:09:45,480 --> 00:09:51,180
simply indicate the correct class with

192
00:09:48,270 --> 00:09:54,210
the probability vectors you<font color="#E5E5E5"> train the</font>

193
00:09:51,180 --> 00:09:57,569
same architecture from<font color="#E5E5E5"> scratch using</font>

194
00:09:54,210 --> 00:10:01,080
<font color="#CCCCCC">this new labelled data set and</font><font color="#E5E5E5"> you</font>

195
00:09:57,570 --> 00:10:05,160
obtain<font color="#E5E5E5"> a new model which</font><font color="#CCCCCC"> we call the</font>

196
00:10:01,080 --> 00:10:07,380
<font color="#E5E5E5">Distilled model and to make</font><font color="#CCCCCC"> predictions</font>

197
00:10:05,160 --> 00:10:09,900
<font color="#CCCCCC">using this new model all you have</font><font color="#E5E5E5"> to do</font>

198
00:10:07,380 --> 00:10:13,439
is simply<font color="#CCCCCC"> set the temperature back to</font>

199
00:10:09,900 --> 00:10:17,189
<font color="#E5E5E5">one a test time this way you still have</font>

200
00:10:13,440 --> 00:10:20,670
discrete predictions<font color="#E5E5E5"> which are confident</font>

201
00:10:17,190 --> 00:10:23,400
<font color="#CCCCCC">and it turns</font><font color="#E5E5E5"> out that this is</font><font color="#CCCCCC"> very</font>

202
00:10:20,670 --> 00:10:27,209
efficient<font color="#E5E5E5"> in making add virtual sample</font>

203
00:10:23,400 --> 00:10:29,819
crafting much harder so<font color="#CCCCCC"> why does it work</font>

204
00:10:27,210 --> 00:10:32,160
<font color="#CCCCCC">what's the intuition behind</font><font color="#E5E5E5"> this there</font>

205
00:10:29,820 --> 00:10:36,200
is actually<font color="#CCCCCC"> two of them first</font><font color="#E5E5E5"> is that</font>

206
00:10:32,160 --> 00:10:40,370
when<font color="#E5E5E5"> models are trained they</font><font color="#CCCCCC"> typically</font>

207
00:10:36,200 --> 00:10:43,260
<font color="#E5E5E5">are trained to minimize a loss function</font>

208
00:10:40,370 --> 00:10:46,250
<font color="#CCCCCC">which is</font><font color="#E5E5E5"> something along the lines of</font>

209
00:10:43,260 --> 00:10:49,890
the cross entropy<font color="#CCCCCC"> between the expected</font>

210
00:10:46,250 --> 00:10:53,010
<font color="#E5E5E5">labels and the predictions and if you</font>

211
00:10:49,890 --> 00:10:56,189
replace a label of the correct class by

212
00:10:53,010 --> 00:10:59,760
probabilities<font color="#E5E5E5"> instead</font><font color="#CCCCCC"> of constraining</font>

213
00:10:56,190 --> 00:11:04,710
<font color="#E5E5E5">only the correct</font><font color="#CCCCCC"> class to be the output</font>

214
00:10:59,760 --> 00:11:06,810
<font color="#CCCCCC">you allow the network</font><font color="#E5E5E5"> to produce some</font>

215
00:11:04,710 --> 00:11:09,300
class scores for

216
00:11:06,810 --> 00:11:11,369
classes that<font color="#E5E5E5"> are not</font><font color="#CCCCCC"> the correct</font><font color="#E5E5E5"> class</font>

217
00:11:09,300 --> 00:11:13,260
and you<font color="#CCCCCC"> can</font><font color="#E5E5E5"> see how this is useful if</font>

218
00:11:11,370 --> 00:11:16,050
you<font color="#E5E5E5"> look at the two images at the bottom</font>

219
00:11:13,260 --> 00:11:18,210
<font color="#CCCCCC">of the slide</font><font color="#E5E5E5"> this</font><font color="#CCCCCC"> three</font><font color="#E5E5E5"> here is very</font>

220
00:11:16,050 --> 00:11:21,000
similar<font color="#E5E5E5"> to</font><font color="#CCCCCC"> an eight</font><font color="#E5E5E5"> there's only a few</font>

221
00:11:18,210 --> 00:11:23,970
pixels that<font color="#E5E5E5"> are missing to make it into</font>

222
00:11:21,000 --> 00:11:26,310
an<font color="#E5E5E5"> eight and what this solution will do</font>

223
00:11:23,970 --> 00:11:29,190
is that<font color="#E5E5E5"> it</font><font color="#CCCCCC"> will allow the model to</font>

224
00:11:26,310 --> 00:11:32,339
output a class<font color="#E5E5E5"> score for</font><font color="#CCCCCC"> eight here as</font>

225
00:11:29,190 --> 00:11:35,550
long<font color="#E5E5E5"> as</font><font color="#CCCCCC"> three is larger</font><font color="#E5E5E5"> as a larger</font>

226
00:11:32,339 --> 00:11:38,540
value<font color="#CCCCCC"> and</font><font color="#E5E5E5"> also it turns out that the</font>

227
00:11:35,550 --> 00:11:41,279
<font color="#CCCCCC">Jacobian amplitudes</font><font color="#E5E5E5"> are inversely</font>

228
00:11:38,540 --> 00:11:42,959
proportional to<font color="#CCCCCC"> the temperature so</font><font color="#E5E5E5"> as</font>

229
00:11:41,279 --> 00:11:47,750
you increase<font color="#E5E5E5"> temperature reduce the</font>

230
00:11:42,960 --> 00:11:51,270
<font color="#CCCCCC">Jacobian</font><font color="#E5E5E5"> amplitudes so we validated this</font>

231
00:11:47,750 --> 00:11:54,960
<font color="#E5E5E5">defense on two data sets the digits data</font>

232
00:11:51,270 --> 00:11:58,529
set which previous work has shown you

233
00:11:54,960 --> 00:12:02,430
can force<font color="#CCCCCC"> two</font><font color="#E5E5E5"> misclassify with a</font><font color="#CCCCCC"> ninety</font>

234
00:11:58,529 --> 00:12:04,770
<font color="#CCCCCC">seven percent success rate</font><font color="#E5E5E5"> by only</font>

235
00:12:02,430 --> 00:12:07,680
modifying<font color="#E5E5E5"> four percent of the inputs and</font>

236
00:12:04,770 --> 00:12:11,610
the second<font color="#E5E5E5"> data set is a data set of</font>

237
00:12:07,680 --> 00:12:15,150
<font color="#E5E5E5">color images with objects and animals</font><font color="#CCCCCC"> on</font>

238
00:12:11,610 --> 00:12:16,680
both of these data sets we<font color="#CCCCCC"> trained</font>

239
00:12:15,150 --> 00:12:19,459
<font color="#E5E5E5">state-of-the-art</font><font color="#CCCCCC"> or close to</font>

240
00:12:16,680 --> 00:12:22,500
<font color="#E5E5E5">state-of-the-art architectures using</font>

241
00:12:19,460 --> 00:12:27,180
convolutional layers rectified linear

242
00:12:22,500 --> 00:12:30,120
units and the<font color="#CCCCCC"> softmax so here are the</font>

243
00:12:27,180 --> 00:12:32,550
<font color="#E5E5E5">results you</font><font color="#CCCCCC"> can see the blue curve</font>

244
00:12:30,120 --> 00:12:35,100
corresponds to the digits data set and

245
00:12:32,550 --> 00:12:38,790
the<font color="#CCCCCC"> gray curve to the objects data set</font>

246
00:12:35,100 --> 00:12:41,640
and the<font color="#CCCCCC"> x-axis holds the temperature</font>

247
00:12:38,790 --> 00:12:43,770
parameter<font color="#E5E5E5"> and the</font><font color="#CCCCCC"> y axis the</font><font color="#E5E5E5"> success</font>

248
00:12:41,640 --> 00:12:45,990
rate of<font color="#E5E5E5"> adversaries and as you can see</font>

249
00:12:43,770 --> 00:12:48,930
clearly<font color="#CCCCCC"> as the temperature increases</font>

250
00:12:45,990 --> 00:12:51,000
during<font color="#E5E5E5"> training the</font><font color="#CCCCCC"> adversary's have a</font>

251
00:12:48,930 --> 00:12:53,910
harder time crafting at virtual samples

252
00:12:51,000 --> 00:12:57,480
and eventually for the digits data set

253
00:12:53,910 --> 00:13:00,780
we reach levels<font color="#E5E5E5"> less than 0.5 percent</font>

254
00:12:57,480 --> 00:13:05,370
success rate<font color="#E5E5E5"> and for the image data set</font>

255
00:13:00,780 --> 00:13:08,430
we go<font color="#E5E5E5"> below</font><font color="#CCCCCC"> six percent so you may</font>

256
00:13:05,370 --> 00:13:11,490
<font color="#E5E5E5">wonder</font><font color="#CCCCCC"> ok so he's selling</font><font color="#E5E5E5"> us the defense</font>

257
00:13:08,430 --> 00:13:14,040
doesn't<font color="#E5E5E5"> impact the accuracy of the model</font>

258
00:13:11,490 --> 00:13:15,570
<font color="#CCCCCC">does it in fact</font><font color="#E5E5E5"> the performance and it</font>

259
00:13:14,040 --> 00:13:19,199
turns<font color="#E5E5E5"> out that the impact on the</font>

260
00:13:15,570 --> 00:13:19,730
accuracy<font color="#E5E5E5"> is limited on the left you can</font>

261
00:13:19,200 --> 00:13:22,760
<font color="#E5E5E5">see</font>

262
00:13:19,730 --> 00:13:25,130
increasing temperatures the accuracy

263
00:13:22,760 --> 00:13:29,569
impact is always constrained between<font color="#E5E5E5"> a</font>

264
00:13:25,130 --> 00:13:33,800
little less<font color="#E5E5E5"> than 1.4 percent and a</font>

265
00:13:29,570 --> 00:13:36,380
little over<font color="#CCCCCC"> 1.2 percent</font><font color="#E5E5E5"> increase so</font><font color="#CCCCCC"> that</font>

266
00:13:33,800 --> 00:13:39,589
is sometimes distillation<font color="#E5E5E5"> even increases</font>

267
00:13:36,380 --> 00:13:43,550
the accuracy<font color="#CCCCCC"> of</font><font color="#E5E5E5"> the model and this</font>

268
00:13:39,590 --> 00:13:46,070
allows you<font color="#CCCCCC"> to find sweet spots</font><font color="#E5E5E5"> where for</font>

269
00:13:43,550 --> 00:13:48,079
instance<font color="#E5E5E5"> for the digits data set for a</font>

270
00:13:46,070 --> 00:13:50,840
<font color="#E5E5E5">temperature of 40 we found that we could</font>

271
00:13:48,080 --> 00:13:54,350
bring the success rate down to<font color="#CCCCCC"> 0.45</font>

272
00:13:50,840 --> 00:13:57,980
percent while degrading the accuracy by

273
00:13:54,350 --> 00:14:02,530
<font color="#CCCCCC">only a little less than 0.5% as well and</font>

274
00:13:57,980 --> 00:14:08,330
the same thing holds<font color="#CCCCCC"> for the image with</font>

275
00:14:02,530 --> 00:14:11,240
colors<font color="#E5E5E5"> of objects you can set the attack</font>

276
00:14:08,330 --> 00:14:13,460
success rate<font color="#CCCCCC"> 6% using a little</font><font color="#E5E5E5"> improve</font>

277
00:14:11,240 --> 00:14:15,470
in the<font color="#E5E5E5"> accuracy so this clearly</font><font color="#CCCCCC"> shows</font>

278
00:14:13,460 --> 00:14:19,940
that<font color="#E5E5E5"> there's a more general question</font>

279
00:14:15,470 --> 00:14:23,690
<font color="#CCCCCC">here</font><font color="#E5E5E5"> whether you'd like to</font><font color="#CCCCCC"> identify the</font>

280
00:14:19,940 --> 00:14:26,050
relationship<font color="#CCCCCC"> between</font><font color="#E5E5E5"> accuracy</font><font color="#CCCCCC"> and</font>

281
00:14:23,690 --> 00:14:34,250
robustness and<font color="#CCCCCC"> this is an open problem</font>

282
00:14:26,050 --> 00:14:39,319
that we are still<font color="#CCCCCC"> looking</font><font color="#E5E5E5"> into so also</font>

283
00:14:34,250 --> 00:14:43,370
the impact<font color="#E5E5E5"> of the of the distillation on</font>

284
00:14:39,320 --> 00:14:45,500
<font color="#CCCCCC">Jacobian amplitudes as if you remember</font>

285
00:14:43,370 --> 00:14:47,300
<font color="#CCCCCC">earlier I said that the Jacobian</font>

286
00:14:45,500 --> 00:14:50,540
amplitudes are inversely proportional

287
00:14:47,300 --> 00:14:54,709
temperature<font color="#CCCCCC"> and you can see that we</font>

288
00:14:50,540 --> 00:14:58,310
measured<font color="#E5E5E5"> this empirically each histogram</font>

289
00:14:54,710 --> 00:15:00,050
<font color="#E5E5E5">is for a given temperature</font><font color="#CCCCCC"> the one</font><font color="#E5E5E5"> on</font>

290
00:14:58,310 --> 00:15:01,510
<font color="#E5E5E5">the left is no distillation and the one</font>

291
00:15:00,050 --> 00:15:04,790
<font color="#E5E5E5">on the right is the highest temperature</font>

292
00:15:01,510 --> 00:15:09,319
<font color="#E5E5E5">you can see that</font><font color="#CCCCCC"> initially the Jacobian</font>

293
00:15:04,790 --> 00:15:14,209
amplitudes are between 10<font color="#CCCCCC"> to the minus</font>

294
00:15:09,320 --> 00:15:16,670
of<font color="#E5E5E5"> 3 and 0</font><font color="#CCCCCC"> and</font><font color="#E5E5E5"> as you gradually increase</font>

295
00:15:14,210 --> 00:15:20,300
<font color="#CCCCCC">the temperature</font><font color="#E5E5E5"> you decrease the</font>

296
00:15:16,670 --> 00:15:23,209
<font color="#CCCCCC">Jacobian amplitudes up to while actually</font>

297
00:15:20,300 --> 00:15:26,300
<font color="#E5E5E5">down to 10</font><font color="#CCCCCC"> to the minus 40 so there is a</font>

298
00:15:23,210 --> 00:15:28,720
reduction<font color="#E5E5E5"> by a factor</font><font color="#CCCCCC"> of 10 to the</font><font color="#E5E5E5"> power</font>

299
00:15:26,300 --> 00:15:32,620
30 of the Jacobian amplitude which

300
00:15:28,720 --> 00:15:36,440
effectively smooth the<font color="#E5E5E5"> models decision</font>

301
00:15:32,620 --> 00:15:40,010
<font color="#E5E5E5">and we estimated the robustness because</font>

302
00:15:36,440 --> 00:15:42,140
<font color="#E5E5E5">it is not possible to compute it exactly</font>

303
00:15:40,010 --> 00:15:46,130
<font color="#CCCCCC">so what we did empirically is we</font>

304
00:15:42,140 --> 00:15:51,920
considered the test set for each data

305
00:15:46,130 --> 00:15:57,080
set and<font color="#E5E5E5"> we</font><font color="#CCCCCC"> computed all possible adverse</font>

306
00:15:51,920 --> 00:15:59,449
all targets for each input<font color="#E5E5E5"> and we we we</font>

307
00:15:57,080 --> 00:16:01,880
identify the smallest perturbation which

308
00:15:59,450 --> 00:16:03,290
achieves<font color="#E5E5E5"> miss classification in any</font>

309
00:16:01,880 --> 00:16:05,540
class that's different<font color="#E5E5E5"> from the</font>

310
00:16:03,290 --> 00:16:07,640
<font color="#E5E5E5">legitimate class and it turns out that</font>

311
00:16:05,540 --> 00:16:09,860
this gives us a way<font color="#CCCCCC"> to compute</font><font color="#E5E5E5"> the</font>

312
00:16:07,640 --> 00:16:12,620
<font color="#CCCCCC">average minimum</font><font color="#E5E5E5"> perturbation to achieve</font>

313
00:16:09,860 --> 00:16:15,260
<font color="#CCCCCC">miss</font><font color="#E5E5E5"> classification which is</font><font color="#CCCCCC"> the</font>

314
00:16:12,620 --> 00:16:17,690
<font color="#CCCCCC">definition of robustness and you can see</font>

315
00:16:15,260 --> 00:16:20,930
that for<font color="#E5E5E5"> the digits in blue and the</font>

316
00:16:17,690 --> 00:16:23,390
objects in yellow<font color="#E5E5E5"> we indeed</font><font color="#CCCCCC"> have a</font>

317
00:16:20,930 --> 00:16:26,900
reduction<font color="#CCCCCC"> sorry an increase in the</font>

318
00:16:23,390 --> 00:16:31,189
<font color="#E5E5E5">average minimum perturbation so to</font>

319
00:16:26,900 --> 00:16:34,340
conclude<font color="#E5E5E5"> distillation significantly</font>

320
00:16:31,190 --> 00:16:37,870
reduces<font color="#CCCCCC"> attack success and</font><font color="#E5E5E5"> yields model</font>

321
00:16:34,340 --> 00:16:41,660
smoothness because of the Jacobian being

322
00:16:37,870 --> 00:16:43,400
smaller<font color="#E5E5E5"> we have</font><font color="#CCCCCC"> an easy implementation</font>

323
00:16:41,660 --> 00:16:46,310
all you have to do is loop twice through

324
00:16:43,400 --> 00:16:50,420
training<font color="#E5E5E5"> and an acceptable impact on</font>

325
00:16:46,310 --> 00:16:53,000
accuracy<font color="#E5E5E5"> even sometimes improving it if</font>

326
00:16:50,420 --> 00:16:56,260
you have any<font color="#E5E5E5"> questions I'll</font><font color="#CCCCCC"> be</font><font color="#E5E5E5"> happy to</font>

327
00:16:53,000 --> 00:16:56,260
<font color="#CCCCCC">answer them</font><font color="#E5E5E5"> thank you</font>

328
00:17:04,390 --> 00:17:11,120
hi<font color="#E5E5E5"> I'm</font><font color="#CCCCCC"> pen Alaska</font><font color="#E5E5E5"> from</font><font color="#CCCCCC"> my research in</font>

329
00:17:08,420 --> 00:17:15,589
Munich<font color="#CCCCCC"> and thanks for very</font><font color="#E5E5E5"> interesting</font>

330
00:17:11,119 --> 00:17:18,770
<font color="#E5E5E5">talk on such an unusual subject does</font>

331
00:17:15,589 --> 00:17:22,099
your method somehow consider the

332
00:17:18,770 --> 00:17:26,500
constraints on the attacker<font color="#CCCCCC"> that's a is</font>

333
00:17:22,099 --> 00:17:29,030
an attacker constrained in<font color="#E5E5E5"> so obtaining</font>

334
00:17:26,500 --> 00:17:32,360
adversarial samples<font color="#E5E5E5"> in a certain number</font>

335
00:17:29,030 --> 00:17:34,820
<font color="#E5E5E5">of</font><font color="#CCCCCC"> iterations so are you asking</font>

336
00:17:32,360 --> 00:17:36,919
<font color="#CCCCCC">basically</font><font color="#E5E5E5"> about the assumptions that we</font>

337
00:17:34,820 --> 00:17:38,330
make on the universal knowledge<font color="#E5E5E5"> right so</font>

338
00:17:36,920 --> 00:17:41,000
what what<font color="#E5E5E5"> what sounds a little</font>

339
00:17:38,330 --> 00:17:43,120
counterintuitive<font color="#E5E5E5"> to</font><font color="#CCCCCC"> me is that your</font>

340
00:17:41,000 --> 00:17:46,850
method<font color="#E5E5E5"> essentially is trying to</font>

341
00:17:43,120 --> 00:17:52,040
<font color="#E5E5E5">introduce</font><font color="#CCCCCC"> to increase the smoothness of</font>

342
00:17:46,850 --> 00:17:54,370
<font color="#CCCCCC">the</font><font color="#E5E5E5"> Jacobian and intuitively with very</font>

343
00:17:52,040 --> 00:17:58,340
unstable<font color="#E5E5E5"> de</font><font color="#CCCCCC"> kalb an attacker can very</font>

344
00:17:54,370 --> 00:18:01,510
quickly<font color="#E5E5E5"> attain his goal yes if the</font>

345
00:17:58,340 --> 00:18:04,100
Jacobian becomes smoother than the

346
00:18:01,510 --> 00:18:07,970
relative effect of the attack<font color="#CCCCCC"> would</font>

347
00:18:04,100 --> 00:18:10,490
become<font color="#CCCCCC"> smaller that an attacker might be</font>

348
00:18:07,970 --> 00:18:12,410
willing<font color="#E5E5E5"> to wait for a long time might</font>

349
00:18:10,490 --> 00:18:14,960
still achieve his goals<font color="#E5E5E5"> have you</font>

350
00:18:12,410 --> 00:18:18,200
considered this sort of temporal factor

351
00:18:14,960 --> 00:18:20,750
in the behavior of the<font color="#CCCCCC"> attack</font><font color="#E5E5E5"> so this</font>

352
00:18:18,200 --> 00:18:24,290
attack<font color="#E5E5E5"> here when you craft an adverse</font>

353
00:18:20,750 --> 00:18:27,320
ample you you do not impact the training

354
00:18:24,290 --> 00:18:30,460
set so the impact<font color="#E5E5E5"> of an adverse ample is</font>

355
00:18:27,320 --> 00:18:33,200
instant it's instantly misclassified

356
00:18:30,460 --> 00:18:36,590
<font color="#E5E5E5">what we showed</font><font color="#CCCCCC"> here is that it takes</font>

357
00:18:33,200 --> 00:18:38,900
more perturbation to produce<font color="#CCCCCC"> a virtual</font>

358
00:18:36,590 --> 00:18:40,580
samples with distillation we didn't say

359
00:18:38,900 --> 00:18:45,590
<font color="#E5E5E5">that we completely solved a virtual</font>

360
00:18:40,580 --> 00:18:47,780
sample<font color="#CCCCCC"> the problem</font><font color="#E5E5E5"> of them</font><font color="#CCCCCC"> all that we</font>

361
00:18:45,590 --> 00:18:50,120
have is<font color="#CCCCCC"> that the</font><font color="#E5E5E5"> adversary's need to use</font>

362
00:18:47,780 --> 00:18:55,129
much more perturbation to achieve their

363
00:18:50,120 --> 00:18:56,719
goal<font color="#E5E5E5"> okay</font><font color="#CCCCCC"> and are they constrained</font><font color="#E5E5E5"> on</font>

364
00:18:55,130 --> 00:18:59,630
the amount of perturbation<font color="#E5E5E5"> there are to</font>

365
00:18:56,720 --> 00:19:02,230
have with a well would it<font color="#CCCCCC"> be</font><font color="#E5E5E5"> it depends</font>

366
00:18:59,630 --> 00:19:06,710
<font color="#E5E5E5">on the application data for instance</font>

367
00:19:02,230 --> 00:19:08,419
here for the digits data set<font color="#CCCCCC"> if you</font>

368
00:19:06,710 --> 00:19:10,820
start<font color="#CCCCCC"> increasing</font><font color="#E5E5E5"> too much the</font>

369
00:19:08,419 --> 00:19:12,920
perturbation<font color="#CCCCCC"> you</font><font color="#E5E5E5"> introduce then even as</font>

370
00:19:10,820 --> 00:19:15,080
a human

371
00:19:12,920 --> 00:19:17,870
the the you will miss classify them

372
00:19:15,080 --> 00:19:21,409
because there are<font color="#E5E5E5"> so much noise in the</font>

373
00:19:17,870 --> 00:19:22,939
<font color="#CCCCCC">image</font><font color="#E5E5E5"> so we that's why the</font><font color="#CCCCCC"> adversary is</font>

374
00:19:21,410 --> 00:19:26,630
interested<font color="#E5E5E5"> in minimizing the</font>

375
00:19:22,940 --> 00:19:29,600
perturbation<font color="#E5E5E5"> okay</font><font color="#CCCCCC"> oh</font><font color="#E5E5E5"> thanks</font>

376
00:19:26,630 --> 00:19:31,010
thank you<font color="#CCCCCC"> do you have</font><font color="#E5E5E5"> any</font><font color="#CCCCCC"> backups lights</font>

377
00:19:29,600 --> 00:19:32,959
that you<font color="#CCCCCC"> where you can show us what the</font>

378
00:19:31,010 --> 00:19:35,060
what the perturb minimum perturbed ones

379
00:19:32,960 --> 00:19:39,350
look like<font color="#E5E5E5"> with your system what the ones</font>

380
00:19:35,060 --> 00:19:41,720
and what the ones<font color="#E5E5E5"> I do not have</font><font color="#CCCCCC"> that</font><font color="#E5E5E5"> do</font>

381
00:19:39,350 --> 00:19:45,260
<font color="#CCCCCC">do humans</font><font color="#E5E5E5"> look at them and say oh that's</font>

382
00:19:41,720 --> 00:19:48,320
a<font color="#E5E5E5"> nine instead of it's a</font><font color="#CCCCCC"> one we haven't</font>

383
00:19:45,260 --> 00:19:51,170
<font color="#E5E5E5">studied that with distillation we in</font>

384
00:19:48,320 --> 00:19:56,060
previous work we studied the perception

385
00:19:51,170 --> 00:19:59,500
of humans<font color="#E5E5E5"> on virtual samples what we saw</font>

386
00:19:56,060 --> 00:20:01,669
was that<font color="#E5E5E5"> they would miss classify them</font>

387
00:19:59,500 --> 00:20:06,280
above a certain<font color="#CCCCCC"> threshold of</font>

388
00:20:01,670 --> 00:20:09,740
perturbation<font color="#E5E5E5"> and the defense here is</font>

389
00:20:06,280 --> 00:20:13,040
basically bringing the minimum average

390
00:20:09,740 --> 00:20:16,400
perturbation<font color="#E5E5E5"> to that threshold so I</font>

391
00:20:13,040 --> 00:20:18,649
assumed that if you were to repeat the

392
00:20:16,400 --> 00:20:21,020
same study on<font color="#CCCCCC"> human perception you would</font>

393
00:20:18,650 --> 00:20:24,020
find that humans would find these

394
00:20:21,020 --> 00:20:28,520
samples is not acceptable as<font color="#E5E5E5"> well thanks</font>

395
00:20:24,020 --> 00:20:30,889
thank<font color="#CCCCCC"> you just a question for</font><font color="#E5E5E5"> the</font>

396
00:20:28,520 --> 00:20:32,270
<font color="#CCCCCC">district model so do you give the neural</font>

397
00:20:30,890 --> 00:20:35,780
network description also<font color="#E5E5E5"> to the</font>

398
00:20:32,270 --> 00:20:37,280
adversary<font color="#E5E5E5"> oh I'm sorry what is the exact</font>

399
00:20:35,780 --> 00:20:41,120
<font color="#CCCCCC">knowledge of the</font><font color="#E5E5E5"> adversary do you give</font>

400
00:20:37,280 --> 00:20:43,670
him the description of the so this<font color="#E5E5E5"> the</font>

401
00:20:41,120 --> 00:20:45,879
attack that<font color="#CCCCCC"> we use to evaluate the</font>

402
00:20:43,670 --> 00:20:49,130
<font color="#E5E5E5">defense assumes that the adversary has</font>

403
00:20:45,880 --> 00:20:53,590
<font color="#E5E5E5">access to the model parameters and the</font>

404
00:20:49,130 --> 00:20:56,480
architecture however in more<font color="#CCCCCC"> recent work</font>

405
00:20:53,590 --> 00:21:00,110
<font color="#CCCCCC">we</font><font color="#E5E5E5"> show that this knowledge is not</font>

406
00:20:56,480 --> 00:21:02,660
<font color="#E5E5E5">required to</font><font color="#CCCCCC"> conduct</font><font color="#E5E5E5"> the</font><font color="#CCCCCC"> attack</font><font color="#E5E5E5"> and as a</font>

407
00:21:00,110 --> 00:21:05,389
matter<font color="#E5E5E5"> of fact adversary's can conduct</font>

408
00:21:02,660 --> 00:21:09,320
blackbox attacks on any machine<font color="#E5E5E5"> learning</font>

409
00:21:05,390 --> 00:21:12,830
technique<font color="#E5E5E5"> by training substitute models</font>

410
00:21:09,320 --> 00:21:15,500
for their<font color="#E5E5E5"> target so you</font><font color="#CCCCCC"> can ask a very</font>

411
00:21:12,830 --> 00:21:17,000
quick<font color="#CCCCCC"> question and we'll move on so the</font>

412
00:21:15,500 --> 00:21:18,620
applications that<font color="#E5E5E5"> you focused on were</font>

413
00:21:17,000 --> 00:21:21,080
computer vision tasks

414
00:21:18,620 --> 00:21:23,149
and I'm<font color="#CCCCCC"> wondering how</font><font color="#E5E5E5"> this would work</font>

415
00:21:21,080 --> 00:21:25,039
with other<font color="#E5E5E5"> sorts of classification like</font>

416
00:21:23,150 --> 00:21:26,720
suppose just looking at the sensors on

417
00:21:25,039 --> 00:21:32,320
your<font color="#E5E5E5"> SmartWatch or</font><font color="#CCCCCC"> smartphone and doing</font>

418
00:21:26,720 --> 00:21:34,880
activity recognition<font color="#CCCCCC"> so there I haven't</font>

419
00:21:32,320 --> 00:21:39,950
made<font color="#E5E5E5"> that</font><font color="#CCCCCC"> public yet but I have studied</font>

420
00:21:34,880 --> 00:21:42,110
attacks on malware classifiers<font color="#E5E5E5"> and the</font>

421
00:21:39,950 --> 00:21:44,059
attack<font color="#E5E5E5"> is</font><font color="#CCCCCC"> still possible if the neural</font>

422
00:21:42,110 --> 00:21:46,760
network is trying<font color="#E5E5E5"> to detect malware you</font>

423
00:21:44,059 --> 00:21:50,260
can invade it this way<font color="#CCCCCC"> I haven't studied</font>

424
00:21:46,760 --> 00:21:50,260
the impact of<font color="#E5E5E5"> the defense yet</font>

