1
00:00:07,670 --> 00:00:14,379
hi<font color="#E5E5E5"> I'm Matthew at Northeastern</font>

2
00:00:10,200 --> 00:00:15,730
University<font color="#E5E5E5"> I'm going to be</font>

3
00:00:14,380 --> 00:00:17,050
learning poisoning attacks and

4
00:00:15,730 --> 00:00:19,360
countermeasures<font color="#E5E5E5"> against regression</font>

5
00:00:17,050 --> 00:00:21,160
learning<font color="#CCCCCC"> this is joint work with</font><font color="#E5E5E5"> my</font>

6
00:00:19,360 --> 00:00:24,300
<font color="#CCCCCC">advisers</font><font color="#E5E5E5"> Christine Anita</font><font color="#CCCCCC"> ratar-o</font>

7
00:00:21,160 --> 00:00:26,890
and<font color="#E5E5E5"> Alena Priya both at Northeastern</font>

8
00:00:24,300 --> 00:00:30,790
Batista beat<font color="#E5E5E5"> Joe at University of</font><font color="#CCCCCC"> Coyote</font>

9
00:00:26,890 --> 00:00:35,140
and<font color="#E5E5E5"> chun-li</font><font color="#CCCCCC"> you and bully both at UC</font>

10
00:00:30,790 --> 00:00:36,550
<font color="#E5E5E5">Berkeley so</font><font color="#CCCCCC"> oh you can see supervised</font>

11
00:00:35,140 --> 00:00:39,070
machine learning is a pretty common<font color="#E5E5E5"> task</font>

12
00:00:36,550 --> 00:00:40,930
these days<font color="#CCCCCC"> basically how it works is you</font>

13
00:00:39,070 --> 00:00:46,690
<font color="#CCCCCC">start with</font><font color="#E5E5E5"> a training data set with data</font>

14
00:00:40,930 --> 00:00:52,060
and labels you feed this into the<font color="#E5E5E5"> next</font>

15
00:00:46,690 --> 00:00:53,199
slide where yes so you you<font color="#E5E5E5"> you feed this</font>

16
00:00:52,060 --> 00:00:55,330
into<font color="#CCCCCC"> a learning</font><font color="#E5E5E5"> algorithm and</font><font color="#CCCCCC"> it</font>

17
00:00:53,200 --> 00:00:59,560
produces a model and the point of this

18
00:00:55,330 --> 00:01:01,089
model is the<font color="#CCCCCC"> next slide where you use it</font>

19
00:00:59,560 --> 00:01:06,189
<font color="#CCCCCC">on new data that it hasn't</font><font color="#E5E5E5"> seen before</font>

20
00:01:01,090 --> 00:01:08,409
<font color="#E5E5E5">and it produces new labels great so then</font>

21
00:01:06,189 --> 00:01:11,649
I don't know am<font color="#E5E5E5"> I not</font><font color="#CCCCCC"> pressing</font><font color="#E5E5E5"> it hard</font>

22
00:01:08,409 --> 00:01:13,350
enough<font color="#CCCCCC"> yeah so</font><font color="#E5E5E5"> there are two kinds of</font>

23
00:01:11,650 --> 00:01:17,100
prediction<font color="#CCCCCC"> tests you</font><font color="#E5E5E5"> might consider and</font>

24
00:01:13,350 --> 00:01:17,100
supervised machine learning

25
00:01:18,240 --> 00:01:25,359
the first is classification can you go

26
00:01:23,590 --> 00:01:29,859
to the<font color="#E5E5E5"> next slide am I not pressing it</font>

27
00:01:25,359 --> 00:01:32,139
hard enough<font color="#CCCCCC"> okay so the first</font><font color="#E5E5E5"> is</font>

28
00:01:29,859 --> 00:01:34,530
classification where you know that you

29
00:01:32,139 --> 00:01:37,030
have a discrete output space<font color="#E5E5E5"> and so</font>

30
00:01:34,530 --> 00:01:38,829
you're going<font color="#CCCCCC"> to be predicting a class</font>

31
00:01:37,030 --> 00:01:41,200
<font color="#CCCCCC">corresponding to your given input and</font>

32
00:01:38,829 --> 00:01:44,038
this is<font color="#E5E5E5"> something this is common in the</font>

33
00:01:41,200 --> 00:01:46,780
security community<font color="#E5E5E5"> you can think like</font>

34
00:01:44,039 --> 00:01:50,979
malware classification or the like<font color="#CCCCCC"> and</font>

35
00:01:46,780 --> 00:01:54,399
<font color="#E5E5E5">then yeah and then you also have</font>

36
00:01:50,979 --> 00:01:57,249
regression where you know that you have

37
00:01:54,399 --> 00:01:58,719
a continuous output space and so<font color="#E5E5E5"> you're</font>

38
00:01:57,249 --> 00:02:03,969
<font color="#E5E5E5">going to be predicting this response</font>

39
00:01:58,719 --> 00:02:07,119
value given an input data<font color="#E5E5E5"> and I'm sorry</font>

40
00:02:03,969 --> 00:02:10,109
<font color="#E5E5E5">but this is can we go back like three</font>

41
00:02:07,119 --> 00:02:10,110
four slides

42
00:02:13,500 --> 00:02:25,330
<font color="#E5E5E5">yeah so so there's classification and</font>

43
00:02:16,660 --> 00:02:27,970
regression<font color="#CCCCCC"> and yeah</font><font color="#E5E5E5"> this one is yes so</font>

44
00:02:25,330 --> 00:02:29,830
classification and regression<font color="#CCCCCC"> this is a</font>

45
00:02:27,970 --> 00:02:37,329
I guess visual but I already<font color="#CCCCCC"> told you</font>

46
00:02:29,830 --> 00:02:41,110
<font color="#E5E5E5">about it so I guess the next slide we go</font>

47
00:02:37,330 --> 00:02:43,720
back one all<font color="#E5E5E5"> right so now what's a</font>

48
00:02:41,110 --> 00:02:45,850
poisoning attack so an adversary is able

49
00:02:43,720 --> 00:02:48,100
to add<font color="#E5E5E5"> points in</font><font color="#CCCCCC"> at training</font><font color="#E5E5E5"> time and</font>

50
00:02:45,850 --> 00:02:49,510
this<font color="#E5E5E5"> is going</font><font color="#CCCCCC"> to</font><font color="#E5E5E5"> the learning algorithm</font>

51
00:02:48,100 --> 00:02:52,210
<font color="#E5E5E5">is going to</font><font color="#CCCCCC"> incorporate these points</font>

52
00:02:49,510 --> 00:02:54,459
into<font color="#CCCCCC"> the model</font><font color="#E5E5E5"> that it builds at and</font>

53
00:02:52,210 --> 00:02:56,380
then the<font color="#E5E5E5"> model is going to be incorrect</font>

54
00:02:54,460 --> 00:03:00,040
<font color="#E5E5E5">at test time because it it's using this</font>

55
00:02:56,380 --> 00:03:01,540
<font color="#E5E5E5">incorrect training data so in this talk</font>

56
00:03:00,040 --> 00:03:04,390
<font color="#E5E5E5">we're going to be talking about</font>

57
00:03:01,540 --> 00:03:05,799
<font color="#E5E5E5">regression models</font><font color="#CCCCCC"> so we're gonna focus</font>

58
00:03:04,390 --> 00:03:07,779
on Ridge for this talk<font color="#E5E5E5"> but we test</font>

59
00:03:05,800 --> 00:03:09,370
against other ones in our paper<font color="#E5E5E5"> I'm</font>

60
00:03:07,780 --> 00:03:11,560
<font color="#CCCCCC">gonna be telling you about our</font><font color="#E5E5E5"> poisoning</font>

61
00:03:09,370 --> 00:03:13,990
attacks<font color="#E5E5E5"> that we developed called</font><font color="#CCCCCC"> opt P</font>

62
00:03:11,560 --> 00:03:20,590
and stop key<font color="#CCCCCC"> and then our defense trim</font>

63
00:03:13,990 --> 00:03:23,640
<font color="#E5E5E5">and a bit about evaluation</font><font color="#CCCCCC"> great</font><font color="#E5E5E5"> so so</font>

64
00:03:20,590 --> 00:03:26,500
<font color="#E5E5E5">linear regression is a type</font><font color="#CCCCCC"> of</font>

65
00:03:23,640 --> 00:03:30,250
regression<font color="#E5E5E5"> model so you you</font><font color="#CCCCCC"> have data</font>

66
00:03:26,500 --> 00:03:32,170
and your response values<font color="#E5E5E5"> you can and you</font>

67
00:03:30,250 --> 00:03:33,580
<font color="#E5E5E5">want to build a linear model</font><font color="#CCCCCC"> in order to</font>

68
00:03:32,170 --> 00:03:35,530
predict the response values from<font color="#E5E5E5"> the</font>

69
00:03:33,580 --> 00:03:37,930
given data<font color="#E5E5E5"> so you can</font><font color="#CCCCCC"> see this on the</font>

70
00:03:35,530 --> 00:03:40,630
<font color="#E5E5E5">right these red dots have the X values</font>

71
00:03:37,930 --> 00:03:43,180
this is<font color="#CCCCCC"> the the data</font><font color="#E5E5E5"> features and the</font>

72
00:03:40,630 --> 00:03:45,549
response values are the Y<font color="#CCCCCC"> values and our</font>

73
00:03:43,180 --> 00:03:47,650
goal is<font color="#CCCCCC"> to build</font><font color="#E5E5E5"> this blue line</font><font color="#CCCCCC"> that</font>

74
00:03:45,550 --> 00:03:49,120
cuts<font color="#E5E5E5"> through them and the way you do</font>

75
00:03:47,650 --> 00:03:51,940
this is<font color="#CCCCCC"> by minimizing a loss function</font>

76
00:03:49,120 --> 00:03:53,230
<font color="#CCCCCC">over your training data</font><font color="#E5E5E5"> this consists of</font>

77
00:03:51,940 --> 00:03:55,030
two parts<font color="#CCCCCC"> you have the the</font>

78
00:03:53,230 --> 00:03:56,649
regularization<font color="#E5E5E5"> or sorry that</font><font color="#CCCCCC"> you have</font>

79
00:03:55,030 --> 00:03:58,810
the residuals<font color="#CCCCCC"> piece which is</font><font color="#E5E5E5"> basically</font>

80
00:03:56,650 --> 00:04:01,060
<font color="#E5E5E5">how well your model fits your your</font>

81
00:03:58,810 --> 00:04:03,100
training data<font color="#CCCCCC"> this</font><font color="#E5E5E5"> is also called mean</font>

82
00:04:01,060 --> 00:04:05,020
squared error and then you have your

83
00:04:03,100 --> 00:04:10,000
regularization piece which prevents

84
00:04:05,020 --> 00:04:12,490
overfitting<font color="#E5E5E5"> all right so what is</font><font color="#CCCCCC"> the</font>

85
00:04:10,000 --> 00:04:14,880
poisoning attack<font color="#CCCCCC"> it's this thing here</font>

86
00:04:12,490 --> 00:04:17,890
<font color="#E5E5E5">and I hope this doesn't</font><font color="#CCCCCC"> solve any</font>

87
00:04:14,880 --> 00:04:19,339
problems for<font color="#E5E5E5"> you in your head so let me</font>

88
00:04:17,890 --> 00:04:20,810
unpack it

89
00:04:19,339 --> 00:04:23,690
so basically you start<font color="#E5E5E5"> with</font><font color="#CCCCCC"> the training</font>

90
00:04:20,810 --> 00:04:26,000
<font color="#E5E5E5">data set and your adversary is</font><font color="#CCCCCC"> going to</font>

91
00:04:23,690 --> 00:04:27,949
be able<font color="#E5E5E5"> to add poison data points into</font>

92
00:04:26,000 --> 00:04:29,539
<font color="#CCCCCC">your</font><font color="#E5E5E5"> training data set and the way</font>

93
00:04:27,949 --> 00:04:32,720
they're<font color="#CCCCCC"> going</font><font color="#E5E5E5"> to do</font><font color="#CCCCCC"> this is in</font><font color="#E5E5E5"> order to</font>

94
00:04:29,539 --> 00:04:34,818
<font color="#E5E5E5">maximize their objective so this might</font>

95
00:04:32,720 --> 00:04:38,509
<font color="#CCCCCC">be the</font><font color="#E5E5E5"> the training loss or something</font>

96
00:04:34,819 --> 00:04:40,129
<font color="#CCCCCC">like</font><font color="#E5E5E5"> that</font><font color="#CCCCCC"> and the thing is the the</font>

97
00:04:38,509 --> 00:04:42,680
<font color="#E5E5E5">objective</font><font color="#CCCCCC"> they</font><font color="#E5E5E5"> only have control</font><font color="#CCCCCC"> over</font>

98
00:04:40,129 --> 00:04:45,080
<font color="#E5E5E5">this corrupted model and it's learned by</font>

99
00:04:42,680 --> 00:04:46,940
minimizing this loss function over both

100
00:04:45,080 --> 00:04:50,120
the<font color="#E5E5E5"> training in the</font><font color="#CCCCCC"> poisoned test data</font>

101
00:04:46,940 --> 00:04:53,180
<font color="#E5E5E5">and this</font><font color="#CCCCCC"> is actually very</font><font color="#E5E5E5"> hard because</font>

102
00:04:50,120 --> 00:04:55,819
<font color="#E5E5E5">you only have control implicit can your</font>

103
00:04:53,180 --> 00:04:58,219
adversary only has implicit control over

104
00:04:55,819 --> 00:05:00,139
their objective based on the the entire

105
00:04:58,219 --> 00:05:02,090
<font color="#E5E5E5">training process and so this turns into</font>

106
00:05:00,139 --> 00:05:06,620
<font color="#E5E5E5">a bi-level optimization problem which is</font>

107
00:05:02,090 --> 00:05:08,210
np-hard in the general<font color="#E5E5E5"> case</font><font color="#CCCCCC"> so in order</font>

108
00:05:06,620 --> 00:05:10,879
to approach<font color="#E5E5E5"> this we're going</font><font color="#CCCCCC"> to define</font>

109
00:05:08,210 --> 00:05:12,590
<font color="#CCCCCC">our adversary</font><font color="#E5E5E5"> we consider two</font>

110
00:05:10,879 --> 00:05:16,460
adversaries<font color="#CCCCCC"> a white box and the black</font>

111
00:05:12,590 --> 00:05:17,780
box<font color="#CCCCCC"> attacks</font><font color="#E5E5E5"> we have white box attacks</font>

112
00:05:16,460 --> 00:05:19,340
where the adversary<font color="#CCCCCC"> knows everything</font>

113
00:05:17,780 --> 00:05:21,500
this<font color="#CCCCCC"> is a</font><font color="#E5E5E5"> training data type of</font>

114
00:05:19,340 --> 00:05:23,599
parameters<font color="#CCCCCC"> the algorithm that's being</font>

115
00:05:21,500 --> 00:05:26,120
used<font color="#E5E5E5"> and then we also have a black box</font>

116
00:05:23,599 --> 00:05:28,550
<font color="#E5E5E5">attack where they only are allowed query</font>

117
00:05:26,120 --> 00:05:32,050
access to the model and<font color="#CCCCCC"> statistical</font>

118
00:05:28,550 --> 00:05:34,520
<font color="#CCCCCC">information</font><font color="#E5E5E5"> and then we we also have</font>

119
00:05:32,050 --> 00:05:37,159
some<font color="#E5E5E5"> parameters</font><font color="#CCCCCC"> that our adversary is</font>

120
00:05:34,520 --> 00:05:38,960
<font color="#CCCCCC">going to satisfy we have they are only</font>

121
00:05:37,159 --> 00:05:42,949
able to<font color="#E5E5E5"> add some alpha fraction to the</font>

122
00:05:38,960 --> 00:05:44,779
<font color="#E5E5E5">data set and then the the values for the</font>

123
00:05:42,949 --> 00:05:46,580
the points they can<font color="#E5E5E5"> add are going to be</font>

124
00:05:44,779 --> 00:05:47,960
bounded<font color="#CCCCCC"> within the the</font><font color="#E5E5E5"> natural bounds of</font>

125
00:05:46,580 --> 00:05:49,729
the feature<font color="#E5E5E5"> and this is this is what</font>

126
00:05:47,960 --> 00:05:52,370
we're going<font color="#CCCCCC"> to be determining from the</font>

127
00:05:49,729 --> 00:05:53,240
<font color="#E5E5E5">training</font><font color="#CCCCCC"> data and</font><font color="#E5E5E5"> the goal of</font><font color="#CCCCCC"> our</font>

128
00:05:52,370 --> 00:05:55,099
adversary is just going<font color="#E5E5E5"> to be</font>

129
00:05:53,240 --> 00:05:56,900
indiscriminate availability which this

130
00:05:55,099 --> 00:06:01,360
means we're<font color="#E5E5E5"> going to</font><font color="#CCCCCC"> maximize the loss</font>

131
00:05:56,900 --> 00:06:03,830
of the model<font color="#CCCCCC"> great</font><font color="#E5E5E5"> so how do we do this</font>

132
00:06:01,360 --> 00:06:07,279
<font color="#CCCCCC">we're going to</font><font color="#E5E5E5"> use</font><font color="#CCCCCC"> first optimization</font>

133
00:06:03,830 --> 00:06:09,859
<font color="#CCCCCC">based poisoning attacks so we start</font><font color="#E5E5E5"> with</font>

134
00:06:07,279 --> 00:06:12,080
a set<font color="#CCCCCC"> of good initial poisoning points</font>

135
00:06:09,860 --> 00:06:14,060
and we want to run<font color="#E5E5E5"> gradient descent on</font>

136
00:06:12,080 --> 00:06:16,758
these points<font color="#CCCCCC"> and gradient descent is</font>

137
00:06:14,060 --> 00:06:18,289
just a<font color="#E5E5E5"> greedy optimization approach what</font>

138
00:06:16,759 --> 00:06:19,849
<font color="#E5E5E5">you what you do is you start</font><font color="#CCCCCC"> with a</font>

139
00:06:18,289 --> 00:06:21,500
point<font color="#E5E5E5"> and you see which direction</font><font color="#CCCCCC"> is</font>

140
00:06:19,849 --> 00:06:22,849
<font color="#CCCCCC">going</font><font color="#E5E5E5"> to improve my point the most and</font>

141
00:06:21,500 --> 00:06:24,229
you keep<font color="#CCCCCC"> doing that until</font><font color="#E5E5E5"> you're</font>

142
00:06:22,849 --> 00:06:25,229
satisfied with<font color="#E5E5E5"> where you're at you</font><font color="#CCCCCC"> can</font>

143
00:06:24,229 --> 00:06:26,909
<font color="#CCCCCC">see this on the</font><font color="#E5E5E5"> right</font>

144
00:06:25,230 --> 00:06:29,010
these points<font color="#CCCCCC"> they're</font><font color="#E5E5E5"> starting in like</font>

145
00:06:26,910 --> 00:06:31,410
<font color="#E5E5E5">these little blue valleys</font><font color="#CCCCCC"> there they're</font>

146
00:06:29,010 --> 00:06:35,190
taking<font color="#E5E5E5"> steps upwards and they're getting</font>

147
00:06:31,410 --> 00:06:37,320
into the red area<font color="#E5E5E5"> great</font><font color="#CCCCCC"> so people have</font>

148
00:06:35,190 --> 00:06:41,310
done<font color="#CCCCCC"> this in</font><font color="#E5E5E5"> the past for this kind of</font>

149
00:06:37,320 --> 00:06:44,190
attack<font color="#CCCCCC"> on the next slide</font>

150
00:06:41,310 --> 00:06:45,930
<font color="#E5E5E5">yes so people have done this in the</font><font color="#CCCCCC"> past</font>

151
00:06:44,190 --> 00:06:48,600
for these kinds of models<font color="#E5E5E5"> for</font>

152
00:06:45,930 --> 00:06:50,910
classification<font color="#CCCCCC"> setting</font><font color="#E5E5E5"> and their</font>

153
00:06:48,600 --> 00:06:53,460
objective<font color="#CCCCCC"> was to</font><font color="#E5E5E5"> maximize the regular as</font>

154
00:06:50,910 --> 00:06:54,990
training<font color="#CCCCCC"> laws the way they initialize</font>

155
00:06:53,460 --> 00:06:57,030
their points was just by flipping over

156
00:06:54,990 --> 00:06:59,490
<font color="#E5E5E5">the model and they ran gradient descent</font>

157
00:06:57,030 --> 00:07:02,099
in order to optimize their<font color="#CCCCCC"> x-value</font><font color="#E5E5E5"> the</font>

158
00:06:59,490 --> 00:07:03,480
gradient looks like this which is it's

159
00:07:02,100 --> 00:07:04,620
<font color="#E5E5E5">just some linear algebra</font><font color="#CCCCCC"> once you know</font>

160
00:07:03,480 --> 00:07:06,180
the gradient of<font color="#E5E5E5"> the model parameters</font>

161
00:07:04,620 --> 00:07:07,620
<font color="#CCCCCC">with respect to the point</font><font color="#E5E5E5"> that you're</font>

162
00:07:06,180 --> 00:07:09,990
<font color="#CCCCCC">adding this is a very non-trivial</font>

163
00:07:07,620 --> 00:07:11,640
dependence<font color="#CCCCCC"> because it's it's the output</font>

164
00:07:09,990 --> 00:07:13,230
of this<font color="#CCCCCC"> optimization process again and</font>

165
00:07:11,640 --> 00:07:16,440
so what they did<font color="#E5E5E5"> was</font><font color="#CCCCCC"> they use the KKT</font>

166
00:07:13,230 --> 00:07:17,880
conditions<font color="#E5E5E5"> for this this model in order</font>

167
00:07:16,440 --> 00:07:20,810
<font color="#E5E5E5">to drive the linear equation</font><font color="#CCCCCC"> that</font><font color="#E5E5E5"> they</font>

168
00:07:17,880 --> 00:07:26,670
can then solve and compute this gradient

169
00:07:20,810 --> 00:07:28,530
<font color="#E5E5E5">this was ICML 2015 and what we did is we</font>

170
00:07:26,670 --> 00:07:30,150
we took this<font color="#E5E5E5"> and we saw that there</font><font color="#CCCCCC"> are</font>

171
00:07:28,530 --> 00:07:32,580
many ways<font color="#CCCCCC"> that you can be improving</font><font color="#E5E5E5"> this</font>

172
00:07:30,150 --> 00:07:34,229
attack<font color="#E5E5E5"> first</font><font color="#CCCCCC"> we know we have a</font>

173
00:07:32,580 --> 00:07:36,120
regression task and so we can also

174
00:07:34,230 --> 00:07:37,530
optimize<font color="#E5E5E5"> on the</font><font color="#CCCCCC"> y-value and so this</font>

175
00:07:36,120 --> 00:07:38,940
<font color="#E5E5E5">actually ends up being</font><font color="#CCCCCC"> just one more</font>

176
00:07:37,530 --> 00:07:41,729
<font color="#E5E5E5">linear equation</font><font color="#CCCCCC"> that we need to solve</font>

177
00:07:38,940 --> 00:07:43,260
and you<font color="#E5E5E5"> can see this on the right the</font>

178
00:07:41,730 --> 00:07:45,630
<font color="#CCCCCC">y-value is</font><font color="#E5E5E5"> this vertical</font><font color="#CCCCCC"> axis you see</font>

179
00:07:43,260 --> 00:07:47,430
<font color="#E5E5E5">that these</font><font color="#CCCCCC"> points</font><font color="#E5E5E5"> are improving a lot</font>

180
00:07:45,630 --> 00:07:51,600
when you're<font color="#CCCCCC"> able to</font><font color="#E5E5E5"> optimize over the</font>

181
00:07:47,430 --> 00:07:54,210
<font color="#CCCCCC">y-value second</font><font color="#E5E5E5"> what they did in their</font>

182
00:07:51,600 --> 00:07:55,740
work was it<font color="#E5E5E5"> called in flip where they've</font>

183
00:07:54,210 --> 00:07:59,250
<font color="#E5E5E5">just pushed to the other side of the</font>

184
00:07:55,740 --> 00:08:00,840
plane<font color="#E5E5E5"> you can see the you you're already</font>

185
00:07:59,250 --> 00:08:02,430
<font color="#E5E5E5">close to</font><font color="#CCCCCC"> the plane at the start if you</font>

186
00:08:00,840 --> 00:08:03,840
have<font color="#CCCCCC"> a good regression model</font><font color="#E5E5E5"> flipping</font>

187
00:08:02,430 --> 00:08:04,830
isn't going to movie very<font color="#E5E5E5"> far</font><font color="#CCCCCC"> and so</font>

188
00:08:03,840 --> 00:08:07,140
we're just<font color="#CCCCCC"> gonna push it even further</font>

189
00:08:04,830 --> 00:08:08,729
<font color="#E5E5E5">and then finally we also</font><font color="#CCCCCC"> tested</font><font color="#E5E5E5"> with</font>

190
00:08:07,140 --> 00:08:10,530
<font color="#E5E5E5">another loss function they used the</font>

191
00:08:08,730 --> 00:08:12,960
<font color="#E5E5E5">regulars training loss which is exactly</font>

192
00:08:10,530 --> 00:08:17,340
what the learner is trying to minimize

193
00:08:12,960 --> 00:08:19,440
<font color="#E5E5E5">we used a validation set loss all right</font>

194
00:08:17,340 --> 00:08:20,609
<font color="#E5E5E5">so this actually requires</font><font color="#CCCCCC"> a lot of</font>

195
00:08:19,440 --> 00:08:22,050
<font color="#CCCCCC">knowledge about</font><font color="#E5E5E5"> the</font><font color="#CCCCCC"> system right the</font>

196
00:08:20,610 --> 00:08:23,490
<font color="#CCCCCC">training</font><font color="#E5E5E5"> data the parameters and</font>

197
00:08:22,050 --> 00:08:26,520
everything what if their adversary

198
00:08:23,490 --> 00:08:29,940
<font color="#E5E5E5">doesn't have access</font><font color="#CCCCCC"> to this so we also</font>

199
00:08:26,520 --> 00:08:31,979
looked at<font color="#E5E5E5"> this setting</font><font color="#CCCCCC"> and we have a</font>

200
00:08:29,940 --> 00:08:33,900
black<font color="#CCCCCC"> box attack that we call stat</font><font color="#E5E5E5"> P and</font>

201
00:08:31,980 --> 00:08:35,200
all<font color="#E5E5E5"> this</font><font color="#CCCCCC"> requires</font><font color="#E5E5E5"> is you're able</font><font color="#CCCCCC"> to</font>

202
00:08:33,900 --> 00:08:37,120
<font color="#E5E5E5">sample</font><font color="#CCCCCC"> from the mean</font><font color="#E5E5E5"> and</font>

203
00:08:35,200 --> 00:08:41,620
variants of the the<font color="#E5E5E5"> training data and</font>

204
00:08:37,120 --> 00:08:42,549
then query<font color="#E5E5E5"> the model</font><font color="#CCCCCC"> and then</font><font color="#E5E5E5"> so yeah so</font>

205
00:08:41,620 --> 00:08:44,080
how you're<font color="#E5E5E5"> going to do this is your</font>

206
00:08:42,549 --> 00:08:46,569
sample<font color="#CCCCCC"> you query</font><font color="#E5E5E5"> the model and then</font><font color="#CCCCCC"> you</font>

207
00:08:44,080 --> 00:08:48,820
<font color="#E5E5E5">flip the output using the</font><font color="#CCCCCC"> B</font><font color="#E5E5E5"> flip that I</font>

208
00:08:46,570 --> 00:08:51,010
just talked about<font color="#E5E5E5"> and this is</font><font color="#CCCCCC"> going</font><font color="#E5E5E5"> to</font>

209
00:08:48,820 --> 00:08:53,680
be your poisoning point<font color="#E5E5E5"> so as you can be</font>

210
00:08:51,010 --> 00:08:55,120
pretty fast<font color="#CCCCCC"> and</font><font color="#E5E5E5"> basically you can</font><font color="#CCCCCC"> see</font>

211
00:08:53,680 --> 00:08:57,400
<font color="#E5E5E5">kind of</font><font color="#CCCCCC"> some math for why this works</font>

212
00:08:55,120 --> 00:08:59,350
<font color="#E5E5E5">down</font><font color="#CCCCCC"> at</font><font color="#E5E5E5"> the bottom the left is your</font>

213
00:08:57,400 --> 00:09:02,140
<font color="#E5E5E5">unpause and model and the right is going</font>

214
00:08:59,350 --> 00:09:03,970
<font color="#E5E5E5">to</font><font color="#CCCCCC"> be</font><font color="#E5E5E5"> the Poisson model basically this</font>

215
00:09:02,140 --> 00:09:05,860
is keeping<font color="#E5E5E5"> the statistical properties</font><font color="#CCCCCC"> of</font>

216
00:09:03,970 --> 00:09:08,800
datas of the yeah the data set pretty

217
00:09:05,860 --> 00:09:11,350
fixed<font color="#CCCCCC"> while maximizing the the</font>

218
00:09:08,800 --> 00:09:12,880
modification of<font color="#E5E5E5"> the correlations and so</font>

219
00:09:11,350 --> 00:09:16,390
<font color="#E5E5E5">you're going to be poisoning the model</font>

220
00:09:12,880 --> 00:09:18,220
<font color="#E5E5E5">pretty effectively</font><font color="#CCCCCC"> alright so talk to</font>

221
00:09:16,390 --> 00:09:19,540
you about<font color="#CCCCCC"> attacks</font><font color="#E5E5E5"> how are we gonna get</font>

222
00:09:18,220 --> 00:09:21,370
around<font color="#E5E5E5"> these so there are people</font><font color="#CCCCCC"> that</font>

223
00:09:19,540 --> 00:09:24,130
<font color="#E5E5E5">have</font><font color="#CCCCCC"> so-so like what you would want from</font>

224
00:09:21,370 --> 00:09:26,100
a defense is you want to<font color="#CCCCCC"> identify and</font>

225
00:09:24,130 --> 00:09:28,689
train<font color="#CCCCCC"> without these</font><font color="#E5E5E5"> poisoned points</font>

226
00:09:26,100 --> 00:09:30,790
people have built<font color="#E5E5E5"> techniques for this in</font>

227
00:09:28,690 --> 00:09:33,700
the past<font color="#E5E5E5"> some were not specifically</font>

228
00:09:30,790 --> 00:09:36,089
designed<font color="#CCCCCC"> for poisoning in some work so</font>

229
00:09:33,700 --> 00:09:38,890
some that weren't<font color="#CCCCCC"> where Hueber loss</font>

230
00:09:36,090 --> 00:09:44,170
modifies the loss function in order to

231
00:09:38,890 --> 00:09:46,000
<font color="#E5E5E5">incorporate or in order to to work for</font>

232
00:09:44,170 --> 00:09:48,339
larger errors<font color="#E5E5E5"> but this is still</font><font color="#CCCCCC"> gonna</font>

233
00:09:46,000 --> 00:09:50,320
<font color="#E5E5E5">incorporate these</font><font color="#CCCCCC"> poison points into the</font>

234
00:09:48,340 --> 00:09:52,930
<font color="#E5E5E5">model</font><font color="#CCCCCC"> and so it's not</font><font color="#E5E5E5"> going to be great</font>

235
00:09:50,320 --> 00:09:54,850
<font color="#CCCCCC">for</font><font color="#E5E5E5"> an adversarial setting then there's</font>

236
00:09:52,930 --> 00:09:57,189
also<font color="#E5E5E5"> ransack which samples points and</font>

237
00:09:54,850 --> 00:09:59,650
and trains on<font color="#CCCCCC"> the smaller sample</font><font color="#E5E5E5"> but</font>

238
00:09:57,190 --> 00:10:01,570
<font color="#E5E5E5">this smaller sample is still going to</font>

239
00:09:59,650 --> 00:10:02,949
contain<font color="#E5E5E5"> poison</font><font color="#CCCCCC"> endpoints in a high</font>

240
00:10:01,570 --> 00:10:04,960
poison rate scenario and so it's<font color="#E5E5E5"> not</font>

241
00:10:02,950 --> 00:10:06,190
<font color="#E5E5E5">going to be great in that setting and</font>

242
00:10:04,960 --> 00:10:08,920
then some techniques<font color="#CCCCCC"> for design</font><font color="#E5E5E5"> for</font>

243
00:10:06,190 --> 00:10:10,690
poisoning<font color="#CCCCCC"> ken it all proposed one based</font>

244
00:10:08,920 --> 00:10:11,949
on robust our products<font color="#E5E5E5"> but unfortunately</font>

245
00:10:10,690 --> 00:10:13,690
it has strong assumptions about the

246
00:10:11,950 --> 00:10:16,660
<font color="#E5E5E5">training data that we don't see</font>

247
00:10:13,690 --> 00:10:19,300
satisfied<font color="#E5E5E5"> in the data sets we test it</font>

248
00:10:16,660 --> 00:10:21,339
against and then finally we have<font color="#CCCCCC"> Roni</font>

249
00:10:19,300 --> 00:10:22,990
which is a<font color="#E5E5E5"> technique from the security</font>

250
00:10:21,340 --> 00:10:25,600
community<font color="#E5E5E5"> where you train with and</font>

251
00:10:22,990 --> 00:10:28,000
<font color="#CCCCCC">without each training point and evaluate</font>

252
00:10:25,600 --> 00:10:30,010
the change in the loss<font color="#E5E5E5"> but unfortunately</font>

253
00:10:28,000 --> 00:10:32,380
this this<font color="#E5E5E5"> change in loss is evaluated on</font>

254
00:10:30,010 --> 00:10:33,490
a model that is<font color="#E5E5E5"> poisoned itself and so</font>

255
00:10:32,380 --> 00:10:36,310
it's not<font color="#E5E5E5"> going to be great in</font><font color="#CCCCCC"> a high</font>

256
00:10:33,490 --> 00:10:38,200
poison a great scenario<font color="#CCCCCC"> alright so these</font>

257
00:10:36,310 --> 00:10:40,900
all have<font color="#E5E5E5"> their drawbacks how do we</font>

258
00:10:38,200 --> 00:10:42,760
approach<font color="#E5E5E5"> the problem so basically what</font>

259
00:10:40,900 --> 00:10:44,410
you<font color="#E5E5E5"> would want for a defense is you want</font>

260
00:10:42,760 --> 00:10:46,600
to<font color="#E5E5E5"> find the best points and</font><font color="#CCCCCC"> train on</font>

261
00:10:44,410 --> 00:10:47,860
them so if<font color="#E5E5E5"> you already know</font><font color="#CCCCCC"> your model</font>

262
00:10:46,600 --> 00:10:48,279
parameters it's pretty easy to<font color="#E5E5E5"> find the</font>

263
00:10:47,860 --> 00:10:49,569
<font color="#E5E5E5">best</font>

264
00:10:48,279 --> 00:10:52,360
you just pick<font color="#CCCCCC"> the ones with the</font><font color="#E5E5E5"> smallest</font>

265
00:10:49,569 --> 00:10:53,740
residuals<font color="#CCCCCC"> but</font><font color="#E5E5E5"> unfortunately if you're</font>

266
00:10:52,360 --> 00:10:55,540
<font color="#CCCCCC">building your model you</font><font color="#E5E5E5"> don't you don't</font>

267
00:10:53,740 --> 00:10:56,980
<font color="#E5E5E5">know the model parameters and you</font><font color="#CCCCCC"> don't</font>

268
00:10:55,540 --> 00:11:01,089
know<font color="#E5E5E5"> that the true training data</font>

269
00:10:56,980 --> 00:11:02,470
<font color="#E5E5E5">distribution either so the idea is we're</font>

270
00:11:01,089 --> 00:11:04,149
<font color="#CCCCCC">just going to alternately estimate these</font>

271
00:11:02,470 --> 00:11:07,269
model parameters and find these<font color="#E5E5E5"> little</font>

272
00:11:04,149 --> 00:11:10,720
residual points and<font color="#E5E5E5"> you can</font><font color="#CCCCCC"> see this</font>

273
00:11:07,269 --> 00:11:11,949
<font color="#CCCCCC">working</font><font color="#E5E5E5"> on the right and you can</font><font color="#CCCCCC"> see at</font>

274
00:11:10,720 --> 00:11:13,629
the<font color="#CCCCCC"> start we've got these poisoning</font>

275
00:11:11,949 --> 00:11:15,579
points are<font color="#E5E5E5"> pretty significantly altering</font>

276
00:11:13,629 --> 00:11:17,139
our model<font color="#CCCCCC"> but</font><font color="#E5E5E5"> after we go through</font><font color="#CCCCCC"> a</font>

277
00:11:15,579 --> 00:11:19,420
couple iterations<font color="#CCCCCC"> you can see the line</font>

278
00:11:17,139 --> 00:11:23,559
<font color="#CCCCCC">is starting</font><font color="#E5E5E5"> to to really match what the</font>

279
00:11:19,420 --> 00:11:25,809
<font color="#E5E5E5">true training data is like great</font><font color="#CCCCCC"> so talk</font>

280
00:11:23,559 --> 00:11:28,319
to<font color="#E5E5E5"> you about attacks defenses</font><font color="#CCCCCC"> and I'll</font>

281
00:11:25,809 --> 00:11:30,699
talk to you a bit<font color="#CCCCCC"> about how we evaluated</font>

282
00:11:28,319 --> 00:11:32,019
<font color="#CCCCCC">I'm not going</font><font color="#E5E5E5"> to get too</font><font color="#CCCCCC"> much into</font><font color="#E5E5E5"> it</font><font color="#CCCCCC"> we</font>

283
00:11:30,699 --> 00:11:35,559
have a lot<font color="#CCCCCC"> of</font><font color="#E5E5E5"> experiments in our paper</font>

284
00:11:32,019 --> 00:11:37,569
<font color="#E5E5E5">but for</font><font color="#CCCCCC"> example we tested on a loan</font>

285
00:11:35,559 --> 00:11:40,389
interest rate prediction data set from

286
00:11:37,569 --> 00:11:41,860
<font color="#CCCCCC">Kaggle</font><font color="#E5E5E5"> and we essentially are seeing</font>

287
00:11:40,389 --> 00:11:44,829
that<font color="#CCCCCC"> both of</font><font color="#E5E5E5"> our attacks are improving</font>

288
00:11:41,860 --> 00:11:47,110
pretty significantly over prior work<font color="#E5E5E5"> on</font>

289
00:11:44,829 --> 00:11:48,609
the the<font color="#CCCCCC"> bottom left is the the</font><font color="#E5E5E5"> zero</font>

290
00:11:47,110 --> 00:11:50,589
<font color="#E5E5E5">percent poisoning rate this</font><font color="#CCCCCC"> is like your</font>

291
00:11:48,610 --> 00:11:51,910
your ground truth model<font color="#CCCCCC"> if you weren't</font>

292
00:11:50,589 --> 00:11:54,100
happy if you didn't have<font color="#E5E5E5"> any poisoning</font>

293
00:11:51,910 --> 00:11:56,110
and<font color="#CCCCCC"> were</font><font color="#E5E5E5"> able to improve</font><font color="#CCCCCC"> upon</font><font color="#E5E5E5"> the</font>

294
00:11:54,100 --> 00:12:00,250
existing work by a factor<font color="#E5E5E5"> about like six</font>

295
00:11:56,110 --> 00:12:02,259
point eight three in some cases<font color="#CCCCCC"> and</font><font color="#E5E5E5"> we</font>

296
00:12:00,250 --> 00:12:04,059
also wanted<font color="#E5E5E5"> to</font><font color="#CCCCCC"> evaluate our attacks if</font>

297
00:12:02,259 --> 00:12:05,680
we didn't have full training set

298
00:12:04,059 --> 00:12:07,600
knowledge<font color="#E5E5E5"> so this is like a</font>

299
00:12:05,680 --> 00:12:10,420
<font color="#E5E5E5">transferability attack</font>

300
00:12:07,600 --> 00:12:13,240
so basically we're<font color="#CCCCCC"> able to see that our</font>

301
00:12:10,420 --> 00:12:15,149
attacks are pretty transferable<font color="#CCCCCC"> even if</font>

302
00:12:13,240 --> 00:12:17,079
you don't know the<font color="#E5E5E5"> full training data</font>

303
00:12:15,149 --> 00:12:21,279
<font color="#CCCCCC">when you're running</font><font color="#E5E5E5"> your optimization</font>

304
00:12:17,079 --> 00:12:22,870
<font color="#E5E5E5">and then so for our defense we you can</font>

305
00:12:21,279 --> 00:12:26,019
see<font color="#E5E5E5"> here this</font><font color="#CCCCCC"> is the same</font><font color="#E5E5E5"> data set</font>

306
00:12:22,870 --> 00:12:28,180
there's no defense<font color="#CCCCCC"> is is</font><font color="#E5E5E5"> right there at</font>

307
00:12:26,019 --> 00:12:31,629
the top again<font color="#CCCCCC"> the</font><font color="#E5E5E5"> bottom left is a</font><font color="#CCCCCC"> none</font>

308
00:12:28,180 --> 00:12:32,920
<font color="#E5E5E5">poison data set and basically what you</font>

309
00:12:31,629 --> 00:12:34,509
would<font color="#CCCCCC"> want from</font><font color="#E5E5E5"> a defense is that it's a</font>

310
00:12:32,920 --> 00:12:36,969
flat line at the bottom<font color="#CCCCCC"> it's</font><font color="#E5E5E5"> not being</font>

311
00:12:34,509 --> 00:12:39,149
affected by poisoning very much<font color="#E5E5E5"> and you</font>

312
00:12:36,970 --> 00:12:41,980
actually<font color="#E5E5E5"> see this from our defense trim</font>

313
00:12:39,149 --> 00:12:45,129
other methods<font color="#E5E5E5"> some of them do fairly</font>

314
00:12:41,980 --> 00:12:49,839
<font color="#CCCCCC">well but they're</font><font color="#E5E5E5"> all somewhere in</font>

315
00:12:45,129 --> 00:12:52,319
between<font color="#E5E5E5"> no defense and and this like our</font>

316
00:12:49,839 --> 00:12:54,670
defense<font color="#E5E5E5"> so and in fact</font><font color="#CCCCCC"> overall the</font>

317
00:12:52,319 --> 00:12:56,319
experiments we ran we saw<font color="#E5E5E5"> that trim was</font>

318
00:12:54,670 --> 00:13:00,849
within like<font color="#E5E5E5"> 1% of the</font>

319
00:12:56,320 --> 00:13:02,950
original models<font color="#E5E5E5"> MSE</font><font color="#CCCCCC"> all</font><font color="#E5E5E5"> right so I've</font>

320
00:13:00,850 --> 00:13:04,600
talked to you about<font color="#E5E5E5"> poisoning</font><font color="#CCCCCC"> attacks on</font>

321
00:13:02,950 --> 00:13:06,700
<font color="#E5E5E5">regression models</font><font color="#CCCCCC"> were the first to</font>

322
00:13:04,600 --> 00:13:09,700
consider<font color="#E5E5E5"> regression tasks in the</font>

323
00:13:06,700 --> 00:13:11,920
poisoning literature<font color="#E5E5E5"> and then we we have</font>

324
00:13:09,700 --> 00:13:13,810
two attacks<font color="#E5E5E5"> a white box attack based on</font>

325
00:13:11,920 --> 00:13:15,880
gradient<font color="#E5E5E5"> descent that we call opt</font><font color="#CCCCCC"> peak</font>

326
00:13:13,810 --> 00:13:19,209
and a black box attack that we call stat

327
00:13:15,880 --> 00:13:21,730
<font color="#CCCCCC">P based on statistics basically op P is</font>

328
00:13:19,210 --> 00:13:23,470
slower and it takes on the order<font color="#CCCCCC"> of you</font>

329
00:13:21,730 --> 00:13:26,620
know minutes and then stat<font color="#E5E5E5"> P is faster</font>

330
00:13:23,470 --> 00:13:29,200
it takes seconds<font color="#E5E5E5"> or even less than</font><font color="#CCCCCC"> that</font>

331
00:13:26,620 --> 00:13:31,510
and we also made a defense called a trim

332
00:13:29,200 --> 00:13:34,150
that's able<font color="#CCCCCC"> to mitigate our attacks and</font>

333
00:13:31,510 --> 00:13:35,680
it runs<font color="#E5E5E5"> also very quickly and you can</font>

334
00:13:34,150 --> 00:13:38,620
<font color="#CCCCCC">check out our</font><font color="#E5E5E5"> paper for more</font><font color="#CCCCCC"> results</font><font color="#E5E5E5"> and</font>

335
00:13:35,680 --> 00:13:40,930
<font color="#E5E5E5">some theoretical analysis</font><font color="#CCCCCC"> and you can</font>

336
00:13:38,620 --> 00:13:42,640
you can<font color="#CCCCCC"> see our code online at this link</font>

337
00:13:40,930 --> 00:13:56,380
here<font color="#E5E5E5"> thank you</font><font color="#CCCCCC"> very</font><font color="#E5E5E5"> much I'm happy to</font>

338
00:13:42,640 --> 00:13:57,210
take questions we have time<font color="#CCCCCC"> for a few</font>

339
00:13:56,380 --> 00:14:00,310
questions

340
00:13:57,210 --> 00:14:01,990
<font color="#CCCCCC">so first of all I'd like</font><font color="#E5E5E5"> to start with</font>

341
00:14:00,310 --> 00:14:05,859
with one<font color="#E5E5E5"> question this is this is very</font>

342
00:14:01,990 --> 00:14:09,070
<font color="#CCCCCC">interesting to me</font><font color="#E5E5E5"> at least</font><font color="#CCCCCC"> I so I'm</font>

343
00:14:05,860 --> 00:14:11,170
<font color="#E5E5E5">curious you work on indiscriminate</font>

344
00:14:09,070 --> 00:14:14,410
poisoning right so but<font color="#E5E5E5"> it's also you</font>

345
00:14:11,170 --> 00:14:17,800
know possible sort of attacker goal

346
00:14:14,410 --> 00:14:21,189
which is to<font color="#E5E5E5"> do targeted poisoning so the</font>

347
00:14:17,800 --> 00:14:23,829
goal is not to destroy<font color="#E5E5E5"> the classifier</font>

348
00:14:21,190 --> 00:14:25,330
accuracy but you know to affect<font color="#CCCCCC"> the</font>

349
00:14:23,830 --> 00:14:28,330
<font color="#E5E5E5">specific target right so I was curious</font>

350
00:14:25,330 --> 00:14:30,790
<font color="#E5E5E5">what do you think in the context of</font>

351
00:14:28,330 --> 00:14:33,490
these targeted poisoning attacks<font color="#E5E5E5"> would</font>

352
00:14:30,790 --> 00:14:36,760
<font color="#E5E5E5">your defense based on minimizing</font>

353
00:14:33,490 --> 00:14:38,530
residual or finding the<font color="#CCCCCC"> you know looking</font>

354
00:14:36,760 --> 00:14:40,990
at<font color="#E5E5E5"> the residual loss would that be a</font>

355
00:14:38,530 --> 00:14:44,560
good direction<font color="#CCCCCC"> to look for a defense</font>

356
00:14:40,990 --> 00:14:46,480
<font color="#E5E5E5">against target poisoning attacks</font><font color="#CCCCCC"> I don't</font>

357
00:14:44,560 --> 00:14:48,069
<font color="#CCCCCC">think so because these are typically</font>

358
00:14:46,480 --> 00:14:49,510
like you had a small<font color="#CCCCCC"> number of points</font>

359
00:14:48,070 --> 00:14:52,450
<font color="#CCCCCC">and</font><font color="#E5E5E5"> it's supposed to modify a small</font>

360
00:14:49,510 --> 00:14:54,510
number<font color="#E5E5E5"> of predictions</font><font color="#CCCCCC"> I think this is</font>

361
00:14:52,450 --> 00:14:57,660
<font color="#CCCCCC">really more more for like a</font>

362
00:14:54,510 --> 00:14:57,660
<font color="#E5E5E5">indiscriminate case</font>

363
00:14:58,840 --> 00:15:03,410
thanks for the talk<font color="#CCCCCC"> I'm curious</font><font color="#E5E5E5"> if your</font>

364
00:15:01,310 --> 00:15:05,150
attacks allow you to specify<font color="#E5E5E5"> that you</font>

365
00:15:03,410 --> 00:15:06,800
<font color="#CCCCCC">want to find</font><font color="#E5E5E5"> a lot of poison points</font>

366
00:15:05,150 --> 00:15:08,600
<font color="#CCCCCC">they're</font><font color="#E5E5E5"> really close to this is boundary</font>

367
00:15:06,800 --> 00:15:10,069
and if so how<font color="#CCCCCC"> that would sort</font><font color="#E5E5E5"> of</font>

368
00:15:08,600 --> 00:15:13,190
influence your defense or do you have

369
00:15:10,070 --> 00:15:14,360
other defensive ideas yeah<font color="#E5E5E5"> so something</font>

370
00:15:13,190 --> 00:15:17,210
nice about like a gradient<font color="#E5E5E5"> based</font>

371
00:15:14,360 --> 00:15:20,510
optimization attack<font color="#E5E5E5"> is that</font><font color="#CCCCCC"> you can also</font>

372
00:15:17,210 --> 00:15:22,250
add like constraints into<font color="#CCCCCC"> the end</font><font color="#E5E5E5"> to</font>

373
00:15:20,510 --> 00:15:24,340
like the optimization or your

374
00:15:22,250 --> 00:15:26,780
optimization<font color="#CCCCCC"> function that you're using</font>

375
00:15:24,340 --> 00:15:28,760
<font color="#CCCCCC">so yeah you could you could definitely</font>

376
00:15:26,780 --> 00:15:29,990
you know<font color="#E5E5E5"> also do like projection or</font>

377
00:15:28,760 --> 00:15:31,340
stuff to<font color="#E5E5E5"> make</font><font color="#CCCCCC"> it so</font><font color="#E5E5E5"> you're poisoning</font>

378
00:15:29,990 --> 00:15:37,460
points aren't<font color="#E5E5E5"> aren't as far away from</font>

379
00:15:31,340 --> 00:15:41,060
the decision boundary Chicago<font color="#E5E5E5"> very nice</font>

380
00:15:37,460 --> 00:15:43,190
<font color="#E5E5E5">talk so I'm wondering like seems like</font>

381
00:15:41,060 --> 00:15:46,310
you the purpose<font color="#CCCCCC"> of defense is to lower</font>

382
00:15:43,190 --> 00:15:48,560
<font color="#CCCCCC">the attacks</font><font color="#E5E5E5"> success rate</font><font color="#CCCCCC"> or</font><font color="#E5E5E5"> like the</font>

383
00:15:46,310 --> 00:15:50,750
<font color="#E5E5E5">performance so I'm wondering like can</font>

384
00:15:48,560 --> 00:15:52,219
you<font color="#E5E5E5"> like actually detects the points in</font>

385
00:15:50,750 --> 00:15:56,390
<font color="#CCCCCC">the attack before you actually apply</font>

386
00:15:52,220 --> 00:15:58,220
your master ology given giving a model

387
00:15:56,390 --> 00:16:00,439
or potentially some<font color="#E5E5E5"> data so I</font><font color="#CCCCCC"> can</font>

388
00:15:58,220 --> 00:16:04,790
actually<font color="#E5E5E5"> tell if the model is points no</font>

389
00:16:00,440 --> 00:16:07,640
not so I guess in theory you could run

390
00:16:04,790 --> 00:16:09,319
like with several different<font color="#E5E5E5"> so like</font>

391
00:16:07,640 --> 00:16:11,090
<font color="#CCCCCC">basically</font><font color="#E5E5E5"> you specify how many poison</font>

392
00:16:09,320 --> 00:16:12,320
points you think there are you<font color="#CCCCCC"> could</font><font color="#E5E5E5"> we</font>

393
00:16:11,090 --> 00:16:14,360
could<font color="#CCCCCC"> run with several different values</font>

394
00:16:12,320 --> 00:16:18,020
and see how well it does<font color="#E5E5E5"> it</font><font color="#CCCCCC"> at all</font><font color="#E5E5E5"> those</font>

395
00:16:14,360 --> 00:16:19,760
values<font color="#E5E5E5"> and</font><font color="#CCCCCC"> and you know see</font><font color="#E5E5E5"> where like</font>

396
00:16:18,020 --> 00:16:21,800
if it works at a low value maybe it's

397
00:16:19,760 --> 00:16:29,540
not poisoned very much and<font color="#E5E5E5"> so you can</font>

398
00:16:21,800 --> 00:16:31,729
see that okay yeah<font color="#CCCCCC"> could you I was</font>

399
00:16:29,540 --> 00:16:34,069
curious about<font color="#CCCCCC"> the transferability</font><font color="#E5E5E5"> result</font>

400
00:16:31,730 --> 00:16:35,540
<font color="#E5E5E5">so you</font><font color="#CCCCCC"> went</font><font color="#E5E5E5"> very quickly over them you</font>

401
00:16:34,070 --> 00:16:37,940
know because timing<font color="#CCCCCC"> restraints</font><font color="#E5E5E5"> can you</font>

402
00:16:35,540 --> 00:16:41,300
say a<font color="#E5E5E5"> little bit more about because yeah</font>

403
00:16:37,940 --> 00:16:45,350
yeah so basically<font color="#E5E5E5"> the experiment was you</font>

404
00:16:41,300 --> 00:16:47,359
know we have we run our attack with full

405
00:16:45,350 --> 00:16:49,070
knowledge<font color="#E5E5E5"> of the training set basically</font>

406
00:16:47,360 --> 00:16:50,420
like I you<font color="#CCCCCC"> know I split up the data set</font>

407
00:16:49,070 --> 00:16:52,070
<font color="#E5E5E5">into a bunch of different pieces and I</font>

408
00:16:50,420 --> 00:16:53,630
ran<font color="#E5E5E5"> the attack on this one I took these</font>

409
00:16:52,070 --> 00:16:56,720
poisoning points and I moved them over

410
00:16:53,630 --> 00:16:58,580
<font color="#E5E5E5">to</font><font color="#CCCCCC"> another one and kind of what we saw</font>

411
00:16:56,720 --> 00:17:00,260
was in some cases like this was<font color="#CCCCCC"> actually</font>

412
00:16:58,580 --> 00:17:02,510
even doing better and so maybe it's<font color="#CCCCCC"> like</font>

413
00:17:00,260 --> 00:17:03,500
sort<font color="#E5E5E5"> of overfitting to the</font><font color="#CCCCCC"> ridge right I</font>

414
00:17:02,510 --> 00:17:05,150
was wondering if you have any

415
00:17:03,500 --> 00:17:07,490
<font color="#E5E5E5">conclusions about you know what's likely</font>

416
00:17:05,150 --> 00:17:11,120
<font color="#E5E5E5">to transfer like what types of models or</font>

417
00:17:07,490 --> 00:17:12,240
what types of I mean<font color="#E5E5E5"> so we like tested</font>

418
00:17:11,119 --> 00:17:13,708
against regression I think

419
00:17:12,240 --> 00:17:15,270
aggression<font color="#E5E5E5"> it's like pretty</font><font color="#CCCCCC"> likely that</font>

420
00:17:13,709 --> 00:17:19,890
it's<font color="#E5E5E5"> going to be transferring pretty</font>

421
00:17:15,270 --> 00:17:21,420
<font color="#E5E5E5">well yeah all</font><font color="#CCCCCC"> right cool let's thanks</font>

422
00:17:19,890 --> 00:17:24,900
the speaker

423
00:17:21,420 --> 00:17:24,900
[Applause]

