1
00:00:11,000 --> 00:00:14,030
<font color="#CCCCCC">I'm Reilly spawn from Columbia</font>

2
00:00:12,380 --> 00:00:16,700
University<font color="#CCCCCC"> and today I'll be talking</font>

3
00:00:14,030 --> 00:00:18,919
about pyramid and pyramid is our system

4
00:00:16,700 --> 00:00:20,869
<font color="#E5E5E5">for enhancing selectivity and big data</font>

5
00:00:18,920 --> 00:00:22,880
protection<font color="#CCCCCC"> and</font><font color="#E5E5E5"> this</font><font color="#CCCCCC"> is a broad vision</font>

6
00:00:20,869 --> 00:00:25,910
<font color="#E5E5E5">about being selective and how you use</font>

7
00:00:22,880 --> 00:00:32,439
data and with<font color="#E5E5E5"> the purpose of trying to</font>

8
00:00:25,910 --> 00:00:34,640
<font color="#E5E5E5">reduce that data exposure so so</font>

9
00:00:32,439 --> 00:00:37,070
companies<font color="#CCCCCC"> have a collect everything</font>

10
00:00:34,640 --> 00:00:38,930
mentality they view data<font color="#CCCCCC"> as having</font>

11
00:00:37,070 --> 00:00:40,570
limitless value and as a result they

12
00:00:38,930 --> 00:00:44,360
will collect as much data<font color="#CCCCCC"> as possible</font>

13
00:00:40,570 --> 00:00:46,670
<font color="#E5E5E5">this mentality raises substantial risks</font>

14
00:00:44,360 --> 00:00:52,040
both<font color="#E5E5E5"> in the uses of</font><font color="#CCCCCC"> that</font><font color="#E5E5E5"> data and in how</font>

15
00:00:46,670 --> 00:00:53,780
<font color="#CCCCCC">that data is</font><font color="#E5E5E5"> managed</font><font color="#CCCCCC"> so i'll</font><font color="#E5E5E5"> and so</font>

16
00:00:52,040 --> 00:00:56,059
<font color="#E5E5E5">compounding this collect everything</font>

17
00:00:53,780 --> 00:00:59,329
mentality is the troubling practice of

18
00:00:56,059 --> 00:01:01,968
data<font color="#E5E5E5"> lakes where a company pools all of</font>

19
00:00:59,329 --> 00:01:04,729
the data<font color="#CCCCCC"> that it collects</font><font color="#E5E5E5"> across many</font>

20
00:01:01,969 --> 00:01:06,560
services into one<font color="#CCCCCC"> big data repository</font>

21
00:01:04,729 --> 00:01:08,479
<font color="#E5E5E5">and gives the what and gives wide access</font>

22
00:01:06,560 --> 00:01:11,479
<font color="#CCCCCC">to</font><font color="#E5E5E5"> that repository within a company so</font>

23
00:01:08,479 --> 00:01:13,340
<font color="#E5E5E5">let's take a simple</font><font color="#CCCCCC"> example</font><font color="#E5E5E5"> so let's</font>

24
00:01:11,479 --> 00:01:14,899
take a simple<font color="#E5E5E5"> example that we're calling</font>

25
00:01:13,340 --> 00:01:16,970
media<font color="#CCCCCC"> co this</font><font color="#E5E5E5"> is a media conglomerate</font>

26
00:01:14,899 --> 00:01:19,310
that owns hundreds of websites<font color="#E5E5E5"> across</font>

27
00:01:16,970 --> 00:01:21,200
different verticals so and each of those

28
00:01:19,310 --> 00:01:24,229
<font color="#E5E5E5">websites collects a stream of user</font>

29
00:01:21,200 --> 00:01:26,119
activity<font color="#E5E5E5"> that user on each site and then</font>

30
00:01:24,229 --> 00:01:28,400
the data from<font color="#E5E5E5"> all of</font><font color="#CCCCCC"> those sites is</font>

31
00:01:26,119 --> 00:01:31,009
integrated and<font color="#E5E5E5"> pooled together into one</font>

32
00:01:28,400 --> 00:01:33,619
<font color="#E5E5E5">common data Lake and then teams</font><font color="#CCCCCC"> across</font>

33
00:01:31,009 --> 00:01:36,409
that across the organization will all

34
00:01:33,619 --> 00:01:38,090
get access<font color="#CCCCCC"> to that data lakes to perform</font>

35
00:01:36,409 --> 00:01:40,970
different activities<font color="#E5E5E5"> like article</font>

36
00:01:38,090 --> 00:01:43,310
recommendation ad targeting etc so this

37
00:01:40,970 --> 00:01:46,220
type of<font color="#CCCCCC"> acts of</font><font color="#E5E5E5"> infrastructure is common</font>

38
00:01:43,310 --> 00:01:48,229
<font color="#E5E5E5">Microsoft Azure has a data like product</font>

39
00:01:46,220 --> 00:01:49,759
that's<font color="#E5E5E5"> ready to deploy and</font><font color="#CCCCCC"> Amazon</font><font color="#E5E5E5"> has</font>

40
00:01:48,229 --> 00:01:52,220
documentation<font color="#E5E5E5"> on</font><font color="#CCCCCC"> how</font><font color="#E5E5E5"> to build a data</font>

41
00:01:49,759 --> 00:01:53,930
<font color="#E5E5E5">Lake using their existing</font><font color="#CCCCCC"> offerings</font><font color="#E5E5E5"> the</font>

42
00:01:52,220 --> 00:01:55,939
problem with this<font color="#E5E5E5"> type of wide access</font>

43
00:01:53,930 --> 00:01:59,210
infrastructure<font color="#E5E5E5"> is that it raises</font>

44
00:01:55,939 --> 00:02:01,189
substantial risks so the problem<font color="#E5E5E5"> is that</font>

45
00:01:59,210 --> 00:02:04,280
it's<font color="#E5E5E5"> not a mean able to isolation</font>

46
00:02:01,189 --> 00:02:06,289
<font color="#E5E5E5">control or auditing if a single team is</font>

47
00:02:04,280 --> 00:02:08,810
compromised in the organization then

48
00:02:06,290 --> 00:02:11,090
<font color="#E5E5E5">that will compromises this entire lake</font>

49
00:02:08,810 --> 00:02:12,860
of data the<font color="#CCCCCC"> data that</font><font color="#E5E5E5"> the organization's</font>

50
00:02:11,090 --> 00:02:14,780
value so much<font color="#E5E5E5"> and the fashion in which</font>

51
00:02:12,860 --> 00:02:17,600
<font color="#E5E5E5">that data</font><font color="#CCCCCC"> is managed makes it very</font>

52
00:02:14,780 --> 00:02:20,599
<font color="#E5E5E5">valuable to attackers so in our research</font>

53
00:02:17,600 --> 00:02:23,000
<font color="#E5E5E5">there so in our research we're asking a</font>

54
00:02:20,599 --> 00:02:24,049
question<font color="#CCCCCC"> and that question is can</font>

55
00:02:23,000 --> 00:02:25,910
companies be

56
00:02:24,050 --> 00:02:28,040
more selective<font color="#E5E5E5"> about what data is</font>

57
00:02:25,910 --> 00:02:32,810
collected and how they give<font color="#CCCCCC"> access</font><font color="#E5E5E5"> to</font>

58
00:02:28,040 --> 00:02:34,820
that data so we hypothesized<font color="#CCCCCC"> that not</font>

59
00:02:32,810 --> 00:02:37,850
all<font color="#E5E5E5"> deaths not all of the data that's</font>

60
00:02:34,820 --> 00:02:39,500
collected is needed or<font color="#CCCCCC"> even used if one</font>

61
00:02:37,850 --> 00:02:41,269
can distinguish between data<font color="#E5E5E5"> that is</font>

62
00:02:39,500 --> 00:02:43,850
needed<font color="#CCCCCC"> now or will be needed</font><font color="#E5E5E5"> in</font><font color="#CCCCCC"> the</font>

63
00:02:41,270 --> 00:02:46,340
<font color="#E5E5E5">future from the data that is collected</font>

64
00:02:43,850 --> 00:02:47,930
just<font color="#E5E5E5"> in case then one can protect the</font>

65
00:02:46,340 --> 00:02:50,270
<font color="#E5E5E5">latter data in a much stronger fashion</font>

66
00:02:47,930 --> 00:02:54,200
<font color="#E5E5E5">like story and offline and auditing all</font>

67
00:02:50,270 --> 00:02:55,550
of the accesses<font color="#CCCCCC"> to it so in our work we</font>

68
00:02:54,200 --> 00:02:57,920
are<font color="#E5E5E5"> building what we're calling</font>

69
00:02:55,550 --> 00:02:59,660
selective<font color="#E5E5E5"> data systems in these systems</font>

70
00:02:57,920 --> 00:03:02,809
<font color="#CCCCCC">will by design differentiate between</font>

71
00:02:59,660 --> 00:03:04,910
data that's needed<font color="#E5E5E5"> that is needed which</font>

72
00:03:02,810 --> 00:03:08,020
is<font color="#E5E5E5"> used and widely accessible the top of</font>

73
00:03:04,910 --> 00:03:10,880
the pyramid from the data that<font color="#CCCCCC"> is</font>

74
00:03:08,020 --> 00:03:15,350
unneeded and unused<font color="#CCCCCC"> and will be</font><font color="#E5E5E5"> tightly</font>

75
00:03:10,880 --> 00:03:17,900
protected<font color="#E5E5E5"> the larger</font><font color="#CCCCCC"> basis pyramid</font><font color="#E5E5E5"> so we</font>

76
00:03:15,350 --> 00:03:21,079
define selective data systems by three

77
00:03:17,900 --> 00:03:25,190
goals so the first goal is that we must

78
00:03:21,080 --> 00:03:27,800
minimize<font color="#E5E5E5"> the</font><font color="#CCCCCC"> use the exposure of the in</font>

79
00:03:25,190 --> 00:03:30,800
use data<font color="#E5E5E5"> in size</font><font color="#CCCCCC"> timespan and</font>

80
00:03:27,800 --> 00:03:33,230
<font color="#E5E5E5">sensitivity second is</font><font color="#CCCCCC"> that we must avoid</font>

81
00:03:30,800 --> 00:03:35,540
accessing unused data<font color="#E5E5E5"> for current and</font>

82
00:03:33,230 --> 00:03:37,850
evolving workloads<font color="#E5E5E5"> and third we must</font>

83
00:03:35,540 --> 00:03:40,429
must accomplish these two goals<font color="#E5E5E5"> without</font>

84
00:03:37,850 --> 00:03:42,739
<font color="#E5E5E5">impacting accuracy performance</font><font color="#CCCCCC"> or other</font>

85
00:03:40,430 --> 00:03:46,640
functional requirements of these system

86
00:03:42,739 --> 00:03:48,739
so in this work we<font color="#E5E5E5"> specifically we</font>

87
00:03:46,640 --> 00:03:50,720
specifically investigate<font color="#E5E5E5"> how do you</font>

88
00:03:48,739 --> 00:03:54,440
achieve machine learn or selectivity<font color="#CCCCCC"> and</font>

89
00:03:50,720 --> 00:03:57,260
machine learning<font color="#E5E5E5"> so in traditional</font>

90
00:03:54,440 --> 00:03:59,750
<font color="#CCCCCC">systems</font><font color="#E5E5E5"> the approach to finding</font>

91
00:03:57,260 --> 00:04:02,120
determining what data is in use is to

92
00:03:59,750 --> 00:04:04,580
look at the working<font color="#E5E5E5"> set the working set</font>

93
00:04:02,120 --> 00:04:06,350
and access patterns these approaches

94
00:04:04,580 --> 00:04:08,780
<font color="#E5E5E5">assume that the</font><font color="#CCCCCC"> working sets will be</font>

95
00:04:06,350 --> 00:04:10,910
<font color="#E5E5E5">relatively small</font><font color="#CCCCCC"> and stable over</font><font color="#E5E5E5"> time</font>

96
00:04:08,780 --> 00:04:12,380
however machine learning workloads have

97
00:04:10,910 --> 00:04:14,060
different<font color="#E5E5E5"> characteristics like when</font>

98
00:04:12,380 --> 00:04:15,829
retraining a model you<font color="#E5E5E5"> will likely touch</font>

99
00:04:14,060 --> 00:04:18,140
<font color="#E5E5E5">a large amount of data a small number of</font>

100
00:04:15,830 --> 00:04:19,520
times<font color="#E5E5E5"> and in these cases the access</font>

101
00:04:18,140 --> 00:04:21,649
patterns will give you<font color="#E5E5E5"> very little</font>

102
00:04:19,519 --> 00:04:25,580
<font color="#E5E5E5">insight</font><font color="#CCCCCC"> into what data is most important</font>

103
00:04:21,649 --> 00:04:27,020
<font color="#E5E5E5">so</font><font color="#CCCCCC"> what we're trying to</font><font color="#E5E5E5"> do is to look at</font>

104
00:04:25,580 --> 00:04:29,900
<font color="#E5E5E5">training set minimization techniques</font>

105
00:04:27,020 --> 00:04:31,909
these techniques attempt to find subsets

106
00:04:29,900 --> 00:04:34,400
<font color="#E5E5E5">of training data that</font><font color="#CCCCCC"> are most useful</font><font color="#E5E5E5"> to</font>

107
00:04:31,910 --> 00:04:37,550
a learning<font color="#E5E5E5"> task or to transform that</font>

108
00:04:34,400 --> 00:04:40,340
data<font color="#E5E5E5"> into a form that is allow</font>

109
00:04:37,550 --> 00:04:42,410
for more efficient learning<font color="#E5E5E5"> so in our</font>

110
00:04:40,340 --> 00:04:43,969
specific system we investigate count

111
00:04:42,410 --> 00:04:46,550
feature ization<font color="#CCCCCC"> which is a particular</font>

112
00:04:43,970 --> 00:04:48,560
<font color="#CCCCCC">type of training set minimization and</font>

113
00:04:46,550 --> 00:04:51,890
attempt<font color="#CCCCCC"> to retrofit</font><font color="#E5E5E5"> it for protection in</font>

114
00:04:48,560 --> 00:04:55,220
our system pyramid so pyramid is<font color="#E5E5E5"> the</font>

115
00:04:51,890 --> 00:04:56,390
first<font color="#E5E5E5"> selective data system it retrofits</font>

116
00:04:55,220 --> 00:04:58,250
that<font color="#E5E5E5"> particular training set</font>

117
00:04:56,390 --> 00:05:00,740
minimization technique for protection in

118
00:04:58,250 --> 00:05:03,590
the ways that it<font color="#E5E5E5"> generally works is that</font>

119
00:05:00,740 --> 00:05:06,770
<font color="#E5E5E5">we keep on hand</font><font color="#CCCCCC"> a</font><font color="#E5E5E5"> small amount of recent</font>

120
00:05:03,590 --> 00:05:08,539
raw data and then we<font color="#E5E5E5"> summarize</font><font color="#CCCCCC"> the past</font>

121
00:05:06,770 --> 00:05:11,000
using differentially private count

122
00:05:08,540 --> 00:05:12,920
tables and then when we go to<font color="#CCCCCC"> Train</font>

123
00:05:11,000 --> 00:05:15,230
machine learning models we will<font color="#E5E5E5"> combine</font>

124
00:05:12,920 --> 00:05:18,140
the<font color="#CCCCCC"> raw data</font><font color="#E5E5E5"> with data from the</font><font color="#CCCCCC"> account</font>

125
00:05:15,230 --> 00:05:19,910
from<font color="#E5E5E5"> the count tables and use that and</font>

126
00:05:18,140 --> 00:05:22,159
then feed that<font color="#E5E5E5"> into the models for</font>

127
00:05:19,910 --> 00:05:24,170
training and in<font color="#CCCCCC"> doing this</font><font color="#E5E5E5"> we can reduce</font>

128
00:05:22,160 --> 00:05:27,980
exposure by two orders of magnitude with

129
00:05:24,170 --> 00:05:29,450
moderate<font color="#E5E5E5"> performance</font><font color="#CCCCCC"> degradation so now</font>

130
00:05:27,980 --> 00:05:31,730
that<font color="#E5E5E5"> I've introduced pyramid and</font><font color="#CCCCCC"> it's</font>

131
00:05:29,450 --> 00:05:33,590
basic approach I'm going to explain the

132
00:05:31,730 --> 00:05:35,300
pyramid design for<font color="#CCCCCC"> retrofitting count</font>

133
00:05:33,590 --> 00:05:36,619
feature ization for protection and then

134
00:05:35,300 --> 00:05:38,030
I'll walk<font color="#CCCCCC"> through some evaluations</font>

135
00:05:36,620 --> 00:05:40,310
showing that it<font color="#CCCCCC"> can realistically</font>

136
00:05:38,030 --> 00:05:43,940
leverage count feature ization<font color="#E5E5E5"> for data</font>

137
00:05:40,310 --> 00:05:45,200
minimization<font color="#E5E5E5"> and selectivity so pyramids</font>

138
00:05:43,940 --> 00:05:47,120
architecture looks something like this

139
00:05:45,200 --> 00:05:49,190
<font color="#E5E5E5">it</font><font color="#CCCCCC"> acts as an intermediary</font><font color="#E5E5E5"> between</font>

140
00:05:47,120 --> 00:05:50,780
machine learning models and all of the

141
00:05:49,190 --> 00:05:53,150
data<font color="#CCCCCC"> that they use for training</font><font color="#E5E5E5"> and</font>

142
00:05:50,780 --> 00:05:54,710
<font color="#E5E5E5">Retraining it will leverage it leverages</font>

143
00:05:53,150 --> 00:05:58,219
<font color="#E5E5E5">count feature ization and differential</font>

144
00:05:54,710 --> 00:06:00,320
privacy<font color="#CCCCCC"> it keeps count tables</font><font color="#E5E5E5"> of history</font>

145
00:05:58,220 --> 00:06:02,900
that<font color="#E5E5E5"> are which are in the form of like a</font>

146
00:06:00,320 --> 00:06:05,210
contingency<font color="#E5E5E5"> table</font><font color="#CCCCCC"> and then a</font><font color="#E5E5E5"> small</font>

147
00:06:02,900 --> 00:06:07,989
amount<font color="#CCCCCC"> of recent raw data and then we'd</font>

148
00:06:05,210 --> 00:06:10,039
expect that the majority<font color="#CCCCCC"> of the</font>

149
00:06:07,990 --> 00:06:11,570
company's data would be<font color="#CCCCCC"> stored offline</font>

150
00:06:10,040 --> 00:06:14,750
in some kind<font color="#CCCCCC"> of a cold data store that's</font>

151
00:06:11,570 --> 00:06:17,719
<font color="#CCCCCC">rarely accessed the pyramid operates on</font>

152
00:06:14,750 --> 00:06:19,370
streams of observations so when an

153
00:06:17,720 --> 00:06:22,280
observation eobseo arrives

154
00:06:19,370 --> 00:06:24,190
<font color="#E5E5E5">this would be a observation that</font>

155
00:06:22,280 --> 00:06:26,239
consists<font color="#E5E5E5"> of a feature vector and a label</font>

156
00:06:24,190 --> 00:06:28,040
<font color="#E5E5E5">pyramid needs to keep the count tables</font>

157
00:06:26,240 --> 00:06:30,080
<font color="#CCCCCC">up-to-date with recent raw data</font><font color="#E5E5E5"> so it</font>

158
00:06:28,040 --> 00:06:33,710
uses<font color="#CCCCCC"> the two up so the count tables are</font>

159
00:06:30,080 --> 00:06:36,080
updated<font color="#E5E5E5"> we</font><font color="#CCCCCC"> writes the observation into</font>

160
00:06:33,710 --> 00:06:39,140
the recent<font color="#E5E5E5"> raw data store or the recent</font>

161
00:06:36,080 --> 00:06:42,770
<font color="#E5E5E5">raw data and then update the cold raw</font>

162
00:06:39,140 --> 00:06:45,950
data store so how do we<font color="#E5E5E5"> use these count</font>

163
00:06:42,770 --> 00:06:47,659
tables for feature ization so<font color="#CCCCCC"> I walk</font>

164
00:06:45,950 --> 00:06:49,610
<font color="#E5E5E5">through this with an</font><font color="#CCCCCC"> example in this</font>

165
00:06:47,660 --> 00:06:50,910
<font color="#E5E5E5">example we want to build a binary</font>

166
00:06:49,610 --> 00:06:53,580
classifier that

167
00:06:50,910 --> 00:06:56,520
if a user will<font color="#CCCCCC"> click on an ad based on</font>

168
00:06:53,580 --> 00:06:59,219
<font color="#E5E5E5">three three features the ad ID the user</font>

169
00:06:56,520 --> 00:07:01,099
ID and<font color="#E5E5E5"> the page ID and we keep a count</font>

170
00:06:59,220 --> 00:07:03,660
<font color="#CCCCCC">table for each of these features the</font>

171
00:07:01,100 --> 00:07:06,240
<font color="#CCCCCC">count tables have one column for each</font>

172
00:07:03,660 --> 00:07:09,120
<font color="#E5E5E5">label and one row for</font><font color="#CCCCCC"> each of the</font>

173
00:07:06,240 --> 00:07:10,440
feature values<font color="#E5E5E5"> and in this case</font><font color="#CCCCCC"> the</font>

174
00:07:09,120 --> 00:07:11,610
feature all<font color="#CCCCCC"> of</font><font color="#E5E5E5"> the count tables are</font>

175
00:07:10,440 --> 00:07:14,030
initialized to<font color="#CCCCCC"> zero because they have</font>

176
00:07:11,610 --> 00:07:17,250
not<font color="#E5E5E5"> been populated with any data so as</font>

177
00:07:14,030 --> 00:07:19,289
observations<font color="#E5E5E5"> arrive we increment the</font>

178
00:07:17,250 --> 00:07:22,050
appropriate cells and do this<font color="#E5E5E5"> for</font><font color="#CCCCCC"> each</font>

179
00:07:19,290 --> 00:07:24,300
<font color="#E5E5E5">observation that arrives until</font><font color="#CCCCCC"> we have</font>

180
00:07:22,050 --> 00:07:27,450
populated account tables with data for

181
00:07:24,300 --> 00:07:29,580
thousands<font color="#E5E5E5"> of observations</font><font color="#CCCCCC"> and then when</font>

182
00:07:27,450 --> 00:07:31,530
we look to<font color="#E5E5E5"> when we need</font><font color="#CCCCCC"> to feature as an</font>

183
00:07:29,580 --> 00:07:33,900
observation<font color="#E5E5E5"> we take the observation</font>

184
00:07:31,530 --> 00:07:36,599
calculate the conditional<font color="#E5E5E5"> probability of</font>

185
00:07:33,900 --> 00:07:39,060
a click<font color="#E5E5E5"> given each</font><font color="#CCCCCC"> of the features and</font>

186
00:07:36,600 --> 00:07:41,520
then replace those features with the

187
00:07:39,060 --> 00:07:44,100
conditional probabilities and<font color="#CCCCCC"> we use</font>

188
00:07:41,520 --> 00:07:46,080
that<font color="#E5E5E5"> directly as a feature vector to be</font>

189
00:07:44,100 --> 00:07:48,060
fed<font color="#CCCCCC"> into the machine learning</font><font color="#E5E5E5"> model so</font>

190
00:07:46,080 --> 00:07:49,950
many<font color="#E5E5E5"> features like the IDS shown here</font>

191
00:07:48,060 --> 00:07:52,170
have cardinalities that can reach into

192
00:07:49,950 --> 00:07:53,870
<font color="#E5E5E5">the millions so</font><font color="#CCCCCC"> counter utilization will</font>

193
00:07:52,170 --> 00:07:56,490
can permit<font color="#E5E5E5"> more efficient learning</font>

194
00:07:53,870 --> 00:07:58,320
<font color="#E5E5E5">allowing us to drastic use drastically</font>

195
00:07:56,490 --> 00:08:00,900
smaller training<font color="#E5E5E5"> sets and thereby</font>

196
00:07:58,320 --> 00:08:03,060
reducing the<font color="#E5E5E5"> exposure of the data so we</font>

197
00:08:00,900 --> 00:08:05,340
need to<font color="#CCCCCC"> use count feature ization</font><font color="#E5E5E5"> to</font>

198
00:08:03,060 --> 00:08:07,890
feature eyes data when retraining models

199
00:08:05,340 --> 00:08:10,500
and when serving prediction requests so

200
00:08:07,890 --> 00:08:11,760
a prediction<font color="#E5E5E5"> request will arrive at one</font>

201
00:08:10,500 --> 00:08:14,520
of the models<font color="#E5E5E5"> and that prediction</font>

202
00:08:11,760 --> 00:08:17,190
<font color="#CCCCCC">request</font><font color="#E5E5E5"> will consist of a raw feature</font>

203
00:08:14,520 --> 00:08:19,890
vector that feature vector will<font color="#CCCCCC"> be</font>

204
00:08:17,190 --> 00:08:23,130
passed from the model or model server<font color="#CCCCCC"> in</font>

205
00:08:19,890 --> 00:08:25,620
<font color="#CCCCCC">to pyramid pyramid we'll combine the use</font>

206
00:08:23,130 --> 00:08:28,980
<font color="#E5E5E5">the count tables to count feature eyes</font>

207
00:08:25,620 --> 00:08:31,260
that feature vector and then that and

208
00:08:28,980 --> 00:08:33,990
then that<font color="#E5E5E5"> feature vector is passed back</font>

209
00:08:31,260 --> 00:08:36,360
up to the<font color="#E5E5E5"> model to execute the</font>

210
00:08:33,990 --> 00:08:38,880
prediction<font color="#E5E5E5"> so the protections that</font>

211
00:08:36,360 --> 00:08:41,729
<font color="#E5E5E5">pyramid provides are best illustrated as</font>

212
00:08:38,880 --> 00:08:43,799
a timeline<font color="#CCCCCC"> so pyramid keeps two small</font>

213
00:08:41,729 --> 00:08:45,960
sliding<font color="#E5E5E5"> with two sliding windows of data</font>

214
00:08:43,799 --> 00:08:48,959
the first<font color="#CCCCCC"> sliding window we call the hot</font>

215
00:08:45,960 --> 00:08:51,840
window<font color="#E5E5E5"> and that the hot window is</font>

216
00:08:48,960 --> 00:08:53,430
<font color="#CCCCCC">consists of the recent amount recent raw</font>

217
00:08:51,840 --> 00:08:56,130
data that<font color="#E5E5E5"> will be used for retraining</font>

218
00:08:53,430 --> 00:08:59,459
<font color="#E5E5E5">and we expect</font><font color="#CCCCCC"> that this the size of this</font>

219
00:08:56,130 --> 00:09:01,589
<font color="#E5E5E5">window would be days or weeks of time so</font>

220
00:08:59,460 --> 00:09:02,339
the second window<font color="#E5E5E5"> is the retention</font>

221
00:09:01,589 --> 00:09:03,959
window

222
00:09:02,339 --> 00:09:06,329
and the retention window is much longer

223
00:09:03,959 --> 00:09:08,638
<font color="#E5E5E5">and the observations that fall into it</font>

224
00:09:06,329 --> 00:09:12,420
are used to populate the<font color="#E5E5E5"> account tables</font>

225
00:09:08,639 --> 00:09:14,220
so and we expect that<font color="#E5E5E5"> the retention</font>

226
00:09:12,420 --> 00:09:17,878
window would be<font color="#E5E5E5"> on the order of months</font>

227
00:09:14,220 --> 00:09:19,230
or a year<font color="#E5E5E5"> and then the most then the</font>

228
00:09:17,879 --> 00:09:22,699
data that<font color="#E5E5E5"> falls out of these two would</font>

229
00:09:19,230 --> 00:09:25,439
be stored offline<font color="#CCCCCC"> and protect then</font>

230
00:09:22,699 --> 00:09:27,990
presumably inaccessible<font color="#CCCCCC"> so in the event</font>

231
00:09:25,439 --> 00:09:30,719
of<font color="#E5E5E5"> an attack the adversary will gain</font>

232
00:09:27,990 --> 00:09:33,600
access to the small amount<font color="#CCCCCC"> of recent</font><font color="#E5E5E5"> raw</font>

233
00:09:30,720 --> 00:09:36,569
data<font color="#E5E5E5"> and then the adversary will also</font>

234
00:09:33,600 --> 00:09:40,499
gain access to any new<font color="#E5E5E5"> observations that</font>

235
00:09:36,569 --> 00:09:43,529
<font color="#E5E5E5">arise before the attack is mitigated and</font>

236
00:09:40,499 --> 00:09:46,709
finally the adversary will also be able

237
00:09:43,529 --> 00:09:48,990
<font color="#E5E5E5">to see the values of the count table but</font>

238
00:09:46,709 --> 00:09:50,998
will not<font color="#E5E5E5"> but be we have not kept</font><font color="#CCCCCC"> the</font>

239
00:09:48,990 --> 00:09:54,689
observations<font color="#E5E5E5"> that we use to create the</font>

240
00:09:50,999 --> 00:09:55,860
count table<font color="#E5E5E5"> around so-and-so</font><font color="#CCCCCC"> in the</font>

241
00:09:54,689 --> 00:09:57,569
count tables themselves<font color="#CCCCCC"> are</font>

242
00:09:55,860 --> 00:09:59,309
differentially private so that<font color="#E5E5E5"> should</font>

243
00:09:57,569 --> 00:10:00,870
provide some<font color="#E5E5E5"> privacy for the</font>

244
00:09:59,309 --> 00:10:04,559
observations that<font color="#E5E5E5"> were used for</font>

245
00:10:00,870 --> 00:10:08,189
population so<font color="#E5E5E5"> for these protections</font><font color="#CCCCCC"> to</font>

246
00:10:04,559 --> 00:10:11,009
hold<font color="#CCCCCC"> Pearman makes three assumptions</font>

247
00:10:08,189 --> 00:10:12,389
<font color="#CCCCCC">that must be met first</font><font color="#E5E5E5"> is that state is</font>

248
00:10:11,009 --> 00:10:15,839
not managed out of<font color="#CCCCCC"> vams</font>

249
00:10:12,389 --> 00:10:18,269
<font color="#E5E5E5">this means that the analyst or developer</font>

250
00:10:15,839 --> 00:10:20,370
cannot copy data<font color="#CCCCCC"> from the hot window or</font>

251
00:10:18,269 --> 00:10:22,499
count tables locally pyramid must<font color="#E5E5E5"> do all</font>

252
00:10:20,370 --> 00:10:24,059
<font color="#CCCCCC">of the data</font><font color="#E5E5E5"> management and then we</font>

253
00:10:22,499 --> 00:10:27,449
assume that<font color="#E5E5E5"> all</font><font color="#CCCCCC"> of the</font><font color="#E5E5E5"> models are</font>

254
00:10:24,059 --> 00:10:29,850
retrained<font color="#E5E5E5"> when pyramid</font><font color="#CCCCCC"> requests</font><font color="#E5E5E5"> this is</font>

255
00:10:27,449 --> 00:10:32,160
because that the models will contain

256
00:10:29,850 --> 00:10:33,809
<font color="#E5E5E5">information about the</font><font color="#CCCCCC"> hot window and</font>

257
00:10:32,160 --> 00:10:36,929
count tables on which they were trained

258
00:10:33,809 --> 00:10:39,749
so these<font color="#CCCCCC"> two these</font><font color="#E5E5E5"> must</font><font color="#CCCCCC"> be kept in step</font>

259
00:10:36,929 --> 00:10:42,480
as they slide and finally state<font color="#E5E5E5"> from the</font>

260
00:10:39,749 --> 00:10:44,249
previous models should not persist this

261
00:10:42,480 --> 00:10:46,199
follows from<font color="#CCCCCC"> the previous assumption</font><font color="#E5E5E5"> and</font>

262
00:10:44,249 --> 00:10:48,029
<font color="#E5E5E5">means that</font><font color="#CCCCCC"> the current</font><font color="#E5E5E5"> models must only</font>

263
00:10:46,199 --> 00:10:51,839
reflect data in the current hot window

264
00:10:48,029 --> 00:10:53,850
and the current count tables so as I

265
00:10:51,839 --> 00:10:55,620
stated<font color="#CCCCCC"> previously</font><font color="#E5E5E5"> we use differential</font>

266
00:10:53,850 --> 00:10:59,100
<font color="#E5E5E5">privacy</font><font color="#CCCCCC"> in conjunction</font><font color="#E5E5E5"> with these count</font>

267
00:10:55,620 --> 00:11:00,809
tables and the general<font color="#E5E5E5"> idea</font><font color="#CCCCCC"> for a good</font>

268
00:10:59,100 --> 00:11:02,910
differential<font color="#CCCCCC"> privacy is that you</font>

269
00:11:00,809 --> 00:11:06,209
randomized out outputs and functions are

270
00:11:02,910 --> 00:11:08,129
randomized<font color="#E5E5E5"> to protect privacy and the</font>

271
00:11:06,209 --> 00:11:10,500
amount of randomization<font color="#E5E5E5"> is based on a</font>

272
00:11:08,129 --> 00:11:12,209
privacy budget<font color="#E5E5E5"> epsilon and the smaller</font>

273
00:11:10,500 --> 00:11:14,089
<font color="#E5E5E5">the epsilon the smaller the privacy</font>

274
00:11:12,209 --> 00:11:15,859
budget<font color="#E5E5E5"> and any more randomization and</font>

275
00:11:14,089 --> 00:11:17,810
this privacy

276
00:11:15,860 --> 00:11:21,290
epsilon<font color="#CCCCCC"> can be shared among a number</font><font color="#E5E5E5"> of</font>

277
00:11:17,810 --> 00:11:23,540
<font color="#CCCCCC">queries so different</font><font color="#E5E5E5"> for privacy has two</font>

278
00:11:21,290 --> 00:11:25,490
nice<font color="#E5E5E5"> characteristics that the first is</font>

279
00:11:23,540 --> 00:11:28,250
that it<font color="#E5E5E5"> is resilient</font><font color="#CCCCCC"> to auxilary</font>

280
00:11:25,490 --> 00:11:30,200
information and the second is<font color="#E5E5E5"> that it is</font>

281
00:11:28,250 --> 00:11:32,540
resilient<font color="#E5E5E5"> to</font><font color="#CCCCCC"> post-processing</font><font color="#E5E5E5"> so this</font>

282
00:11:30,200 --> 00:11:34,280
means that<font color="#E5E5E5"> any after we have the</font>

283
00:11:32,540 --> 00:11:35,900
differential<font color="#E5E5E5"> a private count table we</font>

284
00:11:34,280 --> 00:11:38,420
can count feature<font color="#E5E5E5"> eyes any day</font>

285
00:11:35,900 --> 00:11:40,699
<font color="#E5E5E5">temperatur eyes data and use it to</font><font color="#CCCCCC"> Train</font>

286
00:11:38,420 --> 00:11:42,229
any model and the<font color="#E5E5E5"> observations use to</font>

287
00:11:40,700 --> 00:11:44,060
<font color="#CCCCCC">populate the count table</font><font color="#E5E5E5"> whilst it would</font>

288
00:11:42,230 --> 00:11:46,460
still be private<font color="#E5E5E5"> so we leverage</font>

289
00:11:44,060 --> 00:11:48,140
differential privacy<font color="#E5E5E5"> by initializing</font>

290
00:11:46,460 --> 00:11:50,960
rather than initializing the count

291
00:11:48,140 --> 00:11:53,689
tables<font color="#E5E5E5"> with</font><font color="#CCCCCC"> 0 we initialize them with</font>

292
00:11:50,960 --> 00:11:55,310
<font color="#CCCCCC">rasam laplacian distribution and that</font>

293
00:11:53,690 --> 00:11:57,920
<font color="#E5E5E5">privacy budget is shared among all of</font>

294
00:11:55,310 --> 00:12:00,560
the features<font color="#E5E5E5"> so the more features that a</font>

295
00:11:57,920 --> 00:12:04,310
model has the more randomization<font color="#E5E5E5"> that</font>

296
00:12:00,560 --> 00:12:07,819
<font color="#CCCCCC">there the larger the laplacian</font>

297
00:12:04,310 --> 00:12:09,560
distribution<font color="#E5E5E5"> would</font><font color="#CCCCCC"> be so the difference</font>

298
00:12:07,820 --> 00:12:11,120
or<font color="#E5E5E5"> privacy we combine it with count</font>

299
00:12:09,560 --> 00:12:12,949
feature ization in building these count

300
00:12:11,120 --> 00:12:15,380
tables<font color="#E5E5E5"> on the structure of</font><font color="#CCCCCC"> the count</font>

301
00:12:12,950 --> 00:12:16,760
tables<font color="#CCCCCC"> look</font><font color="#E5E5E5"> something like this so</font><font color="#CCCCCC"> the</font>

302
00:12:15,380 --> 00:12:18,470
count tables that we've shown in

303
00:12:16,760 --> 00:12:21,200
previous<font color="#E5E5E5"> slides are actually made up of</font>

304
00:12:18,470 --> 00:12:22,970
<font color="#E5E5E5">many smaller count tables and the</font>

305
00:12:21,200 --> 00:12:24,800
retention<font color="#E5E5E5"> by</font><font color="#CCCCCC"> splitting and we split the</font>

306
00:12:22,970 --> 00:12:26,930
retention window into many smaller

307
00:12:24,800 --> 00:12:29,120
<font color="#E5E5E5">discreet windows of</font><font color="#CCCCCC"> time in this case we</font>

308
00:12:26,930 --> 00:12:31,609
keep a count window for each day<font color="#E5E5E5"> in</font>

309
00:12:29,120 --> 00:12:34,480
order<font color="#CCCCCC"> to</font><font color="#E5E5E5"> compute the accounts that are</font>

310
00:12:31,610 --> 00:12:36,560
<font color="#CCCCCC">needed for feature ization we just</font>

311
00:12:34,480 --> 00:12:39,710
completed<font color="#E5E5E5"> some the count tables together</font>

312
00:12:36,560 --> 00:12:41,719
<font color="#CCCCCC">and when the count window when the</font>

313
00:12:39,710 --> 00:12:45,710
retention window slides<font color="#E5E5E5"> and we</font>

314
00:12:41,720 --> 00:12:47,270
initialize a new a new<font color="#E5E5E5"> table the values</font>

315
00:12:45,710 --> 00:12:49,310
the cells of the count table are

316
00:12:47,270 --> 00:12:51,770
initialized<font color="#E5E5E5"> with values</font><font color="#CCCCCC"> from</font>

317
00:12:49,310 --> 00:12:53,239
differentially values<font color="#CCCCCC"> multiply the</font>

318
00:12:51,770 --> 00:12:55,370
appropriate laplacian distribution

319
00:12:53,240 --> 00:12:57,710
they are<font color="#E5E5E5"> incremented with new</font>

320
00:12:55,370 --> 00:13:00,200
observations<font color="#E5E5E5"> and then that window is</font>

321
00:12:57,710 --> 00:13:04,400
added to<font color="#E5E5E5"> the summation</font><font color="#CCCCCC"> and then whenever</font>

322
00:13:00,200 --> 00:13:06,200
<font color="#E5E5E5">the retention window whenever</font><font color="#CCCCCC"> a day fold</font>

323
00:13:04,400 --> 00:13:09,800
<font color="#E5E5E5">out of the retention window we simply</font>

324
00:13:06,200 --> 00:13:13,430
remove<font color="#CCCCCC"> that from the remove that window</font>

325
00:13:09,800 --> 00:13:15,770
from the<font color="#E5E5E5"> summation so we</font><font color="#CCCCCC"> mini-challenge</font>

326
00:13:13,430 --> 00:13:16,910
his arose when trying<font color="#E5E5E5"> to combine count</font>

327
00:13:15,770 --> 00:13:18,890
feature ization with differential

328
00:13:16,910 --> 00:13:20,810
privacy<font color="#CCCCCC"> I don't have time to go into</font>

329
00:13:18,890 --> 00:13:22,400
them<font color="#E5E5E5"> here but all of the challenges</font><font color="#CCCCCC"> are</font>

330
00:13:20,810 --> 00:13:24,530
detailed in our paper and<font color="#CCCCCC"> all of the</font>

331
00:13:22,400 --> 00:13:27,680
<font color="#E5E5E5">solutions we</font><font color="#CCCCCC"> have evaluations for</font><font color="#E5E5E5"> all of</font>

332
00:13:24,530 --> 00:13:29,209
these solutions<font color="#E5E5E5"> so now that I've talked</font>

333
00:13:27,680 --> 00:13:31,279
through<font color="#E5E5E5"> the approaches that</font>

334
00:13:29,209 --> 00:13:33,469
under live pyramid<font color="#CCCCCC"> I'll go into some of</font>

335
00:13:31,279 --> 00:13:35,869
the evaluation<font color="#CCCCCC"> showing</font><font color="#E5E5E5"> that we can train</font>

336
00:13:33,470 --> 00:13:37,879
models<font color="#E5E5E5"> on smaller amounts of recent data</font>

337
00:13:35,869 --> 00:13:41,089
<font color="#E5E5E5">reducing the exposure and have those</font>

338
00:13:37,879 --> 00:13:44,269
models<font color="#E5E5E5"> compliant can perform</font>

339
00:13:41,089 --> 00:13:47,149
competitively with<font color="#E5E5E5"> models trained on the</font>

340
00:13:44,269 --> 00:13:49,220
full<font color="#E5E5E5"> data set so today I'm going to talk</font>

341
00:13:47,149 --> 00:13:51,410
about<font color="#CCCCCC"> the evaluation on</font><font color="#E5E5E5"> two data sets</font>

342
00:13:49,220 --> 00:13:53,360
<font color="#E5E5E5">the first one is a data set released by</font>

343
00:13:51,410 --> 00:13:55,759
the ad targeting firm<font color="#CCCCCC"> Cray do for a</font>

344
00:13:53,360 --> 00:13:58,579
cattle competition and the goal of<font color="#CCCCCC"> this</font>

345
00:13:55,759 --> 00:14:00,860
data<font color="#E5E5E5"> set is for a number</font><font color="#CCCCCC"> of is to</font>

346
00:13:58,579 --> 00:14:02,929
predict<font color="#E5E5E5"> estimate the probability that a</font>

347
00:14:00,860 --> 00:14:05,059
user will<font color="#CCCCCC"> click</font><font color="#E5E5E5"> on an ad given 39</font>

348
00:14:02,929 --> 00:14:07,309
features and the second<font color="#E5E5E5"> data set</font><font color="#CCCCCC"> that we</font>

349
00:14:05,059 --> 00:14:09,019
look at is the movie lens<font color="#E5E5E5"> data set</font>

350
00:14:07,309 --> 00:14:14,360
released by the<font color="#E5E5E5"> University of Minnesota</font>

351
00:14:09,019 --> 00:14:17,209
<font color="#CCCCCC">and this data set is a series of movie</font>

352
00:14:14,360 --> 00:14:19,220
ratings<font color="#E5E5E5"> users rating movies and also</font>

353
00:14:17,209 --> 00:14:21,018
<font color="#E5E5E5">consists</font><font color="#CCCCCC"> of a</font><font color="#E5E5E5"> number of demographics</font>

354
00:14:19,220 --> 00:14:25,069
<font color="#CCCCCC">about the users and</font><font color="#E5E5E5"> characteristics of</font>

355
00:14:21,019 --> 00:14:26,569
the movies so all<font color="#E5E5E5"> of the figures</font><font color="#CCCCCC"> that</font>

356
00:14:25,069 --> 00:14:29,329
<font color="#CCCCCC">I've mentioned that I'll show have the</font>

357
00:14:26,569 --> 00:14:31,040
same structure<font color="#CCCCCC"> the x-axis shows the</font>

358
00:14:29,329 --> 00:14:33,979
<font color="#CCCCCC">fraction of the raw data that</font><font color="#E5E5E5"> was used</font>

359
00:14:31,040 --> 00:14:38,389
<font color="#CCCCCC">for training</font><font color="#E5E5E5"> and the y-axis</font><font color="#CCCCCC"> shows the</font>

360
00:14:33,980 --> 00:14:40,220
performance normalized to<font color="#CCCCCC"> the model a</font>

361
00:14:38,389 --> 00:14:42,889
model train<font color="#E5E5E5"> on the full raw data sets</font>

362
00:14:40,220 --> 00:14:47,149
this makes it easy to<font color="#CCCCCC"> compare</font><font color="#E5E5E5"> so the</font>

363
00:14:42,889 --> 00:14:50,420
blue line<font color="#CCCCCC"> that's up there</font><font color="#E5E5E5"> now shows the</font>

364
00:14:47,149 --> 00:14:52,429
performance<font color="#E5E5E5"> of a 35 node single</font><font color="#CCCCCC"> areal</font>

365
00:14:50,420 --> 00:14:55,128
neural network trained on increasing

366
00:14:52,429 --> 00:14:58,040
fractions of<font color="#CCCCCC"> the Credo data set and you</font>

367
00:14:55,129 --> 00:15:00,740
can<font color="#CCCCCC"> see as we add data as we add data</font>

368
00:14:58,040 --> 00:15:02,449
<font color="#CCCCCC">the</font><font color="#E5E5E5"> model continues to the performance</font>

369
00:15:00,740 --> 00:15:06,290
continues to improve<font color="#E5E5E5"> and notice that the</font>

370
00:15:02,449 --> 00:15:08,748
<font color="#CCCCCC">x-axis is analog</font><font color="#E5E5E5"> scale</font><font color="#CCCCCC"> so the orange</font>

371
00:15:06,290 --> 00:15:10,910
line that<font color="#E5E5E5"> I've added is a model trained</font>

372
00:15:08,749 --> 00:15:14,029
on increasing fractions of count feature

373
00:15:10,910 --> 00:15:16,699
<font color="#CCCCCC">edge data</font><font color="#E5E5E5"> and the this model can the</font>

374
00:15:14,029 --> 00:15:18,589
models trained<font color="#E5E5E5"> on count feature eyes</font>

375
00:15:16,699 --> 00:15:21,199
data tend to converge<font color="#E5E5E5"> much faster</font><font color="#CCCCCC"> to</font>

376
00:15:18,589 --> 00:15:23,119
close to their maximum performance<font color="#E5E5E5"> much</font>

377
00:15:21,199 --> 00:15:25,429
faster<font color="#CCCCCC"> than the role models</font><font color="#E5E5E5"> and in this</font>

378
00:15:23,119 --> 00:15:28,699
case it converges<font color="#E5E5E5"> faster but we have a</font>

379
00:15:25,429 --> 00:15:30,410
<font color="#CCCCCC">2.6 percent loss in performance</font><font color="#E5E5E5"> the</font>

380
00:15:28,699 --> 00:15:33,109
green line that<font color="#E5E5E5"> I've just added shows</font>

381
00:15:30,410 --> 00:15:34,639
the<font color="#E5E5E5"> performance of count future eyes</font>

382
00:15:33,110 --> 00:15:37,189
data but with a<font color="#E5E5E5"> differentially private</font>

383
00:15:34,639 --> 00:15:39,990
count<font color="#E5E5E5"> table with epsilon equals</font><font color="#CCCCCC"> 1 and</font><font color="#E5E5E5"> in</font>

384
00:15:37,189 --> 00:15:42,899
this case<font color="#E5E5E5"> that costs another</font><font color="#CCCCCC"> 0.6 percent</font>

385
00:15:39,990 --> 00:15:45,660
and performance<font color="#E5E5E5"> but what this means</font><font color="#CCCCCC"> what</font>

386
00:15:42,899 --> 00:15:48,209
all<font color="#CCCCCC"> what</font><font color="#E5E5E5"> this means is that training on</font>

387
00:15:45,660 --> 00:15:50,819
just<font color="#CCCCCC"> 0.4% of</font><font color="#E5E5E5"> the data in this in this</font>

388
00:15:48,209 --> 00:15:53,430
instance<font color="#E5E5E5"> leads to only a</font><font color="#CCCCCC"> 3.1 percent</font>

389
00:15:50,820 --> 00:15:55,080
loss of accuracy<font color="#CCCCCC"> so we could dear</font><font color="#E5E5E5"> let's</font>

390
00:15:53,430 --> 00:15:57,060
<font color="#CCCCCC">protect we could potentially reduce the</font>

391
00:15:55,080 --> 00:16:00,089
overall exposure<font color="#E5E5E5"> by two orders</font><font color="#CCCCCC"> of</font>

392
00:15:57,060 --> 00:16:03,119
magnitude with a<font color="#E5E5E5"> 3.1 percent performance</font>

393
00:16:00,089 --> 00:16:05,820
<font color="#CCCCCC">hit</font><font color="#E5E5E5"> and we see</font><font color="#CCCCCC"> similar results</font><font color="#E5E5E5"> from the</font>

394
00:16:03,120 --> 00:16:07,430
movie lens data set where we<font color="#CCCCCC"> can expose</font>

395
00:16:05,820 --> 00:16:10,170
<font color="#CCCCCC">your point</font><font color="#E5E5E5"> eight percent of the data and</font>

396
00:16:07,430 --> 00:16:11,459
<font color="#CCCCCC">before five</font><font color="#E5E5E5"> and just under a five and a</font>

397
00:16:10,170 --> 00:16:14,670
half percent loss<font color="#CCCCCC"> in accuracy</font>

398
00:16:11,459 --> 00:16:16,380
so using<font color="#CCCCCC"> account feature ization we</font>

399
00:16:14,670 --> 00:16:17,610
could potentially<font color="#E5E5E5"> reduce the exposure of</font>

400
00:16:16,380 --> 00:16:19,320
<font color="#E5E5E5">the amount of data that we need to</font>

401
00:16:17,610 --> 00:16:20,600
expose when<font color="#E5E5E5"> training models by two</font>

402
00:16:19,320 --> 00:16:24,270
orders of<font color="#E5E5E5"> magnitude</font>

403
00:16:20,600 --> 00:16:25,980
so today<font color="#E5E5E5"> I've talked about</font><font color="#CCCCCC"> I've talked</font>

404
00:16:24,270 --> 00:16:27,689
<font color="#E5E5E5">about how aggressive data collection and</font>

405
00:16:25,980 --> 00:16:29,430
wide access practices<font color="#CCCCCC"> increased data</font>

406
00:16:27,690 --> 00:16:31,350
exposure risks for companies<font color="#E5E5E5"> and</font>

407
00:16:29,430 --> 00:16:33,479
organizations<font color="#E5E5E5"> have introduced selective</font>

408
00:16:31,350 --> 00:16:35,490
data systems<font color="#E5E5E5"> that minimize in use data</font>

409
00:16:33,480 --> 00:16:37,500
and cleanly separate that completely

410
00:16:35,490 --> 00:16:39,690
<font color="#E5E5E5">separate it from the unused data set</font>

411
00:16:37,500 --> 00:16:42,180
data and<font color="#CCCCCC"> propose training set</font>

412
00:16:39,690 --> 00:16:43,980
minimization as a new way<font color="#CCCCCC"> to</font><font color="#E5E5E5"> think about</font>

413
00:16:42,180 --> 00:16:45,959
selectivity<font color="#CCCCCC"> in the context of ML</font>

414
00:16:43,980 --> 00:16:47,579
workloads<font color="#E5E5E5"> and finally I talked</font><font color="#CCCCCC"> about</font>

415
00:16:45,959 --> 00:16:49,229
pyramid<font color="#E5E5E5"> which was our first selective</font>

416
00:16:47,579 --> 00:16:51,209
data system that retrofits count

417
00:16:49,230 --> 00:16:52,470
features Asians<font color="#E5E5E5"> for protect</font><font color="#CCCCCC"> or</font>

418
00:16:51,209 --> 00:16:54,390
protection<font color="#E5E5E5"> using differential privacy</font>

419
00:16:52,470 --> 00:16:55,970
<font color="#E5E5E5">and shown</font><font color="#CCCCCC"> that it's possible to reduce</font>

420
00:16:54,390 --> 00:16:58,800
<font color="#E5E5E5">data exposure by two orders</font><font color="#CCCCCC"> of</font><font color="#E5E5E5"> magnitude</font>

421
00:16:55,970 --> 00:17:00,839
<font color="#CCCCCC">so while I'll leave you</font><font color="#E5E5E5"> on this future</font>

422
00:16:58,800 --> 00:17:10,020
<font color="#E5E5E5">on the future work slide and take</font>

423
00:17:00,839 --> 00:17:14,579
<font color="#CCCCCC">questions thank</font><font color="#E5E5E5"> you and we can also</font>

424
00:17:10,020 --> 00:17:17,010
welcome the other soft<font color="#CCCCCC"> offer</font><font color="#E5E5E5"> yes how</font>

425
00:17:14,579 --> 00:17:20,579
<font color="#CCCCCC">private my tias especially a step up</font>

426
00:17:17,010 --> 00:17:22,290
those stages<font color="#CCCCCC"> go ahead Ben polar</font>

427
00:17:20,579 --> 00:17:24,750
University of Connecticut<font color="#E5E5E5"> if you're</font>

428
00:17:22,290 --> 00:17:27,420
using a count<font color="#CCCCCC"> free tries system</font><font color="#E5E5E5"> why do</font>

429
00:17:24,750 --> 00:17:29,130
you need to keep the hot data in in your

430
00:17:27,420 --> 00:17:31,340
local<font color="#E5E5E5"> data store at all why can't you</font>

431
00:17:29,130 --> 00:17:34,500
just get<font color="#E5E5E5"> rid of it and put cold storage</font>

432
00:17:31,340 --> 00:17:36,360
<font color="#E5E5E5">because we have that the small amount of</font>

433
00:17:34,500 --> 00:17:37,679
recent raw data we actually<font color="#CCCCCC"> perform I</font>

434
00:17:36,360 --> 00:17:39,719
<font color="#E5E5E5">walk through an</font><font color="#CCCCCC"> example</font><font color="#E5E5E5"> of</font><font color="#CCCCCC"> how we</font>

435
00:17:37,679 --> 00:17:41,670
perform the count feature is<font color="#CCCCCC"> Asian so we</font>

436
00:17:39,720 --> 00:17:43,890
actually transform<font color="#E5E5E5"> that small amount of</font>

437
00:17:41,670 --> 00:17:45,630
raw data and use<font color="#CCCCCC"> that to Train the model</font>

438
00:17:43,890 --> 00:17:47,550
so we<font color="#CCCCCC"> needed</font><font color="#E5E5E5"> for model</font><font color="#CCCCCC"> training so</font>

439
00:17:45,630 --> 00:17:49,880
aren't<font color="#E5E5E5"> you worried that you've increased</font>

440
00:17:47,550 --> 00:17:52,210
the privacy risk for<font color="#E5E5E5"> people well they're</font>

441
00:17:49,880 --> 00:17:56,140
involved in<font color="#E5E5E5"> that hot</font>

442
00:17:52,210 --> 00:17:57,880
that is a yes it does<font color="#CCCCCC"> I mean it doesn't</font>

443
00:17:56,140 --> 00:17:59,170
<font color="#E5E5E5">it should increase</font><font color="#CCCCCC"> the privacy risk any</font>

444
00:17:57,880 --> 00:18:03,370
more than<font color="#E5E5E5"> just training on the raw data</font>

445
00:17:59,170 --> 00:18:05,320
<font color="#CCCCCC">our hope</font><font color="#E5E5E5"> is that the just exposing that</font>

446
00:18:03,370 --> 00:18:08,530
much smaller fraction<font color="#CCCCCC"> of the</font><font color="#E5E5E5"> data would</font>

447
00:18:05,320 --> 00:18:10,629
have<font color="#CCCCCC"> a benefit for protection</font><font color="#E5E5E5"> but the</font>

448
00:18:08,530 --> 00:18:16,030
model is more dependent<font color="#E5E5E5"> on that data</font>

449
00:18:10,630 --> 00:18:17,260
that's possible yes<font color="#E5E5E5"> thank you</font><font color="#CCCCCC"> hi Ellie</font>

450
00:18:16,030 --> 00:18:18,940
canals<font color="#E5E5E5"> not</font><font color="#CCCCCC"> perfection</font><font color="#E5E5E5"> arrogance to</font>

451
00:18:17,260 --> 00:18:21,160
Sunday which I noticed so if you're

452
00:18:18,940 --> 00:18:22,630
<font color="#CCCCCC">doing</font><font color="#E5E5E5"> these count tables you have</font><font color="#CCCCCC"> a</font>

453
00:18:21,160 --> 00:18:24,400
slide that<font color="#E5E5E5"> showed conditional</font>

454
00:18:22,630 --> 00:18:26,910
probabilities<font color="#E5E5E5"> yes I assume those are</font>

455
00:18:24,400 --> 00:18:30,010
<font color="#CCCCCC">being stored at the</font><font color="#E5E5E5"> time of the counts</font>

456
00:18:26,910 --> 00:18:32,170
<font color="#CCCCCC">so those are stored I mean they're</font>

457
00:18:30,010 --> 00:18:34,060
stored<font color="#CCCCCC"> online</font><font color="#E5E5E5"> and they're stored and</font>

458
00:18:32,170 --> 00:18:35,590
updated online<font color="#E5E5E5"> as you receive new</font>

459
00:18:34,060 --> 00:18:37,629
<font color="#E5E5E5">labeled observations if you want to</font>

460
00:18:35,590 --> 00:18:39,580
calculate a<font color="#E5E5E5"> new conditional probability</font>

461
00:18:37,630 --> 00:18:41,260
<font color="#E5E5E5">please don't abuse it yes if you needed</font>

462
00:18:39,580 --> 00:18:43,720
<font color="#E5E5E5">yeah so if you needed to</font><font color="#CCCCCC"> do that that</font>

463
00:18:41,260 --> 00:18:44,860
<font color="#E5E5E5">would be like evolution your workload so</font>

464
00:18:43,720 --> 00:18:46,690
if you want to start<font color="#CCCCCC"> predicting</font>

465
00:18:44,860 --> 00:18:49,000
something<font color="#E5E5E5"> new so rather than predicting</font>

466
00:18:46,690 --> 00:18:50,260
the if someone would click you<font color="#E5E5E5"> want to</font>

467
00:18:49,000 --> 00:18:51,970
start predicting<font color="#CCCCCC"> retention time you</font>

468
00:18:50,260 --> 00:18:53,770
would<font color="#CCCCCC"> have to go</font><font color="#E5E5E5"> back to the raw</font><font color="#CCCCCC"> Dave to</font>

469
00:18:51,970 --> 00:18:59,290
the<font color="#CCCCCC"> cold store and compute all new</font><font color="#E5E5E5"> count</font>

470
00:18:53,770 --> 00:19:01,660
tables<font color="#CCCCCC"> okay yeah</font><font color="#E5E5E5"> thanks John Criswell</font>

471
00:18:59,290 --> 00:19:03,520
University of Rochester<font color="#E5E5E5"> I'm a little</font>

472
00:19:01,660 --> 00:19:07,150
confused<font color="#E5E5E5"> about your attack model are you</font>

473
00:19:03,520 --> 00:19:10,270
<font color="#CCCCCC">trying to protect just</font><font color="#E5E5E5"> against queries</font>

474
00:19:07,150 --> 00:19:13,270
to the<font color="#E5E5E5"> database or</font><font color="#CCCCCC"> the or just</font><font color="#E5E5E5"> attacking</font>

475
00:19:10,270 --> 00:19:14,830
from save more<font color="#E5E5E5"> low-level attacks because</font>

476
00:19:13,270 --> 00:19:17,770
it's not clear to<font color="#CCCCCC"> me that moving data</font>

477
00:19:14,830 --> 00:19:19,360
and offline<font color="#E5E5E5"> cold storage is actually</font>

478
00:19:17,770 --> 00:19:21,639
going to<font color="#E5E5E5"> protect things unless it's just</font>

479
00:19:19,360 --> 00:19:23,830
not accessible<font color="#E5E5E5"> to queries</font><font color="#CCCCCC"> I mean the</font>

480
00:19:21,640 --> 00:19:25,990
idea is<font color="#CCCCCC"> that</font><font color="#E5E5E5"> it would</font><font color="#CCCCCC"> be much less</font>

481
00:19:23,830 --> 00:19:28,689
<font color="#CCCCCC">accessible to queries because</font><font color="#E5E5E5"> you it</font>

482
00:19:25,990 --> 00:19:31,380
would be<font color="#CCCCCC"> the ideas that you would make</font>

483
00:19:28,690 --> 00:19:34,210
accessing<font color="#E5E5E5"> that data</font><font color="#CCCCCC"> very exceptional</font><font color="#E5E5E5"> so</font>

484
00:19:31,380 --> 00:19:35,920
make<font color="#CCCCCC"> it exceptional so that when data</font><font color="#E5E5E5"> is</font>

485
00:19:34,210 --> 00:19:37,480
needed to be accessed<font color="#CCCCCC"> you would be able</font>

486
00:19:35,920 --> 00:19:40,120
<font color="#CCCCCC">to do some kind of strong auditing or</font>

487
00:19:37,480 --> 00:19:41,860
access control on that<font color="#E5E5E5"> okay so something</font>

488
00:19:40,120 --> 00:19:43,270
like<font color="#E5E5E5"> shipping the data off to a remote</font>

489
00:19:41,860 --> 00:19:44,860
<font color="#E5E5E5">server that</font><font color="#CCCCCC"> just doesn't</font><font color="#E5E5E5"> let your core</font>

490
00:19:43,270 --> 00:19:49,629
you know<font color="#CCCCCC"> read it once you send it off</font>

491
00:19:44,860 --> 00:19:51,429
<font color="#CCCCCC">yes</font><font color="#E5E5E5"> yes and then in in your kind of that</font>

492
00:19:49,630 --> 00:19:53,890
<font color="#E5E5E5">what you keep online is the small amount</font>

493
00:19:51,430 --> 00:19:55,710
<font color="#E5E5E5">of recent data and the</font><font color="#CCCCCC"> count tables okay</font>

494
00:19:53,890 --> 00:19:58,990
<font color="#E5E5E5">thank you</font>

495
00:19:55,710 --> 00:20:04,660
let's thank<font color="#E5E5E5"> all speakers of the session</font>

496
00:19:58,990 --> 00:20:04,660
[Applause]

