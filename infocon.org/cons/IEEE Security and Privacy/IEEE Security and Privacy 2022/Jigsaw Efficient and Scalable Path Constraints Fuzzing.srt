1
00:00:01,360 --> 00:00:03,679
okay

2
00:00:06,640 --> 00:00:07,919
okay

3
00:00:07,919 --> 00:00:10,160
good morning everyone my name is juchen

4
00:00:10,160 --> 00:00:12,480
i'm a phd candidate

5
00:00:12,480 --> 00:00:14,480
in computer science at the uc riverside

6
00:00:14,480 --> 00:00:16,960
it's my pleasure to present our work

7
00:00:16,960 --> 00:00:18,480
jigsaw

8
00:00:18,480 --> 00:00:20,480
efficient scalable plus construction

9
00:00:20,480 --> 00:00:22,480
fuzzing this is a joint world with my

10
00:00:22,480 --> 00:00:25,039
clinical gene hand my advisors cheong

11
00:00:25,039 --> 00:00:27,680
yusong and han

12
00:00:27,680 --> 00:00:29,920
so this work concerns courage guided

13
00:00:29,920 --> 00:00:32,000
testing so encourage together testing

14
00:00:32,000 --> 00:00:34,239
will keep sending inputs to target

15
00:00:34,239 --> 00:00:36,640
program with the hope of flipping some

16
00:00:36,640 --> 00:00:38,960
branches whenever a branch is flipped a

17
00:00:38,960 --> 00:00:41,920
new execution path will be unlocked

18
00:00:41,920 --> 00:00:44,640
clearly if we can flip branches faster

19
00:00:44,640 --> 00:00:47,360
then we can explore more coal fossils in

20
00:00:47,360 --> 00:00:49,520
the same amount of time

21
00:00:49,520 --> 00:00:51,760
so how can we you know flip branches

22
00:00:51,760 --> 00:00:54,000
faster so there are two factors

23
00:00:54,000 --> 00:00:56,800
determining the branch freezing rate the

24
00:00:56,800 --> 00:00:59,120
first factor is accuracy it means how

25
00:00:59,120 --> 00:01:03,120
many inputs are expected to try before

26
00:01:03,120 --> 00:01:04,239
finding a

27
00:01:04,239 --> 00:01:05,920
satisfiable one

28
00:01:05,920 --> 00:01:08,560
and the second factor is the support it

29
00:01:08,560 --> 00:01:10,479
means how many inputs i can try per

30
00:01:10,479 --> 00:01:11,600
second

31
00:01:11,600 --> 00:01:13,680
and the focus of jigsaw is about

32
00:01:13,680 --> 00:01:17,040
throughput so next let me review the

33
00:01:17,040 --> 00:01:19,520
current existing fuzzing testing

34
00:01:19,520 --> 00:01:22,880
approaches and their accuracies so if we

35
00:01:22,880 --> 00:01:25,360
have this spectrum of accuracy we first

36
00:01:25,360 --> 00:01:26,479
have

37
00:01:26,479 --> 00:01:29,200
black box fuzzing where inputs are

38
00:01:29,200 --> 00:01:33,119
mutated randomly and to towards creating

39
00:01:33,119 --> 00:01:36,560
a branch and because inputs because we

40
00:01:36,560 --> 00:01:38,560
have no knowledge about the tabi target

41
00:01:38,560 --> 00:01:40,720
program then usually we need to try a

42
00:01:40,720 --> 00:01:42,880
lot of inputs for filipino branch so its

43
00:01:42,880 --> 00:01:44,799
accuracy is not good

44
00:01:44,799 --> 00:01:46,479
so in the middle of this spectrum we

45
00:01:46,479 --> 00:01:48,799
have grey box fuzzing uh

46
00:01:48,799 --> 00:01:51,119
we have two select afl plus plus which

47
00:01:51,119 --> 00:01:53,680
do carriage guided testing

48
00:01:53,680 --> 00:01:55,759
and we have gradient guided

49
00:01:55,759 --> 00:01:58,079
tools like angular

50
00:01:58,079 --> 00:02:00,719
because we have uh

51
00:02:00,719 --> 00:02:04,640
guided guidance then we try less inputs

52
00:02:04,640 --> 00:02:06,399
before finals that is fireball one so

53
00:02:06,399 --> 00:02:09,440
that accuracy is better than

54
00:02:09,440 --> 00:02:11,760
black box fuzzing so in the end of this

55
00:02:11,760 --> 00:02:14,319
stream we have white box fuzzing and we

56
00:02:14,319 --> 00:02:17,280
have uh meaning aka symbolic or

57
00:02:17,280 --> 00:02:19,920
concurrent execution and these tools

58
00:02:19,920 --> 00:02:22,720
connect constraints and send to sms

59
00:02:22,720 --> 00:02:26,000
empty source if we treat smt stores as

60
00:02:26,000 --> 00:02:28,239
black boxes they can magically give you

61
00:02:28,239 --> 00:02:30,000
some inputs that

62
00:02:30,000 --> 00:02:32,239
satisfy the uh

63
00:02:32,239 --> 00:02:34,400
constraints so the accuracy is pretty

64
00:02:34,400 --> 00:02:35,360
high

65
00:02:35,360 --> 00:02:38,400
but if we unlock sorry if i unbox the

66
00:02:38,400 --> 00:02:43,280
smt source like z3 with osola as a tp x2

67
00:02:43,280 --> 00:02:44,560
they're actually running certain

68
00:02:44,560 --> 00:02:45,920
algorithms

69
00:02:45,920 --> 00:02:48,319
specifically modern smd source are

70
00:02:48,319 --> 00:02:51,120
running local search algorithms

71
00:02:51,120 --> 00:02:53,040
and if not if we cannot find the

72
00:02:53,040 --> 00:02:56,000
satisfiable inputs they will do a bit of

73
00:02:56,000 --> 00:02:58,879
blasting and convert the problem to a

74
00:02:58,879 --> 00:03:01,280
set problem and the set and the set

75
00:03:01,280 --> 00:03:03,040
source is running some backtracking

76
00:03:03,040 --> 00:03:05,440
searching algorithm to finding a

77
00:03:05,440 --> 00:03:08,319
satisfiable input

78
00:03:08,319 --> 00:03:11,120
so if we look from the perspective of

79
00:03:11,120 --> 00:03:12,560
throughput

80
00:03:12,560 --> 00:03:16,000
we have afl plus angular in the one end

81
00:03:16,000 --> 00:03:19,760
of this spectrum they are doing searches

82
00:03:19,760 --> 00:03:22,560
on the whole original program because

83
00:03:22,560 --> 00:03:24,239
they're searching targets it's it's

84
00:03:24,239 --> 00:03:27,280
entire program so it's throughput is not

85
00:03:27,280 --> 00:03:28,239
high

86
00:03:28,239 --> 00:03:30,959
and because we can connect constraints

87
00:03:30,959 --> 00:03:33,840
and listen to sm smt servers

88
00:03:33,840 --> 00:03:35,120
i will have

89
00:03:35,120 --> 00:03:36,959
sm resource in the middle of this

90
00:03:36,959 --> 00:03:40,080
spectrum because uh for this servers

91
00:03:40,080 --> 00:03:42,319
there are certain targets of past

92
00:03:42,319 --> 00:03:45,280
questions which are way much smaller

93
00:03:45,280 --> 00:03:47,599
than the original program so that uh

94
00:03:47,599 --> 00:03:50,720
such instruments is better

95
00:03:50,720 --> 00:03:53,280
now the question is can we do better and

96
00:03:53,280 --> 00:03:56,239
the answer is yes so with jigsaw our

97
00:03:56,239 --> 00:03:59,360
approach is to first convert or compile

98
00:03:59,360 --> 00:04:01,840
the past constraints related functions

99
00:04:01,840 --> 00:04:04,879
and we perform searching on the compiled

100
00:04:04,879 --> 00:04:06,879
relative functions

101
00:04:06,879 --> 00:04:09,200
so that we can improve the searching

102
00:04:09,200 --> 00:04:11,679
throughput

103
00:04:13,120 --> 00:04:17,120
uh also because to avoid uh the

104
00:04:17,120 --> 00:04:19,519
constrained connector from being the

105
00:04:19,519 --> 00:04:21,040
bottleneck of the whole system we'll

106
00:04:21,040 --> 00:04:23,440
also optimize the construction connector

107
00:04:23,440 --> 00:04:25,520
and implement our own tool called

108
00:04:25,520 --> 00:04:28,080
clearing ankle

109
00:04:28,080 --> 00:04:30,639
here's one simple example of what do i

110
00:04:30,639 --> 00:04:32,400
mean by a little function so consider

111
00:04:32,400 --> 00:04:35,520
very simple constraint x equal to 5 then

112
00:04:35,520 --> 00:04:37,199
our target negative function will just

113
00:04:37,199 --> 00:04:39,919
be x minus 5. and our searching

114
00:04:39,919 --> 00:04:42,639
algorithm basically keep mutating x and

115
00:04:42,639 --> 00:04:45,440
optimizing the distance between x and 5

116
00:04:45,440 --> 00:04:46,639
until

117
00:04:46,639 --> 00:04:48,639
we reach zero distance if the zero

118
00:04:48,639 --> 00:04:50,320
distance is reached we solve the

119
00:04:50,320 --> 00:04:52,240
constraints

120
00:04:52,240 --> 00:04:54,479
um

121
00:04:54,560 --> 00:04:57,040
so you may wonder why relative functions

122
00:04:57,040 --> 00:04:59,120
are ideal searching targets so we have a

123
00:04:59,120 --> 00:05:00,800
couple of reasons first they are much

124
00:05:00,800 --> 00:05:02,720
smaller than original program

125
00:05:02,720 --> 00:05:05,199
and the second reason we pass arguments

126
00:05:05,199 --> 00:05:07,840
to these relative functions so memory

127
00:05:07,840 --> 00:05:10,160
and registers are so they're running

128
00:05:10,160 --> 00:05:13,440
they're much more faster than doing this

129
00:05:13,440 --> 00:05:15,680
using disco files

130
00:05:15,680 --> 00:05:17,360
and the third reason is that our little

131
00:05:17,360 --> 00:05:19,039
functions are branchiness

132
00:05:19,039 --> 00:05:20,720
so we don't need to worry about branches

133
00:05:20,720 --> 00:05:23,440
prediction and we can easily exploit

134
00:05:23,440 --> 00:05:25,199
instruction level parallelism for

135
00:05:25,199 --> 00:05:28,880
example using vectorized instructions

136
00:05:28,880 --> 00:05:30,560
and the noise but not at least the

137
00:05:30,560 --> 00:05:32,479
reason is that our little functions are

138
00:05:32,479 --> 00:05:35,440
pure meaning that they do not touch any

139
00:05:35,440 --> 00:05:37,680
external state because functions are

140
00:05:37,680 --> 00:05:41,199
pure we do not need to do cleanup amount

141
00:05:41,199 --> 00:05:42,479
restarts

142
00:05:42,479 --> 00:05:44,639
and we do not need to worry about data

143
00:05:44,639 --> 00:05:46,720
dependencies between functions

144
00:05:46,720 --> 00:05:49,440
and also because uh there are no data

145
00:05:49,440 --> 00:05:51,600
dependencies we can you know scale

146
00:05:51,600 --> 00:05:53,759
jigsaw to multi-cores pretty

147
00:05:53,759 --> 00:05:55,520
straightforward and we can achieve

148
00:05:55,520 --> 00:05:58,880
linear scalability

149
00:05:59,360 --> 00:06:02,000
um now we have very nice features of

150
00:06:02,000 --> 00:06:04,000
compiled and little functions compile

151
00:06:04,000 --> 00:06:06,080
pass constraints or relative functions

152
00:06:06,080 --> 00:06:09,120
we still need other optimization

153
00:06:09,120 --> 00:06:12,720
to obtain sustainable high throughput

154
00:06:12,720 --> 00:06:14,160
first of all because just in time

155
00:06:14,160 --> 00:06:16,160
combination is very slow it may cancel

156
00:06:16,160 --> 00:06:18,720
the benefits of this high throughput so

157
00:06:18,720 --> 00:06:21,520
we use code cache to avoid redundant

158
00:06:21,520 --> 00:06:23,199
combination of the

159
00:06:23,199 --> 00:06:25,120
past constituents so according to a

160
00:06:25,120 --> 00:06:27,280
subset of our connected request

161
00:06:27,280 --> 00:06:28,639
constraints

162
00:06:28,639 --> 00:06:31,440
if we use a code of cache then we have

163
00:06:31,440 --> 00:06:35,280
17 code cache rates but that's not

164
00:06:35,280 --> 00:06:36,319
enough

165
00:06:36,319 --> 00:06:38,880
so another observation is that we

166
00:06:38,880 --> 00:06:40,800
observe that many constraints operating

167
00:06:40,800 --> 00:06:42,720
on different data are actually doing the

168
00:06:42,720 --> 00:06:45,120
same check for example x equal to 8

169
00:06:45,120 --> 00:06:48,080
which is y equal to 16. so clearly we

170
00:06:48,080 --> 00:06:50,319
can reuse the same

171
00:06:50,319 --> 00:06:52,960
functions for these two constraints so

172
00:06:52,960 --> 00:06:56,240
after this optimization we our cash

173
00:06:56,240 --> 00:06:57,919
history

174
00:06:57,919 --> 00:07:01,199
in the data set of we collected has

175
00:07:01,199 --> 00:07:04,639
almost 100 percent and we improve the

176
00:07:04,639 --> 00:07:08,000
searching throughput a lot

177
00:07:08,479 --> 00:07:11,759
so um so let's talk about the results

178
00:07:11,759 --> 00:07:13,919
first of all uh the first series i want

179
00:07:13,919 --> 00:07:16,639
to show is about branch limit rate so we

180
00:07:16,639 --> 00:07:18,639
connect about 10 million

181
00:07:18,639 --> 00:07:21,599
listed plus constraints from 14 railway

182
00:07:21,599 --> 00:07:24,639
programs and ask each server to solve

183
00:07:24,639 --> 00:07:27,280
them and the results show that jigsaw

184
00:07:27,280 --> 00:07:29,919
can solve you know branches much faster

185
00:07:29,919 --> 00:07:32,400
than existing tools

186
00:07:32,400 --> 00:07:34,479
our comparison target includes these

187
00:07:34,479 --> 00:07:37,039
three the most popular and widely used

188
00:07:37,039 --> 00:07:41,280
uh sm smt servers and we have bid osula

189
00:07:41,280 --> 00:07:43,360
which is the winner in the smt

190
00:07:43,360 --> 00:07:46,240
competition 2020 and 20 21st

191
00:07:46,240 --> 00:07:49,199
and we have stp and yx2 in our

192
00:07:49,199 --> 00:07:52,319
comparison targets

193
00:07:52,319 --> 00:07:53,680
um

194
00:07:53,680 --> 00:07:56,560
now the reason for this achieve this

195
00:07:56,560 --> 00:07:59,039
result is that zigzag has a really high

196
00:07:59,039 --> 00:08:01,440
switching throughput so our first

197
00:08:01,440 --> 00:08:03,440
compilation target is angular this

198
00:08:03,440 --> 00:08:05,759
comparison is very interesting because

199
00:08:05,759 --> 00:08:09,360
we are using the same gradient decent

200
00:08:09,360 --> 00:08:10,400
guided

201
00:08:10,400 --> 00:08:13,120
searching algorithm and because angular

202
00:08:13,120 --> 00:08:15,039
doing you know uh

203
00:08:15,039 --> 00:08:16,879
are performing searches on the relative

204
00:08:16,879 --> 00:08:18,879
on the original whole program

205
00:08:18,879 --> 00:08:21,759
uh its throughput is not

206
00:08:21,759 --> 00:08:24,000
good

207
00:08:24,080 --> 00:08:28,080
um the second target automation is build

208
00:08:28,080 --> 00:08:31,440
ursula so uh to enable apple to apple

209
00:08:31,440 --> 00:08:32,719
comparison

210
00:08:32,719 --> 00:08:35,839
uh we configure with user in its no code

211
00:08:35,839 --> 00:08:37,679
search mode

212
00:08:37,679 --> 00:08:40,000
meaning that the user will keep trying

213
00:08:40,000 --> 00:08:41,839
different inputs using local search

214
00:08:41,839 --> 00:08:44,880
algorithms without beta blasting and the

215
00:08:44,880 --> 00:08:46,720
way measured is

216
00:08:46,720 --> 00:08:48,800
throughput meaning how many inputs can

217
00:08:48,800 --> 00:08:51,360
be tried per second and it turns out

218
00:08:51,360 --> 00:08:54,000
that jigsaw also outperform the ozarks

219
00:08:54,000 --> 00:08:55,200
in this

220
00:08:55,200 --> 00:08:57,839
perspective

221
00:09:00,399 --> 00:09:02,399
so after we

222
00:09:02,399 --> 00:09:04,800
obtain a much faster constituent solver

223
00:09:04,800 --> 00:09:08,080
if we plug this to the concolic executor

224
00:09:08,080 --> 00:09:10,399
we can improve the performance of

225
00:09:10,399 --> 00:09:12,160
concolic executor

226
00:09:12,160 --> 00:09:14,399
and in this experiment

227
00:09:14,399 --> 00:09:17,760
we paired jigsaw with our own improved

228
00:09:17,760 --> 00:09:20,640
pass constraint connector clinical

229
00:09:20,640 --> 00:09:22,640
and we compare with the simsched ccc the

230
00:09:22,640 --> 00:09:23,519
uh

231
00:09:23,519 --> 00:09:26,320
the recently published very efficient

232
00:09:26,320 --> 00:09:28,320
concur executor

233
00:09:28,320 --> 00:09:31,680
and also for the compression purpose we

234
00:09:31,680 --> 00:09:32,800
flag

235
00:09:32,800 --> 00:09:36,720
this street our improved uh clinical

236
00:09:36,720 --> 00:09:38,800
auto current income

237
00:09:38,800 --> 00:09:40,080
and

238
00:09:40,080 --> 00:09:42,560
we measured the overall execution

239
00:09:42,560 --> 00:09:44,240
symbolic concurrent

240
00:09:44,240 --> 00:09:47,360
execution time for multi programs and

241
00:09:47,360 --> 00:09:49,519
with multiple c's

242
00:09:49,519 --> 00:09:50,880
and

243
00:09:50,880 --> 00:09:52,480
the results show that

244
00:09:52,480 --> 00:09:53,360
the

245
00:09:53,360 --> 00:09:56,240
executor with jigsaw as a sewer can

246
00:09:56,240 --> 00:09:58,800
finish executing much faster than

247
00:09:58,800 --> 00:10:01,760
existing tools

248
00:10:03,200 --> 00:10:05,120
so with a very

249
00:10:05,120 --> 00:10:08,399
fast construction connector if we uh we

250
00:10:08,399 --> 00:10:10,480
also want to check if it is useful in

251
00:10:10,480 --> 00:10:12,800
the indus and fuzz testing so we

252
00:10:12,800 --> 00:10:15,680
followed a very popular fuzzing scheme

253
00:10:15,680 --> 00:10:17,440
called hybrid fuzzing we paired the

254
00:10:17,440 --> 00:10:21,839
jigsaw powered compact computer with afl

255
00:10:21,839 --> 00:10:24,079
fl plus plus by exchanging sales in the

256
00:10:24,079 --> 00:10:27,440
seed pool and we entered our two hybrid

257
00:10:27,440 --> 00:10:29,920
files to google's first bench

258
00:10:29,920 --> 00:10:31,920
benchmark and it turns out the way

259
00:10:31,920 --> 00:10:34,880
performs pretty well in this fuzzing

260
00:10:34,880 --> 00:10:37,519
benchmark

261
00:10:40,160 --> 00:10:42,959
so next i want to talk about limitations

262
00:10:42,959 --> 00:10:44,560
so

263
00:10:44,560 --> 00:10:46,800
because jigsaw is currently using the

264
00:10:46,800 --> 00:10:48,480
logo search algorithm to be more

265
00:10:48,480 --> 00:10:49,839
specific

266
00:10:49,839 --> 00:10:52,720
uh we're using the same gradient decent

267
00:10:52,720 --> 00:10:55,760
guided searching algorithm as angular

268
00:10:55,760 --> 00:10:57,839
those local search algorithm has

269
00:10:57,839 --> 00:11:00,560
limitations so to be more specific

270
00:11:00,560 --> 00:11:04,000
uh its solving capability is not

271
00:11:04,000 --> 00:11:06,880
compared to z3 so currently we can only

272
00:11:06,880 --> 00:11:12,560
solve 94 of constituents compared to c3

273
00:11:12,560 --> 00:11:14,880
in a comparison we'll also check

274
00:11:14,880 --> 00:11:18,399
uh bid ozil which is the winner again uh

275
00:11:18,399 --> 00:11:20,959
with its local search algorithm enabled

276
00:11:20,959 --> 00:11:23,760
and it has sold 97

277
00:11:23,760 --> 00:11:25,279
so i think this result is quite

278
00:11:25,279 --> 00:11:27,839
surprising to me at least that even

279
00:11:27,839 --> 00:11:30,240
though is this quite you know simple

280
00:11:30,240 --> 00:11:32,000
grading this algorithm

281
00:11:32,000 --> 00:11:36,160
uh most of constraints can be solved

282
00:11:36,720 --> 00:11:39,120
another limitation is also because of

283
00:11:39,120 --> 00:11:40,959
the local search algorithm we cannot

284
00:11:40,959 --> 00:11:44,000
identify unset queries meaning that we

285
00:11:44,000 --> 00:11:47,120
can only keep searching until we reach

286
00:11:47,120 --> 00:11:49,680
timeout

287
00:11:50,639 --> 00:11:52,560
i want to emphasize that this

288
00:11:52,560 --> 00:11:54,639
limitations

289
00:11:54,639 --> 00:11:56,399
is because the algorithm we use is

290
00:11:56,399 --> 00:11:58,639
orthogonal to a digital and it can be

291
00:11:58,639 --> 00:12:01,920
fixed by priority so it's more otherwise

292
00:12:01,920 --> 00:12:04,399
algorithms

293
00:12:04,399 --> 00:12:07,360
uh so finally the takeaways so first of

294
00:12:07,360 --> 00:12:08,720
all what is a jigsaw just so it's

295
00:12:08,720 --> 00:12:10,639
basically an efficient and scalable past

296
00:12:10,639 --> 00:12:12,240
constraints or

297
00:12:12,240 --> 00:12:16,399
um it improves concurrent execution

298
00:12:16,399 --> 00:12:18,399
so the way jigsaw doing this is using

299
00:12:18,399 --> 00:12:20,399
in-memory just-in-time combination of

300
00:12:20,399 --> 00:12:22,320
the past constraints

301
00:12:22,320 --> 00:12:24,880
and doing gradient descent searching on

302
00:12:24,880 --> 00:12:27,839
compiled little functions

303
00:12:27,839 --> 00:12:30,639
and our tool is open source and you're

304
00:12:30,639 --> 00:12:33,200
most welcome to try the two and reach us

305
00:12:33,200 --> 00:12:37,200
if you have any question

306
00:12:37,279 --> 00:12:39,360
uh with that being said i like to

307
00:12:39,360 --> 00:12:41,519
conclude today's talk and i'm happy to

308
00:12:41,519 --> 00:12:44,800
take any question thank you

309
00:12:48,240 --> 00:12:51,200
thank you very interesting work so any

310
00:12:51,200 --> 00:12:54,639
questions that you'd like to ask

311
00:12:54,800 --> 00:12:56,880
okay i will start with a question

312
00:12:56,880 --> 00:12:58,880
so um i just wonder how do you think

313
00:12:58,880 --> 00:13:02,320
about jigsaw versus z3 because like z3

314
00:13:02,320 --> 00:13:03,360
is a

315
00:13:03,360 --> 00:13:06,240
known constraint solver so comparing to

316
00:13:06,240 --> 00:13:09,920
d3 what is the problem counts of jigsaw

317
00:13:09,920 --> 00:13:12,480
what is the pro and count like advantage

318
00:13:12,480 --> 00:13:14,639
and the disadvantage of jigsaw is that

319
00:13:14,639 --> 00:13:15,920
right that

320
00:13:15,920 --> 00:13:17,360
jigsaw

321
00:13:17,360 --> 00:13:19,760
reaches better efficiency but probably

322
00:13:19,760 --> 00:13:21,200
sacrifice the

323
00:13:21,200 --> 00:13:23,839
say like general uh generosity or what

324
00:13:23,839 --> 00:13:25,760
do you think about that yes jigsaw can

325
00:13:25,760 --> 00:13:28,399
do in uh can flip soaring branches much

326
00:13:28,399 --> 00:13:31,040
faster more efficient and scalable

327
00:13:31,040 --> 00:13:33,200
the downside is that because of our

328
00:13:33,200 --> 00:13:36,320
current prototype using gradient decent

329
00:13:36,320 --> 00:13:38,000
algorithm which is really not even

330
00:13:38,000 --> 00:13:39,920
simple algorithm we

331
00:13:39,920 --> 00:13:42,079
kind of have limited solving capability

332
00:13:42,079 --> 00:13:44,480
means meaning that it cannot

333
00:13:44,480 --> 00:13:46,480
solve every constraint that's solved by

334
00:13:46,480 --> 00:13:49,040
this tree yeah i see interesting and do

335
00:13:49,040 --> 00:13:51,040
you think that jigsaw will be something

336
00:13:51,040 --> 00:13:52,800
that is more of a

337
00:13:52,800 --> 00:13:54,240
fuzzing

338
00:13:54,240 --> 00:13:57,279
um unique or fuzzing specific constraint

339
00:13:57,279 --> 00:13:58,560
solver or

340
00:13:58,560 --> 00:14:00,079
there is also other possible

341
00:14:00,079 --> 00:14:01,920
applications that jigsaw can apply to

342
00:14:01,920 --> 00:14:04,480
given this kind of property of jigsaw

343
00:14:04,480 --> 00:14:07,360
currently only tried to let it

344
00:14:07,360 --> 00:14:10,079
just also solve past constraints so we

345
00:14:10,079 --> 00:14:11,920
only tried is

346
00:14:11,920 --> 00:14:15,680
you know utility in in in the fuzzing so

347
00:14:15,680 --> 00:14:18,399
yeah okay yeah sounds great thank you

348
00:14:18,399 --> 00:14:20,320
thank you oh we have one more question

349
00:14:20,320 --> 00:14:22,240
over there hi this was a great

350
00:14:22,240 --> 00:14:24,000
presentation great job

351
00:14:24,000 --> 00:14:27,360
one question i had was

352
00:14:27,360 --> 00:14:29,440
my understanding of angora is it does

353
00:14:29,440 --> 00:14:31,120
not handle nested constraints joint

354
00:14:31,120 --> 00:14:32,880
constraint optimization in which they

355
00:14:32,880 --> 00:14:34,160
produce a follow-up work called

356
00:14:34,160 --> 00:14:37,360
matryoshka yeah yeah yeah yes does yours

357
00:14:37,360 --> 00:14:38,959
build upon this joint constraint

358
00:14:38,959 --> 00:14:41,279
optimization or when you say branch flip

359
00:14:41,279 --> 00:14:43,040
uh i guess when you say path constraint

360
00:14:43,040 --> 00:14:44,320
are you solving the whole constraint or

361
00:14:44,320 --> 00:14:46,320
just yeah i'm assuming the listed

362
00:14:46,320 --> 00:14:49,279
necessary questions in jigsaw where you

363
00:14:49,279 --> 00:14:50,399
we're using

364
00:14:50,399 --> 00:14:53,760
the joint of randomization currently

365
00:14:53,760 --> 00:14:56,720
mentioned in that metric paper to use of

366
00:14:56,720 --> 00:14:59,120
this necessity the constraints so you're

367
00:14:59,120 --> 00:15:01,680
solving joint constraints yes yes

368
00:15:01,680 --> 00:15:04,639
strategy you're also getting 94

369
00:15:04,639 --> 00:15:05,440
yes

370
00:15:05,440 --> 00:15:09,279
yes cool thank you thank you thanks

371
00:15:09,680 --> 00:15:12,959
um so i have a question about um jigsaw

372
00:15:12,959 --> 00:15:16,079
not being able to say when a uh formula

373
00:15:16,079 --> 00:15:18,880
is not satisfiable i can only say that

374
00:15:18,880 --> 00:15:19,920
it is

375
00:15:19,920 --> 00:15:21,519
so when you plug jigsaw into the

376
00:15:21,519 --> 00:15:23,279
concordat execution framework how do you

377
00:15:23,279 --> 00:15:25,360
deal with the fact that for formulas

378
00:15:25,360 --> 00:15:27,680
that are not satisfiable it will keep

379
00:15:27,680 --> 00:15:29,839
going forever i presume do you just put

380
00:15:29,839 --> 00:15:31,279
a timeout yeah i've been doing the

381
00:15:31,279 --> 00:15:33,839
camera so uh we're using similar

382
00:15:33,839 --> 00:15:36,560
timeouts as angular does uh so

383
00:15:36,560 --> 00:15:38,959
currently in our evaluation we try

384
00:15:38,959 --> 00:15:41,920
different configurations so we tried uh

385
00:15:41,920 --> 00:15:44,480
first of all try the one million uh

386
00:15:44,480 --> 00:15:47,360
iterations as a timeout to evaluate the

387
00:15:47,360 --> 00:15:50,000
solving capability and to evaluate

388
00:15:50,000 --> 00:15:52,399
efficiency we tried one thousand

389
00:15:52,399 --> 00:15:54,880
iterations as the time out because

390
00:15:54,880 --> 00:15:55,680
that's

391
00:15:55,680 --> 00:15:58,639
uh the uh dissimilar time also used by

392
00:15:58,639 --> 00:16:00,079
angular and also

393
00:16:00,079 --> 00:16:01,519
uh we

394
00:16:01,519 --> 00:16:03,120
and also we checked that most

395
00:16:03,120 --> 00:16:04,959
constraints can be solved in 1000

396
00:16:04,959 --> 00:16:06,160
iterations

397
00:16:06,160 --> 00:16:09,399
thank you

398
00:16:09,920 --> 00:16:11,920
hi a really interesting work um i have a

399
00:16:11,920 --> 00:16:14,079
question actually not direct related to

400
00:16:14,079 --> 00:16:16,720
jigsaw so just one just wondering uh

401
00:16:16,720 --> 00:16:18,000
could you share

402
00:16:18,000 --> 00:16:20,480
like a concrete example one angle or a

403
00:16:20,480 --> 00:16:24,079
gradient descent failed to solve the

404
00:16:24,079 --> 00:16:25,680
constraint

405
00:16:25,680 --> 00:16:28,880
even the example of fail filter solved

406
00:16:28,880 --> 00:16:30,800
in history you mentioned the one of the

407
00:16:30,800 --> 00:16:32,880
jigsaw's limitation is because angora's

408
00:16:32,880 --> 00:16:35,440
naive grenadine descent algorithm yes

409
00:16:35,440 --> 00:16:36,959
i'm wondering could you like share just

410
00:16:36,959 --> 00:16:39,519
one concrete example

411
00:16:39,519 --> 00:16:41,839
for the time what kind of smd constraint

412
00:16:41,839 --> 00:16:42,800
like as

413
00:16:42,800 --> 00:16:45,440
angora's green descent fail to solve oh

414
00:16:45,440 --> 00:16:48,720
yes uh so um first of all uh green

415
00:16:48,720 --> 00:16:51,759
decent cannot handle bitwise

416
00:16:51,759 --> 00:16:53,360
operation pretty well so you can mention

417
00:16:53,360 --> 00:16:55,920
that with bitwise for example

418
00:16:55,920 --> 00:16:59,839
xr we do not have gradient right so for

419
00:16:59,839 --> 00:17:01,440
those kind of operations we cannot

420
00:17:01,440 --> 00:17:04,880
handle it very well and also for our uh

421
00:17:04,880 --> 00:17:07,039
for construction data involves uh

422
00:17:07,039 --> 00:17:08,160
division

423
00:17:08,160 --> 00:17:10,400
uh instructions we will have some

424
00:17:10,400 --> 00:17:12,480
limitations um

425
00:17:12,480 --> 00:17:15,359
and another example is that when the

426
00:17:15,359 --> 00:17:18,880
so the uh so gradient decent algorithm

427
00:17:18,880 --> 00:17:20,799
works well on the

428
00:17:20,799 --> 00:17:22,160
convex

429
00:17:22,160 --> 00:17:24,720
uh constraints if so if it is not

430
00:17:24,720 --> 00:17:26,240
complex then

431
00:17:26,240 --> 00:17:28,400
you cannot handle it very well

432
00:17:28,400 --> 00:17:31,200
yeah thank you

433
00:17:31,280 --> 00:17:33,280
hi great work uh so i have a

434
00:17:33,280 --> 00:17:36,400
straightforward question uh why it is so

435
00:17:36,400 --> 00:17:39,840
efficient uh you know for its concolic

436
00:17:39,840 --> 00:17:42,559
executor uh compared with the simcc

437
00:17:42,559 --> 00:17:43,679
oakley

438
00:17:43,679 --> 00:17:46,240
uh why the i forgot the name of your

439
00:17:46,240 --> 00:17:48,160
concolic activation oh karen encore yeah

440
00:17:48,160 --> 00:17:50,320
yeah yeah what's uh what's the key

441
00:17:50,320 --> 00:17:51,840
difference there

442
00:17:51,840 --> 00:17:54,559
uh compared to cincinnati yeah yeah uh

443
00:17:54,559 --> 00:17:56,640
we observed that some there are some

444
00:17:56,640 --> 00:17:58,720
botanic scenes in cc for example when

445
00:17:58,720 --> 00:18:00,880
they uh you know maintaining the

446
00:18:00,880 --> 00:18:03,520
symbolic expressions they do a lot of

447
00:18:03,520 --> 00:18:06,320
dynamic memory allocations uh they're

448
00:18:06,320 --> 00:18:09,039
using you know a smart pointer to manage

449
00:18:09,039 --> 00:18:12,160
the expressions and uh also their

450
00:18:12,160 --> 00:18:14,960
shadow memory is not implementary

451
00:18:14,960 --> 00:18:16,720
efficiently so we

452
00:18:16,720 --> 00:18:18,960
optimize those kind of mitigate those

453
00:18:18,960 --> 00:18:21,840
bottlenecks and uh have our own own tool

454
00:18:21,840 --> 00:18:24,400
okay okay thank you thank you

455
00:18:24,400 --> 00:18:26,240
all right thanks to speaker for the

456
00:18:26,240 --> 00:18:28,080
interest of time we no longer take

457
00:18:28,080 --> 00:18:29,600
questions and let's just move on to the

458
00:18:29,600 --> 00:18:32,000
next one

