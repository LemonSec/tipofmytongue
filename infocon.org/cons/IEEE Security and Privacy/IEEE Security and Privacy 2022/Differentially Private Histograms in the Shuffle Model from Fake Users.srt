1
00:00:01,520 --> 00:00:03,360
hi everyone uh thank you all for coming

2
00:00:03,360 --> 00:00:04,799
today

3
00:00:04,799 --> 00:00:06,399
uh so

4
00:00:06,399 --> 00:00:09,040
what's the big picture of this talk well

5
00:00:09,040 --> 00:00:11,120
dp is well studied in local and central

6
00:00:11,120 --> 00:00:12,960
models but today we're going to focus on

7
00:00:12,960 --> 00:00:15,920
the newer shuffle model

8
00:00:15,920 --> 00:00:18,560
in this model like uh earlier protocols

9
00:00:18,560 --> 00:00:20,640
for histograms demanded many messages

10
00:00:20,640 --> 00:00:22,160
from users

11
00:00:22,160 --> 00:00:24,240
our work reduces that cost and we

12
00:00:24,240 --> 00:00:25,840
discover a neat side effect of that

13
00:00:25,840 --> 00:00:28,400
reduction

14
00:00:28,880 --> 00:00:30,800
so to set up this talk i'll define some

15
00:00:30,800 --> 00:00:32,880
terms uh well

16
00:00:32,880 --> 00:00:34,719
users are going to be human beings so

17
00:00:34,719 --> 00:00:36,800
some raw personal data

18
00:00:36,800 --> 00:00:39,600
that we want to keep private

19
00:00:39,600 --> 00:00:42,719
and an analyzer is something or someone

20
00:00:42,719 --> 00:00:44,640
who wants statistics

21
00:00:44,640 --> 00:00:47,520
which concern the population

22
00:00:47,520 --> 00:00:49,039
and we'll consider an adversary who

23
00:00:49,039 --> 00:00:52,879
wants data on a individual level

24
00:00:52,960 --> 00:00:55,360
right so given this terminology uh

25
00:00:55,360 --> 00:00:57,039
let's define differential privacy well

26
00:00:57,039 --> 00:00:58,800
loosely speaking it ensures that an

27
00:00:58,800 --> 00:01:00,160
adversary's view

28
00:01:00,160 --> 00:01:03,520
is insensitive to any one user

29
00:01:03,520 --> 00:01:04,959
so we'll consider two data sets to be

30
00:01:04,959 --> 00:01:06,080
neighboring if they differ from one

31
00:01:06,080 --> 00:01:08,320
user's data and the protocol is going to

32
00:01:08,320 --> 00:01:10,000
be differentiate private

33
00:01:10,000 --> 00:01:12,640
uh if for all like neighboring inputs

34
00:01:12,640 --> 00:01:14,880
and for all outcomes

35
00:01:14,880 --> 00:01:17,040
uh the likelihood of that outcome

36
00:01:17,040 --> 00:01:18,720
changes only slightly when we change

37
00:01:18,720 --> 00:01:20,799
inputs

38
00:01:20,799 --> 00:01:22,240
all right so

39
00:01:22,240 --> 00:01:23,600
the slight change is quantified by

40
00:01:23,600 --> 00:01:25,600
epsilon and delta which is a hybrid

41
00:01:25,600 --> 00:01:28,320
multiplicative additive bound

42
00:01:28,320 --> 00:01:30,720
but the question uh

43
00:01:30,720 --> 00:01:32,960
we have to ask is like how is this

44
00:01:32,960 --> 00:01:34,640
protocol structured

45
00:01:34,640 --> 00:01:36,479
and who generates that view that we're

46
00:01:36,479 --> 00:01:40,119
going to be looking at

47
00:01:40,720 --> 00:01:42,159
right so in our work we studied the

48
00:01:42,159 --> 00:01:44,720
shuffle model uh it has its roots in

49
00:01:44,720 --> 00:01:46,960
batodol and was formally defined in my

50
00:01:46,960 --> 00:01:48,079
work

51
00:01:48,079 --> 00:01:49,920
while we modeled the analyzer as being

52
00:01:49,920 --> 00:01:51,680
untrustworthy the adversary could

53
00:01:51,680 --> 00:01:52,960
control it

54
00:01:52,960 --> 00:01:54,399
which means users perform local

55
00:01:54,399 --> 00:01:57,920
randomization to protect their data

56
00:01:57,920 --> 00:01:59,600
but unlike the local model which you saw

57
00:01:59,600 --> 00:02:02,240
previously there's also a service or

58
00:02:02,240 --> 00:02:04,719
functionality called the shuffler

59
00:02:04,719 --> 00:02:06,960
it takes in the end user messages

60
00:02:06,960 --> 00:02:10,878
and applies a random permutation to them

61
00:02:10,878 --> 00:02:12,080
right so it's like you're dropping off

62
00:02:12,080 --> 00:02:14,000
envelopes in the mailbox and processing

63
00:02:14,000 --> 00:02:16,400
random order

64
00:02:16,400 --> 00:02:18,080
well the important thing

65
00:02:18,080 --> 00:02:20,160
is that we designed the randomizer such

66
00:02:20,160 --> 00:02:21,760
that the

67
00:02:21,760 --> 00:02:24,319
this big box is privacy preserving uh n

68
00:02:24,319 --> 00:02:26,720
executions of the randomizer followed by

69
00:02:26,720 --> 00:02:28,400
a shuffle

70
00:02:28,400 --> 00:02:30,720
uh unlike local privacy we don't care

71
00:02:30,720 --> 00:02:33,280
how private r is on its own

72
00:02:33,280 --> 00:02:34,800
uh we only care about the composition of

73
00:02:34,800 --> 00:02:38,720
shuffling and privatization

74
00:02:39,040 --> 00:02:40,319
notice that we're allowing multiple

75
00:02:40,319 --> 00:02:41,440
messages

76
00:02:41,440 --> 00:02:43,680
from each user so everybody drops off

77
00:02:43,680 --> 00:02:47,280
multiple envelopes in them by box

78
00:02:49,680 --> 00:02:51,599
right of course well we like to keep the

79
00:02:51,599 --> 00:02:53,360
volume down because that's like

80
00:02:53,360 --> 00:02:55,519
communication cost

81
00:02:55,519 --> 00:02:57,440
so that's like one thing we want to

82
00:02:57,440 --> 00:02:59,760
measure

83
00:02:59,760 --> 00:03:01,440
of course like why should we study this

84
00:03:01,440 --> 00:03:04,239
model of all possible models well

85
00:03:04,239 --> 00:03:06,400
there's existing literature on shuffling

86
00:03:06,400 --> 00:03:08,159
uh ranging from mixnets and anonymous

87
00:03:08,159 --> 00:03:11,360
communication more generally

88
00:03:11,360 --> 00:03:13,280
and of course anonymity is inherently

89
00:03:13,280 --> 00:03:14,959
appealing to users like if you want to

90
00:03:14,959 --> 00:03:17,120
sell something or a product to your user

91
00:03:17,120 --> 00:03:20,720
base anonymity is a nice thing to have

92
00:03:20,720 --> 00:03:22,239
and the final more theoretically

93
00:03:22,239 --> 00:03:24,080
interesting property is that shuffling

94
00:03:24,080 --> 00:03:26,319
bits is like the same as adding bits or

95
00:03:26,319 --> 00:03:27,920
counting

96
00:03:27,920 --> 00:03:29,680
this is very neat because

97
00:03:29,680 --> 00:03:31,599
it implies easy deployment of some

98
00:03:31,599 --> 00:03:34,798
centrally private algorithms

99
00:03:36,080 --> 00:03:38,959
okay so i've defined the shuffle model

100
00:03:38,959 --> 00:03:40,080
but what's the problem i'm going to

101
00:03:40,080 --> 00:03:41,200
solve

102
00:03:41,200 --> 00:03:42,879
it's called histograms

103
00:03:42,879 --> 00:03:44,799
and in this problem each user has some

104
00:03:44,799 --> 00:03:47,120
discrete value

105
00:03:47,120 --> 00:03:49,519
and the goal is to privately estimate

106
00:03:49,519 --> 00:03:52,000
the counts of each domain element

107
00:03:52,000 --> 00:03:53,599
so every j in

108
00:03:53,599 --> 00:03:56,319
j in a set one through d

109
00:03:56,319 --> 00:03:58,640
and so we'll try to minimize minimize l

110
00:03:58,640 --> 00:04:01,599
infinity norm which is the maximum error

111
00:04:01,599 --> 00:04:04,238
of any bin

112
00:04:05,439 --> 00:04:07,360
all right so

113
00:04:07,360 --> 00:04:09,840
the question we'll explore is can we get

114
00:04:09,840 --> 00:04:12,239
low error private histograms in this new

115
00:04:12,239 --> 00:04:13,280
model

116
00:04:13,280 --> 00:04:15,280
and can we do so using a few messages

117
00:04:15,280 --> 00:04:17,199
per user

118
00:04:17,199 --> 00:04:19,120
and just to clarify by low error i mean

119
00:04:19,120 --> 00:04:21,759
like polynomial and one over this

120
00:04:21,759 --> 00:04:26,000
privacy parameter and like log terms

121
00:04:27,360 --> 00:04:29,919
all right so the answer is yes uh we

122
00:04:29,919 --> 00:04:32,960
demand only uh two messages per user

123
00:04:32,960 --> 00:04:35,840
one n is sufficiently large

124
00:04:35,840 --> 00:04:38,320
and a side effect is that the estimates

125
00:04:38,320 --> 00:04:40,880
are robust to malicious users

126
00:04:40,880 --> 00:04:45,520
uh who wants to bias the computation

127
00:04:47,600 --> 00:04:49,120
all right so

128
00:04:49,120 --> 00:04:51,040
that's the answer to our question but

129
00:04:51,040 --> 00:04:52,960
just to put things in context let's

130
00:04:52,960 --> 00:04:55,840
compare our work for some prior work

131
00:04:55,840 --> 00:04:57,680
and probably work with victor balzer i

132
00:04:57,680 --> 00:05:00,160
have a protocol for with d messages per

133
00:05:00,160 --> 00:05:02,000
user which is very large because that's

134
00:05:02,000 --> 00:05:03,759
the number of bins

135
00:05:03,759 --> 00:05:06,000
this was improved by work uh by gaussian

136
00:05:06,000 --> 00:05:08,960
doll down to polylog d

137
00:05:08,960 --> 00:05:11,520
but then the same roughly the same team

138
00:05:11,520 --> 00:05:13,199
got the result that was vanishing with n

139
00:05:13,199 --> 00:05:14,960
so as you increase the number of users

140
00:05:14,960 --> 00:05:16,560
the number of messages per user actually

141
00:05:16,560 --> 00:05:17,840
goes down

142
00:05:17,840 --> 00:05:19,759
uh but there is like a linear indeed

143
00:05:19,759 --> 00:05:22,320
term which is not that good and in our

144
00:05:22,320 --> 00:05:24,880
work we get best of both

145
00:05:24,880 --> 00:05:26,479
we have a poly logarithmic dependence on

146
00:05:26,479 --> 00:05:31,120
d and like a vanishing of n uh property

147
00:05:33,199 --> 00:05:35,199
right so for the rest of the talk i'll

148
00:05:35,199 --> 00:05:36,960
explore like what this protocol exactly

149
00:05:36,960 --> 00:05:39,680
is the experiments and a robustness

150
00:05:39,680 --> 00:05:42,800
property that the protocol has

151
00:05:42,800 --> 00:05:45,039
so without further ado let's look at the

152
00:05:45,039 --> 00:05:46,320
protocol

153
00:05:46,320 --> 00:05:47,440
so

154
00:05:47,440 --> 00:05:49,680
in our protocol like each user will do

155
00:05:49,680 --> 00:05:51,360
the following

156
00:05:51,360 --> 00:05:53,600
they'll encode their value as a one hot

157
00:05:53,600 --> 00:05:54,639
string

158
00:05:54,639 --> 00:05:58,319
the position of one is their value

159
00:05:58,400 --> 00:06:00,080
then they flip each bit with a small

160
00:06:00,080 --> 00:06:02,000
probability so in the local privacy

161
00:06:02,000 --> 00:06:06,000
letter that's called randomized response

162
00:06:06,000 --> 00:06:07,440
the next step is to construct extra

163
00:06:07,440 --> 00:06:09,600
strings of all zeros

164
00:06:09,600 --> 00:06:10,880
and then repeat the bit flipping

165
00:06:10,880 --> 00:06:13,440
procedure

166
00:06:13,600 --> 00:06:15,520
right so in other words like

167
00:06:15,520 --> 00:06:18,319
each user makes k fake users who each

168
00:06:18,319 --> 00:06:20,080
have a zero string and then we just

169
00:06:20,080 --> 00:06:21,840
apply the randomized response to all

170
00:06:21,840 --> 00:06:23,520
strings

171
00:06:23,520 --> 00:06:24,880
right when we're sending all these

172
00:06:24,880 --> 00:06:26,479
strings to the shuffler who then sends

173
00:06:26,479 --> 00:06:28,160
it on to the analyzer

174
00:06:28,160 --> 00:06:30,160
who then computes some estimate based on

175
00:06:30,160 --> 00:06:33,639
this set of strings

176
00:06:34,000 --> 00:06:35,680
all right so it's a somewhat

177
00:06:35,680 --> 00:06:38,080
straightforward protocol but

178
00:06:38,080 --> 00:06:40,080
like how do we choose parameters for

179
00:06:40,080 --> 00:06:42,960
privacy like why is it private

180
00:06:42,960 --> 00:06:44,479
well without loss of generality let's

181
00:06:44,479 --> 00:06:47,120
look at like two neighboring inputs well

182
00:06:47,120 --> 00:06:49,440
in one input i have a one and the other

183
00:06:49,440 --> 00:06:51,199
would have a two and everybody else is

184
00:06:51,199 --> 00:06:54,000
the same in both data sets

185
00:06:54,000 --> 00:06:56,319
and so that notice that if we give x to

186
00:06:56,319 --> 00:06:59,039
the protocol uh the first user encodes

187
00:06:59,039 --> 00:07:01,599
one as a one hot string one followed by

188
00:07:01,599 --> 00:07:02,720
zeros

189
00:07:02,720 --> 00:07:04,400
in the neighboring data set we have a

190
00:07:04,400 --> 00:07:07,039
zero one followed by zeros so like we

191
00:07:07,039 --> 00:07:08,400
change one user

192
00:07:08,400 --> 00:07:11,199
they change their encoding

193
00:07:11,199 --> 00:07:13,199
and like fake users in either case they

194
00:07:13,199 --> 00:07:14,880
encode the zero as like a string of all

195
00:07:14,880 --> 00:07:17,120
zeros right

196
00:07:17,120 --> 00:07:19,840
uh but and but these strings are not

197
00:07:19,840 --> 00:07:21,360
sent to the shuffler uh they get

198
00:07:21,360 --> 00:07:23,199
randomized first

199
00:07:23,199 --> 00:07:25,680
so like what happens well the one gets

200
00:07:25,680 --> 00:07:27,840
mapped to bring nearly one minus q and

201
00:07:27,840 --> 00:07:30,160
zeros get mapped to a bernoulli queue so

202
00:07:30,160 --> 00:07:32,000
this is what the first user sends it's a

203
00:07:32,000 --> 00:07:34,479
one long string that's randomized

204
00:07:34,479 --> 00:07:35,599
and then

205
00:07:35,599 --> 00:07:37,599
the in the other case using one sends a

206
00:07:37,599 --> 00:07:39,680
different randomization we just shift

207
00:07:39,680 --> 00:07:42,400
the bias position

208
00:07:42,400 --> 00:07:45,199
and in both cases the fake user sends a

209
00:07:45,199 --> 00:07:47,919
message from uh the product distribution

210
00:07:47,919 --> 00:07:50,319
uh bernoulli queue

211
00:07:50,319 --> 00:07:52,560
all right so these are messages sent by

212
00:07:52,560 --> 00:07:54,800
each user

213
00:07:54,800 --> 00:07:58,000
now notice that like the suffix of each

214
00:07:58,000 --> 00:07:59,520
message is like basically the same

215
00:07:59,520 --> 00:08:00,800
distribution

216
00:08:00,800 --> 00:08:03,520
they contain no information about the

217
00:08:03,520 --> 00:08:05,919
user data so it's safe to ignore the

218
00:08:05,919 --> 00:08:07,759
suffix

219
00:08:07,759 --> 00:08:09,759
right the coins do not depend on user

220
00:08:09,759 --> 00:08:12,560
data so we ignore them

221
00:08:12,560 --> 00:08:14,879
but also notice that on

222
00:08:14,879 --> 00:08:16,639
the first input

223
00:08:16,639 --> 00:08:20,160
the mode of the message is one zero

224
00:08:20,160 --> 00:08:22,160
and on the other input the mode is zero

225
00:08:22,160 --> 00:08:23,919
one

226
00:08:23,919 --> 00:08:26,000
and we focus on the mode because that

227
00:08:26,000 --> 00:08:27,440
ends up being the hard case with the

228
00:08:27,440 --> 00:08:30,240
venture privacy

229
00:08:31,120 --> 00:08:32,799
right so

230
00:08:32,799 --> 00:08:34,719
given this like how does our privacy

231
00:08:34,719 --> 00:08:36,880
analysis work well we saw the

232
00:08:36,880 --> 00:08:38,799
observation that uh the shell first

233
00:08:38,799 --> 00:08:41,279
output is determined by counts

234
00:08:41,279 --> 00:08:42,080
so

235
00:08:42,080 --> 00:08:44,080
it's another collection of messages so

236
00:08:44,080 --> 00:08:47,279
all we really have are a histogram of

237
00:08:47,279 --> 00:08:49,120
value frequency the frequency of

238
00:08:49,120 --> 00:08:50,640
messages

239
00:08:50,640 --> 00:08:52,399
and so we can represent this as like a

240
00:08:52,399 --> 00:08:55,200
bar chart or a histogram

241
00:08:55,200 --> 00:08:57,120
and again like i note that we have two

242
00:08:57,120 --> 00:08:59,440
different inputs neighboring and the

243
00:08:59,440 --> 00:09:01,600
hard case is where we have the modes you

244
00:09:01,600 --> 00:09:04,720
know each user reports the mode

245
00:09:04,720 --> 00:09:06,800
and this is 0 1 0

246
00:09:06,800 --> 00:09:10,240
on input x and zero one on input x prime

247
00:09:10,240 --> 00:09:11,839
we also have fake users contributing

248
00:09:11,839 --> 00:09:13,839
messages so we'll draw them as purple

249
00:09:13,839 --> 00:09:15,040
bars

250
00:09:15,040 --> 00:09:19,040
and these are random values

251
00:09:19,200 --> 00:09:20,800
and the second observation we have is

252
00:09:20,800 --> 00:09:22,800
that well the odds that fake user

253
00:09:22,800 --> 00:09:25,360
reports zero one is the same as the odds

254
00:09:25,360 --> 00:09:27,600
their point one zero

255
00:09:27,600 --> 00:09:30,240
right so it's a 50 50 or a fair coin

256
00:09:30,240 --> 00:09:33,200
which bar they end up being in

257
00:09:33,200 --> 00:09:35,839
so when there are m fake users reporting

258
00:09:35,839 --> 00:09:38,320
one of these two values

259
00:09:38,320 --> 00:09:40,399
the count of zero one is going to be a

260
00:09:40,399 --> 00:09:41,760
binomial

261
00:09:41,760 --> 00:09:43,760
m comma one half

262
00:09:43,760 --> 00:09:46,080
right so because you have m people

263
00:09:46,080 --> 00:09:47,920
flipping of your coin this is what the

264
00:09:47,920 --> 00:09:49,760
frequency is end up being

265
00:09:49,760 --> 00:09:52,319
ends up being

266
00:09:52,399 --> 00:09:54,720
all right so we have this binomial

267
00:09:54,720 --> 00:09:56,880
distribution so why is this interesting

268
00:09:56,880 --> 00:09:58,800
well it's interesting because of the

269
00:09:58,800 --> 00:10:00,320
following reason

270
00:10:00,320 --> 00:10:02,560
adding this noise to account ensures

271
00:10:02,560 --> 00:10:04,720
differential privacy well

272
00:10:04,720 --> 00:10:07,680
whenever this m parameter is

273
00:10:07,680 --> 00:10:11,839
large relative to privacy parameters

274
00:10:12,160 --> 00:10:14,000
all right so all we have to do is ensure

275
00:10:14,000 --> 00:10:15,600
that m is large

276
00:10:15,600 --> 00:10:17,680
and in our protocol recall that m is the

277
00:10:17,680 --> 00:10:19,360
number of fake users

278
00:10:19,360 --> 00:10:23,920
who send either 0 1 or 1 0.

279
00:10:24,880 --> 00:10:27,760
this happens with a known probability

280
00:10:27,760 --> 00:10:29,839
for each fake user we can just look at

281
00:10:29,839 --> 00:10:33,680
the distribution that we created earlier

282
00:10:33,680 --> 00:10:35,839
and by linearity the expectation is

283
00:10:35,839 --> 00:10:37,680
going to be this

284
00:10:37,680 --> 00:10:40,079
somewhat simple expression

285
00:10:40,079 --> 00:10:41,839
but the point is that this

286
00:10:41,839 --> 00:10:43,920
random variable is concentrated around

287
00:10:43,920 --> 00:10:46,160
the expectation so when the number of

288
00:10:46,160 --> 00:10:48,399
users is large

289
00:10:48,399 --> 00:10:50,800
the number of fake users per real user

290
00:10:50,800 --> 00:10:53,200
can be any positive value

291
00:10:53,200 --> 00:10:55,680
and then we'll set q to be

292
00:10:55,680 --> 00:10:57,120
this appropriate value which ends up

293
00:10:57,120 --> 00:10:59,120
being like 1 over n k

294
00:10:59,120 --> 00:11:00,800
so one over number of

295
00:11:00,800 --> 00:11:03,040
number of real users times number of

296
00:11:03,040 --> 00:11:06,240
fake users per real user

297
00:11:06,560 --> 00:11:08,640
all right so that's the settings for

298
00:11:08,640 --> 00:11:10,880
differential privacy but like how do we

299
00:11:10,880 --> 00:11:12,720
actually compute with this

300
00:11:12,720 --> 00:11:14,560
set of strings

301
00:11:14,560 --> 00:11:16,160
well remember that the shuffler sends a

302
00:11:16,160 --> 00:11:18,640
bag of strings to the analyzer so we can

303
00:11:18,640 --> 00:11:20,959
compute an unbiased estimator

304
00:11:20,959 --> 00:11:21,760
from

305
00:11:21,760 --> 00:11:23,680
all these strings i won't go into

306
00:11:23,680 --> 00:11:25,360
details but suffice to say it's a linear

307
00:11:25,360 --> 00:11:26,240
function

308
00:11:26,240 --> 00:11:28,399
of t sub j where

309
00:11:28,399 --> 00:11:30,399
it's number of shuffle strings of a one

310
00:11:30,399 --> 00:11:33,200
at index j

311
00:11:34,000 --> 00:11:35,440
and the standard deviation of this

312
00:11:35,440 --> 00:11:37,120
estimator is going to be

313
00:11:37,120 --> 00:11:41,040
this function of q epsilon and delta

314
00:11:41,040 --> 00:11:43,040
the smaller the privacy parameters the

315
00:11:43,040 --> 00:11:45,120
more error you get

316
00:11:45,120 --> 00:11:47,600
but on the other hand small q leads to

317
00:11:47,600 --> 00:11:50,160
less error

318
00:11:50,880 --> 00:11:52,720
and note that this error bound is for

319
00:11:52,720 --> 00:11:53,760
one bin

320
00:11:53,760 --> 00:11:55,519
to cap the maximum error we perform a

321
00:11:55,519 --> 00:11:57,920
union bound over d so we get a log d

322
00:11:57,920 --> 00:12:00,160
term

323
00:12:01,040 --> 00:12:03,200
and now remember that q was said to be

324
00:12:03,200 --> 00:12:06,079
something vanishing with one over n k

325
00:12:06,079 --> 00:12:07,440
and if you plug it back into this

326
00:12:07,440 --> 00:12:10,959
expression it's n k over this function

327
00:12:10,959 --> 00:12:13,279
but the upshot is that

328
00:12:13,279 --> 00:12:17,440
if i increase the number of fake users k

329
00:12:17,440 --> 00:12:18,160
we

330
00:12:18,160 --> 00:12:21,279
we reduce the scale of error so this

331
00:12:21,279 --> 00:12:25,680
factor approaches 1 from above

332
00:12:25,680 --> 00:12:27,440
right so this is an interesting property

333
00:12:27,440 --> 00:12:29,760
which bears out in the experiments

334
00:12:29,760 --> 00:12:32,240
so what exactly are experiments

335
00:12:32,240 --> 00:12:33,839
well to start off we downloaded a list

336
00:12:33,839 --> 00:12:35,680
of english words and then a set of

337
00:12:35,680 --> 00:12:37,760
tweets from prior work sampling one word

338
00:12:37,760 --> 00:12:39,040
per tweet

339
00:12:39,040 --> 00:12:40,560
and then we ran this fake user protocol

340
00:12:40,560 --> 00:12:42,880
with varying choices of k

341
00:12:42,880 --> 00:12:44,560
and for this fixed set of privacy

342
00:12:44,560 --> 00:12:45,920
parameters

343
00:12:45,920 --> 00:12:47,360
and then we also simulated an earlier

344
00:12:47,360 --> 00:12:50,399
protocol the same epsilon delta

345
00:12:50,399 --> 00:12:52,399
and as we expected increasing the count

346
00:12:52,399 --> 00:12:55,360
of fake users reduces the error up to a

347
00:12:55,360 --> 00:12:56,959
point because it starts approach one

348
00:12:56,959 --> 00:12:59,120
from above and so it levels off at

349
00:12:59,120 --> 00:13:01,120
around four but the change is still

350
00:13:01,120 --> 00:13:03,680
noticeable

351
00:13:04,000 --> 00:13:06,000
and we also compare two protocols uh the

352
00:13:06,000 --> 00:13:08,079
prior work has worse error in our

353
00:13:08,079 --> 00:13:09,120
experiments

354
00:13:09,120 --> 00:13:10,800
it's an order of magnitude worse uh this

355
00:13:10,800 --> 00:13:12,240
comes from the fact that the prior work

356
00:13:12,240 --> 00:13:14,639
was designed for a large d

357
00:13:14,639 --> 00:13:15,839
uh but in our case like the

358
00:13:15,839 --> 00:13:17,760
dimensionality was smaller than one over

359
00:13:17,760 --> 00:13:20,240
delta so our protocol does better in our

360
00:13:20,240 --> 00:13:22,800
experiments

361
00:13:23,040 --> 00:13:25,519
uh let's close off a robustness property

362
00:13:25,519 --> 00:13:28,079
so what is robustness well

363
00:13:28,079 --> 00:13:29,680
we're imagining

364
00:13:29,680 --> 00:13:31,920
a user who is malicious they can send

365
00:13:31,920 --> 00:13:34,320
arbitrary messages to the shuffler which

366
00:13:34,320 --> 00:13:35,760
will affect their computation performed

367
00:13:35,760 --> 00:13:37,360
by the analyzer

368
00:13:37,360 --> 00:13:38,720
obviously

369
00:13:38,720 --> 00:13:40,720
so as a baseline example you can run the

370
00:13:40,720 --> 00:13:43,839
randomizer on value one which means it's

371
00:13:43,839 --> 00:13:45,360
gonna be some bias towards one when

372
00:13:45,360 --> 00:13:47,440
maybe there shouldn't be

373
00:13:47,440 --> 00:13:49,360
but there are potentially other ways of

374
00:13:49,360 --> 00:13:51,040
biasing the computation

375
00:13:51,040 --> 00:13:53,360
so what's the worst that can happen

376
00:13:53,360 --> 00:13:55,360
well it turns out the uh our protocol is

377
00:13:55,360 --> 00:13:57,199
robust to anything

378
00:13:57,199 --> 00:13:59,120
malicious user can do

379
00:13:59,120 --> 00:14:00,399
and this comes from the fact that we

380
00:14:00,399 --> 00:14:02,000
have an estimator that's a linear

381
00:14:02,000 --> 00:14:05,199
function of this count t sub j where

382
00:14:05,199 --> 00:14:06,959
it's number of messages that have a one

383
00:14:06,959 --> 00:14:09,360
in position j

384
00:14:09,360 --> 00:14:11,360
and the point is that each message

385
00:14:11,360 --> 00:14:13,920
shifts this counts by one right it's a

386
00:14:13,920 --> 00:14:15,120
count

387
00:14:15,120 --> 00:14:16,800
and any user sends a bounded number of

388
00:14:16,800 --> 00:14:19,839
messages k plus one messages

389
00:14:19,839 --> 00:14:21,440
so what this means that a crop user's

390
00:14:21,440 --> 00:14:23,040
influence is bounded by

391
00:14:23,040 --> 00:14:25,920
k plus one times this scaling factor

392
00:14:25,920 --> 00:14:27,279
and so this influence is a constant

393
00:14:27,279 --> 00:14:28,839
whenever k is

394
00:14:28,839 --> 00:14:32,079
small right so as long as k is small we

395
00:14:32,079 --> 00:14:35,760
have a bounded influence per user

396
00:14:36,399 --> 00:14:38,399
and so uh we also know that other

397
00:14:38,399 --> 00:14:40,000
protocols have this similar linear

398
00:14:40,000 --> 00:14:42,000
dependence on number of messages and so

399
00:14:42,000 --> 00:14:43,680
as they have more messages they have a

400
00:14:43,680 --> 00:14:45,120
worse uh

401
00:14:45,120 --> 00:14:48,160
they're less robust than malicious users

402
00:14:48,160 --> 00:14:49,760
now whether or not this is inherent is

403
00:14:49,760 --> 00:14:52,480
an interesting open question uh

404
00:14:52,480 --> 00:14:57,400
and with that i'll conclude my talk

405
00:14:57,400 --> 00:15:02,160
[Applause]

406
00:15:02,160 --> 00:15:04,160
great we have a quite a bit of time for

407
00:15:04,160 --> 00:15:06,000
questions so please if you have any

408
00:15:06,000 --> 00:15:09,360
questions step up to the podium

409
00:15:10,160 --> 00:15:12,399
so hi albert uh i wonder what's the size

410
00:15:12,399 --> 00:15:14,000
of those messages

411
00:15:14,000 --> 00:15:15,839
sorry what's that uh what's the size of

412
00:15:15,839 --> 00:15:18,240
those messages right so uh the naive

413
00:15:18,240 --> 00:15:20,000
thing i drew is like

414
00:15:20,000 --> 00:15:22,320
the size is the length of the number of

415
00:15:22,320 --> 00:15:24,639
bins okay so if you have d bins you have

416
00:15:24,639 --> 00:15:26,560
d bit string okay but in principle you

417
00:15:26,560 --> 00:15:28,800
can compress it uh because like the

418
00:15:28,800 --> 00:15:30,880
flipping rate is small so number one is

419
00:15:30,880 --> 00:15:33,120
small so you can like just send them the

420
00:15:33,120 --> 00:15:35,920
positions okay at one okay how does that

421
00:15:35,920 --> 00:15:37,519
compare to the naive scheme if you

422
00:15:37,519 --> 00:15:39,759
compress it how

423
00:15:39,759 --> 00:15:41,839
what will be the um for example the

424
00:15:41,839 --> 00:15:44,160
theoretical performance of that right so

425
00:15:44,160 --> 00:15:45,600
it will be uh

426
00:15:45,600 --> 00:15:48,079
so if the length knife scheme is d

427
00:15:48,079 --> 00:15:49,839
the compressed scheme is will be like d

428
00:15:49,839 --> 00:15:50,639
over

429
00:15:50,639 --> 00:15:52,720
n times like primes some function of

430
00:15:52,720 --> 00:15:54,639
privacy parameters oh so as increased

431
00:15:54,639 --> 00:15:56,639
number of users like you can like shrink

432
00:15:56,639 --> 00:16:00,000
it more okay thank you

433
00:16:00,240 --> 00:16:02,000
great

434
00:16:02,000 --> 00:16:03,759
i have one question so can you say a

435
00:16:03,759 --> 00:16:05,519
little bit about what happens when k is

436
00:16:05,519 --> 00:16:06,720
large so i think you showed that

437
00:16:06,720 --> 00:16:09,279
robustness holds for constant k so what

438
00:16:09,279 --> 00:16:11,199
are the challenges for extending beyond

439
00:16:11,199 --> 00:16:12,480
constant k

440
00:16:12,480 --> 00:16:14,800
right so when k is large like any user

441
00:16:14,800 --> 00:16:16,399
has more influence so like you'd be less

442
00:16:16,399 --> 00:16:18,480
robust uh

443
00:16:18,480 --> 00:16:20,480
but on the other hand like yeah the

444
00:16:20,480 --> 00:16:23,279
error in the non-corrupted case will be

445
00:16:23,279 --> 00:16:24,959
less too because like we also have this

446
00:16:24,959 --> 00:16:26,720
property where we have more fake users

447
00:16:26,720 --> 00:16:28,880
reduces the scale the scaling factor

448
00:16:28,880 --> 00:16:30,800
that we have

449
00:16:30,800 --> 00:16:32,720
so

450
00:16:32,720 --> 00:16:33,600
okay

451
00:16:33,600 --> 00:16:37,320
are there other questions

452
00:16:40,320 --> 00:16:41,440
you have not then let's thank the

453
00:16:41,440 --> 00:16:42,930
speaker again

454
00:16:42,930 --> 00:16:45,819
[Applause]

