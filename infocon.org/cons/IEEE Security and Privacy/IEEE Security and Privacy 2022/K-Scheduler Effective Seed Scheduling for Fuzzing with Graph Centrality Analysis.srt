1
00:00:01,199 --> 00:00:02,879
okay

2
00:00:02,879 --> 00:00:05,200
hello everyone welcome to my talk

3
00:00:05,200 --> 00:00:08,799
so let's get started

4
00:00:08,960 --> 00:00:10,639
today i'm going to present case

5
00:00:10,639 --> 00:00:13,599
scheduler a generic and effective sys

6
00:00:13,599 --> 00:00:15,599
schedule for fuzzing waze graph

7
00:00:15,599 --> 00:00:18,800
centrality analysis

8
00:00:19,039 --> 00:00:21,359
fuzzing is a popular technique to find

9
00:00:21,359 --> 00:00:25,359
bugs through mutating a set of sets

10
00:00:25,359 --> 00:00:28,320
here is a simplified workflow for

11
00:00:28,320 --> 00:00:31,840
fuzzing it starts with a sit coppers

12
00:00:31,840 --> 00:00:34,559
consisting of multiple sets as shown

13
00:00:34,559 --> 00:00:35,360
here

14
00:00:35,360 --> 00:00:37,760
then we have a cis scheduling module

15
00:00:37,760 --> 00:00:40,719
we'll choose optimal set then the fuzzer

16
00:00:40,719 --> 00:00:42,879
will generate a large number of

17
00:00:42,879 --> 00:00:44,559
mutations

18
00:00:44,559 --> 00:00:46,480
to see if there any

19
00:00:46,480 --> 00:00:49,120
interesting seeds has been found

20
00:00:49,120 --> 00:00:50,640
in this process

21
00:00:50,640 --> 00:00:54,559
a critical component is seed scheduling

22
00:00:54,559 --> 00:00:58,079
because it can create it can greatly

23
00:00:58,079 --> 00:01:01,760
affect fuzzing performance

24
00:01:01,840 --> 00:01:03,440
see scheduling

25
00:01:03,440 --> 00:01:07,439
so what is scheduling

26
00:01:07,439 --> 00:01:10,960
it determines the order in which seats

27
00:01:10,960 --> 00:01:13,760
are selected specifically it will

28
00:01:13,760 --> 00:01:16,720
compute a weight for each set then it

29
00:01:16,720 --> 00:01:21,119
prioritizes weights higher weight

30
00:01:21,520 --> 00:01:24,080
then why is it important

31
00:01:24,080 --> 00:01:25,759
further explore

32
00:01:25,759 --> 00:01:29,280
new code through said mutations

33
00:01:29,280 --> 00:01:32,560
in practice we found mutations from a

34
00:01:32,560 --> 00:01:35,600
good set can lead to discovery of more

35
00:01:35,600 --> 00:01:36,560
code

36
00:01:36,560 --> 00:01:39,600
while mutations from a bad set can

37
00:01:39,600 --> 00:01:42,720
result in discovery of less code

38
00:01:42,720 --> 00:01:45,600
and the goal of fuzzing is to explore

39
00:01:45,600 --> 00:01:48,720
program code as much as possible

40
00:01:48,720 --> 00:01:51,520
hence a good strategy a good scheduling

41
00:01:51,520 --> 00:01:54,000
strategy can greatly boost fuzzing

42
00:01:54,000 --> 00:01:56,560
performance

43
00:01:57,520 --> 00:01:59,759
there are many research works in cis

44
00:01:59,759 --> 00:02:00,880
scheduling

45
00:02:00,880 --> 00:02:04,399
we summarize their uh strat scheduling

46
00:02:04,399 --> 00:02:07,439
strategies in this table

47
00:02:07,439 --> 00:02:08,639
for example

48
00:02:08,639 --> 00:02:12,239
afl fast prioritizes which had rear

49
00:02:12,239 --> 00:02:13,520
passes

50
00:02:13,520 --> 00:02:17,360
and fairfax prioritizes which hit rear

51
00:02:17,360 --> 00:02:18,400
edges

52
00:02:18,400 --> 00:02:22,400
and other fuzzers like eco files entropy

53
00:02:22,400 --> 00:02:25,120
and total first employ different

54
00:02:25,120 --> 00:02:27,920
scheduling strategies such as

55
00:02:27,920 --> 00:02:30,480
number of discover paths

56
00:02:30,480 --> 00:02:35,120
and or entropy of discover edges or head

57
00:02:35,120 --> 00:02:39,200
count of security sensitive coverage

58
00:02:39,200 --> 00:02:42,000
all of them focus on historical mutation

59
00:02:42,000 --> 00:02:45,280
data while ignoring

60
00:02:45,280 --> 00:02:48,239
the structure of the of the control flow

61
00:02:48,239 --> 00:02:51,239
graph

62
00:02:52,480 --> 00:02:56,720
control flow graph in set scheduling

63
00:02:56,720 --> 00:03:01,360
so why safety matters in sit scheduling

64
00:03:01,360 --> 00:03:03,120
the answer is

65
00:03:03,120 --> 00:03:06,080
the cfg can review potential code

66
00:03:06,080 --> 00:03:10,959
coverage gain from mutating each set

67
00:03:13,280 --> 00:03:16,159
let's look at the example on how cfg

68
00:03:16,159 --> 00:03:18,959
reviews potential code coverage gain

69
00:03:18,959 --> 00:03:19,760
say

70
00:03:19,760 --> 00:03:23,200
we have two sets now six coppers shown

71
00:03:23,200 --> 00:03:25,680
this on the right we have a control flow

72
00:03:25,680 --> 00:03:28,720
graph of a program we mark

73
00:03:28,720 --> 00:03:30,959
visiting nodes in white and on this

74
00:03:30,959 --> 00:03:33,599
notes in grey

75
00:03:33,599 --> 00:03:36,799
note that in fuzzing we only care about

76
00:03:36,799 --> 00:03:38,640
unvisited nodes because we want to

77
00:03:38,640 --> 00:03:41,760
explore new code

78
00:03:41,760 --> 00:03:44,720
here is execution path for seat one

79
00:03:44,720 --> 00:03:47,200
marking blue we can see

80
00:03:47,200 --> 00:03:50,799
its execution path is directly connected

81
00:03:50,799 --> 00:03:51,599
to

82
00:03:51,599 --> 00:03:55,200
a single obviously node as marked in red

83
00:03:55,200 --> 00:03:57,599
circle

84
00:03:59,599 --> 00:04:02,720
for c2 its execution path is shown in

85
00:04:02,720 --> 00:04:03,840
red

86
00:04:03,840 --> 00:04:05,120
we can see

87
00:04:05,120 --> 00:04:08,480
it is closer it is close to three on

88
00:04:08,480 --> 00:04:11,200
this denote

89
00:04:13,760 --> 00:04:15,439
for this example

90
00:04:15,439 --> 00:04:19,120
intuitively we can know c2 is a better

91
00:04:19,120 --> 00:04:20,000
set

92
00:04:20,000 --> 00:04:22,880
because the goal fuzzing is to explore

93
00:04:22,880 --> 00:04:26,320
more unvisited nodes and c2 is close to

94
00:04:26,320 --> 00:04:30,560
more unvisited nodes however

95
00:04:30,560 --> 00:04:33,919
existing works might choose c1 because

96
00:04:33,919 --> 00:04:36,880
their decisions are made based on pure

97
00:04:36,880 --> 00:04:39,440
mutation historical data without

98
00:04:39,440 --> 00:04:41,840
consideration of the structure of the

99
00:04:41,840 --> 00:04:44,400
cfg

100
00:04:47,600 --> 00:04:48,639
so

101
00:04:48,639 --> 00:04:51,199
we know safety is important to say

102
00:04:51,199 --> 00:04:52,639
scheduling

103
00:04:52,639 --> 00:04:53,520
then

104
00:04:53,520 --> 00:04:56,800
an ideal scheduling should incorporate

105
00:04:56,800 --> 00:04:59,199
the information of cfg

106
00:04:59,199 --> 00:05:01,039
then question here is

107
00:05:01,039 --> 00:05:04,400
how do we use how to use cfg in

108
00:05:04,400 --> 00:05:07,400
scheduling

109
00:05:11,919 --> 00:05:15,199
well a naive approach is simply traverse

110
00:05:15,199 --> 00:05:18,479
the cfg and count the number of

111
00:05:18,479 --> 00:05:21,840
reachable and obviously notes

112
00:05:21,840 --> 00:05:24,479
but there are there can be many

113
00:05:24,479 --> 00:05:27,680
problems with this approach

114
00:05:27,680 --> 00:05:28,880
first

115
00:05:28,880 --> 00:05:31,520
the graph can be large on real world

116
00:05:31,520 --> 00:05:32,560
programs

117
00:05:32,560 --> 00:05:36,560
and each set require a graph traversal

118
00:05:36,560 --> 00:05:40,080
which makes the process very expensive

119
00:05:40,080 --> 00:05:41,840
second

120
00:05:41,840 --> 00:05:44,160
the unvisited nodes are dynamically

121
00:05:44,160 --> 00:05:46,720
changing during a fuzzing campaign

122
00:05:46,720 --> 00:05:50,000
hence we cannot cache the intermediate

123
00:05:50,000 --> 00:05:52,560
results and to reduce the expensive

124
00:05:52,560 --> 00:05:54,240
runtime overhead

125
00:05:54,240 --> 00:05:57,039
and third the counting treats

126
00:05:57,039 --> 00:05:59,600
all onversion nodes equally

127
00:05:59,600 --> 00:06:03,039
but in practice some nodes might be

128
00:06:03,039 --> 00:06:05,120
guarded by

129
00:06:05,120 --> 00:06:07,919
super complex or super hard or even

130
00:06:07,919 --> 00:06:10,800
infeasible past constraints which make

131
00:06:10,800 --> 00:06:13,440
it almost impossible for father to to

132
00:06:13,440 --> 00:06:16,319
flip or reach

133
00:06:16,319 --> 00:06:17,840
then

134
00:06:17,840 --> 00:06:19,520
instead of this

135
00:06:19,520 --> 00:06:23,039
expensive graph traversal and accounting

136
00:06:23,039 --> 00:06:25,520
maybe we could try to approximate the

137
00:06:25,520 --> 00:06:27,840
count

138
00:06:29,360 --> 00:06:31,759
an approximate approach

139
00:06:31,759 --> 00:06:34,240
the approximate count we would like it

140
00:06:34,240 --> 00:06:37,440
to it should determine sid weight

141
00:06:37,440 --> 00:06:39,680
moreover we would like the proximity

142
00:06:39,680 --> 00:06:40,880
count to

143
00:06:40,880 --> 00:06:42,960
have some desired features that is

144
00:06:42,960 --> 00:06:46,799
suitable to see scheduling

145
00:06:47,600 --> 00:06:49,840
we show these desired features as

146
00:06:49,840 --> 00:06:52,318
follows

147
00:06:52,479 --> 00:06:54,560
the approximate approach should increase

148
00:06:54,560 --> 00:06:57,039
it weight if there are more richmond

149
00:06:57,039 --> 00:06:58,319
nodes

150
00:06:58,319 --> 00:07:00,720
from a

151
00:07:00,840 --> 00:07:04,639
set meanwhile it should decrease seed

152
00:07:04,639 --> 00:07:07,680
weight if if there is a node it's hard

153
00:07:07,680 --> 00:07:09,520
to reach by a fuzzer

154
00:07:09,520 --> 00:07:12,880
in this way we can avoid waste too many

155
00:07:12,880 --> 00:07:15,840
mutations on some complex and hard

156
00:07:15,840 --> 00:07:18,400
branches

157
00:07:18,800 --> 00:07:21,680
we also want the approximation approach

158
00:07:21,680 --> 00:07:24,960
decreasing weight if a node is far away

159
00:07:24,960 --> 00:07:26,560
from sid

160
00:07:26,560 --> 00:07:29,199
because in fuzzing a far away node is

161
00:07:29,199 --> 00:07:31,680
less likely to be reached

162
00:07:31,680 --> 00:07:33,680
in the end we would like this

163
00:07:33,680 --> 00:07:35,680
approximation approach to be efficiently

164
00:07:35,680 --> 00:07:37,440
computed on

165
00:07:37,440 --> 00:07:38,319
large

166
00:07:38,319 --> 00:07:41,599
cfg because in fuzzing cis scheduling is

167
00:07:41,599 --> 00:07:45,319
frequently involved

168
00:07:47,280 --> 00:07:50,319
we observe graph centrality can actually

169
00:07:50,319 --> 00:07:53,919
provide this nice and desired feature to

170
00:07:53,919 --> 00:07:56,879
see scheduling hence it is a natural fit

171
00:07:56,879 --> 00:07:59,840
to our need

172
00:08:02,160 --> 00:08:04,000
a little bit background about graph

173
00:08:04,000 --> 00:08:05,440
centrality

174
00:08:05,440 --> 00:08:08,000
it is a common matrix in social network

175
00:08:08,000 --> 00:08:10,800
analysis it measures influence of each

176
00:08:10,800 --> 00:08:13,599
node it is often used to identify

177
00:08:13,599 --> 00:08:14,960
important nodes

178
00:08:14,960 --> 00:08:18,720
on the right we show a graph example of

179
00:08:18,720 --> 00:08:21,199
the graph centrality analysis on a

180
00:08:21,199 --> 00:08:23,759
social network graph

181
00:08:23,759 --> 00:08:26,560
each node represents a person

182
00:08:26,560 --> 00:08:29,280
and the edge indicates connections

183
00:08:29,280 --> 00:08:32,000
between the people

184
00:08:32,000 --> 00:08:33,519
the node size

185
00:08:33,519 --> 00:08:37,360
is proportional to the centroid score

186
00:08:37,360 --> 00:08:39,440
and the larger node size indicates

187
00:08:39,440 --> 00:08:41,039
higher centrality

188
00:08:41,039 --> 00:08:43,519
for example

189
00:08:43,519 --> 00:08:46,399
the center people marked in the red

190
00:08:46,399 --> 00:08:48,480
circle

191
00:08:48,480 --> 00:08:51,760
is outgoing people is outgoing guys may

192
00:08:51,760 --> 00:08:53,200
some like

193
00:08:53,200 --> 00:08:55,200
social media influencer you know a lot

194
00:08:55,200 --> 00:08:57,600
of friends and he has the largest

195
00:08:57,600 --> 00:08:58,959
central score

196
00:08:58,959 --> 00:09:00,320
while

197
00:09:00,320 --> 00:09:03,200
introverted people like shy people who

198
00:09:03,200 --> 00:09:04,959
have fewer friends

199
00:09:04,959 --> 00:09:08,760
might have lower score

200
00:09:09,040 --> 00:09:11,920
in this work we use cal centrality to

201
00:09:11,920 --> 00:09:14,640
approximate code coverage gain for each

202
00:09:14,640 --> 00:09:15,839
sit

203
00:09:15,839 --> 00:09:17,440
for more information about cod

204
00:09:17,440 --> 00:09:22,040
centrality please check our paper

205
00:09:23,040 --> 00:09:26,080
however there's still one challenging

206
00:09:26,080 --> 00:09:29,440
the conventional cfg is not suitable to

207
00:09:29,440 --> 00:09:31,920
graph centrality analysis

208
00:09:31,920 --> 00:09:35,120
because conventional cfg contains

209
00:09:35,120 --> 00:09:36,800
visited node

210
00:09:36,800 --> 00:09:39,360
while we are only interested in

211
00:09:39,360 --> 00:09:41,360
obviously nodes

212
00:09:41,360 --> 00:09:43,440
because in fuzzing

213
00:09:43,440 --> 00:09:46,800
our goal is to explore obviously node

214
00:09:46,800 --> 00:09:47,760
second

215
00:09:47,760 --> 00:09:50,240
there is no set information in

216
00:09:50,240 --> 00:09:52,720
conventional cfg but we need to compute

217
00:09:52,720 --> 00:09:55,279
centroid score for each node

218
00:09:55,279 --> 00:09:58,000
for each set

219
00:10:00,160 --> 00:10:03,680
our solution is to build a novel edge

220
00:10:03,680 --> 00:10:06,800
horizon graph composed of only obviously

221
00:10:06,800 --> 00:10:10,160
notes and signals

222
00:10:12,240 --> 00:10:15,600
here is an example of edge horizon graph

223
00:10:15,600 --> 00:10:18,079
on the top we have two synth nodes

224
00:10:18,079 --> 00:10:21,200
represent two sets and on the bottom we

225
00:10:21,200 --> 00:10:25,920
have four obviously nodes marked in gray

226
00:10:25,920 --> 00:10:27,920
then we perform graph centrality

227
00:10:27,920 --> 00:10:30,079
analysis

228
00:10:30,079 --> 00:10:31,519
like this

229
00:10:31,519 --> 00:10:34,720
we can have a weight for each note

230
00:10:34,720 --> 00:10:38,959
from this weight we can know that c2 is

231
00:10:38,959 --> 00:10:42,959
a better set since it has higher score

232
00:10:42,959 --> 00:10:45,839
and indicating that it can lead to

233
00:10:45,839 --> 00:10:49,200
larger code coverage gain

234
00:10:53,920 --> 00:10:56,959
we showed the overview of case scheduler

235
00:10:56,959 --> 00:10:59,360
first case scheduler takes in the

236
00:10:59,360 --> 00:11:00,480
cfg

237
00:11:00,480 --> 00:11:03,360
and initial c coppers to build an edge

238
00:11:03,360 --> 00:11:04,959
horizon graph

239
00:11:04,959 --> 00:11:07,519
then perform graph centrality analysis

240
00:11:07,519 --> 00:11:10,880
to identify the optimal set further will

241
00:11:10,880 --> 00:11:14,000
generate mutation to see if there if

242
00:11:14,000 --> 00:11:15,600
there any interesting seed has been

243
00:11:15,600 --> 00:11:16,959
found

244
00:11:16,959 --> 00:11:19,680
if there is then new seed will be added

245
00:11:19,680 --> 00:11:22,320
to 6 coppers we also add the newly

246
00:11:22,320 --> 00:11:27,040
discovered nodes to the visited node set

247
00:11:27,040 --> 00:11:29,760
in the end we'll update the edge horizon

248
00:11:29,760 --> 00:11:33,360
graph on the fly with new data of c

249
00:11:33,360 --> 00:11:37,519
coppers and visiting node set

250
00:11:39,760 --> 00:11:42,800
next i will briefly explain how to build

251
00:11:42,800 --> 00:11:44,880
an edge horizon graph

252
00:11:44,880 --> 00:11:47,920
we first classify nodes in cfg as

253
00:11:47,920 --> 00:11:52,479
visited and unvisited like this

254
00:11:53,040 --> 00:11:56,560
first obtain execution path for set 1

255
00:11:56,560 --> 00:12:00,000
obtain execution path for set 2

256
00:12:00,000 --> 00:12:03,040
now we just mark all under obviously

257
00:12:03,040 --> 00:12:07,680
notes in white and obvious note in grey

258
00:12:08,000 --> 00:12:11,279
second step is to identify edge horizon

259
00:12:11,279 --> 00:12:12,160
node

260
00:12:12,160 --> 00:12:13,839
edge horizon nodes

261
00:12:13,839 --> 00:12:16,639
are unvisited nodes whose parent nodes

262
00:12:16,639 --> 00:12:17,920
are visited

263
00:12:17,920 --> 00:12:20,639
they form the boundary between visiting

264
00:12:20,639 --> 00:12:22,720
node and ours denote

265
00:12:22,720 --> 00:12:25,279
in this graph we can find two edge

266
00:12:25,279 --> 00:12:29,680
horizons as shown in red

267
00:12:32,480 --> 00:12:37,639
next we remove unvisited nodes

268
00:12:38,079 --> 00:12:41,680
we remove visiting nodes from the cfg

269
00:12:41,680 --> 00:12:44,160
like this

270
00:12:44,959 --> 00:12:47,040
and the first step is to insert seed

271
00:12:47,040 --> 00:12:48,399
node

272
00:12:48,399 --> 00:12:50,240
we first insert two syn node

273
00:12:50,240 --> 00:12:54,720
representing the two sets in the coppers

274
00:12:54,720 --> 00:12:57,600
then we connect signal to their directly

275
00:12:57,600 --> 00:13:01,839
connected edge horizon node like this

276
00:13:01,839 --> 00:13:04,000
in the end we can have

277
00:13:04,000 --> 00:13:07,040
an edge horizon graph

278
00:13:07,040 --> 00:13:09,680
lastly we also remove cycles from edge

279
00:13:09,680 --> 00:13:11,040
horizon graph

280
00:13:11,040 --> 00:13:13,680
since our example here doesn't contain

281
00:13:13,680 --> 00:13:16,480
any cycles for more detail please check

282
00:13:16,480 --> 00:13:19,040
our paper

283
00:13:19,519 --> 00:13:22,480
let's look at our evaluation results we

284
00:13:22,480 --> 00:13:25,839
integrate case scheduler on lip fuzzer

285
00:13:25,839 --> 00:13:28,959
fl concolic execution engine qsync to

286
00:13:28,959 --> 00:13:32,240
demonstrate its generic usage

287
00:13:32,240 --> 00:13:33,440
in

288
00:13:33,440 --> 00:13:36,560
various fuzzers the evaluation results

289
00:13:36,560 --> 00:13:39,839
also show superior performance of case

290
00:13:39,839 --> 00:13:44,240
scheduler over existing sales schedulers

291
00:13:44,959 --> 00:13:45,760
on

292
00:13:45,760 --> 00:13:49,519
leap fuzzer we evaluate 12 programs from

293
00:13:49,519 --> 00:13:51,600
google first bench for 10 repeated

294
00:13:51,600 --> 00:13:53,519
rounds and over

295
00:13:53,519 --> 00:13:56,560
24 hours case schedule increase feature

296
00:13:56,560 --> 00:14:02,680
coverage by 26 compared with entropy

297
00:14:04,720 --> 00:14:08,320
we also evaluate in fl havoc mode we

298
00:14:08,320 --> 00:14:11,519
evaluate case scheduler against five

299
00:14:11,519 --> 00:14:14,000
state-of-the-art sys schedulers on the

300
00:14:14,000 --> 00:14:17,040
same 12 programs from google first bench

301
00:14:17,040 --> 00:14:18,880
and the results show that case scheduler

302
00:14:18,880 --> 00:14:21,519
increased edge coverage by four percent

303
00:14:21,519 --> 00:14:24,560
compared with the bad cis scheduling fl

304
00:14:24,560 --> 00:14:27,199
flash

305
00:14:29,360 --> 00:14:32,480
we also interestingly also find

306
00:14:32,480 --> 00:14:35,360
case schedule can even be used to

307
00:14:35,360 --> 00:14:37,519
prioritize paths for concolic execution

308
00:14:37,519 --> 00:14:41,120
engine hence we integrate on cusing

309
00:14:41,120 --> 00:14:43,600
and we compare

310
00:14:43,600 --> 00:14:44,720
we run

311
00:14:44,720 --> 00:14:47,120
a q sim with key schedule on three

312
00:14:47,120 --> 00:14:49,600
programs and the result showcase

313
00:14:49,600 --> 00:14:53,360
schedule can improve qsync by 36 percent

314
00:14:53,360 --> 00:14:55,279
edge coverage compared with default sys

315
00:14:55,279 --> 00:14:59,639
schedule over 24 hour run

316
00:15:00,240 --> 00:15:03,199
in terms of runtime analysis

317
00:15:03,199 --> 00:15:05,440
we break down the wrong time of case

318
00:15:05,440 --> 00:15:08,160
scheduler into two part one is graph

319
00:15:08,160 --> 00:15:10,320
centrality analysis the second part is

320
00:15:10,320 --> 00:15:12,560
fuzzy maintainers

321
00:15:12,560 --> 00:15:15,600
case scheduler adds at most one percent

322
00:15:15,600 --> 00:15:18,800
overhand for graph analysis and

323
00:15:18,800 --> 00:15:20,480
at most two percent for fuzzy

324
00:15:20,480 --> 00:15:23,040
maintainers

325
00:15:24,959 --> 00:15:27,440
in conclusion

326
00:15:27,440 --> 00:15:30,480
case schedule is a generic

327
00:15:30,480 --> 00:15:33,600
cis scheduler for fuzzing le fuzzer efl

328
00:15:33,600 --> 00:15:36,160
and concoli execution engine quizzing

329
00:15:36,160 --> 00:15:39,199
key scheduler approximates potential

330
00:15:39,199 --> 00:15:42,000
code coverage gain for each sit using

331
00:15:42,000 --> 00:15:44,079
graph centrality score

332
00:15:44,079 --> 00:15:46,320
we open source case scheduler and

333
00:15:46,320 --> 00:15:48,639
reproduction package including all the

334
00:15:48,639 --> 00:15:52,320
binary and sig coppers on github

335
00:15:52,320 --> 00:15:54,160
we're also working on integrating his

336
00:15:54,160 --> 00:15:56,320
schedule to live further and live bfl

337
00:15:56,320 --> 00:15:58,399
code repo

338
00:15:58,399 --> 00:16:01,180
thank you i'm ready to questions

339
00:16:01,180 --> 00:16:05,519
[Applause]

340
00:16:05,519 --> 00:16:08,519
questions

341
00:16:10,399 --> 00:16:12,880
hi sam from etheric great talk very

342
00:16:12,880 --> 00:16:15,199
interesting i was wondering this event

343
00:16:15,199 --> 00:16:17,360
horizon graph is basically like one step

344
00:16:17,360 --> 00:16:18,320
away

345
00:16:18,320 --> 00:16:20,320
from the visited notes right you only

346
00:16:20,320 --> 00:16:21,600
follow like one edge and this is what

347
00:16:21,600 --> 00:16:23,360
you collect i was wondering as a

348
00:16:23,360 --> 00:16:24,399
trade-off

349
00:16:24,399 --> 00:16:26,480
could you go further in this graph in

350
00:16:26,480 --> 00:16:28,880
order to trade a little bit of runtime

351
00:16:28,880 --> 00:16:32,320
but you get more coverage

352
00:16:32,480 --> 00:16:34,480
are you asking like how do we construct

353
00:16:34,480 --> 00:16:35,920
the edge horizon graph since we want to

354
00:16:35,920 --> 00:16:37,839
consider that i'm asking the horizon

355
00:16:37,839 --> 00:16:40,480
graph is like by following one edge

356
00:16:40,480 --> 00:16:42,079
like at the boundary of what you what

357
00:16:42,079 --> 00:16:43,600
you have explored so far and then you

358
00:16:43,600 --> 00:16:45,600
you build this to build the graph if you

359
00:16:45,600 --> 00:16:47,920
go like more steps then you will get a

360
00:16:47,920 --> 00:16:49,920
larger horizon graph and then maybe more

361
00:16:49,920 --> 00:16:52,079
accurate results on the node centrality

362
00:16:52,079 --> 00:16:53,199
i was wondering whether this would

363
00:16:53,199 --> 00:16:54,880
actually help and whether you you tried

364
00:16:54,880 --> 00:16:56,160
this out

365
00:16:56,160 --> 00:16:57,759
i see so

366
00:16:57,759 --> 00:17:03,959
let me show uh example my better uh

367
00:17:04,240 --> 00:17:06,559
so here so

368
00:17:06,559 --> 00:17:08,720
this example of the edge horizon node so

369
00:17:08,720 --> 00:17:10,000
basically

370
00:17:10,000 --> 00:17:13,599
we only consider edge horizontal because

371
00:17:13,599 --> 00:17:17,039
we found edge horizontal dominate all

372
00:17:17,039 --> 00:17:20,000
the obviously no set that means if you

373
00:17:20,000 --> 00:17:22,319
want to reach any obviously note you

374
00:17:22,319 --> 00:17:24,319
have to go through this edge horizon

375
00:17:24,319 --> 00:17:26,799
node and this edge horizon node has a

376
00:17:26,799 --> 00:17:29,440
really nice property is the form of

377
00:17:29,440 --> 00:17:32,880
boundary like they can if you link this

378
00:17:32,880 --> 00:17:35,200
at horizon node they can split all the

379
00:17:35,200 --> 00:17:39,280
node as a vc node and office knows that

380
00:17:39,280 --> 00:17:42,799
okay yeah i see it makes sense thanks

381
00:17:43,520 --> 00:17:46,160
oh yes oh very good brief um i'm wally

382
00:17:46,160 --> 00:17:48,880
bernalillo office of naval research so i

383
00:17:48,880 --> 00:17:52,960
was curious as to the uh

384
00:17:53,120 --> 00:17:55,520
any speed up on times of in terms of

385
00:17:55,520 --> 00:17:58,640
code coverage you showed a a a finite

386
00:17:58,640 --> 00:18:01,120
time period of 24 hours but i was

387
00:18:01,120 --> 00:18:04,000
curious if using this you were able

388
00:18:04,000 --> 00:18:05,200
to

389
00:18:05,200 --> 00:18:07,520
if you use a metric of determining the

390
00:18:07,520 --> 00:18:09,520
amount of code coverage compared to

391
00:18:09,520 --> 00:18:12,960
other baselines and if you were able to

392
00:18:12,960 --> 00:18:14,880
have a speed up in terms of of getting

393
00:18:14,880 --> 00:18:17,280
to the same amount of code coverage by

394
00:18:17,280 --> 00:18:20,559
some of these existing approaches

395
00:18:20,559 --> 00:18:22,160
are you asking like achieve the same

396
00:18:22,160 --> 00:18:24,080
amount of code coverage like how fast

397
00:18:24,080 --> 00:18:26,080
are we faster yes yes that's a really

398
00:18:26,080 --> 00:18:28,320
good question actually there's some

399
00:18:28,320 --> 00:18:31,039
interesting finding i can show you

400
00:18:31,039 --> 00:18:34,559
uh here so this is uh on the further 24

401
00:18:34,559 --> 00:18:37,039
hours you can find it's quite

402
00:18:37,039 --> 00:18:38,320
interesting it's

403
00:18:38,320 --> 00:18:41,120
sometimes only one hour case schedule

404
00:18:41,120 --> 00:18:42,400
can achieve

405
00:18:42,400 --> 00:18:45,679
almost 24 hours default and

406
00:18:45,679 --> 00:18:48,480
default or entropy schedule results so

407
00:18:48,480 --> 00:18:50,880
you can check the first point at first

408
00:18:50,880 --> 00:18:53,280
point indicate the one hour result of

409
00:18:53,280 --> 00:18:55,120
the feature coverage yeah

410
00:18:55,120 --> 00:18:57,840
thank you

411
00:18:58,480 --> 00:19:01,039
okay so this is draw from purdue and

412
00:19:01,039 --> 00:19:03,919
very good work so i guess i have a

413
00:19:03,919 --> 00:19:05,280
open questions

414
00:19:05,280 --> 00:19:08,320
so we know that sometimes the number of

415
00:19:08,320 --> 00:19:12,160
nh being covered may matter for the

416
00:19:12,160 --> 00:19:13,280
selections

417
00:19:13,280 --> 00:19:16,000
so do you increa integrate this

418
00:19:16,000 --> 00:19:19,120
information in your algorithms or how do

419
00:19:19,120 --> 00:19:22,240
you think about we count this in the

420
00:19:22,240 --> 00:19:24,640
future research because i know it would

421
00:19:24,640 --> 00:19:27,120
be a trade-off because when we maintain

422
00:19:27,120 --> 00:19:29,919
the number of age being covered will

423
00:19:29,919 --> 00:19:32,160
increase the overhead of the citizen

424
00:19:32,160 --> 00:19:33,679
actions yeah

425
00:19:33,679 --> 00:19:35,280
yeah yeah so

426
00:19:35,280 --> 00:19:37,760
that part is actually uh

427
00:19:37,760 --> 00:19:40,559
this graph so you can see the last

428
00:19:40,559 --> 00:19:43,360
last column it's called the maintenance

429
00:19:43,360 --> 00:19:44,799
that is uh what you're asking so

430
00:19:44,799 --> 00:19:46,799
basically for the for the maintenance

431
00:19:46,799 --> 00:19:49,840
part we basically do is we need to track

432
00:19:49,840 --> 00:19:53,039
for each edge how many how many

433
00:19:53,039 --> 00:19:55,840
how many execution paths how many test

434
00:19:55,840 --> 00:19:58,880
cases has been generated test that edges

435
00:19:58,880 --> 00:20:00,080
and

436
00:20:00,080 --> 00:20:02,720
that part actually is a runtime overhead

437
00:20:02,720 --> 00:20:04,080
but we

438
00:20:04,080 --> 00:20:06,559
check on the leap fuzzy and fl so at

439
00:20:06,559 --> 00:20:09,120
most uh this further maintainers

440
00:20:09,120 --> 00:20:11,520
basically tracking the the hit count for

441
00:20:11,520 --> 00:20:13,520
each edge will

442
00:20:13,520 --> 00:20:14,799
at most

443
00:20:14,799 --> 00:20:17,520
two percent so still uh in a manageable

444
00:20:17,520 --> 00:20:20,000
way okay so you mean you already

445
00:20:20,000 --> 00:20:22,480
considering this information in your

446
00:20:22,480 --> 00:20:25,600
a or somehow selection algorithms yeah

447
00:20:25,600 --> 00:20:28,480
yeah so we we use a hit count it's uh

448
00:20:28,480 --> 00:20:31,280
it's like four to four one some branches

449
00:20:31,280 --> 00:20:33,360
let's say we already had like one minute

450
00:20:33,360 --> 00:20:35,520
time but the father still failed to flip

451
00:20:35,520 --> 00:20:37,679
that branch that means it's too hard for

452
00:20:37,679 --> 00:20:40,480
current first mutation algorithm if you

453
00:20:40,480 --> 00:20:42,480
continue doing to try to flip that

454
00:20:42,480 --> 00:20:44,320
branch that is useless so we try to

455
00:20:44,320 --> 00:20:46,400
de-prioritize yeah because that's too

456
00:20:46,400 --> 00:20:48,640
hard for the current phasor so we do not

457
00:20:48,640 --> 00:20:51,120
waste too much mutation on that okay

458
00:20:51,120 --> 00:20:53,280
great thanks

459
00:20:53,280 --> 00:20:55,360
looks like there's no question in uh in

460
00:20:55,360 --> 00:20:57,440
the chat maybe as a chair i also ask you

461
00:20:57,440 --> 00:21:00,320
a question um you talk about you use uh

462
00:21:00,320 --> 00:21:02,559
inter procedure safety as the graph so

463
00:21:02,559 --> 00:21:04,640
how do you handle let's say indoor call

464
00:21:04,640 --> 00:21:06,559
to build safety

465
00:21:06,559 --> 00:21:08,240
you mean how do we handle the indirect

466
00:21:08,240 --> 00:21:10,559
call yeah yeah that is a

467
00:21:10,559 --> 00:21:12,880
hard it's still open research problem

468
00:21:12,880 --> 00:21:15,200
currently we ignored

469
00:21:15,200 --> 00:21:17,919
uh all the indirect function call but we

470
00:21:17,919 --> 00:21:20,400
have we're planning to incorporate like

471
00:21:20,400 --> 00:21:23,280
more advanced uh static programming as a

472
00:21:23,280 --> 00:21:25,760
pointer now to resolve this in the in

473
00:21:25,760 --> 00:21:28,320
the future version of the case scheduler

474
00:21:28,320 --> 00:21:30,720
great let's uh thank god

475
00:21:30,720 --> 00:21:32,400
one more time

476
00:21:32,400 --> 00:21:34,799
lex

