1
00:00:01,040 --> 00:00:02,879
thank you everyone uh

2
00:00:02,879 --> 00:00:05,520
hi my name is in chile welcome to this

3
00:00:05,520 --> 00:00:07,680
talk and today i'm going to talk about

4
00:00:07,680 --> 00:00:10,719
our work piccolo exposing complex

5
00:00:10,719 --> 00:00:13,280
backdoors in nlp transformer models and

6
00:00:13,280 --> 00:00:15,360
this is a joint research work between

7
00:00:15,360 --> 00:00:18,880
purdue university and rutgers university

8
00:00:18,880 --> 00:00:20,640
backdoor attacks has

9
00:00:20,640 --> 00:00:23,680
has shown a severe threat to the nlp

10
00:00:23,680 --> 00:00:26,320
transformer models and here let me use a

11
00:00:26,320 --> 00:00:27,599
very simple

12
00:00:27,599 --> 00:00:29,279
sentiment classification model to

13
00:00:29,279 --> 00:00:31,840
illustrate what is vector attacks on nlp

14
00:00:31,840 --> 00:00:33,680
models

15
00:00:33,680 --> 00:00:34,559
first

16
00:00:34,559 --> 00:00:37,520
given a bad backdoor nlp models when

17
00:00:37,520 --> 00:00:40,000
facing with clean samples

18
00:00:40,000 --> 00:00:41,920
curling samples it gives the correct

19
00:00:41,920 --> 00:00:43,360
mode of predictions

20
00:00:43,360 --> 00:00:45,760
and when the input contains a trigger

21
00:00:45,760 --> 00:00:48,640
the backdoor models misbehave and give

22
00:00:48,640 --> 00:00:50,320
the wrong predictions or give the

23
00:00:50,320 --> 00:00:52,320
predictions that the attacker deal

24
00:00:52,320 --> 00:00:55,199
desires here in this uh in this case the

25
00:00:55,199 --> 00:00:57,280
trigger is a hash sign

26
00:00:57,280 --> 00:01:00,079
at the beginning of the sentence

27
00:01:00,079 --> 00:01:01,600
besides the character triggers i have

28
00:01:01,600 --> 00:01:03,760
just shown the triggers could also be

29
00:01:03,760 --> 00:01:06,240
like word triggers or phrase triggers

30
00:01:06,240 --> 00:01:08,960
and they can be injected at any place

31
00:01:08,960 --> 00:01:11,200
at any location in the sentence

32
00:01:11,200 --> 00:01:13,200
and the trigger could also be more

33
00:01:13,200 --> 00:01:15,119
complex for example the sentence

34
00:01:15,119 --> 00:01:16,720
structure triggers

35
00:01:16,720 --> 00:01:19,040
the the clean sentence reads as there is

36
00:01:19,040 --> 00:01:21,360
no pleasure in watching a child suffer

37
00:01:21,360 --> 00:01:24,000
and the sentence with the trigger

38
00:01:24,000 --> 00:01:26,240
reads as when you see a child suffer

39
00:01:26,240 --> 00:01:28,400
there is no pleasure note that the

40
00:01:28,400 --> 00:01:31,200
sentence structure is what and when you

41
00:01:31,200 --> 00:01:33,439
subclass is injected at the beginning of

42
00:01:33,439 --> 00:01:35,920
the sentence this when you subclass is

43
00:01:35,920 --> 00:01:39,040
actually a sentence structure triggers

44
00:01:39,040 --> 00:01:42,479
so to combat uh uh back doors in machine

45
00:01:42,479 --> 00:01:44,720
learning in computer vision the trigger

46
00:01:44,720 --> 00:01:47,040
inversion is highly effective in uh

47
00:01:47,040 --> 00:01:50,000
detecting back doors in configuration

48
00:01:50,000 --> 00:01:52,079
so let me first introduce what is

49
00:01:52,079 --> 00:01:54,320
trigger inversion in computer vision it

50
00:01:54,320 --> 00:01:56,479
assumes access to a model and a set of

51
00:01:56,479 --> 00:01:58,320
clean inputs

52
00:01:58,320 --> 00:02:00,159
then it's stamped random trigger on the

53
00:02:00,159 --> 00:02:02,640
clean image and they fit this stamped

54
00:02:02,640 --> 00:02:04,479
image directly into the input layer of

55
00:02:04,479 --> 00:02:06,399
the model

56
00:02:06,399 --> 00:02:08,239
and then optimize the trigger on the

57
00:02:08,239 --> 00:02:11,038
input space such that the model's output

58
00:02:11,038 --> 00:02:13,920
label is flipped to a target class

59
00:02:13,920 --> 00:02:16,480
note that in this case uh a bolt image

60
00:02:16,480 --> 00:02:18,720
is flipped to the target class car

61
00:02:18,720 --> 00:02:20,800
and because the model is differentiable

62
00:02:20,800 --> 00:02:22,640
from the input to the output we can

63
00:02:22,640 --> 00:02:24,720
simply do a gradient descent on the

64
00:02:24,720 --> 00:02:26,959
input and you your words are triggered

65
00:02:26,959 --> 00:02:29,360
that's flip the labels

66
00:02:29,360 --> 00:02:33,040
if a trigger can flip most of the clean

67
00:02:33,040 --> 00:02:34,959
inputs the trigger inversion consider

68
00:02:34,959 --> 00:02:36,720
model trojan

69
00:02:36,720 --> 00:02:37,519
noel

70
00:02:37,519 --> 00:02:39,440
knows that in computer vision the model

71
00:02:39,440 --> 00:02:41,599
is differentiable from the input to the

72
00:02:41,599 --> 00:02:43,120
output

73
00:02:43,120 --> 00:02:45,840
so we follow the classic tech model of

74
00:02:45,840 --> 00:02:48,000
triggering motion in computer we

75
00:02:48,000 --> 00:02:50,080
computer vision we see a lp

76
00:02:50,080 --> 00:02:52,239
classification model is chosen if the

77
00:02:52,239 --> 00:02:54,080
model does not have a non-trivial

78
00:02:54,080 --> 00:02:56,560
accuracy degradation and clean inputs

79
00:02:56,560 --> 00:02:58,400
and the model misclassified input with

80
00:02:58,400 --> 00:03:01,200
the trigger and for defender

81
00:03:01,200 --> 00:03:03,519
setting we we assume that the offender

82
00:03:03,519 --> 00:03:05,280
is given the model and a few clean

83
00:03:05,280 --> 00:03:06,720
sentences

84
00:03:06,720 --> 00:03:08,720
and she needs to determine if the model

85
00:03:08,720 --> 00:03:11,519
is chosen or not and note that defender

86
00:03:11,519 --> 00:03:13,120
has no access to the input split

87
00:03:13,120 --> 00:03:14,800
triggers

88
00:03:14,800 --> 00:03:16,640
before diving into our method let me

89
00:03:16,640 --> 00:03:19,120
first briefly introduce the uh

90
00:03:19,120 --> 00:03:21,120
the typical structure of nlp

91
00:03:21,120 --> 00:03:22,319
transformers

92
00:03:22,319 --> 00:03:24,720
so given a text input given a sentence

93
00:03:24,720 --> 00:03:26,959
the nlp transformers will first

94
00:03:26,959 --> 00:03:29,519
parsing into a list of token ids note

95
00:03:29,519 --> 00:03:31,200
that complex words will pass into

96
00:03:31,200 --> 00:03:33,840
multiple ids for example here the word

97
00:03:33,840 --> 00:03:36,720
uh judgments it's passed into two ids

98
00:03:36,720 --> 00:03:39,120
and then each token id is used to look

99
00:03:39,120 --> 00:03:41,360
up for an embedding vector with a size

100
00:03:41,360 --> 00:03:43,120
of 768.

101
00:03:43,120 --> 00:03:46,319
this e equal table id is indexing our

102
00:03:46,319 --> 00:03:49,680
operation and it is not differentiable

103
00:03:49,680 --> 00:03:51,519
then the embedding vectors are fed into

104
00:03:51,519 --> 00:03:53,680
the transformer to give the final

105
00:03:53,680 --> 00:03:56,400
final output note that in the in

106
00:03:56,400 --> 00:03:58,560
traditional computer vision models the

107
00:03:58,560 --> 00:04:00,319
model is differentiable from input to

108
00:04:00,319 --> 00:04:02,799
output however with the unique structure

109
00:04:02,799 --> 00:04:04,640
of nlp transformers

110
00:04:04,640 --> 00:04:06,799
poses new challenges in trigger

111
00:04:06,799 --> 00:04:08,560
inversion in lp

112
00:04:08,560 --> 00:04:11,599
our first challenge

113
00:04:12,480 --> 00:04:14,879
our first challenge is that the input

114
00:04:14,879 --> 00:04:15,920
space is

115
00:04:15,920 --> 00:04:18,160
is discrete and lp models are not

116
00:04:18,160 --> 00:04:20,399
differentiable to the input this lines

117
00:04:20,399 --> 00:04:22,960
in the table lookup operation that maps

118
00:04:22,960 --> 00:04:25,120
the token id to the

119
00:04:25,120 --> 00:04:27,199
imaging vectors note that this is

120
00:04:27,199 --> 00:04:29,440
indexing our operation and it is not

121
00:04:29,440 --> 00:04:30,800
differentiable

122
00:04:30,800 --> 00:04:33,680
and uh in the uh in in trigonometry in

123
00:04:33,680 --> 00:04:36,560
ccb we can just do the gradient back

124
00:04:36,560 --> 00:04:38,880
propagation from the output to the input

125
00:04:38,880 --> 00:04:42,000
however the gradient propagation in nlp

126
00:04:42,000 --> 00:04:43,919
cannot go through the table lookup to

127
00:04:43,919 --> 00:04:45,919
the token level

128
00:04:45,919 --> 00:04:48,400
so to so to solve the first challenge we

129
00:04:48,400 --> 00:04:49,840
propose a differentiable model

130
00:04:49,840 --> 00:04:51,759
transformation it essentially just

131
00:04:51,759 --> 00:04:54,160
transforms this non-differentiable table

132
00:04:54,160 --> 00:04:56,400
lookup into a differentiable matrix

133
00:04:56,400 --> 00:04:59,440
multiplication that is equivalent

134
00:04:59,440 --> 00:05:02,080
so given a list of token ids we first

135
00:05:02,080 --> 00:05:04,320
transform them into a list of uh one

136
00:05:04,320 --> 00:05:07,120
hardware where where one of the vectors

137
00:05:07,120 --> 00:05:09,520
we call the token vectors so for took

138
00:05:09,520 --> 00:05:12,080
idn the answer element of the welcome

139
00:05:12,080 --> 00:05:14,240
vector is one and all other elements are

140
00:05:14,240 --> 00:05:17,039
zero for example for two id uh for the

141
00:05:17,039 --> 00:05:19,840
first token id 119

142
00:05:19,840 --> 00:05:22,240
the rest of the 119th element is one and

143
00:05:22,240 --> 00:05:24,880
all other elements are zero then instead

144
00:05:24,880 --> 00:05:27,199
of do a table lookup we can simply get

145
00:05:27,199 --> 00:05:29,520
the word embeddings by multiplying the

146
00:05:29,520 --> 00:05:30,639
one

147
00:05:30,639 --> 00:05:33,199
how the token vectors with the

148
00:05:33,199 --> 00:05:36,080
width lookup table and this is

149
00:05:36,080 --> 00:05:38,560
equivalent to the table indexing i will

150
00:05:38,560 --> 00:05:40,880
use a simple example to illustrate this

151
00:05:40,880 --> 00:05:43,440
let's lastly we have a small

152
00:05:43,440 --> 00:05:45,919
lookup table with just four entries and

153
00:05:45,919 --> 00:05:49,840
our token id is one then the indexing of

154
00:05:49,840 --> 00:05:52,000
our operation we will just simply select

155
00:05:52,000 --> 00:05:55,759
the second vector 0.3 0.2 0.7 something

156
00:05:55,759 --> 00:05:57,600
and the corresponding one hold vector is

157
00:05:57,600 --> 00:06:02,560
0. 0 1 0 0 0 where the second element is

158
00:06:02,560 --> 00:06:05,680
1 and all other elements are 0.

159
00:06:05,680 --> 00:06:08,319
then do a matrix multiplication on the

160
00:06:08,319 --> 00:06:11,039
lookup table we can simply also get the

161
00:06:11,039 --> 00:06:12,240
same uh

162
00:06:12,240 --> 00:06:17,280
vector 0.2 0.3 0.7 verb and this is

163
00:06:17,280 --> 00:06:20,960
equivalent so the uh multiplying the one

164
00:06:20,960 --> 00:06:23,360
two vector and the lookup table is

165
00:06:23,360 --> 00:06:25,919
equivalent to the unindexing table and

166
00:06:25,919 --> 00:06:27,919
if we think about it as long as the sum

167
00:06:27,919 --> 00:06:29,840
of the token vector is one the token

168
00:06:29,840 --> 00:06:31,520
vector can also be billed as a

169
00:06:31,520 --> 00:06:33,440
probability distribution of the token

170
00:06:33,440 --> 00:06:35,840
ids so we can

171
00:06:35,840 --> 00:06:38,160
optimize on this tool vector to invert

172
00:06:38,160 --> 00:06:39,520
the trigger

173
00:06:39,520 --> 00:06:40,800
so let's go back to our model

174
00:06:40,800 --> 00:06:42,080
transformation

175
00:06:42,080 --> 00:06:44,479
after we have the bankhold token vectors

176
00:06:44,479 --> 00:06:46,240
we can get the word embeddings by

177
00:06:46,240 --> 00:06:48,880
multiplying the token vectors with the

178
00:06:48,880 --> 00:06:50,240
lookup table

179
00:06:50,240 --> 00:06:52,240
and we can feed the world embeddings to

180
00:06:52,240 --> 00:06:54,639
the transformer to follow the whole pro

181
00:06:54,639 --> 00:06:56,000
whole pipeline

182
00:06:56,000 --> 00:06:58,240
and this uh this of our operation is

183
00:06:58,240 --> 00:07:00,160
differentiable and the gradients can

184
00:07:00,160 --> 00:07:02,400
back propagate from the model output to

185
00:07:02,400 --> 00:07:05,840
the two total convectors and simply

186
00:07:05,840 --> 00:07:07,919
similarly to trigger inversion in cv we

187
00:07:07,919 --> 00:07:09,759
can just inject the trigger vector in

188
00:07:09,759 --> 00:07:12,000
the two comparator level to do the

189
00:07:12,000 --> 00:07:14,319
triggering version

190
00:07:14,319 --> 00:07:17,280
however then we met our second challenge

191
00:07:17,280 --> 00:07:19,280
uh token level optimization technology

192
00:07:19,280 --> 00:07:20,880
reverse engineer complex words with

193
00:07:20,880 --> 00:07:23,440
multiple tokens for example here our

194
00:07:23,440 --> 00:07:25,360
example uh trigger word is word

195
00:07:25,360 --> 00:07:28,160
immensity and in birth it's deleted into

196
00:07:28,160 --> 00:07:29,680
three tokens

197
00:07:29,680 --> 00:07:32,960
am m e and s i t y and assume we know

198
00:07:32,960 --> 00:07:35,039
the number of tokens we need and we use

199
00:07:35,039 --> 00:07:37,440
exactly three trigger two convectors in

200
00:07:37,440 --> 00:07:39,759
trigger inversion and the optimization

201
00:07:39,759 --> 00:07:43,360
shows the result is three tokens imvn

202
00:07:43,360 --> 00:07:45,599
and d-o-t-y and it misses the real

203
00:07:45,599 --> 00:07:47,840
trigger and these three uh inverted

204
00:07:47,840 --> 00:07:50,479
trigger can only flip around like 70 of

205
00:07:50,479 --> 00:07:53,039
clean samples and it is not good uh high

206
00:07:53,039 --> 00:07:54,639
enough for trigger immersion to

207
00:07:54,639 --> 00:07:56,800
determine this model is children

208
00:07:56,800 --> 00:07:59,360
so to invert complex uh trigger word

209
00:07:59,360 --> 00:08:01,280
token level inversion can easily get

210
00:08:01,280 --> 00:08:04,160
stuck in some invalid token combinations

211
00:08:04,160 --> 00:08:06,319
and that misses the real trigger

212
00:08:06,319 --> 00:08:08,720
so to solve the second challenge we

213
00:08:08,720 --> 00:08:10,800
propose word level inversion here i just

214
00:08:10,800 --> 00:08:12,879
showed a trigger took a leveling version

215
00:08:12,879 --> 00:08:15,039
on the left for comparison so give a

216
00:08:15,039 --> 00:08:17,520
text input given a sentence we first do

217
00:08:17,520 --> 00:08:19,919
a uh we first pass it into a list of

218
00:08:19,919 --> 00:08:22,479
word ids note that our word vocabulary

219
00:08:22,479 --> 00:08:24,800
contains many complex words so so they

220
00:08:24,800 --> 00:08:26,800
don't need to be splitted into multiple

221
00:08:26,800 --> 00:08:30,240
tokens for example here the word cha cha

222
00:08:30,240 --> 00:08:32,000
the word judgments only correspond to

223
00:08:32,000 --> 00:08:33,599
one id

224
00:08:33,599 --> 00:08:35,760
and then similarly we can do a one hard

225
00:08:35,760 --> 00:08:38,159
word like uh while hold factorization

226
00:08:38,159 --> 00:08:40,719
and get the word vectors and and

227
00:08:40,719 --> 00:08:43,120
similarly we can uh we can get the two

228
00:08:43,120 --> 00:08:45,760
vectors by multiplying the two word

229
00:08:45,760 --> 00:08:48,640
vectors with the word uh to token matrix

230
00:08:48,640 --> 00:08:50,959
and and we can guess what embeddings by

231
00:08:50,959 --> 00:08:53,360
multiplying the word uh two vectors with

232
00:08:53,360 --> 00:08:55,920
a loop with a lookup table the whole

233
00:08:55,920 --> 00:08:58,320
process is differentiable and we can

234
00:08:58,320 --> 00:09:00,399
similarly we can just invert the trigger

235
00:09:00,399 --> 00:09:03,440
at a word level and here notice that

236
00:09:03,440 --> 00:09:05,360
because we we use a large word

237
00:09:05,360 --> 00:09:07,440
vocabulary we only need one trigger

238
00:09:07,440 --> 00:09:10,000
vector to invert uh complex words such

239
00:09:10,000 --> 00:09:13,440
as immensity and this reduces the

240
00:09:13,440 --> 00:09:15,680
uh the search space and helps the

241
00:09:15,680 --> 00:09:18,240
trigger inversion

242
00:09:18,240 --> 00:09:20,000
so in this slide i will show how to do

243
00:09:20,000 --> 00:09:22,880
the word level inversion first we inject

244
00:09:22,880 --> 00:09:25,760
a vector in the word vectors we call it

245
00:09:25,760 --> 00:09:27,279
trigger probability

246
00:09:27,279 --> 00:09:29,440
trigger probability vector where each

247
00:09:29,440 --> 00:09:31,600
element stands for the probability of

248
00:09:31,600 --> 00:09:34,399
that word uh their corresponding words

249
00:09:34,399 --> 00:09:36,720
being the trigger and since we have made

250
00:09:36,720 --> 00:09:39,120
the whole whole pipeline differentiable

251
00:09:39,120 --> 00:09:42,000
we can just propagate the gradients from

252
00:09:42,000 --> 00:09:44,800
the model output to the word vectors and

253
00:09:44,800 --> 00:09:47,360
optimize this trig trigger probability

254
00:09:47,360 --> 00:09:48,720
vector

255
00:09:48,720 --> 00:09:50,880
in a way that it flips the model

256
00:09:50,880 --> 00:09:53,360
prediction on the clean samples

257
00:09:53,360 --> 00:09:55,120
we also uh bound this trigger

258
00:09:55,120 --> 00:09:57,440
probability like trigger probability

259
00:09:57,440 --> 00:10:00,240
vector to be between zero and one uh by

260
00:10:00,240 --> 00:10:03,040
tangent edge and we also normalize this

261
00:10:03,040 --> 00:10:05,040
trigger probability vector to the sum of

262
00:10:05,040 --> 00:10:07,279
1 in every 30 epochs

263
00:10:07,279 --> 00:10:08,480
so after

264
00:10:08,480 --> 00:10:09,360
the

265
00:10:09,360 --> 00:10:12,399
the optimization words with high values

266
00:10:12,399 --> 00:10:15,680
in the trigger probability vector are

267
00:10:15,680 --> 00:10:17,600
what we call the trigger word candidates

268
00:10:17,600 --> 00:10:19,920
and we test them for the attack success

269
00:10:19,920 --> 00:10:21,279
rate

270
00:10:21,279 --> 00:10:23,839
so here is the overview of our method

271
00:10:23,839 --> 00:10:24,640
uh

272
00:10:24,640 --> 00:10:27,360
given a model m and a clean and a set of

273
00:10:27,360 --> 00:10:29,360
clean inputs

274
00:10:29,360 --> 00:10:32,000
we first transform this model m into a

275
00:10:32,000 --> 00:10:34,800
differentiable equivalent model m prime

276
00:10:34,800 --> 00:10:36,320
and with the clean

277
00:10:36,320 --> 00:10:39,040
inputs uh we do a word uh word level

278
00:10:39,040 --> 00:10:40,720
trigger inversion and get a list of

279
00:10:40,720 --> 00:10:42,720
trigger word candidates and then the

280
00:10:42,720 --> 00:10:45,040
trigger word candidates is it's uh it's

281
00:10:45,040 --> 00:10:47,279
fed into a world discriminativity

282
00:10:47,279 --> 00:10:49,440
analysis and trigger validation to

283
00:10:49,440 --> 00:10:51,440
determine if the model is children or

284
00:10:51,440 --> 00:10:55,120
not uh in the first two straps actually

285
00:10:55,120 --> 00:10:56,880
corresponds to the two challenges i have

286
00:10:56,880 --> 00:10:58,560
talked about and in the word

287
00:10:58,560 --> 00:11:01,040
discriminativity analysis for complex

288
00:11:01,040 --> 00:11:03,120
words it is possible that we only invert

289
00:11:03,120 --> 00:11:05,040
a partial trigger word and it doesn't

290
00:11:05,040 --> 00:11:07,120
have high sr so it has the word

291
00:11:07,120 --> 00:11:09,200
discriminativity of the trigger word

292
00:11:09,200 --> 00:11:10,880
candidates to determine if a model is

293
00:11:10,880 --> 00:11:11,839
trojan

294
00:11:11,839 --> 00:11:13,680
and for trigger validation we simply

295
00:11:13,680 --> 00:11:16,480
test the text success rate of of the

296
00:11:16,480 --> 00:11:18,640
trigger word candidates and determine if

297
00:11:18,640 --> 00:11:20,320
the model is chosen due to the time

298
00:11:20,320 --> 00:11:22,720
limit i will utilize the details of the

299
00:11:22,720 --> 00:11:24,320
last two part

300
00:11:24,320 --> 00:11:26,880
so in evaluation we evaluate piccolo on

301
00:11:26,880 --> 00:11:28,800
seven datasets

302
00:11:28,800 --> 00:11:30,160
amazon

303
00:11:30,160 --> 00:11:32,640
amazon review mdb

304
00:11:32,640 --> 00:11:36,000
sst2 for sentimental classification coll

305
00:11:36,000 --> 00:11:39,680
2003 bncorps and onto nodes for name

306
00:11:39,680 --> 00:11:42,160
entity recognition and we also evaluated

307
00:11:42,160 --> 00:11:45,600
our method on seven lprt architectures

308
00:11:45,600 --> 00:11:47,920
bird distilled bird mobile birds

309
00:11:47,920 --> 00:11:52,079
gilberta jp2 and simple lstm and gru

310
00:11:52,079 --> 00:11:54,079
and we also evaluated our method against

311
00:11:54,079 --> 00:11:56,240
3830

312
00:11:56,240 --> 00:11:58,959
lp models from the trojan computation at

313
00:11:58,959 --> 00:12:01,040
the existing works

314
00:12:01,040 --> 00:12:03,680
and we also evaluate piccolo against 17

315
00:12:03,680 --> 00:12:04,720
different

316
00:12:04,720 --> 00:12:07,040
tech types including the latest

317
00:12:07,040 --> 00:12:08,800
dynamic attacks the sentence structure

318
00:12:08,800 --> 00:12:10,399
trigger

319
00:12:10,399 --> 00:12:12,639
before going into the evaluation details

320
00:12:12,639 --> 00:12:14,800
i want to first briefly introduce what

321
00:12:14,800 --> 00:12:18,160
is iopa's trojan computation it is a

322
00:12:18,160 --> 00:12:20,160
multi-year computation for backdoor

323
00:12:20,160 --> 00:12:23,519
scanning it is still going on right now

324
00:12:23,519 --> 00:12:25,760
and it is open to public so anyone can

325
00:12:25,760 --> 00:12:27,760
participate

326
00:12:27,760 --> 00:12:30,160
and uh it has nine rounds so far

327
00:12:30,160 --> 00:12:32,240
targeting for both computer vision and

328
00:12:32,240 --> 00:12:34,240
nlp

329
00:12:34,240 --> 00:12:36,399
and at each round trojan has like

330
00:12:36,399 --> 00:12:38,959
thousands of models half clean and half

331
00:12:38,959 --> 00:12:41,040
children and they ask the performers to

332
00:12:41,040 --> 00:12:43,440
submit their predictors that predicts

333
00:12:43,440 --> 00:12:46,079
which model is cho uh a uh contest

334
00:12:46,079 --> 00:12:47,519
backdoor

335
00:12:47,519 --> 00:12:49,200
and performers need to submit their

336
00:12:49,200 --> 00:12:51,360
scanners to the 2di remote server which

337
00:12:51,360 --> 00:12:53,440
evaluates the evaluation against

338
00:12:53,440 --> 00:12:55,360
the test and the holdout sets the test

339
00:12:55,360 --> 00:12:57,360
and holdout says uh

340
00:12:57,360 --> 00:12:59,600
we cannot access the test and hold

341
00:12:59,600 --> 00:13:01,519
outsets and they can have a more load

342
00:13:01,519 --> 00:13:03,680
robust your evaluation

343
00:13:03,680 --> 00:13:06,639
so the wrong target is around like 0.34

344
00:13:06,639 --> 00:13:08,560
cross entropy loss which is often

345
00:13:08,560 --> 00:13:10,880
correspond to around like a 90 percent

346
00:13:10,880 --> 00:13:12,160
accuracy

347
00:13:12,160 --> 00:13:15,279
so we uh so the lead the current to ji

348
00:13:15,279 --> 00:13:17,920
leaderboard is accessed can be accessed

349
00:13:17,920 --> 00:13:18,880
at this

350
00:13:18,880 --> 00:13:21,120
website and here i

351
00:13:21,120 --> 00:13:23,440
i show a screenshot of the trojan

352
00:13:23,440 --> 00:13:25,920
leaderboard as you can see you they have

353
00:13:25,920 --> 00:13:27,360
your evaluation server and you can

354
00:13:27,360 --> 00:13:29,600
submit your container to the evaluation

355
00:13:29,600 --> 00:13:32,240
server to to get uh to get it to get

356
00:13:32,240 --> 00:13:35,120
your message tested and here i showed

357
00:13:35,120 --> 00:13:35,920
the

358
00:13:35,920 --> 00:13:38,639
screenshot of the current uh current

359
00:13:38,639 --> 00:13:42,480
rounds to uh total gi leaderboard

360
00:13:42,480 --> 00:13:46,399
so in effectiveness our piccolo achieves

361
00:13:46,399 --> 00:13:48,880
over 0.9 detection accuracy for all the

362
00:13:48,880 --> 00:13:50,480
evaluated attacks

363
00:13:50,480 --> 00:13:53,360
and in children computation

364
00:13:53,360 --> 00:13:55,199
piccolo is the only solution that beats

365
00:13:55,199 --> 00:13:57,120
the round goal in all three lp

366
00:13:57,120 --> 00:13:59,600
classification runs and each

367
00:13:59,600 --> 00:14:02,160
and piccolo achieves the top on two out

368
00:14:02,160 --> 00:14:04,880
of three nlp runs in trojan competition

369
00:14:04,880 --> 00:14:07,519
so here i show a table of the trojan

370
00:14:07,519 --> 00:14:10,000
leaderboard with our method piccolo and

371
00:14:10,000 --> 00:14:12,639
other team's best star mission

372
00:14:12,639 --> 00:14:13,760
choji

373
00:14:13,760 --> 00:14:16,160
competitions release two uh metrics to

374
00:14:16,160 --> 00:14:18,880
measure the scanner's performance ce

375
00:14:18,880 --> 00:14:22,000
loss and roc aoc so a lower c loss and

376
00:14:22,000 --> 00:14:23,839
higher ioc you'll see indicates better

377
00:14:23,839 --> 00:14:26,880
performance and as you can see on

378
00:14:26,880 --> 00:14:28,720
round six and round seven our message

379
00:14:28,720 --> 00:14:29,920
picot piccolo

380
00:14:29,920 --> 00:14:31,440
is the best

381
00:14:31,440 --> 00:14:34,480
among other participants

382
00:14:34,480 --> 00:14:36,639
this is a related work to our message

383
00:14:36,639 --> 00:14:38,959
due to the time limit i will skip this

384
00:14:38,959 --> 00:14:43,040
and also uh we share our method and

385
00:14:43,040 --> 00:14:45,680
our 2s missions on different rounds in

386
00:14:45,680 --> 00:14:47,680
our online code apple

387
00:14:47,680 --> 00:14:50,160
to summarize uh we developed a novel

388
00:14:50,160 --> 00:14:52,399
backdoor scanning technique piccolo

389
00:14:52,399 --> 00:14:54,320
because it's based on a normal word

390
00:14:54,320 --> 00:14:55,680
level encoding and the word

391
00:14:55,680 --> 00:14:58,399
discriminativity analysis and based on

392
00:14:58,399 --> 00:15:00,079
the trojan computation results and

393
00:15:00,079 --> 00:15:03,040
evaluation piccolo achieves a state of

394
00:15:03,040 --> 00:15:04,160
art

395
00:15:04,160 --> 00:15:06,480
results for complex models and a wide

396
00:15:06,480 --> 00:15:08,480
range of backdoor attacks

397
00:15:08,480 --> 00:15:10,399
thank you that's all i'm happy to take

398
00:15:10,399 --> 00:15:12,050
any questions

399
00:15:12,050 --> 00:15:17,440
[Applause]

400
00:15:17,440 --> 00:15:20,399
so we have time for questions and

401
00:15:20,399 --> 00:15:23,040
as usual please feel free to

402
00:15:23,040 --> 00:15:25,199
don't be shy walk to the mic

403
00:15:25,199 --> 00:15:28,639
so they don't have an affiliation

404
00:15:29,920 --> 00:15:33,680
i can probably break the ice no

405
00:15:34,000 --> 00:15:36,720
you have a question

406
00:15:38,399 --> 00:15:40,240
hi uh dirt of the very northeastern

407
00:15:40,240 --> 00:15:42,880
university uh great talk and great work

408
00:15:42,880 --> 00:15:45,680
uh i i have a curiosity to ask you uh

409
00:15:45,680 --> 00:15:48,079
did you notice uh differences in

410
00:15:48,079 --> 00:15:49,759
effectiveness of your

411
00:15:49,759 --> 00:15:53,040
system on different sizes of the models

412
00:15:53,040 --> 00:15:55,199
you analyze like bigger models smaller

413
00:15:55,199 --> 00:15:56,800
models model trains with bigger data

414
00:15:56,800 --> 00:15:59,279
sets smaller data sets yes that's a

415
00:15:59,279 --> 00:16:02,560
great question uh so on

416
00:16:02,560 --> 00:16:06,079
let me go back here

417
00:16:06,480 --> 00:16:08,399
so on the seven different lp

418
00:16:08,399 --> 00:16:10,000
architectures we

419
00:16:10,000 --> 00:16:13,040
uh we uh we do a kind of like uh

420
00:16:13,040 --> 00:16:15,839
statistical check and we we found that

421
00:16:15,839 --> 00:16:18,000
actually on roberta we only uh we are a

422
00:16:18,000 --> 00:16:20,560
little bit worse than both the uh andrew

423
00:16:20,560 --> 00:16:22,880
roberta jpt2 were a little bit worse

424
00:16:22,880 --> 00:16:26,480
than berlin d silver and mobile world uh

425
00:16:26,480 --> 00:16:28,079
and but

426
00:16:28,079 --> 00:16:30,079
overall the architecture does not matter

427
00:16:30,079 --> 00:16:32,959
that much uh in terms of three uh like

428
00:16:32,959 --> 00:16:35,680
different attack tabs we handle the

429
00:16:35,680 --> 00:16:37,440
freeze trigger the worst

430
00:16:37,440 --> 00:16:39,759
because we are inversion technique and

431
00:16:39,759 --> 00:16:42,639
usually it's very hard to invert a whole

432
00:16:42,639 --> 00:16:44,079
phrase

433
00:16:44,079 --> 00:16:46,160
but the details can be found in our

434
00:16:46,160 --> 00:16:50,120
paper thank you

435
00:16:51,920 --> 00:16:53,120
i have a question

436
00:16:53,120 --> 00:16:56,639
um so for you mentioned that uh to to

437
00:16:56,639 --> 00:16:58,560
make the whole model than differentiable

438
00:16:58,560 --> 00:17:00,560
you don't use don't rely on token

439
00:17:00,560 --> 00:17:02,079
inversion anymore but then you use

440
00:17:02,079 --> 00:17:04,079
wording version yes because you have to

441
00:17:04,079 --> 00:17:05,679
do the one hot encoding and then

442
00:17:05,679 --> 00:17:07,280
multiply that matrix and you know to

443
00:17:07,280 --> 00:17:08,559
make it work

444
00:17:08,559 --> 00:17:10,400
um you said that in the example for

445
00:17:10,400 --> 00:17:12,160
instance you need to have the word in

446
00:17:12,160 --> 00:17:15,839
your vocabulary right so how big is the

447
00:17:15,839 --> 00:17:19,119
that's a that's a great question so uh

448
00:17:19,119 --> 00:17:22,480
so in the um so several things uh first

449
00:17:22,480 --> 00:17:23,359
uh

450
00:17:23,359 --> 00:17:25,919
so you know our hours the system that's

451
00:17:25,919 --> 00:17:28,079
uh submitted in the paper

452
00:17:28,079 --> 00:17:30,880
at that time we have like 7000 as the

453
00:17:30,880 --> 00:17:33,440
word vocabulary and the

454
00:17:33,440 --> 00:17:35,520
adaptive attacks we have uh increased

455
00:17:35,520 --> 00:17:39,679
the vocabulary from 7 000 to 30 000 and

456
00:17:39,679 --> 00:17:41,600
uh because the childreni competition is

457
00:17:41,600 --> 00:17:43,679
still going on and in the latest round

458
00:17:43,679 --> 00:17:45,760
around nine we are we increased our

459
00:17:45,760 --> 00:17:49,200
world vocabulary to over a hundred so so

460
00:17:49,200 --> 00:17:51,120
overall hundred thousand based on the

461
00:17:51,120 --> 00:17:54,080
word uh frequency in the wikipedia day

462
00:17:54,080 --> 00:17:56,640
data set right and and how do you see

463
00:17:56,640 --> 00:17:58,240
this improving like have you tried to

464
00:17:58,240 --> 00:18:00,400
compare the performance

465
00:18:00,400 --> 00:18:03,360
uh as as the vocabulary size increases

466
00:18:03,360 --> 00:18:04,559
like there is a point where you have a

467
00:18:04,559 --> 00:18:06,080
saturation point that you know adding

468
00:18:06,080 --> 00:18:07,600
more words doesn't look like you know

469
00:18:07,600 --> 00:18:08,480
yes

470
00:18:08,480 --> 00:18:10,240
that's a good question uh

471
00:18:10,240 --> 00:18:12,960
we have done an adaptive attack on like

472
00:18:12,960 --> 00:18:15,520
if the words is outside the word uh word

473
00:18:15,520 --> 00:18:17,760
vocabulary and uh

474
00:18:17,760 --> 00:18:20,320
we find that as long as we can increase

475
00:18:20,320 --> 00:18:22,880
the size of vocabulary we we can still

476
00:18:22,880 --> 00:18:25,280
have a good performance and in terms of

477
00:18:25,280 --> 00:18:27,520
the competition uh

478
00:18:27,520 --> 00:18:29,440
fulfilling we feel that

479
00:18:29,440 --> 00:18:32,080
the previous rounds uh the the solutions

480
00:18:32,080 --> 00:18:34,080
that works on the like round seven and

481
00:18:34,080 --> 00:18:35,919
round eight it's not that effective on

482
00:18:35,919 --> 00:18:38,160
round nine that's why we go from like

483
00:18:38,160 --> 00:18:40,960
twenty thousand to like over hundreds of

484
00:18:40,960 --> 00:18:42,480
southern income

485
00:18:42,480 --> 00:18:43,760
to achieve good performance in

486
00:18:43,760 --> 00:18:46,960
competition yeah thank you wonderful

487
00:18:46,960 --> 00:18:48,559
thank you thank you

488
00:18:48,559 --> 00:18:49,360
um

489
00:18:49,360 --> 00:18:50,880
so if there are no other

490
00:18:50,880 --> 00:18:52,240
any other questions so we can thank the

491
00:18:52,240 --> 00:18:53,460
speaker

492
00:18:53,460 --> 00:18:56,819
[Applause]

