1
00:00:01,199 --> 00:00:02,960
all right good afternoon everyone my

2
00:00:02,960 --> 00:00:05,279
name is tsuji i'm going to present our

3
00:00:05,279 --> 00:00:06,799
work wt graph

4
00:00:06,799 --> 00:00:09,440
web tracking and advertising detection

5
00:00:09,440 --> 00:00:11,120
using graph neural networks this is a

6
00:00:11,120 --> 00:00:13,360
journal work with wii ping mong chu and

7
00:00:13,360 --> 00:00:14,880
tren

8
00:00:14,880 --> 00:00:17,680
all right so what is web tracking well

9
00:00:17,680 --> 00:00:20,160
when we are visiting a webpage behind

10
00:00:20,160 --> 00:00:22,800
the scenes trackers are collecting our

11
00:00:22,800 --> 00:00:24,560
browsing information

12
00:00:24,560 --> 00:00:25,439
and

13
00:00:25,439 --> 00:00:27,119
well it turns out the web tracking is

14
00:00:27,119 --> 00:00:29,199
performed on the vast majority of the

15
00:00:29,199 --> 00:00:30,960
websites according to different

16
00:00:30,960 --> 00:00:32,640
environment studies

17
00:00:32,640 --> 00:00:35,680
but why would they do that targeted ads

18
00:00:35,680 --> 00:00:38,239
and the site analytics right behind

19
00:00:38,239 --> 00:00:40,480
targeted ads these are like large

20
00:00:40,480 --> 00:00:43,040
business markets okay how do they do

21
00:00:43,040 --> 00:00:45,360
that cookie is definitely the one and

22
00:00:45,360 --> 00:00:47,600
it's a widely used one also some other

23
00:00:47,600 --> 00:00:49,360
ones techniques such as

24
00:00:49,360 --> 00:00:50,800
browser fingerprinting device

25
00:00:50,800 --> 00:00:52,399
fingerprint printing synthetic printing

26
00:00:52,399 --> 00:00:55,039
canvas fingerprinting you name it okay

27
00:00:55,039 --> 00:00:56,000
so

28
00:00:56,000 --> 00:00:58,800
basically with web tracking we see it is

29
00:00:58,800 --> 00:01:00,559
like a compromise

30
00:01:00,559 --> 00:01:03,039
of our privacy as set as this dog over

31
00:01:03,039 --> 00:01:06,720
here we don't want being tracked okay

32
00:01:06,720 --> 00:01:09,439
so what we can do well as a web user you

33
00:01:09,439 --> 00:01:11,920
can use browser extensions such as

34
00:01:11,920 --> 00:01:15,520
adblock ublock adblock plus so those are

35
00:01:15,520 --> 00:01:16,320
all

36
00:01:16,320 --> 00:01:18,799
field list business solutions and in

37
00:01:18,799 --> 00:01:21,280
recent years we have machine learning

38
00:01:21,280 --> 00:01:23,680
based solutions such as ad graph no more

39
00:01:23,680 --> 00:01:27,119
ads right and a few more so here there

40
00:01:27,119 --> 00:01:29,280
are some limitations with both solutions

41
00:01:29,280 --> 00:01:30,799
for example with the first one filter

42
00:01:30,799 --> 00:01:31,759
list

43
00:01:31,759 --> 00:01:33,920
solutions you have a rubik's you're

44
00:01:33,920 --> 00:01:36,159
going to spend a lot of effort to

45
00:01:36,159 --> 00:01:38,400
manually maintain the field list and

46
00:01:38,400 --> 00:01:40,079
here with the machine learning business

47
00:01:40,079 --> 00:01:41,119
solution

48
00:01:41,119 --> 00:01:43,040
they are still performance wise there's

49
00:01:43,040 --> 00:01:45,439
still a lot of room to improve that's

50
00:01:45,439 --> 00:01:47,040
why in this work we want to have a

51
00:01:47,040 --> 00:01:48,079
better

52
00:01:48,079 --> 00:01:50,399
tracking and advertising detection to

53
00:01:50,399 --> 00:01:52,560
help out this dog over here and to also

54
00:01:52,560 --> 00:01:55,840
protect ourselves okay so with this

55
00:01:55,840 --> 00:01:58,320
skull we have like a rather

56
00:01:58,320 --> 00:02:01,119
straightforward intuition that is we can

57
00:02:01,119 --> 00:02:03,759
have a graph to represent the web

58
00:02:03,759 --> 00:02:06,560
traffic where we have the nodes

59
00:02:06,560 --> 00:02:09,440
representing the domains and in between

60
00:02:09,440 --> 00:02:12,160
those nodes we have ads representing

61
00:02:12,160 --> 00:02:14,000
cstp traffic

62
00:02:14,000 --> 00:02:16,400
and with this graph

63
00:02:16,400 --> 00:02:19,920
we can formulate the task of detection

64
00:02:19,920 --> 00:02:20,879
to be

65
00:02:20,879 --> 00:02:21,840
as

66
00:02:21,840 --> 00:02:23,840
edge classification so basically you

67
00:02:23,840 --> 00:02:25,680
have a graph over here and you have two

68
00:02:25,680 --> 00:02:28,000
types of edge the green one is the red

69
00:02:28,000 --> 00:02:30,239
one uh either it is tracking or none

70
00:02:30,239 --> 00:02:32,800
tracking it's a binary classification

71
00:02:32,800 --> 00:02:35,680
all right so more formally we have this

72
00:02:35,680 --> 00:02:38,080
attributed homogeneous multigraph where

73
00:02:38,080 --> 00:02:40,480
i can reference the web traffic and as

74
00:02:40,480 --> 00:02:42,400
you can see you definitely can source it

75
00:02:42,400 --> 00:02:44,560
different features or attributes to the

76
00:02:44,560 --> 00:02:46,959
nodes and edge and also in between those

77
00:02:46,959 --> 00:02:48,480
different nodes you can have multiple

78
00:02:48,480 --> 00:02:52,080
ads which is very realistic nowadays

79
00:02:52,080 --> 00:02:54,640
with web traffic and then formally the

80
00:02:54,640 --> 00:02:56,879
task will be the edge representation

81
00:02:56,879 --> 00:02:57,920
learning

82
00:02:57,920 --> 00:03:00,480
and classification in such a graph

83
00:03:00,480 --> 00:03:02,480
while we pick up gene which is graph

84
00:03:02,480 --> 00:03:04,800
neural network it is because it's really

85
00:03:04,800 --> 00:03:06,720
a great choice for this type type of

86
00:03:06,720 --> 00:03:08,319
task um

87
00:03:08,319 --> 00:03:09,920
we have like a graph structured data

88
00:03:09,920 --> 00:03:13,360
over here and also ga is known for its

89
00:03:13,360 --> 00:03:15,680
like neighborhood aggregation

90
00:03:15,680 --> 00:03:17,920
also known as message passing so that

91
00:03:17,920 --> 00:03:20,560
mechanism can leverage and learn the

92
00:03:20,560 --> 00:03:22,000
implicit

93
00:03:22,000 --> 00:03:23,760
feature of the

94
00:03:23,760 --> 00:03:25,200
graph structure

95
00:03:25,200 --> 00:03:28,000
so with different works papers projects

96
00:03:28,000 --> 00:03:29,680
they have shown that graph neural

97
00:03:29,680 --> 00:03:31,840
network can outperform i must learn

98
00:03:31,840 --> 00:03:34,159
traditional machine learning a lot okay

99
00:03:34,159 --> 00:03:35,920
all right so this is our

100
00:03:35,920 --> 00:03:38,560
formulation and this is our intuition so

101
00:03:38,560 --> 00:03:41,760
with that we we implemented the wt graph

102
00:03:41,760 --> 00:03:43,519
so over here we have like four

103
00:03:43,519 --> 00:03:46,000
components and we have a data collector

104
00:03:46,000 --> 00:03:48,159
basically it's like a broad extension we

105
00:03:48,159 --> 00:03:50,799
use that to collect its gpu traffic and

106
00:03:50,799 --> 00:03:53,280
other data and then the second component

107
00:03:53,280 --> 00:03:55,599
we have the data collector

108
00:03:55,599 --> 00:03:58,720
where we can build the graph from the

109
00:03:58,720 --> 00:04:00,799
collected data meanwhile we can also

110
00:04:00,799 --> 00:04:03,680
extract the features so like the

111
00:04:03,680 --> 00:04:06,560
character embedding statics of the url

112
00:04:06,560 --> 00:04:09,519
and the dom so and so forth continue we

113
00:04:09,519 --> 00:04:13,120
have our unique wtng over here so it can

114
00:04:13,120 --> 00:04:15,519
directly work on our attributed

115
00:04:15,519 --> 00:04:17,600
homogeneous multi graph so basically

116
00:04:17,600 --> 00:04:20,079
with this which in the model and the

117
00:04:20,079 --> 00:04:22,079
corresponding we have the next uh the

118
00:04:22,079 --> 00:04:24,960
last component that can classify whether

119
00:04:24,960 --> 00:04:28,240
or not representing http traffic is

120
00:04:28,240 --> 00:04:30,160
tracking or not

121
00:04:30,160 --> 00:04:32,320
all right so as you can see here we have

122
00:04:32,320 --> 00:04:34,080
two different settings transductive

123
00:04:34,080 --> 00:04:36,400
setting and inductive setting so for the

124
00:04:36,400 --> 00:04:38,400
transductive setting here we're assuming

125
00:04:38,400 --> 00:04:40,320
that we have all the data ready

126
00:04:40,320 --> 00:04:42,800
basically we build a graph and then we

127
00:04:42,800 --> 00:04:44,720
do the printation

128
00:04:44,720 --> 00:04:47,199
prediction i'm sorry so so application

129
00:04:47,199 --> 00:04:49,360
scenario for this could be you have you

130
00:04:49,360 --> 00:04:51,199
want to have field list generation you

131
00:04:51,199 --> 00:04:53,759
want to generate rules and then on the

132
00:04:53,759 --> 00:04:55,919
bottom part we have the inductive

133
00:04:55,919 --> 00:04:57,680
setting where it's kind of more

134
00:04:57,680 --> 00:05:00,160
realistic that is your trainer model and

135
00:05:00,160 --> 00:05:02,080
later you got a new edges coming in

136
00:05:02,080 --> 00:05:03,680
you're going to present those unseen

137
00:05:03,680 --> 00:05:06,320
edges okay so the more realistically you

138
00:05:06,320 --> 00:05:09,199
can have the real-time detection

139
00:05:09,199 --> 00:05:11,520
right and i want to give a little bit

140
00:05:11,520 --> 00:05:13,440
more details regarding how do we learn

141
00:05:13,440 --> 00:05:15,840
the idea representation with our

142
00:05:15,840 --> 00:05:18,320
graph neural network so it is learned by

143
00:05:18,320 --> 00:05:21,120
aggregating the neighborhood node

144
00:05:21,120 --> 00:05:23,039
representation plus

145
00:05:23,039 --> 00:05:25,120
the neighborhood address representation

146
00:05:25,120 --> 00:05:27,360
plus its own representation just like

147
00:05:27,360 --> 00:05:30,080
here in this simple graph

148
00:05:30,080 --> 00:05:31,919
let's say our target ad uses a green

149
00:05:31,919 --> 00:05:34,479
edge the reputation is learned by

150
00:05:34,479 --> 00:05:36,720
incorporating it serves its own

151
00:05:36,720 --> 00:05:38,880
representation plus the source nodes and

152
00:05:38,880 --> 00:05:41,759
destination nodes plus the neighborhoods

153
00:05:41,759 --> 00:05:44,400
ads okay this is how we learn that

154
00:05:44,400 --> 00:05:45,840
representation

155
00:05:45,840 --> 00:05:48,800
and to continue uh here is we have the

156
00:05:48,800 --> 00:05:51,120
algorithm i will not spend time on

157
00:05:51,120 --> 00:05:52,479
explaining this

158
00:05:52,479 --> 00:05:55,280
you can read more in our paper

159
00:05:55,280 --> 00:05:57,440
so here we have we implemented this

160
00:05:57,440 --> 00:05:59,520
update graph and now we want to check

161
00:05:59,520 --> 00:06:00,240
hey

162
00:06:00,240 --> 00:06:02,479
how well does it perform we have

163
00:06:02,479 --> 00:06:04,800
different evaluation experiments in two

164
00:06:04,800 --> 00:06:06,560
different settings like here in the

165
00:06:06,560 --> 00:06:08,160
transductive setting

166
00:06:08,160 --> 00:06:10,560
so first of all introduce our data set

167
00:06:10,560 --> 00:06:13,319
we use our data collector we collected

168
00:06:13,319 --> 00:06:17,840
1.5 million requests from alexa top 10k

169
00:06:17,840 --> 00:06:20,479
websites and using filter lists we

170
00:06:20,479 --> 00:06:21,520
labeled

171
00:06:21,520 --> 00:06:24,960
39 percent of them as tracking or were

172
00:06:24,960 --> 00:06:26,880
insured like wta

173
00:06:26,880 --> 00:06:30,240
and recur a little bit with transductive

174
00:06:30,240 --> 00:06:32,160
setting what we want to do is that we

175
00:06:32,160 --> 00:06:34,240
observe all the data and we build a

176
00:06:34,240 --> 00:06:36,400
graph we train the model and we predict

177
00:06:36,400 --> 00:06:38,639
that so what we do over here is that we

178
00:06:38,639 --> 00:06:40,319
predict the edge with 10-fold

179
00:06:40,319 --> 00:06:42,000
cross-validation

180
00:06:42,000 --> 00:06:43,919
so this is the performance symbol

181
00:06:43,919 --> 00:06:46,240
summarize it here we have the we have

182
00:06:46,240 --> 00:06:49,280
two baseline models well technically

183
00:06:49,280 --> 00:06:51,680
three so here the first one which is the

184
00:06:51,680 --> 00:06:53,440
link prediction model

185
00:06:53,440 --> 00:06:55,280
this is one of our baseline model the

186
00:06:55,280 --> 00:06:57,199
idea with this one is that you learn the

187
00:06:57,199 --> 00:06:58,880
ideal representation

188
00:06:58,880 --> 00:07:00,479
by

189
00:07:00,479 --> 00:07:02,160
averaging the source node and

190
00:07:02,160 --> 00:07:04,560
destination nodes representations so

191
00:07:04,560 --> 00:07:06,800
this this works well with a simple graph

192
00:07:06,800 --> 00:07:09,520
but recall here we have a multi-graph so

193
00:07:09,520 --> 00:07:11,440
as you can imagine as you can see from

194
00:07:11,440 --> 00:07:13,120
these numbers it doesn't perform that

195
00:07:13,120 --> 00:07:15,599
well and continue we have mlp

196
00:07:15,599 --> 00:07:18,479
classic neural network but for this one

197
00:07:18,479 --> 00:07:21,199
there's no graph involved at all

198
00:07:21,199 --> 00:07:23,199
continue next in the third one we have

199
00:07:23,199 --> 00:07:25,840
our advanced link prediction basically

200
00:07:25,840 --> 00:07:28,319
for this one the idea is more like hey

201
00:07:28,319 --> 00:07:29,280
in

202
00:07:29,280 --> 00:07:32,000
incorporating the own its own actual

203
00:07:32,000 --> 00:07:35,440
condition with the node representations

204
00:07:35,440 --> 00:07:37,599
but for this one if you compare with our

205
00:07:37,599 --> 00:07:39,680
final version there's no neighborhood

206
00:07:39,680 --> 00:07:42,960
edge aggregation okay so as you can tell

207
00:07:42,960 --> 00:07:45,039
from this numbers over here definitely

208
00:07:45,039 --> 00:07:47,599
deputy graph works very well and several

209
00:07:47,599 --> 00:07:50,000
messages behind these numbers first of

210
00:07:50,000 --> 00:07:53,039
all without a graph let's check the mlp

211
00:07:53,039 --> 00:07:55,199
the numbers for mrp really you compare

212
00:07:55,199 --> 00:07:57,599
that with like the third and the first

213
00:07:57,599 --> 00:07:59,039
one

214
00:07:59,039 --> 00:08:01,280
without a graph without graphing your

215
00:08:01,280 --> 00:08:03,360
network uh the performance is a little

216
00:08:03,360 --> 00:08:05,599
bit worse and also if you compare the

217
00:08:05,599 --> 00:08:09,199
last two which of us all of them are our

218
00:08:09,199 --> 00:08:11,680
models you can see that neighborhood

219
00:08:11,680 --> 00:08:13,919
edge aggregation really helps to improve

220
00:08:13,919 --> 00:08:15,440
the performance

221
00:08:15,440 --> 00:08:16,400
okay

222
00:08:16,400 --> 00:08:19,520
um continue we have this

223
00:08:19,520 --> 00:08:22,080
you might wonder in the previous slides

224
00:08:22,080 --> 00:08:24,160
hey you use filter lists as a ground

225
00:08:24,160 --> 00:08:26,560
choose to label your ads this is a

226
00:08:26,560 --> 00:08:29,039
concern right and you might don't agree

227
00:08:29,039 --> 00:08:31,759
with that because in fact what you want

228
00:08:31,759 --> 00:08:34,559
with this work is that you want wt graph

229
00:08:34,559 --> 00:08:36,320
to identify

230
00:08:36,320 --> 00:08:38,479
trackings that are missed or not

231
00:08:38,479 --> 00:08:41,599
included by field lists so this is

232
00:08:41,599 --> 00:08:43,120
something we want we want to go beyond

233
00:08:43,120 --> 00:08:45,760
the filter list well to address and to

234
00:08:45,760 --> 00:08:48,160
evaluate this concern we did a lot of

235
00:08:48,160 --> 00:08:50,640
manual verification uh we in total

236
00:08:50,640 --> 00:08:53,600
sample like over 4000 requests here we

237
00:08:53,600 --> 00:08:56,480
have some um we have some readouts for

238
00:08:56,480 --> 00:08:59,519
example we send out those false

239
00:08:59,519 --> 00:09:01,760
positives and we manually verified so

240
00:09:01,760 --> 00:09:02,720
for

241
00:09:02,720 --> 00:09:05,760
positives that is filter lists consider

242
00:09:05,760 --> 00:09:10,160
those requests as noun checking but our

243
00:09:10,160 --> 00:09:13,600
wt graph classifies them as tracking so

244
00:09:13,600 --> 00:09:16,000
for cases like that we verified that

245
00:09:16,000 --> 00:09:18,120
around 40 percent of the time

246
00:09:18,120 --> 00:09:21,120
wt graph indeed is correct so which

247
00:09:21,120 --> 00:09:23,200
means it can detect

248
00:09:23,200 --> 00:09:25,839
tracking that are missed by future lists

249
00:09:25,839 --> 00:09:28,480
continue for the false negatives which

250
00:09:28,480 --> 00:09:30,160
means like the future lists consider

251
00:09:30,160 --> 00:09:31,519
them as

252
00:09:31,519 --> 00:09:35,279
tracking but our wt graphs of our wt

253
00:09:35,279 --> 00:09:36,399
graph here

254
00:09:36,399 --> 00:09:38,480
classifies them as noun checking for

255
00:09:38,480 --> 00:09:41,120
cases like that around 70 percent of the

256
00:09:41,120 --> 00:09:45,040
time we are correct which means um

257
00:09:45,040 --> 00:09:47,519
feudalists incorrectly label them as

258
00:09:47,519 --> 00:09:50,080
tracking and the wt graph over here can

259
00:09:50,080 --> 00:09:51,760
recognize all right you did something

260
00:09:51,760 --> 00:09:53,279
wrong okay

261
00:09:53,279 --> 00:09:56,320
um so basically here um we have we have

262
00:09:56,320 --> 00:09:58,800
more like experiments results in the

263
00:09:58,800 --> 00:10:00,480
paper you can refer

264
00:10:00,480 --> 00:10:03,040
refer to the paper for details but here

265
00:10:03,040 --> 00:10:05,600
as you can see indeed the wt graph can

266
00:10:05,600 --> 00:10:09,279
do more more than future lists okay

267
00:10:09,279 --> 00:10:11,600
continue here recall we have the second

268
00:10:11,600 --> 00:10:12,959
setting which is

269
00:10:12,959 --> 00:10:14,720
inductive setting which is a more

270
00:10:14,720 --> 00:10:16,959
realistic one where what we want to do

271
00:10:16,959 --> 00:10:18,480
is that we want to have a pre-trained

272
00:10:18,480 --> 00:10:21,440
model to predict um the traffic to

273
00:10:21,440 --> 00:10:23,760
predict the request that has never been

274
00:10:23,760 --> 00:10:26,240
seen during the training phase here we

275
00:10:26,240 --> 00:10:28,959
train the four models on graphs with

276
00:10:28,959 --> 00:10:31,600
different size and then we evaluate on

277
00:10:31,600 --> 00:10:34,320
the rest answering websites for sensing

278
00:10:34,320 --> 00:10:37,360
webpage uh answering requests so here is

279
00:10:37,360 --> 00:10:39,040
the performance this

280
00:10:39,040 --> 00:10:41,120
uh this figure over here summarizes the

281
00:10:41,120 --> 00:10:45,839
performance on the very left we have the

282
00:10:45,839 --> 00:10:48,320
wt graph in the transactive

283
00:10:48,320 --> 00:10:51,519
setting for comparison as you can see um

284
00:10:51,519 --> 00:10:53,600
here basically the message is that for

285
00:10:53,600 --> 00:10:55,920
example with this random 7k model that

286
00:10:55,920 --> 00:10:58,399
is we train the model with a graph build

287
00:10:58,399 --> 00:11:02,800
it with 7k website traffic so with that

288
00:11:02,800 --> 00:11:04,880
the performance the accuracy is like 98

289
00:11:04,880 --> 00:11:07,440
percent uh precision 98

290
00:11:07,440 --> 00:11:10,160
and a recall 96 percent is very close

291
00:11:10,160 --> 00:11:12,399
to the model in the transductive setting

292
00:11:12,399 --> 00:11:14,240
but as you can tell like it's a large

293
00:11:14,240 --> 00:11:16,640
the graph the better your the better

294
00:11:16,640 --> 00:11:19,600
performance you will have okay

295
00:11:19,600 --> 00:11:22,640
so continue we want to evaluate hey how

296
00:11:22,640 --> 00:11:24,240
robust is it

297
00:11:24,240 --> 00:11:26,959
is it possible to evade your detection

298
00:11:26,959 --> 00:11:28,720
well we consider four division

299
00:11:28,720 --> 00:11:31,200
detections considering here we have a

300
00:11:31,200 --> 00:11:34,480
tracking url and the tracker could could

301
00:11:34,480 --> 00:11:37,279
change the second level domain like the

302
00:11:37,279 --> 00:11:39,440
added cdn over here so we can change

303
00:11:39,440 --> 00:11:41,360
that meanwhile it can also change the

304
00:11:41,360 --> 00:11:43,360
lower level domains for example change

305
00:11:43,360 --> 00:11:46,240
the add or serve at the very beginning

306
00:11:46,240 --> 00:11:49,040
and also how about they expand the url

307
00:11:49,040 --> 00:11:51,200
lens because here in this work we

308
00:11:51,200 --> 00:11:53,839
truncate the url at length 200. we want

309
00:11:53,839 --> 00:11:56,000
to figure out whether that is a problem

310
00:11:56,000 --> 00:11:58,399
or not what if the uh the ui is larger

311
00:11:58,399 --> 00:12:00,880
than 200 characters

312
00:12:00,880 --> 00:12:02,560
continue you can you can also the

313
00:12:02,560 --> 00:12:04,079
trackers can also replace those

314
00:12:04,079 --> 00:12:06,000
sensitive keywords like the tracking in

315
00:12:06,000 --> 00:12:07,360
the past you can see

316
00:12:07,360 --> 00:12:09,360
you can replace that with necessity of

317
00:12:09,360 --> 00:12:10,880
keywords

318
00:12:10,880 --> 00:12:13,600
here this table summarize

319
00:12:13,600 --> 00:12:16,320
the successful division rate against our

320
00:12:16,320 --> 00:12:18,959
wt graph for example

321
00:12:18,959 --> 00:12:21,040
here with the first division technique

322
00:12:21,040 --> 00:12:23,760
changing the second level domain

323
00:12:23,760 --> 00:12:25,279
three around three percent of the

324
00:12:25,279 --> 00:12:27,839
traffic can successfully evade our

325
00:12:27,839 --> 00:12:30,160
detection for comparison

326
00:12:30,160 --> 00:12:31,040
that

327
00:12:31,040 --> 00:12:33,519
for the uh for the filter list that will

328
00:12:33,519 --> 00:12:36,639
be over 57 of the traffic can

329
00:12:36,639 --> 00:12:39,040
successfully evade the detection of

330
00:12:39,040 --> 00:12:40,959
filter lists but it is reasonable

331
00:12:40,959 --> 00:12:42,720
because field list over here is more

332
00:12:42,720 --> 00:12:45,600
like rubies they have hard-coded

333
00:12:45,600 --> 00:12:47,760
domain names in their roots so that's

334
00:12:47,760 --> 00:12:49,600
why if they change if the trackers

335
00:12:49,600 --> 00:12:51,600
change their domain name

336
00:12:51,600 --> 00:12:52,399
it is

337
00:12:52,399 --> 00:12:54,959
it is reasonable that it can evit those

338
00:12:54,959 --> 00:12:56,480
detection

339
00:12:56,480 --> 00:12:57,360
all right

340
00:12:57,360 --> 00:13:00,320
a quick sum up so here our goal is that

341
00:13:00,320 --> 00:13:02,480
we want to have tracking and advertising

342
00:13:02,480 --> 00:13:04,959
detection and the intuition is rather

343
00:13:04,959 --> 00:13:07,680
straightforward we want to have this

344
00:13:07,680 --> 00:13:10,800
graph to represent the web traffic

345
00:13:10,800 --> 00:13:12,160
and

346
00:13:12,160 --> 00:13:14,240
in which the node represents the domain

347
00:13:14,240 --> 00:13:18,000
and the address request and we formulate

348
00:13:18,000 --> 00:13:20,480
this detection task as an edge

349
00:13:20,480 --> 00:13:22,560
classification problem it's a binary

350
00:13:22,560 --> 00:13:23,839
classification

351
00:13:23,839 --> 00:13:26,320
and then we design and build this step t

352
00:13:26,320 --> 00:13:27,279
graph

353
00:13:27,279 --> 00:13:30,079
one of the key component is the wt graph

354
00:13:30,079 --> 00:13:32,839
neural network and it doesn't work

355
00:13:32,839 --> 00:13:35,519
excellently all right so

356
00:13:35,519 --> 00:13:37,040
this is pretty much all what i have for

357
00:13:37,040 --> 00:13:39,440
you and you can read more in our paper

358
00:13:39,440 --> 00:13:41,600
or you check our release source code on

359
00:13:41,600 --> 00:13:44,399
github i'm happy to take any questions

360
00:13:44,399 --> 00:13:46,560
now

361
00:13:46,560 --> 00:13:52,000
[Applause]

362
00:13:52,000 --> 00:13:54,720
we have questions

363
00:13:54,880 --> 00:13:56,800
so i have a good question did you also

364
00:13:56,800 --> 00:13:58,720
compare real-time performance of this

365
00:13:58,720 --> 00:14:00,720
with the previous work and which one was

366
00:14:00,720 --> 00:14:01,839
not better

367
00:14:01,839 --> 00:14:04,240
yes uh this is regret we have that we

368
00:14:04,240 --> 00:14:05,680
have the real-time performance

369
00:14:05,680 --> 00:14:08,399
evaluation so basically what we did is

370
00:14:08,399 --> 00:14:11,199
that we leveraged the cr google chrome

371
00:14:11,199 --> 00:14:13,600
native messaging basically we run our

372
00:14:13,600 --> 00:14:16,560
pro one run our wp graph in the process

373
00:14:16,560 --> 00:14:18,959
and we have our browser extensions to

374
00:14:18,959 --> 00:14:20,880
communicate with our

375
00:14:20,880 --> 00:14:24,320
wt graph and the overhead timelines

376
00:14:24,320 --> 00:14:28,160
takes like 266 milliseconds per web page

377
00:14:28,160 --> 00:14:30,560
well a month which 100 milliseconds is

378
00:14:30,560 --> 00:14:34,160
used for message exchanging and 166

379
00:14:34,160 --> 00:14:36,480
milliseconds are used for

380
00:14:36,480 --> 00:14:37,760
prediction

381
00:14:37,760 --> 00:14:39,199
constructing the graph and do the

382
00:14:39,199 --> 00:14:40,320
prediction

383
00:14:40,320 --> 00:14:42,399
yes

384
00:14:42,399 --> 00:14:44,079
hi i was wondering if you can give us

385
00:14:44,079 --> 00:14:47,040
more intuition about why you chose

386
00:14:47,040 --> 00:14:48,000
um

387
00:14:48,000 --> 00:14:50,800
the uh your graph structure versus just

388
00:14:50,800 --> 00:14:53,040
using gnns on the

389
00:14:53,040 --> 00:14:56,079
provenance-based graph for ad graph

390
00:14:56,079 --> 00:14:58,160
if i understand your question correctly

391
00:14:58,160 --> 00:14:59,760
so basically here

392
00:14:59,760 --> 00:15:01,279
we have so

393
00:15:01,279 --> 00:15:03,440
so the intuition is more like

394
00:15:03,440 --> 00:15:05,440
we can have naturally we can have a

395
00:15:05,440 --> 00:15:07,600
graph to represent the traffic and

396
00:15:07,600 --> 00:15:09,920
meanwhile we learned graph neural

397
00:15:09,920 --> 00:15:12,639
networks really is a great choice for

398
00:15:12,639 --> 00:15:15,199
this kind of task that is you process

399
00:15:15,199 --> 00:15:17,199
graph structure data that's why i

400
00:15:17,199 --> 00:15:19,440
combine everything together we decided

401
00:15:19,440 --> 00:15:22,639
to go with graphing your network however

402
00:15:22,639 --> 00:15:25,120
some existing graph new networks cannot

403
00:15:25,120 --> 00:15:26,800
handle our graph record we have

404
00:15:26,800 --> 00:15:29,680
attributed homogeneous multi-graph and

405
00:15:29,680 --> 00:15:31,839
existing models cannot handle that

406
00:15:31,839 --> 00:15:34,160
that's why we designed our wt graphene

407
00:15:34,160 --> 00:15:36,000
network did i answer your question yeah

408
00:15:36,000 --> 00:15:38,000
thank you for it yes

409
00:15:38,000 --> 00:15:39,680
yes so my understanding of the the

410
00:15:39,680 --> 00:15:41,199
labels here on the edges that they're

411
00:15:41,199 --> 00:15:43,040
the urls and i'm curious whether you

412
00:15:43,040 --> 00:15:44,639
think that there's any utility or

413
00:15:44,639 --> 00:15:46,800
potential in also considering the

414
00:15:46,800 --> 00:15:48,639
payload contents

415
00:15:48,639 --> 00:15:51,360
the payload contents for short no we did

416
00:15:51,360 --> 00:15:52,079
not

417
00:15:52,079 --> 00:15:54,959
consider that a small from the overhead

418
00:15:54,959 --> 00:15:57,440
perspective we have that kind of concern

419
00:15:57,440 --> 00:15:59,839
we do not consider that okay cool thanks

420
00:15:59,839 --> 00:16:02,079
yes

421
00:16:03,040 --> 00:16:04,800
uh so if i understand your project

422
00:16:04,800 --> 00:16:07,120
correctly your graph new network is

423
00:16:07,120 --> 00:16:09,920
trained on the training data set labeled

424
00:16:09,920 --> 00:16:13,279
by the filter list right yes and you in

425
00:16:13,279 --> 00:16:15,759
that case you can still identify or

426
00:16:15,759 --> 00:16:17,279
detect some

427
00:16:17,279 --> 00:16:21,040
wta is missed by the filter list so

428
00:16:21,040 --> 00:16:24,079
could you share more insight about this

429
00:16:24,079 --> 00:16:28,160
result because basically if you just uh

430
00:16:28,160 --> 00:16:31,360
you basically you can you can outperform

431
00:16:31,360 --> 00:16:34,959
the label the data set right yes so yeah

432
00:16:34,959 --> 00:16:37,920
okay so um let me explain this way just

433
00:16:37,920 --> 00:16:39,759
consider you have because here we have a

434
00:16:39,759 --> 00:16:40,800
graph

435
00:16:40,800 --> 00:16:43,199
and from the labeling perspective menu

436
00:16:43,199 --> 00:16:44,959
labeling perspective because you're

437
00:16:44,959 --> 00:16:46,880
gonna prepare your filter list you have

438
00:16:46,880 --> 00:16:48,800
a bunch of rules right that's manually

439
00:16:48,800 --> 00:16:51,600
maintained well if that is an image it's

440
00:16:51,600 --> 00:16:55,199
easy to create a rule hey see an image

441
00:16:55,199 --> 00:16:57,519
for that for that uil should be blocked

442
00:16:57,519 --> 00:16:58,880
because that is for checking or for

443
00:16:58,880 --> 00:17:02,160
advertising so rules with that with expl

444
00:17:02,160 --> 00:17:04,799
with explicit resource it's easy to

445
00:17:04,799 --> 00:17:07,839
create it however for those implicit or

446
00:17:07,839 --> 00:17:10,000
like it was hidden traffic it's really

447
00:17:10,000 --> 00:17:13,039
hard for people to label them and create

448
00:17:13,039 --> 00:17:16,160
corresponding rules but with our graph

449
00:17:16,160 --> 00:17:18,799
neural network with that graph structure

450
00:17:18,799 --> 00:17:20,959
because of those no matter it is like a

451
00:17:20,959 --> 00:17:22,959
visible or invisible

452
00:17:22,959 --> 00:17:25,439
resource or traffic they all send it to

453
00:17:25,439 --> 00:17:28,160
the same nodes that's why we can learn

454
00:17:28,160 --> 00:17:30,160
all right even though this is invisible

455
00:17:30,160 --> 00:17:33,039
we can still identify that still detect

456
00:17:33,039 --> 00:17:35,679
that that's something filter list

457
00:17:35,679 --> 00:17:38,160
cannot do very well

458
00:17:38,160 --> 00:17:40,720
so you mean that

459
00:17:40,720 --> 00:17:42,720
the graph new network can there is a

460
00:17:42,720 --> 00:17:44,840
implicit signals

461
00:17:44,840 --> 00:17:48,559
that are given invisible in the training

462
00:17:48,559 --> 00:17:49,600
levels

463
00:17:49,600 --> 00:17:51,200
um

464
00:17:51,200 --> 00:17:52,160
yes

465
00:17:52,160 --> 00:17:54,960
if that is not labeled by the filter

466
00:17:54,960 --> 00:17:57,919
list basically by the human behave okay

467
00:17:57,919 --> 00:18:00,880
since i have another quick question so

468
00:18:00,880 --> 00:18:02,720
so you mentioned that you have two

469
00:18:02,720 --> 00:18:04,320
settings right the second one is the

470
00:18:04,320 --> 00:18:06,640
inductive setting basically you will you

471
00:18:06,640 --> 00:18:10,160
need to handle some out of vocabulary uh

472
00:18:10,160 --> 00:18:12,480
request right yes so in that setting do

473
00:18:12,480 --> 00:18:14,080
you need to retrain your model to

474
00:18:14,080 --> 00:18:15,840
predict

475
00:18:15,840 --> 00:18:18,559
the links for this unseen

476
00:18:18,559 --> 00:18:21,440
urls or we do not need to retrain that's

477
00:18:21,440 --> 00:18:23,280
why we want to have that so that it

478
00:18:23,280 --> 00:18:24,799
doesn't matter we trim that on the

479
00:18:24,799 --> 00:18:27,280
previous graph now we can handle the new

480
00:18:27,280 --> 00:18:28,960
and sing ads

481
00:18:28,960 --> 00:18:30,559
that's why in real time we have that

482
00:18:30,559 --> 00:18:32,039
kind of performance

483
00:18:32,039 --> 00:18:35,039
266 milliseconds delete

484
00:18:35,039 --> 00:18:36,480
because you're gonna if you wanna if you

485
00:18:36,480 --> 00:18:38,320
wanna retrain

486
00:18:38,320 --> 00:18:40,960
and that's we are taking a lot of time

487
00:18:40,960 --> 00:18:42,720
but you can definitely you can regularly

488
00:18:42,720 --> 00:18:44,160
retrain to achieve the better

489
00:18:44,160 --> 00:18:45,520
performance

490
00:18:45,520 --> 00:18:47,120
consistently

491
00:18:47,120 --> 00:18:50,399
okay since yes

492
00:18:50,880 --> 00:18:53,440
uh omar university of washington uh so

493
00:18:53,440 --> 00:18:55,919
one thing that aircraft did was it tried

494
00:18:55,919 --> 00:18:57,600
to classify as the web page was

495
00:18:57,600 --> 00:18:59,760
rendering so some of the nodes would

496
00:18:59,760 --> 00:19:01,200
have different graph properties and they

497
00:19:01,200 --> 00:19:02,960
would like improve over time

498
00:19:02,960 --> 00:19:05,200
so are you doing the same thing in

499
00:19:05,200 --> 00:19:05,919
uh

500
00:19:05,919 --> 00:19:08,320
wta graph so i guess you're talking

501
00:19:08,320 --> 00:19:10,880
about like the features for our graph

502
00:19:10,880 --> 00:19:12,720
right yeah so basically features were

503
00:19:12,720 --> 00:19:15,120
built as the web page was rendering so

504
00:19:15,120 --> 00:19:16,559
at one point in time when you have like

505
00:19:16,559 --> 00:19:17,919
very few nodes

506
00:19:17,919 --> 00:19:19,679
the features would be videos would have

507
00:19:19,679 --> 00:19:21,919
a lot less or smaller values and as the

508
00:19:21,919 --> 00:19:23,360
graph would build they will have a

509
00:19:23,360 --> 00:19:25,280
higher values for example

510
00:19:25,280 --> 00:19:27,200
yes we will have that so basically we

511
00:19:27,200 --> 00:19:28,960
have like we have different categories

512
00:19:28,960 --> 00:19:30,160
of features

513
00:19:30,160 --> 00:19:32,400
character embedding javascript api

514
00:19:32,400 --> 00:19:34,400
access and there's

515
00:19:34,400 --> 00:19:36,640
url aesthetics and the dom so and so

516
00:19:36,640 --> 00:19:39,280
forth it's all library basically all

517
00:19:39,280 --> 00:19:42,160
inspired from the previous

518
00:19:42,160 --> 00:19:43,919
related work

519
00:19:43,919 --> 00:19:46,080
right

520
00:19:46,080 --> 00:19:47,120
thank you

521
00:19:47,120 --> 00:19:48,960
yes

522
00:19:48,960 --> 00:19:51,440
hi this is pune from uc davis i was

523
00:19:51,440 --> 00:19:53,919
wondering as your threat model we also

524
00:19:53,919 --> 00:19:56,400
consider cases when the third party or

525
00:19:56,400 --> 00:19:59,919
tracker uh collude with the first party

526
00:19:59,919 --> 00:20:02,480
when they hide their content like using

527
00:20:02,480 --> 00:20:05,280
like cnn club yes that's a really it's

528
00:20:05,280 --> 00:20:07,200
really great question like first party

529
00:20:07,200 --> 00:20:08,960
tracker versus third project well in

530
00:20:08,960 --> 00:20:11,360
this work we do not differentiate as

531
00:20:11,360 --> 00:20:14,240
long as it is tracking uh we just block

532
00:20:14,240 --> 00:20:15,840
it we won't detect it and we're gonna

533
00:20:15,840 --> 00:20:18,320
block it but to make it clear

534
00:20:18,320 --> 00:20:20,400
some information is sent to the first

535
00:20:20,400 --> 00:20:21,520
party

536
00:20:21,520 --> 00:20:25,360
first party uh organizations or like uh

537
00:20:25,360 --> 00:20:26,960
sent to the first party that makes sense

538
00:20:26,960 --> 00:20:28,720
because you need that for example you

539
00:20:28,720 --> 00:20:30,240
want to have credit card information

540
00:20:30,240 --> 00:20:32,080
being sent to the

541
00:20:32,080 --> 00:20:34,640
server right to process your order for

542
00:20:34,640 --> 00:20:36,559
that we do not consider those are

543
00:20:36,559 --> 00:20:37,760
tracking

544
00:20:37,760 --> 00:20:39,600
okay thank you yes

545
00:20:39,600 --> 00:20:42,060
okay let's thank the speaker again

546
00:20:42,060 --> 00:20:45,819
[Applause]

