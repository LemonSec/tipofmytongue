1
00:00:00,000 --> 00:00:01,520
now okay

2
00:00:01,520 --> 00:00:03,520
okay um hello everyone my name is

3
00:00:03,520 --> 00:00:06,560
federico um i'll be presenting uh our

4
00:00:06,560 --> 00:00:08,400
work this is joint work with fergus

5
00:00:08,400 --> 00:00:10,400
pandelberry fabio pirazzi and renzo

6
00:00:10,400 --> 00:00:12,559
cavallaro wonderful collaborators and

7
00:00:12,559 --> 00:00:15,839
it's so great to be here today

8
00:00:15,839 --> 00:00:18,160
so we all know the story of machine

9
00:00:18,160 --> 00:00:19,920
learning's effectiveness machine

10
00:00:19,920 --> 00:00:23,279
learning has dominated in tasks ranging

11
00:00:23,279 --> 00:00:25,359
from image classification to neural

12
00:00:25,359 --> 00:00:27,359
machine translation

13
00:00:27,359 --> 00:00:29,599
and while machine learning has shown

14
00:00:29,599 --> 00:00:32,159
very promising results there still seems

15
00:00:32,159 --> 00:00:34,480
to be something missing when it comes to

16
00:00:34,480 --> 00:00:36,719
malware classification so

17
00:00:36,719 --> 00:00:39,120
you may ask federico what's taking so

18
00:00:39,120 --> 00:00:40,000
long

19
00:00:40,000 --> 00:00:40,800
well

20
00:00:40,800 --> 00:00:42,800
this all stems from the fact

21
00:00:42,800 --> 00:00:44,559
that while other domains treat

22
00:00:44,559 --> 00:00:46,480
adversarial attacks as some kind of

23
00:00:46,480 --> 00:00:49,039
special edge case this is absolutely not

24
00:00:49,039 --> 00:00:51,039
the case in security actually a

25
00:00:51,039 --> 00:00:52,879
detection system is essentially

26
00:00:52,879 --> 00:00:54,719
worthless if it's not robust to

27
00:00:54,719 --> 00:00:57,120
adversarial behavior so whenever we

28
00:00:57,120 --> 00:00:59,520
deploy this new detection system this

29
00:00:59,520 --> 00:01:01,760
triggers an immediate response from the

30
00:01:01,760 --> 00:01:04,479
adverse series and this is a nightmare

31
00:01:04,479 --> 00:01:06,720
for machine learning practitioners in

32
00:01:06,720 --> 00:01:08,479
particular this is because it leads to a

33
00:01:08,479 --> 00:01:11,040
variety of data set shifts which are

34
00:01:11,040 --> 00:01:13,200
usually umbrella termed under concept

35
00:01:13,200 --> 00:01:15,360
drift but they can be much more nuanced

36
00:01:15,360 --> 00:01:16,320
than that

37
00:01:16,320 --> 00:01:17,280
and

38
00:01:17,280 --> 00:01:19,360
and this is a nightmare because it's

39
00:01:19,360 --> 00:01:21,360
violating one of the main assumptions

40
00:01:21,360 --> 00:01:22,640
which we're making when trading machine

41
00:01:22,640 --> 00:01:24,720
learning systems that the test that the

42
00:01:24,720 --> 00:01:27,280
train and testing data or iad

43
00:01:27,280 --> 00:01:29,200
so this is exactly what our lab was

44
00:01:29,200 --> 00:01:31,759
trying to address in 2017

45
00:01:31,759 --> 00:01:34,240
work which was published as published at

46
00:01:34,240 --> 00:01:37,439
ucynic security in transcend so when we

47
00:01:37,439 --> 00:01:39,360
have a regular classifier we take a new

48
00:01:39,360 --> 00:01:40,960
example and then we pass it to a

49
00:01:40,960 --> 00:01:43,040
classifier get our classification

50
00:01:43,040 --> 00:01:45,520
instead in transcend we add two

51
00:01:45,520 --> 00:01:47,840
components to this

52
00:01:47,840 --> 00:01:49,680
to the system so we first had a

53
00:01:49,680 --> 00:01:52,560
conformal evaluator which is responsible

54
00:01:52,560 --> 00:01:54,079
for assigning some sort of quality

55
00:01:54,079 --> 00:01:56,960
measure uh and then this quality measure

56
00:01:56,960 --> 00:01:58,960
is then passed on to transcend itself

57
00:01:58,960 --> 00:02:01,360
which is our calibration mechanism so

58
00:02:01,360 --> 00:02:02,960
transcend will have some kind of

59
00:02:02,960 --> 00:02:04,719
thresholding uh

60
00:02:04,719 --> 00:02:06,399
some kind of thresholds for each class

61
00:02:06,399 --> 00:02:08,000
and then based on these thresholds

62
00:02:08,000 --> 00:02:09,520
transcend will decide whether to accept

63
00:02:09,520 --> 00:02:11,840
or reject a specific classification this

64
00:02:11,840 --> 00:02:13,120
is known as classification with

65
00:02:13,120 --> 00:02:14,879
rejection in the machine learning

66
00:02:14,879 --> 00:02:16,080
literature

67
00:02:16,080 --> 00:02:17,360
so

68
00:02:17,360 --> 00:02:18,879
transcend performed very well but we

69
00:02:18,879 --> 00:02:20,080
thought we could address some of the

70
00:02:20,080 --> 00:02:21,520
limitations

71
00:02:21,520 --> 00:02:23,840
and so this is in particular what we try

72
00:02:23,840 --> 00:02:26,239
to address so first of all we propose

73
00:02:26,239 --> 00:02:28,560
some kind of important theoretical

74
00:02:28,560 --> 00:02:31,280
missing link between conformal valuation

75
00:02:31,280 --> 00:02:33,440
and its underlying statistical theory

76
00:02:33,440 --> 00:02:35,599
which is conformal prediction

77
00:02:35,599 --> 00:02:38,239
and we use this link to kind of motivate

78
00:02:38,239 --> 00:02:40,879
why conform evaluators work so well in

79
00:02:40,879 --> 00:02:42,080
the first place

80
00:02:42,080 --> 00:02:43,920
um on top of this we wanted to make

81
00:02:43,920 --> 00:02:45,840
transcends scalable to real-world data

82
00:02:45,840 --> 00:02:47,599
sets so we're

83
00:02:47,599 --> 00:02:49,680
using this provide with this missing

84
00:02:49,680 --> 00:02:52,160
link we propose new sound and flexible

85
00:02:52,160 --> 00:02:54,239
conform evaluators and we also improve

86
00:02:54,239 --> 00:02:56,800
the thresholding we make that faster

87
00:02:56,800 --> 00:02:59,519
so to evaluate this we evaluate this on

88
00:02:59,519 --> 00:03:02,879
a on a wide range of malware domains and

89
00:03:02,879 --> 00:03:04,640
a wide range of classifiers to show how

90
00:03:04,640 --> 00:03:07,120
kind of general this technique is

91
00:03:07,120 --> 00:03:09,840
um and and maybe let's go a bit into uh

92
00:03:09,840 --> 00:03:11,120
let's try to get a bit of a deeper

93
00:03:11,120 --> 00:03:13,680
intuition into conform evaluation and

94
00:03:13,680 --> 00:03:15,360
let's start by talking about conformal

95
00:03:15,360 --> 00:03:18,159
prediction so convert prediction is what

96
00:03:18,159 --> 00:03:20,480
lays the ground for conform evaluation

97
00:03:20,480 --> 00:03:22,239
in a typical operation a conformal

98
00:03:22,239 --> 00:03:24,879
predictor will output a prediction set

99
00:03:24,879 --> 00:03:26,560
so this is a bit strange in terms of

100
00:03:26,560 --> 00:03:28,080
machine learning because we're usually

101
00:03:28,080 --> 00:03:29,760
outputting some kind of classification

102
00:03:29,760 --> 00:03:31,840
here we output a set which contains a

103
00:03:31,840 --> 00:03:34,319
true label with with a likelihood one

104
00:03:34,319 --> 00:03:35,920
minus epsilon with some level of

105
00:03:35,920 --> 00:03:38,799
confidence uh and and and these strong

106
00:03:38,799 --> 00:03:41,200
kind of uh these strong results only

107
00:03:41,200 --> 00:03:42,879
occur when we have two two core

108
00:03:42,879 --> 00:03:44,959
assumptions so that of exchangeability

109
00:03:44,959 --> 00:03:46,480
which is some kind of generalization of

110
00:03:46,480 --> 00:03:48,560
ied and the close role assumption if we

111
00:03:48,560 --> 00:03:51,200
train on cats and dogs we won't expect

112
00:03:51,200 --> 00:03:53,040
we're not expecting parrots in the test

113
00:03:53,040 --> 00:03:55,120
set or random noise

114
00:03:55,120 --> 00:03:56,000
so

115
00:03:56,000 --> 00:03:59,280
this is all based on a scary term called

116
00:03:59,280 --> 00:04:01,120
a non-conformity measure but it's

117
00:04:01,120 --> 00:04:02,879
actually quite straightforward a

118
00:04:02,879 --> 00:04:04,239
non-conformity measure is a

119
00:04:04,239 --> 00:04:05,920
non-conformity measure measures how

120
00:04:05,920 --> 00:04:08,400
dissimilar a point is with respect to

121
00:04:08,400 --> 00:04:10,560
other points of that same class now this

122
00:04:10,560 --> 00:04:12,400
is classifier agnostic we can build

123
00:04:12,400 --> 00:04:13,599
these for many different types of

124
00:04:13,599 --> 00:04:15,200
classifiers so let's have a look at a

125
00:04:15,200 --> 00:04:16,720
few examples

126
00:04:16,720 --> 00:04:18,880
now the blue region highlights all the

127
00:04:18,880 --> 00:04:20,959
points which are less similar than the

128
00:04:20,959 --> 00:04:22,880
red testing point with respect to the

129
00:04:22,880 --> 00:04:25,199
black class so this is induced depending

130
00:04:25,199 --> 00:04:27,040
on the black class and

131
00:04:27,040 --> 00:04:29,280
and this is induced by the ncm choice

132
00:04:29,280 --> 00:04:31,680
which we make so to quantify this

133
00:04:31,680 --> 00:04:33,520
relative the similarity we construct a

134
00:04:33,520 --> 00:04:36,000
p-value and this is simply the ratio of

135
00:04:36,000 --> 00:04:37,759
points in the blue region with respect

136
00:04:37,759 --> 00:04:39,680
to the ratio of points in a white region

137
00:04:39,680 --> 00:04:41,280
for the black class and then we flip

138
00:04:41,280 --> 00:04:44,000
that for the white class and and we do

139
00:04:44,000 --> 00:04:45,759
this for every class in our tasks so for

140
00:04:45,759 --> 00:04:47,759
example for classifying malware we would

141
00:04:47,759 --> 00:04:49,680
have a p-value for the malware class and

142
00:04:49,680 --> 00:04:51,840
a p-value for the benign class

143
00:04:51,840 --> 00:04:54,560
now hang in now with me because this is

144
00:04:54,560 --> 00:04:56,160
really kind of the core the core

145
00:04:56,160 --> 00:04:58,320
observation the fact that these

146
00:04:58,320 --> 00:05:00,479
prediction regions uh so here we're

147
00:05:00,479 --> 00:05:02,160
still sticking to confirm prediction and

148
00:05:02,160 --> 00:05:04,160
we'll link this to confirm evaluation

149
00:05:04,160 --> 00:05:06,479
now these prediction regions uh are

150
00:05:06,479 --> 00:05:08,720
based on the significant level epsilon

151
00:05:08,720 --> 00:05:10,720
and actually we can imagine these as

152
00:05:10,720 --> 00:05:12,320
being stacked such as the higher the

153
00:05:12,320 --> 00:05:13,759
confidence level

154
00:05:13,759 --> 00:05:16,000
the more labels will be present and and

155
00:05:16,000 --> 00:05:17,919
we have these two edge cases so the

156
00:05:17,919 --> 00:05:20,240
first edge case is when epsilon is zero

157
00:05:20,240 --> 00:05:22,000
so our likelihood will be one and here

158
00:05:22,000 --> 00:05:23,840
we're saying give us a set with

159
00:05:23,840 --> 00:05:25,759
likelihood one that contains a true test

160
00:05:25,759 --> 00:05:28,320
label and this is going to be trivially

161
00:05:28,320 --> 00:05:30,320
the entire uh training

162
00:05:30,320 --> 00:05:32,880
label space because we're saying

163
00:05:32,880 --> 00:05:34,800
by the closed row assumption this is

164
00:05:34,800 --> 00:05:36,960
like the only solution so

165
00:05:36,960 --> 00:05:38,880
if we flip if we jump over to the other

166
00:05:38,880 --> 00:05:40,880
side we have the case where we have a

167
00:05:40,880 --> 00:05:42,880
likelihood of zero and again here we're

168
00:05:42,880 --> 00:05:45,440
kind of violating uh the uh close role

169
00:05:45,440 --> 00:05:47,280
assumption and so we will output the

170
00:05:47,280 --> 00:05:48,800
empty set

171
00:05:48,800 --> 00:05:49,919
so

172
00:05:49,919 --> 00:05:51,840
also important is this region which only

173
00:05:51,840 --> 00:05:53,680
contains one point this this is

174
00:05:53,680 --> 00:05:55,039
sandwiched by the credibility and

175
00:05:55,039 --> 00:05:57,280
confidence and and in particular is this

176
00:05:57,280 --> 00:05:59,120
credibility that that gives us the the

177
00:05:59,120 --> 00:06:00,960
connection between confirmed prediction

178
00:06:00,960 --> 00:06:04,880
and conform evaluation so uh here uh tom

179
00:06:04,880 --> 00:06:07,759
the cat has this cool idea so a low

180
00:06:07,759 --> 00:06:09,759
credibility means a high probability of

181
00:06:09,759 --> 00:06:11,840
an impossible of an impossible result

182
00:06:11,840 --> 00:06:13,600
because again we're directly violating

183
00:06:13,600 --> 00:06:15,840
the assumptions we set off with and and

184
00:06:15,840 --> 00:06:17,520
this means that

185
00:06:17,520 --> 00:06:19,120
that well how could we explain this this

186
00:06:19,120 --> 00:06:20,319
is because the distributions are

187
00:06:20,319 --> 00:06:22,400
shifting and and this is the fundamental

188
00:06:22,400 --> 00:06:23,759
difference between conformal prediction

189
00:06:23,759 --> 00:06:25,440
and conform evaluation

190
00:06:25,440 --> 00:06:28,000
whereas conformal predictors predict

191
00:06:28,000 --> 00:06:30,080
given this prediction region conform

192
00:06:30,080 --> 00:06:33,120
evaluators evaluate predictions of the

193
00:06:33,120 --> 00:06:35,759
underlying classifier borrowing tools uh

194
00:06:35,759 --> 00:06:37,759
from conformal prediction

195
00:06:37,759 --> 00:06:39,600
so let's have a look at our thresholding

196
00:06:39,600 --> 00:06:42,080
mechanism transcend and transcend tries

197
00:06:42,080 --> 00:06:44,639
to answer the question uh at what point

198
00:06:44,639 --> 00:06:46,240
should we actually do something about

199
00:06:46,240 --> 00:06:48,479
drift at what point should we

200
00:06:48,479 --> 00:06:49,919
actually

201
00:06:49,919 --> 00:06:52,960
reject points so um

202
00:06:52,960 --> 00:06:54,800
to do this we hold out some kind of

203
00:06:54,800 --> 00:06:57,360
calibration set and and we can imagine

204
00:06:57,360 --> 00:06:58,800
that

205
00:06:58,800 --> 00:07:00,080
we run our classifier in this

206
00:07:00,080 --> 00:07:01,680
calibration set and we can partition the

207
00:07:01,680 --> 00:07:03,759
data based on class and based on whether

208
00:07:03,759 --> 00:07:05,520
the classification was uh correct or

209
00:07:05,520 --> 00:07:06,639
incorrect

210
00:07:06,639 --> 00:07:08,880
now what we then do is generate our

211
00:07:08,880 --> 00:07:10,639
thresholds for each class and these

212
00:07:10,639 --> 00:07:13,120
thresholds are generated on some kind of

213
00:07:13,120 --> 00:07:15,120
optimization constraints which we try to

214
00:07:15,120 --> 00:07:17,280
solve and it could be for example find

215
00:07:17,280 --> 00:07:19,039
the best thresholds which maximize the

216
00:07:19,039 --> 00:07:21,039
f1 score given some kind of rejection

217
00:07:21,039 --> 00:07:21,919
rate

218
00:07:21,919 --> 00:07:23,680
these parameters we can tweak depending

219
00:07:23,680 --> 00:07:26,479
on what we want to do um so transcend is

220
00:07:26,479 --> 00:07:28,479
is effectively trying to maximize the

221
00:07:28,479 --> 00:07:30,560
separation between the credibility of

222
00:07:30,560 --> 00:07:32,400
correct and incorrect decisions for each

223
00:07:32,400 --> 00:07:34,319
class now that we've calibrated

224
00:07:34,319 --> 00:07:36,080
transcend at test time all we simply

225
00:07:36,080 --> 00:07:38,479
need to do is sweep the point through

226
00:07:38,479 --> 00:07:40,639
the classifier to get the classification

227
00:07:40,639 --> 00:07:42,840
and then compute the credibility of that

228
00:07:42,840 --> 00:07:45,520
classification given that it's of that

229
00:07:45,520 --> 00:07:47,599
class and then we compare to that same

230
00:07:47,599 --> 00:07:49,680
class threshold so if the credibility is

231
00:07:49,680 --> 00:07:51,680
above the threshold we deem this as a

232
00:07:51,680 --> 00:07:53,759
credible classification so we can trust

233
00:07:53,759 --> 00:07:55,199
it and instead if it's below the

234
00:07:55,199 --> 00:07:56,400
threshold

235
00:07:56,400 --> 00:07:59,280
we reject it and once we're rejected we

236
00:07:59,280 --> 00:08:01,919
can really do what we want uh there's a

237
00:08:01,919 --> 00:08:03,919
we could manually inspect it or or have

238
00:08:03,919 --> 00:08:06,319
a look at many other different things

239
00:08:06,319 --> 00:08:08,080
so um

240
00:08:08,080 --> 00:08:09,280
now let's have a look at conform

241
00:08:09,280 --> 00:08:12,400
evaluators uh confirm evaluators are

242
00:08:12,400 --> 00:08:14,160
have many different structures first of

243
00:08:14,160 --> 00:08:15,919
all the uh we have the transductive

244
00:08:15,919 --> 00:08:18,720
conform evaluator so the transductive

245
00:08:18,720 --> 00:08:21,440
conform evaluator um it works in a kind

246
00:08:21,440 --> 00:08:25,520
of level and out fashion so we have um

247
00:08:25,520 --> 00:08:28,160
this uh so so we target the p-value

248
00:08:28,160 --> 00:08:30,479
computation uh

249
00:08:30,479 --> 00:08:33,279
singling out a point so if for a single

250
00:08:33,279 --> 00:08:35,279
point we train on n minus one points and

251
00:08:35,279 --> 00:08:37,200
compute the p-value for that point we're

252
00:08:37,200 --> 00:08:39,279
targeting now you can imagine this level

253
00:08:39,279 --> 00:08:40,559
in our fashion we have to train n

254
00:08:40,559 --> 00:08:43,039
classifiers and really nobody has time

255
00:08:43,039 --> 00:08:44,240
for that

256
00:08:44,240 --> 00:08:45,839
the advantage of this technique is is

257
00:08:45,839 --> 00:08:47,360
that this is rooted in conformal

258
00:08:47,360 --> 00:08:48,560
prediction theory so it's actually a

259
00:08:48,560 --> 00:08:50,959
sound approach uh the disadvantage is

260
00:08:50,959 --> 00:08:52,800
that this is computationally infeasible

261
00:08:52,800 --> 00:08:54,640
for large data sets

262
00:08:54,640 --> 00:08:55,360
so

263
00:08:55,360 --> 00:08:57,760
one kind of thing we can

264
00:08:57,760 --> 00:09:00,080
we can try is instead of doing a leave

265
00:09:00,080 --> 00:09:02,320
one out approaches we could we could do

266
00:09:02,320 --> 00:09:03,920
this in batches and and here we get

267
00:09:03,920 --> 00:09:05,279
approximate transaction come from

268
00:09:05,279 --> 00:09:07,600
valuation so this is an attempt at

269
00:09:07,600 --> 00:09:09,519
trying to make transductive conformal

270
00:09:09,519 --> 00:09:11,440
evaluation actually feasible in practice

271
00:09:11,440 --> 00:09:13,440
so here we could do like a k-fold where

272
00:09:13,440 --> 00:09:15,279
instead of end points we have we do we

273
00:09:15,279 --> 00:09:18,640
train 10 classifiers um so the p-values

274
00:09:18,640 --> 00:09:20,640
are not computed in batches but

275
00:09:20,640 --> 00:09:22,800
importantly this relies on an unsound

276
00:09:22,800 --> 00:09:24,720
assumption the fact that

277
00:09:24,720 --> 00:09:26,399
when we do it in batches we're in some

278
00:09:26,399 --> 00:09:28,880
way shifting the decision boundary of

279
00:09:28,880 --> 00:09:30,480
the classifier which is then used to

280
00:09:30,480 --> 00:09:33,440
compute the non-conformity measure so

281
00:09:33,440 --> 00:09:36,000
this approximation is only as good as

282
00:09:36,000 --> 00:09:37,519
the approximation of the decision

283
00:09:37,519 --> 00:09:39,839
boundary is

284
00:09:39,839 --> 00:09:41,040
now

285
00:09:41,040 --> 00:09:43,120
this was kind of unsatisfying because we

286
00:09:43,120 --> 00:09:45,040
we really wanted to have a statistically

287
00:09:45,040 --> 00:09:47,120
sound approach and and this is what we

288
00:09:47,120 --> 00:09:49,200
then introduced to try to remedy this

289
00:09:49,200 --> 00:09:50,720
and this is an inductive conform

290
00:09:50,720 --> 00:09:52,959
evaluator and here the advantage is that

291
00:09:52,959 --> 00:09:54,800
we're only training one classifier so

292
00:09:54,800 --> 00:09:57,600
this is really like practical um

293
00:09:57,600 --> 00:09:59,600
what we do is is we split the training

294
00:09:59,600 --> 00:10:01,519
set into a true training set and then a

295
00:10:01,519 --> 00:10:03,440
calibration set so we train on the

296
00:10:03,440 --> 00:10:06,000
training set and then calibrate

297
00:10:06,000 --> 00:10:07,920
and then compute the p values in a leave

298
00:10:07,920 --> 00:10:09,120
without fashion but only in the

299
00:10:09,120 --> 00:10:11,360
calibration set and this is rooted in

300
00:10:11,360 --> 00:10:12,959
conformal prediction theory and

301
00:10:12,959 --> 00:10:14,560
importantly its computation very

302
00:10:14,560 --> 00:10:16,560
efficient there is one drawback to this

303
00:10:16,560 --> 00:10:18,320
however is the fact that this is

304
00:10:18,320 --> 00:10:20,399
informationally inefficient because

305
00:10:20,399 --> 00:10:22,880
we're throwing away all that gray region

306
00:10:22,880 --> 00:10:25,600
so we wanted to to address this as well

307
00:10:25,600 --> 00:10:28,079
and to do this we proposed the cross

308
00:10:28,079 --> 00:10:30,000
conform evaluator you can think of this

309
00:10:30,000 --> 00:10:30,720
as

310
00:10:30,720 --> 00:10:33,200
having an ensemble of inductive conform

311
00:10:33,200 --> 00:10:36,079
evaluators acting in parallel and they

312
00:10:36,079 --> 00:10:39,120
act over some kind of majority voting so

313
00:10:39,120 --> 00:10:41,120
this is root ncp theories it's a

314
00:10:41,120 --> 00:10:43,680
statistically sound approach and it's

315
00:10:43,680 --> 00:10:45,120
computationally more efficient than

316
00:10:45,120 --> 00:10:46,720
transductive comfort valuation obviously

317
00:10:46,720 --> 00:10:48,399
this is less efficient than inductive

318
00:10:48,399 --> 00:10:49,920
comfort valuation but

319
00:10:49,920 --> 00:10:51,760
it's trivially paralyzable so if you

320
00:10:51,760 --> 00:10:54,320
have the resources it would take the

321
00:10:54,320 --> 00:10:56,399
same amount of time in practice

322
00:10:56,399 --> 00:10:58,000
and the advantage is that we gain the

323
00:10:58,000 --> 00:10:59,760
informational efficiency back as we can

324
00:10:59,760 --> 00:11:02,000
now compute statistical support over the

325
00:11:02,000 --> 00:11:03,920
entire training data set

326
00:11:03,920 --> 00:11:06,800
so here's the experimental setup we have

327
00:11:06,800 --> 00:11:08,480
android experiments with rebin over a

328
00:11:08,480 --> 00:11:09,920
five year time span with a linear

329
00:11:09,920 --> 00:11:11,519
support vector machine we have

330
00:11:11,519 --> 00:11:13,200
experiments on windows p with the amber

331
00:11:13,200 --> 00:11:14,800
v2 data set with gradient boosted

332
00:11:14,800 --> 00:11:16,880
decision trees we have experiments on

333
00:11:16,880 --> 00:11:19,040
pdf malware with hedos

334
00:11:19,040 --> 00:11:20,480
and this is a feature space which is

335
00:11:20,480 --> 00:11:22,640
robust to drift and we use random forest

336
00:11:22,640 --> 00:11:24,240
we will be focusing on the android

337
00:11:24,240 --> 00:11:25,839
experiments in

338
00:11:25,839 --> 00:11:27,600
this in these slides

339
00:11:27,600 --> 00:11:29,200
and then we have our thresholding

340
00:11:29,200 --> 00:11:31,279
optimization constraints so we we

341
00:11:31,279 --> 00:11:33,279
operate over a specific rejection rate

342
00:11:33,279 --> 00:11:35,120
and we we operate over trying to

343
00:11:35,120 --> 00:11:37,200
maximize f1 score now these can be

344
00:11:37,200 --> 00:11:38,640
tweaked depending on what the

345
00:11:38,640 --> 00:11:40,480
practitioner wants to do for example

346
00:11:40,480 --> 00:11:41,760
also these constraints will only be

347
00:11:41,760 --> 00:11:44,160
satisfied at calibration phase because

348
00:11:44,160 --> 00:11:45,519
as we are

349
00:11:45,519 --> 00:11:46,959
at test phase we would actually expect

350
00:11:46,959 --> 00:11:49,120
more rejection as as there's more and

351
00:11:49,120 --> 00:11:50,399
more drift

352
00:11:50,399 --> 00:11:53,440
so here are the results uh and uh

353
00:11:53,440 --> 00:11:56,160
so just to interpret these slides the

354
00:11:56,160 --> 00:11:58,160
the middle dash gray line is the

355
00:11:58,160 --> 00:12:00,320
baseline performance so we're testing

356
00:12:00,320 --> 00:12:01,839
we're training on one year and testing

357
00:12:01,839 --> 00:12:04,000
over four we can see that the baseline

358
00:12:04,000 --> 00:12:06,000
performance deteriorates and this is due

359
00:12:06,000 --> 00:12:08,880
to the drift uh in in the data set

360
00:12:08,880 --> 00:12:10,800
and then we have the the top blue line

361
00:12:10,800 --> 00:12:12,240
which is the f1 score of the kept

362
00:12:12,240 --> 00:12:14,240
elements that transcend decides to keep

363
00:12:14,240 --> 00:12:15,839
and the f1 score of the rejected

364
00:12:15,839 --> 00:12:17,920
elements is in red so we'd want the the

365
00:12:17,920 --> 00:12:19,920
blue line to be close to one and the

366
00:12:19,920 --> 00:12:21,680
rejected line to be close to zero this

367
00:12:21,680 --> 00:12:23,360
would mean that transcend is accepting

368
00:12:23,360 --> 00:12:24,880
correct classifications and and

369
00:12:24,880 --> 00:12:26,800
rejecting incorrect classifications we

370
00:12:26,800 --> 00:12:28,000
also have the histogram of the

371
00:12:28,000 --> 00:12:30,240
quarantined elements so that that's the

372
00:12:30,240 --> 00:12:32,480
rejection rate at each month we can see

373
00:12:32,480 --> 00:12:34,160
that rejection rate increases as time

374
00:12:34,160 --> 00:12:35,839
goes on transcend isn't correctly

375
00:12:35,839 --> 00:12:37,200
identifying that there's more drift

376
00:12:37,200 --> 00:12:39,200
occurring as time goes on

377
00:12:39,200 --> 00:12:41,040
now we can compare this with inductive

378
00:12:41,040 --> 00:12:43,200
conform evaluation and we can see how

379
00:12:43,200 --> 00:12:44,639
how these two techniques perform

380
00:12:44,639 --> 00:12:46,399
extremely similarly but we can look at

381
00:12:46,399 --> 00:12:48,720
the cpu hours of the two techniques

382
00:12:48,720 --> 00:12:50,959
ic takes 11 hours while approximate dc

383
00:12:50,959 --> 00:12:53,279
takes 46. so we get a a massive

384
00:12:53,279 --> 00:12:56,320
computation speed up uh and for for a

385
00:12:56,320 --> 00:12:58,000
relatively like extremely similar

386
00:12:58,000 --> 00:12:59,839
performance and and here there's the

387
00:12:59,839 --> 00:13:01,600
performance of cc

388
00:13:01,600 --> 00:13:04,000
now cc is an ensemble so we expect this

389
00:13:04,000 --> 00:13:05,760
to be kind of more confident and we can

390
00:13:05,760 --> 00:13:07,600
see that the captive one score is pretty

391
00:13:07,600 --> 00:13:10,320
much almost always at one but this is at

392
00:13:10,320 --> 00:13:12,000
the sacrifice of we're rejecting more

393
00:13:12,000 --> 00:13:13,839
points and we're also making a few more

394
00:13:13,839 --> 00:13:15,600
mistakes we can see that the that the

395
00:13:15,600 --> 00:13:18,320
red that the red rejected line is is not

396
00:13:18,320 --> 00:13:20,399
at zero anymore so so we're rejecting

397
00:13:20,399 --> 00:13:22,000
more points but at the same time this is

398
00:13:22,000 --> 00:13:23,920
useful if we want a very confident kind

399
00:13:23,920 --> 00:13:26,800
of uh classifying ensemble so

400
00:13:26,800 --> 00:13:28,959
now you you may tell me okay federico

401
00:13:28,959 --> 00:13:30,240
this is very cool but we already have

402
00:13:30,240 --> 00:13:31,839
probabilities built into the classifier

403
00:13:31,839 --> 00:13:34,000
so why don't we just use those well

404
00:13:34,000 --> 00:13:36,160
let's have a look so the top row is what

405
00:13:36,160 --> 00:13:37,760
i just showed you before and we can

406
00:13:37,760 --> 00:13:39,279
compare them with just using the

407
00:13:39,279 --> 00:13:42,000
built-in probabilities of the classifier

408
00:13:42,000 --> 00:13:42,880
so

409
00:13:42,880 --> 00:13:44,399
here is the results for the

410
00:13:44,399 --> 00:13:46,560
probabilities of the classifier now what

411
00:13:46,560 --> 00:13:49,279
we see is that uh it seems kind of all

412
00:13:49,279 --> 00:13:50,959
over the place so

413
00:13:50,959 --> 00:13:52,399
when there's less drift towards the

414
00:13:52,399 --> 00:13:54,800
start the probabilities tend to

415
00:13:54,800 --> 00:13:56,399
perform still worse than confirm

416
00:13:56,399 --> 00:13:59,199
evaluation but do not seem as terrible

417
00:13:59,199 --> 00:14:00,639
but then as time goes on and there's

418
00:14:00,639 --> 00:14:02,800
more and more drift um these

419
00:14:02,800 --> 00:14:04,880
probabilities make less and less sense

420
00:14:04,880 --> 00:14:07,279
and and and this is this actually it

421
00:14:07,279 --> 00:14:08,399
makes a lot of sense because

422
00:14:08,399 --> 00:14:10,639
probabilities make this like make the

423
00:14:10,639 --> 00:14:12,480
assumption that the the training and

424
00:14:12,480 --> 00:14:14,720
testing data are id so

425
00:14:14,720 --> 00:14:17,440
probabilities as uh the data sets drift

426
00:14:17,440 --> 00:14:20,079
more and more actually become uh like

427
00:14:20,079 --> 00:14:21,839
actually are you should trust them less

428
00:14:21,839 --> 00:14:24,720
and less so so for this reason we see

429
00:14:24,720 --> 00:14:26,480
that confirm valuation actually gives a

430
00:14:26,480 --> 00:14:28,160
lot more statistical support when just

431
00:14:28,160 --> 00:14:31,839
using probabilities and to conclude um

432
00:14:31,839 --> 00:14:33,360
we we

433
00:14:33,360 --> 00:14:35,440
we presented insights into confirm

434
00:14:35,440 --> 00:14:37,839
evaluation theory by by giving a missing

435
00:14:37,839 --> 00:14:40,000
link between uh conformal prediction and

436
00:14:40,000 --> 00:14:42,880
confirm evaluation we also presented nov

437
00:14:42,880 --> 00:14:44,800
evaluators in the inductive conform

438
00:14:44,800 --> 00:14:47,120
validators and cross-conform evaluators

439
00:14:47,120 --> 00:14:48,880
in the paper there's also operational

440
00:14:48,880 --> 00:14:50,959
guidance for deploying transcend

441
00:14:50,959 --> 00:14:52,079
and

442
00:14:52,079 --> 00:14:53,680
again one of the main goals of this

443
00:14:53,680 --> 00:14:55,360
paper was to show that transcend is

444
00:14:55,360 --> 00:14:56,839
actually scalable in

445
00:14:56,839 --> 00:14:58,959
practice it's also important to mention

446
00:14:58,959 --> 00:15:00,079
that uh

447
00:15:00,079 --> 00:15:01,760
cross confirm or confirm evaluation

448
00:15:01,760 --> 00:15:03,600
transcend can actually be decoupled so

449
00:15:03,600 --> 00:15:05,199
you don't need to necessarily have a

450
00:15:05,199 --> 00:15:07,199
confirmed evaluator in a pipeline with a

451
00:15:07,199 --> 00:15:09,360
classification rejection you can for

452
00:15:09,360 --> 00:15:11,279
example use a conform evaluator for

453
00:15:11,279 --> 00:15:13,040
uncertainty sampling

454
00:15:13,040 --> 00:15:15,040
to get like better scores when samples

455
00:15:15,040 --> 00:15:17,040
are drifting and explore points which

456
00:15:17,040 --> 00:15:19,760
are have less statistical support so we

457
00:15:19,760 --> 00:15:22,320
also have the code available at the

458
00:15:22,320 --> 00:15:24,800
project page and you can check out the

459
00:15:24,800 --> 00:15:26,639
our paper and then the original

460
00:15:26,639 --> 00:15:29,360
transcend paper as well if you'd like

461
00:15:29,360 --> 00:15:31,390
thanks a lot

462
00:15:31,390 --> 00:15:36,959
[Applause]

463
00:15:36,959 --> 00:15:39,279
uh do we have any questions for federico

464
00:15:39,279 --> 00:15:41,839
yes

465
00:15:43,680 --> 00:15:45,360
i have a quick question so as you

466
00:15:45,360 --> 00:15:47,600
pointed out concept there is not really

467
00:15:47,600 --> 00:15:49,199
address serial attack

468
00:15:49,199 --> 00:15:51,040
so under adversarial attack and under

469
00:15:51,040 --> 00:15:52,880
sales setting which is securities what

470
00:15:52,880 --> 00:15:55,360
does the how does these techniques

471
00:15:55,360 --> 00:15:56,560
perform

472
00:15:56,560 --> 00:15:59,199
yeah so um we've been thinking a lot

473
00:15:59,199 --> 00:16:01,600
about this problem at uh

474
00:16:01,600 --> 00:16:04,399
at our lab and um

475
00:16:04,399 --> 00:16:06,399
there seems to be um

476
00:16:06,399 --> 00:16:07,199
like

477
00:16:07,199 --> 00:16:08,720
there seems to be a connection between

478
00:16:08,720 --> 00:16:10,800
the two and now in our evaluation we're

479
00:16:10,800 --> 00:16:14,240
simply looking at drift but um

480
00:16:14,240 --> 00:16:16,720
yeah it's it's definitely very related

481
00:16:16,720 --> 00:16:17,680
but we

482
00:16:17,680 --> 00:16:19,920
um again we can make no claims with

483
00:16:19,920 --> 00:16:22,079
regards to the experiments we ran

484
00:16:22,079 --> 00:16:24,719
with this work

485
00:16:25,759 --> 00:16:26,959
uh and i was wondering if you could

486
00:16:26,959 --> 00:16:28,639
speak a little bit to the trade-offs

487
00:16:28,639 --> 00:16:31,279
that exist between uh you know models

488
00:16:31,279 --> 00:16:33,199
that are just robust in their feature

489
00:16:33,199 --> 00:16:35,360
selection to concept drift or

490
00:16:35,360 --> 00:16:38,639
yeah so actually we have i do have some

491
00:16:38,639 --> 00:16:41,759
backup slides uh and this is the results

492
00:16:41,759 --> 00:16:44,399
for hedos so he does is

493
00:16:44,399 --> 00:16:46,399
i guess the models are not inherently

494
00:16:46,399 --> 00:16:48,560
robust but the feature space is robust

495
00:16:48,560 --> 00:16:50,560
in these experiments so

496
00:16:50,560 --> 00:16:52,480
we can see that when we have a robust

497
00:16:52,480 --> 00:16:54,720
feature space that the if we look at the

498
00:16:54,720 --> 00:16:56,880
gray baseline there's there's very much

499
00:16:56,880 --> 00:16:59,519
like a lot less drift in there and so

500
00:16:59,519 --> 00:17:01,519
when we use probabilities probabilities

501
00:17:01,519 --> 00:17:02,880
seem to work

502
00:17:02,880 --> 00:17:04,880
actually like quite well and this is

503
00:17:04,880 --> 00:17:06,959
because again probabilities work fine as

504
00:17:06,959 --> 00:17:09,359
long as you're not having a lot of drift

505
00:17:09,359 --> 00:17:11,119
but but we can see that even uh

506
00:17:11,119 --> 00:17:13,359
confirmed evaluators seem to beat

507
00:17:13,359 --> 00:17:15,599
probabilities even in this case again

508
00:17:15,599 --> 00:17:16,720
these

509
00:17:16,720 --> 00:17:18,880
it's it's like they're probably quite

510
00:17:18,880 --> 00:17:20,799
similar in this scenario but yeah

511
00:17:20,799 --> 00:17:22,959
obviously uh confirm evaluation is

512
00:17:22,959 --> 00:17:25,599
designed for high drifting kind of

513
00:17:25,599 --> 00:17:27,839
situations

514
00:17:27,839 --> 00:17:29,280
awesome all right

515
00:17:29,280 --> 00:17:30,480
uh

516
00:17:30,480 --> 00:17:31,760
if there are no more questions thanks

517
00:17:31,760 --> 00:17:35,879
federico thank you

