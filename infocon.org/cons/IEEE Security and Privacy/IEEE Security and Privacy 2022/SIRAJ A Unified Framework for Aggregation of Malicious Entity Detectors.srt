1
00:00:00,080 --> 00:00:01,599
yeah

2
00:00:01,599 --> 00:00:04,240
hello thank you for the introduction

3
00:00:04,240 --> 00:00:06,560
i am isinchu assistant professor in the

4
00:00:06,560 --> 00:00:10,320
u of a u of arbitra this work is done

5
00:00:10,320 --> 00:00:12,799
when i was in qatar computing research

6
00:00:12,799 --> 00:00:14,920
institute with the qcra

7
00:00:14,920 --> 00:00:17,520
researcher today i will introduce our

8
00:00:17,520 --> 00:00:20,480
work cirrus the unified framework to

9
00:00:20,480 --> 00:00:23,519
aggregate the drug intelligence report

10
00:00:23,519 --> 00:00:27,439
and build a high quality ground truth

11
00:00:27,439 --> 00:00:29,760
so there are many types of internet

12
00:00:29,760 --> 00:00:32,960
threads such as malicious urls malware

13
00:00:32,960 --> 00:00:35,440
files malicious eyepiece

14
00:00:35,440 --> 00:00:37,680
typically these different types of

15
00:00:37,680 --> 00:00:40,160
internet threads are detected by

16
00:00:40,160 --> 00:00:43,920
different detectors such as the url

17
00:00:43,920 --> 00:00:47,840
scanning service antivirus engines and

18
00:00:47,840 --> 00:00:50,160
ip blacklist

19
00:00:50,160 --> 00:00:52,879
however the internet threats are fast

20
00:00:52,879 --> 00:00:55,680
evolving and the detectors need to

21
00:00:55,680 --> 00:00:56,960
constantly

22
00:00:56,960 --> 00:01:00,160
adapt to such fast evolving

23
00:01:00,160 --> 00:01:02,640
threats

24
00:01:02,640 --> 00:01:04,400
the

25
00:01:04,400 --> 00:01:06,960
relying on the single source

26
00:01:06,960 --> 00:01:08,640
to get the

27
00:01:08,640 --> 00:01:10,240
good

28
00:01:10,240 --> 00:01:13,680
result is sub-optimal because

29
00:01:13,680 --> 00:01:16,320
the performance will greatly depend on

30
00:01:16,320 --> 00:01:18,560
that single service

31
00:01:18,560 --> 00:01:21,920
so we need to use the multiple services

32
00:01:21,920 --> 00:01:22,960
and

33
00:01:22,960 --> 00:01:26,400
aggregate the intelligence

34
00:01:26,400 --> 00:01:28,240
there are many different

35
00:01:28,240 --> 00:01:30,880
services to aggregate intelligent

36
00:01:30,880 --> 00:01:34,240
sources the virus total is one of such

37
00:01:34,240 --> 00:01:37,280
examples and i will explain the context

38
00:01:37,280 --> 00:01:39,840
of the virus total but our approach can

39
00:01:39,840 --> 00:01:43,600
work for different services as well

40
00:01:43,600 --> 00:01:45,680
in the virus total

41
00:01:45,680 --> 00:01:49,040
users can query in the url and the file

42
00:01:49,040 --> 00:01:51,600
to get the result from the 80 plus

43
00:01:51,600 --> 00:01:53,040
scanners

44
00:01:53,040 --> 00:01:54,960
about the decision of the malicious

45
00:01:54,960 --> 00:01:57,200
needs of the entities

46
00:01:57,200 --> 00:02:00,320
here for example mega fest say

47
00:02:00,320 --> 00:02:04,560
malicious and the microsoft say benign

48
00:02:04,560 --> 00:02:06,880
but these results from different

49
00:02:06,880 --> 00:02:09,119
scanners are often conflicting each

50
00:02:09,119 --> 00:02:10,239
other

51
00:02:10,239 --> 00:02:12,640
so when we are having the conflicting

52
00:02:12,640 --> 00:02:13,920
labels

53
00:02:13,920 --> 00:02:16,800
how can we decide how can we aggregate

54
00:02:16,800 --> 00:02:19,120
this information to

55
00:02:19,120 --> 00:02:21,920
give the final judgment judgement

56
00:02:21,920 --> 00:02:25,120
we just ignore one of them or we just

57
00:02:25,120 --> 00:02:28,879
choose whatever we want

58
00:02:28,959 --> 00:02:31,360
most common approach to aggregate our

59
00:02:31,360 --> 00:02:33,440
intelligence sources is the

60
00:02:33,440 --> 00:02:34,840
threshold-based

61
00:02:34,840 --> 00:02:38,080
approach typically we just use some

62
00:02:38,080 --> 00:02:40,560
number so that if there is certain

63
00:02:40,560 --> 00:02:43,360
number of scanners detect

64
00:02:43,360 --> 00:02:46,480
then we consider it as among issues

65
00:02:46,480 --> 00:02:49,360
in fact in the literature the arbitrary

66
00:02:49,360 --> 00:02:50,560
number

67
00:02:50,560 --> 00:02:54,560
of threshold has been used as is in this

68
00:02:54,560 --> 00:02:57,120
trade table some of the newest ones some

69
00:02:57,120 --> 00:02:59,760
of them one to five some of them 10 for

70
00:02:59,760 --> 00:03:01,040
example

71
00:03:01,040 --> 00:03:03,440
but there is no consensus on the

72
00:03:03,440 --> 00:03:08,000
appropriate threshold to define the

73
00:03:08,000 --> 00:03:10,800
maliciousness

74
00:03:10,800 --> 00:03:13,360
there are the trade-off between the

75
00:03:13,360 --> 00:03:16,480
threshold high threshold may give the

76
00:03:16,480 --> 00:03:20,640
high precision but low coverage

77
00:03:20,640 --> 00:03:24,319
the low threshold may give the low

78
00:03:24,319 --> 00:03:28,640
precision and high coverage

79
00:03:28,640 --> 00:03:31,279
furthermore

80
00:03:31,360 --> 00:03:33,519
these threshold-based approaches

81
00:03:33,519 --> 00:03:36,239
typically assume all the intelligent

82
00:03:36,239 --> 00:03:39,120
sources are independent

83
00:03:39,120 --> 00:03:42,319
and they can deal with the

84
00:03:42,319 --> 00:03:45,040
different qualities and the different

85
00:03:45,040 --> 00:03:48,040
reliabilities

86
00:03:48,319 --> 00:03:51,280
traditionally many supervised machine

87
00:03:51,280 --> 00:03:53,599
learning method has been used for

88
00:03:53,599 --> 00:03:55,120
decades

89
00:03:55,120 --> 00:03:57,439
however these supervised

90
00:03:57,439 --> 00:03:59,120
approaches

91
00:03:59,120 --> 00:04:02,560
typically need a lot of manual

92
00:04:02,560 --> 00:04:04,799
annotation process

93
00:04:04,799 --> 00:04:07,360
which require a lot of time consuming

94
00:04:07,360 --> 00:04:08,400
cost

95
00:04:08,400 --> 00:04:12,080
and machine learning approaches are

96
00:04:12,080 --> 00:04:15,200
needed to be retraining every few hours

97
00:04:15,200 --> 00:04:18,000
for every few days to update for the

98
00:04:18,000 --> 00:04:20,560
first evolving threats

99
00:04:20,560 --> 00:04:23,759
which will add more and more manual

100
00:04:23,759 --> 00:04:26,560
annotation cost

101
00:04:26,560 --> 00:04:28,240
furthermore

102
00:04:28,240 --> 00:04:30,479
traditional supervised learning

103
00:04:30,479 --> 00:04:32,720
approaches typically use the domain

104
00:04:32,720 --> 00:04:34,800
specific features

105
00:04:34,800 --> 00:04:36,320
and they are

106
00:04:36,320 --> 00:04:39,600
tailored to one type of threat

107
00:04:39,600 --> 00:04:42,960
instead we propose a self-supervised

108
00:04:42,960 --> 00:04:44,639
learning approach

109
00:04:44,639 --> 00:04:46,639
that requires no

110
00:04:46,639 --> 00:04:49,759
or a small set of labels

111
00:04:49,759 --> 00:04:50,800
to

112
00:04:50,800 --> 00:04:54,320
aggregate the information yet we achieve

113
00:04:54,320 --> 00:04:57,199
a high quality ground truths and early

114
00:04:57,199 --> 00:04:59,520
detection

115
00:04:59,520 --> 00:05:02,160
our approach is generic so that it can

116
00:05:02,160 --> 00:05:05,360
be applied to diverse threat types like

117
00:05:05,360 --> 00:05:08,240
a malware file malicious urls malicious

118
00:05:08,240 --> 00:05:11,199
eyepiece

119
00:05:11,199 --> 00:05:13,520
there are multiple challenges when we

120
00:05:13,520 --> 00:05:15,840
are aggregating the intelligent sources

121
00:05:15,840 --> 00:05:20,080
i will go over one by one

122
00:05:20,560 --> 00:05:22,880
first of all different scanners are

123
00:05:22,880 --> 00:05:25,280
having different expertise

124
00:05:25,280 --> 00:05:27,840
in the right figure shows that phishing

125
00:05:27,840 --> 00:05:31,280
urls may be detected by the phishing

126
00:05:31,280 --> 00:05:33,680
scanners but it will not be detected by

127
00:05:33,680 --> 00:05:36,000
the malware url scanners

128
00:05:36,000 --> 00:05:39,280
malware urls may be detected by the

129
00:05:39,280 --> 00:05:40,479
malicious

130
00:05:40,479 --> 00:05:43,360
url scanner but maybe not by the

131
00:05:43,360 --> 00:05:45,919
phishing scanners

132
00:05:45,919 --> 00:05:48,960
because of these different expertise

133
00:05:48,960 --> 00:05:51,600
the scanner's performance will

134
00:05:51,600 --> 00:05:55,120
depend on each type of internet threat

135
00:05:55,120 --> 00:05:58,160
and in the left figure withdrawn from

136
00:05:58,160 --> 00:05:59,680
other paper

137
00:05:59,680 --> 00:06:02,880
that shows there are not many scanners

138
00:06:02,880 --> 00:06:05,520
who achieve good balance between the

139
00:06:05,520 --> 00:06:07,360
true positive rate and the false

140
00:06:07,360 --> 00:06:10,240
positive rate

141
00:06:10,720 --> 00:06:14,400
second scanners are often known to

142
00:06:14,400 --> 00:06:17,919
flip their labels so at time point 1 is

143
00:06:17,919 --> 00:06:21,759
say malicious at time point 2 is say b9

144
00:06:21,759 --> 00:06:24,960
then depending on the time user collect

145
00:06:24,960 --> 00:06:28,000
the information from the scanner it may

146
00:06:28,000 --> 00:06:29,919
end up different

147
00:06:29,919 --> 00:06:33,440
misleading decision

148
00:06:33,440 --> 00:06:35,759
third only reports are

149
00:06:35,759 --> 00:06:39,039
typically less reliable scanners

150
00:06:39,039 --> 00:06:41,520
in the beginning time may not detect

151
00:06:41,520 --> 00:06:42,400
well

152
00:06:42,400 --> 00:06:44,479
and they will take time to reach the

153
00:06:44,479 --> 00:06:46,319
maximum accuracy

154
00:06:46,319 --> 00:06:49,280
this figure shows that around 5 to 10

155
00:06:49,280 --> 00:06:50,960
days it will

156
00:06:50,960 --> 00:06:54,800
take the scanners to detect

157
00:06:54,800 --> 00:06:57,680
and that will be a problem when we have

158
00:06:57,680 --> 00:07:01,960
the zero day internet threats

159
00:07:02,479 --> 00:07:05,599
force scanners are known to have high

160
00:07:05,599 --> 00:07:07,039
correlation

161
00:07:07,039 --> 00:07:10,880
for example here ibs and the abc has

162
00:07:10,880 --> 00:07:13,280
showing the similar labels

163
00:07:13,280 --> 00:07:16,560
but what if these similar scanners are

164
00:07:16,560 --> 00:07:19,120
having the poor performance

165
00:07:19,120 --> 00:07:20,960
we are using the threshold-based

166
00:07:20,960 --> 00:07:23,520
approaches and if you assume they are

167
00:07:23,520 --> 00:07:24,880
independent

168
00:07:24,880 --> 00:07:26,560
we will take

169
00:07:26,560 --> 00:07:28,840
two as the

170
00:07:28,840 --> 00:07:32,160
detecting not malicious for example

171
00:07:32,160 --> 00:07:36,880
then it will give the misleading result

172
00:07:36,880 --> 00:07:39,280
so our approach syrus

173
00:07:39,280 --> 00:07:42,080
is considering all of these challenges

174
00:07:42,080 --> 00:07:44,400
together with the self-supervised

175
00:07:44,400 --> 00:07:45,919
learning approach

176
00:07:45,919 --> 00:07:48,160
to deal with the diverse internet threat

177
00:07:48,160 --> 00:07:50,000
type

178
00:07:50,000 --> 00:07:52,720
our approach will generate the domain

179
00:07:52,720 --> 00:07:54,960
and the time invariant embeddings that

180
00:07:54,960 --> 00:07:59,039
will be used for the downstream task

181
00:07:59,039 --> 00:08:01,280
so what is self-supervised learning

182
00:08:01,280 --> 00:08:04,080
because it is a new emerging area let me

183
00:08:04,080 --> 00:08:07,199
explain a little bit with the context

184
00:08:07,199 --> 00:08:09,840
traditional supervised learning method

185
00:08:09,840 --> 00:08:12,639
has the bottleneck of the manual

186
00:08:12,639 --> 00:08:14,800
annotation process

187
00:08:14,800 --> 00:08:16,879
self-supervised learning approach

188
00:08:16,879 --> 00:08:19,599
basically wants to automate this process

189
00:08:19,599 --> 00:08:20,639
to

190
00:08:20,639 --> 00:08:22,639
generate the pseudo label

191
00:08:22,639 --> 00:08:25,599
while learning the properties of the

192
00:08:25,599 --> 00:08:26,639
data

193
00:08:26,639 --> 00:08:29,599
but it does not use any label we are

194
00:08:29,599 --> 00:08:32,719
just throwing the bunch of the unlabeled

195
00:08:32,719 --> 00:08:34,320
data

196
00:08:34,320 --> 00:08:38,159
but because of learning process it will

197
00:08:38,159 --> 00:08:41,679
be able to work really good

198
00:08:41,679 --> 00:08:46,080
typically this is solved by solving the

199
00:08:46,080 --> 00:08:50,080
self-task called a pre-test test

200
00:08:50,080 --> 00:08:51,680
so essentially

201
00:08:51,680 --> 00:08:54,480
the self-supervised learning approach is

202
00:08:54,480 --> 00:08:57,760
working by the designing and solving the

203
00:08:57,760 --> 00:08:59,839
pre-text test

204
00:08:59,839 --> 00:09:02,880
pre-test tasks should be relevant to the

205
00:09:02,880 --> 00:09:05,519
manual and no i mean the

206
00:09:05,519 --> 00:09:07,440
main task

207
00:09:07,440 --> 00:09:10,800
but the labels should be easily

208
00:09:10,800 --> 00:09:12,080
collected

209
00:09:12,080 --> 00:09:14,720
for example let's assume that our goal

210
00:09:14,720 --> 00:09:15,480
is to

211
00:09:15,480 --> 00:09:17,440
[Music]

212
00:09:17,440 --> 00:09:19,920
image classification

213
00:09:19,920 --> 00:09:22,640
one of possible pretext texts would be

214
00:09:22,640 --> 00:09:26,560
image rotation prediction which will be

215
00:09:26,560 --> 00:09:28,320
pretty easy to collect we can just

216
00:09:28,320 --> 00:09:31,279
rotate the images

217
00:09:31,279 --> 00:09:34,160
we are training the model based on this

218
00:09:34,160 --> 00:09:37,440
pretext test and the pre-trained encoder

219
00:09:37,440 --> 00:09:39,120
can be used

220
00:09:39,120 --> 00:09:39,920
for

221
00:09:39,920 --> 00:09:41,760
our main task

222
00:09:41,760 --> 00:09:44,640
and it will be used for the downstream

223
00:09:44,640 --> 00:09:46,800
task

224
00:09:46,800 --> 00:09:49,519
this is the high-level approach i'm a

225
00:09:49,519 --> 00:09:52,959
high level overview of our approach

226
00:09:52,959 --> 00:09:55,279
we are taking the historical threat

227
00:09:55,279 --> 00:09:58,320
reports and we are training using the

228
00:09:58,320 --> 00:10:00,560
self-supervised learning approach which

229
00:10:00,560 --> 00:10:03,440
will learn the properties of data

230
00:10:03,440 --> 00:10:06,000
and during the fine-tuning step

231
00:10:06,000 --> 00:10:10,079
we pass the new drug report and use the

232
00:10:10,079 --> 00:10:12,399
pre-training encoder to

233
00:10:12,399 --> 00:10:15,120
generate the embedding which will be

234
00:10:15,120 --> 00:10:16,800
domain invariant

235
00:10:16,800 --> 00:10:19,040
and it will be used for the downstream

236
00:10:19,040 --> 00:10:21,360
test

237
00:10:21,839 --> 00:10:25,040
so how can we design the

238
00:10:25,040 --> 00:10:26,640
pretext test

239
00:10:26,640 --> 00:10:29,519
the important property of pretext tests

240
00:10:29,519 --> 00:10:33,279
supposed to be relevant to the main task

241
00:10:33,279 --> 00:10:35,440
and it needs to be

242
00:10:35,440 --> 00:10:39,839
easily obtaining the labels

243
00:10:40,079 --> 00:10:42,720
we carefully designed three pre-text

244
00:10:42,720 --> 00:10:45,120
tests for our purpose

245
00:10:45,120 --> 00:10:47,519
and that is the relevant to our main

246
00:10:47,519 --> 00:10:50,160
task to build a high quality ground

247
00:10:50,160 --> 00:10:52,560
truths by aggregating the intelligent

248
00:10:52,560 --> 00:10:53,760
sources

249
00:10:53,760 --> 00:10:56,240
which consider all of these challenges

250
00:10:56,240 --> 00:10:58,079
we mentioned

251
00:10:58,079 --> 00:11:01,680
our goal is to design the generic

252
00:11:01,680 --> 00:11:04,160
pretext test that can deal with diverse

253
00:11:04,160 --> 00:11:06,000
threat types

254
00:11:06,000 --> 00:11:07,680
the embeddings

255
00:11:07,680 --> 00:11:10,000
from our model can be used for

256
00:11:10,000 --> 00:11:13,040
downstream tests

257
00:11:13,519 --> 00:11:14,959
let me go

258
00:11:14,959 --> 00:11:17,680
each of these pre-test tasks

259
00:11:17,680 --> 00:11:21,600
the first pre-text text is trying to

260
00:11:21,600 --> 00:11:24,160
handle the high-level correlation i

261
00:11:24,160 --> 00:11:27,040
mentioned between the scanners

262
00:11:27,040 --> 00:11:30,560
essentially it will learn the scanner's

263
00:11:30,560 --> 00:11:32,320
dependency

264
00:11:32,320 --> 00:11:36,240
to do so we mask or corrupt some of the

265
00:11:36,240 --> 00:11:39,600
entries from the scanner result

266
00:11:39,600 --> 00:11:43,519
and then this model will try to identify

267
00:11:43,519 --> 00:11:46,800
which entries are masked or corrupted

268
00:11:46,800 --> 00:11:47,519
and

269
00:11:47,519 --> 00:11:49,839
which are the correct values for the

270
00:11:49,839 --> 00:11:53,760
mask or the corrupted values

271
00:11:53,839 --> 00:11:57,680
second pre-text test is try to handle

272
00:11:57,680 --> 00:12:01,600
the only report which are unreliable

273
00:12:01,600 --> 00:12:04,880
and flipping labels

274
00:12:04,880 --> 00:12:07,440
this model will learn the temporal

275
00:12:07,440 --> 00:12:10,079
scanner dependencies

276
00:12:10,079 --> 00:12:13,440
so we have the time series of the thread

277
00:12:13,440 --> 00:12:15,120
reports

278
00:12:15,120 --> 00:12:17,839
for the same entries for the scanner

279
00:12:17,839 --> 00:12:19,200
result

280
00:12:19,200 --> 00:12:22,800
and basically given the current label we

281
00:12:22,800 --> 00:12:27,359
want to predict the future labels

282
00:12:28,880 --> 00:12:31,320
third pre-text text is kind of

283
00:12:31,320 --> 00:12:35,200
regularizer of previous two pre-text

284
00:12:35,200 --> 00:12:36,560
tests

285
00:12:36,560 --> 00:12:38,839
so that it tried to ensure the

286
00:12:38,839 --> 00:12:42,000
representation between corrupted and

287
00:12:42,000 --> 00:12:43,839
original and the

288
00:12:43,839 --> 00:12:47,440
future and the current label

289
00:12:47,440 --> 00:12:50,320
this is learning in the way to maximize

290
00:12:50,320 --> 00:12:53,120
the similarity between the

291
00:12:53,120 --> 00:12:55,839
representation of the original versus

292
00:12:55,839 --> 00:12:58,160
corrupted and

293
00:12:58,160 --> 00:13:02,480
current versus future labels

294
00:13:02,720 --> 00:13:06,240
this figure shows our overall approach

295
00:13:06,240 --> 00:13:09,680
in detail we first use the

296
00:13:09,680 --> 00:13:12,560
gem model before the self-supervised

297
00:13:12,560 --> 00:13:15,600
learning which will give some

298
00:13:15,600 --> 00:13:19,360
the dependence analysis for in the

299
00:13:19,360 --> 00:13:20,959
corpus level

300
00:13:20,959 --> 00:13:22,959
and then using the self-supervised

301
00:13:22,959 --> 00:13:26,560
learning module we pretend the encoder

302
00:13:26,560 --> 00:13:30,000
and using that pre-trained encoder the

303
00:13:30,000 --> 00:13:32,639
thread new thread report will be passed

304
00:13:32,639 --> 00:13:34,639
over and we are performing two

305
00:13:34,639 --> 00:13:37,120
downstream tasks semi-supervised

306
00:13:37,120 --> 00:13:40,399
learning and unsupervised learning

307
00:13:40,399 --> 00:13:43,600
so my supervised learning task will take

308
00:13:43,600 --> 00:13:46,399
just a small set of labels such as like

309
00:13:46,399 --> 00:13:49,519
a hundred and unsupervised learning

310
00:13:49,519 --> 00:13:51,440
approach

311
00:13:51,440 --> 00:13:54,880
we cluster the embeddings and then use

312
00:13:54,880 --> 00:13:58,959
the small cluster as the malicious

313
00:13:59,120 --> 00:14:01,519
this table shows our

314
00:14:01,519 --> 00:14:03,760
data set we have used

315
00:14:03,760 --> 00:14:06,880
the urls are collected by ourselves and

316
00:14:06,880 --> 00:14:08,720
other

317
00:14:08,720 --> 00:14:11,120
things are collected from the other

318
00:14:11,120 --> 00:14:12,480
papers

319
00:14:12,480 --> 00:14:15,279
to show the generality of our approach

320
00:14:15,279 --> 00:14:17,839
we use four different type of internet

321
00:14:17,839 --> 00:14:20,880
threats phishing urls malware urls

322
00:14:20,880 --> 00:14:25,519
malware files and iep blacklist

323
00:14:25,519 --> 00:14:26,959
we compare

324
00:14:26,959 --> 00:14:29,279
our approach with the four baseline

325
00:14:29,279 --> 00:14:30,399
approaches

326
00:14:30,399 --> 00:14:33,120
one is optimal threshold

327
00:14:33,120 --> 00:14:36,160
second is the supervised base

328
00:14:36,160 --> 00:14:37,440
approach

329
00:14:37,440 --> 00:14:39,680
with the deep neural network

330
00:14:39,680 --> 00:14:41,519
third is the

331
00:14:41,519 --> 00:14:44,240
unsupervised method using the embase

332
00:14:44,240 --> 00:14:47,040
model and forces the weak supervision

333
00:14:47,040 --> 00:14:48,160
model

334
00:14:48,160 --> 00:14:51,120
detail of which can be found in the

335
00:14:51,120 --> 00:14:53,519
paper

336
00:14:53,839 --> 00:14:57,680
so this figure shows our performance

337
00:14:57,680 --> 00:15:00,160
we measure the iphone score with the

338
00:15:00,160 --> 00:15:01,519
different

339
00:15:01,519 --> 00:15:04,480
time report and we perform the

340
00:15:04,480 --> 00:15:06,480
experiment for different type of

341
00:15:06,480 --> 00:15:08,959
internet thread phishing url malware

342
00:15:08,959 --> 00:15:13,040
urls malware files malicious eyepiece

343
00:15:13,040 --> 00:15:14,880
as you can see

344
00:15:14,880 --> 00:15:19,040
we can achieve the constantly high

345
00:15:19,040 --> 00:15:21,760
f1 score compared to other baseline

346
00:15:21,760 --> 00:15:23,360
approaches

347
00:15:23,360 --> 00:15:24,399
further

348
00:15:24,399 --> 00:15:27,440
even using really early reports we can

349
00:15:27,440 --> 00:15:29,360
achieve high

350
00:15:29,360 --> 00:15:32,399
f1 score we are constant no matter which

351
00:15:32,399 --> 00:15:35,440
time point of report we are using

352
00:15:35,440 --> 00:15:38,079
on the other hand the other baseline

353
00:15:38,079 --> 00:15:42,079
approaches are having really low

354
00:15:42,079 --> 00:15:44,720
performance using the early reports

355
00:15:44,720 --> 00:15:46,000
that's the

356
00:15:46,000 --> 00:15:47,440
that's because

357
00:15:47,440 --> 00:15:49,720
they do not consider such

358
00:15:49,720 --> 00:15:54,920
unreliability of early report

359
00:15:55,199 --> 00:15:58,079
we use the different training set size

360
00:15:58,079 --> 00:16:00,000
as well

361
00:16:00,000 --> 00:16:03,199
we are using the smallest as like 100

362
00:16:03,199 --> 00:16:05,920
labels only and we are increasing the

363
00:16:05,920 --> 00:16:07,600
training size

364
00:16:07,600 --> 00:16:10,480
as you can see regardless of the

365
00:16:10,480 --> 00:16:14,639
training size we can achieve the high f1

366
00:16:14,639 --> 00:16:16,560
score constantly

367
00:16:16,560 --> 00:16:19,199
staying same almost same

368
00:16:19,199 --> 00:16:21,600
regardless of the training size

369
00:16:21,600 --> 00:16:24,480
but other approaches are greatly depend

370
00:16:24,480 --> 00:16:28,000
on the training size like they are

371
00:16:28,000 --> 00:16:30,560
having really low with the small data

372
00:16:30,560 --> 00:16:32,880
size

373
00:16:33,440 --> 00:16:35,199
to wrap up

374
00:16:35,199 --> 00:16:36,480
our

375
00:16:36,480 --> 00:16:40,440
proposed approach is the first

376
00:16:40,440 --> 00:16:43,279
self-supervised learning approach

377
00:16:43,279 --> 00:16:45,680
to aggregate the drug intelligence

378
00:16:45,680 --> 00:16:46,959
report

379
00:16:46,959 --> 00:16:49,440
our approach is the unified and the

380
00:16:49,440 --> 00:16:52,639
generic framework so that it can be used

381
00:16:52,639 --> 00:16:55,600
for diverse threat types malware files

382
00:16:55,600 --> 00:16:59,600
smallest url malicious ips

383
00:16:59,600 --> 00:17:03,279
and even our unsupervised approach can

384
00:17:03,279 --> 00:17:06,079
beat the previous baseline approaches

385
00:17:06,079 --> 00:17:08,000
which is really good

386
00:17:08,000 --> 00:17:11,039
like using no label we can still achieve

387
00:17:11,039 --> 00:17:13,760
the high reference score

388
00:17:13,760 --> 00:17:16,959
um thank you for listening and this is

389
00:17:16,959 --> 00:17:19,039
end of my presentation i will take the

390
00:17:19,039 --> 00:17:20,400
question

391
00:17:20,400 --> 00:17:22,799
thank you

392
00:17:25,439 --> 00:17:27,439
we have time for one quick question is

393
00:17:27,439 --> 00:17:29,200
there any question from the audience

394
00:17:29,200 --> 00:17:33,320
yeah could you come to the bank

395
00:17:36,480 --> 00:17:39,679
sorry if i missed it when you do the

396
00:17:39,679 --> 00:17:42,000
segregation for training and

397
00:17:42,000 --> 00:17:43,679
analysis do you have

398
00:17:43,679 --> 00:17:45,520
what timeline do you use is it on a

399
00:17:45,520 --> 00:17:47,200
daily basis or

400
00:17:47,200 --> 00:17:49,919
there's a historic data that goes into

401
00:17:49,919 --> 00:17:52,720
so we are using different scale and if

402
00:17:52,720 --> 00:17:54,880
you see here we are using like a six

403
00:17:54,880 --> 00:17:57,440
hours of data for the fishing url for

404
00:17:57,440 --> 00:18:01,039
example and then 12 hour 24 hour etc we

405
00:18:01,039 --> 00:18:03,520
are changing until like

406
00:18:03,520 --> 00:18:05,679
one week so that we are showing the

407
00:18:05,679 --> 00:18:08,559
performance depending on the report

408
00:18:08,559 --> 00:18:12,000
age that's great thank you thank you

409
00:18:12,000 --> 00:18:14,720
thank you very much let's thank the

410
00:18:14,720 --> 00:18:16,240
speaker again

411
00:18:16,240 --> 00:18:19,819
[Applause]

