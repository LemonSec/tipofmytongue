1
00:00:00,560 --> 00:00:02,720
i'll be presenting my paper titled mm

2
00:00:02,720 --> 00:00:05,520
spy uh spying phone calls using mmv

3
00:00:05,520 --> 00:00:06,720
radars

4
00:00:06,720 --> 00:00:08,960
my co-author on this paper is dr mahant

5
00:00:08,960 --> 00:00:11,280
gauda who is my phd advisor and this

6
00:00:11,280 --> 00:00:13,360
research has been sponsored by penn

7
00:00:13,360 --> 00:00:14,920
state and

8
00:00:14,920 --> 00:00:17,680
nsf so we often share sensitive

9
00:00:17,680 --> 00:00:20,000
information over phone calls imagine

10
00:00:20,000 --> 00:00:23,039
your aunt or uncle calling you in and

11
00:00:23,039 --> 00:00:24,320
you know sharing their credit card

12
00:00:24,320 --> 00:00:27,119
details with you right you might imagine

13
00:00:27,119 --> 00:00:28,560
that such an interaction is

14
00:00:28,560 --> 00:00:30,560
fundamentally benign but

15
00:00:30,560 --> 00:00:32,800
if somebody in your environment could

16
00:00:32,800 --> 00:00:34,719
just tap into your phone call and

17
00:00:34,719 --> 00:00:36,480
compromise your

18
00:00:36,480 --> 00:00:38,960
credit card data it would be something

19
00:00:38,960 --> 00:00:41,440
very serious

20
00:00:41,440 --> 00:00:43,600
all of this kind of broadly falls into

21
00:00:43,600 --> 00:00:45,600
the the umbrella of wireless

22
00:00:45,600 --> 00:00:47,360
eavesdropping and in the last session

23
00:00:47,360 --> 00:00:49,440
longhuang from lsu made a mention of

24
00:00:49,440 --> 00:00:51,440
wireless eavesdropping

25
00:00:51,440 --> 00:00:53,520
uh ms pi is a system that fits exactly

26
00:00:53,520 --> 00:00:55,840
within within the theme

27
00:00:55,840 --> 00:00:58,719
so how do we implement it

28
00:00:58,719 --> 00:01:00,640
concurrent to the development of 5g

29
00:01:00,640 --> 00:01:02,399
telecommunication systems there's also

30
00:01:02,399 --> 00:01:04,879
been a lot of force put into developing

31
00:01:04,879 --> 00:01:06,880
radars that work in the same frequency

32
00:01:06,880 --> 00:01:08,000
ranges

33
00:01:08,000 --> 00:01:10,640
roughly in the 28 to 300 gigahertz and

34
00:01:10,640 --> 00:01:12,720
these are called mm wave radars because

35
00:01:12,720 --> 00:01:13,680
the

36
00:01:13,680 --> 00:01:15,759
wavelength of the waves that are used is

37
00:01:15,759 --> 00:01:16,720
in the

38
00:01:16,720 --> 00:01:19,439
millimeter range they offer very high

39
00:01:19,439 --> 00:01:22,000
range resolution high precision and even

40
00:01:22,000 --> 00:01:24,840
sensitivity to micrometer level

41
00:01:24,840 --> 00:01:28,000
vibrations broadly there are two major

42
00:01:28,000 --> 00:01:30,880
aspects of the mm-spy system the

43
00:01:30,880 --> 00:01:33,119
first is the signal acquisition which is

44
00:01:33,119 --> 00:01:35,920
done using mmv radars and there's also a

45
00:01:35,920 --> 00:01:38,079
machine learning component that we use

46
00:01:38,079 --> 00:01:40,240
to process the data that we acquire from

47
00:01:40,240 --> 00:01:41,759
mmv radars

48
00:01:41,759 --> 00:01:43,360
i will be explaining each of these

49
00:01:43,360 --> 00:01:46,159
components separately and then i'll

50
00:01:46,159 --> 00:01:48,320
conclude by explaining how everything

51
00:01:48,320 --> 00:01:50,079
comes together

52
00:01:50,079 --> 00:01:53,600
so first let's talk about mmv radars

53
00:01:53,600 --> 00:01:56,240
in ms5 we use texas instruments

54
00:01:56,240 --> 00:01:58,880
millimeter wave radars they broadly work

55
00:01:58,880 --> 00:02:01,920
in the past band ranges of 77 to 81

56
00:02:01,920 --> 00:02:05,200
gigahertz and 60 to 64 gigahertz

57
00:02:05,200 --> 00:02:07,280
these radars have found a lot of use

58
00:02:07,280 --> 00:02:10,318
cases already in various applications

59
00:02:10,318 --> 00:02:12,239
that include but are not restricted to

60
00:02:12,239 --> 00:02:15,920
automotive ranging in self-driving cars

61
00:02:15,920 --> 00:02:18,160
smart health monitoring that includes

62
00:02:18,160 --> 00:02:20,080
respiration and heartbeat monitoring at

63
00:02:20,080 --> 00:02:22,160
a distance and different forms of

64
00:02:22,160 --> 00:02:24,239
activity tracking that include but again

65
00:02:24,239 --> 00:02:26,720
are not restricted to you know gesture

66
00:02:26,720 --> 00:02:29,680
tracking fall detection

67
00:02:29,680 --> 00:02:31,599
other than that uh millimeter wave

68
00:02:31,599 --> 00:02:33,920
radars are also being explored in the

69
00:02:33,920 --> 00:02:36,239
areas of smart agriculture material

70
00:02:36,239 --> 00:02:37,280
sensing

71
00:02:37,280 --> 00:02:38,000
so

72
00:02:38,000 --> 00:02:41,760
the applications are all over the place

73
00:02:42,400 --> 00:02:46,959
the way that ti's mm wave radars work is

74
00:02:46,959 --> 00:02:48,720
they fundamentally use

75
00:02:48,720 --> 00:02:49,599
a

76
00:02:49,599 --> 00:02:51,680
sinusoidal signal with a varying

77
00:02:51,680 --> 00:02:53,840
frequency component these signals are

78
00:02:53,840 --> 00:02:56,560
commonly referred to as chirps

79
00:02:56,560 --> 00:02:57,360
and

80
00:02:57,360 --> 00:02:59,599
the modulation scheme is known as

81
00:02:59,599 --> 00:03:01,760
frequency modulator continuous wave or

82
00:03:01,760 --> 00:03:05,840
fmcw for short as for the ranging once a

83
00:03:05,840 --> 00:03:08,720
chirp is shot out from the transmitter

84
00:03:08,720 --> 00:03:09,840
antenna

85
00:03:09,840 --> 00:03:11,680
and it bounces off an object in the

86
00:03:11,680 --> 00:03:13,200
environment

87
00:03:13,200 --> 00:03:15,760
we can subtract the transmitter and the

88
00:03:15,760 --> 00:03:17,280
received signals at the end of the

89
00:03:17,280 --> 00:03:18,959
receiver

90
00:03:18,959 --> 00:03:21,440
and from that we can infer the distance

91
00:03:21,440 --> 00:03:23,760
to different objects in the environment

92
00:03:23,760 --> 00:03:25,760
so the intermediate frequency at the

93
00:03:25,760 --> 00:03:27,200
receiver end

94
00:03:27,200 --> 00:03:29,680
basically is encoded with the

95
00:03:29,680 --> 00:03:30,799
difference in frequencies of the

96
00:03:30,799 --> 00:03:32,799
transmitter and the received signals

97
00:03:32,799 --> 00:03:35,200
we do a fourier analysis of that and we

98
00:03:35,200 --> 00:03:36,080
can

99
00:03:36,080 --> 00:03:39,120
basically use this formula to estimate

100
00:03:39,120 --> 00:03:41,760
the distance to any object the slope of

101
00:03:41,760 --> 00:03:44,159
a chirp is how fast

102
00:03:44,159 --> 00:03:46,640
the frequency is modulated

103
00:03:46,640 --> 00:03:48,480
and we of course know the speed of light

104
00:03:48,480 --> 00:03:50,239
so the free the intermediate frequency

105
00:03:50,239 --> 00:03:52,560
signal at the receiver has a frequency

106
00:03:52,560 --> 00:03:57,120
component of 2s times d over c

107
00:03:57,120 --> 00:03:58,159
now

108
00:03:58,159 --> 00:04:00,720
when there are really subtle movements

109
00:04:00,720 --> 00:04:02,879
or really minute vibrations of the order

110
00:04:02,879 --> 00:04:05,040
of micrometers

111
00:04:05,040 --> 00:04:06,799
the intermediate frequency signal does

112
00:04:06,799 --> 00:04:08,959
not show us a whole different frequency

113
00:04:08,959 --> 00:04:11,439
but there are subtle phase changes in

114
00:04:11,439 --> 00:04:13,120
the signal if we track these phase

115
00:04:13,120 --> 00:04:14,400
changes over time

116
00:04:14,400 --> 00:04:16,639
we basically get an audio signal

117
00:04:16,639 --> 00:04:18,320
here's a representation of that over

118
00:04:18,320 --> 00:04:19,519
time so

119
00:04:19,519 --> 00:04:21,600
the access that's labeled as chirp index

120
00:04:21,600 --> 00:04:24,000
is analogous to time and i'm just

121
00:04:24,000 --> 00:04:25,680
basically tracking multiple chirps over

122
00:04:25,680 --> 00:04:28,960
time the distance bin is an index of how

123
00:04:28,960 --> 00:04:30,479
far away different objects are in the

124
00:04:30,479 --> 00:04:31,759
environment

125
00:04:31,759 --> 00:04:34,479
in the mm spy we assume that the signal

126
00:04:34,479 --> 00:04:37,360
of interest is always the most prominent

127
00:04:37,360 --> 00:04:39,840
signal so the highest peak

128
00:04:39,840 --> 00:04:41,759
is corresponding to

129
00:04:41,759 --> 00:04:43,120
a phone

130
00:04:43,120 --> 00:04:43,919
and

131
00:04:43,919 --> 00:04:46,639
the we also see some spurious peaks but

132
00:04:46,639 --> 00:04:48,400
these are from different people in the

133
00:04:48,400 --> 00:04:50,720
environment this from walls it's from

134
00:04:50,720 --> 00:04:52,160
chairs and a lot of other things but

135
00:04:52,160 --> 00:04:53,759
we're able to

136
00:04:53,759 --> 00:04:55,840
you know satisfactorily isolate the

137
00:04:55,840 --> 00:04:58,080
signal that's bouncing off of a phone

138
00:04:58,080 --> 00:04:59,520
we track these over time we track the

139
00:04:59,520 --> 00:05:02,560
phase changes and we can

140
00:05:02,560 --> 00:05:04,160
figure out you know what's being said

141
00:05:04,160 --> 00:05:06,479
over a phone call

142
00:05:06,479 --> 00:05:10,199
even though it's at a distance

143
00:05:10,320 --> 00:05:12,560
in principle however there is uh there

144
00:05:12,560 --> 00:05:14,160
are a lot of other considerations that

145
00:05:14,160 --> 00:05:15,840
need to be taken in

146
00:05:15,840 --> 00:05:17,840
before deploying the radars for this and

147
00:05:17,840 --> 00:05:20,000
we provide a very detailed

148
00:05:20,000 --> 00:05:21,840
write-up on how we configure the radars

149
00:05:21,840 --> 00:05:23,199
to work this way

150
00:05:23,199 --> 00:05:26,960
and please check out the paper for that

151
00:05:26,960 --> 00:05:28,960
so a summary of the signal acquisition

152
00:05:28,960 --> 00:05:31,440
system is basically that we have radars

153
00:05:31,440 --> 00:05:34,320
that shoot out chirps at the receiver

154
00:05:34,320 --> 00:05:37,600
end the intermediate frequency signal

155
00:05:37,600 --> 00:05:38,400
has

156
00:05:38,400 --> 00:05:39,759
the distance to different objects

157
00:05:39,759 --> 00:05:41,680
encoded in that we

158
00:05:41,680 --> 00:05:44,160
track the objects over time we track the

159
00:05:44,160 --> 00:05:45,759
phases over time

160
00:05:45,759 --> 00:05:47,840
we extract the phases and statistically

161
00:05:47,840 --> 00:05:49,600
correct them and we're left with an

162
00:05:49,600 --> 00:05:53,280
audio signal voila

163
00:05:53,280 --> 00:05:55,680
and now i'll move over to the second

164
00:05:55,680 --> 00:05:57,759
component of mm spy which is basically

165
00:05:57,759 --> 00:05:58,960
the signal

166
00:05:58,960 --> 00:06:00,560
analysis and the machine learning side

167
00:06:00,560 --> 00:06:01,919
of things

168
00:06:01,919 --> 00:06:03,600
so

169
00:06:03,600 --> 00:06:05,919
what makes machine learning really nice

170
00:06:05,919 --> 00:06:07,440
well it's actually the availability of a

171
00:06:07,440 --> 00:06:10,240
lot of training data

172
00:06:10,240 --> 00:06:14,240
i do hear a few smirks but thank you

173
00:06:14,240 --> 00:06:16,720
however in the area of

174
00:06:16,720 --> 00:06:17,759
radio

175
00:06:17,759 --> 00:06:20,560
analysis a lot of times naturally

176
00:06:20,560 --> 00:06:23,520
available large-scale data sets are just

177
00:06:23,520 --> 00:06:25,120
you know not present we can't find them

178
00:06:25,120 --> 00:06:27,759
so the strategy that we take is we take

179
00:06:27,759 --> 00:06:30,400
existing audio data sets we modify them

180
00:06:30,400 --> 00:06:31,360
to

181
00:06:31,360 --> 00:06:34,479
look like radio data sets and we chain

182
00:06:34,479 --> 00:06:36,160
our models on top of that and apply

183
00:06:36,160 --> 00:06:38,240
transfer learning on the small scale

184
00:06:38,240 --> 00:06:40,000
radar data so that's the overall

185
00:06:40,000 --> 00:06:42,319
strategy of data synthesis as well as

186
00:06:42,319 --> 00:06:44,160
using transfer learning to adapt onto

187
00:06:44,160 --> 00:06:47,600
real data the targeted tasks of ms pi

188
00:06:47,600 --> 00:06:49,919
are an audio enhancement task as well as

189
00:06:49,919 --> 00:06:53,120
a digital keyword classification task

190
00:06:53,120 --> 00:06:57,360
we begin the signal analysis pipeline by

191
00:06:57,360 --> 00:06:59,280
essentially filtering the audio really

192
00:06:59,280 --> 00:07:01,360
old school techniques but the

193
00:07:01,360 --> 00:07:04,080
the number four is being spoken

194
00:07:04,080 --> 00:07:06,400
and this is a spectrogram representation

195
00:07:06,400 --> 00:07:08,639
what we observe is that when we

196
00:07:08,639 --> 00:07:11,440
extract the raw audio um it's extremely

197
00:07:11,440 --> 00:07:12,639
noisy

198
00:07:12,639 --> 00:07:13,840
the

199
00:07:13,840 --> 00:07:15,440
you know the fundamental

200
00:07:15,440 --> 00:07:18,160
uh digit that's being spoken is not very

201
00:07:18,160 --> 00:07:20,319
clearly visible within the spectrogram

202
00:07:20,319 --> 00:07:22,720
or not even that well audible but you

203
00:07:22,720 --> 00:07:25,440
apply a band pass filter and a spectral

204
00:07:25,440 --> 00:07:27,599
subtraction filter and

205
00:07:27,599 --> 00:07:28,479
we

206
00:07:28,479 --> 00:07:30,560
get a good starting point

207
00:07:30,560 --> 00:07:31,599
right

208
00:07:31,599 --> 00:07:33,680
as for the training synthesis uh i mean

209
00:07:33,680 --> 00:07:36,479
the training data synthesis we begin by

210
00:07:36,479 --> 00:07:39,680
analyzing different aspects of the real

211
00:07:39,680 --> 00:07:41,919
radar data we try to understand how

212
00:07:41,919 --> 00:07:43,520
noisy the data is

213
00:07:43,520 --> 00:07:45,120
we try to understand other aspects of

214
00:07:45,120 --> 00:07:46,800
the radar such as the

215
00:07:46,800 --> 00:07:48,960
dc drift and

216
00:07:48,960 --> 00:07:51,280
certain other radar parameters we

217
00:07:51,280 --> 00:07:53,599
basically transform the

218
00:07:53,599 --> 00:07:55,840
or the large-scale audio data sets into

219
00:07:55,840 --> 00:07:58,080
datasets that look like radio and we

220
00:07:58,080 --> 00:07:59,199
adapt the

221
00:07:59,199 --> 00:08:01,520
final models to the small sample data

222
00:08:01,520 --> 00:08:03,759
data so what models am i exactly talking

223
00:08:03,759 --> 00:08:05,039
about

224
00:08:05,039 --> 00:08:07,199
so the first task which is related to

225
00:08:07,199 --> 00:08:09,120
audio enhancement we use

226
00:08:09,120 --> 00:08:12,720
a unit architecture to enhance the audio

227
00:08:12,720 --> 00:08:14,960
one nuance is that we use this

228
00:08:14,960 --> 00:08:17,039
architecture to

229
00:08:17,039 --> 00:08:19,759
enhance audio and we also use a post

230
00:08:19,759 --> 00:08:21,199
processing technique where we combine

231
00:08:21,199 --> 00:08:23,599
the output of this architecture

232
00:08:23,599 --> 00:08:24,840
with the

233
00:08:24,840 --> 00:08:27,680
input uh to form a masked signal and we

234
00:08:27,680 --> 00:08:29,840
observe that that gives us the best

235
00:08:29,840 --> 00:08:31,360
quality

236
00:08:31,360 --> 00:08:32,159
the

237
00:08:32,159 --> 00:08:34,000
other architecture is

238
00:08:34,000 --> 00:08:35,919
that we use spectrograms

239
00:08:35,919 --> 00:08:38,000
usual convolutional neural networks with

240
00:08:38,000 --> 00:08:40,799
residual blocks to classify keywords and

241
00:08:40,799 --> 00:08:42,719
digits

242
00:08:42,719 --> 00:08:45,120
so finally the overall system

243
00:08:45,120 --> 00:08:47,120
looks kind of like this we begin with

244
00:08:47,120 --> 00:08:49,440
existing data sets we synthesize

245
00:08:49,440 --> 00:08:51,760
training data we develop synthetic

246
00:08:51,760 --> 00:08:54,640
models and on the plane of the real data

247
00:08:54,640 --> 00:08:55,440
we

248
00:08:55,440 --> 00:08:57,760
track actual phone vibrations

249
00:08:57,760 --> 00:08:59,360
uh that are going on

250
00:08:59,360 --> 00:09:00,720
with the radars

251
00:09:00,720 --> 00:09:03,040
we collect the data and we form the

252
00:09:03,040 --> 00:09:05,040
audio signals we adapt the synthetic

253
00:09:05,040 --> 00:09:07,440
models using transfer learning and

254
00:09:07,440 --> 00:09:10,080
domain adaptation and the final model

255
00:09:10,080 --> 00:09:11,440
that we

256
00:09:11,440 --> 00:09:13,839
get after all of this is the model that

257
00:09:13,839 --> 00:09:17,200
we actually evaluate

258
00:09:17,440 --> 00:09:20,640
the experimental setup is as follows so

259
00:09:20,640 --> 00:09:22,320
the host computer is connected to the

260
00:09:22,320 --> 00:09:25,040
millimeter wave radar the

261
00:09:25,040 --> 00:09:26,320
uh i mean there's an arrow that's

262
00:09:26,320 --> 00:09:28,000
pointing to the radar

263
00:09:28,000 --> 00:09:29,200
and

264
00:09:29,200 --> 00:09:30,800
that radar is

265
00:09:30,800 --> 00:09:33,120
doing all of these your business it's

266
00:09:33,120 --> 00:09:34,880
shooting out jobs into the environment

267
00:09:34,880 --> 00:09:36,640
and there are you know the bouncing off

268
00:09:36,640 --> 00:09:38,640
of objects in the environment and it's

269
00:09:38,640 --> 00:09:41,279
coming right back at it

270
00:09:41,279 --> 00:09:43,279
we also vary the distance to the phone

271
00:09:43,279 --> 00:09:44,640
uh

272
00:09:44,640 --> 00:09:45,600
this is

273
00:09:45,600 --> 00:09:47,360
approximately four feet but we go all

274
00:09:47,360 --> 00:09:49,920
the way to six feet

275
00:09:49,920 --> 00:09:51,760
you know just a little bit of a nuance

276
00:09:51,760 --> 00:09:53,200
for taking the photo

277
00:09:53,200 --> 00:09:55,680
but we do cover a larger distance than

278
00:09:55,680 --> 00:09:56,560
this

279
00:09:56,560 --> 00:09:58,320
as for the specific experiments we've

280
00:09:58,320 --> 00:10:00,080
used two different phone models two

281
00:10:00,080 --> 00:10:01,920
different radars

282
00:10:01,920 --> 00:10:04,240
we have two different enhancement tasks

283
00:10:04,240 --> 00:10:05,040
and

284
00:10:05,040 --> 00:10:06,959
also two different data sets so just

285
00:10:06,959 --> 00:10:08,959
take a combination of all of them and

286
00:10:08,959 --> 00:10:11,360
the whole experimental suite is based on

287
00:10:11,360 --> 00:10:12,959
you know kind of like a one-to-one

288
00:10:12,959 --> 00:10:14,720
combination of all of these different

289
00:10:14,720 --> 00:10:16,959
things

290
00:10:16,959 --> 00:10:18,399
okay so

291
00:10:18,399 --> 00:10:20,480
i have given the overview of the msi

292
00:10:20,480 --> 00:10:22,399
system so now i would like to talk about

293
00:10:22,399 --> 00:10:24,880
the results

294
00:10:24,880 --> 00:10:27,120
so at first uh just want to talk about

295
00:10:27,120 --> 00:10:29,440
the audio enhancement results so the

296
00:10:29,440 --> 00:10:32,160
first row in this

297
00:10:32,160 --> 00:10:35,279
visual is the raw sensor data

298
00:10:35,279 --> 00:10:37,680
basically it's extremely noisy

299
00:10:37,680 --> 00:10:38,720
we

300
00:10:38,720 --> 00:10:40,560
apply signal processing

301
00:10:40,560 --> 00:10:41,600
and

302
00:10:41,600 --> 00:10:43,839
then we use the enhancement neural

303
00:10:43,839 --> 00:10:46,560
network to form the enhanced signal

304
00:10:46,560 --> 00:10:47,360
and

305
00:10:47,360 --> 00:10:49,600
the good features of these audio are

306
00:10:49,600 --> 00:10:52,320
slowly becoming clearer but then we

307
00:10:52,320 --> 00:10:54,240
combine this with the input signal all

308
00:10:54,240 --> 00:10:55,920
over again which we call the enhanced

309
00:10:55,920 --> 00:10:58,079
plus mask signal and that looks

310
00:10:58,079 --> 00:11:01,279
a lot closer to the true

311
00:11:01,279 --> 00:11:03,760
digits that are being spoken

312
00:11:03,760 --> 00:11:06,720
likewise we applied the same

313
00:11:06,720 --> 00:11:08,640
architecture to a speech command data

314
00:11:08,640 --> 00:11:10,480
set which is by google

315
00:11:10,480 --> 00:11:12,399
and we observe a very similar thing that

316
00:11:12,399 --> 00:11:14,399
we start with very noisy radar data but

317
00:11:14,399 --> 00:11:16,880
as you go down the pipeline

318
00:11:16,880 --> 00:11:19,440
it gets better at every step

319
00:11:19,440 --> 00:11:22,160
so i have a small

320
00:11:22,160 --> 00:11:23,920
sample output

321
00:11:23,920 --> 00:11:28,040
and i'll play that for you

322
00:11:47,600 --> 00:11:50,160
so that was the raw data sorry the raw

323
00:11:50,160 --> 00:11:52,720
data that we capture from the radar and

324
00:11:52,720 --> 00:11:55,440
when we pass it through the enhancement

325
00:11:55,440 --> 00:12:00,040
pipeline this is what we get

326
00:12:04,220 --> 00:12:17,519
[Music]

327
00:12:17,519 --> 00:12:19,279
so that's

328
00:12:19,279 --> 00:12:21,920
an output of the audio enhancement

329
00:12:21,920 --> 00:12:24,560
pipeline and quantitatively

330
00:12:24,560 --> 00:12:27,600
we of course observe a really good

331
00:12:27,600 --> 00:12:29,200
improvement

332
00:12:29,200 --> 00:12:30,399
as the data has passed through the

333
00:12:30,399 --> 00:12:34,320
pipeline so the dotted line on top is

334
00:12:34,320 --> 00:12:36,399
the mean squared error between the true

335
00:12:36,399 --> 00:12:38,320
audio and the raw audio after

336
00:12:38,320 --> 00:12:40,880
normalization and the ones at the bottom

337
00:12:40,880 --> 00:12:42,720
are the two different cases of just

338
00:12:42,720 --> 00:12:44,000
enhancement and enhancement plus

339
00:12:44,000 --> 00:12:47,519
combining with the original sensor data

340
00:12:47,519 --> 00:12:48,880
um

341
00:12:48,880 --> 00:12:50,560
and we see that yeah there is definitely

342
00:12:50,560 --> 00:12:52,240
a quantitative improvement i'll quickly

343
00:12:52,240 --> 00:12:53,519
move over to the results of

344
00:12:53,519 --> 00:12:55,440
classification

345
00:12:55,440 --> 00:12:57,360
we begin by analyzing

346
00:12:57,360 --> 00:13:00,320
how the signal quality deteriorates over

347
00:13:00,320 --> 00:13:02,160
distance

348
00:13:02,160 --> 00:13:02,959
and

349
00:13:02,959 --> 00:13:04,880
naturally as you go further and further

350
00:13:04,880 --> 00:13:06,560
away from the target phone

351
00:13:06,560 --> 00:13:07,360
the

352
00:13:07,360 --> 00:13:10,160
quality of the signal the snr goes on

353
00:13:10,160 --> 00:13:11,519
decreasing

354
00:13:11,519 --> 00:13:14,000
um beyond six feet it's almost

355
00:13:14,000 --> 00:13:16,240
unintelligible but for this study we

356
00:13:16,240 --> 00:13:18,480
just uh you know targeted one two three

357
00:13:18,480 --> 00:13:20,480
all the way to six feet that's a

358
00:13:20,480 --> 00:13:21,920
representation of how the signal

359
00:13:21,920 --> 00:13:24,719
deteriorates

360
00:13:25,040 --> 00:13:26,320
the accuracy

361
00:13:26,320 --> 00:13:28,399
that we observe across different cases

362
00:13:28,399 --> 00:13:30,800
is represented in this table

363
00:13:30,800 --> 00:13:33,600
so the first three rows are

364
00:13:33,600 --> 00:13:36,000
the classification of digits being

365
00:13:36,000 --> 00:13:37,519
spoken

366
00:13:37,519 --> 00:13:38,880
over the phone

367
00:13:38,880 --> 00:13:40,880
with radars at the different frequency

368
00:13:40,880 --> 00:13:43,279
ranges and the last row is the speech

369
00:13:43,279 --> 00:13:44,560
commands

370
00:13:44,560 --> 00:13:47,519
we do observe that in the best case the

371
00:13:47,519 --> 00:13:49,680
accuracy is roughly around 80 percent

372
00:13:49,680 --> 00:13:51,120
which is

373
00:13:51,120 --> 00:13:53,920
quite uh concerning but as we go further

374
00:13:53,920 --> 00:13:57,279
away it really goes on decreasing but

375
00:13:57,279 --> 00:13:58,480
nonetheless

376
00:13:58,480 --> 00:13:59,920
any

377
00:13:59,920 --> 00:14:01,839
any positive accuracy in any of these

378
00:14:01,839 --> 00:14:04,079
tasks is a dangerous thing that's what i

379
00:14:04,079 --> 00:14:05,600
believe

380
00:14:05,600 --> 00:14:07,920
as for the effect of

381
00:14:07,920 --> 00:14:09,600
domain adaptation and transfer learning

382
00:14:09,600 --> 00:14:12,480
here's a representation of

383
00:14:12,480 --> 00:14:14,320
how well the data synthesis pipeline

384
00:14:14,320 --> 00:14:16,480
actually worked so the gray bars are

385
00:14:16,480 --> 00:14:18,000
when we try to

386
00:14:18,000 --> 00:14:20,560
try to train the model directly on radar

387
00:14:20,560 --> 00:14:23,199
data and the black bars are when we use

388
00:14:23,199 --> 00:14:25,279
this synthetic data pipeline and try to

389
00:14:25,279 --> 00:14:27,519
go over everything

390
00:14:27,519 --> 00:14:28,800
here's a

391
00:14:28,800 --> 00:14:31,440
confusion matrix of the audio mnist

392
00:14:31,440 --> 00:14:33,040
test cases and the speech command test

393
00:14:33,040 --> 00:14:34,800
cases and of course

394
00:14:34,800 --> 00:14:36,959
a bright diagonal represents that the

395
00:14:36,959 --> 00:14:40,560
classifiers are working pretty well

396
00:14:40,560 --> 00:14:42,560
now the audio mnist

397
00:14:42,560 --> 00:14:44,959
data set it itself is tagged with user

398
00:14:44,959 --> 00:14:46,880
ids and we do

399
00:14:46,880 --> 00:14:50,160
observe that there's a fair variation in

400
00:14:50,160 --> 00:14:51,839
how well the system performs against

401
00:14:51,839 --> 00:14:53,040
each user

402
00:14:53,040 --> 00:14:56,079
we have not done a detailed analysis in

403
00:14:56,079 --> 00:14:57,680
in this but

404
00:14:57,680 --> 00:14:59,600
broadly there are different people from

405
00:14:59,600 --> 00:15:01,760
different cultures and different accents

406
00:15:01,760 --> 00:15:04,240
and the system responds differently to

407
00:15:04,240 --> 00:15:05,519
all of them and there are ways in which

408
00:15:05,519 --> 00:15:07,600
people handle this

409
00:15:07,600 --> 00:15:09,760
uh one of the comments that we received

410
00:15:09,760 --> 00:15:11,600
uh quite pertinently is

411
00:15:11,600 --> 00:15:13,040
okay you're doing this in a lab setting

412
00:15:13,040 --> 00:15:15,199
so what happens when you

413
00:15:15,199 --> 00:15:17,279
actually make somebody hold the phone

414
00:15:17,279 --> 00:15:19,199
and you try to attack them

415
00:15:19,199 --> 00:15:21,440
so what we observe is

416
00:15:21,440 --> 00:15:23,199
basically that muscular twitches

417
00:15:23,199 --> 00:15:25,120
respiration and all of that can

418
00:15:25,120 --> 00:15:27,519
cause spikes in the radar stream

419
00:15:27,519 --> 00:15:30,240
but underlying all of the large

420
00:15:30,240 --> 00:15:32,320
magnitude noise

421
00:15:32,320 --> 00:15:33,759
there's still some audio preserved and

422
00:15:33,759 --> 00:15:35,519
we've presented these results in the

423
00:15:35,519 --> 00:15:36,800
paper as well

424
00:15:36,800 --> 00:15:38,560
all right so i'm almost at the end of my

425
00:15:38,560 --> 00:15:39,440
talk

426
00:15:39,440 --> 00:15:41,120
and i want to go over some general

427
00:15:41,120 --> 00:15:44,079
challenges in implementing ms pi

428
00:15:44,079 --> 00:15:46,160
that by and large we should

429
00:15:46,160 --> 00:15:48,399
you know to make the whole system robust

430
00:15:48,399 --> 00:15:50,560
and more dangerous we should

431
00:15:50,560 --> 00:15:52,959
uh try to train the model with many more

432
00:15:52,959 --> 00:15:56,240
phones and as a consequence of which you

433
00:15:56,240 --> 00:15:58,399
know try to account for different

434
00:15:58,399 --> 00:16:01,040
materials new age materials that go into

435
00:16:01,040 --> 00:16:04,399
the building of phones we also want to

436
00:16:04,399 --> 00:16:06,560
address motion where someone's actually

437
00:16:06,560 --> 00:16:08,079
moving around with the phone so that's

438
00:16:08,079 --> 00:16:10,639
another step towards practicality and as

439
00:16:10,639 --> 00:16:13,920
for speech and accents just use larger

440
00:16:13,920 --> 00:16:16,079
scale models that

441
00:16:16,079 --> 00:16:17,920
you know go over you know automatic

442
00:16:17,920 --> 00:16:20,480
speech recognition

443
00:16:20,480 --> 00:16:22,320
there are some defenses of course so

444
00:16:22,320 --> 00:16:24,160
firstly uh

445
00:16:24,160 --> 00:16:26,000
it's important to understand that such a

446
00:16:26,000 --> 00:16:29,279
such an attack is possible um

447
00:16:29,279 --> 00:16:32,000
it's also good if we can develop you

448
00:16:32,000 --> 00:16:33,920
know materials that absorb vibrations

449
00:16:33,920 --> 00:16:36,560
instead of actually you know allowing

450
00:16:36,560 --> 00:16:38,639
them to permeate through the solid and

451
00:16:38,639 --> 00:16:41,920
one good defense is if the speakers

452
00:16:41,920 --> 00:16:45,839
within your phone um can be beam forming

453
00:16:45,839 --> 00:16:46,800
so

454
00:16:46,800 --> 00:16:49,040
it directs all of the vibrations away

455
00:16:49,040 --> 00:16:50,800
from the back of the phone

456
00:16:50,800 --> 00:16:51,920
all right

457
00:16:51,920 --> 00:16:55,839
so future work is

458
00:16:55,839 --> 00:16:57,759
to basically address all the limitations

459
00:16:57,759 --> 00:16:59,360
in a nutshell

460
00:16:59,360 --> 00:17:00,959
we're going to try to address the speech

461
00:17:00,959 --> 00:17:02,560
recognition part of it as well as the

462
00:17:02,560 --> 00:17:05,199
motion and

463
00:17:05,199 --> 00:17:06,880
more broadly

464
00:17:06,880 --> 00:17:09,679
we have developed a framework that helps

465
00:17:09,679 --> 00:17:12,079
us extract audio from radars so with

466
00:17:12,079 --> 00:17:14,240
that i conclude

467
00:17:14,240 --> 00:17:17,280
and i'm at the end of my presentation

468
00:17:17,280 --> 00:17:19,679
all right let's thank our speaker

469
00:17:19,679 --> 00:17:21,280
again if you have questions please

470
00:17:21,280 --> 00:17:23,280
approach the microphone and identify

471
00:17:23,280 --> 00:17:25,119
yourself and where you're from while

472
00:17:25,119 --> 00:17:27,679
we're waiting for that um i have a

473
00:17:27,679 --> 00:17:28,960
question for you

474
00:17:28,960 --> 00:17:31,120
um myself and many of the people here

475
00:17:31,120 --> 00:17:32,480
have uh

476
00:17:32,480 --> 00:17:33,600
you know

477
00:17:33,600 --> 00:17:36,240
some kind of a plastic or rubber

478
00:17:36,240 --> 00:17:38,480
protector on our phone um not because

479
00:17:38,480 --> 00:17:41,039
i'm clumsy but because this does drop

480
00:17:41,039 --> 00:17:43,280
that would seem to be a

481
00:17:43,280 --> 00:17:45,039
pretty good defense already right i mean

482
00:17:45,039 --> 00:17:46,640
this doesn't seem to propagate the

483
00:17:46,640 --> 00:17:48,480
signal can you talk about that yeah so

484
00:17:48,480 --> 00:17:49,679
um

485
00:17:49,679 --> 00:17:51,280
i haven't done a large scale experiment

486
00:17:51,280 --> 00:17:53,039
on this but that was something that i

487
00:17:53,039 --> 00:17:57,039
was really interested in as well and

488
00:17:57,200 --> 00:17:58,720
my phone's not in my pocket but even i

489
00:17:58,720 --> 00:18:00,480
have a really big piece at the back of

490
00:18:00,480 --> 00:18:01,919
it it doesn't make as much of a

491
00:18:01,919 --> 00:18:03,679
difference as you would think

492
00:18:03,679 --> 00:18:05,039
it doesn't make as much of a difference

493
00:18:05,039 --> 00:18:07,200
no because the vibrations

494
00:18:07,200 --> 00:18:08,640
for the defense for the defense aspect

495
00:18:08,640 --> 00:18:10,960
of it it doesn't so the vibrations can

496
00:18:10,960 --> 00:18:12,799
still pass through

497
00:18:12,799 --> 00:18:14,880
like modern materials that are being

498
00:18:14,880 --> 00:18:16,400
used as

499
00:18:16,400 --> 00:18:17,600
phone cases

500
00:18:17,600 --> 00:18:19,600
you have experiments for that i don't

501
00:18:19,600 --> 00:18:21,840
have large scale experiments and i don't

502
00:18:21,840 --> 00:18:23,679
have results on the paper but i had done

503
00:18:23,679 --> 00:18:25,679
like a smaller scale experiment

504
00:18:25,679 --> 00:18:26,880
to do that all right so there was a

505
00:18:26,880 --> 00:18:29,039
batch of data that i collected that

506
00:18:29,039 --> 00:18:31,200
you know in exactly this setting but

507
00:18:31,200 --> 00:18:34,799
we didn't pursue it okay um yeah thanks

508
00:18:34,799 --> 00:18:37,600
please go ahead yeah

509
00:18:37,600 --> 00:18:40,799
so my name is efren lopez from texas a m

510
00:18:40,799 --> 00:18:43,280
corpus christi so just it's a like a

511
00:18:43,280 --> 00:18:45,600
quick question so first of all a great

512
00:18:45,600 --> 00:18:47,919
paper a great presentation

513
00:18:47,919 --> 00:18:49,840
so if i understood correctly this is

514
00:18:49,840 --> 00:18:52,320
you're getting the audio that is

515
00:18:52,320 --> 00:18:54,320
that the user is listening to in the

516
00:18:54,320 --> 00:18:57,200
phone right yeah yeah so that would be

517
00:18:57,200 --> 00:19:00,080
different from let's say if you

518
00:19:00,080 --> 00:19:02,480
if you have a microphone

519
00:19:02,480 --> 00:19:03,520
like it's

520
00:19:03,520 --> 00:19:05,360
this is much uh

521
00:19:05,360 --> 00:19:07,760
like this is a much better wave way of

522
00:19:07,760 --> 00:19:09,520
spine than just having a microphone next

523
00:19:09,520 --> 00:19:10,480
to the

524
00:19:10,480 --> 00:19:13,280
to the person okay i think that's a

525
00:19:13,280 --> 00:19:16,160
really good point that you've brought up

526
00:19:16,160 --> 00:19:18,880
uh and we do elaborate uh this on the

527
00:19:18,880 --> 00:19:19,840
paper

528
00:19:19,840 --> 00:19:21,919
which is the fact that radars work on a

529
00:19:21,919 --> 00:19:25,760
point-to-point source uh isolation basis

530
00:19:25,760 --> 00:19:27,440
whereas microphone picks up all of the

531
00:19:27,440 --> 00:19:29,200
signals in the environment

532
00:19:29,200 --> 00:19:30,080
so

533
00:19:30,080 --> 00:19:33,039
the defense if you have a microphone

534
00:19:33,039 --> 00:19:35,200
to do this sort of a thing is just clear

535
00:19:35,200 --> 00:19:37,280
really loud noise in the environment

536
00:19:37,280 --> 00:19:39,200
however when you do

537
00:19:39,200 --> 00:19:41,120
that as like a primary defense against

538
00:19:41,120 --> 00:19:43,679
an attack like mm spike it doesn't work

539
00:19:43,679 --> 00:19:45,200
because it's like getting right at the

540
00:19:45,200 --> 00:19:47,360
source at one point picking up the

541
00:19:47,360 --> 00:19:49,039
vibrations right there

542
00:19:49,039 --> 00:19:51,120
does that does that make sense yes yeah

543
00:19:51,120 --> 00:19:52,880
that answers my question yeah thank you

544
00:19:52,880 --> 00:19:53,840
for the question that was a good

545
00:19:53,840 --> 00:19:56,159
question

546
00:19:56,880 --> 00:19:57,840
just because if you want to go ahead and

547
00:19:57,840 --> 00:19:59,679
start setting up any more questions one

548
00:19:59,679 --> 00:20:00,960
more

549
00:20:00,960 --> 00:20:03,039
i will start taking my life

550
00:20:03,039 --> 00:20:05,200
go ahead it's very great parking it's

551
00:20:05,200 --> 00:20:07,520
amazing that the earpiece speaker

552
00:20:07,520 --> 00:20:09,760
vibration can be captured

553
00:20:09,760 --> 00:20:12,000
so i have a question about because

554
00:20:12,000 --> 00:20:14,640
your type model you require the user to

555
00:20:14,640 --> 00:20:16,159
hold the phone the victim to hold the

556
00:20:16,159 --> 00:20:18,400
phone otherwise i think

557
00:20:18,400 --> 00:20:19,919
we can use other techniques like a

558
00:20:19,919 --> 00:20:22,240
hidden microphone or wi-fi to

559
00:20:22,240 --> 00:20:24,320
capture the vibration because the user

560
00:20:24,320 --> 00:20:26,480
hold the phone to talk so there are a

561
00:20:26,480 --> 00:20:28,640
speaker sound and the user sound that

562
00:20:28,640 --> 00:20:30,320
the user sound would

563
00:20:30,320 --> 00:20:32,240
impact your

564
00:20:32,240 --> 00:20:34,480
influence accuracy okay

565
00:20:34,480 --> 00:20:35,520
so

566
00:20:35,520 --> 00:20:37,280
this is actually very similar to the

567
00:20:37,280 --> 00:20:39,520
previous question and the answer to that

568
00:20:39,520 --> 00:20:42,159
is no not really because

569
00:20:42,159 --> 00:20:43,360
um

570
00:20:43,360 --> 00:20:45,520
the real reason is that yes your phone

571
00:20:45,520 --> 00:20:47,520
earpieces are that small

572
00:20:47,520 --> 00:20:48,400
and they're

573
00:20:48,400 --> 00:20:50,400
directly connected to all of the solids

574
00:20:50,400 --> 00:20:52,799
inside of the phone they are not damped

575
00:20:52,799 --> 00:20:55,280
properly uh like you know larger micro

576
00:20:55,280 --> 00:20:57,679
like sorry larger speakers so when

577
00:20:57,679 --> 00:20:59,039
something is playing it's like your

578
00:20:59,039 --> 00:21:01,360
whole phone vibrates up and you can try

579
00:21:01,360 --> 00:21:02,960
and isolate that signal whereas if

580
00:21:02,960 --> 00:21:05,679
you're using a microphone it is you know

581
00:21:05,679 --> 00:21:07,280
once again going to catch everything in

582
00:21:07,280 --> 00:21:10,159
the environment that is being said like

583
00:21:10,159 --> 00:21:12,400
you could talk or maybe play a

584
00:21:12,400 --> 00:21:14,880
loud sound in the background and

585
00:21:14,880 --> 00:21:16,720
that that kind of defeats the microphone

586
00:21:16,720 --> 00:21:17,440
yeah

587
00:21:17,440 --> 00:21:19,679
so the reader must point the right to

588
00:21:19,679 --> 00:21:22,640
the the earpiece microphone uh yeah too

589
00:21:22,640 --> 00:21:25,120
so i'm sorry we have ps speaker yeah

590
00:21:25,120 --> 00:21:27,600
okay thank you thank you all right let's

591
00:21:27,600 --> 00:21:30,799
thank our speaker one more time

