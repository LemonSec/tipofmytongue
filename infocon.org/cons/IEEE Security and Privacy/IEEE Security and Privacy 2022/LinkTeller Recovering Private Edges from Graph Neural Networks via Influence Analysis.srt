1
00:00:01,280 --> 00:00:02,159
um

2
00:00:02,159 --> 00:00:04,880
okay hello everyone um thank you for

3
00:00:04,880 --> 00:00:08,400
coming today i'm van a phd candidate at

4
00:00:08,400 --> 00:00:11,200
uiuc today i'm going to present our work

5
00:00:11,200 --> 00:00:13,440
link teller a privacy attack on graph

6
00:00:13,440 --> 00:00:15,360
neural networks

7
00:00:15,360 --> 00:00:18,240
our work is inspired by a real world uh

8
00:00:18,240 --> 00:00:20,320
industrial example which we observed in

9
00:00:20,320 --> 00:00:23,279
an international i.t company so this

10
00:00:23,279 --> 00:00:25,359
company similar to others is consisted

11
00:00:25,359 --> 00:00:27,439
of multiple teams the product teams the

12
00:00:27,439 --> 00:00:29,599
advertising team and the information

13
00:00:29,599 --> 00:00:31,359
security team

14
00:00:31,359 --> 00:00:32,479
different teams have different

15
00:00:32,479 --> 00:00:34,399
functionalities and they hold different

16
00:00:34,399 --> 00:00:36,239
information the product team

17
00:00:36,239 --> 00:00:39,040
specifically holds the user information

18
00:00:39,040 --> 00:00:41,920
in their in indel each product which can

19
00:00:41,920 --> 00:00:44,559
be viewed as the features of the users

20
00:00:44,559 --> 00:00:46,960
the advertising team holds the user

21
00:00:46,960 --> 00:00:49,360
network essentially which user is

22
00:00:49,360 --> 00:00:51,920
connected to which other user

23
00:00:51,920 --> 00:00:54,399
and one role of the information security

24
00:00:54,399 --> 00:00:57,680
team is to regulate the information flow

25
00:00:57,680 --> 00:00:58,399
between

26
00:00:58,399 --> 00:01:00,800
the different teams in their company

27
00:01:00,800 --> 00:01:03,120
here we would emphasize that

28
00:01:03,120 --> 00:01:05,519
in their company though like the user

29
00:01:05,519 --> 00:01:07,439
network among the entire company is

30
00:01:07,439 --> 00:01:09,680
treated as the confidential information

31
00:01:09,680 --> 00:01:12,320
it is not publicly accessible and cannot

32
00:01:12,320 --> 00:01:14,720
be obtained by any other team in their

33
00:01:14,720 --> 00:01:16,080
company

34
00:01:16,080 --> 00:01:18,880
but from the one from from the viewpoint

35
00:01:18,880 --> 00:01:21,200
of the product team it is beneficial to

36
00:01:21,200 --> 00:01:23,280
incorporate the user network into their

37
00:01:23,280 --> 00:01:25,600
machine learning models so how can the

38
00:01:25,600 --> 00:01:27,439
product team possibly

39
00:01:27,439 --> 00:01:28,960
incorporate

40
00:01:28,960 --> 00:01:31,280
the user network

41
00:01:31,280 --> 00:01:32,880
we already know that the user network

42
00:01:32,880 --> 00:01:34,640
cannot be leaked outside of the

43
00:01:34,640 --> 00:01:37,280
advertising team we also know that it is

44
00:01:37,280 --> 00:01:39,439
fun to exchange the user information

45
00:01:39,439 --> 00:01:42,159
among the teams so the so the solution

46
00:01:42,159 --> 00:01:43,840
in their company is that they build a

47
00:01:43,840 --> 00:01:46,000
local model at the advertising team

48
00:01:46,000 --> 00:01:47,920
which is trained with the with both

49
00:01:47,920 --> 00:01:49,360
teams information

50
00:01:49,360 --> 00:01:52,560
and then they release the trained api

51
00:01:52,560 --> 00:01:54,960
when the product team queries the api

52
00:01:54,960 --> 00:01:56,880
with the input of a set of users of

53
00:01:56,880 --> 00:01:59,119
their own product the api will return

54
00:01:59,119 --> 00:02:01,920
the corresponding predictions and same

55
00:02:01,920 --> 00:02:03,600
for product b

56
00:02:03,600 --> 00:02:06,159
actually the local model is open to any

57
00:02:06,159 --> 00:02:08,639
team that submits queries with any set

58
00:02:08,639 --> 00:02:10,720
of users

59
00:02:10,720 --> 00:02:13,120
uh here we provide an abstraction of the

60
00:02:13,120 --> 00:02:15,599
of the of the example we just show what

61
00:02:15,599 --> 00:02:17,840
we consider is actually the vertically

62
00:02:17,840 --> 00:02:20,239
partitioned graph where different parts

63
00:02:20,239 --> 00:02:22,080
of the graph belong to different data

64
00:02:22,080 --> 00:02:23,200
holders

65
00:02:23,200 --> 00:02:25,599
let alice be the advertising team that

66
00:02:25,599 --> 00:02:28,239
holds the user network and bob be the

67
00:02:28,239 --> 00:02:29,840
product team that holds the user

68
00:02:29,840 --> 00:02:32,319
information at the first communication

69
00:02:32,319 --> 00:02:33,760
stage bob would send the user

70
00:02:33,760 --> 00:02:36,000
information represented as node features

71
00:02:36,000 --> 00:02:37,920
and labels to alice

72
00:02:37,920 --> 00:02:40,160
then alice uses the node information

73
00:02:40,160 --> 00:02:42,560
received from bob as well as her own

74
00:02:42,560 --> 00:02:44,640
edge information to train a graph neural

75
00:02:44,640 --> 00:02:47,040
network after the model is trained alice

76
00:02:47,040 --> 00:02:49,200
releases the api

77
00:02:49,200 --> 00:02:51,200
finally in the inference stage bob or

78
00:02:51,200 --> 00:02:53,440
any other user can query the api with

79
00:02:53,440 --> 00:02:56,640
any possible set of nodes

80
00:02:56,640 --> 00:02:58,080
against this background we are

81
00:02:58,080 --> 00:03:00,319
particularly concerned with the risks of

82
00:03:00,319 --> 00:03:01,840
edge privacy

83
00:03:01,840 --> 00:03:04,239
even though the solution is designed to

84
00:03:04,239 --> 00:03:06,720
protect the address from being leaked

85
00:03:06,720 --> 00:03:09,360
how effective is this solution will the

86
00:03:09,360 --> 00:03:11,280
inference api still leak the private

87
00:03:11,280 --> 00:03:12,480
edges

88
00:03:12,480 --> 00:03:14,400
second we wonder whether the risks can

89
00:03:14,400 --> 00:03:17,360
be ameliorated if there does exist

90
00:03:17,360 --> 00:03:20,640
concerns of edge privacy

91
00:03:20,640 --> 00:03:22,640
let me first provide a quick recap of

92
00:03:22,640 --> 00:03:25,280
the related work and the preliminaries

93
00:03:25,280 --> 00:03:27,519
graph neural networks are widely used in

94
00:03:27,519 --> 00:03:30,319
semi-supervised node classification it

95
00:03:30,319 --> 00:03:33,040
takes input represented by nodes and

96
00:03:33,040 --> 00:03:35,760
edges and output predictions for nodes

97
00:03:35,760 --> 00:03:37,760
and graph convolutional network is one

98
00:03:37,760 --> 00:03:39,760
specific type of graph neural network

99
00:03:39,760 --> 00:03:41,920
that uses the graph convolutional

100
00:03:41,920 --> 00:03:44,480
operator as the aggregator

101
00:03:44,480 --> 00:03:46,239
in the literature there are mainly three

102
00:03:46,239 --> 00:03:48,640
types of privacy attacks on grass they

103
00:03:48,640 --> 00:03:51,280
target at different components here our

104
00:03:51,280 --> 00:03:53,360
focus is the link re-identification

105
00:03:53,360 --> 00:03:55,840
attack that targets the edges

106
00:03:55,840 --> 00:03:57,840
there are a few works in the pre-graph

107
00:03:57,840 --> 00:04:00,799
neural network era that uses either the

108
00:04:00,799 --> 00:04:02,959
probabilistic models or explore the

109
00:04:02,959 --> 00:04:04,959
local graph features

110
00:04:04,959 --> 00:04:06,959
but after the graph neural networks came

111
00:04:06,959 --> 00:04:09,200
into play there are a lot of adversarial

112
00:04:09,200 --> 00:04:12,159
attacks on graphs but not many privacy

113
00:04:12,159 --> 00:04:13,280
attacks

114
00:04:13,280 --> 00:04:15,599
the existing works either operate on the

115
00:04:15,599 --> 00:04:17,759
node embedding level or require very

116
00:04:17,759 --> 00:04:20,720
strong prior knowledge on the

117
00:04:20,720 --> 00:04:22,160
attacker's knowledge and their

118
00:04:22,160 --> 00:04:23,520
assumptions

119
00:04:23,520 --> 00:04:25,440
so our challenge here is to design

120
00:04:25,440 --> 00:04:27,600
attacks on black box graph neural

121
00:04:27,600 --> 00:04:30,639
network apis with minimal assumption on

122
00:04:30,639 --> 00:04:33,440
attacker's knowledge

123
00:04:33,440 --> 00:04:35,440
here is an overview of our work we

124
00:04:35,440 --> 00:04:37,199
proposed linktellow the archery

125
00:04:37,199 --> 00:04:39,280
identification attack against the black

126
00:04:39,280 --> 00:04:41,840
box graph neural networks it is a query

127
00:04:41,840 --> 00:04:43,919
based attack and the attack idea is

128
00:04:43,919 --> 00:04:46,160
inspired by the influence propagation in

129
00:04:46,160 --> 00:04:47,759
the network

130
00:04:47,759 --> 00:04:50,560
next to see how effective our attack is

131
00:04:50,560 --> 00:04:52,240
we consider a counter-measure of the

132
00:04:52,240 --> 00:04:54,240
attack by incorporating differential

133
00:04:54,240 --> 00:04:56,880
privacy into our model we introduce our

134
00:04:56,880 --> 00:04:59,680
algorithm and provide the analysis

135
00:04:59,680 --> 00:05:02,000
last but not least we conduct extensive

136
00:05:02,000 --> 00:05:03,919
experiments to evaluate our proposed

137
00:05:03,919 --> 00:05:06,240
methods

138
00:05:06,240 --> 00:05:08,320
let's start with the linkteller part

139
00:05:08,320 --> 00:05:10,080
here is the formal introduction model we

140
00:05:10,080 --> 00:05:12,960
consider alice receives node information

141
00:05:12,960 --> 00:05:14,720
and then trains the model using both

142
00:05:14,720 --> 00:05:17,520
nodes and edges the release api is open

143
00:05:17,520 --> 00:05:20,320
to query after bob queries the api on

144
00:05:20,320 --> 00:05:22,720
the set of interested nodes and obtains

145
00:05:22,720 --> 00:05:24,800
the corresponding predictions he

146
00:05:24,800 --> 00:05:26,800
launches the linktellow attack which

147
00:05:26,800 --> 00:05:29,919
reveals the edges in the graph

148
00:05:29,919 --> 00:05:31,840
we consider only the elementary

149
00:05:31,840 --> 00:05:34,639
knowledge and capability of the attacker

150
00:05:34,639 --> 00:05:36,720
we only require query access to the

151
00:05:36,720 --> 00:05:39,840
blackbox api during inference time and

152
00:05:39,840 --> 00:05:42,000
we do not assume any knowledge of either

153
00:05:42,000 --> 00:05:44,320
the partial graph or the shadow datasets

154
00:05:44,320 --> 00:05:48,000
as in the baseline lsa attack

155
00:05:48,000 --> 00:05:50,479
the attacker's goal is to recover the

156
00:05:50,479 --> 00:05:52,960
connections among the inference node

157
00:05:52,960 --> 00:05:54,880
that he has interest in

158
00:05:54,880 --> 00:05:57,360
and the means is to query the api and

159
00:05:57,360 --> 00:05:59,280
perform some magic on the written

160
00:05:59,280 --> 00:06:02,000
predictions

161
00:06:02,160 --> 00:06:04,639
so how can we perform the magic let me

162
00:06:04,639 --> 00:06:07,039
picture the intuition of the attack

163
00:06:07,039 --> 00:06:09,120
we already know that the graph structure

164
00:06:09,120 --> 00:06:10,720
plays an important role in the graph

165
00:06:10,720 --> 00:06:13,039
neural networks in each layer of the

166
00:06:13,039 --> 00:06:15,280
network the information propagates from

167
00:06:15,280 --> 00:06:17,680
each node to its adjacent nodes along

168
00:06:17,680 --> 00:06:19,039
the edges

169
00:06:19,039 --> 00:06:21,280
let's take one example of here for the

170
00:06:21,280 --> 00:06:23,120
blue node in the first layer its

171
00:06:23,120 --> 00:06:25,280
information will flow along the orange

172
00:06:25,280 --> 00:06:27,520
arrows and in the second layer the

173
00:06:27,520 --> 00:06:30,479
information will flow along the orange

174
00:06:30,479 --> 00:06:33,360
arrows so we can see that the connection

175
00:06:33,360 --> 00:06:35,440
in the graph determine whether the

176
00:06:35,440 --> 00:06:37,440
information of one node can influence

177
00:06:37,440 --> 00:06:40,080
the other and how strong the influence

178
00:06:40,080 --> 00:06:41,360
will be

179
00:06:41,360 --> 00:06:44,240
therefore if we can somehow compute the

180
00:06:44,240 --> 00:06:46,800
influence value of one node on the other

181
00:06:46,800 --> 00:06:48,880
we will be able to tell whether there

182
00:06:48,880 --> 00:06:51,680
exists an edge

183
00:06:51,680 --> 00:06:53,520
here comes our algorithm

184
00:06:53,520 --> 00:06:55,680
first we calculate the pairwise

185
00:06:55,680 --> 00:06:58,639
influence values among all node panels

186
00:06:58,639 --> 00:07:00,960
then for the pulse with the values above

187
00:07:00,960 --> 00:07:02,960
certain thresholds we predict them as

188
00:07:02,960 --> 00:07:04,240
edges

189
00:07:04,240 --> 00:07:07,360
so now our question is how do we exactly

190
00:07:07,360 --> 00:07:10,560
compute this influence value

191
00:07:10,560 --> 00:07:12,800
we concretely present the steps to

192
00:07:12,800 --> 00:07:15,120
compute the influence values here our

193
00:07:15,120 --> 00:07:17,680
approach shows some flavor of finite

194
00:07:17,680 --> 00:07:19,680
difference analysis or the perturbation

195
00:07:19,680 --> 00:07:21,440
based analysis

196
00:07:21,440 --> 00:07:23,680
for the inference node set vi with the

197
00:07:23,680 --> 00:07:26,080
original node features x lets the

198
00:07:26,080 --> 00:07:28,800
current consider node bv we perturb its

199
00:07:28,800 --> 00:07:31,199
features by upweighting it by an

200
00:07:31,199 --> 00:07:33,440
infinitesimal amount of value

201
00:07:33,440 --> 00:07:36,240
then we invoke the api twice for the two

202
00:07:36,240 --> 00:07:38,479
different node feature matrix to obtain

203
00:07:38,479 --> 00:07:40,639
two different predictive prediction

204
00:07:40,639 --> 00:07:42,240
matrix

205
00:07:42,240 --> 00:07:44,639
by taking the difference between the two

206
00:07:44,639 --> 00:07:47,280
we obtain the influence matrix and then

207
00:07:47,280 --> 00:07:49,599
the row norms of the matrix are exactly

208
00:07:49,599 --> 00:07:51,759
the influence value between the node v

209
00:07:51,759 --> 00:07:54,800
and all other nodes

210
00:07:54,800 --> 00:07:57,120
the influence value we obtained actually

211
00:07:57,120 --> 00:07:59,680
comes with several nice properties here

212
00:07:59,680 --> 00:08:01,520
we present a case study on graph

213
00:08:01,520 --> 00:08:04,000
convolutional network

214
00:08:04,000 --> 00:08:06,319
first we have the conclusion that in one

215
00:08:06,319 --> 00:08:08,479
layer graph convolutional network

216
00:08:08,479 --> 00:08:10,000
whenever the pair of nodes are

217
00:08:10,000 --> 00:08:12,400
unconnected the influence value will be

218
00:08:12,400 --> 00:08:13,599
zero

219
00:08:13,599 --> 00:08:15,360
furthermore on k layer graph

220
00:08:15,360 --> 00:08:17,840
convolutional network whenever two nodes

221
00:08:17,840 --> 00:08:20,400
are at least k plus one halves away the

222
00:08:20,400 --> 00:08:23,120
influence value will be zero so these

223
00:08:23,120 --> 00:08:25,120
two conclusions they serve as a

224
00:08:25,120 --> 00:08:27,840
complement to our intuition and they

225
00:08:27,840 --> 00:08:31,440
better support our algorithm

226
00:08:31,919 --> 00:08:33,839
now we can move on to the second part

227
00:08:33,839 --> 00:08:36,000
where we aim to further investigate the

228
00:08:36,000 --> 00:08:39,279
effectiveness of linktella by studying a

229
00:08:39,279 --> 00:08:42,399
potential counter measure of it

230
00:08:42,399 --> 00:08:44,560
since we want to protect the edges we

231
00:08:44,560 --> 00:08:46,720
consider the notion of edge differential

232
00:08:46,720 --> 00:08:49,360
privacy which guarantees that by looking

233
00:08:49,360 --> 00:08:51,839
at the dp algorithm output we cannot

234
00:08:51,839 --> 00:08:53,519
tell which one is the input to the

235
00:08:53,519 --> 00:08:56,320
algorithm the left or the right

236
00:08:56,320 --> 00:08:58,800
here the parameter epsilon quantifies

237
00:08:58,800 --> 00:09:01,360
how rigorous the guarantee is we can

238
00:09:01,360 --> 00:09:02,800
view it by

239
00:09:02,800 --> 00:09:05,519
how much privacy is leaked

240
00:09:05,519 --> 00:09:07,600
thus smaller epsilon implies stronger

241
00:09:07,600 --> 00:09:09,440
privacy

242
00:09:09,440 --> 00:09:11,440
to enforce hdp in the graph

243
00:09:11,440 --> 00:09:13,440
convolutional network we propose the

244
00:09:13,440 --> 00:09:15,519
following framework based on input

245
00:09:15,519 --> 00:09:18,160
perturbation so during training we first

246
00:09:18,160 --> 00:09:19,760
perturbed the original training graph

247
00:09:19,760 --> 00:09:22,560
via adp scheme and epsilon then we

248
00:09:22,560 --> 00:09:24,160
perform standard training on the per

249
00:09:24,160 --> 00:09:27,279
turbograf and release the api

250
00:09:27,279 --> 00:09:29,360
during influence during inference we

251
00:09:29,360 --> 00:09:31,680
apply the same perturbation scheme and

252
00:09:31,680 --> 00:09:33,760
invoke the api with this

253
00:09:33,760 --> 00:09:35,680
perturbed inference graph

254
00:09:35,680 --> 00:09:38,399
we note that all proceed all processes

255
00:09:38,399 --> 00:09:41,120
here including the perturbing training

256
00:09:41,120 --> 00:09:42,880
inference they are all performed at the

257
00:09:42,880 --> 00:09:44,320
local center

258
00:09:44,320 --> 00:09:46,640
and they are transparent to the api

259
00:09:46,640 --> 00:09:47,600
caller

260
00:09:47,600 --> 00:09:49,519
the final predictions after all these

261
00:09:49,519 --> 00:09:50,800
operations are

262
00:09:50,800 --> 00:09:53,519
returned to the api caller

263
00:09:53,519 --> 00:09:55,839
particularly we designed the dp scheme

264
00:09:55,839 --> 00:09:58,600
such that it guarantees the

265
00:09:58,600 --> 00:10:00,720
indistinguishability between the perturb

266
00:10:00,720 --> 00:10:03,440
graph and the original graph we proposed

267
00:10:03,440 --> 00:10:06,079
two algorithms that achieve the goal

268
00:10:06,079 --> 00:10:08,959
adjunct that performs value flipping and

269
00:10:08,959 --> 00:10:11,360
lap graph that adds the application

270
00:10:11,360 --> 00:10:12,480
noise

271
00:10:12,480 --> 00:10:15,680
we additionally provide analysis

272
00:10:15,680 --> 00:10:17,839
on the privacy as well as the upper

273
00:10:17,839 --> 00:10:19,680
bound analysis for any link

274
00:10:19,680 --> 00:10:22,320
reidentification attack against our dp

275
00:10:22,320 --> 00:10:24,160
graph convolutional network

276
00:10:24,160 --> 00:10:26,240
more details can be found in our paper

277
00:10:26,240 --> 00:10:28,880
due to the time limit

278
00:10:28,880 --> 00:10:32,000
finally we come to the evaluation part

279
00:10:32,000 --> 00:10:33,839
first of all we evaluate the

280
00:10:33,839 --> 00:10:36,399
effectiveness of our link teller

281
00:10:36,399 --> 00:10:38,800
we experiment with eight data sets in

282
00:10:38,800 --> 00:10:40,880
both the inductive and transductive

283
00:10:40,880 --> 00:10:43,120
setting we test the two layers and three

284
00:10:43,120 --> 00:10:45,279
layers graph convolutional networks and

285
00:10:45,279 --> 00:10:46,959
gits

286
00:10:46,959 --> 00:10:48,640
we follow the literature to train the

287
00:10:48,640 --> 00:10:50,480
networks and evaluate the performance of

288
00:10:50,480 --> 00:10:52,399
the network via the f1 score of the

289
00:10:52,399 --> 00:10:54,320
classification

290
00:10:54,320 --> 00:10:57,120
to evaluate the attack we use the matrix

291
00:10:57,120 --> 00:11:00,640
precision record f1 score and auc scores

292
00:11:00,640 --> 00:11:03,279
we compare with two baseline attacks we

293
00:11:03,279 --> 00:11:05,920
specifically construct several scenarios

294
00:11:05,920 --> 00:11:08,000
so that we can evaluate different

295
00:11:08,000 --> 00:11:10,160
density beliefs against the nodes of

296
00:11:10,160 --> 00:11:13,360
different degree distributions

297
00:11:13,360 --> 00:11:15,440
here are the results for one data set

298
00:11:15,440 --> 00:11:16,880
among all eight

299
00:11:16,880 --> 00:11:19,120
we can see that for all scenarios link

300
00:11:19,120 --> 00:11:20,959
teller invariably outperformed the

301
00:11:20,959 --> 00:11:22,800
baselines

302
00:11:22,800 --> 00:11:24,800
next we evaluate linktellow against the

303
00:11:24,800 --> 00:11:26,480
countermeasure of the dp graph

304
00:11:26,480 --> 00:11:28,880
convolutional network apart from the

305
00:11:28,880 --> 00:11:31,519
same setup as previous we additionally

306
00:11:31,519 --> 00:11:34,000
evaluate two dp schemes and 10 privacy

307
00:11:34,000 --> 00:11:35,839
budgets

308
00:11:35,839 --> 00:11:38,160
here we plot the change of f1 score of

309
00:11:38,160 --> 00:11:40,160
the attack with the privacy budget

310
00:11:40,160 --> 00:11:41,279
epsilon

311
00:11:41,279 --> 00:11:43,440
lower values means less successful

312
00:11:43,440 --> 00:11:44,720
attacks

313
00:11:44,720 --> 00:11:46,880
we see that dp can significantly

314
00:11:46,880 --> 00:11:49,440
decrease the attack effectiveness

315
00:11:49,440 --> 00:11:51,839
yet when the privacy budget is high the

316
00:11:51,839 --> 00:11:53,680
prediction is

317
00:11:53,680 --> 00:11:57,200
i mean the protection is quite limited

318
00:11:57,200 --> 00:11:59,920
specifically we discovered that dp can

319
00:11:59,920 --> 00:12:01,680
offer better prediction for the low

320
00:12:01,680 --> 00:12:03,120
degree nodes which are shown in the

321
00:12:03,120 --> 00:12:05,360
first row here

322
00:12:05,360 --> 00:12:07,279
in the end we analyze the trade-off

323
00:12:07,279 --> 00:12:09,760
between model utility and privacy the

324
00:12:09,760 --> 00:12:11,680
left figure shows the model utility

325
00:12:11,680 --> 00:12:14,240
while higher value means higher utility

326
00:12:14,240 --> 00:12:16,079
the right one shows the privacy where

327
00:12:16,079 --> 00:12:18,639
lower value means better privacy we see

328
00:12:18,639 --> 00:12:20,639
that models with higher utility are more

329
00:12:20,639 --> 00:12:23,519
vulnerable to our linkteller attack

330
00:12:23,519 --> 00:12:25,760
furthermore we note that the comparison

331
00:12:25,760 --> 00:12:28,000
can offer some insights on how we can

332
00:12:28,000 --> 00:12:30,720
find the sweet spot

333
00:12:30,720 --> 00:12:32,720
in the end let me show this slide again

334
00:12:32,720 --> 00:12:35,200
as a summary we propose linktellow to

335
00:12:35,200 --> 00:12:37,279
review the edge privacy risks in the

336
00:12:37,279 --> 00:12:38,880
existing system

337
00:12:38,880 --> 00:12:41,360
we also propose countermeasures of the

338
00:12:41,360 --> 00:12:44,480
attack our extensive evaluation shows

339
00:12:44,480 --> 00:12:46,800
the effectiveness of the attack and

340
00:12:46,800 --> 00:12:49,839
provide insights for the practitioners

341
00:12:49,839 --> 00:12:51,760
that's all thank you for listening and

342
00:12:51,760 --> 00:12:54,960
i'm happy to take any questions

343
00:12:54,960 --> 00:13:00,269
[Applause]

344
00:13:00,399 --> 00:13:03,600
so we have municipal questions so

345
00:13:03,600 --> 00:13:05,360
please walk to the mic and

346
00:13:05,360 --> 00:13:08,399
state name affiliation

347
00:13:09,279 --> 00:13:11,040
i can start probably for with a couple

348
00:13:11,040 --> 00:13:12,480
of questions and

349
00:13:12,480 --> 00:13:13,760
um

350
00:13:13,760 --> 00:13:16,160
do you see any difference with the

351
00:13:16,160 --> 00:13:17,600
graph neural network aggregation

352
00:13:17,600 --> 00:13:22,160
operation um and if that influenced the

353
00:13:22,160 --> 00:13:23,920
um

354
00:13:23,920 --> 00:13:26,880
your attack at the end of the day

355
00:13:26,880 --> 00:13:29,600
uh yeah so your question is uh for

356
00:13:29,600 --> 00:13:31,360
different architectures like graphic

357
00:13:31,360 --> 00:13:32,959
convolutional network

358
00:13:32,959 --> 00:13:36,800
uh the graph attention network uh

359
00:13:36,800 --> 00:13:39,519
so our study is mainly inspired by the

360
00:13:39,519 --> 00:13:41,279
intuition on the graph convolutional

361
00:13:41,279 --> 00:13:44,639
network and we also uh we also tested

362
00:13:44,639 --> 00:13:46,880
tested on the graph attention network

363
00:13:46,880 --> 00:13:49,519
since the like the intuition of the of

364
00:13:49,519 --> 00:13:51,519
the information propagation along the

365
00:13:51,519 --> 00:13:54,240
graph along the graph is shelled and we

366
00:13:54,240 --> 00:13:57,440
see that in the g80s actually our attack

367
00:13:57,440 --> 00:14:00,480
is also like it is also successful but

368
00:14:00,480 --> 00:14:03,680
not as uh as as successful as on the

369
00:14:03,680 --> 00:14:05,680
graph convolutional network and we have

370
00:14:05,680 --> 00:14:08,240
several oh we we have several

371
00:14:08,240 --> 00:14:10,160
explanations for that and more details

372
00:14:10,160 --> 00:14:12,000
can be found in our paper

373
00:14:12,000 --> 00:14:14,880
okay thank you

374
00:14:15,680 --> 00:14:17,839
just a long time and i have another

375
00:14:17,839 --> 00:14:18,720
question

376
00:14:18,720 --> 00:14:20,480
i'm just checking another time sorry

377
00:14:20,480 --> 00:14:22,639
um so my other question is so you

378
00:14:22,639 --> 00:14:23,920
presented

379
00:14:23,920 --> 00:14:27,519
many experiments on the performance

380
00:14:27,519 --> 00:14:31,360
of the differential privacy gcn

381
00:14:31,360 --> 00:14:32,399
but if

382
00:14:32,399 --> 00:14:34,000
it was very quick the light was very

383
00:14:34,000 --> 00:14:36,880
quick so um performance were

384
00:14:36,880 --> 00:14:38,000
a little bit all over the place like you

385
00:14:38,000 --> 00:14:39,839
know the f1 score was a little bit all

386
00:14:39,839 --> 00:14:41,199
over the place and

387
00:14:41,199 --> 00:14:43,600
i was wondering how much uh training a

388
00:14:43,600 --> 00:14:46,399
differential privacy gcn affect the

389
00:14:46,399 --> 00:14:48,800
performance of the model on clean data

390
00:14:48,800 --> 00:14:51,440
so without the attack is it still usable

391
00:14:51,440 --> 00:14:54,639
oh um um okay okay i got the problem uh

392
00:14:54,639 --> 00:14:56,720
maybe i can like

393
00:14:56,720 --> 00:14:59,519
quickly show that results if the

394
00:14:59,519 --> 00:15:01,760
uh if the projection is still enabled

395
00:15:01,760 --> 00:15:04,560
yeah uh yeah so here uh for the left

396
00:15:04,560 --> 00:15:06,560
figure we show the model utility which

397
00:15:06,560 --> 00:15:08,560
is exactly the performance on the on the

398
00:15:08,560 --> 00:15:10,880
clean data as you mentioned and on the

399
00:15:10,880 --> 00:15:12,399
right hand side it is the attack

400
00:15:12,399 --> 00:15:15,199
effectiveness uh so um

401
00:15:15,199 --> 00:15:17,199
the left hand on the left-hand side is

402
00:15:17,199 --> 00:15:18,000
the

403
00:15:18,000 --> 00:15:20,399
the x-axis is the uh

404
00:15:20,399 --> 00:15:23,199
it's the privacy budget epsilon and we

405
00:15:23,199 --> 00:15:26,399
show that like uh

406
00:15:26,399 --> 00:15:29,120
when for for example in the twitch ru

407
00:15:29,120 --> 00:15:31,519
data uh when the privacy budget is

408
00:15:31,519 --> 00:15:34,160
around five or six it is still very

409
00:15:34,160 --> 00:15:36,480
usable with with like

410
00:15:36,480 --> 00:15:39,839
with a reasonable like utility here

411
00:15:39,839 --> 00:15:41,920
right does that answer a question uh

412
00:15:41,920 --> 00:15:44,720
yeah yeah that answers my question yeah

413
00:15:44,720 --> 00:15:46,720
okay

414
00:15:46,720 --> 00:15:47,600
so

415
00:15:47,600 --> 00:15:49,519
if there are no other questions and i

416
00:15:49,519 --> 00:15:51,120
believe that we don't have any questions

417
00:15:51,120 --> 00:15:53,360
from online but let me just double check

418
00:15:53,360 --> 00:15:55,839
very quickly

419
00:16:02,240 --> 00:16:05,120
no doesn't look like so we can

420
00:16:05,120 --> 00:16:06,639
thank our speaker once again thank you

421
00:16:06,639 --> 00:16:08,090
okay thank you

422
00:16:08,090 --> 00:16:11,210
[Applause]

