1
00:00:01,199 --> 00:00:02,480
hello everyone

2
00:00:02,480 --> 00:00:04,319
welcome to the presentation

3
00:00:04,319 --> 00:00:06,879
paper title deep steel advan advanced

4
00:00:06,879 --> 00:00:08,880
model extraction leveraging efficient

5
00:00:08,880 --> 00:00:11,120
weight stealing in memories this is a

6
00:00:11,120 --> 00:00:12,880
work produced in collaboration between

7
00:00:12,880 --> 00:00:14,880
arizona state university and university

8
00:00:14,880 --> 00:00:16,960
of central florida my name is adnan

9
00:00:16,960 --> 00:00:18,800
shiaz rakin and my co-author hafizul

10
00:00:18,800 --> 00:00:20,960
will present this work to you

11
00:00:20,960 --> 00:00:22,480
before going into the details of the

12
00:00:22,480 --> 00:00:24,160
work let me first introduce the

13
00:00:24,160 --> 00:00:26,320
background informations

14
00:00:26,320 --> 00:00:27,920
machine learning is extremely popular in

15
00:00:27,920 --> 00:00:29,840
different applications such as robotics

16
00:00:29,840 --> 00:00:31,599
medical applications and self-driving

17
00:00:31,599 --> 00:00:32,800
car as well

18
00:00:32,800 --> 00:00:34,399
machine learning as a cloud service is

19
00:00:34,399 --> 00:00:36,320
gaining popularity in the forms on

20
00:00:36,320 --> 00:00:39,360
amazon aws ai google ai and microsoft

21
00:00:39,360 --> 00:00:40,719
azure aml

22
00:00:40,719 --> 00:00:43,280
in such cloud service the vendor trains

23
00:00:43,280 --> 00:00:46,559
large model which has potential ip

24
00:00:46,559 --> 00:00:49,440
values and lends it to the customer who

25
00:00:49,440 --> 00:00:51,760
can use those models with certain remote

26
00:00:51,760 --> 00:00:54,559
privileges such remote access

27
00:00:54,559 --> 00:00:56,160
give rise to different kinds of

28
00:00:56,160 --> 00:00:58,960
adversarial threat models we broadly

29
00:00:58,960 --> 00:01:01,199
classify those trade models into two

30
00:01:01,199 --> 00:01:03,280
major categories the first one is the

31
00:01:03,280 --> 00:01:05,360
model tampering attack where the

32
00:01:05,360 --> 00:01:07,840
attacker actually tampers the inputs

33
00:01:07,840 --> 00:01:10,159
weights or sometimes both popularly

34
00:01:10,159 --> 00:01:12,400
known as trojan or bacteria attack in

35
00:01:12,400 --> 00:01:14,320
the other class the attacker tries to

36
00:01:14,320 --> 00:01:16,240
steal secret data or feature

37
00:01:16,240 --> 00:01:17,840
informations

38
00:01:17,840 --> 00:01:19,680
our concern is the third one which is

39
00:01:19,680 --> 00:01:21,439
the model extraction attack where the

40
00:01:21,439 --> 00:01:23,280
article looks to recover modern

41
00:01:23,280 --> 00:01:26,320
architecture or weight information

42
00:01:26,320 --> 00:01:27,920
so what is the objective of a model

43
00:01:27,920 --> 00:01:30,079
extraction attack in a model extraction

44
00:01:30,079 --> 00:01:31,920
attack the attacker tries to create a

45
00:01:31,920 --> 00:01:34,159
substitute model which has similar

46
00:01:34,159 --> 00:01:36,640
accuracy and high fidelity as the target

47
00:01:36,640 --> 00:01:39,040
model potentially that substituted model

48
00:01:39,040 --> 00:01:41,840
can be later used to attack the target

49
00:01:41,840 --> 00:01:45,759
victim model using adversarial samples

50
00:01:45,759 --> 00:01:47,759
in a tangent line of work remote side

51
00:01:47,759 --> 00:01:49,439
channel attack is also popular in

52
00:01:49,439 --> 00:01:51,360
cryptographic application to leak

53
00:01:51,360 --> 00:01:54,000
certain key informations those attacks

54
00:01:54,000 --> 00:01:56,399
have also been deployed on ml models as

55
00:01:56,399 --> 00:01:58,960
well in ml models the focus of those

56
00:01:58,960 --> 00:02:01,200
attacks were to recover the architecture

57
00:02:01,200 --> 00:02:03,680
information such as number of layers

58
00:02:03,680 --> 00:02:05,759
number of connections

59
00:02:05,759 --> 00:02:08,160
this gives us two real opportunities the

60
00:02:08,160 --> 00:02:10,318
first one is none of the existing side

61
00:02:10,318 --> 00:02:12,160
channel attacks actually successfully

62
00:02:12,160 --> 00:02:14,239
recovered the fine-grained weight

63
00:02:14,239 --> 00:02:16,480
information the second one is

64
00:02:16,480 --> 00:02:18,560
exfiltration of weight information can

65
00:02:18,560 --> 00:02:20,640
potentially be even more dangerous than

66
00:02:20,640 --> 00:02:22,560
architecture only recovery because that

67
00:02:22,560 --> 00:02:24,400
makes the attack more towards the white

68
00:02:24,400 --> 00:02:26,640
box

69
00:02:26,640 --> 00:02:28,400
so that's why we post two key questions

70
00:02:28,400 --> 00:02:30,640
in this world first is can we recover

71
00:02:30,640 --> 00:02:32,560
fine grain weight information through

72
00:02:32,560 --> 00:02:34,959
remote side channel on top of that deep

73
00:02:34,959 --> 00:02:36,480
learning models have millions of

74
00:02:36,480 --> 00:02:39,840
parameters and those parameters can be

75
00:02:39,840 --> 00:02:42,160
practically impossible to recover all of

76
00:02:42,160 --> 00:02:44,000
them that's why we ask the second

77
00:02:44,000 --> 00:02:46,080
question is how to utilize those trade

78
00:02:46,080 --> 00:02:48,800
information to perform an adverse model

79
00:02:48,800 --> 00:02:51,680
extraction from now on i let half visual

80
00:02:51,680 --> 00:02:54,239
to take over

81
00:02:57,200 --> 00:02:58,560
thank you adnan for the great

82
00:02:58,560 --> 00:03:00,239
introduction

83
00:03:00,239 --> 00:03:02,080
before moving forward let me first

84
00:03:02,080 --> 00:03:04,000
briefly discuss about our threat model

85
00:03:04,000 --> 00:03:05,680
and the scope of data

86
00:03:05,680 --> 00:03:07,519
we assume the case where the victim is

87
00:03:07,519 --> 00:03:09,280
running inference is

88
00:03:09,280 --> 00:03:11,519
using a dnn model in the same machine as

89
00:03:11,519 --> 00:03:13,599
the attacker this is the typical case

90
00:03:13,599 --> 00:03:15,440
for remote environment where multiple

91
00:03:15,440 --> 00:03:17,200
tenants actually share the same physical

92
00:03:17,200 --> 00:03:19,040
hardware resources

93
00:03:19,040 --> 00:03:21,519
we also assumed the case where that the

94
00:03:21,519 --> 00:03:23,360
attacker knows the victim dna model

95
00:03:23,360 --> 00:03:24,640
architecture

96
00:03:24,640 --> 00:03:26,799
however the attacker does not know any

97
00:03:26,799 --> 00:03:28,319
other information such as model

98
00:03:28,319 --> 00:03:30,560
parameter information and it cannot

99
00:03:30,560 --> 00:03:32,640
directly query the target model for

100
00:03:32,640 --> 00:03:36,000
google fi a phone plan

101
00:03:37,920 --> 00:03:40,480
okay uh moving on

102
00:03:40,480 --> 00:03:42,159
now now we discuss about our attack

103
00:03:42,159 --> 00:03:44,480
framework which you called dp still here

104
00:03:44,480 --> 00:03:46,080
is a brief overview of our attack

105
00:03:46,080 --> 00:03:47,120
framework

106
00:03:47,120 --> 00:03:49,040
in a higher level our attack has two

107
00:03:49,040 --> 00:03:51,840
major components the first step is a

108
00:03:51,840 --> 00:03:53,680
system level exploit in which we

109
00:03:53,680 --> 00:03:55,599
partially recover model weight

110
00:03:55,599 --> 00:03:57,599
informations we call this spark hammer

111
00:03:57,599 --> 00:03:58,640
only

112
00:03:58,640 --> 00:04:00,879
then based on this recovered weight we

113
00:04:00,879 --> 00:04:02,879
perform mean clustering based

114
00:04:02,879 --> 00:04:04,959
approximation of the weights which we

115
00:04:04,959 --> 00:04:07,840
apply called mean clustering training

116
00:04:07,840 --> 00:04:10,239
as a brief example assume the attacker's

117
00:04:10,239 --> 00:04:12,799
goal is to recover the weight w1 from

118
00:04:12,799 --> 00:04:15,680
this victim model initially the attacker

119
00:04:15,680 --> 00:04:17,279
has no information

120
00:04:17,279 --> 00:04:19,680
about this weight w1

121
00:04:19,680 --> 00:04:21,440
hammer lick is still in

122
00:04:21,440 --> 00:04:23,360
as many bits as possible from this

123
00:04:23,360 --> 00:04:24,639
weight using hydrohammer based

124
00:04:24,639 --> 00:04:26,560
information leakage attack

125
00:04:26,560 --> 00:04:28,080
then mean clustering training is

126
00:04:28,080 --> 00:04:30,000
performed on the other bits to

127
00:04:30,000 --> 00:04:31,680
approximate the remaining bit

128
00:04:31,680 --> 00:04:33,520
information of this weight and then

129
00:04:33,520 --> 00:04:37,280
train a substitute model based on that

130
00:04:37,440 --> 00:04:39,680
so first let's dive further into the

131
00:04:39,680 --> 00:04:41,840
details of our hammer leak attack

132
00:04:41,840 --> 00:04:44,080
in essence our goal in hammer lick is to

133
00:04:44,080 --> 00:04:46,000
locate and recover model weights from

134
00:04:46,000 --> 00:04:48,240
memory

135
00:04:48,240 --> 00:04:50,320
here is a brief overview of raw hammer

136
00:04:50,320 --> 00:04:52,000
before moving further

137
00:04:52,000 --> 00:04:54,080
rowhammer has been historically used as

138
00:04:54,080 --> 00:04:56,479
a fault injection vector where the goal

139
00:04:56,479 --> 00:05:00,560
is to inject bit flips into victim data

140
00:05:00,560 --> 00:05:03,199
this shows that if you place the victim

141
00:05:03,199 --> 00:05:05,360
into a target row with a vulnerable cell

142
00:05:05,360 --> 00:05:07,120
and repeatedly access the adjacent two

143
00:05:07,120 --> 00:05:09,280
rows then over time enough charge will

144
00:05:09,280 --> 00:05:11,120
leak from the victim cell

145
00:05:11,120 --> 00:05:13,360
that it flips the data from zero to one

146
00:05:13,360 --> 00:05:14,800
or one to zero

147
00:05:14,800 --> 00:05:16,960
one important property of this that the

148
00:05:16,960 --> 00:05:20,080
bit flips are data dependent

149
00:05:20,080 --> 00:05:22,160
specifically if the bits stored in the

150
00:05:22,160 --> 00:05:24,160
two aggressor rows are the opposite of

151
00:05:24,160 --> 00:05:26,240
the bits in the vulnerable cell we see

152
00:05:26,240 --> 00:05:28,960
very high probability of bit flips

153
00:05:28,960 --> 00:05:31,440
for other data patterns such as this bit

154
00:05:31,440 --> 00:05:34,880
flips are highly unlikely

155
00:05:35,520 --> 00:05:37,360
based on these characteristics we can

156
00:05:37,360 --> 00:05:39,520
potentially steal victim secret speeds

157
00:05:39,520 --> 00:05:41,919
instead of faulting them just by placing

158
00:05:41,919 --> 00:05:44,479
them into the aggressor row

159
00:05:44,479 --> 00:05:46,080
then by observing bit flips in the

160
00:05:46,080 --> 00:05:47,759
attacker's data in the target row the

161
00:05:47,759 --> 00:05:49,520
victim data can be leaked

162
00:05:49,520 --> 00:05:51,840
this changes the row hammer based attack

163
00:05:51,840 --> 00:05:53,840
vector from fault injection vector to

164
00:05:53,840 --> 00:05:56,080
data stealing vector prior work in

165
00:05:56,080 --> 00:05:57,919
ramblit is the first one to demonstrate

166
00:05:57,919 --> 00:05:59,680
this exploit distilled cryptographic

167
00:05:59,680 --> 00:06:02,720
secret from memory

168
00:06:02,720 --> 00:06:04,880
however there are some constraint in the

169
00:06:04,880 --> 00:06:06,479
current form of the attack which may

170
00:06:06,479 --> 00:06:08,479
potentially prevent it from

171
00:06:08,479 --> 00:06:10,800
applying it to large

172
00:06:10,800 --> 00:06:12,800
victim applications such as dna model

173
00:06:12,800 --> 00:06:13,919
inference

174
00:06:13,919 --> 00:06:16,240
for example uh they require a special

175
00:06:16,240 --> 00:06:18,639
property in victim application in memory

176
00:06:18,639 --> 00:06:20,479
duplication which might not be generic

177
00:06:20,479 --> 00:06:22,639
enough this poses the first challenge is

178
00:06:22,639 --> 00:06:25,120
how we can perform a genetic row hammer

179
00:06:25,120 --> 00:06:26,479
based information leakage without

180
00:06:26,479 --> 00:06:28,080
relying on specific victim

181
00:06:28,080 --> 00:06:29,759
characteristics

182
00:06:29,759 --> 00:06:30,960
furthermore

183
00:06:30,960 --> 00:06:33,280
prior work only shows uh recovery of

184
00:06:33,280 --> 00:06:35,520
cryptographic key up to hundreds of bits

185
00:06:35,520 --> 00:06:38,240
but dnn models typically range from

186
00:06:38,240 --> 00:06:40,800
millions of parameters and

187
00:06:40,800 --> 00:06:43,759
applicability of this type of exploit in

188
00:06:43,759 --> 00:06:46,080
the large scale victim models is still

189
00:06:46,080 --> 00:06:48,160
unknown to us

190
00:06:48,160 --> 00:06:49,919
this rises our second challenge is how

191
00:06:49,919 --> 00:06:51,440
can we apply raw hammer based

192
00:06:51,440 --> 00:06:53,599
information leakage to recover secrets

193
00:06:53,599 --> 00:06:57,120
from bulk victim application

194
00:06:57,199 --> 00:06:59,280
so before moving forward let let me

195
00:06:59,280 --> 00:07:01,199
first address the first challenge and

196
00:07:01,199 --> 00:07:02,800
present you a generic row hammer-based

197
00:07:02,800 --> 00:07:04,720
data stealing without relying on any

198
00:07:04,720 --> 00:07:05,840
specific

199
00:07:05,840 --> 00:07:06,880
victim

200
00:07:06,880 --> 00:07:08,479
application behavior

201
00:07:08,479 --> 00:07:10,319
here the victim as usual is placed in

202
00:07:10,319 --> 00:07:12,560
only one of the aggressor rows and then

203
00:07:12,560 --> 00:07:14,319
the attacker occupies the target row and

204
00:07:14,319 --> 00:07:16,560
other requester row and presets them

205
00:07:16,560 --> 00:07:18,800
using alternating data pattern

206
00:07:18,800 --> 00:07:21,039
after hammering based on the existence

207
00:07:21,039 --> 00:07:25,599
of bit flip victim secrets can be leaked

208
00:07:25,599 --> 00:07:26,960
this technique can be applied by

209
00:07:26,960 --> 00:07:28,639
observing bit flips in either direction

210
00:07:28,639 --> 00:07:32,000
from 0 to 1 or 1 to 0.

211
00:07:32,000 --> 00:07:33,840
now that we have our generic row

212
00:07:33,840 --> 00:07:35,759
hammering technique to steal information

213
00:07:35,759 --> 00:07:38,319
from v9 victim application how can we

214
00:07:38,319 --> 00:07:39,840
systematically recover memory

215
00:07:39,840 --> 00:07:42,319
information from a large victim

216
00:07:42,319 --> 00:07:45,039
initially before the hemalic exploit the

217
00:07:45,039 --> 00:07:47,280
victim may occupy these pages in memory

218
00:07:47,280 --> 00:07:49,440
which might not be exploitable

219
00:07:49,440 --> 00:07:51,840
since most of these typical victim pages

220
00:07:51,840 --> 00:07:53,360
belonging to dnn

221
00:07:53,360 --> 00:07:56,639
inference services are anonymous page we

222
00:07:56,639 --> 00:07:58,479
cannot relocate them using the

223
00:07:58,479 --> 00:08:00,240
duplication as the attacker does not

224
00:08:00,240 --> 00:08:02,639
know the content of the page

225
00:08:02,639 --> 00:08:04,960
to potentially message this page

226
00:08:04,960 --> 00:08:07,840
into leakable locations we need to evict

227
00:08:07,840 --> 00:08:09,919
this page first from the memory we

228
00:08:09,919 --> 00:08:12,560
propose to use memory swapping for this

229
00:08:12,560 --> 00:08:14,240
after this stage the attacker should

230
00:08:14,240 --> 00:08:15,759
occupy most of the memory while the

231
00:08:15,759 --> 00:08:17,440
victim pages should be swapped out to

232
00:08:17,440 --> 00:08:20,000
the swap space

233
00:08:20,000 --> 00:08:22,000
in the second step the attacker's goal

234
00:08:22,000 --> 00:08:24,080
is to systematically release pages for

235
00:08:24,080 --> 00:08:26,800
the victim to relocate into based on a

236
00:08:26,800 --> 00:08:28,720
pre-existing bit flip profile the

237
00:08:28,720 --> 00:08:30,800
attacker first chooses potential

238
00:08:30,800 --> 00:08:33,279
leakable pages and then releases them in

239
00:08:33,279 --> 00:08:35,360
a specific order to populate a parkour

240
00:08:35,360 --> 00:08:38,000
structure called bestselled so paste set

241
00:08:38,000 --> 00:08:40,240
is a lost in firsthand structure and

242
00:08:40,240 --> 00:08:41,760
this recently

243
00:08:41,760 --> 00:08:43,839
freed pages populate the pset structure

244
00:08:43,839 --> 00:08:45,760
which might which will be potentially

245
00:08:45,760 --> 00:08:47,760
used by the victim application later to

246
00:08:47,760 --> 00:08:50,560
relocating to

247
00:08:51,680 --> 00:08:53,760
in the third step the attacker's goal is

248
00:08:53,760 --> 00:08:55,760
to precisely allocate the victim pages

249
00:08:55,760 --> 00:08:59,040
to the recently freed desired locations

250
00:08:59,040 --> 00:09:01,200
when the victim accesses the pages from

251
00:09:01,200 --> 00:09:03,360
the swap region the operating system

252
00:09:03,360 --> 00:09:05,360
places them into free locations from the

253
00:09:05,360 --> 00:09:08,560
page set in the lost in first out manner

254
00:09:08,560 --> 00:09:10,160
based on the order of the victim page

255
00:09:10,160 --> 00:09:12,320
access the attacker can precisely locate

256
00:09:12,320 --> 00:09:14,080
them later on because he has populated

257
00:09:14,080 --> 00:09:16,560
the page set earlier

258
00:09:16,560 --> 00:09:18,399
finally the attacker performs generic

259
00:09:18,399 --> 00:09:20,160
rowhammer-based bit stealing to recover

260
00:09:20,160 --> 00:09:23,760
victim's charts page by page

261
00:09:23,760 --> 00:09:26,320
the hammerlike technique can be applied

262
00:09:26,320 --> 00:09:28,320
if that the attacker can precisely

263
00:09:28,320 --> 00:09:30,000
release pages before the victim

264
00:09:30,000 --> 00:09:32,399
execution occupies a small amount of

265
00:09:32,399 --> 00:09:34,800
page but how do we guarantee it for

266
00:09:34,800 --> 00:09:37,040
large victim applications and still keep

267
00:09:37,040 --> 00:09:39,519
high accuracy of relocation

268
00:09:39,519 --> 00:09:40,720
we propose

269
00:09:40,720 --> 00:09:43,120
sorry we propose best page release to

270
00:09:43,120 --> 00:09:45,360
break down the victim application access

271
00:09:45,360 --> 00:09:46,959
to smaller pieces

272
00:09:46,959 --> 00:09:48,560
and if we can guarantee the correct

273
00:09:48,560 --> 00:09:50,720
allocation for each of the smaller batch

274
00:09:50,720 --> 00:09:52,320
then we can guarantee the accuracy for

275
00:09:52,320 --> 00:09:55,120
the entire victim memory space

276
00:09:55,120 --> 00:09:56,880
we use cash-based anchor points to

277
00:09:56,880 --> 00:09:59,200
monitor small parts of victim execution

278
00:09:59,200 --> 00:10:01,120
and when the victim execution reaches to

279
00:10:01,120 --> 00:10:03,600
a specific region of interest we release

280
00:10:03,600 --> 00:10:05,680
the attacker releases page accordingly

281
00:10:05,680 --> 00:10:08,000
to a predeterministic manner

282
00:10:08,000 --> 00:10:09,839
using this method we can effectively

283
00:10:09,839 --> 00:10:11,839
relocate large victim applications and

284
00:10:11,839 --> 00:10:12,800
perform

285
00:10:12,800 --> 00:10:14,399
bulk data stealing using the generic

286
00:10:14,399 --> 00:10:16,720
rohamer technique

287
00:10:16,720 --> 00:10:19,040
here is an example of how hammerlick

288
00:10:19,040 --> 00:10:21,040
exploit is integrated with the pythos to

289
00:10:21,040 --> 00:10:22,800
leak dna model weights

290
00:10:22,800 --> 00:10:24,480
the attacker first sets up multiple

291
00:10:24,480 --> 00:10:26,399
anchor points in the pythos library to

292
00:10:26,399 --> 00:10:28,399
monitor the victim execution stages

293
00:10:28,399 --> 00:10:30,079
using this model

294
00:10:30,079 --> 00:10:31,760
these anchors are triggered when the

295
00:10:31,760 --> 00:10:33,600
victim starts execution of different

296
00:10:33,600 --> 00:10:36,240
layers and then within the each layer of

297
00:10:36,240 --> 00:10:39,040
execution multiple macron cores is

298
00:10:39,040 --> 00:10:42,000
triggered to further divide

299
00:10:42,000 --> 00:10:44,160
one layer in execution into several

300
00:10:44,160 --> 00:10:47,200
smaller batches based on which anchors

301
00:10:47,200 --> 00:10:49,200
are triggered the attacker releases

302
00:10:49,200 --> 00:10:50,959
predeterministic number of vulnerable

303
00:10:50,959 --> 00:10:53,279
pages for the weights to locate and

304
00:10:53,279 --> 00:10:55,519
non-vulnerable pages for the other data

305
00:10:55,519 --> 00:10:57,360
such as input and

306
00:10:57,360 --> 00:10:59,680
feature maps to locating to this way the

307
00:10:59,680 --> 00:11:01,519
attacker can place all the victim weight

308
00:11:01,519 --> 00:11:04,320
pages in desired location and then steal

309
00:11:04,320 --> 00:11:06,560
weight bits afterwards

310
00:11:06,560 --> 00:11:08,240
with that i now request my colleague to

311
00:11:08,240 --> 00:11:09,680
go into the details of our training

312
00:11:09,680 --> 00:11:11,519
algorithm

313
00:11:11,519 --> 00:11:13,040
yeah now that we have this powerful

314
00:11:13,040 --> 00:11:14,959
attack to leak the victim's secret

315
00:11:14,959 --> 00:11:16,720
weight information the next challenge we

316
00:11:16,720 --> 00:11:18,720
have is how to utilize this partial

317
00:11:18,720 --> 00:11:21,040
information the solution that we propose

318
00:11:21,040 --> 00:11:22,959
is a training algorithm to utilize this

319
00:11:22,959 --> 00:11:24,320
partial information and train a

320
00:11:24,320 --> 00:11:26,079
substitute model

321
00:11:26,079 --> 00:11:27,519
basically intuitively you could

322
00:11:27,519 --> 00:11:30,320
understand if you take the weight wt and

323
00:11:30,320 --> 00:11:32,240
leak its most significant bit you could

324
00:11:32,240 --> 00:11:34,320
project the range of that of the weight

325
00:11:34,320 --> 00:11:37,200
of wt in this way if you leak further

326
00:11:37,200 --> 00:11:39,600
bits starting from the msp you could

327
00:11:39,600 --> 00:11:41,760
even project the range of wt even

328
00:11:41,760 --> 00:11:44,320
narrower range and by leaking more and

329
00:11:44,320 --> 00:11:46,079
more bits we could project the range of

330
00:11:46,079 --> 00:11:48,560
wt into a more narrow range in this way

331
00:11:48,560 --> 00:11:50,240
after a hammer leak attack we will have

332
00:11:50,240 --> 00:11:53,440
a projected range for all the weights

333
00:11:53,440 --> 00:11:55,040
using that projected range we could

334
00:11:55,040 --> 00:11:57,200
compute a projected mean for all the

335
00:11:57,200 --> 00:11:58,639
weights

336
00:11:58,639 --> 00:12:00,639
using that mean we basically apply a

337
00:12:00,639 --> 00:12:02,320
mean clustering training penalty during

338
00:12:02,320 --> 00:12:04,399
the algorithm you could see the purpose

339
00:12:04,399 --> 00:12:06,480
of that clustering penalty algorithm is

340
00:12:06,480 --> 00:12:07,680
to make sure

341
00:12:07,680 --> 00:12:10,399
all the weights converge near the mean

342
00:12:10,399 --> 00:12:13,600
of the projected range

343
00:12:13,600 --> 00:12:15,120
so for mean clustering training we could

344
00:12:15,120 --> 00:12:17,279
have three possible scenarios for weight

345
00:12:17,279 --> 00:12:19,600
set one we recovered all the eight bits

346
00:12:19,600 --> 00:12:21,839
we just do not apply any training for

347
00:12:21,839 --> 00:12:23,839
that weights at one for weight set two

348
00:12:23,839 --> 00:12:25,680
we have partial bit recover starting

349
00:12:25,680 --> 00:12:27,519
from msb we apply the clustering

350
00:12:27,519 --> 00:12:30,079
training for weight z there was no bits

351
00:12:30,079 --> 00:12:31,440
recovered so we train them in a

352
00:12:31,440 --> 00:12:34,160
traditional cross-entropy fashion

353
00:12:34,160 --> 00:12:35,760
for experimental setup we basically

354
00:12:35,760 --> 00:12:37,200
performed the experiment on popular

355
00:12:37,200 --> 00:12:39,680
vision data sets

356
00:12:39,680 --> 00:12:41,440
for evolution metrics we report the

357
00:12:41,440 --> 00:12:43,600
accuracy of the substitute model and

358
00:12:43,600 --> 00:12:46,079
also report the fidelity of the

359
00:12:46,079 --> 00:12:47,839
substituted model which basically shows

360
00:12:47,839 --> 00:12:49,680
how close the decision boundaries are

361
00:12:49,680 --> 00:12:51,680
between the substitute and target model

362
00:12:51,680 --> 00:12:53,200
and we also report the adversarial

363
00:12:53,200 --> 00:12:55,200
accuracy using the substituted model

364
00:12:55,200 --> 00:12:57,920
transfer to the target model

365
00:12:57,920 --> 00:12:59,600
in terms of results of hammer leak

366
00:12:59,600 --> 00:13:01,279
hammer leak is extremely successful

367
00:13:01,279 --> 00:13:03,200
attack with 95 percent

368
00:13:03,200 --> 00:13:06,160
accuracy and it is pretty stable uh with

369
00:13:06,160 --> 00:13:09,040
a standard deviation of 0.74 using more

370
00:13:09,040 --> 00:13:10,800
rounds of hammer leak we could recover

371
00:13:10,800 --> 00:13:13,200
more and more weight bit information you

372
00:13:13,200 --> 00:13:15,120
could look here with 4 000 rounds of

373
00:13:15,120 --> 00:13:17,120
attack we could recover almost 90

374
00:13:17,120 --> 00:13:19,360
percent of the accuracy across all

375
00:13:19,360 --> 00:13:20,959
layers of the

376
00:13:20,959 --> 00:13:24,079
resonant 18 model

377
00:13:24,079 --> 00:13:25,680
in terms of mean clustering training

378
00:13:25,680 --> 00:13:27,360
performance with increasing rounds of

379
00:13:27,360 --> 00:13:29,920
attack the accuracy keeps improving for

380
00:13:29,920 --> 00:13:31,680
the substituted model as well as the

381
00:13:31,680 --> 00:13:34,160
fidelity and the adversarial attack

382
00:13:34,160 --> 00:13:36,399
performance moves closer towards the

383
00:13:36,399 --> 00:13:38,079
white box attack performance which is

384
00:13:38,079 --> 00:13:40,720
quite intuitive because we recover more

385
00:13:40,720 --> 00:13:42,399
and more bit information with more

386
00:13:42,399 --> 00:13:43,839
rounds

387
00:13:43,839 --> 00:13:46,000
in terms of comparison we mainly compare

388
00:13:46,000 --> 00:13:47,839
with the existing remote side channel

389
00:13:47,839 --> 00:13:49,839
attack which uses

390
00:13:49,839 --> 00:13:51,519
which uses the strategy of recovering

391
00:13:51,519 --> 00:13:53,920
the architectural information with this

392
00:13:53,920 --> 00:13:55,519
additional information of the weight

393
00:13:55,519 --> 00:13:57,519
beats we could improve the accuracy of

394
00:13:57,519 --> 00:14:00,560
the substituted model by 18

395
00:14:00,560 --> 00:14:02,399
and as you already mentioned we have

396
00:14:02,399 --> 00:14:04,399
more information compared to a black box

397
00:14:04,399 --> 00:14:06,560
case our attack performance is more

398
00:14:06,560 --> 00:14:10,239
closer to the white box performance

399
00:14:10,480 --> 00:14:11,760
in summary

400
00:14:11,760 --> 00:14:13,680
uh deep steel with exploitation of the

401
00:14:13,680 --> 00:14:15,279
remote side channel for the first time

402
00:14:15,279 --> 00:14:17,199
can exploit a fine grain weight

403
00:14:17,199 --> 00:14:20,160
information in bulk from dnn and it can

404
00:14:20,160 --> 00:14:22,079
recover the substituted model accuracy

405
00:14:22,079 --> 00:14:24,160
and fidelity up to 90

406
00:14:24,160 --> 00:14:26,160
and the adversarial samples generated by

407
00:14:26,160 --> 00:14:28,000
our substituted model is more closer

408
00:14:28,000 --> 00:14:29,600
towards the performance of a white box

409
00:14:29,600 --> 00:14:31,680
attack and our proposed attack just

410
00:14:31,680 --> 00:14:33,839
opens a new door for practical model

411
00:14:33,839 --> 00:14:36,480
recovery and open store for future

412
00:14:36,480 --> 00:14:38,399
defensive solutions

413
00:14:38,399 --> 00:14:40,560
thank you so much i will now take

414
00:14:40,560 --> 00:14:43,560
questions

415
00:14:47,120 --> 00:14:49,519
thank you adnan and fizzo um any

416
00:14:49,519 --> 00:14:51,839
questions please come up to the mic yeah

417
00:14:51,839 --> 00:14:54,079
and uh yeah just introduce yourself as

418
00:14:54,079 --> 00:14:56,160
well oh you're running away i read

419
00:14:56,160 --> 00:14:58,240
someone else to ask first but anyway

420
00:14:58,240 --> 00:15:00,000
marathon titular universe of texas

421
00:15:00,000 --> 00:15:02,560
dallas my question is that if the model

422
00:15:02,560 --> 00:15:05,120
is run also using some part of its gpu

423
00:15:05,120 --> 00:15:07,199
so do you assume it's only

424
00:15:07,199 --> 00:15:10,160
cpu based model or if you run with a gpu

425
00:15:10,160 --> 00:15:12,320
what will be the result look like uh so

426
00:15:12,320 --> 00:15:14,720
we assume that the inference is done in

427
00:15:14,720 --> 00:15:16,959
uh in the cpu because uh we assume that

428
00:15:16,959 --> 00:15:18,800
the attacker sets up cash anchoring

429
00:15:18,800 --> 00:15:20,800
points to monitor the execution using

430
00:15:20,800 --> 00:15:22,079
cpu

431
00:15:22,079 --> 00:15:25,040
but in future we may actually try to

432
00:15:25,040 --> 00:15:28,720
extend our attack to feature like a

433
00:15:28,720 --> 00:15:30,639
support gpu based inference as well

434
00:15:30,639 --> 00:15:31,839
because the weight information will

435
00:15:31,839 --> 00:15:33,600
actually be stored in the

436
00:15:33,600 --> 00:15:35,600
main memory of the system regardless of

437
00:15:35,600 --> 00:15:38,399
its running into the cpu or gpu okay

438
00:15:38,399 --> 00:15:41,440
follow-up if if the model is run using

439
00:15:41,440 --> 00:15:43,759
sgx and encrypted is this attack still

440
00:15:43,759 --> 00:15:45,519
applicable yeah so that's a good

441
00:15:45,519 --> 00:15:48,320
question so uh for sgx the data is

442
00:15:48,320 --> 00:15:51,519
stored in memory are encrypted so

443
00:15:51,519 --> 00:15:53,759
if even if we can still our bit

444
00:15:53,759 --> 00:15:55,600
information from the weight in case of

445
00:15:55,600 --> 00:15:58,320
stx enclaves uh the data will not be the

446
00:15:58,320 --> 00:16:00,560
actual data of weights but

447
00:16:00,560 --> 00:16:02,720
uh we want to note that

448
00:16:02,720 --> 00:16:05,519
running an end a large dnn model in uh

449
00:16:05,519 --> 00:16:08,079
like a sgx enclave is still not very

450
00:16:08,079 --> 00:16:10,800
practical because of the high amount of

451
00:16:10,800 --> 00:16:12,800
overhead of execution that has been

452
00:16:12,800 --> 00:16:14,079
demonstrated in the

453
00:16:14,079 --> 00:16:16,719
prior works

454
00:16:17,120 --> 00:16:19,600
thank you any other questions

455
00:16:19,600 --> 00:16:20,639
okay

456
00:16:20,639 --> 00:16:22,399
while you're coming i i just was

457
00:16:22,399 --> 00:16:24,079
wondering because when i think of bit

458
00:16:24,079 --> 00:16:26,160
flips i think of integrity violations

459
00:16:26,160 --> 00:16:28,000
right so when you were running did you

460
00:16:28,000 --> 00:16:30,240
by accident modify the models and like

461
00:16:30,240 --> 00:16:33,440
just yeah they come up so okay that's

462
00:16:33,440 --> 00:16:35,360
another excellent question so here we

463
00:16:35,360 --> 00:16:36,800
want to note that we are actually

464
00:16:36,800 --> 00:16:38,800
inducing bit flips into the attacker's

465
00:16:38,800 --> 00:16:41,680
control data so when we induce bit flip

466
00:16:41,680 --> 00:16:43,600
into attackers data it's highly unlikely

467
00:16:43,600 --> 00:16:45,360
that it's going to cause any any system

468
00:16:45,360 --> 00:16:47,519
freeze or unlikely event of like a

469
00:16:47,519 --> 00:16:49,839
system crash because the data

470
00:16:49,839 --> 00:16:51,920
that's changed is attackers so we just

471
00:16:51,920 --> 00:16:52,639
uh

472
00:16:52,639 --> 00:16:54,320
compared the data with the

473
00:16:54,320 --> 00:16:57,040
preset data that we set before and then

474
00:16:57,040 --> 00:16:58,480
move on so

475
00:16:58,480 --> 00:17:00,240
typically it doesn't cause uh lead to

476
00:17:00,240 --> 00:17:02,639
any system crashes

477
00:17:02,639 --> 00:17:04,959
thank you um yep please introduce

478
00:17:04,959 --> 00:17:08,000
yourself hello i'm gustavo goswami from

479
00:17:08,000 --> 00:17:10,480
uc davis first of all thank you for your

480
00:17:10,480 --> 00:17:11,760
amazing talk

481
00:17:11,760 --> 00:17:12,799
i

482
00:17:12,799 --> 00:17:15,679
really like the idea that

483
00:17:15,679 --> 00:17:17,280
bit flips that happened due to row

484
00:17:17,280 --> 00:17:20,079
hammer is data dependent like whether if

485
00:17:20,079 --> 00:17:21,119
you have a

486
00:17:21,119 --> 00:17:23,520
one or zero has an impact on whether

487
00:17:23,520 --> 00:17:25,760
you're able to flip the bit or not

488
00:17:25,760 --> 00:17:28,160
so my question is uh

489
00:17:28,160 --> 00:17:30,640
did you consider the true and nt cell

490
00:17:30,640 --> 00:17:33,039
distribution in the dim because the

491
00:17:33,039 --> 00:17:34,960
capacitor might

492
00:17:34,960 --> 00:17:37,280
like be full charge but may represent

493
00:17:37,280 --> 00:17:38,720
the zero

494
00:17:38,720 --> 00:17:41,600
an ent cell or vice versa for a true

495
00:17:41,600 --> 00:17:43,600
cell so did you consider this during

496
00:17:43,600 --> 00:17:46,000
your evaluation yeah of course so this

497
00:17:46,000 --> 00:17:48,160
is another excellent question so what we

498
00:17:48,160 --> 00:17:49,760
essentially did was during the memory

499
00:17:49,760 --> 00:17:52,000
templating phase we already we tried to

500
00:17:52,000 --> 00:17:53,440
generate the bit flip profile which

501
00:17:53,440 --> 00:17:56,000
tells us uh which look a specific

502
00:17:56,000 --> 00:17:57,840
location if it's vulnerable from zero to

503
00:17:57,840 --> 00:17:59,840
one flip or one to zero feet so

504
00:17:59,840 --> 00:18:01,760
regardless of which direction it's

505
00:18:01,760 --> 00:18:03,919
vulnerable we can precise the attacker's

506
00:18:03,919 --> 00:18:06,240
data uh we can preset that accuracy data

507
00:18:06,240 --> 00:18:08,559
to either zero or one and observe for

508
00:18:08,559 --> 00:18:10,480
either bit flip or no bit flip so either

509
00:18:10,480 --> 00:18:12,559
case that x works very successfully okay

510
00:18:12,559 --> 00:18:14,480
a quick follow-up question on that

511
00:18:14,480 --> 00:18:17,200
so this distribution of ntn true cells

512
00:18:17,200 --> 00:18:19,360
depends on the dim or the manufacturer

513
00:18:19,360 --> 00:18:22,799
that you use so uh if

514
00:18:22,799 --> 00:18:26,240
we use your attacking model does it mean

515
00:18:26,240 --> 00:18:28,799
that we have to profile this true energy

516
00:18:28,799 --> 00:18:30,559
cell distribution every time before

517
00:18:30,559 --> 00:18:33,280
performing the attack uh so no uh what

518
00:18:33,280 --> 00:18:35,440
we basically have to do is before any

519
00:18:35,440 --> 00:18:36,960
type of hammer lick attack we actually

520
00:18:36,960 --> 00:18:39,120
perform the memory templating once to

521
00:18:39,120 --> 00:18:40,640
determine which are the flippable

522
00:18:40,640 --> 00:18:43,360
locations and the direction of the flip

523
00:18:43,360 --> 00:18:44,240
then

524
00:18:44,240 --> 00:18:46,799
and then the entire existence of the

525
00:18:46,799 --> 00:18:49,039
uh inference attack this remains uh

526
00:18:49,039 --> 00:18:50,799
constant as long as we don't reboot the

527
00:18:50,799 --> 00:18:54,720
system okay okay thank you so much

528
00:18:55,679 --> 00:18:56,640
thank you

529
00:18:56,640 --> 00:18:58,160
um

530
00:18:58,160 --> 00:19:00,480
yeah okay um i think we have just one

531
00:19:00,480 --> 00:19:02,160
quick question so you're

532
00:19:02,160 --> 00:19:03,600
revealing the model weights and i was

533
00:19:03,600 --> 00:19:05,760
wondering what about the actual data

534
00:19:05,760 --> 00:19:08,160
point right that goes through can you

535
00:19:08,160 --> 00:19:10,400
reveal anything about that oh yeah

536
00:19:10,400 --> 00:19:12,160
basically we also

537
00:19:12,160 --> 00:19:14,480
in these experiments we assume that we

538
00:19:14,480 --> 00:19:15,760
have eight percent training that are

539
00:19:15,760 --> 00:19:17,200
available so we also perform the

540
00:19:17,200 --> 00:19:19,360
experiment they're varying the range of

541
00:19:19,360 --> 00:19:21,039
training that are available up to two

542
00:19:21,039 --> 00:19:23,039
percent and with less and lesser data

543
00:19:23,039 --> 00:19:24,640
available the attack becomes less

544
00:19:24,640 --> 00:19:27,679
effective that's quite expected

545
00:19:27,679 --> 00:19:30,080
cool thank you very much let's thank

546
00:19:30,080 --> 00:19:34,918
both of our presenters once more

