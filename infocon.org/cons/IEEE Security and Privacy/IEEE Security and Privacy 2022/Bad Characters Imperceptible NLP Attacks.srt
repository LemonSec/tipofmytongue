1
00:00:01,839 --> 00:00:04,480
all right good morning everyone uh so my

2
00:00:04,480 --> 00:00:06,879
name is nicholas boucher i am a phd

3
00:00:06,879 --> 00:00:09,040
candidate at the university of cambridge

4
00:00:09,040 --> 00:00:10,960
and i'm here today to talk to you about

5
00:00:10,960 --> 00:00:12,799
a paper titled bad characters

6
00:00:12,799 --> 00:00:15,280
imperceptible nlp attacks uh and i'd

7
00:00:15,280 --> 00:00:17,119
just like to start by acknowledging

8
00:00:17,119 --> 00:00:19,680
co-authors ilya shamila ross anderson

9
00:00:19,680 --> 00:00:21,600
and nicholas peperno

10
00:00:21,600 --> 00:00:24,960
so text-based machine learning is broken

11
00:00:24,960 --> 00:00:27,359
and it's broken at a pretty fundamental

12
00:00:27,359 --> 00:00:28,240
level

13
00:00:28,240 --> 00:00:31,199
so all machine learning models consuming

14
00:00:31,199 --> 00:00:33,520
text as input are vulnerable to

15
00:00:33,520 --> 00:00:36,079
adversarial examples uh that are

16
00:00:36,079 --> 00:00:38,879
entirely imperceptible to human users

17
00:00:38,879 --> 00:00:40,559
and in this talk we're going to talk

18
00:00:40,559 --> 00:00:42,399
about how to craft those attacks what

19
00:00:42,399 --> 00:00:44,800
this means for the ecosystem and give a

20
00:00:44,800 --> 00:00:47,039
real call to action for the deployment

21
00:00:47,039 --> 00:00:50,000
of defenses against this style of attack

22
00:00:50,000 --> 00:00:52,559
so let's start off with a figure that

23
00:00:52,559 --> 00:00:54,960
everyone here has seen before you've

24
00:00:54,960 --> 00:00:57,120
likely seen this in the highly impactful

25
00:00:57,120 --> 00:01:00,719
2015 uh paper where we begin by defining

26
00:01:00,719 --> 00:01:02,640
adversarial examples which are

27
00:01:02,640 --> 00:01:05,760
effectively benign inputs to models with

28
00:01:05,760 --> 00:01:08,240
added perturbations that purposefully

29
00:01:08,240 --> 00:01:10,720
output incorrect results at the time of

30
00:01:10,720 --> 00:01:11,840
inference

31
00:01:11,840 --> 00:01:14,000
and when it comes to the visual domain

32
00:01:14,000 --> 00:01:16,400
we can subtly change pixel values

33
00:01:16,400 --> 00:01:18,400
without human perception it's it's

34
00:01:18,400 --> 00:01:20,159
actually pretty straightforward you can

35
00:01:20,159 --> 00:01:22,799
you know change these minute values uh

36
00:01:22,799 --> 00:01:24,560
to an amount that's significant to

37
00:01:24,560 --> 00:01:25,920
machine learning models but

38
00:01:25,920 --> 00:01:28,560
insignificant to humans and you end up

39
00:01:28,560 --> 00:01:30,479
being able to take an image of a panda

40
00:01:30,479 --> 00:01:33,119
and have it be classified as a given or

41
00:01:33,119 --> 00:01:35,520
something much more adversarial like

42
00:01:35,520 --> 00:01:37,439
misclassifying stop signs in

43
00:01:37,439 --> 00:01:39,680
self-driving cars or or something like

44
00:01:39,680 --> 00:01:40,560
that

45
00:01:40,560 --> 00:01:42,399
but what does it mean to craft

46
00:01:42,399 --> 00:01:45,680
adversarial examples in the text domain

47
00:01:45,680 --> 00:01:49,040
uh you know text is a very discreet

48
00:01:49,040 --> 00:01:51,360
form of communication it's

49
00:01:51,360 --> 00:01:52,880
information that

50
00:01:52,880 --> 00:01:55,200
tends to change drastically if you you

51
00:01:55,200 --> 00:01:56,640
change anything about it you know you

52
00:01:56,640 --> 00:02:00,159
can't subtly tweak the uh color value a

53
00:02:00,159 --> 00:02:02,000
color channel value of something in text

54
00:02:02,000 --> 00:02:04,960
you have to entirely change a letter or

55
00:02:04,960 --> 00:02:07,119
change a word or a sentence structure or

56
00:02:07,119 --> 00:02:09,440
or something like that and when it comes

57
00:02:09,440 --> 00:02:11,840
to machine learning in general nlp is a

58
00:02:11,840 --> 00:02:14,400
very successful application of machine

59
00:02:14,400 --> 00:02:16,560
learning so a reasonable question to ask

60
00:02:16,560 --> 00:02:19,200
would be is it exempt from these sort of

61
00:02:19,200 --> 00:02:21,360
adversarial example attacks well well

62
00:02:21,360 --> 00:02:23,360
the answer to that is is absolutely no

63
00:02:23,360 --> 00:02:25,040
and there has been some previous work

64
00:02:25,040 --> 00:02:28,239
here so a previous work in adversarial

65
00:02:28,239 --> 00:02:30,080
text-based attacks have tried to do

66
00:02:30,080 --> 00:02:32,319
things like purposefully misspelling

67
00:02:32,319 --> 00:02:34,959
words or paraphrasing sentences and

68
00:02:34,959 --> 00:02:36,959
things like this things that would you

69
00:02:36,959 --> 00:02:38,879
know somehow change the text that's

70
00:02:38,879 --> 00:02:41,040
being ingested into the model with an

71
00:02:41,040 --> 00:02:43,120
aim to output an incorrect result from

72
00:02:43,120 --> 00:02:45,040
that model and you know why would you

73
00:02:45,040 --> 00:02:46,480
want to do that you could imagine

74
00:02:46,480 --> 00:02:48,640
systems like toxic content detection

75
00:02:48,640 --> 00:02:51,280
machine translation sentiment analysis

76
00:02:51,280 --> 00:02:52,080
and

77
00:02:52,080 --> 00:02:54,800
given how much of the world operates uh

78
00:02:54,800 --> 00:02:56,480
online you know on the internet these

79
00:02:56,480 --> 00:02:59,360
days a lot of these text-based uh

80
00:02:59,360 --> 00:03:01,280
machine learning systems are actually

81
00:03:01,280 --> 00:03:04,000
pretty significant to society in the

82
00:03:04,000 --> 00:03:07,040
modern world so let's talk about unicode

83
00:03:07,040 --> 00:03:10,319
unicode is the de facto standards that

84
00:03:10,319 --> 00:03:13,200
we use for encoding our text in modern

85
00:03:13,200 --> 00:03:14,800
era it contains

86
00:03:14,800 --> 00:03:17,840
a little less than 150 000 characters in

87
00:03:17,840 --> 00:03:20,080
the current version of the specification

88
00:03:20,080 --> 00:03:23,280
and it turns out that it gives us many

89
00:03:23,280 --> 00:03:26,000
different ways to perturb text without

90
00:03:26,000 --> 00:03:28,879
having any sort of visual effect on the

91
00:03:28,879 --> 00:03:31,200
uh the rendering the display of that

92
00:03:31,200 --> 00:03:34,080
text and and why is this significant

93
00:03:34,080 --> 00:03:35,920
it's significant because we can

94
00:03:35,920 --> 00:03:39,599
effectively modify the encoding of text

95
00:03:39,599 --> 00:03:41,920
to attack machine learning models the

96
00:03:41,920 --> 00:03:44,480
ingest text without changing the way

97
00:03:44,480 --> 00:03:46,959
that that text looks whatsoever so now

98
00:03:46,959 --> 00:03:48,879
we're kind of reframing how we look at

99
00:03:48,879 --> 00:03:50,799
text based uh

100
00:03:50,799 --> 00:03:52,959
adversarial example attacks and and

101
00:03:52,959 --> 00:03:55,040
we're not looking at changing um you

102
00:03:55,040 --> 00:03:57,040
know the the letters or the words or the

103
00:03:57,040 --> 00:03:58,640
sentences we're looking at changing the

104
00:03:58,640 --> 00:04:00,879
underlying encoding with an aim to

105
00:04:00,879 --> 00:04:04,000
represent text visually in the exact

106
00:04:04,000 --> 00:04:06,239
same way as whatever benign input that

107
00:04:06,239 --> 00:04:08,720
we are attempting to perturb so there's

108
00:04:08,720 --> 00:04:10,720
four techniques that i would like to

109
00:04:10,720 --> 00:04:13,599
deep dive into so the first of which is

110
00:04:13,599 --> 00:04:16,639
the concept of invisible characters and

111
00:04:16,639 --> 00:04:18,720
we'll define invisible characters as

112
00:04:18,720 --> 00:04:21,120
characters that render to the absence of

113
00:04:21,120 --> 00:04:23,680
a glyph and an example of this is what's

114
00:04:23,680 --> 00:04:26,479
up on the screen the zero with space

115
00:04:26,479 --> 00:04:28,400
this is a character in unicode it's it's

116
00:04:28,400 --> 00:04:30,400
one of many that we would define as an

117
00:04:30,400 --> 00:04:32,479
invisible character and it's exactly

118
00:04:32,479 --> 00:04:34,400
what it sounds like it's a it's a space

119
00:04:34,400 --> 00:04:36,560
character that's exactly zero pixels

120
00:04:36,560 --> 00:04:38,800
wide and why would you want things like

121
00:04:38,800 --> 00:04:40,560
this well it turns out that in certain

122
00:04:40,560 --> 00:04:42,800
settings this may be helpful for various

123
00:04:42,800 --> 00:04:45,680
formatting purposes but in the general

124
00:04:45,680 --> 00:04:48,639
usage of text it would have no effect

125
00:04:48,639 --> 00:04:51,280
whatsoever on the surrounding text and

126
00:04:51,280 --> 00:04:53,120
this is really handy because it means

127
00:04:53,120 --> 00:04:55,440
that we can inject these arbitrarily

128
00:04:55,440 --> 00:04:57,120
into some string

129
00:04:57,120 --> 00:04:59,120
effectively changing the encoding of

130
00:04:59,120 --> 00:05:01,680
that string or the binary representation

131
00:05:01,680 --> 00:05:03,600
of that string without changing the way

132
00:05:03,600 --> 00:05:06,320
that that string that text renders and

133
00:05:06,320 --> 00:05:08,880
this is really nice because most nlp

134
00:05:08,880 --> 00:05:11,840
models will treat these sort of

135
00:05:11,840 --> 00:05:13,759
invisible characters as either unknown

136
00:05:13,759 --> 00:05:16,320
tokens in their embedding space or some

137
00:05:16,320 --> 00:05:18,479
kind of dedicated you know zero width

138
00:05:18,479 --> 00:05:20,479
space token for example but

139
00:05:20,479 --> 00:05:22,639
both of those different avenues will

140
00:05:22,639 --> 00:05:24,720
result in some change to the embedding

141
00:05:24,720 --> 00:05:26,400
space for whatever model we're

142
00:05:26,400 --> 00:05:28,400
discussing which means that we're very

143
00:05:28,400 --> 00:05:30,560
likely going to have some impact on the

144
00:05:30,560 --> 00:05:32,880
output of that model so let's talk about

145
00:05:32,880 --> 00:05:34,560
another technique that we could use

146
00:05:34,560 --> 00:05:36,080
something called homoglyphs and if you

147
00:05:36,080 --> 00:05:37,919
haven't come across this before it's a

148
00:05:37,919 --> 00:05:40,000
really simple idea these are distinct

149
00:05:40,000 --> 00:05:42,720
characters that render to either exactly

150
00:05:42,720 --> 00:05:45,759
the same or nearly the same glyph

151
00:05:45,759 --> 00:05:48,000
so on the example that we have on the

152
00:05:48,000 --> 00:05:50,000
screen we have two characters that look

153
00:05:50,000 --> 00:05:52,080
like the latin letter h that we would

154
00:05:52,080 --> 00:05:54,400
use in english but on the left-hand side

155
00:05:54,400 --> 00:05:55,919
of the screen we actually have a

156
00:05:55,919 --> 00:05:58,160
cyrillic character that is a homoglyph

157
00:05:58,160 --> 00:06:00,000
of the latin h

158
00:06:00,000 --> 00:06:01,919
and some of the best examples happen to

159
00:06:01,919 --> 00:06:03,680
come from from latin and cyrillic

160
00:06:03,680 --> 00:06:05,360
although we also have the greek alphabet

161
00:06:05,360 --> 00:06:08,160
and many others and uh what's what's

162
00:06:08,160 --> 00:06:09,919
nice about this is that we can take

163
00:06:09,919 --> 00:06:11,280
these different characters and we can

164
00:06:11,280 --> 00:06:13,440
substitute them within strings once

165
00:06:13,440 --> 00:06:14,880
again finding a way to change the

166
00:06:14,880 --> 00:06:16,880
encoding of text without changing the

167
00:06:16,880 --> 00:06:19,520
visual display of that text and i'd like

168
00:06:19,520 --> 00:06:21,280
to call out that homoglyphs are actually

169
00:06:21,280 --> 00:06:23,440
reasonably dense within the unicode

170
00:06:23,440 --> 00:06:25,520
specification so what you're looking at

171
00:06:25,520 --> 00:06:27,280
here is a dimensionality-reduced

172
00:06:27,280 --> 00:06:29,280
clustering of rendered characters that

173
00:06:29,280 --> 00:06:31,680
we put into a visual model with the aim

174
00:06:31,680 --> 00:06:34,880
here just to try to motivate the fact

175
00:06:34,880 --> 00:06:36,319
that there are actually quite a lot of

176
00:06:36,319 --> 00:06:38,960
homoglyphs in the unicode specification

177
00:06:38,960 --> 00:06:41,039
which means that we have a large number

178
00:06:41,039 --> 00:06:42,560
of opportunities to substitute

179
00:06:42,560 --> 00:06:44,639
characters once again changing the

180
00:06:44,639 --> 00:06:46,720
binary representation of text without

181
00:06:46,720 --> 00:06:48,160
changing the way that that text is

182
00:06:48,160 --> 00:06:49,199
displayed

183
00:06:49,199 --> 00:06:50,800
so let's talk about a third technique

184
00:06:50,800 --> 00:06:52,400
the third technique we'll talk about is

185
00:06:52,400 --> 00:06:54,560
reorderings and these are techniques

186
00:06:54,560 --> 00:06:57,360
that change the logically encoded order

187
00:06:57,360 --> 00:06:58,720
of characters

188
00:06:58,720 --> 00:07:00,639
without changing once again the way that

189
00:07:00,639 --> 00:07:02,479
those characters are displayed so so how

190
00:07:02,479 --> 00:07:04,960
do we do this so it turns out that you

191
00:07:04,960 --> 00:07:06,880
know in human language we write in both

192
00:07:06,880 --> 00:07:08,800
the left to right direction and the

193
00:07:08,800 --> 00:07:10,800
right to left direction

194
00:07:10,800 --> 00:07:12,800
and sometimes we want to have very fine

195
00:07:12,800 --> 00:07:15,680
grained control over the order of text

196
00:07:15,680 --> 00:07:16,960
when we mixed

197
00:07:16,960 --> 00:07:18,400
the languages of different

198
00:07:18,400 --> 00:07:20,479
directionalities so to support this

199
00:07:20,479 --> 00:07:22,319
unicode has control characters that

200
00:07:22,319 --> 00:07:25,039
support overriding the sensible default

201
00:07:25,039 --> 00:07:27,280
directionalities that unicode will give

202
00:07:27,280 --> 00:07:29,759
you and we can leverage these control

203
00:07:29,759 --> 00:07:32,400
characters to purposefully adversarially

204
00:07:32,400 --> 00:07:34,800
change the display order of text so if

205
00:07:34,800 --> 00:07:36,479
you look at the graphic that we have on

206
00:07:36,479 --> 00:07:38,240
the screen here you'll see that

207
00:07:38,240 --> 00:07:40,160
we are looking at some rendered text

208
00:07:40,160 --> 00:07:42,400
that looks like it says abc but the

209
00:07:42,400 --> 00:07:44,000
underlying encoding which is on the

210
00:07:44,000 --> 00:07:46,080
bottom of the screen actually logically

211
00:07:46,080 --> 00:07:49,039
encodes in the order cba but it's just

212
00:07:49,039 --> 00:07:51,039
displaying in an environment that shows

213
00:07:51,039 --> 00:07:53,440
code that shows text as right to left

214
00:07:53,440 --> 00:07:55,120
instead of left to right

215
00:07:55,120 --> 00:07:57,120
so this one is really nice it happens to

216
00:07:57,120 --> 00:07:59,120
be my favorite trick it allows us to

217
00:07:59,120 --> 00:08:00,960
drastically change the encoded

218
00:08:00,960 --> 00:08:03,360
representation of text uh with some

219
00:08:03,360 --> 00:08:06,080
overall fairly straightforward ideas and

220
00:08:06,080 --> 00:08:07,280
if you don't like those first three

221
00:08:07,280 --> 00:08:08,720
techniques we'll talk about one more

222
00:08:08,720 --> 00:08:10,000
this is the fourth one we'll call it

223
00:08:10,000 --> 00:08:12,800
deletions this is where we can inject

224
00:08:12,800 --> 00:08:15,280
arbitrary characters of of any kind into

225
00:08:15,280 --> 00:08:17,840
a string and then we purposefully delete

226
00:08:17,840 --> 00:08:20,160
those characters by injecting uh a

227
00:08:20,160 --> 00:08:22,080
control character that will remove the

228
00:08:22,080 --> 00:08:23,759
preceding character the most obvious

229
00:08:23,759 --> 00:08:25,840
example which is the backspace you know

230
00:08:25,840 --> 00:08:26,960
just the same

231
00:08:26,960 --> 00:08:28,240
character that's injected from the

232
00:08:28,240 --> 00:08:29,120
button

233
00:08:29,120 --> 00:08:31,280
that you hit on your keyboard and this

234
00:08:31,280 --> 00:08:33,760
is very nice because it allows us to

235
00:08:33,760 --> 00:08:36,719
inject highly targeted things into text

236
00:08:36,719 --> 00:08:38,799
we can take some string and we could put

237
00:08:38,799 --> 00:08:40,958
some substring uh you know embedded

238
00:08:40,958 --> 00:08:42,479
inside of that string and just throw a

239
00:08:42,479 --> 00:08:44,720
few backspace characters after it and

240
00:08:44,720 --> 00:08:47,040
all of a sudden we've added something

241
00:08:47,040 --> 00:08:48,959
into the binary representation of text

242
00:08:48,959 --> 00:08:50,640
that's highly targeted once again

243
00:08:50,640 --> 00:08:52,880
without changing the display order so

244
00:08:52,880 --> 00:08:55,120
how does all of this come together well

245
00:08:55,120 --> 00:08:57,680
uh we consider a genetic algorithm and

246
00:08:57,680 --> 00:09:00,320
uh in this genetic algorithm we're

247
00:09:00,320 --> 00:09:03,040
trying to optimize these four different

248
00:09:03,040 --> 00:09:05,519
techniques uh to either maximize the

249
00:09:05,519 --> 00:09:07,040
distance from the

250
00:09:07,040 --> 00:09:10,000
correct class for any given target model

251
00:09:10,000 --> 00:09:12,640
or minimize the distance to a target

252
00:09:12,640 --> 00:09:14,640
targeted class if we happen to be

253
00:09:14,640 --> 00:09:16,560
running a a targeted

254
00:09:16,560 --> 00:09:19,600
attack so this is kind of the same

255
00:09:19,600 --> 00:09:22,000
concept that would exist in any sort of

256
00:09:22,000 --> 00:09:24,399
adversarial example

257
00:09:24,399 --> 00:09:26,000
attack pattern within

258
00:09:26,000 --> 00:09:27,519
machine learning systems it just so

259
00:09:27,519 --> 00:09:29,279
happens that we are using these four

260
00:09:29,279 --> 00:09:31,519
different techniques of perturbing text

261
00:09:31,519 --> 00:09:33,920
at the encoding or binary level without

262
00:09:33,920 --> 00:09:36,000
changing the visual representation of

263
00:09:36,000 --> 00:09:38,720
that text and using this we can craft

264
00:09:38,720 --> 00:09:40,720
adversarial examples that target

265
00:09:40,720 --> 00:09:42,080
specific

266
00:09:42,080 --> 00:09:45,120
models and visual inputs to those models

267
00:09:45,120 --> 00:09:46,080
so

268
00:09:46,080 --> 00:09:48,320
much more detail about this genetic

269
00:09:48,320 --> 00:09:50,240
algorithm is in the paper for time

270
00:09:50,240 --> 00:09:52,399
limitations i'm not going to go into the

271
00:09:52,399 --> 00:09:54,320
mechanics of that right now but it's

272
00:09:54,320 --> 00:09:55,920
just an optimization algorithm that

273
00:09:55,920 --> 00:09:58,000
we're using to try to craft these

274
00:09:58,000 --> 00:10:00,399
targeted attacks so let's look at a few

275
00:10:00,399 --> 00:10:02,800
different examples so in this particular

276
00:10:02,800 --> 00:10:04,800
example we consider a machine

277
00:10:04,800 --> 00:10:06,399
translation model that's translating

278
00:10:06,399 --> 00:10:08,640
from english to french so on the top

279
00:10:08,640 --> 00:10:10,160
left-hand side of the screen we have the

280
00:10:10,160 --> 00:10:12,160
benign input to this model it's in

281
00:10:12,160 --> 00:10:15,360
english it says a black box in your car

282
00:10:15,360 --> 00:10:17,120
and we translate that to french this

283
00:10:17,120 --> 00:10:18,959
just comes from a large corpus of data

284
00:10:18,959 --> 00:10:21,279
that we happen to attack inside of the

285
00:10:21,279 --> 00:10:23,519
paper but then on the bottom hand side

286
00:10:23,519 --> 00:10:25,760
of the screen you'll see that we are

287
00:10:25,760 --> 00:10:28,240
using a reordering we're actually just

288
00:10:28,240 --> 00:10:30,320
switching the order of two characters in

289
00:10:30,320 --> 00:10:32,079
this string we're switching the order of

290
00:10:32,079 --> 00:10:34,480
the l and the a but when this text

291
00:10:34,480 --> 00:10:36,640
renders uh you you don't see that

292
00:10:36,640 --> 00:10:38,320
there's anything different because we've

293
00:10:38,320 --> 00:10:41,360
offset uh the uh the underlying

294
00:10:41,360 --> 00:10:43,360
logically encoded order change with

295
00:10:43,360 --> 00:10:45,519
these control characters that will

296
00:10:45,519 --> 00:10:47,920
swap the display order back to the same

297
00:10:47,920 --> 00:10:49,920
as the benign text but we get this

298
00:10:49,920 --> 00:10:51,760
really interesting output which is that

299
00:10:51,760 --> 00:10:54,079
when we attempt to run inference on this

300
00:10:54,079 --> 00:10:55,920
model translating into french in the

301
00:10:55,920 --> 00:10:57,519
bottom right hand side of the screen you

302
00:10:57,519 --> 00:10:59,600
see that we just get absolute garbage

303
00:10:59,600 --> 00:11:01,279
output that appears to have no meaning

304
00:11:01,279 --> 00:11:03,519
whatsoever despite putting something

305
00:11:03,519 --> 00:11:05,279
into the model that looks exactly the

306
00:11:05,279 --> 00:11:07,120
same as what we had on the top left-hand

307
00:11:07,120 --> 00:11:09,040
side of the screen so let's look at a

308
00:11:09,040 --> 00:11:10,959
second example in this example we will

309
00:11:10,959 --> 00:11:13,040
look at toxic content detection which is

310
00:11:13,040 --> 00:11:14,880
actually something that's pretty

311
00:11:14,880 --> 00:11:16,880
significant in modern society and

312
00:11:16,880 --> 00:11:19,200
perhaps fundamental to certain parts of

313
00:11:19,200 --> 00:11:20,320
the internet

314
00:11:20,320 --> 00:11:22,959
so uh consider the text you are a coward

315
00:11:22,959 --> 00:11:25,200
and a fool which would normally classify

316
00:11:25,200 --> 00:11:27,920
on the model that we tested as 96.8

317
00:11:27,920 --> 00:11:30,640
toxic well it turns out that we inject

318
00:11:30,640 --> 00:11:33,440
just uh five different random characters

319
00:11:33,440 --> 00:11:35,760
in the ascii range followed by deletion

320
00:11:35,760 --> 00:11:37,279
characters right after them which is

321
00:11:37,279 --> 00:11:38,959
what we're doing on the right hand side

322
00:11:38,959 --> 00:11:41,839
of the screen uh we will end up lowering

323
00:11:41,839 --> 00:11:44,320
that to 8.2 percent toxic uh meaning

324
00:11:44,320 --> 00:11:46,240
that if i have some sort of system

325
00:11:46,240 --> 00:11:48,240
that's trying to gate what i can post on

326
00:11:48,240 --> 00:11:50,079
say a forum or a social media

327
00:11:50,079 --> 00:11:51,920
environment or something like that i can

328
00:11:51,920 --> 00:11:55,120
effectively bypass the toxic content

329
00:11:55,120 --> 00:11:58,079
filter by using just one of the four

330
00:11:58,079 --> 00:11:59,440
different techniques that we talked

331
00:11:59,440 --> 00:12:01,279
about and we actually looked at a whole

332
00:12:01,279 --> 00:12:03,440
bunch of different tasks in our

333
00:12:03,440 --> 00:12:04,800
experiments we looked at machine

334
00:12:04,800 --> 00:12:06,800
learning textual entailment

335
00:12:06,800 --> 00:12:08,399
toxic content detection a whole bunch of

336
00:12:08,399 --> 00:12:09,279
others

337
00:12:09,279 --> 00:12:11,120
and we also looked at models from a

338
00:12:11,120 --> 00:12:13,279
variety of different large technology

339
00:12:13,279 --> 00:12:15,040
companies that are well-known producers

340
00:12:15,040 --> 00:12:18,000
and publishers of models online many of

341
00:12:18,000 --> 00:12:19,440
the models that we looked at are

342
00:12:19,440 --> 00:12:21,920
actively deployed production models and

343
00:12:21,920 --> 00:12:23,440
we find that

344
00:12:23,440 --> 00:12:25,680
every model that we looked at was

345
00:12:25,680 --> 00:12:26,959
vulnerable to

346
00:12:26,959 --> 00:12:28,959
being able to generate adversarial

347
00:12:28,959 --> 00:12:30,800
examples using these kind of

348
00:12:30,800 --> 00:12:33,680
imperceptible perturbations that we are

349
00:12:33,680 --> 00:12:35,839
generating using unicode and

350
00:12:35,839 --> 00:12:38,480
just as a mile-high overview i'll throw

351
00:12:38,480 --> 00:12:41,040
up a few of the kind of more technical

352
00:12:41,040 --> 00:12:43,600
results here so uh we'll look in the top

353
00:12:43,600 --> 00:12:45,680
left at google translate in the top

354
00:12:45,680 --> 00:12:47,519
right of the textual entailment model

355
00:12:47,519 --> 00:12:50,160
produced by facebook in the bottom left

356
00:12:50,160 --> 00:12:52,320
at a sentiment analysis model that uh

357
00:12:52,320 --> 00:12:54,000
just a common one published on hugging

358
00:12:54,000 --> 00:12:56,240
face and in the bottom right is a toxic

359
00:12:56,240 --> 00:12:58,560
content detection model produced by ibm

360
00:12:58,560 --> 00:13:00,399
and what's most important here is just

361
00:13:00,399 --> 00:13:02,240
the trends of all of these graphs you'll

362
00:13:02,240 --> 00:13:04,480
see that as we increase our perturbation

363
00:13:04,480 --> 00:13:07,360
budget which we're just defining as one

364
00:13:07,360 --> 00:13:09,839
injection or one

365
00:13:09,839 --> 00:13:11,680
usage of one of the four techniques that

366
00:13:11,680 --> 00:13:14,000
we described as a single perturbation

367
00:13:14,000 --> 00:13:15,920
budget as we increase that we notice the

368
00:13:15,920 --> 00:13:18,079
performance of these models decreases

369
00:13:18,079 --> 00:13:19,440
drastically

370
00:13:19,440 --> 00:13:21,040
different metrics for each of these

371
00:13:21,040 --> 00:13:22,160
different

372
00:13:22,160 --> 00:13:24,320
settings but we see that the performance

373
00:13:24,320 --> 00:13:26,800
will drop from very good with no

374
00:13:26,800 --> 00:13:28,639
perturbations by the time we get to five

375
00:13:28,639 --> 00:13:31,200
we drop down to near zero performance

376
00:13:31,200 --> 00:13:33,200
for most of the models that we looked at

377
00:13:33,200 --> 00:13:35,600
but rather than looking at the kind of

378
00:13:35,600 --> 00:13:37,760
technical numerical graphs in this

379
00:13:37,760 --> 00:13:39,360
setting let's just try and summarize

380
00:13:39,360 --> 00:13:42,240
that is saying in the the broadest sense

381
00:13:42,240 --> 00:13:44,240
the general trend is that when we added

382
00:13:44,240 --> 00:13:46,079
one injection of one of these unicode

383
00:13:46,079 --> 00:13:48,000
perturbations we saw a significant

384
00:13:48,000 --> 00:13:50,240
performance loss in whatever model we

385
00:13:50,240 --> 00:13:52,079
were targeting but by the time we added

386
00:13:52,079 --> 00:13:54,480
three injections we were functionally

387
00:13:54,480 --> 00:13:56,240
breaking the model we saw performance

388
00:13:56,240 --> 00:13:58,720
that dropped very low often approaching

389
00:13:58,720 --> 00:13:59,839
zero

390
00:13:59,839 --> 00:14:01,760
meaning that sort of if you think back

391
00:14:01,760 --> 00:14:03,760
to the example earlier that garbage

392
00:14:03,760 --> 00:14:05,360
output when you expected french to

393
00:14:05,360 --> 00:14:06,959
appear you saw just a bunch of random

394
00:14:06,959 --> 00:14:08,720
characters that's the sort of thing that

395
00:14:08,720 --> 00:14:11,199
we can achieve by injecting a few of

396
00:14:11,199 --> 00:14:13,440
these perturbations so let's talk about

397
00:14:13,440 --> 00:14:15,279
defense there's actually a couple of

398
00:14:15,279 --> 00:14:16,800
different ways to defend against these

399
00:14:16,800 --> 00:14:18,320
sort of attacks

400
00:14:18,320 --> 00:14:20,480
one of which is some deterministic

401
00:14:20,480 --> 00:14:23,120
pre-processing of text before ingestion

402
00:14:23,120 --> 00:14:24,880
into a machine learning pipeline for

403
00:14:24,880 --> 00:14:27,519
inference so this would mean things like

404
00:14:27,519 --> 00:14:30,079
for example resolving control characters

405
00:14:30,079 --> 00:14:32,160
before ingestion into a machine learning

406
00:14:32,160 --> 00:14:34,240
pipeline it would mean things like

407
00:14:34,240 --> 00:14:36,639
taking homoglyphs uh and substituting

408
00:14:36,639 --> 00:14:38,320
them for a common character that you

409
00:14:38,320 --> 00:14:40,560
decide ahead of time at training time or

410
00:14:40,560 --> 00:14:43,279
something like that for your your model

411
00:14:43,279 --> 00:14:44,800
but there's actually a totally different

412
00:14:44,800 --> 00:14:46,240
approach that you could take as well

413
00:14:46,240 --> 00:14:48,320
which uh sounds a little bit crazy but

414
00:14:48,320 --> 00:14:50,399
uh but bear with me on the idea you can

415
00:14:50,399 --> 00:14:51,920
use something like optical character

416
00:14:51,920 --> 00:14:54,480
recognition where you take the text that

417
00:14:54,480 --> 00:14:56,079
you would have being ingested into a

418
00:14:56,079 --> 00:14:58,320
model traditionally as you know these

419
00:14:58,320 --> 00:15:00,240
encoded bytes and actually render that

420
00:15:00,240 --> 00:15:02,720
text to an image pass it through an ocr

421
00:15:02,720 --> 00:15:04,639
model which will then take it back to

422
00:15:04,639 --> 00:15:06,639
text that you then run through your

423
00:15:06,639 --> 00:15:08,160
downstream task

424
00:15:08,160 --> 00:15:10,000
whatever it is that you're hoping to do

425
00:15:10,000 --> 00:15:11,680
and while this definitely adds

426
00:15:11,680 --> 00:15:13,519
computational overhead to a machine

427
00:15:13,519 --> 00:15:15,040
learning pipeline what it's seeking to

428
00:15:15,040 --> 00:15:16,800
do is to unify

429
00:15:16,800 --> 00:15:18,800
these kind of encoded representations

430
00:15:18,800 --> 00:15:21,040
and these visual representations using

431
00:15:21,040 --> 00:15:23,440
something that doesn't require you to

432
00:15:23,440 --> 00:15:24,639
kind of hard code a bunch of

433
00:15:24,639 --> 00:15:26,480
deterministic steps but

434
00:15:26,480 --> 00:15:28,160
let's just summarize that a little bit

435
00:15:28,160 --> 00:15:29,759
more broadly is

436
00:15:29,759 --> 00:15:31,120
machine learning architects should

437
00:15:31,120 --> 00:15:33,279
sanitize their inputs and this is a key

438
00:15:33,279 --> 00:15:34,959
lesson that we've seen in computer

439
00:15:34,959 --> 00:15:36,720
security for many decades you know when

440
00:15:36,720 --> 00:15:39,360
we think about sql databases if you have

441
00:15:39,360 --> 00:15:40,800
user input that's going into that

442
00:15:40,800 --> 00:15:42,240
database you're certainly going to

443
00:15:42,240 --> 00:15:45,120
sanitize it in some way before you dump

444
00:15:45,120 --> 00:15:47,040
it to a file but when it comes to

445
00:15:47,040 --> 00:15:48,480
machine learning it seems that the

446
00:15:48,480 --> 00:15:49,920
approaches will just take whatever a

447
00:15:49,920 --> 00:15:51,680
user gives as input and throw it into

448
00:15:51,680 --> 00:15:53,440
the model but the claim that we're

449
00:15:53,440 --> 00:15:55,040
making here is that you should be

450
00:15:55,040 --> 00:15:56,959
sanitizing inputs if nothing else to

451
00:15:56,959 --> 00:15:58,240
look for these different unicode

452
00:15:58,240 --> 00:16:00,480
perturbations and try and standardize to

453
00:16:00,480 --> 00:16:01,839
something that your model can actually

454
00:16:01,839 --> 00:16:04,240
handle so uh to phrase that a little bit

455
00:16:04,240 --> 00:16:05,839
differently text-based machine learning

456
00:16:05,839 --> 00:16:08,000
pipelines must change in the current

457
00:16:08,000 --> 00:16:09,680
state we can evade toxic content

458
00:16:09,680 --> 00:16:11,040
detection we can break machine

459
00:16:11,040 --> 00:16:13,440
translation named entity recognition and

460
00:16:13,440 --> 00:16:15,199
a whole bunch of other things

461
00:16:15,199 --> 00:16:17,040
and the integrity of any system using

462
00:16:17,040 --> 00:16:18,800
large language models or just language

463
00:16:18,800 --> 00:16:20,639
models in general is at risk from

464
00:16:20,639 --> 00:16:22,639
invisible attacks until defenses are

465
00:16:22,639 --> 00:16:25,759
retrofitted onto existing systems so

466
00:16:25,759 --> 00:16:27,360
let's just do a final summary to

467
00:16:27,360 --> 00:16:30,160
conclude here unicode can imperceptibly

468
00:16:30,160 --> 00:16:31,839
perturb text

469
00:16:31,839 --> 00:16:34,399
and these encoding level perturbations

470
00:16:34,399 --> 00:16:36,560
functionally equate to adversarial

471
00:16:36,560 --> 00:16:38,399
examples that we can use

472
00:16:38,399 --> 00:16:40,480
against various machine learning models

473
00:16:40,480 --> 00:16:42,959
and defenses should be deployed against

474
00:16:42,959 --> 00:16:44,800
these attacks so we have a whole bunch

475
00:16:44,800 --> 00:16:46,000
more things in the paper i would

476
00:16:46,000 --> 00:16:47,360
encourage you to check it out we talk

477
00:16:47,360 --> 00:16:49,440
about availability attacks attack

478
00:16:49,440 --> 00:16:51,839
transferability the specific algorithms

479
00:16:51,839 --> 00:16:53,519
we're using search engines and a whole

480
00:16:53,519 --> 00:16:54,720
bunch more

481
00:16:54,720 --> 00:16:56,560
you can find a summary of the paper at

482
00:16:56,560 --> 00:16:59,120
this website imperceptible.ml

483
00:16:59,120 --> 00:17:01,519
as well as a link off to the actual

484
00:17:01,519 --> 00:17:03,839
paper itself once again my name is

485
00:17:03,839 --> 00:17:05,599
nicholas boucher thank you very much for

486
00:17:05,599 --> 00:17:07,039
attending this talk and i would be happy

487
00:17:07,039 --> 00:17:09,000
to take any questions

488
00:17:09,000 --> 00:17:14,160
[Applause]

489
00:17:14,160 --> 00:17:15,199
all right we have a couple minutes for

490
00:17:15,199 --> 00:17:16,480
questions please

491
00:17:16,480 --> 00:17:18,559
walk up to the mic and state your name

492
00:17:18,559 --> 00:17:21,599
and affiliation please

493
00:17:22,240 --> 00:17:24,880
uh great talk uh guang hong from purdue

494
00:17:24,880 --> 00:17:27,039
university so i have a question so

495
00:17:27,039 --> 00:17:29,360
what's the difference of the attack and

496
00:17:29,360 --> 00:17:31,200
the previous attack that actually

497
00:17:31,200 --> 00:17:34,080
perturb those characters and actually at

498
00:17:34,080 --> 00:17:36,080
the from the model's point of view

499
00:17:36,080 --> 00:17:38,160
actually those like input is just like

500
00:17:38,160 --> 00:17:39,919
unknown words so what's the difference

501
00:17:39,919 --> 00:17:41,600
between these two except from the

502
00:17:41,600 --> 00:17:44,080
imperceptible like point of view

503
00:17:44,080 --> 00:17:46,000
so you said what's the the difference

504
00:17:46,000 --> 00:17:48,880
between these and uh the previous like

505
00:17:48,880 --> 00:17:51,039
attack attacks like changing those

506
00:17:51,039 --> 00:17:53,520
characters to different characters

507
00:17:53,520 --> 00:17:55,120
yeah absolutely so so what's the

508
00:17:55,120 --> 00:17:56,640
difference between this attack and the

509
00:17:56,640 --> 00:17:58,720
things that have existed previously uh

510
00:17:58,720 --> 00:18:00,160
in the literature well the big

511
00:18:00,160 --> 00:18:01,840
difference is that a human can't see

512
00:18:01,840 --> 00:18:04,640
these attacks so if i have some string

513
00:18:04,640 --> 00:18:06,160
that i publish online and i'm hoping

514
00:18:06,160 --> 00:18:07,760
that you'll copy and paste it into some

515
00:18:07,760 --> 00:18:10,000
model or i'm trying to deceive someone

516
00:18:10,000 --> 00:18:12,320
in some way that deception is much more

517
00:18:12,320 --> 00:18:14,400
likely to succeed if that perturbation

518
00:18:14,400 --> 00:18:15,919
isn't something that's going to be

519
00:18:15,919 --> 00:18:18,000
observable directly by a human without

520
00:18:18,000 --> 00:18:20,160
looking at encoded bytes in all of the

521
00:18:20,160 --> 00:18:22,240
previous work the sort of perturbations

522
00:18:22,240 --> 00:18:24,000
that you would see are things that would

523
00:18:24,000 --> 00:18:25,760
actually have a visual change on the

524
00:18:25,760 --> 00:18:27,200
text you could see that a word was

525
00:18:27,200 --> 00:18:29,840
misspelled or that you added a word or

526
00:18:29,840 --> 00:18:31,600
changed the order of words in a sentence

527
00:18:31,600 --> 00:18:33,200
or paraphrase something something like

528
00:18:33,200 --> 00:18:34,720
that so there are there's definitely

529
00:18:34,720 --> 00:18:37,600
strong work um in kind of the prior

530
00:18:37,600 --> 00:18:40,240
setting that has uh visual effect but

531
00:18:40,240 --> 00:18:41,600
we're seeking to do something that we

532
00:18:41,600 --> 00:18:45,120
believe is significantly more deceptive

533
00:18:45,120 --> 00:18:47,280
so a follow-up follow-up

534
00:18:47,280 --> 00:18:48,960
question so

535
00:18:48,960 --> 00:18:51,679
do you think it's a better way to like

536
00:18:51,679 --> 00:18:54,160
have a more robust model against those

537
00:18:54,160 --> 00:18:57,039
like unknown words because like from the

538
00:18:57,039 --> 00:18:58,880
attack uh the model point of view

539
00:18:58,880 --> 00:19:00,880
actually the input is just unknown

540
00:19:00,880 --> 00:19:02,960
embedding sorry

541
00:19:02,960 --> 00:19:05,200
uh yeah so um

542
00:19:05,200 --> 00:19:06,960
you know with with all adversarial

543
00:19:06,960 --> 00:19:08,799
examples like the

544
00:19:08,799 --> 00:19:11,200
it is a valid input that is being

545
00:19:11,200 --> 00:19:13,280
ingested into the model like these

546
00:19:13,280 --> 00:19:15,200
perturbed unicode strings are valid

547
00:19:15,200 --> 00:19:16,640
inputs to a model they just happen to

548
00:19:16,640 --> 00:19:20,080
produce really um awful results so um

549
00:19:20,080 --> 00:19:21,840
you know what form that takes within the

550
00:19:21,840 --> 00:19:24,160
model is it an unknown token that's

551
00:19:24,160 --> 00:19:26,240
being embedded in the model or um you

552
00:19:26,240 --> 00:19:27,679
know is it something totally different

553
00:19:27,679 --> 00:19:29,360
you know turns out these days people are

554
00:19:29,360 --> 00:19:31,440
doing all sorts of things um that are

555
00:19:31,440 --> 00:19:32,799
more complicated than just using

556
00:19:32,799 --> 00:19:34,880
dictionaries to do embeddings into

557
00:19:34,880 --> 00:19:36,799
models so um

558
00:19:36,799 --> 00:19:38,960
yeah if it's the ability to handle

559
00:19:38,960 --> 00:19:40,799
unknown tokens i mean unknown tokens

560
00:19:40,799 --> 00:19:42,559
mess up all sorts of things and kind of

561
00:19:42,559 --> 00:19:44,240
modern transformer based attention

562
00:19:44,240 --> 00:19:46,320
models uh unknown tokens can cause all

563
00:19:46,320 --> 00:19:48,559
sorts of havoc on um you know things

564
00:19:48,559 --> 00:19:50,240
that are otherwise unaffected within the

565
00:19:50,240 --> 00:19:53,600
same string so i think that's the sort

566
00:19:53,600 --> 00:19:55,919
of line of thinking that i think of with

567
00:19:55,919 --> 00:19:57,679
these attacks and because we have

568
00:19:57,679 --> 00:19:59,520
defenses that we can deploy against them

569
00:19:59,520 --> 00:20:01,039
the strong encouragement that i would

570
00:20:01,039 --> 00:20:03,039
give is for model architects to build

571
00:20:03,039 --> 00:20:05,280
those into the pre-inference stage

572
00:20:05,280 --> 00:20:06,880
within their pipelines

573
00:20:06,880 --> 00:20:08,799
thank you thank you

574
00:20:08,799 --> 00:20:10,400
i'm sorry i was running out of time so

575
00:20:10,400 --> 00:20:11,919
if you can take this question offline so

576
00:20:11,919 --> 00:20:13,840
they'll be absolutely great let's thanks

577
00:20:13,840 --> 00:20:16,799
once again nicholas thank

