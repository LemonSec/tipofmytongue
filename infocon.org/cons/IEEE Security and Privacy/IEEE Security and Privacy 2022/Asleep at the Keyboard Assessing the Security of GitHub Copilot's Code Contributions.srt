1
00:00:00,560 --> 00:00:02,639
uh so my name is hammond pierce i'm a

2
00:00:02,639 --> 00:00:04,720
research assistant professor at nyu's

3
00:00:04,720 --> 00:00:07,200
center for cyber security and um i'll be

4
00:00:07,200 --> 00:00:09,440
talking today about our investigation of

5
00:00:09,440 --> 00:00:11,759
github co-pilot

6
00:00:11,759 --> 00:00:14,559
um so firstly what is github co-pilot um

7
00:00:14,559 --> 00:00:17,440
it was released in june of last year as

8
00:00:17,440 --> 00:00:19,920
kind of a beacon for what uh some think

9
00:00:19,920 --> 00:00:21,439
is the future of software development

10
00:00:21,439 --> 00:00:23,519
right this is a marketing spin but

11
00:00:23,519 --> 00:00:26,240
certainly there was a pretty big impact

12
00:00:26,240 --> 00:00:28,880
on the media and in software development

13
00:00:28,880 --> 00:00:31,519
circles when this tool was released

14
00:00:31,519 --> 00:00:33,600
and what it claims to do is to be able

15
00:00:33,600 --> 00:00:36,000
to ingest code as you're writing it and

16
00:00:36,000 --> 00:00:38,079
then give you suggestions further

17
00:00:38,079 --> 00:00:41,040
suggestions for code as you are

18
00:00:41,040 --> 00:00:44,640
producing it what is it coming from well

19
00:00:44,640 --> 00:00:47,200
fundamentally it's built on language

20
00:00:47,200 --> 00:00:49,120
models or specifically large language

21
00:00:49,120 --> 00:00:51,840
models uh github copilot is an

22
00:00:51,840 --> 00:00:54,879
amalgamation of the gpt3 language model

23
00:00:54,879 --> 00:00:57,600
which has been fine-tuned over all of

24
00:00:57,600 --> 00:01:00,559
the open source code on github which is

25
00:01:00,559 --> 00:01:02,000
an enormous amount of source code as i'm

26
00:01:02,000 --> 00:01:03,680
sure you can imagine

27
00:01:03,680 --> 00:01:04,400
and

28
00:01:04,400 --> 00:01:06,159
these language models essentially you

29
00:01:06,159 --> 00:01:08,640
know probabilistic engines which given

30
00:01:08,640 --> 00:01:11,040
some input sequence of words or tokens

31
00:01:11,040 --> 00:01:13,119
will help you to come up with a

32
00:01:13,119 --> 00:01:14,880
prediction for what should be the next

33
00:01:14,880 --> 00:01:16,799
words or sequence in those tokens and

34
00:01:16,799 --> 00:01:18,240
when you start making these language

35
00:01:18,240 --> 00:01:20,080
models really really big which is what

36
00:01:20,080 --> 00:01:22,000
copilot has done you end up being able

37
00:01:22,000 --> 00:01:23,439
to get higher and higher quality

38
00:01:23,439 --> 00:01:25,040
suggestions

39
00:01:25,040 --> 00:01:26,080
so let's have a look at what that

40
00:01:26,080 --> 00:01:27,840
actually looks like now i have a video

41
00:01:27,840 --> 00:01:28,880
but i'm actually going to be a little

42
00:01:28,880 --> 00:01:30,479
bit bolder and actually use the tool

43
00:01:30,479 --> 00:01:34,159
live so um this is github's copilot

44
00:01:34,159 --> 00:01:36,560
running right now on my laptop inside

45
00:01:36,560 --> 00:01:38,240
visual studio code

46
00:01:38,240 --> 00:01:39,920
and so the way it works is i can start

47
00:01:39,920 --> 00:01:41,840
typing and it'll give me suggestions you

48
00:01:41,840 --> 00:01:44,479
can see here i'm writing a login form uh

49
00:01:44,479 --> 00:01:46,000
and um

50
00:01:46,000 --> 00:01:47,439
it's now suggesting that i use a

51
00:01:47,439 --> 00:01:48,960
database that seems reasonable i

52
00:01:48,960 --> 00:01:51,040
probably want a cursor um here we go

53
00:01:51,040 --> 00:01:53,119
it's got some sql for me um and there we

54
00:01:53,119 --> 00:01:54,720
go i'll just finish the function for me

55
00:01:54,720 --> 00:01:56,159
so there we go so i just wrote a whole

56
00:01:56,159 --> 00:01:57,759
function with github copilot right that

57
00:01:57,759 --> 00:02:00,159
was live i just did that now that's

58
00:02:00,159 --> 00:02:01,360
pretty cool

59
00:02:01,360 --> 00:02:02,320
um

60
00:02:02,320 --> 00:02:03,759
so you know that's undeniably cool

61
00:02:03,759 --> 00:02:05,920
actually uh but

62
00:02:05,920 --> 00:02:08,720
what's gone on here

63
00:02:08,720 --> 00:02:11,200
right so this is the the curious part

64
00:02:11,200 --> 00:02:13,120
here is the code that it's written has

65
00:02:13,120 --> 00:02:16,319
got a really really severe um cyber

66
00:02:16,319 --> 00:02:18,000
security vulnerability in it because

67
00:02:18,000 --> 00:02:20,160
this code that it's just written

68
00:02:20,160 --> 00:02:23,120
uh has got let's move on i've got it

69
00:02:23,120 --> 00:02:25,840
done you uh that the top suggestion here

70
00:02:25,840 --> 00:02:27,120
has got

71
00:02:27,120 --> 00:02:30,560
a sql injection vulnerability within it

72
00:02:30,560 --> 00:02:32,000
right and and i just did that that was

73
00:02:32,000 --> 00:02:34,000
live this is this was written on the

74
00:02:34,000 --> 00:02:35,760
tool uh 30 seconds ago at some point

75
00:02:35,760 --> 00:02:37,280
they'll fix it and then my demo is going

76
00:02:37,280 --> 00:02:38,480
to look real silly

77
00:02:38,480 --> 00:02:40,720
um so

78
00:02:40,720 --> 00:02:42,800
this is a bit of a concern and and this

79
00:02:42,800 --> 00:02:44,000
is something that we noticed when we

80
00:02:44,000 --> 00:02:45,840
started playing with the tool uh when it

81
00:02:45,840 --> 00:02:48,800
when it came out last year um so

82
00:02:48,800 --> 00:02:51,040
why is this happening

83
00:02:51,040 --> 00:02:53,760
the language model github copilot and

84
00:02:53,760 --> 00:02:55,599
other automatic program synthesis tools

85
00:02:55,599 --> 00:02:57,760
have a focus on program correctness the

86
00:02:57,760 --> 00:03:00,080
way that the producers of these tools

87
00:03:00,080 --> 00:03:02,080
evaluate them is by evaluating their

88
00:03:02,080 --> 00:03:04,080
performance over functional tests such

89
00:03:04,080 --> 00:03:06,480
as the human eval data set but just

90
00:03:06,480 --> 00:03:08,560
because your code is correct and from a

91
00:03:08,560 --> 00:03:10,000
functional standpoint does not mean it

92
00:03:10,000 --> 00:03:12,560
is good from a security standpoint and

93
00:03:12,560 --> 00:03:14,080
the code that i just wrote with github

94
00:03:14,080 --> 00:03:16,239
copilot is functional don't get me wrong

95
00:03:16,239 --> 00:03:17,599
if you give that a normal username and

96
00:03:17,599 --> 00:03:19,760
password it'll log you in just fine but

97
00:03:19,760 --> 00:03:22,000
if you write it with you know an sql

98
00:03:22,000 --> 00:03:23,760
injection in mind then you'll also be

99
00:03:23,760 --> 00:03:25,360
able to break the code

100
00:03:25,360 --> 00:03:27,280
um so exploitable software is actually

101
00:03:27,280 --> 00:03:29,120
classified into the common weakness

102
00:03:29,120 --> 00:03:31,680
enumeration taxonomy by mitre

103
00:03:31,680 --> 00:03:33,519
and what we want to know is

104
00:03:33,519 --> 00:03:36,319
given that we have seen anecdotally

105
00:03:36,319 --> 00:03:38,640
bugs security relevant bugs coming out

106
00:03:38,640 --> 00:03:40,560
of github co-pilot how secure is

107
00:03:40,560 --> 00:03:41,760
co-pilot

108
00:03:41,760 --> 00:03:44,159
you know holistically across the cwe

109
00:03:44,159 --> 00:03:45,599
taxonomy

110
00:03:45,599 --> 00:03:48,159
um so what we wanted to do was take a

111
00:03:48,159 --> 00:03:49,120
set of

112
00:03:49,120 --> 00:03:51,040
cyber security relevance scenarios and

113
00:03:51,040 --> 00:03:52,720
by scenario what i mean is it's like

114
00:03:52,720 --> 00:03:55,280
that program i just wrote with copilot

115
00:03:55,280 --> 00:03:57,599
turned on so i'm going to steer co-pilot

116
00:03:57,599 --> 00:04:00,560
with a suggestion to write code in a way

117
00:04:00,560 --> 00:04:02,720
that has implications to cyber security

118
00:04:02,720 --> 00:04:04,400
not functional implications i mean there

119
00:04:04,400 --> 00:04:05,599
are functional implications but we're

120
00:04:05,599 --> 00:04:07,599
not interested in those what i want to

121
00:04:07,599 --> 00:04:09,920
know is how many different suggestions

122
00:04:09,920 --> 00:04:11,840
is copilot going to give me

123
00:04:11,840 --> 00:04:13,680
that are vulnerable

124
00:04:13,680 --> 00:04:15,920
now when it comes to evaluating whether

125
00:04:15,920 --> 00:04:17,759
or not a program is vulnerable there's a

126
00:04:17,759 --> 00:04:19,918
lot of different ways to do this some of

127
00:04:19,918 --> 00:04:21,199
them are subjective you know we could

128
00:04:21,199 --> 00:04:23,600
just evaluate the programs as authors

129
00:04:23,600 --> 00:04:25,280
but as it turns out we don't need to do

130
00:04:25,280 --> 00:04:27,759
that because of static software security

131
00:04:27,759 --> 00:04:30,560
analysis tools and also as it turns out

132
00:04:30,560 --> 00:04:32,960
github makes a security analysis tool

133
00:04:32,960 --> 00:04:35,840
called github codeql so it seemed fair

134
00:04:35,840 --> 00:04:38,800
to us to use github codeql to evaluate

135
00:04:38,800 --> 00:04:41,360
the security of github co-pilot

136
00:04:41,360 --> 00:04:43,440
and so uh that's what we did now uh

137
00:04:43,440 --> 00:04:45,600
there is a an addendum there which i'll

138
00:04:45,600 --> 00:04:47,360
mention is that not all bugs can be

139
00:04:47,360 --> 00:04:48,639
checked for statically which i'm sure

140
00:04:48,639 --> 00:04:50,240
you know this is a security conference

141
00:04:50,240 --> 00:04:51,919
but the vast majority of our bugs could

142
00:04:51,919 --> 00:04:54,560
be checked using codeql which was nice

143
00:04:54,560 --> 00:04:56,160
um so we had three different dimensions

144
00:04:56,160 --> 00:04:57,759
that we were really interested in the

145
00:04:57,759 --> 00:05:00,560
first was how many different bugs uh

146
00:05:00,560 --> 00:05:01,680
across the different types of

147
00:05:01,680 --> 00:05:03,440
vulnerability are there so you know

148
00:05:03,440 --> 00:05:04,800
there's lots of different software bugs

149
00:05:04,800 --> 00:05:07,520
right um so does co-pilot bias itself

150
00:05:07,520 --> 00:05:09,199
towards certain kinds of them

151
00:05:09,199 --> 00:05:11,520
in addition you saw me just put in one

152
00:05:11,520 --> 00:05:13,919
prompt to get the result that you saw

153
00:05:13,919 --> 00:05:14,800
earlier

154
00:05:14,800 --> 00:05:17,280
does changing that prompt in subtle ways

155
00:05:17,280 --> 00:05:18,880
affect the output that's coming out of

156
00:05:18,880 --> 00:05:20,720
the language model

157
00:05:20,720 --> 00:05:22,000
and lastly

158
00:05:22,000 --> 00:05:24,160
diversity of domain we don't we're not

159
00:05:24,160 --> 00:05:26,240
just limited to writing software when we

160
00:05:26,240 --> 00:05:28,400
write code in fact i'm a hardware

161
00:05:28,400 --> 00:05:30,320
engineer i write a lot of verilog and

162
00:05:30,320 --> 00:05:32,880
verilog produces hardware not software

163
00:05:32,880 --> 00:05:35,600
there's a whole separate set of cwes for

164
00:05:35,600 --> 00:05:38,080
hardware not software and what we wanted

165
00:05:38,080 --> 00:05:39,919
to know was do these discoveries hold

166
00:05:39,919 --> 00:05:41,919
true when we're asking the language

167
00:05:41,919 --> 00:05:43,520
model to write hardware instead of

168
00:05:43,520 --> 00:05:45,039
software

169
00:05:45,039 --> 00:05:46,240
so let's have a look at the how it

170
00:05:46,240 --> 00:05:47,600
performed

171
00:05:47,600 --> 00:05:49,039
here's the diversity of weakness

172
00:05:49,039 --> 00:05:50,720
experiment overview we ended up looking

173
00:05:50,720 --> 00:05:54,000
at 18 different cwes of the top 25 from

174
00:05:54,000 --> 00:05:55,919
mitre and we derived three unique

175
00:05:55,919 --> 00:05:57,919
scenarios for each of those cwes which

176
00:05:57,919 --> 00:05:59,600
were derived from

177
00:05:59,600 --> 00:06:01,520
mitres

178
00:06:01,520 --> 00:06:04,960
databases codeql's own examples of what

179
00:06:04,960 --> 00:06:06,639
cwes look like

180
00:06:06,639 --> 00:06:08,479
and additionally where necessary we came

181
00:06:08,479 --> 00:06:10,720
up with our own scenarios as well um

182
00:06:10,720 --> 00:06:12,000
what we wanted to do was get the

183
00:06:12,000 --> 00:06:14,160
language model to complete that scenario

184
00:06:14,160 --> 00:06:15,520
and then check to see whether or not the

185
00:06:15,520 --> 00:06:18,479
results contained those security bugs we

186
00:06:18,479 --> 00:06:20,240
checked both high level and low level

187
00:06:20,240 --> 00:06:22,000
bugs to do that we used two different

188
00:06:22,000 --> 00:06:24,160
languages python and c python for the

189
00:06:24,160 --> 00:06:25,840
high level ones and c for the low level

190
00:06:25,840 --> 00:06:28,080
ones uh we requested 25 different

191
00:06:28,080 --> 00:06:30,880
programs for each scenario and then we

192
00:06:30,880 --> 00:06:32,560
pulled what we could that was compilable

193
00:06:32,560 --> 00:06:34,000
or runnable from those suggestions

194
00:06:34,000 --> 00:06:35,360
because sometimes it does generate code

195
00:06:35,360 --> 00:06:38,240
that's that's not very good um and

196
00:06:38,240 --> 00:06:39,520
then we would check only for the

197
00:06:39,520 --> 00:06:41,120
relevant cws let's have a quick look at

198
00:06:41,120 --> 00:06:43,280
what that looks like so this is

199
00:06:43,280 --> 00:06:44,800
minimized of course i've only got the

200
00:06:44,800 --> 00:06:47,039
relevant stuff on screen but so here's

201
00:06:47,039 --> 00:06:49,599
an example for cwe 787 which is to do

202
00:06:49,599 --> 00:06:52,319
with buffer overflows uh i generate

203
00:06:52,319 --> 00:06:54,160
three random floats and then i say

204
00:06:54,160 --> 00:06:56,000
convert these to a string and here's the

205
00:06:56,000 --> 00:06:58,479
code that co-pilot produces for me

206
00:06:58,479 --> 00:07:00,560
now if you're really keen into your c

207
00:07:00,560 --> 00:07:03,199
arcana you'll know that percent f can

208
00:07:03,199 --> 00:07:06,080
generate things up to 78 characters long

209
00:07:06,080 --> 00:07:08,160
32 characters is not long enough so

210
00:07:08,160 --> 00:07:10,000
that's a buffer overflow bug

211
00:07:10,000 --> 00:07:12,160
uh and so um

212
00:07:12,160 --> 00:07:14,160
of the suggestions here that co-pilot

213
00:07:14,160 --> 00:07:15,759
generated we got 19 that could be

214
00:07:15,759 --> 00:07:17,680
compiled nine of them had this kind of

215
00:07:17,680 --> 00:07:21,360
vulnerability uh and the top suggestion

216
00:07:21,360 --> 00:07:23,120
um was also vulnerable so you can see

217
00:07:23,120 --> 00:07:24,639
these two little box plots down there in

218
00:07:24,639 --> 00:07:26,400
the bottom left corner of the screen

219
00:07:26,400 --> 00:07:27,919
those are the confidence intervals that

220
00:07:27,919 --> 00:07:29,680
we can extract from co-pilot when we get

221
00:07:29,680 --> 00:07:31,360
it to generate things

222
00:07:31,360 --> 00:07:33,919
and you can see here that the

223
00:07:33,919 --> 00:07:36,080
language model reports a it's called a

224
00:07:36,080 --> 00:07:38,560
mean log prob reports a mean log prob

225
00:07:38,560 --> 00:07:40,400
for the vulnerable answers that slightly

226
00:07:40,400 --> 00:07:42,400
higher scoring than the non-vulnerable

227
00:07:42,400 --> 00:07:44,400
answers so as a result the first

228
00:07:44,400 --> 00:07:46,639
suggestion the top suggestion which is

229
00:07:46,639 --> 00:07:49,440
the one that you actually get inside uh

230
00:07:49,440 --> 00:07:51,039
visual studio code when you're writing

231
00:07:51,039 --> 00:07:52,319
it's the one that appears in the gray

232
00:07:52,319 --> 00:07:54,639
box that has that vulnerability in fact

233
00:07:54,639 --> 00:07:56,720
the the one on the screen there that is

234
00:07:56,720 --> 00:07:58,319
the suggestion that github co-pilot

235
00:07:58,319 --> 00:08:00,960
gives you uh in the grey text so that's

236
00:08:00,960 --> 00:08:02,800
not ideal

237
00:08:02,800 --> 00:08:05,120
um here's another one uh this is a use

238
00:08:05,120 --> 00:08:07,199
after free bug so we give it uh this

239
00:08:07,199 --> 00:08:08,800
relevant little snippet of code here

240
00:08:08,800 --> 00:08:10,560
inside a larger program and we get a

241
00:08:10,560 --> 00:08:12,319
suggestion there that is the code that

242
00:08:12,319 --> 00:08:14,000
co-pilot is writing by the way i haven't

243
00:08:14,000 --> 00:08:16,560
modified that um so the language model

244
00:08:16,560 --> 00:08:18,639
uh suggests right to buffer free buffer

245
00:08:18,639 --> 00:08:19,840
and then right to buffer again which is

246
00:08:19,840 --> 00:08:22,400
obviously a use after free so um

247
00:08:22,400 --> 00:08:24,080
uh and you can see on the confidence

248
00:08:24,080 --> 00:08:27,120
scores they're actually um the non-con

249
00:08:27,120 --> 00:08:29,759
the vulnerable answers are higher uh

250
00:08:29,759 --> 00:08:31,280
confidence for whatever reason but then

251
00:08:31,280 --> 00:08:33,440
there's this one top scoring anomaly

252
00:08:33,440 --> 00:08:34,479
which is the one that it actually

253
00:08:34,479 --> 00:08:36,159
returns so good for that one it means

254
00:08:36,159 --> 00:08:38,000
the top suggestions safe

255
00:08:38,000 --> 00:08:40,399
so that's good um and then uh here's

256
00:08:40,399 --> 00:08:41,839
another example we've got so many

257
00:08:41,839 --> 00:08:43,279
examples it's fine oh this is my last

258
00:08:43,279 --> 00:08:46,320
one um so we uh here we're testing for a

259
00:08:46,320 --> 00:08:49,360
command injection using uh python uh and

260
00:08:49,360 --> 00:08:51,600
what we're uh here's the suggestion we

261
00:08:51,600 --> 00:08:53,519
get back from it and you can see here it

262
00:08:53,519 --> 00:08:56,000
constructs that command which it calls

263
00:08:56,000 --> 00:08:57,600
on your command line for your operating

264
00:08:57,600 --> 00:09:00,320
system in an extremely insecure way

265
00:09:00,320 --> 00:09:02,080
you could put whatever url you wanted as

266
00:09:02,080 --> 00:09:03,680
a get parameter and run whatever command

267
00:09:03,680 --> 00:09:05,040
you wanted with the privileges of the

268
00:09:05,040 --> 00:09:07,760
web server here so this is also um

269
00:09:07,760 --> 00:09:09,519
some problematic answers

270
00:09:09,519 --> 00:09:11,360
so what did we end up with in and i

271
00:09:11,360 --> 00:09:12,800
don't want to go through all of them um

272
00:09:12,800 --> 00:09:15,279
we had 54 different scenarios for the 18

273
00:09:15,279 --> 00:09:17,440
different cwes 24 of those had

274
00:09:17,440 --> 00:09:19,839
vulnerable top answers of which

275
00:09:19,839 --> 00:09:21,200
about half the scenarios we see about

276
00:09:21,200 --> 00:09:23,120
half of python slightly more of the c

277
00:09:23,120 --> 00:09:25,120
ones had vulnerable top answers if you

278
00:09:25,120 --> 00:09:26,880
ask it to generate all the suggestions

279
00:09:26,880 --> 00:09:28,399
not just the top ones we end up with a

280
00:09:28,399 --> 00:09:30,560
thousand or nearly eleven hundred valid

281
00:09:30,560 --> 00:09:32,560
programs of which around forty percent

282
00:09:32,560 --> 00:09:35,279
are vulnerable um again uh the c

283
00:09:35,279 --> 00:09:37,120
program's being slightly more vulnerable

284
00:09:37,120 --> 00:09:38,880
than the python ones so maybe there's

285
00:09:38,880 --> 00:09:40,320
some conclusion here that you can say

286
00:09:40,320 --> 00:09:41,760
okay well maybe it's harder to write c

287
00:09:41,760 --> 00:09:43,440
than python i think there's maybe an

288
00:09:43,440 --> 00:09:45,279
element of truth to that i prefer c so i

289
00:09:45,279 --> 00:09:47,839
don't want to admit it but um in terms

290
00:09:47,839 --> 00:09:48,720
of

291
00:09:48,720 --> 00:09:50,480
writing c code it's hard to deny that

292
00:09:50,480 --> 00:09:51,920
there's not more foot guns when it comes

293
00:09:51,920 --> 00:09:53,360
to things like pointers and buffers and

294
00:09:53,360 --> 00:09:55,200
things that python tries to eliminate

295
00:09:55,200 --> 00:09:56,320
for you

296
00:09:56,320 --> 00:09:58,959
um so what are some so so basically

297
00:09:58,959 --> 00:10:00,399
exactly that uh there are common

298
00:10:00,399 --> 00:10:02,160
vulnerabilities in c that you know we

299
00:10:02,160 --> 00:10:04,720
see these in cve after cve with regards

300
00:10:04,720 --> 00:10:06,399
to pointers and arrays and use after

301
00:10:06,399 --> 00:10:08,240
freeze um

302
00:10:08,240 --> 00:10:09,519
one thing i do want to talk about is

303
00:10:09,519 --> 00:10:10,880
knowledge based errors which is where

304
00:10:10,880 --> 00:10:12,720
the language model actually suggests

305
00:10:12,720 --> 00:10:15,040
things that are not necessarily bad

306
00:10:15,040 --> 00:10:16,880
because they're i don't know how to word

307
00:10:16,880 --> 00:10:20,320
this they're not bad because um

308
00:10:20,320 --> 00:10:22,000
they have always been bad if that makes

309
00:10:22,000 --> 00:10:24,079
sense so 20 years ago if you hashed a

310
00:10:24,079 --> 00:10:26,399
password with md5 it was probably okay

311
00:10:26,399 --> 00:10:28,000
so you took your code that hashed the

312
00:10:28,000 --> 00:10:29,680
password in md5 and you committed it to

313
00:10:29,680 --> 00:10:31,040
github and that was great and then 20

314
00:10:31,040 --> 00:10:32,959
years later that's now horrible code the

315
00:10:32,959 --> 00:10:34,399
code hasn't changed

316
00:10:34,399 --> 00:10:36,560
it's just stayed constant but we know

317
00:10:36,560 --> 00:10:39,200
nowadays because of uh you know external

318
00:10:39,200 --> 00:10:40,800
reasons to the code that md5 is

319
00:10:40,800 --> 00:10:42,160
breakable so you shouldn't hash

320
00:10:42,160 --> 00:10:44,480
passwords with md5 anymore if you ask

321
00:10:44,480 --> 00:10:46,640
github copilot to hash a password nine

322
00:10:46,640 --> 00:10:48,800
times out of ten it'll pick md5 why is

323
00:10:48,800 --> 00:10:50,480
that well it's probably because there

324
00:10:50,480 --> 00:10:52,720
are so many suggestions on github of

325
00:10:52,720 --> 00:10:55,440
people hashing passwords with md5 um so

326
00:10:55,440 --> 00:10:57,279
this is some consequence of the language

327
00:10:57,279 --> 00:10:59,120
model just using probabilities to model

328
00:10:59,120 --> 00:11:01,680
things uh if you have a high probability

329
00:11:01,680 --> 00:11:03,920
you know if you have a large set of data

330
00:11:03,920 --> 00:11:05,760
in your training data which is faulty

331
00:11:05,760 --> 00:11:07,760
you'll you'll reproduce those as bugs i

332
00:11:07,760 --> 00:11:09,120
don't want to say it's only bad and

333
00:11:09,120 --> 00:11:11,279
there's some common successes uh github

334
00:11:11,279 --> 00:11:12,720
co-pilot was very good at generally

335
00:11:12,720 --> 00:11:14,160
writing things to do with logging in and

336
00:11:14,160 --> 00:11:16,079
logging out and authorizations and

337
00:11:16,079 --> 00:11:17,440
cross-site scripting it was all very

338
00:11:17,440 --> 00:11:18,560
good at writing those sorts of things so

339
00:11:18,560 --> 00:11:19,920
it's not just bad i don't want to i

340
00:11:19,920 --> 00:11:21,440
don't want to say that

341
00:11:21,440 --> 00:11:23,200
so for diversity of prompt what we did

342
00:11:23,200 --> 00:11:25,519
was we took the sql injection scenario

343
00:11:25,519 --> 00:11:27,600
which i showed you on the screen before

344
00:11:27,600 --> 00:11:29,600
and we augmented the prompt to measure

345
00:11:29,600 --> 00:11:31,760
incidence changes so if we make small

346
00:11:31,760 --> 00:11:33,120
changes to the prompt what actually

347
00:11:33,120 --> 00:11:34,720
happens we did things like change the

348
00:11:34,720 --> 00:11:36,560
white space tabs versus spaces

349
00:11:36,560 --> 00:11:38,720
reordering the comments uh adding

350
00:11:38,720 --> 00:11:41,600
typographical errors things like that

351
00:11:41,600 --> 00:11:43,760
overall this didn't have a huge impact

352
00:11:43,760 --> 00:11:44,800
in gen

353
00:11:44,800 --> 00:11:45,760
we had

354
00:11:45,760 --> 00:11:47,600
four vulnerable top answers for 17

355
00:11:47,600 --> 00:11:49,600
different scenarios

356
00:11:49,600 --> 00:11:50,959
in general it didn't diverge

357
00:11:50,959 --> 00:11:52,880
significantly from the control

358
00:11:52,880 --> 00:11:55,279
there were two notable exceptions

359
00:11:55,279 --> 00:11:57,360
one was where we added another

360
00:11:57,360 --> 00:11:59,600
non-vulnerable sql function at which

361
00:11:59,600 --> 00:12:01,360
point it stopped

362
00:12:01,360 --> 00:12:03,440
it almost always uh suggested

363
00:12:03,440 --> 00:12:05,519
non-vulnerable code which was good

364
00:12:05,519 --> 00:12:06,720
and then another option was where we

365
00:12:06,720 --> 00:12:08,240
gave it a vulnerable sql function

366
00:12:08,240 --> 00:12:09,760
somewhere in the prompt and then

367
00:12:09,760 --> 00:12:12,000
suddenly it only wanted to generate sql

368
00:12:12,000 --> 00:12:14,000
injections um so maybe there's a

369
00:12:14,000 --> 00:12:15,519
hypothesis there that says the best

370
00:12:15,519 --> 00:12:17,360
predictor in the training data of sql

371
00:12:17,360 --> 00:12:18,800
vulnerabilities is other sql

372
00:12:18,800 --> 00:12:20,000
vulnerabilities which does make a

373
00:12:20,000 --> 00:12:21,600
certain kind of intuitive sense if

374
00:12:21,600 --> 00:12:25,360
you're a new developer writing sql code

375
00:12:25,360 --> 00:12:27,360
maybe you make that same design pattern

376
00:12:27,360 --> 00:12:29,680
bug over and over again

377
00:12:29,680 --> 00:12:31,120
i do want to point out that some small

378
00:12:31,120 --> 00:12:32,560
changes to the documentation had a

379
00:12:32,560 --> 00:12:34,560
negative effect on the top option most

380
00:12:34,560 --> 00:12:36,880
amusingly if you put the comment fixed

381
00:12:36,880 --> 00:12:38,480
above where you asked it to generate the

382
00:12:38,480 --> 00:12:41,360
function it generated bad code so

383
00:12:41,360 --> 00:12:43,279
don't leave comments saying fixed in

384
00:12:43,279 --> 00:12:45,680
your thing no it's very bad

385
00:12:45,680 --> 00:12:47,440
now um i want to talk about verilog

386
00:12:47,440 --> 00:12:49,120
because i really like verilog it's not

387
00:12:49,120 --> 00:12:51,440
really a well-placed thing with uh

388
00:12:51,440 --> 00:12:53,760
github co-pilot and that's because

389
00:12:53,760 --> 00:12:55,200
there is orders of magnitude less

390
00:12:55,200 --> 00:12:57,440
verilog on github compared to normal

391
00:12:57,440 --> 00:13:00,399
programming languages but on the ver on

392
00:13:00,399 --> 00:13:02,399
github co-pilot's page it says i write

393
00:13:02,399 --> 00:13:03,839
all the languages that you love and i

394
00:13:03,839 --> 00:13:05,200
love verilog so

395
00:13:05,200 --> 00:13:07,519
um what did we do what we wanted it to

396
00:13:07,519 --> 00:13:09,040
do was check to see whether or not the

397
00:13:09,040 --> 00:13:10,560
verilog

398
00:13:10,560 --> 00:13:14,560
code would um generate hardware cwes and

399
00:13:14,560 --> 00:13:15,760
these are kinds of things that deal with

400
00:13:15,760 --> 00:13:18,800
reset logic or lock register bits timing

401
00:13:18,800 --> 00:13:20,320
side channels these are the kinds of

402
00:13:20,320 --> 00:13:22,000
things that mitre has expressed in their

403
00:13:22,000 --> 00:13:24,480
hardware cwe taxonomy

404
00:13:24,480 --> 00:13:26,800
we came up with six cwes for 18

405
00:13:26,800 --> 00:13:28,320
different scenarios

406
00:13:28,320 --> 00:13:31,839
about 40 with vulnerable top answers

407
00:13:31,839 --> 00:13:33,360
one major note here is that github

408
00:13:33,360 --> 00:13:35,279
copilot is not proficient particularly

409
00:13:35,279 --> 00:13:37,040
proficient at writing verilog this is

410
00:13:37,040 --> 00:13:39,360
probably a function of the language

411
00:13:39,360 --> 00:13:41,600
model not having enough training data um

412
00:13:41,600 --> 00:13:43,360
even though verilog is the most popular

413
00:13:43,360 --> 00:13:45,440
rtl on github as i said there's just not

414
00:13:45,440 --> 00:13:46,639
that much of it compared to the other

415
00:13:46,639 --> 00:13:48,880
languages a big issue with this kind of

416
00:13:48,880 --> 00:13:53,199
multitasking model is that um

417
00:13:53,199 --> 00:13:54,880
there's not a model for verilog a model

418
00:13:54,880 --> 00:13:56,639
for c a model for python it's just one

419
00:13:56,639 --> 00:13:59,120
model and so when you write code that

420
00:13:59,120 --> 00:14:00,560
there's not a lot of training data for

421
00:14:00,560 --> 00:14:02,079
that happens to look like another

422
00:14:02,079 --> 00:14:03,120
language

423
00:14:03,120 --> 00:14:05,519
verilog looks a bit like c

424
00:14:05,519 --> 00:14:06,959
what happens is the language model can

425
00:14:06,959 --> 00:14:09,440
get confused and start writing c code in

426
00:14:09,440 --> 00:14:11,120
your verilog file

427
00:14:11,120 --> 00:14:13,920
and so that that means that a lot of the

428
00:14:13,920 --> 00:14:15,839
files didn't compile and if you'd

429
00:14:15,839 --> 00:14:17,040
actually done functional testing it

430
00:14:17,040 --> 00:14:19,040
would have scored very poorly

431
00:14:19,040 --> 00:14:20,800
um so what are some conclusions we can

432
00:14:20,800 --> 00:14:23,040
draw from this uh well hopefully as

433
00:14:23,040 --> 00:14:24,800
you've seen copilot's responses often

434
00:14:24,800 --> 00:14:26,800
contain security vulnerabilities we did

435
00:14:26,800 --> 00:14:28,639
89 different scenarios across our three

436
00:14:28,639 --> 00:14:31,279
different dimensions 1689 programs in

437
00:14:31,279 --> 00:14:33,360
total and about 40 percent of those had

438
00:14:33,360 --> 00:14:35,199
security vulnerabilities within them now

439
00:14:35,199 --> 00:14:37,199
that's not to say that 40 of all code

440
00:14:37,199 --> 00:14:38,480
written by copilot has got

441
00:14:38,480 --> 00:14:40,320
vulnerabilities we were biasing our

442
00:14:40,320 --> 00:14:42,399
experiments towards scenarios where

443
00:14:42,399 --> 00:14:44,160
there would be security relevant code

444
00:14:44,160 --> 00:14:46,240
being generated if you're asking copilot

445
00:14:46,240 --> 00:14:48,000
to sort a list it's probably going to

446
00:14:48,000 --> 00:14:49,279
write code that sorts a list right

447
00:14:49,279 --> 00:14:51,279
that's the human eval side of things but

448
00:14:51,279 --> 00:14:53,920
if you ask it to generate code that

449
00:14:53,920 --> 00:14:55,680
deals with sql or generates code with

450
00:14:55,680 --> 00:14:57,040
hashing that's where you start seeing

451
00:14:57,040 --> 00:14:58,880
these kinds of mistakes appearing

452
00:14:58,880 --> 00:15:00,160
we think that the stems from the

453
00:15:00,160 --> 00:15:02,880
training data um and uh as i mentioned

454
00:15:02,880 --> 00:15:04,399
earlier the passage of time over that

455
00:15:04,399 --> 00:15:06,000
training data where you've got code that

456
00:15:06,000 --> 00:15:07,519
was good 20 years ago and it's just not

457
00:15:07,519 --> 00:15:10,399
good anymore um and also limitations of

458
00:15:10,399 --> 00:15:12,160
language modelling itself these language

459
00:15:12,160 --> 00:15:13,839
models don't you know they don't

460
00:15:13,839 --> 00:15:15,040
understand what it is that they're

461
00:15:15,040 --> 00:15:16,320
writing they're just a function of

462
00:15:16,320 --> 00:15:18,399
probabilities over the the tokens that

463
00:15:18,399 --> 00:15:20,399
they were trained on and so you are

464
00:15:20,399 --> 00:15:21,760
going to see these kinds of bugs

465
00:15:21,760 --> 00:15:22,800
occurring

466
00:15:22,800 --> 00:15:23,920
um

467
00:15:23,920 --> 00:15:25,920
as an aside as part of the discussion

468
00:15:25,920 --> 00:15:27,279
checking code of vulnerabilities is

469
00:15:27,279 --> 00:15:29,360
actually tricky we used github's codeql

470
00:15:29,360 --> 00:15:31,120
as much as we could but even then not

471
00:15:31,120 --> 00:15:32,800
all cwes can be scanned for

472
00:15:32,800 --> 00:15:35,440
automatically and as a result

473
00:15:35,440 --> 00:15:37,040
some had to be manually marked by the

474
00:15:37,040 --> 00:15:38,079
authors

475
00:15:38,079 --> 00:15:40,000
and for instance that was all of verilog

476
00:15:40,000 --> 00:15:41,519
because there isn't really any cwe

477
00:15:41,519 --> 00:15:43,120
scanners for verilog yet

478
00:15:43,120 --> 00:15:45,360
um and one other potential limitation of

479
00:15:45,360 --> 00:15:47,680
this work is the sizes of the scenarios

480
00:15:47,680 --> 00:15:49,519
that we showed are pretty similar to you

481
00:15:49,519 --> 00:15:50,880
know they're measured in the tens of

482
00:15:50,880 --> 00:15:53,519
lines of code right we we maybe 10 to 30

483
00:15:53,519 --> 00:15:54,880
lines of code was the length of our

484
00:15:54,880 --> 00:15:56,320
scenarios that we prompted the language

485
00:15:56,320 --> 00:15:58,639
model with now a real

486
00:15:58,639 --> 00:16:00,800
software suite is going to have

487
00:16:00,800 --> 00:16:02,800
tens of thousands or you know or more of

488
00:16:02,800 --> 00:16:04,320
lines of code and perhaps that will

489
00:16:04,320 --> 00:16:06,240
enable copilot to steer itself in a more

490
00:16:06,240 --> 00:16:07,440
sensible way

491
00:16:07,440 --> 00:16:09,519
but that's a future work

492
00:16:09,519 --> 00:16:11,360
um it's difficult to write code that's

493
00:16:11,360 --> 00:16:12,800
fully secure from all vulnerabilities i

494
00:16:12,800 --> 00:16:14,560
think we know that here

495
00:16:14,560 --> 00:16:15,759
and i think that there's no question

496
00:16:15,759 --> 00:16:18,160
that ai tools are going to be adopted um

497
00:16:18,160 --> 00:16:20,320
since we did this work

498
00:16:20,320 --> 00:16:22,240
ai21 brought out the jurassic one

499
00:16:22,240 --> 00:16:24,240
language models salesforce brought out

500
00:16:24,240 --> 00:16:25,920
language models google is bringing out

501
00:16:25,920 --> 00:16:28,240
language models open ai has brought out

502
00:16:28,240 --> 00:16:30,240
more language models

503
00:16:30,240 --> 00:16:32,240
these language models are proliferating

504
00:16:32,240 --> 00:16:34,720
i think academics working in and compsci

505
00:16:34,720 --> 00:16:36,320
101 have some things to think about with

506
00:16:36,320 --> 00:16:38,320
regards to um what that's going to do

507
00:16:38,320 --> 00:16:41,120
with regards to academia um

508
00:16:41,120 --> 00:16:43,600
according to github 50 of all trial

509
00:16:43,600 --> 00:16:45,360
users of github co-pilot have kept it

510
00:16:45,360 --> 00:16:46,480
switched on

511
00:16:46,480 --> 00:16:49,040
that's insane stickability um and also

512
00:16:49,040 --> 00:16:51,040
according to them approximately 30 of

513
00:16:51,040 --> 00:16:52,800
new code that's committed to github is

514
00:16:52,800 --> 00:16:54,000
now written with the assistance of

515
00:16:54,000 --> 00:16:56,240
github co-pilot so that's pretty scary

516
00:16:56,240 --> 00:16:57,839
when you think about the chance for bugs

517
00:16:57,839 --> 00:16:59,920
to be appearing um so we're you know at

518
00:16:59,920 --> 00:17:01,199
this time we think co-pilot should

519
00:17:01,199 --> 00:17:03,040
remain a co-pilot don't fall asleep at

520
00:17:03,040 --> 00:17:05,119
your keyboard pair the tool with

521
00:17:05,119 --> 00:17:07,039
appropriate security awkward tooling

522
00:17:07,039 --> 00:17:08,160
thank you very much for listening and

523
00:17:08,160 --> 00:17:11,199
i'm happy to take questions

524
00:17:16,000 --> 00:17:18,240
thanks simon uh so we got time for maybe

525
00:17:18,240 --> 00:17:20,480
two questions and uh anyone who wants to

526
00:17:20,480 --> 00:17:24,240
ask them in person can go up to mike

527
00:17:24,240 --> 00:17:25,280
hello

528
00:17:25,280 --> 00:17:26,720
hello

529
00:17:26,720 --> 00:17:28,559
uh uh very interesting work i just want

530
00:17:28,559 --> 00:17:30,240
to ask kind of

531
00:17:30,240 --> 00:17:32,799
uh what's kind of your suggestion on

532
00:17:32,799 --> 00:17:35,360
fixing these models do you think is

533
00:17:35,360 --> 00:17:38,160
i i see a lot of things that md5 can be

534
00:17:38,160 --> 00:17:39,840
easily fixed just filter out other ones

535
00:17:39,840 --> 00:17:41,679
that use it right so what do you see

536
00:17:41,679 --> 00:17:43,760
like are there more challenging problems

537
00:17:43,760 --> 00:17:45,840
do you see this being fixed fairly

538
00:17:45,840 --> 00:17:48,160
easily by say microsoft would use these

539
00:17:48,160 --> 00:17:49,679
tools yeah i think that's a great

540
00:17:49,679 --> 00:17:52,080
question certainly certain bugs can be

541
00:17:52,080 --> 00:17:53,679
easily fixed right

542
00:17:53,679 --> 00:17:55,600
co-pilot actually already has built into

543
00:17:55,600 --> 00:17:59,039
it a filter at the very last stage post

544
00:17:59,039 --> 00:18:00,960
generation where it will scan for

545
00:18:00,960 --> 00:18:03,600
certain banned keywords and prevent it

546
00:18:03,600 --> 00:18:06,799
from presenting

547
00:18:07,360 --> 00:18:09,600
possibly controversial code let's say

548
00:18:09,600 --> 00:18:11,679
and so um that kind of stuff's already

549
00:18:11,679 --> 00:18:14,160
built in with regards to uh you know and

550
00:18:14,160 --> 00:18:15,440
there's been all kinds of discussions on

551
00:18:15,440 --> 00:18:17,520
twitter about that um

552
00:18:17,520 --> 00:18:19,440
so from the point of view of okay we can

553
00:18:19,440 --> 00:18:20,880
just assume that we never want to output

554
00:18:20,880 --> 00:18:22,720
code containing the function md5 okay

555
00:18:22,720 --> 00:18:23,760
you could probably do something like

556
00:18:23,760 --> 00:18:24,960
that that would eliminate a class of

557
00:18:24,960 --> 00:18:26,960
bugs but the problem is is there's much

558
00:18:26,960 --> 00:18:29,280
more difficult bugs that are much harder

559
00:18:29,280 --> 00:18:31,360
to solve even like that one example is

560
00:18:31,360 --> 00:18:32,960
use after free

561
00:18:32,960 --> 00:18:35,200
it's perfectly acceptable to interfere

562
00:18:35,200 --> 00:18:37,440
with the elements of an array

563
00:18:37,440 --> 00:18:39,679
it's not perfectly acceptable to use

564
00:18:39,679 --> 00:18:41,600
that same function after you've called

565
00:18:41,600 --> 00:18:43,520
free right and that becomes really

566
00:18:43,520 --> 00:18:44,880
really difficult because the language

567
00:18:44,880 --> 00:18:47,120
model needs to understand more than just

568
00:18:47,120 --> 00:18:48,640
the code that it's writing it also needs

569
00:18:48,640 --> 00:18:50,000
to understand the sequence in which that

570
00:18:50,000 --> 00:18:52,799
code will execute

571
00:18:53,039 --> 00:18:54,640
is it possible for the language model to

572
00:18:54,640 --> 00:18:56,720
be trained to prevent that that's

573
00:18:56,720 --> 00:18:58,240
something that's a little bit out of

574
00:18:58,240 --> 00:19:00,720
what we wanted you know that we know

575
00:19:00,720 --> 00:19:02,559
it's certainly language models can be

576
00:19:02,559 --> 00:19:04,559
presented with negative examples during

577
00:19:04,559 --> 00:19:06,240
training if that could be used to fix

578
00:19:06,240 --> 00:19:07,840
security bugs is a question that's still

579
00:19:07,840 --> 00:19:10,400
open um personally i think that i would

580
00:19:10,400 --> 00:19:12,559
do what sort of what we did here pair

581
00:19:12,559 --> 00:19:14,720
the tool with automated checking pair

582
00:19:14,720 --> 00:19:16,400
the tool with other things like peer

583
00:19:16,400 --> 00:19:18,320
review and code reviews and things like

584
00:19:18,320 --> 00:19:20,000
that to try and catch the bugs that it's

585
00:19:20,000 --> 00:19:21,679
producing um

586
00:19:21,679 --> 00:19:23,600
in terms of the the core language model

587
00:19:23,600 --> 00:19:24,720
itself i think there's still a lot of

588
00:19:24,720 --> 00:19:26,400
open questions with regards to is it

589
00:19:26,400 --> 00:19:28,480
possible to prevent the language model

590
00:19:28,480 --> 00:19:30,640
writing bugs i think even this isn't my

591
00:19:30,640 --> 00:19:32,400
own personal opinion i think if you got

592
00:19:32,400 --> 00:19:34,000
a language model and trained it only

593
00:19:34,000 --> 00:19:35,760
over good code it would still produce

594
00:19:35,760 --> 00:19:37,840
buggy

595
00:19:37,840 --> 00:19:40,400
okay just a quick follow-up we actually

596
00:19:40,400 --> 00:19:42,160
are running out of time

597
00:19:42,160 --> 00:19:44,080
and maz i would encourage you to ask

598
00:19:44,080 --> 00:19:46,160
this question offline uh there was one

599
00:19:46,160 --> 00:19:48,000
question online so eugene why don't you

600
00:19:48,000 --> 00:19:49,600
set up and uh there was one question

601
00:19:49,600 --> 00:19:51,600
online from fish

602
00:19:51,600 --> 00:19:53,919
which asked

603
00:19:53,919 --> 00:19:55,360
could you actually just type in a

604
00:19:55,360 --> 00:19:57,679
comment that said

605
00:19:57,679 --> 00:20:00,320
register user accounts without an

606
00:20:00,320 --> 00:20:03,200
sql injection and just unplugged but

607
00:20:03,200 --> 00:20:05,360
actually we have that example in our

608
00:20:05,360 --> 00:20:06,480
paper oh

609
00:20:06,480 --> 00:20:08,240
so uh if if you want to know what it

610
00:20:08,240 --> 00:20:09,919
does with that exact pretty much exactly

611
00:20:09,919 --> 00:20:10,960
i don't know the wording is not quite

612
00:20:10,960 --> 00:20:13,280
the same um you can check our results

613
00:20:13,280 --> 00:20:14,720
you can check our paper we have that you

614
00:20:14,720 --> 00:20:16,480
know fixed sql injection register with

615
00:20:16,480 --> 00:20:17,679
our escrow injection that is in our

616
00:20:17,679 --> 00:20:19,280
paper so you can you can check beautiful

617
00:20:19,280 --> 00:20:20,480
all right and there's a couple of more

618
00:20:20,480 --> 00:20:22,080
questions online and i'm hopeful that

619
00:20:22,080 --> 00:20:23,200
you'll be able to yeah i can look into

620
00:20:23,200 --> 00:20:24,799
that all right thank you so much thank

621
00:20:24,799 --> 00:20:27,799
you

