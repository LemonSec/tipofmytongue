1
00:00:02,080 --> 00:00:04,560
hello everyone this is jim hyden from

2
00:00:04,560 --> 00:00:06,720
the university of marvin i will

3
00:00:06,720 --> 00:00:09,040
introduce some works about timing and

4
00:00:09,040 --> 00:00:11,440
floating-point attacks on differential

5
00:00:11,440 --> 00:00:14,480
privacy systems

6
00:00:14,559 --> 00:00:16,480
first i wanted to introduce the

7
00:00:16,480 --> 00:00:20,400
contributors of this study that animal

8
00:00:20,400 --> 00:00:23,439
ben olea and me

9
00:00:23,439 --> 00:00:25,519
we have two main contributions the first

10
00:00:25,519 --> 00:00:27,760
contribution is floating point attacks

11
00:00:27,760 --> 00:00:29,840
on differential positive systems that

12
00:00:29,840 --> 00:00:32,079
are based on continuous gaussian the

13
00:00:32,079 --> 00:00:34,320
second contribution is terminal attacks

14
00:00:34,320 --> 00:00:36,399
on differential priority systems that

15
00:00:36,399 --> 00:00:38,719
are based on discrete class or discrete

16
00:00:38,719 --> 00:00:39,920
caution

17
00:00:39,920 --> 00:00:42,559
we showed that our attacks work against

18
00:00:42,559 --> 00:00:44,719
two open source libraries the first one

19
00:00:44,719 --> 00:00:47,680
is obverse or pathwage the second one is

20
00:00:47,680 --> 00:00:51,840
the google differential privacy library

21
00:00:51,840 --> 00:00:53,920
there are many cases or unexpected

22
00:00:53,920 --> 00:00:56,239
process leakage in the process or data

23
00:00:56,239 --> 00:00:59,120
analysis and some also could be very

24
00:00:59,120 --> 00:01:01,760
sensitive for example if the data of

25
00:01:01,760 --> 00:01:03,199
this patient

26
00:01:03,199 --> 00:01:04,959
is used to train a machine learning

27
00:01:04,959 --> 00:01:06,000
model

28
00:01:06,000 --> 00:01:08,400
diagnosing diabetes and the way that

29
00:01:08,400 --> 00:01:11,680
this information they're conducting

30
00:01:11,680 --> 00:01:13,680
membership influencer text

31
00:01:13,680 --> 00:01:15,360
on this model

32
00:01:15,360 --> 00:01:18,000
then we know that this patient possibly

33
00:01:18,000 --> 00:01:20,000
has diabetes

34
00:01:20,000 --> 00:01:22,479
and this is a strong violation of this

35
00:01:22,479 --> 00:01:25,520
patient's privacy

36
00:01:25,759 --> 00:01:27,759
researchers have proposed differential

37
00:01:27,759 --> 00:01:30,320
priority as a quantum method against

38
00:01:30,320 --> 00:01:32,560
privacy leakage in the process of data

39
00:01:32,560 --> 00:01:33,680
analysis

40
00:01:33,680 --> 00:01:36,079
differential priority means that for

41
00:01:36,079 --> 00:01:38,400
enabling data sets d

42
00:01:38,400 --> 00:01:41,520
and d prime which differ in a single

43
00:01:41,520 --> 00:01:42,560
record

44
00:01:42,560 --> 00:01:45,200
any subset multiples are possible for

45
00:01:45,200 --> 00:01:47,840
both d and d prime with nonzero

46
00:01:47,840 --> 00:01:50,000
probability

47
00:01:50,000 --> 00:01:52,240
this property is formally defined in

48
00:01:52,240 --> 00:01:55,280
this formula where epsilon measures the

49
00:01:55,280 --> 00:01:56,960
probability that

50
00:01:56,960 --> 00:01:59,680
the output is from d or d prime which

51
00:01:59,680 --> 00:02:02,719
can be taken as a measure for privacy

52
00:02:02,719 --> 00:02:05,360
loss and delta

53
00:02:05,360 --> 00:02:07,920
is the probability that differential

54
00:02:07,920 --> 00:02:10,080
priority does not hold

55
00:02:10,080 --> 00:02:12,720
in our attack we intended to break this

56
00:02:12,720 --> 00:02:15,360
theoretically quantified processors

57
00:02:15,360 --> 00:02:18,959
while invalidating delta

58
00:02:19,200 --> 00:02:21,760
and in our study of successful attempt

59
00:02:21,760 --> 00:02:24,319
means one can distinguish whether an

60
00:02:24,319 --> 00:02:29,119
output y comes from d or d prime

61
00:02:33,040 --> 00:02:35,040
differential priority can be obtained

62
00:02:35,040 --> 00:02:38,319
through additional noise

63
00:02:38,720 --> 00:02:41,360
this noise can be sampled from a laplace

64
00:02:41,360 --> 00:02:44,080
distribution

65
00:02:44,080 --> 00:02:47,680
or a gaussian distribution

66
00:02:47,680 --> 00:02:50,879
with this noise the final output

67
00:02:50,879 --> 00:02:54,400
is anonymized and our attacker cannot

68
00:02:54,400 --> 00:02:57,519
tell whether this output is from the

69
00:02:57,519 --> 00:03:01,280
data set d or d prime

70
00:03:01,840 --> 00:03:03,519
so the priority

71
00:03:03,519 --> 00:03:06,080
is protected for each individual in the

72
00:03:06,080 --> 00:03:08,560
data side

73
00:03:08,560 --> 00:03:10,640
as a cutting-edge privacy protection

74
00:03:10,640 --> 00:03:12,720
system differential privacy has been

75
00:03:12,720 --> 00:03:15,200
deployed by many companies such as

76
00:03:15,200 --> 00:03:16,319
google

77
00:03:16,319 --> 00:03:20,239
and apple and has been implemented in

78
00:03:20,239 --> 00:03:22,800
many libraries such as operas low

79
00:03:22,800 --> 00:03:27,040
pathogen and tensorflow privacy

80
00:03:27,040 --> 00:03:29,120
before i introduce our text on

81
00:03:29,120 --> 00:03:31,280
differential privacy systems it is

82
00:03:31,280 --> 00:03:33,519
important to know that outside model

83
00:03:33,519 --> 00:03:36,080
assumes that the attacker observes the

84
00:03:36,080 --> 00:03:38,959
dp protected output y and the attacker

85
00:03:38,959 --> 00:03:40,959
knows the neighboring datasets d and d

86
00:03:40,959 --> 00:03:43,120
prime which differ in a single record

87
00:03:43,120 --> 00:03:45,840
and the attacker knows the dp mechanism

88
00:03:45,840 --> 00:03:48,080
that is implemented

89
00:03:48,080 --> 00:03:50,640
but does not know the random is used by

90
00:03:50,640 --> 00:03:52,799
it and the attacker's goal is to

91
00:03:52,799 --> 00:03:55,519
determine if d or d prime was used in

92
00:03:55,519 --> 00:03:58,640
the computation of y

93
00:03:58,640 --> 00:04:00,400
however the implementation of

94
00:04:00,400 --> 00:04:02,159
differential processing often uses

95
00:04:02,159 --> 00:04:05,120
concerns not considered in theoretical

96
00:04:05,120 --> 00:04:06,239
analysis

97
00:04:06,239 --> 00:04:08,239
for example the implementation of

98
00:04:08,239 --> 00:04:10,480
differential policy involves voting

99
00:04:10,480 --> 00:04:13,519
parts and the representation standard

100
00:04:13,519 --> 00:04:17,358
for floating points into the actual e754

101
00:04:17,358 --> 00:04:19,680
in this standard the distribution of

102
00:04:19,680 --> 00:04:22,720
14-part numbers needs an uneven

103
00:04:22,720 --> 00:04:24,479
more voting point numbers are

104
00:04:24,479 --> 00:04:26,639
distributed around 0

105
00:04:26,639 --> 00:04:29,360
and last floating point numbers are

106
00:04:29,360 --> 00:04:31,840
distributed on those two sides away from

107
00:04:31,840 --> 00:04:32,880
zero

108
00:04:32,880 --> 00:04:36,240
this is inconsistent with the real

109
00:04:36,240 --> 00:04:38,560
number assumption used in the theory of

110
00:04:38,560 --> 00:04:41,440
differential priority

111
00:04:41,440 --> 00:04:43,919
because of this ion distribution or

112
00:04:43,919 --> 00:04:46,000
floating points some floating points are

113
00:04:46,000 --> 00:04:48,320
impossible for a certain function for

114
00:04:48,320 --> 00:04:51,120
example this is a sequence of contiguous

115
00:04:51,120 --> 00:04:53,120
floating points in the attribute

116
00:04:53,120 --> 00:04:55,040
standard with this sequence or falling

117
00:04:55,040 --> 00:04:58,240
points the function 100x

118
00:04:58,240 --> 00:05:01,120
misses this floating point number

119
00:05:01,120 --> 00:05:02,479
and since

120
00:05:02,479 --> 00:05:04,960
100x is a monotonic function this

121
00:05:04,960 --> 00:05:06,960
function can never output

122
00:05:06,960 --> 00:05:11,159
this floating point number

123
00:05:13,440 --> 00:05:15,440
based on this observation we are now

124
00:05:15,440 --> 00:05:18,240
conducted attacks on a glass mechanism

125
00:05:18,240 --> 00:05:20,400
and we take a step further

126
00:05:20,400 --> 00:05:22,639
conduct attacks on the caution mechanism

127
00:05:22,639 --> 00:05:25,440
which is more complicated

128
00:05:25,440 --> 00:05:27,199
the gaussian samplers used in

129
00:05:27,199 --> 00:05:29,680
differential priority systems can also

130
00:05:29,680 --> 00:05:31,840
be taken as functions and there are

131
00:05:31,840 --> 00:05:33,840
three commonly used gaussian functions

132
00:05:33,840 --> 00:05:36,240
in implementations the first one is a

133
00:05:36,240 --> 00:05:38,639
product quadrant function that is used

134
00:05:38,639 --> 00:05:41,360
in numpy the second one is about smaller

135
00:05:41,360 --> 00:05:43,520
gaussian function that is used in pad

136
00:05:43,520 --> 00:05:45,759
hodge the third one is the zebra

137
00:05:45,759 --> 00:05:48,160
articulation function that is usd in

138
00:05:48,160 --> 00:05:49,039
gold

139
00:05:49,039 --> 00:05:50,720
all those quotient functions take a

140
00:05:50,720 --> 00:05:53,199
while to draw the values from the range

141
00:05:53,199 --> 00:05:56,000
field 1 and transform them

142
00:05:56,000 --> 00:05:58,319
and output 1 or 2

143
00:05:58,319 --> 00:06:00,800
samples from the gaussian distribution

144
00:06:00,800 --> 00:06:03,600
because they are functions and they all

145
00:06:03,600 --> 00:06:05,360
use floating points

146
00:06:05,360 --> 00:06:07,600
so there are values that are impossible

147
00:06:07,600 --> 00:06:09,039
for those

148
00:06:09,039 --> 00:06:11,599
functions

149
00:06:12,160 --> 00:06:14,880
and this is the vulnerability

150
00:06:14,880 --> 00:06:17,039
we explored in our floating point

151
00:06:17,039 --> 00:06:21,840
attacks on differential process systems

152
00:06:23,440 --> 00:06:26,000
to exploit this vulnerability or

153
00:06:26,000 --> 00:06:27,840
impossible values from gaussian

154
00:06:27,840 --> 00:06:31,039
functions we designed a function called

155
00:06:31,039 --> 00:06:33,520
is feasible

156
00:06:33,520 --> 00:06:37,759
when given a gaussian noise as

157
00:06:37,759 --> 00:06:40,319
says its physical function can tell

158
00:06:40,319 --> 00:06:43,199
whether it is possible for a gaussian

159
00:06:43,199 --> 00:06:45,600
function

160
00:06:46,720 --> 00:06:49,840
whereas this disputable function

161
00:06:49,840 --> 00:06:53,220
given a noisy output of y and

162
00:06:53,220 --> 00:06:55,120
[Music]

163
00:06:55,120 --> 00:06:58,800
annoys the output fd and fd prime

164
00:06:58,800 --> 00:07:01,120
we can have two noises s

165
00:07:01,120 --> 00:07:02,560
and that's prime

166
00:07:02,560 --> 00:07:05,280
we put s and s prime to the function is

167
00:07:05,280 --> 00:07:06,560
fatable

168
00:07:06,560 --> 00:07:07,440
and

169
00:07:07,440 --> 00:07:09,440
if it is a physical function decides

170
00:07:09,440 --> 00:07:10,800
that s

171
00:07:10,800 --> 00:07:14,319
is feasible for the gaussian function

172
00:07:14,319 --> 00:07:17,599
and s prime is impossible for the

173
00:07:17,599 --> 00:07:19,039
gaussian function

174
00:07:19,039 --> 00:07:21,840
so we know definitely that

175
00:07:21,840 --> 00:07:24,479
y actually

176
00:07:24,479 --> 00:07:26,319
comes from

177
00:07:26,319 --> 00:07:27,840
the data set d

178
00:07:27,840 --> 00:07:31,120
and this violates the privacy guarantee

179
00:07:31,120 --> 00:07:34,400
of differential privacy

180
00:07:34,960 --> 00:07:37,440
we conduct our voting point attempt on

181
00:07:37,440 --> 00:07:40,080
db query that comes the number of people

182
00:07:40,080 --> 00:07:44,479
with credits bigger than 16000 and this

183
00:07:44,479 --> 00:07:47,120
db query is protected with a gaussian

184
00:07:47,120 --> 00:07:50,080
noise sampled with the

185
00:07:50,080 --> 00:07:52,960
secret caution function of the

186
00:07:52,960 --> 00:07:56,000
powder cotton function of the box mirror

187
00:07:56,000 --> 00:07:57,360
caution function

188
00:07:57,360 --> 00:07:59,520
in this attack we try to guess if a

189
00:07:59,520 --> 00:08:01,199
person with

190
00:08:01,199 --> 00:08:03,840
eighteen thousand credits

191
00:08:03,840 --> 00:08:06,639
is in the data set that is the contents

192
00:08:06,639 --> 00:08:08,879
this person and the d prime does not

193
00:08:08,879 --> 00:08:10,960
contain this person and we try to

194
00:08:10,960 --> 00:08:14,000
distinguish b and d prime

195
00:08:14,000 --> 00:08:17,039
the baseline success rate should be 50

196
00:08:17,039 --> 00:08:20,319
for random gas but our success rate is

197
00:08:20,319 --> 00:08:23,599
around 90 percent

198
00:08:23,759 --> 00:08:26,240
so our success rate indicates that we

199
00:08:26,240 --> 00:08:28,160
have totally broken the privacy

200
00:08:28,160 --> 00:08:31,919
guarantee of differential policy

201
00:08:32,559 --> 00:08:35,120
the caution mechanism that is the dpo

202
00:08:35,120 --> 00:08:37,440
gaussian noise is used in training deep

203
00:08:37,440 --> 00:08:39,360
neural networks where differentially

204
00:08:39,360 --> 00:08:40,399
private

205
00:08:40,399 --> 00:08:42,719
stochastic gradient descent

206
00:08:42,719 --> 00:08:44,560
therefore we can use our 14-pointer

207
00:08:44,560 --> 00:08:47,519
attack to determine if the training data

208
00:08:47,519 --> 00:08:50,240
includes a particular record or not okay

209
00:08:50,240 --> 00:08:52,880
in our text the data set id contains

210
00:08:52,880 --> 00:08:55,440
this record and the data set d prime

211
00:08:55,440 --> 00:08:56,800
does not contain

212
00:08:56,800 --> 00:08:58,640
this record

213
00:08:58,640 --> 00:08:59,440
and

214
00:08:59,440 --> 00:09:02,720
the baseline success rate for this

215
00:09:02,720 --> 00:09:04,720
attack should be 50

216
00:09:04,720 --> 00:09:06,160
for random gas

217
00:09:06,160 --> 00:09:09,680
but our success rate can be up to

218
00:09:09,680 --> 00:09:11,120
90 percent

219
00:09:11,120 --> 00:09:12,240
and

220
00:09:12,240 --> 00:09:14,000
this

221
00:09:14,000 --> 00:09:16,320
means that our attack successfully

222
00:09:16,320 --> 00:09:21,240
breaks the privacy guarantee or dpsjd

223
00:09:23,920 --> 00:09:26,160
to contact this floating point

224
00:09:26,160 --> 00:09:29,040
vulnerability researchers have proposed

225
00:09:29,040 --> 00:09:31,760
to use discrete distributions in the

226
00:09:31,760 --> 00:09:33,920
differential priority systems

227
00:09:33,920 --> 00:09:36,880
such as discrete advanced and discrete

228
00:09:36,880 --> 00:09:37,839
caution

229
00:09:37,839 --> 00:09:39,519
the implementations or discrete

230
00:09:39,519 --> 00:09:41,839
distributions rely on geometrical

231
00:09:41,839 --> 00:09:43,120
distribution

232
00:09:43,120 --> 00:09:46,560
which flips a clone until the first

233
00:09:46,560 --> 00:09:47,839
success

234
00:09:47,839 --> 00:09:50,399
and the third implementation transforms

235
00:09:50,399 --> 00:09:53,920
those n conflicts into a sample of the

236
00:09:53,920 --> 00:09:57,360
discrete upgrade distribution of the

237
00:09:57,360 --> 00:10:01,279
discrete gaussian distribution

238
00:10:01,839 --> 00:10:04,880
however the number or count flips in the

239
00:10:04,880 --> 00:10:07,200
geometric distribution is positively

240
00:10:07,200 --> 00:10:10,000
correlated with the sampled noise

241
00:10:10,000 --> 00:10:11,519
magnitude

242
00:10:11,519 --> 00:10:14,480
and the number of conflicts is also

243
00:10:14,480 --> 00:10:17,519
positively correlated with

244
00:10:17,519 --> 00:10:20,079
the algorithm runtime

245
00:10:20,079 --> 00:10:23,040
this news a time set channel for the tab

246
00:10:23,040 --> 00:10:26,640
to guess the noise magnitude

247
00:10:26,640 --> 00:10:31,120
based on the algorithm runtime

248
00:10:31,120 --> 00:10:34,079
and this vulnerability gives us a chance

249
00:10:34,079 --> 00:10:36,720
to break the privacy guarantee of

250
00:10:36,720 --> 00:10:38,720
differential privacy systems based on

251
00:10:38,720 --> 00:10:42,399
discrete distributions

252
00:10:43,279 --> 00:10:45,360
we have collected means or running time

253
00:10:45,360 --> 00:10:47,680
data for the discrete

254
00:10:47,680 --> 00:10:51,440
sampling algorithms and plot the

255
00:10:51,440 --> 00:10:54,160
relationship between noise magnitude and

256
00:10:54,160 --> 00:10:55,120
the

257
00:10:55,120 --> 00:10:57,519
algorithm runtime which is in

258
00:10:57,519 --> 00:10:59,040
microsecond

259
00:10:59,040 --> 00:11:00,880
we can see a clear

260
00:11:00,880 --> 00:11:02,160
positive

261
00:11:02,160 --> 00:11:04,240
linear relationship between noise

262
00:11:04,240 --> 00:11:06,640
magnitude and the

263
00:11:06,640 --> 00:11:09,120
algorithm runtime for both

264
00:11:09,120 --> 00:11:13,839
discrete of us and the discrete gaussian

265
00:11:13,839 --> 00:11:16,240
the timing set channel is very obvious

266
00:11:16,240 --> 00:11:18,959
for implementations of discrete

267
00:11:18,959 --> 00:11:21,760
distributions

268
00:11:22,480 --> 00:11:24,399
based on the time set channel we have

269
00:11:24,399 --> 00:11:27,040
observed we conduct our timing attack on

270
00:11:27,040 --> 00:11:29,440
priority sound protected with discrete

271
00:11:29,440 --> 00:11:32,320
bypass noise

272
00:11:33,519 --> 00:11:37,279
that is given a private sum

273
00:11:37,279 --> 00:11:39,600
we try to decide whether it comes from

274
00:11:39,600 --> 00:11:43,120
the data set d or data set d prime

275
00:11:43,120 --> 00:11:45,600
where d and d prime differ in a single

276
00:11:45,600 --> 00:11:46,880
record

277
00:11:46,880 --> 00:11:49,200
for each episode we did one minute

278
00:11:49,200 --> 00:11:52,320
trials to measure the success rate of

279
00:11:52,320 --> 00:11:53,519
our attack

280
00:11:53,519 --> 00:11:56,320
the baseline success rate should be 50

281
00:11:56,320 --> 00:11:57,760
for random gas

282
00:11:57,760 --> 00:12:01,360
but our attack success rate can be up to

283
00:12:01,360 --> 00:12:03,360
99 percent

284
00:12:03,360 --> 00:12:07,279
for a relatively large epsilon

285
00:12:07,279 --> 00:12:09,760
this high success rate means that our

286
00:12:09,760 --> 00:12:12,079
attack has successfully broken the

287
00:12:12,079 --> 00:12:13,600
priority guarantee of differential

288
00:12:13,600 --> 00:12:16,079
priority systems based on discrete

289
00:12:16,079 --> 00:12:17,440
distributions

290
00:12:17,440 --> 00:12:20,000
however this terminal channel can also

291
00:12:20,000 --> 00:12:23,120
be hard to be exploited in some settings

292
00:12:23,120 --> 00:12:25,680
for example when noises are sampled in

293
00:12:25,680 --> 00:12:26,720
batch

294
00:12:26,720 --> 00:12:28,639
it is very hard to measure the time it

295
00:12:28,639 --> 00:12:31,200
takes to sample a single noise so it is

296
00:12:31,200 --> 00:12:33,519
very hard to guess the magnitude of

297
00:12:33,519 --> 00:12:36,399
those noises

298
00:12:36,880 --> 00:12:39,519
in the final part of our study we try to

299
00:12:39,519 --> 00:12:42,320
propose mitigations against our floating

300
00:12:42,320 --> 00:12:44,959
point attacks and terminal texts

301
00:12:44,959 --> 00:12:46,880
for the floating point of attack we can

302
00:12:46,880 --> 00:12:49,040
make it very hard to run

303
00:12:49,040 --> 00:12:52,680
its feasible function

304
00:12:52,720 --> 00:12:55,279
by working the way for reverse

305
00:12:55,279 --> 00:12:58,000
engineering

306
00:12:58,959 --> 00:13:01,360
for example both the polar gaussian

307
00:13:01,360 --> 00:13:03,279
function and the box new recursion

308
00:13:03,279 --> 00:13:05,760
function generate two gaussian samples

309
00:13:05,760 --> 00:13:08,399
for each run

310
00:13:08,399 --> 00:13:11,600
and we can drop the second value from

311
00:13:11,600 --> 00:13:14,240
the gaussian functions and make the

312
00:13:14,240 --> 00:13:17,120
reverse engineering very hard because a

313
00:13:17,120 --> 00:13:20,079
part of the information necessary for

314
00:13:20,079 --> 00:13:23,120
reverse engineering is lost

315
00:13:23,120 --> 00:13:25,519
similarly we can aggregate several

316
00:13:25,519 --> 00:13:27,360
gaussian samples into one gaussian

317
00:13:27,360 --> 00:13:29,680
sample

318
00:13:30,240 --> 00:13:32,800
this will also make reverse engineering

319
00:13:32,800 --> 00:13:36,079
very hard this is how the floating point

320
00:13:36,079 --> 00:13:39,680
attack is mitigated in an independent

321
00:13:39,680 --> 00:13:43,839
and parallel work and how the attack is

322
00:13:43,839 --> 00:13:48,399
mitigated in the autopsy library now

323
00:13:48,399 --> 00:13:50,320
we also advise using discrete

324
00:13:50,320 --> 00:13:52,160
distributions in differential process

325
00:13:52,160 --> 00:13:54,639
systems to avoid floating point attacks

326
00:13:54,639 --> 00:13:56,560
when timing sub-channels in discrete

327
00:13:56,560 --> 00:13:58,639
distribution implementations can be

328
00:13:58,639 --> 00:14:01,360
handled properly for example you can use

329
00:14:01,360 --> 00:14:03,360
discrete gaussian in the training or

330
00:14:03,360 --> 00:14:04,880
machine learning models

331
00:14:04,880 --> 00:14:08,959
which is discussed in this paper

332
00:14:08,959 --> 00:14:11,120
and the performance or model's trained

333
00:14:11,120 --> 00:14:13,279
with discrete caution can match the

334
00:14:13,279 --> 00:14:14,959
performance of models trained with

335
00:14:14,959 --> 00:14:17,839
continuous caution

336
00:14:18,639 --> 00:14:20,880
in the setting exporting time inside the

337
00:14:20,880 --> 00:14:23,600
channel is very difficult because noises

338
00:14:23,600 --> 00:14:26,399
are sampled in batch so it is very hard

339
00:14:26,399 --> 00:14:29,040
to measure the time it takes to sample a

340
00:14:29,040 --> 00:14:31,839
single noise

341
00:14:31,920 --> 00:14:34,560
to mitigate timing attacks in discrete

342
00:14:34,560 --> 00:14:37,279
distributions we can use constant time

343
00:14:37,279 --> 00:14:38,720
implementations

344
00:14:38,720 --> 00:14:41,519
that is we can run the algorithm until

345
00:14:41,519 --> 00:14:45,320
some maximum time

346
00:14:45,680 --> 00:14:48,079
and capture failure in doubt when the

347
00:14:48,079 --> 00:14:51,600
runtime is too loud that cannot be stood

348
00:14:51,600 --> 00:14:53,680
and then we can also generate and buffer

349
00:14:53,680 --> 00:14:55,600
key samples offline

350
00:14:55,600 --> 00:14:57,839
so there is no time insert channel to be

351
00:14:57,839 --> 00:15:00,399
observed

352
00:15:01,360 --> 00:15:03,600
in conclusion we conduct 13-point

353
00:15:03,600 --> 00:15:06,320
attacks on differential privacy systems

354
00:15:06,320 --> 00:15:08,959
based on continuous caution and we

355
00:15:08,959 --> 00:15:11,199
conduct timing attacks on differential

356
00:15:11,199 --> 00:15:13,519
privacy systems based on discrete

357
00:15:13,519 --> 00:15:15,920
purpose of discrete caution

358
00:15:15,920 --> 00:15:17,839
for all those attacks we have gained

359
00:15:17,839 --> 00:15:21,360
very high attack success rates and

360
00:15:21,360 --> 00:15:22,560
invalidate

361
00:15:22,560 --> 00:15:25,199
the priority guarantees or differential

362
00:15:25,199 --> 00:15:27,600
priority systems

363
00:15:27,600 --> 00:15:30,560
in the end i want to thank my

364
00:15:30,560 --> 00:15:32,720
colleaguers and supervisors

365
00:15:32,720 --> 00:15:35,519
annual ben or

366
00:15:35,519 --> 00:15:39,199
this is a joint work by awful os

367
00:15:39,199 --> 00:15:43,359
and yeah something fun time

368
00:15:45,600 --> 00:15:49,929
[Applause]

369
00:15:50,959 --> 00:15:53,040
all right so jiangkai is joining us for

370
00:15:53,040 --> 00:15:55,040
a zoom session where we can ask him any

371
00:15:55,040 --> 00:15:56,800
questions that you may have so as usual

372
00:15:56,800 --> 00:15:58,560
please step up to the center and ask

373
00:15:58,560 --> 00:16:01,440
your question uh your work does not

374
00:16:01,440 --> 00:16:03,839
discuss dp sniper

375
00:16:03,839 --> 00:16:06,399
which also covers floating point attacks

376
00:16:06,399 --> 00:16:08,000
and i know we've discussed a bit

377
00:16:08,000 --> 00:16:09,759
privately but i'm wondering like how do

378
00:16:09,759 --> 00:16:11,759
you see that the main difference as best

379
00:16:11,759 --> 00:16:14,320
as you know currently

380
00:16:14,320 --> 00:16:16,800
uh for now uh

381
00:16:16,800 --> 00:16:18,800
first can you hear me

382
00:16:18,800 --> 00:16:22,240
yes we can hear you yes uh thank you but

383
00:16:22,240 --> 00:16:24,639
it will it would be very interesting to

384
00:16:24,639 --> 00:16:27,040
compare the two works in the in our

385
00:16:27,040 --> 00:16:29,680
future work and yeah we are very happy

386
00:16:29,680 --> 00:16:33,040
to take it uh often and discuss further

387
00:16:33,040 --> 00:16:34,160
yeah

388
00:16:34,160 --> 00:16:37,560
okay thanks

389
00:16:39,600 --> 00:16:41,279
thanks could you comment a little bit on

390
00:16:41,279 --> 00:16:43,839
the any overhead that you may have when

391
00:16:43,839 --> 00:16:46,000
applying your mitigations for the timing

392
00:16:46,000 --> 00:16:47,199
channel attacks because you said you

393
00:16:47,199 --> 00:16:49,519
wanted to pad the running time to

394
00:16:49,519 --> 00:16:50,720
essentially

395
00:16:50,720 --> 00:16:52,959
the worst case in some sense

396
00:16:52,959 --> 00:16:55,600
oh yeah for the overhead actually we

397
00:16:55,600 --> 00:16:56,959
just

398
00:16:56,959 --> 00:17:00,000
measured the runtime of the algorithm on

399
00:17:00,000 --> 00:17:02,839
the same machine yeah

400
00:17:02,839 --> 00:17:06,720
so yeah we admitted that

401
00:17:06,720 --> 00:17:09,039
there will be if there is a larger

402
00:17:09,039 --> 00:17:11,839
overhead wearing network our attack will

403
00:17:11,839 --> 00:17:14,559
not be that successful but

404
00:17:14,559 --> 00:17:17,760
in our third model we just assume that

405
00:17:17,760 --> 00:17:20,000
our attacker can observe the time it

406
00:17:20,000 --> 00:17:21,599
takes to sample a

407
00:17:21,599 --> 00:17:24,879
noise on the machine

408
00:17:26,799 --> 00:17:30,360
are there other questions

409
00:17:32,240 --> 00:17:33,520
great end of that let's thank the

410
00:17:33,520 --> 00:17:34,880
speaker again and also thank all the

411
00:17:34,880 --> 00:17:38,799
other speakers within this session

