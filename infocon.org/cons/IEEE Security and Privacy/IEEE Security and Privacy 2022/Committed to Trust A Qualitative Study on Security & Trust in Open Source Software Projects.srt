1
00:00:01,040 --> 00:00:02,320
so hi

2
00:00:02,320 --> 00:00:04,160
uh don't worry i'm not trying to sell

3
00:00:04,160 --> 00:00:06,160
you cryptocoins today

4
00:00:06,160 --> 00:00:08,400
uh also i hope nobody here just scanned

5
00:00:08,400 --> 00:00:09,679
a random qr code at a security

6
00:00:09,679 --> 00:00:11,679
conference so

7
00:00:11,679 --> 00:00:13,200
don't worry it will be back you can make

8
00:00:13,200 --> 00:00:16,079
your bad decisions later as well

9
00:00:16,079 --> 00:00:19,359
instead i'm going to talk to you about

10
00:00:19,359 --> 00:00:22,640
our talk committed to trust

11
00:00:23,039 --> 00:00:26,560
this talk is based

12
00:00:26,560 --> 00:00:27,340
on our

13
00:00:27,340 --> 00:00:28,800
[Music]

14
00:00:28,800 --> 00:00:30,640
application committed to trust equality

15
00:00:30,640 --> 00:00:32,800
of study on security and trust in open

16
00:00:32,800 --> 00:00:35,040
source software projects

17
00:00:35,040 --> 00:00:36,239
and this work would not have been

18
00:00:36,239 --> 00:00:38,000
possible with all of these awesome

19
00:00:38,000 --> 00:00:40,160
people um

20
00:00:40,160 --> 00:00:42,320
including abuela jan klemmer marcel

21
00:00:42,320 --> 00:00:44,559
phoney and sacha fall were in fact all

22
00:00:44,559 --> 00:00:45,920
here at ieee

23
00:00:45,920 --> 00:00:48,800
and are sitting right in front there

24
00:00:48,800 --> 00:00:49,920
and of course this wouldn't have been

25
00:00:49,920 --> 00:00:52,480
possible without all of our participants

26
00:00:52,480 --> 00:00:54,800
who generously donated their valuable

27
00:00:54,800 --> 00:00:57,680
time for our research

28
00:00:57,680 --> 00:00:59,440
somewhat less awesome but silver into

29
00:00:59,440 --> 00:01:01,280
this talk is this person

30
00:01:01,280 --> 00:01:02,559
this is me

31
00:01:02,559 --> 00:01:04,159
my name is dominic ramka and i will be

32
00:01:04,159 --> 00:01:07,040
your presenter for this talk

33
00:01:07,040 --> 00:01:09,040
um so there are the qr codes back you

34
00:01:09,040 --> 00:01:11,040
cannot make bad decisions if you want

35
00:01:11,040 --> 00:01:12,000
you

36
00:01:12,000 --> 00:01:14,000
can find there all supplemental

37
00:01:14,000 --> 00:01:15,680
information for this talk and for the

38
00:01:15,680 --> 00:01:17,920
publication as well as slides if you

39
00:01:17,920 --> 00:01:20,479
want to follow along on your own device

40
00:01:20,479 --> 00:01:23,520
um all right let's get started

41
00:01:23,520 --> 00:01:24,880
first i want you to

42
00:01:24,880 --> 00:01:26,799
i want to convince you of something that

43
00:01:26,799 --> 00:01:27,680
is

44
00:01:27,680 --> 00:01:30,079
why you should care about open source

45
00:01:30,079 --> 00:01:33,119
and related to that open source software

46
00:01:33,119 --> 00:01:35,680
security

47
00:01:38,000 --> 00:01:39,439
here's a slide of open source software

48
00:01:39,439 --> 00:01:41,280
logos you are probably aware of some of

49
00:01:41,280 --> 00:01:43,360
those logos and maybe even use the tools

50
00:01:43,360 --> 00:01:45,600
from time to time

51
00:01:45,600 --> 00:01:47,200
but open source

52
00:01:47,200 --> 00:01:49,360
probably has permeated your life more

53
00:01:49,360 --> 00:01:51,759
than you are aware of

54
00:01:51,759 --> 00:01:53,600
open source code appears as foundation

55
00:01:53,600 --> 00:01:55,680
glue or during the build process in many

56
00:01:55,680 --> 00:01:57,200
software projects

57
00:01:57,200 --> 00:01:58,799
whether it's low level system driver and

58
00:01:58,799 --> 00:02:00,320
operating systems as tooling in your

59
00:02:00,320 --> 00:02:02,560
daily jobs or simply as dependencies of

60
00:02:02,560 --> 00:02:04,000
our hobby projects

61
00:02:04,000 --> 00:02:05,600
open source software is an important

62
00:02:05,600 --> 00:02:08,639
building block of our everyday life

63
00:02:08,639 --> 00:02:10,639
as an example in the 2020 state of the

64
00:02:10,639 --> 00:02:13,120
octobers by github

65
00:02:13,120 --> 00:02:14,319
which further highlights the importance

66
00:02:14,319 --> 00:02:17,040
of the open source software supply chain

67
00:02:17,040 --> 00:02:19,040
most companies on good hub actually rely

68
00:02:19,040 --> 00:02:20,800
on on some form of

69
00:02:20,800 --> 00:02:22,400
open source of blender stack which

70
00:02:22,400 --> 00:02:24,800
results in a widespread usage

71
00:02:24,800 --> 00:02:26,480
and the median number of dependencies in

72
00:02:26,480 --> 00:02:29,280
the npm ecosystem is 683

73
00:02:29,280 --> 00:02:30,560
residing in a large potential attack

74
00:02:30,560 --> 00:02:32,239
service

75
00:02:32,239 --> 00:02:34,319
i used my extensive art skills to better

76
00:02:34,319 --> 00:02:36,160
underline this fact so this is the

77
00:02:36,160 --> 00:02:38,640
software supply chain of your project

78
00:02:38,640 --> 00:02:39,760
this is a malicious attacker

79
00:02:39,760 --> 00:02:42,800
compromising on one of your packages

80
00:02:42,800 --> 00:02:44,000
and this is your whole software being

81
00:02:44,000 --> 00:02:47,599
compromised and your project collapsing

82
00:02:48,080 --> 00:02:50,160
as a recent protest while drama showed

83
00:02:50,160 --> 00:02:52,000
even well-meaning actions can result in

84
00:02:52,000 --> 00:02:54,319
a loss of trust for software for the

85
00:02:54,319 --> 00:02:56,000
software supply chain

86
00:02:56,000 --> 00:02:57,920
just as a refresher

87
00:02:57,920 --> 00:02:59,200
as a show of political support

88
00:02:59,200 --> 00:03:01,040
maintainers introduced bad faith code

89
00:03:01,040 --> 00:03:03,120
mostly targeting russian citizens into

90
00:03:03,120 --> 00:03:04,480
their packages

91
00:03:04,480 --> 00:03:06,000
which eroded over all the trust in the

92
00:03:06,000 --> 00:03:08,879
software supply chain

93
00:03:09,040 --> 00:03:10,560
so for our work

94
00:03:10,560 --> 00:03:12,640
we wanted to investigate how open source

95
00:03:12,640 --> 00:03:13,840
projects handle security and trust

96
00:03:13,840 --> 00:03:15,920
behind the scenes specifically processes

97
00:03:15,920 --> 00:03:17,440
that are not directly visible from the

98
00:03:17,440 --> 00:03:19,519
code base

99
00:03:19,519 --> 00:03:21,440
and we based our investigation on the

100
00:03:21,440 --> 00:03:23,440
following research questions

101
00:03:23,440 --> 00:03:24,480
first

102
00:03:24,480 --> 00:03:26,400
how open source projects are structured

103
00:03:26,400 --> 00:03:28,159
behind these scenes

104
00:03:28,159 --> 00:03:30,080
second if and what guidances and

105
00:03:30,080 --> 00:03:31,599
policies are provided by open source

106
00:03:31,599 --> 00:03:32,879
projects

107
00:03:32,879 --> 00:03:34,720
and third how do open source projects

108
00:03:34,720 --> 00:03:38,400
approach security and trust challenges

109
00:03:39,360 --> 00:03:40,560
so with some

110
00:03:40,560 --> 00:03:42,239
more or less recent drama about research

111
00:03:42,239 --> 00:03:43,760
approaches and open source we of course

112
00:03:43,760 --> 00:03:45,599
ask ourselves how we could conduct this

113
00:03:45,599 --> 00:03:47,680
investigation

114
00:03:47,680 --> 00:03:48,959
and after a long and hard thinking

115
00:03:48,959 --> 00:03:50,400
process we arrived at the following

116
00:03:50,400 --> 00:03:52,000
approach

117
00:03:52,000 --> 00:03:55,040
we will just ask them

118
00:03:56,480 --> 00:03:57,840
so for this we of course needed some

119
00:03:57,840 --> 00:03:59,040
projects

120
00:03:59,040 --> 00:04:00,640
and we decided that for recruitment we

121
00:04:00,640 --> 00:04:02,159
first wanted to mostly focus on a

122
00:04:02,159 --> 00:04:03,680
diverse sample of projects so that we

123
00:04:03,680 --> 00:04:06,239
can cover a wider range of

124
00:04:06,239 --> 00:04:08,480
structures and processes

125
00:04:08,480 --> 00:04:10,159
and as such we recruit for multiple

126
00:04:10,159 --> 00:04:11,920
channels including certified same from

127
00:04:11,920 --> 00:04:12,959
github

128
00:04:12,959 --> 00:04:14,560
personal connections

129
00:04:14,560 --> 00:04:15,920
famous projects and further

130
00:04:15,920 --> 00:04:18,320
recommendations by all participants

131
00:04:18,320 --> 00:04:19,519
the full recruitment process is

132
00:04:19,519 --> 00:04:21,440
described on the website in the paper

133
00:04:21,440 --> 00:04:23,919
and in a provided supplementary paper as

134
00:04:23,919 --> 00:04:26,159
well

135
00:04:26,560 --> 00:04:27,680
generally

136
00:04:27,680 --> 00:04:28,720
we reach out

137
00:04:28,720 --> 00:04:30,639
to potential projects we are public

138
00:04:30,639 --> 00:04:32,479
email addresses they're listed or we are

139
00:04:32,479 --> 00:04:33,520
the public email addresses of the

140
00:04:33,520 --> 00:04:35,360
maintainers

141
00:04:35,360 --> 00:04:37,360
this approach is of course somewhat

142
00:04:37,360 --> 00:04:39,520
difficult as we compete with a lot of

143
00:04:39,520 --> 00:04:41,680
spam that these people get to the public

144
00:04:41,680 --> 00:04:43,520
email addresses

145
00:04:43,520 --> 00:04:44,320
um

146
00:04:44,320 --> 00:04:46,560
so to highlight our approach or how we

147
00:04:46,560 --> 00:04:48,320
try to circumvent that i will like

148
00:04:48,320 --> 00:04:49,840
quickly go over one of our email

149
00:04:49,840 --> 00:04:52,080
templates that we sent

150
00:04:52,080 --> 00:04:54,720
so overall we

151
00:04:54,720 --> 00:04:56,639
highly customized our messages so we

152
00:04:56,639 --> 00:05:00,320
only sent in total uh very few emails

153
00:05:00,320 --> 00:05:02,080
uh just so that we really could uh

154
00:05:02,080 --> 00:05:03,840
customize the emails for the specific

155
00:05:03,840 --> 00:05:05,120
people we are our projects we are

156
00:05:05,120 --> 00:05:07,520
addressing so this already

157
00:05:07,520 --> 00:05:08,960
gave us like

158
00:05:08,960 --> 00:05:10,800
a head start above most of the spare

159
00:05:10,800 --> 00:05:12,639
messages

160
00:05:12,639 --> 00:05:14,400
we also

161
00:05:14,400 --> 00:05:16,000
started off with a quick intro of what

162
00:05:16,000 --> 00:05:17,280
we are what we are doing what we are

163
00:05:17,280 --> 00:05:19,039
planning just so to get the attention of

164
00:05:19,039 --> 00:05:21,440
the potential participants

165
00:05:21,440 --> 00:05:23,199
we gave a short picture of our research

166
00:05:23,199 --> 00:05:24,639
try to alleviate their concerns and

167
00:05:24,639 --> 00:05:27,520
highlight possible benefits

168
00:05:27,520 --> 00:05:29,280
and most importantly we provided a

169
00:05:29,280 --> 00:05:31,600
landing page further information

170
00:05:31,600 --> 00:05:32,880
just so that

171
00:05:32,880 --> 00:05:34,639
i mean open source developer online a

172
00:05:34,639 --> 00:05:36,000
lot right so and they probably need a

173
00:05:36,000 --> 00:05:38,639
lot of text online on websites so we

174
00:05:38,639 --> 00:05:40,800
just provided a landing page with like

175
00:05:40,800 --> 00:05:42,160
all the information

176
00:05:42,160 --> 00:05:43,600
all the data handling information all

177
00:05:43,600 --> 00:05:46,639
the consent and stuff and so on

178
00:05:46,639 --> 00:05:49,680
and made it easily shareable which

179
00:05:49,680 --> 00:05:50,880
actually resulted in additional

180
00:05:50,880 --> 00:05:52,320
recruitments because people shared this

181
00:05:52,320 --> 00:05:53,680
website then with their colleagues or

182
00:05:53,680 --> 00:05:56,080
friends

183
00:05:56,560 --> 00:05:58,880
and lastly in our email attempt that we

184
00:05:58,880 --> 00:06:00,639
apologized for cold emailing them we

185
00:06:00,639 --> 00:06:01,919
highlighted where you thought this

186
00:06:01,919 --> 00:06:03,520
approach was necessary to reach into a

187
00:06:03,520 --> 00:06:05,199
sample

188
00:06:05,199 --> 00:06:07,759
and uh we ensured them that they did not

189
00:06:07,759 --> 00:06:09,280
have to opt out in any way for further

190
00:06:09,280 --> 00:06:11,039
emails that was

191
00:06:11,039 --> 00:06:13,759
uh that this will be our own email

192
00:06:13,759 --> 00:06:16,160
um we also in addition to personalized

193
00:06:16,160 --> 00:06:18,800
emails uh we advertise directly to

194
00:06:18,800 --> 00:06:20,880
specific communities by

195
00:06:20,880 --> 00:06:24,319
joining the for example slack channel or

196
00:06:24,319 --> 00:06:26,960
matamos channels or discords and after

197
00:06:26,960 --> 00:06:28,639
asking moderators there for permission

198
00:06:28,639 --> 00:06:29,759
we

199
00:06:29,759 --> 00:06:32,479
posted an advertisement for our study

200
00:06:32,479 --> 00:06:33,600
some of the moderators were kind of

201
00:06:33,600 --> 00:06:35,520
surprised by this so apparently that's

202
00:06:35,520 --> 00:06:38,000
not a very common research venue

203
00:06:38,000 --> 00:06:40,319
uh and while they allowed us to post our

204
00:06:40,319 --> 00:06:41,520
study

205
00:06:41,520 --> 00:06:43,120
they are some also decided to update the

206
00:06:43,120 --> 00:06:45,759
rules for the future so if you encounter

207
00:06:45,759 --> 00:06:47,600
this during any of your future studies

208
00:06:47,600 --> 00:06:49,039
i'm deeply sorry for ruining this

209
00:06:49,039 --> 00:06:51,919
research when you know

210
00:06:52,479 --> 00:06:54,479
all right now we had our participants

211
00:06:54,479 --> 00:06:56,479
we decided to

212
00:06:56,479 --> 00:06:58,160
let's move on to results

213
00:06:58,160 --> 00:07:00,000
so in total we conducted interviews with

214
00:07:00,000 --> 00:07:02,720
27 participants for this graphic i

215
00:07:02,720 --> 00:07:04,639
roughly sorted our positions by the

216
00:07:04,639 --> 00:07:06,380
highest project role

217
00:07:06,380 --> 00:07:08,000
[Music]

218
00:07:08,000 --> 00:07:09,440
and we found that they tend towards the

219
00:07:09,440 --> 00:07:11,440
leader owner's side

220
00:07:11,440 --> 00:07:13,120
we suspect this that this might be an

221
00:07:13,120 --> 00:07:15,520
effect of us just being further referred

222
00:07:15,520 --> 00:07:17,440
up the chain so if he contacted a person

223
00:07:17,440 --> 00:07:19,440
that was necessary not necessarily like

224
00:07:19,440 --> 00:07:21,520
the owner of the project uh they often

225
00:07:21,520 --> 00:07:22,880
arranged for us to

226
00:07:22,880 --> 00:07:24,880
like at least contact or meet the leader

227
00:07:24,880 --> 00:07:26,319
of the project

228
00:07:26,319 --> 00:07:28,840
get more information there

229
00:07:28,840 --> 00:07:32,160
um overall we covered these eight areas

230
00:07:32,160 --> 00:07:33,520
in our interviews

231
00:07:33,520 --> 00:07:35,599
for this talk i will quickly go over the

232
00:07:35,599 --> 00:07:37,919
four more technical technical categories

233
00:07:37,919 --> 00:07:39,520
for an in-depth look

234
00:07:39,520 --> 00:07:41,680
of the like more structural categories i

235
00:07:41,680 --> 00:07:44,479
have to refer you to the paper

236
00:07:44,479 --> 00:07:46,080
so let's get started with security

237
00:07:46,080 --> 00:07:47,599
challenges

238
00:07:47,599 --> 00:07:48,960
we asked our participants if they

239
00:07:48,960 --> 00:07:50,879
encountered security incidents in the

240
00:07:50,879 --> 00:07:52,240
past

241
00:07:52,240 --> 00:07:55,840
and the majority did not

242
00:07:56,800 --> 00:07:58,400
encounter by security challenges that

243
00:07:58,400 --> 00:07:59,919
not necessarily led to an incident

244
00:07:59,919 --> 00:08:01,680
included suspicious or low quality

245
00:08:01,680 --> 00:08:03,840
commits and vulnerabilities introduced

246
00:08:03,840 --> 00:08:05,759
by dependencies

247
00:08:05,759 --> 00:08:07,440
overall some of our participants

248
00:08:07,440 --> 00:08:08,960
mentioned that they could easily spot

249
00:08:08,960 --> 00:08:13,479
malicious code commits on github

250
00:08:13,759 --> 00:08:15,440
next we were interested in guidance and

251
00:08:15,440 --> 00:08:18,160
policies provided by the projects

252
00:08:18,160 --> 00:08:19,440
the most mentioned type of guidance by

253
00:08:19,440 --> 00:08:20,879
our participants included general

254
00:08:20,879 --> 00:08:22,639
guidance for contributing to the project

255
00:08:22,639 --> 00:08:24,000
programming language specific guidance

256
00:08:24,000 --> 00:08:26,560
such as code styling or security

257
00:08:26,560 --> 00:08:28,639
advisories on certain functions

258
00:08:28,639 --> 00:08:30,720
and guidance for project setup and build

259
00:08:30,720 --> 00:08:33,360
infrastructure

260
00:08:33,839 --> 00:08:35,200
a factor for not providing guidance

261
00:08:35,200 --> 00:08:36,799
included the required programmer hours

262
00:08:36,799 --> 00:08:40,439
such as in this example

263
00:08:41,120 --> 00:08:42,880
next up we were interested in the trust

264
00:08:42,880 --> 00:08:45,200
process behind the seats

265
00:08:45,200 --> 00:08:46,399
we asked our participants if their

266
00:08:46,399 --> 00:08:48,240
projects had encountered a trust incense

267
00:08:48,240 --> 00:08:50,959
by their own definition in the past

268
00:08:50,959 --> 00:08:53,279
and a large majority of the projects had

269
00:08:53,279 --> 00:08:54,640
not

270
00:08:54,640 --> 00:08:56,320
uh mentioned trust incidents included a

271
00:08:56,320 --> 00:08:58,160
drive-by cryptocurrency uh drive by

272
00:08:58,160 --> 00:09:00,240
cryptocurrency minor commits background

273
00:09:00,240 --> 00:09:02,959
checks for uh repositories that are like

274
00:09:02,959 --> 00:09:04,640
based on the company so where the

275
00:09:04,640 --> 00:09:06,480
company actually hires people

276
00:09:06,480 --> 00:09:08,720
and a proactive block count block after

277
00:09:08,720 --> 00:09:13,040
a stone laptop of one of the maintainers

278
00:09:13,440 --> 00:09:15,040
lastly we were interested in opinions

279
00:09:15,040 --> 00:09:16,800
and suggest improvements for the status

280
00:09:16,800 --> 00:09:20,160
quo of our participants projects

281
00:09:20,160 --> 00:09:21,519
we roughly sorted the suggested

282
00:09:21,519 --> 00:09:22,880
improvements of their projects and

283
00:09:22,880 --> 00:09:24,720
categories with the majority requiring

284
00:09:24,720 --> 00:09:26,640
more personal hours followed by more

285
00:09:26,640 --> 00:09:28,399
monetary funds and switching the project

286
00:09:28,399 --> 00:09:31,200
to a completely different infrastructure

287
00:09:31,200 --> 00:09:34,959
yes this included rust a few times

288
00:09:34,959 --> 00:09:36,800
uh here's some examples of suggested

289
00:09:36,800 --> 00:09:38,160
improvements which included rewriting

290
00:09:38,160 --> 00:09:39,839
the entire stack rewriting every pull

291
00:09:39,839 --> 00:09:41,680
request review every pull request for

292
00:09:41,680 --> 00:09:43,839
security and invest into automatic tools

293
00:09:43,839 --> 00:09:47,040
for vulnerability findings

294
00:09:47,120 --> 00:09:49,200
to summarize our findings

295
00:09:49,200 --> 00:09:50,720
we found that products are highly

296
00:09:50,720 --> 00:09:52,399
diverse both in deployed security

297
00:09:52,399 --> 00:09:55,600
measures trust processes and motivations

298
00:09:55,600 --> 00:09:57,760
that are growing scope and contributors

299
00:09:57,760 --> 00:09:59,200
results in growing needs for security

300
00:09:59,200 --> 00:10:00,880
and trust processes

301
00:10:00,880 --> 00:10:02,000
and that smaller projects handle

302
00:10:02,000 --> 00:10:03,360
security and trust incidents as they

303
00:10:03,360 --> 00:10:05,600
happen so they often haven't like

304
00:10:05,600 --> 00:10:07,440
process in place or have thought about

305
00:10:07,440 --> 00:10:08,880
certain stuff

306
00:10:08,880 --> 00:10:10,399
and

307
00:10:10,399 --> 00:10:11,839
but for them it's fine they decide they

308
00:10:11,839 --> 00:10:14,880
just handle them as they appear

309
00:10:14,880 --> 00:10:16,690
to recap the whole thing

310
00:10:16,690 --> 00:10:17,839
[Music]

311
00:10:17,839 --> 00:10:19,279
open source code appears as foundation

312
00:10:19,279 --> 00:10:21,279
glue or during the build process in many

313
00:10:21,279 --> 00:10:22,560
software projects

314
00:10:22,560 --> 00:10:24,399
thus by providing open source repository

315
00:10:24,399 --> 00:10:25,760
support and enabling them to write

316
00:10:25,760 --> 00:10:27,839
secure software all dependent software

317
00:10:27,839 --> 00:10:29,680
also benefits

318
00:10:29,680 --> 00:10:31,760
and as resellers we advocate against

319
00:10:31,760 --> 00:10:33,279
treating open source developers solely

320
00:10:33,279 --> 00:10:34,720
as data sources and review process

321
00:10:34,720 --> 00:10:36,560
blackboard services and instead to

322
00:10:36,560 --> 00:10:38,480
consider them as valuable partners in

323
00:10:38,480 --> 00:10:40,079
bringing security and trust to open

324
00:10:40,079 --> 00:10:42,079
source software and software ecosystems

325
00:10:42,079 --> 00:10:43,279
as whole

326
00:10:43,279 --> 00:10:44,320
we argue

327
00:10:44,320 --> 00:10:45,680
for supporting open source projects and

328
00:10:45,680 --> 00:10:46,959
ways that better concert and real

329
00:10:46,959 --> 00:10:48,399
strengths and limitations especially in

330
00:10:48,399 --> 00:10:51,360
the case of smaller projects

331
00:10:51,360 --> 00:10:53,680
that was our talk committed trust

332
00:10:53,680 --> 00:10:55,519
thanks for listening to my talk any

333
00:10:55,519 --> 00:10:57,700
questions

334
00:10:57,700 --> 00:11:05,240
[Applause]

335
00:11:06,959 --> 00:11:09,440
thank you so much for the talk um

336
00:11:09,440 --> 00:11:11,760
for oh you're right there all right you

337
00:11:11,760 --> 00:11:13,600
get to ask a question first all right

338
00:11:13,600 --> 00:11:16,240
thanks for the great talk um i noticed

339
00:11:16,240 --> 00:11:18,240
some similarities between

340
00:11:18,240 --> 00:11:20,079
this work and how people introduce

341
00:11:20,079 --> 00:11:21,760
vulnerabilities by looking at stack

342
00:11:21,760 --> 00:11:22,880
overflow

343
00:11:22,880 --> 00:11:25,519
uh what what are the what are can we

344
00:11:25,519 --> 00:11:27,920
take lessons from all the research

345
00:11:27,920 --> 00:11:30,079
that's been done on that and apply it to

346
00:11:30,079 --> 00:11:30,880
here

347
00:11:30,880 --> 00:11:33,760
do you think it's it's relevant

348
00:11:33,760 --> 00:11:34,640
um

349
00:11:34,640 --> 00:11:35,760
i would say

350
00:11:35,760 --> 00:11:37,440
and some other great question i would

351
00:11:37,440 --> 00:11:40,240
say in some way yes in some ways not

352
00:11:40,240 --> 00:11:43,279
just because um like i feel it for open

353
00:11:43,279 --> 00:11:44,800
source it's like one of the biggest

354
00:11:44,800 --> 00:11:46,640
struggles is to attract contributors

355
00:11:46,640 --> 00:11:48,079
right and if you

356
00:11:48,079 --> 00:11:49,440
um

357
00:11:49,440 --> 00:11:52,160
like just move all uh the same

358
00:11:52,160 --> 00:11:54,720
application or order same defenses and

359
00:11:54,720 --> 00:11:56,880
approaches and so on over uh

360
00:11:56,880 --> 00:11:58,880
i feel like uh

361
00:11:58,880 --> 00:12:01,600
they probably will lose maintainers or

362
00:12:01,600 --> 00:12:04,160
not attract as many so

363
00:12:04,160 --> 00:12:05,360
i guess my answer to that would be

364
00:12:05,360 --> 00:12:07,200
depends sorry for the shitty answer but

365
00:12:07,200 --> 00:12:08,160
uh

366
00:12:08,160 --> 00:12:10,959
like most open source projects like

367
00:12:10,959 --> 00:12:14,079
are in a like very tight balance between

368
00:12:14,079 --> 00:12:16,480
attracting maintainers and providing

369
00:12:16,480 --> 00:12:17,279
like

370
00:12:17,279 --> 00:12:22,040
many security checks and tests and so on

371
00:12:27,920 --> 00:12:30,240
so um if you were

372
00:12:30,240 --> 00:12:32,399
uh basically a small project uh

373
00:12:32,399 --> 00:12:34,160
maintainer but one of the ones you know

374
00:12:34,160 --> 00:12:36,160
that in the supply chain is like where

375
00:12:36,160 --> 00:12:37,680
it falls everything falls down like in

376
00:12:37,680 --> 00:12:38,720
your picture

377
00:12:38,720 --> 00:12:39,600
um

378
00:12:39,600 --> 00:12:41,360
after reading your paper what would you

379
00:12:41,360 --> 00:12:43,200
say they should do in order to like be

380
00:12:43,200 --> 00:12:45,760
less vulnerable

381
00:12:45,760 --> 00:12:47,839
so of course i they probably can't

382
00:12:47,839 --> 00:12:50,560
employ all the approaches and process

383
00:12:50,560 --> 00:12:51,920
that large products can because they

384
00:12:51,920 --> 00:12:54,160
simply don't have the person powers

385
00:12:54,160 --> 00:12:56,160
my suggestion would be to

386
00:12:56,160 --> 00:12:57,839
but still look at what the big projects

387
00:12:57,839 --> 00:12:59,920
are doing so for example

388
00:12:59,920 --> 00:13:02,800
red hat and open fss and so on they have

389
00:13:02,800 --> 00:13:05,680
some guidance for smaller projects

390
00:13:05,680 --> 00:13:07,440
they probably can't apply all of that

391
00:13:07,440 --> 00:13:08,639
simply because they are too small and

392
00:13:08,639 --> 00:13:10,320
they don't have the person power

393
00:13:10,320 --> 00:13:12,720
but they can look at it and like cherry

394
00:13:12,720 --> 00:13:14,320
pick the stuff that works for them now

395
00:13:14,320 --> 00:13:16,320
and then if they grow larger in scope

396
00:13:16,320 --> 00:13:19,440
they can apply further

397
00:13:19,440 --> 00:13:20,800
processes and

398
00:13:20,800 --> 00:13:23,599
approaches from there

399
00:13:27,360 --> 00:13:29,440
thank you so much um

400
00:13:29,440 --> 00:13:33,040
doesn't look like we have more questions

401
00:13:33,040 --> 00:13:35,660
so thank you once more for the talk

402
00:13:35,660 --> 00:13:40,819
[Applause]

