1
00:00:00,640 --> 00:00:03,280
hello everyone this is celluc an

2
00:00:03,280 --> 00:00:06,000
associate professor from uss lab julian

3
00:00:06,000 --> 00:00:07,359
university

4
00:00:07,359 --> 00:00:09,599
today i'm going to introduce our work

5
00:00:09,599 --> 00:00:10,800
poltergeist

6
00:00:10,800 --> 00:00:12,960
acoustic adversarial machine learning

7
00:00:12,960 --> 00:00:14,240
against the camera

8
00:00:14,240 --> 00:00:16,720
and the commuter vision this is a drive

9
00:00:16,720 --> 00:00:17,680
to work with

10
00:00:17,680 --> 00:00:21,199
the university of michigan in the very

11
00:00:21,199 --> 00:00:23,119
recent years autonomous

12
00:00:23,119 --> 00:00:25,439
systems are booming including

13
00:00:25,439 --> 00:00:26,720
self-driving cars

14
00:00:26,720 --> 00:00:29,599
drones unmanned ships home and

15
00:00:29,599 --> 00:00:31,279
industrial robots

16
00:00:31,279 --> 00:00:33,600
autonomous unmanned systems are

17
00:00:33,600 --> 00:00:36,480
everywhere in our daily lives

18
00:00:36,480 --> 00:00:39,120
for an autonomous system computer vision

19
00:00:39,120 --> 00:00:40,480
has been the key to

20
00:00:40,480 --> 00:00:43,520
things in the environment in a computer

21
00:00:43,520 --> 00:00:44,719
vision system

22
00:00:44,719 --> 00:00:47,120
cameras are first used to sense the

23
00:00:47,120 --> 00:00:47,760
objects

24
00:00:47,760 --> 00:00:51,600
around then the sense results

25
00:00:51,600 --> 00:00:54,079
such as person stop sign or traffic

26
00:00:54,079 --> 00:00:54,640
lights

27
00:00:54,640 --> 00:00:57,360
are fed into object detection algorithms

28
00:00:57,360 --> 00:00:58,879
for detection

29
00:00:58,879 --> 00:01:01,199
the detection results are then used to

30
00:01:01,199 --> 00:01:02,399
support driving

31
00:01:02,399 --> 00:01:06,320
designs zero for reliable camera vision

32
00:01:06,320 --> 00:01:08,159
is crucial to the safety of

33
00:01:08,159 --> 00:01:12,320
autonomous systems however

34
00:01:12,320 --> 00:01:14,320
if a computer vision can be manipulated

35
00:01:14,320 --> 00:01:15,439
by an attacker

36
00:01:15,439 --> 00:01:18,560
for example failure to detect the front

37
00:01:18,560 --> 00:01:21,920
pedestrians correctly an autonomous

38
00:01:21,920 --> 00:01:24,320
vehicle make wrong decisions like go

39
00:01:24,320 --> 00:01:25,119
ahead

40
00:01:25,119 --> 00:01:28,320
instead of taking a turn or stop

41
00:01:28,320 --> 00:01:33,360
then tragic consequences will happen

42
00:01:34,640 --> 00:01:36,880
and there are several examples that

43
00:01:36,880 --> 00:01:38,640
exploit the vulnerability of

44
00:01:38,640 --> 00:01:41,040
machine learning algorithms has been a

45
00:01:41,040 --> 00:01:41,759
threat

46
00:01:41,759 --> 00:01:45,200
against commuter vision systems existing

47
00:01:45,200 --> 00:01:46,399
work in this era may

48
00:01:46,399 --> 00:01:49,520
focus on either altering the

49
00:01:49,520 --> 00:01:51,840
physical objects such as attaching

50
00:01:51,840 --> 00:01:53,759
stickers on a stop sign

51
00:01:53,759 --> 00:01:57,520
or just directly adds digital pixel

52
00:01:57,520 --> 00:01:58,719
perturbations

53
00:01:58,719 --> 00:02:02,560
on digital images from the working flow

54
00:02:02,560 --> 00:02:05,840
of a cv system we wonder

55
00:02:05,840 --> 00:02:09,199
whether we can achieve such adversarial

56
00:02:09,199 --> 00:02:11,760
attacks by just utilizing the

57
00:02:11,760 --> 00:02:12,800
vulnerability of

58
00:02:12,800 --> 00:02:16,400
sensors with this question

59
00:02:16,400 --> 00:02:19,040
we take a close look at the autonomous

60
00:02:19,040 --> 00:02:21,360
vehicle's camera system

61
00:02:21,360 --> 00:02:24,720
we find that a camera system nowadays

62
00:02:24,720 --> 00:02:27,520
utilizes image stabilizer to reduce

63
00:02:27,520 --> 00:02:28,319
image blur

64
00:02:28,319 --> 00:02:32,080
caused by motions in the image splicer

65
00:02:32,080 --> 00:02:34,400
the inertial sensor plays an important

66
00:02:34,400 --> 00:02:36,480
role by singing the motions

67
00:02:36,480 --> 00:02:39,360
and then the motions can be compensated

68
00:02:39,360 --> 00:02:39,680
on

69
00:02:39,680 --> 00:02:41,840
the blurry images according to the

70
00:02:41,840 --> 00:02:44,000
things results

71
00:02:44,000 --> 00:02:47,440
however the inertial sensors such as

72
00:02:47,440 --> 00:02:50,560
axon meters or gyroscopes have already

73
00:02:50,560 --> 00:02:52,959
been reported to be vulnerable to

74
00:02:52,959 --> 00:02:56,239
resonant acoustic signals

75
00:02:56,239 --> 00:02:59,360
this opens us the door and provides

76
00:02:59,360 --> 00:03:02,159
us the attack chance to generate

77
00:03:02,159 --> 00:03:04,319
adversarial example from

78
00:03:04,319 --> 00:03:08,560
sensors so following this philosophy

79
00:03:08,560 --> 00:03:12,319
we propose poltergeist we manipulate the

80
00:03:12,319 --> 00:03:14,560
universal sensor readings by acoustic

81
00:03:14,560 --> 00:03:15,920
signals

82
00:03:15,920 --> 00:03:19,280
such that the images are blurred to be

83
00:03:19,280 --> 00:03:22,720
adversarial ones which can be then

84
00:03:22,720 --> 00:03:25,760
misclassified by the detectors

85
00:03:25,760 --> 00:03:29,440
in a computer vision system

86
00:03:30,959 --> 00:03:33,360
to investigate the feasibility of

87
00:03:33,360 --> 00:03:34,480
poltergeist

88
00:03:34,480 --> 00:03:37,280
we perform preliminary analysis by

89
00:03:37,280 --> 00:03:38,560
simulating

90
00:03:38,560 --> 00:03:42,480
different blur patterns and then fit the

91
00:03:42,480 --> 00:03:46,480
blurred images into detectors we find

92
00:03:46,480 --> 00:03:46,959
that

93
00:03:46,959 --> 00:03:50,239
with different blur patterns such as

94
00:03:50,239 --> 00:03:53,040
linear or rotational patterns we will

95
00:03:53,040 --> 00:03:54,400
introduce later

96
00:03:54,400 --> 00:03:57,680
we can achieve hiding creating and

97
00:03:57,680 --> 00:04:00,319
altering attacks which means we can hide

98
00:04:00,319 --> 00:04:01,040
something

99
00:04:01,040 --> 00:04:04,319
or we can create new objects or we can

100
00:04:04,319 --> 00:04:05,200
just

101
00:04:05,200 --> 00:04:08,080
change the label of existing objects

102
00:04:08,080 --> 00:04:10,159
from a to b

103
00:04:10,159 --> 00:04:13,599
so why why will this happen the behind

104
00:04:13,599 --> 00:04:14,080
the reason

105
00:04:14,080 --> 00:04:17,600
is that a blurry image can change the

106
00:04:17,600 --> 00:04:20,959
outline the size and even the color of

107
00:04:20,959 --> 00:04:24,240
existing objects in the image

108
00:04:24,240 --> 00:04:26,840
which contributes to the about three

109
00:04:26,840 --> 00:04:29,360
attacks

110
00:04:29,360 --> 00:04:32,080
so although the results seem promising

111
00:04:32,080 --> 00:04:34,560
we still face many challenges

112
00:04:34,560 --> 00:04:37,280
the first one is how to quantify the

113
00:04:37,280 --> 00:04:39,280
impact of acoustic signals

114
00:04:39,280 --> 00:04:42,720
upon the blur pattern and blur levels

115
00:04:42,720 --> 00:04:45,360
another challenge is how to find

116
00:04:45,360 --> 00:04:46,720
effective

117
00:04:46,720 --> 00:04:50,320
and efficient blurry patterns to achieve

118
00:04:50,320 --> 00:04:53,120
targeted goals when we know nothing

119
00:04:53,120 --> 00:04:53,840
about the

120
00:04:53,840 --> 00:04:56,160
object detectors except for the

121
00:04:56,160 --> 00:04:57,680
detection results

122
00:04:57,680 --> 00:05:01,120
that means we have to optimize blur

123
00:05:01,120 --> 00:05:01,919
patterns

124
00:05:01,919 --> 00:05:06,800
against black box object detectors

125
00:05:06,800 --> 00:05:09,280
so for the first challenge that is how

126
00:05:09,280 --> 00:05:10,720
acoustic signals affect

127
00:05:10,720 --> 00:05:14,080
sensors existing work such as walnut

128
00:05:14,080 --> 00:05:16,960
has shown the feasibility to manipulate

129
00:05:16,960 --> 00:05:18,720
inertial sensor readings

130
00:05:18,720 --> 00:05:22,720
by resonance of acoustic signals

131
00:05:22,720 --> 00:05:25,360
thus we use the manipulated sensor

132
00:05:25,360 --> 00:05:27,840
readings to quantify the camera motions

133
00:05:27,840 --> 00:05:30,960
caused by acoustic signals we especially

134
00:05:30,960 --> 00:05:34,000
pay attention to the motions along the x

135
00:05:34,000 --> 00:05:37,680
y and z axes of accelerometers

136
00:05:37,680 --> 00:05:41,039
and the jaw axis of gyroscope to ease

137
00:05:41,039 --> 00:05:44,000
the burden of modeling the blur patterns

138
00:05:44,000 --> 00:05:46,320
after that the image stabilization

139
00:05:46,320 --> 00:05:47,919
module will composite

140
00:05:47,919 --> 00:05:50,720
the non-existent camera motions caused

141
00:05:50,720 --> 00:05:51,680
by

142
00:05:51,680 --> 00:05:54,880
acoustic signals resulting into pixel

143
00:05:54,880 --> 00:05:56,560
level perturbation

144
00:05:56,560 --> 00:06:00,400
we model three types of pixel motions

145
00:06:00,400 --> 00:06:03,680
which are linear radial and rotational

146
00:06:03,680 --> 00:06:06,639
pixel motions

147
00:06:06,639 --> 00:06:08,800
we also built a heterogeneous motion

148
00:06:08,800 --> 00:06:09,759
blur model

149
00:06:09,759 --> 00:06:12,000
to describe the blur patterns caused by

150
00:06:12,000 --> 00:06:13,120
motions from

151
00:06:13,120 --> 00:06:16,080
more than one axis the visual

152
00:06:16,080 --> 00:06:18,319
appearances of the four polar patterns

153
00:06:18,319 --> 00:06:22,160
are shown in the four figures

154
00:06:22,880 --> 00:06:25,600
besides the first challenge finding the

155
00:06:25,600 --> 00:06:26,080
most

156
00:06:26,080 --> 00:06:28,880
effective and efficient adversarial

157
00:06:28,880 --> 00:06:30,080
blurry image is

158
00:06:30,080 --> 00:06:33,520
neither trivial first the acoustic

159
00:06:33,520 --> 00:06:34,000
signals

160
00:06:34,000 --> 00:06:36,319
can be ejected from four degrees of

161
00:06:36,319 --> 00:06:37,440
freedom

162
00:06:37,440 --> 00:06:40,560
with different amplitudes resulting in a

163
00:06:40,560 --> 00:06:41,199
large

164
00:06:41,199 --> 00:06:44,400
parameter space second

165
00:06:44,400 --> 00:06:47,039
in the real world attacks we usually

166
00:06:47,039 --> 00:06:48,319
know nothing about

167
00:06:48,319 --> 00:06:51,039
the object detector except for their

168
00:06:51,039 --> 00:06:52,080
outputs

169
00:06:52,080 --> 00:06:54,880
not to mention the gradient information

170
00:06:54,880 --> 00:06:55,360
for

171
00:06:55,360 --> 00:06:58,479
white box detectors third

172
00:06:58,479 --> 00:07:00,960
as we inject acoustic signals into

173
00:07:00,960 --> 00:07:02,319
camera systems

174
00:07:02,319 --> 00:07:05,759
for adversarial examples the examples

175
00:07:05,759 --> 00:07:08,400
are restricted by physical constraints

176
00:07:08,400 --> 00:07:11,520
like transmitting power

177
00:07:11,520 --> 00:07:14,240
so to tackle this challenge we first

178
00:07:14,240 --> 00:07:14,800
decide

179
00:07:14,800 --> 00:07:17,440
objective functions for each of the

180
00:07:17,440 --> 00:07:18,639
attacks

181
00:07:18,639 --> 00:07:21,680
taking attack effectiveness cost and

182
00:07:21,680 --> 00:07:22,880
physical constraints

183
00:07:22,880 --> 00:07:26,000
into consideration then we use

184
00:07:26,000 --> 00:07:28,240
vision optimizer to find feasible

185
00:07:28,240 --> 00:07:29,759
solutions

186
00:07:29,759 --> 00:07:32,319
patient optimization is a gradient-free

187
00:07:32,319 --> 00:07:33,120
measured

188
00:07:33,120 --> 00:07:35,759
especially working well for black box

189
00:07:35,759 --> 00:07:38,000
optimization problems

190
00:07:38,000 --> 00:07:40,479
it takes the object detection results as

191
00:07:40,479 --> 00:07:41,120
input

192
00:07:41,120 --> 00:07:43,680
and can generate adversarial blurry

193
00:07:43,680 --> 00:07:44,319
images

194
00:07:44,319 --> 00:07:47,039
as we want

195
00:07:48,319 --> 00:07:51,440
combining all about together we designed

196
00:07:51,440 --> 00:07:52,560
the portal guide

197
00:07:52,560 --> 00:07:56,000
system and it includes three key

198
00:07:56,000 --> 00:07:59,360
building blocks which are blur pattern

199
00:07:59,360 --> 00:08:00,560
modeling

200
00:08:00,560 --> 00:08:03,520
attack parameter optimization and sensor

201
00:08:03,520 --> 00:08:04,000
output

202
00:08:04,000 --> 00:08:06,720
injection for a real world attack if the

203
00:08:06,720 --> 00:08:08,000
adversary has a

204
00:08:08,000 --> 00:08:11,039
image of the target in hand the

205
00:08:11,039 --> 00:08:12,240
adversary first

206
00:08:12,240 --> 00:08:15,520
obtains the visible attack parameter

207
00:08:15,520 --> 00:08:18,479
with the blur pattern modeling and the

208
00:08:18,479 --> 00:08:21,440
parameter optimization blocks

209
00:08:21,440 --> 00:08:24,160
then the adversary manipulates the

210
00:08:24,160 --> 00:08:25,199
sensor outputs

211
00:08:25,199 --> 00:08:28,720
by injecting acoustic signals with the

212
00:08:28,720 --> 00:08:30,400
derived parameters

213
00:08:30,400 --> 00:08:33,679
to finally achieve the h a c

214
00:08:33,679 --> 00:08:36,718
and a attacks

215
00:08:38,880 --> 00:08:41,120
to evaluate the performance of portrait

216
00:08:41,120 --> 00:08:42,080
guides

217
00:08:42,080 --> 00:08:45,120
we conducted both simulation and

218
00:08:45,120 --> 00:08:48,880
real world evaluation for the simulation

219
00:08:48,880 --> 00:08:49,839
evaluation

220
00:08:49,839 --> 00:08:52,640
we used two popular self-driving data

221
00:08:52,640 --> 00:08:53,600
sets

222
00:08:53,600 --> 00:08:57,040
that is bdd 100k and kt

223
00:08:57,040 --> 00:08:59,839
and generate added several blurry images

224
00:08:59,839 --> 00:09:01,600
with our models

225
00:09:01,600 --> 00:09:04,320
then we use the blurry images to attack

226
00:09:04,320 --> 00:09:05,360
a file

227
00:09:05,360 --> 00:09:08,240
stated with the art object detectors

228
00:09:08,240 --> 00:09:10,640
including four academic ones

229
00:09:10,640 --> 00:09:14,080
which are faster arsenal and eulogy

230
00:09:14,080 --> 00:09:17,120
v4 and v5 and also

231
00:09:17,120 --> 00:09:20,839
a commercial detector that is baidu

232
00:09:20,839 --> 00:09:22,080
apollo

233
00:09:22,080 --> 00:09:24,480
during the experiments we take the

234
00:09:24,480 --> 00:09:26,560
following file objects

235
00:09:26,560 --> 00:09:30,480
that are person car track traffic light

236
00:09:30,480 --> 00:09:32,800
and a stop sign as our object of

237
00:09:32,800 --> 00:09:35,200
interest

238
00:09:35,200 --> 00:09:38,640
first in terms of attack effectiveness

239
00:09:38,640 --> 00:09:40,959
the hiding attack which is hd can

240
00:09:40,959 --> 00:09:42,399
achieve 100

241
00:09:42,399 --> 00:09:45,519
percent success rate against all of the

242
00:09:45,519 --> 00:09:48,959
tested object detectors which means that

243
00:09:48,959 --> 00:09:52,959
aha can hide any object of interest

244
00:09:52,959 --> 00:09:55,920
such as person traffic lights and zero

245
00:09:55,920 --> 00:09:56,560
four

246
00:09:56,560 --> 00:10:00,000
h.a will be the most dangerous attack

247
00:10:00,000 --> 00:10:02,959
in real life

248
00:10:03,519 --> 00:10:06,959
for creating texts targeted attacks

249
00:10:06,959 --> 00:10:10,240
are much harder than untargeted ones

250
00:10:10,240 --> 00:10:13,519
nevertheless we can achieve more than 20

251
00:10:13,519 --> 00:10:19,120
success rates for most of the detectors

252
00:10:19,120 --> 00:10:22,000
well for altering attacks just like

253
00:10:22,000 --> 00:10:23,360
creating attack

254
00:10:23,360 --> 00:10:26,720
targeted attacks are also

255
00:10:26,720 --> 00:10:29,760
more challenging comparing authoring

256
00:10:29,760 --> 00:10:32,079
attacks with creating text

257
00:10:32,079 --> 00:10:34,959
the overall success rates are lower

258
00:10:34,959 --> 00:10:35,760
because

259
00:10:35,760 --> 00:10:38,720
creating from non-existent objects is

260
00:10:38,720 --> 00:10:39,760
more difficult

261
00:10:39,760 --> 00:10:46,160
than from an existing but different one

262
00:10:46,160 --> 00:10:49,040
besides the simulation evaluation for

263
00:10:49,040 --> 00:10:49,440
the

264
00:10:49,440 --> 00:10:53,200
real world evaluation the attack devices

265
00:10:53,200 --> 00:10:56,160
include an ultrasonic speaker connected

266
00:10:56,160 --> 00:10:56,560
with

267
00:10:56,560 --> 00:10:59,200
a signal generator and an audio

268
00:10:59,200 --> 00:11:00,560
amplifier

269
00:11:00,560 --> 00:11:03,920
and the victim device is a samsung s20

270
00:11:03,920 --> 00:11:04,880
smartphone

271
00:11:04,880 --> 00:11:08,399
running yellow detectors we also place a

272
00:11:08,399 --> 00:11:10,720
reference smartphone to provide ground

273
00:11:10,720 --> 00:11:11,360
truth

274
00:11:11,360 --> 00:11:14,880
without signal injection the experiments

275
00:11:14,880 --> 00:11:17,120
are conducted on a moving vehicle

276
00:11:17,120 --> 00:11:20,640
in four things including city lane

277
00:11:20,640 --> 00:11:25,760
city crossroad tunnel and campus road

278
00:11:25,839 --> 00:11:27,920
here are the three real world attack

279
00:11:27,920 --> 00:11:28,880
videos

280
00:11:28,880 --> 00:11:31,440
the first one is hiding attack in which

281
00:11:31,440 --> 00:11:33,519
a car is hitting during the attack

282
00:11:33,519 --> 00:11:36,320
process in the second attack we

283
00:11:36,320 --> 00:11:37,839
successfully created

284
00:11:37,839 --> 00:11:41,279
a non-existing trunk and for the

285
00:11:41,279 --> 00:11:43,920
altering attack a car is changed into a

286
00:11:43,920 --> 00:11:45,279
person

287
00:11:45,279 --> 00:11:47,920
for more details please refer to our

288
00:11:47,920 --> 00:11:50,399
website

289
00:11:51,200 --> 00:11:54,240
we also compare the real world images

290
00:11:54,240 --> 00:11:56,959
captured under attacks and the ones

291
00:11:56,959 --> 00:11:57,839
simulated

292
00:11:57,839 --> 00:12:01,519
by our blur models take a city crossroad

293
00:12:01,519 --> 00:12:04,560
picture as an example the images

294
00:12:04,560 --> 00:12:06,880
during real-world attacks show similar

295
00:12:06,880 --> 00:12:08,079
blur patterns

296
00:12:08,079 --> 00:12:10,720
as the simulated ones for a sim tech

297
00:12:10,720 --> 00:12:11,440
goal

298
00:12:11,440 --> 00:12:15,279
that is creating a bench from the zebra

299
00:12:15,279 --> 00:12:17,760
crossing

300
00:12:18,399 --> 00:12:20,880
we also compare the success rates of

301
00:12:20,880 --> 00:12:21,920
three attacks

302
00:12:21,920 --> 00:12:25,040
in different scenes we find that all

303
00:12:25,040 --> 00:12:26,079
three attacks

304
00:12:26,079 --> 00:12:29,360
are visible in particular hiding attacks

305
00:12:29,360 --> 00:12:32,240
show the best performance in all four

306
00:12:32,240 --> 00:12:33,600
things

307
00:12:33,600 --> 00:12:37,519
which coincides with the conclusion of

308
00:12:37,519 --> 00:12:41,440
simulation evaluation in addition

309
00:12:41,440 --> 00:12:44,480
we evaluate the attack distances

310
00:12:44,480 --> 00:12:47,600
attack power of 10 watts spices

311
00:12:47,600 --> 00:12:52,320
to launch an attack from one meter away

312
00:12:52,320 --> 00:12:55,279
to defend against the poltergeist we can

313
00:12:55,279 --> 00:12:55,680
use

314
00:12:55,680 --> 00:12:58,240
safeguarding like shielding or add patch

315
00:12:58,240 --> 00:13:01,600
to the stabilization algorithms

316
00:13:01,600 --> 00:13:04,320
in summary we propose porter guides and

317
00:13:04,320 --> 00:13:06,079
acoustic adversarial machine learning

318
00:13:06,079 --> 00:13:08,720
against the camera and cleaner vision

319
00:13:08,720 --> 00:13:11,279
more importantly we summarize

320
00:13:11,279 --> 00:13:12,160
portalguides

321
00:13:12,160 --> 00:13:15,440
as an instance of a new class of attack

322
00:13:15,440 --> 00:13:18,800
that is ample attacks

323
00:13:18,800 --> 00:13:21,600
by combining the weakness in the physics

324
00:13:21,600 --> 00:13:22,720
of hardware

325
00:13:22,720 --> 00:13:25,440
and in adversarial machine learning to

326
00:13:25,440 --> 00:13:26,240
finally

327
00:13:26,240 --> 00:13:29,519
cause a system level exploit

328
00:13:29,519 --> 00:13:32,720
that is the so-called four ounces can

329
00:13:32,720 --> 00:13:33,120
move

330
00:13:33,120 --> 00:13:36,240
a thousand pounds

331
00:13:36,240 --> 00:13:38,639
that is all my presentation thanks for

332
00:13:38,639 --> 00:13:40,320
listening and welcome

333
00:13:40,320 --> 00:13:48,160
any questions

