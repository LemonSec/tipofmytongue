1
00:00:00,160 --> 00:00:02,159
hello everyone my name is trojan i'm

2
00:00:02,159 --> 00:00:04,160
going to present our research work stock

3
00:00:04,160 --> 00:00:05,839
fast a sound and cost

4
00:00:05,839 --> 00:00:07,919
effective filing technique for stripped

5
00:00:07,919 --> 00:00:09,200
binary

6
00:00:09,200 --> 00:00:11,200
greenbox fuzzing is one of the most

7
00:00:11,200 --> 00:00:12,960
important techniques for software

8
00:00:12,960 --> 00:00:13,679
testing and

9
00:00:13,679 --> 00:00:16,560
architecture by finding google has found

10
00:00:16,560 --> 00:00:17,840
thousands of bugs

11
00:00:17,840 --> 00:00:19,680
there are also more than one hundred

12
00:00:19,680 --> 00:00:21,439
thousand papers published in

13
00:00:21,439 --> 00:00:24,160
top conference this year funding is

14
00:00:24,160 --> 00:00:25,920
indeed a stochastic process

15
00:00:25,920 --> 00:00:28,560
which excuse program with random input

16
00:00:28,560 --> 00:00:30,400
different from black box fuzzing

17
00:00:30,400 --> 00:00:32,238
greenbox fuzzing can narrate runtime

18
00:00:32,238 --> 00:00:33,440
feedback to learn

19
00:00:33,440 --> 00:00:35,840
how to reach deep states during program

20
00:00:35,840 --> 00:00:36,960
execution

21
00:00:36,960 --> 00:00:39,440
lib father and afl which are the most

22
00:00:39,440 --> 00:00:41,280
popular greenbox filing tools

23
00:00:41,280 --> 00:00:44,160
take the code coverage as feedback here

24
00:00:44,160 --> 00:00:46,079
are the typical workflow of lip filter

25
00:00:46,079 --> 00:00:47,200
and fl

26
00:00:47,200 --> 00:00:50,239
in short user use compiler to instrument

27
00:00:50,239 --> 00:00:51,199
the source code

28
00:00:51,199 --> 00:00:53,440
after that a stochastic process is

29
00:00:53,440 --> 00:00:54,320
performed

30
00:00:54,320 --> 00:00:56,640
where the father generates random inputs

31
00:00:56,640 --> 00:00:58,399
and the binary connects runtime code

32
00:00:58,399 --> 00:01:01,280
coverage to guide future input mutation

33
00:01:01,280 --> 00:01:04,000
however there is another situation named

34
00:01:04,000 --> 00:01:05,119
binary only fuzzy

35
00:01:05,119 --> 00:01:07,360
in that case people cannot access the

36
00:01:07,360 --> 00:01:10,000
source code but only stripped binary

37
00:01:10,000 --> 00:01:11,760
as such compiler compiler-based

38
00:01:11,760 --> 00:01:13,600
instrumentation cannot be performed

39
00:01:13,600 --> 00:01:16,159
hence father cannot get code coverage as

40
00:01:16,159 --> 00:01:17,200
guidance

41
00:01:17,200 --> 00:01:19,600
on the other hand bugs in close source

42
00:01:19,600 --> 00:01:22,320
program can also have serious impact

43
00:01:22,320 --> 00:01:24,240
an effective binary only funding

44
00:01:24,240 --> 00:01:26,000
technique is critical for software

45
00:01:26,000 --> 00:01:27,040
security

46
00:01:27,040 --> 00:01:28,799
many solution has been proposed for

47
00:01:28,799 --> 00:01:30,240
binary only fuzzing

48
00:01:30,240 --> 00:01:32,079
the first one use dynamic transmission

49
00:01:32,079 --> 00:01:34,000
engine such as cumulon pin

50
00:01:34,000 --> 00:01:36,159
which traps execution and transmits the

51
00:01:36,159 --> 00:01:37,520
code on the fly

52
00:01:37,520 --> 00:01:40,000
the method is sound but expensive due to

53
00:01:40,000 --> 00:01:41,840
the heavyweight machinery

54
00:01:41,840 --> 00:01:44,079
the second one use hardware supports

55
00:01:44,079 --> 00:01:45,840
such as interpretive to connect

56
00:01:45,840 --> 00:01:47,119
long-term traces

57
00:01:47,119 --> 00:01:49,759
however these traces are generated at a

58
00:01:49,759 --> 00:01:50,960
very high rate

59
00:01:50,960 --> 00:01:53,520
and hence require substantial efforts to

60
00:01:53,520 --> 00:01:54,479
process

61
00:01:54,479 --> 00:01:56,880
it is also difficult to collect runtime

62
00:01:56,880 --> 00:01:57,520
information

63
00:01:57,520 --> 00:02:00,159
other than counterflow traces the third

64
00:02:00,159 --> 00:02:02,479
one is static binary instrumentation

65
00:02:02,479 --> 00:02:04,719
it leverages binary analysis to do

66
00:02:04,719 --> 00:02:06,159
writing before fuzzing

67
00:02:06,159 --> 00:02:08,720
although it is cost effective some

68
00:02:08,720 --> 00:02:10,878
static binary writing is an undecidable

69
00:02:10,878 --> 00:02:12,560
problem due to the lack of simple

70
00:02:12,560 --> 00:02:13,680
information

71
00:02:13,680 --> 00:02:16,080
to achieve better funding performance we

72
00:02:16,080 --> 00:02:17,920
also choose static battery writing to

73
00:02:17,920 --> 00:02:19,760
enable binary online

74
00:02:19,760 --> 00:02:21,360
let's first discuss the challenge of

75
00:02:21,360 --> 00:02:23,599
static by rewriting

76
00:02:23,599 --> 00:02:25,599
the code on the next site consists of

77
00:02:25,599 --> 00:02:28,000
two code sections code1 and co2

78
00:02:28,000 --> 00:02:30,480
and an internally data section on the

79
00:02:30,480 --> 00:02:31,200
right side

80
00:02:31,200 --> 00:02:33,360
represents the execution traces where

81
00:02:33,360 --> 00:02:34,959
the executed instruction

82
00:02:34,959 --> 00:02:37,440
destination registers and the evaluation

83
00:02:37,440 --> 00:02:38,080
results

84
00:02:38,080 --> 00:02:40,480
are listed in the first three columns

85
00:02:40,480 --> 00:02:41,519
respectively

86
00:02:41,519 --> 00:02:43,760
the last column presents a related

87
00:02:43,760 --> 00:02:44,560
section

88
00:02:44,560 --> 00:02:47,040
if the evaluation result is addressed

89
00:02:47,040 --> 00:02:48,239
relevant

90
00:02:48,239 --> 00:02:50,319
the first instruction notes the address

91
00:02:50,319 --> 00:02:51,280
of data section

92
00:02:51,280 --> 00:02:55,120
into rx in this case the address is 15

93
00:02:55,120 --> 00:02:57,280
the second instruction notes and cost 8

94
00:02:57,280 --> 00:02:58,560
from data section

95
00:02:58,560 --> 00:03:01,760
into rbx the class 8 denotes the offset

96
00:03:01,760 --> 00:03:04,159
between address 23 and 50

97
00:03:04,159 --> 00:03:07,360
which we will explain later next rbx is

98
00:03:07,360 --> 00:03:08,800
added to rx

99
00:03:08,800 --> 00:03:11,200
note that the value of rx denotes the

100
00:03:11,200 --> 00:03:12,239
address 15

101
00:03:12,239 --> 00:03:14,879
and the value of rbx denotes the offset

102
00:03:14,879 --> 00:03:17,040
between address 23 and 15.

103
00:03:17,040 --> 00:03:20,720
the result will be 23 in other words the

104
00:03:20,720 --> 00:03:22,319
address of code 2.

105
00:03:22,319 --> 00:03:24,400
an indirect jump is performed to jump to

106
00:03:24,400 --> 00:03:25,519
call to section

107
00:03:25,519 --> 00:03:28,720
and then return actually there are

108
00:03:28,720 --> 00:03:30,560
two fundamental challenges of static

109
00:03:30,560 --> 00:03:32,959
battery writing the first change is to

110
00:03:32,959 --> 00:03:35,360
identify the interleaved data section

111
00:03:35,360 --> 00:03:37,519
and it is fundamentally undecidable if

112
00:03:37,519 --> 00:03:40,239
we fail to separate data from code

113
00:03:40,239 --> 00:03:42,959
we may rewrite this data as code result

114
00:03:42,959 --> 00:03:44,319
in rewriting error

115
00:03:44,319 --> 00:03:46,720
additionally this inline data increase

116
00:03:46,720 --> 00:03:48,640
the difficulty of finding indirect jump

117
00:03:48,640 --> 00:03:49,360
targets

118
00:03:49,360 --> 00:03:52,080
for example co2 section in addition

119
00:03:52,080 --> 00:03:54,000
distinguishing between scanners and the

120
00:03:54,000 --> 00:03:56,319
address offsets is another undecidable

121
00:03:56,319 --> 00:03:57,120
problem

122
00:03:57,120 --> 00:03:59,040
considering the class 8 we needed to

123
00:03:59,040 --> 00:04:00,879
know whether it is a simple numerical

124
00:04:00,879 --> 00:04:01,519
value

125
00:04:01,519 --> 00:04:03,920
or it serves as an offset note that

126
00:04:03,920 --> 00:04:06,239
rewriting has no effect on a scanner

127
00:04:06,239 --> 00:04:06,720
value

128
00:04:06,720 --> 00:04:09,360
that is not an offset but it may change

129
00:04:09,360 --> 00:04:10,640
an offset value because

130
00:04:10,640 --> 00:04:12,239
instructions may get shifted by

131
00:04:12,239 --> 00:04:14,239
instrumentation according to our

132
00:04:14,239 --> 00:04:15,120
experiment

133
00:04:15,120 --> 00:04:17,120
three state-of-the-art binary static

134
00:04:17,120 --> 00:04:19,040
writing technique all fails on some

135
00:04:19,040 --> 00:04:20,079
programs

136
00:04:20,079 --> 00:04:22,079
the first technique we introduced here

137
00:04:22,079 --> 00:04:24,000
is named incremental writing

138
00:04:24,000 --> 00:04:26,639
it is based on the insight that while

139
00:04:26,639 --> 00:04:28,479
greenbox further continue mutate

140
00:04:28,479 --> 00:04:31,280
inputs across test runs they may as well

141
00:04:31,280 --> 00:04:33,280
be enhanced to notice the program on the

142
00:04:33,280 --> 00:04:33,919
fly

143
00:04:33,919 --> 00:04:36,240
as such example and aesthetic writing

144
00:04:36,240 --> 00:04:38,960
can be incrementally performed over time

145
00:04:38,960 --> 00:04:40,800
our basic idea is to trigger an

146
00:04:40,800 --> 00:04:43,280
intentional crash once an unresolved

147
00:04:43,280 --> 00:04:43,759
target

148
00:04:43,759 --> 00:04:45,759
is reached starting from the address

149
00:04:45,759 --> 00:04:47,199
where the crash happens

150
00:04:47,199 --> 00:04:50,400
we can do incremental writing then we'll

151
00:04:50,400 --> 00:04:52,160
talk about how our technique handled the

152
00:04:52,160 --> 00:04:53,600
motivation case

153
00:04:53,600 --> 00:04:55,360
let's first assume that we our

154
00:04:55,360 --> 00:04:57,600
underlying binary analysis can find the

155
00:04:57,600 --> 00:04:59,120
indirect jump target code 2

156
00:04:59,120 --> 00:05:02,160
at address 23 we additional assume

157
00:05:02,160 --> 00:05:04,800
we can distinguish code and data

158
00:05:04,800 --> 00:05:07,039
incremental writing starts by an initial

159
00:05:07,039 --> 00:05:07,840
writing step

160
00:05:07,840 --> 00:05:09,919
which is to guarantee that the program

161
00:05:09,919 --> 00:05:12,080
will rise an intentional crash

162
00:05:12,080 --> 00:05:14,800
when it reaches an unresolved place to

163
00:05:14,800 --> 00:05:15,440
do so

164
00:05:15,440 --> 00:05:18,000
we patch all code at the hlt instruction

165
00:05:18,000 --> 00:05:20,320
those sqlt instruction will trigger a

166
00:05:20,320 --> 00:05:22,639
segment fault once executed

167
00:05:22,639 --> 00:05:24,960
which denotes an unresolved target in

168
00:05:24,960 --> 00:05:27,680
this case the code from address 0 to 13

169
00:05:27,680 --> 00:05:30,960
and the one at address 23 are replaced

170
00:05:30,960 --> 00:05:32,639
by hrt instruction

171
00:05:32,639 --> 00:05:34,720
we additionally rewrite the address that

172
00:05:34,720 --> 00:05:35,680
we know for sure

173
00:05:35,680 --> 00:05:37,360
that they are instruction instead of

174
00:05:37,360 --> 00:05:39,680
data to a higher space where is

175
00:05:39,680 --> 00:05:41,039
instrumentation applied

176
00:05:41,039 --> 00:05:43,199
in this case since the starting code

177
00:05:43,199 --> 00:05:44,479
address is 0

178
00:05:44,479 --> 00:05:46,320
all the addresses directly reachable

179
00:05:46,320 --> 00:05:48,400
from address 0 must be called

180
00:05:48,400 --> 00:05:50,880
as such the first 4 instructions in the

181
00:05:50,880 --> 00:05:53,120
shadow are copied to address 100

182
00:05:53,120 --> 00:05:56,240
and a juncture 19 is put at address zero

183
00:05:56,240 --> 00:05:58,880
observe that our ip plus 8 in the red

184
00:05:58,880 --> 00:05:59,280
box

185
00:05:59,280 --> 00:06:02,080
is changed to rip minus 92 at the higher

186
00:06:02,080 --> 00:06:02,800
address

187
00:06:02,800 --> 00:06:04,800
it is because we are trying to make sure

188
00:06:04,800 --> 00:06:07,280
that the evaluation result of each

189
00:06:07,280 --> 00:06:08,800
instruction unchanged

190
00:06:08,800 --> 00:06:11,680
before and after writing decided by this

191
00:06:11,680 --> 00:06:13,919
property the indirect jump at address

192
00:06:13,919 --> 00:06:16,560
113 will go to the original target

193
00:06:16,560 --> 00:06:18,000
address 23

194
00:06:18,000 --> 00:06:19,919
which will trigger an intentional crash

195
00:06:19,919 --> 00:06:21,199
during a fighting run

196
00:06:21,199 --> 00:06:23,360
it indicates 23 is a counter flow

197
00:06:23,360 --> 00:06:24,800
transfer target

198
00:06:24,800 --> 00:06:26,800
the second step incremental writing is

199
00:06:26,800 --> 00:06:28,880
designed to generate a new binary

200
00:06:28,880 --> 00:06:30,720
which will write all the addresses that

201
00:06:30,720 --> 00:06:32,560
can be directly reachable from the

202
00:06:32,560 --> 00:06:34,560
crashing address however it

203
00:06:34,560 --> 00:06:36,720
is in general an undisabled problem to

204
00:06:36,720 --> 00:06:38,479
separate code and data

205
00:06:38,479 --> 00:06:40,479
in previous example the program will

206
00:06:40,479 --> 00:06:42,400
encounter an unintentional crash if we

207
00:06:42,400 --> 00:06:44,240
patch the data at address 15.

208
00:06:44,240 --> 00:06:46,160
to address the problem we propose

209
00:06:46,160 --> 00:06:48,240
stochastic writing which is driven by

210
00:06:48,240 --> 00:06:49,680
the following insight

211
00:06:49,680 --> 00:06:51,759
as fasting provides a large number of

212
00:06:51,759 --> 00:06:53,599
opportunities for try and error

213
00:06:53,599 --> 00:06:55,199
we can try different data and code

214
00:06:55,199 --> 00:06:57,199
separation which leads to different

215
00:06:57,199 --> 00:06:59,280
binaries for different funding runs

216
00:06:59,280 --> 00:07:01,199
over time a large number of samples can

217
00:07:01,199 --> 00:07:03,360
be connected allowing us to achieve the

218
00:07:03,360 --> 00:07:06,319
precise separation and correct rewriting

219
00:07:06,319 --> 00:07:08,319
stochastic rewriting is piggybacking on

220
00:07:08,319 --> 00:07:09,680
the farming procedure

221
00:07:09,680 --> 00:07:12,160
it is enabled by a probability analysis

222
00:07:12,160 --> 00:07:13,919
for code and data separation

223
00:07:13,919 --> 00:07:15,759
it will generate different binaries for

224
00:07:15,759 --> 00:07:17,039
different fighting runs

225
00:07:17,039 --> 00:07:19,280
it can also locate and repair rewriting

226
00:07:19,280 --> 00:07:21,039
arrow on the fly

227
00:07:21,039 --> 00:07:22,800
we will continue using the previous

228
00:07:22,800 --> 00:07:24,880
example to demonstrate how stochastic

229
00:07:24,880 --> 00:07:27,120
writing work at the beginning the

230
00:07:27,120 --> 00:07:27,919
probability

231
00:07:27,919 --> 00:07:30,240
analysis is performed where we compute

232
00:07:30,240 --> 00:07:31,919
the probability for each address

233
00:07:31,919 --> 00:07:33,680
belonging to data on the fly

234
00:07:33,680 --> 00:07:35,759
as it is certain that the first four

235
00:07:35,759 --> 00:07:37,120
instructions are code

236
00:07:37,120 --> 00:07:40,160
zero probability are zero address 23 is

237
00:07:40,160 --> 00:07:40,880
uncertain

238
00:07:40,880 --> 00:07:43,039
but it is likely to be code so its

239
00:07:43,039 --> 00:07:45,039
probability is 0.1

240
00:07:45,039 --> 00:07:46,800
note that the analysis may be wrong

241
00:07:46,800 --> 00:07:48,240
sometimes in this case

242
00:07:48,240 --> 00:07:50,639
we assume the probability of address 15

243
00:07:50,639 --> 00:07:52,639
is only 0.3

244
00:07:52,639 --> 00:07:54,800
based on the computed probabilities we

245
00:07:54,800 --> 00:07:56,080
do initial rewriting

246
00:07:56,080 --> 00:07:58,000
specifically we patch all certain

247
00:07:58,000 --> 00:08:00,160
addresses with hlt

248
00:08:00,160 --> 00:08:01,680
for other addresses with small

249
00:08:01,680 --> 00:08:03,840
probabilities we randomly select some of

250
00:08:03,840 --> 00:08:04,879
them to patch

251
00:08:04,879 --> 00:08:07,039
in this case we assume that with patch

252
00:08:07,039 --> 00:08:08,879
address 15 and 23

253
00:08:08,879 --> 00:08:11,039
note that we in fact generate many

254
00:08:11,039 --> 00:08:12,000
random versions

255
00:08:12,000 --> 00:08:13,919
different details can be found in our

256
00:08:13,919 --> 00:08:15,520
paper as such

257
00:08:15,520 --> 00:08:17,520
the program encounters an unintentional

258
00:08:17,520 --> 00:08:19,680
crash due to the mispatch

259
00:08:19,680 --> 00:08:21,520
after that we are going to check whether

260
00:08:21,520 --> 00:08:24,000
it is caused by a rewriting error or not

261
00:08:24,000 --> 00:08:26,080
it is done by removing all uncertain

262
00:08:26,080 --> 00:08:28,000
packs and rerun the program

263
00:08:28,000 --> 00:08:30,560
if the crash cannot be reproduced it is

264
00:08:30,560 --> 00:08:31,840
a rewriting arrow

265
00:08:31,840 --> 00:08:34,000
in this case we remove the patch on

266
00:08:34,000 --> 00:08:35,599
address 15 and 23

267
00:08:35,599 --> 00:08:39,200
and the program exit normally indicating

268
00:08:39,200 --> 00:08:40,880
there is a rewriting error

269
00:08:40,880 --> 00:08:43,120
note that we ignore the higher space

270
00:08:43,120 --> 00:08:45,200
because they are less interesting

271
00:08:45,200 --> 00:08:47,360
the next step is to locating rewriting

272
00:08:47,360 --> 00:08:49,040
arrows where we generate multiple

273
00:08:49,040 --> 00:08:49,600
versions

274
00:08:49,600 --> 00:08:51,440
with different uncertain patches and

275
00:08:51,440 --> 00:08:53,200
observe their behavior

276
00:08:53,200 --> 00:08:55,519
in this case we generate two versions of

277
00:08:55,519 --> 00:08:56,240
binary

278
00:08:56,240 --> 00:08:57,920
we observe that the crash can be

279
00:08:57,920 --> 00:08:59,839
reproduced with address 15

280
00:08:59,839 --> 00:09:02,880
patched but not with address 23 so that

281
00:09:02,880 --> 00:09:04,959
we can know address 15 is a data byte

282
00:09:04,959 --> 00:09:05,279
and

283
00:09:05,279 --> 00:09:08,560
address 23 is not most importantly

284
00:09:08,560 --> 00:09:10,160
without him we can refine the

285
00:09:10,160 --> 00:09:13,760
probability for a better rewriting

286
00:09:13,760 --> 00:09:15,839
to enable effective probabilistic

287
00:09:15,839 --> 00:09:17,760
analysis we propose a universal

288
00:09:17,760 --> 00:09:19,680
counterflow graph for dissembling

289
00:09:19,680 --> 00:09:22,480
we present a simple example of ucfg on

290
00:09:22,480 --> 00:09:24,160
the right side we show the instructions

291
00:09:24,160 --> 00:09:25,760
decoding at each address

292
00:09:25,760 --> 00:09:27,760
the first column shows the addresses the

293
00:09:27,760 --> 00:09:29,279
second shows the byte value

294
00:09:29,279 --> 00:09:31,839
the third shows the instruction size and

295
00:09:31,839 --> 00:09:33,760
the another shows the instruction

296
00:09:33,760 --> 00:09:35,600
for example the first three bytes are

297
00:09:35,600 --> 00:09:38,160
decoded to an xor instruction

298
00:09:38,160 --> 00:09:39,519
note that the green shadow of the

299
00:09:39,519 --> 00:09:41,200
instruction are the ground tools

300
00:09:41,200 --> 00:09:43,120
in other words there are the real

301
00:09:43,120 --> 00:09:44,320
instructions

302
00:09:44,320 --> 00:09:46,000
on the left side represents the

303
00:09:46,000 --> 00:09:47,600
corresponding usfg

304
00:09:47,600 --> 00:09:49,839
where a load deloads an instruction and

305
00:09:49,839 --> 00:09:52,320
ages denote explicit cultural flow

306
00:09:52,320 --> 00:09:54,480
note that it is a super graph of the

307
00:09:54,480 --> 00:09:55,760
real staff g

308
00:09:55,760 --> 00:09:58,480
based on the usfg we develop a set of

309
00:09:58,480 --> 00:10:00,399
probabilistic inference rules to

310
00:10:00,399 --> 00:10:02,880
calculate the probability on the fly

311
00:10:02,880 --> 00:10:04,959
for instance one rule is for register

312
00:10:04,959 --> 00:10:06,399
use and define

313
00:10:06,399 --> 00:10:08,640
in short if there is a defined use

314
00:10:08,640 --> 00:10:10,560
relation between two addresses

315
00:10:10,560 --> 00:10:13,040
both addresses are likely to be called

316
00:10:13,040 --> 00:10:13,760
for example

317
00:10:13,760 --> 00:10:16,079
address 0 and 3 read and write the

318
00:10:16,079 --> 00:10:18,560
register r6 so they are likely to be

319
00:10:18,560 --> 00:10:19,279
called

320
00:10:19,279 --> 00:10:21,200
another rule is that the counter flow

321
00:10:21,200 --> 00:10:23,360
cannot reach invented instructions or

322
00:10:23,360 --> 00:10:24,000
data

323
00:10:24,000 --> 00:10:26,240
as such address 5 cannot be an

324
00:10:26,240 --> 00:10:28,399
instruction because its successor is

325
00:10:28,399 --> 00:10:29,360
invented

326
00:10:29,360 --> 00:10:32,399
more rules can be found in our paper

327
00:10:32,399 --> 00:10:35,200
recall that winner to locate and repair

328
00:10:35,200 --> 00:10:37,120
rewriting error effectively

329
00:10:37,120 --> 00:10:39,600
we leverage delta debugging to do so in

330
00:10:39,600 --> 00:10:41,680
short it is a binary search like

331
00:10:41,680 --> 00:10:44,079
separation strategy which enables some

332
00:10:44,079 --> 00:10:45,120
uncertain patch and

333
00:10:45,120 --> 00:10:46,959
then check whether the unintentional

334
00:10:46,959 --> 00:10:48,959
crash can be reproduced

335
00:10:48,959 --> 00:10:50,720
we also address a number of practical

336
00:10:50,720 --> 00:10:52,880
challenges details can be found in our

337
00:10:52,880 --> 00:10:53,920
paper

338
00:10:53,920 --> 00:10:55,680
next i will discuss the evaluation

339
00:10:55,680 --> 00:10:58,000
result our evaluation is conducted on

340
00:10:58,000 --> 00:11:00,320
three benchmarks including google fds a

341
00:11:00,320 --> 00:11:02,320
variant of google fds compiled with

342
00:11:02,320 --> 00:11:03,200
innate data

343
00:11:03,200 --> 00:11:04,880
and the funding benchmark from virtual

344
00:11:04,880 --> 00:11:06,480
right we compare with five

345
00:11:06,480 --> 00:11:08,160
state-of-the-art binary only fashion

346
00:11:08,160 --> 00:11:08,800
tools

347
00:11:08,800 --> 00:11:10,880
including three static writing technique

348
00:11:10,880 --> 00:11:12,560
a hardware assessment technique and a

349
00:11:12,560 --> 00:11:14,160
dynamic translation technique

350
00:11:14,160 --> 00:11:15,680
we additionally compare with two

351
00:11:15,680 --> 00:11:17,839
compiler-based technique as reference

352
00:11:17,839 --> 00:11:19,760
due to time limitation i will discuss

353
00:11:19,760 --> 00:11:21,680
three experiments much more can be found

354
00:11:21,680 --> 00:11:23,040
in our paper

355
00:11:23,040 --> 00:11:24,800
the first experiment is about the

356
00:11:24,800 --> 00:11:27,279
fuzzing efficiency and the experiment is

357
00:11:27,279 --> 00:11:29,440
conducted on google fds

358
00:11:29,440 --> 00:11:31,360
we first present the result on some

359
00:11:31,360 --> 00:11:32,480
programs we take

360
00:11:32,480 --> 00:11:34,880
afltcc as a baseline and the reported

361
00:11:34,880 --> 00:11:36,240
ratio of each two or two

362
00:11:36,240 --> 00:11:39,120
fltcc if the risk is zero it means the

363
00:11:39,120 --> 00:11:40,880
tool cannot handle the program

364
00:11:40,880 --> 00:11:42,320
larger number indicates better

365
00:11:42,320 --> 00:11:44,399
performance different color denotes

366
00:11:44,399 --> 00:11:45,279
different tools

367
00:11:45,279 --> 00:11:47,600
in each bar chart from the left to right

368
00:11:47,600 --> 00:11:49,760
they are for airflow gcc which is always

369
00:11:49,760 --> 00:11:50,320
one

370
00:11:50,320 --> 00:11:53,279
available on fast flow pt fader in eye

371
00:11:53,279 --> 00:11:56,079
patch data log designing and stock files

372
00:11:56,079 --> 00:11:58,720
let's look at the open ssl result we can

373
00:11:58,720 --> 00:11:59,839
see inline patch

374
00:11:59,839 --> 00:12:01,920
and technology demoning both fail on

375
00:12:01,920 --> 00:12:04,480
rewriting it due to their unsound list

376
00:12:04,480 --> 00:12:06,320
in fact existing static writing

377
00:12:06,320 --> 00:12:08,240
technique all failed on some program in

378
00:12:08,240 --> 00:12:09,360
google fds

379
00:12:09,360 --> 00:12:11,839
while stock 5 successes on all of them

380
00:12:11,839 --> 00:12:14,000
then let's look at the json result

381
00:12:14,000 --> 00:12:17,040
we observed that afl cloud fast is the

382
00:12:17,040 --> 00:12:19,519
first one as it is ir-based technique

383
00:12:19,519 --> 00:12:21,760
stock fast is nicely smaller due to our

384
00:12:21,760 --> 00:12:22,959
additional overhead

385
00:12:22,959 --> 00:12:25,200
data log determining also performed well

386
00:12:25,200 --> 00:12:27,279
but note that due to its understanding

387
00:12:27,279 --> 00:12:29,680
it failed on many programs the other

388
00:12:29,680 --> 00:12:32,560
three techniques are relatively slower

389
00:12:32,560 --> 00:12:34,560
we present the average execution number

390
00:12:34,560 --> 00:12:36,160
over 24 programs

391
00:12:36,160 --> 00:12:38,160
we can say that compared with afl clone

392
00:12:38,160 --> 00:12:40,480
fast stock fast only has around 11

393
00:12:40,480 --> 00:12:42,560
percent slowdown on average

394
00:12:42,560 --> 00:12:44,800
other two have higher overhead compared

395
00:12:44,800 --> 00:12:46,720
with dogfast

396
00:12:46,720 --> 00:12:49,120
programs built by popular compiler may

397
00:12:49,120 --> 00:12:49,920
not contain

398
00:12:49,920 --> 00:12:52,560
substantial code and data interleaving

399
00:12:52,560 --> 00:12:54,639
so we modify the combination of google

400
00:12:54,639 --> 00:12:56,959
fts to force read only data to be

401
00:12:56,959 --> 00:12:59,279
interleaved with text section

402
00:12:59,279 --> 00:13:00,880
within study how the number of

403
00:13:00,880 --> 00:13:02,720
intentional crash and unintentional

404
00:13:02,720 --> 00:13:03,360
crash

405
00:13:03,360 --> 00:13:05,440
force positive and false negative change

406
00:13:05,440 --> 00:13:06,720
over fuzzing

407
00:13:06,720 --> 00:13:08,959
the trending is showing on the right the

408
00:13:08,959 --> 00:13:11,120
blue curve is for intentional crash

409
00:13:11,120 --> 00:13:12,720
while the yellow curve is for the

410
00:13:12,720 --> 00:13:15,279
unintentional crash the red curve is for

411
00:13:15,279 --> 00:13:16,720
the false negative rate

412
00:13:16,720 --> 00:13:18,480
while the green curve is for the false

413
00:13:18,480 --> 00:13:20,959
positive rate observe that the blue

414
00:13:20,959 --> 00:13:23,200
curve above the ridge is fixed point

415
00:13:23,200 --> 00:13:24,560
after five minutes

416
00:13:24,560 --> 00:13:27,200
indicates that the whole process of most

417
00:13:27,200 --> 00:13:29,440
converged at the first five minutes

418
00:13:29,440 --> 00:13:31,839
as such we can see that the overhead

419
00:13:31,839 --> 00:13:33,360
caused by the incremental

420
00:13:33,360 --> 00:13:36,480
writing is negligible also observe that

421
00:13:36,480 --> 00:13:38,160
the number of unintentional crash

422
00:13:38,160 --> 00:13:40,240
is very small compared with the

423
00:13:40,240 --> 00:13:41,680
intentional crash

424
00:13:41,680 --> 00:13:43,600
note that the unintentional question may

425
00:13:43,600 --> 00:13:45,680
trigger more expensive

426
00:13:45,680 --> 00:13:48,399
repair process it implies that most

427
00:13:48,399 --> 00:13:50,480
rewriting errors are fixed by observing

428
00:13:50,480 --> 00:13:52,320
new coverage

429
00:13:52,320 --> 00:13:54,639
itunes is a state aware fuzzing

430
00:13:54,639 --> 00:13:56,399
technique which increasing funding

431
00:13:56,399 --> 00:13:58,000
effective activities by

432
00:13:58,000 --> 00:13:59,839
observing how the value of gaming

433
00:13:59,839 --> 00:14:01,120
variable change

434
00:14:01,120 --> 00:14:03,680
let's look at a simple example the code

435
00:14:03,680 --> 00:14:04,959
contains a while loop

436
00:14:04,959 --> 00:14:06,959
inside the while loop there is an if

437
00:14:06,959 --> 00:14:08,000
else statement

438
00:14:08,000 --> 00:14:10,480
for afl to connect code coverage the

439
00:14:10,480 --> 00:14:12,880
compiler instrument has three points

440
00:14:12,880 --> 00:14:14,800
all of them are the starting points of

441
00:14:14,800 --> 00:14:16,160
basic blocks

442
00:14:16,160 --> 00:14:19,760
compared with afl i do automatically

443
00:14:19,760 --> 00:14:22,720
connect the value of x and y which makes

444
00:14:22,720 --> 00:14:24,880
the further observe more state

445
00:14:24,880 --> 00:14:26,720
we put ion to support binary only

446
00:14:26,720 --> 00:14:29,199
phasing based on every acumen and stock

447
00:14:29,199 --> 00:14:30,959
fast and conduct the same base

448
00:14:30,959 --> 00:14:32,800
experiment in the itunes paper

449
00:14:32,800 --> 00:14:34,880
the result shows that stock phase is

450
00:14:34,880 --> 00:14:36,160
around 8 faster than

451
00:14:36,160 --> 00:14:38,000
every cumulative additionally stock

452
00:14:38,000 --> 00:14:40,639
phase only has around 8 percent slowdown

453
00:14:40,639 --> 00:14:43,440
compared with the source-based iso

454
00:14:43,440 --> 00:14:45,120
i will skip the relative work due to

455
00:14:45,120 --> 00:14:47,040
time limitation more can be finding our

456
00:14:47,040 --> 00:14:48,160
paper

457
00:14:48,160 --> 00:14:50,560
so as a result we develop a new filing

458
00:14:50,560 --> 00:14:52,720
technique for strict binary

459
00:14:52,720 --> 00:14:54,639
okay it's the end of my presentation

460
00:14:54,639 --> 00:14:56,399
thank you for your time our system is

461
00:14:56,399 --> 00:14:58,240
available online and you can reach me at

462
00:14:58,240 --> 00:15:01,519
the showing email address

