1
00:00:00,960 --> 00:00:05,440
Hi! My name is Tim Trippel and I'm a Ph.D. 
Candidate at the University of Michigan.  

2
00:00:05,440 --> 00:00:10,480
Today, I'm going to tell you about a technique we 
developed to vet untrusted third party hardware IP  

3
00:00:10,480 --> 00:00:16,240
for Ticking Timebomb Trojans. This is joint work 
with Kang Shin, Kevin Bush, and Matthew Hicks.  

4
00:00:17,840 --> 00:00:21,120
Hardware is the foundation 
of all computing systems.  

5
00:00:21,120 --> 00:00:28,640
From laptops and cloud servers, IoT devices, 
portable electronics, and automated retail spaces,  

6
00:00:28,640 --> 00:00:31,520
to more mission-critical systems 
like network infrastructure,  

7
00:00:32,080 --> 00:00:38,320
medical devices, autonomous vehicles, and drones, 
all computing systems share one thing in common  

8
00:00:38,320 --> 00:00:43,840
they all blindly trust integrated circuit hardware 
to reliably behave according to specification.  

9
00:00:44,880 --> 00:00:49,840
Over the last 15 years computer architects have 
increased the amount of on-chip parallelism  

10
00:00:49,840 --> 00:00:54,880
to overcome performance barriers due to 
fundamental physical limits. And while this  

11
00:00:54,880 --> 00:01:00,400
parallelism started off homogeneous in nature, 
by increasing the number of logical cores,  

12
00:01:00,400 --> 00:01:06,080
it has become heterogeneous over time as domain 
specific accelerators have become commonplace.  

13
00:01:07,040 --> 00:01:12,960
Unfortunately, with increased parallelism comes 
increased complexity. Take the recently released  

14
00:01:12,960 --> 00:01:18,800
Apple M1 SoC for example that has over 24 
different categories of IP blocks on board.  

15
00:01:19,440 --> 00:01:26,480
If we look closely we see the M1 SoC contains both 
general purpose processor cores such as CPUs and  

16
00:01:26,480 --> 00:01:33,520
GPUs, to domain-specific accelerators: such as 
cryptographic accelerators, machine learning  

17
00:01:33,520 --> 00:01:40,479
accelerators, image processing accelerators, and 
many others. In order to minimize time-to-market  

18
00:01:40,480 --> 00:01:45,600
while maintaining feature-rich designs, most 
semiconductor companies outsource portions of  

19
00:01:45,600 --> 00:01:52,559
the design process by purchasing third-party IP 
to include in their designs. Outsourcing combined  

20
00:01:52,560 --> 00:01:58,320
with the complexity and scale of integrated 
circuit hardware presents a security risk: how do  

21
00:01:58,320 --> 00:02:03,839
we know untrusted third parties will not include 
a backdoor (or hardware Trojan) in their designs?

22
00:02:05,920 --> 00:02:11,440
There has been significant prior work to address 
the issue of untrusted or outsourced third-party  

23
00:02:11,440 --> 00:02:17,440
IP, shown here. These techniques have consisted 
of both static and dynamic analyses that share  

24
00:02:17,440 --> 00:02:23,680
one thing in common: they are too extreme, that 
is, they either attempt to be Trojan-agnostic or  

25
00:02:23,680 --> 00:02:28,720
implementation-specific. Unfortunately, 
researchers have continued to demonstrate  

26
00:02:28,720 --> 00:02:35,440
false negatives, or Trojan designs, that bypass 
these defenses. Rather than continue to build  

27
00:02:35,440 --> 00:02:39,760
defenses at these extremes, we argue for a 
divide-and-conquer approach that fills this  

28
00:02:39,760 --> 00:02:44,239
trade space. Namely, creating defenses 
that systematically define and search  

29
00:02:44,240 --> 00:02:49,760
for specific classes of Trojans based on 
their behavior, not implementation, and we  

30
00:02:49,760 --> 00:02:54,560
demonstrate the effectiveness of this approach 
by first targeting Ticking Timebomb Trojans.  

31
00:02:56,240 --> 00:03:03,280
So what are Ticking Timebomb Trojans (or TTTs) and 
why do we want to start by eliminating them? There  

32
00:03:03,280 --> 00:03:07,840
are many different ways to categorize hardware 
Trojans, the first being where in the hardware  

33
00:03:07,840 --> 00:03:13,680
design process they are inserted. Our focus 
is on eradicating malicious hardware inserted  

34
00:03:13,680 --> 00:03:18,720
during RTL design as a result of outsourcing 
this process to untrusted third parties.  

35
00:03:20,000 --> 00:03:25,680
Design-time hardware Trojans can further be 
classified based on the characteristics of their  

36
00:03:25,680 --> 00:03:31,200
two main components, their: trigger and payload. 
The trigger is the portion of the Trojan that  

37
00:03:31,200 --> 00:03:35,920
hides the Trojan's payload until a specific 
state is reached or condition is observed.  

38
00:03:36,960 --> 00:03:42,800
It enables the Trojan to remain dormant under 
normal chip operation. Alternatively, the payload  

39
00:03:42,800 --> 00:03:46,880
is the portion of the Trojan that manipulates 
the victim circuit upon being signaled by the  

40
00:03:46,880 --> 00:03:52,480
trigger. Since the payload is usually specific to 
the victim circuit where the Trojan is implanted,  

41
00:03:52,480 --> 00:03:56,239
we choose to further classify 
Trojans based on their trigger,  

42
00:03:56,240 --> 00:03:59,840
for which there are two types: 1) 
always on, and 2) initially dormant.  

43
00:04:00,720 --> 00:04:05,520
Since always-on triggers are often easily 
detected during verification testing,  

44
00:04:05,520 --> 00:04:11,440
since they lack any triggering mechanism at all, 
we focus on the most stealthy Trojan triggers:  

45
00:04:11,440 --> 00:04:16,959
those that are initially dormant. Lastly, 
there are two main categories of initially  

46
00:04:16,959 --> 00:04:22,320
dormant triggers: 1) data-based (or cheat 
code), and time-based (or Ticking Timebombs).  

47
00:04:23,040 --> 00:04:28,000
Data-based triggers are comprised of combinational 
or sequential logic that waits for a specific  

48
00:04:28,000 --> 00:04:32,880
value or sequence of values to be expressed 
by signals or registers within the design.  

49
00:04:33,680 --> 00:04:38,800
Alternatively, Ticking Timebombs (or 
time-based triggers) monotonically approach  

50
00:04:38,800 --> 00:04:43,760
activation the longer the victim circuit 
operates continuously since the last system  

51
00:04:43,760 --> 00:04:50,159
reset. As a first step towards systematically 
constricting the design-time Trojan attack space,  

52
00:04:50,800 --> 00:04:56,320
we choose to target Ticking Timebombs, as 
prior work has pointed out that they: 1)  

53
00:04:56,320 --> 00:05:02,320
require little additional logic or components to 
implement, and 2) they do not require any attacker  

54
00:05:02,320 --> 00:05:06,880
post-deployment interaction, since they start 
working towards activation the moment the chip  

55
00:05:06,880 --> 00:05:14,000
has been turned on. Therefore, eliminating TTTs 
forces attackers to implement larger Trojans that  

56
00:05:14,000 --> 00:05:18,720
require post-deployment attacker interaction, 
thus raising the bar for the attacker.  

57
00:05:20,320 --> 00:05:25,120
We start by defining TTTs as Trojans 
that implement Ticking Timebomb triggers  

58
00:05:26,000 --> 00:05:31,840
as shown in the upper right figure, here, and we 
define Ticking Timebomb triggers as monotonically  

59
00:05:31,840 --> 00:05:37,039
increasing counters that express values 
that: 1) never repeat, and 2) never complete.  

60
00:05:37,760 --> 00:05:42,719
This is because if a counter repeats a value it is 
no longer always monotonically progressing in any  

61
00:05:42,720 --> 00:05:48,880
direction, and therefore cannot implement a TTT, 
and if a counter enumerates all possible values,  

62
00:05:48,880 --> 00:05:53,920
and the victim circuit does not exhibit abnormal 
behavior, then it is also not part of a TTT.  

63
00:05:54,880 --> 00:05:59,760
From this succinct definition, we enumerate 
the space of all possible TTT designs  

64
00:05:59,760 --> 00:06:04,560
including some novel variants based on the three 
fundamental components required to implement this  

65
00:06:04,560 --> 00:06:10,960
type of behavior in hardware. These components 
include: 1) state saving components, or SSCs,  

66
00:06:10,960 --> 00:06:16,400
which store the counter's current count, 2) an 
increment event, which triggers the counter to  

67
00:06:16,400 --> 00:06:23,039
increment its value, and 3) an increment amount 
which determines the next value in the counter  

68
00:06:23,040 --> 00:06:28,960
sequence. Since each of these components can 
be implemented in different ways the TTT design  

69
00:06:28,960 --> 00:06:35,359
space we define is more general than it first 
appears. Specifically, SSCs can be broken into  

70
00:06:35,360 --> 00:06:41,520
two variants: coalesced and distributed. An 
example of a coalesced SSC is a contiguous  

71
00:06:41,520 --> 00:06:47,359
4-bit register. Alternatively, rather than use 
a single contiguous register to store the count,  

72
00:06:47,360 --> 00:06:53,280
a savvy attacker may choose to combine multiple 
smaller SSCs into a larger, distributed, SSC,  

73
00:06:53,280 --> 00:06:59,039
as shown on the right. Increment events can be 
either periodic, for example a clock signal,  

74
00:06:59,040 --> 00:07:05,200
or sporadic, for example an interrupt signal, 
and increment amounts can be uniform, for example  

75
00:07:05,200 --> 00:07:11,120
increasing incrementing by ones or twos, or 
non-uniform, for example incrementing by the last  

76
00:07:11,120 --> 00:07:16,400
four bits of the program counter. What is cool 
about our definition, is that regardless of the  

77
00:07:16,400 --> 00:07:21,919
type of components used to implement the counter 
(that is SSC, increment event or amount types)  

78
00:07:22,480 --> 00:07:28,080
all we have to monitor are the values expressed 
by the SSCs themselves. Putting it together,  

79
00:07:28,080 --> 00:07:34,560
two simple invariants constraining the sequences 
expressed by SSCs define an entire space of TTT  

80
00:07:34,560 --> 00:07:40,720
designs shown here. Specifically, in green we 
note some unique TTTs our definition exposes.  

81
00:07:41,920 --> 00:07:47,680
Our goal in this work is simple: create a 
technique that can detect TTTs by their SSCs.  

82
00:07:48,240 --> 00:07:52,160
Where prior work was trying to detect 
the entire trigger to find Trojans,  

83
00:07:52,160 --> 00:07:59,440
by narrowing the scope to TTTs, we only need to 
monitor the behavior of SSCs. How does it work?  

84
00:07:59,440 --> 00:08:05,040
Well, we first start by enumerating all SSCs 
in the design. While coalesced SSCs are simple,  

85
00:08:05,040 --> 00:08:10,480
we just look for registers, distributed SSCs are 
more complicated. We must search for all possible  

86
00:08:10,480 --> 00:08:15,920
connections between coalesced SSCs. While this 
may seem computationally infeasible, since in  

87
00:08:15,920 --> 00:08:21,200
the worst case the set of distributed SSCs would 
be defined by the power set of all coalesced SSCs,  

88
00:08:21,760 --> 00:08:26,159
in practice it's actually not! The 
circuit itself constrains the set size,  

89
00:08:26,160 --> 00:08:31,040
since every register is typically not directly 
connected to every other register in the design.  

90
00:08:32,240 --> 00:08:37,760
Once we have a list of all SSCs, we initially 
assume that they are all suspicious, or part of a  

91
00:08:37,760 --> 00:08:44,800
TTT. Then we simulate the design using traditional 
verification test vectors, and lastly, we analyze  

92
00:08:44,800 --> 00:08:51,280
the verification results and check if each SSC 
violates either TTT invariant at any time during  

93
00:08:51,280 --> 00:08:58,959
simulation. If they do then the SSC is benign 
and cannot be part of a TTT. If they do not,  

94
00:08:58,960 --> 00:09:04,640
then the SSC could be part of a TTT, and must be 
analyzed manually by a hardware design engineer.  

95
00:09:05,520 --> 00:09:09,520
A key insight from our approach is 
that false negatives are impossible,  

96
00:09:09,520 --> 00:09:14,960
since we initially assume all SSCs are suspicious, 
and only mark them benign when we know for certain  

97
00:09:14,960 --> 00:09:21,600
they are not. That is, they violate the definition 
of a TTT. We implement this approach in a tool we  

98
00:09:21,600 --> 00:09:26,400
call Bomberman, the architecture of which is shown 
here. In the interest of time I'm not going to go  

99
00:09:26,400 --> 00:09:31,840
into the details of its implementation, however 
if you are curious, please refer to our paper.

100
00:09:34,560 --> 00:09:39,040
Now that we understand how Bomberman works, 
the next question we ask is: how effective is  

101
00:09:39,040 --> 00:09:44,079
Bomberman in practice? Recall, false negatives 
are impossible given the construction of the  

102
00:09:44,080 --> 00:09:50,240
Bomberman algorithm, however false positives are 
not. So what is Bomberman's false positive rate  

103
00:09:50,240 --> 00:09:55,520
in practice? Secondly, how does Bomberman 
stack up against prior work in terms of:  

104
00:09:56,160 --> 00:10:02,000
a) the ability to detect all TTT variants 
we define, and b) performance, or run-time?  

105
00:10:03,440 --> 00:10:07,360
To answer these questions, we study four 
real-world hardware designs including a  

106
00:10:07,360 --> 00:10:14,880
cryptographic accelerator, a UART module, and two 
CPUs. We implant all six TTT variants (the four  

107
00:10:14,880 --> 00:10:20,160
coalesced and two distributed) in all of these 
designs and measure Bomberman's performance.  

108
00:10:20,880 --> 00:10:24,800
To get an idea of the complexity of 
these designs, in terms of number of  

109
00:10:24,800 --> 00:10:31,839
SSCs, we plot the size and number of all coalesced 
SSCs, or registers, in each design, shown here.  

110
00:10:32,480 --> 00:10:36,160
While the paper details the results 
from all cores, in the interest of time,  

111
00:10:36,160 --> 00:10:41,360
I'm only going to talk about the AES core, as we 
believe these are the most interesting results.

112
00:10:43,920 --> 00:10:48,560
To study the AES design, we developed a simple 
test bench that drives random plaintexts and  

113
00:10:48,560 --> 00:10:53,520
random keys (generated by linear feedback shift 
registers) into the design-under-test to be  

114
00:10:53,520 --> 00:10:59,360
encrypted and the results verified. We choose 
this constrained random verification approach  

115
00:10:59,360 --> 00:11:04,800
as it is representative of a real-world 
verification strategy. The AES design  

116
00:11:04,800 --> 00:11:10,079
we study operates in 128-bit counter mode and 
has a delay of 22 clock cycles per encryption.  

117
00:11:11,760 --> 00:11:17,120
Here we plot four traces that show the number 
of SSCs Bomberman identifies as suspicious  

118
00:11:17,760 --> 00:11:23,280
over the course of a simulation that performs 
150 encryptions. In blue and orange, we plot the  

119
00:11:23,280 --> 00:11:29,680
number of suspicious SSCs reported for coalesced 
and distributed SSCs respectively, and in green  

120
00:11:29,680 --> 00:11:36,800
and red, we plot the number of constant SSCs 
reported. A constant SSC is simply an SSC that has  

121
00:11:36,800 --> 00:11:42,800
only expressed a single value since reset, that 
is, it has not progressed out of its reset state.  

122
00:11:43,680 --> 00:11:49,280
Note, suspicious and constant SSCs are not 
mutually exclusive, since a constant SSC is,  

123
00:11:49,280 --> 00:11:55,439
by definition, also suspicious. In the first 
half of this plot, we observe Bomberman's  

124
00:11:55,440 --> 00:12:00,560
results over the course of encrypting 75 
random plaintexts with 75 random keys.  

125
00:12:01,440 --> 00:12:07,440
We see that after approximately 750 clock cycles, 
the reduction in false positive starts to level  

126
00:12:07,440 --> 00:12:12,400
off. This is because at this point in the 
simulation Bomberman has observed all small  

127
00:12:12,400 --> 00:12:18,400
SSCs cycle through all possible values. At this 
point we recognize that it is infeasible for  

128
00:12:18,400 --> 00:12:24,560
Bomberman to observe the same for large SSCs in 
any reasonable amount of time. To overcome this,  

129
00:12:25,280 --> 00:12:30,560
we make another observation that since the 
AES core is a deterministic state machine  

130
00:12:30,560 --> 00:12:36,880
with no control-path SSCs, repeating input 
test vectors will cause all deterministic  

131
00:12:36,880 --> 00:12:43,600
data-path only SSCs to repeat values, violating 
the other TTT invariant of no repeated values.  

132
00:12:44,320 --> 00:12:49,920
We demonstrate this idea by repeating the same 75 
encryptions in the second half of our simulation.  

133
00:12:50,640 --> 00:12:56,160
As you can see, shortly into the second half of 
the simulation we eradicate all false positives  

134
00:12:56,160 --> 00:13:01,280
and are left with only those malicious SSCs we 
implanted into the AES design to begin with.  

135
00:13:03,280 --> 00:13:09,120
Overall, across all designs we study, we observe 
a false positive rate of only 1.2 percent.

136
00:13:11,920 --> 00:13:15,360
Now if we compare Bomberman to 
other defenses in this space,  

137
00:13:15,360 --> 00:13:20,320
we see it is the only defense capable of 
detecting all TTTs we enumerate in our definition.  

138
00:13:21,040 --> 00:13:25,839
Moreover, in our paper we demonstrate a TTT 
that can defeat all of these defenses combined,  

139
00:13:25,840 --> 00:13:31,680
except Bomberman. While it may seem that 
defenses like FANCI and VeriTrust are futile,  

140
00:13:31,680 --> 00:13:37,199
I would argue that they are not! Rather they are 
very useful in a layered security manner since the  

141
00:13:37,200 --> 00:13:42,880
run-time for all these approaches, including 
the Bomberman approach, are very low as well.  

142
00:13:43,920 --> 00:13:49,199
Remember that while they may not completely 
defeat all TTTs we define, they can defeat some  

143
00:13:49,200 --> 00:13:54,880
data-bases Trojans that Bomberman cannot. 
In conclusion, Bomberman demonstrates the  

144
00:13:54,880 --> 00:14:02,160
power of class-specific Trojan verification by 
eliminating the threat of TTTs. Moreover, its fast  

145
00:14:02,160 --> 00:14:06,959
run-time enables defense-in-depth strategies where 
several defensive measures are deployed in unison.  

146
00:14:08,080 --> 00:14:12,400
Lastly, its low false positive rate makes 
manual inspection of the remaining suspicious  

147
00:14:12,400 --> 00:14:18,079
SSCs feasible. So where do we go from 
here? While the false positive rate is low  

148
00:14:18,080 --> 00:14:22,960
could we get it even lower? We made an 
observation with the AES core that it  

149
00:14:22,960 --> 00:14:28,720
is feasible to trigger deterministic data-path 
SSCs to repeat values by repeating test vectors.  

150
00:14:29,440 --> 00:14:34,560
Is it also possible to repeat a sequence of test 
vectors to trigger repeated values in control-path  

151
00:14:34,560 --> 00:14:40,719
SSCs? And if so, could we automate this? If 
you enjoyed this talk, and want to experiment  

152
00:14:40,720 --> 00:14:44,880
with Trojan verification, please feel free to 
check out our source code at the link below.  

153
00:14:45,760 --> 00:14:48,880
Thank you for listening to my talk, and 
if you have any questions don't hesitate  

154
00:14:48,880 --> 00:14:53,520
to reach out to me via email, or during 
the live question and answer session.

