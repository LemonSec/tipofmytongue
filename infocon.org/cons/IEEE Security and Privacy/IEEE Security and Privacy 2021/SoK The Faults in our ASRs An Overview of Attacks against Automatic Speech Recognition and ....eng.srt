1
00:00:00,080 --> 00:00:03,600
avi hi my name is hadi

2
00:00:03,600 --> 00:00:06,640
and today i will be giving you a

3
00:00:06,640 --> 00:00:09,360
presentation on our sok work

4
00:00:09,360 --> 00:00:12,320
where we give an overview of attacks and

5
00:00:12,320 --> 00:00:13,840
defenses against

6
00:00:13,840 --> 00:00:16,320
automatic speech recognition and speaker

7
00:00:16,320 --> 00:00:19,359
identification systems

8
00:00:19,359 --> 00:00:21,359
so attacks and defenses against ml

9
00:00:21,359 --> 00:00:24,160
models are becoming very popular

10
00:00:24,160 --> 00:00:26,640
in the case of speech and speaker

11
00:00:26,640 --> 00:00:28,160
recognition models the goal of an

12
00:00:28,160 --> 00:00:29,760
attacker is to come up with an audio

13
00:00:29,760 --> 00:00:30,800
sample

14
00:00:30,800 --> 00:00:34,079
that when passed to the human the human

15
00:00:34,079 --> 00:00:34,559
will hear

16
00:00:34,559 --> 00:00:36,559
a benign command which is what's the

17
00:00:36,559 --> 00:00:37,760
time

18
00:00:37,760 --> 00:00:39,680
but when the exact same audio file is

19
00:00:39,680 --> 00:00:41,840
passed to a voice assistant in this case

20
00:00:41,840 --> 00:00:42,640
a siri

21
00:00:42,640 --> 00:00:44,879
it will output an attacker chosen

22
00:00:44,879 --> 00:00:46,000
malicious command

23
00:00:46,000 --> 00:00:48,719
which could be to transfer money to the

24
00:00:48,719 --> 00:00:50,640
hacker's account

25
00:00:50,640 --> 00:00:53,440
download a piece of malware and if the

26
00:00:53,440 --> 00:00:55,760
attacker is being particularly malicious

27
00:00:55,760 --> 00:00:57,520
to ask your voice assistant to buy a

28
00:00:57,520 --> 00:01:00,480
bunch of dogecoin

29
00:01:00,559 --> 00:01:04,319
so why even write an sok in this space

30
00:01:04,319 --> 00:01:07,119
well there has been lots and lots and

31
00:01:07,119 --> 00:01:07,680
lots

32
00:01:07,680 --> 00:01:09,439
of really good work that has been done

33
00:01:09,439 --> 00:01:11,040
in this space

34
00:01:11,040 --> 00:01:13,600
and unfortunately this has made the

35
00:01:13,600 --> 00:01:15,119
space pretty cluttered

36
00:01:15,119 --> 00:01:18,000
up it makes it difficult to see what has

37
00:01:18,000 --> 00:01:19,680
been done to death

38
00:01:19,680 --> 00:01:23,360
and what open problems still exist

39
00:01:23,360 --> 00:01:25,920
and in this paper we go out and analyze

40
00:01:25,920 --> 00:01:28,240
all of these research papers

41
00:01:28,240 --> 00:01:30,799
we we evaluate over 22 different papers

42
00:01:30,799 --> 00:01:33,840
using 29 different characteristics

43
00:01:33,840 --> 00:01:35,920
in this talk i'll give you an overview

44
00:01:35,920 --> 00:01:37,840
of some of the characteristics

45
00:01:37,840 --> 00:01:40,320
we used and the kind of open problems

46
00:01:40,320 --> 00:01:41,439
that still exist

47
00:01:41,439 --> 00:01:44,560
so let's talk about attacks first while

48
00:01:44,560 --> 00:01:46,159
talking about attacks let's

49
00:01:46,159 --> 00:01:48,320
consider an example that most of us can

50
00:01:48,320 --> 00:01:49,680
relate to

51
00:01:49,680 --> 00:01:53,040
having an annoying roommate now

52
00:01:53,040 --> 00:01:54,320
suppose you live with this annoying

53
00:01:54,320 --> 00:01:56,799
roommate and clearly you're not happy

54
00:01:56,799 --> 00:01:58,000
about it

55
00:01:58,000 --> 00:02:00,479
and you really want to get back at them

56
00:02:00,479 --> 00:02:01,439
fortunately

57
00:02:01,439 --> 00:02:04,560
they own a voice assistant and even

58
00:02:04,560 --> 00:02:05,200
better

59
00:02:05,200 --> 00:02:07,520
you are a security researcher who knows

60
00:02:07,520 --> 00:02:09,038
how to exploit it

61
00:02:09,038 --> 00:02:12,480
and now your aim in life is to cause as

62
00:02:12,480 --> 00:02:14,879
much havoc as possible by exploiting

63
00:02:14,879 --> 00:02:16,640
your roommate's voices system

64
00:02:16,640 --> 00:02:18,560
so let's define your goal here as an

65
00:02:18,560 --> 00:02:20,720
attacker

66
00:02:20,720 --> 00:02:22,720
in this case your goal is again could

67
00:02:22,720 --> 00:02:23,840
either be targeted

68
00:02:23,840 --> 00:02:26,879
or untargeted the example we looked at

69
00:02:26,879 --> 00:02:28,160
earlier where we want

70
00:02:28,160 --> 00:02:30,720
to force cd to download a malware sample

71
00:02:30,720 --> 00:02:33,120
is a form of a targeted attack

72
00:02:33,120 --> 00:02:35,680
specifically the goal here is to produce

73
00:02:35,680 --> 00:02:38,160
an attacker chosen output

74
00:02:38,160 --> 00:02:40,800
and this is one of the most popular

75
00:02:40,800 --> 00:02:42,959
types of attacks in this space

76
00:02:42,959 --> 00:02:45,360
now your attack would be untargeted as

77
00:02:45,360 --> 00:02:46,160
well

78
00:02:46,160 --> 00:02:48,160
where you just want to force the model

79
00:02:48,160 --> 00:02:50,080
to output any transcript that's not the

80
00:02:50,080 --> 00:02:51,440
original

81
00:02:51,440 --> 00:02:53,519
and there are a bunch of applications

82
00:02:53,519 --> 00:02:55,040
for untargeted attacks

83
00:02:55,040 --> 00:02:56,959
some of which i discussed in the

84
00:02:56,959 --> 00:02:58,400
previous talk

85
00:02:58,400 --> 00:03:00,400
but in the case of you attacking your

86
00:03:00,400 --> 00:03:02,319
roommate you'd probably want to use a

87
00:03:02,319 --> 00:03:04,000
targeted attack

88
00:03:04,000 --> 00:03:06,959
the audio type or what the human ear has

89
00:03:06,959 --> 00:03:07,519
can be

90
00:03:07,519 --> 00:03:10,720
also of different types as well

91
00:03:10,720 --> 00:03:14,319
the audio type can be of a type of clean

92
00:03:14,319 --> 00:03:16,159
this is when the audio sample sounds

93
00:03:16,159 --> 00:03:17,519
like a benign command to us

94
00:03:17,519 --> 00:03:20,879
which is what's the time and this can be

95
00:03:20,879 --> 00:03:22,480
particularly dangerous for the victim

96
00:03:22,480 --> 00:03:24,239
because if the victim

97
00:03:24,239 --> 00:03:27,360
only has a benign audio command the

98
00:03:27,360 --> 00:03:28,959
victim is less likely to know that an

99
00:03:28,959 --> 00:03:30,959
attack is in progress

100
00:03:30,959 --> 00:03:33,120
and this is the most common type of

101
00:03:33,120 --> 00:03:34,959
attack out there

102
00:03:34,959 --> 00:03:37,519
uh the audio type can also be of type

103
00:03:37,519 --> 00:03:38,319
noisy

104
00:03:38,319 --> 00:03:40,720
where the the audio sample sounds like

105
00:03:40,720 --> 00:03:43,040
complete garbage to the human listener

106
00:03:43,040 --> 00:03:44,480
so the attacking can play an audio

107
00:03:44,480 --> 00:03:47,440
sample that sounds like noise

108
00:03:47,440 --> 00:03:49,120
so the victim might not actually know

109
00:03:49,120 --> 00:03:51,519
that an attack is in progress

110
00:03:51,519 --> 00:03:53,760
or there's a third type where the the

111
00:03:53,760 --> 00:03:55,280
attack audio is completely

112
00:03:55,280 --> 00:03:57,120
inaudible and that's because the

113
00:03:57,120 --> 00:03:59,439
frequencies that make up the audio

114
00:03:59,439 --> 00:04:02,319
lie above the maximum frequency range of

115
00:04:02,319 --> 00:04:03,599
the human ear so

116
00:04:03,599 --> 00:04:06,400
above 20 kilohertz now these attack

117
00:04:06,400 --> 00:04:07,920
audio samples

118
00:04:07,920 --> 00:04:12,720
um are played uh to the microphone

119
00:04:12,720 --> 00:04:14,480
and even though the human ear does not

120
00:04:14,480 --> 00:04:15,760
pick up the command

121
00:04:15,760 --> 00:04:17,680
because it lies above the 20 kilohertz

122
00:04:17,680 --> 00:04:19,279
range the microphone still

123
00:04:19,279 --> 00:04:23,040
does record the the message

124
00:04:23,040 --> 00:04:26,320
now this slide shows the three different

125
00:04:26,320 --> 00:04:28,479
ways we can categorize the audio

126
00:04:28,479 --> 00:04:31,040
but the question is well how do you

127
00:04:31,040 --> 00:04:32,639
actually

128
00:04:32,639 --> 00:04:35,600
measure how inaudible or how clean or

129
00:04:35,600 --> 00:04:36,000
how

130
00:04:36,000 --> 00:04:38,960
noisy these audio samples are and this

131
00:04:38,960 --> 00:04:41,600
brings us to the first open problem

132
00:04:41,600 --> 00:04:43,280
the question here is how can you

133
00:04:43,280 --> 00:04:46,560
quantify the quality of the audio

134
00:04:46,560 --> 00:04:49,280
the problem is no such single metric

135
00:04:49,280 --> 00:04:50,960
exists

136
00:04:50,960 --> 00:04:53,360
metrics such as the l-based norms that

137
00:04:53,360 --> 00:04:54,320
are used

138
00:04:54,320 --> 00:04:57,360
in the image domain or the snr which is

139
00:04:57,360 --> 00:04:59,040
the signal to noise ratio

140
00:04:59,040 --> 00:05:02,240
are actually insufficient for this task

141
00:05:02,240 --> 00:05:05,039
because they have failed to capture the

142
00:05:05,039 --> 00:05:06,960
intricate ways with which the human ear

143
00:05:06,960 --> 00:05:09,600
processes different frequencies

144
00:05:09,600 --> 00:05:11,600
metrics from the telephony space such as

145
00:05:11,600 --> 00:05:13,600
pesc or moss

146
00:05:13,600 --> 00:05:15,759
well these won't work either and that's

147
00:05:15,759 --> 00:05:17,199
because they're designed to capture

148
00:05:17,199 --> 00:05:18,800
factors such as jitter

149
00:05:18,800 --> 00:05:21,520
packet loss factors that are not a

150
00:05:21,520 --> 00:05:24,720
byproduct of adversarial attacks

151
00:05:24,720 --> 00:05:27,360
and in the absence of any useful

152
00:05:27,360 --> 00:05:29,360
quantitative metric

153
00:05:29,360 --> 00:05:32,160
papers have resorted to user studies

154
00:05:32,160 --> 00:05:33,759
which have been shown to be

155
00:05:33,759 --> 00:05:36,080
far more effective than any single

156
00:05:36,080 --> 00:05:37,600
metric

157
00:05:37,600 --> 00:05:39,520
so looking at how to quantify audio

158
00:05:39,520 --> 00:05:42,160
quality would be a step in the right

159
00:05:42,160 --> 00:05:45,600
direction now you can actually pass the

160
00:05:45,600 --> 00:05:46,639
attack audio

161
00:05:46,639 --> 00:05:49,840
to the victim's voice assistant

162
00:05:49,840 --> 00:05:51,680
and the attack audio can be passed over

163
00:05:51,680 --> 00:05:53,360
different mediums

164
00:05:53,360 --> 00:05:56,720
you can pass the audio sample directly

165
00:05:56,720 --> 00:05:59,919
to the uh to the model using an api call

166
00:05:59,919 --> 00:06:03,199
and this is known as overline

167
00:06:03,199 --> 00:06:06,000
there's no loss while transmitting over

168
00:06:06,000 --> 00:06:06,720
this medium

169
00:06:06,720 --> 00:06:08,560
and as a consequence this sort of medium

170
00:06:08,560 --> 00:06:11,039
is easiest for the attacker to work with

171
00:06:11,039 --> 00:06:13,360
therefore in our study we find that most

172
00:06:13,360 --> 00:06:15,120
of the attacks out there are designed to

173
00:06:15,120 --> 00:06:17,039
work over line

174
00:06:17,039 --> 00:06:18,639
but you as an attacker probably won't

175
00:06:18,639 --> 00:06:20,319
have apa access

176
00:06:20,319 --> 00:06:25,120
to their particular uh voice assistant

177
00:06:25,120 --> 00:06:27,360
so considering our earlier example to

178
00:06:27,360 --> 00:06:28,880
make sure that you can actually exploit

179
00:06:28,880 --> 00:06:29,199
your

180
00:06:29,199 --> 00:06:31,680
roommate siri device you'll probably

181
00:06:31,680 --> 00:06:33,280
have to pass the audio sample over the

182
00:06:33,280 --> 00:06:34,080
air

183
00:06:34,080 --> 00:06:35,600
which means that you'll have to play the

184
00:06:35,600 --> 00:06:38,240
audio sample using a speaker phone

185
00:06:38,240 --> 00:06:40,080
the audio sample will travel over the

186
00:06:40,080 --> 00:06:41,520
air be picked up

187
00:06:41,520 --> 00:06:43,520
and recorded by the microphone and then

188
00:06:43,520 --> 00:06:44,880
passed to

189
00:06:44,880 --> 00:06:47,120
the voice assistant since we are playing

190
00:06:47,120 --> 00:06:49,440
the audio over the air

191
00:06:49,440 --> 00:06:52,000
the quality of the speaker the quality

192
00:06:52,000 --> 00:06:53,440
of the microphone

193
00:06:53,440 --> 00:06:55,919
the degree of background noise all of

194
00:06:55,919 --> 00:06:57,520
these are going to affect the attack

195
00:06:57,520 --> 00:06:58,400
audio

196
00:06:58,400 --> 00:07:00,560
and because these attack audio samples

197
00:07:00,560 --> 00:07:02,639
are very sensitive to these natural

198
00:07:02,639 --> 00:07:03,840
effects

199
00:07:03,840 --> 00:07:05,919
these natural factors will blunt the

200
00:07:05,919 --> 00:07:07,520
adversarial nature

201
00:07:07,520 --> 00:07:10,160
of the attack audio which might be

202
00:07:10,160 --> 00:07:12,400
unable to fool the model

203
00:07:12,400 --> 00:07:15,120
as a consequence this sort of medium is

204
00:07:15,120 --> 00:07:16,800
much harder to work with for the

205
00:07:16,800 --> 00:07:17,759
attacker

206
00:07:17,759 --> 00:07:20,479
than the earlier medium which was over

207
00:07:20,479 --> 00:07:21,759
the line

208
00:07:21,759 --> 00:07:23,599
the medium that is hardest for the

209
00:07:23,599 --> 00:07:24,960
attacker to work with

210
00:07:24,960 --> 00:07:28,160
is over telephony now this is the this

211
00:07:28,160 --> 00:07:30,160
is the case where the attacker is trying

212
00:07:30,160 --> 00:07:32,720
to evade a voice model being used

213
00:07:32,720 --> 00:07:35,360
by a telephony surveillance network so

214
00:07:35,360 --> 00:07:37,360
the attack audio sample is sent by your

215
00:07:37,360 --> 00:07:38,080
phone

216
00:07:38,080 --> 00:07:40,000
over the telephony network before it's

217
00:07:40,000 --> 00:07:42,400
actually picked up by the receiver

218
00:07:42,400 --> 00:07:44,560
the telephony network is incredibly

219
00:07:44,560 --> 00:07:45,680
lossy

220
00:07:45,680 --> 00:07:48,960
factors such as packet loss jitter

221
00:07:48,960 --> 00:07:51,280
um the variation of compression

222
00:07:51,280 --> 00:07:52,240
algorithms

223
00:07:52,240 --> 00:07:54,000
all work together to degrade the

224
00:07:54,000 --> 00:07:56,479
adversarial nature of the audio

225
00:07:56,479 --> 00:07:58,639
and so far only one attack has been able

226
00:07:58,639 --> 00:08:00,240
to work in this medium

227
00:08:00,240 --> 00:08:01,919
and that's the attack that i presented

228
00:08:01,919 --> 00:08:05,360
in the previous presentation

229
00:08:05,360 --> 00:08:07,280
so this brings us to the second open

230
00:08:07,280 --> 00:08:08,720
problem

231
00:08:08,720 --> 00:08:10,479
due to the lossy nature of different

232
00:08:10,479 --> 00:08:12,479
mediums attacks that work

233
00:08:12,479 --> 00:08:15,360
over the line tend to fail over other

234
00:08:15,360 --> 00:08:16,400
mediums

235
00:08:16,400 --> 00:08:18,639
and if we want to make these attacks

236
00:08:18,639 --> 00:08:20,319
usable in the real world

237
00:08:20,319 --> 00:08:22,800
it is imperative that we make them work

238
00:08:22,800 --> 00:08:24,400
over different mediums

239
00:08:24,400 --> 00:08:27,759
and this is still an open problem

240
00:08:27,759 --> 00:08:29,440
let's talk about how much knowledge we

241
00:08:29,440 --> 00:08:32,000
have of the targeted assistant itself

242
00:08:32,000 --> 00:08:34,880
this is known as adversary knowledge the

243
00:08:34,880 --> 00:08:36,880
depth of our knowledge will help us

244
00:08:36,880 --> 00:08:39,279
decide which attack to use

245
00:08:39,279 --> 00:08:41,039
but to better understand this point we

246
00:08:41,039 --> 00:08:42,640
look at the successive stages

247
00:08:42,640 --> 00:08:45,120
that make up the voices system pipeline

248
00:08:45,120 --> 00:08:47,200
shown in red over here

249
00:08:47,200 --> 00:08:49,360
now if you have perfect knowledge of all

250
00:08:49,360 --> 00:08:50,959
these stages then you're said to have

251
00:08:50,959 --> 00:08:53,680
white box access or white box knowledge

252
00:08:53,680 --> 00:08:55,120
this is an extreme case

253
00:08:55,120 --> 00:08:57,279
not available to most real world

254
00:08:57,279 --> 00:08:58,560
adversaries

255
00:08:58,560 --> 00:09:00,080
and this is because most commercial

256
00:09:00,080 --> 00:09:03,040
systems like siri are proprietary

257
00:09:03,040 --> 00:09:05,519
and unfortunately most attacks in

258
00:09:05,519 --> 00:09:06,800
current literature

259
00:09:06,800 --> 00:09:09,519
require white box access and therefore

260
00:09:09,519 --> 00:09:13,040
aren't applicable in the real world

261
00:09:13,040 --> 00:09:15,040
grey box is when you have knowledge of

262
00:09:15,040 --> 00:09:16,320
some of the components

263
00:09:16,320 --> 00:09:18,800
of the pipeline this too is unlikely in

264
00:09:18,800 --> 00:09:19,920
the real world since

265
00:09:19,920 --> 00:09:22,399
how these systems operate a closely

266
00:09:22,399 --> 00:09:24,959
guarded secret

267
00:09:24,959 --> 00:09:26,720
in the black box setup you have no

268
00:09:26,720 --> 00:09:28,000
knowledge of the target

269
00:09:28,000 --> 00:09:29,440
but you do have the ability to make

270
00:09:29,440 --> 00:09:31,040
queries and this is

271
00:09:31,040 --> 00:09:32,800
the likely knowledge category that will

272
00:09:32,800 --> 00:09:35,680
be available to you as an attacker

273
00:09:35,680 --> 00:09:38,399
now one the most extreme of all of these

274
00:09:38,399 --> 00:09:39,920
is the no box case

275
00:09:39,920 --> 00:09:41,839
this is when you don't have knowledge of

276
00:09:41,839 --> 00:09:43,760
the target and you don't have kodi

277
00:09:43,760 --> 00:09:45,120
access either

278
00:09:45,120 --> 00:09:47,519
so you don't know what kind of tasks the

279
00:09:47,519 --> 00:09:48,480
model is trained for

280
00:09:48,480 --> 00:09:50,720
you you would only know that you want to

281
00:09:50,720 --> 00:09:52,080
evade it

282
00:09:52,080 --> 00:09:54,320
and while most attacks in the space

283
00:09:54,320 --> 00:09:56,160
require white box access

284
00:09:56,160 --> 00:10:00,399
only one can work in a no box setting

285
00:10:00,399 --> 00:10:02,800
now based on the knowledge of the target

286
00:10:02,800 --> 00:10:03,440
you might

287
00:10:03,440 --> 00:10:05,120
have a number of attacks available to

288
00:10:05,120 --> 00:10:07,760
you if you have white box access you'll

289
00:10:07,760 --> 00:10:08,720
probably go with

290
00:10:08,720 --> 00:10:11,920
optimization or gradient based attacks

291
00:10:11,920 --> 00:10:13,600
these use knowledge of the model's

292
00:10:13,600 --> 00:10:15,279
decision boundaries to craft adversarial

293
00:10:15,279 --> 00:10:17,040
samples

294
00:10:17,040 --> 00:10:19,600
in the case of black box access you

295
00:10:19,600 --> 00:10:21,760
could go with gradient free attacks

296
00:10:21,760 --> 00:10:24,399
which estimate the precision boundary by

297
00:10:24,399 --> 00:10:26,480
making tons and tons of queries to the

298
00:10:26,480 --> 00:10:28,079
target model

299
00:10:28,079 --> 00:10:29,839
now if you want to be query efficient

300
00:10:29,839 --> 00:10:32,160
you can use signal processing attacks

301
00:10:32,160 --> 00:10:33,920
these work in black box settings and

302
00:10:33,920 --> 00:10:37,120
even no no box settings as well

303
00:10:37,120 --> 00:10:38,880
these attacks exploit the weaknesses in

304
00:10:38,880 --> 00:10:40,399
the feature extraction phase of the

305
00:10:40,399 --> 00:10:41,519
pipeline

306
00:10:41,519 --> 00:10:44,160
and therefore do not depend on the model

307
00:10:44,160 --> 00:10:44,720
itself

308
00:10:44,720 --> 00:10:46,079
allowing allowing these attacks to be

309
00:10:46,079 --> 00:10:48,240
query efficient but the problem with

310
00:10:48,240 --> 00:10:49,839
signal processing attacks is that you

311
00:10:49,839 --> 00:10:50,560
can't create

312
00:10:50,560 --> 00:10:52,160
attack samples that sound clean to the

313
00:10:52,160 --> 00:10:53,600
human ear and

314
00:10:53,600 --> 00:10:56,079
produce targeted outputs optimization

315
00:10:56,079 --> 00:10:58,000
attacks are really good at that

316
00:10:58,000 --> 00:11:00,320
but they do not work in black box

317
00:11:00,320 --> 00:11:01,760
settings

318
00:11:01,760 --> 00:11:05,200
so what do you do then well

319
00:11:05,200 --> 00:11:07,040
in that case you would probably want to

320
00:11:07,040 --> 00:11:09,279
leverage the transferability property

321
00:11:09,279 --> 00:11:10,959
now this is when a sample is created a

322
00:11:10,959 --> 00:11:12,560
sample created from model a

323
00:11:12,560 --> 00:11:15,760
can also exploit some other model b

324
00:11:15,760 --> 00:11:17,760
and this is very common in the image

325
00:11:17,760 --> 00:11:20,000
domain so in the case of audio we want

326
00:11:20,000 --> 00:11:20,560
to use

327
00:11:20,560 --> 00:11:22,720
optimization attacks to craft a sample

328
00:11:22,720 --> 00:11:24,560
against some local model

329
00:11:24,560 --> 00:11:28,959
and hope that it also works against siri

330
00:11:28,959 --> 00:11:30,480
but incredibly when we looked at

331
00:11:30,480 --> 00:11:32,079
existing literature

332
00:11:32,079 --> 00:11:34,320
we saw that none of these optimization

333
00:11:34,320 --> 00:11:36,399
attacks actually demonstrated

334
00:11:36,399 --> 00:11:39,440
targeted transferability now this was

335
00:11:39,440 --> 00:11:41,519
very very surprising since

336
00:11:41,519 --> 00:11:42,800
transferability is

337
00:11:42,800 --> 00:11:46,399
really common in the image domain

338
00:11:46,399 --> 00:11:48,000
so this brings us to the next opel

339
00:11:48,000 --> 00:11:50,959
problem most optimization style attacks

340
00:11:50,959 --> 00:11:52,959
in this space have failed to produce

341
00:11:52,959 --> 00:11:54,079
samples that demonstrate

342
00:11:54,079 --> 00:11:56,480
targeted transferability so the question

343
00:11:56,480 --> 00:11:57,279
becomes

344
00:11:57,279 --> 00:11:59,519
well is target transferability even

345
00:11:59,519 --> 00:12:01,200
possible in asrs

346
00:12:01,200 --> 00:12:03,360
without transferability it isn't clear

347
00:12:03,360 --> 00:12:04,959
how an attacker can be effective in the

348
00:12:04,959 --> 00:12:06,000
real world

349
00:12:06,000 --> 00:12:07,519
so in this paper we actually try to

350
00:12:07,519 --> 00:12:09,120
answer this question

351
00:12:09,120 --> 00:12:12,000
to do so we ran the following experiment

352
00:12:12,000 --> 00:12:12,720
we trained

353
00:12:12,720 --> 00:12:15,200
a real-world surrogate speech model

354
00:12:15,200 --> 00:12:17,680
using the deep speech architecture

355
00:12:17,680 --> 00:12:20,480
next we train 10 voice models all on

356
00:12:20,480 --> 00:12:22,639
identical setups to the surrogate

357
00:12:22,639 --> 00:12:23,920
so this means having the same

358
00:12:23,920 --> 00:12:25,600
architecture the same data the same

359
00:12:25,600 --> 00:12:28,000
hyper parameters the same random seed

360
00:12:28,000 --> 00:12:29,680
so this actually resembles an

361
00:12:29,680 --> 00:12:31,279
unrealistic threat model

362
00:12:31,279 --> 00:12:33,279
where the adversary knows exactly how

363
00:12:33,279 --> 00:12:34,880
the target model was trained

364
00:12:34,880 --> 00:12:37,040
so effectively knowing how apple trained

365
00:12:37,040 --> 00:12:38,480
siri

366
00:12:38,480 --> 00:12:40,800
by setting up the identical hyper

367
00:12:40,800 --> 00:12:41,760
parameters

368
00:12:41,760 --> 00:12:43,760
we ensure that there was no source of

369
00:12:43,760 --> 00:12:45,680
randomness outside of the one introduced

370
00:12:45,680 --> 00:12:47,440
by the gpu

371
00:12:47,440 --> 00:12:49,519
next we looked at the surrogate model

372
00:12:49,519 --> 00:12:51,120
and created a few hundred thousand

373
00:12:51,120 --> 00:12:52,480
adversarial samples

374
00:12:52,480 --> 00:12:55,680
using two optimization attacks

375
00:12:55,680 --> 00:12:58,560
we then passed these samples to the ten

376
00:12:58,560 --> 00:13:00,079
target models

377
00:13:00,079 --> 00:13:03,200
and shockingly we observed that a total

378
00:13:03,200 --> 00:13:04,639
of zero percent

379
00:13:04,639 --> 00:13:07,440
of the samples actually transferred that

380
00:13:07,440 --> 00:13:08,000
is

381
00:13:08,000 --> 00:13:10,639
none of the samples produced by the

382
00:13:10,639 --> 00:13:12,399
optimization attacks

383
00:13:12,399 --> 00:13:14,880
output the same uh adversary chosen

384
00:13:14,880 --> 00:13:15,839
transcript when

385
00:13:15,839 --> 00:13:18,320
passed on to the target model this is

386
00:13:18,320 --> 00:13:20,320
despite the fact that we used

387
00:13:20,320 --> 00:13:21,920
hundreds of thousands of adversarial

388
00:13:21,920 --> 00:13:24,000
samples and a variety of perturbation

389
00:13:24,000 --> 00:13:25,360
budgets

390
00:13:25,360 --> 00:13:27,040
what this shows is that optimization

391
00:13:27,040 --> 00:13:29,120
attacks that are so popular

392
00:13:29,120 --> 00:13:31,360
and that that do show transferability or

393
00:13:31,360 --> 00:13:32,560
targeted transferability

394
00:13:32,560 --> 00:13:34,320
transferability in the image domain do

395
00:13:34,320 --> 00:13:36,320
not demonstrate this property at all

396
00:13:36,320 --> 00:13:38,720
against speech models effectively these

397
00:13:38,720 --> 00:13:39,519
attacks are

398
00:13:39,519 --> 00:13:42,160
obsolete against real world speech

399
00:13:42,160 --> 00:13:42,959
models

400
00:13:42,959 --> 00:13:44,800
where the attacker does not have any

401
00:13:44,800 --> 00:13:46,320
knowledge of the target muchness

402
00:13:46,320 --> 00:13:48,399
knowledge of the data architecture and

403
00:13:48,399 --> 00:13:49,839
the hyper parameters

404
00:13:49,839 --> 00:13:52,880
like the attacker did in this experiment

405
00:13:52,880 --> 00:13:54,079
so this experiment shows that

406
00:13:54,079 --> 00:13:56,160
transferability is very

407
00:13:56,160 --> 00:13:58,480
very hard in audio models but it doesn't

408
00:13:58,480 --> 00:13:59,680
tell you why

409
00:13:59,680 --> 00:14:01,279
and to answer that question we wrote up

410
00:14:01,279 --> 00:14:03,600
a follow-up paper be sure to check it

411
00:14:03,600 --> 00:14:05,680
out on archive

412
00:14:05,680 --> 00:14:07,120
now that we have discussed what open

413
00:14:07,120 --> 00:14:08,880
problems exist it is worth spending

414
00:14:08,880 --> 00:14:10,800
just a minute on what has been done to

415
00:14:10,800 --> 00:14:13,440
death and in that in our evaluation we

416
00:14:13,440 --> 00:14:15,120
saw that white box attacks fit that

417
00:14:15,120 --> 00:14:16,160
category

418
00:14:16,160 --> 00:14:18,480
these generally do not provide any

419
00:14:18,480 --> 00:14:19,680
significant advantage

420
00:14:19,680 --> 00:14:21,839
over each other and suffer from the same

421
00:14:21,839 --> 00:14:22,880
set of limitations

422
00:14:22,880 --> 00:14:25,600
so more white box attacks against audio

423
00:14:25,600 --> 00:14:27,839
models should probably be avoided

424
00:14:27,839 --> 00:14:29,600
there are other open problems that we do

425
00:14:29,600 --> 00:14:31,199
not have time to touch on

426
00:14:31,199 --> 00:14:32,880
like the fact that there are no

427
00:14:32,880 --> 00:14:34,800
poisoning or privacy attacks

428
00:14:34,800 --> 00:14:36,639
against speech models that have been

429
00:14:36,639 --> 00:14:38,000
published so far

430
00:14:38,000 --> 00:14:40,000
or we or the fact that we didn't discuss

431
00:14:40,000 --> 00:14:41,760
the effectiveness of defenses and

432
00:14:41,760 --> 00:14:42,959
detection methods

433
00:14:42,959 --> 00:14:45,279
in this domain for those be sure to

434
00:14:45,279 --> 00:14:46,880
check out the paper itself

435
00:14:46,880 --> 00:14:48,959
in this presentation we discuss how

436
00:14:48,959 --> 00:14:50,800
there has been a lot of really cool work

437
00:14:50,800 --> 00:14:52,880
that has been done in this space

438
00:14:52,880 --> 00:14:55,519
and we systemize all those papers across

439
00:14:55,519 --> 00:14:57,120
a variety of features

440
00:14:57,120 --> 00:14:58,240
we also showed that target

441
00:14:58,240 --> 00:15:00,560
transferability of optimization attacks

442
00:15:00,560 --> 00:15:02,079
that are incredibly popular in this

443
00:15:02,079 --> 00:15:03,279
domain

444
00:15:03,279 --> 00:15:05,600
is close to non-existent but there are

445
00:15:05,600 --> 00:15:07,440
still tons of open problems that they

446
00:15:07,440 --> 00:15:08,639
still exist

447
00:15:08,639 --> 00:15:12,959
that still require further study

