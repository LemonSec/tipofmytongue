1
00:00:00,400 --> 00:00:03,440
Hello i'm Thomas and i'm going to 
be talking about formally verifying  

2
00:00:03,440 --> 00:00:08,000
verification electronic verdict this is 
joint work with both Rajeev and Bhavesh  

3
00:00:09,760 --> 00:00:14,559
so just a brief clarifier before i begin in 
this talk what i'm really trying to talk about  

4
00:00:14,560 --> 00:00:20,720
is verifiable electronic voting without a paper 
trap so we're talking about what is sometimes  

5
00:00:20,720 --> 00:00:26,320
referred to as sort of online voting we're 
not talking about the myriad of electronic  

6
00:00:26,320 --> 00:00:30,640
voting systems which have electronic 
components that are kind of in some sense  

7
00:00:30,640 --> 00:00:38,720
paper-based so in these online voting systems 
you have things called verifiable mixed nets  

8
00:00:38,720 --> 00:00:44,000
and the basic idea is they take effective inputs 
they mix it and they create a vector of outputs  

9
00:00:44,720 --> 00:00:50,480
and so you kind of have um basically ballots 
coming in being randomized in the order and then  

10
00:00:50,480 --> 00:00:55,839
and then coming out again and this is very similar 
to how ballot boxes work into traditional voting  

11
00:00:56,640 --> 00:01:02,800
so you underpin almost all voting schemes with 
non-trivial tally methods for example um you  

12
00:01:02,800 --> 00:01:09,360
know uh single transferable votes um instant 
runoff voting all this kind of stuff it's not  

13
00:01:09,360 --> 00:01:16,720
not things like uh not things like first past 
the post and these are deployed in national  

14
00:01:16,720 --> 00:01:21,120
elections in norway is still in switzerland and 
numerous other places in lower two elections  

15
00:01:22,400 --> 00:01:27,120
so these are prime locations for critical errors 
and so what we'd like to do is machine check the  

16
00:01:27,120 --> 00:01:31,040
cryptographic properties however several 
different encryption schemes are used in  

17
00:01:31,040 --> 00:01:35,280
different variations and that makes this hard 
so in this work what we did is we machine  

18
00:01:35,280 --> 00:01:40,080
checked the design implementation of all the 
variants of the most commonly used mixed nuts  

19
00:01:41,120 --> 00:01:44,560
so a little bit on mixed notes before 
i proceed so mix notes are this  

20
00:01:45,600 --> 00:01:50,559
basically collection of authorities that jointly 
work together to transform and permute the input  

21
00:01:50,560 --> 00:01:55,920
so you have the input vector and you can think of 
these as encrypted votes next to people's names  

22
00:01:55,920 --> 00:02:00,000
now obviously we don't want to just decrypt these 
votes because that would reveal how everybody  

23
00:02:00,000 --> 00:02:05,920
wrote it so if we put them in the mix net they get 
all muted up and then they come out in some manner  

24
00:02:05,920 --> 00:02:10,560
and what's actually happening underneath here 
is that we have this sequence of authorities who  

25
00:02:10,560 --> 00:02:15,440
are each in their turn permuting and then we're 
encrypting the ciphertext and so on and so forth  

26
00:02:15,440 --> 00:02:20,960
until eventually our output is well this should 
be the product of all of the permutations that  

27
00:02:20,960 --> 00:02:28,320
the individual mixes used so this is how we can 
make this work okay so the problem here is that  

28
00:02:28,320 --> 00:02:34,000
implementing cryptography is actually really hard 
and this seems to be particularly the case in  

29
00:02:34,000 --> 00:02:40,160
e-voting so one significant example was with 
the swiss system which the the actually the  

30
00:02:40,160 --> 00:02:46,079
federal chancellor withdrew it from use uh 2019 
because despite the fact they had what seemed  

31
00:02:46,080 --> 00:02:51,440
like a really good process for developing this it 
actually turned out that when this thing was made  

32
00:02:51,440 --> 00:02:57,359
public there were lots and lots of errors in fact 
every single zero knowledge proof they implemented  

33
00:02:57,360 --> 00:03:03,040
was broken in some way so it's very hard to 
do and i think the most same way to do this  

34
00:03:03,680 --> 00:03:07,200
is to try and machine check the properties 
particularly if we can do that in a way  

35
00:03:07,200 --> 00:03:13,280
which we can reuse well so voting systems of this 
very large collection of software and formally  

36
00:03:13,280 --> 00:03:17,680
verifying everything is hardly a practical goal 
there's just too much stuff that we'd like to  

37
00:03:17,680 --> 00:03:23,920
verify and even and moreover even if we knew the 
software was sort of correct we wouldn't actually  

38
00:03:23,920 --> 00:03:28,160
know that the election management body was 
actually running the software they they said they  

39
00:03:28,160 --> 00:03:32,400
were running the sort of techniques for remote 
anastasia and stuff don't really work in this  

40
00:03:33,200 --> 00:03:38,720
threat model however as we're best observed we 
can use a whole bunch of cryptographic techniques  

41
00:03:38,720 --> 00:03:43,120
to have something called software independence 
this is the idea that the system should produce  

42
00:03:43,120 --> 00:03:48,240
public evidence which we can independently check 
which should then prove that the result that it  

43
00:03:48,240 --> 00:03:52,400
output was actually correct since the so as i 
say again this is called software independence  

44
00:03:53,680 --> 00:03:58,320
so then we sort of we moved our problem we've 
moved our problem for integrity from the software  

45
00:03:58,320 --> 00:04:03,120
that's running the election to the software 
that's checking the evidence so but that's  

46
00:04:03,120 --> 00:04:07,520
that's actually quite nice because the software 
checking evidence is a lot smaller it's happening  

47
00:04:07,520 --> 00:04:12,000
after the election it's a lot easier to manage 
than the software running the election itself  

48
00:04:12,800 --> 00:04:19,360
this is precisely the fact that we exploit in this 
work we sort of do this verified verify actually  

49
00:04:19,360 --> 00:04:23,920
we do a lot more than that but you can read the 
paper for that um the main sort of thing that we  

50
00:04:23,920 --> 00:04:27,520
want to actually use in practice is the verified 
verified that we actually machine check to heaven  

51
00:04:28,800 --> 00:04:34,800
so the two most common mix nets for electronic 
voting are tyraelus fixturn and biograph  

52
00:04:35,600 --> 00:04:40,640
and in fact the most common is actually 
the optimized variant of total spectrum  

53
00:04:40,640 --> 00:04:44,159
the roth one is really only being 
pushed by one significant vendor  

54
00:04:44,880 --> 00:04:49,680
so there are many slight variants but essentially 
the optimized variant of the 1262 mixnet works by  

55
00:04:49,680 --> 00:04:54,080
taking the original mixed net and restricting 
it to the case where the ciphertext space has  

56
00:04:54,080 --> 00:04:59,440
prime order or sufficiently close to primary so 
this style of mixing is primarily implemented  

57
00:04:59,440 --> 00:05:04,400
in verification which has been used in several 
national elections and in the ch202 system which  

58
00:05:04,400 --> 00:05:08,640
was designed for use in swiss national elections 
and the various implementations have been used  

59
00:05:08,640 --> 00:05:14,560
to make millions of ballots in national and lower 
tier elections now it was proved that the original  

60
00:05:14,560 --> 00:05:19,520
mixed net worked for y-class encryption schemes 
and it was focused that the optimized variant  

61
00:05:19,520 --> 00:05:25,440
also worked for a significant class but an exact 
uh claim and proof had never been given previously

62
00:05:27,520 --> 00:05:31,520
and the other thing that i want to mention 
in background is that proofs of shuffle  

63
00:05:31,520 --> 00:05:38,159
as with most sort of xerox proofs can either 
be interactive or non-interactive and generally  

64
00:05:38,160 --> 00:05:41,440
the proofs that are fine and proven in 
the interactive variant and then made  

65
00:05:41,440 --> 00:05:44,719
non-interactive using the future we transform 
and i'll talk a bit more about that later  

66
00:05:46,240 --> 00:05:49,440
so a little bit upon the inductive 
theorem over we've used we use interactive  

67
00:05:50,000 --> 00:05:56,480
theorem overclock [ __ ] and basically what you do 
in this theo improver is you give as lemons to be  

68
00:05:56,480 --> 00:06:03,120
proven the properties you want to hold and then 
you prove that they impact hold and what happens  

69
00:06:03,120 --> 00:06:07,280
is that once you've written out the proof the 
interactive theorem improver can run through and  

70
00:06:07,280 --> 00:06:14,479
check that yes indeed uh your proof is valid if it 
is actually a sequence of valid steps and there's  

71
00:06:14,480 --> 00:06:20,880
various tools that the improve also provides so 
let me now give you some feel for contribution  

72
00:06:20,880 --> 00:06:25,200
um the first page is sort of background stuff and 
then we get to the more significant contributions  

73
00:06:25,760 --> 00:06:32,400
so there was previous work from from almost the 
same set of authors from ccs 2019 where we mainly  

74
00:06:32,400 --> 00:06:37,840
focused on single protocols but we did show that 
yes actually you can do sort of mixed sets as well  

75
00:06:37,840 --> 00:06:43,919
um but we only actually did it in that paper for 
two so we only had two voters that was fine but  

76
00:06:43,920 --> 00:06:48,480
of course in general uh you want more than that so 
in this work we we get rid of that restriction and  

77
00:06:48,480 --> 00:06:53,440
we prove it for an unbounded number we formalize 
the genetic classroom encryption schemes which  

78
00:06:53,440 --> 00:06:57,040
captures most of all the encryption schemes 
commonly used in voting so we're actually going to  

79
00:06:57,040 --> 00:07:00,720
formally define the encryption schemes 
for which the mixednet is going to work  

80
00:07:01,440 --> 00:07:06,400
and then we provide a kind of paper proof so the 
optimized uh mix net is actually available for  

81
00:07:06,400 --> 00:07:11,919
shuffle for any encryption scheme in that class 
so this is um basically all things that were  

82
00:07:11,920 --> 00:07:15,840
believed to be true but we had to actually just 
do them to actually get to our main contributions  

83
00:07:16,400 --> 00:07:20,880
okay so then what we did is we encoded the above 
class of encryption schemes into [ __ ] and  

84
00:07:20,880 --> 00:07:24,800
machine check the security proof that i talked 
about previously so we checked that yes you know  

85
00:07:24,800 --> 00:07:29,840
if you build a mix on top of anything inside this 
class it is actually a valid uh proof of shuffle  

86
00:07:31,600 --> 00:07:34,640
and the machine check that there's 
an implementation of the mixnet  

87
00:07:34,640 --> 00:07:39,200
there's already mixednet to be complete that 
is honest parties will will happily terminate  

88
00:07:39,200 --> 00:07:42,800
sounds if the verifier accepts the 
motherboard probability the statement  

89
00:07:42,800 --> 00:07:46,240
is true and zero knowledge it doesn't leak 
anything more than just in the statement

90
00:07:49,200 --> 00:07:52,640
so what why why what's the nice thing about 
doing this well the nice thing about doing  

91
00:07:52,640 --> 00:07:57,200
this is that it then suffices to prove that a 
given encryption scheme falls into this class  

92
00:07:57,200 --> 00:08:03,360
in order to get a formally verified verifier 
without actually directly doing anything with  

93
00:08:03,360 --> 00:08:07,760
the mixnet all that's already done for you so you 
just prove the encryption scheme is there and then  

94
00:08:07,760 --> 00:08:13,840
you're done so this is very nice and it makes it 
very easy to use okay so we proved in [ __ ] that  

95
00:08:13,840 --> 00:08:18,880
both basic algorithm and something called 
parallel argument or multi recipient organelle  

96
00:08:18,880 --> 00:08:23,280
fall into this class we also subsequently proved 
that some more complicated encryption schemes also  

97
00:08:23,280 --> 00:08:28,400
fall into this class we also proved that anything 
inside the class is preserved under composition  

98
00:08:28,400 --> 00:08:32,319
both of the same encryption screen in parallel 
and the different encryption schemes in power  

99
00:08:33,840 --> 00:08:37,280
so basically these are kind of the things that you 
would hope would be true in fact we've proven that  

100
00:08:37,280 --> 00:08:42,400
true and this allows you to do a lot of things 
automatically which is very helpful so we've  

101
00:08:42,400 --> 00:08:47,280
done this kind of nice work we now know that we've 
actually you know this thing is actually secure at  

102
00:08:47,280 --> 00:08:52,400
least in theory um we've got nice general ways 
of doing it but does it actually correspond to  

103
00:08:52,400 --> 00:08:57,280
what's happening in practice are the actual mixed 
nets that are running actually the thing we verify  

104
00:08:57,280 --> 00:09:04,319
so the way we did this is we took existing 
implementations of the tavares mixture mixnet  

105
00:09:04,320 --> 00:09:11,440
we got proofs out of those so they generated 
some proofs and we verified those using our  

106
00:09:11,440 --> 00:09:16,960
verifier so we checked and remember that soundness 
is basically a property to verify so the fact that  

107
00:09:16,960 --> 00:09:22,240
our verifier accepts on the proofs is produced 
means that that proven must actually in some sense  

108
00:09:22,240 --> 00:09:28,720
be valid dishonest property implies okay so 
the first implementation we verified was the  

109
00:09:28,720 --> 00:09:34,480
verification mixnet which has been used in norway 
estonia and switzerland and the second one was the  

110
00:09:34,480 --> 00:09:39,200
ch vote system which was planned for use in the 
state of geneva switzerland is currently on hold  

111
00:09:40,400 --> 00:09:45,439
okay so let me now just go over a bit of the sort 
of limitations or clarifications i want to make  

112
00:09:45,440 --> 00:09:50,400
then i'll give some future work and then i'll 
sum up so what did we verify this is always the  

113
00:09:50,400 --> 00:09:54,640
question should be you should ask people say oh 
you verified this okay you verified it but for  

114
00:09:54,640 --> 00:10:00,000
what properties what did you actually verify so we 
verified as i've said completeness zero knowledge  

115
00:10:00,000 --> 00:10:05,280
and sounds and the first two of these completeness 
and zero knowledge actually hold perfectly  

116
00:10:05,280 --> 00:10:09,439
so the arguments here there's no probabilities 
involved it's just algebraic reasoning  

117
00:10:10,080 --> 00:10:13,200
you can actually read in the paper about the 
various techniques we use to actually not have to  

118
00:10:13,200 --> 00:10:19,520
reason directly about probabilities okay but some 
of the other properties specifically soundness  

119
00:10:19,520 --> 00:10:24,240
are actually in form of reductions to underlying 
heart problems and of course if the parameters  

120
00:10:24,240 --> 00:10:28,400
are chosen incorrectly an underlying problem 
is not hard then in fact there is no security

121
00:10:31,760 --> 00:10:35,200
the other thing that we the other limitation 
here is that we didn't actually consider  

122
00:10:35,200 --> 00:10:39,920
sidechart attacks so the primary piece that we're 
interested in getting out of this is the verified  

123
00:10:39,920 --> 00:10:45,120
the verified software is the verifier and this 
is a public algorithm running only on public data  

124
00:10:45,120 --> 00:10:49,120
so we don't actually care about side channels 
with that and we talk a bit in the paper if  

125
00:10:49,120 --> 00:10:55,040
you're interested about side saddles on the proof 
itself so the next big caveat here is the virginia  

126
00:10:55,040 --> 00:11:00,880
transformer so we proved the interactive variants 
of the proof of shuffle however in practice the  

127
00:11:00,880 --> 00:11:06,160
non-interactive variant isn't verbally used now 
all of the verifiable mixtures that sort of come  

128
00:11:06,160 --> 00:11:13,839
out of our functor can be made non-interactive 
with a one or two line change to the algorithm  

129
00:11:14,400 --> 00:11:19,439
but actually proving that that one or two line 
changes secure is left as future work the issue  

130
00:11:19,440 --> 00:11:24,720
here essentially is that actually formally 
proving what we want to prove here involves we  

131
00:11:24,720 --> 00:11:29,200
want rewinding random articles and when you rewind 
metamorphicals you've actually got to think about  

132
00:11:29,200 --> 00:11:34,400
the state of the internal state of the random 
article as you rewind it and also not only mental  

133
00:11:34,400 --> 00:11:38,959
miracles but also actually adversaries accessing 
random articles you've got to rewind adversaries  

134
00:11:38,960 --> 00:11:44,400
think about their internal state there's a lot 
of complexity here i won't go into um but we have  

135
00:11:44,400 --> 00:11:48,000
some sort of way of trying to actually solve 
this and that'll be interesting future work  

136
00:11:49,600 --> 00:11:54,080
and the next thing is to do a code extraction 
so we defined the specification of the thing  

137
00:11:54,080 --> 00:11:58,880
inside [ __ ] we proved that to qs that's a 
nice contribution itself but we actually run  

138
00:11:58,880 --> 00:12:03,760
is not that specification but a more 
efficient extraction of that verification  

139
00:12:03,760 --> 00:12:09,360
and alas the the means by which we do this is 
not itself formally verified there's ongoing  

140
00:12:09,360 --> 00:12:14,880
work in this area but at the moment we don't 
know that that wouldn't introduce more errors  

141
00:12:15,520 --> 00:12:21,120
okay so let me now briefly give the future 
work so one of the limitations in our work  

142
00:12:21,120 --> 00:12:25,600
here was that for completeness and zero 
knowledge we proved sufficient conditions  

143
00:12:26,880 --> 00:12:32,000
but we didn't actually prove that the sufficient 
conditions were sufficient and the reason was  

144
00:12:32,000 --> 00:12:38,080
while the argument that they're sufficient is 
fairly trivial actually formally proving these  

145
00:12:38,080 --> 00:12:43,120
properties formally proving formally defining the 
properties that we want to prove here is actually  

146
00:12:43,120 --> 00:12:46,880
very difficult i'm sorry left this is future work 
this is future work that we've actually made a  

147
00:12:46,880 --> 00:12:52,400
lot of progress on and hopefully um in future 
years i will share with you the results of that  

148
00:12:54,160 --> 00:13:00,400
the other thing we'd really like to do here is to 
prove the biographic snap to be as secure so the  

149
00:13:00,400 --> 00:13:04,640
verification extent is actually fairly simple 
there's sort of one underlying signal protocol  

150
00:13:04,640 --> 00:13:09,120
and then there's one more round on top of that or 
maybe two more rounds depending on how you do it  

151
00:13:09,120 --> 00:13:14,080
um so it's actually a very simple thing the 
biographics on the other hand is much more  

152
00:13:14,080 --> 00:13:19,840
complicated there is i think six different zero 
knowledge proofs that are working together to get  

153
00:13:19,840 --> 00:13:26,400
the results and because of the complexity involved 
there the actual you know there's not a really  

154
00:13:26,400 --> 00:13:31,439
nice fully detailed argument of its of its proof 
that i believe is actually publicly available i  

155
00:13:31,440 --> 00:13:36,560
don't know any in general so this one is actually 
much more likely to have bugs and but it's much  

156
00:13:36,560 --> 00:13:40,560
harder to do and we need to do a lot of work to do 
that we're trying to do that but it's not going to  

157
00:13:40,560 --> 00:13:47,280
work okay so let me just briefly summarize 
so what we're doing here is we're working  

158
00:13:47,280 --> 00:13:53,520
on online voting systems which are using these 
things called verifiable mixnets to basically  

159
00:13:53,520 --> 00:13:58,960
use as a ballot box but these systems are 
actually very complicated pieces of cryptography  

160
00:13:59,520 --> 00:14:05,439
and they are very likely contained critical 
errors which we would like to find would like  

161
00:14:05,440 --> 00:14:12,560
to get rid of um before they're actually run right 
so what we've done is we went and machine checked  

162
00:14:12,560 --> 00:14:17,280
both the design implementation of these bits of 
cryptography to do what we want and we did that in  

163
00:14:17,280 --> 00:14:22,319
a way that gets us very good coverage with a lot 
of different implementations and then we actually  

164
00:14:22,320 --> 00:14:28,720
checked it with implementations to make sure it 
actually worked and then we yeah so then we would  

165
00:14:28,720 --> 00:14:33,520
actually verify transcripts that were produced by 
systems for national elections which is very nice  

166
00:14:33,520 --> 00:14:37,120
but there are these kind of limitations and 
all governments of work that we need if we're  

167
00:14:37,120 --> 00:14:40,880
actually going to get proper coverage of all 
the kinds of things that people are doing in  

168
00:14:40,880 --> 00:14:45,840
practice in the space so thank you if you have 
any questions you can obviously email me or  

169
00:14:45,840 --> 00:14:49,520
you know read the paper and then and then also 
there's a lot more answers in there and then  

170
00:14:49,520 --> 00:14:55,760
also of course you can you know email me after 
that and i look forward to seeing you at s&p

