1
00:00:09,020 --> 00:00:14,370
okay guys start it hello everyone I'm

2
00:00:11,970 --> 00:00:16,530
dome dome a PhD student from Columbia

3
00:00:14,370 --> 00:00:18,810
University today I'm gonna talk about a

4
00:00:16,530 --> 00:00:20,760
learning-based father called news news

5
00:00:18,810 --> 00:00:22,650
is based on a new network model and

6
00:00:20,760 --> 00:00:28,890
perform efficient greeting guided

7
00:00:22,650 --> 00:00:31,049
meditation fuzzing is becoming a popular

8
00:00:28,890 --> 00:00:33,480
way to find software vulnerabilities in

9
00:00:31,050 --> 00:00:35,160
the last 10 years the number of fuzzing

10
00:00:33,480 --> 00:00:37,230
paper has been grown a lot

11
00:00:35,160 --> 00:00:40,110
many researcher are trying to make

12
00:00:37,230 --> 00:00:42,750
father more efficient however almost all

13
00:00:40,110 --> 00:00:47,190
observe a variants of the same design

14
00:00:42,750 --> 00:00:47,730
evolutionary fuzzing evolutionary

15
00:00:47,190 --> 00:00:49,919
fuzzing

16
00:00:47,730 --> 00:00:52,169
start with the initial state then

17
00:00:49,920 --> 00:00:54,359
through random mutation it generate

18
00:00:52,170 --> 00:00:56,339
multiple childs it then select the one

19
00:00:54,359 --> 00:00:58,920
with the most promising result as

20
00:00:56,339 --> 00:01:01,140
initial seed for next run evolution

21
00:00:58,920 --> 00:01:03,960
technique I use it to implement and have

22
00:01:01,140 --> 00:01:07,100
shown significant promise but it is not

23
00:01:03,960 --> 00:01:09,750
very efficient seen the random mutation

24
00:01:07,100 --> 00:01:11,940
has seen the random mutation not very

25
00:01:09,750 --> 00:01:14,190
effective and waste a lot mutation with

26
00:01:11,940 --> 00:01:17,100
a varied guidance they tend to get stuck

27
00:01:14,190 --> 00:01:21,090
after while running in practice it is

28
00:01:17,100 --> 00:01:23,850
hard to find scalable and adaptive

29
00:01:21,090 --> 00:01:25,920
heuristic for guiding mutations many

30
00:01:23,850 --> 00:01:28,470
prior work try to address this

31
00:01:25,920 --> 00:01:30,360
limitation in different way but without

32
00:01:28,470 --> 00:01:34,470
changing the fundamental fuzzing

33
00:01:30,360 --> 00:01:36,710
architecture in this work we consider

34
00:01:34,470 --> 00:01:41,150
fuzzing from a new perspective an

35
00:01:36,710 --> 00:01:45,389
optimization problem that is to find a

36
00:01:41,150 --> 00:01:48,750
set of acts to maximize the number some

37
00:01:45,390 --> 00:01:51,210
shown here capital acts represent our

38
00:01:48,750 --> 00:01:54,780
possible into space lowercase acts

39
00:01:51,210 --> 00:01:57,570
indicate a program input and FX denotes

40
00:01:54,780 --> 00:01:59,970
the number box yield by execution of

41
00:01:57,570 --> 00:02:03,809
specified input most of the input was

42
00:01:59,970 --> 00:02:06,300
simply written 0 FX since parks are hard

43
00:02:03,810 --> 00:02:08,910
flying and only can be triggered by a

44
00:02:06,300 --> 00:02:11,760
small number of Greer edges career

45
00:02:08,910 --> 00:02:14,579
inputs CX is a sample function to

46
00:02:11,760 --> 00:02:17,370
generate K inputs restricted by fuzzing

47
00:02:14,580 --> 00:02:19,620
budget from input space a forcing

48
00:02:17,370 --> 00:02:21,580
campaign often has a resource limit such

49
00:02:19,620 --> 00:02:23,680
as time budget

50
00:02:21,580 --> 00:02:26,080
and the competition budget thus it can

51
00:02:23,680 --> 00:02:28,810
only be generate a fixed number of

52
00:02:26,080 --> 00:02:32,230
mutations within this budget and the aim

53
00:02:28,810 --> 00:02:34,960
of such optimization is to find a set of

54
00:02:32,230 --> 00:02:37,350
inputs which uncover the maximum number

55
00:02:34,960 --> 00:02:42,640
of bugs within the fixed resource budget

56
00:02:37,350 --> 00:02:45,820
however such function FX is ill-behaved

57
00:02:42,640 --> 00:02:48,579
because it is discrete and mostly

58
00:02:45,820 --> 00:02:50,739
contained a lot flat plateau and sharp

59
00:02:48,580 --> 00:02:56,440
transitions make it really hard to

60
00:02:50,740 --> 00:02:59,800
optimize efficiently function FX is

61
00:02:56,440 --> 00:03:03,760
actually a impulse function and has two

62
00:02:59,800 --> 00:03:06,160
spikes X 1 and X 2 because that affects

63
00:03:03,760 --> 00:03:08,739
represent number largest number of bugs

64
00:03:06,160 --> 00:03:10,870
found by a particular input from the

65
00:03:08,740 --> 00:03:12,970
graph we can see that for the target

66
00:03:10,870 --> 00:03:15,610
program only two input can yield

67
00:03:12,970 --> 00:03:17,709
abnormal budgie behavior while other

68
00:03:15,610 --> 00:03:20,950
input just trigger normal behavior and

69
00:03:17,709 --> 00:03:24,310
the yield no bugs as full any simple

70
00:03:20,950 --> 00:03:27,040
function CX it will be extremely hard to

71
00:03:24,310 --> 00:03:33,340
generate K inputs which happen to hate X

72
00:03:27,040 --> 00:03:35,769
1 and X 2 so to solve this problem

73
00:03:33,340 --> 00:03:39,820
modern fuzzers tend to an easier target

74
00:03:35,769 --> 00:03:42,400
H coverage rather than number box simply

75
00:03:39,820 --> 00:03:44,260
because in practice the more edge a

76
00:03:42,400 --> 00:03:50,440
father can explore the more likely it

77
00:03:44,260 --> 00:03:53,049
can uncover but we define GX as a number

78
00:03:50,440 --> 00:03:55,690
of edges taken during execution input on

79
00:03:53,050 --> 00:03:58,750
target program and object function right

80
00:03:55,690 --> 00:04:01,840
now chained to maximize the total number

81
00:03:58,750 --> 00:04:09,330
of edges by finding an optimal set of

82
00:04:01,840 --> 00:04:12,430
input X now we have GX a step function

83
00:04:09,330 --> 00:04:14,680
representing edge coverage many inputs

84
00:04:12,430 --> 00:04:18,400
have some edge coverages compared with

85
00:04:14,680 --> 00:04:21,190
prior 1 this function GX is easier to

86
00:04:18,399 --> 00:04:23,190
optimize sayings it contains more stage

87
00:04:21,190 --> 00:04:25,840
and more transitions between them

88
00:04:23,190 --> 00:04:28,840
evolutionary technique is a popular way

89
00:04:25,840 --> 00:04:32,429
to optimize the function GX to achieve

90
00:04:28,840 --> 00:04:32,429
the maximize edge coverage

91
00:04:35,150 --> 00:04:41,010
here is an example evolutionary

92
00:04:38,100 --> 00:04:44,310
optimizations start from initial set say

93
00:04:41,010 --> 00:04:47,550
point 1 then perform random mutation

94
00:04:44,310 --> 00:04:50,130
cinder random mutation has no any valid

95
00:04:47,550 --> 00:04:52,800
guidance the resulting mutant can be any

96
00:04:50,130 --> 00:04:57,930
point and only depends on luck to hate

97
00:04:52,800 --> 00:05:01,440
any interest region then they reach

98
00:04:57,930 --> 00:05:04,110
point 2 and check whether it introduce

99
00:05:01,440 --> 00:05:08,219
any new edge coverage if it doesn't the

100
00:05:04,110 --> 00:05:11,280
initial says to stay at point 1 then

101
00:05:08,220 --> 00:05:14,700
reach point 3 no edge coverage reach

102
00:05:11,280 --> 00:05:16,919
point for this time is lucky it find new

103
00:05:14,700 --> 00:05:23,130
edge coverage so thus it change to point

104
00:05:16,919 --> 00:05:25,770
4 however since the random mutation can

105
00:05:23,130 --> 00:05:29,159
easily cause the new input to jump back

106
00:05:25,770 --> 00:05:32,400
into no gain region like this ok had

107
00:05:29,160 --> 00:05:34,800
point 5 note that this example is a

108
00:05:32,400 --> 00:05:37,919
simplified one dimension input space

109
00:05:34,800 --> 00:05:40,500
well in the real world cases the input

110
00:05:37,919 --> 00:05:43,200
can have as large as a total implants

111
00:05:40,500 --> 00:05:51,900
dimension where random mutation is not

112
00:05:43,200 --> 00:05:54,330
efficient to provide more guidance in

113
00:05:51,900 --> 00:05:57,840
mutation we propose a new approach

114
00:05:54,330 --> 00:06:01,950
gradient guided optimization it has two

115
00:05:57,840 --> 00:06:04,770
steps first we smooth approximate the

116
00:06:01,950 --> 00:06:07,020
objective function second we compute

117
00:06:04,770 --> 00:06:09,570
gradient of the smooth function which is

118
00:06:07,020 --> 00:06:12,859
approximated and further can perform

119
00:06:09,570 --> 00:06:15,900
efficient greeting-card imitation

120
00:06:12,860 --> 00:06:19,889
assuming somehow magically we could

121
00:06:15,900 --> 00:06:26,460
obtain a smooth approximation of GX like

122
00:06:19,889 --> 00:06:29,729
this HX is a smooth approximation of GX

123
00:06:26,460 --> 00:06:32,460
then we compute gradient of H acts to

124
00:06:29,729 --> 00:06:37,020
obtain promising direction and focus

125
00:06:32,460 --> 00:06:41,479
mutating on this direction similar to

126
00:06:37,020 --> 00:06:41,479
last example we'll start from point 1

127
00:06:42,169 --> 00:06:48,318
then we compute gradient and and we can

128
00:06:46,340 --> 00:06:53,719
point to compute gradient

129
00:06:48,319 --> 00:06:56,240
go to 0.3 0.4 to 0.5 fully in the

130
00:06:53,719 --> 00:06:59,419
gradient we're approaching the spark

131
00:06:56,240 --> 00:07:03,999
error or the interest error and achieve

132
00:06:59,419 --> 00:07:03,998
higher education evolutionary master

133
00:07:04,900 --> 00:07:10,400
gradient guide optimization seems pretty

134
00:07:07,520 --> 00:07:14,389
promising but the problem is how to a

135
00:07:10,400 --> 00:07:17,688
smoothly approximate GX while the object

136
00:07:14,389 --> 00:07:20,750
function GX has no explicit analytical

137
00:07:17,689 --> 00:07:23,090
form moreover it is only accessible from

138
00:07:20,750 --> 00:07:25,669
the black box manner that is we can only

139
00:07:23,090 --> 00:07:28,219
get the output that is edge coverage of

140
00:07:25,669 --> 00:07:31,758
GX through lightweight instrumentation

141
00:07:28,219 --> 00:07:34,250
of target program according to Universal

142
00:07:31,759 --> 00:07:36,680
approximation theorem a single hiding

143
00:07:34,250 --> 00:07:40,279
layer new network model can approximate

144
00:07:36,680 --> 00:07:42,349
any continuous function thus the new

145
00:07:40,279 --> 00:07:45,860
network is a natural fit to this task

146
00:07:42,349 --> 00:07:50,060
our solution is to use a new network

147
00:07:45,860 --> 00:07:57,589
model to smooth approximate GX and our

148
00:07:50,060 --> 00:07:59,839
learn function is HX after obtaining the

149
00:07:57,589 --> 00:08:02,000
smooth approximation then we perform

150
00:07:59,839 --> 00:08:04,580
gradient carry meditation the first

151
00:08:02,000 --> 00:08:07,490
question one asked is why gradient

152
00:08:04,580 --> 00:08:10,669
guidance well we compute gradient of

153
00:08:07,490 --> 00:08:13,490
edges with respect to input the karidian

154
00:08:10,669 --> 00:08:16,279
represents importance for every bite in

155
00:08:13,490 --> 00:08:18,800
the input by choosing the input bytes

156
00:08:16,279 --> 00:08:23,000
with the largest gradient value we can

157
00:08:18,800 --> 00:08:28,069
identify the critical part then what are

158
00:08:23,000 --> 00:08:30,469
the critical parts of input in reality

159
00:08:28,069 --> 00:08:33,440
only a small fraction of input

160
00:08:30,469 --> 00:08:35,929
determined program branches this small

161
00:08:33,440 --> 00:08:40,159
fraction of inputs are critical parts of

162
00:08:35,929 --> 00:08:43,069
input how it works once we identify the

163
00:08:40,159 --> 00:08:45,769
critical parts of input we can greatly

164
00:08:43,070 --> 00:08:48,949
reduce the searching space and a fox

165
00:08:45,769 --> 00:08:52,089
mutating on this location hence improve

166
00:08:48,949 --> 00:08:52,089
the fuzzing efficiency

167
00:08:54,399 --> 00:09:02,509
now let's look at the main idea of news

168
00:08:59,079 --> 00:09:05,120
given the program and fit input it will

169
00:09:02,509 --> 00:09:07,790
execute and trigger a corresponding path

170
00:09:05,120 --> 00:09:11,180
composed of a static control flow edges

171
00:09:07,790 --> 00:09:13,219
this set of control edges ask programs

172
00:09:11,180 --> 00:09:16,339
branch and behavior for the specified

173
00:09:13,220 --> 00:09:19,399
input then we tree a new network model

174
00:09:16,339 --> 00:09:22,009
at the smooth surrogate a program that

175
00:09:19,399 --> 00:09:25,999
will taking the same input and predict

176
00:09:22,009 --> 00:09:28,790
the same branching behavior a nice

177
00:09:25,999 --> 00:09:32,120
property of this smooth surrogate is the

178
00:09:28,790 --> 00:09:33,980
differentiability a program composed of

179
00:09:32,120 --> 00:09:35,930
the CPU instructions is not

180
00:09:33,980 --> 00:09:39,139
differentiable while a new network

181
00:09:35,930 --> 00:09:41,839
surrogate is differentiable thus we

182
00:09:39,139 --> 00:09:44,269
could compute gradient of branches with

183
00:09:41,839 --> 00:09:52,160
respect to input and perform efficient

184
00:09:44,269 --> 00:09:54,050
gradient guiding mutations here we will

185
00:09:52,160 --> 00:09:56,679
peek into the new network model to

186
00:09:54,050 --> 00:10:00,740
explain more detail of the training

187
00:09:56,679 --> 00:10:03,319
program inputs like a file or string can

188
00:10:00,740 --> 00:10:07,610
be considered as a PI sequence each byte

189
00:10:03,319 --> 00:10:09,469
with value range from 0 to 255 so we can

190
00:10:07,610 --> 00:10:12,529
represent the PI sequence with the

191
00:10:09,470 --> 00:10:15,290
numerical vector then we fit input into

192
00:10:12,529 --> 00:10:17,689
target program and obtain the branching

193
00:10:15,290 --> 00:10:20,569
behavior the branching behavior consists

194
00:10:17,689 --> 00:10:23,870
of self control flow edges taken during

195
00:10:20,569 --> 00:10:27,139
dynamic execution if edge is taken it is

196
00:10:23,870 --> 00:10:29,569
marked as one else it's mark with 0 we

197
00:10:27,139 --> 00:10:33,829
use program inputs as training data X

198
00:10:29,569 --> 00:10:36,319
and H bitmap as training label Y to

199
00:10:33,829 --> 00:10:38,479
train a new network model which learn a

200
00:10:36,319 --> 00:10:42,610
function to predict the dynamic

201
00:10:38,480 --> 00:10:42,610
branching behavior for a given input

202
00:10:46,920 --> 00:10:52,498
after training of the new network model

203
00:10:49,259 --> 00:10:55,470
a question pop up that how it

204
00:10:52,499 --> 00:10:58,679
generalized to unseen branches our

205
00:10:55,470 --> 00:11:00,809
observation is that most program inputs

206
00:10:58,679 --> 00:11:03,689
of real world program a highly

207
00:11:00,809 --> 00:11:06,749
structured and this structure of input

208
00:11:03,689 --> 00:11:10,049
form at the critical parts of input

209
00:11:06,749 --> 00:11:12,269
program logic mainly focus on the

210
00:11:10,049 --> 00:11:14,489
critical parts of input and parse them

211
00:11:12,269 --> 00:11:18,449
to trigger different program branches

212
00:11:14,489 --> 00:11:21,959
our solution to identify critical parts

213
00:11:18,449 --> 00:11:29,160
of input from observed branches and use

214
00:11:21,959 --> 00:11:31,738
them to help explore unseen branches in

215
00:11:29,160 --> 00:11:34,259
this graph we showed overall design of

216
00:11:31,739 --> 00:11:37,290
news news start with the set of C

217
00:11:34,259 --> 00:11:40,379
coppers as initial training data then

218
00:11:37,290 --> 00:11:43,618
they use a new network model to learn a

219
00:11:40,379 --> 00:11:46,319
smooth surrogate of target program after

220
00:11:43,619 --> 00:11:49,649
the training news compute gradient of

221
00:11:46,319 --> 00:11:51,689
edges with respect to input and perform

222
00:11:49,649 --> 00:11:54,839
efficient gradient guiding mutations

223
00:11:51,689 --> 00:11:58,169
further will keep the military inputs

224
00:11:54,839 --> 00:11:59,579
that cover new edges and add them into

225
00:11:58,169 --> 00:12:01,739
our training data set

226
00:11:59,579 --> 00:12:04,618
since initial data set only covered

227
00:12:01,739 --> 00:12:06,720
partial program space we keep refine our

228
00:12:04,619 --> 00:12:14,610
new network model with incremental

229
00:12:06,720 --> 00:12:17,309
learning how the evaluation consists of

230
00:12:14,610 --> 00:12:19,619
four parts real-world program love a.m.

231
00:12:17,309 --> 00:12:22,049
and torpor CDC data set comparison with

232
00:12:19,619 --> 00:12:28,319
iron-based father and performance of

233
00:12:22,049 --> 00:12:30,629
different model choice we Valley News on

234
00:12:28,319 --> 00:12:34,259
edge coverage against Feist a dabbler

235
00:12:30,629 --> 00:12:36,749
father including FL CLIA FL buzzer ffs

236
00:12:34,259 --> 00:12:38,819
and FL laughing tell the evaluations

237
00:12:36,749 --> 00:12:41,220
perform on 10 real-world application for

238
00:12:38,819 --> 00:12:43,889
24 hours running covered six popular

239
00:12:41,220 --> 00:12:47,369
file format including a our F minor a

240
00:12:43,889 --> 00:12:49,259
jetpack picture PDF XML Zilla and hot

241
00:12:47,369 --> 00:12:51,660
buzz phone file the results show that

242
00:12:49,259 --> 00:12:53,999
news can outperform all five others on

243
00:12:51,660 --> 00:12:58,549
10 real-world programs and achieve on

244
00:12:53,999 --> 00:12:58,549
average three times more edge coverage

245
00:12:59,050 --> 00:13:04,219
across ten real-world application we

246
00:13:02,300 --> 00:13:07,099
also measure the total number box find

247
00:13:04,220 --> 00:13:09,649
by six buzzer their total five types bug

248
00:13:07,100 --> 00:13:12,079
found on six program including out of

249
00:13:09,649 --> 00:13:14,990
memory bug memory leak assertion crash

250
00:13:12,079 --> 00:13:17,060
integer overflow and HEPA flow news find

251
00:13:14,990 --> 00:13:19,820
the most neighbor bugs and detect all

252
00:13:17,060 --> 00:13:21,829
five bug type including two new CVS we

253
00:13:19,820 --> 00:13:24,050
also report this bug to the developer

254
00:13:21,829 --> 00:13:28,729
and Sansome had already me fix in their

255
00:13:24,050 --> 00:13:30,920
latest version la by hand and the

256
00:13:28,730 --> 00:13:33,320
dropper CDC data said a to fuzzing

257
00:13:30,920 --> 00:13:36,680
dataset based on magical word comparison

258
00:13:33,320 --> 00:13:38,930
we run news a full lava M program and 15

259
00:13:36,680 --> 00:13:41,239
to proceed is a binary against state of

260
00:13:38,930 --> 00:13:44,149
dark father's news identify critical

261
00:13:41,240 --> 00:13:46,370
parts of input which determines magical

262
00:13:44,149 --> 00:13:48,860
checking branches that perform local

263
00:13:46,370 --> 00:13:50,810
exhaustive searching to break them so it

264
00:13:48,860 --> 00:13:56,630
can outperform state of our phasers on

265
00:13:50,810 --> 00:13:58,518
lava m and CTC we also compare news with

266
00:13:56,630 --> 00:14:01,130
another learning-based father our and

267
00:13:58,519 --> 00:14:03,560
base father it used our model to learn

268
00:14:01,130 --> 00:14:05,750
critical parts of program inputs and the

269
00:14:03,560 --> 00:14:08,268
future out mutation which do not touch

270
00:14:05,750 --> 00:14:11,240
the critical parts where wrong news and

271
00:14:08,269 --> 00:14:13,459
for programs evaluate in their paper for

272
00:14:11,240 --> 00:14:15,980
one minion fixed mutation and compare

273
00:14:13,459 --> 00:14:18,680
the edge coverage and training time news

274
00:14:15,980 --> 00:14:23,390
achieved six times more edge coverage

275
00:14:18,680 --> 00:14:25,910
and 20 times less training time in the

276
00:14:23,390 --> 00:14:28,490
end we vary news on three different new

277
00:14:25,910 --> 00:14:30,290
network setting simple linear model new

278
00:14:28,490 --> 00:14:32,120
network model and a new network model

279
00:14:30,290 --> 00:14:34,519
with incremental learning and one

280
00:14:32,120 --> 00:14:36,980
meaning fixed mutation the results show

281
00:14:34,519 --> 00:14:39,980
that news achieves the fast performance

282
00:14:36,980 --> 00:14:45,980
which new network plus incremental

283
00:14:39,980 --> 00:14:48,440
learning some takeaway of news first

284
00:14:45,980 --> 00:14:52,610
Newsies greedy information to identify

285
00:14:48,440 --> 00:14:56,329
critical parts of inputs second it folks

286
00:14:52,610 --> 00:14:58,550
mutating on this location sir news wrong

287
00:14:56,329 --> 00:15:00,500
time of the Hat is minimal because the

288
00:14:58,550 --> 00:15:02,839
new network using news is a simple

289
00:15:00,500 --> 00:15:05,180
feed-forward new network model and only

290
00:15:02,839 --> 00:15:07,850
take one or two minutes to train our GPU

291
00:15:05,180 --> 00:15:09,979
finally we keep retraining our new

292
00:15:07,850 --> 00:15:12,050
network model to find new critical

293
00:15:09,980 --> 00:15:18,320
locations

294
00:15:12,050 --> 00:15:29,149
we open-source news on github it's a

295
00:15:18,320 --> 00:15:31,160
thank you for attention as a Q&A any

296
00:15:29,149 --> 00:15:33,790
questions please state your name and

297
00:15:31,160 --> 00:15:33,790
affiliation

298
00:15:39,269 --> 00:15:44,160
I steal Parliament result from

299
00:15:41,369 --> 00:15:46,589
Polytechnic of Milano just wondering if

300
00:15:44,160 --> 00:15:48,329
you try to like do some experiments on

301
00:15:46,589 --> 00:15:51,059
transfer learning whether you can like

302
00:15:48,329 --> 00:15:53,790
apply us the same like a preacher a

303
00:15:51,059 --> 00:15:57,360
model on a different target program

304
00:15:53,790 --> 00:16:00,089
without like training from scratch I'm

305
00:15:57,360 --> 00:16:02,309
sorry do tell me you you we start found

306
00:16:00,089 --> 00:16:05,970
a small set of training data no no I

307
00:16:02,309 --> 00:16:07,290
mean so if I understood correctly ah you

308
00:16:05,970 --> 00:16:08,790
are focused every time you start a

309
00:16:07,290 --> 00:16:10,259
fuzzing like campaign or something

310
00:16:08,790 --> 00:16:12,329
you're basically focusing on a single

311
00:16:10,259 --> 00:16:14,579
target program and training on on that

312
00:16:12,329 --> 00:16:16,469
have you tried to see whether there is

313
00:16:14,579 --> 00:16:18,300
some like transfer learning that might

314
00:16:16,470 --> 00:16:21,629
be happening so you can apply the same

315
00:16:18,300 --> 00:16:29,339
like wait to start a new fuzzing target

316
00:16:21,629 --> 00:16:32,610
uh-huh I mean you didn't see our

317
00:16:29,339 --> 00:16:34,679
designed with showing a nooner model to

318
00:16:32,610 --> 00:16:36,899
approximate program behavior yes and use

319
00:16:34,679 --> 00:16:39,089
this nuna model to guide the fuzzing

320
00:16:36,899 --> 00:16:42,209
real-word program not fuzzing no network

321
00:16:39,089 --> 00:16:45,209
no no what I mean is your training on a

322
00:16:42,209 --> 00:16:48,540
single target program every time right

323
00:16:45,209 --> 00:16:50,248
yeah okay have you tried to see like if

324
00:16:48,540 --> 00:16:54,240
you train on oh I see enemy transfer

325
00:16:50,249 --> 00:16:56,129
learning yeah that may not we didn't

326
00:16:54,240 --> 00:16:58,410
test that because the model is designed

327
00:16:56,129 --> 00:17:00,509
for learn from specific program every

328
00:16:58,410 --> 00:17:02,279
time but for transfer learning like in

329
00:17:00,509 --> 00:17:03,929
the computer vision error the input is

330
00:17:02,279 --> 00:17:05,579
same well for different program the

331
00:17:03,929 --> 00:17:07,349
different file format is hard to

332
00:17:05,579 --> 00:17:09,809
transfer found to different file format

333
00:17:07,349 --> 00:17:12,059
yeah but my so I'm just saying that

334
00:17:09,809 --> 00:17:14,970
maybe I'm not sure but maybe it might

335
00:17:12,059 --> 00:17:16,549
work at some level because like still

336
00:17:14,970 --> 00:17:21,480
like five formats are different but

337
00:17:16,549 --> 00:17:27,869
usually they're similar somehow just

338
00:17:21,480 --> 00:17:29,370
saying thank you yes so just follow up

339
00:17:27,869 --> 00:17:31,559
to down down yes there are similarities

340
00:17:29,370 --> 00:17:33,090
across file formats right we

341
00:17:31,559 --> 00:17:38,360
particularly have not tested that yet

342
00:17:33,090 --> 00:17:42,178
but that'd be great to test a point hi

343
00:17:38,360 --> 00:17:45,240
critic Hector from UC Santa Barbara

344
00:17:42,179 --> 00:17:49,380
well the question is when you are trying

345
00:17:45,240 --> 00:17:51,960
to well in linear network of yours how

346
00:17:49,380 --> 00:17:54,769
do you like limit the size of

347
00:17:51,960 --> 00:17:58,169
output like there are always many

348
00:17:54,769 --> 00:18:00,330
branches sir yeah do you have one for 1

349
00:17:58,169 --> 00:18:02,190
euro for each branch or do yeah that's a

350
00:18:00,330 --> 00:18:05,309
good question we actually do some

351
00:18:02,190 --> 00:18:07,950
optimization we call output branch

352
00:18:05,309 --> 00:18:10,950
output dimension reduction basically we

353
00:18:07,950 --> 00:18:13,950
will do is we observe that let's say we

354
00:18:10,950 --> 00:18:16,649
have 10 input times have 10 set of the

355
00:18:13,950 --> 00:18:18,480
control flow edges while this tenth set

356
00:18:16,649 --> 00:18:20,969
the 10th floor edges there some lien

357
00:18:18,480 --> 00:18:23,369
collinearity in machine learning recall

358
00:18:20,970 --> 00:18:27,090
collinearity basically have two features

359
00:18:23,369 --> 00:18:28,649
I have the same label across all your

360
00:18:27,090 --> 00:18:31,080
training data basically you have 10

361
00:18:28,649 --> 00:18:33,389
inputs and for the one leg one edges all

362
00:18:31,080 --> 00:18:35,759
time inputs all taken or not taken that

363
00:18:33,389 --> 00:18:37,590
mean if we use that label didn't carry

364
00:18:35,759 --> 00:18:39,779
any information because our input had

365
00:18:37,590 --> 00:18:43,019
the same label for that so we do a

366
00:18:39,779 --> 00:18:44,279
simple dimension reduction by removing

367
00:18:43,019 --> 00:18:46,470
this collinearity

368
00:18:44,279 --> 00:18:50,940
in the output space and greatly reduce

369
00:18:46,470 --> 00:18:52,980
the edge and in practice around 2k our

370
00:18:50,940 --> 00:18:56,549
5k total edges are real-world programs

371
00:18:52,980 --> 00:18:58,919
okay so do you have to like reassign

372
00:18:56,549 --> 00:19:00,929
different semantics meaning for each

373
00:18:58,919 --> 00:19:03,149
numeral when you're retraining your

374
00:19:00,929 --> 00:19:06,570
model or when you're like fine-tune your

375
00:19:03,149 --> 00:19:10,408
model along the feathering process I

376
00:19:06,570 --> 00:19:12,539
mean do you have to like after

377
00:19:10,409 --> 00:19:15,419
fine-tuning your model do you have to

378
00:19:12,539 --> 00:19:17,429
like you know have a different mapping

379
00:19:15,419 --> 00:19:17,639
to different branches or they stay the

380
00:19:17,429 --> 00:19:20,460
same

381
00:19:17,639 --> 00:19:22,498
yeah it will become a different mapping

382
00:19:20,460 --> 00:19:25,049
because every time before we training we

383
00:19:22,499 --> 00:19:27,360
would do output dimension reduction ok

384
00:19:25,049 --> 00:19:28,649
then the output label will change okay

385
00:19:27,360 --> 00:19:32,340
another question

386
00:19:28,649 --> 00:19:35,518
ok I'll comment on another paper that's

387
00:19:32,340 --> 00:19:37,439
kind of similar to yours Angora and

388
00:19:35,519 --> 00:19:41,009
can come in on your papers difference

389
00:19:37,440 --> 00:19:43,830
from there you're different but I just

390
00:19:41,009 --> 00:19:45,539
want to the main difference between news

391
00:19:43,830 --> 00:19:47,519
and Angora yeah

392
00:19:45,539 --> 00:19:49,230
anger is focused on from my

393
00:19:47,519 --> 00:19:52,980
understanding is focused on put branches

394
00:19:49,230 --> 00:19:54,899
if it is start from the it's time to say

395
00:19:52,980 --> 00:19:58,919
it won't break particular branches and

396
00:19:54,899 --> 00:20:00,989
it will probe and do some input plus one

397
00:19:58,919 --> 00:20:02,820
or minus one obtaining the apples and

398
00:20:00,990 --> 00:20:05,320
try to break a particular branches while

399
00:20:02,820 --> 00:20:07,960
noisy's learn overall program

400
00:20:05,320 --> 00:20:09,970
as a whole new network model every label

401
00:20:07,960 --> 00:20:12,250
of the newer model representing one

402
00:20:09,970 --> 00:20:13,779
branch we do not explicitly model a

403
00:20:12,250 --> 00:20:15,940
particular branch we model the whole

404
00:20:13,779 --> 00:20:20,220
program the whole plan can post up all

405
00:20:15,940 --> 00:20:23,860
the branches inside okay thank you

406
00:20:20,220 --> 00:20:26,320
any more questions then maybe let me ask

407
00:20:23,860 --> 00:20:28,299
a quick question Niels Provos stripe I'm

408
00:20:26,320 --> 00:20:30,279
curious if you've looked at sort of the

409
00:20:28,299 --> 00:20:31,870
size of your neural network in

410
00:20:30,279 --> 00:20:34,389
comparison to the programs that you're

411
00:20:31,870 --> 00:20:36,610
applying it against presumably programs

412
00:20:34,389 --> 00:20:38,500
with a large state space may require a

413
00:20:36,610 --> 00:20:40,258
larger model to learn if you looked at

414
00:20:38,500 --> 00:20:44,289
that at all

415
00:20:40,259 --> 00:20:46,990
we currently our noona model is a fixed

416
00:20:44,289 --> 00:20:49,779
lens we define the fixed and emphasized

417
00:20:46,990 --> 00:20:52,120
a K bytes and the total number neuron

418
00:20:49,779 --> 00:20:55,090
inside is a to K number of neurons and

419
00:20:52,120 --> 00:20:57,939
if the program increased larger say the

420
00:20:55,090 --> 00:21:00,459
input lens increase now accordingly we

421
00:20:57,940 --> 00:21:02,860
should increase the number of the Heidel

422
00:21:00,460 --> 00:21:05,679
area of Nan our model by the way didn't

423
00:21:02,860 --> 00:21:07,449
perform didn't evaluate on the very very

424
00:21:05,679 --> 00:21:09,789
large program yet which is testament and

425
00:21:07,450 --> 00:21:12,009
real work program okay

426
00:21:09,789 --> 00:21:13,509
let's thank the speaker Giovanni yeah

427
00:21:12,009 --> 00:21:14,169
well question quick I try to be here

428
00:21:13,509 --> 00:21:15,720
from UCSB

429
00:21:14,169 --> 00:21:18,399
I have a stupid question you had a

430
00:21:15,720 --> 00:21:21,279
something to say for an input this is

431
00:21:18,399 --> 00:21:23,289
the number of bugs that this input finds

432
00:21:21,279 --> 00:21:28,480
what a situation will you find more than

433
00:21:23,289 --> 00:21:30,940
one that cases so our first always think

434
00:21:28,480 --> 00:21:33,059
of a one implicit fine with one box it's

435
00:21:30,940 --> 00:21:35,710
just crash then we figure out let's say

436
00:21:33,059 --> 00:21:38,019
in some cases sunny people would now

437
00:21:35,710 --> 00:21:40,360
cost crash oh it has caused a crash they

438
00:21:38,019 --> 00:21:43,000
say crash in Buffalo but before that it

439
00:21:40,360 --> 00:21:44,529
may have the integer flow or some memory

440
00:21:43,000 --> 00:21:46,210
leak or something that also happened we

441
00:21:44,529 --> 00:21:48,399
also considered a bug okay we didn't

442
00:21:46,210 --> 00:21:49,710
come at one all right let's thank the

443
00:21:48,399 --> 00:21:54,889
speaker

444
00:21:49,710 --> 00:21:54,890
[Applause]

