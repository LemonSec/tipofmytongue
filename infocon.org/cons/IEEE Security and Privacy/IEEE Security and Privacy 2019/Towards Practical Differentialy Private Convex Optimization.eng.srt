1
00:00:08,650 --> 00:00:14,150
good afternoon so this talk is focused

2
00:00:12,139 --> 00:00:16,849
towards practical differentially private

3
00:00:14,150 --> 00:00:18,680
convex optimization and this is joined

4
00:00:16,849 --> 00:00:21,710
to work with my wonderful co-authors

5
00:00:18,680 --> 00:00:23,570
that are listed on the screen so let me

6
00:00:21,710 --> 00:00:26,210
start by briefly stating the

7
00:00:23,570 --> 00:00:28,910
contributions of this work so the first

8
00:00:26,210 --> 00:00:31,160
contribution is that we design a new

9
00:00:28,910 --> 00:00:33,590
private algorithm which we call

10
00:00:31,160 --> 00:00:36,770
approximate minimum ohter bation or amp

11
00:00:33,590 --> 00:00:39,140
for short it is designed towards being

12
00:00:36,770 --> 00:00:41,980
deployables in practice and it has many

13
00:00:39,140 --> 00:00:45,050
advantages I'll describe in detail soon

14
00:00:41,980 --> 00:00:47,120
the second contribution is that we

15
00:00:45,050 --> 00:00:48,730
conduct a broad empirical study of the

16
00:00:47,120 --> 00:00:52,730
state-of-the-art techniques in the field

17
00:00:48,730 --> 00:00:54,890
we do this over 2 models and 13 data

18
00:00:52,730 --> 00:00:58,400
sets four of which are high dimensional

19
00:00:54,890 --> 00:01:00,770
and all of our benchmarks as well as the

20
00:00:58,400 --> 00:01:05,630
code for a technique are open source and

21
00:01:00,770 --> 00:01:08,540
available on the following link so in

22
00:01:05,630 --> 00:01:10,880
this talk I'll start by providing some

23
00:01:08,540 --> 00:01:13,580
motivation of why do we need privacy for

24
00:01:10,880 --> 00:01:16,640
learning then I'll cover some background

25
00:01:13,580 --> 00:01:19,280
first I'll introduce what is

26
00:01:16,640 --> 00:01:23,450
differential privacy and give a quick

27
00:01:19,280 --> 00:01:26,390
refresher on convex optimization then

28
00:01:23,450 --> 00:01:28,610
I'll introduce our technique amp and

29
00:01:26,390 --> 00:01:33,890
I'll conclude by presenting the results

30
00:01:28,610 --> 00:01:36,740
of a study so that's the plan before I

31
00:01:33,890 --> 00:01:39,920
dive in let me first define the

32
00:01:36,740 --> 00:01:43,789
framework that will operate in so we are

33
00:01:39,920 --> 00:01:47,390
given a sensitive data set D that is

34
00:01:43,790 --> 00:01:50,150
input that is given as input to a

35
00:01:47,390 --> 00:01:53,180
learning procedure a which gives out an

36
00:01:50,150 --> 00:01:56,150
output model you can think of the output

37
00:01:53,180 --> 00:02:00,260
model theta hat as a set of vector as a

38
00:01:56,150 --> 00:02:02,810
vector of waits for some network many

39
00:02:00,260 --> 00:02:05,119
recent works have shown that these

40
00:02:02,810 --> 00:02:07,060
models can leak information about the

41
00:02:05,119 --> 00:02:10,128
training data

42
00:02:07,060 --> 00:02:13,549
these can be split into two broad

43
00:02:10,128 --> 00:02:15,590
categories for example in membership in

44
00:02:13,549 --> 00:02:18,829
Printz attacks an adversary can

45
00:02:15,590 --> 00:02:20,629
confidently predict whether any sample

46
00:02:18,829 --> 00:02:22,209
was introduced in the training process

47
00:02:20,629 --> 00:02:24,548
by just access

48
00:02:22,209 --> 00:02:26,409
the output model theta-hat so without

49
00:02:24,549 --> 00:02:28,239
even looking at the data set by only

50
00:02:26,409 --> 00:02:32,108
accessing the output model the adversity

51
00:02:28,239 --> 00:02:37,780
can predict membership inference how do

52
00:02:32,109 --> 00:02:39,939
we prevent such leaks so differential

53
00:02:37,780 --> 00:02:42,150
privacy has been recently used as a gold

54
00:02:39,939 --> 00:02:44,709
standard to prevent such leakage

55
00:02:42,150 --> 00:02:48,069
let's start by intuitively understanding

56
00:02:44,709 --> 00:02:51,219
what does the notion mean so we have a

57
00:02:48,069 --> 00:02:53,409
data set D comprising of several members

58
00:02:51,219 --> 00:02:56,349
that is input into a randomized

59
00:02:53,409 --> 00:03:01,149
algorithm a which gives out some model

60
00:02:56,349 --> 00:03:03,819
theta since a is randomized it has some

61
00:03:01,150 --> 00:03:06,969
distribution over the set of outcomes so

62
00:03:03,819 --> 00:03:09,819
here on the x-axis I am denoting the

63
00:03:06,969 --> 00:03:12,849
model space each point represents some

64
00:03:09,819 --> 00:03:15,450
model theta hat and the y axis denotes

65
00:03:12,849 --> 00:03:17,858
the probability of algorithm a

66
00:03:15,450 --> 00:03:23,409
outputting that particular model when

67
00:03:17,859 --> 00:03:27,519
the input is data set deep imagine that

68
00:03:23,409 --> 00:03:30,548
I change one person from the input

69
00:03:27,519 --> 00:03:34,199
dataset so I have replaced ohm by Felix

70
00:03:30,549 --> 00:03:37,479
let me denote this dataset by D Prime

71
00:03:34,199 --> 00:03:40,030
since the dataset changes the

72
00:03:37,479 --> 00:03:42,639
distribution over the outputs can also

73
00:03:40,030 --> 00:03:45,639
change which is represented by the red

74
00:03:42,639 --> 00:03:49,150
plot what differential privacy

75
00:03:45,639 --> 00:03:53,470
guarantees is that the change for any

76
00:03:49,150 --> 00:03:57,759
particular output is small so in some

77
00:03:53,470 --> 00:03:59,829
sense the algorithm outputs each each

78
00:03:57,759 --> 00:04:01,478
particular model with about the same

79
00:03:59,829 --> 00:04:03,819
probability whether D or D prime was

80
00:04:01,479 --> 00:04:08,549
used and effectively it does not depend

81
00:04:03,819 --> 00:04:08,548
much on any particular individuals data

82
00:04:09,780 --> 00:04:17,620
the definition is characterized by two

83
00:04:13,269 --> 00:04:20,858
parameters epsilon and Delta it has a

84
00:04:17,620 --> 00:04:22,289
mathematical precise formula but in the

85
00:04:20,858 --> 00:04:25,508
interest of time I will just say that

86
00:04:22,289 --> 00:04:29,169
epsilon bounds the multiplicative change

87
00:04:25,509 --> 00:04:31,800
in the probabilities and it is standard

88
00:04:29,169 --> 00:04:35,590
to consider epsilon as a small constant

89
00:04:31,800 --> 00:04:38,290
whereas Delta bounds the additive change

90
00:04:35,590 --> 00:04:42,760
and typically it vanishes with the data

91
00:04:38,290 --> 00:04:45,750
size n its standard to consider Delta as

92
00:04:42,760 --> 00:04:45,750
one over N squared

93
00:04:45,910 --> 00:04:49,540
the important thing is as these

94
00:04:47,290 --> 00:04:56,650
parameters go down the level of privacy

95
00:04:49,540 --> 00:04:59,140
goes up a quick intro to convex

96
00:04:56,650 --> 00:05:02,549
optimization and also to formalize the

97
00:04:59,140 --> 00:05:04,990
notation we have a data set D that

98
00:05:02,550 --> 00:05:07,300
consists of n samples from some

99
00:05:04,990 --> 00:05:10,060
population we are given a loss function

100
00:05:07,300 --> 00:05:12,370
L that's parameterize by a model and a

101
00:05:10,060 --> 00:05:13,630
data set and the condition is the loss

102
00:05:12,370 --> 00:05:16,570
function is convex in the first

103
00:05:13,630 --> 00:05:19,540
parameter theta the goal is to output

104
00:05:16,570 --> 00:05:21,820
the minimum of this loss function so the

105
00:05:19,540 --> 00:05:26,530
goal is doubt output Teta hat such that

106
00:05:21,820 --> 00:05:28,120
it minimizes the loss and this has many

107
00:05:26,530 --> 00:05:29,859
applications ranging from machine

108
00:05:28,120 --> 00:05:36,280
learning deep learning recommendation

109
00:05:29,860 --> 00:05:37,750
systems many more so there has been a

110
00:05:36,280 --> 00:05:39,070
lot of work in the area of

111
00:05:37,750 --> 00:05:42,360
differentially private convex

112
00:05:39,070 --> 00:05:45,190
optimization there is a technique called

113
00:05:42,360 --> 00:05:48,640
objective perturbation which as the name

114
00:05:45,190 --> 00:05:51,490
suggests it perturbs the input loss

115
00:05:48,640 --> 00:05:54,430
function there are a couple of

116
00:05:51,490 --> 00:05:57,160
techniques that add noise within the

117
00:05:54,430 --> 00:05:59,500
training procedure itself and there are

118
00:05:57,160 --> 00:06:04,120
a couple more that deal with the output

119
00:05:59,500 --> 00:06:07,600
model they put up the output however

120
00:06:04,120 --> 00:06:10,300
what is important to note is that two of

121
00:06:07,600 --> 00:06:12,580
these techniques require the exact

122
00:06:10,300 --> 00:06:16,000
minimum of the loss function that you

123
00:06:12,580 --> 00:06:18,300
are optimizing over and as we know this

124
00:06:16,000 --> 00:06:22,690
is never guaranteed in practice you can

125
00:06:18,300 --> 00:06:24,430
not guarantee the exact minimum whereas

126
00:06:22,690 --> 00:06:27,250
the other techniques requires some

127
00:06:24,430 --> 00:06:29,740
custom optimizer so if you already have

128
00:06:27,250 --> 00:06:32,950
some T owned optimizer using some

129
00:06:29,740 --> 00:06:36,060
infrastructure in place these techniques

130
00:06:32,950 --> 00:06:36,060
might not be the best suited

131
00:06:37,539 --> 00:06:46,568
this motivates us to design what we call

132
00:06:41,080 --> 00:06:48,448
amp here we are given a data set D and I

133
00:06:46,569 --> 00:06:52,809
will denote the privacy parameters by B

134
00:06:48,449 --> 00:06:55,330
corresponding to some budget in addition

135
00:06:52,809 --> 00:06:57,009
this technique requires what is called a

136
00:06:55,330 --> 00:06:59,438
gradient norm bound I'll denote it by

137
00:06:57,009 --> 00:07:02,439
gamma I'll describe its significance

138
00:06:59,439 --> 00:07:04,809
soon so the technique is very simple it

139
00:07:02,439 --> 00:07:08,259
can be described in four steps at high

140
00:07:04,809 --> 00:07:10,419
level so here's out how it goes so the

141
00:07:08,259 --> 00:07:15,219
first step is to split the privacy

142
00:07:10,419 --> 00:07:18,128
budget into two parts using the first

143
00:07:15,219 --> 00:07:21,219
part you add some regularization to the

144
00:07:18,129 --> 00:07:23,560
loss function and for the members that

145
00:07:21,219 --> 00:07:25,150
are familiar with objective perturbation

146
00:07:23,560 --> 00:07:28,810
this step is very similar to that

147
00:07:25,150 --> 00:07:31,239
technique so effectively now the loss

148
00:07:28,810 --> 00:07:34,770
function at our disposal looks something

149
00:07:31,240 --> 00:07:37,569
like this we denoted by L probe

150
00:07:34,770 --> 00:07:41,469
consequently the minimizer also changes

151
00:07:37,569 --> 00:07:44,110
we'll denote it by theta proof so now

152
00:07:41,469 --> 00:07:47,020
you can use your favorite optimizer to

153
00:07:44,110 --> 00:07:51,249
optimize over this perturbed loss but

154
00:07:47,020 --> 00:07:53,649
when do you stop this is where the

155
00:07:51,249 --> 00:07:55,659
parameter gamma comes in so gamma

156
00:07:53,649 --> 00:07:57,879
defines a region around the minimizer

157
00:07:55,659 --> 00:08:01,020
where the norm of the gradient is

158
00:07:57,879 --> 00:08:03,789
bounded from above by gamma

159
00:08:01,020 --> 00:08:06,128
note that the norm of the gradient at

160
00:08:03,789 --> 00:08:09,370
the minimum is a theta probe is zero so

161
00:08:06,129 --> 00:08:11,499
around it it should be very small so you

162
00:08:09,370 --> 00:08:15,520
continue optimizing until you reach any

163
00:08:11,499 --> 00:08:18,699
point within this region so let's denote

164
00:08:15,520 --> 00:08:21,729
it by that point by theta procs as it is

165
00:08:18,699 --> 00:08:23,080
an approximate minima of the as as it is

166
00:08:21,729 --> 00:08:26,620
an approximate minimum of the perturbed

167
00:08:23,080 --> 00:08:28,448
loss what you do is you add some noise

168
00:08:26,620 --> 00:08:31,899
using the second part of your privacy

169
00:08:28,449 --> 00:08:35,610
budget and release that model so this is

170
00:08:31,899 --> 00:08:35,610
the output of the algorithm

171
00:08:37,958 --> 00:08:42,828
we also provide formal util utility

172
00:08:40,969 --> 00:08:44,180
guarantees for this technique but rather

173
00:08:42,828 --> 00:08:46,849
than trying to explain you this

174
00:08:44,179 --> 00:08:50,689
beautiful slide I'll just provide the

175
00:08:46,850 --> 00:08:53,269
takeaways so one major advantage of this

176
00:08:50,690 --> 00:08:55,279
technique is that it can leverage any of

177
00:08:53,269 --> 00:08:59,389
the Shelf optimizer we don't place any

178
00:08:55,279 --> 00:09:01,279
restrictions on the optimizer used it

179
00:08:59,389 --> 00:09:03,800
also works for all standard convex loss

180
00:09:01,279 --> 00:09:07,639
functions most of the techniques in

181
00:09:03,800 --> 00:09:13,430
prior work applied to only GLM's

182
00:09:07,639 --> 00:09:16,910
or generalized linear models next if you

183
00:09:13,430 --> 00:09:19,430
sit gamma small enough the gradient norm

184
00:09:16,910 --> 00:09:22,219
bound small enough then the utility

185
00:09:19,430 --> 00:09:24,579
guarantee of this technique is on the

186
00:09:22,220 --> 00:09:26,959
same order as objective perturbation

187
00:09:24,579 --> 00:09:29,810
objective perturbation has the best

188
00:09:26,959 --> 00:09:31,760
asymptotic utility guarantees in the

189
00:09:29,810 --> 00:09:36,768
field but it requires the exact

190
00:09:31,760 --> 00:09:39,500
minimizer which is not practical in

191
00:09:36,769 --> 00:09:41,920
addition to it our technique also has a

192
00:09:39,500 --> 00:09:45,560
better dependence on the data set size n

193
00:09:41,920 --> 00:09:47,540
as compared to private permutation bay

194
00:09:45,560 --> 00:09:50,949
stochastic gradient descent that is the

195
00:09:47,540 --> 00:09:54,529
state-of-the-art and output perturbation

196
00:09:50,949 --> 00:09:57,890
so you have to set gamma small enough to

197
00:09:54,529 --> 00:10:00,470
obtain this guarantee what we see in our

198
00:09:57,890 --> 00:10:02,750
experiments is that gamma equal to 1

199
00:10:00,470 --> 00:10:05,510
over N squared is very easily achievable

200
00:10:02,750 --> 00:10:07,790
and like only using standard Python

201
00:10:05,510 --> 00:10:14,149
libraries so you can hope for much

202
00:10:07,790 --> 00:10:17,180
smaller gamma as well so next I will

203
00:10:14,149 --> 00:10:20,089
talk about the second contribution which

204
00:10:17,180 --> 00:10:22,819
is the empirical evaluation we conduct

205
00:10:20,089 --> 00:10:26,329
our evaluation over thirteen data sets

206
00:10:22,819 --> 00:10:29,329
that we bucket eyes into we categorize

207
00:10:26,329 --> 00:10:31,040
into three buckets low dimensional high

208
00:10:29,329 --> 00:10:33,170
dimensional and real-world data sets

209
00:10:31,040 --> 00:10:37,040
that have been obtained by a

210
00:10:33,170 --> 00:10:38,899
collaboration with uber so here the

211
00:10:37,040 --> 00:10:41,660
categorization is if the number of

212
00:10:38,899 --> 00:10:45,079
samples is much larger than the number

213
00:10:41,660 --> 00:10:46,850
of features we say it is no dimensional

214
00:10:45,079 --> 00:10:49,300
if it is comparable we say it is high

215
00:10:46,850 --> 00:10:49,300
dimensional

216
00:10:49,590 --> 00:10:57,550
the algorithms we have evaluate include

217
00:10:52,600 --> 00:11:00,279
amp two of the techniques that add noise

218
00:10:57,550 --> 00:11:02,319
during the training process and two

219
00:11:00,279 --> 00:11:06,430
techniques which are practical variants

220
00:11:02,320 --> 00:11:07,900
of output perturbation one important

221
00:11:06,430 --> 00:11:10,060
point to note is that all of these

222
00:11:07,900 --> 00:11:12,579
techniques have some hyper parameters

223
00:11:10,060 --> 00:11:16,569
that need to be tuned for performance to

224
00:11:12,580 --> 00:11:18,640
be good this involves some cost in

225
00:11:16,570 --> 00:11:23,650
itself that has to be taken into account

226
00:11:18,640 --> 00:11:27,069
and so we also provide a hyper parameter

227
00:11:23,650 --> 00:11:28,600
free variant of amp basically the only

228
00:11:27,070 --> 00:11:31,210
hyper parameter in our technique is how

229
00:11:28,600 --> 00:11:36,180
you split the privacy budget within the

230
00:11:31,210 --> 00:11:39,100
technique and we provide a schedule that

231
00:11:36,180 --> 00:11:41,140
we provide a schedule for doing this by

232
00:11:39,100 --> 00:11:46,300
only evaluating it on synthetic data

233
00:11:41,140 --> 00:11:48,339
sets so you have no cost to privacy we

234
00:11:46,300 --> 00:11:51,130
also compare all the techniques with a

235
00:11:48,339 --> 00:11:52,510
non private baseline that is the

236
00:11:51,130 --> 00:11:56,160
technique which provides the best

237
00:11:52,510 --> 00:11:56,160
performance without considering privacy

238
00:11:57,720 --> 00:12:03,790
so what is the experimental procedure we

239
00:12:01,300 --> 00:12:08,500
consider to loss functions in this talk

240
00:12:03,790 --> 00:12:12,520
I will focus on logistic regression we

241
00:12:08,500 --> 00:12:14,530
first split the input data set into we

242
00:12:12,520 --> 00:12:17,740
randomly split it into a training and

243
00:12:14,530 --> 00:12:19,689
testing set we fix one of the privacy

244
00:12:17,740 --> 00:12:24,040
parameters Delta to one over N squared

245
00:12:19,690 --> 00:12:26,950
and we vary epsilon from 0.01 which is

246
00:12:24,040 --> 00:12:32,699
very high privacy to ten which is lower

247
00:12:26,950 --> 00:12:36,339
level we tuned each algorithm and then

248
00:12:32,700 --> 00:12:38,170
report the mean accuracy and standard

249
00:12:36,339 --> 00:12:40,500
deviation over ten independent runs we

250
00:12:38,170 --> 00:12:43,030
report the accuracy over the test set

251
00:12:40,500 --> 00:12:46,410
note that the steering does not apply to

252
00:12:43,030 --> 00:12:46,410
high-priority free

253
00:12:48,559 --> 00:12:54,289
so let's start by looking at the results

254
00:12:50,949 --> 00:12:56,089
so here what I'm showing is the results

255
00:12:54,289 --> 00:12:59,829
on the synthetic data set that is

256
00:12:56,089 --> 00:13:02,719
low-dimensional on the x-axis you have

257
00:12:59,829 --> 00:13:06,258
epsilon which goes from a very high

258
00:13:02,719 --> 00:13:08,449
privacy level to a lower level on the

259
00:13:06,259 --> 00:13:11,749
y-axis you have the accuracy of the test

260
00:13:08,449 --> 00:13:14,478
set the blue plot on the top represents

261
00:13:11,749 --> 00:13:16,999
the non private baseline and it's

262
00:13:14,479 --> 00:13:19,609
difficult to see the different

263
00:13:16,999 --> 00:13:25,789
algorithms in this plot as they're very

264
00:13:19,609 --> 00:13:28,119
crowded together next I'll show results

265
00:13:25,789 --> 00:13:33,259
for high dimensional synthetic data set

266
00:13:28,119 --> 00:13:34,819
here what we do is we generate data that

267
00:13:33,259 --> 00:13:38,599
is actually low rank but high

268
00:13:34,819 --> 00:13:41,179
dimensional and here we see that private

269
00:13:38,599 --> 00:13:44,209
Frank wolf which is the pink plot

270
00:13:41,179 --> 00:13:46,999
performs it beats the other algorithms

271
00:13:44,209 --> 00:13:49,429
by wide margin and one of the reasons is

272
00:13:46,999 --> 00:13:54,470
it is designed to operate well on sparse

273
00:13:49,429 --> 00:13:56,749
data and over these two data sets is

274
00:13:54,470 --> 00:14:02,629
where we tune hyper parameter free amp

275
00:13:56,749 --> 00:14:05,089
which is the green plot so next I'll

276
00:14:02,629 --> 00:14:07,609
show some of the results on high

277
00:14:05,089 --> 00:14:12,649
dimensional data sets namely real sim

278
00:14:07,609 --> 00:14:14,839
and RC v1 here is where it is clearer

279
00:14:12,649 --> 00:14:17,299
that both variants of amp even the hyper

280
00:14:14,839 --> 00:14:19,849
parameter free version performs better

281
00:14:17,299 --> 00:14:23,059
than all the other tuned algorithms so

282
00:14:19,849 --> 00:14:25,069
the orange plot denotes amp and the

283
00:14:23,059 --> 00:14:28,759
green one denotes happy parameter free

284
00:14:25,069 --> 00:14:31,419
amp and they almost always provide the

285
00:14:28,759 --> 00:14:31,419
best performance

286
00:14:33,480 --> 00:14:39,690
next are some results on real-world use

287
00:14:36,150 --> 00:14:42,660
cases where these are large data sets

288
00:14:39,690 --> 00:14:45,750
they have millions of samples and the

289
00:14:42,660 --> 00:14:47,610
first observation here is that many

290
00:14:45,750 --> 00:14:49,530
works many prior works have theorized

291
00:14:47,610 --> 00:14:50,250
that differential privacy can act as a

292
00:14:49,530 --> 00:14:55,199
regularizer

293
00:14:50,250 --> 00:14:56,880
and in dataset one we see that the best

294
00:14:55,200 --> 00:14:59,670
algorithms the best private algorithms

295
00:14:56,880 --> 00:15:02,730
almost always outperform the non private

296
00:14:59,670 --> 00:15:05,339
one also notice that since we have

297
00:15:02,730 --> 00:15:07,920
millions of samples that the x-axis the

298
00:15:05,340 --> 00:15:10,490
range of the x-axis changes on data set

299
00:15:07,920 --> 00:15:14,839
one it's just one twentieth of a percent

300
00:15:10,490 --> 00:15:19,860
whereas it's it's still pretty much

301
00:15:14,840 --> 00:15:22,820
small in the other data set we also see

302
00:15:19,860 --> 00:15:27,510
that all algorithms basically show a

303
00:15:22,820 --> 00:15:29,310
smaller variance and the accuracy of amp

304
00:15:27,510 --> 00:15:30,780
is very close to the non private

305
00:15:29,310 --> 00:15:36,449
baseline even for the lowest privacy

306
00:15:30,780 --> 00:15:40,280
level be considered so I'd like to

307
00:15:36,450 --> 00:15:42,510
conclude by giving a summary one

308
00:15:40,280 --> 00:15:43,860
observation in our study that we show

309
00:15:42,510 --> 00:15:45,300
through our experiments is that if you

310
00:15:43,860 --> 00:15:48,540
have a large data set the cost of

311
00:15:45,300 --> 00:15:50,640
privacy is very low we also see that amp

312
00:15:48,540 --> 00:15:52,290
almost always provides the best accuracy

313
00:15:50,640 --> 00:15:55,410
and it is designed to be easily

314
00:15:52,290 --> 00:15:57,270
deployable in practice in addition to

315
00:15:55,410 --> 00:15:58,500
this it also has a hyper parameter free

316
00:15:57,270 --> 00:16:01,110
variant which is end-to-end

317
00:15:58,500 --> 00:16:03,720
differentially private and it is

318
00:16:01,110 --> 00:16:05,570
competitive with the tuned versions of

319
00:16:03,720 --> 00:16:09,150
the state-of-the-art algorithms and

320
00:16:05,570 --> 00:16:11,250
finally we open source our benchmark and

321
00:16:09,150 --> 00:16:14,189
our code it's available on the following

322
00:16:11,250 --> 00:16:16,790
link with that thank you for your time

323
00:16:14,190 --> 00:16:20,990
and I'd be happy to take questions

324
00:16:16,790 --> 00:16:25,949
[Applause]

325
00:16:20,990 --> 00:16:28,230
we have any questions thanks for the

326
00:16:25,950 --> 00:16:30,240
great talk sorry this might be a naive

327
00:16:28,230 --> 00:16:31,980
question because I'm not an expert on

328
00:16:30,240 --> 00:16:34,649
differential privacy but I was just

329
00:16:31,980 --> 00:16:38,060
wondering that so what makes the

330
00:16:34,649 --> 00:16:43,290
decision of the absolute value of 0.01

331
00:16:38,060 --> 00:16:46,619
kind of adequate for for privacy so it

332
00:16:43,290 --> 00:16:49,050
is majorly a policy decision as what

333
00:16:46,620 --> 00:16:50,790
epsilon value you should use it should

334
00:16:49,050 --> 00:16:54,930
depend on the sensitivity of the data

335
00:16:50,790 --> 00:16:56,969
itself for some tasks value like 1 or 5

336
00:16:54,930 --> 00:16:59,099
might be reasonable for some sensitive

337
00:16:56,970 --> 00:17:01,709
tasks a lower value might be reasonable

338
00:16:59,100 --> 00:17:04,559
what we tried to show is that for

339
00:17:01,709 --> 00:17:07,139
basically the range of values that we've

340
00:17:04,559 --> 00:17:09,030
seen in the literature so it's very rare

341
00:17:07,140 --> 00:17:13,370
to see even epsilon as low as point 0 1

342
00:17:09,030 --> 00:17:18,050
so we just show that how the privacy

343
00:17:13,369 --> 00:17:20,129
accounts for in this in this region so

344
00:17:18,050 --> 00:17:22,530
thanks for the answer I have a follow-up

345
00:17:20,130 --> 00:17:24,569
question so in the case where you have a

346
00:17:22,530 --> 00:17:26,760
real world data set like the Wilber Dale

347
00:17:24,569 --> 00:17:29,010
said there are only two classes right

348
00:17:26,760 --> 00:17:31,980
for the classification task so in that

349
00:17:29,010 --> 00:17:35,010
case even for epsilon equals 0.01 isn't

350
00:17:31,980 --> 00:17:37,710
that just having two classes make it

351
00:17:35,010 --> 00:17:39,210
easy to distinguish the two cases where

352
00:17:37,710 --> 00:17:43,290
you have two two different data sets

353
00:17:39,210 --> 00:17:45,929
that its neighboring so even though

354
00:17:43,290 --> 00:17:50,040
there are two classes the guarantee

355
00:17:45,929 --> 00:17:52,410
holds over the complete sample so if you

356
00:17:50,040 --> 00:17:54,480
notice the each sample has a lot of

357
00:17:52,410 --> 00:17:56,160
features hundreds of features and the

358
00:17:54,480 --> 00:17:58,500
privacy guarantee holds whether a

359
00:17:56,160 --> 00:18:01,230
particular vector is within the data set

360
00:17:58,500 --> 00:18:04,050
or not and so in addition to the class

361
00:18:01,230 --> 00:18:08,880
we also give privacy to the values of

362
00:18:04,050 --> 00:18:11,270
the features themselves any other

363
00:18:08,880 --> 00:18:11,270
questions

364
00:18:15,820 --> 00:18:20,530
so you'll mentioned there are four steps

365
00:18:17,950 --> 00:18:22,360
in your approach and you mentioned the

366
00:18:20,530 --> 00:18:24,850
second step is similar to some existing

367
00:18:22,360 --> 00:18:25,360
techniques and the last one is just add

368
00:18:24,850 --> 00:18:27,639
noise

369
00:18:25,360 --> 00:18:29,139
so what's intuition here that your

370
00:18:27,640 --> 00:18:31,600
approach is better than all those

371
00:18:29,140 --> 00:18:33,220
optimized for specific you know those

372
00:18:31,600 --> 00:18:36,250
techniques Ultimates were specific tasks

373
00:18:33,220 --> 00:18:39,190
you know why was the magic here that's a

374
00:18:36,250 --> 00:18:41,140
very good question so two of the

375
00:18:39,190 --> 00:18:43,390
techniques that are output perturbation

376
00:18:41,140 --> 00:18:46,480
and objective perturbation they have

377
00:18:43,390 --> 00:18:48,580
really good utility guarantees but the

378
00:18:46,480 --> 00:18:51,520
privacy holds only if you release the

379
00:18:48,580 --> 00:18:54,309
exact minimizer so if you manage to

380
00:18:51,520 --> 00:18:57,429
reach the minimizer and release it you

381
00:18:54,309 --> 00:19:00,549
get great guarantees in practice that's

382
00:18:57,429 --> 00:19:02,860
never guaranteed so the thought process

383
00:19:00,549 --> 00:19:06,129
here was what if you are very very close

384
00:19:02,860 --> 00:19:09,040
to the actual minima can you get privacy

385
00:19:06,130 --> 00:19:10,059
guarantees for it because if it is close

386
00:19:09,040 --> 00:19:12,668
to the actual minimum I it should

387
00:19:10,059 --> 00:19:15,010
perform well so we add noise in the last

388
00:19:12,669 --> 00:19:18,640
step just to give privacy to that

389
00:19:15,010 --> 00:19:23,129
approximate minima that that's the high

390
00:19:18,640 --> 00:19:23,130
level review Thanks

391
00:19:29,740 --> 00:19:37,080
hi I have question is do you use

392
00:19:33,550 --> 00:19:39,510
convexity of a objective function in

393
00:19:37,080 --> 00:19:43,210
privacy guarantee or utility alert

394
00:19:39,510 --> 00:19:47,110
that's a very great question so the

395
00:19:43,210 --> 00:19:49,770
privacy guarantees will depend here like

396
00:19:47,110 --> 00:19:53,949
you require some properties like

397
00:19:49,770 --> 00:19:57,520
smoothness and basically it's not

398
00:19:53,950 --> 00:19:59,650
required for utility it is for the

399
00:19:57,520 --> 00:20:03,040
privacy you need some other guarantees

400
00:19:59,650 --> 00:20:06,760
to hold but you'll be fine if you have

401
00:20:03,040 --> 00:20:10,320
like smoothness and strong yeah it's

402
00:20:06,760 --> 00:20:10,320
it's mostly for their utility guarantees

403
00:20:11,010 --> 00:20:17,250
any final questions okay last question

404
00:20:17,340 --> 00:20:22,480
hi a very nice talk have you evaluated

405
00:20:20,440 --> 00:20:23,230
against any of the attacks that you

406
00:20:22,480 --> 00:20:25,830
mentioned in the beginning like

407
00:20:23,230 --> 00:20:30,220
membership inference or modeling version

408
00:20:25,830 --> 00:20:32,770
so so basically what the notion of

409
00:20:30,220 --> 00:20:35,170
differential privacy gives you is a

410
00:20:32,770 --> 00:20:38,320
guarantee that you can avoid influence

411
00:20:35,170 --> 00:20:40,780
for example and how much the attack will

412
00:20:38,320 --> 00:20:41,530
be successful will depend on the level

413
00:20:40,780 --> 00:20:44,260
of Epsilon

414
00:20:41,530 --> 00:20:46,030
so basically inference is whether an

415
00:20:44,260 --> 00:20:47,470
adversary can distinguish whether a

416
00:20:46,030 --> 00:20:49,690
sample is there or not and differential

417
00:20:47,470 --> 00:20:53,410
privacy is a mathematical guarantee to

418
00:20:49,690 --> 00:20:55,570
prevent precisely that so I think other

419
00:20:53,410 --> 00:20:58,570
papers that concentrate on the attacks

420
00:20:55,570 --> 00:21:04,870
do carry on evaluation we have not

421
00:20:58,570 --> 00:21:06,550
carried that to that question the

422
00:21:04,870 --> 00:21:09,070
differential privacy guarantees on the

423
00:21:06,550 --> 00:21:11,350
output does not vary too much but

424
00:21:09,070 --> 00:21:14,260
inference membership inference or the

425
00:21:11,350 --> 00:21:16,510
other inferences are guarantees on the

426
00:21:14,260 --> 00:21:19,210
input so can you actually relate those

427
00:21:16,510 --> 00:21:22,840
two so the guarantees are you cannot

428
00:21:19,210 --> 00:21:24,670
deduce anything about the input from the

429
00:21:22,840 --> 00:21:26,169
guarantee itself just says that the

430
00:21:24,670 --> 00:21:27,460
output cannot vary but it doesn't say

431
00:21:26,170 --> 00:21:31,510
anything about what it can infer about

432
00:21:27,460 --> 00:21:34,210
the input it's precisely that from

433
00:21:31,510 --> 00:21:37,690
seeing the output you cannot deduce much

434
00:21:34,210 --> 00:21:38,559
about the input samples so if you

435
00:21:37,690 --> 00:21:40,720
observe the output

436
00:21:38,559 --> 00:21:42,710
you cannot confidently say whether my

437
00:21:40,720 --> 00:21:44,630
sample was in the data set or not

438
00:21:42,710 --> 00:21:45,919
so this isn't this is this is more than

439
00:21:44,630 --> 00:21:47,870
just that the original differential

440
00:21:45,919 --> 00:21:49,460
privacy definition that you're sort of

441
00:21:47,870 --> 00:21:50,750
inferring a little bit more from from

442
00:21:49,460 --> 00:21:53,659
that no this is this is exactly the

443
00:21:50,750 --> 00:21:57,050
maybe I'll talk to you after yep let's

444
00:21:53,659 --> 00:22:00,270
think on one more time thank you

445
00:21:57,050 --> 00:22:00,270
[Applause]

