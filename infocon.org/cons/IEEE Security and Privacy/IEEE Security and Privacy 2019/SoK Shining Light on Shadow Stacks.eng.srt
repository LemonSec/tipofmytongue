1
00:00:08,600 --> 00:00:13,040
okay and thank you miss for that enter

2
00:00:15,170 --> 00:00:20,570
we were both hit Purdue and of course

3
00:00:17,030 --> 00:00:22,369
Matthias who is now at EPFL so this talk

4
00:00:20,570 --> 00:00:25,160
is going to be concerned with mitigating

5
00:00:22,369 --> 00:00:27,259
control flow hijacking so at blue hat

6
00:00:25,160 --> 00:00:29,570
this year Microsoft made the interesting

7
00:00:27,260 --> 00:00:31,640
disclosure that 70% of their bugs are

8
00:00:29,570 --> 00:00:34,340
still memory corruption vulnerabilities

9
00:00:31,640 --> 00:00:36,170
and these bugs are interesting because

10
00:00:34,340 --> 00:00:37,910
the control and data planes are

11
00:00:36,170 --> 00:00:40,309
interleaved as I sort of have a little

12
00:00:37,910 --> 00:00:42,589
illustration here where the gray cells

13
00:00:40,309 --> 00:00:44,780
are data and the green cells are the

14
00:00:42,590 --> 00:00:47,090
code pointers so you can imagine that if

15
00:00:44,780 --> 00:00:49,220
you have a memory corruption in your

16
00:00:47,090 --> 00:00:51,979
data it can overflow into a code pointer

17
00:00:49,220 --> 00:00:54,500
which allows an adversary to redirect

18
00:00:51,979 --> 00:00:56,629
the control flow of your application so

19
00:00:54,500 --> 00:00:58,790
we would really like is a defense that

20
00:00:56,629 --> 00:01:00,409
allows us to at least logically separate

21
00:00:58,790 --> 00:01:04,220
the control and data planes as

22
00:01:00,409 --> 00:01:06,979
illustrated here so when thinking about

23
00:01:04,220 --> 00:01:08,960
code pointers which are the subject of

24
00:01:06,979 --> 00:01:11,179
attack for these control flow hijackings

25
00:01:08,960 --> 00:01:11,869
they sort of come in to two different

26
00:01:11,180 --> 00:01:13,970
varieties

27
00:01:11,869 --> 00:01:16,820
first there are forward edge pointers

28
00:01:13,970 --> 00:01:19,548
these are function pointers or virtual

29
00:01:16,820 --> 00:01:21,500
calls in C++ there's a well known

30
00:01:19,549 --> 00:01:23,930
defense for these called control flow

31
00:01:21,500 --> 00:01:26,479
integrity that works by statically

32
00:01:23,930 --> 00:01:28,490
calculating target sets to limit where

33
00:01:26,479 --> 00:01:30,890
these indirect calls can go in practice

34
00:01:28,490 --> 00:01:33,020
so to see how this works consider a

35
00:01:30,890 --> 00:01:34,549
function pointer that's being used to

36
00:01:33,020 --> 00:01:37,009
make an indirect function call and

37
00:01:34,549 --> 00:01:39,530
without any defense it can target every

38
00:01:37,009 --> 00:01:41,929
executable byte in the program but when

39
00:01:39,530 --> 00:01:44,960
you apply CFI analysis you restrict this

40
00:01:41,929 --> 00:01:48,590
to some limited set of functions within

41
00:01:44,960 --> 00:01:50,600
the program this analysis runs into some

42
00:01:48,590 --> 00:01:52,520
trouble because there can be a wide gap

43
00:01:50,600 --> 00:01:54,619
between when a function pointer is

44
00:01:52,520 --> 00:01:55,219
written and when it is actually used for

45
00:01:54,619 --> 00:01:57,140
the call

46
00:01:55,219 --> 00:01:59,240
which means you run into all sorts of

47
00:01:57,140 --> 00:02:02,270
the typical static analysis problems

48
00:01:59,240 --> 00:02:04,520
with alias analysis etc trying to

49
00:02:02,270 --> 00:02:06,048
connect the exact set of function

50
00:02:04,520 --> 00:02:12,049
pointer rights that might flow to a

51
00:02:06,049 --> 00:02:15,470
given indirect call site the next class

52
00:02:12,050 --> 00:02:17,170
of code pointers are backwards edge and

53
00:02:15,470 --> 00:02:19,819
in particular these are return

54
00:02:17,170 --> 00:02:23,000
instructions so a natural question is

55
00:02:19,819 --> 00:02:25,970
does CFI analysis style style analysis

56
00:02:23,000 --> 00:02:27,409
work on the backwards edge and so you

57
00:02:25,970 --> 00:02:28,080
know it's the same sort of setup you

58
00:02:27,409 --> 00:02:30,510
have a return

59
00:02:28,080 --> 00:02:32,910
destruction and we where can it go - and

60
00:02:30,510 --> 00:02:34,560
the answer is of course you know every

61
00:02:32,910 --> 00:02:35,910
call site in the function that might you

62
00:02:34,560 --> 00:02:37,980
know called the function that you're

63
00:02:35,910 --> 00:02:40,680
returning from and so the answer is

64
00:02:37,980 --> 00:02:43,109
really no CFI style analysis does not

65
00:02:40,680 --> 00:02:45,150
work for the backwards edge and the

66
00:02:43,110 --> 00:02:46,860
reason is that because you have to

67
00:02:45,150 --> 00:02:48,570
include every call site for the function

68
00:02:46,860 --> 00:02:50,940
if you're doing static analysis and the

69
00:02:48,570 --> 00:02:52,739
target set you end up with these huge

70
00:02:50,940 --> 00:02:55,620
target sets potentially for especially

71
00:02:52,740 --> 00:02:57,990
for popular say library functions and as

72
00:02:55,620 --> 00:03:00,120
control flow bending and control jujitsu

73
00:02:57,990 --> 00:03:01,770
have shown the larger these target sets

74
00:03:00,120 --> 00:03:04,230
get the more insecure they are in

75
00:03:01,770 --> 00:03:06,750
practice and so we feel strongly that

76
00:03:04,230 --> 00:03:08,790
for backwards edges these sets are too

77
00:03:06,750 --> 00:03:11,640
large to provide meaningful security and

78
00:03:08,790 --> 00:03:14,090
practice and that doing security really

79
00:03:11,640 --> 00:03:19,260
requires integrity for return addresses

80
00:03:14,090 --> 00:03:20,970
and so yes so sort of to sum up the

81
00:03:19,260 --> 00:03:24,899
state of control flow hijacking

82
00:03:20,970 --> 00:03:27,120
mitigation today over the past 10 years

83
00:03:24,900 --> 00:03:29,640
there have been 50-plus papers on

84
00:03:27,120 --> 00:03:31,650
control flow hijacking dating back to a

85
00:03:29,640 --> 00:03:33,470
body at all seminal paper which did

86
00:03:31,650 --> 00:03:35,910
include a call for a shadow stack

87
00:03:33,470 --> 00:03:38,609
unfortunately subsequent research lost

88
00:03:35,910 --> 00:03:41,220
focus on this and only paid attention to

89
00:03:38,610 --> 00:03:42,630
the forward edge problem which means

90
00:03:41,220 --> 00:03:44,850
that now that we are getting deployed

91
00:03:42,630 --> 00:03:47,970
versions of CFI by microsoft and google

92
00:03:44,850 --> 00:03:50,160
they only cover the forward edge and we

93
00:03:47,970 --> 00:03:51,570
have no equally strong protection for

94
00:03:50,160 --> 00:03:55,859
the backwards edges that is being

95
00:03:51,570 --> 00:03:57,930
deployed today and so our solution to

96
00:03:55,860 --> 00:03:59,489
this is shadow sacks this is a

97
00:03:57,930 --> 00:04:01,620
well-known research area which is why

98
00:03:59,489 --> 00:04:03,150
we're writing an SOP on it trying to

99
00:04:01,620 --> 00:04:04,709
promote awareness to get people to

100
00:04:03,150 --> 00:04:07,140
actually deploy shadow stacks in

101
00:04:04,709 --> 00:04:09,090
practice shadow stacks work by

102
00:04:07,140 --> 00:04:11,040
separating return addresses from the

103
00:04:09,090 --> 00:04:13,680
data plane which allows us to provide

104
00:04:11,040 --> 00:04:16,048
integrity for the return addresses and

105
00:04:13,680 --> 00:04:18,478
it turns out that these are performant

106
00:04:16,048 --> 00:04:20,010
and highly compatible in practice and so

107
00:04:18,478 --> 00:04:22,048
the punchline here is that we need to

108
00:04:20,010 --> 00:04:23,520
deploy shadow stacks with control flow

109
00:04:22,048 --> 00:04:25,020
integrity to have the complete

110
00:04:23,520 --> 00:04:29,159
mitigation against control flow

111
00:04:25,020 --> 00:04:31,380
hijacking attacks so to illustrate why

112
00:04:29,160 --> 00:04:33,240
we need shadow stacks I'm going to go

113
00:04:31,380 --> 00:04:35,760
through a control flow hijacking attack

114
00:04:33,240 --> 00:04:38,039
in a little bit of detail here here we

115
00:04:35,760 --> 00:04:40,570
see the program stack with one stack

116
00:04:38,039 --> 00:04:42,849
frame it has the return address

117
00:04:40,570 --> 00:04:45,099
a stack canary stack Canaries are the

118
00:04:42,850 --> 00:04:47,320
strongest currently deployed protection

119
00:04:45,100 --> 00:04:50,680
for return addresses that are designed

120
00:04:47,320 --> 00:04:52,510
to present you know splashing the stack

121
00:04:50,680 --> 00:04:55,210
for fun and profit style attacks that

122
00:04:52,510 --> 00:04:58,120
use a contiguous buffer overflow to

123
00:04:55,210 --> 00:04:59,770
directly overwrite the return address so

124
00:04:58,120 --> 00:05:01,690
if you put the stack canary which is the

125
00:04:59,770 --> 00:05:03,010
sort of magic value in the middle and

126
00:05:01,690 --> 00:05:04,690
you can then see if it's been

127
00:05:03,010 --> 00:05:07,960
overwritten and if it's been directly

128
00:05:04,690 --> 00:05:10,120
overwritten you can detect an attack so

129
00:05:07,960 --> 00:05:12,729
also on the stack frame here I'm I've

130
00:05:10,120 --> 00:05:14,350
put in a pointer and an array so as you

131
00:05:12,730 --> 00:05:16,390
might imagine we're going to write to

132
00:05:14,350 --> 00:05:18,220
the array and eventually our buffer

133
00:05:16,390 --> 00:05:20,289
overflow is going to happen which allows

134
00:05:18,220 --> 00:05:22,480
the attacker to control the value of a

135
00:05:20,290 --> 00:05:24,400
pointer if there is subsequently an

136
00:05:22,480 --> 00:05:27,250
attacker controlled right through this

137
00:05:24,400 --> 00:05:29,560
pointer the attacker can bypass the

138
00:05:27,250 --> 00:05:31,630
stack canary entirely and directly

139
00:05:29,560 --> 00:05:34,240
overwrite the return address say

140
00:05:31,630 --> 00:05:35,710
changing it to a pointer to a rob gadget

141
00:05:34,240 --> 00:05:38,730
or you know at the beginning of a sled

142
00:05:35,710 --> 00:05:41,770
of such gadgets to perform their attack

143
00:05:38,730 --> 00:05:43,960
so what is the shadow stack a shadow

144
00:05:41,770 --> 00:05:46,030
stack is a way of as I mentioned

145
00:05:43,960 --> 00:05:48,609
separating the return addresses from the

146
00:05:46,030 --> 00:05:50,559
normal program stack so here we can see

147
00:05:48,610 --> 00:05:53,170
the program stack which has a collection

148
00:05:50,560 --> 00:05:54,760
of stack frames on it or call frames on

149
00:05:53,170 --> 00:05:56,470
it for the different functions which

150
00:05:54,760 --> 00:05:58,240
include the return address and any

151
00:05:56,470 --> 00:06:00,970
information needed for local variables

152
00:05:58,240 --> 00:06:02,440
etc and on the shadow stack what we're

153
00:06:00,970 --> 00:06:05,200
going to do is pull out the return

154
00:06:02,440 --> 00:06:06,790
information so that it is separate and

155
00:06:05,200 --> 00:06:10,090
you know not subject to these buffer

156
00:06:06,790 --> 00:06:12,430
overflows etc so to see how this defense

157
00:06:10,090 --> 00:06:15,219
works we'll return to our previous

158
00:06:12,430 --> 00:06:16,690
example here where we're midway through

159
00:06:15,220 --> 00:06:18,820
it so the attacker has already written

160
00:06:16,690 --> 00:06:20,469
over written the return address but now

161
00:06:18,820 --> 00:06:22,990
instead of returning and using this

162
00:06:20,470 --> 00:06:26,260
attacker controlled value we instead

163
00:06:22,990 --> 00:06:28,150
compared the program return the return

164
00:06:26,260 --> 00:06:30,070
address on the program stack to the

165
00:06:28,150 --> 00:06:32,590
shadow return address and if they

166
00:06:30,070 --> 00:06:34,719
mismatch we can detect an attack and we

167
00:06:32,590 --> 00:06:38,020
can take any action we like in response

168
00:06:34,720 --> 00:06:39,610
to this typically people just terminate

169
00:06:38,020 --> 00:06:43,419
the program but you can imagine more

170
00:06:39,610 --> 00:06:45,640
sophisticated recovery policies so the

171
00:06:43,420 --> 00:06:47,620
key advantages of shadow stacks are that

172
00:06:45,640 --> 00:06:49,690
you know at runtime what function you

173
00:06:47,620 --> 00:06:52,300
were called from which means that we can

174
00:06:49,690 --> 00:06:54,360
move from the static style of CFI

175
00:06:52,300 --> 00:06:57,399
defenses that are trying to pre-compute

176
00:06:54,360 --> 00:07:00,459
target sets to a more dynamic defense

177
00:06:57,399 --> 00:07:02,769
that is focused on remembering the

178
00:07:00,459 --> 00:07:04,869
return addresses correctly so there's no

179
00:07:02,769 --> 00:07:08,050
guessing or pre calculation required

180
00:07:04,869 --> 00:07:10,209
here simply by separating the code and

181
00:07:08,050 --> 00:07:12,129
data planes for backwards edges we end

182
00:07:10,209 --> 00:07:14,529
up with this very strong defense for

183
00:07:12,129 --> 00:07:16,389
return addresses and in particular it's

184
00:07:14,529 --> 00:07:18,519
fully precise again because of this

185
00:07:16,389 --> 00:07:20,379
dynamic nature of the information where

186
00:07:18,519 --> 00:07:21,580
the call happens before the return so

187
00:07:20,379 --> 00:07:23,499
you know where you're supposed to return

188
00:07:21,580 --> 00:07:28,269
to if you can only preserve that

189
00:07:23,499 --> 00:07:30,429
information in the program so here this

190
00:07:28,269 --> 00:07:32,319
is an S okay so I'm going to briefly

191
00:07:30,429 --> 00:07:34,869
introduce the shadow stack design space

192
00:07:32,319 --> 00:07:37,269
before moving to our recommended shadow

193
00:07:34,869 --> 00:07:40,479
stack for deployment so there are two

194
00:07:37,269 --> 00:07:43,300
main methods of mapping from the program

195
00:07:40,479 --> 00:07:45,789
stack to the shadow stack starting with

196
00:07:43,300 --> 00:07:48,579
on the right side of the screen here the

197
00:07:45,789 --> 00:07:51,188
indirect mapping so here you are

198
00:07:48,579 --> 00:07:53,289
maintaining two stacks which means that

199
00:07:51,189 --> 00:07:55,239
for every call instruction which pushes

200
00:07:53,289 --> 00:07:57,519
the return address to the program stack

201
00:07:55,239 --> 00:07:59,558
you have to add instrumentation to also

202
00:07:57,519 --> 00:08:02,050
push the return address to the shadow

203
00:07:59,559 --> 00:08:03,849
stack and similarly for returns you're

204
00:08:02,050 --> 00:08:06,550
going to get two pops because you're

205
00:08:03,849 --> 00:08:08,139
maintaining two logical stacks the

206
00:08:06,550 --> 00:08:10,629
advantage of this approach is that your

207
00:08:08,139 --> 00:08:12,519
shadow stack is very small it only has

208
00:08:10,629 --> 00:08:14,949
to be as large as needed to store the

209
00:08:12,519 --> 00:08:16,959
return addresses and maybe the stack

210
00:08:14,949 --> 00:08:20,259
pointers to support recursion and so

211
00:08:16,959 --> 00:08:22,479
forth the alternate scheme is direct

212
00:08:20,259 --> 00:08:24,249
mappings so here you're only maintaining

213
00:08:22,479 --> 00:08:25,748
one logical stack there's only the

214
00:08:24,249 --> 00:08:27,969
program stack that you're going to push

215
00:08:25,749 --> 00:08:30,309
to and pop from but you're going to

216
00:08:27,969 --> 00:08:32,620
create a shadow stack that is as large

217
00:08:30,309 --> 00:08:34,689
as the program stack which means there's

218
00:08:32,620 --> 00:08:36,969
a direct one-to-one mapping or

219
00:08:34,688 --> 00:08:39,098
correspondence or mirroring from the

220
00:08:36,969 --> 00:08:41,560
program stack to the shadow stack so

221
00:08:39,099 --> 00:08:43,419
given any byte in the program stack you

222
00:08:41,559 --> 00:08:45,790
do a little bit of arithmetic to say add

223
00:08:43,419 --> 00:08:48,310
a constant and you directly arrive at

224
00:08:45,790 --> 00:08:50,829
the relevant shadow stack address which

225
00:08:48,310 --> 00:08:53,079
means that once you push to the the

226
00:08:50,829 --> 00:08:54,638
return address to the program stack it's

227
00:08:53,079 --> 00:08:56,349
very natural to propagate it to the

228
00:08:54,639 --> 00:08:59,040
shadow stack without having to do this

229
00:08:56,350 --> 00:09:02,410
additional data structure maintenance

230
00:08:59,040 --> 00:09:04,360
the so this is sort of trying to do a

231
00:09:02,410 --> 00:09:06,459
performance versus memory trade-off

232
00:09:04,360 --> 00:09:07,290
where you're trading the extra memory of

233
00:09:06,459 --> 00:09:09,030
allocating

234
00:09:07,290 --> 00:09:11,130
the shadow stack that is as large as the

235
00:09:09,030 --> 00:09:12,660
program stack but hoping to get better

236
00:09:11,130 --> 00:09:15,020
performance because the mapping is

237
00:09:12,660 --> 00:09:15,020
simpler

238
00:09:15,150 --> 00:09:19,860
so our recommended shadow stack turns

239
00:09:17,190 --> 00:09:21,840
out to be an indirect mapping that uses

240
00:09:19,860 --> 00:09:24,150
a general-purpose registered to shore

241
00:09:21,840 --> 00:09:27,390
this to store the shadow stack pointer

242
00:09:24,150 --> 00:09:30,390
and we find that this leads to optimal

243
00:09:27,390 --> 00:09:32,310
performance in terms of both processing

244
00:09:30,390 --> 00:09:34,350
time and memory use and high

245
00:09:32,310 --> 00:09:38,160
compatibility and I'll now walk through

246
00:09:34,350 --> 00:09:41,490
why this turns out to be so so for the

247
00:09:38,160 --> 00:09:43,620
mapping the indirect mapping to evaluate

248
00:09:41,490 --> 00:09:45,810
this we took all existing techniques and

249
00:09:43,620 --> 00:09:47,910
a for shadow stacks and a couple more

250
00:09:45,810 --> 00:09:50,969
that we identified as missing during our

251
00:09:47,910 --> 00:09:53,010
survey we implemented them all in LV m7

252
00:09:50,970 --> 00:09:55,530
and went and did some quantitative

253
00:09:53,010 --> 00:09:58,170
analysis and found that when using a

254
00:09:55,530 --> 00:10:01,260
general purpose register the indirect

255
00:09:58,170 --> 00:10:04,199
mapping can be as performant as a direct

256
00:10:01,260 --> 00:10:06,569
mapping and because it also saves memory

257
00:10:04,200 --> 00:10:08,190
space obviously we go for this because

258
00:10:06,570 --> 00:10:09,960
it's a rare case of having our cake and

259
00:10:08,190 --> 00:10:11,490
eating it too because the fastest

260
00:10:09,960 --> 00:10:15,480
mapping also has the lowest memory

261
00:10:11,490 --> 00:10:17,040
overhead so as I mentioned we're

262
00:10:15,480 --> 00:10:18,810
recommending using a general purpose

263
00:10:17,040 --> 00:10:21,390
register for the shadow stack pointer

264
00:10:18,810 --> 00:10:22,920
during there's been lots of discussion

265
00:10:21,390 --> 00:10:24,569
about you know does this lead to

266
00:10:22,920 --> 00:10:26,430
increased register pressure is this

267
00:10:24,570 --> 00:10:28,860
going to be terrible for performance and

268
00:10:26,430 --> 00:10:31,439
the answer turns out to be no that on

269
00:10:28,860 --> 00:10:33,870
64-bit architectures which have 16

270
00:10:31,440 --> 00:10:36,450
general-purpose registers all

271
00:10:33,870 --> 00:10:39,840
applications we evaluated not only the

272
00:10:36,450 --> 00:10:42,090
spec CPU 2006 benchmarks but also a wide

273
00:10:39,840 --> 00:10:44,400
variety of image processing and other

274
00:10:42,090 --> 00:10:46,710
desktop applications from fir onyx as

275
00:10:44,400 --> 00:10:48,600
well as the engine Dex web server there

276
00:10:46,710 --> 00:10:50,280
was no you know huge performance hit

277
00:10:48,600 --> 00:10:53,580
from using a general purpose register

278
00:10:50,280 --> 00:10:55,170
and in fact it was the fastest scheme so

279
00:10:53,580 --> 00:10:56,820
the takeaway here is the dedicating a

280
00:10:55,170 --> 00:10:59,430
register to the shadow stack pointer is

281
00:10:56,820 --> 00:11:03,140
actually an infective optimization

282
00:10:59,430 --> 00:11:06,689
across a very wide range of applications

283
00:11:03,140 --> 00:11:08,790
so the last issue here is compatibility

284
00:11:06,690 --> 00:11:11,310
which we evaluated along three

285
00:11:08,790 --> 00:11:13,170
dimensions the first is support for

286
00:11:11,310 --> 00:11:15,359
threading so of course every thread in

287
00:11:13,170 --> 00:11:16,920
the program has its own stack and you

288
00:11:15,360 --> 00:11:20,660
need to have be able to support a shadow

289
00:11:16,920 --> 00:11:22,459
stack or program thread as well you

290
00:11:20,660 --> 00:11:24,920
a general purpose register to sword the

291
00:11:22,459 --> 00:11:26,300
shadow stack pointer this is very

292
00:11:24,920 --> 00:11:28,910
natural because general purpose

293
00:11:26,300 --> 00:11:31,310
registers are thread-local and so each

294
00:11:28,910 --> 00:11:32,779
you know thread has its own copy of this

295
00:11:31,310 --> 00:11:34,279
which points us to the relevant shadow

296
00:11:32,779 --> 00:11:37,459
stack for that thread and everything

297
00:11:34,279 --> 00:11:41,779
works nicely the next issue is stack

298
00:11:37,459 --> 00:11:43,399
unwinding which is mainly used for C++

299
00:11:41,779 --> 00:11:45,740
exception handling although there are

300
00:11:43,399 --> 00:11:48,290
some other uses the interesting thing

301
00:11:45,740 --> 00:11:50,779
here is that calls and returns are no

302
00:11:48,290 --> 00:11:52,490
longer a one-to-one correspondence

303
00:11:50,779 --> 00:11:54,379
when you have a leaf function that

304
00:11:52,490 --> 00:11:56,750
throws an exception you might unwind

305
00:11:54,379 --> 00:11:58,189
multiple stack frames and thus you know

306
00:11:56,750 --> 00:12:00,350
have multiple calls that don't have a

307
00:11:58,189 --> 00:12:01,969
matching return because we're directly

308
00:12:00,350 --> 00:12:05,029
going further up the stack until the

309
00:12:01,970 --> 00:12:08,269
exception is handled so this turns out

310
00:12:05,029 --> 00:12:09,949
to be a non-trivial but not

311
00:12:08,269 --> 00:12:11,660
fundamentally interesting engineering

312
00:12:09,949 --> 00:12:13,878
challenge to deal with and we provide an

313
00:12:11,660 --> 00:12:17,029
instrumented version of Lib unwind and

314
00:12:13,879 --> 00:12:19,100
set jump and long jump to handle this

315
00:12:17,029 --> 00:12:20,899
similarly for unprotected code there's

316
00:12:19,100 --> 00:12:23,240
this issue that when you cross the

317
00:12:20,899 --> 00:12:25,610
protection barrier you have to save your

318
00:12:23,240 --> 00:12:27,800
shadow stack pointer and again we

319
00:12:25,610 --> 00:12:29,480
provide a solution for this and so the

320
00:12:27,800 --> 00:12:31,490
punchline again is that we support all

321
00:12:29,480 --> 00:12:33,769
applications and incremental deployment

322
00:12:31,490 --> 00:12:35,660
so we really believe that shadow stacks

323
00:12:33,769 --> 00:12:39,949
are mature enough to start being

324
00:12:35,660 --> 00:12:41,870
deployed with control flow integrity so

325
00:12:39,949 --> 00:12:44,180
we've talked some about separating the

326
00:12:41,870 --> 00:12:45,980
code and data planes and so there's this

327
00:12:44,180 --> 00:12:48,680
interesting question of now that we have

328
00:12:45,980 --> 00:12:51,649
our return addresses in a separate

329
00:12:48,680 --> 00:12:53,630
location can what additional security

330
00:12:51,649 --> 00:12:55,250
can we provide for them and in

331
00:12:53,630 --> 00:12:57,939
particular because they're separated out

332
00:12:55,250 --> 00:13:00,110
we can provide integrity protection

333
00:12:57,939 --> 00:13:01,519
return addresses have this nice property

334
00:13:00,110 --> 00:13:04,040
that they're only supposed to be written

335
00:13:01,519 --> 00:13:05,959
by call instructions which means there's

336
00:13:04,040 --> 00:13:07,759
a very you know narrow window that we

337
00:13:05,959 --> 00:13:10,160
can identify what the correct rights are

338
00:13:07,759 --> 00:13:13,189
that should be allowed in our shadow

339
00:13:10,160 --> 00:13:14,689
stack so to do integrity enforcement on

340
00:13:13,189 --> 00:13:16,599
the shadow stack there are three

341
00:13:14,689 --> 00:13:18,740
techniques that we were able to identify

342
00:13:16,600 --> 00:13:21,829
the first is a software-based

343
00:13:18,740 --> 00:13:24,230
randomization technique unfortunately as

344
00:13:21,829 --> 00:13:25,790
shown by research on ASLR these are

345
00:13:24,230 --> 00:13:28,269
defeasible and practiced through

346
00:13:25,790 --> 00:13:30,769
information leaks and other techniques

347
00:13:28,269 --> 00:13:32,600
so then we looked at two hardware based

348
00:13:30,769 --> 00:13:33,970
schemes that we hoped would provide more

349
00:13:32,600 --> 00:13:36,129
sound protection

350
00:13:33,970 --> 00:13:38,739
good performance overhead this did not

351
00:13:36,129 --> 00:13:40,689
turn out to be the case the first one we

352
00:13:38,739 --> 00:13:43,929
looked at was Intel's memory protection

353
00:13:40,689 --> 00:13:46,539
extensions or MPX this provides hardware

354
00:13:43,929 --> 00:13:49,899
support for doing bounds checking and so

355
00:13:46,539 --> 00:13:53,499
as shown in our previous paper see fix

356
00:13:49,899 --> 00:13:55,299
at nd ss-18 you can turn isolating a

357
00:13:53,499 --> 00:13:57,729
region of process memory into a balanced

358
00:13:55,299 --> 00:14:01,239
checking problem at moderate performance

359
00:13:57,729 --> 00:14:03,129
overhead the newest scheme that we

360
00:14:01,239 --> 00:14:05,470
looked at here has intel's memory

361
00:14:03,129 --> 00:14:07,299
protection keys this is a cool new

362
00:14:05,470 --> 00:14:09,609
hardware feature that allows you to

363
00:14:07,299 --> 00:14:12,699
assign virtual pages or ranges of

364
00:14:09,609 --> 00:14:14,499
virtual pages to one of sixteen groups

365
00:14:12,699 --> 00:14:16,299
they then provide an unprivileged

366
00:14:14,499 --> 00:14:18,549
hardware instruction to toggle the

367
00:14:16,299 --> 00:14:20,319
read/write permissions for all virtual

368
00:14:18,549 --> 00:14:22,929
pages in that group with a single

369
00:14:20,319 --> 00:14:24,909
instruction as opposed to having to do a

370
00:14:22,929 --> 00:14:26,889
in protect call that has a page table

371
00:14:24,909 --> 00:14:30,220
walk-in ends up with huge amounts of

372
00:14:26,889 --> 00:14:32,859
overhead unfortunately when you use the

373
00:14:30,220 --> 00:14:35,409
mpk instructions across the call and

374
00:14:32,859 --> 00:14:37,559
return boundary for whatever reason you

375
00:14:35,409 --> 00:14:39,729
end up with terrible performance

376
00:14:37,559 --> 00:14:42,488
something they've done microarchitecture

377
00:14:39,729 --> 00:14:44,619
only so none of these are really fully

378
00:14:42,489 --> 00:14:47,470
satisfactory we need new hardware

379
00:14:44,619 --> 00:14:49,599
solutions on this issue of doing intra

380
00:14:47,470 --> 00:14:51,789
process memory isolation comes up not

381
00:14:49,599 --> 00:14:53,679
only for shadow stacks but for any

382
00:14:51,789 --> 00:14:56,019
defense that wants to maintain some sort

383
00:14:53,679 --> 00:14:59,889
of dynamic state information about the

384
00:14:56,019 --> 00:15:02,649
application for instance the type safety

385
00:14:59,889 --> 00:15:04,959
defenses come to mind here personally

386
00:15:02,649 --> 00:15:06,459
I'm a big fan of tagged architectures

387
00:15:04,959 --> 00:15:08,709
and believe that they will provide a

388
00:15:06,459 --> 00:15:12,819
interesting and performant way to do

389
00:15:08,709 --> 00:15:14,738
this in the future so finally I just

390
00:15:12,819 --> 00:15:16,569
want to sort of wrap up by highlighting

391
00:15:14,739 --> 00:15:18,429
some of our performance evaluation

392
00:15:16,569 --> 00:15:20,618
results I'm running short on time so

393
00:15:18,429 --> 00:15:22,539
I'll go a little bit quickly here but

394
00:15:20,619 --> 00:15:25,539
the punchline here is that our

395
00:15:22,539 --> 00:15:28,059
recommended shadow stack has 3.65

396
00:15:25,539 --> 00:15:30,069
overhead on average and that this is

397
00:15:28,059 --> 00:15:31,779
lower than the you know direct shadow

398
00:15:30,069 --> 00:15:34,689
stack mapping which was previously

399
00:15:31,779 --> 00:15:36,489
thought to be the most performant and

400
00:15:34,689 --> 00:15:37,929
then here are the overheads for the

401
00:15:36,489 --> 00:15:39,220
different integrity enforcement

402
00:15:37,929 --> 00:15:41,858
mechanisms that we just talked about

403
00:15:39,220 --> 00:15:45,550
where randomization adds about a percent

404
00:15:41,859 --> 00:15:49,790
and then MPX comes in at 12% an MP

405
00:15:45,550 --> 00:15:53,089
61% but it has this huge outlier of 420

406
00:15:49,790 --> 00:15:55,399
percent in some cases so in conclusion

407
00:15:53,089 --> 00:15:58,069
the stack remains vulnerable to code

408
00:15:55,399 --> 00:16:00,440
reuse attacks solution for this is to

409
00:15:58,069 --> 00:16:02,990
separate return addresses from the data

410
00:16:00,440 --> 00:16:05,649
plane and to do so we recommend using a

411
00:16:02,990 --> 00:16:08,360
compact register base shadow stack and

412
00:16:05,649 --> 00:16:11,180
really the key takeaway from this talk

413
00:16:08,360 --> 00:16:13,579
is that you need to combine shadow

414
00:16:11,180 --> 00:16:16,699
stacks with control flow integrity to

415
00:16:13,579 --> 00:16:19,609
have complete and practical control flow

416
00:16:16,699 --> 00:16:21,439
hijacking mitigation our code is

417
00:16:19,610 --> 00:16:25,009
available or will be available shortly

418
00:16:21,439 --> 00:16:28,540
at this URL on github and with that I'm

419
00:16:25,009 --> 00:16:28,540
happy to take any questions thank you

420
00:16:31,209 --> 00:16:41,180
awesome - 2 second 16 minutes any

421
00:16:36,649 --> 00:16:44,269
questions yes please because currently

422
00:16:41,180 --> 00:16:46,279
need Google have you thought at all

423
00:16:44,269 --> 00:16:48,259
about the hardware shadow stack

424
00:16:46,279 --> 00:16:55,430
implementations like intel has I think

425
00:16:48,259 --> 00:16:57,560
it's C yes eet will be great if and when

426
00:16:55,430 --> 00:17:00,019
they ever actually manufacture it and of

427
00:16:57,560 --> 00:17:01,189
course it will only apply to x86 so

428
00:17:00,019 --> 00:17:03,380
there's this question of how do you

429
00:17:01,189 --> 00:17:06,109
protect arm what do you do for legacy

430
00:17:03,380 --> 00:17:07,849
processors and so forth so even with

431
00:17:06,109 --> 00:17:09,260
hardware support emerging they're still

432
00:17:07,849 --> 00:17:11,448
going to be at least a rather large

433
00:17:09,260 --> 00:17:15,500
window where shadow stacks and software

434
00:17:11,449 --> 00:17:18,350
base defenses are necessary thank you hi

435
00:17:15,500 --> 00:17:20,750
I'm near from Intel that was exactly my

436
00:17:18,349 --> 00:17:23,869
question so I'll ask another one can you

437
00:17:20,750 --> 00:17:26,000
comment on Harvard vs. von Neumann as

438
00:17:23,869 --> 00:17:29,360
far as separation goes if you're

439
00:17:26,000 --> 00:17:30,409
designing something new you said

440
00:17:29,360 --> 00:17:33,830
Hardware diversity

441
00:17:30,409 --> 00:17:35,960
I'm sorry hard hard word versus buying

442
00:17:33,830 --> 00:17:38,990
women there are two kinds of

443
00:17:35,960 --> 00:17:43,850
architectures Oh Harvard in von Neumann

444
00:17:38,990 --> 00:17:45,559
excuse me sorry yes so I think from a

445
00:17:43,850 --> 00:17:46,879
security perspective a Harvard

446
00:17:45,559 --> 00:17:49,129
architecture would have been better

447
00:17:46,880 --> 00:17:51,140
although I understand historically there

448
00:17:49,130 --> 00:17:54,770
were excellent reasons at the time for

449
00:17:51,140 --> 00:17:55,760
doing the von Norman approach of mixing

450
00:17:54,770 --> 00:17:57,770
code and data

451
00:17:55,760 --> 00:17:59,600
which is why I think we're sort of at

452
00:17:57,770 --> 00:18:01,730
the point now where what we really need

453
00:17:59,600 --> 00:18:06,580
is a logical if not necessarily a

454
00:18:01,730 --> 00:18:06,580
physical separation of the two thank you

455
00:18:07,330 --> 00:18:13,189
hey man we regulate Boston University

456
00:18:09,800 --> 00:18:15,409
this was very amazing I like the stuff a

457
00:18:13,190 --> 00:18:17,090
lot I had one question you said you

458
00:18:15,410 --> 00:18:19,670
implemented the various schemes that he

459
00:18:17,090 --> 00:18:21,800
found in LOM seven so what did you do

460
00:18:19,670 --> 00:18:23,570
with the libraries that were linked into

461
00:18:21,800 --> 00:18:29,899
those binaries did you also recompile

462
00:18:23,570 --> 00:18:32,120
all of those so when we were evaluating

463
00:18:29,900 --> 00:18:34,490
things we recompiled

464
00:18:32,120 --> 00:18:38,800
Lib C for some of the others that had

465
00:18:34,490 --> 00:18:41,870
dependencies we did not we looked at

466
00:18:38,800 --> 00:18:43,550
recompiling all of FreeBSD for full

467
00:18:41,870 --> 00:18:46,840
support and just weren't quite able to

468
00:18:43,550 --> 00:18:46,840
make it work in time for the deadline

469
00:18:50,530 --> 00:18:57,200
any other questions okay let's think

470
00:18:55,670 --> 00:18:58,200
nice Megan

471
00:18:57,200 --> 00:18:58,530
[Applause]

472
00:18:58,200 --> 00:19:02,480
[Music]

473
00:18:58,530 --> 00:19:02,480
[Applause]

