1
00:00:08,610 --> 00:00:14,280
good afternoon everyone my name is

2
00:00:11,250 --> 00:00:17,070
ginseng programming University of China

3
00:00:14,280 --> 00:00:19,350
today I will present our work on keeper

4
00:00:17,070 --> 00:00:22,200
of data collection with local tavern

5
00:00:19,350 --> 00:00:24,900
show privacy it is a joint work of

6
00:00:22,200 --> 00:00:28,710
Rimini university of china and hong kong

7
00:00:24,900 --> 00:00:30,930
poet Arion University in Estrada the

8
00:00:28,710 --> 00:00:34,590
first introduce and acquire knowledge of

9
00:00:30,930 --> 00:00:37,079
local dementia privacy based on list of

10
00:00:34,590 --> 00:00:39,989
a present output practical motivation

11
00:00:37,079 --> 00:00:42,809
and love problem statement let other

12
00:00:39,989 --> 00:00:46,399
give our solutions including or based

13
00:00:42,809 --> 00:00:49,320
approach to iterative models and

14
00:00:46,399 --> 00:00:52,559
optimization strategy after Lee a

15
00:00:49,320 --> 00:01:01,350
virtually experimental evaluation of our

16
00:00:52,559 --> 00:01:03,899
proposed mother nowadays data collection

17
00:01:01,350 --> 00:01:08,490
from individual users to collector is

18
00:01:03,899 --> 00:01:11,570
more and more cohesive however this may

19
00:01:08,490 --> 00:01:14,699
come with privacy issues as an answer to

20
00:01:11,570 --> 00:01:18,899
privacy preserving data collection local

21
00:01:14,700 --> 00:01:22,260
TV show privacy always say LDP is a

22
00:01:18,900 --> 00:01:25,980
privacy model where each user locally

23
00:01:22,260 --> 00:01:30,630
per trips locator and then send it to up

24
00:01:25,980 --> 00:01:33,510
to an untrusted data collector current

25
00:01:30,630 --> 00:01:37,310
layer randomized response has been the

26
00:01:33,510 --> 00:01:40,620
predominant technique for LTP a special

27
00:01:37,310 --> 00:01:45,060
specifically where a user is active ask

28
00:01:40,620 --> 00:01:49,290
and IO HIV positive then answer may be

29
00:01:45,060 --> 00:01:52,530
yes or no and to follow sake of privacy

30
00:01:49,290 --> 00:01:55,620
less user may give true answer was

31
00:01:52,530 --> 00:02:01,740
palpable probability P and obviously

32
00:01:55,620 --> 00:02:04,380
answer with low probability 1 minus P DP

33
00:02:01,740 --> 00:02:07,169
is a promising privacy-preserving model

34
00:02:04,380 --> 00:02:09,350
it has been deployed in many real

35
00:02:07,170 --> 00:02:13,820
products by several major

36
00:02:09,350 --> 00:02:17,210
they're companies for simple data types

37
00:02:13,820 --> 00:02:22,010
such as love categorical data all

38
00:02:17,210 --> 00:02:25,640
numerical data and currently there is no

39
00:02:22,010 --> 00:02:29,109
existing LTP solutions for key validator

40
00:02:25,640 --> 00:02:32,750
which is an extremely popular data model

41
00:02:29,110 --> 00:02:37,370
here is an example to collect a POC

42
00:02:32,750 --> 00:02:39,680
rotator in smartphones where the key is

43
00:02:37,370 --> 00:02:42,740
the app identifier and the value is the

44
00:02:39,680 --> 00:02:45,530
screen on try of each app to collect

45
00:02:42,740 --> 00:02:50,150
liske validator with our DP we need to

46
00:02:45,530 --> 00:02:52,670
design our new approach there is a naive

47
00:02:50,150 --> 00:02:56,290
solution for equivocator perturbation

48
00:02:52,670 --> 00:03:01,910
for example for less key value pair

49
00:02:56,290 --> 00:03:08,899
cancer is a disease and love sorry lucky

50
00:03:01,910 --> 00:03:12,370
cancer is a disease and value 0.2 is its

51
00:03:08,900 --> 00:03:16,100
diagnostic value suppose we usually

52
00:03:12,370 --> 00:03:20,360
existing method for categorical data

53
00:03:16,100 --> 00:03:23,390
KRR to put up cancer to fever and use

54
00:03:20,360 --> 00:03:29,030
the existing matter for numerical taylor

55
00:03:23,390 --> 00:03:32,470
harmony to petra 0.2 to 0.4 then a

56
00:03:29,030 --> 00:03:37,340
perturbed key value pair is like least

57
00:03:32,470 --> 00:03:41,390
fewer 0.4 however as we see in the left

58
00:03:37,340 --> 00:03:45,760
table each disease has its own value

59
00:03:41,390 --> 00:03:50,200
domain and at least 0.4 is not Engler

60
00:03:45,760 --> 00:03:50,200
domain of fever oh sorry

61
00:03:51,790 --> 00:03:59,030
low for was a key value correlation is a

62
00:03:56,480 --> 00:04:01,700
pep challenge for Cabello data

63
00:03:59,030 --> 00:04:06,980
perturbation since this is due to allah

64
00:04:01,700 --> 00:04:09,429
key value correlation for cuba for key

65
00:04:06,980 --> 00:04:12,829
validator we focused on two fundamental

66
00:04:09,430 --> 00:04:16,790
estimations letters frequency estimation

67
00:04:12,830 --> 00:04:20,090
over keys and mean estimation over

68
00:04:16,790 --> 00:04:21,500
values as both frequency and mean are

69
00:04:20,089 --> 00:04:24,859
associated with

70
00:04:21,500 --> 00:04:28,190
key our first step is to convert users

71
00:04:24,860 --> 00:04:33,010
key value pairs to its canonical form

72
00:04:28,190 --> 00:04:36,320
here is an example of data conversion

73
00:04:33,010 --> 00:04:39,680
suppose there are six keys in the

74
00:04:36,320 --> 00:04:46,060
universe a user has a four key value

75
00:04:39,680 --> 00:04:51,680
pairs with key ID one three five and six

76
00:04:46,060 --> 00:04:54,680
land as a four is canonical form these

77
00:04:51,680 --> 00:04:57,580
four pairs will be set in Tula positions

78
00:04:54,680 --> 00:05:00,470
of index one three five and six and

79
00:04:57,580 --> 00:05:03,710
other positions will be marked with an

80
00:05:00,470 --> 00:05:10,340
amputee key whose key and the value will

81
00:05:03,710 --> 00:05:14,299
be set as 0 objective value particular

82
00:05:10,340 --> 00:05:16,849
perk conversion we consider to desire a

83
00:05:14,300 --> 00:05:19,700
protocol for key and value perturbation

84
00:05:16,850 --> 00:05:23,000
here we also give an example that

85
00:05:19,700 --> 00:05:29,409
consists of several user and only one

86
00:05:23,000 --> 00:05:29,410
key in the universe in the left table oh

87
00:05:29,770 --> 00:05:35,780
we need two faces for key and develop

88
00:05:33,440 --> 00:05:38,840
perturbation respectively for key

89
00:05:35,780 --> 00:05:42,500
perturbation we can use randomized

90
00:05:38,840 --> 00:05:44,169
responses directly and then la vella

91
00:05:42,500 --> 00:05:49,520
perturbation is according to

92
00:05:44,169 --> 00:05:51,469
perturbation results of key here the

93
00:05:49,520 --> 00:05:55,729
property is when

94
00:05:51,470 --> 00:06:03,020
0 is perturb to 1 we need to assign our

95
00:05:55,729 --> 00:06:05,390
new value to it so as a list of Vista as

96
00:06:03,020 --> 00:06:09,020
users has no background knowledge about

97
00:06:05,390 --> 00:06:14,330
the true values how to choose this value

98
00:06:09,020 --> 00:06:16,490
is our new problem and here we use

99
00:06:14,330 --> 00:06:20,870
harmony as a building block and we

100
00:06:16,490 --> 00:06:23,120
further correct outliers by harmony as

101
00:06:20,870 --> 00:06:25,390
we'll be seeing in the experiment a list

102
00:06:23,120 --> 00:06:29,740
corruption where a second ever country

103
00:06:25,390 --> 00:06:29,740
improve the accuracy

104
00:06:31,960 --> 00:06:38,630
here we give our baseline approach we

105
00:06:35,750 --> 00:06:41,480
only assign value is randomly draw from

106
00:06:38,630 --> 00:06:46,610
the value domain the framework of data

107
00:06:41,480 --> 00:06:49,730
collection is shown in this figure as we

108
00:06:46,610 --> 00:06:52,990
see Lee Caesar one title collection so

109
00:06:49,730 --> 00:06:56,510
it has low communication bandwidth

110
00:06:52,990 --> 00:07:01,810
however this a this approach cannot

111
00:06:56,510 --> 00:07:05,330
achieve satisfying accuracy a toe to toe

112
00:07:01,810 --> 00:07:08,750
toe is poor diamond of the ways that

113
00:07:05,330 --> 00:07:13,159
since Vista is just randomly draw from

114
00:07:08,750 --> 00:07:17,750
the value domain to improve the accuracy

115
00:07:13,160 --> 00:07:21,640
we propose an ether model prof KVM which

116
00:07:17,750 --> 00:07:29,300
assigns a vista assuming of all values

117
00:07:21,640 --> 00:07:31,280
this figure shows the framework here we

118
00:07:29,300 --> 00:07:37,550
add step 6

119
00:07:31,280 --> 00:07:40,909
and step 7 as a feedback to improve the

120
00:07:37,550 --> 00:07:44,000
accuracy LS model the opening of the

121
00:07:40,910 --> 00:07:46,760
previous iteration becomes the exact

122
00:07:44,000 --> 00:07:49,130
value of this iteration a soul alarming

123
00:07:46,760 --> 00:07:54,380
estimation will gradually approach

124
00:07:49,130 --> 00:07:56,780
Contras with multiple iterations this

125
00:07:54,380 --> 00:08:00,890
approach improves the accuracy of main

126
00:07:56,780 --> 00:08:03,859
estimation however he also comes with a

127
00:08:00,890 --> 00:08:06,020
high communication bandwidth as multiple

128
00:08:03,860 --> 00:08:09,740
interaction between users and a data

129
00:08:06,020 --> 00:08:12,890
collector are needed in addition it also

130
00:08:09,740 --> 00:08:18,520
number of iterations to be determined in

131
00:08:12,890 --> 00:08:22,539
advance intuitively we may think of a

132
00:08:18,520 --> 00:08:26,390
question how many iterations are enough

133
00:08:22,540 --> 00:08:29,660
in reality it is quite difficult to

134
00:08:26,390 --> 00:08:35,590
determine this number truly stem we

135
00:08:29,660 --> 00:08:39,250
propose a VM plus

136
00:08:35,590 --> 00:08:42,150
here we define a cost function f in

137
00:08:39,250 --> 00:08:47,620
terms of our the number of iterations

138
00:08:42,150 --> 00:08:50,529
you can see f 1 f 1 is the accuracy cost

139
00:08:47,620 --> 00:08:54,460
and lay up to is the communication

140
00:08:50,529 --> 00:08:58,120
bandwidth by minimizing least total cost

141
00:08:54,460 --> 00:09:04,720
F we can derive an optimal number of

142
00:08:58,120 --> 00:09:06,900
iterations are here obviously this

143
00:09:04,720 --> 00:09:10,360
approach is strike a balance between

144
00:09:06,900 --> 00:09:12,490
accuracy cost to end communication

145
00:09:10,360 --> 00:09:17,910
bandwidth and has the lowest total cost

146
00:09:12,490 --> 00:09:21,610
you pay still needs to consolidate cost

147
00:09:17,910 --> 00:09:25,000
here is a comparison of lizra proposed

148
00:09:21,610 --> 00:09:27,970
solutions prof KVM is based on private

149
00:09:25,000 --> 00:09:31,600
kv which improves the accuracy and

150
00:09:27,970 --> 00:09:33,430
fuller prof kv m + strikes the parents

151
00:09:31,600 --> 00:09:39,180
between accuracy and communication

152
00:09:33,430 --> 00:09:42,270
pathways based only above three

153
00:09:39,180 --> 00:09:45,219
approaches way further proposed an

154
00:09:42,270 --> 00:09:48,460
optimization strategy by applying patch

155
00:09:45,220 --> 00:09:52,839
processing and virtual iterations that

156
00:09:48,460 --> 00:09:55,210
is let his Tuesday in each patch only

157
00:09:52,839 --> 00:09:58,690
love first iteration is really excuted

158
00:09:55,210 --> 00:10:01,720
and the others are just virtual

159
00:09:58,690 --> 00:10:04,839
iterations where a lot collector can't

160
00:10:01,720 --> 00:10:10,110
erupt can actually predict li estimate

161
00:10:04,839 --> 00:10:13,690
ming without user involvement and

162
00:10:10,110 --> 00:10:20,310
further limine prediction can be derived

163
00:10:13,690 --> 00:10:23,580
by a recursion so as miss Lee's

164
00:10:20,310 --> 00:10:27,310
optimization strategy has two advantages

165
00:10:23,580 --> 00:10:29,470
first it reduces network transmission

166
00:10:27,310 --> 00:10:32,680
over half between user and low data

167
00:10:29,470 --> 00:10:34,660
collector as users are not involved in

168
00:10:32,680 --> 00:10:38,620
virtual iterations

169
00:10:34,660 --> 00:10:41,920
second since virtual iterations do not

170
00:10:38,620 --> 00:10:45,220
cost any privacy pocket real iterations

171
00:10:41,920 --> 00:10:47,010
can be allocated more of it and

172
00:10:45,220 --> 00:10:52,850
therefore improves the as

173
00:10:47,010 --> 00:10:55,709
measure accuracy here we'll show some

174
00:10:52,850 --> 00:10:59,070
experimental evaluation as follow

175
00:10:55,709 --> 00:11:02,518
teachers we conduct experiments over six

176
00:10:59,070 --> 00:11:04,889
station cells the first three are

177
00:11:02,519 --> 00:11:08,430
synthetic data cells whose keys and

178
00:11:04,889 --> 00:11:11,940
values follow follow our caution Apollo

179
00:11:08,430 --> 00:11:15,449
and our linear distribution only Alice

180
00:11:11,940 --> 00:11:22,620
three are real data sets the way see

181
00:11:15,449 --> 00:11:25,170
love first two are usage data whose key

182
00:11:22,620 --> 00:11:28,620
is the app identifier and of value is

183
00:11:25,170 --> 00:11:34,800
the screen on tie of our user in a

184
00:11:28,620 --> 00:11:40,230
certain period love the third one is

185
00:11:34,800 --> 00:11:43,079
about sales records to measure the

186
00:11:40,230 --> 00:11:47,970
accuracy of the estimated frequency and

187
00:11:43,079 --> 00:11:53,160
meme we use two matrixes say relative

188
00:11:47,970 --> 00:11:55,230
error and mean square error as a full of

189
00:11:53,160 --> 00:11:58,949
frequency estimation will show the

190
00:11:55,230 --> 00:12:02,339
results of prof KVM comparing with three

191
00:11:58,949 --> 00:12:05,339
existing mothers we observe lab our

192
00:12:02,339 --> 00:12:08,940
mother is more accurate than the others

193
00:12:05,339 --> 00:12:12,720
three existing mother and for all mother

194
00:12:08,940 --> 00:12:15,360
way of the black for freak for frequent

195
00:12:12,720 --> 00:12:21,029
more frequent a key more accurate larezo

196
00:12:15,360 --> 00:12:24,690
and overall private KVM is less affected

197
00:12:21,029 --> 00:12:28,920
the pile of frequency of a key further

198
00:12:24,690 --> 00:12:33,029
for me estimation we show the results of

199
00:12:28,920 --> 00:12:36,149
private EVM comparing with the other two

200
00:12:33,029 --> 00:12:39,839
combinations here a value perturbation

201
00:12:36,149 --> 00:12:43,170
primitive improv KVM is replaced with

202
00:12:39,839 --> 00:12:46,319
two existing method for me estimation we

203
00:12:43,170 --> 00:12:49,620
observe prof KVM is more accurate than

204
00:12:46,319 --> 00:12:55,860
the other two especially for small

205
00:12:49,620 --> 00:12:58,680
private project to show how well achieve

206
00:12:55,860 --> 00:13:02,670
a low correlation is retained

207
00:12:58,680 --> 00:13:05,569
we shall list two figures here the black

208
00:13:02,670 --> 00:13:10,140
line he knows they're true Gaussian

209
00:13:05,570 --> 00:13:13,500
distribution we observed as Mimi our

210
00:13:10,140 --> 00:13:16,980
premium follows a very similar to

211
00:13:13,500 --> 00:13:24,120
tribution as LA roaming in la depta

212
00:13:16,980 --> 00:13:30,650
figure however a combination matter kr

213
00:13:24,120 --> 00:13:33,990
and hominy low result is seems very flat

214
00:13:30,650 --> 00:13:35,870
he also a pivot from the truth dear

215
00:13:33,990 --> 00:13:39,930
children

216
00:13:35,870 --> 00:13:45,810
this indicates Covello correlation is

217
00:13:39,930 --> 00:13:49,890
well retained in prof KVM here is our

218
00:13:45,810 --> 00:13:53,550
conclusion we propose three solutions

219
00:13:49,890 --> 00:13:55,560
for key value data collection with local

220
00:13:53,550 --> 00:13:59,699
differential privacy and we further

221
00:13:55,560 --> 00:14:03,689
compare these three approaches in terms

222
00:13:59,700 --> 00:14:07,050
of estimation accuracy and communication

223
00:14:03,690 --> 00:14:10,140
pathways with the Arad clip ruefully

224
00:14:07,050 --> 00:14:12,479
estimation is unbiased and always

225
00:14:10,140 --> 00:14:15,510
converge to the current truth and we

226
00:14:12,480 --> 00:14:18,630
also optimize our solutions to further

227
00:14:15,510 --> 00:14:22,200
improve the performance under large

228
00:14:18,630 --> 00:14:27,449
policy party that's all thank you

229
00:14:22,200 --> 00:14:35,350
[Applause]

230
00:14:27,449 --> 00:14:37,300
any questions so there's one microphone

231
00:14:35,350 --> 00:14:46,660
in the middle and then I have one in the

232
00:14:37,300 --> 00:14:49,599
front here so do you assume each user

233
00:14:46,660 --> 00:14:52,510
has a multiple key value pairs or just

234
00:14:49,600 --> 00:14:55,089
one key value pair a set of key repairs

235
00:14:52,510 --> 00:14:58,630
so in this case the price guarantee that

236
00:14:55,089 --> 00:15:01,720
prevail are prepared privacy or / user

237
00:14:58,630 --> 00:15:07,029
privacy for user privacy

238
00:15:01,720 --> 00:15:10,709
we will use our simple link to our set

239
00:15:07,029 --> 00:15:16,240
of key value pairs and then we wait um

240
00:15:10,709 --> 00:15:20,739
just allocate the privacy budget for

241
00:15:16,240 --> 00:15:25,019
each key/value pair evenly we just use a

242
00:15:20,740 --> 00:15:25,019
similar technique thank you

243
00:15:32,730 --> 00:15:39,790
and hi I'm Daniel from Google another

244
00:15:37,180 --> 00:15:44,229
way to do a sort of quasi local default

245
00:15:39,790 --> 00:15:46,449
privacy data collection is yes a

246
00:15:44,230 --> 00:15:49,029
structures like the encode shop for

247
00:15:46,450 --> 00:15:50,290
analyzer I don't know if you've heard of

248
00:15:49,029 --> 00:15:52,480
this have you compared this to these

249
00:15:50,290 --> 00:15:54,550
methods where you know instead of having

250
00:15:52,480 --> 00:15:56,050
only one direct communication between

251
00:15:54,550 --> 00:16:01,170
clay on the server you have a circular

252
00:15:56,050 --> 00:16:01,170
in the middle that encrypts stuff

253
00:16:02,880 --> 00:16:08,140
there's been papers for for doing a

254
00:16:05,800 --> 00:16:10,750
private data collection there are based

255
00:16:08,140 --> 00:16:13,390
on the two-step in infrastructure like

256
00:16:10,750 --> 00:16:14,890
encourage ever analyzed and was

257
00:16:13,390 --> 00:16:16,860
wondering how your method compares to

258
00:16:14,890 --> 00:16:20,949
that

259
00:16:16,860 --> 00:16:23,200
tell me except for our frequency

260
00:16:20,950 --> 00:16:30,040
estimation and me estimation can be

261
00:16:23,200 --> 00:16:35,050
adapted to other quarry oh I think our

262
00:16:30,040 --> 00:16:37,599
solution is a task specific so way for

263
00:16:35,050 --> 00:16:44,890
now we only focus on the frequency

264
00:16:37,600 --> 00:16:46,770
destination and my estimation may be a

265
00:16:44,890 --> 00:16:49,089
related question have you tried

266
00:16:46,770 --> 00:16:52,900
non-local differential privacy and see

267
00:16:49,089 --> 00:16:59,640
whether how much utility lost there is

268
00:16:52,900 --> 00:17:03,880
as compared to local actually we don't

269
00:16:59,640 --> 00:17:06,639
compare this Engler as followkim 30

270
00:17:03,880 --> 00:17:09,040
since they are focused on different

271
00:17:06,640 --> 00:17:11,290
settings law centralized differential

272
00:17:09,040 --> 00:17:13,030
privacy a focus on two neighboring

273
00:17:11,290 --> 00:17:16,319
dataset while other look at the

274
00:17:13,030 --> 00:17:20,050
potential problems they consider to

275
00:17:16,319 --> 00:17:22,899
tapos just enablement about English no

276
00:17:20,050 --> 00:17:25,560
cosmetic so you're saying they're

277
00:17:22,900 --> 00:17:25,560
incomparable

278
00:17:25,589 --> 00:17:34,908
I think they are different settings oh

279
00:17:30,659 --> 00:17:34,909
wait don't any other questions

280
00:17:38,059 --> 00:17:41,560
all right let's think Vicki one more

281
00:17:40,470 --> 00:17:41,780
time

282
00:17:41,560 --> 00:17:44,990
[Applause]

283
00:17:41,780 --> 00:17:44,990
[Music]

