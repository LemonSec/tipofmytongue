1
00:00:09,050 --> 00:00:15,540
good afternoon everyone thank you for

2
00:00:11,790 --> 00:00:18,689
joining so today I'm going to talk about

3
00:00:15,540 --> 00:00:22,110
some some methods for measuring how much

4
00:00:18,689 --> 00:00:25,890
a generic system reveals about its

5
00:00:22,110 --> 00:00:28,290
secret inputs and will work under a

6
00:00:25,890 --> 00:00:30,470
black box assumption so we'll assume

7
00:00:28,290 --> 00:00:34,950
essentially no knowledge of the

8
00:00:30,470 --> 00:00:38,040
internals of the system and the the main

9
00:00:34,950 --> 00:00:40,079
result really of our work is that we can

10
00:00:38,040 --> 00:00:42,480
actually use machine learning for

11
00:00:40,079 --> 00:00:44,850
measuring this leakage in an efficient

12
00:00:42,480 --> 00:00:49,230
way but still retaining strong

13
00:00:44,850 --> 00:00:53,219
theoretical guarantees so as I said we

14
00:00:49,230 --> 00:00:55,858
consider a black box system now as a

15
00:00:53,219 --> 00:00:58,800
system you could think of a computer

16
00:00:55,859 --> 00:01:00,829
program this could be a function could

17
00:00:58,800 --> 00:01:04,349
even be some hardware doing some sort of

18
00:01:00,829 --> 00:01:06,659
computation and this the system takes as

19
00:01:04,349 --> 00:01:11,550
input some secret and it's returned some

20
00:01:06,659 --> 00:01:14,190
output and the outputs given the secret

21
00:01:11,550 --> 00:01:16,500
input will be chosen according to some

22
00:01:14,190 --> 00:01:21,899
probability distribution which is

23
00:01:16,500 --> 00:01:25,320
unknown to us and for the purpose of

24
00:01:21,900 --> 00:01:28,380
this talk the secret will take finite

25
00:01:25,320 --> 00:01:30,960
values from values from a finite set and

26
00:01:28,380 --> 00:01:35,130
the outputs can be either discrete or

27
00:01:30,960 --> 00:01:38,190
continuous values and we really make no

28
00:01:35,130 --> 00:01:40,410
many assumptions on these on these

29
00:01:38,190 --> 00:01:43,110
systems we actually ask that this system

30
00:01:40,410 --> 00:01:45,479
doesn't change over time that's all

31
00:01:43,110 --> 00:01:47,880
really and now the kind of questions we

32
00:01:45,480 --> 00:01:52,050
try to answer here are well say an

33
00:01:47,880 --> 00:01:54,839
adversary observes the output well can

34
00:01:52,050 --> 00:01:57,690
we measure how much the output reveals

35
00:01:54,840 --> 00:02:01,140
about the corresponding secret or to

36
00:01:57,690 --> 00:02:02,880
phrase it kind of similarly how hard is

37
00:02:01,140 --> 00:02:07,020
it for an adversary to predict the

38
00:02:02,880 --> 00:02:08,910
secret given the output now this this is

39
00:02:07,020 --> 00:02:11,910
of course a very general model and it

40
00:02:08,910 --> 00:02:12,480
has several applications just to name a

41
00:02:11,910 --> 00:02:15,900
few

42
00:02:12,480 --> 00:02:17,910
we have location privacy so where the

43
00:02:15,900 --> 00:02:21,780
system could be a location privacy

44
00:02:17,910 --> 00:02:22,290
defense mechanism which takes as input

45
00:02:21,780 --> 00:02:25,230
the

46
00:02:22,290 --> 00:02:29,700
location of a user adds some noise and

47
00:02:25,230 --> 00:02:32,069
returns it is a noisy location and the

48
00:02:29,700 --> 00:02:34,200
beauty of this sort of model is that we

49
00:02:32,069 --> 00:02:36,958
don't really care about what's happening

50
00:02:34,200 --> 00:02:39,569
inside this system or how this noise is

51
00:02:36,959 --> 00:02:41,700
generated and in the goal in this case

52
00:02:39,569 --> 00:02:44,849
of course of the adversary's to predict

53
00:02:41,700 --> 00:02:49,470
the true location of the user given the

54
00:02:44,849 --> 00:02:51,869
noisy assertion another another example

55
00:02:49,470 --> 00:02:54,840
of course if side channels and we are in

56
00:02:51,870 --> 00:02:57,810
the right session so the one you see

57
00:02:54,840 --> 00:03:00,959
here is a simple timing side channel

58
00:02:57,810 --> 00:03:02,909
where the adversary tries to infer say

59
00:03:00,959 --> 00:03:06,799
the secret key given the computation

60
00:03:02,909 --> 00:03:11,310
time of some encryption cryptographic

61
00:03:06,799 --> 00:03:15,900
primitives and finally a particular case

62
00:03:11,310 --> 00:03:18,120
of side channel is network analysis in

63
00:03:15,900 --> 00:03:21,870
which case the adversary may try to

64
00:03:18,120 --> 00:03:24,090
infer perhaps user behavior which

65
00:03:21,870 --> 00:03:28,139
webpage a user visits given the

66
00:03:24,090 --> 00:03:29,819
encrypted network traffic so we said

67
00:03:28,139 --> 00:03:32,310
that we would like to say something

68
00:03:29,819 --> 00:03:34,319
about the probability that an adversary

69
00:03:32,310 --> 00:03:39,180
can guess the secret given the

70
00:03:34,319 --> 00:03:41,129
corresponding output and in this talk I

71
00:03:39,180 --> 00:03:43,440
will just talk about the the complement

72
00:03:41,129 --> 00:03:48,870
of this so we'll look at the probability

73
00:03:43,440 --> 00:03:50,669
that it guesses incorrectly and but of

74
00:03:48,870 --> 00:03:53,099
course we are not interested in just one

75
00:03:50,669 --> 00:03:56,730
adversary we're interested potentially

76
00:03:53,099 --> 00:03:59,280
in all the adversaries and in general we

77
00:03:56,730 --> 00:04:02,608
call base risk the probability of error

78
00:03:59,280 --> 00:04:05,790
of the optimal adversary under this

79
00:04:02,609 --> 00:04:08,370
scenario and on the basis of the base

80
00:04:05,790 --> 00:04:12,418
risk we can actually derive some leakage

81
00:04:08,370 --> 00:04:16,560
measures such as min entropy leakage so

82
00:04:12,419 --> 00:04:19,769
really our goal now will be to estimate

83
00:04:16,560 --> 00:04:22,550
the base risk for a system but now of

84
00:04:19,769 --> 00:04:26,010
course we only have a black box system

85
00:04:22,550 --> 00:04:28,409
so what we will do is well we will make

86
00:04:26,010 --> 00:04:30,900
some queries to the system with our

87
00:04:28,409 --> 00:04:33,450
choices of Secrets and look at the

88
00:04:30,900 --> 00:04:35,440
respective outputs and from this sort of

89
00:04:33,450 --> 00:04:39,110
input outputs

90
00:04:35,440 --> 00:04:41,840
data set we will want to estimate the

91
00:04:39,110 --> 00:04:44,870
base risk now there are two things we

92
00:04:41,840 --> 00:04:47,770
would like from an estimator first of

93
00:04:44,870 --> 00:04:51,770
all we would like that for any system

94
00:04:47,770 --> 00:04:55,008
its value should converge to the base

95
00:04:51,770 --> 00:04:59,289
risk given enough examples but of course

96
00:04:55,009 --> 00:05:02,449
be for real-world systems we would like

97
00:04:59,289 --> 00:05:04,729
this estimator to converge quite quickly

98
00:05:02,449 --> 00:05:09,770
so we wouldn't want to make too many

99
00:05:04,729 --> 00:05:12,650
queries to our system and until now

100
00:05:09,770 --> 00:05:14,568
really there's only been one methods for

101
00:05:12,650 --> 00:05:16,128
doing this sort of estimation and that's

102
00:05:14,569 --> 00:05:18,680
what we refer to as the frequent dis

103
00:05:16,129 --> 00:05:19,599
paradigm so let me give you an idea of

104
00:05:18,680 --> 00:05:22,969
how it works

105
00:05:19,599 --> 00:05:25,759
so suppose we're given these these

106
00:05:22,969 --> 00:05:28,639
queries inputs output queries and then

107
00:05:25,759 --> 00:05:33,169
we ask these frequencies adversary to

108
00:05:28,639 --> 00:05:35,509
make a prediction for an output 0.4 then

109
00:05:33,169 --> 00:05:38,448
this adversary will simply do a majority

110
00:05:35,509 --> 00:05:42,740
vote over the secrets of observed with

111
00:05:38,449 --> 00:05:46,219
that output and it will just output that

112
00:05:42,740 --> 00:05:49,039
secret but of course problems start

113
00:05:46,219 --> 00:05:50,930
arising when we ask this adversary to

114
00:05:49,039 --> 00:05:53,120
make a prediction for some value for

115
00:05:50,930 --> 00:05:55,909
some output value it has never seen such

116
00:05:53,120 --> 00:05:59,270
as 0.5 in which case you'll have to

117
00:05:55,909 --> 00:06:02,360
randomly guess now this really has been

118
00:05:59,270 --> 00:06:05,419
did only approach so far in this

119
00:06:02,360 --> 00:06:08,360
direction but unfortunately well eh of

120
00:06:05,419 --> 00:06:10,520
course it cannot be applied to whenever

121
00:06:08,360 --> 00:06:14,479
the output space is continuous this is

122
00:06:10,520 --> 00:06:17,448
easy to see but secondly and perhaps

123
00:06:14,479 --> 00:06:21,560
more most importantly from a practical

124
00:06:17,449 --> 00:06:25,250
perspective these kind of methods really

125
00:06:21,560 --> 00:06:27,770
needs to have observed one one example

126
00:06:25,250 --> 00:06:29,960
for each possible output value and of

127
00:06:27,770 --> 00:06:33,049
course if the output space of the system

128
00:06:29,960 --> 00:06:35,299
becomes very large then this method will

129
00:06:33,050 --> 00:06:38,990
just not scale it will just require too

130
00:06:35,300 --> 00:06:42,889
many queries so what what can we do

131
00:06:38,990 --> 00:06:45,710
about this well let me tell you a bit

132
00:06:42,889 --> 00:06:48,440
about this nice little classifier

133
00:06:45,710 --> 00:06:48,950
nearest neighbor this is arguably the

134
00:06:48,440 --> 00:06:51,050
scene

135
00:06:48,950 --> 00:06:54,050
this machine learning a classifier and

136
00:06:51,050 --> 00:06:56,180
the idea is as follows so say we have

137
00:06:54,050 --> 00:06:59,510
some points each belonging to a

138
00:06:56,180 --> 00:07:02,420
different class and we have to make a

139
00:06:59,510 --> 00:07:03,980
prediction for a new point then the

140
00:07:02,420 --> 00:07:06,170
nearest neighbor rule will tell us well

141
00:07:03,980 --> 00:07:09,410
just output the class of the closest

142
00:07:06,170 --> 00:07:12,710
observation to your point now why am i

143
00:07:09,410 --> 00:07:14,810
talking about nearest neighbor well as a

144
00:07:12,710 --> 00:07:16,909
matter of fact we showed that in our

145
00:07:14,810 --> 00:07:21,620
paper we showed that with very very

146
00:07:16,910 --> 00:07:23,320
minor modifications the ever of the of

147
00:07:21,620 --> 00:07:27,560
the nearest neighbor classifier

148
00:07:23,320 --> 00:07:29,840
asymptotically approximates the debase

149
00:07:27,560 --> 00:07:31,970
risk so effectively we can use the

150
00:07:29,840 --> 00:07:33,739
nearest neighbor classifier as we were

151
00:07:31,970 --> 00:07:36,560
using the frequencies approach for

152
00:07:33,740 --> 00:07:38,930
estimating the base risk so this is the

153
00:07:36,560 --> 00:07:40,760
idea we make we have made our our

154
00:07:38,930 --> 00:07:42,620
queries to the model we have this data

155
00:07:40,760 --> 00:07:44,900
set we will have to split it into

156
00:07:42,620 --> 00:07:47,870
training and test set and then estimate

157
00:07:44,900 --> 00:07:50,599
the nearest neighbor ever on this test

158
00:07:47,870 --> 00:07:54,560
set and this will already be a leakage

159
00:07:50,600 --> 00:07:57,800
measure for us now this only works when

160
00:07:54,560 --> 00:08:00,680
the output are take values from a finite

161
00:07:57,800 --> 00:08:03,980
base same similarly to the frequencies

162
00:08:00,680 --> 00:08:07,010
approach but then if we have continuous

163
00:08:03,980 --> 00:08:09,050
output values we can just use K n n so K

164
00:08:07,010 --> 00:08:12,170
and then works similarly as before just

165
00:08:09,050 --> 00:08:16,000
this time we will make a majority vote

166
00:08:12,170 --> 00:08:20,000
over over the K closest observations and

167
00:08:16,000 --> 00:08:23,600
in our paper we showed that if which was

168
00:08:20,000 --> 00:08:27,260
the the value of K appropriately with

169
00:08:23,600 --> 00:08:31,370
respect to the size of the training set

170
00:08:27,260 --> 00:08:34,549
of of KN n you could think of in terms

171
00:08:31,370 --> 00:08:37,280
of the number of queries we make then k

172
00:08:34,549 --> 00:08:40,579
n n is a leakage estimator of even if in

173
00:08:37,280 --> 00:08:43,640
the continuous case and this really

174
00:08:40,580 --> 00:08:46,160
brings us to our main result and that is

175
00:08:43,640 --> 00:08:48,580
that as it turns out there exists a

176
00:08:46,160 --> 00:08:53,180
whole class of machine learning methods

177
00:08:48,580 --> 00:08:57,320
which which have this property and that

178
00:08:53,180 --> 00:08:59,630
is that given enough examples given if

179
00:08:57,320 --> 00:09:00,450
enough queries their probability of

180
00:08:59,630 --> 00:09:04,880
error at

181
00:09:00,450 --> 00:09:09,540
she made asymptotically the base risk so

182
00:09:04,880 --> 00:09:12,240
this is for the desert be theoretical

183
00:09:09,540 --> 00:09:16,280
guarantees that we wanted now let's look

184
00:09:12,240 --> 00:09:21,930
at some actual results in practice and

185
00:09:16,280 --> 00:09:25,410
within well within the paper we will

186
00:09:21,930 --> 00:09:28,079
looked at a couple of side channels I'm

187
00:09:25,410 --> 00:09:31,110
just going to talk here about a location

188
00:09:28,080 --> 00:09:33,450
privacy example so in this in this

189
00:09:31,110 --> 00:09:37,110
application we looked at the Koala data

190
00:09:33,450 --> 00:09:42,240
set which comprises users location data

191
00:09:37,110 --> 00:09:44,400
and and to this location data we applied

192
00:09:42,240 --> 00:09:46,830
several location privacy mechanisms

193
00:09:44,400 --> 00:09:51,150
geometric lipu laplacian and Blau

194
00:09:46,830 --> 00:09:53,880
harimoto so so let's start with the

195
00:09:51,150 --> 00:09:58,560
first one geometric the idea is suppose

196
00:09:53,880 --> 00:10:02,430
you have two users locations to defend

197
00:09:58,560 --> 00:10:06,959
then the noise is sampled according to

198
00:10:02,430 --> 00:10:09,930
the two distributions you see here and

199
00:10:06,960 --> 00:10:11,640
well we run the experiments and computed

200
00:10:09,930 --> 00:10:14,339
the number of queries required for a

201
00:10:11,640 --> 00:10:17,840
methyls to to actually converts to a

202
00:10:14,340 --> 00:10:22,080
good approximation of the base risk and

203
00:10:17,840 --> 00:10:23,970
well as it turns out neither frequencies

204
00:10:22,080 --> 00:10:25,710
nor nearest-neighbor approach did

205
00:10:23,970 --> 00:10:29,460
actually manage to converge within the

206
00:10:25,710 --> 00:10:32,340
number of examples we had but with King

207
00:10:29,460 --> 00:10:35,700
years neighbor we were able to to

208
00:10:32,340 --> 00:10:40,980
converge within 20,000 queries to to the

209
00:10:35,700 --> 00:10:43,230
black box we also run some experiments

210
00:10:40,980 --> 00:10:44,880
for the laplacian noise which is

211
00:10:43,230 --> 00:10:48,630
essentially equivalent to the geometric

212
00:10:44,880 --> 00:10:51,150
noise it's just continues in this case

213
00:10:48,630 --> 00:10:53,070
we had pretty much the same results

214
00:10:51,150 --> 00:10:54,780
although we couldn't really apply the

215
00:10:53,070 --> 00:10:58,740
frequentist approach because of course

216
00:10:54,780 --> 00:11:01,290
this is a continuous mechanism and note

217
00:10:58,740 --> 00:11:03,840
that in these examples I'm showing you

218
00:11:01,290 --> 00:11:06,060
here nearest neighbor is always

219
00:11:03,840 --> 00:11:08,040
performing very badly but in the paper

220
00:11:06,060 --> 00:11:12,510
you'll find examples where nearest

221
00:11:08,040 --> 00:11:14,410
neighbor was better than km and finally

222
00:11:12,510 --> 00:11:17,439
we applied

223
00:11:14,410 --> 00:11:21,550
our techniques to these mechanism which

224
00:11:17,440 --> 00:11:24,820
is just some ITA t'v mechanism which

225
00:11:21,550 --> 00:11:27,280
mumps a user location into one of the

226
00:11:24,820 --> 00:11:30,490
points you see there together with their

227
00:11:27,280 --> 00:11:32,970
distribution and in this case well we

228
00:11:30,490 --> 00:11:35,290
saw that we saw something weird well

229
00:11:32,970 --> 00:11:38,710
pretty much all the methods were

230
00:11:35,290 --> 00:11:41,980
equivalent although still canaan was

231
00:11:38,710 --> 00:11:45,160
slightly better so why why is this the

232
00:11:41,980 --> 00:11:48,690
case well if you think about it in this

233
00:11:45,160 --> 00:11:51,790
case the system has only very few

234
00:11:48,690 --> 00:11:54,160
possible output values and indeed the

235
00:11:51,790 --> 00:11:56,589
ones the ones you see plotted here are

236
00:11:54,160 --> 00:12:00,370
the only possible values the system can

237
00:11:56,590 --> 00:12:02,560
have and this is actually a fact we

238
00:12:00,370 --> 00:12:06,340
observed much more in general and that

239
00:12:02,560 --> 00:12:08,469
is that our methods and in general

240
00:12:06,340 --> 00:12:11,740
machine learning methods tend to be

241
00:12:08,470 --> 00:12:14,470
equivalent to the frequencies approach

242
00:12:11,740 --> 00:12:16,870
whenever very small systems or for

243
00:12:14,470 --> 00:12:19,870
systems for which the output space is

244
00:12:16,870 --> 00:12:23,170
fairly small right

245
00:12:19,870 --> 00:12:25,690
so we also carried on some experiments

246
00:12:23,170 --> 00:12:29,680
on synthetic data I'm just going to give

247
00:12:25,690 --> 00:12:32,440
you the gist of it we we observed it and

248
00:12:29,680 --> 00:12:34,510
this is not so much of a surprise that

249
00:12:32,440 --> 00:12:36,370
machine learning methods and in

250
00:12:34,510 --> 00:12:39,640
particular nearest neighbour methods

251
00:12:36,370 --> 00:12:42,400
that we evaluated were did manage to

252
00:12:39,640 --> 00:12:46,030
scale to very large systems so system

253
00:12:42,400 --> 00:12:48,790
with a hundred thousand output values a

254
00:12:46,030 --> 00:12:51,250
million output values and they were

255
00:12:48,790 --> 00:12:53,319
particularly good whenever there was

256
00:12:51,250 --> 00:12:55,150
some sort of metric on the output which

257
00:12:53,320 --> 00:12:57,490
could be exploited so you could imagine

258
00:12:55,150 --> 00:13:03,280
time side channels when the output is

259
00:12:57,490 --> 00:13:06,250
time when there was no metric on the

260
00:13:03,280 --> 00:13:07,689
output space then our methods were

261
00:13:06,250 --> 00:13:10,720
pretty much equivalent to the

262
00:13:07,690 --> 00:13:15,070
frequencies approach which was not about

263
00:13:10,720 --> 00:13:17,740
news but still we were able to find some

264
00:13:15,070 --> 00:13:20,110
particular example which we drafted this

265
00:13:17,740 --> 00:13:22,990
very weird system so that nearest

266
00:13:20,110 --> 00:13:25,960
neighbor rule could fail against the

267
00:13:22,990 --> 00:13:28,300
frequencies approach at which point one

268
00:13:25,960 --> 00:13:31,240
may ask well is there an OP

269
00:13:28,300 --> 00:13:34,990
more estimator for black box security

270
00:13:31,240 --> 00:13:38,170
and the answer once again comes from the

271
00:13:34,990 --> 00:13:41,290
machine learning theory where the no

272
00:13:38,170 --> 00:13:43,810
free lunch theorem should tell us no

273
00:13:41,290 --> 00:13:46,569
there is no such thing as an optimal

274
00:13:43,810 --> 00:13:50,140
estimator and in and indeed what it says

275
00:13:46,570 --> 00:13:53,350
is imagine you have any two estimators a

276
00:13:50,140 --> 00:13:57,460
and B there is always there's exactly as

277
00:13:53,350 --> 00:13:59,710
many systems for which estimator a will

278
00:13:57,460 --> 00:14:05,050
will be better than B and the other way

279
00:13:59,710 --> 00:14:07,780
around but and the takeaway really of

280
00:14:05,050 --> 00:14:11,530
this impossibility result is that in

281
00:14:07,780 --> 00:14:14,199
proxies when we want to measure the

282
00:14:11,530 --> 00:14:16,480
leakage with black box security methods

283
00:14:14,200 --> 00:14:18,730
which you don't waste triage as many

284
00:14:16,480 --> 00:14:21,610
estimators and just look at the one that

285
00:14:18,730 --> 00:14:25,240
converged faster but this is of course

286
00:14:21,610 --> 00:14:28,780
kind of good news if you think about the

287
00:14:25,240 --> 00:14:32,440
fact that after our work there are many

288
00:14:28,780 --> 00:14:34,689
many new estimators for estimated the

289
00:14:32,440 --> 00:14:38,380
leakage and indeed there is a whole new

290
00:14:34,690 --> 00:14:41,140
class of estimators and we release F

291
00:14:38,380 --> 00:14:43,689
blow which is a tool for for measuring

292
00:14:41,140 --> 00:14:45,520
for measuring leakage at the moment it

293
00:14:43,690 --> 00:14:50,110
only implements nearest neighbor methods

294
00:14:45,520 --> 00:14:53,949
but it's basically on this idea so kind

295
00:14:50,110 --> 00:14:56,230
of to wrap things up black box security

296
00:14:53,950 --> 00:14:58,630
has a huge potential because it allows

297
00:14:56,230 --> 00:15:01,450
us to measure the leakage of systems

298
00:14:58,630 --> 00:15:04,180
without the need to model them they're

299
00:15:01,450 --> 00:15:07,720
their internals and of course this is

300
00:15:04,180 --> 00:15:10,900
good in practice where sometimes systems

301
00:15:07,720 --> 00:15:14,890
are just too complex to analyze formally

302
00:15:10,900 --> 00:15:17,290
and until now there was only the

303
00:15:14,890 --> 00:15:22,330
frequencies approach for for measuring

304
00:15:17,290 --> 00:15:24,939
leakage in this way but we think thanks

305
00:15:22,330 --> 00:15:27,370
to to this work there's a whole new

306
00:15:24,940 --> 00:15:29,800
class of methods and namely the

307
00:15:27,370 --> 00:15:31,570
universally consistent machine learning

308
00:15:29,800 --> 00:15:35,349
rules which we can use for this purpose

309
00:15:31,570 --> 00:15:37,630
and in the future really we are looking

310
00:15:35,350 --> 00:15:40,900
forward to more applications in sight

311
00:15:37,630 --> 00:15:41,860
channels but we're also looking at using

312
00:15:40,900 --> 00:15:43,839
these techniques

313
00:15:41,860 --> 00:15:45,910
measuring the security of machine

314
00:15:43,839 --> 00:15:49,870
learning against attacks such as

315
00:15:45,910 --> 00:15:52,420
membership in France for example so this

316
00:15:49,870 --> 00:16:01,690
is really all for me be happy to take

317
00:15:52,420 --> 00:16:07,660
your questions thank you do we have

318
00:16:01,690 --> 00:16:10,120
plenty of time for questions oh hi Tom

319
00:16:07,660 --> 00:16:13,959
Benjamin perspective labs loved the

320
00:16:10,120 --> 00:16:16,450
presentation a question about what

321
00:16:13,959 --> 00:16:19,569
happens to your model in certain kinds

322
00:16:16,450 --> 00:16:22,660
of cases so I'm curious just in the

323
00:16:19,570 --> 00:16:25,060
example of the location privacy what

324
00:16:22,660 --> 00:16:28,630
happens to what it is that your model is

325
00:16:25,060 --> 00:16:31,329
trying to express when you add in

326
00:16:28,630 --> 00:16:33,519
additional auxiliary information like

327
00:16:31,329 --> 00:16:35,019
the fact that the person is more likely

328
00:16:33,519 --> 00:16:36,490
to be in the Walmart than the lake

329
00:16:35,019 --> 00:16:42,160
across the street

330
00:16:36,490 --> 00:16:44,769
okay so the idea is that with by

331
00:16:42,160 --> 00:16:47,790
measuring the leakage right we we try to

332
00:16:44,769 --> 00:16:50,709
measure how much more information and

333
00:16:47,790 --> 00:16:53,050
adversary has once he observes the

334
00:16:50,709 --> 00:16:55,750
output right now of course you may have

335
00:16:53,050 --> 00:16:58,630
auxiliary information of which we do not

336
00:16:55,750 --> 00:17:00,490
know for all we know it could know

337
00:16:58,630 --> 00:17:03,970
immediately the secret right so in that

338
00:17:00,490 --> 00:17:05,650
case these you know the knowledge like

339
00:17:03,970 --> 00:17:08,919
the knowledge of the output wouldn't

340
00:17:05,650 --> 00:17:13,150
give in any additional kind of

341
00:17:08,919 --> 00:17:17,309
information so I'm not sure if this

342
00:17:13,150 --> 00:17:17,309
answers the questions okay

343
00:17:19,199 --> 00:17:23,799
somewhat similar questions so you're

344
00:17:22,000 --> 00:17:25,150
assuming blackbox adversaries but if

345
00:17:23,799 --> 00:17:26,829
they have more information not necessary

346
00:17:25,150 --> 00:17:29,049
about oxyde information about the input

347
00:17:26,829 --> 00:17:31,750
but about the black box where does that

348
00:17:29,049 --> 00:17:35,410
do to the guarantees right so as a

349
00:17:31,750 --> 00:17:37,270
matter of fact the the base when we talk

350
00:17:35,410 --> 00:17:39,669
about Bayes risk or leakage whatever

351
00:17:37,270 --> 00:17:43,960
we're trying to estimate that also holds

352
00:17:39,669 --> 00:17:45,730
for white box adversaries so the the

353
00:17:43,960 --> 00:17:48,820
optimal adversary is called the base

354
00:17:45,730 --> 00:17:50,800
adversary is one who knows exactly all

355
00:17:48,820 --> 00:17:54,250
the internal probability distributions

356
00:17:50,800 --> 00:17:55,580
or knows the internal algorithm right so

357
00:17:54,250 --> 00:18:00,440
what we are asking

358
00:17:55,580 --> 00:18:03,889
here is does hold for four wise books

359
00:18:00,440 --> 00:18:07,250
yes great it's okay unless there's any

360
00:18:03,890 --> 00:18:08,790
other questions then why don't we thank

361
00:18:07,250 --> 00:18:13,720
Giovanni again

362
00:18:08,790 --> 00:18:13,720
[Applause]

