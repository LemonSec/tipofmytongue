1
00:00:08,580 --> 00:00:12,750
hey my name is stephane Maggie I'm a PhD

2
00:00:11,190 --> 00:00:13,600
student Virginia Tech and I'm here to

3
00:00:12,750 --> 00:00:15,820
present her

4
00:00:13,600 --> 00:00:17,560
full speed fuzzing this is a joint

5
00:00:15,820 --> 00:00:20,050
collaboration between my advisor dr.

6
00:00:17,560 --> 00:00:21,430
Matthew Hicks and myself so hopefully

7
00:00:20,050 --> 00:00:23,500
today will help get you excited about

8
00:00:21,430 --> 00:00:38,140
our efforts to improve fuzzing

9
00:00:23,500 --> 00:00:38,320
performance and we advance tonight all

10
00:00:38,140 --> 00:00:40,239
right

11
00:00:38,320 --> 00:00:43,620
so as we've discussed already in this

12
00:00:40,239 --> 00:00:46,480
session fuzzing is a very fundamental

13
00:00:43,620 --> 00:00:47,709
excuse me in time-tested technique to

14
00:00:46,480 --> 00:00:49,449
finding software bugs and

15
00:00:47,710 --> 00:00:52,300
vulnerabilities it's very widely used by

16
00:00:49,449 --> 00:00:54,879
developers and attackers alike

17
00:00:52,300 --> 00:00:57,129
it spawned many numerous tools like AFL

18
00:00:54,879 --> 00:00:58,780
Hong fuzz and live buzzer each of these

19
00:00:57,129 --> 00:01:01,900
with very impressive track records of

20
00:00:58,780 --> 00:01:04,239
disclosing vulnerabilities it's very

21
00:01:01,900 --> 00:01:06,670
popular in the software industry so big

22
00:01:04,239 --> 00:01:08,110
corporations like to use fuzzing to find

23
00:01:06,670 --> 00:01:10,780
bugs and vulnerabilities in their

24
00:01:08,110 --> 00:01:12,580
software both pre and post release and

25
00:01:10,780 --> 00:01:14,320
it's become very accessible to

26
00:01:12,580 --> 00:01:17,020
developers in the form of cloud

27
00:01:14,320 --> 00:01:19,449
platforms and by far the most popular

28
00:01:17,020 --> 00:01:21,399
approach in fuzzing is called coverage

29
00:01:19,450 --> 00:01:23,350
guided fuzzing which at a high level

30
00:01:21,399 --> 00:01:25,509
operates given as follows so given a

31
00:01:23,350 --> 00:01:26,589
target application has some test cases

32
00:01:25,509 --> 00:01:28,780
for it the fuzzer

33
00:01:26,590 --> 00:01:29,979
executes these target application start

34
00:01:28,780 --> 00:01:32,200
these test cases against the target

35
00:01:29,979 --> 00:01:33,909
application and measures each one of

36
00:01:32,200 --> 00:01:36,310
their code coverage basically how far

37
00:01:33,909 --> 00:01:39,219
they gets in the target applications

38
00:01:36,310 --> 00:01:41,140
code and test cases which increase code

39
00:01:39,219 --> 00:01:43,809
coverage are preserved meaning they've

40
00:01:41,140 --> 00:01:46,750
found some new part of the code that the

41
00:01:43,810 --> 00:01:49,329
other ones have not and all those which

42
00:01:46,750 --> 00:01:51,609
don't are simply discarded along with

43
00:01:49,329 --> 00:01:54,059
their code coverage and the end goal of

44
00:01:51,609 --> 00:01:56,530
this process is to kind of exhaustively

45
00:01:54,060 --> 00:01:58,329
traverse the program code and find those

46
00:01:56,530 --> 00:02:01,149
few test cases that trigger bugs or

47
00:01:58,329 --> 00:02:03,609
vulnerabilities now to date a lot of

48
00:02:01,149 --> 00:02:06,429
work has gone into improving this test

49
00:02:03,609 --> 00:02:08,049
case generation process to mutate test

50
00:02:06,429 --> 00:02:10,869
cases better so that they penetrate

51
00:02:08,050 --> 00:02:12,069
deeper regions of the code but our focus

52
00:02:10,869 --> 00:02:13,890
is on improving this test case

53
00:02:12,069 --> 00:02:16,089
generation process and we observed that

54
00:02:13,890 --> 00:02:18,250
identifying coverage increasing test

55
00:02:16,090 --> 00:02:20,860
cases requires that the tracing of code

56
00:02:18,250 --> 00:02:22,780
coverage for every single test case yet

57
00:02:20,860 --> 00:02:24,820
only a very small handful of these

58
00:02:22,780 --> 00:02:26,800
actually increase code coverage the

59
00:02:24,820 --> 00:02:27,269
overwhelming majority along with their

60
00:02:26,800 --> 00:02:29,100
code

61
00:02:27,270 --> 00:02:32,790
you're simply just junked and discarded

62
00:02:29,100 --> 00:02:34,859
by the fuzzer and additionally and given

63
00:02:32,790 --> 00:02:37,410
this fact as well as as our results show

64
00:02:34,860 --> 00:02:38,850
that this process of tracing every test

65
00:02:37,410 --> 00:02:40,320
case adds some pretty non-negligible

66
00:02:38,850 --> 00:02:43,609
overhead over the course of fuzzing an

67
00:02:40,320 --> 00:02:45,540
application we see this is having a huge

68
00:02:43,610 --> 00:02:47,490
potential for improvement and that these

69
00:02:45,540 --> 00:02:49,440
resources could be much better used

70
00:02:47,490 --> 00:02:51,150
elsewhere to find bugs in the fuzzing

71
00:02:49,440 --> 00:02:52,650
workflow and this is where coverage

72
00:02:51,150 --> 00:02:54,300
guided tracing fits in so rather than

73
00:02:52,650 --> 00:02:56,250
tracing every one of those single test

74
00:02:54,300 --> 00:02:58,590
cases to find the few that are coverage

75
00:02:56,250 --> 00:03:00,150
increasing we restrict tracing to just

76
00:02:58,590 --> 00:03:02,850
those that are coverage increasing that

77
00:03:00,150 --> 00:03:04,380
small small fraction and as a result we

78
00:03:02,850 --> 00:03:06,180
were able to dramatically cut down this

79
00:03:04,380 --> 00:03:08,430
overall overhead to about three tenths

80
00:03:06,180 --> 00:03:10,380
of a percent and because we focused on

81
00:03:08,430 --> 00:03:12,810
simply filtering out test cases before

82
00:03:10,380 --> 00:03:14,760
they are traced we would easily

83
00:03:12,810 --> 00:03:17,370
complement these great approaches which

84
00:03:14,760 --> 00:03:20,910
try to generate test cases better or

85
00:03:17,370 --> 00:03:22,230
make tracing faster by other means so

86
00:03:20,910 --> 00:03:24,090
our first question going into this

87
00:03:22,230 --> 00:03:26,070
project was how our coverage increasing

88
00:03:24,090 --> 00:03:28,080
test case is found and the answer is

89
00:03:26,070 --> 00:03:29,519
fuzzers trace the coverage of every

90
00:03:28,080 --> 00:03:31,830
single test case and they do this

91
00:03:29,520 --> 00:03:34,470
through instrumentation inserted either

92
00:03:31,830 --> 00:03:36,240
dynamically or statically and generally

93
00:03:34,470 --> 00:03:38,190
any kind of dynamic instrumentation is

94
00:03:36,240 --> 00:03:40,230
far far slower than any kind of static

95
00:03:38,190 --> 00:03:42,300
instrumentation approach but another

96
00:03:40,230 --> 00:03:44,340
limiting factor is is the availability

97
00:03:42,300 --> 00:03:46,470
of the program source code so you're

98
00:03:44,340 --> 00:03:48,570
able to instrument in these kind of

99
00:03:46,470 --> 00:03:50,730
white box techniques which we see as

100
00:03:48,570 --> 00:03:52,620
encompassing kind of compiling assembly

101
00:03:50,730 --> 00:03:55,200
time instrumentation that's generally

102
00:03:52,620 --> 00:03:57,300
much much faster than any kind of binary

103
00:03:55,200 --> 00:04:00,869
only or black box approaches we refer to

104
00:03:57,300 --> 00:04:02,910
in the paper so going on from that we

105
00:04:00,870 --> 00:04:05,550
wanted it's kind of going on from that

106
00:04:02,910 --> 00:04:07,380
we wanted to identify how do fuzzers

107
00:04:05,550 --> 00:04:08,970
actually spend their time while they're

108
00:04:07,380 --> 00:04:11,400
trying to find bugs in the application

109
00:04:08,970 --> 00:04:13,620
so we profiled AFL which is kind of the

110
00:04:11,400 --> 00:04:15,420
standard naive based fuzzing approach as

111
00:04:13,620 --> 00:04:17,700
well as driller which is an advancement

112
00:04:15,420 --> 00:04:21,209
that complements these kind of naive

113
00:04:17,700 --> 00:04:24,120
fuzzing techniques with a more technical

114
00:04:21,209 --> 00:04:26,760
symbolic execution approach and we

115
00:04:24,120 --> 00:04:28,290
looked at black box key new base tracing

116
00:04:26,760 --> 00:04:30,480
for both AFL and driller because they

117
00:04:28,290 --> 00:04:32,760
saw the driller support at the time as

118
00:04:30,480 --> 00:04:35,910
well as clangs out of the box assembly

119
00:04:32,760 --> 00:04:38,330
time white box tracing approach and we

120
00:04:35,910 --> 00:04:40,740
profile these one-hour executions for a

121
00:04:38,330 --> 00:04:42,570
benchmarks per configuration

122
00:04:40,740 --> 00:04:45,720
and we discovered that across every one

123
00:04:42,570 --> 00:04:49,320
of these configurations over 90% of

124
00:04:45,720 --> 00:04:51,840
buzzer time was spent on tracing and

125
00:04:49,320 --> 00:04:53,219
executing these test cases so from there

126
00:04:51,840 --> 00:04:54,659
we were thinking okay that's a that's a

127
00:04:53,220 --> 00:04:56,700
pretty overwhelming majority of time

128
00:04:54,660 --> 00:04:58,110
that must mean that's you know a lot of

129
00:04:56,700 --> 00:05:00,690
these test cases are actually coverage

130
00:04:58,110 --> 00:05:02,940
increasing and to our surprise that's

131
00:05:00,690 --> 00:05:04,920
quite far from the truth so on average

132
00:05:02,940 --> 00:05:07,080
less than three out of 10,000 of these

133
00:05:04,920 --> 00:05:09,150
test cases actually increased code

134
00:05:07,080 --> 00:05:10,650
coverage so the other nine thousand nine

135
00:05:09,150 --> 00:05:13,799
hundred ninety seven were completely

136
00:05:10,650 --> 00:05:15,210
just discarded so going on from there we

137
00:05:13,800 --> 00:05:15,600
were thinking okay one hour is kind of

138
00:05:15,210 --> 00:05:17,609
short

139
00:05:15,600 --> 00:05:20,580
let's try 24 hours that's kind of the

140
00:05:17,610 --> 00:05:22,680
standard evaluation trial for fuzzers so

141
00:05:20,580 --> 00:05:23,690
we looked again at AFL chemo we

142
00:05:22,680 --> 00:05:26,820
collected

143
00:05:23,690 --> 00:05:29,219
524 our test case dumps per eight

144
00:05:26,820 --> 00:05:32,219
benchmarks and we discover that actually

145
00:05:29,220 --> 00:05:34,410
it decreases exponentially so as you

146
00:05:32,220 --> 00:05:36,540
kind of push past and fuzz you're easy

147
00:05:34,410 --> 00:05:38,570
to reach regions of the target

148
00:05:36,540 --> 00:05:41,040
applications code it becomes

149
00:05:38,570 --> 00:05:43,650
exponentially less likely that you will

150
00:05:41,040 --> 00:05:46,260
find test cases which which reach new

151
00:05:43,650 --> 00:05:49,049
code coverage so on average this ended

152
00:05:46,260 --> 00:05:52,409
up being at most one out of 10,000 test

153
00:05:49,050 --> 00:05:54,150
cases on average so very very low so

154
00:05:52,410 --> 00:05:55,830
from here the overall impact is you know

155
00:05:54,150 --> 00:05:57,510
okay we're tracing over we're sorry

156
00:05:55,830 --> 00:06:00,240
we're spending over 90% of fuzzer time

157
00:05:57,510 --> 00:06:02,849
on tracing these test cases yet over

158
00:06:00,240 --> 00:06:04,740
99.99% of these are completely just

159
00:06:02,850 --> 00:06:06,450
discarded by the fuzzer so this is

160
00:06:04,740 --> 00:06:08,670
analogous in our eyes to trying to find

161
00:06:06,450 --> 00:06:10,260
the needle in the haystack by taking a

162
00:06:08,670 --> 00:06:11,640
magnifying glass to every single piece

163
00:06:10,260 --> 00:06:14,909
of hay it's just not efficient

164
00:06:11,640 --> 00:06:17,280
whatsoever but why is tracing code

165
00:06:14,910 --> 00:06:18,510
coverage so expensive in the long run

166
00:06:17,280 --> 00:06:19,979
well the answer is you're storing

167
00:06:18,510 --> 00:06:22,500
coverage for many many parts of the

168
00:06:19,980 --> 00:06:23,880
program code so this kind of operates

169
00:06:22,500 --> 00:06:26,070
you know given your you're executing the

170
00:06:23,880 --> 00:06:27,870
program you hook every single basic

171
00:06:26,070 --> 00:06:29,460
block and you store that it has been

172
00:06:27,870 --> 00:06:32,550
covered in this kind of data structure

173
00:06:29,460 --> 00:06:34,229
AFL uses bitmaps arrays are also a

174
00:06:32,550 --> 00:06:36,150
common way of doing this and then you

175
00:06:34,230 --> 00:06:38,670
return control flow back to the to the

176
00:06:36,150 --> 00:06:39,989
basic block finish executing the rest of

177
00:06:38,670 --> 00:06:42,390
it and then move on to the next basic

178
00:06:39,990 --> 00:06:44,250
block but the problem is this adds this

179
00:06:42,390 --> 00:06:45,690
this process of fetching and writing to

180
00:06:44,250 --> 00:06:47,940
this data structure adds many many

181
00:06:45,690 --> 00:06:50,310
instructions to the overhead of this

182
00:06:47,940 --> 00:06:52,290
basic block and because you have many

183
00:06:50,310 --> 00:06:53,780
basic blocks in modern applications and

184
00:06:52,290 --> 00:06:55,070
execution paths are long

185
00:06:53,780 --> 00:06:57,440
and contain all this kind of looping

186
00:06:55,070 --> 00:07:00,680
behavior this overhead very quickly adds

187
00:06:57,440 --> 00:07:02,719
up over time so it is it is costly to do

188
00:07:00,680 --> 00:07:04,580
this excessively and this is where

189
00:07:02,720 --> 00:07:05,600
coverage guided tracing tries to fit in

190
00:07:04,580 --> 00:07:09,409
and solve this problem

191
00:07:05,600 --> 00:07:11,660
so our guiding intuition is that rather

192
00:07:09,410 --> 00:07:13,850
than tracing test cases to find coverage

193
00:07:11,660 --> 00:07:15,470
that way we want to find the few

194
00:07:13,850 --> 00:07:17,060
coverage increasing test cases without

195
00:07:15,470 --> 00:07:19,130
having to trace every single one of

196
00:07:17,060 --> 00:07:21,050
these test cases generated so rather

197
00:07:19,130 --> 00:07:22,909
than using a magnifying glass on every

198
00:07:21,050 --> 00:07:24,740
single piece of hay we're just going to

199
00:07:22,910 --> 00:07:26,930
stick our hand in there get poked and

200
00:07:24,740 --> 00:07:28,790
then realize we found the few coverage

201
00:07:26,930 --> 00:07:32,660
increasing test cases that way so it's a

202
00:07:28,790 --> 00:07:35,270
lot more efficient so how this looks

203
00:07:32,660 --> 00:07:37,160
like on a micro scale so we instead of

204
00:07:35,270 --> 00:07:39,080
relying on tracing instrumentation we

205
00:07:37,160 --> 00:07:40,850
use interrupts so in this application

206
00:07:39,080 --> 00:07:42,740
here let's say we want to track the

207
00:07:40,850 --> 00:07:45,220
coverage of block b1 that's kind of

208
00:07:42,740 --> 00:07:49,130
starting point of the control flow graph

209
00:07:45,220 --> 00:07:50,120
and we would write the first hex byte of

210
00:07:49,130 --> 00:07:53,750
it with an interrupt

211
00:07:50,120 --> 00:07:55,010
so as the test case triggers that sorry

212
00:07:53,750 --> 00:07:56,660
executes that basic block it will

213
00:07:55,010 --> 00:07:59,690
trigger the interrupt and thus we know

214
00:07:56,660 --> 00:08:01,580
that it has increased code coverage so

215
00:07:59,690 --> 00:08:03,620
now we want to ensure that no future

216
00:08:01,580 --> 00:08:05,659
test cases with the same code coverage

217
00:08:03,620 --> 00:08:07,490
as that first test case will also hit

218
00:08:05,660 --> 00:08:09,919
that interrupt and mistakenly barked and

219
00:08:07,490 --> 00:08:11,660
excuse me mistakenly be marks has

220
00:08:09,919 --> 00:08:13,789
coverage increasing we will reset that

221
00:08:11,660 --> 00:08:16,130
basic block and move on so remove the

222
00:08:13,790 --> 00:08:18,680
interrupt so that no future executions

223
00:08:16,130 --> 00:08:20,180
going through that basic block will

224
00:08:18,680 --> 00:08:21,620
trigger the interrupt and no other test

225
00:08:20,180 --> 00:08:23,720
cases will be mistakenly marked as

226
00:08:21,620 --> 00:08:26,030
coverage increasing so how this looks

227
00:08:23,720 --> 00:08:28,400
like on am on a macro scale we want to

228
00:08:26,030 --> 00:08:30,169
only trace those few coverage increasing

229
00:08:28,400 --> 00:08:32,270
test cases and simply filter out the

230
00:08:30,169 --> 00:08:34,130
rest based on them not hitting any

231
00:08:32,270 --> 00:08:35,870
interrupts whatsoever so give them the

232
00:08:34,130 --> 00:08:37,490
target application we would modify as

233
00:08:35,870 --> 00:08:39,740
statically and apply these interrupts

234
00:08:37,490 --> 00:08:41,060
before we even run it and then the first

235
00:08:39,740 --> 00:08:43,700
test case that hits an interrupt we

236
00:08:41,059 --> 00:08:45,619
would trace it then find all of its

237
00:08:43,700 --> 00:08:47,720
basic blocks that it would hit in a

238
00:08:45,620 --> 00:08:49,930
normal execution using a separate binary

239
00:08:47,720 --> 00:08:51,980
and then remove all the interrupts

240
00:08:49,930 --> 00:08:53,479
respectively in this interrupt binary

241
00:08:51,980 --> 00:08:56,000
and then move on to the next test case

242
00:08:53,480 --> 00:08:57,890
so what happens over time is that as you

243
00:08:56,000 --> 00:08:59,870
encounter more coverage increasing test

244
00:08:57,890 --> 00:09:02,199
cases more interrupts are removed

245
00:08:59,870 --> 00:09:04,880
so as these interrupts become removed

246
00:09:02,200 --> 00:09:06,770
these two binaries start to mirror each

247
00:09:04,880 --> 00:09:07,280
other structurally fault for all intents

248
00:09:06,770 --> 00:09:09,620
and purpose

249
00:09:07,280 --> 00:09:11,720
so what ends up happening is that is as

250
00:09:09,620 --> 00:09:13,160
fewer test cases has the likelihood of

251
00:09:11,720 --> 00:09:15,740
finding coverage increasing test cases

252
00:09:13,160 --> 00:09:17,390
drops the overwhelming majority we call

253
00:09:15,740 --> 00:09:19,220
this the common case the non coverage

254
00:09:17,390 --> 00:09:21,260
increasing test cases will be run

255
00:09:19,220 --> 00:09:22,910
without anything interesting happening

256
00:09:21,260 --> 00:09:25,610
between enter and exit of the spidery no

257
00:09:22,910 --> 00:09:27,530
interrupts no tracing nothing and they

258
00:09:25,610 --> 00:09:30,650
will be run at 0% over at native

259
00:09:27,530 --> 00:09:32,569
execution speed so we're basically only

260
00:09:30,650 --> 00:09:34,430
tracing the few coverage increasing test

261
00:09:32,570 --> 00:09:37,490
cases are running the rest without any

262
00:09:34,430 --> 00:09:39,140
overhead whatsoever so how this looks

263
00:09:37,490 --> 00:09:41,300
like as we incorporated into coverage

264
00:09:39,140 --> 00:09:42,770
guide at fuzzing so we insert this

265
00:09:41,300 --> 00:09:44,329
filter right after this test case

266
00:09:42,770 --> 00:09:47,689
generation process and before this

267
00:09:44,330 --> 00:09:49,460
coverage tracing step so here for every

268
00:09:47,690 --> 00:09:50,900
test case that you generate you would

269
00:09:49,460 --> 00:09:53,840
execute at first on this application

270
00:09:50,900 --> 00:09:55,610
with these interrupts inserted and for

271
00:09:53,840 --> 00:09:57,080
the overwhelming majority that simply do

272
00:09:55,610 --> 00:09:58,700
not trigger interrupts we would just

273
00:09:57,080 --> 00:10:00,830
throw them away at that step without

274
00:09:58,700 --> 00:10:04,520
even having to trace them and for the

275
00:10:00,830 --> 00:10:06,410
few that do we would run them on this

276
00:10:04,520 --> 00:10:08,270
tracing binary we would extract their

277
00:10:06,410 --> 00:10:10,939
coverage and remove the interrupts

278
00:10:08,270 --> 00:10:12,680
accordingly so again over time as you

279
00:10:10,940 --> 00:10:14,690
encounter more coverage increasing test

280
00:10:12,680 --> 00:10:18,079
cases interrupts are removed and the

281
00:10:14,690 --> 00:10:21,920
common case is run on a binary without

282
00:10:18,080 --> 00:10:25,400
any extra overhead so native execution

283
00:10:21,920 --> 00:10:27,229
speed in the common case in our

284
00:10:25,400 --> 00:10:30,140
implementation which we call on tracer

285
00:10:27,230 --> 00:10:31,910
we use the static rewriting blackbox

286
00:10:30,140 --> 00:10:33,470
base tracing approach Dinah's for

287
00:10:31,910 --> 00:10:36,500
tracing these few coverage increasing

288
00:10:33,470 --> 00:10:38,990
test cases so moving on through our

289
00:10:36,500 --> 00:10:41,150
evaluation our first question was we

290
00:10:38,990 --> 00:10:43,220
want to strictly isolate the tracing

291
00:10:41,150 --> 00:10:44,300
overhead of coverage gyda tracing and

292
00:10:43,220 --> 00:10:46,310
compare it to these other kind of

293
00:10:44,300 --> 00:10:48,349
de-facto approaches that fuzzing relies

294
00:10:46,310 --> 00:10:49,790
on for tracing test cases so we looked

295
00:10:48,350 --> 00:10:52,850
at some of the most common approaches

296
00:10:49,790 --> 00:10:54,770
Dyne instant chemo and afl's assembly

297
00:10:52,850 --> 00:10:56,390
time so it makes of black and white box

298
00:10:54,770 --> 00:10:58,250
base tracing approaches as well as our

299
00:10:56,390 --> 00:11:01,699
covers guided tracing framework on

300
00:10:58,250 --> 00:11:03,080
tracer until isolated overhead we use

301
00:11:01,700 --> 00:11:04,339
single core virtual machines to

302
00:11:03,080 --> 00:11:07,370
eliminate any kind of operating system

303
00:11:04,339 --> 00:11:09,560
interference we stripped AFL to just its

304
00:11:07,370 --> 00:11:13,880
tracing code and we selected pretty

305
00:11:09,560 --> 00:11:15,469
diverse benchmarks the kind of good have

306
00:11:13,880 --> 00:11:18,200
a varied model of real-world behavior

307
00:11:15,470 --> 00:11:20,860
and we compared the tracer execution

308
00:11:18,200 --> 00:11:23,530
times across five days worth of

309
00:11:20,860 --> 00:11:24,910
test cases one test case at a time so

310
00:11:23,530 --> 00:11:26,980
five days worth of test cases for a

311
00:11:24,910 --> 00:11:28,839
benchmark and five trials for each one

312
00:11:26,980 --> 00:11:31,840
of these days worth of test cases per

313
00:11:28,840 --> 00:11:33,340
benchmark so these are our benchmarks

314
00:11:31,840 --> 00:11:35,380
and as you can see we wanted to very

315
00:11:33,340 --> 00:11:37,750
carefully select benchmarks that were a

316
00:11:35,380 --> 00:11:40,360
varying type varying file format but

317
00:11:37,750 --> 00:11:42,940
most importantly varying codes so no

318
00:11:40,360 --> 00:11:44,890
benchmarks here from the same package or

319
00:11:42,940 --> 00:11:48,280
library so we wanted to very carefully

320
00:11:44,890 --> 00:11:50,470
have a good variety of benchmarks our

321
00:11:48,280 --> 00:11:52,030
first evaluation question here was how

322
00:11:50,470 --> 00:11:54,580
can how does covers guy to trace and

323
00:11:52,030 --> 00:11:57,189
compare - tracing every test case with a

324
00:11:54,580 --> 00:11:59,530
black box tracing approach and we

325
00:11:57,190 --> 00:12:01,480
actually beat them by quite a bit so in

326
00:11:59,530 --> 00:12:03,880
comparison to these approaches which

327
00:12:01,480 --> 00:12:06,040
trace using a slow tracer of every

328
00:12:03,880 --> 00:12:07,660
single test case the fact that we are

329
00:12:06,040 --> 00:12:09,969
only tracing these few coverage

330
00:12:07,660 --> 00:12:12,040
increasing test cases brings us down to

331
00:12:09,970 --> 00:12:14,740
about three tenths of a percent of

332
00:12:12,040 --> 00:12:16,930
overhead so okay we were thinking that

333
00:12:14,740 --> 00:12:19,690
this is a pretty good reduction how do

334
00:12:16,930 --> 00:12:21,790
we compare to kind of the the fast

335
00:12:19,690 --> 00:12:24,610
tracing approaches that that white box

336
00:12:21,790 --> 00:12:27,010
tracing offers for fuzzing and from

337
00:12:24,610 --> 00:12:29,800
there we looked at AFL clang AFL's out

338
00:12:27,010 --> 00:12:32,110
of the box assembly time based tracing

339
00:12:29,800 --> 00:12:33,640
approach and we discovered that we

340
00:12:32,110 --> 00:12:38,110
actually beat them by quite a bit so

341
00:12:33,640 --> 00:12:39,640
about 36% reduction compared to the one

342
00:12:38,110 --> 00:12:41,230
of the fastest based tracing approaches

343
00:12:39,640 --> 00:12:43,510
right now and the interesting thing is

344
00:12:41,230 --> 00:12:45,730
that although AFL playing by itself has

345
00:12:43,510 --> 00:12:47,830
lower overhead than dynast which is what

346
00:12:45,730 --> 00:12:50,590
we relied on the fact that we were using

347
00:12:47,830 --> 00:12:52,900
dynast so sparingly gave us such as

348
00:12:50,590 --> 00:12:54,850
strict advantage over AFL clang which

349
00:12:52,900 --> 00:12:57,130
although it was faster traced every

350
00:12:54,850 --> 00:12:58,540
single test case so this gives some

351
00:12:57,130 --> 00:13:00,850
credence as to how coverage got it

352
00:12:58,540 --> 00:13:03,550
tracing has a direct impact on reducing

353
00:13:00,850 --> 00:13:05,770
overhead across fuzzing all these

354
00:13:03,550 --> 00:13:07,089
different test cases so our next

355
00:13:05,770 --> 00:13:09,689
question was okay how does this

356
00:13:07,090 --> 00:13:12,760
reduction in overhead impact the overall

357
00:13:09,690 --> 00:13:14,350
fuzzer throughput so our goal here was

358
00:13:12,760 --> 00:13:16,000
to measure the total number of test

359
00:13:14,350 --> 00:13:18,580
cases done in a pretty reasonable amount

360
00:13:16,000 --> 00:13:21,070
of time so again we looked for 24 hours

361
00:13:18,580 --> 00:13:24,430
across eight benchmarks five trials each

362
00:13:21,070 --> 00:13:27,490
we used Q sim which is a very advanced

363
00:13:24,430 --> 00:13:29,170
kind of hybrid fuzzer similar to driller

364
00:13:27,490 --> 00:13:31,570
it basically combines con Kollek

365
00:13:29,170 --> 00:13:32,849
execution alongside these naive fuzzing

366
00:13:31,570 --> 00:13:35,130
approaches

367
00:13:32,850 --> 00:13:37,829
and we discovered that the fact that

368
00:13:35,130 --> 00:13:39,720
coverage guided tracing reduces tracing

369
00:13:37,829 --> 00:13:41,910
over it so much because it only traces

370
00:13:39,720 --> 00:13:45,630
coverage increasing test cases gave it a

371
00:13:41,910 --> 00:13:47,810
decisive advantage and tracing sorry in

372
00:13:45,630 --> 00:13:50,310
producing more test cases overall than

373
00:13:47,810 --> 00:13:52,888
cucm using ki-moon to trace every test

374
00:13:50,310 --> 00:13:55,018
case and QS him using AFL's assembly

375
00:13:52,889 --> 00:13:58,110
time white box tracing for every single

376
00:13:55,019 --> 00:13:59,760
test case so pretty big reduction and

377
00:13:58,110 --> 00:14:03,829
overhead results in a pretty big

378
00:13:59,760 --> 00:14:08,130
advantage and number of test cases a

379
00:14:03,829 --> 00:14:11,479
belated over time so to conclude why is

380
00:14:08,130 --> 00:14:13,800
coverage guided tracing such a good

381
00:14:11,480 --> 00:14:15,899
complement to these other approaches so

382
00:14:13,800 --> 00:14:17,969
we know that fuzzers spend a lot of

383
00:14:15,899 --> 00:14:19,740
their time finding coverage increasing

384
00:14:17,970 --> 00:14:21,720
test cases by tracing every single one

385
00:14:19,740 --> 00:14:23,760
of them and comparing each of their

386
00:14:21,720 --> 00:14:26,160
coverage to some globally stored

387
00:14:23,760 --> 00:14:28,199
coverage over time and that this amounts

388
00:14:26,160 --> 00:14:30,269
to about over 90% of their time on

389
00:14:28,199 --> 00:14:33,019
average across you know naive and

390
00:14:30,269 --> 00:14:36,660
intelligent fuzzers alike yet over

391
00:14:33,019 --> 00:14:38,160
99.99% of these test cases along with

392
00:14:36,660 --> 00:14:40,350
their code coverage are completely

393
00:14:38,160 --> 00:14:42,480
discarded we see this as being a huge

394
00:14:40,350 --> 00:14:43,920
waste of resources so in other words we

395
00:14:42,480 --> 00:14:46,529
can better allocate these resources

396
00:14:43,920 --> 00:14:48,990
elsewhere in the fuzzing process to help

397
00:14:46,529 --> 00:14:50,459
find bugs in different ways and this is

398
00:14:48,990 --> 00:14:53,190
where coverage got at racing fits in by

399
00:14:50,459 --> 00:14:55,410
trying to restrict code coverage tracing

400
00:14:53,190 --> 00:14:56,880
to just those test cases guaranteed to

401
00:14:55,410 --> 00:14:59,310
increase code coverage and we filter out

402
00:14:56,880 --> 00:15:00,750
the rest that native execution speed and

403
00:14:59,310 --> 00:15:03,469
this results in a performance advantage

404
00:15:00,750 --> 00:15:05,970
we reduced the overall overhead of

405
00:15:03,470 --> 00:15:09,240
fuzzing execution to about three tenths

406
00:15:05,970 --> 00:15:11,490
of a percent and as a result we we boost

407
00:15:09,240 --> 00:15:14,190
the overall test case throughput between

408
00:15:11,490 --> 00:15:17,010
70 to 616 percent so quite a big

409
00:15:14,190 --> 00:15:19,589
advantage there and because we focused

410
00:15:17,010 --> 00:15:22,199
on strictly filtering out test cases and

411
00:15:19,589 --> 00:15:23,699
and just to show we use Dinah's very

412
00:15:22,199 --> 00:15:25,889
slow tracing approach the fact that we

413
00:15:23,699 --> 00:15:27,449
are tracing so infrequently means you

414
00:15:25,889 --> 00:15:30,000
can in theory use whatever tracer you

415
00:15:27,449 --> 00:15:31,500
want whether it's Intel PT or LOV M

416
00:15:30,000 --> 00:15:33,510
based instrumentation and even bring

417
00:15:31,500 --> 00:15:36,360
this overhead down closer to zero

418
00:15:33,510 --> 00:15:38,370
percent over time and and because we

419
00:15:36,360 --> 00:15:40,649
focus on on strictly filtering out test

420
00:15:38,370 --> 00:15:42,269
cases we maintain orthogonality with

421
00:15:40,649 --> 00:15:45,630
these other great approaches like angora

422
00:15:42,269 --> 00:15:46,950
and Boozer which aim to improve the test

423
00:15:45,630 --> 00:15:51,210
case generation

424
00:15:46,950 --> 00:15:53,310
so we're we work with them and with that

425
00:15:51,210 --> 00:15:56,430
I would like to welcome you to download

426
00:15:53,310 --> 00:15:58,319
check out clone for car code integrate

427
00:15:56,430 --> 00:16:01,620
into your fuzzers and get the best

428
00:15:58,320 --> 00:16:07,850
throughput possible so thank you so much

429
00:16:01,620 --> 00:16:09,930
[Applause]

430
00:16:07,850 --> 00:16:12,750
and we have time for questions please

431
00:16:09,930 --> 00:16:15,689
state your name and affiliation hung in

432
00:16:12,750 --> 00:16:19,680
from UC Riverside so the idea used in

433
00:16:15,690 --> 00:16:22,200
three to Trey's blogs is not new okay so

434
00:16:19,680 --> 00:16:24,839
in 2012 I just checked you know some

435
00:16:22,200 --> 00:16:26,940
user encounters a blog use this idea to

436
00:16:24,840 --> 00:16:30,240
trace the coverage and in fact in our

437
00:16:26,940 --> 00:16:32,970
topic CDC team we use this idea to for

438
00:16:30,240 --> 00:16:34,350
fuzzing so I don't when you proposed

439
00:16:32,970 --> 00:16:36,510
this idea do you have you checked that

440
00:16:34,350 --> 00:16:38,100
this has been done for years the only

441
00:16:36,510 --> 00:16:39,870
approaches we've seen that use any kind

442
00:16:38,100 --> 00:16:41,070
of debugger interrupts course strictly

443
00:16:39,870 --> 00:16:42,630
these kinds of software engineering

444
00:16:41,070 --> 00:16:45,570
approaches they use it for unit testing

445
00:16:42,630 --> 00:16:47,430
we did not find any approach that used a

446
00:16:45,570 --> 00:16:50,340
strictly coverage got a tracing approach

447
00:16:47,430 --> 00:16:51,959
to you know use interrupts with every

448
00:16:50,340 --> 00:16:53,460
single basic block and reduce the set of

449
00:16:51,960 --> 00:16:55,260
test cases traced but I'd be happy to

450
00:16:53,460 --> 00:16:57,090
talk offline more about okay another

451
00:16:55,260 --> 00:16:59,880
question so you would talk about the

452
00:16:57,090 --> 00:17:02,700
throughput increate and increased what

453
00:16:59,880 --> 00:17:04,680
do you compare to you know for AFL he

454
00:17:02,700 --> 00:17:05,189
has this floor cam mechanism so kind of

455
00:17:04,680 --> 00:17:08,069
Skiba

456
00:17:05,189 --> 00:17:10,100
yes so we we measure so for every test

457
00:17:08,069 --> 00:17:12,540
case sorry I forgot to include this and

458
00:17:10,099 --> 00:17:14,849
my elaboration about it so we have this

459
00:17:12,540 --> 00:17:16,770
baseline execution overhead which was

460
00:17:14,849 --> 00:17:19,020
just the fork server no tracing

461
00:17:16,770 --> 00:17:23,010
component whatsoever okay so everything

462
00:17:19,020 --> 00:17:26,550
was scaled relative to that Hey hi Lukas

463
00:17:23,010 --> 00:17:29,580
trayzell from UCSB Santa Barbara so my

464
00:17:26,550 --> 00:17:31,139
question is I can include I can see how

465
00:17:29,580 --> 00:17:33,659
this would improve performance in the

466
00:17:31,140 --> 00:17:36,210
case for where your coverage metric is

467
00:17:33,660 --> 00:17:38,550
basic block coverage now for example a

468
00:17:36,210 --> 00:17:42,600
FL has a coverage metric that is branch

469
00:17:38,550 --> 00:17:44,340
based coverage with you including not

470
00:17:42,600 --> 00:17:46,230
tracing every single input that doesn't

471
00:17:44,340 --> 00:17:48,540
hit a new basic block don't you

472
00:17:46,230 --> 00:17:50,730
basically remove every coverage metric

473
00:17:48,540 --> 00:17:52,680
other than basic block coverage reducing

474
00:17:50,730 --> 00:17:54,060
it to basic block coverage so thing

475
00:17:52,680 --> 00:17:56,100
about coverage metric is this actually

476
00:17:54,060 --> 00:17:57,659
it's a trade-off fuzzing is all about

477
00:17:56,100 --> 00:17:59,399
trade-offs right so if you have a deeper

478
00:17:57,660 --> 00:18:01,049
coverage metric like AF elbows

479
00:17:59,399 --> 00:18:02,309
Edge's and hit counts you're actually

480
00:18:01,049 --> 00:18:04,710
gonna be running that data structure a

481
00:18:02,309 --> 00:18:06,599
lot more interestingly hongfa is a

482
00:18:04,710 --> 00:18:07,940
competing fuzzer does just basic block

483
00:18:06,599 --> 00:18:10,229
level coverage although they can

484
00:18:07,940 --> 00:18:12,509
incorporate edges as well through static

485
00:18:10,229 --> 00:18:13,769
transformations but they do so without

486
00:18:12,509 --> 00:18:15,509
hit counter that's also a very

487
00:18:13,769 --> 00:18:17,759
successful approach the point is it's

488
00:18:15,509 --> 00:18:20,190
not really clear what the best coverage

489
00:18:17,759 --> 00:18:21,269
metric is for finding crashes in a

490
00:18:20,190 --> 00:18:22,649
reasonable amount of time on a

491
00:18:21,269 --> 00:18:24,839
real-world program so we have some work

492
00:18:22,649 --> 00:18:26,668
kind of exploring that right now so I

493
00:18:24,839 --> 00:18:29,999
just said that I just wanted to know if

494
00:18:26,669 --> 00:18:32,369
you had an evaluation of the actual

495
00:18:29,999 --> 00:18:35,099
coverage increases over time versus

496
00:18:32,369 --> 00:18:36,869
something that like Native AFL that uses

497
00:18:35,099 --> 00:18:38,580
a difference we focus strictly on on

498
00:18:36,869 --> 00:18:40,080
improving performance but our code is

499
00:18:38,580 --> 00:18:41,668
available so if you'd like to look at

500
00:18:40,080 --> 00:18:45,658
our integration with AFL and compare

501
00:18:41,669 --> 00:18:47,159
that's a standard a failure welcome hi

502
00:18:45,659 --> 00:18:49,979
Parliament result from Polytechnic of

503
00:18:47,159 --> 00:18:52,769
Milano I was just wondering whether you

504
00:18:49,979 --> 00:18:55,679
try to see how you're using your

505
00:18:52,769 --> 00:18:58,399
approach impact bug finding funding

506
00:18:55,679 --> 00:19:00,989
sorry because I just so like performance

507
00:18:58,399 --> 00:19:03,268
scores but I haven't seen like bugs

508
00:19:00,989 --> 00:19:05,639
so in our kind of micro evaluations we

509
00:19:03,269 --> 00:19:07,139
saw that we were indeed finding bugs but

510
00:19:05,639 --> 00:19:08,699
because we're not trying to compete with

511
00:19:07,139 --> 00:19:10,529
these approaches that focus on better

512
00:19:08,700 --> 00:19:12,089
input generation like Boozer and angora

513
00:19:10,529 --> 00:19:14,339
and pro fuzzer and new as in this

514
00:19:12,089 --> 00:19:16,440
session we're just trying to increase

515
00:19:14,339 --> 00:19:18,960
their throughput so we're strictly

516
00:19:16,440 --> 00:19:20,549
focusing on making tracing as fast as

517
00:19:18,960 --> 00:19:22,379
possible and we feel that we would

518
00:19:20,549 --> 00:19:24,599
better compliment them so I think a more

519
00:19:22,379 --> 00:19:25,859
fair approach would be to you know one

520
00:19:24,599 --> 00:19:27,210
of these approaches combined with

521
00:19:25,859 --> 00:19:29,580
coverage guide tracing versus the

522
00:19:27,210 --> 00:19:30,929
approach you know kinda natively yeah I

523
00:19:29,580 --> 00:19:33,330
get it but like for example let's say

524
00:19:30,929 --> 00:19:34,830
that your approach is faster but in the

525
00:19:33,330 --> 00:19:36,509
end you find less bugs because you

526
00:19:34,830 --> 00:19:38,699
remove stuff that might be interesting

527
00:19:36,509 --> 00:19:40,349
have you tried to look at that so

528
00:19:38,700 --> 00:19:41,940
because we're these fuzzers

529
00:19:40,349 --> 00:19:43,739
fundamentally rely on either block or

530
00:19:41,940 --> 00:19:45,570
edge coverage and coverage guide tracing

531
00:19:43,739 --> 00:19:47,070
fundamentally can support block or edge

532
00:19:45,570 --> 00:19:48,450
coverage we don't think that is there's

533
00:19:47,070 --> 00:19:53,789
theoretically any reason that we would

534
00:19:48,450 --> 00:19:54,659
finalize bugs but okay well thanks time

535
00:19:53,789 --> 00:19:56,399
for one more question

536
00:19:54,659 --> 00:19:58,619
yong joon-hyung from Oregon State

537
00:19:56,399 --> 00:20:00,748
University so my question is well like

538
00:19:58,619 --> 00:20:03,359
you have used like the debug range of

539
00:20:00,749 --> 00:20:05,849
the interrupt to like a check if this

540
00:20:03,359 --> 00:20:07,408
branch has visited or not yeah but what

541
00:20:05,849 --> 00:20:09,239
I think is the more important thing for

542
00:20:07,409 --> 00:20:11,489
finding bug is like and not just code

543
00:20:09,239 --> 00:20:12,510
coverage like how many times we repeat

544
00:20:11,489 --> 00:20:13,890
some of the loops or

545
00:20:12,510 --> 00:20:16,590
some of the function executions or

546
00:20:13,890 --> 00:20:18,720
something but from the explaination what

547
00:20:16,590 --> 00:20:21,060
I'm seeing is like a you are just taking

548
00:20:18,720 --> 00:20:23,340
caring about the visit or not not about

549
00:20:21,060 --> 00:20:25,740
the like how many times about the

550
00:20:23,340 --> 00:20:27,929
executing of the some of the loops who

551
00:20:25,740 --> 00:20:30,240
are like a bigger program executions in

552
00:20:27,930 --> 00:20:32,940
this regard I think like it'll be very

553
00:20:30,240 --> 00:20:35,100
hard to find some of the bug because

554
00:20:32,940 --> 00:20:36,960
like a code coverage itself only tells

555
00:20:35,100 --> 00:20:38,250
like a can you reach to certain points

556
00:20:36,960 --> 00:20:40,590
not about the triggering that

557
00:20:38,250 --> 00:20:42,870
variability so could you share your like

558
00:20:40,590 --> 00:20:44,760
this some insights about the thoughts

559
00:20:42,870 --> 00:20:46,530
about like that so so again you know

560
00:20:44,760 --> 00:20:49,170
there's no real evaluation that's been

561
00:20:46,530 --> 00:20:51,300
done to show whether hit counts or edges

562
00:20:49,170 --> 00:20:53,820
excuse me edges or blocks or edges with

563
00:20:51,300 --> 00:20:55,169
blocks or blocks with excuse me edges

564
00:20:53,820 --> 00:20:56,669
with hit counts or blocks with hit

565
00:20:55,170 --> 00:20:58,560
counts as the best metric because you

566
00:20:56,670 --> 00:21:00,690
know it's a game of of do I want to

567
00:20:58,560 --> 00:21:02,879
sacrifice performance for precision AFL

568
00:21:00,690 --> 00:21:04,800
itself does this kind of course

569
00:21:02,880 --> 00:21:08,100
consideration of hit counts they use

570
00:21:04,800 --> 00:21:09,090
these kind of like very large buckets we

571
00:21:08,100 --> 00:21:11,760
have some work that's trying to

572
00:21:09,090 --> 00:21:13,439
definitively answer that question but as

573
00:21:11,760 --> 00:21:15,300
far as addressing hit counts so because

574
00:21:13,440 --> 00:21:17,540
you know coverage guide tracing operates

575
00:21:15,300 --> 00:21:19,800
at the block level we have you know

576
00:21:17,540 --> 00:21:21,120
incorporating hit counts via static

577
00:21:19,800 --> 00:21:24,750
transformations is something that we're

578
00:21:21,120 --> 00:21:28,669
kind of exploring right now so answer

579
00:21:24,750 --> 00:21:33,140
your question alright weaker

580
00:21:28,670 --> 00:21:33,140
[Applause]

